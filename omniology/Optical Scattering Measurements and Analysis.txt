SPIE PRESS


Stover, John C.
Optical scattering : measurement and analysis / John C. Stover. – 3rd ed.
p. cm.
Includes bibliographical references and index.
ISBN 978-0-8194-9251-7
1. Light–Scattering. I. Title.
QC427.4.S76 2012
535
′
.43–dc23
2012017677
Published by
SPIE
P.O. Box 10
Bellingham, Washington 98227-0010 USA
Phone: +1 360.676.3290
Fax: +1 360.647.1445
Email: Books@spie.org
Web: http://spie.org
Copyright c⃝2012 Society of Photo-Optical Instrumentation Engineers (SPIE)
All rights reserved. No part of this publication may be reproduced or distributed in
any form or by any means without written permission of the publisher.
The content of this book reﬂects the work and thoughts of the author(s).
Every effort has been made to publish reliable and accurate information herein,
but the publisher is not responsible for the validity of the information or for any
outcomes resulting from reliance thereon.
Printed in the United States of America.
First printing

Bellingham, Washington  USA

 

Dedication
I’ve been privileged to play a small part in moving the measurement of surface
scatter from an art to a metrology. En route, I had the opportunity to work with
many of the individuals that made this possible. Four of them come to mind as
performing pivotal roles, and this edition of Optical Scattering is dedicated to their
insight and effort.
Dr. Hal Bennett
In 1961, the year the laser was invented, Hal published the ﬁrst paper detailing the
use of a TIS instrument with Jim Porteus. This effectively started scatter metrology.
Hal, his wife Jean, and their coworkers at China Lake followed this up with dozens
of papers on surface metrology.
Dr. Petr Beckmann
Petr wrote The Scattering of Electromagnetic Waves from Rough Surfaces (1963
and 1987) with Andre Spizzichino. This book introduced the idea of measuring
scatter as a function of angle and relating it to surface statistics.
Dr. Eugene Church
Gene introduced the Rayleigh–Rice vector perturbation theory to the BRDF
community in 1975, providing an accurate polarization-sensitive relationship
between scatter and surface statistics. His following publications introduced the
importance of spatial bandwidths and detailed elegant ways of expressing surface
statistics.
Dr. Yuri Eremin
Yuri led a team at Moscow State University creating scatter models of
surface-bound features. The models have resulted in dramatic improvements in
semiconductor particle scanners. He is a coauthor of Acoustic and Electromagnetic
Scattering Analysis (2000), where much of his nonproprietary work is published.

 

Contents
Preface to the First Edition .............................................................................. xiii
Preface to the Second Edition.......................................................................... xv
Acknowledgments for the Second Edition.................................................... xvii
Preface to the Third Edition............................................................................. xix
Acknowledgments for the Third Edition......................................................... xxi
List of Acronyms............................................................................................. xxiii
Chapter 1
Quantifying Light Scatter ............................................................
1
1.1
The Scattering of Light ..................................................................................
2
1.2
Scatter from a Smooth Sinusoidal Surface..............................................
3
1.3
Scatter from Other Surfaces .........................................................................
8
1.4
Scatter from Windows and Particulates....................................................
11
1.5
Bidirectional Scatter Distribution Functions ..........................................
14
1.6
Total Integrated Scatter ..................................................................................
17
1.7
Differential Scattering Cross Section........................................................
20
1.8
Summary.............................................................................................................
21
Chapter 2
Quantifying Surface Roughness ................................................ 23
2.1
Proﬁle Characterization .................................................................................
23
2.1.1
Deterministic proﬁles .....................................................................
24
2.1.2
Random proﬁles ...............................................................................
29
2.1.3
Sampled proﬁles...............................................................................
30
2.1.4
Two-dimensional (area) proﬁles.................................................
31
2.2
The Surface Power Spectral Density and Autocovariance
Functions.............................................................................................................
34
2.2.1
The power spectral density function from the proﬁle .........
34
2.2.2
Extension to two-dimensional spectra......................................
38
2.2.3
The autocorrelation function........................................................
40
2.3
The Effects of Proﬁle Measurement Error...............................................
43
2.4
Summary.............................................................................................................
44
vii

viii
Contents
Chapter 3
Scatter Calculations and Diffraction Theory............................. 47
3.1
Overview.............................................................................................................
47
3.2
Kirchhoff Diffraction Theory.......................................................................
52
3.3
The Rayleigh Approach.................................................................................
60
3.4
Comparison of Scalar and Vector Results................................................
64
3.5
Calculating Scatter from Optically Rough Surfaces ............................
65
3.5.1
The Beckmann rough-surface result .........................................
66
3.5.2
Other rough-surface calculations................................................
67
3.6
Summary.............................................................................................................
68
Chapter 4
Using Rayleigh–Rice to Calculate Smooth-Surface Statis-
tics from the BRDF............................................................................................ 69
4.1
Practical Application of the Rayleigh–Rice Perturbation Theory ...
69
4.2
Roughness Statistics of Isotropic Surfaces..............................................
74
4.3
Roughness Statistics of One-Dimensional Surfaces ............................
77
4.4
Roughness Statistics for the General Case ..............................................
84
4.5
The ABC or K-Correlation Surface Power Spectrum Models..........
85
4.5.1
The Lorentzian power spectrum .................................................
86
4.5.2
Fractal surfaces.................................................................................
86
4.6
The TIS Derivation from the Rayleigh–Rice Perturbation
Theory..................................................................................................................
88
4.7
Summary.............................................................................................................
89
Chapter 5
Polarization of Scattered Light ................................................... 91
5.1
A Review of Polarization Concepts...........................................................
92
5.2
The Polarization Factor Q.............................................................................
99
5.3
Scattering Vectors and Matrices.................................................................. 103
5.4
Summary............................................................................................................. 108
Chapter 6
Scattering Models for Discrete Surface Features..................... 109
6.1
Particle Scatter .................................................................................................. 109
6.2
Modeling Techniques and Accomplishments......................................... 110
6.3
Model Availability ........................................................................................... 113
6.4
Summary............................................................................................................. 114
Chapter 7
Instrumentation and Measurement Issues................................ 115
7.1
Scatterometer Components........................................................................... 115
7.2
Instrument Signature....................................................................................... 118
7.3
Aperture Effects on the Measured BSDF ................................................ 120
7.4
Signature Reduction and Near-Specular Measurements..................... 123
7.4.1
Reﬂective versus refractive focusing optics............................ 124

Contents
ix
7.4.2
Minimizing the near-angle/far-angle boundary θN .............. 126
7.4.3
Scatter measurement inside θN ................................................... 128
7.5
Scatter Screens.................................................................................................. 130
7.6
The Noise-Equivalent BSDF........................................................................ 131
7.7
Measurement of Scatter from Discrete Surface Features in DSC
Units ..................................................................................................................... 134
7.8
Measurement of Pi and Instrument Calibration..................................... 134
7.9
Measurement of Curved Optics................................................................... 137
7.10
Coordinate Systems and Out-of-Plane Measurements........................ 137
7.11
Camera-based Systems................................................................................... 140
7.12
Raster Scans....................................................................................................... 141
7.13
Measurement of Retroreﬂection.................................................................. 144
7.14
Alternative TIS Devices................................................................................. 146
7.15
Error Analysis of the Measured BSDF..................................................... 150
7.16
Obtaining Appropriate PSD Measurements............................................ 152
7.17
Summary............................................................................................................. 155
Chapter 8
Predicting Scatter from Roughness........................................... 157
8.1
Optical Surfaces: Using the Rayleigh–Rice Equation......................... 158
8.1.1
The general case............................................................................... 159
8.1.2
Isotropic samples ............................................................................. 160
8.1.3
One-dimensional samples............................................................. 165
8.2
Optically Rough Front-Surface Reﬂectors .............................................. 166
8.2.1
Stretching the Rayleigh smooth-surface limit........................ 166
8.2.2
Predicting rough-surface scatter from the PSD..................... 168
8.2.3
TIS measurements and rough surfaces..................................... 168
8.3
Partial Data Sets................................................................................................ 172
8.3.1
Fractal surfaces................................................................................. 172
8.3.2
Curve ﬁtting....................................................................................... 173
8.4
Scatter from Diffuse Samples ...................................................................... 174
8.4.1
Lambertian samples........................................................................ 175
8.4.2
Non-Lambertian samples and material signatures ............... 178
8.5
BRDF Standard Surfaces............................................................................... 178
8.6
Software for Prediction of Stray Light in Optical Systems ............... 180
8.7
Summary............................................................................................................. 183
Chapter 9
Detection of Discrete Defects ..................................................... 185
9.1
Polarization Effects Associated with Defect Scatter............................ 186
9.2
Bulk Defects in Transparent Optics........................................................... 192
9.3
Near-Point-Scatter Sources........................................................................... 197
9.4
Nontopographic Defects in Opaque Materials....................................... 199
9.5
Summary............................................................................................................. 200

x
Contents
Chapter 10 Appearance and Scattered Light................................................ 201
10.1
Beauty is in The Eye of the Beholder—And What We See is
Scattered Light.................................................................................................. 201
10.2
Practical Appearance Monitoring............................................................... 202
10.3
Other Examples ................................................................................................ 206
10.4
Summary............................................................................................................. 207
Chapter 11 Industrial Applications ................................................................ 209
11.1
Semiconductor Applications ........................................................................ 210
11.1.1 Finding small particulates and point defects on polished
surfaces................................................................................................ 211
11.1.2 Scattering and roughness characterization of silicon .......... 212
11.1.3 Particle scanner inspection of wafers........................................ 216
11.2
Computer Disks ................................................................................................ 218
11.3
Measurement of Retinal Scatter Induced by Intraocular Lenses ..... 219
11.4
Contamination Measurement by Wavelength Discrimination .......... 220
11.5
Solar Energy Applications ............................................................................ 220
11.5.1 Photovoltaic collectors................................................................... 221
11.6
General Manufacturing Examples.............................................................. 222
11.6.1 Detection of paper ﬂaws................................................................ 223
11.6.2 Noncontact monitoring of emissivity and temperature....... 224
11.6.3 Ball bearings...................................................................................... 227
11.7
Summary............................................................................................................. 228
Chapter 12 Published Scatter Standards ...................................................... 229
12.1
Integrated Scatter Standards......................................................................... 230
12.2
Angle-Resolved Scatter Standards............................................................. 230
12.3
The PSD Standard............................................................................................ 231
12.4
Standards for Semiconductor Particle Scanners.................................... 231
12.4.1 SEMI M52—Scanner speciﬁcations......................................... 231
12.4.2 SEMI M50—Capture rate............................................................. 233
12.4.3 SEMI M53—Scanner calibration............................................... 235
12.4.4 SEMI M58—Particle deposition conﬁrmation...................... 235
12.5
Summary............................................................................................................. 237
Chapter 13 Scatter Speciﬁcations.................................................................. 239
13.1
Generic Speciﬁcations.................................................................................... 240
13.2
Application-Speciﬁc Speciﬁcations........................................................... 242
13.2.1 Example 1: Scatterometer-focusing mirrors........................... 242
13.2.2 Example 2: Imaging optics........................................................... 244
13.2.3 Example 3: Laser resonator losses............................................. 246

Contents
xi
13.2.4 Example 4: Diffraction from precision-machined
turning mirrors.................................................................................. 250
13.2.5 Example 5: Scatter in a laser rangeﬁnder................................ 251
13.2.6 Example 6: Roughness speciﬁcations for semiconduc-
tor components ................................................................................. 253
13.3
Empirical Scatter Speciﬁcations ................................................................. 254
13.4
Summary............................................................................................................. 255
Appendix A Review of Electromagnetic Wave Propagation......................... 257
A.1
The Wave Equation.......................................................................................... 257
A.2
Electromagnetic Plane Waves in Free Space .......................................... 258
A.3
Plane Waves in a Dielectric .......................................................................... 261
A.4
Plane Waves in a Conducting Medium..................................................... 263
Appendix B Kirchhoff Diffraction from Sinusoidal Gratings ....................... 265
Appendix C BSDF Data .................................................................................... 273
Appendix D Units .............................................................................................. 281
References......................................................................................................... 283
Works Consulted............................................................................................... 297
Index................................................................................................................... 303

 

Preface to the First Edition
This book originates from a set of notes developed over several years of teaching
the fundamentals of light-scatter measurement and analysis to optical engineers
(and those converting to optical engineering) at various conferences. Except for
conference tutorials and a few isolated projects and classroom examples, very
little is formally taught about the subject. The Universities of Arizona, Alabama,
New Mexico, and Montana State have done most of the university scatter work,
and combined they have probably produced less than 50 graduate students with
thesis work on the subject. At the same time, as the sophistication, number, and
expense of optical systems have grown during the 1970s and 80s, optical scatter
has been increasingly recognized as a serious problem. Outside the optics industry,
noncontact process control and metrology scatter applications are just starting to be
recognized. The high economic beneﬁts associated with fast quality control in these
higher-volume industries (paper, steel, aluminum, ceramics, etc.) have created a
need for new inspection techniques. Current indications are that by the year 2000,
there will be more scatter metrology applications found outside the optics industry
than within. As a result, engineers, with or without an optics background, are
ﬁnding themselves thrust (sometimes kicking and screaming) into the position of
becoming “the company scatter expert” as new applications are recognized.
Hundreds of papers have now been written on the subject, using various
notations, starting from different theoretical foundations, and describing small
facets of an increasingly complex ﬁeld of study. These papers can be categorized
as “scatter in theory,” “scatter is a system problem,” or “scatter is a metrology
solution.” The intention of this book is to introduce engineers and physicists to
scatter fundamentals for theory, problems, and solutions, as well as acquaint them
with the rather diverse set of background subjects and literature required to help
them become “the company scatter experts.”
The ﬁrst ﬁve chapters concentrate on background information. Chapter 1 is
required reading for any other chapter, as it introduces much of the notation
and basic concepts. Scatter is often tied to sample surface roughness, and
Chapter 2 overviews the various roughness terms and deﬁnitions. Scatter can
be analyzed from diffraction theory, as shown in Chapter 3. The fourth chapter
combines the results of Chapters 2 and 3 to convert scatter data to surface
statistics. Chapter 5 discusses polarization concepts: there are some very powerful
polarization techniques that can be used in various process- and quality-control
applications. Experimental instrumentation, techniques, limitations, and problems
xiii

xiv
Preface to the First Edition
are covered in Chapter 6. In the seventh chapter, various scatter prediction
techniques are presented. These include wavelength scaling for smooth optical
surfaces and curve ﬁtting for more generic samples. Chapter 8 discusses more-
advanced measurement and analysis techniques that take advantage of polarization
for process- and quality-control applications. Chapter 9 provides a small sampling
of industrial applications. In the last chapter, scatter speciﬁcations are illustrated
through the use of several examples.
Each chapter indicates in its opening paragraphs what material is required for
background, and each chapter closes by indicating which of the following chapters
contain material relating to the same topic. There are three appendices. The
ﬁrst is a review of ﬁeld theory necessary for electromagnetic wave propagation.
Appendix B covers some diffraction theory calculations too detailed for Chapter 3.
Appendix C contains scatter data for several different materials taken at several
different wavelengths and angles of incidence. It is organized so the various plots
can be looked up by either wavelength or sample material. Its purpose is to give
the reader some indication of expected scatter levels that may be encountered. For
example, if after reading the book you are able to determine that your system needs
a zinc selenide beamsplitter with a BTDF of less than 10−3 at 20 deg at 10.6 µm,
you will also be able to determine if this is reasonable, based on previous data.
John C. Stover
August 1990

Preface to the Second Edition
I wrote the ﬁrst edition more for love than for money, and quite frankly, this attitude
turned out to be quite appropriate. I was one of the Optical Engineering Series
authors who suffered through a confusing publisher switch from Macmillan to
McGraw-Hill. In the ﬁnal rush to press, a number of things were left unﬁnished,
and I have always been a little dissatisﬁed with some of the errors that crept in
(yes, Figure 8.5 in the ﬁrst edition is upside down!) and some of the material that
lack of time forced me to leave out. So when McGraw-Hill announced that the ﬁrst
edition was going out of print, I took possession of the book and started back in to
do it again. I have admired the professional attitude and performance of SPIE for
more years than I care to admit, and when I realized that it might be possible to
have them publish a second edition of Optical Scattering, I jumped at the chance.
It makes a lot of sense that a book like this, which will never be printed in large
numbers, have both author and publisher in it for love and not money.
A number of things in scatter measurement have changed or improved in the
last four years, and these are reﬂected in this edition. You will ﬁnd some additions
and changes in every chapter; however, three chapters underwent major changes.
Chapter 2, on roughness calculations, has been reorganized—hopefully in a way
that will make the analysis of surface-proﬁle data more understandable. The
inclusion in Chapter 7 of a section on rough surfaces is intended to help those
readers who are interested in using light scatter as a source of process control for
products that do not meet the smooth-surface criterion so blithely assumed in the
optics industry. The new sections in Chapter 9, on inspection of silicon wafers and
computer disks, are a result of real interest in those industries in catching up with
the optics crowd in scatter/roughness metrology. Bare silicon wafers scatter mostly
from surface topography (as opposed to ﬁlms, discrete defects, etc.). Thus not
only is silicon a great material for illustrating some of the points about roughness
calculations via scatter measurements made throughout the book, but because
roughness and roughness-induced haze are currently high-visibility issues (no pun
intended) in the semiconductor industry, it is information of real contemporary
importance. The same thing is true for the comments and examples on computer
disk inspection, where roughness (called texture in that industry) is also an issue.
I do not expect a third edition. For one reason, SPIE has promised that this
edition will not go out of print as long as there is even a small market for the
information. Secondly, my experience with the ﬁrst edition has taught me that
it is easier to retire on money than on love, and having already sown my wild
xv

xvi
Preface to the Second Edition
academic oats, I probably need to concentrate on retirement and getting four kids
through college (unfortunately not in that order). I wish all of you old and new
“scatterbrains” the very best, and hope you ﬁnd this edition worth your money and
my time.
John C. Stover
July 1995

Acknowledgments for the
Second Edition
Neither the ﬁrst nor second editions of this book would have been possible without
the help and cooperation of a great many people. First, I have to thank my wife
and children for their patience and understanding during twenty long months of
lost weekends and late suppers. I owe a tremendous debt to my coworkers at
TMA. Bob Mathis and Don Bjork made it their job to lighten my load in order
to provide enough time during the work week to complete the book. Marvin Bernt
and Doug McGary are responsible for taking most of the scatter data that appears
in the volume. I used a great deal of information generated by TMA authors for
their technical publications and have had the pleasure, and advantage, of being
able to discuss scatter issues with a ﬁrst-class group of knowledgeable engineers
and physicists who make their living doing scatter research. Dan Cheever, Kyle
Klicker, Tod Schiff, and Dan Wilson, in particular, played key roles in designing
and building the early instrumentation used to generate data and conclusions for
the text. Michele Manry cheerfully typed through the seemingly endless supply
of Greek symbols and manuscript changes to produce the ﬁrst edition, and Cheryl
Petersen repeated the process for the second edition. Mary Horan, senior editor at
SPIE, did a great job of checking the details I ﬁnd so easy to miss. Mark Stefan did
the technical drawings. If every picture is worth a thousand words, he has saved
us all considerable effort. Outside of Bozeman, I am indebted to several members
of the optical community for their help and support. As indicated by the book
references, Dr. Gene Church is a wealth of information on proﬁle analysis and
scatter. He reviewed the entire text and took time from his schedule to discuss his
views with me on many key topics. In many respects, this book could have been his
to write instead of mine. Win Baylies read the book and helped me a great deal with
the additions on the semiconductor and computer-disk industries. Jean Bennett, Hal
Bennett, Bob Breault, Tom Leonard, Steve McNeany, and Joe McNeely are just a
few of the individuals who have given me the support (or needed stimulation) over
the last two decades required to make the book possible. And last, but not least, I
wish to thank Richard Skulski, my ﬁrst industry supervisor (and good friend), for
giving me the chance to work in this exciting technology.
John C. Stover
xvii

Preface to the Third Edition
When the last edition was published, I really didn’t expect another one would
be written. Instrumentation was being sold that could measure down to the
practical noise ﬂoor associated with Rayleigh scatter from air molecules. The math
for scatter from optically smooth surfaces was understood and experimentally
conﬁrmed. Round-robin tests had been performed, ﬁnally conﬁrming that we all
spelled BRDF the same way. What else could possibly be needed? Then, I entered
the semiconductor industry for several years, where signals are scatter from small
isolated defects, and roughness scatter is a noise source, and realized that the book
really only covered half of the scatter issues for that industry. Other industries
became concerned about scatter from much-rougher surfaces (solar energy and
appearance, to name two), and this opened another set of scatter-related problems.
My SPIE course, which was the inspiration for the book, kept changing to keep
up with industry concerns, and eventually I realized that there was material for
another edition. Then, a friend told me that the book was old enough that some of
his colleagues assumed I was dead, and that pushed me into action. As a result, the
book you are holding has three new chapters, several new sections, and a rewrite
of the older material. I expect in another decade or two that there will be enough
material for yet another edition, but without serious advances in medical science
as well, I doubt if I will be writing it.
Several hundred million dollars worth of scatterometers have been sold in
the semiconductor industry since publication of the last edition. They are called
“particle scanners” but are just scatterometers automated for beam scanning and
wafer handling. As you read this, several thousands of these instruments are hard
at work, and they remain so 24/7. International standards are used to support the
speciﬁcation of these instruments, and I was lucky enough to become involved
in writing them in both ASTM and SEMI. Chapter 12 reviews scatter-related
standards.
Just as we learned to model scatter from residual roughness on optics, some
really smart people leaned how to model scatter from discrete surface defects.
Scatter signals can now be used to determine whether that ﬂash of light in a scanner
is from a pit or a particle. Unfortunately, a lot of these models are proprietary (but
not all), and there is a chapter on capabilities and availability of discrete scatter
models.
Beauty is in the eye of the beholder, and, as you are well aware, what we see is
scattered light. As a result, industries concerned with appearance have also learned
xix

xx
Preface to the Third Edition
about BRDF and its measurement. Examples are new car interiors, beer cans, and
movie scenes of everything from dinosaurs to spacecraft. These kinds of problems
often require full hemispherical measurement (not just incident plane scans), and
array camera instrumentation has been developed. There is a new chapter on
appearance (Chapter 10) and new sections involving instrumentation and scatter
from optically rough surfaces.
So once again, dear scatterbrains, I am hoping you ﬁnd the new edition worth
my time and your (company’s?) money.
John C. Stover
Tucson, Arizona
June 2012

 

Acknowledgments for the Third
Edition
This edition would not have been possible without the help of all those who
supported me in earlier versions of the book and in my career. I will approach
my acknowledgments chronologically.
All the way back in 1971, my ﬁrst industry boss, Richard Skulski, had the
conﬁdence to turn me loose to ﬁnd a noncontact way of measuring surface
roughness. I had no idea that it would so dramatically affect my life. After deciding
on light scatter as an approach, I met Petr Beckmann, Hal and Jean Bennett, and
Eugene Church—all leading experts. My work with Gene has continued all these
years, and his contributions to my understanding and to all editions of the book
have been enormous.
After a ﬁve-year stint teaching at Montana State, I helped get TMA Technologies
into the “scatterometer business,” supporting optics for the Star Wars program.
Designing and building instrumentation for those applications required real
engineers. Key contributors were Marvin Bernt, Don Bjork, Fred Cady, John
Carlsten, Dan Cheever, Kyle Klicker, Mary Knighten, Tod Schiff, and Dan Wilson.
A mix of local engineers, professors, and ex-students, they all became my friends
and worked long, hard, creative hours designing, building, and using the CASI R⃝
Scatterometer. Now a quarter-century old, the CASI Scatterometer is still sold
today; it played a key role in moving scatterometry from an art to a metrology
and was used to create most of the data in the book. I have one in my lab today,
so I am still beneﬁting from their efforts. Along the way, TMA learned from our
interactions with Bob Breault, Jim Harvey, Peter Takacs, and Bill Wolfe. After
TMA sold, Yoji Kurokawa facilitated my acquisition of his company’s CASI
Scatterometer, which eventually became crucial to this edition of the book and
is central to how I earn a living.
About the time TMA sold, Win Baylies got me involved in the semiconductor
industry at ADE Corporation. I quickly discovered that I had a lot to learn and
beneﬁted from the expertise of Robert Abbe, Lee Clementi, Mike Fossey, Chuck
Monjak, Craig Scheer, and Kevin Welch, to name a few. We also had a great team
from Moscow State University doing scatter modeling for us, and I still enjoy
interacting with Yuri Eremin, Vlad Lopushenko, and Vlad Ivaknenko. I got started
in industry standards at ADE and worked with Murray Bullis, Thom Germer, Yoshi
Masanori, Noel Peduje, and Peter Wagner, among many others.
xxi

xxii
Acknowledgments for the Third Edition
I am winding up my career in Tucson running The Scatter Works, Inc., and I
enjoy local support from Rich Pﬁsterer, Mike Gauvin, Bill Kuhn, and Bob Parks.
I’ve partnered with Eric Hegstrom to develop new instrumentation. Outside of
Tucson, Angela Duparré, Ed Frenier, Sven Schroeder, and Chris Staats all provide
needed expertise and feedback.
And then there is my wife, who has waited through lost weekends and evenings
as I pondered equations, ﬁgures, and text. Donna—this really is the last one.
I owe all of you a lot. Thank you so much, and God Bless every one of you.
John C. Stover

List of Acronyms
a.a.
arithmetic average
AR
antireﬂection
ARS
angle-resolved scatter
ASTM
American Society of Testing Materials
BRDF
bidirectional reﬂective distribution function
BRO
Breault Research Organization
BSDF
bidirectional scatter distribution function
BTDF
bidirectional transmissive distribution function
BVDF
bidirectional volume distribution function
CAD
computer-aided design
CASI R⃝
complete angle scatter instrument
CCBRDF
cosine-corrected bidirectional reﬂectance distribution
function
CCD
charge-coupled device
COP
crystal-originated particle
cw
continuous wave
dc
direct current
DMA
differential mobility analyzer
DSC
differential scattering cross section
DSM
discrete sources method
EM
electromagnetic
FWHM
full width at half maximum
IOL
intraocular lens
IR
infrared
ISO
International Standards Organization
LED
light-emitting diode
LPD
light point defect
LSE
light-scattering equivalent
MFT
mean-ﬁeld theory
MIST
modeled integrated scattering tool
NEBRDF
noise-equivalent BRDF
NEBSDF
noise-equivalent BSDF
xxiii

xxiv
List of Acronyms
NEP
noise-equivalent power
NIST
National Institute of Standards and Technology
PPM
parts per million
PSD
power spectral density (function)
PSL
polystyrene latex (sphere)
RLG
ring laser gyroscope
rms
root mean square
SEMI
Semiconductor Equipment and Materials International
SRM
standard reference material
SSIS
surface-scanning inspection system (particle scanner)
TCO
transparent conductive oxide
TEM
transverse electromagnetic
TIS
total integrated scatter
TS
total scattering (IOP terminology)

Chapter 1
Quantifying Light Scatter
“But, soft! What light through yonder window breaks?” – Shakespeare
This chapter discusses the origins of light scatter and the various scatter sources
that are commonly observed, and it deﬁnes how scattered light is quantiﬁed. Except
for the following brief overview, the book is largely restricted to the measurement
and analysis of scatter caused by surface, bulk, and contaminant imperfections,
as opposed to scatter from individual molecules, aerosols, and resonance effects,
such as Raman scattering. Scatter from optically smooth components is treated as
diffraction in many cases. For the special case of clean, optically smooth, reﬂective
surfaces, there is a well-deﬁned relationship between the scatter distribution pattern
and surface roughness statistics, and scatter measurements can be manipulated
to characterize the surface. In many cases, insight may be gained into possible
improvements in surface-ﬁnish techniques. A simple example of this technique
is given in this chapter and treated in more depth later. In later chapters it will
be seen that in some cases, discrete surface features can be identiﬁed as pits or
particles from their scatter patterns, and estimates can be made of their diameters
from scatter measurements.
Scatter from windows, caused by both bulk and surface imperfections, is also
introduced here and examined in more detail later. Although the mechanisms of
bulk and particulate scatter do not lend themselves to the quantitative analysis
used for surface scatter, they are still strong indicators of component quality, and
measurement of the resulting scatter patterns is a viable source of metrology.
Scatter measurement is proving to be a useful inspection technique for many
applications outside the optics industry. It is proving to be particularly useful in
the semiconductor industry in applications varying from the study of polishing
to inspection during device manufacturing. Similar applications are found in the
computer disk and ﬂat panel display industries. Measured scatter can be used to
monitor changes in surface appearance in a variety of products. It can be used
to detect and map component defects in a variety of materials, including painted
surfaces, paper, metallic coatings, and medical implants such as artiﬁcial joints
and intraocular lenses. Bulk and surface scatter can be separated through the use
of special measurement techniques, so it is possible to determine whether or not
surface polishing or a better material is required to reduce component scatter.
1

2
Chapter 1
This chapter introduces various sources of scatter and the analysis approaches
that are described in later chapters. Chapter 7 introduces the measurement
techniques needed to obtain the data used throughout the book.
1.1 The Scattering of Light
Most of the light we see is scattered light. We live in a world of objects that,
with a few specular exceptions, scatter the visible spectrum diffusely. If those
specular exceptions were the norm, it would be a confusing existence at best. Some
examples of scatter are more impressive than others. For instance, rainbows, alpine
glow, sunsets, and blue sky are more awesome than the ability to discern print on
this page. These examples illustrate that in a certain sense we are all experienced
in the observation and analysis of scattered light.
The interaction of light [electromagnetic (EM) radiation] with matter can be
viewed through the classical mechanism of polarization. The charged particles
(electrons and protons) associated with the atoms and molecules composing a
gas, liquid, or solid are stretched to form dipoles under the inﬂuence of an EM
ﬁeld. Since each atomic charge interacts with every other charge (to at least some
degree), the number of dipole combinations is enormous. When dipoles are created
and/or stretched by the electric ﬁeld, energy is absorbed from the exciting ﬁeld. The
absorbed energy takes the form of a secondary ﬁeld because accelerated charges
produce EM radiation. These secondary ﬁelds do not necessarily propagate in
the same direction or with the same phase as the initiating ﬁeld. In some cases,
part of the energy is lost to heat, causing the effect of absorption. Although in a
low-pressure gas the interaction of a single molecule is nearly independent of its
neighbors, the situation is vastly more complicated for liquids and solids. These
interactions are not independent, as the induced dipole ﬁelds associated with each
molecule and group of molecules affect neighboring dipoles. For objects that are
large compared to a wavelength, the result is further complicated by the fact that the
amplitude and phase of the exciting ﬁeld change as a function of material position.
This complex situation deﬁes a complete analytical description.
Rayleigh ﬁrst studied scatter (1871) by considering the simple case of well-
separated particles much smaller than a wavelength. His work included the
determination that the scattered intensity from isolated particles, which are small
compared to a wavelength, is proportional to one over the wavelength to the
fourth power. This relationship was used to explain the blue color of the sky
and red sunsets. Subsequent work eventually led to an explanation of atmospheric
polarization effects as well. Mie theory (1908), after Gustav Mie, is the term often
used for the mathematical solution for scatter from a sphere of both arbitrary radius
and index of refraction. For particles much larger than a wavelength, shape is also
a factor in the resulting scatter pattern, so Mie calculations do not provide an exact
solution for many practical situations.
Because of the complexity of the situation, it is common to characterize larger
scattering bodies by various macroscopic quantities. Reﬂectivity, transmissivity,
and index of refraction are material properties that are actually the result of

Quantifying Light Scatter
3
averaging millions of loosely coupled scatter events. As such, the so-called laws of
reﬂection and refraction are merely statistical results that are true only in an average
sense and depend heavily on material homogeneity. A reﬂected (or transmitted)
beam of light is the summation of a huge number of scatter components that are
similar in direction, phase, and frequency. In this sense, scatter (or diffraction) out
of the specular beam can be viewed as the result of ﬂuctuations in an otherwise
homogeneous material. If the ﬂuctuations are periodic, then so is the scatter (as
in the example of the next section), while random ﬂuctuations produce a random
scatter pattern. It is exactly this property that makes scatter measurement such a
valuable tool for characterizing component quality and locating defects. This book,
which contains more engineering than physics, is intended to explore and review
the various measurement and analysis techniques available, rather than to explain
the basic interactions of light and matter. Even so, it is well worth remembering
the fragile microscopic mechanisms that paint our macroscopic view of the world.
1.2 Scatter from a Smooth Sinusoidal Surface
This section examines the special case of scatter (diffraction) from a smooth,
clean, reﬂective sinusoidal surface. The objective is to deﬁne terms and illustrate
a few concepts that will be useful throughout the remainder of the book. The
term smooth implies that surface height variations are small when compared to
the wavelength of light. This assumption is almost always true for optics and has
the added attraction that the required math is much easier. If you can see your face
in the sample, it is optically smooth at visible wavelengths. The adjectives clean
and reﬂective imply that the sample scatter is dominated by diffraction from surface
topography and not surface contamination or bulk (subsurface) defects. As will be
seen, these two assumptions are not always true and are more difﬁcult to check.
In Chapter 2, surface statistics for arbitrary smooth, clean, reﬂective optics will
be found by considering the sample topography to be composed of a summation
of sinusoidal surfaces (through Fourier analysis), so the following example of
diffraction from a sinusoidal grating provides a great deal of insight into the
later discussion in Chapter 4 of converting scattered light into surface-roughness
characterization. Figure 1.1 gives the geometry of the situation. The sample face
(the x, y plane) is oriented perpendicular to the page with the light incident in the
x, z plane at angle θi. This orientation causes the x, z plane to be the plane of
incidence deﬁned by the incident beam (Pi) and the surface normal. The specular
reﬂection (P0) also lies in the incident plane. The sinusoidal grooves on the surface
are rotated parallel to the y axis, causing all of the diffracted orders to also lie in
the plane of incidence (denoted by Pn where n = ±1, ±2, etc.). The positions of the
diffracted orders are given by the well-known grating equation:
sin θn = sin θi + n fgλ.
(1.1)
The quantity λ is the wavelength of the incident light, and fg is the grating
frequency, which has units of inverse length and consequently is often referred

4
Chapter 1
Figure 1.1
Diffraction from a sinusoidal grating.
to as a spatial frequency. The value Λg = 1/fg is the distance between peaks on the
grating. In this orientation, the grating surface is described by
z(x, y) = a sin(2π fgx + α),
(1.2)
where a is the grating amplitude, and α is an arbitrary phase that describes the
location of the grating relative to x = 0. Notice that the location of the diffracted
orders [Eq. (1.1)] is dependent on the grating line spacing and the light wavelength
but not on grating line depth, phase, or light power.
The powers Pn depend on grating amplitude and are found through the use of
diffraction theory. Exact solutions are available for simple situations; however,
more-complicated surfaces often require the use of approximations and, as a
result, several different expressions are sometimes available in the literature
to describe the same situation. Solutions may be divided into the classes of
scalar and vector calculations that respectively ignore and include effects of light
polarization. Most scalar diffraction derivations result in diffracted orders Pn that
are proportional to a summation of squared Bessel functions (Beckmann and
Spizzichino 1963; Goodman 1968). For normal-incidence and low-angle scatter,
most of these relationships reduce to the proportionality shown in Eq. (1.3), where
the Jn are Bessel functions of the ﬁrst kind, and for smooth surfaces the argument
(4πa cos θi/λ) is much less than 1. Conservation of energy is easily shown for the
normal, small-scatter-angle case of Eq. (1.3) because the sum of the squared Bessel
functions over n from minus to plus inﬁnity is unity. Conservation of energy is not
as easy to demonstrate when high-angle scatter is included.
Pn ≈
"
Jn
 4πa cos θi
λ
!#2

 2πa
λ
cos θi
!2
.
(1.3)
A more accurate vector perturbation result, developed in the radar literature
(Rice 1951; Barrick 1970) and based on earlier diffraction calculations (Rayleigh

Quantifying Light Scatter
5
1907), was introduced to the optical scattering literature by Church and Zavada
(1975), Church et al. (1977, 79). Church’s papers go far beyond examining
diffraction from sinusoidal gratings and actually form the basis for our current
understanding of the relationship between wavelength, angle of incidence, scatter
distribution, and the surface roughness of smooth, clean, reﬂective optics. This
relationship is commonly referred to as the Rayleigh–Rice vector perturbation
theory or the vector theory, and more recently as the Golden Rule. The theory
consists of an equation for each of the two orthogonal polarizations. In the optics
literature, s (perpendicular or occasionally TE) polarization is deﬁned as the
electric ﬁeld vector perpendicular to the plane of propagation, and p (parallel
or occasionally TM) polarization is deﬁned as the electric vector in the plane
of propagation. The plane of propagation is formed by the direction of scatter
propagation and the sample normal. Care is required here, as the reverse deﬁnition
is common in the radar literature.
Under the assumption of a perfectly conducting surface, which implies that
the reﬂectance is unity, the equations for ﬁrst-order diffraction from a sinusoidal
surface are
P±1/Pi =
 2πa
λ
!2
cos θi cos θ±1
(1.4)
for s-polarized light, and
P±1/Pi =
 2πa
λ
!2 (1 −sin θi sin θ±1)2
cos θi cos θs
(1.5)
for p-polarized light.
These two equations become identical as the limit θi = θ±1 = 0 is approached.
For diffraction close to specular, these perturbation results are virtually identical
to the scalar equations derived by Beckmann, Goodman, and others. All of these
relationships rely on the grating equation (which is exact) to predict the position of
each order.
Equation (1.4), for s-polarization, will be used to demonstrate the importance of
these simple results. Notice that if θi, θ1, P0, and P1 are measured, the quantities a
and fg can be easily calculated as
fg = sin θ1 −sin θi
λ
(1.6)
and
a = λ
2π
 
P±1
Pi cos θ±1 cos θi
! 1
2
.
(1.7)

6
Chapter 1
In other words, measuring the diffracted light on either side of the specular
reﬂection very nearly allows calculation of the surface proﬁle. Notice that the exact
proﬁle is not available, as the phase α has not been found. If the absolute phase
angle between the electric ﬁelds associated with P1 and P0 were measured, then α
could also be calculated. Grating interferometers (Huntley 1980) make use of this
effect to measure transverse motion; however, for the general case of an arbitrary
surface (composed of many sinusoidal gratings), measurement of all of the α’s is
impractical.
The root-mean-square (rms) roughness σ of a sinusoidal surface is a/
√
2, and the
average surface wavelength is obviously Λg. The rms surface slope m can be shown
to be 2πσ/Λg. The implication is that surface statistics can be evaluated even if the
phase information is not known. It will be shown in Chapter 4 how these parameters
can be found for more complicated surfaces by evaluating the surface power
spectral density (PSD) function. It is useful to introduce this function for the case of
the sinusoidal grating. The PSD may be thought of as surface-roughness power per
unit spatial frequency. For the case at hand, all of the roughness is at the frequency
fg (and −fg), so the PSD is a pair of impulse functions as shown in Fig. 1.2(a).
Readers with a background in electrical engineering or communications will see
the immediate parallel to displaying power spectra of temporal waveforms.
Figure 1.2
PSD functions.

Quantifying Light Scatter
7
The rms roughness is the square root of the zero moment (or integral) of the
PSD, and the rms slope is given by the square root of the second moment of
the PSD. Because the PSD is symmetrical around f = 0, it is often plotted only
for f > 0, which can be confusing when the integrals are taken. This difﬁculty
comes about because sometimes the one-sided PSDs are multiplied by 2, and
sometimes they are not. One has to exercise caution when comparing results within
the literature. Differences are pointed out in this text. If an asymmetrical PSD is
computed from scatter data, it is an indication that the reﬂector is not a smooth,
clean, front-surface reﬂector. Thus, the PSD asymmetry constitutes a check for
these requirements. In other words, computed asymmetrical PSDs are by deﬁnition
incorrect.
Figure 1.2(b) shows the case where three sinusoids have been summed to form
a surface. This surface has a spatial bandwidth of frequencies from fg1 to fg3,
and no information has been given about the relative phase of the sinusoidal
components, so this PSD actually represents an inﬁnite number of possible surface
topographies that all have the same surface statistics. The observable spatial
frequency bandwidth may be caused by the sample and/or by limitations of the
light-measurement instrumentation (scatterometer). As will be seen, knowing the
bandwidth limits can be critical to making valid comparisons of data taken on
different instruments. Examination of the grating equation reveals that as the spatial
frequency increases, the diffraction angle from the specular reﬂection (zero order)
also increases. Eventually, a maximum spatial frequency is reached that diffracts
along the surface of the grating (θs = 90 deg). Spatial frequencies higher than this
maximum value diffract into the surface and contribute to absorption by the sample.
A minimum observable spatial frequency is deﬁned by the ability to measure close
to the specular beam. This can be enhanced by using a converging beam that comes
to a focus on the detector observation path. If a minimum angle from specular is
determined from practical measurement considerations, then the grating equation
can be used to calculate the minimum observable spatial frequency, which is a
function of both the wavelength and the angle of incidence.
Another observation that can be drawn from this simple example involves the
minimum required light-spot size on the sample. In order to have diffraction from
a grating, the spot diameter must be larger than a spatial wavelength (1/f). A
rule of thumb is that at least three to ﬁve spatial wavelengths must be present
in the spot to have well-deﬁned diffraction. Thus, the spot size also places a
limit on the minimum observable frequency that can be measured. Near-specular
scatter measurement is an important issue for many optical imaging systems.
The sinusoidal grating example can also be used to illustrate some practical
measurement considerations. The tacit assumption has been made that when
any of the diffracted powers are measured, the detector aperture is centered on
the diffracted beam and is large enough to capture all of the power. Consider
a measurement made by rotating the detector in the plane of incidence about
the illuminated grating, as shown in Fig. 1.1. As the aperture approaches each
diffracted spot center, the measured power increases to a maximum, holds steady,
and then declines again to zero as the aperture leaves the spot. The measured

8
Chapter 1
width and shape of the diffracted beam is determined by aperture shape and width
as well as by the beam shape and width. Mathematically, the measured result is
known as the convolution of the beam and the aperture. Wide apertures and spots
limit the degree to which closely spaced beams can be separated (or resolved) by
the measurement. The situation is often improved by focusing the incident beam
onto the detector path (thus reducing the spot size) and by using small detector
apertures. Techniques allowing measurement to within the 0.01- to 0.1-deg region
from specular for many samples are discussed in Chapter 7.
Consideration of the single-frequency grating example makes it clear that once
the values of a and f are known, it is possible to calculate (or predict) the scatter
pattern that would result from other angles of incidence or wavelengths. These
predictions can easily be made for various surfaces by using the grating equation
to ﬁnd scatter angles and the appropriate form of the vector perturbation theory
to determine scattered powers. Obviously these predictions depend on the smooth,
clean, reﬂective assumptions being true for the new angles and wavelengths as
well. The ability to scale results in wavelength can be an economically attractive
alternative to taking scatter data at several wavelengths. Conversely, if a surface
scales in wavelength as predicted by our surface diffraction model, then it is a
good indication that the smooth, clean, reﬂective condition has been met. Chapter 4
discusses this topic in more detail and gives the results of wavelength-scaling
experiments performed to check predictions based on topographic scatter.
The case of diffraction from a sinusoidal grating illustrates many of the
basic issues associated with scatter measurement and interpretation. It is often
useful to return to this simple example in order to understand more-complicated
measurement situations.
1.3 Scatter from Other Surfaces
One of the major situations analyzed in this book is the special case where a
one-to-one relationship exists between reﬂector surface statistics and the resulting
light-scatter pattern. In fact, Chapters 3 and 4 and parts of Chapters 5 and 8
are almost solely devoted to developing and exploiting the relationship between
surface topography and reﬂective scatter. The mathematical expression of this
relationship, which is founded on the Rayleigh–Rice vector perturbation theory,
can be used to compute surface statistics from measured scatter patterns and is
a sensitive noncontact metrology technique. However, a qualitative appreciation
of the relationship between scatter and reﬂector topography allows insight into
how a given surface (or manufacturing technique) can affect scatter, or conversely,
what an observed scatter pattern implies about reﬂector topography. An insightful
overview of this relationship can be achieved without the mathematics of the later
chapters, and that is the goal of the arm-waving arguments presented in this section.
The concepts are illustrated in Fig. 1.3. The geometry, shown at the top of the
ﬁgure, consists of an illuminated reﬂective sample located in the x, y plane and
scattering onto the x0, y0 observation plane. Figure 1.3(a) through 1.3(f) illustrate
scatter patterns observed in x0, y0 for various reﬂector topologies. The perfectly

Quantifying Light Scatter
9
smooth surface of Fig. 1.3(a) scatters no light, and only the specular reﬂection is
observed in x0, y0. The sinusoidal grating in Fig. 1.3(b) produces the scatter pattern
predicted in the last section. The spacing of the diffracted orders can be calculated
from the grating equation. The cusp-shaped surface of Fig. 1.3(c) diffracts several
orders onto the observation screen. If the sinusoidal gratings (or surfaces) that
correspond to the pairs of diffraction spots are added together (with the correct
phase), the resulting shape will be the cusp-shaped surface. In Chapter 3, it
will be shown that the diffracted electric-ﬁeld amplitudes from these sinusoidal
component gratings fall off as their inverse order number squared (1/n2). Because
the diffracted light from sinusoidal gratings falls off as the amplitude squared, the
diffracted intensities of Fig. 1.3(c) will drop off as 1/n4. In Fig. 1.3(d), a grating-
like surface of arbitrary cross section diffracts a band of light onto the x0 axis. Many
spatial frequencies are present in this surface, and each one of them produces a pair
of diffraction spots. Because the band of scattered light is essentially continuous,
we can infer that essentially all spatial frequencies (in the available bandwidth) are
present in the surface.
The surfaces of Figs. 1.3(b), 1.3(c), and 1.3(d) all scatter light onto just the
x0 axis of the observation plane. This is because the grating lines are oriented
parallel to the y axis in the reﬂector plane. If the sample is rotated about its surface
normal, the scatter pattern will rotate with it according to a two-dimensional
version of the grating equation presented in Section 3.1. Surfaces that scatter
onto straight lines on the observation sphere in this manner are referred to as
one-dimensional surfaces in the scatter literature. This deﬁnition does not refer to
spatial dimensions (the sample has three spatial dimensions), but to the number of
spatial frequency propagation directions required to represent the surface through
Fourier composition (Church, Jenkinson, and Zavada 1979).
In Fig. 1.3(e) a two-dimensional isotropic surface diffracts light over the entire
observation plane. The scattering surface is considered two-dimensional because
spatial frequencies propagating in at least two directions are required to represent
the surface topography and the resulting scatter pattern. The frequency of a
sinusoidal component oriented in an arbitrary direction can be expressed as a
quadrature sum of fx and fy components, i.e., f 2 = (f 2
x + f 2
y )1/2. The term isotropic
refers to the fact that if the surface proﬁle is measured in any direction, the
same surface statistics (e.g., rms roughness) would be found. Correspondingly,
for near-normal incidence, the scatter pattern is observed to decrease from the
specular peak with near-circular symmetry. Polished surfaces often exhibit near-
isotropic properties. By deﬁnition, one-dimensional surfaces cannot be isotropic.
The two-dimensional surface of Fig. 1.3(f) is formed by the superposition of the
previous three examples, and the resulting scatter pattern is also the superposition
of the previous three. This surface is similar in nature to a precision-machined
(or diamond-turned) mirror. The cusp shape represents residual tool marks, the
arbitrary one-dimensional roughness is caused by machine chatter and chip drag,
and the background isotropic roughness is caused by random events (grain
boundaries, surface scratches and digs, etc.) that are unrelated to the periodic
nature of the manufacturing process. Obviously, a great deal of information about

10
Chapter 1
Figure 1.3
Scatter patterns from various surfaces.

Quantifying Light Scatter
11
the microscopic surface is readily available in the scatter pattern. For example,
tool feed rate may be checked by analyzing the scatter pattern with the grating
equation. The diffraction peaks often decrease more slowly than the expected
1/n4 falloff, a fact that will be shown to indicate the presence of additional high-
frequency roughness. This often takes the form of a burr on each tool mark left
by the machining process. Tool wear, chip drag, and material properties all affect
the scatter pattern and can be checked before the part is even removed from the
machine.
1.4 Scatter from Windows and Particulates
Scatter from transmissive optics has four sources: surface topography, surface
contamination, bulk index ﬂuctuations, and bulk particulates. These sources and
their general scatter characteristics are introduced individually.
Surface topography. Surface topography, in both transmission and reﬂection,
introduces phase deviations to the wavefront that can be analyzed by diffraction
theory; however, transmissive scatter, which will contain contributions from two
surfaces—the bulk material and often a multiple-reﬂection component—is much
harder to analyze than scatter from a front-surface reﬂector. The vector perturbation
theory, which has already been mentioned, can be used to deﬁne polarization
characteristics for some situations. Chapters 2–5 concentrate on developing these
relationships.
Surface contamination. Scatter from surface contamination is less easily
characterized. Particulates that are not small (compared to a wavelength) produce
scatter patterns whose intensity and polarization depend on particulate size, shape,
orientation, and material constants. Analysis of scatter from complex shapes
is difﬁcult (Young 1976a, 1976b). Even correctly determining the size/density
distribution of particulates on a contaminated surface is difﬁcult. Particulates
play a signiﬁcant role in producing scatter if the samples are allowed to
become contaminated. Cleaning samples and working under clean conditions
can be expected to reduce surface particulate scatter to low levels in laboratory
conditions; however, scatter from optics in less-controlled environments is often
dominated by particulates. This is often true for space optics and necessitates
sophisticated (expensive) cleaning methods. Chapter 6 is dedicated to modeling
scatter from discrete surface features. Chapter 9 discusses the detection of discrete
defects on optics. The semiconductor industry is concerned with the presence of
subwavelength-sized surface features on very smooth surfaces; these issues are
addressed in Section 11.1.
Bulk index ﬂuctuations. Index ﬂuctuations may be inherent ﬂaws in sample
material (Church 1980) or near-surface damage layers introduced by the ﬁnishing
process (Brown 1989). Because these ﬂuctuations introduce a phase change to
the transmitted beam, they may be treated in much the same manner as surface

12
Chapter 1
Figure 1.4
Diagram of an acousto-optic RF spectrometer.
ﬂuctuations introducing a phase change to the reﬂected beam. As a diffraction
effect, scatter from these ﬂaws has a dependence on spot size similar to that of
surface ﬂuctuations. As shown in Fig. 1.4, optoacoustic RF spectrometers make
use of the effect by inducing it in materials via modulated acoustic waves. When
a laser beam is propagated perpendicular to the induced index ﬂuctuations, part of
the beam is diffracted to angles determined by the acoustic frequencies. The result
is a diffraction pattern that is a measure of frequency content in the acoustic signal.
The resolution of these is, in turn, limited by the scatter-producing bulk ﬂaws of
the acoustic material.
Bulk particulates. Bulk particulate ﬂaws may be due to small bubbles, inclusions,
or contamination. Scatter from these sources is similar in nature to that from
surface particulates except that it cannot be eliminated by cleaning. The scattered
intensity and polarization are not easily related to defect characteristics, and there
is no minimum scatter angle associated with the illuminated spot size, as is found
with surface scatter. Scatter-based instrumentation can be built to detect bulk ﬂaws.
An example of this is found in Section 11.3, where age-induced submicroscopic
defects are found in intraocular lenses.
Bulk scatter caused by isolated particulates that are small compared to the
wavelength of light is called Rayleigh scatter. In this case, the particulates may be
contaminants or individual molecules. Rayleigh scatter from air molecules, which
is proportional to the fourth power of the inverse wavelength, is an explanation
for blue sky and red sunsets. Another explanation is scatter from small, thermally
induced index ﬂuctuations, which behaves in essentially the same manner. On
a per-molecule basis, gases actually scatter more than either liquids or solids
because of the independent nature of gas molecules. More molecular scatter
is normally observed from liquids and solids because there are usually more

Quantifying Light Scatter
13
Figure 1.5
Normalized scatter intensity in the plane of the ﬁgure, from a small spherical
particle. The scatter pattern changes dramatically with polarization of the incident beam
because the particle cannot radiate in the direction in which it is polarized.
molecules scattering. True Rayleigh scatter from isolated small particles tends to
be uniform in angle but is polarization dependent, as shown in Fig. 1.5.
The dependence of scatter from small particles on inverse wavelength to the
fourth power was deduced by Rayleigh on the basis of dimensional analysis alone.
This so-called blue-sky factor is also seen to appear in the relationship for scatter
from surface roughness. Rayleigh’s equation for small-particle scatter, which is
available from many sources (e.g., Bohren and Huffman 1982, 132) is given below
for an unpolarized source of intensity Ii (watts per meter squared). The source is
incident on a particle of radius r and index n in a medium of unity index and is
located a distance R from the position where the scattered intensity Is is measured:
Is/Ii = 8π4a6
λ4R2

n2 −1
n2 + 2

2
(1 + cos2 θ).
(1.8)
The 1 in the ﬁnal parentheses is the term for incident light polarized perpendicular
to the plane in which scatter is measured, cos2 θ is the term for light polarized in the
measurement plane, and θ is the angle between the incident beam and the direction
of scatter. The two terms in parentheses make up the classic donut-shaped dipole
scatter shape, where the donut hole is caused by the inability of light to propagate
in the direction of the electric ﬁeld vector in the polarized particle.
Molecular scatter from liquids and solids is dominated by forward scatter
and is not uniform; however, the polarization effects illustrated in Fig. 1.5 can
be exploited in the instrumentation used to map bulk defects, as explained in
Chapter 9. It is impossible to eliminate molecular scatter from transmissive optics.
The scatter patterns discussed in this section and the previous one are measured
by sweeping a detector through the scatter ﬁeld. This is usually accomplished with
computer-aided instrumentation to ease the measurement process as well as data
analysis and storage. A discussion of scatterometer instrumentation is found in

14
Chapter 1
Chapter 7. The next section is devoted to explaining the format commonly used to
present scatter data.
1.5 Bidirectional Scatter Distribution Functions
As seen in the preceding two sections, scatter from optical components can ﬁll
the entire sphere centered about the sample. The distribution of light within the
sphere is a function of incident angle, wavelength, polarization total beam power,
and in some cases, beam intensity (power per unit cross section), as well as
sample parameters (orientation, transmittance, reﬂectance, absorptance, surface
ﬁnish, index of refraction, bulk homogeneity, contamination, discrete defect size,
etc.). The bidirectional scatter distribution function (BSDF) is commonly used to
quantify scattered light patterns from uniformly distributed scatter sources (such
as roughness). (Quantifying scatter from discrete scatter sources, such as pits and
particles that do not ﬁll the incident beam, will be discussed in Section 1.7.) The
terms BRDF, BTDF, and BVDF, used for reﬂective, transmissive, and volume
samples, respectively, are merely subsets of the more-generic BSDF. Although
the mathematical expressions for these quantities are quite simple, they are
often misunderstood. Because the BSDF is the most common form of scatter
characterization, and because it can be used to generate scatter speciﬁcations
that enable designers, manufacturers, and users of optics to communicate and
check requirements, it is well worth the minimal effort required to understand the
mathematical deﬁnition and become familiar with its variations and limitations.
The derivation and notation for BRDF is credited to F. E. Nicodemus et al.
(1977), who expended considerable effort examining the problem of measuring
(and deﬁning) the reﬂectance of optics that are neither completely diffuse nor
completely specular (i.e., virtually all optics). The deﬁning geometry is shown in
Fig. 1.6, where the subscripts i and s are used to denote incident and scattered
quantities, respectively.∗The notation is consistent with Fig. 1.1 (where θ+/−1 is
just the discrete value of θs) and will be used throughout the book. Thus, the
direction of the specular beam is θs = θi and φs = 0. The retrodirection (for
light scattered back into the incident specular beam) is given by θs = θi and
φs = 180 deg.
Nicodemus started with a fairly complicated, general case of light reﬂected from
a surface and made several logical approximations to arrive at a simple manageable
form for the BRDF. Since the object here is an understanding of the use of the
expression and not its complete derivation, this review is restricted to the relatively
simple case of a nearly collimated beam of light reﬂecting from a sample. He
further simpliﬁed the situation by assuming that the beam has a uniform cross
section, that the illuminated reﬂector area A is isotropic, and that all scatter comes
from the surface and none from the bulk. The BRDF is then deﬁned in radiometric
terms as the surface radiance divided by the incident surface irradiance. The surface
irradiance is the light ﬂux (watts) incident on the surface per unit illuminated
∗Nicodemus used θr instead of θs, and that is still found in many papers; however, s is a more logical common subscript for
both reﬂection and transmission and has now been adapted by many authors publishing in the scatter literature.

Quantifying Light Scatter
15
Figure 1.6
Geometry for the deﬁnition of BSDF showing both a reﬂective source (for
BRDF) and a transmissive source (for BTDF).
surface area (not beam cross-sectional area). The scattered surface radiance is the
light ﬂux scattered through solid angle Ωs per unit illuminated surface area per
unit projected solid angle. The projected solid angle is the solid angle times cos θs.
(Refer again to Fig. 1.6.) Thus, the BRDF becomes
BRDF ≡diﬀerential radiance
diﬀerential irradiance  dPs/dΩs
Pi cos θs

Ps/Ωs
Pi cos θs
.
(1.9)
This equation is appropriate for all angles of incidence and all angles of scatter.
Another way to look at the cos θs factor is as a correction to adjust the illuminated
area A to its apparent size when viewed from the scatter direction. Notice that
BRDF has units of inverse steradians and, depending on the relative sizes of Ps
and Ωs, can take on either very large or very small values. For example, (Ps/Pi) is
approximately 1 if the entire specular reﬂection is measured from a good mirror, so
the BRDF approaches a value of 1/Ωs and can exceed 106/sr for small solid angles.
Conversely, far from the specular beam, the power ratio is tiny, a larger collection
aperture is required for measurements, and the BRDF can approach noise-limiting
values from the surrounding air molecules (on the order of 10−9/sr). Thus, a huge
dynamic range (ﬁfteen orders of magnitude in this example) can be required for
scatter instrumentation.
The differential form of the BSDF is more correct, but because of the
convolution effects introduced in the last section, it is only approximated when
measurements are taken with a ﬁnite-diameter aperture. The approximation is very
good when the ﬂux density is reasonably constant over the measuring aperture but
can be very poor when using a large aperture to measure focused specular beams.
The BRDF value is bidirectional in that it depends on both the incident direction
(θi, 0) and the scatter direction (θs, φs) and, as intended by Nicodemus, may be
viewed as directional reﬂectance per unit solid angle (in steradians) of collected
scatter.

16
Chapter 1
The assumptions made in the Nicodemus derivation are not completely true in
real measurement situations. For example, an incident laser beam is likely to have
a Gaussian intensity cross section instead of one that is uniform. A truly isotropic
surface does not exist, and even good reﬂectors have some bulk scatter. And, for the
case of a transmitting sample, where two surfaces and the bulk are scattering, the
idea of illuminated surface area becomes a little fuzzy at best; however, this only
means that, as measured, the BRDF is no longer the scattered radiance divided by
the incident irradiance. It still makes perfect sense to specify and measure the last
term deﬁned in Eq. (1.9) to characterize components. The BSDF was deﬁned in
order to include other types of scatter, such as that from transmissive optics. Thus,
from a practical point of view, the BSDF can be deﬁned as exactly the last term in
Eq. (1.9) and not as the ratio of radiance and irradiance:
BSDF ≡
Ps/Ωs
Pi cos θs
.
(1.10)
For this reason, the cos θs term, which was dragged into the fray from the deﬁnition
of surface radiance, is often viewed as a piece of historical baggage that no
longer adds any mathematical (or physical) value to the expression. Regardless
of personal preference, the BRDF is deﬁned with the cosine in both the American
Society of Testing Materials (ASTM) and Semiconductor Equipment and Materials
International (SEMI) standards and is used this way in the published literature.
When the cosine factor is dropped from the deﬁnition, the result is often called
the cosine-corrected BSDF (which is the choice made in this text because of
its use in some scatterometer software) or, sometimes, the scatter function. It is
also often referred to as angle-resolved scatter (ARS). Care is required here as
some publications do not follow this convention and will refer to the expression
of Eq. (1.10) as both the BSDF and the cosine-corrected BSDF. The differential
BRDF does not need to go to zero at θs = 90 deg, but the cosine-corrected BRDF
(CCBRDF) does. In the measurement world, some part of a ﬁnite aperture remains
above the sample plane when centered at 90 deg, and the signal does not completely
go to zero.
With the cosine dropped, the light scattered from a particular optic into any
given solid angle, from any hypothetical source, can be found by multiplying
the appropriate value of the cosine-corrected BSDF by the incident power and
solid angle. Thus, a designer with a library of typical BSDF data can address
system scatter issues and assign meaningful BSDF speciﬁcations to components.
Components can then be accepted or rejected on the basis of appropriate BSDF
speciﬁcations and measurements, just as interferometer measurements are used to
conﬁrm speciﬁed surface contour. Scatter speciﬁcations are covered in Chapter 13.
BSDF measurements from a number of typical samples are found in Appendix C,
which may be used as a small-scatter database for system designers.
Although scatter research and measurement facilities have been developed
within the optical industry for the purpose of controlling scatter in optical systems,
there are many more scatter metrology applications in other industries. These

Quantifying Light Scatter
17
are applications where scatter measurements are used in quality inspection or
process control to check appearance and limit roughness, contamination, etc., as
opposed to the optical industry, where scatter is often a direct system problem.
One example is the semiconductor industry, which has built more scatterometers
(in the form of surface particle scanners) than have been produced for the optics
industry. As will be seen in later chapters, the BSDF is an excellent format for
developing speciﬁcations and communicating information in these other industries
even though scatter itself may not be the parameter of concern.
1.6 Total Integrated Scatter
The earliest scatterometers were not designed to measure BSDF or even light
scattered as a function of angle. Instead, these instruments gather (or integrate)
a large fraction of the light scatter into the reﬂective hemisphere and measure it
with a single detector. The measured scattered power is then normalized by the
total reﬂected power and the ratio deﬁned as the total integrated scatter (TIS). The
result is an instrument that provides repeatable results, fast sample throughput,
and (without looking too closely) a single number to characterize sample scatter.
TIS instrumentation introduced optical scatter as a recognized source of metrology
information, and these measurements are currently used as an important scatter
speciﬁcation. The ratio has been more recently deﬁned as haze in the solar power
industry and is being used to monitor the level of texture introduced onto surfaces
used in photovoltaic collectors (see Section 11.4). This section is devoted to a brief
description of TIS measurements and the relationship of TIS to the more general
scatter distribution case discussed in the previous two sections. The concepts of
spatial frequencies, diffraction, and the BSDF have been introduced ﬁrst because
they provide valuable insights into the operation of TIS instrumentation.
During World War II, there was considerable interest in understanding radar
scatter from rough surfaces because of the problem of background sea clutter
associated with the detection of naval targets. A paper published in 1954 by
H. Davies reported the relationship of Eq. (1.11) for the fractional scattered power
from a smooth, clean, conducting surface. For optically smooth surfaces, virtually
all of the reﬂected power is in the specular reﬂection, and the exponential term
approaches 1.0, the TIS becomes approximately Ps/P0, and the expression reduces
to the well-known approximation on the right:
TIS ≡
Ps
P0 + Ps
= 1 −exp
−
 4πσ cos θi
λ
!2 Ps
P0

 4πσ cos θi
λ
!2
.
(1.11)
In addition to the smooth-surface requirement (4πσ cos θi ≪λ), Davies assumed
that the surface height-distribution function was Gaussian (in order to simplify
the mathematics) and that most of the light was restricted to scatter angles close to
specular (θs  θi). Davies extended his results to very rough surfaces and compared
them to experimental data obtained at radar frequencies with encouraging results.
That the TIS relationship to rms roughness [Eq. (1.11)] is not restricted to only

18
Chapter 1
Gaussian surfaces is easy to show. Assume that the surface is a smooth, perfectly
reﬂecting sinusoidal grating as described by Eq. (1.4), which gives a TIS of 2P1/Pi.
Setting the cosines approximately equal to unity and solving for the rms gives an
answer of a/
√
2, which we know is the rms of a sinusoid, so the expression is
correct for at least this non-Gaussian surface. A more complete analysis of this
equation and related expressions used for the measurement of rough surfaces is
found in Section 4.6, where it is shown that the Gaussian assumption for the
proﬁle height distribution was convenient but not necessary. Later in Section 8.2.3,
Eq. (1.11) is investigated for use on optically rough surfaces.
In 1961, H. E. Bennett and J. O. Porteus of China Lake Naval Weapons Center
published a paper that deﬁned TIS, described the ﬁrst optical TIS instrument, and
made use of Davies’s smooth-surface scatter derivation. The general form of these
instruments is shown in Fig. 1.7. Light strikes the sample at near-normal incidence
and is reﬂected back to a detector used to measure P0. The scattered light is
gathered by a nearly complete hemispherical mirror (sometimes called a Coblentz
sphere) that is oriented so that its center is midway between the illuminated spot
on the sample and a small nearby detector. Scattered light is gathered over the
region from the mirror entrance/exit aperture out to the mirror waist and is focused
on the scatter detector by the Coblentz sphere. The mirror aperture is typically 2
to 6 deg in diameter, and the rim is about 70 to 85 deg from the sample normal.
A small computer or microprocessor is often installed to calculate average TIS
values. These instruments have been built to accommodate transmissive samples
and various angles of incidence and operate at several laser wavelengths. The
ability to x, y raster-scan the sample and plot TIS as a function of sample position
has also been implemented at a number of labs. An alternative approach to this
Coblentz sphere design is found in Section 7.14. As implied by Eq. (1.11), Davies’s
approximate result can be used to convert the measured TIS to the rms roughness
of optically smooth surfaces.
It is worthwhile to evaluate TIS instrumentation in terms of the scatter picture
introduced by the sinusoidal-grating example. Davies’s assumptions of a smooth,
clean, conductive Gaussian surface are more restrictive than the smooth, clean,
Figure 1.7
The TIS scatterometer.

Quantifying Light Scatter
19
reﬂective requirements of Section 1.2. Since surface proﬁles can be decomposed
into an inﬁnite summation of sinusoids, it is reasonable to use the results of
Section 1.2 to analyze TIS behavior. These results are somewhat incomplete for
TIS analysis in this form because Section 1.2 does not account for scatter out of
the plane of incidence, but several insightful observations can still be made. First,
notice that the hemispherical mirror entrance aperture and rim deﬁne minimum
and maximum scatter angles, respectively, and hence, also deﬁne minimum
and maximum spatial frequency values from which scatter (diffraction) can be
measured. So TIS is not truly a total integrated scatter measurement, but instead a
measure of scatter associated with only a large range of angles that [via Eq. (1.6)]
correspond to a spatial frequency bandwidth. Since it has been common practice to
give only the TIS value (or the corresponding rms roughness) and not the associated
collection angles (or bandwidth), this has complicated attempts to compare results
between various labs and instruments that often operate over different spatial
bandwidths. Close comparisons cannot be obtained if the same collection angles
(or correspondingly the same set of sinusoidal components) are not used. This is
especially true for the near-specular limit, where scattered light is usually quite
intense. TIS results are only meaningful when the limiting angles are known and
should always be reported this way. Unfortunately, the literature, as well as many
scatter speciﬁcations, abounds with single-number TIS scatter and rms roughness
characterizations that ignore angle and frequency limits. These issues are now
addressed in international standards, which are reviewed in Chapter 12.
Large differences often result when rms roughness calculations obtained by
TIS are compared to measurements on the same sample obtained by other types
of surface-inspection instrumentation (interferometers, proﬁlometers, etc.). One
apparent difﬁculty is assuring that the Gaussian surface statistics assumption has
been met, and in fact, this served as a convenient scapegoat for poor comparisons
for several years; however, it was later shown by Church, Jenkinson, and Zavada
(1977, 1979; see Section 4.6) that it is unnecessary to make the Gaussian
assumption in order to obtain Eq. (1.11). In fact, the assumption is disregarded for
bandwidth limits (or angular collection limits) that cause most of the comparison
problems.
All surface-measurement systems have spatial frequency bandwidth limits, and
these limits must be matched before valid comparisons of measured rms roughness
and integrated scatter can be made. The low-frequency (near-specular) limit of a
TIS device can be sharply deﬁned if the reﬂected beam is centered in a circular
entrance/exit aperture; however, the high-frequency limit is not well deﬁned. Two
effects work to discriminate against measurement of scatter from high-frequency
roughness by TIS instruments. First, Davies’s analysis assumed that θs  θi,
which is clearly not true at high-scatter angles. Examination of Eq. (1.4) shows
that high-frequency roughness (large θs) scatters less light than low-frequency
roughness of the same amplitude, and this effect is not accounted for in the TIS
expression for rms roughness. Second, because signal light reﬂected by the scatter
detector (and hence not detected) goes up with angle of incidence, the detector
itself discriminates against high-angle scatter. Fortunately, a majority of samples

20
Chapter 1
scatter most of their light close to specular, so the high-angle limitations often do
not pose a serious problem.
TIS analysis also suffers from the fact that Davies’s scalar result does not
include the polarization differences apparent between Eqs. (1.4) and (1.5). Another
problem with comparison measurements is that TIS, with the above reservations
considered, is a true measure of area (or two-dimensional) roughness. That is,
sinusoidal frequency components propagating in all x, y directions on the surface
scatter light to the detector. This is not true for many other measurement systems.
For example, interferometers and proﬁlometers are insensitive to roughness
components that propagate perpendicular to their sampling directions, and these
perpendicular components are not included in the rms roughness values found from
proﬁle measurements. Similar difﬁculties arise when TIS and incident-plane BRDF
measurements are compared (Stover and Hourmand 1984a). These issues will be
explored further in Chapters 3 and 4.
Finally, there is another literature problem with the TIS: unfortunately, when
some of the more popular stray-light programs were written, a mistake was made,
and the TIS was deﬁned as being normalized by the incident power instead of the
total reﬂected power. This ratio (which is just the diffuse reﬂectance) obviously
has no relationship to surface roughness. Using this deﬁnition, two surfaces with
identical proﬁles but different reﬂectances will have different TIS values. Be sure
to know how your TIS values are obtained, and get the angle limits before blindly
using them to ﬁnd rms values.
1.7 Differential Scattering Cross Section
BRDF has been deﬁned as a way to quantify measured scatter from uniform
surfaces. Consider why it works—and when it will not:
BRDF 
Ps/Ωs
Pi cos θs
.
(1.12)
Increasing the incident power also increases the scatter signal, and the ratio remains
constant. Changing the illuminated spot size but keeping the incident power
constant does not change the BRDF because neither Ps nor Pi will change. Based
on the discussions in the preceding sections, it seems likely that for the special case
of smooth, clean front-surface reﬂectors, the BRDF can be related to roughness
statistics, although this may require introducing reﬂectance (material properties),
as shown in the relationship for TIS [Eq. (1.11)]. Surface roughness and ﬁlms are
extended sources of scatter, and we can assume them to be “uniform” over the
entire illuminated spot on the surface. The situation for a discrete surface feature
is different.
If the scatter pattern is dominated by light from a small feature that occupies
only a small fraction of the illuminated spot on the sample, then increasing the
spot size (at constant incident power) will decrease the scatter signal because there
is less light incident on the dominant scattering feature. In this situation, the BRDF

Quantifying Light Scatter
21
is no longer a reasonable way to attempt to characterize the feature; however,
by normalizing the scatter signal by the incident intensity (Ii = Pi/A with units
of watts per unit area), we can deﬁne the differential scattering cross section (or
DSC) as
DSC  Ps/Ωs
Ii
.
(1.13)
The cosine term, which came from the radiometric deﬁnition of BRDF, is now
missing. Now, if the spot size changes, the DSC remains constant, and with an
appropriate scatter model, it can be related to the discrete surface feature. In
real measurement situations, there is likely to be a background-signal surface
roughness that must be treated as noise to obtain the feature related DSC. In
addition, calculating the DSC from the measured BRDF requires some knowledge
about power distribution within the spot. These practical issues will be discussed
in Section 7.7.
1.8 Summary
Optical scatter is a result of interaction, at a very basic level, between EM radiation
and matter. Except for a few special cases, analytical solutions do not exist that
completely describe the scatter pattern in terms of an input beam and the scattering
element. A reasonably accurate description for scatter from a sinusoidal grating can
be used to gain insight into the general principles that govern scatter distributions
generated by reﬂective surfaces. Grating frequency determines the angular position
of scatter components, while grating amplitude and frequency determine scattered
power. Considering reﬂectors of arbitrary surface topography to be composed of a
summation of sinusoidal gratings (a Fourier spectrum) will allow these results to
be applied to more practical situations involving clean, smooth reﬂectors. Scatter
from bulk imperfections and particulates is not as easily analyzed but can still be
usefully measured and speciﬁed.
Scatter patterns are conventionally presented in the form of the BSDF. A clear
understanding of this form of presentation, and the limitations imposed on it
by the measurement process, allows its use as a standard scatter speciﬁcation
by designers, vendors, and users of optical systems and components. TIS
measurements are a fast, repeatable form of scatter metrology that have found many
applications and initiated scatter measurement as a recognized form of inspection.
The sinusoidal grating example can be applied to understanding measurement
results and limitations of TIS instrumentation. The underlying principles developed
to reduce scatter in optical systems provide a useful background for extension of
these techniques into the areas of quality inspection and process control.
Chapter 1 has presented basic concepts and deﬁnitions, and an outline of
the conversion technique used to relate scatter to surface roughness parameters.
Chapters 2–4 deﬁne surface roughness and discuss its relationship to topographic
scatter via diffraction theory. A similar discussion is given in Chapter 6 for

22
Chapter 1
discrete surface features. Polarization of scattered light is discussed in Chapter 5.
A discussion of instrumentation and measurement issues is found in Chapter 7.
Chapter 8 deals with various analysis issues, for example, when can you use scatter
data taken in the visible to predict IR scatter? Further, how can optically rough
surfaces be analyzed? In Chapter 9, the discussion of scatter from transmissive
optics, subsurface defects, and contamination reveals that when the smooth,
clean, reﬂective restrictions are lifted, the analysis is far more complicated, and
in most cases, impractical. Changes in measured scatter levels used to detect
defects and changes in manufacturing processes (as opposed to calculated sample
parameters) become the primary result. Polarization effects, subsurface (or bulk)
scatter measurements, and differential-scattering cross sections are also discussed.
The measurement of appearance—how things look—is discussed in Chapter 10.
Additional industrial applications are found in Chapter 11. The semiconductor
and computer disk industries are examples where scatter metrology can be used
to compute surface statistics; however, there are many examples (paper gloss,
metal extrusions, rolling operations, etc.) where fast noncontact process control
can be achieved by monitoring changes in measured scatter. International standards
related to scatter and surface roughness are reviewed in Chapter 12. The generation
of scatter speciﬁcations (which is viewed as a bottom-line issue) is illustrated
through the use of practical examples in Chapter 13. Appendix A reviews the
basics of EM wave propagation. In Appendix B, Kirchhoff diffraction theory is
applied to a sinusoidal grating. Measurements of a number of samples are given in
Appendix C, and a discussion of units is given in Appendix D.

Chapter 2
Quantifying Surface
Roughness
“‘Smooth as a baby’s bottom’ just isn’t enough information.” – Unknown
The optics industry has concerned itself with the measurement and characterization
of roughness on (relatively) smooth surfaces (sometimes called microroughness)
for many years. In the 1990s, as smaller defects became important to newer
products, there was increasing concern in semiconductor-related industries (wafer
processing, ﬂat panel displays, computer disks, etc.) about the ability to measure
and communicate roughness values. Light scatter proved to be an ideal solution
for many of these measurement and process-control problems because it is fast,
noncontact, and performs well on very smooth surfaces; however, even in the optics
industry, there has been considerable confusion about which roughness parameters
should be calculated and how they should be reported. This chapter addresses the
issue of how roughness can be quantiﬁed.
Everyone knows what is meant by surface roughness, or topography, and it is
generally recognized that when even the smoothest surfaces are viewed in enough
detail, they will exhibit some form of texture. But describing surface topography
in measurable, quantitative terms is more difﬁcult. Even the simple surfaces of
Section 1.3 are not easily compared for relative roughness. Are any of these
surfaces inherently rougher than the others, or are they just different? How should
those differences be reported? This chapter reviews some of the common methods
of roughness measurement and presents deﬁnitions of common terms such as rms
roughness, PSD, autocorrelation length, etc., used to quantify surface topography.
It is left to the following chapters to develop the relationship of these statistical
parameters to the associated scatter patterns.
2.1 Proﬁle Characterization
A real three-dimensional surface, described by height z over an x, y plane requires
a huge amount of information to completely describe it. Given two such complete
descriptions, how does one decide which is rougher? What sort of measurable, and
easily reportable, quantities should be speciﬁed to characterize surface texture?
These problems were ﬁrst faced in the manufacture of machined parts. One of the
23

24
Chapter 2
early methods used a set of roughness standards that were compared to machined
parts by scraping the two surfaces with a thumbnail. This was followed with
stylus devices that operated something like a phonograph needle on a record.
As the stylus moved across the surface, its vertical motion was converted to an
electrical signal that was plotted to give an indication of surface proﬁles. In order
to interpret the resulting proﬁle information, the signal is processed (via computer)
to give a number of surface statistics, although early stylus instruments gave just
the average height deviation from the surface mean. Thus, the complex proﬁle
information is converted to one (or more) numbers that are easy to understand and
compare. This section gives the mathematical deﬁnitions of some of the various
statistical quantities that are used to quantify surface proﬁles. Additional roughness
parameters can be deﬁned, calculated from proﬁle data (Dagnall 1980; Thomas
1982), and even standardized (ANSI/ASME 2009), but are not of direct interest in
exploring the relationship between smooth surface topography and light scatter.
Surface proﬁles that can be completely described by mathematical expressions
(such as the sinusoidal surfaces of Chapter 1) are labeled deterministic in this text.
The advantage is that the various mathematical operations required to produce
statistics (such as integration) are more easily carried out. Side-by-side proﬁles
will be identical or related in a calculable manner. Unfortunately, at some small-
scale level all surfaces lose their deterministic nature. In a sense, roughness is often
the deviations from the ideal deterministic shape. Random surface structure, such
as the roughness found on a polished mirror, is not deterministic. At best, we can
hope to analyze large-enough proﬁle samples (lengths or areas) so that the same
statistics can be measured from adjacent proﬁles and compared. In some cases, it
may be necessary to average statistics found from several proﬁles in order to obtain
meaningful results.
In addition, surfaces can be thought of as either one-dimensional or two-
dimensional, as pointed out in Section 1.3 (see Fig. 1.3). Polished surfaces
are two-dimensional, while machined surfaces tend to be one-dimensional
with a two-dimensional background. Any of the four combinations between
deterministic, random, and one- and two-dimensional are possible, and more than
one combination may be present. An aluminum extrusion, for example, will have
a dominant one-dimensional random structure with a two-dimensional random
background.
In a like manner, measurements may be classiﬁed into four categories by
deﬁning linear and area proﬁles and continuous and discrete (sampled) proﬁles.
These four measurement combinations can be applied to any of the four possible
surface types. As will be shown, the apparent type of surface often depends on
another important measurement parameter—proﬁle length (or area).
2.1.1 Deterministic proﬁles
The more commonly used roughness parameters are most easily introduced in
terms of a one-dimensional surface (or proﬁle) z(x). The average, mean, or

Quantifying Surface Roughness
25
expected value of z(x) over distance L is denoted as ¯z and is deﬁned as follows:
z = lim
L→∞
1
L
Z L/2
−L/2
z(x) dx.
(2.1)
The surface z(x) = (¯z) would be considered perfectly smooth. Roughness is deﬁned
in terms of deviations from the mean value. The arithmetic average (a.a.) roughness
σa (or Ra) is given by
σa = lim
L→∞
1
L
Z L/2
−L/2
|z(x) −¯z| dx.
(2.2)
This deﬁnition of roughness became a standard within the machine tool industry
because it is obtained naturally from stylus measurements. Early stylus instruments
made use of the fact that the average vertical velocity of a probe tracing the surface
at constant horizontal velocity is very nearly the a.a. roughness. The averaging
was conveniently accomplished by using a probe whose vertical position was
proportional to the probe transducer voltage. The electrical signal was applied to a
dc meter to accomplish averaging. The result is nearly exact for sinusoidal surfaces
and poor for surfaces composed of long, ﬂat sections that are interrupted by
sudden jumps. This straightforward, repeatable method was developed to quantify
roughness. Dagnall (1980) points out that Ra is easier to obtain from a proﬁle than
rms by graphical techniques. More-sophisticated proﬁlometers now digitize the
measured proﬁle and use a computer to perform the required statistical analysis.
Stylus-generated proﬁles tend to discriminate against high-frequency roughness
because of the ﬁnite tip radius. The error is not easy to compensate for in
postprocessing (Wilson, Al-Jumaily, and McNeil 1987; Church and Takacs 1988;
Church et al. 1988).
Another surface height average is the rms roughness σ (or Rq in machining
terminology). Optical surface-roughness measurements have taken advantage of
the fact that the rms roughness can be obtained directly from scattered-light
measurements. This was initiated in the early 1960s, as mentioned in Section 1.6,
by exploiting the convenient relationship between σ and TIS. The rms roughness
is also deﬁned in terms of surface height deviations from the mean surface as
σ =
 
lim
L→∞
1
L
Z L/2
−L/2
[z(x) −¯z]2 dx
!1/2
.
(2.3)
Although it is not obvious from these two deﬁnitions, rms is actually a more
fundamental quantity than the a.a. This is true because it can be calculated directly
from the surface PSD function (not yet deﬁned), while the a.a. cannot.
The name root mean square is obtained from the mathematical operations used
in Eq. (2.3). This deﬁnition depends on the existence of the limit as L approaches
inﬁnity, which is satisﬁed for real surfaces [but not for all functions z(x)]. Notice

26
Chapter 2
that the deﬁnitions of both a.a. and rms roughness are independent of adding or
subtracting a constant (or dc) value to the surface function, z(x). On the other hand,
surface tilt and/or curvature results in changing the roughness as calculated by
Eqs. (2.2) and (2.3). Compensation can be made, but for the moment these issues
will be ignored. Tilt and curvature are also measurement issues.
The values of either average are obtained by direct substitution into the
equations. For example, if z(x) = a sin(2πf x), as in Section 1.2, then ¯z = 0, and
the two roughness averages may be evaluated as follows:
σa =
2f
M + ∆
Z
M+∆
2f
0
|a sin(2π f x)| dx  2a
π
 
1 + 1 −2∆−cos(π∆)
2M
+ · · ·
!
, (2.4)
σ =

2 f
M + ∆
Z
M+∆
2f
0
a2 sin2(2π f x) dx

1
2

a√
2
 
1 −sin(2π∆)
4Mπ
+ · · ·
!
.
(2.5)
In the above equations, the integration has been evaluated over an integer number
of half surface wavelengths M plus a fractional half wavelength ∆. The fraction
results in small deviations from the values expected for sinusoids. These deviations
approach zero as the limit of integration approaches inﬁnity. The approximation
sign results from ignoring terms in inverse M2 and larger. In practice, it is merely
necessary to assure that the integration limits are large enough that calculated
representative surface height averages are not dominated by integration over
fractional wavelengths. If M is only 2, then the maximum errors can be found
as about −5% in σa and +4% in σ from Eqs. (2.4) and (2.5). Larger values of M
result in even smaller errors.
For most physically realizable surfaces, the two representative surface heights σ
and σa are usually quite close, and they are identical for the physically unrealizable
square wave surface, as shown in Table 2.1.
Another surface of interest is the periodic cusp-shaped surface, shown in
Fig. 2.1, that is approached (but never realized) when a circular-tipped tool is
used to ﬁnish a surface. The ideal proﬁle is similar in cross section to the smooth
surfaces produced by precision machining (diamond turning). Because the surface
is periodic, it is again important to either limit the integral to an integer number
of periods, or extend the integration far enough so that a partial period does
not dominate the result. In principle, almost arbitrarily smooth surfaces can be
achieved if the tool radius R is kept much larger than the tool feed per revolution
d, and it was this reasoning that led to precision-machined optics. There are two
approaches to evaluating rms roughness. The obvious one is to use the relationship
for z(x) over 0 to +d/2, given in Fig. 2.1, and then evaluate z(x) and σ over the
integral limits 0 to d/2 using Eq. (2.3). After the required math, this results in
σ = 0.037d2/R.
(2.6)

Quantifying Surface Roughness
27
Figure 2.1
The ideal cusp-shaped surface produced by precision machining a surface
with tool radius R and feed rate d.
Table 2.1
Comparison of rms and a.a. roughness for various one-dimensional z(x) surface
proﬁles. All of the proﬁles are deﬁned with peak-to-valley height of 2a and zero mean.
Evaluation is done in the x direction over an integer number of wavelengths.
Waveform
σa
σ
Triangle
0.5a
a√
3
 0.58a
Sinusoid
2a
π  0.64a
a√
2
 0.71a
Square wave
a
a
Circular cusp
0.51a
0.60a
Random roughness
with a Gaussian
height distribution
r
2
π σ  0.80σ
σ
A less-obvious (but less-painful) approach to this calculation is to use a table of
Fourier transforms to express the cusp shape as a summation of sinusoids:
z(x) = a0
2 +
∞
X
n=1
an cos(2nπx/d),
(2.7)
where
a0 = d2/12R
and
an = (−1)nd2
2(nπ)2R.
The mean surface height ¯z is the dc term in the expansion a0/2, and, just as before,
conveniently drops out of the integral. The phase term of each component 0 or
180 deg [given by (−1)n] acts to alternate the signs of each term. The square on the
inﬁnite series looks messy, but all of the cross-product terms have zero averages,

28
Chapter 2
so they drop out as well. All that remains is the square root of the sum of the mean-
square values of the individual Fourier components, and these can be summed by
inspection to give
σ =

∞
X
n=1
a2
n
2

1/2
=

1
8π4
∞
X
n=1
1
n4

1/2 d2
R  0.0373d2
R .
(2.8)
The inﬁnite sum converges to π4/90 to obtain essentially the same result as
Eq. (2.6).
This method is interesting from several other aspects as well. Notice that if only
one term is evaluated, the expression for σ is the one obtained in Eq. (2.5) for a
single sinusoidal grating, and when several sinusoids are added together, the result
is similar to that shown in Fig. 1.2(b). Thus, the contributions from the individual
sinusoidal components of the cusp shape add in quadrature. That is, their squares
add linearly to form the mean-square roughness σ2. If a Fourier series was used
that had the same amplitudes but different phases, the same rms roughness would
be found, even though the components would no longer add to the cusp-shaped
surface, and the surface proﬁle would be different. This means that if the values
of the component amplitudes are obtained without measuring the corresponding
phases (perhaps by light-scatter measurements), the actual surface proﬁle could
not be obtained directly from the data, but the rms surface roughness could. For
machined surfaces, the phases can be guessed to alternate by 180 deg by examining
Eq. (2.7). This calculation has been done in the past (Stover 1976b), and the results
were used to show the presence of a burr on the expected cusp-shaped tool marks.
And ﬁnally, notice that the rms roughness does not depend at all on the component
frequencies but only on the component amplitudes an, which are determined by d
and R, as indicated in Eq. (2.7). The cusp proﬁle will be analyzed further from a
light-scatter viewpoint in Chapter 4.
The dependence of rms roughness on height alone is illustrated in Fig. 2.2.
Although the two surfaces can be shown to have the same roughness, via our
deﬁnitions (if appropriate sampling is used) they are likely to behave quite
differently in many situations. The one on the right looks smoother and would feel
smoother to the thumbnail test. Some sort of transverse quantity needs to be added
to the height deﬁnitions to improve roughness characterization. Surface slope m is
a logical choice and can be deﬁned in a manner analogous to the surface-height
deﬁnitions:
ma = lim
L→∞
1
L
Z L
0

dz
dx −¯z′
 dx
for arithmetic averaging,
(2.9)
m =
lim
L→∞
Z L
0
 dz
dx −¯z′
!2
dx

1
2
for the rms,
(2.10)

Quantifying Surface Roughness
29
Figure 2.2
Which surface is smoother? The surface in (b) looks smoother, but the surfaces
in (a) and (b) each have the same roughness values (rms or a.a.). Obviously, a transverse
parameter is also needed to help describe roughness.
Table 2.2
Comparison of sinusoidal surface parameters.
Parameter
rms
a.a.
Height
a√
2
2a
π
Slope
√
2π fa
4 fa
Wavelength
1/ f
1/ f
where
¯z′ = lim
L→∞
1
L
Z L
0
dz
dx dx.
The surface rms height and slope can be combined to form a transverse
surface length parameter or average surface wavelength ℓequal to the sinusoidal
wavelength:
ℓ= 2πσ/m.
(2.11)
Table 2.2 gives the values of height, slope, and average wavelength found from
these deﬁnitions for the sinusoidal grating z(x) = a sin(2πf x) evaluated over an
exact number of half wavelengths.
2.1.2 Random proﬁles
For random proﬁles, although the shape cannot be determined by formula, the
statistics can. The proﬁle z(x) is replaced by a height distribution function P(z).
The integral of P(z) from z1 to z2 is the probability that z will be between z1 and
z2. There are many distribution forms to choose from, but the most common is the
Gaussian, which is given in terms of σ, the rms roughness, as
P(z) =
1
σ
√
2π
e−z2/2σ2.
(2.12)

30
Chapter 2
The integral of P(z) over z from plus to minus inﬁnity is 1.0. The mean value of z
may be found by averaging the quantity z times the distribution function. Because
P(z) is even, the mean of a Gaussian height distribution is zero:
z =
Z ∞
−∞
zP(z) dz = 0.
(2.13)
In a similar fashion, the a.a. and rms roughness may be evaluated:
σa =
Z ∞
−∞
|z|P(z) dz,
(2.14)
σ =
"Z ∞
−∞
z2P(z) dz
#1/2
.
(2.15)
Of course, the distribution was written in terms of σ, so the second moment of P(z)
will be by deﬁnition σ2. Notice the similarity of the last three equations to those
deﬁning the same quantities for the deterministic surfaces. The statistics of random
surfaces having other height distributions may be found in a similar fashion. This is
important because real surfaces may have non-Gaussian distributions. For example,
it seems quite reasonable that a polished surface would have fewer high peaks than
deep valleys and thus have a nonsymmetrical distribution function. The issue of
a Gaussian or non-Gaussian height distribution function is also important because
early scattering work (unnecessarily) assumed a Gaussian distribution, and this
caused some confusion for several years. (See Sections 1.6 and 4.6.)
Another statistical property that can be evaluated is the surface power spectrum,
which is yet to be discussed. Its introduction will allow consideration of the
correlation length, which is the characteristic transverse parameter for random
surfaces. Before addressing these issues, sampled proﬁles need to be considered.
2.1.3 Sampled proﬁles
The deﬁnitions of both σ and σa assume that essentially an inﬁnite length L is
available for the calculations. Clearly, this is not the case. No matter how long
the sample of z(x) is, there will always be spatial frequencies with wavelengths so
long that they cannot contribute to the calculation. There will be some frequencies
that contribute only one and a fraction wavelengths, thus errors similar to those
discussed for Eqs. (2.4) and (2.5) are inherent. The trick is to get L large enough
that all of the frequencies of interest are well represented and, in any case,
recognize and record the limitations for each practical situation. This limitation
is analogous to the previously discussed light-scatter limitation imposed by spot
size (Section 1.2).
Less obvious is the limitation inherent at the high-spatial-frequency (short-
wavelength) end of the spectrum. The deﬁning Eqs. (2.2) and (2.3) and the
deterministic examples assume that z(x) is known at all points. In the real-
measurement world, z(x) is not known in equation form and instead is sampled

Quantifying Surface Roughness
31
at discrete points. The length of the sample string deﬁnes the longest measurable
spatial wavelength or largest value of L. The shortest measurable wavelength is
deﬁned by the Nyquist criteria to be twice the sample spacing (i.e., three zero
crossings, or two sample separations, are required to deﬁne a full cycle). When z(x)
is deﬁned as a string of N samples, given by zn = z(xn), instead of a continuous
function, the roughness values can only be estimated because of the errors
associated with the just-discussed bandwidth-limit problems. The expressions used
to provide numerical values in these situations are called estimators and are
indicated in this text by the presence of a “∧” above the estimated quantity. The
commonly used estimators for the a.a. and rms roughness are given below:
σa  ˆσa = 1
N
N−1
X
n=0
|zn −ˆ¯z|,
(2.16)
σ  ˆσ =

1
N
N−1
X
n=0
(zn −ˆ¯z)2

1/2
,
(2.17)
where
ˆ¯z = 1
N
N−1
X
n=0
zn,
and
n = 0, 1, 2, . . . N −1.
The slope may be found in a manner analogous to Eqs. (2.9) and (2.10) for the
case of N discrete data points as
ma  ˆma =
1
N −1
N−1
X
n=1

zn −zn−1
xn −xn−1
−ˆ¯z′
 ,
(2.18)
m  ˆm =

1
N −1
N−1
X
n=1
 zn −zn−1
xn −xn−1
−ˆ¯z′
!2
1/2
,
(2.19)
where
ˆ¯z′ =
1
N −1
N−1
X
n=1
 zn −zn−1
xn −xn−1
!
= Zn −Z0
d(N −1),
where n = 0, 1, 2, . . . N −1, and d is the common sampling distance. As in
Eq. (2.11), a transverse length parameter can be formed from the estimated values
of σ and m.
2.1.4 Two-dimensional (area) proﬁles
Although it is reasonable to express grating-like surfaces by one-dimensional
proﬁles and measure (or calculate) along those proﬁles as discussed above, many

32
Chapter 2
surfaces need a two-dimensional expression, z(x, y), to adequately describe them.
For these surfaces, measured roughness is often a function of measurement
direction. Along the y axis, both the height and slope averages are zero with
intermediate values obtained in other directions. Many components exhibit a
“surface lay” and have a strong one-dimensional roughness dependence on
direction. If the surface is isotropic, then the height and slope values will be
independent of measurement direction if other measurement parameters (scan
length, sample interval, etc.) are ﬁxed.
It is fairly common practice to generate area proﬁles of two-dimensional
surfaces by presenting several z(x) traces, offset by a small increment in y, into
an isometric display of the surface. The result is a reasonable picture of surface
topography, as shown in Fig. 2.3. The surface height averages can be computed
from this information in a manner similar to that presented earlier. The following
equations apply:
z = lim
Lx→∞
Ly→∞
1
LxLy
Z Lx
0
Z Ly
0
z(x, y) dy dx.
(2.20)
σa = lim
Lx→∞
Ly→∞
1
LxLy
Z Lx
0
Z Ly
0
|z(x, y) −¯z| dy dx.
(2.21)
σ =
lim
Lx→∞
Ly→∞
1
LxLy
Z Lx
0
Z Ly
0
[z(x, y) −¯z]2 dy dx

1/2
.
(2.22)
To simplify the notation for the discrete sample case, znm is used to represent
z(xn, ym), where n and m are subscripts used to denote NM sample positions over
the x and y directions, respectively:
¯z  ˆ¯z =
1
NM
N−1
X
n=0
M−1
X
m=0
znm.
(2.23)
σa  ˆσa =
1
NM
N−1
X
n=0
M−1
X
m=0
|znm −¯z|.
(2.24)
σ  ˆσ =

1
NM
N−1
X
n=0
M−1
X
m=0
(zni −¯z)2

1/2
.
(2.25)
The concept of surface slope implies a ﬁxed direction on the surface, so the
calculation of a slope on a two-dimensional surface requires some caution. If
a known direction is desired, Eqs. (2.11) and (2.12) can be used by simply
substituting polar coordinates (i.e., use r instead of x). If the surface is nonisotropic,
then the calculated slope can be different for different directions. The slopes of
two-dimensional surfaces are given in terms of the surface gradient. The gradient

Quantifying Surface Roughness
33
Figure 2.3
The superposition of consecutive z(x) scans to form a two-dimensional surface
proﬁle.
squared of an isotropic surface is equal to the sum of the mean-square slopes of
orthogonal slices (Church, Jenkinson, and Zavada 1979).
The dangers of assigning numerical values to surface-roughness parameters
without also revealing the corresponding spatial frequency bandwidths have been
alluded to in Chapter 1 and will be further discussed in Chapter 4; however,
it is reasonable to consider a few numbers to put the surfaces in question into
proper perspective. For optics and polished semiconductor wafers, the calculated
(or measured) values of rms surface roughness do not generally exceed an upper
limit of about 100 Å. A lower limit of about 1 Å, which is now realized in practice,
is imposed by atomic dimensions. The range of spatial wavelengths found on
these surfaces is much larger and varies from atomic spacings up to the surface
diameter. These limits are rather extreme. A surface wavelength as short as one
light wavelength (for example, 5000 Å) causes normally incident light to scatter
along the surface. Thus, shorter spatial wavelengths do not contribute to the scatter
pattern. Optical microscopes are limited by their collection angles, which do not
even begin to include scatter near the surface. Measurement of shorter spatial
wavelengths, which are not generally considered as optical roughness, requires an
electron microscope, scanning tunneling microscope, or atomic force microscope.
Longer-surface-roughness wavelengths are deﬁned rather arbitrarily into three
categories. The short wavelengths (up to about 1 mm) are referred to as ﬁnish or
microroughness. Wavelengths from about 1 mm to 20 mm have become known
as nanotopography because of their importance in the semiconductor industry.
Wavelengths longer than 20 mm are generally thought of as surface contour or
ﬁgure. When one hears the term roughness applied to optics or semiconductors,
it generally implies surface wavelengths ranging from the optical wavelength of
interest up to a few millimeters. Thus, optical proﬁle slopes are generally smaller
than 50/5000 = 10−2 and often smaller than 10−5. These are very ﬂat surfaces.
Placed on such a surface, you would have to walk a mile to gain (or lose) several
inches in altitude. If you have ever driven across western Kansas, you have the
general idea.

34
Chapter 2
The surface slopes and heights can be combined to ﬁnd average surface
wavelengths as in the one-dimensional case; however, in order to provide additional
information, the surface PSD and autocovariance functions can be deﬁned. The
surface PSD will prove to be of particular value to surface characterization by
light-scatter techniques because, as was hinted at in Chapter 1, it is easily related
to the scatter pattern from smooth, clean, front-surface reﬂectors.
2.2 The Surface Power Spectral Density and Autocovariance
Functions
The statistics of random processes have been studied in several different
disciplines. In engineering circles, the power spectrum has been used as a powerful
statistical tool for many years. For many situations it offers a very physical
view of the process under study. Correlation functions, which are used for
similar purposes, have seen considerably more use among mathematicians and
statisticians. Although in principle the same information is available from the
two functions (i.e., they are mathematically equivalent), the PSD can be more
accurately obtained from proﬁle data because it is much easier to correct for the
instrumental and sampling effects that unavoidably appear in real measurement
situations. It will be seen in later chapters that a similar situation is true for
surface statistics found from scatter measurements where the PSD is again the
better choice. Nevertheless, because the autocovariance function approach has been
used for several years, and because considerable insight can be gained by studying
both approaches, it is worthwhile to deﬁne this function and its relationship to the
power spectrum, and indicate the methods of obtaining each of these functions
from proﬁle data.
2.2.1 The power spectral density function from the proﬁle
The PSD may be found directly from surface-proﬁle data. This is accomplished
through the use of Fourier analysis and random signal theory, the details of which
are well beyond the scope of this book. Fortunately, these topics have been the
subject of considerable work in the ﬁelds of communication theory and signal
processing. The conversion from electrical signals of time to proﬁles in space is
straightforward. The following is intended as a review to allow the grasp of basic
essentials. An in-depth understanding can be accomplished through the study of
a small fraction of the available literature (e.g., Hancock 1961; Jenkins and Watts
1968; Bendat and Piersol 1971, 1986; McGillem and Cooper 1984).
To ﬁnd the PSD, z(x) is ﬁrst expressed in terms of its spatial frequency content
by taking its Fourier transform:
Z(fx) = F[z(x)] =
Z ∞
−∞
z(x)e−j2π fxx dx.
(2.26)
The integral in Eq. (2.26) replaces the variable x with the spatial frequency fx
propagating in the x direction. This happens in the following way. Consider z(x)

Quantifying Surface Roughness
35
to be the summation of a constant ¯z and a large (perhaps inﬁnite) number of
sinusoids of different frequencies, phases, and amplitudes. In the integral, these
components are multiplied by the exponential (or phasor). At any given frequency
fx, the resulting products are all periodic functions with zero mean except for two.
The periodic zero-mean terms integrate to zero over the inﬁnite length deﬁned
by the integration limits. The nonzero-mean terms are the ones formed from ¯z
and the component at frequency f. The Fourier transform of the constant ¯z is an
impulse function at f = 0 with area ¯z. The component at f times the phasor at
f has a sinusoid-squared appearance with a nonzero mean that depends on the
component amplitude. So the Fourier transform calculates a function giving the
amplitude frequency content of z(x). Because the phasor is a complex function,
both amplitude and phase information are available in the result. The transform
cannot be applied to any arbitrary function z(x); however, physically realizable
surface proﬁles meet the requirements for transformation. By performing the
inverse transform, the surface proﬁle may be recovered:
z(x) = F −1[Z( fx)] =
Z ∞
−∞
Z(fx)e j2π fxx d f.
(2.27)
Fourier transforms can also be calculated for functions that are known over
limited ranges. For example, in practical measurement cases, z(x) will be known
only over a ﬁnite distance L and can be considered zero elsewhere. Then,
Z(fx, L) =
Z L/2
−L/2
z(x)e−j2π fxx dx,
(2.28)
which, because of the limit imposed on long surface features, will drop to zero
above spatial wavelengths greater than about 2L. Conversely,
z(x) =
Z ∞
−∞
Z(fx, L)e j2π fxx d f.
(2.29)
In effect, the same information can be presented as a function of either distance or
spatial frequency, and z(x) and Z(fx, L) are known as a transform pair. The identical
concept is common in many other disciplines where functions of time (instead of
distance) are studied, and frequency is expressed in cycles per second (instead of
cycles per unit length).
In an effort to bring some physical insight into the properties of the PSD, we
can rely on this established work for some background mathematics. According
to Parseval’s theorem, the energy associated with transform pairs can be found by
integration in either time or frequency. In keeping with the analogy between time
and distance, the term roughness energy is used to deﬁne these integrations as
roughness energy =
Z L/2
−L/2
z(x)2 dx =
Z ∞
−∞
|Z( fx, L)|2 d f.
(2.30)

36
Chapter 2
Then, the average roughness power can be found by taking the distance average of
the energy as
Pave = lim
L→∞
1
L
Z L/2
−L/2
z(x)2 dx = lim
L→∞
1
L
Z ∞
−∞
|Z(fx, L)|2 d f.
(2.31)
If the limit is moved inside the integral in the last term of Eq. (2.31), then the
integrand is roughness power per unit roughness frequency because it integrates to
roughness power, and
Pave =
Z ∞
−∞
1
L|Z(fx, L)|2 d f.
(2.32)
The integrand is the PSD function, or simply PSD, and is expressed mathematically
as S 1(fx), where the subscripts indicate that the surface is one dimensional, and fx
is propagating in the x direction. It is evaluated from the Fourier transform of the
surface proﬁle as:
PSD = S 1(fx) = lim
L→∞
1
L|Z(fx, L)|2.
(2.33)
The phase information is lost in the process of taking the absolute value, so the
surface proﬁle cannot be recovered from the PSD (just as it is lost in determining
sinusoidal surface parameters from light-scatter measurements). The fact that
Z(fx, L) is squared makes the PSD symmetrical in fx. The situation is slightly more
complicated when z(x) is one sample of a random process—as would be the case
for practical surface-proﬁle measurements. The PSD is then expressed in terms of
the expected value of Z(fx, L)2 (denoted by ⟨⟩), which is formed by averaging over
an ensemble of Z(fx, L), each found from a unique z(x). In practice, proﬁlometers
actually ﬁnd PSDs from the average of many traces. In this text, the S 1 (and later
S 2) functions are expected values as deﬁned below:
S 1(fx) = lim
L→∞
⟨|Z( fx, L)|2⟩
L
= lim
L→∞
1
L
*
Z L/2
→L/2
z(x)e−j2π fxx dx

2+
.
(2.34)
Notice that the units of the one-dimensional PSD are length to the third power.
Because the PSD is symmetrical, it is fairly common to plot only the positive
frequency side. Some authors include a factor of 2 in their expressions for the
PSD to account for this, and integrate over only positive frequencies. Others, as is
the choice here, leave the PSD value as it is, and multiply the positive frequency
integral by 2 to account for the negative side. This can be a problem if PSDs
calculated by different groups need to be compared.
Various surface statistics can be found by calculating the even moments of the
PSD. (The odd moments evaluate to zero because of symmetry.) As shown below,
bandwidth-limited values of the mean-square surface roughness and mean-square

Quantifying Surface Roughness
37
slope are easily found. Again, in this text, the factor of 2 in front of each integral
accounts for integration over only one side of the symmetrical power spectrum. The
surface curvature can be obtained from the fourth moment; however, it is seldom
used or speciﬁed:
σ2 = 2
Z fmax
fmin
(2π fx)0S 1(fx) d fx.
(2.35)
m2 = 2
Z fmax
fmin
(2π fx)2S 1(fx) d fx.
(2.36)
In these equations, fmin and fmax deﬁne the spatial bandwidth over which σ and
m are deﬁned. These limits must be adjusted to allow meaningful comparison
between measurement systems with different bandwidths.
In the previous discussion, the surface proﬁles have all been known
mathematical functions that can be evaluated at any location x. In the real world
where measurements are taken, z(x) is known only at speciﬁc values of x where z(x)
is sampled. The PSD and mean-square statistics are then evaluated by estimators
instead of being fully determined (Church and Takacs 1988). N (even) samples
zn at xn locations are taken of the proﬁle at spacing d, where n varies from 0 to
N −1. This is consistent with the notation used to generate estimators for surface
statistics from the proﬁle [Eqs. (2.17) and (2.19)]. The corresponding bandwidth
and interval in spatial frequency are determined by the proﬁle sample position and
interval as
0 ≤xn = nd ≤(N −1)d,
(2.37)
1
Nd ≤fk = k
Nd ≤1
2d,
(2.38)
where
∆f = 1
Nd, and k varies from 1 to N/2.
The estimator for the one-dimensional PSD, which is similar to its integral
deﬁnition [Eq. (2.34)], can be formed from these elements.
One other key assumption is made before generating the PSD estimator: the
sample proﬁle values represent the zero-mean surface microtopography only. All
effects due to electronic noise, nonlinear instrumentation, sample tilt, curvature,
etc., have been removed by various detrending techniques (Church and Takacs
1988). This is noted in these equations by expressing the sampled values of
the proﬁle as zrn for roughness, instead of zn. This assumption is the key to
producing simple estimators that can be easily related to another means of proﬁle
characterization, the autocorrelation function. Unfortunately, these effects cannot

38
Chapter 2
be ignored and will eventually dictate the manner in which surface-proﬁle data
need to be analyzed.
The ﬁnal expression for the estimated PSD is
ˆS (fk) = 1
P
P
X
p=0
d
N

N−1
X
n=0
exp
 
−j2πkn
N
!
Wnzrnp

2
K(k).
(2.39)
The quantity K(k), which is equal to 1/2 at k = 0 and at N/2 equals 1 elsewhere,
is a “bookkeeping factor” to account for end effects. In essence, the transforms are
done as if the proﬁle segment repeats itself, and K(k) is used to avoid doubling the
contribution of the end points.
Wn is a window function that is used to reduce the “ringing” that comes about
from the sudden start and stop of the sampled proﬁle at n = 0 and N −1. The
summation over p from 1 to P is the averaging of P independent proﬁles, which
is expressed by ⟨⟩in Eq. (2.30). Equation (2.35) is the one-sided PSD and is
multiplied by 2 when integrated to obtain rms values. The use of Eq. (2.39) is more
completely deﬁned in SEMI Standard MF 1811, where several window functions
are deﬁned. It should be used in all modern stylus and optical proﬁlometers to
calculate the one-dimensional PSD from measured proﬁles. Additional discussion
on this topic is in Section 12.3.
The mean-square roughness and slope estimators follow by summing the
product of each estimated PSD segment with the associated change in frequency:
σ2  ˆσ2 = 2
kmax
X
k=kmin
ˆS 1(fk)∆fk = 2
Nd
kmax
X
k=kmin
ˆS 1(fk).
(2.40)
m2  ˆm2 = 2
kmax
X
k=kmin
(2πfk)2 ˆS 1(fk)∆fk = 2
Nd
kmax
X
k=kmin
(2π fk)2 ˆS k(fk).
(2.41)
2.2.2 Extension to two-dimensional spectra
If the analysis is extended to a two-dimensional surface z(x, y), deﬁned over a
square of dimension L, then the PSD has units of length to the fourth power. The
subscript 2 is used to denote the power spectra of a two-dimensional surface:
S 2( fx, fy) = lim
L→∞
1
L2

Z L/2
−L/2
Z L/2
−L/2
z(x, y)e−j2π(fxx+fyy) dx dy

2
.
(2.42)
The shape of the two-dimensional power spectrum and its relationship to the ﬁnish
of various optics is studied further in Chapter 4, where the power spectrum is found
from scatter data, and then used to calculate surface-roughness parameters. The
moments of the two-dimensional PSD will be used in Chapter 4 to ﬁnd surface
statistics from BRDF data.

Quantifying Surface Roughness
39
A one-dimensional spectrum, over frequencies propagating in a ﬁxed direction,
can be found from the two-dimensional spectrum by integrating over the frequency
set propagating in the orthogonal direction:
S 1(fx) =
Z ∞
−∞
S 2(fx, fy) d fy.
(2.43)
In general, S 2(fx, fy) cannot be found from S 1(fx) because the information that
describes the surface in other directions is not contained within S 1(fx). There are
two obvious exceptions. If the surface is one-dimensional in nature (grating like)
and fx propagates across the surface lay, then there is no information in the y
direction, and
S 2(fx, fy) = S 1(fx)δ(fy),
(2.44)
where δ(fy) is a Dirac delta function.
The other exception is an isotropic surface, where the same statistics are
obtained regardless of direction. In this case a single-proﬁle sweep can be used
as a sample that represents the whole surface. Then Eq. (2.43) can be rewritten as
S 1(fx) = 4
Z ∞
fx
fS 2(f)
p
f 2 −f 2x
,
(2.45)
where f 2 = f 2
x + f 2
y . This can be solved for S 2(f) as
S 2( f) = −1
2π
Z ∞
f
1
p
f 2x −f 2
dS 1(fx)
d fx
d fx.
(2.46)
By having the power spectrum available, the limits of integration used
to evaluate these parameters can be varied, facilitating comparison to other
bandwidth-limited measurements. Viewing the PSD as roughness power density
gives real physical intuition into the surface structure, and the technique
used to produce it, that is not available from the roughness averages alone.
Figure 2.4 shows a hypothetical surface PSD. It covers spatial frequencies normally
associated with both ﬁgure and ﬁnish. As shown here, the PSD is symmetrical
in frequency and has increasing roughness at increasing spatial wavelengths.
Some proﬁles follow well-deﬁned inverse power relationships between roughness
amplitude and frequency, known as fractals, which produce straight-line PSDs
on log–log plots. The impulse function at f = 0 is caused by a nonzero-mean
value of z(x). The minimum displayed frequency is due to the ﬁnite length of the
proﬁle data, while the maximum frequency is limited by N, the number of proﬁle
samples. The peak at fp is caused by a periodic surface structure with spacing 1/ fp.
The integral from f1 to f2 allows calculation of a bandwidth-limited value of the
mean square roughness σ12. The next section examines these same issues from the
viewpoint of correlation functions.

40
Chapter 2
Figure 2.4
A hypothetical surface power spectrum, showing both positive and negative
frequencies. The sharp corners at the plus and minus max frequencies indicate a “top hat”
frequency response, which will not be true for most proﬁlometer-generated PSDs.
2.2.3 The autocorrelation function
Correlation functions are used to study the relationship between two data sets.
When the two data sets are different, the process is referred to as cross correlation.
A special case, the autocorrelation function, is used to compare a data set to a
translated version of itself. Autocorrelation is carried out, as shown below, by
multiplying the function by the translated version of itself, and then averaging.
It is essentially the average of a function convolved with itself. The quantity τ
is the amount of translation and is sometimes called the slip or lag. For zero
translation the averaged integral is a maximum. As the translation increases and
τ approaches the width of prominent surface features, the integrand will sharply
reduce in average value giving an indication of prominent feature width:
C(τ) = lim
L→∞
1
L
Z L/2
−L/2
z(x)z(x + τ) dx.
(2.47)
The autocovariance function G(τ) of z(x) correlates deviations from the function
mean with a translated version of itself:
G(τ) = lim
L→∞
1
L
Z L/2
−L/2
[z(x) −¯z][z(x + τ) −¯z] dx.
(2.48)
Expansion of Eq. (2.48) reveals that
G(τ) = C(τ) −¯z2.
(2.49)
References abound on the subject (Bendat and Piersol 1971, 1986; Bennett and
Mattson 1989); however, caution is required as there are some variations in the
literature on the deﬁnition of the term autocovariance. Several features are worth
mentioning. The autocovariance is always an even function of τ, that is, G(τ) =

Quantifying Surface Roughness
41
G(−τ), and, as can be easily seen from its deﬁnition, its peak value at τ = 0 is the
surface mean-square roughness. Not as obvious is the fact that its second derivative,
evaluated at τ = 0, is the surface mean-square slope m2:
G(0) = σ2 = lim
L→∞
1
L
Z L
0
[z(x) −¯z]2 dx.
(2.50)
 d2G(τ)
dτ2
!
τ=0
= m2.
(2.51)
The autocorrelation approach suffers from the same effective-bandwidth limits
as the power spectrum did in the last section. They each use ﬁnite-length scans
of the proﬁle, sampled at ﬁnite increments, as input to equations deﬁned for all
values over an inﬁnite scan length. Using the notation of the last section, and again
restricting the proﬁle to samples of roughness only, an estimator for C(τ) can be
written as
ˆC(τk) = 1
N
N−1−|k|
X
n=0
ZrnZrn+|k|,
(2.52)
where τk = kd is the lag.
The autocovariance function can take on both positive and negative values. If
the surface is periodic, then G(τ) will also be periodic with the same wavelength.
As indicated in Fig. 2.5, the autocovariance of a surface dominated by random
structure will fall from a peak at zero lag and eventually, as all similarity is lost
between the surface and its translated counterpart, will approach zero. Unlike
Fig. 2.5, some autocovariance functions may have an inﬂection point at zero lag
and no deﬁned deriviative at this point. The lag length required to drop from the
peak value by a factor of e−1 is sometimes called the autocorrelation length ℓc. It is
generally regarded as being a representative lateral dimension of surface structure,
similar, but not equal to, the average surface wavelength ℓdeﬁned in Eq. (2.11).
Other deﬁnitions of the autocorrelation length are common. For example, it can
also be evaluated by integrating the squares of either the autocorrelation function
or the power spectrum, as follows (Church 1987, 1988). This deﬁnition yields the
e−1 value when the correlation function is an exponential:
ℓc = 2
σ4
Z ∞
0
C2(τ) dτ = 2
σ4
Z ∞
0
S 2
1(fx) d fx.
(2.53)
The autocorrelation function and the power spectrum are both found from the
surface proﬁle, and both can be used to ﬁnd the standard surface descriptors σ
and m and a characteristic surface length. It is reasonable to expect a relationship
between the two. This is expressed in the Wiener–Khinchin relationship (Bendat
and Piersol 1986), which states that the two functions are a Fourier transform pair.

42
Chapter 2
Figure 2.5
Autocovariance function of a random surface.
Further, because C(τ) is even, only the even part of the transform phasor is required.
The same is true of the inverse transform because, as has been made clear, the PSD
is also an even function:
S 1(fx) =
Z ∞
−∞
C(τ) e−j2π fxτ dτ = 2
Z ∞
0
C(τ) cos(2πfxτ) dτ.
(2.54)
C(τ) =
Z ∞
−∞
S 1( fx) ej2π fxτ d fx = 2
Z ∞
0
S 1(fx) cos(2πfxτ) d fx.
(2.55)
When the PSD is written in terms of the autocovariance function, the impulse
function, located at fx = 0 in Fig. 2.4 and discussed in the previous section,
becomes evident:
S 1(fx) =
Z ∞
−∞
[G(τ) + ¯z2] e−j2π fxτ dτ =
Z ∞
−∞
G(τ)e−j2π fxτ dτ + ¯z2δ( fx). (2.56)
The symmetry property leads to the use of one-sided power spectra and
autocorrelation functions. As previously indicated, display and integration over
only the positive frequencies is common after doubling the integrand. Similar
expressions can be developed (Church, Jenkinson, and Zavada 1979) for the two-
dimensional spectra.
Functions that are Fourier transform pairs, such as C(τ) and S 1( fx), are
simply two different vehicles for expressing the same information. The PSD
expresses proﬁle statistics in spatial frequency space (units of inverse distance),
and the autocorrelation function expresses the same information in slip space
(units of distance). Expressing information ﬁrst as a function of a variable and
then as the inverse variable results in a curious relationship between the two
expressions. Multiplication of two functions in the variable space is equivalent to
the convolution of the two functions in the inverse variable space, and the converse
is also true. This fact becomes important in the next section, where the effects of
proﬁle errors are discussed.

Quantifying Surface Roughness
43
As described, the power spectrum and the autocovariance function are
equivalent in their information content. They both offer bandwidth-limited views of
surface characterization. The power spectrum is more physically intuitive for most
people, but some would disagree. There are some practical caveats that sometimes
dictate the use of one over the other. The deﬁnition of a deterministic z(x) over
a ﬁnite distance L imposes a practical difﬁculty on using the two as a transform
pair. For example, if a bandwidth-limited section of the PSD had been obtained
from the proﬁle data (or by some other technique such as light scatter) it would be
utter folly to transform to the autocorrelation function and then use that to obtain
surface statistics. To do so requires that the transform be applied over frequencies
from zero to inﬁnity [Eq. (2.51)], and this cannot be accomplished because of the
bandwidth limitation. Errors are introduced at no real gain in information, and the
reverse is also true. On the other hand, the estimators for S 1(fx) and C(τ) deﬁned
for ﬁnite scans and given in Eqs. (2.39) and (2.52) transform exactly. However,
there is another very basic concern that tips the balance heavily in favor of using
the power spectrum rather than the correlation approach to characterize surfaces,
and this concern is the topic of the next section.
2.3 The Effects of Proﬁle Measurement Error
The discussion in the preceding sections has assumed that the proﬁle data is
essentially error free. In fact, this will not be the case, as indicated just prior to
Eq. (2.39). In addition to the bandwidth limitations imposed by sampling a ﬁnite
proﬁle length, the measuring instrument (whether stylus or optical proﬁlometer)
will also have a frequency-dependent response. In stylus proﬁlometers, these types
of errors are caused by stylus skip and bounce, and the nonlinear effects are
introduced by ﬁnite stylus radius (Wilson, Al-Jumaily, and McNeil 1987; Church
and Takacs 1988; Church et al. 1988). Errors vary for the different types of
interferometric instruments but include the ﬁnite pixel size of recording CCDs and
the usual imaging limitations of the optics employed. Electronic noise and analog
ﬁltering are also responsible for measurement limitations. Additional problems can
be introduced because the exact spatial relationship (height, tilt, and roll, which are
also called piston, slope, and curvature) between the instrument and the sample is
unknown. Thus, some combination of the scan length, the measurement procedure,
and the instrument characteristics results in a frequency response that is not ideal.
The instrument frequency response will not be a “top hat” (or ﬂat rectangular
shape) with constant value over a ﬁxed frequency band but will vary and is likely
to change with different instrument settings.
If the resulting instrument response is known, or can be estimated, then its
effect can be removed or reduced during computer analysis of the data. This is
accomplished through the use of random signal theory tools (Church and Takacs
1986a, 1986b, 1988; Church et al. 1988; Church and Takacs 1989b). A common
approach is to characterize the bandwidth-limited instrument-frequency response
and the bandwidth limitations imposed by sampling the ﬁnite scan length as
functions of frequency. These responses can then be applied as inverse multipliers

44
Chapter 2
to the power spectrum found from the measured proﬁle data. This process allows
estimated values of the actual power spectrum to be calculated. These corrections,
which are easily expressed as functions of frequency and can be applied as
multipliers in the frequency domain, would have to be transformed to functions
of slip (distance) and then convolved with the autocovariance function in order
to correct it for the same errors. Both of these operations require integration from
minus to plus inﬁnity and introduce bandwidth effects into the corrections. Because
the tools for applying the corrections need to compensate for instrument error,
and bandwidth limits are more naturally (and accurately) applied in the frequency
domain, the bottom line is that the PSD function is the logical mechanism for
characterizing surface roughness and extracting surface statistics.
In order to generate the proﬁlometer frequency corrections mentioned above,
the true PSD of a sample needs to be found. A technique for accomplishing this is
described in Section 7.16 and relies on using light-scatter measurements taken on
samples that are known to scatter only from their topography. The techniques for
identifying these special samples rely on information presented in the next several
chapters.
2.4 Summary
For a book on scatter, this chapter has spent a great deal of time on the analysis
of proﬁle data. This was done because of rampant confusion in industry over the
comparison of roughness statistics that are obtained by different techniques. It
will soon become evident that BRDF data can be used to provide a bandwidth-
limited section of the two-dimensional surface power spectrum. The deﬁnitions
and discussion of this chapter are intended to act as a guide for comparing (or
sometimes refusing to compare) BRDF-generated surface statistics with proﬁle-
generated surface statistics. The key issue is to be able to measure and calculate
roughness in a manner that allows producers and users of a variety of products to
clearly communicate with one another.
Roughness is commonly quantiﬁed by analyzing surface-proﬁle data to extract
various statistical averages. The surface height deviation, from a mean value, is
usually expressed as an a.a. in the nearly macroscopic world of the machine tool
industry. It makes sense to express roughness as a mean square because this average
is easily calculated from the PSD, and for smooth surfaces is proportional to
scattered-light measurements. The a.a. cannot be found from the PSD. In addition
to surface height averages, it is also useful to characterize roughness in terms
of its average lateral dimensions. The parameters of interest are mean-square
slope, average spatial wavelength, and the autocorrelation length. An extremely
important point is that all of these quantities are dependent, to some degree, on the
measurements used to obtain them. So, although it would be nice to know that a
sample has an rms roughness of, for example, 50 Å, with an average wavelength of
10 µm, in fact the same sample measurement done in a different direction, or with
a different instrument or using a different scan length or a different sample interval,
is very likely to result in different values for the roughness and wavelength. This

Quantifying Surface Roughness
45
is caused not only by instrument error and sample nonuniformity, but also by the
inherent bandwidth limitations imposed on all measurements. Thus, in order to
be meaningful, roughness characterization should be reported with the associated
measurement bandwidths.
Two approaches are commonly used to enhance surface characterization beyond
that available from just two or three proﬁle averages: calculation of the surface
PSD function and the autocovariance function. These functions are generated from
surface-proﬁle data, and they can each be used to calculate the various proﬁle
averages of interest. The PSD is the preferred route because, as a function of
frequency, it displays the required bandwidth limits, and it can be more accurately
corrected for known deviations from ideal instrument response.
Chapter 3 introduces the known relationships between surface proﬁle and the
associated reﬂected scatter pattern (BRDF). The PSD plays an important role, as
it is nearly proportional to the BRDF. In Chapter 4, relationships are presented
that allow calculation of the PSD, the various proﬁle averages, and associated
bandwidth limits from the BRDF.

 

Chapter 3
Scatter Calculations and
Diffraction Theory
“In theory there is no difference between theory and practice. In practice there is.”
– Yogi Berra
This chapter outlines the important elements of diffraction theory and gives several
key results that pertain to the interpretation of measured scatter data. These results
are employed in Chapters 4 and 8 to relate measured scatter from reﬂective
surfaces to the corresponding surface roughness and to consider various methods
of scatter prediction. In Chapter 9, the diffraction theory results presented here are
combined with the polarization concepts found in Chapter 5 and used to outline
a technique for separating surface scatter from that due to subsurface defects and
contamination. A complete development of diffraction theory is well beyond the
scope of this book; however, excellent texts on the subject are available, and these
will be referenced in the basic review presented in the next three sections. Some
relatively new diffraction results are presented in Sections 3.4–3.6. The following
discussions assume that the reader has some familiarity with EM ﬁeld theory and
the required complex math notation. Appendix A is a brief review of the elements
of ﬁeld theory, and Appendix B gives details of some diffraction calculations.
3.1 Overview
When light from a point source passes through an aperture or past an edge, it
expands slightly into the shadowed region. The result is that the shadow borders
appear fuzzy instead of well deﬁned. The effect is different from the one obtained
by illuminating an object with an extended light source (such as the shadow of
your head on this book) where the width of the reading lamp also contributes to
an indistinct shadow. Well-collimated light sources (sunlight, for example) also
produce fuzzy shadow edges. This bending effect, which illustrates the failure of
light to travel in exactly straight lines, is called diffraction and is analyzed through
the wave description of light.
As explained in Appendix A, the propagation of light is described in terms of the
transverse electric ﬁeld E(t, r), where r denotes position, and t is time. The value
k is 2π/λ, and v is the light frequency. The expression in Eq. (3.1) is for a wave
47

48
Chapter 3
traveling in the direction of increasing r:
E(t, r) = Re[e(r)e j(kr−2πvt)].
(3.1)
E(r) = e(r)e jkr.
(3.2)
Phasor notation is used (the “real part” is understood), and the dependence on
time, which will appear in all terms, is dropped for convenience as indicated in
Eq. (3.2). The term e(r) gives spatial dependence. Quantities shown in bold are
vectors, indicating that they denote the polarization direction. Three common cases
given below are for a plane wave traveling from r = 0, a spherical wave diverging
from r = 0, and a spherical wave converging to r = 0. The value E0 is a constant
in space and time. The power of the converging and diverging waves, which is
proportional to 1/r2, follows the expected inverse square law:
E(r) = E0e jkr
Plane wave.
(3.3)
E(r) = E0
r ejkr
Diverging.
(3.4)
E(r) = E0
r e−jkr
Converging.
(3.5)
An inﬁnitely wide plane wave can be thought of as being made up of an inﬁnite
number of spherical waves. Imagine the spherical waves originating at each point
along a constant phase plane of the plane wave. Superimposing the spherical
waves at some distance results in equal forward (Z direction) contributions and
equal but opposite contributions in the XY directions. Thus, at each point, the
spherical contributions sum to a forward-propagating wave with equal amplitude
and phase—in other words, a plane wave. If the original wave has amplitude or
phase variations, then the result will not be a plane wave, but summing the spherical
components will give the new wavefront. This is the essence of the calculations
in the next few paragraphs; variations are the result of approximations made to
simplify the mathematics.
Figure 3.1 shows the diffraction geometry for light transmitted through an
aperture in the x, y plane. The aperture, centered at r = 0, is typically illuminated by
a point source (diverging), a collimated beam (plane wave), or a converging beam
(virtual point source). In general, the aperture modulates the transmitted light in
both amplitude and phase. The modulated light leaving the aperture is given by
E(x, y), and the object of the diffraction calculation is to ﬁnd the resulting electric
ﬁeld E(xs, ys) in the observation plane, located a distance R from the aperture. The
source could also be located on the z > 0 side of a reﬂective aperture (or sample).
Amplitude modulations, caused by changes in aperture reﬂectance or
transmittance, are expressed by variations in e(x, y). For example, a slit aperture
changes from zero transmittance to unity and back again with no phase modulation.
Phase modulations are caused by index of refraction changes in transmitting

Scatter Calculations and Diffraction Theory
49
Figure 3.1
Geometry for diffraction from an aperture in the x, y plane to the xs, xy plane.
samples and by surface roughness on reﬂecting samples and are expressed by
changes in the exponential component of E(r).
A useful exercise is the calculation of diffracted light from a slit aperture without
the beneﬁt of using a diffraction theory result. The general nature of the solution,
the approximations required, and the limitations of such an approach become
immediately obvious. Consider a slit aperture of width L to be centered on the
x, y plane along the y axis, as shown in Fig. 3.2. A plane wave traveling along
the z axis is incident upon the aperture, and diffraction is to be observed at the
xs, ys plane located at z = R. The assumption is made that R ≫L. Use is
made of the Huygens principle, which is an intuitive statement that wavefronts
can be constructed by allowing each point in a ﬁeld to radiate as a spherical
source. The new wavefront, downstream, is then found from the envelope of the
spherical fronts. Early diffraction results depended on variations of this reasoning,
even though there are some obvious problems. For example, what do we do about
the backward-traveling wave? Polarization issues are ignored. We will also ignore
any ﬁeld–aperture interaction, and assume that the ﬁeld exists as presented by
the source right up to the aperture edge, where it drops to zero in a sudden
discontinuity. This is a true “back-of-the-envelope” calculation, whose purpose is
to develop insight for the more complicated issues to follow.
Two rays leaving from x = 0 and x = L/2 and eventually interfering at
coordinate Cs on the xs axis are shown in the diagram. The path difference of
the two waves is the small distance h shown in the ﬁgure. Making use of the small-
angle assumptions gives
h = Lxs/2R.
(3.6)
At some value of xs, h will reach the value λ/2, and the two waves will cancel
in the observation plane. Within the limitations of the small-angle assumption, the
same reasoning holds for all the other pairs of rays separated by L/2 at the aperture
and reaching point Cs. Thus, the condition
xs = ±nλR/L
(3.7)

50
Chapter 3
Figure 3.2
Plane wave diffraction from a slit.
(where n is an integer) will result in a zero-intensity value on the otherwise
illuminated xs axis. The relative intensity pattern can also be found. Ignoring
polarization issues, the spherically expanding wave from a differential source dE
over dx, located at x in the aperture, will have an amplitude proportional to dx
and inversely proportional to the distance from x. The resulting differential scalar
amplitude from the differential source may be evaluated in the observation plane,
where K has been used as a proportionality constant:
dEs =
Kdx
p
R2 + (xs −x)2 e jk√
R2+(xs−x)2.
(3.8)
The approach is to integrate over x from −L/2 to L/2, and thus obtain the total ﬁeld
strength at Cs. In order to perform the integral easily, some assumptions are made
to simplify the expression for the distance rs between x and Cs. In the amplitude
component, the distance is approximated as R; however, in the phase component,
this is inappropriate, as distance errors of only half a wavelength change the sign
with which a particular component is summed. For the phase term, the radical can
be expanded as
p
R2 + (xs −x)2 = R
"
1 + (xs −x)2
R2
#1/2
= R
"
1 + (xs −x)2
2R2
−(xs −x)4
8R4
+ · · ·
#
= R + x2
s
2R −xsx
R + x2
2R −x4
s
8R3 · · ·

Fraunhofer
←−−−−−−−−−−→


Fresnel
←−−−−−−−−−−−−−→

(3.9)

Scatter Calculations and Diffraction Theory
51
Each additional term makes the integral more accurate and more difﬁcult to
evaluate. The two common approximations have been named after the men who
made them, as indicated. The approximations are better for large R. This has led to
the terminology getting to the far ﬁeld, which usually implies that the Fraunhofer
approximation is accurate enough to predict experimental results. If a source is
used that converges at the observation plane, then a term is introduced that cancels
the x2/2R term, making the Fraunhofer and Fresnel approximations identical. For
the example at hand, we will proceed with the Fraunhofer approximation and
evaluate the integral as follows:
Es = KL
R ejk(R+x2
s/2R)
Z L/2
−L/2
e−j(2πxsx/λR)dx,
(3.10)
Es = KL
jR e jk(R+x2
s/2R) sinc
 xsL
λR

,
(3.11)
where
sinc(α) = sin(πα)
πα
for any real argument α.
Squaring the absolute value of the electric ﬁeld and dividing by twice the
impedance of free space η0 gives the time-average power density Is (watts per
unit area) as a function of xs:
Is =
1
2η0
KL
R
2
sinc2  xsL
λR

.
(3.12)
This relationship is plotted in Fig. 3.3. Notice that the zero intensity values appear
at the locations predicted earlier by Eq. (3.7). This means that the Fraunhofer
approximation is equivalent to the same small-angle approximation. Patterns very
much like the one in Fig. 3.3 can be observed by placing a small slit in a HeNe
laser beam. The inverse aperture, a small block, is easier to do. A piece of hair
works just ﬁne. Using the above relationships and measurements of the diffraction
pattern made with a ruler allows the hair diameter to be calculated (and makes
a great classroom demonstration). The proportionality constant K has not been
evaluated, but this can be accomplished by integrating over the observation plane
and applying the conservation of energy.
Another observation is worth making: the sinc function is the Fourier transform
of the slit aperture [sometimes expressed as rect(x/L)]. In fact, Eq. (3.10) shows
this explicitly. In this context, the quantity (xs/λR) may be viewed as a spatial
frequency propagating in the x direction in the aperture plane. Notice that it has
units of inverse length, as required in Chapter 1. In fact, this is the same expression
for spatial frequency that is obtained from the grating equation at normal incidence
and small angles. Retracing our steps back through the development, it is easy to
see that if an aperture function other than unity had been applied, the Fraunhofer

52
Chapter 3
Figure 3.3
Diffraction pattern from a slit.
approximation is equivalent to simply taking the Fourier transform of that function.
This is one of the results of scalar diffraction theory and is the basis for the ﬁeld of
study called Fourier optics.
Analysis of the single slit, examined above, is straightforward because the
sample (the slit) is very simple. For one thing, the slit has constant transmission
amplitude across its aperture. Many samples will require that phase changes also
be considered (for example, the reﬂective sinusoidal surface of Chapter 1). Even for
the slit, the required mathematics are messy, and several assumptions are needed.
If the sample is somehow more complicated than the on/off nature of the slit, or
can be deﬁned only statistically, then the situation is far more difﬁcult.
It has been common practice to refer to diffraction calculations as either
scalar or vector, depending on whether or not polarization is considered. A more
descriptive way is to label the calculations based on the mathematical approach.
Most optics texts analyze diffraction by the Kirchhoff method, which is described
in the next section and can be either scalar or vector in its approach. A second
method, introduced by Rayleigh in 1895, has been less well traveled because of
the considerably stiffer mathematical requirements but offers advantages in some
areas. The next two sections review these approaches.
3.2 Kirchhoff Diffraction Theory
Diffraction calculations based on the Kirchhoff theory address many of the loose
ends of the section: the proportionality constant is evaluated, and boundary
conditions are handled by various approximations. The Fraunhofer and Fresnel
approximations are generally treated exactly as they were in the last section.
There are lots of approximations to make, leaving ample room for considerable
individuality in applications to speciﬁc problems. The general scalar Kirchhoff
approach is outlined in this section, and a commonly used Fraunhofer equation is
derived in two dimensions. This equation is then used for several easily deﬁned
cases, including the sinusoidal grating of Chapter 1.

Scatter Calculations and Diffraction Theory
53
This presentation is intended as an outline and is restricted to scalar results only.
Far more complete treatments of this subject are readily available in the literature
(Beckmann and Spizzichino 1963; Goodman 1968). The derivation is based on
Green’s theorem, which is used to convert back and forth between volume and
surface integrals over two functions. One of these functions plays the role of an
unknown to be evaluated, while the other is arbitrarily chosen. The two complex
scalar functions in question, E(x, y, z) and G(x, y, z), are restricted to situations
where they and their ﬁrst and second derivatives are single valued and continuous
within a volume V and on its bounding surface S . In addition, since the objective
here is a solution for electric ﬁeld strength of diffracted light, it is required that
both functions obey the wave equation. The vector n is deﬁned as the outwardly
directed unit normal to the surface S . Green’s theorem is expressed as
Z
V
[G∇2E −E∇2G]dV =
Z
S
[G∇E −E∇G] · n dS,
(3.13)
and the wave equation is given as
(∇2 + k2)E = (∇2 + k2)G = 0.
(3.14)
We will solve for the unknown E(x, y, z) at point Cs within V and choose
G(x, y, z) as an arbitrary Green’s function. The solution will depend not only on the
choice of G(x, y, z) but also on the choice of the bounding surface S surrounding V.
This freedom of choice gives the solution a rather arbitrary aroma. Would a better
solution have been obtained if another course had been chosen? But the purpose
here is to follow well-trod paths.
The wave equation allows the functions to be deﬁned throughout the volume V1,
and we convert to the surface evaluations using Green’s theorem. The solution for
E(x, y, z) at Cs is then regarded as being due to diffraction occurring from S . The
geometry is shown in Fig. 3.4. Kirchhoff picked a unit-amplitude spherical wave
expanding from the observation point Cs as his choice for G(x, y, z). Therefore,
G(r) = e jkrs
rs
.
(3.15)
The value rs is the distance from Cs to the point where G(x, y, z) is to be evaluated,
as indicated in Fig. 3.4. The point Cs must be excluded from the volume V because
of the discontinuity in G(x, y, z). This is handled by creating a sphere of differential
radius around Cs that is excluded from the volume. Substituting ﬁrst into the wave
equation (to evaluate the Laplacians) and then into Green’s theorem gives
Z
V
(G∇2E −E∇2G)dV =
Z
S s+S a+S 0
"e jkrs
rs
∇E −E∇
 ejkrs
rs
!#
· n dS.
(3.16)

54
Chapter 3
Figure 3.4
Geometry for the Kirchhoff solution.
The four integrals are evaluated individually. The volume integral is zero by
inspection. This will be true as long as there are no sources within the volume.
The surface integral over S s evaluates to −4πE(xs, ys) in a straightforward manner
when the radius of the differential sphere is reduced to zero in the limit. With
some difﬁculty, the integral over S 0 can be shown to reduce to zero for most
physically realizable situations as the radius of that surface approaches inﬁnity.
Equation (3.16) now reduces to an expression for E(xs, ys) in terms of the ﬁeld,
and its normal derivative over the inﬁnite plane S a directly behind the aperture:
E(xs, ys) = 1
4π
Z
S a
"e jkrs
rs
∇E −E∇
 ejkrs
rs
!#
· n dS.
(3.17)
Now, if the emission from Ce is a spherical wave, given by
E = E0
ejkre
re
,
(3.18)
and, if the radii rs and re are much larger than a wavelength, then
∇
 e jkr
r
!
=
 
jk −1
r
! ejkrr
r2
 jkejkrr
r2 .
(3.19)
Substitution back into Eq. (3.17) gives an integral expression for E(xs, ys) that
includes contributions from the entire inﬁnite plane behind the aperture. If the
boundary conditions of the previous section are imposed (i.e., outside the aperture
E = ∇E = 0), and inside the aperture the evaluations follow from Eqs. (3.18)

Scatter Calculations and Diffraction Theory
55
and (3.19), then the result is the Fresnel–Kirchhoff diffraction formula (sometimes
known as the reciprocity theorem of Helmholtz):
E(xs, ys) = E0
j2λ
Z
S a
ejk(rs+re)
rsre
[cos(rs, n) −cos(re, n)] dS.
(3.20)
The bracketed cosines (deﬁned in terms of the angle between the indicated vectors)
are called the obliquity factor, which is approximately 2 for geometries where rs
and re are nearly perpendicular to the x, y plane. Equation (3.20) can be related
to Huygens’ principle in an interesting way. The integrand can be broken into
two parts by factoring out the exponential, which looks like a Huygens spherical
wave, expanding from ds in the aperture to Cs in the observation plane. Everything
that remains can be considered a complex amplitude of that spherical wave. If the
observation point is moved back to the source, then the obliquity factor is zero (the
cosines cancel), and the backward traveling wave is zero:
E(xs, ys) =
1
j2λ
Z
S a
[complex aperture amplitude]e jkrs
rs
dS.
(3.21)
Unfortunately, there is a problem with the boundary conditions in Eq. (3.20), as
it can be shown that if E and its derivative are identically zero over the aperture
edge, then they are also zero within the aperture. This can be addressed (Goodman
1968) by choosing a Green’s function that corresponds to a source at Cs and its
mirror image, 180 deg out of phase. This choice was motivated by the fact that G
is identically zero over the aperture, so that the zero value boundary condition on
∇E need not be applied:
G = ejkrs
rs
−e jkr′
s
r′s
.
(3.22)
The result is known as the Rayleigh–Sommerfeld diffraction formula:
E(xs, ys) = E0
jλ
Z
S a
ejk(re+rs)
rers
cos(rs, n)dS.
(3.23)
Notice that the only difference is in the obliquity factor, which is now
independent of the incident angle. This solves the boundary condition problem;
however, if the observation point is again moved to the source, there is a backward-
traveling wave. The relative merits of these two scalar representations has been
studied (Wolf and Marchand 1964) and are still a topic of interest.
Another way of looking at scalar diffraction, which gives similar results and
is more pleasing physically, is to assume that the waves within a clear aperture
progress undisturbed (no Huygens wavelets), and the diffraction pattern is caused
by the superimposition of a second set of waves that originate from the aperture

56
Chapter 3
boundaries (Keller 1962). Considering all of the approximations and rather
arbitrary choices in approach, it is amazing that diffraction theory produces results
that even resemble reality.
As long as the source is kept reasonably close to the aperture normal, our
two results [Eqs. (3.20) and (3.23)] are identical, except for small variations in
the obliquity factor. Further, if we restrict ourselves to apertures that are small
compared to re and rs, then the cosines are nearly cos θi and cos θs, respectively,
and are independent of x and y. Under these assumptions, it is convenient to express
Eq. (3.23) as
E(xs, ys) = cos(θs)
jλ
Z
S a
Ea(x, y, 0)e jkrs
rs
dS,
(3.24)
where Ea(x, y, 0) is the incident ﬁeld modulated by whatever is in the aperture. For
the clear aperture studied so far,
Ea(x, y, 0)| Clear
Apt. = E0
re
ejkre.
(3.25)
In general, Ea(x, y, 0) are composed of whatever source wave impinges upon the
aperture modulated in amplitude and/or phase by whatever is contained within
the aperture. In the case of a reﬂective “aperture,” amplitude is modulated by
changes in reﬂectance and phase modulated by roughness. The radius rs can now
be evaluated much as we did in the last section to any degree of accuracy:
rs = [(xs −x)2 + (ys −y)2 + R2]1/2,
(3.26)
rs = R + x2
s
2R + y2
s
2R −xsx
R −ysy
R + x2
2R + y2
2R −x4
s
2R −y4
s
2R + · · ·

Fraunhofer
←−−−−−−−−−−−−−−−−−−−→


Fresnel
←−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−→

(3.27)
Again, of particular interest is the Fraunhofer approximation, which gives the
common scalar diffraction formula:
E(xs, ys) = cos θs
jλR e jk(R+x2
s/2R+y2
s/2R)
Z
S a
Ea(x, y, 0)e−j2π(fxx+fyy)dxdy.
(3.28)
The quantities fx and fy are deﬁned as spatial frequencies in the aperture:
fx = xs
λR
fy = ys
λR.
(3.29)

Scatter Calculations and Diffraction Theory
57
Equation (3.28) is simply the Fourier transform of the electric ﬁeld within the
aperture multiplied by a complex amplitude. Notice that it is identical to the one-
dimensional form derived in Eq. (3.10), where the proportionality constant K has
now been evaluated as 1/jλ. If the obliquity factor had been left exact, then the
integral would have been considerably more difﬁcult to evaluate.
Equation (3.28), with slight variations on the obliquity factor, has been used
throughout the literature to evaluate a number of common diffraction problems
(Goodman 1968; Iizuka 1985). Here, it is enough to give three brief examples.
First, by inspection after reviewing Eqs. (3.10)–(3.12), the diffracted intensity
Is = I(xs, ys) in watts per unit area from a rectangular aperture of dimensions
Lx, L with normal incidence is given as
Is =
1
2η0
 E0LxLy cos θs
λR
!2
sinc2  xsLx
λR

sinc2
 ysLy
λR
!
,
(3.30)
where η0 is the impedance of free space.
Notice that, as in the one-dimensional slit, diffracted power and the min/max
diffraction locations depend on both wavelength and aperture size, and the ﬁrst
minima is pushed farther from specular as the aperture size decreases. The two-
dimensional result shows that there is no coupling of diffraction from the x and y
aperture edges.
The second result is obtained for a circular aperture of diameter L, as shown in
Eq. (3.31), where J1 is a ﬁrst-order Bessel function of the ﬁrst kind, and r2
s = x2
s+y2
s.
Known as an Airy pattern, these concentric diffraction rings are familiar to anyone
who has adjusted a conventional spatial ﬁlter. The ﬁrst minimum does not come at
quite the same distance from center as for the slit aperture:
Is =
1
2η0
 E0kL2 cos θs
16R
!2 " J1(kLrs/2R)
kLrs/4R
#2
.
(3.31)
The third example, which is the sinusoidal surface of Section 1.2, is of particular
interest because of its use in modeling more complicated surfaces through Fourier
series. The surface is a square reﬂective surface of side length L. It differs from
the previous examples in three respects. First, as a reﬂector, it represents an inverse
aperture. Second, because we assume the material reﬂectance to be constant across
the surface (1.0 in this case), the effect is one of phase (not amplitude) modulation
on the incident light. This is because light striking a surface valley travels farther
than light striking a surface peak. The grating is oriented in the x, y plane at z = 0,
with the grating lines parallel to the y axis, as depicted in Fig. 1.1. The grating
amplitude is a, the frequency is fg, and α is the phase at x = 0:
z(x, y) = a sin(2π fgx + α).
(3.32)
The third difference allows large incident angles and large scatter angles. These
changes require considerably more manipulation than is easily accomplished by

58
Chapter 3
“inspection,” so the calculation has been banished to Appendix B. The sinc
functions are now given in terms of θs,φs locations on a scattering sphere centered
on the scattering aperture:
Is =
1
2η0
 E0L2 cos θs
λR
!2
∞
X
n=−∞
J2
n(∆) sinc2 L
λ (sin θs cos φs −n fgλ −sin θi)

× sinc2 L
λ sin θs sin φs

.
(3.33)
The argument of the Bessel function ∆is the peak phase retardation introduced by
the grating:
∆= ka(cos θi + cos θs).
(3.34)
The summation terms (n = 0, 1, 2, . . .) represent the various orders present
in the diffraction pattern. The intensities of various orders may be converted to
powers and the various grating efﬁciencies calculated, as shown in Appendix B.
The incident power Pi is merely cos θi(E0L)2/2η0:
Pn/Pi = cos θs
cos θi
[Jn(∆)]2.
(3.35)
P1/Pi = cos θs
cos θi
[1/2ka(cos θi + cos θs)]2  (ka)2
for small angles,
(3.36)
where J1(∆)  ∆/2 has been used. The angle θs can be found from the grating
equation by inserting the appropriate value of n.
Relative amplitudes are determined by the Bessel functions. Thus, the squared
ratio of the ﬁrst-order to zero-order Bessel functions (with the cosine) determines
grating efﬁciency, which in turn can be used to ﬁnd the grating amplitude
a. Appendix B points out that the argument of the ﬁrst sinc function, which
determines order position, is nothing more than the grating equation given
in Chapter 1. Order position can be used to determine the grating frequency
f1. Conversion of the measured scatter pattern to surface roughness statistics,
discussed in Chapter 4, relies on these relationships. Notice that the surface phase
term α is missing from Eq. (3.33). It appears in the corresponding expression
for diffracted ﬁeld strength (see Appendix B) and is lost in the process of
taking the absolute square to obtain diffracted power. It can be recovered by
interferometrically measuring the relative phase between any order and the zero
order; however, this is not typically done in scatter measurements.
Equations (3.33) and (3.35) have been obtained without any apparent restrictions
on the surface roughness or grating amplitude a. Actually, as pointed out by
Beckmann and Spizzichino (1963, p. 178), there is a hidden restriction. In
Eq. (3.35), the cosine term, which comes from the obliquity factor, should actually
be the cosine of the angle between the scatter direction and the surface normal,

Scatter Calculations and Diffraction Theory
59
which has been assumed to be parallel to the z axis. As grating amplitude (and/or
frequency) increases, the amount by which the surface normal waves back and forth
as a function of the x coordinate increases. Assuming that no more than a 10% error
in the obliquity factor is permissible, and that the light is normally incident on the
surface, the maximum allowed grating amplitude can be shown to be
amax
λ
≤
0.025
π tan2 θs
.
(3.37)
For visible wavelengths and diffraction within about 20 deg of specular, this
restricts amax to several hundred angstroms, which is a rough surface by optical
standards. However, at higher scatter angles (corresponding to steeper surface
slopes), the restriction is much more severe. Although more-sophisticated obliquity
factors may be less sensitive, this does illustrate that one failing of the Kirchhoff
theory is its inability to accurately handle high-angle diffraction. On the other hand,
the Rayleigh–Rice theory, which is used in Chapter 4 to convert the diffraction
pattern to surface statistics, requires that the surfaces be smoother.
The method of Appendix B can be applied to surfaces that are composed of
more than one sinusoidal grating. For the simple case of two sinusoidal gratings
(subscripts 1 and 2) oriented along the x and y axes, respectively, the diffraction
intensity is given by
Is =
1
2η0
 E0L2 cos θS
λR
!2
∞
X
n=−∞
∞
X
m=−∞
J2
n(∆1)J2
m(∆2)
× sinc2
"1
λ(sin θs cos φs −n f1λ −sin θi)
#
sinc2
"1
λ(sin θs sin φs −m f2λ)
#
.
(3.38)
The diffraction pattern is now composed of a grid of points given in θs, φs on
the scattering sphere. The point locations are determined by the arguments of the
two sinc functions. These arguments are composed of the two grating equations
necessary to describe hemispherical diffraction:
sin θs cos φs = sin θi + fxλ.
(3.39)
sin θs sin φs = fyλ.
(3.40)
Refer to Fig. 1.6 for a deﬁnition of angle φs. Observations similar to those for
the one-dimensional grating apply to the calculations of grating amplitude and
frequency and to the restrictions on grating dimensions.
The true issue of boundary conditions has been avoided so far by neglecting
edge effects, sticking to apertures instead of real surfaces, and assuming inﬁnite
conductivity for the sinusoidal surfaces. The actual situation is more complicated.
Reﬂectance is a function of conductivity, incident angle, and diffraction angle

60
Chapter 3
(and thus surface contour). It is less accurate to assume the simple modulations
of the source wave used above for the more complicated case of scatter from real,
arbitrarily rough surfaces.
Beckmann and Spizzichino’s book (1963) gives a rather complete description
of the Kirchhoff method applied to rough surfaces. They include reasonable
approximations for the boundary conditions over the surface under the assumption
of inﬁnite conductivity, and treat both s- and p-polarized light. Their well-known
results, which are obtained under the slightly different condition of an inﬁnitely
wide sample, are expressed as diffracted ﬁeld strength over incident ﬁeld strength
[p. 48, Eqs. (7) and (8) in Beckmann and Spizzichino (1963)], and are expressed
here, after notation changes, as power grating efﬁciency:
Pn/Pi =
"
sec θi
1 + cos(θs + θsn)
cos θi + cos θsn
#2 J2
n(∆)
J2
0(∆),
(3.41)
where again,
∆= ka(cos θi + cos θs).
(3.42)
Except for a more-complicated obliquity factor and a less-complicated phase delay,
the result is similar to Eq. (3.33).
Beckmann and Spizzichino have also derived Kirchhoff results for isotropic
randomly rough surfaces with a normal (Gaussian) height distribution (Beckmann
and Spizzichino 1963, p. 88). They divide his result into six cases to cover smooth-,
medium-, and rough-surface calculations for both one- and two-dimensional
surfaces. Interpretation of these equations requires careful reading of the associated
text and is not an enterprise for the timid of heart. They also assume a Gaussian
form for the surface autocovariance function, which is equivalent to assuming
a Gaussian power spectrum. This has the disadvantage that the PSD cannot be
accurately found for the many other smooth-surface situations that occur. In fact,
we will see in the next chapter that fractal (power law), or “Lorentzian-like”
distributions, are far more common for many polished surfaces. For this reason,
Beckmann’s and Spizzichino’s result will not be discussed further here; however,
it will be resurrected in Section 7.4 for a discussion of rough surface scatter.
The various Kirchhoff approaches allow a great deal of ﬂexibility in dealing
with different situations and are capable of predicting diffraction from known
surfaces that are rougher than most optics. They cannot deal easily with exact
boundary conditions on real (ﬁnite conductivity) samples, and the small-angle
assumptions raise questions about performance at large angles of incidence.
The next section presents vector results obtained by variations on the Rayleigh
approach to diffraction theory.
3.3 The Rayleigh Approach
The Kirchhoff method, outlined in the preceding section, approximates the
boundary conditions present on the sample (in the aperture) and then applies some

Scatter Calculations and Diffraction Theory
61
variation of the Fresnel–Kirchhoff diffraction formula [Eq. (3.20) or (3.24), etc.]
to the resulting aperture ﬁeld to ﬁnd the ﬁeld in the observation plane. In contrast,
Rayleigh published a vector-perturbation technique in 1895 and 1907 that takes
just the opposite approach. The boundary condition is left (almost) intact, and
the ﬁeld is assumed to be composed of an inﬁnite summation of plane waves.
The solution, which takes the form of an inﬁnite series, converges quickly only
for very smooth surfaces. However, the results are applicable for most optical
surfaces and can be applied to samples with ﬁnite conductivity. Beckmann and
Spizzichino (1963, pp. 41, 99, 107) review the work of several authors who have
published variations on the technique in the radar literature (Rice 1951; Barrick
1970). Others followed Rayleigh’s approach in following years (Maradudin and
Mills 1975; Ishimaru 1978).
Church published a series of papers, based on the Rayleigh–Rice publications,
that speciﬁcally addressed scatter from optical surfaces and introduced the vector-
perturbation technique into the optics literature (Church and Zavada 1975; Church,
Jenkinson, and Zavada 1977,1979). In 1979, Elson and Bennett published a similar
perturbation approach to optical scattering theory in the optical literature that (after
considerable tinkering with the notation) proved to yield identical expressions. The
technique has become known as the Rayleigh–Rice vector perturbation theory,
or sometimes just the vector theory, and more recently as the ‘golden rule.’
Rice succeeded in expressing the mean-square value of the scattered plane wave
coefﬁcients as a function of the surface PSD function. This seems quite reasonable
in view of the results of the previous section. Although the theoretical derivation is
well beyond the scope of this book, the results have become an important scatter
analysis tool and are used throughout this text.
The Rayleigh–Rice vector perturbation theory relates the scattered power
density per unit incident power to the surface PSD function:
(dP/dΩs)dΩs
Pi
=
 16π2
λ4
!
cos θi cos2 θsQS (fx, fy)dΩs.
(3.43)
The quantity (dP/dΩs)dΩs/Pi is the power scattered in the s direction through
dΩs per unit incident power. You will notice, from Chapter 1, that except for
multiplication by the differential solid angle dΩs, this quantity is also the cosine-
corrected BSDF. Both sides of the equation are multiplied by the differential solid
angle dΩs = sin θsdφsdθs to facilitate a later integration. The quantity (16πy/λ4) is
sometimes referred to as the Rayleigh blue-sky factor because of its appearance
in his explanation of molecular scattering. The cosines amount to an obliquity
factor, similar to those found in the last section. The remaining quantities are
used to provide a description of the sample. The dimensionless quantity Q is the
reﬂectivity polarization factor. It expresses the action of sample material properties
on the reﬂected light. Q is a function of the sample complex dielectric constant
plus the angles of incidence and scatter, and takes on different forms depending on
incident and scattered polarization states. For many cases of interest, its numerical
value can be approximated by the sample reﬂectance. Exact relationships for Q

62
Chapter 3
and several approximations are discussed in Chapter 5. S (fx, fy) is the two-sided,
two-dimensional surface PSD function in terms of the sample spatial frequencies
fx and fy. As pointed out in Chapter 2, it has units of length to the fourth power. The
difference of (2π)2 between Eq. (3.43) and the corresponding equations published
in early papers (Church and Zavada 1975; Church, Jenkinson, and Zavada 1977,
1979) is due to the notation choice of expressing the PSD frequencies as spatial
cycles per unit length rather than spatial radians per unit length.
The interpretation of Eq. (3.43) is straightforward: normalized scatter in the s
direction (determined by θs and φs) is proportional to S (fx, fy), evaluated at
fx = sin θs cos φs −sin θi
λ
,
(3.44)
fy = sin θs sin φs
λ
,
(3.45)
which are obtained from the hemispherical grating equations. The restrictions
on Eq. (3.43) are those mentioned in Chapter 1. The sample must be a clean,
smooth, front-surface reﬂector. Cleanliness and skin depth are not of concern to
the theoretical nature of this chapter. The smoothness requirement restricts surface-
height deviations to be much less than a wavelength, and surface slope to be less
than one.
There is no ﬁrmly established smooth-surface limit; however, the Rayleigh
smooth-surface criterion, given as
 4πσ cos θi
λ
!2
= 1
2
 4πα cos θi
λ
!2
≪1,
(3.46)
is often used. Figure 3.5 illustrates the height restriction from the UV to the mid-IR
using “much less than” to mean 0.01. The amplitude limit in the visible is about 100
Å. This is more restrictive than the Kirchhoff results; however, it easily meets the
requirements of most mirrors. The limitation on slope is less of a problem than the
height restriction for sinusoidal surfaces. High-frequency nonsinusoidal surfaces
could exceed unity slopes, but this would be unusual for real surfaces. As a result,
the Rayleigh–Rice relationship gives excellent results at high-scatter angles.
If the surface is one dimensional (i.e., the PSD is constrained to variations in
only one frequency component), then Eq. (3.43) can be simpliﬁed a bit as indicated
in Eq. (2.42) (Church and Zavada 1975; Church, Jenkinson, and Zavada 1977,
1979). Consider z(x, y) = z(x), then S (fx, fy) = S (fx)δ( fy), and light is diffracted
only in directions for which φs = 0. Correspondingly from Eq. (3.45), fy = 0.
Then, integrating both sides over any ﬁnite increment of φs centered about zero
gives the one-dimensional analogue of Eq. (3.43). Q must also be evaluated at
φs = 0:
[dP/dθs]sdθs
Pi
= 16π2
λ3
cos θi cos2 θsQS (fx)dθs.
(3.47)

Scatter Calculations and Diffraction Theory
63
Figure 3.5
The line (ka)2 = 0.01 represents an arbitrary smooth-surface limit on grating
amplitude a versus wavelength. Different limits can be imposed for different types of
surfaces and different theoretical relationships.
Now, the light scattered into the plus-one order by a sinusoidal grating can be found
by substituting the appropriate expression for S (fx) and integrating over θs in the
neighborhood of the diffracted spot to obtain
S (fx) = a2
4 [δ( fx −fg) + δ(fx + fg)],
(3.48)
where z(x) = a sin(2π fgx + α).
Integration over the left-hand side of Eq. (3.47) about the θs direction gives the
grating efﬁciency. Integration over the right-hand side is trivial after a change of
variables from θs to fy. Assuming inﬁnite conductivity, as we did in Section 3.2,
and using the appropriate approximations for Q (to be given in Chapter 5), the
grating efﬁciencies are
P1/Pi = (ka)2 cos θi cos θs
for s-polarized light.
(3.49)
P1/Pi = (ka)2
"(1 −sin θi sin θs)2
cos θi cos θs
#
for p-polarized light.
(3.50)
For unpolarized light, the two results are averaged. These are similar, but not
identical to Eqs. (3.36) and (3.41), which were derived under the same assumptions
for the sinusoidal grating. Notice that under a small-scatter-angle assumption
(θs  θi), all three equations approach the common relationship:
Ps1/Pi = (ka cos θi)2.
(3.51)

64
Chapter 3
The implication is that we can expect good agreement between the various results
near the specular direction and some divergence at higher angles.
The very general nature of Eqs. (3.43) and (3.47), and their accuracy at high
angles, are their main advantages over the Kirchhoff approach of the last section.
Diffraction (scatter) can be found for any smooth reﬂective sample that can be
expressed as its power spectrum. And, conversely, if the BRDF of a clean, smooth
reﬂector is known, the sample PSD can be found. This two-way street provides
a fast, noncontact way to obtain surface statistics, as well as a way to calculate
scatter from a mirror with a known PSD. This will be the topic of Chapter 4. The
next section compares the various diffraction results obtained to measured data
from a sinusoidal grating.
3.4 Comparison of Scalar and Vector Results
Veriﬁcation of diffraction theory is always a bit difﬁcult because it is never
clear whether modest deviations from the predicted results are due to the
approximations in the theoretical model or to problems with producing a sample
with a known microscopic surface. Although reasonably good sinusoidal gratings
can be produced via holographic techniques, there is still a degree of uncertainty.
A technique can be used that allows a comparison of the various theoretical results
to measure data that is independent of grating amplitude, shape, and frequency
(Stover 1975; Schiff and Stover 1989). Notice in Eqs. (3.36), (3.41), (3.49), and
(3.50) that if the ﬁrst-order efﬁciency at θi is normalized to itself at a ﬁxed angle,
then the grating amplitudes cancel. The various normalized efﬁciencies can then
be plotted as a function θi and compared to measured efﬁciencies.
Figures 3.6 and 3.7 give the results of such a test. The gratings were sinusoidal
surfaces with a nominal value of a = 50, 500, and 5000 Å, and wavelengths of
6.7 µm (shown in Fig. 3.6) and 20 µm (shown in Fig. 3.7). The source light was
an s-polarized HeNe laser at a wavelength of 0.633 µm. Each ﬁgure gives plots of
the ﬁrst-order grating efﬁciency as a function of incident angle, normalized by the
grating efﬁciency at 5 deg.
The two solid curves are the results predicted by the Rayleigh–Rice approach
[Eq. (3.49)] and the Beckmann–Kirchhoff approach [Eq. (3.41)]. The discrete
points indicate actual measured data for the three grating amplitudes. The two
theoretical results are closer for the longer spatial-wavelength grating and for lower
incident angles. These results are expected because as the scatter angle approaches
the incident angle, the two obliquity factors become identical. The experimental ﬁt
for the 50-Å grating is actually quite good for the Rayleigh–Rice curves, regardless
of incident angle, scatter angle, or grating wavelength. The 500-Å amplitude
grating violates the smoothness requirement for the Rayleigh–Rice formalism,
and these experimental points are found closer to the Beckmann–Kirchhoff
model. The 5000-Å grating (available only at a spatial wavelength of 20 µm)
violates smoothness requirements for both gratings, and neither theory predicts
the wild variations in the experimental data. For gratings with shorter wavelengths
and lower amplitudes, the theoretical models diverge more rapidly, and the

Scatter Calculations and Diffraction Theory
65
Figure 3.6
Comparison of the diffraction theories with experimental data for a 6.67-µm
grating wavelength.
Figure 3.7
Comparison of diffraction theories with experimental data for a 20-µm grating
wavelength.
experimental data ﬁts very closely to the Rayleigh–Rice result (Stover 1975). If
the wavelength, or the angle of incidence, is increased, then the Rayleigh–Rice
theory applies for the rougher gratings as well (Schiff and Stover 1989).
3.5 Calculating Scatter from Optically Rough Surfaces
A surface is optically rough when second-order diffraction becomes an issue. The
limit is loosely deﬁned by Eq. (3.46), where it is obvious that increasing either
the incident angle or the wavelength (or both) increases the roughness that can
be measured as optically smooth. A good rule of thumb for scatter at visible

66
Chapter 3
wavelengths is if you can see your face in the sample, it is optically smooth. The
question then becomes—what can be done beyond the smooth-surface limit?
Calculating scatter from optically rough surfaces is considerably more
complicated than the techniques reviewed in the preceding sections. All of the
smooth-surface relationships [including the sinusoidal relationship Eqs. (1.4) and
(1.5)] in Chapter 1 depend on the one-to-one relationship between the surface PSD
and the BRDF. That is, each sinusoidal component making up the surface PSD
contributes only ﬁrst-order diffraction to the BRDF. If sinusoidal components are
strong enough (i.e., rough enough) to have measurable second-order diffraction,
then this will mix with ﬁrst-order diffraction from the next-higher harmonic
(at twice the surface frequency), and the roughness–scatter relationship at that
frequency is lost. Another way of looking at this is that for optically rough
surfaces, several different PSDs can give the same BRDF. Thus, at least for single-
wavelength measurements, it is impossible to ﬁnd the PSD from the measured
BRDF.
Finding the BRDF from the PSD still seems possible, and attempts have been
made. Rough-surface scatter is of interest in the photovoltaic solar industry, where
surface texture is used to reduce reﬂection and thus increase absorption, and in a
variety of short-wavelength applications, such as ultraviolet lithography and x-ray
detection.
3.5.1 The Beckmann rough-surface result
Beckmann derived (Kirchhof-based) relationships for scatter from isotropic
randomly rough surfaces with a normal (Gaussian) height distribution (Beckmann
and Spizzichino 1963, p. 88) and a Gaussian autocorrelation function. As all
Juniors in engineering know (and as many of the rest of us have forgotten), the
Fourier transform of a Gaussian is a Gaussian. Thus, the PSD associated with
Beckmann’s model is a Gaussian expression containing the correlation length and
the rms roughness:
S 2(f) = πσ2ℓ2
c exp −(πfℓc)2.
(3.52)
Beckmann and Spizzichino break their result into six cases to cover smooth-,
general-, and rough-surface calculations for both one- and two-dimensional
surfaces. The general solution contains an inﬁnite series that can be evaluated
for both smooth and rough cases. Beckmann’s two-dimensional rough-surface
equation is rewritten here (and does not appear anywhere in his text) in terms of
BRDF:
BRDF = πR(θi)F2
3(L/λ)2 exp −(πf L)2,
(3.53)

Scatter Calculations and Diffraction Theory
67
where
F3 = 1 + cos θi cos θs −sin θi sin θs cos φs
cos θi(cos θi + cos θs)
,
f = 1
λ
h
(sin θs cos φs −sin θi)2 + (sin θs sin φs)2i1/2 ,
L =
ℓcλ
[2πσ(cos θi + cos θs)].
The parameter F3 is Beckmann’s obliquity factor, f is the spatial frequency for any
grating orientation, and L is a characteristic length.
Notice that in the expression for the BRDF, the rms roughness and the
autocorrelation length always appear in the ratio
√
2σ/ℓc and become a single
variable, the rms proﬁle slope. Because they cannot be individually evaluated from
Eq. (3.52), the surface PSD cannot be found by scatter measurement. If the two
variables σ and ℓc could be individually evaluated with a scatter measurement, then
Eq. (3.51) could be used to ﬁnd the rough-surface PSD. The inability to separate
these two variables is in complete agreement with the arm-waving conclusion of
the last section. The measured BRDF of rough surfaces cannot be used to calculate
the corresponding PSD. Notice also that the wavelength cancels out of Eq. (3.52)
after F3, f, and L are substituted. This implies that with surface features now
larger than a wavelength, the result has moved from diffractive (or physical optics)
to geometric optics, which is based on specular reﬂection from inclined facets.
Similar results are true for Beckmann’s one-dimensional rough-surface case.
Two ﬁnal points: ﬁrst, Beckmann derived his results for the case of the Gaussian
height distribution and the Gaussian PSD. It can be shown that Eq. (3.52) applies
to any surface with a Gaussian height distribution and a ﬁnite rms slope (but not
necessarily a Gaussian PSD). The second point relates to another conclusion of the
last section. Equation (3.52) demonstrates that many different values of roughness
and autocorrelation length, all resulting in the same ratio, will produce the same
BRDF. But these changes correspond to different PSDs, as shown by Eq. (3.51).
Thus, many different (rough-surface) PSDs may be formulated that will produce
the same BRDF.
Other assumptions regarding the form of the PSD, and/or the autocorrelation
function, result in different theoretical relationships. In those cases, the rms
roughness and the autocorrelation length ratio differently to form some other
inseparable combination, and the same reasoning applies relative to BRDF–PSD
calculations. Fractal surfaces and surfaces with exponential autocorrelation
functions do not have a ﬁnite rms slope (over inﬁnite bandwidth), but still exhibit
a one-to-one BRDF–PSD relationship in the smooth-surface limit (Church 1988;
Church, Asmail, and Parks 1994).
3.5.2 Other rough-surface calculations
As this book nears publication, at least two other approaches are being made to
ﬁnd the BRDF of optically rough surfaces from the surface statistics.

68
Chapter 3
Recently Harvey et al. (1999 and 2000) and Krywonos, Harvey, and Choi
(2006) have published several papers reviewing a scalar calculation dubbed “The
Generalized Harvey Shack Model” that report quite good results at most scatter
angles for several samples. In addition to the source wavelength and incident
angle, the inputs are the surface PSD, the Fresnel reﬂection, and the rms roughness
integrated over a large bandwidth. Unfortunately, in its current conﬁguration, it
does not reduce to the Rayleigh–Rice result when used with a smooth-surface
PSD–wavelength combination. The obliquity factor used, which seems necessary
for modest scattering angle accuracy, never drops to zero as the scattering angle
approaches 90 deg. Accuracy of the technique may also depend on how close the
surface comes to having a Gaussian height distribution.
A vector approach based on the mean-ﬁeld theory (MFT) has been published by
Lopushenko (2000). MFT is based on treating near-surface roughness as variations
in material index. In other words, the near-surface volume is composed of the
substrate material and air. The spatial frequency contributions to the surface PSD
now become frequency variations in material index, which eases the mathematical
solution. A perfectly ﬂat surface with index changes in the substrate will, in fact,
scatter light.
At the time of publication of this book, both the Harvey and Loposhenko
approaches are works in progress. They are not publicly available and have not
been “proven” using a wide range of samples. One of the issues in conﬁrming
or refuting new models is in obtaining accurate surface statistics. Section 7.16
discusses some of the issues involved with obtaining accurate two-dimensional
surface PSDs.
3.6 Summary
The basics of diffraction theory, as it applies to the problems of light scatter,
have been presented for both the Kirchhoff and the Rayleigh–Rice formulations.
Experiment tells us that the perturbation approach is more accurate for smooth
optical surfaces, especially at high-scatter angles. This approach also has an
analytical edge in terms of the versatility with which real ﬁnite conductivity
samples are described. On the other hand, the mathematical derivation of the
Kirchhoff approach is easier and more accurate for rougher surfaces. This suggests
that the perturbation approach is the logical one to use for analyzing scatter
data from optical reﬂectors and for inspection of many semiconductor industry
components (wafers, computer disks, etc.) The Kirchhoff approach can be reserved
for the rougher surfaces found in more-general manufacturing applications. In fact,
that is just how they will be used in the following chapters. Chapter 4 combines
the vector perturbation equations with the surface analysis of Chapter 2 to allow
calculation of surface statistics from the measured BRDF. For rougher surfaces, it
becomes impossible to ﬁnd surface statistics from the measured scatter. The reverse
is not true, and Section 8.2 explores some of the issues related to the calculation of
scatter from optically rough surfaces.

Chapter 4
Using Rayleigh–Rice to
Calculate Smooth-Surface
Statistics from the BRDF
“Statistics are no substitute for judgment.” – Henry Clay
Chapters 2 and 3 have revealed the surface PSD function as the logical path
to move back and forth between surface topography and scatter generated
by roughness. This chapter concentrates on application of the Rayleigh–Rice
relationship to the inverse-scatter problem: the calculation of reﬂector surface
statistics from measured scatter data. This is important because a number of
industrial surfaces meet the smooth, clean, front-surface-reﬂective requirements
introduced in Chapter 1, and in these cases, scatter measurement can be used as
a fast, noncontact method of microroughness characterization. The special cases
of one-dimensional grating-like surfaces and isotropic two-dimensional surfaces
receive most of the attention. The conversion of the Rayleigh–Rice diffraction
result to the Davies–Bennett TIS relationship is also reviewed. Other than the
scatter measurement geometry, the details of how the scatter data is obtained is
left for Chapter 7. Chapters 1–3 are used as source material.
4.1 Practical Application of the Rayleigh–Rice Perturbation
Theory
The use of scatter data as a means of specifying reﬂector surface quality is a
powerful noncontact inspection technique. This chapter discusses the inverse-
scatter problem, where BRDF data is used to calculate the PSD and the various
surface parameters. Eq. (3.43), introduced in Section 3.3, gives the general
relationship between the PSD of an arbitrary, smooth, clean, front-surface reﬂector
and the corresponding scatter pattern, or BRDF. In Eq. (4.1), the terms have been
rearranged so that the BRDF is given directly in terms of measurement and sample
parameters:
BRDF = dP/dΩ
Pi cos θs
= 16π2
λ4
cos θi cos θsQS (fx, fy).
(4.1)
69

70
Chapter 4
Several points about this key result are worth mentioning. First, note that except
for the factor cos θsQ, the BRDF and the surface PSD are directly proportional.
Although in general Q can change dramatically over the observation hemisphere
in front of the sample, it will be learned in Chapter 6 that for the special case of
an s-polarized source and plane-of-incidence measurements (φs = 0 or 180 deg),
Q is given exactly by the geometric mean of the sample specular reﬂectances at θi
and θs:
Qss = [Rs(θi)Rs(θs)]1/2.
(4.2)
For highly reﬂective surfaces, this means that Qss is nearly equal to any measured
specular reﬂectance. Even for the more-difﬁcult cases (Qsp, Qps, out-of-plane,
etc.), Q can be evaluated exactly (with effort) by using relationships presented in
Chapter 6 and the value of the complex dielectric constant. Polarization effects will
be discussed further in Chapter 8 and exploited in Chapter 9 to detect contaminants
and subsurface defects. The important point here is that evaluation of a bandwidth-
limited section of the PSD takes place directly from the angle-limited section of
the BRDF, without any of the integration-limit problems discussed in Chapter 2.
Sections of the calculated PSD can then be used to evaluate bandwidth-limited
values for the rms roughness, the rms slope, and the average surface wavelength,
or component-roughness speciﬁcations can be written directly in terms of the PSD
itself. Errors that arise are associated with the measurement process and the degree
to which the surface meets the smooth, clean, front-surface requirements and not
with mathematical difﬁculties associated with data analysis. By the same token
(as pointed out in Chapter 2), it does not make sense to attempt conversion of the
calculated PSD (via a Fourier transform) to the autocovariance function because
the inherent bandwidth limits prevent integration over the required range of zero to
inﬁnity and because the same sample information is available in both functions.
Second, notice that Eq. (4.1) implies near symmetry for the BRDF. This is
because the PSD is, by deﬁnition, symmetrical [see Eq. (2.29)]. For θi = 0,
the BRDF of Eq. (4.1) is exactly symmetrical. For θi > 0, the BRDF, plotted
against (θs −θi) will be skewed slightly to one side relative to the specular
reﬂection. If the BRDF is plotted against the difference of the sines of the angles
(sin θs −sin θi = β −β0), the symmetry is nearly exact again. This comes about
because (β −β0) is directly proportional to the spatial frequency, as shown in the
grating equation. It is not quite symmetrical because of the quantity (cos θsQ).
This property has been explained from several viewpoints. Church, Jenkinson,
and Zavada (1977, 1979) point out that it is the result of conservation of linear
momentum. Harvey (1976, 1989) took a linear systems approach and termed it
linear shift invariance, but this is just an approximation because, as pointed out
above, the (cos θsQ) term forces asymmetry when θi is not zero. For situations
where the surface is not optically smooth, the PSD will still be symmetrical but,
assuming that the BRDF plotted against (β −β0) is also symmetrical, pushes the
user even further out on the limb of approximation. This is worth keeping in mind,
as a number of stray radiation codes treat this BRDF symmetry as established fact.

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
71
A useful consequence of this property is that Eq. (4.1) can be used to scale the
BRDF in incident angle. That is, BRDF data taken at one angle of incidence can
be used to predict the sample BRDF at other angles of incidence. Fig. 4.1(a) shows
an asymmetrical BRDF (θi = 30 deg) ﬁrst plotted against (θs −θi), and then folded
over (to show the symmetry) and plotted against (β −β0) in Fig. 4.1(b).
Figure 4.1
(a) The BRDF is clearly asymmetrical when plotted against (θs −θi). The
asymmetry increases as θi increases. (b) The data of Eq. (4.1)(a) exhibits near-symmetry
when plotted against (β−β0). The slight deviation from symmetry is due to the factor cos θsQ
in Eq. (4.1).

72
Chapter 4
Third, notice that Eq. (4.1) implies that scatter measurements taken at one
wavelength can be used to predict scatter measurements at other wavelengths. In
effect, this is done by calculating the PSD, and then using the same relationship
(after updating Q) to ﬁnd the BRDF at the new wavelength. The same scaling
technique can be used for changes in source polarization as well. These issues will
be further discussed in Chapter 8.
It is important to realize that these techniques (calculation of the PSD and
scaling by the source parameters) are all properties of the same simple equation,
which depends on surface topography as the only source of sample scatter. If the
surface is truly smooth, clean, and front-surface reﬂective, then all three features
can be used. Conversely, if one property cannot be relied on, then none of them
can! If the sample does not “wavelength scale” for example, then the BRDF cannot
be trusted to give correct surface statistics. This can be checked by measuring the
BRDF at two wavelengths from the same sample and then checking to see if the
same PSD is found.
Of the three, the symmetry property is the easiest to check because its
veriﬁcation does not require measurement at a second wavelength or a surface-
proﬁle measurement (and the associated conversion to the two-dimensional PSD).
The fact that symmetry is present does not absolutely mean that surface statistics
can be correctly calculated. Some transmissive samples, volume reﬂectors (i.e.,
dielectric mirrors), rough surfaces, and contaminated surfaces exhibit angle
symmetry even though they are obviously not smooth, clean, and front-surface
reﬂective. The implication is that some forms of nontopographic scatter also obey
the grating equation (momentum conservation) even though their intensities cannot
be predicted by Eq. (4.1). Finding the scaling laws for other scatter sources besides
smooth, clean, front-surface reﬂectors will dramatically increase the use of scatter
measurement as an analytical tool for materials research.
The two-dimensional power spectrum S (fx, fy) is a surface above the fx, fy
plane that can take on only symmetrical shapes. This still leaves a lot of possible
variation, as shown in Fig. 4.2. All four PSDs pictured in Fig. 4.2 have a volcano
appearance that peaks at low spatial frequencies (as is the case for virtually all
smooth-surface reﬂectors). The upper rim of each volcano represents the PSD at
the low-frequency limit to which each function was evaluated. A similar limit exists
at fmax. These pictures are similar to the scatter pattern representations shown in
Fig. 1.3. In Fig. 4.2(a) the PSD is symmetrical in f but does not exhibit circular
symmetry. The surface in Fig. 4.2(b) is isotropic in that only one sweep from
fmin to fmax is necessary to characterize the entire surface because of the circular
symmetry. In terms of z(x, y), this implies that straight-line proﬁles of the surface
taken in any direction from any starting point will result in the same surface
statistics if care is taken to compare over the same spatial frequency bandwidths. It
does not require that z(x, y) have circular symmetry and, as shown, does not restrict
circular structure on the PSD. The PSD of Fig. 4.2(c) is of a one-dimensional
surface. The last PSD in Fig. 4.2, the combination of a smooth one-dimensional
surface with an isotropic surface, is similar to a precision-machined surface.

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
73
Figure 4.2
PSDs of various surfaces.
Most scatterometers take data in the incident plane in a scan that starts near,
or progresses through, the specular beam, and then continues out to θs = 90 deg.
It is rare for the full-scatter hemisphere in front of the sample to be completely
measured, even if the instrumentation is available to do so. If the sample is
nonisotropic, then rotating it about the surface normal will change the BRDF in the
incident plane. Because the incident plane always includes the specular reﬂection,
these measurements always approach the S (0, 0) axis. A number of incident plane
scans can be taken at different sample orientations to deduce the complete three-
dimensional form of the PSD. Examples are shown in Fig. 4.2. The objective is to
pick the minimum number of slices (or measurements) that allow characterization
of the sample. Thus, a large number of slices would be required for Fig. 4.2(a).
Any slice will work for Fig. 4.2(b); there is only one choice for Fig. 4.2(c), and
two slices can be used to characterize Fig. 4.2(d).
Many other combinations are possible. One interesting combination is the
typical silicon wafer. As will be seen in Section 11.1, clean-polished silicon scatters
almost exclusively from surface topography from the near IR to the UV, making
scatter measurement an ideal choice as a roughness-characterization technique.
Most wafers also appear to be very isotropic when measured via scatterometry.

74
Chapter 4
However, when these same wafers are proﬁled at higher spatial frequencies—via an
atomic force microscope—they often exhibit a periodic structure caused by a slight
angle (on the order of from 0.01 to 0.1 deg) between the wafer plane and the crystal
structure. The result is a stair-step, or terraced, surface if the angle is aligned with
a crystal axis, and more of a herringbone pattern if not. The spatial frequency of
these structures is often larger than can be resolved by scatter measurement, unless
the wafer–crystal angle is very small. This effect would modify the isotropic PSD
in Fig. 4.2(b) with the addition of two high-frequency peaks located on opposite
sides (180-deg apart) of the main low-frequency contribution. Because the high-
frequency peaks are isolated, they will only be seen if the correct scan-angle choice
is made. The isotropic solution presented in this chapter can be used in the lower-
frequency section of the PSD, but the two-sweep approach [as for Fig. 4.2(d)]
would be required at higher frequencies.
Another interesting surface is the textured computer disk. In many of these
products, roughness (texture) is intentionally added to the disk surface so that the
parked head will not ring (stick) to the disk. Texture is often created by linear belts
that “polish” the rotating disk while it is translated linearly through the system.
The result is a surface with two (unaligned) one-dimensional components on an
isotropic background.
Whatever the shape of the PSD, once it is known, it can be manipulated
according to the techniques of Chapter 2 to obtain the various roughness
parameters. For example, the bandwidth-limited mean-square roughness is the
volume under the bandwidth-limited PSDs shown in Fig. 4.2 (i.e., the zeroth
moment), the rms slope is the second moment, and so on. The next three sections
discuss conversion of the scatter data to the PSD and roughness parameters.
4.2 Roughness Statistics of Isotropic Surfaces
Many polished and coated surfaces have PSDs that are nearly isotropic and can
be characterized with a single sweep through the scatter hemisphere in front
of the sample. The easiest choice is usually the plane-of-incidence slice, which
corresponds to the S (fx, 0) plane. The corresponding PSD can be found by
rearranging Eq. (4.1):
S ( fx, fy) =
λ4(BRDF)
16π2 cos θi cos θsQÅ
2µ2.
(4.3)
If a factor of 108 is added in Eq. (4.3) to the numerator of the right-hand side, it
gives the PSD units of (Å µm)2 when the wavelength is in micrometers. This is
the choice for most of the PSD ﬁgures in this text (see Fig. 4.5 for example). This
allows the PSD to be plotted over a frequency plane measured in units of inverse
micrometers so that integrals of the PSD have units of angstroms squared. Other
systems of units are common. If micrometers or nanometers are used for all length
dimensions, then the multiplication factor is a convenient 1.0. See Appendix D for
further discussion.

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
75
Evaluation of Eq. (4.3) is straightforward except for the factor Q. As discussed
above, analysis is simpliﬁed by making use of one of the approximations given
in Chapter 5. The easiest course—to simply substitute the specular reﬂectance for
Q—is an excellent approximation when s-polarization is used and the material has
a high reﬂectance.
To avoid the complications of a three-dimensional plot, the calculated slice
through S (fx, fy) can be plotted directly, or an effective value of the PSD cone
S iso can be obtained by integrating the slice around 360 deg, as shown in Fig. 4.3.
The integration is trivial because S (fx, fy) is constant for constant f:
S iso(f) =
Z 2π
0
S (fx, fy)fdβ = 2πfS (fx, fy).
(4.4)
S iso( f) has units of length cubed. The value of f 2 at any point on the plot is the
quadrature sum of the fx and fy components. The bandwidth-limited rms roughness
σ can be found by taking the square root of the integral over f, as indicated in
Fig. 4.4. In most practical cases, this will be evaluated as a sum of discrete values,
where the distance between data points is given as ∆fi. Then,
σ =
"Z fmax
fmin
S iso(f) d f
#1/2
,
(4.5)
and
ˆσ =

I−1
X
i=0
S iso(fi)∆fi

1/2
=

I−1
X
i=0
2πfiS (fi)∆fi

1/2
,
(4.6)
Figure 4.3
Integration of a section of an isotropic PSD to obtain the effective value, S iso( f).

76
Chapter 4
Figure 4.4
Integration of S iso(f) gives the mean-square roughness.
where
∆fi = fi −fi−1 = cos θsi
λ
∆θsi.
(4.7)
These equations are slightly different from the estimators used in Chapter 2 to
evaluate roughness from proﬁle data. S iso(f) should not be confused with S 1( fx),
which is found from the one-dimensional PSD calculated from a linear proﬁle z(x)
taken on a two-dimensional surface. S iso(f) and S 1(fx) are numerically different.
Another difference from the Chapter 2 estimators results because here it has been
assumed that BRDF data is taken at equal increments in angle, which are not
equal frequency increments in the PSD. Using the philosophy of Chapter 2, similar
relationships are obtained for the rms proﬁle slope m and the average surface
wavelength:
m =
"1
2
Z fmax
fmin
(2π f)2S iso(f) d f
#1/2
.
(4.8)
The factor 1
2 results from integration of the two-dimensional power spectrum:
ˆm =

1
2
I−1
X
i=0
(2πf 2
i )S iso(fi)∆fi

1/2
=

(2π)2
2
I−1
X
i=0
f 3
i S i(fi, 0)∆fi

1/2
.
(4.9)
ℓ= 2πσ/m.
(4.10)
Figure 4.5 shows a PSD plot of the molybdenum mirror of Fig. 4.1 on a
log–linear scale. The integration to obtain the rms roughness is given on the linear
scale to the right. Figure 4.6 shows a plot of the average surface wavelength, given
in Eq. (4.10), for the same sample. In Chapter 6, this sample will be shown to
exhibit scaling in both wavelength and angle of incidence.
The PSDs in Figs. 4.5 and 4.6 have a high-frequency (high-scatter angle)
spike that is a common feature when ﬁnding the PSD from the BRDF via the
Rayleigh–Rice perturbation theory. It can quickly be established that the spike is

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
77
Figure 4.5
The PSD of the molybdenum mirror can be used to ﬁnd the rms roughness
(right-hand scale). The value of the computed roughness depends on the bandwidth of
integration.
not real by simply changing the measurement incident angle and/or wavelength,
which changes the spatial bandwidth of the calculation. The PSD spike will move
to the new high-frequency end of the spectrum. So, what causes the spike? There
are some measurement situations that will create a spike as the detector aperture
drops behind the sample plane, but the effect is often observed starting tens of
degrees before that region. It is the log scale that makes it appear as a spike. It
was suggested (Harvey, Krywonos, and Stover 2007) that the problem was in the
Rayleigh–Rice obliquity factor, which drops to zero in the denominator of the PSD
calculation as the sample plane is approached by the measuring detector. This was
put to rest by applying the sinusoidal version of Rayleigh–Rice [Eq. (1.4)] and
checking it by both measurement (Stover 2010) and calculation (Schröder 2011).
In Stover’s paper, the ﬁrst-order diffraction was moved ever closer to θs = 90 deg
by increasing the incident angle. At each location, the diffracted ﬁrst-order power
was measured. It matched the Rayleigh calculation within experimental error,
and no spike was observed. Schröder employed an exact numerical calculation
available for sinusoids and also veriﬁed the Rayleigh result. The real cause of the
spike is that at high-scatter angles, the topographic scatter drops off faster than
scatter from other sources, such as particulates and surface ﬁlms. The BRDF is no
longer dominated by topographic scatter, as is calculated by Rayleigh–Rice. The
problem is not with Rayleigh–Rice, but with failing to meet the optically clean,
front-surface-reﬂective requirements for the relationship.
4.3 Roughness Statistics of One-Dimensional Surfaces
The geometrical conﬁguration for the plot in Fig. 4.6 is illustrated in Fig. 4.7. The
illuminating source is located in the x, y plane at angle θi from the surface normal

78
Chapter 4
Figure 4.6
The data of Fig. 4.5 is used to calculate average surface wavelength (right-
hand scale).
with the grating lines perpendicular to the incident plane. Scatter is conﬁned
to the incident x, y plane. In Section 3.3, the one-dimensional version of the
Rayleigh–Rice relationship [Eq. (3.47)] is found by setting the two-dimensional
power spectrum to its one-dimensional equivalent [S (fx, fy) = S (fx)δ( fy)] and
integrating out the dependence on fy and φs. It is appropriate to use this expression
only for surfaces that are one dimensional (grating-like). In Eq. (4.11), the terms are
rearranged to solve for the one-dimensional PSD in terms of the one-dimensional
BRDF (given in the brackets). The one-dimensional PSD has units of length cubed
(roughness power per unit roughness frequency). As before, a factor of 108 needs
to be introduced to make the units angstroms squared per unit inverse micrometer,
as used in Fig. 4.9:
S 1(fx) =
" dP/dθs
Pi cos θs
#
λ3
16π2Q cos θi cos θs
Å
2µm.
(4.11)
The comments of the preceding section on the value of Q and the choice of
polarization apply again here.
Figure 4.8 shows the BRDF for a precision-machined mirror plotted as a
function of degrees from the reﬂected specular beam. The sample was illuminated
with a HeNe laser of wavelength 0.6328 µm at an angle of incidence of 5 deg. A
number of diffraction peaks are apparent. This data is converted via Eq. (4.11) to
the PSD displayed in Fig. 4.9. The two plots are very similar in shape. Only the
positive frequency (and positive angle) sides of the plots are shown. If both sides
were plotted, then the PSD would be symmetrical in frequency and the BRDF
slightly asymmetrical, as predicted by the grating equation (see Section 1.2) and
the reasoning of Section 4.1.

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
79
Figure 4.7
Geometry for BRDF measurement of one-dimensional surfaces.
Figure 4.8
BRDF of the precision-machined mirror.
Notice in Fig. 4.9 that the prominent peaks at frequencies of 0.45, 0.9, and 1.35
inverse microns are harmonically related. These diffraction peaks (labeled F, 2F,
3F in the ﬁgure) are caused by the periodic tool marks left on the surface (see
Section 2.1) by the machining process. The tool is advanced by the inverse of
the fundamental frequency (2.22 µm) for each revolution of the part on the lathe
spindle. The tool mark cross section is not a true cusp shape because these peaks do
not fall off as (1/n)4 per the reasoning of Section 2.1. Instead, there is apparently
more high-frequency roughness present in the cross section. This effect has been
analyzed in the literature (Stover 1976b) and can be viewed interferometrically.
The tip of each cusp has a small burr on its top that extends into the region that
was occupied by the tool during its pass (see Fig. 4.10). The burr is folded over

80
Chapter 4
Figure 4.9
PSD of the precision-machined surface of Fig. 4.8.
Figure 4.10
Passage of a circular tip tool (radius R) through the material with a feed
distance d. Very smooth surfaces can be machined if the depth of cut is kept small.
along the tool edge during its pass. After the tool is gone, the hotter side of the burr
(the tool side) cools and contracts, and the burr rises, forming a long furrow on the
surface (Burnham 1976). This effect and others, which are dependent on material
constants and machining parameters (feed rate, rake angle, tool radius, etc.), all
affect the BRDF and can be monitored with light-scatter measurements.
In Fig. 4.8, several satellite peaks are grouped in pairs around the ﬁrst, second-,
and third-order peaks. Two explanations can be given for the presence of
diffraction peaks at these locations. The ﬁrst explanation attributes their presence
to the interaction (or mixing) between diffracted components [see Appendix B,
Eq. (B.19)]. It essentially reveals that when two parallel sinusoidal components
are present on a surface, there will be diffraction in directions that correspond

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
81
to the sum-and-difference frequencies of the two surface waves. In this case,
as described above, the prominent tool marks are not sinusoidal, so there
are several harmonically related surface waves. When the harmonics of one
fundamental mix with each other, the resulting sum-and-difference frequencies
are still multiples of the fundamental, so no new frequencies are expected. A
direct analog of this behavior will be familiar to electrical engineers with a
background in communications theory. Careful study of Fig. 4.9 reveals that a
second harmonically related series (labeled f, 2f, and 3f) starts at 0.33 inverse
microns. When this series of surface waves mixes with the series starting at 0.45
inverse microns, a variety of new peaks at various sum-and-difference frequencies
are created in the diffraction pattern. All of the major peaks in Fig. 4.9 can
be identiﬁed as a combination of these two series, as indicated. Therefore, this
explanation does predict the correct location of these peaks.
Eq. (B.19) also predicts the relative intensities of the various peaks. Using
the notation of this equation, each peak intensity is given by J2
n(∆F)J2
m(∆f). The
two Bessel series in n and m share the same zeroth order [that is: J2
0(∆F) =
J2
0(∆f)]. Setting the cosines in the obliquity factor and the Bessel function
arguments equal to unity (i.e., assuming small-angle scatter) gives the ﬁrst-order
diffracted intensities at 0.33 and 0.45 inverse-micron values of J2
0(∆F)J2
1(∆f) and
J2
0(∆f)J2
1(∆F), respectively. The sum-and-difference peaks (labeled F−f and F+ f)
have calculated intensities given by J2
1(∆f)J2
1(∆F). Approximate values for J2
1(∆F)
and J2
1(∆f) can be found to be 3 × 10−3 and 5 × 10−4 using Fig. 4.8, which includes
the BRDF at zero. The sum-and-difference intensities (at F+ f and F−f) should be
lower than those at F and f by these Bessel function multipliers if the calculation
of Appendix B is to be used to explain their existence. Examination of Fig. 4.8
quickly conﬁrms that this is not the case. The sum-and-difference terms are larger
than expected by about three orders of magnitude. The difference is too large to
be caused by our cavalier treatment of the cosines. Hence, only a small fraction of
these satellite peaks is due to the nonlinear mixing of Appendix B.
The second possible source of these peaks in the diffraction pattern is their
actual appearance as sinusoidal components on the surface. This means that the
machine tool is somehow producing them. In effect, the nonlinear mixing between
the vibration f and the feed F takes place in the machine tool, and the resulting
motion of the tool on the part faithfully reproduces these components. There
was apparently a machine vibration present, causing relative motion between the
part and the tool that created the 0.33-inverse-micron fundamental. Its temporal
frequency, in hertz, can be found from the spindle speed used when cutting the
part. This can be used as a clue to ﬁnding the vibration source and eliminating
it. This particular BRDF scan is an indication that the machine tool itself has a
serious problem. The scan represents a source of useful production feedback that
goes beyond roughness characterization of the surface.

82
Chapter 4
The rms roughness, slope, and average wavelength are again found by the
integration techniques of Chapter 2:
σ =
"
2
Z fmax
fmin
S (fx) d f
#1/2
.
(4.12)
ˆσ =
2
I−1
X
i=0
S (fi)∆fi

1/2
.
(4.13)
m =
"
2
Z fmax
fmin
(2π fx)2S (fx) d f
#1/2
.
(4.14)
ˆm =
2
I=1
X
i=0
(2π fi)2S (fi)∆fi

1/2
.
(4.15)
ℓ= 2πσ/m.
(4.16)
In Fig. 4.11, the surface rms roughness of the same part is shown superimposed
on the PSD. The integral starts on the left near f = 0 and progresses toward
the roughness scale on the right-hand side of the plot. The abrupt contributions
of the various diffraction peaks and the bandwidth-limited nature of the rms
roughness are evident. The peak amplitudes of individual sinusoidal components
can be evaluated from the corresponding rms contributions. For example, the
fundamental at 0.45 inverse microns increases the rms integral from 12.5 to 22.5 Å.
Remembering that these contributions add linearly to the mean-square roughness
gives
σ(0.45) = (22.52 −12.52)1/2 = 18.7 Å,
(4.17)
which converts to a peak sinusoidal amplitude of 26.5 Å. The average surface
wavelength, shown in Fig. 4.12, is also strongly affected by the presence of the
prominent periodic components.
Of course, the precision-machined surface illustrated above is not truly one
dimensional. All real surfaces scatter some light throughout the full-scatter
hemisphere, implying that there are roughness components that do not run parallel
to the tool marks. These components are analyzed by rotating the sample 90 deg
about its surface normal and taking a BRDF scan perpendicular to the plane of the
prominent diffraction peaks. This data is analyzed using the isotropic assumption
of the last section. The resulting PSD is shown in Fig. 4.13 with the corresponding
integration for the rms roughness. As expected, most of the surface roughness was
associated with the one-dimensional components. In order to obtain the total rms
roughness, the values must be added in quadrature:
σtotal = (σ2
1D + σ2
iso)1/2 = (302 + 42)1/2 = 30.2 Å.
(4.18)

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
83
Figure 4.11
Integration to obtain the rms roughness. The discrete jumps in the integral can
be used to determine the amplitude of individual Fourier components making up the periodic
surface structure. This insight is not possible when analyzing with the autocovariance
function.
Figure 4.12
Integration to obtain the average surface wavelength.

84
Chapter 4
Figure 4.13
The isotropic PSD of the precision-machined mirror of Figs. 4.8, 4.9, and 4.11.
It is important to make certain before they are added that the two values of σ
correspond to the same band of spatial frequencies.
4.4 Roughness Statistics for the General Case
Occasionally, sample scatter needs to be measured over the full observation
hemisphere in front of the sample. The BRDF at any point can be used to ﬁnd
the corresponding values of the PSD via Eq. (4.3), and the surface statistics can
again be found by using the results of Chapter 2:
σ =
"Z fmax
fmin
Z fmax
fmin
S (fx, fy) d fx d fy
#1/2
.
(4.19)
d fxd fy = cos θsdΩs
λ2
= cos θs sin θs dφs dθs
λ2
.
(4.20)
ˆσ =

N
X
n=1
M
X
m=1
S ( fx, fy)(∆fxn∆fym)

1/2
.
(4.21)
∆fxn∆fym = cos θsn sin θsm∆φsm∆θsn
λ2
.
(4.22)
In practice, the situation is not always this simple because the scatterometer
receiver may be swept over the hemisphere using rotations about axes other
than the θs and φs axes (see Fig. 7.14). In this case, an instrument-speciﬁc
transformation must be added to the above equations to convert from the instrument
coordinate system to the analysis coordinate system.

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
85
4.5 The ABC or K-Correlation Surface Power Spectrum Models
Many surface power spectra have shapes that are close ﬁts to algebraic forms
related to low-pass ﬁlters. As an example, notice that the PSD for the molybdenum
mirror of Fig. 4.5 is close to a straight line on a log–log plot. The ABC, or
K-correlation, model is commonly used for this purpose (Church, Takacs, and
Leonard 1989) and can be expressed for both one- and two-dimensional proﬁles
in terms of the parameters A, B, and C:
S 1( fx) =
A
2[1 + (Bfx)2](C/2) ,
(4.23)
S 2(f) =
A′
2[1 + (Bf)2](C+1)/2 ,
(4.24)
where
A′ = Γ[(C + 1)/2]
2 √πΓ(C/2) AB.
(4.25)
The factor of 2 difference between Eq. (4.23)—and the corresponding relationship
in Church’s paper—exists because this text uses the double-sided deﬁnition of
the PSD. The 2 will reappear during integration to obtain the rms roughness [see
Eq. (4.12)].
Church shows that an ABC version of C(t) can be found using Eq. (2.55) as
C(τ)ABC =
√
2π2A
B
2−C/2
Γ(C/2)
 
2π|τ|
B
!(C−1)/2
·
K(c−1)/2
 
2π|τ|
B
!
,
C > 0, (4.26)
where Kn is a modiﬁed Bessel function and leads to also calling the ABC model a
“K-correlation” model.
In these equations, the value of A is determined by low-frequency behavior (i.e.,
small Bf). The parameter B is related to the correlation length. For the special
case C = 2, B equals 2πℓc, where ℓc is the e−1 deﬁnition of the correlation
length. In effect, B determines the frequency location of the breakpoint in the low-
pass response that separates the low- and high-frequency regions. The value C
determines the rate of falloff (or slope) of the power spectrum at high frequencies.
These curves can be conveniently divided into the two sections Bf ≪1 and
Bf ≫1. In the low-frequency section, the curve is essentially constant. In the
high-frequency section, the curve has a constant negative slope when log(S ) is
plotted against log(f). This allows the power spectrum to be ﬁt with two straight-
line asymptotes whose constant value and constant slope can, in principle, be
easily evaluated. The technique, which is outlined in Fig. 4.14, consists of merely
ﬁnding the breakpoint, or knee, at which the two asymptotes meet and evaluating
the two unknowns in terms of the equations of the asymptotes. Once A, A′, B,
and C have been evaluated graphically, then σ and ℓcan be found according

86
Chapter 4
Figure 4.14
Solution for the rms roughness and autocovariance length for the special case
of a Lorentzian power spectrum.
to relationships published by Church and Takacs (1991). A′ can be found from
A for the one-dimensional evaluation. The technique is interesting in that many
samples do exhibit constant slopes on log–log plots. Often troublesome—from
a practical point of view—is that the breakpoint often cannot be found. It can
be at a small-enough frequency (corresponding to near-specular scatter) that the
measurement technique does not always reveal it. These limitations severely
restrict the usefulness of the graphical technique for evaluation of surface statistics,
especially in view of the ease with which results can be obtained with the methods
of Sections 4.2 and 4.4. Two special cases have found prominence in the literature
and are reviewed in the next two sections.
4.5.1 The Lorentzian power spectrum
If C = 2, then the K-correlation form of the proﬁle spectrum is called a Lorentzian.
Workers at the University of Arizona College of Optical Sciences used this form
to reduce BRDF data to surface statistics (Wolfe and Wang 1982; Wang 1983).
The relationships for one- and two-dimensional surfaces are given below, again
showing the relationship to the correlation function. It is clear that S 1 and S 2 have
units of length cubed and quadrupled, respectively:
S 1(fx) = 2
Z ∞
0
cos(2πfxτ)σ2e−|τ|/ℓc dτ =
2σ2ℓc
1 + (2π fxℓc)2 .
(4.27)
S 2(fx, fy) = 2π
Z ∞
0
J0(2πfτ)σ2e−|τ|/ℓc dτ =
2πσ2ℓ2
c
[1 + (2π fℓc)2]3/2 .
(4.28)
4.5.2 Fractal surfaces
Some optically ﬁnished surfaces exhibit the curious property that their measured,
or calculated, surface power spectra very nearly follow an inverse power law

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
87
with no apparent breakpoint (that is, Bf ≫1). This was pointed out by Church,
Jenkinson, and Zavada (1979), and Church has since considered the measurement
implications of such behavior (Church 1980, 1988; Church, Takacs, and Leonard
1989). For one-dimensional surfaces, the power spectrum is expressed as
S 1(fx) = Kn
2f nx
= S 1(1)
f nx
,
(4.29)
where 1 < n < 3, and Kn is a constant numerically equal to 2S 1(1) with units
of (length)3−n Here, the value n = C has been substituted (to match Church’s
notation), and Kn is a combination of A, B, and C. This means that a log–log plot
of the power spectrum is a straight line with slope (−n) and value S 1(1) at fx = 1.
If the surface is isotropic, the two-dimensional power spectrum takes the form
S 2(f) = Γ[(n + 1)/2]S 1(1)
2 √πΓ(n/2)f n+1 ,
(4.30)
where again the factor of 2 in Eq. (2.29) is used because S 1(fx) is a two-
sided function in the notation of this book. An example of a two-dimensional
to one-dimensional conversion is given in Section 11.1, where the scattering
characteristics of silicon are discussed.
These are called fractal surfaces, and they have some interesting properties. The
special cases n = 1, 2, and 3 are called the extreme fractal, the Brownian fractal,
and the marginal fractal, respectively. Notice that there is a singularity at f = 0,
where the fractal spectrum takes on an inﬁnite value. In reality, this causes no
problem, since the lowest relevant spatial frequency is on the order of the inverse
illuminated spot diameter. This makes the form of these PSDs very similar to
the high-frequency section of Lorentzian shapes discussed earlier, except that the
slope is no longer restricted to −2 or −3 for the one- and two-dimensional cases,
respectively.
A true fractal proﬁle (without a breakpoint in the PSD) will have an
apparent correlation length approximately equal to the length of the proﬁle under
consideration, and the rms roughness calculated from such a PSD will be strongly
dominated by the low-frequency contributions. Thus, the calculated roughness
parameters are strongly bandwidth- (or measurement-) dependent for fractals, just
as they are for nonfractals. This strong bandwidth dependence, which is readily
apparent in the PSD, is one of the reasons for preferring PSD analysis over the
autocorrelation function approach.
Fractals have the unique quality that their power spectra can be characterized by
only two quantities: −n and Kn. In other words, in some ways it would make more
sense to report the fractal constants instead of a height parameter (rms roughness),
transverse parameter (average wavelength or correlation length), and the associated
bandwidths. As will be seen, these distinctions are signiﬁcant because the PSDs
of many practical surfaces (optics, semiconductors, etc.) are fractal-like over
bandwidths of interest.

88
Chapter 4
4.6 The TIS Derivation from the Rayleigh–Rice Perturbation
Theory
When Davies (1954) derived the relationship between smooth-surface TIS and
rms roughness (Section 1.6), he assumed that most of the scatter was close to
specular (cos θs = 1 for θi = 0) and that the surface had a Gaussian height
distribution function. Both assumptions simplify the mathematics. Unfortunately,
the Gaussian assumption was used as a convenient scapegoat for several years to
explain differences in measured rms roughness observed when the same sample
was measured by different measurement techniques. The Rayleigh–Rice equations,
which relate scatter to the surface power spectrum independent of the form of
the height distribution, suggest that perhaps the Gaussian assumption was not
necessary. Church pointed this out in 1977, and his approach is outlined below
in Eqs. (4.31) to (4.34).
The TIS is ﬁrst expressed in terms of the BRDF by integrating from the small
entrance/exit hole out to the waist of the observation hemisphere (see Fig. 1.7).
The polarization constant is approximated by the surface reﬂectance R, and then
Eq. (4.1) is used to express the BRDF in terms of the surface power spectrum. An
exchange of variables from (θs, φs) to (fx, fy) is made to allow integration over the
power spectrum. The small-scatter-angle assumption, which removes the cosines,
is then made, and the result is the familiar expression for TIS of a smooth surface
in terms of the surface rms roughness:
TIS ≡
scattered power
specularly reﬂected power =
Z 2π
0
Z θmax
θmin
"(dP/dΩ)s
RPi
#
dΩs.
(4.31)
TIS =
Z fmax
fmin
Z fmax
fmin
"16π2
λ4
cos θi cos2 θsS (fx, fy)
#
λ2
cos θs
d fxd fy.
(4.32)
dΩs = sin θs dθs dφs = λ2 d fx d fy
cos θs
.
(4.33)
TIS =
 4π
λ
!2 Z fmax
fmin
Z fmax
fmin
cos θi cos θsS (fx, fy)d fxd fy 
 4πσ cos θi
λ
!2
.(4.34)
The result is important from several aspects. In addition to removing
the Gaussian restriction, it is another point of common ground between the
Rayleigh–Rice and Kirchhoff approaches to diffraction theory. The fact that TIS
is strictly a scalar result is brought home by the use of the specular reﬂectance in
place of the polarization constant. Scatter amplitude from a normally illuminated
isotropic sample will not be constant in φs at ﬁxed θs if the source is plane
polarized. The variations are due to the differences in s and p polarization that
are evident in the expressions for Q (given in Section 5.2). These differences can
be more important than the issues imposed by the small-angle assumption and
detector issues associated with the Coblentz sphere systems (Stover and Hourmand
1984a).

Using Rayleigh–Rice to Calculate Smooth-Surface Statistics from the BRDF
89
A simple demonstration of the effectiveness of TIS measurements on non-
Gaussian surfaces can be made by returning to the sinusoidal grating (which
is obviously non-Gaussian). The scatter signal will consist of two ﬁrst-order
diffraction spots, as predicted by the Rayleigh–Rice result Eq. (3.49) for s-
polarization:
TIS = 2[(ka)2 cos θi cos θs]|θsθ0  2
 2πa
λ
!2
=
 4πσ
λ
!2
.
(4.35)
Assuming unity reﬂectance, normal incidence, and small-angle scatter, and
substituting the sinusoidal rms roughness σ = a/
√
2 gives the Davies TIS result.
Even the assumption of s-polarization is not critical, since for small-angle scatter
both polarization results are identical [Eq. (3.51)].
4.7 Summary
When the smooth, clean, front-surface reﬂective conditions are met, a bandwidth-
limited section of the surface PSD function is nearly proportional to the angle-
limited BRDF. Given one of the two functions, it is then possible to ﬁnd the other.
If the PSD is found from the BRDF, it is possible to compute the surface rms
roughness, rms slope, and average surface wavelength as indicated in Chapter 2.
The speciﬁc equations of interest have been presented for the special cases of
the isotropic and one-dimensional surfaces, which can be analyzed using plane-
of-incidence scatter data. Equations for the more-general case, requiring scatter
measurement over the full hemisphere in front of the sample, have also been
given. Power spectra that ﬁt (or nearly ﬁt) ABC expressions offer the advantage
of characterizing the surface with quantities that are not measurement (i.e.,
bandwidth) dependent. The Rayleigh–Rice relationship has been integrated to
obtain the familiar relationship between TIS and rms roughness without requiring
that the surface have a Gaussian height distribution. Finally, the philosophical stage
has been set to introduce wavelength and angle-of-incidence scaling, which will be
presented in Chapter 8.

 

Chapter 5
Polarization of Scattered Light
“There are two kinds of light–the glow that illuminates, and the glare that
obscures.” – James Thurber
Some
of
you
are
probably
old
enough
(like
me)
to
remember
when
Polaroid R⃝sunglasses ﬁrst became available. They were a sensation. Glare light
is reduced by more than the background light with the result that you actually
have better vision—not just less light in your eyes. They work best in situations
where the sun is more or less in front of you, and the combination of reﬂected
light and near-specular scatter causes a bright glare that dominates your ﬁeld
of view. Because reﬂectance is a function of polarization, the glare light (which
has been reﬂected once) often has a horizontal polarization component that is
much stronger than the vertical component. Normal background light (which has
been reﬂected many times, at many angles) is more evenly divided between the
two polarizations. Polaroid sunglasses simply discriminate against the horizontal
component to reduce the fraction of glare light. If you look at the blue sky—a
source of scattered light—through your sunglasses, you will ﬁnd that rotating the
glasses 90 deg causes the sky to look dimmer (i.e., the sky has a strong vertical
component). This effect is most strongly pronounced if you look in a direction
perpendicular to the sun’s rays. These two examples clearly demonstrate that
scattering is polarization sensitive.
When light is scattered, its polarization—along with its amplitude and
direction—is changed. The changes depend on the sample shape and material,
as well as the polarization, amplitude, and direction of the incident beam. All
three quantities must be considered when examining the effect of a sample on
the reﬂected and transmitted light. A complete description of the polarization
characteristics of an EM wave, before or after sample interaction, can be
accomplished by straightforward measurements. Comparison of polarization
amplitude and direction before and after interaction with the sample allows
information about the sample material to be obtained. The trick is to relate the
before-and-after changes to useful, or needed, sample characteristics.
Chapters 3 and 4 discussed the relationship between smooth reﬂector
topography and the resulting changes in the reﬂected light. Polarization changes
were presented as being contained in the factor Q. For an s-polarized source,
incident plane measurements and a high-reﬂectance Q are nearly constant. There
91

92
Chapter 5
are other scatter measurement applications besides roughness characterization that
beneﬁt from analysis of the polarization state of both incident and reﬂected light.
Different forms of characterizing polarization are often used in these situations.
This chapter reviews polarization concepts and characterization requirements in
a general sense, using various scattering vectors and matrices. The factor Q is
then completely deﬁned and discussed in terms of its general description. The
use of wave polarization vectors and matrices to represent sample/component
effects is reviewed. These representations are shown to be more tedious and less
quantitative in terms of the sample’s physical characteristics, but they can be
extremely useful for locating and empirically grading sample defects and changes
in sample properties. In other words, polarization effects present a noncontact
technique to monitor industrial quality in both process-control systems and ﬁnal
inspection.
5.1 A Review of Polarization Concepts
The assumption behind most of this text has been that the reader does not need
a tutorial on the basic principles of optics. In this section, that assumption is
dropped long enough to brieﬂy review required polarization concepts. This is
done to save a fairly large fraction of the readers a dash for their reference texts
and to avoid confusion due to the diversity in the way various terms have been
deﬁned in the literature. Some readers will want to skim this section just long
enough to pick up the nomenclature. For those who want a more complete review
of polarization, a number of texts are available (two classics are Shurcliff 1962;
and more recently, Collett 1993). Chipman (2009a, 2009b) has two chapters in the
2009 edition of Handbook of Optics, plus he and his various teams have published a
number of papers providing basic polarization information (for example, Pezzaniti,
Chipman, and McClain 1994, Chipman 2007). Appendix A reviews necessary
wave-propagation concepts.
It is the electric ﬁeld component in the transverse electromagnetic (TEM) wave
description that is responsible for most observed EM wave–material interactions.
And, it is the direction of this vector that is used (in this text) to deﬁne the direction
of polarization. In general, the polarization of monochromatic coherent light is
elliptical. As shown in Fig. 5.1, all of the elliptical conﬁgurations can be expressed
as the summation of two orthogonal linearly polarized waves traveling in the same
direction with phase difference δ between them. At zero phase difference (δ = 0),
the two waves sum to a linearly polarized beam. If the phase difference is increased,
then the resultant polarization moves from linear, to elliptical, to circular, back to
elliptical, and at a phase difference of π, the resultant wave is plane-polarized
again but rotated by 90 deg from the original zero-phase condition. Increasing
the phase difference by another π (a total of 2π) brings the wave back to its
original plane-polarized state. Phase differences may be introduced between wave
components through the use of retardation plates (quarterwave, half wave, etc.)
made of birefringent materials. The direction around the ellipse that is traced out
by the resultant electric vector is determined by which of the two plane waves leads

Polarization of Scattered Light
93
in phase. If the vector rotates in the clockwise direction when propagating toward
the observer, then polarization is right handed. Counterclockwise rotation is known
as left handed. Using the phasor notation of Chapter 3 and Appendix A, the ﬁgure
shows that the amplitudes of the two plane waves (Ex, Ey), and the phase difference
between the two (δ = δx −δy) are the three quantities needed to completely
characterize the general elliptical polarization state. Thus, for linear optics, all
waves of interest, regardless of the polarization state, can be represented by the
sum of two orthogonal, out-of-phase, linearly polarized waves. Without too much
difﬁculty, it can be shown that arbitrarily phased right- and left-hand circularly
polarized waves can also be used as a composite pair to represent the polarization
state of an EM wave. Figure 5.1 applies to a strictly polarized source. If the phase
between Ex and Ey is not well deﬁned, as in the case of a quasi-monochromatic
wave, then the light is said to be unpolarized or partially polarized.
The polarization characteristics of scattered light are more easily understood in
terms of the concepts developed for specular light. Figure 5.2 shows the geometry
for light Pi incident on a sample medium of index n with a boundary surface at the
x, y plane. The boundary reﬂects Pr, transmits Pt, and scatters Ps. Each ray has a
plane of propagation deﬁned by the ray direction (k vector) and the surface normal
(z). The electric ﬁeld vectors (Ei, Er, Et, Es) are composed of an s component,
perpendicular to the plane of propagation, and a p component that is in the plane
of propagation. Notice that the s components are all parallel to the sample face
(the x, y plane). The other common notation for these two polarizations is “⊥” for
s and “∥” for p. These are more functional than x and y (or horizontal and vertical)
because polarization needs to be deﬁned in terms of the beam propagation plane,
which depends on both beam direction and sample normal. The arrangement in
Fig. 5.2 is essentially the same geometry used to deﬁne the BSDF in Chapter 1.
There are some serious issues regarding sample orientation within this geometry,
but they will be put off until Chapter 7.
When the situation of Fig. 5.2 is analyzed by applying the EM boundary
conditions, two familiar results are derived. The ﬁrst is Snell’s law, which is a result
of the condition that the phase variations of the incident, reﬂected, and transmitted
waves at the interface be identical. This relationship can be used to ﬁnd the angle
from normal of the transmitted light:
n sin θt = sin θi.
(5.1)
The angles found through Snell’s Law are independent of polarization if the index
of refraction is independent of polarization. If n changes with polarization, then
the angles change and the material is birefringent. The second result, known as
the Fresnel reﬂection equations, relates the ﬁeld strengths on either side of the
boundary. The subscripts i, r, and t are used to indicate incident, reﬂected, and
transmitted ﬁelds and powers, respectively. The s and p subscripts refer to the
polarization state. These equations can be used to establish the relative values of
Pt, Pr, and Pi as well as their dependence on the angle of incidence, the index of

94
Chapter 5
Figure 5.1
(a) Two orthogonal plane waves combine to form an elliptically polarized wave.
(b) Viewed from the +Z axis, the resultant vector sweeps out an elliptical form in x, y that
depends on δ = δy −δx, Ex, and Ey. (c) The value of δ can be obtained from Ex, Ey, and α,
as shown.
refraction, and the polarization:
Ers
Eis
= −sin(θi −θt)
sin(θi + θt) = cos θi −
p
n2 −sin2 θi
cos θi +
p
n2 −sin2 θi
.
(5.2)
Erp
Eip
= tan(θi −θt)
tan(θi + θt) = n2 cos θi −
p
n2 −sin2 θi
n2 cos θi +
p
n2 −sin2 θi
.
(5.3)
Ets
Eis
= 2 sin θt cos θi
sin(θi + θt) =
2 cos θi
cos θi +
p
n2 −sin2 θi
.
(5.4)
Etp
Eip
=
2 sin θt cos θi
sin(θi + θt) cos(θi −θt) =
2n cos θi
n2 cos θi +
p
n2 −sin2 θi
.
(5.5)

Polarization of Scattered Light
95
Figure 5.2
Deﬁnition of s and p polarization in terms of the incident plane and scatter
plane. s and p are always perpendicular to the propagation direction and to each other. p is
always in the propagation plane, formed by the propagation vector and the surface normal.
s is always perpendicular to the propagation plane and parallel to the reﬂecting.
The value n is the refractive index of the medium beyond the interface divided by
the index of the incident beam medium. For light in space incident on a dielectric,
n becomes the refractive index of the dielectric. The reﬂection equations will be
considered ﬁrst. The minus sign in front of the ratio in Eq. (5.2) implies a 180-deg
phase shift of the reﬂected s-polarized component. The dependence on the index of
refraction can be made apparent by expanding the different functions into products,
and using Snell’s law to convert from transmitted angles to incident angles. The
squares of the ﬁrst two relationships for the reﬂected power are plotted in Fig. 5.3
for the case of n = 1.5. The dip to zero, at 56.3 deg for p polarization, is called
Brewster’s angle (or the polarization angle). Brewster’s law gives the polarization
angle as tan θi = n. Equation (5.3) predicts its existence at θi+θt = 90 deg, or when
the reﬂected and transmitted electric ﬁeld vectors are perpendicular. This makes
sense physically because the reﬂected ray would have to travel in the direction of
the transmitted p-polarized electric ﬁeld vector, which is caused by vibrations of
the induced material dipoles. Because light is a transverse wave, propagation in the
direction of the induced electric ﬁeld cannot take place.
Total internal reﬂection can also be predicted from these equations. In this case,
the wave crosses an interface that goes from high index to low index. The effect on
the equations is that n, which is really the ratio of indices, becomes less than 1. For
both s and p polarization, the reﬂectance is equal to 1 when the square root term

96
Chapter 5
Figure 5.3
Reﬂectance of s- and p-polarized light from a dielectric with an index of 1.5
surface.
reaches zero. This corresponds to the transmitted beam being refracted along the
interface surface.
Thus, in general, if the source is unpolarized, much more s-polarized light will
be found after reﬂection. It is this light that is ﬁltered out by Polaroid sunglasses.
The reﬂectance at both polarizations is unity at grazing angles. Finally, notice that
Fig. 5.3 is a plot of the ratioed intensities (ﬁeld strength squared). Because the
incident and reﬂected beams are traveling in the same medium (at the same speed)
and because they have the same cross-sectional area, the intensity ratio is equal to
the power ratio. This is not the case for the transmitted beam traveling in index
n. Its cross-sectional area is increased by the ratio of the propagation direction
cosines after refraction, and its time-average power ﬂow is proportional to n [see
Eq. (A.23) in Appendix A]. Thus, assuming no absorption, the power conservation
equation for either polarization becomes
 Er
Ei
!2
+ n
 Et
Ei
!2 cos θt
cos θi
= R + T = 1.
(5.6)
Because more s-polarized light is reﬂected, one would expect more p-polarized
light to be transmitted. This is easily veriﬁed by noticing that Eqs. (5.4) and (5.5)
are identical except for the cos(θi −θt) factor. Finally, the Fresnel equation can
be evaluated at zero angle of incidence. In this case, if the sample is isotropic,
there is no distinction between s- and p-polarized specular light, as there are no
asymmetries. Converting from intensities to powers, as indicated above, gives
R =
 n −1
n + 1
!2
and
T = 1
n
 2n
n + 1
!2
,
(5.7)

Polarization of Scattered Light
97
which evaluate to 0.04 and 0.96, respectively, for n = 1.5 (a value that is
representative of many dielectrics at visible wavelengths).
Several preliminary conclusions can be drawn about the polarization
dependence of the scatter pattern associated with the reﬂection and refraction of
light from an isotropic dielectric plane. Based on the relative values of reﬂectance
and transmittance, scatter in the forward direction (transmission) is likely to exceed
scatter in the back (reﬂective) direction. Thus, measuring transmissive scatter
is likely to be a more sensitive choice than reﬂective scatter when inspecting
transparent materials for defects. For an unpolarized input, there is likely to be
much more s-polarized light in the reﬂected scatter than p-polarized light. The
reverse is true of the transmitted-scatter pattern. These statements are true simply
because a larger fraction of the incident p-polarized light is transmitted. Although
at zero angle of incidence there is a polarization symmetry for the specular beams,
this is not true for the scattered beams. If a plane-polarized beam is normally
incident on the sample, there is an asymmetry over the scattering sphere relative to
the direction of polarization. And further, based on the reasoning used to explain
the Brewster angle, there should be scatter directions in which there is only one
polarization present.
Figure 5.4 compares reﬂective and transmissive scatter from a glass window.
The scatter was observed to be strong at the ﬁrst sample surface, weak at the second
sample surface, and very weak in the bulk. The incident light was a circularly
polarized HeNe laser at a wavelength of .633 µm and an incident angle of 30 deg.
Both s and p scatter were measured on each side of the window, as indicated in
Fig. 5.4(a), by placing a polarizing ﬁlter (analyzer) in front of the detector. Using
the transmitted (or reﬂected) specular beam as the zero-degree location, the data
in Fig. 5.4(b) was obtained. As predicted, the reﬂective s-polarized scatter was
stronger than the reﬂective p-polarized scatter. The second surface reﬂection is also
apparent in the reﬂective scans just to the right of the main specular peak. The two
transmissive scans are almost identical in intensity. This is because the reﬂective
component removes a relatively small fraction of the light from the transmitted
beam [Rs = .058, Rp = .025 via Eqs. (5.2) and (5.3)], so the ratio of s to p light
in the transmitted beam is still nearly equal. The transmissive scatter is modulated
by another effect described by the Fresnel equations. The fast drop in transmissive
scatter between 10 and 20 deg is caused by total internal reﬂection of front-surface
scatter at the second surface. This brings up another point: these various effects
make the bulk material a scatter shield between either surface and the hemisphere
on the other side of the window. Thus, in order to reduce scatter into a particular
hemisphere, windows should be oriented with the high-scatter surface away from
the hemisphere of concern. This is especially true when concerned about high-
angle scatter.
The situation for reﬂection from metals is more complicated because, unlike
dielectrics, a phase difference is introduced between the s- and p-reﬂected
components. The degree of elliptical polarization introduced into the reﬂected
beam is a function of the angle of incidence as well as the wavelength-dependent
metallic optical constants. These effects are explained through the use of a complex

98
Chapter 5
Figure 5.4
(a) Reﬂective and transmissive scatter measured from a glass window for both
s and p components. The source is a circularly polarized laser incident at 30 deg from
normal. (b) Transmissive scatter is much higher until total internal reﬂection reduces scatter
from the ﬁrst surface.
refractive index (or complex dielectric constant), which is given in terms of the
optical constants and depends on the material conductivity (see Appendix A).
Metallic reﬂectance at normal incidence is generally higher than for a dielectric.
There is a nonzero minimum in the p-polarized reﬂectance, similar to the Brewster
angle minimum for dielectrics, called the principal angle of incidence θ′
i. By
choosing an appropriate conﬁguration, the complex index can be evaluated after
appropriate measurement of the polarization state of both the incident and reﬂected
specular beams. This process, which is called ellipsometry, is based on Eqs. (5.2)

Polarization of Scattered Light
99
and (5.3), where the complex index is given as
ˆn = n + jnK = n + jK0.
(5.8)
The real index n and the absorption index K (or the absorption coefﬁcient K0)
are known as the optical constants. Taking the absolute squares of Eqs. (5.2)
and (5.3) gives the s and p reﬂectances as a function of incident angle. By
taking two reﬂectance measurements, these relationships can be used to produce
two equations that can be solved for the two unknowns. Many measurement
combinations are possible, but most are difﬁcult to evaluate. One of the
easier combinations requires measurement of the principal angle θ′
i and of the
corresponding reﬂectances of the s and p light. This results in two approximate
relationships that can be used to evaluate the optical constants (Jenkins and White
1976, p. 537):
K = tan

2a tan
q
R′p/R′s

.
(5.9)
n
√
1 + K2 = sin2 θ′
i/ cos θ′
i.
(5.10)
The values Rp and Rs are simply the p and s reﬂectances measured at θ′
i.
The relationships presented above, based on the Fresnel equations, are standard
fare in many basic texts on optics. Although the dependence of scatter on
polarization is somewhat more complicated than the specular relationships
discussed above, it should come as no surprise that scatter effects can be explained
through the use of the complex dielectric constant (or index of refraction). The
next section relates polarization effects in the light scattered from optical surfaces
through the use of the polarization factor introduced in Chapter 3.
5.2 The Polarization Factor Q
As indicated in the Chapter 3 discussion of the Rayleigh–Rice perturbation
diffraction theory, the polarization factor Q is a real number that relates the effect
of surface material properties (as opposed to surface shape) on the BRDF. Its
value depends on the sample dielectric constant ε as well as the incident angle and
the scatter angles. In addition, it depends on the incident polarization and on the
polarization states allowed to pass to the detector. As one would expect, it accounts
for several familiar effects. Evaluated in the specular direction, the expressions
for Q reduce to the Fresnel reﬂectance equations deﬁned in the previous section.
Brewster’s angle, ellipsometry effects, and the presence of plasmons (surface
waves) are also accounted for within Q.
Barrick (1970), Maradudin and Mills (1975), and Church (Church and Zavada
1975; Church, Jenkinson, and Zavada 1977, 1979) are responsible for introducing
these relationships into the modern radar and optical literature. Q is actually the
sum of as many as four different quantities that correspond to the four possible
combinations of input and observation polarization. Borrowing Church’s notation,

100
Chapter 5
the subscripts α and β refer to the incident and observed polarizations, respectively,
and Q becomes
Q = Qαβ
(5.11)
for an α-polarized source and a β-sensitive receiver. If the receiver is insensitive to
polarization, Q becomes
Q =
X
β
Qαβ
(5.12)
for a polarized source, and
Q = 1
2
X
α
X
β
Qαβ
(5.13)
for an unpolarized source. The individual expressions for the Qαβ are
Qss =

(ε −1) cos φs
(cos θi +
p
ε −sin2 θi)(cos θs +
p
ε −sin2 θs)

2
.
(5.14)
Qsp =

(ε −1)
p
ε −sin2 θs sin φs
(cos θi +
p
ε −sin2 θi)(ε cos θs +
p
ε −sin2 θs)

2
.
(5.15)
Qps =

(ε −1)
p
ε −sin2 θi sin φs
(ε cos θi +
p
ε −sin2 θi)(cos θs +
p
ε −sin2 θs)

2
.
(5.16)
Qpp =

(ε −1)(
p
ε −sin2 θs
p
ε −sin2 θi cos φs −ε sin θi sin θs)
(ε cos θi +
p
ε −sin2 θi)(ε cos θs +
p
ε −sin2 θs)

2
.
(5.17)
Although these equations are fairly intimidating at ﬁrst glance, and they
require considerable effort for exact computation by hand (especially when the
dielectric constant is complex), examination of several special cases will provide
considerable insight into their characteristics. And, in fact, these equations are
simply a more-general representation of the more-familiar relationships presented
in Section 5.1.
In the plane of incidence (sin φs = 0), the cross-polarization terms (Qsp and
Qps) are zero. In the specular direction, θs = θi, and Eqs. (5.14) and (5.17) reduce
to the Fresnel reﬂection coefﬁcients. They are given here for power instead of ﬁeld

Polarization of Scattered Light
101
strength and are expressed slightly differently from Eqs. (5.2) and (5.3):
Qss specular =

cos θi −
p
ε −sin2 θi
cos θi +
p
ε −sin2 θi

2
= Rs(θi).
(5.18)
Qpp specular =

ε cos θi −
p
ε −sin2 θi
ε cos θi +
p
ε −sin2 θi

2
= Rp(θi).
(5.19)
The results of Eq. (5.7) are found if θi = 0 is substituted into either Eq. (5.18)
or (5.19). Brewster’s law can be derived directly from Eq. (5.19) by setting the
numerator equal to zero. Remember that the relative dielectric constant is the
square of the refractive index.
As indicated in Chapter 4, the value of Q is necessary to compute the PSD of a
reﬂective surface. The problem is that Eqs. (5.14) to (5.17) are not easy to evaluate
without computer help, even if the optical constants are known for the sample in
question. Combination of Eqs. (5.14) and (5.18) proves the following identity for
the incident plane. This is a very convenient way to compute exact values of Qss
from experimental reﬂectance data without knowing the sample optical constants
(Church 1989):
Qss = [Rs(θi)Rs(θs)]1/2 cos2 φs.
(5.20)
Here, Rs(θi) and Rs(θs) are the specular reﬂectances measured at θi and θs,
respectively. For in-plane measurements of good reﬂectors, this relationship makes
exact data analysis much easier. The shape of Qss for φs = 0 is seen from Eq. (5.20)
to be much like that of Rs(θs), as shown in Fig. 5.5. Because Qss is a smooth
function, an excellent curve ﬁt can be obtained by measuring sample reﬂectance at
just a few angles of incidence. Further, if Rs(θi) is reasonably large, then
Qss  Rs(θi) cos2 φs,
(5.21)
which is even easier to use and, for most metallic reﬂectors, does not introduce
signiﬁcant error. The point here is that if conversion of the BRDF to the surface
PSD is one of the desired results of a scatter measurement, then both source and
detector polarization are issues, and an s-polarized source with in-plane detection
makes the data far more convenient to analyze.
For a high-reﬂectance material, the absolute value of the dielectric coefﬁcient
is much larger than sin θ and approximately cancels throughout, simplifying
Eqs. (5.14) to (5.17) to the following idealized relationships:
Qss = cos2 φs.
(5.22)
Qsp = (sin φs/cosθs)2.
(5.23)
Qps = (sin φs/cosθi)2.
(5.24)

102
Chapter 5
Figure 5.5
Comparison of Qss with R(θi) and R(θs) for a high-reﬂectance mirror. The Qss
scale does not start at zero.
Qpp = [(cos φs −sin θi sin θs)/(cos θi cos θs)]2.
(5.25)
The incident plane value of Qss (see Fig. 5.2 for geometry) is now unity. Out of
the plane, Qss falls off to zero as φs is increased to 90 deg. This is true even
if θs is very small and occurs because light will not propagate in the direction
of the s-polarized electric ﬁeld. Qsp is identically zero on the incident plane for
both the perfect reﬂector and the exact relationships. Except for unbounded values
at θs = 90 deg, it is a nonzero, ﬁnite number out of the incident plane. Qps is
very similar except that it reaches unbounded values only for θi = 90 deg. The
divergence of Eq. (5.25) for Qpp at θs = 90 deg is due to surface wave effects in
Eq. (5.17). For a ﬁnite dielectric constant [using Eq. (5.17)], the peak comes at a
little less than 90 deg.
An approximation for Qss is also available for surfaces that are poor reﬂectors.
When scatter measurements are taken, it is quite common to measure the specular
reﬂectance at the incident angle, and this contains useful material information.
Notice in Fig. 5.5 that Rs(θs) looks similar to an inverted and shifted cosine
function in θs with amplitude [1 −Rs(0)]. If Rs(θi) is measured, then a little bit
of algebra gives an approximate expression for the specular reﬂectance as
Rs (θs)  1 −
"1 −R(θi)
cos θi
#
cos θs,
(5.26)
and then, using Eq. (5.20), an approximate expression for Qss is
Qss 
"
R(θi) −cos θs
cos θi

R(θi) −R(θi)2#1/2
.
(5.27)

Polarization of Scattered Light
103
Thus, approximate values for Qss can be found from measured incident angle
reﬂectance alone without knowing the material or the associated complex index
of refraction. This further means that the BRDF-to-PSD conversions described
in Chapter 3 can be implemented (when appropriate) without detailed sample
information.
The complete polarization state (Ex, Ey, and δ) is not used to obtain surface
statistics. To do so would require that the “Q information” be applied to the ﬁelds
prior to taking absolute squares, which could be a useful exercise. The next section
outlines the techniques reported to describe the complete polarization state of
scattered waves.
5.3 Scattering Vectors and Matrices
The Q expressions have been used for the case of smooth, clean, front-surface
reﬂectors. Unfortunately, there is no well-established ﬁeld theory analysis that
allows the light scattered from samples not meeting these requirements to be
related directly to sample properties. The problem of rough-surface scatter analysis
(σ ≈λ) has deﬁed an exact solution, and the Mie theory, explaining particulate
scatter, is restricted to scatter from uniform index spheres. There are, however,
ways to characterize, or document, the effect of rough and contaminated samples
on the scatter polarization. The techniques are very useful for comparing similar
samples and as process-control monitors. In other words, it may not be easy
to deﬁne the relationship between scatter and large-defect geometry, but under
the right polarization conditions those defects are readily detected. The methods
involve ﬁrst deﬁning vectors that describe the polarization state of an EM wave.
The incident and scattered waves are written in terms of the vector deﬁnition, and
then the vectors are linearly related to each other by a sample-dependent matrix.
The simplest of these methods, known as the Jones calculus, or the scattering
amplitude matrix, is used to relate the complex s- and p-polarized ﬁeld vectors of
the incident and output waves (Shurcliff 1962, p. 118; Bohren and Huffman 1983,
p. 61; Azzam and Bashara 1977, p. 67). It is common to omit the time-dependent
terms and leave only the relative phase components. Vector component amplitudes
are often normalized by the electric ﬁeld amplitude. The two components of a
Jones vector contain a real and an imaginary part. Thus, each vector is described
by four variables. These amount to Ex, Ey, δ, and the absolute phase of either
component at t = 0. Although the Jones calculus is very useful for analysis of
polarization of specular elements where the phase relationships are well preserved
(or understood), it is impractical to implement in most optical scatter problems
because of the difﬁculty in measuring the relative phase between the incident
and scattered amplitude components. Its strength lies in analysis of specular
beams through well-characterized optical components such as retardation plates.
Electrical engineers will be familiar with variations on the Jones calculus that are
used to analyze a variety of waveguide and transmission-line problems.
The Stokes vectors, which are another common way of characterizing the
polarization state of an EM wave, are deﬁned in terms of the three critical

104
Chapter 5
polarization parameters, Ex, Ey, and δ, as shown in the ﬁrst half of the following
equations (Shurcliff 1962, p. 18; Bohren and Huffman 1983, p. 46; Azzam and
Bashara 1977, p. 59; Collett 1993, p. 33). They do not require evaluation of an
absolute phase variable [the I, M, C, S notation (which was used in the ﬁrst edition
of this book) is shown below because it appears in many texts. Newer references
favor the S x notation, which is employed for the rest of this text]:
I = E2
x + E2
y = 2η0
A (Px + Py) = S 0.
(5.28)
M = E2
x −E2
y = 2η0
A (Px −Py) = S 1.
(5.29)
C = 2ExEy cos δ = 2η0
A (PR −PL) = S 2.
(5.30)
S = 2ExEy sin δ = 2η0
A (PR −PL) = S 3.
(5.31)
The last term of each equation indicates how these vectors can be measured
for an EM wave of time-average power P = Px + Py over an aperture of area
A. The relationship between average wave power and ﬁeld strength is given in
Eq. (A.14) of Appendix A. S 1 is found from the difference of powers associated
with the x and y components. This measurement can be accomplished by using a
polarizer in front of the radiometer. S 2 is proportional to the difference in powers
(P+−P−) measured by orienting the polarizer at +45 deg and –45 deg, respectively,
from the Ex direction. The last Stokes vector is proportional to the difference in
powers (PR −PL) found by measuring the right- and left-hand circular polarized
components. This measurement requires a quarterwave plate and a polarizer in
front of the radiometer. These four quantities, which “over-deﬁne” the three-
parameter description, are related to each other as
(S 2
1 + S 2
2 + S 2
3)/S 2
0 = 1
(5.32)
if the wave is monochromatic and fully polarized. If there is no well-deﬁned phase
relationship δ between Ex and Ey (the light is unpolarized), then the ratio is zero.
Partially polarized light gives a ratio between zero and one. This is the reason for
over-deﬁning the polarization with four Stokes parameters instead of three. If the
light is quasi-monochromatic, then the four parameters are deﬁned in terms of their
time averages, and the ratio of Eq. (5.32) will be less than 1. Although there are no
truly monochromatic light sources, lasers provide a close enough approximation to
the situation of Fig. 5.1.
Thus, for polarized light, the Stokes vector gives the entire intensity and
polarization description of the EM wave. It contains the information necessary
to determine δ, the phase between the s and p components, but does not give any
information about the absolute phase of the composite wave amplitude. The Stokes
vectors for vertically polarized and right-hand circularly polarized light are shown
below. The vectors can be conveniently normalized by the ﬁrst parameter S 0 so

Polarization of Scattered Light
105
that each parameter varies between 0 and 1, depending on the polarization state:

S 0
S 1
S 2
S 3

V
= E2
y

1
−1
0
0


S 0
S 1
S 2
S 3

RC
= (E2
x + E2
y)

1
0
0
1

.
(5.33)
The four-by-four Mueller matrix Mi j is used with the Stokes vectors to represent
the effect of a sample on the intensity and polarization properties of an incident
EM wave. The sixteen matrix elements are the values necessary to convert an
input Stokes vector to an output Stokes vector. The matrix elements change with
wave direction, as well as sample properties, and can be used to describe effects
induced on transmitted, reﬂected, and scattered light. As an example, consider the
conversion of linearly polarized light from vertical to horizontal by a halfwave
plate oriented with its fast axis at 45 deg from horizontal. By inspection, the
following matrix correctly performs the conversion. You can quickly conﬁrm that,
as expected, it will also reverse the process. Normalized vectors are used:

1
1
0
0

=

1
1
0 0
0 −1 0 0
0
0
1 0
0
0
0 1


1
−1
0
0

.
(5.34)
The matrix elements are not derived from ﬁeld theory but are empirically found
to work, either by inspection or experiment. A Mueller matrix can be found
that will convert between any two arbitrary Stokes vectors; however, not all
Mueller matrices are physically realizable. Collett (1993) reviews the use of Stokes
vectors and Mueller matrices and includes chapters that contain some general
measurement techniques, as well as evaluation of several matrices for different
optical components. Shurcliff (1962) has an appendix that contains the form of
many matrices and vectors.
The Mueller matrix approach has been applied to scattering problems. Bohren
and Huffman (1983) review the methodology and apply the technique to scattering
by small particles. Hunt and Huffman (1973) and Bickel et al. (1976) have reported
a scatterometer capable of measuring the various Mueller elements. The technique
has been used to measure Mueller elements associated with a variety of particles,
ﬁbers, biological samples, and optical elements (Bell and Bickel 1981; Bickel,
Iafelice, and Videen 1986; Bickel, Zito, and Iafelice 1987; Zito and Bickel 1986;
Iafelice and Bickel 1987; Schiff et al. 1992a, 1992b; Schiff, Stover, Swimley, and
Bjork 1992; Stover and Bernt 1993).
The power of the matrix approach to characterizing polarization changes is in
reducing complex problems to a standard procedure. Set up the situation, turn
the crank, and out pops an answer. Once a matrix is evaluated, it can be used
to ﬁnd the output vector for any input vector of interest. The Stokes–Mueller
approach is superior to the Jones calculus for scatter problems because it can

106
Chapter 5
handle unpolarized light and avoids the issue of absolute phase. Light diffracted
from an isolated spatial frequency can be treated much like a specular reﬂection
because it has a well-deﬁned polarization state. Light scattered from a rough
surface composed of many surface frequencies presents a phase front that can
vary dramatically with angle, even if a well-polarized source is used. The speckle
pattern formed when laser light is reﬂected from a rough surface is an example. If
the measurement aperture accepts many speckles, then, at best, an average relative
phase can be deﬁned. Thus, the surface information available in the specular
reﬂection (e.g., optical constants from ellipsometry) is not necessarily present. The
Stokes–Mueller approach provides a way to characterize this type of sample.
Probably
the
most
serious
difﬁculty
in
the
practical
application
of
Stokes–Mueller polarimetry to scatter problems (and even many specular
measurements) is the number of errors introduced by the polarization elements
in the source and detection optics. Two examples are a polarizer rotated just
slightly off null and a wave plate that does not have quite the required retardance.
Angular errors as small as a few hundredths of a degree (in either position or
retardance) can produce a matrix noise ﬂoor that masks the deviations under
investigation. For many applications, the normalized matrix element uncertainty
must drop below 1% and approach 0.1%. There have been two approaches to
meeting this requirement. The ﬁrst (Goldstein and Chipman 1990) analyzes the
effects of various component errors and generates corrections for the various
potential problems. The various deviations are then measured for the components
actually in use, and the corrections are applied. The second approach (Schiff et al.
1992a, 1992b; Schiff, Stover, Swimley, and Bjork 1992) employs an automated
“no-sample” measurement that results in correction matrices for both the source
and detection optics. Because the corrections are combined, knowing individual
element deviations is not necessary, and this permits broadband measurements
(where retardation values can change dramatically). Both techniques appear to
give a matrix element noise ﬂoor in the 0.1 to 0.3% percent range. Conﬁrmation is
always difﬁcult because these accuracies are at the limit of any known polarization
standard.
There are some serious problems with use of the Stokes–Mueller approach
for scatter characterization. For many reﬂectors, only a fraction of the sixteen
matrix elements will be unique. Measurement of the Mueller elements is not
straightforward, and once they are found, the elements are not easily related
to more conventional sample parameters, such as the optical constants. A new
matrix must be evaluated for each desired pair of incident–scatter directions. These
difﬁculties can be reduced by choosing an input vector that forces many of the
matrix elements to zero and by using automated instrumentation that eliminates
many of the calculation problems.
There is no need to be constrained to the historical vector/matrix choices for
some problems. For many applications it is probably enough to know the BRDF
associated with the four input/output polarization combinations. An approach that
may prove more useful to modern scatter problems is to deﬁne wave vector
parameters that result in matrix elements that are more easily used. As an example,

Polarization of Scattered Light
107
the incident vector might be composed of the s and p powers Pis and Pip. The
scattered vector could be the s and p power/solid angle Pos/Ωand Pop/Ω. The 2H2
scattering matrix S i j, relating the two vectors, contains four independent elements
(S 11, S 12, S 21, S 22) that are easily identiﬁed as the cosine-corrected BSDF values
for the four input/output polarization combinations (ss, ps, pp, sp):
"Pos/Ω
Pop/Ω
#
=
"S 11S 12
S 21S 22
# "Pis
Pip
#
.
(5.35)
Pos/Ω= S 11Pis + S 12Pip.
(5.36)
Pop/Ω= S 21Pis + S 22Pip.
(5.37)
Evaluation of the elements can be accomplished by automating the incident
beam polarizer and receiver analyzer positions. In principal, a system like this
could operate as an ellipsometer in the specular direction and as a polarization-
sensitive scatterometer elsewhere. The key to developing these techniques is a ﬁrm
handshake between the choice of scattering vectors and the instrumentation design.
If the polarization vectors are chosen in such a way that the matrix elements are
easy to evaluate and relate to physical quantities of meaning, then the result will be
effective, efﬁcient quality-control instrumentation capable of signiﬁcantly reducing
scrap and increasing throughput.
By the early 1990s, there was great interest in exploiting the polarization-
sensitive nature of scatter measurements at a number of laboratories. Two
investigators, Thomas Germer at the National Institute of Standards and
Technology (NIST) and Russell Chipman working at the University of Alabama
(Huntville), and later Arizona, led the way.
Germer combined a series of scatter models with measurements from a
conventional goniometer-based scatterometer (see Chapter 7) to report progress
on polarization calculations on scatter from sinusoidal surfaces, silicon wafers,
coated surfaces, and contaminated surfaces (Germer, 1997, 2000, 2001, 2007a,
2007b; Germer, Asmail, and Scheer 1997; Germer and Asmail, 1999a, 1999b;
Germer and Marx, 2004). As mentioned in Chapters 6, 9, 11 and 12, he also
published models for scatter from surface particles that allow calculation of their
polarization characteristics. He provides the scattering models on a NIST website
(http://physics.nist.gov/Divisions/Div844/facilities/MIST/mist.htm), where they
can be downloaded free of charge. This is a signiﬁcant resource because companies
that develop similar models consider them to be proprietary, and these models are
not made public.
Chipman’s university teams developed instrumentation capable of fast
polarization measurements (Nobel et al. 2007) and used them to measure
polarization characteristics of scatter from a variety of natural and manmade
objects (Pezzaniti and Chipman 1995, McClain et al. 1995, Gerliand et al. 1999),
including diamond turned mirrors and integrating-sphere ports. They have also
studied the effects of surface lay on scatter polarization (Noble et al. 2009) and

108
Chapter 5
the level to which surface texture is related to the level of depolarization of
scattered light (DeBoo, Sasian, and Chipman 2004, 2005, Sayler et al. 2008).
These papers just open the door to a huge number of potential industry applications
for monitoring the manufacture of products for everything from surface ﬁnish to
product appearance (see Chapter 10).
5.4 Summary
A complete description of an EM wave includes its polarization state as well as
its direction, wavelength, amplitude, and absolute phase. The polarization state is
deﬁned if the electric ﬁeld amplitudes of the s- and p-wave components and the
phase difference between them are known. Measurement of the input and output
polarization states, along with the other specular beam parameters, allows the
sample optical constants to be evaluated through a process known as ellipsometry.
The polarization factor Q helps describe the dependence of scatter from smooth,
clean, reﬂective surfaces. It can be evaluated exactly in terms of the complex
dielectric constant for the four incident/scattered combinations: ss, sp, ps, and
pp. Rough, contaminated, or volume-scattering surfaces cannot be evaluated with
these relationships. Instead, scatter is characterized in terms of polarization wave
vectors that are acted upon by sample dependent matrices. The matrix elements are
generally found empirically and, at this stage, have no well-deﬁned relationship to
material constants.
Polarization-sensitive scatter measurements have the potential for providing a
new class of instrumentation for inspection and process-control applications, both
in and out of the optics industry. For a given sample, product, or process, an
unwanted defect will often have a matrix element in some preferred direction that
is orders of magnitude different from the undamaged substrate, or host, material.
By measuring that particular element alone, fast, sensitive measurement systems
can be developed. Examples are given in Chapters 9 and 11.

Chapter 6
Scattering Models for Discrete
Surface Features
“As far as the laws of mathematics refer to reality, they are not certain; and as far
as they are certain, they do not refer to reality.” – Albert Einstein
The ability to accurately model scatter from discrete surface features has huge
advantages over having to actually take the measurements. Beyond the problems
associated with building (or buying) a scatterometer (see Chapter 7) and using it
to measure defect scatter in the presence of surface scatter (see Section 7.7), there
is the issue of sample preparation. How do you determine that your sample really
is, for example, a 95-nm spherical silicon particle and not something else that has
ended up on the sample substrate? Or, if it is silicon—is it spherical? Or, maybe
it is not a particle at all but a surface pit, and the particle of interest is another
100 µm to the left. What if you want to determine the relative effects of variations
in particle index on variations in surface index—how would you prepare those
samples? Modeling is obviously the practical solution to answer questions like
these—if you can get a conﬁrmed model.
Because scatter models of localized surface features are calculation intensive
(and often privately owned), there is no attempt here to derive or even give
equations—that is handled in the literature. Instead, this chapter reviews a couple of
approaches that have been used to create models for particle scanners used in the
semiconductor industry, discusses model conﬁrmation, and gives some example
results. A source of publicly available code is also given. Conﬁrmation techniques
are discussed in Section 7.7.
6.1 Particle Scatter
Scattering models from discrete defects require a number of inputs even for simple
situations. Consider a spherical particle of diameter d on an otherwise perfect
surface with optical constants np and kp. The surface has optical constants ns and ks.
Because it is perfectly smooth, the surface does not scatter any light; however, it
does reﬂect, absorb, and transmit light, and this needs to be part of the model. The
light is incident at θi deg from normal and has a polarization state given by a Stokes
vector. To ﬁnd the particle scatter into direction θs, φs from surface normal, three
109

110
Chapter 6
events must be considered. Some incident light strikes the particle and scatters
directly into direction θs, φs. Additionally, some light from the particle scatters
toward the surface and reﬂects off of it into the θs, φs direction. Scatter also comes
from light that strikes the surface, reﬂects onto the particle, and then scatters in
the θs, φs direction. The model must combine these three sources accounting for
amplitude, phase, and polarization differences. Then, the process must be repeated
for all possible scatter directions in the reﬂective hemisphere—not an easy task.
Unfortunately, the calculation can become even more complicated. Many
substrate surfaces are covered with an oxide or some other transmissive ﬁlm so
that there are two surfaces reﬂecting onto the particle. The particle may also be
covered with a ﬁlm, and it may not be spherical. Scatter from both oblate and
prolate ellipsoids have been modeled. Similar conditions must be considered to
model scatter from isolated surface pits and subsurface voids.
A veriﬁed model can be used for more than just optimizing scanner geometry
and source conﬁguration. For example, signal sensitivity to particle diameter can
be compared to changes caused by particle index (about equal) and substrate index
(much less) by simply running the model a number of times. Imagine trying to
obtain this information experimentally.
6.2 Modeling Techniques and Accomplishments
As indicated previously, much of the light scatter modeling work has been
stimulated by the semiconductor industry. Millions of silicon wafers are
manufactured each month, and they are all measured at least twice with a particle
scanner to assure that they meet cleanliness speciﬁcations. The objective is to
minimize the number of particles with diameters large enough to cause a break
in a conductive line in the circuits that are to be built on the wafer surface. The
diameter limit varies with application, but particles 20 nm and larger are of interest
at the time this book is being published. Scanner calibration and particle “sizing”
associated with these instruments are described in Sections 11.1 and 12.4. Both
scanner calibration and interpretation of results depend heavily on scatter models.
If the scattering objects are tiny compared to a wavelength, then the Rayleigh
approximation applies and each object can be considered as a dipole source.
However, as the scattering particle reaches even a few tens of nanometers in
diameter, the dipole ﬁelds become distorted, and more advanced calculations are
used. Three commonly used modeling calculations are the null-ﬁeld method, the
discrete sources method (DSM) [both well described in Doicu, Eremin, and Wriedt
(2000)], and the Bobbert–Vlieger calculation (Bobbert, Vlieger 1986a, Bobbert,
Vlieger, and Greef 1986b). There are many others approaches and lots of variations
involving a variety of mathematical assumptions.
The DSM technique is based on the concept that the scattering particles can be
replaced by one or more light sources, arranged such that they combine to meet
the required boundary conditions of the situation. These sources are then used to
calculate the scatter pattern in the exterior regions of interest. DSM can be applied
to a lot of different situations, such as particles, pits, ﬁlmed surfaces, etc. Circular

Scattering Models for Discrete Surface Features
111
symmetry makes the calculation easier but is not required. The null-ﬁeld approach,
ﬁrst suggested by Waterman (1965), is similar, but in this case the particle is
replaced by surface currents that produce the required exterior scattered ﬁelds. The
previously mentioned book by Doicu, Eremin, and Wriedt (2000) details many
of the calculations and gives an extensive list of references. The Bobbert–Vlieger
approach is exact for spherical particles, and both the particle and the substrate are
allowed to have one ﬁlm. The three approaches give nearly identical results for
spherical particles on surfaces and have been conﬁrmed by measurement.
Measured and DSM-modeled DSC (deﬁned in Section 1.7) curves from
100-nm tungsten particles are compared in Fig. 6.1. In-plane measurements are
usually considered sufﬁcient to verify the model (Stover, Scheer 2001). Details on
a measurement veriﬁcation technique are covered in Section 7.7. Differences start
to appear between model and measurement as the particle diameter and/or index
are increased, but model improvements are constantly pushing these boundaries.
Figure 6.1 involves the use of a large-incident-angle p-polarized source, which
became common in the particle scanners developed in the mid-1990s. When
illuminated in this manner, particles much smaller than a wavelength tend to
scatter, much like ideal dipoles with doughnut-shaped scatter patterns, giving
relatively large particle signals at angles far from the surface normal. This is
desirable because detectors can then be positioned far from the specular direction,
where roughness scatter is small. The dipole orientation is such that the surface
normal points roughly in the zero-scatter (doughnut-hole) direction. Figure 6.1 is
an incident plane slice through the dipole pattern.
Figure 6.1
Measured scatter from a deposition of several thousand 100-nm tungsten
particles deposited on a silicon wafer is compared to a scatter model based on the DSM.
The source was a p-polarized 488-nm laser incident at 65 deg.

112
Chapter 6
Figure 6.2 shows why small particles illuminated with a p source at a large
incident angle scatter as dipoles. The electric ﬁeld vectors in the light incident
directly on the particle and the light reﬂected from the surface add to polarize the
particle in a direction close to surface normal. Because light is a transverse wave,
the particle cannot radiate (scatter) in the direction of the electric ﬁeld vector, and
the classic dipole pattern is established. The asymmetry in the pattern of Fig. 6.1 is
real and is caused in part by the tendency of larger particles to scatter more in the
forward direction and absorption of the wave reﬂected from the surface. Smaller
lower-index particles have more-equal lobes and dips that are centered closer to 0
deg.
A number of key papers concerning scatter from discrete surface features have
been published in the last couple of decades. In the 1990s, a team led by Dr. Yuri
Eremin at Moscow State University employed the DSM technique to investigate
scatter from silicon wafers. In addition to describing particle scatter, a study was
performed on the scatter from surface pits using DSM (Eremin and Orlov 1996,
1998; Eremin, Orlov, and Sveshnikov 1999; Eremin 2000). Scatter from small
surface pits is quite different from scatter from particles. The space in a pit does
not polarize, and the boundary conditions governing reﬂection and transmission at
a surface result in the electric ﬁeld vectors in the surface plane, regardless of source
polarization. The result is that the surface, broken by a pit, scatters normal to the
surface and scatters less at higher angles than a particle, so a pit scatters more like
a weak Lambertian source, regardless of source incident angle and polarization.
Thus, by using the high-incident angle/p-polarization conﬁguration, and ratioing
the signal from a detector placed near surface normal scatter to that of a high-angle
detector surface, features can be identiﬁed as either pits or particles. Pits have a
ratio larger than 1.0 and particles less than 1.0.
The result was a wafer scanner that was capable of separating surface pits from
surface particles and led to a signiﬁcant patent (Fossey et al. 1995). The distinction
is important because particles come from contamination sources (which can be
Figure 6.2
The vector sum of direct and reﬂected rays polarize the surface-bound particle.
As shown above, the vector sum results in an internal ﬁeld close to surface normal if the
beam is incident at a large angle and is p polarized. Because light is a transverse wave,
the particle cannot radiate in the direction of the electric ﬁeld (polarization) vector, and the
particle reradiates (scatters) into a pattern with a dipole shape.

Scattering Models for Discrete Surface Features
113
found and eliminated from production), and the wafers can be cleaned. Pits, on
the other hand (sometimes called COPs—for crystal-originated particles), cannot
be cleaned and originate from tiny voids created in the bulk silicon before it is cut
into wafers. Discriminating between these surface features from the scatter pattern
was a big step forward in scanner technology. This signiﬁcant accomplishment
was a direct result of the use of veriﬁed models. (A few years later, it resulted in
a nasty legal battle, but that story is better told over a beer than in writing.) Work
has continued to further identify small surface features. In particular, classifying
dielectric, semiconductor, and metal particles is desirable because it would aid in
identifying contamination sources and in calculating true particle size (Ivakhnenko
et al. 2001; Stover, Ivakhenko, and Eremin 2001). Unfortunately, as of this writing,
a combination of issues (true use of calibration standards, particle shape, particle
orientation, and an insufﬁcient number of scanner scatter signals) has prevented a
practical solution from reaching the market.
6.3 Model Availability
Many (probably most) of the scattering models have been written “in-house” and
are not available to the public. Related publications generally give much (but
not always all) of the required background and no working code. Creating code
from scratch and then conﬁrming it is not inexpensive, but research groups are
often left with no other choice. One happy exception is that a number of Thomas
Germer’s modeling codes, created at NIST, are available for free on the Internet at
http://physics.nist.gov/Divisions/Div844/facilities/scatmech/html/. In addition to
the Bobbert–Vlieger approach, a number of other scatter models are available.
There is also a routine called modeled integrated scattering tool (MIST) that allows
the scattering hemisphere to be interrogated with a user-deﬁned scatter collection
aperture. Thus, proposed scanner hardware designs can be “tested and compared”
via modeling before actually building a system. Unfortunately, the NIST website
does not have a scattering model for pits.
Bohren and Huffman (1983) and van de Hulst (1957) are good references for
scatter from isolated particles (not surface-bound). When the particles are small
compared to a wavelength, it is called Rayleigh scatter, and the relationship is
given in Eq. (1.8). Because the particles are small, the scatter pattern is relatively
independent of particle shape. We see an example of Rayleigh scatter every time
we look at the blue sky. Air molecules are more likely to scatter the shorter the
sunlight wavelengths, turning the sky blue and sunsets red.
Scatter from larger particles is more difﬁcult to model because the pattern
depends on particle shape as well as index and wavelength. The special case of
a spherical particle is called Mie scatter, and exact solutions exist. This is one
of the few ways to estimate scatter from larger particles. The above references
also cover Mie scatter. A Mie scatter calculator is available on the Internet at
http://omlc.ogi.edu/calc/mie_calc.html.

114
Chapter 6
6.4 Summary
In the early 1990s, the semiconductor industry started seriously pursuing the use of
scatter models as a way to increase the sensitivity and accuracy of particle scanners.
Discrete feature-scattering models are far more complex than those used for surface
roughness, more difﬁcult to create, and more difﬁcult to conﬁrm experimentally.
On the other hand, their use has allowed for some amazing progress in wafer
particle scanners, and even more progress could be made. A number of models
that are publicly available from NIST can save a great deal of development effort
and expense.

Chapter 7
Instrumentation and
Measurement Issues
“It doesn’t matter how beautiful your theory is, it doesn’t matter how smart you
are. If it doesn’t agree with experiment, it’s wrong.” – Richard P. Feynman
This chapter reviews the methods and equipment used to take scatter
measurements. As pointed out in Section 1.5, the BSDF is deﬁned in differential
form but is measured with the incremental limitations imposed by real
instrumentation. The ﬁnite detector aperture, scatter created by the instrument,
calibration inaccuracies, and other practical equipment limitations, such as noise,
detector nonlinearity, and mechanical errors, all produce noticeable deviations
between the true BSDF and the measured BSDF. In order to generate meaningful
scatter speciﬁcations and fully utilize the data, it is important to understand the
source and magnitude of these deviations. System calibration, an often-discussed
issue, is described in detail. The chapter progresses from these basic concepts to
discussions of other measurement techniques (curved samples, area raster scans,
retroscatter, TIS, and out-of-plane scatter) and concludes with a section on error
analysis. Chapter 1 provides necessary background information for understanding
this material.
7.1 Scatterometer Components
The simple plane-of-incidence scatterometer outlined in Fig. 7.1 contains most of
the components typically found in more-sophisticated systems. These are easily
grouped into four categories: light source, sample mount, receiver (detection
system), and computer/electronics package. A ﬁfth important element is the
controlling software package. This section outlines the need for and general
operation of these modules.
The light source is shown as a laser beam that is chopped, spatially ﬁltered,
expanded, and ﬁnally brought to a focus on the detector path. Lasers are convenient
but unnecessary sources for scatter measurements. The beam is chopped to reduce
both optical and electronic noise. This is accomplished through the use of lock-
in detection in the electronics package that suppresses all signals except those
at the chopping frequency. The reference detector allows the computer to ratio
115

116
Chapter 7
Figure 7.1
Components of a typical BSDF scatterometer.
out light-source power ﬂuctuations and can also be used to provide the necessary
timing signal to the lock-in electronics. In Fig. 7.1, the reference signal is obtained
by measuring the light scattered off of the chopper blade when the beam is
blocked. Polarizers, wave plates, and neutral-density ﬁlters used to adjust the
source beam are also commonly found at this location. The spatial ﬁlter removes
scatter from these elements and presents a near point source that is imaged by the
ﬁnal focusing element to the detector zero position. Although a lens is shown in
Fig. 7.1, the use of a low-scatter mirror, which often works over a larger range of
wavelengths and generally scatters less light, is very common. The spot size on the
sample and location of the source focus are determined by elements of the system
geometry and can be conveniently adjusted by changing the focal length of the
ﬁrst (less-expensive) lens and the position of the pinhole. The lens/spatial ﬁlter
combination is typically adjusted with source wavelength changes. The source
region is completed by a shield that isolates stray source light from the receiver.
The sample mount can be very simple or very complex. In principle, six degrees
of mechanical freedom are required to fully adjust the sample. Three translational
degrees of freedom allow the sample area (or volume) of interest to be positioned
at the detector rotation axis and illuminated by the source. Three rotational degrees
of freedom allow the sample to be adjusted for angle of incidence, out-of-plane tilt,
and rotation about sample normal. In practice, it may prove convenient to eliminate
(or duplicate) some of these degrees of freedom. Exact requirements for these
stages differ, depending on whether the sample is reﬂective or transmissive, as well

Instrumentation and Measurement Issues
117
as depending on size and shape. In addition, some of these axes may be motorized
to allow the sample area to be raster-scanned, to automate sample alignment, or to
measure reference samples. The order in which these stages are mounted affects
the ease of sample alignment and the cost of the sample holder.
The receiver–rotation stage is motorized and under computer control so that the
input aperture can be placed at any position on the observation circle (indicated by
the dotted circle in Fig. 7.1). Data scans can be initiated at any location. Systems
vary as to whether data points are taken “on the ﬂy” or with the receiver stopped,
but unlike the TIS system shown in Section 1.6, the detector is always normal
to the incoming scatter signal. Receiver design varies, but changeable apertures,
bandpass ﬁlters, polarizers, lenses, and ﬁeld stops are often positioned in front of
the detector element. In addition to the indicated axis of rotation, some mechanical
freedom is required to insure that the receiver is at the correct height and pointed
at the illuminated sample. Sensitivity, low noise, linearity, and dynamic range are
the important issues in choosing a detector and designing the receiver housing and
preampliﬁer.
The mechanical structure allowing the relative positioning of source, sample,
and receiver is called a goniometer. Other conﬁgurations are possible. For example,
the source and sample can be rotated as a unit in front of a ﬁxed receiver (Orazio,
Stowell, and Silva 1982), or for reﬂective samples, the scatter pattern can be
moved past a ﬁxed receiver by rotating the sample with the source ﬁxed (Church,
Jenkinson, and Zavada 1977). There is a practical difﬁculty with conﬁgurations
that move the sample and/or the source during the measurement. If the sample
is optically smooth, then the reﬂected beam sweeps about the laboratory during
the measurement. Unless a moving beam dump is designed to track the beam, the
result is a potential safety problem and a large quantity of unwanted stray light
that can become confused with sample scatter (see the next section on instrument
signature).
Although less visible, the electronics/computer package represents over half of
the effort that goes into a well-designed system. Instrument versatility, sample
throughput, and ease of use are all determined by the decisions made during the
design of these elements. Measured BRDF levels from a smooth sample are likely
to vary by as much as 15 orders of magnitude. Even after changes in apertures
and ﬁlters, detector output signals are likely to vary over the entire available linear
range (ﬁve to nine orders of magnitude, depending on the detector), so some form
of data compression or signal processing is needed to obtain the signal through the
A/D converter and into the computer. This usually involves the use of automated
electronic gain changes or a log-conversion device. In more sophisticated systems
these changes are automated, and the computer controls the data-taking process
under the direction of previously entered operator instructions. For example, the
operator might ask for data points to be taken every 0.5 deg over the range of 2
to 85 deg from specular. The aperture size, distance from sample to detector, and
total source power Pi would also be entered so that the BSDF can be calculated.
The specular zero location (position of the focused spot) must be determined prior

118
Chapter 7
Figure 7.2
The BRDF of a molybdenum mirror compared to instrument signature.
to taking data. It is extremely helpful if the computer displays the BSDF during the
measurement process.
The ability to store, analyze, and display data in convenient graphical format is
a key feature of the instrument. An example of BRDF data from a front-surface
mirror is shown in Fig. 7.2. The horizontal axis is a log scale of degrees from
specular (θs −θi), and the vertical axis is a log scale of the BRDF in sr−1. Notice
that the BRDF drops by more than 11 orders of magnitude. Measurements are
typically in the range of 107 to 10−7 sr−1 but can go an order or two lower. The
second plot in Fig. 7.2, labeled Signature, is a measure of light scattered by the
instrument and is clearly a concern for BSDF interpretation in the near-specular
region.
If the angular position of a measurement is referenced to the specular reﬂection
(instead of surface normal), it is much easier to make near-specular measurements.
The scatter pattern will not change much if there is a 1-deg error in incident
angle, but if receiver position is referenced to surface normal, this error makes
it difﬁcult to measure close to specular. The center location of the reﬂected (or
transmitted) specular is found before the measurement is started, and the receiver
is stepped in θs −θi space during the measurement. During analysis, the result can
be converted back to θs space. The next section discusses the causes, measurement,
and interpretation of instrument signature.
7.2 Instrument Signature
The instrument signature is a combination of several factors. The signature data
of Fig. 7.2 was measured by removing the sample and then scanning the incident
beam after it passes through the empty sample holder. It is plotted on a log–log
scale to emphasize the near-specular region, where signature light is usually
strongest. The signature proﬁle differs from that of an ideal diffraction-limited
spot for three reasons: light scattered by the instrument is included in the measured

Instrumentation and Measurement Issues
119
proﬁle; the spot contains aberrations caused by the focusing element (in this case,
a mirror) and is not truly diffraction limited; and, as discussed in Chapter 1, the
measured proﬁle is broadened because it is actually the convolution of the ﬁnite
receiver aperture with the focused spot. The ﬁrst two effects are discussed here,
and convolution broadening, which affects sample scatter as well as signature, is
covered in Section 7.3.
Although both stray source light and room light contribute to signature, the
source is a more severe problem because it easily passes through the detector ﬁlter
and lock-in electronics. Figure 7.3 shows where stray laser light is generated and
how it mixes with the measured scatter signal. The dotted line represents scatter
signal from the sample that will pass through the receiver aperture to become the
measured signal. The shaded lines represent stray laser light within the system
that can potentially contribute to instrument signature. The ﬁnal source-focusing
optic is a source of scatter, and its own BSDF will be added to the sample
scatter. However, this signature contribution is reduced relative to sample scatter
because of the longer distance to the receiver. Once the aperture is moved just
off of the focused spot, the detector face becomes a scatter source illuminating
the hemisphere in front of the detector. Every object within the detector ﬁeld of
view is illuminated and becomes a source of instrument signature. Of particular
importance are the sample holder and the system-output spatial ﬁlter. The latter
has the focused spot imaged onto it by the focusing optic. Methods of reducing
signature include beam dumps, limiting the detector ﬁeld of view, and using black
surfaces at every possible location (including the output spatial ﬁlter). These issues
will be discussed further in Section 7.4 on near-specular measurements.
The second source of signature is broadening due to aberrations induced by the
focusing element. Ideally, this effect can be eliminated by using diffraction-limited
optics. However, because spherical mirrors and lenses are usually lower scatter
than aspherical reﬂectors or multielement lenses, the less-expensive elements often
produce lower signatures. This means that minimizing aberrations through system
geometry is often a design issue. Although aberrations can be predicted from
geometrical considerations and as such are independent of wavelength, the width
Figure 7.3
Stray scattered light represented by the shaded arrows mixes with the
measured scatter signal.

120
Chapter 7
of a diffraction-limited spot increases with wavelength so the effect of aberrations
is lower in the IR than in the visible. Figure 7.4(a) shows a signature scan taken at
0.6328 µm with a 50-cm-radius spherical mirror used to focus the spot. The spot
shape, as found by a raytracing program and shown in Fig. 7.4(b), is asymmetrical
because of comatic and spherical aberrations introduced by the mirror. This effect,
seen also in the near-specular data of Fig. 7.4(a), starts to become apparent less
than one order of magnitude below the peak. If very near-specular measurements
are required from this instrument, they should be taken on the low-aberration side
of specular. At about 0.1 deg from center, the signature is dominated by scatter
from the focusing mirror, and this continues until the mirror is out of the detector
ﬁeld of view by about 2 deg from specular (see Fig. 7.2). This location, dubbed θN
in the literature (Klicker et al. 1987), will be calculated from system geometry
in Section 7.4. Beyond θN, the signature is dominated by the electronic noise
ﬂoor if care is taken to avoid stray light. On BSDF plots, the noise ﬂoor slowly
rises at higher angles as cos θs decreases. The electronic noise-equivalent BSDF
(sometimes called NEBSDF) is discussed in Section 7.5.
7.3 Aperture Effects on the Measured BSDF
The true BSDF is a complex three-dimensional intensity pattern. Not only does its
intensity generally vary by several orders of magnitude, but it often contains a great
deal of structure. As we have seen, this structure is directly related to the surface
or bulk defects under investigation, so it is important to understand any deviations
between the actual BSDF and the measured results. As indicated in Section 1.5
Figure 7.4
Instrument signature and aberration. (a) Near-specular signature contributions
from aberrations. (b) Comatic and spherical aberration from a mirror.

Instrumentation and Measurement Issues
121
and implied by the approximation sign in Eq. (1.8), there is an inherent error in
the measurement process. This error, known as aperture convolution, is due to the
ﬁnite size of the receiver aperture.
The effect is easily demonstrated near specular, as shown in Fig. 7.5. Here,
four measurements were made of the same focused spot, using circular receiver
apertures of four different diameters. The results are dramatically different. The
peak value decreases by two orders of magnitude as the aperture diameter is
increased from 100 to 2540 µm. The width at the half-power points does just the
opposite. Which one is correct? In a certain sense all of them, and in a different
sense none of them, are correct.
The BSDF at each measurement location is calculated according to Eq. (1.8),
repeated below as Eq. (7.1) for convenience. The value Ps is treated as the average
over Ωs and the calculated BSDF assigned to the position θs. If the aperture is
larger than the focused spot and centered on it, then Ps is nearly Pi, and the BSDF
approaches the constant 1/Ωs. Essentially the same value will be obtained for
any position θs that allows a particular aperture to capture most of the focused
specular light. It will be shown below that reducing the aperture to zero does not
result in an inﬁnite measured BSDF. The distance from aperture to sample was
R = 51 cm for these measurements, which, as graphed in Fig. 7.5, gives the value
1/Ωs = R2/πr2 = 12, 839 for the 2540-µm aperture. As the aperture diameter
is decreased, the ﬂat section becomes shorter. At 100 µm, the aperture is about
the size of the focused spot. The 100-µm aperture comes closest to the actual
BSDF, although even it is in error. If one treats the plots as the convolutions of
the apertures with the BSDF, then all four plots are correct. A good approximation
is that the measured specular beam width at the half-power points is equal to the
Figure 7.5
The effect of aperture convolution on signature measurements.

122
Chapter 7
true half-power spot diameter plus the aperture diameter:
BSDF =
Ps/Ωs
Pi cos θs
.
(7.1)
Beyond a few tenths of a degree the curves converge, although the 100-µm
aperture data has a lot more structure associated with it. The structure is actually
there; you see it as laser speckle. In order to measure it, a small aperture must be
used because larger apertures average it out. The data were taken by moving the
receiver in one-third-aperture steps. The price paid for resolving the structure is
additional time and data. Notice that all four plots in Fig. 7.5 exhibit the aberration-
induced asymmetry of Fig. 7.4. The slopes of the four curves as the spot leaves the
aperture are almost identical. If the four curves were integrated, nearly the same
result would be achieved for each curve (remember the log scale and out-of-plane
contributions).
The advantage of a large aperture in low-light-level conditions is that the signal-
to-noise ratio is increased. The practical upper limit is usually imposed by the
clear aperture of the optics behind the receiver aperture. Typical maximum aperture
sizes are 1 to 5 deg in diameter (as measured from the sample). If the aperture is
increased to cover the entire hemisphere in front of the sample, then the measured
BSDF is just the total reﬂectance (specular and diffuse) divided by 2π.
Occasionally, it makes sense to reduce the aperture to very small sizes. This
is true for some of the near-specular measurements described in Section 7.4.
However, the smallest aperture is usually kept larger than the focused specular spot
because of some unwanted structure that is often imposed on the scatter pattern. If
the scatterometer light source is a laser, there will be a speckle pattern modulating
the BSDF that depends on source characteristics as well as sample characteristics.
Speckle diameter will be about one half of the focused spot diameter. If the aperture
is kept large enough to accept several speckles, then this effect is averaged out.
Minimum apertures are typically 0.01 to 0.1 deg in diameter.
The maximum measurable BSDF has been found (Schiff et al. 1988) by
analyzing the characteristics of the focused laser spot at the receiver aperture. For
a Gaussian beam, the magnitude of the electric ﬁeld in the focused spot is given as
|E| = E0e−r2/ω2
0,
(7.2)
where E0 is the electric ﬁeld value at beam center, r is the radial distance from
beam center, and ω0 is the beam radius at the point where the ﬁeld has dropped by
e−1 from center. The value of ω0 is given as
ω0 = 2λR
πD ,
(7.3)
where R is the detector sweep radius, and D is the illuminated sample spot diameter.
The measured value of Ps is found by integrating the square of the electric ﬁeld

Instrumentation and Measurement Issues
123
(divided by twice the impedance of free space) over Ωs. Applying this process to
Eq. (7.1) gives an expression for the maximum measurable value of the BSDF:
BSDFmax =
Ps
PiΩs
= (1 −e−2r2/ω2
0)R2
πr2
.
(7.4)
If the detector aperture radius is larger than the beam waist radius (r > ω0), then
the maximum measurable BSDF is approximately the inverse of the solid angle
1/Ωs, as previously noted. The maximum measurable value goes up as the detector
aperture goes down. A limit is approached for the maximum possible measurable
BSDF as the detector aperture radius is reduced to zero:
BSDFmax(r = 0) = 2R2
πω2
0
= πD2
2λ2 .
(7.5)
This is an interesting result because it gives the maximum measurable BSDF
independent of instrument geometry. For a 5-mm spot on the sample at a
wavelength of 0.633 µm, this is 9.8 × 106 sr−1. The values predicted by Eq. (7.5)
are difﬁcult to reach experimentally because the focused spot is usually aberration
broadened; however, values exceeding 50% of this theoretical maximum are not
uncommon.
The effects of using small but ﬁnite apertures to measure the differential BSDF
have been shown to vary from rather inconsequential to very signiﬁcant. These
difﬁculties are especially severe in regions where there are large intensity variations
over the receiver aperture. Near-specular measurements, described in the next
section, are a good example of BSDF data that should be viewed with these
limitations ﬁrmly in mind.
7.4 Signature Reduction and Near-Specular Measurements
The reduction of near-specular scatter from optics has become an increasingly
important issue. Near-specular scatter is particularly troublesome in systems where
high-resolution imaging is required. Modern spacecraft and aircraft optics often
need to meet these types of requirements in the visible and the IR. Until the mid-
1980s, scatter measurements closer than 1 or 2 deg from specular were difﬁcult or
impossible to obtain because of the uncertainties caused by instrument signature.
However, as equipment was developed to the point where sample scatter could be
separated from instrument signature, these measurements became possible (Stover,
Cady, and Sklar 1985; Cady et al. 1988; Klicker, Stover, and Wilson 1988). The
techniques involve reduction of signature light through proper system design and
reduction of measured specular beam width (by reducing the diameter of both the
aperture and the focused specular beam).
This section addresses the issues associated with the causes of instrument
signature and suggests several methods for its reduction. For the purposes of this
discussion, it is assumed that the input specular beam is focused in the detector

124
Chapter 7
aperture plane so that the aperture is in the diffraction far ﬁeld. Most scatterometers
achieve the focused spot by imaging the light from a spatial ﬁlter with an objective
mirror (or lens) onto the detector–aperture plane. These arrangements are shown
in Fig. 7.6. There are four possible sources of signature light in such a system:
(1) light leaving the focused specular beam due to reﬂections in the lens, (2) stray
light scattered from the specular beam at the receiver, (3) scatter associated with
the focusing optic, and (4) aberrations and diffraction associated with the focusing
optic. Without proper treatment, even just one of these sources can signiﬁcantly
affect the ability to measure sample scatter near the specular beam.
Section 7.4.1 examines the choice of whether to use a lens or a mirror to focus
the beam and concludes that a mirror is the better choice. Section 7.4.2 discusses
the use of apertures to limit the extent of near-angle scatter. The most effective way
to accomplish this is to limit the detector ﬁeld of view. An expression is found for
the maximum angle θN from specular over which near-specular signature light is
expected to play a signiﬁcant role. Reduction of signature at observation angles
inside θN is the topic of Section 7.4.3. Light scattered from the focusing element
presents the largest problem.
7.4.1 Reﬂective versus refractive focusing optics
Two conﬁgurations of focusing optics are shown in Fig. 7.6. One illustrates the use
of a lens, while the other uses a mirror as the ﬁnal focusing element prior to the
sample. Comparisons between these two conﬁgurations are made assuming that
the system is constrained to ﬁt on a 4 × 8-ft optical table. Using a mirror for the
focusing element folds the system and allows for the use of longer focal lengths.
Of the four contributors to instrument signature, light reﬂected off of the lens
surfaces is present only in the refractive system. Reﬂections off of the lens surfaces
result in three cones of light superimposed on each other. The ﬁrst cone is due
to a double reﬂection that proceeds forward to the detector. The other two are
reﬂections from each individual lens surface that propagate in the reverse direction
and illuminate the spatial ﬁlter. The illuminated region around the spatial ﬁlter is
imaged in the detector plane, creating signature light. These reﬂective sources of
light have been examined in detail through the use of a raytracing program (Klicker
et al. 1987) and have been found to be quite severe for lenses of all shapes. There is
no choice but to eliminate these reﬂections through the use of antireﬂection (AR)
coatings on the lens. Unfortunately, these coatings tend to be higher scatter than
the surfaces they cover.
Another contribution to signature is stray light scattered into the system
when the specular beam reﬂects off of the receiver aperture housing. This light
illuminates virtually everything within the ﬁeld of view of the detector. There will
be little difference between using a lens or a mirror.
Scatter associated with the focusing element clearly contributes to the
instrument signature light. The mirror scatters light from one surface. The
lens scatters from two surfaces and its bulk. Similar single-surface scatter
characteristics are expected for the best spherical metal and dielectric surfaces,

Instrumentation and Measurement Issues
125
Figure 7.6
Geometrical conﬁgurations: (a) shows the lens conﬁguration of a scatterometer,
and (b) shows the mirror conﬁguration of a scatterometer.
so the best lens probably has more scatter than the best mirror. In addition, as
mentioned above, the lens must be AR coated, which usually increases the scatter.
The angular distribution of the scattered light and distance to the detector also play
a role, as will be described later.
The fourth source of signature light is due to focused spot aberrations and
diffraction. Because spherical surfaces can be made lower scatter than aspheres,
they are often chosen, and aberrations result. The specular point source (spatial
ﬁlter) can be located on the principal axis of the lens so that off-axis aberrations
such as coma and astigmatism are not present in the refractive system. This is
not true for the mirror, which must be tilted to separate the incident and reﬂected
beams.

126
Chapter 7
Table 7.1
Lens/mirror signature comparison.
Source
Lens
Mirror
Lens reﬂections
AR elimination
Nonexistent
Stray specular light
Equal
Equal
Scattered light
Slightly larger
Slightly smaller
Aberrations
Large
Small
The aberrations associated with the two systems can be compared using spot
diagrams produced by a raytracing program. The comparison is made with the two
conﬁgurations constrained to ﬁt on a 4 × 8-ft table. The angle of convergence of
the focused beam at the detector is kept the same for each case. This allows the
relationship between sample spot size 2ωs and sample-to-receiver distance R to be
identical for the two cases. (This is an important consideration, as will be shown
in the next section.) The distance from the focusing element to the receiver L was
150 cm for the lens and 250 cm for the mirror. The two cases have been examined
through the use of a raytracing program. Spot diagrams, taken in and near the
focal plane, are shown in Fig. 7.7 for each conﬁguration. Notice that the scales are
different for the lens spot diagram. The lens was optimized for minimum spherical
aberration (nearly plano-convex); however, even for this situation, it produces a
considerably larger aberrated spot than the mirror. This is true even though the
mirror produces both astigmatism and coma in addition to spherical aberration.
Mirror tilt was minimized to reduce aberrations. The size of the diffraction-limited
spot for this geometry is also shown. For a ﬁxed R, as 2ωs decreases, the aberrations
decrease, and the diffraction limit increases. This effect is considered further in the
next section. Table 7.1 summarizes the signature comparison of the reﬂective and
refractive systems. The mirror conﬁguration is clearly superior.
7.4.2 Minimizing the near-angle/far-angle boundary θN
The measured contributions to instrument signature from spot aberrations and
diffraction can normally be conﬁned to within a few tenths of a degree from
specular by choosing a suitably small receiver aperture. The scatter contribution
from the focusing optic extends much farther out and determines the boundary
angle θN beyond which the near-specular contributions to signature are greatly
reduced. θN is deﬁned as the angle from specular at which the illuminated spot on
the focusing element has left the receiver ﬁeld of view. Examination of Fig. 7.8
makes it clear that when the receiver is close to the specular beam, it can look
through (or off of) the sample and see scattered light coming from the focusing
optic. As the receiver moves away from specular, the sample holder (or any
other beam aperture) blocks this light from reaching the detector and reduces
the signature. The maximum receiver angle θN at which light scattered from the
focusing element contributes to the instrument signature is a function of instrument
geometry and can be found from Fig. 7.8, which shows the detector located at θN.
Scattered light works its way from the top of the focusing element (radius rm)
through the bottom of the sample (radius rc) and just into the edge of the receiver

Instrumentation and Measurement Issues
127
Figure 7.7
(a) The circular focused spot from the lens is enlarged to about 1-mm diameter
by spherical aberration. (b–d) Off-axis aberrations associated with a focusing mirror cause
the spot to change shape along the focus path, but the largest dimension is about 0.06 mm,
which is considerably smaller than the spot formed by the lens.
aperture (radius rs), whose ﬁeld of view is limited by the sample holder. The small-
angle approximation sinθ = θ has been made throughout the derivation:
θN = (rm + rc)
L
+ (rc + rs)
R
−rc
F .
(7.6)
The last term covers the special case of a sample with focal length F (F > 0
for a converging sample) and is derived under the assumption that the source
optics are adjusted to bring the specular beam back to focus after the sample is
inserted (Klicker, Stover, and Wilson 1988). Substituting typical component values
of R = 50 cm, L = 100 cm, rm = 5 cm, rc = 2 cm, rs = 0.2 cm, and F = 4 gives a
value of 6.5 deg for θN, which is fairly large. This can be reduced by limiting the
receiver ﬁeld of view to an area on the sample a little larger than the illuminated
spot and by considering the effective mirror size to be limited to its illuminated
portion. Assuming a Gaussian beam of radius ωc (e−2 power point) at the sample,

128
Chapter 7
Figure 7.8
Geometry for the calculation of θN.
the designer might choose to limit the ﬁeld of view to a value twice that size, or
rc = 2ωc. In a similar fashion, the effective mirror radius is chosen as twice the
beam radius at the mirror (rm = 2ωm). Because the beam is focused at the receiver,
the two beam radii are related as Ωm = Ωc(R + L)/R. Substituting into Eq. (7.6)
gives
θN = 4ωc
 1
L + 1
R
!
+ rs
R ,
(7.7)
which has been presented by other authors after making slightly different
assumptions (Lee, Scherr, and Barsh 1986). Using ωc = 0.2 cm gives θN = 1.6 deg,
which is much better. After dropping the ﬁrst and last terms, which are smaller, the
result is
θN > 4ωc
R
= the observed source convergence angle,
(7.8)
which is a convenient design rule for near-specular scatterometers.
Figure 7.9 illustrates a simple method of restricting the ﬁeld of view to the
region around the illuminated spot. A lens behind the receiver aperture images
the illuminated sample onto a ﬁeld stop. The ﬁeld-stop aperture is then the receiver
ﬁeld-of-view limit and acts to limit θN. Restricting the detector ﬁeld of view in this
manner also eliminates the stray light reﬂected off of the sample mount. When this
receiver system is used, the receiver solid angle is deﬁned by the detector aperture,
and the ﬁeld of view does not change as the receiver aperture is increased.
7.4.3 Scatter measurement inside θN
Signature contributions inside θN can be reduced by obtaining a focusing mirror
that is low scatter near specular. This Catch-22 situation (it takes one to measure

Instrumentation and Measurement Issues
129
Figure 7.9
Limiting the detector ﬁeld of view to the region around the illuminated spot.
one) was confronted in the mid-1980s as the ﬁrst near-specular scatterometers
were built (Stover, Cady, and Sklar 1985; Cheever et al. 1987). As mirror quality
improves, so will the scatterometers that measure them. Using low-reﬂectance
materials for the receiver aperture and the source output spatial ﬁlter will also
reduce near-specular signature.
In order to measure near the focused specular beam, a small receiver aperture
must be used. Very near-specular measurements can make use of apertures that
are about the same diameter as the focused spot. Apertures less than 0.1-deg
wide are not uncommon, and apertures as small as 0.003 deg have been used.
Away from specular, the apertures must be larger so that the individual speckles
inherent in scatter patterns from laser sources can be averaged out and, as discussed
in Section 7.5, so that the noise equivalent BSDF can be reduced. Because the
measurements can change rapidly near specular, the data points are spaced less than
an aperture width apart. To avoid convolution discontinuities, the aperture changes
should be made on relatively ﬂat sections of the BSDF. And, for the comparison
between signature and sample data to be meaningful, the aperture changes should
come at the same locations for each scan.
Figure 7.10 shows near-specular scatter data taken on a TeO2 Bragg cell (Cady
et al. 1988) at a wavelength of 0.86 µm. Separation from the instrument signature
was achieved at about 0.009 deg from specular. Three scatter regions have been
identiﬁed on the plot corresponding to signature scatter, bulk scatter, and surface
scatter. Near-specular data from reﬂectors can be converted to surface statistics via
the reasoning of Chapters 3 and 4. The grating equation [Eq. (1.6)] is used to ﬁnd
the associated spatial wavelengths:
1
f =
λ
(sin θs −sin θi),
(7.9)
which gives a surface wavelength of 4.9 mm at 0.86 µm and 0.01 deg. It would
appear from Eq. (7.8) that the maximum-observable spatial wavelengths could be
increased even further by increasing the source wavelength. However, an increase
in source wavelength results in a larger diffraction-limited spot with a resulting
increase in the separation angle. Another approach (Stover and Bernt 1992) is

130
Chapter 7
Figure 7.10
Near-specular scatter measured at 0.86 µm from a TeO2 Bragg cell.
to increase the angle of incidence. The difference in angles (determined by how
close the receiver can approach the specular center without being dominated by
signature effects) remains the same, but the difference in the sines of the angles
is smaller. This results in the ability to measure ﬁrst-order diffraction from longer
spatial wavelengths. Another way to look at this effect is that diffraction peaks
move farther from the specular beam as the incident angle is increased.
7.5 Scatter Screens
Holding a scrap of paper in front of the illuminated sample allows visualization
of details in the scatter pattern on a screen. The technique is old and was in use
long before the introduction of TIS systems. A better method uses a relatively
large screen with a hole at its center so that the specular beam can pass out of
the viewing area and increase visibility of the pattern. Such screens are standard
fare in most scatterometer laboratories and are used for sample alignment as well
as determining the nature of the sample. For example, the presence of a periodic
diffraction pattern quickly reveals that the sample has a periodic component and
can be used to orient the sample so that the pattern falls in the incident plane
where it can be easily measured. Another common use is observation of the speckle
pattern off of the sample (or the receiver) to determine if the beam is focused on the
sample (or receiver). Speckles reach a maximum size when the illumination spot is
at a minimum; this is a very sensitive technique to correctly adjust the source light.
Scatter screens can be viewed in either reﬂection or transmission.
Instrumentation can also be based on scatter screens. Arizona State University
researchers used a frosted hemisphere as a scatter screen to reveal scatter patterns
from submicrometer surface-bound particles in the 1980s (Stover 1980s). The
patterns were photographed and revealed striking differences dependent on particle
diameter and material. In 1991 the author designed an instrument using a scatter
screen with a specular pass-through hole to accept (or reject) low-scatter mirrors

Instrumentation and Measurement Issues
131
used in commercial particle scanners (unpublished). A silicon diode was used to
monitor near-specular scatter from the test mirror that reﬂected off the scatter
screen. Most of the scatter from optically smooth surfaces appears within 20 or
30 deg of specular, and a full integrating-sphere system is not required. In a later
project, the author designed a scatter screen demonstration that let customers (and
engineers) understand how the scatter signal from a surface scratch changes with
scratch orientation. The demonstration was used to explain to customers why
some scratches were easy to detect and some were not. In that particular case, a
competing manufacturer of a particle scanner was completely missing the scratch
signal for scratches oriented nominally parallel to the wafer edge.
More recent innovations involve the use of scatter screens to monitor changes
in product scatter patterns that can be related to product (surface) appearance (see
Section 10.2).
7.6 The Noise-Equivalent BSDF
The minimum-measurable BSDF, limited by electronic noise, has also been
investigated (Schiff et al. 1988) and is discussed here. By careful design of the
system electronics, it is often possible to reduce the noise to the point where it is
dominated by detector noise. For this case, the noise can then be expressed as a
function of the detector alone in terms of its noise-equivalent power (NEP). The
NEP, or apparent light noise signal, of the detector can be found from either of the
following relations:
NEP =
A1/2
d
D∗
(7.10)
NEP = In
Rk
,
(7.11)
where D∗, Ad, In, and Rk are the detector detectivity, active area, noise current,
and responsivity, respectively. NEP has units of watts per square root hertz.
The equivalent total noise power PN at the detector is found from the NEP by
multiplying by the square root of the system noise bandwidth BWN:
PN = NEP
p
BWN.
(7.12)
The noise bandwidth of the system is found by approximate numerical analysis
techniques (Krauss, Bostian, and Raab 1980) and is greater than the normal signal
bandwidth. An expression for the noise bandwidth of a lock-in ampliﬁer/digital
numerical integration combination (common to these systems) is
BWN =
1.57
(TI + 2πTC),
(7.13)

132
Chapter 7
where TI is the digital integration time, and TC is the lock-in ampliﬁer output time
constant.
The noise-equivalent BSDF (NEBSDF) can then be expressed in terms of the
detector noise PN:
NEBSDF =
PN
PiΩs cos θs
.
(7.14)
The NEBSDF can be reduced by increasing either the total incident power Pi or
the receiver solid angle Ωs. Values approaching 10−9 sr−1 can be achieved with a
5-mW HeNe laser and a silicon detector, and 10−11 sr−1 (electronic noise limit) can
be realized with a photomultiplier.
The ﬁnal source of background noise that limits measurable BSDF is Rayleigh
scatter from air molecules and particulates in the volume, deﬁned by the
intersection of the ﬁeld-of-view cone and the incident, transmitted, and reﬂected
beams. The size of the observable illuminated volume is increased dramatically
when the receiver is near a specular beam. In these regions, the scatter signal
is dominated by the instrument signature effects discussed in the preceding
section. At higher-scatter angles, however, the noise ﬂoor can be limited by either
particulate or molecular scatter. These various associated effects are shown in
Fig. 7.11, where four measurement scans through the specular beam and 160 deg
beyond are shown. The bottom measurement, which does not have a specular
peak, was made with the receiver aperture blocked and constitutes a measurement
of electronic NEBSDF as deﬁned in Eq. (7.13). Notice that this measurement is
very random. The highest of the three instrument signatures was made without a
clean air ﬁlter, and the source polarized perpendicular to the measurement plane at
0.633 µm. A second measurement was made with the same polarization, with most
of the source beam in a down wash of clean air from a high-efﬁciency particulate
air (HEPA) ﬁlter. The ﬁlter reduces the high-angle scatter by about an order of
magnitude. The measurement is still well above the electronic noise ﬂoor and is a
measure of Rayleigh scatter from air molecules. To demonstrate that this is indeed
the effect, the source polarization was rotated 90 deg to place the electric ﬁeld
vector in the measurement plane. At a scatter angle 90 deg from specular, the
receiver looks directly into the electric ﬁeld vector. Because light is a transverse
wave, single-scatter events cannot propagate in this direction, and the measurement
drops to the electronic noise ﬂoor. This behavior is predicted by Eq. (1.8) and
Fig. 1.5.
Rayleigh scatter from gases [Eq. (1.8)] has been expressed as BSDF (Asmail
et al. 1994) from an illuminated volume of gas in terms of the illuminated length
L in the ﬁeld of view, the gas index of refraction n, and the molecular density N
(n = 1.000293 for air, and N = 2.68 × 1019 molecules/cm3 for all gases, both at
standard temperature and pressure). That result is repeated here for the case of the
cosine-corrected BSDF [which avoids the awkward situation of a nonzero scatter

Instrumentation and Measurement Issues
133
Figure 7.11
Comparison of instrument signature, with ss and pp source/receiver
combinations, to the electronic noise ﬂoor. The peak at 11 deg was caused by a specular
glint off of an external polarizer at the receiver. The high-angle BRDF signal is caused by
Rayleigh scatter from air molecules. At 90 deg from specular, scatter from the p-polarized
source drops into the electronic noise as expected.
signal and division by cos(90 deg)] in this notation as
Ps/Ωs
Pi
= 4π2L(n −1)2
λ4N
 ℘Lab
℘Std
!
.
(7.15)
The factor (℘Lab/℘Std) has been included here to correct for lower pressure at
altitudes above sea level (0.89 in Bozeman, Montana). For the scatterometer of
Fig. 7.11 at 0.633 µm and L = 4.6 mm, viewing perpendicular to the beam,
the calculated BSDF from air is 3.2
× 10−9 sr−1, which is very close to the
corresponding experimental value of 3.1 × 10−9 sr−1. No correction was made for
the slightly elevated laboratory temperature. As pointed out by Asmail laboratory
et al. (1994), and as Fig. 7.11 indicates, Rayleigh scatter from the air can represent
a more severe limitation than electronic noise for many measurement situations.
It is important to realize that the electronic noise signal is statistical in nature, as
can be seen by examining Fig. 7.11. The signal is due to random electronic noise
ﬂuctuations and will not repeat if the signature is remeasured. Therefore, its level
should be expressed as an rms value. The rms value of such signals is deﬁned just as
it was for surface topographies in Eq. (2.3). The rms value of a random noise signal
can be estimated with reasonable accuracy as one-third of the peak signal value.
Thus, NEBSDF should be given as an rms value in speciﬁcations. By contrast, the
scans taken with the aperture uncovered that are the result of averaging signals
from many scatter events (particulates, molecules, etc.) are far more uniform in
measured BRDF value.

134
Chapter 7
7.7 Measurement of Scatter from Discrete Surface Features in
DSC Units
The DSC was deﬁned in Section 1.7 as a way to meaningfully quantify scatter from
discrete surface features:
DSC  Ps/Ωs
Ii
.
(7.16)
The purpose of this section is to explain how to obtain the feature DSC from BRDF
measurements that are a summation of scatter from the surface feature and the
surrounding (illuminated) surface.
Two BRDF scans need to be taken. The ﬁrst is with the feature centered within
the illuminated spot. This is accomplished by moving the sample laterally in both
the X and Y directions until a maximum signal is obtained. If the maximum is
not clearly deﬁned, then the illuminated spot is too large and must be reduced to
put more light on the feature. If the wavelength is visible, the maximum defect
signal can usually be determined by eye. The second scan is taken after moving the
sample laterally by at least a couple of illuminated spot widths. This second scan
represents the background signal (or noise) in the ﬁrst scan that was not caused
by the feature. Then, point by point, the second scan is subtracted from the ﬁrst to
obtain the net feature BRDF. Often the background is small enough that it can be
ignored. By combining Eqs. (7.1) and (7.16), the DSC is then found as
DSC = [NetBRDF] cos θsπω2
0,
(7.17)
where Ii is Pi/πω2
0, and ω0 is the e−2 intensity radius of the illuminated spot on the
sample. The radius ω0 is usually expressed in micrometers, giving the DSC units
of µm2/sr.
The value of ω0 can be found experimentally by moving the surface feature in
the Y direction completely through the illuminated spot while recording the signal
at a ﬁxed receiver direction. The resulting bell-shaped curve (superimposed above
a noise background) will have an e−2 diameter of 2ω0.
This technique can be used to refute or conﬁrm discrete feature scatter models.
It has been used effectively to conﬁrm modeling of scatter from polystyrene latex
(PSL) spheres on silicon, as shown in Fig. 7.12 (Stover, Scheer 2001).
7.8 Measurement of Pi and Instrument Calibration
Regardless of the type of BSDF measurement, the degree of conﬁdence in
the results is determined by instrument calibration as well as by attention to
the measurement limitations previously discussed. Scatter measurements are
often received with considerable skepticism. In part, this has been due to
misunderstanding of the deﬁnition of BSDF, differences in units, and confusion
about various measurement subtleties such as instrument signature or aperture
convolution. However, quite often the measurements have simply been wrong,

Instrumentation and Measurement Issues
135
Figure 7.12
The smooth line is the result of a computer model of scatter from 204-nm
PSF spheres illuminated with a p-polarized 488-nm laser. The irregular plot is found from a
BRDF measurement and Eq. (7.17).
and the skepticism is justiﬁed. The results of several round-robin measurement
comparison studies (Young 1975; Leonard and Pantoliano 1988; Leonard,
Pantoliano, and Reilly 1989) attest to the difﬁculties associated with these
measurements. As with many new metrology techniques, these problems are
overcome once they are understood.
Instrument calibration is often confused with the measurement of Pi, explaining
why these topics are covered in the same section. To understand the source of
this confusion, it is necessary to ﬁrst consider the various quantities that need to
be measured to calculate the BSDF. From Eq. (7.1), they are Ps, θs, Ωs, and Pi.
The ﬁrst two require measurement over a range of values. In particular, Ps, which
may vary over many orders of magnitude, is a problem. In fact, linearity of the
receiver to obtain a correct value of Ps is a key calibration issue. Notice that an
absolute measurement of Ps is not required, as long as the Ps/Pi ratio is correctly
evaluated. Pi and Ωs generally take on only one (or just a few) discrete values
during a data scan. The value of Ωs is determined by system geometry. The value
of Pi is generally measured in one of two convenient ways.
The ﬁrst technique, sometimes referred to as the absolute method, makes use
of the scatter detector (and sometimes a neutral density ﬁlter) to directly measure
the power incident upon the sample. This method relies on receiver linearity over
the full dynamic signal range between the specular and high-angle scatter and on
ﬁlter accuracy if one is used. The second technique, sometimes referred to as the
reference method, makes use of a known BSDF reference sample (usually a diffuse
reﬂector and unfortunately often referred to as the calibration sample) to obtain the
value of Pi. The reference sample scatter is measured, and the result used to infer
the value of Pi from Eq. (7.1). This method depends on knowing the absolute BSDF
of the reference. It also depends on receiver linearity but not over as wide a range.

136
Chapter 7
The choice of methods is usually determined by whether it is more convenient to
measure the BSDF of a reference or the total power Pi. Both are equally valid
methods of obtaining Pi. The use of reference samples is an excellent system
check regardless of what method is used to measure Pi. Signature measurement is
another good check on whether the instrument is performing as expected. Neither
the absolute method, the reference method, nor the system checks constitutes a
system calibration. This is because calibration issues such as an error analysis and
a linearity check over a wide range of scatter values are not addressed over the full
range of BSDF angles and powers when Pi is measured.
System calibration requires an error analysis on the four quantities in question.
In order to accomplish this for Ps, the receiver transfer characteristic, signal-
out as a function of light-in, must be obtained and checked for linearity. This
may be obtained through the use of a known set of neutral density ﬁlters or
through the use of a comparison technique that makes use of two data scans,
with and without a single ﬁlter (Cady et al. 1989b). Section 7.11 outlines an error
analysis for BSDF systems. Full calibration is not required on a daily basis. Sudden
changes in instrument signature are an indication of possible calibration problems.
A diffuse sample with nearly constant BRDF is a good reference choice for the
measurement of Pi but a poor one for checking system calibration. A better choice
is measurement of a reference sample that varies over several orders of magnitude.
It is prudent to take reference scans before measuring new samples in case the
validity of the data is questioned at a later date.
Wavelength and angle-of-incidence scaling can be excellent checks of
instrument calibration. In order for the check to work, the scaling properties of a
sample must be known. Topographic scaling of smooth, clean, reﬂective samples,
as described in Chapters 4 and 5, is the easiest check to make. Not all front-surface
mirrors will scale topographically because of other sources of scatter (Stover
et al. 1989; Stover and Bernt 1993). Many thinly coated optics do not scale, and
beryllium mirrors do not scale. Solid molybdenum mirrors have been shown to
scale from the blue to the near IR. Silicon, gold, and copper scale in the near
IR to UV. Aluminum mirrors do not scale. Softer materials are a poor choice for
reference mirrors because they can be damaged with cleaning. A silicon carbide
mirror that scales would be an excellent choice because its hardness resists damage,
but it appears to scatter much like beryllium.
An ASTM standard on BRDF measurements has now been published (ASTM
1991). This standard calls for the same calibration checks outlined above.
Its publication is a reﬂection of government and industry policies that will
require more formal assurances of accuracy in both scatter instrumentation and
measurements; however, it is written noting that the standard is restricted to
reﬂective measurements. A discussion of potential BRDF standard surfaces is
found in Section 8.5.

Instrumentation and Measurement Issues
137
7.9 Measurement of Curved Optics
Measurement of scatter from curved optics presents a new set of problems. In order
to bring the beam back into focus at the receiver path after inserting the sample,
the source optics must be adjusted. This can be accomplished by moving the
lens/spatial ﬁlter combination shown to the left of the focusing element in Fig. 7.3.
This point source of light is conjugate with the focused spot at the receiver. The
direction of motion depends on whether the sample is converging or diverging. For
samples with short focal lengths, the source may need to be focused very close to
the sample, possibly causing a drastic reduction in sample spot size.
The problems are more severe for near-specular measurements because when
the source is adjusted, the instrument signature changes. Fortunately, the changes
can be accounted for with computer modeling if necessary (Klicker, Stover, and
Wilson 1988). The diffraction-limited spot decreases in size if the sample is
converging and increases if it is diverging. θN also decreases for a converging
sample but not by the same amount. The change in θN is accounted for in Eq. (7.6).
If the radius of curvature is very tight (a few cm or less), and a laser is being
used as the light source, then Gaussian beam characteristics, instead of geometric
optics, may have to be used to determine the relative positions of source sample
and receiver. This is a result of the inﬁnite radius of curvature found in the phase
front at focus of a Gaussian beam.
7.10 Coordinate Systems and Out-of-Plane Measurements
Out-of-plane measurements raise some difﬁculties that are not always confronted
when measurements are taken in the incident plane, and there are some sample
orientation issues for in-plane measurements that still need to be discussed. In
addition to keeping track of the position of source and receiver relative to the
illuminated spot (or volume), the angular orientation of the sample and the location
of the illuminated spot must be recorded. The geometry used in Fig. 1.6 to deﬁne
BSDF is redrawn in Fig. 7.13(a), showing a reﬂective sample with more detail to
illustrate these issues. For the moment, the discussion is limited to a ﬂat reﬂective
sample.
Figure 7.13(b) shows the reﬂective sample plane with two sets of Cartesian
coordinates superimposed on it. These are the beam coordinates (x, y, z), which
will be deﬁned by the incident and reﬂected beams and a set of coordinates (X, Y, Z)
ﬁxed to the sample. Thus, z and Z are normal to the sample surface, and the other
four axes are in the sample plane. The −x axis is the projection of the incident
beam on the sample plane. This coordinate system moves with the illuminated
spot on the sample. The incident and reﬂected beam directions are given by the
propagation vectors ki and ko, respectively. These two vectors deﬁne the x, y, z
(beam coordinate) system. The X, Y, Z system is used to deﬁne “sample center”
and sample orientation. The location of the X and Y axes is usually accomplished
through the use of ﬁducial marks on the sample or its holder. These marks and the
X, Y coordinates of the illuminated spot allow the sample to be measured at known,

138
Chapter 7
Figure 7.13
(a) Scatter angles are deﬁned in terms of the beam coordinates (x, y). The
(x, y) axes are determined by the incident beam and specular reﬂection with x in the incident
plane. Thus, φi = ±180 deg for all cases. (b) Sample orientation and the illuminated spot
location are given in terms of the sample coordinates (X, Y) and a rotation angle φz. The
(X, Y) axes are often indicated by ﬁducial marks located on the sample edge.
repeatable locations. For ﬂat samples, the Z axis is normal to the sample surface.
When the sample is rotated about z or Z, the x, y axes are separated in angle from
the X, Y coordinates by the rotation angle φz, but the Z and z axes remain parallel.
The polar and azimuthal angles can now be deﬁned in terms of the axis sets and
the propagation vectors.
The polar angles, θi and θs, are deﬁned as the angles between z and the
propagation vectors ki and ks, respectively. The azimuthal angles φi and φs are
deﬁned as originating from the x axis to the projections of the propagation vectors
ki and ks on the sample face (X, Y or x, y plane). This deﬁnition ﬁxes φi equal to
180 deg, independent of sample rotation.

Instrumentation and Measurement Issues
139
Some authors deﬁne the φ angles from X instead of x and use this angle as a
measure of sample rotation. This is, for example, the choice made by Nicodemus
et al. (1977). Unfortunately, with this deﬁnition, the value of φs cannot be
substituted into either the grating equation or the expressions for Q without ﬁrst
reducing it by the sample rotation angle. This is because all of those equations
assume the special case that φi = 180 deg. This can lead to confusion when these
equations are used to interpret results. However, there is another problem with this
deﬁnition that is potentially more serious. If the sample is curved, then x, y and
X, Y will in general be nonplanar and z and Z will be nonparallel. Now, a new
set of axes is required, or some difﬁcult transformations must be made to correct
all of the polar and azimuthal angles. All of these complications are avoided if
the incident and scattered angles are deﬁned relative to beam coordinates, and
the illuminated sample spot location and sample orientation are deﬁned with the
sample coordinates. With a beam-coordinate deﬁnition, the angles are deﬁned
in a manner that is independent of sample holder design. Thus, deﬁnitions (and
standards) can be set that are both instrument independent and consistent with
equations and notation that currently exist. SEMI Standard ME1392 mandates
use of the beam coordinate system for exactly these reasons (see Section 12.2 for
details).
When measurements are taken out of the incident plane, the situation can be
confusing from another aspect because the receiver may not move naturally along
paths of constant θs and/or φs. Figure 7.14 shows the two common ways to cover
the full hemisphere in front of the sample. Essentially they may be thought of
as viewing lines of longitude and latitude on a globe of the Earth from either a
position above a pole or in the equatorial plane. The former, shown in Fig. 7.14(a),
allows the receiver to be moved along paths of constant θs and φs. This is very
convenient because in order to measure only s or p polarization, the receiver
analyzer can remain at a ﬁxed roll angle during a scan. However, there are often
practical reasons for choosing other receiver sweep patterns, such as the one in
Fig. 7.14(b). These may include sample size and/or required ﬁeld of view (which
increase receiver arm length), receiver weight, and multiple source requirements.
Out-of-plane instrument conﬁgurations that involve tilting the sample about the
x axis so that the beam is reﬂected out of the initial incident plane and around
the laboratory are often avoided because of the resulting increases in instrument
signature and safety problems associated with undumped beams.
Finally, there are some useful relationships that allow incident plane
scatterometers to be used to measure out-of-incident plane scatter that make use
of tilting the sample. When this is done the sample normal no longer falls in the
measurement plane, and the detector is measuring light out of the incident plane.
The question is, at what out-of-plane locations are the measurements being taken?
Consider Fig. 7.13, where in the original laboratory system the receiver moves
(only) in a horizontal plane and the incident beam comes in over the −X axis.
Then, tilt the sample about the X axis by angle α so that the +Y-axis edge of the
sample is moved in the +Z-axis direction. (Realize that if your instrument is set up
in the opposite fashion, then all of the following equations will be correct if you

140
Chapter 7
Figure 7.14
Two common hemispherical receiver paths are shown projected onto the
sample plane. The path in (a) follows standard θs, φs coordinates but may not be as
mechanically convenient as the one in (b).
consider the Y axis to be directed down in your laboratory.) Now there is a new
sample coordinate system x′, y′, z′ (where x = x′) in front of the tilted sample, and
there are associated values of θ′
s, θ′
i, and φ′
s in that system that are required for the
measurement. The following equations give the necessary values of θs, θi, and α
to orient the receiver/sample such that the θ′
s, θ′
i, and φ′
s combination can be found
in the horizontal measurement plane:
α = tan−1[sin φ′
s tan θ′
s].
(7.18)
θi = cos−1[cos θ′
i/ cos α].
(7.19)
∆θ = θi + θs = θi + cos−1[cos θ′
s/ cos α].
(7.20)
Calculate the three angles found above, then align the sample perpendicular to the
source (to set θi = 0). Rotate your incident angle to the θi value found above, and
then tilt the sample (about the X axis) by the calculated value α so that the +Y
edge of the sample is moved in the +Z direction. Then, position your detector so
that it is ∆θ deg from the incident beam, and take the measurement. This gives
you a single measurement point out of the incident plane. By putting the equations
into a spreadsheet, you can quickly take several points along a desired scan line
that is out of the incident plane. There will be problems very close to the specular
beam, where location errors will be bothersome, but over most of the reﬂective
hemisphere, the procedure will work ﬁne. Another issue is that tilting the sample
changes the size and shape of the illuminated spot on the sample. This means that
sample uniformity is important. Make sure you move a beam dump to the new
location of the specular reﬂection with each measurement.
7.11 Camera-based Systems
Combining a digital camera with a scatter screen of some type (see Section 7.5)
provides a fast way to obtain a large quantity of scatter data, both in and out of

Instrumentation and Measurement Issues
141
the incident plane. A number of conﬁgurations have been tried that involve both
ﬂat and hemispherical screens and reﬂective and transmissive screens. Two serious
issues that must be faced are dynamic range and calibration.
A number of tricks (varying exposure time, source power, screen position, and
even variations in screen reﬂectance) can be employed to increase dynamic range;
however, these systems do not approach the ten plus orders available in the single-
detector scanning systems described in Section 7.1. In general, these systems are
restricted to use with high-scatter, optically rough samples.
Calibration is usually achieved using a white diffuse reﬂector with a known
BRDF. If the calibration sample is truly Lambertian, it will have a constant BRDF
of 0.31/sr (Section 8.4.1). Care must be taken because most “Lambertian” surfaces
begin to lose this characteristic at incident angles above about 45 deg, and, in the
IR, very few surfaces uniformly scatter with a constant BRDF. When some of the
dynamic-range-extension techniques are applied, calibration often suffers.
Nevertheless, the speed with which data is obtained and the ease with which
data can be analyzed in the accompanying software makes these systems truly
impressive. An example of scatter data is shown in Fig. 7.15 in grayscale format.
The false color images on the book cover are more impressive. Data can also be
present in maps and virtual detectors deﬁned and applied to arbitrary regions of
the hemisphere. Integrating the CCBRDF over these “detectors” gives the sample
reﬂectance into the detector. Laboratory data taken on such an instrument can be
used to deﬁne detector locations in manufacturing environments that are optimized
for sensitivity to production variables. An example is given in Section 10.2.
7.12 Raster Scans
The presence of light scatter from a discrete spot on an otherwise uniform
optic indicates the presence of a defect or a contamination site. Coverage of the
complete sample area by full-angle BSDF inspection is usually impractical due
to time and cost limitations imposed by sample size and/or sample numbers.
For situations where area information is needed, a raster-scanning technique
that rapidly covers the required sample area is often the best solution. Raster
data provides valuable insights into sample nonuniformity caused by production
processes and contamination.
Sample raster scans are accomplished by measuring the BSDF at constant
incident and scatter angles from specular over the sample area of interest (Rifkin
and Stover 1988). This can be done by moving the sample in its own plane with
the receiver ﬁxed at one position. The BSDF value, measured at the ﬁxed-receiver
angle, is assigned to the corresponding illuminated sample area (or pixel). Raster
data is presented either as color maps or isometric 3D plots of the scanned sample
area. The results reveal the locations of high- and low-scatter areas on the sample.
Because scatter patterns are often asymmetrical, the sample must be moved in an
x, y grid pattern (as opposed to an r, θ area coverage) so that the pattern is not
rotated during the measurement process. Moving the sample by stepping motors is
a time-consuming process (it requires approximately one pixel/second). At this rate

142
Chapter 7
Figure 7.15
A three-dimensional view of BRDF data over a region of the scattering
hemisphere surrounding the direction of specular reﬂection, taken with a camera-based
scatterometer. Courtesy of ScatterMasterTM, LLC.
a 10,000-pixel scan takes almost three hours. Wafer- and disk-handling systems
have been developed that can accurately move samples much faster.
Even-faster scans can be taken by imaging the fully illuminated sample onto
a CCD array. Sample pixels are now deﬁned by the detector array. Because the
imaged pixels are not uniformly illuminated, the incident power associated with
each pixel must be found prior to calculating the BSDF via Eq. (7.1). Although the
values of Ps and Pi change as a function of pixel location, the values of Ωs and θs
remain essentially constant. The receiver solid angle Ωs is determined by the full
aperture of the CCD camera. The calculation process is shown in Figs. 7.16–7.18
for the case of an incident beam with a near-Gaussian intensity cross section. Color
mapping (shown as grayscale here) is used to indicate light intensity. Figure 7.16 is
an intensity map of the incident beam obtained by imaging a uniform white diffuse
surface. The spot is elliptical because the angle of incidence was not zero. The
image of an illuminated front-surface mirror is shown in Fig. 7.17. The data of
Figs. 7.16 and 7.17 are used to calculate the sample BRDF, which is mapped in
Fig. 7.18. Notice that the prominent scratch across the width of the sample appears
relatively uniform in this ﬁgure, even though its illumination in Fig. 7.17 is uneven.
Resolution on the sample is about 10 µm. The 150,000 pixels making up this image
were obtained and displayed in less than one minute.
If an acceptable BSDF level can be established, the inspection time can be
further reduced by eliminating the need for a complete color plot of the sample.
Instead, the computer can simply check for pixels that exceed the acceptance level

Instrumentation and Measurement Issues
143
Figure 7.16
Intensity map of the incident beam.
Figure 7.17
Intensity map of the illuminated sample.
and either reject the component or plot the high-scatter points, as required. The
short measurement time allows easy integration of this inspection technique with
other processes, such as various surface-ﬁnishing methods, dielectric coating, and
laser damage threshold testing.
The advantages of quickly inspecting large numbers of relatively inexpensive
mirrors prior to their integration with more expensive system components are
obvious. Laser mirrors, requiring a check of only the center spot, can be inspected
at a rate of about one per second. Measurements can be made immediately after
dielectric coating, using the same part holder (Perilloux 1991).

144
Chapter 7
Figure 7.18
BRDF map of the sample resulting from the data of Figs. 7.15 and 7.16.
Systems designed to measure large-area optics can also be designed. After
determining the source intensity, the sample can be measured one piece at a time
by moving the instrument system (source, ﬁlters, lenses, and detector) to adjoining
ﬁelds of view. After all of the data is taken, the computer “cuts and pastes” the
various pieces together to form a complete picture. For large-area, high-resolution
scans, a huge amount of data will need to be stored. However, by retaining only
the data associated with defects that exceed operator-chosen limits (in size and/or
BSDF), this difﬁculty is eliminated.
This rapid measurement technique is expected to play a signiﬁcant role in the
inspection of both high-volume production optics and large-area optics. Because
this technique provides production process information in addition to acting as a
quality control, it is expected to have a positive impact on several segments of
the optics industry. Raster scans are also used in the detection of discrete defects
in the optics, semiconductor, computer disk, and ﬂat panel display industries, as
described in Chapter 11.
7.13 Measurement of Retroreﬂection
Measurement of light scattered back in the incident direction by conventional
means is difﬁcult because the receiver shadows the sample from the source.
The data shown in Fig. 7.19(c) is for a ring laser gyro mirror. Minimizing
retroreﬂection, or retroscatter, is important to the correct operation of optical gyros.
These devices are ring lasers with cavity modes propagating simultaneously in the
clockwise and counterclockwise directions [Fig. 7.19(a)]. If the laser is rotated
during operation, the two modes are frequency shifted in opposite directions. One
Doppler shifts up and the other down. Rotation is detected by combining the two
beams outside the laser and watching for motion of the resulting fringe pattern.
The resolution with which rotation can be monitored is controlled by the degree

Instrumentation and Measurement Issues
145
Figure 7.19
(a) A simpliﬁed schematic of a ring laser gyroscope. (b) Scatter measurement
geometry for an RLG mirror. (c) Data taken using the arrangement shown in (b).
to which the frequencies of the two counterpropagating beams are separated.
Retroscatter from the gyroscope mirrors acts to mix the two beams in the laser
cavity and thus limits resolution.
The conﬁguration of Fig. 7.19(b) was used to obtain the data of Fig. 7.19(c).
It would appear to be easy to infer the BRDF in the retrodirection from the
measured scatter levels on either side; however, some materials have BRDFs that
are enhanced in the retrodirection. Referred to as the opposition effect, enhanced
backscatter, or just retroscatter, the effect takes the form of a narrow peak (one
degree or less) that can vary from a few percent to several hundred percent higher
than the background scatter levels. The effect is easily observed by eye, with
sunlight as the source, from airplanes. It is most evident as a halo appearing
around the airplane shadow when ﬂying above clouds; however, it can also be
observed as a faint bright spot on the ground (located where the airplane shadow
should be) that travels with the plane. The intensity of the spot varies with ground

146
Chapter 7
cover. Although it is narrow enough that it has little impact on total reﬂectance,
it has direct consequences on the design of laser radar systems and targets, can
be of practical importance to air (or space) ground surveillance systems, and as
mentioned, is a problem for laser gyros.
Gu et al. (1989a, 1989b) review the various theoretical explanations that have
been advanced to explain the effect. Different mechanisms may be responsible for
enhanced backscatter from different materials (water droplets, diffuse reﬂectors,
metal mirrors, etc.). Gu et al. report a clever Doppler-shift technique to measure
retroscatter directly. The sample, inducing the Doppler shift, is moved, and
its magnitude is determined by monitoring the amplitude of the resulting
difference (or beat) frequency after recombining the retrobeam with a reference.
Beamsplitters can be used to separate retroscatter from the incident beam if the
target samples are much-higher scatter than the beamsplitter and associated beam
dumps [see Fig. 7.20(a)]. Lenses are used to put the sample in the far ﬁeld of
the source and the detector in the far ﬁeld of the sample. If a charge-coupled
device (CCD) array is employed as the detector, a map of the scatter through the
incident angle can be made as shown in Fig. 7.20(b), where the sample has been
rotated to average speckle effects. If a pulsed laser is used as a source and the
beamsplitter/target distance is sufﬁciently large, the sample scatter can be separated
from that of the beamsplitter.
Because its reﬂectance and transmittance are polarization sensitive, a
beamsplitter has another undesirable effect—it acts as a polarization-sensitive
ﬁlter. Both of these limitations have been eliminated by measuring the full
polarization content of the retroreﬂected light and by moving the source chopper to
a position directly in front of the sample (Schiff et al. 1992c). In this conﬁguration
(shown in Fig. 7.21), the beamsplitter is illuminated with dc source light, so the
input scatter signal from it is ignored by the receiver electronics. The reported
noise-equivalent BRDF (NEBRDF) was 3 × 10−6 sr−1, and signiﬁcantly lower
values could be obtained by this technique.
7.14 Alternative TIS Devices
Section 1.6 deﬁned TIS and reviewed the Coblentz sphere technique developed
for its measurement. Another method is outlined here that in some situations
has advantages over the original technique. The difference is the use of a high-
reﬂectance, diffuse integrating sphere to gather the scattered light, instead of the
specular Coblentz sphere.
The system, shown in Fig. 7.22, consists of a laser source, an integrating
sphere, three detectors, and associated electronics and optics. The laser beam is
divided by a beamsplitter, allowing the transmitted power to enter the ﬁrst detector.
The reﬂected segment becomes the incident power on the sample. The specular
reﬂection from the sample returns to the beamsplitter, and part of it is transmitted to
a second detector. A third detector views the interior of the integrating sphere. This
detector is shielded by a bafﬂe from directly viewing the sample. Light scattered
out of the specular beam by the sample is trapped in the sphere. The inside of the

Instrumentation and Measurement Issues
147
Figure 7.20
(a) A beamsplitter used to measure retroscatter from a diffuse sample. (b)
Retroscatter measured with the arrangement shown in (a) and a CCD array detector. The
sample is white Spectralon R⃝. The spot is about 0.5 deg wide and about 20% brighter than
the background.

148
Chapter 7
Figure 7.21
Chopping the incident light after it passes the beamsplitter allows the
dc scatter from the beamsplitter to be electronically separated from the often smaller
retroscatter signal.
sphere and the bafﬂe are coated with a diffuse, high-reﬂectance coating that, after
multiple reﬂections, causes the interior of the sphere to be uniformly illuminated.
The relative sensitivity of the three detectors and the transmission/reﬂection ratio of
the beamsplitter must be determined. The relationship between the scatter detector
signal and sample scatter is found by misaligning the incident beam (of known
power) so that it strikes the interior of the integrating sphere. All three detectors
must be linear over their range of use. Using this information, the relative values of

Instrumentation and Measurement Issues
149
Figure 7.22
TIS measurement with a diffuse integrating sphere. All three ratios of the
measured signals are meaningful.
the incident power Pi, the specularly reﬂected power P0, and the scattered power
Ps can be found. When these signals are ratioed, values of the specular reﬂectance,
diffuse reﬂectance, and TIS are obtained:
Rspec = P0
Pi
.
(7.21)
Rdiﬀ= Ps
Pi
.
(7.22)
TIS =
Ps
(Ps + P0).
(7.23)
Advantages of this technique are ease of alignment (the scatter detector is
relatively insensitive to position), reduction of the high-angle scatter problems
mentioned in Section 1.6, and commercially available diffuse integrating spheres.
A disadvantage is that it requires more than one integrating sphere to cover both
visible and mid-IR wavelengths.
Another TIS instrument that makes use of diffuse integration employs an
integration plate (Bender, Henning, and Berndt 1992). The converging source beam

150
Chapter 7
is reﬂected off of the sample and focuses at a small hole in the center of a circular,
diffuse white plate. A detector views the plate and records a signal proportional to
the integrated scatter signal from 0.05 to 3.0 deg. This type of system provides
a quick measure of optical quality and lends itself to rapid inspection of the
low scatter that is required for the growing use of optical inspection in the
semiconductor and computer disk industries.
7.15 Error Analysis of the Measured BSDF
BSDF measurement variations as large as an order of magnitude have been
reported (Leonard and Pantoliano 1988; Leonard, Pantoliano, and Reilly 1989;
Leonard and Rudolph 1993; Young 1975) in round-robin tests, where several
laboratories measured the same sample(s). Measurement variations have been so
common that agreement within a factor of two is often viewed as “close enough
for government work” (which is often the case). Wild variations in near-specular
measurements have led to the (often correct) view that the laboratory with the
lowest-measured BSDF has the most accurate value. Because the calculation of
BSDF is very straightforward, the source of these disagreements can be examined
through a simple error analysis (Cady et al. 1989a):
BSDF =
Ps/Ω
Pi cos θs
.
(7.24)
∆BRDF
BRDF =

 ∆Ps
Ps
!2
+
 ∆Pi
Pi
!2
+
 ∆Ω
Ω
!2
+
 ∆θs sin θs
cos2 θs
!2
1/2
.
(7.25)
Equation (7.25) has been found by standard error analysis (Squires 1985), under
the assumption that the four deﬁning variables are independent of one another.
In similar fashion, the ﬁrst term can be broken into the components that cause
errors in the measured scatter signal. These are ∆Py, the error caused by aperture
misalignment in the Y direction (perpendicular to the sweep direction), ∆Vs, the
electrical noise generated in the receiver electronics, and NL, the fractional receiver
nonlinearity:
∆Ps
Ps
=

 ∆Py
Ps
!2
+
 ∆Vs
Vs
!2
+ (NL)2

1/2
.
(7.26)
The vertical misalignment term can be estimated everywhere (except in the
specular direction) by assuming that on a log–log plot, the BSDF falls off as a
straight line with slope m. It is not uncommon to ﬁnd such straight-line segments
with slopes varying from −1 to −3 (Section 4.5). Assuming circular symmetry in
the scatter pattern in the near-specular region, the fractional error in the received

Instrumentation and Measurement Issues
151
power is
∆Py
Ps
= M
θ
cos−1

R cos θ
p
∆y2 + R2
−θ
,
(7.27)
where R is the receiver/sample distance, ∆y is the vertical misalignment, and
θ = θs−θi. This source of error is small at large scatter angles but can be signiﬁcant
near specular.
The electronic noise term dominates all BSDF measurements near the NEBSDF.
However, since we are concerned with instrument errors where there is sufﬁcient
signal available, this term will be ignored. The nonlinearity term depends on the
individual instrument. Most photovoltaic detectors and photomultiplier tubes are
linear to within 1 or 2% for several decades, until either saturation (on the high-
signal end) or the noise ﬂoor (on the low-signal end) is approached. The saturation
point for each detector should be found experimentally to avoid the introduction of
large errors.
The component for errors in Pi in Eq. (7.25) can also be broken into individual
terms. If the absolute method is used to ﬁnd Pi, these terms are
∆Pi
Pi
=

 ∆Py
Pi
!2
+
 ∆Vs
Vs
!2
+ (NL)2

1/2
.
(7.28)
The ﬁrst term accounts for the loss of signal associated with the ﬁnite aperture of
the receiver. For a sufﬁciently large aperture, this error can be kept well below
1%. The second and third terms are identical to those discussed above. If the
reference sample method is used to measure Pi, then one must loop back through
the entire error analysis to evaluate this term. However, by looking ahead to the end
of this calculation, errors of only a few percent are achievable under the optimum
conditions that should be present for a reference sample measurement of Pi.
Uncertainties in the solid angle account for the third error component. These are
caused by measurement errors in the receiver aperture radius rs and in the aperture
to sample distance R:
∆Ω
Ω=

 2∆rs
rs
!2
+
 2∆R
R
!2
1/2
.
(7.29)
The last component accounts for uncertainty in receiver position θs. Near the
sample normal, the error is quite small; however, it grows without limit near
grazing scatter angles.
These errors are calculated in Table 7.2 at various values of θ for a typical
situation described by constants θi = 5 deg, ∆y = 25 µm, R = 50 cm, ∆R =
0.1 cm, and ∆θ = 0.05 deg. Values smaller than 1% are ignored. Very near
specular, the error exceeds 10% and is dominated by the contribution from aperture

152
Chapter 7
Table 7.2
Example error values.
θ = θs −5 deg =
.01 deg
.1 deg
1 deg
10 deg
80 deg
M
2
2
2
2
2
∆r (µm)
5
5
20
50
50
r (µm)
150
150
800
5000
5000
∆Py
Ps
.15
.002
0
0
0
∆Vs
Vs
.001
.01
.001
.001
.001
NL
.02
.02
.02
.02
.02
∆Pi
Pi
.005
.005
.005
.005
.005
2∆r
r
.067
.067
.050
.020
.020
2∆R
R
.004
.004
.004
.004
.004
∆θ sin θs
cos2 θs
.114
0
0
0
0
∆BS DF
BS DF
.166
.07
.054
.028
.117
misalignment out of the incident plane. Near grazing angles, the error is dominated
by uncertainty in the value of θs and again exceeds 10%. However, between those
two extremes, the error stays well below 10%. A 1% instrument has been reported
that measures from the near-IR region to the near-UV region (Schiff et al. 1993).
Combining Eq. (7.25) to Eq. (7.29) and eliminating the terms that give little
contribution results in the following expression for errors in the measured BSDF:
∆BSDF
BSDF −

 M
θ
2 cos−1

R cos θ
p
∆y2 + R2
−θ

2
+ 2(NL)2
+
"2∆r
r
#2
+
 ∆θs sin θs
cos θs
!2
1/2
.
(7.30)
BSDF measurements are not inherently error prone. Over most of the angular
range, consistent results can (and have) been achieved. Detector saturation,
ignoring convolution and signature effects, operator error resulting in gross
increases to parameter uncertainties, software problems, lack of a common data
format, and confusion about the deﬁnition of BSDF lead to most of the wide
variations reported in the round-robin studies.
7.16 Obtaining Appropriate PSD Measurements
The last ﬁfteen sections have discussed issues with obtaining reliable scatter
measurements; however, if scatter and roughness are to be related to each other,
then it is equally important to have accurate surface PSDs. In fact, the next chapter

Instrumentation and Measurement Issues
153
is devoted to making scatter predictions—often from the surface PSD. There are
two issues. First, as explained in Chapter 3, the BRDF is essentially proportional to
the two-dimensional PSD, but while many of proﬁlometers measure over areas and
obtain z(x, y) proﬁle data, most of them use this to create average one-dimensional
PSDs in the x and y directions. If these one-dimensional PSDs are similar, then
the surface is probably isotropic, and the resulting PSD can be curve ﬁt, and the
technique of Section 4.5 can be used to obtain the two-dimensional PSD, which
can be used in the Rayleigh–Rice perturbation relationship.
Unfortunately, the second issue is not so easy to solve. Proﬁlometers, whether
stylus or optical, at some point suffer from a reduced response at higher spatial
frequencies. The tip of a stylus instrument is too large to drop to the bottom of
narrow surface valleys and discriminate against higher-frequency roughness. An
optical proﬁlometer gathers reﬂected light out to a limiting maximum angle that
does not begin to approach the large angles over which scatter measurements are
made. As a result, PSDs in general may not be appropriate to estimate higher-angle
scatter. The following example illustrates the problem and a ﬁrst-order correction.
A study of scatter from optically rough surfaces was made (Stover 2007) to
investigate the accuracy of the MFT for predicting scatter (see Section 8.2.2).
The two-dimensional PSD of a number of surfaces was required for the study.
Surfaces were measured with a MicroXAM R⃝optical proﬁlometer to obtain one-
dimensional PSDs. An optically smooth molybdenum mirror, whose PSD had been
found from BRDF measurements at several wavelengths, was also measured on the
proﬁlometer. The sample was chosen because it had an exceptionally straight PSD.
Figure 7.23 shows the two-dimensional PSD obtained from BRDF measurements,
a straight line ﬁt to the PSD, and the resulting one-dimensional PSD found by
using the equations of Section 4.5. The process is easier for this straight-line
situation because (Bf)2 ≫1 applies. The result is a straight line with a slope
that is lower by 1.0. Then, in Fig. 7.24, this PSD is compared to the PSDs obtained
from proﬁlometer measurements taken with high- and low-power objectives. As
expected, the PSDs match well at lower frequencies, but the proﬁle-generated
PSDs drop off rapidly at higher frequencies. The high-power objective has a better
high-frequency response but does not measure at the lower frequencies because of
its smaller ﬁeld of view.
Notice that the PSD from the high-power objective starts to deviate at just
below a spatial frequency of 0.1/µm, and that it is off by a factor of ×100 at
1.0 µm. Assume that we wanted to use the proﬁlometer PSD in the Rayleigh–Rice
relationship to generate the BRDF when a 488-nm laser is normally incident on
the sample. Applying the grating equation we learn that under these conditions
scatter associated with a spatial frequency of 0.1/µm is about 3 deg from the
specular reﬂection. In other words, the proﬁlometer-generated PSD can be used
to accurately predict only a tiny fraction of the scattering hemisphere at this light
wavelength. It could be used to ﬁnd most of the scattering hemisphere if the
laser were a 10-µm CO2 laser. Thus, proﬁlometer bandwidth can be a serious
limitation for predicting scatter from the PSD. However, Figs. 7.23 and 7.24 also
show a ﬁrst-order correction to the issue. If the one-dimensional PSD from BRDF

154
Chapter 7
Figure 7.23
The two-dimensional PSD found from BRDF measurements is ﬁt with a
straight line and then converted to its one-dimensional equivalent.
Figure 7.24
The one-dimensional PSD found in Fig. 7.23 is compared to one-dimensional
PSDs found from an optical proﬁlometer using two different microscope objectives.
measurements in Fig. 7.24 is divided by the proﬁlometer PSD, then the result is
a correction function that can be applied to PSDs generated by the proﬁlometer.
These corrections work reasonably well for surfaces that are optically smooth
because the scatter ﬁeld contains almost no second-order diffraction; however, for
rougher surfaces they can create some odd situations.
Oddly enough, this situation is not widely appreciated, or at least not widely
discussed. When the author questioned a proﬁlometer manufacturer about the

Instrumentation and Measurement Issues
155
situation, he learned that they were aware that a high-frequency software correction
could be applied to their PSDs, but when he asked why they did not do it, he was
told: “Oh, that would make the surfaces look rougher, and our customers would
not like that.” The clear message is to tread carefully if you are more interested in
metrology than feeling happy.
7.17 Summary
As with many other ﬁelds of metrology, the computer has had an almost magical
effect on the ability to produce fast, accurate scatter data in an expanding variety of
forms. For the most part, modern instrumentation leaves the operator free to worry
about sample-dependent issues. The key issues for operator concern are instrument
calibration and instrument noise (or signature). Measurement noise can be a
problem both near specular (where it is usually dominated by instrument-induced
scatter) and far from specular, where a low signal competes with background
light and electronic noise for attention. The techniques for overcoming near-
specular difﬁculties include the use of small apertures and focused beams, careful
consideration of system geometry, the use of a mirror as a ﬁnal focusing element,
careful receiver design, low-noise electronics, and the use of system software that
checks for signal deviation. These techniques have been outlined in the chapter.
The second situation in which noise is difﬁcult to eliminate is the case of very
smooth, low-scatter reﬂectors, such as the best silicon wafers currently being
made. The best of these surfaces have such a small BRDF that even scatter from
surrounding air molecules can rival the sample scatter. Calibration and checks on
calibration have been discussed, and an error analysis has been presented. Careful
design will limit errors to about 5%, except very near specular or at sample-grazing
scatter angles. In addition to the fairly common in-plane measurements, out-of-
plane measurements, raster scans, retroreﬂection measurements, and integrating
TIS systems have been discussed.
Additional measurement techniques are described in Chapter 9, which combines
the more-standard techniques presented here with some of the polarization
relations given in Chapter 5. The next chapter covers scatter predictions based on
scaling, curve ﬁtting, and the known scatter behavior of optical components.

 

Chapter 8
Predicting Scatter from
Roughness
“Prediction is very difﬁcult, especially if it’s about the future.” – Niels Bohr
One of the difﬁculties associated with scatter measurements is the large number
of variables on which the scatter distribution depends. In addition to sample
parameters such as roughness, bulk defects, and contamination, there are
instrumentation-dependent parameters such as polarization, angle of incidence,
and wavelength. Separating the various effects is not trivial, although there can
be strong economic motivations to do so. The usual approach has been to make
scatter measurements under the conditions expected for actual use; that is, to use
the polarization, incident angle, and wavelength that are intended for eventual use
to make the scatter measurements. Although polarization and incident angle are
relatively easy to adjust in most instruments, a huge amount of data would be
required to cover all of the combinations that a given sample might encounter in
its expected use. In addition, generating scatter data at arbitrary wavelengths is an
expensive task. Therefore, there are strong motivations for being able to predict
sample scatter and avoid taking the data.
Unfortunately, there has been a tendency to oversimplify some scatter
predictions, which has led to poor results and considerable confusion. For example,
the relationship TIS = (4πσ/λ)2 can be interpreted as follows: if the rms roughness
doubles, the measured TIS will quadruple. This is essentially true (ignoring the
high-angle sensitivity limitations of TIS measurements given in Section 1.6) if the
increase in σ is produced proportionally over the spatial bandwidth corresponding
to the angular collection cone of the scatter instrument (i.e., the PSD doubles over
the collection angles). But the equation is easily misinterpreted as indicating that if
the illuminating wavelength is doubled, the measured scatter from a given reﬂector
should be reduced by one fourth. Although one could probably guess that the TIS
would be reduced in such a case, it would be just a guess because changing the
wavelength changes the spatial bandwidth of the measurement. If a grating was
being measured, and doubling the wavelength brought the ﬁrst-order diffraction
into the collection optics, the TIS would probably increase! The equation is simply
not appropriate for wavelength scaling because it tacitly assumes a ﬁxed spatial
157

158
Chapter 8
bandwidth. In fact, variations in wavelength change the spatial bandwidth but not
the solid angle coverage.
Equally misleading would be the assumption that scatter in a given direction will
scale as (1/λ)4 because of the leading factor in Eq. (3.43). Chapters 1–4 indicate
that the real issues are the shape of the PSD and which section of it scatters into the
instrument at each wavelength. Because these concepts are not widely understood,
wavelength-scaling predictions have developed a much shadier reputation than
their surface-statistical cousins. In fact, as illustrated in Chapter 4, if surface
statistics (found from scatter) can be relied on, then so can proper predictions based
on changes in wavelength, angle of incidence, and polarization. The yellow brick
road for these predictions is the Rayleigh–Rice BRDF–PSD relationship, which is
built on the bedrock of the smooth, clean, front-surface-reﬂective (i.e., topographic
scatter) conditions.
This chapter categorizes various aspects of predicting scatter and gives
guidelines for some cases. The Rayleigh–Rice predictions in the next section
follow directly from the previous chapter. Section 8.2 examines the problems
encountered when the surface is not optically smooth. Other predictions are
more speculative in nature but not restricted to the well-behaved reﬂectors of
Chapter 4. These include curve ﬁtting of discrete data points, extension of BSDF
data into unmeasured regions, and the use of sample characterization computer
code (based on constants found from a few measurement scans) to predict any
BSDF combination. Chapters 1–5 are required background material to understand
the reasoning, as is Chapter 7 if measurements are being considered.
8.1 Optical Surfaces: Using the Rayleigh–Rice Equation
If
Sections
4.1–4.4
have
been
carefully
read,
it
will
be
clear
that
Eqs. (4.3), (4.4), (4.11) can be used to predict an angle-limited section of the
BRDF from a bandwidth-limited section of the sample PSD. The angle-limited
blocks of scatter predicted in this manner will shift in location, width, and ampli-
tude as a function of wavelength, incident angle, and polarization. It will also be
clear that these predictions will be accurate only for those cases where the samples
are smooth, clean, front-surface reﬂectors. Furthermore, regardless of past preju-
dices, these predictions should be treated with the same degree of conﬁdence with
which the scatter-to-surface statistics calculations are treated (Stover, Serati, and
Gillespie 1984; Stover et al. 1988; Stover and Bernt 1993). If the surfaces are not
smooth, clean, front-surface reﬂectors (i.e., they do not scatter topographically)
at all wavelengths, then other scaling laws must be found to predict their scatter
(Church and Takacs 1989a; Stover et al. 1989). The predictions of this section are
restricted to the cases where topographic scattering applies, although deviations
from this special case will be noted.
Topographic scaling predictions are made directly from the PSD and the
corresponding choices of wavelength, incident angle, and polarization (value or
expression for Q). The result is an asymmetrical cone of scattered light about the
specular reﬂection. Prediction of the scatter pattern includes values for the scatter

Predicting Scatter from Roughness
159
direction (θs, φs) as well as the BRDF. The general, isotropic, and one-dimensional
cases are treated separately in the next three subsections.
8.1.1 The general case
Equation (4.3) is easily expressed as the BRDF in terms of the PSD magnitude
S (fx, fy), and the two-dimensional grating equations [Eqs. (3.44) and (3.45)] can
be solved for the corresponding scatter direction in terms of the PSD frequencies
(fx, fy):
BRDF = 16π2
λ4
cos θi cos θsQS (fx, fy).
(8.1)
In most of the graphs that follow, S (fx, fy) has units of Å
2 µm2, and therefore
requires the PSD in Eq. (8.1) to be normalized by 108. See Appendix D for
comments on units.
φs = tan−1
"
λfy
λfx + sin θi
#
.
(8.2)
θs = sin−1
"λfx + sin θi
cos φs
#
.
(8.3)
The 1, 2 subscripts of Chapter 2 on S have been dropped here, and the dimension
of S is inferred from the number of frequency components in the argument. In
order to make a prediction, the PSD is inserted as a function, a curve ﬁt, or as
discrete points, and the desired wavelength, angle of incidence, and polarization
Q are used. If the surface is not isotropic, then each point in the predicted BRDF
must be associated with a point in the measured BRDF. Wavelength changes affect
ﬁrst-order diffraction position and intensity. The scatter pattern will expand (or
collapse) about the specular beam as the wavelength increases (or decreases). The
pattern moves with the specular beam as θi changes, becoming less symmetrical as
θi increases. Values of θs greater than 90 deg correspond to light scattered into the
surface and do not produce meaningful BRDF results. This is quite likely to occur
if the values of θi or λ are increased from those used to obtain the PSD.
There are some practical complications. In order to properly handle the
variations in Q, the complex dielectric constant must be known as a function of
wavelength and the values of Q evaluated by one of the techniques suggested in
Section 5.2. If the PSD was obtained from discrete scatter data taken at evenly
spaced points, after the method of Chapter 4, then the discrete PSD will be a series
of unevenly spaced points. When these are used to evaluate a new BRDF, the points
will again be unevenly spaced, making the computer codes used to analyze and
display the predictions more cumbersome.
The resolution of imaging optics can be limited by near-specular scatter.
Because near-specular measurements are subject to the various problems outlined
in Section 7.4 (aperture convolution, for one), it may be easier and more

160
Chapter 8
economical to calculate (or predict) the near-specular BRDF. In principle, it would
appear that scatter very near the specular beam at one wavelength can be predicted
from scatter data taken at longer wavelengths (Vernold 1989). However, the
usefulness of this technique is limited to some extent because the scatter very near
specular is masked by the diffraction-limited specular focus (which expands as the
wavelength increases), and because there is a tendency for wavelength scaling to
break down at longer wavelengths for materials in which the skin depth increases.
Another approach to predicting near-specular scatter involves using a very large
incident angle when measuring the BRDF. This approach allows the PSD at small
spatial frequency values to be computed. The BRDF for other incident angles can
then be calculated. BRDF values as close as a few thousandths of a degree from
specular corresponding to spatial frequencies as small as 0.0001 µm−1 (or a 1-cm
spatial wavelength!) have been reported (Stover and Bernt 1992).
8.1.2 Isotropic samples
The equations of interest are identical to those used for the general case. The PSD is
symmetrical, and except for normal incidence, the BRDF is not. Again, predictions
are made by inserting the appropriate values of θi, λ, and Q. The quantity S iso(f) of
Section 4.2 is not of interest because it is used only as a mathematical convenience
for calculation of surface statistics.
Figure 8.1 shows plots of S (fx, 0) (a portion of the two-dimensional PSD)
calculated from BRDF data taken at two angles of incidence from the molybdenum
mirror of Figs. 4.1, 4.5, and 4.6, as well as an aluminum mirror. The molybdenum
mirror was shown in Chapter 4 to be linear shift invariant in the visible and near IR.
Because the PSDs for these mirrors are identical within the regions of overlap, it
is reasonable to use them in Eq. (8.1) to predict scatter patterns associated with
different angles of incidence. In Fig. 8.2, the molybdenum mirror is shown to
exhibit wavelength scaling in the visible and near-IR regions. The same PSD is
found at three different wavelengths. If the same PSD is found from each BRDF,
then it is clear that only one BRDF is needed to accurately predict scatter at any
of the wavelengths. In these charts, the PSD was evaluated after subtracting the
instrument signature (multiplied by the sample reﬂectance) from the measured
BRDF. Near specular, a point is reached where the adjusted signature is equal to the
BRDF. This point determines the low-spatial-frequency limit of each PSD curve
and is determined by the various contributions to signature for each experimental
setup, as well as the relationship between frequency and wavelength expressed in
the grating equation. Also of interest is the fact that the PSDs of Figs. 8.1 and 8.2
are near-straight lines on log–log scales. They are fractal in nature with slopes of
about −1.6 (see Section 4.5.2).
The fact that the molybdenum mirror scales at the three wavelengths shown
in Fig. 8.2 does not mean that it scatters topographically at all wavelengths. As
shown in Fig. 8.3, the same PSD is not found if the wavelength is increased into
the mid-IR region. It is difﬁcult to say what causes the effect. It may be that the
increased skin depth associated with the longer wavelength is enough to reach

Predicting Scatter from Roughness
161
Figure 8.1
The PSD of the front-surface mirrors calculated from BRDF data taken at two
angles of incidence.
Figure 8.2
The PSD of the molybdenum mirror calculated from scatter data taken at three
wavelengths in the visible and near IR.
centers of subsurface scatter, or variations in the optical constants across grain
boundaries may be more signiﬁcant in the mid-IR region. The essential point is
that this molybdenum mirror scatters topographically in the visible and near-IR
region, but not in the mid-IR. This type of behavior appears to be both sample and
material dependent.
A number of materials have been measured and checked for their wavelength-
scaling properties (Stover and Bernt 1993). These include molybdenum, silicon,
silicon carbide, gold, copper, aluminum, and beryllium. In general, most metals
scale topographically in the visible and near UV. Many do not scale in this
manner in the mid-IR region. Many aluminum reﬂectors appear to violate this
generalization by refusing to scale at any wavelength from the mid-IR to near-UV

162
Chapter 8
Figure 8.3
The PSD of a molybdenum mirror calculated from BRDF data obtained at four
different wavelengths.
regions. Section 11.1.2 relates the consistency with which single-crystal silicon
wafers wavelength scale and the advantages that this brings to wafer inspection
in the semiconductor industry. The following paragraphs detail the failure of
beryllium, the material of choice for many space mirrors, to wavelength scale.
Figure 8.4 shows the measured BRDFs at 0.633 and 10.6 µm of a beryllium
mirror plotted against the absolute value of β −β0, which is proportional to the
spatial frequency. The data was taken with an incident angle of 30 deg. The BRDF
is symmetrical in frequency at both wavelengths. Figure 8.5 shows plots of the
sample PSD calculated from both the BRDF data of Fig. 8.4 and a second set of
BRDF curves with an incident angle of 5 deg. The PSDs are noticeably different
for the wavelength change, but virtually identical for the incident-angle change.
This sample scales in incident angle and exhibits symmetry with spatial frequency
but does scale in wavelength. The sample does not scatter topographically at one
(maybe both) of the wavelengths. The smooth, clean, front-surface requirements
of the Rayleigh–Rice model are not met by this sample, but the grating equation
(and conservation of momentum) still applies. This means that we cannot use the
symmetry properties found from β −β0 plots (essentially, incident-angle scaling)
as a way to conﬁrm that the scatter is strictly from surface roughness. On the other
hand, it means that at a given wavelength, scatter for many different incident angles
can be estimated from just one data set.
To further emphasize this point, Fig. 8.6 shows PSDs found from BRDF data
taken at four different wavelengths for the beryllium mirror of Fig. 8.5. Because
four different results were obtained, we know that the surface is not scattering
topographically. Remember that the PSD is a property of the sample, not the
measurement technique. By deﬁnition, the PSDs of Figs. 8.5 and 8.6 should be
identical within their regions of overlap if the samples are actually smooth, clean,
front-surface reﬂectors. The conclusion is that this beryllium sample does not meet
these conditions and that probably none of the calculated PSDs in Figs. 8.5 and

Predicting Scatter from Roughness
163
Figure 8.4
The BRDF of a beryllium mirror plotted against |β −β0|. The plus and minus
sides are symmetrical.
Figure 8.5
The PSD of a beryllium mirror formed from BRDFs taken at two different angles
of incidence and two wavelengths.
8.6 are correct. If the trend observed for the molybdenum mirror is still in effect,
the PSDs found from the short-wavelength measurements are likely to be more
accurate. In fact, many beryllium mirrors do wavelength scale over the visible-
to-UV spectra. The Rayleigh–Rice equation cannot be accurately employed for
wavelength scaling the data taken on this sample.
Because of its low weight and strength and high thermal conductance, beryllium
is a desirable material for space optics. It is formed by pressing the powdered
metal together and then machining it to shape. For mirrors, this is followed by
polishing. The surface looks a bit like a cobblestone street that has been polished
ﬂat—small chunks of beryllium held together by an oxide motar. The problem is
that the beryllium itself is birefringent, the chunks have different orientations, and

164
Chapter 8
Figure 8.6
The PSD of the beryllium mirror of Fig. 8.5 taken at four wavelengths.
the oxide’s third index is very different from that of beryllium. Even if the mirror
surface were perfectly ﬂat, it would still scatter signiﬁcant light because of the
changes in index. Beryllium mirrors do not scatter only from roughness.
The nonconforming PSD curves are still of some interest. Notice that the
calculated PSD grows with wavelength for both materials. This implies that there
is extra scatter at the longer-source wavelengths. We know that topographic scatter
falls off as the fourth power of the inverse wavelength. If nontopographic scatter
is proportional to the inverse wavelength squared or cubed, then its contribution
to the BRDF would become more evident at longer wavelengths—just as the data
in Figs. 8.3, 8.5, and 8.6 indicate. Church and Takacs (1989a) have postulated the
following relationship for various weak scattering sources:
BRDF ≈1
λn S | sin θs −sin θi|
λ
.
(8.4)
The wavelength dependence of material properties is ignored in this equation. The
value n is 4 for topographic and thin columnar defects, 3 for interference and
random bulk defects, and 2 for thick columnar defects.
Because the molybdenum mirror scales topographically at several wavelengths
in the visible and near IR, the corresponding PSD should be correct. This means
that in this wavelength region, scatter data can be used with Eq. (8.1) to ﬁnd surface
statistics or scatter in that wavelength band, but not in the mid-IR region. And,
using the techniques published by Church, it should also be possible to predict the
scatter from surface-proﬁle data (Church 1988, 1989). For nontopographic samples
(such as beryllium) the only safe method to obtain the sample BRDF is to measure
it directly at the wavelength of interest, or to establish a new scaling law that
incorporates a description of the appropriate nontopographic behavior. Unless it
is already known that a sample is going to scale topographically, it is inappropriate

Predicting Scatter from Roughness
165
Table 8.1
Calculation of grating amplitude.
Order
θi
a at 0.633 µm
a at 0.488 µm
+1
5 deg
213 Å
211 Å
−1
−45 deg
210 Å
208 Å
to use surface-proﬁling speciﬁcations to assure that a component will be low scatter
or meet a given scatter speciﬁcation.
8.1.3 One-dimensional samples
The one-dimensional version of the Rayleigh–Rice relationship [Eq. (4.11)] gives
the BRDF in terms of the one-dimensional PSD magnitude S (fx), and the equation
can be solved for the corresponding value of θs in terms of the PSD frequency fx.
The assumption has been made that the grating lines are ﬁxed perpendicular to the
incident plane:
BRDF = dP/dθs
Pi cos θs
= 16π2
λ3
cos θi cos θsQS (fx).
(8.5)
θs = sin−1[sin θi + fxλ].
(8.6)
A near-sinusoidal reﬂective grating can be used to demonstrate the validity of
the Rayleigh–Rice equation for one-dimensional samples (Stover et al. 1988). The
plus and minus ﬁrst orders from a reﬂective aluminum grating were measured using
incidence angles of 5 and 45 deg and wavelengths of .488 and .633 µm. For the
special case of a sinusoidal grating, Eq. (8.7) can be reduced to
P±1/Pi = (2πa)2 cos θi cos θs
√R(θi)R(θs)
λ2
,
(8.7)
where an exact evaluation of Q (see Section 5.2) has been added to the reasoning
behind Eq. (3.49). This form is convenient because it allows direct calculation
of the grating amplitude a. Table 8.1 gives the results of these calculations. The
average calculated value of the grating amplitude is 211 Å with a standard deviation
of about 1%. The agreement is excellent for changes both in wavelength and
incident angle. Obviously, the Rayleigh–Rice equation can be used in this situation.
One more point is worth extracting from the data in Table 8.1. Although data
was not shown in Section 11.1.2, it was mentioned that aluminum does not scatter
topographically in the visible. Given this information, why is such good agreement
obtained for the aluminum grating? The answer is that the grating ﬁrst order
is a very strong source of topographic scatter and dominates the much smaller
nontopographic scatter in the ﬁrst-order direction. Thus, the rougher a surface
is, the more likely it is that its BRDF can be described by the Rayleigh–Rice
relationship, up to the smooth-surface limit. That limit will be explored in the next
section.

166
Chapter 8
8.2 Optically Rough Front-Surface Reﬂectors
Many industrial processes depend on ﬁnish measurements where the smooth-
surface (Rayleigh) criterion is not met, and scatter is a fast noncontact way to
monitor surface ﬁnish in industrial situations. As discussed in Section 3.5, if the
measurement situation does not meet the Rayleigh smooth-surface limit, then the
Rayleigh–Rice relationship cannot be used to move back and forth between the
PSD and the BRDF. In fact, because rough surfaces with different PSDs may
produce the same BRDF, at best any PSD–BRDF relationship will be a one-way
street. That is, it may be possible to start with the PSD and get the BRDF, but it is
not possible to obtain the PSD from the BRDF. This section discusses various ways
to stretch the smooth-surface limit, the problems encountered when the limit is
violated, and what can be done with rough-surface scatter measurements. Although
there are many analytical difﬁculties associated with rough-surface scatter, there is
one bright spot (pun intended): there is lots of scatter from a rough surface, and the
scatter measurements are relatively easy.
8.2.1 Stretching the Rayleigh smooth-surface limit
The Rayleigh smooth-surface criterion is repeated here (from Section 3.3) for
convenience in terms of the rms roughness σ and the sinusoidal grating amplitude
a:
 4πσ
λ
cos θi
!2
= 1
2
 4πa cos θi
λ
!2
≪1.
(8.8)
It is obvious that the absolute roughness limit can be improved to some degree
by increasing the source wavelength and/or the angle of incidence. If the incident
angle is increased to 84 deg, where the cosine is 0.1, the implication is that an
order of magnitude can be gained on the smooth-surface limit. Figure 8.7 shows
the calculated PSDs of a molybdenum mirror for several incident angles using a
0.633-µm laser source. The minus sign on some incident angles implies that the
calculation was made using scatter from specular back toward the incident beam
(negative spatial frequencies) as opposed to forward scatter between the specular
beam and the surface (positive spatial frequencies). The correlation is excellent
and conﬁrms that for this relatively smooth mirror, which is known to scatter
topographically at this wavelength, incident-angle scaling to large angles is valid.
The value of Q was approximated by the measured specular reﬂectance, which will
be in slight error at high-scatter angles and is probably responsible for the slight
deviations at the high-angle end of each trace. The high-frequency peaks are not
real and are explained near the end of Section 4.2.
Incident-angle scaling has been performed on a holographically produced
sinusoidal grating that (unlike the grating of the last section) does not meet the
smooth-surface requirement. The measured BRDFs at incident angles of 45, 60,
75, and 85 deg are used to calculate one-dimensional PSDs, as shown in Fig. 8.8.
Integration of the ﬁrst-order peak to obtain the grating rms roughness reveals that

Predicting Scatter from Roughness
167
Figure 8.7
Incident-angle scaling demonstrated at near grazing incidence on a surface
known to be a smooth topographic source of scatter.
Figure 8.8
The ﬁrst-order diffraction from a “rough” sinusoidal grating is analyzed via the
PSD calculation at increasing incident angles. As predicted, the calculated rms roughness
becomes a constant at larger incident angles, where the smooth-surface criterion is
satisﬁed.
as the incident angle is increased, the calculated rms approaches a constant value
of 340 Å, independent of incident angle. When the incident angle is increased
enough to meet the smooth-surface requirement, the PSD calculation applies and
can be used to ﬁnd the rms roughness. At 45 deg, the Rayleigh ratio is 0.23, and
the error in σ is about 5%. This looks pretty good, but as will be seen in the next
section, a key issue is the dramatic growth of the second-order peak.
Notice that the area under the peaks becomes identical even though the peak
heights are not. This is because the diffraction peak spreads out at larger scatter
angles, but the broader lower peak has the same area. In effect, integration of the

168
Chapter 8
peaks is required to obtain the power ratio of Eq. (8.7). Two effects can explain
this spreading behavior. First, the radius from the sample where diffracted light
comes to a focus decreases with scatter angle. (Study the Rowland circle used
for diffraction measurements to learn more about this effect.) Secondly, small
variations in actual grating frequency spread the spot farther at higher angles.
This can be predicted by differentiating the grating equation to obtain d f/dθs =
cos θs/λ. Because df, the variation in grating frequency, is a constant, dθs must
increase.
There is still the question of whether incident-angle scaling can be used for
rough surfaces with steeper slopes. At very large incident angles, an increasing
fraction of the surface is shadowed and cannot contribute to the topographic BRDF.
The maximum slope on the grating of Fig. 8.8 is 2.6 deg, so shadowing was not an
issue for those measurements.
As seen in Section 8.1.2, increasing the wavelength results in nontopographic
scatter from some materials. Once nontopographic scatter becomes unacceptably
large, the PSD calculation no longer applies.
8.2.2 Predicting rough-surface scatter from the PSD
As indicated in Section 3.5, at the time of this book’s publication there are three
possible choices to predict the BRDF from a rough-surface PSD, and none of
them were very effective. The oldest is the Beckmann approach (Section 3.5.1),
which assumes a Gaussian PSD. The expression for the BRDF is given in terms
of the ratioed rms roughness and correlation length over (apparently) the spatial
bandwidth, corresponding to the angular spread of the calculated BRDF. The next
two, the generalized Harvey–Shack approach and Lopshenko’s mean-ﬁeld theory
(MFT) approach, are both still works in progress. Encouraging results have been
published, but neither has been extensively tested, and neither is available for
use by the general public. A major issue with using these emerging techniques
is obtaining accurate two-dimensional PSDs (see Section 7.16). In addition, both
approaches use normalization by the complete (or full-bandwidth) rms roughness,
and that is not always an easy value to obtain. The next section discusses the
possibility of obtaining rough-surface rms values from TIS measurements, without
using the PSD.
8.2.3 TIS measurements and rough surfaces
Moving to the less-sophisticated TIS measurement makes sense for rougher
surfaces because calculation of the PSD is not attempted, and the TIS measurement
provides a fast technique to monitor changes in surface ﬁnish. Now the questions
are: How rough can the surface become before the measured TIS can no longer
be related to the surface rms roughness? How far can the smooth-surface limit be
pushed if calculation of the PSD is not required? Could it be used to provide the
rough-surface rms values needed for the models mentioned in the last section?
In fact, it has been suggested that if the smooth-surface approximation used
in the optics industry for half a century is not employed, then Davies’s original

Predicting Scatter from Roughness
169
exponential expression gives an accurate rms value for many rough-surface
reﬂectors. The following analysis investigates this hypothesis.
Davies’s (1954) TIS relationship, which was based on a Gaussian height
distribution and a Gaussian PSD, has been discussed earlier. As was deﬁned in
Section 1.6, and later in 4.6, it was shown that under many common situations
the Gaussian assumption was not necessary, at least for most optically smooth
surfaces. His full expression is repeated here as Eq. (8.9), where the smooth-surface
approximation is found for the last two terms:
TIS ≡
Ps
P0 + Ps
= 1 −exp
−
 4πσ cos θi
λ
!2 Ps
P0

 4πσ cos θi
λ
!2
.
(8.9)
An obvious way to at least partially analyze the situation is to use sinusoidal
surfaces, which of course do not have Gaussian statistics (Stover, Schroeder, and
Germer 2012a). The TIS for this situation can be found from “exact” diffraction
calculations of a sinusoidal surface available on the NIST website and elsewhere.
Equation (8.10) shows the TIS, calculation for normal incidence, where Pn are the
diffracted orders from the grating that appear in the reﬂective hemisphere:
TIS =
2
∞P
n=1
Pn(α)
P0(α) + 2
∞P
n=1
Pn(α)
,
(8.10)
where α = 4πa cos θi
λ
,
and a is the amplitude of the grating. The rms roughness σ is then 0.7a, no matter
how many diffraction peaks are in the hemisphere and no matter how large the
value a.
TIS calculations as a function of σ/λ are plotted in Fig. 8.9 for two sinusoidal
grating periods and increasing amplitude. All of the calculations use normal-
incidence light of 0.633 µm with the electric-ﬁeld vector parallel to the grating
lines. The ﬁrst gating period is 1 µm, and only the ﬁrst orders diffract into the
hemisphere. The second grating period is 1.5 µm, and both the ﬁrst and second
orders appear in the reﬂective hemisphere. TIS calculations are made for these two
situations over a large range of grating amplitude values using several expressions.
Davies’s exponential solution and smooth-surface approximation from Eq. (8.9)
are also plotted. They are identical for low rms and start to diverge near σ/λ values
of 0.05, so the approximation is good up to about a twentieth of a wavelength.
The smooth-surface approximation continues as a straight line, and the exponential
expression approaches a TIS of 1.0, as expected. Also plotted are the results
obtained from Eq. (8.10) using ﬁrst- and second-order values found from the
Bessel function approximations found in Eq. (B.14) of Appendix B. These are
very close to the exponential solution up to about an σ/λ value of 0.12. For higher

170
Chapter 8
Figure 8.9
The exponential expression for TIS and its smooth-surface approximation
[given in Eq. (8.11)] are compared to diffraction calculations for two increasingly rough
sinusoidal gratings of constant frequency. The horizontal variable is σ/λ.
values, the Bessel results tend to oscillate instead of remaining at a TIS of 1.0.
Finally, the results of an exact diffraction calculation for the same sinusoidal
surfaces imposed on a silicon substrate are plotted. These also oscillate beyond
TIS = 1.0. The oscillations vary in location and amplitude with substrate material
and incident angle (Stover 2012a). (More instrument variations are examined in
the publication.) Once a TIS value approaching 1.0 is reached, the rms is no longer
uniquely related to the TIS, so the useful rms limit for the exponential form is about
an eighth of a wavelength for the conditions associated with Fig. 8.9.
There are two additional ways to extend this limit. First, notice in Eq. (8.9) that
the cosine of the incident angle is multiplied by the rms roughness. The data of
Fig. 8.9 and Eq. (8.10) both assumed normal incidence. Increasing the incident
angle to about 75 deg gives a cosine of about 0.26 and allows almost a fourfold
increase in the σ/λ ratio to almost 0.5.
Second, measurement of the specular reﬂection can be used. This can be done
by plotting (1 −TIS), which can be found from Eq. (8.9) by inspection:
1 −TIS ≡
P0
P0 + Ps
.
(8.11)
In effect, this is proportional to the specular reﬂectance, just as TIS is proportional
to the diffuse reﬂectance. It would be reasonable to measure a 1000/1 reduction in
specular reﬂectance or a σ/λ value of 0.21 from Fig. 8.9. Combining this with the
maximum change in incident angle of four times the highest value of σ/λ is about
0.8. Silicon detectors are responsive out to light wavelengths of about 1 µm, so if

Predicting Scatter from Roughness
171
all of these assumptions are true, the maximum rms roughness that could be found
via a silicon-based TIS system is in the neighborhood of 32 µin (microinches),
which is a common industrial surface.
Another way of looking at integrated scatter measurements is illustrated by the
data in Fig. 8.10. The graph shows data taken by measuring the diffuse reﬂectance
and the specular reﬂectance using an integrating sphere (of the type shown in
Fig. 7.20) as a function of sample rms roughness. The source was a 0.633-µm
laser incident at 5 deg on the sample. The reﬂectance data was converted to TIS
and (1 −TIS) and then plotted against σ/λ so that it takes the same form as the
calculations shown in Fig. 8.9. The samples are gray metals and semiconductors
having reﬂectances of about 0.35. The rms roughness was found in different ways,
and they do not all have the same frequency bandwidth. The smoother samples
were analyzed using the Rayleigh–Rice techniques described in previous chapters
to ﬁnd the rms roughness. The rms values varied from 0.3 to 800 nm, or about 32
µin. Unfortunately, no samples were measured between 20- and 100-nm rms. The
roughest samples were standard rough-surface examples found in machine shops,
and their rms values were inferred from the reported a.a. values. There is clearly
some uncertainty about the rms values and the associated spatial bandwidths. These
effects cause the two resulting curves to be somewhat irregular; however, the chart
can still be used to make some useful points.
Notice that the low-rms end of the TIS plot (Fig. 8.9) has a slope of −2 on the
log–log scale. This is expected because it is proportional to the smooth-surface
expression for the TIS [Eq. (8.19)] and lends credence to that expression. Above
a few hundred angstroms, the TIS starts to level out and loses any sensitivity to
roughness changes as it reaches a constant value. The (1 −TIS) values do just
Figure 8.10
Measurement of diffuse and specular reﬂectance from a number of surfaces
of different roughness.

172
Chapter 8
the opposite as expected. As the diffuse signal becomes less sensitive to changes
in roughness, the specular reﬂectance drops rapidly and becomes more sensitive.
Thus, at least for a particular product (with ﬁxed material and manufacturing
process) these two signals can be used to monitor roughness over a range far
exceeding the smooth-surface limit. Notice that the (1−TIS) values in Fig. 8.10 fall
off much more slowly than the corresponding plot in Fig. 8.9 [found from the exact
TIS expression inserted into Eq. (8.11)]. This is because an aperture of 2.4 deg was
used to collect the specular signal. To truly measure only the specular component,
the aperture would need to be close to the diffraction-limited spot size—just a
fraction of a degree. Thus, for the rougher surfaces, the specular reﬂection was
artiﬁcially large. Even so, it appears that these simple measurements provide a
practical method of monitoring surface roughness.
It certainly appears that TIS measurements can be made on industrial surfaces
to at least track changes, if not provide rms roughness estimates for surfaces
that are not even remotely optically smooth. Some applications employing scatter
measurement of optically rough surfaces will be given in Chapter 10.
8.3 Partial Data Sets
All BSDF measurements are incomplete in some way. Apparently, continuous plots
are usually the result of many closely spaced discrete measurements, and there are
always limits in scan length. In particular, near-specular measurements are limited
by instrument signature and a ﬁnite-width receiver aperture (see Sections 7.2–
7.4). There are situations where drastically reducing the number of data points
or extending the measured curve into difﬁcult-to-measure regions will offer large
returns in time and cost with minimum risk.
8.3.1 Fractal surfaces
Fractal surfaces, which were discussed in Section 4.5, have the unique property
that their PSDs follow power–law relationships and can be expressed in terms of
only two constants. A true fractal has a PSD that is a straight line on a log–log plot.
The molybdenum mirror of Figs. 8.1 and 8.2 is a good example of a fractal-like
surface. As pointed out in Section 4.5, there is an anomaly at zero frequency in the
fractal relationship that is not found in measured data. Power–law behavior is not
limited to front-surface mirrors. It is not uncommon for transmissive samples to
exhibit near-straight-line behavior of their BTDFs on log–log plots. The effect is
common enough that scatter speciﬁcations (see Chapter 13) can be written in terms
of a value and slope at a ﬁxed angle of the measured BSDF.
The case of n = 1 (one-dimensional slope = −1, two-dimensional slope = −2)
has some interesting properties. One of these is that the rms roughness values
calculated from S 2( f) are identical with those found from S 1(fx), as long as the
same spatial bandwidth is used. When n is greater than 1, the two-dimensional
rms roughness is larger than the one-dimensional value (and vice versa for n less
than one), but the change in the computed rms is slow with a change in n. Take
the case of silicon wafers where typically n takes on values between one and two.

Predicting Scatter from Roughness
173
This large increase in n results in the two-dimensional to one-dimensional rms
ratio increasing by only 25% (over the same bandwidth), and it does so in a nearly
linear fashion. Speciﬁcally, consider the case where the two-dimensional rms is
5 Å, and the two-dimensional slope is 2.4 (i.e., n = 1.4). Then, the corresponding
one-dimensional rms can be estimated as 5[1 + .25(.4)]−1 = 4.5.
It is particularly tempting to extend fractal behavior into the near-specular
region, where measurements are difﬁcult to take. Section 13.2.3 gives an example
where scatter speciﬁcations are developed using this technique. The point is that
extending a constant-slope PSD beyond its measured boundaries in order to predict
additional sample behavior is not always as risky as predicting stock market trends.
This is especially true if the material and manufacturing techniques have been
known to previously produce the predicted PSD. Granted, sooner or later a “Black
Monday” will be encountered by all speculators, but sometimes the odds are worth
taking.
8.3.2 Curve ﬁtting
Samples that have prominent spatial frequency components (on the surface or as
bulk index ﬂuctuations) exhibit diffraction peaks that are difﬁcult to predict from
the measurement point of view (the precision-machined surface of Section 4.3, for
example). Therefore, as recommended in Chapter 7, careful scatter measurement
employs receiver step sizes that are smaller than the aperture width. Using this rule
and a small aperture typically results in as many as 500 to 1000 data points in a
90-deg scan. On the other hand, polished samples, and even many one-dimensional
samples, have BSDFs that are relatively smooth, even though they vary over many
orders of magnitude. Figure 8.11 shows the BRDF of the molybdenum mirror
found by curve ﬁtting ﬁve logarithmically spaced data points. The curve ﬁt was
done with a cubic spline. Essentially, this means that the ﬁtted curve is forced
to go through each data point with a slope equal to the straight-line slope that is
obtained by connecting the two neighboring points. The slope at the end points
is the straight-line slope between the end point and its neighbor. The operation
can be applied to the various plotting combinations (i.e., log–log, log–linear, etc.).
Using the curve-ﬁtting routines in commercially available spreadsheets (and other
programs) is a fast and powerful way to present discrete data points.
It has already been pointed out that for an optically smooth surface, the BRDF is
often nearly proportional to the PSD. As a result, it makes sense to make use of the
low-pass ﬁlter and fractal-curve ﬁts that were used to model the PSD in Section 4.5.
(These relationships are not repeated here.) This also means that for a vast number
of samples and process-control applications, only a few data points are necessary
to obtain useful information about changes in a production process. In the limit, the
straight line in log–log space can be found from just two scatter measurements and
the BRDF (or PSD) found by an additional specular measurement. These concepts
will be applied in Chapter 11 where industrial applications are discussed.

174
Chapter 8
Figure 8.11
Curve ﬁtting to BRDF of the molybdenum mirror.
8.4 Scatter from Diffuse Samples
Diffuse samples scatter all of the specular light into the sphere about the sample.
Samples may be reﬂective, transmissive, or translucent. In the case of a diffuse
reﬂector, the TIS is very large because the power reﬂected in the specular direction
is very small. Thus, diffuse surfaces are, by deﬁnition, optically rough; however,
many reﬂective diffusers (such as paints) scatter from the bulk as well as the
surface. Diffuse samples require the entire hemisphere (or sphere) to be considered
in order to measure the total reﬂectance or transmittance. In the case of translucent
materials, secondary scattering usually causes the scattering area (or volume) to be
larger than the area (or volume) illuminated by the incident beam (see Fig. 8.12).
The combination of these effects can make the accurate prediction of scatter from
diffuse (rough) components very difﬁcult.
The hemispherical reﬂectance RH from an opaque diffuser can be deﬁned as
RH = 1
Pi
Z π/2
0
Z 2π
0
(dPs/dΩs) sin θsdφsdθs
(8.12)
in terms of the spherical geometry deﬁned in Fig. 1.6 or 7.13. This integral contains
all of the reﬂected light—specular and scattered. The incident power, the reﬂected
specular power, and the diffusely reﬂected power can be combined into ratios
to form the diffuse reﬂectance, the specular reﬂectance, and the TIS. Diffusely
transmitting samples can be similarly deﬁned. In general, the resulting scatter
patterns can be very complex. Fortunately, many diffuse materials do not scatter in
an arbitrary fashion. The easiest assumption to make about a diffuser is discussed
in the next section.

Predicting Scatter from Roughness
175
Figure 8.12
A piece of translucent opal glass has been raster-scanned, using the CCD
technique of Section 7.9. The ring around the central disk is an artifact of the BRDF
calculation. Multiple bulk scattering causes light to be radiated from outer regions, where
little or no light is incident. Thus, with Pi near zero, a large BRDF is calculated even though
the radiance from that location is lower.
8.4.1 Lambertian samples
A common assumption that is fairly reasonable for many diffuse samples is to
deﬁne the scattered radiance as a constant. This means that the scattered power/unit
solid angle falls off as cos θs. In other words, as an observer of the illuminated
spot moves in increasing θs toward the waist of the hemisphere, the measured
light intensity falls off in proportion to the apparent size of the radiating source.
At θs = 90 deg, the source is viewed on edge (zero apparent area), and the
scatter signal drops to nothing. This relationship is assumed true, regardless of the
source incident angle. Samples that scatter in this manner are known as Lambertian
samples. If the scattered intensity is proportional to cos θs, then the BRDF is a
constant:
BRDF = F = dPs/dΩs
Pi cos θs
= constant.
(8.13)
The value of the BRDF can be evaluated in terms of the hemispherical
reﬂectance by substituting F cos θs into Eq. (8.13) for the normalized scattered
intensity and solving for F:
RH =
Z π/2
0
Z 2π
0
(F cos θs) sin θsdφsdθs.
(8.14)
F = RH/π.
(8.15)
Further, if the sample has completely diffused the incident beam, the scattered
polarization will be independent of the incident polarization. Using subscripts on

176
Chapter 8
F to denote the incident and scattered polarizations, as we did with Q, gives
Fss = Fsp = Fps = Fpp = RH/(2π).
(8.16)
Thus, a good white diffuser does not have a BRDF exceeding 1/π, and a low-
reﬂectance diffuser (say, for example, a minimum of 1%) does not have a BRDF
less than about 3 × 10−3 sr−1.
Figure 8.13 shows the measured BRDF of several white diffusers on linear
scales. The BRDF is reasonably ﬂat over most of the hemisphere. The
hemispherical reﬂectance can be estimated by using Eq. (8.15) or evaluated by
integrating the curves as though the measurement is a sample on the (assumed)
symmetrical scatter hemisphere. Figure 8.14 shows the BRDF of several black
diffusers. The rise in BRDF at high angles is common among many black diffusers,
and a possible explanation for this effect is the large change in Fresnel reﬂectance
with incident angle that is associated with low-reﬂectance materials (Section 6.1)
and the fact that little light is scattered back out of the black material. Consider
a beam of light normally incident on a rough, black diffuse surface composed of
facets that are tilted in random directions. In general, rays that are scattered through
a large angle from specular must have encountered one or more facets at large
incident angles. These rays suffer less absorption than those that strike at near-
normal incidence. Of course, rays that are trapped into many reﬂections essentially
disappear through multiple absorption losses.
Figure 8.15 shows the depolarization of the scattered light from a piece of white
paper. Spectralon R⃝, a common white diffuser used in many laboratories as a BRDF
reference material (see Fig. 8.13), is also an excellent depolarizer. Its Mueller
matrix (which should be M00 = 1 with all other elements equal to zero) has been
Figure 8.13
The BRDF of several white diffuse reﬂectors.

Predicting Scatter from Roughness
177
Figure 8.14
The BRDF of several black diffuse reﬂectors.
Figure 8.15
Depolarization of scatter light from a white Spectralon R⃝sample is shown by
rotating an analyzer in the receiver to accept s- or p-scattered light. The source was s-
polarized.
measured to be M00 = 1.00 with M j j < 0.05 and all others approaching the noise
ﬂoor (Schiff et al. 1992b). Thus, the BRDF from this material is an excellent source
of depolarized light.
Using the above relationships and a book value (or estimate) of the
hemispherical reﬂectance allows rough predictions of diffuse scatter to be made.
Simply knowing the max/min bounds (which are less than three orders apart) can
be enough to determine whether or not measurements are required. Many diffuse
samples are not Lambertian enough to make use of this easy assumption. Another
approach is required for these situations.

178
Chapter 8
8.4.2 Non-Lambertian samples and material signatures
Many IR and visible remote sensing applications require a rather complete
knowledge of the BRDF of many different materials. For example, military
camouﬂage netting and paint perform well over the visible wavelengths, but are
the camouﬂaged objects invisible to a satellite using an IR sensor? What is the
optimum wavelength and polarization to use to check for the spread of spotted
knapweed in the western United States? To answer these types of questions, BRDF
data would be needed for essentially all incident directions and polarizations, all
scatter directions and polarizations, and over many different wavelength bands for
a huge variety of materials. A complete data set for a given material is known
as the material signature. Collection and even storage of such a data set for even
one material is obviously impractical. Instead, a model is developed that allows the
calculation of the BRDF at the particular directions, polarizations, and wavelengths
of interest. Based on the last section, it is easy to envision a straightforward
model based on the Lambertian assumption. All that would be needed for input
to the model is the hemispherical reﬂectance over the required wavelength regions.
Unfortunately, many of the materials in question fall into that broad region between
optically smooth and ideally diffuse, where an assumption of Lambertian behavior
would be inappropriate over at least some of the required wavelengths.
The obvious approach is to use an essentially empirical computer model that
requires a relatively small amount of measured data to predict the desired BRDF
values. A few carefully chosen data scans are taken as input to the model. Model
parameters are calculated from this data, and the result is used to predict the BRDF.
The model is easily checked for a few situations by comparing results to additional
experimental data. Taking even the reduced set of data required for the model is not
an easy task. Measurements must be taken out of the incident plane and at several
wavelengths. A review of some of the out-of-plane experimental issues is found in
Section 7.10.
Material signature codes are obviously of great interest to the government
(Department of Defense, NASA, etc.) and also to many of their contractors. The
manufacturers of military aircraft, for example, believe that this type of information
offers a potentially strong competitive edge. As a result, although several material
signature codes exist, very few of the algorithms on which they are based have
been published. Two exceptions are the Maxwell–Beard model, developed at the
Environmental Research Institute of Michigan (Maxwell et al. 1973) and the code
developed at McDonnell Douglas Corp. by Leader (1979).
8.5 BRDF Standard Surfaces
Although the procedure for making BRDF measurements is now standardized,
there is no BRDF standard sample. The closest example is probably the diffuse
whites used in the visible, which have a nominal BRDF of 1/π. Examination of
Fig. 8.13 reveals that due to laser speckle and some natural high-angle falloff,
these samples differ from the nominal value by several percent. In the mid-
IR region (where diffuse gold surfaces have been traditionally used as diffuse

Predicting Scatter from Roughness
179
whites), there are often surface-nonuniformity problems exceeding 100%. These
difﬁculties can be signiﬁcantly reduced by spinning the reference sample during
measurement to average out nonuniformity and speckle, but signiﬁcant variation
and uncertainty remains, especially when using the relative method to measure Pi
in the mid-IR region. What is really required for system checks is a BRDF standard
sample. Preferably, such a standard would have the BRDF value established by the
manufacturing method, or by some other means that is independent of a BRDF
measurement. One option would be the use of a sinusoidal grating measured by
optical proﬁlometer, with the ﬁrst-order diffraction as the “standard measurement.”
Unfortunately, this provides a system check at only one angle and one BRDF value.
Signiﬁcant progress in solving these various problems was reported by Church
and Takacs (1993). Their approach was to produce a smooth, clean surface with a
sharp-edged step of known height (determined by optical proﬁlometry). They have
found the associated (one-dimensional) BRDF in terms of the step height H and
the beam width centered on the step. Their expression is repeated here in slightly
different notation, where ω is the characteristic Gaussian beam radius (deﬁned as
the radius at which the beam intensity drops to e−2 of the peak value):
dPs/dθs
Pi cos θs
= 2 cos2 θi sin2(βH)
(2π)5/2 cos θsωλ f 2 ,
(8.17)
where β = π(cos θs + cos θi)
λ
,
and f = (sin θs −sin θi)
λ
.
The BRDF is deﬁned here in terms of a one-dimensional measurement [BRDF =
Ps/Pi∆θs cos θs, as in Eq. (8.5)], where ∆θs is the angular extent (width) of a slit
aperture (through which Ps is measured) oriented with its length perpendicular to
the (one-dimensional) streak of light from the step. The point is that, if the surface
step is square, the associated PSD can be shown to fall off as (1/ f)2. The step
height and the beam width, and hence the BRDF, can be established independently
of the scatter measurement. The step produces a relatively strong scatter signal
(the streak of light), which can be oriented in the incident plane for measurement.
Unwanted sources of scatter (such as contamination, microroughness, etc.) scatter
into the full hemisphere and produce only a low-noise background.
Figure 8.16 shows a 0.633-µm BRDF measurement of a 97-nm step on a silicon
surface taken with a slit aperture and a 0.66-mm-radius Gaussian spot centered on
the step. The BRDF predicted from Eq. (8.17) is also shown in the ﬁgure, and the
agreement is excellent. The use of relatively clean, sharp-edged steps of known
height appears to offer an independent check of BRDF measurement that covers
several orders of magnitude. It should be possible to produce such surfaces in a
variety of heights and materials to obtain BRDF reference standard samples that
can be used from the mid-IR to the near-UV regions. Such samples will greatly

180
Chapter 8
Figure 8.16
The BRDF measured from a 97-nm step (slightly curved line) is compared to
the BRDF calculated from the PSD of the step (straight line). Steps with square corners will
always have the (1/ f)2 (i.e., slope of −2) PSD form. As a result, they are good candidates
for use as both PSD and BRDF standards.
facilitate comparing instruments, checking system operation, and performing the
relative measurements of incident power described in Section 7.8.
8.6 Software for Prediction of Stray Light in Optical Systems
Analysis of scatter in optical systems is reasonably straightforward when only
two or three components are involved. The speciﬁcation examples in Chapter 13
illustrate back-of-the-envelope calculations that can be used for simple systems;
however, as the number of system elements increases, analysis by hand quickly
becomes unmanageable. Those familiar with the use of raytracing software will
appreciate the use of a computer to handle this type of calculation-intensive
problem.
Scatter prediction and analysis is more complicated than ray tracing. Raytracing
programs simply follow the laws of reﬂection and refraction to determine ray
location (which is more difﬁcult than it sounds when hundreds of rays and tens of
components are involved). Scatter analysis requires that all or part of each ray be
reduced to a scatter pattern at each component. The scattered light and the original
specular ray must be accounted for while they propagate through the system.
Scatter-prediction codes make use of various statistical techniques. Component
BSDF data (or predictions) and the usual raytracing information (component
location, radius of curvature, etc.) are used to deﬁne the system. The number of
rays and directions are often limited (at the operator’s discretion) to examination
of scatter from just a few “critical objects.” Using the programs can be a little like
playing a musical instrument in that, due to the operator inﬂuence on the obtained
output, beginners often miss the desired result.

Predicting Scatter from Roughness
181
Stray-light-analysis codes were developed in the early 1970s to improve
bafﬂes in space telescopes (Breault 1986) after it became apparent that BRDF
measurements, involving hundreds of data points, could often be represented by
simple three-parameter (low-pass ﬁlter) expressions similar to the ABC shapes
of Section 4.5. Over the following decades, a number of commercial codes were
developed and used in diverse industry applications including ﬂat panel displays,
car headlights, and LED lighting systems, as well as government space and military
projects. Systems became available that were compatible with standard computer-
aided design (CAD) modeling systems (Freniere, Gregory, and Chase 1997), thus
simplifying the task of entering system geometry.
These codes all had to solve a major scatter-prediction problem. Curve ﬁtting
BRDF data had solved the problem of not needing to store measured in-plane data,
which is usually all that is available, but left the issue of how to estimate the light
that is scattered out of the incident plane. So the question became, can incident
plane measurements be used to estimate hemispherical scatter for an isotropic
sample? If the sample meets the Rayleigh–Rice conditions, the answer is obviously
yes. Once the PSD is found, then hemispherical scatter can be estimated from other
incident angles and wavelengths. But for optically rough surfaces, where the PSD
cannot be found from the BRDF, there is a problem. Nevertheless, for an isotropic
sample, the incident plane data includes scatter from every fundamental surface
frequency and harmonic that scatters into the hemisphere, so for isotropic samples,
there is information in the incident plane that seems relevant to hemispherical
scatter. A huge advantage for many of the stray-light applications is that often only
estimates are needed. While the accuracy goal for measuring in-plane data is often
on the order a few percent, stray-light estimates of a few hundred percent are often
good enough to ﬁnd the ﬂaw in a bafﬂe system, or direct light from an illumination
system into the required directions.
Alan Greynolds (2012) was perhaps the ﬁrst to develop a sophisticated method
for estimating hemispherical scatter from in-plane data. Unfortunately, his work
was never published; however, a periodically updated outline of his approach can
be found on the Breault Research Organization (BRO) website (2012).∗Other
methods (often proprietary) are also used in the various available stray-light
codes, but Greynolds’ approach has been used in more than one. Another oddity
associated with this calculation—however it is accomplished—is that very little
experimental work has been published to explore the accuracy of hemispherical
scatter estimates from in-plane data. A paper on the topic will be out about the
same time as this book publishes (Stover et al. 2012b). An outline of Greynolds’
approach to the problem and comments on it follows.
Figure 8.17 shows the geometry used for analyzing the problem, regardless
of whose approach is used. The standard right-hand coordinate system is shown
with a unit vector S deﬁning the direction of an arbitrary scattered ray in the
θs, φs direction associated with illumination incident on the X, Y (sample) plane
∗After going to BRO.com, enter the “Knowledge Base” section and search for “Scattering in ASAP.” In that publicly available
PDF ﬁle, ﬁnd the section on “Isotropic Scatter Models,” currently under “Types of Scatter Models” for an outline of Greynolds’s
approach.

182
Chapter 8
Figure 8.17
The standard scattering geometry is displayed with a unit-scattering vector S
and the direction cosines β, α, γ related to the X, Y, Z axes, respectively, shown as distances.
This diagram facilitates expressing the direction cosines in terms of the scatter direction θs,
φs and then the spatial frequencies associated with the vector S.
at incident angle θi in the (φs = 180) plane. Examination of the situation shows
that the projection of S onto the X, Y plane has length sin θs, and that distances
β, α, γ on the X, Y, Z axes are, in fact, numerically equal to the direction cosines
of S relative to those same axes. This means that in direction-cosine space, the
unit-vector scattered ray projects to β, α on the X, Y axes, respectively, and the
specular reﬂection projects to β0, α0 on the −X, Z axes, respectively, for this
normal choice of putting the incident beam over the −X axis (α0 = 0). This
is the direction-cosine notation that seems to be favored by the stray-radiation
researchers. Greynolds deﬁned the variables T and V as shown below in terms
of the direction cosines. Because this book has emphasized spatial frequencies, the
conversions to frequency space have been made for
√
T. This is easily performed
by using Fig. 8.17 to express the direction cosines in terms of θs and φs, and then
noticing that the expressions for fx and fy appear in the T deﬁnition:
√
T =
q
(β −β0)2 + (α −α0)2 = λ
q
f 2x + f 2y = λf.
(8.18)
V = ββ0 + αα0 = sin θs cos φs sin θi.
(8.19)
The variable V covers all locations available in an in-plane data set and changes
with incident angle as well as scatter angle. Notice that the variable
√
T is simply
the projected distance from the specular reﬂection to the scatter vector in both
direction-cosine space and in wavelength-frequency space. Greynolds then plotted
V versus
√
T in a family of curves for different incident angles. Each point on

Predicting Scatter from Roughness
183
a curve has a BRDF value found in plane at that particular incident angle. The
assumption for estimating hemispherical scatter is that all hemispherical points
having the same θi and
√
T have the same BRDF. Further, by interpolating between
different θi plots on the V,
√
T plane, it is possible to estimate hemispherical scatter
for other incident angles and (if the material constants are not changing too fast)
even for other wavelengths. One ﬁnal caveat is that Greynolds’ formulation of
√
T
and V as variables offers a symmetry that should support reciprocity—the scatter
characteristic that, if the incident angle and scattering angle are interchanged, the
same BRDF is obtained. Notice the symmetry in Eqs. (8.18) and (8.19) allows
the scatter direction (β, α) to be interchanged with the specular direction (β0, α0),
which also changes the incident direction, without changing the values of either V
or T.
Unlike the discrete-defect scatter models, which have remained largely
proprietary, a number of stray radiation codes are commercially available and have
been used successfully in a variety of industry and government projects.
8.7 Summary
The precision with which BSDF data can be predicted depends on the accuracy
with which the sample can be modeled. Near-specular samples that ﬁt the
Rayleigh–Rice topographic criteria (smooth, clean, reﬂective) are the easiest to
predict. In fact, conﬁrmed predictions on samples that are known to ﬁt the criteria
constitute a good check on instrument calibration. The general case for this model
is conveniently broken into isotropic (polished) and one-dimensional (grating-like)
subsets that cover many practical applications. Fortunately, many optically smooth
surfaces have PSDs that are fractal in nature and follow a convenient power–law
relationship. Because these relationships exist in many places throughout nature,
the scatter of many samples can sometimes be predicted over wide ranges from a
small section of data. Rougher (diffuse) samples are subdivided into Lambertian
and non-Lambertian classes. Lambertian samples scatter at constant radiance,
regardless of angle of incidence. Scatter from near-ideal Lambertian surfaces of
known hemispherical reﬂectance is very easy to predict. Just the reverse is true for
samples that are neither specular nor perfectly diffuse.
The upper roughness limit for which the PSD can be found via diffraction
theory is determined by the Rayleigh criterion. The rms roughness can be found
for rougher topographic surfaces by TIS measurements without ﬁrst ﬁnding the
PSD. Characterizing the BRDF of a huge class of samples that violate the Rayleigh
criteria has become increasingly important for remote sensing applications. The
only practical way to obtain the full BRDF characteristic (or material signature) of
such samples is by means of computer codes that use a limited set of BRDF data
to predict the complete material signature. The software and algorithm problems
are not trivial, and as was seen in the last chapter, the hardware required to supply
the multiple-wavelength, variable-polarization, and out-of-plane input data is also
very difﬁcult to obtain. Scatter codes now exist that make use of all of the above
observations to predict scatter in optical systems. The codes combine the known

184
Chapter 8
or predicted BSDF of all system elements with raytracing techniques to provide
designers with system limits prior to reduction to hardware. Originally written to
develop telescope bafﬂes, these programs are now being applied to a wide variety
of optical system scatter problems.

Chapter 9
Detection of Discrete Defects
“It has long been an axiom of mine that the little things are inﬁnitely the most
important.” – Sherlock Holmes in A Case of Identity
Chapters 2–4 and 8 concentrated on the relationship between scatter and smooth-
surface topography. However, another extremely useful application of light-scatter
metrology is the detection and mapping of component defects that do not meet
the smooth, clean, reﬂective conditions of mirror surfaces. Examples of such
defects are surface contaminants, particulates, scratches, digs, coating globs, and
residues. If a smooth surface is contaminated with very many defects, the combined
scatter of the defects can dominate the surface BRDF as shown by Young (1976a,
1976b) in his study of particulate-contaminated mirrors. Nahm and Wolf (1986,
1987) also studied the contamination problem, using a modiﬁed Mie theory. In
measurement situations where scatter is being used to detect defects, surface scatter
is considered background noise, and the defect scatter is signal. Although defects
often scatter more light per unit area than the surrounding surface topography,
they can sometimes scatter considerably less total light because they have a cross-
sectional area much smaller than the illuminated spot, or because they are buried
just beneath a reﬂective surface. In such cases, a low signal-to-noise ratio results.
If it can be established that nontopographic defects scatter light differently from
the way surface topography scatters light, then these differences can be exploited
to improve signal-to-noise ratio and map the defects, using the raster techniques
described in Section 7.12. This chapter discusses the differences in topographic
and defect scatter and outlines techniques that have been used to enhance defect
detection.
Perhaps the most common application exploiting defect scatter is the use of
“particle scanners” in the semiconductor industry. Because this is covered in
Section 11.1 and further in Chapter 12, it is only mentioned here.
One way that has been used to improve discrete-defect signal-to-noise ratio
is to cross polarize the source and receiver. This technique has been employed
successfully for a variety of applications. It has been used to separate the specular
and diffuse return of radar signals from the moon (Mathis 1963) to infer the
relative amounts of moon rock and dust. The cross-polarization technique is used
as a standard scan to check for Lambertian scatter and subsurface scatter, as
part of the Maxwell–Beard model for obtaining material signatures (Maxwell
185

186
Chapter 9
1973; see Section 8.4.2). The method works because, for the correct choices of
incident polarization and observation angle, the scatter from surface topography
can be virtually eliminated, while enough cross-polarized defect scatter remains
to dramatically increase signal-to-noise ratio. When combined with raster or fast-
raster measurements (Section 7.9), the result is a sensitive measure of defect
size and location. Results can be analyzed further to produce statistics describing
sample defects (size, density, etc.).
A general understanding of the material in Chapters 1 and 3–7 is required for
this chapter. The next section gives an arm-waving explanation of the differences
in defect and topographic scatter and why the cross-polarization technique
works. Later sections give results obtained for large surface defects (height ≫
wavelength), particulate contamination, subsurface defects in transparent optics,
and subsurface defects in opaque materials.
9.1 Polarization Effects Associated with Defect Scatter
As mentioned above, the cross-polarization technique has been employed by
several different groups since the 1950s or earlier. In order for the technique to
work well, some care must be given to the choice of measurement parameters,
such as receiver position, incident angle, and aperture size and shape. As might be
expected, the optimum choice of these parameters is sample dependent. However,
some general guidelines can be formulated by analyzing the material presented in
the preceding chapters, and that is the subject of this section.
In Chapter 3, we saw that scatter from smooth-surface topography (diffraction)
occurs because of the phase changes introduced into the reﬂected light by the small
deviations in path length caused by surface topography. Scatter from other sources
can also be explained by induced phase and amplitude changes. For example,
even a perfectly smooth surface that has random, and possibly abrupt, changes
in dielectric constant would scatter light. Grain boundaries, which are evident on
the surface of many metallic mirrors, can provide a close approximation of this
situation. As illustrated in Fig. 9.1, scatter can be caused by many different types
of variation in material surface and bulk. If these variations are mild, then they can
be characterized by weak single-scatter events, as in the case of smooth-surface
topography, and polarization changes may not occur (Church and Takacs 1989a).
On the other hand, if the surface defects are more pronounced, then they may cause
multiple-scatter events, and dramatic polarization changes can be detected. The
following discussion concentrates on polarization differences between smooth-
surface (topographic) scatter (which has been extensively analyzed) and stronger
sources of scatter (particulates, subsurface damage sites, etc.) that can be exploited
to enhance defect detection. The object is to identify locations on the scatter
hemisphere in front of a smooth, clean, front-surface mirror that for certain source
conditions contain only one linearly polarized component. This component can
then be rejected with an analyzer in front of the receiver. Defects that scatter
to this location with a different polarization state can then be observed without
interference from surface scatter.

Detection of Discrete Defects
187
Figure 9.1
Scatter is caused by a variety of surface and subsurface imperfections. Only
the smooth, clean, front-surface topography has been used to predict the corresponding
scatter. Scatter from other defects can be fully characterized, but it is more difﬁcult to relate
it to defect parameters.
The smooth-surface requirement virtually assures that all surface scatter is the
result of single reﬂections from the surface. For all but the very highest scatter
angles, there is no chance for reﬂected light to encounter the surface a second
time. The result, as described by Eqs. (5.14) to (5.17) for the polarization constant
Q is that incident s-polarized light diffracted into the plane of incidence is still
s polarized. The polarization vector of incident p-polarized light scattered into the
incident plane is also unaffected. Light scattered out of the plane from either of
these incident beams contains a cross-polarized component. This is expressed in
Eqs. (5.15) and (5.16), where Qsp and Qps take on zero values in the incident plane
and nonzero values for out-of-plane scatter. Linearly polarized light that is incident
with both s and p components is elliptically polarized upon reﬂection because the
relative phase δ between the two vectors changes. At least three types of defects
can be readily identiﬁed that do not scatter in this manner.
If the surface features are rough, then light can be reﬂected (scattered) several
times before leaving the surface. For example, consider the following scenario:
An incident s-polarized ray of light enters a relatively deep surface feature and is
reﬂected off of a wall in an out-of-plane direction. It now contains both s and p
components. It strikes the far wall of the deep surface valley and is reﬂected away
from the sample and out into a plane that is parallel to, and just slightly offset
from, the sample plane of incidence. This second reﬂection further changes the
polarization vector of the ray. The (now) elliptically polarized ray is then measured
as plane-of-incidence scatter that contains both s and p components. Multiple-
scatter events involving many surface reﬂections are responsible for depolarizing
the light scattered by diffuse surfaces and explain why the ideal Lambertian surface
scatters light equally in p and s components regardless of the source polarization

188
Chapter 9
state. Rough surfaces and rough (deep or high) defects do not preserve the incident
s- or p-polarized state upon scattering into the incident plane.
The subject of scattering by small particles is an area of ongoing research, and
anything beyond the cursory explanation in Section 6.2 is outside the scope of
this text. Bohren and Huffman (1983), van de Hulst (1957) and Eremin (2000)
have published texts on this subject. Lamb (1991) has measured Mueller matrix
elements of spheres and right cylinders on surfaces. For our purposes here, it is
enough to say that for the general case of arbitrarily shaped particles larger than a
wavelength, incident s and p polarization are not preserved in the scatter pattern
even in the incident plane. The effect is easily observed by placing small particles
between two polarizers and holding them up to a light. When the polarizers
are rotated to the crossed position, the particulates are seen as bright dots on a
dark ﬁeld. Thus, just as for rough surfaces, the “noise” associated with surface
topography can be separated from a portion of the “scatter signal” associated with
a surface particulate.
For the special case of ﬁnding discrete defects on silicon wafers, the defects
(usually pits and particles) are mostly much smaller than a wavelength, making the
scatter pattern depend more strongly on object material and average diameter than
on shape. Signals are small, which makes roughness scatter a serious noise source.
Fortunately, silicon wafers are the smoothest manmade objects. Details on wafer
particle scanners and the issues associated with sizing and identifying defect types
are left for Section 11.1.
Light that is transmitted into a material is reduced exponentially in distance by
absorption, as described in Appendix A. The skin depth is the distance required
for an intensity reduction of e−1. In the visible, the skin depth varies from tens
of angstroms in metals, to thousands of angstroms in semiconductors, to many
meters in transparent dielectrics (such as optical ﬁbers). Subsurface defects in a
uniform substrate scatter like particulates. Some of the light that is scattered from
the defect back toward the surface is transmitted out of the substrate material and
can be detected to show defect location. This light amounts to backscatter from a
particle (adjusted by Snell’s law). As indicated above, the incident polarization is
not preserved in the plane of incidence. Thus, even in opaque materials, defects
beneath the surface can be detected if they are within roughly a skin depth of
the surface. Elimination of surface scatter in these measurements is particularly
important because the scatter levels from subsurface defects can be relatively low.
A key to improving defect signal-to-noise ratio is to remove as much of
the surface topography scatter as possible. The equations for the polarization
constant of Chapter 5 suggest more than one way to do this, as a variety of
observation and source polarizations and directions can be used. In addition
there is a series of scattering papers published by Germer’s team at NIST
(Germer and Asmail 1999a; Germer 2001; Germer 2007a; Kim, Ehrman,
Mulholland, and Germer 2002; Sung, Mulholland, and Germer 1999) studying
the polarization characteristics of roughness and surface bound features. It is
worth repeating here that Germer’s vector scattering code can be used for

Detection of Discrete Defects
189
many smooth-surface defect and roughness applications. It can be found at:
http://physics.nist.gov/Divisions/Div844/facilities/scatmech/html/.
The cross-polarization technique can be illustrated by considering the situation
where s-polarized light is incident on a surface with several discrete defects, as
shown in Fig. 9.2. A scatter receiver is centered on the surface normal with a
slit aperture in the plane of incidence. Light entering the aperture is transmitted
through a receiver analyzer that is oriented to pass only horizontally polarized light.
If there are no defects present, then most of the aperture light is s-polarized, and
ideally none of it will be transmitted to the detector. For two practical reasons,
a small amount of surface scatter is transmitted to the receiver. First, the crossed
polarizers (source and receiver) do not give zero extinction of the s-polarized light.
And secondly, because the slit aperture must have a ﬁnite width, a small amount of
out-of-plane light, with some p-polarized topographic scatter, will be passed to the
detector. Because the defect-dependent fraction of incident-plane scattered light
that is converted from s to p is unknown and is often relatively small, it is worth
looking more closely at the effect of these two noise sources.
In order to analyze the situation, the receiver signal must be obtained by
integrating the scattered light over the receiver aperture and then passing it through
the analyzer. An expression for the signal-to-noise ratio can be derived in terms
of sample and system components. Of particular interest is the optimum out-
of-plane opening of the aperture. Too small an opening drops the signal below
the electronic noise ﬂoor, and too large an opening increases unwanted surface
scatter. Figure 9.3 illustrates the situation of Fig. 9.2 with a bowtie-shaped aperture
centered on the surface normal. This shape is easier to analyze than the rectangle
of Fig. 9.2. The angular extent of the aperture is 2∆φ and 2∆θ. F′ is used to denote
the CC BRDF, with subscripts D and T used to indicate defect and topographic
scatter, respectively. The polarization components are indicated as before by s
Figure 9.2
An s-polarized (vertical) source and a p-polarized (horizontal) analyzed
receiver in the plane of incidence. The aperture is shown as a narrow rectangle centered in
the plane of incidence at the surface normal.

190
Chapter 9
Figure 9.3
The shaded bowtie aperture has dimensions of 2∆θ and 2∆φ. This aperture
shape is easier to analyze than the rectangle of Fig. 9.2 and restricts all values of φ to less
than ±∆φ.
and p. The extinction ratio of the two polarizers is given by ξ and is equal to
the ratio of minimum-to-maximum transmission of a crossed-polarizer pair as one
is rotated against the other. The light-power equivalent value of the background
electronic and detector noise is denoted by PNE. The signal-to-noise ratio can then
be expressed as
S/N =
4Pi
R ∆θ
0
R ∆φ
0
(F′
Dsp + ξF′
Dss) dΩs
PNE + 4Pi
R ∆θ
0
R ∆φ
0
(F′
T sp + ξF′
T ss) dΩs
.
(9.1)
The extinction ratio is applied only to the ss components. The various terms can
then be evaluated with the use of several simplifying assumptions. The term ξF′
Dss
is dropped because it almost always is signiﬁcantly smaller than F′
Dsp for a typical
value of ξ. Although the value F′
Dsp is unknown, it is reasonable to assume that
it is constant over the aperture and can be brought outside the integral, although
this may not be true if the aperture is too close to the reﬂected specular beam. The
values of F′
T ss and F′
T sp can be evaluated from Eq. (4.1), giving surface scatter in
terms of the polarization factor Q and the power spectrum S 2( f):
F′ = F cos θs = 16π2
λ4
cos θi cos2 θsQS 2( f).
(9.2)
To ease the calculation, the sample is assumed to be a good conductor and thus have
polarization constants that are given by the simpliﬁed expressions of Eqs. (5.22)

Detection of Discrete Defects
191
to (5.25):
Q = Qss + Qsp = cos2 φs +
 sin φs
cos θs
!2
.
(9.3)
It is further assumed that S 2(f) is a constant over the limited bandwidth represented
by the aperture. Thus, the signal-to-noise ratio becomes
S/N =
4PiF′
Dsp
R ∆θ
0
R ∆φ
0
sin θs dφs dθs
PNE + 4i
 16π2 cos θiS 2(f)
λ4
 R ∆θ
0
R ∆φ
0
[ξ cos2 θs cos2 φs + sin2 φs] sin θs dφs dθs
,
(9.4)
where the differential aperture is
dΩs = sin θs dφs dθs.
(9.5)
The bowtie-shaped aperture eases integration because the aperture boundaries
(integration limits) are along lines of constant θs or φs on the scatter hemisphere.
The shape of the aperture ﬁxes ∆φs ≪∆θs so the small-angle approximation is
used for φs but not for θs. Substituting cos φs = 1 and sin φs = φs, and then
integrating gives
S/N =
4PiF′
Dsp∆φ[1 −cos(∆θ)]
PNE + 4
3Pi
 16π2 cos θiS 2( f)
λ4

{ξ∆φ[1 −cos3(∆θ)] + ∆φ3[1 −cos(∆θ)]}
.
(9.6)
The value of ∆φ that optimizes the signal-to-noise ratio can now be found. As
expected, the signal (numerator) increases as the aperture is opened in either φs or
θs; however, the maximum value of ∆θ is limited by the width of the receiver and is
considered to be a constant. The ﬁrst denominator term is a constant. The second
and third denominator terms increase from zero as ∆φ increases. They are the
noise due to ss surface light transmitting through the analyzer and sp surface light
coming through the aperture just out of plane. As ∆φ is increased, the third term
grows faster than the second. The signal-to-noise ratio grows as ∆φ increases until
either the second or third denominator terms are approximately the size of PNE,
and the denominator starts to increase. When the noise is dominated by the second
term, the signal-to-noise ratio is roughly constant. Then as further increases in ∆φ
will eventually result in the noise being dominated by the third term, the signal-
to-noise ratio decreases, and smaller defects will start to be lost in surface scatter.
So not only is the bowtie shape easier to analyze, but it also reduces noise, as the
rectangular aperture contains some very large ∆φ values. The signal-to-noise ratio

192
Chapter 9
starts to decrease just before the point where the second and third terms are about
equal. This occurs at
∆φ =
"
ξ
 1 −cos3(∆θ)
1 −cos(∆θ)
!# 1
2
 3 deg for cos(∆θ) = 0.9,
and
ξ = 10−3. (9.7)
The relatively small value of ∆φ justiﬁes the earlier small-angle approximation.
Crossed polarizers with extinction ratios as low as 10−5 are available in the visible.
In the IR, ratios of about 10−1 to 10−2 are more common, but units lower than 10−5
can be purchased. The signal-to-noise ratio can be peaked by setting the differential
of Eq. (9.6) with respect to ∆φ equal to zero and solving for ∆φoptimum:
∆φoptimum =
 
9PNEλ4
8Pi(1 −cos θs)16π2 cos θiS 2(f)
! 1
3
=
"
9PNE
8Pi(1 −cos θs)FS S
# 1
2
.
(9.8)
The values PNE and S 2(f), or Fss, can be found experimentally. The larger of the
two values of ∆φ, found from Eq. (9.7) or (9.8), should be used to obtain maximum
signal at a good signal-to-noise ratio.
Obviously, other combinations exist. A bowtie oriented vertically (φs = 90 deg)
for the input situation of Fig. 9.2 gives identical results (remember that the
directions deﬁning s and p change with φs). Values of φs between 0 and 90 deg
result in excessive surface scatter passing through the analyzer. The situation for a
p-polarized input is more complicated because of the addition of terms required for
Brewster’s angle; however, similar results are obtained. p-polarized light incident
at Brewster’s angle reduces the near-specular surface reﬂection, but Qpp away from
the incident angle is not zero, so “surface noise” is still present in other directions.
Other zero-noise locations can be found elsewhere on the scatter hemisphere by
analyzing the full expressions for Q.
9.2 Bulk Defects in Transparent Optics
For many applications involving transmissive optics, it is useful to separate scatter
caused by surface roughness from that due to bulk defects. For example, substrates
to be coated for use as low-scatter reﬂectors (such as ring laser gyroscope mirrors)
are more sensitive to surface defects than to bulk defects. Damage just below the
surface of a polished optic is often caused in fabrication. Changes in fabrication
technique intended to reduce the generation of subsurface defects are difﬁcult to
monitor without the ability to separate surface and subsurface scatter.
Figure 9.4 shows the top view of a laser beam passing through a transparent
sample. The incident laser beam strikes the front surface, propagates through the
bulk, and exits through the back surface. Multiple reﬂections are not shown in this
ﬁgure. The sample scatters enough light such that a CCD camera and an eight-bit
frame grabber can record the image and send the information to a computer. A

Detection of Discrete Defects
193
Figure 9.4
Top view of the laser beam passing through a transmissive sample, showing
regions of bulk scatter and regions of surface and bulk scatter.
combination of bulk and surface scatter are viewed at the ends of the illuminated
volume (shaded areas), and bulk scatter alone makes up the center section. It is
apparent from this ﬁgure that signiﬁcantly large amounts of scatter from the bulk
could totally obscure measurement of scatter from the surface. One method used to
calculate the surface scatter is that of subtracting bulk scatter measured in the center
of the image from the surface- and bulk-scatter combination measured at the ends
(Orazio, Stowell, and Silva 1982). Unfortunately, this method sometimes results in
negative values for the calculated surface scatter. The negative values arise from
uncertainties in geometry and beam proﬁle, and from problems associated with
subtracting noisy signals of similar magnitude.
The measurement can also be made by applying a variation of the cross-
polarization technique (McGary et al. 1988). Using an s-polarized source, a
receiver analyzer, and an aperture that admits only light in or near the incident
plane, three images of the sample are recorded. The ﬁrst is with the receiver
analyzer removed. The second is with the analyzer in place and oriented to
pass s-polarized light. The third is with the analyzer rotated to pass only the
cross-polarized p component. The center of the beam, as recorded in the two
cross-polarized measurements, is used to determine the relative intensity of s-
and p-polarized light from the bulk scatter. This ratio is then multiplied by the
third image to obtain the total bulk scatter (s and p) without any surface scatter
present. This image is then subtracted from the ﬁrst (total-scatter) image. The
difference is an image of the surface scatter alone. Additional adjustments must
be made to the images to compensate for transmission of the analyzer, changes in
camera integration time, and changes in camera noise level with integration time.
Figure 9.5 is a photograph of the video monitor screen with the resulting total,

194
Chapter 9
Figure 9.5
Total scatter (top), volume scatter (middle), and surface scatter (bottom)
displayed on a video monitor.
bulk, and surface-scatter images superimposed for a Zerodur R⃝ﬂat. Horizontal
cross sections taken from the data shown in Fig. 9.5 are plotted in Fig. 9.6. The
solid line in Fig. 9.6(a) is a plot of the total scatter, while the dashed line shows the
bulk scatter. The surface scatter is shown in Fig. 9.6(b). The front surface shown
on the left side has a better polish than the back surface and scatters less. The
high-scatter signal from the back surface is visible on the right.
Due to a combination of scattering and absorption, the transmitted beam is
reduced in power as it passes through the volume. The data also provides a
means for calculating the exponential loss coefﬁcient α for the material. Assuming
the bulk to be homogeneous and isotropic, then light propagating through the
bulk decreases exponentially in intensity due to absorption and scatter (see
Appendix A). The loss coefﬁcient is obtained from the image of bulk scatter.
Figure 9.7 is a plot of beam intensity as a function of distance in the Zerodur
sample and was taken from Fig. 9.5. An exponential ﬁt was made to the center
portion of the curve, and the loss coefﬁcient was found to be 0.0178 mm−1. This
coefﬁcient can also be calculated using the measured values of sample reﬂectance,
transmittance, and thickness, which for the Zerodur sample gives a value of
0.0181 mm−1, conﬁrming the previous technique.
Similar proﬁles of the volume and surface scatter from a zinc selenide window
are shown in Fig. 9.8. The volume-scatter proﬁle peaks just under both surfaces.
This is probably due to subsurface damage that occurred during polishing.
Polycrystalline substrates are particularly sensitive to this kind of damage. There
is no evidence of large discrete defects in this ﬁrst sample, but the zinc selenide
of Fig. 9.9 shows several bulk defects. These two windows were part of a set of
samples that had been polished to similar surface ﬁnishes but had different bulk
qualities. Figure 9.10 shows BTDF scans of these samples taken at 0.633 µm. Each

Detection of Discrete Defects
195
Figure 9.6
Plots of horizontal cross sections taken from data shown in Fig. 9.5. In (a) the
total scatter (solid line) and the volume scatter (dashed line) are plotted. In (b) the surface
scatter is plotted. Scatter from the rear surface is seen on the right.
Figure 9.7
A horizontal cross-sectional plot of the bulk-scatter proﬁle is given by the solid
line. Data was ﬁt with an exponential given by the dashed line to obtain the extinction
coefﬁcient, 0.0178 mm−1, for the Zerodur sample.

196
Chapter 9
Figure 9.8
Plots of total, volume, and surface scatter for a zinc selenide window. In (a), the
total scatter (solid line) and volume scatter (dashed line) are plotted, and in (b), the surface
scatter is plotted. The front- and back-surface scatter are approximately the same due to
uniform ﬁnishing. The volume scatter peaks just under both surfaces.
Figure 9.9
Plots of total scatter (solid line) and bulk scatter (dashed line) for a zinc selenide
window with bulk defects.

Detection of Discrete Defects
197
Figure 9.10
BTDF scans of the zinc selenide windows of Figs. 9.8 and 9.9. Each window
was scanned in the plane of incidence for Fss and Fsp.
sample was scanned twice, once to obtain Fss and once to obtain Fsp. Notice that
for these samples the ratio of Fss to Fsp is about the same (remember the log
scale). This indicates that the bulk defects are relatively weak. They do not cause
multiple-scatter events that are responsible for depolarization.
9.3 Near-Point-Scatter Sources
The cross-polarization technique can also be used to separate surface-roughness
scatter from surface-contaminant scatter. In order to accomplish this, CCD raster
measurements (Section 7.12) are combined with the separation technique. The
result is shown in Fig. 9.11, where colors (shades of gray) are used to map BSDF
scatter values as a function of location on a front-surface mirror. In the top half of
the ﬁgure, scatter is due predominantly to surface roughness. Notice the prominent
scratch running diagonally across the sample. Several dust particles, scattering
at about 25 times the background level, can also be found. In the lower half of
the ﬁgure, the same sample area is mapped, using the separation technique to
suppress scatter from surface roughness and pass contaminant-induced scatter.
Notice that the same prominent contaminants can be found in the lower image.
The contrast between contamination scatter and background has been increased
from 25:1 to 1000:1 and is limited by the dynamic range imposed by the CCD
camera electronics. Given sufﬁcient dynamic range in the electronics, the contrast
ratio should approach the extinction ratio of the polarizers. The sample area in
Fig. 9.11 is approximately 6 × 12 mm, and the pixel resolution on the sample is
20 µm.
Figure 9.12 shows a BRDF raster map of a front-surface mirror with particulate
contamination and polarization ﬁltering. The data is then organized into the
histogram shown in Fig. 9.13. BRDF levels are plotted horizontally, and the

198
Chapter 9
Figure 9.11
The top half is a raster map of all sample scatter. The bottom exposure of the
same sample area is a raster map with surface scatter suppressed by the cross-polarization
technique.
Figure 9.12
CCD raster scan of the contaminated mirror using the cross-polarization
technique.
number of pixels at each level vertically. The near-Gaussian shape is the noise
distribution signals of near-zero light pixels, and the high BRDF spikes are due to
contamination.
Figure 9.14 shows the cross-polarization technique used to locate and map
splatter defects on a coated metal surface. A coating has been applied to harden
the polished surface. Notice that the scatter signal is weaker on the relatively ﬂat
top of the larger defects than on the steeper edges.

Detection of Discrete Defects
199
Figure 9.13
A histogram of the raster data in Fig. 9.12. The low BRDF peak is due to noise
signals associated with a dark ﬁeld.
Figure 9.14
The cross-polarization technique used to locate and map coating defects. The
resolution is 2.5 µm/pixel.
9.4 Nontopographic Defects in Opaque Materials
Precision-machined mirrors tend to have much larger cross-polarized BRDFs than
their polished counterparts, so one would guess that the amount of postpolishing
required to remove subsurface damage from diamond-turned mirrors could be
monitored with the cross-polarization technique. The technique can be used with
semiconductor wafers to identify defects that are within a skin depth or two of the
surface. Defects can be located that are not apparent by inspecting the surface of
the wafer. This can be especially important in developing high-volume production
techniques for materials that are softer than silicon, such as gallium arsenide.

200
Chapter 9
9.5 Summary
The location and mapping of defects using scatter measurements is a powerful
inspection technique. Its purpose is often different from more conventional scatter
measurements in that the defect size, number, or density could be the issue of
concern instead of how much light is scattered. Scatter is just the means of
detection and mapping. The cross-polarization technique is a powerful tool in
such cases. The true scatter level is suppressed to obtain a low-noise indication of
defect location and size. The technique has been applied to a variety of inspection
problems and is ﬁnding use in both the semiconductor and optical industries.

Chapter 10
Appearance and Scattered
Light
“My wife has lovely colored eyes. I particularly like the blue one.” – Bob
Monkhouse
Scatter plays a major role in how things appear; therefore, “appearance” deserves
mention in this book. This chapter concentrates on some of the issues related
to scatter that affect appearance; however, there is a lot more to appearance
than just scatter. Color is a major factor in appearance, and the quantiﬁcation
of color is not an issue in this text. Gloss (specular reﬂection measured under
special circumstances) is another appearance quantiﬁer. The response of the human
eye also modiﬁes appearance. For a full treatment of these other issues, The
Measurement of Appearance by Hunter and Harold (1987) is a good place to start.
Nevertheless, scatter measurements are an excellent way to monitor appearance
(and texture) in manufacturing situations, where circumstances do not allow the use
of a well-deﬁned relationship (such as the Rayleigh–Rice golden rule) to quantify
surface statistics. Because the CCBRDF is a measure of scattered light as seen
by the eye, it (as opposed to the BRDF) is usually used for appearance. (The
differences are explained in Section 1.5.)
10.1 Beauty is in The Eye of the Beholder—And What We See
is Scattered Light
That statement pretty well summarizes a main point of this chapter. The
CCBRDF changes dramatically with the light source (wavelength, incident angle,
polarization) as well as with surface variables (roughness, shape, material, etc.).
As a result, providing a measured appearance number (like rms), or even an
appearance function, is not really practical. Nevertheless, appearance can be
monitored, and it is important to do so. Consider the issue of adding decorative
hardware (door hinges, cabinet knobs, etc.) to a new room in a house or
to replace a broken unit. Making the new parts look like the old ones is
important. It would be nice if the “antique bronze” purchased several years
ago (and produced at site ABC) could be matched by the same company now
manufacturing at site XYZ (probably in China). Alternatively, just consider the
201

202
Chapter 10
(easier?) manufacturing problems associated with maintaining substrate-surface
ﬁnish and coating parameters on thousands of parts produced over a few months.
The substrate ﬁnish depends on tool wear and substrate material (to mention
a couple of factors), and the coating depends on material mixture and oven
temperature (to mention a couple more). Changes in these variables taking place
over hours, days, weeks, or even months can dramatically change the appearance
of “antique bronze.”
While it is not practical to monitor all of the combinations of lighting the
product will be subjected to, it is pretty clear that if the appearance changes,
then the CCBRDF has changed—after all, “what we see is scattered light.” If a
system can be devised that appropriately (and quickly) monitors and classiﬁes the
scatter pattern, then notable changes in scatter imply a change in appearance. These
changes can be used as a signal to modify the appropriate manufacturing variable
before “antique bronze” becomes “rusted steel.”
10.2 Practical Appearance Monitoring
Products manufactured in bulk require fast measurements, even if the product is
only sampled. There is simply not time to even begin to check them for different
lighting conditions and viewing angles. In addition, most of the products in which
appearance is an issue are optically rough, so there is no straightforward analytical
relationship between the scatter and the surface ﬁnish.
The key is to identify several good (acceptable) samples of a given product and
several, or a set, of bad (unacceptable) ones. That is to say, some samples may
fail because of texture, and others may fail because of coating issues, or there
may be other causes for failure. Once these are identiﬁed, a series of CCBRDF
measurements are taken on each class of sample (i.e., Good, Bad 1, Bad 2,
etc.), all at the same location on the selected parts. As a general rule, these
laboratory measurements should be taken over a large part of the reﬂective (or
transmissive) hemisphere and should include the direction of specular reﬂection.
There is going to be a lot of data, but in most cases, the signals will be large,
so noise will not be an issue. The laboratory instrumentation will probably be
a screen-based scatterometer, as described in Sections 7.5 and 7.11. If there are
observable appearance differences in the parts (making them Good or Bad), then
there will be differences in the measured scatter patterns. Locate the areas of the
patterns where the differences are the greatest, and design simple ﬁxed single-
detector scatterometers for the manufacturing line that will detect these changes so
that manufacturing parameters can be adjusted.
Consider the following simple example that compares scatter data taken on a
screen-based instrument from two plated-metal tiles that have been brushed for a
desired ﬁnish. While the plating is an isotropic process, the brushing makes the
samples nonisotropic and gives them a deﬁnite surface lay. Although the intent
is for the two tiles to appear the same, in fact, they look different. One of the
manufacturing issues is that there are variations in the amount of brushing applied.
Figure 10.1 shows CCBRDF data taken on Sample 1 with a 6.35-nm s-polarized

Appearance and Scattered Light
203
Figure 10.1
Measured CCBRDF data from Sample 1 is shown as a three-dimensional
image above the sample X, Y plane, with the origin below the direction of specular reﬂection.
The incident plane is X, Z, and most of the scattered light is in the X, Z plane because
the brush marks on the surface run parallel to the Y axis. Data and ﬁgure courtesy of
ScatterMaster, LLC.
source, incident at 30 deg above the −X axis, using a screen- or camera-based
instrument. The brush marks are nominally perpendicular to the incident plane
and create a well-deﬁned streak of scatter. After measuring both samples in this
manner, incident-plane proﬁles of the two CCBRDF streaks are made, as shown
in Fig. 10.2. Notice that Sample 1 is clearly more specular, with a better-deﬁned
peak; however, you cannot see your face in either sample. Figure 10.3 compares
the CCBRDF proﬁles of the two samples running across the streaks but through the
two peaks. At higher-scatter angles, Sample 1 scatters slightly less light because it
is directing more light in the specular direction. High-angle scatter across the streak
is caused by a combination of roughness along the brush lines and roughness left by
the plating process. One way to monitor the process would be to place detectors in
both the specular direction and in the high-angle cross direction (out of the streak)
and set limits for these two signals. The instrument software can be used to deﬁne
virtual detectors at arbitrary scatter locations.
Figures 10.4 and 10.5 show the CCBRDF data as grayscale plots for the two
samples. The view is like looking straight down the Z axis in Fig. 10.1. Notice
the two dark circles near the top (high-angle cross scatter) and center (specular
reﬂection). Integrating the CCBRDF over these two virtual detectors gives the
directional reﬂectance. The values in the specular direction are 9.2% and 4.9%, and

204
Chapter 10
Figure 10.2
CCBRDF proﬁles along the streaks of Samples 1 and 2. Data and ﬁgure
courtesy of ScatterMaster, LLC.
Figure 10.3
CCBRDF proﬁles across the streaks and through the specular reﬂections of
Samples 1 and 2. Data and ﬁgure courtesy of ScatterMaster, LLC.

Appearance and Scattered Light
205
Figure 10.4
A top view of the CCBRDF from Sample 1 in grayscale. The two dark
circles are virtual detectors deﬁned in software to compare directional scatter signals. The
ellipse/rectangle deﬁnes an area that corresponds to the signal level at 10% of maximum.
Courtesy of ScatterMaster, LLC.
Figure 10.5
A top view of the CCBRDF from Sample 2 in grayscale. The two dark
circles are virtual detectors deﬁned in software to compare directional scatter signals. The
ellipse/rectangle deﬁnes an area that corresponds to the signal level at 10% of maximum.
Courtesy of ScatterMaster LLC.

206
Chapter 10
in the high-scatter direction, 0.15% and 0.14% for Samples 1 and 2, respectively.
Levels for these two signals could be easily deﬁned to control sample appearance.
This would probably work well for an automated system in which the tiles are
moved rapidly down a horizontal track after brushing or cleaning.
If there is time to measure each sample a little more completely, another
technique is available. Notice that in Figs. 10.4 and 10.5, there are ellipses enclosed
in rectangles that surround most of the streak. The software was set to inscribe
the streak with best-ﬁt ellipses at a level equal to 10% of the peak streak signal,
and then ﬁt them with rectangles. The rectangles have relative sizes of 20 × 1
and 67 × 3 deg around specular for Samples 1 and 2, respectively. Sample 1 has a
much smaller rectangle because it has a much higher peak signal. These signals are
more sensitive to differences in the samples than can be shown simply comparing
specular reﬂectance and scatter level.
None of these signals actually measure appearance because appearance cannot
be easily quantiﬁed with a few numbers. The measurements clearly identify regions
where there are changes in scatter (directional reﬂectance) that must be related to
appearance. Because the measurements are reported in a standardized format, they
provide a repeatable quantitative way to monitor product appearance no matter
when or where the products are being produced.
10.3 Other Examples
Flat panel displays (you probably use several) are another product where scatter
characteristics determine appearance. Both image sharpness and viewing-angle
variation are deﬁned by the combined BTDF of the elements making up the display
screen. The technique described in the last section of comparing “good ones and
bad ones” to deﬁne key measurements that will detect manufacturing drift can be
employed to deﬁne in-house speciﬁcations that will reduce product scrap.
Now, let’s go behind the screen. Many of the images we enjoy in today’s
entertainment are computer generated. From a space ship to King Kong, they
can be made to look “real” because their appearance changes with both viewing
angle and illumination (incident) angle. The information needed to create the
image comes from what can be thought of as BRDF tables: directional reﬂectance
over appropriate wavelengths as a function of incident angle and viewing angle.
These tables can be formed from scattering models, actual measurements, or a
combination of both. In the case of the 2005 ﬁlm version of King Kong, the “BRDF
tables” were created by combining a scattering model (Marschner et al. 2003) with
a series of digital images (using different incident and observation angles) of a
manufactured hairy surface, i.e., bleached yak hair protruding from silicon skin
(Harvey 2011). Marschner’s model was created from a series of digital images of a
single human hair and deﬁnes the BRDF in terms of a number of input parameters
related to hair strand. Harvey used his yak hair photos to deﬁne input parameters for
Kong’s hair, and then applied the model. To look real, one side of King Kong’s arm
should scatter differently in the morning sun than the other side, and the appearance
should vary as he moves, i.e., the scattering geometry should change. The computer

Appearance and Scattered Light
207
takes over and applies the BRDF information to King Kong’s image based on
the geometry of the speciﬁc scene. When King Kong (or the camera) moves, the
scattering geometry changes, the BRDF values change, the image changes, and
(presto!) Kong appears “real” to our eyes. Aren’t computers wonderful?
10.4 Summary
Appearance, like beauty, is an elusive quantity. The point of this chapter is that
even though it may be impossible to measure appearance, it is not impossible to
monitor (or to create) it. The key is to appropriately monitor scattered light, and
that is accomplished by comparing scatter patterns and identifying the regions that
are sensitive to change in the product of interest.

 

Chapter 11
Industrial Applications
“You can’t do today’s job with yesterday’s methods and be in business tomorrow”
– Anonymous
It should be obvious at this point that scatter measurement is a source of metrology
not only for the laboratory, but also for many production applications. The purpose
of this chapter is to review several of these applications. Some applications require
only that changes in a production process are detected, with no need to quantify
the change in terms of surface statistics or defect density. The semiconductor and
computer disk industries are high-tech examples of situations where the increased
use of light-scatter metrology is being pushed by tighter product requirements.
Many general manufacturing applications rely on the experienced human eye
to qualify a product. Some of those experienced eyes have reached retirement
age, and scatter metrology, which amounts to a quantiﬁable measure of product
appearance, offers a way to standardize quality control without retraining. These
applications rely on the combination of high-speed, noncontact quantiﬁcation of
product characteristics that scatter measurement offers.
A large portion of this book has been devoted to obtaining surface-roughness
parameters from measured surface scatter. The various conditions necessary for
these calculations to be made accurately have been discussed in some detail. In the
optics and semiconductor industries the smooth, clean, front-surface requirements
are met in many situations. However, in other industries this is often not the case.
Fortunately, in many applications it is not necessary to actually compute roughness
(or BSDF) parameters. It is enough to be able to quickly detect a difference in
scatter level that, through experience, can be related to a change in product quality.
Experience is gained for these relative-measurement situations by examining good
and bad product samples in a controlled laboratory situation. In this manner, the
polarization, wavelength, incident angle, and scatter angles that optimize detection
of changes in quality can be determined. The laboratory situation is used to
simulate the desired in-process instrumentation.
The purpose of the examples in the following sections is to review several
important applications and expose the breadth of potential uses outside the optics
industry. Chapter 12 reviews a number of international scatter-related standards
that have been written to further industry communication, and Chapter 13 discusses
the generation of speciﬁcations for scatter measurements.
209

210
Chapter 11
11.1 Semiconductor Applications
Light scatter has been used to map and size particulates on silicon wafers since the
1980s, but in contrast to the optics industry, it was not until the early 1990s that
microroughness was considered a serious problem in the semiconductor industry
(Abe et al. 1992; Denes and Huff 1992; Bawolek et al. 1993; Bullis 1994). It is
interesting that these two industries approached the problem of component surface
roughness so differently.
The optics community started by devising means to measure roughness through
proﬁlometry, scatter, etc., and carefully monitored its progress in producing better
surfaces. From the mid-1960s to the late 1980s, the instrumentation, standards,
and conventions necessary for measurement, communication, and speciﬁcation
of optical surface roughness were developed. The means to polish better optical
surfaces never really exceeded the capability to measure them. Meanwhile, during
roughly the same time period, engineers and scientists in the semiconductor
industry were producing surfaces so smooth that characterizing roughness was not
a major concern. Their attention was focused on a host of other problems associated
with increasing product yield and quality of products that were rapidly growing in
complexity.
The author remembers measuring the scatter from a silicon wafer sometime
around 1980–81 and being astounded at the lack of a visible scatter spot on the
surface (was the source laser really on?) and how fast the signal reached the
instrument NEBRDF. It was obvious that the optics community still had a great
deal to learn about polishing surfaces. Of course, there is an advantage to having
single-crystal substrates to work with, but the difference was amazing. By the mid-
1990s, the optics community had learned more about producing smooth surfaces,
the BRDF was standardized, the PSD was being used to characterize roughness,
and bandwidth limits were being accepted by the industry cognoscenti. Meanwhile,
the semiconductor industry was hitting the surface roughness wall as ever-tighter
device speciﬁcations forced them to detect smaller and smaller surface pits and
particles. The problem was simple—smaller discrete defects were hard to see in
the presence of surface roughness scatter (referred to as haze). Learning from the
optics community (and the ﬁrst edition of this book), they quickly caught up with
the optics industry and mastered issues of spatial frequencies, PSDs, comparison
measurements, and associated standards.
Because scatter is a fast, noncontact area measurement, it is an obvious
choice for off-line (laboratory), on-line, and in-line instrumentation needed to
characterize roughness in this industry. As will be seen in the following sections,
it turns out that silicon is an ideal material for roughness analysis by scatter. The
ever-tightening requirements and the economics associated with producing large
quantities of faster, smaller semiconductor products can be expected to stimulate
the development of new capabilities in scatter-based instrumentation. Because
turnabout is fair play, the optical industry also beneﬁted from these advances. The
following sections review the current problems, issues, and capabilities and give a
preview of expected improvements.

Industrial Applications
211
11.1.1 Finding small particulates and point defects on polished
surfaces
A number of laser-based particle scanners have been available for several decades
that use the sudden increase in scatter signal from a scanning laser beam to
map defects and particulates on, or near, the wafer surface. These measurements
have had their greatest impact as a means of checking and improving process
cleanliness in both material and wafer fabrication. They are particularly important
as a production process comes up for the ﬁrst time, where they are used to
identify sources of process contamination that prevent the high yields necessary
for proﬁtable operation. Surface pits, particulates, and subsurface defects can all
cause these systems to register the location and relative scatter signal size of a
surface problem. Because of the uncertainty over the cause of a particular signal,
these defects have been referred to as light point defects (LPDs), or, more recently,
light-scattering equivalents (LSEs).
Most of these particle-scanning systems integrate the scattered signal through
collection optics onto one, two, or more detectors. Signals are usually expressed
in parts per million (PPM) against a model-speciﬁc standard, or simply in volts.
Because the various models available use different angular-integration limits,
incident angles, wavelengths, and polarizations, comparison of PPM values from
one model to another is pointless but often done anyway. Originally, little design
attention was been paid to the spatial frequency limits imposed by the collection
optics, and, in fact, the limits can change during a scan because of incident-angle
variations and/or relative motion of the scatter source to the collection optics.
Scanners developed in the mid-1990s and later addressed most of these issues.
The measurements made by these instruments cannot be easily converted to
surface-roughness information. The background signal, measured when a particle
is not illuminated, is called haze. It is simply the integrated scatter from whatever is
in the illuminated spot (roughness, ﬁlms, very small particulates, etc.). Background
haze is a source of noise for particle-scanning measurements and appertains
to determining the smallest LSE that can be detected. Obviously, the use of
BRDF and TIS measurements (for haze quantiﬁcation) and the conversion to PSD
and bandwidth-limited rms values (for topographic scatter) are appropriate for
understanding many of the issues involved in these complex measurements.
New semiconductor device speciﬁcations are imposing additional requirements
on the next generation of wafer scanners. One very important requirement, the
detection of much smaller particles, is driven by the need to build circuits with
smaller features on the wafer. A reduction in linewidth by a factor of 2 drops the
minimum acceptable particle diameter by the same amount. A rough rule of thumb
is that particulate diameter must be kept below minimum feature size. Linewidths
dropped from about 1 µm in the 1990s and are approaching 10 nm as of publication
of this book. This drop has required a huge improvement in sensitivity, as particle
scatter tends to drop as diameter to the sixth power [see Eq. (1.8)]. To put this
into perspective, assume that the wafer was about the size of the San Francisco
peninsula and the illuminated spot was about the size of a football ﬁeld (instead

212
Chapter 11
of approximately 0.005 mm2), then a 20-nm particle would be about as large as
a golf ball. At a scan rate corresponding to half a minute for a 300-mm-diameter
wafer, then a modern scanner would have 200 nanosec to determine if there was a
golf ball on the football ﬁeld. Particle scanners are truly amazing scatterometers.
Of course, at roughly $1,000,000 each, you do expect some performance. As you
read this text there are several thousand scanners operating.
Much of the background haze that limits particle detection comes from surface
roughness and from the instrument source optics (instrument signature). The six
obvious approaches to improving particle detection are (1) to make smoother
surfaces (reducing roughness scatter), (2) increase the power density in the
illuminated spot (increasing particle scatter but not roughness scatter), (3) ﬁnd
new ways to discriminate particle scatter from roughness scatter, (4) reduce
illumination wavelength [again, see Eq. (1.8)], (5) reduce Rayleigh scatter through
the introduction of a low-scatter gas, and (6) reduce instrument signature. All of
these have been considered or employed in scanner designs since the late 1990s.
11.1.2 Scattering and roughness characterization of silicon
It was pointed out in the last section that reducing wafer front-side roughness would
improve particle detection. It has also been speculated that reducing roughness
increases gate oxide breakdown voltage and could be a contributor to problems
in other aspects of device fabrication (Bullis 1994). These potential effects are
documented only with great difﬁculty because of the number of production steps
(each potentially changing surface roughness) required to create features that
can be tested (such as a gate oxide capacitor). Even so, it stands to reason
that roughness will eventually play a role in component quality as component
dimensions shrink. The roughness of wafer backsides and edges is also of concern.
In-process planarization, accomplished via chemical mechanical polishing and
performed to assure a ﬂat surface for photolithography, is another step that is
sensitive to surface roughness. So, there are several production applications where
reducing roughness on bare wafers or other production process surfaces is of value.
The logical question is whether silicon roughness can be characterized via light
scatter. Examples have been given elsewhere in this book (see Section 8.1.2) of
materials whose surface scatter is dominated by effects other than topographic
scatter. If this is true for silicon, then additional polishing will be of only marginal
beneﬁt in reducing background haze, and further, light scatter cannot be used to
provide a measure of wafer surface roughness.
Figures 11.1 and 11.2 show the PSDs calculated from BRDF measurements
taken at several wavelengths in the near-IR to near-UV range on bare silicon
wafers. The agreement in these measurements is excellent. Wavelength scaling for
silicon sputtered on fused silica has also been reported (Stover and Bernt 1993).
Figure 11.3 compares the measured BRDF of a wafer at different rotations about
surface normal. The lack of variation between scans demonstrates that this wafer
is isotropic.
Figure 11.4 compares the PSDs of a bare silicon substrate and a sister wafer with
an epitaxial layer of silicon (Stover et al. 1994). Both wafers wavelength scale,

Industrial Applications
213
Figure 11.1
A silicon wafer exhibits wavelength scaling.
Figure 11.2
All smooth, clean silicon seems to wavelength scale, but the PSDs are not
always fractal.

214
Chapter 11
Figure 11.3
Because the BRDF does not vary with orientation angle, this silicon wafer has
an isotropic surface roughness out to about 2 µm−1. Many polished wafers have crystalline-
related periodicities beyond this point.
which means that the calculated PSDs are reasonably accurate. The addition of the
epitaxial silicon produces surface changes that reduce low-frequency roughness
and increase high-frequency roughness. The crossover point comes at about
5 deg from the specular beam. Thus, an rms measurement made with an optical
proﬁlometer would ﬁnd the substrate to be much rougher. On the other hand,
background haze measurements made with a particle scanner (where integration
typically starts outside 5 deg from specular) would result in the conclusion that the
epitaxial surface was rougher. The data dramatically demonstrate the usefulness
of the PSD presentation and the beneﬁts of understanding bandwidth limits. This
behavior has been observed on more than one sample. If it is typical of the epitaxial
process, then because of the increased haze, it could be an argument against its use
in applications where the detection of very small particles is required.
Many wafers have now been measured for a variety of industry, ASTM, and
SEMI studies. As long as clean, uncoated wafers are used, the answer seems to
be that silicon exhibits qualities that make it an excellent candidate for roughness
characterization by light-scatter measurement. For these situations, where scatter
from the bare wafer surface is topographic, haze can be reduced (and thus smaller
particles can be detected) by further reducing surface roughness.
As a further check, the BRDF of a silicon surface was measured and the resulting
two-dimensional PSD was ﬁtted with a straight line (Stover et al. 1994). This ﬁt,
expressed as a fractal in terms of Kn and n (see Section 4.5.2), was
S 2(f) = 10−2/f 3.13 Å
2 µm2.
(11.1)

Industrial Applications
215
Figure 11.4
The addition of an epitaxial layer of silicon to the silicon substrate dramatically
changes the shape of the PSD on this wafer.
This expression, when converted to the corresponding one-dimensional PSD via
Eqs. (4.28) and (4.29), was found to be
S 1( fx) = 1.92 × 10−10/ f 2.13 µm3.
(11.2)
The same surface was measured with two optical proﬁlometers, and the one-
dimensional PSDs were found from that data according to the recipe of Eq. (2.35).
The three independent PSDs, which are compared in Fig. 11.5, show excellent
agreement over their regions of overlap. This is a demonstration that scatter from
this wafer is predominantly from isotropic surface topography. It also shows
that optical proﬁlometry and scatterometry are complementary measurements.
Proﬁlometry can be used when proﬁle data are required. Scatterometry can be used
when speed is required. Either one can be used to ﬁnd the PSD and related statistics.
Attention must be given to the bandwidth limits of all of these measurements as
has been stressed throughout the book.
The conclusion is that a number of scatter techniques can be employed to make
roughness maps. Conventional TIS is a viable technique for this measurement,
although it will be slow compared to laser particle scanners because of the time
required for sample motion. Another approach would be to take advantage of the
fact that, for production of a given material, the BRDF/PSD shape is likely to be
relatively constant. You simply measure a couple of points to allow characterization
of the entire angular plot and thus calculate the rms roughness over desired limits.
The example in Section 13.2.6 details a method of roughness speciﬁcation for a
hypothetical situation.
There are some exceptions to the isotropic, topographic nature of silicon wafers.
Wafers cut on at a small angle from the intended crystalline plane have been

216
Chapter 11
Figure 11.5
The calculated one-dimensional PSD found from BRDF compares favorably
with the PSDs found from proﬁle data on the same wafer.
shown via atomic force microscopy to exhibit a periodic stepped surface (Izunome,
Saito, and Kubota 1992; Strausser et al. 1994). For some wafers, this periodicity
is at a low-enough frequency that the effect can be seen in the spatial bandwidth
available to scatter measurements. This bandwidth has a practical maximum just
under 2/λ µm−1. The usual topographic nature of silicon wafer scatter over the
near-IR to UV range can be lost when the wafer is coated with typical process ﬁlms.
Figure 11.6 shows a failure to wavelength scale on a wafer with a nitride coating.
Whether other coatings exhibit similar properties and whether these measurements
can be exploited to characterize coatings remains to be seen.
11.1.3 Particle scanner inspection of wafers
Particle scanners (sometimes referred to as SSISs, which is short for surface-
scanning inspection systems) are used in industries requiring contamination- and
defect-free surfaces. The basic goal of scanner measurement is to prevent the
use of wafers with “killer defects” that are large enough to block, or cut, a
device conduction line. SSISs operate by scanning a focused laser spot over
the wafer surface and detecting the light scattered by surface features. The shot
noise associated with the slowly varying scatter from surface roughness limits the
smallest defect signals that can be reliably detected. The original rule of thumb
was to eliminate defects larger than one-third of a linewidth; however, that rule
was relaxed as linewidths decreased to below 65 nm, and now a full-linewidth
speciﬁcation is generally used. SSISs rely on accurate quantiﬁcation of scattered
light from both defects and roughness.
Calibrating a scanner to size real defects is not easy because defect scatter
signals vary with defect material, shape, and orientation, as well as average
diameter (Stover 2001; Stover, Ivakhenko, and Eremin 2001; Stover and Scheer

Industrial Applications
217
Figure 11.6
This wafer with a nitride coating does not wavelength scale.
2001; Germer, Wolters, and Brayton 2008). Even the qualitative assumption that
smaller signals mean smaller defects cannot be made for single-detector scanners
because of the “lumpy” scatter patterns that very small defects tend to have.
To avoid these issues, defects are “sized” through comparison to PSL spheres,
and the sizing units are LSEs. Scanners are “calibrated” in these same units by
determining how the scanner signal varies with PSL spheres of different diameters.
PSL spheres are commercially available in certiﬁed diameters and are deposited on
“calibration wafers” that meet accepted international standards (see Section 12.4).
PSL spheres have a uniform refractive index, but their diameter distributions and
percent uncertainty in peak diameter vary, depending on the commercial source and
on the nominal size. It was recognized early in the development of PSL standards
that scanners of different designs (measuring defect scatter in different directions
and using different laser sources) do not report the same LSE values for real defects
because of the changes in scatter pattern with each defect type. Unfortunately,
it soon became apparent that differences were found even when PSL calibration
spheres were measured on different SSIS models, and, in some cases, on different
systems of the same model. Prior to about 1996, this inconsistency was largely
ignored because high device yields could be achieved by simply tightening the
LSE particle size speciﬁcation on wafer cleanliness: it was easier to tighten the
speciﬁcation than to understand what was wrong with the calibration procedure.
Two events occurred to change this situation. As device linewidth became
smaller, defect signals were swallowed by the roughness-generated noise ﬂoor, and
it became difﬁcult to meet the one-third-linewidth speciﬁcation. This was initially
“solved” by relaxing the diameter speciﬁcation to one-half of a linewidth, but
of course that only delayed the inevitable problem. The second change was the
introduction of multiple-detector scanners.

218
Chapter 11
By placing sources and detectors in optimum locations, it was possible to
increase SSIS sensitivity. A signiﬁcant advancement was the discovery (Fossey
et al. 1995) that surface pits and particles could be discriminated from each other
by ratioing signals from detectors at a high-scatter angle to one near surface normal
when using a high-incident-angle p-polarized source (see Section 6.2). Using
several detectors might allow identiﬁcation of particle material type (dielectric,
metallic, or semiconductor). Defect identiﬁcation leads to at least the possibility of
true defect sizing (Stover, Ivakhenko, and Eremin 2001; Ivakhnenko et al. 2001).
These advances are necessary if particles are to be sized in approximate diameters
and not in LSEs; however, these advances are very competitive, and the research is
tightly held.
In order to detect particles smaller than about 50 nm, it became necessary to go
to UV wavelengths and smaller spot sizes. The result was that the PSL spheres used
for scanner calibration were being damaged by the scanner laser. A change was
made that involved depositing near-spherical SiO2 particles on calibration wafers
(Germer, Wolters, and Brayton 2008).
11.2 Computer Disks
In the computer hard-disk industry, surface roughness (referred to as texture) is
an important parameter. The issue is the size of any surface defect (particle or
substrate mound) that rises above the nominal ﬂy height of the head. Packing more
memory onto a disk means that there are more bits/unit area and that the heads are
required to ﬂy lower.
On the older, nickel-coated aluminum hard drives, texture was introduced
intentionally to prevent the smooth head from wringing (sticking) to the stationary
surface when the head is parked. On the other hand, too much texture can create
collisions between the surface and the low-ﬂying head. Texture introduced over
the entire disk typically consists of two sets of nearly circular lines, or grooves,
on the surface. Because the two sets have nearly the same center of curvature, the
corresponding streaks in the scatter pattern are fairly close together. A drawing of
a typical scatter pattern is shown in Fig. 11.7.
Newer disks with lower-ﬂying heads have smoother surfaces and leave the
heads in “parking lots” when the disk is not in use. These areas are textured
(often using laser ablation) and are not used for memory. Newer disk surfaces
are much smoother and are inspected for discrete defects using technology very
similar to that described in the preceding sections on semiconductor wafers (11.1.1
and 11.1.3). Because the main issue is defect height, inspecting the surface with
scattered light means that defect identiﬁcation is important. A large dielectric
particle scatters less total light than a smaller metal particle, and the scatter patterns
are not identical. Surface pits, which do not pose a collision problem, can be
detected by some scanners as surface protrusions. Research on defect identiﬁcation
is going to be an important part of progress in this industry.

Industrial Applications
219
Figure 11.7
The texture lines on many computer disks produce a scatter pattern that has
a characteristic bowtie shape with a near-isotropic background.
11.3 Measurement of Retinal Scatter Induced by Intraocular
Lenses
Intraocular lenses (IOLs) are plastic inserts that replace natural lenses that have
been destroyed by cataracts. IOLs have become increasingly common and do a
miraculous job of restoring vision; however, there has been some concern that
after several years, they degrade and then might start to impair vision. Concern
was raised after Scheimpﬂug measurements revealed some backscatter from both
the cornea and the IOL while in the patient’s eye. The problem with these
measurements is that there is no way to use them to determine forward scatter,
which might impact vision when it reaches the retina.
This issue was addressed and resolved in a recent publication by Das et al.
(2012), which reports measurement of scatter from aged IOLs in the forward
direction (toward the retina) in BTDF units in a laboratory situation. A series of
new, artiﬁcially aged and surgically removed lenses were measured while hydrated
in a cylindrical tank. The measured scatter deﬁnitely increased with lens age by
as much as a couple of orders of magnitude, but it was still low enough that
normal vision would not be impacted. There would be an increased sensitivity
to glare situations—such as those often encountered during nighttime driving. In
the course of this study, it was learned that the scatter behaved like Rayleigh
scatter. It increased with the inverse wavelength to the fourth power and had
a constant intensity in the horizontal plane when hit with a vertically polarized
source. This was consistent with the observation that individual scatter sites could
not be resolved with a microscope. The advantage of true BTDF measurements is
that the increased background created by the scatter can be calculated.

220
Chapter 11
11.4 Contamination Measurement by Wavelength
Discrimination
Low contamination and pollution levels can be detected by measuring variations
in scattering signal at wavelengths in and near contaminant absorption bands.
These types of measurements involve a mixture of spectroscopy and scattering.
Spectroscopy is used to identify the contamination material, and scattering is used
to provide the signal and subsequent analysis.
Air pollution can be detected by measuring the backscatter signal from
the atmosphere. The expected return signal, based on Rayleigh scattering (see
Section 1.4), dips at wavelengths corresponding to absorption bands of gases
present in the atmosphere. By tuning the laser to known absorption bands, the
presence of particular pollutants can be monitored. By pulsing the laser and
watching the return signal as a function of time, distance can be monitored. By
changing the source direction, three-dimensional pollution maps can be made.
Surface contamination can also be measured by analyzing the scatter signal near
an absorption band. In particular, surface hydrocarbon contamination as low as 3
mg/ft2 (the measurement units are standard for that industry) has been measured
(Swimley et al. 1993) by sampling a broadband scatter signal from a variety of
substrates at the 3.4-µm hydrocarbon stretch band and on either side. The scatter
signal is dominated by substrate roughness, which also varies with wavelength.
By ratioing the in-band signal to the average of the two out-of-band signals,
a parameter is arrived at that is sensitive to contamination level and relatively
insensitive to surface roughness. The technique has been applied to rough metal
spacecraft components that must be very clean prior to bonding; however, a number
of other industrial processes (galvanizing, plating, painting, etc.) requiring clean
surfaces can beneﬁt from this type of inspection.
11.5 Solar Energy Applications
The solar energy industry’s goal is to concentrate and convert light to more usable
(and storable) forms of energy. Conversion efﬁciencies are relatively low (10% to
20%) when compared to carbon-based (coal, oil, gas) energy systems; however,
the potential is truly impressive. For example, if all of the light falling into a
100 × 100-mi square in the Arizona desert could be converted to electrical energy
at an efﬁciency rate of 15%, this energy would equal the total electrical usage
of the entire United States. Of course, there are some serious problems. Two
of them are the cost needed to produce those systems, followed by storing the
energy until it is needed. Things start to make economic sense when systems
that last twenty years can be produced and installed for $1 per production watt.
That requirement has not yet been met in 2012 as this text is being written.
In the preceding few years, industry, economic, and government pressure have
created a “wild west” industrial environment with dozens of new companies.
Truly impressive production systems producing photovoltaic collectors at rates of
several square meters/minute were developed. All of the approaches to solar energy

Industrial Applications
221
involve collecting or redirecting light over large areas because the equivalent of the
10,000 square miles of Arizona desert is ﬁlled with these collectors. Maintaining
and improving collection efﬁciency requires the ability to perform fast metrology
over large surface areas. Because the medium of interest is light, it should not be a
surprise that scatter measurement can be successfully exploited to meet the need.
11.5.1 Photovoltaic collectors
There are many variations on the semiconductor photovoltaic units that power
watches and calculators, but all of these devices have a common element: a
depletion region between n-type material (with a lot of free electrons) and p-
type material with many empty spots (holes) for free electrons. Opposites attract,
and very quickly some extra electrons end up in the p-type material, creating a
depletion region free of mobile electrons between the two types of semiconductor.
An electric ﬁeld is created in the region by the extra electrons on one side and
the missing electrons on the other. If a photon enters the depletion region and is
absorbed by an atom, it kicks a bound electron free, and the electron is swept
off by the electric ﬁeld, creating a photovoltaic current. One problem is that the
depletion region is narrow (about a micrometer), and as a result, there is a strong
probability that a photon can penetrate without being absorbed. By scattering the
incoming light so that it goes through at an angle, the chances of absorption are
increased and efﬁciency goes up. Scatter can be induced by surface roughness on
a layer upstream of the depletion region, and the desired level of roughness can be
monitored by light scatter. In fact, the solar industry has deﬁned the parameter haze
to do just this. In the solar industry, haze is identical to TIS in the optics industry,
that is, the integrated scattered light normalized by all of the light reﬂecting off of
(or transmitting through) the scattering surface.
A convenient layer choice to induce roughness is the transparent conductor that
is deposited on the sunny side of the semiconductor junction. These are often TCO
(transparent conductive oxide) ﬁlms deposited on glass, and they can be inspected
for their scatter characteristics with either laboratory instrumentation or in process
(Stover and Hegstrom 2010). Haze (TIS) is a good way to inspect TCO surfaces
because these surfaces have a diffuse scatter pattern. Another option is using a
laser source and discrete detector combination with the geometry optimized for
maximum sensitivity in surface variations. Stover and Hegstrom (2010) showed
that on one type of TCO ﬁlm looking in reﬂection about 10 deg from specular with
an incident angle of 45 deg was a very sensitive measurement. Using laboratory
measurements to maximize in-line inspection sensitivity of fast-moving product is
very effective.
Another reason for texturing the sunny side of a photovoltaic collector is to
increase light absorption (decrease reﬂection) through the use of a surface that
is rough enough to cause multiple bounces. The top of the silicon layer is often
textured for this reason. Figure 11.8 shows an example of such a surface. The
crystalline nature of silicon creates a series of surface pyramids. These surfaces
create a strange scatter pattern in reﬂection. Regardless of incident angle, the

222
Chapter 11
Figure 11.8
Textured crystalline taking on a jumbled pyramid surface. Scatter from this
surface is shown in Fig. 11.9. Data and image courtesy of Zeta Instruments.
surfaces produce a minimal reﬂection in the specular direction. The effect is shown
in Fig. 11.9 using a wavelength of 635 nm and an incident angle of 30 deg. At
normal incidence, this surface reﬂects (scatters) in a diffuse doughnut shape around
the specular direction. Haze (TIS) is a terrible choice to monitor a surface like this,
as the value will always be close to unity.
There are other choices for semiconductors than silicon, and the substrates can
be metal and plastic as well as glass. In addition, collectors are being made with
more than one semiconductor junction to help increase photon capture and device
efﬁciency. The common theme, though, is fast, economic production of layered
ﬁlms with the need for consistency in thickness, roughness, material contestants,
and a lack of penetrating defects. These are exactly the kinds of inspection where
light scatter has been used effectively in other industries.
Concentrating systems of many different conﬁgurations have been designed and
built. Either the optics or their covers are exposed to the environment with the
result that contamination or surface degradation cause enough scatter to reduce
system efﬁciency. Typically, light scattered by a degree (or less) results in a system
loss. Scatter measurements in the ﬁeld are a potential way to make cleaning and
replacement decisions.
11.6 General Manufacturing Examples
The object of scatter measurement for process control is often not the BRDF of the
sample but the indication of change on or in a material. Samples are often diffuse
and could be in hard-to-reach hostile environments. It is the noncontact, real-
time aspects of scatter measurements that are exploited. For example, particulate
emissions from an exhaust system can be monitored. Because scatter is not the
key issue, it is more difﬁcult to obtain a direct scatter speciﬁcation. Often, an
empirical relationship between process quality and the measured scatter needs to

Industrial Applications
223
Figure 11.9
The scatter pattern of the surface in Fig. 11.8 when illuminated at 30 deg.
There is virtually no light reﬂected in the specular direction. Data and image courtesy of
ScatterMaster, LLC.
be developed. In the case of the exhaust stack, it might be learned by experience
that if the BTDF at 20 deg rises above 103 sr−1, downwind neighbors will start
complaining to county ofﬁcials about the stack odor. The following examples
illustrate this growing use of scatter metrology.
11.6.1 Detection of paper ﬂaws
The paper industry currently uses scatter as a means of process control. Continuous
sheets, or webs, of paper, which are 1- to 5-m wide, require inspection for holes,
blotches, streaks, and coating nonuniformities. At web speeds of up to 2000 m/min,
a streak can scrap a lot of paper in a short time.
Two inspection techniques are commonly used (Paumi 1988). The laser
technique, which is shown in Fig. 11.10, consists of a laser scanner used to produce
a line of light across the moving web. A detector is then placed in the resulting
transmissive (or reﬂective) scatter pattern, and the signal is monitored to check
for defects under computer control. If 100% coverage of the paper is required,
the web speed is limited by scan rate, spot size, and detector sensitivity. There
is obviously a design tradeoff between minimum defect size (often less than 1
mm) and speed. Depending on the sophistication of the device, the system might
be capable of discriminating between the various kinds of defects. A streak could
stop the paper, while holes or blotches could need to reach a critical density, or size,
before production is stopped. Figure 11.11 compares the BRDFs from paper with

224
Chapter 11
Figure 11.10
Transmissive scatter used to detect ﬂaws on a web of fast-moving paper.
three different gloss coatings. Notice that the three have distinctly different BRDFs,
and that all of them are very ﬂat at high-scatter angles. It is this ﬂat characteristic,
which is typical of many rough (diffuse) surfaces, that is exploited in this process-
control system. By placing the detector well away from the specular direction, it is
insensitive to changes in scatter direction and incident direction.
A second type of system employs an array camera and a white-light source.
Data is taken in a manner similar to the fast raster scans described in Section 7.8.
Although the CCD camera instruments are less expensive, they are slower for a
given resolution.
11.6.2 Noncontact monitoring of emissivity and temperature
A number of industrial processes involve ﬁrst heating materials to several hundred
degrees centigrade and then cooling them in a controlled manner to bring about
desired material changes. Temperature control of the process to a few degrees
can be critical. Because the processes often involve molten, or near molten,
materials, monitoring the temperature can be difﬁcult. Techniques that have been

Industrial Applications
225
Figure 11.11
BRDFs of three different papers with different clay coatings to produce
differing levels of gloss. High-angle scatter is dominated by the diffuse surface under the
coating.
developed to calculate temperature (DeWitt 1986; Tanaka and DeWitt 1989)
based on measurements of infrared radiation from the material require that the
emissivity be known. Unfortunately, the emissivity varies not only with material
type, wavelength, and temperature, but also with surface roughness. Furthermore,
the roughness can change dramatically during some of these processes.
An example is the galvanneal process, which is used to improve the quality
of galvanized steel. In a hot-dip galvanization process, a coating of zinc several
micrometers thick is applied to cold-rolled steel to prevent corrosion and improve
paint adhesion. The coating properties can be improved if the coated steel is heated
further, allowing the zinc to diffuse into the steel. This requires temperatures
of about 600◦C that are controlled to about ±10◦C. As the material is cooled,
the surface changes visibly from a rather shiny molten zinc to a duller, rougher
alloy ﬁnish. In work initiated at Purdue University (DeWitt and Nutter 1989; Hill
et al. 1989), the BRDF of the surface is measured to monitor changes in surface
structure, and the effects of changes in emissivity are entered into the temperature
calculation. A well-controlled, repeatable process can make a big difference in
quality and economics for high-volume users, e.g., the automobile industry.
Because the surface can change drastically in ﬁnish during these processes,
it is often difﬁcult to meet the optically smooth requirement for calculation of
surface statistics. And, depending on the process, the front-surface criteria might
also be violated at some point. The inherent limits on the ability to directly
calculate surface statistics should be established for each process by taking BRDF
measurements on representative samples at various wavelengths. Once the limits
are exceeded, it will not be possible to rely on the relationships of Chapters 4 and
8 to ﬁnd the surface roughness; however, the BRDF is still a sensitive indication
of changes in surface roughness. By measuring the BRDF, empirical relationships

226
Chapter 11
can be developed speciﬁc to a given process that allow surface-ﬁnish (and hence
emissivity) changes to be monitored.
Figures 11.12 and 11.13 show the BRDF at two different wavelengths of several
steel plates that have completed different phases of the galvanneal process. In
Fig. 11.12, at 10.6 µm, a specular peak is still plainly observed, even though the
surface is rough to the eye. This is not the case at 1.06 µm, as shown in Fig. 11.13.
The longer wavelength is a better indicator over the full length of the process.
Figure 11.12
The BRDF at 10.6 µm is shown for steel plates pulled from the galvanneal
steel process at different points. The surfaces become progressively more diffuse as a
function of process time.
Figure 11.13
The samples of Fig. 11.12 are remeasured at roughly one-tenth the
wavelength. At 50 sec, the surface looks nearly Lambertian at this wavelength.

Industrial Applications
227
11.6.3 Ball bearings
Another example is the manufacture of ball bearings, where there is an optimum
surface roughness: too rough, and a surface increases wear; too smooth, and a
surface limits the ability to hold lubrication. There is interest in manufacturing ball
bearings in space, where globs of molten metal form good spherical shapes. The
surface roughness is determined by the rate at which they cool. In order to properly
develop the heating and cooling processes, many of the problems encountered in
the galvanneal example above are encountered.
The BRDF measurement of small-diameter spheres presents its own problems.
The geometry is shown in Fig. 11.14. In principle, it would seem that if the incident
beam converges toward a focus located at the center of the sphere, the beam reﬂects
directly back on itself, with only scattered light outside the incident beam volume.
Unfortunately, physical optics is a little more subtle than geometric optics. If a
TEM00 laser source, which allows a tight beam, is used, then the light is easily
described by a Gaussian beam (Verdeyen 1989; see also Appendix A.2.). The beam
never reaches a point focus. It has a minimum spot size where the phase surface is
ﬂat (inﬁnite radius of curvature). At beam positions near focus, the phase surface
Figure 11.14
The BRDF measurement of short-radius spheres.
Figure 11.15
BRDF of two ball bearings. The incident angle was 15 deg and the
wavelength 0.633 µm.

228
Chapter 11
can be approximated by a large-radius sphere. The result is that the specularly
reﬂected light is a cone of considerably larger diameter than the incident beam. The
smaller the diameter of the sample, the more pronounced is the effect. Figure 11.15
shows the BRDF of two ball bearings taken at wavelengths of .633 and 1.06 µm.
The larger-diameter ball has a smaller reﬂected specular beam. Scatter well away
from specular is reasonably ﬂat and is higher than most optical surfaces.
11.7 Summary
Scatter metrology has expanded from the optics industry, where scatter itself
was the key parameter, into a variety of diverse applications. In addition to the
measurement of surface roughness (texture, ﬁnish, haze), scatter metrology is
routinely used to detect various contaminants. This is particularly true in the
semiconductor and computer-disk industries, where cleanliness and surface-quality
speciﬁcations continue to tighten for products that are to be mass produced.
Scatter metrology is expected to play an increasingly important role in the solar
energy industry. System efﬁciency can be increased in photovoltaic systems by
appropriately increasing scatter, while for concentrating systems, reducing scatter
improves conversion. The examples given in this chapter represent only a small
fraction of the viable applications.

Chapter 12
Published Scatter Standards
“It’s not over until the paperwork is done.” – Unknown.
The purpose of publishing standards is to give industrial communities an
accepted and universal way to communicate requirements for instrumentation and
measurements. Standards are a sort of language that industry competitors and
collaborators can use to reduce the amount of complex communication required
to order, test, and accept equipment and to easily communicate measurements. For
example, when purchasing an optical proﬁlometer that calculates the surface PSD
of the measured sample, it would be nice to know that it is found by the standard
calculation that was outlined in Section 2.2.1 and follows SEMI Standard MF 1811
described below. When using a commercial TIS system, it is useful to know that
the instrument is SEMI MF 1048 or ISO 13696 compliant and that it does not use
the incorrect deﬁnitions that have crept into some stray-light literature and (very
unfortunately) software products.
Standards are arrived at by committees composed of volunteers from different
industry segments. For example, in the semiconductor industry, a meeting might
have several representatives from manufacturing companies of wafers, wafer
inspection equipment, and semiconductor devices. The room is full of customers
and suppliers—many of whom compete with each other. Outside of the meeting
rooms, a lot of business might take place in private conversations. Inside the room,
conversation promoting products is prohibited, as the group struggles to produce
a consensus standard. Passage of a document requires that it receive no negative
votes that are found to be technically persuasive. Negative votes must be found
persuasive (or nonpersuasive) in both the task force creating the document and in
supervising committee. The process can be slow.
The objective of this chapter is to brieﬂy review and reference some key
standards applicable to surface scatter. In the United States, most of these
documents are now controlled by Semiconductor Equipment and Materials
International (SEMI, found at semi.org) and the American Society of Testing
Materials (ASTM, found at astm.org). In Europe, standards are more often written
by the International Standards Organization (ISO, found at iso.org). The brief
descriptions in this chapter are not working substitutions for the actual standards,
which are sold by the relevant organizations and can be obtained through their
websites. Background material for the ﬁrst several standards is found throughout
229

230
Chapter 12
this book. The last section, on semiconductor standards, includes material relevant
to operation of wafer particle scanners.
12.1 Integrated Scatter Standards
The SEMI standard for TIS measurements is MF 1048, and the European standard
is ISO 13696. Both of these documents act as test methods for measuring integrated
scatter, ranging from an angle close to the specular reﬂection to an angle far from
the specular reﬂection. They give methods for calibrating instruments, quantifying
the noise ﬂoor, taking data, and reporting requirements. They are consistent with
the information given in Section 1.6 and can be used with both integrating-sphere
and Coblentz sphere hardware systems. They can be used for measurements of
surfaces that are optically smooth or optically rough. One minor difference in
terminology is the use of total scattering (TS) in the ISO document instead of TIS
in the SEMI document; however, both documents normalize by the total reﬂected
power (not the total incident power), avoid the confusion introduced in some stray-
radiation analysis codes (see Section 1.6), recognize the equivalence of angle and
spatial frequency limits, and relate the measured scatter to rms roughness in the
same way.
12.2 Angle-Resolved Scatter Standards
The ﬁrst BRDF standard was written as an ASTM document in the 1980s. In the
late 1990s, several documents relating to the semiconductor industry were moved
from ASTM to SEMI in order to reduce travel expense and time for volunteers
who were attending meetings at both societies. At that point, ASTM E1392 was
rewritten in SEMI format, and it became SEMI ME1392. A few years later, a
similar ASTM standard (ASTM E2387) was written for ASTM Committee E12,
where the concern was surface appearance. There are only minor differences
between the two. Both active documents deﬁne BRDF (or BSDF) in a manner
consistent with the deﬁnitions and measurement procedures outlined in this book.
Prior to the early ASTM standard, in the 1970s and early 1980s, it was necessary
to deﬁne what was meant by “BRDF” in publications because there were several
accepted deﬁnitions in use. Fortunately, that is no longer the case; the standards
have made a difference.
In addition to giving the necessary deﬁnitions, both documents outline
measurement issues, calibration techniques, noise-ﬂoor determination, and
reporting requirements. Because BRDF (and DSC) signals are the baseline
quantities measured by semiconductor particle scanners (see Sections 12.4 and
11.1), a clear understanding of these issues is important to product development,
sales, and marketing in a multibillion-dollar industry.
Scatter-related SEMI documents are also being written for the solar energy
industry. (See Section 11.5.1 for a discussion of surface texturing in the
photovoltaic industry.) One is SEMI PV15, which involves writing BRDF
speciﬁcations for the purpose of monitoring textured surfaces. The idea is to be

Published Scatter Standards
231
able to deﬁne BRDF speciﬁcations associated with discrete directions so that the
measurement is simple, cost effective, and fast enough to be used in production
systems of both silicon and coated glass. An example of this technique is given
in Section 10.2. Another photovoltaic (PV) standard is being written by SEMI
for using TIS, which is a useful technique for monitoring texturing on the TCO
ﬁlms applied to many of these products. Texturing is also applied to silicon wafers
in the photovoltaic industry, but TIS is not a good indicator for that process (see
Section 11.5.1).
12.3 The PSD Standard
Like the BRDF standard, the PSD standard made the move from ASTM to SEMI,
and after a rewrite, it became SEMI MF1811. The active standard is consistent
with the material in Chapter 2. SEMI MF1811 is limited to one-dimensional proﬁle
measurements and the extension to two-dimensional isotropic surfaces. Calculation
of rms roughness and rms slope are discussed, as well as ABC curve ﬁts and the use
of windowing functions. A sample proﬁle data set and the associated PSD results
are given in an appendix to this standard to help users check their own computer
codes. A useful extension would be to add the calculation of the two-dimensional
PSD.
12.4 Standards for Semiconductor Particle Scanners
As pointed out in Section 11.1.3, particle scanners are critical for wafer inspection
in the semiconductor industry. Because they only estimate particle size in units
associated with PSLs, different scanner designs give conﬂicting results for particle-
diameter distributions. Making the situation even worse, there was a lot of industry
disagreement about the true sizes of the PSL calibration standards. In 1995, the
industry was struggling to detect 100-nm PSL spheres. Scanner manufacturers, of
course, wanted to test with the “largest” 100-nm PSL spheres they could ﬁnd, while
buyers had just the opposite goal. The situation was a bit chaotic.
An effort coordinated by SEMI standards was initiated to overcome these
problems in the mid-1990s. It took over a decade to develop the four related
standards shown in Fig. 12.1, but these standards now form the basis for controlling
the PSL sphere calibration issues. The industry segments involved were: wafer
manufacturers, scanner manufacturers, wafer end users, PSL sphere manufacturers,
providers of PSL standards, and PSL sphere deposition system manufacturers. The
four standards each have their own story, and the following subsections review the
purpose of each document.
12.4.1 SEMI M52—Scanner speciﬁcations
M52 gives the format for specifying a scanner that is to be purchased. It
was promoted by the wafer manufacturers, who were justiﬁably concerned that
different model scanners gave different results on the same wafers. In some cases,
even identical model scanners gave different results. Its development was viewed

232
Chapter 12
Figure 12.1
Four SEMI standards form the basis for providing uniform calibration
throughout the semiconductor industry.
cautiously by the scanner manufacturers, who had a vested interest in ﬁnding and
“calibrating” with PSL spheres that were larger than their “traceable diameters.”
Approaching calibration in this manner made the scanners appear more sensitive
than they really were and kept the company marketing departments happy. M52
covers many issues, but in the context of defect detection, the key result was the
recognition that PSL sphere depositions (used for calibration) must be speciﬁed
by the diameters that actually end up on the calibration wafer, and not by what
starts out in the PSL sphere bottle. Because the particles deposited on the wafer
are often only a fraction of the available diameter distribution in the bottle, the two
are often not the same. Further, the mean diameter on the wafer should be used for
calibration—not the mean diameter given on the bottle.
For example, when completed, M52 required that 130-nm generation scanners
be able to detect 65-nm PSL spheres with a capture rate (another undeﬁned term)
of 95%, and that they have a sizing variability of less than 2.3% (one standard
deviation). To accomplish this, it was recommended that the PSL sphere calibration
depositions have a diameter distribution with a full width at half maximum
(FWHM) of less than 5%, and a peak-diameter expanded uncertainty of no more
than 3% (two standard deviations). [The actual wording in the standard is a little
different (and harder to understand) but is essentially equivalent to the above
statement.]
Agreement on these speciﬁcations was reached only after PSL depositions made
at SEMATECH were sent around the world for measurement on different scanners.
The PSL spheres used had been sized in a project for SEMATECH (Stover
and Scheer 2001a) and included a 100.7-nm PSL standard reference material
(SRM) available from NIST. That particle source had been sized by three different
techniques and was found to have a peak diameter uncertainty of +/−2 nm and
a diameter-distribution width of 2%. The results were analyzed at NIST and are
shown in Fig. 12.2. To the embarrassment of many, the spread in measured values
for the NIST SRM ranged from 86 to 96 nm. The measurement range did not

Published Scatter Standards
233
Figure 12.2
Results of NIST’s analysis are shown by plotting the ratio of the diameter
measured by the scanners to a value determined in a PSL sizing study (done for
SEMATECH) and then plotting against the true diameter. Ratios near 1.0 indicate agreement
between the scanner and the true value. Notice that not one scanner got a value
within 2% of the NIST SRM (sized at 100.7 nm, 100.6 nm, and 100.8 nm by three
independent techniques). Each symbol represents a different unidentiﬁed laboratory where
measurements were made.
even include the true particle diameter. This resulted in heated discussion (lasting
several months) that now included the PSL sphere manufacturers and deposition
companies, as issues of scanner sensitivity and PSL diameter uncertainty collided.
In the end, the discussion even resulted in NIST redeﬁning what was meant by the
term “NIST traceability.” A good time was not had by all (perhaps not by any),
but the industry was better off after the standard was balloted (many would say
negotiated) and published.
M52 did not address three key issues: (1) How does one quantify the probability
of detecting a PSL sphere near the noise-ﬂoor limit? (In other words, what is
capture rate?) (2) How is scanner calibration performed (given that you actually
know the size of the calibration spheres being used)? (3) How does one know if the
calibration PSL sphere depositions used actually meet the speciﬁcation of M52?
(How do you know the deposition system is working correctly?) These questions
were left to be addressed in the three supporting standards shown in Fig. 12.1.
12.4.2 SEMI M50—Capture rate
M52 requires that the capture rate be greater than 95% for the minimum PSL
diameter. Shot noise associated with the noise ﬂoor, imposed by background
surface roughness, limits the scanner sensitivity. Thus, near the noise ﬂoor, some
particles can be missed, and shot noise signals can also be confused with particles.
The objective of M50 is to provide a way to ﬁnd the true capture rate and false

234
Chapter 12
count rate as a function of particle diameter. Until M50 was written and accepted,
the scanner manufacturers were using “somewhat” empirical methods to generate
the best possible capture rates for their products.
Determining capture technique is relatively simple. A statistically signiﬁcant
number of scans are made of a bare wafer using a calibrated scanner. The X, Y
location of each measured particle is recorded along with particle size, given as
its PSL equivalent diameter. Particles that are closer than several times the X, Y-
location uncertainty of the system are eliminated from the maps. Using 200 µm as
the isolation distance between particles gives about 750,000 isolation spots on a
200-mm wafer. There will be perhaps 100 real particles on the surface, and if the
low-noise cutoff is set appropriately, perhaps 100 false counts as well on each scan.
The apparent positions of the false counts move around, but the actual particles do
not. Thus, the probability of capturing a real particle can be calculated for each of
the locations where a repetition occurs as the number of hits at that location divided
by the number of scans. A plot of capture rate versus measured LSE diameter
can then be made, as shown in Fig. 12.3. In a similar fashion, signals that do not
repeat in location are assumed to be false counts, and their apparent size can also
be plotted. Figure 12.4 shows the false count result using the data collected for
Fig. 12.3.
Several older (less accurate) methods of ﬁnding capture rate were employed
by the scanner manufacturers. It took a lot of work to create agreement between
these groups, but the fact that one of the wafer manufacturers (and a large user of
scanners) came up with the basics of the approach helped convince the scanner
manufacturers to accept change.
Figure 12.3
Capture rate is shown as a function of LSE diameter. The points off the
obvious curve, near the center of the graph, can be caused by particles added during the
scans.

Published Scatter Standards
235
Figure 12.4
False count rate is plotted on an expanded scale using the data associated
with Fig. 12.3.
12.4.3 SEMI M53—Scanner calibration
The objective of the calibration process is to provide a curve relating channel
(detector) response to PSL sphere size that allows PSL spheres to be sized to within
5% uncertainty. M53 outlines the necessary procedure under the assumption that
calibration depositions meeting the speciﬁcations of M52 are available. Because of
differences between detection channels and different scanner designs, the process
avoids mandating sphere sizes but simply requires that the difference between
sphere diameters be small enough to meet the 5% uncertainty requirement. Thus,
the manner in which a curve is ﬁt to the calibration points becomes important.
The early technique of straight-line connections between calibration points was
dropped, ﬁrst in favor of curve ﬁtting, and then (better yet) in favor of a modeled
response.
Modeled scatter curves of surface-bound spheres (of known diameter and
material) were developed by both the scanner manufactures and NIST during this
period with very good agreement between them (Stover and Scheer 2001a; Germer,
Wolters, and Brayton 2008). It became apparent that the modeled response should
be the best ﬁt to the calibration data, and M53 in its 2009 form employs this
technique. It also allows materials that are more robust (SiO2) than PSL spheres to
be used as calibration standards. This is especially useful for scanners employing
high-power short-wavelength lasers, which tend to deform PSL spheres.
12.4.4 SEMI M58—Particle deposition conﬁrmation
M53 assumes that the depositions used for calibration are accurate and meet
the requirements of M52. Many of the available PSL spheres have NIST-

236
Chapter 12
traceable mean diameters that meet the M52 peak diameter expanded uncertainty
requirement of no more than 3% (2σ), but they have diameter distributions that
violate the FWHM of less than 5%. In addition, many PSL bottles are labeled
with the modal (peak) diameter, which is different from the mean diameter if the
distribution is asymmetrical. Fortunately, modern particle deposition systems make
use of a particle counter and a differential mobility analyzer (or DMA, described in
M58) that acts as a diameter ﬁlter. The FWHM of the DMA can also be controlled.
If particles are counted as the DMA is swept in diameter, then the convolution of
the FWHM and the bottle-diameter distribution can be measured, and a very good
idea of bottle content can be obtained.
Figure 12.5 shows an example of such a measurement. Using all of the diameters
in the bottle would cause a calibration problem. The peak diameter (given on the
label as the traceable diameter) is 52 nm. If the DMA is centered at 52 nm and
ﬁltered at 5% FWHM, then a useable deposition will be made. If the FWHM
is widened to include the minor peak at 65 nm, then the scanner might appear
more sensitive, but the calibration point would be very poor. M58 provides a way
to check both the diameter accuracy and the FWHM of the DMA so that the
requirements of M52 can be met.
The DMA FWHM is controlled by adjusting air ﬂows into and out of the DMA,
and the adjustment is easily checked by using the NIST 100.7-nm SRM, which has
a very narrow FWHM. The peak diameter uncertainty is checked by again using the
NIST SRM (and two other diameters evaluated in the SEMATECH sizing study).
Repeatability is determined by making depositions twice a day over a one-week
Figure 12.5
Plot of the convolution of a DMA transfer function (with FWHM set at 5%)
with a PSL sphere distribution whose peak diameter is 52 nm. It is clear that there will be a
difference between mean and modal diameters for this distribution. It is also clear that the
source distribution width is quite wide because the FWHM of the main peak is about 10 nm
(20%), which leaves about 15% of this spread being caused by the particle source. If the
entire particle source were deposited (without a DMA), then a lot of 65-nm PSL spheres
would end up in a deposition that could be used as a 52-nm calibration point!

Published Scatter Standards
237
period. Particle count is checked by measuring the depositions with a scanner. The
details, with some real DMA data, are given in M58.
12.5 Summary
Standards provide a way for manufacturers, users, and competitors to specify, test,
and accept equipment. They are produced slowly and with considerable effort
through volunteer work within the industries that have an economic need for them.
Using the standards is not mandatory as a matter of law, but adherence is often
required by the purchaser of equipment.
Written standards for surface scatter measurements (rms, PSD, TIS, BRDF,
and DSC) and instruments are available through SEMI and ASTM in the United
States. In addition, the semiconductor industry has developed a series of standards
deﬁning the speciﬁcation and calibration of particle scanners.

 

Chapter 13
Scatter Speciﬁcations
“The indispensable ﬁrst step to getting the things you want out of life is this: decide
what you want.” – Ben Stein
Scatter speciﬁcations are for the most part the main point for this book. You need
them in order to qualify parts and/or systems. You even need scatter speciﬁcations
to build a scatterometer. And, to be appropriate, speciﬁcations need to address the
issue at hand: they must be application speciﬁc. Generating the right speciﬁcation
requires knowledge of the system (or process) under design (or test), as well
as knowledge of scatter measurement and analysis. The preceding chapters have
presented the deﬁnitions and techniques for quantifying, measuring, and analyzing
optical scatter. The issue is now approached from the other direction. How can
meaningful scatter speciﬁcations be found?
The 1970s and 80s generated considerable concern over scatter in optical
systems. Although it was often recognized that low-scatter optics were required
for a given application, actual speciﬁcations were seldom given. The easiest, most
available, and cheapest scatter measurement was the TIS. Most of the speciﬁcations
written to handle scatter concerns are either TIS (usually given without angle or
frequency limits) or rms roughness found from proﬁle data and often given without
spatial bandwidth limits. Surface roughness was often speciﬁed to control scatter,
even though it was recognized that it would be difﬁcult, futile, and sometimes
impossible to attempt to relate the roughness parameter σ to actual component
scatter. But at least the direction was right (no sign error), as smoother surfaces
do generally mean less scatter. In the late 1980s, serious work began on BSDF
standards in an ASTM committee, funded in part by the United States Air Force.
The result (as described in the previous chapter) was a set of written standards that
not only detailed measurement requirements, but also gave a data-format system.
This enabled the easy transfer of data between laboratories, and increased the ease
with which speciﬁcations could be written and checked. Unfortunately, the industry
has made very limited use of these documents. Roughness, and occasionally TIS,
are still by far the most common choice to specify low-scatter requirements.
This chapter gives examples of generic, application-speciﬁc, and empirical
scatter speciﬁcations. As discussed in the next section, most optics are speciﬁed,
produced, and sold without knowledge of their eventual application. These may
require some sort of generic scatter speciﬁcation, which is usually easy to generate,
239

240
Chapter 13
but often meaningless. A smaller percentage of optical components are speciﬁed
to do a particular job. In these cases, the scatter speciﬁcation should be application
speciﬁc, and although it may not be easy to generate it, there is usually a well-
deﬁned relationship between the speciﬁcation and system behavior. The idea is to
address scatter-sensitive issues in the design phase, before they become system
problems that require breakthroughs in hardware development. Writing good
speciﬁcations forces the design effort in the right direction. Several application-
speciﬁc examples are given in Section 13.2. The third class of speciﬁcations
(empirical) involves the use of scatter measurements as a means of quality control
in situations where either there is not a well-deﬁned (or understood) relationship
between scatter and the effects causing it, or it is simply too expensive to check an
entire production run with application-speciﬁc measurements.
13.1 Generic Speciﬁcations
TIS is an example of a generic scatter speciﬁcation that can be given for general-
purpose optics. A TIS speciﬁcation should always include the light wavelength
and the corresponding measurement limits (bandwidths, angles, etc.) as well as the
TIS number. For example, in addition to speciﬁcations for reﬂectance and ﬂatness,
front-surface aluminum mirrors could be speciﬁed as having a TIS < 10−3 at
0.633 µm over the collection angles between 3 and 85 deg from a 5-deg incident
specular beam. Without a scatter speciﬁcation, it is not obvious which components
are more suitable for a low-scatter application. This is illustrated in Fig. 13.1, which
shows the BRDF from three front-surface aluminum mirrors. The mirrors were
purchased from the same vendor at the prices indicated in the ﬁgure. Is this a
clear-cut case of getting what you pay for? (i.e., more BRDF for more money?)
Actually, the mirrors were speciﬁed for ﬂatness, not scatter, at λ/2, λ/4, and λ/10
wavelengths. The increase in cost reﬂected the extra time required to polish the
mirror ﬂat—and inadvertently increase the scatter. A TIS speciﬁcation on these
mirrors, in addition to the ﬂatness and reﬂectance values, would have revealed the
trend.
This is not an isolated example. It is difﬁcult to purchase off-the-shelf optics
that are known to be low scatter. The addition of simple bandpass or AR coatings
generally increases scatter. Waveplates and polarizers tend to be high-scatter
components. One high-scatter element in a transmissive chain of optics can
dominate scatter in the system and reduce the expense “required” for other low-
scatter components. Manufacturers of generic optics can give scatter speciﬁcations
as “not to exceed” limits, similar to existing reﬂectance and ﬂatness speciﬁcations,
and expressed as piecewise linear plots. This makes a lot of sense for components
whose scatter patterns follow apparent power–law distributions (see Sections 4.5.2
and 8.3.1 on fractals).
Expressing component scatter as a BSDF curve gives considerably more
information than TIS measurements. Figure 13.2 shows the BRDF of two ﬂat
mirrors at 0.633 µm. The curves have been integrated, assuming an isotropic
BRDF, to give estimates of the corresponding TIS values over two different sets

Scatter Speciﬁcations
241
Figure 13.1
Comparison of scatter from three front-surface aluminum mirrors. The price
of the mirrors increased with ﬂatness (λ/2, λ/4, λ/10) and, unfortunately, so did the BRDF.
Figure 13.2
The BRDFs of two replicated mirrors are compared. “Orange peel” effects on
one mirror cause it to have excessive near-specular scatter that would not be caught by TIS
measurements, which typically start at about 2 deg from specular.

242
Chapter 13
Figure 13.3
Diagram of a scatterometer employing a mirror as the ﬁnal focusing element.
The spatial ﬁlter removes most of the source scatter. The scatter speciﬁcation for the ﬁnal
mirror can be determined from the required signature.
of limits. Starting the integral near separation from the instrument signature gives
an ambiguous result. The TIS values are very close. A real TIS measurement would
probably start integration about 2 deg from specular and show a striking difference
in quality; however, if the application required low scatter near specular, the TIS
numbers would result in choosing the wrong component. Two recommendations
are clear: require that angular limits be given with TIS speciﬁcations, and do not
rely on TIS for near-specular scatter requirements. The next section addresses the
more difﬁcult issue of reducing system requirements to component speciﬁcations.
13.2 Application-Speciﬁc Speciﬁcations
One of the reasons scatter speciﬁcations have not been used extensively (or
appropriately) is because it is not always obvious how to proceed from the
functional system requirement to a particular component scatter requirement.
Another reason has been the lack of representative data available in a timely
fashion. Appendix C contains BSDF data for a variety of materials and
wavelengths. It is intended to be used as a data source that allows order-
of-magnitude and achievable BSDF levels to be used in system design. The
following examples illustrate the conversion from real-system scatter problems
to the corresponding component speciﬁcations. In some of these examples, the
calculation is only approximate and deﬁnes only a good place to start. The eventual
speciﬁcation will be determined empirically with experience.
13.2.1 Example 1: Scatterometer-focusing mirrors
Problem. This problem was actually encountered, and solved, in real life by
an optical instrumentation company. It may be useful to review the material
on instrument signature found in Section 7.4. Figure 13.3 is a diagram of a
scatterometer that uses a front-surface mirror to focus the incident source beam.
The spatial ﬁlter removes most of the scatter from the chopper, beamsplitter, and

Scatter Speciﬁcations
243
Figure 13.4
Conversion of required instrument signature into a BRDF speciﬁcation.
turning mirrors, so that the scatter from the source box is dominated by the focusing
mirror. The receiver optics are arranged so that the focusing mirror leaves the
ﬁeld of view at θs = 3 deg. An early prototype of the instrument used an off-
the-shelf 50-cm focal length mirror that, by a stroke of luck, proved to be low
scatter. The instrument signature for a system to be delivered was quoted on this
basis and speciﬁed by the piecewise linear representation shown in Fig. 13.4.
The instrument under development for the customer required the use of a 30-
cm focal length mirror, and, unfortunately, these off-the-shelf components, which
could not be purchased at the same optical house, proved to be comparatively
high scatter. The resulting instrument signature exceeded the speciﬁcation by more
than an order of magnitude. The system NEBRDF is about 10−7 sr−1. What is the
relationship between instrument signature and mirror scatter, and what should the
scatter speciﬁcation be for the focusing mirror?
Solution. The instrument signature, expressed in BRDF units, is calculated as
though it originates from the sample position. By the reasoning presented in
Section 7.4, the mirror is completely in the receiver ﬁeld of view for less than
a degree. At θN (about 3 deg in this case) the mirror has left the ﬁeld of view
completely. Thus, mirror scatter is reduced to some degree by ﬁeld of view. An
expression can be derived to account for this effect; however, if the mirror meets
the speciﬁcation from 0.1 to 1 deg, it should easily meet it from 1 to 3 deg as
well because at 3 deg the signal should be near the NEBRDF, which is well below
the required signature. So, the question is: what should the mirror BRDF be to
meet the 0.1- to 1-deg signature speciﬁcation? The mirror is farther away from
the receiver aperture than the sample by the ratio (1 + L/R). Thus, the receiver
presents a smaller solid angle to the mirror [by (1 + L/R)2] than to the sample. By
the same reasoning, mirror scatter that deviates by angle α from specular appears

244
Chapter 13
Figure 13.5
Measured BRDF from two mirrors that failed to meet the scatter speciﬁcation.
in the signature at location θs = α(1 + L/R). Thus,
Fmir[α] = Fmir[θs/(1 + L/R)] = (1 + L/R)2Fsig[θs].
(13.1)
Using the dimensions given in Fig. 13.3, the signature requirement for 0.1 to
1.0 deg translates up and to the left, as shown in Fig. 13.4, to become the mirror
BRDF speciﬁcation. The straight-line segment can be extended to θN = 3 deg
because the required drop in signature is achieved through controlling the receiver
ﬁeld of view. The speciﬁcation is most easily expressed, in graphical form (as in
Fig. 13.4), or in equation form, as
log[Fmir(θ)] < 0.01 −(1/2) log θ.
(13.2)
Fmir[θ] < 0.01/
√
θ.
(13.3)
One of the problems with this particular speciﬁcation was that the optical houses
could not check their product. As shown in Fig. 13.5, several mirrors were obtained
and measured by the instrumentation company before an acceptable supplier was
found.
13.2.2 Example 2: Imaging optics
Problem. Consider the very simple situation in Fig. 13.6, where a camera (lens
focal length f of 6 cm and diameter D of 3 cm) is to be used by an astronaut
to image a star located at a small angle θ from the moon. The star is about the
brightness of the sun and is 50 light years away. The lens images light from the
star and the moon onto separate locations at the image plane. Moonlight, scattered
by the lens, creates a glow of light over the entire image plane. Because the moon

Scatter Speciﬁcations
245
Figure 13.6
A camera photographs a star close to the moon. If the moon is too close to
the star, moonlight scattered by the lens obscures the image of the star. Using a lens with a
smaller near-specular BTDF improves the situation.
is so much brighter than the star, a close angle point exists where the image of the
star is lost in the scattered moonlight. So, how low does the BTDF of the lens have
to be in order to photograph the star as close as 1 deg away? Could we reasonably
expect to image the star closer than 1 deg?
Solution. This problem simply requires that the deﬁnition of BSDF be applied
several times. The sun illuminates the moon, producing scatter that becomes a
source of incident light on the lens. The incident light scatters according to its
BTDF to the ﬁlm and is compared to the image of the star. Repetitive use of the
BSDF deﬁnition in this way is a useful approach to solving many scatter problems.
To illustrate the situation, assume that the minimum acceptable signal-to-noise
ratio (starlight density to scattered moonlight density) at the image plane is 1
and the BRDF of the moon is Lambertian in form with a reﬂectance of 0.1 (i.e.,
FM = 0.1/π). Scattered moonlight intensity at the image of the star is then set equal
to the intensity of the imaged starlight in Eq. (13.3). (Details of the calculation are
given in Fig. 13.7.) The ﬁrst two terms give sunlight on the moon in watts. The
next two terms convert this to moonlight on the lens, the next two give scattered
moonlight on the ﬁlm, and ﬁnally, division by A (the diffraction-limited area of the
star image) gives noise intensity. The right-hand side of Eq. (13.3) gives the signal
intensity:
Psun
Ω
 ΩMS FMΩCMFLΩLA
A
=
Pstar
Ω
 ΩCstar
A
.
(13.4)
After cancellation of terms (remember Psun/Ω= Pstar/Ω), the required value of
the lens BTDF is found to be
FL =
ΩCS tar
ΩMS ΩCMΩLAFM
 30 sr−1.
(13.5)
Figure 13.8 gives the BTDF of a camera lens. The level 30 sr−1 is reached at 0.2
deg. If the moon moves closer than this to the star, it will be lost from view. If a

246
Chapter 13
Figure 13.7
Calculation of lens BTDF.
signal-to-noise ratio of 10 is required, then the maximum BTDF would be 3.0 sr−1,
and the star could be photographed no closer than 1.3 deg from the moon.
This example is very simplistic. It ignores secondary scatter from the image of
the moon at the focal plane and from the walls of the camera. Practical problems are
considerably more complex. But, with very little effort, a scatter speciﬁcation has
been generated that addresses the speciﬁc problem at hand. Real space-imaging
systems often use several reﬂective elements with complex bafﬂes to reduce
scattered light. Analysis requires the use of raytracing/scatter-prediction programs
to predict critical scatter levels, and the choice of acceptable signal-to-noise ratios
depends on the hardware being used (e.g., array detectors instead of ﬁlm), but the
approach is essentially the one outlined here.
13.2.3 Example 3: Laser resonator losses
Problem. Scatter from laser cavity elements is an unwanted source of intracavity
loss. In high-gain lasers, scatter losses are not a signiﬁcant factor. However, in low-
gain, low-power, continuous-wave (cw) lasers, scatter loss can play a signiﬁcant
role. Relatively inexpensive mirrors are hard sealed onto a relatively expensive

Scatter Speciﬁcations
247
Figure 13.8
The BTDF of the camera lens marked to indicate the (30 sr−1/0.2 deg)
locations that correspond to signal-to-noise levels of 1 and 10, respectively.
tube in the production process. The mirror scatter can be checked before sealing
to the tube. The issue here is whether or not scatter from laser cavity mirrors is of
practical concern, and, if so, what scatter speciﬁcation is appropriate?
Solution. A number of authors (Verdeyen 1989; Siegman 1986; Yariv 1976) have
presented the development of the simple equation giving laser output power, in
terms of saturation power Ps, the output mirror transmission T, the percent round-
trip loss L, and the percent round-trip gain g for low-gain cavities:
P0 = Ps

g
L + T −1
 T
2 .
(13.6)
The gain is proportional to the length of the active medium. Losses are due to
scatter and absorption at the cavity windows and mirrors, and to Rayleigh scatter
from gas molecules within the medium. Window losses can be eliminated in some
cases by sealing the cavity mirrors directly to the gas discharge tube. For this
situation, see Fig. 13.9. If the transmission of the output mirror is high, losses
can often be ignored entirely because they are small compared to the round-trip
reduction in cavity power lost to the output beam. The common route to analyzing
Eq. (13.6) is to differentiate with respect to T, and demonstrate that there is a value
of T that will give maximum output power:
Toptimum = −L +
p
gL.
(13.7)
For the shorter, low-power lasers, this value is often around 1%, which is
comparable with other cavity-loss mechanisms. A slightly different approach is

248
Chapter 13
Figure 13.9
Loss mechanisms in a low-power gas laser.
taken here to allow the relative importance of losses to be examined. If the internal
round-trip loss is held to about the 1% level, the round-trip gain is about 4 to 5%.
Assuming a laser with T = 1% and g = 4%, the ratio P0/Ps can be plotted as
a function of the round-trip loss, as shown in Fig. 13.10. Figure 13.11 shows the
measured BRDF for three laser mirrors. One mirror was known to be damaged.
The other two were selected from a group of several mirrors to show the spread
in BRDF from laser mirrors. The curves have been integrated from 0.75 deg to
grazing to obtain the calculated TIS. Because the mirrors have reﬂectances of
almost 1.0, there is little difference between fractional loss and TIS. The damaged
mirror (TIS = 4.8%) would probably shut down the laser completely. Two high-
scatter mirrors (TIS = 0.23%) would reduce laser power by about 30% (see
Fig. 13.10). The conclusion is that excessive scatter should be of concern. But,
what speciﬁcation should be used?
The data cannot be integrated closer to specular because of the instrument
signature. However, an estimate can be obtained by extending the curves into the
very-near-specular region. This can be done graphically (with some software help)
or algebraically, as follows. Assume that the BRDF (given as F) is linear on a
log–log scale with slope M and multiplier B as shown. Then,
log F = log B + M log θ.
(13.8)
F = BθM.
(13.9)
The fractional loss is obtained by integrating F around the hemisphere:
Frac.loss = 2πB
Z π/2
θmin
θ1+Mdθ = 2πB
2 + M(π/2)2+M −(θmin)2+M.
(13.10)
Values for M and B were obtained from the data of Fig. 13.11. The curves were
assumed to be linear, and M was found near specular from the difference between

Scatter Speciﬁcations
249
Figure 13.10
Laser output falls as internal cavity losses increase. Fractional scatter losses
as high as 0.005 (or 0.5%) make a signiﬁcant difference in laser output power.
Figure 13.11
BRDF and calculated TIS for three laser mirrors.
the BRDF values over 1 to 10 deg. Using this value of slope and the BRDF at
1 deg, B was calculated as the linear-ﬁt BRDF value at 1 rad. These constants
were substituted into Eq. (13.10), and the fractional loss calculated. Integration
was started at 0.75 deg to compare to the TIS values. The calculated and measured
values agree to within a factor of 2, as shown in Table 13.1, so the conclusion is that
our BRDF ﬁt is fairly good. It seems reasonable to extend the integration into about
twice the angular halfwidth of the diverging output beam (about 1 mrad or 0.06

250
Chapter 13
Table 13.1
Summary of calculated scatter losses.
TIS
Fractional loss
Fractional loss
Mirror
B
M
.75 →90 deg
.75 →90 deg
.06 →90 deg
Damaged
2.13 × 10−3
−1.8
4.8 × 10−2
3.6 × 10−2
4.8 × 10−2
High scatter
4.4 × 10−4
−1.2
2.3 × 10−3
3.8 × 10−3
3.9 × 10−3
Good
1.6 × 10−6
−2.4
2.0 × 10−4
1.2 × 10−4
3.8 × 10−4
deg for a typical low-power HeNe laser). This gives the second set of calculated
fractional loss values shown in Table 13.1. As expected, if the slope is high, then a
big increase in fractional loss is found, and if the slope is low, then the difference
is much smaller.
Based on the data available here, one would be tempted to call out a speciﬁcation
based on a calculated fractional loss, say less than 0.1% over 0.06 to 90 deg. This
will work, but it is rather calculation intensive. If a number of undamaged mirrors
that have been coated by the same process are examined, there is a tendency for
them to range from the “good” to “high-scatter” mirrors shown in Fig. 13.11. That
is, as the BRDF increases, the slope tends to decrease. This means that by watching
the BRDF at one angle, the acceptable mirrors can be quickly found. This trend
must be checked for each coating process and an empirical limit decided upon.
Thus, the speciﬁcation for these mirrors might be: the BRDF shall be less than
5 × 10−4 sr−1 at 10 deg.
13.2.4 Example 4: Diffraction from precision-machined turning
mirrors
Problem. High-power laser systems sometimes make use of large-diameter
precision-machined mirrors to turn the beam. It is often desirable to minimize the
light diffracted back into the incident-beam direction. Even after polishing, some
tool-mark diffraction may remain, and there have been cases where tool marks
reappear on the surface over several months following polishing. The mirror is
to be speciﬁed in such a way that light will not retrodiffract from the tool marks
back into the output laser port of the incident beam. The geometry is shown in
Fig. 13.12.
Solution. Diffraction will appear on both sides of the reﬂected beam. If the mirror
is center cut, then the various orders will appear as elliptical cones of light with
negative orders (n < 0), accounting for diffraction back toward the laser port. The
two-dimensional grating equations describe the position of the diffracted light in
terms of laser wavelength and spatial frequency:
cos φs sin θs = sin θi + n fxλ.
(13.11)
sin φs sin θs = n fyλ.
(13.12)
f 2
x + f 2
y = f 2 = d−2.
(13.13)

Scatter Speciﬁcations
251
Figure 13.12
Scatter back into the laser port is to be minimized. The geometry dictates
that diffraction from the mirror-tool marks be eliminated from a 6-deg cone about the incident
beam.
The quantity d is deﬁned as the tool feed, or the distance the tool moves between
spindle revolutions. The problem reduces to one of in-plane considerations only
because the closest approach of a diffraction ring to the laser port occurs at
φs = −180. Thus, from Eq. (13.11),
d =
−nλ
sin θs + sin 45 deg = 0.75n|θs=45 deg
(13.14)
for the problem at hand. Solving for d at θs = 45 deg gives values of the feed that
will diffract light directly back into the laser port. Feeds that diffract within 6 deg
of these directions must also be avoided. These can be evaluated by differentiating
with respect to θs and setting the differential angle equal to 6 deg:
∆d =
−nλ∆θs
 sin θs + sin 45 deg2 = 0.039n
for θs = 45 deg and ∆θs = 6 deg.
(13.15)
Feeds must not be used in the ranges given by
d + ∆d = (0.75 ± 0.039)n µm.
(13.16)
It has been assumed here that the machine tool does not have any prominent
internal vibration that produces surface periodicities at other frequencies. If this
is not the case, then additional unwanted diffraction will occur, as explained in
Section 4.3 and Appendix B.
13.2.5 Example 5: Scatter in a laser rangeﬁnder
Problem. A junior engineer (the boss’ son) has just brought you his design for a
laser rangeﬁnder. This is one job where nothing must go wrong, and you need to
check it out carefully. The design is shown in Fig. 13.13. The detector samples
the outgoing beam by sensing scatter from the beam dump, the beamsplitter,

252
Chapter 13
Figure 13.13
Design features of a simple laser range ﬁnder.
and the output window (which has been tilted to avoid direct backreﬂections). It
also senses the return pulse from the target. A microprocessor monitors the time
between pulses and calculates the distance to the target. The effective aperture
of the detector system is 1 cm2, and the distances from the detector to various
system elements, with their BRDFs, are found in the chart in Fig. 13.13. The linear
response of the detector and a saturation level are given. Once in saturation, the
detector is blind for several microseconds and is likely to miss the return pulse.
Will the design work?

Scatter Speciﬁcations
253
Solution. The detector signal from each scatter source can be evaluated in terms of
its BRDF as follows:
Ps = FPiΩs.
(13.17)
Results are given in Table 13.2. The beamsplitter is assumed to be 50% reﬂective.
The system will not work when the window gets dirty. However, if the peak laser
power is cut back to 104 W, the system will function at distances beyond 3100 m.
The more difﬁcult question of whether or not to improve your future boss’ design
with a second window for the detector is well beyond the scope of this book.
13.2.6 Example 6: Roughness speciﬁcations for semiconductor
components
Problem. In the process of manufacturing a new integrated circuit, a number of
small capacitors are to be built by sandwiching a layer of insulating silicon oxide
between two layers of silicon. The ﬁnal dimensions of these capacitors are 1-
µm squares with an oxide thickness of 100 Å. In a design review, someone has
just asked whether surface roughness will be a problem. If there is a surface
dip on the upper conductor at the same location as a surface rise on the lower
conductor, will the capacitor breakdown voltage be signiﬁcantly changed? Another
engineer claims that if the oxide ﬁlm drops below 90 Å in thickness, the breakdown
voltage will be unacceptable. At this point, everyone starts looking at you because
you have just returned from an SPIE course on scatter and roughness. Questions
ﬁll the surrounding ether: What sort of roughness values should the group be
concerned about? Can meaningful speciﬁcations be written? And, ﬁnally, can
scatter metrology be used to inspect the process?
Solution. The surface is a random function with its roughness expressed as an
rms value. The peak variations are typically about three times the rms value on a
random signal. Holding the roughness of each surface to 5/3 = 1.7-Å rms would
keep the surfaces smooth enough to prevent two aligned peak values from summing
to 10 Å. There would still be some chance that on the random surface occasional
very large peak values could exceed 10 Å, but the probability would be low.
(Your presentation is met with an immediate objection: “Wait a minute—1.7
angstroms is very small. How smooth are our wafers?” You conﬁdently answer:
“Sometimes they come out a little rougher than that, but there is still the matter of
spatial bandwidth to consider.”)
Table 13.2
Calculation of scatter signals at the detector.
Beam splitter
Ps = (10−4)(2 × 104)(1/5)2 = 0.08 W
Beam dump
Ps = (10−3)(0.5 × 104)(1/10)2 = 0.05 W
Clean window
Ps = (10−4)(0.5 × 104)(1/20)2 = 0.00125 W
Dirty window
Ps = (10−2)(0.5 × 104)(1/20)2 = 0.125 W
Target
Ps = (10−2)(0.5 × 104)(1/3.1 × 105) = 5 × 10−10 W

254
Chapter 13
Larger height variations are associated with larger lateral dimensions (or spatial
wavelengths). For this problem, we are concerned only with spatial wavelengths
that are shorter than twice the capacitor width. That is, the worst case is a half-
wave centered on the 1-µm capacitor, contributing a full peak (or valley) to the
roughness. At these spatial frequencies (0.5 µm−1 and above), silicon surface PSDs
can often be described as fractals having the form
S 2(f) = S 2(1)/ f n,
(13.18)
where n is the absolute slope of log[S 2(f)] when plotted against log[ f]. Values of
n = 3 are typical for many silicon wafers (e.g., see Figs. 11.1 and 11.2). The mean-
square roughness can be found via Eqs. (4.4) and (4.5) in terms of S 2(1), under the
assumption that n = 3, as
σ2 = 2π
Z f2
f1
f
 S 2(1)
f 3
!
d f = 2πS 2(1)
" 1
f1
−1
f2
#
,
(13.19)
where f1 and f2 are the minimum and maximum limits of integration, respectively.
Because frequencies much larger than f1 do not make large contributions to the
rms roughness, the upper frequency limit can be extended to inﬁnity, and the
requirement on S 2(1) becomes
S 2(1) ≤f1σ2
2π = 0.5(1.7)2
2π
= 0.23 Å
2 µm2
(13.20)
for the situation described here. The wafers of Figs. 11.1 and 11.2 would easily
meet this requirement.
The surface-ﬁnishing process could be monitored by measuring larger sections
of appropriate material. If scatter is used, then wavelength scaling must be checked
(up front, not on every piece). If an optical proﬁlometer is used, the conversion
from S 1(f) to S 2(f) must be made to make use of the result derived above
[see Eqs. (4.29) and (4.30)]. Once wavelength scaling is established, the scatter
measurement, which can be made very simple (probably one measurement at one
scatter angle; at most, two measurements if the value of n is uncertain), will have
the advantage of speed. The details of such metrology depend on production-
process details and are beyond the scope of this example.
13.3 Empirical Scatter Speciﬁcations
There are situations where it is impractical to measure all of the parts in
a production run, even if a speciﬁcation has been calculated. For example,
measurements in the IR are more complicated and expensive; however, a simple
process can be used to avoid this expense. Simply verify that the parts can meet
the speciﬁcation with measurements on a witness sample. Then, also measure the
component with a relatively inexpensive scatter measurement. This might consist

Scatter Speciﬁcations
255
of measurement at a few discrete scatter angles using an inexpensive visible
laser, or, in some cases, even a proﬁlometer. The objective is not to measure
at the correct wavelength, incident angle, or polarization, but to get a scatter
measurement of a surface that is going to produce an acceptable product. Small
surface changes will produce changes in the measured scatter and indicate that the
manufacturing process has changed. As product is produced, the proﬁlometer and
scatterometer measurements are repeated. The user makes identical measurements
and accepts product based on these measurements. Deviations from these
secondary measurements are reason for the vendor to check its process. Occasional
reference samples are checked by correct-wavelength BRDF measurements.
This approach could be used for catalog optics as well if a universal standard
were accepted. This standard could be a TIS measurement at a standard wavelength
and exit post diameter, or it could be a BSDF scan at a standard wavelength and
incident angle. The manufacturer simply speciﬁes that a particular product will
have a BSDF below some prescribed value (plot) under the standard conditions.
Not perfect—but a large improvement on the current industry practice.
13.4 Summary
Appropriate scatter speciﬁcations are the key to obtaining economic advantages
from scatter metrology. For many generic uses, a TIS or a simple not-to-exceed
BSDF limit makes perfect sense. Vendor speciﬁcations are set at the levels they are
able to maintain economically. For optics that are purchased to be used in critical
low-scatter applications and for the designers of those systems, application-speciﬁc
speciﬁcations are needed. The speciﬁcation must be tight enough to guarantee
system performance, but not overly tight such that the design or component cost is
unnecessarily affected. These speciﬁcations are harder to generate than the generic
ones, and they require that someone knowledgeable in both scatter and the product
design consider all of the issues involved at an early development stage. The
economic advantages for properly setting these speciﬁcations can be large. It costs
a lot of money to put a high-scatter mirror into space, only to ﬁnd out that the
mirror has caused the failure of the entire project. Harder yet are the speciﬁcations
required for process-control applications, where product quality parameters are
related to scatter only by experience or the generation of an empirical relationship.
However, for many high-volume industrial applications, the economic beneﬁts can
be very signiﬁcant.
The ability to write speciﬁcations that are both technically and economically
sound is a sign of expertise in a given ﬁeld. Problems with writing speciﬁcations
should naturally lead to the key questions or to the missing pieces of required
information. The people who can write scatter speciﬁcations that are appropriate
for a company’s product become “the company scatter experts,” which brings us
full circle to the goals stated in the Preface.

 

Appendix A
Review of Electromagnetic
Wave Propagation
Some sections of this book rely on the reader’s familiarity with various aspects
of EM ﬁeld theory. This appendix brieﬂy reviews wave propagation, the idea
of a complex refraction index, the Poynting vector, and the diffraction limit.
The concepts introduced here are reviewed only—not fully developed. Maxwell’s
equations are used as the starting point. SI units (meter, kilogram, second, ampere)
are used throughout.
A.1 The Wave Equation
Assuming that there are no external free charges or currents, Maxwell’s equations
can be written in terms of the electric ﬁeld intensity E, the electric displacement
vector D, the magnetic ﬂux density B, and the magnetic ﬁeld intensity H as
∇× E = −δB
δt = σ −µδH
δt ,
(A.1)
∇× µH = ∇× B = µσE + µεδE
δt ,
(A.2)
∇· D = ∇· εE = 0,
(A.3)
∇· B = 0.
(A.4)
D, E, B, and H are in bold to indicate that they are vector quantities. The symbols µ,
σ, and ε represent the medium permeability, conductivity, and dielectric constants,
respectively. Taking the curl of Eq. (A.1) and substituting Eq. (A.2) to eliminate B
(or H) gives
∇× (∇× E) = −d(∇× B)
dt
.
(A.5)
257

258
Appendix A
Using the identity
∇× (∇× E) = ∇(∇· E) −∇2E = −∇2E
(A.6)
gives the differential relationship
∇2E = µσdE
dt + µεd2E
dt2 ,
(A.7)
which is known as the wave equation. An identical equation can be found for B
by eliminating E. Solutions for E in different mediums will be pursued in the next
section.
A.2 Electromagnetic Plane Waves in Free Space
In free space,
µ = µ0,
E = E0,
σ = 0.
(A.8)
One possible solution to Eq. (A.7) can be shown to take the form of
E = E0ej(2πv √µ0ε0z−2πvt),
(A.9)
where E0 is a constant vector that determines electric ﬁeld amplitude and
polarization direction. The parameter v is the frequency of the sinusoidal wave,
and 1/ √µ0ε0 is identically the speed of light c in vacuum. The usual convention of
writing the solution in terms of a complex phasor, but recognizing that only the real
part is of interest, has been used. The speciﬁc solution shown in Eq. (A.9) is a wave
propagating in the z direction. The more-general solution is given in terms of the
propagation constant k, which is the phase increase per unit propagation distance
and is deﬁned as
k = 2πv/c = 2π/λ.
(A.10)
The propagation constant is also deﬁned as a vector k of magnitude k in the
direction perpendicular to surfaces of constant phase. Then,
E = E0ej(k·r−2πvt).
(A.11)
The full solution to Eq. (A.7) is actually the summation of many waves of the
form of Eq. (A.11) plus their complex conjugates. If k < 0, then the wave travels
in the opposite direction. Some texts deﬁne plane waves with the negative of the

Review of Electromagnetic Wave Propagation
259
Figure A.1
The transverse nature of the EM wave. The wave is plotted in space for an
instant of time.
exponent shown in Eq. (A.11). This apparent difference is resolved when the real
part is taken. An identical solution set exists for B. The two ﬁeld vectors can be
shown to be perpendicular to each other and to k, making the solution a transverse
wave. Figure A.1 shows the relative directions of E, B, and k (which is in the z
direction) for the solution.
Substituting the plane-wave solution into Maxwell’s equations and manipulating
gives a relationship for η0, the impedance of free space, which evaluates to
377 ohms. This expression can be used for other mediums by substituting the
appropriate material constants:
η0 = |E|
|H| = 2πvµ0
k
=
k
2πvε0
=
rµ0
ε0
 377 ohms.
(A.12)
The Poynting vector S gives the instantaneous power density (watts per unit
area) associated with the wave. For isotropic media, it has the same direction as
k. In much of the literature, time-average power density is expressed as the scalar
I, and that notation is used throughout this book. For sinusoidal ﬁelds, the time
average introduces a factor of 1/2. The resulting equations are analogous to power
calculations based on Ohm’s law:
S = E × H∗.
(A.13)
I = 1
2|E × H| = 1
2
|E |2
η0
= P/A.
(A.14)
The ∗indicates taking the complex conjugate. P is the power measured over cross-
sectional area A.
A true plane wave has an inﬁnite transverse width and no beam divergence
(angle spread). This makes sense because with inﬁnite width, there is no room for
divergence. However, beams of ﬁnite width do diverge. The case of a plane wave
incident upon a limiting aperture is covered in Chapter 3. The common situation of
a ﬁnite-width laser beam with a Gaussian electric ﬁeld cross section is analyzed in
many texts (Verdeyen 1989; Yariv 1976), and the results are useful for developing

260
Appendix A
the practical measurement applications described in Chapter 7. Gaussian beams
have electric-ﬁeld cross sections that are described by
E = E0
ω0
ω(z)e−[r/ω(z)]2e j[kz−tan−1(z/z0)+kr/2R(z)−2πvt],
(A.15)
where
ω2(z) = ω2
0
1 +
 z
z0
!2,
ω0 ≡e−1 beam radius at z = 0 (e−2 intensity radius),
ω(z) ≡e−1 beam radius at z (e−2 intensity radius),
R(z) = z
"
1 +
z0
z
2#
≡phase radius of curvature,
z0 = πω2
0
λ
≡characteristic length.
The geometry, shown in Fig. A.2, is for a beam propagating in the z direction.
The beam has an e−1 ﬁeld radius of w(z) that has a minimum width ω0 located at
z = 0. The beam radius expands to 2ω0 after traveling a distance z0. Cross-sectional
amplitude variations are described by the ﬁrst three terms in Eq. (A.15). The second
exponential term contains the phase information. At z = 0, R(z) = 4, the phase
radius of curvature R(z) becomes inﬁnite and the phase exponential term looks like
the phase description of a plane wave. Notice that knowledge of the wavelength
and either ω0 or z0 is enough to deﬁne everything about the beam except total
power. For example, it can be shown that the beam radius expands to approach the
asymptotic limits deﬁned by θdiv, as shown in Fig. A.2. For visible wavelengths,
divergences are small (approximately a milliradian for a conventional HeNe laser).
The minimum focused spot size can be calculated, as shown in Fig. A.3. A broad
(slowly diverging) Gaussian beam [ω(z) = ω01] is focused by a thin lens to a
diffraction-limited spot diameter of 2ω02 located approximately one focal length
from the lens.
Beam divergence and minimum spot size are realities that must be dealt with
in the design of optical instrumentation. As indicated in Chapter 7, the width of
the focused source beam in a scatterometer limits the largest measurable value of
BSDF, and divergence limits the ability to work with long thin beams, especially
in the IR. However, the plane-wave approach to analyzing wave behavior is a
useful tool, and the results are indicative of the behavior expected in many practical
situations. The next two sections analyze wave behavior in dielectrics and metals,
assuming plane-wave propagation.

Review of Electromagnetic Wave Propagation
261
Figure A.2
Divergence of a Gaussian beam.
Figure A.3
Gaussian beam focused by a lens.
A.3 Plane Waves in a Dielectric
In a nonmagnetic, nonconducting dielectric, such as glass,
µ = µ0,
ε = ε0εr,
σ = 0.
(A.16)
The velocity of light is now given by
c′ =
1
√µ0ε0εr
=
c
√εr
= c/n,
(A.17)
where n is deﬁned as the index of refraction. The propagation constant (phase
change/unit distance) increases to
k = 2πv
c′
= 2πv √εr
c
= 2πn
λ
= 2π
λm
,
(A.18)

262
Appendix A
where λm is the shortened wavelength in the dielectric medium. The wave still
propagates according to Eq. (A.11) but with the new value of k. The physical
explanation for the change in velocity lies in the polarization of the dielectric
material. The dipoles formed by displacing the bound electrons in the dielectric are
set into vibration by the incident wave. The moving charges reradiate at the same
frequency but with a slightly retarded phase when compared to the incident beam.
The resultant ﬁeld is the sum of the reduced incident ﬁeld and the polarization-
radiated ﬁeld. Because slightly retarded waves are combining with the beam at
every point within the medium, and because sinusoids of a ﬁxed frequency (but
different phase) sum to a sinusoid of the same frequency (but intermediate phase),
the resultant ﬁeld propagates at a lower net velocity.
There is some loss of beam power as the beam propagates through the dielectric.
This occurs for two reasons. First, there are some scattering losses from the bulk
material. A small fraction of the reradiated ﬁeld propagates in directions different
from that of the incident ﬁeld. This power is lost to the beam, but is not strongly
absorbed by the dielectric. Secondly, a small amount of power is absorbed by the
dielectric. This is sometimes thought of as being due to viscous damping of the
bound electrons. That is, the dipoles do not quite swing all the way back. Power
losses in a material are usually expressed as an exponential decay by means of a
loss coefﬁcient α with units of inverse length. For propagation in the z direction,
I = I0e−αz.
(A.19)
Equation (A.19) can be arrived at intuitively by solving the linear differential
equation that describes the loss in I per unit propagation distance as proportional
to I. However, it can be found directly for the case of absorption losses by
considering the material to have a complex dielectric constant:
ˆε = ε0ˆεr = ε0(εr −jε′
r),
(A.20)
where, for dielectrics, εr ≫ε′
r, and ψ = tan−1(0′
r/0r) is a small angle. The
implication is that k and n are also both slightly complex. Substituting into
Eqs. (A.18), (A.11), and (A.19) gives
ˆk  2πv
c
√εr cos ψ + j2πv
c
√εr sin
ψ
2

,
(A.21)
E = E0e−αz/2e−j[(2πv|n|z/c)−2πvt],
(A.22)
and
I = E2
0
η e−αz,
and
η 
r µ0
ε0εr
= η0n
(A.23)
for propagation in the z direction. The ﬁrst exponential term in Eq. (A.22), which
is due to the imaginary term in the dielectric constant, accounts for the losses in the

Review of Electromagnetic Wave Propagation
263
material. For glass and a wavelength of 0.633 µm, α is on the order of 0.005 mm−1.
That is, it takes tens of centimeters before beam intensity is reduced by e−1. The
second exponential term in Eq. (A.22) describes phase propagation in the medium
and is identical to that for the lossless dielectric.
When the dielectric is isotropic (as in glass), and polarization occurs as easily
in one direction as in another, the material has only one index of refraction, and
the above equations provide an accurate description of propagation. However,
many materials are anisotropic in nature (quartz, mica) and have one (or two)
directions of preferred polarization. Then, the index of refraction depends on
the direction of polarization, and the material is said to be birefringent. In these
cases, the dielectric constant can take on several direction-dependent values and is
described by a tensor. If propagation is not along, or perpendicular to, a preferred
direction, then E and k are no longer perpendicular (S and k are not parallel). For
very high ﬁeld strengths, such as those found in some pulsed lasers, the induced
material polarization is not proportional to the incident ﬁeld. This gives rise to
the ﬁeld of nonlinear optics, which includes effects such as optical harmonic
generation and Raman scattering. Although these two effects, birefringence and
optical nonlinearity, are important in some scatter measurement situations, they
are beyond the scope of this review.
A.4 Plane Waves in a Conducting Medium
In a conductor,
µ = µ,
ε = ε0εr,
σ > 0.
(A.24)
All three terms of Eq. (A.7) must now be considered in the solution. When a
solution of the form of Eq. (A.11) is substituted into Eq. (A.7), it is found that
the propagation constant and the frequency are deﬁned by a dispersion relation:
ˆk2 = (2πv)2µε + j2πvµσ.
(A.25)
If the frequency is allowed to be complex, the ﬁelds will damp in time, an
occurrence that does not pertain to the steady state solutions being reviewed here.
Thus, to satisfy Eq. (A.25), it is again necessary for k to be complex. Using a little
foresight, ˆk is deﬁned in terms of the two real numbers α and β as
ˆk = β + jα/2.
(A.26)
Then, as before,
E = E0e−αz/2ej(βz−2πvt),
and
I = I0e−αz.
(A.27)

264
Appendix A
Thus, the effect of conduction losses is to introduce a damping term just as in the
lossy dielectric. The skin depth 1/α is on the order of a few hundred angstroms (or
less) for metals and a few thousand angstroms for semiconductors.
The quantities α/2 and β can be evaluated by substituting Eq. (A.26) into
Eq. (A.25) and equating real and imaginary parts:
β = 2π
λ

r
1 +

σ
2πvε
2
+ 1

1/2
.
(A.28)
α/2 = 2π
λ

r
1 +

σ
2πvε
2
−1

1/2
.
(A.29)
It is common to view conduction losses as being caused by a complex dielectric
constant or, equivalently, a complex index of refraction. To see how this comes
about, consider the deﬁnition of the propagation constant. If ˆk is complex, as
required in the above analysis, then ˆv, ˆλm, ˆn, and ˆεr are also complex:
ˆk = 2π/ˆλm = 2πˆn/λ = 2π
p
ˆεr/λ.
(A.30)
This means that the complex index can be expressed in terms of α/2 and β:
ˆn = λ
2π
ˆk = λ
2π[β + jα/2].
(A.31)
ˆn = n + jnK = n + jK0.
(A.32)
The complex index is usually deﬁned in terms of the real index and the absorption
index K or the absorption coefﬁcient K0, which are known as the optical constants
of metals. Notice that these real constants depend on the conductivity. Values for n
and nK are commonly found by a process known as ellipsometry. Ellipsometry
involves measuring the reﬂectance of s- and p-polarized light at the angle of
incidence corresponding to minimum p reﬂectance (similar to Brewster’s angle).
If the index of refraction is complex, then the dielectric constant is also complex.
Rewriting Eq. (A.25) allows the complex dielectric to also be deﬁned in terms of
the conductivity and the optical constants:
ˆk2 = (2πv)2µ

ε + j σ
2πv

.
(A.33)
ˆε/ε0 = εr + j
σ
ε02πv = ˆn2 = n2 −(nK)2 + j2nK.
(A.34)
Once the optical constants are known at the wavelength of interest (from
experiment or handbook), Eq. (A.34) can be used to provide the complex dielectric
constant required for computation of the polarization constant Q, described in
Chapter 5.

Appendix B
Kirchhoff Diffraction from
Sinusoidal Gratings
The objective of this appendix is to review a scalar Kirchhoff calculation of
diffraction from surfaces composed of sinusoidal reﬂection gratings by the method
outlined in Section 3.2. The surface material is assumed to have a reﬂectance of 1.0.
The examples are important because of the use of Fourier composition to represent
more-arbitrary surface topography. Equation (3.28) will be used. This requires that
the Fourier transform of Ea(x, y, 0), the incident ﬁeld in the aperture, be found.
Figure B.1 shows light incident at angle θi upon a sinusoidal surface of
amplitude a, frequency f1, and phase α that is propagating in the x direction. Ray 2,
diffracted from the actual surface at angle θs, is compared to Ray 1, diffracting at
the same angle from the mean (z = 0) surface. These rays interfere at inﬁnity
and thus meet the far-ﬁeld conditions required in the development of Eq. (3.28).
Because of the unit reﬂectance assumption, there is no amplitude modulation of
the reﬂected rays. The path length (h1 + h2) is the extra distance traveled by Ray 2,
and it imposes a phase difference ∆(x) between Rays 1 and 2 that is proportional
to z(x). This amounts to phase modulation (without amplitude modulation) of the
wave at the aperture:
∆(x) = 2π(h1 + h2)
λ
= k(cos θi + cos θs)z(x).
(B.1)
For the sinusoidal grating,
∆(x) = ka(cos θi + cos θs) sin(2πfgx + α) = ∆sin(2π fgx + α),
(B.2)
where ∆= ka(cos θi + cos θs) and is the peak value of ∆(x).
The work of Sections 3.1 and 3.2 treats diffraction from transmissive apertures.
Figure B.2 shows how we can take advantage of this treatment for the case of
reﬂective samples. The plane-wave source, which is actually viewed in reﬂection,
can be thought of as coming from its mirror image. The square grating of side
265

266
Appendix B
Figure B.1
Phase modulation by reﬂection from a sinusoidal surface.
L becomes a square aperture with a transmission of T(x, y, 0) that induces phase
modulation:
T(x, y, 0) = ej∆(x) rect (x/L) rect (y/L),
(B.3)
where
rect [x/L] = 1 for |x| ≤L/2,
and = 0 for |x| > L/2.
The plane-wave source propagates along the z′ axis in the x, z plane at an angle θi
to the z axis. A rotational coordinate transformation is used to evaluate the source
wave at the z = 0 plane for any incident angle θi, just as it passes through the
aperture (see Fig. B.2). The wave just following the aperture is then given by the
rotated incident wave times the aperture transmission, given in Eq. (B.3):
Ea(x, y, 0) = E0e j[kx sin θi+∆sin(2π fgx+α)] rect (x/L) rect (y/L).
(B.4)
The following identity is used to rewrite the aperture ﬁeld in a form more
convenient for integration:
e j∆sin Φ =
∞
X
n=−∞
Jn(∆)ej∆Φ,
(B.5)

Kirchhoff Diffraction from Sinusoidal Gratings
267
Figure B.2
Viewing the reﬂected source in transmission.
where ∆is constant, and Φ is variable. Jn(∆) is an nth-order Bessel function of the
ﬁrst kind. Remember that sin θi in Eq. (B.4) is a constant. Then,
Ea(x, y, 0) = E0
∞
X
n=−∞
Jn(∆)ej[kx sin θi+n2π fgx+nα] rect(x/L) rect(y/L).
(B.6)
Substitution into Eq. (3.28) gives an expression that requires the Fourier transform
of the aperture ﬁeld to be found:
E(xs, ys) = cos θs
jλR e jk[R+(x2
s+y2
s)/2R]
Z ∞
−∞
Z ∞
−∞
Ea(x, y, 0)e−j2π( fxx+ fyy) dx dy. (B.7)
In the development of Chapter 3, R is the distance between the aperture and a
point on the observation (scatter) plane. The use of two planes is convenient for
near-normal incidence and low-angle diffraction; however, in the measurement of
scatter (as represented by sinusoidal diffraction in this example), it is often useful
to employ high-angle incidence and/or measure high-angle scatter. For the rest of
this derivation, R will be the distance from the aperture to a point on an observation
sphere centered on the aperture. Thus, xs/R = sin θs, and ys/R = sin θs sin φs.

268
Appendix B
The transform of Eq. (B.7) can be performed by inspection if four points are
remembered:
1. F[e j2π(f1x+ f2y)] = δ(fx −f1, fy −f2), where F denotes the Fourier transform,
and δ(0, 0) an impulse function at fx = f1, fy = f2.
2. F[rect(x/L) rect(y/L)] = L2sinc(L fx)sinc(L fy).
3. The Bessel function argument ∆is not a function of x and y.
4. Multiplication in the space domain is convolution (given by ∗) in the frequency
domain:
Ea = E0[L2sinc(L fx) sinc(L fy)] ∗

∞
X
n=−∞
e jnαJn(∆)δ
 
fx −n fg −sin θi
λ
, fy
!.
(B.8)
The sinc functions are narrow, and the convolution simply acts to impose their
shape on the impulse functions. That is, the diffracted orders have sinc2 cross
sections:
Ea = E0L2
∞
X
n=−∞
e jnαJn(∆) sinc
"
L
 
fx −n fg −sin θi
λ
!#
sinc[L fy].
(B.9)
The impulse functions (and the sinc functions) have nonzero values only for fy = 0,
and
fx = (sin θi)/λ + n fg.
(B.10)
Substituting fx = xs/λz = xs/λR = (sin θs)/λ and rearranging terms gives
sin θs = sin θi + n fgλ,
(B.11)
which is the grating equation (introduced in Chapter 1). The result can be extended
out of the incident plane by substituting the two-dimensional version of the grating
equation. Thus, fy = ys/λR = (sin θs sin φs)/λ. Substituting Eq. (B.9) into Eq. (B.7)
and expressing the spatial frequencies on the x, y plane in terms of position on the
observation sphere gives
E(xs, ys) = E0L2 cos θs
jλR
e
jk

R+

x2s +y2s
2R

∞
X
n=−∞
e jnαJn(∆)
× sinc
"
L
 sin θs cos φs
λ
−nfg −sin θi
λ
!#
sinc
L
λ sin θs sin φs

.
(B.12)
Equation (B.12) is easily squared if the sinc functions are narrow compared to their
spacing. This is normally true and merely implies that many spatial wavelengths

Kirchhoff Diffraction from Sinusoidal Gratings
269
are present within the grating, or fg ≫1/L. Then,
I(xs, ys) =
1
2η0
 E0L2 cos θs
λR
!2
∞
X
n=−∞
J2
n(∆)
× sinc2 L
λ (sin θs cos φs −n fgλ −sin θi)

sinc2 L
λ sin θs sin φs

.
(B.13)
This result is discussed at the end of Section 3.2. I(xs, ys) is power per unit area.
In practice, power measurements are made over ﬁxed apertures. A measurement
of grating efﬁciency, for example, would involve opening the detector aperture so
that it accepted all of the power in each order of interest. Equation (B.11) can be
converted from intensity to power by integrating over xs, ys, one order at a time. We
have already assumed that the order width is small compared to order spacing, so
all variables, except the sinc arguments, can be regarded as constant over the tight
region where the sinc functions are appreciably greater than zero. Setting φs = 0,
using 1/A as the area under sinc2Ax = [(sin Ax)/Ax]2, and remembering to change
variables in the integral gives
Pn =
1
2η0
 E0L2 cos θsn
λR
!2
J2
n(∆)
 
λ
L cos θsn
!  λ
L
!
= E2
0 cos θsn
2η0
J2
n(∆). (B.14)
The incident power that passes through the aperture is reduced by cos θi; thus,
Pi = cos θi(E0L)2/2η0. Expanding J1(∆) for small ∆gives an expression for the
ﬁrst-order grating efﬁciency:
P1/Pi =
"∆
2
cos θs1
cos θi
#
= cos θs1
cos θi
"1
2ka(cos θi + cos θs1)
#2
(B.15)
for J1(∆)  ∆/2. At small scattering angles this reduces to the result referred to in
Section 1.2:
P1/Pi  (ka cos θi)2.
(B.16)
The ﬁrst-order vector perturbation efﬁciencies for both s- and p-polarized light
reduce to the same small-angle expression.
The effect of two parallel gratings on the surface can be analyzed in a similar
fashion. Substitute
z(x) = a1 sin(2πf1x + α1) + a2 sin(2π f2x + α2)
(B.17)

270
Appendix B
into Eq. (B.1) to get the phase delay. The summation in Eq. (B.6) is now a double
summation over the product of two Bessel functions:
Ea(x, y, 0) = E0
rect(x/L)rect(y/L)
∞
X
n=−∞
∞
X
m=−∞
Jn(∆1)Jm(∆2)
× ej(kx sin θi+n2π f1x+m2π f2x+nα1+mα2)
.
(B.18)
After convolution, the sinc arguments are rearranged in a fashion similar to
Eq. (B.11), and the intensity is found as
I(xs, ys) = 1
2η
 E0L2 cos θs
λR
!2
∞
X
n=−∞
∞
X
m=−∞
J2
n(∆1)J2
m(∆2)
× sinc2 L
λ (sin θs −sin θi −nλf1 −mλf2)

sinc2 L
λ sin θs sin φs

.
(B.19)
The diffracted orders are still conﬁned to the incident plane, but there are more of
them. Notice that for either n or m = 0, the result is essentially that of Eq. (3.38)
because J0(∆)  1 for small ∆. Thus, the f1 and f2 spectra are both present,
essentially undisturbed, as predicted by Eq. (B.13). In addition, the sum-and-
difference frequencies are present as cross terms with amplitudes that depend on
both Jn(∆1) and Jm(∆2). The situation is easiest to picture if the two frequencies
are well separated and is illustrated in Fig. B.3 for f1 ≫f2. These types of effects
are important when nonsinusoidal grating surfaces, such as those generated by
precision machining, are analyzed. If f1 and f2 are harmonically related, as will
be the case with a nonsinusoidal grating made up of several Fourier components,
the cross-product terms fall on top of higher-order terms that are already present.
For example, if 2 f2 = f1, then the sum frequency f1 + f2 is simply 3 f2. However, if
an unwanted, nonharmonically related frequency is present in the surface, then the
Figure B.3
Diffraction locations for two parallel sinusoidal gratings with f1 ≫f2.

Kirchhoff Diffraction from Sinusoidal Gratings
271
cross terms can be used to provide clues as to the value of the second fundamental.
Knowing the second fundamental frequency might allow it to be eliminated (see
Section 4.3).
Another case of interest is diffraction from crossed sinusoidal gratings. The
analysis is very similar to that of the parallel gratings, except that the f1 and f2
spectra are now located along the xs and ys axes, and the cross-product terms
are off-axis, forming rectangles in frequency space. The relationship is given in
Chapter 3 as Eq. (3.38).

 

Appendix C
BSDF Data
This text has gone into considerable detail on the analysis and measurement of
BSDF data. The importance of using a data set that truly matches a speciﬁc
should be very clear. There are times when knowing general BSDF levels can
be of considerable help. For example, if you have determined via analysis that
a ZnSe window will work in your application if its mid-IR scatter can be kept
below 10−3 sr−1 at 30 deg from specular, then knowing that windows are routinely
made at 10−5 sr−1 in this region lets you proceed with your design. If you needed
10−6 sr−1, then the situation would be a little more difﬁcult. You might actually
want your component measured, or you might want to change your design.
Another problem with practical use of BSDF data sets is categorizing the
variables associated with the sample, the measuring instrument, and the laboratory-
reporting methods. The two BRDF standards (SEMI 1392 and ASTM E2387)
described in Section 12.2 provide formats for reporting BRDF data as well as
complete deﬁnitions of terms. These documents provide a means for laboratories
to compare, trade, and purchase reliable measurements on samples of interest. It is
also expected that a relational database, probably PC based, will become available
that will allow a fast search of hundreds of ﬁles to obtain data that ﬁt a particular
requirement.
The 32 BSDF scans in this appendix are offered in the spirit of giving merely
a sense of values measured from a few samples. Hopefully, it will be useful in the
short term. Once an accessible national database is available there will be little
need for the microscopic, difﬁcult-to-use windows on BSDF data provided by data
sets similar to those in this appendix.
Table C.1 provides a means of locating the various BSDF data ﬁles in the book.
The materials measured are listed alphabetically, and the corresponding ﬁgure
numbers given by wavelength region. The data sets of this appendix are given
in ascending order of wavelength. This is far short of the relational database just
discussed. As you use the list, you may begin to appreciate the value of establishing
a national database.
273

274
Appendix C
Figure C.1
Figure C.2

BSDF Data
275
Figure C.3
Figure C.4

276
Appendix C
Figure C.5
Figure C.6

BSDF Data
277
Figure C.7
Figure C.8

278
Appendix C
Figure C.9

BSDF Data
279
Table C.1
List of BSDF data in the book.
Visible
Near-IR
Mid-IR
0.4–0.7 mm
0.7–2 mm
2–12 mm
(Figure #)
(Figure #)
(Figure #)
Air, Rayleigh scatter
7.11
Aluminum, polished
C.6
C.6
C.6
Aluminum on glass
13.1, 13.5
Beryllium
C.7, 8.4, 8.5, 8.6
C.7, 8.6
C.7, 8.4, 8.5, 86
Cloth, black corduroy
8.14
Copper
C.4
Dielectric-coated laser mirror
13.11
Dielectric-coated RLG mirror
7.19c
Gallium arsenide
C.9
Gallium phosphide
C.3
Germanium
C.9
Glass, AR coated
C.2
Glass, uncoated
5.4b
Glass lens
13.8
Martin black
8.14
Molybdenum
C.5, C.8, 4.1, 7.2, 8.11
C.8
C.5, C.8
Nickel on copper #2
C.4
Nickel on copper #1
4.8
Paper
8.13, 11.11
Pellicle
C.2
Plexiglass
C.2
Polyurethane enamel, white
8.13
Potassium chloride
C.9
Replicated mirrors
13.2
Silicon carbide
C.5
Silicon wafers
11.3
Silicon step
8.16
Spectralon R
⃝
C.1, 8.13, 8.14, 8.15
Steel, ball bearings
9.18
Sunglasses
C.2
Tellurium dioxide
C.3
7.10
White ﬂat spray paint
8.13
Zinc selenide
9.10
C.9
Zinc on steel
11.13
11.12

 

Appendix D
Units
A brief discussion of units might be helpful. Back in the 1960s, when scatterometry
started as a useful way to monitor surface roughness, it was common to express the
rms roughness of mirrors in angstroms, spatial wavelengths in microns, and spatial
frequency in inverse microns. Angstroms have given way to nanometers (ten times
larger), and microns are now more properly called micrometers. Machine shop
surface roughness in the United States has been expressed in microinches using
a coarse geometric scale of 2, 4, 8, 16, 32, . . ., but as pointed out in Chapter 2,
machine slope roughness is usually expressed as an arithmetic average (a.a.) rather
than rms (see Table 2.2).
The Schmitt Measurement Systems CASI R⃝(complete angle scatter instrument)
Scatterometer was developed in the late 1980s, and it used angstroms for rms. The
CASI software used units of Å
2µm and Å
2µm2 for the one- and two-dimensional
PSDs. This was done so that when the PSD was integrated over spatial frequency to
obtain the rms roughness, it resulted in numerical values in angstroms. It all made
sense at the time. The CASI has had a long life, and probably well over half of
the low-noise scatterometers operating in the world today are still CASIs. Almost
all of the BRDF and PSD charts in this book were created via the CASI software,
and the PSDs are given in units of Å
2µm2 and the spatial frequency as inverse
micrometers. When using the Rayleigh–Rice equation, S 1 and S 2 take on units of
λ3 or λ4, respectively, and this will determine the resulting units for the rms, unless
a normalization factor is applied. The following factors and charts attempt to make
conversion between these various units easy.
1 mm = 1000 µm (or microns) = 106 nm = 107 Å.
If you are converting the older units in the PSD charts used throughout the book
into newer units, the following could be useful:
1 Å
2µm2 = 104 nm4
1 Å
2µm2 = 10−8 µm4
1 Å
2µm = 10 nm3
1 Å
2µm = 10−8 µm3
If you are converting between the metric system and microinches for rms
roughness, the charts on the following pages could be useful.
281

282
Appendix D
Figure D.1
Conversion between microinches and nanometers.
Figure D.2
Conversion between microinches and angstroms.
Figure D.3
Conversion between microinches and micrometers (microns).

References
Abe, T., Steigmeier, E. F., Hagleitner, W., and Pidduck, A. J.
1992. “Microroughness measurements on polished silicon wafers,” Jpn.
J. Appl. Phys. 31, 721–728.
ANSI/ASME
2009. Standard # B46.1-2009, Surface Texture (Surface Roughness,
Waviness, and Lay), Am. Soc. Mech. Eng., New York.
Asmail, C., Hsia, J., Parr, A., and Hoeft, J.
1994. “Rayleigh scattering limits for low-level bidirectional reﬂectance
distribution function (BRDF) measurements,” Appl. Opt. 38(28), 6027.
ASTM
1991. Standard # E1392-90, Standard Practice for Angle Resolved
Optical Scatter Measurements on Specular or Diffuse Surfaces.
Azzam, R. M. A. and Bashara, N. M.
1977. Ellipsometry and Polarized Light, North Holland, New York.
Barrick, D. E.
1970. Radar Cross Section Handbook, Chap. 9, Plenum, New York.
Bawolek, E. J., Mohr, J. B., Hirleman, E. D., and Majumdar, A.
1993. “Light scatter from polysilicon and aluminum surfaces and compar-
ison with surface-roughness statistics by atomic force microscopy.” Appl.
Opt. 32(19), 3377.
Beckmann, P., and Spizzichino, A.
1963. The Scattering of Electromagnetic Waves from Rough Surfaces,
Pergamon, New York.
Bell, B. W. and Bickel, W. S.
1981. “Single ﬁber light scattering matrix: an experimental determina-
tion,” Appl. Opt. 20(22), 3874.
Bendat, J. S. and Piersol, A. G.
1971. Random Data: Analysis and Measurement Proceedures, Wiley-
Interscience, New York.
1986. Engineering Applications of Correlation and Spectral Analysis, 2nd
ed., John Wiley & Sons, New York.
283

284
References
Bender, J. A., Henning, T. D., and Bernt, M. L.
1992. “Near-specular measurements of integrated scatter,” Proc. SPIE
1753, 121–126. [doi: 10.1117/12.140696].
Bennett, H. E. and Porteus, J. O.
1961. “Relation between surface roughness and specular reﬂectance at
normal incidence,” JOSA 51, 123.
Bennett, J. M. and Mattsson, L.
1989.
Introduction
to
Surface
Roughness
and
Scattering,
OSA,
Washington, D.C.
Bickel, W. S., Davidson, J. F., Huffman, D. R., and Kilkson, R.
1976. “Application of polarization effects in light scattering: a new
biophysical tool,” Proc. Nat. Acad. Sci. USA 73(2), 486.
Bickel, W. S., Iafelice, V., and Videen, G.
1986. “The role of polarization in the measurement and characterization
of scattering,” Proc. SPIE 679, 91–98.
Bickel, W. S., Zito, R. R., and Iafelice, V.
1987. “Polarized light scattering from metal surfaces,” J. Appl. Phys.
61(12), 5392.
Bobbert, P. A. and Vlieger, J.,
1986a, “Light scattering by a sphere on a substrate,” Physica 137A,
209–242.
Bobbert, P. A., Vlieger, J., and Greef, R.,
1986b, “Light reﬂection from a substrate sparsley seeded with spheres—
Comparison with an ellipsometric experiment,” Physica 137A, 243–257.
Bohren, C. E. and Huffman, D. R.
1983. Absorption and Scattering of Light by Small Particles, John Wiley
& Sons, New York.
Breault Research Organization (2012) http://www.breault.com/.
Breault, R. P.
1986. “Current technology of stray light,” Proc. SPIE 675, 4–13.
Brown, N. J.
1989. “Optical fabrication,” Lawrence Livermore National Laboratories,
Report MISC-4476, Rev. 1.
Bullis, W. M.
1994. “Microroughness of silicon wafers,” Proc. Electrochem. Soc.
94(10), 1156.
Burnham, M.
1976. “The mechanics of micromachining,” Proc. SPIE 93, 38–45.
Cady, F. M., Bjork, D. R., Rifkin, J., and Stover, J. C.
1989a. “BRDF error analysis,” Proc. SPIE 1165, 154–164.
1989b. “Linearity in BSDF measurements,” Proc. SPIE 1165, 192–201.

References
285
Cady, F. M., Stover, J. C., Schiff, T. F., Klicker, K. A., and D. R. Bjork
1988. “Measurement of very near specular scatter,” Proc. SPIE 967,
264–271.
Cheever, D. R., Cady, F. M., Klicker, K. A., and Stover, J. C.
1987. “Design review of a unique complete angle-scatter instrument
(CASI),” Proc. SPIE 818, 13–20.
Chipman, R. A.
2007. “Degrees of freedom in depolarizing Mueller matrices,” Proc. SPIE
6682, 66820I. [doi: 10.1117/12.735892].
2009a. “Mueller Matrices” in Handbook of Optics (Vol. I, Chapter 14),
M. Bass, Ed., McGraw-Hill.
2009b. “Polarimetry” in Handbook of Optics (Vol I, Chapter 15) M. Bass,
Ed., McGraw-Hill.
Church, E. L.
1977. Private communication with author.
1980. “The statistical description of optical inhomogeneities,” NBS
Special Publication 574, 51–54.
1987. “Comments on the correlation length,” Proc. SPIE 680, 102–111.
1988. “Fractal surface ﬁnish,” Appl. Opt. 27(8), 1518–1526.
1989.
Private
communication:
This
useful
relationship
was
ﬁrst
discovered serendipitously while checking Q values with a calculator and
then later conﬁrmed by derivation.
1994. Private communication with
author.
Church, E. L. and Takacs, P. Z.
1986a. “Statistical and signal processing concepts in surface metrology,”
Proc. SPIE 645, 107–115.
1986b. “Use of an optical-proﬁling instrument for the measurement of the
ﬁgure and ﬁnish of optical-quality surfaces,” Wear 109, 257.
1988. “Instrumental effects in surface ﬁnish measurement,” Proc. SPIE
1009, 46–55.
1989a. “Subsurface and volume scattering from smooth surfaces,” Proc.
SPIE 1165, 31–41.
1989b. “Effects of the optical transfer function in surface proﬁle
measurements,” Proc. SPIE 1164, 46–59.
1993. “Speciﬁcation of surface ﬁgure and ﬁnish in terms of system
performance,” Appl. Opt. 32(19), 3344–3353.
Church, E. L. and Zavada, J. M.
1975. “Residual surface roughness of diamond-turned optics,” Appl. Opt.
14, 1788.

286
References
Church, E. L., Asmail, C. C., and Parks, R. E.
1994. “Scattering predictions based on the plateau-polishing model,”
unpublished.
Church, E. L., Dainty, J. C., Gale, D. M., and Takacs, P. Z.
1988. “Comparison of optical and mechanical measurements of surface
ﬁnish,” Proc. SPIE 954, 189–199.
Church, E. L., Jenkinson, H. A., and Zavada, J. M.
1977. “Measurement of the ﬁnish of diamond-turned metal surfaces by
differential light scattering,” Opt. Eng. 16(4), 360–374.
1979. “Relationship between surface scattering and microtopographic
features,” Opt. Eng. 18(2), 125–136.
Church, E. L., Takacs, P. Z., and Leonard, T. A.
1989. “The prediction of –RDFs from surface proﬁle measurements,”
Proc. SPIE 1165, 136–150.
Collett, E.
1993. Polarized Light: Fundamentals and Applications, Marcel Dekker,
New York.
Dagnall, H.
1980. Exploring Surface Texture, Rank Taylor Hobson, Leicester,
England.
Das, K. K., Stover, J. C., Schwiegerling, J., and Karakelle, M.,
“A technique for measuring forward light scatter in intraocular lenses.”
To be published.
Davies, H.
1954. “The reﬂection of electromagnetic waves from a rough surface,”
Proc. Inst. Elec. Engrs. 101, 209.
DeBoo, B., Sasian, J., and Chipman, R.
2004. “Degree of polarization surfaces and maps for analysis of
depolarization,” Op. Ex. 12(20), 4941–4958.
2005. “Depolarization of diffusely reﬂecting manmade objects,” Appl.
Opt. 44(26), 5434–5445.
Denes, L. and Huff, H.
1992. “A Fourier analysis of silicon wafer topography,” Abstract 823
RNP, 182nd Meeting of the Electrochemical Society.
DeWitt, D. P.
1986. “Inferring temperature from optical radiation measurements,” Opt.
Eng. 25(4), 596–601.
DeWitt, D. P. and Nutter, G.D. (eds.)
1989. Theory and Practice of Radiation Thermometry, Wiley Inter-
science, New York.

References
287
Doicu, A., Eremin, Y., and Wriedt, T.
2000. Acoustic and Electromagnetic Scattering Analysis, Academic
Press, Waltham, MA.
Elson, J. M. and Bennett, J. M.
1979. Opt. Eng. 18(2), 116–124.
Eremin, Y.-A.,
2000. “The method of discrete sources in electromagnetic scattering
by axially symmetric structures,” J. Commun. Techn. Electron. 45(2),
S269–S280.
Eremin, Y.-A. and Orlov, N. V.
1996. “Simulation of light scattering from a particle upon a wafer
surface,” Appl. Opt. 35(33), 6599–6605.
1998. “Study of scattering properties of defects of silicon wafers,” Opt.
Spectrosc. 84(4), 557–562.
Eremin, Y.-A., Orlov, N. V., and Sveshnikov, A. G.
1999. “Models of electromagnetic scattering problems based on
discrete sources method” in Generalized Multipole Techniques for
Electromagnetic and Light Scattering (Vol. 4), T. Wriedt, Ed., Elsevier
Science, Amsterdam.
Eremin, Y.-A., Stover, J. C., and Orlov, N. V.
1999. “Modeling scatter from silicon wafers features based on discrete
sources method,” Opt. Eng. 38(8), 1296–1304. [doi: 10.1117/1.602187].
Fossey, M. E., Stover, J. C., and Clementi, L. D.
1995. “Wafer inspection system for distinguishing pits and particles,”
ADE Optical Systems Corporation, U.S. Patent No. 5712701.
Freniere, E. R., Gregory G. G, and Chase, R. C.
1997. “Interactive software for optomechanical modeling,” Proc. SPIE
3130, 128. [doi: 10.1117/12.284054].
Gerliand, P. V., Smith, M. H., and Chipman, R. A.
1999. “Polarimetric images of a cone,” Op. Ex. 4(10), 420–430.
Germer, T. A.
1997a. “Angular dependence and polarization of out-of-plane optical
scattering from particulate contamination, subsurface defects and surface
microroughness,” Appl. Opt. 36(33).
2000. “Measurement of roughness of two interfaces of a dielectric ﬁlm by
scattering ellipsometry,” Phys Rev. Lett. 85, 349-352.
2001. “Polarized light scattering by microroughness and small defects in
dielectric layers,” JOSA 18(6), 1279.
2007a. “Effect of line and trench proﬁle variation on specular and diffuse
reﬂectance from a periodic structure,” JOSA 24(3), 696.

288
References
Germer, T. A. and Asmail, C. C.
1999a.
“Goniometric
optical
scatter
instrument
for
out-of-plane
ellipsometry measurements,” Rev. Sci. Inst. 70(9), 3688.
1999b. “Polarization of light scattered by microrough surfaces and
subsurface defects,” JOSA 16(6), 1326.
Germer, T. A., Asmail, C. C., and Scheer, B. W.
1997. “Polarization of out-of-plane scattering from microrough silicon,”
Opt. Lett. 22(17), 1284.
Germer, T. A. and Marx, E.
2004. “Ray model of light scattering by ﬂake pigments or rough surfaces
with smooth transparent coatings,” Appl. Opt. 43(6), 1266.
Germer, T. A., Wolters, C., and Brayton, D.
2008. “Calibration of wafer surface inspection systems using spherical
silica nanoparticles,” Op. Ex. 16(7), 4698.
Goldstein, D. H. and Chipman, R. A.
1990. “Error analysis of a Mueller matrix polarimeter,” JOSA A. 7(4),
693–700.
Goodman, J. W.
1968. Introduction to Fourier Optics, McGraw-Hill, New York.
Greynolds, A.
2012. Private communication with the author. See Breault Research
Organization website (2012) for additional information.
Gu, Z. H., Dummer, R. S., Maradudin, A. A., and McGurn, A. R.
1989a. “Experimental study of the opposition effect in the scattering of
light from a randomly rough metal surface,” Appl. Opt. 28(3), 537.
1989b. “Opposition effect in the scattering of light from a random rough
metal surface,” Proc. SPIE 1165, 42–51.
Hancock, J. C.
1961. Principles of Communication Theory, McGraw-Hill, New York.
Harvey, J. E.
1976. “Light Scattering Characteristics of Optical Surfaces,” Ph.D.
Dissertation, U. of Arizona.
1989. “Surface scatter phenomena: a linear, shift-invariant process,” Proc.
SPIE 1165, 87–99.
Harvey, J. E., Krywonos, A., and Stover, J. C.
2007. “Uniﬁed scatter model for rough surfaces at large incident and
scatter angles,” Proc. SPIE 6672, 6620C. [doi: 10.1117/12.739139].
Harvey, J. E., Vernold, C. L., Krywonos, A., and Thompson, P. L.
1999. “Diffracted radiance: a fundamental quantity in non-paraxial scalar
diffraction theory,” Appl. Opt. 38, 6469–6481.

References
289
2000. “Diffracted radiance: a fundamental quantity in non-paraxial scalar
diffraction theory, Errata” Appl. Opt. 39, 6374–6375.
Harvey, T. A.
2011. Cornell University; Private communication with author.
Hill, D. P., Shoemaker, R. L., De Witt, D. P., Gaskell, D. R., Schiff, T. F., Stover,
J. C., White, D., and Gaskey, K. M.
1989. “Relating surface scattering characteristics to emissivity changes
during the galvanneal process,” Proc. SPIE 1165, 62–71.
Hunt, A. J. and Huffman, D. R.
1973. “A new polarization-modulated light scattering instrument,” Rev.
Sci. Instrum. 44(12), 1753.
Hunter, R. S. and Harold, R. W.
1987. The Measurement of Appearance, 2nd Ed, John Wiley and Sons,
New York.
Huntley, W. H.
1980. “Grating interferometers,” Lasers 80, T Japan.
Iafelice, V. J., and Bickel, W. S.
1987. “Polarized light-scattering matrix elements for select perfect and
perturbed optical surfaces,” Appl. Opt. 26(12), 2410.
Iizuka, K.
1985. Engineering Optics, Springer-Verlag, Berlin.
Ishimaru, A.
1978. Wave Propagation in Random Media, Academic Press, New York.
Ivakhnenko, V., Stover, J. C., Scheer, C. A., and Eremin, Y. A.
2001. “Effects of particle shape on particle identiﬁcation and scatter
predictions,” Proc. SPIE 4449, 140. [doi: 10.1117/12.450087].
Izunome, K., Saito, Y., and Kubota, H.
1992. “Periodic step and terrace formation on Si(100) surface during Si
epitaxial growth by atmospheric chemical vapor deposition,” Jpn. J. Appl.
Phys. 31, L1277–L1279.
Jenkins, F. A. and White, H. E.
1976. Fundamantals of Optics, McGraw-Hill, New York.
Jenkins, G. M. and Watts, D. G.
1968. Spectral Analysis and its Applications, Holden-Day, San Francisco.
Keller, J. B.
1962. “Geometrical theory of diffraction,” JOSA 52, 116.
Kim, J. H., Ehrman, S. H., Mulholland, G. W., and T. A. Germer,
2002. “Polarized light scattering from metallic particles on silicon
surfaces,” Appl. Opt. 43(3), 585.

290
References
Klicker, K. A. and Bjork, D. R.
1988. “Model of port scatter from lasers,” Final Report to U.S. Army
White Sands Missile Range, Contract No. DAAD07-87-0083.
Klicker, K. A., Fuhrman, D., and Bjork, D. R.
1990. “BSDF database,” Proc. SPIE 1331, 270. [doi: 10.1117/12.22663].
Klicker, K. A., Stover, J. C., and Wilson, D. J.
1988. “Near-specular measurement techniques for curved samples,” Proc.
SPIE 967, 255–263.
Klicker, K. A., Stover, J. C., Cheever, D. R., and Cady, F. M.
1987. “Practical reduction of instrument signature in near specular light
scatter measurements,” Proc. SPIE 818, 26–33.
Krauss, H. L., Bostian, C., and Raab, F. R.
1980. Solid State Radio Engineering, John Wiley & Sons, New York.
Krywonos, A.
2006. “Predicting Surface Scatter Using a Linear Systems Formulation of
Nonparaxial Scalar Diffraction,” Ph.D. dissertation, U. Central Florida.
Krywonos, A., Harvey, J. E., and Choi, N.
“Linear systems formulation of surface scatter theory for rough surfaces
with arbitrary incident and scattering angles,” JOSA A 28(6), 1121–1138
(2011).
Lamb, L. D.
1991. “The Scattering of Infrared Light by Small Particles on Substrates,”
Ph.D. Thesis, Dept. of Physics, U. of Arizona.
Leader, J. C.
1979. “Analysis and prediction of laser scattering from rough surface
materials,” JOSA 69, 610–628.
Lee, W. W., Scherr, L. M., and Barsh, M. K.
1986. “Stray light analysis and suppression in small angle BRDF/BTDF
measurement,” Proc. SPIE 675, 207–216.
Leonard, T. A. and Pantoliano, M. A.
1988.
“BRDF
round
robin,”
Proc.
SPIE
967,
226–235.
[doi:
10.1117/12.22656].
Leonard, T. A. and Rudolph, P.
1993. “BRDF round robin test of ASTM E1392,” Proc. SPIE 1995,
285–293. [doi: 10.1117/12.162658].
Leonard, T. A., Pantoliano, M. A., and Reilly, J.
1989. “Results of a CO2 BRDF round robin,” Proc. SPIE 1165, 444–449.
Lopushenko, V. V.
2000. “Applying mean-ﬁeld theory in scattering from microroughness
of ﬁlmed wafers,” Proc. of Fifth International Conference on Light
Scattering by Nonspherical Particles, 196–199.

References
291
Maradudin, A. A. and Mills, D. L.
1975. “Scattering and absorption of electromagnetic radiation by a semi-
ﬁnite medium in the presence of surface roughness,” Phys. Rev. B 11,
1392.
Marschner, S. R., Jensen, H. W., Cammarano, M., Worley, S., and Hanrahan, H.
2003. “Light scattering from human hair ﬁbers,” Proc. SIGGRAPH 2003
22, 780–791.
Mathis, R. C.
1963. “A Lunar Echo Study at 425 mcs,” Ph.D. dissertation, U. of Texas.
Maxwell, J. R., Beard, J., Weiner, S., Ladd, D., and Ladd, S.
1973. Bidirectional Reﬂectance Model Validation and Utilization.
Technical Report AFAL-TR-73-303, Wright-Patterson AFB.
McClain, S. C., Bartlett, C. L., Pezzaniti, J. L., and Chipman, R. A.
1995. “Depolarization measurements of an integrating sphere,” Appl. Opt.
34(1), 152–154.
McGary, D. E., Stover, J. C., Rifkin, J., Cady, F. M., and Cheever, D. R.
1988. “Separation and measurement of surface scatter and volume scatter
from transmissive optics,” Proc. SPIE 967, 197–203.
McGillem, C. D. and Cooper, G. R.
1984. Continuous and Discrete Signal and System Analysis, Holt,
Rinehart & Winston, New York.
Nahm, K. B. and Wolfe, W. L.
1986. “Light scattering by polystyrene spheres on a mirror,” Proc. SPIE
675, 295–304.
1987. “Light-scattering models for spheres on a conducting plane:
comparison with experiment,” Appl. Opt. 26(15), 2995.
Nicodemus, F. E., Richmond, J. C., Hsia, J. J., Ginsberg, I., and Limperis, T.
1977. Geometric Considerations and Nomenclature for Reﬂectance, U.S.
Dept. of Commerce, NBS Monograph 160.
Noll, R. J., and Glenn, P. E.
1982. “Optical surface analysis code (OSAC),” Proc. SPIE 362, 78–85.
Orazio, F. D., Stowell, W. K., and Silva, R. M.
1982. “Instrumentation of a variable angle scatterometer (VAS),” Proc.
SPIE 362, 165–171.
Paumi, J. D.
1988. “Laser vs. camera inspection in the paper industry,” Tappi Journal
71, 129–135.
Perilloux, B. E.
1991. “Helium neon laser optics: scattered light measurements and
process control,” Proc. SPIE 1530, 255–262. [doi: 10.1117/12.50515].

292
References
Pezzaniti, J. L. Chipman, R. A., and McClain, S. C.,
1994.
“Polarization
bidirectional
reﬂectance
distribution
function
(BRDF),” Proc. SPIE 2260, 160. [doi: 10.1117/12.189211].
Pezzaniti, J. L. and Chipman, R. A.
1995. “Mueller matrix scatter polarimetry of a diamond-turned mirror,”
Opt. Eng. 34(6), 1593–1598. [doi: 10.1117/12.202109].
Rayleigh, Lord.
1907. “On the Dynamical Theory of Gratings,” Proc. R. Soc. Lond. A 79,
399.
Rice, S. O.
1951. “Reﬂection of electromagnetic waves from slightly rough surfaces,”
Commun. Pure Appl. Math. 4, 351.
Rifkin, J., Stover, J. C., McGary, D. E., Kirchner, K. H., and Wilson, D. J.
1988. “Raster area scatter measurements and sample uniformity,” Proc.
SPIE 967, 171–177.
Salyer, D. A., Beaudry, N., Chipman, R. A., Denninghoff, K. R., Basavanthappa,
S., and Park, R. I.
2008.
“Diffuse
spectral
fundus
reﬂectance
measured
using
sub-
retinally
placed
spectralon,”
J.
Biomed.
Opt.
13,
044004.
[doi:
10.1117/1.2966953].
Schiff, T. F. and Stover, J. C.
1989. “Surface Statistics determined from IR scatter,” Proc. SPIE 1165,
52–61.
Schiff, T. F., Knighton, M. W., Wilson, D. J., Cady, F. M., Stover, J. C., and
Butler, J. J.
1993. “Design review of a high-accuracy UV to near-IR scatterometer,”
Proc. SPIE 1995, 121–130. [doi: 10.1117/12.162643].
Schiff, T. F., Stover, J. C., Swimley, B. D., and Bjork, D. R.
1992. “Mueller matrix measurements of scattered light,” Proc. SPIE
1753, 269–277. [doi: 10.1117/12.140706].
Schiff, T. F., Stover, J. C., Cheever, D. R., and Bjork, D. R.
1988.
“Maximum
and
minimum
limitations
imposed
on
BSDF
measurements,” Proc. SPIE 967, 50–57.
Schiff, T. F., Stover, J. C., Wilson, D. J., Swimley, B. D., Southwood, M. E., and
Bjork, D. R.
1992a. “Mueller Matrix measurements with an out-of-plane polarimetric
scatterometer,” Proc. SPIE 1746, 295–306. [doi: 10.1117/12.138799].
1992b. “Design review of a unique out-of-plane polarimetric scatterome-
ter,” Proc. SPIE 1753, 262–268. [doi: 10.1117/12.141440].
1992c. “Retroreﬂections on a low-tech approach to the measurement of
opposition effect,” Proc. SPIE 1753, 278–284. [doi: 10.1117/12.140707].

References
293
Schröder, S., Duparre, A., Coriand, L., Tünnermann, Penalver, D. H., and Harvey,
J. E.
2011. Opt. Ex. 19(10), 9820.
Shurcliff, W. A.
1962. Polarized Light, Harvard University Press, Cambridge, MA.
Siegman, A. E.
1986. Lasers, University Science Books, Mill Valley, CA.
Squires, G. L.
1985. Practical Physics, Cambridge University Press, Cambridge, UK.
Stover, J. C.
1975. “Roughness characterization of smooth machined surfaces by light
scattering,” Appl. Opt. 14(8), 1796.
1976b. “Surface characteristics of machined optics,” Proc. SPIE 93,
90–95.
1980s. Personal observation during several tours of Arizona State
University labs.
2001. “Calibration of particle detection systems,” in Handbook of Silicon
Semiconductor Metrology, Diebold, A., Ed., Marcel Dekker, New York.
2007. “The art of specifying optics for scatter,” Proc. SPIE 6291, 62910O.
[doi: 10.1117/12.693206].
2010. “Experimental conﬁrmation of the Rayleigh–Rice obliquity factor”,
Proc. SPIE 7792, 77920J. [doi: 10.1117/12.858799].
Stover, J. C. and Bernt, M. L.
1992. “Very near specular measurements via incident angle scaling,”
Proc. SPIE 1753, 115–120. [doi: 10.1117/12.140695].
1993. “Wavelength scaling investigation of several materials,” Proc. SPIE
1995, 256–266. [doi: 10.1117/12.162654].
Stover, J. C. Hegstrom, E. L.,
2010. “Scatter metrology of photovoltaic textured surfaces,” Proc. SPIE
7771, 777109. [doi: 10.1117/12.858802].
Stover, J. C. and Hourmand, B.
1984a. “Comparison of roughness measurements by differential scatter
and total integrated scatter,” Proc. SPIE 511, 2–6.
1984b. “Some deviations associated with the vector perturbation theory,”
Proc. SPIE 511, 12–17.
Stover, J. C., Bernt, M. L., Church, E. C., and Takacs, P. Z.
1994. “Measurement and analysis of scatter from silicon wafers,” Proc.
SPIE 2260, 182–191. [doi: 10.1117/12.189215].

294
References
Stover, J. C., Bernt, M. L., McGary, D. E., and Rifkin, J.
1989. “Investigation of anomalous scatter from beryllium mirrors,” Proc.
SPIE 1165, 100–109.
Stover, J. C., Cady, F. M., and Sklar, E.
1985. “Measurement of low angle scatter,” Opt. Eng. 24(3), 404–407.
Stover, J. C., Ivankhnenko, V. I., and Eremin, Y. A.
2001. “The use of light scatter signals to identify particle material,” Proc.
SPIE 4449, 131. [doi: 10.1117/12.450086].
Stover, J. C., Klicker, K. A., Cheever, D. R., and Cady, F. M.
1987. “Reduction of instrument signature in near angle scatter
measurements,” Proc. SPIE 749, 46–53.
Stover, J. C., Rifkin, J., Cheever, D. R., Kirchner, K. H., and Schiff, T. F.
1988. “Comparisons of wavelength scaling predictions to experiment,”
Proc. SPIE 967, 44–49.
Stover, J. C. and Scheer, C. A.,
2001a; “Accurate sizing of deposited PSL spheres from light scatter
measurements;” Proc. SPIE 4449, 147. [doi: 10.1117/12.450088].
Stover, J. C., Schroeder, S., and Germer, T.,
2012a. “Upper roughness limitations on the TIS/RMS relationship;” Proc.
SPIE 8495 (In Press).
Stover, J. C., Schroeder, S., von Finck, A., and Duparré, A.,
2012b. “Estimating hemispherical scatter from incident plane measure-
ments of isotropic samples;” Proc. SPIE 8495 (In Press).
Stover, J. C., Serati, S. A., and Gillespie, C. H.
1984. “Calculation of surface statistics from light scatter,” Opt. Eng.
23(4), 406.
Strausser, Y. E., Doris, B., Diebold, A. C., and Huff, H. R.
1994. “Measurement of silicon surface microroughness by AFM,” Proc.
185th Meeting Electrochem. Soc., 461.
Sung, L., Mulholland, G. W., and Germer, T. A.
1999. “Polarized light-scattering measurements of dielectric spheres upon
a silicon surface,” Opt. Lett. 24(13), 866.
Swimley, B. D., Knighton, M. W., Skurdal, V. C., Pearson, L. H., and Stover, J. C.
1993. “Design review of an instrument to map low-level hydrocarbon
contamination,” Proc. SPIE 1995, 92–100. [doi: 10.1117/12.162641].
Tanaka, F. and DeWitt, D. P.
1989. “Theory of a new radiation thermometry method and an
experimental study using galvannealed steel specimens,” Trans. Soc. Inst.
& Cont. Eng. (Japan), 25(10), 1031.
Thomas, T. R.
1982. Rough Surfaces, Longman, New York.

References
295
van de Hulst, H. C.
1957. Light Scattering by Small Particles, Wiley, New York.
Verdeyen, J. T.
1989. Laser Electronics, 2nd. ed., Prentice Hall, Englewood Cliffs, NJ.
Vernold, C. L.
1989. “Application and veriﬁcation of wavelength scaling for near
specular scatter predictions,” Proc. SPIE 1165, 18–30.
Wang, Y.
1983. “Comparison of BRDF Theories with Experiment,” Ph.D.
dissertation, U. of Arizona.
Waterman, P. C.
1965. “Matrix formulation of electromagnetic scattering,” Proc. IEEE 53,
805–812.
Wilson, S. R., Al-Jumaily, G. A., and McNeil, J. R.
1987. “Nonlinear characteristics of a stylus proﬁlometer,” Proc. SPIE
818, 10–12.
Wolf, E. and Marchand, E. W.
1964. “Comparison of the Kirchhoff and the Rayleigh-Sommerﬁeld
theories of diffraction at an aperture,” JOSA 54, 587.
Wolfe, W. L. and Wang, Y.
1982. “Comparisons of theory and experiment for BRDF of microrough
surfaces,” Proc. SPIE 362, 40–45.
Yariv, A.
1976. Introduction to Optical Electronics, 2nd ed., Holt, Rinehart &
Winston, New York.
Young, R. P.
1975. “Mirror scatter measurement facility comparison,” AEDC-TR-
75–68.
1976a. “Degradation of low-scatter mirrors by particulate contamination,”
Opt. Eng. 15(6), 516–520.
1976b. “Degradation of mirror BRDF by particulate contamination,”
AEDC-TR-177 [or AD-B015792].
Zito, R. R. and Bickel, W. S.
1986. “Light scattering from twisted metal cylinders,” Appl. Opt. 25(11),
1833.

 

Works Consulted
This list includes a number of works that are related to the book but are
never directly referenced. These works provide coverage of topics (such as
the UV scatterometry developed at the Fraunhofer Institute) that are important
contributions to scatter metrology. They are included as an additional resource.
Bamberg, J.
1983. “Stray light analysis with the HP-41C/CV calculator,” Proc. SPIE
384, 109–116.
Bawolek, E.J.
1992. “Light Scattering by Spherical Particles on Semiconductor
Surfaces,” Ph.D. dissertation, 82, Arizona State University, Tempe.
Baylies, W.
1994. Private communication.
Bernt, M.L. and Stover, J.C.
1990. “IR and visible BSDF measurements of several materials,” Proc.
SPIE 1331, 261–269. [doi: 10.1117/12.22661].
1991. “Infrared window damage measured by reﬂective scatter,” Proc.
SPIE 1530, 42–49 (1991). [doi: 10.1117/12.50495].
Bickel, W.S. and Videen, G.W.
1991. “Stokes vectors, Mueller matrices and polarized light: experimental
applications to optical surfaces and all other scatterers,” Proc. SPIE 1530,
2–6.
Bjork, D.R., Klicker, K.A., and Cady, F. M.
1988. “Predicting laser port scatter,” Proc. SPIE 967, 58–61.
Breault, R.P., Greynolds, A.W., and Gauvin, M.A.
1986. “Stray-light analysis with APART/PADE, version 8.7,” Proc. SPIE
675, 4–13.
Brown, J.L.
1991. “Light scatter variations with respect to wafer orientation in GaAs,”
Proc. SPIE 1530, 299–305. [doi: 10.1117/12.50519].
1993. “Preparing samples for scattering measurements—a cleaning study:
part 2,” Proc. SPIE 1995, 80–91. [doi: 10.1117/12.162666].
297

298
Works Consulted
Cady, F.M., Cheever, D.R., Klicker, K.A., and Stover, J.C.
1987. “Comparison of scatter data from various beam dumps,” Proc. SPIE
818, 21–25.
Cady, F.M., Knighton, M.W., Cheever, D.R., Swimley, B.D., Huntdoff, T.L, Schiff,
T.F., and Southwood, M.E.
1992. “Design review of a broadband, 3-dimensional scatterometer,”
Proc. SPIE 1753, 148–157. [doi: 10.1117/12.141438].
Cady, F.M., Stover, J.C., Bjork, D.R., Bernt, M.L., Knighton, M.W., Wilson, D.J.,
and Cheever, D.R.
1990. “Design review of a multiwavelength, three-dimensional scatterom-
eter,” Proc. SPIE 1331, 201–208. [doi: 10.1117/12.22658].
Church, E.L.
1978. “Corrections to stylus measurements of surface ﬁnish,” JOSA 68,
1425A–1426A.
1986. “Models for the ﬁnish of precision machined optical surfaces,”
Proc. SPIE 676, 142–152.
1991. “Scattering from slightly rough crystal surfaces,” Proc. SPIE 1530,
171–184. [doi: 10.1117/12.50507].
Church, E.L. and Berry, H.C.
1982. “Spectral analysis of the ﬁnish of polished optical surfaces,” Wear
83, 189–201.
Church, E.L. and Takacs, P.Z.
1991. “Optimal estimation of ﬁnish parameters,” Proc. SPIE 1530, 71–85.
[doi: 10.1117/12.50498].
Church, E.L., Howells, M.R., and Vorburger, T.V.
1982. “Spectral analysis of the ﬁnish of diamond-turned mirror surfaces,”
Proc. SPIE 315, 202–218.
Church, E.L., Sanger, G.M., and Takacs, P.Z.
1987. “Comparison of WYKO and TIS measurements of surface ﬁnish,”
Proc. SPIE 749, 65–73.
Church, E.L., Takacs, P.Z., and Stover, J.C.
1990. “Scattering by anisotropic grains in beryllium mirrors,” Proc. SPIE
1331, 12–17. [doi: 10.1117/12.22644].
Dolan, A.
1989. “An interactive graphical, CAD integrated tool for stray radiation
analysis,” Proc. SPIE 675, 80–84.
Egert, C.M.
1991.
“Material
characterization
of
beryllium
mirrors
exhibiting
anomalous scatter,” Proc. SPIE 1530, 162–170. [doi: 10.1117/12.50506].

Works Consulted
299
Egert, C.M., Stover, J.C., and Bernt, M.L.
1993. “Wavelength dependence of scatter from 0–50 grade beryllium
mirrors,” Proc. SPIE 1995, 57–65. [doi: 10.1117/12.162649].
Elson, J.M., Bennett, J.M., and Stover, J.C.
1993. “Wavelength and angular dependence of light scattering from
beryllium: comparison of theory and experiment,” Appl. Opt. 32(19),
3362.
Foo, L.D.
1985. “Computer analysis of background radiation sources for a staring
IRCCD camera,” M.S. Thesis, U. of Arizona.
Freniere, E.R.
1980. “Simulation of stray light in optical systems with the GUERAP III,”
Proc. SPIE 257, 78–85.
Freniere, E.R. and Skelton, D.L.
1986. “Use of specular black coatings in well-bafﬂed optical systems,”
Proc. SPIE 675, 126–132.
Greynolds, A.
1980. “Formulas for estimating stray-radiation levels in well-bafﬂed
optical systems,” Proc. SPIE 257, 39–49.
Gu, Z.H., Dummer, R.S., Maradudin, A.A., Lu, J.Q., McGurn, A.R., and Méndez,
E.R.
1990. “Experimental study of enhanced transmission through rough metal
surfaces,” Proc. SPIE 1331, 36–47. [doi: 10.1117/12.22647].
Harvey, J.E. and Lewotsky, K.
1991. “Scattering from multilayer coatings: a linear systems model,”
Proc. SPIE 1530, 35–44. [doi: 10.1117/12.50494].
Kylner, C., Ingers, J.P., Mattsson, L.H., and Bjuggren, M.
1993. “Scattering signatures of isolated surface features,” Proc. SPIE
1995, 66–73. [doi: 10.1117/12.162657].
Larson, T.
1993. “Particle measurement on ﬁlms,” ASTM/SEMATECH Symposium
on Particles, Haze, and Microroughness on Silicon Wafers, Austin, TX
(unpublished).
Leonard, T.A.
1990. “Standardization of optical scatter measurements,” Proc. SPIE
1331, 188–194. [doi:].
Lewis, I.T., Ledebuhr, A.G., and Bernt, M.L.
1991. “Stray-light implications of scratch/dig speciﬁcations,” Proc. SPIE
1530, 22–34. [doi: 10.1117/12.50493].

300
Works Consulted
Likeness, B.K.
1977. “Stray light simulation with advanced Monte Carlo techniques,”
Proc. SPIE 107, 80–88.
Marvin, A., Toigo, F., and Celli, V.
1975. Phys. Rev. B 11, 2777.
Matovich, T., Stover, J.C., and Rifkin, J.
1990. “Design review of a vacuum cryogenic scatterometer,” Proc. SPIE
1331, 135–142. [doi: 10.1117/12.22655].
McNeil, J.R., Herrman, W.C., and Stover, J.C.
1983. “Light scattering characteristics of some metal surfaces—a
smoothing effect?” Proc. Fifteenth Annual Symposium on Optical
Materials for High-Power Lasers, 202–210.
Neu, J.T. and Bressler, M.
1991. “Design considerations for multipurpose bidirectional reﬂectome-
ters,” Proc. SPIE 1530, 244–254. [doi: 10.1117/12.50514].
Noble, H., Lam, W.-S., and Chipman, R.A.,
2009. “Inferring the orientation of texture from polarization parameters,”
Proc. SPIE 7461, 746109. [doi: 10.1117/12.828261].
Noble, H., Smith, G.A., Lam, W.-S., McClain, S., and Chipman, R.A.
2007.“Polarization imaging light scattering facility,” Proc. SPIE 6682,
66820U. [doi: 10.1117/12.735013].
Pirooz, S., Shive, L.W., Malik, I.J., and Martin, A.C.
1993. “Predicting technology advances for wafer surface inspection
systems,” Microcontamination 11(10), 21.
Rifkin, J., Klicker, K.A., Bjork, D.R., Cheever, D.R., Schiff, T.F., Stover, J.C.,
Cady, F.M., Wilson, D.J., Chausse, P.D., and Kirchner, K.H.
1988. “Design review of a complete angle scatter instrument,” Proc. SPIE
1036, 116–124.
Rock, D.
1986. “ORDASCa new ray-based stray radiation analysis program,” Proc.
SPIE 675, 85–94.
Rönnow, D.
1993.
“Sources
of
error
in
spectroscopic
low-level
integrated
light-scattering measurements,” Proc. SPIE
1995, 143–151. [doi:
10.1117/12.162645].
Rudberg, D.A., Stover, J.C., and McGary, D.E.
1991. “Mapping of imbedded contaminants in transparent material by
optical scatter,” Proc. SPIE 1530, 232–239. [doi: 10.1117/12.50512].
Schröder, S., Duparre, A., and Tünnerman, A.
2007. “Roughness evolution and scatter losses of multilayers for 193-nm
optics,” Appl. Opt. 47(13), C88.

Works Consulted
301
Schröder, S., Herffurth, T., Trost, M., and Duparre, A.,
2010a “Angle-resolved scattering and reﬂectance of extreme-ultraviolet
multilayer coatings: measurement and analysis,” Appl. Opt. 49(9), 1503.
2010b. “Angle-resolved scattering: an effective method for characterizing
thin-ﬁlm coatings,” Appl. Opt. 50(9), C164.
St. Clair Dinger, A.
1986. “STRAY—an interactive program for the computation of stray
radiation in infrared telescopes,” Proc. SPIE 675, 95–104.
Stover, J.C.
1974. “Roughness measurement by light scattering,” Laser-Induced
Damage in Optical Materials 1974 (NBS Spec. Publ. 414), 163.
1976a. “Spectral density function gives surface roughness,” Laser Focus
12(2), 83.
1982. “Surface roughness measurements of curved surfaces by light
scatter,” Opt. Eng. 21(6), 987.
1987a. “Overview of current scatterometer measurements and the impact
on optical systems,” Proc. SPIE 776, 33–41.
1987b. “Near specular light scatter measurements,” Proc. Int. Conf. on
Lasers ’87.
1988. “Optical scatter measurements and speciﬁcations,” Lasers and
Optronics 7(8), 61.
1989. “Scatter from optical components: an overview,” Proc. SPIE 1165,
2–9.
1990. Optical Scattering: Measurement and Analysis, McGraw-Hill, New
York.
2005.
“Rough
surface
characterization
and
comparison
of
scat-
ter measurements and models,” Proc. SPIE 5878, 58780U. [doi:
10.1117/12.613780].
Stover, J.C. and Gillespie, C.H.
1982. “Design review of three reﬂectance scatterometers,” Proc. SPIE
362, 172–180.
Stover, J.C. and McGary, D.E.
1990. “Scatter from subsurface defects and contaminants,” Proc. SPIE
1331, 48–52. [doi: 10.1117/12.22648].
Stover, J.C., Bernt, M.L., and Henning, T.D.
1991. “Study of anomalous scatter characteristics,” Proc. SPIE 1530,
185–195. [doi: 10.1117/12.50508].
Stover, J.C., Bernt, M.L., Schiff, T.F., and Swimley, B.
1993. “Mueller matrix measurements of several optical components,”
Proc. SPIE 1995, 267–272. [doi: 10.1117/12.162655].

302
Works Consulted
Stover, J.C., Gillespie, C.H., Cady, F.M., Cheever, D.R., and Klicker, K.A.
1987a. “Wavelength scaling of BRDF scatter data,” Proc. SPIE 818,
62–67.
1987b. “Comparison of BRDF data from two scatterometers,” Proc. SPIE
818, 68–73.
Stover, J.C., Skurdal, V., Bender, J., and Chausse, P.D.
1990. “Design review of a hand-held scatterometer,” Proc. SPIE 1331,
195–200. [doi: 10.1117/12.22657].
Takacs, P.Z., Hewitt, R.C., and Church, E.L.
1987. “Correlation between the performance and metrology of glancing
incidence mirrors containing millimeter wavelength shape errors,” Proc.
SPIE 749, 119–124.
Takacs, P.Z., Li, M.X.-O., Furenlid, K., and Church, E.L.
1993. “Step-height standard for surface-proﬁler calibration,” Proc. SPIE
1995, 235–244. [doi: 10.1117/12.164974].
Trost, M., Schröder, S., Feigl, T., Duparre, A., and Tünnerman, A.
2010. “Inﬂuence of the substrate ﬁnish and thin ﬁlm roughness on the
optical performance of Mo/Si multilayers,” Appl. Opt. 50(9), C148.
Videen, G.
1991. “Light scattering from a sphere on or near a surface,” JOSA A 8,
483-489.
Warner, T.L., Hirleman, E.D., and Bawolek, E.J.
1993. “Characteristics of light scattering signatures of various particle
types on wafer surfaces,” ASTM/SEMATECH Symposium on Particles,
Haze, and Microroughness on Silicon Wafers, Austin, TX, Nov. 2–3, 1993
(unpublished).
Wolff, L.B.
1993. “Diffuse reﬂections from smooth dielectric surfaces,” Proc. SPIE
1995, 26–44. [doi: 10.1117/12.162663].
Xie, Q.Y. and Fesko, D.G.
1993. “Characterization of curved plastic surfaces,” Proc. SPIE 1995,
193–201. [doi: 10.1117/12.162648].
Young, M.
1982. “Objective measurement and characterization of scratch standards,”
Proc. SPIE 362, 86–92.

Index
A
ABC correlation, 85
absolute method, 135
absorption losses, 176
Airy pattern, 57
aluminum, 161
American Society of Testing
Materials (ASTM), 229
angle-resolved scatter (ARS), 16
angle-resolved scatter (ARS)
standards, 230
angular collection limits, 19
aperture convolution, 121
aperture effects, 120
aperture misalignment, 150
appearance, 201
appearance monitoring, 202
application-speciﬁc speciﬁcations,
242
area proﬁles, 31
arithmetic average (a.a.), 25
autocorrelation function, 40
autocovariance function, 34, 40
B
bandwidth limits, 19
beryllium, 161, 162
bidirectional reﬂective distribution
function (BRDF), 14, 158
standard, 230
bidirectional scatter distribution
function (BSDF), 14
bidirectional transmissive distribution
function (BTDF), 14, 219
bidirectional volume distribution
function (BVDF), 14
birefringent materials, 92
black diffusers, 176
Bobbert–Vlieger calculation, 110
Brewster’s law, 95
bulk defects, 192
C
calibration sample, 135
calibration wafers, 217
camera-based systems, 140
capture rate, 233
Coblentz sphere, 18, 230
color, 201
columnar defects, 164
computer disks, 74, 218
conducting medium, 263
contamination, 220
coordinate systems, 137
copper, 161
cosine-corrected BRDF (CCBRDF),
16
cosine-corrected BSDF, 16
cross-polarization technique, 186
crystal-originated particle (COP), 113
cubic spline, 173
curve ﬁtting, 173
cusp shape, 79
cusp-shaped surface, 26
D
defect identiﬁcation, 218
defect scatter, 186
depletion region, 221
303

304
Index
depolarization, 177
deterministic proﬁles, 24
dielectric, 261
differential mobility analyzer (DMA),
236
differential scattering cross section
(DSC), 20, 134, 230
diffraction theory, 47
diffuse integrating sphere, 146
diffuse reﬂectance, 170
diffuse samples, 174
dipole pattern, 111
discrete defects, 210
discrete sources method (DSM), 110
discrete surface features, 134
E
electrical noise, 150
emissivity, 224
empirical scatter speciﬁcations, 254
enhanced backscatter, 145
error analysis, 150
estimators, 31
F
false counts, 234
far ﬁeld, 51, 265
ﬁeld-stop aperture, 128
ﬂat panel displays, 206
Fourier transform, 35
fractal surfaces, 86, 172
Fraunhofer approximation, 51
Fresnel approximations, 51
Fresnel–Kirchhoff, 55
Fresnel reﬂectance, 176
Fresnel reﬂection, 93
Fresnel reﬂection coefﬁcients, 100
full width at half maximum (FWHM),
236
G
galvanneal process, 225
Gaussian beams, 260
Gaussian height distribution, 30, 88,
169
Gaussian PSD, 169
generic speciﬁcations, 240
glare, 219
gold, 161
diffuse, 178
golden rule, 61
grating efﬁciencies, 63, 269
grating equations, 62, 159
grating interferometers, 6
H
Harvey–Shack, generalized, 168
haze, 17, 210
hemispherical scatter, 181
high-frequency limit, 19
Huygens’ principle, 49
I
impedance, 259
incident-angle scaling, 162, 168
instrument calibration, 134
instrument signature, 118
integrating sphere, 230
intraocular lens (IOL), 219
isotropic, 72
isotropic samples, 160, 181
isotropic surfaces, 74
J
Jones calculus, 103
K
K-correlation, 85
Kirchhoff diffraction, 265
Kirchhoff diffraction theory, 52
L
ℓ(surface wavelength), 29
lag, 40
Lambertian samples, 175
light point defect (LPD), 211
light-scattering equivalent (LSE), 211
linear shift invariance, 70
linearly polarized, 92
Lorentzian power spectrum, 86
loss coefﬁcient, 262
low-frequency limit, 19
low-frequency roughness, 214

Index
305
M
m (surface slope), 28
machine vibration, 81
material signature, 178
mean-ﬁeld theory (MFT), 168
metallic reﬂectance, 98
microroughness, 33
mid-IR, 178
Mie theory, 2
modeled integrated scattering tool
(MIST), 113
molybdenum, 161, 163
Mueller matrix, 105, 176
multiple detector scanners, 217
N
nanotopography, 33
National Institute of Science and
Technology (NIST)
“traceability,” 233
near-specular measurements, 123
near-specular scatter, 159
noise-equivalent BSDF (NEBSDF),
120, 131
noise-equivalent power (NEP), 131
nonuniformity, 179
null-ﬁeld method, 110
Nyquist criteria, 31
O
obliquity factor, 55
Ohm’s law, 259
one-dimensional measurement, 179
one-dimensional samples, 165
one-dimensional surfaces, 9, 72, 77
opposition effect, 145
optical constants, 97, 264
optical proﬁlometers, 215
optically rough surfaces, 65, 166
out-of-plane measurements, 137
P
p polarization, 95
paper ﬂaws, 223
parallel gratings, 271
Parseval’s theorem, 35
partial data sets, 172
particle deposition, 235
particle scanners, 211, 231
particle scatter, 109
particulates, 210
phase difference, 92
photovoltaics, 220
plane waves, 258, 265
point defects, 211
polarimetry, 106
polarization concepts, 92
polarization factor Q, 61, 99
polished surfaces, 211
pollution, 220
polystyrene latex (PSL) spheres, 217,
231
power spectral density (PSD), 6, 157,
212
accurate surface, 152
standard, 231
Poynting vector, 257
precision-machined mirror, 78
precision-machined surface, 72
proﬁle measurement error, 43
propagation constant, 258
PSD moments, 36
PSD spike, 77
Q
Q (polarization factor), 61
R
Ra (arithmetic average), 25
Rq (rms roughness), 25
random proﬁles, 29
raster scans, 141
Rayleigh, 2
Rayleigh blue-sky factor, 61
Rayleigh–Rice equation, 158
Rayleigh–Rice perturbation theory, 69
Rayleigh–Rice prediction, 158
Rayleigh–Rice vector perturbation
theory, 61
Rayleigh smooth-surface criterion, 62

306
Index
Rayleigh–Sommerfeld, 55
receiver nonlinearity, 150
reciprocity, 183
reference method, 135
reference signal, 116
refractive index, 101
relative dielectric constant, 101
retardation, 92
retinal scatter, 219
retroreﬂection, 144
ring laser gyroscope (RLG) mirror,
144
rms roughness, 25
root mean square (rms), 25
Rowland circle, 168
S
σ (rms roughness), 25
s polarization, 95
sample mount, 116
sampled proﬁles, 30
scanner calibration, 235
scatter
dipole, 13
from small particles, 13
scatter analysis, 180
scatter function, 16
scatter prediction, 180
scatter screens, 130
scatter speciﬁcations, 239
scatter standards, 229
scatterometer components, 115
Semiconductor Equipment and
Materials International (SEMI), 229
sharp-edged step, 179
signature reduction, 123
silicon, 161
silicon carbide, 161
silicon substrate, 212
silicon wafers, 73, 210
sinusoidal grating, 89, 165, 166, 265
sinusoidal surface, 3, 57, 169
SiO2 particles, 218
skin depth, 264
slip, 40
slit aperture, 49
small particulates, 211
smooth-surface approximation, 168
smooth-surface criterion, 166
Snell’s law, 93
solar energy, 220, 230
spatial bandwidth, 37, 158, 172
spatial wavelengths, 268
Spectralon R⃝, 176
specular reﬂectance, 170
speed of light, 258
spherical aberrations, 120
standard surfaces, 178
Stokes vectors, 103
stray light, 180
surface contour, 33
surface defects, 186
surface ﬁgure, 33
surface irradiance, 14
surface pits, 112, 210, 218
surface PSD, 34
surface radiance, 14
surface slope, 28
surface statistics, 158
surface step, 179
surface wavelength, 29
T
texture, 201, 218
TIS derivation, 88
topographic scatter, 158
total integrated scatter (TIS), 17, 146,
157, 215, 230, 240
relationship, 169
total internal reﬂection, 95
translucent, 174
two-dimensional power spectrum, 72
two-dimensional proﬁles, 31
two-dimensional spectra, 38
two-dimensional surface, 9
U
UV wavelengths, 218
V
vector theory, 61

Index
307
W
wave equation, 257
wavelength scale, 72
wavelength scaling, 158
white diffuser, 176
window function, 38

Photo courtesy of Ptolomey Slocum.
After receiving his Ph.D. from Purdue University,
John worked on a light scatter project—a ﬁeld he
returned to for most of his career. On his way, he
taught at two universities, worked in the defense and
semiconductor industries, and was involved in a few
startup ventures. He teaches a course for SPIE, holds
over ten patents, and is the author of over 100 papers
and articles as well as several book chapters. He has
been active in national and international standards work in ASTM and SEMI for
over twenty years and is an SPIE Fellow. He resides in Tucson, Arizona, where he
consults, runs a measurement service, and provides scatter instrumentation through
The Scatter Works, Inc. and ScatterMaster, LLC.
John can be reached at:
John C. Stover
The Scatter Works, Inc.
Tucson, AZ
thescatterworks.com

The first edition of Optical Scattering: Measurement and Analysis concentrated 
on relating scatter from optically smooth surfaces to the microroughness on those
surfaces. After spending six years in the semiconductor industry, the author has 
updated and expanded the third edition. Newly included are scatter models for pits and 
particles, as well as the use of wafer scanners to locate and size-isolate surface features. 
New sections cover the multimillion-dollar wafer scanner business, establishing that 
microroughness is the noise, not the signal, in these systems. Scatter measurements, now 
routinely used to determine whether small-surface features are pits or particles and inspiring new 
technology that provides information on particle material, are also discussed. These new 
capabilities are now supported by a series of international standards, and a new chapter reviews 
those documents. New information on scatter from optically rough surfaces has also been added.  
Once the critical limit is exceeded, scatter cannot be used to determine surface-roughness 
statistics, but considerable information can still be obtained—especially when measurements are 
made on mass-produced products. Changes in measurement are covered, and the reader will find 
examples of scatter measurements made using a camera for a fraction of the cost and in a fraction 
of the time previously possible. The idea of relating scatter to surface appearance is also 
discussed, and appearance has its own short chapter.  After all—beauty is in the eye of the 
beholder, and what we see is scattered light.
Contents: Quantifying Light Scatter · Quantifying Surface Roughness · Scatter 
Calculations and Diffraction Theory · Using Rayleigh–Rice to Calculate 
Smooth-Surface Statistics from the BRDF · Polarization of Scattered Light 
· Scattering Models for Discrete Surface Features · Instrumentation and Measurement 
Issues · Predicting Scatter from Roughness · Detection of Discrete Defects 
· Appearance and Scattered Light · Industrial Applications · Published Scatter 
Standards · Scatter Specifications
Appendices: Review of Electromagnetic Wave Propagation · Kirchhoff 
Diffraction from Sinusoidal Gratings · BSDF Data · Units
P.O. Box 10
Bellingham, WA 98227-0010
ISBN: 9780819492517
SPIE Vol. No.: PM224

