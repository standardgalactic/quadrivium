Lecture Notes in Computer Science
6035
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison
Lancaster University, UK
Takeo Kanade
Carnegie Mellon University, Pittsburgh, PA, USA
Josef Kittler
University of Surrey, Guildford, UK
Jon M. Kleinberg
Cornell University, Ithaca, NY, USA
Alfred Kobsa
University of California, Irvine, CA, USA
Friedemann Mattern
ETH Zurich, Switzerland
John C. Mitchell
Stanford University, CA, USA
Moni Naor
Weizmann Institute of Science, Rehovot, Israel
Oscar Nierstrasz
University of Bern, Switzerland
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Bernhard Steffen
TU Dortmund University, Germany
Madhu Sudan
Microsoft Research, Cambridge, MA, USA
Demetri Terzopoulos
University of California, Los Angeles, CA, USA
Doug Tygar
University of California, Berkeley, CA, USA
Gerhard Weikum
Max-Planck Institute of Computer Science, Saarbruecken, Germany

Dieter Gollmann Jean-Louis Lanet
Julien Iguchi-Cartigny (Eds.)
Smart Card Research
and Advanced Application
9th IFIP WG 8.8/11.2 International Conference
CARDIS 2010
Passau, Germany, April 14-16, 2010
Proceedings
1 3

Volume Editors
Dieter Gollmann
Hamburg University of Technology
Institute for Security in Distributed Applications
21071 Hamburg, Germany
E-mail: diego@tu-harburg.de
Jean-Louis Lanet
Julien Iguchi-Cartigny
University of Limoges, XLIM
87000 Limoges, France
E-mail: {jean-louis.lanet, julien.cartigny}@unilim.fr
Library of Congress Control Number: 2010924121
CR Subject Classiï¬cation (1998): E.3, C.2, K.6.5, D.4.6, H.4, J.1
LNCS Sublibrary: SL 4 â€“ Security and Cryptology
ISSN
0302-9743
ISBN-10
3-642-12509-3 Springer Berlin Heidelberg New York
ISBN-13
978-3-642-12509-6 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciï¬cally the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting,
reproduction on microï¬lms or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer. Violations are liable
to prosecution under the German Copyright Law.
springer.com
Â© IFIP International Federation for Information Processing 2010
Printed in Germany
Typesetting: Camera-ready by author, data conversion by Scientiï¬c Publishing Services, Chennai, India
Printed on acid-free paper
06/3180

Preface
These proceedings contain the papers selected for presentation at CARDIS 2010,
the 9th IFIP Conference on Smart Card Research and Advanced Application
hosted by the Institute of IT-Security and Security Law (ISL) of the University
of Passau, Germany. CARDIS is organized by IFIP Working Groups WG 8.8 and
WG 11.2. Since 1994, CARDIS has been the foremost international conference
dedicated to smart card research and applications. Every second year leading
researchers and practitioners meet to present new ideas and discuss recent de-
velopments in smart card technologies.
The fast evolution in the ï¬eld of information security requires adequate means
for representing the user in humanâ€“machine interactions. Smart cards, and by
extension smart devices with their processing power and their direct association
with the user, are considered the ï¬rst choice for this purpose. A wide range of
areas including hardware design, operating systems, systems modelling, cryp-
tography, and distributed systems contribute to this fast-growing technology.
The submissions to CARDIS were reviewed by at least three members of the
Program Committee, followed by a two-week discussion phase held electronically,
where committee members could comment on all papers and all reviews. Finally,
16 papers were selected for presentation at CARDIS.
There are many volunteers who oï¬€ered their time and energy to put together
the symposium and who deserve our acknowledgment. We want to thank all the
members of the Program Committee and the external reviewers for their hard
work in evaluating and discussing the submissions. We are also very grateful to
Joachim Posegga, the General Chair of CARDIS 2010, and his team for the local
conference management.
Last, but certainly not least, our thanks go to all the authors who submitted
papers and all the attendees. We hope you ï¬nd the proceedings stimulating.
March 2010
Jean-Louis Lanet
Dieter Gollmann

Organization
General Chair
Joachim Posegga
University of Passau, Germany
Program Chairs
Jean-Louis Lanet
UniversitÂ´e de Limoges, France
Dieter Gollmann
Hamburg University of Technology, Germany
Program Committee
Liqun Chen
Hewlett-Packard, UK
Christophe Clavier
XLIM, France
Wolfgang Eï¬ƒng
Giesecke & Devrient, Germany
Benoit Feix
Inside Contactless, France
Benedikt Gierlichs
COSIC Leuven, Belgium
Louis Goubin
UniversitÂ´e de Versailles, France
Gilles Grimaud
UniversitÂ´e de Lille, France
Marc Joye
Technicolor, France
Josef Langer
CDE Hagenberg, Austria
CÂ´edric Lauradoux
INRIA RhË†one-Alpes, Equipe SWING, France
Kostas Markantonakis
Royal Holloway, UK
Vaclav Matyas
Masaryk University, Czech Republic
Bernd Meyer
Siemens AG, Germany
Wojciech Mostowski
University of Nijmegen, The Netherlands
Pierre Paradinas
INRIA, France
Emmanuel Prouï¬€
Oberthur Technology, France
Jean-Jacques Quisquater
UniversitÂ´e Catholique de Louvain, Belgium
Jean Marc Robert
Ecole de technologie supÂ´erieure MontrÂ´eal, Canada
Jean-Jacques Vandewalle
Gemalto, France
Additional Reviewers
Lejla Batina
Samia Bouzefrane
Guillaume Dabosville
Elke De Mulder
Simon Duquennoy
Hermann Drexler
Junfeng Fan
Lars Hoï¬€mann
Jan Krhovjak
FranÂ¸cois-Xavier Marseille
Nathalie Mitton
Kenny Paterson

VIII
Organization
Michael Roland
Martin Seysen
Petr Svenda
Hugues Thiebeauld
Vincent Verneuil
Colin Walter
Marc Witteman
Local Organization
Arne Bilzhause
Sigline BÂ¨ock
Bastian Braun
Agnes GrÂ¨utzner
Peter HÂ¨aring
Daniel Hausknecht
Michael Kaeuï¬‚
Markus Karwe
Guido Lenk-Blochowitz
Simon Niechzial
Henrich PÂ¨ohls
Daniel Schreckling
Martin Steininger
Marita Ward

Table of Contents
Mathematical Algorithms
The Polynomial Composition Problem in (Z/nZ)[X] . . . . . . . . . . . . . . . . .
1
Marc Joye, David Naccache, and StÂ´ephanie Porte
Enhance Multi-bit Spectral Analysis on Hiding in Temporal
Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
Qiasi Luo
Secure Delegation of Elliptic-Curve Pairing . . . . . . . . . . . . . . . . . . . . . . . . . .
24
BenoË†Ä±t Chevallier-Mames, Jean-SÂ´ebastien Coron, Noel McCullagh,
David Naccache, and Michael Scott
Side Channel Analysis
Side-Channel Leakage across Borders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
JÂ¨orn-Marc Schmidt, Thomas Plos, Mario Kirschbaum,
Michael Hutter, Marcel Medwed, and Christoph Herbst
Designing a Side Channel Resistant Random Number Generator . . . . . . .
49
Suresh N. Chari, Vincenzo V. Diluoï¬€o, Paul A. Karger,
Elaine R. Palmer, Tal Rabin, Josyula R. Rao, Pankaj Rohotgi,
Helmut Scherzer, Michael Steiner, and David C. Toll
Simple Power Analysis on Exponentiation Revisited . . . . . . . . . . . . . . . . . .
65
Jean-Christophe Courr`ege, Benoit Feix, and Myl`ene Roussellet
Atomicity Improvement for Elliptic Curve Scalar Multiplication . . . . . . . .
80
Christophe Giraud and Vincent Verneuil
Systems
Key-Study to Execute Code Using Demand Paging and NAND Flash
at Smart Card Scale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
102
Geoï¬€roy Cogniaux and Gilles Grimaud
Firewall Mechanism in a User Centric Smart Card Ownership Model . . .
118
Raja Naeem Akram, Konstantinos Markantonakis, and Keith Mayes
Logical Attacks
Combined Attacks and Countermeasures . . . . . . . . . . . . . . . . . . . . . . . . . . . .
133
Eric Vetillard and Anthony Ferrari

X
Table of Contents
Attacks on Java Card 3.0 Combining Fault and Logical Attacks . . . . . . . .
148
Guillaume Barbu, Hugues Thiebeauld, and Vincent Guerin
Fault Analysis
Improved Fault Analysis of Signature Schemes . . . . . . . . . . . . . . . . . . . . . . .
164
Christophe Giraud, Erik W. Knudsen, and Michael Tunstall
When Clocks Fail: On Critical Paths and Clock Faults . . . . . . . . . . . . . . . .
182
Michel Agoyan, Jean-Max Dutertre, David Naccache,
Bruno Robisson, and Assia Tria
Privacy
Modeling Privacy for Oï¬€-Line RFID Systems . . . . . . . . . . . . . . . . . . . . . . . .
194
Flavio D. Garcia and Peter van Rossum
Developing Eï¬ƒcient Blinded Attribute Certiï¬cates on Smart Cards via
Pairings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
209
Lejla Batina, Jaap-Henk Hoepman, Bart Jacobs,
Wojciech Mostowski, and Pim Vullers
On the Design and Implementation of an Eï¬ƒcient DAA Scheme . . . . . . .
223
Liqun Chen, Dan Page, and Nigel P. Smart
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
239

The Polynomial Composition Problem in (Z/nZ)[X]
Marc Joye1, David Naccache2, and StÂ´ephanie Porte3
1 Thomson R&D, Security Competence Center
1 avenue de Belle Fontaine, 35576 Cesson-SÂ´evignÂ´e Cedex, France
marc.joye@thomson.net
2 Ecole normale supÂ´erieure, DÂ´epartement dâ€™informatique
45 rue dâ€™Ulm, 75230 Paris Cedex 05, France
david.naccache@ens.fr
3 Smart Consulting
2 rue Louis Vignol, 13600 La Ciotat, France
stef.porte@gmail.com
Abstract. Let n be an RSA modulus and let P, Q âˆˆ(Z/nZ)[X]. This pa-
per explores the following problem: Given polynomials Q and Q(P),
ï¬nd polynomial P. We shed light on the connections between the above
problem and the RSA problem and derive from it new zero-knowledge
protocols suited to smart-card applications.
Keywords:
Polynomial
composition,
zero-knowledge
protocols,
Fiat-Shamir protocol, Guillou-Quisquater protocol, smart cards.
1
Introduction
Smart cards play an active role in security systems. Their salient features make
them attractive in numerous applications, including â€” to name a few â€” the ar-
eas of banking, telephone, health, pay TV, home computers, and communication
networks.
One of the primary use of smart cards resides in authentication. There exist
basically two families of methods currently used for authenticating purposes.
The ï¬rst family relies on secret-key one-way functions while the second one
makes use of public-key techniques. Both families have their own advantages.
This paper focuses on the second family. In particular, we study zero-knowledge
techniques. In a typical scenario, the smart card, characterized by a set of cre-
dentials, plays the role of the proving entity.
The ï¬rst practical zero-knowledge protocol is due to Fiat and Shamir [3].
Remarkably, the protocol is rather eï¬ƒcient, computation-wise. It amounts to at
most two modular multiplications per interaction. However, in order to reach
a level of conï¬dence of (1 âˆ’2âˆ’k), the basic protocol has to be repeated k times
â€” a typical value for k is k = 40. In order to reduce the communication over-
head, there is also a multiple-key protocol, at the expense of more key material.
Another zero-knowledge protocol well suited to smart-card applications is the
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 1â€“12, 2010.
câƒIFIP International Federation for Information Processing 2010

2
M. Joye, D. Naccache, and S. Porte
Guillou-Quisquater protocol [4] (a.k.a. GQ protocol). The GQ protocol features
small storage requirements and needs a single interaction.
In this paper we introduce a new problem, the Polynomial Composition Problem,
which can be stated as follows.
Let P and Q be two polynomials in (Z/nZ)[X] where n is an RSA
modulus. Given polynomials Q and S := Q(P), ï¬nd P.
Most public-key cryptographic schemes base their security on the diï¬ƒculty of
solving a hard mathematical problem. Given that the number of hard problems
harnessable to cryptographic applications is rather limited, the investigation
of new problems is of central importance in cryptography. To understand the
Polynomial Composition Problem and its variants, we explore in the following
sections the way in which the PCP relates to the celebrated RSA problem.
The Polynomial Composition Problem in (Z/nZ)[X] does not imply the RSA
Problem, that is, the computation of roots in Z/nZ. Nevertheless, we exhibit
a related problem that we call Reducible Polynomial Composition Problem (RPCP)
and prove that RPCP â‡”RSA. In particular, we prove that when Q(X) = Xq then
the Polynomial Composition Problem is equivalent to the problem of extracting
qth roots in Z/nZ.
These new problems allow us to broaden the view of existing cryptographic
constructions. Namely, we describe a general PCP-based zero-knowledge pro-
tocol of which the Fiat-Shamir and the Guillou-Quisquater protocols are par-
ticular instances. As will be seen later, if s denotes the secret, they respectively
correspond to the cases Q(X) = vX2 and Q(X) = vXÎ½ (Î½ â‰¥3), with Q(s) = 1.
The rest of this paper is organized as follows. In Section 2, we formally
deï¬ne the Polynomial Composition Problem and introduce the notations used
throughout this paper. The hardness of the problem and its comparison with
RSA are analyzed in Section 3. Finally, in Section 4, we show that the PCP allows
one to generalize several zero-knowledge protocols.
2
The Polynomial Composition Problem
We suggest the following problem as a basis for building cryptographic
protocols.
Problem 1 (Polynomial Composition Problem (PCP)). Let P and Q be two
polynomials in (Z/nZ)[X] where n is an RSA modulus. Given polynomials Q
and S := Q(P), ï¬nd P.
Throughout this paper p and q denote the degrees of P and Q, respectively. Let
P(X) =
p

i=0
uiXi
where the uiâ€™s denote the unknowns we are looking for. We assume that
Q(Y) =
q

j=0
kjYj

The Polynomial Composition Problem in (Z/nZ)[X]
3
is known. Hence,
S (X) =
q

j=0
kj
 p
i=0
uiXi
j
.
If, given polynomials Qâ€²(Y) := Q(Y) âˆ’k0 and S â€²(X) := Qâ€²(P(X)), an attacker
can recover P then the same attacker can also recover P from {Q, S } by ï¬rst
forming polynomials Qâ€²(Y) = Q(Y) âˆ’k0 and S â€²(X) = S (X) âˆ’k0. Therefore
the problem is reduced to that of decomposing polynomials where Q has no
constant term, i.e., Q(Y) = q
j=1 kjYj. Similarly, once this has been done, the
attacker can divide Q by a proper constant and replace one of the coeï¬ƒcients
kj by one. Consequently and without loss of generality we restrict our attention
to monic polynomials Q with no constant term, that is,
Q(Y) = Yq + kqâˆ’1Yqâˆ’1 + Â· Â· Â· + k1Y .
(1)
Noting that q = 1 implies that S = Q(P) = P, we also assume that q â‰¥2.
3
Analyzing the Polynomial Composition Problem
As before, let P(X) = p
i=0 uiXi and let Q(Y) = Yq + qâˆ’1
j=1 kjYj. Generalizing
Newtonâ€™s binomial formula and letting kq := 1, we get
S (X) =
q

j=1
kj
 p
i=0
uiXi
j
=
pq

t=0
â›
âœâœâœâœâ

1â‰¤i0+Â·Â·Â·+ipâ‰¤q
i1+2i2+Â·Â·Â·+pip=t
ki0+Â·Â·Â·+ip
(i0+Â·Â·Â·+ip)!
i0!...ip!
u0i0 Â· Â· Â· upip
â
âŸâŸâŸâŸâ 

:=ct
Xt ,
(2)
where the second sum is extended over all nonnegative integers ij satisfying
1 â‰¤p
j=0 ij â‰¤q and p
j=0 j ij = t.
3.1
RSA Problem â‡’Polynomial Composition Problem
We deï¬ne polynomials P0, . . ., Ppq âˆˆ(Z/nZ)[U0, . . ., Up] as
Pt(U0, . . ., Up) :=

1â‰¤i0+Â·Â·Â·+ipâ‰¤q
i1+2i2+Â·Â·Â·+pip=t
ki0+Â·Â·Â·+ip
(i0 + Â· Â· Â· + ip)!
i0! . . .ip!
U0
i0 Â· Â· Â· Up
ip âˆ’ct .
(3)
Note that Pt(u0, . . ., up) = 0 for all 0 â‰¤t â‰¤pq.
Proposition 1. For all 0 â‰¤r â‰¤p, Ppqâˆ’r âˆˆ(Z/nZ)[Upâˆ’r, . . ., Up]. Furthermore, for
all 1 â‰¤r â‰¤p, Ppqâˆ’r is of degree exactly one in variable Upâˆ’r.

4
M. Joye, D. Naccache, and S. Porte
Proof. For r = 0, we have Ppq(U0, . . . , Up) = Upq âˆ’cpq. For r = p, the condition
Ppqâˆ’r âˆˆ(Z/nZ)[Upâˆ’r, . . ., Up] is trivially satisï¬ed.
Fix r in [1, p). By contradiction, suppose that Ppqâˆ’r  (Z/nZ)[Upâˆ’r, . . ., Up]. So
from Eq. (3), there exists some ij  0 with 0 â‰¤j â‰¤pâˆ’râˆ’1. Since 1 â‰¤i0+Â· Â· Â·+ip â‰¤q,
it follows that i1 + 2i2 + Â· Â· Â·+ pip â‰¤jÂ·1 + p Â·(qâˆ’1) < pqâˆ’r; a contradiction because
i1 + 2i2 + Â· Â· Â· + pip = pq âˆ’r for polynomial Ppqâˆ’r.
Moreover, for all 1 â‰¤r â‰¤p, Ppqâˆ’r is of degree one in variable Upâˆ’r since
we cannot simultaneously have 1 â‰¤p
j=0 ij â‰¤q, p
j=0 j ij = pq âˆ’r, and ipâˆ’r â‰¥2.
Indeed, ipâˆ’r â‰¥2 implies i1 + 2i2 + Â· Â· Â· + pip â‰¤(p âˆ’r) Â· 2 + p Â· (q âˆ’2) < pq âˆ’r, a
contradiction. When ipâˆ’r = 1, i1 + 2i2 + Â· Â· Â· + pip = pq âˆ’r if ip = q âˆ’1 and ij = 0 for
all 0 â‰¤(j  p âˆ’r) â‰¤p âˆ’1. This implies that the only term in Upâˆ’r appearing in
polynomial Ppqâˆ’r is qUpâˆ’r Upqâˆ’1, whatever the values of variables kiâ€™s are.
âŠ“âŠ”
Corollary 1. If the value of up is known then the Polynomial Composition Problem
can be solved in time O(p).
Proof. Solving for Upâˆ’1 the relation Ppqâˆ’1(Upâˆ’1, up) = 0 (which is a univariate
polynomial of degree exactly one in Upâˆ’1 by virtue of the previous proposition),
the value of upâˆ’1 is recovered. Next, the root of Ppqâˆ’2(Upâˆ’2, upâˆ’1, up) gives the
value of upâˆ’2 and so on until the value of u0 is found.
Note that the running time of the resolution process is O(p) and is thus
exponential in the bit-length of p.
âŠ“âŠ”
This means that for low degree polynomials, the Polynomial Composition Prob-
lem in Z/nZ is easier than the problem of computing qth roots in Z/nZ because
if an attacker is able to compute a qth modular root (i.e., to solve the RSA Prob-
lem) then she can ï¬nd up from Ppq(up) = upq âˆ’cpq = 0 and then apply the
technique explained in the proof of Corollary 1 to recover upâˆ’1, . . . , u0. In other
words,
Corollary 2. RSA Problem â‡’Polynomial Composition Problem.
âŠ“âŠ”
There is a proposition similar to Proposition 1. It says that once u0 is known,
u1, . . . , up can be found successively thanks to polynomials P1, . . ., Pp,
respectively.
Proposition 2. For all 0 â‰¤r â‰¤p, Pr âˆˆ(Z/nZ)[U0, . . ., Ur]. Furthermore, for all
1 â‰¤r â‰¤p, Pr is of degree exactly one in variable Ur.
Proof. We have P0(U0) = q
j=1 kjU0
j âˆ’c0.
For r âˆˆ[1, p], suppose that Pr  (Z/nZ)[U0, . . ., Ur]. Therefore, i1 + 2i2 + Â· Â· Â· +
pip â‰¥(r + 1) Â· 1 > r; a contradiction since i1 + 2i2 + Â· Â· Â· + pip = r. Moreover, we can
easily see that Pr(U0, . . ., Ur) = qUqâˆ’1
0
Ur + qâˆ’1
j=1 kj j U0
jâˆ’1Ur + Qr(U0, . . ., Urâˆ’1)
for some polynomial Qr âˆˆ(Z/nZ)[U0, . . ., Urâˆ’1].
âŠ“âŠ”

The Polynomial Composition Problem in (Z/nZ)[X]
5
3.2
Reducible Polynomial Composition Problem â‡’RSA Problem
The Polynomial Composition Problem cannot be equivalent to the RSA Problem.
Consider for example the case p = 2 and q = 3: we have P(X) = u2X2 + u1X + u0
and Q(X) = X3 + k2X2 + k1X, and
S (X) = c6X6 + c5X5 + c4X4 + c3X3 + c2X2 + c1X + c0
with
â§âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ¨âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ©
c0 = k1u0 + k2u2
0 + u3
0 ,
c1 = k1u1 + 2k2u0u1 + 3u2
0u1 ,
c2 = k2u2
1 + 3u0u2
1 + k1u2 + 2k2u0u2 + 3u2
0u2 ,
c3 = u3
1 + 2k2u1u2 + 6u0u1u2 ,
c4 = 3u2
1u2 + k2u2
2 + 3u0u2
2 ,
c5 = 3u1u2
2 ,
c6 = u3
2 .
We deï¬ne the polynomials P0(U0) := k1U0 + k2U2
0 + U3
0 âˆ’c0, P1(U0, U1) :=
k1U1 + 2k2U0U1 + 3U2
0U1 âˆ’c1, and P5(U1, U2) := 3U1U2
2 âˆ’c5. Now we ï¬rst
compute the resultant of P0 and P1 with respect to variable U0 and obtain
a univariate polynomial in U1, say R0 = ResU0(P0, P1). Next we compute
the resultant of R0 and P5 with respect to variable U1 and get a univariate
polynomial in U2, say R1 = ResU1(R0, P5). After computation, we get
R1(U2) = 27c3
1U6
2 + (27c2
1c5k1 âˆ’9c2
1c5k2
2)U4
2
+(âˆ’4c3
5k3
1 + c3
5k2
2b2 âˆ’18c0c3
5k1k2 + 4c0c3
5k3
2 âˆ’27c2
0c3
5) .
Since u2 is a root of both R1(U2) and P6(U2) := U3
2 âˆ’c6, u2 will be a root of their
greatest common divisor in (Z/nZ)[U2], which is given by
(27c2
1c5k1 âˆ’9c2
1c5k2
2)c6U2
+ (27c3
1c2
6 âˆ’4c3
5k3
1 + c3
5k2
1k2
2 âˆ’18c0c3
5k1k2 + 4c0c3
5k3
2 âˆ’27c2
0c3
5) ,
from which we derive the value of u2. Once u2 is known, the values of u1 and
u0 trivially follow by Corollary 1.
We now introduce a harder problem: the Reduced Polynomial Composition
Problem in (Z/nZ)[X].
Problem 2 (Reduced Polynomial Composition Problem (RPCP)). Let P and
Q be two polynomials in (Z/nZ)[X] where n is an RSA modulus. Given Q and
the deg(P) + 1 most signiï¬cant coeï¬ƒcients of S := Q(P), ï¬nd P.
Deï¬nition 1. When the Polynomial Composition Problem is equivalent to the Reduced
Polynomial Composition Problem, it is said to be reducible.
Equivalently, the Polynomial Composition Problem is reducible when the values
of c0, . . ., cp(qâˆ’1)âˆ’1 can be derived from cp(qâˆ’1), . . . , cpq and k1, . . . , kqâˆ’1. This is for

6
M. Joye, D. Naccache, and S. Porte
example the case when p = q = 2, that is, when P(X) = u2X2 + u1X + u0,
Q(X) = X2 + k1X, and
S (X) = c4X4 + c3X3 + c2X2 + c1X + c0
with
â§âªâªâªâªâªâªâªâªâªâªâ¨âªâªâªâªâªâªâªâªâªâªâ©
c0 = k1u0 + u2
0 ,
c1 = k1u1 + 2u0u1 ,
c2 = k1u2 + 2u0u2 + u2
1 ,
c3 = 2u1u2 ,
c4 = u2
2 .
An astute algebraic manipulation yields:
c1 =
4c2c3c4 âˆ’c3
3
8c2
4
(mod n)
and
c0 =
4c2
1c4 âˆ’c2
3k2
1
4c2
3
(mod n) .
If follows that we can omit the ï¬rst two relations (the information included
therein is anyway contained in the remaining three as we had just shown) and
the problem amounts to solving the Reduced Polynomial Composition Problem:
â§âªâªâªâªâ¨âªâªâªâªâ©
c2 = k1u2 + 2u0u2 + u2
1 ,
c3 = 2u1u2 ,
c4 = u2
2 .
Theorem 1. Reducible Polynomial Composition Problem â‡’RSA Problem.
Proof. Assume that we are given an oracle OPCP(k1, . . ., kqâˆ’1; c0, . . . , cpq) which
on input polynomials Q(X) = Xq + qâˆ’1
j=1 kjXj and S (X) = pq
t=0 ctXt returns the
polynomial P(X) = p
i=0 uiXi such that S (X) = Q(P(X)). When the polynomial
composition is reducible, oracle OPCP can be used to compute a qth root of a given
x âˆˆZ/nZ, i.e., compute a y satisfying yq â‰¡x (mod n).
1. choose p + q âˆ’1 random values k1, . . ., kqâˆ’1, cp(qâˆ’1), . . ., cpqâˆ’1 âˆˆZ/nZ;
2. compute c0, . . ., cp(qâˆ’1)âˆ’1;
3. run OPCP(k1, . . ., kqâˆ’1; c0, . . . , cpqâˆ’1, x);
4. get u0, . . ., up;
5. set y := up and so yq â‰¡x (mod n).
Note that Step 2 can be executed since the composition is supposed to be re-
ducible. Furthermore, note that the values of cpqâˆ’1, . . . , cp(qâˆ’1) uniquely determine
the values of upâˆ’1, . . . , u0, respectively. Indeed, from Proposition 1,
Ppqâˆ’r(Upâˆ’r, upâˆ’r+1, . . . , up) âˆˆ(Z/nZ)[Upâˆ’r]
is a polynomial of degree exactly one of which upâˆ’r is root, for all 1 â‰¤r â‰¤p.
âŠ“âŠ”

The Polynomial Composition Problem in (Z/nZ)[X]
7
3.3
A Practical Criterion
In this section, we present a simple criterion allowing to decide if a given
composition problem is reducible.
During the proof of Proposition 1, we have shown that there exists a polyno-
mial Qpqâˆ’r âˆˆ(Z/nZ)[Upâˆ’r+1, . . ., Up] such that
Ppqâˆ’r(Upâˆ’r, . . ., Up) = qUpâˆ’rUp
qâˆ’1 + Qpqâˆ’r(Upâˆ’r+1, . . . , Up)
for all 1 â‰¤r â‰¤p. From cpq = (up)q, we infer:
upâˆ’r =
âˆ’Qpqâˆ’r(upâˆ’r+1, . . ., up)
q cpq
up ,
(1 â‰¤r â‰¤p) .
(4)
Using Eq. (4), for r = 1, . . ., p, we now iteratively compute upâˆ’1, . . ., u0 as a
polynomial function in up. We let Î¥pâˆ’r denote this polynomial function, i.e.,
upâˆ’r = Î¥pâˆ’r(up) for all 1 â‰¤r â‰¤p. We then respectively replace u0, . . ., upâˆ’1 by
Î¥0(up), . . ., Î¥pâˆ’1(up) in the expressions of c0, . . ., cpqâˆ’pâˆ’1. If, for each ci (0 â‰¤i â‰¤
pq âˆ’p âˆ’1), the powers of up cancel thanks to (up)qâˆ’1 = cpq then the problem is
reducible.
We illustrate the technique with the example P(X) = u3X3 + u2X2 + u1X + u0
and Q(Y) = Y3. Then S (X) = 9
t=0 ctXt with
â§âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ¨âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ©
c0 = u3
0 ,
c1 = 3u2
0u1 ,
c2 = 3u2
0u2 + 3u0u2
1 ,
c3 = 3u2
0u3 + 6u0u1u2 + u3
1 ,
c4 = 6u0u1u3 + 3u0u2
2 + 3u2
1u2 ,
c5 = 6u0u2u3 + 3u2
1u3 + 3u1u2
2 ,
c6 = 3u0u2
3 + 6u1u2u3 + u3
2 ,
c7 = 3u1u2
3 + 3u2
2u3 ,
c8 = 3u2u2
3 ,
c9 = u3
3 .
From the respective expressions of c8, c7 and c6, we successively ï¬nd
Î¥2(u3) = c8
3c9
u3 ,
Î¥1(u3) = 3c7c9 âˆ’c8
9c2
9
u3 ,
and
Î¥0(u3) =
27c6c2
9 âˆ’6c8(3c7c9 âˆ’c2
8) âˆ’c3
8
81c3
9
u3 .
Since c0, . . ., c5 are homogeneous in u0, u1, u2, u3 and of degree three, they can be
evaluated by replacing u0, u1, u2 by Î¥0(u3), Î¥1(u3), Î¥2(u3), respectively, and then
replacing (u3)3 by c9. Consequently, the composition is reducible: the values of

8
M. Joye, D. Naccache, and S. Porte
c0, . . ., c5 can be inferred from c6, . . ., c9 and the problem amounts to computing
cubic roots in Z/nZ.
This is not fortuitous and can easily be generalized as follows.
Corollary 3. For Q(Y) = Yq, the Polynomial Composition Problem in Z/nZ is equiv-
alent to the RSA Problem, i.e. to the problem of extracting qth roots in Z/nZ.
Proof. From Eq. (2), it follows that S (X) = pq
t=0 ctXt with
ct =

i0+Â·Â·Â·+ip=q
i1+2i2+Â·Â·Â·+pip=t
q!
i0! Â· Â· Â·ip! u0
i0 Â· Â· Â· up
ip ,
which is homogeneous in u0, . . ., up and of degree i0 + Â· Â· Â· + ip = q. Moreover
since by induction, for 1 â‰¤r â‰¤p, Î¥pâˆ’r(up) = Kpâˆ’r Â· up for some constant Kpâˆ’r, the
corollary follows.
âŠ“âŠ”
4
Cryptographic Applications
Loosely speaking, a zero-knowledge protocol allows a prover to demonstrate the
knowledge of a secret without revealing any useful information about the secret.
We show how to construct such a protocol thanks to composition of polynomials.
4.1
A PCP-Based Zero-Knowledge Protocol
A trusted third party selects and publishes an RSA modulus n. Each prover P
chooses two polynomials P, Q in (Z/nZ)[X] and computes S = Q(P). {Q, S }
is Pâ€™s public key given to the veriï¬er V so as to ascertain Pâ€™s knowledge of the
secret key P.
Execute â„“times the following protocol:
â€¢
P selects a random r âˆˆZ/nZ.
â€¢
P evaluates c = S (r) and sends c to V.
â€¢
V sends to P a random bit b.
â€¢
If b = 0, P reveals t = r and V checks that S (t) = c.
â€¢
If b = 1, P reveals t = P(r) and V checks that Q(t) = c.
PCP-Based Protocol
4.2
Improvements
Eï¬ƒciency can be increased by using the following trick:
P chooses Î½ polynomials P1, . . . , PÎ½âˆ’1, Q in (Z/nZ)[X], with Î½ â‰¥3. Her
secret key is the set {P1, . . ., PÎ½âˆ’1} while her public key consists of
the set {S0
=
Q, S1
=
Q(PÎ½âˆ’1), S2
=
Q(PÎ½âˆ’1(PÎ½âˆ’2)), . . ., Sj
=
Q(PÎ½âˆ’1(. . .(PÎ½âˆ’j))), . . ., SÎ½âˆ’1 = Q(PÎ½âˆ’1(. . . (P1)))}.

The Polynomial Composition Problem in (Z/nZ)[X]
9
The protocol is shown below:
â€¢
P selects a random r âˆˆZ/nZ
â€¢
P evaluates c = SÎ½âˆ’1(r) and sends c to V.
â€¢
V sends to P a random integer 0 â‰¤b â‰¤Î½ âˆ’1.
â€¢
If b = 0, P reveals t = r and V checks that SÎ½âˆ’1(t) = c.
â€¢
If b  0, P reveals t = Pb(. . . (P1(r))) and V checks that SÎ½âˆ’bâˆ’1(t) = c.
Nested PCP Protocol
4.3
Relations with Other Zero-Knowledge Protocols
It is interesting to note that our ï¬rst protocol coincides with the (simpliï¬ed)
Fiat-Shamir protocol [3] (see also [5, Protocol 10.24]) when P(X) = sX and
Q(X) = vX2 where vs2 â‰¡1 (mod n).
The nested variant may be seen as a generalization of the Guillou-Quisquater
protocol [4] by taking P1(X) = P2(X) = Â· Â· Â· = PÎ½âˆ’1(X) = sX where s is a secret
value and Q(X) = vXÎ½ so that vsÎ½ â‰¡1 (mod n). Indeed, in this case we have
PÎ½âˆ’1(. . .(PÎ½âˆ’j(X))) = sjX and hence Sj(X) = v1âˆ’jXÎ½.
An interesting research direction would be to extend the above protocols to
Dickson polynomials.
5
Conclusion
This paper introduced the Polynomial Composition Problem (PCP) and the re-
lated Reducible Polynomial Composition Problem (RPCP). Relations between
these two problems and the RSA Problem were explored. Further, two con-
crete zero-knowledge protocols suited to smart-card applications were given as
particular instances of PCP-based constructs.
Acknowledgments. We are grateful to Jesper Buus Nielsen (ETHZ) for attract-
ing our attention to an important detail in the proof of Corollary 1. We are also
grateful to the anonymous referees for useful comments.
References
1. Cohen, H.: A Course in Computational Algebraic Number Theory. In: GTM 138.
Springer, Heidelberg (1993)
2. Coppersmith, D., Franklin, M., Patarin, J., Reiter, M.: Low-exponent RSA with re-
lated messages. In: Maurer, U.M. (ed.) EUROCRYPT 1996. LNCS, vol. 1070, pp. 1â€“9.
Springer, Heidelberg (1996)
3. Fiat, A., Shamir, A.: How to prove yourself: Practical solutions to identiï¬cation and
signature problems. In: Odlyzko, A.M. (ed.) CRYPTO 1986. LNCS, vol. 263, pp. 186â€“
194. Springer, Heidelberg (1987)

10
M. Joye, D. Naccache, and S. Porte
4. Guillou, L.C., Quisquater, J.-J.: A practical zero-knowledge protocol ï¬tted to security
microprocessor minimizing both transmission and memory. In: GÂ¨unther, C.G. (ed.)
EUROCRYPT 1988. LNCS, vol. 330, pp. 123â€“128. Springer, Heidelberg (1988)
5. Menezes, A.J., van Oorschot, P.C., Vanstone, S.A.: Handbook of Applied Cryptogra-
phy. CRC Press, Boca Raton (1997)
A
Mathematical Background
Let R be an integral domain with quotient ï¬eld K.
Deï¬nition 2. Given two polynomials A , B âˆˆR[X], the resultant of A and B,
denoted by Res(A , B), is deï¬ned as
Res(A , B) = (am)n (bn)m

1â‰¤iâ‰¤m,1â‰¤jâ‰¤n
(Î±i âˆ’Î²j)
(5)
if A (X) = am

1â‰¤iâ‰¤m(X âˆ’Î±i) and B(X) = bn

1â‰¤jâ‰¤n(X âˆ’Î²j) are the decompositions
of A and B in the algebraic closure of K.
From this deï¬nition, we see that Res(A , B) = 0 if and only if polynomials A and
B have a common root (in K); hence if and only if A and B have a (non-trivial)
common factor. Equivalently, we have
Res(A , B) = (am)n 
1â‰¤iâ‰¤m
B(Î±i) = (bn)m 
1â‰¤jâ‰¤n
A (Î²j) .
The resultant Res(A , B) can be evaluated without knowing the decompo-
sition of A and B. Letting A (X) = 
1â‰¤iâ‰¤m aiXi and B(X) = 
1â‰¤jâ‰¤n bjXj, we
have
Res(A , B) = det
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
am amâˆ’1 . . . a0
0
. . . 0
0
am amâˆ’1 . . . a0
. . . 0
...
...
... ... Â· Â· Â· ... ...
0
0
0
am amâˆ’1 . . . a0
bn bnâˆ’1 . . . b0
0
. . . 0
0
bn
bnâˆ’1 . . . b0
. . . 0
...
...
... ... Â· Â· Â· ... ...
0
0
0
bn bnâˆ’1 . . . b0
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
â«âªâªâªâªâªâªâªâ¬âªâªâªâªâªâªâªâ­
n rows
â«âªâªâªâªâªâªâªâ¬âªâªâªâªâªâªâªâ­
m rows
.
This clearly shows that Res(A , B) âˆˆR.
A multivariate polynomial A âˆˆR[X1, . . . , Xk] (with k â‰¥2) may be viewed as
a univariate polynomial in R[X1, . . ., Xkâˆ’1][Xk]. Consequently, it makes sense
to compute the resultant of two multivariate polynomials with respect to one
variable, say Xk. If A , B âˆˆR[X1, . . ., Xk], we let ResXk(A , B) denote the resultant
of A and B with respect to Xk.

The Polynomial Composition Problem in (Z/nZ)[X]
11
Lemma 1. Let A , B âˆˆR[X1, . . ., Xk] (with k â‰¥2). Then (Î±1, . . ., Î±k) is a common
root (in K) of A and B if and only if (Î±1, . . . , Î±kâˆ’1) is a root of ResXk(A , B).
B
Additional Examples
B.1
The Case p = 3 and q = 2
Using the previous notations and simpliï¬cations, we write P(X) = u3X3 +
u2X2 + u1X + u0 and Q(Y) = Y2 + k1Y. Expressing the ciâ€™s we get:
â§âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ¨âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ©
c0 = k1u0 + u2
0 ,
c1 = k1u1 + 2u0u1 ,
c2 = u2
1 + k1u2 + 2u0u2 ,
c3 = 2u1u2 + k1u3 + 2u0u3 ,
c4 = u2
2 + 2u1u3 ,
c5 = 2u2u3 ,
c6 = u2
3 .
Now using the criterion of Â§ 3.3, we ï¬nd u2 =
c5
2c6 u3, u1 = Vu3, and u0 =
âˆ’
k2
1
4 + Lu3 with V :=
4c4c6âˆ’c2
5
8c2
6
and L :=
8c3c2
6âˆ’c5(4c4c6âˆ’c2
5)
16c3
6
. Hence, we derive:
c2 = c6V2 + c5L,
c1 = 2c6LV ,
and c0 = âˆ’
k2
1
4 + L2c6 .
Being reducible, this proves that solving the PCP for p = 3 and q = 2 amounts
to computing square roots in Z/nZ.
B.2
The Case p = 3 and q = 3
We have P(X) = u3X3 + u2X2 + u1X + u0 and Q(X) = X3 + k2X2 + k1X. Deï¬ning
polynomials Pi as in Eq. (3), we successively compute R0 := ResU0(P0, P1),
R1 := ResU1(R0, P7), and R2 = ResU2(R1, P8) wherefrom
R2(u3) = 19683c3
1u18
3 + (âˆ’6561c2
1c7k2
2 + 19683c2
1c7k1)u16
3
+ (2187c2
1c2
8k2
2 âˆ’6561c2
1c2
8k1)u13
3
+ (2916c0c3
7k3
2 + 729c3
7k2
1k2
2 âˆ’13122c0c3
7k2k1 âˆ’2916c3
7k3
1
âˆ’19683c3
7c2
0)u12
3
+ (âˆ’2916c0c2
7c2
8k3
2 âˆ’729c2
8c2
7k2
2k2
1 + 13122c2
8c2
7c0k2k1 + 2916c2
8c2
7k3
1
+ 19683c2
8c2
7c2
0)u9
3
+ (972c4
8c7c0k3
2 + 243c4
8c7k2
1k2
2 âˆ’4374c4
8c7c0k1k2 âˆ’972c4
8c7k3
1
âˆ’6561c4
8c7c2
0)u6
3
+ (âˆ’108c6
8c0k3
2 âˆ’27c6
8k2
1k2
2 + 486c6
8c0k1k2 + 108c6
8k3
1 + 729c6
8c2
0)u3
3
= 0 .

12
M. Joye, D. Naccache, and S. Porte
So, we obtain the value of u3 by exploiting the additional relation c9 = u3
3 and
hence the values of u2, u1, and u0.
Note that if we choose k1 = k2
2/3 then the terms in u16
3 (= c5
9 u3) and in u13
3
(= c4
9 u3) disappear and consequently the value of u3 cannot be recovered. In
this case, the criterion shows again that the problem is equivalent to that of
computing cubic roots in Z/nZ.

Enhance Multi-bit Spectral Analysis on Hiding in
Temporal Dimension
Qiasi Luo
Shanghai Fudan Microelectronics Co., Ltd
Building 4, 127 Guotai Road, Shanghai 200433, China
Abstract. Random delays and dynamic frequency switching are widely
adopted in smartcards and embedded systems as temporal hiding coun-
termeasures to side channel attack.Temporal hiding is regarded as eï¬ƒcient
to enhance the security of cryptographic devices. However, spectral anal-
ysis with Fast Fourier Transform is a powerful method to defeat temporal
hiding countermeasures. Spectral analysis shares the same merit with in-
tegration diï¬€erent power attack. Multi-bit spectral analysis is enhanced
with partitioning power analysis, which is much more eï¬€ective than
the correlation power analysis in the spectral domain. Multi-bit spectral
analysis eï¬€ectively defeats temporal hiding countermeasure with ï¬‚oating-
mean dynamic frequency switching countermeasure. It is suggested cryp-
tographic devices should employ other countermeasures together with
hiding to ensure side channel security.
Keywords: Side channel attack, spectral analysis, diï¬€erential power
analysis, correlation power analysis, partitioning power analysis.
1
Introduction
Nowadays symmetric block ciphers are widely adopted in smartcards and em-
bedded systems to provide security conï¬dence to sensitive data. The implemen-
tation of the cryptographic algorithm may leak out side-channel information
such as power consumption [1] , electromagnetic emanation [2], etc. These leak-
age information can be utilized by side channel attack (SCA) to retrieve the key
of cipher. Masking, power-balanced logic and Hiding are main countermeasures
to SCA [3]. Hiding in the temporal dimension is regarded as an eï¬ƒcient coun-
termeasure in practice, since it is easy to implement together with masking and
power-balanced logic to reinforce the security of cryptographic devices.
Hiding is usually implemented by inserting random delays or dummy
operations which are called random process interrupts (RPIs) [4]. The RPIs
de-synchronize the traces of side-channel signals, therefore the leakage infor-
mation is concealed by noises in the classic SCA. More traces are need to distill
the signal out of noise. Random delays can also be inserted at gate-level [5].
Dynamic frequency switching (DFS) [6] is another eï¬€ective approach of hid-
ing in the temporal dimension. Re-synchronize the random clocks of DFS is
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 13â€“23, 2010.
câƒIFIP International Federation for Information Processing 2010

14
Q. Luo
very diï¬ƒcult in practice. More eï¬€ective way to generate the random delays or
frequency switchings is the ï¬‚oating-mean method [7].
Several analysis methods were proposed to attack hiding in temporal dimen-
sion. Integration DPA (IDPA) [4] substantially reduces the number of traces with
RPIs. Phase-Only Correlation (POC) technique [8] evaluates the displacements
between traces, realigns traces or removes bad traces, and defeats countermea-
sure of random delays [9].
Diï¬€erential frequency analysis (DFA) [10] is a powerful method against hid-
ing, since the amplitude of Fast Fourier Transform (FFT) is time-shift invari-
ant. To retain leakage position information, diï¬€erential spectrogram analysis
(DSA)[11]usesspectrogramtracesgeneratedwithshort-timeFouriertransform.
DEMA with DFA technique against HF and UHF tag prototype [12] proved the
eï¬€ectiveness and advantage of DFA over ï¬ltering and integration techniques [4]
at the presence of noise and hiding both in amplitude and timing dimensions.
In this paper, we propose a signiï¬cantly more eï¬ƒcient multi-bit spectral
analysis method to attack hiding in the temporal dimension. The method avoid
large random correlation noise and have much better performance. The method
is also capable to attack DFS.
First, We introduce the basic concepts about spectral analysis and generalize
the methodology. Analysis of its eï¬ƒciency on hiding is presented. Then we
compare diï¬€erent multi-bit spectral analysis methods both analytically and
empirically. Finally, multi-bit spectral analysis method is carried out on two
diï¬€erent DFS strategies and the results conform to the analysis.
2
Spectral Analysis Methods
2.1
Diï¬€erential Power Spectral Analysis
Consider a cryptographic device that carries out encryption with secret key k.
Let d = {d1, . . ., dNd} be the intermediate data related to k which an adversary
attacks, and Nd be the number of data bits. The side-channel measurement
such as power consumption or EM trace is w = {w1, . . . , wNw}, where Nw is the
total number of points. Multiple traces are W = {w1, . . . , wNW}, where NW is
the number of traces. The leakage information in w usually resides within a
particular time interval Tl. Let l = {l1, . . ., lNl} be the leakage trace during Tl,
where Nl the number of sample points of l and Nl < Nw. The portion other
than l in w is regarded as non-leakage trace and random to the intermediate
data, and is denoted as n = {n1, . . . , rNn}. Thus, the full trace can be written as
w = {n  l} = {n1, . . ., ni, l1, . . . , lNl, ni+1, . . . , nNn}.
The original single bit DPA [1] computes diï¬€erence of means (DOM) as
Î”w =

di=1 wj
Ndi=1
âˆ’

di=0 wj
Ndi=0
where Ndi=1 is the number of traces with di = 1, and Ndi=0 the number of
traces with di = 0, both under a particular key hypothesis Ë†k. For the correct

Enhance Multi-bit Spectral Analysis on Hiding in Temporal Dimension
15
key, the correlation Îµl during Tl indicates the leakage correlation. Theoretically,
Îµl converges to the ideal DOM Îµ with Nw, i.e. Îµl â†’Îµ when Nw â†’âˆ. The
correlations Îµn at other places are random correlations which converge to zero,
i.e. Îµn â†’0 when Nw â†’âˆ. So if we separate l and n in w, then
Îµl =

di=1 lj
Ndi=1
âˆ’

di=0 lj
Ndi=0
â†’Îµ
Îµn =

di=1 nj
Ndi=1
âˆ’

di=0 nj
Ndi=0
â†’0
Îµl of diï¬€erent keys are used for hypothesis test with the maximum likelihood
method, i.e. the correct key hypothesis has the maximum Îµl.
Applying the principles of DPA to spectral signals in frequency domain leads
to diï¬€erential power spectral analysis (DPSA). Let the power spectral density
(PSD) of l be L = {L f, f = 1, Â· Â· Â· , N f}, where N f is the number of points in
FFT and also indicates corresponding sample frequency. DOM of DPSA at each
frequency is computed as follow:
ÎµL =

di=1 Lj
Ndi=1
âˆ’

di=0 Lj
Ndi=0
â†’Îµâ€²
(1)
ÎµN =

di=1 Nj
Ndi=1
âˆ’

di=0 Nj
Ndi=0
â†’0
(2)
where Îµâ€˜ is the theoretical DOM of DPSA when Nw â†’âˆ.
After computation of ÎµL, all frequency components of ÎµL are summed up
(SumAll) as the overall evaluation Ë†e = 
f ÎµL, to test key hypotheses with maxi-
mum likelihood method.
2.2
Generic Spectral Analsyis
Generic spectral analysis method is illustrated in Fig. 1. Two additional steps
(in white box) are inserted into the temporal analysis method procedure. The
two steps, spectral signal generation and evaluation metrics, are symmetric
operations. The former is analytical and the latter synthetical.
The spectral signal generation decomposes original temporal signal into lin-
early independent components at diï¬€erent frequencies. The evaluation metric
accumulates leakage at all frequencies to get the overall evaluation for hypoth-
esis test. There are various PSD estimation methods in digital singal process-
ing. Periodgram is a simple yet eï¬€ective method, which is employed in this
paper.
The straightforward evaluation metric is summation of all frequencies
(SumAll), i.e. the leakage at all frequencies are added up to get the overall
evaluation. In [13], the side-channel leakage information distributes along a
very wide frequency rang from 10 MHz to 400 MHz almost uniformly. The

16
Q. Luo
Fig. 1. Spectral analysis method
evaluation metric employed in [10] [11] is summation of signiï¬cance (SumSig),
i.e. only correlations larger than a certain signiï¬cant level are accumulated. This
approach helps to diminish the inï¬‚uence of noise. There are also various forms
of noise in SCA such as electronic noise, data dependent switching noise etc
[3]. The random correlations of wrong key hypotheses are also considerated as
noise while distinguishing keys. The standard deviation of evaluations of all
keys is regarded as the threshold level to distinguish leakage correlation and
random correlations, and is usually set as the signiï¬cance threshold. Practical
experience shows that the SumAll metric is of good balance between eï¬ƒciency
and robustness.
The sliding-window spectrogram analysis approach can be adopted [11],
when the leakage position is not known. A window is set to include a portion
of the trace to generate PSD. The window slides along the trace with speciï¬ed
step length to generate the spectrogram with temporal information. Separated
spectral analyses are performed on corresponding PSD signals from the same
window. As a result, the position of window where the largest correlation rises
indicates the leakage position.
3
Spectral Analysis on Hiding
Hiding in temporal dimension is of great practical importance. RPIs increase the
amount of traces needed for DPA quadratically, yet integration DPA reduce the
quadratical redundancy into linear [4]. In embedded software implementation,
RPIs are inserted by integer values. Integration DPA on RPIs adds points of ï¬xed
cycle intervals in the traces, which is easy to carry out. However, on DFS [6], this
integration operation is not so easy to implement, since the cycles lengths are
variant and the positions of leakage in diï¬€erent traces do not align with ï¬xed
clock edges.
Spectral analysis has inherent integration property thanks to time-shift in-
variance of FFT. This makes spectral analysis a natural method against hiding
in temporal dimension. A typical DFS scenario is investigated as follow.
Suppose the trace w = {n  l} = {n1, . . ., ni, l1, . . . , lNl, ni+1, . . ., nNn} is randomly
shifted with DFS. For diï¬€erent traces, the positions of l are ï¬‚oating randomly.
Suppose the ï¬‚oating range of l falls into a particular interval I called as leakage
interval. Let the lower and upper bounds of the leakage interval I be il and
iu, i.e. the positions of l1 and lu. The bounds il, iu are random variables with
mean values ul, uu and standard deviations Ïƒl, Ïƒu respectively. The statistics of
I depend on how many cycles it contains:

Enhance Multi-bit Spectral Analysis on Hiding in Temporal Dimension
17
â€“ If I contains exact one cycle, then Nl is constant because the leakage infor-
mation resides within a small interval right after the clock edge. So il and iu
have identical statistics.
â€“ If I contains multiple cycles, Nl is variant with diï¬€erent traces. il and iu are
independent.
For spectral signal generation, only the portion of waveform falling in the leak-
age interval is of interest. Denote this portion of waveform as wI. For simplicity
and without confusion, rewrite w as wI by discarding the portion of waveform
out of I. Then wI = {n  l; n âˆˆI} = {n1, . . ., ni, l1, . . . , lNl, ni+1, . . . , nNn}. Let F (Â·)
denote the FFT operator.
|F (wI)| = |F ({n1, Â· Â· Â· , ni, l1, Â· Â· Â· , lNl, ni+1, Â· Â· Â· , nNn})|
= |F ({n1, Â· Â· Â· , ni, 0, Â· Â· Â· , 0, 0, Â· Â· Â· , 0})| +
|F ({0, Â· Â· Â· , 0, l1, Â· Â· Â· , lNl, 0 Â· Â· Â· , 0})| +
|F ({0, Â· Â· Â· , 0, 0, Â· Â· Â· , 0, ni+1, Â· Â· Â· , nNn})|
= |F ({n1, Â· Â· Â· , ni, })| + |F ({l1, Â· Â· Â· , lNl})| + |F ({ni+1, Â· Â· Â· , nNn})|
= |F ({n1, Â· Â· Â· , ni, ni+1, Â· Â· Â· , nNn})| + |F ({l1, Â· Â· Â· , lNl})|
= |F (nI)| + |F (l)|.
Then the PSD of wI is
WI = |F (wI)|2
= |F (nI)|2 + |F (l)|2 + 2|F (nI)| Â· |F (l)|
= NI + L + 2NIL.
According to formula (1) and (2),
ÎµL â†’Îµâ€²,
ÎµNI â†’0,
ÎµNIL â†’o(ÎµL) â†’0.
Thus
ÎµWI = ÎµNI + ÎµL + 2ÎµNIL â†’Îµâ€².
The formulas shows the integration process of spectral analysis method on
the shifted leakage intervals. Although leakage positions in diï¬€erent traces are
variant, they are all included in, thanks to the time-shift invariance of FFT.
Besides, the linearity of FFT helps to eliminate noise and accumulate signal
simultaneously.
In practical spectral analysis, the leakage interval is usually set as IS = [Î¼l âˆ’
Ïƒl, Î¼u+Ïƒu] to include most of the leakage information and avoid too much noise.
If the Ïƒl and Ïƒu of the particular DFS are larger, more noise should be included
in spectral signal generation, then the signal-noise-ratio (SNR) of the spectral
analysis is less, and the DFS is more resistant to attack.

18
Q. Luo
Consider two DFSs with same mean values ul and uu, but diï¬€erent standard
deviations Ïƒl, Ïƒu and Ïƒâ€²
l, Ïƒâ€²
u respectively. The delay penalties are the same, but the
resistances to spectral analysis are diï¬€erent. The leakage interval Is may contain
only one cycle or multiple cycles:
â€“ One cycle. The lower and upper bounds of leakage intervals have identical
statistics, Ïƒl = Ïƒu = Ïƒ and Ïƒâ€²
l = Ïƒâ€²
u = Ïƒâ€². To successfully retrieve the key with
spectral analysis, the amount of traces needed for DFS with Ïƒ is Ïƒâ€²/Ïƒ times
as much as DFS with Ïƒâ€².
â€“ Multiple cycles. The lower and upper bounds of leakage intervals are in-
dependent. Each bound introduces noise independently. The noise level
is proportional to the length of I. To successfully retrieve the key with
spectral analysis, the amount of traces needed for DFS with Ïƒl and Ïƒu
is (Ïƒâ€²
l + Ïƒâ€²
u + uâ€²
u âˆ’uâ€²
l)/(Ïƒl + Ïƒu + uu âˆ’ul) times as much as DFS with Ïƒâ€²
l
and Ïƒâ€²
u.
4
Enhance Multi-bit Spectral Analysis
4.1
Correlation Power Spectral Analysis
To improve DPA SNR, analysis methods make use of multi-bit leakage in-
formation. The most widely adopted multi-bit power analysis method is cor-
relation power analysis (CPA) [14]. The Hamming distance model of CPA is
written as
l = ah(d) + b
(3)
where h(Â·) is Hamming distance function, a is scalar gain, and b is the overall
noise eï¬€ect independent with h(d).
The Pearson correlation coeï¬ƒcient between the power consumption and
Hamming distance is
Ïl =
NT
 ljhj âˆ’ lj  hj

NT
 lj2 âˆ’
 lj2 
NT
 hj2 âˆ’
 hj2 .
CPA has its corresponding spectral form. Rewrite formula (3) in the frequency
domain,
L = ah(d) + B
where B is the PSD of b and is also independent with h(d).
Pearson correlation coeï¬ƒcients are computed at all frequencies of L for cor-
relation power spectral analysis (CPSA):
ÏL =
NT
 Ljhj âˆ’ Lj  hj

NT
 Lj2 âˆ’
 Lj2 
NT
 hj2 âˆ’
 hj2 .
(4)

Enhance Multi-bit Spectral Analysis on Hiding in Temporal Dimension
19
Afterward all frequency components of ÏL are summed up to get the overall
evaluation Ë†e = 
f ÏL. Evaluation Ë†e is served for key hypothesis test.
Simple CPSA without evaluation metric synthesis has already been employed
in [12] [15]. Here in this paper, a CPSA is exempliï¬ed on the data set of DPA
contest [16]. The Pearson correlation coeï¬ƒcients of all frequencies of the CPSA
with 5000 traces are shown Fig. 2(a), and the result along with number of traces
are shown in Fig. 3(a). The evaluation metric is SumAll. One major problem with
CPSA is the random correlations at higher frequencies. After FFT, the signals
at the same frequency are already linear correlated. The Pearson coeï¬ƒcients
of CPSA give large values even there are only random correlations at higher
frequencies. If these random correlations are summed up with the SumAll
metric, it will reduce the eï¬ƒciency of CPSA.
4.2
Partitioning Power Spectral Analysis
Random correlations at higher frequencies in CPSA mainly originate from the
normalization of standard deviations in the denominator of formula (4). The
partitioning power analysis (PPA) [17] [18] without standard deviation normal-
ization, has the same even better eï¬ƒciency compared with CPA.
PPA attacks on multi-bit intermediate data dp = {d1, Â· Â· Â· , dNp}, where Np is
the number of data bits PPA attacks and Np â‰¤Nd. The traces are partitioned
into groups by Hamming weights g = h(dp) = {0, Â· Â· Â· , Np} under diï¬€erent key
hypotheses. Then means of groups are computed and they are summed up with
diï¬€erent weights ag to get the overall correlation ÎµP
l .
ÎµP
l =
Np

g=0
ag

g lj
Ng
where Ng is number of traces partitioned in group g and 
g ag = 0. For Np = 4,
a2 = 0, âˆ’2a0 = âˆ’a1 = a3 = 2a4, or ag = {âˆ’1, âˆ’2, 0, 2, 1}.
The corresponding partitioning power spectral analysis (PPSA) computes
correlations at diï¬€erent frequencies as
ÎµP
L =
Np

g=1
ag

g Lj
Ng
.
Then all frequency components of are summed up (SumAll) as the overall
evaluation Ë†e = 
f ÎµP
L for hypotheses test.
A PPSA is performed on the same data set with the same order of traces
as CPSA in Section 4. The correlations of PPSA with 5000 traces are shown in
Fig. 2(b), and the results with number of traces are shown in Fig. 3(b). Compared
to CPSA, there are no large random correlations at the higher frequencies. The
characteristic frequencies where the correlation of correct key begins to sink into
the random correlations of CPSA and PPSA are the same, which indicates that
the leakage signals extracted by both methods are the same. The diï¬€erence is

20
Q. Luo
0
0.2
0.4
0.6
0.8
1
âˆ’0.1
âˆ’0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
â† 0.66
Radian / Ï€
Pearson coefficient
CPSA
(a)
0
0.2
0.4
0.6
0.8
1
âˆ’0.03
âˆ’0.02
âˆ’0.01
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
PPSA
Radian / Ï€
Correlation
â† 0.66
(b)
Fig. 2. (a) Pearson correlation coeï¬ƒent of CPSA . (b) Correlation of PPSA. The red curves
are for correct key and blue curves for wrong keys.
0
500
1000
1500
2000
2500
0
10
20
30
40
50
60
70
80
CPSA
Number of traces
Evaluation
â† 933
(a)
0
100
200
300
400
500
600
0
5
10
15
20
25
30
35
40
45
50
Number of traces
Evaluation
Static Frequency
â† 98
(b)
Fig. 3. Results of (a) CPSA. (b) PPSA. The red curves are for correct key and blue curves
for wrong keys.
about the noise. The results in Fig. 3 show that amount of traces needed to get
the same SNR level with CPSA is nearly 10 times as much as PPSA.
5
Experimental Results
The original data set is from DPA contest [16], which contains power consump-
tion traces of an unprotected DES crypto-processor on a SoC in ASIC with
static frequency. In general ASICs or micro-controllers, the power consump-
tion leakage information all resides within a short time interval right after the
clock edges. To generate traces with DFS, random delays of zero values are
inserted into the original trace before the clock edges. DFS traces generated
by this method share the same characteristic of randomly shifted leakage with
actual DFS traces. The only diï¬€erence is the actual DFS traces have very small
power consumption for the random delays between shifted clock cycles, while

Enhance Multi-bit Spectral Analysis on Hiding in Temporal Dimension
21
the generated DFS traces have zero values. However, the signal, i.e. the leakage
information residing right after the clock edges is the same.
Data sets for two kinds of random DFS are generated. The ï¬rst DFS employs
the most commonly used uniform distribution. The random delays follow in-
dependently uniform distribution with mean value Î¼0 and standard deviation
Ïƒ0. For one single trace with 32 frequency switchings, the overall delay is the
accumulation of 32 independent uniform delays. So the standard deviation of
the overall delay ÏƒÎ£ is much less than Ïƒ0, which leads to eï¬ƒciency degeneration.
The second DFS employs more eï¬ƒcient ï¬‚oating mean method [7] with parame-
ters a and b. The standard deviation of the overall delay with the ï¬‚oating mean
method does not diminish with accumulation.
The parameters used for random delay generation in this paper is as follow.
Clock cycle length of the original traces is T = 625. The statistics of one single
random delay of the uniform DFS are mean value Î¼0 = 625, and standard
deviation Ïƒ0 = 360. Parameters for ï¬‚oating mean DFS are a = 1250 and b = 250.
The standard deviations of lower and upper bounds of leakage interval I for
uniform DFS and ï¬‚oating mean DFS are shown in Table 1. Floating mean DFS
has larger standard deviations than the uniform DFS, thus is more resistant to
spectral analysis.
Table 1. Parameters of DFSs
Uniform
Floating Mean
il
iu
il
iu
Î¼ 14376 16253 14353
16244
Ïƒ 1730
1838
6653
7520
One trace from the original DPA contest data set and the DPA leakage
positions are shown in Fig. 4(a). The red curve is for DOM of correct key
and blue for wrong keys. One trace with uniform DFS and one with ï¬‚oat-
ing mean DFS are shown in Fig. 4(b). The red lines indicates the positions
of lower and upper bounds of leakage interval I in spectral analysis on the
DFSs. The range of leakage interval with ï¬‚oating mean DFS is much wider than
uniform DFS.
The temporal analysis methods including CPA and PPA on the DFS traces all
fail to retrieve the correct key with up to 81000 traces. PPSAs are performed on
the original data with static frequency, generated data with uniform DFS and
ï¬‚oating mean DFS. The PPSAs attack on the ï¬rst S-Box of the 16th round in
DES. The PPSAs process the data set with the same orders. Evaluation metric is
SumAll. The results are shown in Fig. 5(a) and 5(b). According to the analysis
in section 3, the ratio of amount of traces needed to retrieved the correct key
for spectral analysis on two DFSs is (Ïƒâ€²
l + Ïƒâ€²
u + uâ€²
u âˆ’uâ€²
l)/(Ïƒl + Ïƒu + uu âˆ’ul) =
(7520+6653+16244âˆ’14353)/(1730+1838+16253âˆ’14376) = 2.95. While in Fig. 5,
the ratio is 48663/6138 = 7.92. The empirical value does ont ï¬t the theoretical
value very well, because more leakages are not included in the leakage interval

22
Q. Luo
Fig. 4. (a) Up: original trace with static frequency; Down: DPA leakage positions. (b) Up:
generated trace with uniform DFS; Down: generated trace with ï¬‚oating mean DFS. The
dashed lines are nominal clock edges.
Fig. 5. PPSA on (a) uniform DFS and (b) ï¬‚oating mean DFS. The red curves are for correct
key and blue for wrong keys.
I with the ï¬‚oating mean DFS than uniform DFS. Compared to results in [7] with
DPA where the ratio is 45000/2500 = 18, the PPSA gives much better results.
6
Conclusions
We proposed the spectral analysis method with evaluation metric on hiding in
temporal dimension such as RPIs and DFS. The spectral analysis has inherent in-
tegration property thanks to shift-invariance of FFT. We proposed PPSA method
to enhance the multi-bit spectral analysis. PPSA does not generate large ran-
dom correlations at higher frequencies, and is much more eï¬ƒcient than CPSA.
Experimental results show PPSA break down DFS. Hiding as a countermeasure
can increase the amount of traces needed for successful attacks, but it is not
always safe and should be implemented together with other countermeasures
such as masking to ensure security.

Enhance Multi-bit Spectral Analysis on Hiding in Temporal Dimension
23
References
1. Kocher, P.C., Jaï¬€e, J., Jun, B.: Diï¬€erential power analysis. In: Wiener, M. (ed.)CRYPTO
1999. LNCS, vol. 1666, pp. 388â€“397. Springer, Heidelberg (1999)
2. Agrawal, D., Archambeault, B., Rao, J., Rohatgi, P.: The EM side channel(s). In: Kaliski
Jr., B.S., KocÂ¸, CÂ¸ .K., Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp. 29â€“45. Springer,
Heidelberg (2003)
3. Mangard, S., Oswald, E., Popp, T.: Power Analysis Attacks: Revealing the Secrets of
Smart Cards (Advances in Information Security). Springer, New York (2007)
4. Clavier, C., Coron, J.S., Dabbous, N.: Diï¬€erential power analysis in the presence of
hardware countermeasures. In: Paar, C., KocÂ¸, CÂ¸ .K. (eds.)CHES 2000. LNCS, vol. 1965,
pp. 252â€“263. Springer, Heidelberg (2000)
5. Bucci, M., Luzzi, R., Guglielmo, M., Triï¬letti, A., AG, I., Graz, A.: A countermea-
sure against diï¬€erential power analysis based on random delay insertion. In: IEEE
International Symposium on Circuits and Systems, ISCAS 2005, pp. 3547â€“3550 (2005)
6. Yang, S., Wolf, W., Vijaykrishnan, N., Serpanos, D.N., Yuan, X.: Power attack resistant
cryptosystem design: a dynamic voltage and frequency switching approach. In:
Proceedings of the Design, Automation and Test in Europe, vol. 3, pp. 64â€“69 (2005)
7. Coron, J., Kizhvatov, I.: An eï¬ƒcient method for random delay generation in em-
bedded software. In: Clavier, C., Gaj, K. (eds.) CHES 2009. LNCS, vol. 5747, p. 170.
Springer, Heidelberg (2009)
8. Homma, N., Nagashima, S., Sugawara, T., Aoki, T., Satoh, A.: A high-resolution
phase-based waveform matching and its application to side-channel attacks. IEICE
Trans. Fundam. Electron. Commun. Comput. Sci. E91-A, 193â€“202 (2008)
9. Nagashima, S., Homma, N., Imai, Y., Aoki, T., Satoh, A.: DPA using phase-based
waveform matching against random-delay countermeasure. In: IEEE International
Symposium on Circuits and Systems, ISCAS 2007, pp. 1807â€“1810 (2007)
10. Gebotys, C., Tiu, C., Chen, X.: A countermeasure for EM attack of a wireless PDA.
In: International Conference on Information Technology: Coding and Computing,
ITCC 2005, vol. 1, pp. 544â€“549 (2005)
11. Gebotys, C.H., Ho, S., Tiu, C.: EM analysis of Rijndael and ECC on a wireless Java-
based PDA. In: Rao, J.R., Sunar, B. (eds.) CHES 2005. LNCS, vol. 3659, pp. 250â€“264.
Springer, Heidelberg (2005)
12. Plos, T., Hutter, M., Feldhofer, M.: Evaluation of side-channel preprocessing tech-
niques on cryptographic-enabled HF and UHF RFID-tag prototypes. In: Workshop
on RFID Security 2008, Budapest, July 9-11 (2008)
13. Hutter, M., Mangard, S., Feldhofer, M.: Power and EM attacks on passive RFID
devices. In: Paillier, P., Verbauwhede, I. (eds.) CHES 2007. LNCS, vol. 4727, pp. 320â€“
333. Springer, Heidelberg (2007)
14. Brier, E., Clavier, C., Olivier, F.: Correlation power analysis with a leakage model.
In: Joye, M., Quisquater, J.-J. (eds.) CHES 2004. LNCS, vol. 3156, pp. 16â€“29. Springer,
Heidelberg (2004)
15. Hutter, M., Medwed, M., Hein, D., Wolkerstorfer,J.: Attacking ECDSA-Enabled RFID
Devices. In: Abdalla, M., Pointcheval, D., Fouque, P.-A., Vergnaud, D. (eds.) ACNS
2009. LNCS, vol. 5536, p. 534. Springer, Heidelberg (2009)
16. DPA Contest 2008/2009, http://www.dpacontest.org/
17. Le, T.H., ClÂ´edi`ere, J., Canovas, C., Robisson, B., Servi`ere, C., Lacoume, J.-L.: A propo-
sition for correlation power analysis enhancement, pp. 174â€“186 (2006)
18. Le, T.H., Canovas, C., ClÂ´edi`ere, J.: An overview of side channel analysis attacks, 33-43
(2008), 1368319

Secure Delegation of Elliptic-Curve Pairingâ‹†
BenoË†Ä±t Chevallier-Mames1, Jean-SÂ´ebastien Coron2, Noel McCullagh3,
David Naccache4, and Michael Scott3
1 benoit.chevalliermames@gemplus.com
2 UniversitÂ´e du Luxembourg
6, rue Richard Coudenhove-Kalergi
l-1359 Luxembourg, Luxembourg
jean-sebastien.coron@uni.lu
3 School of Computing, Dublin City University
Glasnevin, Dublin 9, Ireland
{noel.mccullagh,mike}@computing.dcu.ie
4 Â´Ecole normale supÂ´erieure
DÂ´epartement dâ€™informatique, Groupe de cryptographie
45, rue dâ€™Ulm, f-75230 Paris Cedex 05, France
david.naccache@ens.fr
Abstract. In this paper we describe a simple protocol for secure del-
egation of the elliptic-curve pairing. A computationally limited device
(typically a smart-card) will delegate the computation of the pairing
e(A, B) to a more powerful device (for example a PC), in such a way
that 1) the powerful device learns nothing about the points A and B,
and 2) the limited device is able to detect when the powerful device is
cheating.
Keywords:
Elliptic-curve pairing, secure delegation protocol, Boneh-
Franklin IBE.
1
Introduction
Since the discovery of the ï¬rst practical identity-based cryptosystem based on the
elliptic-curve pairing [1], pairing-based cryptography has become a very active
research area. Many pairing-based protocols have been proposed with novel and
attractive properties, for example for key-exchange [6] and digital signatures [3].
The increasing popularity of pairing-based cryptosystems and their foresee-
able deployment in computationally constrained devices such as smart-cards and
dongles spurred recent research in the implementation of pairing (e.g. [8]). Un-
fortunately, although pairing is a cubic-time operation, pairing implementation
attempts in limited devices such as smart-cards reveal that the embedded code
may be slow, resource-consuming and tricky to program.
â‹†Work done while authors Chevallier-Mames, Coron and Naccache were with Gemplus
(now Gemalto). Authors McCullagh and Scott are also aï¬ƒliated to NoreTech.
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 24â€“35, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Secure Delegation of Elliptic-Curve Pairing
25
Given that several PC-based pairing libraries exist, it seems natural to ï¬nd-out
whether a smart-card could interact with such packages to privately compute the
elliptic-curve pairing. Note that beyond preserving operands from preying eyes,
the card must also ascertain that bogus libraries donâ€™t mislead it into generating
wrong results.
In this paper, we propose a simple protocol for secure delegation of elliptic-
curve pairing. A computationally limited device (for example a smart-card) will
delegate the computation of the elliptic-curve pairing e(A, B) to a more powerful
device (for example a PC), in such a way that 1) the powerful device learns
nothing about the points A and B, and 2) the limited device is able to detect
when the powerful device is cheating. The limited device will restrict itself to
simple curve or ï¬eld operations. We also describe some eï¬ƒcient variants of our
protocol if one of the points A and B or both are already publicly known, or
when the point A can be considered as constant, as it is the case for the Boneh-
Franklin identity-based encryption scheme [1].
2
Preliminaries
2.1
Bilinear Map
Our protocol for secure pairing delegation is actually more general than just
elliptic-curve pairing : as most pairing-based cryptosystems, it works for any
bilinear map. Therefore, we brieï¬‚y review the basic facts about bilinear maps. We
follow the notations in [2]. We refer the reader to [7] for an extensive background
on elliptic-curve pairing.
1. G1 and G2 are two (additive) cyclic groups of prime order p;
2. G1 is a generator of G1 and G2 is a generator of G2;
3. Ïˆ is a computable isomorphism from G1 to G2 with Ïˆ(G1) = G2;
4. e is a computable bilinear map e : G1 Ã— G2 â†’GT ;
5. GT is a multiplicative cyclic group of order p.
A bilinear map is a map e : G1 Ã— G2 â†’GT with the following properties :
1. Bilinear: for all U âˆˆG1, V âˆˆG2 and a, b âˆˆZZ, e(a Â· U, b Â· V ) = e(U, V )aÂ·b
2. Non-degenerate: e(G1, G2) Ì¸= 1
Note that the previous conditions imply that e(G1, G2) is a generator of GT .
2.2
Computational Indistinguishability
We recall the notion of computational indistinguishability [5], which will be used
in the deï¬nition of secure pairing delegation. Two distribution ensemble X =
{Xn}nâˆˆN and Y = {Yn}nâˆˆN are said to be computationally indistinguishable
and denoted X
câ‰¡Y if for every (probabilistic) polynomial-time algorithm A,
and every c > 0, there exists an integer N such that for all n > N
|Pr[A(Xn) = 1] âˆ’Pr[A(Yn) = 1]| < 1
nc

26
B. Chevallier-Mames et al.
3
Secure Pairing Delegation
In this section, we formalize the security notions for secure pairing delega-
tion. Our setting is the following : a computationally limited device, called the
card and denoted C, will delegate the computation of the pairing e(A, B) to a
more powerful device, called the terminal and denoted T . Both devices C and
T are actually probabilistic polynomial-time Turing machines. We denote by
ViewT (A, B) the terminalâ€™s view when interacting with C with points A, B. The
terminalâ€™s view includes the randomness used by the terminal, and the data
received from the card.
The security notions could be formalized in the general framework of secure
multiparty computation (for standard deï¬nitions, see for example [4]). However,
we observe that our setting is much simpler than for general secure multiparty
computation : the terminal has no secret and outputs nothing; moreover only
the terminal can be malicious. Therefore, we adapt the general notions for secure
multiparty computation to our restricted setting. We obtain that a protocol for
pairing delegation is secure if it satisï¬es the three following security notions :
Completeness: after completion of the protocol with an honest terminal, the
card obtains e(A, B), except with negligible probability.
Secrecy: a (possibly cheating) terminal should not learn any information about
the points A and B. More formally, for any malicious terminal T , there exists a
simulator S such that for any A, B, the output of S is computationally indistin-
guishable from the terminalâ€™s view :
S
câ‰¡ViewT (A, B)
Note that the simulator S is not given A, B as input.
Correctness:
The card should be able to detect a cheating terminal, except
with negligible probability. More formally, for any cheating terminal T and for
any A, B, the card outputs either âŠ¥or e(A, B), except with negligible probability.
4
Our Protocol
In order to delegate the pairing computation, one could think of the follow-
ing protocol. On input A, B, the card could generate random x, y and ask the
terminal to compute the pairing :
Î± = e(x Â· A, y Â· B)
The card would then recover e(A, B) by simply computing :
e(A, B) = Î±(xÂ·y)âˆ’1
However, it is easy to see that this is not a secure pairing delegation protocol.
Namely, although the terminal learns nothing about A, B, the card cannot detect

Secure Delegation of Elliptic-Curve Pairing
27
a cheating terminal. Namely, if the terminal outputs Î±r for some r instead of Î±,
the card will obtain e(A, B)r instead of e(A, B), and will not be able to detect
the cheating terminal. In the following, we describe a secure pairing delegation
protocol, such that if the terminal is cheating, then the card outputs either the
correct e(A, B) or nothing with overwhelming probability.
4.1
Description
The card and the terminal are given as input a description of the groups G1, G2
and GT , and a description of the bilinear map e : G1Ã—G2 â†’GT . The card and the
terminal receive the generators G1 and G2; we also assume that the card receives
e(G1, G2). The card is given as input the points A and B and must eventually
output e(A, B). Recall that G1, G2 and GT are additive groups of order p.
1. The card generates a random g1 âˆˆZZp and a random g2 âˆˆZZp, and queries
the three following pairings to the terminal :
Î±1 = e(A + g1.G1, G2),
Î±2 = e(G1, B + g2.G2)
Î±3 = e(A + g1.G1, B + g2.G2)
2. The card checks that Î±1, Î±2, Î±3 âˆˆGT , by checking that (Î±i)p = 1 for i =
1, 2, 3. Otherwise, the card outputs âŠ¥and halts.
3. The card computes a purported value for e(A, B):
eAB = Î±âˆ’g2
1
Â· Î±âˆ’g1
2
Â· Î±3 Â· e(G1, G2)g1g2
(1)
4. The card generates four random values a1, r1, a2, r2 âˆˆZZp and queries the
pairing :
Î±4 = e(a1.A + r1.G1, a2.B + r2.G2)
5. The card computes :
Î±â€²
4 = (eAB)a1a2 Â· (Î±1)a1r2 Â· (Î±2)a2r1 Â· e(G1, G2)r1r2âˆ’a1g1r2âˆ’a2g2r1
(2)
and checks that Î±â€²
4 = Î±4. In this case, the card outputs eAB; otherwise it
outputs âŠ¥.
4.2
Security Proof
The following theorem shows that our protocol is secure :
Theorem 1. The previous protocol is a secure pairing delegation protocol.
Proof. The completeness property is easily established. We obtain from the bi-
linear property :
e(A + g1.G1, B + g2.G2) = e(A, B) Â· e(A, G2)g2 Â· e(G1, B)g1 Â· e(G1, G2)g1g2

28
B. Chevallier-Mames et al.
Then, for an honest terminal, we have :
Î±1 = e(A + g1.G1, G2) = e(A, G2) Â· e(G1, G2)g1
(3)
Î±2 = e(G1, B + g2.G2) = e(G1, B) Â· e(G1, G2)g2
(4)
Î±3 = e(A + g1.G1, B + g2.G2)
(5)
Combining the four previous equations, we obtain :
Î±3 = e(A, B) Â· (Î±1)g2 Â· (Î±2)g1 Â· e(G1, G2)âˆ’g1g2
which, using (1), shows that the card computes the correct eAB = e(A, B).
Moreover, using :
Î±4 = e(a1.A + r1.G1, a2.B + r2.G2)
= e(A, B)a1a2 Â· e(A, G2)a1r2 Â· e(G1, B)r1a2 Â· e(G1, G2)r1r2
we obtain from equations (3) and (4) :
Î±4 = (eAB)a1a2 Â· (Î±1)a1r2 Â· (Î±2)r1a2e(G1, G2)r1r2âˆ’a1g1r2âˆ’a2g2r1
which, using (2), gives Î±4 = Î±â€²
4 and shows that the card eventually outputs the
correct eAB = e(A, B).
The secrecy property follows from the fact that the terminal receives only
random, independently distributed points in the groups G1 and G2. Therefore, the
simulator S simply consists in running the terminal T with randomly generated
points. The simulatorâ€™s output and the terminalâ€™s view when interacting with C
are then identically distributed.
The correctness property is established as follows : we show that if the value
eAB computed by the card at step 3 is not equal to e(A, B), then the element
Î±â€²
4 computed by the card at step 5 has a nearly uniform distribution in GT ,
independent from the terminalâ€™s view. Then, the probability that Î±4 = Î±â€²
4 at step
5 will be roughly 1/p. Therefore, the card will output âŠ¥, except with negligible
probability.
We let U = a1.A+r1.G1 and V = a2.B+r2.G2. Moreover, we let a, b, u, v âˆˆZZp
be such that A = a.G1, B = b.G2, U = u.G1, V = v.G2, which gives :
u = a1 Â· a + r1
(6)
v = a2 Â· b + r2
(7)
The card checks that Î±1, Î±2, Î±3 âˆˆGT . Therefore, we must have eAB âˆˆGT , and
since e(G1, G2) is a generator of GT , we can let Î²1, Î²2, Î²3 âˆˆZZp be such that :
Î±1 = e(A, G2) Â· e(G1, G2)g1+Î²1
(8)
Î±2 = e(G1, B) Â· e(G1, G2)g2+Î²2
(9)
eAB = e(A, B) Â· e(G1, G2)Î²3
(10)
Therefore, the value eAB is correct iï¬€Î²3 = 0.

Secure Delegation of Elliptic-Curve Pairing
29
From the previous observation, we also have Î±â€²
4 âˆˆGT . Therefore, we can
assume that Î±4 âˆˆGT , since otherwise Î±â€²
4 Ì¸= Î±4 and the card outputs âŠ¥. Then
we can let Î²4, Î²â€²
4 âˆˆZZp be such that :
Î±4 = e(U, V ) Â· e(G1, G2)Î²4
(11)
Î±â€²
4 = e(U, V ) Â· e(G1, G2)Î²â€²
4
(12)
Therefore, the card outputs eAB iï¬€Î²4 = Î²â€²
4.
In the following, we assume that u Ì¸= 0 and v Ì¸= 0. Since (u, v) is uniformly
distributed in ZZp, this happens with probability (1 âˆ’1/p)2 â‰¥1 âˆ’2/p.
We show that if Î²3 Ì¸= 0, then Î²â€²
4 has a nearly uniform distribution in ZZp,
independent from the terminalâ€™s view, and therefore Î²4 = Î²â€²
4 happens with
negligible probability.
From equations (2), (8), (9), (10) and (12), we obtain :
Î²â€²
4 = a1a2Î²3 + a1r2Î²1 + a2r1Î²2
(13)
The terminalâ€™s view includes the points A + g1.G1, B + g2.G2, U and V and
the group elements Î±1, Î±2, Î±3 and Î±4. Therefore, the terminalâ€™s view is entirely
determined by (Î²1, Î²2, Î²3, Î²4, u, v, r), where r is the randomness used by the
terminal. Moreover, given (Î²1, Î²2, Î²3, Î²4, u, v, r), the element (a1, a2) is uniformly
distributed over ZZ2
p.
From equations (6), (7) and (13), we obtain :
Î²â€²
4 = a1a2(Î²3 âˆ’bÎ²1 âˆ’aÎ²2) + a1(vÎ²1) + a2(uÎ²2)
Lemma 1. Let p be a prime integer and let a, b, c, d âˆˆZZ such that (a, b, c) Ì¸=
(0, 0, 0). Then the number of solutions (x, y) âˆˆZZ2
p to the polynomial equation
a Â· xy + b Â· x + c Â· y + d = 0 mod p is at most 2p âˆ’1.
Proof. The proof is straightforward and is therefore omitted.
Since u, v Ì¸= 0, then Î²3 Ì¸= 0 implies (Î²3 âˆ’bÎ²1 âˆ’aÎ²2, vÎ²1, uÎ²2) Ì¸= (0, 0, 0). Then
using the previous lemma, for any Î³ âˆˆZZp, the probability over (a1, a2) âˆˆZZ2
p
that Î²â€²
4 = Î³ is such that :
Pr[Î²â€²
4 = Î³] â‰¤2p âˆ’1
p2
â‰¤2
p
Therefore, if Î²3 Ì¸= 0, the probability that Î²â€²
4 = Î²4 is at most 2/p.
Since we have that u = 0 or v = 0 with probability at most 2/p, we conclude
that if eAB Ì¸= e(A, B), then the card outputs âŠ¥, except with probability at
most 4/p.
âŠ“âŠ”
Note that the security of the protocol is not based on any computational
assumption; namely the protocol achieves unconditional security.

30
B. Chevallier-Mames et al.
4.3
Eï¬ƒciency
Our protocol requires a total of 4 scalar multiplications in G1 and G2, and a total
of 10 exponentiations in GT . Our protocol is actually a one-round protocol since
the four pairing queries can be performed in the same round.
5
Eï¬ƒcient Variants with Public A or B
In this section, we describe more eï¬ƒcient variants of our protocol, when one of
the points A and B or both are already publicly known.
For example, when decrypting with Boneh and Franklinâ€™s identity-based en-
cryption scheme [1], the point A is the userâ€™s private key, and the point B is
some part of the ciphertext. Therefore, the point B is already publicly known
and does not need to be protected. Similarly, when encrypting with Boneh and
Franklinâ€™s scheme, the point A is the recipientâ€™s identity, and the point B is the
trusted partyâ€™s public-key. Therefore, both points A and B are already publicly
known and donâ€™t need to be protected.
When the point B is publicly known, the deï¬nition of the secrecy property is
modiï¬ed by simply giving B to the simulator. When both points A and B are
publicly known, the secrecy property is not necessary anymore.
5.1
Secure Pairing Delegation with Public B
The protocol is the same as the protocol described in the previous section, except
that we can take g2 = 0 since the point B does not need to be protected.
1. The card generates a random g1 âˆˆZZp and queries the three following pairings
to the terminal :
Î±1 = e(A + g1.G1, G2),
Î±2 = e(G1, B),
Î±3 = e(A + g1.G1, B)
2. The card checks that Î±1, Î±2, Î±3 âˆˆGT , by checking that (Î±i)p = 1 for i =
1, 2, 3. Otherwise, the card outputs âŠ¥and halts.
3. The card computes a purported value for e(A, B):
eAB = (Î±2)âˆ’g1 Â· Î±3
(14)
4. The card generates four random values a1, r1, a2, r2 âˆˆZZp and queries the
pairing :
Î±4 = e(a1.A + r1.G1, a2.B + r2.G2)
5. The card computes :
Î±â€²
4 = (eAB)a1a2 Â· (Î±1)a1r2 Â· (Î±2)a2r1 Â· e(G1, G2)r1r2âˆ’a1g1r2
(15)
and checks that Î±â€²
4 = Î±4. In this case, the card outputs eAB; otherwise it
outputs âŠ¥.

Secure Delegation of Elliptic-Curve Pairing
31
The protocol is more eï¬ƒcient than the protocol of Section 4 since only 3 scalar
multiplications in G1 and G2, and 8 exponentiations in GT are required.
Theorem 2. The previous protocol with public B is a secure pairing delegation
protocol.
Proof. The proof is similar to the proof of theorem 1 and is therefore omitted.
5.2
Secure Pairing Delegation with Public A and B
The protocol is similar to the previous protocol except that we can also take
g1 = 0 since A does not need to be protected.
1. The card queries the three following pairings to the terminal :
Î±1 = e(A, G2),
Î±2 = e(G1, B),
Î±3 = e(A, B)
2. The card checks that Î±1, Î±2, Î±3 âˆˆGT , by checking that (Î±i)p = 1 for i =
1, 2, 3. Otherwise, the card outputs âŠ¥and halts.
3. The card computes a purported value for e(A, B):
eAB = Î±3
4. The card generates four random values a1, r1, a2, r2 âˆˆZZp and queries the
pairing :
Î±4 = e(a1.A + r1.G1, a2.B + r2.G2)
5. The card computes :
Î±â€²
4 = (eAB)a1a2 Â· (Î±1)a1r2 Â· (Î±2)a2r1 Â· e(G1, G2)r1r2
and checks that Î±â€²
4 = Î±4. In this case, the card outputs eAB; otherwise it
outputs âŠ¥.
The protocol is more eï¬ƒcient than the protocol of Section 4 since only 2 scalar
multiplications in G1 and G2, and 7 exponentiations in GT are required.
Theorem 3. The previous protocol with public A and B is a secure pairing
delegation protocol.
Proof. The proof is similar to the proof of theorem 1 and is therefore omitted.
6
Eï¬ƒcient Variant for Constant Point
In this section, we provide two eï¬ƒcient variants of the previous protocol, when
the point A can be considered as constant. In the ï¬rst protocol, both points
A and B are public, whereas in the second protocol, A is private whereas B is
public.

32
B. Chevallier-Mames et al.
Those two variants are particularly useful for Boneh and Franklinâ€™s identity-
based encryption scheme [1]. Namely, when encrypting with Boneh and Fran-
klinâ€™s IBE, the point B is the trusted server public-key, and the point A is the
receiverâ€™s identity-based public-key. Therefore, B can be considered as constant,
and both A and B are public. This corresponds to the ï¬rst protocol (with con-
stant B instead of constant A, but the protocol modiï¬cation is straightforward).
Moreover, when decrypting with Boneh and Franklinâ€™s IBE, the point A is
the userâ€™s private key, and the point B is some part of the ciphertext. Therefore,
A can be considered as constant and private, whereas B can be considered as
public. This corresponds to the second protocol.
6.1
Eï¬ƒcient Variant for Constant A and Public A, B
As in the previous protocol, the card and the terminal are given as input a
description of the groups G1, G2 and GT , and a description of the bilinear map
e : G1 Ã— G2 â†’GT . Moreover, the card receives e(A, Q) for some random Q âˆˆG2.
The point Q and e(A, Q) are kept private by the card. The card is given as input
the point B and must eventually output e(A, B).
1. The card generates a random r âˆˆZZp and queries the following pairings to
the terminal :
Î±1 = e(A, B),
Î±2 = e(A, r Â· B + Q)
2. The card checks that
(Î±1)r Â· e(A, Q) = Î±2
(16)
and that (Î±1)p = 1. In this case, it outputs Î±1, otherwise it outputs âŠ¥.
The protocol is more eï¬ƒcient than the protocol of section 5.2 since it requires
only one scalar multiplication and 2 exponentiations in GT .
Theorem 4. The previous protocol with constant public A and public B is a
secure pairing delegation protocol.
Proof. The completeness property is straightforward to establish. The protocolâ€™s
correctness is showed as follows :
Let b be such B = b Â· G2. Let q be such that Q = q Â· G2. Let
u = r Â· b + q
mod p
which gives rÂ·B +Q = uÂ·G2. We have that the terminalâ€™s view is entirely deter-
mined by (b, u) and by the randomness used by T . Since r and q are randomly
generated in Zp, we obtain that the distribution of r is independent from the
terminalâ€™s view. Let Î²1, Î²2 be such that :
Î±1 = e(A, B) Â· e(A, G2)Î²1
Î±2 = e(A, r Â· B + Q) Â· e(A, G2)Î²2

Secure Delegation of Elliptic-Curve Pairing
33
We have that Î²1, Î²2 are a function of the terminalâ€™s view, and that Î±1 = e(A, B)
if Î²1 = 0. Moreover, we obtain from (16) that the card outputs Î±1 iï¬€:
r Â· Î²1 = Î²2
mod p
(17)
Assume now that Î²1 Ì¸= 0. Then since Î²1 and Î²2 are a function of the terminalâ€™s
view, and the distribution of r is independent from the terminalâ€™s view, equality
(17) holds with probability at most 1/p. Therefore, for any cheating terminal,
the card outputs either âŠ¥or the correct e(A, B), except with probability at
most 1/p.
âŠ“âŠ”
6.2
Eï¬ƒcient Variant for Constant Private A and for Public B
As in the previous protocol, the card and the terminal are given as input a
description of the groups G1, G2 and GT , and a description of the bilinear map
e : G1 Ã— G2 â†’GT . Moreover, the card receives e(A, Q) for some random Q âˆˆG2.
The points A, Q and the value e(A, Q) are kept private by the card. The card
is given as input the point B and must eventually output e(A, B).
1. The card generates random x, y, z âˆˆZp and queries the following pairings
to the terminal :
Î±1 = e(x Â· A, B),
Î±2 = e(y Â· A, z Â· (B + Q))
2. The card computes :
eAB = (Î±1)xâˆ’1,
Î±3 = (Î±2)(yz)âˆ’1
3. The card checks that
eAB Â· e(A, Q) = Î±3
(18)
and that (eAB)p = 1. In this case, it outputs eAB; otherwise it outputs âŠ¥.
The protocol is more eï¬ƒcient than the protocol of section 5.1 as it requires only
3 scalar multiplications and 3 exponentiations in GT .
Theorem 5. The previous protocol with constant private A and public B is a
secure pairing delegation protocol.
Proof. The protocolâ€™s completeness is easily established. The protocolâ€™s secrecy
follows from the fact that the terminal receives only randomly distributed points.
The protocolâ€™s correctness is established as follows :
Let b be such B = b Â· G2. Let q be such that Q = q Â· G2. Let
u = z Â· (b + q)
mod p
which gives z Â· (B + Q) = u Â· G2. The terminalâ€™s view is then entirely determined
by (b, u, xÂ·A, yÂ·A) and by the randomness used by T . Since z and q are randomly
generated in Zp, we obtain that the distribution of z is independent from the
terminalâ€™s view.

34
B. Chevallier-Mames et al.
Let Î²1, Î²2 be such that :
Î±1 = e(x Â· A, B)1+Î²1
Î±2 = e(y Â· A, z Â· (B + Q))1+Î²2
We have that Î²1 and Î²2 are a function of the terminalâ€™s view. Moreover, we
obtain :
eAB = e(A, B)1+Î²1
Î±3 = e(A, B + Q)1+Î²2
Therefore, eAB = e(A, B) iï¬€Î²1 = 0. Moreover, we obtain from (18) that the
card outputs eAB if :
e(A, B + Q)Î²1 = e(A, B)Î²2
which gives :
b Â· Î²1 = (b + q) Â· Î²2
mod p
(19)
Then since b, Î²1, Î²2 are a function of the terminalâ€™s view, and the distribution
of q is uniform in Zp, independent of the terminalâ€™s view, we obtain that if
Î²1 Ì¸= 0, the equality (19) holds with probability at most 1/p. Therefore, for any
cheating terminal, the card outputs either âŠ¥or the correct e(A, B), except with
probability 1/p.
âŠ“âŠ”
7
Conclusion
In this paper we have described a simple protocol for secure delegation of elliptic-
curve pairing. Our protocol allows a computationally limited device (for example
a smart-card) to delegate the computation of the pairing e(A, B) to a more
powerful device (for example a PC), in such a way that 1) the powerful device
learns nothing about the points A and B, and 2) the limited device is able
to detect when the powerful device is cheating. We have also described more
eï¬ƒcient variants of our protocol when one of the points or both are already
publicly known, and when one of the points can be considered as constant.
We observe that our protocols achieve unconditional security. An interest-
ing research direction would be to further optimize the protocols by trading-oï¬€
unconditional security against computational security. A second interesting ques-
tion consists in bounding the number of protocol rounds (passes) necessary to
delegate pairing in diverse contexts.
References
1. Boneh, D., Franklin, M.: Identity based encryption from the Weil pairing. SIAM J. of
Computing 32(3), 586â€“615 (2003); Extended abstract In: Kilian, J. (ed.) CRYPTO
2001. LNCS, vol. 2139, pp. 213â€“229. Springer, Heidelberg (2001)
2. Boneh, D., Shacham, H., Lynn, B.: Short signatures from the Weil pairing. In: Boyd,
C. (ed.) ASIACRYPT 2001. LNCS, vol. 2248, pp. 514â€“532. Springer, Heidelberg
(2001)

Secure Delegation of Elliptic-Curve Pairing
35
3. Boneh, D., Boyen, X.: Short Signatures Without Random Oracles. In: Cachin, C.,
Camenisch, J.L. (eds.) EUROCRYPT 2004. LNCS, vol. 3027, pp. 56â€“73. Springer,
Heidelberg (2004)
4. Canetti, R.: Security and Composition of Multiparty Cryptographic Protocols. Jour-
nal of Cryptology 13, 143â€“202 (2000)
5. Goldwasser, S., Micali, S.: Probabilistic Encryption. JCSS 28(2), 270â€“299 (1984);
Previous version in STOC 2002 (2002)
6. Joux, A.: A one round protocol for tripartite Diï¬ƒe-Hellman. In: Bosma, W. (ed.)
ANTS 2000. LNCS, vol. 1838, pp. 385â€“394. Springer, Heidelberg (2000)
7. Menezes, A.: Elliptic Curve Public Key Cryptosystems. Kluwer Academic Publish-
ers, Dordrecht (1993)
8. Scott, M., Barreto, P.: Compressed Pairings. In: Franklin, M. (ed.) CRYPTO 2004.
LNCS, vol. 3152, pp. 140â€“156. Springer, Heidelberg (2004)

Side-Channel Leakage across Borders
JÂ¨orn-Marc Schmidt, Thomas Plos, Mario Kirschbaum, Michael Hutter,
Marcel Medwed, and Christoph Herbst
Institute for Applied Information Processing and Communications (IAIK)
Graz University of Technology, Inï¬€eldgasse 16a, 8010 Graz, Austria
{joern-marc.schmidt,thomas.plos,mario.kirschbaum,michael.hutter,
marcel.medwed,christoph.herbst}@iaik.tugraz.at
Abstract. More and more embedded devices store sensitive informa-
tion that is protected by means of cryptography. The conï¬dentiality of
this data is threatened by information leakage via side channels like the
power consumption or the electromagnetic radiation. In this paper, we
show that the side-channel leakage in the power consumption is not lim-
ited to the power-supply lines and that any input/output (I/O) pin can
comprise secret information. The amount of leakage depends on the de-
sign and on the state of the I/O pin. All devices that we examined leaked
secret information through their I/O pins. This implies that any I/O pin
that is accessible for an adversary could be a security hole. Moreover, we
demonstrate that the leakage is neither prevented by transmitter/receiver
circuits as they are used in serial interfaces, nor by a galvanic isolation of
a chip and its output signals via optocouplers. An adversary that is able
to manipulate, for example, the pins of a PCâ€™s I/O port, can attack any
device that is connected to this port without being detected from outside.
Keywords: Power Analysis, I/O Pin, Microcontroller, Optocoupler,
Serial Interface.
1
Introduction
Security-related devices are an integral part of our everyday life. Typically, it is
rather diï¬ƒcult to verify whether a device reaches a certain security level or not.
Insuï¬ƒcient security protection remains often unnoticed until a successful attack
is found. The security level is basically determined by two factors: the choice of
the cryptographic algorithm (including the protocol), and the way the algorithm
is implemented.
Even if a cryptographic algorithm is mathematically secure, its implementa-
tion in hardware might not be. About one decade ago, Kocher et al. published a
ground-breaking paper about diï¬€erential power analysis (DPA) attacks [1]. They
showed that analyzing the power consumption of a cryptographic device can re-
veal secret information that is stored in it, e.g. an encryption key. Since that
time, many research groups have gradually improved power-analysis attacks and
performed them on a variety of devices, like smart cards [2], ï¬eld-programmable
gate arrays (FPGAs) [3], and radio-frequency identiï¬cation (RFID) devices [4].
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 36â€“48, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Side-Channel Leakage across Borders
37
Power-analysis attacks are a very powerful technique that even works in pres-
ence of strong noise. In a ï¬rst step, an adversary generates key hypotheses, which
contain all possible values for a small part of the secret key (e.g. one byte). Inter-
mediate values of the attacked algorithm are calculated from the key hypotheses
and a set of diï¬€erent input values. Based on the intermediate values, the adver-
sary estimates the power consumption of the device by means of an appropriate
power model. During the second step, the power consumption of the device is
measured and recorded (leading to the so-called power traces) while it computes
the intermediate values. In the third and last step, the power-consumption esti-
mations for each key hypothesis are compared with the measured power traces
by means of statistical methods. If the adversary uses an appropriate power
model, the analysis leads to the correct key. The adversary has successfully re-
vealed a part of the secret key. This procedure is repeated for the remaining
parts. Experience shows that in case of unprotected cryptographic devices, some
hundred up to a few thousand input values and corresponding power traces are
suï¬ƒcient to distinctly reveal the whole secret key [5].
Most of the published side-channel attacks measure the power consumption of
the target device via a resistor in one of the power-supply lines. Other methods
measure, for example, the electromagnetic radiation during the computation of
the cryptographic algorithm [6,7]. In order to prevent the leakage of sensitive in-
formation via the power-supply lines, countermeasures are integrated into cryp-
tographic devices. Various countermeasure approaches have been presented in
the past, for example, by using special logic styles [8,9,10], by inserting ï¬lters [11],
or by decoupling the power consumption with switched capacitors [12,13].
It was ï¬rst mentioned by Shamir [12] that side-channel information can also
leak through the input/output (I/O) pins of a device. Oren et al. [14] presented
practical results about analyzing the power consumption of a PC via its univer-
sal serial bus (USB) port. In [15], Plos pointed out the problem of side-channel
leakage via I/O pins of RFID tags. However, there is no work so far that inves-
tigates the eï¬€ectiveness of side-channel attacks via I/O pins in detail and that
compares them with the results from classical attacks in the power-supply lines.
In this paper, we discuss the possibilities to measure the voltage variations at
I/O pins. We show that power-analysis attacks are feasible in the same way by
using the I/O pins. This presents an alternative attack method whenever a direct
measurement in the power-supply lines is not possible. We evaluated the voltage
variations at the I/O pins of ï¬ve devices for diï¬€erent pin-conï¬gurations. For
each device, we found at least one conï¬guration that leaked information at the
I/O pins. The standard microcontrollers, for example, leaked information in any
conï¬guration. In addition, we measured a device with capacitors as ï¬lters in the
power-supply lines, which reduced the leakage in the ground line, but not at the
I/O pins. This demonstrates that protecting only the power-supply lines is not
suï¬ƒcient and that additional precautions should be taken to prevent I/O pin
leakage. For embedded systems with more than one device integrated onto a
board, measuring the voltage variations at an I/O pin can be an improvement
compared to measuring the power consumption of the whole system. We show

38
J.-M. Schmidt et al.
that information leakage also occurs if the I/O pin is not directly measured, but
after passing a signal ampliï¬er. We demonstrate this by successfully performing
a DPA attack on a serial interface that uses a receiver/transmitter module.
Hence, an adversary can perform attacks without being noticed by the owner of
the device, e.g. by manipulating the serial interface of a PC to which the device
is connected to. Moreover, we demonstrate that even a galvanic isolation via
optocouplers does not totally suppress the information leaking at the I/O pin.
The remaining paper is organized as follows. After giving a brief introduction
into I/O pins in Section 2, we present our measurement setup in Section 3. The
results of the measurements are given in Section 4. Afterwards, Section 5 dis-
cusses some practical scenarios that arise from the presented attacks, including
(among others) a DPA measurement on the clock signal as well as DPA measure-
ments of an I/O pin that is separated by an optocoupler. Finally, conclusions
are drawn in Section 6.
2
I/O Pins
I/O pins are the interface between an integrated circuit and the outside world.
They are used to transfer data and control signals. Depending on their design,
I/O pins can act in one direction only or they can support both directions: input
and output.
Especially input pins require a protection mechanism to prevent damage of
the inner circuits caused by an overvoltage. This mechanism is called electro-
static discharge (ESD) protection and typically consists of two diodes that drain
oï¬€the overvoltage to the positive supply voltage (VDD) or to ground (GND).
In addition, a resistor is inserted to limit the current ï¬‚owing over the diodes.
Figure 1 shows an I/O pin that comprises such an ESD-protection circuit.
In contrast to input pins, output pins have a low-resistance connection to
VDD or GND. Thus, a dedicated ESD-protection is not necessary for them.
Since output pins have to drive logic signals oï¬€-chip, a circuit that is able to
provide enough current is required. These circuits are often implemented as
parallel transistors of increasing width and length [16].
Protection
Diodes
Pull Up
Pad
Control
Data
Input
Fig. 1. Schematic of a standard I/O pin.
The control signal can switch the pin to
tri-state.
Pad
PU
KEEP
PD
SMT
PU
PD
Protection
Diodes
Input
2-16mA
slew rate
driving
strength
D
Output Buffer
Input Buffer
Fig. 2. Schematic of a programmable out-
put and a programmable input buï¬€er of
the ASIC prototype chip

Side-Channel Leakage across Borders
39
Pins that can either be conï¬gured as input or as output, provide a so-called tri-
state. This state allows to deï¬ne the value of the pin externally, i.e. the pin acts
as input. Thereby, the output transistors are disabled and the pin is in a high-
impedance state. Such an I/O pin is depicted in Figure 1. The schematic features
also a pull-up resistor, which holds the input pin in a high state whenever it is
not driven externally. This prevents the pin from being in a random or undeï¬ned
state. Other constructions provide pull-down resistors to put a pin into a low
state if no external signal is present.
Figure 2 shows a programmable output and a programmable input buï¬€er of
the application-speciï¬c integrated circuit (ASIC) prototype chip that we used
for some of our measurements. The ASIC input buï¬€er contains ESD protec-
tion structures similar to the one described above. The input buï¬€er can be
programmed to work as pull up, as pull down, or as keeper1. Additionally, the
input buï¬€er can be programmed to work as a Schmitt trigger to switch the input
value only if a clearly diï¬€erent signal is applied. Also the output buï¬€er can be
programmed to some degree. The driving strength can vary between 2 mA and
16 mA, and the slew rate of the output buï¬€er can be either set to slow or to
fast. On our prototype chip, the input buï¬€ers are programmed as pull down with
Schmitt-trigger functionality disabled. The output buï¬€ers are conï¬gured to have
a driving strength of 2 mA with the slew rate set to fast.
3
Measurement Setup
For a general characterization of the I/O pin leakage of the devices, we compare
the leakage in the GND supply line to the information that leaves the device
via the I/O pins in diï¬€erent conï¬gurations. We test ï¬ve devices, an Atmel AT-
Mega163 8-bit microcontroller on a smart card, an 8-bit 8051 microcontroller
AT89S8253 from Atmel, a 32-bit ARM7 microcontroller LPC2148 from NXP,
a Virtex-II Pro XC2VP7 FPGA, and an ASIC chip. Each of them contains
an implementation of the Advanced Encryption Standard (AES) that uses a
key length of 128 bits. None of these implementations include side-channel
countermeasures.
For each measurement, we perform a Diï¬€erential Power Analysis (DPA) at-
tack. The goal of our DPA attacks on the AES implementations is to reveal the
secret key. During the last years, several approaches for DPA attacks on AES
implementations have been proposed ([17,18,19]). Our DPA attacks are based
on the Hamming distance of two intermediate byte values. The target of the
attack is the result of the SubBytes transformation in the ï¬rst round of the AES
algorithm. We use the Pearson correlation coeï¬ƒcient for matching our power
estimations with the measurements.
Our measurement setup mainly consists of a PC, an oscilloscope, measurement
probes, and the device under test. A Matlab script running on the PC controls
the whole measurement. It sends the plaintexts to the device via a serial interface
1 The input value does not change when the signal is disconnected from the pin if the
buï¬€er is programmed as keeper.

40
J.-M. Schmidt et al.
and reads the power traces from the oscilloscope that measures the voltage on
the I/O pin and the voltage drop across a resistor in the ground line of the
device.
A classical measurement in the GND line is performed in parallel to the mea-
surement at the I/O pin. The power measurement delivers a basis for comparison
with the results from I/O pin measurements. For each device, the pin conï¬gu-
rations output high, output low, and input (with 10 kÎ© pull-down resistor) are
measured. Each measurement uses the same ï¬xed AES key and the same input
plaintexts.
Since no side-channel countermeasures are included in our implementations, a
DPA attack was possible with some hundred to a few thousand traces. Our mea-
surements show that the same attacks are possible when measuring the I/O pins
instead of the power-supply lines.
4
Practical Results
This section shows the practical outcomes of our measurements. We describe
the special properties of all ï¬ve devices, present the analysis results, and discuss
them.
4.1
Atmel ATMega163 8-Bit Microcontroller on a Smart Card
In the ï¬rst experiment, we measured a programmable smart card with an in-
tegrated 8-bit microcontroller. The microcontroller is an ATMega163 from At-
mel, which has a reduced instruction set (RISC) architecture. The ATMega163
comprises various features, including internal EEPROM, a serial interface, a
Fig. 3. Measurement setup for the Atmel
ATMega163 smart card. One probe mea-
sures the trigger signal, the other probe
measures the voltage variation of a ï¬x pro-
grammed I/O pin.
Fig. 4. Comparison between the power
consumption measured in the GND line
and the voltage variations at an I/O pin
of the AT89S8253. The I/O pin was set to
logic low for the measurement.

Side-Channel Leakage across Borders
41
serial peripheral interface, and an analog comparator. A self-made smart-card
reader, which is depicted in Figure 3, was used to establish the communication
between the PC and the smart card. Since the smart card only provides an
8-pin connector, the number of pins of the microcontroller that are accessible is
strongly limited. However, there is one unused I/O pin that we measured in our
experiments.
We conducted four DPA attacks on the smart card and compared them with
respect to the maximum achievable correlation. The ï¬rst attack measured the
power consumption of the smart card in the GND line of the power supply. The
remaining three attacks targeted the voltage variations at the unused I/O pin
with diï¬€erent conï¬gurations: pin deï¬ned as output and logic high, pin deï¬ned
as output and logic low, and pin deï¬ned as input (tri-state).
All attacks were successful. The reference measurement in the GND sup-
ply line led to a maximum correlation of 0.57. The voltage variations at the
I/O pin deï¬ned as output delivered similar values: 0.64 for logic high and 0.56
for logic low. Deï¬ning the I/O pin as input reduced the maximum correlation to
about 0.11.
4.2
Virtex-II Pro FPGA XC2VP7
For testing the leakage at an I/O pin of an FPGA, we targeted a Xilinx XC2VP7
of a SASEBO board2. Our AES implementation for the FPGA includes one
extra pin for the measurements, which varied between input and output. A
measurement in the GND line resulted in a correlation of 0.06, setting the output
pin to low reduced the correlation to 0.03. A correlation of 0.01 was achieved for
the pin conï¬gured as input. For a pin that was set to high, no correlation was
measured by using up to 300 000 power traces.
In order to characterize further details of the leakage, we added area constrains
to the implementation that forced the place and route utilities to concentrate on
one half of the chip and leave the second half unprogrammed. In addition, two
wires were routed through the device to an output pin, one straight through the
programmed logic, and one through the empty part. The measurements revealed
no diï¬€erence between the information leakage of the two pins.
4.3
ARM 32-Bit RISC Processor
The LPC2148 from NXP is an ARM7TDMI-S based microcontroller with a
32-bit architecture. Our device under test features a wide range of peripherals
like USB, analog-to-digital converters, and several bus standards. None of those
peripherals was turned oï¬€during the measurements. Thus, the noise level was
comparable to an unprotected real-world application.
Our development board gave access to the I/O pins of the microcontroller.
The measurement at the I/O pins was threefold: output pin set to one, output
2 The control FPGA of the SASEBO board was programmed to forward the serial
interface.

42
J.-M. Schmidt et al.
pin set to zero, and input pin pulled down to GND. For the correct AES key,
the power measurements in the GND line achieved a correlation of 0.56. The
traces acquired at the high output pin still yielded a correlation of 0.44. The
voltages at the low output pin and at the input pin correlated with 0.15 and
0.12, respectively.
4.4
Atmel 8051 Microcontroller
The data-dependent I/O leakage of an 8051 8-bit microcontroller was investi-
gated on an AT89S8253 from Atmel. The microcontroller is shipped with 32
programmable I/O pins that can be accessed by four 8-bit bi-directional ports.
One port provides eight open-drain pins, which can be conï¬gured to logic low
(actively sinking current) or to a high impedance state. The pins of the three re-
maining ports can be conï¬gured as sink or source input/output that are equipped
with internal pull-up resistors.
We performed four attacks. First, we measured the power consumption in
the GND line of the prototyping board and obtained a correlation of 0.59 for
the correct key hypothesis. Next, we performed attacks on 20 diï¬€erent I/O pins,
which where conï¬gured to logic low. All attacks were successful and led to nearly
the same correlation of 0.56. This demonstrates that the leakage does not depend
on the measured I/O pin (the standard deviation of the correlation was 0.01). A
comparison between two power traces, one measured at the GND line and one
at the I/O pin conï¬gured to output logic low is given in Figure 4. After that
experiment, we performed an attack on a pin that was conï¬gured to logic high.
The attack was successful with a correlation of 0.30. Our last attack on this
device targeted the open-drain port, which was conï¬gured as a high-impedance
output. The attack was also successful and led to a correlation of 0.22.
4.5
180 nm CMOS ASIC Prototype Chip
The ASIC prototype chip for testing the leakage of I/O pins was produced in
a 180 nm CMOS process technology from UMC [20] and uses the standard cell
library from Faraday [21]. The chip contains an AES crypto module with a size
of 0.1 mm2, which equals approximately 10 770 GEs.
First, a DPA attack based on the power consumption measured in the GND
line of the prototype chip was performed. The result of this attack served as
a reference for the other DPA attacks that targeted the voltage variations at
I/O pins. The other DPA attacks were performed on an output pin with logic
level low, on an output pin with logic level high, and on an input pin with logic
level low (programmed as pull-down, see Section 2).
All attacks on the AES crypto module on the ASIC prototype chip were
successful. The reference attack based on the power measurement in the GND
line led to a maximum correlation of 0.0119. The other DPA attacks led to quite
similar results: 0.0124 for the low output pin, 0.011 for the high output pin, and
0.0121 for the low input pin.

Side-Channel Leakage across Borders
43
Table 1. Summary of the Results
Device
Corr.
Correlation (Percentage of GND)
in GND Output High Output Low
Input
ATMega163 (Smart Card) 0.57
0.64 (112%)
0.56 (98%)
0.11 (19%)
LPC2148 (ARM7)
0.56
0.44 (79%)
0.15 (27%)
0.12 (21%)
AT89S8253 (8051)
0.59
0.30 (54%)
0.56 (95%)
0.22 (37%)
XC2VP7 (FPGA)
0.06
0.03 (50%)
0.01 (17%)
ASIC Prototype (180 nm)
0.0119
0.011(92%)
0.0124(104%) 0.0121(101%)
4.6
Summary of the Practical Results
Table 1 summarizes the results of our DPA attacks on the ï¬ve diï¬€erent devices.
It can clearly be seen that DPA attacks based on voltage variations at I/O pins
can successfully be mounted on many devices even if the VDD line or GND line
are not directly accessible. Furthermore, regardless of the conï¬guration of the
I/O pin, a successful DPA attack is possible. The fact that conventional DPA
attacks can easily be performed by measuring the voltage variations at I/O pins
opens new possibilities for adversaries to attack cryptographic devices, even if
the accessibility of the target is limited. Some practical scenarios demonstrating
new attack variants are discussed in the following section.
5
Practical Scenarios
In order to transfer our results into a more practical context, we performed
additional experiments, which demonstrate the relevance of our research. Since
the AT89S8253 shows the strongest information leakage of all tested devices,
we focus on this device in the following experiments. Considering the results
presented in the previous section, it is very likely that the following scenarios
work with the other devices alike.
5.1
Signal Filter
Throughout this paper, our experiments assumed that the power-supply lines
of the device under test are not accessible for an adversary and hence a direct
measurement of the consumed power is not possible. This can be the case, for
example, if a ï¬lter suppresses the leakage in the power supply lines. We used a
cascade of capacitors as ï¬lter to reduce the data-dependent signal. Although our
ï¬lter signiï¬cantly reduced the data dependency in the GND line, we were not
able to eliminate it totally. However, our approach did not inï¬‚uence the leakage
in the I/O pins. The experiment demonstrates that the information leakage via
the I/O pins does not depend on the information leakage in the power-supply
lines.

44
J.-M. Schmidt et al.
5.2
Clock Supply
A special case of an I/O pin is the clock interface. While capacitors can ï¬lter the
power-supply lines to prevent information leakage, this approach is not applicable
in the same simple way to the clock supply. We tried two diï¬€erent scenarios. First,
an on-board crystal oscillator generated the clock signal. For the measurement,
we concentrated on the positive part of the signal and cut the negative part oï¬€to
get a better measurement resolution. Our attack was successful with a correlation
of 0.4, which is about two third of the correlation in the GND line, as depicted in
Figure 5 and Figure 6. Second, an external signal generator provided the signal.
We achieved a correlation of 0.5. Hence, whenever the clock signal is accessible,
it is a potential threat to the security of the device.
Fig. 5. Correlation plot of AT89S8253
measured with a passive probe in the GND
line of the power supply. The measurement
serves as reference.
Fig. 6. Correlation plot of AT89S8253
measured with a passive probe at the
clock interface, supplied with an on-board
crystal oscillator
5.3
Serial Interface
A very common way to transfer data between devices is a serial port. The results
from the previous section showed that I/O pins leak information. This includes
the pins of the serial interface. However, in an embedded system, the device is
often supplied by a lower voltage than the one required for the serial connection
(+/- 12 V). Hence, a signal ampliï¬er converts the logical signals from the de-
vice to the voltage range required for the serial connection. An adversary may
only have access to those signals, not to I/O pins directly. Fortunately for an
adversary, the information is not suppressed by the ampliï¬er. We measured the
receive (RX) and transmission (TX) line of a signal converter (MAX232) directly
on the board and achieved a correlation of 0.1 in the TX line and in the RX
line, compared to a correlation of 0.6 for a direct measurement in the GND line.
A correlation plot for the TX line is given in Figure 7. Using a 1 m cable that
is connected to a computer and measuring at the input port of the PC reduced
the correlation to 0.05. Hence, an adversary that is able to modify the serial
port of a computer can successfully attack devices without the device ownersâ€™
knowledge who connects the device to a PC.

Side-Channel Leakage across Borders
45
Fig. 7. Correlation plot of AT89S8253
measured with a passive probe at the se-
rial interface on the transmission line after
the signal converter (MAX232) directly on
the test board.
Test
Board
PC
Digital-
storage
Oscilloscope
Oscilloscope 
Control
Trigger Signal
ÈC
Output Port
Probe
10V
10V
Probe
Serial Interface
Shielded Area
Fig. 8. Measurement setup with galvani-
cally isolated circuits. The measurement
signal, the trigger, as well as the transmis-
sion line of the serial interface are trans-
ferred via optocouplers.
5.4
Device and Measurement Circuit Separated via Optocoupler
A common idea when talking about information leakage via power lines is to
separate the circuit in which the computation takes place from the outside world.
In order to transfer information between the device and the outside world, it
is possible to use optocouplers. These small devices consist of a light-emitting
diode and a phototransistor. Thus, they allow data transfer without an electric
connection. We performed two diï¬€erent measurements. In the ï¬rst one, only the
trigger signal and the signal of the I/O pin were separated via optocouplers. In
the second experiment, the two circuits were galvanically isolated.
In the setup for the ï¬rst measurement, one optocoupler provides the trigger
signal, another one was connected to a high output pin. The inï¬‚uence of the pin
on the second circuit was measured via an oscilloscope. We could successfully
perform a DPA and achieved a correlation of 0.02. The corresponding correlation
plot is given in Figure 9.
However, this measurement setup still has a common ground connection since
the PC is connected to the oscilloscope and to the device. Thus, the measurement
circuit and the target circuit are not galvanically isolated. In order to achieve
a galvanic isolation, the device was powered by a battery and the transmission
line of the serial connection was established via an optocoupler3 in the setup
for our second measurement. The whole measurement circuit was put into a
shielding box to suppress possible coupling between the measurement circuit
and the target circuit. Figure 8 sketches the measurement setup. Even with
the galvanic isolation, we achieved a correlation of 0.01. Figure 10 shows the
corresponding plot.
3 The setup did not use the RX line of the serial interface.

46
J.-M. Schmidt et al.
Fig. 9. Correlation plot of AT89S8253
measured with a passive probe at the sep-
arated circuit with common ground
Fig. 10. Correlation plot of AT89S8253
measured with a passive probe at the gal-
vanically isolated circuit
5.5
Summery of Practical Scenarios
Table 2 summarizes the results of the practical scenarios provided in this section.
In addition to the achieved correlation, the table provides the estimated number
of traces required to succeed with an attack. The numbers were calculated with
the rule of thumb from [5]: n = 3+8
z2
1âˆ’Î±
ln2 1+Ï
1âˆ’Ï , with n the number of required traces,
Ï the correlation coeï¬ƒcient for the correct hypothesis, and Î± the conï¬dence. For
Î± = 0.0001 we get a value z0.9999 = 3.719.
Table 2. Summary of the Results of the Practical Scenarios
Scenario
Correlation
Required Samples
Reference in GND
0.6
61
Clock with Signal Generator
0.5
95
Clock with Crystal Oscillator
0.4
158
Serial Interface (RX and TX)
0.1
2 751
Serial Interface at a Distance of 1 m
0.05
11 050
Optocouplers with Common Ground
0.02
69 140
Galvanic Isolation via Optocouplers
0.01
276 604
6
Conclusion
In this paper we demonstrate that side-channel information not only leaks via
the power supply lines but also via I/O pins. We performed DPA attacks on ï¬ve
diï¬€erent devices that have integrated a hardware or a software implementation
of the AES-128. Our investigations show that DPA attacks can be mounted
even if the access to the examined device is severely limited. For example, if the
power supply lines are not at an adversaryâ€™s disposal, or if the adversary wants
to attack a device that consists of several chips but has only access to the chip of
interest by some sort of interface. Moreover, our results make clear that even in
the presence of ï¬ltering techniques, signal converters, or optocouplers, successful
DPA attacks are possible.

Side-Channel Leakage across Borders
47
Acknowledgement
The work described in this paper has been supported through Austrian Gov-
ernment funded project PowerTrust established under the Trust in IT Systems
program FIT-IT.
The authors want to thank Akashi Satoh (National Institute of Advanced
Industrial Science and Technology, Japan) and designers of SASEBO for the
board we used for the FPGA measurements.
The information in this document reï¬‚ects only the authorsâ€™ views, is provided
as is and no guarantee or warranty is given that the information is ï¬t for any
particular purpose. The user thereof uses the information at its sole risk and
liability.
References
1. Kocher, P.C., Jaï¬€e, J., Jun, B.: Diï¬€erential Power Analysis. In: Wiener, M. (ed.)
CRYPTO 1999. LNCS, vol. 1666, pp. 388â€“397. Springer, Heidelberg (1999)
2. Messerges, T.S., Dabbish, E.A., Sloan, R.H.: Investigations of Power Analysis At-
tacks on Smartcards. In: USENIX Workshop on Smartcard Technology (Smartcard
1999), May 1999, pp. 151â€“162 (1999)
3. Â¨Ors, S.B., Oswald, E., Preneel, B.: Power-Analysis Attacks on FPGAs â€“ First
Experimental Results. In: Walter, C.D., KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2003.
LNCS, vol. 2779, pp. 35â€“50. Springer, Heidelberg (2003)
4. Hutter, M., Mangard, S., Feldhofer, M.: Power and EM Attacks on Passive 13.56
MHz RFID Devices. In: Paillier, P., Verbauwhede, I. (eds.) CHES 2007. LNCS,
vol. 4727, pp. 320â€“333. Springer, Heidelberg (2007)
5. Mangard, S., Oswald, E., Popp, T.: Power Analysis Attacks â€“ Revealing the Secrets
of Smart Cards. Springer, Heidelberg (2007), ISBN 978-0-387-30857-9
6. Agrawal, D., Archambeault, B., Rao, J.R., Rohatgi, P.: The EM Side-channel(s).
In: Kaliski Jr., B.S., KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp.
29â€“45. Springer, Heidelberg (2003)
7. Gandolï¬, K., Mourtel, C., Olivier, F.: Electromagnetic Analysis: Concrete Results.
In: KoÂ¸c, CÂ¸.K., Naccache, D., Paar, C. (eds.) CHES 2001. LNCS, vol. 2162, pp.
251â€“261. Springer, Heidelberg (2001)
8. Tiri, K., Akmal, M., Verbauwhede, I.: A Dynamic and Diï¬€erential CMOS Logic
with Signal Independent Power Consumption to Withstand Diï¬€erential Power
Analysis on Smart Cards. In: Proceedings of 28th European Solid-State Circuits
Conference - ESSCIRC 2002, Florence, Italy, September 24-26, pp. 403â€“406. IEEE,
Los Alamitos (2002)
9. Tiri, K., Verbauwhede, I.: A Logic Level Design Methodology for a Secure DPA
Resistant ASIC or FPGA Implementation. In: 2004 Design, Automation and Test
in Europe Conference and Exposition (DATE 2004), Paris, France, February 16-20,
vol. 1, pp. 246â€“251. IEEE Computer Society, Los Alamitos (2004)
10. Popp, T., Mangard, S.: Masked Dual-Rail Pre-Charge Logic: DPA-Resistance with-
out Routing Constraints. In: Rao, J.R., Sunar, B. (eds.) CHES 2005. LNCS,
vol. 3659, pp. 172â€“186. Springer, Heidelberg (2005)
11. Coron, J.S., Kocher, P.C., Naccache, D.: Statistics and Secret Leakage. In: Frankel,
Y. (ed.) FC 2000. LNCS, vol. 1962, pp. 157â€“173. Springer, Heidelberg (2001)

48
J.-M. Schmidt et al.
12. Shamir, A.: Protecting Smart Cards from Passive Power Analysis with Detached
Power Supplies. In: Paar, C., KoÂ¸c, CÂ¸.K. (eds.) CHES 2000. LNCS, vol. 1965, pp.
71â€“77. Springer, Heidelberg (2000)
13. Corsonello, P., Perri, S., Margala, M.: A New Charge-Pump Based Countermea-
sure Against Diï¬€erential Power Analysis. In: Proceedings of the 6th International
Conference on ASIC (ASICON 2005), vol. 1, pp. 66â€“69. IEEE, Los Alamitos (2005)
14. Oren, Y., Shamir, A.: How not to protect pcs from power analysis. Rump Session,
Crypto 2006 (August 2006),
http://iss.oy.ne.ro/HowNotToProtectPCsFromPowerAnalysis.pdf
15. Plos, T.: Evaluation of the Detached Power Supply as Side-Channel Analysis Coun-
termeasure for Passive UHF RFID Tags. In: Fischlin, M. (ed.) RSA Conference
2009. LNCS, vol. 5473, pp. 444â€“458. Springer, Heidelberg (2009)
16. Weste, N.H.E., Eshraghian, K.: Principles of CMOS VLSI Design - A Systems Per-
spective, 2nd edn. VLSI Systems Series. Addison-Wesley, Reading (1993) (reprinted
with corrections October 1994), ISBN 0-201-53376-6
17. Brier, E., Clavier, C., Olivier, F.: Correlation Power Analysis with a Leakage Model.
In: Joye, M., Quisquater, J.-J. (eds.) CHES 2004. LNCS, vol. 3156, pp. 16â€“29.
Springer, Heidelberg (2004)
18. Â¨Ors, S.B., GÂ¨urkaynak, F.K., Oswald, E., Preneel, B.: Power-Analysis Attack on
an ASIC AES Implementation. In: Proceedings of the International Conference on
Information Technology: Coding and Computing (ITCC 2004), Las Vegas, Nevada,
USA, April 5-7, vol. 2, pp. 546â€“552. IEEE Computer Society, Los Alamitos (2004)
19. Schramm, K., Leander, G., Felke, P., Paar, C.: A Collision-Attack on AES: Com-
bining Side Channel- and Diï¬€erential-Attack. In: Joye, M., Quisquater, J.-J. (eds.)
CHES 2004. LNCS, vol. 3156, pp. 163â€“175. Springer, Heidelberg (2004)
20. United Microelectronics Corporation: The United Microelectronics Corporation
Website, http://www.umc.com/
21. Faraday Technology Corporation: Faraday FSA0A C 0.18 Âµm ASIC Standard Cell
Library (2004), http://www.faraday-tech.com.
22. Mangard, S., Aigner, M., Dominikus, S.: A Highly Regular and Scalable AES
Hardware Architecture. IEEE Transactions on Computers 52(4), 483â€“491 (2003)
23. Wolkerstorfer, J., Oswald, E., Lamberger, M.: An ASIC implementation of the AES
SBoxes. In: Preneel, B. (ed.) CT-RSA 2002. LNCS, vol. 2271, pp. 67â€“78. Springer,
Heidelberg (2002)

Designing a Side Channel Resistant Random
Number Generator
Suresh N. Chari1, Vincenzo V. Diluoï¬€o2, Paul A. Karger1, Elaine R. Palmer1,
Tal Rabin1, Josyula R. Rao1, Pankaj Rohotgi1,â‹†, Helmut Scherzer3,â‹†â‹†,
Michael Steiner1, and David C. Toll1
1 IBM Corporation, Thomas J. Watson Research Center
P.O. Box 704, Yorktown Heights, NY 10598, USA
{schari,diluoffo,erpalmer,talr,jrrao,msteiner,toll,pkarger}@us.ibm.com,
pankaj.rohatgi@cryptography.com
2 IBM Corporation, Systems and Technology Group
150 Kettletown Rd., Southbury, CT 06488, USA
3 IBM Deutschland GmbH, Secure Systems and Smart Cards
SchÂ¨onaicher Str. 220, D-71032 BÂ¨oblingen, Germany
helmut.scherzer@gi-de.com
Abstract. This paper describes the design of the random number gen-
erator (RNG) in the Caernarvon high assurance smart card operating
system. Since it is used in the generation of cryptographic keys and
other sensitive materials, the RNG has a number of stringent security
requirements that the random bits must be of good quality i.e. the bits
must not be predictable or biased. To this end, a number of standards
such as the German AIS 31 mandate that true random bits be continu-
ously tested before use in sensitive applications such as key generation.
A key issue in implementing this standard is that such testing before use
in key generation greatly increases the attack surface for side-channel
attacks. For example, template attacks which can extract information
about the random bits from even a single run provided we use the same
bits at many diï¬€erent points in the computation. Because of these poten-
tial risks, the Caernarvon operating system uses pseudo random number
generators which are initially seeded by externally generated high quality
random bits, and then perturbed by bits from the true random number
generator. We describe a PRNG design which yields high quality random
bits while also ensuring that it is not susceptible to side-channel attacks
and provide an informal argument about its eï¬€ectiveness.
1
Introduction
This paper describes the design of a side-channel resistant random number gener-
ator for the Caernarvon [31] high-assurance smart card operating system project.
â‹†Now with Cryptography Research, 575 Market Street, 11th Floor, San Francisco,
CA 94105, USA.
â‹†â‹†Now with Giesecke & Devrient GmbH, Postfach 80 07 29, D-81607, MÂ¨unchen,
Germany.
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 49â€“64, 2010.
c
âƒIFIP International Federation for Information Processing 2010

50
S.N. Chari et al.
The Caernarvon OS is intended to test if it is possible to build very high levels
of assurance into smart card operating systems - it is to be evaluated at Com-
mon Criteria EAL7 under the German evaluation scheme. The choices we have
evaluated and the features of our design would also be applicable to a number of
other high security environments. In particular, practical considerations such as
resistance to side-channel attacks and minimizing the wear on persistent memory
which have guided our design will be relevant in many diï¬€erent applications.
High assurance systems such as Caernarvon require high quality random bits
to support a multitude of uses. In Caernarvon the use cases include:
â€“ Key Generation. Random sources are typically used to generate keys for
symmetric ciphers such as DES and AES. Frequently, they are also used to
generate keying material in algorithms such as Diï¬ƒe-Hellman key exchange.
Occasionally they are used to generate asymmetric cryptographic keys such
as RSA keys.
â€“ Random nonce and other parameter generation. Smart card sys-
tems use RNGs to generate nonces and randomness used in cryptographic
protocols.
â€“ Blinding. Commonly used countermeasures to defeat timing attacks use
random numbers to blind data and keys.
â€“ Masking. Increasingly, random numbers are used to mask operands to pro-
tect against side-channel attacks such as SPA/DPA[20], EM analysis[1], etc.
The security and eï¬€ectiveness of the implementation of cryptographic algorithms
and functions crucially rely on the random numbers used in the above operations:
they should be of â€œgoodâ€ quality and should be kept secret. Random numbers
that are predictable or biased may open the crypto algorithms (or their keys) to
attack. Equally, it is of little use to generate keys for cryptographic algorithms
if random numbers used to generate these keys leak to the outside world.
Smart cards and other systems typically contain a true random number gen-
erator (TRNG), i.e. a physical source of entropy. These are implemented by
circuits which generate random numbers and whose physical properties are cho-
sen to produce high quality random bits which could pass all the standard tests
for random sequences. However, the use of true RNGs is not without poten-
tial problems. For example, it has been observed that hardware random number
generators may â€œageâ€, i.e. the quality of the random numbers degrades over
time. Also, small devices, such as smart cards, can sometimes be vulnerable to
diï¬€erential fault attacks [5, 4] against the the hardware RNG itself, such that it
generates predictable numbers or even always generates the same number.
Given the potential for such problems, a number of standards place stringent
requirements on the use and testing of random numbers from a hardware RNG.
For Common Criteria evaluations under the German scheme, these requirements
are speciï¬ed in AIS 31 [15] which requires that the RNG be tested on system start
up, (i.e. on every activation of the smart card), and also that the used random
numbers are continuously tested. The tests speciï¬ed in AIS 31 are those deï¬ned
in FIPS 140-2 [27]. These testing requirements, of course, have signiï¬cant impact
on performance and usability. Performing FIPS 140-2 tests on card activation

Designing a Side Channel Resistant Random Number Generator
51
takes a signiï¬cant amount of time, which would be noticeable by any user of the
card. Further, performing such tests would be very diï¬ƒcult while still meeting the
stringent timing constraints imposed on smart card startup by the ISO 7816-
3 standard [16]. Continuous RNG tests, executed as the smart card performs
crypto operations, also exacerbate performance problems.
Such testing of random bits can also adversely aï¬€ect the security of the im-
plementation: Side-channel attacks such as SPA/DPA [20], EMF [1], template
attacks [7], and other â€TEMPESTâ€ attacks [30] are capable of extracting use-
ful information from even a single operation of a device. While it is diï¬ƒcult to
extract signiï¬cant information from just reading the TRNG output, the leakage
is ampliï¬ed if the same sensitive value is used at many diï¬€erent places in the
computation. Template attacks work by building a â€œdatabaseâ€ of signatures of
the side channel for each possible value of some sensitive byte or bits; the likeli-
hood of building a good distinguishing signature increases direcly in proportion
to the number of places the same value is used or manipulated. If we run a series
of tests on the output of the TRNG before other uses, then we manipulate the
output bits of the TRNG without modiï¬cation at many diï¬€erent places. This
increases the attack surface of side-channel attacks!
We even proposed testing the TRNG output with one set of bits, conï¬rming
that the TRNG is operating correctly, and then immediately generating a new set
of random bits from the TRNG to use without testing. However, our evaluation
laboratory concluded that this proposal would not comply with the AIS 31
requirements. Thus, we concluded that it was unrealistic to use a TRNG directly
for a high-assurance system that must comply with AIS 31 and also resist side-
channel attacks.
Instead, we adopted a compelling alternative: pseudo random number gen-
erators (PRNGs) which generate a sequence of random bits starting from an
initial (random) seed. There are many secure methods to construct PRNGs: for
example the algorithms speciï¬ed in FIPS 186-2 [11]. Our design generates good
quality random bits compliant to relevant standards while simultaneously en-
suring that the PRNG cannot be attacked using side-channels. Our PRNG is
based on a random seed generated oï¬€-line using a fully tested source of true
random bits. This seed is stored in persistent memory and feeds a component
PRNG whose output is the seed for a second component PRNG whose output
is used for card operations. The ï¬rst PRNG is run for each activation of the
smart card and its state is fed back to memory. Thus, we minimize the number
of updates to persistent memory which is crucial due to the limited number of
write cycles for EEPROM/Flash. We use the TRNG to perturb the values of
the seeds to protect against any possible compromise of the stored seeds. Since
this perturbation of the seeds does not constitute direct use of TRNG output
for cryptographic purposes, AIS 31 does not apply, but AIS 20 [14] does. We
argue that this construction results in a good quality stream of random bits and
justify the security of our construction and its resistance to side channel attacks.
The construction of our PRNG is similar to that of Petit, et. al. [22] who also
design a similar PRNG with the goal of resistance to side channel attacks. We
note here that our construction [8] precedes theirs.

52
S.N. Chari et al.
This paper is organized as follows: Section 2 describes Caernarvon and pro-
vides relevant background on hardware RNGs and standards which govern their
testing. Sections 3 and 3.1 describe the construction of our PRNG, and Sec-
tion 4 argues that the quality of random numbers produced by the PRNG is
good. We discuss the security of our construction and speciï¬cally the resistance
to side-channel attacks in Section 5, and Section 6 describes related work.
2
Background
2.1
Caernarvon Operating System
The Caernarvon operating system was designed to be evaluated under the Com-
mon Criteria [10] at EAL7, the highest deï¬ned level of assurance, under the
German evaluation scheme. It demonstrates that high assurance for smart cards
is technically feasible and commercially viable. Historically, smart card proces-
sors have not supported hardware protection features necessary to separate the
OS from the applications, and one application from another [18]. The assurance
in the Caernarvon OS is based on exploiting the ï¬rst smart card processors to
oï¬€er such hardware protection features.
The Caernarvon OS implements a formally speciï¬ed, mandatory security pol-
icy [23] providing multiâ€“level security, suitable for both government agencies
and commercial users. The mandatory security policy requires eï¬€ective authen-
tication of its users independent of applications, for which the Caernarvon OS
contains a privacy-preserving, twoâ€“way authentication protocol [24] integrated
with the policy. The Caernarvon OS also includes a strong cryptographic library
that has been separately certiï¬ed under the Common Criteria at EAL5+ for
use with other systems. While the initial platform for the operating system was
smart cards, the design could also be used in other embedded devices, such as
USB tokens, PDAs, cell phones, etc.
2.2
Hardware Random Number Generators
Smart cards and other similar systems typically feature true random number
generators (TRNG) built from physical sources of noise. There has been con-
siderable amount of work on harnessing such physical sources to produce good
quality unbiased random output ( see, for example, [2, 21, 13]).
Since they are built from physical sources, the output of TRNGs may include
biases. Thus, before use in sensitive applications, the output needs to be tested
to ensure quality. A good description of an potential evaluation methodology
for TRNGs is described by Schindler, et. al.[25]. This and other standards oï¬€er
testing guidelines but do not endorse or exclude any TRNG design principles.
It should be noted that, as of July 2009, as stated on page 1 of FIPS 140-2,
Annex C [6], â€œThere are no FIPS Approved non-deterministic random number
generators.â€ FIPS-140-2 refers to hardware or TRNGs as non-deterministic.

Designing a Side Channel Resistant Random Number Generator
53
2.3
Testing Requirement Standards
The following are some of the standards for testing of RNGs before using the
output in cryptographic and other sensitive applications.
The AIS 31 RNG Testing Requirements. Killman and Schindler [19] pro-
posed tests for RNGs to ensure that evaluated systems do not suï¬€er from failure
models of hardware RNGs. This was later implemented in an Application Note
and Interpretation of the Scheme(AIS 31) [15] and recommends that the output
of hardware RNGs be testing carefully prior to use with start-up and continuous
tests. While such testing will certainly result in better quality, we feel that the
recommendations do not take into account the potential for side channel attacks
on the implementation of such testing. Section 2.4 discusses some of these at-
tacks and how they can be applied to RNG testing phases. It is our belief that
the AIS 31 mandated testing can signiï¬cantly increase the attack surface for side
channel attacks. This issue was ï¬rst discussed by Karger [17].
Because AIS 31 does not consider this increased potential for side-channel
attacks due to testing, Common Criteria Guidance Documents for several eval-
uated smart card chips1 require that cryptographic use of the random numbers
generated by a true RNG be subject to the tests of FIPS 140-2 [27, Section
4.9.1], thereby requiring the increased attack surface.
We note that the latest protection proï¬le for smart card chips [26] does discuss
the risks of the inherent leakage. However, an update to AIS 31 is still needed,
because the potential risks are not limited only to smart cards.
FIPS Tests. FIPS-140, the deï¬nitive US standard for cryptographic devices,
did include a number of test on the output of RNGs which have been dropped
since 2002. The draft of the upcoming FIPS 140-3 [28] includes a number of
tests for pseudo random number generators (PRNGs). FIPS 140-3 mandates the
following tests for PRNGs (Random bit generator(RBG) in their terminology):
â€“ Deterministic components of a Random Bit Generator (RBG) shall be sub-
ject to the Cryptographic Algorithm Test in Section 4.9.1 (of FIPS 140-3).
â€“ Data output from the RBG shall pass the Continuous RBG Test as speciï¬ed
in Section 4.9.2 (of FIPS 140-3).
The cryptographic algorithm test requires that the algorithms used in the PRNG
be tested before they are used. The continuous test is that each generated random
number be saved so that the next one generated compared with the previous one.
The standard further speciï¬es that if an entropy source (a hardware RNG) is
used, then the minimum entropy test must be performed on each output of the
source. We note that the same performance and security issues are applicable
to these tests. For instance, it will be diï¬ƒcult to perform the cryptographic
algorithm test at start-up while still meeting the maximum latency requirements
of ISO 7816-3 [16]. As argued earlier, any testing performed on random bits can
increase the attack surface for side channel attacks.
1 Guidance documents are deï¬ned in the Common Criteria [9] assurance component
AGD USR.1. Citations can not be provided due to non-disclosure requirements.

54
S.N. Chari et al.
2.4
Side Channel Attacks
High assurance systems must be built to resist attacks which exploit informa-
tion such as power consumption [20], EM emanations [1], template attacks [7],
TEMPEST attacks [30] and other such by-products of the implementation of
sensitive operations that are capable of extracting useful information during the
computation. Here we only highlight how these attacks aï¬€ect our design choices
for the RNG.
Simple Power Attacks (SPA) and its EM equivalent (SEMA) target leakages
that occur in a single execution of the device, e.g. through conditional execution
of code depending on a sensitive value. While these are very powerful they are
easy to protect against, and most implementations guard against such obvious
leakage. These attacks also target other leakages that can occur in a single step,
e.g. in some hardware reading a byte from EEPROM leaks the Hamming weight
of the byte that is read.
Diï¬€erential Power and EM attacks (DPA/DEMA) exploit statistical biases
that occur in side channels due to manipulation of sensitive values. The attacks
work by ï¬rst amplifying these biases by running the device with multiple diï¬€erent
inputs. For these attacks to be successful, the same sensitive values must be
manipulated in all diï¬€erent runs of the device.
Template attacks extract useful information from a single sample of the side
channel from the device. These work by building signatures of the side channel for
each possible value of some sensitive byte (or a few bits) using a test device. Given
a single run of the device under test they attempt to identify using statistical
techniques the most likely value of the sensitive byte. Key to the success of these
attacks is building the right set of signatures. The likelihood of building better
signatures increases with the number of places in the computation that the
same byte is manipulated. For instance, if random bits sampled from an RNG
are subject to a number of tests where the same bits are being manipulated,
then the likelihood of building good signatures increases.
2.5
Constraints of Persistent Memory
Smart cards use EEPROM and/or Flash as persistent memory since they have
no access to oï¬€-chip memory. The PRNG in the Caernarvon system is designed
to use persistent memory across runs of the card.
Write operations to EEPROM or Flash memory are slow, usually in the 1 to
6 millisecond range each, depending on the technology generation. Further, the
write block size for EEPROM is limited, for example, to 128 bytes. Thus writing
any signiï¬cant amount of data to a ï¬le is likely to take multiple write operations,
plus additional writes to update the control block information. Furthermore,
EEPROM and Flash memories have a limited number of write cycles before
they start to fail, for example between 100,000 and 500,000 for EEPROM, and
only 10,000 for Flash.
Our PRNG described below will store PRNG state in persistent storage but
do this once per run of the card. The Caernarvon operating system includes
extensive techniques to mitigate these problems for more general applications.

Designing a Side Channel Resistant Random Number Generator
55
3
RNG Design Overview
The design criteria for the PRNG are the following:
â€“ Quality. The random bits produced in each run of the smart card should be
unpredictable. Further, the random bits in any run should be unpredictable,
even knowing the bits in any other run.
â€“ Security. The random number generator should be resistant to side-channel
attacks such as SPA/DPA [20], EM Analysis [1] and Template Attacks [7].
â€“ Eï¬€ectiveness. The RNG should make eï¬€ective use of persistent storage
minimizing updates to such storage.
Given these requirements the design follows quite naturally: First, quality ne-
cessitates a seed sampled from a high entropy source, but obtaining this from an
on-chip source would require testing the bits. As noted, this can increase the sur-
face for side channel attacks, thus lowering the eï¬€ective entropy of the on-chip
source. Thus our PRNG is seeded by random bits which are stored in EEP-
ROM which can, of course, be generated oï¬„ine securely and comprehensively
tested. The FIPS 140-2 standard [27] does not impose requirements or tests on
this external source of entropy. However, the draft for FIPS 140-3 requires that
the claimed minimum entropy of the source be provided to the cryptographic
module which is then required to verify that the claimed value is suï¬ƒcient for
intended applications. This is currently not part of our design, but we note that
the device canâ€™t directly test the source entropy. The best one could do is check
for plausible error conditions, such as strings of all constants, etc.
The PRNG in the Caernarvon operating system is shown in Fig. 1. It consists
of two component PRNGs cascaded: the ï¬rst is called the Lifetime PRNG or the
LPRNG and the second is called the Activation PRNG or APRNG. LPRNG is
seeded by random bits which are stored in persistent memory. Each invocation
of either component can be optionally seeded with additional random bits from
an on-chip source of randomness. We stress that the strength of the random
bits generated by the composite PRNG primarily depends on the quality of the
external seed LSEED. For instance, if this seed is revealed due to a compromise
of the oï¬€-chip process then this can compromise the PRNG. Adding on-chip
randomness can ensure that the output of the PRNG is not a deterministic
function of LSEED. While the PRNG doesnâ€™t depend on this on-chip source
for its strength, a pedantic reading of the standards may require us to test
this input. Template and other side channel attacks can signiï¬cantly reduce the
eï¬€ective entropy of the on-chip source. Adding this to the seed obtained from
the external source can not decrease the strength of the PRNG. Further, while
complying with standards, one could argue that since the claimed strength is
only dependent on LSEED, we may not need to test this additional optional
input. AIS 31 [19] recognizes this type of use as functionality class P1 which
does not require such extensive testing.
Each invocation changes the internal state of the PRNG which is used in the
next invocation. For the LPRNG, this is stored back in EEPROM as the seed
for the next run as shown. The output of the ï¬rst invocation of the LRPNG

56
S.N. Chari et al.
Fig. 1. Functional Outline of Caernarvon PRNG
is the seed for the APRNG whose output is used whenever random bits are
required in this run of the smart card. In the Caernarvon OS, we choose as
PRNG implementations schemes recommended by FIPS 186-2 [11]. The analysis
of our random number generator does not depend on the choice of the PRNG
block chosen from amongst those recommended in Annex C of the FIPS 140-2
standard [6]. We have chosen the algorithm for generating random values from
the Appendix 3.2 of the Digital Signature Algorithm standard [11] with the
method described in Appendix 3.4 using the DES algorithm to implement the
G() function. We note here that the recommendations given by NIST [3] are
more recent and should be the choice for an updated design.
3.1
Detailed Description of the PRNG
This section brieï¬‚y describes the construction of the two PRNGs and documents
the choices made from relevant standards.
LPRNG is seeded by a 160 bit value LSEED from EEPROM. The value t chosen
as 67452301 EFCDAB89 98BADCFE 10325476 C3D2E1F0 is used in the â€œcompressâ€
function at each invocation. The pseudo-code for the update function of LPRNG is
Inputs:
- LSTATE: content of LSEED, stored in persistent storage; initially
generated from an external source of entropy and installed in the
chip at initialization.
- LOPT: optional input from Hardware RNG (corresponding to input
labelled â€˜â€˜optional user-inputâ€™â€™ in FIPS 186-2).
Update:
a. LSTATE = (LSTATE + LOPT)
b. LOUT = G(t, LSTATE)
c. LNEXTSTATE = (LSTATE + 1 + LOUT)
Output:
- LOUT: used as new seed ASEED by APRNG.
- LSTATENEXT: new state used to replace previous LSEED

Designing a Side Channel Resistant Random Number Generator
57
This sequence is executed exactly once during an activation of the card. The
initial value of LSTATE is obtained from persistent storage LSEED. To potentially
add more entropy, we chose to add randomness from an on-chip source via LOPT.
Testing the bits LOPT will, of course, reduce the eï¬€ective entropy of the source
due to side channel attacks. As we have noted before, the strength of our PRNG
rests solely on the strength of LSEED and hence we argue that this may be enough
to address the requirements of the standards even without testing LOPT.
The output of LPRNG, i.e. LOUT = G(t, LSTATE), is used to seed the APRNG.
The updated state LNEXTSTATE is written back to persistent storage. Our imple-
mentation ensures that until this state is successfully updated in persistent stor-
age, APRNG will not be activated. This ensures that if random bits are used
anywhere in this activation of the card, then the value of LSEED will indeed
be diï¬€erent in future activations. This prevents the attack where the card is
disabled before the write back to EEPROM is completed resulting in the same
sequence of random bits across diï¬€erent activations.
The â€œcompressâ€ function G() will be based on the DES algorithm, speciï¬ed
in Section 3.4 of FIPS 186-2, chosen because of on-chip DES hardware. The
properties of our RNG would be the same for compress functions built from
other algorithms. For new designs, a better choice would be the HMAC-SHA1
based construction of deterministic RBGs given by [3].
The APRNG uses LOUT, the output from the LRPNG, as its seed. It is con-
structed similar to LPRNG with optional additional input from on-chip random
sources. Its pseudo-code is:
Inputs:
- ASTATE: content of ASEED, on activation the output of the LPRNG.
- AOPT: optional input chosen from source of randomness This is done
at most once. Further invocations will NOT have any additional input.
Update:
a. ASTATE = (ASTATE + AOPT)
b. AOUT = G(t, ASTATE)
c. ANEXTSTATE = (ASTATE + 1 + AOUT)
Output:
- AOUT: randomness returned to caller of APRNG.
- ASTATENEXT: new state used to replace previous ASEED.
This generates 160 bits of randomness for each invocation and updates the in-
ternal state of APRNG.
The Caernarvon random number generation process described above realizes
the requirements we had earlier listed. First, cryptographic keys and other sen-
sitive values are generated from the output of a PRNG. Thus, we do not need
to test the quality before use which may result in exposure through side channel
attacks. However, the quality of the random bits is still high since the seed used
by the PRNG is sampled from an high entropy source oï¬€-line. The strength of
our PRNG rests (almost) exclusively on the strength of the oï¬€-line process for
generating LSEED. We note that even if testing of optional input from on-chip

58
S.N. Chari et al.
random sources results in reduced levels of entropy due to side channel attacks,
it is still suï¬ƒcient when combined with LSEED. The analysis will show that the
quality is maintained across diï¬€erent activations of the card. Further we note
that the update to the seed in LPRNG is done only once per activation of the
card, and thus we make eï¬€ective use of persistent storage.
4
Cryptographic Analysis
This section justiï¬es the cryptographic strength of the PRNG construction.
First, we argue generically that the chaining construction of the PRNG is secure
assuming we start with a secure individual PRNG construction. This and the
assumption that the PRNG schemes recommended by the FIPS 186-2 standard
are secure yield a proof of security of our chaining construction. We also argue
that our PRNG is a class K4 DRNG according to the AIS 20 [14] standard.
In following lemma we state that our construction as shown in Figure 1 is a
special instance (with n = 2) of a general class of secure PRNGs composed by
chaining a primitive PRNG n times:
Lemma 1. Let rchain(n) be a PRNG formed by chaining n primitive PRNGs
rprim. If there is a distinguisher which can distinguish the output of rchain(n)
from a uniformly distributed random string of equal length then there is also a
distinguisher distinguishing the output of rprim from a random string.
Proof. Without loss of generality, assume that rprim has a seed length of l, each
inner PRNG ri
prim reseeds its child m times before getting reseeded itself and we
output externally lmn bytes, i.e., each ri
prim expands a seed to length lm. When
reseeding a particular PRNG ri
prim we talk of a new instance of that PRNG.
For this case, you can visualize rchain(n) as a m-ary tree of depth n where the
ith level corresponds to the instances of the ith PRNG ri
prim and the jth child
of a node corresponds to the jth chunk of l bytes returned by the correspond-
ing instance of the PRNG. The concatenation of the leaf nodes is the output
produced by rchain(n).
The lemma follows from an inductive hybrid argument. The hybrids at depth
n are rchain(n), rchain(n) with each of the m sub-trees of depth n âˆ’1 recomputed
from a fresh random seed (instead of the seed derived from the parent), and for
progressive hybrids we replace the sub-trees in increasing order of index with a
sub-tree where all nodes are freshly sampled random elements.
The distribution induced by the extreme hybrids correspond to the distri-
bution of rchain(n) and of a random distribution, respectively. It is also easy to
see that neighboring hybrids either diï¬€er by (a) a single value which is either
a random lm string or a single expansion of rprim from a random and indepen-
dent seed or (b) a sub-tree which correspond to an (independent) n âˆ’1 PRNG
rchain(nâˆ’1) or a random tree. Hence, we can reduce a distinguisher of any pair of
hybrids in a distinguisher of either rprim or rchain(nâˆ’1) from random data. The
latter in turn can be reduced recursively into hybrids until we arrive in hybrids

Designing a Side Channel Resistant Random Number Generator
59
diï¬€ering all only in a rprim distinguishing problem. As there are only a polyno-
mial number of hybrids, any non-negligible advantage in distinguishing rchain(n)
from a random string can be converted into a non-negligible distinguisher of
rprim from a random string.
âŠ“âŠ”
Thus if we are given a secure PRNG primitive and the seed to the PRNG chain
is chosen uniformly at random then our construction is cryptographically secure.
Thus under the assumption that the FIPS 186-2 PRNG is secure and assuming
proper secret and random seed generation at smart card personalization time,
our overall realization is cryptographically secure as well. (Note that to our
knowledge there is no published security proof (in a strong cryptographic sense)
for the FIPS-186-2 PRNG. However, sound design principles, a number of easy to
made security arguments and empirical evidence give us a reasonable assurance
of its security.)
Informally, note that in the construction of the PRNG, on each invocation
we add the output of the PRNG back to its internal state. Thus the PRNG is
forward secure i.e. given the internal state after k invocations we can not infer the
random outputs from prior invocations of the PRNG. Thus, the PRNG design
fulï¬lls the requirements of a K4 DRNG according to the AIS-20 standard. More
precisely, the fulï¬llment of the individual criteria is as follows:
â€“ K1 DRNG: This is a simple requirement which requires that we identify
an integer value c such that every sequence of c outputs of the PRNG is
distinct. By our assumption, the output of the core PRNG primitive i.e. the
FIPS 186-2 generator is indistinguishable from random so it trivially satisï¬es
this requirement ignoring the eventual cycling of the 160 bit output.
â€“ K2 DRNG: Speciï¬cally, we are asked to characterize the statistical proper-
ties of the RNG such as the monobit test, poker test and tests on runs. We
note that the FIPS 186-2 generators and hence our construction will satisfy
all these criteria.
â€“ K3 DRNG: This level requires us to assert that the entropy of the PRNG
is at least 80. We note here that our PRNG operates on 160 bit seeds which
are chosen oï¬€-line from a high entropy source which is carefully tested. Thus
our PRNG achieves this level.
â€“ K4 DRNG: For this level, we are required to argue that the PRNG is
forward-secure as describe above. As argued, our PRNG meets this criterion.
FIPS 186-2 does not impose any requirements on the user input, i.e. it does
not need to be random or secret to guarantee pseudo-randomness of the output
stream or the security of the algorithm. Thus, replacing the user input with the
output of the HW/RNG does not aï¬€ect the security of the implementation, even
if the HW/RNG malfunctions. On the other hand, if the HW/RNG is functioning
properly then the output of LPRNG is truly random, and the output of APRNG
is pseudo-random. This shows that there is no requirement to test the statistical
properties of the bits of the HW/RNG, as they do not aï¬€ect the security of the
cryptographic aspects of the system. Yet, when it is functioning properly we gain
entropy.

60
S.N. Chari et al.
5
Attacks and Defenses
A key criterion for our design was resistance to side-channel attacks against the
functioning of the PRNG. We have considered the following attacks.
â€“ Simple Power Analysis/Simple EM Analysis (SPA/SEMA).
â€“ Diï¬€erential Power Analysis/Diï¬€erential EM Analysis (DPA/DEMA)
â€“ Template attacks using Power or EM or both.
Our design and implementation has been guided by techniques which are eï¬€ective
in the mitigation of these attacks. In particular, the following techniques which
minimize and practically eliminate the threat posed by these attacks.
Technique 1. The strength of our PRNG relies on the entropy of the external
seed supplied to the card. Using oï¬€-chip sources greatly reduces the attack
surface for template attacks as discussed below. Our PRNG is only claimed
to be as strong as this external seed. The addition of the input from an
on-chip source does not aï¬€ect this claim.
Technique 2. The execution sequence of all PRNG code is independent of its
internal state.
Technique 3. As deï¬ned, both the component PRNGs can be optionally pro-
vided additional seeding material from on-chip sources. Due to the testing
requirements this can only be counted on to provide a marginal additional
source of entropy. However, even this amount can add to the strength of
the PRNG. While it is certainly not feasible to base the entire PRNG on
sampling from the on-chip source due to the low eï¬€ective entropy, adding
this optional input can be beneï¬cial.
Technique 4. The implementation utilizes the hardware RNG to implement
random masking/share based computation of the PRNG speciï¬cation. While
side channel attacks will only result in lowered entropy we argue below that
this is suï¬ƒcient to protect against statistical side-channel attacks.
As discussed below these techniques provide adequate countermeasures against
side-channel attacks. The Caernarvon Persistent Storage Management code pro-
vides a CRC check on bits being stored. This will be disabled due to potential
leakage of information.
5.1
Simple Power Analysis (SPA)
Simple power/EM analysis attacks target leakage that occurs in a single activa-
tion of the card such as through conditional execution depending on sensitive
state OR high leakage on any given step of the computation. Our implementa-
tion is careful to ensure that the PRNG code execution sequence is independent
of state (Technique 2). Thus SPA/SEMA attacks are limited to leakage at in-
dividual steps such as reading of bytes from EEPROM in the case of LPRNG.
Masking steps in the computation, even when sampled from the hardware RNG,
can also reduce the information that is revealed during the computation.

Designing a Side Channel Resistant Random Number Generator
61
5.2
Diï¬€erential Power Analysis (DPA)
Classical DPA is not a problem with LPRNG/APRNG since an attacker cannot
invoke the update function of any PRNG many times with the same secret
state. The state gets modiï¬ed at each invocation of the update function and this
constantly evolving secret state is a good defense against DPA style attacks;
the attacker gets only one sample to attack any secret state. Note that in our
implementation we actually add random masks with the bits sampled from an
on-chip source. As we have discussed before, we can only count on this being a
low entropy source. However, even with this source of bits, masking can further
prevent DPA. We reiterate that the main defense is that DPA is not easy to
mount since the keys change at every invocation.
5.3
Template Attacks
Template attacks can be used to classify the single signal received during the op-
eration of the LPRNG/APRNG on a given unknown state. The eï¬ƒcacy of this
attack relies on having a large enough â€signatureâ€ or â€œtemplateâ€ of computation
manipulating the same sensitive value. The attacker can build oï¬„ine a series of
templates for this signature corresponding to diï¬€erent values of this sensitive in-
put and use them to identify the speciï¬c value on a given activation of the card.
The main defense against template attacks is the use of an oï¬€-chip source to
generate LSEED. This can be directly used in the computation of the PRNG
and thus we can be certain that building templates this will be diï¬ƒcult. This
is because of the properties of the PRNG there is rapid diï¬€usion and LSEED
will not be manipulated unmodiï¬ed at too many points. We do allow for the
optional input sampled from the on-chip RNG. With full conformance to the
standards, there is a good chance that template attacks can substantially reduce
the eï¬€ective entropy. Note, however, that the PRNG is still secure since LSEED
is not tested. The masking of the computation using Technique 4 above will also
make it diï¬ƒcult to build eï¬€ective templates even though it is sampled from a
source with low eï¬€ective entropy.
Resistance to side channel attacks can be best argued with a description of
the implementation, since there are many implementation details relevant to the
argument. Further, to convincingly argue against side channel attacks we have
to formalize the precise attack models along the lines of Petit et. al.[22]. We have
not built such a model for our system.
6
Additional Related Work
Several recent designs for hardware random number generators have appeared,
including Doleâ€™s [12] that describes networked computers generating and shar-
ing entropy in proportion to the need for random numbers, Walsh and Beister-
feldtâ€™s [33] that generates high-quality random numbers by sampling the output
of a Voltage Controlled Oscillator (VCO) at a frequency much lower than the

62
S.N. Chari et al.
frequency of the oscillator output, and Sprunkâ€™s [29] which uses a TRNG to drive
a PRNG. Tsoi, Leung and Leong [32] show compact FPGA implementations of
both a TRNG and a PRNG, but they do not connect them together. Further-
more, none of these designs address the possibility of side channel attacks or the
issues of EEPROM memory wear.
7
Conclusions
We have seen that generation of cryptographically strong random numbers is
actually quite diï¬ƒcult. While many of the standards concerning the testing
of random numbers generated by hardware or true random number generators
(TRNG) quite properly worry about hardware failures, they do not adequately
cover the possibility of side channel attacks during RNG testing. We have shown
a novel combination of a TRNG with a PRNG that alleviates both the test-
ing concerns and the side-channel concerns that also limits the possibility of
EEPROM or Flash memories being worn out from re-writing seed values too
frequently. While our examples have all focused on cryptographic algorithms,
such as DES, SHA-1, DSA, and RSA, the principles equally well apply to newer
algorithms, such as elliptic curves, AES, and SHA-256, etc.
We must recommend that both the NIST FIPS 140 standard and the German
AIS 31 guideline be updated to reï¬‚ect these kinds of issues, so that future de-
velopers can more easily construct random number-based systems that are truly
secure against both hardware failures and side-channel attacks.
References
[1] Agrawal, D., Archambeault, B., Rao, J.R., Rohatgi, P.: The EM side-channel(s).
In: Kaliski Jr., B.S., KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp.
29â€“45. Springer, Heidelberg (2003)
[2] Bagini, V., Bucci, M.: A design of reliable true random number generator for
cryptographic applications. In: KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 1999. LNCS,
vol. 1717, pp. 204â€“218. Springer, Heidelberg (1999)
[3] Barker, E., Kelsey, J.: Recommendation for random number generation using
deterministic random bit generators (revised). NIST SP800-90, National Institute
of Standards and Technology, Gaithersburg, MD (March 2007),
http://csrc.nist.gov/publications/nistpubs/800-90/
SP800-90revised March2007.pdf
[4] Biham, E., Shamir, A.: Diï¬€erential fault analysis of secret key cryptosystems. In:
Kaliski Jr., B.S. (ed.) CRYPTO 1997. LNCS, vol. 1294, pp. 513â€“525. Springer,
Heidelberg (1997)
[5] Boneh, D., DeMillo, R.A., Lipton, R.J.: On the importance of checking cryp-
tographic protocols for faults. In: Fumy, W. (ed.) EUROCRYPT 1997. LNCS,
vol. 1233, pp. 37â€“51. Springer, Heidelberg (1997)
[6] Campbell, J., Easter, R.J.: Annex c: Approved random number generators for
FIPS PUB 140-2, security requirements for cryptographic modules. FIPS PUB
140-2, Annex C, National Institute of Standards and Technology, Gaithersburg,
MD (Draft of July 31, 2009),
http://csrc.nist.gov/publications/fips/fips140-2/fips1402annexc.pdf

Designing a Side Channel Resistant Random Number Generator
63
[7] Chari, S., Rao, J.R., Rohatgi, P.: Template attacks. In: Kaliski Jr., B.S., KoÂ¸c,
CÂ¸.K., Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp. 13â€“28. Springer, Heidel-
berg (2003)
[8] Chari, S.N., Diluoï¬€o, V.V., Karger, P.A., Palmer, E.R., Rabin, T., Rao, J.R.,
Rohatgi, P., Scherzer, H., Steiner, M., Toll, D.C.: Method, apparatus and system
for resistence to side channel attacks on random number generators. United States
Patent No. 7496616 (Filed November 12, 2004, Issued February 24, 2009)
[9] Common Criteria for Information Technology Security Evaluation, Part 3: Se-
curity assurance requirements. Version 2.3 CCMB2005-08-003 (August 2005),
http://www.commoncriteriaportal.org/public/files/ccpart3v2.3.pdf
[10] Common Criteria for Information Technology Security Evaluation, Parts 1, 2,
and 3. Version 2.3 CCMB2005-08-001, CCMB2005-08-002, and CCMB2005-08-
003 (August 2005), http://www.commoncriteriaportal.org/thecc.html
[11] Digital signature standard. FIPS PUB 186-2, with Change Notice 1, 5 Octo-
ber 2001, National Institute of Standards and Technology, Gaithersburg, MD
(January 2000),
http://csrc.nist.gov/publications/fips/archive/
fips186-2/fips186-2.pdf
[12] Dole, B.: Distributed state random number generator and method for utilizing
same. United States Patent No. US6628786B1, September 30 (2003)
[13] Epstein, M., Hars, L., Krasinski, R., Rosner, M., Zheng, H.: Design and imple-
mentation of a true random number generator based on digital circuit artifacts.
In: Walter, C.D., KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2003. LNCS, vol. 2779, pp.
152â€“165. Springer, Heidelberg (2003)
[14] Functionality classes and evaluation methodology for deterministic random num-
ber generators. AIS 20, Version 1, Bundesamt fÂ¨ur Sicherheit in der Information-
stechnik (BSI), Bonn, Germany, December 2 (1999),
http://www.bsi.bund.de/zertifiz/zert/interpr/ais20e.pdf
[15] Functionality classes and evaluation methodology for physical random number
generators. AIS 31, Version 1, Bundesamt fÂ¨ur Sicherheit in der Informationstech-
nik (BSI), Bonn, Germany, September 25 (2001),
http://www.bsi.bund.de/zertifiz/zert/interpr/ais31e.pdf
[16] ISO 7816-3, Identiï¬cation cards - Integrated circuit(s) with contacts - Part 3:
Electronic signals and transmission protocols, Second edition. ISO Standard 7816-
3, International Standards Organization (December 1997)
[17] Karger, P.A.: The importance of high-assurance security in pervasive computing.
In: Hutter, D., MÂ¨uller, G., Stephan, W., Ullmann, M. (eds.) Security in Pervasive
Computing. LNCS, vol. 2802, p. 9. Springer, Heidelberg (2004),
http://web.archive.org/web/20040524183841/,
http://www.dfki.de/spc2003/karger.pdf
[18] Karger, P.A., Toll, D.C., McIntosh, S.K.: Processor requirements for a high secu-
rity smart card operating system. In: Proc. 8th e-Smart Conference. Eurosmart,
Sophia Antipolis, France, September 19-21 (2007), Available as IBM Research
Division Report RC 24219 (W0703-091),
http://domino.watson.ibm.com/library/CyberDig.nsf/Home
[19] Killman, W., Schindler, W.: A proposal for: Functionality classes and evalu-
ation methodology for true (physical) random number generators. Tech. rep.,
T-Systems debis Systemhaus Information Security Services and Bundesamt fÂ¨ur
Sicherheit in der Informationstechnik (BSI), Bonn, Germany (September 25,
2001), http://www.bsi.bund.de/zertifiz/zert/interpr/trngk31e.pdf

64
S.N. Chari et al.
[20] Kocher, P., Jaï¬€e, J., Jun, B.: Diï¬€erential Power Analysis: Leaking Secrets. In:
Wiener, M. (ed.) CRYPTO 1999. LNCS, vol. 1666, pp. 143â€“161. Springer, Hei-
delberg (1999)
[21] Maher, D.P., Rance, R.J.: Random number generators founded on signal and
information theory. In: KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 1999. LNCS, vol. 1717,
pp. 219â€“230. Springer, Heidelberg (1999)
[22] Petit, C., Standaert, F.X., Pereira, O., Malkin, T., Yung, M.: A block cipher
based pseudo random number generator secure against side-channel key recovery.
In: ASIACCS 2008, Tokyo, Japan, March 18â€“20, pp. 56â€“65 (2008)
[23] Schellhorn, G., Reif, W., Schairer, A., Karger, P., Austel, V., Toll, D.: Veriï¬cation
of a formal security model for multiapplicative smart cards. In: Cuppens, F.,
Deswarte, Y., Gollmann, D., Waidner, M. (eds.) ESORICS 2000. LNCS, vol. 1895,
pp. 17â€“36. Springer, Heidelberg (2000)
[24] Scherzer, H., Canetti, R., Karger, P.A., Krawczyk, H., Rabin, T., Toll, D.C.:
Authenticating Mandatory Access Controls and Preserving Privacy for a High-
Assurance Smart Card. In: Snekkenes, E., Gollmann, D. (eds.) ESORICS 2003.
LNCS, vol. 2808, pp. 181â€“200. Springer, Heidelberg (2003)
[25] Schindler, W., Killmann, W.: Evaluation criteria for true (physical) random num-
ber generators used in cryptographic applications. In: Kaliski Jr., B.S., KoÂ¸c, CÂ¸.K.,
Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp. 431â€“449. Springer, Heidelberg
(2003)
[26] Security IC platform protection proï¬le. Tech. Rep. BSI-PP-0035, developed by
Atmel, Inï¬neon Technologies AG, NXP Semiconductors, Renesas Technology Eu-
rope, and STMicroelectronics, registered and certiï¬ed by Bundesamt fÂ¨ur Sicher-
heit in der Informationstechnik (BSI), Bonn, Germany, June 15 (2007),
http://www.commoncriteriaportal.org/files/ppfiles/pp0035b.pdf
[27] Security requirements for cryptographic modules. FIPS PUB 140-2, Change
Notice 2, National Institute of Standards and Technology, Gaithersburg, MD,
December 3 (2002),
http://csrc.nist.gov/publications/fips/fips140-2/fips1402.pdf
[28] Draft - security requirements for cryptographic modules. FIPS PUB 140-3, Na-
tional Institute of Standards and Technology, Gaithersburg, MD, April 6 (2007),
http://csrc.nist.gov/publications/fips/fips140-3/fips1403Draft.pdf
[29] Sprunk, E.J.: Robust random number generator. United States Patent No.
US6253223B1, June 26 (2001)
[30] Tempest fundamentals (u). Declassiï¬ed in 2000 under Freedom of Information Act
NACSIM 5000, National Security Agency, Ft. George G. Meade, MD, February
1 (1982), http://cryptome.org/nacsim-5000.zip
[31] Toll, D.C., Karger, P.A., Palmer, E.R., McIntosh, S.K., Weber, S.: The caernar-
von secure embedded operating system. Operating Systems Review 42(1), 32â€“39
(2008)
[32] Tsoi, K.H., Leung, K.H., Leong, P.H.W.: Compact FPGA-based true and pseudo
random number generators. In: 11th Annual IEEE Symp. on Field-Programmable
Custom Computing Machines, Napa, CA, April 9â€“11 (2003)
[33] Walsh, J.J., Biesterfeldt, R.P.: Method and apparatus for generating random num-
bers. United States Patent No. US6480072B1, November 12 (2002)

Simple Power Analysis on Exponentiation
Revisited
Jean-Christophe Courr`ege1, Benoit Feix2, and Myl`ene Roussellet2
1 CEACI-THALES
18 Avenue Edouard BELIN
31401 Toulouse, France
Jean-Christophe.courrege@thalesgroup.fr
2 INSIDE CONTACTLESS
41 Parc Club du Golf
13856 Aix-en-Provence, Cedex 3, France
{bfeix,mroussellet}@insidefr.com
Abstract. Power Analysis has been studied since 1998 when P. Kocher
et al. presented the ï¬rst attack. From the initial Simple Power Analy-
sis more complex techniques have been designed and studied during the
previous decade such as Diï¬€erential and Correlation Power Analysis. In
this paper we revisit Simple Power Analysis which is at the heart of side
channel techniques. We aim at showing its true eï¬ƒciency when stud-
ied rigorously. Based on existing Chosen Message attacks we explain in
this paper how particular message values can reveal the secret exponent
manipulated during a modular exponentiation with a single power con-
sumption curve. We detail the diï¬€erent ways to achieve this and then
show that some blinded exponentiations can still be threatened by Sim-
ple Power Analysis depending on the implementation. Finally we will
give advice on countermeasures to prevent such enhanced Simple Power
Analysis techniques.
Keywords: Public key cryptography, long integer arithmetic, modular
exponentiation, power analysis.
1
Introduction
The appearance of public key cryptography [DH76] and of the RSA cryptosystem
[RSA78] was the beginning of modern cryptography. The use of these schemes,
and especially RSA, has become very popular and more and more systems have
based their security on it. Thus, in order to implement these systems eï¬ƒciently,
various modular multiplication algorithms have been designed to be embedded
in constrained hardware resources devices such as Trusted Platform Modules
(TPM) and smart cards.
Another consideration has become a key point for developers is the tamper
resistance topic. For years smart cards had been considered as tamper resistant
devices until Kocher et al. introduced in 1996 the Timing Attacks [Koc96] and
few years later the Power Analysis Attacks [KJJ99]. Their techniques, named
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 65â€“79, 2010.
c
âƒIFIP International Federation for Information Processing 2010

66
J.-C. Courr`ege, B. Feix, and M. Roussellet
Simple Power Analysis (SPA) and Diï¬€erential Power Analysis (DPA), threaten
any naive cryptographic algorithm implementation. As electronic devices are
composed of thousands of logical gates that switch diï¬€erently depending on the
executed operations, the power consumption depends on the executed instruc-
tions and the manipulated data. Thus by analyzing the power consumption of
the device on an oscilloscope it is possible to observe its behavior and then to
deduce from this power curve the secret data manipulated.
From the initial SPA and DPA of Kocher et al. many studies were presented
to introduce new attack techniques on diï¬€erent popular cryptographic schemes
and to improve the power curve processing in order to recover secrets with fewer
curves than the classical DPA. Others presented some countermeasures to these
attacks. In this paper we focus on SPA and show it is more powerful than what can
be inferred from reading current side channel papers. To illustrate our paper and
assertions some practical results are presented on some secure implementations.
The paper is organized as follows. First we recall in sections 2 and 3 the fun-
damentals notations and techniques on which our work is based. Section 2 gives
an overview of long integer arithmetic for public key embedded implementations.
Section 3 describes the Side Channel Analysis techniques related to this paper.
We present in Section 4 some chosen message SPA techniques and explain the
reasons of observed power leakages. We also explain how these power leakages
can be exploited to mount enhanced SPA on non-chosen or blinded message
exponentiations. In Section 5 we analyze the eï¬ƒciency of the classical counter-
measures and give some advice on their use for preventing enhanced SPA. We
conclude our research in Section 7.
2
Embedded Implementations of Exponentiation
We recall here the mathematical principles and the arithmetic algorithms that
are used to implement public key algorithms in embedded devices.
2.1
Long Integer Multiplication
In this paper we use the following notation: x = (xkâˆ’1 . . . x1x0)b corresponds to
integer x decomposition in base b, i.e. the x decomposition in t-bit words with
b = 2t and k = âŒˆlogb(x)âŒ‰.
Algorithm 2.1 presents to the classical long integer multiplication algorithm
used to compute x Ã— y.
2.2
Long Integer Modular Multiplication
Chip manufacturers usually embed arithmetic coprocessors to compute modular
multiplications x Ã— y mod n for long integers x, y and n. In this paper we
choose to illustrate our analysis on the Barrett and the Montgomery [Mon85]
reductions. But other techniques exist such as the interleaved multiplication-
reduction with Knuth, Sedlack or Quisquater methods [Dhe98]. Our analysis
can also be adapted to these methods.

Simple Power Analysis on Exponentiation Revisited
67
Algorithm 2.1 Long Integer Multiplication
Input: x = (xkâˆ’1xkâˆ’2 . . . x1x0)b, y = (ykâˆ’1ykâˆ’2 . . . y1y0)b
Output: LIM(x, y) = x Ã— y
Step 1. for i from 0 to 2k âˆ’1 do wi = 0
Step 2. for i from 0 to k âˆ’1 do
c â†0
for j from 0 to k âˆ’1 do
(uv)b â†wi+j + xj Ã— yi + c
wi+j â†v and c â†u
wi+k â†v
Step 3. Return(w)
Multiplication with Barrett Reduction. Here a modular multiplication
x Ã— y mod n is the combination of a long integer multiplication LIM(x,y)
followed by a Barrett reduction by the modulus value n. We use the notation
BarrettRed(a,n) for this reduction, thus BarrettRed(LIM(a,m),n) corresponds to
the computation of a Ã— m mod n. We do not detail the Barrett reduction
algorithm here, for more details the reader can refer to [MOV96] or [ACD+06].
Montgomery Modular Multiplication. Given a modulus n and two integers
x and y, of size v in base b, with gcd(n, b) = 1 and r = bâŒˆlogb(n)âŒ‰, MontMul
algorithm computes:
MontMul(x, y, n) = x Ã— y Ã— râˆ’1 mod n
Refer to papers [Mon85] and [KAK96] for details of MontMul implementation.
We denote by ModMul(x,y,n) the operation xÃ—y mod n, it can be done using
Barrett or Montgomery processing.
Then the Square and Multiply algorithm used for an exponentiation becomes:
Algorithm 2.2 Exponentiation
Input: integers m and n with m < n, k-bit exponent d = (dkâˆ’1dkâˆ’2 . . . d1d0)2
Output: Exp(m,d,n)= md mod n
Step 1. a = 1
Step 2. Process ModMul precomputations
Step 3. for i from k âˆ’1 to 0 do
a = ModMul(a,a,n)
if di = 1 then a = ModMul(a,m,n)
Step 4. Return(a)
2.3
The RSA Cryptosystem
Let p and q be two secret prime integers and n = pÃ—q be the public modulus used
in the RSA cryptosystem. Let e be the public exponent and d the corresponding

68
J.-C. Courr`ege, B. Feix, and M. Roussellet
private exponent such that e Â· d = 1 mod Ï†(n) where Ï†(n) = (p âˆ’1)(q âˆ’1).
Signing with RSA a message m consists of computing the value s = md mod n.
Signature s is then veriï¬ed by checking that se mod n is equal to m.
3
Simple Power Analysis
Power Analysis has been studied for years since it was introduced by Kocher,
Jaï¬€e and Jun in [KJJ99]. Many attacks on the most frequently used cryptosys-
tems (DES, AES, RSA, ECC . . . ) have been published and improvements on
power analysis techniques have been done during the last decade. For example
Correlation Power Analysis publication from Brier, Clavier and Olivier [BCO04]
requires far fewer curves for recovering the key than the original DPA. More re-
cently many studies have been published to improve the Side Channel method-
ology [GBTP08], [SGV08], [PR09].
The initial publication [KJJ99] on SPA showed how to recover the secret
exponent during a modular exponentiation from a single power consumption
curve. Impressive results are obtained when the squaring and the multiplying
operations have diï¬€erent recognizable and sizeable patterns. If so the bits of the
secret exponent can directly be read on the power curve of a classical Square
and Multiply algorithm. Indeed two consecutives squares on the curve imply the
exponent bit is 0 while when a squaring is followed by a multiplication the
exponent bit is 1.
This SPA corresponds to the power leakage related to diï¬€erences in the
executed code. The leakage is caused by the fact that the executed code is
diï¬€erent for a squaring than for a multiplication. An eï¬ƒcient countermeasure
against this SPA is the Side-Channel Atomicity introduced by Chevalier-Mames,
Ciet and Joye [CCJ04]. In their implementation the code executed during the
whole exponentiation loop is the same for a squaring and a multiplication step.
Consequently, it is no more possible to distinguish which operation is performed.
Their method improves resistance to classical SPA without adding supplementary
multiplications contrary to the Square and Multiply Always algorithm.
Yen et al. introduced in [YLMH05] a new type of SPA attack based on the
use of particular message values. It defeats previous countermeasures considered
as resistant against SPA. In their paper Yen et al. use as an input message
m = n âˆ’1 for modular exponentiation. The only two values involved during
the exponentiation md mod n are 1 and n âˆ’1. The Hamming weights of these
data are so diï¬€erent by simply observing the power trace, it is very easy to
determine the moments when 1 is involved in a multiplication. Only three
diï¬€erent operation cases can be processed during the exponentiation: 1 Ã— 1,
1 Ã— n âˆ’1 or n âˆ’1 Ã— n âˆ’1 with three diï¬€erent and recognizable signal patterns.
It is then simple to deduce the sequence of squarings and multiplications and to
recover the secret exponent.
Other attacks named Doubling and Collision attacks have been presented in
[FV03] and [YLMH05] but they need at least two executions of an exponentiation
with the same exponent to mount the attack. However in this paper we choose

Simple Power Analysis on Exponentiation Revisited
69
to only consider attacks recovering the secret from a single power consumption
curve and thus counterfeiting the exponent blinding countermeasure.Therefore
we do not consider Doubling and Collision attacks here.
4
Enhanced Simple Power Analysis on Exponentiation
In Yen et al. attack and the other techniques introduced in this paper, SPA does
not aim at distinguishing diï¬€erences in code execution but rather to detect when
speciï¬c data are manipulated through their speciï¬c power signature. Indeed
power signatures during an operation (x Ã— y) or (x Ã— y mod n) will depend on
values x and y. If x and/or y have very particular Hamming weights then it
will lead to a very characteristic power trace for the multiplication. We present
here many values which can generate a recognizable pattern and thus lead to
the exponent being recovered from a single power trace.
We illustrate our analysis on the ModMul operation using the Barrett reduc-
tion and especially during the computation of LIM(x,y). The same analysis can
be done in other kind of modular multiplication methods, for instance in the
modular Montgomery multiplication method MontMul(x,y).
4.1
Origin of Power Leakage
The power leakage appears during the operation xi Ã— yj of the long integer
multiplication LIM(x,y). Any operation xi Ã—yj has a power consumption related
to the number of bit ï¬‚ips of the bit lines manipulated. When one of the operands
is null or has very few bits set, for instance is equal to 0, or 2i with i in 0 . . . tâˆ’1,
the t-bit multiplication has a lower power consumption than the average one.
We can then distinguish in a long integer multiplication when such a value is
manipulated.
If the value of the multiplicand m contains one (or more) of the t-bit word(s) set
to 0 or 2i with i in 0 . . . tâˆ’1, during an atomic exponentiation loop we can recognize
each time this value m is manipulated, i.e. each time the exponent bit is 1.
The condition for this SPA to succeed is that one (or more) of the t-bit word(s)
of x or y is set to 0 (or in some cases it could be also to 2i with i in 0 . . . t âˆ’1).
We consider here that the leakage appears only for zero values.
We can then quantify the power consumed by the device for computing xiÃ—yj.
We denote by C(xi, yj) this power consumption . As illustrated in Table 1 we
can distinguish three categories depending on whether xi and yj values are 0
or not.
When xi = 0 and yj = 0 the device only manipulates zero bits. Thus the
amount of power consumed by the multiplication is Low, we denote it as CLow.
A multiplication with non zero values (xi Ì¸= 0 and yj Ì¸= 0) yields a higher power
consumption: we consider this as High and denote it as CHigh. Finally when
xi Ì¸= 0 and yj = 0 the amount of power consumed by a multiplication is consid-
ered as Medium: we denote it as CMedium.

70
J.-C. Courr`ege, B. Feix, and M. Roussellet
Table 1. Power Signal quantity for xi Ã— yj
xi
yj
C(xi, yj)
xi Ì¸
= 0
yj Ì¸
= 0
CHigh
xi Ì¸
= 0
yj = 0
CMedium
xi = 0
yj = 0
CLow
In the operation LIM(x,y) we can graphically estimate the power curve by
CLIM(x,y) = kâˆ’1
i=0
kâˆ’1
j=0 C(xi, yj) Â· T (k, i, j) with C(xi, yj) being the power
consumption of the device for computing xi Ã— yj and T a function which
represents the number of cycles executed for a set (k, i, j). This corresponds
to the schematic power curve of Figure 1.
A graphical estimation of power consumption expected depending on whether
we have CHigh, CMedium or CLow is given in Figure 2.
Fig. 1. CLIM(x,y): power curve representation
of operation LIM(x,y) with k = 4
Fig. 2. Three cases of estimated power
curves for C(xi, yj)
When an operation xi Ã— yj leads to C(xi, yj) being CLow or CMedium we can
identify this operation in the curve. This explains why the SPA introduced by Yen
et al. allows the secret exponent recovering with a single curve for a well chosen
message. Indeed when comparing the three possible operations occurring in an
exponentiation with the input chosen message m = n âˆ’1 we obtain for k = 3
the Table 2. In this table we observe that CLIM(x,y) has diï¬€erent recognizable
patterns for each long integer multiplication.
Table 2. The three possible power traces for LIM(x,y) in Yen et al.â€™s attack for k = 3
x Ã— y
x in base b
y in base b
CLIM(x,y)
(n âˆ’1) Ã— (n âˆ’1) a = (a2, a1, a0)b
a = (a2, a1, a0)b
CH|CH|CH|CH|CH|CH|CH|CH|CH
1 Ã— (n âˆ’1)
a = (0, 0, 1)b
m = (m2, m1, m0)b CH|CM|CM|CH|CM|CM|CH|CM|CM
1 Ã— 1
a = (0, 0, 1)b
a = (0, 0, 1)b
CH|CM|CM|CM|CL|CL|CM|CL|CL

Simple Power Analysis on Exponentiation Revisited
71
More Chosen Messages. From this analysis we can enumerate other chosen
messages leading to successful SPA on atomic exponentiations such as messages
with one or many t-bit word equal to 0 or 2i with i in 0 . . . t âˆ’1. Messages
with a globally low Hamming weight can also lead to a medium or low power
consumption and allow to recover the secret exponent in a single power curve.
4.2
Experiments and Practical Results
We experimented this attack on many diï¬€erent multipliers processors to conï¬rm
our theoretical analysis. In this section we present some results we obtained on
two diï¬€erent devices.
First Device. We implemented a Montgomery Modular exponentiation on a
32 Ã— 32-bit multiplier, in this case we have t equal to 32. We chose as input
messages for exponentiations the following values with k = 4: m1 = (Î±, Î±, 0, 0),
m2 = (Î±, 0, 0, 0) where Î± is 32-bit random value.
Fig. 3. Part of exponentiation power curves with messages m1 and m2 and k = 4,
zoom on LIM(m1,a) (black) and LIM(m2,a) (grey)
Figure 3 represents a part of the measured exponentiation curves of these
two messages. The black curve corresponds to the exponentiation with message
m1 and grey curve with m2. The multiplication is clearly identiï¬able by a lower
power consumption compared to the squaring. Message m2 takes one more 32-bit
word equal to 0 than m1. This results in Figure 3 in a low power consumption
longer for grey curve than for black curve during the multiplication.
In this case we also observed that CMedium is close to CHigh but the two can
be distinguished.
Second Device. We designed an 8 Ã— 64-bit hardware multiplier with the
associated long integer exponentiation. In the multiplication x Ã— y the operand
x is manipulated by 64-bit words when the operand y is taken by 8-bit words.

72
J.-C. Courr`ege, B. Feix, and M. Roussellet
The message is placed in the second operand y for the multiplications during
the exponentiation.
We chose several messages containing one or more zero 8-bit words and
executed the corresponding long integer exponentiations. We then simulated the
power consumption of the synthesized multiplier we have designed. By analyzing
these power curves we can observe that a zero byte yj in operand y produces a
lower power consumption curve in the cycles where yj is manipulated. We are
then able to recover the whole secret exponent in an exponentiation when a zero
byte is present in the message value.
We have explained here the potential power leakages related to multiplication
and exponentiation computations and conï¬rmed our analysis with some practical
results. In the next paragraph we study the probability of leakage depending on
the multiplier and modulus bit lengths.
4.3
Leakage Probability
In this paragraph letters p and q design probabilities.
Probability of leakage during a multiplication. Let xi be a t-bit word,
and p be the probability for xi to be null, then we have P(xi = 0) =
1
2t = p and
P(xi Ì¸= 0) = 1 âˆ’p.
If Y is the event {None of the t-bit word is null in a k-word integer} with
P(Y ) = (1 âˆ’p)k, then we have Y which corresponds to the event {at least one
of the t-bit words is null in a k-word integer} with probability:
q = P(Y ) = 1 âˆ’P(Y ) = 1 âˆ’(1 âˆ’p)k = 1 âˆ’(1 âˆ’1
2t )k
During a long integer modular multiplication x Ã— y the leakage appears only if
at least one of the k t-bit words of x or/and y is null. The probability for this
leakage to appear corresponds to 1 âˆ’(1 âˆ’p)2k.
Probability of leakage during an exponentiation. During an exponentia-
tion we focus on the probability of having a leakage in a t-bit multiplication xÃ—y
when only y takes part in the leakage and not x (or the opposite). Indeed during
an exponentiation md mod n the message m is used during each multiplication
at step 3 of Algorithm 2.2, when di = 1. Thus if the value m contains a t-bit
word mi leading to leakage in the operations mi Ã— aj and/or mi Ã— a then each
multiplication by mi and thus by m could be identiï¬ed and the secret exponent
d can be recovered from a single power curve.
In this case the probability of having one or many of the t-bit words of m
leading to a signing pattern is:
q = 1 âˆ’(1 âˆ’p)k = 1 âˆ’(1 âˆ’1
2t )k
This is also the probability of having an SPA leaking curve for a single execution
of the exponentiation.

Simple Power Analysis on Exponentiation Revisited
73
Fig. 4. Probability of having a message with a signing pattern depending of multiplier
size (t) and modulus size (1024, 1536, 2048)
In the case of an 8-bit multiplier Figure 4 shows that the probability of having
a message with a signing pattern is about 0.394 for a 1024-bit modulus, 0.528
for a 1536-bit modulus and 0.633 for a 2048-bit modulus. When the multiplier
is greater than 16 bits this probability decreases for all modulus sizes.
It also obvious that bigger the key length is and smaller the multiplier size
(t) is, the higher the probability of recovering the secret exponent d in a single
curve is.
Using Poisson law as an approximation of binomial law we have the property
that with 1/q exponentiation power curves the probability for recovering the
secret exponent is (1 âˆ’
1
exp(1)). Thus the probability Pleak of recovering the
secret exponent using one of the h/q acquired curves is approximated by
Pleak = P(h/q) = 1 âˆ’(
1
exp(1))h.
Figures 5 and 6 show how many curves would be needed to have, with a
probability close to 1, a message leading to a signing pattern which can be used
for our SPA attack. With an 8-bit multiplier (Figure 5), a very few messages
(5 to 10) are necessary to obtain an exploitable leakage with high probability.
Fig. 5. Probability Pleak for an 8-bit
multiplier depending on the number of
curves acquired and modulus size (1024,
1536, 2048)
Fig. 6. Probability Pleak for a 16-bit
multiplier depending on the number of
curves acquired and modulus size (1024,
1536, 2048)

74
J.-C. Courr`ege, B. Feix, and M. Roussellet
For a 16-bit multiplier (Figure 6) between 3000 and 5000 curves are needed for
a success probability close to 1. But for a multiplier size greater than 16 the
number of curves needed for recovering the secret exponent makes the attack
not practical; example is given for t = 32 in Appendix A.
The bigger the multiplier, the greater the number of collected curves needed.
Examples are given in Table 3.
Table 3. Number of messages needed to have Pleak â‰¥0.99
Modulus
Multiplier size
size
8
16
32
1024
12
4720
â‰ˆ229
1536
9
3150
â‰ˆ229
2048
8
2360
â‰ˆ228
4.4
Enhanced Simple Power Analysis on Blinded Exponentiations
In this section we consider that the exponentiation is secured using message and
exponent blinding.
Exponent Blinding. This common countermeasure consists in randomizing
the secret exponent d by dâ‹†= d+r1Â·n mod Ï†(n) with r1 being a random value.
However here the exponent blinding has no eï¬€ect on our analysis since a single
curve is used to recover the private exponent and recovering dâ‹†is equivalent to
recovering d.
Randomized Chosen Message. Now we consider that the message is ran-
domized additively by the classical countermeasure: mâ‹†= m+r1 Â·n mod r2 Â·n,
with r1 and r2 being two l-bit random values. In this case we have mâ‹†equal
to m + u Â· n with u being a l-bit value equal to r1 mod r2. In this case an at-
tack could consist of choosing a message mâ‹†being 1 or 2i, guessing a random
Fig. 7. Distribution of u for l = 8

Simple Power Analysis on Exponentiation Revisited
75
value uguess, computing message m from guessed randomized message mâ‹†, i.e.
m = mâ‹†âˆ’uguess Â· n, and executing at least 2l exponentiations with input mes-
sage m. One of the 2l exponentiation power curves should present leakages and
should allow the secret exponent to be recovered with SPA.
However if r1 and r2 are eï¬€ectively chosen in a pure random way we observe
that this attack could be done faster. Indeed if we analyze the distribution
of values u = r1 mod r2 we observe that values do not appear with same
probability and that the more frequent are the smallest ones. The most frequent
one being u = 0. It is illustrated in Figure 7 for l = 8. While less pronouced
the same phenomenon can also be observed for bigger l values. The best attack
method in this case would consist of choosing uguess = 0 (or 1 or 2) and executing
the exponentiation many times until a leaking power curve is obtained.
Unknown Message. When analyzing the leakage probabilities of Section 4.3
it appears that the number of curves needed to recover the secret exponent for
a ï¬xed multiplier size only depends on the modulus length, even if the message
is unknown to the attacker. For instance for a 1024-bit modulus and a 16-
bit multiplier by collecting 5000 power consumption curves of exponentiations
done with unknown diï¬€erent messages the probability of recovering the secret
exponent is close to 1.
Synthesis. As the additive randomization of the message does not signiï¬cantly
increase message length, the amount of messages needed does not increase either.
Thus if the attacker can choose input messages of the blinded exponentiation,
he will choose the attack which requires less eï¬€ort comparing number of chosen
message acquisitions needed (when guessing the random) with the number of
curves to collect to have PLeak = 1.
5
Countermeasures and Recommendations
5.1
Balancing the Power Consumption
The attack presented in this paper is based on the fact that manipulating zero t-
bit values results in low power consumption cycles. Thus a method to prevent this
attack would consist in using balanced power consumption technology such as
dual rail technique. In this case the manipulation of a value with a low Hamming
weight (for instance 0) will no longer have a diï¬€erent power consumption than
the one due to the manipulation of other values.
5.2
Random Choice for Blinding
As we showed previously the values r1 mod r2 are not uniformly distributed
when r1 and r2 are random. A better solution consists of choosing a ï¬xed value
for r2 and a random value for r1. From our analysis the best choice for r2 is

76
J.-C. Courr`ege, B. Feix, and M. Roussellet
Fig. 8. Distribution of u for l = 8 and r2 = 251
to take the biggest l-bit prime number. In that case r2 will never divide r1,
thus u cannot be null and u values are uniformly distributed as it is showed in
Figure 8.
Another consideration is that the random length choice is also directly related
to the multiplier size. In section 4.4 we have seen that while the number of
possible random values u is smaller than the number of messages to test given by
the leakage probability analysis, it is easier to test all random values u. Regarding
this statistical properties we showed that when the multiplier is small (8 or 16
bits) the quantity of curves needed for a successful Simple Power Analysis is
reasonable.
Thus by combining a multiplier with a size of at least equal to 32 bits, with
big random number r1 (longer than 32 or 64 bits) and the biggest prime integer
r2, the feasibility of the attack explained in this paper is signiï¬cantly reduced.
6
Remarks on RSA CRT and ECC
We presented our analysis on exponentiation computations. It corresponds di-
rectly to straightforward implementations of RSA signature and decryption al-
gorithms as they simply consist of an exponentiation with the secret exponent.
In case of RSA CRT the analysis is a little bit diï¬€erent since the input message
is reduced modulo p and q before the exponentiations. Even if data manipulated
into the multiplications are twice shorter than the modulus n, similar analy-
sis can be conducted on reduced messages. However the countermeasure which
consists in ï¬xing the random value r2, must not be used in RSA CRT implemen-
tations as it would not be protected against the correlation analysis on the CRT
recombination presented in [AFV07].
ECC are also concerned. The analysis depends on the kind of coordinates and
algorithm chosen for the scalar multiplication, anyway implementations using
small multipliers and/or small random numbers for coordinates randomization
[Cor99] have to be avoided.

Simple Power Analysis on Exponentiation Revisited
77
7
Conclusion
In this paper we have explained the origin of the power leakages during
multiplications and presented other ways to mount Simple Power Analysis
attacks. Indeed by observing diï¬€erences in data power signatures instead of
diï¬€erences in code execution, using some well chosen messages allows the whole
secret exponent of RSA cryptosystem to be recovered from a single curve.
Moreover we have shown that some improvements in SPA attacks lead to
the recovery of the secret exponent on secured exponentiations using blinding
countermeasures and with non chosen messages. We analyzed the blinding
countermeasures and gave advice to developers to protect their implementations
against this enhanced SPA. Judicious choice and large random numbers in
blinding countermeasures combined with large size multipliers, especially greater
than 32 bits, are recommended for SPA resistance.
Acknowledgments
The authors would like to thank Christophe Clavier for the fruitful discussions we
had and the improvements he suggested to us. Thanks also to Sean Commercial
and Vincent Verneuil for their valuable comments and advice on this manuscript.
References
[ACD+06]
Avanzi, R.-M., Cohen, H., Doche, C., Frey, G., Lange, T., Nguyen, K.,
Verkauteren, F.: Handbook of Elliptic and Hyperelliptic Curve Cryptog-
raphy (2006)
[AFV07]
Amiel, F., Feix, B., Villegas, K.: Power Analysis for Secret Recovering
and Reverse Engineering of Public Key Algorithms. In: Adams, C., Miri,
A., Wiener, M. (eds.) SAC 2007. LNCS, vol. 4876, pp. 110â€“125. Springer,
Heidelberg (2007)
[BCO04]
Brier, E., Clavier, C., Olivier, F.: Correlation Power Analysis with a
Leakage Model. In: Joye, M., Quisquater, J.-J. (eds.) CHES 2004. LNCS,
vol. 3156, pp. 16â€“29. Springer, Heidelberg (2004)
[CCJ04]
Chevallier-Mames, B., Ciet, M., Joye, M.: Low-cost Solutions for Prevent-
ing Simple Side-Channel Analysis: side-channel atomicity. IEEE Transac-
tions on Computers 53(6), 760â€“768 (2004)
[Cor99]
Coron, J.-S.: Resistance against diï¬€erential power analysis for elliptic
curve cryptosystems. In: KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 1999. LNCS,
vol. 1717, pp. 292â€“302. Springer, Heidelberg (1999)
[DH76]
Diï¬ƒe, W., Hellman, M.E.: New Directions in cryptography. IEEE Trans-
actions on Information Theory 22(6), 644â€“654 (1976)
[Dhe98]
Dhem, J.-F.: Design of an eï¬ƒcient public-key cryptographic library for
RISC-based smart cards. PhD thesis, UniversitÂ´e catholique de Louvain,
Louvain (1998)

78
J.-C. Courr`ege, B. Feix, and M. Roussellet
[FV03]
Fouque, P.-A., Valette, F.: The Doubling Attack - why upwards is better
than downwards. In: Walter, C.D., KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2003.
LNCS, vol. 2779, pp. 269â€“280. Springer, Heidelberg (2003)
[GBTP08]
Gierlichs, B., Batina, L., Tuyls, P., Preneel, B.: Mutual Information
Analysis. In: Oswald, E., Rohatgi, P. (eds.) CHES 2008. LNCS, vol. 5154,
pp. 426â€“442. Springer, Heidelberg (2008)
[KAK96]
KoÂ¸c, CÂ¸.K., Acar, T., Kaliski, B.-S.: Analysing and comparing Montgomery
multiplication algorithms. IEEE Micro 16(3), 26â€“33 (1996)
[KJJ99]
Kocher, P.C., Jaï¬€e, J., Jun, B.: Diï¬€erential Power Analysis. In: Wiener, M.
(ed.) CRYPTO 1999. LNCS, vol. 1666, pp. 388â€“397. Springer, Heidelberg
(1999)
[Koc96]
Kocher, P.C.: Timing attacks on implementations of Diï¬ƒe-Hellman, RSA,
DSS, and other systems. In: Koblitz, N. (ed.) CRYPTO 1996. LNCS,
vol. 1109, pp. 104â€“113. Springer, Heidelberg (1996)
[Mon85]
Montgomery, P.L.: Modular multiplication without trial division. Mathe-
matics of Computation 44(170), 519â€“521 (1985)
[MOV96]
Menezes, A., van Oorschot, P.C., Vanstone, S.A.: Handbook of Applied
Cryptography. CRC Press, Boca Raton (1996)
[PR09]
Prouï¬€, E., Rivain, M.: Theoretical and practical aspects of mutual in-
formation based side channel analysis. In: Abdalla, M., Pointcheval, D.,
Fouque, P.-A., Vergnaud, D. (eds.) ACNS 2009. LNCS, vol. 5536, pp.
499â€“518. Springer, Heidelberg (2009)
[RSA78]
Rivest, R.L., Shamir, A., Adleman, L.: A method for obtaining digital
signatures and public-key cryptosystems. Communications of the ACM 21,
120â€“126 (1978)
[SGV08]
Standaert, F.-X., Gierlichs, B., Verbauwhede, I.: Partition vs. comparison
side-channel distinguishers: An empirical evaluation of statistical tests for
univariate side-channel attacks against two unprotected cmos devices. In:
Lee, P.J., Cheon, J.H. (eds.) ICISC 2008. LNCS, vol. 5461, pp. 253â€“267.
Springer, Heidelberg (2009)
[YLMH05]
Yen, S.-M., Lien, W.-C., Moon, S., Ha, J.: Power Analysis by Exploiting
Chosen Message and Internal Collisions - Vulnerability of Checking Mech-
anism for RSA-decryption. In: Dawson, E., Vaudenay, S. (eds.) Mycrypt
2005. LNCS, vol. 3715, pp. 183â€“195. Springer, Heidelberg (2005)

Simple Power Analysis on Exponentiation Revisited
79
A
Leakage Probability for t Up to 32
The following ï¬gures give the probability of leakage for a 32-bit multiplier and
the leakage probability increasement regarding the number of exponentiation
executions.
Fig. 9. Probability of having a message with a signing pattern for 32-bit multiplier
depending on modulus size (1024, 1536, 2048)
Fig. 10. Probability Pleak for a 32-bit multiplier depending on the number of curves
acquired and modulus size (1024, 1536, 2048)

Atomicity Improvement for Elliptic Curve Scalar
Multiplication
Christophe Giraud1 and Vincent Verneuil2,3,â‹†
1 Oberthur Technologies,
4, allÂ´ee du doyen Georges Brus, 33 600 Pessac, France
c.giraud@oberthur.com
2 Inside Contactless,
41, parc du Golf, 13 856 Aix-en-Provence cedex 3, France
vverneuil@insidefr.com
3 Institut de MathÂ´ematiques de Bordeaux,
351, cours de la LibÂ´eration, 33 405 Talence cedex, France
Abstract. In this paper we address the problem of protecting elliptic
curve scalar multiplication implementations against side-channel analysis
by using the atomicity principle. First of all we reexamine classical as-
sumptions made by scalar multiplication designers and we point out that
some of them are not relevant in the context of embedded devices. We
then describe the state-of-the-art of atomic scalar multiplication and pro-
pose an atomic pattern improvement method. Compared to the most ef-
ï¬cient atomic scalar multiplication published so far, our technique shows
an average improvement of up to 10.6%.
Keywords: Elliptic Curves, Scalar Multiplication, Atomicity, Side-
Channel Analysis.
1
Introduction
1.1
Preamble
We consider the problem of performing scalar multiplication on elliptic curves
over Fp in the context of embedded devices such as smart cards. In this con-
text, eï¬ƒciency and side-channel resistance are of utmost importance. Concerning
the achievement of the ï¬rst requirement, numerous studies dealing with scalar
multiplication eï¬ƒciency have given rise to eï¬ƒcient algorithms including sliding-
window and signed representation based methods [19].
Regarding the second requirement, side-channel attacks exploit the fact that
physical leakages of a device (timing, power consumption, electromagnetic radia-
tion, etc) depend on the operations performed and on the variables manipulated.
These attacks can be divided into two groups: the Simple Side-Channel Anal-
ysis (SSCA) [25] which tries to observe a diï¬€erence of behavior depending on
the value of the secret key by using a single measurement, and the Diï¬€eren-
tial Side-Channel Analysis (DSCA) [26] which exploits data value leakages by
â‹†A part of this work has been done while at Oberthur Technologies.
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 80â€“101, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Atomicity Improvement for Elliptic Curve Scalar Multiplication
81
performing statistical treatment over several hundreds of measurements to re-
trieve information on the secret key. Since 1996, many proposals have been made
to protect scalar multiplication against these attacks [12,23,7]. Amongst them,
atomicity introduced by Chevallier-Mames et al. in [9] is one of the most interest-
ing methods to counteract SSCA. This countermeasure has been widely studied
and Longa recently proposed an improvement for some scalar multiplication
algorithms [27].
In this paper we present a new atomicity implementation for scalar multi-
plication, and we detail the atomicity improvement method we employed. This
method can be applied to minimize atomicity implementation cost for sensitive
algorithms with no security loss. In particular our method allows the implemen-
tation of atomic scalar multiplication in embedded devices in a more eï¬ƒcient
way than any of the previous methods.
The rest of this paper is organized as follows. We ï¬nish this introduction
by describing the scalar multiplication context which we are interested in and
by mentioning an important observation on the cost of ï¬eld additions. In Sec-
tion 2 we recall some basics about Elliptic Curves Cryptography. In particular
we present an eï¬ƒcient scalar multiplication algorithm introduced by Joye in
2008 [21]. Then we recall in Section 3 the principle of atomicity and we draw
up a comparative chart of the eï¬ƒciency of atomic scalar multiplication algo-
rithms before this work. In Section 4, we propose an improvement of the original
atomicity principle. In particular, we show that our method, applied to Joyeâ€™s
scalar multiplication, allows a substantial gain of time compared to the original
atomicity principle. Finally, Section 5 concludes this paper.
1.2
Context of the Study
We restrict the context of this paper to practical applications on embedded
devices which yields the constraint of using standardized curves over Fp1. As far
as we know, NIST curves [17] and Brainpool curves [14,15] cover almost all curves
currently used in the industry. We thus exclude from our scope Montgomery
curves [32], Hessian curves [20], and Edwards curves2 [16] which do not cover
NIST neither Brainpool curves.
Considering that embedded devices â€“ in particular smart cards â€“ have very
constrained resources (i.e. RAM and CPU), methods requiring heavy scalar
treatment are discarded as well. In particular it is impossible to store scalar pre-
computations for some protocols such as ECDSA [1] where the scalar is randomly
generated before each scalar multiplication. Most of the recent advances in this
1 The curves over Fp are generally recommended for practical applications [33,34].
2 An elliptic curve over Fp is expressible in Edwards form only if it has a point of
order 4 [6] and is expressible in twisted Edwards form only if it has three points
of order 2 [4]. Since NIST and Brainpool curves have a cofactor of 1 there is not
such equivalence. Nevertheless, for each of these curves, it is possible to ï¬nd an
extension ï¬eld Fpq over which the curve has a point of order 4 and is thus birationally
equivalent to an Edwards curve. However the cost of a scalar multiplication over Fpq
is prohibitive in the context of embedded devices.

82
C. Giraud and V. Verneuil
ï¬eld cannot thus be taken into account: Double Base Number System [13, 31],
multibase representation [28], Euclidean addition chains and Zeckendorf repre-
sentation [30].
1.3
On the Cost of Field Additions
In the literature, the cost of additions and subtractions over Fp is generally
neglected compared to the cost of ï¬eld multiplication. While this assumption
is relevant in theory, we found out that these operations were not as insigniï¬-
cant as predicted for embedded devices. Smart cards for example have crypto-
coprocessors in order to perform multi-precision arithmetic. These devices
generally oï¬€er the following operations: addition, subtraction, multiplication,
modular multiplication and sometimes modular squaring. Modular addition (re-
spectively subtraction) must therefore be carried out by one classical addition
(resp. subtraction) and one conditional subtraction (resp. addition) which should
always be performed â€“ i.e. the eï¬€ective operation or a dummy one â€“ for SSCA
immunity. Moreover every operation carried out by the coprocessor requires
a constant extra software processing Î´ to conï¬gure the coprocessor. As a re-
sult, the cost of ï¬eld additions/subtractions is not negligible compared to ï¬eld
multiplications. Fig. 1 is an electromagnetic radiation measurement during the
execution on a smart card of a 192-bit modular multiplication followed by a mod-
ular addition. Large amplitude blocks represent the 32-bit crypto-coprocessor
activity while those with smaller amplitude are only CPU processing. In this
case the time ratio between modular multiplication and modular addition is
approximately 0.3.
From experiments on diï¬€erent smart cards provided with an arithmetic copro-
cessor, we estimated the average cost of modular additions/subtractions
Fig. 1. Comparison between modular multiplication (M) and modular addition (A)
timings

Atomicity Improvement for Elliptic Curve Scalar Multiplication
83
Table 1. Measured A/M ratio on smart cards with crypto-coprocessor for NIST and
Brainpool ECC bit lengths
Bit length 160
192
224
256
320
384
512
521
A/M
0.36 0.30 0.25 0.22 0.16 0.13 0.09 0.09
compared to modular multiplications. Our results are presented in Table 1 where
A and M denote the cost of a ï¬eld addition/subtraction and the cost of a ï¬eld
multiplication respectively. We observe that the average value of A/M for con-
sidered bit lengths is about 0.2.
Another useful ï¬eld operation is negation in Fp, i.e. the map x â†’âˆ’x, which
can be carried out by one non-modular subtraction p âˆ’x. The cost N of this
operation is therefore half the cost of modular addition/subtraction and thus we
ï¬x N/M = 0.5 A/M.
In the following sections we also consider the cost S of ï¬eld squaring. The
cost of a squaring compared to a multiplication depends on the functionalities
of the corresponding crypto-coprocessor. When a dedicated squaring is available
a commonly accepted value for S/M is 0.8 [8,18] which is also corroborated by
our experiments. Otherwise squarings must be carried out as multiplications and
the ratio S/M is thus 1.
2
Elliptic Curves
In this section we recall some generalities about elliptic curves, and useful point
representations. Then we present two eï¬ƒcient scalar multiplication algorithms.
Cryptology makes use of elliptic curves over binary ï¬elds F2n and large char-
acteristic prime ï¬elds Fp. In this study we focus on the latter case and hence
assume p > 3.
2.1
Group Law over Fp
An elliptic curve E over Fp, p > 3 can be deï¬ned as an algebraic curve of aï¬ƒne
WeierstraÃŸ equation:
E : y2 = x3 + ax + b
(1)
where a, b âˆˆFp and 4a3 + 27b2 Ì¸â‰¡0 (mod p).
The set of points of E â€“ i.e. the pairs (x, y) âˆˆFp
2 satisfying (1) â€“, plus an extra
point O called point at inï¬nity form an abelian group where O is the neutral
element. In the following, we present the corresponding law depending on the
selected point representation.
Aï¬ƒne Coordinates. Under the group law a point P = (x1, y1) lying on the
elliptic curve E admits an opposite âˆ’P = (x1, âˆ’y1).
The sum of P = (x1, y1) and Q = (x2, y2), with P, Q Ì¸= O and P Ì¸= Â±Q, is
the point P + Q = (x3, y3) such that:

x3 = ((y2 âˆ’y1)/(x2 âˆ’x1))2 âˆ’x1 âˆ’x2
y3 = (x1 âˆ’x3)(y2 âˆ’y1)/(x2 âˆ’x1) âˆ’y1
(2)

84
C. Giraud and V. Verneuil
The double of the point P = (x1, y1), with P Ì¸= O and y1 Ì¸= 0, is the point
2P = (x2, y2) as deï¬ned below, or O if y1 = 0.
x2 = ((3x12 + a)/(2y1))2 âˆ’2x1
y2 = (x1 âˆ’x2)(3x12 + a)/(2y1) âˆ’y1
(3)
Each point addition or point doubling requires an inversion in Fp. This opera-
tion can be very time consuming and leads developers on embedded devices to
use other kinds of representations with which point operations involve no ï¬eld
inversion. In the following part of this section, we detail two of them.
Jacobian Projective Coordinates. By denoting x = X/Z2 and y = Y/Z3,
Z Ì¸= 0, we obtain the Jacobian projective WeierstraÃŸ equation of the elliptic
curve E:
Y 2 = X3 + aXZ4 + bZ6 ,
(4)
where a, b âˆˆFp and 4a3 +27b2 Ì¸= 0. Each point P = (x, y) can be represented by
its Jacobian projective coordinates (q2x : q3y : q) with q âˆˆFp. Conversely, every
point P = (X : Y : Z) diï¬€erent from O can be represented in aï¬ƒne coordinates
by (x, y) = (X/Z2, Y/Z3).
The opposite of a point (X : Y : Z) is (X : âˆ’Y : Z) and the point at inï¬nity
O is denoted by the unique point with Z = 0, O = (1 : 1 : 0).
The sum of P = (X1 : Y1 : Z1) and Q = (X2 : Y2 : Z2), with P, Q Ì¸= O and
P Ì¸= Â±Q, is the point P + Q = (X3 : Y3 : Z3) such that:
â§
â¨
â©
X3 = F 2 âˆ’E3 âˆ’2AE2
Y3 = F

AE2 âˆ’X3

âˆ’CE3
Z3 = Z1Z2E
with
A = X1Z2
2
B = X2Z1
2
C = Y1Z2
3
D = Y2Z1
3
E = B âˆ’A
F = D âˆ’C
(5)
If P is given in aï¬ƒne coordinates â€“ i.e. Z1 = 1 â€“ it is possible to save up one
ï¬eld squaring and four multiplications in (5). Such a case is referred to as mixed
aï¬ƒne-Jacobian addition. On the other hand if P has to be added several times,
storing Z1
2 and Z1
3 saves one squaring and one multiplication in all following
additions involving P. This latter case is referred to as readdition.
The double of the point P = (X1 : Y1 : Z1) is the point 2P = (X2 : Y2 : Z2)
such that:
â§
â¨
â©
X2 = C2 âˆ’2B
Y2 = C (B âˆ’X2) âˆ’2A2
Z2 = 2Y1Z1
with
A = 2Y1
2
B = 2AX1
C = 3X1
2 + aZ1
4
(6)
When curve parameter a is âˆ’3, doubling can be carried out taking C = 3

X1 + Z1
2 
X1 âˆ’Z1
2
which saves two squarings in (6). We denote this opera-
tion by fast doubling.
Adding up ï¬eld operations yields 12M +4S +7A for general addition, 11M +
3S + 7A for readdition, 8M + 3S + 7A for mixed addition, 4M + 6S + 11A for
general doubling formula and 4M + 4S + 12A for fast doubling.

Atomicity Improvement for Elliptic Curve Scalar Multiplication
85
Modiï¬ed Jacobian Projective Coordinates. This representation, intro-
duced in [11], is derived from the Jacobian projective representation to which a
fourth coordinate is added for computation convenience. In this representation, a
point on the curve E is thus represented by (X : Y : Z : aZ4), where (X : Y : Z)
stands for the Jacobian representation.
Modiï¬ed Jacobian projective coordinates provide a particularly eï¬ƒcient dou-
bling formula. Indeed, the double of a point P = (X1 : Y1 : Z1 : W1) is given by
2P = (X2 : Y2 : Z2 : W2) such that:
â§
âª
âª
â¨
âª
âª
â©
X2 = A2 âˆ’2C
Y2 = A (C âˆ’X2) âˆ’D
Z2 = 2Y1Z1
W2 = 2DW1
with
A = 3X1
2 + W1
B = 2Y1
2
C = 2BX1
D = 2B2
(7)
Doubling hence requires only 4M + 4S + 12A for all a values. On the other
hand, addition is less eï¬ƒcient compared to Jacobian projective representation:
by applying formula (5), we need to compute the fourth coordinate which is
required in point doubling, adding an overhead of 1M + 2S [21].
On Sâ€“M Trade-Oï¬€s. Addition and doubling formulas presented above are
voluntarily not state-of-the-art, see [5]. Indeed, recent advances have provided
Jacobian formulas where some ï¬eld multiplications have been traded for faster
ï¬eld squarings [27, Sec. 4.1]. These advances have been achieved by using the
so-called Sâ€“M trade-oï¬€principle which is based on the fact that computing ab
when a2 and b2 are known can be done as 2ab = (a + b)2 âˆ’a2 âˆ’b2. This allows a
squaring to replace a multiplication since the additional factor 2 can be handled
by considering the representative of the Jacobian coordinates equivalence class
(X : Y : Z) = (22X : 23Y : 2Z).
Nevertheless such trade-oï¬€s not only replace ï¬eld multiplications by ï¬eld
squarings but also add ï¬eld additions. In the previous example at least 3 ex-
tra additions have to be performed, thus taking S/M = 0.8 implies that the
trade-oï¬€is proï¬table only if A/M < 0.067 which is never the case with devices
considered using standardized curves as seen in Section 1.3. These new formulas
are thus not relevant in the context of embedded devices.
2.2
Scalar Multiplication
Generalities. The operation consisting in calculating the multiple of a point
k Â· P = P + P + Â· Â· Â· + P (k times) is called scalar multiplication and the integer
k is thus referred to as the scalar.
Scalar multiplication is used in ECDSA signature [1] and ECDH key agree-
ment [2] protocols. Implementing such protocols on embedded devices requires
particular care from both the eï¬ƒciency and the security points of view. In-
deed scalar multiplication turns out to be the most time consuming part of the
aforementioned protocols, and since it uses secret values as scalars, side-channel
analysis endangers the security of those protocols.

86
C. Giraud and V. Verneuil
Most of the scalar multiplication algorithms published so far are derived from
the traditional double and add algorithm. This algorithm can scan the binary
representation of the scalar in both directions which leads to the left-to-right
and right-to-left variants. The former is generally preferred over the latter since
it saves one point in memory.
Moreover since computing the opposite of a point P on an elliptic curve is
virtually free, the most eï¬ƒcient methods for scalar multiplication use signed
digit representations such as the Non-Adjacent Form (NAF) [3]. Under the NAF
representation, an n-bit scalar has an average Hamming weight of n/3 which
implies that one point doubling is performed every bit of scalar and one point
addition is performed every three bits.
In the two next subsections, we present a left-to-right and a right-to-left NAF
scalar multiplication algorithms.
Left To Right Binary NAF Scalar Multiplication. Alg. 1 presents the
classical NAF scalar multiplication algorithm.
Algorithm 1. Left-to-right binary NAF scalar multiplication [19]
Inputs : P = (X1 : Y1 : Z1) âˆˆE (Fp), k = (klâˆ’1 . . . k1k0)NAF
Output : k Â· P
1. (X2 : Y2 : Z2) â†(X1 : Y1 : Z1)
2. i â†l âˆ’2
3. while i â‰¥0 do
(X2 : Y2 : Z2) â†2 Â· (X2 : Y2 : Z2)
if ki = 1 then
(X2 : Y2 : Z2) â†(X2 : Y2 : Z2) + (X1 : Y1 : Z1)
if ki = âˆ’1 then
(X2 : Y2 : Z2) â†(X2 : Y2 : Z2) âˆ’(X1 : Y1 : Z1)
i â†i âˆ’1
4. return (X2 : Y2 : Z2)
Point doubling can be done in Alg. 1 using general Jacobian doubling formula
or fast doubling formula. Since NIST curves fulï¬ll a = âˆ’3 and each Brainpool
curve is provided with an isomorphism to a curve with a = âˆ’3, we thus assume
that fast doubling is always possible. Point addition can be performed using
mixed addition formula if input points are given in aï¬ƒne coordinates or by
using readdition formula otherwise.
It is possible to reduce the number of point additions by using window tech-
niques3 which need the precomputation of some ï¬rst odd multiples of the point
P. Table 2 recalls the number of point additions per bit of scalar when having
from 0 (simple NAF) to 4 precomputed points. More than 4 points allows even
better results but seems not practical in the context of constrained memory.
3 By window techniques we mean the sliding window NAF and the Window NAFw
algorithms, see [19] for more details.

Atomicity Improvement for Elliptic Curve Scalar Multiplication
87
Table 2. Average number of point additions per bit of scalar using window NAF
algorithms
Nb. of precomp. points
0
1
2
3
4
Precomputed points
â€“
3P
3P, 5P
3P, 5P, 7P
3P, . . . , 9P
Point additions / bit
1/3 â‰ˆ0.33 1/4 = 0.25 2/9 â‰ˆ0.22 1/5 = 0.20 4/21 â‰ˆ0.19
Right To Left Binary NAF Mixed Coordinates Multiplication. We
recall here a very eï¬ƒcient algorithm performing right-to-left NAF scalar multi-
plication. Indeed this algorithm uses the fast modiï¬ed Jacobian doubling formula
which works for all curves â€“ i.e. for all a â€“ without needing the slow modiï¬ed
Jacobian addition.
This is achieved by reusing the idea of mixed coordinates scalar multiplication
(i.e. two coordinate systems are used simultaneously) introduced by Cohen, Ono
and Miyaji in [11]. The aim of this approach is to make the best use of two coor-
dinates systems by processing some operations with one system and others with
the second. Joye proposed in [21] to perform additions by using Jacobian coor-
dinates, doublings â€“ referred to as âˆ—â€“ by using modiï¬ed Jacobian coordinates,
and to compute the NAF representation of the scalar on-the-ï¬‚y, cf. Alg. 24.
In the same way as their left-to-right counterpart beneï¬ts from precomputed
points, right-to-left algorithms can be enhanced using window techniques if ex-
tra memory is available [35, 22]. In this case precomputations are replaced by
postcomputations the cost of which is negligible for the considered window sizes
and bit lengths.
Algorithm 2. Right-to-left binary NAF mixed coordinates multiplication [21]
Inputs : P = (X1 : Y1 : Z1) âˆˆE (Fp), k
Output : k Â· P
1. (X2 : Y2 : Z2) â†(1 : 1 : 0)
2. (R1 : R2 : R3 : R4) â†(X1 : Y1 : Z1 : aZ1
4)
3. while k > 1 do
if k â‰¡1 mod 2 then
u â†2 âˆ’(k mod 4)
k â†k âˆ’u
if u = 1 then
(X2 : Y2 : Z2) â†(X2 : Y2 : Z2) + (R1 : R2 : R3)
else
(X2 : Y2 : Z2) â†(X2 : Y2 : Z2) + (R1 : âˆ’R2 : R3)
k â†k/2
(R1 : R2 : R3 : R4) â†2 âˆ—(R1 : R2 : R3 : R4)
4. (X2 : Y2 : Z2) â†(X2 : Y2 : Z2) + (R1 : R2 : R3)
5. return (X2 : Y2 : Z2)
4 In Alg. 2, Jacobian addition is assumed to handle the special cases P = Â±Q, P = O,
Q = O as discussed in [21].

88
C. Giraud and V. Verneuil
In [21] the author suggests protecting Alg. 2 against SSCA by using the so-
called atomicity principle. We recall in the next section the principle of this
SSCA countermeasure.
3
Atomicity
In this section we recall the principle of atomicity and its application to scalar
multiplication. Other countermeasures exist in order to thwart SSCA such as
regular algorithms [12,24,22] and uniï¬ed formulas [7,16]. However regular algo-
rithms require costly extra curve operations, and uniï¬ed formulas for Weierstrass
curves over Fp â€“ only known in the aï¬ƒne and homogeneous coordinate systems,
see [7] â€“ are also very costly. Therefore atomicity turns out to be more eï¬ƒcient
in the context of embedded devices. It is thus natural to compare the eï¬ƒciency
of the two scalar multiplication methods presented in Section 2.2 protected by
atomicity.
We recall in the following how atomicity is generally implemented on elliptic
curves cryptography, for a complete atomicity principle description see [9].
3.1
State-of-the-Art
The atomicity principle has been introduced in [10]. This countermeasure con-
sists in rewriting all the operations carried out through an algorithm into a
sequence of identical atomic patterns. The purpose of this method is to defeat
SSCA since an attacker has nothing to learn from an uniform succession of iden-
tical patterns.
In the case of scalar multiplications, a succession of point doublings and point
additions is performed. Each of these operations being composed of ï¬eld oper-
ations, the execution of a scalar multiplication can be seen as a succession of
ï¬eld operations. The atomicity consists here in rewriting the succession of ï¬eld
operations into a sequence of identical atomic patterns. The atomic pattern (1)
proposed in [9] is composed of the following ï¬eld operations: a multiplication,
two additions and a negation. Riâ€™s denote the crypto-coprocessor registers.
(1)
â¡
â¢â¢â£
R1 â†R2 Â· R3
R4 â†R5 + R6
R7 â†âˆ’R8
R9 â†R10 + R11
This choice relies on the observation that during the execution of point additions
and point doublings, no more than two additions and one negation are required
between two multiplications. Atomicity consists then of writing point addition
and point doubling as sequences of this pattern â€“ as many as there are ï¬eld
multiplications (including squarings).
Therefore this countermeasure induces two kinds of costs:
â€“ Field squarings have to be performed as ï¬eld multiplications. Then this
approach is costly on embedded devices with dedicated hardware oï¬€ering
modular squaring operation, i.e. when S/M < 1.

Atomicity Improvement for Elliptic Curve Scalar Multiplication
89
â€“ Dummy additions and negations are added. Their cost is generally negligible
from a theoretical point of view but, as shown in Section 1.3, the cost of such
operations must be taken into account in the context of embedded devices.
To reduce these costs, Longa proposed in his PhD thesis [27, Chap. 5] the two
following atomic patterns in the context of Jacobian coordinates:
(2)
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†R2 Â· R3
R4 â†âˆ’R5
R6 â†R7 + R8
R9 â†R10 Â· R11
R12 â†âˆ’R13
R14 â†R15 + R16
R17 â†R18 + R19
(3)
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†R2
2
R3 â†âˆ’R4
R5 â†R6 + R7
R8 â†R9 Â· R10
R11 â†âˆ’R12
R13 â†R14 + R15
R16 â†R17 + R18
Compared with atomic pattern (1), these two patterns slightly reduce the
number of ï¬eld additions (gain of one addition every two multiplications). More-
over, atomic pattern (3) takes advantage of the squaring operation by replacing
one multiplication out of two by a squaring.
In [27, Appendices] Longa expresses mixed aï¬ƒne-Jacobian addition formula
as 6 atomic patterns (2) or (3) and fast doubling formula as 4 atomic patterns (2)
or (3). It allows to perform an eï¬ƒcient left-to-right scalar multiplication using
fast doubling and mixed aï¬ƒne-Jacobian addition protected with atomic patterns
(2) or (3).
3.2
Atomic Left-to-Right Scalar Multiplication
We detail in the following why the Longaâ€™s left-to-right scalar multiplication
using fast doubling and mixed aï¬ƒne-Jacobian addition is not compatible with
our security constraints.
Defeating DSCA5 requires the randomization of input point coordinates. This
can be achieved by two means: projective coordinates randomization [12] and
random curve isomorphism [23]. The ï¬rst one allows to use the fast point dou-
bling formula but prevents the use of mixed additions since input points P, 3P, . . .
have their Z coordinate randomized. On the other hand the random curve iso-
morphism keeps input points in aï¬ƒne coordinates but randomizes a which thus
imposes the use of the general doubling formula instead of the fast one.
Since Longa didnâ€™t investigate general doubling nor readdition, we present in
Appendix A.1 the formulas to perform the former by using 5 atomic patterns (2)
or (3) and in Appendix A.2 the formulas to perform the latter by using 7 atomic
patterns (2). It seems very unlikely that one can express readdition using atomic
pattern (3): since state-of-the-art readdition formula using the Sâ€“M trade-oï¬€
requires 10 multiplications and 4 squarings, 3 other multiplications would have
to be traded for squarings.
Therefore secure left-to-right scalar multiplication can be achieved either
by using atomic pattern (2) and projective coordinates randomization which
5 We include in DSCA the Template Attack on ECDSA from [29].

90
C. Giraud and V. Verneuil
would involve fast doublings and readditions or by using atomic pattern (3) and
random curve isomorphism which would involve general doublings and mixed
additions.
3.3
Atomic Right-to-Left Mixed Scalar Multiplication
As suggested in [21] we protected Alg. 2 with atomicity. Since Longaâ€™s atomic
patterns have not been designed for modiï¬ed Jacobian doubling, we applied
atomic pattern (1) to protect Alg. 2.
The decomposition of general Jacobian addition formula in 16 atomic pat-
terns (1) is given in [9]. Since we havenâ€™t found it in the literature, we present
in Appendix A.3 a decomposition of modiï¬ed Jacobian doubling formula in 8
atomic patterns (1).
Projective coordinates randomization and random curve isomorphism coun-
termeasures can both be applied to this solution.
3.4
Atomic Scalar Multiplication Algorithms Comparison
We compare in Table 3 the three previously proposed atomically protected algo-
rithms. As discussed in Section 1.3 we ï¬x A/M = 0.2 and N/M = 0.1. Costs are
given as the average number of ï¬eld multiplications per bit of scalar. Each cost is
estimated for devices providing dedicated modular squaring â€“ i.e. S/M = 0.8 â€“
or not â€“ i.e. S/M = 1. If extra memory is available, precomputations or postcom-
putations are respectively used to speed up left-to-right and right-to-left scalar
multiplications. The pre/postcomputation cost is here not taken into account
but is constant for every row of the chart.
It appears that in our context atomic left-to-right scalar multiplication using
atomic pattern (2) with fast doubling and readditions is the fastest solution and
is, on average for the 10 rows of Table 3, 10.5 % faster than atomic right-to-left
mixed scalar multiplication using atomic pattern (1).
Table 3. Cost estimation in ï¬eld multiplications per bit of the 3 atomically protected
scalar multiplication algorithms with A/M = 0.2
Nb. of extra S/M Left-to-right Left-to-right Right-to-left
points
with (2)
with (3)
with (1)
0
0.8
17.7
18.2
20.0
1
17.7
19.6
20.0
1
0.8
16.1
16.9
18.0
1
16.1
18.2
18.0
2
0.8
15.6
16.5
17.3
1
15.6
17.7
17.3
3
0.8
15.1
16.1
16.8
1
15.1
17.4
16.8
4
0.8
14.9
16.0
16.6
1
14.9
17.2
16.6

Atomicity Improvement for Elliptic Curve Scalar Multiplication
91
In the next section we present our contribution that aims at minimizing
the atomicity cost by optimizing the atomic pattern. Then we apply it on the
right-to-left mixed scalar multiplication algorithm since eï¬ƒcient patterns are
already known for the two left-to-right variants.
4
Atomic Pattern Improvement
We propose here a twofold atomicity improvement method: ï¬rstly, we take ad-
vantage of the fact that a squaring can be faster than a multiplication. Secondly,
we reduce the number of additions and negations used in atomic patterns in
order to increase the eï¬ƒciency of scalar multiplication.
4.1
First Part: Atomic Pattern Extension
As explained previously, our ï¬rst idea is to reduce the eï¬ƒciency loss due to ï¬eld
squarings turned into multiplications.
Method Presentation. Let O1 and O2 be two atomically written operations
(point addition and doubling in our case) such that they require m and n
atomic patterns respectively. Let us assume that a sub-operation o1 from the
atomic pattern (ï¬eld multiplication in our case) could sometimes be replaced by
another preferred sub-operation o2 (such as ï¬eld squaring). Let us eventually
assume that O1 requires at least mâ€² sub-operations o1 (along with m âˆ’mâ€² sub-
operations o2) and O2 requires at least nâ€² sub-operations o1 (along with n âˆ’nâ€²
sub-operations o2).
Then, if d = gcd(m, n) > 1, let e represents the greatest positive integer
satisfying:
e Â· m
d â‰¤m âˆ’mâ€²
and
e Â· n
d â‰¤n âˆ’nâ€² .
(8)
Since 0 is obviously a solution, it is certain that e is deï¬ned. If e > 0 we can now
apply the following method. Let a new pattern be deï¬ned with d âˆ’e original
atomic patterns followed by e atomic patterns with o2 replacing o1 â€“ the order
can be modiï¬ed at convenience.
It is now possible to express operations O1 and O2 with m/d and n/d new
patterns respectively. Using the new pattern in O1 (resp. O2) instead of the old
one allows replacing e Â· m/d (resp. e Â· n/d) sub-operations o1 by o2.
Application to Mixed Coordinates Scalar Multiplication. Applying this
method to Alg. 2 yields the following result: O1 being the Jacobian projective
addition, O2 the modiï¬ed Jacobian projective doubling, o1 the ï¬eld multipli-
cation and o2 the ï¬eld squaring, then m=16, mâ€²=11, n = 8, nâ€² = 3, d = 8
and e = 2. Therefore we deï¬ne a new temporary atomic pattern composed of
8 patterns (1) where 2 multiplications are replaced by squarings. We thus have

92
C. Giraud and V. Verneuil
Add. 1
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†Z2
2
â‹†
â‹†
â‹†
R2 â†X1 Â· R1
â‹†
â‹†
â‹†
R1 â†R1 Â· Z2
â‹†
â‹†
â‹†
R3 â†Y1 Â· R1
â‹†
â‹†
â‹†
R1 â†Z1
2
â‹†
â‹†
â‹†
R4 â†R1 Â· X2
â‹†
R4 â†âˆ’R4
R4 â†R2 + R4
R1 â†Z1 Â· R1
â‹†
â‹†
â‹†
R1 â†R1 Â· Y2
â‹†
R1 â†âˆ’R1
R1 â†R3 + R1
Add. 2
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
R6 â†R4
2
â‹†
â‹†
â‹†
R5 â†Z1 Â· Z2
â‹†
â‹†
â‹†
Z3 â†R5 Â· R4
â‹†
â‹†
â‹†
R2 â†R2 Â· R6
â‹†
R1 â†âˆ’R1
â‹†
R5 â†R1
2
â‹†
R3 â†âˆ’R3
â‹†
R4 â†R4 Â· R6
R6 â†R5 + R4
R2 â†âˆ’R2
R6 â†R6 + R2
R3 â†R3 Â· R4
X3 â†R2 + R6
â‹†
R2 â†X3 + R2
R1 â†R1 Â· R2
Y3 â†R3 + R1
â‹†
â‹†
Dbl.
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†X1
2
R2 â†Y1 + Y1
â‹†
â‹†
Z2 â†R2 Â· Z1
R4 â†R1 + R1
â‹†
â‹†
R3 â†R2 Â· Y1
R6 â†R3 + R3
â‹†
â‹†
R2 â†R6 Â· R3
R1 â†R4 + R1
â‹†
R1 â†R1 + W1
R3 â†R1
2
â‹†
â‹†
â‹†
R4 â†R6 Â· X1
R5 â†W1 + W1
R4 â†âˆ’R4
R3 â†R3 + R4
W2 â†R2 Â· R5
X2 â†R3 + R4
R2 â†âˆ’R2
R6 â†R4 + X2
R4 â†R6 Â· R1
â‹†
R4 â†âˆ’R4
Y2 â†R4 + R2
Fig. 2. Extended atomic pattern applied to Jacobian projective addition and modiï¬ed
Jacobian projective doubling
one fourth of the ï¬eld multiplications carried out as ï¬eld squarings. This ex-
tended pattern would have to be repeated twice for an addition and once for a
doubling.
We applied this new approach in Fig. 2 where atomic general Jacobian addi-
tion and modiï¬ed Jacobian doubling are rewritten in order to take advantage
of the squarings. We denote by â‹†the dummy ï¬eld additions and negations that
must be added to complete atomic patterns.
4.2
Second Part: Atomic Pattern Cleaning-Up
In a second step we aim at reducing the number of dummy ï¬eld operations. In
Fig. 2, we identiï¬ed by â‹†the operations that are never used in Add.1, Add.2

Atomicity Improvement for Elliptic Curve Scalar Multiplication
93
Add. 1
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†Z22
â‹†
â‹†
â‹†
R2 â†Y1 Â· Z2
â‹†
â‹†
â‹†
R5 â†Y2 Â· Z1
â‹†
â‹†
â‹†
R3 â†R1 Â· R2
â‹†
â‹†
â‹†
R4 â†Z12
â‹†
â‹†
â‹†
R2 â†R5 Â· R4
â‹†
â‹†
R2 â†R2 âˆ’R3
R5 â†R1 Â· X1
â‹†
â‹†
â‹†
R6 â†X2 Â· R4
â‹†
â‹†
R6 â†R6 âˆ’R5
Add. 2
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†R62
â‹†
â‹†
â‹†
R4 â†R5 Â· R1
â‹†
â‹†
â‹†
R5 â†R1 Â· R6
â‹†
â‹†
â‹†
R1 â†Z1 Â· R6
â‹†
â‹†
â‹†
R6 â†R22
â‹†
â‹†
â‹†
Z3 â†R1 Â· Z2
R1 â†R4 + R4
â‹†
R6 â†R6 âˆ’R1
R1 â†R5 Â· R3
X3 â†R6 âˆ’R5
â‹†
R4 â†R4 âˆ’X3
R3 â†R4 Â· R2
â‹†
â‹†
Y3 â†R3 âˆ’R1
Dbl.
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†X12
R2 â†Y1 + Y1
â‹†
â‹†
Z2 â†R2 Â· Z1
R4 â†R1 + R1
â‹†
â‹†
R3 â†R2 Â· Y1
R6 â†R3 + R3
â‹†
â‹†
R2 â†R6 Â· R3
R1 â†R4 + R1
â‹†
R1 â†R1 + W1
R3 â†R12
â‹†
â‹†
â‹†
R4 â†R6 Â· X1
R5 â†W1 + W1
â‹†
R3 â†R3 âˆ’R4
W2 â†R2 Â· R5
X2 â†R3 âˆ’R4
â‹†
R6 â†R4 âˆ’X2
R4 â†R6 Â· R1
â‹†
â‹†
Y2 â†R4 âˆ’R2
Fig. 3. Improved arrangement of ï¬eld operations in extended atomic pattern from
Fig. 2
and Dbl. These ï¬eld operations may then be removed saving up 5 ï¬eld additions
and 3 ï¬eld negations per pattern occurrence.
However, we found out that ï¬eld operations could be rearranged in order
to maximize the number of rows over the three columns composed of dummy
operations only. We then merge negations and additions into subtractions when
possible. This improvement is depicted in Fig. 3.
This ï¬nal optimization now allows us to save up 6 ï¬eld additions and to
remove the 8 ï¬eld negations per pattern occurrence. One may note that no more
dummy operation remains in modiï¬ed Jacobian doubling. We thus believe that
our resulting atomic pattern (4) is optimal for this operation:

94
C. Giraud and V. Verneuil
(4)
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†R2
2
R3 â†R4 + R5
R6 â†R7 Â· R8
R9 â†R10 + R11
R12 â†R13 Â· R14
R15 â†R16 + R17
R18 â†R19 Â· R20
R21 â†R22 + R23
R24 â†R25 + R26
R27 â†R28
2
R29 â†R30 Â· R31
R32 â†R33 + R34
R35 â†R36 âˆ’R37
R38 â†R39 Â· R40
R41 â†R42 âˆ’R43
R44 â†R45 âˆ’R46
R47 â†R48 Â· R49
R50 â†R51 âˆ’R52
4.3
Theoretical Gain
In Table 4 we present the cost of right-to-left mixed scalar multiplication pro-
tected with atomic pattern (4). We also draw up in this chart the gains obtained
over left-to-right and right-to-left algorithms protected with atomic patterns (2)
and (1) respectively.
Due to our new atomic pattern (4), right-to-left mixed scalar multiplication
turns out to be the fastest among these solutions in every cases. The average
speed-up over pattern (1) is 18.3 % and the average gain over left-to-right scalar
multiplication protected with atomic pattern (2) is 10.6 % if dedicated squaring
is available or 7.0 % otherwise.
Table 4. Costs estimation in ï¬eld multiplications per bit of Alg. 2 protected with
improved pattern (4) and comparison with two others methods presented in Table 3
assuming A/M = 0.2
Nb. of extra S/M Right-to-left
Gain over
Gain over
points
with (4)
l.-to-r. with (2) r.-to-l. with (1)
0
0.8
16.0 M
9.6 %
20.0 %
1
16.7 M
5.6 %
16.5 %
1
0.8
14.4 M
10.6 %
20.0 %
1
15.0 M
6.8 %
16.7 %
2
0.8
13.9 M
10.9 %
19.7 %
1
14.4 M
7.7 %
16.8 %
3
0.8
13.4 M
11.3 %
20.2 %
1
14.0 M
7.3 %
16.7 %
4
0.8
13.3 M
10.7 %
19.9 %
1
13.8 M
7.4 %
16.9 %

Atomicity Improvement for Elliptic Curve Scalar Multiplication
95
Table 5. Characteristics of our implementation of the atomically protected 192-bit
scalar multiplication on an 8-bit chip with a 32-bit crypto-coprocessor
Timing RAM size Code size
29.6 ms
412 B
3.5 KB
4.4
Experimental Results
We have implemented Alg. 2 â€“ without any window method â€“ protected with
the atomic pattern (1) on one hand and with our improved atomic pattern (4)
on the other hand. We used a chip equipped with an 8-bit CPU running at 30
MHz and with a 32-bit crypto-coprocessor running at 50 MHz. In particular, this
crypto-coprocessor provides a dedicated modular squaring. The characteristics
of the corresponding implementation are given in Table 5. On the NIST P-192
curve [17] we obtained a practical speed-up of about 14.5 % to be compared
to the predicted 20 %. This diï¬€erence can be explained by the extra software
processing required in the scalar multiplication loop management, especially the
on-the-ï¬‚y NAF decomposition of the scalar in an SSCA-resistant way.
When observing the side-channel leakage of our implementation we obtained
the signal presented in Fig. 4. Atomic patterns comprising 8 modular multipli-
cations and several additions/subtractions can easily be identiï¬ed.
Fig. 4. Side-channel leakage observed during the execution of our scalar multiplication
implementation showing a sequence of atomic patterns
5
Conclusion
In this paper, we propose a new atomic pattern for scalar multiplication on el-
liptic curves over Fp and detail our method for atomic pattern improvement. To
achieve this goal, two ways are explored. Firstly we maximize the use of squarings

96
C. Giraud and V. Verneuil
to replace multiplications since the latter are slower. Secondly we minimize the
use of ï¬eld additions and negations since they induce a non-negligible penalty.
In particular, we point out that the classical hypothesis taken by scalar multipli-
cation designers to neglect the cost of additions/subtractions in Fp is not valid
when focusing on embedded devices such as smart cards.
In this context our method provides an average 18.3 % improvement for the
right-to-left mixed scalar multiplication from [21] protected with the atomic
pattern from [9]. It also provides an average 10.6 % gain over the fastest algorithm
identiï¬ed before our contribution if dedicated squaring is available. Furthermore,
though the topic of this paper is right-to-left scalar multiplication, our atomic
pattern improvement method can be generically used to speed up atomically
protected algorithms.
In conclusion we recommend that algorithm designers, addressing the scope
of embedded devices, take into account additions and subtractions cost when
these operations are heavily used in an algorithm. Moreover the issue of design-
ing eï¬ƒcient atomic patterns should be considered when proposing non regular
sensitive algorithms.
Acknowledgments
The authors are very grateful to Yannick Sierra for pointing them out the im-
provement using the subtractions leading to the eï¬ƒcient patterns of Fig. 3. The
authors would also like to thank Christophe Clavier, Sean Commercial, Em-
manuelle Dottax, Emmanuel Prouï¬€, Matthieu Rivain and the anonymous refer-
ees of Cardis 2010 for their helpful comments on the preliminary versions of this
paper.
References
1. ANSI X9.62â€“2005. Public Key Cryptography for The Financial Service Indus-
try: The Elliptic Curve Digital Signature Algorithm (ECDSA). American National
Standards Institute, November 16 (2005)
2. ANSI X9.63â€“2001. Public Key Cryptography for The Financial Service Industry:
Key Agreement and Key Transport Using Elliptic Curve Cryptography. American
National Standards Institute, November 20 (2001)
3. Arno, S., Wheeler, F.: Signed digit representations of minimal Hamming weight.
IEEE Transactions on Computers 42(8), 1007â€“1009 (1993)
4. Bernstein, D.J., Birkner, P., Joye, M., Lange, T., Peters, C.: Twisted edwards
curves. In: Vaudenay, S. (ed.) AFRICACRYPT 2008. LNCS, vol. 5023, pp. 389â€“
405. Springer, Heidelberg (2008)
5. Bernstein, D.J., Lange, T.: Explicit-formulas database,
http://www.hyperelliptic.org/EFD
6. Bernstein, D.J., Lange, T.: Faster addition and doubling on elliptic curves. Cryp-
tology ePrint Archive, Report 2007/286 (2007), http://eprint.iacr.org/
7. Brier, E., Joye, M.: WeierstraÃŸ Elliptic Curves and Side-Channel Attacks. In: Nac-
cache, D., Paillier, P. (eds.) PKC 2002. LNCS, vol. 2274, pp. 335â€“345. Springer,
Heidelberg (2002)

Atomicity Improvement for Elliptic Curve Scalar Multiplication
97
8. Brown, M., Hankerson, D., LÂ´opez, J., Menezes, A.: Software Implementation of
the NIST Elliptic Curves Over Prime Fields. In: Naccache, D. (ed.) CT-RSA 2001.
LNCS, vol. 2020, pp. 250â€“265. Springer, Heidelberg (2001)
9. Chevallier-Mames, B., Ciet, M., Joye, M.: Low-cost Solutions for Preventing Simple
Side-Channel Analysis: Side-Channel Atomicity. IEEE Transactions on Comput-
ers 53(6), 760â€“768 (2004)
10. Chevallier-Mames, B., Joye, M.: ProcÂ´edÂ´e cryptographique protÂ´egÂ´e contre les at-
taques de type Â´a canal cachÂ´e. French patent, FR 28 38 210 (April 2002)
11. Cohen, H., Ono, T., Miyaji, A.: Eï¬ƒcient Elliptic Curve Exponentiation Using
Mixed Coordinate. In: Ohta, K., Dingyi, P. (eds.) ASIACRYPT 1998. LNCS,
vol. 1514, pp. 51â€“65. Springer, Heidelberg (1998)
12. Coron, J.-S.: Resistance against Diï¬€erential Power Analysis for Elliptic Curve
Cryptosystems. In: KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 1999. LNCS, vol. 1717, pp.
292â€“302. Springer, Heidelberg (1999)
13. Dimitrov, V., Imbert, L., Mishra, P.: Eï¬ƒcient and Secure Elliptic Curve Point
Multiplication using Double-Base Chains. In: Roy, B. (ed.) ASIACRYPT 2005.
LNCS, vol. 3788, pp. 59â€“78. Springer, Heidelberg (2005)
14. ECC Brainpool. ECC Brainpool Standard Curves and Curve Generation. BSI, v.
1.0 (2005), http://www.ecc-brainpool.org
15. ECC Brainpool. ECC Brainpool Standard Curves and Curve Generation. BSI,
Internet Draft v. 3 (2009),
http://tools.ietf.org/html/draft-lochter-pkix-brainpool-ecc-03
16. Edwards, H.M.: A normal form for elliptic curves. Bulletin of the American Math-
ematical Society 44, 393â€“422 (2007)
17. FIPS PUB 186-3. Digital Signature Standard. National Institute of Standards and
Technology, March 13 (2006), Draft
18. GroÃŸschÂ¨adl, J., Avanzi, R.M., Savas, E., Tillich, S.: Energy-Eï¬ƒcient Software Im-
plementation of Long Integer Modular Arithmetic. In: Rao, J.R., Sunar, B. (eds.)
CHES 2005. LNCS, vol. 3659, pp. 75â€“90. Springer, Heidelberg (2005)
19. Hankerson, D., Menezes, A., Vanstone, S.: Guide to Elliptic Curve Cryptography,
Springer Professional Computing Series (January 2003)
20. Hesse, O.: Uber die Elimination der Variabeln aus drei algebraischen Gleichungen
vom zweiten Grade mit zwei Variabeln. Journal fÂ¨ur die reine und angewandte
Mathematik 10, 68â€“96 (1844)
21. Joye, M.: Fast Point Multiplication on Elliptic Curves Without Precomputation.
In: von zur Gathen, J., ImaËœna, J.L., KoÂ¸c, CÂ¸.K. (eds.) WAIFI 2008. LNCS, vol. 5130,
pp. 36â€“46. Springer, Heidelberg (2008)
22. Joye, M.: Highly regular m-ary powering ladders. In: Jacobson, M.J., Rijmen, V.,
Safavi-Naini, R. (eds.) SAC 2009. LNCS, pp. 135â€“147. Springer, Heidelberg (2009)
23. Joye, M., Tymen, C.: Protections against Diï¬€erential Analysis for Elliptic Curve
Cryptography. In: KoÂ¸c, CÂ¸.K., Naccache, D., Paar, C. (eds.) CHES 2001. LNCS,
vol. 2162, pp. 386â€“400. Springer, Heidelberg (2001)
24. Joye, M., Yen, S.-M.: The Montgomery Powering Ladder. In: Kaliski Jr., B.S.,
KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp. 291â€“302. Springer,
Heidelberg (2003)
25. Kocher, P.: Timing Attacks on Implementations of Diï¬ƒe-Hellman, RSA, DSS, and
Other Systems. In: Koblitz, N. (ed.) CRYPTO 1996. LNCS, vol. 1109, pp. 104â€“113.
Springer, Heidelberg (1996)
26. Kocher, P., Jaï¬€e, J., Jun, B.: Diï¬€erential Power Analysis. In: Wiener, M. (ed.)
CRYPTO 1999. LNCS, vol. 1666, pp. 388â€“397. Springer, Heidelberg (1999)

98
C. Giraud and V. Verneuil
27. Longa, P.: Accelerating the Scalar Multiplication on Elliptic Curve Cryptosystems
over Prime Fields. PhD thesis, School of Information Technology and Engineering,
University of Ottawa (2007)
28. Longa, P., Miri, A.: New Multibase Non-Adjacent Form Scalar Multiplication and
its Application to Elliptic Curve Cryptosystems (extended version). Cryptology
ePrint Archive, Report 2008/052 (2008), http://eprint.iacr.org/
29. Medwed, M., Oswald, E.: Template attacks on ECDSA. Cryptology ePrint Archive,
Report 2008/081 (2008), http://eprint.iacr.org/
30. Meloni, N.: New point addition formulae for ECC applications. In: Carlet, C.,
Sunar, B. (eds.) WAIFI 2007. LNCS, vol. 4547, pp. 189â€“201. Springer, Heidelberg
(2007)
31. Meloni, N., Hasan, M.A.: Elliptic Curve Scalar Multiplication Combining Yaoâ€™s
Algorithm and Double Bases. In: Clavier, C., Gaj, K. (eds.) CHES 2009. LNCS,
vol. 5747, pp. 304â€“316. Springer, Heidelberg (2009)
32. Montgomery, P.: Speeding the Pollard and Elliptic Curve Methods of Factorization.
Mathematics of Computation 48, 243â€“264 (1987)
33. SP 800-78-1. Cryptographic Algorithms and Key Sizes for Personal Identity Veri-
ï¬cation. National Institute of Standards and Technology (August 2007)
34. TR-03111. Elliptic Curve Cryptography Based on ISO 15946. Federal Oï¬ƒce for
Information Security (BSI), February 14 (2007)
35. Yao, A.C.-C.: On the Evaluation of Powers. SIAM Journal on Computing 5(1),
100â€“103 (1976)

Atomicity Improvement for Elliptic Curve Scalar Multiplication
99
A
Atomic Formulas
A.1
Atomic General Doubling Using Pattern (2) or (3)
The decomposition of a general â€“ i.e. for all a â€“ doubling in Jacobian coordinates
using atomic pattern (3) is depicted hereafter. The corresponding decomposition
using atomic pattern (2) can straightforwardly be obtained by replacing every
squaring by a multiplication using the same operand twice.
The input point is given as (X1, Y1, Z1) and the result is written into the point
(X2, Y2, Z2). Four intermediate registers, R1 to R4, are used.
1
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†X1
2
â‹†
R3 â†R1 + R1
R2 â†Z1 Â· Z1
â‹†
R1 â†R1 + R3
R4 â†X1 + X1
4
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R2 â†R1
2
â‹†
â‹†
R4 â†R4 Â· R3
R4 â†âˆ’R4
R2 â†R2 + R4
X2 â†R2 + R4
2
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R2 â†R2
2
â‹†
â‹†
R2 â†a Â· R2
â‹†
R1 â†R1 + R2
R2 â†Y1 + Y1
5
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R3 â†R3
2
R1 â†âˆ’R1
R4 â†X2 + R4
R1 â†R1 Â· R4
R3 â†âˆ’R3
R3 â†R3 + R3
Y2 â†R3 + R1
3
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R3 â†Y1
2
â‹†
â‹†
Z2 â†Z1 Â· R2
â‹†
R3 â†R3 + R3
â‹†

100
C. Giraud and V. Verneuil
A.2
Atomic Readdition Using Pattern (2)
The decomposition of a readdition in Jacobian coordinates using atomic pattern
(2) is depicted hereafter.
The input points are given as (X1, Y1, Z1), (X2, Y2, Z2) and the result is writ-
ten into the point (X3, Y3, Z3). Seven intermediate registers, R1 to R7, are used.
1
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R1 â†Y2 Â· Z1
3
â‹†
â‹†
R2 â†Y1 Â· Z2
â‹†
â‹†
â‹†
5
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R5 â†R5 Â· R3
â‹†
â‹†
R3 â†Z2 Â· R3
â‹†
â‹†
â‹†
2
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R3 â†Z2 Â· Z2
â‹†
â‹†
R4 â†R2 Â· R3
R5 â†âˆ’R1
R4 â†R4 + R5
â‹†
6
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R7 â†R4 Â· R4
â‹†
â‹†
Z3 â†R3 Â· Z1
R5 â†âˆ’R5
R7 â†R7 + R6
X3 â†R7 + R5
3
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R2 â†X2 Â· Z1
2
â‹†
â‹†
R3 â†X1 Â· R3
R5 â†âˆ’R2
R3 â†R3 + R5
â‹†
7
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R3 â†R1 Â· R5
R1 â†âˆ’X3
R2 â†R2 + R1
R1 â†R2 Â· R4
â‹†
Y3 â†R1 + R3
â‹†
4
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
R5 â†R3 Â· R3
â‹†
â‹†
R2 â†R2 Â· R5
R6 â†âˆ’R2
R6 â†R6 + R6
â‹†

Atomicity Improvement for Elliptic Curve Scalar Multiplication
101
A.3
Atomic Modiï¬ed Jacobian Coordinates Doubling Using
Pattern (1)
The decomposition of a doubling in modiï¬ed Jacobian coordinates using atomic
pattern (1) is depicted hereafter.
The input point is given as (X1, Y1, Z1) and the result is written into the point
(X2, Y2, Z2). Six intermediate registers, R1 to R6, are used.
1
â¡
â¢â¢â£
R1 â†X1 Â· X1
R2 â†Y1 + Y1
â‹†
â‹†
5
â¡
â¢â¢â£
R3 â†R1 Â· R1
â‹†
â‹†
â‹†
2
â¡
â¢â¢â£
Z2 â†R2 Â· Z1
R4 â†R1 + R1
â‹†
â‹†
6
â¡
â¢â¢â£
R4 â†R6 Â· X1
R5 â†W1 + W1
R4 â†âˆ’R4
R3 â†R3 + R4
3
â¡
â¢â¢â£
R3 â†R2 Â· Y1
R6 â†R3 + R3
â‹†
â‹†
7
â¡
â¢â¢â£
W2 â†R2 Â· R5
X2 â†R3 + R4
R2 â†âˆ’R2
R6 â†R4 + X2
4
â¡
â¢â¢â£
R2 â†R6 Â· R3
R1 â†R4 + R1
â‹†
R1 â†R1 + W1
8
â¡
â¢â¢â£
R4 â†R6 Â· R1
â‹†
R4 â†âˆ’R4
Y2 â†R4 + R2

Key-Study to Execute Code Using Demand
Paging and NAND Flash at Smart Card Scale
Geoï¬€roy Cogniaux and Gilles Grimaud
LIFL, CNRS UMR 8022, University of Lille I. INRIA, Nord-Europe, France
Abstract. Nowadays, the desire to embed more applications in systems
as small as Smart Cards or sensors is growing. However, physical lim-
itations of these systems, like very small main memory, and their cost
of production make it very diï¬ƒcult to achieve. One solution is to ex-
ecute code from a secondary memory, cheaper, denser, but slower, as
NAND Flash. Solutions based on Demand Paging and using a cache in
main memory, began to be proposed and implemented in the domain of
mobile phones, but consume too much RAM yet, compared to what a
Smart Card can provide. In this paper, we show that we can dramat-
ically increase performance by reducing the size of pages in the cache.
This solution then allows a more intelligent access to the NAND. We also
show that our solution allows to use Demand Paging within the limits
of Smart Cards memories, where a conventional approach, oï¬€ering too
low bandwidth, makes code execution impossible from this kind of sec-
ondary memory. Finally, we present important future keys to optimize
our proposal even more, and specially oï¬€-line code specialization aware
of NAND characteristics and advanced cache properties.
1
Introduction
Nowadays, the desire to embed more applications in systems as small as Smart
Cards or sensors is growing. However, challenges are not the same between a
mobile phone and a Smart Card. Beyond the extreme physical constraints, as
only a few kilobytes of RAM and not much more storage space for code, a
Smart Card also has an extremely restrictive speciï¬cation in regard to costs of
production or energy consumption. It is not conceivable in these targets to run
programs more expensive in space or energy only by inï¬‚ating the hardware. The
possible solution is to replace or at least extend the code storage capacity with
another hardware with lower cost per bit of storage.
Generally, NOR ï¬‚ash is used as code storage space on systems such as Smart
Cards. The NAND ï¬‚ash is another type of ï¬‚ash memory with diï¬€erent proper-
ties. This memory is also nonvolatile, has greater density, and therefore allows to
embed more data than the NOR on a same silicon size, near 60%. The tempta-
tion is then huge to replace NOR by NAND. Unfortunately, the NAND, although
coming with faster writings, is much slower to perform readings, and is not ac-
cessible byte per byte as NOR interface but per pages. This access mode causes
incompressible latency and a priori excludes random accesses. NAND is then
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 102â€“117, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Key-Study to Execute Code Using Demand Paging and NAND Flash
103
most often used to support a ï¬le system and so far, its development has mainly
been driven for this purpose.
Executing code from memories such as NAND is made possible by the intro-
duction of a cache in main memory or the use of SRAM buï¬€ers added directly
into the NAND. This new category is called hybrid Flash. However, the presence
of a dedicated RAM space is not suï¬ƒcient to close the gaps between NAND and
NOR. A cache manager will then have to be smart enough to hide the latency
of the NAND and ensure ï¬‚uidity when providing instructions to a processor or
a virtual machine. In this context of paged memory, the Demand Paging is the
most popular caching strategy because it oï¬€ers the best balance between overall
performance and reduced cache space. The idea of this method is to access slow
hardware only in cases of extreme necessity and try to keep in cache as much
data as possible, generally sorted by relevance of future uses. Of course, knowing
if a cached data will be ï¬nally useful or not, is a non-trivial problem.
If hardware researches are working to provide more eï¬ƒcient device to reduce
the latency of the NAND, at software level, greater eï¬€orts are usually done on
the optimization of the page replacement policy in the cache. But in systems
with tiny main memory, it remains to be seen how many bytes to sacriï¬ce for a
cache, in addition to the vital needs of the system. But beyond that, the main
problem with these systems will be to know if this sacriï¬ce will be enough to
perform code execution from this slow memory.
The remaining of this paper is organized as follow: Section 2 describes research
motivations and issues. Section 3 lists related works. Section 4 discusses a new
way to use Demand Paging and NAND ï¬‚ash memory to use it in Smart Card
too. Section 5 presents experimental results on reading performance. Finally,
section 6 will discuss about best cache page size and its direct interactions with
page content for future optimizations.
2
Motivations Around Smart Card and Flash Memories
Characteristics
In this paper, we focus on very small embedded systems such as Smart Cards
or sensors. This kind of devices has very restrictive speciï¬cations and hardware
constraints aiming to reduce production cost and energy consumption dramati-
cally. Despite their size, industrial trends would like to embed more applications
and bigger programs in those targets.
Smart Card and sensors are mainly built around an 8 or 16 bits processor
and generaly between 1 and 8KB of RAM. Code is then executed from ï¬‚ash
memory such as NOR, reserving RAM for volatile data such as execution stack
and variables. Thus, executing bigger applications will require more NOR, which
would also be too expensive in energy, size and production cost. As an alterna-
tive, read-only code could be executed from a cheaper and denser ï¬‚ash memory
such as NAND.
NOR is byte-wise and has a good and constant performance in random read-
ings. With these properties, NOR can support XIP (execute-In-Place), to run

104
G. Cogniaux and G. Grimaud
programs directly, without any intermediate copy in main memory. The NAND
ï¬‚ash has better writing performance and is cheaper and denser. It can store more
informations on same die size and thus has a lower cost per bit. But NAND is
much more slower in readings. NAND is block-wise [1]. The smallest read and
write unit is the page that can store 512 or 2048 bytes. To read a byte ran-
domly, the corresponding page must be ï¬rst completly loaded in the hardware
NAND data register. Only after this long time consuming operation, bytes can
be fetched sequentially from the register until the wanted one is reached. In those
conditions (Random worst case column of Table 1), NAND is not designed to
support intensive random readings and is widely used to support ï¬le systems,
designed with a per-block logic and almost always accessed sequentially.
Table 1. NAND characteristics aligned on a bus at 33MHz and 8bits wide
Device
Page Size Latency Byte Fetch Page Fetch Min1 Max2
K9F1208Q0B 3
512 bytes
15Âµs
50ns
25.6Âµs
0.02 12.03
MT29F2G08A-
ACWP 4
2048 bytes
25Âµs
40ns
81.94Âµs
0.01 18.27
NOR Flash
-
-
40ns
-
-
23.84
Table 2. NAND characteristics aligned on a bus at 54MHz and 16bits wide
Device
Page Size Latency Byte Fetch Page Fetch Min1 Max2
K9F1208Q0B 3
512 bytes
15Âµs
50ns
25.6Âµs
0.02 12.03
MT29F2G08A-
ACWP 4
2048 bytes
25Âµs
20ns
40.9Âµs
0.01 29.61
NOR Flash
-
-
9ns
-
-
108
1 Worst Case: random reading bandwidth in MB/s
2 Sequential reading Bandwidth in MB/s
3 http://www.samsung.com
4 http://www.micron.com
3
Related Works
The studies of code execution from NAND ï¬‚ash can be classiï¬ed in four cate-
gories. In the ï¬rst place, we can distinguish pure hardware solutions since NAND
is not a well-adapted device to do random readings, and so far XIP [2, 3, 4, 5].
[6, 7, 8, 9, 10, 11, 12, 13] proposed software solutions using already available
NAND, even if software is often limited to ï¬rmware here.
Besides, we can split both categories into two others: one aiming to propose
an universal solution working with any program, and another one aiming to ï¬nd
best performance dedicating solutions to one program or one type of programs
such as multimedia streaming.
In systems with limited SRAM size, copying the entire program in main mem-
ory is not possible. Instead, hardware and software researchers have worked on

Key-Study to Execute Code Using Demand Paging and NAND Flash
105
solutions using a cache managed by the Demand Paging strategy. It can be either
in existing main memory or in SRAM integrated directly in the NAND device
[2], resulting in a new one, now called hybrid NAND.
Generally, hardware based solutions are coming with a local SRAM cache
managed by new circuits but many parts of the implementation are performed
by the ï¬rmware. The main purpose to introduce a SRAM and a cache in the
NAND device is to provide an interface similar to the NOR one, which is byte-
wise and randomly accessible. But as explained in [10], in already available
hybrid NAND such as OneNANDTM by Samsung[14], the integrated SRAM
is not a cache yet, and doesnâ€™t oï¬€er enough performance to actually execute
code1. If OneNAND oï¬€ers a double buï¬€ers mechanism to access stored data
more randomly by overlapping some internal NAND accesses and their latency,
it doesnâ€™t hide all of them. [11, 15] propose a software-based solution to use this
buï¬€er as a true but secondary cache in relation with a higher level cache in main
memory. When a NAND page is accessed more often than a static threshold,
this page is promoted from in-NAND cache to main memory cache which allows
faster accesses.
Most of the time, solutions aim at improving or adapting the replacement
policy needed by the Demand Paging strategy because researches [16] showed
that a gap always exists up to the theoretical best one, known as MIN [17]. When
a cache is full and when the CPU tries to read instructions not present in cache
yet, the new page loaded from the NAND must overwrite an existing one in
the cache. Then, the replacement policy must decide which one to erase, hoping
that this choice will be relevant for the future execution of the program. In the
studied works, this choice may be based on priorities [2], pinning [9, 12], derived
from well-known policies like LRU (Least Recently Used) [8, 9, 11],... , or using a
completely new approach [4] by embedding a trace-based prediction tree within
the NAND device, with good performance (being close to MIN behaviour) but
with a RAM overhead, and universality lost.
All of these proposals have mobile phones as smallest devices. In this paper,
we take an interest in extreme constraints of Smart Cards-sized devices with very
small SRAM space to manage a cache (less than 4KB). We also want to evaluate
performance behind very slow bus (33MHz, 8bits wide). Because in such devices,
reserving SRAM bytes for a dedicated process represents a strong sacriï¬ce, and
buses are well-known bottlenecks. To successfully execute code from NAND-like
memory, we will have to tune implementation to reduce this sacriï¬ce, but as a
ï¬rst issue, it remains to be seen whether this sacriï¬ce will be enough to reach
abilities, before performance.
4
Demand Paging at Smart Card Scale
4.1
Conventional Demand Paging Issue in Smart Card
In conventional Demand Paging used in literature, a page in the cache has the
same size that a physical NAND page, since reading a NAND page has a very
1 Though it can execute a boot loader.

106
G. Cogniaux and G. Grimaud
high cost, due to long access latency. An eï¬ƒcient Demand Paging and its replace-
ment policy are aware of this problem and access the managed slow memory as
less as possible.
Smart Cards, mobile sensors, and other small embedded systems have con-
straints that make conventional Demand Paging unusable in their context be-
cause of low performance. For instance, if we consider a system with only 2KB
of RAM available for a cache, and a NAND with a page size of 2KB, there will
be only one page in the cache. With this assumption, a replacement policy is
useless, and the read bandwidth will be close to worst case of Table 1, unless
executed program is only 2KB.
It can be said that the main problem with NAND is its long access latency.
But, in our context, hiding latencies is not enough. We have explained there
are two steps for bytes reading from NAND : a load phase and a sequential
fetch phase. If the load phase has a good attention in research and industry, the
second topic has not been well investigated yet, since, in mobile phone, authors
considered good clock and bandwidth for buses. But, even if we have a NAND
claiming to have a 108MB/s bandwidth and hiding all latencies, we will not have
a real bandwidth faster than the bus one and copying a complete NAND page
into SRAM cache may take a long time too (5th column of table 1).
4.2
Performance Is under Inï¬‚uence
A parameter may inï¬‚uence another and an accurate assessment must take these
interactions into account. Into a graph of inï¬‚uence (Fig. 1), we listed and put
physical and logical parameters face to intermediate results that are necessary
for a proper assessment of our study. They can be classiï¬ed into 4 categories:
â€“ physical parameters related to hardware (rectangle boxes)
â€“ logical parameters conï¬guring the cache (inversed house boxes)
â€“ development toolkit, languages, compilers, ... (ellipse boxes)
â€“ intermediate statistics inï¬‚uencing the overall bandwidth (rounded boxes)
As shown in Fig. 1, page fault or MISS causes a series of transactions that aï¬€ect
the overall throughput. To make an instruction not present in cache available,
the cache manager must load the new page into the hardware NAND data reg-
ister, read the content of this register through the bus, then copy this page into
the cache and ï¬nally actually read the requested instruction. (For short, in the
remaining of this paper, we will refer to these four steps as load, fetch, write,
and read steps). A MISS is itself inï¬‚uenced by the cache size (in pages count),
the size of a cache page, the content of this page and of course the replacement
policy. The Demand Paging is not only dependent on the way it is managed.
If a replacement policy follows locality principle [18], only page size and page
content create conditions for a better locality.
A compiled program is not a random series of instructions but follows some
patterns of instructions and controls ï¬‚ows. The analysis of these patterns shows
that a program has two interesting features grouped under the concept of the

Key-Study to Execute Code Using Demand Paging and NAND Flash
107
Fig. 1. Parameters inï¬‚uence graph
Fig. 2. Conventional approach of Demand Paging
locality principle [18]. A program tends to use instructions located in the same
memory area. This is the principle of spatial locality and this area is therefore
strongly related to the size of a page. A program also tends to reuse instructions
that have already served in the recent past, typically in a loop. This is the tem-
poral locality. To help a replacement policy to use more eï¬ƒciently the temporal
principle, blocks of code should be grouped by aï¬ƒnity, and therefore in the same
page of NAND to avoid or reduce page faults.
4.3
Performance Improvement without Replacement Policy Change
or Redesign
Regardless of the manner in which it is implemented and which policy is used, if
we analyse the behaviour of the Demand Paging using NAND with small pages
compared to NAND with big pages, we can see that the smallest achieves best
performance. First because it has shorter access latency, and second because at
the same cache size we can store more pages in it, for instance within 4KB of

108
G. Cogniaux and G. Grimaud
Fig. 3. A new approach using reduced cache page size
SRAM, we will store 8 pages of 512 bytes versus 2 pages of 2048. Using small
pages, the changes applied to the content of the cache by the replacement policy
are more relevant and eï¬ƒcient. It then speaks in favour of smaller cache pages.
If we reduce the size of a cache page, the number of bytes fetched from NAND,
put on the bus, and then written into the SRAM cache decreases because there
is no need to retrieve complete pages of NAND, but only smaller inner-block.
The number of pages loaded into the data register of the NAND also decreases
for two reasons:
1. The replacement policy tends to keep in cache only needed code blocks in-
stead of full pages of NAND with potentially unnecessary methods. (The
smaller the methods are, the more this probability increases).
2. Reducing the size of a cache page can increase its number into same con-
sumed SRAM space, and thus improve the relevance of the cache content.
Reducing the cache page size introduces another advantage, completely useless
until now if a page of cache and a page of NAND have the same size. Without
hardware changes, we can now consider the data register as a real buï¬€er. We have
seen that for a conventional NAND (non-hybrid), it was sequentially accessible.
Let us consider now a page of NAND with 512 bytes, a data register with the
same capacity and a page cache size of 64 bytes, which divides the data register
into 8 consecutive logical blocks. Three cases may arise after the fetch of the
block number i of page number P and following a new page fault:
1. the page fault requests another page than P: we have to load the new page
in the NAND register
2. the page fault requests block i+j of P, then in that case there is no need to
reload data register, we can fetch this block
3. the page fault requests the block i-j of P, which causes a reload of the
register, because we cannot turn back
j is here the number of block to skip to reach the wanted one. (We notice that
all blocks between i and j will have to be fetched too)
Storing in memory the page number that is currently in the NAND register
and the current block number is enough to distinguish the case (1) of the cases

Key-Study to Execute Code Using Demand Paging and NAND Flash
109
(2) and (3), and up to avoid unnecessary register reloads which slow down overall
performance.
5
Experiments
We investigated cache conï¬gurations independently of replacement policies and
cache manager implementations, and diï¬€erent contexts such as native programs
or Java programs. Our goal is to ï¬nd solutions in case that replacement policies
are useless, as described in Section 4.1, instead of redesigning a new one. Thus,
we used LRU and MIN as references (which are the most common boundaries
in cache studies), to instead investigate more specially NAND characteristics,
cache conï¬gurations and crtitical Smart Cardâ€™s hardware constraints such as
the external bus frequency.
5.1
Experimental Setup
The results are from a new dedicated simulator based on the parameters de-
scribed in Fig. 1. The simulation process happens in two stages. After providing
the physical parameters to build a simulated architecture, a trace is replayed
against it by applying the desired replacement policy, and then counting the
MISS and HIT as well as collecting the necessary informations to compute the
overall bandwidth in MB/s. We wanted to analyse and characterize the impact
of pages sizes. Results are thus presented with the assumption that the simula-
tor knew with a null cost if an instruction was already in the cache or not. It
assumes a negligible overhead executing cache lookups since we will use ï¬nally a
limited number of cache pages here. But it will be investigated in future works.
Traces of C programs (like Typeset from the MiBench benchmark suite) were
obtained using Callgrind on Linux. The traces of Java programs have been gen-
erated by JITS (Java In The Small [19]), an instrumental JVM developed and
maintained by the INRIA-POPS team2. Regarding the storage in NAND, we
consider only what would be in the NOR: the .text section of ELF binaries, and
raw bytecode arrays of Java class ï¬les. They are in consecutive pages of NAND
(if necessary, the same function can be distributed among several pages) as if
they were copied by a programmer, in the order of the binary produced by the
compiler.
5.2
Event-Driven Java Applications
We also needed a true Smart Card scale use-case, because most of benchmark
programs come with big loops and/or deep dependencies on external libraries.
At the same time, existing embedded systems benchmarks do not provide similar
environment to those used in todayâ€™s Smart Card. Systems such as JavaCard are
based on event-driven multi-applicative environment (like Cardlets processing
APDU).
2 http://www.inria.fr/recherche/equipes/pops.en.html

110
G. Cogniaux and G. Grimaud
The JITS platform is also one of them, when conï¬gured for sensors or Smart
Cards. This suite of tools allows oï¬€-board code specialization to reduce the total
memory footprint to strictly necessary Java classes and methods. Diï¬€erent from
other embedded JVM, JITS allows the use of standard Java API instead of being
limited to a speciï¬c subset, like in JavaCard. We then use the on-board JITS
bytecodes interpreter, working in events fashion, which enables us to simulate
parallel execution of several Java applications without the need to have a per-
thread execution stack.
In our simulation, the JITS platform is conï¬gured for applications running on
a Crossbow MicaZ target: 4KB of RAM, 128KB of NOR Flash. The applications
deployed on the target then contain 56 classes and 119 methods for 6832 bytes
of Java bytecodes, and requires 2.1 KB of RAM for volatile data such as stack,
some basic Java objects and critical sections of code like the event manager.
It leaves only 1.9 KB of RAM to physically store a cache on-board. In the
simulator, we will consider that the JVM is in NOR, and Java bytecodes stored
in a simulated NAND. The results reproduced here are from a trace of 1,534,880
Java bytecodes through 172,411 calls/returns of methods during the execution of
3 parallel event-driven applications, sampling data at diï¬€erent frequencies and
then forwarding samples over the air network.
5.3
Experimental Results
Impact of NAND Pagesize and Buses Constraints. As a starting point,
we explored conventional Demand Paging with cache page size aligned on NAND
page size. Fig. 4(up) reports reading performance of the MiBench-Typeset appli-
cations after simulations of caches between 2 and 16KB, and using NAND ï¬‚ash
with 512 or 2048 bytes per page. It shows that small pages outperforms large
pages, even if it is no more an industrial trend to provide NAND with small
pages. If we look at Fig. 4(bottom), with hardware reduced to Smart Card abili-
ties (see Table 1), we are further from NOR performance. Code caching seems to
require much RAM to hide weaknesses of NAND and buses, which is impossible
in our targets.
Impact of Cache Page Size. Aiming at giving power back to replacement
policy with another way, we investigated reduction of cache page size, discovering
a new way to manage the NAND register. Fig. 5a shows, using a cache of 2KB,
that performance is becoming closer to NOR. Fig. 5a reproduces simulations
of our JITS sample with cache page size reduced by 2 each time. The ï¬rst
consequence is that cache page count increases. As described in Section 4.3, Fig.
5b shows with the same conï¬gurations as Fig. 5a, the impact on each page fault
step : a decrease of write (due to reduction), and then a decrease of fetch and
load (due to reduction and new register management).
With this new conï¬guration, the gain is double:
â€“ Either, at same cache size, we are improving reading performance.
â€“ Or, at same reading performance, we are reducing dramatically the size of
the cache.

Key-Study to Execute Code Using Demand Paging and NAND Flash
111
Fig. 4. Impact of NAND page size and bus speed on read Bandwidth, on a bus
@54MHz-16bits (up) and on a bus @33MHz-8bits (bottom)
(a) JITS - Cache page reduction
(b) JITS - Reductionâ€™s eï¬€ect
Fig. 5. Reduction of cache page size
If we take a look at our JITS application side (Fig. 6a for a 512 bytes NAND
page size, Fig. 6b for a 2048 bytes NAND), we can show another very interesting
advantage. These ï¬gures report reading performance using a cache page size of

112
G. Cogniaux and G. Grimaud
(a) JITS - NAND 512
(b) JITS - NAND 2048
Fig. 6. Conventional Demand Paging compared to a cache with reduced page size
64 bytes. With a cache of 2KB (32 pages of 64 bytes), reading performance out-
performs conventional Demand Paging, and even more, it makes code execution
from a NAND with Demand Paging strategy possible (see Section 4.3). We are
closer to NOR performance.

Key-Study to Execute Code Using Demand Paging and NAND Flash
113
6
Discussion about the Best Cache Page Size
As shown in Fig. 5a, tuning the cache page size can improve overall performance.
Unfortunately, the best cache page size is not unique, and may diï¬€er from pro-
grams to programs, and what is more, it may diï¬€er in a same program. For
instance, the best cache page size for our JITS Java sample is 64 bytes when
using LRU, though it is 32 when using MIN. To understand this diï¬€erence, we
have to distinguish two concurrent phenomenons, both getting better each other,
but with some limits we will discuss here.
6.1
Buï¬€er Eï¬€ect
The ï¬rst phenomenon, the buï¬€er eï¬€ect, has already been described above and
refers to the new management of the NAND register. Based on it, a good page
replacement policy is able to specialize the code on the ï¬‚y, while searching and
keeping only what it needs, without loading unnecessary instructions. Never-
theless, the limit to this specialization cannot be the instruction itself (ie, a
cache page size of one byte), mainly because performance bottleneck would be
transferred to lookups and indexing phases of the replacement policy algorithm.
6.2
Matching Code Granularity
The second phenomenon is based on code granularity concept and can set the
limit of the ï¬rst one, while explaining for example why a small cache page size
can be better than another smaller one. In fact, a simple code specialization is
already done by the page replacement policy. It means that ï¬nally, the policy
splits code into two distinct categories: used and unused code. Following this, to
keep eï¬ƒciently data in cache, it will access NAND only to ï¬nd useful code. If
we help it with doing this distinction, overall performance will be improved.
At sources level, a program consists of classes and methods, or functions,
depending on the programming languages. Once compiled, it then consists in
series of basic blocks. A basic block is a group of several instructions, which
will always be executed sequentialy because being between two jumping instruc-
tions (call/return, conditional jumps). With these bounds and to be eï¬ƒcient,
a replacement policy should load an entire basic block when accessing its ï¬rst
instruction for the ï¬rst time. Reducing cache page size to match the average
size of a basic block as close as possible then gives better chance to the replace-
ment policy to ï¬nd more quickly useful sub-parts in a program, that may be
spread over many pages into the NAND. For instance, the average basic block
size (among only used basic blocks during simulation) of our JITS Java sample
is about 60 bytes. That is the reason why the best cache page size for this sam-
ple is between 32 and 64 bytes. At this point, we can understand the impact of
the noticed concurrent phenomenons. The best cache page size for LRU is 64
bytes, with the average code size aligned up to the cache page size. But MIN,
having a better prediction mecanism than LRU, can take more advantage of the
previously described buï¬€er eï¬€ect, and continue to have better performance with

114
G. Cogniaux and G. Grimaud
Fig. 7. MiBench-MAD - LRU and cache page reduction in a cache of 2KB
smaller and smaller cache page size. Its limit will be now the number of pages
to maintain in cache and the time consumed by the replacement algorithm for
looking up or indexing.
The MiBench-MAD benchmark (Fig. 7) shows that in fact the average basic
block size is dominating the search for the best cache page size. MAD is a MP3
decoder calling, 90% of the time, two big functions. It puts the average size to
220 bytes. As shown in Fig. 7, best cache page size is still around this value.
Nevertheless, with a higher value we see that we donâ€™t have the positive buï¬€er
as expected any more. Code granularity is thus as important as other cache
parameters to tune an eï¬ƒcient cache system.
6.3
Toward a Better In-Binary Organization
We noticed in section 4.3 that a page fault can request a new block in the page
already present in the NAND register. It results in a block jump (from block i
to j). Getting j smaller than i is not an optimal situation because it causes the
page to be reloaded. On the other hand, getting j greater than i+1 is neither
a good situation because unnecessary bytes between block i and block i+j will
have to be fetched. Fig. 8 shows a spectrum of distance between i and j during
our JITS sample (cases 2 and 3 described in section 4.3). A negative distance
means that the same page had to be reloaded int the NAND register to read a
block towards. A distance of 0 means that whereas the replacement has choosen
to replace a block, it has ï¬nally needed the same block again resolving the next
page fault. A distance of 31 means that the full NAND page had to be loaded
and fetched, only to access its last logical block. Only 11.5% are in the optimal
case where j=i+1, the only one without useless fetches.

Key-Study to Execute Code Using Demand Paging and NAND Flash
115
Fig. 8. JITS sample - Distance between two consecutive block requests using a cache
of 2KB (32 pages of 64B)
In-binary organization is conditioned either by language, by compiler, or both.
Fig. 8 speaks in favour of a control-ï¬‚ow analysis to group blocks by aï¬ƒnity of
calls or sequences, directly in the binary.
7
Conclusion
We presented a new approach to parameterize the Demand Paging strategy to
cache a slow secondary memory such as NAND ï¬‚ash in the context of Smart
Card or embedded systems with the same size and the same constraints, such
as slow buses and tiny main memory. Combined with an intelligent access to
the NAND data register, reducing cache page size dramatically improves per-
formance where conventional approach was close to worst case in term of band-
width. We discussed about the optimality of our proposal, showing that the best
cache page size were close to average size of used basic blocks. We noticed that
this value could diï¬€er from programs to programs, and then may not always
be shared between them to optimize all in once. We also pointed that the page
replacement policy acted almost naturally as a on-the-ï¬‚y code specializer. It
means that running already Demand Paging-specialized code on this kind of
targets may represent another interesting opportunity of gains.
References
[1] Micron Technical Note 29-19: NAND Flash 101 (2006)
[2] Park, C., Seo, J., Bae, S., Kim, H., Kim, S., Kim, B.: A low-cost memory
architecture with nand xip for mobile embedded systems. In: CODES+ISSS
2003: Proceedings of the 1st IEEE/ACM/IFIP international conference on Hard-
ware/software codesign and system synthesis, pp. 138â€“143. ACM, New York
(2003)

116
G. Cogniaux and G. Grimaud
[3] Lee, K., Orailoglu, A.: Application speciï¬c non-volatile primary memory for em-
bedded systems. In: CODES/ISSS 2008: Proceedings of the 6th IEEE/ACM/IFIP
international conference on Hardware/Software codesign and system synthesis, pp.
31â€“36. ACM, New York (2008)
[4] Lin, J.H., Chang, Y.H., Hsieh, J.W., Kuo, T.W., Yang, C.C.: A nor emulation
strategy over nand ï¬‚ash memory. In: 13th IEEE International Conference on
Embedded and Real-Time Computing Systems and Applications, RTCSA 2007,
pp. 95â€“102 (2007)
[5] Lee, J.H., Park, G.H., Kim, S.D.: A new nand-type ï¬‚ash memory package with
smart buï¬€er system for spatial and temporal localities. Journal of Systems Archi-
tecture: the EUROMICRO Journal (2005)
[6] Lin, C.C., Chen, C.L., Tseng, C.H.: Source code arrangement of embedded java
virtual machine for nand ï¬‚ash memory, pp. 152â€“157 (2007)
[7] In, J., Shin, I., Kim, H.: Swl: a search-while-load demand paging scheme with
nand ï¬‚ash memory. In: LCTES 2007: Proceedings of the 2007 ACM SIG-
PLAN/SIGBED conference on Languages, compilers, and tools for embedded
systems, pp. 217â€“226. ACM, New York (2007)
[8] Lachenmann, A., MarrÂ´on, P.J., Gauger, M., Minder, D., Saukh, O., Rothermel,
K.: Removing the memory limitations of sensor networks with ï¬‚ash-based virtual
memory. SIGOPS Oper. Syst. Rev. 41, 131â€“144 (2007)
[9] Kim, J.C., Lee, D., Lee, C.G., Kim, K., Ha, E.Y.: Real-time program execution
on nand ï¬‚ash memory for portable media players. In: RTSS 2008: Proceedings of
the 2008 Real-Time Systems Symposium, Washington, DC, USA, pp. 244â€“255.
IEEE Computer Society, Los Alamitos (2008)
[10] Hyun, S., Lee, S., Ahn, S., Koh, K.: Improving the demand paging performance
with nand-type ï¬‚ash memory. In: ICCSA 2008: Proceedings of the 2008 Interna-
tional Conference on Computational Sciences and Its Applications, Washington,
DC, USA, pp. 157â€“163. IEEE Computer Society Press, Los Alamitos (2008)
[11] Joo, Y., Choi, Y., Park, C., Chung, S.W., Chung, E., Chang, N.: Demand paging
for onenandTM ï¬‚ash execute-in-place. In: CODES+ISSS 2006: Proceedings of the
4th international conference on Hardware/software codesign and system synthesis,
pp. 229â€“234. ACM, New York (2006)
[12] Park, C., Lim, J., Kwon, K., Lee, J., Min, S.L.: Compiler-assisted demand paging
for embedded systems with ï¬‚ash memory. In: EMSOFT 2004: Proceedings of the
4th ACM international conference on Embedded software, pp. 114â€“124. ACM,
New York (2004)
[13] Kim, S., Park, C., Ha, S.: Architecture exploration of nand ï¬‚ash-based multimedia
card. In: DATE 2008: Proceedings of the conference on Design, automation and
test in Europe, pp. 218â€“223. ACM, New York (2008)
[14] http://www.samsung.com (OnenandTM clock application note)
[15] Joo, Y., Choi, Y., Park, J., Park, C., Chung, S.W.: Energy and performance opti-
mization ofdemand paging with onenand ï¬‚ash. IEEE Transactions on Computer-
Aided Design of Integrated Circuits and Systems 27(11), 1969â€“1982 (2008)
[16] Al-Zoubi, H., Milenkovic, A., Milenkovic, M.: Performance evaluation of cache
replacement policies for the spec cpu2000 benchmark suite. In: ACM-SE 42: Pro-
ceedings of the 42nd annual Southeast regional conference, pp. 267â€“272. ACM,
New York (2004)

Key-Study to Execute Code Using Demand Paging and NAND Flash
117
[17] Belady, L.A.: A study of replacement algorithms for virtual storage computers.
IBM Systems Journal 5(2), 78â€“101 (1966)
[18] Denning, P.J.: The locality principle (2005)
[19] Courbot, A.: Eï¬ƒcient oï¬€-board deployment and customization of virtual machine
based embedded systems. ACM Transactions on Embedded Computing Systems
(2010)

Firewall Mechanism in a User Centric Smart
Card Ownership Model
Raja Naeem Akram, Konstantinos Markantonakis, and Keith Mayes
Information Security Group Smart card Centre, Royal Holloway, University of London
Egham, Surrey, United Kingdom
{R.N.Akram,K.Markantonakis,Keith.Mayes}@rhul.ac.uk
Abstract. Multi-application smart card technology facilitates applica-
tions to securely share their data and functionality. The security enforce-
ment and assurance in application sharing is provided by the smart card
ï¬rewall. The ï¬rewall mechanism is well deï¬ned and studied in the Is-
suer Centric Smart Card Ownership Model (ICOM), in which a smart
card is under total control of its issuer. However, it is not analysed in
the User Centric Smart Card Ownership Model (UCOM) that delegates
the smart card control to their users. In this paper, we present UCOMâ€™s
security requirements for the ï¬rewall mechanism and propose a generic
framework that satisï¬es them.
1
Introduction
The multi-application smart card initiative [1] ensures a secure and ï¬‚exible
execution environment for multiple applications from same or diï¬€erent organisa-
tions [2,3]. It facilitates the co-existence of interrelated and cooperative applica-
tions that augment each otherâ€™s functionality. This enables applications to share
their data as well as functionality with other applications, introducing a major
security concern of unauthorised inter-application communication. The solution
to this problem has been the smart card ï¬rewall.
The ï¬rewall acts as a supervisory authority on a smart card, monitoring inter-
application communications [4]. The main aim is to ensure security and reliability
of application sharing mechanisms even in adverse conditions such as caused
by a malicious application, a developerâ€™s mistake or design oversight [5]. The
ï¬rewall deployed in the Issuer Centric Smart Card Ownership (ICOM) is well
deï¬ned [6, 7, 8, 9, 5] and studied [10, 11, 12, 13]. However, this is not the case
for the ï¬rewall mechanism in the User Centric Smart Card Ownership Model
(UCOM) [14], and it is the focus of this paper.
The widely adopted smart card based business model is the ICOM [14,2,15].
In this model, smart cards are under total control of the issuing organisation,
referred to as the Card Issuer. Smart cards issued by a Card Issuer can host
multiple applications and if required these can be from diï¬€erent organisations.
Organisations that provide applications, but do not issue cards are referred to as
Application Providers (or Service Providers) and they are reliant on establishing
a business and trust relationship with Card Issuers. Card Issuers and Application
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 118â€“132, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Firewall Mechanism in a User Centric Smart Card Ownership Model
119
Providers also establish the necessary trust and assurance that the application
will not harm the card platform and vice versa. Such an explicit business and
trust relationship does not exist in the UCOM.
The UCOM gives the choice of applications to the users and they can request
to have any application on their cards. The request is sent to the corresponding
Service Provider (SP) in the UCOM. If the security assurance provided by the
smart card along with its services and user credentials are valid then the SP
leases its application(s) under certain terms and condition stipulated by the
SP [14]. Leased application(s) are controlled only by their respective SPs and
so this introduces unique issues regarding inter-application communications. In
this paper, we will analyse the functional nature of the UCOM and its eï¬€ects
on the ï¬rewall mechanism and propose a framework that is suitable for secure
operation.
In section two, we discuss the ï¬rewall mechanism within the multi-application
smart card environment and how they are implemented in popular smart card
platforms (e.g. Java Card [8] and Multos [9]). Section three describes unique
issues presented to the ï¬rewall mechanism in the UCOM. In section four, a
framework for a smart card ï¬rewall is presented that is suitable for the UCOM
environment. In section ï¬ve a case study brieï¬‚y illustrates how the framework
can be implemented, and ï¬nally section six provides the concluding remarks.
2
Multi-application Smart Card Platforms
In this section, we describe an application sharing mechanism in multi-application
smart card platforms and how it is implement in Java Card and Multos.
2.1
An Application Sharing Mechanism
The most adopted business and operational scenario for the smart card based
service model has been the ICOM [15]. For brevity, we will only discuss the
application sharing (ï¬rewall) mechanism related to the ICOM in this section.
Multi-application smart cards facilitate co-
Platform Runtime
Environment
Firewall
A
B
C
X
Fig. 1. A Generic Application
Sharing Mechanism
operative schemes enabling optimised memory us-
age, with scope for data and service sharing
between applications [15]. Therefore, a ï¬rewall
mechanism should ensure application segregation
while providing a secure and controlled way to al-
low applications to communicate data and share
functionality. In the ICOM the issuer provides the
platform security and reliability assurance, includ-
ing the application segregation [7] that is neces-
sary to avoid any on-card leakage of secret data.
A ï¬rewall is basically an access control mechanism that does not protect against
information propagation [7] (which is beyond the scope of this paper). In addi-
tion to protecting applications; the ï¬rewall mechanism should also protect the
platform by ensuring that applications can only access platform services through

120
R.N. Akram, K. Markantonakis, and K. Mayes
a well formed interface that cannot be used to subvert any protection of the
platform.
To explain the ï¬rewall mechanism refer to simple example illustrated in ï¬gure
1. Consider that there are three applications: A, B, and C. The Application
Providers of A and B have a trust relationship but Application Provider of
C is not fully trusted by them. Application A speciï¬es data and functionality
that it wants to share with B, these are termed as shareable resources. The
ï¬rewall facilitates the sharing with the help of the runtime environment. When
B requests access to the resource of A, the ï¬rewall veriï¬es the access credentials
and if successful it allows the access. However, in the case of a request from the
application C, the request will be denied.
The ï¬rewall should also segregate the platform runtime environment from the
application space. To execute privileged services the application(s) could only
make requests to the runtime environment through well formed Application Pro-
gramming Interfaces (APIs). The ï¬rewall should ensure that this communication
channel should not become a means to subvert the ï¬rewall in order to gain unau-
thorised access to resources from other applications.
2.2
Firewall Mechanism in Java Card
Java Card [4] is a smart card platform that supports a scaled down version of
the popular Java language. The architecture of a Java Card is shown in ï¬gure 2.
The Java Card Runtime Environment (JCRE) sits on top of the smart card
hardware and manages the on-card resources, applet execution and applet secu-
rity [8]. The JCRE consists of APIs (e.g. javacard.framework.APDU, Util and
Shareable) that an application can use to access JCRE services. The JCRE
also has system classes that are integral to its functions and these classes are not
visible to applications. Applets reside on top of the JCRE, and they are grouped
together into packages.
Smart Card Hardware
Java Card Runtime Environment (JCRE)
Java Card Virtual Machine (JCVM)
Native Methods
System Classes
Framework Classes (APIs)
Java Card Firewall
.
Package A
Package B
Applet A1
Applet A2
Applet B1
Applet B2
System
Context
Context A
Context B
SIO
JCRE Entry Point
Objects
Fig. 2. Java Card Architecture

Firewall Mechanism in a User Centric Smart Card Ownership Model
121
Each instance of an applet has a unique Application Identiï¬er (AID) [8].
An instantiated representation of an applet is termed an object. Each object is
associated with a context, including the JCRE objects (System Context). The
Java Card Virtual Machine (JCVM) only allows an object to execute if the
current "Active" context is the one from which it belongs. In ï¬gure 2, object
of AppletB1 will only executes if the "Active" context is context B. The ï¬rewall
restricts all cross context communication except for object sharing mechanisms:
JCRE Entry Point Objects and Shareable Interface Objects (SIO). All applets
in a package have the same context so there is no ï¬rewall between them.
The JCRE Entry Point Objects are instances of the Java Card APIs that can
be used by applications to access platform services. These objects are accessible
to all applets, and they enable non privileged (applets) applications to execute
privileged commands. The JCRE Entry Point Objects are implemented by the
Java Card manufacturer who is responsible for their security and reliability.
The SIO enables an application to share its resources with other authorised
application(s). To utilise the SIO functionality, an application should extend
the shareable interface (javacard.framework.Shareable) and the functionality
implemented in the extended class will be shareable with other applets.
When an object requests either an SIO or JCRE Entry Point Object, the
JCVM saves the current "Active" context and invokes the requested object along
with the associated context. Therefore, a shareable object always executes in its
own context, enabling it to access any applet from the package it belongs. By
taking into account ï¬gure 2 when AppletA1 calls the SIO of AppletB1, the JCVM
saves context A and invokes context B along with initiating the execution of the
SIO. The SIO object can then call any method in package B. Furthermore, it can
also call any JCRE Entry Point Object. When the SIO completes its execution,
the JCVM restores the previous context (context A).
2.3
Firewall Mechanism in Multos
Compared to Java Card, Multos [9] takes a diï¬€erent approach to the smart card
ï¬rewall. The Multos Card Operating System (COS) resides over the smart card
hardware as illustrated in ï¬gure 3a. The Multos COS administers communica-
tion, resource management, and the virtual machine [9]. Applications do not have
direct access to the Multos COS services, instead they utilise the Application
Abstract Machine that is a set of standard APIs consisting of instructions and
built-in functions. These APIs are used by applications to communicate with the
COS and request privileged services. The top layer is the application space, and
similar to Java Card the application segregation is implemented by the ï¬rewall.
In Multos, application delegation is implemented to facilitate application re-
source sharing. The application that initiates the process is called the delegator
and the application that is initiated is called the delegate. The process of dele-
gation works as described below and shown in ï¬gure 3b:
1. Application A (delegator) creates an APDU in the public memory and in-
vokes the delegate command. The APDU consists of application Bâ€™s AID,
requested data or function and delegatorâ€™s AID.

122
R.N. Akram, K. Markantonakis, and K. Mayes
Multos Firewall
Smart Card Hardware
Multos Operating System
Application Abstract Machine
Multos Firewall
MultosFirewall
Application
A
(Delegator)
Application
B
(Delegate)
INS
P1
P2
Lc
Le
SW1
SW2
Le
Data
Public Memory
Application
A
(Delegator)
Application
B
(Delegate)
1
2
3
4
(a) Multos Card Architecture
(b) Multos Application Sharing Mechanism
Fig. 3. Multos Card Architecture and Firewall Mechanism
2. The Multos COS initiates the execution of B that looks for the APDU in
the public memory. It reads the APDU and processes it.
3. On completion, B creates a response APDU within the public memory.
4. The Multos COS switches back to A that then retrieves Bâ€™s APDU.
In both Java Card and Multos, additional measures are implemented in con-
junction with the ï¬rewall mechanism to protect the platform. These measures
include byte-code veriï¬cation (on-card and oï¬€-card) [16,17], strict mechanism to
install applications [18] and virtual machine based security mechanisms [19,20].
3
User Centric Smart Card Ownership Model
In this section, we discuss the security and operational requirements for a ï¬rewall
mechanism in the UCOM.
3.1
Application Sharing Requirements
The UCOM is expected to support a dynamic service environment with a wide
range of application types. Therefore, the ï¬rewall mechanism should also reï¬‚ect
this dynamic nature [14].
Inter-application Communication. The UCOM ï¬rewall should facilitate a
ï¬‚exible mechanism that enables a server application1 to implement a hierarchical
access level ï¬rewall. In such a ï¬rewall, a server application assigns shareable
resources according to diï¬€erent access levels. A client application2 is initially
assigned an access level although the server application can also revoke, upgrade,
or demote the existing privileges of a client application, illustrated by ï¬gure 4.
1 Server application: An application that provides shareable data or functionality to
authorised applications.
2 Client application: An application that requests the shareable resources of a server
application. The notation to present this relationship is Server â†’Client.

Firewall Mechanism in a User Centric Smart Card Ownership Model
123
H0 (FH0)
H1 (FH1)
H2 (FH2)
H4 (FH4)
Application A
Application B
(H2, -FExceptionB)
Application C
(H1, -FExceptionC)
Application A
Application C
(H2, -FExceptionC)
Application B
(H1, -FExceptionB)
(b) Sharing Status at time T1
(c) Sharing Status at time T2
(a) Access Levels
Fig. 4. Hierarchical Access Level Firewall
Consider an application A that oï¬€ers shareable data and functionality divided
into diï¬€erent hierarchical levels. Requesting applications are only authorised to
access data or functionality matching assigned level. In ï¬gure 4a, there are four
hierarchical levels with H0 the lowest and H3 the most privileged level. The data
and functionality associated with each level is denoted by the "FLevel". The "-
FException" is the negative permission, that lists the data or functionality that is
not authorised to an application for the given access privileges. Application A
keeps track of access levels along with -FException" associated with each applica-
tions. Application Bâ€™s access privileges (H2, -FExceptionB) will be read as B has
access to all data and function associated with level H2 (FH2)and below (FH0
and FH1) with an exception of data or functionality of "-FExceptionBâ€™. B and C
have access rights "H2, -FExceptionB" and "H1, -FExceptionC" respectively for A
at time T1. At some later time (T2) A modiï¬es the access privileges of B and C,
demoting B to H1 and upgrading C to H2. In addition, the ï¬rewall mechanism
will also allow the modiï¬cation of the "-FException".
Unlike the present Java Card or Multos ï¬rewalls, in the UCOM the sharing
permissions will have limited lifetime and on expiry the client application(s) have
to renegotiate the access permissions with the server application.
Application Sharing Delegation. A client application can delegate access to
a server application (after authorisation) to another application on its behalf.
Consider the following scenario with three applications A, B, and C. There is
an application sharing relationships Aâ†’B, and B â†’C; but none between A and
C. Let us assume by way of example that application B gives royalty points if
the cardholder uses A and these points are redeemable from C. Therefore, usage
of A can lead to redeemable points (beneï¬ts) from C. At some point in time, the
cardholder requests the deletion of application B and it requests the permission
from A to delegate its sharing privileges to C. It is at the sole discretion of Aâ€™s
SP whether it would allow such an action or not. The SP of A may allow such
action completely or impose conditions such as demoting the privileges to the
lowest possible level for application C. Therefore from this point of time, C can
access A on behalf of the B.
Application-Platform Communication. This requirement deals with bi-
directional communication between an application and a smart card platform
and it is sub-divided into two sections as listed below.

124
R.N. Akram, K. Markantonakis, and K. Mayes
Application to Platform Communication. Platforms make their services available
to applications either through Entry Point Objects [8] or standard APIs [9]. In
both cases, applications may have access to more platform services than required
that would not be desirable in the UCOM [14]. In the UCOM, applications
are only given access to those platform services that are authorised by their
SPs. The ï¬rewall ensures that an application cannot have access to any other
services from the platform for which it is not authorised. This allows the SPs to
control their applicationsâ€™ behaviours, especially in terms of on-card and oï¬€-card
communication.
Platform to Application Communication. Java Card (like other multi-application
smart cards) provides global access rights to the platform. The global access
rights mean that an object of JCRE System Context can access any method
(object) in any of the application contexts. However, the Java Card speciï¬cation
explicitly notes that the platform should only access certain methods (select,
process, deselect, or getShareableInterfaceObject) from an applet con-
text [8, see section 6.2.3]. In case of the UCOM, the ï¬rewall should ensure that
a platform cannot have access to methods that are not sanctioned by the ap-
plication SPs. Furthermore, it should enable an object or method to verify the
requesting source. For example if the source is the platform, and it is trying
to access an object or method not sanctioned by the corresponding SP, then it
should throw a security exception.
Privacy Issues. In the UCOM, cardholders can have diverse applications on
their smart cards, and each of these applications may represents their identity in
some context. The ï¬rewall mechanism should not allow an application to discover
the existence of other applications, because such a privilege could be abused
to proï¬le a user, perhaps for marketing or fraudulent purposes. In Java Card,
public static AID lookupAID can be used to list the installed applications.
It is not an issue in the ICOM as there is a central authority (card issuer) that
has prior knowledge of installed applications and policed their functionality.
However, it is a potential privacy threat in the UCOM.
4
Proposed Framework for the UCOM Firewall
In this section, the architecture of the proposed UCOM ï¬rewall is described
along with explanation of its operations.
4.1
Overall Architecture
The UCOM is a smart card operating system and platform independent frame-
work [14]. However, for brevity, clarity and intuitiveness we consider the Java
Card ï¬rewall mechanism as the basis of our proposal. To illustrate the UCOM
ï¬rewall, ï¬gure 5 shows a generic architectural view of the UCOM smart card
that is principally similar to the Java Card (shown in ï¬gure 3).
The Runtime Environment (RE) Resource Manager controls the access to the
RE Entry Point Objects that are used to access platform services. The resource

Firewall Mechanism in a User Centric Smart Card Ownership Model
125
UCOM Firewall
Smart Card Hardware
Runtime Environment
Application Programming Interfaces (APIs)
Runtime Environment Entry Point Objects
RE Resource Manager
Virtual Machine
Native Code
UCOM Firewall
Package A
Package B
Applet A1
Applet A2
Applet B1
Applet B2
SIOs
Application Resource
Manager (ARM)
System
Context
Context B
Context A
System Classes
ACL
ACL
Application Resource Manager
(ARM)
Fig. 5. Generic Architecture of User Centric Smart Card Firewall Mechanism
manager will enforce the security policy for applications as deï¬ned by the SPs,
limiting the access to the platform resources as stipulated by the policy.
For each application (package), an Application Resource Manager (ARM) is
introduced. This component will act as the authentication and resource allo-
cation point. A client application will request a server applicationâ€™s ARM for
shareable resources. The ARM will decide whether to grant the request based
upon the clientâ€™s credentials (associated privileges). At the time of application
installation, the ARM also establishes a shareable interface connection with the
platform, enabling it to access methods that are essential for the application exe-
cution. The platform can access any method in the application context only after
authorisation from the applicationâ€™s SP. The ARM also receives information re-
garding the requesting application. If the request is from the system context for
a method that is not allowed to be accessed by the platform, then the ARM will
throw a security exception.
An Access Control List (ACL) is a private list and it is used to facilitate the im-
plementation of the hierarchical access mechanism. It can be update remotely by
the corresponding SP via the ARM, enabling the SP to change the behaviour of
its applicationâ€™s sharing mechanism. The ACL holds the lists of granted permis-
sions, received permissions (permissions to access other applicationâ€™s resources)
and a cryptographic certiï¬cate revocation list of client applications. The struc-
ture of an ACL is under the sole discretion of its SP.
The operations of the UCOM ï¬rewall can be sub-divided into two distinctive
phases. In phase one, a binding is established between the client and server
applications. This process includes authentication of the clientâ€™s credentials and

126
R.N. Akram, K. Markantonakis, and K. Mayes
access privileges by the serverâ€™s ARM. In the second phase, the client application
requests resources in line with the privileges sanctioned by the ARM.
To have a consistent view of the sharing mechanism over diverse application
scenarios, the description of the application binding and resource request process
are deliberately deï¬ned in high-level representations. The ï¬ne details of these
processes are left to the individual preferences of the SPs. The UCOM ï¬rewall
mechanism supports these operations but does not deï¬ne the minute details.
4.2
Application Binding
This process deals with the ï¬rst request by a client application for shareable
resource(s) of a server application (phase one). Upon receiving the request, the
server application ï¬rst ascertains that the requesting application is the autho-
rised application as it claims. After authentication, both applications establish
a cryptographic binding that is used in all future requests.
Application A
(Client)
Firewall
Application B
(Server)
BindingReq( ServerAID, ClientAID, Client Credentials)
Firewall verifies whether Application B
exists on card or not.
Verifies the Client Credentials
BindingReq( ClientAID, Client Credentials)
Initiate Authentication Protocol
Error in case B does not exist
or denies Binding Request
Fig. 6. Illustration of Application Binding Request Process
The process is illustrated in ï¬gure 6 and explained as below. Application A
(client) sends a binding request message. This message consists of application
Bâ€™s (server) Application Identiï¬er (AID), along with Aâ€™s AID and credentials.
The nature of the credentials can be at the sole discretion of the server appli-
cation. However, to explain the process we use cryptographic certiï¬cates [21].
The SP of the server application, issues a cryptographic certiï¬cate to the client
applicationâ€™s SP who in return issues individual (unique) certiï¬cates for its ap-
plications, certifying the unique public key pair of each client application. As the
root authority (Certiï¬cation Authority [21]) is the SP of a server application,
any instance of the server application will be able to verify and accept it. On
receiving the binding request the ï¬rewall mechanism looks up for the ServerAID
to verify whether the application exists on the card or not. If it exists, the request
would be forwarded to the corresponding ARM. Conversely, if the application
does not exist, or server turns down the binding request, the ï¬rewall mechanism
would throw an exception that would be same in both cases, to avoid a mali-
cious application from potentially discovering the existence of an application on
a card.
If the ï¬rewall forwards the request to the server application (Application B),
it veriï¬es the requesting applicationâ€™s credentials by initiating an authentication

Firewall Mechanism in a User Centric Smart Card Ownership Model
127
protocol. The outcome of the authentication protocol is generation and veriï¬ca-
tion of a cryptographic (symmetric) binding key [22]. The client application will
use this key in all future resource requests and in any related operation discussed
in the subsequent sections. SPs should ensures that their authentication protocol
is secure against application impersonation [22], and replay attacks [21].
4.3
Requesting Resource
A client application can request the server applicationâ€™s shareable resource as it
required (subject to valid access permissions) as illustrated by ï¬gure 7.
Firewall
Application B (Server)
ARM
Shareable Resources
ACL
Application A (Client)
ACL
Requesting
Component
Req(ClientAID, EBindingKey(),Access Permission,
Resource Required, Random Number)
Permision
Permision
Permision
ResAllocation(ResourceObjectRef, Lifetime)
RequestService
Fig. 7. Application Shareable Resource Access Request Process
The request message sent to the corresponding ARM consists of a ClientAID,
an authenticator (message encrypted with binding key), access permission, re-
quired resource and a random number to provide freshness [21]. By verifying
the authenticator, the ARM ascertains the origin of the message, i.e. the client
application. Subsequently it checks the access permission for the client applica-
tion (from the server applicationâ€™s ACL). If the client application is authorised
to access the requested resource, the ARM would return the resourceâ€™s object
reference along with the sharing lifetime.
As described in section 3.1, the client application may have negative permis-
sion. To implement negative permission control each of the data or methods
of the shareable resource is tagged with a unique ID. When the client appli-
cation accesses a method from a shareable resource object, the unique ID of
the method is compared with the negative permissions. If there is a match the
method returns with an exception.
4.4
Privilege Modiï¬cation
The SP of a server application can modify the privileges of a client application by
updating the ACLs. The ARM of the server application veriï¬es the initiatorâ€™s
(SPâ€™s) identity and credentials, before it allowing the update of the ACL(s).
The implementation of the privilege modiï¬cation is at the sole discretion of the
SP. However, such an update could be similar to application update mechanism
already deployed, notably Over-The-Air updates in (U)SIM application [23].

128
R.N. Akram, K. Markantonakis, and K. Mayes
4.5
Application Sharing Delegation
This functionality of the UCOM ï¬rewall is subject to the sharing terms and con-
ditions between the relevant SPs, which will grant or deny requests as
appropriate.
Delegated Application
Client Application
Server Application
ECS (ClientAID, DelegatedApplication AID,
Liftime, RandomNumber)
ECS(ServerAID, DelegatedAppliation AID, KAuthorisation,
Permission, Lifetime, RandomNumber)
Decides Permission Level and
Generate Authorisation Key
Request Binding Key
EDC(ServerAID, DelegatedAppliation AID, KAuthorisation,
Permission, Lifetime, RandomNumber)
ECS: Binding Key between Client and Server Applications
EDS: Binding Key between Delegated and Client Applications
KAuthorisation: Key that authenticates the Delegated application when it makes the binding key request.
Fig. 8. Application Sharing Devolvement Dialogue
The privilege level of an application (delegated application) to which the client
application delegates the resource-sharing does not have to be the same as itself.
The privilege level of the delegated application is at the sole discretion of the
server applicationâ€™s SP. The steps involved in the process of resource sharing
delegation are listed below.
1. A client application requests a server application to delegate its resource-
sharing privilege to another application.
2. According to the server applicationâ€™s policy, it can either keep the same
level of privileges as the client application or demote the privileges for the
delegated application. The server application generates a message encrypted
by the binding key (Serverâ†’Client binding key) and sends it to the client
application. The message contains Server AID, DelegatedApplication AID,
Access permissions, Delegation lifetime and Delegation Request Key.
3. The client application decrypts the message and re-encrypts it with the
Clientâ†’Delegated binding key and sends it to delegated application.
4. The delegated application uses it to authenticate itself to the server appli-
cation and establishes a binding (section 4.2).
Once the delegation is completed, the client application cannot have access to the
shareable resources, unless it requests the resource delegation to be terminated.
The termination process is similar to the delegation process. Therefore, only
one application (either client or delegated application) can access the shareable
resources. The ï¬rewall mechanism ensures that once the resource delegation is
terminated, the delegated application cannot have access to the resources.

Firewall Mechanism in a User Centric Smart Card Ownership Model
129
4.6
Application-Platform Communication
At the time of installation, an application establishes bidirectional resource shar-
ing with the platform. The application can access those platform APIs that are
stipulated in the SPâ€™s application lease policy [14] and the platform obtains the
shared resources of the application that are necessary to initiate the application
execution. The platform security context does not have global access in UCOM
based smart cards. This is to avoid any possible exploitation of the platform
that could lead to the information leakage (data or code) from an application.
The resource-sharing delegation is disabled in the platform-application commu-
nication and the ï¬rewall would deny such requests to avoid any illegal access to
the APIs by an application through resource sharing delegation.
5
Case Study
In this section, a UCOM case study is discussed of an electronic purse application
with special functionality. The described implementation is simply to illustrate
the ï¬rewall mechanism.
5.1
Overall Scenario
In this scenario there are three applications, Electronic Purse, ABC Airline and
XYZ Rentacar. The electronic purse application has a trust relationship with
the other two applications but with diï¬€erent privilege levels. Whenever the card-
holder uses the Electronic Purse application, royalty points can be earned for the
airline application that can either be redeemed from the airline or from rent a car
service. For brevity, the details are brief focusing only on the ï¬rewall mechanism.
The electronic purse application implements the shareable resources as illus-
trated by ï¬gure 9a. These resources have unique identiï¬ers that are used to
implement negative permission. The identiï¬er is in the form of a byte value. For
example, the byte gainRoyality() of the airline shareable resources, has the
identiï¬er "0x0001" represented by the private static byte gainRoyalityID.
To enforce the negative permission, method identiï¬ers are listed in the ACL that
a method should check when it receives a request from the client applications.
Client Application
ABC Airline
XYZ Rentacar
â€¦...
Electronic Purse (Server)
Shareable Resources
Hierarchical Level
H1
H0
...
Negative Permission
Non
Non
â€¦.
Delegated
false
false
â€¦.
Hierarchical Levels:
H1: Access allowed to Airline and RentaCar Shareable Resources
H2: Access allowed to only RentaCar Shareable Resources
(a) Electronic Purse Shareable Resouces
(b) ACL Implementation
byt e gai nRoyal i t y( )
bool ean r ent ACar Ser vi c e
( booki ng,
payment )
RentaCar Shareable Resources
byt e gai nRoyal i t y( )
bool ean ai r l i neSer vi c e
( booki ng,
payment )
Airline Shareable Resources
Fig. 9. Electronic Purse Application Implementation

130
R.N. Akram, K. Markantonakis, and K. Mayes
5.2
Implementation Examples
In this section, we will describe the details of the SPâ€™s dependent components of
the UCOM based ï¬rewall mechanism, which are listed below:
Authentication Protocol. The protocol [24] is based on two steps. In the ï¬rst
step the protocol initiates the mutual authentication, and at the second step a
symmetric key is mutually generated and shared.
Authenticator. It is an encrypted message that veriï¬es the identity of a client
application. The authenticator for the airline application is EBindingKeyABC(ABC-
Identity | ResourceRequested | Random Number | Lifetime). The electronic purse
application also calculates the authenticator, and if the results are the same then
the ABC Airline request would be authenticated.
Application Sharing Delegation. The ABC airline application requests the
resource sharing delegation. The electronic purse application only allows the
delegated application to access the gainRoyality(). The resource sharing del-
egation process will upgrade the XYZ Rentacar applicationâ€™s privileges to H1
with negative permission for private static byte airlineServicesID.
This case study shows a simplistic view of an implementation of those ï¬rewall
components that are left to a SPâ€™s discretion. The proposed framework provides
a supporting platform that enables individual SPs to either implement their
proprietary or well studied public algorithm to protect their shareable resources.
This enables them to implement the crucial element of the ï¬rewall, and remove
any possible ambiguity in diï¬€erent implementations (by card manufacturers).
6
Conclusion
In this paper, we discussed popular smart card based ï¬rewall mechanisms and
how they work. Then we described the unique security requirements of the
UCOM and presented an appropriate ï¬rewall mechanism extended from the
Java Card ï¬rewall. During the research, the Multos based ï¬rewall mechanism
was considered unsuitable for the open and dynamic environment that UCOM
aims to support, because the security of the Multos ï¬rewall is reliant on the
stringent application installation mechanism. In addition to implementing the
traditional ï¬rewall controls, we also presented functionality that is lacking in
the present popular ï¬rewall mechanism, but we consider them to be useful for
the UCOM proposal. Future research directions will focus on implementation to
test performance and practical feasibility of such proposals.
References
1. Deville, D., Galland, A., Grimaud, G., Jean, S.: Smart card operating systems: Past,
present and future. In: Proceedings of the 5 th NORDU/USENIX Conference (2003)
2. Sauveron, D.: Multiapplication Smart Card: Towards an Open Smart Card? Inf.
Secur. Tech. Rep. 14(2), 70â€“78 (2009)

Firewall Mechanism in a User Centric Smart Card Ownership Model
131
3. Chaumette, S., Sauveron, D.: New Security Problems Raised by Open Multiappli-
cation Smart Cards. LaBRI, UniversitÃ© Bordeaux 1 (2004), RR-1332â€“04
4. Chen, Z.: Java Card Technology for Smart Cards: Architecture and Programmerâ€™s
Guide. Addison-Wesley Longman Publishing Co., Inc., Boston (2000)
5. Montgomery, M., Krishna, K.: Secure Object Sharing in Java Card. In: WOST
1999: Proceedings of the USENIX Workshop on Smartcard Technology, p. 14.
USENIX Association, Berkeley (1999)
6. Ã‰luard, M., Jensen, T.P., Denney, E.: An Operational Semantics of the Java Card
Firewall. In: Attali, S., Jensen, T. (eds.) E-SMART 2001. LNCS, vol. 2140, pp.
95â€“110. Springer, Heidelberg (2001)
7. Bernardeschi, C., Martini, L.: Enforcement of Applet Boundaries in Java Card
Systems. In: IASTED Conf. on Software Engineering and Applications, pp. 96â€“101
(2004)
8. Java Card Platform Speciï¬cation; Application Programming Interface, Runtime
Environment Speciï¬cation, Virtual Machine Speciï¬cation. Sun Microsystem Inc
Std. Version 2.2.2 (March 2006), http://java.sun.com/javacard/specs.html
9. Multos: The Multos Speciï¬cation, Online, Std., http://www.multos.com/
10. Huisman, M., Gurov, D., Sprenger, C., Chugunov, G.: Checking Absence of Illicit
Applet Interactions: A Case Study. In: Wermelinger, M., Margaria-Steï¬€en, T. (eds.)
FASE 2004. LNCS, vol. 2984, pp. 84â€“98. Springer, Heidelberg (2004)
11. Mostowski, W., Poll, E.: Malicious Code on Java Card Smartcards: Attacks and
Countermeasures. In: Grimaud, G., Standaert, F.-X. (eds.) CARDIS 2008. LNCS,
vol. 5189, pp. 1â€“16. Springer, Heidelberg (2008)
12. Ã‰luard, M., Jensen, T.: Secure Object Flow Analysis for Java Card. In: CARDIS
2002: Proceedings of the 5th conference on Smart Card Research and Advanced
Application Conference, p. 11. USENIX Association, Berkeley (2002)
13. Bieber, P., Cazin, J., Marouani, A.E., Girard, P., Lanet, J.L., Wiels, V., Zanon, G.:
The PACAP Prototype: A Tool for Detecting Java Card Illegal Flow. In: Attali, I.,
Jensen, T. (eds.) JavaCard 2000. LNCS, vol. 2041, pp. 25â€“37. Springer, Heidelberg
(2001)
14. Akram, R.N., Markantonakis, K., Mayes, K.: Application Management Framework
in User Centric Smart Card Ownership Model. In: Youm, H.Y., Jang, J. (eds.)
WISA 2009. LNCS, vol. 5932, pp. 20â€“35. Springer, Heidelberg (2009)
15. Girard, P.: Which Security Policy for Multiplication Smart Cards? In: WOST 1999:
Proceedings of the USENIX Workshop on Smartcard Technology, p. 3. USENIX
Association, Berkeley (1999)
16. Basin, D.A., Friedrich, S., Posegga, J., Vogt, H.: Java Bytecode Veriï¬cation by
Model Checking. In: Halbwachs, N., Peled, D.A. (eds.) CAV 1999. LNCS, vol. 1633,
pp. 491â€“494. Springer, Heidelberg (1999)
17. Basin, D.A., Friedrich, S., Gawkowski, M.: Veriï¬ed Bytecode Model Checkers. In:
CarreÃ±o, V.A., MuÃ±oz, C.A., Tahar, S. (eds.) TPHOLs 2002. LNCS, vol. 2410, pp.
47â€“66. Springer, Heidelberg (2002)
18. Colby, C., Lee, P., Necula, G.C., Blau, F., Plesko, M., Cline, K.: A Certifying
Compiler for Java. In: PLDI 2000: Proceedings of the ACM SIGPLAN 2000 con-
ference on Programming language design and implementation, pp. 95â€“107. ACM,
New York (2000)
19. Barthe, G., Dufay, G., Jakubiec, L., Melo de Sousa, S.: A Formal Correspondence
between Oï¬€ensive and Defensive JavaCard Virtual Machines. In: Cortesi, A. (ed.)
VMCAI 2002. LNCS, vol. 2294, pp. 32â€“45. Springer, Heidelberg (2002)

132
R.N. Akram, K. Markantonakis, and K. Mayes
20. BÃ¶rger, E., Schulte, W.: Deï¬ning the Java Virtual Machine as Platform for Prov-
ably Correct Java Compilation. In: Brim, L., Gruska, J., ZlatuÅ¡ka, J. (eds.) MFCS
1998. LNCS, vol. 1450, pp. 17â€“35. Springer, Heidelberg (1998)
21. Schneier, B.: Applied cryptography: protocols, algorithms, and source code in C,
2nd edn. John Wiley & Sons, Inc., New York (1995)
22. Deville, D., Grimaud, G.: Building an â€œimpossible" veriï¬er on a java card. In:
WIESS 2002: Proceedings of the 2nd conference on Industrial Experiences with
Systems Software, p. 2. USENIX Association, Berkeley (2002)
23. Mayes, K., Markantonakis, K. (eds.): Smart Cards, Tokens, Security and Applica-
tions. Springer, Heidelberg (2008)
24. Markantonakis, K., Mayes, K.: A Secure Channel protocol for multi-application
smart cards based on public key cryptography. In: Chadwick, D., Prennel, B. (eds.)
CMS 2004 - Eight IFIP TC-6-11 Conference on Communications and Multimedia
Security, pp. 79â€“96. Springer, Heidelberg (2004)

Combined Attacks and Countermeasures
Eric Vetillard and Anthony Ferrari
Trusted Labs, 790 Avenue Maurice Donat, 06250 Mougins, France
Abstract. Logical attacks on smart cards have been used for many
years, but their attack potential is hindered by the processes used by
issuers to verify the validity of code, in particular bytecode veriï¬cation.
More recently, the idea has emerged to combine logical attacks with a
physical attack, in order to evade bytecode veriï¬cation. We present prac-
tical work done recently on this topic, as well as some countermeasures
that can be put in place against such attacks, and how they can be
evaluated by security laboratories.
1
Forward
This paper presents theoretical work1 related to the development of attacks that
combine logical attacks on the cardâ€™s software with physical attacks on the cardâ€™s
hardware. This particular piece of work has been performed on Java Card-based
smart cards. However, we will see that the new attacks can be applied to other
platforms, and Java Card has mostly been chosen because it is the most common
interoperable smart card application platform.
2
Background
2.1
Physical Attacks
Smart cards have been subject to physical attacks since their inception. Attack
techniques have evolved over time, and new attacks are being invented or en-
hanced all the time, either on the ï¬eld (by hackers) or in security laboratories.
However, most of the attacks fall in two main categories: observation attacks,
whose goal is to observe the behavior of the card through some kind of side chan-
nel (timing, power consumption, electromagnetic signals, etc.), and perturbation
attacks, whose goals is to modify the behavior of the card, usually by inducing
a fault in the silicon.
Around 2000, observation attacks were greatly enhanced by the appearance
of complex power analysis attacks, and in particular Diï¬€erential Power Analysis
(DPA, [6]). In the recent years, most developments have focused on fault induc-
tion attacks. When these attacks were invented, they were highly unpredictable,
with low success rates. Recently, some laboratories have achieved very high suc-
cess rates on very precise attacks, allowing attackers to design sophisticated
attack paths.
1 This work has been made possible by sponsorship from MasterCard International,
and has been practically implemented through a collaboration with the EDSI labo-
ratory, who performed the hardware attacks.
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 133â€“147, 2010.
c
âƒIFIP International Federation for Information Processing 2010

134
E. Vetillard and A. Ferrari
2.2
Logical Attacks
As smart cards grew more complex, so did their embedded software. In the
end of the 1990â€™s, a few systems appeared that allowed multiple applications
to run on the same smart card. These systems, such as Multos and Java Card,
introduced an additional abstraction layer, a virtual machine, which separated
the smart cardâ€™s system layer from its applications, and allowed the system layer
to perform adequate security checks when running applications.
With the ability to load code, these systems also opened the possibility to load
malicious code. This led to the development of logical attacks. Although such
attacks can be applied on any system that allows code loading, the work has
mostly focused on Java Card, for two reasons: ï¬rst, it has always been an open
system, whose speciï¬cation is readily available; second, Java Card has become
the dominant smart card middleware layer.
Commercial security evaluation laboratories, such as Trusted Labs, have used
such attacks for several years in the evaluation of the security of smart cards.
However, these attacks have remained conï¬dential for a few years, even though
the security of smart cards was studied [3] but recent work from the Radboud
University Nijmegen [9] and from University of Limoges [7] have made some
basic logical attacks publicly available.
There are mostly two categories of logical attacks that can be used on a system
like Java Card:
â€“ Illegal bytecode. The attack leverages the fact that Java Card cards are not
able to verify that the bytecode that runs is valid (contrarily to other Java
virtual machines, running on servers, workstations, or mobile phones). These
attacks are quite powerful, and they achieve good results on many platforms.
â€“ Bug exploitation. The attack uses legal bytecode that exploits a bug on the
platform. Typical exploitable bugs are buï¬€er overï¬‚ow bugs, which result
from missing checks, usually in lower layers of the cardâ€™s software. Attack
applications of this kind can be veriï¬ed (their code is correct), and they can
therefore be loaded on actual cards. However, they are speciï¬c to a given
platform.
In both cases, there is a practical limitation today, as very few applications are ac-
tually downloaded into smart cards. In addition, the management of applications
is restricted on deployed cards, which makes it diï¬ƒcult to load malicious code
to perform actual attacks. Attacks based on illegal bytecode face an additional
limitation, since application loading procedures usually require the veriï¬cation
of bytecode in order to detect such attacks.
In a typical attack path based on logical attacks, illegal bytecode is used
in the attack design phase. Such code is loaded on development cards by the
attacker, in order to determine the operational and security characteristics of the
platform. At the same time, extensive testing is performed in order to identify
an exploitable bug. If both parts are successful, the results are then combined to
write an attack application that exploits a platform bug to perform an attack.
Of course, since this last attack application exploits a bug, it is perfectly legal,
and its bytecode can be successfully veriï¬ed.

Combined Attacks and Countermeasures
135
With such attacks, it is possible to cover all typical smart card threats: code
and data disclosure, useful for reverse engineering; data modiï¬cation; and even
code modiï¬cation and injection in some cases, usually successful. Ultimately, in
some cases, conï¬dential data disclosure can be achieved.
The illegal bytecode and the exploited bugs have varied eï¬€ects, but the basic
components are often the same:
â€“ Type confusion. This is the most documented attack, which is used to trans-
form integral values into references and vice-versa. The illegal references can
then be used to access data illegally.
â€“ Tampering with system data. Modifying an objectâ€™s descriptor or a stack
frame can be used to modify the execution context, and get access to data
illegally.
â€“ Illegal jump. Jumping illegally in the bytecode may allow a malicious appli-
cation to jump into hidden attack code, or even dynamically loaded code, if
the jump targets the content of an array.
â€“ Buï¬€er overï¬‚ow/underï¬‚ow. A very basic tool, which can be used on arrays,
of course, and also on frames and on system buï¬€ers.
Of course, card designers have added countermeasures to their implementations,
in order to make all of these attacks more diï¬ƒcult. Some of these countermea-
sures are actually part of the Java Card speciï¬cation (or companion speciï¬ca-
tions), whereas some others have been designed by developers in order to make
their platforms more robust:
â€“ GlobalPlatform application management. This is a very basic countermea-
sure, as well as a highly eï¬ƒcient one. Most Java Card platforms also im-
plement GlobalPlatform, which will require at least a cryptographic authen-
tication before to allow any application management operation. This is of
course a strong limitation for logical attackers.
â€“ Java Card ï¬rewall. A Java Card platform hosts persistent data that belongs
to several diï¬€erent applications. The ï¬rewall is a mechanism that ensures
that an application cannot access another applicationâ€™s data, unless that data
has been explicitly shared. The Java Card speciï¬cation does not mandate
any speciï¬c implementation, so the strength of the ï¬rewall greatly varies
among platforms.
â€“ Defensive virtual machines. Making a virtual machine defensive explicitly
targets logical attacks, by making the virtual machine perform runtime
checks that are redundant with the Java Card bytecode veriï¬cation. The
main issue is here performance, since adding redundancy at the virtual ma-
chine level has obvious costs.
â€“ Advanced memory layouts. The ï¬rst implementations of Java Card mostly
used a ï¬‚at memory model, in which user data was mixed with security at-
tributes, and in which objects from diï¬€erent applications could be mixed. As
memory grew and memory management became more complex, the layouts
also changed, often becoming a countermeasure, in particular against system
data disclosure.

136
E. Vetillard and A. Ferrari
â€“ Classical countermeasures. Naturally, most classical countermeasures are
used on Java Card platforms. Conï¬dential objects are stored encrypted, and
integrity-sensitive objects are implemented with enough redundancy.
With all these countermeasures, or even with a subset, it is in most cases diï¬ƒ-
cult to identify an attack path based on logical attacks, except on the weakest
platforms.
3
Mixing Physical and Logical Attacks
An idea that has been around for a while is to mix physical and logical attacks
in order to build a successful attack path on a platform or application. In most
cases, the high-level attacks is performed at the logical level, while physical
attacks are used to thwart the countermeasures included on the platforms. Here
are a few ways in which physical attacks can make logical attacks easier:
â€“ GlobalPlatform attacks. One of the main limitations of logical attacks is
that they are based on malicious code. This code cannot be loaded on cards
by following standard content management procedures. By attacking Glob-
alPlatformâ€™s cryptographic mechanisms, physical attacks may allow a logical
attack application to be loaded on a given platform. Since most platforms
donâ€™t include on-card bytecode veriï¬cation, if such attacks succeed on a plat-
form, it becomes possible to include logical attacks in attack paths on such
platforms.
â€“ Memory dumps. It is possible to perform partial memory dumps using log-
ical attacks during the reverse engineering phase; however, physical attacks
provide ways to perform more complete memory dumps, in particular of the
EEPROM.
â€“ Execution trace analysis. It is possible, for instance by using power analysis
[10], to ï¬gure out the sequence of instructions that is executed. Such attacks
allow attackers to know precisely the sequence of bytecode instructions that
runs, and to understand where to attack.
Similarly, logical attacks can make physical attacks easier, at least in a lab-
oratory setting. The ability to load a well-known application, designed to be
attacked, greatly simpliï¬es the attackerâ€™s job. For instance, designing an attack
on a counter is much easier on a platform where the attacker has the ability to
reset the counter at will.
Overall, an attack scenario is likely to comprise many steps, in which logical
and physical attacks will be mixed. In a typical laboratory scenario, we may
start by getting a memory dump by a physical attack, then design a few logical
attacks in order to get a better understanding of the platformâ€™s protections, and
ï¬nally use a physical attack on a speciï¬c part of the code.
Over the years, we have developed a speciï¬c methodology for performing
evaluations in which logical and physical attacks are mixed, by collaborating
with several hardware labs. In a typical evaluation, we provide the code for

Combined Attacks and Countermeasures
137
the attack applications, as well as the guidelines for performing the attacks
(how the attack point can be located, how the attack should be performed, and
which results are expected). The hardware laboratory performs the attack (which
often requires state-of-the-art techniques), and returns us the results. We then
analyze the results obtained (for instance, a memory dump), and then provides
the laboratory with new guidelines.
With such collaborations, it has been possible to exploit a wide range of
software vulnerabilities, beyond traditional areas such as user authentication
and cryptography.
4
Combined Attacks
It has now become possible to push the collaboration between hardware and
software laboratories one step further, by designing attacks that can be applied
in a systematic way on smart card application platforms. Such attacks have been
designed by making the hypothesis that speciï¬c hardware attacks are possible,
and by then determining the possible eï¬€ect of these attacks on application mid-
dleware. The result of this analysis is a list of possible vulnerabilities, and an
evaluation then consists in ï¬guring out which ones are actually available on a
given platform.
This approach has always been possible, but two factors have made it more
interesting in the past few years:
â€“ Attacks have become more accurate. In particular, the accuracy and success
rate of fault induction attacks have greatly improved, making these attacks
exploitable.
â€“ Smart card software has become much more complex. Several application
platforms are available, and the current shift to ï¬‚ash-based smart cards is
going to make application platforms available even on low-end smart cards.
Barbu has applied this technique to Java Card 3.0 [1]. In the present paper, we
apply it to classical Java Card 2.2 cards. We ï¬rst make assumptions that are
consistent with todayâ€™s state-of-the-art on fault induction attacks [5], as follows:
â€“ It is possible to perturb (with a good success rate) a mutable persistent
memory read operation in order to replace the read value by a constant 00
value.
â€“ It is possible to perturb (with a good success rate) a speciï¬c conditional
jump instruction in order to â€ï¬xâ€ its result and have it always jump in the
same direction.
These assumptions are not unrealistic today, and they are likely to become even
more realistic in the future. We will ï¬rst present a few of the attack scenarios
that become possible with such combined attacks.

138
E. Vetillard and A. Ferrari
4.1
Introducing a NOP
The ï¬rst attack is based on a really simple fact: in Java Card, the opcode nop
is represented by the value 00. Since application bytecode is read from mutable
persistent memory, our ï¬rst hypothesis implies that any opcode in the bytecode
stream can be replaced by a nop opcode, with two possible consequences:
â€“ If the replaced opcode has no parameters, the instruction it represents is
skipped.
â€“ If the replaced opcode has parameters, then its ï¬rst parameter byte will be
interpreted as an opcode, and the following bytes as its parameters.
We therefore see that this simple attack allow us not only to skip instructions,
but also to introduce instructions at will in the bytecode stream.
The main interest of this attack is that it targets the main bytecode exe-
cution loop. This piece of code is critical for the performance of the platform,
and it is therefore very diï¬ƒcult for developers to defend them with complex
countermeasures.
4.2
Dropping the Firewall
The second attack focuses on the ï¬rewall checks, in order to allow an illegal
access on an object through the ï¬rewall. In most object-related instructions, the
ï¬rewall checks consist of a series of checks; the access is allowed if one of them
succeeds.
For instance, the invocation of a virtual method is authorized if the object is
owned by an applet in the currently active context, or if the object is designated
as a Java Card RE Entry Point Object, or if the Java Card RE is the currently
active context.
The attack here consists in using our second hypothesis to attack one of these
checks, and to make it positive. The method invocation then becomes possible.
This main interest of this attack is that some platforms rely on encryption to
protect the applicationsâ€™ assets, rather than on the ï¬rewall. In such applications,
the ï¬rewall tests often include little redundancy, and can therefore be attacked.
4.3
Combining the Attacks
The attacks described above allow us to introduce unveriï¬ed code in an appli-
cation, (and in particular to forge a reference), and to â€removeâ€ the ï¬rewall
tests on a reference access. By combining both attacks, and by also including
traditional attacks, we are able to build interesting attack paths, such as the
following one:
â€“ Using a memory dump, determine the reference of a key object from a sensi-
tive application, or a way to determine the value of that reference. This ï¬rst
part of the attack is performed in a â€traditionalâ€ way on development cards,
or partly on attacked cards, once a dump method has been discovered.

Combined Attacks and Countermeasures
139
â€“ In an apparently legal application, forge a copy of that reference. We will
show in the practical results how this can be achieved by injecting a nop in
an apparently normal program.
â€“ Invoke the getKey() method, which returns the key value, on that reference,
removing the ï¬rewall test. This can also be achieved by a simple attack, this
time exploiting our attack on the ï¬rewall.
â€“ Output the key value.
This is a very simple scenario, one that we have actually implemented. However,
this is just one way of combining these attacks, leading to diï¬€erent attack paths.
Our objective is here to show that, provided that perturbation attacks reach a
certain quality threshold, an entire range of new attacks becomes available on
open cards.
5
Experiments
Experiments have been conducted on a common Java Card platform, with a
medium level of security. The targeted implementation is not considered as de-
fensive, and its implementation of the Java Card ï¬rewall is rather simple, ap-
parently without any signiï¬cant redundancy. Quite likely, the typical ï¬rewall
test consists in retrieving the object context from the objectâ€™s header, and then
comparing it with the current execution context, as required by the speciï¬ca-
tion. This implementation is typical of cards developed by smaller vendors. Such
cards can achieve security certiï¬cations, at least private ones, usually by relying
on cryptography to protect the integrity and conï¬dentiality of sensitive data.
Our experiments on the target platform have shown that it is very easy to
identify the ï¬rewall test very precisely (it is easily identiï¬ed as â€theâ€ test that
fails when there is a ï¬rewall error). Breaking this test is therefore a rather simple
task for a fault induction specialist, and the hardware laboratory has succeeded
several times with good success rates (about 10%, without being detected).
With that result, on our target card, we have the ability to illegally access any
object from any application, once we have obtained a reference to that object.
The next step therefore consists in building a forged reference to an object. The
way in which we can do that is to use another attack to transform an integral
value into a reference. We will do that by writing a legal program, which can
be transformed into an illegal one through a simple fault induction attack. The
attack is based on the fact that the opcode for the nop bytecode is 00, and that
we are able to replace a value read from EEPROM by a 00. Letâ€™s for instance
consider the following code:
byte KEY_ARRAY_SIZE = 0x77;
Key getKey(short index){
if (index<KEY_ARRAY_SIZE) {return keys[index];} else {return null;}}

140
E. Vetillard and A. Ferrari
This is a rather inconspicuous sequence of code, which simply performs a range
check before to read a value from a local array of references. The bytecode
sequence generated for this method is as follows:
00 1D
sload_1
01 10 77
bspush 0x77
03 6D 08
if_scmpge +08
05 AD 01
getfield_a_this objects
07 1D
sload_1
08 24
aaload
09 77
areturn
0A 01
aconst_null
0B 77
areturn
The attack simply consists in replacing the ï¬rst bspush opcode by a nop opcode.
The executed sequence then becomes:
00 1D
sload_1
01 00
nop
02 77
areturn
We have achieved our goal of transforming an integral value into a reference.
In this particular case, we even have transformed a key index (possibly fetched
directly from an incoming command) into a key object.
Once we have forged a reference, we simply need to invoke a method on it
(for instance, the getKey() method), and to â€removeâ€ the ï¬rewall test.
We have implemented a similar scenario in practice, and we have actually
been able to disclose the value of a key owned by another application with a
success rate of about 5%. In addition, such an attack can be performed step
by step, using diï¬€erent APDU commands. This greatly reduces the constraints
on the hardware attack, because every fault induction attack can be performed
independently of each other.
6
Protecting against the Attack
6.1
Preventing a Full Attack Path
We have shown and implemented an example of a combined attack that works
on a basic implementation of Java Card. However, we are still missing some steps
in order to industrialize the attack:
â€“ The attack is able to disclose the value of a key whose reference is already
known to the attacker. This implies that the attacker must also have the
ability to analyze the target application, for instance by dumping the cardâ€™s
memory or analyzing the execution of code [10].
â€“ The attack includes conspicuous code that would not go through a code
review, even a basic one. In our example, the value of a key is sent unen-
crypted to the outside. This would raise questions from any code reviewer.

Combined Attacks and Countermeasures
141
This dormant code is in fact equivalent to a Trojan horse, waiting to be
activated.
Combined attacks allow a wide range of diï¬€erent attacks, but all the attacks
that we have looked at have at least one of the following characteristics:
â€“ They include a test whose result needs to be changed for the attack to
succeed. This implies that the code that follows this test cannot be reached
(dead code), or at least that it cannot be reached in a given case (dead path).
â€“ They include a piece of code that conceals another one, which usually per-
forms an unusual operation, or at least gives access to an unusual operation.
All these characteristics provide us with two leads to defend eï¬ƒciently against
such combined attacks: defensive virtual machines and application code analysis.
We will review these two possibilities.
6.2
Defensive Virtual Machines
The idea behind a defensive virtual machine is that it will be under attack. It
therefore includes countermeasures that make it hard to build a successful attack
path. They do not defend against a speciï¬c and well-identiï¬ed attack, but they
rather reinforce the general robustness of the virtual machine.
â€“ Firewall design. The Java Card speciï¬cation only mandates a few simple
checks to implement the ï¬rewall. It is also possible to implement the ï¬rewall
using additional security mechanisms, such as memory encryption or MMUâ€™s.
â€“ Redundant checks in the virtual machine. Bytecode veriï¬cation makes most
runtime checks useless under standard hypotheses. In a defensive virtual
machine, the assumptions are weakened, and some checks are reintroduced.
For instance, the virtual machine may verify that all jump targets are legal.
The diï¬ƒculty in designing a defensive virtual machine is not in ï¬nding new
countermeasures to include in the virtual machine, but rather to ï¬nd a good
compromise between security and performance. Each countermeasure has a cost
(in memory, execution time, or both), which reduces the performance level of
the card.
For instance, checking that the destination on a jump is in an appropriate
range is very costly if performed on all jumps. However, this can be optimized
by only checking the â€longâ€ jumps, which are used to jump over 128 bytes in
one direction or another. Such jumps are far less frequent than short jumps, and
they are far more likely to be involved in an attack, because they can reach a
large part of memory.
Beyond local optimizations, the most diï¬ƒcult part in designing a defensive
virtual machine is to build an impenetrable web of countermeasures, and to
ensure that attackers are very likely to encounter one of the measures when de-
signing new attacks. Some of the cards that we have evaluated greatly succeeded
at this, making logical and combined attacks very hard to implement on their
cards.

142
E. Vetillard and A. Ferrari
On the other hand, we also have evaluated many cards that are vulnerable
to logical attacks, and whose sole protection against them is in the robustness
of their GlobalPlatform implementation and the encryption of sensitive data.
That means that such cards could be vulnerable to combined attacks, since the
applications used in these attacks are valid and can be veriï¬ed and legally loaded
on a card.
6.3
Static Analysis
Application code analysis comes in complement to on-card runtime veriï¬cations
(defensive virtual machines) and others hardware countermeasures, by statically
ensuring a code being present on-card is not malicious. Static veriï¬cation of
programs is a very active research ï¬eld, in particular around Java.
The Java bytecode veriï¬er is the most commonly used static analysis tool.
However, it is a very simple analyzer, and it remains possible to prove many
more properties on Java bytecode. If it has been demonstrated that static veriï¬-
cation could be performed on-card during code loading [8], bytecode veriï¬cation
remains traditionally performed oï¬€-card and has to be included in organizational
countermeasures (bytecode veriï¬cation and signature).
We have been working since 2002 on a tool that veriï¬es the portability and
security of Java Card applets. This tool has been used in many evaluations for
the validation of numerous security rules e.g. tracing the use of critical APIs.
Over the years, it has been extended mostly in collaborative research projects
with information ï¬‚ow analysis [2] and security contract veriï¬cation [4].
Static analysis tools for Java Card work by running analysed applications on
an abstract virtual machine, and then checking that some rules can be veriï¬ed.
The abstraction can be quite precise, with an execution model that performs a
global analysis of the code (in contrast to a method-local analysis), and a precise
representation of the heap. This is possible because in Java Card, most of the
objects are statically allocated, and the depth of invocations is limited by the
small size of the Java stack.
We here suggest using a static analysis tool in order to identify applications
that may contain Trojan horses to be used in combination with a physical attack
as for instance
â€“ Identify dead code and dead paths.
â€“ Identify code that output secrets, in particular key values.
â€“ Identify â€unusualâ€ constants.
â€“ Identify unused variables.
7
Analysis
7.1
Can the Attacks Be Reproduced?
Yes, they can. On the logical part, implementing these attacks only requires a
good level of expertise on smart card weaknesses and an in-depth knowledge

Combined Attacks and Countermeasures
143
about the implementation of Java runtime environments. On the physical part,
implementing these attacks simply requires an ability to perform very precise
fault induction attacks.
In both cases, few laboratories have the required skills in early 2009, and we
donâ€™t know any laboratory that has both skills. Nevertheless, these skills are
likely to become more common in the future.
7.2
Is Java Card Less Secure Than Other Systems?
In terms of resistance to attacks, there is no reason to believe that the Java Card
platform is more sensitive than other platforms to our attacks. With the kind
of precision that physical attacks can now achieve, all other existing middleware
become vulnerable, as soon as they include the ability to load code.
However, a few factors make Java Card a common target for such attacks:
â€“ Greater availability. Getting a development kit for a Java Card platform is
quite easy, and the Java Card speciï¬cation is also available to everybody.
â€“ The â€Windows eï¬€ectâ€. Just like Microsoft Windows, Java Card is todayâ€™s
dominant platform, so there are more incentives for attackers to develop an
attack against Java Card.
This status may evolve with the gradual deployment of Java Card 3 platforms.
The new platform includes new countermeasures, like mandatory bytecode ver-
iï¬cation, but it is also exposed to many new kinds of attacks. In addition, as it
is new, it will be easier to ï¬nd exploitable bugs, at least for a while.
About other platforms, the minimum requirement for being able to perform
the attacks described here is to be able to develop an attack application and run
it on a development platform, which must be similar enough to the platforms
being actually deployed. In addition to traditional â€openâ€ Java Card-based smart
cards, this covers the following cases:
â€“ Any open card based on downloadable applications, such as BasicCard or
Multos.
â€“ Any closed card based on one of these open systems, provided that the
application code runs in the same way on these cards.
â€“ Any card OS that can be customized using an open API, as we can expect
to ï¬nd on ï¬‚ash-based smart cards.
Although they are nice-to-have features, the following are not absolute require-
ments for these new attacks to work:
â€“ The ability to load applications on the attacked cards. Once an attack pat-
tern is known, it is easiest to load an application that contains the pattern
on an attacked card. However, it is also possible to analyze a closed cardâ€™s
code in order to ï¬nd and exploit an instance of the attack pattern.
â€“ A bytecode interpreter. The attack must be applied on a generic abstraction
layer, but this layer does not need to be a bytecode interpreter. For instance,
our ï¬rewall attack could work just as well on any memory management API
that provides isolation between applications.

144
E. Vetillard and A. Ferrari
Of course, openness leads to an increase of the risk. However, developers of high-
end open cards are likely to be aware of these risks and to include appropriate
countermeasures, whereas developers of low-end closed cards are more likely to
include very basic security measures, leaving more vulnerabilities available for
exploitation.
7.3
Can Platforms Be Protected?
Of course, it is possible to include adequate protection in Java Card platforms.
The main consequence of the new combinations of attacks described in the
present paper is that some implementations become too vulnerable, and need
to be replaced by alternative implementations. For instance, implementing ï¬re-
wall checks by a simple comparison between the current context and an objectâ€™s
owning context becomes almost impossible to protect.
The main challenge for platform developers will be to design new counter-
measures that are eï¬ƒcient against combined logical and physical attacks, while
providing an adequate performance level. This will in some cases require a sig-
niï¬cant redesign of the platform, with the introduction of new countermeasures.
However, this kind of situation occurs with all new attacks. For instance, in
order to protect against DPA attacks [6], a well-known countermeasure consists
in introducing counters that limit the number of uses of any given key. In that
particular case, the countermeasure that protects a cryptographic implementa-
tion does not strengthen the cryptographic algorithm itself; it just makes the
new attack unpractical.
7.4
What Security Measures for Certiï¬ed Platforms?
In order to certify a platform in the context of this new attack, we need to look
for suitable security measures on the platform, and to ensure that the proper
assurance measures are taken in order to guarantee that these measures are
theoretically suitable and that they have been correctly applied on the platform.
Reverse engineering is a key part of most attack paths, as the attackers need
some information about the application and about the platform. Limiting the
amount of information leaked from the platform then becomes an objective by
itself. Protecting the conï¬dentiality of the application bytecode remains diï¬ƒcult,
since we have seen that power analysis allows signiï¬cant disclosure. On the
other hand, power analysis is very time-consuming, and it remains interesting to
include protections against the more eï¬ƒcient alternative for reverse engineering:
memory dumps. There are at least two interesting leads to get that protection:
â€“ Protecting against classical physical memory dumps. The code targeted by
memory dumps usually includes a transfer of memory (for instance, copying
an array). These operations are not numerous. They should be carefully pro-
tected, and evaluations should verify the eï¬ƒciency of the countermeasures.
â€“ Protecting against logical memory dumps. Standard logical attacks are often
used in the reverse engineering part, because they are very eï¬ƒcient (once an
attack works, it is entirely deterministic, and it can be exploited in limited

Combined Attacks and Countermeasures
145
time). The idea would here be to ensure that development cards, which are
typically accessible to hackers, only accept veriï¬ed bytecode. This can be
achieved by embedding a bytecode veriï¬er, or by embedding a mandatory
DAP veriï¬cation, and by having all applications veriï¬ed and signed, either
manually or automatically.
Another potential direction is to make the virtual machine more defensive, in
particular regarding ï¬rewall checks. The objective is here to limit the potential
harm made by an application to its own data. It is diï¬ƒcult to design systematic
protections of the bytecode, mostly because of the high cost. For instance, adding
redundancy to the main bytecode interpretation loop (for instance, to check the
integrity of the opcode) will incur a signiï¬cant performance cost. There are
nevertheless a few leads:
â€“ Protecting the ï¬rewall tests. The ï¬rewall tests are executed often, but only on
object accesses. It is therefore possible to introduce some level of redundancy
without paying a very high cost. The laboratories should focus on these tests,
and perform fault induction tests on them.
â€“ Protecting the virtual machine locally. Even if global countermeasures are
very costly, it is possible to introduce some countermeasures that make the
attacks more diï¬ƒcult, for instance performing some checks when running a
nop opcode, which is very unusual in normal applications. The laboratories
should look for such protections during evaluations.
The examples above are only instances of the checks to be performed. Yet, they
show that in most cases, the countermeasures are indirect, and require a good
understanding of combined attacks to be designed, implemented, and tested.
7.5
What Security Measures for Certiï¬ed Applications?
In order to certify an application in the context of this new attack, the objective
for a laboratory is to ensure that the application does not include any Trojan
horse, and that it does not contain any code that has been designed to be
attacked.
It is possible to introduce both intentional weaknesses and attack code in
applications, even if it undergoes a security certiï¬cation. Since such attacks
require an insider job from the developerâ€™s staï¬€, all countermeasures need to be
implemented at the laboratory level. The laboratory therefore needs to consider
bytecode-level attacks in their analysis of the application code. There are at least
two things to watch:
â€“ Analyze thoroughly unusual or useless code. If a piece of code does not seem
to perform any interesting computation, it may be part of a Trojan Horse.
Evaluators should be careful about this when performing a code review.
â€“ Consider bytecode-level attacks. In addition to the obvious application weak-
nesses, which are visible at the application level, evaluators should be careful
about bytecode-level attacks, which may either be voluntary or not.

146
E. Vetillard and A. Ferrari
The last point is very important. Although we have focused here on voluntary
injection of vulnerable code, these attacks can be applied to any code, and they
make it quite easy to modify the outcome of a program. Such fault induction
attacks are already possible, but the attacks on bytecode may be easier to im-
plement in some cases, for instance when attacking memory read operations has
a good success rate.
7.6
Conclusion and Future Work
Logical attacks on smart cards have been available for many years. However,
their practical application has been limited by the fact that, in order to be ap-
plied, they required an attack on the GlobalPlatform card content management
commands, which are often diï¬ƒcult to implement.
With combined attacks, this work demonstrates that it becomes possible to
implement a full attack path by combining logical attacks with a standard fault
induction attack. Such combined attacks can therefore be implemented on plat-
forms that were until now considered suï¬ƒciently safe.
We have shown a complete attack path based on combined attacks, which
we have implemented on a classical platform. The results presented here remain
incomplete, in the sense that we have mostly worked on code in which we have
planted attack code without making signiï¬cant eï¬€orts to conceal it. Therefore it
would be of interest to work on attacks that can be concealed in a standard ap-
plication, as well as to work on the exploitation of combined attacks on standard
applications.
The platform on which we have performed the attacks has received many
security certiï¬cations, while being known as sensitive to logical attacks. The
availability of combined attacks raises the question of the requirements for cer-
tiï¬cations of open card platforms in the future. Evaluation laboratories should
determine how these attacks should be considered in standard security evalua-
tion programs.
Finally, another challenge raised by this paper consists in working on counter-
measures against these attacks, and in particular on the detection of vulnerable
code, totally or partially automated. Evaluation laboratories will however be
confronted to a double problem:
â€“ Certifying sensitive applications. In that case, laboratories have access to the
applicationâ€™s code and speciï¬cation, and signiï¬cant resources are allocated
to the evaluation. In such case, a partially automated analysis tool, identi-
fying potential vulnerabilities is most useful, even if it possibly leads to false
alarms.
â€“ Scanning non-sensitive applications. In that case, laboratories only have ac-
cess to the applicationâ€™s binary code, and the resources allocated to the
evaluation are limited (a few hours). In such case, an automated tool that
only detects obviously malicious code is needed.
Improvements of static analysis tools and application evaluation strategies have
to be made to take combined attacks in consideration.

Combined Attacks and Countermeasures
147
References
1. Barbu, G.: Fault attacks on a java card 3.0 virtual machine
2. Barthe, G., Beringer, L., CrÂ´egut, P., GrÂ´egoire, B., Hofmann, M., MÂ¨uller, P., Poll,
E., Puebla, G., Stark, I., VÂ´etillard, E.: Mobius: Mobility, ubiquity, security. In:
Montanari, U., Sannella, D., Bruni, R. (eds.) TGC 2006. LNCS, vol. 4661, pp.
10â€“29. Springer, Heidelberg (2007)
3. Chaumette, S., Hatchondo, I., Sauveron, D.: Jcat: An environment for attack and
test on java card&trade. In: Proceedings of CCCT 2003 and 9th ISAS 2003, vol. 1,
pp. 270â€“275 (2003)
4. Dragoni, N., Massacci, F., Schaefer, C., Walter, T., VÂ´etillard, E.: A security-by-
contracts architecture for pervasive services. In: Proceedings of 3rd Intâ€™l Workshop
on Security, Privacy and Trust in Ubiquitous Computing (SecPerU 2007). IEEE
Press, Los Alamitos (2007)
5. ITSEC Joint Interpretation Library (JIL). Version 2.7. Application of Attack Po-
tential to Smartcards (February 2009)
6. Kocher, P., Jaï¬€e, J., Jun, B.: Diï¬€erential power analysis. In: Wiener, M. (ed.)
CRYPTO 1999. LNCS, vol. 1666, pp. 388â€“397. Springer, Heidelberg (1999)
7. Lanet, J.-L., Iguchi-Cartigny, J.: Developing a trojan applet in a smart card. Jour-
nal in Computer Virology 6(1) (2009)
8. Leroy, X.: Bytecode veriï¬cation for java smart card. Software Practice & Experi-
ence 32, 319â€“340 (2002)
9. Mostowski, W., Poll, E.: Malicious code on java card smartcards: Attacks and
countermeasures. In: Grimaud, G., Standaert, F.-X. (eds.) CARDIS 2008. LNCS,
vol. 5189, pp. 1â€“16. Springer, Heidelberg (2008)
10. Vermoen, D., Witteman, M.F., Gaydadjiev, G.: Reverse engineering java card
applets using power analysis. In: Sauveron, D., Markantonakis, K., Bilas, A.,
Quisquater, J.-J. (eds.) WISTP 2007. LNCS, vol. 4462, pp. 138â€“149. Springer,
Heidelberg (2007)

Attacks on Java Card 3.0
Combining Fault and Logical Attacks
Guillaume Barbu1,2, Hugues Thiebeauld1, and Vincent Guerin1
1 Oberthur Technologies - France
{g.barbu,h.thiebeauld,v.guerin}@oberthur.com
http://www.oberthur.com/
2 Telecom ParisTech, Dep. ComElec, Groupe SEN - France
guillaume.barbu@telecom-paristech.fr
http://www.telecom-paristech.fr/
Abstract. Java Cards have been threatened so far by attacks using
ill-formed applications which assume that the application bytecode is
not veriï¬ed. This assumption remained realistic as long as the bytecode
veriï¬er was commonly executed oï¬€-card and could thus be bypassed.
Nevertheless it can no longer be applied to the Java Card 3 Connected
Edition context where the bytecode veriï¬cation is necessarily performed
on-card. Therefore Java Card 3 Connected Edition seems to be immune
against this kind of attacks. In this paper, we demonstrate that running
ill-formed application does not necessarily mean loading and installing
ill-formed application. For that purpose, we introduce a brand new kind
of attack which combines fault injection and logical tampering. By these
means, we describe two case studies taking place in the new Java Card
3 context. The ï¬rst one shows how ill-formed applications can still be
introduced and executed despite the on-card bytecode veriï¬er. The sec-
ond example leads to the modiï¬cation of any method already installed
on the card into any malicious bytecode. Finally we successfully mount
these attacks on a recent device, emphasizing the necessity of taking into
account these new threats when implementing Java Card 3 features.
Keywords: Java Card 3, Combined Attack, Fault Injection, Logical
Attack.
1
Introduction
Nowadays Java Card technology is widely spread over the smartcard market for
a large spectrum of applications, such as banking, identity or GSM. According
to [19], more than 3.5 billion of Java Cards have been deployed worldwide so far,
proving the needs in inter-operability, post-issuance loading, multi-application
capability and security.
Fundamentally, smartcards are devoted to play a key role in secure transac-
tions operating potentially in hostile environments. They are designed to resist
to numerous attacks using both physical and logical techniques. Today fault
attacks represent certainly the most powerful threat for smartcards. They con-
sist in inducing a fault during a code execution as explained in [5] and then in
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 148â€“163, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
149
exploiting either a faulty computation result or an erroneous behavior to ob-
tain information on secrets stored in the card. Although fault attacks have been
mainly used in the literature from a cryptanalytic angle [2,6,3], their strength
is to potentially stress every code layers embedded in a device. Practical details
and comprehensive consequences could be found in [8].
Thanks to the inherent structure of the Java language, Java Cards have shown
an improved robustness compared to native applications regarding fault attacks.
However a device oï¬€ering post-issuance loading and multi-application capability
must also face to new threats associated to these features. Thus, the so-called
malicious applets which are speciï¬cally developed by an attacker aiming at tam-
pering with a Java Card device, should then be taken into consideration. Until
now, all attacks based on malicious applet only used logical techniques to defeat
the Java Cards security [24,17,13].
In this paper, we will introduce for the ï¬rst time how a fault injection and a
logical attack using a malicious applet can be combined to defeat a Java Card
3. The novelty of this paper is twofold. Firstly, such a combination has never
been exploited until now. It turns out to be a very eï¬ƒcient way to tamper with
a device like a Java Card. Secondly, we will show that even if the Java Card 3
standard appears to be very well designed with a real concern for security, it
is still possible to attack devices embedding straightforward Java Card 3 imple-
mentations. We will also demonstrate that our attack is not purely theoretical,
as it was successfully put into practice on a recent chip.
This paper is organized as follows : In Section 2, a brief reminder of Java
Card 3 is exposed, with a special interest on the new features introduced by
this standard. In Section 3, after a brief description of already published logical
attacks on Java Card, we analyse if they are still relevant in the Java Card
3 context. In Section 4, we introduce a new kind of attacks combining fault
injection and logical tampering. Two case studies are then exposed in Section 5
revealing how the security of a Java Card 3 device can be defeated. Finally, we
discuss in Section 6 how to protect a platform against that kind of attack and
how to handle the security to anticipate any weakness.
2
Brief Description of Java Card 3
This section aims at describing the context of the Java Card 3, with a special
interest on the newly introduced features.
To follow the still growing requirements in embedded security, the Java Card
3.0 speciï¬cation has been released [1]. For a best suitability, two editions are
available: the Classic and the Connected.
2.1
Classic versus Connected Java Card 3.0 Editions
The Classic Edition stands for a moderate evolution of the previous Java Card
2.2.2 standard [22,20] and ensures a regular compatibility with classical applets
and Java Card platforms deployed so far. Therefore all previous vulnerability

150
G. Barbu, H. Thiebeauld, and V. Guerin
analyses [24,17,13] applied on previous Java Card products remain valid on de-
vices implementing Classic Edition Java Card 3.0.
The major evolution of Java Card 3 concerns the Connected Edition which
represents a signiï¬cant breakthrough compared to the previous Java Card stan-
dards. This latest release oï¬€ers a myriad of new features and then opens up
new opportunities for possible applications. This standard addresses the high-
end range of devices and mainly targets the network ï¬eld, where the smartcard
plays a vital part in security.
The most interesting features introduced by Java Card 3.0 Connected Edition
are:
â€“ a strong evolution of the language, now closer to the standard java,
â€“ a multi-threading capability,
â€“ a connectivity adapted to the most common network standards (TCP/IP,
HTTP(S)),
â€“ an on-card class loader and linker.
For the sake of interest only the Connected version of Java Card 3.0 will be taken
into consideration in the remainder of this paper.
2.2
Java Card 3.0: A Set of New Security Features
The complete speciï¬cations of the Java Card 3 Connected Edition have been
revisited and enriched by new requirements to ensure a very high level of security.
The main security features concern:
â€“ a context isolation mechanism, more commonly called the application ï¬re-
wall, ensuring that objects created in an application are not accessed by any
other application,
â€“ a mandatory On-Card Bytecode Veriï¬er (OCBV) to prevent any ill-formed
applet to be loaded and installed,
â€“ a code isolation mechanism,
â€“ optional security annotations to speciï¬cally deï¬ne in the code particular
sequences requiring a stronger security,
â€“ secure communications such as Transport Layer Security,
â€“ a security policy enforced by role-based and permission-based rules.
Why would the OCBV inï¬‚uence the Java Card security?
2.3
The ByteCode Veriï¬cation
The bytecode veriï¬cation [21] consists in checking the coherence of the CAP ï¬le
before installing the applet on the card. Such operation turns out to be costly
in term of code size, which can be critical for resources-restricted devices like
smartcards. For this reason, up to the Java Card 3 standard, the speciï¬cations
[21] allowed the possibility to execute this bytecode veriï¬cation outside the card,
which is the case for a majority of the Java Cards deployed so far.
To force this veriï¬cation, Global Platform (GP) has speciï¬ed the notion of
Data Authentication Pattern (DAP). According to the Java Card conï¬guration

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
151
set by the issuer, an optional DAP veriï¬cation can be requested during each
new applet installation, consisting in checking the signature validity. The issuer
or the application provider has then to sign the CAP ï¬le after processing the
bytecode veriï¬cation.
Considering the Java Card 3 Connected Edition, the loading and installation
of ill-formed applets is now compromised since the bytecode veriï¬er is now on
card. Therefore it could be interesting to analyse the consequences of this new
feature on the previously published attacks.
3
State of the Art of Java Card Software Attacks
In literature, previous works [24,17,13] attempting to attack Java Card devices
assumed systematically that the attacker has the right to load an applet. Firstly,
the context describing how one can load and install his own applet is recalled.
And then, previous attacks are brieï¬‚y described in order to analyse how they
can be applied on Java Card 3 Connected Edition.
3.1
Loading an Applet: In the Jungle of Permission
The right to load an applet is not obvious in the reality of the ï¬eld. To have this
capability, an attacker has several possibilities:
1. The attacker owns the card manager key set, which means he plays the role
of the issuer. No additional conditions are requested, the attacker is then able
to load any package or install an applet without any further restrictions. It
is the case for instance of white cards that anyone can buy on several web
stores. Such cards are commonly provided with the card manager key set.
2. The attacker is in condition to load a package or install an applet by Dele-
gated Management (only available from GP 2.1.1 [9]). That means the issuer
has created on the card a kind of loading environment, called a Security Do-
main, providing loading, installation and extra secure communication fea-
tures with certain privileges. The use of Security Domains requires owner-
ship of some secret keys to achieve both authentication and communication
through a secure messaging. Furthermore, loading and installing the applet
by Delegated Management requires the INSTALL commands to be signed
by the cardâ€™s issuer.
3. The attacker is in condition to load a package or install an applet by Autho-
rized Management (only available from GP 2.2 [10]). To do so, it is necessary
that a Security Domain has been created beforehand by the issuer. The ac-
cess to this Security Domain requires being authenticated and then owning
the corresponding key set.
In conclusion, having the opportunity to load an applet on a Java Card is not
obvious. This is simple indeed for everyone using white cards. However in that
case, few assets are at stake, rendering the reach of any attack limited. Otherwise
we can consider very unlikely the possibility for a basic attacker to load his own
applet in normal conditions of use.

152
G. Barbu, H. Thiebeauld, and V. Guerin
Nevertheless this assumption is necessary to consider any software attack.
Therefore, in the following of this paper, we will assume:
H0: The attacker is able to load and install applications on card.
3.2
Ill-Formed Applets: The Threat Number One
Until now, attacks threatening Java Cards are mainly divided into two categories:
â€“ They exploit a weakness in the Virtual Machine (VM) implementation [24],
or even a bug in the atomic operations [17]. These attacks are still valid
in Java Card 3 Connected Edition. However, the number of such attacks
is limited and can be easily addressed by developers without aï¬€ecting the
product performances.
â€“ Another kind of attack concerned the execution of ill-formed applets. Such
techniques are now considered as a classical attack (a brief description could
be found in [7]). Their principle is to modify the CAP ï¬le in order to defeat
security controls ensured typically by the ï¬rewall. They can be extremely
powerful, as it was shown in [24], [17] and [13].
Why would the security of a Java Card be threatened by a CAP ï¬le
modiï¬cation?
Firstly, [24] and [17] have exposed how the type confusion could eventually lead
to either Non Volatile Memory dump possibilities or to ï¬rewall circumventing.
The success of their attacks was nevertheless conditioned by the absence of
dynamic controls embedded in the platform, explaining why the attacks failed
on some cards.
Secondly, [13] has described how changing a bytecode could provide the knowl-
edge of manipulated references. This information was then exploited in a second
step of the attack, consisting in changing the Method Component contained in
the CAP ï¬le, improving an attack proposed by [12]. Finally [13] showed how a
malicious appletâ€™s method could be replaced with a data array playing so the
rule of a trojan horse, and giving the access in reading and writing to a large
part of the memory space. Once again, the viability of this attack is mainly
dependent on the implementation choices of the diï¬€erent cards tested.
Moreover, every ill-formed attack requires that the CAP ï¬le has not passed
the bytecode veriï¬er. As explained in Section 2.3, this assumption is not longer
applicable on Java Card 3 Connected Edition. The direct consequence seems to
be an apparent protection face to ill-formed applet attacks, and to most of others
attacks published in literature so far.
However, this bytecode veriï¬cation remains static, as it is executed once when
the applet is being installed. The attack described in the next section will show
why this â€staticâ€ protection is not suï¬ƒcient. We will demonstrate that logical
attacks are still possible by combining them with a single fault injection during
the application execution.

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
153
4
Combined Attack on Java Card 3.0, Theory and
Practice
As explained in Section 3, it is now admitted that loading ill-formed application
in order to get a type ï¬‚aw is not an option anymore. In this section, we will
ï¬rstly demonstrate that a combined attack can be an alternative to an ill-formed
application loading. Then, we will show how this can be particulary dangerous
for a Java Card 3.0 platform.
4.1
Attack Step 1: Combining Fault and Logical Attacks to Forge
References
In this section we will ï¬rstly recall some basics about type conversion in Java.
Then, we will demonstrate how a single physical disturbance of the code execu-
tion will enable us to induce a type confusion. This idea has been suggested in
[17] and presented in [4] but neither any theoretical nor any practical examples
have been published. Finally, we will show that the type confusion will permit
to forge references and even possibly read and write their content, and this until
the deletion of the application.
Recalls on Type Conversion
It is common knowledge that Java objectsâ€™ types (classes) organization forms a
hierarchy. Each class is a subclass of another class, except for the Object class
on top of the hierarchy. This hierarchy enforces the principle of conversion which
allows an object of type T1 to be used as if it were an object of type T2. A type
conversion can be explicitly requested in the source code by the use of the cast
operator: ().
For type safety reason, such conversions must be checked. Conversions proven
incorrect at compile time result in a error. But, in most case, the check will
happen at runtime via the checkcast instruction produced by the compiler and
executed by the VM. Such an example is given below:
T1 t1;
aload X
T2 t2 = (T2) t1;
â‡”
checkcast Y
astore Z
where X, Y and Z point respectively to t1, T2â€™s class and t2.
The checkcast instruction takes as parameter the class into which the object
(on top of the stack) is being converted. Its execution will merely consist in
checking that the object is convertible into the given class regarding the class
hierarchy. If the conversion is correct, the object reference is still on top of the
stack at the end of the checkcast execution. Otherwise, a ClassCastException
is thrown and the stack is cleared.
How a Faulty Conversion Leads to Reference Forgery
In [11], Govindavajhala et al. proposed a way to achieve type confusion and
reference forgery on a virtual machine thanks to memory errors. Our approach,
although slightly diï¬€erent, is inspired by their attack.

154
G. Barbu, H. Thiebeauld, and V. Guerin
We consider the following classes1:
- public class A {byte b00,...,bFF;}
- public class B {short addr;}
- public class C {A a;}
Let us focus on the internal representation of instances of B and C classes (cf.
Fig. 1). It is important to notice that both objects have the very same internal
structure.
Fig. 1. Internal representation of instance of B and C
Imagine we can access an object either as an instance of B or C. Treating this
object as a B instance, it is possible to set the value of its short ï¬eld (b.addr =
0x1234;). And due to the internal structures of B and C classes, we have set the
reference of the a ï¬eld of this very object seen as an instance of C, as illustrated
in Fig. 2.
Fig. 2. Access to the same object either as B or C instance
Now let an application module containing the following extended applet (as
well as classes A, B and C) be loaded, and this applet installed, on a recent
chip embedding a straightforward implementation of the Java Card 3 Connected
Edition speciï¬cations.
1. public class AttackExtApp extends Applet {
2.
B b; C c; boolean classFound;
3.
... // Constructor (objects initialization), install method
4.
public void process(APDU apdu) {
5.
byte[] buffer = apdu.getBuffer();
6.
...
7.
switch (buffer[ISO7816.OFFSET_INS]) {
8.
case INS_ILLEGAL_CAST:
9.
try {
10.
c = (C) ( (Object) b );
11.
return; // Success, return SW 0x9000
12.
} catch (ClassCastException e) {/*Failure, return SW 0x6F00*/}
13.
... // more later defined instructions
14. } } }
1 The size of a reference is implementation speciï¬c. Therefore the type of ï¬eld addr
in B could be either short or int.

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
155
Obviously, this application is well-formed and the OCBV will allow its loading
and installation. However, the reader may have noticed the incorrect cast con-
version of a B instance into a C instance (step 10)2. Checking the correctness of
cast conversions is not in the scope of the OCBV, it is left to the checkcast
execution, at runtime, which will prove this one incorrect.
In [23], Vermoen et al. successfully applied the principle of Power Analysis
(PA) [14,15] to Java Cards in order to reverse engineer an applet. In our case,
we will only rely on PA to monitor our applicationâ€™s execution, which is much
less diï¬ƒcult.
Fig. 3. Execution of the appletâ€™s INS ILLEGAL CAST instruction
By analysing this power consumption curve, we are able to determine the
moment when the ClassCastException is thrown and thus when the checkcast
is executed.
We are now going to disturb the execution at the precise moment when the
checkcast is executed. For this purpose, we will use a laser equipment, targeting
the back side of the chip. The following ï¬gure (Fig. 4) depicts the faulty execution
of the same instruction.
We can see the instructionâ€™s execution is a little shorter than the regular
execution in Fig. 3 (because the VM doesnâ€™t have to treat an exception raising)
and the returned status word is the one expected when no error has occurred
(90 00). The attack succeeded.
We are then able to access an actual B instance either as a B or a C ob-
ject. Thus we can forge aâ€™s reference to any value (via b.addr), which in turn
may let us read and write as many bytes as declared byte ï¬elds of class A
(cf. Fig. 5.).
2 The Object conversion is only meant to fool certain compilers. This conversion will
probably not even be checked as each class is a subclass of Object.

156
G. Barbu, H. Thiebeauld, and V. Guerin
Fig. 4. Disturbed execution of the appletâ€™s INS ILLEGAL CAST instruction
Fig. 5. Forgery of object aâ€™s reference
This can be done without requiring any additional disturbance. The sole se-
curity check we encountered has been permanently3 neutralized by one single
fault injection.
Can we then dump the whole VM heap? Surely not. Even forging references,
access to an object that is not owned by our application and not shared must
be forbidden by the application ï¬rewall, as speciï¬ed in [21] and result in a
SecurityException being thrown. Also, the behavior of the platform when
trying to access bytes beyond the objectâ€™s size, thanks to forgery, is not speciï¬ed
and is then typically implementation dependent.
Nevertheless, we are able to assign any reference to c.a and possibly read and
write bytes c.a.bXY within the boundaries ï¬xed by the application ï¬rewall and
the VM implementation. This is roughly equivalent to the type-confusion-based
attacks presented in Section 3 on Java Card 2.x platforms. However, we do not
need ill-formed application loading nor speciï¬cation/implementation ï¬‚aws, the
fault injection being the type confusionâ€™s cause.
3 As long as our application is not deleted from the card.

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
157
4.2
Attack Step 2: Using our Reference Forgery Tool against a Java
Card 3 Platform
We are now going to expose how the reference forgery tool presented in Section 4
can jeopardize a Java Card 3 Connected Edition platform thanks to the new
dynamic features. We will start by setting our working hypothesis. Then we will
explain how we can access and modify Class objects on the platform.
An Assumption about the Class Object
One of the features introduced by the Java Card 3 Connected Edition platform
is on-card class loading. This can be used within an application thanks to the
java.lang.Class class that has been added to the standard API [18] which
speciï¬es that â€Instances of the class Class represent classes and interfaces in
a running Java applicationâ€. Class objects are constructed by the class loading
process, as deï¬ned in the standard Java VM speciï¬cation [16], from the binary
representation of these classes (the .class ï¬le). Working in a constrained envi-
ronment, we cannot expect the Class object to be the exact copy of the .class
ï¬le. Nevertheless we venture the following hypothesis:
H1: The bytecode of a class is stored in its Class instance.
This assumption appears quite natural as the Class object aims at representing a
running or ready-to-run class. Besides, if the .class ï¬le format can be optimized
in some ways, the bytecode array itself cannot be modiï¬ed without modifying
the behavior of the methods it represents.
Remark. Another interesting point concerning Class object is that the speciï¬-
cation requires root classes (applet, servlet, ï¬lter and listener classes), dynami-
cally loadable classes and shareable interface classes of an application module to
be loaded and linked during this application module loading. Thus we know that
these instances of the class Class are constructed as soon as an application is
loaded.
Searching and Accessing Class Objects
Section 4 shows how we can forge reference of an A instance and access memory
using its byte ï¬elds. This access will be executed on the platform respectively
by the getfield and putfield instructions wether we try to get (read) or set
(write) the byte value. A particularity of Java Card 3 Connected Edition is that
its speciï¬cation [21] allows access to implicitly transferable objects via getfield
and putfield instructions. An implicitly transferable object is an object that is
not bound to a speciï¬c java context.
Therefore, when an application requests access to such an object, the applica-
tion ï¬rewall will grant the access instead of checking that the java context of the
application matches the requested objectâ€™s java context. In other words, such ob-
jects are not protected by the application ï¬rewall. The list of speciï¬ed implicitly
transferable classes [21] contains an interesting element: java.lang.Class.
To access a Class object (i.e. to forge bâ€™s reference to that of a Class object
instance), we need to know the fully qualiï¬ed name of this class and have the
following instruction in the process method of our attack application:

158
G. Barbu, H. Thiebeauld, and V. Guerin
1. case INS_SEARCH_CLASS:
2.
while (!classFound) {
3.
try {
4.
// Increment the forged reference
5.
b.addr++;
6.
// Convert the bytes given in APDU command into String
7.
String name = bytesToString(buffer, ISO7816.OFFSET_CDATA);
8.
// Is it a Class instance ?
9.
if (((Object) (c.a)) instanceof Class) {
10.
// Is it the Class instance weâ€™re looking for ?
11.
// Let us check its name
12.
if (((Class)((Object) (c.a))).getName().equals(name))
13.
classFound = true;
14.
}
15.
} catch (SecurityException se) {}
16.
}
Remark. In this instruction, we already take advantage of the implicitly trans-
ferable property of Class objects by using type conversion, the instanceof in-
struction and the getName() method on the forged reference (steps 9 and 12).
Another way to achieve this could be to use the hashCode method of the Object
class provided it is typically implemented as per [18]:
â€œAs much as is reasonably practical, the hashCode method deï¬ned
by class Object does return distinct integers for distinct objects. (This
is typically implemented by converting the internal address of the object
into an integer, but this implementation technique is not required by the
JavaTMprogramming language.)â€
Under H1, and provided we can forge aâ€™s reference to a Class objectâ€™s reference,
then we can modify this classâ€™s bytecode array, regardless of the application it
belongs to.
We expose in the following section two case studies of such an attack.
5
Applications of Our Combined Attack
In this section, we will present two case studies based on our combined attack
proving we can execute ill-formed code despite the OCBV and modify any ap-
plication installed on the card.
5.1
Case Study 1: Ill-Formed Code Injection
The OCBV prevents ill-formed applications from being loaded. This case study
will show that our reference forgery tool enables an attacker to execute any
sequence of bytecode instructions.
Imagine the attackerâ€™s application module contains an additional class with
dummy methods ï¬lled with instructions ment to produce an easy to detect (and
to modify) bytecode within the corresponding Class instance.

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
159
Fig. 6. Identiï¬cation of dummyMethod and ill-formed code injection
To access his dummy Class object, he only has to use the INS SEARCH CLASS
instruction with the proper class name (he obviously knows) to forge aâ€™s refer-
ence. He can then easily read the content of the Class object and detect the
bytes corresponding to his dummy method. He can ï¬nally write the bytecode he
wants, in disregard for any rule (Fig. 6).
This proves that under hypotheses H0 and H1, one can use the reference
forgery tool to eventually have ill-formed code loaded on card despite the OCBV
and without any additional fault injections.
Remark. Considering the state of the art, an application containing erroneous
bytecode will not be more hazardous than the type-confusion we already got. Actu-
ally, we have the same chances to dump memory than with the attacks published
in [24] and [17]. With a good knowledge of the Class objectâ€™s structure we could
also try to modify the static ï¬eld resolution, as proposed in [12] and used in
[13], to circumvent the application ï¬rewall. Nevertheless, this may enable future
ill-formed-application-based attacks to target platform protected by OCBV.
5.2
Case Study 2: Modifying Any Application Behavior
Unlike the previous case study, we will now fully take advantage of the implicitly
transferable property of Class objects. Thanks to our reference forgery tool,
the attacker is also able to modify any other applications regardless its context,
endangering thus the whole platform integrity.
To illustrate how dangerous this can be, we study here the case of an appli-
cation whose security relies on user/client authentication based on a signature
scheme. The designers of this application being totally conï¬dent in the embedded
signature scheme, since its implementation has been certiï¬ed resistant against
all kinds of side channel and fault attacks.
Therefore, somewhere in this applicationâ€™s code, the following lines will
appear:

160
G. Barbu, H. Thiebeauld, and V. Guerin
1. if (sig.verify(inBuff, inOff, inLen, sigBuff, sigOff, sigLen)) {
2.
... // Success, access granted.
3. } else {
4.
... // Failure, access denied.
5. }
Consider now an attacker who wants to access this applicationâ€™s assets. Without
the knowledge of the signatureâ€™s private key he cannot be successful. But the
forgery tool will allow him to circumvent this obstacle.
Thanks to the transferability of Class objects, under H1 and provided the
attacker knows the fully qualiï¬ed name of the class containing the call to the
verify method, he is then able to forge a reference to the corresponding Class
instance (still using the INS SEARCH CLASS OBJECT instruction). He will then
have access to its bytecode array.
Knowing the verify methodâ€™s descriptor, he can deduce that a call to this
method will consist in pushing the sigâ€™s reference and all the arguments on the
stack (inBuff, inOff, ...).
He can then identify the bytes involved in the call to the verify method in
the bytecode array (Fig. 7).
Fig. 7. The call of the verify method
Finally, he has just to set all these bytes to 0x00, which corresponds to the
nop instruction (i.e. no operation), except the last one, to which he assigns the
value corresponding to iconst 1, pushing the value 1 on the stack (Fig. 8).
Fig. 8. Making the signature veriï¬cation always successful

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
161
Operating this modiï¬cation, the attacker changes the applicationâ€™s code as if
its Java source code were the following:
1. if (true) {
2.
... // Success, access granted.
3. } else {
4.
... // Failure, access denied.
5. }
He has then granted access to the applicationâ€™s assets whatever the value of the
signature.
This simple case study shows the potential threat such attacks can represent.
Our application becomes a trojan horse capable of modifying other applications
from the inside (as suggested in [13]). The number of possible attack scenarii is
only limited by the attackerâ€™s imagination. Besides, although a good knowledge
of the target application will ease the attack, we can eventually consider it as
not necessary. If an attacker is able to read the content of all Class objects,
identifying his target amongst those should not require huge eï¬€orts.
6
Security Concerns
The attacks described in Sections 4 and 4.2 reveal that some weaknesses in open
platforms can defeat the whole security of a device. In a same vein, the attack
described in [13] has shown that once a trojan horse had been setup, it could
lead, in certain implementation conditions, to an access in both writing and
reading to a large part of the memory, opening then plenty of possibilities to
aï¬€ect seriously the device reliability.
These examples illustrate that the open platform security relies on the imple-
mentation quality. Our attacks show that the Java Card 3 Connected Edition is not
an exception. This new standard with all his additional features is not less secure
than the previous versions, quite the reverse, and does not seem to contain any
weakness. However to achieve a high level of security, even if a speciï¬cation has
been designed with a real concern for security, it must be associated to an appro-
priate security-oriented implementation. Therefore we can raise the question, how
implementing the Java Card 3 speciï¬cations taking into account those threats?
Even if the chips appear to be more and more resistant with regard to fault
injections, this risk should systematically be taken into consideration in the
software, as an adequate complement. To achieve a resistant implementation,
well-known countermeasures could be inserted, like execution ï¬‚ow controls, dou-
bling sensitive operations and checking their coherency, variable redundancies,
etc (cf. [8]). In the context of our attacks, the checkcast bytecode should then
be considered as sensitive and handled accordingly.
Moreover, the success of the case studies described in Section 4.2 relies on an
implementation choice: for optimization reason, as explained in Section 4.2, it
was natural to associate the bytecode to the Class objects. However, it turns
out to be a potential vulnerability regarding the logical attacks. It explains why
the developer should often ï¬nd the accurate balance between performance and

162
G. Barbu, H. Thiebeauld, and V. Guerin
security. A good know-how of the potential risks is then necessary to prevent
any implementation weakness.
Last but not least, this attack has revealed that static controls could still be
circumvented. We mean by static controls the controls performed for instance
during the bytecode veriï¬cation, ensuring the .class ï¬le is well-formed. How-
ever, once this veriï¬cation achieved, the bytecode coherency is not checked dur-
ing its execution. In other words, the installation of ill-formed applet is nearly
impossible, but not its eventual execution. In normal conditions of use, the ap-
plication needs obviously to be loaded and installed beforehand, the platform
then looks secure. Nevertheless, for an attacker, once this ï¬rst static veriï¬cation
bypassed, the platform does not ensure anymore an adequate protection, leading
to a potential vulnerability. Finally the mandatory OCBV is a consequent se-
curity improvement, but it does not take the place of eï¬ƒcient dynamic controls
performed during the VM execution.
7
Conclusion
In this paper, a new attack combining fault injection and logical tampering
has been presented and applied on the Java Card 3 Connected Edition. We have
demonstrated that this kind of attack is very eï¬ƒcient. It is thus possible to either
alter any method regardless its java context or even to execute any bytecode,
even ill-formed, bypassing the OCBV. Such vulnerabilities successfully applied
on a device would aï¬€ect dramatically its security.
Our attack is speciï¬c to Java Card 3.0 for two reasons. Firstly it held in a
context of a mandatory OCBV, which is a speciï¬city of the last Java Card spec-
iï¬cation. Secondly the possibility to handle Class objects, a newly introduced
feature, was exploited.
Its practicability has been successfully demonstrated on a recent micro-
controller, with a straightforward Java Card 3 implementation. These results
have revealed the necessity of a secure implementation, even when speciï¬cations
are designed to resist to the current state of the art attacks on smartcards.
Acknowledgement
The authors would like to thank Nicolas Bousquet, for his valuable suggestions
during the design of the case studies presented in this paper, and Nicolas Morin,
for his contribution to this work, putting the theoretical attack into practice.
Additionally, thanks to Christophe Giraud and Philippe Hoogvorst for their
helpful comments during this paper writing.
References
1. Allenbach, P.: Java Card 3: Classic Functionality Gets a Connectivity Boost (2009),
http://java.sun.com/developer/technicalArticles/javacard/javacard3/
2. Anderson, R., Kuhn, M.: Tamper Resistance â€“ a Cautionary Note. In: Proceed-
ings of the 2nd USENIX Workshop on Electronic Commerce, pp. 1â€“11. USENIX
Association (1996)

Attacks on Java Card 3.0 Combining Fault and Logical Attacks
163
3. AumÂ¨uller, C., Bier, P., Fischer, W., Hofreiter, P., Seifert, J.P.: Fault Attacks on
RSA with CRT: Concrete Results and Practical Countermeasures. In: Kaliski
Jr., B.S., KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp. 260â€“275.
Springer, Heidelberg (2003)
4. Barbu, G.: Fault Attacks on Java Card 3 Virtual Machine. In: e-Smart 2009 (2009)
5. Bauduin, R.: Fault Attacks, an Intuitive Approach. In: Fault Diagnosis and Toler-
ance in Cryptography, FDTC 2006 (2006) (invited talk)
6. Boneh, D., DeMillo, R., Lipton, R.: On the Importance of Checking Cryptographic
Protocols for Faults. In: Fumy, W. (ed.) EUROCRYPT 1997. LNCS, vol. 1233, pp.
37â€“51. Springer, Heidelberg (1997)
7. Common Criteria: Application of Attack Potential to Smartcards - Version 2.7,
Rev.1 (2009)
8. Giraud, C., Thiebeauld, H.: A Survey on Fault Attacks. In: Smart Card Re-
search and Advanced Application Conference (CARDIS 2004). LNCS, pp. 159â€“176.
Springer, Heidelberg (2004)
9. GlobalPlatform Inc.: GlobalPlatform Card Speciï¬cation 2.1.1. (2003)
10. GlobalPlatform Inc.: GlobalPlatform Card Speciï¬cation 2.2. (2006)
11. Govindavajhala, S., Appel, A.: Using Memory Errors to Attack a Virtual Machine.
In: IEEE Symposium on Security and Privacy, SP 2003 (2003)
12. HyppÂ¨onen, K.: Use of Cryptographic Codes for Bytecode Veriï¬cation in Smartcard
Environment. Masterâ€™s thesis, University of Kuopio, Finland (2003)
13. Iguchi-Cartigny, J., Lanet, J.L.: Â´Evaluation de lâ€™injection de code malicieux dans
une Java Card. In: Symposium sur la SÂ´ecuritÂ´e des Technologies de lâ€™Information
et de la Communication, SSTIC 2009 (2009)
14. Kocher, P., Jaï¬€e, J., Jun, B.: Introduction to Diï¬€erential Power Analysis and
Related Attacks. Technical report, Cryptography Research Inc. (1998)
15. Kocher, P., Jaï¬€e, J., Jun, B.: Diï¬€erential Power Analysis. In: Wiener, M. (ed.)
CRYPTO 1999. LNCS, vol. 1666, pp. 388â€“397. Springer, Heidelberg (1999)
16. Lindholm, T., Yellin, F.: The Java Virtual Machine Speciï¬cation, 2nd edn.
Addison-Wesley, Reading (1999)
17. Mostowski, W., Poll, E.: Malicious Code on Java Card Smartcards: Attacks and
Countermeasures. In: Grimaud, G., Standaert, F.-X. (eds.) CARDIS 2008. LNCS,
vol. 5189, pp. 1â€“16. Springer, Heidelberg (2008)
18. Sun Microsystems Inc.: Application Programming Interface, Java Card Platform
Version 3.0.1 Connected edn. (2009)
19. Sun Microsystems Inc.: Java Card Portal, http://java.sun.com/javacard/
20. Sun Microsystems Inc.: Runtime Environment Speciï¬cation, Java Card Platform
Version 2.2.2 (2006)
21. Sun Microsystems Inc.: Runtime Environment Speciï¬cation, Java Card Platform
Version 3.0.1 Connected edn. (2009)
22. Sun Microsystems Inc.: Virtual Machine Speciï¬cation, Java Card Platform Version
2.2.2 (2006)
23. Vermoen, D., Witteman, M., Gaydadjiev, G.: Reverse Engineering Java Card
Applet Using Power Analysis. In: Sauveron, D., Markantonakis, K., Bilas, A.,
Quisquater, J.-J. (eds.) WISTP 2007. LNCS, vol. 4462, pp. 138â€“149. Springer,
Heidelberg (2007)
24. Witteman, M.: Java Card Security. Information Security Bulletin 8, 291â€“298 (2003)

Improved Fault Analysis of Signature Schemes
Christophe Giraud1, Erik W. Knudsen2, and Michael Tunstall3
1 Oberthur Technologies,
4, allÂ´ee du doyen Georges Brus, 33 600, Pessac, France
c.giraud@oberthur.com
2 Alm. Brand,
Midtermolen 7, 2100 KÃ¸benhavn Ã˜, Denmark
aberkn@almbrand.dk
3 Department of Computer Science, University of Bristol,
Merchant Venturers Building, Woodland Road,
Bristol BS8 1UB, United Kingdom
tunstall@cs.bris.ac.uk
Abstract. At ACISP 2004, Giraud and Knudsen presented the ï¬rst
fault analysis of DSA, ECDSA, XTR-DSA, Schnorr and ElGamal sig-
natures schemes that considered faults aï¬€ecting one byte. They showed
that 2304 faulty signatures would be expected to reduce the number of
possible keys to 240, allowing a 160-bit private key to be recovered. In
this paper we show that Giraud and Knudsenâ€™s fault attack is much more
eï¬ƒcient than originally claimed. We prove that 34.3% less faulty signa-
tures are required to recover a private key using the same fault model.
We also show that their original way of expressing the fault model un-
der a system of equations can be improved. A more precise expression
allows us to obtain another improvement of up to 47.1%, depending on
the values of the key byte aï¬€ected.
Keywords: Fault analysis, Signature schemes, Smart card.
1
Introduction
Since their introduction in 1996 by Boneh, DeMillo and Lipton [3], fault attacks
have been widely studied from both practical and theoretical points of view.
This type of attack poses a serious threat that needs to be considered when
implementing cryptographic algorithms on embedded devices [2]. Once a suitable
mechanism for injecting a fault is found, fault attacks would allow an attacker to
break any cryptographic implementation faster than any other kind of attacks.
The following examples speak for themselves: a DES secret key can be revealed by
using two faulty ciphertexts [4,10], an 128-bit AES secret key can be recovered
by using one faulty ciphertext [16] and CRT RSA private parameters can be
obtained by using one faulty signature [13,11]. In the particular case of DSA [8],
ECDSA [8], XTR-DSA [14], Schnorr [17] and ElGamal [7] signature schemes,
fault attacks are not as eï¬ƒcient. Indeed, if an attacker is able to induce an
error on a single bit, the most eï¬ƒcient attacks on such schemes can recover the
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 164â€“181, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Improved Fault Analysis of Signature Schemes
165
corresponding private keys by using one faulty signature per bit of the private
key [1,6]. However, injecting a fault that would only aï¬€ect one bit would be very
diï¬ƒcult to put into practice. Giraud and Knudsen extended previous attacks
to use a more realistic model where faults where considered that would aï¬€ect
one byte [9]. By using this fault model, they claimed that one would be able to
recover a 160-bit private key by using 2304 faulty signatures and then conducting
an exhaustive search amongst 240 possible keys.
In this paper, we analyse the attack proposed by Giraud and Knudsen [9] in
more detail, and we show that their attack is much more eï¬ƒcient than originally
claimed. Our improved analysis is two-fold. Firstly, under the same assumptions
used in [9], we prove that the average number of trials required to conduct an
exhaustive search is 230 and not 239 as implicitly indicated in [9]. Consequently,
under the same attack model used in [9] we show that an attacker needs 34.3%
less faulty signatures to recover a 160-bit private key. Secondly, we improve the
detail of the system of equations representing the fault model. This more precise
deï¬nition allows us to signiï¬cantly improve the results given in [9], especially if
the key is composed of bytes close to 0 or 255. In such a case, the improvement
can be up to 47.1%.
The rest of this paper is organised as follows. In Section 2, we recall the previ-
ous fault attacks which have been published on signature schemes. In Section 3,
we compute the average number of guesses to conduct an exhaustive search if
performing a fault attack by using the fault model presented in [9]. In Section 4,
we present a more accurate system of equations representing the fault model
used in [9]. This allows us to improve the original result and to show that the
eï¬ƒciency of this attack is dependant on the key value. Finally, Section 5 inves-
tigates if there is an optimal method to perform the exhaustive search.
2
Previous Work
The ï¬rst fault attack on signature schemes was proposed in [5] on the RSA
using the Chinese Remainder Theorem (CRT). It was shown that a CRT RSA
private key could be derived if one fault was injected during the generation of
a signature. This attack requires an attacker to obtain two signatures for the
same message M, where one signature is correct and the other one is faulty. By
computing the gcd of the modulus N and the diï¬€erence between the correct and
the faulty signature, the attacker would obtain one private factor of the modulus.
This attack was extended in [13,11] by using only one signature generation.
A fault attack on RSA, where the CRT is not used, is deï¬ned in [1]. Again the
attack compares the result of generating signatures from the same message with,
and without faults. While a signature is being generated an attacker generates
a fault causing one bit of the private exponent d to be changed, resulting in a
faulty signature Sâ€². Assuming that the i-th bit of d is complemented, then, as
described in [1], we have:
Sâ€²
S â‰¡M dâ€²âˆ’d â‰¡

M 2i
(mod N)
if the i-th bit of d = 0,
1
M2i
(mod N)
if the i-th bit of d = 1.
(1)

166
C. Giraud, E.W. Knudsen, and M. Tunstall
where S is the correct signature. In [1] it was also shown that this attack can be
applied to other signature schemes, such as ElGamal, Schnorr and DSA.
In [12] it was shown that this attack can be improved by raising the formula
to the power of the public exponent v, giving:
Sâ€²v
M â‰¡

(M v)2i
(mod N)
if the i-th bit of d = 0,
1
(Mv)2i
(mod N)
if the i-th bit of d = 1.
(2)
In this case it is not necessary to know the correct signature S.
An attacker can compute Sâ€²v
M mod N for all the possible one-bit fault errors
in d. This requires a total of log2 d trials to completely derive d if an attacker is
able to dictate which bit of d is complemented.
This was extended by Giraud and Knudsen in [9] to consider faults that aï¬€ect
one byte of an exponent. Let us now describe this extension where, to avoid
any ambiguity, the fault needs to be treated as an integer diï¬€erence between
a correct exponent byte and a corrupted exponent byte. As above, we deï¬ne
the private key as d and dâ€² as the corresponding corrupt private key. We deï¬ne
dj and dâ€²
j as the jth byte of d and dâ€² respectively, a fault on the ith byte will
therefore produce:
dâ€²
j = dj,
âˆ€j Ì¸= i
dâ€²
j = dj + e, if j = i
(3)
with dj, dâ€²
j âˆˆ{0, . . ., 255} and e âˆˆ{âˆ’255, . . ., 255} where e = 0 corresponds to
no error. For each fault on one byte of d, the attacker will deduce the position i
of the corrupted byte since it is the only value for j which satisï¬es dj Ì¸= dâ€²
j. He
will then compute the corresponding value of e by subtracting dâ€²
i with di.
By deï¬nition, the possible values for e are:
e âˆˆ{âˆ’di, . . . , 255 âˆ’di} .
(4)
If two faults are observed, e and e, the possible values of di can be restricted to
n values where:
e < e : e âˆ’e = 256 âˆ’n ,
(5)
which means that:
âˆ’e â‰¤di â‰¤âˆ’e + (n âˆ’1) .
(6)
In [9] it is shown that the number of faulty signatures required to observe two
faults with a signiï¬cant enough diï¬€erence to reduce di to a certain number of
hypotheses can be deï¬ned. The average number of faults required to reduce the
possible values to x values, for x âˆˆ{1, . . . , 8}, are shown in Table 1.
In the next section, we present another way of analysing the eï¬ƒciency of the
attack described in [9]. Indeed, whatever the number of candidates left, the most
important information is the average number of guesses the attacker needs to do
to recover the value of the secret key.

Improved Fault Analysis of Signature Schemes
167
Table 1. Expected number of faulty signatures required to reduce the number of
possible values for one key byte [9]
Maximum1 number of candidates Expected number of faulty
left for di
signatures required
1
384.0
2
213.3
3
149.3
4
115.2
5
93.9
6
79.2
7
68.6
8
60.4
3
A More Practical Analysis
The analysis in [9] deï¬nes the average number of faulty signatures that are
required to reduce the number of possible values for di to a given number of
hypotheses. It is then suggested that the private key can be found using an
exhaustive search. However, the expected number of guesses an attacker would
have to conduct is not deï¬ned in [9]. This information is of uttermost importance
when analysing the eï¬ƒciency of the attack. For example, it is shown in [9] that a
2160 key space is reduced to at most 240 by using 2304 faulty signatures. There-
fore, one could assume that expected number of guesses in the exhaustive search
is 239, but this is not the case as it will be seen in this section. In the following,
we derive the expected number of guesses for a given number of induced faults
under the same assumptions deï¬ned in [9].
3.1
Notation
After inducing t faults Î³i for i âˆˆ{1, Â· Â· Â· , t}, we deï¬ne the Min statistic by:
min = Min(Î³1, . . . , Î³t) ,
(7)
and the Max statistic by:
max = Max(Î³1, . . . , Î³t) .
(8)
3.2
Expected Search Time
By denoting by N the number of possible values for the variable we disturb (in
our case N = 256 since we disturb one byte), we summarise the attack described
in [9] as follows:
1 In [9], it is written â€œAverage number of candidates leftâ€ but their formula gives the
average number of faulty signatures required to reduced the number of candidates
to at most n. Therefore we need to replace â€œAverageâ€ by â€œMaximumâ€.

168
C. Giraud, E.W. Knudsen, and M. Tunstall
â€œInduce t faults on a variable K âˆˆ{0, Â· Â· Â· , N âˆ’1} which results in
observed values min and max with diï¬€erence f = max âˆ’min. Then
guess between the N âˆ’f remaining candidates at random.â€
Theorem 1 gives the probability of guessing the correct key in the gth guess using
this algorithm:
Theorem 1. Let a variable K âˆˆ{0, Â· Â· Â· , N âˆ’1} with value a be given. The prob-
ability of the number of guesses X being equal to g using the ACISP Algorithm
with t faulty signatures uniformly distributed is given by:
Pr(X = g|K = a) = Pr(max = a âˆ’g + 1|K = a)
=

Nâˆ’g+1
N
t
âˆ’

Nâˆ’g
N
t
(9)
Using Theorem 1, we can compute the expected waiting time as:
Corollary 1. The expected size of an exhaustive search by using the algorithm
described in [9] is:
N

s=1
 s
N
t
.
The proofs of Theorem 1 and Corollary 1 are given in Appendix A2.
By using Corollary 1 with N = 256, we can compute the expected number
of faulty signatures to reduce the number of guesses to x, for x âˆˆ{2, . . . , 8}, as
shown in Table 2.
Table 2. Expected number of faulty signatures required to reduce the expected number
of guesses to x, for x âˆˆ{2, . . . , 8}
Expected number of guesses for di Number of faulty signatures performed
2
176.5
3
102.8
4
72.7
5
56.2
6
45.7
7
38.5
8
33.2
We can, therefore, demonstrate using Corollary 1 that using 2304 faulty signa-
tures to attack a 160-bit key (i.e. 115.2 faulty signatures per key byte) implies
that the expected number of guesses required to conduct an exhaustive search
is
256
s=1
	 s
256

115.220
â‰ˆ230 and not 239 as implicitly indicated in [9].
2 In Appendix A.1, we present a simpler proof of [9, Theorem 1] than the one in the
aforementioned article.

Improved Fault Analysis of Signature Schemes
169
Moreover, under the same attack model as in [9] (i.e. an attacker being able
to inject faults on one byte and being able to perform 239 signatures during the
exhaustive search to ï¬nd the correct key), we compute by using Corollary 1 that
only 1513.3 faulty signatures are required3 to recover a 160-bit private key. It is
therefore an improvement of 34.3% compared to what was announced in [9].
The analysis presented in [9] and in this section are based on Relations (4)
and (6). However, we show in the next section that these Relations can be reï¬ned,
leading to an improvement of the corresponding analyses.
4
Improving the Analysis
In this section we will discuss some improvements to the analysis given in [9].
This is based on a more precise deï¬nition of the fault model and subsequent
interpretation.
4.1
Reducing the Number of Possible Values for the Error
In this section, we present two remarks that allow us to improve the number of
faulty signatures required.
Firstly, as described above, we have:
di + e = dâ€²
i
(10)
with di, dâ€²
i âˆˆ{0, . . ., 255} and e âˆˆ{âˆ’255, . . ., 255}. In [9], Relation (10) leads
them to the following relation:
âˆ’e â‰¤di â‰¤255 âˆ’e
(11)
However, we can reduce this interval of possible values for di by taking into
account that di âˆˆ{0, . . ., 255}. This leads us to the following relation:
Max(0, âˆ’e) â‰¤di â‰¤Min(255, 255 âˆ’e) ,
(12)
One may note that this restriction only signiï¬cantly improves the analysis when
the key byte value is close to 0 or to 255.
Another way to slightly improve the analysis of [9] is to notice that they take
into account the case e = 0 when computing their probabilities. As this case
corresponds to not inï¬‚icting any error, the resulting signature will be correct
and can then be excluded. We can, therefore, deï¬ne the error e as:
e âˆˆ{âˆ’di, . . . , 255 âˆ’di} \ {0} ,
(13)
which further allows us to reduce the number of faulty signatures required.
In the next section, we redo the analysis done in [9] and in Section (3) by
using Relations (12) and (13) instead of Relations (6) and (4) respectively.
3 To obtain
256
s=1
	
s
256

t20
â‰ˆ239, we need to use t = 75.66 faulty signatures per
byte.

170
C. Giraud, E.W. Knudsen, and M. Tunstall
4.2
The Expected Number of Faults Required
To compute the statistically expected number of faults that will need to be
observed we can model the system using a series of geometric distributions (see
Appendix B). In this section we assume that an attacker wants to reduce the
number of possible hypotheses for a given byte to less than Î±. That is, the results
of this analysis can be directly compared to those presented in [9].
The simplest case will be where the key byte is equal to zero or 255. Assuming
that the eï¬€ect of a fault is uniformly distributed, the probability of a given event
allowing this is Î±/255. So, we can say that attacker would expect to reduce the
hypotheses to less than Î± after 255/Î± observed faults.
This is no longer the case if we consider other key values as observations
can occur that are improved upon with subsequent observations. An attacker
will be interested in observing a fault such that e âˆˆ{âˆ’k, . . . , âˆ’k + Î±} or e âˆˆ
{255 âˆ’k âˆ’Î±, . . . , 255 âˆ’k}, for some key byte k. This is because these values can
be combined to make a list of less than, or equal to, Î± hypotheses. For any event
an attacker would expect to observe a value form these groups with a probability
of 2 Î±
255, and therefore would expect this to occur after 255
2 Î± observed faults.
For each of the 2 Î± possible faults there will be a certain number of faults that
will be of interest to an attacker. For each of the possible faults the number of
faults that improve the amount of information can be noted. The probability of
observing a further fault of interest can be computed and another expectation
derived from this. This can be continued for each possible combination of obser-
vations for a given Î± and the average expected number of observations can be
computed.
For key values close to zero or 255 the initial two groups {âˆ’k, . . ., âˆ’k + Î±} or
{255 âˆ’kâˆ’Î±, . . . , 255 âˆ’k} will be modiï¬ed since an attacker will know the value
when no fault is applied, i.e. e = 0. This means that the average expectation
across all the possible key values will lead to the expected number of faults.
If, for example, we consider the case where Î± = 2. For simplicity, we will
also assume that the key byte value is âˆˆ{2, . . ., 253}, i.e. the value of the key
byte will not interfere with the analysis. Using the above method the expected
number of observations X1 is computed as
E(X1) = 255
4
+ 1
4 Â· 255
2
+ 1
4
255
3
+ 2
3 Â· 255
2

+ 1
4 Â· 255
2
+ 1
4
255
3
+ 2
3 Â· 255
2

= 212.5 ,
where E is a function that returns the statistical expectation.
If the key byte value is âˆˆ{1, 254}, then the known value for no fault being
injected will be part of the process. Using the above method the expected number
of observations X2 is computed as
E(X2) = 255
3
+ 1
3 Â· 255
2
+ 1
3 Â· 255
2
= 170 .

Improved Fault Analysis of Signature Schemes
171
If the key byte value is âˆˆ{0, 255}, then we only need one observation of interest
to reduce the number of possible values to the required amount. Using the above
method the expected number of observations X3 is computed as
E(X3) = 255
2
= 127.5 .
The expectation for a uniformly distributed key âˆˆ{0, . . . , 255} is a weighted
mean of the above expectations. The expected number of faults required X
therefore becomes
E(X) = 252 E(X1) + 2 E(X2) + 2 E(X3)
256
= 211.5 .
The results of computing the above for Î± âˆˆ{1, . . ., 8} is shown in Table 3 (all
rounded to one decimal place).
Table 3. Expected number of guesses for one key byte depending on the number of
faulty signatures
Maximum number of hypotheses for di Expected number of faulty signatures
1
381.5
2
211.5
3
147.8
4
113.8
5
92.5
6
77.9
7
67.3
8
59.2
One can note that the improvement in Table 3 is minimal compared to Ta-
ble 1 (1.3% on average). The improvements discussed in Section 4.1 only have a
signiï¬cant impact when a the value of a key byte is close to 0 or to 255. Figure 1
shows the key value dependency of this improvement when using 114 faulty sig-
natures. In such a case, the improvement is of 39.2% if the key byte is equal
to 0 or 255. Moreover, the smallest the number of faulty signatures we use, the
biggest the improvement is. For instance, we obtain an improvement of 49.3%
when using 10 faulty signatures if the key byte is equal to 0 or 255.
4.3
The Expected Size of an Exhaustive Search
The analysis described in the previous section is limited in the same way as
the analysis described in [9]. The number of faults required is that needed to
reduce the number of faults to less than a given value. In this section we deï¬ne
the expected number of faults required to produce an exhaustive search of a
given size.

172
C. Giraud, E.W. Knudsen, and M. Tunstall
0
50
100
150
200
250
0
5
10
15
20
25
30
35
40
Improvement in %
Value of the key byte
240
245
250
255
0
5
10
15
20
25
30
35
40
Improvement in %
Value of the key byte
Fig. 1.a. Global view
Fig. 1.b. Zoom on Fig. 1.a
Fig. 1. Improvement of the analysis on the number of remaining candidates depending
of the key byte value when using 114 faulty signatures
We ï¬rst deï¬ne the probability that a set of t observations will span X diï¬€erent
values, for X âˆˆ{1, . . . , N âˆ’1} (in our case N = 256). Trivially, we can say that
Pr(X = 1) =
N âˆ’1
(N âˆ’1)t
(14)
since the probability of all t observations having the same value is
1
(Nâˆ’1)t for
each possible value of X.
For X = 2,
Pr(X = 2) = 2 S(t, 2) (N âˆ’2)
(N âˆ’1)t
(15)
where we deï¬ne S(n, i) as a function that returns the Stirling numbers of the
second kind. That is, the number of ways of partitioning n elements into i non-
empty sets. Given that our sets are unique this needs to be multiplied by 2.
Furthermore, there are (N âˆ’2) possible sets where X = 2.
Computing the expectation becomes more complex for X > 2 since the sets
representing the minimum and maximum possible values need to be non-empty,
but the values in between can be empty. In order to compute the number of
possible combinations that will span x diï¬€erent values we consider that the
values fall into two sets. The ï¬rst set represents the minimum and maximum
values (there will be a minimum of two observations in this set). The second set
represents the values in between the minimum and maximum observation and
can contain empty sets.
We consider t faults that span x diï¬€erent values, where t > 2 and x > 2.
These faults will be distributed between the two sets deï¬ned above. The set
representing the minimum and maximum values contains i observations, where
i is âˆˆ{2, . . ., t}, then the number of combinations that are possible for a given
i will be 2 S(i, 2), as described above. The remaining observations will be in
the other set where the number of combinations will be (x âˆ’2)tâˆ’i. We can note
that this number of combinations will only take into account one particular set of

Improved Fault Analysis of Signature Schemes
173
i observations from t faults. This means that there will be
	t
i

possible ways of
choosing i observations. This leads to
Pr(X = x | x > 2) = (N âˆ’x) t
i=2 2 S(i, 2) (x âˆ’2)tâˆ’i 	t
i

(N âˆ’1)t
,
(16)
where we note that there are (N âˆ’x) possible combinations where X = x.
The list of key hypotheses that can be excluded will also depend on the value
of the byte aï¬€ected by the fault being injected. The probability of a set of
observations having a particular diï¬€erence between the maximum and minimum
observation x for a speciï¬c key value k is
Pr(X = x | k = z) = Pr(X = x)
256
,
(17)
where we assume that the z is âˆˆ{0, . . ., 255}, i.e. 256 possible values.
However, the expectation cannot be computed directly from this probability.
This is because the signature where no fault is injected is known, i.e. an obser-
vation where the fault induced is equal to zero. For a minimum observation M1
and a maximum observation M2, spanning x values, we can deï¬ne:
Min(M1, 0)
Max(0, M2)
For a given M1 and M2 the number of values that are actually spanned will be
equal to Max(0, M2) âˆ’Min(M1, 0), and the number of remaining hypotheses is
equal to N âˆ’1âˆ’Max(0, M2)+Min(M1, 0). Therefore, the probability given above
for Pr(X = x | k = z) needs to be divided by N âˆ’x to produce the probability
for speciï¬c values of M1 and M2.
The expected number of remaining hypotheses E(Y ) can be computed as
E(Y )=
Nâˆ’1

z=0
Nâˆ’1

x=1

m âˆˆÎ¦
m + x âˆ’1 âˆˆÎ¦
(Nâˆ’Max(0, m+xâˆ’1)+Min(m, 0))Pr(X = x | k = z)
N âˆ’x
,
where we use the notation deï¬ned above (cf. (14), (15), (16) and (17)). In addi-
tion we denote m as the minimum observation in a set of observations that span
x values. The values that m and m + x âˆ’1 can take are in Î¦, where Î¦ is the set
{âˆ’z, . . ., N âˆ’z âˆ’x} \ {0}.
If we assume the actual key value is uniformly distributed between the re-
maining hypotheses h then the expected number of tests required to ï¬nd a key
byte is computed as (h + 1)/2. For a fault in one by these values are shown in
Table 4, rounded to one decimal place.
In order to allow the results of the improvement to be directly compared to
the results described in Section 3, we used the formula for E(Y ) to compute the
expected number of faulty signatures required to reduce the number of guesses
between 2 and 8, cf. Table 5.

174
C. Giraud, E.W. Knudsen, and M. Tunstall
Table 4. Expected number of hypotheses and guesses required to determine a given
key byte
t E(# of Remaining Hypotheses) E(# of Tests)
1
170.3
85.7
2
127.7
64.3
3
102.1
51.6
4
85.1
43.0
5
72.9
37.0
6
63.7
32.4
7
56.7
28.8
8
51.0
26.0
9
46.4
23.7
10
42.5
21.8
Table 5. Expected number of faulty signatures required to reduce the expected number
of guesses to x, for x âˆˆ{1, . . . , 8}
Expected number of guesses for di Number of faulty signatures required
2
174.8
3
101.4
4
71.4
5
55.0
6
44.5
7
37.4
8
32.1
By observing Table 5, one can see that the improvement is minimal compared
to Table 2 (2.1% on average). It only has a signiï¬cant impact when the value
of a key byte is close to 0 or 255. Figure 2 shows this improvement when using
73 faulty signatures. In such a case, the improvement is of 37.6% if the key byte
is equal to 0 or 255. Moreover, the smallest the number of faulty signatures we
use, the biggest the improvement is. For instance, we obtain an improvement of
48.1% when using 10 faulty signatures.
The analysis conducted in this section shows that using the same attack model
used in [9]4 and considering a random 160-bit key (resp. a 160-bit key that
consists of bytes equal to 0 or 255), we would need 14885 (resp. 8006) faulty
ciphertexts to recover the entire key. In the latter case, we have an improvement
of 47.1% comparing to the result presented in Section 3.
4 That is, by using byte-fault model and a expected number guesses of 239.
5 To obtain E(Y )20 â‰ˆ239 with N = 256, we need to use t = 74.4 faulty signatures
per key byte.
6 To obtain E(Y )20 â‰ˆ239 with N = 256, z âˆˆ{0, 255} and by dividing Pr(X = x) by
2 instead of 256 to obtain Pr(X = x | k = z), we need to use t = 40 faulty signatures
per key byte.

Improved Fault Analysis of Signature Schemes
175
0
50
100
150
200
250
0
5
10
15
20
25
30
35
40
Improvement in %
Value of the key byte
240
245
250
255
0
5
10
15
20
25
30
35
40
Improvement in %
Value of the key byte
Fig. 2.a. Global view
Fig. 2.b. Zoom on Fig. 2.a
Fig. 2. Improvement of the analysis on the number of guesses depending of the key
byte value when using 73 faulty signatures
5
The Exhaustive Search
In [9], no detail is given on how to obtain the correct value of the key amongst
the possible values that are deï¬ned by the analysis. If, for example, there are
420 (240) possible values for a private key, we can say that one would expect
to conduct 239 trials, on average, to identify the correct value amongst the 420
possible values. In this section we demonstrate that there is no best method of
searching through the hypotheses that are produced by the analyses described
in this paper.
We deï¬ne a series of t faults Î³i for i âˆˆ{1, . . ., t}, which we assume are drawn
from a distribution that is uniform over the integers in {Î·, . . . , 255 âˆ’Î·} \ {0},
where Î· is an unknown integer âˆˆ{0, . . ., 255}. In order to rank a given value
of Î·, we divide the interval into s intervals. For simplicity, we assume that the
intervals are evenly spaced. Let xi denote the number of the observed Î³ which
fall within the i-th interval, so we have
x1 + Â· Â· Â· + xs = t .
(18)
Given that the faults induced are uniformly distributed, then
E(x1) = Â· Â· Â· = E(xs) = t
s ,
(19)
where E is a function that returns the statistical expectation.
This can be used to conduct a frequency test. That is, we compute a statistic
Î», where
Î» =
s

i=1
(O(xi) âˆ’E(xi))2
E(xi)
,
(20)
and O is a function that returns the number of observed faults in a particular
interval. Then Î» âˆ¼Ï‡2(s âˆ’1) and can be used to test the null hypothesis that Î·
is a given value for each possible value âˆˆ{0, . . . , 255}. For a given Î» the P-value

176
C. Giraud, E.W. Knudsen, and M. Tunstall
0
50
100
150
200
250
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Key Hypothesis
Pâˆ’value
0
50
100
150
200
250
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Key Hypothesis
Pâˆ’value
0
50
100
150
200
250
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Key Hypothesis
Pâˆ’value
Fig. 3. Returned P-values plotted for all possible values for one byte for s = 3, 5, 15
(top left, top right and bottom middle respectively). The dashed lines represent the
boundaries identiï¬ed by the minimum and maximum observed fault.
can be computed which is a value between 0 and 1, where the larger the value
the more evidence is provided against a hypothesis for Î· (typically values above
0.95 or 0.99 are used as a boundary, above which it can be stated that there is
no evidence to support a given null hypothesis).
A set of 32 simulated observations were generated where Î· was, arbitrarily, set
to 140. The above statistical test was then conducted for s âˆˆ{3, 5, 15}, i.e. small
divisors of 255. In Figure 3 we show the resulting P-values for all the possible
hypotheses for Î·. The dashed lines represent the boundaries that can be deduced
by observing the maximum and minimum possible values (see Equation (12)).
One could assume that the P-value between the two lines could be used to
determine which values of Î· are most likely and use this to optimise the exhaus-
tive search required once the possible values for a private key have been reduced
to a certain amount. However, this is not the case.
The test described above where the number of faults was set to values âˆˆ
{1, . . ., 64}, where 10 000 tests were conducted for each value. In each case the
distribution of the number of tests required in an exhaustive search was iden-
tical to that produced by simply starting with the least (or most) signiï¬cant
hypothesis and incrementing (or decrementing) the hypothesis for each test.
This is because the number of observed faults is not enough to give a good in-
dication of the distribution to which they belong. If enough faults were observed
to give a strong indication of the correct value of Î·, it would be expected that
the minimum and maximum observation would also identify Î· without requiring
any further computation.

Improved Fault Analysis of Signature Schemes
177
6
Conclusion
In this paper, we show that the fault attack described by Giraud and Knudsen
at ACISP 2004 is much more eï¬ƒcient than originally claimed. We proved that,
using the same attack model, we need 34.3% less faulty signatures to recover a
160-bit private key. Furthermore, by improving the fault model expression, we
show that for some key values we obtain another improvement of up to 47.1%.
Finally, we show that there is no optimal way of performing the exhaustive search
in order to reduce the computation complexity of this step.
In summary, Giraud and Knudsen claim that they need 2304 faulty signatures
to recover a 160-bit private key, but in this paper we prove that one would only
need between 800 and 1488 faulty signatures to recover such a key, using the
same model and expected size of the required exhaustive search.
Acknowledgments
The authors would like to thank FrÂ´edÂ´eric Amiel for initiating this work and Em-
manuel Prouï¬€for his helpful comments on the preliminary version of this paper.
The work described in this paper has been supported in part by the European
Commission IST Programme under Contract IST-2002-507932 ECRYPT and
EPSRC grant EP/F039638/1.
References
1. Bao, F., Deng, R., Han, Y., Jeng, A., Narasimhalu, A.D., Ngair, T.-H.: Breaking
Public Key Cryptosystems an Tamper Resistance Devices in the Presence of Tran-
sient Fault. In: Christianson, B., Lomas, M. (eds.) Security Protocols 1997. LNCS,
vol. 1361, pp. 115â€“124. Springer, Heidelberg (1998)
2. Bar-El, H., Choukri, H., Naccache, D., Tunstall, M., Whelan, C.: The Sorcererâ€™s
Apprentice Guide to Fault Attacks. IEEE 94(2), 370â€“382 (2006)
3. Bellcore. New Threat Model Breaks Crypto Codes. Press Release (September 1996)
4. Biham, E., Shamir, A.: Diï¬€erential Fault Analysis of Secret Key Cryptosystem.
In: Kaliski Jr., B.S. (ed.) CRYPTO 1997. LNCS, vol. 1294, pp. 513â€“525. Springer,
Heidelberg (1997)
5. Boneh, D., DeMillo, R., Lipton, R.: On the Importance of Checking Cryptographic
Protocols for Faults. In: Fumy, W. (ed.) EUROCRYPT 1997. LNCS, vol. 1233, pp.
37â€“51. Springer, Heidelberg (1997)
6. Dottax, E.: Fault Attacks on NESSIE Signature and Identiï¬cation Schemes. Tech-
nical report, NESSIE (October 2002)
7. ElGamal, T.: A Public-Key Cryptosystems and a Signature Scheme based on Dis-
cret Logarithms. IEEE Transaction on Information Theory 31(4), 172â€“469 (1985)
8. FIPS PUB 186-3. Digital Signature Standard. National Institute of Standards and
Technology, Draft (March 2006)
9. Giraud, C., Knudsen, E.: Fault Attacks on Signature Schemes. In: Wang, H.,
Pieprzyk, J., Varadharajan, V. (eds.) ACISP 2004. LNCS, vol. 3108, pp. 478â€“491.
Springer, Heidelberg (2004)

178
C. Giraud, E.W. Knudsen, and M. Tunstall
10. Giraud, C., Thiebeauld, H.: A Survey on Fault Attacks. In: Quisquater, J.-J.,
Paradinas, P., Deswarte, Y., Kalam, A.E. (eds.) Smart Card Research and Ad-
vanced Applications VI â€“ CARDIS 2004, pp. 159â€“176. Kluwer Academic Publish-
ers, Dordrecht (2004)
11. Joye, M., Lenstra, A., Quisquater, J.-J.: Chinese Remaindering Based Cryptosys-
tems in the Presence of Faults. Journal of Cryptology 12(4), 241â€“245 (1999)
12. Joye, M., Quisquater, J.-J., Bao, F., Deng, R.: RSA-type Signatures in the Presence
of Transient Faults. In: Darnell, M.J. (ed.) Cryptography and Coding 1997. LNCS,
vol. 1355, pp. 155â€“160. Springer, Heidelberg (1997)
13. Lenstra, A.: Memo on RSA Signature Generation in the Presence of Faults.
Manuscript (1996)
14. Lenstra, A., Verheul, E.: An Overview of the XTR Public Key System. In: Alster,
K., Urbanowicz, J., Williams, H. (eds.) Public Key Cryptography and Computa-
tional Number Theory, de Gruyter, pp. 151â€“180 (2000)
15. Naccache, D., Nguyen, P., Tunstall, M., Whelan, C.: Experimenting with Faults,
Lattices and the DSA. In: Vaudenay, S. (ed.) PKC 2005. LNCS, vol. 3386, pp.
16â€“28. Springer, Heidelberg (2005)
16. Saha, D., Mukhopadhyay, D., RoyChowdhury, D.: A Diagonal Fault Attack on
the Advanced Encryption Standard. Cryptology ePrint Archive, Report 2009/581
(2009), http://eprint.iacr.org/
17. Schnorr, C.: Eï¬ƒcient Identiï¬cation and Signatures for Smart Cards. In: Brassard,
G. (ed.) CRYPTO 1989. LNCS, vol. 435, pp. 239â€“252. Springer, Heidelberg (1990)
A
Proof of Theorem 1 and Corollary 1
A.1
Distributions
Theorem 2. Let a random variable X be given, which is uniformly discrete on the
interval 1 to N:
âˆ€1 â‰¤x â‰¤N : P(X â‰¤x) = x
N
and deï¬ne the function G as:
âˆ€1 â‰¤x â‰¤N : G(x) := P(X1, Â· Â· Â· , Xt â‰¤x) = P(X â‰¤x)t =
 x
N
t
.
The following hold:
i. For a âˆ’(N âˆ’1) â‰¤m â‰¤a:
P(max = m|K = a) =
N + m âˆ’a
N
t
+
N âˆ’1 + m âˆ’a
N
t
P(min = m|K = a) =
a + 1 âˆ’m
N
t
+
 a âˆ’m
N
t
ii. For d â‰¥2 and a âˆ’(N âˆ’1) â‰¤m â‰¤a âˆ’d:
P(min = m, max = m + d|K = a) = P(max = a âˆ’(N âˆ’1) + d|K = a)
âˆ’P(max = a âˆ’N + d|K = a)

Improved Fault Analysis of Signature Schemes
179
iii. For d â‰¥2:
P(max âˆ’min = d) = (N âˆ’d)(P(max = d + 1) âˆ’P(max = d))
P(d â‰¤max âˆ’min) = 1 âˆ’(N âˆ’d + 1)G(d) + (N âˆ’d)G(d âˆ’1)
The latter result is the same as the result from [9]:
P(Tn â‰¤t) = P(d â‰¤max âˆ’min) = 1 âˆ’(N âˆ’d + 1)G(d) + (N âˆ’d)G(d âˆ’1)
Proof (Theorem 2.i).
P(max â‰¤a) = P(X1, Â· Â· Â· , Xt â‰¤a)
=
t

i=1
P(Xi â‰¤a)
= P(X â‰¤x)t
= G(a)
P(min â‰¤a) = 1 âˆ’P(min > a)
= 1 âˆ’P(a + 1 â‰¤X1, Â· Â· Â· , Xt)
= 1 âˆ’G(N âˆ’a)
P(max = a) = P(max â‰¤a) âˆ’P(max â‰¤a âˆ’1)
= G(a) âˆ’G(a âˆ’1)
P(min = a) = P(min â‰¤a) âˆ’P(min â‰¤a âˆ’1)
= G(N âˆ’a + 1) âˆ’G(N âˆ’a)
â–¡
Proof (Theorem 2.ii). For d â‰¥0 and 1 â‰¤a â‰¤N âˆ’d:
P(min â‰¥a, max â‰¤a + d) = P(a â‰¤X1, Â· Â· Â· , Xt â‰¤a + d)
= P(1 â‰¤X1, Â· Â· Â· , Xt â‰¤d + 1)
= G(d + 1)
For d â‰¥2 and 1 â‰¤a â‰¤N âˆ’d:
P(min = a, max = a + d) = P(a â‰¤X1, Â· Â· Â· , Xt â‰¤a + d)
+P(a + 1 â‰¤X1, Â· Â· Â· , Xt â‰¤a + d âˆ’1)
âˆ’P(a â‰¤X1, Â· Â· Â· , Xt â‰¤a + d âˆ’1)
âˆ’P(a + 1 â‰¤X1, Â· Â· Â· , Xt â‰¤a + d)
= G(d + 1) âˆ’G(d) âˆ’(G(d) âˆ’G(d âˆ’1))
= P(max = d + 1) âˆ’P(max = d)
â–¡
Proof (Theorem 2.iii).
P(max âˆ’min = d) =
Nâˆ’d

a=1
P(min = a, max = d + a)
=
Nâˆ’d

a=1
(P(min = d + 1) âˆ’P(max = d))
= (N âˆ’d)(P(max = d + 1) âˆ’P(max = d))

180
C. Giraud, E.W. Knudsen, and M. Tunstall
P(d â‰¤max âˆ’min) = P(d â‰¤max âˆ’min â‰¤N âˆ’1) =
Nâˆ’1

a=d
P(max âˆ’min = a)
=
Nâˆ’1

a=d
(N âˆ’a)(P(max = a + 1) âˆ’P(max = a))
=
N

a=d+1
(N âˆ’a + 1)P(max = a) âˆ’
Nâˆ’1

a=d
(N âˆ’a)P(max = a)
=
Nâˆ’1

a=d+1
P(max = a) + P(max = N) âˆ’(N âˆ’d)P(max = d)
= P(d + 1 â‰¤max) âˆ’(N âˆ’d)P(max = d)
= 1 âˆ’G(d) âˆ’(N âˆ’d)(G(d) âˆ’G(d âˆ’1))
= 1 âˆ’(N âˆ’d + 1)G(d) + (N âˆ’d)G(d âˆ’1)
If we substitute N = 256 and d = N âˆ’n = 256 âˆ’n we get the result from [9, Theorem
1]:
P(Tn â‰¤t) = P(256 âˆ’n â‰¤max âˆ’min â‰¤255)
= 1 âˆ’(n + 1)G(256 âˆ’n) + nG(255 âˆ’n)
= 1 âˆ’(n + 1)
 256 âˆ’n
256
t
+ n
255 âˆ’n
256
t
but the derivation here is much simpler than the one in the aforementioned article. â–¡
A.2
Generic Formula for Making the Correct Guess
Lemma 1. With the notation:
A = â€NumGuess = nâ€
Bm,d = â€min = m, max = m + dâ€
C = â€K = aâ€
The probability of guessing the correct key in the gth guess can be expressed as
P(NumbGuess = g|K = a) = Nâˆ’g
d=0 (P(max = d) âˆ’P(max = d âˆ’1))
Ã— aâˆ’d
m=aâˆ’(Nâˆ’1) P(A|Bm,d âˆ©C)
Proof. Notice that
P(A âˆ©B|C) = P(A âˆ©B âˆ©C)
P(C)
= P(A|B âˆ©C)P(B âˆ©C)
P(C)
= P(A|B âˆ©C)P(B|C)
and
P(A|C) = P(âˆªm,d(Aâˆ©Bm,d)|C) =

m,d
P((Aâˆ©Bm,d)|C) =

m,d
P(A|Bm,dâˆ©C)P(Bm,d|C)
Now we can write:
P(NumbGuess = g|K = a) =
Nâˆ’g

d=0
aâˆ’d

m=aâˆ’(Nâˆ’1)
P(A|Bm,d âˆ©C)P(Bm,d|C)

Improved Fault Analysis of Signature Schemes
181
and we know from Theorem 2.ii that
P(Bm,d|C) = P(max = d) âˆ’P(max = d âˆ’1)
Insertion concludes the proof.
â–¡
A.3
Proofs of Theorem 1 and Corollary 1
Proof (Theorem 1). Having observed min = m and max = m + d, [9] is content with
noting that the number of remaining candidates equals N âˆ’d and therefore
P(A|Bm,d âˆ©C) =
1
N âˆ’d
The claim follows by insertion in the formula of Lemma 1.
â–¡
Proof (Corollary 1). The expected is given by the formula
N

s=1
sP(NumbGuess = g|K = a) =
N

s=1
s
N âˆ’s + 1
N
t
âˆ’
N âˆ’s
N
t
which reduces to the claimed formula.
â–¡
B
The Geometric Distribution
A geometric distribution is produced when we consider a system
Pr(X = x) = (1 âˆ’p)xâˆ’1 p
That is, a geometric distribution is produced when there will be x âˆ’1 failures before
a successful event (that occurs with probability p) and the system stops.
We note that a geometric series, for âˆ’1 < r < 1 gives
g(x) =
âˆ

k=0
a rk =
a
1 âˆ’r ,
and the ï¬rst diï¬€erential is
gâ€²(x) =
âˆ

k=1
a k rkâˆ’1 =
a
(1 âˆ’r)2 .
If X has a geometric distribution and 0 < p < 1, then the expectation of X is given
by
E(X) =
âˆ

x=1
x qxâˆ’1 p =
p
(1 âˆ’q)2 = 1
p ,
using the above formula for gâ€²(x) with a = p and r = q.

When Clocks Fail:
On Critical Paths and Clock Faults
Michel Agoyan1, Jean-Max Dutertre2,
David Naccache1,3, Bruno Robisson1, and Assia Tria1
1 cea-leti
Centre microÂ´electronique de Provence G. Charpak
DÂ´epartement sas
80 Avenue de Mimet, f-13120 Gardanne, France
{michel.agoyan,bruno.robisson,assia.tria}@cea.fr
2 Â´Ecole nationale supÂ´erieure des Mines de Saint-Â´Etienne
Centre microÂ´electronique de Provence G. Charpak
DÂ´epartement sas
80 Avenue de Mimet, f-13120 Gardanne, France
dutertre@emse.fr
3 Â´Ecole normale supÂ´erieure, DÂ´epartement dâ€™informatique, Â´Equipe de cryptographie,
45 rue dâ€™Ulm, f-75230 Paris cedex 05, France
david.naccache@ens.fr
Abstract. Whilst clock fault attacks are known to be a serious security
threat, an in-depth explanation of such faults still seems to be put in
order.
This work provides a theoretical analysis, backed by practical experi-
ments, explaining when and how clock faults occur. Understanding and
modeling the chain of events following a transient clock alteration allows
to accurately predict faulty circuit behavior. A prediction fully conï¬rmed
by injecting variable-duration faults at predetermined clock cycles.
We illustrate the process by successfully attacking an fpga aes im-
plementation using a dll-based fpga platform (one-bit fault attack).
1
Introduction
Fault attacks consist in modifying an electronic circuitâ€™s behavior to achieve
malicious goals [2,3]. Fault attacks exist in numerous variants ranging from a
simple alteration of a round counter during symmetric encryption [4] to math-
ematical Diï¬€erential Fault Attacks (dfa) where secret information is obtained
by comparing (diï¬€erentiating) correct and faulty encryption results [6,12].
Faults can be caused by a variety of intrusive and non-intrusive means [1]
such as lasers [16], electromagnetic perturbations [10,13], voltage variations [9]
or clock glitches [7].
In this work we present a new clock alteration technique for scenarii in which
the attacker is given access to the targetâ€™s clock. We start by explaining and mod-
eling the chain of events causing the faulty behavior. This theoretical analysis
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 182â€“193, 2010.
Â© IFIP International Federation for Information Processing 2010

When Clocks Fail: On Critical Paths and Clock Faults
183
perfectly reï¬‚ects experimental observations and allowed the injection of precise
single-bit faults into a chip running the aes algorithm (an actual implementation
of the attack described in [8]).
After introducing the model, we will overview the fault injectorâ€™s design, the
target chipâ€™s structure and the way in which the injector was used to extract
aes keys.
2
Why Clock Faults Occur?
We inject faults by violating synchrony, a basic assumption under which tra-
ditional digital ICs operate. In essence, most1 ICs execute calculations by pro-
cessing data by combinatorial logic blocks separated by D ï¬‚ip-ï¬‚op register banks
sharing the same clock (ï¬gure 1).
D
Q
D
Q
combinatorial
logic
clock
data
n
n
m
m
D Flip-Flop
Register
propagation delay
D Flip-Flop
Register
Fig. 1. Synchronous Representation of Digital ICs
Data is usually latched by registers at raising clock edges. Between two such
edges, the computed data travels between registers and gets modiï¬ed by the inter-
mediate combinatorial logic blocks. The time needed to propagate data through
combinatorial logic is called propagation delay. The propagation delay and a sec-
ond delay element, inherent to the use of D ï¬‚ip-ï¬‚op, called set-up time, deï¬ne the
circuitâ€™s maximal operating frequency (nominal circuit period). Indeed, to ensure
proper circuit operation, the clock period must be strictly greater than the max-
imal propagation delay in concerned circuit (this maximal propagation delay is
called critical path) plus the registersâ€™ set-up time. In other words:
Tclock > tcritical + tset-up
(1)
As a matter of fact any data bit entering a register is the result of a combinatorial
calculation involving several previous register output bits. The transformation of
the previous registersâ€™ output into the next registerâ€™s input bit takes a determined
delay. This delay depends on the the logic performed as well as on the data
transiting through the logic. In addition, propagation time varies with circuit
temperature and power supply voltage.
1 ICs that do not assume synchrony exist but we do not consider these in this work.

184
M. Agoyan et al.
2.1
Overclocking
Overclocking consists in decreasing the clock period (or, put diï¬€erently, increas-
ing clock frequency). If setup delays are not respected, the D ï¬‚ip-ï¬‚opâ€™s input is
not given suï¬ƒcient time to reach the latch. Causing faulty data to be latched in-
stead. This led several authors to use overclocking as fault injection means [9,15].
A decreased clock period can potentially aï¬€ect logical paths whose propaga-
tion times exceed the decreased clock period minus the set-up time. From the
attackerâ€™s perspective, the ability to control precisely the clock period is cru-
cial for inducing faults with precision. Note that temperature and power supply
changes may also be used to exert such control.
Fault attacks consist in injecting faults at precise moments. To avoid injecting
faults continuously, overclocking must be brief and transient. The fault injection
technique described in the next section allows doing so.
2.2
Injecting Clock Delay Faults
An attacker needs to control two parameters: the precise moment at which the
fault occurs and the clock anomalyâ€™s duration. The latter must be controlled
with high resolution, typically a few of tens of picoseconds.
Figure 2 illustrates a correct clock signal, clk, and a modiï¬ed clock meant to
cause faults, faulty clk.
5ns
10ns
15ns
20ns
25ns
30ns
35ns
40ns
45ns
CLK
O
100MHz
FAULTY CLK
O
Period - Delta
Period
Fig. 2. Normal (clk) vs. Faulty (faulty clk) Clock Signals
The two waveforms diï¬€er only between the delimiters positioned at 20ns and
30ns. During that interval, the faulty clkâ€™s period is reduced by Î” ns. The Î”
time decrement causes a set-up time violation fault. Note that the extension by
Î” of the preceding clock cycleâ€™s low state has no adverse eï¬€ect.
Generating faulty clk with suï¬ƒcient accuracy and precision is a challenging
task. To do so, we use the embedded Delay Locked Loop (dll) of a recent fpga
family (Xilinx Virtex 5). Two clocks (clk delayed i) with programmable skews
are generated from clk. The skews of the clk delayed i signals, denoted Î´i, are
programmable. faulty clk is obtained by switching between the clk delayed
i using a trigger signal. Figure 3 depicts this process in further details.
If clk delayed 2 is delayed by Î´2 time units, clk delayed 1 must be
delayed by Î´1 = Î´2
2 to preserve a 50% duty cycle at faulty clkâ€™s transient fault
interval.

When Clocks Fail: On Critical Paths and Clock Faults
185
0ps
5ns
10ns
15ns
20ns
25ns
30ns
35ns
40ns
45ns
50ns
CLK
O
100MHz
CLK DELAYED 1
CLK DELAYED 2
TRIGGER
O
FAULTY CLK
O
Rising edge
Falling edge
Fig. 3. Faulty (faulty clk) Clock Signal Generation
t1
t1
t2
both signals are represented on a 2.0V/div scale
8.2ns
Fig. 4. faulty clk (uppermost signal) and aes start (lowermost signal)
The device assembles faulty clk by combining clk delayed 2â€™s raising
edge and clk delayed 1â€™s falling edge. This is controlled by the signal trigger
that positions the perturbation in time. The accurancy at which faulty clkâ€™s
shape can be controlled (in our setting 35ps) depends on Î´t, the smallest ele-
mentary delay that the dll is able to provide. We will refer to faulty clkâ€™s
altered signal chunk as the faulting period (in Figure 3, the interval between
24ns and 30ns).
An oscilloscope screen-shot of faulty clk is shown on Figure 4 (uppermost
signal). Here, clkâ€™s period (10ns) was reduced to [t1, t2] = 49Î´t â‰ƒ8.2ns in
faulty clk. The lowermost signalâ€™s high level indicates the aesâ€™ start. The
implementation completes an encryption round in one cycle. Hence, the diagram
shows a fault injection at the ninth round (cf. section 3.2).
As we write these lines, a Xilinx Virtex 5 development board costs less than
$1000.
3
Clock Fault dfa on aes
We tested the attack setup on a concrete aes implementation. The following sec-
tions describe the target chip, the attackâ€™s theoretical principle ([8]) and report
practical experiment results.

186
M. Agoyan et al.
3.1
The Test Chip
The test chip (Xilinx Spartan 3AN fpga) implements a hardware 128-bit aes
[11,5] written in vhdl. The design consists of three main blocks: a commu-
nication and control module (ccm), a key expansion module (kem), and an
encryption module (enm).
The ccm manages the serial link through which plaintext and key material
are input. The start signal triggering the encryption and the resulting ciphertext
also transit through the ccm. In addition, the ccm controls the kem and the
enmâ€™s operations during encryption.
The implementation uses a 128-bit data path and runs the kem and the enm
in parallel. Consequently, an encryption round is completed in one clock cycle
and the entire aes computation takes 11 clock cycles.
The kem generates the round keys â€œon the ï¬‚yâ€. At each clock cycle, a new
round key is transferred from the kem to the enm. We will not overview the
kem in detail as it is of little relevance to our attack. We nonetheless underline
that the kemâ€™s critical delay path is much smaller than the enmâ€™s one â€“ this is
essential for the attack to work.
The enm architecture is depicted on Figure 5. The enm breaks-down into
ï¬ve submodules: AddRoundKey, SubBytes, ShiftRows, MixColumns, and Mux.
As their names suggest, the ï¬rst four correspond to the standard aes transfor-
mations. They are assembled with the multiplexer module, Mux, to form a closed
loop, implementing a complete aes round.
The Mux module opens the loop for plaintext acquisition during the ini-
tial round and closes it afterwards. The AddRoundKey module has a dedicated
bus (ciphertext) through which ciphertext is output after the ï¬nal round. The
MixColumns module is bypassed during the ï¬nal round. SubBytes is the only
clocked module (all the others being purely combinatorial blocks). This al-
lows, as mentioned before, to complete an encryption round in one clock cycle.
This loop architecture features a long data propagation path. Consequently, the
mux
AddRoundKey
plaintext
128
128
128
128
128
128
clock
round key
ciphertext
round number
SubBytes
ShiftRows
MixColumns
128
128
Fig. 5. aes Structure

When Clocks Fail: On Critical Paths and Clock Faults
187
designâ€™s critical delay path is located in the enm. The nominal clock frequency
of this aes implementation is 100 MHz.
3.2
Giraudâ€™s One-Bit Attack
This section recalls Giraudâ€™s dfa [8] (hereafter â€œGiraudâ€™s one-bit attackâ€). The
attack is based on the restrictive assumption that the opponent can inject one-
bit faults. We use the following notations:
M i
the algorithmâ€™s state at the end of round i
Ki
i-th round key number
C
a correct ciphertext
D
a faulty ciphertext
The attacker injects a single bit fault into one byte of state M 9 just before the
ï¬nal roundâ€™s SubBytes operation. This allows to retrieve the last round key K10.
Consider the i-th state byte just before the ï¬nal round M 9
i . The corresponding
byte index in the ciphertext is ShiftRows(i). As per the aesâ€™ speciï¬cations, for
all i âˆˆ{0, . . . , 15}:
CShiftRows(i) = SubBytes(M 9
i ) âŠ•K10
ShiftRows(i)
(2)
If a one-bit fault e,2 is injected into the j-th byte of M 9, we obtain at index j:
DShiftRows(j) = SubBytes(M 9
j âŠ•e) âŠ•K10
ShiftRows(j)
(3)
and for index i âˆˆ{0, . . . , 15}\{j}:
DShiftRows(i) = SubBytes(M 9
i ) âŠ•K10
ShiftRows(i)
(4)
Hence, a comparison (diï¬€erentiation) between the correct and the faulty ci-
phertexts leaks information both on the faultâ€™s position and on the aes key. For
i âˆˆ{0, . . . , 15}\{j}, equations 2 and 4 yield:
CShiftRows(i) = DShiftRows(i)
(5)
This allows to identify the faulty byteâ€™s index j because the only index for
which C âŠ•D is nonzero is ShiftRows(j). Moreover, at index j, equations 2 and
3 yield:
CShiftRows(j) âŠ•DShiftRows(j) = SubBytes(M 9
j ) âŠ•SubBytes(M 9
j âŠ•e)
(6)
Equation 6 is then solved for the eight possible values of e (the only hypothesis
made on e is that e = 2i for some i). This provides a set of candidates for M 9
j .
At this point, new one-bit fault injections targeting the same byte are required
to reduce the solution set to one item, namely M 9
j . The probability to ï¬nd M 9
j
in three attempts (i.e. three diï¬€erent faults) is â‰ƒ99%.
2 That is: e = 2i for i = 0, . . . , 7.

188
M. Agoyan et al.
K10
ShiftRows(j) is then calculated from M 9
j , using equation 2:
K10
ShiftRows(j) = CShiftRows(i) âŠ•SubBytes(M 9
j )
(7)
Equation 7 shows that the attack works independently on each round key byte.
Indeed, no MixColumns transformation follows the fault injection and MixColumns
is the only transformation capable of propagating faults among bytes. Conse-
quently, the whole round key K10 can be progressively retrieved by the attacker.
Finally, knowing K10, the secret key K is found by reversing the key expansion
algorithm.
3.3
The Attack Process
The experimental set-up (Figure 6) consists in a test chip board (tcb), a clock
fault generator (cfg) and a computer.
The tcb embeds the aes implementation described in the previous section.
Its clock is provided by the cfg. The secret key, the plaintext and the encryption
start signal are transmitted to the tcb from the computer via a serial link. As
encryption ends, the ciphertext is oï¬„oaded via the serial link. The tcb provides
a trigger signal to the cfg indicating the exact beginning of the encryption
process. This is done to ease synchrony between fault injection and aes rounds.
Note that the trigger could be replaced by the inspection of power consumption
(spa) to precisely locate the aes rounds in time.
serial link to PC
serial link to PC
test chip board
(Xilinx Spartan 3)
clock
trigger
clock fault generator
(Xilinx ML 501 board)
Fig. 6. Experimental Set-up

When Clocks Fail: On Critical Paths and Clock Faults
189
The cfg generates a 100 MHz clock signal continuously fed into the tcb.
When the trigger signal indicates that encryption was started, a countdown is
started. As the countdown ends a faulting period is produced during round nine,
as required by Giraudâ€™s one-bit attack. The serial link between the computer and
the cfg is used to deï¬ne the exact value of the faulting period decrement Î”.
The computer runs a test campaign as described in Algorithm 1.
Algorithm 1. Test Campaign Pseudo-Code
send the key K and the plaintext M to the test chip.
Î” â†0.
while (clock period > Î”) do
encrypt and retrieve the ciphertext
Î” â†Î” + Î´t
end while
The generation of a faulting period is automatic and hence not explicitly men-
tioned in the pseudo-code. Indeed, the trigger signal sent from the tcb to the
cfg indicates the encryptionâ€™s launch and causes a faulting period generation
during the ninth round as shown in Figure 4. As the faulting period gradually de-
creases, more set-up time violation faults appear in the calculation process. The
resulting faulty ciphertexts are ordered by decreasing faulting periods. Then,
faulty ciphertexts are successively compared with the correct ciphertext. This
allows identifying the faulty bytes (Eq. 6 and Eq. 7). In addition, for each cipher-
text byte, a list of induced faults is built in order of appearance. Assuming that
the ï¬rst injected fault stems from a one-bit fault induced just before the last
SubBytes, we build the corresponding set of guessed bytes for K10 from equa-
tions 6 and 7. For the test campaign described in Algorithm 1, we obtain a set
of guesses for every byte of K10. To reduce progressively these sets to singletons
we inject diï¬€erent one-bit faults repeating the test campaigns with the same key
but with diï¬€erent plaintexts. Indeed, each data bit arriving to the SubBytesâ€™s
registers possesses its own logic path and propagation time (section 2). This
propagation time highly depends on the data handled during encryption. Con-
sequently, plaintext changes modify all propagation times. As propagation times
vary, the injected one-bit faults diï¬€er with a 7/8 probability at the byte level.
As a result, one needs at least three (and sometimes four) test campaigns
(same key and diï¬€erent plaintexts) to retrieve the entire round key. Finally, K
is obtained by reversing the key expansion process.
3.4
Experimental Results
A ï¬rst experiment targeting the ï¬nal aes round was conducted to test the cfg.
We implemented successfully Giraudâ€™s one-bit attack as well as its extension to
two bits.

190
M. Agoyan et al.
no faults
2 bit faults
1 bit faults
other faults
faulty period (picoseconds)
7585
5485
7235
6885
6535
6185
5835
10
11
12
13
14
15
5
6
7
8
9
0
1
2
3
4
byte index
10
11
12
13
14
15
5
6
7
8
9
0
1
2
3
4
byte index
no faults
2 bit faults
1 bit faults
other faults
7340
5240
6990
6640
6290
5940
5590
faulty period (picoseconds)
Fig. 7. Two fault injection experiments: same key, diï¬€erent plaintexts
Injecting multiple-bit faults. To test the hypothesis that a decrease in the
faulting period causes more internal faults, we targeted the aesâ€™ tenth round
while progressively increasing Î”.
As expected, the comparison of correct and faulty ciphertexts reveals that the
device progressively transits from normal operation to multi-bit faults. This is
done by exhibiting none, one-bit, two-bit and multiple-bit faults as described
in Figure 7. Note that the above is not an attack but an experimental fault
characterization experiment where the aes plays the role of a big propagation
delay cause.
Figure 7 reports fault characterization experiments conducted with a constant
key and two diï¬€erent plaintexts.
Figure 7 shows the faultsâ€™ timing and nature as a function of the faulting
periodâ€™s duration (the horizontal axis). Each horizontal bar, associated with a
byte number, uses a color code to reï¬‚ect the nature of faults (no fault, one-bit
fault, two-bits fault, more than two bits fault) and their point of appearance
in time. The ï¬rst one-bit fault occurs in byte 3 for a faulting period of 7585 ps
(= 10000âˆ’69Ã—35 ps), and the last fault appears on byte 0 for a 5800 ps faulting

When Clocks Fail: On Critical Paths and Clock Faults
191
25
02
DC
45
39
AC
21
E3
18
0B
59
FF
3A
32
54
e1
e3
e4
e2
Fig. 8. Reducing the number of bytes candidates
period. With the exception of bytes 2 and 8, the ï¬rst fault is always a one-bit
fault. This is compatible with the theoretical fault genesis model introduced at
the beginning of this paper. Figure 8 shows how the number of byte candidates
is progressively reduced. Each of the four sets in the example is associated with
a diï¬€erent one-bit fault ei (for i âˆˆ{1, 2, 3, 4}). Here, the correct round key
byte, 0x25, is found at the intersection of sets associated with e1, e3 and e4.
The fact that the set associated with e2 stands apart indicates that the one-
bit fault assumption about e2 was wrong. Leaving aside e2, the set of guesses is
reduced by successive sets intersections until a singleton containing the round key
byte is reached. However, taking into account set e2 requires the more complex
intersection process described in Algorithm 2.
Algorithm 2. Determining the correct key byte
i â†2
S â†e1
while (|S| Ì¸
= 1) do
if S âˆ©ei = âˆ…then
S = S âˆªei
else
S = S âˆ©ei
end if
i â†i + 1
end while
return the single element of S as the correct key byte.
The probability of injecting successively a one-bit and a two-bit fault when
reducing the faulty period can be estimated from Figure 7, where bytes 8, 5, 2 and
0 are counter-examples. Many examples seem to indicate that this probability is
greater than 70% (experimentally).
The probability to cause successively one-bit, two-bit, and three-bit faults
seems to be 50% (experimentally). These statistics were obtained thanks to the

192
M. Agoyan et al.
very small value of the faulty-period granularity, namely 35ps. This resolution
seems to allow the progressive accumulation of faulty propagation paths as the
faulting period is decreased.
Implementation of Giraudâ€™s one-bit attack. We wrote a script that plays
the elementary test campaign described in section 3.3. The test was run several
tens of times, for at least ï¬ve diï¬€erent plaintexts per run. We always found the
correct round key. The probability of injecting one-bit faults was found to be
greater or equal to 90%.
Extension to two-bit attack. The ability to inject and identify two-bit faults
has prompted us to extend the attack. Note that two-bit attacks can defeat one-
bit parity check countermeasures. To that end, we need to solve equation 6 with
the assumption that e is a two-bit fault. The only adverse eï¬€ect is an increase in
the cardinality of potential solution sets. The experiment was successful: 13 to
14 round key bytes were found on average with the automated test campaign.
This allowed to exhaustive-search the whole key.
Repeating the campaign with many diï¬€erent plaintexts, we were always able
to inject two-bit fault at every byte location, even if we never succeeded in
injecting two-bit faults simultaneously on all bytes.
4
Conclusion
This paper describes a new fault injection technique based on clock reshaping
during a precise cycle to cause setup time violation faults. The new technique
would be a good candidate to benchmark safe-error [17] or diï¬€erential behaviorial
[14] analysis.
This technique is inexpensive, eï¬ƒcient and non-intrusive. As such, it under-
lines the importance of further research in countermeasure design.
References
1. Bar-El, H., Choukri, H., Naccache, D., Tunstall, M., Whelan, C.: The sorcererâ€™s
apprentice guide to fault attacks. Special Issue on Cryptography and Security 94(2),
370â€“382 (2006)
2. Biham, E., Shamir, A.: Diï¬€erential fault analysis of secret key cryptosystems. In:
Kaliski Jr., B.S. (ed.) CRYPTO 1997. LNCS, vol. 1294, pp. 513â€“525. Springer,
Heidelberg (1997)
3. Boneth, D., DeMillo, R.A., Lipton, R.J.: On the importance of checking cryp-
tographic protocols for faults. In: Fumy, W. (ed.) EUROCRYPT 1997. LNCS,
vol. 1233, pp. 37â€“51. Springer, Heidelberg (1997)
4. Choukri, H., Tunstall, M.: Round reduction using faults. In: Proc. Second Intâ€™l
Workshop Fault Diagnosis and Tolerance in Cryptography, FDTC 2005 (2005)
5. Daemen, J., Rijmen, V.: Rijndael, Aes proposal (1998)
6. Dusart, P., Letourneux, G., Vivolo, O.: Diï¬€erential fault analysis on aes. In: Zhou,
J., Yung, M., Han, Y. (eds.) ACNS 2003. LNCS, vol. 2846, pp. 293â€“306. Springer,
Heidelberg (2003)

When Clocks Fail: On Critical Paths and Clock Faults
193
7. Fukunaga, T., Takahashi, J.: Practical fault attack on a cryptographic lsi with
iso/iec 18033-3 block ciphers. In: Proc. of the 2009 Workshop on Fault Diagnosis
and Tolerance in Cryptography, FDTC 2009, pp. 84â€“92 (2009)
8. Giraud, C.: DFA on AES. In: Dobbertin, H., Rijmen, V., Sowa, A. (eds.) AES
2005. LNCS, vol. 3373, pp. 27â€“41. Springer, Heidelberg (2005)
9. Guilley, S., Sauvage, L., Danger, J.-L., Selmane, N., Pacalet, R.: Silicon-level solu-
tions to counteract passive and active attacks. In: FDTC 2008: Proceedings of the
2008 5th Workshop on Fault Diagnosis and Tolerance in Cryptography, pp. 3â€“17
(2008)
10. Hutter, M., Schmidt, J.-M.: Optical and em fault-attacks on crt-based rsa: Concrete
results. In: Proceedings of the 15th Austrian Workhop on Microelectronics (2007)
11. NIST. Announcing the Advanced Encryption Standard (AES). Federal Information
Processing Standards Publication No. 197, November 26 (2001)
12. Piret, G., Quisquater, J.-J.: A diï¬€erential fault attack technique against spn struc-
tures, with application to the aes and khazad. In: Walter, C.D., KoÂ¸c, CÂ¸.K., Paar,
C. (eds.) CHES 2003. LNCS, vol. 2779, pp. 77â€“88. Springer, Heidelberg (2003)
13. Quisquater, J.J., Samyde, D.: Eddy current for magnetic analysis with active sen-
sor. In: Proceedings of ESmart 2002, Eurosmart, pp. 185â€“194 (2002)
14. Robisson, B., Manet, P.: Diï¬€erential behavioral analysis. In: Paillier, P., Ver-
bauwhede, I. (eds.) CHES 2007. LNCS, vol. 4727, pp. 413â€“426. Springer, Heidelberg
(2007)
15. Selmane, N., Guilley, S., Danger, J.-L.: Practical setup time violation attacks on
AES. In: EDCC-7 2008: Proceedings of the 2008 Seventh European Dependable
Computing Conference, pp. 91â€“96 (2008)
16. Skorobogatov, S.P., Anderson, R.J.: Optical fault induction attacks. In: Kaliski Jr.,
B.S., KoÂ¸c, CÂ¸.K., Paar, C. (eds.) CHES 2002. LNCS, vol. 2523, pp. 2â€“12. Springer,
Heidelberg (2003)
17. Yen, S.-M., Joye, M.: Checking before output may not be enough against fault-
based cryptanalysis. IEEE Transactions on Computers 49, 967â€“970 (2000)

Modeling Privacy for Oï¬€-Line RFID Systemsâ‹†
Flavio D. Garciaâ‹†â‹†and Peter van Rossum
Institute for Computing and Information Sciences,
Radboud University Nijmegen, The Netherlands
{flaviog,petervr}@cs.ru.nl
Abstract. This paper establishes a novel model for RFID schemes
where readers are not continuously connected to the back oï¬ƒce, but only
periodically. Furthermore, adversaries are not only capable of compro-
mising tags, but also of compromising readers. This more properly mod-
els large scale deployment of RFID technology such as in public transport
ticketing systems and supply-chain management systems. In this model
we deï¬ne notions of security (only legitimate tags can authenticate) and
of privacy (no adversary is capable of tracking legitimate tags). We show
that privacy is always lost at the moment that a reader is compromised
and we develop notions of forward and backward privacy with respect to
reader corruption. This models the property that tags cannot be traced,
under mild additional assumptions, for the time slots before and after
reader corruption. We exhibit two protocols that only use hashing that
achieve these security and privacy notions and give proofs in the random
oracle model.
1
Introduction
During the last decade, the use of RFID technology has expanded enormously.
It is currently deployed in electronic passports, tags for consumer goods, public
transport ticketing systems, race timing, and countless other applications.
The widespread use of RFID has raised privacy concerns. Since most RFID
tags will send a unique identiï¬er to every reader that attempts to communicate
with it, an adversary could build an â€œRFID proï¬leâ€ of an individual, i.e., the
collection of unique identiï¬ers of the RFID tags that the individual usually
carries. This proï¬le could be used to track this person, or to infer behavior such
as spending or traveling patterns, jeopardizing this personâ€™s privacy.
For simple RFID applications (for instance the tagging of products in stores
to enable RFID based cash registers), the privacy problems could be solved
â‹†The work described in this paper has been partially supported by the Euro-
pean Commission through the ICT program under contract ICT-2007-216676
ECRYPT II.
â‹†â‹†Partially supported by the research program Sentinels (www.sentinels.nl), project
PEARL (7639). Sentinels is being ï¬nanced by Technology Foundation STW, the
Netherlands Organization for Scientiï¬c Research (NWO), and the Dutch Ministry
of Economic Aï¬€airs.
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 194â€“208, 2010.
c
âƒIFIP International Federation for Information Processing 2010

Modeling Privacy for Oï¬€-Line RFID Systems
195
by sending the kill-command to the RFID tags (upon leaving the store). This,
however, is useless for situations such as access control, where legitimate readers
need to verify the authenticity of tags.
Various RFID schemes using cryptographic techniques that guarantee both
security (authenticity of accepted tags) and privacy have been proposed. Because
RFID tags are low-cost and low-power devices, they are limited in the type of
cryptography that can be used. In particular, it is not possible to use public key
cryptography in a way that is both cheap and fast enough. Additionally, most
RFID tags are not tamper-resistant and do not have the ability to keep time,
since they lack an independent energy source.
Protocols that have been proposed to achieve both security and privacy are,
among others,OSK/AO[OSK03,AO05],NIBY[NIBY06],andYA-TRAP [Tsu06].
In the literature, RFID schemes are typically modeled as a multi-threaded reader
that enjoys an always-active secure communication channel with the back oï¬ƒce
[JW07, Vau07, Avo05]. Although this approach is simple and practical, it cannot
model several widely deployed RFID systems nowadays.
In practice, in a number of large-scale RFID systems, readers remain oï¬€-line
most of the time and have only periodic connection with the central back oï¬ƒce.
During that connection, the readers and the back oï¬ƒce synchronize. Typical ex-
amples of this conï¬guration are transport ticketing systems such as the London
Oyster card and the Dutch OV-chipkaart, where readers in buses and trains con-
nect to a central database during the night and remain oï¬€-line during the day.
This conï¬guration enforces the migration of sensitive information from the back
oï¬ƒce to the readers, since readers now have to be able to decide by themselves
whether to grant access to a passenger or not, to name an example. This con-
ï¬guration brings new security threats: readers might de-synchronize with other
readers, tags or with the back oï¬ƒce itself. Besides that, if an attacker steals
or tampers with a reader that now contains sensitive information it should not
compromise the security and privacy of the whole system. Concurrently and in-
dependently this issue has also been studied by Avoine et al. in [ALM09]; both
results were presented at RFIDSecâ€™09.
Our contribution. In this paper, we propose to explicitly model the existence of
multiple readers, that, just as tags, can be compromised by the adversary and
their secret information obtained. With respect to tag corruption, we consider a
â€œforwardâ€ notion of privacy: if a tag is corrupted in the future, its past behavior
is still private. With respect to reader corruption, we consider both a â€œforwardâ€
and a â€œbackwardâ€ notion of privacy: if a reader is corrupted in the future, privacy
of past communication should still be guaranteed, but also if some reader has
been corrupted in the past, privacy should still be guaranteed in the future. See
Figures 1 and 2.
Because readers only periodically connect to the back oï¬ƒce, one cannot ex-
pect to retain privacy of tags (or security of the system) at the moment a reader
is destroyed. More precisely, during a time slot (a period between two successive
synchronizations of the whole system) in which a reader gets corrupted, security
and privacy cannot be guaranteed. There is the additional point that tags do

196
F.D. Garcia and P. van Rossum

time

safe
day 9
legitimate
authentication
day 11
day 12
compromised
reader
Fig. 1. Self-stabilizing Forward Privacy
not have an intrinsic notion of time. For forward privacy, since the adversary
can corrupt a reader in the future, privacy is only guaranteed if the last commu-
nication of the tag (before the time slot where reader corruption takes place) is
with a legitimate reader. When there is no reader corruption, this condition is
not necessary and our notion of forward privacy reduces to the standard one.
For backward privacy, note that a corrupted reader will always be able to
communicate with a tag that has not communicated with the system since the
reader corruption took place. It is not until a tag communicates with a legitimate
reader that one can expect to regain privacy guarantees.

time

safe
day 9
day 10
day 12
compromised
reader
legitimate
authentication
Fig. 2. Self-stabilizing Backward Privacy
We formulate three notions of privacy: forward privacy with respect to tag
corruption, self-stabilizing forward privacy with respect to reader destruction,
and self-stabilizing backward privacy with respect to reader destruction. â€œSelf-
stabilizingâ€ refers to the fact that privacy is not immediately guaranteed outside
the time slot where reader destruction takes place, but only after communicating
with a legitimate reader.
As in [Vau07], we consider several classes of adversaries (depending on their
ability to corrupt or destroy tags, destroy readers, or see the result of an authen-
tication protocol between a tag and a reader) and the privacy (and security)
notions are parameterized by the class of adversaries under consideration. We
model the privacy requirements as in [JW07]. An attacker generates two uncor-
rupted tags. Later, he get access to only one of them and has to guess which one
it is. The privacy requirement is that he only guesses correctly with probability
negligibly larger than 1
2. The diï¬€erence between the three privacy notions is ex-
pressed in the diï¬€erent capabilities the adversary has. For privacy with respect to
tag corruption, the adversary cannot destroy readers. For self-stabilizing forward

Modeling Privacy for Oï¬€-Line RFID Systems
197
privacy with respect to reader destruction, the adversary can only corrupt read-
ers after being given access to the challenge tag. For self-stabilizing backward
privacy with respect to reader corruption, it can only corrupt readers before it
is given access to the challenge tag.
Finally, we analyze three protocols. First, because we have slightly modi-
ï¬ed the notion of privacy from the literature combining ideas from [JW07] and
[Vau07], we present a slightly modiï¬ed version of the OSK protocol that obtains
security and privacy with respect to tag corruption. We then describe two other
protocols, using only hashing, that additionally achieve self-stabilizing forward
and backward privacy with respect to reader corruption. In all three cases, we
prove the security and privacy of the scheme in the random oracle model.
Structure of the paper. In Section 2 we formally model an RFID system with
oï¬€-line readers. We model adversaries, as usual, as probabilistic polynomial-time
algorithms that interact with an RFID system by means of oracles. In Section 3,
we deï¬ne the notions of security and privacy, using a game-based approach.
Section 4 describes the three protocols achieving our security and privacy notions
and the proofs in the random oracle model. Finally, Section 5 concludes.
2
System Model
To model this scenario, consider a scheme where readers have a secure commu-
nication channel with the back oï¬ƒce that is only active during synchronization.
We assume that readers are single threaded, i.e., can only have one active pro-
tocol instance with a tag at a time. After running a protocol with a tag, the
reader has an output that is typically the identity of the tag. New readers and
tags can be added to the system at will. The formal deï¬nition follows.
Deï¬nition 2.1 (RFID scheme). An RFID scheme Î  consists of:
â€¢ a probabilistic polynomial-time algorithm SetupSystem that takes as input the
security parameter 1Î· and outputs the public key pair (sk, pk) of the system.
â€¢ a probabilistic polynomial-time algorithm SetupReader that takes as input the
secret key of the system sk and outputs the initial state of the reader s and
the readerâ€™s secret k.
â€¢ a probabilistic polynomial-time algorithm SetupTag that takes as input the
secret key of the system sk and outputs the initial state of the tag s and the
tagâ€™s secret k.
â€¢ a polynomial-time interactive protocol Sync between the readers and the back-
oï¬ƒce.
â€¢ a polynomial-time interactive protocol between a reader and a tag, where the
reader returns Output. Output is typically the identity of the tag.
An adversary is a probabilistic polynomial-time algorithm that interacts with
the system by means of diï¬€erent oracles. The environment keeps track of the
state of each element in the system and answers the oracle queries according to

198
F.D. Garcia and P. van Rossum
the protocol. Besides adding new tags and readers to the system and being able
to communicate with them, an adversary can also corrupt tags. This models
techniques like diï¬€erential power analysis and chip slicing. By corrupting a tag
an adversary retrieves its internal state. Something similar happens with readers,
although in this case we assume that the system can detect that. In the example
of the transport ticketing system we assume that the company would detect if
a bus gets stolen or a missing gate at the metro station. An adversary can also
initiate the synchronization protocol which models waiting until the next time-
period. Additionally, an adversary might be capable of seeing the result of an
authentication attempt by external means, for instance, by looking whether a
door opens or not. The formal deï¬nition of adversary follows.
Deï¬nition 2.2 (Adversary). An adversary is a probabilistic polynomial-time
algorithm that takes as input the system public key pk and has access to the
following oracles:
â€¢ CreateReader(R) creates a new reader by calling SetupReader(sk) and updates
the state of the back-oï¬ƒce. This new reader is referenced as R.
â€¢ DestroyReader(R) destroys reader R and returns its internal state s to the
adversary. After calling DestroyReader, oracle calls with this reference are
no longer valid.
â€¢ CreateTag(T ) creates a new tag T by calling SetupTag(sk) and updates the
state of the back-oï¬ƒce. This new tag is referenced as T .
â€¢ CorruptTag(T ) returns the internal state s of the tag T .
â€¢ Launch(R) attempts to initiate a new protocol instance at reader R. If R
has already an active protocol instance then Launch fails and returns zero.
Otherwise it starts a new protocol instance and returns one.
â€¢ Send(m, A) sends a message m to the entity A and returns its response mâ€².
The entity A can either be a reader R or a tag T .
â€¢ Result(R) outputs whether or not the output of the last ï¬nished protocol
instance at reader R is not âŠ¥, i.e., Output Ì¸
= âŠ¥.
â€¢ Sync() initiates the interactive protocol Sync between the readers and the
back-oï¬ƒce.
Deï¬nition 2.3. We denote by O the set of oracles {CreateReader, CreateTag,
CorruptTag, Launch, Send, Sync, Result} and O+ = O âˆª{DestroyReader}.
3
Security Deï¬nitions
This section elaborates on the security and privacy deï¬nitions from the litera-
ture, adapting them to our model. Then, it also discusses (when applicable) the
relations among them.
The main goal of an RFID system is security, which means that readers are
able to authenticate legitimate tags. Throughout this paper we focus on privacy.
For the sake of self containment, we include here the following security deï¬nition
which is an adapted version of the security deï¬nition proposed in [Vau07].

Modeling Privacy for Oï¬€-Line RFID Systems
199
Deï¬nition 3.1 (Security). An RFID scheme is secure if for all adversaries A
and for all readers R, the probability that R outputs the identity of a legitimate
tag while the last ï¬nished protocol instance at reader R and this tag did not have
any matching conversation, is a negligible function of Î·. Matching conversation
here means that R and the tag (successfully) executed the authentication protocol.
Next we deï¬ne privacy with respect to tag corruption. We compose the deï¬ni-
tions of Juels and Weis [JW07] and Vaudenay [Vau07] since each of them has its
advantages: the former is indistinguishability based, which makes it more prac-
tical; the latter has the drawback of being simulation based but is stronger and
allows for a variety of adversaries with custom capabilities. Privacy is deï¬ned in
an IND-CCA like fashion where the adversary tries to win the privacy game. In
this game, the environment creates system parameters by calling SetupSystem.
Then it gives the public key of the system pk to the adversary A0. This adversary
has access to the set of oracles O. Eventually, A0 must output two uncorrupted
challenge tags T â‹†
0 and T â‹†
1 . Then, the environment chooses a random bit b and
gives the adversary A1 access to T â‹†
b . At this point, the original references to T â‹†
0
and T â‹†
1 are no longer valid. Again, the adversary has access to all oracles O.
Finally, the adversary outputs a guess bit bâ€². The adversary wins the game if
b = bâ€². The formal deï¬nition follows.
Deï¬nition 3.2 (Privacy game)
Priv-GameÎ ,A(Î·) :
(sk, pk) â†SetupSystem(1Î·)
T â‹†
0 , T â‹†
1 â†AO
0 (pk)
b â†{0, 1}
bâ€² â†AO
1 (T â‹†
b )
winif if b = bâ€².
The challenge tags T â‹†
0
and T â‹†
1
must be uncorrupted, which means that no
CorruptTag(T â‹†
{0,1}) query has been made. Adversaries implicitly pass state.
In general, it is hard to deï¬ne a realistic adversarial model as diï¬€erent applica-
tions have diï¬€erent requirements. Following the lines of Vaudenay [Vau07], we
consider diï¬€erent classes of adversaries depending on their capabilities. The no-
tions of forward, weak and narrow adversaries are due to Vaudenay. Intuitively,
a forward adversary is an adversary that observes communication between tags
and readers and later on acquires one of these tags and tries to link it with some
of the past sessions, compromising its privacy. If the adversary succeeds to do
so, with non-negligible probability, we say that is a winning adversary. A weak
adversary is an adversary that is unable to corrupt tags. In real life scenarios it
is often realistic to assume that an adversary can see the outcome of an authen-
tication attempt. For instance, this is the case of transport ticketing systems
where an adversary could observe whether the gate of the metro opens or not,
for a speciï¬c tag. An adversary that is unable to do so is called narrow.
We introduce the notion of reader-destructive adversary which is a forward
adversary, additionally empowered with a DestroyReader oracle.

200
F.D. Garcia and P. van Rossum
Deï¬nition 3.3 (Types of adversaries). An adversary who has access to all
oracles O is called forward. Note that A1 is allowed to perform CorruptTag
queries on T â‹†
b . An adversary is called weak if it does not perform any CorruptTag
query. An adversary is called narrow if it does not perform any Result query. An
adversary is called
reader-destructive if it additionally
has access to a
DestroyReader oracle.
Remark 3.4. Note that this notion of forward adversary is stronger than the one
proposed by Vaudenay and closer to the notion of Juels and Weis.
Deï¬nition 3.5 (Privacy). Let C be a class of adversaries in {forward, weak,
narrow}. An RFID scheme is said to be C-private if for all probabilistic polyno-
mial-time adversaries A = (A0, A1) âˆˆC
P[Priv-GameÎ ,A(Î·)] âˆ’1/2
is a negligible function of Î·.
Next, we want to generalize this privacy deï¬nition to the oï¬€-line setting, where
readers can be subdued. A ï¬rst attempt would be to take Deï¬nition 3.5 and
additionally empower the adversary with a DestroyReader oracle. Unfortunately,
the resulting deï¬nition is not achievable since the following adversary wins the
privacy game with probability one, regardless of the particular scheme.
AO+
0
(pk):
CreateReader(R)
CreateTag(T â‹†
0 )
CreateTag(T â‹†
1 )
Sync()
s â†DestroyReader(R)
id â†Execute(s, T â‹†
0 )
return T â‹†
0 , T â‹†
1
AO+
1
(T â‹†
b ):
if id = Execute(s, T â‹†
b ) then return 0
else return 1
where Execute(s, T ) runs the authentication protocol with tag T using s as the
internal state of the reader.
A setup with oï¬€-line readers is inherently insecure during the time-period
where reader destruction takes place. The following deï¬nition captures the notion
of self-stabilizing forward privacy with respect to reader destruction. Intuitively,
is the same deï¬nition as before. However, before reader destruction takes place,
we must guarantee that readers and tags have the same notion of time. This is
achieved by having the tags communicate with a legitimate reader followed by
a Sync, without the adversary interfering. This means that once the time moves
forward, the privacy of past sessions is ensured, even if the adversary retrieves
the internal state of a reader, see Figure 3.

Modeling Privacy for Oï¬€-Line RFID Systems
201
Deï¬nition 3.6 (Self-stabilizing forward privacy game)
SS-Fwd-Priv-GameÎ ,A(Î·) :
(sk, pk) â†SetupSystem(1Î·)
T â‹†
0 , T â‹†
1 â†AO
0 (pk)
b â†{0, 1}
Râ‹†
0, Râ‹†
1 â†AO
1 (T â‹†
b )
Execute(Râ‹†
0, T â‹†
0 )
Execute(Râ‹†
1, T â‹†
1 )
Sync()
bâ€² â†AO+
2
(T â‹†
b )
winif if b = bâ€².
where Execute(R, T ) runs the authentication protocol between the reader R and
the tag T . The challenge tags T â‹†
0 and T â‹†
1 must be uncorrupted, which means that
no CorruptTag(T â‹†
{0,1}) query has been made. Adversaries implicitly pass state.

time

safe
Sync()
Execute() Sync()
Sync()
DestroyReader()
Fig. 3. Self-stabilizing Forward Privacy
Deï¬nition 3.7 (Self-stabilizing forward privacy). Let C be a class of ad-
versaries in {forward, weak, narrow, reader-destructive}. An RFID scheme is
said to be C-forward private w.r.t. tag corruption and reader destruction if for
all probabilistic polynomial-time adversaries A = (A0, A1, A2) âˆˆC
P[SS-Fwd-Priv-GameÎ ,A(Î·)] âˆ’1/2
is a negligible function of Î·.
Theorem 3.8. Let Î  be a self-stabilizing forward private RFID system. Then,
Î  is private with respect to Deï¬nition 3.5.
Proof. By inspection. Note that the games are the same up to the Execute call.
The new adversary just has extra power, namely, the distinguishing capability of
AO+
2
, i.e., a winning adversary against Priv-Game is also a winning adversary
against SS-Fwd-Priv-Game, where A2 just outputs the bit b chosen by A1.
âŠ“âŠ”
Next we introduce the notion of backward privacy with respect to reader de-
struction. Backward privacy is the time-transposed analogy of forward privacy,
see Figure 4. Therefore, the same limitations on privacy during the time-period

202
F.D. Garcia and P. van Rossum

time

safe
Sync()
Sync()
Sync()
DestroyReader()
Execute()
Fig. 4. Self-stabilizing Backward Privacy
where reader destruction takes place still apply. Moreover, since tags lack a tim-
ing device, the lapse extends beyond the compromised time slot. From the tagâ€™s
perspective it is impossible to know that time has passed and therefore when
an attacker interacts ï¬rst with the tag during a later time slot, the tag is in an
inherently insecure situation. In such a situation, the best one can hope for is
that the tag gets back to a secure state (it self-stabilizes) after interacting with
a legitimate reader. The following security deï¬nition captures this notion.
Deï¬nition 3.9 (Self-stabilizing backward privacy game)
SS-Back-Priv-GameÎ ,A(Î·) :
(sk, pk) â†SetupSystem(1Î·)
T â‹†
0 , T â‹†
1 â†AO+
0
(pk)
Sync()
Râ‹†â†AO
1 ()
b â†{0, 1}
Execute(Râ‹†, T â‹†
b )
bâ€² â†AO
2 (T â‹†
b )
winif if b = bâ€².
The challenge tags (T â‹†
0 and T â‹†
1 ) must be uncorrupted, i.e., no CorruptTag(T â‹†
{0,1})
query has been made. Adversaries implicitly pass state.
Deï¬nition 3.10 (Self-stabilizing backward privacy). Let C be a class of
adversaries in {forward, weak, narrow, reader-destructive}. An RFID scheme is
said to be C-self-stabilizing backward private w.r.t. tag corruption and reader
destruction if for all probabilistic polynomial-time adversaries A = (A0, A1, A2)
âˆˆC
P[SS-Back-Priv-GameÎ ,A(Î·)] âˆ’1/2
is a negligible function of Î·.
4
Protocol Description
In this section we ï¬rst recall a slightly modiï¬ed version of the OSK proto-
col [OSK03] and prove it narrow-forward private in the random oracle model,
as a proof-of-concept. Then, we propose two new protocols that achieve self-
stabilizing forward and backward privacy. Both security proves are in the random
oracle model.

Modeling Privacy for Oï¬€-Line RFID Systems
203
4.1
The OSK Protocol
The modiï¬ed version of the OSK protocol is depicted in Figure 5. The protocol
uses two hash functions f and g. The state of the tag consists of a symmetric
key k that gets hashed with every authentication attempt. The reader has a
table T consisting of pairs of tag identities id and keys k. When the reader gets
an answer c to a challenge n, it will search in T for any matching key, and will
literately hash the keys when no match is found.
T
R
state: k
state: T = [id, k]
0
n â†{0, 1}l
1
n
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
2
c â†h(k, n)
3
k â†g(k)
4
c
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
5
âˆƒ(id, k) âˆˆT, i < t: h(gi(k), n) = c
6
then k â†gi(k); return T
7
else return âŠ¥
Fig. 5. Slightly modiï¬ed version of the OSK protocol
Theorem 4.1. The modiï¬ed version of the OSK protocol depicted in Fig. 5 is
narrow-forward private in the random oracle model.
Proof. Suppose that there is an adversary A = (A0, A1) that wins the Priv-
Game with non-negligible probability. Then we build the following simulator
S. S initializes the system and then runs the adversary A0 simulating all oracle
calls. The random oracle H is simulated as usual by having a table TH storing
previous queries and answers. Eventually A0 ï¬nishes and outputs tags (T â‹†
0 , T â‹†
1 ).
Let k0, k1 be respectively the secret of T â‹†
0 and T â‹†
1 . As in the game, S will draw
a random bit b. Next, S runs AO
1 (T â‹†
b ) which eventually outputs a guess bit bâ€².
By hypothesis we get that bâ€² = b with probability signiï¬cantly higher than 1/2.
Now T rewinds the adversary A1 until it performs the ï¬rst call to the random
oracle H of the form k0, m or k1, mâ€². Then runs AO
1 (T â‹†
1âˆ’b) and swaps in TH all
occurrences of k0 and k1. By hypothesis we get that A1 outputs bâ€² = 1 âˆ’b with
probability signiï¬cantly higher than 1/2. Since A1 is narrow, its view is exactly
the same as in the previous run, which leads to a contradiction.
âŠ“âŠ”
4.2
A Self-stabilizing Private Protocol
Figure 6 depicts our protocol for self-stabilizing forward and backward privacy.
The core of the protocol is the OSK protocol plus some modiï¬cations for back-
ward privacy. The state of the tag consists of two keys k and kâ€². Intuitively, the
former key is used for communication with the readers and the latter is used for
(indirect) communication with the back oï¬ƒce. The state of the reader includes

204
F.D. Garcia and P. van Rossum
T
R
state: k, kâ€²
state: T = [id, k, Ëœk, h(kâ€², C0), u]
0
n â†{0, 1}l
1
n
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
2
c â†h(k, n)
3
k â†h(k)
4
c
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
5
âˆƒk âˆˆT, i â‰¤N : h(hi(k), n) = c
6
then m â†h(hi+1(k), h(kâ€², C0))
7
u â†1
8
âˆƒËœk âˆˆT, i â‰¤N : h(hi(Ëœk), n) = c
9
then m â†{0, 1}l
10
Ëœk â†hi+1(Ëœk)
11
otherwise m â†{0, 1}l
12
m
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
13 if h(k, h(kâ€², C0)) = m
14 then k â†h(kâ€² + 1)
15
kâ€² â†h(kâ€²)
Fig. 6. Self-stabilizing Forward and Backward Private Protocol
a table T consisting of a tag identity id; the last-known key k; the ï¬st-key-of-
the-day Ëœk; a MAC h(kâ€², C0) and a bit u that tells whether or not the tag has
authenticated during the current time period. The MAC constitutes a proof of
knowledge of kâ€² and C0 is a system-wide constant.
The Sync() protocol gathers the tables TR from each reader R. Then it com-
putes, for each tag, the latest key k used. If there is a table TR for which u = 1
then it sets u â†0, Ëœk â†h(kâ€²+1) and it updates kâ€² in the back oï¬ƒce by computing
kâ€² â†h(kâ€²). Finally, it distributes the updated tables to all readers.
Theorem 4.2. The protocol depicted in Fig. 6 is narrow self-stabilizing forward
private in the random oracle model.
Proof. Suppose that there is an adversary A = (A0, A1, A2) that wins the SS-
Fwd-Priv-Game with non-negligible probability. We build the following simu-
lator S. S ï¬rst creates system parameters by calling (sk, pk) â†SetupSystem(1Î·).
Then, it proceeds as in the SS-Fwd-Priv-Game, invoking A when speciï¬ed.
Again, the random oracle H is simulated by having a table TH storing previous
query-answer pairs. At some point A0 outputs challenge tags T â‹†
0 and T â‹†
1 . Let
tâ€ 
0 and tâ€ 
1 be respectively the time when T â‹†
0 and T â‹†
1 initiated the last successful
authentication, see Figure 7.
Deï¬ne kâ€ 
i , kâ€²â€ 
i as the secret keys of T â‹†
i at time tâ€ 
i, for i = 0, 1. Let tâ€¡
i be the time
of the last Sync call before tâ€ 
i and let kâ€¡
i , kâ€²â€¡
i be the secret keys of T â‹†
i at time tâ€¡
i,
for i = 0, 1. Next S will rewind the adversary A0 and resume its execution with a
modiï¬ed random oracle Ëœh. Ëœh is deï¬ned as h, except for the following four points:
Ëœh(kâ€²â€¡
i ) := h(kâ€²â€¡
1âˆ’i) and Ëœh(kâ€ 
i ) := h(kâ€ 
1âˆ’i) for i = 0, 1. Note that this modiï¬cation

Modeling Privacy for Oï¬€-Line RFID Systems
205

time
Sync()
tâ€¡
0
Sync()
tâ€¡
1
T â‹†
0 T â‹†
1 Â· Â· Â· T â‹†
1
T â‹†
0
tâ€ 
0
T â‹†
1
T â‹†
1
tâ€ 
1
T â‹†
b
Execute() Sync()
Fig. 7. Timeline of events
does not aï¬€ect the view of A0 but with negligible probability. Next, S calls
AO
1 (T â‹†
1âˆ’b). Note that T â‹†
1âˆ’b has exactly the same state that T â‹†
b had in the previous
execution of AO
1 , therefore the view of A1 remains unchanged. Finally, S calls
Execute(Râ‹†
0, T â‹†
0 ), Execute(Râ‹†
1, T â‹†
1 ) and Sync() followed by AO+
2
(T â‹†
1âˆ’b). It remains
to show that DestroyReader calls do not change the view of the adversary. This is
easy to see since the internal state of tags and readers at any time are the same,
with exception of h(kâ€¡
i ) and h(kâ€²â€¡
i ). For example, the information on the readers
about T â‹†
i
at time max(tâ€¡
0, tâ€¡
1) is idi, k = h(kâ€ 
i ), Ëœk = h(h(kâ€²â€¡
i ) + 1), h(kâ€²â€¡
i , Ëœd), 0 in
one view, and id1âˆ’i, k = h(kâ€ 
i ), Ëœk = h(h(kâ€²â€¡
i ) + 1), h(kâ€²â€¡
i , Ëœd), 0 in the other. But
this is not a problem since the adversary never has access to these values, due
to the fact that the Execute and Sync calls destroy this information.
Note that since A is narrow, it does not have access to a Result oracle.
This time, A must output 1 âˆ’b with probability signiï¬cantly higher than 1/2
but since its views are indistinguishable, this leads to a contradiction.
âŠ“âŠ”
Theorem 4.3. The protocol depicted in Fig. 6 is narrow self-stabilizing back-
ward private in the random oracle model.
Proof. The main idea of the proof is similar to the one of Theorem 4.2. Suppose
that there is an adversary A = (A0, A1, A2) that wins the SS-Back-Priv-Game
with non-negligible probability. As before, we build the following simulator S.
S ï¬rst creates system parameters by calling (sk, pk) â†SetupSystem(1Î·). Then,
it proceeds as in the SS-Back-Priv-Game, invoking A when speciï¬ed. Again,
the random oracle H is simulated by having a table TH storing previous query-
answer pairs. At some point A0 outputs challenge tags T â‹†
0 and T â‹†
1 . Let tâ€ 
i be
the time when T â‹†
i
initiated the last successful authentication, for i = 0, 1, see
Figure 8.
Let tâ€¡
i be the time of the last Sync call before tâ€ 
i and let kâ€¡
i , kâ€²â€¡
i be the secret
keys of T â‹†
i
at time tâ€¡
i, for i = 0, 1. Next S will rewind the adversary A0 and

time
Sync()
tâ€¡
0
Sync()
tâ€¡
1
T â‹†
0 T â‹†
1 Â· Â· Â· T â‹†
1
T â‹†
0
tâ€ 
0
T â‹†
1
T â‹†
1
tâ€ 
1
Sync() T â‹†
b
Fig. 8. Timeline of events

206
F.D. Garcia and P. van Rossum
resume its execution with a modiï¬ed random oracle Ëœh deï¬ned as h except for
the points Ëœh(kâ€²â€¡
0 ) := h(kâ€²â€¡
1 ) and Ëœh(kâ€²â€¡
1 ) := h(kâ€²â€¡
0 ). Note that this modiï¬cation does
not aï¬€ect the view of A0 but with negligible probability. Next, S calls Sync()
and then AO
1 (), which does not have access to either T â‹†
0
or T â‹†
1 . Eventually
A1 outputs a reader Râ‹†and then S runs Execute(Râ‹†, T â‹†
1âˆ’b). Finally, S calls
AO
2 (T â‹†
1âˆ’b). Note that T â‹†
1âˆ’b has exactly the same state that T â‹†
b in the previous
execution of A2 and therefore the view of A2 remains unchanged. This time, A
must output 1 âˆ’b with probability signiï¬cantly higher than 1/2 but since its
views are indistinguishable, this leads to a contradiction.
âŠ“âŠ”
Remark 4.4. This protocol suï¬€ers from de-synchronization when reader corrup-
tion has taken place.An adversary can use the data from a corrupted reader to
move forward the key kâ€² both in a tag or in the back oï¬ƒce. Throughout this pa-
per we focus on privacy and the purpose of this protocol is to show achievability
of our privacy notions. In this protocol there is still a trade-oï¬€possible between
de-synchronization resistance and privacy. The reader could additionally store
the keys Ëœk from adjacent time-slots. This, of course, extends the unsafe window
from one to three time slots but it allows re-synchronization.
T
R
state: k, kâ€²
state: T = [id, k, Ëœk, h(kâ€², C0), u]
0
n â†{0, 1}l
1
n
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
2
c â†h(k, n)
3
k â†h(k)
4
c
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
5
âˆƒk âˆˆT, i â‰¤N : h(hi(k), n) = c
6
then m â†h(hi+1(k), h(kâ€², C0))
7
ï¬‚ag â†true
8
âˆƒËœk âˆˆT, i â‰¤N : h(hi(Ëœk), n) = c
9
then m â†{0, 1}l
10
Ëœk â†hi+1(Ëœk)
11
otherwise m â†{0, 1}l
12
m
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
13 if h(k, h(kâ€², C0)) = m
14 then k â†h(kâ€² + 1)
15
kâ€² â†h(kâ€²)
16 câ€² â†h(k, n)
17 k â†h(k)
18
câ€²
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
19
if ï¬‚ag and h(Ëœk, n) = câ€²
20
then update kâ€² in BO (u â†1)
Fig. 9. Improved Self-stabilizing Forward and Backward Private Protocol

Modeling Privacy for Oï¬€-Line RFID Systems
207
T
R
state: k, kâ€²
state: T = [id, k, Ëœk, h(kâ€², b), t]
0
n â†{0, 1}l
1
n
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
2
c â†h(k, n)
3
k â†h(k)
4
c
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
5
âˆƒk âˆˆT, i â‰¤N : h(hi(k), n) = c
6
then m â†h(hi+1(k), h(kâ€², b))
7
output id
8
âˆƒËœk âˆˆT, i â‰¤N : h(hi(Ëœk), n) = c
9
then m â†{0, 1}l
10
output id
11
otherwise m â†{0, 1}l
12
output âŠ¥
13
m
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
14 if h(k, h(kâ€², b)) = m
15 then k â†h(kâ€², b + 2)
16
kâ€² â†h(kâ€²)
17 t â†h(kâ€², k, 4)
18
t
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
19
store t for the BO
On the time slots where reader destruction has taken place, the back
oï¬ƒce does not update any key.
Fig. 10. Improved Self-stabilizing Forward and Backward Private Protocol
4.3
Improving Synchronization
Figure 10 depicts an improved version of the protocol from Section 4.2. By adding
a second authentication it is possible to address the de-synchronization issue ex-
posed in Remark 4.4. This allows the reader to verify whether or not the key update
has been successful and only report successful key updates to the back oï¬ƒce.
Theorem 4.5. The protocol depicted in Fig. 10 is narrow self-stabilizing for-
ward and backward private in the random oracle model.
Proof. The proof closely follows the lines of the ones of Theorems 4.2 and 4.3.
Note that authenticating twice does not compromise privacy, otherwise that
would be a valid attack against the protocol from Section 4.2, contradicting
Theorem 4.2 or 4.3.
âŠ“âŠ”
5
Conclusions
We have proposed a new model for RFID privacy that considers oï¬€-line systems
and the potential threat of reader subversion. We have elaborated on the pri-
vacy notions from the literature and adapted the standard notions of forward

208
F.D. Garcia and P. van Rossum
and backward security to this setting. We have shown that the straightforward
generalization is unachievable. We have proposed the notions of self-stabilizing
forward and backward privacy, which are the strongest one can expect to attain.
We have designed two authentication protocols that achieve self-stabilizing
forward and backward privacy. We have proven the security of these protocols
in the random oracle model. This protocols use only a hash function as a cryp-
tographic primitive, which makes it suitable to be implemented using some of
the many lightweight functions proposed in the literature [Sha08, PHER07].
References
[ALM09]
Avoine, G., Lauradoux, C., Martin, T.: When Compromised Readers Meet
RFID. In: Youm, H.Y., Jang, J. (eds.) WISA 2009. LNCS, vol. 5932, pp.
36â€“50. Springer, Heidelberg (2009)
[AO05]
Avoine, G., Oechslin, P.: RFID Traceability: A Multilayer Problem. In:
S. Patrick, A., Yung, M. (eds.) FC 2005. LNCS, vol. 3570, pp. 125â€“140.
Springer, Heidelberg (2005)
[Avo05]
Avoine, G.: Adversary Model for Radio Frequency Identiï¬cation. Techni-
cal Report LASEC-REPORT-2005-001, Swiss Federal Institute of Technol-
ogy (EPFL), Security and Cryptography Laboratory (LASEC), Lausanne,
Switzerland (September 2005)
[JW07]
Juels, A., Weis, S.: Deï¬ning Strong Privacy for RFID. In: International
Conference on Pervasive Computing and Communications â€“ PerCom 2007,
New York City, New York, USA, pp. 342â€“347. IEEE Computer Society
Press, Los Alamitos (2007)
[NIBY06]
Nohara, Y., Inoue, S., Baba, K., Yasuura, H.: Quantitative Evaluation of
Unlinkable ID Matching Schemes. In: Workshop on Privacy in the Elec-
tronic Society â€“ WPES, Alexandria, Virginia, USA, pp. 55â€“60. ACM Press,
New York (2006)
[OSK03]
Ohkubo, M., Suzuki, K., Kinoshita, S.: Cryptographic Approach to
â€œPrivacy-Friendlyâ€ Tags. In: RFID Privacy Workshop. MIT, Massachusetts
(2003)
[PHER07] Peris-Lopez, P., Hernandez-Castro, J.C., Estevez-Tapiador, J.M., Rib-
agorda, A.: An eï¬ƒcient authentication protocol for rï¬d systems resistant
to active attacks. In: Denko, M.K., Shih, C.-s., Li, K.-C., Tsao, S.-L., Zeng,
Q.-A., Park, S.H., Ko, Y.-B., Hung, S.-H., Park, J.-H. (eds.) EUC-WS 2007.
LNCS, vol. 4809, pp. 781â€“794. Springer, Heidelberg (2007)
[Sha08]
Shamir, A.: SQUASH - A New MAC With Provable Security Properties for
Highly Constrained Devices Such as RFID Tags. In: Nyberg, K. (ed.) FSE
2008. LNCS, vol. 5086, pp. 144â€“157. Springer, Heidelberg (2008)
[Tsu06]
Tsudik, G.: YA-TRAP: Yet Another Trivial RFID Authentication Protocol.
In: International Conference on Pervasive Computing and Communications
â€“ PerCom 2006, Pisa, Italy. IEEE Computer Society Press, Los Alamitos
(March 2006)
[Vau07]
Vaudenay, S.: On Privacy Models for RFID. In: Kurosawa, K. (ed.)
ASIACRYPT 2007. LNCS, vol. 4833, pp. 68â€“87. Springer, Heidelberg (2007)

Developing Eï¬ƒcient Blinded Attribute
Certiï¬cates on Smart Cards via Pairings
Lejla Batina1, Jaap-Henk Hoepman1,2, Bart Jacobs1,
Wojciech Mostowski1,â‹†, and Pim Vullers1,â‹†â‹†
1 Institute for Computing and Information Sciences,
Radboud University Nijmegen, The Netherlands
{lejla,jhh,bart,woj,p.vullers}@cs.ru.nl
2 TNO Information and Communication Technology, The Netherlands
jaap-henk.hoepman@tno.nl
Abstract. This paper describes an elementary protocol to prove pos-
session of anonymous credentials together with its implementation on
smart cards. The protocol uses self-blindable attribute certiï¬cates rep-
resented as points on an elliptic curve (which are stored on the card).
These certiï¬cates are veriï¬ed on the reader-side via a bilinear pairing.
Java Card smart cards oï¬€er only very limited access to the crypto-
graphic coprocessor. It thus requires some ingenuity to get the protocol
running with reasonable speed. We realise protocol runs with on-card
computation times in the order of 1.5 seconds. It should be possible to
further reduce this time with extended access to the cryptographic co-
processor.
Keywords: anonymous credentials, elliptic curve cryptography, smart
card, bilinear pairing, attributes, blinding, protocols, Java Card.
1
Introduction
With the growing use of smart cards in e-ticketing in public transport, huge
centralised databases are compiled with detailed travel information of individual
citizens. This raises considerable privacy and security concerns [14]. It leads to
a renewed interest in anonymous credential systems, oï¬€ering attribute-based
authorisation. With such system a smart card may be personalised, but does
not show its identity on entry into a public transport system. Instead it shows
an attribute â€” such as â€œï¬rst class train pass valid in December 2009â€ â€” together
with a signature on the public key of the card that is linked to this attribute.
The corresponding private key is assumed to be stored in protected hardware
in the card, inaccessible from the outside. We assume the attribute to be fairly
general, and not identifying individual cards/people. The signature, however, is
speciï¬c, and may be used for tracing. Therefore we are interested in self-blindable
signatures as proposed by Verheul [25].
â‹†Sponsored by the NLnet foundation through the OV-chipkaart project.
â‹†â‹†Sponsored by Trans Link Systems/Open Ticketing.
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 209â€“222, 2010.
c
âƒIFIP International Federation for Information Processing 2010

210
L. Batina et al.
Other credential systems exist, see for instance [5,6,8]. They typically require
non-trivial computational resources, such that implementing them on smart
cards is a serious challenge, see for example [12,21,23]. Of these Danes [12] imple-
ments idemix [8] zero knowledge proofs on smart cards, with running times in the
order of tens of seconds; Sterckx et al. [21] implement direct anonymous attes-
tation [6] with running times under 3 seconds; Tews and Jacobs [23] describe an
implementation of Brandsâ€™ selective disclosure protocols [5], with running times
around 5 seconds. All quoted times refer to the execution time on a smart card.
This paper distinguishes itself through its use of elliptic curve cryptography
(ECC). It does so for two (main) reasons.
â€“ ECC supports small key and certiï¬cate lengths â€” compared to RSA â€” and
thus reduces the time and bandwidth needed for transfer (of public keys
between card and terminal) and for blinding (via modular multiplication of
big natural numbers).
â€“ ECC supports a form of signature via bilinear pairings [20] which is stable
under blinding [25].
Actual use of ECC on smart cards is relatively new. The major deployment is
probably in the latest generation of European e-passports, using Extended Ac-
cess Control to protect ï¬nger prints [7]. Java Card generation 2.2 smart cards
oï¬€er support for ECC, through the cryptographic coprocessor, basically via only
two primitives, namely Diï¬ƒe-Hellman key agreement (ECDH) and Digital Sig-
nature Algorithm (ECDSA). This is barely enough to implement our protocol
on a card eï¬ƒciently. Crucial in our implementation are the following two points.
â€“ We abuse ECDH to perform point multiplication (repeated addition, or in-
teger scalar multiplication) on the card. Diï¬ƒe-Hellman does such a multipli-
cation implicitly, however, it only returns the x-coordinate of the resulting
(multiplied) point. In principle, we have to reconstruct the corresponding y-
coordinate (on the reader-side) by taking a square root, and checking which
version (positive or negative) is the right one. However, we show how this
reconstruction can be partially avoided via some tricks (see Section 4.2).
â€“ Modular multiplication of two (big) natural numbers is not supported, that
is, the Java Card API does not provide access to this operation on the cardâ€™s
cryptographic coprocessor. Therefore we use our own implementation in Java
Card, which leads to a signiï¬cant slow down. It can be mitigated by reducing
the number of bits in the blinding factor, for instance from 192 to 96 (or even
to 48).
The main contributions of this work are as follows.
â€“ A new protocol for anonymous credentials is described that can be used for
various applications which require smart cards, in particular e-ticketing.
â€“ An implementation of this protocol, via several optimisations, on an ordinary
Java Card, using bilinear pairings on elliptic curves on the terminal-side.
â€“ A running time on the card in the order of 1.5 seconds.

Developing Eï¬ƒcient Blinded Attribute Certiï¬cates
211
Our results show that anonymous credentials on smart cards are becoming fea-
sible. Also, they show that increasing access to the cryptographic coprocessor
may increase the number of applications of advanced smart cards. Hopefully this
perspective stimulates card manufacturers.
This paper is organised as follows. In Section 2 an overview of elliptic curve
cryptography and pairings is given. These techniques are used for the protocol
given in Section 3. Finally, Section 4 describes the implementation details and
gives an indication of times needed for protocol runs, with a number of diï¬€erent
parameters.
2
Elliptic Curves and Pairings
In this section we introduce some notation and we give an overview of the math-
ematical background of elliptic curves and pairings. The ï¬nite ï¬eld containing q
elements, where q is a prime power, is denoted by Fq. An elliptic curve E over
Fq is the set of all solutions, that is, all the points P = (x, y) satisfying the
following equation
E : y2 = x3 + ax + b,
(1)
where a, b âˆˆFq and 4a3 + 27b2 Ì¸
= 0, together with a special point âˆcalled the
point at inï¬nity. The set of points P âˆˆFq
2 on the curve is sometimes written
as E(Fq).
Here, a and b are called the curve parameters. The ï¬eld Fq is of the form Fpn
for some prime number p and n âˆˆN (p Ì¸
= 2, 3). The solutions of equation (1)
form an abelian group with point addition as the group operation and the point
at inï¬nity as the zero-element. The condition 4a3 +27b2 Ì¸
= 0 is required for E to
be non-singular, as required for cryptographic applications. For cryptography we
need a ï¬nite cyclic group in which the group operation is eï¬ƒciently computable,
but the discrete logarithm problem is very diï¬ƒcult to solve. Elliptic curve groups
meet these criteria when the underlying ï¬eld is ï¬nite and p is at least 160 bits.
We write n Â· P, with scalar n âˆˆZ, for repeated group operation, that is, the
point addition. Let E be an elliptic curve over Fq and let P âˆˆE be a point of
order k. Let Q âˆˆâŸ¨PâŸ©be a point generated by P, that is, Q = Î± Â· P for Î± where
0 â‰¤Î± < k. The problem of ï¬nding the logarithm Î± for given P and Q is called
the elliptic curve discrete logarithm problem (ECDLP).
As mentioned above, we are using bilinear pairings on elliptic curves for our
protocol. Therefore, a so-called pairing friendly elliptic curve is required, that is,
a curve with a small embedding degree and large prime-order subgroup. In 2005,
Barreto and Naehrig (BN) discovered a new method for constructing pairing
friendly elliptic curves of prime order over a prime ï¬eld [1]. More precisely, BN
curves are deï¬ned over Fp where p = p(u) = 36u4+36u3+24u2+6u+1 for u âˆˆZ
such that p is prime. The order of a BN curve is a prime n where n = n(u) =
36u4 + 36u3 + 18u2 + 6u + 1. Hence, a BN curve is constructed by generating
integers u until both p(u) and n(u) are prime numbers. The embedding degree
of BN curves is 12 and we detail the parameters for our case in Section 4.3.

212
L. Batina et al.
2.1
DH and DSA for Elliptic Curves
The Diï¬ƒe-Hellman key agreement protocol (DH) and the Digital Signature Al-
gorithm (DSA) are easily adapted to the ECC case as in [2] and [15] respectively.
We recall the protocols, which in this case are called ECDH and ECDSA.
EC Diï¬ƒe-Hellman Key Agreement (ECDH). Alice (A) and Bob (B) wish
to agree on a secret key over an insecure channel. They ï¬rst agree on the set of
domain parameters (Fq, E, n, h, G). Here, E is an elliptic curve over Fq, G is a
generating (publicly known) point in the elliptic curve group of order n and the
integer h is called the cofactor. For the cofactor we have: #E(Fq) = h n. Due
to the security of the ECDLP one usually selects a curve for which h â‰¤4. Any
random point of suï¬ƒciently high order on an elliptic curve E can be used as
a key.
Fq, E, n, h, G
A
Fq, E, n, h, G
B
random secret x
random secret y
x Â· G
y Â· G
key k = x Â· (y Â· G)
key k = y Â· (x Â· G)
Fig. 1. EC Diï¬ƒe-Hellman key agreement protocol
Key Agreement. Each time a shared key is required, the following steps, as
depicted in Fig. 1, have to be performed.
1. A chooses a random secret x, where 1 â‰¤x â‰¤n âˆ’1, as her private key and
sends B the corresponding public key x Â· G
2. B chooses a random secret y, where 1 â‰¤y â‰¤n âˆ’1, as his private key and
sends A the corresponding public key y Â· G.
3. B receives x Â· G and computes the shared key as k = y Â· (x Â· G) = (xy) Â· G.
4. A receives y Â· G and computes the shared key as k = x Â· (y Â· G) = (xy) Â· G.
So, they both end up with the same point as the common key: k = xy Â· G. An
adversary Eve may have knowledge of G, x Â· G, and y Â· G but not of x or y.
She wants to determine number xy Â· G. This task is called the â€œ(computational)
Diï¬ƒe-Hellman problem for elliptic curvesâ€.
EC Digital Signature Algorithm (ECDSA). The ECDSA is speciï¬ed by
an elliptic curve E deï¬ned over Fq and a publicly known point G âˆˆE of prime
order n. As above, a private key of Alice is a scalar z and the corresponding
public key is Q = z Â· G âˆˆE. The ECDSA requires a hash function in addition
and consists of two parts as explained below.

Developing Eï¬ƒcient Blinded Attribute Certiï¬cates
213
Signature Generation. In order to sign a message m, A should perform the
following steps:
1. Select a random integer k, where 1 â‰¤k â‰¤n âˆ’1.
2. Compute (x1, y1) = k Â· G.
3. Compute r = x1 mod n. If r = 0, then go back to the step 1.
4. Compute s = kâˆ’1(h(m) + z r) mod n, where h is a hash function. If s = 0,
then go to step 1.
5. Aâ€™s signature for the message m is the pair (r, s).
Signature Veriï¬cation. In order to verify Aâ€™s signature on m, B performs the
following steps:
1. Obtain an authenticated copy of Aâ€™s public key Q.
2. Verify that r and s are integers in the interval [1, n âˆ’1].
3. Compute w = sâˆ’1 mod n and h(m).
4. Compute u1 = h(m) w mod n and u2 = r w mod n.
5. Compute (x0, y0) = u1 Â· G + u2 Â· Q and v = x0 mod n.
6. Accept the signature if and only if v = r.
2.2
Pairings
A bilinear pairing is a map G1 Ã— G2 â†’GT where G1 and G2 are typically
additive groups and GT is a multiplicative group and the map is bilinear, that
is, linear in both components. Many pairings are used in cryptography such as
the Tate pairing, ate pairing and the most recent R-ate pairing [24]. For all these
pairings one often uses speciï¬c cyclic subgroups of E(Fpk) as G1 and G2 and
Fâˆ—
pk as GT .
The bilinearity property can be written as follows:
e(P + P â€², Q) = e(P, Q) Â· e(P â€², Q)
and
e(P, Q + Qâ€²) = e(P, Q) Â· e(P, Qâ€²)
As a result, e(n Â· P, m Â· Q) = e(P, Q)n m. Pairings are used for many (new)
cryptographic protocols [2], such as short signatures [4], three-party one-round
key agreement [16], identity based encryption [3] and anonymous credentials [9].
Here we use pairings of the form e: E(Fp)Ã—E(Fpk) â†’Fpk, obtained by taking
G1 = G2 = Fpk and using the obvious inclusion Fp â†’Fpk in the ï¬rst argument.
The number k is known in this context as the embedding degree. As previously
mentioned, one uses k = 12 for BN-curves.
Pairing-based Signatures. We brieï¬‚y recall the pairing-based signature ap-
proach of Verheul [25], but here in the context of e-ticketing. Assume there is a
system-wide public key s Â· Q, for Q âˆˆE(Fpk), with private key s under control
of a scheme provider. Let ticket/card c have private key kc, with corresponding
public key Pc = kc Â· P, for some generator P âˆˆE(Fp). An interesting form of

214
L. Batina et al.
signature, by the scheme provider, on such a key is simply multiplication with
s. Thus, s Â· Pc = s Â· (kc Â· P) = (s kc) Â· P = R can be used as signature on Pc.
A pairing e can be used to check a claim that a point R âˆˆE(Fp) really is a
signature, namely by checking:
e(Pc, s Â· Q)
?= e(R, Q).
Indeed, if R = s Â· Pc then both sides are equal to e(Pc, Q)s, and thus equal. In
this scenario the card terminal, and not the card, veriï¬es the signature. Notice
that the ï¬rst argument of the pairing e(âˆ’, âˆ’) involves a point in E(Fp) coming
from the card. Hence the card does not have to do any of the (more complicated)
work in Fpk.
A powerful aspect about these signatures is that they are invariant under
blinding. Thus, if a card chooses an arbitrary number b as blinding factor, the
resulting pair (b Â· Pc, b Â· (s Â· Pc)) is again a signature, for the private-public key
pair (b kc, b Â· Pc = (b kc) Â· P). Each time the card is used it can thus present a
diï¬€erent (signed) public key, such that the diï¬€erent uses cannot be linked.
Of course, when a card presents a reader with such a pair Pc, R the reader
should not only check that R is a proper signature on Pc, that is, R is s Â· Pc,
but also that the card knows the private key corresponding to the public key Pc.
This can be done via standard challenge-response exchange, for example using
ECDSA.
2.3
Elliptic Curves on Smart Cards
The on-card part of our protocol is running on a Java Card smart card [11]. Java
Card technology gives us an open environment where we can easily implement
our protocols using Java and load them onto a development smart card. A Java
Card may be equipped with a cryptographic coprocessor to support a selection
of cryptographic algorithms deï¬ned by the oï¬ƒcial Java Card API [22], and
possibly some proprietary extensions provided by the card manufacturer [18].
Since version 2.2 the Java Card API oï¬€ers support for EC based algorithms.
When it comes to the implementation of our protocol on a Java Card â€œEC
supportâ€ alone is not enough as there are some issues that we need to be aware
of, as follows.
Java Card is an embedded and closed device. Internally its cryptographic
coprocessor implements all the routines required for a given cryptographic pro-
tocol (for example ECDH), but externally we can only utilise what is exported
through the API. For example, we may be able to perform the ECDH key agree-
ment protocol on the card (and hence scalar point multiplication), but we do
not have access to the point addition or point doubling primitives. The only
other EC based algorithms that the card can support are EC key generation
and ECDSA signature generation and veriï¬cation. Extension of the algorithms
that the card provides is practically impossible. The cryptographic coprocessor
is not accessible through Java code, and implementing EC operations in Java
(byte)code hinders performance signiï¬cantly [23]. As long as we stick to the

Developing Eï¬ƒcient Blinded Attribute Certiï¬cates
215
built-in cryptographic operations the performance is acceptable. For example, a
single point multiplication for 192 bit keys/points (using the ECDH operation)
takes about 0.10 seconds, ECDSA signature generation about 0.12 seconds, and
EC key pair generation about 0.60 seconds. A detailed method to measure Java
Card performance and some performance results can be found in [19]. Further-
more, the card may or may not support the compressed point format (and hence
point reconstruction) as input for EC based algorithms.
Due to this limited environment and performance requirements we need to bal-
ance our protocol such that the operations required on the card are minimised
and match the cards capabilities. The computationally expensive operations,
like pairing, should be performed by the terminal. Ideally, the card should only
be asked to perform operations supported natively by the Java Card crypto-
graphic API.
Finally, as all cryptographic support is optional in Java Card, we need a
development card that actually does support the EC based algorithms. We used
the NXP JCOP31 2.4.1 Java Card based on the SmartMX platform. It supports
ECDH and ECDSA with key sizes up to 320 bits, but it does not support the
compressed point format.
3
Protocol for Attribute-Proving
This section describes an elementary protocol of how a card c demonstrates in
a secure and privacy friendly manner that it possesses some attribute(s) a. This
attribute is just a number, with certain meaning that we abstract away.
3.1
The Protocol
System Setup The scheme provider has a public ï¬xed point Q âˆˆE(Fpk) and a
ï¬nite set of attributes. For each attribute a a secret key sa, which is a number
below the order of Q, and public key Qa = sa Â· Q are generated. The associated
pairs (a, Qa) of attributes and public keys are publicly known, and stored in all
terminals together with the ï¬xed point Q. This use of diï¬€erent signing keys for
diï¬€erent attributes goes back to work of Chaum on e-cash [10], where for instance
an e-coin of 50 cents had a diï¬€erent (â€œ50 centâ€) signature than an e-coin with a
value of 100 cents.
A card c generates a key pair kc, Pc = kc Â· P where P âˆˆE(Fp) is a ï¬xed
system wide generator. The private key kc of the card is assumed to be stored
in a protected manner such that it cannot leave the card. Upon personalisation
it receives an attribute together with a certiï¬cate Ca = sa Â· Pc linking its public
key Pc to the attribute a. The attribute a corresponds to a product that the
owner of the card has bought.
Before the protocol, as described below, will be run, some form of authenti-
cation between the card and terminal should be performed. This is required to
protect the card from proving the possession of an attribute to a rogue reader.
After this initial authentication phase the card can be sure that it communicates

216
L. Batina et al.
kc, Pc = kc Â· P, a, Ca = sa Â· Pc
Card
Q, (a, Qa)
Terminal
getAttribute
fresh blinding b
b Â· Pc,
b Â· Ca,
a
if e( b Â· Pc, Qa ) = e( b Â· Ca, Q )
then random nonce n
getSignature(n)
(r, s) = signECDSA( n, b kc )
(r, s)
verifyECDSA( r, s, b Â· Pc )
Fig. 2. Protocol for proving self-blindable attributes
with a genuine reader and can proceed with the execution of the protocol. This
preceding step will be ignored here.
Protocol Description. The protocol for proving self-blindable attributes, as de-
picted in Fig. 2, is initiated by a terminal which requests an attribute from the
card. The card generates a fresh blinding factor b to blind its public key and the
certiï¬cate. It responds by sending the blinded values (b Â· Pc and b Â· Ca) together
with the attribute stored on the card.
The terminal can now perform a pairing signature veriï¬cation, as discussed
in Section 2.2, using the cardâ€™s response, the attributeâ€™s public key Qa and the
ï¬xed point Q. Note that the terminal can select the correct public key Qa to use
by matching the attribute returned by the card. If the veriï¬cation succeeds the
terminal generates a random nonce n which is used to challenge the card, that
is, to request a signature over n. The card responds with an ECDSA signature
(r, s) of this nonce, which is created using its blinded private key b kc.
Finally the terminal veriï¬es the ECDSA signature using the blinded public
key. This works since b kc together with b Â· Pc = (b kc) Â· P is a valid key pair.
When the veriï¬cation succeeds the card has proved possession of the requested
attribute.
3.2
Some Issues
Privacy. In this protocol the attribute itself is not hidden, and may thus be
used to trace cards/people. This can be overcome to some extent by using only a
limited number of fairly general attributes. For instance, as possible validity date
one can choose to use only the ï¬rst day of each month, and not every possible day
of the year. Alternatively, one may provide a card with several attributes, stating

Developing Eï¬ƒcient Blinded Attribute Certiï¬cates
217
for instance: â€œyear card valid in January 2009â€, â€œyear card valid in February
2009â€, and so on. In this way each card can present the appropriate attribute,
after receiving the current date from the terminal.
Eï¬ƒciency. A drawback of the current protocol is that it only proves a single
attribute to the terminal. Consider the situation in which a card holds more
than one attribute. The terminal could then perform multiple requests to the
card in which an index indicates which attribute is requested. This is, however,
not a very eï¬ƒcient solution since the required amount of time for proving grows
linearly with the amount of attributes to be proved.
One approach could be to combine all attributes into a single point on the
curve, requiring only a single protocol run to proof all attributes. However, such
method could lead to new privacy issues since all attributes are disclosed at once.
Therefore selective disclosure of these attributes, as proposed by Brands [5],
would be preferred. The eï¬ƒcient adaption of these techniques to the elliptic
curve setting is a subject for further research.
Revocation. Within various settings, for example e-ticketing for public trans-
port, it is highly desirable to be able to revoke cards, for instance after abuse or
after early termination of a contract. However, revocation is non trivial as termi-
nals only get to verify blinded keys and blinded certiï¬cates. This blinding makes
straightforward black listing impossible. Kiyomoto and Tanaka [17] proposed a
solution to this problem that is unfortunately broken. The essence of their idea
is that the private key consists of two parts, the second part encoding some per-
sonal identiï¬able information. This second subkey is put on the blacklist, and the
protocol checks, in a blinded fashion, whether the subkey occurs on the blacklist.
This approach does not work because the user, after getting revoked, can choose
new subkeys that, when combined, still match with the original certiï¬cate, but
where the second subkey is diï¬€erent and no longer occurs on the blacklist.
The solution to this problem can be obtained as follows (to be detailed in a
forthcoming paper). The crucial observation is that even though Ki = ki Â· P is
called a public key, there is no reason to actually make it public: the proof that
you have a certiï¬cate for a certain attribute always blinds both the public key
and the certiï¬cate. So let us assume we keep the public key and certiï¬cate secret,
and only publish it when we want to revoke it. This way, users whose public key
is unknown cannot be traced because their key cannot be guessed, breaking out
of the assumed paradox.
4
Implementation and Performance Indicators
To understand practical limitations and estimate performance of our protocols,
we implemented the protocol from Fig. 2 in Java (terminal-side application) and
Java Card (card-side application). Our implementation involves the following
components:

218
L. Batina et al.
Bouncy Castle Library with Extension for Pairings. The Bouncy Castle
(BC) library1 is a collection of cryptographic APIs for Java and C# pro-
gramming languages. Bouncy Castle provides full support for ECC and an
interface to the common Java Cryptography Extension API. However, it
does not implement pairings or elliptic curves over ï¬elds other than Fp and
F2m. Thus we have added our own implementations of Fp2 and Fp12, and
the Tate, ate, and R-ate pairings. To minimise maintenance overhead we
strived to keep our extensions purely on top of the Bouncy Castle library,
that is, we did not change anything in the original library. In future we plan
to contact the BC development team to incorporate our extensions into the
oï¬ƒcial BC tree.
Smart Card IO Library. Since version 6.0 the standard Java Development
Kit includes support for communication with smart cards by providing the
javax.smartcardio package. We used it to talk to a Java Card smart card
on which our client applet was installed.
A Java Card with the Client Applet. The protocol on the card-side is imple-
mented as a Java Card [11] applet and loaded onto a development Java Card.
4.1
Java Card Applet
In Section 2.3 we described the practical limitations of Java Cards that we
have to take into account while programming the card. The actual operations
that the card needs to perform are scalar multiplication of points and modulo
multiplication of natural numbers. In the end the applet performs the required
steps of the protocol in the following way.
An on-card random number generator is used to generate the blinding value.
This value is stored in an EC private key structure on the card, which we call the
blind (not blinded) key. Then two ECDH key agreement operations (eï¬€ectively
two scalar point multiplications) are performed with this blind key to calculate
the blinded public key, and the blinded certiï¬cate, both of which are EC points.
As mentioned in the introduction, the ECDH implementation only returns the
x-coordinate of these multiplications, forcing the terminal to reconstruct the
y-coordinate (see below).
The second part of the protocol requires the card to sign a nonce with the
ECDSA algorithm using a blinded private key bÂ·kC. The modular multiplication
of these two large natural numbers has to be performed using hand implemented
Java code. That is, for this last step we cannot utilise any of the Java Card
API routines, like the key agreement above, to make the coprocessor do the
multiplication with high performance. This single modular multiplication is the
main bottleneck on the card-side implementation (see Section 4.5).
4.2
Terminal Application
The terminal application needs to cope with the shortcomings of the Java Card
applet. This comes down to the fact that the terminal has to reconstruct the
1 http://www.bouncycastle.org

Developing Eï¬ƒcient Blinded Attribute Certiï¬cates
219
points received from the card, b Â· Pc and b Â· Ca, before they can be processed any
further.
If we know the x-coordinate of a point on the curve, the square of the cor-
responding y-coordinate is known, namely as y2 = x3 + ax + b. By taking the
square root of x3 + ax + b we ï¬nd either y or âˆ’y. This forms the basis of â€œpoint
compressionâ€, for compact representation of points. This is important for the
implementation, because Diï¬ƒe-Hellman on a Java smart card only produces the
x-coordinate of a multiplication, as mentioned in Section 4.1.
This reconstruction is a simple guess work, trying diï¬€erent signs for the two
y-coordinates. For the ECDSA signature veriï¬cation this is not a real issue since
this veriï¬cation is reasonably fast, although this is of course not optimal. For
the pairing signature veriï¬cation simple guessing is not desirable. Therefore we
exploit the bilinearity of the pairing to avoid computing more than two pairings,
as would be the case without point reconstruction.
First we calculate e1 = e(b Â· Pc, Qa) and e2 = e(b Â· Ca, Q) where we take any
sign for the y-coordinate of b Â· Ca. If e1 = e2, which happens if we have two
right, or two wrong, signs in the ï¬rst parameters of the pairing, the veriï¬cation
succeeds. In the remaining case, which means we took one right and one wrong
sign, we check whether e1 e2 = 1 holds. If it holds, the veriï¬cation also succeeds.
This is true because of the following. If e1 Ì¸
= e2, the error is caused by the wrong
sign resulting in one pairing being the inverse of the other, that is, e2 = eâˆ’1
1 .
Here we can use that e1 e2 = e1(eâˆ’1
1 ) = 1 to avoid an extra pairing calculation
for the negated point of b Â· Ca.
4.3
System Parameters
For our test we selected three BN curves for keys of length 128, 160 and 192
bits. The domain parameters p and n are generated by the BN indices u =
1678770247, u = 448873116367 and u = 105553250485267 respectively (see
Section 2). The curve E is deï¬ned as y2 = x3 + 3, that is, take a = 0 and b = 3
in the general form y2 = x3 + ax + b, with the default generator G = (1, 2).
These key lengths have been chosen to indicate performance for various levels
of security, that is, protection against fraud. A key length of 128 bits provides
borderline security, whereas 160 and 192 bits provide, respectively, a minimal
and a standard level of security [13].
The length of the blinding factor generated by the card is either equal to the
chosen key length or a half or a quarter of this length. Reducing this length
of the blinding factor is a way to partially compensate for the slowness of the
modular multiplication (in Java Card) of big numbers. This way a trade oï¬€can
be made between privacy and performance.
4.4
Test Results
The results of our tests are summarised in Table 1. These values are the average
of ten test runs for each conï¬guration, that is, for each combination of key and
blinding length.

220
L. Batina et al.
Table 1. Test results for various key and blinding lengths
key
blinding getAttribute getSignature card total veriï¬cation protocol
(bits)
(bits)
(ms)
(ms)
(ms)
(ms)
(ms)
192
545
2202
2748
143
2891
192
96
543
1340
1884
136
2020
48
544
907
1451
130
1582
160
442
1417
1860
126
1987
160
80
443
912
1355
133
1489
40
442
670
1113
127
1240
128
364
1235
1599
91
1691
128
64
363
780
1143
93
1237
32
362
565
927
86
1014
The table shows the duration (in milliseconds) of the getAttribute and getSig-
nature requests to the card. The total amount of time spent by the card, which
is the sum of the durations of the requests, is shown in the â€˜card totalâ€™ column.
For the terminal we measured the duration of the signature veriï¬cations, sum-
marised in the â€˜veriï¬cationâ€™ column. Finally the total duration of the protocol
execution is shown in the â€˜protocolâ€™ column.
4.5
Analysis
We ï¬rst look at the part of the protocol executed on the smart card. From the
results given in Table 1 it can be seen that the duration of the getAttribute
request depends only on the length of the key. This is in strong contrast with
the getSignature request which also depends heavily on the blinding size.
This contrast can be explained by the available support from the crypto-
graphic coprocessor. For the blinding in the getAttribute request the applet uses
the ECDH primitive provided by the coprocessor to perform the required two
point multiplications. The blinding in the getSignature request, which requires
a modular multiplication, has to be calculated without the help of the copro-
cessor. In theory it is possible to abuse the RSA cipher (and hence use the
coprocessor) to do large part of the modulo multiplication by using the fact that
4ab = (a + b)2 âˆ’(a âˆ’b)2, as in [21,23]. The squares in this equation can be per-
formed by doing an RSA encryption/exponentiation with a suitable RSA public
key, that is, one with the exponent 2 and the required modulus. The numbers
a + b and a âˆ’b are then just messages to be encrypted using the RSA cipher,
which is provided by the Java Card API.
We tried this approach, but with no success. The main obstacle is that the
RSA cipher on the card operates only within valid bit lengths for RSA keys,
starting with 512 bit keys. Although the number to be multiplied (the message)
can be any value, the number of non-zero bits in the modulus has to be at least

Developing Eï¬ƒcient Blinded Attribute Certiï¬cates
221
488 bits for 512 bit keys according to our tests. Since our modulus is only 192
bit long the card refused to perform RSA encryption with such short modulus
value. However, we believe that a more ï¬‚exible RSA implementation on the card
would allow this optimisation.
The performance of the terminal application is good, taking less than a tenth
of running time on the smart card. The drawback on this side is caused by
the use of the ECDH primitive to calculate the blinded value. This results in
the problem that the card only responds with the x-coordinates of the blinded
values. Therefore the terminal has to reconstruct the actual point from these
values as mentioned above. If the card could respond with the actual points,
either in compressed or uncompressed format, instead of just the x-coordinate,
the duration of the veriï¬cation phase could be shortened.
A large beneï¬t of our use of ECC is the small amount of data that needs to
be exchanged between the terminal and the card. For key lengths of 192, 160 and
128 bits the total amount of bytes exchanged is 168, 152 and 136 respectively.
This would allow an implementation to use a single APDU pair (command and
response) for all communication. This is in strong contrast with RSA-based proto-
cols [21,23] which already require multiple APDUs to transfer a single command.
5
Conclusions
In line with results of others [12,21,23] this paper demonstrates that implementa-
tions of anonymous credential systems with smart cards are becoming possible.
One important bottleneck (and source of frustration) remains the limited ac-
cess oï¬€ered to the coprocessor on current Java Card smart cards. This paper
uses elliptic curves (with pairings) and abuses Diï¬ƒe-Hellman key agreement for
(scalar) point multiplication, together with several other tricks, to bring on-card
computation times down to around 1.5 seconds. We expect to be able to further
reduce this time via additional optimisations.
References
1. Barreto, P., Naehrig, M.: Pairing-friendly elliptic curves of prime order. In: Preneel,
B., Tavares, S. (eds.) SAC 2005. LNCS, vol. 3897, pp. 319â€“331. Springer, Heidelberg
(2006)
2. Blake, I., Seroussi, G., Smart, N.P.: Advances in Elliptic Curve Cryptography. In:
LMS, vol. 317. Cambridge Univ. Press, Cambridge (2005)
3. Boneh, D., Franklin, M.: Identity-based encryption from the Weil pairing. In: Kil-
ian, J. (ed.) CRYPTO 2001. LNCS, vol. 2139, pp. 213â€“229. Springer, Heidelberg
(2001)
4. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the Weil pairing. Journal
of Cryptology 17(4), 297â€“319 (2004)
5. Brands, S.: Rethinking Public Key Infrastructures and Digital Certiï¬cates: Build-
ing in Privacy. MIT Press, Cambridge (2000)
6. Brickell, E.F., Camenisch, J., Chen, L.: Direct anonymous attestation. In: Pï¬tz-
mann, B., Liu, P. (eds.) Computer and Communications Security - CCS 2004, pp.
132â€“145. ACM Press, New York (2004)

222
L. Batina et al.
7. BSI: Advanced security mechanisms for machine readable travel documents â€“ Ex-
tended Access Control (EAC). Tech. Rep. TR-03110, German Federal Oï¬ƒce for
Information Security, BSI (2008)
8. Camenisch, J., van Herreweghen, E.: Design and implementation of the idemix
anonymous credential system. In: Computer and Communications Security - CCS
2002, pp. 21â€“30. ACM, New York (2002)
9. Camenisch, J., Lysyanskaya, A.: Signature schemes and anonymous credentials
from bilinear maps. In: Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp.
56â€“72. Springer, Heidelberg (2004)
10. Chaum, D.: Blind signatures for untraceable payments. In: Chaum, D., Rivest,
R.L., Sherman, A.T. (eds.) Advances in Cryptology - CRYPTO 1982, pp. 199â€“
203. Plenum Press, New York (1983)
11. Chen, Z.: Java Card Technology for Smart Cards: Architecture and Programmerâ€™s
Guide. Java Series. Addison-Wesley, Reading (2000)
12. Danes, L.: Smart card integration in the pseudonym system idemix. Masterâ€™s thesis,
University of Groningen, The Netherlands (2007)
13. ECRYPTII: Yearly report on algorithms and keysizes (2008-2009). Tech. Rep.
D.SPA.7, European Network of Excellence in Cryptology II (ECRYPTII) (2009)
14. Jacobs, B.: Architecture is politics: Security and privacy issues in transport and
beyond. In: Gutwirth, S., Poullet, Y., Hert, P. (eds.) Data Protection in a Proï¬led
World - CPDP 2008. Springer, Heidelberg (2010)
15. Johnson, D., Menezes, A.: The elliptic curve digital signature algorithm (ECDSA).
Tech. Rep. CORR 99-34, Department of Combinatorics & Optimization, University
of Waterloo, Canada (2000)
16. Joux, A.: A one round protocol for tripartite Diï¬ƒe-Hellman. Journal of Cryptol-
ogy 17(4), 263â€“276 (2004)
17. Kiyomoto, S., Tanaka, T.: Anonymous attribute authentication scheme using self-
blindable certiï¬cates. In: Intelligence and Security Informatics - ISI 2008, pp. 215â€“
217. IEEE, Los Alamitos (2008)
18. NXP: Smart solutions for smart services (z-card 2009). NXP Literature, Document
75016728 (2009)
19. Paradinas, P., Cordry, J., Bouzefrane, S.: Performance evaluation of Java Card
bytecodes. In: Sauveron, D., Markantonakis, K., Bilas, A., Quisquater, J.-J. (eds.)
WISTP 2007. LNCS, vol. 4462, pp. 127â€“137. Springer, Heidelberg (2007)
20. Smart, N.: Elliptic curve based protocols. In: Blake, I., Seroussi, G., Smart, N. (eds.)
Advances in Elliptic Curve Cryptography. LMS, vol. 317, pp. 3â€“19. Cambridge
Univ. Press, Cambridge (2005)
21. Sterckx, M., Gierlichs, B., Preneel, B., Verbauwhede, I.: Eï¬ƒcient implementation
of anonymous credentials on Java Card smart cards. In: Information Forensics and
Security â€“ WIFS 2009, pp. 106â€“110. IEEE, Los Alamitos (2009)
22. Sun Microsystems, Inc.: Java Card 2.2.2 Application Programming Interface Spec-
iï¬cation (2006)
23. Tews, H., Jacobs, B.: Performance issues of selective disclosure and blinded issuing
protocols on java card. In: Markowitch, O., Bilas, A., Hoepman, J.H., Mitchell,
C., Quisquater, J.J. (eds.) WISTP 2009. LNCS, vol. 5746, pp. 95â€“111. Springer,
Heidelberg (2009)
24. Vercauteren, F.: Pairings on elliptic curves. In: Joye, M., Neven, G. (eds.) Identity-
Based Cryptography. CIS, vol. 2, pp. 13â€“30. IOS Press, Amsterdam (2009)
25. Verheul, E.: Self-blindable credential certiï¬cates from the Weil pairing. In: Boyd,
C. (ed.) ASIACRYPT 2001. LNCS, vol. 2248, pp. 533â€“550. Springer, Heidelberg
(2001)

On the Design and Implementation of an
Eï¬ƒcient DAA Schemeâ‹†
Liqun Chen1, Dan Page2, and Nigel P. Smart2
1 Hewlett-Packard Laboratories,
Long Down Avenue, Stoke Giï¬€ord,
Bristol, BS34 8QZ,
United Kingdom
liqun.chen@hp.com
2 Computer Science Department,
Woodland Road, University of Bristol,
Bristol, BS8 1UB,
United Kingdom
{page,nigel}@cs.bris.ac.uk
Abstract. Direct Anonymous Attestation (DAA) is an anonymous dig-
ital signature scheme that aims to provide both signer authentication
and privacy. One of the properties that makes DAA an attractive choice
in practice is the split signer role. In short, a principal signer (a Trusted
Platform Module (TPM)) signs messages in collaboration with an assis-
tant signer (the Host, a standard computing platform into which the
TPM is embedded). This split aims to harness the high level of security
oï¬€ered by the TPM, and augment it using the high level of compu-
tational and storage ability oï¬€ered by the Host. Our contribution in
this paper is a modiï¬cation to an existing pairing-based DAA scheme
that signiï¬cantly improves eï¬ƒciency, and a comparison with the original
RSA-based DAA scheme via a concrete implementation.
1
Introduction
An anonymous signature scheme is a special type of digital signature. In common
with a conventional signature scheme, an anonymous signature scheme must
ensure that only an authorised signer can produce a valid signature. However,
given a signature it must also ensure that no unauthorised entity should be
able to identify the signer. Another diï¬€erence is highlighted by the nature of
the public keys used to perform signature veriï¬cation. To verify a conventional
signature, the veriï¬er makes use of a single public veriï¬cation key which is bound
to the identity of the signer. In contrast, to verify an anonymous signature the
veriï¬er makes use of either a group public key or multiple public keys. In either
case the keys are not bound to an individual signer, and the level of anonymity
â‹†The second and third author would like to thank the EU funded project eCrypt-2
for partially supporting the work in this paper. The third author was supported by
a Royal Society Wolfson Merit Award.
D. Gollmann, J.-L. Lanet, J. Iguchi-Cartigny (Eds.): CARDIS 2010, LNCS 6035, pp. 223â€“237, 2010.
c
âƒIFIP International Federation for Information Processing 2010

224
L. Chen, D. Page, and N.P. Smart
provided depends upon the size of the group or the number of public keys. The
ï¬rst anonymous signature schemes were group signatures, introduced in 1991 by
Chaum and van Heyst [12].
In this paper we shall concentrate on a speciï¬c form of anonymous signature
that uses a group public key, namely a signature provided by a Direct Anonymous
Attestation (DAA) protocol. The security notions of DAA are diï¬€erent from
group signatures, e.g., there is no group manager-based traceability in DAA. For
the details of the security model of DAA and diï¬€erentiation between the group
signatures and DAA, we direct the reader to [5,7]. In addition to a number of
interesting security and privacy features, DAA has a unique property that makes
it an attractive choice. In short, the signer role in DAA is split between
1. a principal signer with limited computational and storage capability but high
security assurance, and
2. an assistant signer with greater computational and storage capability, but
lesser security.
Concrete realisation of these entities is provided by a TPM and a standard
computing platform, termed the Host, into which the TPM is embedded. The
TPM represents the principle signer and holds the secret signing key; the Host
assists the TPM in computing a signature, and satisfying the privacy require-
ment. Note that the Host is prevented from learning the secret signing key, and
hence from producing a valid signature without interaction with the TPM.
The TPM is a physically secure hardware device designed to enable higher
levels of security than are possible using software alone. One can view the TPM
as a form of coprocessor capable of storing cryptographic keys and performing
limited computational tasks in a secure manner; communication with the TPM
is typically performed via a low-bandwidth Low Pin Count (LPC) bus interface.
From a functional perspective, the TPM is speciï¬ed by the Trusted Computing
Group (TCG); estimates suggest over 100 million standardised TPM devices
are currently in existence, mostly within high-end laptops. This deployment is
intended to support a wide variety of applications including full disk encryption,
Digital Rights Management (DRM) and, crucially for this work, anonymous
digital signatures. Crucially, said applications must be designed with great care
so as not to expose the constrained nature of both TPM and LPC bus as a
bottleneck.
The concept of DAA, and a concrete scheme, were ï¬rst introduced by Brickell,
Camenisch, and Chen [5]; for a historical perspective, we direct the reader to [6].
This RSA-based scheme, which we term RSA-DAA from here on, was adopted
by the TCG and included in version 1.2 of the TPM speciï¬cation [26]; this TPM
speciï¬cation was recently adopted by ISO/IEC as an international standard [23].
Support for RSA-DAA alone represents around 10% of the TPM resources and
as such, schemes that retain the same functionality but do so more eï¬ƒciently
remain an interesting and challenging open problem. One option, which has
formed the focus of much recent work, is the development of DAA schemes based
on elliptic curves and pairings; we generically term such schemes ECC-DAA from

On the Design and Implementation of an Eï¬ƒcient DAA Scheme
225
here on. The advantage of using these underlying building blocks is obvious:
both the key and signature length can be much shorter, and computational load
placed on the TPM less severe. As a result, ECC-DAA is typically more eï¬ƒcient
in computation, storage and communication cost than RSA-DAA.
Main Contributions: To the best of our knowledge, there are six existing
ECC-DAA schemes. Brickell, Chen and Li [7,8] proposed the ï¬rst such scheme,
basing it on symmetric pairings. In order to improve ï¬‚exibility and eï¬ƒciency,
Chen, Morrissey and Smart proposed two extensions [15,16,17] based instead on
asymmetric pairings. Although the security of all three schemes is based on both
the LRSW [24] and DDH problems, a ï¬‚aw in the ï¬rst extension was discovered
by Li and further discussed in [14,17]. Three further schemes were proposed by
Chen and Feng [19], Brickell and Li [10], and Chen [13] respectively. The security
of these schemes is based on the q-SDH [4] and DDH problems. Using previous
work as a starting point, this paper makes two main contributions.
Firstly, we make three modiï¬cations to the ECC-DAA scheme described in
[17]. In summary, these modiï¬cations are:
1. The ï¬rst modiï¬cation is purely syntactic and implies no change to the secu-
rity proof from [17]: we simply move computations which could be performed
by the TPM to the Host, and vice versa. This has the eï¬€ect of balancing
the workloads of TPM and Host, ultimately reducing the computational
load placed on the TPM.
2. Next we replace the public key signature based endorsement key from [17]
with a public key encryption based endorsement key, combined with a Mes-
sage Authentication Code (MAC). This mirrors more closely how the au-
thentic channel is created in the currently deployed RSA-DAA scheme.
3. Finally we replace the root key, used by the Issuer in generation of the
TPM DAA secret key, with a small subset of public system parameters.
We also remove the requirement for the TPM to verify a certiï¬cate chain
(from the root public key of the Issuer to the current public key) in every
join process. This veriï¬cation was required in all previous DAA schemes,
including RSA-DAA, and has two main purposes: ï¬rstly to allow the TPM
DAA secret key to have a diï¬€erent life-cycle from the Issuer public key,
and secondly to to avoid the TPM accepting an arbitrary key that does not
belong to a given issuer. Our modiï¬cation is based on two facts:
(a) in our new DAA scheme the TPM operations are strictly limited to the
small subset of public system parameters and do not actually use the
issuer current public key, and
(b) the public system parameters can have a much longer life-cycle than the
Issuer public key.
The modiï¬cation vastly reduces the TPM workload in the Join protocol.
From here on, and unless otherwise speciï¬ed, one can read ECC-DAA as meaning
our modiï¬ed scheme as described in Section 2.
Secondly, we demonstrate how the ECC-DAA scheme can be implemented
and evaluate it via a concrete comparison with the incumbent RSA-DAA. In par-
ticular, we present experimental results that illustrate various implementation

226
L. Chen, D. Page, and N.P. Smart
options and compare aspects of the schemes (e.g., eï¬ƒciency and communication
cost) using a commodity computing platform (that represents the Host) and
an embedded computing platform (that represents the TPM).
2
The Pairing-Based ECC-DAA Scheme
A DAA scheme involves a set of issuers, signers, and veriï¬ers. An Issuer is in
charge of verifying the legitimacy of signers, and of issuing a DAA credential to
each signer. A signer, which due to the split role is a pair of Host and associated
TPM, can prove membership to a Verifier by providing a DAA signature; this
requires the signer holds a valid DAA credential. The Verifier can verify the
membership credential from the signature, but it cannot learn the identity of
the signer. Linkability of signatures issued by a Host TPM pair is controlled
by an input parameter bsn (standing for â€œbase nameâ€) which is passed to the
signing operation. There is assumed to be a list RogueList which contains a list
of TPM secret keys which have been compromised. Based on these deï¬nitions,
the rest of this section describes our ECC-DAA scheme, which is based on the
scheme of [17] and relies on the use of asymmetric pairings.
Notation: Throughout the constituent protocols and algorithms, we let I,
H and V denote the set of all Issuer, Host and Verifier entities; the set
of all TPM entities is denoted by M. The value of bsn will be used by the
signer/veriï¬er to link signatures, if bsn =âŠ¥then this implies that signatures
should be unlinkable.
If S is a set, we denote the act of sampling from S uniformly at random
and assigning the result to the variable x by xâ†S. We let {0, 1}âˆ—and {0, 1}t
denote the set of binary strings of arbitrary length and length t respectively.
If A is an algorithm, we denote the action of obtaining x by invoking A on
inputs y1, . . . , yn by x â†A(y1, . . . , yn), where the probability distribution on x
is determined by the internal coin tosses of A. Finally, we use [x]P to denote the
scalar multiplication of an elliptic curve point P by some integer x.
Note: Before proceeding with the description of our scheme, we note a general
issue that needs to be considered throughout. Speciï¬cally, every group element
received by any entity needs to be checked for validity, i.e., that it is within the
correct group; in particular, it is important that the element does not lie in some
larger group which contains the group in question. This strict stipulation avoids
numerous attacks such as those related to small subgroups. When asymmetric
pairings are used, as here, this is particularly important since G1 and G2 can
be considered as distinct subgroups of a large group G. If communicated group
elements are actually in G, as opposed to G1 and G2, then various properties
such as anonymity and linkability break down. As a result, we implicitly assume
that all transmitted group elements are elements of the speciï¬ed groups: within
our scheme, the use of Type-III pairings [20] allows eï¬ƒcient methods for checking
subgroup membership as described by [18] and expanded upon in Section 3.

On the Design and Implementation of an Eï¬ƒcient DAA Scheme
227
2.1
The Setup Algorithm
To initialise the system, one needs to select parameters for each protocol as well
as the long term parameters for each Issuer. We assume that prior to initial-
isation each TPM has a private endorsement key SK embedded into it (e.g.,
in read-only memory) and that each Issuer has access to the corresponding
public endorsement key PK. We also assume a public key IND-CCA encryp-
tion/decryption scheme (ENC/DEC) has been selected for use with these keys,
and a MAC algorithm (MAC) with key space MK has been selected in order to
achieve authentication.
As explained previously, this latter point is both a minor departure from
the ECC-DAA scheme of [17] (in that there, the TPM endorsement key was a
signature/veriï¬cation key pair) and a minor departure from the TCG developed
TPM speciï¬cation [26] (in that there, message integrity was â€œachievedâ€ by using
SHA-1 in [26] instead of a MAC function1).
On input of the security parameter 1t, the Setup algorithm executes the fol-
lowing steps:
1. Generate the Commitment Parameters parC. In this step, three groups G1, G2
and GT, of suï¬ƒciently large prime order q, are selected. Two random genera-
tors are then selected such that G1 = âŸ¨P1âŸ©and G2 = âŸ¨P2âŸ©along with a pair-
ing Ë†h : G1 Ã—G2 â†’GT . Next, two hash functions H1 : {0, 1}âˆ—â†’G1 and H2 :
{0, 1}âˆ—â†’Zq are selected and parC is set to (G1, G2, GT , Ë†h, P1, P2, q, H1, H2).
Note that in our scheme, and in contrast with existing ECC-DAA schemes,
the TPM operations are strictly limited to G1. This allows a subset of parC,
namely parT, to be set to (G1, P1, q) and installed on the TPM in preference
to parC.
2. Generate Signature and Veriï¬cation Parameters parS. Two additional hash
functions are selected, namely H3 : {0, 1}âˆ—â†’Zq and H4 : {0, 1}âˆ—â†’Zq, and
parS is set to (H3, H4).
3. Generate the Issuer Parameters parI. For each ik âˆˆI, the following steps
are performed. Two integers x, yâ†Zq are selected, and the Issuer private
key iskk is set to (x, y). Next, the values X = [x]P2 âˆˆG2 and Y = [y]P2 âˆˆG2
are computed; the Issuer public key ipkk is set to (X, Y ). Then an Issuer
value Kk is derived from the Issuer public values. Finally, parI is set to
({ipkk, Kk}) for each Issuer ik âˆˆI.
4. Generate TPM Parameters. The TPM generates a public/private key pair
(PK, SK) for the associated endorsement key. In addition, it generates the
private secret value DAAseed. Finally, parT is set to (PKh) for each TPM
embedded in some host h âˆˆH.
5. Publish Public Parameters. Finally, the public system parameters par are set
to (parC, parS, parI, parT) and published.
1 We place â€œachievedâ€ in quotes, since it is a well known that a Merkleâ€“DamgËšard style
hash function, when applied to a concatenation of the message and a key, cannot
provide secure message authentication.

228
L. Chen, D. Page, and N.P. Smart
Note 1: In our scheme, the Issuer value Kk is derived from a representation
of parT; if the same parT is used by multiple issuers, in order to limit Kk to a
single issuer, the issuer value Kk can be set by using both parT and a unique
issuer name. This is an important diï¬€erence from other existing DAA schemes,
including RSA-DAA. In all the previous DAA schemes, Kk is computed to be a
representation of the Issuer root public key. This is used to certify the Issuerâ€™s
public key ipkk so that the Issuer and TPM can update their keys without
synchronising with each other.
However, there may be a long certiï¬cate chain between Kk and ipkk that could
result in the Join protocol very ineï¬ƒcient; speciï¬cally, the TPM needs to verify
said certiï¬cate chain. Our modiï¬cation is based on the fact that the parameter
parT could be used over a longer timescale than the the Issuer public/private key
pair (iskk, ipkk). Therefore, the Issuer could update his key without changing
parT and without requiring each TPM to update its private key synchronously.
Note 2: Each TPM has a single DAAseed, but can create multiple DAA secret
keys, even associated with a single issuer. To allow this, a number cnt is used as
an additional input to DAA secret key generation: the TPM DAA secret key is
generated by using DAAseed, Kk and cnt as input.
2.2
The Join Protocol
This is a protocol between a given TPM m âˆˆM, the corresponding Host h âˆˆH
and an Issuer i âˆˆI. The protocol proceeds as shown in Figure 1, and it is
virtually identical to that of [17]. The diï¬€erence is the way that the Issuer
and TPM establish an authentic channel between themselves. For simplicity of
analysis, in [17] this mechanism was provided by a digital signature algorithm.
However, in practice the TPM will not use a signature algorithm, but an en-
cryption algorithm and an integrity check function. For the sake of privacy, the
TCG does not want a TPM to provide a piece of evidence for each transaction.
Since each endorsement key is bound to a particular TPM, a signature signed
under the endorsement key can be used as such evidence in a public manner,
(although the public key encryption mechanism still provides this evidence to
an issuer). In this paper we follow this approach; the minor diï¬€erence from the
TPM speciï¬cation [26] is, as mentioned, that we make use of a MAC function
to achieve authentication rather than a hash function as in [26].
2.3
The Sign/Verify Protocols
This is a protocol between a given TPM m âˆˆM, Host h âˆˆH and Verifier
v âˆˆV as described in Figure 2. The main diï¬€erence between this version and
the protocol in [17] is the computation of Wâ†[t]D by the Host, as opposed to
the computation of Î²â†Ë†h(S, X). This avoids a costly pairing operation by the
Host, and an expensive GT operation by the TPM. This advantage comes at
the expense of the Verifier being required to compute more operations in G1,
but less pairing operations and operations in GT.

On the Design and Implementation of an Eï¬ƒcient DAA Scheme
229
TPM (m)
Host (h)
Initiator (I)
Issuer Request
kMâ†MK
cIâ†ENCPK(kM)
nIâ†{0, 1}t
TPM Response
commreq

commreq

commreqâ†(cI, nI)
skT â†PRF(DAAseedâˆ¥KIâˆ¥cnt)
kM â†DECSK(cI)
If kM =âŠ¥then abort
strâ†Xâˆ¥Y âˆ¥nI
strâ†Xâˆ¥Y âˆ¥nI
Q2â†[skT ]P1
uâ†Zq; Uâ†[u]P1
vâ†H2(P1âˆ¥Q2âˆ¥Uâˆ¥str)
wâ†u + v Â· skT (mod q)
Î³â†MACkM (P1âˆ¥Q2âˆ¥vâˆ¥w)
commâ†(Q2, v, w, Î³, nI)
comm-
comm-
Issuer Response
If nI Ì¸âˆˆ{commreq}
then abort
Î³â€²â†MACkM (P1âˆ¥Q2âˆ¥vâˆ¥w)
If Î³ Ì¸= Î³â€² then abort
Uâ€²â†[w]P1 âˆ’[v]Q2
vâ€²â†H2(P1âˆ¥Q2âˆ¥Uâ€²âˆ¥str)
If v Ì¸= vâ€² then abort
âˆ€skâ€²
T âˆˆRogueList
if Q2 = [skâ€²
T ]P1
then abort
râ†Zq
Aâ†[r]P1; Bâ†[y]A
Câ†[x]A + [rxy]Q2
B

cre

creâ†(A, B, C)
TPM Open
Dâ†[skT ]B
D-
Host Verify
If Ë†h(A, Y )
Ì¸= Ë†h(B, P2)
or Ë†h(A + D, X)
Ì¸= Ë†h(C, P2)
then abort
Fig. 1. The Join protocol
It is easy to see that these minor modiï¬cations to the Sign and Verify protocols
have no aï¬€ect on the security proof from [17]. Indeed, the Verifier still veriï¬es
a Camensich-Lysyanskaya credential [11] and a proof of equality of two discrete

230
L. Chen, D. Page, and N.P. Smart
TPM (m)
Host (h)
Verifier (v)
Start Sign
nV

nV âˆˆ{0, 1}t
If bsn =âŠ¥then Jâ†G1
else Jâ†H1(bsn)
lâ†Zq
Râ†[l]A; Sâ†[l]B
T â†[l]C; W â†[l]D
TPM Sign
c, J, S, msg, bsn

câ†H4(Râˆ¥Sâˆ¥T âˆ¥W âˆ¥nV )
K = [skT ]J
nT â†{0, 1}t
râ†Zq
R1â†[r]J; R2â†[r]S
strâ†Jâˆ¥Kâˆ¥bsnâˆ¥R1âˆ¥R2
hâ†H5(câˆ¥msgâˆ¥strâˆ¥nT )
sâ†r + h Â· skT (mod q)
(K, h, s, nT )
-
Ïƒâ†(R, S, T, W,
J, K, h, s, nV , nT )
Ïƒ -
Verify
âˆ€skâ€²
T âˆˆRogueList
if K = [skâ€²
T ]J
return false
If bsn Ì¸=âŠ¥
and J Ì¸= H1(bsn)
return false
If Ë†h(R, Y )
Ì¸= Ë†h(S, P2)
or Ë†h(R + W, X)
Ì¸= Ë†h(T, P2)
return false
Râ€²
1 = [s]J âˆ’[h]K
Râ€²
2 = [s]S âˆ’[h]W
câ€²â†H4(Râˆ¥Sâˆ¥T âˆ¥W âˆ¥nV )
strâ€²â†Jâˆ¥Kâˆ¥bsnâˆ¥Râ€²
1âˆ¥Râ€²
2
hâ€²â†H5(câ€²âˆ¥msgâˆ¥strâ€²âˆ¥nT )
If hâ€² Ì¸= h return false
Return true
Fig. 2. The Sign/Verify protocol
logarithms. However, now these two veriï¬cations are performed in distinct steps
rather than being mixed together; we suggested this makes the overall protocol
structure simpler to understand. In addition, the modiï¬cations produces a more
eï¬ƒcient protocol for the Host, TPM and Verifier. In addition, by splitting
the proof of equality of discrete logarithms from the credential veriï¬cation step,
we enable the use of batch pairing veriï¬cation techniques as expanded upon in
Section 3.

On the Design and Implementation of an Eï¬ƒcient DAA Scheme
231
3
Implementation Details
3.1
RSA-DAA Scheme
Rather than replicate the detail here, we refer the reader to [5] for much of
the notation and the RSA-DAA scheme itself. Several implementation details
demand some discussion and clariï¬cation.
Choice of Parameters: The RSA-DAA scheme was instantiated using the
security parameters deï¬ned in [5]. That is, the security parameters in [5, Section
4.2] were used to generate public and private Issuer keys as described by [5,
Section 4.3]; pertinent features include the 2048-bit n and 1632-bit Î“.
Endorsement Key Algorithm: As described in [5, Appendix B], we altered
the Join protocol to include the notion of TPM endorsement. Eï¬€ectively this
means the TPM holds a 2048-bit RSA key, and the PKCS#1 RSAES-OAEP
primitive is used as the endorsement key algorithm within Step 4 of the Join
protocol; we assume the public key of each TPM utilises a â€œsmallâ€ exponent (i.e.,
e = 65537) and interleave additional messages to avoid extra communication
steps.
Implementation Options: A central part of each protocol in the scheme is
computation of k-term (multi-)exponentiations (i.e., the product of k single-
exponentiations) modulo an n and Î“.
Three issues related to this type of computation are worthy of note. Firstly,
there is scope for pre-computation based on the â€œsomewhat ï¬xedâ€ bases taken
from the per-Issuer public key (e.g., gâ€², g and h). The value of such an approach
relates to the frequency of interaction with a given Issuer, and therefore we do
not pursue it in our implementation. Secondly, there exists a subtle overhead
associated with the fact that various exponents for exponentiation modulo n are
larger than the group order; no entity other than the Issuer has knowledge of
Î¦(n) and hence they must be used, as presented, in their larger form. Thirdly,
we suggest that the diverse range of operand lengths used leads to some natural
ineï¬ƒciency: in short, one must either employ a general-purpose implementation
strategy and pay a penalty in terms of performance, or employ a special-purpose
implementation strategy and pay a penalty in terms of memory footprint. De-
pending on the entity (i.e., Issuer, Host, Verifier or TPM) one or other may
be unattractive. Examples of this issue include:
â€“ In various steps, entities perform computation modulo n and Î“ which are of
signiï¬cantly diï¬€erent lengths: either one adopts a general-purpose strategy
that supports all moduli, or a special-purpose strategy for each.
â€“ In various steps, entities compute the result of multi-exponentiation with
2, 3, 4 and 6 terms with varying length exponents. Either one adopts a
general-purpose strategy for any number of terms and any exponent length,
or a special-purpose strategy or each. As an example, consider that in step
3.a.i of the Sign protocol, the TPM is required to compute
R
rf0
0
R
rf1
1
Srv
(mod n)

232
L. Chen, D. Page, and N.P. Smart
where rf0 and rf1 are both 688-bit integers and rv is a signiï¬cantly larger
2776-bit integer. One could view the resulting mismatch as disadvantageous
in the sense that some eï¬€ort is being â€œwastedâ€during a multi-exponentiation,
We opted for general-purpose strategy throughout our implementation, reason-
ing that this provides a fair comparison given the similar approach in the ECC-
DAA case.
3.2
ECC-DAA Scheme
The ECC-DAA under consideration is that described in Section 2; several im-
plementation details demand some discussion and clariï¬cation.
Choice of Parameters: To instantiate the ECC-DAA scheme, we use pairing
groups based on Barreto-Naehrig (BN) curves [2]. These are elliptic curves of
the form
E : y2 = x3 + b,
for b Ì¸= 0, where the curve order and the ï¬nite ï¬eld are deï¬ned by the polynomials
q(s) = 36s4 âˆ’36s3 + 18s2 âˆ’6s + 1,
p(s) = 36s4 âˆ’36s3 + 24s2 âˆ’6s + 1.
To generate such curves, one searches random values of s of the correct form
until q(s) and p(s) are both prime; searching for a b that produces a valid
elliptic curve over Fp, of order q, is then a simple task. In our implementation
we selected s = âˆ’7493989779944505618 and deï¬ned a curve using b = 18. This
yields roughly 256-bit values for q(s) and p(s) that are hence compatible with
AES-128 bit key sizes; alternatively, one could consider the security level as
comparable with 3000-bit RSA. Based on this curve, we select
1. The rational points on the curve E(Fp) as G1.
2. The order-q subgroup of Ë†E(Fp2), where Ë†E is the sextic twist of E available
due to the form of BN-curves, as G2.
3. The order-q subgroup of the ï¬nite ï¬eld Fp12, available due to the embedding
degree of BN-curves being 12, as GT.
Elements of the ï¬nite ï¬eld Fp12 are represented by a polynomial basis with
respect to the polynomial Ï‡12 + 6. Using these groups, we implemented the Ate
pairing [22], which runs a short full-Miller loop followed by an exponentiation in
GT . We note that more eï¬ƒcient pairing algorithms exist (e.g., R-ate), but made
this selection partly based on possible inclusion in the IEEE P1363.3 Identity-
Based Public Key Cryptography standard.
Endorsement Key Algorithm: The choice of TPM endorsement key algo-
rithm was selected to be ECIES deï¬ned over the group G1. The KEM component
consists of a single element in G1. For encryption two point multiplications are
required, whilst for decryption one point multiplication is required. The DEM

On the Design and Implementation of an Eï¬ƒcient DAA Scheme
233
component consisted of AES-128, combined with a CBC-MAC, (actually a vari-
ant of CBC-MAC called EMAC was used, which corresponds to MAC algorithm
two in the ISO 9797-1 standard).
Credential Verification: In both the Join and Sign/Verify protocols, veriï¬-
cation of a blinded Camenisch-Lysyanskaya signature is required. Namely, given
A, B, C, D âˆˆG1 we need to verify whether both
Ë†h(A, Y ) = Ë†h(B, P2)
and
Ë†h(A + D, X) = Ë†h(C, P2).
To optimise this operation, we use an analogue of the small-exponent batch veriï¬-
cation techniques from [3]. Speciï¬cally, we select two small exponents e1, e2 âˆˆZq
whose bit length is half that of q; to verify the two pairing equations we then
verify whether
Ë†h([e1]A, Y ) Â· ([âˆ’e1]B, P2) Â· Ë†h([e2](A + D), X) Â· Ë†h([âˆ’e2]C, P2) = 1.
Thus the veriï¬cation involving four pairing computations is replaced by one
product of four pairings, plus four (relatively short) multiplications in G1. As
surveyed in [21], computing a â€œproduct of pairingsâ€ is less expensive than com-
puting the pairings independently; the methods improves veriï¬cation of a blinded
Camenisch-Lysyanskaya signature by around 40%.
Subgroup Checking: Recall from Section 2 that group element accepted by
some entity within a protocol needs to be veriï¬ed, i.e., checked to ensure it is
within the correct subgroup. Such checking falls into one of three categories:
â€“ Checking whether X, Y âˆˆG2 can be done by ï¬rst checking whether X, Y âˆˆ
Ë†E(Fp2), and then verifying that [q]X = [q]Y = O.
â€“ Checking whether x âˆˆZq or Y âˆˆG1 is trivial. In the ï¬rst case we simply
need to check whether x is an integer in the range [0, . . . , q âˆ’1], and in the
second case we check whether Y lies on the curve E(Fp). This simplicity is
possible because there is no cofactor of G1 in E(Fp) as a result of the curve
choice.
â€“ We ignore the cost of checking whether X, Y âˆˆG2 because this is performed
once only, by a given entity, on receipt of a public key from some Issuer.
That is, we expect the cost to be amortised across all interactions with the
Issuer.
3.3
Experimental Results
To evaluate the proposed ECC-DAA scheme, and compare it with RSA-DAA,
we present some concrete experimental results. We used two platforms where
1. the Issuer, Host and Verifier entities were represented by a 64-bit, 2.4
GHz Intel Core2 (6600) processor targeted with GCC 4.3.2, and
2. the TPM entity was represented by a (simulated) 32-bit, 33 MHz ARM7TDMI
processor targeted with ARM ADS 1.2.

234
L. Chen, D. Page, and N.P. Smart
Table 1. Experimental results for RSA-DAA and ECC-DAA. Note that Steps 5 and
6.c of the RSA-DAAJoin protocol involve primality testing and, as such, the results
have quite a high standard deviation; where operations relate to entries in a rogue list
(e.g., Step 4 of the RSA-DAAVerify protocol), the quoted result is per-entry rather
than based on an assumed list length.
Join
Step
Issuer
Host
TPM
1
âˆ’âˆ’
13.38ms
âˆ’âˆ’
2
âˆ’âˆ’
âˆ’âˆ’
25.73s
3
1.62ms
âˆ’âˆ’
âˆ’âˆ’
4.a
âˆ’âˆ’
âˆ’âˆ’
30.15s
4.b
0.32ms
âˆ’âˆ’
âˆ’âˆ’
4.c
âˆ’âˆ’
< 0.01ms
âˆ’âˆ’
4.d
âˆ’âˆ’
âˆ’âˆ’
< 0.01s
4.e
âˆ’âˆ’
âˆ’âˆ’
17.26s
4.f
âˆ’âˆ’
âˆ’âˆ’
âˆ’âˆ’
4.g
46.15ms
âˆ’âˆ’
âˆ’âˆ’
5
138.08ms
âˆ’âˆ’
âˆ’âˆ’
6.a
âˆ’âˆ’
< 0.01ms
âˆ’âˆ’
6.b
30.61ms
âˆ’âˆ’
âˆ’âˆ’
6.c
âˆ’âˆ’
72.99ms
âˆ’âˆ’
7
âˆ’âˆ’
âˆ’âˆ’
âˆ’âˆ’
8
âˆ’âˆ’
âˆ’âˆ’
< 0.01s
(a) Performance of the RSA-DAAJoin
protocol.
Sign
Step
Host
TPM
bsn =âŠ¥bsn Ì¸
=âŠ¥bsn =âŠ¥bsn Ì¸
=âŠ¥
1.a
2.03ms 13.33ms
1.b
âˆ’âˆ’
1.28s
2.a
71.69ms
âˆ’âˆ’
2.b
âˆ’âˆ’
1.27s
3.a.i
âˆ’âˆ’
30.99s
3.a.ii
144.19ms
âˆ’âˆ’
3.b.i
0.04ms
âˆ’âˆ’
3.b.ii
âˆ’âˆ’
< 0.01s
3.c.i
âˆ’âˆ’
< 0.01s
3.c.ii
< 0.01ms
âˆ’âˆ’
4
âˆ’âˆ’
âˆ’âˆ’
Verify
Step
Verifier
bsn =âŠ¥bsn Ì¸
=âŠ¥
1
175.04ms
âˆ’âˆ’
2
3.99ms
âˆ’âˆ’
3
âˆ’âˆ’
13.31ms
4
1.61ms
âˆ’âˆ’
(b) Performance of the
RSA-DAASign/Verify protocols.
Join
Step
Issuer
Host
TPM
Issuer Request 1.14ms
âˆ’âˆ’
âˆ’âˆ’
TPM Response
âˆ’âˆ’
âˆ’âˆ’
2.77s
Issuer Response 4.16ms
âˆ’âˆ’
âˆ’âˆ’
TPM Open
âˆ’âˆ’
âˆ’âˆ’
1.12s
Host Verify
âˆ’âˆ’
46.08ms âˆ’âˆ’
(c) Performance of the ECC-DAAJoin
protocol.
Sign
Step
Host
TPM
bsn =âŠ¥bsn Ì¸
=âŠ¥bsn =âŠ¥bsn Ì¸
=âŠ¥
Start Sign 4.09ms
6.53ms
âˆ’âˆ’
TPM Sign
âˆ’âˆ’
3.34s
Verify
Step
Verifier
bsn =âŠ¥bsn Ì¸
=âŠ¥
Verify
47.19ms 48.31ms
(d) Performance of the
ECC-DAASign/Verify protocols.
One might argue this software-only approach makes little sense because a TPM
will typically be equipped with hardware accelerators for primitives such as RSA,
SHA1 and a PRNG. As a result, we stress that our results are indicative only:
we attempt to model the asymmetry that exists between entities in terms of

On the Design and Implementation of an Eï¬ƒcient DAA Scheme
235
computational ability, and give a relative comparison of the two schemes that
relates move directly to a software-based TPM [27].
Our implementation of both schemes was constructed using vanilla C with
assembly language fragments for performance-critical sections. Both use SHA-
256 as an underlying hash function with a counter-based iteration extending the
digest size where appropriate; rather than a cryptographically secure PRNG,
both implementations use the C LCG-based PRNG. Within both schemes we
take advantage of persistent state where possible: we avoid re-computation of
common intermediate results (e.g., between Step 5 and 6.b of RSA-DAA) via
caching. However, the clear advantage that exists in terms of computation is
counter-balanced by an implication for memory footprint that we ignore some-
what.
An important diï¬€erence is the algorithms used for exponentiation (resp. scalar
multiplication):
â€“ Within RSA-DAA and with k = 1 term, the Host, Issuer and Verifier
use sliding window (with w = 4) exponentiation; with k > 1 terms they
use Straussâ€™ method (or Shamirâ€™s trick) for multi-exponentiation. The more
constrained TPM platform also uses sliding window (with w = 4) exponen-
tiation when k = 1, but repeated single-exponentiation for k > 1.
â€“ Within ECC-DAA, all entities use (signed) sliding window (with w = 4)
scalar multiplication and group exponentiation; there are no instances of
multi-exponentiation.
We concede that aggressive specialisation and eï¬ƒcient (multi-)exponentiation
techniques (e.g., those described in detail by MÂ¨oller [25] and Avanzi [1]) would
yield improved results for both schemes.
The results are given in Tables 1. For each step in each protocol, we give
timings in milli-seconds on the Host, Issuer, Verifier or (simulated) TPM
platform as appropriate. The names for the diï¬€erent stages for the RSA-DAA
protocol are taken from the description in [5]. We again stress that the results are
indicative only, and they do not include hidden costs such as communication and
random number generation. Even so, one can draw several concrete conclusions:
â€“ Aside from performance, the results highlight that the RSA-DAA scheme is
signiï¬cantly more complicated in terms of the number of steps and interac-
tion between entities; we suggest that this hints at a higher communication
cost.
â€“ The performance of RSA-DAA has some signiï¬cant performance bottlenecks
in our software-only approach, particularly in terms of computation on the
TPM; the availability of hardware accelerators within makes this point moot
however. In contrast, the results indicate that our ECC-DAA scheme is fea-
sible using a software-only approach. As such, one can either view it as
removing the need for dedicated hardware in the TPM (e.g., for modular
arithmetic) or potentially being signiï¬cantly faster should similarly dedi-
cated hardware be available.

236
L. Chen, D. Page, and N.P. Smart
â€“ Our ECC-DAA scheme not only provides performance advantages for the
TPM, but also for the Issuer and Host. What is surprising is that even
though the veriï¬cation in our ECC-DAA scheme requires several pairing op-
erations, it is still faster than the equivalent RSA-DAA veriï¬cation operation
by some margin. In part, this is due to our eï¬ƒcient batching technique, and
the speciï¬c choice of pairings adopted.
â€“ Finally, we note that the security parameters for our ECC-DAA scheme
have been selected to be equivalent to a 128-bit AES security level. Thus,
on paper at least, our ECC-DAA scheme has a higher security margin than
the RSA-DAA scheme while still delivering the aforementioned performance
advantages.
References
1. Avanzi, R.M.: The complexity of certain multi-exponentiation techniques in cryp-
tography. Journal of Cryptology 18, 357â€“373 (2005)
2. Barreto, P.S.L.M., Naehrig, M.: Pairing-friendly elliptic curves of prime order. In:
Preneel, B., Tavares, S. (eds.) SAC 2005. LNCS, vol. 3897, pp. 319â€“331. Springer,
Heidelberg (2006)
3. Bellare, M., Garay, J., Rabin, T.: Fast batch veriï¬cation for modular exponen-
tiation and digital signatures. In: Nyberg, K. (ed.) EUROCRYPT 1998. LNCS,
vol. 1403, pp. 236â€“250. Springer, Heidelberg (1998)
4. Boneh, D., Boyen, X.: Sort signatures without random oracles. In: Cachin, C.,
Camenisch, J.L. (eds.) EUROCRYPT 2004. LNCS, vol. 3027, pp. 56â€“73. Springer,
Heidelberg (2004)
5. Brickell, E., Camenisch, J., Chen, L.: Direct anonymous attestation. In: Computer
and Communications Security â€“ CCS 2004, pp. 132â€“145. ACM Press, New York
(2004)
6. Brickell, E., Camenisch, J., Chen, L.: Direct anonymous attestation in context. In:
Mitchell, C. (ed.) Trusted Computing, ch. 5, pp. 143â€“174. IEEE, London (2005)
7. Brickell, E., Chen, L., Li, J.: Simpliï¬ed security notions for direct anonymous attes-
tation and a concrete scheme from pairings. Int. Journal of Information Security 8,
315â€“330 (2009)
8. Brickell, E., Chen, L., Li, J.: A new direct anonymous attestation scheme from
bilinear maps. In: Lipp, P., Sadeghi, A.-R., Koch, K.-M. (eds.) Trust 2008. LNCS,
vol. 4968, pp. 166â€“178. Springer, Heidelberg (2008)
9. Brickell, E., Li, J.: Enhanced privacy ID: A direct anonymous attestation scheme
with enhanced revocation capabilities. In: Privacy in the Electronic Society â€“
WPES 2007, pp. 21â€“30. ACM Press, New York (2007)
10. Brickell, E., Li, J.: Enhanced privacy ID from bilinear pairing. Cryptology ePrint
Archive. Report 2009/095, http://eprint.iacr.org/2009/095
11. Camenisch, J., Lysyanskaya, A.: Signature schemes and anonymous credentials
from bilinear maps. In: Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp.
56â€“72. Springer, Heidelberg (2004)
12. Chaum, D., van Heyst, E.: Group signatures. In: Davies, D.W. (ed.) EUROCRYPT
1991. LNCS, vol. 547, pp. 257â€“265. Springer, Heidelberg (1991)
13. Chen, L.: A DAA scheme requiring less TPM resources. In: Int. Conference on
Information Security and Cryptology - Inscrypt 2009 (2009) (to appear)

On the Design and Implementation of an Eï¬ƒcient DAA Scheme
237
14. Chen, L., Li, J.: A note on the Chen-Morrissey-Smart direct anonymous attestation
scheme (preprint)
15. Chen, L., Morrissey, P., Smart, N.P.: Pairings in trusted computing. In: Galbraith,
S.D., Paterson, K.G. (eds.) Pairing 2008. LNCS, vol. 5209, pp. 1â€“17. Springer,
Heidelberg (2008)
16. Chen, L., Morrissey, P., Smart, N.P.: On proofs of security of DAA schemes. In:
Baek, J., Bao, F., Chen, K., Lai, X. (eds.) ProvSec 2008. LNCS, vol. 5324, pp.
156â€“175. Springer, Heidelberg (2008)
17. Chen, L., Morrissey, P., Smart, N.P.: DAA: Fixing the pairing based protocols.
Cryptology ePrint Archive. Report 2009/198, http://eprint.iacr.org/2009/198
18. Chen, L., Cheng, Z., Smart, N.P.: Identity-based key agreement protocols from
pairings. Int. Journal of Information Security 6, 213â€“242 (2007)
19. Chen, X., Feng, D.: Direct anonymous attestation for next generation TPM. Jour-
nal of Computers 3, 43â€“50 (2008)
20. Galbraith, S., Paterson, K., Smart, N.P.: Pairings for cryptographers. Discrete
Applied Mathematics 156, 3113â€“3121 (2008)
21. Granger, R., Smart, N.P.: On computing products of pairings. Cryptology ePrint
Archive. Report 2006/172, http://eprint.iacr.org/2006/172
22. Hess, F., Smart, N.P., Vercauteren, F.: The Eta pairing revisited. IEEE Transac-
tions on Information Theory 52, 4595â€“4602 (2006)
23. ISO/IEC 11889: 2009 Information technology â€“ Security techniques â€“ Trusted Plat-
form Module (2009)
24. Lysyanskaya, A., Rivest, R., Sahai, A., Wolf, S.: Pseudonym systems. In: Heys,
H.M., Adams, C.M. (eds.) SAC 1999. LNCS, vol. 1758, pp. 184â€“199. Springer,
Heidelberg (2000)
25. MÂ¨oller, B.: Algorithms for multi-exponentiation. In: Vaudenay, S., Youssef, A.M.
(eds.) SAC 2001. LNCS, vol. 2259, pp. 165â€“180. Springer, Heidelberg (2001)
26. Trusted Computing Group. TCG TPM speciï¬cation 1.2 (2003),
http://www.trustedcomputinggroup.org
27. Strasser, M., Stamer, H.: A software-based trusted platform module emulator. In:
Lipp, P., Sadeghi, A.-R., Koch, K.-M. (eds.) Trust 2008. LNCS, vol. 4968, pp.
33â€“47. Springer, Heidelberg (2008)

Author Index
Agoyan, Michel
182
Akram, Raja Naeem
118
Barbu, Guillaume
148
Batina, Lejla
209
Chari, Suresh N.
49
Chen, Liqun
223
Chevallier-Mames, BenoË†Ä±t
24
Cogniaux, Geoï¬€roy
102
Coron, Jean-SÂ´ebastien
24
Courr`ege, Jean-Christophe
65
Diluoï¬€o, Vincenzo V.
49
Dutertre, Jean-Max
182
Feix, Benoit
65
Ferrari, Anthony
133
Garcia, Flavio D.
194
Giraud, Christophe
80, 164
Grimaud, Gilles
102
Guerin, Vincent
148
Herbst, Christoph
36
Hoepman, Jaap-Henk
209
Hutter, Michael
36
Jacobs, Bart
209
Joye, Marc
1
Karger, Paul A.
49
Kirschbaum, Mario
36
Knudsen, Erik W.
164
Luo, Qiasi
13
Markantonakis, Konstantinos
118
Mayes, Keith
118
McCullagh, Noel
24
Medwed, Marcel
36
Mostowski, Wojciech
209
Naccache, David
1, 24, 182
Page, Dan
223
Palmer, Elaine R.
49
Plos, Thomas
36
Porte, StÂ´ephanie
1
Rabin, Tal
49
Rao, Josyula R.
49
Robisson, Bruno
182
Rohotgi, Pankaj
49
Roussellet, Myl`ene
65
Scherzer, Helmut
49
Schmidt, JÂ¨orn-Marc
36
Scott, Michael
24
Smart, Nigel P.
223
Steiner, Michael
49
Thiebeauld, Hugues
148
Toll, David C.
49
Tria, Assia
182
Tunstall, Michael
164
van Rossum, Peter
194
Verneuil, Vincent
80
Vetillard, Eric
133
Vullers, Pim
209

