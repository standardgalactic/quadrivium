Signals and
Systems
Mahmood Nahvi
Emeritus Professor of Electrical Engineering
California Polytechnic State University
San Luis Obispo, California

SIGNALS AND SYSTEMS
Published by McGraw-Hill, a business unit of The McGraw-Hill Companies, Inc., 1221 Avenue of the
Americas, New York, NY, 10020. Copyright c⃝2014 by The McGraw-Hill Companies, Inc. All rights
reserved. Printed in the United States of America. No part of this publication may be reproduced or
distributed in any form or by any means, or stored in a database or retrieval system, without the prior
written consent of The McGraw-Hill Companies, Inc., including, but not limited to, in any network or other
electronic storage or transmission, or broadcast for distance learning.
The author and publisher have applied their best effort in preparing this book. They make no warranty with
regard to the material or programs contained in this book and shall not be liable to any damages
consequential to its publication.
Some ancillaries, including electronic and print components, may not be available to customers outside the
United States.
This book is printed on acid-free paper.
1 2 3 4 5 6 7 8 9 0 DOC/DOC 1 0 9 8 7 6 5 4 3
ISBN 978-0-07-338070-4
MHID 0-07-338070-9
Vice President and Editor-in-Chief: Marty Lange
Managing Director: Thomas Timp
Editorial Director: Michael Lange
Global Publisher: Raghothaman Srinivasan
Marketing Manager: Curt Reynolds
Development Editor: Katie Neubauer
Senior Project Manager: Lisa A. Bruﬂodt
Buyer: Nicole Baumgartner
Media Project Manager: Prashanthi Nadipalli
Cover Designer: Studio Montage, St. Louis, MO
Cover Image: c⃝Brand X Pictures/Punchstock; Photodisc/Punchstock
Typeface: 10/12 Times
Compositor: Cenveo Publisher Services
Printer: R. R. Donnelley
All credits appearing on page or at the end of the book are considered to be an extension of the copyright
page.
Library of Congress Cataloging-in-Publication Data
Nahvi, Mahmood.
Signals and systems / Mahmood Nahvi.
pages cm
Includes index.
ISBN 978-0-07-338070-4 (alk. paper)
1. Signal processing. I. Title.
TK5102.9.N34 2012
621.382’2–dc23
2012038055
The Internet addresses listed in the text were accurate at the time of publication. The inclusion of a website
does not indicate an endorsement by the authors or McGraw-Hill, and McGraw-Hill does not guarantee the
accuracy of the information presented at these sites.
www.mhhe.com

BRIEF CONTENTS
Preface
xvii
1
Introduction to Signals
1
2
Sinusoids
121
3
Systems, Linearity, and Time Invariance
157
4
Superposition, Convolution, and Correlation
203
5
Differential Equations and LTI Systems
259
6
The Laplace Transform and Its Applications
313
7
Fourier Series
377
8
Fourier Transform
427
9
System Function, the Frequency Response, and Analog Filters
487
10
Time-Domain Sampling and Reconstruction
623
11
Discrete-Time Signals
683
12
Linear Time-Invariant Discrete-Time Systems
733
13
Discrete Convolution
763
14
LTI Difference Equations
797
15
The z-Transform and Its Applications
827
16
Discrete-Time Fourier Transform
881
17
Discrete Fourier Transform
947
18
System Function, the Frequency Response, and Digital Filters
1005
Appendix
Electric Circuits
1093
Index
1107
v

CONTENTS
Preface
xvii
Chapter 1
Introduction to Signals
1
Introduction and Summary
2
1.1
Discrete Versus Continuous;
Digital Versus Analog
3
1.2
Deterministic Versus Random
5
1.3
Examples of Natural and
Societal Signals
6
1.4
Voice and Speech Signals
14
1.5
Communication Signals
16
1.6
Physiologic Signals
21
1.7
Electrocardiogram Signals
22
1.8
Electromyogram Signals
25
1.9
Electroencephalogram
Signals
26
1.10
Electrocorticogram Signals
28
1.11
Neuroelectric Signals from
Single Neurons
30
1.12
Applications of
Electrophysiologic Signals
32
1.13
Characterization and
Decomposition of Signals
32
1.14
Mathematical Representations
of Signals
35
1.15
Time Averages
48
1.16
Operations on Signals
51
1.17
Time Transformation
51
1.18
Even and Odd Functions
58
1.19
Integration and Smoothing
61
1.20
Weighted Integration
68
1.21
Window Averaging
71
1.22
Differentiation and Differences
73
1.23
Concluding Remarks
76
1.24
Problems
76
1.25
Project 1: Binary Signal in Noise
116
1.26
Project 2: Signals Stored as
Computer Data Files
120
Chapter 2
Sinusoids
121
Introduction and Summary
121
2.1
Sine and Cosine
122
2.2
Angles
123
2.3
Series Approximations
124
2.4
Trigonometric Identities
and Relations
125
2.5
Sinusoidal Waveforms
126
2.6
Sine or Cosine?
128
2.7
Period and Frequency
128
2.8
Phasors
129
2.9
Lag and Lead
129
2.10
Time Shift and Phase Shift
130
2.11
Summing Phasors
130
2.12
Combination of Sinusoids
131
2.13
Combination of Periodic
Signals
132
2.14
Representation of a Sum
of Sinusoids
132
2.15
Power in a Sinusoid
133
2.16
One-Sided Line Spectrum
134
vii

viii
Contents
2.17
Complex Representation
of Sinusoids and the
Two-Sided Spectrum
136
2.18
Problems
137
2.19
Project: Trajectories, Wave
Polarization, and Lissajous
Patterns
151
Chapter 3
Systems, Linearity, and
Time Invariance
157
Introduction and Summary
157
3.1
Formulation of Equations
159
3.2
Classiﬁcations of Systems
160
3.3
Causality
162
3.4
Linearity, Time Invariance,
and LTI Systems
162
3.5
Derivative and Integral
Properties of LTI Systems
166
3.6
Examples from Electric
Circuits
166
3.7
Examples from Other Fields
172
3.8
Response of LTI Systems
to Impulse and Step Inputs
175
3.9
Response of LTI Systems
to Exponential Inputs
176
3.10
Response of LTI Systems
to Sinusoids
178
3.11
Use of Superposition
and Other Properties
of LTI Systems
179
3.12
LTI Systems and Fourier
Analysis
181
3.13
Analysis and Solution Methods
for LTI Systems
182
3.14
Complex Systems
183
3.15
Neuronal Systems
184
3.16
Problems
188
3.17
Project: Open-Loop Control
200
Chapter 4
Superposition, Convolution, and
Correlation
203
Introduction and Summary
203
4.1
Superposition of Responses
204
4.2
Convolution Sum
211
4.3
Convolution Integral
214
4.4
Graphical Convolution
217
4.5
Properties of Convolution
222
4.6
Filtering by Convolution
226
4.7
Matched Filter
228
4.8
Deconvolution
231
4.9
Autocorrelation
233
4.10
Cross-Correlation
237
4.11
Correlation and Convolution
240
4.12
Concluding Remarks
241
4.13
Problems
242
4.14
Project: Signal Detection
by Matched Filter
255
Chapter 5
Differential Equations and LTI
Systems
259
Introduction and Summary
260
5.1
Formulation of Differential
Equations
260
5.2
Solution in the Time Domain
by the Classical Method
270
5.3
The Particular Solution
272
5.4
The Homogeneous Solution
274
5.5
Composing the Complete
Solution
275

Contents
ix
5.6
Examples of Complete
Solutions
275
5.7
Special Case: Multiple
Roots
279
5.8
When the Input Contains
Natural Frequencies
280
5.9
When the Natural Response
May Be Absent
281
5.10
Response to an Exponential
Input
282
5.11
The System Function
283
5.12
Sinusoidal Steady-State
Response
284
5.13
Unit-Step Response
285
5.14
Unit-Impulse Response
288
5.15
Effect of Discontinuity in the
Forcing Function
290
5.16
Solution by Convolution
293
5.17
Zero-Input and Zero-State
Responses
295
5.18
Zero-State Response and
Convolution
298
5.19
Properties of LTI Differential
Equations
299
5.20
Solution by Numerical
Methods
299
5.21
Concluding Remarks
300
5.22
Problems
301
5.23
Project: System of Differential
Equations
310
Chapter 6
The Laplace Transform and
Its Applications
313
Introduction and Summary
314
6.1
Deﬁnition of the Laplace
Transform
315
6.2
Linearity Property
317
6.3
Examples of the Unilateral
Laplace Transform
317
6.4
Differentiation and Integration
Properties
320
6.5
Multiplication by t
323
6.6
Multiplication by eat
324
6.7
Time-Shift Property
324
6.8
Scale Change
325
6.9
Convolution Property
325
6.10
Initial-Value and Final-Value
Theorems
327
6.11
Lower Limit of Integration:
0−, 0, 0+
328
6.12
Laplace Transform of the Unit
Impulse
328
6.13
The Inverse Laplace
Transform
329
6.14
Partial Fraction Expansion;
Simple Poles
331
6.15
Partial Fraction Expansion;
Multiple-Order Poles
335
6.16
Summary of the Laplace
Transform Properties and
Theorems
336
6.17
A Table of Unilateral Laplace
Transform Pairs
337
6.18
Circuit Solution
338
6.19
Solution of Dynamical
Equations
340
6.20
Bilateral Laplace Transform
343
6.21
Region of Convergence of the
Bilateral Laplace Transform
346
6.22
Properties of the Bilateral Laplace
Transform
348
6.23
Inverse of the Bilateral Laplace
Transform
349

x
Contents
6.24
A Table of Bilateral Laplace
Transform Pairs
353
6.25
System Function
354
6.26
Comprehensive Examples
356
6.27
Concluding Remarks
361
6.28
Problems
361
6.29
Project: Pulse-Shaping Circuit
375
Chapter 7
Fourier Series
377
Introduction and Summary
377
7.1
Signal Synthesis
379
7.2
Fourier Series Expansion
383
7.3
The Generalized Fourier Series
and Vectorial Representation
of Signals
384
7.4
Dirichlet Conditions and
Beyond
385
7.5
Trigonometric Fourier Series
386
7.6
Exponential Fourier Series
391
7.7
Properties of Fourier Series
393
7.8
Time Reversal and Shift
394
7.9
Conjugate Symmetry
395
7.10
Waveform Symmetry
396
7.11
Time Averages
397
7.12
Pulses and Impulses
398
7.13
Convergence of the Fourier
Series
404
7.14
Finite Sum
405
7.15
Gibbs’ Phenomenon
406
7.16
Extension of Fourier Series
to Transforms
408
7.17
Envelope of Fourier Coefﬁcients
410
7.18
Concluding Remarks
411
7.19
Problems
412
7.20
Project: Computer Explorations in
Fourier Analysis
423
Chapter 8
Fourier Transform
427
Introduction and Summary
428
8.1
Fourier Transform of Energy
Signals
429
8.2
Inverse Fourier Transform
430
8.3
Examples of Fourier Transform
Pairs
430
8.4
Linearity Property
433
8.5
Conjugate Symmetry
434
8.6
Time Reversal
434
8.7
Waveform Symmetry
435
8.8
Even and Odd Parts
of Functions
437
8.9
Causal Functions
439
8.10
Time-Frequency Duality
441
8.11
Time Shift
442
8.12
Frequency Shift
443
8.13
Differentiation and Integration
444
8.14
Convolution Property
444
8.15
Product Property
445
8.16
Parseval’s Theorem and Energy
Spectral Density
446
8.17
Summary of Fourier Transform
Properties
447
8.18
Time-Limited Signals
447
8.19
Windowing
450
8.20
Band-Limited Signals
452
8.21
Paley-Wiener Theorem
453
8.22
Gibbs’ Phenomenon
454

Contents
xi
8.23
Fourier Transform of Power
Signals
456
8.24
Fourier Transform of Generalized
Functions
457
8.25
Impulse Function and
Operations
458
8.26
Fourier Transform of Periodic
Signals
460
8.27
Concluding Remarks
465
Appendix 8A A Short Table
of Fourier Transform Pairs
465
8.28
Problems
467
8.29
Project: Spectral Analysis
Using a Digital Oscilloscope
482
Chapter 9
System Function, the Frequency
Response, and Analog Filters
487
Introduction and Summary
488
9.1
What Is a System Function?
489
9.2
The Time Response May Be
Obtained from H(s)
494
9.3
The Frequency Response
H(ω)
496
9.4
Plotting H(ω)
500
9.5
Vectorial Interpretation of H(s)
and H(ω)
515
9.6
Second-Order Systems
518
9.7
Dominant Poles
521
9.8
Stability and Oscillations
526
9.9
Analog Filters
528
9.10
First-Order Low-Pass Filters
531
9.11
Integrators
534
9.12
First-Order High-Pass Filters
536
9.13
Differentiators
537
9.14
First-Order All-Pass Phase
Shifters
538
9.15
Lead and Lag Compensators
540
9.16
Summary of First-Order
Filters
544
9.17
Second-Order Low-Pass
Filters
544
9.18
Second-Order High-Pass
Filters
549
9.19
Second-Order Bandpass Filters
551
9.20
Second-Order Notch Filters
554
9.21
Second-Order All-Pass Filters
556
9.22
Contribution from a Zero
556
9.23
Series and Parallel RLC Circuits
557
9.24
Summary of Second-Order
Filters
559
9.25
Group and Phase Delay
560
9.26
Measurements, Identiﬁcation, and
Modeling
565
9.27
System Interconnection
566
9.28
Feedback
568
9.29
Pole-Zero Cancellation
579
9.30
Inverse Systems
582
9.31
Concluding Remarks
584
9.32
Problems
584
9.33
Project 1: RC/CR Passive
Bandpass Filter
606
Appendix 9A
612
Appendix 9B
612
9.34
Project 2: Active
Bandpass Filter
613
9.35
Project 3: An Active Filter with
Bandpass/Low-Pass Outputs
618
9.36
Project 4: Examples of Modeling
LTI Systems
621

xii
Contents
Chapter 10
Time-Domain Sampling
and Reconstruction
623
Introduction and Summary
623
10.1
Converting from Continuous Time
to Discrete
624
10.2
Mathematical Representation
of Sampling
627
10.3
Sampling and Reconstruction of
Strictly Low-Pass Signals
632
10.4
Sample and Hold
635
10.5
Sampling Nearly Low-Pass
Signals
638
10.6
Aliasing and Leakage
642
10.7
Frequency Downshifting
644
10.8
Summary of Sampling and
Reconstruction Process
650
10.9
Complex Low-Pass Signals
651
10.10 Bandpass Signals and Their
Sampling
653
10.11 Reconstruction of Bandpass
Signals
658
Appendix 10A Additional
Notes on Sampling
661
10.12 Problems
662
10.13 Project 1: Sampling Neuroelectric
Signals
677
10.14 Project 2: Time-Domain
Sampling
677
Chapter 11
Discrete-Time Signals
683
Introduction and Summary
684
11.1
Domain and Range of Discrete
Signals
684
11.2
Actual Signals and Their
Mathematical Models
685
11.3
Some Elementary Functions
686
11.4
Summary of Elementary
Functions
691
11.5
Periodicity and Randomness
691
11.6
Examples of Periodic Signals
694
11.7
Sources of Discrete Signals
696
11.8
Representation of Discrete
Signals
697
11.9
Digital Signals
699
11.10 Energy and Power Signals
700
11.11 Time Reversal
700
11.12 Time Shift
703
11.13 Combination of Time Reversal
and Shift
704
11.14 Time Scaling and
Transformation
706
11.15 Circular Shift
708
11.16 Even and Odd Functions
709
11.17 Windows
713
11.18 Signal Processing and
Filtering
715
11.19 Problems
718
11.20 Project: An Introduction
to Discrete-Time Signal
Processing
728
Chapter 12
Linear Time-Invariant
Discrete-Time Systems
733
Introduction and Summary
733
12.1
Linear Time-Invariant (LTI)
Discrete-Time Systems
734
12.2
The Unit-Sample Response
737
12.3
Response of LTI Discrete-Time
Systems to Power Signals
and Sinusoids
741

Contents
xiii
12.4
Some Properties and Classiﬁcations
of Discrete-Time LTI Systems
743
12.5
Discrete LTI Operators and
Difference Equations
745
12.6
Block Diagram
Representation
747
12.7
Analysis and Solution
Methods
751
12.8
Problems
752
12.9
Project: Deadbeat Control
758
Chapter 13
Discrete Convolution
763
Introduction and Summary
763
13.1
Linear Convolution and LTI
Systems
764
13.2
Properties of Convolution
765
13.3
Solution by Numerical
Method
766
13.4
Product Property
768
13.5
Solution by Analytical
Method
771
13.6
Graphical Convolution
774
13.7
Convolution in Linear
Time-Varying Systems
779
13.8
Deconvolution
783
13.9
Inverse Systems
784
13.10 Problems
787
13.11 Project: Deconvolution and
Inverse Systems
792
Chapter 14
LTI Difference Equations
797
Introduction and Summary
797
14.1
What Is a Difference
Equation?
798
14.2
Numerical Solution
799
14.3
Analytic Solution in the
n-Domain
800
14.4
The Homogeneous Solution
801
14.5
The Particular Solution
802
14.6
The Total Solution
803
14.7
Special Cases, Repeated Roots
804
14.8
Properties of LTI Difference
Equations
805
14.9
Response to zn
805
14.10 Response to the Complex
Exponentials and Sinusoids
805
14.11 Unit-Step Response, g(n)
806
14.12 Unit-Sample Response, h(n)
807
14.13 Relation Between h(n) and
g(n)
808
14.14 Use of Superposition
809
14.15 Zero-Input and Zero-State
Responses
811
14.16 A Nonlinear Time-Varying
Difference Equation
812
14.17 Problems
813
14.18 Project: Low-Pass Filtering
by Difference Equation
825
Chapter 15
The z-Transform and Its
Applications
827
Introduction and Summary
827
15.1
Deﬁnition of the z-Transform
828
15.2
Region of Convergence
829
15.3
More Examples
832
15.4
Properties of the z-Transform
836
15.5
Inverse z-Transform
842

xiv
Contents
15.6
Partial Fraction Expansion
Method
843
15.7
Application to Difference
Equations
848
15.8
Application to the Analysis of
LTI Systems
850
15.9
One-Sided z-Transform
852
15.10 Evaluating the Inverse
z-Transform by the Residue
Method
854
15.11 Relationship Between the s- and
z-Planes
859
Appendix 15A Table of
z-Transform Properties
and Theorems
865
Appendix 15B Table of
z-Transform Pairs
866
15.12 Problems
867
15.13 Project 1: FIR Filter Design
by Zero Placement
874
15.14 Project 2: IIR Filter Design
by Pole-Zero Placement
877
Chapter 16
Discrete-Time Fourier Transform
881
Introduction and Summary
881
16.1
Deﬁnitions
883
16.2
Examples of DTFT
885
16.3
The DTFT and the
z-Transform
889
16.4
Examples of IDTFT
890
16.5
Rectangular Pulse
893
16.6
DTFT Theorems and
Properties
895
16.7
Parseval’s Theorem and Energy
Spectral Density
900
16.8
DTFT of Power Signals:
The Limit Approach
902
16.9
DTFT of Periodic Signals:
The Convolution Approach
906
16.10 Zero-Insertion
909
16.11 Decimation
912
16.12 Interpolation
918
16.13 How Rate Conversion
Reshapes DTFT
920
Appendix 16A Short Table of
DTFT Pairs
923
Appendix 16B Symmetry Properties of
the DTFT
924
Appendix 16C Summary of
DTFT Theorems
925
16.14 Problems
926
16.15 Project 1: Windows
939
16.16 Project 2: Decimation and
Frequency Downshifting
944
Chapter 17
Discrete Fourier Transform
947
Introduction and Summary
947
17.1
Deﬁnitions
948
17.2
Examples of the DFT
948
17.3
Examples of the IDFT
954
17.4
Time Reversal and Circular
Shift
956
17.5
Circular Convolution
961
17.6
Properties of the DFT
963
17.7
Relation Between the DFT
and DTFT
968
17.8
Fast Fourier Transform (FFT)
971
17.9
Linear Convolution from
Circular
974
17.10 DFT in Matrix Form
978
17.11 Conclusions: FS, FT, DTFT,
and DFT
981

Contents
xv
17.12 Problems
983
17.13 Project: DFT Spectral Analysis
993
Chapter 18
System Function, the Frequency
Response, and Digital Filters
1005
Introduction and Summary
1005
18.1
The System Function H(z)
1006
18.2
Poles and Zeros
1011
18.3
The Frequency Response
H(ω)
1015
18.4
Vectorial Interpretation of H(z)
and H(ω)
1025
18.5
Transforming Continuous Time
to Discrete Time
1029
18.6
Digital Filters
1036
18.7
Simple Filters
1039
18.8
Filter Design
1044
18.9
Filter Design by Pole-Zero
Placement
1046
18.10 FIR Filter Design
1047
18.11 IIR Filter Design
1052
18.12 Filter Structures
1055
18.13 Problems
1060
18.14 Project 1: FIR Filter Design by
Windowing
1081
18.15 Project 2: Discrete-Time Modeling
and Control of a Dynamic
System
1084
18.16 Project 3: Modeling a Random Trace
Generator
1090
Appendix
ElectricCircuits
1093
Index
1107

PREFACE
The subject of signals and systems is a requirement in undergraduate electrical and
computer engineering programs. The subject provides the student a window through
which he or she can look into and examine the ﬁeld. In addition, it provides the necessary
background for more specialized subjects, including communication, control, and signal
processing. Several other engineering majors offer similar courses in the same subject
matter.
This book is designed to serve as the primary textbook for a course in signals and
systems at the junior undergraduate level. It is to be used mainly in the electrical, elec-
tronics, and computer engineering programs but is also appropriate for other engineering
majors. It may be used in a one- or two-semester or two-quarter sequence according to the
criteria of the curriculum and depending on an appropriate selection of material which
meets the needs and backgrounds of students.
This book treats the continuous- and discrete-time domains separately in two parts.
Part One (Chapters 1–9) covers continuous-time signals and systems; Part Two
(Chapters 10–18) covers discrete-time signals and systems. Both parts stand alone
and can be used independently of each other. This allows instructors to use the text
for instruction on either domain separately, if desired. The book may also be used for
courses that teach the two domains simultaneously in an integrated way, as the chapters
in Parts One and Two provide parallel presentations of each subject. The parallelism
of the chapters on the continuous- and discrete-time domains facilitates the integra-
tion of the two parts and allows for ﬂexibility of use in various curricula. The chapter
topics and the parallelism between the time-domain treatments are listed in the table
below.
Part One, Continuous-Time Domain
Part Two, Discrete-Time Domain
Chapter
Topic
Chapter
Topic
1
Introduction to Signals
10
Time-Domain Sampling and Reconstruction
2
Sinusoids
11
Discrete-Time Signals
3
Systems, Linearity, and Time Invariance
12
Linear Time-Invariant Discrete-Time Systems
4
Superposition, Convolution, and Correlation
13
Discrete Convolution
5
Differential Equations and LTI Systems
14
LTI Difference Equations
6
The Laplace Transform and Its Applications
15
The z-Transform and Its Applications
7
Fourier Series
16
Discrete-Time Fourier Transform
8
Fourier Transform
17
Discrete Fourier Transforms
9
System Function, the Frequency Response,
18
System Function, the Frequency Response,
and Analog Filters
and Digital Filters
Whether the subject of signals and systems in the continuous- and discrete-time
domains is taught separately or in integrated form, the present organization of the book
provides both pedagogical and practical advantages. A considerable part of the subject
matter in signals and systems is on analysis techniques (such as solution methods in the
time and frequency domains) which, although conceptually similar, use different tools.
xvii

xviii
Preface
Introducing the tools and applying them separately simpliﬁes the structure of the course.
Another advantage of the present organization is that the analyses of signals and systems
in the continuous- and discrete-time domains can stand on their own (both conceptually
and in terms of analysis tools). Each domain may be taught without requiring the other.
Thus, for programs that are designed to offer a DSP course, the discrete-time part of the
book will satisfy the prerequisites of such a course.
Each part begins with the introduction of signals and their models in the time do-
main. It then deﬁnes systems, linearity, and time invariance, along with examples. Time-
domain solution methods, such as convolution and differential/difference equations, are
presented next, followed by the transform domains. These are brought together in cap-
stone chapters on the system function and frequency response. Chapter 10 on sampling
provides a bridge between the continuous- and discrete-time domains.
Each chapter is made of sections and no subsections. Each section addresses a
single discussion item, starting with the introduction of a topic, mathematical tools
used to address that topic, the application of those tools, and one or two examples. To
a large extent, therefore, each section is a learning unit and can provide the student
with a concluding marker in learning the subject. In that sense the sections are modular
and convenient for instruction. The modular organization of the book provides a direct
approach and an effective tool for learning the fundamentals of signals and systems. As
a vehicle for lectures, 5 to 10 essential sections may be covered in an hour, while others
may be assigned as outside reading or homework.
Reference to other sections, ﬁgures, formulas, and other chapters is kept to a min-
imum. This provides easy and direct access to material, a feature much preferred by
students and instructors. The modular structure of the chapters and sections also makes
the book a convenient tool for instructional needs in a wide range of teaching scenarios
at various levels of complexity.
Illustrative examples, end-of-chapter problems, and supplementary problems with
solutions comprise other important components of the book. The book contains a total
of nearly 475 examples, 175 problems with solutions, and 750 end-of-chapter problems.
The examples and problems are of two types: (1) mathematical analyses and exercises
that represent abstractions of engineering subjects and (2) contextual problems, such
as those seen in electric circuits and devices, communication, and control. For the EE
and CPE student these subjects provide a context to convey and develop fundamental
concepts in signals and systems.
Examples from familiar signals and tangible systems in engineering can illustrate the
utility of the relevant mathematical analysis. They can make the subject more attractive
and generate motivation. In accordance with the above pedagogy, the book assumes
that the reader is familiar with the operation of basic circuits and devices (such as
passive RLC circuits and active circuits including dependent sources and operational
ampliﬁer models) and uses these to illustrate and reinforce the mathematical concepts.
It also assumes familiarity with elementary trigonometric functions, complex numbers,
differentiation/integration, and matrices. The Appendix at the end of the book can be
used to refresh the reader’s memory on electric circuits.

Preface
xix
ORGANIZATION OF CHAPTERS
The detailed outline of the ﬁrst part, covering signals and systems in the continuous-time
domain, is as follows.
Chapter 1 introduces various signal types (such as those that are natural, societal, or
human-made)andtheirmodels.Itshowsthat,asfunctionsoftime,signalsarespeciﬁedby
a wide set of parameters and characteristics (e.g., rate of change, time course, periodicity,
and ﬁne, coarse, and nested-loops structures). Time averages are discussed, along with
some simple operations on signals.
Chapter 2 is on sinusoids and contains a review of basic trigonometry. The examples
in this chapter employ simple sinusoids in illustrating some topics of practical interest
such as phase and group delay, power, and more.
Chapter 3 introduces the deﬁnitions of linearity and time invariance. Examples teach
the student how to test for these properties. This initial chapter is not intended to cover all
properties of LTI systems, but only as much as is needed at this stage in such a course on
signals and systems. More exposure will be provided throughout other parts of the book.
Chapter 4 discusses the time-domain solution of LTI systems by convolution. Convo-
lution of a system’s unit-impulse response with the input produces the system’s response
to that input. The chapter starts with convolution as a method of obtaining the response
of a linear system. It uses the linearity and superposition properties to develop the convo-
lution sum and integral. It then illustrates their evaluation by numerical, analytical, and
graphical methods. The ﬁltering property of convolution is explained next. The chapter
also brieﬂy touches on deconvolution. This latter concept is brought up in future chapters
on solutions in the frequency domain.
Chapter 5 presents the time-domain solution of LTI systems by an examination of
their describing differential equations in classical form. Parallels are drawn between
the homogeneous and particular components of the total solution and the familiar com-
ponents in the response of physical systems; that is, the natural and forced parts of the
response from system analysis and design. The homogeneous and particular components
of the total solution are then also related to the zero-input and zero-state responses. An
example of a numerical computation of a response is provided at the end of the chapter.
Chapter 6 analyzes the solution of LTI systems by the Laplace transform in the
frequency domain. Both the unilateral and bilateral forms of the transform are considered.
The ﬁrst half of the chapter focuses on the unilateral version, its inverse evaluation by the
partial fraction expansion method, and some applications. The residue method of ﬁnding
the inverse is also presented. The second half addresses the bilateral Laplace transform
and its inverse. Comprehensive examples demonstrate how to obtain the response of an
LTI system by the frequency domain approach and observe parallels with those in the
time domain.
Chapters 7 and 8 are on Fourier analysis in the continuous-time domain. Chapter
7 discusses the Fourier series expansion of periodic signals, in both trigonometric and
exponential forms, and visualizes methods of extending the expansion to nonperiodic
signals, which is a topic presented in detail in Chapter 8. Introduction of the impulse
function in the frequency domain provides a uniﬁed method of Fourier analysis for a

xx
Preface
large class of signals and systems. The convolution property of the Fourier transform
enables system analysis in the frequency domain. The frequency variable f (or ω) in
that analysis is more reminiscent of the actual real-world physical frequency than the
complex frequency shown by s in the method of Laplace transforms.
Chapter 9 envisions a multiangle capstone perspective of the analysis methods pre-
sented up to this point. It introduces the system function, poles and zeros, the frequency
response, and Bode plots. It then explains their relationships to each other and to the
time-domain characteristics of a system. A vectorial interpretation of the system function
and frequency response is included in order to help provide a qualitative understanding of
the system’s characteristics. Modeling a system by its dominant poles is then discussed
in sufﬁcient detail and illustrated by examples for ﬁrst- and second-order systems. In-
terconnections between systems and the concept of feedback are then covered. Finally,
the chapter concludes with a brief review of the effect of feedback on system behavior,
along with an example of controller design.
The detailed outline of the second part of the book, covering signals and systems in
the discrete-time domain, is as follows.
Chapter 10 is on the time-domain sampling of continuous-time signals and their re-
construction. It uses Fourier transform techniques and properties developed for
continuous-time signals in Chapter 8 in order to derive the minimum sampling rate
and a method for the error-free reconstruction of low-pass signals. The continuous-time
signals used in the examples of this chapter are mostly built around 1 Hz to coincide,
without loss of generality, with the normalized frequency encountered in the Fourier
analysis of discrete-time signals in the second part of the book. The effects of sampling
rate, the reconstruction ﬁlter, nearly low-pass signals, and the aliasing phenomenon are
discussed. The chapter also extends the presentation to sampling and reconstruction of
complex low-pass and bandpass signals.
Chapters 11 and 12 introduce discrete-time signals and LTI systems in a way that
parallels the discussions in Chapters 1 and 3.
The discrete convolution and difference equations are discussed in Chapters 13 and
14. In these chapters, as in Part One, in addition to developing quantitative analytical tech-
niques the text also aims to develop the student’s intuitive sense of signals and systems.
Chapter 15 is on the z-transform and parallels the Laplace transform in providing a
frequency domain analysis of discrete-time signals and systems. However, the chapter
starts with the bilateral transform and its applications to signals and systems and then
proceeds to the unilateral transform. The z-transform is normally deﬁned on its own.
However,itisrelatedtotheLaplacetransformandcanbederivedfromit.Therelationship
between these two transforms is explained in the chapter.
Chapters 16 and 17 discuss the discrete-time Fourier transform (DTFT) and the
discrete Fourier transform (DFT). As is true of the z-transform, they can be deﬁned
on their own or be derived as extensions of the Fourier transform for continuous-time
signals. Primary emphasis is given to the DTFT and DFT as stand-alone operations with
a secondary reminder of their relationship to the Fourier transform for continuous-time
signals. Having introduced the DTFT as an analysis tool, Chapter 16 introduces the
concepts of decimation, interpolation, and sampling rate conversion. These concepts
have a special place in discrete-time signal processing.

Preface
xxi
Chapter 18 is the discrete-time counterpart to Chapter 9. It encapsulates the system
function, poles and zeros, and the frequency response. It includes an introduction to
digital ﬁlters with relevant examples.
The book includes an appendix on the basics of electric circuit analysis.
PROJECTS
As a concept, projects cannot only reinforce a theory learned but also motivate it. Ideally,
they have the most impact on learning when most of their formulation and solution steps
arelefttothestudent.Withtheseideasinmind,eachchapterincludesoneormoreprojects
germane to the subject of that chapter. These projects present self-contained theory and
procedures that lead the student toward expected results and conclusions. Most projects
are designed to be carried out in a laboratory with basic measurement instruments. They
can also be implemented by using a simulation package such as Matlab. It is, however,
recommended that they be done in a real-time laboratory environment whenever possible.
For example, despite its simplicity, a simple passive RLC circuit can demonstrate many
features of ﬁrst- and second-order systems. Similarly, time and frequency responses,
system function, oscillations, and the stability of systems can best be explored using an
actual op-amp circuit.
PEDAGOGY
The book is designed with the following pedagogical features in mind.
1.
One learns from being exposed to examples, each of which addresses a single,
not-too-complicated question. The examples should be easy to grasp, relevant, and
applicable to new scenarios.
2.
One learns by doing, whether using paper and pencil, computer tools, projects, or
laboratory experiments employing hardware. This leads students to search,
explore, and seek new solutions. This point, along with the previous one, helps
them develop their own methods of generalization, concept formation, and
modeling.
3.
One learns from exposure to a problem from several angles. This allows for the
analysis of a case at various levels of complexity.
4.
One needs to develop a qualitative and intuitive understanding of the principles
behind, applications of, and solutions for the particular problem at hand. This is to
supplement the quantitative and algorithmic method of solving the problem.
5.
One beneﬁts a great deal from gradual learning; starting from what has
already been learned, one builds upon this foundation using familiar tools. In order
to discuss a complex concept, one starts with the discussion and use of a simpler
one upon which the former is based. An example would be introducing and using
mathematical entities such as the frequency-domain variables s and z initially as
complex numbers in exponential functions. The student ﬁrst becomes familiar with
the role the new variables play in the analysis of signals and systems before moving
on to the Laplace and z-transforms. Another example would be the frequency

xxii
Preface
response, a concept that can be developed within the existing realm of sinusoids
and as an experimentally measurable characteristic of a system, as opposed to the
more mathematical formulation of evaluating the system function on the imaginary
axis of the complex plane. Yet another example would be the convolution
integral, which can initially be introduced as a weighted averaging process.
ACKNOWLEDGMENTS
The author is indebted to many faculty colleagues who reviewed the manuscript and
provided valuable comments and suggestions. Reza Nahvi also contributed to the book
signiﬁcantly during its various stages. I also wish to acknowledge the expertise and as-
sistance of the project team at McGraw-Hill Higher Education, especially global brand
manager Raghothaman Srinivasan, executive marketing manager Curt Reynolds, devel-
opmental editor Katie Neubauer, and senior project manager Lisa Bruﬂodt. I thank them
all for making this book possible.
Permissions were granted for the use of material from the following sources, whose
details are given within the text:
Experimental Brain Research, Elsevier Inc.
Experimental Neurology, Springer Inc.
Squire, L. et al ed. Fundamental Neuroscience, Elsevier Inc. 2008.
Data from the following sources were used in constructing several ﬁgures, details for
which are given within the text.
National Geophysical Data Center (NGDC), www.ngdc.noaa.gov.
Dr. Pieter Tans, NOAA/ESRL (www.esrl.noaa.gov/gmd/ccgg/trends/) and Dr.
Ralph Keeling, Scripps Institution of Oceanography (scrippsco2.ucsd.edu).
Northern California Earthquake Data Center and Berkeley Seismological
Laboratory, University of California, Berkeley, www.ncedc.org.
Bureau of Labor Statistics, www.bls.gov.
ONLINE RESOURCES
INSTRUCTOR AND STUDENT WEBSITE
Available at www.mhhe.com/nahvi 1e are a number of additional instructor and student
resources to accompany the text. These include solutions for end-of-chapter problems
and lecture PowerPoints. The site also features COSMOS, a complete online solutions
manual organization system that allows instructors to create custom homework, quizzes,
and tests using end-of-chapter problems from the text.

Preface
xxiii
This text is available as an eBook at www.CourseSmart.com. At CourseSmart your
students can take advantage of signiﬁcant savings off the cost of a print textbook, reduce
their impact on the environment, and gain access to powerful web tools for learning.
CourseSmart eBooks can be viewed online or downloaded to a computer.
The eBooks allow students to do full text searches, add highlighting and notes, and
share notes with classmates. CourseSmart has the largest selection of eBooks available
anywhere. Visit www.CourseSmart.com to learn more and to try a sample chapter.
Craft your teaching resources to match the way you teach! With McGraw-Hill Create,
www.mcgrawhillcreate.com, you can easily rearrange chapters, combine material from
other content sources, and quickly upload content you have written like your course
syllabus or teaching notes. Find the content you need in Create by searching through thou-
sands of leading McGraw-Hill textbooks. Arrange your book to ﬁt your teaching style.
Create even allows you to personalize your book’s appearance by selecting the cover and
addingyourname,school,andcourseinformation.OrderaCreatebookandyou’llreceive
a complimentary print review copy in three to ﬁve business days or a complimentary elec-
tronic review copy (eComp) via e-mail in minutes. Go to www.mcgrawhillcreate.com
today and register to experience how McGraw-Hill Create empowers you to teach your
students your way.

Chapter1
Introduction to
Signals
Contents
Introduction and Summary
2
1.1
Discrete Versus Continuous; Digital Versus Analog
3
1.2
Deterministic Versus Random
5
1.3
Examples of Natural and Societal Signals
6
1.4
Voice and Speech Signals
14
1.5
Communication Signals
16
1.6
Physiologic Signals
21
1.7
Electrocardiogram Signals
22
1.8
Electromyogram Signals
25
1.9
Electroencephalogram Signals
26
1.10
Electrocorticogram Signals
28
1.11
Neuroelectric Signals from Single Neurons
30
1.12
Applications of Electrophysiologic Signals
32
1.13
Characterization and Decomposition of Signals
32
1.14
Mathematical Representations of Signals
35
1.15
Time Averages
48
1.16
Operations on Signals
51
1.17
Time Transformation
51
1.18
Even and Odd Functions
58
1.19
Integration and Smoothing
61
1.20
Weighted Integration
68
1.21
Window Averaging
71
1.22
Differentiation and Differences
73
1.23
Concluding Remarks
76
1.24
Problems
76
1.25
Project 1: Binary Signal in Noise
116
1.26
Project 2: Signals Stored as Computer Data Files
120
1

2
CHAPTER 1
Introduction to Signals
Introduction and Summary
A major part of this book is about signals and signal processing. In the conventional sense,
signals are elements of communication, control, sensing, and actuation processes.They
convey data, messages, and information from the source to the receiver and carry com-
mands to inﬂuence the behavior of other systems. Radio, television, telephone, and
computer communication systems use time-varying electromagnetic ﬁelds as signals.
Command, control, and communication centers also use electromagnetic signals. Living
systems employ sensory signals such as acoustic, visual, tactile, olfactory, or chemical.
They also send signals by motion of their body parts such as the arms, hands, and
face. The presence or unexpected absence of such signals is then detected by other
living systems with whom communication is made. Neurons of the nervous system
communicate with other neurons and control activity of muscles by electrical signals.
Another group of signals of interest are those that represent variations of economic and
societal phenomena (e.g., historical unemployment rate, stock market prices, and in-
dexes such as the Dow Jones Industrial Average, median prices of houses, the federal
funds interest rate, etc.). Still another group of signals of interest represent natural phe-
nomena (pressure, temperature, and humidity recorded by weather stations, number of
sunspots, etc.).
Signals, Information, and Meaning
As an element of communication and control processes, a signal is strongly related
to other concepts such as data, codes, protocols, messages, information, and meaning.
However, our discussion of signals and signal processing will be, to a large degree,
conﬁned outside of the context of such facets attached to a signal.
Signals and Waveforms
In this book a signal is a time-varying waveform. It may be an information-carrying
element of a communication process that transmits a message. It may be the unwanted
disturbance that interferes with communication and control processes, distorts the mes-
sage, or introduces errors. It may represent observations of a physical system and our
characterizations of it regardless of its inﬂuence (or lack thereof) on other systems.
We are interested in signals used in ﬁelds such as electrical communication, speech,
computer and electronics, electromechanical systems, control systems, geophysical sys-
tems, and biomedical systems. Such signals represent variations of physical phenomena
such as air pressure, electric ﬁeld, light intensity and color in a visual ﬁeld, vibrations
in a liquid or solid, and so on. These signals are waveforms that depend on one or more
variables such as time or space. (For example, a speech signal is a function of time but
can also vary as a function of another variable such as space, if it is multiply recorded at
several locations or if the microphone is moved around relative to the speaker. Geophysi-
cal signals are another set of such examples. Weather data collected at various stations at
various times are still another such set.) The words signals and waveforms are, therefore,
often used interchangeably.

Signals and Systems
3
Signals and Functions
We represent signals by mathematical functions. To this end, we often use the words
signals, waveforms, and functions synonymously. Some simple elementary functions
used in the mathematical representation of signals are steps, impulses, pulses, sinosoids,
and exponentials. These are brieﬂy described in section 1.14 of this chapter. Sinusoids
are of special interest in signal analysis. They are treated in detail in the next chapter.
The chapter aims at achieving two interrelated goals. First, it presents the reader
with a qualitative landscape of signals of common interest by giving actual examples
such as natural, societal, ﬁnancial, voice and speech, communication, and bioelectric
signals. Second, in order to prepare the reader for the analytical conversation carried
on throughout the book, it introduces, in detail, signal notations and elementary math-
ematical functions of interest (such as step, impulse, exponential, sinusoid, sinc, pulse,
windows), and their basic properties such as the time average, even and odd parts, causal-
ity, and periodicity. It then introduces time transformation and scaling, which are parts
of many mathematical operations on signals. Random signals are brieﬂy introduced to
broaden the scope of applications and projects. The Matlab programs in this chapter
focus on generating and plotting signals and functions.
1.1
Discrete Versus Continuous;
Digital Versus Analog
Discrete Versus Continuous
Some quantities appear to be analog in nature. They change in a continuous way. Ge-
ometrical and physical quantities are considered continuous. Some other examples are
the following: time; muscle force; the intensity of sound, light, or color; the intensity of
wind, ocean waves, or pain; the motion of the sun, moon, and planets; water ﬂow from a
spring; the growth of a tree; the radius of a circle; voltage, current, and ﬁeld strength; the
distance between two points; the size of a foot; the circumference of a waist measured
using a rope.
Some quantities appear to be discrete and change in a discrete way. Quantities
expressed by numbers are discrete. Some examples are the following: the number of
ﬁngers on our hands, teeth in our mouths, trees in an orchard, oranges on a tree, members
of a tribe; the number of planets and stars in the sky; the price of a loaf of bread; the rings
on a tree; the distance between two cities; the size of a shoe; voltage, current, and weight
measurements; a credit card monthly balance; waist size measured using a pinched belt.
On some occasions a discrete quantity is treated (modeled) as a continuous variable.
This may be for modeling convenience (e.g., the amount of hair on a person’s head)
or an effect of perception (e.g., the construction of a carpet, see Plate 1.1). Similarly, a
continuous quantity may be expressed in discrete form. The number of colors appearing
on a computer monitor is an example of this. Once a continuous variable is measured and
expressed by a number it becomes discrete. Most computations are done in the discrete
domain.

4
CHAPTER 1
Introduction to Signals
(a) Front side of a segment of a carpet appears as having a continuous structure.
(b) The back side shows the discrete structure.
Plate 1.1 An example of continuous versus discrete representation of a signal can be observed
by comparing the continuous front (a) with the discrete back (b) of a hand-woven carpet. The
carpet has a discrete structure that characterizes the carpet by the number of knots per unit length,
measured on the back side. The pattern shown in this plate is repeated several times throughout
the carpet (not shown). The pattern is deterministic and is provided to the weaver for exact
implementation. The weaver, however, introduces unintentional randomness seen in the product
as slight variations. These variations are not observed by an untrained person but are detected by
a specialist or through magniﬁcation.

Signals and Systems
5
Digital Versus Analog
A continuous-time signal is converted into a discrete signal by sampling. The samples,
however, are analog because they assume a continuous range of values. We can convert
the sample values into a discrete set by assigning the value of each sample to one of n
predetermined levels. The result is a digital signal. For instance, in the case of a binary
discrete signal, there are only two predetermined levels into which the analog samples are
forced: 0 and 1. Changes between these levels occur at the arrival time of a clock signal.
Because of ﬁnite wordlength, which determines the resolution in the magnitude value
of discrete-time functions, these are often called digital signals and discrete systems are
called digital systems.
1.2
Deterministic Versus Random
Signals are said to be deterministic or probabilistic (random). Once it appears, a determin-
istic signal does not provide any new information, unless some of its properties change
with time. A signal that could be predicted from its past values causes less surprise and
carries less information. The only information available from the 60 Hz sinusoidal signal
of a power line is its presence.1 In contrast, a code that reduces the correlation between
consecutive segments of the signal increases the information content of the signal.2
Some signals originating from natural, living, or societal systems vary with time
in an exact and regular way, making them predictable. An example would be the rising
sun. Or take the regularity of an electrocardiogram signal (EKG) that conveys health
information. The appearance of an irregularity is taken as a sign of disease. As a third
example, consider an advertisement for a candy brand touting the consistency of the
product. In this case, the information intended to be conveyed is predictability. Within
the above category we may also include signals that vary somewhat in a regular and
complicated (but not random) manner. An example would be the positions of the planets
in the sky, perceived and determined by an observer of the sky 5,000 years ago, and their
application in predicting future events and fortune telling by astronomers, astrologers,
and seers, or in decision making by rulers or elected ofﬁcials in the past or current
times.
In contrast, a signal may contain some stochastic (random) characteristic contained
within quasi-deterministic features and, depending on the degree of randomness in the
signal, still be considered predictable probabilistically within some statistical error rate.3
The combination of regularity and randomness in natural or societal signals is to be
expected. Such signals are the collective result of many interacting elements in physical
systems. The signals, therefore, reﬂect the regularity of the physical structure and the
irregularity of the message. The apparent randomness may also be due to our lack of
1The information provided by the above signal is only one bit. However, the information is normally very
valuable and important.
2By some deﬁnitions, signals that appear most random contain the most information.
3Sometimes the signal might appear to be totally unpredictable (e.g., appearance and time of a shooting star).

6
CHAPTER 1
Introduction to Signals
knowledge about the system responsible for generating the signal or an inability to
incorporate such knowledge in a model.
1.3
Examples of Natural and Societal Signals
Sunspot Numbers
Of interest in electrical communication (as well as in other ﬁelds) is the level of solar
activities, signaled by the number of sunspots as a function of time. Figure 1.1(a) shows
the annual mean number of sunspot records from AD 1700 to 2010 with the abscissa
indicating days. A clear feature of the record is the pattern of its variation, which exhibits
28 cycles of activity with an average period of 11 years during the past 310 years. Each
cycle has its own duration, peak, and valley values. One can also observe some waxing
and waning of the peak values, suggesting stratiﬁcation of the record into three centennial
groups of cycles (one segment consisting of cycles from 1770 to about 1810, the second
segment from 1810 to 1900, and the third from 1900 to 2010). In relation to the signal of
Figure 1.1(a) one may deﬁne several variables exhibiting random behavior. Examples of
such random variables are the number of sunspots (daily, monthly, and yearly numbers),
period of cyclic variations, peaks and valleys, and rise and fall times within each cycle.
A ﬁrst step in the analysis of signals such as that in Figure 1.1(a) would be to estimate
the mean and variance of the variables. To acquire more insight one would also ﬁnd the
correlation and interdependencies between them. Toward that goal one would use a more
detailed set of sunspot data such as average daily measurements. These provide a better
source for analysis of cyclic variation and ﬁne structures within a cycle. Figure 1.1(b)
plots such a set of data for the period of January 1, 1818, through September 30, 2010.
In this ﬁgure and its subsets shown in Figure 1.1(c), (d), and (e), the numbers on the
abscissas indicate the day, counting from the beginning of the time period for that ﬁgure.
The dates of the beginning and end of the time period are shown at the left and right sides
of the abscissa, respectively. The data of Figure 1.1(b) show many days with average
sunspot numbers above 200 and even some above 300 per day. Daily averages also
provide a better tool for analysis of cyclic variation and ﬁne structure within a cycle.
Bursts of activities lasting 10 to 20 days are observed in Figure 1.1(c), which plots the
data for the years January 1, 1996, through December 31, 2009, covering the most recent
cycle. Two extreme examples of yearlong daily measurements during the most recent
cycle of sunspot activities are shown in Figure 1.1(d) and (e). Figure 1.1(d) (for the year
2001, which was an active one) indicates high levels of activity with the occurrence of
strong periodic bursts. In contrast, Figure 1.1(e) (for the year 2009) shows weak levels
of activity but still occurring in the form of bursts.
Atmospheric CO2 Content
Carbon dioxide (CO2) is one of the greenhouse gases associated with thermal changes
of the atmosphere and is a signal for it. Monitoring atmospheric CO2 and trends in its
temporal and spatial variations is of potential importance to every person. Scientiﬁc
work on atmospheric carbon dioxide uses long-term historical information as well as

Signals and Systems
7
200
150
100
50
0
1700
1720
1740
1760
1780
1800
1820
1840
(a)
1860
1880
1900
1920
1940
1960
1980
2010
2000
400
(b)
300
200
100
0
0
January 1, 1818
September 30, 2010
10,000
20,000
30,000
40,000
50,000
60,000
70,000
250
200
150
100
50
0
0
January 1, 1996
(c)
500
1,000
1,500
2,000
2,500
3,000
3,500
4,000
4,500
5,000
December 31, 2009
FIGURE 1.1 Sunspot numbers. (a) Mean annual values (AD 1700–2010); (b), (c), (d), and (e) daily values for selected
time intervals during 1818 to 2010.
Source: National Oceanic and Atmospheric Association’s (NOAA) National Geophysical Data Center (NGDC) at www.ngdc.noaa.gov.

8
CHAPTER 1
Introduction to Signals
250
200
150
100
50
0
0
January 1, 2001
December 31, 2001
50
100
150
200
(d)
250
300
350
30
25
20
15
10
5
0
0
January 1, 2009
50
100
150
(e)
200
250
300
350
December 31, 2009
FIGURE 1.1 (Continued)
contemporary observations. Historical records indicate that trends in atmospheric CO2
are associated with glacial cycles. During the last 400,000 years, the CO2 content of the
atmosphere ﬂuctuated between a value below 200 to nearly 300 ppmv (parts per million
volume). The data are obtained by analyzing gas contents of the air bubbles entrapped
in polar ice sheets.
An example of the historical data is shown in Figure 1.2(a) which plots the results of
measuring the CO2 content of air bubbles in the ice cores of Vostock station in Antarctica.
The air in these bubbles is from 400,000 to 5,000 years ago. The data for the plot of
Figure 1.2(a) show long-term cyclic variations of 80 to 120,000 years with minima
and maxima of nearly 180 and 300 ppm, respectively. Present-day atmospheric CO2
shows much higher values which are unprecedented during the past half a million years.
Contemporary measurements are done under controlled and calibrated conditions to
avoid the inﬂuence of local sources (such as emissions) or environmental elements (such
as trees) that absorb, trap, or remove CO2 from the air. Figure 1.2(b) plots contemporary
data for 1959 to 2010 from measurements at the Mauna Loa observatory station in
Hawaii (chosen for its suitable location in terms of providing base measurements). The

Signals and Systems
9
400
350
300
250
200
CO2 Concentration (ppmv)
150
–400,000
–400,000
Years
(a)
Now
–350,000
–250,000
–150,000
–50,000
0
150
200
250
300
320
350
390
400
–300,000
–200,000
–100,000
390
380
370
360
350
Parts per million
340
330
320
310
1960
1965
1970
1975
1980
1985
Year
Monthly Plot of Atmospheric CO2 Measurements at Mauna Loa Observatory, Hawaii, 1960–2010
(b)
1995
2000
2005
2010
1990
390
385
380
Parts per million
375
2005
2005.5
2006
2006.5
Monthly Plot of Recent Atmospheric CO2 Measurements at Mauna Loa Observatory, Hawaii, 1960–2010
2007
2007.5
Year
(c)
2008
2008.5
2009
2009.5
2010
FIGURE 1.2 (a) Historical carbon dioxide record from Vostok ice cores. (b) and (c) Monthly carbon dioxide record from
Mauna Loa observatory, Hawaii. The record for 1960–2010 is shown in (b), while (c) shows the record for 2005–2010 at
a higher resolution.
Sources: (a) Carbon Dioxide Information Analysis Center (CDIAC) of the U.S. Department of Energy at http://cdiac.ornl.gov/. (b) and
(c) Dr. Pieter Tans, NOAA/ESRL (www.esrl.noaa.gov/gmd/ccgg/trends/).

10
CHAPTER 1
Introduction to Signals
measurements exhibit seasonal variations with a trend of steady growth. Since 1959
the annual average of CO2 content has grown from about 315 to nearly 390 ppmv. For
comparison, the contemporary values are also shown as a bar on the right-side end of
the plot on Figure 1.1(a) using the same vertical scale as for the historical data. It is seen
that while during the last 400,000 years atmospheric CO2 remained within the range
of 200 to 300 ppmv, it has grown from about 315 to nearly 390 ppmv during the last
50 years. The recent data for 2005 to 2010 and its trend are shown in Figure 1.2(c) on
an expanded time scale to better visualize the change. The plot of Figure 1.2(c) shows
seasonal variations of 6 to 10 ppmv riding on a steady growth of 2 ppmv per year.
Seismic Signals
Seismic signals are recordings of earth vibrations caused by factors as diverse as earth-
quakes, explosions, big falling objects (a giant tree, a building, etc.), the galloping of a
horse, the passing of a car nearby, and the like. Seismic signals are of interest for several
reasons among which are oil and gas exploration, treaty veriﬁcation and monitoring,
and, most importantly, earthquake studies and predictions. In the case of earthquakes,
the source of vibrations is a sudden movement of the ground, such as slippage at an area
of broken earth crust called a fault. The energy released by the slippage produces waves
that propagate throughout the earth similar to the radiation of electromagnetic waves
from an antenna. Earthquake studies and predictions are of great interest, especially for
those living in earthquake areas close to faults such as the San Andreas fault. The San
Andreas fault is the meeting boundary between two plates of the crust of the earth: the
Paciﬁc plate on the west and the North American plate (the continental United States).
The fault runs from southern to northern California, for a length of about 800 miles. It is
as narrow as a few hundred feet in some locations and as wide as about a mile in others.
The Paciﬁc plate has been moving slowly in the northwest direction with respect to the
North American plate for more than a million years. The current rate of this movement
is an average of 2 inches per year. Once in a while the fault may snap, making the two
plates suddenly slip and causing the sudden release of energy and strong vibrations in
the ground we know as an earthquake. Both the gradual and sudden movement of the
earth can change features on the ground. See Figure 1.3.
A transducer, which senses the earth’s movement and converts it to an electric signal,
records the results (in analog form on paper and magnetic tape or as a digital signal by
electronic device). Such a transducer is called a seismograph. The earthquake record
is called a seismogram. Traditional seismographs record the signal on paper covering a
slowly rolling cylinder that completes one turn every 15 minutes. This produces a trace
that begins at the left side of the seismogram and records 15 minutes of data, at which
time it reaches the right side of the paper. The trace then returns to the left side and starts
at a location slightly below the previous trace, as is done by the sweep mechanism in a
television cathode ray tube. The time of each trace is shown on the left side. Because of the
three-dimensional nature of seismic wave propagation in the earth, a set of seismograms
recorded at several locations, or several seismograms each recording the vibrations at
a different location or direction, are needed to produce a three-dimensional picture.

Signals and Systems
11
FIGURE 1.3 Sharp twisting of Wallace Creek in Carrizo Plane, central California, due to earth
plate movements. The stream channel crosses the San Andreas fault at the twisted segment. The
sharp twist (made of two bends of 90◦) indicates the narrowness of the fault at that location. The
gradual movements of the earth at the fault (at an average rate of 2 inches per year) along with
the sudden movements due to earthquakes have twisted the channel and shifted its downstream
path by about 100 meters toward the northwest (approximate direct measurement by the author).
It is estimated that during the past 1,500 years earthquakes have occurred along the San Andreas
fault about once every 150 years. The earthquakes may also rupture the ground and produce larger
abrupt shifts in the surface, as in the Tejon earthquake of 1857 (the largest earthquake in California
with a magnitude of 7.9, an average slip of 4.5 meters, and a maximum displacement of about
9 meters in the Carrizo Plane area).
The motion may last from tens of seconds to several minutes. The seismogram reﬂects
the duration of the motion, its intensity, and the physical properties of the ground. An
example is shown in Figure 1.4.
Release of energy in an earthquake shakes and displaces the rocks and earth elements
and causes them to vibrate back and forth. The frequency of the vibrations varies from
nearly 0.1 to 30 hertz (Hz). The vibrations propagate and travel as seismic waves on the
surface and also within the body of the earth (both within the crust and the core). Surface
waves have a lower frequency and travel slower than body waves. Propagations can be in
the form of longitudinal waves, where the direction of propagation is the same as the
vibration of earth materials. (Visualize the forward motion of a running tiger in relation

12
CHAPTER 1
Introduction to Signals
+180s
+270s
+360s
+450s
+540s
+630s
+720s
+810s
+900s
1994
Jan 17
Mon
GMT
GMT
12:30:00
CMB LHZ
23:30:00
+90s
Jan 17
Mon
+90s
+180s
+270s
+360s
+450s
+540s
+630s
+720s
+810s
+900s
1994
FIGURE 1.4 TheseismogramoftheNorthridgeearthquakeofJanuary17,1994,withamagnitude
of 6.7. The main shock of the earthquake occurred at 4:30:55 a.m. local time (PST), 12:30:55
Coordinated Universal Time (UTC). The center of the earthquake was located at 1 mile south-
southwest of Northridge and 20 miles west-northwest of Los Angeles. The seismogram in this
ﬁgure shows vertical motion of the ground. It is plotted from the digital seismic data (sampled
at the rate of 1 sample per second) which was recorded by Berkeley Digital Seismic Network
(BDSN) at an earthquake station in Berkeley, California. The station is at a distance of 525 km
from the earthquake location. The seismogram shows arrival of the main shock 63 seconds after
the earthquake occurred in Northridge, indicating a travel speed of 8,333 m/s through the earth. An
aftershock of the earthquake arriving at 23.32.51 UTC is shown in the lower trace. The guidelines
of the BDSN web page were used to construct the plot of the seismogram in this ﬁgure.
Source: www.ncedc.org/bdsn/make seismogram.html.
to the motion of its limbs.) The propagation can also be in the form of transverse waves,
where the direction is perpendicular to the vibration of earth materials. (Visualize the
forward motion of a snake in relation to the sideways motion of its body.) Considering
the above characteristics, four main types of seismic waves are recognized and used in
earthquake studies. These are the following:
1.
A P- (primary) wave travels through the crust or the core of the earth and is
longitudinal. It compresses the earth in the direction of its travel and is, therefore,
called a compression wave. It propagates faster than other wave types, traveling at
an average speed of 7 km per second (slower in the crust and faster within the core).
It is, therefore, the ﬁrst to be felt or registered as a seismogram. It is the ﬁrst wave
to shake the buildings when an earthquake occurs, hence called the primary wave.

Signals and Systems
13
2.
An S- (secondary) wave also travels through the earth’s body but is a transverse
wave. Therefore, it is called a sheer wave. S-waves are about half as fast as
P-waves. They shake the ground in a direction that is perpendicular to the direction
of wave travel.
3.
A Love wave is a transverse surface wave. It shakes the ground horizontally in a
direction perpendicular to the direction of its travel.
4.
A Rayleigh wave is also a surface wave, but not a transverse one. It shakes the
ground in an elliptical motion with no component perpendicular to the direction
of travel.
P- and S-waves are called body waves. They arrive ﬁrst and result in vibrations at
high frequencies (above 1 Hz). Love and Rayleigh waves are called L-waves. They arrive
last and result in vibrations at low frequencies (below 1 Hz). The above collection of
waves appear one way or another in the total waveform. Their contribution to the overall
spectrum of the earthquake wave is inﬂuenced by the earthquake magnitude.
Societal Signals
Some signals originating from societal systems also vary in a somewhat regular but
possibly complicated way, appearing as random. The apparent randomness may be due
to our lack of knowledge about the system responsible for generating the signal, or
an inability to incorporate such knowledge in a model.4 Examples of such signals are
indexes reﬂecting contraction and expansion of the economy, industrial averages, stock
market prices, the unemployment rate, and housing prices.
Figure 1.5 shows the rate of unemployment in the United States and its relationship
with recession.5 The latter are shown by vertical bands on the top section of the plot.
Note the periodicity in the unemployment rate, its rise associated with recession, and the
shape of its decline after recovery from recession.
Another example of a societal signal containing regularity and randomness is the
Dow Jones Industrial Average (DJIA) taken every minute, at the end of the day, or as a
weekly average. The signal exhibits some features such as trends and oscillations that
generally vary with the time period analyzed. There is great interest in predicting the
signal’s behavior within the next minute, day, month, or years. Analysis methods here
have a lot in common with signal analysis in other ﬁelds such as communication, signal
detection, and estimation.
4A correct understanding of the system that generates the signal or reshapes it is not essential for predicting
or modeling it. An astronomer can adequately predict the movements of the planets based on the earth-center
theory which is considered an incorrect theory. James Clerk Maxwell, in formulating the propagation of
electromagnetic signals, assumed the existence of a medium for such propagation even though it presently is
considered nonexistent.
5A period characterized by negative growth in gross domestic product (GDP) for two or more consecutive
quarters of the year is called a recession.

14
CHAPTER 1
Introduction to Signals
1948
1950
1952
1954
1956
1958
1960
1962
1964
1966
1968
1970
1972
1974
1976
1978
1980
1982
1984
1986
1988
1990
1992
1994
1996
1998
2000
2002
2004
2006
2008
2010
1948
2.5
1954
1960
1966
1972
1978
1984
1990
1996
2002
2008
5
7.5
10
FIGURE 1.5 Plot of monthly unemployment rate in the United States as a percentage of the
labor force from January 1948 to October 2010. The vertical bands on the top display periods of
recession. Note the association between recessions and the rise in umemployment.
Source: Bureau of Labor Statistics, http://data.bls.gov.
1.4
Voice and Speech Signals
Voice and speech signals are vocal expressions. They are generally perceived through
the auditory system, although other senses such as visual and tactile lip reading could
also serve as a transmission channel. In the present context, by voice and speech signals
we mean variations of a scalar that is plotted in analog form versus time. The scalar
may be air pressure, electric voltage, or vibrations in a liquid or solid. A voice signal
is the representation and reproduction of air pressure variation emanating (also called
radiating) from a speaker’s lips (or throat) and registered by a transducer such as a
microphone in the form of a time-varying voltage. Time is a continuous variable. The air
pressure is also a continuous variable. The auditory waveform can also vary as a function
of an additional variable such as space, if it is multiply recorded at several locations or
if the microphone is moved around relative to the speaker. This representation is raw
and not coded in that it contains features both relevant and irrelevant to its information
content. It can be directly converted back into the original signal by the use of a transducer
such as an earphone without any decoding. In a broad sense, speech processing is the
collection of operations done on speech for the purpose of encoding, communication,
recognition, data reduction and storage, text-to-speech conversion, and so on. Speech
processing is done in the analog and digital domains. The digital processing of speech
has vastly expanded speech technologies.

Signals and Systems
15
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1
27.3
27.4
27.5
27.6
Time (s)
(a)
Time plot of 700 msec of a bird song (lob1a.wav) containing two chirps
27.7
27.8
27.9
28
1
Amplitude
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1
27.42
27.43
27.44
27.45
Time (s)
(b)
60-msec segment of the bird song in (a) containing the first chirp
27.46
27.47
27.48
1
Amplitude
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1
27.44
27.442
27.444
27.446
Time (s)
(c)
Display of a 20-msec segment of the chirp shown in (b)
27.448
27.45
27.452
27.454
27.456
27.458
27.46
1
Amplitude
FIGURE 1.6 The waveform of a bird song (lob1a.wav, 22,050 samples per sec., 8 bits per sample, mono). The plot in
(a) is 700 msec long and contains two chirps. The plots in (b), (c), and (d) reveal the ﬁne structure of the chirp.

16
CHAPTER 1
Introduction to Signals
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1
0
10
20
Sample numbers
(d)
2,721-microsecond portion of the display in (c) shows 3.3 kHz oscillations
30
40
50
60
1
Amplitude
FIGURE 1.6 (Continued)
Speech signals contain a considerable degree of structural regularity. A 700-msec
sample of a bird song is shown in Figure 1.6(a) . The sample contains two chirp
sounds. The ﬁrst chirp, lasting 60 msec, is displayed with an expanded time axis in
Figure 1.6(b). It reveals some regularity in the form of oscillations, as seen in the ﬁner
structure of the chirp. The oscillations carry the chirp sound in their modulated ampli-
tude. The expanded plot of the chirp in Figure 1.6(c) shows amplitude modulation of the
carrier. To ﬁnd the frequency of this carrier, a portion of Figure 1.6(c), lasting 2,721
microseconds (60 samples), is displayed in Figure 1.6(d). It contains 9 cycles. The pe-
riod of oscillations is, therefore, T = 302 µsec, which corresponds to a frequency of
f ≈3.3 kHz.
A similar effect is observed in the signal of Figure 1.7(a), which shows the record-
ing of the spoken phrase a cup of hot tea. The waveform shows ﬁve distinct bursts
corresponding to the utterance of the ﬁve elements of the phrase. The waveform for hot
shown in (b) lasts 150 msec and exhibits some regularity, in the form of a wavelet, in its
ﬁne structure. The ﬁne structure of (b) is shown in (c) and (d).
1.5
Communication Signals
Communication signals such as those in radio, television, telephone, computer, mi-
crowaves, and radar systems are made of electromagnetic ﬁelds and waves. They are
distinguished from each other by their frequency, bandwidth, and method of carrying
information. Here are some examples.

Signals and Systems
17
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1
0.4
0.6
0.8
Time (s)
(a)
Time plot of a cup of hot tea (cht5.wav). Time is in seconds
1
1.2
1.4
1.6
1.8
1
Amplitude
0.5
0.4
0.3
0.2
0.1
0
–0.1
–0.2
–0.3
–0.4
1.2
1.25
Time (s)
(b)
Time plot of enunciation of the word hot in (a)
1.3
1.35
1.4
0.6
Amplitude
0.5
0.4
0.3
0.2
0.1
0
–0.1
–0.2
–0.3
–0.4
1.23
1.22
1.25
1.24
Time (s)
(c)
Nine wavelets (8 msec each) illustrate the fine structure of the word hot in (b)
1.26
1.27
1.28
1.29
1.3
0.6
Amplitude
FIGURE 1.7 (a) The waveform of the utterance a cup of hot tea (cht5.wav, 22,050 samples per sec, 8 bits per sample,
mono). The plot in (b) shows the waveform for hot. The ﬁne structure of (b) is revealed in (c) and (d).

18
CHAPTER 1
Introduction to Signals
0.5
0.4
0.3
0.2
0.1
0
–0.1
–0.2
1.282
1.28
1.286
1.284
Time (s)
(d)
The last two of the nine wavelets in (c)
1.288
1.29
1.292
1.294
1.296
1.298
1.3
Amplitude
FIGURE 1.7 (Continued)
Example
1.1
An energy signal
A signal picked up by a microwave antenna is modeled by the sinusoidal function
v(t) = A cos(ωt + θ), where ω = 2π f and f = 100 MHz. The signal lasts only T
seconds. Find the total energy in the signal as a function of A and T , and compute its
value when A = 1 mV and T = 1 µsec.
If the signal contains an integer number of cycles, we have
W =
 T
0
v2(t)dt = A2
 T
0
cos2(ωt + θ)dt = A2T
2
Joules
For A = 1 mV and T = 1 µsec, W = (10−12)/2 J = 0.5 pJ.
Example
1.2
Dual-tone multi-frequency signaling (DTMF)
Touch-tonetelephonesdialusingDTMFsignaling.InthisDTMFsystemeachdecimal
digit (0 to 9) is identiﬁed by a signal that is the sum of two pure tones, one from low-
band and another from high-band frequencies. The low-band frequencies are 697,
770, 852, 941 and the high-band frequencies are 1,209, 1,336, 1,477, 1,633, all in Hz.
Frequency assignments are shown in Figure 1.8. For example, the signal for the digit
1 is the sum of the 697 and 1,209 Hz tones. Telephone key pads also include more
buttons: the star ∗and the # (called the pound key) which provide the capability to
communicate with automated systems and computers. The combination of a low-band
and the high-band tone of 1,633 Hz (the column on the right side of Figure 1.8) provide
four additional signals called A, B, C, D tones, which are used for communication or
control purposes.

Signals and Systems
19
1
697 Hz
2
3
A
4
770 Hz
5
6
B
7
852 Hz
8
9
C
*
941 Hz
1,209
Hz
1,336
Hz
High-band frequencies
Low-band frequencies
1,477
Hz
1,633
Hz
0
#
D
FIGURE 1.8 Dual-tone multi-frequency signaling (DTMF).
Example
1.3
Phase-shift keyed (PSK) signals
a.
A binary stream of data is represented by a two-level (e.g., 0 or 1) signal (to be
called symbol). The signal modulates an RF carrier, at the frequency fc, in the
form of two-state phase-shift keying (2PSK), producing the signal
si(t) = cos(ωct + θi), i = 1, 2, where θi is 0◦or 180◦. The modulated signal,
therefore, shifts its phase by 180◦whenever the data switch between the two
levels. Each data bit maps into one signal (called a symbol) with a PSK phase
of 0◦or 180◦. The bit and symbol rates are equal.
b.
Now assume that each two successive bits in the binary stream of data are
mapped into phase values of θi = 0, ±π/2, π (or ±π/4, ±3π/4). Each pair of
data bits 00, 01, 10, and 11 produces one symbol and a signal with its own
phase out of the four phase values: si(t) = cos(ωct + θi), i = 1, 2, 3, 4, where
the phase θi assumes one of the four permitted values. This is called
quadrature- (or quaternary-) phase-shift-keyed (QPSK) signaling (also 4PSK).
The bit rate in QPSK is, therefore, twice the rate of 2PSK with the same carrier.
If M values of phase are permitted, the modulation is called M-ary PSK
(MPSK). The bit rate is then M times the symbol rate.
Signal Constellation
The QPSK signal can be generated by modulating the phase of a single sinusoidal carrier
cos ωt according to the permitted phase values θi. It can also be produced by modulating
the amplitudes of two quadrature carriers by xi and yi, and be expressed by
si(t) = xi cos ωct −yi sin ωct,
i = 1, 2, 3, 4

20
CHAPTER 1
Introduction to Signals
1.5
0.5
–0.5
–1
–1.5
–1.5
–1
–0.5
0
(a)
0.5
xq
xp
1
1.5
–1.5
–1
–0.5
0
(b)
0.5
1
1.5
0
1
1.5
0.5
–0.5
–1
–1.5
0
1
xq
xp
FIGURE 1.9 Two QPSK constellations.
where,
(xi, yi)
= (1, 0), (0, −1), (−1, 0), (0, −1)
for the case when
θi = 0, ±π/2, π.
(
√
2xi,
√
2yi)
= (1, 0), (0, −1), (−1, 0), (0, −1)
for the case when
θi = ±π/4, ±3π/4.
The pair (xi, yi) are normally represented on an x-y plane (with the x-axis labeled in-
phase and the y-axis labeled quadrature-phase) and called the signal constellation. See
Figure 1.9.
Example
1.4
Multilevel amplitude-modulation signals
Suppose the amplitude of a single analog pulse could be discretized to M levels with
an acceptable error. Discretization maps the pulse height into a binary number of
length n bits, where M = 2n. For M = 2, we have n = 1, a one-bit binary number
(0 or 1). For M = 4, we obtain n = 2 with four binary numbers, each of them being
two bits long (00, 01, 10, 11). For N = 8, we have a three-bit binary number (word
length = 3 bits). The bit rate is three times the symbol rate. Using the reverse of the
above process a sequence of n data bits can be represented by a single pulse (a symbol)
with an amplitude M = 2n, which can modulate the amplitude of a sinusoidal carrier.
The bit rate is n times the symbol rate.
Example
1.5
Quadrature amplitude modulation signals (QAMs)
Communication signals that transmit digital data are generated by modulating some
features of a sinusoid (called the carrier) by the binary data to be transmitted. Ex-
amples 1.3 and 1.4 introduced two types of signals generated by PSK and multilevel
pulse amplitude modulation. Another type of communication signal is generated by a
method called quadrature amplitude modulation (QAM), which combines PSK with

Signals and Systems
21
1.5
0.5
A
B
C
–0.5
–1
–1.5
–1.5
–1
–0.5
0
(a)
0.5
xq
xp
1
1.5
0
1
(b)
4
2
A
B
C
1
–1
–2
–3
–4
–4
–3
–2
–1
0
1
xq
xp
2
4
3
0
3
(c)
4
2
A
B
C
1
–1
–2
–3
–4
–4
–3 –2
–1
0
1
xq
xp
2
4
3
0
3
Signal
A
B
C
dmin
Pavg
(a)
(0 , 1)
(
√
2/2 ,
√
2/2)
(1 , 0)
0.765
1
(b)
(0 , 3)
(1 , 1)
(3 , 0)
2
5.5
(c)
(0 , 1 +
√
3)
(1 , 1)
(1 +
√
3 , 0)
2
4.73
FIGURE 1.10 Three different constellations of eight-point QAM signals. They are differentiated from each other by
their average power (Pavg) and the minimum distance (dmin) between their subsignals. The table above gives Pavg, dmin, and
the coordinates of three subsignals in each constellation. The coordinates of the A, B, and C signals are shown in the table.
pulse amplitude modulation. The QAM signal may be written as
si(t) = xi cos ωct + yi sin ωct = r cos(ωct + θ)
The signal is represented in two-dimensional space by the location of various permit-
ted pairs (xi, yi). The horizontal axis represents the xi coordinate of such points and
is called the in-phase axis. The vertical axis represents the yi coordinate and is called
the quadrature axis. The resulting set of points on the diagram is called the signal
constellation. For example, a modem that recognizes 1 of 16 levels of a sinusoidal
signal, and can distinguish 16 different phases, has a signal constellation of 256 ele-
ments and is called 256 QAM. It can carry 128 times more binary information than
a 2PSK modem. Three 8-symbol constellations are shown in Figure 1.10.
1.6
Physiologic Signals
Physiologic signals are those which are obtained from a living tissue or organism and
reﬂect the physiological state of that organism. As such, they are used in diagnosis,
prosthesis, and research. Some physiologic signals require a transducer in order to be
converted to electrical signals for recording, processing, and use. Examples are mea-
surements of blood pressure, temperature, and blood oxygen content. Some others are
electric potentials generated by the living tissue and recorded by placing two electrodes

22
CHAPTER 1
Introduction to Signals
between two points in the body. These potentials are normally called electrophysio-
logic signals.6 Familiar examples of electrophysiologic signals are those recorded from
the skin surface: electrocardiogram signals (EKG), electroencephalogram signals (EEG),
surface electromyogram signals (surface EMG), and electro-oculogram signals (to mea-
sure eye movement). Other examples of electrophysiologic signals are electric potentials
recorded by electrodes inserted under the skin or into a muscle (subdermal EMG), from
the surface of the cortex (electrocorticogram, ECG), from the collection of neurons of
the central nervous system (ﬁeld potentials, gross potentials, or evoked potentials), from
extracellular space near individual neurons (action potentials), or from inside a neuron
(intracellular potentials). The above signals are of interest in clinical diagnosis and pros-
thetic devices, as well as in research. Here we discuss brieﬂy the salient features of some
of them.
1.7
Electrocardiogram Signals
EKG Signals
Electrocardiogram (EKG) is the most familiar of physiologic signals. It is of special
interest because it relates to the operation of the heart, one of the most important functions
in the living body. EKG is the recording of electric potentials associated with contraction
of the heart muscles and picked up by electrodes on the surface of the body. The ﬁrst
noticeable temporal feature of an electrocardiogram is its periodicity which is produced
by the ventricular cycle of contraction (heartbeat). This is called the rate and is measured
in units of beats per minutes (BPM). An example of an EKG recording is shown in
Figure 1.11. Each division on the electrocardiogram chart paper is 1 mm, with the grid
conveniently designed for easy reading of the amplitude and beat rate. The vertical scale
is 0.1 mV per division. The time scale is 40 msec per division (the distance between
two thick lines being 200 msec). The time scale allows a direct reading of the rate off
the trace without much computation. The distance between two consecutive heavy black
lines (a box composed of 5 divisions) is 200 msec = 1/300 minutes, which corresponds
to a rate of 300 BPM. A distance of two boxes represents 2/300 minutes (i.e., a rate of
150 BPM) and three boxes mean 3/300 minutes (i.e., a rate of 100 BPM).7 The rate in
the trace in Figure 1.11(a) is 70 BPM.
Standard EKG
Standard EKG is composed of 12 trace recordings (called leads). They are produced
by two sets of recording electrodes: three limb electrodes (left and right arms, and the
left leg) and six chest electrodes (which cover the projection of the normal position
of the heart on the chest). The limb electrodes provide three bipolar (or differential)
6They are also called bioelectric signals as they are biologically based. Those recorded from the nervous
system are sometimes referred to as neuroelectric signals also.
7For details see Rapid Interpretation of EKG by Dale Dubin, Cover Pub. Co., c⃝2000. 6th ed.; and
Introduction to ECG Interpretation by Frank G. Yanowitz, http://library.med.utah.edu/kw/ecg/.

Signals and Systems
23
(a)
V5
FIGURE 1.11 (a) Twelve consecutive cycles of continuous EKG recording (lead V5 recorded by
the electrode on the left side of the chest). Each division on the chart paper is 1 mm. One division
on the time axis is 40 msec (a total of about 3 seconds and 4 beats on the lower trace), resulting
in a rate of about 70 beats per minute (BPM). In practice, the BPM number is read directly off the
chart (see text). One division on the vertical axis represents 100 µV, resulting in a base-to-peak
value of 1.5 mV. Note the remarkable reproduction of the waveform in each cycle. The schematic
of one cycle of EKG and its noted components are shown in Figure 1.11(b).
R
P
Q
S
T
PR
QRS
QT
(b)
FIGURE 1.11 (b) Schematic representation of one cycle of an EKG and its noted components,
recognized and understood as the manifestations of the physiological activity of the heart:
P-wave (depolarization of the atria)
QRS complex (depolarization of the ventricular muscle)
ST-T wave (repolarization of the ventricular muscle)
recordings between each two electrodes, with the third electrode acting as the reference
ground. These are called leads I, II, and II. The limb electrodes also provide three more
leads (unipolar recordings from each electrode with the other two connected as the
common reference). These are called augmented voltages: AVF (left foot), AVR (right
arm), and AVL (left arm). The leads obtained from the chest electrodes are labeled V1
through V6. Collectively, the trace recordings from the 12 leads are referred to as the
electrocardiogram. An example is shown in Figure 1.12(a).

24
CHAPTER 1
Introduction to Signals
(a)
AVR
AVL
AVF
I
V1
V2
V3
V4
V5
V6
II
III
FIGURE 1.12 (a) The standard EKG chart contains 12 traces (12 leads) obtained from electric
potential recordings by nine electrodes (three limb and six chest electrodes). In general, the traces
are not recorded simultaneously. An example is shown along with the summary interpretation.
Amplitude scale is 0.1 mV per division and time scale is 40 msec per division. (b) Interpretation
of the above EKG is by a specialist.

Signals and Systems
25
Name:
ID:
Sex:
BP:
Weight:
Height:
DOB:
Req. Physician:
Clinic ID:
Technician:
History:
Medication:
Date of Report:
Reviewed By:
Review Date:
PR:
Rate:
QT/QTc:
QRSD:
P Axis:
QRS Axis:
T Axis:
162
69
374/391
82
37
–1
40
(b)
msec
BPM
msec
msec
Sinus Rhythm
Interpretation:
P:QRS - 1:1, Normal P axis, H Rate 69
WITHIN NORMAL LIMITS
Comments: Unconfirmed Report
FIGURE 1.12 (Continued)
Interpretation of EKG
The temporal and spatial features obtained from the ensemble of 12 EKG leads are
associated with the functioning of the heart and are used as diagnostic tools for it. In in-
terpreting an EKG, the following time intervals and durations (along with the amplitudes
and timings of the above components) are used:
PR interval,
QRT duration,
QP interval,
PP interval,
RR interval
An interpretation of the EKG of Figure 1.12(a) by a specialist is shown in
Figure 1.12(b).
1.8
Electromyogram Signals
Electromyogram (EMG) signal is the recording of electric potentials arising from the
activity of the skeletal muscles. EMG activity can be recorded by a pair of surface disk
electrodes placed over the skin on the muscle (a better representation of the entire muscle
activity, representing the activity of a larger number of motor units and, therefore, the en-
tire muscle) or by a subdermal bipolar needle electrode inserted under the skin or inside
the muscle. Three mechanisms can contribute to an increase in EMG activity. These are
(1) more motor units of the muscle being recruited, (2) the rate of motor units involved
being increased, and (3) stronger synchronization between the motor units involved.
Characteristics
EMG is the collective electric potentials of individual motor-unit activations involved
in muscular contraction. This manifests itself in the form of a burst of electrical activity
composed of spike-shaped wavelets. Traditionally, an EMG signal has been characterized
by its amplitude, duration, and shape which are used in simple analysis. Within an EMG
signal one observes bursts of spikes with multiple peaks. These spikes and their parame-
ters (such as shape, duration, sharpness, and peak amplitude) are used for a more reﬁned
analysis of the EMG. The bandwidth of 2 Hz to 2 kHz often sufﬁces for a general EMG
recording. Some EMG recorders accommodate higher bandwidths (up to 20 kH), which
would keep more details from the spike parameters. The amplitude of the EMG depends
on the activity of the muscle and is normally on the order of several hundred microvolts.

26
CHAPTER 1
Introduction to Signals
Applications
The study of the EMG and its relation to movement is of interest in several areas. These
are (1) clinical diagnosis, (2) kinesiological studies, (3) research on initiation and control
of movement in living systems, and (4) development of movement-assisting devices and
prostheses. In the last case, being of much practical application, the EMG of some
muscles controls an external device that has replaced a limb that does not function or is
lost.
Example
1.6
Samples of EMG activities recorded during a series of experiments on the extension
of the right-upper limb in the sagittal plane are shown in Figure 1.13. Extensions
were made at normal [Figure 1.13(a)] or fast speeds [Figure 1.13(b)] and under four
cases of different load conditions (the subject holding no load in his hand, or a load
of 0.5, 1, and 3 kg). EMG activities from the biceps and triceps brachii were each
recorded differentially by a pair of surface disk electrodes placed 2.5 cm apart on
each muscle. The reference electrode was placed on the forehead. Simultaneously,
the motion trajectories of 10 points on the arm were recorded by fast movies and
photographically sampled by stroboscopic ﬂashing on still ﬁlm snapshots. The strobe
light was synchronized with the initiation of the movement during the experiment
and ﬂashed at the rate of 50 Hz while the shutter of a still camera was kept open to
take in the sequence of motion.
1.9
Electroencephalogram Signals
The potential difference measured between an electrode placed on the scalp and some
other point such as the neck or ear has a time-varying magnitude of 20–100 µV and is
called an electroencephalogram (EEG). The EEG is the electric ﬁeld potential generated
by the sum of the electrical activities of the population of neurons within a distance
of several mm from the recording electrode ﬁltered through the dura, skull, and skin.
The ﬁlter has smoothing effects in time and space. However, two electrodes placed
only 1 or 2 mm apart from each other may record distinctly different (but correlated)
electrical activities. The number of electrodes and their placement on the scalp varies
from under 10 to more than 20. The 10–20 system of electrode placement recommended
by the International Federation of Societies for Electroencephalography and Clinical
Neurophysiology(orasimplerversionofit)ismostlyused.AnEEGsignalisspontaneous
or evoked. Its temporal characteristics depend on the recording location on the scalp and
the physiological state (e.g., the subject being awake or asleep, eyes opened or closed,
etc.). The basic variables of an EEG signal are amplitude and frequency. The frequency
band ranges from less than 4 Hz (called delta) to more than 13 Hz (called beta).
The intermediate bands are 4 to less than 8 Hz (called theta) and 8 to 13 Hz (called
alpha).

Signals and Systems
27
0.5 kg
1 kg
3 kg
50 msec
(a)
(b)
0 kg
Cue
Movement
Triceps
0 kg
0.5 kg
1 kg
3 kg
100 msec
Biceps
Triceps
Fast Extensions
FIGURE 1.13 (a) EMG activities recorded from the triceps brachii in normal extensions of
the arm under four load conditions are shown. The amplitude and duration of the EMG activity
increase with the load. The EMG signal contains spikes whose number and amplitude also increase
with the load. The upper trace in each case shows the cue to begin the extension and its start. The
extension starts about 250 msec after the acoustic cue is given. EMG activity begins to manifest
itself about 100 msec before the actual movement appears. Each trace is 500 msec long. (b) EMG
activities recorded from the biceps and triceps brachii in fast extensions of human arm, again under
four load conditions are shown. The triphasic activity pattern of triceps-biceps-triceps is observed
in all cases. In addition, as the load increases (from 0 to 3 kg), a second phase of biceps activity
becomes more pronounced. Each trace is 1 sec long. (Nahvi, 1983, unpublished.)
These basic variables of the EEG change with the behavioral state and the mental and
physical aspects of the subject. These changes are well understood and established in the
study of EEGs. Their association with physiological, behavioral, and mental states (e.g.,
eyes opened or closed, fear, relaxation, and sleep) is also well known. In a more detailed
description of EEGs, one recognizes complex wave patterns (modeled as combinations
of sinusoids and simple patterns) and waveforms described by special features (such as
spikes). Examples of such patterns are shown in Figure 1.14.

28
CHAPTER 1
Introduction to Signals
Awake: low voltage-random, fast
Drowsy: 8 to 12 cps- alpha waves
Stage 1: 3 to 7 cps- theta waves
Stage 2: 12 to 14 cps- sleep spindles and K complexes
Deep sleep: 1/2 to 2 cps- delta waves > 75 µV
REM sleep: low voltage-random, fast with sawtooth waves
1 s
50 µV
FIGURE 1.14 Examples of EEG patterns during various stages of sleep.
Source: This ﬁgure was published in Fundamental Neuroscience, Larry Squire, Darwin Berg, et al., page 963,
Copyright Elsevier (2008).
1.10
Electrocorticogram Signals
Evoked Gross Potentials
An electrode made of a silver wire about 1 mm in diameter with a round tip (called
the gross electrode) and placed on the cortex (with the reference electrode placed on
the neck) records voltages of about 500 µV. Such recordings are referred to as an elec-
trocorticogram (ECG). These voltages are ﬁeld potentials resulting from the electrical
activities of population of nearby neuronal elements. They are generated spontaneously
or evoked in response to external (acoustic, visual, or tactile) stimuli. A gross evoked
cortical response has a positive deﬂection (historically shown by a downward direction).

Signals and Systems
29
P0
P1
(a)
(b)
10 msec
P2
N2
N1
Click
R = 60
N1
200
µV
200
µV
200
µV
40 msec
(i)
(ii)
(iii)
P1
P2
FIGURE 1.15 Cortical gross evoked potentials. (a) Average of 60 responses to acoustic clicks
(one per second) recorded from the surface of the cerebellum of unanesthetized cats by a macro-
electrode. A sharp negative deﬂection (N1) interrupts the positive component of the response,
creating two positive deﬂections (P1 and P2), followed by a slow negative deﬂection (N2).
The waveform changes from location to location but the general shape is the same. The shape
of the evoked response and its peaks are associated with the elements of the electrical activity
of the cellular neural network such as the incoming volley through input pathways, postsynaptic
potentials at the neuronal elements, and the evoked action potentials of individual neurons. (Nahvi,
1965, unpublished.) (b) Average click evoked potentials from three locations on the surface of the
cerebellum show the range of variations in the triphasic response characteristic.
Source: With kind permission from Springer Science+Business Media: Experimental Brain Research. “Firing
Patterns induced by Sound in Single Units of the Cerebellar Cortex,” Volume 8, Issue 4, 1969, pages 327-45,
M.J. Navhi and R.J. Shofer.
It starts with a latency that varies from several msec to tens of msec and lasts from 10 to
30 msec. The positive component may be interrupted by a negative deﬂection. Examples
of cortical evoked potentials in response to acoustic clicks are shown in Figure 1.15.
Using a smaller recording electrode allows a better discrimination of localized elec-
trical activity of the neurons of the brain. A macroelectrode with a tip-size of about
0.1 mm records more localized extracellular ﬁeld potentials (still called gross potential
in contrast to single-unit action potentials, to be discussed shortly). A bipolar macro-
electrode can be constructed to measure the potential difference between two adjacent
(e.g., 100 or 200 microns apart) points or between a single point and a common ref-
erence point. Figure 1.16 shows examples of electrical potentials recorded from the
coronal-precruciate cortex of an awake cat conditioned to twitch its nose in response
to a hiss conditional stimulus (CS). Recent advances have enhanced the possibility of
using similar cortical potentials to program and operate prosthetic devices for control of
movement in persons with impaired motor skills.

30
CHAPTER 1
Introduction to Signals
A
T
B
C
D
150 µV
20 msec
E
FIGURE 1.16 Cortical potentials associated with a nose twitch recorded from the coronal-
precruciate cortex. The recording electrodes were made of teﬂon-coated stainless-steel wire of
0.1 mm diameter, insulated except at the tip, and implanted chronically and approximately 1.5 mm
below the surface of the cortex. The ﬁve traces shown in this ﬁgure are representative samples of
cortical recordings. Each trace (160 msec shown) contains a CS-evoked response (aligned at the
vertical line) preceding a conditioned nose twitch movement. Nose twitch was monitored by TV
ﬁlm and concurrent subdermal EMG recordings from the activity of the levator oris muscles. The
evoked response was successfully detected by cross-correlation with a template matched to the
signal. The template (20 msec long) is shown on the top of the ﬁgure.
Source: With kind permission from Springer Science+Business Media: Experimental Brain Research, “Appli-
cation of Optimum Linear Filter Theory to the Detection of Cortical Signals Preceding Facial Movement in
Cat,” Volume 16, Issue 5, 1973, pages 455-65, C.D. Woody and M.J. Nahvi.
1.11
Neuroelectric Signals from Single Neurons
Action Potentials
Neurons are processing elements of the brain. A neuron is composed of a set of dendrites
that receive signals from other cells (as few as several and as numerous as several hundred
thousand inputs), a cell body (5 to 70 microns across) that integrates and processes the
information, and an axon that sends the output signal to other cells. A thin membrane
separates the inside from the outside of the neuron. The liquid inside the neuron contains
ions that are positively or negatively charged. Ion pumps in the membrane maintain
different concentrations of positive and negative ions on the two sides of the membrane.
This creates a negative electrical potential of −70 to −80 mV across the membrane (with
the inside being more negative with respect to the outside) called the resting potential.
An incoming signal from sensory receptors or other neurons may be inhibitory, causing
the neuron to become hyperpolarized (resting potential becoming more negative), or
excitatory, causing the neuron to become depolarized (resting potential becoming less
negative). If depolarization reaches a certain threshold level, the electrical conductance
of the membrane at the axon hillock is dramatically reduced for a brief period, triggering
a rush of positive ions (such as Na+ ions) from outside to the cell interior. The movement

Signals and Systems
31
of positive ions creates a positive current ﬂow and reduces the negative magnitude of
the resting potential toward zero for a brief period of time. The cell is said to have
ﬁred. These events take about a millisecond, after which the cell membrane recovers
and intracellular potential returns to the former resting potential value. The effect of
the above sequence of events is a spike in voltage change called an action potential.
It is an all-or-none event. The depolarization and the action potential propagate along
the cell’s axon away from the cell body and reach synapses on other cells, thereby
transmitting information to other neurons. In summary, action potentials are all-or-none
events that transmit information by the timing of their occurrence.
The action potentials are recorded by ﬁne electrodes (called microelectrodes) with a
tip size on the order of microns or less. Action potentials can be recorded on the outside or
inside of neurons. In processing neuroelectric data, an action potential can be treated as
a discrete-time unitary signal which carries information in its inter-spike time interval or
its rate of spike. It can be spontaneous or evoked by external factors such as an acoustic,
visual, or tactile stimulus.
Recordings of Extracellular Action Potentials
Microelectrodes with ﬁne tips can pick up single-unit action potentials from neuronal
elements in the extracellular space. Metal microelectrodes can be made of tungston wires
which are insulated except for a few microns at the tip. Glass microelectrodes are made
of glass pipets ﬁlled with KCl solutions with 3-mol density. Extracellular recordings
of action potentials vary from 100 µV to 10 mV or higher. Their shape and magnitude
vary depending on the recording distance from the neuronal element and the electrical
properties of the recording electrode, but they are always brief and unitary in the form
of spikes. An example is shown in Figure 1.17.
FIGURE 1.17 Single-unit recording of extracellular action potentials using a glass microelec-
trode from the auditory area of the cerebellum (upper trace) and simultaneous recording of surface
gross potential (lower trace) evoked by an acoustic click (shown by the bar below the gross potental
recording).
Source: With kind permission from Springer Science+Business Media: Experimental Brain Research, “Firing
Patterns Induced by Sound in Single Units of the Cerebellar Cortex,” Volume 8, Issue 4, 1969, pages 327-45,
M.J. Nahvi and R.J. Shofer.

32
CHAPTER 1
Introduction to Signals
Recordings of Intracellular Potentials
The membrane of a neuron may be penetrated by a glass pipet microelectrode with
a tip-size of 1 micron or less to record electrical potentials from inside the cell. The
intracellular electrical potential recording is composed of (1) a resting potential of −70
to−80mVand(2)postsynapticpotentialsgeneratedbythearrivalofelectricsignalsfrom
other cells. Such signals generate electric potentials inside the cell which can be positive
(excitatory postsynaptic potentials, EPSP, making the interior of the cell less negative
and thus depolarizing it) or negative (inhibitory postsynaptic potentials, IPSP, making
the interior of the cell more negative and thus hyperpolarizing it). Postsynaptic potentials
are in the form of decaying exponentials with peak magnitudes of 0.1 to 10 mV and time
constants of 5 msec to several minutes. They add algebraically to the resting potential.
Upon reaching a depolarization threshold (−65 mV at the axon hillock and −35 mV
at the cell body), the cell ﬁres with one or more action potentials that travel through
the axon and carry information to other cells. Examples of intracellular recordings are
shown in Figure 1.18.
1.12
Applications of Electrophysiologic Signals
Understanding the physiological correlates of neuroelectric signals in the functioning of
the central nervous system and methods for their analysis has found many applications
in medicine and engineering. Advances in communication and computer technologies
(both hardware and software) have provided vast opportunities for using biological sig-
nals in general (and electrophysiologic signals in particular) for many purposes and
tasks. EEG signals (as well as EKG, EMG, and signals generated by eye movement)
provide signal sources for controlling prostheses (prosthetic limbs, assistive devices, and
robots), computer recognition of unuttered speech (synthetic generation of live speech)
and real-time monitoring, analysis, and decision making in preventive care (such as for
heart attacks). In such applications, several measures need to be deﬁned, evaluated, and
investigated. One important measure is the probability (or rate) of error. For example,
(1) By how much may the error rate in an assistive device be reduced through use of
multiple signals? (2) How accurately can one predict the occurrence of a signal intended
for movement before the movement has been initiated? (3) Can one reduce the error rate
by increasing the number of recording electrodes? (4) Can one record the single-unit
activity of neurons and use them in daily tasks?
Besides current applications, studies of neuroelectric signals (especially at the neu-
ronal and subneuronal levels) suggest applications in neurocomputing and new methods
of mass storage of data, a ﬁeld with much future promise.
1.13
Characterization and Decomposition
of Signals
Complex signals are difﬁcult to characterize unless we ﬁnd ways to decompose and
expand them into simpler components that can be represented by familiar mathematical
functions such as DC levels, sinusoids, pulses, waveforms having speciﬁc features, and

Signals and Systems
33
20 msec
200 msec
40 mV
40 mV
20 mV
*
20 mv
10 msec
FIGURE 1.18 Recordings of intracellular potentials. (a) Top traces. Recordings of electrical po-
tentials at penetration time from three morphologically identiﬁed neurons of the cerebellar cortex
of an unanesthetized awake cat. The downward negative voltage shift shows the intracellular pen-
etration of the electrode. The intracellular recording also shows the presence of both undershoot
and overshoot action potentials. (b) Right traces. Sample recordings of action potentials. Two
types of action potentials are recognized: one type is a simple spike with short duration and slower
rise time; the other is a complex one with faster rise time but longer duration. The two types of
action potentials seen in these recordings are attributed to Purkinje cells in the cerebellum.
Source: Reprinted from Experimental Neurology, Volume 67, Issue 2, Mahmood J. Nahvi, Charles D. Woody,
Eric Tzebelikos, Charles E. Ribak, “Electrophysiologic Characterization of Morphologically Identiﬁed Neu-
rons in the Cerebellar Cortex of Awake Cats,” pages 368–376, (1980), with permission from Elsevier.
so on. One such expansion method was proposed by Jean Baptiste Joseph Fourier in the
early 19th century8 and later generalized by others. Fourier discovered that any periodic
signal can be represented by a collection of sinusoidal functions, leading to the Fourier
series and transform. The power of Fourier analysis is in the fact that sinusoids are
eigenfunctions of an important class of system models called linear time-invariant (LTI)
systems. Linear systems are convenient and rather accurate models of many physical
8The Analytical Theory of Heat by Joseph Fourier, Dover Phoenix Editions, 2003, originally published as
Theorie Analytic de la Chaleur in 1822. Fourier (1768–1830) submitted his paper on this subject to the
Academy of Science, Paris, in 1807.

34
CHAPTER 1
Introduction to Signals
systems within the range of interest. A sinusoidal signal entering a linear time-varying
system appears at the output as a sinusoid. The system can change only the amplitude and
phase of the signal. This is called the frequency response. The frequency response allows
us to predict the output of an LTI system for any input, as long as the input is expressed
in the form of a sum of sinusoids. The Fourier expansion of the input signal provides that
expression. In Fourier analysis, sinusoids are the building blocks. In wavelet analysis,
the building blocks are wavelets.
Almost every communication, control, and measurement process is vulnerable to
noise. Noise interferes with a signal’s mission and potentially degrades its performance.
Ifitwerenotfornoise,alargeamountofinformationcouldbeencodedintheamplitudeof
a single pulse and transmitted to a receiver. Below we mention important characteristics
that notably inﬂuence the functioning of signals in combating the effect of noise.
Duration and amplitude. Mathematical models allow a function to have an inﬁnite
range and domain. Real signals, however, have ﬁnite duration and amplitude. These two
characteristics translate into energy which is an indication of a signal’s strength. (See
Example 1.1 in section 1.5.) Signals with more energy are less vulnerable to noise and
impairment.
Rate of change. Signals which change more often can carry more information with less
error. The faster the signal switches from one form to another, the more data it transmits.
Size of the alphabet. The change in a signal may be digital (using one of N letters of an
alphabet every T seconds). The alphabet may be binary (a voltage being high or low; the
man in a picture either standing or sitting; a variable being +1 or −1; a ﬂag being up or
down). It may be tertiary (high, medium, or low; standing, sitting, or lying down; +1, 0,
or −1; up, down, or at half mast). It may contain 10 decimal digits or be made of the 26
letters of the English language. The larger the size of the alphabet, the more informative
the signal is. The information carried by a single letter of a binary alphabet is called a bit.
Frequency. The change in the signal may also be analog and continuous in amplitude,
frequency, and phase (analog modulation). Similar to the digital case, analog high-
frequency signals can transmit more data. The examples given in section 1.5 combine
the case of digital and analog signals and show how the size of the alphabet and a
high-frequency carrier increase the data rate.
Bandwidth. Signals are rarely made of a pure sinusoid. A signal may contain a range of
frequencies called the bandwidth. Higher bandwidths increase the rate of information
transmission and reduce the error rate. The bandwidth will be discussed in Chapters 7
and 8 on Fourier analysis.
Sampling rate. Many discrete signals are generated by sampling a continuous-time
signal. For the discrete signal to contain the same information, the sampling should be
done fast enough to capture the changes in the signal. The miminum rate is called the
Nyquist rate. In practice, the reconstruction process is not perfect and a higher sampling
rate is needed. When the sampling is done below the Nyquist rate, not only is some
information lost, but the remaining information is also distorted.
Coarse and ﬁne structure. Several structural levels can be observed in the signal ex-
amples of Figures 1.1, 1.2, and 1.3. Similar aspects are also seen in other signals (natural

Signals and Systems
35
or synthetic) such as amplitude-modulated signals, radar signals, neuroelectric signals,
seismic signals, and many more. Several tools such as ﬁltering, Fourier methods, and
wavelets can be employed to analyze these structures.
Other domains. Mathematical modeling of signals is not limited to waveforms and
functions in the time domain. Signals may also be represented in the frequency or other
domains (e.g., by an alphabet or a dictionary). For most of our discussions in this book
we employ signals in the time and frequency domains.
1.14
Mathematical Representations of Signals
The following three classes of mathematical functions are used to represent signals. They
are as follows:
1.
Periodic functions, such as sinusoids.
2.
Nonperiodic functions (also called aperiodic), such as impulse, step, ramp,
exponentials, pulses, and sinc function.
3.
Random functions.
In this section we discuss functions that belong to the ﬁrst two classes. There are several
aspects that distinguish signals from these functions. For one thing, the domain of these
functions is −∞< t < ∞while actual signals have a ﬁnite duration. The other thing
is that actual signals, by necessity, include unpredictability while these functions are
deterministic. The differences, however, don’t undermine the value of these representa-
tions in the analysis and design of linear systems, as should become clear to the student
throughout this book.
Periodic Functions
A function f (t) is periodic with period T if
f (t) = f (t + T )
for all t,
−∞< t < ∞
Note that nT , where n is a positive integer, is also a period of f (t). The function repeats
itself every T seconds. Therefore, it is sufﬁcient to know its value during one period.
This information may be provided by an analytical expression, a graph, or in tabular
form. A well-known periodic function is the sinusoid V0 cos(ωt +θ). Periodic functions
may be very complex. However, as we will see in Chapter 7 on Fourier series, they can
always be represented by a sum of sinusoids. Therefore, sinusoids play an important role
in the analysis of signals and linear systems. Sinusoids are treated in detail in Chapter 2.
Sum of Periodic Functions
The sum of two periodic functions with respective periods T1 and T2 is periodic if a
common period T = n1T1 = n2T2, where n1 and n2 are integers, can be found. This
requires that T1/T2 = n2/n1 be a rational number. Otherwise, the sum is not periodic
and usually called almost periodic. A similar conclusion applies to the product of two
periodic functions.

36
CHAPTER 1
Introduction to Signals
Example
1.7
For each time function given below, determine if it is periodic or aperiodic. Specify
its period if periodic.
a. cos(3t + 45◦) + sin(
√
2t −120◦)
b. cos(5t) + cos π(t −0.5)
c. cos(πt + 10◦) −cos(2πt + π/3)
d. sin(6.28t −2π/3) + cos 0.2(t −0.5)
Solution
a. Aperiodic
b. Aperiodic
c. Periodic, period = 2
d. Periodic, period = 50π
Example
1.8
Repeat Example 1.7 for the time functions given below.
a. cos(3t + 45◦) sin(
√
2t −120◦)
b. cos(5t) cos π(t −0.5)
c. cos(πt + 10◦) cos(2πt + π/3)
d. sin(6.28t −2π/3) cos 0.2(t −0.5)
Solution
a. Aperiodic
b. Aperiodic
c. Periodic, period = 2
d. Periodic, period = 25π
Elementary Functions
The unit-impulse, unit-step, unit-ramp, sinusoidal, exponential, and sinc functions, as
wellaspulsesandwindows,areoftenusedastheelementarybuildingblocksformodeling
signals and they will be discussed here. Finite-duration pulses and windows will be
discused in detail in Chapters 7 and 8 on Fourier analysis.
Unit Impulse
The unit-impulse function δ(t)9 (also called Dirac’s delta function) is represented by a
double-stem up arrow as shown in Figure 1.19. A delay of τ produces δ(t −τ), while
an advance of τ produces δ(t + τ).
0
–t
d(t + t)
d(t – t)
d(t)
t
t
FIGURE 1.19 Representation of the unit-impulse function δ(t). A delayed unit-impulse δ(t −τ)
and an advanced unit-impulse δ(t + τ) are also shown.
9In the strict mathematical sense, δ(t) is not a conventional function but a generalization of functions. It,
therefore, has sometimes been called a symbol rather than a function, as emphasized by Ruel Churchill in his
lectures (see also his Operational Mathematics, (New York: McGraw-Hill, 1958), pp. 26–28).

Signals and Systems
37
The unit-impulse function is deﬁned in less rigorous ways than a conventional
function. One such deﬁnition is
δ(t) =

0,
t ̸= 0
∞,
t = 0
and
 ∞
−∞
δ(t)dt = 1
Another deﬁnition involves the limit of a narrow pulse T (t) with unit area, as the
pulse-width approaches zero, but the area remains equal to 1. For example, let
T (t) =

1
T ,
−T
2 < t < T
2
0,
elsewhere
Then,
δ(t) = lim
T →0 T (t)
Note that
 ∞
−∞T (t)dt = 1. The initial pulse need not be rectangular, or even of ﬁnite
duration, as long as it narrows down and keeps its area at 1. Examples are pulses described
by exponential, Gaussian, and sinc functions listed below and shown in Figure 1.20.
These functions will be described in detail shortly.
Rectangular pulses, Figure 1.20(a):
x1(t) =

1
T ,
−T
2 < t < T
2
0,
elsewhere
−∞< t < ∞
lim
T →0 x1(t) = δ(t)
Exponential pulses, Figure 1.20(b):
x2(t) = 1
2τ e−|t|
τ
−∞< t < ∞
lim
τ→0 x2(t) = δ(t)
Gaussian pulses, Figure 1.20(c):
x3(t) =
1
σ
√
2π
e−x2
2σ2
−∞< t < ∞
lim
σ→0 x3(t) = δ(t)
Sinc pulses, Figure 1.20(d):
x4(t) = sin
 πt
T

πt
T
−∞< t < ∞
lim
T →0 x4(t) = δ(t)
Sieving Property of Impulse
A more rigorous deﬁnition of δ(t), based on generalized functions and distribution, is
given by its “sieving” property
 ∞
−∞
f (t)δ(t −t0)dt = f (t0)
where f (t) is a well-behaved function and continuous at t0.

38
CHAPTER 1
Introduction to Signals
−3
−2
−1
0
1
2
3
0
0.5
1
1.5
2
−3
−2
−1
0
1
2
3
0
0.5
1
1.5
2
−3
−2
−1
0
1
2
3
0
0.5
1
1.5
2
−3
−2
−1
0
1
2
3
0
0.5
–0.5
1
1.5
2
Time (s)
Three narrowing Gaussian pulses with unit area
Three narrowing rectangular pulses with unit area
Three narrowing two-sided exponential pulses with unit area
x1 = sinc(π t/T)
(c) Gaussian pulses
(d) Sinc pulses
(a) Rectangular pulses
(b) Exponential pulses
Amplitude
Time (s)
Amplitude
Time (s)
Amplitude
Time (s)
Amplitude
FIGURE 1.20 The unit-impulse function δ(t) may be deﬁned as the limit of narrowing pulses with constant unit area.
Example
1.9
Let x(t) be an even rectangular pulse at the origin
x(t) =

1
T ,
−T
2 < t < T
2
0,
elsewhere
Shift it by t0 and multiply by a well-behaved function f (t), which is continuous at
t0, and integrate. Show that
lim
T →0
 ∞
−∞
f (t)x(t −t0)dt = f (t0)

Signals and Systems
39
Solution
I =
 ∞
−∞
f (t)x(t −t0)dt = 1
T
 t0+T/2
t0−T/2
f (t)dt
For small T :
I ≈f (t0 −T/2) + f (t0 + T/2)
2
As the limit:
I = lim
T →0
f (t0 −T/2) + f (t0 + T/2)
2
= f (t0)
Unit Step
The unit-step function u(t) is deﬁned by
u(t) =

1,
for t ≥0
0,
for t < 0
A delay of τ produces u(t −τ), while an advance of τ produces u(t +τ). See Figure 1.21.
Unit Ramp
The unit-ramp function r(t) is deﬁned by
r(t) =

t,
for t ≥0
0,
for t < 0
A delay of τ produces r(t −τ), while an advance of τ produces r(t +τ). See Figure 1.22.
u(t + t)
u(t – t)
– t
0
t
t
u(t)
FIGURE 1.21 The unit-step function u(t), a delayed unit-step u(t−τ), and an advanced unit-step
u(t + τ).
r(t + t)
r(t – t)
– t
r(t)
0
t
t
FIGURE 1.22 The unit-ramp function r(t), a delayed unit-ramp r(t −τ), and an advanced
unit-ramp r(t + τ).

40
CHAPTER 1
Introduction to Signals
In addition to impulse, step, and ramp functions, other user-deﬁned functions may be-
come desirable, especially when employing computer software. An example of such a
user-deﬁned function is Rect(t) = u(t) −u(t −1). Such additional functions will not
be employed in this book.
Sinusoid
The sinusoidal function v(t) = V0 cos(ωt) is periodic. The period is T = 2π/ω. The
frequency is f = 1/T = ω/2π. A delay of τ produces v(t −τ) = V0 cos(ωt −ωτ) =
V0 cos(ωt −θ), where θ = ωτ is the phase lag. Similarly, an advance of τ produces the
phase lead θ = ωτ. See Figure 1.23. For more details on sinusoids see Chapter 2.
Exponential
An exponential function grows or decays at a rate proportional to its value: dv/dt = αv,
where α is a positive number when exponentially growing, and a negative number when
decaying. It is easy to show that v(t) = V0eαt, where V0 is its initial value (i.e., at t = 0).
Decaying exponentials are of special interest as they are often encountered in the analysis
of stable systems. A causal decaying exponential is shown in Figure 1.24. It is also written
as v(t) = V0e−t/τu(t), where τ is called the exponential’s time constant. The maximum
value of the function is V0 at t = 0, which also produces the (maximum) decay rate
of V0/τ at that time. This is the downward slope of the line tangent to the exponential
function at t = 0. Consequently, such a line intersects the time axis at t = τ. At t = τ,
the decaying exponential function is reduced to V0e−1 ≈0.368 V0 and at t = 2τ to
0.135 times its initial value. At t = 5τ, the reduction is more than 99%, which for
−6
−4
−2
0
2
4
6
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
cos (t − 1)
cos t
FIGURE 1.23 The sinusoidal function cos t is periodic with period T = 2π ≈6.2832 seconds.
A delay of τ seconds produces an equivalent amount, in radians, of phase lag (e.g., a one-second
delay creates a phase lag of 1 radian ≈57 degrees). Similarly, an advance of τ seconds produces
a phase lead of τ radians (or, equivalently, a phase lag of 2π −τ radians).

Signals and Systems
41
−0.5
0
0.5
1
1.5
2
2.5
3
0
0.2
0.4
0.6
0.8
1
Normalized decaying exponential function
Time (s)
Amplitude
FIGURE 1.24 A decaying exponential e−t with a time constant of τ = 1 sec. The tangent to the
function at t = 0 intersects the time axis at t = 1. The value of the function at t = 1 is ≈0.368.
most practical purposes may be considered reaching a zero value. The two parameters
(V0 and τ) of an exponential function may be computed from two measurements as
described in Example 1.10.
Example
1.10
Determining a time constant
A signal is known to be exponentially decaying toward its zero ﬁnal value. Derive its
time constant from the ratio of two measurements taken T seconds apart.
Solution
An exponentially decaying signal with zero ﬁnal value can be represented by v(t) =
Ae−t/τ, where A is the value of the signal at t = 0 and τ is its time constant. Let
V1 = Ae−t1/τ and V2 = Ae−t2/τ be the measured values at t1 and t2, respectively.
The time constant can be derived from a knowledge of V1/V2 and T = t2 −t1 by the
following:
V1
V2
= Ae−t1/τ
Ae−t2/τ = e(t2−t1)/τ = eT/τ,
and
ln
V1
V2

= T/τ, τ =
T
ln
 V1
V2

For example, let V1 = 0.6, V2 = 0.2, and T = 1 s, as shown in Figure 1.25.
Then τ = T/ ln( V1
V2 ) =
1
ln 3 = 0.91 s. Having found the time constant, the function
can now be expressed by v(t) = V1e−t/τ (taking the time of the ﬁrst measurement as
the time origin). If the time origin is already set, then the parameter A (the value of
the exponential at t = 0) can be found from V1 = Ae−t1/τ or A = V1e−t1/τ.

42
CHAPTER 1
Introduction to Signals
1
0.8
0.6
Two measurements of an exponentially decaying function.
V1
V2
0.4
Measurement values
0.2
0
t1 = 1
t2 = 2
T
Time (s)
FIGURE 1.25 Finding the time constant of a decaying exponential from two measurements.
Example
1.11
Response of an RC circuit to step and impulse voltages
A 1-	 resistor and a 1-F capacitor are connected in series with a voltage source v1(t)
as in Figure 1.26.
a.
With v1(t) = u(t) (V), the capacitor current and voltage signals are shown to be
i(t) = e−tu(t) (A) and v2(t) = (1 −e−t)u(t) (V), respectively. Plot i(t) and
v2(t) for −τ < t < 5τ, where τ is their common time constant. For each signal
determine initial and ﬁnal values.
b.
Repeat with v1(t) = δ(t).
v1
v2
C
i
+
–
+
–
R
FIGURE 1.26 An RC circuit in series with a voltage source.
Solution
a.
The unit-step voltage source is shown in Figure 1.27[a(i)]. The capacitor
current decays exponentially from 1 A to a zero value with a time constant of 1
second. It is plotted in Figure 1.27[a(ii)] for −1 < t < 5. At t = 0+ (in the

Signals and Systems
43
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
(i) Unit-step voltage source u(t).
(i) Unit-impulse voltage source d(t).
Voltage (V)
0
0.2
0.4
0.6
0.8
1
Voltage (V)
−1
0
1
2
3
4
5
Time (s)
(ii) Capacitor current e–t u(t).
(ii) Capacitor current d(t) – e–t u(t).
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
(a) Unit-step input voltage
(b) Unit-impulse input voltage
Current (A)
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Current (A)
−1
0
1
2
3
4
5
Time (s)
(iii) Capacitor voltage (1 – e–t) u(t)
(iii) Capacitor voltage e–t u(t)
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Voltage (V)
−1
0
1
2
3
4
5
Time (s)
0
0.2
0.4
0.6
0.8
1
Voltage (V)
FIGURE 1.27 Capacitor current and voltage in response to unit-step (a) and unit-impulse (b) voltage sources (see the
circuit of Figure 1.26).
direction of increasing t), the slope of the tangent to the exponential is 1 A/s.
Therefore, for small values of t such as t < 5 ms, the exponential can be appro-
ximated by its tangent line i = 1 −t/1,000 A. For example, at t = 5 ms, the
linear approximation results in a value of iapproximate = 1 −5/1,000 = 0.995 A,
while the exact value of the current is iexact = e−0.005 = 0.9950125 A. The
percentage error is
ϵ% = 100 × iexact −iapproximate
iexact
= 100 × 0.9950125 −0.995
0.9950125
≈0.001% (or one in 100,000)
This is an extremely small error, prompting an approximation of capacitor
current by the ﬂat line of a unit-step function. (For further elaboration see
problem 98.)

44
CHAPTER 1
Introduction to Signals
b.
The unit impulse is derivative of unit step. The responses of the circuit to the
unit-impulse voltage are derivatives of its responses to unit-step voltage. These
are given in Figure 1.27(b).
Complex Exponential
The function est, with s = σ + jω a complex number, is called a complex exponential
function. It is the only mathematical function that retains its functional form under the
derivative and integration operations.
d
dt {est} = sest
and

esτdτ = 1
s est
Taking the derivative of a complex exponential function changes only its magnitude
by a factor s. Similarly, taking its integral multiplies the magnitude by 1/s. This in-
variance property remains true under the class of operations called linear time-invariant
(LTI). Hence, the complex exponential function is called the characteristic function (also
eigenfunction) of the LTI systems.
Complex exponential functions can represent sinusoids, including those with time-
varying amplitudes, resulting in a simpliﬁcation of analysis. For example, consider the
function V (t) = V est with the complex magnitude V = V0e jθ. Then a sinusoidal
function of time with exponentially varying amplitude can be written as the real part (or
the imaginary part) of a complex exponential.
v(t) = V0eσt cos(ω + θ)t = RE{V (t)}
u(t) = V0eσt sin(ω + θ)t = IM{V (t)}
where
V (t) = V0eσte j(ω+θ)t = v(t) + ju(t)
Throughout an analysis, the signal V (t) may be used instead of v(t) or u(t). At the end
of the analysis the result will be converted back to the real or imaginary parts. Due to
the above properties the complex exponential function occupies a unique place in the
analysis of signals and systems, thereby called analysis in the s-domain.
Sinusoiod with Exponentially Varying Amplitude
The function v(t) = V0eσt cos(ωt + θ) is a sinusoidal function with exponential growth
(if σ > 0) or decay (if σ < 0). It is the real part of the complex exponential V (t) =
V0eσte j(ω+θ)t, where V0, σ, ω, and θ are constant real numbers. An example is shown in
Figure 1.28(a) for V0 = 1, σ = −2, ω = 10π, and θ = −π/2. For σ = 0, the amplitude
of the sinusoid is constant. For σ > 0, the amplitude of the sinusoid grows with time;
see Figure 1.28(b). The complex exponential function and its real part are completely
speciﬁed by the four parameters V0, θ, σ, and ω. These parameters are combined in pairs
as the complex amplitude V = V0e jθ (also called the phasor V = V0̸ θ) and the complex
frequency s = σ + jω. Exponential and sinusoidal functions are important building
blocks in the analysis and design of signals and linear systems and are encountered
frequently.

Signals and Systems
45
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
Amplitude
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−8
−6
−4
−2
0
2
4
6
8
Time (s)
Amplitude
(a)
(b)
FIGURE 1.28 (a) An exponentially decaying sinusoid V0eσt sin(2πft) and its envelope. V0 = 1, f = 5 Hz, σ = −2 s−1
(or, equivalently, a time constant of τ = −1/σ = 0.5 sec.). (b) An exponentially growing cosine function e2t cos(10πt)
and its envelope.
The Sinc Function
The unit-sinc function is given by sinc(t) = sin t
t ,
−∞< t < ∞, See Figure 1.29(a).
The function contains positive and negative lobes whose amplitudes diminish with t. The
main lobe is centered at t = 0 and has a maximum of sinc(0)=1. Zero-crossings occur
at t = ±kπ, where k is a nonzero integer. The regularity of the zero-crossings produces
positive and negative lobes which create a sort of periodicity.
−6
−4
−2
0
2
4
6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Amplitude
−5
−4
−3
−2
−1
0
1
2
3
4
5
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Amplitude
(a)
(b)
FIGURE 1.29 (a) A unit-sinc function sinc(t) = sin(t)
t . Zero-crossings are at t = ±kπ. The area under the sinc function
is equal to the area of the dashed triangle within the main lobe. (b) A sinc function sinc(πt) = sin(πt)
πt . Zero-crossings are
at t = ±k (Example 1.12).

46
CHAPTER 1
Introduction to Signals
Example
1.12
Write the mathematical expression for a sinc function with a maximum value of 1
and a main lobe that is 2 sec wide.
Solution
The general expression for a sinc function is x(t) = sin(at)/(bt). To ﬁnd a we note
that the ﬁrst pair of zero-crossings occurs at ±1. The other crossings occur at t = ±k,
where k is a nonzero integer. The numerator of the sinc function is, therefore, sin(πt).
To ﬁnd b we note that x(0) = a/b = 1 which results in b = π. The mathematical
expression for the desired unit-sinc function is sinc(πt) = sin πt
πt . Figure 1.29(b) plots
this unit-sinc function.
Example
1.13
Determinethemaximumvalueandzero-crossingsofthesincfunction x(t) = sin(2π f0t)
πt
in terms of f0. Determine f0 so that the main lobe of the function is 1 ms wide.
Solution
The maximum of the function occurs at t = 0. The value of the maximum is
lim
t→0
sin(2π f0t)
πt
=
d
dt [sin(2π f0t)]
d
dt (πt)
					
t=0
= 2 f0 cos(2π f0t)
		
t=0 = 2 f0
Zero-crossingsoccurat2π f0t = ±kπ ort = ± k
2 f0 ,k beinganinteger.For f0 = 1kHz
the main lobe is 1 ms wide.
Gaussian Function
The normalized Gaussian function is
e−πt2,
−∞< t < ∞
It is an even function of t and positive with a peak value of 1 at t = 0. As t →0, the
Gaussian function diminishes to zero faster than the exponential function does.
Example
1.14
Show that the area under the normalized Gaussian function is equal to 1:
 ∞
−∞
e−πt2dt = 1
Solution
Start with the square of the integral and transform it to the polar coordinate system:

 ∞
−∞
e−πt2dt
2
=

 ∞
−∞
e−πx2dx
 
 ∞
−∞
e−πy2dy

=
 ∞
−∞
 ∞
−∞
e−π(x2+y2)dxdy
=
 ∞
r=0
 2π
θ=0
re−πr2dθdr =
 ∞
0
2πre−πr2dr

Signals and Systems
47
where x2 + y2 = r2 and dxdy = rdθdr. To evaluate the last integral let πr2 = t and
2πrdr = dt. Then,
 ∞
0
2πre−πr2dr =
 ∞
0
e−tdt = 1
Example
1.15
The following function is called the Gaussian density function with a mean value of
µ and variance = σ 2.
f (x) =
1
σ
√
2π
e−(x−µ)2
2σ2
Show that a)
 ∞
−∞f (x)dx = 1 for any set of µ and σ, b)
 ∞
−∞x f (x)dx = µ, and
c)
 ∞
−∞(x −µ)2 f (x)dx = σ 2.
Solution
Let x −µ = σ
√
2πt and dx = σ
√
2πdt.
a.
 ∞
−∞
f (x)dx =
 ∞
−∞
1
σ
√
2π
e−t2σ
√
2πdt =
 ∞
−∞
e−πt2dt = 1
b.
 ∞
−∞
x f (x)dx =
 ∞
−∞
(µ + σ
√
2πt)e−πt2dt
= µ
 ∞
−∞
e−πt2dt + σ
√
2π
 ∞
−∞
te−πt2dt = µ
c.
 ∞
−∞
(x −µ)2 f (x)dx =
 ∞
−∞
2πσ 2t2e−πt2dt
= σ 2 
−te−πt2∞
−∞+ σ 2
 ∞
−∞
e−πt2dt = σ 2
Pulses and Windows
Apulseisasignalwithitsenergymostlyconcentratedduringaﬁnitedurationoftime.The
exponential, sinc, and Gaussian functions introduced previously exemplify one class of
such pulses. Another class consists of strictly time-limited pulses with zero value outside
their durations:
x(t) =

f (t),
−τ
2 < t < τ
2
0,
elsewhere
Time-limited pulses are of much practical interest. They constitute the basic building
blocks in analog electrical instruments such as function generators. They are also the
focus of signal design for transmission of digital data. Finite-duration pulses also serve

48
CHAPTER 1
Introduction to Signals
t
t
2
(a) Rectangular window
w(t) = 1,
(b) Triangular window
w(t) = 1 – 2 |t|
t
–
T
V0
t
2
0
t
t
2
–
T
V0
0
t
2
t
t
2
–
T
V0
0
t
2
t
t
2
–
T
V0
0
t
2
t
t
2
–
T
V0
V1
0
t
2
t
t
2
–
T
V0
0
t
2
(d) Sawtooth pulse
p(t) =     + 1
2
t
t
(e) Rectified cosine pulse
p(t) = cos
(c) Raised cosine window
w(t) = 0.5 + 0.5 cos 2pt
t
(
)
pt
t
(
)
(f) Finite exponential
, time constant = q
t
2
(t + )
p(t) = e– 1
q
FIGURE 1.30 Windows and pulses with V0 = 1.
as windows. A window is a ﬁnite-duration pulse through which we look at a data stream
or a function such as an impulse response. The ﬁrst row in Figure 1.30 shows three
such windows (rectangular, triangular, and raised cosine). The second row shows three
other familiar pulses from which a variety of pulse shapes and periodic signals may be
constructed. All pulses are τ sec wide and expressed in the interval −τ/2 < t < τ/2.
Elsewhere, the pulses have zero values.
1.15
Time Averages
Power and Energy
The square of f (t) is called its power. Its energy from t0 to t0 + T is
Energy =
 t0+T
t0
f 2(t)dt
If the integration over the inﬁnite range of time results in a ﬁnite number, then f (t) is
called an energy signal. A ﬁnite-duration pulse has ﬁnite energy. However, not all energy
functions are necessarily of ﬁnite length. An energy signal may have inﬁnite duration.
Examples are the sinc function, pulses, and functions whose amplitudes are modulated
by an exponential decay. Clearly, energy signals are not periodic.
The average of power from t0 to t0 + T is
Average power = 1
T
 t0+T
t0
f 2(t)dt

Signals and Systems
49
For a periodic function with a period T , the integral may be taken over any time duration
nT , where n is a positive integer. If a function has inﬁnite energy it might have ﬁnite
power, in which case it is called a power function. Periodic functions are power functions.
Many random functions are also modeled as power functions. Nonperiodic functions can
have ﬁnite power, too.
Average (DC) and Effective (RMS) Values
The average (also called the DC value) of f (t) from t0 to t0 + T is
favg = 1
T
 t0+T
t0
f (t)dt
The rms (which stands for root-mean-square) or effective value of f (t) from t0 to t0+T is
frms =

1
T
 t0+T
t0
f 2(t)dt
From the above deﬁnition, the average power in f (t) is equal to the square of its rms
value; that is, Pavg = f 2
rms. The rms value of a function, therefore, is a measure of its
average power and is often used to identify signals and noise powers and their effects.
Because of this, the rms value is also called the effective value (i.e., feff and frms are
equivalent).
Calculating Averages
Averaging is a linear operation and also invariant with respect to time shift. Multiplying
a function by a constant k, multiplies its DC and rms values by k and its average power
by k2. These properties can be used to simplify evaluation of the DC and rms values and
average power.
Example
1.16
a.
Find the DC value and average power of the unit-sawtooth pulse
x(t) =

t,
0 ≤t < 1
0,
elsewhere
taken over a period of T .
b.
Find the DC value and average power of the even triangular pulse
y(t) =

1 −2 |t|
τ ,
−τ
2 ≤t < τ
2.
0,
elsewhere
[Figure 1.30(b)] taken over a period of T .

50
CHAPTER 1
Introduction to Signals
Solution
a.
The area under x(t) is 1
2 and its DC value during a period T is xDC =
1
2T . The
average power is
1
T
 1
0
t2dt =
1
(3T )
b.
The area under y(t) is τ
2 and its DC value is yDC =
τ
2T . To evaluate the average
power shift y(t) by τ/2, calculate the energy in the left-half side of the pulse
and then double it:
PAvg = 2
T
 τ/2
0
2
τ t
2
dt
To evaluate the integral, let 2
τ t ≡θ and use the result of part (a) to ﬁnd
PAvg = 2
T
τ
2
 1
0
θ2dθ = τ
3T
Note that the DC value and average power in (b) may be directly derived from
those in (a).
Example
1.17
Find the DC values, average powers, and the rms values of the pulses of Figure 1.30
taken over a period of T . In all cases a pulse width is τ and its height is V0 = 1.
Solution
Pulse
Equation
DC Value
PAvg
RMS Value
Shape

−τ
2 < t < τ
2

During T
During T
During T
Rectangular
1
τ
T
τ
T
 τ
T
Triangular
1 −2|t|
τ
τ
2T
τ
3T
 τ
3T
Raised cosine
0.5 + 0.5 cos

2πt
τ

1
2T
3τ
8T

3τ
8T
Sawtooth
t
τ + 1
2
τ
2T
τ
3T
 τ
3T
Rectiﬁed cosine
cos
πt
τ

2τ
πT
τ
2T
 τ
2T
Finite exponential
e−1
θ (t+ τ
2 )
θ
T

1 −e−τ
2 )
θ
2T [1 −e−2τ
θ ]

θ
2T

1 −e−2τ
θ 

Signals and Systems
51
1.16
Operations on Signals
Signal processing involves analytical and computational operations on signals done for
a variety of purposes; examples are enhancing a signal, reducing noise and disturbances,
compensating for some deﬁciencies in a system’s performance, recording and storing
data, coding, ﬁltering, analyzing, detecting, synthesizing, designing, and predicting a
signal. Signals include speech, audio, images, communication, geophysical, sonar, radar,
medical, societal, commercial, and ﬁnancial. Presenting signal by components that are
suitable for processing (such as in harmonics analysis) is a main step in signal processing.
In addition, recognizing classes of waveforms and wavelets speciﬁc to a signal (such
as those mentioned for seismic, physiologic, and speech signals) provides additional
processing avenues tailored to that signal. Signal processing operations are, therefore,
done in the time domain (i.e., on the signals that are expressed as functions of time) and
in the frequency domain (on the frequency representations of signals). Examples of such
operations of common interest are integration, differentiation, correlation, convolution,
spectral analysis, and ﬁltering. The last four operations involve integration of weighted
signal and, therefore, have much in common. These operations are brieﬂy introduced
below and will be discussed in detail in future chapters.
1.17
Time Transformation
Some elementary operations are widely applied in signal processing. Among these are
time shift (delay or advance), time reversal, and time scaling. These elementary opera-
tions provide basic mathematical tools and building blocks for higher-level operations
such as correlation, convolution, and ﬁltering. In addition, some elementary operations
are also associated with physical phenomena such as time delay or space displacement.
A graphical visualization by signal plots is often helpful, especially when time reversal
and time shift are combined. These operations are described below.
Time Shift
For notational convenience, let τ be a positive constant. In a signal modeled by the
function x(t) change t to t −τ and obtain x(t −τ). This shifts the plot of x(t) to the right
by τ units and, therefore, is called shifting to the right. When the variable t represents
actual time, the above operation represents a time delay as in an echo of a radar signal
bouncing from a target or an audio signal bouncing from a wall. Conversly, a shift to the
left by τ units converts x(t) to x(t +τ) and is called an advance. In summary, to produce
a delay (shift to the right) or an advance (shift to the left) in x(t) change t to t ∓τ,
respectively. Time shift was brieﬂy illustrated for elementary functions in section 1.14
and Figures 1.19, 1.21, 1.22, and 1.23.

52
CHAPTER 1
Introduction to Signals
Example
1.18
The effect of 1-unit shifts (to the left and right) on a sawtooth pulse is shown in
Figure 1.31. The left side is a shift to the left and the right side is shift to the right.
x(t + 1)
x(t + 1)
1
0
–1
t
x(t)
x(t)
1
0
1
t
x(t – 1)
x(t)
2
1
0
1
t
FIGURE 1.31 Time-shifting a sawtooth pulse.
Example
1.19
The effect of 1-unit shifts on a unit-step function is given below. The left side shows
a shift to the left and the right side shows a shift to the right.
u(t + 1) =

1,
t ≥−1
0,
t < −1,
u(t) =

1,
t ≥0
0,
t < 0,
u(t −1) =

1,
t ≥1
0,
t < 1
Example
1.20
The effect of 1-unit shifts (to the left and right) on a causal exponential function is
shown below. The left side is a shift to the left and the right side is a shift to the right.
x(t + 1) = e−(t+1)u(t + 1),
x(t) = e−tu(t),
x(t −1) = e−(t−1)u(t −1)
Example
1.21
The effect of a 2-second delay on a causal exponential function with a 1-second time
constant is shown by
x(t) = 2−tu(t),
x(t −2) = 2−(t−2)u(t −2) = 4 × 2−tu(t −2)
The effect of the delay may also be shown in the following way:
x(t −2) =

2−(t−2),
(t −2) ≥0
0,
(t −2) < 0 =

4 × 2−t,
t ≥2
0,
t < 2
The last presentation expresses the effect of u(t −2) verbally; that is, by noting that
x(t −2) is zero for t < 2 and equal to 4 × 2−t for t ≥2 and it appears to be more
convenient and intuitive.

Signals and Systems
53
Time Reversal
Change t to −t in x(t) and you will have a time reversal (also called a time inversion). For
example, reversing time in the causal exponential function x(t) = 2−tu(t) will produce
x(−t) = 2tu(−t) =

2t,
t ≤0
0,
t > 0
Time reversal ﬂips the plot of x(t) around the origin producing its mirror image with
respect to the ordinate (vertical axis). Obviously, when the variable t represents actual
time, its reversal is not realizable in real time but only off-line and on the recorded
data (e.g., by reversing the motion of a tape recorder and running it backward) or by
constructing a mathematical function that models the time-reversed signal.
Example
1.22
The effect of time reversal on a sawtooth pulse is shown in Figure 1.32.
x(t)
x(t)
x(–t)
1
1
0
t
1
1
–1
0
x(–t)
t
FIGURE 1.32 Time reversal of a sawtooth pulse.
Example
1.23
The effect of time reversal on a delayed unit-step function is given below.
x(t) = u(t −1) =

1,
t ≥1
0,
t < 1,
x(−t) = u(−t −1) =

1,
t ≤−1
0,
t > −1
Example
1.24
The effect of time reversal on three exponential functions is given below.
a.
x(t) = e−2tu(t)
x(−t) = e2tu(−t)
b.
x(t) = e−2tu(t −2)
x(−t) = e2tu(−t −2)
c.
x(t) = e−2tu(−t + 1)
x(−t) = e2tu(t + 1)
Combining Time Shift and Reversal
Mathematically, in the equation that describes x(t) change t to −(t −t0) and you have
combined time reversal and a time shift of t0 (for both positive and negative values

54
CHAPTER 1
Introduction to Signals
of t0).10 When using signal plots, note that the time-reversal operation is pivoted around
t = 0.
Example
1.25
The effect of time reversal on a sawtooth pulse followed by unit shifts to the right
and left is shown in Figure 1.33. The ﬁgure on the top is the original pulse x(t). The
second row shows its reversal x(−t). The reversal of x(t) followed by 1-unit shift to
the right is shown in the third row. The fourth row is x(−t + 1), the reversal of x(t)
followed by a 1-unit shift to the right.
(a) x(t) =
 t,
0 ≤t < 1
0,
elsewhere
x(t)
1
1
–1
0
t
(b) x(−t) =
 −t,
−1 < t ≤0
0,
elsewhere
x(–t)
1
1
–1
0
t
(c) x(−t + 1) =
 −t + 1,
0 < t ≤1
0,
elsewhere
x(–t + 1)
1
1
0
t
(d) x(−t −1) =
 −t −1,
−2 < t ≤−1
0,
elsewhere
x(–t – 1)
1
1
–1
–2
0
t
FIGURE 1.33 Combination of time reversal and unit shifts on a sawtooth pulse.
10Time reversal in conjunction with time shift is used in superposition of responses due to several inputs
arriving at various times. The method is called convolution and will be discussed in detail in Chapter 4.

Signals and Systems
55
Example
1.26
This example examines the order of operations on a unit-step function when combin-
ing time reversal and shift.
a.
Time reversal followed by time shift:
unit-step function:
u(t)
time reversal:
u(−t)
time reversal followed by unit shift to left:
u(−t −1)
time reversal followed by unit shift to right:
u(−t + 1)
b.
Time shift followed by time reversal:
unit shift to right:
u(t −1)
unit shift to right followed by time reversal:
u(−t −1)
unit shift to left:
u(t + 1)
unit shift to left followed by time reversal:
u(−t + 1)
The validity of the above results may be checked by applying the deﬁnition of the
unit-step function or by applying the graphical effects of time shift and reversal. Note
that changing the order of time shift and time reversal would lead to the same result
only if at the same time delay and advance are also interchanged. As an example,
u(−t −1) may be obtained by a delay/reverse sequence; ﬁrst introduce a 1-unit
delay in u(t) (by changing t to t −1) to produce u(t −1), then reverse u(t −1) (by
changing t to −t) to obtain u(−t −1). Conversely, u(−t −1) may be obtained by a
reverse/advance sequence; ﬁrst reverse u(t) to obtain u(−t), then introduce a 1-unit
advance in u(−t) (by changing t to t + 1) to produce u(−(t + 1)) = u(−t −1).
Example
1.27
The results of time reversal and unit shifts (to the left or right) on two exponential
functions x(t) and y(t) are given below. In this example y(t) = x(−t). Note that
x(−t + 1) = y(t −1) and x(−t −1) = y(t + 1). This indicates, as in Example 1.26,
that changing the order of time shift and time reversal would lead to the same result
only if, at the same time, delay and advance are also interchanged.
function
⇒unit shift to left
⇒time reversal
(a) x(t) = e−tu(t)
⇒x(t + 1) = e−(t+1)u(t + 1)
⇒x(−t + 1) = e(t−1)u(−t + 1)
(b) y(t) = etu(−t) ⇒y(t + 1) = e(t+1)u(−t −1)
(c) x(t) = e−tu(t)
⇒x(t −1) = e−(t−1)u(t −1)
⇒x(−t −1) = e(t+1)u(−t −1)
(d) y(t) = etu(−t) ⇒y(t −1) = e(t−1)u(−t + 1)

56
CHAPTER 1
Introduction to Signals
Time Scaling
Change t to at in x(t), where a is a constant called the scale factor, and you will have
time scaling. For example, a causal exponential function and its time-scaled (by a factor
of 2) version are
x(t) = 2−tu(t)
x(2t) = 2−2tu(2t) = 4−tu(t) =

4−t,
t ≥0
0,
t < 0
Scaling time by a factor greater than 1 compresses the time axis in the plot of x(t).
Conversely, a factor smaller than 1 stretches the time axis.
Example
1.28
A sawtooth pulse x(t) with a base of 1 second starts at t = 1. The pulse x(2t) is a
sawtooth with a base of 0.5 second and starts at t = 0.5. See Figure 1.34.
1
1
0
2
t
x(t)
x(2t)
1
1
0.5
0
1
t
FIGURE 1.34 Time compression of a sawtooth pulse.
When the variable t represents actual time, its scaling is not realizable in real time but
only off-line, on the recorded data (e.g., by running a tape recorder at a faster or slower
speed), or through the mathematical functions that model the signal. Time transformation
is used in multirate signal processing, decimation, and interpolation, all of which require
storage of the signal.
General Form of Time Transformation
A time transformation that changes t to at +b, with a and b positive or negative numbers,
can represent a combination of time shift, reversal, and scaling.

Signals and Systems
57
−8
−6
−4
−2
0
2
4
6
8
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
−8
−6
−4
−2
0
2
4
6
8
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
x(t) = e−t u(t)
y(t) = x(−0.2t + 1) = e0.2(t−5) u(−t + 5)
FIGURE 1.35 Time transformation from t to 1 −0.2t.
Example
1.29
a.
Find y(t) = x(−0.2t + 1) from x(t) = e−tu(t).
b.
Plot x(t) and y(t). Describe how to obtain the plot of y(t) from the plot of x(t).
Solution
a.
y(t) = e−(−0.2t+1)u(−0.2t + 1) = e0.2(t−5)u(−t + 5).
b.
See Figure 1.35. The plot of y(t) is produced by reversing the plot of x(t),
shifting it by 5 units to the right, and increasing its time constant by a factor of 5.
Summary of Time Transformation
The general form of time transformation means changing t to at + b where a and b are
positive or negative constants. In this section we have considered the following special
cases individually:
Time shift: a = 1, b ̸= 0
Time reversal: a = −1, b = 0
Combined time shift and reversal: a = −1, b ̸= 0
Time scaling: 0 < a ̸= 1, b = 0
For implementation, we replace t by at + b in the expression that describes a
function. The expression may be verbal, analytical, or a computer program.

58
CHAPTER 1
Introduction to Signals
1.18
Even and Odd Functions
A function f (t) is even if f (t) = f (−t) for all t. An example of such a function
is cos(ωt). A function f (t) is odd if f (t) = −f (−t) for all t. An example of such a
function is sin(ωt). Any function f (t) may be represented by the sum of two components
such that f (t) = fe(t) + fo(t), where fe(t) is an even function, called the even part of
f (t), and fo(t) is an odd function, called the odd part of f (t). For example,
f (t) = cos(ωt −θ) = fe(t) + fo(t), where
fe(t) = cos θ cos(ωt)
fo(t) = sin θ sin(ωt)
Another example is
f (t) = sin(ωt −θ) = fe(t) + fo(t), where
fe(t) = −sin θ cos ωt
fo(t) = cos θ sin ωt
The even and odd parts of a function are uniquely determined from the following:
fe(t) = f (t) + f (−t)
2
fo(t) = f (t) −f (−t)
2
Example
1.30
The even and odd parts of f (t) = 2u(t) are
fe(t) = f (t) + f (−t)
2
= 2u(t) + 2u(−t)
2
= 1
fo(t) = f (t) −f (−t)
2
= 2u(t) −2u(−t)
2
△= sgn(t)
where sgn(t) (pronounced as signum, standing for sign of) is deﬁned by
sgn(t) =

1,
for t > 0
−1,
for t < 0
The unit-step can then be written as
u(t) = 1
2(1 + sgn(t))
Example
1.31
Find the even and odd parts of the square pulse:
f (t) =
2,
for 0 < t < 1
0,
elsewhere

Signals and Systems
59
Solution
Apply the rule to ﬁnd
fe(t) =

1,
for −1 < t < 1
0,
elsewhere
fo(t) =



−1,
for −1 < t < 0
1,
for 0 < t < 1
0,
elsewhere
Example
1.32
Find the even and odd parts of a sawtooth pulse:
f (t) =
 2 + t,
for −1 < t < 1
0,
elsewhere
−3
−2
−1
0
1
2
3
−1
−0.5
0
0.5
1
1.5
2
2.5
3
(a)
Solution
fe(t) =
 (2+t)+(2−t)
2
= 2,
for −1 < t < 1
0,
elsewhere
−3
−2
−1
0
1
2
3
−1
−0.5
0
0.5
1
1.5
2
2.5
3
(b)
fo(t) =
 (2+t)−(2−t)
2
= t,
for −1 < t < 1
0,
elsewhere
−3
−2
−1
0
1
2
3
−1
−0.5
0
0.5
1
1.5
2
2.5
3
(c)
FIGURE 1.36 (a) A sawtooth pulse, (b) even part, (c) odd part.

60
CHAPTER 1
Introduction to Signals
Even and Odd Parts of Causal Signals
A function f (t) is causal if f (t) = 0, t < 0. The even and odd parts of a causal function
are related to each other and a causal function may be obtained from its even part or from
its odd part alone. Any one of the three functions can specify the others by the equations
given below:
f (t) = 2 fe(t)u(t) = 2 fo(t)u(t)
Example
1.33
Show that a causal function f (t) may be obtained from its even part or from its odd
part alone by f (t) = 2 fe(t)u(t) = 2 fo(t)u(t).
Solution
fe(t) = f (t) + f (−t)
2
⇒

for t < 0 f (t) = 0,
therefore, fe(t) = 1
2 f (−t),
t < 0
for t > 0 f (−t) = 0,
therefore, fe(t) = 1
2 f (t),
t > 0
fo(t) = f (t) −f (−t)
2
⇒

for t < 0 f (t) = 0,
therefore, fo(t) = −1
2 f (−t), t < 0
for t > 0 f (−t) = 0,
therefore, fo(t) = 1
2 f (t),
t > 0
In summary,
fe(t) =
 1
2 f (−t),
for t < 0
1
2 f (t),
for t > 0
fo(t) =

−1
2 f (−t),
for t < 0
1
2 f (t),
for t > 0
Note that
fe(t) = −fo(t) = 1
2 f (−t), for t < 0
fe(t) = fo(t) = 1
2 f (t), for t > 0
Checking the results,
fe(t) + fo(t) =

0,
for t < 0
2 fe(t) = 2 fo(t) = f (t),
for t > 0
In conclusion, for a causal f (t)
f (t) = 2 fe(t)u(t) = 2 fo(t)u(t)
fe(t) = f (t) + f (−t)
2
= fo(t)sgn(t)
fo(t) = f (t) −f (−t)
2
= fe(t)sgn(t)

Signals and Systems
61
Simply put, in the case of a causal function

for t > 0,
fe(t) = fo(t) = 1
2 f (t)
for t < 0,
fe(t) = −fo(t) and f (t) = 0
The even and odd parts of a causal function f (t) are equal for t > 0; To ﬁnd them,
scale f (t) down by a factor of 2. For t < 0, ﬂip them around the origin (and also
vertically for the odd part).
Example
1.34
Find the even and odd parts of f (t) = e−αtu(t) and verify the statement in Exam-
ple 1.33.
Solution
fe(t) = e−αtu(t) + eαtu(−t)
2
= 0.5e−α|t|,
2 fe(t)u(t) = e−αtu(t) = f (t)
fo(t) = e−αtu(t) −eαtu(−t)
2
= 0.5e−α|t|sgn(t),
2 fo(t)u(t) = e−αtu(t) = f (t)
1.19
Integration and Smoothing
The integral of a function x(t) over a time period from t1 to t2 is given by
 t2
t1
x(t)dt
The value of the integral is the area under the plot of x as the dependent variable versus t
as the independent variable. For a discrete-time function x(n), integration over the range
n = k1 to k2 becomes summation of its element values within that range.
k2

n=k1
x(n)
In either case integration removes discontinuities in the signal, reduces the variations,
and results in smoothing.
Example
1.35
An example of the smoothing property of integration is shown in Figure 1.37. The
function
x(t) =



1,
0 ≤t < 0.5
−1,
2.5 ≤t < 3,
0,
elsewhere
which is shown in Figure 1.37(a), is discontinuous at four locations t = 0, 0.5, 2.5,
and 3. For example, at t = 0 the function experiences a unit jump: x(0+)−x(0−) = 1.
Its integral y(t) =
 t
−∞x(t)dt, shown in Figure 1.37(b), becomes a continuous
function. The discontinuities in x(t) manifest themselves as discontinuities in the

62
CHAPTER 1
Introduction to Signals
derivative of y(t). At the locations of former discontinuities the derivative of y(t) will
depend on the direction from which one approaches the location. When approaching
t = 0 from the left direction, the derivative of y(t) is zero while from the right
direction the derivative is 1. Integrating once more, z(t) =
 t
−∞y(t)dt, removes the
discontinuities in the derivative of y(t) [see Figure 1.37(c)].
(a) x(t) =

1,
0 ≤t < 0.5
−1,
2.5 ≤t < 3
0,
elsewhere
−1
0
1
2
3
4
5
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
(b)
y(t) =
 t
−∞
x(t)dt
=





t,
0 ≤t < 0.5
0.5,
0.5 ≤t < 2.5
3 −t,
2.5 ≤t < 3
0,
elsewhere
−1
0
1
2
3
4
5
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
Time (s)
Magnitude
(c)
z(t) =
 t
−∞
y(t)dt
=







0,
t < 0
0.5t2,
0 ≤t < 0.5
0.5t −0.125,
0.5 ≤t < 2.5
−0.5t2 + 3t −3.25,
2.5 ≤t < 3
1.25,
t ≥3
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Time (s)
Magnitude
FIGURE 1.37 Smoothing effect of integration.

Signals and Systems
63
Example
1.36
Another illustrative example of the smoothing property of integration is its effect on
high-frequency components of a signal. Take the integral of a cosine function at the
frequency ω:
 t
−∞
cos(ωt)dt = 1
ω sin(ωt)
After integration, the amplitude of the sinusoid is reduced by the factor ω, reducing
its power by ω2. Integrating random functions and noise also reduces their variance
and thus their power.
Practical Integrators
In practice real-time integration of signals is made by electrical, pneumatic, or hydraulic
instruments. The following three examples discuss performance of three analog circuits
commonly used for integration.
Example
1.37
An ideal integrator circuit
The op amp circuit of Figure 1.38(a) is an ideal integrator (considering the op amp
to be an ideal one). The input to the circuit is the voltage v1 and the output is v2, both
functions of t. To ﬁnd the input–output relationship, we ﬁrst note that the ideal op
amp draws zero current at the input terminals (nodes A and B) and when operating as
an element of a linear circuit it brings the inverting and noninverting terminals to the
same voltage level [vA = vB = 0 in Figure 1.38(a)]. The input voltage generates the
resistor current i = v1/R, all of which passes through the capacitor. The capacitor
integrates the current and produces the output voltage
v2(t) = −1
C
 t
−∞
i(τ)dτ = −1
RC
 t
−∞
v1(τ)dτ
The factor 1/(RC) is the gain of the integrator circuit and is dimensionless. The
negative sign in front of the above integral indicates that the circuit inverts the in-
tegration results. The output voltage is the integral of the input multiplied by the
number −1/(RC), where R is in ohms and C is in farads. For example, with R = 1
M	 and C = 1 µF, the magnitude gain of the integrator circuit of Figure 1.38(a)
is 1/(RC) = 1/(106 × 10−6) = 1. The input voltage v1(t) produces an output
voltage v2(t) = −
 t
∞v1(t). With v1(t) = est and an integrator circuit with a unity
magnitude gain, the output is v2(t) = −1
s v1(t). The gain of the exponential signal
passing through the integration is −1/s, which diminishes with increasing s. In the
sinusoidal case of v1(t) = cos ωt, the input and output voltages may be written as
v1(t) = RE{e jωt} and v2(t) = RE{ j
ωe jωt}, respectively. The gain of the integration
operation is the complex number j
ω, which means a magnitude change of 1
ω and a 90◦
phase advance.

64
CHAPTER 1
Introduction to Signals
+
–
R
A
B
v2
v1
C
i
i
+
–
FIGURE 1.38 (a) An ideal integrator circuit. The op amp makes the inverting input a virtual
ground (vA = 0), thus the resistor current becomes i = v/R. All of the current goes through the
capacitor (the op amp does’t draw any current), establishing an output voltage proportional to the
integral of the input voltage, with a negative sign.
v1
v2
C
i
+
R
–
+
–
FIGURE 1.38 (b) An RC integration circuit. The capacitor voltage in a series RC circuit is the
integral of the current, not the input voltage. It can be shown that in this circuit v2(t) is the integral
of the product of the input voltage and an exponential weighting function, see Example 1.38. In
addition, v2(t) is also modiﬁed when a load is connected to the output of the circuit.
v2
R1
A
B
i2 C
R2
i1
iC
+
–
v1
+
–
FIGURE 1.38 (c) A leaky integrator circuit using an ideal op amp. The circuit operates similar to
the ideal integrator of Figure 1.38(a), except that the resistor in parallel with the capacitor provides
a path for the capacitor charges to leak through it, thereby reducing the output voltage v2. The
operation can also be qualitatively analyzed in terms of the effect of the frequency of the input
signal; From an AC point of view, the input current i1 = v1/R1 gets divided between i2 and iC,
with the current in each element being inversely proportional to the impedance of that element.
At higher frequencies, the capacitor has a lower impedance, thus absorbing a bigger share of the
input current. This leaves less current to pass through R2 and reduces v2. The reduction in v2(t)
accentuates as the frequency goes up.

Signals and Systems
65
Example
1.38
RC integrator circuit
The passive RC circuit of Figure 1.38(b) [with v1(t) as the input and v2(t) as the
output] implements an integration with an exponential weighting factor. In that ﬁgure,
the input–output differential equation and its solution are
d
dt v2(t) + αv2(t) = αv1(t), where α =
1
RC
v2(t) = α
 t
−∞
e−α(t−τ)v1(τ)dτ
In the above, v1(τ) is weighted by αe−α(t−τ), where (t −τ) is the distance from the
past. The above integral is called a convolution integral.
Example
1.39
Leaky integrator in the time domain
The integration equations obtained for the RC integrator of Example 1.38, how-
ever, may change when another device is connected to the output. The circuit of
Figure 1.38(c) contains an op amp that overcomes this limitation. To ﬁnd v2(t) as a
weighted integral of v1(t), we ﬁrst obtain the differential equation relating v2(t) to
v1(t). From that circuit we have:
i1(t) = v1(t)
R1
, i2(t) = −v2(t)
R2
, iC(t) = −C dv2
dt
iC(t) + i2(t) = i1(t)
d
dt v2(t) +
1
R2C v2(t) = −1
R1C v1(t)
The time-domain solution to the above differential equation is
v2(t) = −1
R1C
 t
−∞
e−(t−τ)
R2C v1(τ)dτ
As in Example 1.38 the above is also a convolution integral. v1(τ) is weighted by
1
R1C e
−(t−τ)
R2C , where (t −τ) is the distance from the past.
Example
1.40
Leaky integrator in the s-domain
For a direct quantitative analysis of the operation of the leaky integrator in the s-
domain, let v1(t) = V1est. The input current i1 = v1/R1 = (V1/R1)est ≡I1est gets
divided between R2 and C as i2(t) = I2est and iC(t) = ICest. [Note that i2(t) and
iC(t) are necessarily exponentials.]
Kirchhoff’s current law requires I2est + ICest = I1est
or
I2 + IC = I1.
Kirchhoff’s voltage law requires R2I2est = IC
Cs est
or
R2I2 = IC
Cs .

66
CHAPTER 1
Introduction to Signals
From the above set of equations we ﬁnd
I2 =
I1
1 + R2Cs , i2(t) =
I1
1 + R2Cs est, and v2(t) = −R2i2(t) = −R2
R1
V1
1 + R2Cs est
With increasing s the magnitude of the output voltage gets reduced.
Time-Domain Solution Versus s-Domain
We have analyzed the operation of the leaky integrator by two methods, to be called
the time- and s-domain methods. In future chapters the relationship between these two
solutions will become clear. Here we verify that the s-domain solution obtained for the
leaky integrator is in agreement with the solution obtained in the time domain. For this,
after substituting for v1(t) = V1est, we evaluate the convolution integral for the time-
domain solution. The result is the same as the solution obtained by direct application of
v1(t) = V1est in the s-domain.
v1(t) = V1est
v2(t) = −1
R1C
 t
−∞
e−(t−τ)
R2C v1(τ)dτ
= −V1
R1C e−
t
R2C
 t
−∞
e
τ
R2C esτdτ
= −V1
R1C e−
t
R2C
 t
−∞
e(s+
1
R2C )τdτ
= −V1
R1C
1

s +
1
R2C
e−
t
R2C e(s+
1
R2C )t
= −R2
R1
V1
1 + R2Cs est (Q.E.D)
Example
1.41
Summary of responses of integrators to impulse, step,
and pulse functions
The response of a unity-gain ideal integrator to a unit-impulse input is a unit-step
function and its response to a unit-step is a unit ramp. A rectangular pulse input
creates a steplike function that reaches its DC steady-state level linearly within the
time duration of the input pulse. A unit-step input results in a unit ramp that grows
linearly with time. The above sets of inputs are expressed mathematically in column 1
of Figure 1.39 with their plots shown in column 2. Column 3 shows the corresponding
response of a unity-gain ideal integrator and column 4 shows the response of a leaky
integrator with a time constant of 200 µsec. The leaky integrator doesn’t sustain
a DC level in its response to the impulse. Its response to a step input becomes an
exponential with a ﬁnite ﬁnal value rather than a ramp. This becomes a desired
feature when accumulation of a small DC level would threaten to saturate the op amp
in the circuit.

Signals and Systems
67
−1 −0.5 0 0.5 1 1.5 2 2.5 3 3.5 4
−0.2
0
0.2
0.4
0.6
0.8
Input
Output of Perfect Integrator
Output of Leaky Integrator
1
1.2
Time (s)
Magnitude
−1 −0.5 0 0.5 1 1.5 2 2.5 3 3.5 4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
(a)
(b)
(c)
(d)
Magnitude
−1 −0.5 0 0.5
1 1.5 2 2.5
3 3.5 4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
−1 −0.5 0 0.5 1 1.5 2 2.5 3 3.5
4
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
−1 −0.5 0
0.5 1
1.5 2
2.5 3
3.5 4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
−1 −0.5 0 0.5 1 1.5 2 2.5 3 3.5 4
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
−1 −0.5 0 0.5 1 1.5 2 2.5 3 3.5
4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
Time (s)
−1 −0.5 0 0.5
1 1.5 2 2.5 3 3.5 4
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Magnitude
−1 −0.5 0 0.5 1 1.5 2 2.5 3 3.5 4
−0.5
0
0.5
1
1.5
2
2.5
3
Time (s)
Magnitude
−1−0.5 0
0.5 1 1.5
2 2.5 3 3.5 4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
−1 −0.5 0 0.5 1 1.5
2 2.5 3 3.5 4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
−1 −0.5
0 0.5 1 1.5 2 2.5 3 3.5 4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
FIGURE 1.39 Responses of perfect and leaky integrators to impulse, step, and pulse voltage inputs. The inputs are (a)
δ(t), (b) δ(t) −δ(t −1), (c) u(t), (d) u(t) −u(t −1).

68
CHAPTER 1
Introduction to Signals
1.20
Weighted Integration
In integrating a function x(τ) from τ = −∞to t, one sums up the past values of x
with equal weight. In some applications, contributions from x(τ) to the integral may be
weighted differently (for example, the recent past may be more valuable than the remote
past). In such cases under the integral x(τ) is multiplied by a weighting function h(t, τ)
which depends on τ and t.
y(t) =
 t
−∞
x(τ)h(t, τ)dτ
In the above weighted integral, τ represents the input’s past time and t is the upper limit
of integration (i.e., the present time of the output). In many cases of interest in signals
and systems, the weighting factor h is a function of (t −τ). The RC and leaky integrators
of Figure 1.38(b) and (c) are two examples of weighted integration. The following are
some more examples.
Example
1.42
Weighted integration
Consider an integration operation on x(τ) from −∞< τ < t, where the contribution
to y(t) from x at time τ diminishes exponentially with its distance from the present
time t with a time constant of (1/α) sec. Find y(t) for x(τ) = cos(πτ), given that
the time constant of the weighting function is i) 0.5 sec, ii) 2 sec, and iii) ∞.
Solution
With a weighting function of h(t, τ) = e−α(t−τ) the integral becomes
y(t) =
 t
−∞
cos(πτ)e−α(t−τ)dτ = e−αt
 t
−∞
eατ cos(πτ)dτ
However,
 t
−∞
eατ cos(πτ)dτ =
eαt
α2 + π2 [α cos(πt) + π sin(πt)] ,
(α ≥0)
Therefore,
y(t) =
1
α2 + π2 [α cos(πt) + π sin(πt)] =
1
√
α2 + π2 sin(πt+θ), where tan θ = α
π
(i)
α = 2, y(t) = 0.26851 sin(πt + 32.5◦)
(ii)
α = 0.5, y(t) = 0.31435 sin(πt + 9◦)
(iii)
α = 0, y(t) = 0.31831 sin(πt)
The shorter the time constant of the weighting function, the more pronounced its
effect is. Implementation of the above integral is illustrated in Figure 1.40 for the
2-second time constant.
The time axis in Figure 1.40(a–c) represents τ. Figure 1.40(a) shows x(τ) = cos πτ.
Figure 1.40(b) shows h(t −τ) = e−(t−τ)
2
at t = 2, which is the weighting function for

Signals and Systems
69
(a) The function
x = cos(πτ)
−4
−3
−2
−1
0
1
2
3
4
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
(b) The weight factor
h(t −τ) = e−(t−τ)
2
, at t = 2
−4
−3
−2
−1
0
1
2
3
4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
(c) The integrand
x(τ)h(t −τ), at t = 2
−4
−3
−2
−1
0
Time (s)
1
2
3
4
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
(d) The integral
y(t) =
 t
−∞
cos(πτ)e−(t−τ)
2
dτ
= 0.31435 sin(πt + 9◦),
−∞< t < ∞
−4
−3
−2
−1
0
1
2
3
4
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
Time (s)
FIGURE 1.40 Integration of a 0.5-Hz cosine function multiplied by an exponential weighting factor with a 2-second
time constant. (The operation is identical with convolution of the two functions to be discussed in Chapter 4.)

70
CHAPTER 1
Introduction to Signals
evaluating the integral at t = 2. The product x(τ)h(t −τ) is shown in (c) for t = 2.
The net area under the curve is the value of the integral at t = 2. It is seen that the x(τ)s
of the past gradually contributes less to the value of the integral due to the attenuating
effect of multiplication by h. The decaying weighting function makes the memory of the
past gradually fade away. The result of the integral as a function of t is shown in (d).
Example
1.43
In Example 1.42 we observed the effect of the time constant of the exponential
weighting function on the integration outcome. Here we generalize that observation
and show that the effect is a function of the ratio of the time constant to the period of
the sinusoidal input. Let
y(t) =
 t
−∞
x(τ)h(t, τ)dτ
x(τ) = cos(2π f τ)
h(t, τ) = e−α(t−τ)
a.
Find y(t) and express it in terms of k = time constant of the weighting function
period of the sinusoial input
. Describe
the effect of k on the integration outcome.
b.
Obtain y(t) for f = 1Hz and the following time constants: (i) 0.05 sec, (ii) 0.25
sec, (iii) 0.5 sec, (iv) 1 sec, (v) 2 sec, and (vi) ∞.
Solution
a.
y(t) =
 t
−∞
x(τ)h(t, τ)dτ =
 t
−∞
cos(2π f τ)e−α(t−τ)dτ, α ≥0
= e−αt
 t
−∞
eατ cos(2π f τ)dτ
= e−αt

eατ
α2 + 4π2 f 2

α cos(2π f τ) + π sin(2π f τ)
t
−∞
=
1
α2 + 4π2 f 2

α cos(2π f t) + 2π f sin(2π f t)

=
1

α2 + 4π2 f 2 sin(2π f t + θ), where θ = tan−1
 α
2π f

.
In terms of the ratio k = (time constant of the weighting function)/
(period of the sinusoial input) = f/α:
y(t) =
1
2π f
k

k2 +
1
4π2
sin(2π f t + θ), where θ = tan−1
 1
2πk

The exponentially decaying weighting function attenuates the amplitude and
introduces a phase advance in the integration outcome, both of which depend
on k. A shorter k has a more pronounced effect on both the amplitude and phase
of the outcome. Here are some examples:

Signals and Systems
71
(i) Short time constant
2πk << 1,
y(t) ≈k
f sin(2π f t + 900)
= 1
α sin(2π f t + 900)
(ii) Medium time constant
2πk = 1,
y(t) =
1
2
√
2π f sin(2π f t + 450)
(iii) Long time constant
2πk >> 1,
y(t) ≈
1
2π f sin(2π f t)
b.
For f = 1 Hz the period of the sinusoid is 1 second and k = time constant. The
integration outputs for the various time constants are then
(i) time constant = 0.05
k = 0.05
y(t) = 0.04770 sin(2πt + 72.5◦)
(ii) time constant = 0.25
k = 0.25
y(t) = 0.13425 sin(2πt + 32.5◦)
(iii) time constant = 0.5
k = 0.5
y(t) = 0.15166 sin(2πt + 17.6◦)
(iv) time constant = 1
k = 1
y(t) = 0.15717 sin(2πt + 9◦)
(v) time constant = 2
k = 2
y(t) = 0.15865 sin(2πt + 4.5◦)
(vi) time constant = ∞
k = ∞
y(t) = 0.15915 sin(2πt)
The last line above is simply
y(t) =
 t
−∞
cos(2πτ)dτ = 1
2π sin(2πt) = 0.15915 sin(2πt)
1.21
Window Averaging
A special case of weighted integration is the ﬁnite duration integration, also called
window averaging, as it takes the average of data seen through a window of T seconds
length. We already have seen an example of window averaging in the plots of sunspot
numbers from 1700 to 2010, where annual averages shown in Figure 1.1(a) are obtained
from monthly and daily averages used in the plots of Figure 1.1(b) to (d). The averaging
reduces the daily variations and smooths the data. In the case of sunspot numbers, the
data is discrete and the windows are uniform, nonoverlapping, and 365 days long.
In another class of window averaging, the window slides along the time axis and
has overlap with its neighbor. For example, the ﬁnite integral
y(t) = 1
T
 t
t−T
x(τ)dτ
takes the average of x(t) seen through a uniform window of length T and assigns the
result as y(t). In the above integral, the variable t sweeps from −∞to ∞. The window,
therefore, moves along with t and y(t) is called the moving average. For a discrete-time
function the moving average under a uniform window of length N becomes
y(n) =
n

k=n−N
x(k)

72
CHAPTER 1
Introduction to Signals
Example
1.44
Moving averages
Moving averages are commonly used to reduce ﬂuctuations in data and to discern
trends. For this purpose, the effects of several features of a window need to be con-
sidered. The most important features are the window’s width and shape. Some other
factors such as magnitude scaling and the DC level in the original signal also affect the
windowing outcome. An example is given in Figure 1.41, which shows a deterministic
signal to which a random ﬂuctuation is added
x(t) = [a cos(πt) + b cos(2πt) + c tan−1(t + 6) + d tan−1(t −5)] + n(t)
−6
−4
−2
0
2
4
6
8
10
−1
−0.5
0
0.5
1
1.5
Signal amplitude
2
2.5
3
3.5
4
Time (s)
(a)
(b)
(c)
FIGURE 1.41 Moving averages are superimposed on the function. (a) The original function
x(t). (b) Averaged by an exponential window (time constant = 2). (c) Averaged by a uniform
window. Both windows are 4 seconds wide.
The component n(t) is a ﬁltered Gaussian random variable. The coefﬁcients a, b, c,
and d are constants. The signal is then window averaged by two different windows
that are both 4 seconds wide. One is a uniform window and the other is an exponential
one (with a 2-second time constant). In the latter case, recent signal values are con-
sidered more relevant and given more weight by the exponential weighting function.
Superimposed on the ﬁgures are trends extracted from the data by window averag-
ing. The rapid signal ﬂuctuations due to the sinusoidal and random components are
reduced. The slowly varying components have become prominent. The appropriate
choice of window parameters is required to extract desired trends in the signal.

Signals and Systems
73
1.22
Differentiation and Differences
The derivative of a function x(t) at a given point indicates the rate of change of the
dependent variable x with respect to the independent variable t. Mathematically it is
deﬁned as
dx
dt = lim
t→0
x
t
The derivative of x(t), when it exists, is the slope of its tangent line (tangent of the angle
of the line with the horizontal axis). The faster the function changes with time, the bigger
the derivative numerically.
Example
1.45
Derivative of a steplike function
An example of interest is the derivative of a function that grows linearly with time
from zero to one in T seconds. See Figure 1.42.
x(t) =



0,
t < 0
t
T ,
0 < t < T
1,
t > T
and
dx
dt =



0,
t < 0
1
T ,
0 < t < T
0,
t > T
The derivative of x(t) is a rectangular pulse (width = T , height =
1
T ). Three such
functions are shown in Figure 1.42(a) for T = 1, 2, and 3 seconds, with their deriva-
tives given in Figure 1.42(b). As T becomes smaller, x(t) approaches the unit step
and its derivative approaches the unit impulse. At the limit,
lim
t→0 x(t) = u(t) and lim
t→0
dx
dt = δ(t)
Example
1.46
The unique derivative property of exponential function
The derivative of the exponential function is an exponential function with the same
time constant but an amplitude change.
x(t) = eat,
dx
dt = aeat = ax(t), dx
dt −ax = 0
This unique property belongs to exponential functions only. The constant a may be a
real or complex number. Of special interest are the derivatives of complex exponential
and sinusoidal functions:
d
dt e jωt = jωe jωt,
d
dt sin ωt = ω cos ωt,
d
dt cos ωt = −ω sin ωt
Another example of is the two-sided exponential function
x(t) = e−|at|,
dx
dt = −ae−|at|sgn(t),
where sgn(t) =
1,
t > 0
−1,
t < 0 .

74
CHAPTER 1
Introduction to Signals
−4
−3
−2
−1
0
1
2
3
4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
(a)
(b)
Magnitude
−4
−3
−2
−1
0
1
2
3
4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
FIGURE 1.42 Three steplike time functions (a) and their derivatives (b).
The derivative is made of exponential functions scaled by ±a. At t = 0, the sign of the
derivative depends on the direction from which the function approaches the origin,
resulting in a biphasic character. As a becomes larger, the time constant becomes
smaller, x(t) becomes narrower, and its derivative becomes sharper. Accordingly, the
derivative operator ampliﬁes the high-frequency components of a signal compared to
its low frequencies. It functions as a high-pass ﬁlter.
Practical Differentiator Circuits
Three commonly used analog differentiator circuits are described in the next three
examples.
Example
1.47
Ideal differentiator
The op amp circuit of Figure 1.43(a) is a perfect differentiator. By an approach similar
to that of the ideal integrator, the input–output relationship in Figure 1.43(a) is found
to be v2 = −RC dv1
dt .

Signals and Systems
75
R
(a) Ideal differentiator
(b) CR differentiator
v1
R
–
+
v2
–
+
C
i
(c) Differentiator with high-frequency
      limiting capacity
v2
v1
R
C
+
–
v2
v1
R
C
+
–
FIGURE 1.43 Three differentiation circuits.
Example
1.48
Capacitor-resistor ( CR) differentiator
The CR circuit of Figure 1.43(b) (with v1 as the input and v2 as the output) approxi-
mates a differentiator. To analyze the operation of the circuit we note that the output
voltage v2 is proportional to the current through the circuit, while the current is pro-
portional to the derivative of the capacitor voltage. Consequently, v2 is proportional to
the derivative of the capacitor voltage which is v1 −v2. The input–output differential
equation of the circuit is obtained from
i = C d
dt (v1 −v2)
v2 = Ri = RC d
dt (v1 −v2).
dv2
dt + αv2 = dv1
dt , where α =
1
RC
For a complex exponential input v1 = e jωt we obtain v2 =
jω
α+ jωe jωt.
The above equation approximates the derivative operation only at low frequencies
where ω << α. At high frequencies, where ω >> α, the gain approaches unity. The
output of the circuit in response to the exponential input v1 = eωt is given below for
three ranges of frequencies:
Low frequencies,
ω << α and v2 ≈jω
α e jωt. It approximates a differetiator
with a gain of RC.
Mid-range frequencies,
ω = α and v2 = 0.707e j(ωt+π/4).
High frequencies,
ω >> α and v2 ≈e jωt. It approximates a unity-gain
transfer of the input to the output.
The above conclusions may also be derived by a direct examination of the circuit at
various frequencies: At low frequencies the capacitor represents a large impedance
compared to the resistor and receives the major share of input voltage, vC ≈v1.
The capacitor current and the output voltage become i = CdvC/dt ≈Cdv1/dt and
v2 = Ri ≈Cdv1/dt, respectively. By a similar argument, at high frequencies the
capacitor functions almost as a short-circuited element and nearly all of the input
voltage gets transferred to the output, v2 ≈v1.

76
CHAPTER 1
Introduction to Signals
Example
1.49
Differentiator with high-frequency limiting
The relationship between v2 and v1 in the op amp circuit of Figure 1.43(c) is found
by applying circuit laws and assuming an ideal op amp:
dv2
dt + αv2 = −dv1
dt , where α =
1
RC
Except for a sign inversion, it is similar to that of the CR circuit of Figure 1.46(b).
However, unlike the passive CR circuit of Figure 1.43(b), the performance of the
active circuit of Figure 1.43(c) is not affected by loading.
1.23
Concluding Remarks
The goal of this chapter has been to familiarize the student with some signal notations
that are used later in the book. Actual signals convey information, are often complex,
and are analyzed probabilistically. Examples of such signals were given at the start of
this chapter. However, in this book we employ deterministic functions that, despite their
simplicity, provide convenient and useful means for the analysis of signals and systems.
The utility of these functions is primarily due to our interest in systems being modeled
as linear time-invariant (LTI). For example, a great deal can be derived from knowledge
of the step response of a system that lends itself to an LTI model. After describing
mathematical functions of interest (such as step, impulse, exponential, sinusoids, sinc,
pulses, and windows), the chapter introduced several basic operations on signals such as
time transformation, integration, and differentiation.
1.24
Problems
Solved Problems
Note. To get started on Matlab or to ﬁnd out about Matlab commands use the Help button on the menu bar of its
command window.
1. Plotting a function. Digital computer software packages sample continuous-time functions and represent the
samples as vectors or matrixes. This problem illustrates the use of basic commands for sampling and plotting
functions.
a. Basic plot. The Matlab program given below generates two vectors: one is t (the sequence of time samples) and
the other is y [the sequence of the function y(t) = sin(2πt) evaluated at those time samples]. The program then
plots y vs. t (with time as the abscissa and y as the ordinate).
% CH1«PR1«a.m
t=0:0.05:1;
y=sin(2*pi*t);
plot(t,y)
The ﬁrst line in the above list is a comment; for example, the ﬁle name. Comment lines start with the symbol
%, which tells the computer to ignore that line. The second line in the above list generates a vector representing
time. It determines sampling instances. Starting from t = 0 and ending at t = 1 second, with samples taken

Signals and Systems
77
every 0.05 second, it produces a total of 21 points. The third line evaluates the sinusoid at the sampling instances
and creates the vector y containing 21 samples. The last line plots the vector y versus the vector t. The plot
appears as a continuous-time function. Run the above program under Matlab and observe the outcome.
b. Using stem, stairs, and ﬁgure commands. The following commands create plots as stem or stairs.
stem(y);
% plot y as stem.
stairs(t,y);
% plot y as stairs.
The command ﬁgure creates a window for each plot. Explore the effect of including the command ﬁgure by
running the program given below, ﬁrst with and then without the command ﬁgure, and then with and without
the numbers associated with each ﬁgure.
t=0:0.05:1;
y=sin(2*pi*t);
figure(1); plot(t,y);
figure(2); stem(t,y);
figure(3); stairs(t,y);
c. Subplot, customizing and saving plots. The command
subplot(a,b,c);
places the current plot in an a × b matrix at a location determined by c.
Customizing a plot. The plot may be customized by the following commands:
axis([ƒ])
% Specifies range of axes.
xlabel('ƒ')
% Places a label on the abscissa.
ylabel('ƒ')
% Places a label on the ordinate.
title('ƒ')
% Gives the plot a title.
grid
% Puts a grid on the plot.
In addition, the color of the plot, its line width, and the shape may be speciﬁed.
The following commands save the current plot as a postscript ﬁle in the working directory.
print -dps filename.ps
print -dpsc filename.eps
A plot may also be saved as an *.m ﬁle using the menu bar of the plot window. The above features are illustrated
by the program below.
t=0:0.05:2;
y=sin(2*pi*t);
subplot(3,1,1)
plot(t,y,'r','LineWidth',2 ) % Plots in red color with a line-width=2.
axis([0 2 -1.5 1.5]);
% The range of abscissa is from 0 to 2
% that of ordinate is from -1.5 to 1.5.
grid
title('Subplot, stem, stairs, customize and save.');
xlabel('time (s)'); ylabel('volts');
subplot(3,1,2)
stem(t,y,'b');
% plots in blue color
axis([0 2 -1.5 1.5]);
grid
xlabel('time (s)'); ylabel('volts')
subplot(3,1,3)
stairs(t,y,'m');
% plots in magenta color
axis([0 2 -1.5 1.5]);
grid
xlabel('time (s)'); ylabel('volts')
print -dps CH1«PR1«c.ps

78
CHAPTER 1
Introduction to Signals
d. Multiple plots on the same graph. A single command may plot more than one pair of vectors in one window.
The following program plots in a single window three instantaneous voltages of a 3-phase 120-V, 60-Hz system:
v1(t) = 170 sin(2π f t), v2(t) = 170 sin(2π f t −120◦), v3(t) = 170 sin(2π f t −240◦)
The plots are then saved as a postscript ﬁle.
f=60;
% Sets the frequency at 60 Hz.
t=0:.0001:.05;
% Time vector, t=0 to t=0.05 every 0.0001 second.
v1=170*sin(2*pi*f*t);
% Generates the vector of voltage values, v1.
v2=170*sin(2*pi*f*t-2*pi/3);
% Generates the vector of voltage values, v2.
v3=170*sin(2*pi*f*t-4*pi/3);
% Generates the vector of voltage values, v2.
plot(t,v1,'r',t,v2,'b',t,v3,'m') % Plots v1, v2, and v3 versus t (in red, blue, and magenta).
xlabel('time (s)'); ylabel('volts');
title('Phase voltages in a 3-phase 120 V 60-Hz system.');
grid
% Places a grid on the plot.
print -dps CH1«PR1«d.ps
% Saves the plot under the name CH1«PR1«d.ps
Alternatively, one may apply the command hold on which holds the current window for adding more plots. For
example, in the above program replace the single plot command by the following set of commands which holds
the plot to includes three separate commands with individually controlled line widths and colors.
plot(t,v1,'r','LineWidth',2)
% Plots v1 versus t in red color with 2-units thickness.
hold on
% Holds the current graph for more plots
plot(t,v2,'b','LineWidth',2)
% Plots v2 versus t in blue color with 2-units thickness.
plot(t,v3,'m','LineWidth',2)
% Plots v3 versus t in magneta color with 2-units thickness.
hold off
2. Impulse and step functions. Consider a ﬁnite-duration pulse xa(t) made of a single cycle of a sinusoid:
xa(t) =
 a2
2π sin(at),
0 < t < 2π
a
0,
elsewhere
a. Sketch xa(t) for a = 2nπ, n = 1, 3, 5. Find the area under each half cycle of x(t).
b. Let ya(t) =  t
−∞xa(t)dt. Find ya(t) and sketch it for a = 2nπ, n = 1, 3, 5. Show that ya(t) is a ﬁnite-duration
positive pulse. Find its duration, maximum value, and area.
c. Let za(t) =  t
−∞ya(t)dt. Find za(t) and sketch it for a = 2nπ, n = 1, 3, 5. Find its DC steady-state value and
the transition time to reach the steady-state value.
d. Argue that
(i)
lima→∞ya(t) = δ(t)
(ii)
lima→∞za(t) = u(t)
Solution
a.
xa(t) =

a2
2π sin(at),
0 < t < 2π
a
0,
elsewhere.
For a = 2πn we have xa(t) =

2πn2 sin(2πnt),
0 < t < 1/n
0,
elsewhere
See Figure 1.44(a). The area under a half cycle of xa(t) is  1/(2n)
−∞
2πn2 sin(2πnt)dt = 2n.
b. ya(t) =

t
−∞
xa(t)dt =

t
−∞
2πn2 sin(2πnt) [u(t) −u(t −1/n)] dt =

n [1 −cos(2πnt)] ,
0 < t < 1/n
0,
elsewhere.
ya(t) is a positive ﬁnite-duration pulse. Its duration is 1/n. Its maximum value is 2n which occurs at t = 1/(2n).
See Figure 1.44(b). The area under the pulse is

1/n
0
ya(t)dt =

1/n
0
n [1 −cos(2πnt)] dt = 1

Signals and Systems
79
c.
za(t) =

t
−∞
ya(t)dt =

t
−∞
n[1 −cos(2πnt)] [u(t) −u(t −1/n)] =



0,
t < 0
n(t −sin(2πnt)
2πn
),
0 < t < 1/n
1,
t > 1/n
The DC steady-state value is 1. The transition time from zero to 1 is 1/n. See Figure 1.26(c).
d. As a = 2πn →∞, the pulse ya(t) becomes narrower and taller, but its area remains equal to 1. Similarly,
za(t) reaches the DC steady state in a shorter time. At the limit, therefore,
(i)
lima→∞ya(t) = δ(t)
(ii)
lima→∞za(t) = u(t)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−200
−150
−100
−50
0
50
100
150
200
Plots of x(t) versus time for n = 1, 3, 5
n = 1
n = 3
n = 5
Amplitude of xa(t)
Time (s)
(a)
Plots of y(t) versus time for n = 1, 3, 5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
1
2
3
4
5
6
7
8
9
10
n = 1
n = 3
n = 5
Amplitude of ya(t) 
Time (s)
(b)
FIGURE 1.44

80
CHAPTER 1
Introduction to Signals
Plots of z(t) versus time for n = 1, 3, 5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
n = 1
n = 3
n = 5
Amplitude of za(t) 
Time (s)
(c)
FIGURE 1.44 (Continued)
3.
a. A pair of input–output waveforms for a physical system with an attenuating property is shown in Figure 1.45(a).
Model the waveforms by sinusoids. Designate the input by x(t) = A1 sin(2π f t + θ1) + B1 and the output by
y(t) = A2 sin(2π f t + θ2) + B2, where Ai > 0 and −π < θi < π, i = 1, 2. Find the period T , frequency
f , A1, θ1, A2, and θ2. Determine the system’s attenuation 20 log(A1/A2) (in decibel) and its phase shift in
degrees. Find the phase lag and the minimum time delay of the output with reference to the input. Express y(t)
in terms of x(t).
b. Repeat for Figure 1.45(b).
Solution
Modeling a plot by a sinusoid.
a. Both traces in Figure 1.45(a) have a 0 DC value resulting in B1 = B2 = 0. For each trace the period is given
by twice the time between its consecutive zero crossings or by twice the time between consecutive peaks. For
both traces the period is measured to be T = 0.4 sec, corresponding to a frequency of f = 1/T = 2.5 Hz.
The trace with a peak-to-peak value of 6 V is the input x(t) with an amplitude A1 = 3. Its phase θ1 may be
determined from two perspectives: From one point of view, x(t) is a sinusoid that has been shifted to the left
by T/8, corresponding to θ = 2π/8 = π/4. From another point of view, the sinusoid has been shifted to
the right 7T/8, corresponding to θ = −7π/4. The second point of view results in a phase outside the range
speciﬁed by the problem and doesn’t constitute an answer in the present setting. The input can be written as
x(t) = 3 sin(5πt + π/4).
Similarly, the mathematical expression for the output trace in Figure 1.45(a) is found to be y(t) = 2 sin(5πt−
π/2). The system’s attenuation is 20 log(3/2) = 3.52 dB. Because the system is causal, the output lags the
input by θ = θ1 −θ2 = π/4 + π/2 = 3π/4. At the frequency of f = 2.5 Hz the phase lag of θ corresponds
to a minimum time delay of t0 = θ/(2π f ) = (3π/4)/(5π) = 0.15 sec. (The minimum time delay indicated
directly from the plots is three divisions of 0.05 sec each, also yielding t0 = 3×0.5 = 0.15 sec). The particular
output shown in Figure 1.45 (a) may be expressed in terms of the input by y(t) = 2
3 x(t −t0). (This will not
necessarily be valid at other frequencies or for other input–output pairs.)
b. By a parallel analysis done on Figure 1.45(b) we obtain: period T = 0.5 sec, frequency f = 2 Hz, x(t) =
5 sin(4πt + 0.2π), y(t) = 3 sin(4πt −0.4π), attenuation= 20 log(5/3) = 4.44 dB, phase lag θ = 0.6π, and

Signals and Systems
81
−0.25−0.2 −0.15 −0.1 −0.05
Two sinosoids
Two sinosoids
0
0.05 0.1 0.15 0.2 0.25
−3
−2
−1
0
1
2
3
Time (s)
(a)
(b)
Amplitude
−0.5 −0.4 −0.3 −0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
−5
−4
−3
−2
−1
0
1
2
3
4
5
Time (s)
Amplitude
FIGURE 1.45 Modeling an input–output pair of systems in the form of sinusoidal functions.
a minimum time delay t0 = θ/(2π f ) = 0.6π/(4π) = 0.15 sec.
Note. The knowledge of the phase lag of the sinusoidal output with respect to the input is not enough to specify
the time delay between them unambiguously. The actual time delay may be any value given by
θ
2π f + kT, k =
0, 1, . . ., k being a nonnegative integer. For an unambiguous determination of time delay one needs additional
information.
4. Modeling a plot by an exponential.
a. A voltage signal that decays to a zero steady-state level is ploted in Figure 1.46. Model it by a single exponential
function. Obtain the time constant of the exponential from the fact that during an interval that lasts τ seconds the
signal is reduced by a factor of e−1 = 0.368. Alternatively, obtain the time constant from two measurements of
the signal, v1 and v2, taken at two instances t1 and t2, T seconds apart, and compare the time constants obtained
by the two approaches. When using the alternative approach, what are the preferred measurement instances t1
and t2 for better accuracy?
b. How does one ﬁnd the time constant if the signal decays toward a known nonzero ﬁnal value? If the ﬁnal value
is not known, what additional information is needed to determine the complete mathematical expression for the
signal? Show whether or not in that situation a third measurement of the signal amplitude at t3 may be enough
and, if so, how.
Solution
a. The general form of a decaying exponential function with a single time constant is A + Be−t/τ, where A + B is
the initial value at t = 0, A is the ﬁnal value at t = ∞, and τ is the time constant. From Figure 1.46, the initial
value is 2 and the ﬁnal value is 0. This gives us A = 0, B = 2, and v(t) = 2e−t
τ u(t). The time constant is the
amount of time it takes x(t) to decay by a factor of e−1 = 0.368; for example, down from 2 at t = 0 to 0.736
at t = τ. From the plot we observe x(0.5) ≈0.74 which suggests τ = 0.5 sec.
The time constant may also be obtained from two measurements of magnitudes v1 and v2 made T seconds
apart. The equation for computing τ from v1 and v2, and the time interval T between them, is (see Example 1.10)
τ =
T
ln v1
v2

Measurements of the amplitudes v1 and v2 are more accurate during the steep segment of the function, while
determinations of t1 and t2 are more accurate during the less steep segment. With those considerations in mind,

82
CHAPTER 1
Introduction to Signals
−0.5
0
0.5
Causal exponential
1
1.5
2
0
0.5
1
1.5
2
Time (s)
Amplitude
Q
FIGURE 1.46 Determining the time constant of an exponential function.
we choose the following set of measurements from the plot in Figure 1.46: v1 = 2 at t1 = 0, v2 = 0.75 at
t2 = 0.5, and T = t2 −t1 = 0.5.
The time constant of the exponential is computed to be
τ =
T
ln x1
x2
 =
0.5
ln 
2
0.75
 = 0.51 s
b. If the ﬁnal value A of the exponential is not zero, then v1 and v2 used in the above equation would be replaced
by v1 −A and v2 −A; in other words, the deviations of the value of the function from the ﬁnal value at the two
measurement instances. If the ﬁnal value A is not known, a third measurement at t3 would add a third equation
to the set from which the three unknowns A, B, and τ, may be obtained.
5. A plot made of the sum of two exponentials. The function v(t) plotted in Figure 1.47 is known to be the sum of
two exponentials. Specify its parameters. The early part of the function is shown by the fast trace in (b). Assume
the ﬁnal value is zero.
Solution
We observe that v(0) = v(∞) = 0. Therefore, we start with a sum of two exponential functions having time
constants τ1 and τ2, with equal but opposing initial values ±B at t = 0, and zero ﬁnal values at t = ∞.
v(t) = B

e
−t
τ1 −e
−t
τ2

The exponential with time constant τ1 contributes positive values to the function and the exponential with time
constant τ2 provides negative values.
Both exponential components decay from their respective initial values of ±B toward a zero ﬁnal value. The
three parameters τ1, τ2, and B may be calculated from three measurements of the function at three instances of time

Signals and Systems
83
−0.5
0
0.5
1
1.5
Sum of two exponentials
Early part of the sum of two exponentials
2
2.5
3
3.5
4
4.5
5
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Time (s)
(a)
(b)
Amplitude
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Amplitude
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Time (s)
FIGURE 1.47 (a) A plot of the sum of two exponentials. (b) Fast trace of the early part of the plot.
t1, t2, and t3. The measurements provide the following three independent equations:
v1 = B

e
−t1
τ1 −e
−t1
τ2

v2 = B

e
−t2
τ1 −e
−t2
τ2

v3 = B

e
−t3
τ1 −e
−t3
τ2

The equations can be solved for B, τ1, and τ2 using computational and numerical methods. To obtain a solution of
the above equations we choose t2 = 2t1 and t3 = 3t1. Then,
v1 = B(x1 −x2)
v2 = B
x2
1 −x2
2

= B(x1 −x2)(x1 + x2)
v3 = B
x3
1 −x3
2

= B(x1 −x2)
x2
1 + x1x2 + x2
2

where x1 = e
−t1
τ1 and x2 = e
−t1
τ2 . We then ﬁnd
(x1 + x2) = v2/v1

x2
1 + x1x2 + x2
2

= v3/v1
The solution is
x2 −v2
v1
x +
v2
v1
2
−v2
v1
= 0
x1,2 = v2
2v1

1 ±

4v1v3
v2
2
−3

,
τ1 = −t1
ln x1
,
and
τ2 = −t1
ln x2

84
CHAPTER 1
Introduction to Signals
(i) From the plots of Figure 1.47 the following three measurements and the resulting parameters were obtained:
t1 = 0.5
t2 = 1
t3 = 1.5
v1 = 4.15
v2 = 3.35
v3 = 2.15
⇒
x1 = 0.575
x2 = 0.232
τ1 = 0.905
τ2 = 0.342
B = 12
(ii) For better accuracy, the plots were enlarged and the following three measurements with the resulting parameters
were obtained:
t1 = 0.5
t2 = 1
t3 = 1.5
v1 = 4.166
v2 = 3.324
v3 = 2.166
⇒
x1 = 0.605
x2 = 0.193
τ1 = 0.995
τ2 = 0.304 B = 10.112
(iii) To compare the above results with the actual parameters used by the computer to plot v(t), the sample values
at t1, t2, and t3 were picked from the computer plots, resulting in the following:
t1 = 0.5
t2 = 1
t3 = 1.5
v1 = 4.176
v2 = 3.322
v3 = 2.164
⇒
x1 = 0.60652 x2 = 0.18898
τ1 = 1
τ2 = 0.3
B = 10
6. Model the plot of Figure 1.47 as a sum of two exponentials. The function that generated the plot may or not have
been the sum of two exponentials.
Solution
As in problem 5, we observe that v(0) = v(∞) = 0. The desired model should have the following form:
v(t) = v+(t) −v−(t),
where v+(t) = Be
−t
τ1 and v−(t) = Be
−t
τ1
The model has three parameters τ1, τ2, and B, which may be found from three measurements as done in problem 5.
However, because the plot may not represent the sum of two exponentials, the resulting model parameters may
depend on measurement times t1, t2, and t3, possibly making the model inaccurate. The method described below
can provide an approximate solution.
The early part of the plot changes noticeably faster than the later part, suggesting a shorter time constant for
v−(t). During the later part of the plot, v−(t) has noticeably diminished and the plot is dominated mainly by v+(t)
whose time constant τ1 and initial value B may be estimated ﬁrst. Two measurements v1 and v2, taken at t1 and t2,
during the later part of the function yield
v1 = B

e
−t1
τ1 −e
−t1
τ2

≈Be
−t1
τ1
v2 = B

e
−t2
τ1 −e
−t2
τ2

≈Be
−t2
τ1
τ1 ≈t2 −t1
Ln v1
v2
 and B ≈v2e

t2
τ1


Signals and Systems
85
Note that in addition to the time constant τ1, the above two measurements will also provide us with an estimate of
B. The above approach is applied to the later part of the plot of Figure 1.47(a) with the following results:
t1 = 2,
v1 = 1.353
t2 = 4,
v2 = 0.206
τ1 = t2 −t1
ln

v1
v2
 =
2
ln 1.353
0.206
 = 1.06258
B ≈v2e
t2
τ1 = 0.206e
4
1.062 = 9.5
To ﬁnd τ2 we obtain a third measurement v3 = 1.833 at t3 = 0.1 (during the early part of the plot in Figure 1.47(b)
which yields the following:
v3 = B
e
−t3
τ1 −e
−t3
τ2 
1.833 = 9.5
e−
0.1
1.0625 −e
−0.1
τ2 
e
−0.1
τ2 = 0.7215, τ2 = 0.306
7. Modeling a plot by a decaying sinusoid. Model the function plotted in Figure 1.48 by an exponentially decaying
sinusoid:
x(t) = A + Be−t/τ sin(2π f t + θ)
Determine A, B, τ, f, and θ.
Solution
We begin with A, τ, and f which are easier to determine. From Figure 1.48(a), the ﬁnal steady-state value is seen
to be A = 1, and the time constant of the decay is computed to be τ = 0.4 sec. (Use the value of the ﬁrst two
peaks of the function with a time separation of 0.3 sec to compute τ as done in problem 4.) The frequency f is
the inverse of the period. The period T is twice the time between two adjacent crossings of x(t) at x(t) = 1. From
Figure 1.48(b) we obtain T/2 = 0.15 sec and f = 1/(2 × 0.15) = 10/3 Hz.
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
0
0.5
1
1.5
2
2.5
Time (s)
(a)
(b)
Amplitude
−0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0
0.5
1
1.5
2
2.5
Time (s)
Amplitude
FIGURE 1.48 (a) Plot of a function to be modeled by an exponentially decaying sinusoid. (b) Fast trace of the early
part of the function.

86
CHAPTER 1
Introduction to Signals
The phase angle θ is found by observing that the ﬁrst crossing of the function at x(t) = 1 occurs at t = 0.025.
The resulting equation is sin(2π f × 0.025 + θ) = 0 or θ = −30◦. Finally, the parameter B is found from
x(t)|t=0 = 1 + B sin(θ) = 0 or B = 2. In summary, the model for the plot of Figure 1.48 is
x(t) =

1 + 2e−2.5t sin

20πt
3
−π
6

u(t)
=

1 + 2e−2.5t sin

20π
3

t −1
40

u(t)
= 
1 + 2e−2.5t sin ω(t −τ)
u(t),
ω = 20π
3 , τ = 25 msec
8. Time averages and time transformations. Consider the single sawtooth pulse function
x(t) =
 0,
t < 0
t,
0 < t < 1
0,
t > 1
a. Find a mathematical expression for x(−t).
b. Find a mathematical expression for x(−t −1).
c. Find the average of x(t) and its rms value during t = 0 to t = 1.
d. Consider periodic functions y1(t), y2(t), and y3(t) with period T = 2, where for one period
y1(t) = x(t) + x(−t),
−1 < t < 1
y2(t) = x(t) −x(−t),
−1 < t < 1
y3(t) = x(t) + x(t −1),
0 < t < 2
Find their average and rms values.
Solution
a. In the expression for x(t) replace t by −t
x(−t) =
 0,
−t < 0
−t,
0 < −t < 1
0,
−t > 1
To clean up the above expressions, trade the inequality signs with minus signs and order the segments in form
of increasing t:
x(−t) =
 0,
t < −1
−t,
−1 < t < 0
0,
t > 0
Alternatively, one may start with x(t) = t[u(t) −u(t −1)] and change t to −t to obtain x(−t) = t[u(−t −
1) −u(−t)]. In either approach the plot of x(t) ﬂips around the origin.
b. In the expression for x(t) replace t by −t −1 to ﬁnd
x(−t −1) =
 0,
−t −1 < 0
−t −1,
0 < −t −1 < 1
0,
−t −1 > 1
=
 0,
t < −2
−t −1,
−2 < t < −1
0,
t > −1
Alternatively, one may start with x(t) = t[u(t) −u(t −1)] and change t to −t −1 resulting in x(−t −1) =
(t + 1)[u(−t −2) −u(−t −1)]. In either approach the plot of x(t) ﬂips around the origin and then shifts to the
right by one unit.

Signals and Systems
87
c. Average of x(t) during t = 0 to t = 1 is
1
T

T
0
x(t)dt =

1
0
tdt = 1
2.
The rms value of x(t) during t = 0 to t = 1 is

1
T

T
0
x2(t)dt =

1
0
t2dt =
√
3
3 .
d. See Figure 1.49. The average and rms values for y1(t), y2(t), and y3(t) are obtained from those for x(t).
Function
Average
RMS
y1(t)
1/2
√
3/3
y2(t)
0
√
3/3
y3(t)
1/2
√
3/3
y1(t)
1
–1
–1
–1
1
0
1
1
t
y2(t)
1
1
–1
t
y3(t)
t
0
0
FIGURE 1.49
9. Time shift, time reversal, and their interchange. Given u(t) =

1,
t ≥0
0,
t < 0
a. Express u(−t −3) in terms of t, plot it, and show how it may be constructed by a delay followed by a time
reversal or, equivalently, by a time reversal followed by an advance.
b. Express u(−t + 3) in terms of t, plot it, and show how it may be constructed by a time reversal followed by a
delay or, equivalently, by an advance followed by a time reversal.
c. Conclude that a delay followed by a time reversal is equivalent to a time reversal followed by an advance.
Similarly, a time reversal followed by a delay is equivalent to an advance followed by a time reversal.
Solution
a. See a1 and a2 in Figure 1.50(a).
b. See b1 and b2 in Figure 1.50(b).
The results shown in Figure 1.50 may be veriﬁed by (i) applying the deﬁnition of the unit-step function or by
(ii) graphical effects of time shift and reversal. Note that changing the order of time shift and time reversal would
lead to the same result only if at the same time delay and advance are also interchanged. As an example, u(−t −3)
may be obtained by a delay/reversal sequence; ﬁrst introduce a 3-unit delay in u(t) (by changing t to t −3) to
produce u(t −3), then reverse u(t −3) (by changing t to −t) to obtain u(−t −3). Conversely, u(−t −3) may
be obtained by a reverse/advance sequence; ﬁrst reverse u(t) to obtain u(−t), then introduce a 3-unit advance in
u(−t) (by changing t to t + 3) to produce u[−(t + 3)] = u(−t −3).

88
CHAPTER 1
Introduction to Signals
(a1) Delay
u(t −3) =

1,
t ≥3
0,
t < 3
and
Reversal
u(−t −3) =

1,
t ≤−3
0,
t > 3
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
Plot of u(2t − 6)
Plot of u(−t − 3)
(a2) Reversal
u(−t) =

1,
t ≤0
0,
0, t > 0
and
Advance
u[−(t + 3)] = u(−t −3) =

1,
t ≤−3
0,
t > −3
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
Plot of u(−t)
Plot of  u(−t − 3)
FIGURE 1.50 (a) Two ways to transform u(t) to u(−t −3).

Signals and Systems
89
(b1) Reversal
u(−t) =

1,
t ≤0
0,
t > 0
and
Delay
u[−(t −3)] = u(−t + 3) =

1,
t ≤3
0,
t > 3
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
Plot of u(−t)
Plot of u(−t + 3)
(b2) Advance
u(t + 3) =

1,
t ≥−3
0,
t < −3
and
Reversal
u(−t + 3) =

1,
t ≤3
0,
t > 3
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
Plot of u(t + 3)
Plot of u(−t + 3)
FIGURE 1.50 (b) Two ways to transform u(t) to u(−t + 3).

90
CHAPTER 1
Introduction to Signals
10. The unit-step function is expressed as a function of time by u(t) =

1,
t ≥0
0,
t < 0 . In a similar way, express the
following as functions of time and plot them:
a. 0.5u(t), 2u(t)
b. u(0.5t), u(2t)
c. u(t + 1), u(t −2)
d. u(−t), u(−t + 1)
e. u(2t + 1), u(−3t + 2)
f. u(t)u(2 −t), u(t)u(2 + t)
Solution
a. 0.5u(t) =

0.5,
t ≥0
0,
t < 0
2u(t) =

2,
t ≥0
0,
t < 0
b. u(0.5t) =

1,
t ≥0
0,
t < 0
u(2t) =

1,
t ≥0
0,
t < 0
c. u(t + 1) =

1,
t ≥−1
0,
t < −1
u(t −2) =

1,
t ≥2
0,
t < 2
d. u(−t) =

1,
t ≤0
0,
t > 0
u(−t + 1) =

1,
t ≤1
0,
t > 1
e. u(2t + 1) =

1,
t ≥−0.5
0,
elsewhere
u(−3t + 2) =

1,
t ≤2
3
0,
elsewhere
f. u(t)u(2 −t) =

1,
0 ≤t ≤2
0,
elsewhere
u(t)u(2 + t) =

1,
t ≥0
0,
elsewhere
11. A unit pulse is deﬁned by d(t) =

1,
0 < t < 1
0,
elsewhere . In a similar way, express the following as functions of time
and plot them:
a. d(0.5t)
b. d(2t)
c. d(t + 1)
d. d(−t + 1)
e. d(2t + 1)
f. d(t)d(2 −t)
Solution
See below.
a. d(0.5t) =

1,
0 < 0.5t < 1
0,
elsewhere
=

1,
0 < t < 2
0,
elsewhere
b. d(2t) =

1,
0 < 2t < 1
0,
elsewhere
=

1,
0 < t < 0.5
0,
elsewhere
c. d(t + 1) =

1,
0 < (t + 1) < 1
0,
elsewhere
=

1,
−1 < t < 0
0,
elsewhere
d. d(−t + 1) =

1,
0 < (−t + 1) < 1
0,
elsewhere
=

1,
0 < t < 1
0,
elsewhere

Signals and Systems
91
e. d(2t + 1) =

1,
0 < (2t + 1) < 1
0,
elsewhere
=

1,
−0.5 < t < 0
0,
elsewhere
f. d(t)d(2 −t) =

1,
0 < t < 1 and 0 < (2 −t) < 1
0,
elsewhere
=

1,
0 < t < 1 and 1 < t < 2
0,
elsewhere
= 0 (all t)
A Matlab program for creating some of the above functions is given below.
t=[-2.5:.01:2.5]; T=length(t)
% Create d(t)=u(t)-u(t-1);
a=1; b=0;
for i=1:T
if a*t(i)+b ø0;
if a*t(i)+b °1;
x1(i)=1;
else
x1(i)=0;
end
end
end
%Create d(t+1);
a=1; b=1;
for i=1:T
if a*t(i)+b ø0;
if a*t(i)+b °1;
x4(i)=1;
else
x4(i)=0;
end
end
end
%Create
d(-t+1);
a=-1; b=1;
for i=1:T
if a*t(i)+b °1;
if a*t(i)+b ø0;
x5(i)=1;
else
x5(i)=0;
end
end
end
%Create
d(2t+1);
a=2; b=1;
for i=1:T
if a*t(i)+b ø0;
if a*t(i)+b °1;
x6(i)=1;
else

92
CHAPTER 1
Introduction to Signals
x6(i)=0;
end
end
end
%Create d(2-t) and d(t)d(2-t);
a=-1; b=2;
for i=1:T
if a*t(i)+b °1;
if a*t(i)+b ø0;
x7(i)=1;
else
x7(i)=0;
end
end
end; x1x7=x1.*x7;
12. Shifts and reversals of a right-sided function. Given x(t) = 2−tu(t) =

2−t,
t ≥0
0,
t < 0 , express the following as
functions of t:
a. x(t −3)
b. x(t + 4)
c. x(−t)
d. x(−t −3)
e. x(−t −4)
Solution
a. Shifting x(t) to the right by 3 units produces
x(t −3) = 2−(t−3)u(t −3) =

8 × 2−t,
t ≥3
0,
t < 3
b. Shifting x(t) to the left by 4 units produces
x(t + 4) = 2−(t+4)u(t + 4) =
 2−t
16 ,
t ≥−4
0,
t < −4
c. Reversal of x(t) around the point t = 0 produces
x(−t) = 2tu(−t) =

2t,
t ≤0
0,
t > 0
d. Reversal of x(t −3) around the point t = 0 produces
x(−t −3) = 2(t+3)u(−t −3) =

8 × 2t,
t ≤−3
0,
t > −3
e. Reversal of x(t + 4) around the point t = 0 produces
x(−t + 4) = 2(t−4)u(−t + 4) =
 1
162t,
t ≤4
0,
t > 4
13. A one-sided function is given by x(t) =

2−t,
t ≥0
0,
t < 0 . In a similar way, express the following as functions of
time:
a. x(0.5t)
b. x(2t)
c. x(t + 1)
d. x(t −2)
e. x(2t + 1)
f. x(t)x(2 −t)

Signals and Systems
93
Solution
See below.
a. x(0.5t) =

2−0.5t,
t ≥0
0,
t < 0
b. x(2t) =

2−2t,
t ≥0
0,
t < 0
c. x(t + 1) =

2−(t+1),
(t + 1) ≥0
0,
elsewhere
=

0.5 × 2−t,
t ≥−1
0,
elsewhere
d. x(t −2) =

2−(t−2),
(t −2) ≥0
0,
elsewhere
=

4 × 2−t,
t ≥2
0,
elsewhere
e. x(2t + 1) =

2−(2t+1),
(2t + 1) ≥0
0,
elsewhere
=

0.5 × 2−2t,
t ≥−0.5
0,
elsewhere
f. x(2 −t) =

2−(2−t),
(2 −t) ≥0
0,
elsewhere
=

0.25 × 2t,
t ≤2
0,
elsewhere
g. x(t)x(2 −t) =

2−t × 0.25 × 2t,
t ≥0 and t ≤2
0,
elsewhere
=

0.25,
0 ≤t ≤2
0,
elsewhere
14. Time transformations. Let x(t) = e−t [u(t) −u(t −1)].
a. Express y(t) = x(−t −1) in terms of exponential and step functions.
b. Describe the sequence of time transformations which generates y(t) from x(t).
c. Write computer code to plot x(t) and y(t) for −2.5 < t < 2.5 and save the plots as postscript graphs.
d. Verify the sequence of time transformations described in part (b) by examining the plots obtained in part (c).
Solution
a. In the expression given for x(t) replace t by −t −1 to ﬁnd
y(t) = x(−t −1) = e−(−t−1) [u(−t −1) −u(−t −1 −1)] = e(t+1) [u(−t −1) −u(−t −2)]
b. A time reversal changes x(t) to x(−t). Shifting the new function to the left by one unit changes t to t + 1,
thus producing x[−(t + 1)] = x(−t −1). The sequence of operations is time reversal followed by a left-shift.
Alternatively, one could start with a right shift, changing x(t) to x(t −1), then perform a time reversal that
changes t to −t, thus producing x(−t −1). The sequence of operations is then right-shift followed by a time
reversal.
c. TheMatlabcodeandresultingplotsareshownbelow.Notethatthecodedetermines y(t)bydirectlyimplementing
the expression given in part (a).
t=linspace(-2.5, 2.5, 500);
x=zeros(1,500 );
y=zeros(1,500 );
for i=250:350;
x(i)=exp(-t(i));
end
for i=50:150;
y(i)=exp(t(i)+1);
end
x(t) and y(t) generated by the above Matlab code are plotted in Figure 1.51(a) and (b), respectively.

94
CHAPTER 1
Introduction to Signals
d. Flip the plot in Figure 1.51(a) around the origin and shift it to the left by one unit and you will get the plot in (b).
−2.5 −2
−1.5
−1 −0.5
0
x(t) = e–t, 0 < t < 1
x(–t – 1) = et+1, –2 < t < –1
0.5
1
1.5
2
2.5
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
(a)
(b)
Magnitude
−2.5
−2
−1.5 −1 −0.5
0
0.5
1
1.5
2
2.5
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (s)
Magnitude
FIGURE 1.51 (a) A ﬁnite-duration exponential pulse x(t) = e−t[u(t) −u(t −1)]. (b) A time reversal in x(t) followed
by a unit shift to the left produces y(t) = x(−t −1) = et+1[u(−t −1) −u(−t −2)].
15. Even and odd parts of one-sided function.
a. Let y(t) be the causal part (the right-side segment) of a two-sided function x(t). Can one relate the even and
odd parts of y(t) to the even and odd part of x(t)?
b. Repeat for z(t) = x(t)u(−t) [i.e., the left-sided function made of the left side of x(t)].
Solution
a.
y(t) = x(t)u(t)
ye(t) = x(t)u(t) + x(−t)u(−t)
2
xe(t) = x(t) + x(−t)
2
yo(t) = x(t)u(t) −x(−t)u(−t)
2
xo(t) = x(t) −x(−t)
2
b.
z(t) = x(t)u(−t)
ze(t) = x(t)u(−t) + x(−t)u(t)
2
ze(t) = z(t) + z(−t)
2
zo(t) = x(t)u(−t) −x(−t)u(t)
2
zo(t) = z(t) −z(−t)
2
Given the even and odd parts of x(t), one can ﬁnd y(t) and z(t) and, as a result, their even and odd parts. However,
given either y(t) or z(t) (or, equivalently, the even or odd parts of each but not both), one cannot ﬁnd the even and
odd parts of x(t). In such a case, one side of x(t) will not be known.
16. Integration. A step function with non-zero rise-time may be obtained by integrating a ﬁnite-duration pulse. Consider
x(t) =





sin 2πt,
0 ≤t < 0.5
0,
0.5 ≤t < 1.5
sin 2πt,
1.5 ≤t < 2
0,
elsewhere
which is shown in Figure 1.52(a). Find and plot y(t) =  t
−∞x(t)dt and z(t) =  t
−∞y(t)dt.

Signals and Systems
95
Solution
See below and the plots in Figure 1.52.
t < 0





x(t) = 0
y(t) =  t
−∞x(t)dt = 0
z(t) =  t
−∞y(t)dt = 0
0 ≤t < 0.5





x(t) = sin 2πt
y(t) =  t
0 sin 2πtdt =
1
2π (1 −cos 2πt)
y(0.5) = 1
π
z(t) =
1
2π
 t
0 (1 −cos 2πt)dt =
1
2π

t −sin 2πt
2π

z(0.5) =
1
4π
0.5 ≤t < 1.5





x(t) = 0
y(t) = y(0.5) +  t
0.5 x(t)dt = 1
π + 0 = 1
π
y(1.5) = 1
π
z(t) = z(0.5) +  t
0.5 y(t)dt =
1
4π +  t
0.5
1
π dt = 1
π

t −1
4

z(1.5) =
5
4π
1.5 ≤t < 2











x(t) = sin 2πt
y(t) = y(1.5) +  t
1.5 x(t)dt = 1
π +  t
1.5 sin 2πtdt =
1
2π (1 −cos 2πt)
y(2) = 0
z(t) = z(1.5) +  t
1.5 y(t)dt =
5
4π +  t
1.5
1
2π (1 −cos 2πt)
z(2) =
3
2π
=
1
2π

1 + t −sin 2πt
2π

t ≥2





x(t) = 0
y(t) = y(2) +  t
2 x(t)dt = 0
z(t) = z(2) +  t
2 y(t)dt =
3
2π
17. Random signals.
a. Write a Matlab program to produce a Gaussian random sequence of length k with an expected mean = b and
variance of σ 2 = a2. The elements of the sequence are random variables which are independent from each other.
Discretize the amplitudes with a resolution of  = 1/N and obtain the frequency distribution of its elements.
Generate a sequence of 524,288 samples with mean = 10 and σ = 5. Call it xa(n). Find and plot the histogram
of its amplitude with a bin-width of 0.1. Find and plot its covariance function and spectrum.
b. Repeat for a random signal xb(n) with uniform amplitude distribution between −5 to 25.
Solution
a. The Matlab command randn(N, M) generates an N by M matrix of Gaussian (also called normal) random
numbers with zero mean and unity variance. The histogram of amplitude values can be constructed using the hist
command. The Matlab ﬁle given below generates a sequence of 524,288 Gausian random variables (mean = 10,
σ = 5) and obtains the amplitude distribution. Assuming a sampling rate of Fs = 8 kHz, the spectrum z versus
frequency f is obtained by applying the command [z, f ] = spectrum(x, f s). The maximum frequency is
Fs/2 = 4 kHz.
x=5*randn(1,1024*512)+10; figure(1); stairs(x); grid; axis([1
100
-5
25])
bin=-30:1/10:30; figure(2); hist(x,bin); h=hist(x,bin);
grid;
axis([-30
30
0
4500 ])

96
CHAPTER 1
Introduction to Signals
(a)
x(t) =





sin 2πt,
0 ≤t < 0.5
0,
0.5 ≤t < 1.5
sin 2πt,
1.5 ≤t < 2
0,
elsewhere
−1
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
Magnitude
(b)
y(t) =
 t
−∞
x(t)dt
=







1
2π (1 −cos 2πt) ,
0 ≤t < 0.5
1
π ,
0.5 ≤t < 1.5
1
2π (1 −cos 2πt),
1.5 ≤t < 2
0,
elsewhere
−1
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Time (s)
Magnitude
(c)
z(t) =
 t
−∞
y(t)dt
=











0
t < 0
1
2π (1 −cos 2πt) ,
0 ≤t < 0.5
1
2π

t −sin 2πt
2π

,
0.5 ≤t < 1.5
1
2π

1 + t −sin 2πt
2π

,
1.5 ≤t < 2
3
2π ,
t ≥2
−1
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
Time (s)
Magnitude
FIGURE 1.52
b. The Matlab command rand(N, M) generates an N by M matrix of random numbers between 0 and 1 with
uniform probability density. The following command generates the signal with uniform amplitude distribution
from −5 to 25.
x=30*rand(1,1024*512)-5;
The rest is the same as in part (a).
Chapter Problems
18. Sketch the following functions made of unit impulses. They may be called difference operators:
a. forward difference operator:
(i) 1st-order, δ(t + 1) −δ(t)
(ii) 2nd-order, δ(t + 2) −2δ(t + 1) + δ(t)
b. backward difference operator:
(iii) 1st-order, δ(t) −δ(t −1)
(iv) 2nd-order, δ(t) −2δ(t −1) + δ(t −2)

Signals and Systems
97
19. Sketch the following functions made of unit impulses:
a. x(t) = 6δ(t) −4δ(t −1) + 2δ(t −2)
b. xo(t) = −δ(t + 2) + 2δ(t + 1) −2δ(t −1) + δ(t −2)
c. xe(t) = δ(t + 2) −2δ(t + 1) + 6δ(t) −2δ(t −1) + δ(t −2)
Express x(t) in terms of xo(t) and xe(t). Argue if xo(t) and xe(t) may be considered the odd and even parts of x(t),
respectively.
20. Sketch the following functions made of unit impulses. In each case determine if the function is even or odd. If it is
neither, determine if by a time shift it may become even or odd.
a. δ(t) −δ(t −1)
b. −2δ(t) + 2δ(t −1)
c. δ(t + 2) + δ(t + 1) −δ(t −1) −δ(t −2)
d. δ(t + 1) −δ(t −1)
e. δ(t + 1) −2δ(t) + δ(t −1)
f. δ(t + 2) −2δ(t + 1) + 2δ(t −1) −δ(t −2)
g. −δ(t + 2) −δ(t + 1) + 4δ(t) −4δ(t −1) + δ(t −2) + δ(t −3)
21. Repeat problem 20 for the functions given below.
a. δ(t) −2δ(t −1) + δ(t −2)
b. δ(t) + δ(t −1) −3δ(t −2) + δ(t −3) + δ(t −4)
c. δ(t) + δ(t −1) −δ(t −2) −δ(t −3)
d. δ(t) −δ(t −1) + δ(t −4) −δ(t −5) + δ(t −8) −δ(t −9)
e. δ(t) −3δ(t −1) + 3δ(t −2) −δ(t −3)
f. δ(t) −δ(t −1) −δ(t −4) + δ(t −5) + δ(t −8) −δ(t −9)
g. δ(t) −2δ(t −1) + δ(t −2) + δ(t −4) −2δ(t −5) + δ(t −6) + δ(t −8) −2δ(t −9) + δ(t −10)
h. δ(t) −2δ(t −1) + δ(t −2) −δ(t −4) + 2δ(t −5) −δ(t −6) + δ(t −8) −2δ(t −9) + δ(t −10)
22. Repeat problem 20 for the functions given below. Assume sin(kπ)
πk
			
k=0 = 1.
a.
3

k=0
(k + 1)δ(t −k)
b. 3δ(t) −
3

k=1
δ(t −k)
c. 7δ(t) −
3

k=−3
δ(t −k)
d.
3

k=1
[δ(t + k) −δ(t −k)]
e. 5δ(t) −
5

k=1
δ(t −k)
f.
1

k=−1
[d(t −3k) −d(t −3k −1)]
g.
6

k=−6
sin(kπ/2)
k
δ(t −k)
h.
6

k=−6
sin(kπ/5)
k
δ(t −k)
i.
6

k=−6
sin(kπ/8)
k
δ(t −k)
23. Repeat problem 20 for the functions given below.
a. e−tδ(t)
b. e−t/5δ(t −5)
c. cos
πt
6

δ(t −2)
d.
3

k=0
e−tδ(t −k)
e.
5

k=0
e−t/5δ(t −k)
f.
2

k=−2
cos
πt
6

δ(t −k)
24. a. Find the values of the integrals given below.
(i)

∞
−∞
e−tδ(t)dt
(ii)

∞
−∞
e−t/5δ(t −5)dt
(iii)

∞
−∞
cos
πt
6

δ(t −1)dt
b. Find the values of the summations given below.
(iv)
3

k=0

∞
−∞
e−tδ(t −k)dt
(v)
5

k=0

∞
−∞
e−t/5δ(t −k)dt
(vi)
2

k=−2

∞
−∞
cos
πt
6

δ(t −k)dt
25. Find the values of the integrals given below.
a. 1−

t
−∞
[δ(t) + δ(t −1)] dt
b. 1−

t
−∞
[δ(t) −δ(t −1)]
c. −0.5+

t
−∞
[δ(t) −δ(t −1) + δ(t −2)] dt

98
CHAPTER 1
Introduction to Signals
26. a. Sketch the following functions made of unit impulses and determine if each function is odd, even, or neither.
Argue if x2(t) and x3(t) may be considered the odd and even parts of x1(t), respectively.
x1(t) = 3d(t) −
3

k=1
(k + 1)δ(t −k)
x2(t) =
3

k=1
[δ(t + k) −δ(t −k)]
x3(t) = 7d(t) −
3

k=−3
(k + 1)δ(t −k)
b. Find and sketch yi(t) =  t
−∞xi(τ)dτ, i = 1, 2, 3, where the xi(t)s are given in part (a). Show that y2(t) and
y3(t) are the even and odd parts of y1(t), respectively.
27. Sketch the following functions made of unit steps:
a. u(t + 1) −u(t −1)
b.
N

k=1
u(t + k) −u(t −k), N = 3, 5, 7
c. u(t + 0.5) −u(t −0.5)
d.
N

k=1
k odd
u(t + 0.5k) −u(t −0.5k), N = 5, 7, 9
e. u(t) + u(t −1) −2u(t −2)
f.
N−1

k=0
u(t −k) −Nu(t −N), N = 5, 7, 9
g. u(t −1) −u(−t −1)
h. u(t −1) −u(−t −1) + t [u(t + 1) −u(t −1)]
28. Find the time derivatives of the functions given in problem 27.
29. Let x(t) =

k
akδ(t −tk) and y(t) =

t
−∞
x(τ)dτ, where ak and tk are constants. Determine the DC steady-state
value of y(t) and ﬁnd condition in order for y(t) to be a ﬁnite-duration pulse.
30. Let the area under a pulse and its energy (shown by A and E, respectively) be deﬁned by
A =

∞
−∞
x(t)dt
E =

∞
−∞
|x|2(t)dt
a. Find A and E for x1(t), ax1(t), and x1(bt), where a and b are constants and x1(t) is a unit-sawtooth pulse
given by
x1(t) =

t,
0 < t ≤1
0,
elsewhere
b. Repeat for x1(−t).
c. Repeat for x1(t) + x1(−t).
31. Repeat problem 30 for the unit-sawtooth pulse given by
x2(t) =

1 −t,
0 ≤t < 1
0,
elsewhere
32. Repeat problem 30 for a one-sided unit-exponential x3(t) = e−tu(t).

Signals and Systems
99
33. Sketch the following functions made of unit steps.
a. u(t) −u(t −1)
b. −2u(t) + 2u(t −1)
c. u(t + 2) + u(t + 1) −u(t −1) −u(t −2)
d. u(t + 1) −u(t −1)
e. u(t + 1) −2u(t) + u(t −1)
f. u(t + 2) −2u(t + 1) + 2u(t −1) −u(t −2)
g. −u(t + 2) −u(t + 1) + 4u(t) −4u(t −1) + u(t −2) + u(t −3).
Show that in all cases the functions are ﬁnite-duration pulses. Find their DC, rms, and average power values taken
over the pulse duration.
34. For each function given in problem 33 determine if it is even or odd, and if it is neither, then determine if a time
shift may make it even or odd.
35. Show that the functions given in problem 33 are integrals of the functions given in problem 20.
Hint: In the expressions for the functions in problem 33, replace u by δ and you will get the expressions for the
functions in problem 20.
36. Repeat problems 33 through 34 for yi(t) =  t
−∞xi(τ)dτ, where the xi(t)s are as given in problem 28.
37. Repeat problems 33 through 34 for yi(t) =  t
−∞xi(τ)dτ, where the xi(t)s are as given in problem 30.
38. Let a unit square pulse be deﬁned by d(t) = u(t) −u(t −1).
a. A staircaselike function with four steps is speciﬁed by d(t) + 2d(t −1) + 3d(t −2) + 4d(t −3). Sketch it and
show that
3

k=0
d(t −k) =
3

k=0
u(t −k) −4u(t −4)
b. Show that
N−1

k=0
d(t −k) =
N−1

k=0
u(t −k) −Nu(t −N), where N ≥1 is an integer.
39. Sketch the following functions made of unit pulses deﬁned in problem 38.
a. d(t)
b. −2d(t)
c. d(t + 1) + 2d(t) + d(t −1)
d. d(t + 1) + d(t)
e. d(t + 1) −d(t)
f. d(t + 2) −d(t + 1) −d(t) + d(t −1)
g. −d(t + 2) −d(t + 1) + 2d(t) −2d(t −1) −d(t −2)
Which of the above functions are integrals of the impulse functions of problem 20?
40. Sketch the following functions and express them in terms of steps.
xa(t) =



−t,
−1 ≤t < 0
t,
0 ≤t < 1
0,
elsewhere
xb(t) =



t
0, ≤t < 1
2 −t,
1 ≤t < 2
0,
elsewhere
xc(t) =



t
0, ≤t < 1
t −2,
1 ≤t < 2
0,
elsewhere
xd(t) =



−1 −t,
−1 ≤t < 0
1 −t,
0 ≤t < 1
0,
elsewhere
xe(t) =



t
0 ≤t < 1
t −1,
1 ≤t < 2
1,
elsewhere
x f (t) =



1 −t
−1, ≤t < 0
t −2
< 0 ≤t < 1
0
elsewhere
41. Find the DC, rms, and average power value of each pulse in problem 40 taken over the pulse duration.

100
CHAPTER 1
Introduction to Signals
42. a. Sketch the ﬁnite-duration pulses speciﬁed below.
xa(t) =

−1,
−2 ≤t < 0
1,
0 ≤t < 2
xb(t) =



0,
t < 0
t,
0 ≤t < 1
1,
1 ≤t < 2
xc(t) =



−1,
−2 ≤t < −1
t,
−1 ≤t < 1
1,
1 ≤t < 21
b. In each case determine if the pulse is even or odd. If it is neither, determine if it may be made odd and/or even
by a shift in time or level.
c. Find the average and rms value of each pulse taken over the pulse duration.
43. Express the pulses given in problem 42 in terms of steps and ramps.
44. a. Sketch the following functions and determine their average (DC level) values.
xa(t) = tan−1(t)
xb(t) =
1
1 + e−t
xc(t) = 1 −e−t
1 + e−t
b. In each case determine if the pulse is even or odd. If it is neither, determine if it may be made odd and/or even
by a shift in time or level.
45. a. Write a Matlab program to plot the function y(t) = u(t) −u(t −1).
b. Repeat for the function speciﬁed in problem 33 g.
c. Repeat for y(t) = 
k aku(t −tk), where ak and tk are two known vectors of the same length.
46. a. Write a Matlab program to plot the function y(t) = d(t) −d(t −1), where d(t) = u(t) −u(t −1).
b. Repeat for the function speciﬁed in problem 39 g.
c. Repeat for y(t) = 
k akd(t −tk), where ak and tk are two vectors of the same length.
47. A unit ramp function is deﬁned by r(t) =

t,
t ≥0
0,
t < 0 .
a. Argue that the unit-step function u(t) is the integral of a unit impulse, and that the unit-ramp function r(t) is the
integral of a unit step.
u(t) =

t
−∞
δ(t)dτ =

1,
t > 0
0,
t < 0
r(t) =

t
−∞
u(τ)dτ =

t,
t > 0
0,
t < 0
b. Sketch the functions given below and graphically conﬁrm the above relationships.
(i) u(t)
(ii) u(−t)
(iii) u(t) −u(−t)
(iv) u(t −1)
(v) u(−t −1)
(vi) u(t −1) −u(−t −1)
(vii) r(t)
(viii) r(−t)
(ix) r(t) −r(−t)
(x) r(t −1)
(xi) r(−t −1)
(xii) r(t −1) −r(−t −1)
(xiii) r(t) −r(−t) + r(t −1) −r(−t −1)
48. Consider the single sawtooth pulse function x(t) = r(t) −r(t −1) −u(t −1) where r(t) is the unit ramp.
a. Sketch x(t), x(t + 1), x(t −1), x(−t), x(−t + 1), and x(−t −1).
b. Write a computer program to plot x(t) and x(−t −1) for −3 < t < 3. Save the plots as postscript graphs.
49. Consider a periodic signal
y(t) =
∞

n=∞
x(t + nT )

Signals and Systems
101
where x(t) is one of the pulses given in problem 48, n is an integer, and T is the period. Deﬁne the DC value of
y(t) and its average power (shown by DC and P, respectively) by
DC = 1
T

t0+T
t0
y(t) dt, P = 1
T

t0+T
t0
y2(t)dt
Plot y(t) and ﬁnd the DC and P values for (i) T = 4, (ii) T = 8, (iii) T = 12.
50. Repeat problem 49 for
y(t) =
∞

n=∞
(−1)nx(t + nT )
51. A single triangular waveform grows from 0 to 1 volt in 1 second and then is reduced to 0 in 2 seconds. Plot it and
express it in terms of step functions.
52. The periodic rectangular pulse train x(t) shown in Figure 1.53(a) is speciﬁed by a period T = 10 msec, a pulse
duration τ = 2 msec, and a base to peak value of V0 = 5 V.
a. Find its frequency, duty cycle (deﬁned by τ
T %), DC, and rms values.
b. Shift it by 1 msec to the right and subtract the result from x(t) to ﬁnd a new pulse train to be called y(t). Plot
y(t) and ﬁnd its DC and rms values.
c. Deﬁne ζ(t) (pronounced zeta of t) to be a 1-V, 1-msec wide rectangular pulse at the origin,
ζ(t) =

1,
0 < t < 1 msec
0,
elsewhere
.
Express x(t) and y(t) in terms of ζ(t). Then express their DC and rms values in terms of the area under ζ(t)
and its energy.
53. Five periodic functions xi(t), i = 1, . . . , 5 shown in Figure 1.53(b)–(g), resepectively, are speciﬁed by T = 10
msec, τ = 1 msec, and V0 = 5 V.
a. Find the DC and rms value of each function.
b. Deﬁne
ζ(t) =

1,
0 < t < 1 msec
0,
elsewhere
Express each function in Figure 1.53 in terms of ζ(t). Then determine their DC and rms values in terms of of
the area under ζ(t) and its energy.
c. Investigate if any of the above functions can be obtained analytically by a linear combination of the others or by
any combination of shift and/or reversal operations on the others.
54. Two periodic functions x1(t) and x2(t) [shown in Figure 1.54(a) and (b), respectively] are speciﬁed by T = 10 msec,
τ = 1 msec, and V0 = 5 V.
a. Find the DC and rms values of each function.
b. Deﬁne η(t) (pronounced eta of t) to be a single equilateral triangular pulse with a height of 1 and a base of τ:
η(t) =

1 −2 |t|
τ ,
−τ
2 < t < τ
2
0,
elsewhere
Express x1(t) and x2(t) in terms of η(t). Then determine their DC and rms values in terms of the area under η(t)
and its energy.
c. Investigate if x2(t) may be expressed analytically in terms of x1(t).

102
CHAPTER 1
Introduction to Signals
τ
T
0
(a)
(b)
(c)
(d)
(e)
(f)
V0
t
τ
τ
τ
T
0
V0
τ
T
–V0
V0
0
t
τ
τ
τ
T
0
V0
T
0
–V0
V0
t
τ
τ
T
–V0
V0
τ
τ
τ
FIGURE 1.53
T
0
(a)
(b)
V0
t
τ
t
T
2
0
V0
–V0
τ
FIGURE 1.54
55. Three periodic functions x1(t), x2(t), and x3(t) shown in Figure 1.55 (a), (b), and (c), respectively, are speciﬁed by
T = 10 msec, τ = 1 msec, and V0 = 5 V.
a. Find the DC and rms values of each function.

Signals and Systems
103
T
0
V0
t
τ
0
(a)
(b)
(c)
t
τ
V0
–V0
t
τ
0
V0
–V0
T
2
T
2
FIGURE 1.55
b. Deﬁne ξ(t) (pronounced cai of t) to be a single right-angle triangular pulse with a height of 1 and a base of τ:
ξ(t) =

t,
−0 ≤t < τ
0,
elsewhere
Express x1(t), x2(t), and x3(t) in terms of ξ(t). Then determine their DC and rms values in terms of the area
under ξ(t) and its energy.
c. Investigate if any of the above functions can be obtained by a linear combination of the others or by any
combination of shift and/or reversal operations on the others.
56. The periodic functions x1(t) and x2(t) shown in Figure 1.56 are called half-symmetric. Plot their time integrals
yi(t) =

t
−∞
xi(τ)dτ,
i = 1, 2
and compute their DC and rms values. Assume y1(−∞) = y2(−∞) = 0.
57. Repeat problem 56 for the periodic functions shown in:
a. Figure 1.53(c), (d), (e), and (f).
b. Figure 1.54(b).
c. Figure 1.55(b) and (c).
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
(a)
(b)
Amplitude
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time (s)
Amplitude
An odd periodic sawtooth train
An even triangular pulse train with DC level
FIGURE 1.56 Two periodic functions with the same period T and half-symmetry property: x(t) = −x(t + T/2).

104
CHAPTER 1
Introduction to Signals
0
T
τ
V0
FIGURE 1.57
58. A ﬁnite-duration pulse is described by x(t) = cos(2πt/T )[u(t −T/4)−u(t −T/4)]. Sketch the following functions
and ﬁnd their DC and rms values.
y1(t) =
∞

n=−∞
V0x(t −nT ),
y2(t) =
∞

n=−∞
V0x(t −nT/2),
y3(t) =
∞

n=−∞
(−1)nV0x(t −nT )
59. The power drawn from a sinusoidal source is controlled by applying a threshold level λ to it in order to produce the
signal:
x(t) =

sin ωt −λ,
if sin ωt > λ
0,
otherwise
Sketch x(t) and ﬁnd its DC value and average power as a function of λ > 0.
60. a. Find the area and energy of a single pulse made of the partial sinusoid described by
x(t) =

V0 cos  πt
T

,
T
2 −τ ≤t < T
2
0,
elsewhere
b. Find the DC and rms values of the following periodic functions made of the pulse of part (a).
y1(t) =
∞

n=−∞
x(t −nT ),
y2(t) =
∞

n=−∞
(−1)nx(t −nT/2)
61. A ﬁnite-duration pulse is described by x(t) = e−t [u(t) −u(t −3)]. Sketch the following functions and ﬁnd their
DC and rms values over a period of 6. Describe symmetry property of each function.
y1(t) = x(t) + x(−t), y2(t) = x(t) −x(−t), y3(t) = x(t) −x(t −3),
62. A ﬁnite-duration sinc pulse is given by x(t) = sin(πt)
πt
[u(t + 2) −u(t −2)]. Obtain the DC and rms values of the
following pulses over the period of 10 seconds (|t| < 5).
a. y1(t) = x(t)
b. y2(t) = x(t + 2) + x(t) + x(t −2)
c. y3(t) = x(t + 1) + x(t) + x(t −1)
63. a. Consider a ﬁnite-duration pulse η(t) with area A and energy S. Find the area of the pulse y(t) = aη(bt), where
a and b are real constants, in terms of A, S, a, and b.
b. Let η(t) be a unit rectangular pulse η(t) = u(t) −u(t −1). Using the result of part (a) ﬁnd the area and energy
in the pulse shown in Figure 1.58(a) as a function of τ, τ1, V0, and V1.
c. Let η(t) be an equilateral triangular pulse speciﬁed by
η(t) =

1 −2 |t|
τ ,
−τ
2 < t < τ
2
0,
elsewhere
Using the results of parts (a) and (b), ﬁnd the area and energy of the pulse of Figure 1.58(b) in terms of τ, V0,
and V1.

Signals and Systems
105
0
(a)
(b)
t
τ
V0
–V1
τ1
0
τ
t
V0 + V1
V0
FIGURE 1.58
64. a. Find the area and energy of the following single pulse made of a segment of an exponential function:
x(t) =

e−t,
0 < t < 1
0,
elsewhere
b. Consider the periodic function y1(t) =
∞

k=−∞
x(t −k), where k is an integer. Plot y1(t) and ﬁnd its DC and rms
values.
c. Repeat part (b) for
(i) y2(t) =
∞

k=−∞
x(t −2k)
(ii) y3(t) =
∞

k=−∞
(−1)kx(t −k)
(iii) y4(t) =
∞

k=−∞
x(t −2k) −x(t −2k −1)
(iv) y5(t) =
∞

k=−∞
x(t −2k) −(−1)kx(t −2k −1)
65. a. Find the area and energy of the following single pulse made of a segment of an exponential function:
x(t) =

e−t,
0 < t < 2
0,
elsewhere
b. Consider the periodic function y1(t) =
∞

k=−∞
x(t −2k), where k is an integer. Plot y(t) and ﬁnd its DC and
rms values.
c. Repeat part (b) for
(i) y2(t) =
∞

k=−∞
(−1)kx(t −2k)
(ii) y3(t) =
∞

k=−∞
x(t −4k)
(iii) y4(t) =
∞

k=−∞
(−1)kx(t −4k)
(iv) y5(t) =
∞

k=−∞
x(2t −k)
(v) y6(t) =
∞

k=−∞
(−1)kx(2t −k)
66. a. Find the area and energy of the following single pulse made of a segment of an exponential function:
x(t) =

e−t
0 < t < 3
0
elsewhere

106
CHAPTER 1
Introduction to Signals
b. Consider the periodic function y1(t) =
∞

k=−∞
x(t −3k), where k is an integer. Plot y(t) and ﬁnd its DC and rms
values.
c. Repeat part (b) for
(i) y2(t) =
∞

k=−∞
(−1)kx(t −3k)
(ii) y3(t) =
∞

k=−∞
x(t −6k)
(iii) y4(t) =
∞

k=−∞
(−1)kx(t −6k)
(iv) y5(t) =
∞

k=−∞
x(3t −k)
(v) y6(t) =
∞

k=−∞
(−1)kx(3t −k)
67. a. Prove that x(t) = x(−t) where
x(t) =



1 + 2 t
τ
−τ
2 < t < 0
1 −2 t
τ
0 < t < τ
2
0
elsewhere
Plot x(t) and observe that it is an even function of t.
68. Let x(t) be the even equilateral triangular pulse with a base τ and height 1 speciﬁed in problem 67.
a. Express y(t) = x(t + τ/2) + x(t) + x(t −τ/2) section-wise in terms of t.
b. Find its rise time (the time it takes for the pulse to grow from 10% to 90% of its ﬁnal value).
69. In the expression given for x(t) in problem 67 replace t by t −τ/2 and show that the new function is expressed by
x(t −τ) =



2 t
τ ,
0 < t < τ
2
2 
1 −t
τ

,
τ
2 < t < τ
0,
elsewhere
Plot the new function and observe that it is the same as the plot obtained in problem 67, except for a shift to the
right by the amount τ/2.
70. Repeat problem 68 for
x(t) =
 0.5 + 0.5 cos  2πt
τ

,
−τ
2 < t < τ
2
0,
elsewhere
71. In the expression given for x(t) in problem 70 replace t by t −τ/2 and show that the new function is expressed by
x(t) =
 0.5 −0.5 cos  2πt
τ

,
0 < t < τ
0,
elsewhere
Plot the new function and observe that it is the same as the plot of x(t) from problem 70, except for a shift to the
right by the amount τ/2.
72. Given the one-sided exponential function x(t) = e−tu(t), express the following as functions of time and plot them:
a. x(t −1), x(t + 1)
b. x(−t), x(−t + 1), x(−t −1)
c. x(4t), x(0.25t + 1), x(−0.25t + 0.5)

Signals and Systems
107
73. The unit-step function u(t) is deﬁned by u(t) =

1,
t ≥0
0,
t < 0 . Plot
a. u(t), u(t −2), u(t + 2)
b. u(−t), u(−t + 2), u(−t −2)
c. u(2t), u(−2t + 6), u(2t −6)
74. Consider the single pulse speciﬁed by
x(t) =
 e−t,
0 < t < 1
0,
elsewhere
a. Plot x(t), x(t + 1), x(t −1), x(−t), x(−t + 1), and x(−t −1).
b. By examining the graphs verify that the plot of x(−t + 1) may be found by ﬂipping the plot of x(t + 1) around
the vertical axis at t = 0. Similarly, the plot of x(−t −1) is that of x(t −1) ﬂipped around the vertical line
t = 0.
c. Consider periodic functions yi(t), i = 1, 2, 3, 4 with periods T = 2, where, for one period,
y1(t) = x(t) + x(−t),
−1 < t < 1
y2(t) = x(t) −x(−t),
−1 < t < 1
y3(t) = x(t) −x(t −1),
0 < t < 2
y3(t) = x(t) + x(t −1),
0 < t < 2
Plot yi(t), i = 1, 2, 3, 4 and ﬁnd their average and rms values.
75. Repeat problem 74 for
x(t) =

t,
0 < t < 1
0,
elsewhere
76. Consider the periodic functions x1(t) and x2(t) with period τ, where, for one period,
x1(t) = e−t/τ,
0 < t < τ
x2(t) = e−2t/τ,
0 < t < τ
a. Plot x1(t) and x2(t) and ﬁnd their average and rms values.
b. Find mathematical expressions for dx1(t)/dt and dx2(t)/dt, and sketch them.
77. A 1-kHz periodic voltage v(t) grows exponentially from −2.3 V to 2.3 V and decays back to −2.3 V, in both cases
with a time constant of 0.5 msec.
a. Find a mathematical expression for v(t) and plot it. Find its rise and fall times, average, and rms values.
b. Find a mathematical expression for dv(t)/dt and sketch it.
78. A 1-kHz periodic voltage v(t) grows exponentially from 1 to 4 V with a time constant of 0.15 msec, and decays
back to 1 V with a time constant of 0.6 msec.
a. Find a mathematical expression for v(t) and plot it. Find its rise and fall times, average, and rms values.
b. Let x(t) = v(t) −V0, where V0 is the average of v(t). Find the rms value of x(t) and relate it to V0 and the rms
value of v(t).

108
CHAPTER 1
Introduction to Signals
79. Let x(t) = sin(2π f t). Deﬁne
y1(t) =

x(t),
when x(t) > V0
0,
otherwise
y2(t) =

x(t),
when |x(t)| > V0
0,
otherwise
where V0 is a nonnegative constant.
a. Plot y1(t) and y2(t) and ﬁnd their average and rms values as functions of V0.
b. Find mathematical expressions for dyi(t)/dt (i = 1, 2) and sketch them.
80. Consider a single cycle of a sinusoid x(t) and its ﬁrst and second integrals y(t) and z(t), respectively.
x(t) =

sin t,
0 < t < 2π
0,
elsewhere
y(t) =

t
−∞
x(t)dt =

1 −cos t,
0 < t < 2π
0,
elsewhere
z(t) =

t
−∞
y(t)dt =
 0,
t < 0
t −sin t,
0 < t < 2π
2π,
t ≥2π
a. Sketch x(t), y(t), and z(t).
b. Show that the area under each half cycle of x(t) is 2, its DC value is zero, and its rms value deﬁned over the
period 0 < t < 2π is 1/
√
2.
c. Show that y(t) is a ﬁnite-duration positive pulse that lasts 2π seconds with a maximum value of 2 and an area
equal to 2π.
d. Show that z(t) has a steady-state DC level of 2π and reaches it in 2π seconds.
81. A periodic waveform f (t) with period T is made of isosceles triangular pulses (height = 1, base = T ). It is passed
through a level detector set at a positive-level threshold V0, producing a rectangular output waveform v(t) such that
v(t) =

1,
f ≥V0
0,
f < V0
Find the DC, rms, and average power values of v(t) as functions of period T and the threshold level V0.
82. The average power of a voltage signal is one Watt and its average value is zero. A DC level of V0 is added to the
signal. Find the new average power.
83. On-off control. A sinusoidal wave sin(2π f t) is gated by a periodic rectangular pulse with a period T and a duty
cycle (T1/T ) × 100%. One cycle of the gated signal is given by
x(t) =

V0 sin(2π f t),
0 ≤t ≤T1
0,
T1 ≤t ≤T
where T1 = k1/f , T = k/f , and k1 and k are integers. Find the rms value of x(t) as a function of α = k1/k.
84. Light dimmer. A sinusoidal signal sin(2πt/T ) is sent through a gating device such that only an initial portion of
each half cycle passes through. One period of the resulting signal is expressed by
v(t) =

sin(2πt/T ),
0 ≤t ≤τ
and T/2 ≤t ≤(T/2 + τ)
0,
τ < t < T/2 and
(T/2 + τ) < t < T

Signals and Systems
109
a. Let τ = αT (0 < α < 0.5). Show that the rms of v(t) as a function of α is given by
Vrms(α) = 2
T

αT
0
sin(2πt/T )dt
Find Vrms(α) and plot it vs. α.
b. Observe that the plot is not linear. Devise and use a nonlinear scale for the α-axis such that the plot of Vrms(α)
vs. α under the new scale becomes a linear one.
85. By using a computational/plotting software of your choice plot the function x(t) = 10[e−t −e−t/5]u(t). Then use
measurements off the graph to model it by the sum of two exponentials. Compare the model with x(t).
86. In an electric device, a pair of input output voltage signals is given by v1(t) = 10 cos t and v2(t) = 2 sin(t + π/3),
respectively.
a. Show that their phasor representations are V1 = 10̸ 0◦and V2 = 2̸ −30◦.
b. Determine H = V2/V1.
c. By using a computational/plotting software of your choice, plot v1(t) and v2(t) on the same graph (sharing the
same axes).
d. From measurements off the graph model the plots by ˆv1(t) = a1 cos(2π f t + θ1) and ˆv2(t) = a2 cos(2π f t + θ2).
Then ﬁnd the ratio of their phasors and compare with the original voltages.
87. Plot the exponential function x(t) = 10e−t/5 cos(10t)u(t). Then use measurements off the graph to model it.
Compare the model with x(t).
88. Let x(t) be a continuous-time function that changes smoothly. Let ζ(t) (pronounced zeta of t) be the rectangular
pulse
ζ(t) =

1,
0 < t < T
0,
elsewhere
x(t) may be approximated by ˆx(t) [made of the sum of rectangular pulses shifted in time and scaled by x(nT )]:
ˆx(t) =
∞

n=−∞
x(nT )ζ(t −nT )
Apply the above approximation to the periodic functions listed below. Note that in all cases the period is 1 second.
x(t) = t,
0 < t ≤1,
x(t) = x(t ± n), n an integer
x(t) = cos(2πt),
all t,
x(t) = e−t,
0 < t ≤1,
x(t) = x(t ± n), n an integer
x(t) = e−|t|,
−0.5 < t ≤0.5,
x(t) = x(t ± n), n an integer
Deﬁne the approximation error by ϵ(t) = x(t) −ˆx(t). Find E = rms of ϵ(t):
E =

t0+1
t0
ϵ2(t)dt
as a function of the sampling interval T and ﬁnd its limit as T →0.
89. The unit-step function may be approximated by analytic functions. One such function is the sigmoid containing a
parameter a and described by
x(t) =
1
1 + e−at

110
CHAPTER 1
Introduction to Signals
a. Verify that
x(−∞) = 0, x(∞) = 1 x(0) = 0.5 and dx
dt
		
t=0 = a
b. By simulation method explore if
(i) lim
a→∞x(t) = u(t)
(ii) lim
a→∞
dx
dt = kδ(t)
90. It is desired to approximate the even rectangular pulse x(t) = u(t + 1) −u(t −1) by analytic functions. The
following two families of functions, in which n is a positive integer, are proposed:
a. ηn(t) =
1
1 + t2n
b. ζn(t) =
1
100 +
n

k=1

2
kπ sin

kπ
100

cos

kπt
100

By simulation method explore if
a. lim
n→∞ηn(t) = x(t)
b. lim
n→∞ζn(t) = x(t)
and examine how ηn(t) and ζn(t) would or would not converge to x(t) in the neighborhood of t = ±1.
91. a. Sketch the ﬁnite-duration pulse made of the half cycle of a cosine
x(t) =
 1
2 cos t,
−π/2 < t < π/2
0,
elsewhere
and show that the area under the pulse is 1.
b. Sketch the family of ﬁnite-duration pulses yω(t) = ωx(ωt)
yω(t) =
 ω
2 cos ωt,
−π/2 < ωt < π/2
0,
elsewhere
for ω = n/π, n = 1, 2, 3, 4, 5. Note that as ω increases, the pulse becomes narrower and taller. Show that the
area under the pulse always remains equal to 1:

∞
−∞
yω(t)dt = 1, for all ω
c. Argue that
lim
ω→∞

∞
−∞
yω(t)φ(t)dt = φ(0)
where φ(t) is a smooth function in the neighborhood of t = 0. Extend the argument to
lim
ω→∞

∞
−∞
yω(t −t0)φ(t)dt = φ(t0)
Argue that in that sense,
lim
ω→∞yω(t) = δ(t)
d. Find

t
−∞
yω(t)dt

Signals and Systems
111
and argue that
lim
ω→∞

t
−∞
yω(t)dt = u(t)
e. Provide three other pulse functions that exhibit limit properties similar to those of yω(t) given in this problem.
92.
a. Sketch the family of sinc functions yn(t) = sin(πnt)
πt
for n = 1, 2, 3, 4, 5. Note that as n increases, the main lobe
becomes narrower and taller. Show that the net area under the function always remains equal to 1.
b. Can you assert that
lim
n→∞

∞
−∞
yn(t)φ(t)dt = φ(0)
where φ(t) is a smooth function in the neighborhood of t = 0? And, consequently, that
lim
n→∞yn(t)
?= δ(t)
c. Sketch

t
−∞
yn(t)dt
for n = 1, 2, 3, 4, 5 and argue that
lim
n→∞

t
−∞
yn(t)dt = u(t)
93. Consider a ﬁnite-duration pulse xa(t) made of a single cycle of a sinusoid
xa(t) =

a2 sin at,
0 < t < 2π
a
0,
elsewhere
a. Sketch xa(t) for a = 2nπ, n = 1, 2, 3, 4, 5. Find the area under each half cycle of x(t) and its rms value deﬁned
over the duration of the pulse.
b. Let
ya(t) =

t
−∞
xa(t)dt
Find ya(t) and sketch it for a = 2nπ, n = 1, 2, 3, 4, 5. Show that ya(t) is a ﬁnite-duration positive pulse. Find
its duration, its maximum value, and its area.
c. Let
za(t) =

t
−∞
ya(t)dt
Find za(t) and sketch it for a = 2nπ, n = 1, 2, 3, 4, 5. Find its DC steady-state value and the transition time to
reach the steady-state value.
d. Argue that
(i) lim
a→∞ya(t) = 2πδ(t)
(ii) lim
a→∞za(t) = 2πu(t)
94. Repeat problem 93 starting with the ﬁnite-duration odd pulse
xa(t) =

−a2 sin at,
−π/a < t < π/a
0,
elsewhere
and ﬁnd the limits as a →∞.

112
CHAPTER 1
Introduction to Signals
95. Repeat problem 93 starting with the ﬁnite-duration odd pulse
xb(t) =
 b2,
−1/b < t < 0
−b2,
0 < t < 1/b
0,
elsewhere
and ﬁnd the limits as b →∞.
96. Repeat problem 93 starting with the ﬁnite-duration odd pulse
xc(t) =

ect,
t < 0
−e−ct,
t > 0
and ﬁnd the limits as c →∞.
97. Consider the sinc function x(t) = sin(at)
bt ,
−∞< t < ∞.
a. Plot x(t) and show that its maximum value is a/b and the area under it is π/b.
b. Consider the family of functions
yk(t) =

x(t),
−kπ/a < t < (k + 1)π/a, k = 1, 2, 3, 4 · · ·
0,
elsewhere
Show that lim
a→∞yk(t) = αkδ(t), where αk are constants.
c. Consider the family of periodic functions
z(t) = x(t),
−3π
2 < t < 3π
2 , z(t) = z(t + T ), T = 3π,
for all t
Show that z(t) is an even function and lim
a→∞z(t) is a train of impulses spaced every 3π seconds.
98. Response of RC to step voltage and its approximation. A 1-k	 resistor and a 1,000-µF capacitor are connected
in series with a voltage source v1(t) as in Figure 1.26. With v1(t) = u(t) (V), the capacitor current and voltage
signals are shown to be i(t) = e−tu(t) (mA) and v2(t) = (1 −e−t)u(t) (V), respectively. Plot i(t) and v2(t) for
−τ < t < 5τ, where τ is their common time constant. For each signal determine initial and ﬁnal values. An
exponential function can be approximated as ex ≈1 + x near |x| ≈0 (as evidenced by the Taylor series expansion
near zero of the exponential, or the behavior of its tangent at x = 0). Using that approximation, ﬁnd the behavior of
the current and voltage signals for −0.001τ < t < 0.005τ and plot them. For the current signal ﬁnd the maximum
percentage difference between the exact and approximate values within the above range.
99. Response of RC to narrow pulse voltage and its approximation. Let the voltage source in the RC circuit of
Figure 1.26 be a 1-kV, 1-ms pulse [i.e., v1(t) = 103[u(t) −u(t −0.001)] V]. Obtain and plot i(t) and v2(t) for the
range of −τ < t < 5τ, and their linear approximations during −0.001τ < t < 0.005τ.
100. Modem standard (QAM). The 2400 bit/sec CCITT V.22 bis modem11 uses the 16-symbol QAM signal constellation
shown in Figure 1.59 at a bit rate of 2,400 bit/sec. Compute its average power (Pavg) and the minimum distance
(dmin) between the subsignals. Give the coordinates of the four subsignals A, B, C, and D shown on the ﬁgure.
11International Telegraph and Telephone Consultative Committee (CCITT) has been renamed ITU-T. It is the
standardization division for telecommunication of the International Telecommunication Union (ITU).

Signals and Systems
113
0
–1
–2
–3
–4–4
–3
–2
–1
0
1
2
3
4
1
2
3
4
xq
A
B
C
D
xp
FIGURE 1.59 16-QAM constellation signaling for 2,400 bit/sec V.22 bis computer modem.
101. Barker code. A Barker code is a binary sequence cN(n), n = 1, 2, · · · N (shown by + and −, or 1 and −1) with
code length N = 1, 2 · · · 11, 13, as listed in the table below.
N
cN(n)
2
1 −1 or −1 1
3
1 1 −1
4
1 −1 1 1 or 1 −1 −1 −1
5
1 1 1 −1 1
7
1 1 1 −1 −1 1 −1
11
1 1 1 −1 −1 −1 1 −1 −1 1 −1
13
1 1 1 1 1 −1 −1 1 1 −1 1 −1 1
To obtain an indicator for the pattern of dependency between 1s and −1s in the Barker code, for each code sequence
c(n) listed in the table above deﬁne ρ(k) as the index of correlation between its elements:
ρ(k) =
N

n=1
c(n)c(n −k), k = 0, 1, 2, . . . , N
For codes with lengths N = 2, 3, 4, 5, 7, 11, 13 ﬁnd and plot ρ(k) and determine the ratio ρ(k)/ρ(0).
102. Signaldetection.Adeterministicperiodicbinarysequence x(n)madeofregularlyalternating1sand0sistransmitted
at the rate of 106 bits per second. For transmission it uses an on-off encoding scheme where the 1 bits are transmitted
by s(t) and the 0 bits are transmitted by silent periods each 1 µs long. The encoded signal is a periodic signal x(t)
given by
x(t) =

s(t),
0 < t < 0.5 µs
0,
0.5 µs < t < 1 µs ,
x(t) = x(t + 1µs) all t
To detect the occurrence of a 1 or 0, the received signal ˆx(t) [generally a corrupted version of x(t) due to commu-
nication noise and interference] is continually matched with the template s(t) and the results are observed every
T = 1/M µs (i.e., at intervals t = k/M µs, k = 0, 1, 2 · · · , M −1 ). The integer M indicates the frequency

114
CHAPTER 1
Introduction to Signals
(or number) of observations during transmission of each bit. The present problem illustrates the effect of s(t) on
separability of 1s and 0s at the receiver. For simplicity we assume no interference or noise; that is, ˆx(t) = x(t).
Assume a matching scheme where x(t) is multiplied by a sliding s(t)-shaped window slid every 1/M µs. The
results are integrated over 1 µs, resulting in observation values y(k):
y(k) =

1 µs
0
x(t)s(t −kµs)dt,
k = 0, 1, 2 · · · (M −1)
a. Let s(t) be a 1-volt rectangular 1 µs pulse. Find the maximum value yMax and its location k0. Find the distance
between the peak value and its immediate neighbor yMax −y(k0 −1). Consider this to be a separability distance.
b. Repeat for a binary s(t) = ±1 made of a 7-segment Barker code and observations every 1/7 µs. Compare with
the corresponding value obtained in part (a).
c. Repeat for a binary s(t) = ±1 made of an 11-segment Barker code and observations every 1/11 µs. Compare
with corresponding values obtained in parts (a) and (b).
d. Repeat for a binary s(t) = ±1 made of a 13-segment Barker code and observations every 1/13 µs. Compare
with corresponding values obtained in parts (a), (b), and (c).
e. Discuss the gain in separability distance versus the increase in eventual transmission rate as you increase the
length of the Barker code used.
103. A ranging signal for space communication and control uses a binary code cn of order n with a period Tn = 2n. The
signal is a periodic binary function produced by assigning an amplitude of +1 to the high values of the code and 0 to
the low values. The (n + 1)-th code c(n+1) is constructed by cascading cn with its logical complement. Alternatively,
the code of order n may be generated through the recursive equation
Cn+1(t) = cn(t) −cn(t −T n)
starting from c0(t) = −1. Examples of the signal for the ﬁrst ﬁve codes (n = 0, 1, 2, 3, 4) are as follows:
c0 = 0
c1 = 01
c2 = 0110
c3 = 01101001
c4 = 0110100110010110
Find the DC and rms values of the codes for order n = 4, 8, and 10.
104. Signal encoding. Consider a binary sequence x(n) made of + and −(or, equivalently, +1 and −1) which occur
randomly with equal probability of 50% and independently of each other. By encoding, we convert x(n) into a time
signal x(t). In this problem you compare two such schemes called on-off and polar encoding.
a. In on-off encoding, the 1 bits are transmitted by ra(t) = Ra sin(2π f t), 0 < t < T (shown by the phasor Ra̸ 0◦)
with an energy content of T R2
a/2, and the 0 bits are transmitted by no pulse (a silent period T seconds long
shown by the phasor 0̸ 0◦, with zero energy content). Deﬁne the distance between the encoded 1s and 0s to be
Da = T R2
a/2. The resulting encoded time signal is xa(t). Find the average power Pa in xa(t).
b. In polar encoding, the 1 and 0 bits are transmitted by rb(t) = Rb sin(2π f t) and −rb(t), respectively (and shown
by the phasors Rb̸ 0◦and Rb̸ 180◦, each with the same energy content T R2
b/2). However, because of the 180◦
phase shift, the distance between 1 and 0 will be Db = T R2
b. The resulting encoded time signal is xb(t). Find
the average power Pb in xb(t).
c. Find the relationship between Ra and Rb if distances between 1s and 0s are to be the same. Then compare Pa
with Pb.

Signals and Systems
115
105. Morse code. The international Morse code12 converts symbols (letters, numbers, and some other characters) to a
sequences of short (dots, pronounced dit) and long (dashes, pronounced dah) tone bursts. In terms of timing, a dit
takes one unit of time (also called an element), a dah takes three units of time, and a pause between a dit and a dah
takes one dit of time. The pause between letters lasts three units, and that between words lasts seven units of time.
The code is given in the table below.
Symbol
Morse Code
Symbol
Morse Code
Symbol
Morse Code
A
. —
U
. . —
0
— — — — —
B
— . . .
V
. . . —
1
. — — — —
C
— . — .
W
. — —
2
. . — — —
D
— . .
X
— . . —
3
. . . — —
E
.
Y
— . — —
4
. . . . —
F
. . — .
Z
— — . .
5
. . . . .
G
— — .
6
— . . . .
H
. . . .
7
— — . . .
I
. .
8
— — — . .
J
. — — —
9
— — — — .
K
— . —
Period
. — . — . —
L
. — . .
Comma
— — . . — —
M
— —
?
. . — — . .
N
— .
Hyphen
— . . . . —
O
— — —
Apostrophe
. — — — — .
P
. — — .
Colon
— — — . . .
Q
— — . —
Quotation
. — . . — .
R
. — .
/
— . . — .
S
. . .
@
. — — . — .
T
—
a. The standard word for measuring transmission speed is the word paris. Find the Morse code for it, count the
number of dits, dahs, and spaces, and determine how many elements it takes.
b. Find the Morse code sequence for the phrase “An introduction to signals and systems, @ Cal Poly State
University.”
c. Count the number of dits, dahs, and spaces, and ﬁnd their percentage in the code sequence of part (b).
d. Consider a tone burst r(t) = sin(2πft), 0 < t < T , lasting T seconds with an rms value of
√
2/2 V, and assume
each dit is transmitted by an r(t). This is called continuous wave (CW) operation. Find the total energy in the
signal representing the code sequence found in (a), its duration, and its average power during transmission.
e. Assume a CW operator using a bencher iambic key transmits 30 WPM (words per minute, based on the standard
of 50 time-elements per word). Determine how long it takes the operator to transmit the phrase in (b), and the
average power needed during transmission.
12The original code was invented by Samuel Morse in 1838 and was used for the ﬁrst time in 1844 to send a
message over a telegraph line between Baltimore and Washington. The international Morse code, devised in
1851 and currently in use with some modiﬁcations, simpliﬁed the code. Proﬁciency in communication using
Morse code, which has been a requirement for obtaining the amater Radio license, was phased out by 2010.

116
CHAPTER 1
Introduction to Signals
106. Mapping a code. Let a Morse code sequence (made of dits, dahs, and pauses) be mapped into a sequence of tertiary
numbers made of 1, −1, and 0.
a. Map the Morse code sequence obtained in problem 105(b) into a new sequence based on the “tertiary code”
described above.
b. Count the number of 1s, −1s, and 0s in the tertiary sequence and ﬁnd their percentage in the code sequence.
c. Assume the 1 and −1 bits in the tertiary code sequence are transmitted by r(t) = sin(2π f t) and −r(t) =
−sin(2πft) = sin(2πft−180◦) of duration T (also called polar or phase-shift keying), respectively. A 0 bit is
signaled by a silent period of T seconds. Find the total energy in the signal representing the code sequence, its
duration, and its average power during transmission.
107. ASCII code. A popular code for converting symbols to 8-bit binary numbers is the ASCII (American Standard
Code for Information Interchange) code.
a. Obtain an ASCII code table, then ﬁnd the ASCII code sequence for the phrase “An introduction to signals and
systems, @ Cal Poly State University.”
b. Count the number of 1s and 0s and ﬁnd their percentage in the code sequence.
c. Assume each 1 is transmitted by r(t) = sin(2πft) and each 0 bit is signaled by a silent period of T seconds.
Find the total energy in the signal representing the code sequence, its duration, and its average power during
transmission.
1.25
Project 1: Binary Signal in Noise
Summary
This project formulates detection of a signal in noise and errors associated with it when the signal is corrupted by additive
noise.
The Signal
In a binary communication system the high bit is transmitted as the sinc voltage function ζ(t) = sin(2πt)/(2πt). For
example, the data sequence z(k) = {0, 1
↑, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0} is represented by s(t) = ζ(t) + ζ(t −3) +
ζ(t −5) + ζ(t −6) + ζ(t −9). See Figure 1.60. Note that in this scheme all zero crossings occur at t = k, where k is an
integer. At t = k the signal value is, therefore, either zero (for a low bit) or one (for a high bit). The presence of a high bit
at t = k can be detected from the value of s(t) at such times, as the interferences from neighboring bits are zero. To detect
the presence or absence of a high bit, the signal is passed through a threshold level λ and its value at t = k is examined.
Detection is unambiguous and error-free if the signal is not corrupted by noise (e.g., no noise is added to the signal) and
if ζ(t) extends over the range −∞< t < ∞.
Detection of Signal in Noise
With additive noise n(t), the received waveform is x(t) = s(t) + n(t). At t = k
x(k) =

1 + n(k),
if a high bit was sent
n(k),
if a low bit was sent
and the descision rule becomes

x(k) > λ
the transmitted bit is assumed high
x(k) < λ
the transmitted bit is assumed low

Signals and Systems
117
1.2
1
0.8
0.6
0.4
0.2
Amplitude
0
–0.2
–0.4
–6
–4
–2
0
x0 = sinc(2pi*t)
Time (s)
2
4
6
sin(2πt)
2πt
(a) Plot of ζ(t) =
representing a high bit in a binary communication system.
Amplitude
–0.2
0
2
4
Representing binary number 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0 by rectangular pulses
Time (s)
(b) Plot of the binary sequence {0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0} with a rectangular pulse representing the high level.
6
8
10
0
0.2
0.4
0.6
0.8
1
1
0.8
0.6
0.4
Amplitude
0.2
0
–0.2
0
2
4
Time (s)
6
8
10
Representing binary number 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0
(c) Superimposed plots of ζ(t), ζ(t – 3), ζ(t – 5), ζ(t – 6), and ζ(t – 9) representing the sequence in (b).
FIGURE 1.60 Representation of a binary number by sinc signals. The signal at t = k is either zero or 1.

118
CHAPTER 1
Introduction to Signals
1
0.8
0.6
0.4
Amplitude
0.2
0
–0.2
–0.4
0
2
4
Time (s)
x = sinc(2*pi*t) + sinc[2*pi*(t – 3)] + sinc[2*pi*(t – 5)] + sinc[2*pi*(t – 6)] + sinc[2*pi*(t – 9)]
6
8
10
(d) The signal s(t) = z(t) + z(t – 3) + z(t – 5) + z(t – 6) + z(t – 9) representing the sequence in (b).
FIGURE 1.60 (Continued)
Under this rule, a high bit may be diagnosed as a low (to be called a miss) or a low bit may be diagnosed as a high (to be
called a false alarm). To compute error rates, we assume that the noise has a random value equally likely from −1 to 1 volt
and independent from neighboring values. Mathematically, n(t) is a random variable (R.V.) with uniform probability
distribution between −1 and 1 volt and zero correlation between neighboring values: p(n) = 0.5, −1 < n < 1 [see
Figure 1.61(a)]. For a low bit, x(k) = n(k); x(k) is an R.V. with the same probability distribution function as noise.
Then the probability of a false alarm is P(x > λ) = 0.5(1 −λ), where P indicates “the probability of.” For a high bit,
x(k) = 1 + n(k); x(k) is an R.V. with a uniform probability distribution function between 0 and 2 [see Figure 1.61(b)].
Then the probability of a false alarm is P(x > λ) = 0.5(2 −λ). From Figure 1.61(a) and (b) we can readily deduce that
for 0 < λ < 1.
Probability of detection ≡Pd = 1 −0.5λ
Probability of false alarm ≡Pf = 0.5(1 −λ)
The choice of threshold level follows some optimization criteria; for example, minimizing a cost function such as c(λ) =
1 −pd + αp f where α > 0 is the relative cost of a false alarm compared to a miss. In the present case, pm = 1 −pd and
p f are given in Figure 1.61(c) and (d).
Simulation
To simulate the project, proceed as follows:
(i) Generate a binary sequence z(k) of length N in which the high and low bits occur randomly and equally likely.
(ii) Obtain s(t) from z(k).
(iii) Generate a random sequence n(t) with values between −1 and 1 with uniform probability.
(iv) Obtain x(t) = s(t) + n(t) and x(k) (with k an integer).
(v) Pass x(k) through a level detector λ to obtain the binary sequence y(k) such that y(k) =

1,
x(k) ≥λ
0,
x(k) < λ . Do
this for −1 < λ < 2 in steps of size 0.2 and plot y(k).
(vi) For each λ compare y(k) with z(k) to ﬁnd the total number of misses (Nm) and false detections (N f ). (If N is
large enough, you may estimate 1 −pd and p f by Nm/N and N f /N, respectively.)

Signals and Systems
119
(a) Probability distribution of the amplitude of x(k) =
n(k) is uniform with a mean of 0 when the signal
is absent (low bit). A false detection occurs when
x(k) = n(k) > λ, in which case p f = 0.5(1 −λ).
In this ﬁgure, λ = 0.5 results in p f = 0.25 (shaded
area)
0.6
0.5
0.4
0.3
Probability
0.2
0
0.1
–0.1
–1.5
–1
–2
–0.5
0
0.5
pf
Amplitude
1
1.5
2
2.5
3
Probability density function of noise.
(b)Probabilitydistributionoftheamplitudeof x(k) =
s(k) + n(k) is uniform with a mean of 1 when the
signal is present (high bit). The signal is detected
when x(k) = s(k) + n(k) > λ, in which case
pd = 0.5(2 −λ). In this ﬁgure, λ = 0.5 results in
pd = 0.75 (shaded area)
0.6
0.5
0.4
0.3
Probability
0.2
0
0.1
–0.1
–1.5
–1
–2
–0.5
0
0.5
pf
Amplitude
1
1.5
2
2.5
3
Probability density function of signal + noise.
(c) Probability of a false alarm as a function of thresh-
old level. In the present case,
p f =

1,
λ < −1
0.5(1 −λ),
−1 < λ < 1
0,
λ > 1
1
0.8
0.6
Probability
0.4
0
0.2
–1.5
–1
–2
–0.5
0
0.5
Threshold λ
1
1.5
2
2.5
3
Probability of a false alarm as a function of λ.
(d) Probability of a miss as a function of threshold
level. In the present case,
pm = 1 −pd =

0,
λ < 0
0.5λ,
0 < λ < 2
1,
λ > 2
1
0.8
0.6
Probability
0.4
0
0.2
–1.5
–1
–2
–0.5
0
0.5
Threshold λ
1
1.5
2
2.5
3
Probability of a miss as a function of λ.
FIGURE 1.61
(vii) Let each miss cost 1 cent and each false detection α. The total cost is, therefore, C(α) = Nm + αN f . For each
λ ﬁnd c(α), α = 0.1, 0.2, 0.5, 1, 2, 5, 10. Plot the family of curves showing c(α, λ) versus λ with α as a
parameter. For each α determine the λ that produces the smallest cost.
Discussion and Conclusions
Discuss the advantages, potentials, and limitations of the modulation method studied in this project.

120
CHAPTER 1
Introduction to Signals
1.26
Project 2: Signals Stored as Computer
Data Files
In this project you will access the data used to produce Figures 1.1, 1.2, 1.4, 1.6, and 1.7 in this chapter. The Internet
sources for Figures 1.1, 1.2, and 1.4 are given along each ﬁgure. The data for Figures 1.6 and 1.7 are available on the
book’s website. Using a software package or a computer tool of your choice, retrieve the data and reproduce the above
ﬁgures. Then store them as ASCII ﬁles.

Chapter2
Sinusoids
Contents
Introduction and Summary
121
2.1
Sine and Cosine
122
2.2
Angles
123
2.3
Series Approximations
124
2.4
Trigonometric Identities and Relations
125
2.5
Sinusoidal Waveforms
126
2.6
Sine or Cosine?
128
2.7
Period and Frequency
128
2.8
Phasors
129
2.9
Lag and Lead
129
2.10
Time Shift and Phase Shift
130
2.11
Summing Phasors
130
2.12
Combination of Sinusoids
131
2.13
Combination of Periodic Signals
132
2.14
Representation of a Sum of Sinusoids
132
2.15
Power in a Sinusoid
133
2.16
One-Sided Line Spectrum
134
2.17
Complex Representation of Sinusoids and the Two-Sided Spectrum
136
2.18
Problems
137
2.19
Project: Trajectories, Wave Polarization, and Lissajous Patterns
151
Introduction and Summary
Sinusoidal functions form the cornerstone of the analysis of signals and systems. Many
signals, whether natural or synthetic, continuous or discrete, contain repetitive features. A
fewexamplesofnaturalphenomenathatexhibitrepetitivefeaturesinclude:dayandnight;
seasonal variations of weather attributes such as temperature, humidity, and rainfall; the
motion of heavenly objects (sun, moon, planets, and stars); ocean waves; the ﬂappings of
121

122
CHAPTER 2
Sinusoids
the wings of a hummingbird the galloping of a horse; the sounds of a person’s heartbeat,
breathing, blood pressure in the veins, and swinging of hands when walking; eruption of
geysers; radiation from a quasar; oscillations of a cesium clock; and the yearly number
of sunspots. Wheels, windmills, rotating machines, the pendulum of a grandfather clock,
the motion and sound of a pneumatic drill, the whistle of a train, the sound of a train’s
steam engine, the click-clack sound of a train on the rail, the sound of a car engine, the roar
of a jet engine, radio and radar signals, and AC power are some human-made examples.
At the root of many such phenomena we detect oscillatory components with one or
more frequencies. The building block that describes them is the sinusoidal function,
which is the main theme of this chapter. Sinusoids have been used for millennia to
build mathematical models of natural signals and systems. In ancient astronomy, the
sine of an angle became a prime tool in modeling cosmic systems. It was noticed that
the combination of sinusoids can account for some of their complicated motions. The
art of computing sinusoids became precise and reﬁned.
In the early part of the 18th century, mathematicians noted that a ﬁnite sum of
harmonically related sinusoids is itself a periodic function. In 1807, Fourier suggested
that a periodic function may be represented by an inﬁnite series of sinusoids, later
to be called its Fourier series expansion. The observation that a sinusoidal excitation
evokes a sinusoidal response from a class of systems called linear time-invariant (LTI)
has made sinusoids and the Fourier method of waveform analysis a very important tool
for linear systems analysis.
This chapter provides a basic set of deﬁnitions and operational tools used in work-
ing with sinusoids. Both time- and phasor-domain representations are used to illustrate
operations such as combinations of sinusoids, their power, and spectra. Examples draw
on familiar situations and contexts and provide an additional intuitive and qualitative
understanding of the subject. Simulations and computational solutions are included to
broaden the scope of the examples and to facilitate explorations of the concepts. Phase
shift and delay in passing through a ﬁlter are illustrated by employing sinusoids. Several
examples of approximating a periodic function are discussed through the solved prob-
lems. The project and some problems at the end of the chapter highlight the power of
the computational tools and the need for their use in working with signals.
2.1
Sine and Cosine
Refer to the right triangle of Figure 2.1(a). The sine of the angle θ is the ratio of the
opposite side to the hypotenuse.
sin θ = AB
AC
Similarly, the cosine of θ is the ratio of the neighboring side to the hypotenuse.
cos θ = C B
C A
Note that sin2 θ + cos2 θ = 1. If the hypotenuse is equal to one, the sine and cosine of
an angle θ are equal to the ordinate and abscissa, respectively, of point A, a point on the
unit circle located at the angle θ. (See Figure 2.1b.)

Signals and Systems
123
A
B
cos θ
θ
θ
C
–1
1
–1
1
sin θ
A
B
C
B
0
1 rad = 
57.29°
A
R
R
(c) One radian = 57.29°
(a)
sin θ = AB/AC
cos θ = CB/CA
(b) For a unit circle, 
sin θ = AB
cos θ = CB
FIGURE 2.1 (a) Deﬁnitions of sin θ = AB/AC and cos θ = C B/C A. (b) In a right triangle
with hypotenuse equal to one, sin θ = AB (the side opposite of the angle) and cos θ = C B (the
side adjacent to the angle). (c) One radian is the size of the angle whose circular arc is equal in
length to the radius of the circle.
2.2
Angles
Angles are expressed in degrees or radians. If the circumference of a circle is divided
into 360 equal arc segments, each segment will cover one degree. The degree symbol is
shown by a small circle on the upper-right side of the angle: θ◦. A right angle is 90◦.
Another unit is the radian, which stands for radial angle. One radian is the size of the
angle whose circular arc is equal in length to the radius of the circle. (See Figure 2.1c.)
Since the circumference of a circle is 2π R, it contains 2π radians. Accordingly, 1 rad =
360◦/(2π) = 360◦/(2 × 3.141593 · · ·) = 57.29577951◦.
Table 2.1 shows the sine and cosine of seven angles expressed in degrees and
radians.1
TABLE 2.1 Sine and Cosine of Seven Angles
θ in degrees
0◦
1◦
30◦
45◦
60◦
89◦
90◦
θ in radians
0
1
180π
π
6
π
4
π
3
89
180π
π
2
sin θ
0
0.01745 ≈
1
180π
1/2
√
2/2
√
3/2
0.99985 ≈1
1
cos θ
1
0.99985 ≈1
√
3/2
√
2/2
1/2
0.01745 ≈
1
180π
0
1Another unit is the grad which rhymes with Brad. Divide a right angle into 100 parts and each will be one
grad. The grad unit is almost obsolete and seldom used.

124
CHAPTER 2
Sinusoids
1/2
1
30°
2
3
180°
90°
270°
0°
45°
1
2
2
2
2
(a)
(b)
(c)
FIGURE 2.2 (a) In a right triangle, the side opposite of a 30◦angle is half the length of the
hypotenuse (sin 30◦= 0.5). (b) In an isosceles right triangle with the hypotenuse equal to one, the
two sides are sin 45◦= cos 45◦=
√
2/2 in length. (c) The circle is divided into four quadrants of
90◦each.
Remember: (1) In a right triangle, the side opposite of a 30◦angle is half the length
of the hypotenuse (Figure 2.2a). (2) In an isosceles right triangle with the hypotenuse
equal to one, the two sides are sin 45◦= cos 45◦=
√
2/2 in length (Figure 2.2b).
Reference and Direction
Sinusoids are used to model physical entities (such as electric ﬁelds) as functions of
time and space. As such, angles are algebraic quantities that can be positive or negative.
Therefore, in addition to specifying the unit, we need to determine a reference position
and a direction from which the angles on a circle are measured. The horizontal coordinate
axis in the Cartesian plane is the zero reference for the angle and the counterclockwise
direction on the circle is its positive direction. Using the above notations, the circle is
divided into four quadrants of 90◦(π/2 radians) each. (See Figure 2.2c.) Angles may be
measured and plotted using the graduated arc of a protractor.
Inverses of Trigonometric Functions
The inverse of x = sin θ is shown by θ = sin−1 x (also shown by θ = arc sin x, which
reads as arc sine). The inverse expression says that θ is the angle whose sine value is x.
Similar notations apply to the other trigonometric functions such as cosines and tangents.
An inverse function has multiple answers. For example, the answer to θ = sin−1 0.5 is
θ = 30◦or 150◦. To produce a unique answer, one needs to specify to which quadrant
the angle belongs.
2.3
Series Approximations
The sine and cosine may be approximated by their series expansions shown below.
sin θ = θ −θ3
3! + θ5
5! −θ7
7! + θ9
9! −· · ·
cos θ = 1 −θ2
2! + θ4
4! −θ6
6! + θ8
8! −· · ·

Signals and Systems
125
θ is in radians. For small angles (θ << 1 radian), the ﬁrst few terms of the sine series
are sufﬁcient to give an accurate estimate of sin θ. As an example,
sin 1◦=
 π
180

−1
3!
 π
180
3
+ 1
5!
 π
180
5
+ · · ·
= 0.017453293 −0.000005317 + 0.000000002 −· · ·
It is seen that the ﬁrst term in the series is quite capable of estimating the sum; that is,
sin θ ≈θ, for θ << 1, where θ is in radians.2
2.4
Trigonometric Identities and Relations
Some useful trigonometric relations are listed in Table 2.2. Also see Figure 2.3.
TABLE 2.2 Some Trigonometric Relationships
sin(−a) = −sin a
cos(−a) = cos a
sin(a + 90◦) = cos a
cos(a + 90◦) = −sin a
sin(a −90◦) = −cos a
cos(a −90◦) = sin a
sin(90◦−a) = cos a
cos(90◦−a) = sin a
If a + b = 90◦, cos a = sin b, sin a = cos b
sin(a + 180◦) = −sin a
cos(a + 180◦) = −cos a
sin(a + 360◦) = sin a
cos(a + 360◦) = cos a
sin(a + b) = sin a cos b + cos a sin b
cos(a + b) = cos a cos b −sin a sin b
sin a + sin b = 2 sin 1
2(a + b) cos 1
2(a −b)
cos a + cos b = 2 cos 1
2(a + b) cos 1
2(a −b)
sin a sin b = 1
2 cos(a −b) −1
2 cos(a + b)
cos a cos b = 1
2 cos(a + b) + 1
2 cos(a −b)
sin a cos b = 1
2 sin(a + b) + 1
2 sin(a −b)
cos a sin b = 1
2 sin(a + b) −1
2 sin(a −b)
sin 2a = 2 sin a cos a
cos 2a = cos2 a −sin2 a = 2 cos2 a −1 = 1 −2 sin2 a
sin2 a = (1 −cos 2a)/2
cos2 a = (1 + cos 2a)/2
sin 3a = 3 sin a −4 sin3 a
cos 3a = 4 cos3 a −3 cos a
See problem 2.7 for sin(na) and cos(na).
A sin a + B cos a = C sin(a + θ) = C cos(a −φ)
C =
√
A2 + B2, θ = tan−1(B/A), φ = tan−1(A/B)
2An iterative algorithm by Al-Kasi (died H.G. 832, AD 1428–1429) computes sin 1◦to any desired accuracy.
See A. Aaboe, “Al-Kasi’s Iteration Method for Determination of Sin 1◦,” Scripta Mathematica, 20 (1954),
pp. 24–29.

126
CHAPTER 2
Sinusoids
A
B
1
1
1
C
O
α
–α
H
G
F
E
A
B
α + 90°
α + 180°
α – 90°
α
C
D
1
A
Unit circle
C
B
O
α
β
FIGURE 2.3 Visualization of some useful trigonometric relationships.
(a) symmetry
(b) 90◦and 180◦phase differences
(c) α + β = 90◦

sin(−α) = −sin(α)
cos(−α) = cos(α)

sin(α + 90◦) = cos α
cos(α + 90◦) = −sin α

sin(α + 180◦) = −sin α
cos(α + 180◦) = −cos α

sin(α) = cos(β)
cos(α) = sin(β)
2.5
Sinusoidal Waveforms
Look at the uniform rotary motion of a ceiling fan. The actual trajectory of the tip of a
blade is a circle. This trajectory is projected on a plane perpendicular to the direction of
view and perceived as the motion. If you view the fan from below at the center (a direction
perpendicular to the plane of motion), each blade appears to move along a circular path
(a)
(b)
(c)
FIGURE 2.4 The trajectory of the tip of a blade of a uniformly rotating ceiling fan viewed from
three directions.
(a) Viewed from below at the center (perpendicular to the plane of motion), the trajectory is a
circular path traversed at a constant angular speed. (b) Viewed from below and off-center (at a
slant), the trajectory appears as an ellipse. (c) Viewed from the side (a direction in the plane of
motion), the tip appears to go back and forth on a straight line with its position proportional to the
sine of the angle of rotation. The perceived trajectory is the projection of the circular rotation on
the axis and is a sinusoidal function.

Signals and Systems
127
at a constant speed (Figure 2.4a). If you view it at a slant, the motion appears to follow an
ellipse (Figure 2.4b). Finally, if you view the fan from the side (a direction in the plane of
motion), the tip appears to move from one end of a segment of a straight line to the other
end with a nonuniform speed (Figure 2.4c). The position of the tip along this path is
proportional to the sine of the angle of rotation θ. It is modeled by a sinusoidal function.
A sinusoid is a function proportional to the sine of its argument. One way to visualize
the sinusoidal function sin θ is to project on the vertical axis the trajectory of the tip of
a unity vector with angle θ as θ changes. Such a function is shown in Figure 2.5(a).
Similarly, projection on the horizontal axis generates cos θ. (See Figure 2.5b.)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−1 −0.8 −0.6 −0.4 −0.2
0
0.2
0.4
0.6
0.8
1
–1 –0.8 –0.6 –0.4 –0.2
0
0.2
0.4
0.6
0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Time
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
FIGURE 2.5 Projections of a vector on the x and y axes generate the sinusoidal functions sine and cosine. The sinusoidal
function v(t) = V cos(ωt + θ), therefore, may be interpreted as the projection of the rotating vector V ̸ (ωt + θ) on the
x-axis. V is the length of the vector and θ is its angle with the x-axis at t = 0.

128
CHAPTER 2
Sinusoids
If the vector rotates with the uniform angular speed of ω radians per second, then,
after t seconds, the angle traversed by it is θ = ωt and the sinusoid becomes a function
of time. If the radius is V and the angle begins from zero, then the sinusoid is v(t) =
V sin ωt. If at t = 0 the vector is at the angle θ0, then v(t) = V sin(ωt + θ0).
2.6
Sine or Cosine?
A sine function may equivalently be expressed in cosine form (and vice versa) as listed
in Table 2.2:
sin θ = cos(θ −π/2)
cos θ = sin(θ + π/2)
Therefore, v(t) = V0 sin(ωt + θ0) = V0 cos(ωt + θ1), where θ1 = (θ0 −π/2). In this
book, sine and cosine functions are both referred to as sinusoids. But when a sinusoid is
represented by a phasor (to be discussed in section 2.8), the cosine form of the function
is used.
2.7
Period and Frequency
The function v(t) is periodic with period T if
v(t) = v(t + T ) for all t
The sinusoidal function v(t) = V sin(ωt + θ) is clearly periodic with period T = 2π/ω
because
v(t + 2π/ω) = V sin(ωt + 2π + θ) = V sin(ωt + θ) = v(t)
If it takes T seconds for the periodic function v(t) to go through one full cycle of change,
then the repetition rate is 1/T cycles per second. This quantity is called the frequency
f = 1/T and its unit is the Hertz (shown by Hz), where 1 Hz = 1 cycle per second. The
angular frequency ω, period T , and frequency f are related by
ω = 2π f = 2π
T ,
f = 1
T = ω
2π ,
T = 1
f = 2π
ω
Decimal multiples and submultiples of Hz are also used. For example,
mHz
for
millihertz = 10−3 Hz
kHz
for
kilohertz = 103 Hz
MHz
for
megahertz = 106 Hz
GHz
for
gigahertz = 109 Hz
THz
for
terahertz = 1012 Hz
The frequency spectrum of electromagnetic waves ranges from extremely low frequen-
cies (ELF, 3–30 Hz) in the radio range to gamma rays (up to 1023 Hz).

Signals and Systems
129
2.8
Phasors
A sinusoid V sin(ωt + θ) or V cos(ωt + θ) is completely speciﬁed by its amplitude
V , phase θ, and angular frequency ω (or f = ω/2π). The amplitude and phase of a
sinusoid may be combined into a two-dimensional (or complex) number V called the
complex amplitude, which can be expressed in polar form as V= V e jθ = V ̸ θ, or in
Cartesian form as V= V cos θ + jV sin θ. The complex amplitude may be shown by a
vector or point in the complex plane (Figure 2.6). The real and imaginary parts of V are
the abscissa and the ordinate of the tip of the vector, respectively. The quantity V is also
called a phasor. In representing a sinusoid by a phasor, the cosine form V cos(ωt + θ)
is normally meant.
Imaginary part
Real part
V sin θ
V
V cos θ
V = Ve jθ = V(cos θ + j sin θ)
θ
0
FIGURE 2.6 Phasor V = V̸ θ (shown by a vector) is the complex representation of the sinusoid
v(t) = V cos(ωt + θ).
2.9
Lag and Lead
Consider two vectors V1 and V2 with phase angles θ1 and θ2, respectively (Figure 2.7).
The phase difference between V1 and V2 is θ0 = θ1 −θ2. It is said that V2 lags V1 by θ0.
The word lag assumes more physical meaning if the angles vary with time. For example,
if both change uniformly with an angular velocity ω, then the phase lag θ0 translates
into a time lag of τ0 = θ0/ω seconds. If θ0 is negative, then V2 leads V1 by τ0 = θ0/ω
seconds. More on this subject in the next section.
V1
V2
0
θ1
θ1 – θ2
θ2
FIGURE 2.7 Lead and lag. Phasor V1 leads phasor V2 by θ0 = θ1 −θ2. Equivalently, V2 lags V1
by θ0.

130
CHAPTER 2
Sinusoids
2.10
Time Shift and Phase Shift
If a function f (t) is delayed by τ seconds, one obtains f (t −τ). The delay operation
shifts the graph of f (t) to the right by the amount τ. Likewise, an advance by τ seconds
produces f (t + τ) and shifts the graph of f (t) to the left by the amount τ.
In the case of sinusoidal functions, time shift translates into phase shift. A delay
produces a phase lag and an advance produces a phase lead. Delay the function cos(ωt)
by τ seconds to get cosω(t −τ) = cos(ωt −θ), where θ = ωτ. The graph of cos(ωt)
is shifted to the right by τ, which corresponds to a phase lag of θ = ωτ = 2π f τ. See
Figure2.8(a).Similarly,atimeadvancebyτ secondsmeansashiftedgraphtotheleft.See
Figure2.8(b).Ingeneral,atimeshiftofτ correspondstoaphaseshiftofθ = ωτ = 2π f τ.
For a given phase shift, the higher the frequency, the smaller the time shift.
0
0.1
0.2
0.3
0.4
0.5
(a)
(b)
0.6
0.7
0.8
0.9
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
cos(2πt)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
cos(2πt)
cos(2πt + π/4)
cos(2πt − π/4) 
FIGURE 2.8 (a) Phase lag. A 125-msec delay in cos 2πt produces cos 2π(t −0.125) = cos(2πt −π/4), shown by the
dashed curve, creating a 45◦phase lag. (b) Phase lead. A 125-msec advance in cos 2πt produces cos 2π(t + 0.125) =
cos(2πt + π/4), shown by the dashed curve, creating a 45◦phase lead.
2.11
Summing Phasors
Let V1= V1̸ θ1 and V2= V2̸ θ2 be two phasors. Their sum is
V = V1 + V2= V ̸ θ
where V and θ are found from
V cos θ = V1 cos θ1 + V2 cos θ2
V sin θ = V1 sin θ1 + V2 sin θ2
See Figure 2.9.

Signals and Systems
131
V = V1 + V2
V2
0
V1
θ
θ2
θ1
FIGURE 2.9 Sum of two phasors V = V1 + V2.
Example
2.1
Use the phasor notation to ﬁnd the amplitude and phase of v(t) = 2 cos(ωt + 25◦) −
3 sin(ωt −30◦).
Solution
Let
v1 = 2 cos(ωt + 25◦)
⇒V1 = 2̸ 25◦
v2 = −3 sin(ωt −30◦) = 3 cos(ωt + 60◦) ⇒V2 = 3̸ 60◦
V = V1 + V2 = 2̸ 25◦+ 3̸ 60◦
= 3.3126 + j3.4433 = 4.7781̸ 46.1◦
⇒v(t) = 4.7781 cos(ωt + 46.1◦)
2.12
Combination of Sinusoids
The sum of two sinusoids with frequencies f1 and f2 is periodic only if the ratio of the two
frequencies is a rational number; that is, if f1/f2 = k1/k2, where k1 and k2 are integers.
Thecommondivisor f foundfrom f1 = k1 f and f2 = k2 f isthencalledthefundamental
frequency and f1 and f2 are its harmonics. For example, v(t) = cos(πt) + cos(5πt)
is periodic because it contains the fundamental frequency 0.5 Hz and its harmonic
at 2.5 Hz. In contrast, v(t) = cos(πt) + cos t is not periodic. The same is true of
v(t) = 2 cos(πt) cos t = cos[(π −1)t] + cos[(π + 1)t]. We conclude that a ﬁnite sum
of sinusoidal waveforms that are harmonics of a fundamental frequency is a periodic
waveform with period equal to the inverse of the fundamental frequency.
Beat Frequency
Consider the sum of two sinusoids v(t) = cos(ω1t) + cos(ω2t), where ω1 and ω2 are
not harmonics of a fundamental frequency and, therefore, v(t) is not periodic. However,
v(t) may be written as
v(t) = cos(ω1t) + cos(ω2t) = 2 cos(ω0t) cos(ωdt)
ω0 = ω2 + ω1
2
ωd = ω2 −ω1
2

132
CHAPTER 2
Sinusoids
v(t) is a sinusoid at frequency ω0 whose amplitude is modulated by a sinusoid at fre-
quency ωd. If ω1 and ω2 are very close, the amplitude of v varies slowly. ωd is then called
the beat frequency.
2.13
Combination of Periodic Signals
The observations regarding a sum of two sinusoids can be generalized to the sum of
two periodic functions v1(t) and v2(t) with periods T1 and T2, respectively. The sum
v1(t) + v2(t) is periodic if the ratio T1/T2 is a rational number. The period of the sum is
then T = n1T1 = n2T2, where n1 and n2 are integers. In such a case, v1(t), v2(t), and
their sum contain harmonics of the frequency f = 1/T .
2.14
Representation of a Sum of Sinusoids
A waveform, which is a sum of sinusoids, whether periodic or not, is completely speciﬁed
bythecomplexamplitude(magnitudeandphase)ofitscomponentsandtheirfrequencies.
These may be given in tabular or graphical form.
Example
2.2
The waveform v(t) = 1 + 3 cos(πt) + cos(5πt + 30◦) + 0.5 cos(20t + 90◦) may
be represented by the table below. The waveform is a sum of periodic functions and
the table contains a ﬁnite number of sinusoids. However, the waveform v(t) is itself
not periodic because the elements of the table are not harmonics of a fundamental
frequency.
f in Hz
Amplitude ̸ Angle
0
1̸ 0◦
0.5
3̸ 0◦
2.5
1̸ 30◦
10/π
0.5̸ 90◦
Example
2.3
The waveform v(t) = 1 + 3 cos(πt) + cos(5πt + 30◦) + 0.5 cos(20πt + 90◦) is
represented by the table below.
f in Hz
Amplitude ̸ Angle
0
1̸ 0◦
0.5
3̸ 0◦
2.5
1̸ 30◦
10
0.5̸ 90◦
The table contains a ﬁnite number of harmonics of 0.5 Hz. The waveform, therefore,
is periodic.

Signals and Systems
133
2.15
Power in a Sinusoid
The instantaneous power in a waveform v(t) is deﬁned by p(t) = v2(t). The average of
p(t) over the duration 0 to T is
P =< p(t) >=< v2(t) >= 1
T
 T
0
v2(t)dt
The rms value of v(t) over the duration 0 to T is
√
P. For a sinusoidal signal with
amplitude V , the average power and rms value (shown by Vrms) deﬁned over its period
T are
P = 1
T
 T
0
V 2 cos2(ωt + θ)dt = V 2
2
Vrms =
√
P = V
√
2
The average power and rms values are normally deﬁned over one period of the sinusoid
and, therefore, are independent of its frequency and phase angle.
The average power in a waveform that is made of harmonics is the sum of the
average powers in the harmonics, because the integral of cross terms in the expression
for instantaneous power is zero.
Example
2.4
Find the average power in v(t) = V1 cos(nωt) + V2 cos(mωt), where m and n are
integers.
P = < v2(t) >=< V 2
1 cos2(nωt) + V 2
2 cos2(mωt) + 2V1V2 cos(nωt) cos(mωt) >
= V 2
1 < cos2(nωt) > +V 2
2 < cos2(mωt) > +2V1V2 < cos(nωt) cos(mωt) >
= V 2
1
2 + V 2
2
2
This example shows the superposition of power and is valid if a common period can
be found for all components. The following is a counterexample to the concept of
universal application of superposition of power.
Example
2.5
Find the average power in v(t) = v1(t) + v2(t), where v1(t) = V1 cos(ωt) and
v2(t) = V2 cos(
√
2ωt).
P = < v2(t) >=< v2
1(t) > + < v2
2(t) > +2 < v1(t)v2(t) >
= V 2
1
2 + V 2
2
2 + 2V1V2 < cos(ωt) cos(
√
2ωt) >

134
CHAPTER 2
Sinusoids
But
2 cos(ωt) cos(
√
2ωt) = cos(
√
2 + 1)ωt + cos(
√
2 −1)ωt
These two components do not have a common period and the average of their sum is
not zero for any time interval. Therefore, superposition of power does not apply in
this case.
2.16
One-Sided Line Spectrum
The table or graph showing the amplitude of a sinusoid becomes an especially useful tool
when its components are harmonics, in which case it is called a one-sided line spectum.
The spectrum is discrete and contains a ﬁnite or inﬁnite number of lines.
Example
2.6
Plot the one-sided line spectrum of
x(t) =
∞

n>0, n odd
1
n cos(100nπt + θn)
Computethepowerinthefundamentalfrequencyandthenextﬁvenonzeroharmonics.
Solution
The spectrum is given by 1
n , n = 1, 3, 5, . . .. See Figure 2.10. The ﬁrst seven nonzero
amplitudes are
1, 1
3, 1
5, 1
7, 1
9, 1
11, 1
13
The power in the above harmonics is
1
2

1 + 1
9 + 1
25 + 1
49 + 1
81 +
1
121 +
1
169

≈0.599
0
2
4
6
8
10
12
14
0
0.2
0.4
0.6
0.8
1
1.2
FIGURE 2.10 The one-sided line spectrum of x(t) which is a sum of sinusoids
x(t) =
13

n>0, n odd
1
n cos(100nπt + θn)

Signals and Systems
135
The line spectrum is insensitive to the phase of the harmonics or their time shift and
does not possess all the information needed to reconstruct the waveform. Two com-
pletely different waveforms may have identical spectra. Nevertheless, the spectrum
is a useful characteristic of the waveform because it conveys information about the
density of its average power.
Example
2.7
Consider the even periodic squarewave signal with period T , peak-to-peak value A,
and zero DC level. One period of the signal is described by
v(t) =







−A
2
−T
2 < t < −T
4
A
2
−T
4 < t < T
4
−A
2
T
4 < t < T
2
and v(t) = v(t + T )
As you will see in Chapter 7 on the Fourier series, the above square wave may be
represented by an inﬁnite series of the following form:
v(t) = 2A
π

cos ωt −1
3 cos 3ωt + 1
5 cos 5ωt −1
7 cos 7ωt + · · ·

Compute the percentage of average power in the fundamental component and in the
next ﬁve nonzero harmonics.
Solution
The one-sided line spectrum of v(t) is given by 2A/(πn), n odd. The total power in
v(t) is A2/4. The power in the n-th harmonic is 2A2/(πn)2. The ratio of the power
in each harmonic to the total power is
2A2/(πn)2
A2/4
=
8
(πn)2 ,
n odd
The percentages are shown in Table 2.3, which may be called the relative power
spectral density of the signal.
TABLE 2.3 Relative Power Spectral Density of a Square Wave
n
1
3
5
7
9
11
Higher harmonics
Percentage power
81.06
9.01
3.24
1.65
1.00
0.67
3.34
In summary, out of every 1,000 watts in the waveform, about 810 watts come from
the fundamental component, 156 watts from the next ﬁve components, and 34 watts from
the remaining higher components.

136
CHAPTER 2
Sinusoids
2.17
Complex Representation of Sinusoids
and the Two-Sided Spectrum
In section 2.8 we introduced the phasor V as a vector drawn from the origin to the tip at
point M in the xy plane. The vector is expressed in the rectangular coordinate system
by x = ρ cos θ and y = ρ sin θ, where ρ is the length of the vector and θ is its angle
with the abscissa. The x and y coordinates may be written in a combined form as
V ≡ρ cos θ + jρ sin θ ≡ρe jθ
where j is the imaginary number j2 = −1. Of special interest are the following identities:
e jθ = cos θ + j sin θ
cos θ = RE

e jθ
= e jθ + e−jθ
2
sin θ = IM

e jθ
= e jθ −e−jθ
2 j
A sinusoid, therefore, may be represented by the sum of two complex conjugate expo-
nential functions of time:
V cos(ωt + θ) = V
2 e jθe jωt + V
2 e−jθe−jωt
In the above representation, the term e jωt speciﬁes the time dependency of the sinusoid
and V
2 e jθ (called the complex amplitude) determines its magnitude and phase. The two-
sided spectrum of the sinusoid represents the complex amplitude and its conjugate versus
frequency as shown in Figure 2.11(a). The two-sided spectrum of a signal made of several
sinusoids is the sum of the individual spectra. See Example 2.8. Unlike the one-sided line
spectrum, the two-sided spectrum includes the phases of the harmonics and possesses
all the information needed to reconstruct the waveform.
Hz
–f
f
0
(a)
(b)
1.5 ∠ –π/3
1 ∠ –π/4
1.5 ∠ π/3
1 ∠ π/4
Hz
–10
10
10
π
10
π
–
V
2 ∠–θ0
V
2 ∠θ0
FIGURE 2.11 (a) Two-sided spectrum of V cos(2π f t + θ). (b) Two-sided spectrum of
2 cos(20πt + π/4) + 3 cos(20t + π/3).
Example
2.8
Plot the two-sided spectrum of v(t) = 2 cos(20πt + π/4) + 3 cos(20t + π/3).
Solution
See Figure 2.11(b).

Signals and Systems
137
2.18
Problems
Solved Problems
1. Determine the phase relationship between x1(t) = cos(t + 10◦) and x2(t) = cos(t −30◦) by choosing the correct
answer:
a. x1 leads x2 by 10◦
b. x1 leads x2 by 40◦
c. x2 lags x1 by 30◦
d. none of the above
Solution
The phase of x1(t) with reference to x2(t) is 10◦−(−30◦) = 40◦. The correct answer is b.
2. For each time function given below determine if it is periodic or aperiodic, and specify the period if the function is
periodic.
a. cos(3t + 45◦) + sin(
√
2t −120◦)
b. cos(5t) + cos π(t −0.5)
c. cos(πt + 10◦) −cos(2πt + π/3)
d. sin(6.28t −2π/3) + cos 0.2(t −0.5)
Solution
A combination of two periodic functions with periods T1 and T2 is periodic if the ratio of the two periods is a rational
number, T1
T2 = k1
k2 , where k1 and k1 are integers. In that case, the common period is T = k2T1 = k1T2. Expressed in
terms of ω for sinusoids, the periodicity condition becomes ω1
ω2 = k2
k1 , with k1 and k1 integers.
a. ω1
ω2 =
3
√
2 ̸= k2
k1 , aperiodic
b. ω1
ω2 = 5
π ̸= k2
k1 , aperiodic
c. ω1
ω2 =
π
2π = 1
2, periodic (period = 2)
d. ω1
ω2 = 6.28
0.2 = 157
5 , periodic (period = 50π)
3. Repeat problem 2 for the time functions given below.
a. cos(3t + 45◦) sin(
√
2t −120◦)
b. cos(5t) cos π(t −0.5)
c. cos(πt + 10◦) cos(2πt + π/3)
d. sin(6.28t −2π/3) cos 0.2(t −0.5)
Solution
a. Aperiodic, b. Aperiodic, c. Periodic (period = 2), d. Periodic (period = 25π).
4. Consider the sum of two sinusoids having the same frequency but different phases x(t) = cos ωt + cos(ωt + θ),
where 0 ≤θ ≤2π is the phase.
a. Express it in the form of x(t) = A cos(ωt + φ), with A ≥0 and −π ≤φ ≤π. Determine A and φ as functions
of θ and obtain their values for θ = kπ/4, 0 ≤k ≤8; k is an integer. Plot A and φ versus θ.
b. Repeat part a, allowing A to assume any value and 0 ≤φ ≤π. In problem 5 you will be asked to write a Matlab
program and execute it to plot the magnitude and phase of x(t) as functions of θ for 0 < θ < 2π.
Solution
a. Expand cos(ωt + θ) in terms of sin ωt and cos ωt. Collect terms and convert the sum into a single cosine form
A cos(2π f t + φ) as shown below.
x(t) = cos ωt + cos(ωt + θ) = cos ωt + cos ωt cos θ −sin ωt sin θ
= (1 + cos θ) cos ωt −sin θ sin ωt = A cos(ωt + φ),
where
A =

(1 + cos θ)2 + sin2 θ =

2(1 + cos θ) and φ = tan−1

sin θ
1 + cos θ

.

138
CHAPTER 2
Sinusoids
Values of A and φ for θ = kπ/4, 0 ≤k ≤8, are given in the table below.
θ
0
π/4
π/2
3π/4
π
5π/4
3π/2
7π/4
2π
A
2
1.848
√
2
0.765
0
0.765
√
2
1.848
2
φ
0
22.5◦
45◦
67.5◦
0
−67.5◦
−45◦
−22.5◦
0
b. x(t) = (1 + cos θ) cos ωt −sin θ sin ωt = 2 cos2(θ/2) cos ωt −sin θ sin ωt = 2 cos(θ/2) cos(ωt + θ/2). The
amplitude of x(t) is 2 cos(θ/2), which can be a positive or negative number. See the table below.
θ
0
π/4
π/2
3π/4
π
5π/4
3π/2
7π/4
2π
A
2
1.848
√
2
0.765
0
−0.765 −
√
2 −1.848
−2
φ
0
22.5◦
45◦
67.5◦
90◦
112.5◦
135◦
157.5◦
180◦
5. The following Matlab program plots x(t) = cos(2πt) + cos(2πt + θ) for 11 values of θ from 0 to 2π.
theta=linspace(0,2*pi,11);
t=linspace(0,1,500);
for j=1:11;
for i=1:500;
x(i,j)=cos(2*pi*t(i))+cos(2*pi*t(i)+theta(j));
end
end
for j=1:11;
plot(t,x,'LineWidth',2)
axis([0 1 -2.2 2.2]);
end
xlabel('Time(s)');
ylabel('x(t)');
title('Plot of x(t)=cos(2\pit)+cos(2\pit+\theta) for 11 values of \theta
from 0 to 2\pi.')
grid
Execute the program and examine the plots. Verify that the plots are in agreement with the results developed in
problem 4.
6. a. Convert the sum of two sinusoids with different frequencies x(t) = cos ω1t + cos ω2t into a product of two
sinusoids.
b. Given ω2 = (1 + k)ω1, ﬁnd and plot x(t) for k = 1/2, 1/4, 1/16.
c. Interpret the plots in light of the approach of problem 4.
Solution
a. Using the identity
cos a + cos b = 2 cos

a −b
2

cos

a + b
2

we ﬁnd cos ω1t + cos ω2t = 2 cos(ωdt) cos(ωst), where ωd = (ω1 −ω2)/2 and ωs = (ω1 + ω2)/2.

Signals and Systems
139
b. Using the result of part a we ﬁnd
x(t) = 2 cos(ωdt) cos(ωst), where ωd = (k/2)ω1 and ωs = (1 + k/2)ω1.
See Figure 2.12.
0 0.5 1 1.5 2 2.5 3 3.5 4
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time (s)
(a) x1(t) = cos(2πt) + cos(3πt)
x1(t)
0
1
2
3
4
5
6
7
8
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
(b) x2(t) = cos(2πt) + cos(2.5πt)
Time (s)
x2(t)
0
5
10
15
20
25
30
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time (s)
(c) x3(t) = cos(2πt) + cos(17πt/8)
x3(t)
FIGURE 2.12 Plot of x(t) = cos ω1t + cos(1 + k)ω1t for three values of k.
c. View x(t) as the sum of cos(ω1t)+cos(ω1t +θ) = 2 cos(θ/2) cos(ωt +θ/2), where θ = kω1t. x(t) is a sinusoid
whose amplitude depends on θ, which in the present case is a time-varying quantity. This is reﬂected in the
envelopes of the plots of Figure 2.12. When the phase angle is an odd multiple of π, the amplitude becomes
zero. In Figure 2.12 with ω = 2π, the zero amplitudes occur at tM = M/(2k), where M is an odd number. In
Figure 2.12(a), k = 1/2 results in tM = 1, 3, . . .. In Figure 2.12(b), k = 1/2 results in tM = 2, 6, . . ., and in
Figure 2.12(c), k = 1/16 results in tM = 8, 24, . . ..
7. Find cos nθ and sin nθ in terms of cos θ and sin θ. Then express cos nθ in terms of cos θ only.
Solution
Start with
e jθ = x + jy, where x = cos θ, y = sin θ, and x2 + y2 = 1
Raise it to the power of n
e jnθ = (x + jy)n
But
e jnθ = cos nθ + j sin nθ
Therefore,
cos nθ = RE{(x + jy)n} and sin nθ = IM{(x + jy)n}
Apply the binomial expansion
(a + b)n = an + nan−1b + n(n −1)
2!
an−2b2 + n(n −1)(n −2)
3!
an−3b3 + · · · · · · + n(n −1)
2!
a2bn−2 + nabn−1 + bn
to ﬁnd the real and imaginary parts of (x + jy)n and set them equal to cos nθ and sin nθ, respectively. Then use
x2 + y2 = 1 to simplify. Here are some examples:
(x + jy)2 = (x2 −y2) + j2xy,
cos 2θ = 2x2 −1,
sin 2θ = 2xy
(x + jy)3 = (x3 −3xy2) + j(3x2y −y3),
cos 3θ = 4x3 −3x,
sin 3θ = 3y −4y3
(x + jy)4 = (x4 −6x2y2 + y4) + j(4x3y −4xy3), cos 4θ = 8x4 −8x2 + 1, sin 4θ = 4x3y −4xy3
In summary, cos 2θ = 2 cos2 θ −1
sin 2θ = 2 sin θ cos θ
cos 3θ = 4 cos3 θ −3 cos θ
sin 3θ = 3 sin θ −4 sin3 θ
cos 4θ = 8 cos4 θ −8 cos2 θ + 1
sin 4θ = 4 sin θ cos θ −4 sin3 θ cos θ

140
CHAPTER 2
Sinusoids
8. Phase shift and delay. The input signal to a device (to be called a ﬁlter) is a sinusoid vi(t) = V cos ωt. The signal
at the output terminal of the ﬁlter is vo(t) = V cos(ωt −θ) for all V and ω. The ﬁlter doesn’t change the frequency
of the signal and has a unity amplitude gain but introduces a phase lag θ. The transformation is shown below.
vi(t) = V cos ωt
⇒vo(t) = V cos(ωt −θ)
Given vi(t) = (1 + 2 cos ω0t) cos ωct, where ω0 = 107 rad/s and ωc = 108 rad/s, ﬁnd vo(t) for the following three
cases:
a. Linear phase θ = 10−9ω.
b. Constant phase θ = 10−1.
c. Linear phase with a constant bias θ = (10−9ω + 10−1).
θ and ω are in radians and radians per second, respectively.
Solution
Assuming ωl = ωc −ω0 = 0.9 × 108 and ωh = ωc + ω0 = 1.1 × 108, the input signal may be expanded into its
sinusoidal components:
vi(t) = cos ωlt + cos ωht + cos ωct
The output is
vo(t) = cos(ωlt −θl) + cos(ωht −θh) + cos(ωct −θc)
a. In the case of a linear phase ﬁlter, θl = 10−9ωl, θh = 10−9ωh, and θc = 10−9ωc. The output is
vo(t) = cos(ωlt −10−9ωl) + cos(ωht −10−9ωh) + cos(ωct −10−9ωc)
= cos ωl(t −10−9) + cos ωh(t −10−9) + cos ωc(t −10−9)
= vi(t −10−9)
Because of the linear phase property, the output is a delayed version of the input. The delay is equal to the slope
of the phase lag versus the ω curve, which is equal to 10−9 seconds.
b. In the case of a ﬁlter with constant phase, θl = θh = θc = 0.1.
vo(t) = cos(ωlt −0.1) + cos(ωht −0.1) + cos(ωct −0.1)
= cos ωl(t −1.1 × 10−9) + cos ωh(t −0.9 × 10−9) + cos ωc(t −10−9)
Because of the constant phase, the time delay depends on the frequency. Higher frequencies pass through the
ﬁlter faster than lower frequencies, producing a distortion. The time delays are given below.
ω in rad/s
Delay in sec
ωℓ= 0.9 × 108
1.11 × 10−9
ωc = 108
10−9
ωh = 1.1 × 108
0.91 × 10−9
c. In the case of a linear phase with a constant bias we have
vo(t) = cos(ωlt −θℓ) + cos(ωht −θh) + cos(ωct −θc)

Signals and Systems
141
where
θl = 10−9ωl + 0.1 = 0.19
θh = 10−9ωh + 0.1 = 0.21
θc = 10−9ωc + 0.1 = 0.2
Substituting for θ we get
vo(t) = cos(ωlt −0.19) + cos(ωht −0.21) + cos(ωct −0.2)
= cos ωl(t −2.11 × 10−9) + cos ωh(t −1.9 × 10−9) + cos ωc(t −2 × 10−9)
As in case b. the three frequency components in vo(t) undergo three different delays as given below.
ω in rad/s
Delay in sec
ωℓ= 0.9 × 108
2.11 × 10−9
ωc = 108
2 × 10−9
ωh = 1.1 × 108
1.9 × 10−9
In summary,
a. In a linear phase ﬁlter all input frequencies are delayed by the same amount, resulting in y(t) = x(t −τ).
b. In a ﬁlter with constant phase, higher frequencies are delayed by a lesser amount, thus creating a distortion.
c. In a biased linear phase ﬁlter, individual frequencies experience different delays but share a common group delay.
By way of simpliﬁcation, one may consider that the total signal is delayed by an average of 2 × 10−9 seconds.
However, in this case the nonuniformity in delays doesn’t produce destructive distortion. By combining the low-
and high-frequency components in vo(t), we ﬁnd
vo(t) = 
1 + 2 cos ω0(t −11 × 10−9)
cos ωc(t −2 × 10−9)
Note that the amplitude 1 + 2 cos ω0t is delayed by 11 nanoseconds, becoming 1 + 2 cos ω0(t −11 × 10−9), but
experiences no distortion. The carrier cos ωct is delayed by 2 nanoseconds and becomes cos ωc(t −2 × 10−9). This
phenomenon is generalized in the next problem.
9. A simple case of group delay. In section 2.10 we illustrated the relationship between phase shift and time shift for
a single sinusoid, and problem 8 examined time delays experienced by a group of sinusoids in passing through a
ﬁlter. In this problem we formulate a simple case of group delay. A more general treatment of group delay is found
in Chapter 9.
Consider a linear ﬁlter that has unity gain within the passband ωc ± 
ω and introduces a phase lag θ in a
sinusoidal signal passing through it. In other words,
vi(t) = V cos(ωt) ⇒vo(t) = V cos(ωt −θ)
for all V and (ωc −
ω) < ω < (ωc + 
ω). Within the above band the phase lag is θ = θc + τ0(ω −ωc). Let the
input to the ﬁlter be an amplitude-modulated waveform
vi(t) = [1 + 2A cos(ω0t)] cos(ωct)
where cos(ωct) is the carrier and 1 + 2A cos(ω0t) is the modulating signal with ω0 < 
ω. Find the output vo(t).

142
CHAPTER 2
Sinusoids
Solution
Expand the input signal into its sinusoidal components:
vi(t) = A cos(ωℓt) + A cos(ωht) + cos(ωct)
where
ωℓ= ωc −ω0
ωh = ωc + ω0
The input signal, therefore, falls within the passband. The output is
vo(t) = A cos(ωℓt −θℓ) + A cos(ωht −θh) + cos(ωct −θc)
where
θℓ= θc + τ0(ωℓ−ωc) = θc −τ0ω0
θh = θc + τ0(ωh −ωc) = θc + τ0ω0
Combining the ﬁrst two terms of vo(t) and noting that
ωc = ωh + ωℓ
2
ω0 = ωh −ωℓ
2
we get
vo(t) = 2A cos

ω0t −θh −θℓ
2

cos

ωct −θh + θℓ
2

+ cos(ωct −θc)
Deﬁne τc = θc/ωc. Then
θh + θℓ= 2θc = 2τcωc
θh −θℓ= 2θ0 = 2τ0ω0
Therefore,
vo(t) = 2A cos(ω0t −θ0) cos(ωct −θc) + cos(ωct −θc)
= 2A cos ω0(t −τ0) cos ωc(t −τc) + cos(ωct −τc)
= [1 + 2A cos ω0(t −τ0)] cos ωc(t −τc)
The modulating signal and the carrier are delayed by τ0 and τc, respectively. In general, the modulating signal may
contain many frequency components. As long as they remain within the band 2
ω, all will be delayed by the same
amount τ0, which makes the modulating signal undistorted. The carrier cos ωct is delayed by τc, a different amount.
This, however, doesn’t introduce any distortion in the modulating signal. As a group, the total signal is delayed by
an average of τc.
10. Let x(t) be the sum of a ﬁnite set of sinusoids in which the frequency and amplitude of the components are known
and speciﬁed by the two vectors f and a, respectively.
x(t) =
N

k=1
ai sin(2π fit)

Signals and Systems
143
Write a Matlab program to sample x(t) for 0 ≤t ≤T at the rate of fs. Choose T = 10 seconds, fs = 10 kHz, and
f
5
25
50
75
100
125
150
250
275
300
325
350
375
400
a
1
1
1
1
1
1
1
1
1
1
1
1
1
1
then, compute the average power by integrating Px = 1
T

T
0
x(t)2dt and compare with Ptheory = 1
2
N

i=1
a2
i .
Solution
See the program below.
clear
f=[5 25 50 75 100 125 150 250 275 300 325 350 375 400];
a=[1 1
1
1
1
1
1
1
1
1
1
1
1
1
];
t=0:.001:10;
M=length(t); N=length(f);
for i=1:N
for j=1:M
q(i,j)=a(i)*sin(2*pi*f(i)*t(j));
end;
end;
x=sum(q,1);
% Constructing x(t)
Px=sum(x.*x)/M;
Pt=sum(v1.*v1)/2
% Finding power in x(t)
The average power is Px = 6.9993 [obtained by averaging the integral of x2(t)]. The expected theoretical value is
Ptheory = 7 (obtained from the amplitude vector a), both in watts.
11. Pass the signal x(t) of problem 10 through a device that changes the magnitude and phase of a sinusoidal input, but
not its frequency. An input sin(ωt) produces the output H sin(ωt + θ), where H and θ (called the gain and phase
of the ﬁlter, respectively) depend on the frequency of the sinusoid. Assume θ = 0, but that H decreases from unity
(at DC) to zero (at high frequencies) as given below.3
H( f ) =
1

1 + ( f/150)10 , where f is in Hz.
Call the output of the ﬁlter y(t) and compute its average power. Finally, by examining H( f ), suggest a method to
predict an approximate value for Py without integration.
Solution
Continue the program in problem 10 with the following:
% Finding the vector H
for i=1:N;
H=1./sqrt(1+(f/150).√10)
end;
b=a.*H;
3This is called an ideal 5th-order lowpass Butterworth ﬁlter with cutoff frequency at 150 Hz.

144
CHAPTER 2
Sinusoids
for i=1:N
for j=1:M
r(i,j)=b(i)*sin(2*pi*f(i)*t(j));
end;
end;
y=sum(r,1);
The result is Py = 3.1762. By approximation,
H( f ) =
 1,
f < 150
0.707,
f = 150
0,
f > 150
,

H 2 = 6.5,
and
Py ≈

6.5
14

Px = 3.25.
12. An ampliﬁer with a 1- output resistance feeds an 8- loudspeaker. See Figure 2.13(a). The signal put out by the
voltage source is
v1(t) = 9[sin(100t + 45◦) + cos(10,000t)]
a. Find the average power in the loudspeaker.
b. Place a 100-µF capacitor in parallel with the loudspeaker as shown in Figure 2.13(b). Find the average power in
the loudspeaker and compare it with the result in part a.
Solution
a. The average power delivered by a sinusoidal voltage to a resistor is V 2
max/(2R), where Vmax is the amplitude of
the sinusoid. By voltage division, the voltage at the terminals of the loudspeaker is
v2(t) = 8 [sin(100t + 45◦) + cos(10,000t)]
The average power in the loudspeaker is, therefore,
P = 82/16 + 82/16 = 4 + 4 = 8 W
b. With the capacitor in place, the magnitude of the frequency response is
|V2/V1| =
R
√
1 + R2C2ω2
where R = 8/9  is the Thevenin equivalent resistance of the circuit seen by the capacitor. See Figure 2.13(c).
Substituting for the two ω components in v1(t) and applying superposition of power we ﬁnd the power in the
loudspeaker to be
P = 64
16 × 64
81

1
1 + 64
81 10−8 (100)2 +
1
1 + 64
81 10−8 (10,000)2

= 3.16 + 1.76 = 4.92 W

Signals and Systems
145
amplifier
loudspeaker
(a)
amplifier
loudspeaker
Thevenin equivalent
(b)
(c)
v1(t)
8 Ω
1 Ω
v2(t)
+
–
+
–
1 Ω
v2(t)
v1(t)
8 Ω
100 µF
+
–
+
–
Ω
A
B
8
9
8
9 v1(t)
v2(t)
+
–
+
–
100 µF
FIGURE 2.13 (a) An ampliﬁer with a 1- output resistance feeds an 8- loudspeaker. (b) A 100-µF capacitor in
parallel with the loudspeaker reduces its power at high frequencies. (c) Thevenin’s equivalent of (b).
Chapter Problems
13. The four corners of a quadrilateral in the xy plane are labeled in clockwise direction as ABC D. It is given that
AC = 1, ABC and ADC are right angles, and BD is perpendicular to AC. The intersection of AC and BD is
labeled O and the angle B AC called α. Show that OC = sin2 α and BD = sin 2α.
14. The expression A cos(2π f t + θ), where A > 0 is the amplitude, f is the frequency (in Hz), and −π < θ < π is
the phase in radians, represents a sinusoidal signal in cosine form. Determine the amplitude, frequency, and phase
of the following signals when represented in the above form.
a. 3 cos(3t + 45◦)
b. 2 sin(
√
2t −120◦)
c. −4 cos 5t
d. 2 cos π(t −0.5)
e. 2.5 cos(πt + 10◦)
f. −cos(2πt + π/3)
g. −3 sin(6.28t −2π/3)
h. 2 cos 0.2(t −1)
15. Sketch and label the signals given in problem 14.
Problems 16--21
Identify the correct frequency of the given sinusoids.
16. The frequency of sin 106πt is
a. 2 MHz
b. 2 MHz
c. 500 kHz
d. 250 kHz
e. none of the above
17. The frequency of cos 106t is most nearly
a. 318 kHz
b. 159 kHz
c. 159 Hz
d. 16 Hz
e. none of the above
18. The frequency of sin(πt/6 + 3) is
a. 1/6 Hz
b. 1/12 Hz
c. 1/3 Hz
d. 2/π Hz
e. none of the above
19. The frequency of sin(t/6) + 3 is
a. π/3 Hz
b. 1/(12π) Hz
c. 1/12 Hz
d. π/3 Hz
e. none of the above
20. The frequency of cos(3000πt + θ) is
a. 6 kHz
b. 3 kHz
c. 1.5 kHz
d. 300 Hz
e. none of the above

146
CHAPTER 2
Sinusoids
21. The frequency of cos 103t is most nearly
a. 159 kHz
b. 159 Hz
c. 80 Hz
d. 50 Hz
e. none of the above
Problems 22--31
Identify the correct period of the given signals.
22. The period of cos 106πt is
a. 1 ms
b. 2 µs
c. 1 µs
d. 1 ns
e. none of the above
23. The period of 3 sin 106t is most nearly
a. 6 ms
b. 6 µs
c. 1 µs
d. 6 ns
e. 1 ns
24. The period of 2 + cos(2 × 105πt) is
a. 2 ms
b. 20 µs
c. 10 µs
d. 2 ns
e. none of the above
25. The period of sin 20πt + 4 cos 2πt is
a. 1 s
b. 500 ms
c. 50 ms
d. 500 µs
e. none of the above
26. The period of sin 5πt + cos 3πt is
a. 5 s
b. 2.5 s
c. 2 s
d. 1.2 s
e. none of the above
27. The period of sin t + cos 2t is
a. 3π/2 s
b. π s
c. 1 s
d. 1 ms
e. none of the above
28. The period of sin 5t + cos 3t is
a. 5π s
b. 2π s
c. (1/5 + 1/3)2π s
d. 3π/5 s
e. none of the above
29. The period of sin 4t + 3 cos 2t is
a. 2π s
b. π s
c. π/2 s
d. π/3 s
e. none of the above
30. The period of sin 200t + sin 201t is
a. 2.1π s
b. 2π s
c. 1.99π s
d. π s
e. none of the above
31. The period of sin 200πt + sin 201πt is
a. 2.2 s
b. 2.1 s
c. 2 s
d. 1.9 s
e. none of the above

Signals and Systems
147
Problems 32--37
Identify the correct phase θ of the following sinusoids
when expressed in the form of cos(ωt + θ).
32. The phase of cos(πt + 30◦) is
a. 30 degrees
b. 3π radians
c. 3 radians
d. 60 degrees
e. none of the above
33. The phase of sin(2πt −30◦) is
a. −30◦
b. 90◦
c. −120◦
d. 120◦
e. none of the above
34. The phase of cos(πt + 1) is
a. 30 degrees
b. 3π radians
c. 1 radian
d. 60 degrees
e. none of the above
35. The phase of sin(πt + 1) is most nearly
a. −1 radian
b. −23 degrees
c. 1 radian
d. 23 radians
e. −33 degrees
36. The phase of cos π(t −0.5) is
a. 90 degrees
b. −π/2 radians
c. −π radians
d. −5 radians
e. none of the above
37. The phase of cos 500π(t + 10−3) is
a. 30 degrees
b. 0.5π radian
c. 0.5 radian
d. 2 radians
e. none of the above
Problems 38--45
Determine the correct phase relationship between the si-
nusoids given below.
38. x1 = cos(t + 10◦), x2 = cos(t −30◦)
a. x1 leads x2 by 10◦
b. x1 lags x2 by 130◦
c. x1 leads x2 by 40◦
d. x2 lags x1 by 130◦
e. none of the above
39. x1 = cos(t + 30◦), x2 = cos(t + 55◦)
a. x1 lags x2 by 65◦
b. x1 lags x2 by 25◦
c. x2 lags x1 by 55◦
d. x1 leads x2 by 85◦
e. none of the above
40. x1 = cos(t + 10◦), x2 = sin(t −30◦)
a. x1 leads x2 by 10◦
b. x1 leads x2 by 40◦
c. x2 lags x1 by 130◦
d. x1 lags x1 by 130◦
e. none of the above
41. x1 = cos(t + 30◦), x2 = sin(t + 55◦)
a. x1 leads x2 by 65◦
b. x1 lags x2 by 85◦
c. x1 lags x2 by 25◦
d. x2 leads x1 by 35◦
e. none of the above
42. x1 = cos t, x2 = cos(t −5 ms)
a. x1 leads x2 by 1 degree
b. x1 leads x2 by 9/(2π) degrees
c. x1 lags x2 by 1 radian
d. x1 and x2 are almost in phase
e. none of the above
43. x1 = cos t, x2 = cos(t −1)
a. x1 leads x2 by 55 degrees
b. x1 leads x2 by 1 radian
c. x1 leads x2 by 1 degree
d. x1 and x2 are almost in phase
e. x2 lags x1 by 0.1 radian

148
CHAPTER 2
Sinusoids
44. x1 = cos 104t, x2 = cos 104(t −10µs)
a. x1 lags x2 by 10 degrees
b. x1 and x2 are almost in phase
c. x1 leads x2 by 5 degrees
d. x2 lags x1 by 10 degrees
e. x2 lags x1 by 0.1 radian
45. x1 = cos 105t, x2 = cos 106(t + 1µs)
a. x1 leads x2 by 1 degree
b. x1 leads x2 by 1 radian
c. x1 and x2 are almost in phase
d. x1 lags x2 by 1 radian
e. none of the above
46. Use phasors to convert each time function given below into the form A cos(2π f t + θ).
a. 3 cos(3t + 45◦) + 2 sin(3t −120◦)
b. −4 cos(5t) + 2 cos 5(t −0.5)
c. 2.5 cos(πt + 10◦) −cos(πt + π/3)
d. −3 sin(6.28t −2π/3) + 2 cos 6.28(t −0.5)
47. For each time function given below determine if it is periodic or aperiodic, and specify its period if periodic.
a. cos 5t + cos πt
b. cos(5t) + cos 3.1416t
c. cos(πt + 10◦) −cos(2πt + π/3)
d. sin(6.28t −2π/3) + cos 0.2(t −1)
e. sin 5t + cos(3t + θ)
f. sin t + sin 2πt
g. sin πt + sin 3.141592t
h. cos(1.14t + θ) + sin 3.141592t
48. For each time function given below determine if it is periodic or aperiodic, and specify its period if periodic.
a. cos 2πt + cos 6.28t
b. cos 2πt + cos 6.2816t
c. cos 2πt + cos 6.28159t
d. cos 6.2816t + cos 6.28159t
e. cos
√
2t + cos 1.41t
f. cos 1.4142t + cos 1.41t
49. For each time function given below determine if it is periodic, aperiodic, or whether more information is needed.
Specify its period if periodic.
a. cos 3.14t + sin 2πt
b. cos 3.14t + sin 3.1416t
c. cos πt −sin(100πt + π/3)
d. sin(6.28t −π/3) + cos(t −1)
50. A sinusoidal voltage v(t) has a frequency of 100 Hz, a zero DC value, and a peak value of 13 V which it reaches at
t = 1 ms. Write its equation as a function of time in cosine form and plot it for 0 < t < 10 msec.
51. For the following cases determine the phase lag of x2(t) with reference to x1(t).
a. x1(t) = cos(t + 30◦) and x2(t) = cos(t −10◦)
b. x1(t) = sin(t + 30◦) and x2(t) = cos(t −10◦)
c. x1(t) = cos(t + 30◦) and x2(t) = sin(t −10◦)
d. x1(t) = sin(t + 30◦) and x2(t) = sin(t −10◦)
52. Consider the sum of two sinusoids having the same frequency but different phases x(t) = cos ωt + cos(ωt + θ),
where 0 ≤θ ≤2π is the phase. Problem 4 expressed it as x(t) = A cos(ωt +φ) and obtained the A and phi values
for θ = kπ/4, 0 ≤k ≤8, k an integer. Write a Matlab program to plot x(t) for ω = 2π and the above 9 values of
θ. As in problem 4 consider the following two conditions for A and φ:
a. A ≥0, and −π ≤φ ≤π.
b. A any value, and 0 ≤φ ≤π.
53. The following three measurements are made off a sinusoidal signal x(t) = X0 cos(2π f t + θ), where the frequency
is assumed to be 1 MHz.
t
0
0.1 µs
0.2 µs
x(t)
2.1213
0.4693
−1.3620
a. Verify the above frequency assumption.
b. Find the amplitude and phase of x(t).

Signals and Systems
149
c. Knowing the frequency, what is the minimum number of samples from which the amplitude may be computed?
Show how this minimum sample number is obtained.
54. For each set of measurements given in Table 2.4, model the signal by x(t) = A cos(2π f t + θ) (i.e., ﬁnd the
amplitude, frequency, and phase of the sinusoid).
TABLE 2.4 (Problem 54)
t
0
0.1 µs
0.2 µs
a.
x1(t)
1.7321
1.8437
1.9263
b.
x2(t)
1.6209
0.7615
−0.1725
c.
x3(t)
0.1732
0.1889
0.1979
d.
x4(t)
1.4494
2.0148
2.5306
e.
x5(t)
1.4330
1.3831
1.3201
f.
x6(t)
4.2092
4.9875
5.0184
g.
x7(t)
−0.2499
−0.3516
−0.4500
55. Write the mathematical expression A cos(2π f t + θ) for the sinusoidal signals whose measurements are recorded
in Table 2.5 and then sketch them.
TABLE 2.5 (Problem 55)
Signal
Period
xmax
xmin
x(0)
Slope at t = 0
a.
x1(t)
10 ms
3
−1
2.7321
+
b.
x2(t)
6.67 µs
3.5
0.9
2.85
−
c.
x3(t)
8.33 µs
4
0
−0.3823
−
d.
x4(t)
12.5 ms
−1
−4
−1.0511
+
e.
x5(t)
10 ms
2.5
0.5
2.366
+
f.
x6(t)
1334 µs
−2.5
−7.5
−3.1823
−
g.
x7(t)
4 ms
1
−5
−1.0729
+
56. A sinusoidal voltage v(t) has a frequency of 200 Hz, a zero DC value, and a peak value of 13 V, which it reaches
at t = 0.5 ms. Write its equation as a function of time in a cosine form.
57. A low-frequency periodic signal s(t) is modeled by a DC value added to the sum of the ﬁrst N harmonics of a
fundamental frequency fs (in Hz) as given below:
s(t) = C0 + 1
2
N

n=1
Cn cos(2πnfst)
The highest frequency in s(t) is f0 = N fs. The signal s(t) modulates a sinusoidal carrier cos(2π fct),
fc > f0.
The modulated waveform is x(t) = s(t) cos(2π fct). Let fs = 100 kHz, f0 = 1 MHz, and fc = 100 MHz. The
modulated waveform x(t) is passed through an ideal bandpass ﬁlter with unity amplitude gain within the band of
99 MHz to 101 MHz and zero gain outside it. The phase lag introduced by the ﬁlter in a sinusoidal input at frequency
f within the above band is θ = 0.2π 
1 + 10−8 f 
radian. Find the output of the ﬁlter y(t) and discuss possible
distortions.
58. Use the phasor notation to show that V1 cos(ωt + θ1) + V2 cos(ωt + θ2) = V cos(ωt + θ), where
θ = tan−1

V1 sin θ1 + V2 sin θ2
V1 cos θ1 + V2 cos θ2

and V =

V 2
1 + V 2
2 + 2V1V2 cos(θ1 −θ2)

150
CHAPTER 2
Sinusoids
59. Shift the periodic squarewave signal of Example 2.7 by a constant value and show that the shifted waveform may
be represented by an inﬁnite series of the following form:
v(t) =
∞

n=1
an cos

2πnt
T
+ θn

, where |an| = 2A
πn
and n odd.
Show that the shift does not affect conclusions regarding power distribution obtained in Example 2.7.
60. The unit-ramp function x(t) = t can be approximated during −T/2 < t < T/2 by the ﬁnite series
y(t) = T
π
N

n=1
sin

2πnt
T

One measure of approximation error is
E = 1
T

−T
2
−T
2
|x(t) −y(t)|2dt.
Write a program to generate x(t) and y(t), plot them, and compute the error as deﬁned above. Run the program for
N = 1, . . . , 10 and plot E versus N.
61. Motion of a free electron in a sinusoidal electric ﬁeld. An electron has a negative electric charge of e =
1.602 × 10−19 C and a mass of m = 9.109 × 10−31 kg. When placed in an electric ﬁeld of ﬁeld strength E, it
experiences a force of e × E. Determine the span of the motion of an electron in vaccuum when subjected to an
electric ﬁeld E = 10−6 cos(2π f t) V/m at frequencies of (a) 60 Hz, (b) 1 kHz, (c) 1 MHz, and (d) 1 GHz.
62. The following Matlab program is written to sweep from left to right in the xy plane. In each sweep it plots a
sinusoid, then moves down an incremental value, similar to the motion of the electron beam in a cathod ray tube or
the operation of the recording element in a seismograph.
t=[0:0.001:1];
hold on
for k=1:30,
x=sin(2*pi*k*t)+10-2*k-0.3;
axis([0 1 -50 10]);
plot(t,x);
xlabel('Time (s)'); ylabel('harmonics'); title(' harmonics of 1 Hz');
grid;
end
hold off
a. Execute the program and examine the plot to verify that it agrees with expectation.
b. In successive steps replace the fourth line in the program with a new command line from the following list and
note if the resulting plot agrees with your expectation.
x=sin(2*pi*k*t)+2*k+0.3;
axis([0 1 0 50]);
x=sin(2*pi*k*t)+50-2*k-0.3;
axis([0 1 0 50]);
x=sin(2*pi*k*t)+60-2*k-0.5;
axis([0 1 0 60]);
x=sin(2*pi*k*t)+90-2*k-1;
axis([0 1 30 90]);
x=sin(2*pi*k*t)+90-4*k-1;
y=cos(2*pi*k*t)+90-4*k-3;
axis([0 1 30 90]);
plot(t,x,t,y);
Explore an alternative set of variables that enhance the wavy appearance of the two-dimensional plot.

Signals and Systems
151
2.19
Project: Trajectories, Wave Polarization,
and Lissajous Patterns
Purpose
To investigate the trajectories of the sinusoidal motion of a point in the xy plane and obtain parameters of the motion from
the patterns of the trajectories.
Introduction and Summary
The motion of a point M in the xy plane can be stated as a time-varying vector drawn from the origin to its tip at point
M. The motion is described by two equations that specify the Cartesian coordinates of M as functions of time. The path
traversed by the tip of the vector, called its trajectory, may be found by eliminating the variable t from those equations.
Some parameters of the motion (such as the amplitude, phase, and frequency) may be deduced from the trajectory. In this
project you will generate and examine several classes of trajectories where the x and y coordinate values vary sinusoidally
with time. The project contains six sections.
i. x(t) and y(t) have the same frequency.
ii. x(t) and y(t) have slightly different frequencies.
iii. The frequencies of x(t) and y(t) are harmonics of a principle frequency.
iv. The frequencies of x(t) and y(t) are not harmonics of a principle frequency.
v. The effect of the sampling rate.
vi. Implementation through an electric circuit.
The present project may be carried out by mathematical simulation or in real time by physical oscillators. Examples
from both are included.
Section I.
x(t) and y(t) have the same frequency. Consider the time-varying vector E in the xy plane drawn from the
origin to point M whose projections on the x and y axes are given by
 x = Ex cos ωt
y = Ey cos(ωt + θ)
Depending on the phase difference and amplitude ratio, three types of trajectories are observed: linear (zero phase or π),
circular (equal amplitudes with ±π/2 phase), and elliptical (all other values).
a. Linear trajectory. For θ = 0 or π, the trajectory is a straight line. See Figure 2.14(a). Show that y = ±
Ey
Ex x.
Rotate the xy coordinate system by an angle γ in the counterclockwise direction to have a new coordinate system
αβ. Show that the relationship between the two coordinate systems is
α = x cos γ + y sin γ
β = −x sin γ + y cos γ
Find the equation of the trajectory in the new coordinate system. Determine the appropriate γ value to represent E
by a one-dimensional vector that oscillates in time along the α-axis only.
b. Circular trajectory. For Ey = Ex = E and θ = π/2 or −π/2, the motion has a circular trajectory. See
Figure 2.14(b). Show that x2 + y2 = E2 and determine the direction of motion for the trajectory.
c. Elliptical trajectory. For the general case, the tip of the vector moves along an elliptical trajectory. Show that

x
Ex
2
+

y
Ey
2
−2xy
Ex Ey
cos θ = sin2 θ

152
CHAPTER 2
Sinusoids
−1 −0.8 −0.6 −0.4 −0.2
0
0.2 0.4 0.6 0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
B 
A 
−1 −0.8 −0.6 −0.4 −0.2
0
(a) Linear trajectory
0.2 0.4 0.6 0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−1 −0.8 −0.6 −0.4 −0.2
0
0.2 0.4 0.6
0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
x = Ex cos ωt
y = ±Ey cos ωt
(b) Circular trajectory
x = Ex cos ωt
y = ±Ey sin ωt
(c) Elliptical trajectory
x = Ex cos ωt
y = ±Ey cos(ωt + π /4)
FIGURE 2.14 Trajectories of the motion of the tip of a rotating vector in the xy plane. The trajectories have the form
of simple Lissajous patterns.
and determine the direction of motion for the trajectory. Show that the phase angle θ can be found from
sin θ = ±(B/A)
where A and B are as shown on Figure 2.14(c). Rotate the xy coordinate system by an appropriate angle to align
the x-axis along the major axis of the ellipse. Determine the rotation angle. Write the equation for the trajectory in
the new coordinate system.

Signals and Systems
153
Simulation by Computer
Run the Matlab code given below to generate a linear trajectory.
f=1; w=2*pi*f; T=1/f; N=1; a=1; b=1; theta=0;
% Motion parameters.
t=linspace(0,N*T,100*N*T); x=a*cos(w*t); y=b*cos(w*t+theta); plot(x,y)
% Trajectory.
Change the parameters of the motion and the variables in the above code to explore how each one may or may not change
the shape of the trajectory. From the plots of the trajectories obtain the amplitudes of the horizontal and vertical motions
and the phase difference between them. Compare with the values used in the simulation.
Parallels with Electromagnetic Wave Polarization
The electric ﬁeld vector E in an electromagnetic plane wave is a time-varying vector E that lies in the plane that is
perpendicular to the direction of propagation. It has two components; namely, in the x and y directions. In the case of
sinusoidal time variation, the electric ﬁeld is an E vector with x and y components (each of which vary sinusoidally with
time) as follows:
 x = Ex cos ωt
y = Ey cos(ωt + θ)
This is the same vector we discussed at the beginning of this section with three possible tip trajectories. Each trajectory
is associated with one type of wave polarization. The electromagnetic wave, therefore, is said to be polarized as any of
the above types. In addition, the motion of the tip of the electric ﬁeld vector can be in the clockwise or counterclockwise
directions, labeled left or right, circular or elliptical.
Section II.
x(t) and y(t) have slightly different frequencies.

x(t) = a cos ω1t
y(t) = b cos ω2t
With ω1 and ω2 approximately the same (but not exactly equal), the difference in frequencies will appear as a time-varying
phase difference, resulting in a trajectory that slowly moves between the above three patterns. Construct an example where

x(t) = cos 2πt
y(t) = b cos 2.1πt
(corresponding to f1 = 1 Hz and f2 = 1.05 Hz, respectively). Modify the Matlab program given in section I to plot the
Lissajous patterns for this example, allowing the plots to be generated for (a) 2 seconds, (b) 3 seconds, (c) 8 seconds,
and (d) 150 seconds. Determine the time needed for a full cycle in each plot. Explore the effect for f2 = (1 + k) f1, with
k = 0.2 , 0.1, and 0.01.
Section III.
The frequencies of x(t) and y(t) are harmonics of a principle frequency. In this case, more complex
patterns are generated whose shapes and parameters are associated with the ratio of the two frequencies. Four examples
are shown in Figure 2.15 for x = cos ωt and four different variations of y(t).
Using Matlab, plot trajectories of y versus x with x = cos(at) and y = cos(bt), for a/b = 3 and 3/5. Repeat for
x = cos(at) and y = sin(bt). In each case eliminate t between y and x to obtain the equation relating them together and
verify its representation by a plot obtained through Matlab. Determine the number of crossings of a horizontal line and
a vertical line and relate them to the ratio a/b. Suggest a method to measure the frequency of a sinusoidal signal from
Lissajous patterns.

154
CHAPTER 2
Sinusoids
(a) y = cos 2ωt
(b) y = cos 3ωt
(c) y = sin 2ωt
(d) y = sin 3ωt
−1 −0.8−0.6−0.4−0.2
0
0.2 0.4 0.6 0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−1 −0.8−0.6−0.4−0.2
0
0.2 0.4 0.6 0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−1 −0.8−0.6−0.4−0.2
0
0.2 0.4 0.6 0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−1 −0.8−0.6−0.4−0.2
0
0.2 0.4 0.6 0.8
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
FIGURE 2.15 Four Lissajous patterns with x = cos ωt and various y(t).
Section IV.
The frequencies of x(t) and y(t) are not harmonics of a principle frequency. In theory, the motion is not
periodic and it takes T = ∞for it to repeat. In practice (e.g., in simulation by Matlab or in a real-time experiment using
two physical oscillators), the Lissajous pattern will eventually repeat itself. Run the following Matlab code, observe the
trend, and compare it with the observations in section II. Repeat the procedure after replacing cos(πt) by cos(3.1t).
N=4; %Repeat for N=2, 8, 20, 50
t=linspace(0,N*pi,800);
x=cos(t);
y=cos(pi*t); plot(x,y);
Section V.
Effect of low sampling rate. In plotting a trajectory, the x and y coordinates need to be sampled sufﬁciently
fast. Otherwise the plot will exhibit the artifacts caused by a low number of samples. This effect is shown by the following
two examples.

Signals and Systems
155
a. Generate three examples of Lissajous patterns derived from the same motion but with three different sampling
rates. You may use the following code for this purpose.
N=2; % Repeat for N=20 and 50.
t=linspace(0,N*pi,100);
x= cos(2*t); y=sin(3*t); plot(y,x)
b. For the following set of samples (N) and time (T )
i. N = 20,
T = 100, 50, 25
ii. N = 50,
T = 10, 20, 25
iii. N = 100,
T = 40, 50
iv. N = 200,
T = 2
run the Matlab code given below and explain trends in the plots.
t=linspace(0,T,N);
x=cos(2*pi*t); y=cos(2*pi*t+pi/4); plot(x,y)
Section VI.
Implementation through an electric circuit. An oscilloscope whose horizontal and vertical deﬂections are
controlled by the signals x(t) and y(t), respectively, eliminates t between them and displays the xy motion trajectory. For
this purpose, an ordinary oscilloscope can be used if set in the X deﬂection mode.
a. Start with the situation described in section I of this project. Conﬁgure the circuit of Figure 2.16(a) with R = 1 k
and C = 0.1 µF. Set up the function generator to provide a 2-volt peak-to-peak sinusoidal voltage signal v1 at
1590 Hz and connect it to the RC circuit as shown, and also to the horizontal axis of the scope and set it in X
deﬂection mode. Connect the capacitor voltage v2 to the vertical axis of the scope. The relationship between v1
and v2 can be readily found using terminal characteristics of R and C, and Kirchhoff’s current and voltage laws.
The result is
v1(t) = V1 cos ωt, v2(t) = V2 cos(ωt + θ), V2 =
1
√
1 + R2C2ω2 V1,
and θ = −tan−1(RCω)
Show that at the above settings,
v1(t) = cos 10,000t and v2(t) = 0.707 cos

10,000t −π
4

The elliptic pattern shown in Figure 2.16(a) should appear on the scope. Find the equation of the trajectory on the
screen as predicted from theory. Compute the phase angle between v1 and v2 from
sin θ = ±(B/A)
where A and B are shown on the ellipse. The phase angle is expected to be 45◦. The amplitudes of the horizontal
and vertical signals may be changed through the horizontal and vertical gains of the scope. The phase angle
between the horizontal and vertical signals can be changed by changing the frequency of the signal generator.
Explore the effect of the above parameters on the shape of the trajectory.
To obtain a linear trajectory, replace the capacitor in the circuit by a resistor. The circuit and resulting trajectory
are shown in Figure 2.16(b). Relate the slope of the trajectory to the resistor values and the horizontal and vertical
gains of the oscilloscope.
To obtain a circular trajectory use the circuit conﬁguration of Figure 2.16(c), which contains an isolation trans-
former.
b. Continue with real-time implementations of the situations described in sections II, III, IV, and V. For that purpose
you will employ two sinusoidal signal generators directly connected to the horizontal and vertical channels.

156
CHAPTER 2
Sinusoids
(a) RC circuit
(b) RR circuit
(c) RC circuit and an isolation transformer
Sample Rate = 2.00MSa/s
1 200
?
/
mv
2 500
XY
B
A
1
/
mv
Main
Delayed
Roll
XY
Vernier
Time Ref
Center
Elliptic trajectory
?
Sample Rate = 50.0MSa/s
Main
Delayed
Roll
XY
Vernier
Linear trajectory
Time Ref
Center
1 500 /
mv
2 100
XY
1
/
mv
?
Sample Rate = 50.0MSa/s
Main
Delayed
Roll
XY
Vernier
Time Ref
Center
Circular trajectory
1 500 /
mv
2 500
XY
1
/
mv
XY
1
/
v1
R
C
v2
+
–
+
–
v1
R1
R2
v2
+
–
+
–
+
+
–
–
v1
R
C
v2
FIGURE 2.16 Three circuits for generating x and y coordinate signals and the resulting trajectories captured off an
oscilloscope.
Conclusions
Describe your overall conclusions from the project. What applications may it have? Where can one draw the line that
distinguishes the results obtained by the digital approach (using the computer) from the analog approach (using the funtion
generator and oscilloscope)?

Chapter3
Systems, Linearity,
and Time Invariance
Contents
Introduction and Summary
157
3.1
Formulation of Equations
159
3.2
Classiﬁcations of Systems
160
3.3
Causality
162
3.4
Linearity, Time Invariance, and LTI Systems
162
3.5
Derivative and Integral Properties of LTI Systems
166
3.6
Examples from Electric Circuits
166
3.7
Examples from Other Fields
172
3.8
Response of LTI Systems to Impulse and Step Inputs
175
3.9
Response of LTI Systems to Exponential Inputs
176
3.10
Response of LTI Systems to Sinusoids
178
3.11
Use of Superposition and Other Properties of LTI Systems
179
3.12
LTI Systems and Fourier Analysis
181
3.13
Analysis and Solution Methods for LTI Systems
182
3.14
Complex Systems
183
3.15
Neuronal Systems
184
3.16
Problems
188
3.17
Project: Open-Loop Control
200
Introduction and Summary
In its common usage, the word system signiﬁes a combination or collection of intercon-
nected elements or parts performing certain functions or producing certain effects. The
elements may be physical (as in electrical or mechanical systems), models of nonphysical
157

158
CHAPTER 3
Systems, Linearity, and Time Invariance
entities(asincomputational,economic,societal,environmental,andecologicalsystems),
or a combination of physical and nonphysical models (as in digital communication sys-
tems, data communication systems, and systems of computer networks).
Systems and subsystems may be analyzed at various levels and from different view-
points. One may analyze the operation of a system at the component level. As an example,
we may analyze an ampliﬁer circuit using Kirchhoff’s current and voltage laws, along
with the characteristics of elements such as energy sources, resistors, inductors, capaci-
tors, switches, transistors, op-amps, and the like. At this level, the focus is more on the
internal structure of the ampliﬁer, for instance, how it functions, and how it should be
designed to produce the desired performance. One is interested in not only what it does
but also how it does it. At a higher level, one addresses the function and usage of the
ampliﬁer within a bigger system. We call this the system level. From this point of view,
the internal structure of the ampliﬁer is of less interest than its operation within the bigger
system. Therefore, a description of the function and performance is more important than
how the internal structure of the ampliﬁer leads to that performance.
Clearly, the borderline between the component and system levels depends on what
is called a component and what is called a system. For example, consider a digital signal
processing (DSP) system, such as a stand-alone board or one embedded in a computer,
that acquires analog signals, converts them to digital data, performs DSP operations on
the data, and sends the results to a user. The system is made of several subsystems such as
analog-to-digital and digital-to-analog (A/D and D/A) converters, interfaces, processor,
and communication ports, each of which is constructed from components (integrated
circuits, resistors, capacitors, op-amps, etc.). Each of the components may be considered
asystemonitsown.Atthesametime,mostprobably,theDSPsystemunderconsideration
maybefunctioningwithinalargersystemsuchasaspeechprocessingsystem,atelephone
network, a digital communication system, a data transmission network, or a computer
network. In that role, the DSP system is a component of a larger system.
What then constitutes the system view? How important is the distinction between
the system view and the component view? Should analysis of a system be detached
from the components of which it is composed? Is there an advantage in developing a
uniﬁed approach to describing various systems regardless of whether the components
and variables are electrical, mechanical, thermal, or societal? In the present discussion
we will avoid such an abstract approach as much as possible. We will use mathematical
models of systems, with occasional insights into their physical structure, derived mostly
from electrical and electromechanical systems. For our purposes, a system is deﬁned by
an input space, an output space, and the relationship between them. The formulation of
equations that describe the system is shown in the next section, followed by the system’s
classiﬁcations.
In this book we consider the class of engineering systems that interact with the
outside world through signals and waveforms which are functions of time and space.
This class covers a vast population of systems. We concentrate on a special subset called
linear time-invariant (LTI) systems, knowledge of which greatly facilitates the analysis
anddesignofalargenumberofengineeringsystems.Furthermore,thesystemsaresingle-
input, single-output deterministic, and real-valued (described by linear differential or
difference equations with real-valued coefﬁcients). Unless otherwise speciﬁed, the input

Signals and Systems
159
and output are also real-valued functions of time. The linearity and time-invariance
properties are sunmmarized below.
Linearity
Time Invariance
input
⇒output
x1(t)
⇒y1(t)
x2(t)
⇒y2(t)
x3(t) = ax1(t) + bx2(t) ⇒y3(t) = ay1(t) + by2(t),
for all x1(t), x2(t), a, and b
input
⇒output
x(t)
⇒y(t)
x(t −T ) ⇒y(t −T ),
for all x(t) and T
The chapter shows how to test for LTI properties and how to construct or predict
the response to a new input by using superposition of known responses and applying
the derivative and integral properties. After presenting several examples from various
engineering ﬁelds, the chapter introduces a system’s responses to the impulse, step,
exponential, and sinusoidal inputs. While the technique of superposition will be formally
presented in the next chapter, the examples and solved problems in this chapter are
designed to illustrate the application of the fundamentals independent of any technique.
Methods for the analysis and solutions of LTI systems (including Fourier techniques) are
direct consequences of LTI properties and are summarized for expansion and discussion
in later chapters.
In an introductory textbook on signals and systems such as this one, LTI models
of simple and familiar devices and systems are used to illustrate the concepts. Real-life
systems on the other hand, be they synthetic or natural, are neither LTI nor simple.
However, the LTI modeling provides an initial step toward the analysis and design of
such complex systems. Also, a brief discussion of complex systems exposes the reader
to some prominent examples such as the human central nervous system and adaptive
learning models. The former is too advanced to lend itself to the basic methods presented
in such an introductory book, but the latter are not. Finally, the open-loop control project
at the end of the chapter shows how to apply LTI properties to produce a desired output
and, therefore, helps the reader develop basic skills in this area.
3.1
Formulation of Equations
Mathematically, a system is speciﬁed by the following three entities:
i.
The collection of all possible inputs, designated as the input set X = {xi}.
ii.
The collection of all possible outputs, designated as the output set Y = {y j}.
iii.
The input-output transformation or the mapping function X ⇒Y.
See Figure 3.1.

160
CHAPTER 3
Systems, Linearity, and Time Invariance
(b)
Input set X
Output set Y
Mapping
yj
xi
(a)
Input
Output
System
FIGURE 3.1 (a) A system has an input space, output space, and input-output mapping. (b) Block
diagram representation.
Systems are, in general, made of interconnected elements. The performance of a
system is then governed by two groups of relationships:
i.
Group one: The elements’ individual characteristics (i.e., the relationships
among each element’s variables).
ii.
Group two: Interconnection constraints (i.e., the relationships created by
interconnecting the elements).
The above groups of relationships are combined and formulated as the system’s dynam-
ical equations in two ways.
1.
Input-output formulation. The input-output formulation limits itself to the
mapping function; the output is expressed in terms of input only. The internal
variables don’t appear in the system’s dynamical equations. Once the input-output
relationship is determined, one no longer needs to know the internal structure of
the system or the physical laws governing the internal variables.
2.
State-variable formulation. In an alternative formulation, the internal states of
the system constitute the variables of its dynamical equations. This is also called
the state-space description. In this formulation, the output is expressed in terms
of the input and internal states. An example would be the voltage appearing at the
output of an RLC circuit which is expressed in terms of (a) the input to the circuit,
(b) the capacitors’ voltages, and (c) the inductors’ currents. These last two groups
of variables constitute the state space of the system at any moment.
In formulating and solving dynamical equations, we observe great similarities and
strong analogies between many physical systems in various areas such as the electrical,
mechanical, and thermal arts. This is especially evident in the case of linear time-invariant
systems, to be introduced later in this chapter.
3.2
Classifications of Systems
Input and output spaces in Figure 3.1 may be continuous or discrete. The sets may
be ﬁnite or inﬁnite, bounded or unbounded. The mapping may be one-to-one or not,
deterministic or probabilistic, with or without memory. The mapping may be expressed

Signals and Systems
161
by a table, an equation, or a graph. Based on such aspects, systems are classiﬁed in
several different ways. Some classiﬁcations are listed below.
Continuous Versus Discrete, Analog Versus Digital Systems
A system is called continuous-time if its input and output signals may change at any
instance of time (or at any location of space, in which case it should be called continuous-
space). Most physical systems are continuous-time. A system is called discrete-time if
the values of its inputs and outputs may change (or be observed) only at discrete instances
of time, such as every T seconds.
If the system’s input and output assume a continuous range of values the system is
called analog. If they can assume only one of n predetermined levels the system is called
discrete. In a binary system, signals belong to one of two states, each represented by a
level; for example, 0 or 1. If the signal level may switch between only these levels and
at discrete times, the system is called digital.
The above groupings are based on the properties of input and output signals and
reﬂect the signal processing function of the system. In a different venue, a system may
be concerned with discrete events, in which case it is called a discrete-event system.
An example is a decision system that classiﬁes members of a discrete set of events into
another discrete set of decisions.
Static Versus Dynamic Systems
A system is said to be without memory if the output at any moment depends only on
the input at that moment. Memoryless systems are sometimes called instantaneous, or
static, because the output at each instant is inﬂuenced only by the input at that instant.
The input effect is immediate and does not last. Past inputs have no inﬂuence on present
or future outputs. Passive resistive circuits are examples of memoryless systems.
Systems with storage capability (energy or state) have memory, as past input values
inﬂuence the present state of the system and its output. Electric circuits made of RLC
elements store energy and are systems with memory. Mechanical systems with masses
and springs (i.e., energy storage elements) have memory, too. Energy storage elements,
however, are not the only devices that provide memory in physical systems. Introduction
of a nonlinear active element in a resistive memoryless system may provide it with
information storage capability, thus providing memory. Flip-ﬂops, Schmitt triggers, and
comparators with feedback are examples of systems that do not store energy, but rather
information about past inputs. Systems that contain such elements are said to have
memory. Systems with memory are also called dynamic and the equations that describe
them are called the dynamical equations of the system.
Systems with Feedback
The output of a system may physically travel back through a path and be fed back (e.g.,
by simple addition) to the input of the system. This creates a feedback system. See
Figure 3.2. An example is the reverberation and echo present in an acoustic system.
Feedback paths may also be created to modify the behavior of a system; for example, to
reduce the system’s sensitivity to noise or increase its linearity range. In other situations

162
CHAPTER 3
Systems, Linearity, and Time Invariance
Forward
path
x(t)
y(t)
Feedback
FIGURE 3.2 A system with feedback.
the feedback signal (be it the output or a state variable) may be used to design new
commands.
3.3
Causality
The distinction between causal and noncausal systems becomes clear when input x(t)
and output y(t) are functions of time only. A causal system is a system whose output
is zero until an input arrives. Therefore, if x(t) = 0 for t < t0, then y(t) = 0 for
t < t0. With time being the independent variable, a causal system may be realizable and
a noncausal system is physically impossible. If the independent variable is something
other than time (e.g., space), a noncausal system may be physically realizable.
3.4
Linearity, Time Invariance, and LTI Systems
The most important and useful properties of some systems are linearity and time invari-
ance, which allow us to predict the output of a large class of inputs based on a single
input-output pair, and often provide an analytical and closed-form formulation of the
relationship between input and output.
Linearity
Let x(t) and y(t) designate the input and output of a system, respectively. In some sys-
tems, superposition of inputs results in superposition of outputs. If the property remains
in effect for all possible inputs, the system is called linear. One consequence of linearity is
proportionality: multiplying an input by a number, multiplies the output by the same num-
ber. Another consequence of linearity is the ability to predict the output in response to new
inputs that may be represented by linear combinations of previously experienced inputs.
To test for linearity, let two arbitrary inputs x1 and x2 produce outputs y1 and y2,
respectively. If the input x = ax1 + bx2 produces y = ay1 + by2 for all constants a and
b, then the system is called linear.
x1
⇒
y1
x2
⇒
y2
x = ax1 + bx2
⇒ay1 + by2
Time Invariance
The characteristics of some systems are independent of time. As a result, a time shift in
the input causes a time shift of the same value in the output, with no other effects. The

Signals and Systems
163
system is called time invariant if the above property holds true for all inputs, at all times,
and for all time shifts. This property allows the use of previously measured input-output
pairs for future prediction. If some characteristics of a system change with time, a delay
in an input may not result in a similar delay in the output, or may result in a longer delay.
The system is then time variant.
To test for time invariance, let an arbitrary input x(t) produce the output y(t). If the
input x(t −T ) produces the output y(t −T ) for all T , then the system is called time
invariant.
x(t)
⇒y(t)
x(t −T ) ⇒y(t −T )
Linearity and time invariance are two separate properties of systems. Systems that are
both linear and time invariant (LTI) are of great interest because they may often be
described sufﬁciently well by a certain single input-output pair. The output to any other
input may then be predicted from such a description.
Example
3.1
Is the system y(t) = kx(t), with k a constant, linear? Is it time invariant?
Solution
Testing for linearity:





x1
⇒y1 = kx1
x2
⇒y2 = kx2
x = ax1 + bx2 ⇒y = kx = k(ax1 + bx2) = akx1 + bkx2 = ay1 + by2
The system is linear because y = ay1 + by2 for all a, b, x1, and x2.
Testing for time invariance:

x(t)
⇒kx(t) = y(t)
x(t −T ) ⇒kx(t −T ) = y(t −T )
The system is also time invariant because the shift property is valid for all T and x.
Example
3.2
Is the system y(t) = k1x(t) + k0, where k0 and k1 are nonzero constants, linear? Is it
time invariant?
Solution
Testing for linearity:



x1
⇒y1 = k1x1 + k0
x2
⇒y2 = k1x2 + k0
x = ax1 + bx2 ⇒y = k1x + k0 = k1 [ax1 + bx2] + k0 ̸= ay1 + by2
The system is not linear because y ̸= ay1 + by2.
Testing for time invariance:

x(t)
⇒y(t) = k1x(t) + k0
x(t −T ) ⇒k1x(t −T ) + k0 = y(t −T )
The system is time invariant because the shift property is valid for all T and all x.

164
CHAPTER 3
Systems, Linearity, and Time Invariance
Examples 3.3 to 3.5
In the systems of Examples 3.3 to 3.5, x(t) is the input and y(t) is the output.
a.
Determine if the system is (i) linear, (ii) time invariant.
b.
Find the unit-impulse response h(t) for the LTI systems.
Example
3.3
y(t) =
 t
−∞
x(τ)dτ
Solution
a.
Testing for linearity:
y1(t) =
 t
−∞
x1(τ)dτ
and
y2(t) =
 t
−∞
x2(τ)dτ
x3(t) = ax1 + bx2(t) ⇒y3(t) =
 t
−∞
(ax1 + bx2)dτ
y3(t) = a
 t
−∞
x1dτ + b
 t
−∞
x2(τ)dτ = ay1 + by2(t)
for all x1, x2, a , and b. The system is linear.
b.
Testing for time invariance:
x1(t) = x(t −t0) ⇒y1(t) =
 t
−∞
x(τ −t0)dτ =
 t−t0
−∞
x(θ)dθ = y(t −t0)
for all x(t) and t0. The system is time invariant with
h(t) =
 t
−∞
δ(τ)dτ = u(t)
Example
3.4
y(t) = t
 t
−∞
x(τ)dτ
Solution
a.
Testing for linearity:
y1(t) = t
 t
−∞
x1(τ)dτ and y2(t) = t
 t
−∞
x2(τ)dτ
x3(t) = ax1(t) + bx2(t) ⇒y3(t) = t
 t
−∞
[ax1(τ) + bx2(τ)]dτ
y3(t) = at
 t
−∞
x1(τ)dτ + bt
 t
−∞
x2(τ)dτ = ay1(t) + by2(t)
for all x1, x2, a, and b. The system is linear.

Signals and Systems
165
b.
Testing for time invariance:
x1(t) = x(t −t0) ⇒y1(t) = t
 t
−∞
x(τ −t0)dτ = t
 t−t0
−∞
x(θ)dθ ̸= y(t −t0)
The system is not time invariant.
Note 1. To see that
y1(t) ̸= y(t −t0), let yα(t) =
 t
−∞
x(τ)dτ
Then
y(t) = tyα(t), y(t −t0) = (t −t0)yα(t −t0), and y1(t) = tyα(t −t0) ̸= y(t −t0)
Time variance could also have been directly concluded from the presence of factor t
in the expression for y(t).
Example
3.5
dy(t)
dt
+ y(t) = x(t)
Solution
a.
Testing for linearity:
dy1(t)
dt
+ y1(t) = x1(t)
(1)
dy2(t)
dt
+ y2(t) = x2(t)
(2)
dy3(t)
dt
+ y3(t) = ax1(t) + bx2(t) (3)
Multiply (Eq. 1) by a and (Eq. 2) by b and add them together to obtain
d
dt [ay1(t) + by2(t)] + [ay1(t) + by2(t)] = ax1(t) + bx2(t) (Eq. 4)
Compare (Eq. 4) with (Eq. 3). You will ﬁnd y3(t) = ay1(t) + by2(t) for all
x1, x2, a, and b. The system is linear.
b.
Testing for time invariance:
x1(t) = x(t −t0) ⇒dy1(t)
dt
+ y1(t) = x(t −t0)
Compare with dy(t)
dt
+ y(t) = x(t) to conclude y1(t) = y(t −t0) for all x(t)
and t0.
The system is also time invariant. The unit-impulse response of the system h(t) is
obtained from
dh(t)
dt
+ h(t) = δ(t),
h(t) = e−tu(t)

166
CHAPTER 3
Systems, Linearity, and Time Invariance
3.5
Derivative and Integral Properties
of LTI Systems
The linearity and time-invariance properties lead to the derivative and integral properties
of the input and output.
x(t) ⇒
y(t)
dx
dt
⇒
dy
dt
 t
−∞
x(τ)dτ
⇒
 t
−∞
y(τ)dτ
One result of these properties is that dynamic systems are represented by linear differ-
ential equations with constant coefﬁcients
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = bm
dmx
dtm + bm−1
dm−1x
dtm−1 + · · · + b1
dx
dt + b0x
where dk y/dtk and dkx/dtk are the k-th time derivatives of y(t) and x(t), respectively,
and ak and bk are constants.
3.6
Examples from Electric Circuits
Electric circuits are interconnections of electrical elements and devices. The variables
of interest in an electric circuit are currents through branches and voltages between
connection nodes. These variables are under three types of constraints:
i.
The terminal current-voltage characteristics of constituent elements.
ii.
Kirchhoff’s current law.
iii.
Kirchhoff’s voltage law.
These constraints provide equations that are necessary and sufﬁcient to solve for all
currents and voltages in the circuit. The equations are called equilibrium or dynamical
equations. In a circuit made of ideal sources and linear elements (resistors, capacitors, in-
ductors, and dependent sources), the dynamic equations are linear differential equations.
Let the circuit contain ℓ(passive) elements with n loops and m nodes. To obtain element
currents and voltages (a total of 2ℓvariables), we use the following sets of equations:
1.
Elements’ i-v characteristics (ℓequations) are linear or nonlinear, see table below.
2.
KVL (n equations):

k vk = 0
3.
KCL (m −1 equations): 
k ik = 0

Signals and Systems
167
Element
v-i
i-v
Property
Resistor, R
v = Ri
i = v
R
linear
Inductor, L
v = L di
dt
i =

t
−∞
v dt
linear
Capacitor, C
v =

t
−∞
i dt
i = C dv
dt
linear
Diode
v = 0 when i ≥0
i = 0 when v < 0
nonlinear
Switch
v = 0 when open
i = 0 when closed
nonlinear
The KVL and KCL equations are composed of linear combinations of the 2ℓun-
known voltages and currents, their derivatives, or their integrals. It may be shown that
ℓ= n + m −1, and that the total number of independent equations is 2ℓ, equivalent
to the total number of unknowns. The coefﬁcients of the equations are derived from the
element values of the circuits. If element values don’t change with time, we obtain a
set of linear differential equations with constant coefﬁcients, making the systems time
invariant. In these mathematical models, the input and output spaces are the collection
of all continuous-time analog waveforms.
Input-Output Description
The set of node (or loop) equations may be reduced to a set of differential equations
containing only the independent sources (i.e., inputs) and the desired unknowns (i.e.,
outputs). This is the input-output relationship of the system.
State-Space Description
The state of the circuit at any moment is completely known from the set of currents in the
inductors and voltages at the terminals of the capacitors at that moment. These are called
the state variables and their space is called the state space. The dynamical equations of
the circuit may be formulated directly in terms of state variables. The equations are of
ﬁrst order.
The systems of Examples 3.6 to 3.12 below are all causal and time invariant.
Otherwise, they may be static, dynamic, linear, or nonlinear.
Example
3.6
In the circuit of Figure 3.3 ﬁnd the capacitor voltage vc as a function of the source
voltage vs. Show that the relationship is linear and time invariant.
R
+
–
vc
+
–
vs
C
i
+
–
FIGURE 3.3 A linear RC circuit.

168
CHAPTER 3
Systems, Linearity, and Time Invariance
Solution
Applying KVL around the loop we have
vs = Ri + vc
and i = C dvc
dt
The input-output relationship is, therefore,
RC dvc
dt + vc = vs
To test for linearity, let an input voltage vs1 produce the output voltage vc1:
RC dvc1
dt
+ vc1 = vs1
(1)
Let another input vs2 produce the output vc2:
RC dvc2
dt
+ vc2 = vs2
(2)
Multiplying both sides of (1) by a constant a and (2) by another constant b and adding
the results, we have
RC d
dt (avc1 + bvc2) + (avc1 + bvc2) = avs1 + bvs2
(3)
From (3) we deduce that vc = avc1 + bvc2 is the capacitor voltage produced by the
source vs = avs1+bvs2. Since in the above derivation no limitations were imposed on
a, b, vs1, and vs2, the system is linear and is described by a linear differential equation.
The coefﬁcients of the equation are constant and the system is time invariant.
Example
3.7
Voltage follower
In the circuit of Figure 3.4 (with an ideal op-amp, drawing zero current and having an
inﬁnite open-loop gain) the output is equal to the input vo = vs. The system isolates
the load Zℓfrom the signal source vs, making the internal resistance of the signal
source ineffective. The system is causal, memoryless, linear, and time invariant with
unity gain.
+
–
+
–
vs
vo
Rs
i = 0
Zl
+
–
FIGURE 3.4 A voltage follower circuit.

Signals and Systems
169
Example
3.8
Inverting amplifier
The circuit of Figure 3.5 (with an ideal op-amp, drawing zero current and having an
inﬁnite open-loop gain) is an ampliﬁer. It is described by the following input-output
relationship:
v2 = −R2
R1
v1
(For the derivation apply KCL at the inverting terminal of the op-amp.)
+
–
+
–
v1
R2
R1
v2
+
–
FIGURE 3.5 An inverting ampliﬁer.
The system is causal, static, linear, and time invariant. With a real op-amp, the
output of Figure 3.5 saturates at VSH and −VSL, making the system nonlinear. The
circuit is then limited by the following relationships:
v2 =













VSH,
−R2
R1
v1 ≥VSH
−R2
R1
v1,
−VSL < −R2
R1
v1 < VSH
−VSL,
−R2
R1
v1 ≤−VSL
Example
3.9
Integrator
In the circuit of Figure 3.5 (with an ideal op-amp) replace the feedback resistor R2
by a capacitor C and the circuit then becomes an integrator. It is described by the
following input-output relationship:
v2 = −1
RC
 t
−∞
v1 dt
The system is causal, dynamical, linear, and time invariant. With a real op-amp, the
output saturates at VSH and −VSL, making the system nonlinear.

170
CHAPTER 3
Systems, Linearity, and Time Invariance
Example
3.10
Multi-input system
The summing circuit of Figure 3.6 has n inputs vi, i = 1 · · · n, and one output vout.
vout
Rn
vn
v3
v2
v1
R3
Z
R2
R1
+
–
FIGURE 3.6 A summing circuit.
With the feedback element Z being a resistor R f , the input-output relationship is
vout = −
 R f
R1
v1 + R f
R2
v2 + · · · + R f
Rn
vn
	
(For the derivation apply KCL at the inverting terminal of the op-amp.) The circuit
is linear, time invariant, and memoryless. Replacing the feedback resistor R f with a
capacitor C, we obtain a summing integrator with the input-output relationship
vout = −1
C
 t
−∞
 1
R1
v1 + 1
R2
v2 + · · · + 1
Rn
vn
	
dt
The circuit is then dynamic.
Example
3.11
Multi-output system
The circuit of Figure 3.7 has one input is, and two outputs v(t) and i(t). Let R1 = 3 ,
R2 = 2 , L = 1 H, and C = 1 F. Formulate the system’s dynamical equations to
ﬁnd v(t) and i(t).
L
R1
+
–v
i
A
R2
is
C
FIGURE 3.7 A multi-output system.

Signals and Systems
171
Solution
We write node and loop equations using inductor current i and capacitor voltage v.

v′ + v
2 + i = is
(KCL at node A)
v −3i −i′ = 0
(KVL around the external loop)
Moving the derivative terms to the left side and the rest of the terms to the right side
we get

v′ = −0.5v −i + is
(KCL)
i′ = v −3i
(KVL)
The above equations may also be written in matrix form in terms of the input (is),
state (v, i), and the output.

v′
i′

=

−0.5 −1
1
−3
 
v
i

+

1
0

is
The input-output relationships are
v′′ + 3.5v′ + 2.5v = i′
s + 3is
i′′ + 3.5i′ + 2.5i = is
The system is causal, dynamic, linear, and time invariant.
Example
3.12
State-variable description
The circuit of Figure 3.8 has one input x, one output y, and two state variables z1 and
z2, which are the voltages at the output terminals of op-amps 1 and 2, respectively.
+
–
R3
–z1´
z2
z1
y
R1
–z1
R2
C
C
+
–
+
–
R1
x
R
R
2
1
FIGURE 3.8 An op-amp circuit that solves a single-input single-output differential
equation and provides access to state variables. See Example 3.12.

172
CHAPTER 3
Systems, Linearity, and Time Invariance
Given R1 = 1 M, R2 = 500 k, R3 = 333 k, and C = 1 µF, the state and
output equations become
z′
1 = −z2
z′
2 = 2z1 −3z2 −x
y = z1
which may be written in matrix form as

z′
1
z′
2

=

0
−1
2
−3
 
z1
z2

+

0
−1

x and y =

1
0
 
z1
z2

The circuit solves the following LTI differential equation
y′′ + 3y′ + 2y = x
Example
3.13
Multi-input multi-output system with state-variable
description
An electronic circuit has two inputs (x1, x2) and two outputs (y1, y2), all functions
of time. It is described by the following input-output relationships:
y′
1 = −y2 −x1
y′
2 = −3y1 −2y2 −x2
which may be written in matrix form as

y′
1
y′
2

= −

0
1
3
2
 
y1
y2

−

1
0
0
1
 
x1
x2

The system is linear, time invariant, and dynamic. The project at the end of Chapter 5
synthesizes an analog circuit to solve a set of differential equations.
3.7
Examples from Other Fields
In this section we present three additional examples commonly encountered in basic
engineering systems. The systems are all causal and time invariant. In addition, they
may be static, dynamic, linear, or nonlinear.
Example
3.14
Motion of a pendulum
A simple rigid pendulum is made of a bob of mass m and a rigid bar of length l and
negligible mass. See Figure 3.9(a).
Let the external torque applied to the pivot of the pendulum be τ. The damping
force of the environment opposing the motion of the bob is proportional to its velocity,
−β v = −β θ′l, resulting in the damping torque −βθ′ l2. The pivot has a coil that

Signals and Systems
173
Spring
and
friction
m
l
g
(b)
(a)
L
R
v
i
C
+
–
FIGURE 3.9 (a) A pendulum, (b) Its linearized model is represented by an RLC circuit.
creates an opposing torque of −ksθ. The torque produced by gravity is −mgl sin θ.
The equation of motion (i.e., the relationship between the pendulum’s displacement,
θ, and the external torque) is found by applying Newton’s law:
ml2θ′′ + βθ′l2 + ksθ + mgl sin θ = τ
θ′′ + β
m θ′ + ks
ml2 θ + g
l sin θ =
1
ml2 τ
This is a time invariant, dynamic, and nonlinear system. However, if θ is small (e.g.,
θ < 10◦), one can assume sin θ ≈θ, and the system becomes linear:
θ′′ + β
m θ′ +
 ks
ml2 + g
l

θ =
1
ml2 τ
The dynamical equation of this linear system is then the same as the dynamical
equation of a series RLC circuit driven by a voltage source v (Figure 3.9b) with the
differential equation
q′′ + R
L q′ +
1
LC q = 1
L v
where q is the charge on the capacitor at time t.
With no external torque, friction, spring, or stiffness in the pendulum, the equation
of motion becomes
θ′′ + g
l sin θ = 0
For small displacements, sin θ ≈θ, and we have a zero-input, second-order linear
system
θ′′ + g
l θ = 0
The systems described in Examples 3.15 and 3.16 represent more comprehensive
cases of linear systems whose input and output are functions of time and space.

174
CHAPTER 3
Systems, Linearity, and Time Invariance
Example
3.15
A public address sound system
In a public address sound system, let the air pressure at the microphone constitute
the input and the air pressure at a given point in space constitute the output. Consider
a single input-output system with a microphone (the input) and a loudspeaker (the
output), both placed at ﬁxed positions. The input and output spaces are collections of
all real-valued time functions. This system may be partitioned into six subsystems,
as shown in Figure 3.10, and described below.
1.
The microphone that converts the incoming sound into electrical signals.
2.
The voltage ampliﬁer that ampliﬁes the voltage signals.
3.
The current ampliﬁer that provides the power to drive the loudspeaker.
4.
The loudspeaker that converts the electrical signal into sound.
5.
The air through which sound propagates.
6.
The echo from walls that may feed back into the microphone.
1
2
x
y
3
4
5
Wall
6
FIGURE 3.10 Elements of a public address system.
Each subsystem has an input and an output. Assume that within the operation
range a sinusoidal input to the i-th subsystem is transformed into a sinusoidal output
with a magnitude gain of Ai and a phase addition of θi, both of which are functions of
frequency. We show this transfromation by Ai ̸ θi and call it the transfer function for
the i-th subsystem. The transfer function of the forward path (made of subsystems 1
through 4) is A̸ θ, where A = A1· A2· A3· A4 and θ = θ1+θ2+θ3+θ4. Similarly, the
transfer function of the feedback path (made of subsystems 5 and 6) is B̸ φ. The total
phase shift around the loop is θ +φ. If this loop phase equals 360◦, a very small input
may produce a large output, which manifests itself by whistling. The system is then
called unstable. The above system becomes multi-input–multi-output if it employs
several microphones and loudspeakers.
Example
3.16
Acoustic system in a room
In another system that models the acoustic properties of a room, the sound generated
by a loudspeaker constitutes the input and the acoustic vibrations picked up by a
microphone constitute the output. The input and output become functions of time and
space. To characterize the system, we gather data by placing a sound source at a

Signals and Systems
175
location s in the room to produce input x(s, t) and a microphone at another location to
measure the response y(s, t). We then repeat the time-space response measurement
for frequencies and locations of interest. The input-output inventory created by the
above experiment will describe the acoustic properties of the room. The system then
becomes multivariable, multi-input–multi-output, where the time t is a continuous
variable and s may assume discrete or continuous values.
3.8
Response of LTI Systems to Impulse
and Step Inputs
An LTI system may be completely speciﬁed by its response h(t) to a unit impulse or,
equivalently, its response to a step input. Methods for ﬁnding the unit-impulse response
and its use in analyzing a system and predicting its output to a new input will be discussed
in Chapters 4, 5, and 6. Here we provide three examples.
Example
3.17
The response of an LTI system to a unit impulse is measured and modeled by h(t) =
e−tu(t). Find its unit-step response g(t).
Solution
g(t) =
 t
−∞
h(τ)dτ =
 t
0
e−τdτ = (1 −e−t)u(t)
Example
3.18
The response of an LTI system to a unit step is measured and modeled by g(t) =
(1 −e−2t)u(t). Find its unit-impulse response.
Solution
h(t) = dg
dt = d
dt

(1 −e−2t)u(t)

= 2e−2tu(t)
Example
3.19
Unit-impulse response in an RC circuit
In the circuit of Figure 3.3 a unit-impulse voltage is applied by the voltage source,
vs = δ(t). Find capacitor and resistor voltages vc and vR, respectively.
Direct Approach
A unit-impulse voltage at vs produces an impulse current i = δ(t)/R in the circuit
which charges the capacitor to an initial voltage vc(0+) = 1/(RC). For t > 0, this initial
voltage is discharged through the resistor with a time-constant RC. The unit-impulse

176
CHAPTER 3
Systems, Linearity, and Time Invariance
responses are, therefore,
vc =
1
RC e−t/RCu(t)
vR = vs −vc = δ(t) −
1
RC e−t/RCu(t)
Alternative Approach
A unit impulse may be considered the derivative of a unit step: du(t)
dt
= δ(t). The capacitor
and resistor voltages in response to a unit-step input voltage are
Capacitor voltage = (1 −e−t/RC)u(t)
Resistor voltage = e−t/RCu(t)
Taking derivatives of the above voltages results in the unit-impulse responses found by
the direct approach.
3.9
Response of LTI Systems to
Exponential Inputs
The response of LTI systems1 to an exponential input est, where s is a constant, is an
exponential H(s)est. This may be derived directly from the linearity and time-invariance
properties. To show this, and to ﬁnd the scale factor H(s), start with the unit-impulse
response h(n) (entry 1 in the table below) and follow steps 2 through 7, where you will
have the desired result.
Step
Actions and Their Rationale
Input
=⇒
Output
1
From unit-impulse response we have:
δ(t)
⇒
h(t)
2
From time invariance we have:
δ(t −τ)
⇒
h(t −τ)
3
From linearity we have:
esτδ(t −τ)
⇒
esτh(t −τ)
4
From linearity we have:

∞
−∞
esτδ(t −τ)dτ
⇒

∞
−∞
esτh(t −τ)dτ
5
In entry #4 change τ to τ = t −θ

∞
−∞
es(t−θ)δ(θ)dθ
⇒

∞
−∞
es(t−θ)h(θ)dθ
to obtain:
6
From sifting property of δ(θ) we get:
est
⇒
est

∞
−∞
e−sθh(θ)dθ
7
Now let

∞
−∞
e−sth(t)dt = H(s), then
est
⇒
H(s)est
1We assume the LTI system under consideration has an impulse response.

Signals and Systems
177
Note that the above property is not derived from the Laplace transform operation.
Exponential time functions are called characteristic functions (or eigenfunctions) of
linear time-invariant systems. The input est produces the output H(s)est, which is an
exponential with the same exponent. H(s) and s are, in general, complex numbers. The
system scales only the amplitude of the input by the factor H.
Example
3.20
Response of an RC circuit to est
In the circuit of Figure 3.11, v(t) = est. Find H(s).
i1
v(t) = est
i
C
R
+
–
i2
FIGURE 3.11 Response of a parallel RC circuit to est is H(s)est.
Solution
i1 = vs
R = est
R , i2 = C dvs
dt = Csest
and
i = i1 + i2 =
 1
R + Cs
	
est = H(s)est
From which H(s) = 1
R + Cs
Example
3.21
DC steady-state response
Given h(t), the unit-impulse response of an LTI system, ﬁnd its response to x(t) = 1.
Solution
est ⇒H(s)sst, where H(s) =
 ∞
−∞
h(t)e−stdt
DC input
est
s=0 = 1 ⇒H(s)est
s=0 = H(0) =
 ∞
−∞
h(t)dt

178
CHAPTER 3
Systems, Linearity, and Time Invariance
Alternative Solution
u(t) ⇒g(t) =
 t
−∞
h(τ)dτ.
DC input
u(t)

t=∞= 1 ⇒g(t)

t=∞
=
 ∞
−∞
h(t)dt
3.10
Response of LTI Systems to Sinusoids
In Section 3.9, let s = jω. Then we will have
Input
=⇒
Output
est
⇒
H(s)est
e jωt
⇒
H(ω)e jωt
cos(ωt) = RE 
e jωt
⇒
RE 
H(ω)e jωt
= |H(ω)| cos(ωt + θ)
Alternatively:
cos(ωt) = e jωt + e−jωt
2
⇒
H(ω)e jωt + H ∗(ω)e−jωt
2
= |H(ω)| cos(ωt + θ)
In the above table,
H(ω) = H(s)

s= jω = |H(ω)|̸ θ and H ∗(ω) = H(s)

s=−jω = |H(ω)|̸ −θ
We deduce that the response of an LTI system to a sinusoid is a sinusoid of the same
frequency. The system generally changes the amplitude and phase of the input. The
change depends on the frequency and is called the system’s frequency response.
Note: The scale factors H(s) and H(ω) are two different functions. For systems with
real-valued elements, H(s) is a real function of s (with s being a complex or real number).
Therefore, H(ω) is a real function of jω, which makes it a complex function of ω. It is
for convenience and simplicity that the same notation H is used to represent the scale
factor when we switch from s to ω.
Example
3.22
Response of an RC circuit to sinusoids
In the circuit of Figure 3.11 let R = 1 k, C = 1 µF, and v(t) = cos(1,000t) +
cos(2,000t). Find i(t).

Signals and Systems
179
Solution
With v(t) as the input and i(t) as the output, the frequency response of the circuit
is H(ω) = 10−6 (1,000 + jω). Let v(t) = v1 + v2, with v1(t) = cos(1,000t) and
v2(t) = cos(2,000t). From linearity,
H1 = 10−3(1 + j) =
√
2 × 10−3̸ 45◦
H2 = 10−3(1 + 2 j) =
√
5 × 10−3̸ 63.4◦
i1 =
√
2 × 10−3 cos(1,000t + 45◦)
i2 =
√
5 × 10−3 cos(2,000t + 63.4◦)
i = i1 + i2 =
√
2 × 10−3 cos(1,000t + 45◦) +
√
5 × 10−3 cos(2,000t + 63.4◦)
Note the amplitude and phase changes at ω = 1,000 and 2,000 rad/s.
3.11
Use of Superposition and Other Properties
of LTI Systems
The following three examples illustrate the use of superposition in LTI systems. This
subject will be treated in detail in Chapter 4.
Example
3.23
An input-output pair for an LTI system is shown in Figure 3.12, where d(t) is the
input and p(t) is the output.
d(t)
1
0
1
t
{1, –1}
{1}
p(t)
1
–1
0
1
2
t
FIGURE 3.12 An input-output pair for the LTI system of Example 3.23.
a.
Express p(t) in terms of d(t).
b.
For convenience represent the unit rectangular pulse
d(t) = u(t) −u(t −1) ≡{1
↑}. Consider an input x(t) = {1
↑, −1, −1}. By
superposition ﬁnd y(t), the system’s output, and verify that it is equal to
x(t) −x(t −1).
c.
Repeat part b for x(t) = {1
↑, −1, −1, 1}.
d.
Repeat part b for x(t) = {1
↑, −1, −1, 1, 1 · · ·}.
e.
Find the unit-step response of the system.
f.
Write the input-output relationship.

180
CHAPTER 3
Systems, Linearity, and Time Invariance
Solution
a.
p(t) = d(t) −d(t −1)
b.
x(t) = d(t) −d(t −1) −d(t −2)
y(t) = p(t) −p(t −1) −p(t −2) = {1
↑, −1} −{0
↑, 1, −1} −{0
↑, 0, 1, −1}
= {1
↑, −2, 0, 1}
x(t) −x(t −1) = {1
↑, −1, −1} −{0
↑, 1, −1, −1} = {1
↑, −2, 0, 1} = y(t)
c.
x(t) = d(t) −d(t −1) −d(t −2) + d(t −3)
y(t) = p(t) −p(t −1) −p(t −2) + p(t −3) = {1
↑, −2, 0, 2, −1}
x(t)−x(t −1) = {1
↑, −1, −1, 1}−{0
↑, 1, −1, −1, 1} = {1
↑, −2, 0, 2, −1} = y(t)
d.
x(t) = d(t) −d(t −1) −d(t −2) +
∞

k=3
d(t −k)
y(t) = p(t) −p(t −1) −p(t −2) +
∞

k=3
p(t −k) = {1
↑, −2, 0, 2}
x(t) −x(t −1) = {1
↑, −1, −1, 1, 1, · · ·} −{0
↑, 1, −1, −1, 1, 1, · · ·}
= {1
↑, −2, 0, 2} = y(t)
e.
x(t) =
∞

k=0
d(t −k)
y(t) =
∞

k=0
p(t −k) = {1
↑}
x(t) −x(t −1) = {1
↑, 1, 1, 1, 1, · · ·} −{0
↑, 1, 1, 1, 1, 1, · · ·} = {1
↑}
f.
y(t) = x(t) −x(t −1)
In summary,
x(t)
⇒y(t)
{1
↑}
⇒{1
↑, −1}
{1
↑, −1, −1}
⇒{1
↑, −2, 0, 1}
{1
↑, −1, −1, 1}
⇒{1
↑, −2, 0, 2, −1}
{1
↑, −1, −1, 1, 1, · · ·} ⇒{1
↑, −2, 0, 2}
{1
↑, 1, 1, 1, 1, · · ·}
⇒{1
↑}
Example
3.24
Find h(t), the unit-impulse response of the system in Example 3.23.
Solution
Take the derivatives of the given input-output pairs:
x(t) = u(t) −u(t −1) ⇒y(t) = u(t) −2u(t −1) + u(t −2)
x′(t) = δ(t) −δ(t −1) ⇒y′(t) = δ(t) −2δ(t −1) + δ(t −2)

Signals and Systems
181
From examination of x′(t) and y′(t) we conclude that h(t) is made of unit impulses.
The ﬁrst impulse in y′(t) is due to the ﬁrst impulse in x′(t); therefore, h(0) = δ(t).
From the second impulse y′(1) = −2δ(t −1) we derive h(1) = −δ(t) and from the
third impulse y′(2) = δ(t −2) we conclude h(2) = 0 and h(t) = 0, t > 2. The
unit-impulse response of the system is h(t) = δ(t)−δ(t −1). It is veriﬁed as follows:
δ(t)
⇒δ(t) −δ(t −1)
δ(t −1)
⇒δ(t −1) −δ(t −2)
δ(t) −δ(t −1) ⇒[δ(t) −δ(t −1)] −[δ(t −1) −δ(t −2)]
= δ(t) −2δ(t −1) + δ(t −2)
Example
3.25
The response of an LTI system to u(t) is g(t) = e−tu(t). Find its responses to the
following inputs:
a.
u(t) −u(t −1)
b.
tu(t)
c.
tu(t) −u(t −1)
d.
δ(t)
Solution
a.
x(t) = u(t) −u(t −1)
y(t) = g(t)−g(t−1) = e−tu(t)−e−(t−1)u(t−1) =



0,
t < 0
e−t,
0 < t < 1
−1.718e−t,
t > 1
b.
x(t) = tu(t) =
 t
−∞
u(τ)dτ
y(t) =
 t
−∞
g(τ)dτ =
 t
0
e−τdτ = (1 −e−t)u(t)
c.
x(t) = tu(t) −u(t −1)
y(t) = (1 −e−t)u(t) −e−(t−1)u(t −1) =



0,
t < 0
1 −e−t,
0 < t < 1
1 −3.718e−t,
t > 1
d.
x(t) = δ(t) = du(t)
dt
y(t) = dg(t)
dt
= δ(t) −e−tu(t)
3.12
LTI Systems and Fourier Analysis
The relationship between sinusoidal signals and linear time-invariant systems has im-
portant consequences.2 In almost all cases of interest, a sinusoidal input to an LTI system
2Sinusoids are called eigenfunctions of LTI systems, which are described by linear differential equations
with constant real coefﬁcients.

182
CHAPTER 3
Systems, Linearity, and Time Invariance
produces a sinusoidal output with the same frequency but possibly different amplitude
and phase. Moreover, by superposition, if an input is made of a sum of sinusoids, the
output will be a sum of sinusoids also, each weighted by the frequency response. Thus,
by expanding a signal into its sinusoidal components, the Fourier method provides a
powerful tool for the analysis and synthesis of signals and linear systems. In almost all
cases, the frequency response of an LTI system contains all the input-output information.
Using generalized harmonic analysis, inputs are transformed into the frequency domain.
The frequency response then provides the change in phase and amplitude of each har-
monic. Since the frequency response of an LTI system may be measured experimentally,
Fourier analysis enables us to predict the output of an LTI system given any input and
without modeling the internal structure of the system.
The above discussion illustrates the convenience of having the input in the form of a
sinusoid.Fourieranalysisisamethodforrepresentingwaveformsassumsofsinusoids.It,
therefore, provides a useful and powerful tool for the analysis and synthesis of signals and
linear systems. Historically, the Fourier method started with the analysis and exploration
of continuous-time signals made of a ﬁnite weighted sum of harmonic sinusoids. This
led to the inﬁnite Fourier series for periodic signals and then was extended to the Fourier
transform. In this book we will follow the historical route, starting with the Fourier
series (FS), its properties, and its applications in Chapter 7. In Chapter 8 we consider
the Fourier transform (FT) and generalize it to periodic and nonperiodic signals.
3.13
Analysis and Solution Methods for LTI
Systems
A linear time-invariant system is completely speciﬁed by its impulse response.3 The
input-output relationship for such a system is given in one of the following forms:
i.
Convolution integral of the input with the unit-impulse response.
ii.
Linear differential equations with constant coefﬁcients.
iii.
System (transfer) function H(s) or the frequency response H(ω).
In summary, the analysis of an LTI system may be done in the time or frequency domains.
In the time domain the output is found by convolving the input with the impulse response
of the system, or by solving the input-output differential equation (see Chapters 4 and 5).
In the frequency domain, as will be seen in Chapters 6–9, the time functions will be
transformed and the transform of the output is equal to the product of the transforms of
the input signal and the system’s impulse response. The different methods are generally
convertible to each other. In fact, the transform of the impulse response is the frequency
response of the system, and the set of integro-differential equations of LTI systems in
the time domain become linear equations in the frequency domain.
3There are exceptions, however. The system y(t) = x(t) + x(−t) is linear but does not have an impulse
response.

Signals and Systems
183
3.14
Complex Systems
Previous examples showed simple systems that are analyzed by commonly used mathe-
matical models, tools, and techniques. These examples are appropriate for the scope and
aim of this book, but give only a limited, albeit clear and correct, view of engineering
systems. Many systems of interest are much more complex than those discussed here.
Despite their complexity, however, these systems can be analyzed and designed using
classes of analytic methods and computer tools of the type discussed in this book. Below
are three examples.
Multiple Input-Output and Multivariable Systems
Systems can have multiple inputs and outputs. The input and output are then given in
the form of vectors and the input-output description assumes a matrix form.
X =


x1(t)
x2(t)
...
xi(t)
...
xm(t)


⇒
Y =


y1(t)
y2(t)
...
y j(t)
...
yn(t)


Probabilistic Systems
Some systems are deterministic. Their responses can be predicted from the inputs. How-
ever, in some systems the input-output relationship is probabilistic. We may predict only
some output averages from the input, but a complete output speciﬁcation is not possible.
An example would be a binary digital communication channel shown in Figure 3.13.
The input x(n) and the output y(n) are both binary numbers (0 or 1). Due to factors such
as channel noise and interference, mapping from the input to the output is not totally
predictable. An input x(n) = 0 may result in y(n) = 0 (with a probability of p) or
y(n) = 1 (with a probability of 1 −p). Similarly, an input x(n) = 1 may result in
y(n) = 1 (with a probability of q) or y(n) = 0 (with a probability of 1 −q). Proba-
bilistic systems are distinguished from deterministic systems whose inputs are stochastic
processes (normally called random signals and noise).
Channel
X
Y
0
1
X
0
1
Y
p
q
1 – q
1 – p
FIGURE 3.13 A probabilistic system.

184
CHAPTER 3
Systems, Linearity, and Time Invariance
Adaptive Systems
The properties of a system may change in order to adapt to new circumstances according
to a predetermined rule or goal, or to seek another appropriate goal. Such adaptation
generally requires feedback. In a simple adaptive system the output signal is sensed and
used to modify the system parameters. The block diagram of an adaptive system is shown
in Figure 3.14.
Feedforward
controller
Feedback
controller
Adaptation law
Plant
Sensors
Environment reaction
Command generation
FIGURE 3.14 An adaptive system.
Some other examples of complex systems are the following: manufacturing systems,
fuzzy systems, purposive and goal-seeking systems, self-organizing systems, decision
systems, organizations as systems, computer networks, power systems, and qualitative
analysis of systems. Powerful tools and techniques exist for analyzing and synthesizing
such systems. These will not be discussed in this book.
3.15
Neuronal Systems
Still more complex are some systems for which no satisfactory analysis methods or
models have been developed yet. Biological neuronal systems in general, and the central
nervous system (CNS) in particular, are examples of such systems. The CNS receives,
processes, and stores data. It controls the behavior of the living organism. It learns from
experience and adapts to new situations. It is an accepted belief that the brain extracts fea-
tures, generalizes, constructs models of the external world, forms ideas, reasons, makes
decisions, and thinks. Other functions attributed to the brain are motivation, emotions,
fear, pleasure, abstract thoughts, consciousness, and so on. For all those reasons, under-
standing how the brain works has been one of the greatest challenges of science and
remains so at present. Despite the large amount of impressive data collected on the struc-
ture and the function of the nervous system, no satisfactory model exists to explain how
these functions are performed. The existing methods of system analysis and modeling
don’t seem to promise a breakthrough, but they are the only tools presently available. In
Chapter 1 we presented several classes of bioelectric signals associated with the activity
of the CNS, along with a brief introduction to neurons. Here we describe some basic

Signals and Systems
185
operations from which an input-output relationship in a neuronal unit may be constructed
and models for it built.
The CNS contains individual nerve cells or neurons that are assembled and inter-
connected into subsystems and networks. There are about 1010 to 1011 neurons in the
human CNS. They communicate with each other by electrical and chemical connections
called synapses. A neuron receives electrical impulses from as few as less than ten to
as many as several hundred thousand (e.g., a Purkinje cell in the cerebellum) and sends
its output signal to an average of 1,000 other neurons. Moreover, rather than being a
simple processing element of information, many neurons are composed of a complex
collection of dendritic processing elements of their own. A thin membrane separates the
inside from the outside of the neuron. By holding unequal concentrations of ions (higher
concentration of positive ions outside and negative ions inside), it develops and maintains
a negative intracellular voltage of 65 to 70 mV with respect to the extracellular space.
Structurally, a neuron is made of a cell body, dendrites, and an axon. See Figure 3.15.
The cell body varies across in size from a few microns to as much as 75 microns. It is the
site of integration of the incoming signals and processing of the information. Dendrites
are short neuronal processes that branch off the cell body like tree branches and receive
signals from other neurons. A neuron has many dendrites but a single axon. The axon
is a thin tube arising from the cell body at a location called the axon hillock. The axon
may branch off and carry the electrical signal to several other neurons or even back to
itself (called axon collateral). The axon varies in length from a few microns to more than
Cell Body
Axon (Out)
C F (In)
c
b
a
e
p
(a)
(b)
(c)
l
d
c
b
a
FIGURE 3.15 (a) A pyramidal cell of the cerebral cortex of rabbit. (b) A Purkinje cell of human cerebellum showing
the ﬂat dendritic tree. (c) A schematic representation of a Purkinje cell of the cerebellar cortex [dendrites, cell body, and
climbing ﬁbers (CF)]. Climbing ﬁbers wrap around the cell and deliver one type of input to the cell. The other group of
input ﬁbers (called mossy ﬁbers) are not shown. The output signal is carried by the cell axon.
Source (a, b, and c): From S. Ramon Cajal, Histologie du System Nerveux de L’Homme & des Vertebres, 1909 Paris. Part (c) of this
ﬁgure is an adaptation from the original.

186
CHAPTER 3
Systems, Linearity, and Time Invariance
a meter. The axon carries the output signal of the neuron. Therefore, a neuron has mul-
tiple inputs but only a single output. A schematic is shown in Figure 3.15(c). The cells
shown in Figure 3.16 were marked with intracellularly injected horseradish proxidate.
The electrical signals from the cells were shown in Chapter 1.
(a)
(c)
(b)
FIGURE 3.16 Purkinje cells from the cat’s cerebellum. (a) The cell body of a Purkinje cell and its axon is shown on
the top left. Purkinje cell bodies are typically about 50 to 75 microns across. (b) A dendritic segment from another cell
shows ﬁngerlike spines, which are the arrival sites of signals from other neurons. (c) On the bottom another Purkinje cell
shows the cell body and its dendritic branches. The dendrites cover a span of about 1 mm.
Sources: From Nahvi, Woody, et al., “Electrophysiologic Characterization of Morphologically Identiﬁed Neurons in the Cerebellar
Cortex of Awake Cats,” Experimental Neurology, 67 (1980), pp. 368–76; and Nahvi and Woody, unpublished.

Signals and Systems
187
Signaling and Processing
Dendrites receive electrical signals in the form of narrow electric pulses (called action
potentials, spikes, or nerve impulses) from other neurons. An action potential is a unitary
all-or-none narrow electrical pulse that travels along the axon of the transmitting neuron.
The sites where axon terminals from transmitting neurons impinge upon receiving neu-
rons are called synapses. They are located on ﬁngerlike projections (called spines) arising
from the dendrites. See Figure 3.16(b). An action potential arriving at a synapse produces
a postsynaptic potential inside the cell. Postsynaptic potentials can be positive [called
excitatory postsynaptic potentials (EPSPs)] or negative [called inhibitory postsynaptic
potentials (IPSPs)]. Their magnitudes vary from one to several mV. The postsynaptic
potentials spread through the cell body as decaying exponentials with time and alge-
braically add to the intracellular potential. Thus, an EPSP reduces the negative electrical
potential inside the neuronal unit (it is said to make the intracellular space depolarized)
and an IPSP makes it more negative (making it hyperpolarized). It is said that the gain
of the input pathways is modiﬁed by adaptation, due to conditioning and experience,
and provides learning and memory. With sufﬁcient depolarization, the intracelluar po-
tential is reduced to a threshold level (e.g., −50 mV), causing a momentary change in
the conductance of the membrane. This allows positive sodium ions to move from the
outside to the interior, thus producing a momentary increase of the interior voltage from
the negative resting potential to zero or even a positive level. This is the action potential.
The phenomenon progresses along the axon away from the cell body and propagates the
action potential. The action potential constitutes the output signal of the neuron.
Modeling
Based on the above observations, simple models for neurons are suggested and used in
modeling biological and artiﬁcial neural networks. See Figure 3.17.
An incoming action potential produces an exponentially decaying postsynaptic
potential.Thegainoftheinputismodiﬁablebasedonalearningalgorithm.Thecollection
of input action potentials are grouped into excitatory and inhibitory inputs, producing
EPSPs and IPSPs, respectively. The postsynaptic potentials and the resting potential of
Excitatory inputs
(EPSP)
Output y
x
Resting potential
Inputs
Inhibitory inputs
(IPSP)
y
x
FIGURE 3.17 A model for a neuronal unit. x(t) is the state of internal polarization (sum of postsynaptic and resting
potentials). The output of the cell is y(t), the rate of ﬁring of spikelike action potentials.

188
CHAPTER 3
Systems, Linearity, and Time Invariance
the unit algebraically add to produce an internal variable labeled x(t). Transformation of
x(t) to the output y(t) (e.g., representing the rate of ﬁring of the unit) is accomplished by
a sigmoid transfer function (shown in the ﬁgure) or a piecewise linear transfer function
with saturation levels. Artiﬁcial neural networks have been used in signal processing,
pattern recognition, decision systems, and similar applications. Their impact on our
understanding of the operation and modeling of the brain remains to be demonstrated.
3.16
Problems
Solved Problems
Problems 1--5
In the following systems x(t) is the input and y(t) is the output. (a) Determine if the systems are
(i) linear, (ii) time invariant. (b) Find the unit-impulse response h(t) for the LTI systems.
1. y(t) = 2x2(t) + 1
Solution
a. Testing for linearity:
y1 = 2x2
1 + 1 and y2 = 2x2
2 + 1
x3 = ax1 + bx2 ⇒y3 = 2(ax1 + bx2)2 + 1 = 2a2x2
1 + 2b2x2
2 + 2abx1x2 + 1 ̸= ay1 + by2
The system is nonlinear.
b. Testing for time invariance:
x1(t) = x(t −t0) ⇒y1(t) = 2x2(t −t0) + 1 = y(t −t0)
for all x(t) and t0. The system is time invariant.
2. y(t) = x(5t)
Solution
a. Testing for linearity:
y1(t) = x1(5t) and y2(t) = x2(5t)
x3(t) = ax1(t) + bx2(t) ⇒y3(t) = x3(5t) = ax1(5t) + bx2(5t) = y1(t) + y2(t)
for all x1, x2, a, and b. The system is linear.
b. Testing for time invariance:
x1(t) = x(t −t0) ⇒y1(t) = x[5(t −t0)] = x(5t −5t0) ̸= y(t −t0)
The system is not time invariant.
3. y(t) = 2x(t) + 3 t
−∞x(τ)dτ
Solution
Let ya(t) = 2x(t) be an LTI system with the unit-impulse response ha(t) = 2δ(t)and
yb(t) = 3

t
−∞
x(τ)dτ

Signals and Systems
189
be an LTI system with the unit-impulse response hb(t) = 3u(t). Then, y(t) = ya(t) + yb(t) is the LTI with
unit-impulse response h(t) = ha(t) + hb(t) = 2δ(t) + 3u(t).
4. y(t) =

∞
−∞
x(τ)h(t −τ)dτ, where h(t) is a continuous function.
Solution
a. To test for linearity, let x(t) = ax1(t) + bx2(t). The output is
y(t) =

∞
−∞
[ax1(τ) + bx2(τ)]h(t −τ)dτ = a

∞
−∞
x1(τ)h(t −τ)dτ + b

∞
−∞
x2(τ)h(t −τ)dτ = ay1(t) + by2(t)
for all x1, x2, a, and b. The system is linear.
b. To test for time invariance, let a new input be x1(t) = x(t −t0). The new output is then
y1(t) =

∞
−∞
x(τ −t0)h(t −τ)dτ
By changing the variable τ to a new variable θ via τ −t0 = θ, we get τ = θ + t0, dτ = dθ, and
y1(t) =

∞
−∞
x(θ)h[t −(θ + t0)]dθ =

∞
−∞
x(θ)h(t −t0 −θ)dθ = y(t −t0)
The system is, therefore, also time invariant. To ﬁnd the unit-impulse response, let x(t) = δ(t). Then

∞
−∞
δ(τ)h(t −τ)dτ = h(t −τ)|τ=0 = h(t)
5. y(t) =

∞
−∞
x(τ)g(t + τ)dτ
Solution
a. To test for linearity, let x(t) = ax1(t) + bx2(t). The output is
y(t) =

∞
−∞
[ax1(τ) + bx2(τ)]g(t + τ)dτ = a

∞
−∞
x1(τ)g(t + τ)dτ + b

∞
−∞
x2(τ)g(t + τ)dτ = ay1(t) + by2(t)
The system is linear. To test for time invariance, let a new input be x1 = x(t −t0). The new output is
y1(t) =

∞
−∞
x(τ −t0)g(t + τ)dτ
By changing the variable τ to a new variable θ via τ −t0 = θ, we get τ = θ + t0, dτ = dθ, and
y1(t) =

∞
−∞
x(θ)g[t + (θ + t0)]dθ =

∞
−∞
x(θ)g[(t + θ) + t0]dθ = y(t + t0)
x(t −t0) produces y(t + t0). Shifting the input in one direction shifts the output in the opposite direction. The
system is not time invariant.
6. The signal
x(t) =
4

k=0
δ(t −k)
is the input to an LTI system. Find the output if the unit-impulse response of the system is (a) h1(t) = δ(t)−δ(t −1),
and (b) h2(t) = δ(t) −2δ(t −1) + δ(t −2).

190
CHAPTER 3
Systems, Linearity, and Time Invariance
Solution
Apply superposition.
x(t) =
δ(t)
δ(t −1)
δ(t −2)
δ(t −3)
δ(t −4)
(a)
δ(t)
−δ(t −1)
δ(t −1)
−δ(t −2)
δ(t −2)
−δ(t −3)
δ(t −3)
−δ(t −4)
−δ(t −4)
−δ(t −5)
y1(t) =
δ(t)
0
0
0
0
−δ(t −5)
x(t) =
δ(t)
δ(t −1)
δ(t −2)
δ(t −3)
δ(t −4)
(b)
δ(t)
−2δ(t −1)
+δ(t −2)
δ(t −1)
−2δ(t −2)
+δ(t −3)
δ(t −2)
−2δ(t −3)
+δ(t −4)
δ(t −3)
−2δ(t −4)
+δ(t −5)
δ(t −4)
−2δ(t −5)
+δ(t −6)
y2(t) =
δ(t)
−δ(t −1)
0
0
0
−δ(t −5)
δ(t −6)
A simpler visualization of the above is shown below.
x = {1
↑
, 1, 1, 1, 1}
h1 = {1
↑, −1, 0, 0, 0, 0}
h2 = {1
↑, −2, 1, 0, 0, 0, 0}
y1 = {1
↑, −1, 0, 0, 0, 0}+
y2 = {1
↑, −2, 1, 0, 0, 0, 0}+
{0
↑, 1, −1, 0, 0, 0}+
{0
↑, 1, −2, 1, 0, 0, 0}+
{0
↑, 0, 1, −1, 0, 0}+
{0
↑, 0, 1
↑, −2, 1, 0, 0}+
{0
↑, 0, 0, 1, −1, 0}+
{0
↑, 0, 0, 1, −2, 1, 0}+
{0
↑, 0, 0, 0, 1, −1}
{0
↑, 0, 0, 0, 1, −2, 1}
= {1
↑, 0, 0, 0, 0, −1}
= {1
↑, −1, 0, 0, 0, −1, 1}

Signals and Systems
191
7. The response of an LTI system to a narrow pulse ζ(t) (width = 1 µs, height = 106) is η(t) = e−tu(t). Find its
response to a unit-square pulse d(t) = u(t) −u(t −1).
Solution
Let α = 10−6 be an incremental time. We express x(t) in terms of ζ(t) and α. Then we use the linearity and time
invariance properties of the system to express y(t) in terms of η(t) and α.
x(t) = α
N

k=0
ζ(t −kα)
y(t) = α
N

k=0
η(t −kα) = α
N

k=0
e−(t−kα), where N = 106 −1.
k = 0, 0 < t < α,
y(t) = αe−t
y(t) ≈αe−α ≈1 −e−α
k = 1, α < t < 2α,
y(t) = α(1 + eα)e−t
y(t) ≈α(1 + e−α) ≈1 −e−2α
k = 2, 2α < t < 3α,
y(t) = α(1 + eα + e2α)e−t
y(t) ≈α(1 + e−α + e−2α) ≈1 −e−3α
· · ·
· · ·
· · ·
k = ℓ, ℓα < t < (ℓ+ 1)α,
y(t) = α(1 + eα + e2α + · · · + eℓα)e−t
y(t) ≈1 −e−(ℓ+1)α
· · ·
· · ·
k ≥N, t ≥Nα,
y(t) = α(1 + eα + e2α + · · · + eNα)e−t
≈(e −1) e−t
Note 1. Taylor series expansion of the exponential function is:
ex = 1 + x + x2
2! + x3
3! + · · · xn
n! + · · ·
Then, 1 −ex ≈−x for x << 1.
Note 2. Sum of the ﬁnite geometrical series is
N

k=0
xk = 1 −x N+1
1 −x
.
Then,
N

k=0
xk ≈
1
1 −x
for x < 1 and N large.
Alternate Approach
x(t) ≈

t
−∞
ζ(t)dt −

t
−∞
ζ(t −1)dt
y(t) ≈

t
−∞
η(t)dt −

t
−∞
η(t −1)dt = 
1 −e−t
u(t) −
1 −e−(t−1)
u(t −1) =

 0,
t < 0
1 −e−t,
0 < t < 1
(e −1) e−t,
t > 1
In this alternate approach we have approximated ζ(t) by the unit impulse δ(t). The unit-impulse response of the
system is, therefore, h(t) ≈e−tu(t). But x(t) = u(t) −u(t −1). Therefore,
y(t) =

t
0
e−tdt −

t
1
e−(t−1)dt =

 0,
t < 0
1 −e−t,
0 < t < 1
(e −1) e−t,
t > 1

192
CHAPTER 3
Systems, Linearity, and Time Invariance
8. An LTI system is speciﬁed by its unit-impulse response h(t) = e−
t
1000 u(t) V.
a. Find its unit-step response g(t).
b. Find its response to the pulse d(t) ≡u(t) −u(t −1). Approximate the response by a piecewise linear curve and
describe your method.
c. Find its response to the pulse d(t) ≡103[u(t) −u(t −10−3)]. Approximate the response by a piecewise linear
curve and describe your method.
Solution
The unit-impulse response is a slowly decaying exponential that decreases from an initial value of 1 (at t = 0) to
a ﬁnal value of zero (at t = ∞), with a long time constant of 1,000 seconds. For example, at t = 1 its value is
h(1) = e−0.001 = 0.999 (a reduction of only 0.1%). Because of the very slow decay, during its early part it can be
considered to be a unit step.
a. The unit-step response is
g(t) =

t
−∞
h(τ)dτ =

t
−∞
e−
τ
1000 u(τ)dτ =

t
0
e−
τ
1000 dτ = 1,000(1 −e−
t
1000 )u(t).
It is an exponential function that grows very slowly (with a time constant of 1,000 seconds) from an initial value
of zero to a ﬁnal value of 1,000. During its early part it can be considered to be ≈t (a ramp with a slope of
1 s−1 because e−α ≈1 −α if α << 1.) Overall, the unit-step response appears like a ramp that, after several
hundred seconds, ﬂattens to the level of 1,000. The system is a leaky integrator with a long time constant of
1,000 seconds.
b. The response to the unit pulse u(t) −u(t −1) is
g(t)−g(t−1)=1,000(1−e−
t
1,000 )u(t)−1,000(1−e−(t−1)
1,000 )u(t−1)=



0,
t<0
1,000(1 −e−
t
1,000 ),
0<t<1
1,000e−
t
1,000 (e
1
1,000 −1)≈e−
t
1,000 , t>1
During the pulse period the response grows almost linearly from 0 to 1. At t = 1, the response is 1,000(1 −
e−0.001) = 0.999 ≈1 (note that e−0.001 ≈0.999 and e0.001 ≈1.001). From that value it slowly decays to zero with
a time constant of 1,000 seconds. Once beyond the early part, the response to a 1-V, 1-s pulse soon becomes
identical to the unit-impulse response. The 1-V, 1-s rectangular pulse approximates an impulse.
c. The response to the 1-kV, 1-ms pulse is obtained by a way similar to part b. The response is ≈e−
t
1,000 . This is
even closer to the unit-impulse response than was the case in part b.
Chapter Problems
Note: Use the linearity and time-invariance properties of LTI systems to solve problems 9 through 14.
9. An input-output pair of an LTI system was shown in Figure 3.12. Represent the unit rectangular pulse by d(t) =
u(t) −u(t −1) ≡{1
↑}. The input-output pair is, therefore, given by {1
↑} ⇒{1
↑, −1}. Find the system’s response to
the following inputs:
a. x(t) = {1
↑, 1, 1, 1, 1}
b. x(t) = {0, 1, −1
↑, 1, 0}
c. x(t) = {1
↑, −1, 1, −1, 1}
d. x(t) = {1
↑, 0, 1, 0, 1}
e. x(t) = {1
↑, 0, −1, 1, 0, −1, 1, 0, −1}
f. x(t) = {1
↑, 0, 0, 0, 1}

Signals and Systems
193
10. Find the response of the system of problem 9 to the following inputs:
a. x(t) = u(t)
b. x(t) = 1
c. x(t) =
∞

n=0
(−1)nd(t −n)
d. x(t) =
∞

n=0
(n + 1)d(t −n)
11. Following the notation of Figure 3.12, an input-output pair of an LTI system is given by
x(t) = {1
↑} ⇒
y(t) = {1
↑, 1}
Find its response to the following inputs:
a. x(t) = {1
↑, 1, 1, 1, 1, 1, 1}
b. x(t) = {1
↑, −1, 1, −1, 1, −1, 1}
12. Find the response of the system of problem 11 to the following inputs:
a. x(t) = d(t) + 2d(t −1) + 3d(t −2) + 4d(t −3) + 5d(t −4)
b. x(t) = d(t) −2d(t −1) + 3d(t −2) −4d(t −3) + 5d(t −4)
13. Find the response of the system of problem 11 to the following inputs:
a. x(t) = u(t)
b. x(t) = 1
c. x(t) =
99

n=0
(n + 1)d(t −n)
d. x(t) =
99

n=0
(−1)n(n + 1)d(t −n)
14. An input-output pair of an LTI system is given by
x(t) = {1
↑, −1} ⇒
y(t) = {1
↑, −1, 1}
a. Find and sketch the system’s output y2(t) for the input x2(t) = {1
↑, 1}.
b. Find the unit-step response of the system.
c. Give the input-output relationship.
15. Determine if the output of an LTI system due to an arbitrary input can be predicted from knowledge of the system’s
response to one of the following inputs:
a. x(t) = sin(2t), all t
e. x(t) = δ(t)
i.
x(t) = sin(2t)u(t −t0)
b. x(t) = e−t, all t
f. x(t) = e−(1+ j)t, all t
j.
x(t) = eσt sin(ωt)u(t −t0)
c. x(t) = e−t sin(2t), all t
g. x(t) = e−tu(t −t0)
k. x(t) = δ(t) + 1
d. x(t) = u(t)
h. x(t) = u(t −t0)
ℓ. x(t) = u(t) −u(t −1)
Support your answer by reasoning.
16. In each of the following relationships x(t) is the input and y(t) is the output of a system. a and b are constants.
Determine which system is (1) linear and/or (2) time invariant, and ﬁnd the unit-impulse response if linear.
a. y(t) = ax + b
b. y(t) = x(t −1)
c. y(t) = |x(t)|
d. y(t) = x(t) + x(−t)
e. y(t) = x(2t)
f. y(t) = x(2t) + 1
g. y(t) = sin x
h. x(t) = sin y
i. y(t) = x(2t + 1)
j. y(t) = x(t)u(t)
k. y(t + 2) = x(t)
ℓ. y(t) = x(t + 2) + x(−t)

194
CHAPTER 3
Systems, Linearity, and Time Invariance
17. Repeat problem 16 for the following systems
a. y(t) =

t
0
x(τ)dτ
b. y(t) =

t
−∞
x(τ −1)dτ
c. y(t) = t

t−1
−∞
x(τ)dτ
d. y(t) = ax(t) + b dx(t)
dt
e. y(t) = x(t + 2) −dx(t −1)
dt
f. y(t) = dx(3t)
dt
g. dy(t)
dt
+ y = 2d2x(t)
dt2
+ 3dx(t)
dt
+ x
h. y(t) =

∞
−∞
x(τ)x(t + τ)dτ
i. y(t) =

t
t−T
x(τ)dτ
j. y(t) = 2x(t) + 3

t
−∞
x(τ)dτ
k. y = dx(t)
dt
+

t−1
−∞
x(τ)dτ
ℓ. y(t) = x(t) + t dx(t)
dt
m. dy(t)
dt
= dx(t)
dt
+ x, t > 0, y(0) = y0
n. dy(t)
dt
+ y = x(t)u(t)
o. dy(t)
dt
+ y = tx(t)
18. In each of the following relationships x(t) is the input, y(t) is the output, and g(t) is a time function. Determine
which system is (1) linear and/or (2) time invariant, and ﬁnd the unit-impulse response if linear.
a. y(t) =

∞
−∞
x(τ)g(t −τ)dτ
c. y(t) = g(t)

t
−∞
x(τ)dτ
b. y(t) =

∞
0
x(τ)g(τ −t)dτ
d. y(t) =

∞
−∞
x(τ)g(t + τ)dτ
19. a. Two systems are cascaded, with system 1 preceding system 2. System 1 is speciﬁed by y = x + 1 and system 2
by z = dy
dt . Determine if the combined system (with x as the input and z as the output) is (1) linear and (2) time
invariant.
b. Switch the order of the connection so system 2 precedes system 1. Determine if the new combination is (1) linear
and (2) time invariant.
20. The unit-impulse response of an LTI system is a unit-square pulse, h(t) = u(t) −u(t −1). Find and sketch its
response to a rectangular pulse of width = T seconds and height = 1/T . Find the limit of the response as T →0.
21. The unit-impulse response of an LTI system is a unit-square pulse d(t) = u(t) −u(t −1). Find and sketch its
response to the input x(t) = d(t) −d(t −1) + d(t −2).
22. Deﬁne d(t) = u(t) −u(t −1). Find and sketch the responses of the systems speciﬁed below, where x(t) is the
input, y(t) is the output, and h(t) is the unit-impulse response.
a. x(t) = h(t) = d(t)
b. x(t) = d(t) + d(t −10) and h(t) = d(t/5)
c. x(t) = d(t) + d(t −2) and h(t) = (1 −t)d(t)
23. The response of an LTI system to a narrow pulse (width = 1 µs, height = 100) is e−2tu(t). Find its response to a
unit-square pulse d(t) = u(t) −u(t −1).
24. Find the time constant of the signal x(t) = (0.5)t.
25. The response of an LTI system to a unit-square pulse d(t) = u(t) −u(t −1) is 0.5tu(t). Find its response to (a)
x2(t) = d(0.5t) and (b) x(t) = ∞
n=0(−1)nx2(t −n)
26. Find the response of the system of problem 25 to x(t) = u(t) −u(t −100).
27. The response of an LTI system to a unit-square pulse d(t) = u(t) −u(t −1) is 0.5tu(t). Find its response to
x(t) = 1.
28. Draw the diagram of a linear electric circuit made of resistors, a capacitor, and op-amps, to produce the unit-impulse
response h(t) = ae−btu(t). Determine element values in terms of a and b.

Signals and Systems
195
29. The unit-impulse response of an LTI system is h(t) = e−tu(t). Find its response to the following:
a. An inﬁnite train of unit impulses
xa(t) =
∞

n=−∞
δ(t −n)
b. An inﬁnite train of alternating positive-negative unit impulses
xb(t) =
∞

n=−∞
(−1)nδ(t −n)
c. An inﬁnite train of alternating positive-negative unit-square pulses
xc(t) =
∞

n=−∞
(−1)nd(t −2n), where d(t) = u(t) −u(t −1)
30. The unit-impulse response of an LTI system is h(t) = (1−e−t)u(t). Find its response to x(t) = 1.6u(t)−0.6u(t−1).
31. Find and sketch the responses of the systems speciﬁed below. [δ(t) is the unit-impulse function.]
a. x(t) =
3

n=−1
δ(t −n)
and
h(t) =
4

n=0
δ(t −n)
b. x(t) = δ(t) −δ(t −1)
and
h(t) =
4

n=0
δ(t −n)
c. x(t) =
4

n=0
δ(t −n)
and
h(t) = δ(t) −δ(t −1)
d. x(t) = −δ(t + 1) + δ(t −1) + 2δ(t −2) + δ(t −3)
and
h(t) = δ(t) + 2δ(t −1) + δ(t −2)
32. The LTI systems in Table 3.1 are speciﬁed by their unit-impulse responses, where d(t) ≡u(t)−u(t −1) and n is an
integer. In each case ﬁnd and sketch the output to the given input. Hint: Use the linearity, superposition, integration,
and differentiation properties of LTI systems.
TABLE 3.1 (Problem 32)
Input
Unit-Impulse Response
a.
d(t) −d(t −1)
d(t) −d(t −1)
b.
d(t)
e−βtu(t)
c.
sin(t)u(t)
δ(t) + δ(t −π)
d.
∞

n=0
(−1)nδ(t −n)
u(t)
e.
∞

n=0
(−1)nδ(t −n)
e−βtu(t)
f.
δ(t) + d(t)
e−tu(t)
g.
δ(t) + δ(t −1)
sin 2πt
t

196
CHAPTER 3
Systems, Linearity, and Time Invariance
33. The LTI systems in Table 3.2 are speciﬁed by their unit-step responses. In each case ﬁnd and sketch the output to
the given input. Again, d(t) ≡u(t) −u(t −1) and n is an integer.
TABLE 3.2 (Problem 33)
Input
Unit-Step Response
a.
d(t)
e−βtu(t)
b.
d(t)
(1 −e−2t)u(t)
c.
∞

n=−∞
(−1)nd(t −n)
u(t)
d.
∞

n=−∞
(−1)nd(t −n)
e−βtu(t)
e.
cos(t)u(t −π/2)
u(t) + u(t −π)
f.
∞

n=0
δ(t −n)
u(t)
g.
δ(t) + d(t)
u(t)
34. The response of an LTI system to x(t) = u(t) is y(t) = e−tu(t). Find its responses to the following inputs:
a. x(t) −x(t −1)
b.

t
−∞
x(t)dt
c.

t
−∞
x(t)dt −u(t −1)
d. dx(t)
dt
35. Repeat problem 34 for the LTI system with the input-output pair
x(t) = e−2tu(t) ⇒y(t) = 
e−t −e−2t
u(t)
36. The response of an LTI system to u(t) is 
2e−t −e−5t
u(t). Find its responses to
a. δ(t)
b. 1
c.

t
−∞
u(τ)dτ
d.

t
t−1
u(τ)dτ
37. The response of an LTI system to u(t) is e−2tu(t). Find its responses to
a. u(t) + u(t −2)
b. 3u(t −1) +

t
−∞
u(τ)dτ
c. du(t −1)
dt
+

t
−∞
u(τ)dτ
d. du(t)
dt
+ u(t)
38. An LTI system is speciﬁed by its unit-impulse response h(t) = e−106tu(t).
a. Find its unit-step response and sketch it.
b. Find its response to the unit-square pulse d(t) ≡u(t) −u(t −1) and sketch it.
c. Describe a method to approximate the system’s response in part b during 1 msec < t < 1 sec.
39. The response of an LTI system to u(t) is 2−tu(t). Find its response to
a. u(t −1) −u(t −2)
b. t

t
−∞
u(τ)dτ
c.

1
−∞
u(τ)dτ + u(t + 1)
d.
du(t)
dt
−du(t −2)
dt

Signals and Systems
197
40. The unit-impulse response of an LTI system is h(t) = u(t) −u(t −1). Find and plot its output for the periodic
input x(t), where, for one period T ,
a. x1(t) =

2
0 < t < 1
0
1 < t < 6,
period T = 6
b. x2(t) =

3
0 < t < 1
−1
1 < t < 2,
period T = 2
Problems 41--48
Identify the correct output of the given LTI systems. The unit-impulse response h(t) and the input x(t) are given.
41. h(t) = e−2tu(t) and x(t) = 1. The output is most
nearly
a. e−2t
b. 1
c. 0.5
d. e−t
e. none of the above
42. h(t) = e−tu(t) and x(t) = u(−t). The output for
t < 0 is most nearly
a. −1
b. 1
c. et
d. e−t
e. none of the above
43. h(t) = e−tu(t) and x(t) = u(−t). The output for
t > 0 is most nearly
a. −1
b. 1
c. et
d. e−t
e. none of the above
44. h(t) = (e−t + e−2t)u(t) and x(t) = u(−t). The
output for t < 0 is most nearly
a. A(e−t + e−2t)
b. Be−t + Ce−2t, B ̸= C
c. 0
d. 1.5
e. none of the above
45. h(t) = (e−t −2e−2t)u(t) and x(t) = u(−t). The
output for t < 0 is most nearly
a. A(e−t + e−2t)
b. Be−t + Ce−2t, B ̸= C
c. 0
d. 1
e. none of the above
46. h(t) = e−2tu(t) and x(t) = u(t) −u(t −1). The
output for 0 < t < 1 is most nearly
a. 0
b. A
c. Be−2t
d. C(1 −e−2t)
e. none of the above
47. h(t) = x(t) = e−2t[u(t) −u(t −1)]. The output for
t > 2 is most nearly
a. 0
b. A
c. Be−2t
d. C(1 −e−2t)
e. none of the above
48. h(t) = e−3tu(t) and x(t) = δ(t) −δ(t −1). The
output for t > 0 is most nearly
a. 0
b. A
c. Be−3t
d. C(1 −e−3t)
e. none of the above
Problems 49--52
Identify the correct output of the given LTI systems.
The unit-step response g(t) and the input x(t) are
given.
49. g(t) = (1 −e−2t)u(t) and x(t) = u(t) −u(t −1).
The output during 0 < t < 1 is most nearly
a. A
b. Be−2t
c. (1 −e−2t)
d. C + De−2t, C ̸= D
e. none of the above

198
CHAPTER 3
Systems, Linearity, and Time Invariance
50. g(t) = (1 −e−2t)u(t) and x(t) = u(t) −u(t −1).
The output during t > 1 is most nearly
a. A
b. Be−2t
c. (1 −e−2t)
d. C + De−2t, C ̸= D
e. none of the above
51. g(t) = (1 −e−2t)u(t) and x(t) = 2u(t) −u(t −1).
The output during 0 < t < 1 is most nearly
a. A
b. Be−2t
c. C(1 −e−2t)
d. D + Ee−2t, D ̸= E
e. none of the above
52. g(t) = (1 −e−2t)u(t) and x(t) = 2u(t) −u(t −1).
The output during t > 1 is most nearly
a. A
b. Be−2t
c. C(1 −e−2t)
d. D + Ee−2t, D ̸= E
e. none of the above
53. The input-output relationship of an LTI system is
d2y
dt2 + 5dy
dt + 6y(t) = x(t)
a. Show that the h(t) and g(t) given below are the responses of the system to the unit-impulse and unit-step inputs,
respectively.
h(t) = (e−2t −e−3t)u(t)
g(t) =

1
6 −1
2e−2t + 1
3e−3t
	
u(t)
Problems 54--56
These problems are concerned with an LTI system that has an oscillatory step response. The project at the end of
the chapter expands upon this class of systems.
54. The input-output relationship of an LTI system is
d2y
dt2 + 2dy
dt + 4y(t) = 4x(t)
a. Show that the h(t) and g(t) given below are the responses of the system to the unit-impulse and unit-step inputs,
respectively.
h(t) =
4
√
3
e−t sin
√
3tu(t)
g(t) =

1 −

4
3e−t cos(
√
3t −30◦)

u(t)
b. Plot the two complex numbers s1,2 = −1 ± j
√
3 on the complex plane. Note that the complex numbers s1,2 are
the roots of the equation s2 + 2s + 4 = 0. Draw a semicircle of radius 2 in the left half-plane and center it at
the origin. Describe the correspondence between the system’s time responses and the diagram on the complex
plane.

Signals and Systems
199
55. The input-output relationship of an LTI system is
d2y
dt2 + 2σ dy
dt + ω2
0y(t) = ω2
0x(t)
a. Show that the h(t) and g(t) given below are the responses of the system to the unit-impulse and unit-step inputs,
respectively.
h(t) = ω2
0
ωd
e−σt sin ωdtu(t)
g(t) =

1 −

ω2
0
ω2
d
e−σt cos(ωdt −φ)

u(t), where ω2
0 = σ 2 + ω2
d and φ = tan−1

σ
ωd
	
b. Plot the two complex numbers s1,2 = −σ ± jωd on the complex plane. Note that the complex numbers s1,2 are
the roots of the equation s2 + 2σs + ω2
0 = 0. Draw a semicircle of radius ω0 in the left half-plane and center it
at the origin. Show σ, ωd, and φ on the complex plane. Describe the correspondence between the system’s time
responses and the diagram on the complex plane.
56. The input-output relationship of the LTI system in problem 55 is also written as
d2y
dt2 + 2ξω0
dy
dt + ω2
0y(t) = ω2
0x(t)
a. Show that the unit-impulse and unit-step responses, expressed in terms of ω0 and ξ, are
h(t) =
ω0
√1 −ξ 2 e−ξω0 sin ω0

1 −ξ 2tu(t)
g(t) =

1 −
1
√1 −ξ 2 e−ξω0 sin(ω0

1 −ξ 2t + θ)

u(t), where θ = cos−1 ξ
b. Plot the two complex numbers s1,2 = −ω0(ξ ± j√1 −ξ 2) on the complex plane. Note that the complex numbers
s1,2 are roots of the equation s2 + 2ξω0s + ω2
0 = 0. Draw a semicircle of radius ω0 in the left half-plane and
center it at the origin. Show the angle θ.
c. Show that in an oscillatory step response,
period of oscillations is T =
2π
ω0
√1 −ξ 2 and the
relative overshoot is ρ = e
−πξ
√
1−ξ2
57. In the circuit of Figure 3.7, let R1 = 3 k, R2 = 2 k, L = 1 H, and C = 1 µF.
a. Show that the capacitor voltage v and inductor current i are related to the current source by

v′ = −500v −106i + 106is
i ′ = v −3,000i
or

v′
i ′

=

−500
−106
1
−3,000

v
i

+

106
0

is
b. Show that the above relationships may be reduced to
v′′ + 3,500v′ + 2.5 × 106v = 106(i ′
s + 3,000is)
i ′′ + 3,500i ′ + 2.5 × 106i = 106is
c. Argue that the system is causal, dynamic, linear, and time invariant.

200
CHAPTER 3
Systems, Linearity, and Time Invariance
58. State equations for a pendulum. In the pendulum of Example 3.14, let the applied external torque τ constitute
the input, y = θ be the output, and z1 = θ ′ and z2 = θ be the two state variables. Show that the state and output
equations of the pendulum system are
z′
1 = −kdz1 −ks
ml2 z2 −g
l sin z2 +
1
ml2 τ
z′
2 = z1
y = z2
Show that for small angles we have
 z′
1
z′
2

=
 −kd
−ks
mℓ2 −g
ℓ
1
0
  z1
z2

+ τ

1
mℓ2
0

which may be written in matrix form as the following ﬁrst-order differential equations
 Z′ = AZ + BX
Y = CZ
where
Z =
 z1
z2

,
X =
 τ
0

,
A =
 −kd
−ks
mℓ2 −g
ℓ
1
0

,
B = 
1
mℓ2
0 
,
and C = 
0
1
3.17
Project: Open-Loop Control
Open-Loop Procedure
An LTI system is completely speciﬁed by the following two parameters:
ξ = damping ratio
ω0 = undamped natural frequency
The unit-step response of the system is
g(t) = 1 −
1
√1 −ξ 2 e−σt cos(ωdt −φ), where σ = ω0ξ, φ = sin−1 ξ, and ω0 =

ω2
d + σ 2
a. Show that the response overshoot (before it reaches the DC steady state) is
ρ = e
−π
ξ
√
1−ξ2
b. Show that for a system with 50% overshoot the damping ratio is ξ = 0.21545. Write the equation for the step
response of such a system if the period of oscillation equals T = 200 s and then plot it. From the plot verify the
percentage overshoot and period of oscillation assumed initially. See Figure 3.18(a).
c. To avoid oscillations and reach the ﬁnal steady state in ﬁnite time, apply the input x(t) = au(t)+(1−a)u(t −t0).
The output may be found by superposition. Determine a and t0 so that the response reaches its DC steady state in
100 s. See Figure 3.18(b).
d. To reduce the transition time, apply the input u(t) −ku(t −T1) + ku(t −T2), where the parameters k, T1, and
T2 can be adjusted. Find relationships between the three parameters such that the system reaches the steady state
in T2 s. Find example pairs of T1 and T2 for k = 1, 2. An example is shown in Figure 3.18(c) for k = 1, T1 = 46,

Signals and Systems
201
−50
0
50
100
150
200
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
Time (s)
Plot of g0(t)
Plot of g(t)
Plot of g(t) = g0(t − T/2)
x(t)
(a)
−50
0
50
100
150
200
0
0.2
0.4
0.6
0.8
1
Time (s)
x(t)
(b)
−50
0
50
100
150
200
0
0.2
0.4
0.6
0.8
1
Time (s)
x(t)
(c)
FIGURE 3.18
and T2 = 67.5. Reproduce Figure 3.18(c). Then, given k = 2 and T1 = 50, ﬁnd T2 and plot the response.
Hint: To accomplish this part you need g(T2) = 1 and dg(t)/dt = 0 at t = T2.
e. Given the overshoot ρ and k, develop and plot a family of curves from which one may ﬁnd T1 and T2. Keep the
period of oscillation at T = 200 s and change the overshoot from 20% to 90% in steps of 10%.
Discussion and Conclusions
The procedure described in this project is for open-loop control. Do you see any practical application for it? How sensitive
are the values of T1 and T2 to a changing k as it becomes larger? Does the procedure work for any inputs other than a step
function?

Chapter4
Superposition,
Convolution, and
Correlation
Contents
Introduction and Summary
203
4.1
Superposition of Responses
204
4.2
Convolution Sum
211
4.3
Convolution Integral
214
4.4
Graphical Convolution
217
4.5
Properties of Convolution
222
4.6
Filtering by Convolution
226
4.7
Matched Filter
228
4.8
Deconvolution
231
4.9
Autocorrelation
233
4.10
Cross-Correlation
237
4.11
Correlation and Convolution
240
4.12
Concluding Remarks
241
4.13
Problems
242
4.14
Project: Signal Detection by Matched Filter
255
Introduction and Summary
Convolution is the general formulation of the superposition of responses of linear systems
in the time domain. It is a cornerstone of linear systems analysis and ﬁltering. It states that
an LTI system is completely described by its unit-impulse response h(t). The convolution
203

204
CHAPTER 4
Superposition, Convolution, and Correlation
of two continuous-time functions x(t) and h(t) is deﬁned by the integral
y(t) =
 ∞
−∞
x(τ)h(t −τ)dτ
(1)
When both x(t) and h(t) are right-sided, the limits of the integral given above are reduced
to 0 to t. The above integral produces the response of the LTI system having the unit-
impulse response h(t) to the input x(t) (or vice versa). In addition, through its properties,
the convolution operation can provide insight into the functioning of a system in terms
of its subsystems. For example, the unit-impulse response of a cascade of several LTI
systems can be obtained from convolution of the individual unit-impulse responses, and
the cascading order may be changed without affecting the overall unit-impulse response
of the ensemble. As another example, the unit-impulse response of several LTI systems
in parallel is equal to the sum of the individual unit-impulse responses. Such properties
provide useful tools not only for the analysis but also for the synthesis and design of
systems (e.g., how to reduce design complexity by breaking down a system into simpler
subsystems).
Convolution constitutes the core subject of this chapter. By way of several examples
we ﬁrst show the use of superposition to ﬁnd the response of an LTI system to a new input
given the response to other inputs. Expanding upon the superposition and time-invariance
properties, we then derive the convolution sum and integral and present their properties.
The graphical method of visualizing the convolution integral is illustrated next. The
method is especially helpful in determining the limits of the integral and evaluating it
when x(t) and/or h(t) are sectionwise continuous functions. Finally, the chapter brieﬂy
introduces the concepts of ﬁltering by convolution, the matched ﬁlter, correlations, and
deconvolution. An application of a matched ﬁlter is provided as a project at the end of
the chapter.
4.1
Superposition of Responses
The linearity property leads to the superposition of responses due to individual inputs.
If a complex input can be broken down into simpler components with known responses,
the output may then be constructed from the responses to the input components.
Example
4.1
An input-output pair x1(t) →y1(t) for an LTI system is given in Figure 4.1(a). Find
the response of the system to inputs x2 and x3 of Figure 4.1(b) and 4.1(c) in terms of
y1(t) and evaluate them.
Solution
Express x2(t) and x3(t) in terms of x1(t). Then construct their outputs using y1(t) as
the building block. For brevity and convenience we use the following representations:
x1(t) = {1
↑, −1, 0}
x2(t) = {1
↑, 0, −1}
x3(t) = {1
↑, 1, −2}

Signals and Systems
205
1.
x1(t) ⇒y1(t) = {1
↑, −2, 1, 0}
2.
x2(t) = x1(t) + x1(t −1)
y2(t) = y1(t) + y1(t −1) = {1
↑, −2, 1, 0} + {0
↑, 1, −2, 1} = {1
↑, −1, −1, 1}
3.
x3(t) = x1(t) + 2x1(t −1)
y3(t) = y1(t) + 2y1(t −1) = {1
↑, −2, 1, 0} + {0
↑, 2, −4, 2} = {1
↑, 0, −3, 2}
(a)
(b)
(c)
0
1
2
t
1
x1(t)
–1
0
1
2
3
t
1
x2(t)
–1
0
1
2
3
t
1
x3(t)
–1
–2
0
1
2
3
t
1
y1(t)
–1
–2
0
1
2
3
4
t
1
y2(t)
–1
0
1
2
3
4
t
1
2
y3(t)
–1
–2
–3
FIGURE 4.1 The outputs y2 and y3 (due to inputs x2 and x3) are found by knowing the
input-output pair x1, y1.
Example
4.2
Given the input-output pair x1(t) →y1(t) for the LTI system shown in Figure 4.1(a),
ﬁnd the output due to x4(t) = {1
↑, −1, −1}.

206
CHAPTER 4
Superposition, Convolution, and Correlation
Solution
Express x4(t) in terms of x1(t), then construct its response y4(t) in terms of y1(t) and
evaluate it as done below.
x4(t) = x1(t) −
∞

k=2
x1(t −k)
y4(t) = y1(t) −
∞

k=2
y1(t −k) = {1
↑, −2, 1}
−{0
↑, 0, 1, −2, 1}
−{0
↑, 0, 0, 1, −2, 1}
−{0
↑, 0, 0, 0, 1, −2, 1}
−{0
↑, 0, 0, 0, 0, 1, −2, 1}
· · · · · ·
· · ·
· · ·
· · ·
· · ·
= {1
↑, −2, 0, 1, 0, 0, 0, 0}, (See Figure 4.2.)
0
1
2
3
t
1
x4(t)
–1
0
1
2
3
4
t
1
y4(t)
–1
–2
FIGURE 4.2 The output y4 (due to input x4) is found by knowing the input-output pair
x1, y1 given in Figure 4.1(a).
Alternative Solution
From an examination of the given relationship x1(t) →y1(t) in Figure 4.1(a), one
can deduce that the input-output relationship for the systems of Examples 4.1 and 4.2
is y(t) = x(t) −x(t −1). The relationship can be used to directly obtain the output
given any input.
Example
4.3
The response of an LTI system to a unit pulse at the origin, d(t) = u(t) −u(t −1),
is ˆh(t) = 4d(t) + 3d(t −1) + 2d(t −2) + d(t −3), a 4-step downstairs curve. as
shown in Figure 4.3(a). Find the system’s response to x(t) = u(t) −u(t −4).

Signals and Systems
207
0
1
t
(a)
(b)
1
d(t)
0
1
2
3
4
t
1
2
4
3
h(t)
ˆ
0
1
2
3
4
t
1
x(t)
0
1
2
3
4
5
6
7
t
1
2
4
5
6
7
8
9
10
3
y(t)
FIGURE 4.3 The output y2 (due to input x2 in [b]) is found by knowing the input-output
pair d(t), ˆh(t) in (a).
Solution
Since time is discrete, we designate it by the integer variable n. Then the unit pulse at
the origin is represented by d(n) = {1
↑} and produces the output ˆh(n) = {4
↑, 3, 2, 1}.
Similarly, the input x(n) = u(n) −u(n −4) may be expressed in terms of d(n) by
x(n) =
3

k=0
d(n −k)
By superposition, the response to x(n) is
y(n) =
3

k=0
ˆh(n −k)
Because d(n), ˆh(n), and x(n) assume constant values during discrete time intervals,
they may also be represented by sequences of numbers as shown in Table 4.1.

208
CHAPTER 4
Superposition, Convolution, and Correlation
TABLE 4.1 Finding y(n) by Superposition
d(n)
=
{. . . , 0, 1
↑, 0, 0, 0, 0, 0, 0, 0, 0, . . .}
ˆh(n)
=
{. . . , 0, 4
↑, 3, 2, 1, 0, 0, 0, 0, 0, . . .}
x(n)
=
d(n) + d(n −1) + d(n −2) + d(n −3)
=
{. . . , 0, 1
↑, 1, 1, 1, 0, 0, 0, 0, 0, . . .}
y(n)
=
ˆh(n) + ˆh(n −1) + ˆh(n −2) + ˆh(n −3)
=
{. . . , 0, 4
↑, 3, 2, 1, 0, 0, 0, 0, 0, . . .}
+
{. . . , 0, 0
↑, 4, 3, 2, 1, 0, 0, 0, 0, . . .}
+
{. . . , 0, 0
↑, 0, 4, 3, 2, 1, 0, 0, 0, . . .}
+
{. . . , 0, 0
↑, 0, 0, 4, 3, 2, 1, 0, 0, . . .}
=
{. . . , 0, 4
↑, 7, 9, 10, 6, 3, 1, 0, 0, . . .}
The system’s response to x(t) = d(t) + d(t −1) + d(t −2) + d(t −3) is
y(t) = 4d(t)+7d(t −1)+9d(t −2)+10d(t −3)+6d(t −4)+3d(t −5)+d(t −6),
shown in Figure 4.3(b).
Alternative Solution
From an examination of the given relationship d(t) →ˆh(t), we can deduce that the
input-output relationship for the system is y(t) = 4x(t) + 3x(t −1) + 2x(t −2) +
x(t −3). The relationship can then be used to directly obtain the output given any
input.
Example
4.4
A continuous-time waveform x(t) that may change its value at unit-time steps is repre-
sented by a ﬁnite sequence made of four elements: {. . . , 0, 0, x0
↑, x1, x2, x3, 0, 0, 0 . . .}
≡{x0
↑, x1, x2, x3}. The response of the LTI system of Example 4.3 to a unit pulse may,
therefore, be shown by ˆh(t) = {4
↑, 3, 2, 1}. The response of that system to the above
x(t) is
y(t) = x0 ˆh(t) + x1 ˆh(t −1) + x2 ˆh(t −2) + x3 ˆh(t −3) =
3

n=0
xn ˆh(t −n)

Signals and Systems
209
For example, let x(t) = {1
↑, 2, 3, 4}. Then y(t) = ˆh(t) + 2ˆh(t −1) + 3ˆh(t −2) +
4ˆh(t −3) can be constructed as shown below.
y(t)
=
4,
3,
2,
1,
0,
0,
0,
+
0,
8,
6,
4,
2,
0,
0,
+
0,
0,
12,
9,
6,
3,
0,
+
0,
0,
0,
16,
12,
8,
4,
=
4,
11,
20,
30,
20,
11,
4,
Example
4.5
Pat has established a credit account with a bank that requires N monthly payments of
(a + 1
N ) dollars each for every dollar of purchase. Statements are issued at the end of
each month and payments are made in the following month. Pat’s monthly charges
in dollars from January (marked by ↑) to December are
x(n) = {50
↑, 100, 200, 150, 300, 250, 350, 300, 100, 150, 400, 500}
with no purchase from then on. Starting with zero debt and for N = 5 and a = 0.02,
calculate the monthly payments for as long as they last.
Solution
The monthly charges x(n) (charges made to the account in the nth month) and the
monthly payments due y(n) (for payments due in the nth month) are listed in Table 4.2.
The system along with its input and output functions are shown in Figure 4.4.
TABLE 4.2 Monthly Charges and Payments of Example 4.5
Monthly
Payments Due
Charges
Jan Feb Mar Apr May June July Aug Sep Oct Nov Dec Jan Feb Mar Apr May June
Jan: $50
11
11
11
11
11
Feb: $100
22
22
22
22
22
Mar: $200
44
44
44
44
44
Apr: $150
33
33
33
33
33
May: $300
66
66
66
66
66
June: $250
55
55
55
55
55
July: $350
77
77
77
77
77
Aug: $300
66
66
66
66
66
Sep: $100
22
22
22
22
22
Oct: $150
33
33
33
33
33
Nov: $400
88
88
88
88
88
Dec: $500
110 110
110
110
110
Monthly
Payments
0
11
33
77
110
176
220
275
297 286
253
286 319 253
231
198
110
0

210
CHAPTER 4
Superposition, Convolution, and Correlation
Payments
LTI
Charges
0
1
t
t
1
d(t)
0
1
2
3
4
5
6
0.22
h(t)
(a)
500
400
300
200
100
0
0
2
4
6
8
10
12
t
x(t)
500
400
300
200
100
0
0
2
4
6
8
10
12
14
16
18
t
y(t)
(b)
FIGURE 4.4 The system of Example 4.5 and two input-output pairs.
Example
4.6
In the circuit of Figure 4.5(a), let vs be made of a rectangular voltage pulse (starting
at the origin) of magnitude k and duration T , superimposed on a unit step. See
Figure 4.5(b). Find vc and determine k so that the capacitor voltage reaches its DC
value in T seconds.
Solution
Let the step response be shown by g(t). It may be found that
g(t) =

1 −e−t/τ
u(t), τ = RC
The rectangular pulse of height k and width T may be written as k [u(t) −u(t −T )].
Using the linearity and time-invariance properties of the circuit, the capacitor voltage
in response to the pulse is determined to be k [g(t) −g(t −T )]. The response to the
pulse superimposed on a unit step is then
vc(t) = k [g(t) −g(t −T )] + g(t) =





0,
t < 0
(k + 1)

1 −e−t/τ
,
0 ≤t < T
1 +

keT/τ −1 −k

e−t/τ,
t ≥T

Signals and Systems
211
(a)
R
vs
C
vc
+
–
+
–
(b)
(c)
1 + k
0
T
t
1
vs(t)
t
1 + k
vc(t)
0
T
1
FIGURE 4.5 Charging a capacitor to a DC ﬁnal value in ﬁnite time.
For the capacitor voltage to reach its DC value at T we need
vc(t) = 1 + e−t/τ
keT/τ −1 −k

= 1, all t ≥T
This requires
keT/RC −1 −k = 0, or k =
1
eT/RC −1
An Alternate and More Elegant Solution
During 0 < t ≤T the circuit experiences a step input of size (k + 1). In response,
the capacitor voltage at t = T is
vc(T ) = (1 + k)(1 −e−T/τ)
Since for t > T the input is vs = 1, the response will remain constant if vc(T ) = 1.
vc(T ) = (1 + k)(1 −e−T/τ) = 1 or k =
1
eT/τ −1
Note that k is a positive number. See Figure 4.5(c).
4.2
Convolution Sum
Superposition of a system’s response to a sequence of pulses leads to the convolution
sum as illustrated in the following examples.

212
CHAPTER 4
Superposition, Convolution, and Correlation
Example
4.7
Let ζ(t) (written and pronounced as zeta) designate a rectangular pulse of width T
and unit height with its left edge at the origin. Then ζ(t −nT ) represents such a pulse
shifted to the right by the amount nT . Let the response of an LTI system to ζ(t) be
ψ(t) (written psi and pronounced sie). Consider an input x(t) to the LTI system
made of a sequence of rectangular pulses of width T and height xn, each placed at
t = nT . The input can be expressed in terms of ζ(t):
x(t) =
∞

n=−∞
xnζ(t −nT ), xn = {1
↑, 2, 0.5, −0.5, 0, 1}
See Figure 4.6. Find the response of the system to x(t).
Input
Output
LTI
(a)
(b)
(c)
0
t
y(t) = ψ(t) + 2ψ(t – 1)
+0.5 ψ(t – 2)
–0.5 ψ(t – 3) + ψ(t – 5)
0
t
1
ψ(t)
0
t
ψ(t  nT)
nT
T
nT
0
5T
t
1
2
x(t)
0
t
1
ζ(t)
0
t
1
ζ(t – nT)
FIGURE 4.6 Constructing the response to x(t) from its building blocks.
Solution
Using the linearity and time-invariance properties of the system, the output may
be found by the superposition of responses to individual pulses in the input. The
summation is called the convolution sum.
y(t) =
∞

n=−∞
xnψ(t −nT )
The summation operation and resulting output are shown in Table 4.3.

Signals and Systems
213
TABLE 4.3 Finding y(t) from the Convolution Sum
ζ(t)
⇒
ψ(t)
ζ(t −nT )
⇒
ψ(t −nT )
xnζ(t −nT )
⇒
xnψ(t −nT )
x(t) = ζ(t) + 2ζ(t −T ) + 0.5ζ(t −2T ) −0.5ζ(t −3T ) + ζ(t −5T )
y(t) = ψ(t) + 2ψ(t −T ) + 0.5ψ(t −2T ) −0.5ψ(t −3T ) + ψ(t −5T )
Example
4.8
The response of an LTI system to a unit pulse d(t) = u(t) −u(t −1) is e−tu(t). Find
the system’s response to the input x(t) = 4d(t) + 3d(t −1) + 2d(t −2) + d(t −3).
Solution
Applying the linearity and time-invariance properties, we ﬁnd y(t) from Table 4.4.
TABLE 4.4 Finding y(t) from the Convolution Sum
t < 0
y(t) = 0
0 ≤t < 1 y(t) = 4e−t
1 ≤t < 2 y(t) = 4e−t + 3e−(t−1) = (4 + 3e) e−t
2 ≤t < 3 y(t) = 4e−t + 3e−(t−1) + 2e−(t−2) = (4 + 3e + 2e2)e−t
t ≥3
y(t) = 4e−t + 3e−(t−1) + 2e−(t−2) + e−(t−3) = (4 + 3e + 2e2 + e3)e−t
Note the components in the amplitude of the output and how each input pulse
contributes to the total output. The above system is not realizable from a ﬁnite number
of lumped elements, delays, and differentiators.
Example
4.9
Let ξ(t) (written xi and pronounced cai) designate a rectangular pulse of width T
and height 1/T with its left edge at the origin. Then ξ(t −nT ) represents such a pulse
shifted to the right by the amount nT . Note that the area under every such pulse is
unity. Let the response of an LTI system to ξ(t) be η(t) (written and pronounced as
eta). See Figure 4.7. Find the response of the system to
ˆx(t) =
∞

n=−∞
T e−snT ξ(t −nT )
and determine its limit as T →0.
Solution
By time invariance, the response of the system to ξ(t −nT ) is η(t −nT ) and, by
superposition, the response to ˆx(t) is
ˆy(t) =
∞

n=−∞
T e−snT η(t −nT )

214
CHAPTER 4
Superposition, Convolution, and Correlation
LTI
Input
Output
0
T
t
ξ(t)
1
T
0
nT
t
ξ(t – nT)
1
T
0
t
x(t) = e–st
1
0
t
η(t)
0
nT
t
η(t – nT)
0
t
y(t) = H(s) e–st
(a)
(b)
(c)
FIGURE 4.7 Formulating response to an exponential input.
As T approaches zero, ξ(t) approaches the unit-impulse function, δ(t), and ˆx(t)
approaches e−st. If
lim
T →0 η(t) = h(t)
then
y(t) = lim
T →0 ˆy(t) =
	 ∞
−∞
h(t)estdt

e−st = H(s)e−st
Note that in passing through the system the exponential input e−st is multiplied by
the scale factor H(s).
4.3
Convolution Integral
We extend Example 4.9 to derive a general expression for the convolution integral.
Again, let ξ(t) designate a rectangular pulse of width T and unit area with its left
edge at the origin. Then ξ(t −nT ) represents such a pulse shifted to the right by the
amount nT . Let the response of the LTI system to ξ(t) be η(t). Let the input x(t) to the
LTI system be approximated by a stepwise function made of narrow rectangular pulses

Signals and Systems
215
of width T and height x(nT ) placed at t = nT . This stepwise approximation may be
expressed by
ˆx(t) =
∞

k=−∞
T x(nT )ξ(t −nT )
See Figure 4.8. The output is then found by superposition as shown in Table 4.5.
x(t)
nT
(n + 1)T
x(t)
T
t
FIGURE 4.8 Stepwise approximation to a continuous-time function. Each step is T seconds wide
and has a height of x(nT ). The step that starts at t = nT can be expressed by T x(nT )ξ(t −nT ).
TABLE 4.5 Developing the Convolution Integral
ξ(t)
⇒η(t)
ξ(t −nT )
⇒η(t −nT )
T x(nT )ξ(t −nT )
⇒T x(nT )η(t −nT )
ˆx(t) =
∞

n=−∞
T x(nT )ξ(t −nT ) ⇒ˆy(t) =
∞

n=−∞
T x(nT )η(t −nT )
In the limit T →0,
lim
T →0 nT = τ
lim
T →0 T = dτ
lim
T →0 ξ(t) = δ(t)
lim
T →0 x(t) = x(t)
lim
T →0 y(t) =
 ∞
−∞
x(τ)h(t −τ)dτ
The convolution sum becomes the convolution integral
y(t) =
 ∞
−∞
x(τ)h(t −τ)dτ

216
CHAPTER 4
Superposition, Convolution, and Correlation
Special Case
The convolution of two right-sided functions x(t)u(t) and h(t)u(t) becomes
 ∞
−∞
[x(τ)u(τ)][h(t −τ)u(t −τ)]dτ =
 t
0
x(τ)h(t −τ)dτ. See Example 4.10.
Example
4.10
Given x(t) = e−αtu(t) and h(t) = e−βtu(t), ﬁnd
y(t) =
 ∞
−∞
x(τ)h(t −τ)dτ
Solution
Because x(τ) = 0 for τ < 0, the lower limit of the integral is set to 0.
y(t) =
 ∞
0
x(τ)h(t −τ)dτ =
 ∞
0
e−ατe−β(t−τ)u(t −τ)dτ
But u(t −τ) = 0 for τ > t. Therefore, the upper limit of the integral is reduced to t
y(t) =
 t
0
e−ατe−β(t−τ)dτ = e−βt
 t
0
e−(α−β)τdτ =
1
β −α

e−αt −e−βt
u(t)
Example
4.11
Given x(t) = u(t) and h(t) = sin(ωt)u(t), ﬁnd y(t) = x(t) ⋆h(t).
Solution
y(t) =
 ∞
−∞
x(t −τ)h(τ)dτ =
 t
0
x(t −τ)h(τ)dτ
=
 t
0
sin(ωτ)dτ = −1
ω

cos(ωτ)
τ=t
τ=0
= 1
ω

1 −cos(ωt)

u(t)
Summary
The convolution of two functions x(t) and h(t) produces a new function y(t) de-
ﬁned by
y(t) =
 ∞
−∞
x(τ)h(t −τ)dτ
where −∞< t < ∞. It will be shown that the convolution operation between x(t)
and h(t) is commutative:
 ∞
−∞
x(τ)h(t −τ)dτ =
 ∞
−∞
x(t −τ)h(τ)dτ

Signals and Systems
217
The operation involves time reversal of one of the functions, its time shift, multi-
plication by the other function, and integration. The amount of shift constitutes the
independent variable in the convolution result. For simplicity and convenience, the
convolution integral of x(t) and h(t) is also shown by y(t) = x(t)⋆h(t) = h(t)⋆x(t).
4.4
Graphical Convolution
The convolution integral of (1) may be evaluated by plotting the function x(τ)h(t −τ)
[or x(t −τ)h(τ)] versus τ and then evaluating the area under the curve either geomet-
rically (from the graph) or analytically (from the integral). This is called the graphical
method. It is especially helpful in determining the upper and lower limits of integration
when the functions are speciﬁed graphically or by piecewise equations.1 The process is
summarized by the ﬂip-shift-multiply-integrate recipe as described below:
Step 1.
Flip h(τ) around τ = 0 to obtain h(−τ).
Step 2.
Shift h(−τ) by the amount t to obtain h(t −τ). A positive value of t shifts
h(−τ) to the right. A negative value of t shifts h(−τ) to the left. Start with
t = −∞.
Step 3.
Multiply h(t −τ) by x(τ) to obtain x(τ)h(t −τ).
Step 4.
Integrate x(τ)h(t −τ) over the range of −∞< τ < ∞. Call the sum y(t)
for the given t.
Step 5.
Go back to step 2. Increment the shift in h(t −τ) and continue the cycle until
y(t) is found for all values of t.
Needless to say, the ﬂip and shift may be performed on x(t).
Example
4.12
Find the convolution y(t) = x(t) ⋆h(t), where x(t) = e−tu(t) and h(t) = u(t).
Solution
y(t) =
 ∞
−∞
x(τ)h(t −τ)dτ =
 ∞
−∞
e−τu(τ)u(t −τ)dτ
Because u(τ) is zero for τ < 0, its presence in the integrand brings up the lower limit
of the integral to zero. Similarly, since u(t −τ) = 0 for τ > t, the upper limit of the
integral becomes t. Therefore,
y(t) =
 t
0
e−τdτ =

1 −e−t
u(t)
The above convolution is graphically visualized in Figure 4.9.
1The method is identical to the graphical method for evaluating the discrete convolution.

218
CHAPTER 4
Superposition, Convolution, and Correlation
t < 0
t > 0
–5
–4
–3
–2
–1
0
1
2
3
4
5
0
1
Time (s)
Magnitude
Plot of x(t) = e−tu(t)
–5
–4
–3
–2
–1
0
1
2
3
4
5
0
1
Time (s)
Magnitude
Plot of x(t) = e−tu(t)
e –τu(τ)
u(t – τ)
 t < 0 
 
t > 0 
ƒ∞
–∞e –τ u(τ)u(t – τ)dτ
t < 0  
t > 0
y(t) = ƒt0e –τ dτ = 1 – e–t, t  0
y(t) = 0, t < 0
y(t) = (1 – e–t) u(t)
−5 −4 −3 −2 −1
0
1
2
3
4
5
0
1
Time (s)
Magnitude
Plot of  u(−t − 2)
–5
–4
–3
–2
–1
0
1
2
3
4
5
0
1
Time (s)
Magnitude
Plot of x(t) = e–tu(t)  u(–t – 2)  
–5
–4
–3
–2
–1
0
1
2
3
4
5
0
1
Time (s)
Magnitude
Plot of u(–t + 2)
–5
–4
–3
–2
–1
0
1
2
3
4
5
0
1
Time (s)
Magnitude
Plot of x(t) = e–tu(t)  u(–t + 2)  
FIGURE 4.9 Graphical visualization of the convolution y(t) = [e−tu(t)] ⋆u(t) and its evaluation (Example 4.12). The
column on the left is for t < 0 and that on the right for t > 0.

Signals and Systems
219
Example
4.13
The unit-impulse response of an LTI system is h(t) = αe−βtu(t). Find its response
to the unit pulse x(t) = u(t) −u(t −1).
y(t) = x(t) ⋆h(t) =
 ∞
−∞
h(τ)x(t −τ)dτ
Solution
First, sketch graphs of h(τ) and x(τ). Then ﬂip x(τ) around the vertical axis to get
x(−τ). See Figure 4.10(a).
Next, shift the pulse x(−τ) to the left to get x(t −τ). For t < 0 the product
h(τ)x(t −τ) is zero and so is y(t). See Figure 4.10(b).
h(t) = αe–βt
t
0
x(t)
(a)
(b)  t < 0
t
0
1
1
1
x(–τ)
h(τ)
x(t – τ)
0
–1
0
1
t – 1
t
τ
τ
α
α
FIGURE 4.10 Convolution of the unit pulse with a causal exponential function
(Example 4.13).
h(t) = αe−βtu(t)
x(t) = u(t) −u(t −1),
y(t) = x(t) ⋆h(t)
=





0,
t < 0
α
β (1 −e−βt),
0 ≤t < 1
α
β (eβ −1)e−βt,
t ≥1

220
CHAPTER 4
Superposition, Convolution, and Correlation
(c)  0 ≤ t < 1
(d)  t ≥ 1
1
a
a
h(t)
h(t)
x(t – t)
x(t – t)
t – 1 0
t
t
t – 1
t
1
t
x(t)
t
0
1
1
*
h(t)
t
0
y(t) = x*h
t
0
=
1
a
a
b (eb – 1)
FIGURE 4.10 (Continued)
Then, shift the pulse x(−τ) to the right. The product h(τ)x(t −τ) is either zero
or αe−βt.
For 0 ≤t < 1 (Figure 4.10c), the integration is done from τ = 0 to τ = t and
y(t) =
 t
0
αe−βτdτ = α
β

1 −e−βt
, 0 ≤t < 1
For t ≥1 (Figure 4.10d), the integration is from t −1 to t and
y(t) =
 t
t−1
αe−βτdτ = −α
β

e−βt −e−β(t−1)
= α
β (eβ −1)e−βt, t ≥1
Example
4.14
Find the convolution of the unit pulse x(t) = u(t) −u(t −1) with itself.
Solution
Using the graphical method we ﬁnd the values of y(t) at the break points t = 0, 1,
and 2. Because x(t) is either zero or one, the product x(τ)x(t −τ) is either zero or
one and its integral between break points is a straight line. It is therefore sufﬁcient to
compute y(t) at the break points t = 0, 1, and 2, and then connect them by straight
lines. The result is a triangular pulse that is twice as wide as the rectangular pulse
(see Figure 4.11).

Signals and Systems
221
1
0
1
x(t)
t
1
0
t – 1
t
1
x(t)
h(t – t)
t
1
0 t
t – 1
1
t
1
0
1
t
0
t – 1
t
1
t
0
t – 1
t
t > 2,
1 < t < 2,
t = 1,
y = 1
0 < t < 1,
y = t
t < 0,
y = 0
t < 0,
y = x*h
y = 2 – t
y = 0
1
1
t
1
0
t
1
1
0
1
2
0
*
t
t
1
1
FIGURE 4.11 Convolution of the unit pulse with itself results in a triangular pulse
(Example 4.14).
y(t) =





0,
t < 0
t,
0 ≤t < 1
2 −t,
1 ≤t < 2
0,
t ≥2
Example
4.15
(1) Find the convolution of x(t) with the unit impulse δ(t). (2) Repeat for the unit
impulse located at t0, δ(t −t0).
Solution
1.
x(t) ⋆δ(t) =
 ∞
−∞
x(τ)δ(t −τ)dτ = x(t)
2.
x(t) ⋆δ(t −t0) =
 ∞
−∞
x(τ)δ(t −τ + t0)dτ = x(t −t0)

222
CHAPTER 4
Superposition, Convolution, and Correlation
Example
4.16
Given f (t) = δ(t −t0) + δ(t + t0) and x(t) = sin t
t , ﬁnd and plot y(t) = x(t) ⋆f (t)
for t0 = 7π/2.
Solution
y(t) = x(t) ⋆f (t) = sin t
t
⋆[δ(t −t0) + δ(t + t0)] = y1(t) + y2(t)
y1(t) = sin t
t
⋆δ(t −t0) = sin(t −t0)
t −t0
y2(t) = sin t
t
⋆δ(t + t0) = sin(t + t0)
t + t0
For t0 = 7π/2 we obtain
y(t) = sin(t −7π/2)
t −7π/2
+ sin(t + 7π/2)
t + 7π/2
See Figure 4.12.
t
t
t
1
1
1
–3π
–t0 – 3π
–t0 – π
–t0 + π
t0 – π
t0 + π
t0 + 3π
–t0 – 2π
–t0
–t0 + 2π
t0 – 2π
t0 + 2π
t0
3π
1
–π
–2π
–t0
t0
2π
π
x(t) = 
f(t) = δ(t – t0)
     + δ(t + t0)
x(t) f(t)
0
sin t
t
FIGURE 4.12 (For Example 4.16)
4.5
Properties of Convolution
Convolution is an operation with several algebraic properties. Three such properties
with important consequences are the commutative, associative, and distributive laws.
In addition, we note that convolution is a linear and time-invariant operation. (For the
proof see problem 4 in Chapter 3.) It, therefore, exhibits the additional properties of LTI
systems that were presented in Chapter 3. Here we brieﬂy summarize these properties.

Signals and Systems
223
Commutative Property
x(t) and h(t) in the convolution integral (1) may switch places and the result remains
the same:
x(t) ⋆h(t) = h(t) ⋆x(t)
To verify this property, change the integration variable τ in (1) to a new variable θ so
that τ = t −θ and dτ = −dθ. Substituting for τ and t −τ we have
y(t) =
 ∞
τ=−∞
x(τ)h(t −τ)dτ =
 ∞
θ=−∞
x(t −θ)h(θ)dθ
This property indicates that the output of an LTI system with the unit-impulse response
h(t) to an input x(t) is the same as the output of another system with the unit-impulse
response x(t) to an input h(t). The commutative property, in conjunction with some
others (such as the differentiation property, to be presented shortly by Example 4.20),
can facilitate and simplify the analysis of LTI systems.
Example
4.17
The unit-impulse response of an LTI system is cos(2π f t)u(t), where f is an integer.
Find its response to the pulse u(t) −u(t −1).
Solution
The above response is the same as that of an LTI system with an input cos(2π f t)u(t),
where f is an integer, and the unit-impulse response u(t)−u(t −1). The input-output
relationship for the second system is
y(t) =
 t
−∞
[x(τ) −x(τ −1)] dτ
For x(t) = cos(2π f t)u(t) we get
y(t) = sin(2π f t)
2π f

u(t) −u(t −1)

Distributive Property
According to this property,
x(t) ⋆[h1(t) + h2(t)] = x(t) ⋆h1(t) + x(t) ⋆h2(t)
This is the linearity property of the convolution integral. It expresses the parallel
operation of two LTI systems with unit-impulse responses h1(t) and h2(t) and their
equivalence to an LTI system whose unit-impulse response is h(t) = h1(t) + h2(t).
Example
4.18
Use the result of Example 4.17 to ﬁnd y(t) = h(t) ⋆x(t), where h(t) = u(t) −2u
(t −1) + u(t −2), x(t) = cos(2π f t)u(t), and f is an integer.

224
CHAPTER 4
Superposition, Convolution, and Correlation
Solution
Let h1(t) = u(t)−u(t−1).Then, h(t) = h1(t)−h1(t−1)and y(t) = y1(t)−y1(t−1).
From Example 4.17 we have
y1(t) = sin(2π f t)
2π f

u(t) −u(t −1)

Therefore,
y(t) = sin(2π f t)
2π f

u(t) −2u(t −1) + u(t −2)

Alternative Solution
Let
h0(t) = u(t),
y0(t) = h0(t) ⋆x(t) = sin(2π f t)
2π f
u(t)
Then,
h(t) = h0(t) −2h0(t −1) + h0(t −2),
y(t) = y0(t) −2y0(t −1) + y0(t −2)
= sin(2π f t)
2π f

u(t) −2u(t −1) + u(t −2)

Associative Property
According to this property,
x(t) ⋆[h1(t) ⋆h2(t)] = [x(t) ⋆h1(t)] ⋆h2(t)
The proof can be derived directly from the deﬁnition of convolution. The associative
property provides an alternative method for obtaining the output of the cascade of two
LTI systems with unit-impulse responses h1(t) and h2(t). Either convolve the input x(t)
with the result of the convolution of h1(t) and h2(t), or convolve the input with h1(t)
ﬁrst and then convolve the result with h2(t). Alternatively, one can interchange the order
of h1(t) and h2(t) and the output remains the same.
Example
4.19
Find y(t) = x(t) ⋆h1(t) ⋆h2(t), where x(t) = cos(ω0t), h1(t) = ae−atu(t), h2(t) =
δ(t) −h1(t) and ω0 = a.
Solution
First obtain
z1(t) = x(t) ⋆h1(t) =
 t
−∞
ae−a(t−τ) cos(ω0τ)dτ = (
√
2/2) cos(ω0t −π/4)
Then ﬁnd
y(t) = z1(t) ⋆h2(t) = z(t) ⋆δ(t) −z(t) ⋆h1(t)
= (
√
2/2) cos(ω0t −π/4) −0.5 cos(ω0t −π/2) = 0.5 cos(ω0t)

Signals and Systems
225
Alternative Solution
First obtain
z2(t) = x(t) ⋆h2(t) = cos(ω0t) −
 t
−∞
ae−a(t−τ) cos(ω0τ)dτ
= cos(ω0t) −(
√
2/2) cos(ω0t −π/4)
Then ﬁnd
y(t) = z2(t) ⋆h1(t)
= (
√
2/2) cos(ω0t −π/4) −0.5 cos(ω0t −π/2) = 0.5 cos(ω0t)
Comment
The above solution is performed in the time domain. A frequency domain solution of
this problem provides an easier, more intuitive, and elegant approach.
Other Properties of Convolution
In addition to the algebraic properties given above, other properties arising from the
LTI nature of the convolution integral (such as the differentiation, integration, and
shift properties) may help in obtaining the output of an LTI system and provide insight
into the systems’ synthesis and design. For example, consider an LTI system with
the unit-impulse response h(t) and an input x(t) that produces the output y(t). Then
from the differentiation property of LTI systems,
dx(t)
dt
⇒
dy(t)
dt
Example
4.20
Find y(t) = h(t) ⋆x(t), where h(t) = cos(2π f t)u(t) and x(t) is the triangular pulse
x(t) =



t,
0 ≤t < 1
2 −t,
1 ≤t < 2
0,
elsewhere
shown in Figure 4.13(a). Assume f to be an integer.
0
1
x(t)
1
(a)
2
t
0
1
dx
dt
1
–1
(b)
2
t
(c)
1
1
0
2
t
–2
1
d2x
dt2
FIGURE 4.13 (For Example 4.20)

226
CHAPTER 4
Superposition, Convolution, and Correlation
Solution
Take the ﬁrst two derivatives of x(t). The second derivative is composed of impulses.
Convolve h(t) with the second derivative of x(t) and integrate the result twice.
dx
dt = u(t) −2u(t −1) + u(t −2)
See Figure 4.13(b).
d2x
dt2 = δ(t) −2δ(t −1) + δ(t −2)
See Figure 4.13(c).
d2y
dt2 = h(t) ⋆d2x
dt2 = h(t) ⋆

δ(t) −2δ(t −1) + δ(t −2)

= h(t) −2h(t −1) + h(t −2)
= cos(2π f t)u(t) −2 cos

2π f (t −1)

u(t −1) + cos

2π f (t −2)

u(t −2)
Since f is an integer, the phase delays become multiples of 2π and so
d2y
dt2 = cos(2π f t)

u(t) −2u(t −1) + u(t −2)

dy
dt = sin(2π f t)
2π f

u(t) −2u(t −1) + u(t −2)

y(t) = 1 −cos(2π f t)
(2π f )2

u(t) −2u(t −1) + u(t −2)

4.6
Filtering by Convolution
Filtering is a frequency selection operation. A ﬁlter allows signals within a frequency
band (passband) to pass and attenuates or blocks those within another band (stopband).
This may be performed by matching the signal with a template; for example, through
convolution or correlation. The method is called ﬁltering in the time domain. Here we
illustrate the ﬁltering operation in the time domain by two examples.
Example
4.21
A signal is composed of the sum of N sinusoids:
x(t) =
N

k=1
Ak sin(ωkt)
To extract a possible component at the frequency ω0, we convolve x(t) with h(t) =
sin ω0t. The convolution outcome is
y(t) = lim
T →∞
1
2T
 T
−T
h(τ)x(t−τ)dτ =
N

k=1
lim
T →∞
1
2T
 T
−T
Ak sin ω0τ sin ωk(t−τ)dτ

Signals and Systems
227
To evaluate the integral, we convert the product of sinusoids in the integrand to the
sum of two cosines
sin ω0τ sin ωk(t −τ) = 1
2

cos[(ω0 + ωk)τ −ωkt] −cos[(ω0 −ωk)τ + ωkt]

and examine the integrals. If ωk ̸= ω0 for k = 1, . . . , N, then all the integrals under
the summation become zero, resulting in y(t) = 0. On the other hand, if one of the
frequency components of x(t) (e.g., ω j) is equal to ω0, then
y(t) = lim
T →∞
1
2T
 T
−T
A j
2 sin ω0τ sin ω0(t −τ)dτ = −A j
2 cos(ω0t)
Example
4.22
Consider a 0.5-Hz periodic square wave x(t) with a DC value of 0.5 and base-to-peak
value of 0 to 1, where for one period
x(t) =

1,
0 ≤t < 1
0,
1 ≤t < 2
See Figure 4.14(a). To ﬁlter out frequencies other than 0.5 Hz, convolve x(t) with a
signal made of a single cycle of a 0.5-Hz sinusoid:
h(t) =

sin(πt),
0 ≤t < 2
0,
elsewhere
0.8
0
0.2
0.4
0.6
y(t)
–0.2
–0.4
–0.6
–0.8
–4
–3
–2
–1
0
1
2
3
4
1
x(t)
0
–3
–2
–1
0
1
Time (s)
Time (s)
(a)
2
3
4
5
1
0
–1
h(t)
–3
–2
–1
0
1
2
3
4
5
(b)
Time (s)
(c)
FIGURE 4.14 Convolving a 0.5-Hz square wave with a single cycle of a 0.5-Hz sinusoid extracts the principal harmonic
of the square wave. (a) A periodic 0.5-Hz square wave x(t). (b) A single cycle of a 0.5-Hz sinusoid h(t) = sin(πt)[u(t)−
u(t −2)]. (c) The convolution outcome y(t) = h(t) ⋆x(t) = −2
π cos(πt).

228
CHAPTER 4
Superposition, Convolution, and Correlation
See Figure 4.14(b). The convolution output is
y(t) =
 ∞
−∞
h(τ)x(t −τ)dτ =
 2
0
sin(πτ)x(t −τ)dτ
=

For 0 < t < 1 y(t) =
 t
0 sin(πτ)dτ +
 2
t+1 sin(πτ)dτ = −2
π cos(πt)
For 1 < t < 2 y(t) =

(t −1)0t sin(πτ)dτ = −2
π cos(πt)

= −2
π cos(πt) all t
The convolution outcome, y(t), is a 0.5-Hz sinusoid, as in Figure 4.14(c). Convolution
has ﬁltered the 0.5-Hz component (called the principal harmonic) of the square wave
signal. The step-by-step evaluation of the above integral is given in problem 6.
The ﬁltering operations in Examples 4.21 and 4.22 were done by convolution. They
used representations of the signals in the time domain and, therefore, are called time-
domain ﬁlterings. Filtering may also be performed by representing the signal through its
frequency components and then either selecting the desired or rejecting the undesired
ones. This method is called ﬁltering in the frequency domain. A signal’s representation
in the frequency domain provides a parallel path for signal analysis, which computa-
tionally can become much more efﬁcient than in the time domain. Frequency-domain
representation of signals is introduced in Chapters 7 and 8.
4.7
Matched Filter
The convolution η(t)⋆η(T −t) concentrates the energy of the signal at t = T and is called
a matched ﬁlter. If the signal is corrupted by noise, the ﬁlter maximizes the ratio of the
signal to the noise at the output. In that sense, the ﬁlter is optimum. This section presents
the concept in detail. Further practice and exploration of the matched ﬁlter operation is
given in the project at the end of the present chapter.
Let η(t) be a continuous-time signal with a ﬁnite duration (from 0 to T ). Outside that
period η(t) = 0. Consider an LTI system with the unit-impulse response h(t) = η(T −t).
The unit-impulse response is constructed by time-reversing η(t) and shifting it to the
right by T units. Pass the signal through the system (where the ﬁlter is matched to the
signal; hence, a matched ﬁlter) and examine the ﬁlter’s output.
The output is
y(t) = η(t)⋆h(t) =
 t
0
η(τ)h(t −τ)dτ
But,
h(t) = η(T −t)
Therefore,
y(t) =
 t
0
η(τ)η[T −(t −τ)]dτ

Signals and Systems
229
At, t = T
y(T ) =
 T
0
|η(τ)|2τ
The ﬁlter’s output at t = T is the energy in the signal. It may be shown that it is the
maximum value of y(t).
Example
4.23
Let η(t) be a ﬁnite-duration continuous-time signal with amplitude ±1. Switching
between the ±1 levels may occur only at multiples of θ seconds, where θ is the bit
duration.
a.
Consider the η(t) shown in Figure 4.15(a) with seven bits, each bit being
1 second long (θ = 1). Take an LTI system whose unit-impulse response is
constructed by time-reversing η(t) and shifting it to the right by T = 7θ. The
unit-impulse response obtained by these operations will be h(t) = η(T −t),
where T = 7θ. Find the outcome of the convolution y(t) = η(t) ⋆h(t).
b.
Repeat for the 13-bit long signal
η(t) = {1
↑, 1, 1, 1, 1, −1, −1, 1, 1, −1, 1, −1, 1}.
1
0
–1
0
1
2
3
Time (s)
Time (s)
(a)
η(t)
(n = 7)
η(t)
(n = 13)
y(t)
(n = 13)
(b)
Time (s)
Time (s)
(c)
(d)
4
5
6
7
1
0
–1
0
1
2
3
4
5
6
7
8
9
10 11 12 13
8
6
4
2
0
–2
–7 –6 –5 –4 –3 –2 –1
0
1
5
4
3
2
6
7
14
12
10
6
8
2
4
–2
0
–12–10 –8 –6 –4 –2
0
2
4
6
8
10 12
y(t)
(n = 7)
FIGURE 4.15 (a) A seven-segment signal. (b) Filter’s output matched to the seven-segment signal. (c) A 13-segment
signal. (d) Filter’s output matched to the 13-segment signal.

230
CHAPTER 4
Superposition, Convolution, and Correlation
Solution
The signal can be speciﬁed by its samples η(nθ) and for simplicity, be represented in
discreteformasη(n) = {1
↑, 1, 1, −1, −1, 1, −1}.Similarly,theunit-impulseresponse
may be represented by h(n) = {−1
↑, 1, −1, −1, 1, 1, 1}. Since η(t) and h(t) are
constants during any interval nθ < t < (n + 1)θ, the ﬁlter’s output will be piecewise
linear (see Example 4.14). We, therefore, ﬁrst evaluate samples of the ﬁlter output
y(t) at t = nθ, −∞< n < ∞.
y(t) =
∞

τ=−∞
η(τ)h(t −τ)dτ =











 t
0 η(τ)h(t −τ)dτ,
0 < t < T
 T
t−T η(τ)h(t −τ)dτ,
T < t < 2T
0,
elsewhere
y(nθ) =
∞

k=−∞
η(kθ)h(nθ −kθ)θ
y(n) =
∞

k=−∞
η(k)h(n −k) =











n
0 η(k)h(n −k),
0 < n < 7
7
n−7 η(k)h(n −k),
7 < n < 14
0,
elsewhere
y(n) is obtained by a convolution sum. Flip h(k) around the origin and shift it by
n units, then multiply term by term by η(k) and add up. You will have y(n). The
operation is shown in Table 4.6.
TABLE 4.6 Calculation of y(n) = 
η(k)h(n −k) for η(n) = {1
↑
, 1, 1, −1, −1, 1, −1}
←
k
→
−7
−6
−5
−4
−3
−2
−1
0
1
2
3
4
5
6
η(k)
⇒
0
0
0
0
0
0
0
1
1
1
−1
−1
1
−1
h(k)
→
0
0
0
0
0
0
0
−1
1
−1
−1
1
1
1
0
h(−k)
→
1
1
1
−1
−1
1
−1
0
0
0
0
0
0
0
y(0) = 0
1
h(1 −k)
→
0
1
1
1
−1
−1
1
−1
0
0
0
0
0
0
y(1) = −1
2
h(2 −k)
→
0
0
1
1
1
−1
−1
1
−1
0
0
0
0
0
y(2) = 0
3
h(3 −k)
→
0
0
0
1
1
1
−1
−1
1
−1
0
0
0
0
y(3) = −1
4
h(4 −k)
→
0
0
0
0
1
1
1
−1
−1
1
−1
0
0
0
y(4) = 0
5
h(5 −k)
→
0
0
0
0
0
1
1
1
−1
−1
1
−1
0
0
y(5) = −1
↑
6
h(6 −k)
→
0
0
0
0
0
0
1
1
1
−1
−1
1
−1
0
y(6) = 0
n
7
h(7 −k)
→
0
0
0
0
0
0
0
1
1
1
−1
−1
1
−1
y(7) = 7
↓
8
h(8 −k)
→
0
0
0
0
0
0
0
0
1
1
1
−1
−1
1
y(8) = 0
9
h(9 −k)
→
0
0
0
0
0
0
0
0
0
1
1
1
−1
−1
y(9) = −1
10
h(10 −k)
→
0
0
0
0
0
0
0
0
0
0
1
1
1
−1
y(10) = 0
11
h(11 −k)
→
0
0
0
0
0
0
0
0
0
0
0
1
1
1
y(11) = −1
12
h(12 −k)
→
0
0
0
0
0
0
0
0
0
0
0
0
1
1
y(12) = 0
13
h(13 −k)
→
0
0
0
0
0
0
0
0
0
0
0
0
0
1
y(13) = −1
14
h(14 −k)
→
0
0
0
0
0
0
0
0
0
0
0
0
0
0
y(10) = 0

Signals and Systems
231
Three sample calculations are given below:
y(3) = (1)(−1) + (1)(1) + (1)(−1) = −1
y(7) = (1)(1) + (1)(1) + (1)(1) + (−1)(−1) + (−1)(−1) + (1)(1) + (−1)(−1) = 7
y(10) = (−1)(1) + (−1)(1) + (1)(1) + (−1)(−1) = 0
Because η(t) is a constant during any interval nT < t < (n + 1)T , the ﬁlter’s output is
piecewise linear. Note that the ﬁlter output is at a maximum when n = 7. The ﬁlter has
integrated the energy of the signal and placed it at the output at t = T . At other times,
the ﬁlter’s output is low. See Figure 4.15(b).
The 13-bit long signal η(t) = {1
↑, 1, 1, 1, 1, −1, −1, 1, 1, −1, 1, −1, 1} and the
result of passing it through a ﬁlter matched to it are shown in Figure 4.15(c) and d,
respectively. The maximum output is 13 and it occurs at t = T .
Repeat the above procedure for a code of length 15,
η(t) = {1
↑, 1, 1, −1, −1, −1, −1, 1, −1, 1, −1, −1, 1, 1, −1}.
4.8
Deconvolution
Convolution of x(t) and h(t) produces y(t). Can one reverse the operation, obtaining
h(t) from x(t) and y(t)? In other words, can one extract the unit-impulse response of an
LTI system from an input-output pair? The answer is yes, and one does so through an
operation called deconvolution. It reverses the effect of the convolution and, therefore, is
closely related to the inverse of the system. Here we illustrate the deconvolution concept
by an example in which the functions involved change their values at unit-time steps,
resulting in a convolution sum. More discussion and examples on these topics will be
provided in Chapters 9 and 18.
Example
4.24
An input-output pair x1, y1 for a causal LTI system is given by
x1 = {1
↑, −1} →y1 = {1
↑, −1, 1}
in Figure 4.16(a). Find the response of the system to the unit pulse d(t) = u(t) −u
(t −1) and call it ˆh(t). Then use ˆh(t) to ﬁnd the response to the input x2 = u(t) −
u(t −2).
Solution
Since time is discrete, we designate it by the integer variable n. Then the unit pulse
d(t) = u(t) −u(t −1) is represented by d(n) as shown in Figure 4.15(b). Let ˆh(n)
be the response to d(n). Then,
x2(n) = d(n) + d(n −1)
y2(n) = ˆh(n) + ˆh(n −1)

232
CHAPTER 4
Superposition, Convolution, and Correlation
(a)
(b)
(c)
0
1
2
t
1
x1(t)
–1
1
0
t
1
d(t)
0
1
2
t
1
x2(t)
0
1
2
3
t
1
y1(t)
–1
0
1
3
2
4
5
t
t
0
1
3
2
4
5
1
2
y2(t)
1
2
h(t)
ˆ
FIGURE 4.16 Deconvolutionofthegiveninput-outputpairin(a)providestheresponse
to the unit pulse (b) which is used to construct the reponse to x2 (c).
From the known pair x1(n) and y1(n) we search for ˆh(n).
x1(n) = d(n) −d(n −1)
y1(n) = ˆh(n) −ˆh(n −1)
ˆh(n) = y1(n) + ˆh(n −1), n ≥0, and ˆh(n) = 0, n < 0
By successive application of the above rule, ˆh(n) may be found to be as shown in
Table 4.7.
TABLE 4.7 Finding ˆh(n) by Successive Calculations
n
x1(n)
y1(n)
ˆh(n −1)
ˆh(n) = y1(n) + ˆh(n −1)
−1
0
0
0
0
0
1
1
0
1
1
−1
−1
1
0
2
0
1
0
1
3
0
0
1
1
4
0
0
1
1
...
...
...
...
...

Signals and Systems
233
Now we ﬁnd y2(n) as shown in Table 4.8.
TABLE 4.8 Finding y(n) by Successive Calculations
n
x2(n) = d(n) + d(n −1)
y2(n) = ˆh(n) + ˆh(n −1)
−1
0
0
0
1
1
1
1
1
2
0
1
3
0
2
4
0
2
...
...
...
The result is y2(t) = {1
↑, 1, 1, 2, 2, · · ·}.
Alternative Solution
In this example, x2(t) may be obtained by superposition of time-shifted x1(t) func-
tions, allowing a direct construction of y2(t) from y1(t).
x2(t) =
∞

k=0
(k+1)x1(t −k)
⇒
y2(t) =
∞

k=0
(k+1)y1(t −k) = {1
↑, 1, 1, 2, 2, · · ·}
4.9
Autocorrelation
The autocorrelation function, rxx(τ), of an energy signal x(t) is deﬁned by
rxx(τ) =
 ∞
−∞
x(t)x(t −τ)dt, −∞< τ < ∞
For a power signal the autocorrelation is given by
rxx(τ) = lim
T →∞
1
2T
 T
−T
x(t)x(t −τ)dt, −∞< τ < ∞
It is seen that autocorrelation is an even function: rxx(τ) = rxx(−τ).

234
CHAPTER 4
Superposition, Convolution, and Correlation
Example
4.25
Find the autocorrelation of the energy signal x(t) = e−tu(t).
Solution
rxx(τ) =
 ∞
−∞
x(t)x(t −τ)dt
=
 ∞
−∞

e−tu(t)
 
e−(t−τ)u(t −τ)

dt = eτ
 ∞
0
e−2tu(t −τ)dt
τ < 0,
rxx(τ) = eτ
 ∞
0
e−2tdt = 1
2eτ
τ > 0,
rxx(τ) = eτ
 ∞
τ
e−2tdt = 1
2e−τ
Hence,
rxx(τ) = 1
2e−|τ|
for −∞< τ < ∞
Example
4.26
Find the autocorrelation of the power signal x(t) = cos 2πt.
Solution
rxx(τ) = lim
T →∞
1
2T
 T
−T
cos 2πt cos 2π(t −τ)dt
= lim
T →∞
1
4T
 T
−T
[cos 2π(2t −τ) + cos 2πτ] dt = 1
2 cos(2πτ)
Example
4.27
An early correlator
A tape recorder running at the speed of v cm/sec with two playback heads placed at
a distance of d cm from each other produces a signal x(t) and its delayed version
x(t −τ), where τ = d/v. By employing a multiplier and an integrator one can build
a device to estimate the autocorrelation of x(t) deﬁned by
rxx(τ) = lim
T →∞
1
2T
 T
−T
x(t)x(t −τ)dt
The physical settings for d may need to be adjusted for each desired time shift τ
with the data played back at each new setting. By practical necessity, the duration of
integration will be ﬁnite, resulting in an estimation:
rxx(τ) ≈1
2T
 T
−T
x(t)x(t −τ)dt

Signals and Systems
235
Similar practical limitations apply when the correlation is obtained by numerical
computation. In that case, the limiting factor is computation time. Another factor will
be the ﬁnite length of the data available for computation. In the latter case, T (and
τ) in the above integral will be chosen such that x(t) and x(t −τ) exist during the
integration period.
A parallel formulation is employed to ﬁnd the autocorrelation of a discrete-time
signal. It uses summation rather than integration:
rxx(k) ≈
1
(2M + 1)
M

n=−M
x(n)x(n −k)
k is the amount of shift and 2M + 1 is the data length over which the summation
operation is performed. If the mean value of x(n) is excluded from summation, the
result is called the covariance function of the signal. An estimate of the covariance
function is given by
Covxx(k) ≈
1
(2M + 1)
M

n=−M
[x(n) −X][x(n −k) −X]
where
X =
1
(2M + 1)
M

n=−M
x(n)
is an estimate of the mean value of x(n). If ﬁnite data of size N is available, an
unbiased estimate of the covariance function is obtained from
Covxx(k) ≈
1
(N −k)
N−k

n=0
[x(n) −X][x(n + k) −X], Covxx(k) = Covxx(−k)
Examples 4.28 and 4.29 illustrate two such cases.
Example
4.28
Obtain and plot the covariance function for the number of annual sunspots.
Solution
The time series of annual sunspot numbers for the years 1700–2010 (Figure 4.17a,
also Figure 1.1 in Chapter 1) has 305 data points. An estimate of the covariance as a
function of the shift k ≥0 is given by
Covxx(k) ≈
1
(305 −k)
305−k

n=0
[x(n) −X][x(n + k) −X]
The estimation error increases as k in the above summation is increased. Covxx(k)
is computed for 0 ≤k ≤150 and plotted in Figure 4.17(b). As expected, the plot

236
CHAPTER 4
Superposition, Convolution, and Correlation
Yearly sunspot numbers from  1700 to 2010
50
0
100
150
200
250
300
0
20
40
60
80
100
120
140
160
180
200
Year (from 1700 through 2010)
(a)
(b)
Mean annual number of sunspots
−150
−100
−50
0
50
100
150
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Year
Normalized Cov
Normalized autocorrelation of yearly sunspot numbers
FIGURE 4.17 (a) Annual sunspot numbers for the years 1700–2010 and (b) unbiased estimate of its covariance function.
Source: 4.17 (a) NOAA’s National Geophysical Data Center (NGDC) at www.ngdc.noaa.gov.
of Figure 4.17(b) is an even function. It shows periodicity of the data with a period
of about 10 years. The waxing and waning of the numbers over a 100-year period is
also reﬂected in the envelope of the covariance function.
Note: Problem 7 contains the Matlab code for the numerical evaluations and plots in
this example.
Example
4.29
Find the covariance function of monthly and yearly rates of unemployment in the
United States. The unemployment rate is deﬁned by the U.S. Labor Department as
a percentage of the labor force aged 16 years and above. The data is available at
www.bls.gov/data/.
Solution
Monthly unemployment rates from January 1968 through December 2010 (a total
of 516 months) and an unbiased estimate of their covariance function are plotted
in Figure 4.18(a). Yearly unemployment rates from 1940 through 2009 (a total
of 70 years) and an unbiased estimate of their covariance function are plotted in
Figure 4.18(b). In both cases the main lobes in the covariance functions indicate
a correlation between successive data points (monthly and yearly) which gradually
diminishes with the time lapse between them. The periodicity of annual rates (1940–
2010) is reﬂected as periodicity in the covariance function.

Signals and Systems
237
50
100 150 200 250 300 350 400 450 500
0
2
4
6
8
10
12
14
16
18
20
Month
Unemployment rate, in percentage
Monthly Plot of Unemployment in U.S., 1968–2010
(a)
(b)
−150
−100
−50
0
50
100
150
−1
−0.5
0
0.5
1
1.5
2
2.5
3
Month 
Covariance
Covariance of Unemployment in U.S., 1968−2010
1940
1950
1960
1970
1980
1990
2000
2010
0
5
10
15
Year
Unemployment rate, in percentage
Yearly Rate of Unemployment in U.S., 1940–2009
−30
−20
−10
0
10
20
30
−1
0
1
2
3
4
Year
Covariance
Covariance of Unemployment in U.S., 1940−2009
FIGURE 4.18 (a) Monthly U.S. unemployment rate for January 1968 through December 2010 and its covariance.
(b) Annual U.S. unemployment rate for 1940 through 2009 and its covariance.
Source: Bureau of Labor Statistics, http://data.bls.gov.
Note: Problem 8 contains the Matlab code for the numerical evaluations and plots in
this example.
4.10
Cross-Correlation
The cross-correlation function rxy(τ) between two energy signals x(t) and y(t) is de-
ﬁned by
rxy(τ) =
 ∞
−∞
x(t)y(t −τ)dt, −∞< τ < ∞
For power signals we scale the integral:
rxy(τ) = lim
T →∞
1
2T
 T
−T
x(t)y(t −τ)dt, −∞< τ < ∞

238
CHAPTER 4
Superposition, Convolution, and Correlation
It is seen that rxy(τ) = ryx(−τ). As in the autocorrelation operation, one of the signals
is shifted, multiplied by the other, and then integrated.
Example
4.30
Find the cross-correlations rxy(τ) and ryx(τ), where x(t) = cos t and y(t) = e−tu(t).
Show that rxy(τ) = ryx(−τ).
Solution
rxy(τ) =
 ∞
−∞
x(t)y(t −τ)dt =
 ∞
−∞
cos t

e−(t−τ)u(t −τ)

dt
= eτ
 ∞
τ
e−t cos tdt = 1
2(cos τ −sin τ)
ryx(τ) =
 ∞
−∞
y(t)x(t −τ)dt =
 ∞
−∞

e−tu(t)

cos(t −τ)dt
=
 ∞
0
e−t cos(t −τ)dt = 1
2(cos τ + sin τ)
rxy(τ) = ryx(−τ)
Correlation operations enhance similarities within a signal or between two signals.
The autocorrelation exposes periodicities in signals that are weak, are masked by
other features, or are embedded in noise and disturbances. This is because shifting
a periodic signal by multiples of its period reverts the signal to the original form
and creates a periodic component in the correlation function (with the same period).
Similarly, the cross-correlation between two signals serves as a method for matching
a signal with a template. It is, therefore, used to detect signals of interest embedded
in noise and hence the method is called correlation detection.
Example
4.31
Let a signal be composed of the sum of N sinusoids:
x(t) =
N

k=1
sin(ωkt)
Each ωk is a ﬁxed but unknown frequency. To ﬁnd out if the signal contains a certain
frequency ω0, we cross-correlate x(t) with h(t) = sin ω0t at zero shift.
rxh(0) = lim
T →∞
1
2T
 T
−T
x(t) sin(ω0t)dt = lim
T →∞
1
2T
N

k=1
 T
−T
sin(ω0t) sin(ωkt)dt
= lim
T →∞
1
4T
N

k=1
 T
−T

cos(ω0 −ωk)t −cos(ω0 + ωk)t

dt ≈
 1
2
if ωk = ω0
0
if ωk ̸= ω0
A nonzero output indicates the presence of the ω0 component in x(t).

Signals and Systems
239
Example
4.32
Cross-covariance between unemployment rates in
the United States and in California
Monthly unemployment rates in California and the rest of the United States from
1976 through 2010 are plotted in Figure 4.19(a) Obtain an unbiased estimate of their
cross-covariance function and plot it.
Solution
An unbiased estimate of the cross-covariance function for a ﬁnite data of size N is
obtained from
Xcovxy(k) ≈
1
(N −k)
N−k

n=0

x(n) −X
 
x(n −k) −X

,
Xcovxy(k) = Xcovyx(−k)
Inthepresentcase, N = 420.Thecross-covariancefunctionsXcovxy(k)andXcovyx(k),
where x and y are monthly unemployment rates for California and the United States
respectively, are shown in Figure 4.19(b), with a maximum shift of 150. The rates in
California and in the United States are strongly correlated. Note that Xcovxy(k) =
Xcovyx(−k).
50
100
150
200
250
300
350
400
3
4
5
6
7
8
9
10
11
12
13
Month (from January 1976 through December 2010)
(a)
(b)
Rate (percent)
Monthly Rate of Unemployment in CA and US
CA
US
−150
−100
−50
0
50
100
150
−1
−0.5
0
0.5
1
1.5
2
2.5
3
Month 
Xcov
Xcov(US, CA) and Xcov(CA, US)
Xcov(US, CA) 
Xcov(CA, US)
FIGURE 4.19 (a) Plot of monthly unemployment rates in California and in the United States from 1976 through 2010
and (b) their cross-covariance functions.
Source: 4.19 (a) Bureau of Labor Statistics, http://data.bls.gov.
Note: Problem 9 contains the Matlab code for the numerical evaluations and plots in
this example.

240
CHAPTER 4
Superposition, Convolution, and Correlation
4.11
Correlation and Convolution
Convolution and correlation are two related operations. The autocorrelation function of
an energy signal x(t) is deﬁned by
rxx(t) =
 ∞
−∞
x(τ)x(τ −t)dτ, −∞< τ < ∞
In section 4.7 the ﬁlter matched to an energy signal x(t) was deﬁned by its impulse
response h(t) = x(T −t). Here we will show that the output of the matched ﬁlter is
the autocorrelation of x(t) shifted to the right by T seconds. The output of the matched
ﬁlter to the input x(t) is
y(t) =
 ∞
−∞
x(t −τ)h(τ)dτ =
 ∞
−∞
x(t −τ)x(T −τ)dτ = rxx(t −T )
The matched ﬁlter takes the autocorrelation of the signal. A detector based on a matched
ﬁlter (as in the project at the end of the present chapter) is, therefore, called a correlation
detector.
Example
4.33
For an energy signal that can be represented in discrete form as η(n), the autocorre-
lation is given by
rηη(n) =
∞

k=−∞
η(k)η(k −n)
Find the autocorrelation function of η(n) = {1
↑, 1, 1, −1, −1, 1, −1} and compare
with the output of the matched ﬁlter in Example 4.23.
Solution
Shift η(k) by n units (to the left or right) to ﬁnd η(k −n). Then multiply by η(k) term
by term and add up. You will then have rηη(n). The operation is shown in Table 4.9.
Three sample calculations are given below:
rηη(−4) = (1)(−1) + (1)(1) + (1)(−1) = −1
rηη(0) = (1)(1) + (1)(1) + (1)(1) + (−1)(−1) + (−1)(−1)
+ (1)(1) + (−1)(−1) = 7
rηη(3) = (−1)(1) + (−1)(1) + (1)(1) + (−1)(−1) = 0

Signals and Systems
241
TABLE 4.9 Calculation of rηη(n) = 
η(k)η(k −n)
←
k
→
−7
−6
−5
−4
−3
−2
−1
0
1
2
3
4
5
6
η(k)
⇒
0
0
0
0
0
0
0
1
1
1
−1
−1
1
−1
−7
η(k + 7)
→
1
1
1
−1
−1
1
−1
0
0
0
0
0
0
0
rηη(−7) = 0
−6
η(k + 6)
→
0
1
1
1
−1
−1
1
−1
0
0
0
0
0
0
rηη(−6) = −1
−5
η(k + 5)
→
0
0
1
1
1
−1
−1
1
−1
0
0
0
0
0
rηη(−5) = 0
−4
η(k + 4)
→
0
0
0
1
1
1
−1
−1
1
−1
0
0
0
0
rηη(−4) = −1
−3
η(k + 3)
→
0
0
0
0
1
1
1
−1
−1
1
−1
0
0
0
rηη(−3) = 0
−2
η(k + 2)
→
0
0
0
0
0
1
1
1
−1
−1
1
−1
0
0
rηη(−2) = −1
↑
−1
η(k + 1)
→
0
0
0
0
0
0
1
1
1
−1
−1
1
−1
0
rηη(−1) = 0
n
0
η(k)
→
0
0
0
0
0
0
0
1
1
1
−1
−1
1
−1
rηη(0) = 7
↓
1
η(k −1)
→
0
0
0
0
0
0
0
0
1
1
1
−1
−1
1
rηη(1) = 0
2
η(k −2)
→
0
0
0
0
0
0
0
0
0
1
1
1
−1
−1
rηη(2) = −1
3
η(k −3)
→
0
0
0
0
0
0
0
0
0
0
1
1
1
−1
rηη(3) = 0
4
η(k −4)
→
0
0
0
0
0
0
0
0
0
0
0
1
1
1
rηη(4) = −1
5
η(k −5)
→
0
0
0
0
0
0
0
0
0
0
0
0
1
1
rηη(5) = 0
6
η(k −6)
→
0
0
0
0
0
0
0
0
0
0
0
0
0
1
rηη(6) = −1
7
η(k −7)
→
0
0
0
0
0
0
0
0
0
0
0
0
0
0
rηη(7) = 0
The autocorrelation function is at a maximum when n = 0; that is, with no shift, when
theoperationintegratestheenergyofthesignal.Notetheclosecorrespondence,except
for a shift of 7 units, between Tables 4.6 and 4.9, resulting in y(n) = rηη(n −7).
4.12
Concluding Remarks
In theory, convolution is a mathematical operation deﬁned by equation (1) at the begin-
ning of this chapter. It can be applied routinely, as it requires no more than an introductory
course in calculus. The same observation applies to correlation operations. In practice,
however, applying the convolution or correlation integrals to signals of common interest
(especially those which are sectionwise continuous, discontinuous, or contain singular-
ity functions) may become a challenge that can only be overcome by a conceptual and
intuitive understanding of the operation. This chapter has attempted to present a bal-
anced mix of theoretical and conceptual understandings of the topic and illustrate those
through many examples. A point of departure from theory often is the fact that in many
practical situations the signals involved are given in the form of tabular data and not as
analytic functions. In such situations, computers become vital tools. The data needs to
be read in, a computer program needs to evaluate the convolution/correlation integral,
and the result needs to be plotted and stored. Several examples and solved problems that
use Matlab programs are provided to help the student with an introductory experience
in this area. The project included in this chapter offers further practice and explorations
in signal detection by convolution and correlation.

242
CHAPTER 4
Superposition, Convolution, and Correlation
4.13
Problems
Solved Problems
1. The unit-impulse response of an LTI system is d(t) = u(t) −u(t −1). Find and plot its output for the periodic
input x(t), where, for one period T
a. x1(t) =

2,
0 ≤t < 1
0,
1 ≤t < 6
Period T = 6
b. x2(t) =

3,
0 ≤t < 1
−1,
1 ≤t < 2
Period T = 2
Hint: Use the graphical method.
Solution
a. Express x1(t) in terms of d(t) so that
x1(t) =
∞

k=−∞
2d(t −6k)
Let
ζ(t) = d(t) ⋆d(t) =
 t,
0 ≤t < 1
2 −t,
1 ≤t < 2
0,
elsewhere
Then,
y1(t) =
∞

k=−∞
2ζ(t −6k) =
 2t,
0 ≤t < 1
4 −2t,
1 ≤t < 2
0,
2 ≤t < 6
Period T = 6
(a)
0
1
t
1
2
*
0
1
1
t
0
1
t
1
2
2
*
0
1
2
3
4
5
6
7
8
t
2
2
0
1
2
3
4
5
6
7
8
t
2
0
1
2
t
FIGURE 4.20(a) Graphical solution to problem 1 (a).
b. Let
η(t) = 3d(t) −d(t −1) and ξ(t) = η(t) ⋆d(t) =





3t,
0 ≤t < 1
7 −4t,
1 ≤t < 2
t −3,
2 ≤t < 3
0,
elsewhere
Then,
x2(t) =
∞

k=−∞
η(t−2k) and y2(t) =
∞

k=−∞
ξ(t−2k) =

−1 + 4t,
0 < t < 1
7 −4t,
1 < t < 2 Period T = 2. See Figure 4.20(b).

Signals and Systems
243
(b)
0
1
t
1
3
*
0
1
t
0
1
0
1
t
1
*
–1
0
1
2
3
4
5
6
7
8
t
t
3
3
0
1
2
t
3
3
–1
3
t
1
*
t
–1
–1
0
1
t
1
*
t
t
0
1
2
3
4
5
6
7
8
9
FIGURE 4.20(b) Graphical solution to problem 1 (b).
2. Find y(t) = x(t) ⋆h(t), where
a. h(t) = e−3tu(t) and x(t) = 1
b. h(t) = e−3tu(t) and x(t) = u(t −2)
c. h(t) = e−3tu(t) and x(t) = e−tu(−t)
d. h(t) = δ(t −2) + u(t) and x(t) = (cos t)u(t)
Solution
a. h(t) = e−3tu(t), x(t) = 1
y(t) =

∞
−∞
x(τ)h(t −τ)dτ =

t
−∞
e−3(t−τ)dτ = e−3t

t
−∞
e3τdτ = 1
3
Alternatively,
y(t) =

∞
−∞
h(τ)x(t −τ)dτ =

∞
0
e−3τdτ = 1
3
b. h(t) = e−3tu(t), x(t) = u(t −2)
y(t) =

∞
−∞
x(τ)h(t −τ)dτ =

t
2
e−3(t−τ)dτ = 1
3[1 −e−3(t−2)]u(t −2)
Alternatively,
y(t) =

∞
−∞
h(τ)x(t −τ)dτ =

t−2
0
e−3τdτ = 1
3[1 −e−3(t−2)]u(t −2)

244
CHAPTER 4
Superposition, Convolution, and Correlation
c. h(t) = e−3tu(t), x(t) = e−tu(−t)
y(t) =

∞
−∞
x(τ)h(t −τ)dτ =
 t
−∞e−3(t−τ)e−τdτ = 1
2e−t
t < 0
 0
−∞e−3(t−τ)e−τdτ = 1
2e−3t
t > 0
Alternatively,
y(t) =

∞
−∞
h(τ)x(t −τ)dτ =
 ∞
0 e−3τe−(t−τ)dτ = 1
2e−t
t < 0
 ∞
t
e−3τe−(t−τ)dτ = 1
2e−3t
t > 0
d.
h(t) = δ(t −2) + u(t), x(t) = (cos t)u(t)
y(t) = x(t −2) +

t
−∞
x(τ)dτ
= [cos(t −2)]u(t −2) +

t
0
(cos τ)dτ
= [cos(t −2)]u(t −2) + (sin t)u(t)
3. The response of an LTI system to u(t) is g(t) = 
2e−t −e−5t
u(t). Find its responses to
a. x(t) = δ(t)
b. x(t) = 1
c. x(t) =

t
−∞
u(τ)dτ
Solution
a. x(t) = δ(t)
⇒y(t) = d
dt g(t) = (5e−5t −2e−t)u(t) + (2e−t −e−5t)

t=0δ(t)
= (5e−5t −2e−t)u(t) + δ(t)
b. x(t) = 1
⇒y(t) = lim
t→∞g(t) = 0
c. x(t) =

t
−∞
u(τ)dτ ⇒y(t) =

t
−∞
g(τ)dτ =
	
t
0
(2e−τ −e−5τ)dτ

u(t)
= (1.8 −2e−t + 0.2e−5t)u(t)
4. The response of an LTI system to x(t) = u(t) is y(t) = e−2tu(t). Find its responses to
a. x(t) + x(t −2)
b. 3x(t −1) +

t
−∞
x(τ)dτ
c. dx(t −1)
dt
d. dx(t)
dt
+ x(t)
Solution
a. x(t) + x(t −2)
⇒y(t) = e−2tu(t) + e−2(t−2)u(t −2)
b. 3x(t −1) +

t
−∞
x(τ)dτ ⇒y(t) = 3e−2(t−1)u(t −1) +

t
0
e−2τdτ
= 3e−2(t−1)u(t −1) + 1
2

1 −e−2t
u(t)
c. dx(t −1)
dt
⇒y(t) = d
dt

e−2(t−1)u(t −1)
= −2e−2(t−1)u(t −1) + δ(t −1)
d. dx(t)
dt
+ x(t)
⇒y(t) = d
dt

e−2tu(t)
+ e−2tu(t)
= −2e−2tu(t) + e−2t
t=0δ(t) + e−2tu(t) = δ(t) −e−2tu(t)

Signals and Systems
245
5. Evaluate and plot the convolution integral y(t) = x(t) ⋆h(t), where
a. x(t) = sin(2πt)u(t) and h(t) = u(t)
b. x(t) = e−t/50u(t)
and h(t) = e−2tu(t)
c. x(t) = e−tu(−t)
and h(t) = e−2tu(t)
d. x(t) = etu(−t)
and h(t) = e−2tu(t)
e. x(t) = e−3tu(−t)
and h(t) = e−tu(t)
f. x(t) = e−|t|
and h(t) = e−t/5u(t)
Provide a sample Matlab code for the above operations.
Hint: Evaluate 
e−αtu(t)
⋆
e−βtu(t)
and 
e−αtu(−t)
⋆
e−βtu(t)
. In each case observe the condition(s) for the
existence of the integral.
Note 1. Convolution of two right-sided exponential functions.

e−αtu(t)

⋆

e−βtu(t)

=

∞
−∞

e−ατu(τ)

e−β(t−τ)u(t −τ)

dτ =

t
0
e−ατe−β(t−τ)dτ = e−αt −e−βt
β −α
u(t)
Note 2. Convolution of a left-sided and a right-sided exponential function. It exists only if α + β > 0.

eαtu(−t)
⋆
e−βtu(t)
=



 t
−∞eατe−β(t−τ)dτ =
eαt
α+β ,
t ≤0
 0
−∞eατe−β(t−τ)dτ =
e−βt
α+β ,
t ≥0
=
1
α + β

eαtu(−t) + e−βtu(t)
,
α + β > 0
Alternatively,

eαtu(−t)
⋆
e−βtu(t)
=



 ∞
0 e−βτeα(t−τ)dτ =
eαt
α+β ,
t ≤0
 ∞
t
e−βτeα(t−τ)dτ =
e−βt
α+β ,
t ≥0
=
1
α + β

eαtu(−t) + e−βtu(t)
,
α + β > 0
Note 3. Convolution of a two-sided and a right-sided exponential function. It exists only if α + β > 0.

e−α|t|
⋆
e−βtu(t)
= 
eαtu(−t)
⋆
e−βtu(t)
+ 
e−αtu(t)
⋆
e−βtu(t)
=
1
α + β

eαtu(−t) + e−βtu(t)
+ e−αt −e−βt
β −α
u(t)
=
eαt
α + β u(−t) +

2αe−βt
α2 −β2 + e−αt
β −α

u(t)
Solution
Answers to parts a to f and plots of y(t) are given below.
a. sin(2πt)u(t) ⋆u(t) = 0.159(1 −cos 2πt)u(t).
b. e−t/50u(t) ⋆e−2tu(t) = 0.5051
e−t/50 −e−2t
u(t).
c. e−tu(−t) ⋆e−2tu(t) = e−tu(−t) + e−2tu(t).
d. etu(−t) ⋆e−2tu(t) = 1
3[etu(−t) + e−2tu(t)].

246
CHAPTER 4
Superposition, Convolution, and Correlation
e. e−3tu(−t) ⋆e−tu(t) = ∞. (It doesn’t exist. However, a plot is produced by Matlab for a ﬁnite data segment.)
f. e−|t| ⋆e−t/5u(t) = etu(−t) ⋆e−t/5u(t) + e−tu(t) ⋆e−t/5u(t).
Here is the sample Matlab program:
%Part a, x(t)=sin(2pit) u(t), h(t)=u(t)
t=[-1:0.01:3.5];
x=0*t;
h=0;
z=0*t;
for i=100:450
x(i)=sin(2*pi*t(i));
h(i)=1;
end
figure(1)
y=conv(x,h)/100;
ty=-2:0.01:7-0.01;
plot(ty,y,'LineWidth',2)
grid
xlabel('Time (s)');
ylabel('Magnitude' );
title('Plot of
convolution y(t)=sin(2\pit)*u(t).');
axis([-1
3.5
-.1
.4])
6. Evaluate the convolution integral of Example 4.22 for t = 0 to 2 at incremental steps of 0.25 second each.
Solution
See Figure 4.21.
(a)























x(t) =

1,
0 < t < 1
0,
1 < t < 2 , x(t) = x(t −2).
h(t) =

sin(πt),
0 < t < 2
0,
elsewhere
y(t) =

h(τ)x(t −τ)dτ
−1
−0.5
0
0.5
1
1.5
(a)
2
2.5
3
−1
0
1
t
Magnitude
h(t)
FIGURE 4.21 Details of the convolution of a single cycle of a sinusoid h(t) with a square wave x(t). (a) h(t), x(t),
and their superimposed plots. Rows (b) to (j) show h(τ), x(t −τ), and their product for nine values of 0 ≤t ≤2, at
increments of 0.25. In each case, the convolution outcome is the area of the shaded region under the curve h(τ)x(t −τ).
Its numerical value is given for each t.

Signals and Systems
247
(b)











t = 0,
y =

h(τ)x(0 −τ)dτ
=
 2
1
sin(πt)dt = −2
π
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 0
(b)
(c)









t = 0.25,
y =

h(τ)x(0.25 −τ)dτ
=
 0.25
0
sin(πt)dt +
 2
1.25
sin(πt)dt = −
√
2
π
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 0.25
(c)
(d)











t = 0.5,
y =

h(τ)x(0.5 −τ)dτ
=
 0.5
0
sin(πt)dt +
 2
1.5
sin(πt)dt = 0
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 0.5
(d)
FIGURE 4.21 (Continued)

248
CHAPTER 4
Superposition, Convolution, and Correlation
(e)











t = 0.75,
y =

h(τ)x(0.75 −τ)dτ
=
 0.75
0
sin(πt)dt +
 2
1.75
sin(πt)dt =
√
2
π
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 0.75
(e)
(f)











t = 1,
y =

h(τ)x(1 −τ)dτ
=
 1
0
sin(πt)dt = 2
π
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 1
(f)
(g)









t = 1.25,
y =

h(τ)x(1.25 −τ)dτ
=
 1.25
0.25
sin(πt)dt =
√
2
π
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 1.25
(g)
FIGURE 4.21 (Continued)

Signals and Systems
249
(h)









t = 1.5,
y =

h(τ)x(1.5 −τ)dτ
=
 1.5
0.5
sin(πt)dt = 0
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 1.5
(h)
(i)









t = 1.75,
y =

h(τ)x(1.75 −τ)dτ
=
 1.75
0.75
sin(πt)dt = −
√
2
π
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 1.75
(i)
(j)









t = 2,
y =

h(τ)x(2 −τ)dτ
=
 2
1
sin(πt)dt = −2
π
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−1
0
1
t
Magnitude
h(t) x(t – t), t = 2
(j)
FIGURE 4.21 (Continued)

250
CHAPTER 4
Superposition, Convolution, and Correlation
7. Write Matlab code to read the annual sunspot numbers for the years 1700–2010, and compute and plot the covariance
function for them. See Example 4.28.
Solution
Obtain the time series of annual sunspot numbers for the years 1700–2010 and place it in a data ﬁle. [Source:
NOAA’s National Geophysical Data Center (NGDC) at www.ngdc.noaa.gov] In this problem we have called it
yearly−plt−ascii.dat. The following Matlab program loads the data, calculates its covariance, and plots it.
load yearly«plt«ascii.dat; A=yearly«plt«ascii; yearly«plt«sunspots=A;
save yearly«plt«sunspots -ascii;
m=1:1:length(A); figure(1); plot(m,A,'b','LineWidth',2); axis([1 length(A)
0 200]);
xlabel('Year (from 1700 through 2010)'); ylabel('mean annual number of
sunspots');
title('Sunspot numbers from 1700 to 2010.'); grid;
%
% Find autocorrelation of A and plot it.
maxlag=150; B=xcov(A,maxlag,'unbiased');
[c,lags]=xcov(A,150,'coeff');yearly«plt«sunspots«Xcorr=B;
save yearly«plt«sunspots«Xcorr -ascii;
figure(2); plot(lags,c,'m','LineWidth',2); axis([-maxlag maxlag -.6 1.2])
xlabel('Year '); ylabel('Normalized Cov'); title('Autocorrelation of
sunspot numbers.');
8. Write a Matlab program to load and plot the monthly (from January 1968 through December 2010) and yearly (from
1940 through 2009) rates of unemployment in the United States. Find and plot their autocovariance functions. The
data is available at www.bls.gov/data/. See Example 4.29.
Solution
load BLS«Data«US«Unemployment«1968«2010.dat;
A=BLS«Data«US«Unemployment«1968«2010;
BLS«USUnemp«1968«2010=A; save BLS«USUnemp«1968«2010 -ascii;
m=1:1:length(A); figure(1); plot(m,A,'b','LineWidth',2);
axis([1 length(A) 2 13]); grid;
%
% Find autocorrelation.
maxlag=150; E=xcov(A,maxlag,'unbiased'); [c,lags]=xcov(A,150,'unbiased');
BLS«USUnemp«1968«2010«XCORR«a=E; save BLS«USUnemp«1968«2010«XCORR«a -ascii;
figure(2); plot(lags,E,'m','LineWidth',2); axis([-maxlag maxlag -1.2 3.2])
grid;
%
load aat«all.txt; x=aat«all; z=x(1:71,10); E=z';
t = linspace(1940,2009,71); figure(3); plot(t,E); grid;
%
% Find autocorrelation.
maxlag=35; F=xcov(E,maxlag,'unbiased'); [c,lags]=xcov(F,35,'unbiased');
BLS«USUnemp«1940«2009«XCORR«a=E; save BLS«USUnemp«1940«2009«XCORR«a -ascii;
figure(4); plot(lags,F,'m','LineWidth',2);
axis([-maxlag maxlag -1.8 4.8]); grid;

Signals and Systems
251
9. Write a Matlab program to load and plot the monthly unemployment rates in California and in the United States
from 1976 through 2010. Find unbiased estimates of their cross-covariance functions and plot them. The data is
available at www.bls.gov/data/. See Example 4.32.
Solution
load BLS«Data«US«Unemployment«1976«2010.dat;
B=BLS«Data«US«Unemployment«1976«2010;
BLS«USUnemp«1976«2010=B; save BLS«USUnemp«1976«2010 -ascii;
load BLS«Data«CA«Unemployment«1976«2010.dat;
C=BLS«Data«CA«Unemployment«1976«2010';
BLS«CAUnemp«1976«2010=C; save BLS«CAUnemp«1976«2010 -ascii;
%
m=1:1:length(C); figure(1); plot(m,C,'r','LineWidth',2); hold on
plot(m,B,'b','LineWidth',2); axis([1 length(C) 3 13])
grid; hold off;
%
% Find cross-correlation.
maxlag=150; D=xcov(B,C,maxlag,'unbiased');
[c,lags]=xcov(B,C,150,'unbiased');
BLS«USCAUnemp«1976«2010«XCORR«a=D;
save BLS«USCAUnemp«1976«2010«XCORR«a -ascii;
E=xcov(C,B,maxlag,'unbiased'); [c,lags]=xcov(C,B,150,'unbiased');
BLS«CAUSUnemp«1976«2010«XCORR«a=E; save
BLS«CAUSUnemp«1976«2010«XCORR«a -ascii;
%
figure(2): plot(lags,D,'b','LineWidth',2); hold on;
plot(lags,E,'r','LineWidth',2); axis([-maxlag maxlag -1.2 3.2])
grid;
10. Convolution with a delayed unit-step function. Find the convolution y(t) = x(t) ⋆u(t −t0) and model it by a
combination of an integrator and a delay element.
Solution
y(t) = x(t) ⋆u(t −t0) =

∞
−∞
x(τ)u(t −t0 −τ)dτ
But u(t −t0 −τ) = 0 for τ > t −t0. Therefore,
y(t) =

t−t0
−∞
x(τ)dτ =

t
−∞
x(τ −t0)dτ
The convolution result may be interpreted as the output of an integrator followed by a delay element, or a delay
element followed by an integrator y(t) = x(t) ⋆u(t) ⋆δ(t −t0).
Chapter Problems
11. Convolution with an impulse.
a. Show that the convolution of a unit impulse located at t0 with a function that is continuous at t0 shifts the function
by t0:
φ(t)⋆δ(t −t0) =

∞
−∞
φ(t −τ)δ(τ −t0)dτ = φ(t −t0)

252
CHAPTER 4
Superposition, Convolution, and Correlation
b. The convolution of two periodic functions φ(t) and η(t) that have the same period T is deﬁned by
φ(t)⋆η(t) = 1
T

T
2
−T
2
φ(t −τ)η(τ)dτ
Show the convolution of a periodic function φ(t) with a periodic train of unit impulses (with the same period T )
to be φ(t) itself with a scale factor 1/T :
φ(t) ⋆
∞

k=−∞
δ(t −kT ) = 1
T

T
2
−T
2

φ(t −τ)
∞

k=−∞
δ(τ −kT )

dτ = 1
T φ(t)
The convolution integrals in problems 12 through 17 address the LTI systems of some of the problems in
Chapter 3 whose outputs you derived by superposition. Here, the convolution operation will be performed by
evaluating the integral in the time domain.
12. The unit-impulse response of an LTI system is δ(t) −e−tu(t). Find its responses to the following inputs:
a. u(t) −u(t −1)
b. tu(t)
c. tu(t) −u(t −1)
d. δ(t) −δ(t −1)
13. Find y(t) = d(t) ⋆h(t), where d(t) = u(t) −u(t −1) and
a. h(t) = δ(t) −δ(t −1)
b. h(t) =
∞

n=0
(−1)nδ(t −n)
c. h(t) = d(t)
d. h(t) = e−t
14. Find y(t) = d(t) ⋆h(t), where d(t) = u(t) −u(t −1) and h(t) = e−106tu(t). Describe a method to approximate
y(t) during 0 ≤t < 1 sec.
15. Find y(t) = x(t) ⋆h(t) for the sets of inputs and unit-impulse responses given in Table 3.1 of Chapter 3.
16. Repeat problem 15 for the set of inputs and unit-impulse responses given in Table 3.2 of Chapter 3.
17. Find y(t) = x(t) ⋆h(t), where
a. h(t) = e−2tu(t) and x(t) = 1
b. h(t) = e−2tu(t) and x(t) = u(t + 1)
c. h(t) = e−2tu(t) and x(t) = e−tu(−t)
d. h(t) = e−2tu(t) and x(t) = e3tu(−t)
e. h(t) = (e−2t + e−3t)u(t) and x(t) = e−tu(−t)
f. h(t) = e−tu(t) and x(t) = e−2tu(−t)
g. h(t) = x(t) = e−2t[u(t) −u(t −1)]
h. h(t) = (1 −e−2t)u(t) and x(t) = u(t) −u(t −1)
Evaluate the convolution integrals of problems 18 through 24 directly in the time domain. (They will be evaluated
again in the frequency domain by the Laplace transform. See Chapter 6.)
18. Evaluate the convolution integral y(t) = x(t) ⋆h(t), where
a. h(t) = sin t [u(t) −u(t −2π)] and x(t) = sin tu(t)
b. h(t) = δ(t −2π) + 2u(t) and x(t) = cos tu(t)
c. h(t) = e−tu(t) and x(t) = sin 2tu(t)
d. h(t) = e−tu(t) and x(t) = sin 2tu(−t)
19. Evaluate convolution integrals y(t) = x(t) ⋆h(t) for the following cases:
a. x(t) = sin t and h(t) = e−0.1t sin 2tu(t)
b. x(t) = sin tu(t) and h(t) = e−0.1t sin 2tu(t)
c. x(t) =
n=∞

n=0
δ(t −n) and h(t) =

sin πt,
0 < t < 1
0,
elsewhere
d. x(t) = u(−t) and h(t) = e−αtu(t)
e. x(t) =

1/T,
0 < t < T
0,
elsewhere
and h(t) = e−αtu(t)
f. x(t) = tu(t) and h(t) = e−αtu(t)

Signals and Systems
253
20. Let x(t) = 1
T [u(t) −u(t −T )]. Show that
lim
T →0 [x(t) ⋆h(t)] = h(t)
21. Find y(t) = x(t) ⋆h(t) for the following three cases:
a. x(t) = (sin t)u(t) and h(t) = e−αt(sin t)u(t) for α = 0.1, 1, 10
b. x(t) = (cos t)u(t) and h(t) = (cos 2t)u(t)
c. x(t) = (cos t)u(t) and h(t) = (cos 1.1t)u(t)
22. Directly evaluate the convolution integral y(t) = x(t) ⋆h(t), where
a. x(t) = cos tu(t)
and
h(t) = δ(t −2π) −2u(t)
b. x(t) = e−t/100u(t)
and
h(t) = 2e−tu(t)
c. x(t) = e−|t|
and
h(t) = e−t/10u(t)
d. x(t) = (1 + sin 2t)u(t)
and
h(t) = e−2tu(t)
e. x(t) = e−2tu(t)
and
h(t) = (1 + e−t)u(t)
f. x(t) = (sin 3t)u(t)
and
h(t) = (e−t −2e−2t)u(t)
g. x(t) = e−tu(t)
and
h(t) = δ(t) −e−tu(t)
23. The input to an LTI system is x(t) = (sin 3t)u(t). Find the output y(t) and its steady-state value for
a. h(t) = (sin t)u(t)
b. h(t) = e−t(sin t)u(t).
24. Directly evaluate the convolution integral y(t) = y1(t) + y2(t) = [x1(t) + x2(t)] ⋆h(t) for the cases listed below.
δ′(t) is a unit doublet, the time derivative of a unit impulse. y1(t) is the contribution to the output by the input x1(t)
and y2(t) is the contribution to the output by x2(t).
a.
h(t) = (1 −2t)e−tu(t)
x1(t) = 
e−3t −e−2t
u(t)
and
x2(t) = δ(t) + δ′(t)
b.
h(t) = e−3tu(t)
x1(t) = e−2tu(t)
and
x2(t) = δ(t)
c.
h(t) = 1
8

9e−t −e−9t
u(t)
x1(t) = 9u(t)
and
x2(t) = δ(t) + δ′(t)
d.
h(t) = 
e−2t −e−3t
u(t)
x1(t) = 6u(t)
and
x2(t) = δ(t)
e1.
h(t) = e−3tu(t)
x1(t) = e−2tu(t)
and
x2(t) = δ(t)
e2.
”
”
x2(t) = 0
e3.
”
”
x2(t) = −δ(t)
f1.
h(t) = 0.5e−t/2u(t)
x1(t) = 3e−tu(t)
and
x2(t) = 6δ(t)
f2.
”
”
x2(t) = 0
f3.
”
”
x2(t) = −6δ(t)
25. The impulse response of an LTI system is h(t) = (e−t + e−2t)u(t) and the input is x(t)u(t0 −t). Show that the
output for t > t0 is y(t) = Ae−t + Be−2t, t > t0. Find A and B in terms of x(t)u(t0 −t).
26. The input x(t) and the output y(t) in an LTI system are related by the differential equation
d2y
dt2 + 2dy
dt + y = dx
dt + 2x
Show that
y(t) =

∞
−∞
h(t −τ)x(τ)dτ
where h(t) is the system’s unit-impulse response.

254
CHAPTER 4
Superposition, Convolution, and Correlation
27. Consider x(t) = 0.01 cos t + e−|t| and h(t) = e−tu(t). Find
y(t) =

∞
−∞
x(τ)h(t −τ)dτ, −∞< t < ∞
and compare with the cross-correlation between x(t) and h(−t).
28. Correlation. Consider x(t) = 0.01 cos t, y(t) = e−tu(t), and z(t) = x(t) + y(t). Find and plot
rxz(τ) =

∞
−∞
x(t)z(t −τ)dt, −∞< τ < ∞
29. Barker code. The Barker code is a binary sequence cN(n), n = 1, 2, . . . , N (shown by + and −, or 1 and −1),
with code length N = 1, 2 · · · 11, 13, as listed in the table below.
N
cN(n)
2
1 −1 or −1 1
3
1 1 −1
4
1 −1 1 1 or 1 −1 −1 −1
5
1 1 1 −1 1
7
1 1 1 −1 −1 1 −1
11
1 1 1 −1 −1 −1 1 −1 −1 1 −1
13
1 1 1 1 1 −1 −1 1 1 −1 1 −1 1
To obtain an indicator for the pattern of dependency between 1s and −1s in the Barker code, for each code sequence
c(n) listed in the table above deﬁne ρ(k) as the index of correlation between the elements:
ρ(k) =
N

n=1
c(n)c(n −k), k = 0, 1, 2, . . . , N
For codes with lengths N = 2, 3, 4, 5, 7, 11, and 13, ﬁnd and plot ρ(k) and determine the ratio ρ(0)/ρ(k).
30. Signaldetection.Adeterministicperiodicbinarysequence x(n)madeofregularlyalternating1sand0sistransmitted
at the rate of 106 bits per second. For transmission it uses an on-off encoding scheme where the 1 bits are transmitted
by s(t) and the 0 bits are transmitted by silent periods each 1 µs long. The encoded signal is a periodic signal x(t)
given by
x(t) =

s(t),
0 < t < 0.5 µs
0,
0.5 µs < t < 1 µs , x(t) = x(t + 1µs) all t
To detect the occurrence of a 1 or 0, the received signal ˆx(t) [generally a corrupted version of x(t) due to commu-
nication noise and interference] is continually matched with the template s(t) and the results are observed every
T = 1/M µs (i.e., at intervals t = k/M µs, k = 0, 1, 2 . . . , M −1). The integer M indicates the frequency
(or number) of observations during transmission of each bit. The present problem illustrates the effect of s(t) on
separability of 1s and 0s at the receiver. For simplicity we assume no interference or noise [i.e., ˆx(t) = x(t)].
Assume a matching scheme where x(t) is multiplied by a sliding s(t)-shaped window that is slid every 1/M µs.
The results are integrated over 1 µs, resulting in observation values y(k):
y(k) =

1 µs
0
x(t)s(t −kµs)dt, k = 0, 1, 2 . . . (M −1)
a. Let s(t) be a 1-volt rectangular 1-µs pulse. Find the maximum value yMax and its location k0. Find the distance
between the peak value and its immediate neighbour yMax −y(k0 −1). Consider this to be a separability distance.

Signals and Systems
255
b. Repeat for a binary s(t) = ±1 made of a seven-segment Barker code and observations every 1/7 µs. Compare
with the corresponding value obtained in part a.
c. Repeat for a binary s(t) = ±1 made of an 11-segment Barker code and observations every 1/11 µs. Compare
with corresponding values obtained in parts a and b.
d. Repeat for a binary s(t) = ±1 made of a 13-segment Barker code and observations every 1/13 µs. Compare
with corresponding values obtained in parts a, b, and c.
e. Discuss the gain in separability distance versus the increase in eventual transmission rate as you increase the
length of the Barker code used.
4.14
Project: Signal Detection by Matched Filter
Objectives and Summary
This project explores, by computer simulation, detection of known and deterministic signals of ﬁnite length embedded
in noise. This is done by a matched ﬁlter followed by a decision rule. The data is made of signals of ﬁnite duration that
occur randomly and are corrupted by additive white Gaussian noise (which is independent of the signal). The signal used
in this project is Barker code of length 7, 13, or 15. In procedure 1, signals without noise are convolved with templates
matched to them, and their properties examined. Procedure 2 examines the detection of signals embedded in noise. To
determine signal occurrence, the data is convolved with an LTI system whose unit-impulse response is matched to the
signal and the output is then passed through a threshold level. The performance is measured by obtaining the probability
of correct detection and the rate of false alarm for several signal-to-noise ratios and for several threshold levels.
Procedure 1: Operation of a Matched Filter
In this procedure you will implement, by computer simulation, the operation of a matched ﬁlter and examine its properties.
a. Write Matlab code to implement the operation of the matched ﬁlter of section 4.7 with the seven-segment signal
η(n) = {1
↑, 1, 1, −1, −1, 1, −1}. Obtain the output and plot it. The signal and the ﬁlter’s output are shown in
Figure 4.15(a) and (b), respectively.
b. Repeat the above procedure for the 13-segment signal η(t) = {1
↑, 1, 1, 1, 1, −1, −1, 1, 1, −1, 1, −1, 1}. The
signal and the ﬁlter’s output are shown in Figure 4.15(c) and (d), respectively.
c. Repeat the above procedure for the 15-segment signal η(t) = {1
↑, 1, 1, −1, −1, −1, −1, 1, −1, 1, −1, −1, 1, 1,
−1}.
Procedure 2: Filtering and Detection
a. Signal and noise. Design and run a detection experiment involving a binary signal embedded in noise. The data
to be transmitted is binary. It assumes one of two states (e.g., high or low, 1 or 0, plus or minus, . . .), which occur
randomly. One of the states is transmitted by the seven-bit long waveform η(t) = {1, 1, 1, −1, −1, 1, −1} of
procedure 1a. The other state is transmitted by the absence of η(t); that is, seven zeros. The result is a signal s(t)
which contains η(t) repeatedly but randomly. The noise is an additive white Gaussian stochastic process. The
input arriving at the receiver is the signal plus noise x(t) = s(t) + w(t), within which η(t) appears repeatedly
but irregularly. To generate s(t), pass a random signal through a threshold level and convolve it with η(t). An
example is shown in Figure 4.22.
b. Filtering and detection. The goal is to detect the occurrence of η(t). Detection is done by ﬁrst ﬁltering the data
through a matched ﬁlter with h(t) = η(NT −t) and then passing the ﬁlter’s output through a threshold level λ.
In this operation, two types of error may occur: a miss or a false alarm. Both of these depend on the signal-to-noise
ratio (SNR) and the threshold λ. An example is shown in Figure 4.23. By simulation of a long stretch of data,

256
CHAPTER 4
Superposition, Convolution, and Correlation
η(t)
w > 1.8
w (t)
s (t)
1
0
–1
0
1
2
3
4
Time (s)
Time (s)
5
6
7
3
2
1
0
–1
–2
–3
0
10
20
30
40
50
60
70
80
90 100 110 120
1
0
0
10
20
30
40
50
60
(a)
(b)
Time (s)
Time (s)
(c)
(d)
70
80
90 100 110 120
1
0
–1
0
10 20 30 40 50 60
80
70
90 100 110 120 130
FIGURE 4.22 Generating s(t). (a) A seven-segment η(t). (b) A sample of a white Gaussian noise with zero mean and
average power of 1 [shown by N(0, 1)]. (c) The noise is passed through a threshold level of 1.8 to generate a sequence of
random events. (d) Convolution of η(t) with the sequence of random events generates the signal s(t).
s(t)
y(t) = x(t)*η(t)
x(t) = s(t) + w(t)
y > 7
1
0
–1
0
10 20 30 40 50 60
(a)
(b)
70
Time (s)
Time (s)
(c)
(d)
Time (s)
Time (s)
80 90 100 110 120 130
4
3
2
1
–1
0
–2
–3
0
10
20 30 40 50 60
70
80 90 100 110 120 130
15
10
–10
–5
0
5
0
10 20 30 40 50 60 70 80 90 100 110 120130
1
0
0
10 20 30 40 50 60 70 80 90 100 110 120 130
FIGURE 4.23 Detecting occurrences of η(t). (a) A sample of the signal s(t) containing 5 randomly occurring η(t).
(b) A sample of white Gaussian noise N(0, 1) with zero mean and average power of 1. (c) The sum of the signal and
noise in (a) and (b), x(t) = s(t) + w(t). (d) Comparing ﬁlter’s output with a threshold level λ = 7 in order to decide on
the presence of η(t). This ﬁgure shows one miss and no false alarm.

Signals and Systems
257
0.999
0.99
0.98
0.9
Pf = 10–1
5 × 10–2
5 × 10–3
5 × 10–4
10–2
10–3
10–4
10–5
10–6
10–8
10–10
0.8
Pd
0.7
0.6
0.5
0.4
0.3
0.2
0.1
1
2
3
4
SNR
5
6
7
FIGURE 4.24 Theoretical relationship between Pd, Pf , and the signal-to-noise ratio (SNR) in an optimum linear ﬁlter for
detection of signals in additive white Gaussian noise. The ﬁlter is matched to the signal. It maximizes the signal-to-noise
ratio at the output. The threshold level provides a tradeoff between correct detections and false alarms.
Source: From Woody and Nahvi, “Application of Optimum Linear Filter Theory to Detection of Cortical Signals Preceding Facial
Movement in Cat,” Experimental Brain Research, 16 (1973), pp. 455–65.
measure the probability of detection and the rate of false alarm for two types of signals (using η(t) in procedure
1a and 1b), six signal-to-noise ratios, and ﬁve threshold levels of your choice. Use the normalized frequency of
occurrence of an event as an estimate of its probability. Compile your results in the form of the receiver operating
curve (ROC). An example is shown in Figure 4.24. Discuss the detector’s performance.
Note. The ROC of a matched ﬁlter is the plot of the relationship between Pd, Pf , and the signal-to-noise ratio
(SNR) in an optimum linear ﬁlter for detection of signals containing noise. Pd is the probability of detection and
Pf is the probability of false alarm. The ﬁlter is matched to the signal. It maximizes the SNR at the output. The
threshold level provides a tradeoff between correct detections and false alarms.
c. Effect of signal-to-noise ratio. Deﬁne the signal-to-noise ratio to be the ratio of signal power to noise power at
the output of the ﬁlter. Investigate the effect of SNR on Pd and Pf for ﬁve values of SNR of your choice.
Discussion and Conclusions
Discuss the detector’s performance. Discuss the effect of the length of η on the detection outcome. How does one choose
the threshold level λ? Discuss application of the above detection scheme in other ﬁelds which involves missing a signal
or producing a false alarm.

Chapter5
Differential
Equations and
LTI Systems
Contents
Introduction and Summary
260
5.1
Formulation of Differential Equations
260
5.2
Solution in the Time Domain by the Classical Method
270
5.3
The Particular Solution
272
5.4
The Homogeneous Solution
274
5.5
Composing the Complete Solution
275
5.6
Examples of Complete Solutions
275
5.7
Special Case: Multiple Roots
279
5.8
When the Input Contains Natural Frequencies
280
5.9
When the Natural Response May Be Absent
281
5.10
Response to an Exponential Input
282
5.11
The System Function
283
5.12
Sinusoidal Steady-State Response
284
5.13
Unit-Step Response
285
5.14
Unit-Impulse Response
288
5.15
Effect of Discontinuity in the Forcing Function
290
5.16
Solution by Convolution
293
5.17
Zero-Input and Zero-State Responses
295
5.18
Zero-State Response and Convolution
298
5.19
Properties of LTI Differential Equations
299
5.20
Solution by Numerical Methods
299
5.21
Concluding Remarks
300
5.22
Problems
301
5.23
Project: System of Differential Equations
310
259

260
CHAPTER 5
Differential Equations and LTI Systems
Introduction and Summary
Linear differential equations with constant coefﬁcients are the main vehicles for describ-
ing a linear time-invariant (LTI) system. The input-output relationships for the majority
of linear time-invariant systems, as well as their state-space dynamical equations, are
expressed by linear differential equations with constant coefﬁcients. Examples of these
were given in Chapter 3. A linear differential equation with constant coefﬁcients is
written as:
dny
dtn +an−1
dn−1y
dtn−1 +· · ·+a1
dy
dt +a0y = bm
dmx
dtm +bm−1
dm−1x
dtm−1 +· · ·+b1
dx
dt +b0x (1)
where x(t) is the input and y(t) is the output. Also, dk y/dtk and dkx/dtk are the kth time
derivatives of y(t) and x(t), respectively, and ak and bk are constants. The differential
equation is of order n. It is customary to arrange the output terms on the left side and
the input terms on the right side of the equation. In this book differential equations are
solved by one of the following methods:
1.
Time-domain method:







homogeneous and particular solutions
convolution
zero-input and zero-state solutions
numerical solution
2.
Transform method
In this chapter we discuss both a time-domain and a numerical method of ﬁnding
the solution. Solutions using the Fourier or Laplace transforms are discussed in other
chapters. This chapter starts with the classical method of ﬁnding the particular and homo-
geneous solutions. The method is simple and intuitive, as the components of the solution
reﬂect the physical and measurable attributes of a system’s response. These include
things such as the forced and natural responses (especially the transient and steady-state
responses) and its natural frequencies. The effect of an input discontinuity on the initial
conditions and the response is then described. The impulse, step, exponential, and sinu-
soidal inputs are used in order to bring to the reader’s attention the utility of tools such
as the system function and the frequency response. After a detailed presentation of the
classical method, the chapter brieﬂy describes the zero-input and zero-state responses
and the connection between the above methods and the convolution method of ﬁnding
the response of an LTI system. The project at the end of the chapter is intended to help
the student with second-order systems in more detail. It contains mathematical analyses
and measurements that can be carried out in the laboratory or by simulation.
5.1
Formulation of Differential Equations
A system is an interconnection of its subsystems and elements. Each subsystem or
element is described by relationships between certain variables of interest. The intercon-
nection of the elements imposes additional constraints on these variables. The system is
also connected to the outside world by input-output ports. The result is a set of equations

Signals and Systems
261
that include internal and external variables. By eliminating some internal variables we
obtain a set of equations that describe the system. When the elements are linear and their
interconnections are also expressed by linear equations, the system becomes linear.1
Similarly, the time invariance of the elements and their interconnections produce a time-
invariant system. For the LTI systems of interest, the resulting equations are ordinary
linear differential equations with constant coefﬁcients. Some examples in sections 3.6
and 3.7 of Chapter 3 illustrated how the differential equations were formulated for LTI
systems. The present section discusses more examples of formulating differential equa-
tions and their possible linearization. The examples cover electrical, mechanical, thermal,
biological, and hydraulic systems. In the case of some nonlinear systems, a linear model
may be constructed to represent the system within a limited range of operation.
The input-output differential equation of an LTI system may also be constructed
from the input-output data, along with some reasonable assumptions about the system,
or from knowledge of the system’s response to a given input such as the impulse or step
functions. In fact, any input-output pair (except exponential or sinusoidal) would work
for that purpose. Mathematical tools for such formulations and modeling are provided
by the Laplace transform and will be discussed in Chapter 8. Here we include 11 simple
examples to illustrate the concept. For the sake of simplicity, the ﬁrst 10 examples in this
section are limited to ﬁrst-order equations, but the methods apply to systems of higher
order as well.
Example
5.1
An electrical system
A 10-µF capacitor carrying an initial charge of 1 µC is connected at t = 0 in parallel
with a 10-M resistor. Formulate the differential equation that describes capacitor
charge as a function of time.
Solution
Let q, v, and i represent the electric charge, the voltage, and the current coming out
of the capacitor, respectively. All are functions of time. Then
From the capacitor side we have
i = −dq
dt
From the resistor side we have
i = v
R =
q
RC = 10−2q
By eliminating i we get
dq
dt + 10−2q = 0
It will be shown that the general solution to the above equation is q = Ce−t/100. In
the present case, given q(0) = 10−6 we ﬁnd q(t) = 10−6e−10−2t. The charge on the
capacitor dissipates exponentially with a time constant of 100 seconds.
1A linear system may also contain nonlinear elements.

262
CHAPTER 5
Differential Equations and LTI Systems
Example
5.2
A piecewise linear system
The symbol for a rectiﬁer diode and the convention for its terminal variables are
shown in Figure 5.1(a). An ideal diode is a voltage-controlled switch that remains
open (R = ∞) as long as the voltage across its terminal is negative, and operates as a
short (R = 0) when the current through it is positive. Its terminal characteristic may
be expressed by
i = 0,
when v < 0
v = 0,
when i > 0
InthecircuitofFigure5.1(b)thediodeisideal.Assume R1 = R2 = 500, C = 2µF
and v1(t) = u(t) −u(t −t0), t0 = 10 msec. Find differential equations that describe
the capacitor voltage as a function of time.
v
Cathode
(a)
Anode
+
–
v1
R1
C
i
+
–
(b)
v2
+
–
R2
D
+
–
i
FIGURE 5.1
Solution
From KVL around the loop we have
v1 = Ri + v2
From the capacitor side we have
i = C dv2
dt
By eliminating i(t) we get
RC dv2
dt + v2 = v1
During t < 0, v1 = 0 and the circuit is at rest [all variables are zero, including
v2(0) = 0]. For t > 0, the diode can be in one of two states: on or off. Absent
any a priori knowledge about the state of the diode, we assume a state and solve the
problem. Then we test to see if the assumption holds true.
a.
During 0 ≤t < t0, v1 = 1, we assume the diode is on. Then R = R1 = 500 ,
RC = 10−3 and
dv2
dt + 1,000v2 = 1,000, 0 ≤t < t0, v2(0) = 0
As will be seen later, the solution to the above differential equation is
v2 = 1 −e−1,000t, 0 ≤t < t0
To test the assumption, we note that during the above period i = v1−v2
500 > 0,
which would turn the diode on. The assumption, then, was correct. In contrast,

Signals and Systems
263
assuming the diode to be off would result in
R = R1 + R2 = 1,000, RC = 2 × 10−3, v2 = 1 −e−500t,
and
i = v1 −v2
1,000 =
1
1,000e−500t > 0
which would create a positive voltage across the diode. This contradicts the
terminal characteristics of the diode indicating that the assumption was
incorrect.
b.
During t ≥t0, v1 = 0, we assume the diode is off. Then
R = R1 + R2 = 1,000 , RC = 2 × 10−3 and
dv2
dt + 500v2 = 0, t ≥t0, v2(t0) ≈1
The solution to the above differential equation is
v2 = e−500(t−t0), t ≥t0
By a similar test we afﬁrm that the assumption is correct.
Example
5.3
Mechanical system
A solid object with mass M slides on a lubricated horizontal surface with speed v
under an external driving force. Formulate the differential equation that describes the
speed in terms of the driving force.
Solution
According to Newton’s law, the net force acting on the object is equal to the product
of the mass with acceleration. In the present case the motion is one-dimensional.
The net horizontal component of the force in the direction of motion of the object is
f −bv, where f represents the external driving force (which produces the motion)
and bv models the damping effect of the viscosity of the lubrication on the support
surface (which opposes it).
f −bv = M dv
dt
Collecting the unknown terms on the left-hand side and dividing both sides by M we
ﬁnd
dv
dt + b
M v = f
M
Example
5.4
Thermal system
This example formulates the relationship between the temperature of a liquid and that
of a solid body immersed in it. The solid body doesn’t contain any energy-generating
source. The parameters involved are the following:
θ1
temperature of the liquid in ◦C
θ2
temperature of the solid object in ◦C

264
CHAPTER 5
Differential Equations and LTI Systems
A
surface area of the solid object in m2
M
mass of the solid object in kg
C
speciﬁc heat of the solid object in Calories/(◦C × kg)
h
surface heat transfer coefﬁcient in Calories/(◦C × hr × m2)
Find the differential equation that describes θ2 in terms of θ1.
Solution
In accordance with the principle of conservation of energy, the heat exchange between
the solid body and the surrounding liquid has to satisfy the condition below:
Energy transferred from the liquid = Energy stored in the solid body
Assuming that the temperature is uniform throughout the solid body, during a time
period dt the above equation becomes
h A(θ1 −θ2)dt = MCdθ2
or
dθ2
dt + h A
MC θ2 = h A
MC θ1
The above is a ﬁrst-order differential equation with θ1 being the input variable and θ2
the output variable. M, A, and C are constants, but h is generally a function of θ1
and θ2, making the equation a nonlinear one. In avoiding a mathematically rigorous
linearization procedure, one may approximate h by its average value during a small
perturbation.
Example
5.5
Hydraulic system
An open storage tank of cylindrical shape with cross-section area A receives liquid
at a ﬂow rate of q liters per second. It partly stores the incoming liquid and partly
discharges it to atmospheric space through a sharp oriﬁce.
a.
Let the height of the liquid stored in the tank be h. Set up the differential
equation that describes h in terms of input ﬂow rate q.
b.
Assume the liquid has been arriving in the tank at a constant rate of Q0 for a
long time. In the steady state the discharge becomes equal to the intake and the
tank level reaches a steady-state height H0, to be called the DC steady-state
operating point. Linearize the equation around the operating point Q0 and H0 to
obtain a linear differential equation describing perturbations (small variations
in h produced by small variations in q).
Solution
a.
From the application of the basic laws of hydraulics it can be shown that the
ﬂow rate through the oriﬁce is k
√
h, where h is the height of the liquid stored in
the tank and k is a constant whose value is determined from a combination of

Signals and Systems
265
theory and measurements. From conservation of mass we have
Mass stored + Mass out = Mass in
Assuming an incompressible liquid we can substitute volumes for the masses.
Volume stored + Volume out = Volume in
During a period dt we have



volume stored = A × dh
volume in = q × dt
volume out = k
√
h × dt
which results in the following differential equation:
Adh
dt + k
√
h = q
where q(t) is the known variable (the system’s input) and h(t) is the unknown
(the system’s response). A and k are constants, making the system described by
the above equation time invariant. However, the term
√
h causes it to become
nonlinear. (It fails the linearity test because
√
h1 +
√
h2 ̸= √h1 + h2.)
b.
The operating point satisﬁes the steady-state equation
k
√
H 0 = Q0
In its neighborhood the input and output variables can be expressed by Q0 + q
and H0 + h, respectively, where q and h are small perturbations. The input-
output equation then becomes
Ad(H0 + h)
dt
+ k

H0 + h = Q0 + q
But
d(H0 + h)
dt
= dh
dt
and, since h is assumed to be small, the √H0 + h term can be approximated by
the ﬁrst two terms in its Taylor series:

H0 + h ≈
√
H 0 +
1
2
√
H 0
h
The input-output equation is, therefore, approximated by
Adh
dt + k
√
H 0 +
k
2
√
H 0
h = Q0 + q
Noting that k
√
H 0 = Q0, the above equation is reduced to
Adh
dt +
k
2
√
H 0
h = q
This is a linear differential equation with constant coefﬁcients.

266
CHAPTER 5
Differential Equations and LTI Systems
Example
5.6
Response of hydraulic system of Example 5.5 to a step
perturbation
The coefﬁcient k of the discharge oriﬁce in Example 5.5 is given by
k =

2g × a × c
where g is the gravitational acceleration and a is the cross section of the discharge
oriﬁce. The coefﬁcient c has no dimension and its value depends on the geometry
of the oriﬁce. It can be determined by a combination of theoretical analysis and
experimental measurement. Assume that the area of the cross section of the tank is
A = 1 m2, the cross section of the discharge oriﬁce is a = 1 cm2, acceleration due to
gravity is g = 9.81 m × s−2, and c = 0.65. Assume that the liquid has been ﬂowing
into the tank at a constant rate of Q0 = 0.2 liters/second for a long time so that the
ﬂuid height in the tank has reached a steady-state level H0. (a) Fing H0. (b) Find
the response of the tank to an input perturbation in the form of a step increase of
10 cc/second. (c) Find the new steady-state level by using the linearized differential
equation. Then verify that it is in agreement with the value found from the nonlinear
equation.
Solution
In the following solution we will use the SI system of units.
k =

2g × a × c =
√
2 × 9.81 × 10−4 × 0.65 = 2.88 × 10−4
a.
H0 =
 Q0
k
2
=

0.0002
2.88 × 10−4
2
= 0.482 m
b.
Adh
dt + αh = 10−5u(t), α =
k
2
√
H 0
= 2.88 × 10−4
2
√
0.482
= 2.072 × 10−4
h(t) = 10−5
α
	
1 −e−αt
= 0.0483
	
1 −e−αt
h(∞) = 0.0483 m, H0 + h(∞) = 0.483 + 0.0482 = 0.5308 m
c.
H(∞) =
 Q0 + q
k
2
=
 2.1 × 104
2.88 × 104
2
= 0.532 m
H(∞) = H0 + h(∞)
Example
5.7
Modeling a mixing process
A tank contains 200 liters of liquid with a salt concentration of 30 grams/liter. At
t = 0, fresh liquid, whose concentration is 5 grams/liter, starts ﬂowing in the tank at
the rate of 10 liters/minute. At the same time, the tank discharges at the same rate of
10 liters/minute. Throughout the process the content of the tank is kept at a uniform
concentration level by continuous stirring.

Signals and Systems
267
a.
Write the differential equation that describes salt concentration in the tank as a
function of time. Show that the tank’s concentration of salt decreases
exponentially with time and determine its time constant τ.
b.
Find the concentration at t = 3τ.
c.
Determine the time required to reduce the concentration of salt in the tank to
the level of 6 grams/liter.
Solution
a.
Let the concentration of the salt in the tank at time t be represented by c(t) (in
grams/liter). The amount of salt entering the tank during a brief period dt is
10 × 5dt = 50dt grams and the amount discharged is 10c × dt. The change in
concentration is dc. The change in the total salt content of the tank is, therefore,
200 × dc = 50 × dt −10c × dt, t > 0, or dc
dt = 0.25 −0.05c, t > 0,
with c(0) = 30
The only solution that satisﬁes the above equation and the initial condition of
c(0) = 30 is
c(t) = 5 + 25e−0.05t, t > 0
The concentration of salt inside the tank starts at the level of 30 grams/liter at
t = 0 and decreases exponentially to a ﬁnal value of 5 grams/liter. The time
constant of the process is τ = 20 seconds. Theoretically, it requires t = ∞to
reach the ﬁnal value, but, as seen next, after a time lapse of 3 to 5 time constants
it reaches a level close enough to the ﬁnal value.
b.
At t = 3τ seconds, c = 5 + 25e−3 = 6.245 grams/liter.
c.
The time required to reach c = 6 is the solution of the equation
5 + 25e−0.05t = 6, which is t = 64.38 seconds.
Example
5.8
Modeling a population’s growth
Annual measurements of a certain population show an increase of 2.5% per year.
That is, the number of people (shown by yn) on the last day of the nth year is related
to yn−1 (the number a year before) by yn = (1 + 0.025)yn−1. Assume growth is a
continuous function of time and the rate of growth is proportional to the population
number:
dy(t)
dt
= αy(t)
α a constant. Then, construct a simple model of population growth by a ﬁrst-order
differential equation.

268
CHAPTER 5
Differential Equations and LTI Systems
Solution
The above proportionality assumption translates directly into the following ﬁrst-order
equation and its solution
dy(t)
dt
−αy(t) = 0, y(t) = y0eαt,
where y0 = y(0)
The annual rate of increase of 2.5% is produced by continuously compounding the
population increase during the year. If the unit of time is chosen to be 1 year, then
eα = 1.025 and α = ln(1.025) = 0.02469261.2
Example
5.9
Modeling an interest rate problem
Pat has invested X0 units of money in an account with an annual interest rate of r%.
a.
Find the account value (sum of principal X0 and the accrued interest) at the end
of the year if the interest is compounded (i) annually, (ii) semiannually, (iii)
quarterly, (iv) monthly, (v) daily, and, ﬁnally, (vi) continuously.
b.
Find the differential equation from which the account value can be obtained as
a function of time when interest is compounded continuously.
c.
At an interest rate of r = 3%, how long does it take for Pat’s money to double if
the interest is compounded (i) continuously and (ii) monthly?
Solution
a.
Let the account value at time t be shown by x(t). At the end the ﬁrst year,
(i)
annual compounding
x = X0 (1 + r)
(ii)
semiannual compounding
x = X0

1 + r
2
2
(iii) quarterly compounding
x = X0

1 + r
4
4
(iv) monthly compounding
x = X0

1 + r
12
12
(v)
daily compounding
x = X0

1 +
r
360
360
(vi) continuous compounding
x = limn→∞

X0

1 + r
n
n
= X0er
b.
With continuous compounding of interest, at the end of the ﬁrst year x = X0er.
At the end of the nth year Pat will have x = X0enr or x(t) = X0ert, if t is
speciﬁed in units of year. The differential equation whose solution is X0ert is
dx
dt −rx(t) = 0,
with x(0) = X0
2Note the parallels to the relationship between nominal and effective values of annual interest rates.

Signals and Systems
269
c.
Pat’s investment will double in t = (ln 2)/r = 23.105 years, if interest is
compounded continuously. If interest is compounded monthly, doubling time
will be 23.134 years.
Example
5.10
Modeling a system from measurements
The impulse response of a system is measured experimentally and a table of sampled
data (hi vs. ti, i = 1, 2, . . . , t > 0) is obtained. Based on a preliminary examination,
it is hypothesized that the data ﬁts a decaying exponential function h(t) = h0e−αt.
Test this hypothesis and ﬁnd parameters for the exponential model h(t).
Solution
To test the hypothesis, the data points are plotted in the form of ln(h) versus time
(i.e., with a linear abscissa for time and a logarithmic ordinate for h). The plot is then
examined visually and is seen to ﬁt a straight line. The slope of the line becomes
α because ln(h) = ln(h0) + ln(e−αt) = ln(h0) −αt. As an example, assume the
following two measurements:

t1 = 0, h1 = 2,
ln(h1) = 0.693
t2 = 5, h2 = 1.213, ln(h2) = 0.193 α = ln(h1) −ln(h2)
t2 −t1
= 0.693 −0.193
5 −0
= 0.1
The unit-impulse response is modeled by
h(t) = 2e−0.1tu(t)
The only differential equation that can produce the above unit-impulse response is
dy(t)
dt
+ 0.1y(t) = 2x(t)
Example
5.11
A second-order electrical system
In the circuit of Figure 5.2, R = 500 , L = 1 mH, and C = 10 µF. The variables
of interest are the elements’ voltages and currents.
a.
Write the terminal characteristics of the elements and the interconnection
constraints.
b.
Find differential equations that relate iR(t), ic(t), iL(t), and v(t) to vs(t).
c.
Summarize your observations.
iC
R
iL
iR
C
L
v
+
–
vs
+
–
FIGURE 5.2

270
CHAPTER 5
Differential Equations and LTI Systems
Solution
(1)
Resistor characteristic:
iR(t) = vs(t) −v(t)
R
(2)
Inductor characteristic:
iL(t) = 1
L
 t
−∞
v(τ)dτ
(3)
Capacitor characteristic:
iC(t) = C dv(t)
dt
(4)
Apply KCL at output node:
iR(t) = iC(t) + iL(t)
(5)
Substitute 1, 2, and 3 in 4:
vs(t) −v(t)
R
= 1
L
 t
−∞
v(τ)dτ + C dv(t)
dt
(6)
Differentiate 5:
d2v
dt2 +
1
RC
dv
dt +
1
LC v =
1
RC
dvs
dt
(7)
v(t) : Plug in element values in 6:
d2v
dt2 + 200dv
dt + 108v = 200dvs
dt
(8)
iR(t) : Find v(t) from 1 and apply to 7:
d2iR
dt2 + 200diR
dt + 108iR =
1
500
d2vs
dt2 + 2 × 105vs
(9)
iL(t) : Integrate 7 and apply 2:
d2iL
dt2 + 200diL
dt + 108iL = 2 × 105vs
(10) iC(t) : Differentiate 7 and apply 3:
d2iC
dt2 + 200diC
dt + 108iC =
1
500
d2vs
dt2
Observations
a.
KCL applies to the differential equations for iR(t), iL(t) and iC(t): [i.e., with
regard to their right side (8) = (9) + (10)].
b.
The left sides of all differential equations that describe the system’s variables
have the same form. The implications of the above two observations will be
discussed in sections 5.3 and 5.4.
5.2
Solution in the Time Domain by
the Classical Method
Consider the nth-order differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = f (t), t ≥0

Signals and Systems
271
where t is time. We assume the differential equation represents a real physical system,3
and f (t) represents the total contribution from the input and its derivatives.4 By a solution
we mean a function y(t) that (i) satisﬁes the differential equation and (ii) is of such a
nature that it and its n −1 derivatives at t = 0 are equal to a set of prescribed initial
conditions. Such a solution is also often called the complete solution. The following
discussion elaborates on this point.
If the differential equation is valid for −∞< t < ∞and f (t) is known for all
times, then initial conditions at t = −∞are assumed to be zero. If the input is given
only for t ≥0, then additional information must be provided to summarize the effect
of the unknown past on the state of the system at t ≥0 and hence on the future output.
For example, the information about the past history of the system may be supplied in
the form of the value of y and its ﬁrst n −1 derivatives at t = 0. The initial conditions,
therefore, contain the cummulative effect of all past inputs to the system.
From the above perspective, one expects that the response at t ≥0 is affected by
two factors: (i) the input after t ≥0 and (ii) the initial conditions at t = 0. The solution
y(t) is a function that satisﬁes the equation for t ≥0 and meets the conditions for y
and its n −1 derivatives at t = 0. To achieve this goal, the solution is composed of two
components. One component makes the left side of the differential equation equal to the
right side for t ≥0 and is called the particular solution, yp(t). The particular solution
satisﬁes the differential equation for t ≥0, but generally doesn’t agree with the initial
conditions by itself. It, therefore, is not the complete solution. To make it comply with
the initial conditions as well, we add to it a second component called the homogeneous
solution, yh(t). When substituted in the differential equation, the homogeneous solution
makes the left side equal to zero. It is obtained by setting the left side of the differential
equation equal to zero.
Example
5.12
Find the response of the ﬁrst-order differential equation
y′(t) + y(t) = 1, t ≥0, y(0) = 0
Solution
Try yp(t) = 1, t ≥0. Then
yp(t) + y′
p(t) = 1, t ≥0
The proposed yp(t) satisﬁes the equation, but because yp(0) = 1, it contradicts the
required initial condition y(0) = 0. It is not the solution to the equation. To remove
the contradiction we add a second component, yh(t), and try y(t) = yp(t) + yh(t).
3A consequence of this assumption is that if f (t) = 0 for t < t0, then y(t) = 0 for t < t0.
4For simplicity, we may represent the time derivative of a function by a prime sign′ placed at its upper-right
corner:
y′ = dy
dt , y′′ = d2y
dt2 , y′′′ = d3y
dt3 , . . . , y(n) = dn y
dtn

272
CHAPTER 5
Differential Equations and LTI Systems
The function of yh(t) is to contribute yh(0) = −1 such that y(0) = yp(0) + yh(0) =
1 −1 = 0, in agreement with the required initial condition. At the same time, yh(t)
should contribute zero to the right side of the equation as shown below:
y(t) + y′(t) = yp(t) + y′
p(t)



+ yh(t) + y′
h(t)


 = 1
⇓
⇓
1
0
In other words, yh(t) is the solution to the so-called homogeneous equation
yh(t) + y′
h(t) = 0
The only function that when added to its derivative sums up to zero is an exponential
function yh(t) = Ae−st, where A is a constant and can assume any value. In the present
example, yh(t) = Ae−t and y(t) = 1 + Ae−t. The parameter A will be adjusted to
satisfy the initial condition. Here, A = −1 will set y(0) = 0. The complete solution
is, therefore, y(t) = 1 −e−t, t ≥0. There is not enough information available to
determine y(t) for t < 0.
In summary, the solution of the linear time-invariant differential equation with
constant coefﬁcients is the sum of the particular solution and the homogeneous
solution.
y(t) = yp(t) + yh(t)
In circuits and systems theory we refer to the input x(t) as the forcing function, the
particular solution as the forced response, and the homogeneous solution as the natural
response. The exponent s is called the complex frequency and the roots of the charac-
teristic equation (to be discussed shortly) are the natural frequencies. In the following
sections we will expand upon ways to ﬁnd the two components of the response and
show how together they complete the solution. We start with the particular solution.
5.3
The Particular Solution
A function that satisﬁes the differential equation without necessarily meeting the initial
conditions is called the particular solution. The particular solution depends on the forcing
function f (t) and may be found by inspection or a process of guess and test (i.e.,
substitution).5 A short list of forcing functions and their particular solutions is given in
Table 5.1. More details on the responses to the step, impulse, exponential, and sinusoidal
forcing functions are found in sections 5.10 to 5.14.
The constants ci in a particular solution are found by its substitution into the differ-
ential equation. See the examples in section 5.6.6
5This method is also known by the phrase undetermined coefﬁcients.
6When the particular solution contains a large number of constants ci, their determination by substitution
becomes tedious. In such cases more efﬁcient methods are employed.

Signals and Systems
273
TABLE 5.1 A Short Table of Forcing Functions and Their Particular Solutions
Forcing Function
⇒
Form of the Particular Solution
1
⇒
c
est
⇒

cest,
s is not a root of the characteristic equation.
ctest,
s is a root of the characteristic equation
(Characteristic equation is described in the next section.)
sin ωt or cos ωt
⇒
c1 sin ωt + c2 cos ωt = A cos(ωt + φ)
tk
⇒
c0 + c1t + · · · + cktk
tket
⇒
et(c0 + c1t + · · · + cktk)
eσt sin ωt or eσt cos ωt
⇒
eσt(c1 sin ωt + c2 cos ωt) = Aeσt cos(ωt + φ)
tsin ωt or tcos ωt
⇒
c1 sin ωt + c2 cos ωt + c3t sin ωt + c4t cos ωt
Example
5.13
The differential equations for the circuit of Figure 5.2 were found in Example 5.11.
Use those results to ﬁnd the particular responses in iR(t), iC(t), iL(t), and v(t) to
vs(t) = estu(t) and evaluate them for s = 0.
Solution
The particular solution to an exponential input est is an exponential function Hest.
H is a function of s and is found by substituting est into the differential equation.
d2v
dt2 + 200dv
dt + 108v = 200dvs
dt ,
Hv(s) =
200s
s2 + 200s + 108 ,
Hv(0) = 0
d2iR
dt2 + 200diR
dt + 108iR =
1
500
d2vs
dt2 + 2 × 105vs,
HR(s) = 0.002s2 + 2 × 105
s2 + 200s + 108 ,
HR(0) = 2 × 10−3
d2iL
dt2 + 200diL
dt + 108iL = 2 × 105vs,
HL(s) =
2 × 105
s2 + 200s + 108 ,
HL(0) = 2 × 10−3
d2iC
dt2 + 200diC
dt + 108iC =
1
500
d2vs
dt2 ,
HC(s) =
0.002s2
s2 + 200s + 108 ,
HC(0) = 0
Example
5.14
In the circuit of Figure 5.2 ﬁnd the particular responses in v(t) to an input vs(t) =
cos(ωt)u(t) for ω = 9,900, 10,000, and 10,100 rad/s.
Solution
Using the results of Example 5.13, we ﬁrst ﬁnd the particular solutions to exponential
inputs est with s = j10,000 and j(10,000 ± 100).
input
⇒
H(s)
⇒
particular response
e j9,900t
Hv(s)

s= j9,900 ≈0.707̸ π/4
vp(t) ≈0.707e j(9,900t+π/4)
e j10,000t
Hv(s)

s= j10,000 = 1
vp(t) = e j10,000t
e j10,100t
Hv(s)

s= j10,100 ≈0.707̸ −π/4
vp(t) ≈0.707e j(10,100t−π/4)

274
CHAPTER 5
Differential Equations and LTI Systems
The sinusoidal input vs(t) = cos(ωt)u(t) is the sum of two complex conjugate
exponentials. Its particular solution is found by superposition of the individual expo-
nentials. The results are
input
⇒
particular response
cos(9,900t)u(t)
vp(t) ≈0.707 cos(9,900t + π/4)u(t)
cos(10,000t)u(t)
vp(t) = cos(10,000t)u(t)
cos(10,100t)u(t)
vp(t) ≈0.707 cos(9,900t −π/4)u(t)
5.4
The Homogeneous Solution
The equation with zero input is called the homogeneous equation and its solution is
called the homogeneous solution.
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = 0, t ≥0
The only function that can satisfy the above equation is an exponential Aest. By substi-
tuting Aest into the differential equation we ﬁnd
Aest(sn + an−1sn−1 + · · · + a1s + a0) = 0
The above equation is satisﬁed if either A = 0 (which results in a zero homogeneous
solution and is of no interest) or s is a root of the following equation (called the charac-
teristic equation):
sn + an−1sn−1 + · · · + a1s + a0 = 0
The characteristic equation of an nth-order differential equation has n roots sk, k =
1, 2, . . . n. Assume at ﬁrst no multiple roots. Each exponential Akeskt satisﬁes the ho-
mogeneous equation individually. However, for the n boundary conditions to be met, the
homogeneous solution should contain all n exponentials. Therefore, the homogeneous
solution is
yh(t) =
n

k=1
Akeskt
Akeskt is called a natural response and sk is called a natural frequency as these have
correlations with responses of physical systems.
Example
5.15
In the circuit of Figure 5.2 ﬁnd the homogeneous responses in iR, iC(t), iL(t), and
v(t).
Solution
The differential equations have the same characteristic equation and natural frequen-
cies
s2 + 200s + 108 = 0, s1,2 = −100 ± j

108 −104 ≈−100 ± j104

Signals and Systems
275
The homogeneous solutions have the same functional form yh(t) shown below:
yh(t) = e−100t(αe j104t + βe−j104t),
= e−100t[A cos(104t) + B sin(104t)],
= Ce−100t cos(104t + θ),
In the above equation, α and β are complex conjugate constants. A, B, C, and θ are
real-valued constants. The constants are to be determined by the input and the initial
conditions for each variable.
5.5
Composing the Complete Solution
The complete solution needs to satisfy (1) the differential equation and (2) the initial
conditions. You can easily see that the sum of the homogeneous and particular solutions
can satisfy the differential equation. By setting coefﬁcients Ak in the homogeneous
solution to the appropriate values, the homogeneous solution makes it possible for the
complete solution to satisfy the boundary conditions also. In this sense, the homogeneous
solution complements the particular solution in meeting the boundary conditions and,
therefore, is also called the complementary solution. The following recipe is, therefore,
used to ﬁnd the complete response:
1.
From the characteristic equation ﬁnd the natural frequencies and natural response
with the unknown coefﬁcients.
2.
Find the forced response and form the complete response.
3.
Determine the unknown coefﬁcients of the natural response by matching the
complete response to the initial conditions.
5.6
Examples of Complete Solutions
Example
5.16
Find the response of the ﬁrst-order differential equation
y′(t) + 0.5y(t) = 1, t ≥0, y(0) = 1
Solution
The forced response (from Table 5.1, or by inspection) is yp(t) = c. By substituting
yp(t) in the equation we ﬁnd c = 2. However, we observe that yp(0) ̸= 1. Therefore,
we need to add the natural response to meet the initial condition. To ﬁnd the natural
response we form the characteristic equation s+0.5 = 0 and ﬁnd its root at s = −0.5.
The natural response is yh(t) = Ae−0.5t. The complete response is y(t) = 2+ Ae−0.5t.
The initial condition requires y(0) = 2 + A = 1, from which we ﬁnd A = −1. The
complete response is, therefore,
y(t) = 2 −e−0.5t, t ≥0

276
CHAPTER 5
Differential Equations and LTI Systems
Example
5.17
Find the solution to the second-order differential equation
y′′(t) + 3y′(t) + 2y(t) = sin 3t, t ≥0, y(0) = 0, y′(0) = 0
Solution
The characteristic equation is s2 + 3s + 2 = 0. The natural frequencies are s1,2 =
−1, −2. The natural response is yh(t) = A1e−t + A2s−2t. The forced response is
yp(t) = c1 sin 3t + c2 cos 3t. By substituting yp(t) in the equation we ﬁnd c1 =
−7/130 and c2 = −9/130. The complete response is
y(t) = A1e−t + A2s−2t −
1
130(7 sin 3t + 9 cos 3t)
Constants A1 and A2 are found from the initial conditions
y(0) = A1 + A2 −
9
130 = 0
y′(0) = −A1 −2A2 −21
130 = 0
These give A1 = 39/130 and A2 = −30/130. The complete response is, therefore,
y(t) =
1
130
	
39e−t −30e−2t −7 sin 3t −9 cos 3t

, t ≥0
Example
5.18
Given
y′′(t) + 2y′(t) + 5y(t) = x′(t) + x(t)
ﬁnd y(t) for x(t) = sin t, t ≥0, y(0) = 0, y′(0) = 0.
Solution
The characteristic equation is s2 + 2s + 5 = 0. The natural frequencies are s1,2 =
−1 ± j2. The natural response is
yh(t) = A1e(−1+ j2)t + A2s(−1−j2)t
Since yh(t) is a real function of t and the natural frequencies are complex conjugates
of each other, the coefﬁcients A1 and A2 must also be a complex conjugate pair:
A1 = A∗
2 = (C/2)e jθ. The natural response may, therefore, be written as
yh(t) = C
2 e jθe(−1+ j2)t + C
2 e−jθe(−1−j2)t
= C
2 e−t 
e j(2t+θ) + e−j(2t+θ)
= Ce−t cos(2t + θ)

Signals and Systems
277
The forced response is yp(t) = k sin(t + φ). By substituting yp(t) in the equation we
ﬁnd k = 1/
√
10 = and φ = sin−1(1/
√
10) = 18.44◦.7 The complete response is
y(t) = yh(t) + yp(t) = Ce−t cos(2t + θ) +
1
√
10
sin(t + 18.44◦)
The two parameters C and θ are determined from the initial conditions.
y(0) = C cos θ + 0.1 = 0
y′(0) = −C cos θ −2C sin θ + 0.3 = 0
C =
√
5
10 , and θ = tan−1(−2) = 116.56◦
The complete response is then
y(t) =
√
5
10 e−t cos(2t + 116.56◦) +
√
10
10 sin(t + 18.44◦)
=
√
5
10

e−t cos(2t + 116.56◦) +
√
2 sin(t + 18.44◦)

, t ≥0
Alternative Solution
The homogeneous solution is e−t(C cos 2t + D sin 2t). The particular solution is
yp(t) = A cos t + B sin t. By substituting yp(t) in the equation, we ﬁnd A = 0.1,
B = 0.3, and yp(t) = 0.1 cos t + 0.3 sin t.
The complete solution is
y(t) = yh(t) + yp(t) = e−t(C cos 2t + D sin 2t) + 0.1 cos t + 0.3 sin t
The two parameters C and D are determined from the initial conditions.
y(0) = C + 0.1 = 0
y′(0) = −C + 2D + 0.3 = 0
C = −0.1 and D = −0.2
The complete solution is then
y(t) = 1
10

cos t + 3 sin t −e−t(cos 2t + 2 sin 2t)

, t ≥0
Example
5.19
As previously mentioned in section 5.2, in circuits and systems theory we refer to
the particular solution as the forced response and the homogeneous solution as the
natural response. Exponent s is called the complex frequency and the roots of the
characteristic equation are the natural frequencies. In some cases, the natural and
forced responses, including a possible steady-state response and initial conditions,
can be deduced directly from the properties of the system and its elements. The circuit
7The sinusoidal forced response may also be found more easily by employing the system f unction
described in section 5.11.

278
CHAPTER 5
Differential Equations and LTI Systems
of Figure 5.2 provides such an example. Find the responses of iR(t), iC(t), iL(t), and
v(t) to a unit-step input vs(t) = u(t).
Solution
The differential equations were obtained previously in Example 5.11. The particular
solutions to vs(t) = u(t) and the homogeneous solutions were found in Examples
5.13 and 5.15, respectively. The particular solutions are speciﬁc to each variable but
homogeneous solutions have the same functional form e−at(A cos ωt + B sin ωt),
where a = −100 and ω = 10, 000. The total solution is the sum of the particular
and homogeneous solutions. Since the functions and variables of the equation are all
zero for t < 0, in the following table we have multiplied the total responses by u(t).
The initial conditions can be derived from the behavior of the differential equations
in transition from t = 0−(where vs = 0) to t = 0+ (where vs = 1). (In the present
case, the initial conditions can also be derived directly from the circuit.) The results
are summarized below.
1. v(t) = e−at(Av cos ωt + Bv sin ωt)u(t),
v(0+) = 0,
v′(0+) = 200
2. iR(t) = [e−at(AR cos ωt + BR sin ωt) + 2 × 10−3]u(t),
iR(0+) = 2 × 10−3,
i′
R(0) = 2 × 10−3δ(t)
3. iL(t) = [e−at(AL cos ωt + BL sin ωt) + 2 × 10−3]u(t),
iL(0+) = 0,
i′
L(0+) = 0
4. iC(t) = e−at(AC cos ωt + BC sin ωt)u(t),
iC(0+) = 2 × 10−3,
i′
C(0) = 2 × 10−3δ(t)
The constants in (1) and (3) can be determined by application of the initial conditions.
The results are
Av = 0
and
Bv = 0.02 V/s
AL = −2 × 10−3
and
BL = −2 × 10−5 A/s
Application of the initial conditions to (2) results in AR = 0 but cannot determine
BR because it produces an identity with both sides containing an impulse function.
A similar situation arises with (4), resulting in AC = 2 × 10−3 but leaving BC
undetermined. The apparent difﬁculty can be overcome by ﬁrst ﬁnding the solution
to the following differential equation:
d2y
dt2 + 200dy
dt + 108y = u(t)
Then, by using the derivative and superposition properties of the LTI systems, con-
struct the solutions to (2) and (4). The solution y(t) to a unit-step input is given by
the ﬁrst line of the table below. Responses to the ﬁrst two derivatives of the above
input are obtained simply by taking the derivatives of the unit-step response. They
are given by the second and third lines in the table, respectively.
Input
⇒
Complete Solution
vs = u(t)
⇒
y(t) = 10−8
1 −e−100t 	
cos ωt + 10−2 sin ωt

 
u(t),
ω = 10, 000
dvs
dt
⇒
dy
dt = 10−4e−100t (sin ωt) u(t)
d2vs
dt2
⇒
d2y
dt2 = e−100t 	
cos ωt −10−2 sin ωt

u(t)

Signals and Systems
279
By applying superposition we can ﬁnd the solutions for (2) and (4) in response to the
input vs = u(t).
(2)
d2iR
dt2 + 200diR
dt + 108iR =
1
500
d2vs
dt2 + 2 × 105vs,
iR(t) =
1
500
d2y
dt2 + 2 × 105y(t)
= 2 × 10−3 	
1 −0.02e−100t sin ωt

u(t)
(4)
d2iC
dt2 + 200diC
dt + 108iC =
1
500
d2vs
dt2 ,
iC(t) =
1
500
d2y
dt2
= 2 × 10−3e−100t 	
cos ωt −10−2 sin ωt

u(t)
From the above responses one can easily verify that
(2) iR(0+) = 2 × 10−3
and
i′
R(0) = 2 × 10−3δ(t)
(4) iC(0+) = 2 × 10−3
and
i′
C(0) = 2 × 10−3δ(t)
5.7
Special Case: Multiple Roots
A root of an equation repeated p times is called a multiple root of the pth order. The
contribution to the natural response from a multiple root sk of order p is
(Ak + Ak+1t + Ak+2t2 + · · · + Ak+p−1t p−1)e−skt
For example, the equation s2 + 2s + 1 −0 has a multiple root of order 2 at s = −1. The
natural response due to it is (A1 + A2t)e−t.
Example
5.20
Find the solution to the differential equation below.
y′′′ + 5y′′ + 7y′ + 3y = 0, t ≥0, y(0) = 1, y′(0) = 1, y′′(0) = 1
Solution
The characteristic equation is
s3 + 5s2 + 7s + 3 = 0
The roots are s1,2 = −1 and s3 = −3. The solution contains the natural response
only:
y(t) = (A1 + A2t)e−t + A3e−3t
y′(t) = (−A1 + A2 −A2t)e−t −3A3e−3t
y′′(t) = (A1 −2A2 + A2t)e−t + 9A3e−3t

280
CHAPTER 5
Differential Equations and LTI Systems
From the initial conditions we see that
y(0) = A1 + A3 = 1
y′(0) = −A1 + A2 −3A3 = 1
y′′(0) = A1 −2A2 + 9A3 = 1
Hence,
A1 = 0,
A2 = 4,
A3 = 1,
and
y(t) = 4te−t + e−3t,
t ≥0
5.8
When the Input Contains Natural
Frequencies
An LTI system may be driven by a forcing function that has the same frequency as the
natural frequency of the system; for example, x(t) = es0t, with s0 being a root of the
characteristic equation. In that case, the particular solution is yp(t) = Ates0t. The factor
A is obtained by substituting yp(t) in the equation.
Example
5.21
Find the solution of the differential equation
y′(t) + y(t) = e−t, t ≥0, and y(0) = 0
Solution
The homogeneous solution is Ae−t. By substitution we ﬁnd the particular solution to
be te−t. The complete solution is y(t) = Ae−t + te−t. From the initial condition we
ﬁnd y(0) = A = 0 and so y(t) = te−t, t ≥0.8
Example
5.22
Find the solution of the differential equation
y′′(t) + y(t) = cos t, t ≥0
given the following initial conditions:
a)
y(0) = 0 and y′(0) = 0
b)
y(0) = 1 and y′(0) = 0
Solution
The particular solution and its derivatives are
yp(t) = t(A cos t + B sin t)
y′(t) = A cos t + B sin t + t(−A sin t + B cos t)
y′′(t) = (−A sin t + B cos t) + (−A sin t + B cos t) + t(−A cos t −B sin t)
8By inspection one can see that y(t) = te−t is the solution.

Signals and Systems
281
By substituting those into the differential equation we obtain
y′′(t) + y(t) = (−A sin t + B cos t) + (−A sin t + B cos t)
+ t(−A cos t −B sin t) + t(A cos t + B sin t) = cos t
which results in A = 0, B = 0.5, and yp(t) = 0.5t sin t. The homogeneous solution
is yh(t) = C cos t + D sin t. The complete solution is
y(t) = yp(t) + yh(t) = 0.5t sin t + C cos t + D sin t
The initial conditions are y(0) = C and y′(0) = D. The complete solutions for t ≥0
are (a) y(t) = 0.5t sin t and (b) 0.5t sin t + cos t.
5.9
When the Natural Response May Be Absent
The natural response would be absent if the forced response by itself meets the initial
conditions. Example 5.22(a) was such a case. Four more examples are given below.
Example
5.23
Find the response of the ﬁrst-order differential equation
y′(t) + 0.5y(t) = 1, t ≥0, y(0) = 2
Solution
The forced response is yp(t) = 2. The natural response is yh(t) = Ae−0.5t. The total
response is y(t) = 2 + Ae−0.5t. The initial condition requires A = 0. The complete
response is, therefore,
y(t) = yp(t) = 2, t ≥0
Example
5.24
Find the solution to the second-order differential equation
y′′(t) + 3y′(t) + 2y(t) = sin 3t, t ≥0, y(0) = −9
130, y′(0) = −21
130
Solution
This is the equation of Example 5.17, except for the different initial conditions. The
particular solution was found to be
yp(t) = −1
130(7 sin 3t + 9 cos 3t)
The above solution by itself meets the initial conditions: yp(0) = −9
130 and y′
p(0) =
−21
130. The natural response is, therefore, zero.

282
CHAPTER 5
Differential Equations and LTI Systems
Example
5.25
Consider the differential equation
y′(t) + y(t) =

cos t,
t ≤t0
0.5,
t > t0
Find t0 so that y(t) = 0.5, t > t0.
Solution
Before the switch the response is y(t) = A sin t + B cos t. The unknown coefﬁcients
A and B can be found by substitution:
y′(t) + y(t) = (A cos t −B sin t) + (A sin t + B cos t)
= (A + B) cos t + (A −B) sin t = cos t
From which A = B = 0.5 and y(t) = 0.5(sin t + cos t), t ≤t0. During the switch
y(t) remains continuous. After the switch the forced response is 0.5. For the natural
response to disappear, the forced response alone must meet the initial condition,
that is,
y(t0) = 0.5(sin t0 + cos t0) = 0.5
For the above equation to be valid, the switch must act at the following instances:
sin(t0 + π4) =
√
2
2 ,
t0 = k0
π
2 ± 2kπ,
k0 = 0 or 1, and k an integer
t0 = · · · −7π/2, −2π, −3π/2, 0, π/2, 2π, 5π/2, . . .
Example
5.26
Find the solution of the differential equation
y′(t) + y(t) = e−2t, t > 0, and y(0) = −1
Solution
By inspection and substitution we ﬁnd the particular solution to be yp(t) = −e−2t,
which by itself satisﬁes the initial condition yp(0) = −1. There is no natural compo-
nent in the response.
5.10
Response to an Exponential Input
Consider the differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = est
where s is not a root of the characteristic equation. The particular response is found by
substitution:
yp(t) =
1
sn + an−1sn−1 + · · · + a1s + a0
est

Signals and Systems
283
Regardless of the period during which the differential equation is speciﬁed, the particular
response is proportional to the input. If the equation is valid for −∞< t < ∞, then
the complete response becomes proportional to the input as it is made of the particular
response only. If the period of the equation is semi-inﬁnite (e.g., t ≥0) and the system is
causal, then the total response will contain additional exponential components of natural
frequencies whose strengths are found from the initial conditions.
5.11
The System Function
The response of the differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = bm
dmx
dtm + bm−1
dm−1x
dtm−1 + · · · + b1
dx
dt + b0x
to an exponential input is an exponential
X0est
⇒Y0est
where Y0 is found by substitution:9
	
sn + an−1sn−1 + · · · + a1s + a0

Y0est =
	
bmsm + bn−1sm−1 + · · · + b1s + b0

X0est
From the above equation, the amplitude of the output is Y0 = H(s)X0, where
H(s) = bmsm + bn−1sm−1 + · · · + b1s + b0
sn + an−1sn−1 + · · · + a1s + a0
It is seen that the output is proportional to the input. The proportionality factor, H(s),
is called the system function. It is easily obtained from the differential equation by
employing the notation s = d
dt to represent the derivative operator.10 The system function
not only gives the response amplitude to an exponential input, but also can provide the AC
steady-state response and the response to any input expressed as a sum of exponentials
or sinusoids. In addition, the denominator of the system function contains the natural
frequencies of the system, which determine its natural response. In fact, the complete
response may easily be written from the system function if the input and the initial
conditions are given. This makes H(s) a powerful tool in linear system analysis. The
following example illustrates this point.
9The special case of s being a root of the characteristic equation was addressed in section 5.8.
10Using the D operator, the differential equation may be written as Dn[y] = Dm[x], where Dn and Dm are
linear operators acting on y(t) and x(t), respectively. They are constructed from sums of sk, where sk
represents differentiation repeated k times.
Dn = sn + an−1sn−1 + · · · + a1s + a0
Dm = bmsm + bm−1sn−1 + · · · + b1s + b0
The system function is then
H(s) = Dm(s)
Dn(s) = bmsm+bm−1sm−1+···+b1s+b0
sn+an−1sn−1+···+a1s+a0

284
CHAPTER 5
Differential Equations and LTI Systems
Example
5.27
Using the system function, ﬁnd the solution to the differential equation
y′′′ + 5y′′ + 7y′ + 3y = 3x′ + 2x
where x = e−2t, t ≥0, y(0) = 0, y′(0) = 0, and y′′(0) = 3.
Solution
The system function is
H(s) =
3s + 2
s3 + 5s2 + 7s + 3
The roots of the denominator polynomial are s1,2 = −1 and s3 = −3. The natural
response is
yn(t) = (A1 + A2t)e−t + A3e−3t
The system function evaluated at s = −2 (exponent of the input) is
H(s)

s=−2 =
−3 × 2 + 2
−8 + 5 × 4 −7 × 2 + 3 = −4
The forced response is
yp(t) = H(s)|s=−2 e−2t = −4e−2t
The total response is
y(t) = yh(t) + yp(t) = (A1 + A2t)e−t + A3e−3t −4e−2t
To ﬁnd A1, A2, and A3 we ﬁrst ﬁnd y′(t) and y′′(t).
y′(t) = (−A1 + A2 −A2t)e−t −3A3e−3t + 8e−2t
y′′(t) = (A1 −2A2 + A2t)e−t + 9A3e−3t −16e−2t
From the initial conditions we get
y(0) = A1 + A3 −4 = 0
y′(0) = −A1 + A2 −3A3 + 8 = 0
y′′(0) = A1 −2A2 + 9A3 −16 = 3
Solving for A1, A2, A3 we have A1 = 2.25,
A2 = −0.5,
A3 = 1.75. After
substituting for A1, A2, A3 we have the complete solution.
y(t) = (2.25 −0.5t)e−t + 1.75e−3t −4e−2t, t ≥0
5.12
Sinusoidal Steady-State Response
Consider the differential equation with a sinusoidal input
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = X0 cos(ωt),
−∞< t < ∞

Signals and Systems
285
where X0 and ω are real constants. The input may be written as the sum of two expo-
nentials with s1 = jω and s2 = −jω:
X0 cos(ωt) = X0
2
	
e jωt + e−jωt
Fromthediscussiononexponentialinputsandthelinearitypropertyweﬁndtheresponses
to the above components and their sum. The system function for s = ± jω may be
written as
H(s)

s=± jω = |H(ω)|e± jθ
which is a real function of jω (or a complex function of ω). For simplicity, in this book
we use the following notation:
H(s)

s= jω = H(ω) = |H(ω)|e jθ
Construction of sinusoidal steady-state responses from exponential inputs is given below.
Input
⇒
Response
e jωt
⇒
|H(ω)|e j(ωt+θ)
e−jωt
⇒
|H(ω)|e−j(ωt+θ)
e jωt + e−jωt
⇒
2|H(ω)| cos(ωt + θ)
X0 cos ωt
⇒
|H(ω)|X0 cos(ωt + θ)
The differential equation scales the magnitude of the sinusoidal input by the factor
|H(ω)| and adds θ = ̸ H(ω) to its phase angle. The above result may also be derived
directly from the real property of the system.
cos ωt = RE{e jωt} ⇒RE{H(ω)e jωt} = |H(ω)| cos(ωt + θ)
For more details on this subject see the discussion on the frequency response in Chapter 9.
5.13
Unit-Step Response
The solution of the following differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = u(t)
is called the unit-step response. Assume a causal system y(t) = 0, t < 0. For t > 0,
the response is made of the homogeneous solution and the particular solution.
y(t) = yh(t) + yp(t)

286
CHAPTER 5
Differential Equations and LTI Systems
Let the roots of the characteristic equation be sk, k = 1, . . . , n, with none being a
multiple root. The homogeneous solution is
yh(t) =
n

k=1
Akeskt
The particular solution is a constant whose value may be found by substitution.
yp(t) = 1
a0
The total solution is, therefore,
y(t) =
 n

k=1
Akeskt + 1
a0

u(t)
The constants Ak are found from the initial conditions of y and its n −1 derivatives
at t = 0+. These remain at a zero value because the step jump in the right side of the
differential equation produces a jump in the highest derivative on the left side and leaves
the rest of the terms unchanged.11
y(0+) = 1
a0
+
n

k=1
Ak = 0
y′(0+) =
n

k=1
Aksk = 0
y′′(0+) =
n

k=1
Aks2
k = 0
...
y(n−1)(0+) =
n

k=1
Aksn−1
k
= 0
Example
5.28
The circuit of Figure 5.3 is a second-order passive low-pass ﬁlter. Let R = 1 k,
L = 1/(
√
2π) H and C = 1/(
√
2π) µF.
a.
Find the differential equation that relates v2(t) to v1(t).
b.
Find its unit-step response.
R
L
v2
R
C
+
–
v1
+
–
+
–
FIGURE 5.3 A second-order passive low-pass ﬁlter.
11For a broader discussion on the effect of discontinuity in the forcing function see section 5.15.

Signals and Systems
287
Solution
a.
Let i be the current ﬂowing from left to right through the RL path. Then,
From KVL around the RL loop
Ri + L di
dt = v1 −v2
From KCL at the output node
i = v2
R + C dv2
dt
Eliminate i from the above equations to ﬁnd
dv2
2
dt2 +
 1
RC + R
L
 dv2
dt +
2
LC v2 =
1
LC v1
Substitute for the element values to obtain
dv2
2
dt2 +
√
2ω0
dv2
dt + ω2
0v2 = ω2
0
2 v1
where ω0 ≡

2
LC = 2,000π.
b.
The characteristic equation and its roots are
s2 +
√
2ω0s + ω2
0 = 0, s1,2 = −ω0 (1 ± j) /
√
2
The particular solution is a constant, and by substitution, its value is found to be
0.5. The total solution is
v2(t) =

0.5 + e−ω0t
√
2

A cos ω0t
√
2
+ B sin ω0t
√
2

u(t)
The initial conditions are v2(0) = v′
2(0) = 0. By using the initial conditions we
ﬁnd A = −0.5 and B = −0.5/ω0. The unit-step response is, therefore,
v2(t) = 0.5

1 −e−ω0t
√
2

cos ω0t
√
2
+ 1
ω0
sin ω0t
√
2

u(t)
Example
5.29
The active circuit of Figure 5.4 is called a Sallen-Key low-pass ﬁlter. Let m = n = 1,
R = 159 , C = 1 µF, and β ≡
R1
R1+R2 = 0.63.
+
–
+
–
v1
v2
R2
R1
A
mR
B
R
i
C
A
nC
FIGURE 5.4 An equal-component Sallen-Key low-pass ﬁlter circuit.

288
CHAPTER 5
Differential Equations and LTI Systems
a.
Show that
dv2
2
dt2 +
√
2ω0
dv2
dt + ω2
0v2(t) = ω2
0
β v1(t), where ω0 =
1
RC = 2,000π
b.
Find its unit-step response.
Solution
a.
The op-amp is operating in a noninverting conﬁguration with a gain of
v2/vA = 1 + R2/R1 ≡1/β. From the above observation and from application
of KCL at nodes A and B we obtain the following three equations:
Noninverting ampliﬁer:
vA = βv2
(1)
KCL at node A:
vA −vB
R
+ C dvA
dt
= 0
(2)
KCL at node B:
vB −vA
R
+ vB −v1
R
+ C d(vB −v2)
dt
= 0
(3)
Eliminate VA and VB between the above three equations to ﬁnd
dv2
2
dt2 +
1
RC

3 −1
β
 dv2
dt +
1
R2C2 v2(t) =
1
R2C2
1
β v1(t)
Substitute for element values to obtain
dv2
2
dt2 +
√
2ω0
dv2
dt + ω2
0v2(t) = ω2
0
β v1(t)
where ω0 =
1
RC = 2,000π.
b.
From the linearity property we deduce that the unit-step response is the same as
that of Example 5.28 but scaled by 2/β.
5.14
Unit-Impulse Response
The solution of the following differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = δ(t)
is called the unit-impulse response and shown by h(t). The unit-impulse response is the
solution of the homogeneous equation for t > 0.
h(t) =
n

k=1
Bkeskt
The constants Bk are found from the nonzero initial conditions of y and its n −1
derivatives at t = 0+. To ﬁnd these conditions we examine the two sides of the equation
during 0−< t < 0+. During this period the right side of the equation contains a unit
impulse δ(t). The left side should also contain an impulse of the same order and strength.

Signals and Systems
289
Such an impulse can appear only in the highest-order derivative of y:
dny
dtn (t) = δ(t), during 0−< t < 0+
which means a unit jump in y(n−1) at t = 0. Since y(n−1)(0−) = 0, we conclude that
y(n−1)(0+) = 1. All other lower-level derivatives remain zero through the transition from
0−to 0+. The equations that determine the constants Bk are
y(0+) =
n

k=1
Bk = 0
y′(0+) =
n

k=1
Bksk = 0
y′′(0+) =
n

k=1
Bks2
k = 0
...
y(n−1)(0+) =
n

k=1
Bksn−1
k
= 1
Alternate Method
The unit-impulse response is the time derivative of the unit-step response:
h(t) = d
dt g(t) = d
dt
 n

k=1
Akeskt + 1
a0

u(t)

=
n

k=1
Akskesktu(t) +
 n

k=1
Akeskt + 1
a0
 
t=0
δ(t)
But,
 n

k=1
Akeskt + 1
a0
 
t=0
= y(0+) = 0.
Therefore,
h(t) =
n

k=1
Akskesktu(t).
Example
5.30
Find the unit-step and unit-impulse responses of the passive low-pass RC and high-
pass CR ﬁlters.
Solution
The input-output differential equations and responses are derived and included in
Figure 5.5. Note that, as expected, the unit-step responses of the two circuits add up
to a unit step, and the sum of the unit-impulse responses is a unit impulse.

290
CHAPTER 5
Differential Equations and LTI Systems
Circuit
Differential Equation
Unit-Step Response
Unit-Impulse Response
v2
v1
C
R
+
–
+
–
−0.5
0
0.5
1
1.5
2
2.5
3
0
0.2
0.4
0.6
0.8
1
Time (s)
g(t) = (1 – e–t/RC)u(t)
Amplitude
−0.5
0
0.5
1
1.5
2
2.5
3
0
0.2
0.4
0.6
0.8
1
Time (s)
Amplitude
Unit-impulse response of RC
low-pass filter
Unit-step response of RC
low-pass filter
dv2
dt
=
+
v2
1
RC
h(t) = –
e–t/RCu(t)
1
RC
v1
1
RC
FIGURE 5.5 (a)
g(t) = e–t/RCu(t)
Time (s)
dv2
dv1
dt
=
+
v2
1
RC
dt
−0.5
0
0.5
1
1.5
2
2.5
3
0
0.2
0.4
0.6
0.8
1
Time (s)
Amplitude
Amplitude
Unit-impulse response of CR
high-pass filter
Unit-step response of CR
high-pass filter
h(t) = δ(t) –
e–t/RCu(t)
1
RC
1
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1
−0.5
0
0.5
1
1.5
2
2.5
3
v2
v1
R
C
+
–
+
–
FIGURE 5.5 (b)
5.15
Effect of Discontinuity in
the Forcing Function
Consider an LTI system described by the differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = bm
dmx
dtm + bm−1
dm−1x
dtm−1 + · · · + b1
dx
dt + b0x
Let the input x(t) contain a discontinuity (e.g., unit jump, unit impulse, etc.) at t0. What
is the effect of such a discontinuity on y(t) and its derivatives at t0? This question has
direct relevance to the derivation of initial conditions at t+
0 based on their values at t−
0 .
For simplicity we assume t0 = 0, but the conclusions are valid for any t0. In this section
we examine the effect of a unit jump in x(t).
Unit Jump
A unit jump in the input at t = 0 means x(0+) = x(0−)+1. Let the following quantities
be known at t = 0−:
y(n−1)(0−), . . . , y′′(0−), y′(0−), y(0−)

Signals and Systems
291
It is not readily clear whether y(t) and its derivatives are, or are not, continuous at t = 0.
This depends on the structure of the differential equation. The unit jump in the input at
t = 0 produces a sequence of progressively higher-order impulses (i.e., impulse, doublet,
and their higher derivatives) in the right side of the equation, the highest order of which
is an impulse of order m with strength bm. In the functional sense, an impulse of order
m corresponds to the mth derivative of a unit-step function, the Dirac δ (unit-impulse)
function being an impulse of the ﬁrst order and a unit doublet being an impulse of second
order. Using the symbol δm(t) to show a unit inpulse of order m, the right side of the
equation in the vicinity of t = 0 will be bmδm(t). Since the differential equation is valid
during the period 0−≤t ≤0+, the left side should also contain an impulse of the same
order and strength: bmδm(t). Such an impulse can appear only in the highest derivative
of y; that is,
y(n)(t) = bmδm in the vicinity of t = 0
However, this may or may not give us all of the information we would like to have about
the post-jump conditions; in other words,
y(n−1)(0+), . . . , y′′(0+), y′(0+), y(0+)
The analytic solution and simulation of systems represented by the differential equation
are simpliﬁed if a ﬁnite jump in the input does not change the n initial conditions (y and
its n −1 derivatives). That happens when the right side of the differential equation is
limited to b0x(t) and has no derivative components.
Example
5.31
In the following differential equations ﬁnd the initial conditions at t = 0+ necessary
for obtaining the complete response to
a.
a unit impulse x(t) = δ(t)
b.
a unit step x(t) = u(t)
c.
a unit ramp x(t) = tu(t). Note that y(t) and all its derivatives are zero at
t = 0−.
(i)
y′ + 2y = x
(ii)
y′ + 2y = 3x
(iii)
y′ + 2y = x′
(iv)
y′ + 7y = 5x′
(v)
y′′ + 2y′ + 3y = 2x
(vi)
y′′ + 2y′ + 3y = x′ + x
(vii) y′′ + 3y′ + 40y = 4x′
(viii) y′′ + 5y′ + 4y = x′ + 2x
(ix)
y′′′ + 5y′′ + 6y′ + y = 2x
(x)
y′′′ + 5y′′ + 6y′ + y = 3x′ + 2x

292
CHAPTER 5
Differential Equations and LTI Systems
Solution
a.
For x(t) = δ(t) we have
Differential Equation
y(0+)
y ′(0+)
y ′′(0+)
(i)
y′ + 2y = x
1
(ii)
y′ + 2y = 3x
3
(iii)
y′ + 2y = x′
δ(t)
(iv)
y′ + 7y = 5x′
5δ(t)
(v)
y′′ + 2y′ + 3y = 2x
0
2
(vi)
y′′ + 2y′ + 3y = x′ + x
1
δ(t)
(vii)
y′′ + 3y′ + 40y = 4x′
4
4δ(t)
(viii)
y′′ + 5y′ + 4y = x′ + 2x
1
δ(t)
(ix)
y′′′ + 5y′′ + 6y′ + y = 2x
0
0
2
(x)
y′′′ + 5y′′ + 6y′ + y = 3x′ + 2x
0
3
3δ(t)
b.
For x(t) = u(t) we have
Differential Equation
y(0+)
y ′(0+)
y ′′(0+)
(i)
y′ + 2y = x
0
(ii)
y′ + 2y = 3x
0
(iii)
y′ + 2y = x′
1
(iv)
y′ + 7y = 5x′
5
(v)
y′′ + 2y′ + 3y = 2x
0
0
(vi)
y′′ + 2y′ + 3y = x′ + x
0
1
(vii)
y′′ + 3y′ + 40y = 4x′
0
4
(viii)
y′′ + 5y′ + 4y = x′ + 2x
0
1
(ix)
y′′′ + 5y′′ + 6y′ + y = 2x
0
0
0
(x)
y′′′ + 5y′′ + 6y′ + y = 3x′ + 2x
0
0
3
c.
For x(t) = tu(t) we have
Differential Equation
y(0+)
y′(0+)
y ′′(0+)
(i)
y′ + 2y = x
0
(ii)
y′ + 2y = 3x
0
(iii)
y′ + 2y = x′
0
(iv)
y′ + 7y = 5x′
0
(v)
y′′ + 2y′ + 3y = 2x
0
0
(vi)
y′′ + 2y′ + 3y = x′ + x
0
0
(vii)
y′′ + 3y′ + 40y = 4x′
0
0
(viii)
y′′ + 5y′ + 4y = x′ + 2x
0
0
(ix)
y′′′ + 5y′′ + 6y′ + y = 2x
0
0
0
(x)
y′′′ + 5y′′ + 6y′ + y = 3x′ + 2x
0
0
0

Signals and Systems
293
5.16
Solution by Convolution
A linear differential equation with constant coefﬁcients represents an LTI relationship
between the input and output. In the previous sections it was shown how to obtain the
unit-impulse response, h(t). One expects that, like any LTI system, such a differential
equation is also completely characterized by its unit-impulse response. This is in fact true.
From h(t) one can construct the differential equation in its familiar form. The simple case
of a ﬁrst-order equation, given the unit-impulse response, was presented in Example 5.10.
Formal methods of such modeling use the Laplace transform and frequency response
methods. It is, therefore, not surprising that the solution of an LTI differential equation
may be obtained by convolving its unit-impulse response with the input. In other words,
the convolution integral satisﬁes the differential equation and thus, constitutes the com-
plete solution. See Example 5.32 below. The use of convolution as an instrument to
obtain the solution of a differential equation is illustrated by Examples 5.33 and 5.34.
Example
5.32
Consider the differential equation
dy
dt + ay(t) = x(t)
The unit-impulse response of the equation is
h(t) = e−atu(t)
Verify that the convolution integral y(t) = x(t) ⋆h(t) satisﬁes the equation.
Solution
y(t) =
 t
−∞
x(τ)e−a(t−τ)dτ = e−at
 t
−∞
x(τ)eaτdτ
dy
dt = −ae−at
 t
−∞
x(τ)eaτdτ + e−at d
dt
 t
−∞
x(τ)eaτdτ
= −ae−at
 t
−∞
x(τ)eaτdτ + e−atx(t)eat
By substitution,
dy
dt + ay(t) = x(t).
Example
5.33
Given the unit-impulse response of an LTI differential equation, use convolution to
obtain its solution to the input est. Compare the result with the response obtained by
the direct method in sections 5.10 and 5.11 and conclude a relationship between the
two methods.

294
CHAPTER 5
Differential Equations and LTI Systems
Solution
Let h(t) and y(t) represent the unit-impulse response and the solution to x(t) = est,
respectively. Then,
y(t) = x(t) ⋆h(t) =
 ∞
−∞
h(τ)es(t−τ)dτ = est
 ∞
−∞
h(τ)e−sτdτ = H(s)est
The above result conﬁrms the previous observation that the response of an LTI system
to an exponential is an exponential of the same form but magnitude-scaled by a factor
H(s), called the system function (see sections 5.10 and 5.11). The result obtained in
the present example also suggests the following relationship:
H(s) =
 ∞
−∞
h(τ)e−sτdτ



Example 5.33
= bmsm + bn−1sm−1 + · · · + b1s + b0
sn + an−1sn−1 + · · · + a1s + a0



Section 5.11
Example
5.34
Consider the differential equation
d2y
dt2 + 4dy
dt + 3y = 2dx
dt + 8x
a.
Verify that the response to x(t) = est is y(t) = Haest and determine Ha.
b.
Verify that the unit-impulse response is h(t) = (3e−t −e−3t)u(t).
c.
Show that
Hb =
 ∞
−∞
h(τ)e−sτdτ = Ha(s)
Solution
a.
Substitute est for x(t) and collect terms.
d2y
dt2 + 4dy
dt + 3y = (2s + 8)est
The only solution to the above equation is y(t) = Haest, which, by substitution,
results in
(s2 + 4s + 3)Haest = (2s + 8)est
⇒
Ha =
2s + 8
s2 + 4s + 3
b.
Substitute h(t) and its derivatives in the left-hand side of the equation and
verify that it equals the right-hand side with x(t) = δ(t).
h(t) = (3e−t −e−3t)u(t)
dh
dt = (−3e−t + 3e−3t)u(t) + 2δ(t)
d2h
dt2 = (3e−t −9e−3t)u(t) + 2δ′(t)
d2h
dt2 + 4dh
dt + 3h(t) = 8δ(t) + 2δ′(t)

Signals and Systems
295
c.
Hb = 3
 ∞
0
e−τe−sτdτ −
 ∞
0
e−3τe−sτdτ
=
−3
s + 1

e−(s+1)τ∞
τ=0 +
1
s + 3

e−(s+3)τ∞
τ=0
=
3
s + 1 −
1
s + 3 =
2s + 8
s2 + 4s + 3, RE(s) > −1, Hb = Ha
Example
5.35
To prevent aliasing in sampling a speech signal v1(t), the signal is ﬁrst passed through
a ﬁrst-order low-pass ﬁlter (called an antialiasing ﬁlter) such as the RC ﬁlter of
Figure 5.5(a) made of a 530- resistor and a 100-nF capacitor.
a.
Show that the ﬁlter attenuates the power in frequencies above 3 kHz by a factor
of two or more.
b.
The RC ﬁlter may be replaced by a computer software program that performs
convolution between v1(t) and the ﬁlter’s unit-impulse response h(t). Find h(t)
and construct the convolution integral. Then observe that the resulting
convolution integral performs a weighted integration and averaging as
discussed in Chapter 1.
Solution
The differential equation of the RC ﬁlter is
dv2
dt +
1
RC v2 =
1
RC v1, RC = 53 × 10−6
The response to a sinusoidal input v1(t) = cos ωt is v2(t) = |H(ω)| cos(ωt +θ) (see
section 5.12). The ratio of output-to-input power is
|H(ω)|2 =
1
1 +
	 ω
ω0

2 , where ω0 = 1/(RC) = 6,000π (corresponding to 3 kHz).
For f ≥3 kH, the above ratio is less than 0.5. The unit-impulse response of the ﬁlter
and the convolution integral are
h(t) =
1
RC e−t/RCu(t), v2(t) =
1
RC e−t/RC
 t
−∞
v1(τ)eτ/RCdτ
The convolution introduces an exponential weighting factor in v1(t) before integra-
tion. This is similar to section 1.20 in Chapter 1.
5.17
Zero-Input and Zero-State Responses
Consider an LTI system described by the differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = f (t), t ≥0
with nonzero initial conditions at t = 0. From the previous discussions, one expects that
the complete response at t ≥0 is affected by two factors: (i) the initial state at t = 0 and

296
CHAPTER 5
Differential Equations and LTI Systems
(ii) the input during t ≥0. Due to the linearity property of the differential equation, one
expects the complete response to be the sum of the above two responses. One is due to
the initial conditions only and with no input; hence, the zero-input response. The other
is due to the input only and with zero initial conditions; hence, the zero-state response.
Therefore,
y(t) = y1(t) + y2(t)
where y1(t) and y2(t) are zero-input and zero-state responses of the system, respectively.
Zero Input
The zero-input response y1(t) is the complete solution of the following equation
dny1
dtn + an−1
dn−1y1
dtn−1 + · · · + a1
dy1
dt + a0y1 = 0, t ≥0
with nonzero initial conditions
y(n−1)
1
(0), . . . , y′′
1(0), y′
1(0), y1(0).
The solution is made of natural responses only
y1(t) =
n

k=1
Bkeskt
where the coefﬁcients Bk are found from the following n equations:
y(0) =
n

k=1
Bk
y′(0) =
n

k=1
Bksk
y′′(0) =
n

k=1
Bks2
k
...
y(n−1)(0) =
n

k=1
Bksn−1
k
Zero State
The zero-state response y2(t) is the complete solution of the following equation:
dny2
dtn + an−1
dn−1y2
dtn−1 + · · · + a1
dy2
dt + a0y2 = f (t), t ≥0
with zero initial conditions
y(n−1)
2
(0) = · · ·
= y′′
2(0) = y′
2(0) = y2(0) = 0

Signals and Systems
297
The solution is the sum of the homogeneous and particular solutions
y2(t) = yp(t) +
n

k=1
Ckeskt
where the coefﬁcients Ck are found from the following equations:
yp(0) +
n

k=1
Ck = 0
y′
p(0) +
n

k=1
Cksk = 0
y′′
p(0) +
n

k=1
Cks2
k = 0
...
y(n−1)
p
(0) +
n

k=1
Cksn−1
k
= 0
By linearity, the complete response is
y(t) = y1(t) + y2(t) =
n

k=1
(Bk + Ck)eskt + yp(t)
One may easily verify that Bk + Ck = Ak,
k = 1, . . . , n, where the constants Ak are
the coefﬁcients of the natural components found in section 5.5.
Example
5.36
Consider the system described by the differential equation
y′′(t) + 5y′(t) + 6y(t) = x(t)
a.
Find the zero-input response for x(t) = 0, t ≥0, y(0) = 2, y′(0) = −5.
b.
Find the zero-state response for x(t) = 2e−t, t ≥0, y(0) = 0, y′(0) = 0.
c.
Find the complete response for x(t) = 2e−t, t ≥0, y(0) = 2, y′(0) = −5
and verify that the zero-input and zero-state responses add up to the complete
response.
Solution
a.
The zero-input response y1(t) is made of the natural response only. From the
characteristic equation s2 + 5s + 6 = 0 we ﬁnd y1(t) = B1e−2t + B2s−3t. The
initial conditions require that
y1(0) = B1 + B2 = 2
y′
1(0) = −2B1 −3B2 = −5

298
CHAPTER 5
Differential Equations and LTI Systems
from which B1 = B2 = 1 and so
y1(t) = e−2t + e−3t,
t ≥0
b.
The zero-state response is y2(t) = C1e−2t + C2s−3t + e−t, in which e−t is the
particular solution. To satisfy the initial conditions we need
y2(0) = C1 + C2 + 1 = 0
y′
2(0) = −2C1 −3C2 −1 = 0
from which C1 = −2, C2 = 1 and so
y2(t) = −2e−2t + e−3t + e−t,
t ≥0
c.
The complete response to x(t) = 2e−t, t > 0, is y(t) = A1e−2t + A2s−3t +
e−t. However, the initial conditions require that
y(0) = A1 + A2 + 1 = 2
y′(0) = −2A1 −3A2 −1 = −5
from which A1 = −1, A2 = 2 and so
y(t) = −e−2t + 2e−3t + e−t,
t ≥0
Note that A1 = B1 + C1 and A2 = B2 + C2. Consequently,
y(t) = y1(t) + y2(t).
5.18
Zero-State Response and Convolution
The zero-state response of a differential equation may also be obtained by the convolution
of its unit-impulse response with a function that is zero for t < 0 and equal to the input
of the differential equation for t > 0. This is illustrated by the following example.
Example
5.37
Find the zero-state response of the differential equation of Example 5.36 by convo-
lution.
Solution
The differential equation is
y′′(t) + 5y′(t) + 6y(t) = x(t)
The unit-impulse response is h(t) = (e−2t −e−3t)u(t) and x(t) = e−t for t > 0. The
zero-state response is
y2(t) = x(t) ⋆h(t) =
 t
0
eτ−t 	
e−2τ −e−3τ
dτ =
	
e−t −2e−2t + e−3t
u(t)
The convolution produces the same solution as the zero-state response obtained in
Example 5.36 by the classical method.

Signals and Systems
299
5.19
Properties of LTI Differential Equations
A linear differential equation with constant coefﬁcients establishes a linear time-invariant
relationship between the input x(t) and the output y(t). The most widely used properties
of such a relationship are
1.
Linearity
2.
Conjugate symmetry
3.
Derivative and integral
Table 5.2 summarizes some properties of linear time-invariant systems described by
linear differential equations with real constant coefﬁcients.
TABLE 5.2 Properties of Linear Differential Equations with Real Constant Coefficients
Property
Input
⇒
Output
1
Basic pair
x(t)
⇒
y(t)
2
Linearity
ax1(t) + bx2(t)
⇒
ay1(t) + by2(t)
3
Complex function
RE[x(t)] + IM[x(t)]
⇒
RE[y(t)] + IM[y(t)]
4
Real part
RE[x(t)]
⇒
RE[y(t)]
5
Imaginary part
IM[x(t)]
⇒
IM[y(t)]
6
Time delay
x(t −t0)
⇒
y(t −t0)
7
Differentiation
dx(t)
dt
⇒
dy(t)
dt
8
Integration

t
−∞
x(t) dt
⇒

t
−∞
y(t)dt
5.20
Solution by Numerical Methods
A differential equation may be approximated by a discrete equation12 by substituting for
the derivatives of y(t). This may be done in several ways. In the backward approximation
method (also called the backward Euler algorithm),
dy(t)
dt
≈y(t) −y(t −t)
t
The time is incremented by t, while t = nt, ∞< n < ∞, y(t), and its derivatives
become functions of the discrete variable n as listed below.
y(nt) ⇒y(n)
y′(nt) ⇒y(n) −y(n −1)
t
12This results in a difference equation.

300
CHAPTER 5
Differential Equations and LTI Systems
y′′(nt) ⇒y(n) −2y(n −1) + y(n −2)
t2
y′′′(nt) ⇒y(n) −3y(n −1) + 3y(n −2) −y(n −3)
t3
y(n) is calculated iteratively from the weighted ﬁnite sums of its own past values and
the input’s present and past values sampled at intervals of T .
This method may be implemented graphically, or on a computer. The method may
also be applied to nonlinear and time-varying differential equations. The method is
computationally inefﬁcient and the solution is not in closed form. However, it may be
used when input data is given in tabular form or ﬂows in real time.
Example
5.38
Convert the following second-order differential equation to a difference equation
using the backward Euler algorithm.
y′′(t) + 2ζω0y′(t) + ω2
0y(t) = x(t)
Solution
Let the time increment be T . Substituting for y(t) and its derivatives and collecting
terms of y(n), y(n −1), and y(n −2), we obtain
 1
T 2 + 2ζω0
T
+ ω2
0

y(n) −
 2
T 2 + 2ζω0
T

y(n −1) +
 1
T 2

y(n −2) = x(n)
In simpliﬁed form,
y(n) = b0x(n) −a1y(n −1) −a2y(n −2)
where,
b0 =
T 2
1 + 2ζω0T + ω2
0T 2
a1 = −
2 + 2ζω0T
1 + 2ζω0T + ω2
0T 2
a2 =
1
1 + 2ζω0T + ω2
0T 2
5.21
Concluding Remarks
This chapter has presented a detailed solution method for linear differential equations
with constant coefﬁcients. The method recognizes the correlation of the homogeneous
and particular parts of the solution with familiar components of the responses in physical
systems—the natural and forced responses. Many physical systems of interest are non-
linear, which may seem to make the present chapter idealized and irrelevant. Such is not

Signals and Systems
301
the case, however. Linearization of complex nonlinear systems may require extensive
analytical manipulation of equations, a task that was daunting several decades ago and
made practical applications less likely. The help provided by computers, however, has
made the use of the smalll scale piecewise linear model approach a practical tool for
analysis and design. Examples and problems in this chapter are designed primarily to
clarify concepts, but they also provide brief insights into some broader aspects of system
analysis such as modeling and system functions.
5.22
Problems
Solved Problems
Find y(t), the solution to the differential equation in each of problems 1–6.
1. d2y
dt2 + 2dy
dt + y = x(t) −dx
dt , t > 0, with y(0) = 1, dy
dt (0) = −1, and x(t) = e−3t −e−2t, t > 0
Solution
The characteristic equation and natural frequencies are
s2 + 2s + 1 = 0, s1,2 = −1
The homogeneous solution is
yh(t) = (A + Bt)e−t
The system function and its values at s corresponding to the right-hand side of the differential equation are
H(s) =
−s + 1
s2 + 2s + 1, H1 = H(s)

s=−3 = 1, and H2 = H(s)

s=−2 = 3
The particular solution is
yp(t) = H1e−3t −H2e−2t = e−3t −3e−2t
The total solution is
y(t) = yp(t) + yh(t) = e−3t −3e−2t + (A + Bt)e−t
By applying the initial conditions we ﬁnd A and B.
 y(0) = A + 1 −3 = 1,
A = 3
y′(0) = B −A −3 + 6 = −1,
B = −1
The solution to the differential equation is, therefore,
y(t) = e−3t −3e−2t + (3 −t)e−t, t > 0
2. d2y
dt2 + 200dy
dt + 108y = 200dx
dt , t > 0, with y(0+) = 0, dy
dt (0+) = 200, and x(t) = 1, t > 0

302
CHAPTER 5
Differential Equations and LTI Systems
Solution
s2 + 200s + 108 = 0, s1,2 ≈−100 ± j104, yh(t) = e−100t 	
A cos 104t + B sin 104t
, yp(t) = 0
By applying the initial conditions, we ﬁnd A, B, and the total solution.
y(0) = A = 0, y′(0) = 104B = 200, B = 0.02
y(t) = 0.02e−100t sin 104t, t > 0
3. d2y
dt2 + 200dy
dt + 108y = 5x(t) + 100dx
dt , where x(t) = u(t)
Solution
H(s) =
100s + 5
s2 + 200s + 108 , H1 = H(s)

s=0 = 5 × 10−8, yp(t) = 5 × 10−8
yh(t) = e−100t 	
A cos 104t + B sin 104t
y(t) = yh(t) + yp(t) = e−100t 	
A cos 104t + B sin 104t
+ 5 × 10−8
The conditions at t = 0+ are y(0+) = 0 and y′(0+) = 100. By applying the initial conditions we ﬁnd A and B.

y(0) = A + 5 × 10−8 = 0,
A = −5 × 10−8
y′(0) = −100A + 104B = 100,
B = 0.01
The total solution is
y(t) = 
e−100t 	
−5 × 10−8 cos 104t + 0.01 sin 104t
+ 5 × 10−8
u(t)
≈(5 × 10−8 + 0.01e−100t sin 104t)u(t)
4. d2y
dt2 + 650dy
dt + 30, 000y = 104

3x(t) + dx
dt

, where x(t) = (sin 100t)u(t)
Solution
H(s) =
104(s + 3)
s2 + 650s + 30,000, H(s)

s= j100 = 103 + 100 j
20 + 65 j = 14.71̸ 15.4◦
The particular solution is 14.71 sin(100t + 15.4◦).
The characteristic equation and its roots are s2 + 650s + 30,000 = 0, s1,2 = −600, −50.
The homogeneous solution is Ae−600t + Be−50t.
The total solution is 14.71 sin(100t + 15.4◦) + Ae−600t + Be−50t.
Initial conditions are y(0+) = 0 and y′(0+) = 0, which result in A = 2.933 and B = −6.836.
y(t) = 
14.71 sin(100t + 15.4◦) + 2.933e−600t −6.836e−50t
u(t)

Signals and Systems
303
An alternative method for ﬁnding yp(t) in problem 4
yp(t) = C cos ωt + D sin ωt, ω = 100
y′
p(t) = 100 (−C sin ωt + D cos ωt)
y′′
p(t) = −104 (C cos ωt + D sin ωt)
Substitute the above expressions in the differential equation
−104 (C cos ωt + D sin ωt) + 65,000 (−C sin ωt + D cos ωt) + 30,000 (C cos ωt + D sin ωt)
= 104(3 sin ωt + 100 cos ωt)
−(C cos ωt + D sin ωt) + 6.5 (−C sin ωt + D cos ωt) + 3 (C cos ωt + D sin ωt)
= (3 sin ωt + 100 cos ωt)
By collecting all terms and equating same-kind coefﬁcients we get

6.5D + 2C = 100
6.5C −2D = −3
from which we ﬁnd C = 3.902 and D = 14.184.
The particular solution becomes yp(t) = 3.902 cos 100t + 14.184 sin 100t = 14.71 sin(100t + 15.38◦).
5. d2y
dt2 + 3dy
dt + 2y = −dx
dt , where x(t) = (sin 3t)u(t)
Solution
The homogeneous solution is yh(t) = Ae−t + Be−2t.
The particular solution is
yp(t) = C cos ωt + D sin ωt, ω = 3
y′
p(t) = 3 (−C sin ωt + D cos ωt)
y′′
p(t) = −9 (C cos ωt + D sin ωt)
Substitute the above expressions in the differential equation to get
−9 (C cos ωt + D sin ωt) + 9 (−C sin ωt + D cos ωt) + 2 (C cos ωt + D sin ωt) = −3 cos ωt
By collecting terms on the left-hand side and equating with same-kind coefﬁcients on the right-hand side we get

7C −9D = 3
, from which we ﬁnd C = 0.162 and D = −0.208.
7D + 9C = 0
y(t) = (0.162 cos 3t −0.208 sin 3t + Ae−t + Be−2t)u(t)
Initial conditions are y(0) = y′(0) = 0, which give y(0) = 0.162 + A + B = 0 and y′(0) = −0.208 × 3 −
A −2B = 0.

A + B = −0.162
, A = 0.3, B = −0.462
A + 2B = −0.623
The total solution is, therefore,
y(t) = 	
0.162 cos 3t −0.208 sin 3t + 0.3e−t −0.462e−2t
u(t)
= 
0.263 cos(3t + 52◦) + 0.3e−t −0.462e−2t
u(t)
6. d3y
dt3 + d2y
dt2 + dy
dt + y = e−tu(t)

304
CHAPTER 5
Differential Equations and LTI Systems
Solution
The characteristic equation and the natural frequencies are
s3 + s2 + s + 1 = (s + 1)(s2 + 1) = 0, s1,2,3 = −1, ± j
The homogeneous solution is yh(t) = Ae−t + B sin t + C cos t. The particular solution is yp(t) = Dte−t. By
substitution we determine D = 0.5. The total solution for t > 0 is
y(t) = Ae−t + B sin t + C cos t + 0.5te−t
y′(t) = −Ae−t + B cos t −C sin t + 0.5e−t −0.5te−t
y′′(t) = Ae−t −B sin t −C cos t −e−t + 0.5te−t
From the initial conditions we ﬁnd y(0) = A +C = 0, y′(0) = −A + B +0.5 = 0, and y′′(0) = A −C −1 = 0.
The constants are A = 0.5, B = 0, and C = −0.5.
The solution to the differential equation is
y(t) = [0.5(1 + t)e−t −0.5 cos t]u(t)
7. In the circuit of Figure 5.2, R = 500 , L = 1 mH, and C = 10 µF
a. Find the system function H(s) = V/Vs and its natural frequencies.
b. Let vs(t) = 1, t > 0. Show that regardless of the initial state of the circuit at t = 0, the response at t > 0 is
v(t) = V0e−αt cos(ωt + θ) and determine α and ω.
c. Given iL(0−) = vC(0−) = 0 and vs(t) = 1, t > 0, ﬁnd V0 and θ in part b.
d. Given vs(t) = 1, t > 0, specify iL(0−) and vC(0−) so that the response v(t) becomes zero at t > 0.
Solution
a. We ﬁrst ﬁnd the system function by applying KVL and LCL in the s domain. From voltage division:
H(s) = V
Vs
=
Z LC
R + Z LC
=
1
RC
s
s2 +
1
RC s +
1
LC
=
200s
s2 + 200s + 108
b. vs(t) = 1 and d2v
dt2 + 200dv
dt + 108v = 200dvs
dt = 0, for t > 0.
The characteristic equation and its roots are s2 + 200s + 108 = 0, s1,2 = −100 ±
√
104 −108 ≈−100 ± 104 j.
The homogeneous solution is vh(t) = e−100t (A cos 10,000t + B sin 10,000t) = V0e−100t cos(10,000t + θ).
The particular solution is zero and the complete solution is v(t) = vh(t) = V0e−100t cos(10,000t + θ), t > 0.
c. iL(0+) = iL(0−) = 0, vC(0+) = vC(0−) = 0, iC(0+) = vs(0+)
R
=
1
500 = C dv
dt

t=0+ and v′(0+) = 105
500 = 200.
The initial conditions for v(t) in the differential equation are v(0+) = 0, and v′(0+) = 200.
Applying the initial conditions we get:
v(0+) = V0 cos θ = 0, V0 ̸= 0, cos θ = 0, θ = π
2
v′(0+) = V0 [−100 cos θ −10,000 sin θ] = 200, V0 = −0.02
v(t) = −0.02e−100t cos

10,000t + π
2

= 0.02e−100t sin 10,000t, t ≥0
d. iL(0−) =
1
500 and vC(0−) = 0
8. Find the sinusoidal steady-state response of the circuit of problem 7 to vs(t) = sin(ωt). Write the response in the
form of v(t) = V sin(ωt + θ), where V is a nonnegative number. Determine V and θ as functions of ω. Write a

Signals and Systems
305
Matlab program to plot 20 log10 V (in units of dB) and θ versus log10 ω. [The plots will be called the Bode diagram
for the given H(s).]
Solution
Evaluate H(s) at s = jω to ﬁnd its magnitude and phase, which are the magnitude and phase of v(t), too.
H(s)

s= jω =
200s
s2 + 200s + 108

s= jω =
j200ω
108 −ω2 + j200ω = |H(ω)|e jθ(ω)
|H(ω)| =
200ω
√(108 −ω2)2 + (200ω)2
θ(ω) = 90◦−tan−1

200ω
108 −ω2

= tan−1

108 −ω2
200ω

20 log10 |H(ω)| = 20 log10 200 + 20 log10 ω −10 log10

(108 −ω2)2 + (200ω)2
The following Matlab program produces the Bode diagram.
num=[200 0];
den=[1 200 10√8];
sys=tf(num,den)
grid
bode(sys)
Chapter Problems
9. Find y(t), the solution of
dy
dt + y = x(t), t ≥0, x(t) = 1
for each of the following initial conditions:
a. y(0) = −1
b. y(0) = −0.5
c. y(0) = 0
d. y(0) = 0.5
e. y(0) = 1
f. y(0) = 2
Verify that the following Matlab program plots the solution functions.
t=linspace(0,5,1001);
y0=[-1 -0.5 0 0.5 1 2];
for i=1:6;
y =1+(y0(i)-1)*exp(-t);
plot(t,y,'r','LineWidth',2)
title('Response of dy/dt+y=1 under various initial conditions');
xlabel('Time (s)');
ylabel('y(t)');
axis([0
5 -1.5
2.5]);
hold on
end
grid

306
CHAPTER 5
Differential Equations and LTI Systems
hold off
print -dpsc CH5«Pr9.eps
10. Repeat problem 9 with x(t) = sin 2t. Plot the solution functions using Matlab.
11. Repeat problem 10 with x(t) = cos 2t.
12. Repeat problem 10 with x(t) = sin t.
13. Find y(t), the solution to each of the following differential equations:
a. dy
dt + y = (sin 2t)u(t)
b. d2y
dt2 + y = (sin 2t)u(t)
c. d2y
dt2 + 2dy
dt + 2y = e−
t
100 u(t)
d. dy
dt + y = (sin t)u(t)
e. dy
dt + 2y = 5u(t)
f. dy
dt + 2y = e−3tu(t)
14. Find y(t), the solution to each of the following differential equations:
a. dy
dt + 3y = e−2t, t > 0, with y(0) = 1
b. d2y
dt2 + 10dy
dt + 9y = 0, t > 0, with y(0) = 1, dy
dt (0) = 0
c. d2y
dt2 + 10dy
dt + 9y = 9, t > 0, with y(0) = 1, dy
dt (0) = 0
d. d2y
dt2 + 5dy
dt + 6y = 6, t > 0, with y(0) = 0, dy
dt (0) = 1
15. The input-output relationship in a system is
2dy(t)
dt
+ y(t) = 3x(t)
where x is the input and y is the output. Given x(t) = e−t, t > 0, ﬁnd y(t) for the following three initial conditions:
a. y(0) = 3
b. y(0) = 0
c. y(0) = −3
16. Find y(t), the solution to each of the following differential equations:
a. d2y
dt2 + dy
dt = u(t)
b. d2y
dt2 + dy
dt = 1.6u(t) −0.6u(t −1)
17. Find y(t), the solution to each of the following differential equations:
a. d2y
dt2 + 3dy
dt + 2y(t) = u(t)
b. d3y
dt3 + 13d2y
dt2 + 32dy
dt + 20y(t) = u(t)
18. Find y(t), the solution to each of the following differential equations:
a. d2y
dt2 + 2dy
dt + y = x(t) −dx
dt , t > 0, with y(0) = 1, dy
dt (0) = −1, and x(t) = e−2t −e−3t
b. d2y
dt2 + 200dy
dt + 108y = 200dx
dt , t > 0, with y(0) = 0, dy
dt (0) = 200, and x(t) = t

Signals and Systems
307
19. Find y(t), the solution to each of the following differential equations:
a. d2y
dt2 + 200dy
dt + 108y = 5x(t) + 100dx
dt , where x(t) = (t + 1)u(t)
b. d2y
dt2 + 650dy
dt + 30000y = 104

3x(t) + dx
dt

, where x(t) = (sin 200t)u(t)
c. d2y
dt2 + dy
dt = x(t) + 2dx
dt , where x(t) = e−2tu(t)
d. d2y
dt2 + 4dy
dt + 3y = dx
dt , where x(t) = (sin 3t)u(t)
20. Find y(t), the solution to the following differential equation:
d4y
dt4 + 2d3y
dt3 + 2d2y
dt2 + 2dy
dt + y = x(t), where
a. x(t) = e−tu(t)
b. x(t) = (cos t)u(t)
c. x(t) = e−t, t ≥0, and y′′′(0) = y′′(0) = y′(0) = 0, and y(0) = 1
d. x(t) = sin t, t ≥0, and y′′′(0) = y′′(0) = y′(0) = 0, and y(0) = 1
21. In the circuit of Figure 5.2, R = 1 , L = 1 H, and C = 1 F.
a. Show that
d2v
dt2 + dv
dt + v = dvs
dt
b. Given vs = 1, t > 0, i(0) = 0.5 A, and v(0) = 0.5 V, ﬁnd v for t > 0.
22. In the circuit of Figure 5.2, R = 1 , L = 1 H, and C = 1 F.
a. Show that
d2i
dt2 + di
dt + i = vs(t)
where i(t) is the current in the inductor.
b. Given vs(t) = 1, t > 0, i(0) = 0.5 A, and v(0) = 0.5 V, ﬁnd i for t > 0.
23. In the circuit of Figure 5.6, R = 1 , L = 1 H, and C = 2 F.
a. Show that
2d2v
dt2 + 2dv
dt + v = vs + is + dis
dt
b. Given vs = 1, is = e−t, t > 0, i(0) = 1 A, and v(0) = 1 V, ﬁnd v for t > 0.
L
B
A
R
C
+
–
+
–
vs
v
is
i
+
–
FIGURE 5.6 (For Problem 23)

308
CHAPTER 5
Differential Equations and LTI Systems
24. In the circuit of Figure 5.7
a. Show that
dv
dt +
1
RC v =
1
RC vs
b. With RC = 1 s and vs = u(t), ﬁnd v.
c. With RC = 0.1 s, let vs = 2u(t)−u(t −T ), where T is a constant. Find T so that v reaches its ﬁnal steady-state
value in T seconds.
d. With RC = 0.1 s, let vs = (1 + k)u(t) −ku(t −T ), where k and T are constants. Determine the relationship
between k and T so that v reaches its ﬁnal steady-state value in T seconds.
R
+
–
v
C
+
–
vs
+
–
FIGURE 5.7 (For Problem 24)
25. a. In the circuit of Figure 5.8, show that
d2v
dt2 + R
L
dv
dt +
1
LC v =
1
LC vs
b. With R = 123.5 , L = 8.207 H, C = 100 µF, and vs = u(t), show that v(t) is expressed by
v(t) = [1 −Ae−σt sin(ωdt + φ)]u(t)
Find the constants in the above expression and verify that the period of its decaying oscillations is 184.3 ms.
C
+
–
+
–
vs
v
R
L
+
–
FIGURE 5.8 (For Problem 25)
26. Open-loop control. Oscillations in the step response of Figure 5.8 can be reduced or eliminated by modifying
the input step voltage before it acts on the circuit. In this problem you will investigate the effects of three such
modiﬁcations. In each case ﬁnd the output voltage v(t). Determine the time it takes to reach the steady-state value
(exactly or approximately). The three cases are as follows:
a. vs = ku(t)+(1−k)u(t −T ), where T = 90 msec (Figure 5.9a). Find k so that v almost reaches its steady-state
value in 90 ms.
b. vs = u(t) −u(t −T1) + u(t −T2), where T1 = 40 msec and T2 = 60 (Figure 5.9b).
c. vs = u(t) −2u(t −T1) + 2u(t −T2), where T1 = 46 msec and T2 = 56 msec (Figure 5.9c).
Sample plots of the system’s responses superimposed on the unit-step response are shown in Figure 5.9 for
each case.

Signals and Systems
309
0
0.05
0.1
0.15
Time (s)
Time (s)
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
vs
1
k
0
Input
Response
Response
Time (s)
Time
Time
Time
Response
Input
Input
T
t
vs
1
0
T2
T1
t
vs
1
0
T2
T1
t
–1
(a)
(b)
(c)
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
FIGURE 5.9 Three cases of input modiﬁcation to improve transition time and reduce oscillations in the step response of
a second-order system. For each case the responses to modiﬁed inputs are shown superimposed on the system’s unit-step
response. (For Problem 26.)

310
CHAPTER 5
Differential Equations and LTI Systems
27. In the circuit of Figure 5.2, R = 500 , L = 10 mH, and C = 100 µF. Find v(t) for (a) vs(t) = u(t) and (b)
vs(t) = δ(t).
28. Find the sinusoidal steady-state response of the circuit of problem 27 to vs(t) = sin ωt. Follow the procedure of
problem 8.
5.23
Project: System of Differential Equations
Summary
A two-input, two-output linear time-invariant system is described by
dy1
dt + y2 = x1
dy2
dt + 3y2 −2y1 = x2
where x1(t) and x2(t) are the input, and y1(t) and y2(t) are the output pairs.
a. Find the differential equations that separately describe y1(t) and y2(t) in terms of x1(t) and x2(t). Show that the
characteristic equations and natural frequencies of the two differential equations you obtain are identical. They
are, thus, called the natural frequencies of the system. Find the outputs of the above system to x1(t) = u(t) and
x2(t) = (cos t)u(t).
b. Write the differential equations in matrix form as given below and determine A.

dy1
dt
dy2
dt

=

0
−1
2
−3

×

y1
y2

+

x1
x2

or
Y′ = AY + X
Find the roots of the following equation and show that they are the same as those found in part a.
|sI −A| = 0
where I is the 2 × 2 identity matrix and |sI −A| is the determinant.
c. Refer to the circuit of Figure 5.10 in which x1(t) and x2(t) are voltage sources with the polarities shown. Verify
that the outputs of op-amps 1 and 2 can represent y1 and y2, respectively, and determine appropriate elements
values.
+
–
+
–
3
1
y1
y2
R3
R
R2
R
R1
R4
R5
2
C
C
x2
+
–
+
–
x1
+
–
FIGURE 5.10

Signals and Systems
311
d. Remove op-amp number 3 from the circuit of Figure 5.10. Write the new input-output equations. Find the
response to x1(t) = x2(t) = u(t). Show that the system is unstable. Can you infer the unstable behavior of the
system by merely examining the circuit?
e. You have been asked to conﬁgure a circuit for solving the system shown by
Y′ = AY + BX
where A and B are 2 × 2 matrices with nonzero elements. Suggest a circuit and discuss if there are any limiting
factors or considerations.

Chapter6
The Laplace
Transform and
Its Applications
Contents
Introduction and Summary
314
6.1
Deﬁnition of the Laplace Transform
315
6.2
Linearity Property
317
6.3
Examples of the Unilateral Laplace Transform
317
6.4
Differentiation and Integration Properties
320
6.5
Multiplication by t
323
6.6
Multiplication by eat
324
6.7
Time-Shift Property
324
6.8
Scale Change
325
6.9
Convolution Property
325
6.10
Initial-Value and Final-Value Theorems
327
6.11
Lower Limit of Integration: 0−, 0, 0+
328
6.12
Laplace Transform of the Unit Impulse
328
6.13
The Inverse Laplace Transform
329
6.14
Partial Fraction Expansion; Simple Poles
331
6.15
Partial Fraction Expansion; Multiple-Order Poles
335
6.16
Summary of the Laplace Transform Properties and Theorems
336
6.17
A Table of Unilateral Laplace Transform Pairs
337
6.18
Circuit Solution
338
6.19
Solution of Dynamical Equations
340
6.20
Bilateral Laplace Transform
343
6.21
Region of Convergence of the Bilateral Laplace Transform
346
313

314
CHAPTER 6
The Laplace Transform and Its Applications
6.22
Properties of the Bilateral Laplace Transform
348
6.23
Inverse of the Bilateral Laplace Transform
349
6.24
A Table of Bilateral Laplace Transform Pairs
353
6.25
System Function
354
6.26
Comprehensive Examples
356
6.27
Concluding Remarks
361
6.28
Problems
361
6.29
Project: Pulse-Shaping Circuit
375
Introduction and Summary
A signal may be represented in various forms; for example, by its variations as a func-
tion of time, by its decomposition into components, or by a mathematical operation
(transformation) that maps it from one domain to another. Each form may have a cer-
tain advantage over the others. Some transforms provide tools for converting a set of
integro-differential equations into a set of simultaneous linear equations. This property,
in conjunction with the use of matrix notations, greatly simpliﬁes the analysis and design
of linear systems and is especially useful in the state-space approach and multivariable
systems. The Laplace transform belongs to a class of transforms, called linear integral
transforms, that have such a property. The Fourier transform is another member of this
class. In this chapter we present the Laplace transform and its applications. The Fourier
series and transform are discussed in Chapters 7 and 8.
The Laplace transform converts linear time-invariant differential equations into al-
gebraic equations that are generally easier to solve. In doing so, it incorporates the initial
conditions into the solution. Partial differential equations and some time-varying dif-
ferential equations are also more easily solved by application of the Laplace transform.
Such features make the Laplace transform an attractive tool in operational mathematics.
In addition, Laplace transform solutions can provide insights into the properties and be-
haviors of systems. Another application of the Laplace transform is the development and
use of the system function, through which natural frequencies, poles and zeros, stability,
feedback, and frequency response can be discussed.
This chapter starts with the deﬁnition of the Laplace transform in both its unilateral
and bilateral forms. The former version is applied to the analysis of LTI systems subjected
to causal (right-sided) inputs. The effect of nonzero initial conditions is explored, as are
the zero-state and zero-input responses of the systems in the transform domain. The
many examples based on causal functions provide a smooth transition to the bilateral
version of the transform, where a broad class of applications is addressed. These include
applications dealing with forcing functions that contain discontinuities and impulses.
The chapter also covers the inverse Laplace transform and expansion by partial
fractions. Tables of useful Laplace transform pairs are given as a handy aid. The essentials
of regions of convergence, properties, and theorems involving the Laplace transform are
explained as well. Finally, the application of the transform to circuits and their describing
dynamical equations serves to highlight the power and usefulness of this tool.

Signals and Systems
315
The organization of the chapter permits sequential, parallel, or mixed approaches
to the study of both forms of the transform. The examples and problems serve to clarify
the concepts presented, bridge the discussions on the unilateral and bilateral Laplace
transforms, and bring to the reader’s attention parallels between the time and transform
domains.
6.1
Definition of the Laplace Transform
The Laplace transform of a function x(t) is deﬁned by
Unilateral Laplace transform: L[x(t)] = X(s) =
 ∞
0
x(t)e−stdt
(1 −a)
Bilateral Laplace transform: L[x(t)] = X(s) =
 ∞
−∞
x(t)e−stdt
(1 −b)1
For the above integrals to converge, the new variable s (in general, a complex number)
has to be limited to a part of the s-plane called the region of convergence (ROC). It is
seen that the Laplace transform produces a function of the new variable s. The mapping
between x(t) and X(s) is one-to-one so that one can ﬁnd x(t) from X(s).
Unilateral Transform
The Laplace transform has traditionally been used in its unilateral form. The unilateral
Laplace transform provides a simple but powerful tool for analysis of causal LTI systems
given the input for t > 0 and the initial conditions at t = 0. This is especially suitable
for the case of physical systems such as those containing electrical and mechanical com-
ponents. The effect of past inputs manifests itself in the form of initial conditions. The
unilateral Laplace transform method is widely used in analysis and design of feedback
and control systems. The fact that the integral in the unilateral Laplace transform ex-
cludes the negative half of x(t) does not imply that the transform is deﬁned only for
causal functions or that the negative half of x(t) is set to zero and its effect discarded.
Through the differentiation property, the unilateral Laplace transform incorporates the
initial conditions into the solution of the differential equation. We refer to the unilateral
Laplace transform simply as the Laplace transform, requiring a knowledge of the time
function for t > 0 only.
Bilateral Transform
If the conditions of the LTI system at t = 0 are not known, we need to know its past
history (e.g., all past values of the input) in order to determine the future values of the
output. In such a case the bilateral Laplace transform is used in which the lower bound
of the integral in (1-a) is taken to be −∞. The bilateral Laplace transform is also used in
noncausal systems and will be discussed later on. Moreover, in many communication and
1In both cases the transform is shown by X(s).

316
CHAPTER 6
The Laplace Transform and Its Applications
information applications we deal with signals and systems that are modeled for the whole
range of time. Mathematical causality and initial conditions don’t command a prominant
feature anymore. There is a need to consider the past values of functions explicitly, not
merely as initial conditions. The bilateral Laplace transform is a generalization of the
Laplace transform that answers that need. It requires the knowledge of x(t) from −∞
to ∞.
Region of Convergence
The Laplace transform exists only in the region of convergence (ROC). The roots of the
denominator of the Laplace transform of a function are called its poles. By deﬁnition, the
region of convergence doesn’t include any poles. The Laplace transform is analytic in
that region. As will be seen, for the right-sided functions the ROC is RE[s] > a, where,
depending on the time function, a is a positive or negative number. It is a contiguous
region on the right side of the pole with the largest real part. For the left-sided functions
the ROC is RE[s] < b, where b may be a positive or negative number. It is a contiguous
region on the left side of the pole with the smallest real part. For the two-sided functions
the ROC is a < RE[s] < b, a vertical strip with no poles inside it.
Uniqueness Theorem
In a nutshell, the uniqueness theorem states that the Laplace transform pairs are unique.
More precisely, if X1(s) = L[x1(t)] and X2(s) = L[x2(t)] are equal in a region of the
s-plane, then x1(t) and x2(t) are functionally equal for t > 0. 2 Due to the uniqueness
theorem, a time function x(t) and its Laplace transform X(s) form a transform pair.
Knowledge of one would lead to the other. This property is used to determine the inverse
Laplace transform of a function from a known transform. Tables of Laplace transform
pairs can be comfortably used for transition from one domain to the other without fear
of multiplicity errors.
Equivalence of the Unilateral and Bilateral Transforms
Obviously, the unilateral and bilateral transforms of a function x(t) become the same if
x(t) = 0 for t < 0. In other words, the Laplace transform of a function x(t)u(t) is the
same regardless of which deﬁnition is used. If x(t) contains an impulse at t = 0, we set
the lower limit of the unilateral integral to 0−. This will result in the same expression
for X(s) regardless of which transform deﬁnition is used.
The unilateral Laplace transform (referred to simply as the Laplace transform), along
with its inverse, properties, and applications are discussed in sections 6.2 through 6.19
of this chapter. The bilateral transform is considered in sections 6.20 through 6.25.
2Two time functions may be different at a set of isolated points with little practical overall effect; for
example, their Laplace transform integrals will be equal in a region of the s-plane.

Signals and Systems
317
6.2
Linearity Property
Linearity is a basic property of the Laplace transform. It states that
if:
x(t)
⇒X(s)
y(t)
⇒Y(s)
then:
ax(t) + by(t) ⇒aX(s) + bY(s)
where a, b are any constants and x, y are any functions. This property, also called the
linearity theorem, is due to the integration in Eq. (1-a) being a linear operation. The
linearity property may be derived directly from the deﬁnition of the Laplace transform.
L [ax1(t) + bx2(t)] =

[ax1(t) + bx2(t)] e−stdt
= a

x1(t)e−stdt + b

x2(t)e−stdt
= aX1(s) + bX2(s)
6.3
Examples of the Unilateral
Laplace Transform
The unilateral Laplace transform of a function x(t) is deﬁned by
L[x(t)] = X(s) =
 ∞
0
x(t)e−stdt
The variable s is, in general, a complex number. For the transform to exist, the above
integral should converge. This requirement generally limits s to a part of the s-plane
called the region of convergence (ROC).
Example
6.1
Transform of a constant
The Laplace transform of x(t) = 1, t > 0, is
X(s) =
 ∞
0
e−stdt = −1
s

e−stt=∞
t=0
At t = ∞, the value of e−st either goes to zero (when RE[s] > 0, in which case
the integral converges) or ∞(when RE[s] ≤0, in which case the integral doesn’t
converge). Therefore, the Laplace transform exists only if s is located in the region
speciﬁed by RE[s] > 0.
X(s) = −1
s

e−∞−1

= 1
s ,
RE[s] > 0
The ROC is the right-half plane starting from RE[s] = 0 and stretching to ∞.

318
CHAPTER 6
The Laplace Transform and Its Applications
Example
6.2
A rectangular pulse
A rectangular pulse and its Laplace transform are given below.
x(t) =

1,
0 < t < T
0,
t > T
and
X(s) =
 T
0
e−stdt = 1 −e−sT
s
The transform exists everywhere in the s-plane.
Example
6.3
An exponential
The Laplace transform of x(t) = eat, t > 0 is
X(s) =
 ∞
0
eate−stdt =
−1
s −a

e−(s−a)tt=∞
t=0
By an argument similar to that of Example 6.1, we note that the integral converges if
RE(s −a) > 0. The Laplace transform of eat is then
X(s) =
−1
s −a

0 −1

=
1
s −a ,
RE[s] > a
The ROC is the half-plane to the right of the line RE[s] > a. For a decaying expo-
nential a < 0 and the ROC includes the imaginary axis. For a growing exponential
a > 0 and the ROC excludes the imaginary axis. It is observed that for a = 0 we get
x(t) = 1 and
X(s) = 1
s ,
RE[s] > 0
Example
6.4
Two exponentials
Find the Laplace transform of y(t) = e−t −e−2t, t > 0, shown in Figure 6.1. Also
see Example 6.10.
1
0.8
0.6
0.4
0.2
–0.2
–0.4
Amplitude
–0.6
–0.8
–1
0
0.5
1
1.5
Time (s)
2
2.5
0
1
0.8
Pole Plot
0.6
0.4
0.2
–0.2
–0.4
Imaginary
–0.6
–0.8
–1
–3
–2.5
–1.5
–1
Real
0
1
0
–2
–0.5
0.5
FIGURE 6.1 Sum of two exponentials x(t) = e−t −e−2t, t > 0, ⇒
X(s) =
1
(s+1)(s+2), RE[s] > −1

Signals and Systems
319
Solution
Applying the linearity property we get
Y(s) =
1
s + 1 −
1
s + 2 =
1
(s + 1)(s + 2) =
1
s2 + 3s + 2 where RE[s] > −1
Example
6.5
Trigonometric functions
Use the linearity property and transform of an exponential function to ﬁnd the Laplace
transforms of sin(ωt) and cos(ωt).
Solution
Transforms of trigonometric functions are derived in the following table.
x(t)
=⇒
X(s)
ROC
e jωt
⇒
1
s −jω
RE[s] > 0
e−jωt
⇒
1
s + jω
RE[s] > 0
sin(ωt) = 1
2 j

e jωt −e−jωt
⇒
1
2 j
	
1
s −jω −
1
s + jω

=
ω
s2 + ω2
RE[s] > 0
cos(ωt) = 1
2

e jωt + e−jωt
⇒
1
2
	
1
s −jω +
1
s + jω

=
s −a
s2 + ω2
RE[s] > 0
Example
6.6
Decaying or growing sinusoids
The Laplace transforms of eat sin(ωt), t > 0, eat cos(ωt), t > 0, and eat cos(ωt +
θ), t > 0, may be deduced from the transform of an exponential with the exponent
a ± jω as derived below. See Figure 6.2.
x(t)
=⇒X(s)
ROC
eat, t > 0
⇒
1
s −a
RE[s] > a
eat sin(ωt) = e(a+ jω)t −e(a−jω)t
2 j
⇒
1
2 j
	
1
s −a −jω −
1
s −a + jω

=
ω
(s −a)2 + ω2
RE[s] > a
eat cos(ωt) = e(a+ jω)t + e(a−jω)t
2
⇒1
2
	
1
s −a −jω +
1
s −a + jω

=
s −a
(s −a)2 + ω2
RE[s] > a

320
CHAPTER 6
The Laplace Transform and Its Applications
1
0.8
0.6
0.4
0.2
–0.2
–0.4
Amplitude
–0.6
–0.8
–1
0
0.5
1
1.5
Time (s)
2
2.5
0
20
Pole Plot
15
10
5
–5
Imaginary
–10
–15
–20
–2.5
–2
–1
–0.5
Real
0
2.5
0
–1.5
0.5
1
1.5
2
FIGURE 6.2 Exponential sinusoid x(t) = e−t sin(5πt), t > 0, ⇒X(s) =
15.71
s2+2s+247.74, ROC = RE[s] > −1
Example
6.7
Hyperbolic functions
Use the linearity property and transform of an exponential function to ﬁnd the Laplace
transforms of sinh(at) and cosh(at).
Solution
Transforms of hyperbolic functions are derived in the following table.
x(t)
=⇒
X(s)
ROC
eat
⇒
1
s −a
RE[s] > a
e−at
⇒
1
s + a
RE[s] > −a
sinh(at) = 1
2

eat −e−at
⇒
1
2
	
1
s −a −
1
s + a

=
a
s2 −a2
RE[s] > a
cosh(at) = 1
2

eat + e−at
⇒
1
2
	
1
s −a +
1
s + a

=
s
s2 −a2
RE[s] > a
6.4
Differentiation and Integration Properties
Transforms of the derivative and integral of x(t) are related to X(s) by
dx(t)
dt
⇒sX(s) −x(0)
 t
0
x(τ)dτ ⇒X(s)
s

Signals and Systems
321
Proof of the Derivative Property
First apply the deﬁnition of the Laplace transform to dx(t)/dt.
L
	dx(t)
dt

=
 ∞
0
dx(t)
dt
e−stdt
Then integrate by parts.

udv = uv −

vdu where u = e−st, du = −se−st, dv = dx(t)
dt
dt, and v = x(t)
L
	dx(t)
dt

=
	
e−stx(t)

∞
0
−
 ∞
0
x(t)(−se−st)dt = sX(s) −x(0)
The derivative property is of prime importance in the solution of LTI differential
equations by the Laplace transform. It incorporates the initial conditions in the solution.
Proof of the Integral Property
First apply the deﬁnition of the Laplace transform to
 t
0 x(τ)dτ. The result is a double
integral in τ and t.
L
	 t
τ=0
x(τ)dτ

=
 ∞
t=0
 t
τ=0
x(τ)e−stdτdt
Integration is done on a region that is deﬁned by t ≥0, τ ≥0 and t ≥τ. Then, change
the order and integrate over the same region to get
L
	 t
τ=0
x(τ)dτ

=
 ∞
τ=0
x(τ)
 ∞
t=τ
e−stdt

dτ = 1
s
 ∞
τ=0
x(τ)e−sτdτ = X(s)
s
The use of integral property is illustrated in the following example.
Example
6.8
A DC voltage source, V1, gets connected to a capacitor C through a resistor R at
t = 0. Capacitor voltage at t = 0 is V0 volt. Use a Laplace transform to ﬁnd current
i ﬂowing into the capacitor for t > 0.
Solution
From KVL around the loop for t > 0 we have the following equation in the time
domain.
Ri(t) + 1
C
 t
0
i(τ)dτ + V0 = V1
Taking Laplace transform of both sides we have
RI (s) + 1
C
I (s)
s
+ V0
s = V1
s
from which we ﬁnd I (s)
I (s) = (V1 −V0)
R
1
s +
1
RC

322
CHAPTER 6
The Laplace Transform and Its Applications
The current in the time is
i(t) = (V1 −V0)
R
e−
t
RC , t ≥0
The derivative and integral properties provide circuit solutions in the transform do-
main. See section 6.18.
Example
6.9
Given dy(t)
dt
+ 2y(t) = e−t, t ≥0, y(0) = 1 ﬁnd Y(s).
Solution
Take the transform of both sides of the differential equation
L
	dy(t)
dt
+ 2y(t)

=
1
s + 1, RE[s] > −1
By the linearity property of the Laplace transform
L
	dy(t)
dt
+ 2y(t)

= L
	dy(t)
dt

+ 2L [y(t)]
and by the derivative property
L
	dy(t)
dt

= sY(s) −y(0) = sY(s) −1
Therefore,
L
	dy(t)
dt
+ 2y(t)

= sY(s) −1 + 2Y(s) =
1
s + 1, RE[s] > −1
from which we ﬁnd
Y(s) =
1
s + 1, RE[s] > −1
The only time function with the above unilateral Laplace transform is y(t) = e−t,
t ≥0. The solution is made of the particular part only. The given initial condition
y(0) = 1 has resulted in elimination of the homogeneous solution.
Repeated application of the derivative property results in the relationships be-
tween transforms of higher derivatives of x(t) to X(s), as shown in the list below.
1.
L
	dx(t)
dt

= sX(s) −x(0)
2.
L
	d(2)x(t)
dt2

= s2X(s) −sx(0) −x′(0)
...
...
n.
L
	d(n)x(t)
dtn

= sn X(s) −sn−1x(0) −sn−2x′(0) · · · −x(n−1)(0)
Repeated application of integral property is left as an exercise.

Signals and Systems
323
6.5
Multiplication by t
Multiplication of x(t) by t is equivalent to taking the derivative of its Laplace transform
with respect to s and then negating the result:
tx(t) ⇐⇒−d X(s)
ds
To derive the above property take the derivative of both sides of the transform integral
with respect to s.
d X(s)
ds
= d
ds
 ∞
0
x(t)e−stdt =
 ∞
0
x(t) d
ds [e−st]dt
=
 ∞
0
−tx(t)e−stdt = −L [tx(t)]
The above property may be extended to multiplication by tn resulting in the following
summary table:
tx(t)
⇐⇒
−d X(s)
ds
...
...
tnx(t)
⇐⇒
(−1)n dn X(s)
dsn
Example
6.10
The following table uses the t-multiplication property to ﬁnd the Laplace transform
pairs shown.
1
⇐⇒
1
s
RE[s] > 0
t
⇐⇒
−d
ds
	
1
s

= 1
s2
RE[s] > 0
tn
⇐⇒
n!
sn+1
RE[s] > 0
te−at
⇐⇒
−d
ds
	
1
s + a

=
1
(s + a)2
RE[s] > −a
tne−at
⇐⇒
n!
(s + a)n+1
RE[s] > −a
t sin ωt
⇐⇒
2ωs
(s2 + ω2)2
RE[s] > 0
t cos ωt
⇐⇒
s2 −ω2
(s2 + ω2)2
RE[s] > 0

324
CHAPTER 6
The Laplace Transform and Its Applications
6.6
Multiplication by eat
Multiplication of a time function x(t) by eat shifts its Laplace transform by the amount
a to the right.
x(t)eat ⇒X(s −a)
This property, also called s-domain shift, is the counterpart of the time shift.
Example
6.11
Decaying or growing sinusoids revisited
Use multiplication by eat to ﬁnd the Laplace transforms of eat sin(ωt),
t > 0,
eat cos(ωt), t > 0, and eat cos(ωt + θ), t > 0.
Solution
We start with the transforms of sin(ωt) and cos(ωt), and apply the multiplication by
exponential property to ﬁnd
sin ωt
⇒
ω
s2 + ω2
RE[s] > 0
cos ωt
⇒
s
s2 + ω2
RE[s] > 0
eat sin ωt
⇒
ω
(s −a)2 + ω2
RE[s] > a
eat cos ωt
⇒
s −a
(s −a)2 + ω2
RE[s] > a
eat cos(ωt + θ)
⇒
(s −a) cos θ −ω sin θ
(s −a)2 + ω2
RE[s] > a
6.7
Time-Shift Property
Shifting of x(t)u(t) to the right by T seconds results in the multiplication of X(s) by
e−sT .
x(t −T )u(t −T ) ⇒X(s)e−sT
The shifted function x(t −T )u(t −T ), therefore, is zero at 0 < t < T 3
3Note that this property applies to right-shift (or delay) of x(t)u(t), which is not the same as a right-shift of
x(t) if x(t) ̸= 0, t < 0.

Signals and Systems
325
Example
6.12
Rectangular pulse revisited
Using the shift and linearity properties, ﬁnd the Laplace transform of the rectangular
pulse x(t) = u(t) −u(t −T ).
Solution
u(t)
⇒
1
s
u(t −T )
⇒
e−sT
s
u(t) −u(t −T ) ⇒1
s −e−sT
s
= 1 −e−sT
s
Example
6.13
A 1-volt, 1-sec rectangular voltage source is connected to a 1-µF capacitor through
a 1-M resistor. The capacitor has zero initial charge. Find the Laplace transform of
the current in the circuit.
Solution
Let the voltage be given by u(t) −u(t −1). The current and its transform are
i(t) = 10−6 
e−t −e−(t−1)u(t −1)

= 10−6 ×



0,
t < 0
e−t,
0 ≤t < 1
(1 −e)e−t, t ≥1
⇒
I (s) = 10−6 1 −e−s
s + 1
6.8
Scale Change
Changing the time scale by a positive factor α changes the s scale by a factor of 1
α and
multiplies the transform by 1
α.
L [x(αt)] =
 ∞
0
x(αt)e−stdt = 1
α
 ∞
0
x(τ)e−(s/α)τdτ = 1
a X
 s
α

, α > 0
In summary,
x(αt) ⇒1
α X
 s
α

, α > 0
6.9
Convolution Property
Convolution is an important and exceedingly useful property of the Laplace transform. It
states that convolution in the time domain is equivalent to multiplication in the s-domain.
x(t) ⋆h(t)
⇐⇒
X(s)H(s)

326
CHAPTER 6
The Laplace Transform and Its Applications
To show the above, we start with the convolution of two causal functions x(t) and h(t)
given by
y(t) = x(t) ⋆h(t) =
 t
0
x(t −τ) h(τ)dτ
By direct evaluation, the Laplace transform of y(t) is
Y(s) =
 ∞
0
y(t)e−stdt =
 ∞
0
	 t
0
x(t −τ) h(τ) dτ

e−st dt
=
 ∞
0
	 ∞
0
x(t −τ)u(t −τ) h(τ) dτ

e−st dt
Interchanging the order of integration we get
Y(s) =
 ∞
0
h(τ)
	 ∞
0
x(t −τ)u(t −τ) e−stdt

dτ
By the time-shift property,
 ∞
0
x(t −τ)u(t −τ) e−stdt = X(s)e−sτ
Therefore,
Y(s) = X(s)
 ∞
0
h(τ)e−sτ dτ = X(s)H(s)
Observanda
The convolution property is of great importance because it establishes the s-domain
input-output relationship for LTI systems,
Y(s) = X(s)H(s)
where Y(s), X(s), and H(s) are the Laplace transforms of the output, the input, and
the impulse response, respectively. The ROC of Y(s) is the intersection of the ROCs of
X(s) and H(s). A null ROC indicates y(t) doesn’t exist.
Example
6.14
Convolution of two exponentials
Using the Laplace transform method ﬁnd y(t) = h(t) ⋆x(t), where h(t) = e−tu(t)
and x(t) = e−2tu(t).
Solution
H(s) =
1
s + 1, RE[s] > −1, and X(s) =
1
s + 2, RE[s] > −2

Signals and Systems
327
Apply the convolution property to get
Y(s) = H(s)X(s) =
1
(s + 1)(s + 2), RE[s] > −1
Toﬁnd y(t)weexpandY(s)intofractionsthataretransformsofknowntimefunctions.
The method is called inverse Laplace transform and will be discussed in details in
sections 6.13 to 6.17.
Y(s) =
1
(s + 1)(s + 2) =
1
s + 1−
1
s + 2, RE[s] > −1and y(t) = e−t−e−2t, t > 0
Example
6.15
The impulse response of an LTI system is h(t) = e−t cos(2t)u(t). Using the Laplace
transform method, ﬁnd the system’s response to x(t) = −4e−3tu(t).
Solution
The transform of the impulse response and the input are
h(t) = e−t cos(2t)u(t) ⇒H(s) =
s + 1
(s + 1)2 + 4 RE[s] > −1
x(t) = −4e−3tu(t) ⇒X(s) =
−4
s + 3 RE[s] > −3
Y(s) = H(s)X(s) =
s + 1
(s + 1)2 + 4 · (−4)
s + 3 = −
s + 3
(s + 1)2 + 4 +
1
s + 3,
RE[s] > −1
The inverse of Y(s) may be found from the known transform pairs.
y(t) = −e−t(cos 2t+sin 2t)u(t)+e−3tu(t) =
	√
2e−t cos

2t + 3π
4

+ e−3t

u(t)
Note the natural and the forced components of the response.
6.10
Initial-Value and Final-Value Theorems
The initial-value theorem states that
lim
s→∞{sX(s)} = x(0)
Strictly speaking, this applies only if X(s) is a proper rational function or only if the
proper part of X(s) is used. Otherwise, one may employ impulse and other generalized
functions to extend the above theorem. (A proper rational function is the ratio of two
polynomials in which the power of the numerator is less than that of the denominator.)
The ﬁnal-value theorem states that
lim
s→0{sX(s)} = x(∞)
The ﬁnal-value theorem is applicable only when all poles of sX(s) have negative real
parts. Otherwise, as t →0, the limit becomes inﬁnite or indeterminate.

328
CHAPTER 6
The Laplace Transform and Its Applications
6.11
Lower Limit of Integration: 0-, 0, 0+
The lower limit of integration in the unilateral Laplace transform is zero. But does that
mean 0−, 0, or 0+? Unless the time function contains an impulse at the origin, there
is no problem. However, if x(t) includes a δ(t), one must decide whether to include or
exclude the impulse from integration. Some authors specify the lower limit to be 0+ to
exclude the impulse. In that case, the effect of δ(t) will translate into initial conditions at
t = 0+. Some authors take t = 0−to be the lower limit to include the impulse directly
in the transform. We keep the lower limit at t = 0 and accept L[δ(t)] = 1. Other forms
of discontinuity of x(t) at t = 0 (e.g., a ﬁnite jump) are accounted for in the derivative
property by selecting x(0+). Many questions regarding the effect of discontinuities of
the time function at the lower limit of the integral will vanish if the bilateral Laplace
transform is used.
6.12
Laplace Transform of the Unit Impulse
A unit impulse located at t = T > 0 is represented by δ(t −T ). Its Laplace transform
is evaluated to be
L[δ(t −T )] =
 ∞
0
δ(t −T )e−stdt = e−sT
For T = 0, the value of the integral seems to be unclear because of the presence of the
impulse at t = 0.4 Here we determine the transform of δ(t) from
L[δ(t)] = lim
T →0 e−sT = 1
Alternate Method
δ(t) may be considered the limit of a narrowing rectangular pulse, xT (t), of duration T
and height 1/T at the origin.
δ(t) = lim
T →0 xT (t)
xT (t) =
 1
T ,
0 < t < T
0,
elsewhere
In the s-domain,
XT (s) = 1
T
 T
0
e−stdt = 1 −e−sT
T s
L[δ(t)] = lim
T →0 XT (s) = 1
4To overcome the above ambiguity, one may deﬁne the lower limit of the unilateral Laplace transform to be
at t = 0−, in which case, L[δ(t)] = 1.

Signals and Systems
329
The above two derivations obtain the Laplace transform of δ(t) without getting involved
with the question of the lower limit being 0−or 0+.
Generalization
The perceived ambiguity surrounding the Laplace transform of the unit-impulse func-
tion disappears if the bilateral Laplace transform is used and the unit impulse δ(t) is
considered as a generalized function deﬁned by
 ∞
−∞
δ(t −t0)φ(t)dt = φ(t0)
In the above deﬁnition let φ(t) = e−st. Then
L[δ(t −t0)] = e−st0
L[δ(t)] = 1
6.13
The Inverse Laplace Transform
The inverse transform is a time function x(t) whose Laplace transform is given by X(s),
including the ROC. The inverse transform may be found from
x(t) = L−1[X(s)] =
1
2π j

C
X(s)estds
where the integration path C is a vertical line deﬁned by s = σ0 + jω in the ROC, from
ω = −∞to ∞. In the case of the unilateral Laplace transform [concerning x(t) for
t > 0] the path closes itself in the left half of the s-plane through a very large semicircle
surrounding all poles of X(s) as shown in Figure 6.3. Then the value of the integral
over the semicircle becomes zero [because t > 0 and RE[s] < 0 result in est = 0] and,
according to Cauchy’s theorem on contour integration of functions of complex variables,
the above integral becomes equal to the sum of residues of the function X(s)est at all
poles (to the left of the ROC). Finding the inverse Laplace transform then becomes a
matter of ﬁnding the residues.
Example
6.16
Given the unilateral Laplace transform X(s) = B(s)/(s3 + 4s2 + 9s + 10), what can
be said about x(t)? Assume B(s) is a polynomial of second order or less in s.
Solution
The roots of the denominator of X(s) (called its poles) are at s1,2 = −1 ± j2 and
s3 = −2. They are displayed in Figure 6.3. The ROC is RE[s] > −1; that is, the

330
CHAPTER 6
The Laplace Transform and Its Applications
RHP to the right of the pole with the largest real part. The contour integral for
evaluation of x(t) circles the poles in a counterclockwise direction and generates x(t)
for t ≥0, with a functional form determined by the poles:
x(t) = k1e−(1+2 j)t + k∗
1e−(1−2 j)t + k2e−2t
= e−t[C1 cos(2t) + C2 sin(2t)] + k2e−2t
= Ce−t cos(2t + θ) + k2e−2t, t > 0
Todeterminetheparametersk1 andk2 (C1,C2,C,andθ)weneed B(s)or,equivalently,
the zeros of X(s).
3
Pole Plot
2
1
1
–1
–2
–3
C
(t > 0)
2
Real
Imaginary
0
0
–1
–2
–3
FIGURE 6.3 Atimefunction x(t), t > 0,isfoundfromitsunilateralLaplacetransform
X(s) by
x(t) = L−1[X(s)] =
1
2π j

C
X(s)estds
where the path C goes from −∞< IM[s] < ∞within the ROC.

Signals and Systems
331
For t > 0, the path may be closed by an inﬁnitely large semicircle to the left, as
shown in this ﬁgure, without affecting the value of the above integral. Then, according
to Cauchy’s theorem on contour integration of functions of complex variables, the value
of the integral becomes equal to the sum of the residues of X(s)est at its poles within
the contour C; that is, at poles of X(s) to the left of its ROC. The residues may be found
by expanding X(s) into its fractions.
The inverse Laplace transform can, however, be determined by ﬁrst expanding X(s)
into simpler components and then using tables of transform pairs. One such method,
which is in harmony with the residue method, is partial fraction expansion discussed
next.
6.14
Partial Fraction Expansion; Simple Poles
Let X(s) be a rational function with distinct poles (denominator polynomial has no
repeatedroots)si, i = 1, 2, . . . n.Inaddition,letthedegreeofthenumeratorpolynomial
be less than that of the denominator polynomial. Then
X(s) = bmsm + bm−1sm−1 + · · · + b0
sn + an−1sn−1 + · · · + a0
= bmsm + bm−1sm−1 + · · · + b0
(s −s1)(s −s2) · · · (s −sn)
=
k1
s −s1
+
k2
s −s2
+ · · · +
kn
s −sn
where ki, i = 1, 2, . . . , n are constants called residues of X(s). They are found from
ki = X(s)(s −si)

s=si
From the table of Laplace transform pairs and based on the uniqueness theorem we ﬁnd
x(t)
x(t) = k1es1t + k2es2t + · · · + knesnt
Example
6.17
Find x(t) for t > 0, given
X(s) =
s + 1
s2 + 3s

332
CHAPTER 6
The Laplace Transform and Its Applications
Solution
X(s) = k1
s +
k2
s + 3
k1 = X(s)s

s=0 = s + 1
s + 3

s=0
= 1
3
k2 = X(s)(s + 3)

s=−3 = s + 1
s

s=−3
= 2
3
x(t) = 1
3 + 2
3e−3t, t > 0
Example
6.18
Find x(t) for t > 0 given
X(s) =
s2 + 3s + 2
(s + 1)(s + 2)(s + 5)
Solution
X(s) =
k1
s + 1 +
k2
s + 2 +
k3
s + 5
k1 = X(s)(s + 1)

s=−1 =
s2 + 3s + 2
(s + 2)(s + 5)

s=−1
= 0
The result indicates that X(s) has a zero at s = −1, which cancels the denominator
term s + 1. Similarly, k2 = 0.
X(s) =
1
s + 5, x(t) = e−5t, t > 0
Example
6.19
Find x(t) for t > 0 given
X(s) =
s2 + 3s + 3
(s + 1)(s −2)(s + 5)
Solution
X(s) =
k1
s + 1 +
k2
s −2 +
k3
s + 5
k1 = X(s)(s + 1)

s=−1 =
s2 + 3s + 3
(s −2)(s + 5)

s=−1
= −1
12
k2 = X(s)(s −2)

s=2 =
s2 + 3s + 3
(s + 1)(s + 5)

s=2
= 13
21
k3 = X(s)(s + 5)

s=−5 =
s2 + 3s + 3
(s + 1)(s −2)

s=−5
= 13
28
x(t) = −1
12e−t + 13
21e2t + 13
28e−5t, t > 0

Signals and Systems
333
Needless to say that in the above class of expansions, poles are not required to be real
valued (i.e., be on the real axis in the s-plane). The method works as long as the poles
are not repeated. They can be anywhere in the s-plane. When they are not on the real
axis they occur in complex conjugate pairs. See Example 6.20.
Example
6.20
Find x(t), t > 0, given
X(s) =
s + 1
s(s2 + 4) =
s + 1
s(s + 2 j)(s −2 j) = k1
s +
k2
s −2 j +
k3
s + 2 j
Solution
Contributions from the poles at s = ± j2 may be combined in the s-domain and X(s)
be expanded in the form of
X(s) =
s + 1
s(s2 + 4) = k1
s + As + B
s2 + 4
k1 = X(s)s

s=0 = s + 1
s2 + 4

s=0
= 0.25
Coefﬁcients A and B may be found by combining the fractions on the right side and
matching with the original function.
0.25
s
+ As + B
s2 + 4 = 0.25s2 + 1 + As2 + Bs
s(s2 + 4)
=
s + 1
s(s2 + 4)
By matching numerator terms we get 0.25s2 + 1 + As2 + Bs = s + 1 from which
A = −0.25, and B = 1.
X(s) = 0.25
s
+ −0.25s + 1
s2 + 4
x(t) = 0.25 −0.25 cos(2t) + 0.5 sin(2t) = 0.25 + 0.56 cos(2t −116.6◦), t > 0
Alternate Method
One may also evaluate contributions of the poles at s = ± j2 to x(t) (i.e., k2e j2t +
k3e−j2t) and combine them in the time domain.
k2 = X(s)(s −2 j)

s=2 j =
(s + 1)
s(s + 2 j)

s=2 j
= 0.28̸ −116.6◦
k3 = k∗
2 = 0.28̸ 116.6◦
x(t) = 0.25 + 0.28e j(2t−116.6◦) + 0.28e−j(2t−116.6◦)
= 0.25 + 0.56 cos(2t −116.6◦), t > 0
Example
6.21
The system function of an LTI system is
H(s) = 2s + 1
s + 1
Find the system’s response to the input
x(t) = e−t sin(2t) u(t)

334
CHAPTER 6
The Laplace Transform and Its Applications
Solution
The Laplace transform of x(t) is
X(s) =
2
(s + 1)2 + 4
The Laplace transform of y(t) is
Y(s) = X(s)H(s) =
2(2s + 1)
(s + 1)(s2 + 2s + 5)
=
2(2s + 1)
(s + 1)(s + 1 + 2 j)(s + 1 −2 j)
= k1
s +
k2
s + 1 −2 j +
k∗
2
s + 1 + 2 j
k1, k2, and y(t) are found from
k1 = Y(s)(s + 1)

s=−1 = −1
2
k2 = Y(s)(s + 1 −2 j)

s=−1+2 j
=
√
17
4
̸ −76◦, and k∗
2 =
√
17
4
̸ 76◦
y(t) = −1
2e−t +
√
17
4 e−t 
e−j76◦e j2t + e j76◦e−j2t
= 1
2e−t 
−1 +
√
17 cos(2t −76◦)

, t > 0
Alternate Method
Y(s) =
2(2s + 1)
(s + 1)(s2 + 2s + 5) =
k1
s + 1 +
As + B
(s + 1)2 + 4
where k1 = −1
2 as before. By taking the common denominator of the terms on the
right-hand side of the above equation and then matching the two sides we ﬁnd A = 0.5
and B = 4.5. Then
Y(s) = −1
2
1
s + 1 + 1
2
s + 9
(s + 1)2 + 4
y(t) = 1
2e−t
−1 + cos(2t) + 4 sin(2t)

= 1
2e−t 
−1 +
√
17 cos(2t −76◦)

, t > 0
Another Alternate Method to Find As + B
Y(s) =
2(2s + 1)
(s + 1)(s2 + 2s + 5) =
k1
s + 1 +
As + B
(s + 1)2 + 4
Multiply both sides by (s2 + 2s + 5) and set s = −1 + j2.
2(2s + 1)
s + 1

s=−1+ j2 = A(−1 + j2) + B
By matching the real and imaginary parts of the two sides of the above equation we
ﬁnd A = 0.5 and B = 4.5. This method is more convenient and recommended.

Signals and Systems
335
6.15
Partial Fraction Expansion; Multiple-Order Poles
A pole that occurs more than once is called a multiple-order pole. A partial fraction
involving an nth-order pole contains additional terms up to the nth power of the repeated
factor. This is illustrated in the following example.
Example
6.22
Find x(t) for t > 0, given
X(s) =
s2 + 3
(s + 2)(s + 1)2 =
k1
s + 2 +
k2
(s + 1)2 +
k3
s + 1
Solution
X(s) =
k1
s + 2 +
k2
(s + 1)2 +
k3
s + 1
k1 = X(s)(s + 2)

s=−2 = 7 and k2 = X(s)(s + 1)2
s=−1 = 4
k3 may be found by taking the common denominator of the fractions and matching it
with the original function
7
s + 2+
4
(s + 1)2 + k3
s + 1 = 7(s + 1)2 + 4(s + 1) + k3(s + 1)(s + 2)
(s + 2)(s + 1)2
=
s2 + 3
(s + 2)(s + 1)2
Matching terms of numerators on both sides results in k3 = −6.
x(t) = 7e−2t + 2(2t −3)e−t, t > 0
Alternate Method
k3 may also be found from
k3 = d
ds

X(s)(s + 1)2
s=−1 = d
ds
	s2 + 3
s + 2

s=−1
= −6
Generalization
The alternate method of ﬁnding residues may be generalized to the case of nth-order
poles. This generalization is included here for the sake of completeness. In many
cases the method of matching coefﬁcients may prove to be easier, safer, and more
practical. Let
X(s) =
A(s)
(s + a)n B(s)
be a proper rational fraction with an nth-order pole at s = −a. The partial fraction
expansion of X(s) is
X(s) =
k0
(s + a)n +
k1
(s + a)n−1 + · · ·
ki
(s + a)n−i+1 + · · ·
kn
s + a + · · · etc.
where,
k0 = [X(s)(s + a)n]s=−a
k1 = d
ds [X(s)(s + a)n−1]s=−a
ki = 1
i!
di
dsi [X(s)(s + a)n]s=−a

336
CHAPTER 6
The Laplace Transform and Its Applications
6.16
Summary of the Laplace Transform
Properties and Theorems
See Table 6.1 for a summary of the Laplace transform properties and theorems.
TABLE 6.1 Some Properties of the Unilateral Laplace Transform
Property
Time Domain
⇐⇒
s-Domain
1
Deﬁnition
x(t) =
1
2π j

C
X(s)estds
⇐⇒
X(s) =

∞
0
x(t)e−stdt
2
Linearity
ax(t) + by(t)
⇐⇒
aX(s) + bY(s)
3
Time delay
x(t −T )u(t −T )
⇐⇒
X(s)e−st, T > 0
4
Multiplication by t
tx(t)
⇐⇒
−d X(s)
ds
5
Multiplication by t2
t2x(t)
⇐⇒
d2X(s)
ds2
6
Multiplication by tn
tnx(t)
⇐⇒
(−1)n dn X(s)
dsn
7
Multiplication by eat
x(t)eat
⇐⇒
X(s −a)
8
Scale change
x(at)
⇐⇒
1
a X
 s
a

, a > 0
9
Integration

t
0
x(t)dt
⇐⇒
X(s)
s
10
Differentiation
dx
dt
⇐⇒
sX(s) −x(0)
11
2nd-order differentiation
d2x
dt2
⇐⇒
s2X(s) −sx(0) −x′(0)
12
nth-order differentiation
dnx
dtn
⇐⇒
sn X(s) −sn−1x(0) −sn−2x′(0) · · · −x(n−1)(0)
13
Convolution

t
0
y(τ)x(t −τ)dτ
⇐⇒
X(s)Y(s)
Initial value theorem
lim
s→∞{sX(s)} = x(0)
Final value theorem
lim
s→0 {sX(s)} = x(∞)
Zero s

∞
0
x(t)dt = X(0)

Signals and Systems
337
6.17
A Table of Unilateral Laplace
Transform Pairs
See Table 6.2 for a table of unilateral Laplace transform pairs. In this table x(t) is deﬁned
for t > 0.
TABLE 6.2 Unilateral Laplace Transform Pairs
x(t) = L−1[X(s)]
⇐⇒
X(s) = L[x(t)] =  ∞
0
x(t)e−stdt
Region of Convergence
1
δ(t)
⇐⇒
1
all s
2
1
⇐⇒
1
s
RE[s] > 0
3
eat
⇐⇒
1
s −a
RE[s] > a
4
sin(ωt)
⇐⇒
ω
s2 + ω2
RE[s] > 0
5
cos(ωt)
⇐⇒
s
s2 + ω2
RE[s] > 0
6
eat sin(ωt)
⇐⇒
ω
(s −a)2 + ω2
RE[s] > a
7
eat cos(ωt)
⇐⇒
s −a
(s −a)2 + ω2
RE[s] > a
8
sin(ωt + θ)
⇐⇒
s sin θ + ω cos θ
s2 + ω2
RE[s] > 0
9
cos(ωt + θ)
⇐⇒
s cos θ −ω sin θ
s2 + ω2
RE[s] > 0
10
eat sin(ωt + θ)
⇐⇒
(s −a) sin θ + ω cos θ
(s −a)2 + ω2
RE[s] > a
11
eat cos(ωt + θ)
⇐⇒
(s −a) cos θ −ω sin θ
(s −a)2 + ω2
RE[s] > a
12
sinh(at)
⇐⇒
a
s2 −a2
RE[s] > a
13
cosh(at)
⇐⇒
s
s2 −a2
RE[s] > a
14
tn
⇐⇒
n!
sn+1
RE[s] > 0
15
tneat
⇐⇒
n!
(s −a)n+1
RE[s] > a
Note: The ROC for the unilateral Laplace transform is always the region of the s-plane
to the right of that pole of X(s) with largest real part. Hence, if σ0 is the real part of such
a pole then ROC = {s; RE[s] > σ0}.

338
CHAPTER 6
The Laplace Transform and Its Applications
6.18
Circuit Solution
Linear circuits may be analyzed by applying the Laplace transform technique. This can
be done in one of two ways. In one approach, covered in this section, the current-voltage
relationships of circuit elements are written in the s-domain by taking the Laplace trans-
forms of their time-domain versions. In doing this, the initial voltages of the capacitors
and initial currents of the inductors are incorporated in the s-domain terminal characteris-
tics. By applying Kirchhoff’s laws to the transform circuit, the Laplace transforms of the
desired variables (and hence their time-domain counterparts) are obtained. In the second
approach, covered in section 6.19, the Laplace transform is applied to the dynamical
equations of the circuit.
The terminal characteristics of R, L, and C and their transforms, along with the equiv-
alent circuit models, are summarized in Table 6.3. Models are shown in Figure 6.4. Note
that V (s) and I (s) in Table 6.3 are not phasors. They are the Laplace transforms of the el-
ements’ terminal voltages and currents, respectively. In the special case where initial con-
ditions are zero, the transform characteristics become the same as a generalized phasor.
TABLE 6.3 Laplace Transform Models of R, L, C
Element
Time Domain
⇔
Transform Domain
Figure
Resistor
v(t) = Ri(t)
⇔
V (s) = RI (s)
Figure 6.4(a)
Capacitor
v(t) = v(0) + 1
C

t
0
i(t)dt
⇔
V (s) = v(0)
s
+ I (s)
Cs
Figure 6.4(b)
Inductor
i(t) = i(0) + 1
L

t
0
v(t)dt
⇔
I (s) = i(0)
s
+ V (s)
Ls
Figure 6.4(c)
It should be remembered that the actual capacitor voltage is the inverse transform
of V (s). Similarly, the actual inductor current is the inverse transform of I (s).
R
v(t)
v(t) = Ri(t)
V(s) = RI(s)
V(s) =
+
i(t)
+
Domain
Time
Transform
a) Resistor
v(t) =
i(t)dt + V0
t∫
b) Capacitor
c) Inductor
–
R
V(s)
I(s)
+
–
C
v(t)
i(t)
+
–
V(s)
I(s)
+
–
1
Cs
L
v(t)
i(t)
+
–
1
C
0
I(s)
Cs
i(t) =
v(t)dt + I0
t∫
1
L
0
V0s
V0s
I(s) =
+
V(s)
Ls
I0
s
+–
V(s)
Ls
I(s)
+
–
I0
s
FIGURE 6.4 Laplace transform models of R, L, and C, including initial conditions.

Signals and Systems
339
Example
6.23
In Figure 6.5(a) R1 = 3 , R2 = 2 , L = 1 H, and C = 1 F. Find v(t) and i(t)
given
ig =

1 A,
t < 0
cos t,
t > 0
L
R1
(a)
(c)
R2
+
+
–
–
v
V(s)
C
i
ig
I(s)
A
A
A
R1
Ls
Ig(s)
R2
R1
(b)
R2
+
–
v(0) i(0)
s
ig
i(0)
+–
1
Cs
v(0)
s
FIGURE 6.5 (a)An RLC circuit with R1 = 3 , R2 = 2 , L = 1 H, C = 1 F, and ig = u(−t) + cos t u(t). (b) The
equivalent DC circuit for t < 0. (c) The Laplace transform model for t > 0. See Example 6.23.
Solution
For t < 0 we have the DC circuit of Figure 6.5(b), which generates i(0) = 0.4 A and
v(0) = 1.2 V. Applying the above conditions to t > 0 we construct the transform
circuit of Figure 6.5(c) from which the dynamical equations of the circuit in terms of
V (s) and I (s) are formulated.









KCL at node A:
	
V (s) −v(0)
s

s + V (s)
2
+ I (s) = Ig(s)
KVL around the external loop:
−V (s) + 3I (s) +
	
I (s) −i(0)
s

s = 0
where v(0) = 1.2 V, i(0) = 0.4 A, and Ig(s) = s/(s2 + 1) is the Laplace transform
of ig = cos t. Substituting for v(0), i(0), and Ig(s) we obtain the following two
equations:







V (s)

s + 1
2

+ I (s) = 1.2s2 + s + 1.2
s2 + 1
−V (s) + I (s)(s + 3) = 0.4
Solving for V (s) and I (s) we obtain
V (s) = (s + 3)(1.2s2 + s + 1.2) −0.4(s2 + 1)
(s2 + 1)(s2 + 3.5s + 2.5)
I (s) = (1.2s2 + s + 1.2) + 0.4(s + 0.5)(s2 + 1)
(s2 + 1)(s2 + 3.5s + 2.5)

340
CHAPTER 6
The Laplace Transform and Its Applications
Applying partial fraction expansions
V (s) = 0.6667
s + 1 −0.0184
s + 2.5 + 0.5513s + 0.621
s2 + 1
I (s) = 0.3332
s + 1 −0.0367
s + 2.5 + 0.1034s + 0.2414
s2 + 1
Taking the inverse transforms
v(t) = 0.6667e−t −0.0185e−2.5t + 0.8304 cos(t −48.4◦), t > 0
i(t) = 0.3332e−t −0.0367e−2.5t + 0.2626 cos(t −66.8◦), t > 0
6.19
Solution of Dynamical Equations
LinearcircuitsmayalsobeanalyzedbyapplyingtheLaplacetransformtotheirdynamical
equations. In this method, circuit laws are applied to the time-domain circuit to obtain
lineardifferentialequations,calleddynamicalequations,intermsofthedesiredvariables.
The Laplace transform is then used as a solution tool.
Example
6.24
Again, let in the circuit of Figure 6.5(a) R1 = 3 , R2 = 2 , L = 1 H, C = 1 F,
and
ig =

1 A,
t < 0
cos t,
t ≥0
Write two equations involving v(t), i(t), their ﬁrst-order derivatives, and the source
ig only. Solve using the Laplace transform technique.
Solution
For t < 0 we have the DC circuit of Figure 6.5(b) in which i = 0.4 A and v = 1.2 V.
For t ≥0 we use variables i and v to formulate the dynamical equations of the circuit.
These variables determine the state of the system and are called state variables. The
dynamical equations based on state variables are called state equations. From the
circuit of Figure 6.5(a) we have

KCL at node A:
v′ + v
2 + i = ig
KVL around the external loop:
v −3i −i′ = 0
Moving the derivative terms to the left side and the rest of the terms to the right side
we get

v′ = −0.5v −i + ig
i′ = v −3i

Signals and Systems
341
By taking the Laplace transforms of the above equations we have

L[v′] = sV (s) −v(0)
L[i′] = sI (s) −i(0)

sV (s) −v(0) = −0.5V (s) −I (s) + Ig(s)
sI (s) −i(0) = V (s) −3I (s)
Note that the above includes the initial conditions. Substituting for v(0), i(0), and
Ig(s) and collecting terms



V (s)(s + 1
2) + I (s) = 1.2s2 + s + 1.2
s2 + 1
−V (s) + I (s)(s + 3) = 0.4
Solving for V (s) and I (s) we ﬁnd
V (s) = (s + 3)(1.2s2 + s + 1.2) −0.4(s2 + 1)
(s2 + 1)(s2 + 3.5s + 2.5)
I (s) = (1.2s2 + s + 1.2) + 0.4(s + 0.5)(s2 + 1)
(s2 + 1)(s2 + 3.5s + 2.5)
Note that these are the same expressions found from the transform circuit of
Example 6.23. Taking the inverse transforms
v(t) = 0.6667e−t −0.0185e−2.5t + 0.8304 cos(t −48.4◦), t > 0
i(t) = 0.3332e−t −0.0367e−2.5t + 0.2626 cos(t −66.8◦), t > 0
Matrix Form
The state equations derived in Example 6.24 may be written in matrix form, with inputs,
states, coefﬁcients, and the outputs shown as
X′ = A × X + B
where X is the array of state variables, A is the coefﬁcients matrix, and B is the array of
inputs. The state equations for the circuit of Examples 6.24 are

KCL:
v′ = −0.5v −i + ig
KVL:
i′ = v −3i
These may be written as
	
v′
i′

=
	−0.5
−1
1
−3

 	v
i

+
	ig
0


342
CHAPTER 6
The Laplace Transform and Its Applications
Example
6.25
Consider the circuit of Example 6.23 once more. Without using the Laplace transform,
ﬁnd and solve two separate differential equations for v(t) and i(t). Identify the forced
and natural components of the responses.
Solution
By using the generalized phasor (i.e., the s-operator) and generalized impedances we
ﬁrst write the state equations in the following form:
V (0.5 + s) + I = Is
V −I (3 + s) = 0
and obtain system functions V/Ig and I/Ig.
V
Ig
=
s + 3
s2 + 3.5s + 2.5
I
Ig
=
1
s2 + 3.5s + 2.5
The differential equations are
v′′ + 3.5v′ + 2.5v = i′
g + 3ig
i′′ + 3.5i′ + 2.5i = ig
The above equations apply at all times. For t < 0 we have ig = 1 A, from which we
get v = 1.2 V and i = 0.4 A. These results agree with the DC steady-state response
directly obtained from the resistive circuit. For t ≥0, ig = cos t. Solutions to the
differential equations contain a forced part (shown by the subscript f ) and a natural
part (shown by the subscript n). The forced and natural responses are the particular
and homogeneous parts of the solution of the differential equation.
v(t) = v f + vn and i(t) = i f + in
The complex amplitude of the forced response is found by evaluating system functions
at the complex frequency of the current source, s = j1, and multiplying it by Ig = 1.
We get V = 0.8.3̸ −48.4◦and I = 0.2626̸ −66.8◦which in time domain means
v f = 0.83 cos(t −48.4◦)
and
i f = 0.2626 cos(t −66.8◦)
The natural frequencies are found from the characteristic equation
s2 + 3.5s + 2.5 = 0, s = −1,
−2.5
The natural responses are
vn(t) = Ae−t + Be−2.5t
and
in(t) = Ce−t + De−2.5t
Total responses at t > 0 are
v(t) = 0.83 cos(t −48.4◦) + Ae−t + Be−2.5t
i(t) = 0.2626 cos(t −66.8◦) + Ce−t + De−2.5t

Signals and Systems
343
To ﬁnd A, B, C, and D we need the initial conditions i(0+), i′(0+), v(0+), and v′(0+).
In transition from t = 0−to t = 0+ i and v do not change, remaining at i(0+) =
0.4 A and v(0+) = 1.2 V. To ﬁnd i′(0+) and v′(0+) we apply the state equations
at t = 0+.

v′ = −0.5v −i + ig
i′ = v −3i
⇒

v′(0+) = −0.5 × 1.2 −0.4 + 1 = 0
i′(0+) = 1.2 −3 × 0.4 = 0
The initial conditions i(0+), i′(0+), v(0+), and v′(0+) can also be found directly
from time analysis of the circuit around t = 0. It should not be a surprise that
i′(0+) = v′(0+) = 0, as the value of the current source and its derivative didn’t
change at t = 0. Applying the initial conditions to v we get
v(0+) = 0.83 cos 48.4◦+ A + B = 1.2
v′(0+) = −0.83 sin(−48.4◦) −A −2.5B = 0
from which we ﬁnd A = 0.6667, B = −0.0185, and
v(t) = 0.6667e−t −0.0185e−2.5t + 0.8304 cos(t −48.4◦), t > 0
Similarly,
i(t) = 0.3332e−t −0.0367e−2.5t + 0.2626 cos(t −66.8◦), t > 0
6.20
Bilateral Laplace Transform
The bilateral Laplace transform of a function x(t) is deﬁned by
L[x(t)] = X(s) =
 ∞
−∞
x(t)e−stdt
The range of the integral requires the knowledge of x(t) from −∞to ∞. Again, for
the transform to exist, the above integral should converge, limiting s to a region of
convergence (ROC) in the s-plane.
Example
6.26
Unit-step function
The bilateral Laplace transform of x(t) = u(t) is
X(s) =
 ∞
−∞
x(t)e−stdt =
 ∞
0
e−stdt = 1
s ,
RE[s] > 0
It is readily seen that because x(t) = 0 for t < 0, the unilateral and bilateral transforms
of x(t) are identical. X(s) has a pole at the origin. The ROC is on the right of the pole
(i.e., the right-half plane, RHP).

344
CHAPTER 6
The Laplace Transform and Its Applications
Example
6.27
Left-sided unit-step function
The bilateral Laplace transform of x(t) = u(−t) is
X(s) =
 0
−∞
e−stdt = −1
s ,
RE[s] < 0
The ROC is the right-half plane, RHP (on the left of the pole at s = 0).
Example
6.28
Unit impulse
The bilateral Laplace transform of δ(t) is
 ∞
−∞
δ(t)e−stdt = 1 ROC = {s}, all of the s −plane
Example
6.29
Right-sided exponential
The bilateral Laplace transform of x(t) = eatu(t) is
X(s) =
 ∞
0
eate−stdt =
1
s −a ,
RE[s] > a
Again, because x(t) = 0 for t < 0, the unilateral and bilateral transforms are the
same. X(s) has a pole at s = a. The ROC is the portion of the s-plane to the right of
the pole.
Example
6.30
Left-sided exponential
The bilateral Laplace transform of x(t) = ebtu(−t) is
X(s) =
 0
−∞
ebte−stdt =
−1
s −b,
RE[s] < b
The bilateral transform has a pole at s = b. The ROC is to the left of the pole.
Example
6.31
Two-sided exponential
The bilateral Laplace transform of x(t) = e−c|t|, c > 0, −∞< t < ∞is
X(s) =
 0
−∞
ecte−stdt +
 ∞
0
e−cte−stdt = −
1
s −c +
1
s + c
=
−2c
s2 −c2 , −c < RE[s] < c
Table 6.4 summarizes transform pairs for various exponential functions.

Signals and Systems
345
TABLE 6.4 Bilateral Transforms of Exponential Functions and Their ROC
x(t)
X(s)
ROC
Existence of the Transform
eatu(t)
1
s −a
RE[s] > a
Transform always exists in the ROC
ebtu(−t)
−1
s −b
RE[s] < b
Transform always exists in the ROC
e−c|t|
−2c
s2 −c2
−c < RE[s] < c Transform exists only if c > 0
eatu(t) + ebtu(−t)
a −b
(s −a)(s −b) a < RE[s] < b
Transform exists only if b > a
Example
6.32
One-sided decaying or growing sinusoids
The bilateral Laplace transforms of eat sin(ωt)u(t) and eat cos(ωt)u(t) may be de-
duced from Example 6.29. Similarly, the transforms of ebt sin(ωt)u(−t) and
ebt cos(ωt)u(−t) may be deduced from Example 6.30. These are derived in Table 6.5.
The transforms of eat sin(ωt)u(t) and eat cos(ωt)u(t) each have two poles at s1,2 =
a ± jω. Their ROC are to the right of the poles. Similarly, the transforms of ebt
sin(ωt)u(−t) and ebt cos(ωt)u(−t) have two poles at s1,2 = b ± jω, with the ROC
to the left.
TABLE 6.5 Bilateral Laplace Transforms of One-Sided Decaying or Growing Exponentials and Sinusoids
and Their ROC
x(t)
=⇒
X(s)
ROC
eatu(t)
⇒
1
s −a
RE[s] > a
ebtu(−t)
⇒
−1
s −b
RE[s] < b
eat sin(ωt)u(t) = eat
	
e jωt −e−jωt
2 j

u(t)
⇒
1
2 j
	
1
s −a −jω −
1
s −a + jω

=
ω
(s −a)2 + ω2
RE[s] > a
eat cos(ωt)u(t) = eat
	
e jωt + e−jωt
2

u(t)
⇒
1
2
	
1
s −a −jω +
1
s −a + jω

=
s −a
(s −a)2 + ω2
RE[s] > a
ebt sin(ωt)u(−t) = ebt
	
e jωt −e−jωt
2 j

u(−t) ⇒
1
2 j
	
−1
s −b −jω +
1
s −b + jω

= −
ω
(s −b)2 + ω2 RE[s] < b
ebt cos(ωt)u(−t) = ebt
	
e jωt + e−jωt
2

u(−t) ⇒
1
2
	
−1
s −b −jω −
1
s −b + jω

= −
s −b
(s −b)2 + ω2
RE[s] < b

346
CHAPTER 6
The Laplace Transform and Its Applications
Example
6.33
Two-sided decaying sinusoids
The bilateral transforms of e−c|t| sin(ωt) and e−c|t| cos(ωt), c > 0, −∞< t < ∞
are given in Table 6.6.
TABLE 6.6 Bilateral Transforms of Two-Sided Decaying Exponentials Sinusoids and Their ROC
x(t)
=⇒
X(s)
ROC
e−c|t|, c > 0
⇒
−2c
s2 −c2
−c < RE[s] < c
e−c|t| sin(ωt)
⇒
ω
(s + c)2 + ω2 −
ω
(s −c)2 + ω2 =
−4ωcs
(s2 −c2)2 + 2ω2(s2 + c2) + ω4
−c < RE[s] < c
e−c|t| cos(ωt) ⇒
s + c
(s + c)2 + ω2 −
s −c
(s −c)2 + ω2 = −2c
(s2 −c2) −ω2
(s2 −c2) + 2ω2(s2 + c2) + ω4
−c < RE[s] < c
6.21
Region of Convergence of the Bilateral
Laplace Transform
In section 6.2 we discussed the ROC for the unilateral transform. Similar considerations
abouttheconvergenceoftheintegralapplytotheROCofthebilateraltransform,resulting
in more restrictions. The ROC can include the LHP, the RHP, or be limited to a vertical
band in the s-plane. In this section we begin with some examples, then summarize the
features of the ROC.
Example
6.34
For each time function in Table 6.7(a), identify the correct expression for its bilat-
eral Laplace transform [in the form of A, B, C, . . . , L from Table 6.7(b)], and the
correct ROC [in the form of 1, 2, 3, . . . , 12, from Table 6.7(c). Enter your answers in
Table 6.7(a)].
TABLE 6.7a
(Questions)
x1(t) = etu(t)
x2(t) = e−tu(t)
x3(t) = etu(−t)
x4(t) = e−tu(−t)
x5(t) = e2tu(t)
x6(t) = e−2tu(t)
x7(t) = e2tu(−t)
x8(t) = e−2tu(−t)
x9(t) = e3tu(t)
x10(t) = e−3tu(t)
x11(t) = e3tu(−t)
x12(t) = e−3tu(−t)
TABLE 6.7b
(Possible answers)
A
−1
s+2
B
1
s−1
C
−1
s−1
D
1
s+3
E
1
s+1
F
−1
s+3
G
−1
s+1
H
1
s−2
I
1
s−3
J
−1
s−3
K
1
s+2
L
−1
s−2
TABLE 6.7c
(Possible answers)
1
RE[s] > 2
2
RE[s] < −2
3
RE[s] > 3
4
RE[s] > 1
5
RE[s] < 3
6
RE[s] > −2
7
RE[s] < 2
8
RE[s] < −1
9
RE[s] < −3
10
RE[s] > −3
11
RE[s] < 1
12
RE[s] > −1

Signals and Systems
347
Solution
From Table 6.4, the answers are, respectively: B4, E12, C11, G8, H1, K6, L7, A2, I3,
D10, J5, F9.
Example
6.35
Find the expression for the bilateral Laplace transform and the ROC of the fol-
lowing time functions which are constructed from xk(t), k = 1, 2 · · · 12, given in
Table 6.7(a).
1.
xa(t) = x3(t) + x6(t) + x10(t)
2.
xb(t) = x1(t) + x7(t) + x11(t)
3.
xc(t) = x2(t) + x5(t) + x11(t)
Solution
Using the linearity property and the results of Table 6.4 we ﬁnd
1.
Xa(s) = X3(s) + X6(s) + X10(s) =
−1
s −1 +
1
s + 2 +
1
s + 3
=
s2 −2s −11
s3 + 4s2 + s −6
−2 < RE[s] < 1
2.
Xb(s) = X1(s) + X7(s) + X11(s) =
1
s −1 −
1
s −2 −
1
s −3
=
−s2 + 2s + 1
s3 −6s2 + 11s −6
1 < RE[s] < 2
3.
Xc(s) = X2(s) + X5(s) + X11(s) =
1
s + 1 +
1
s −2 −
1
s −3
=
s2 −6s + 5
s3 −4s2 + s + 6
2 < RE[s] < 3
Example
6.36
The ROC of two-sided exponentials
Find the bilateral transforms of the following functions:
1. x1(t) = e−3|t|, −∞< t < ∞
2. x2(t) = e3tu(−t) + e−2tu(t)
3. x3(t) = e−2tu(−t) + e−3tu(t)
4. x4(t) = e3tu(−t) + e2tu(t)
5. x5(t) = e−3tu(−t) + e2tu(t)
6. x6(t) = e−3tu(−t) + e−2tu(t)
Solution
The transforms are derived below.
1.
X1(s) =
 0
−∞
e3te−stdt +
 ∞
0
e−3te−stdt = −
1
s −3 +
1
s + 3
=
−6
s2 −9,
−3 < RE[s] < 3

348
CHAPTER 6
The Laplace Transform and Its Applications
2.
X2(s) =
 0
−∞
e3te−stdt +
 ∞
0
e−2te−stdt = −
1
s −3 +
1
s + 2
=
−5
s2 −s −6,
−2 < RE[s] < 3
3.
X3(s) =
 0
−∞
e−2te−stdt +
 ∞
0
e−3te−stdt = −
1
s + 2 +
1
s + 3
=
−1
s2 + 5s + 6,
−3 < RE[s] < −2
4.
X4(s) =
 0
−∞
e3te−stdt +
 ∞
0
e2te−stdt = −
1
s −3 +
1
s −2
=
−1
s2 −5s + 6,
2 < RE[s] < 3
5.
X5(s) =
 0
−∞
e−3te−stdt +
 ∞
0
e2te−stdt = ∞,
transform doesn’t exist No ROC
6.
X6(s) =
 0
−∞
e−3te−stdt +
 ∞
0
e−2te−stdt = ∞,
transform doesn’t exist No ROC
Note that the ROC of X(s), if it exists, is the single vertical band in the s-plane limited
by its two poles. Transforms of x5(t) and x6(t) don’t exist because the convergence
of their integrals would have required 2 < RE[s] < −3 and −2 < RE[s] < −3,
respectively, which are not realizable.
Summary on ROC of bilateral transform
From the above examples we observe that
1.
The ROC, if it exists, is a contiguous region in the s-plane. It doesn’t contain
any poles.
2.
The ROC of a right-sided function is the area to the right of its pole with the
greatest real part, RE[s] > a.
3.
The ROC of a left-sided function is the area to the left of its pole with the
smallest real part, RE[s] < b.
4.
The ROC of a two-sided function, if it exists, is a vertical strip a < RE[s] < b.
The poles on the left of the ROC are due to the causal portion of x(t) and the
poles on the right are due to the anticausal portion.
6.22
Properties of the Bilateral Laplace Transform
The basic properties of the Laplace transform were presented in sections 6.2 and 6.4 to
6.11. These properties apply to the bilateral transform as well. However, in this case,
because of the range of the integral: (a) the initial and ﬁnal value theorems become mute,

Signals and Systems
349
(b) the differentiation property becomes simpler, and (c) the time-shift property will
apply uniformly to shifts to the left as well as to the right. These properties are listed in
Table 6.8 below.
TABLE 6.8 Properties of the Bilateral Laplace Transform
1
Deﬁnition
L[x(t)] ≡X(s) =

∞
−∞
x(t)e−stdt
2
Linearity
L[ax1(t) + bx2(t)] = aX1(s) + bX2(s)
3
Time shift
L[x(t −T )] = X(s)e−sT
4
Multiplication by t
L[tx(t)] = −d X(s)
ds
5
Multiplication by eat
L[x(t)eat] = X(s −a)
6
Differentiation
L
	
dx(t)
dt

= sX(s)
7
Integration
L
	
t
−∞
x(t)dt

= X(s)
s
8
Convolution
L[x(t) ⋆h(t)] = X(s)H(s)
9
Uniqueness
x(t) ⇐⇒X(s)
Time Shift
To show this property, apply the deﬁnition of the bilateral transform and change (t −T )
to τ as shown below.
L[x(t −T )] =
 ∞
−∞
x(t −T )e−stdt =
 ∞
−∞
x(τ)e−s(τ+T )dτ
= e−sT
 ∞
−∞
x(τ)e−sτdτ = e−sT X(s)
A time shift doesn’t inﬂuence the ROC.
6.23
Inverse of the Bilateral Laplace Transform
The inverse of the Laplace transform is found from
x(t) = L−1[X(s)] =
1
2π j

C
X(s)estds
where the integral is taken along a line (a contour) in the ROC. As in the case of the
unilateral transform, the integration path goes from −∞< IM[s] < ∞within the
ROC. According to Cauchy’s theorem on contour integration of functions of complex
variables, the value of the above integral along a closed contour is equal to the sum of
residuesofthefunction X(s)est atallpolesinsidethecontour.Evaluatingtheintegralthen
becomes a matter of ﬁnding the residues. The closed integration path may be traversed
by an inﬁnitely large semicircle without affecting the value of the above integral. To

350
CHAPTER 6
The Laplace Transform and Its Applications
evaluate x(t) for t > 0, we choose a closed contour which is a very large semicircle
(R = ∞) in the LHP and on which RE[s] < 0. The value of the integral over the
semicircle then becomes zero and the inverse transform becomes equal to the sum of
the residues of X(s)est at its poles within the contour; that is, to the left of the ROC.
Similarly, to evaluate x(t) for t < 0, we traverse the closed contour through a very large
semicircle in the RHP, on which RE[s] > 0. The value of the integral over the semicircle
then becomes zero and the inverse transform becomes equal to the sum of the residues
of the function X(s)est at its poles within the contour; that is, to the right of the ROC.
The residues may be found by expanding X(s) to its fractions. The sum of residues of
the function X(s)est at poles to the left of the ROC produces the causal portion of x(t).
The sum of poles to the right generates its anticausal portion. In practice, one expands
X(s) into its partial fractions and then uses tables of transform pairs.
Example
6.37
Given the bilateral Laplace transform
X(s) =
B(s)
(s + 2)(s + 1)(s −1.5)(s −3), with the ROC of −1 < RE[s] < 1.5
(see Figure 6.6), what can be said about x(t)?
Real
Imaginary
Pole plot
0.8
1
0.6
0.4
0.2
–0.2
1
0
0
–1
–2
–3
–4
2
3
4
–0.4
–0.6
–0.8
–1
C1
(t > 0)
C2
(t < 0)
FIGURE 6.6 The ROC of X(s) is the vertical band −1 < RE[s] < 1.5 in the s-plane.
The poles to the left of the ROC constitute the causal part of the time function and those
on the right produce the anticausal part.
Solution
In this case the poles are at −2, −1, 1.5, and 3. The time function is two-sided. It
is made of two left-sided and two right-sided exponentials. The two poles on the left
of ROC constitute the causal part of x(t) and those on its right produce its anticausal

Signals and Systems
351
segment. The initial vale of each exponetial is set by the residue of X(s) at the
corresponding pole. The Laplace transform and time function are summarized below:
X(s) =
B(s)
(s + 2)(s + 1)(s −1.5)(s −3)
=
k1
s + 2 +
k2
s + 1 +
k3
s −1.5 +
k4
s −3, ROC is −1 < RE[s] < 1.5
x(t) = −

k4e3t + k3e1.5t
u(−t) +

k2e−t + k1e−2t
u(t)
Example
6.38
This example considers ﬁve different ROCs associated with the pole conﬁguration in
Figure 6.6 and evaluates their corresponding time functions. Given
H(s) =
s3 + 7s2 + 1.5s −34
s4 −1.5s3 −7s2 + 4.5s + 9
a.
Find the poles of H(s) and expand it to its partial fractions.
b.
Find all possible inverse bilateral Laplace transforms of H(s).
Solution
a.
First ﬁnd the roots of the denominator:
s4 −1.5s3 −7s2 + 4.5s + 9 = 0
s = −2, −1, 1.5, 3
Then expand H(s) to its partial fractions.
H(s) =
s3 + 7s2 + 1.5s −34
(s + 2)(s + 1)(s −1.5)(s −3) =
k1
s + 2 +
k2
s + 1 +
k3
s −1.5 +
k4
s −3
k1 =
s3 + 7s2 + 1.5s −34
(s + 1)(s −1.5)(s −3)

s=−2
= 0.9714
k2 =
s3 + 7s2 + 1.5s −34
(s + 2)(s −1.5)(s −3)

s=−1
= −2.95
k3 = s3 + 7s2 + 1.5s −34
(s + 2)(s + 1)(s −3)

s=1.5
= 0.9616
k4 =
s3 + 7s2 + 1.5s −34
(s + 2)(s + 1)(s −1.5)

s=3
= 2.0167
b.
The transform has four poles at s = −2, −1, 1.5, 3. The ﬁve possible ROCs,
and the time functions associated with each, are listed below.
ROC1 is RE[s] < −2
⇒
h1(t) = [−k1e−2t −k2e−t −k3e1.5t −k4e3t]u(−t)
ROC2 is −2 < RE[s] < −1
⇒
h2(t) = [−k2e−t −k3e1.5t −k4e3t]u(−t) + k1e−2tu(t)
ROC3 is −1 < RE[s] < 1.5
⇒
h3(t) = [−k3e1.5t −k4e3t]u(−t) + [k1e−2t + k2e−t]u(t)
ROC4 is 1.5 < RE[s] < 3
⇒
h4(t) = −k4e3tu(−t) + [k1e−2t + k2e−t + k3e1.5t]u(t)
ROC5 is RE[s] > 3
⇒
h5(t) = [k1e−2t + k2e−t + k3e1.5t + k4e3t]u(t)

352
CHAPTER 6
The Laplace Transform and Its Applications
Example
6.39
Using partial fraction expansion ﬁnd the inverse of the following bilateral Laplace
transforms:
α)
Xα(s) =
s2 −2s −11
s3 + 4s2 + s −6
−2 < RE[s] < 1
β)
Xβ(s) =
−s2 + 2s + 1
s3 −6s2 + 11s −6
1 < RE[s] < 2
γ )
Xγ (s) =
s2 −6s + 5
s3 −4s2 + s + 6
2 < RE[s] < 3
Solution
We ﬁrst ﬁnd the roots of the denominator of X(s). (This may be done by an analytical
method, a successive approximation technique, or using a software package such as
Matlab.) We then expand each X(s) into its partial fractions. The fractions containing
the poles on the left of the ROC generate the causal part of x(t). The poles on the
right generate the anticausal part. See Figure 6.7 −α, β, γ .
α) Xα(s) =
s2 −2s −11
s3 + 4s2 + s −6,
−2 < RE[s] < 1
s3 + 4s2 + s −6 = 0, s1,2,3 = 1, −2, −3.
Xα(s) =
s2 −2s −11
((s −1)(s + 2)(s + 3) =
k1
s −1 +
k2
s + 2 +
k3
s + 3
k1 = (s −1)Xα(s)

s=1 = s2 −2s −11
(s + 2)(s + 3)

s=1 = −1
k2 = (s + 2)Xα(s)

s=−2 = s2 −2s −11
(s −1)(s + 3)

s=−2 = 1
k3 = (s + 3)Xα(s)

s=−3 = s2 −2s −11
(s −1)(s + 2)

s=−3 = 1
xα(t) = etu(−t) + e−2tu(t) + e−3tu(t)
Similarly,
β) Xβ(s) =
−s2 + 2s + 1
s3 −6s2 + 11s −6 =
1
s −1 −
1
s −2 −
1
s −3,
1 < RE[s] < 2
xβ(t) = etu(t) + e2tu(−t) + e3tu(−t)
and,
γ ) Xγ (s) =
s2 −6s + 5
s3 −4s2 + s + 6 =
1
s + 1 +
1
s −2 −
1
s −3,
2 < RE[s] < 3
xγ (t) = e−tu(t) + e2tu(t) + e3tu(−t)

Signals and Systems
353
Pole Plot
Imaginary
–1
–4
–3
–2
–1
0
Real
(α)
1
2
3
4
5
0
1
Imaginary
–4
–3
–2
–1
0
Real
(β)
1
2
3
4
5
–4
–3
–2
–1
0
Real
(χ)
1
2
3
4
5
Imaginary
–1
0
1
Imaginary
–1
0
1
Pole Plot
Pole Plot
FIGURE 6.7 The ROCs for three transforms. For t < 0 the integration contour circles the RHP poles in a clockwise
direction. For t > 0 it circles the LHP poles in a counterclockwise direction. See Example 6.39.
6.24
A Table of Bilateral Laplace
Transform Pairs
See Table 6.9 for a list of bilateral Laplace transform pairs. In this table x(t) is deﬁned
for −∞< t < ∞.
TABLE 6.9 Bilateral Laplace Transform Pairs
x(t) = L −1[X(s)]
⇐⇒
X(s) =  ∞
−∞x(t)e−stdt
Region of Convergence
1
δ(t)
⇐⇒
1
all s
2
u(t)
⇐⇒
1
s
RE[s] > 0
3
u(−t)
⇐⇒
−1
s
RE[s] < 0
4
eatu(t)
⇐⇒
1
s −a
RE[s] > a
5
ebtu(−t)
⇐⇒
−1
s −b
RE[s] < b
6
e−c|t|
⇐⇒
−2c
s2 −c2
−c < RE[s] < c
7
eat sin(ωt)u(t)
⇐⇒
ω
(s −a)2 + ω2
RE[s] > a
8
eat cos(ωt)u(t)
⇐⇒
s −a
(s −a)2 + ω2
RE[s] > a
9
ebt sin(ωt)u(−t)
⇐⇒
−
ω
(s −b)2 + ω2
RE[s] < b
10
ebt cos(ωt)u(−t)
⇐⇒
−
s −b
(s −b)2 + ω2
RE[s] < b

354
CHAPTER 6
The Laplace Transform and Its Applications
6.25
System Function
From the convolution property we see that Y(s) = H(s)X(s), where Y(s) and X(s) are
the Laplace transforms of an input-output pair to an LTI system and H(s) is the Laplace
transform of its unit-impulse response. We deﬁne H(s) to be the system function. In this
section we present some applications. More detail will be given in Chapter 9.
H(s) Is the Ratio Y(s)/X(s)
The system function is the ratio of the Laplace transform of the output to the Laplace
transform of the input. This may be considered the ﬁrst deﬁnition of the system function.
Based on this deﬁnition, the system function can be obtained from input-output pair (of
an LTI system) regardless of how that pair was obtained. For instance, the output to a
given input may be measured experimentally and modeled as a mathematical function.
The system function can then be obtained as the ratio of input-output Laplace tranforms.
Example 6.40 illustrates the above method.
Example
6.40
You are asked to identify a two-port electronic device and model it by an LTI system.
For this purpose, a 1-volt rectangular voltage pulse lasting 1 ms is applied to the input
of the device:
v1(t) =

1,
0 < t < 1 msec.
0,
elsewhere
The output is recorded and modeled by
v2(t) =



0,
t < 0
1 −e−1,000t,
0 < t < 1 msec
1.718e−1,000t,
t > 1 msec
Assume the device is linear and time invariant and ﬁnd its system function.
Solution
Laplacetransformswillbeused.Theinputisv1(t) = u(t)−u(t−0.001)andtheoutput
may be represented as v2(t) = y(t) −y(t −0.001), where y(t) = (1 −e−1,000t)u(t).
The system function is then found from
v1(t) = u(t) −u(t −0.001)
⇒
V1(s) = (1 −e−0.001s)
s
y(t) = (1 −e−1000t)u(t)
⇒
Y(s) = 1
s −
1
s + 1,000 =
1,000
s(s + 1,000)
v2(t) = y(t) −y(t −0.001)
⇒
V2(s) = (1 −e−0.001s)Y(s) = 1,000 1 −e−0.001s
s(s + 1,000)
H(s) = V2(s)
V1(s)
⇒
H(s) = 1,000 1 −e−0.001s
s(s + 1,000) ×
s
1 −e−0.001s =
1,000
s + 1,000

Signals and Systems
355
Note: Because we are modeling the device by a causal LTI system, y(t) is in fact the
unit-step response of the system. Derivation of H(s) can, therefore, be simpliﬁed by the
following approach:
Input:
x(t) = u(t)
⇒
X(s) = 1
s
Output:
y(t) = (1 −e−1,000t)u(t)
⇒
Y(s) =
1,000
s(s + 1,000)
System function:
H(s) = Y(s)
X(s)
⇒
H(s) =
1,000
s + 1,000
This is a consequence of H(s) being the ratio of the transform of the output to that of
the input.
H(s) Is the Laplace Transform of h(t)
The system function is the Laplace transform of the unit-impulse response. This is a
consequence of H(s) being the ratio of the transform of the output to that of the input. The
Laplace transform of a unit impulse is 1 which makes H(s) the Laplace transform of h(t).
Example
6.41
Find the system function of the LTI system with the unit-impulse response h(t) =
e−atu(t).
Solution
From the table of Laplace transform pairs we ﬁnd
H(s) =
1
s + a , RE[s] > −a
Example
6.42
Find the system function of a ﬁnite integrator with unity gain and duration T seconds.
h(t) =

1,
0 ≤t ≤T
0,
elsewhere
Solution
H(s) =
 T
0
e−stdt = 1 −e−sT
s
, all s
Example
6.43
Find H(s) of the system with the unit-impulse response h(t) =
√
2e−t cos(t +
45◦)u(t).

356
CHAPTER 6
The Laplace Transform and Its Applications
Solution
From the table of Laplace transform pairs we ﬁnd
e−at cos(ωt + θ)u(t)
⇒
(s + a) cos θ −ω sin θ
(s + a)2 + ω2
RE[s] > −a
h(t) =
√
2e−t cos(t + 45◦)u(t)
⇒
H(s) =
s
s2 + 2s + 2
RE[s] > −1
6.26
Comprehensive Examples
This section presents two examples for ﬁnding the responses of LTI systems by the time
and transform-domain methods, and observes parallels between them.
Example
6.44
ConsidertheLTIsystemspeciﬁedbytheunit-impulseresponseh(t) = 5e−t sin(t)u(t).
Find the system’s response to x(t) = etu(−t) by the following three methods:
1.
Bilateral Laplace transform method.
2.
Convolution of x(t) with h(t).
3.
Time-domain solution of the differential equation.
Method 1. Laplace Transform
Multiply the bilateral Laplace transforms of x(t) and h(t) with each other, then take
the inverse transform of the result to obtain y(t).
x(t) = etu(−t)
X(s) =
−1
s −1,
RE[s] < 1
h(t) = 5e−t sin tu(t)
H(s) =
5
s2 + 2s + 2,
RE[s] > −1
Y(s) = X(s)H(s) =
−5
(s −1)(s2 + 2s + 2) =
−1
s −1 +
s + 3
s2 + 2s + 2,
−1 < RE[s] < 1
y(t) = etu(−t) + e−t(cos t + 2 sin t)u(t)
= etu(−t) +
√
5e−t cos(t −63◦)u(t)
−∞< t < ∞
Method 2. Convolution
y(t) = x(t) ⋆h(t) =
 ∞
−∞
x(t −τ)h(τ)dτ
t ≤0
yℓ(t) =
 ∞
0
e(t−τ) × 5e−τ sin τdτ
= 5et
 ∞
0
e−2τ sin τdτ = et

Signals and Systems
357
Note:
 τ2
τ1
e−2τ sin τdτ = −1
5e−2τ(cos τ + 2 sin τ)

τ2
τ1
t ≥0
yr(t) =
 ∞
0
e(t−τ) × 5e−τ sin τdτ
= 5et
 ∞
t
e−2τ sin τdτ =
√
5e−t cos(t −63◦)
y(t) = yℓ(t) + yr(t) = e−tu(−t) +
√
5e−t cos(t −63◦)u(t) −∞< t < ∞
Method 3. Time-Domain Solution
Solve the system’s input-output differential equation.
d2y
dt2 + 2dy
dt + 2y = 5x
t ≤0
d2yℓ
dt2 + 2dyℓ
dt + 2yℓ= 5et
yℓ(t) =
5
s2 + 2s + 2

s=1et = et particular solution only
t ≥0
d2yr
dt2 +2dyr
dt + 2yr = 0
initial conditions: y(0) = 1, y′(0) = 1
yr(t) =
√
5e−t cos(t −63◦)
homogeneous solution only
y(t) = yℓ(t) + yr(t)
total solution for −∞< t < ∞
= etu(−t) +
√
5e−t cos(t −63◦)u(t)
Example
6.45
Consider the causal LTI system described by the differential equation
d2y
dt2 + 4dy
dt + 5y = 2x
where x(t) is the input and y(t) is the output. Find the system’s response to x(t) =
e−tu(−t) + e−2tu(t) by:
1.
Bilateral Laplace transform.
2.
Convolution of x(t) with h(t).
3.
Time-domain solution of the differential equation.
4.
Superposition of responses to the causal and anticausal inputs,
transform-domain approach.
5.
Superposition of responses to the causal and anticausal inputs, time-domain
approach.

358
CHAPTER 6
The Laplace Transform and Its Applications
Method 1. Laplace Transform
Take the bilateral transform of the two sides of the differential equation.
d2y
dt2 + 4dy
dt + 5y = 2x
s2Y(s) + 4sY(s) + 5Y(s) = 2X(s)
Y(s) =
2
s2 + 4s + 5 X(s)
x(t) = e−tu(−t) + e−2tu(t)
X(s) =
−1
s + 1 +
1
s + 2 =
−1
(s + 1)(s + 2),
−2 < RE[s] < −1
Y(s) =
−2
(s2 + 4s + 5)(s + 1)(s + 2)
−2 < RE[s] < −1
=
−2
(s + 2 + j)(s + 2 −j)(s + 1)(s + 2)
=
k1
s + 2 + j +
k∗
1
s + 2 −j +
k2
s + 1 +
k3
s + 2
k1 =
−2
(s + 2 −j)(s + 1)(s + 2)

s=−2−j =
√
2
2
̸ 135◦
k2 =
−2
(s2 + 4s + 5)(s + 2)

s=−1 = −1
k3 =
−2
(s2 + 4s + 5)(s + 1)

s=−2 = 2
y(t) = e−tu(−t) + 2e−2tu(t) +
√
2e−2t cos(t −135◦)u(t)
−∞< t < ∞
Method 2. Convolution
The unit-impulse response of the differential equation is h(t) = 2e−2t sin tu(t).
y(t) = x(t) ⋆h(t) =
 ∞
−∞
x(t −τ)h(τ)dτ
t ≤0
yℓ(t) = 2
 ∞
0
e(t−τ) × e−2τ sin τdτ = 2e−t
 ∞
0
e−τ sin τdτ = et

Signals and Systems
359
Note:
 τ2
τ1
e−τ sin τdτ = −1
2e−τ(cos τ + sin τ)

τ2
τ1
t ≥0
yr(t) = 2
 ∞
t
e−(t−τ) × e−2τ sin τdτ + 2
 t
0
e−2(t−τ) × e−2τ sin τdτ
= 2e−t −
 ∞
t
e−τ sin τdτ + 2e−2t
 t
0
sin τdτ
= e−2t(cos t + sin t) + 2e−2t(1 −cos t)
= 2e−2t +
√
2e−2t cos(t −135◦)
y(t) = yℓ(t) + yr(t)
= e−tu(−t) + 2e−2tu(t) +
√
2e−2t cos(t −135◦)u(t)
−∞<t<∞
Method 3. Time-Domain Solution
Solve the differential equation for t < 0 and t > 0 separately.
t ≤0
d2yℓ
dt2 + 4dyℓ
dt + 5yℓ= 2e−t
yℓ(t) = yℓp(t) =
2
s2 + 4s + 5

s=−1e−t = e−t
total solution for t ≤0
t ≥0
d2yr
dt2 + 4dyr
dt + 5yr = 2e−2t
boundary conditions:
y(0) = 1, y′(0) = −1
yrp(t) =
2
s2 + 4s + 5

s=−2e−2t = 2e−2t
particular solution
yrh(t) = Ae−2t cos(t + θ)
homogeneous solution,
=
√
2e−2t cos(t −135◦)
apply boundary conditions
yr(t) = yrp(t) + yrh(t)
total solution for t ≥0
= 2e−2t +
√
2e−2t cos(t −135◦)
y(t) = yℓ(t) + yr(t)
= e−tu(−t) + 2e−2tu(t) +
√
2e−2t cos(t −135◦)u(t)
(total solution for −∞< t < ∞)

360
CHAPTER 6
The Laplace Transform and Its Applications
Method 4. Superposition in the Transform Domain
Use the transform method to ﬁnd the system’s response to the causal and anticausal
components of the input separately. Then add them together.
x(t) = x1(t) + x2(t)
x1(t) = e−tu(−t)
X1(s) =
−1
s + 1,
RE[s] < −1
Y1(s) =
2
s2 + 4s + 5 X1(s) =
−2
(s2 + 4s + 5)(s + 1)
−2 < RE[s] > −2
=
−1
s + 1 +
s + 3
s2 + 4s + 5
y1(t) = e−tu(−t) +
√
2e−2t cos(t −45◦)u(t)
−∞< t < ∞
x2(t) = e−2tu(t)
X2(s) =
1
s + 2,
RE[s] > −2
Y2(s) =
2
s2 + 4s + 5 X2(s) =
2
(s2 + 4s + 5)(s + 2)
−2 < RE[s] < −1
=
2
s + 2 −2
s + 2
s2 + 4s + 5
y2(t) = 2e−2tu(t) −2e−2t cos(t)u(t)
−∞< t < ∞
y(t) = y1(t) + y2(t)
= e−tu(−t) +
√
2e−2t cos(t −45◦)u(t)
+2e−2tu(t) −2e−2t cos(t)u(t)
= e−tu(−t) + 2e−2tu(t) +
√
2e−2t cos(t −135◦)u(t)
−∞< t < ∞
Method 5. Superposition in the Time Domain
Use the time-domain approach to ﬁnd the system’s response to the causal and anti-
causal components of the input separately. Then add them together.
x(t) = x1(t) + x2(t)
x1(t) = e−tu(−t)
y1(t) = y1p(t) + y1h(t)
particular plus homogeneous responses to x1(t)
= e−tu(−t) +
√
2e−2t cos(t −45◦)u(t)
−∞< t < ∞
x2(t) = e−2tu(t)
y2(t) = y2p(t) + y2h(t)
particular plus homogeneous responses to x2(t)
= 2e−2tu(t) −2e−2t cos(t)u(t)
−∞< t < ∞
y(t) = y1(t) + y2(t)
total response to x(t)
= e−tu(−t) + 2e−2tu(t) +
√
2e−2t cos(t −135◦)u(t)
−∞< t < ∞

Signals and Systems
361
6.27
Concluding Remarks
The Laplace transform is a powerful tool for the analysis and synthesis of LTI systems.
It converts a set of integro-differential equations into algebraic equations and, in this
capability, is used to solve differential equations. This chapter started with the historical
developments of the unilateral Laplace transform and its use in solving differential
equations with given initial conditions. The discussion was kept at the basic level of
solving linear differential equations with constant coefﬁcients with one input and one
output. Even within the framework of the unilateral transform, one needs to include
singularity functions such as the unit-impulse function, especially those occurring at
t = 0. Although most of the chapter discussed the unilateral transform, it did so in a
way that its extension to the bilateral form does not present a rift but rather a way to
overcome limitations in the power of the unilateral transform and clarify some apparent
ambiguities in its application.
The importance of the Laplace transform in system analysis and design, however,
is in its ability to decribe the behavior of an LTI system in the frequency domain. The
vehicle for this task is the system function, which was introduced brieﬂy in this chapter.
The frequency domain analysis of LTI systems is the subject of Chapter 9.
6.28
Problems
Solved Problems
1. Find the Laplace transform of the functions given below. Specify the region of convergence.
a.
e3tu(t)
⇒
1
s −3,
σ > 3
b.
√
2 cos(3t + 45◦)u(t)
⇒
s −3
s2 + 9
σ > 0
c.
e−3t sin(3t)u(t)
⇒
3
(s + 3)2 + 9
σ > 0
d.
1
b −a

e−at −e−bt
u(t)
⇒
1
b −a
	
1
s + a −
1
s + b

=
1
(s + a)(s + b)
σ > −min(a, b)
2. Find the inverse Laplace transform of
X(s) = s + 2
s2 + 1, σ > 0
by the following two expansion methods and compare results:
(a) X(s) =
A
s + j +
A∗
s −j
(b) X(s) =
s
s2 + 1 +
2
s2 + 1

362
CHAPTER 6
The Laplace Transform and Its Applications
Solution
a. X(s) =
A
s + j +
A∗
s −j , A = 1
2 + j = 1.118̸ 63◦, x(t) = 2.236 cos(t −63◦), t > 0
b. X(s) =
s
s2 + 1 +
2
s2 + 1, x(t) = cos t + 2 sin t = 2.236 cos(t −63◦), t > 0
3. Find the inverse Laplace transform of X(s) = 1/(s + 2)(s + 1)2, σ > −1.
Solution
X(s) =
1
(s + 2)(s + 1)2 =
k1
s + 2 +
k2
(s + 1)2 +
k3
s + 1
k1 = X(s)(s + 2)

s=−2 =
1
(s + 1)2

s=−2 = 1
k2 = X(s)(s + 1)2
s=−1 =
1
s + 2

s=−1 = 1
k3 = d
ds

X(s)(s + 1)2
s=−1 = d
ds
	
1
s + 2

s=−1
= −
1
(s + 2)2 = −1
Check:
1
s + 2 +
1
(s + 1)2 −
1
s + 1 =
1
(s + 2)(s + 1)2
x(t) = e−2t + te−t −e−t = e−2t + (t −1)e−t, t > 0
4. Find the inverse of the Laplace transforms given below. Time functions are causal.
a. X1(s) = s + 3
s2 + 9 =
s
s2 + 9 +
3
s2 + 9 ⇒x1(t) = [cos(3t) + sin(3t)] u(t) =
√
2 cos

3t −π
4

u(t)
b. X2(s) =
1
(s −1)2 = −d
ds
	
1
s −1

⇒x2(t) = tetu(t)
5. Find the inverse Laplace transforms of
X(s) =
3
s2 + 6s + 18 =
3
(s + 3)2 + 9
for each of the following ROCs: (a) σ < −3, (b) σ > −3.
a. Let
X1(s) =
3
s2 + 9,
σ < −3
⇒
x1(t) = −sin(3t)u(−t)
Then
X(s) =
3
(s + 3)2 + 9 = X1(s + 3),
σ < −3
⇒
x(t) = e−3tx1(t) = −e−3t sin(3t)u(−t)
b. Let
X1(s) =
3
s2 + 9,
σ > −3
⇒
x1(t) = sin(3t)u(t)
Then
X(s) =
3
(s + 3)2 + 9 = X1(s + 3),
σ > −3
⇒
x(t) = e−3tx1(t) = e−3t sin(3t)u(t)

Signals and Systems
363
Alternate Solution
a.
σ < −3, X(s) =
3
(s + 3)2 + 9 =
k1
s + 3 + 3 j +
k∗
1
s + 3 −3 j
k1 = X(s)(s + 3 + 3 j)

s=−3−3 j =
3
s + 3 −3 j

s=−3−3 j = j
2
x(t) =
	
−j
2 e(−3−3 j)t + j
2 e(−3+3 j)t

= −e−3t
	
e j3t −e−j3t
2 j

u(−t) = −e−3t sin(3t)u(−t)
b.
σ > −3, X(s) =
3
(s + 3)2 + 9 =
k1
s + 3 + 3 j +
k∗
1
s + 3 −3 j ,
k1 = X(s)(s + 3 + 3 j)

s=−3−3 j =
3
s + 3 −3 j

s=−3−3 j = j
2
x(t) =
	
j
2 e(−3−3 j)t −j
2 e(−3+3 j)t

= e−3t
	
e j3t −e−j3t
2 j

u(t) = e−3t sin(3t)u(t)
6. Find the inverse Laplace transform of
X(s) =
2s + 7
s2 + 7s + 12 =
1
s + 3 +
1
s + 4
for each of the following ROCs: (a) σ < −4, (b) −4 < σ < −3, (c) σ > −3.
a. σ < −4
x(t) = −
e−3t + e−4t
u(−t)
b. −4 < σ < −3
x(t) = −e−3tu(−t) + e−4tu(t)
c. σ > −3
x(t) = x(t) = 
e−3t + e−4t
u(t)
7. The input to an LTI system is x(t) = (sin 2t)u(t). Use the Laplace transform to ﬁnd the output y(t) and its
steady-state part for (a) h(t) = e−tu(t), (b) h(t) = (sin t)u(t).
Solution
x(t) = (sin 2t)u(t)
X(s) =
2
s2 + 4, σ > 0
a. h(t) = e−tu(t)
H(s) =
1
s + 1, σ > −1
Y(s) = X(s) × H(s) =
2
(s2 + 4)(s + 1) =
0.4
s + 1 −0.4 s −1
s2 + 4, σ > 0
y(t) =
	
2
5e−t −0.4 cos(2t) + 0.2 sin(2t)

u(t)
=
	
2
5e−t −
√
5
5 cos(2t + 26.6◦)

u(t) =
	
2
5e−t +
√
5
5 sin(2t −63.4◦)

u(t)
b. h(t) = (sin t)u(t)
H(s) =
1
s2 + 1, σ > 0
Y(s) = X(s) × H(s) =
2
(s2 + 4)(s2 + 1), σ > 0
= As + B
s2 + 4 + Cs + D
s2 + 1 = (A + C)s3 + (B + D)s2 + (A + 4C)s + B + 4D
(s2 + 4)(s2 + 1)
,

364
CHAPTER 6
The Laplace Transform and Its Applications
A = C = 0, D = −B = 2
3
Y(s) = −2
3
1
s2 + 4 + 2
3
1
s2 + 1,
y(t) =
	
2
3 sin(t) −1
3 sin(2t)

u(t)
8. The unit-impulse response of an LTI system is h(t) = e−t sin 2t u(t). Use the Laplace transform to ﬁnd its response
to (a) x(t) = (sin t)u(t), (b) x(t) = sin t.
Solution
h(t) = e−t(sin 2t)u(t),
H(s) =
2
(s + 1)2 + 4, σ > −1
a. x(t) = (sin t)u(t),
X(s) =
1
s2 + 1, σ > 0
Y(s) = H(s) × X(s) =
2
(s2 + 2s + 5)(s2 + 1), σ > 0
=
As + B
(s + 1)2 + 4 + Cs + D
s2 + 1
= (A + C)s3 + (B + 2C + D)s2 + (A + 5C + 2D)s + B + 5D
(s2 + 2s + 5)(s2 + 1)
,
A = −C = 0.2, B = 0, D = 0.4
Y(s) =
0.2s
(s + 1)2 + 4 + −0.2s + 0.4
s2 + 1
= 0.2
s + 1
(s + 1)2 + 4 −0.1
2
(s + 1)2 + 4 −0.2
s
s2 + 1 + 0.4
1
s2 + 1
y(t) = 
0.1e−t (2 cos 2t −sin t) + 0.4 sin t −0.2 cos t
u(t)
b. x(t) = sin t,
y(t) = yss(t) = [0.4 sin t −0.2 cos t] = 0.447 sin(t −26.6◦), at t >> 0.
9. The unit-impulse response of an LTI system is h(t) = e−t sin 2t u(t). Use the Laplace transform to ﬁnd its response
to x(t) = sin t.
Solution
h(t) = e−t(sin 2t)u(t),
H(s)
=
2
(s + 1)2 + 4, σ > −1
x(t) = sin t,
X(s)
= δ(s −j) −δ(s + j)
2 j
Y(s)
= H(s) × X(s) = H(s)|s= j δ(s −j) −H(s)|s=−j δ(s + j)
2 j
H(s)|s= j =
1
2 + j = 0.447 e−j 26.6◦
H(s)|s=−j =
1
2 −j = 0.447 e j 26.6◦
Y(s)
= 0.447 e−j 26.6◦δ(s −j) −e j 26.6◦δ(s + j)
2 j
y(t)
= 0.447 sin(t −26.6◦)

Signals and Systems
365
An Alternative Approach
Use the frequency response.
H(ω) =
2
5 −ω2 + j 2ω
H(ω)

ω=1 =
2
5 −1 + j 2 =
1
2 + j = 0.447 e−j 26.6◦
x(t) = sin t
y(t) = 0.447 sin(t −26.6◦)
10. Use the Laplace transform to ﬁnd Y(s) and y(t), t > 0 when
d2y
dt2 + 10dy
dt + 9y = 9, t ≥0
Initial conditions are y(0) = 1 and y′(0) = 0. Identify the zero-state and zero-input responses.
Solution
L[y(t)] = Y(s)
L
	
dy
dt

= sY(s) −y(0) = sY(s) −1
L
	
d2y
dt2

= s2Y(s) −y(0)s −y′(0) = s2Y(s) −s
L
	
d2y
dt2 + 10dy
dt + 9y

= s2Y(s) −s + 10[sY(s) −1] + 9Y(s)
= (s2 + 10s + 9)Y(s) −(s + 10) = L[9] = 9
s
Y(s) =
9
s(s2 + 10s + 9) +
s + 10
s2 + 10s + 9
↑
↑
Zero-state response
+ Zero-input response
Y(s) = 1
s −
s + 10
s2 + 10s + 9 +
s + 10
s2 + 10s + 9 = 1
s , y(t) = 1, t > 0
11. Use the Laplace transform to ﬁnd Y(s) and y(t), t > 0 given
d2y
dt2 + 2dy
dt + y = x(t) −dx
dt , y(0) = 1, y′(0) = −1, and x(t) = e−3t −e−2t, t ≥0
Solution

s2Y(s) −sy(0) −y′(0)
+ 2 [sY(s) −y(0)] + Y(s) = X(s) −[sX(s) −x(0)] , x(0) = 1 −1 = 0
Y(s)(s + 1)2 −(s + 1) = X(s)(1 −s) = (1 −s)
	
1
s + 3 −
1
s + 2

Y(s)(s + 1)2 = (s + 1) +
s −1
(s + 3)(s + 2) = s3 + 6s2 + 12s + 5
(s + 3)(s + 2)
Y(s) =
s3 + 6s2 + 12s + 5
(s + 3)(s + 2)(s + 1)2 =
1
s + 3 −
3
s + 2 + As + B
(s + 1)2
A = d
ds

Y(s)(s + 1)2
s=−1 = 3,

366
CHAPTER 6
The Laplace Transform and Its Applications
(As + B)

s=−1 = 
Y(s)(s + 1)2
s=−1, B = 2
Y(s) =
1
s + 3 −
3
s + 2 + 3s + 2
(s + 1)2 =
1
s + 3 −
3
s + 2 +
3
s + 1 −
1
(s + 1)2
y(t) = e−3t −3e−2t + (3 −t)e−t, t ≥0
12.
a. Let H(s) be the Laplace transform of an LTI system and Yss(s) the Laplace transform of the steady-state
component of its response to a sinusoidal input x(t) = sin(ωt)u(t). Find Yss(s) and show that yss(t) = A sin(ωt+
θ), where B = |H(ω)| and θ = ̸ H(ω).
b. Apply to H(s) = (s + 2)/(s2 + 4s + 6) and x(t) = 10 sin(5t + 36◦)u(t) to ﬁnd yss(t).
Solution
a.
Y(s) = H(s)X(s) = H(s)
ω
s2 + ω2 =
A
s −jω +
A∗
s + jω + · · · ,
where
A = H(s)
ω
s + jω

s= jω = H(ω)
2 j
= |H(ω)|e jθ
2 j
and A∗= −|H(ω)|e−jθ
2 j
Yss(s) = |H(ω)|
2 j
	
e jθ
s −jω −
e−jθ
s + jω

yss(t) = |H(ω)|e j(ωt+θ) −e j(ωt+θ)
2 j
= |H(ω)| sin(ωt + θ)
b. H(s)

s= j5 = 0.195̸ −65◦, yss(t) = 1.95 sin(5t + 36◦−65◦) = 1.95 sin(5t −29◦)
Chapter Problems
I. Laplace Transform
(Problems 13–17)
13. Find the Laplace transform of the time functions given below.
a. tu(t)
b. e−3tu(t)
c.
√
2 cos(2t + 45◦)u(t)
d. 2−tu(t)
e. e3t sin(2t)u(t)
f.
√
2e−3t cos(2t + 45◦)u(t)
g. teatu(t)
h. t sin(at)u(t)
i. t cos(at)u(t)
14. Find the Laplace transform of each of the time functions below. Specify the region of convergence. Assume a and
ω are positive quantities.
a. u(t) −u(t −1)
b. e−atu(t −1)
c. [1 −e−at]u(t)
d. eat cos(ωt)u(t)
e. eat cos(ωt + θ)u(t)
f. eat sin(ωt + θ)u(t)
g. teat cos(ωt)u(t)
h.
1
b−a

e−at −e−bt
u(t)
15. Find the Laplace transform of
a. x(t) =

t,
0 ≤t < 1
0,
elsewhere
b. x(t) =
 1 + t,
−1 ≤t < 0
1 −t,
0 ≤t < 1
0,
elsewhere

Signals and Systems
367
16. Find the Laplace transform of each of the time functions below. Specify the region of convergence. Assume a and
ω are positive quantities.
a. u(−t) −u(−t −1)
b. eatu(−t + 1)
c. [1 −eat]u(−t)
d. eat sin(ωt)u(−t)
e. e−|at|, all t
f. e−|at| cos ωt, all t
g. e−|at| sin ωt, all t
h. e−|at| sin(ωt + θ), all t
17. A transformation from the time domain to another domain (called p-domain) is known to be linear. Given the
transform pair
e−at sin bt ⇐⇒
b
(p + a)2 + b2
If the above information about the transformation is sufﬁcient, ﬁnd the inverse transform of
a.
2
p2 + p + 0.5
b.
p + 1
p2 + 2p + 12
If it is not, determine what additional information is needed.
II. Inverse Laplace Transform
(Problems 18–26; note that σ = RE[s])
18. Find the inverse Laplace transform of
X(s) =
s + 2
s2 + 2s + 2, σ > −1
by the following two expansion methods and compare results:
a. X(s) =
A
s + 1 −j +
A∗
s + 1 + j
b. X(s) =
s + 1
(s + 1)2 + 1 +
1
(s + 1)2 + 1
19. Find the inverse of the Laplace transforms given below. All time functions are causal.
a.
e−s
s + 1
b.
s + 3
s2 + 9
c. 1 −e−πs/3
s2 + 9
d. 2e−3s
s −1
e. 2
s2
f.
−3
s + 3
g.
1
(s + 1)2
h.
s
(s + 1)2
i.
1
(s −1)2
20. Repeat problem 19 assuming the time functions to be anticausal.
21. Find the inverse transforms of the functions given below.
a. 1
s , σ > 0
b. e−(s+1)
s + a , σ > −a
c.
a
s(s + a), σ > 0
d.
s −a
(s −a)2 + ω2 , σ > −a
e.
(s + a)2 −ω2
[(s + a)2 + ω2]2 , σ > −a
f.
1
(s + a)(s + b), σ > −min(a, b)
22. Find the inverse Laplace transform of
a. X(s) =
5s2 + 3s + 1
(s2 + 4)(s + 1), σ > 0
b. X(s) =
5s2 + 3s + 1
(s2 + 4)(s + 1)2 , σ > 0

368
CHAPTER 6
The Laplace Transform and Its Applications
23. Find the inverse Laplace transform of
X(s) =
1
(s + 1)2(s + 2), σ > −1
24. Find the inverse Laplace transforms of
a. X(s) =
3
s2 + 6s + 18
b. X(s) =
3
s2 + 6s + 9
For each of the following ROCs:
(i) σ < −3
(ii) σ > −3
25. Find the inverse Laplace transforms of
a. X(s) =
2s + 7
s2 + 7s + 12,
b. X(s) =
1
(s + 4)(s2 + 6s + 18), and
c. X(s) =
1
(s + 3)(s2 + 8s + 25)
if
(i) σ < −4,
(ii) −4 < σ < −3, and
(iii) σ > −3.
26. Find all the time functions for which
a.
X(s) =
1
(s + 2)(s2 −1)
b. X(s) =
s + 10
(s + 2)(s2 −1)
c. X(s) =
s −10
(s + 2)(s2 −1)
d.
X(s) =
s + 1.9
(s + 2)(s2 −1)
e. X(s) =
s + 0.9
(s + 2)(s2 −1)
f. X(s) =
s2 −0.81
(s + 2)(s2 −1)
III. LTI, Convolution, and the Laplace Transform
(Problems 27–33)
27. The unit-impulse response of an LTI system is h(t) = sin t [u(t) −u(t −2π)].
a. Find H(s).
b. Find the response of the system to x(t) = sin tu(t) by (i) using the Laplace transform method and (ii) using the
convolution integral.
28. Find y(t) = x(t) ⋆h(t) for the following cases:
a. x(t) = (sin t)u(t) and h(t) = e−0.1t sin 2tu(t)
b. x(t) =
n=∞

n=0
δ(t −n) and h(t) =

sin πt,
0 < t < 1
0,
elsewhere
c. x(t) = u(t) and h(t) = e−αtu(t)
d. x(t) = tu(t) and h(t) = e−αtu(t)
e. x(t) =

1
T ,
0 < t < T
0,
elsewhere and h(t) = e−αtu(t)
29. Let x(t) =
1
T [u(t) −u(t −T )] and h(t) be a well-behaved function. Find Y(s) = X(s)H(s). Then, show that
limT →0 [Y(s)] = H(s) and conclude that limT →0 [x(t) ⋆h(t)] = h(t).
30. Find y(t) = x(t) ⋆h(t) for the following three cases:
a. x(t) = (sin t)u(t)
and
h(t) = e−αt(sin t)u(t) for α = 0.1, 1, 10
b. x(t) = (cos t)u(t)
and
h(t) = (cos 2t)u(t)
c. x(t) = (cos t)u(t)
and
h(t) = (cos 1.1t)u(t)

Signals and Systems
369
31. The input to an LTI system is x(t) = sin 2tu(t). Find the output y(t) and the steady-state part for
a. h(t) = e−tu(t)
b. h(t) = sin tu(t)
32. The unit-impulse response of an LTI system is h(t) = δ(t −2) + 2u(t) and its input is x(t) = cos tu(t).
a. Find Y(s) = X(s)H(s) and its inverse. Identify the amplitude and phase of the output.
b. Find y(t) by direct evaluation of the convolution integral y(t) = x(t) ⋆h(t).
33. The impulse response of an LTI system is h(t) = e−3tu(t). Find Y(s) = X(s)H(s) and y(t) for the following
inputs:
a. x(t) = [sin(2t) + cos(2t)]u(t)
b. x(t) = [sin(2t) + cos(3t)]u(t)
IV. Differential Equations and the Laplace Transform
(Problems 34–48)
34. Given
dy
dt + 3y = x(t) and x(t) = e−2t, t ≥0
ﬁnd Y(s) and y(t), t ≥0, for a) y(0) = 1, b) y(0) = 0, c) y(0) = −1, d) y(0) = y0.
35. Given
d2y
dt2 + 2dy
dt + y = x(t) −dx
dt , y(0) = 1, y′(0) = 2, and x(t) = e−3t −e−2t, t ≥0
ﬁnd Y(s) and y(t), t ≥0.
36. a. An LTI system is given by
y′(t) + ay(t) = x(t)
Let h(t) be the system’s unit-impulse response. Show that the convolution integral

∞
−∞
x(τ)h(t −τ)dτ
satisﬁes the differential equation.
b. Repeat for an LTI system described by an nth-order differential equation.
37. Find Y(s) and y(t), the solutions to each of the following differential equations:
a. d2y
dt2 + 2dy
dt + y = x(t) −dx
dt , t > 0, with y(0+) = 1, dy
dt (0+) = 0, and x(t) = e−3t −e−2t, t > 0
b. d2y
dt2 + 200dy
dt + 108y = 200dx
dt , t > 0, with y(0+) = 0, dy
dt (0+) = 200, and x(t) = −1, t > 0
38. Find Y(s) and y(t), the solutions to each of the following differential equations:
a. d2y
dt2 + 200dy
dt + 108y = 5x(t) + 100dx
dt , where x(t) = 2u(t)
b. d2y
dt2 + 650dy
dt + 30000y = 104
	
3x(t) + dx
dt

, where x(t) = (sin 100t)u(t)

370
CHAPTER 6
The Laplace Transform and Its Applications
c. d2y
dt2 + dy
dt = x(t) + 2dx
dt , where x(t) = e−2tu(t)
d. d2y
dt2 + 3dy
dt + 2y = −dx
dt , where x(t) = (sin 3t)u(t)
39. Find Y(s) and y(t), the solutions to each of the following differential equations:
a. d2y
dt2 + 10dy
dt + 9y = 0, t > 0, with y(0) = 1, dy
dt (0) = 0
b. dy
dt + y = 5(sin 2t)u(t)
c. d2y
dt2 + 10dy
dt + 9y = 9, t > 0, with y(0) = 1, dy
dt (0) = 0
d. dy
dt + 2y = tu(t)
e. dy
dt + y = 2(sin t)u(t)
f. dy
dt + 2y = te−tu(t)
40. Use the Laplace transform to ﬁnd Y(s) and y(t) given
d2y
dt2 + 10dy
dt + 9y = 9, t ≥0, y(0) = 0, y′(0) = 0
41. In the circuit of Figure 6.8, R = 1 ,
L =
√
2 H, and C =
√
2 F. Given vC(0) = 1 V and iL(0) = 1 A, ﬁnd
vC(t) and iL(t) for t ≥0 if the applied voltage source for t ≥0 is
a. v(t) = 1
b. v(t) = 2
R
R
+
+
–
–
v(t)
vC
iL
L
C
FIGURE 6.8 (For Problem 41)
42. A rectangular voltage source (0 to 1/T V, T msec long) charges a capacitor C through a resistor R. See Figure 6.9.
a. Find i(t) and vC(t) by solving circuit equations in the time domain. Find their limits as T →0.
b. Find i(t) and vC(t) by the Laplace transform method and ﬁnd their limits as T →0.
c. Let the voltage source be a unit impulse. Find i(t) and vC(t) and compare with results of parts (a) and (b).
v(t)
i
1
T
T
t
R
+
+
–
–
v(t)
vC
C
FIGURE 6.9 (For Problem 42)

Signals and Systems
371
43. In a parallel RLC circuit (with R = 1/3 , L = 1/2 H, and C = 1 µF), iL(0) = 1 and vC(0) = 1. For t ≥0 the
circuit is fed by a 1-A parallel current source. Find iL(t) and vC(t) for t ≥0 by using the Laplace transform method.
44. In the circuit of Figure 6.10, R = 1 k, L = 1 mH, and C = 1 µF. The initial conditions are i2(0+) = −i1(0+) =
1 m A, and vC(0+) = 1 V . Find i1(t), i2(t), and vC(t) for t ≥0 by using the Laplace transform method, given
a. v(t) = 1 V, t > 0
b. v(t) = 2 V, t > 0
R
L
R
+
+
–
–
v(t)
vC
i1(t)
L
i2(t)
C
FIGURE 6.10 (For Problem 44)
45. In the circuit of Figure 6.11, R1 = 1/3 , R2 = 10 m, L = 1/2 H, C = 1 µF, i(0+) = 1 A, and v(0+) = 1 V.
Find i(t) and v(t) for t ≥0 by using the following steps:
a. Formulate time-domain differential equations for i and v using (i) circuit laws, (ii) impedances (s-operator).
b. Solve the differential equations using (i) time-domain approach, (ii) the Laplace transform approach.
c. Formulate state equations and solve for i and v.
+
–
R1
R2
L
v
C
i
FIGURE 6.11 (For Problem 45)
46. In the circuit of Figure 6.12, R = 1 , L = 1 H, C = 2 F and

v(t) = 1,
t ≥0
i(t) = e−t,
t ≥0 with initial conditions

vC(0) = 1 V
iL(0) = 1 A
Find iL(t) and vC(t) for t > 0.
R
L
+
+
–
–
vC
C
iL
v(t)
i(t)
FIGURE 6.12 (For Problem 46)

372
CHAPTER 6
The Laplace Transform and Its Applications
47. The circuit of Figure 6.13 (R = 5 , L = 0.1 H, and C = 20 µF) with zero energy is connected to a DC voltage
source (V = 10 volts) at t = 0. Find the currents i1 and i2 for t ≥0.
C
L
R
R
10 V
t = 0
i1(t)
i2(t)
+–
FIGURE 6.13 (For Problem 47)
48. A series RLC circuit (R = 5 , L = 1 H, and C = 500 µF) with zero energy is connected to a DC voltage source
(V = 10 volts) at t = 0. Find the current for t ≥0.
49. The switch in the circuit of Figure 6.14 closes at t = 0. Using the Laplace transform method ﬁnd steady states vc(t)
and i(t) for
a. v(t) = sin 2π f0t,
f0 = 159 Hz.
b. v(t), a periodic square pulse (50% duty cycle) which switches from 0 to 1 volt every 1/159 sec.
t = 0
+
–
C
R
vC (t)
i(t)
+–
v(t)
FIGURE 6.14 (For Problem 49)
50. In the circuit of Figure 6.15, R1 = 3 k, R2 = 2 k, L = 1 H, and C = 1 µF. Find v(t) and i(t) for
a. ig = 10 cos 1,000t mA, all t
b. ig =

10 mA,
t < 0
10 cos 1,000t mA,
t ≥0
+
–
L
R1
R2
v
C
i
ig
FIGURE 6.15 (For Problem 50)
V. System Function
(Problems 51–57)
51. In the circuit of Figure 6.16, R = 1 k, L = 1 H, and C = 1,000 µF.
L
C
+
–
v2
+
–
v1
–+–
R
FIGURE 6.16 (For Problem 51)
Verify that the system function is H(s) = V2
V1
=
s
s2 + s + 1,000.

Signals and Systems
373
52. In the series RLC circuit of Figure 6.17, vs(t) is the input and element voltages v1(t), v2(t), and v3(t) (across R, L,
and C, respectively,) are the outputs.
a. Verify the three differential equations and system functions given below. Observe that the system functions have
the same set of poles and relate that property to the natural response of the circuit.
Resistor:
dv2
1
dt2 + R
L
dv1
dt +
1
LC v1 = R
L
dvs
dt ,
H1(s) = V1
Vs =
R
L s
s2+ R
L s+ 1
LC =
1
Q

s
ω0


s
ω0
2
+ 1
Q

s
ω0

+1
Inductor:
dv2
2
dt2 + R
L
dv2
dt +
1
LC v2 = d2vs
dt2 ,
H2(s) = V2
Vs =
s2
s2+ R
L s+ 1
LC =

s
ω0
2

s
ω0
2
+ 1
Q

s
ω0

+1
Capacitor:
dv2
3
dt2 + R
L
dv3
dt +
1
LC v3 =
1
LC vs,
H3(s) = V3
Vs =
1
LC
s2+ R
L s+ 1
LC =
1

s
ω0
2
+ 1
Q

s
ω0

+1
where ω0 =
1
√
LC
and Q = Lω0
R
b. For each of the following three cases obtain the location of poles and zeros of H1(s), H2(s), and H3(s) and ﬁnd
their step and impulse responses:
(i) R > 2

L
C ,
(ii) R = 2

L
C ,
(iii) R < 2

L
C
+
–
+
–
v3
vs
v1
+
–
v2
i
+–
FIGURE 6.17 (For Problem 52)
53. In the series RLC circuit of Figure 6.18 connect a current source is(t) in parallel with an element and consider it to
be the input (three possible inputs). Let an element’s current or voltage be the output (six possible outputs), for a
total of 18 input-output pairs each represented by a system function. Discuss the common features of the collection
of system functions and interpret them in terms of the circuit’s natural response. Relate your observations to the
results of problem 52.
+
–
v3
+
–
v1
+
–
v2
is
FIGURE 6.18 (For Problem 53)
54. In the parallel RLC circuit of Figure 6.19, is(t) is the input and the elements’ currents i1(t), i2(t), and i3(t) (in the
resistor, inductor, and the capacitor, respectively) are the outputs.

374
CHAPTER 6
The Laplace Transform and Its Applications
a. Verify the three differential equations and system functions given below. Observe that the system functions have
the same set of poles and relate that property to the natural response of the circuit.
Resistor:
di 2
1
dt2 +
1
RC
di1
dt +
1
LC i1 =
1
RC
dis
dt ,
H1(s) = I1
Is =
1
RC s
s2+ 1
RC s+ 1
LC =
1
Q

s
ω0


s
ω0
2
+ 1
Q

s
ω0

+1
Inductor:
di 2
2
dt2 +
1
RC
di2
dt +
1
LC i2 =
1
LC is,
H2(s) = I2
Is =
1
LC
s2+ 1
RC s+ 1
LC =
1

s
ω0
2
+ 1
Q

s
ω0

+1
Capacitor:
di 2
3
dt2 +
1
RC
di3
dt +
1
LC i3 = d2is
dt2
H3(s) = I3
Is =
s2
s2+ 1
RC s+ 1
LC =

s
ω0
2

s
ω0
2
+ 1
Q

s
ω0

+1
where ω0 =
1
√
LC
and Q = RCω0
b. For each of the following three cases obtain the location of poles and zeros of H1(s), H2(s), and H3(s) and ﬁnd
their step and impulse responses:
(i) R < 1
2

L
C ,
(ii) R = 1
2

L
C ,
(iii) R > 1
2

L
C
is
i1
+
–
v
i2
i3
FIGURE 6.19 (For Problem 54)
55. In a parallel RLC circuit place a voltage source vs(t) in series with an element (as in Figure 6.20) and consider it to
be the input (three possible inputs). Let an element’s current or voltage be the output (six possible outputs), for a
total of 18 input-output pairs each represented by a system function. Discuss the common features of the collection
of system functions and interpret them in terms of the circuit’s natural response. Relate your observations to the
results of problem 54.
i2
i3
i1
vs +–
FIGURE 6.20 (For Problem 55)
56. a. In the circuit of Figure 6.21, R = 50 , L = 1 mH, and C = 10 µF. Find the system function H(s) = V2/V1,
its poles and zeros, and show them on the s-plane.
b. Let v1(t) = 1, t ≥0. Show that regardless of the initial state of the circuit at t = 0, the response at t ≥0 is
v2(t) = V0e−αt cos(ωt + θ) and determine α and ω.
c. Given iL(0−) = v(0) = 0 and v1(t) = 1, t ≥0, ﬁnd V0 and θ in part b.
d. Given v1(t) = 1, t ≥0, specify i(0) and v(0) so that the response becomes zero at t ≥0.

Signals and Systems
375
i
L
C
R
v1
+
–
v2
+
–
+–
FIGURE 6.21 (For Problem 56)
57. The only poles of an LTI system are at −1 ± j. The system has no zeros at ﬁnite values of s. Its steady-state
response to a unit-step input is 5. Find (a) the system function H(s), (b) the system’s unit-impulse response, and
(c) the dominant part of the response to the input e−t/100u(t) at t > 10.
6.29
Project: Pulse-Shaping Circuit
Summary and Objectives
This project is an exercise in using the Laplace transform in circuit analysis. The circuit under study is a passive RC
circuit (made of a cascade of resistors and capacitors). It is shown in Figure 6.22. The input is v1(t) and the output is v2(t).
The goal of the project is to ﬁnd its system function, frequency, and time responses by analytic methods, simulation, and
measurement and relate the results. Simulation may be done by Matlab or Spice. Laboratory measurements may use a
function generator, an oscilloscope, and the circuit of Figure 6.22. Alternatively, the measurements can be made on the
graphs obtained from simulation.
A
B
C
C2
R1
R1
V1
C1
C1
R2
+
–
V2
+
–
–+–
FIGURE 6.22 A two-terminal ladder RC circuit with open terminals. Element values are R1 = 470 , R2 = 4,700 ,
C1 = 10 nF, and C2 = 47 nF.
Analysis
This part of the project has four sections, which are to be done by mathematical analysis. You may simulate the circuit or
use a computation package to obtain the plots.
System Function
In the circuit of Figure 6.22, write KCL at nodes A, B, and C using node voltages V a, V b, and V c
in the s-domain as variables.
Show that three node voltage equations in the s-domain are given in matrix form by


2YR1 + YC1
−YR1
0
−YR1
YR1 + YC1 + YC2
−YC2
0
−YC2
YR2 + YC2




Va
Vb
Vc

= YR1


V 1
0
0

,
where YR = 1
R and YC = Cs

376
CHAPTER 6
The Laplace Transform and Its Applications
To simplify, you may divide both sides of the matrix equation by YR1 and note that YR1 = 1/470, YR2 = 0.1YR1,
YC1 = 10−8s, and YC2 = 4.7YC1. Show that
H(s) = V2
V1
=
R2C2s
R2
1C2
1 R2C2s3 + (R2
1C2
1 + R2
1C1C2 + 3R1C1R2C2)s2 + (3R1C1 + 2R1C2 + R2C2) + 1
=
2.209 × 10−4s
4.879 × 10−15s3 + 3.241 × 10−9s2 + 2.792 × 10−4s + 1
Using Matlab ﬁnd the roots of the characteristic equation and show that
H(s) =
4.5227 × 1010s
(s + 5.633 × 105) (s + 9.719 × 104) (s + 3.743 × 103)
Time Responses
Write the differential equation. Find and plot its response to (i) a unit impulse, (ii) a unit step, and
(iii) a 1-V, 100-µs rectangular voltage pulse. Compute the 10% to 90% rise time, the 90% to 10% fall time, and the drop
in the pulse response.
Frequency Response
Find v2(t) = V2 sin(ωt + θ), the steady-state response to a sinusoidal input v1(t) = sin(ωt)
with a frequency range of 1 Hz to 100 MHz. Plot 20 log V2 (in dB units) and θ (in degrees) versus log ω. You will use
semilog graph paper having eight decades for the given frequency range, and 12 vertical divisions.
Measurement
a. Record the unit-impulse response. Model it by a mathematical expression and compare with the result obtained
in section 1(b).
b. Record the unit-step response. Model it by a mathematical expression and compare with the result obtained in
section 1(b).
c. Record the response to a 100-µs, 1-V pulse. Model it by a mathematical expression and compare with the result
obtained in section 1(b). Verify that the pulse response is a superposition of the responses to two steps.
d. Measure and record the frequency response of the circuit, H(ω) = H(s)|s= jω, for 10 Hz ≤f ≤100 kHz and
plot it. Use log scale for the frequency axis and uniform scale for the magnitude.
Conclusions
a. By qualitative reasoning determine if the system is low pass, high pass, or bandpass.
b. From the poles of the system [obtained from the denominator of H(s)] reason that the system can’t oscillate and
that the recorded step response is in agreement with expectations.
c. Approximate the above system by a ﬁrst-order model containing a single pole. Specify the location of the pole.
Represent the ﬁrst-order approximation by an RC circuit and compare it with Figure 6.22.
d. Summarize your overall conclusions, especially the relationship between the system function, frequency re-
sponse, impulse response, step response, and pulse response.

Chapter7
Fourier Series
Contents
Introduction and Summary
377
7.1
Signal Synthesis
379
7.2
Fourier Series Expansion
383
7.3
The Generalized Fourier Series and Vectorial Representation of Signals
384
7.4
Dirichlet Conditions and Beyond
385
7.5
Trigonometric Fourier Series
386
7.6
Exponential Fourier Series
391
7.7
Properties of Fourier Series
393
7.8
Time Reversal and Shift
394
7.9
Conjugate Symmetry
395
7.10
Waveform Symmetry
396
7.11
Time Averages
397
7.12
Pulses and Impulses
398
7.13
Convergence of the Fourier Series
404
7.14
Finite Sum
405
7.15
Gibbs’ Phenomenon
406
7.16
Extension of Fourier Series to Transforms
408
7.17
Envelope of Fourier Coefﬁcients
410
7.18
Concluding Remarks
411
7.19
Problems
412
7.20
Project: Computer Explorations in Fourier Analysis
423
Introduction and Summary
Linearity is a property that provides for the ability to predict the output of a system to a
new input if the new input can be expressed as a linear combination of functions for which
the outputs are already known. The new output then becomes the linear combination of
the known outputs weighted appropriately. Let the set of the known input-output pairs
in a linear system be called the repertoire set. To be of greatest and most efﬁcient use,
377

378
CHAPTER 7
Fourier Series
the repertoire set should be as small as possible (or its representation be as simple as
possible), while the population of inputs that it can describe be as large as one may
encounter. (The time-invariance property will reduce the complexity of the repertoire
and its description still more.) As we already have seen on several occasions in Chapters
3, 4, and 5, an exponential input est, with s allowed to be a complex number, produces
the exponential output H(s)est. The function est is called a characteristic function (or
an eigenfunction) of the LTI system. The function H(s), therefore, describes the system.
The question now is how large a class of input functions can be represented by est
and how easily this can be done. For a periodic function with period T , the answer to
the question is clear and simple: In the complex plane restrict s to the imaginary axis
jω, leading to the set of exponential functions e jnω0t, where ω0 = 2π/T is called the
fundamental frequency and n is an integer in the range −∞< n < ∞. The description
of a periodic function by the above set of exponentials is called its exponential Fourier
series expansion, or simply its Fourier series. It is shown by
x(t) =
∞

n=−∞
Xne jnω0t
Xn is called the Fourier coefﬁcient and Xne jnω0t is called the nth harmonic of x(t).
The Fourier series representation of functions allows for their analysis in the frequency
domain. It remains to be shown how conveniently the coefﬁcients Xn can be obtained
from x(t) and how the above expansion facilitates the analysis of LTI systems.
This chapter covers material that has practical applications and, as such, places
less emphasis on purely theoretical considerations (e.g., the uniform convergence of
the Fourier series). Throughout the chapter, real-valued signals are assumed, unless
speciﬁed otherwise. The chapter starts with approximating periodic signals, and then
considers signal synthesis by a ﬁnite set of weighted sinusoids and the resulting error.
It then introduces the trigonometric form of the series (useful in dealing with some
problems of interest such as ﬁltering), followed by its exponential form. For the sake
of completeness, the generalized Fourier series and vectorial interpretation are brieﬂy
introduced. However, the exponential form of the Fourier series is used throughout the
rest of the chapter. The properties and applicability of the series are then discussed. The
role and importance of the Fourier series in the frequency domain analysis of signals and
systems is illustrated within the context of real-life problems. Examples and problems are
designed to teach analytical solutions, while bringing to the student’s attention the need
for and advantages of using a computer. Computation engines and simulation software for
Fourier analysis provide more than just powerful tools for deriving analytical solutions.
By removing the constraints imposed by heavy manual calculations, computer programs
enable the user to expand his or her horizons, explore in detail many aspects of Fourier
analysis, and examine these same aspects both quantitatively and qualitatively within an
engineering context. Finally, the chapter uses a traditional route in extending the Fourier
series to the Fourier transform (rather than the reverse). The project proposed at the end
of the chapter is intended as an introduction to the use of computer methods in Fourier
analysis and a practical bridge between the Fourier series and transform.

Signals and Systems
379
7.1
Signal Synthesis
With regard to the representation of periodic signals by the Fourier series, several ques-
tions come to mind. For example: (1) Does the inﬁnite sum converge to the value of x(t)
for all instances of times? (2) How is the instantaneous error [deﬁned by the square of
the difference between x(t) and its series expansion at any instance of time] distributed
over time? (3) Can a ﬁnite sum of weighted exponentials approximate x(t) in order to
meet a desired average error taken over one period? If so, what is the optimum set of
coefﬁcients? To provide some insight into the above questions we start with two exam-
ples on synthesizing a signal so that a periodic function may be approximated by a ﬁnite
sum. In this formulation we desire to approximate x(t) by
y(t) =
N

n=1
Xnφn(t)
over an interval t1 < t < t2. The instantaneous difference will be deﬁned by e(t) =
y(t)−x(t) and its instantaneous power by |e(t)|2. It can be shown that the average power
of the difference
E =
1
t2 −t1
 t2
t1
|e(t)|2dt
is minimized if Xn =
 t2
t1 x(t)φ∗(t)dt.
Example
7.1
Consider a periodic sawtooth waveform x(t) = t, −1 < t < 1, which repeats itself
every 2 seconds. It will be shown (shortly) that the above waveform may be expressed
by an inﬁnite sum of sinusoidal components called its harmonics:
x(t) = 2
π

sin πt −1
2 sin 2πt + 1
3 sin 3πt −1
4 sin 4πt + 1
5 sin 5πt + · · · · · ·

In this example we will approximate x(t) by the ﬁnite sum of its ﬁrst N harmonics.
The ﬁnite sum is
y(t) = 2
π
N

n=1
(−1)n−1
n
sin nπt
The average power of the difference (to be called the average error) is
E = 1
2
 1
−1
|y(t) −x(t)|2dt
a.
Plot y(t) and |y(t) −x(t)|2 for N = 1 and 3 for the period −2 < t < 2. Overlay
x(t) on the plots and qualitatively discuss the salient features of the error.
b.
Find E for N = 1 by analytical and numerical (computational) methods and
verify that they are in agreement.

380
CHAPTER 7
Fourier Series
c.
Find E for N = 2, 3, 4, and 5 by a numerical method and plot it versus N.
Qualitatively and quantitatively, describe the decrease in E as the number of
harmonics increases.
Solution
a.
See Figure 7.1(a) and (b).
0
x and y
–1
–2
–1.5
–0.5
0
Time (s)
0.5
1.5
2
1
–1
1
0
x and y
–1
–2
–1.5
–0.5
0
Time (s)
0.5
1.5
2
1
–1
1
1
(y – x)2
0
–2
–1.5
–0.5
0
Time (s)
(a) Approximation by the principal harmonic (top)
and the instantaneous power of error (bottom).
(b) Approximation by the sum of three harmonics
(top) and the instantaneous power of error (bottom).
0.5
1.5
2
1
–1
1
(y – x)2
0
–2
–1.5
–0.5
0
Time (s)
0.5
1.5
2
1
–1
0.15
0.1
0.05
Average error
0
0
1
2
3
Number of harmonics
(c) Average error versus number of harmonics.
4
5
6
FIGURE 7.1 Approximating a periodic sawtooth waveform by ﬁnite sums of its harmonics and the resulting average
errors.

Signals and Systems
381
The difference between the sawtooth and its approximation is oscillatory, with a
growing amplitude. It is not evenly distributed along time. It is zero at
t = −2, 0, and 2, and 1 at the discontinuity points t = −1 and 1.
b.
E1 = 1
2
 1
−1

t −2
π sin πt
2
dt = 0.1307
c.
See Figure 7.1(c).
N = 1,
y1(t) = 2
π sin πt,
E1 = 0.1307
N = 2,
y2(t) = 2
π

sin πt −1
2 sin 2πt

,
E2 = 0.0800
N = 3,
y3(t) = 2
π

sin πt −1
2 sin 2πt + 1
3 sin 3πt

, E3 = 0.0575
N = 4,
y4(t) = 2
π

sin πt −1
2 sin 2πt + 1
3 sin 3πt
−1
4 sin 4πt

,
E4 = 0.0448
N = 5,
y5(t) = 2
π

sin πt −1
2 sin 2πt + 1
3 sin 3πt
−1
4 sin 4πt + 1
5 sin 5πt

,
E5 = 0.0367
Example
7.2
Following the approach of Example 7.1 we will approximate a periodic square wave
by the ﬁnite sum of its ﬁrst N harmonics y(t) and obtain the average error as deﬁned
in Example 7.1. Consider the periodic square wave x(t) with a period of 2 seconds,
which switches between ±1 at equal time intervals. One cycle of the waveform is
described by
x(t) =



−1,
−1 < t ≤−0.5
1,
−0.5 < t ≤0.5
−1,
0.5 < t ≤1
The waveform has a zero DC value and a peak-to-peak value of 2. Its Fourier series
expansion is
x(t) = 4
π

cos πt −1
3 cos 3πt + 1
5 cos 5πt −1
7 cos 7πt + 1
9 cos 9πt

You will approximate x(t) by the ﬁnite sum of its ﬁrst N harmonics, y(t). The average
error will be deﬁned, as in Example 7.1, by
E = 1
2
 1
−1
|e(t)|2dt, where e(t) = y(t)−x(t) is the instantaneous difference.
a.
Plot y(t) and |e(t)|2 for N = 1 and 3 for the period −2 < t < 2. Overlay x(t)
on the plots and qualitatively discuss the salient features of the error.
b.
Find E for N = 1 by analytical and numerical (computational) methods and
verify that they are in agreement.

382
CHAPTER 7
Fourier Series
c.
Find E for N = 2, 3, 4 and 5 by a numerical method and plot it versus N.
Qualitatively and quantitatively describe the decrease in E as the number of
harmonics increases.
Solution
a.
See Figure 7.2(a) and (b). The difference between the square wave and its
approximation is oscillatory with maximum error at the discontinuity points.
b.
E1 =
 0.5
−0.5

1 −4
π cos πt
2
dt = 0.1894
c.
See Figure 7.2(c).
N = 1,
y1(t) = 4
π cos πt,
E1 = 0.1894
N = 2,
y2(t) = 4
π

cos πt −1
3 cos 3πt

,
E2 = 0.0993
N = 3,
y3(t) = 4
π

cos πt −1
3 cos 3πt + 1
5 cos 5πt

, E3 = 0.0669
N = 4,
y4(t) = 4
π

cos πt −1
3 cos 3πt + 1
5 cos 5πt
−1
7 cos 7πt

,
E4 = 0.0504
N = 5,
y5(t) = 4
π

cos πt −1
3 cos 3πt + 1
5 cos 5πt
−1
7 cos 7πt + 1
9 cos 9πt

,
E5 = 0.0404
0
x(t)
(x(t) – t)2
–1
–2
–1.5
–0.5
0
Time (s)
0.5
1.5
2
1
–1
1
0
x(t)
–1
–2
–1.5
–0.5
0
Time (s)
0.5
1.5
2
1
–1
1
1
0
–2
–1.5
–0.5
0
Time (s)
(a) Approximation by the principal harmonic (top)
and the instantaneous power of error (bottom).
(b) Approximation by the sum of three harmonics
(top) and the instantaneous power of error (bottom).
0.5
1.5
2
1
–1
(x(t) – t)2
1
0
–2
–1.5
–0.5
0
Time (s)
0.5
1.5
2
1
–1
FIGURE 7.2 Approximating a periodic square wave by ﬁnite sums of its harmonics and the resulting errors.

Signals and Systems
383
0.2
0.18
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
Average error
0
0
1
2
3
Number of harmonics
(c) Average error versus number of harmonics.
4
5
6
FIGURE 7.2 (Continued)
In both examples the error is greater at instances of discontinuity in the function. By
increasing the number of harmonics one may reduce the average error but not the
instantaneous values at discontinuity points.
7.2
Fourier Series Expansion
The question now is how large a class of input functions can be represented by est
and how easily this can be done. For a periodic function with period T , the answer to
the question is clear and simple: In the complex plane restrict s to the imaginary axis
jω, leading to the set of exponential functions e jnω0t, where ω0 = 2π/T is called the
fundamental frequency and n is an integer with −∞< n < ∞. The description of a
periodic function by the above set of exponentials is called its exponential Fourier series
expansion, or simply its Fourier series. It is shown by
x(t) =
∞

n=−∞
Xne jnω0t
Xn is called the Fourier coefﬁcient and Xne jnω0t is called the nth harmonic of x(t).
The coefﬁcients Xn can be obtained from x(t) using orthogonality of the set of
exponential functions. Two functions x(t) and y(t) are said to be orthogonal to each
other on an interval t1 to t2 if
 t1
t0
x(t)y∗(t)dt = 0
The set of exponential functions e jnω0t have such a property on any interval of length
T = 2π
ω0 . For those functions the integral yields
 t0+T
t0
e jnω0te−jmω0tdt =
 t0+T
t0
e j(n−m)ω0tdt =

0,
n ̸= m
T,
n = m
= T δmn

384
CHAPTER 7
Fourier Series
The orthogonality of the set of e jnω0t, −∞< n < ∞on any interval T suggests the
easy approach of ﬁnding Xn through the following integral:
 t0+T
t0
x(t)e−jnω0t =
 t0+T
t0

∞

m=−∞
Xme jmω0t

e−jnω0tdt
Exchange the order by which the integration and the summation operations are performed
to obtain
∞

m=−∞
Xm
  t0+T
t0
e j(m−n)ω0tdt

=
∞

n=−∞
T Xnδmn = T Xn
Therefore,
x(t) =
∞

n=−∞
Xne jnω0t
Xn = 1
T
 t0+T
t0
x(t)e−jnω0tdt
It is seen that when x(t) is a real-valued function of time, Xn and X−n are complex
conjugates, Xn = X∗
−n. The series, therefore, can be represented in trigonometric form
(to be discussed in section 7.5).
7.3
The Generalized Fourier Series and Vectorial
Representation of Signals
In the previous section we introduced a way to expand a periodic signal in the form of a
sumofexponentialfunctions.TheexpansioniscalledtheFourierseries.Theexponentials
are eigenfunctions of LTI systems, making the Fourier series a very attractive tool for
the analysis and design of LTI systems. In fact, our approach to the Fourier expansion
was taken with that idea in mind.
Signals may also be represented by a set of functions φn(t) other than exponentials.
The representation has the familiar form
x(t) =

n
Xnφn(t)
The expansion is called a generalized Fourier series and the set of Xn are called gen-
eralized Fourier coefﬁcients. To look into the applicability of such expansions, assume
the functions φn(t) are orthonormal.
 t1
t0
φi(t)φ∗
j (t)dt =

1,
i = j
0,
i ̸= j
The Fourier coefﬁcients Xn can then be found, as shown in section 7.2, by multiplying
x(t) with φ∗
n(t) and integrating, as was done in the previous section for the Fourier

Signals and Systems
385
coefﬁcients
Xn =
 t1
t0
x(t)φ∗(t)dt
In view of the above expansion, one may think of the signal x(t) = N
n=1 Xnφn(t) as the
vector x in an orthogonal n-dimensional space. The vector x is speciﬁed by the ordered
set Xn which constitutes its coordinate values. The coordinate system within which the
signal is deﬁned may also have inﬁnite dimensions. The vectorial interpretation of signals
is very useful in that it facilitates many analytical operations on signals. For the time
being, the present chapter concentrates on the trigonometric and exponential Fourier
series representations.
7.4
Dirichlet Conditions and Beyond
A rigorous proof of Fourier’s theorem requires determination of conditions for conver-
gence of the series to the original time function. One set of conditions was given by
Dirichlet in 1829. The Dirichlet conditions are that
1.
x(t) be absolutely integrable over the period T :
 T
0
|x(t)|dt < ∞
2.
x(t) have a ﬁnite number of discontinuities and a ﬁnite number of maxima and
minima during the period T .
If the Dirichlet conditions are met by a function x(t), then its Fourier series representation
converges to x(t) at all points where the function is continuous. At points where x(t) is
discontinuous, the series converges to the average of the limits of x(t) from the left and
right sides. For example, if x(t) has a ﬁnite discontinuity at a point, the series converges
to the midpoint of the discontinuity. (For more examples see section 7.13.) In almost all
practical situations dealing with physical signals and systems, the Dirichlet conditions
are satisﬁed and the Fourier series exists. [An example of a function for which the
Dirichlet conditions do not apply is x(t) = sin(1/t).]
The Dirichlet conditions are sufﬁcient to ensure validity of the series representa-
tion. They are, however, not necessary for the convergence of the series.1 A periodic
time function may violate the Dirichlet conditions and still have a valid Fourier series
representation in the form described in section 7.1. As an example, a periodic impulse
train in the time domain can be represented by the sum of harmonics of equal strength
in the frequency domain. See section 7.12 on the Fourier series of impulse trains.
If a periodic function is square-integrable over one period
 T
0
|x(t)|2dt < M, where M is any large number
1“The necessary conditions for convergence are not known” according to J. W. Nilsson, Electric Circuits,
3rd ed. (Upper Saddle River, NJ: Prentice Hall, 1990), p. 671.

386
CHAPTER 7
Fourier Series
then its Fourier series converges in the mean-squared sense. For more details on proof
of Fourier’s theorem and its convergence, see the references listed in footnotes 2
and 3.2,3
7.5
Trigonometric Fourier Series
A periodic signal with period T 4 may, in general, be represented by the inﬁnite sum5
x(t) = 1
2a0 + a1 cos(ωt) + a2 cos(2ωt) · · · + b1 sin(ωt) + b2 sin(2ωt) + · · ·
= 1
2a0 +
∞

n=1
an cos(nωt) +
∞

n=1
bn sin(nωt)
(7.1)
an = 2
T
 T
0
x(t) cos(nωt) dt, for n = 0, 1, 2, ....
(7.2a)
bn = 2
T
 T
0
x(t) sin(nωt) dt, for n = 1, 2, ....
(7.2b)
where ω = 2π/T is the fundamental frequency and nω, n >1 are the harmonic frequen-
cies (or simply, its harmonics). A ﬁrst question pertains to the conditions for validity
of the series representation. We are interested in the application of the Fourier series in
the analysis of signals and linear systems, and are comforted in the knowledge that all
periodic functions that model practical signals and systems may be represented by the
Fourier series. Nonetheless, some conditions for convergence of the series are brieﬂy
discussed in section 7.4.
Derivation of the Trigonometric Fourier Coefficients
To derive an given in (7.2a) we multiply both sides of (7.1) by cos(mωt), integrate over
one period, and then interchange the order of summation and integration.
 T
0
x(t) cos(mωt) dt = 1
2a0
 T
0
cos(mωt)dt +
∞

n=1
 T
0
an cos(nωt) cos(mωt)dt
+
∞

n=1
 T
0
bn sin(nωt) cos(mωt)dt
2H. S. Carslaw, Introduction to Theory of Fourier’s Series and Integrals (London: Macmillan, 1930).
3L. Carlson, “On Convergence and Growth of Partial Sums by Fourier Series,” Acta Mathematica, June
1966, pp. 135–157.
4x(t) = x(t + T ) for all t.
5Presented by Fourier to the French Academy in 1807. See J. B. J. Fourier, “Theory Analytique de la
Chaleur,” 1822. An English edition of the work is published by Dover, New York.

Signals and Systems
387
For m = 0 : a0 = 2
T
 T
0
x(t)dt
For m ̸= 0 :
 T
0
sin(nωt) cos(mωt)dt = 0, all n and m
 T
0
sin(nωt) sin(mωt)dt =
 T
0
cos(nωt) cos(mωt)dt =
0,
n ̸= m
T
2 ,
n = m
Therefore, all integral terms become zero except when n = m, which results in (7.2a).
Similarly, to derive coefﬁcientsbn given in (7.2b) multiply both sides of (7.1) by sin(mωt)
and integrate over one period.
Note: The limits of the integrals for evaluating the Fourier coefﬁcients are from t0 to
t0 + T , with t0 chosen for the convenience of integration as long as the integral is taken
over one period.
Simplified Derivation of the Coefficients
The derivations of the trigonometric coefﬁcients may be simpliﬁed by choosing a new
variable τ = ωt in the integrals of (7.2a) and (7.2b). Hence, dt = 1
ωdτ =
T
2π dτ. The
trigonometric coefﬁcients are then found from
an = 1
π
 2π
0
χ(τ) cos(nτ) dτ
bn = 1
π
 2π
0
χ(τ) sin(nτ) dτ
where χ(τ) = x( τ
ω). A plot of χ(τ) versus τ is identical to a plot of x(t) versus ωt. In
other words, compress the time axis in the x plot by a factor of ω and you will get the plot
of χ. In general, the limits of the integrals are from θ to θ +2π, with θ chosen to simplify
the integration.
Sine and Cosine Series
The sine and cosine terms of (7.2a) and (7.2b) may be combined to form a series with
sines or cosines only:
x(t) = 1
2c0 +
∞

n=1
cn cos(nωt −θn) = 1
2c0 +
∞

n=1
cn sin(nωt + φn)
where c0 = a0 and
cn =

a2n + b2n,
θn = tan−1
bn
an

, and φn = tan−1
an
bn

,
n ≥1

388
CHAPTER 7
Fourier Series
Example
7.3
Rectangular pulse train
Rectangular pulses and pulse trains have a special place in Fourier analysis, signal
processing, and ﬁlter design. In this example we derive the trigonometric Fourier
coefﬁcients of a rectangular pulse train. (We will revisit it in sections 7.6 and 7.12
when we consider the exponential form of the Fourier series.)
a.
Find the coefﬁcients of the trigonometric Fourier series for the periodic
rectangular pulse train x(t) with period T , pulse duration τ, baseline at 0, and
pulse height V0.
b.
Write the ﬁrst seven terms in x(t) when the pulse train becomes a square.
c.
A pulse with a period T and pulse duration τ is said to have a duty cycle of
τ
T × 100%. For example, a pulse with τ = T/100 has 1% duty cycle. Write the
ﬁrst seven terms in x(t) when τ = T/100 (a narrow pulse train with a 1%
duty cycle).
Solution
a.
Choose the time origin such that the signal is an even function. During the
period −T
2 < t < T
2 the pulse is given by
x(t) =
 V0,
−τ
2 ≤t < τ
2
0,
elsewhere
The trigonometric Fourier coefﬁcients are
an = 2
T

τ
2
−τ
2
V0 cos
2πn
T t

dt =

2V0
sin(πn τ
T )
πn
,
n > 0
2 V0τ
T
n = 0
Note that a0/2 = V0τ/T is the DC value of the waveform. The coefﬁcients bn
are zero because x(t) is even, x(t) sin(2πn t
T ) is odd, and the integral in (7.2b)
becomes zero.
b.
In the case of a square pulse where τ = T
2 ,
an = V0
sin πn
2
πn
2
x(t) = V0
2 + 2V0
π

cos(ωt) −1
3 cos(3ωt) + 1
5 cos(5ωt) −1
7 cos(7ωt) + · · ·

= V0 [0.5 + 0.637 cos(ωt) −0.212 cos(3ωt) + 0.127 cos(5ωt)
−0.091 cos(7ωt) + · · ·]
where ω = 2π
T is the fundamental angular frequency. The even rectangular
pulse train with 50% duty cycle has odd harmonics only.
c.
In the case of a narrow pulse with τ = T/100, an = 2V0 sin
 πn
100)/(πn

. For
n < 10,

Signals and Systems
389
sin
 πn
100

≈πn
100, ⇒an ≈2V0
πn
100
πn = 0.02V0
x(t) ≈V0
100 + 2V0
100 [cos(ωt) + cos(2ωt) + cos(3ωt) + cos(4ωt) + · · ·]
For the narrow pulse, the coefﬁcients an have become smaller and almost equal, with
all harmonics being present. As n increases, the spectral lines do not diminish as fast
as in (7.2b). See section 7.12 for a comprehensive picture.
Example
7.4
Filtering
When a periodic waveform passes through an LTI system, its Fourier coefﬁcients
undergo different gains at different frequencies. Some harmonics may be attenuated
more strongly than others and thus ﬁltered out. In this example a 159.155-Hz square
wave v1(t) with its base-to-peak voltage spanning zero to 1 volt is passed through a
1 k resistor in series with a 1 µF capacitor. See Figure 7.3(a). Find the frequency
components of the capacitor voltage as a function of time. Plot the amplitudes of the
DC value and the next nth harmonics versus n for n = 1 to 7, and call it the one-sided
line spectra.
Solution
We ﬁrst ﬁnd the expansion of the input and pass it through the circuit that works as
a ﬁlter. Choosing the time origin at the center of a pulse makes the input voltage an
even function of time so that its Fourier series will contain cosine terms only. The
Fourier coefﬁcients of an input cosine series are
v1(t) = 1
2 +
∞

n=1
an cos(nω0t)
ω0 = 2π × 159.155 = 1,000 rad/s
and
an = sin( πn
2 )
( πn
2 ) , n ≥1
The input voltage and its line spectrum are plotted in Figure 7.3(b) and (c), respec-
tively. Now note that a sinusoidal component cos ωt of v1(t) produces |H| cos(ωt +θ)
at the terminals of the capacitor, where
|H(ω)| =
1
√
1 + R2C2ω2
and
θ(ω) = −tan−1(RCω)
The capacitor voltage in response to the square wave input may be shown by the series
v2(t) = 1
2 +
∞

n=1
Hn
2 sin( πn
2 )
πn
cos(nω0t + θn)
where Hn is found from |H(ω)| by setting ω = nω0. Note that if ω0 = 1/(RC), as
in the present example, we obtain RCω = n and
|H(ω)| = Hn =
1
√
1 + n2
and
θn = −tan−1(n)

390
CHAPTER 7
Fourier Series
The sum of the DC value and the ﬁrst four nonzero harmonics in v1(t) and v2(t) are
listed below.
v1(t) = 0.5 + 0.637 cos(ω0t) −0.212 cos(3ω0t) + 0.127 cos(5ω0t) −0.091 cos(7ω0t)
v2(t) = 0.5 + 0.450 cos(ω0t −0.45o) −0.067 cos(3ω0t −71.6o)
+0.025 cos(5ω0t −78.7o) −0.013 cos(7ω0t −81.9o)
The output voltage and its line spectrum are plotted in Figure 7.3(d) and (e), respec-
tively.
1
Amplitude
0
–8
–6
–4
–2
0
Time (s)
(b) Input v1(t)
2
4
6
8
× 10–3
0.7
0.6
0.5
Amplitude
0.1
–0.1
0
–0.2
0
1
2
3
n
(c) Input line spectrum
4
5
6
7
(a) The circuit
1 µF
v1
+
–
v2
+
–
1 kΩ
+
–
0.5
0.4
Amplitude
–0.1
0
0
1
2
3
n
(e) Output line spectrum
4
5
6
7
1
Amplitude
0
–8
–6
–4
–2
Time (s)
(d) Output v2(t)
0
2
6
4
8
× 10–3
FIGURE 7.3 An RC circuit with a 1-msec time constant receives a rectangular pulse train voltage at 159.155 Hz as
shown in (b). The output voltage across the capacitor is shown in (d). The one-sided spectra of the input and output
voltages are shown in (c) and (e), on the upper and lower traces, respectively. Note attenuation of spectral lines at the
output.

Signals and Systems
391
7.6
Exponential Fourier Series
As introduced in section 7.1, the Fourier series expansion of a periodic signal x(t) may,
alternatively, be expressed by the inﬁnite sum of exponential terms
x(t) =
∞

n=−∞
Xne j2πnt/T
(7.3)
Xn = 1
T

T
x(t)e−j2πnt/T dt
(7.4)
where the integral is taken over a time period which is T seconds long. Coefﬁcients Xn
are called the exponential Fourier coefﬁcients of x(t) and the sum is the exponential
Fourier series representation, or expansion, of x(t). From now on we use the exponential
form of the Fourier series unless speciﬁed otherwise. To derive Xn, ﬁrst multiply both
sides of (7.3) by e−j2πmt/T and integrate over one period. By exchanging the order of
summation and integration, and observing that e j2πnt/T and e−j2πmt/T are orthogonal,
all terms vanish except when n = m, from which (7.4) results. The four examples given
below will be revisited again in more detail.
Example
7.5
Rectangular pulse train
Find the exponential Fourier coefﬁcients of a periodic rectangular pulse train with
period T and pulse width τ. See Figure 7.4. During −T
2 < t < T
2 the pulse is given
by
x(t) =

1,
−τ
2 ≤t < τ
2
0,
elsewhere
T
t
τ
0
1
FIGURE 7.4 An even periodic rectangular pulse train.
Solution
Xn = 1
T

T
2
−T
2
x(t)e−j2πnt/T dt = 1
T

τ
2
−τ
2
e−j2πnt/T dt =
 sin(πn τ
T )
πn
,
n ̸= 0
τ
T ,
n = 0

392
CHAPTER 7
Fourier Series
Example
7.6
Triangular pulse train
Find the exponential Fourier coefﬁcients of a periodic triangular pulse train with
period T . The base of the triangle is τ and the height is 1. See Figure 7.5.
t
T
1
1
1
–T
–T
τ0
FIGURE 7.5 An even periodic triangular pulse train.
During the period −T
2 < t < T
2 the pulse is given by
x(t) =





1 + 2 t
τ ,
−τ
2 ≤t < 0
1 −2 t
τ ,
0 ≤t < τ
2
0,
elsewhere
solution
Xn = 1
T
 0
−τ/2

1 + 2 t
τ

e−j2πnt/T dt +
 τ/2
0

1 −2 t
τ

e−j2πnt/T dt

=

2T
τ
sin2( πnτ
2T )
(πn)2
,
n ̸= 0
τ
2T ,
n = 0
Example
7.7
Impulse train
Find the exponential Fourier coefﬁcients of a periodic impulse train. See Figure 7.6.
x(t) =
∞

n=−∞
δ(t −nT )
t
T
–T
T
δ (t + T)
δ (t – T)
δ (t)
0
. . .
. . .
FIGURE 7.6 An impulse train.

Signals and Systems
393
Solution
Xn = 1
T
 T/2
−T/2
δ(t)e−j2πnt/T dt = 1
T , −∞< n < ∞
In summary,
∞

n=−∞
δ(t −nT ) = 1
T
∞

n=−∞
e j2πnt/T
All harmonics are equally represented in the waveform.
7.7
Properties of Fourier Series
Some features of the time functions reﬂect upon the Fourier coefﬁcients in ways that
facilitate their derivation. These are called properties of Fourier series. Several such
properties are listed in Table 7.1 and discussed in the following sections. Some other
properties, not listed in Table 7.1, are more applicable when in the guise of Fourier
transform (e.g., differentiation and integration).
TABLE 7.1 Some Properties of the Fourier Series of Real-Valued Time Function
Property
Time Domain
⇐⇒
Frequency Domain
Deﬁnition
x(t) =
∞

−∞
Xne j2πnt/T
⇐⇒
Xn = 1
T

T
x(t)e−j2πnt/Tdt
Superposition
ax(t) + by(t)
⇐⇒
aXn + bYn
Time reversal
x(−t)
⇐⇒
X ∗
n
(real-valued functions)
Time shift
x(t −t0)
⇐⇒
Xne−j2πnt0/T
Real-valued function
x(t) = x∗(t)
⇐⇒
Xn = X ∗
−n
Even symmetry
x(t) = x(−t)
⇐⇒
Xn = X−n
Odd symmetry
x(t) = −x(−t)
⇐⇒
Xn = −X−n
Half-wave symmetry
x(t) = −x(t + T/2)
⇐⇒
Xn = 0 for n even
Even part of x(t)
x(t)+x(−t)
2
⇐⇒
RE{Xn}
Odd part of x(t)
x(t)−x(−t)
2
⇐⇒
jIM{Xn}
Theorems:
DC Value
1
T

T
x(t)dt = X0
Zero Time
x(0) =
∞

−∞
Xn
Parseval’s Theorem
1
T

T
|x(t)|2dt =
∞

−∞
|Xn|2

394
CHAPTER 7
Fourier Series
7.8
Time Reversal and Shift
Time Reversal
Time reversal in a real-valued function changes the Fourier coefﬁcients to their complex
conjugate.
x(t) ⇐⇒Xn
x(−t) ⇐⇒X∗
n
To prove the above, let y(t) = x(−t). Then
Yn = 1
T
 T/2
t=−T/2
x(−t)e−j2πnt/T dt = 1
T
 T/2
t=−T/2
x(t)e j2πnt/T dt = X∗
n
Time Shift
A time shift, or delay in time, by t0 seconds multiplies Xn by e−j2πnt0/T :
x(t −t0)
⇐⇒
Xne−j2πnt0/T
Proof. Let y(t) = x(t −t0). Then
Yn = 1
T
 T/2
−T/2
y(t)e−j2πnt/T dt = 1
T
 T/2
−T/2
x(t −t0)e−j2πnt/T dt
= 1
T
 T/2
−T/2
x(τ)e−j2πn(τ+t0)/T dt = Xne−j2πnt0/T
Example
7.8
Find, by applying the deﬁnition, the exponential Fourier coefﬁcients of the periodic
rectangular pulse train with a period T . During one period the pulse is shown by
x(t) =

1,
0 ≤t < τ
0,
τ ≤t < T
Show that the same result is obtained by applying the shift property to the coefﬁcients
of the rectangular pulse train in Example 7.5.
Solution
Xn = 1
T
 τ
0
e−j2πnt/T dt =

1
j2πn

1 −e−j2πnτ/T 
=
sin(πn τ
T )
πn
e−jπnτ/T ,
n ̸= 0
τ
T ,
n = 0
The pulse train of this example is the same as that of Example 7.5 but delayed by τ/2
units of time. The Fourier coefﬁcients are, therefore, those of Example 7.5 multiplied
by e−jπnτ/T .

Signals and Systems
395
Example
7.9
Find the exponential Fourier series coefﬁcients for the periodic signals shown in
Figure 7.7.
t
τ
τ
–1
0
(a)
1
T
t
τ
τ
–1
0
(b)
1
T
FIGURE 7.7
Solution
Consider the periodic rectangular even pulse train x(t) of Example 7.5 with period
T and pulse width τ. One period of the pulse and its Fourier coefﬁcients are
x(t) =
1,
−τ/2 ≤t < τ/2
0,
elsewhere
⇐⇒Xn = sin
 πnτ
T

πn
For Figure 7.7(a), we have
x(t) −x(t −T/2)
⇐⇒
Xn −Xne−jπn =

2
sin( πnτ
T )
πn
,
n odd
0
n even
For Figure 7.7(b),
x(t + τ/2) −x(t −τ/2)
⇐⇒
Xne j πnτ
T −Xne−j πnτ
T = 2 j
sin2( πnτ
T )
πn
7.9
Conjugate Symmetry
If x(t) is real, x(t) = x∗(t), then Xn = X∗
−n. In other words, a real function x(t) is
completely speciﬁed from Xn, n ≥0, which may be given in the form of its real and
imaginary parts or by its magnitude and phase. This property can be observed throughout
the examples in this chapter, as the time functions are all real valued.

396
CHAPTER 7
Fourier Series
7.10
Waveform Symmetry
Certain types of symmetry in a periodic waveform result in speciﬁc properties of its
Fourier series. In this section consider three properties concerning real functions and
their Fourier series: even symmetry, odd symmetry, and half-wave symmetry.
Even Symmetry
A function x(t) is even if x(t) = x(−t). The plot of a waveform represented by an even
function is symmetrical with respect to the vertical axis. An example of an even function
is x(t) = 1 + x2. The cosine is an even function by its deﬁnition. Also, note that
cos(t) = 1 −t2
2! + t4
4! −t6
6! + t8
8! + ....
which is made of even terms. The exponential Fourier coefﬁcients of an even function
are purely real numbers. In the trigonometric representation of the Fourier series for such
a function, bn = 0 and the series contains only cosine terms and possibly a constant if
its average is nonzero.
Odd Symmetry
A function x(t) is odd if x(t) = −x(−t). The plot of a waveform represented by an
odd function is symmetrical with respect to the origin. An example of an odd function
is x(t) = x + x3. The sine is an odd function by its deﬁnition. Also note that
sin(t) = t −t3
3! + t5
5! −t7
7! + t9
9! −....
which is made of odd terms. The exponential Fourier coefﬁcients of an odd function are
purely imaginary numbers. In the trigonometric representation of the Fourier series of
such a function, an = 0 and the series contains sine terms only.
The product of two odd functions is an even function and the sum of two odd
functions is an odd function. Adding a constant value to an odd function removes its odd
property. Conversely, a waveform may become odd by removing its average value, in
which case the series representing the original waveform is seen to contain sine terms
and a constant value representing the average.
Half-Wave Symmetry
A function x(t) is said to have half-wave symmetry if x(t) = −x(t + T/2), where T
is the period. If a waveform has half-wave symmetry, then Xn = 0 for n even, and its
series contains only odd harmonics.

Signals and Systems
397
Even and Odd Parts of a Function
Any function x(t) may be split into an even and an odd part: x(t) = xe(t)+ xo(t), where
xe(t) = x(t)+x(−t)
2
xo(t) = x(t)−x(−t)
2
If x(t) is real, its even and odd parts are related to the trigonometric coefﬁcients an
and bn.
Relationships between the Fourier series coefﬁcients of a real-valued waveform and
its even and odd parts are summarized as follows:
x(t)
⇐⇒
Xn = 1
2(an + jbn)
x(−t)
⇐⇒
X−n = 1
2(an −jbn)
xe(t) = x(t)+x(−t)
2
⇐⇒
Xn = X−n = an/2, (cosine terms only)
xo(t) = x(t)−x(−t)
2
⇐⇒
Xn = −X−n = jbn/2, (sine terms only)
Summary
The symmetry properties are summarized below:
Even function
x(t) = x(−t)
⇐⇒Xn = X−n
Odd function
x(t) = −x(−t)
⇐⇒Xn = −X−n
Half-wave symmetry
x(t) = −x(t + T/2) ⇐⇒Xn = 0 (n even)
The symmetry conditions considered above may be used to simplify the Fourier rep-
resentation of a waveform. When representing a waveform by a mathematical function,
the time origin and the DC level may be chosen conveniently so that its Fourier series
may contain sine or cosine terms only. The square pulse train (Figure 7.4 with τ = T/2)
can be odd, even, or neither, depending on placement of the time origin. Similarly, the
sawtooth waveform [Figure 7.13(a) with τ = T ] becomes odd (and its series will contain
only sine terms) if the DC value is subtracted. In summary, depending on the time origin,
a rectangular pulse train becomes even, odd, or neither. Removing the DC level may
make it an odd function.
7.11
Time Averages
The average (or DC) value of a waveform x(t) over the time duration t0 to t0 + T is
Xavg ≡< x(t) >≡1
T
 t0+T
t0
x(t) dt

398
CHAPTER 7
Fourier Series
Similarly, the root-mean-square (rms) or effective (eff) value of the waveform x(t) over
the same time duration is
Xrms ≡Xeff ≡
 1
T
 t0+T
t0
x2(t) dt
 1
2
One can see that X2
rms =< x2(t) >.
The average and rms values of a periodic waveform may be obtained directly from
the above deﬁnitions or from the Fourier series coefﬁcients of the waveform. Let
x(t) = 1
2a0 + a1 cos(ωt) + a2 cos(2ωt) · · · + b1 sin(ωt) + b2 sin(2ωt) · · ·
By applying the above deﬁnitions and considering that the sine and cosine functions
have zero average values and are orthogonal, we get
Xavg = a0/2
Xrms =
1
2a0
2
+1
2a2
1 + 1
2a2
2+ · · · +1
2b2
1 + 1
2b2
2 + · · · =

c2
0+1
2c2
1 + 1
2c2
2 + · · ·
where c0 = a0/2 and c2
n = a2
n + b2
n, n > 0. In the exponential form, Xavg = X0
Parseval’s Theorem
This theorem states that the (average) power in a periodic waveform x(t) is the sum of
powers in its harmonics.
P = 1
T
 T/2
−T/2
|x(t)|2dt =
∞

−∞
|Xn|2
This is simply a consequence of orthogonality of the harmonics. |Xn|2 is called the power
spectrum density of x(t). The power contained in the harmonics N1 ≤n ≤N2 is
P =
N2

n=N1
2|Xn|2
7.12
Pulses and Impulses
Periodic trains such as rectangular, triangular, sawtooth, and sinc pulses have many ap-
plications in electrical engineering. Function, pulse, and signal generators, which can
produce such pulse trains, constitute basic instruments of an analog electrical engineering
laboratory. In addition, pulse signals are often used to transmit binary numbers. They are
also encountered in ﬁnite-duration signal processing, discrete-time signal modeling, dig-
ital signal processing, speech processing and coding, and pattern recognition. Similarly,
impulse trains are the mathematical instrument for sampling continuous-time signals.
Because of their importance and repeated use, we will revisit and examine in detail the

Signals and Systems
399
exponential Fourier series expansion of rectangular and triangular pulse and impulse
trains. The sinc pulse train is analyzed in an exercise. More discussion on windows is
found in Chapters 8, 16, and 17.
Rectangular Pulse Revisited
Consider the periodic rectangular pulse train x(t) and its exponential Fourier coefﬁcients
(see Example 7.5):
x(t) =

1,
−τ
2 < t < τ
2
0,
elsewhere
,
x(t) = x(t + T )
Xn =
 sin(πn τ
T )
πn
,
n ̸= 0
τ
T ,
n = 0
The coefﬁcients Xn exhibit the following features (see Figure 7.8):
1.
Xn is real and an even function of n, decreasing with n. The plot of Xn has an
inﬁnite number of alternating positive and negative lobes whose amplitudes
decrease with n. The main lobe extends from −n0 to n0, where n0 is the integer
found by truncating T/τ. When T/τ is an integer, the amplitude of the harmonic
represented by that integer is zero. The major part of the power in the signal is
concentrated at low frequencies within the main lobe.
2.
The DC value, or average of the pulse train, is X(0) = τ/T .
3.
For τ = T
2 , the waveform becomes a square pulse train and
Xn =
 sin( πn
2 )
πn
,
n ̸= 0
1
2
n = 0
x(t) =

· · · + 1
5π e−j5ω0t −1
3π e−j3ω0t + 1
π e−jω0t + 1
2 + 1
π e jω0t
−1
3π e jω0t + 1
5π e j5ω0t · · ·

, where ω0 = 2π
T
In this case the average power in x(t) is
P = 1
T

T
4
−T
4
dt = 1
2
The average power in the principal harmonic is 2|X1|2 = 2/π2. As the percentage
of the total power, it is
2|X1|2
P
× 100 = 4
π2 × 100 ≈40.5%
4.
As the pulse narrows its spectrum broadens.

400
CHAPTER 7
Fourier Series
(a)
(b)
(c)
1
x (t)
0
–0.5 –0.4 –0.3 –0.2 –0.1
0
Time (s)
xa(t), Periodic rectangular pulse, 50% duty cycle.
Xn, Its exponential Fourier coefficients.
0.1
0.2
0.3
0.4
0.5
0.5
0.4
0.3
0.2
X(n)
0.1
0
–0.1
–20
–15
–10
–5
0
Frequency (Hz)
5
0.2
15
20
1
x (t)
0
–0.5 –0.4 –0.3 –0.2 –0.1
0
Time (s)
xb(t), Periodic rectangular pulse, 20% duty cycle.
Xn, Its exponential Fourier coefficients.
0.1
0.2
0.3
0.4
0.5
0.2
0.15
0.1
X(n)
0.05
0
–0.05
–20
–15
–10
–5
0
Frequency (Hz)
5
10
15
20
1
x (t)
0
–0.5 –0.4 –0.3 –0.2 –0.1
0
Time (s)
xc(t), Periodic rectangular pulse, 10% duty cycle.
Xn, Its exponential Fourier coefficients.
0.1
0.2
0.3
0.4
0.5
0.1
0.08
0.06
X(n)
0.04
0
–0.02
–20
–15
–10
–5
0
Frequency (Hz)
5
10
15
20
0.02
FIGURE 7.8 The time plots on the left show one cycle of a 1-Hz periodic rectangular pulse train with pulse duration of
0.5, 0.2, and 0.1 sec in (a), (b), and (c), respectively. The time origin has been chosen so that the pulses are even functions
of time. Their exponential Fourier coefﬁcients are, therefore, real valued and shown in the right column, respectively. As
the pulse narrows, its frequency spectrum broadens.

Signals and Systems
401
Triangular Pulse Revisited
The exponential Fourier coefﬁcients of the periodic triangular pulse train with period T
and base τ were obtained in Example 7.6.
x(t) =





1 + 2 t
τ ,
−τ
2 < t < 0
1 −2 t
τ ,
0 < t < τ
2
0,
elsewhere
, x(t) = x(t + T )
Xn =

2T
τ
sin2( πnτ
2T )
(πn)2
,
n ̸= 0
τ
2T ,
n = 0
See Figure 7.9.
The Fourier coefﬁcients exhibit the following features:
1.
X(n) is a real and even function of n. It is always nonnegative. It extends over the
inﬁnite frequency range.
2.
The DC value of the transform is X(0) = τ/(2T ), which is equal to the average of
the area in one cycle.
3.
Compared to the transform of the rectangular pulse, the mathematical expression
of X( f ) for the triangular pulse indicates that the lobes attenuate faster with
increased frequency.
4.
For τ = T/2, the Fourier series become
Xn =



4 sin2( πn
4 )
π2n2 ,
n ̸= 0
1
4
n = 0
x(t) =

· · ·
2
9π2 e−j3ω0t + 1
π2 e−j2ω0t + 2
π2 e−jω0t + 1
4 + 2
π2 e jω0t + 1
π2 e j2ω0t
+ 2
9π2 e j3ω0t · · ·

, where ω0 = 2π
T
In this case the average power in x(t) is
P = 2
T

T
4
0
4t
T
2
dt = 1
6

402
CHAPTER 7
Fourier Series
1
x(t)
0
–0.5 –0.4 –0.3 –0.2 –0.1
0
Time (s)
xb(t), Periodic triangular pulse, 20% duty cycle.
0.1
0.2
0.3
0.4
0.5
1
x(t)
0
–0.5 –0.4 –0.3 –0.2 –0.1
0
Time (s)
xc(t), Periodic triangular pulse, 10% duty cycle.
0.1
0.2
0.3
0.4
0.5
Xn, Its exponential Fourier coefficients.
0.1
0.08
0.06
0.04
X(n)
0.02
0
–20
–15
–10
–5
0
Frequency (Hz)
5
10
15
20
Xn, Its exponential Fourier coefficients.
0.05
0.04
0.03
0.02
X(n)
0.01
0
–20
–15
–10
–5
0
Frequency (Hz)
5
10
15
20
(a)
(b)
(c)
1
x(t)
0
–0.5 –0.4 –0.3 –0.2 –0.1
0
Time (s)
xa(t), Periodic triangular pulse, 50% duty cycle.
0.1
0.2
0.3
0.4
0.5
Xn, Its exponential Fourier coefficients.
0.25
0.2
0.15
0.1
X(n)
0.05
0
–20
–15
–10
–5
0
Frequency (Hz)
5
10
15
20
FIGURE 7.9 The time plots on the left show one cycle of a 1-Hz periodic triangular pulse train with pulse duration of
0.5, 0.2, and 0.1 sec in (a), (b), and (c), respectively. The time origin has been set so that the pulses are even functions
of time. Their exponential Fourier coefﬁcients are, therefore, real valued and are shown in the right column, respectively.
As the pulse narrows, its frequency spectrum broadens.

Signals and Systems
403
The average power in the principal harmonic is 2|X1|2 =
8
π4 . As the percentage of
the total power, it is
2|X1|2
P
× 100 = 48
π4 × 100 ≈49.3%
Observation
Convolve a periodic square pulse x(t) (spanning from zero to 1 volt with a period
T and 50% duty cycle) with itself. The result is a periodic triangular pulse y(t) =
x(t) ⋆x(t) (same period T , 100% duty cycle, and height = T/2). The exponential
Fourier coefﬁcients of x(t) and y(t) are given below.
Xn = sin( πn
2 )
πn
Yn = T
sin( πn
2 )
πn
2
= T × X2
n
Note the appearance of the multiplier T in Yn. This is in agreement with the convolution
property of the Fourier analysis, to be discussed in Chapter 8.
Impulse Train Revisited
A periodic unit-impulse train with period T and its exponential Fourier series coefﬁcients
are (see Example 7.7)
x(t) =
∞

n=−∞
δ(t −nT )
Xn = 1
T , −∞< n < ∞
∞

n=−∞
δ(t −nT ) = 1
T
∞

n=−∞
e j2πnt/T
The Fourier coefﬁcients are equal to 1/T for all n. Since the impulse is the limit of
a narrow pulse with unit area, we derive the above result as the limit of the Fourier
coefﬁcients of a narrowing rectangular pulse train. We start with a periodic rectangular
pulse x(t) of unit height and duration τ. We express its Fourier coefﬁcients Xn in terms
of the duty cycle α = τ/T
Xn = sin (απn)
πn
and ﬁnd their limit when τ →0.

404
CHAPTER 7
Fourier Series
First consider the case where the pulse duration τ becomes small but the height
remains the same. For αn << 1, we have sin(απn) ≈απn and Xn = α. Therefore,
x(t) ≈2α [0.5 + cos(ωt) + cos(2ωt) + cos(3ωt) + cos(4ωt) + · · ·]
where ω = 2π/T . The magnitude spectrum is diminished but remains ﬂat for a wide
frequency range. Compare with part c in Example 7.3.
Now consider the case where the pulse duration τ becomes small but the height
is increased by a factor 1/τ so that the pulse area remains the same. The exponential
Fourier coefﬁcients are then
Xn = sin(πn τ
T )
πnτ
= sin(παn)
πnτ
where α = τ/T is the duty cycle. For αn << 1, we have sin(παn) ≈παn and
Xn = 1/T . In the limit when τ →0, the waveform becomes a train of unit impulses
every T seconds and all its exponential Fourier coefﬁcients become equal to 1/T .
x(t) =
∞

n=−∞
δ(t −nT ) ⇐⇒
Xn = 1
T
From the above pair we ﬁnd
∞

n=−∞
δ(t −nT ) = 1
T
∞

n=−∞
e j2πnt/T
A similar result may be obtained from the limit behavior of other pulse trains that
progressively narrows, becoming an impulse train.
7.13
Convergence of the Fourier Series
The Fourier series converges to x(t) whenever x(t) is continuous. If x(t) has a ﬁnite
discontinuity at t, its Fourier series converges to the mid-value between x(t−) and x(t+),
which is the average of the limits from the left and right sides. In other words,
lim
N→∞
N

n=−N
Xne j2πnt/T = x(t−) + x(t+)
2
This, however, does not mean that within the discontinuity region the difference between
the sum and x(t) (the actual value) or x(t−)+x(t+)
2
[the average value of x(t−) and x(t+)]
could be reduced to a desired value by increasing N. The convergence is not uniform.

Signals and Systems
405
7.14
Finite Sum
The Fourier series coefﬁcients minimize the average power (or the rms) of difference
between x(t) and the ﬁnite sum of its harmonics. Let
ψ(t) =
N

n=−N
ne j2πnt/T
be a ﬁnite sum of harmonics of x(t) with arbitrary coefﬁcients n. Let the energy of the
difference between x(t) and ψ(t) over one period be deﬁned by
ϵ =
 t0+T
t0
|x(t) −ψ(t)|2 dt
The above measure is a function of the coefﬁcients {n} which constitute a set of
variables. It may be shown that given N, ϵ is at a minimum when n = Xn, in which
case
ψ(t) =
N

n=−N
Xne j2πnt/T
To show this, we express ϵ in terms of coefﬁcients 
ϵ =
 T/2
−T/2
x(t) −
N

n=−N
ne j2πnt/T

2
dt
To ﬁnd the set of n which minimizes ϵ, noting that x(t) is a real-valued function, we
get
dϵ
dn
= 0
for −N ≤n ≤N
Noting that x(t) is a real-valued function
dϵ
dn
=
d
dn


 T/2
−T/2
x(t) −
N

n=−N
ne j2πkt/T

2
dt

= 0
which results in
 T/2
−T/2

x(t) −
N

k=−N
ke j2πkt/T

e j2πnt/T dt = 0,
−N ≤n ≤N
Separating the two parts we have
 T/2
−T/2
x(t)e j2πnt/T dt =
 T/2
−T/2
e j2πnt/T

N

k=−N
ke j2πkt/T

dt
The aim is to ﬁnd n so that the right-side integral is equal to the left-side integral.
Let the integral on the right side be called In. To evaluate In we exchange the order of

406
CHAPTER 7
Fourier Series
integration and summation to get
In =
N

k=−N
k
 T/2
−T/2
e j2π(n+k)t/T dt =
N

k=−N
T k
sin(n + k)π
(n + k)π
=
N

k=−N
T kδ(n + k) = T −n
Therefore,
 T/2
−T/2
x(t)e−j2πnt/T dt = T n
n = 1
T
 T/2
−T/2
x(t)e−j2πnt/T dt
This shows that for the average power of difference between x(t) and the ﬁnite sum to be
at a minimum, the coefﬁcients of the ﬁnite sum should be the coefﬁcients of the Fourier
series. The maximum of the difference, however, is not reduced.
7.15
Gibbs’ Phenomenon
Let x(t) be a periodic rectangular pulse train with period T and pulse width τ. The
Fourier series expansion of x(t) was obtained in sections 7.6 and 7.12. Consider the
ﬁnite sum
ˆx(t) =
M

n=−M
Xne j2πnt/T
where Xn is the Fourier coefﬁcient of x(t). ˆx(t)is obtained from a ﬁnite segment of the
Fourier expansion, selected by a uniform window in the frequency domain. Examine the
difference x(t) −ˆx(t) as a function of M. As M increases, the difference approaches
zero, except at the discontinuity points of x(t) where it persists in the form of horns. See
details in Figure 7.10. This is a special case of a broader effect called Gibbs’ phenomenon.
(In the case of Fourier series we already have examined the effect for a sawtooth and
rectangular pulse train.) The mathematical reasoning behind Gibbs’ phenomenon will
be discussed in section 8.22 of Chapter 8 on the Fourier transform.

Signals and Systems
407
1
x(t)
0
–1 –0.8 –0.6 –0.4
0
0.2
0.4
0.6
1
–0.2
0.8
(a)
0.5
0.3
x(n)
0
–20
–15
–10
–5
0
Contributing exponential coefficients
{X±n}, n = 0, and 1
5
10
15
20
Sum of DC and principal harmonic
1
x(t)
0
–1 –0.8 –0.6 –0.4
0
Time (s)
0.2
0.4
0.6
1
–0.2
0.8
0.5
0.3
x(n)
0.1
0
–0.1
–20
–15
–10
–5
0
Contributing exponential coefficients
{X±n}, n = 0, 1, 3, and 5
5
10
15
20
Sum of DC and three harmonics
Time (s)
1
x(t)
0
–1 –0.8 –0.6 –0.4
0
0.2
0.4
0.6
1
–0.2
0.8
Time (s)
(b)
0.5
0.3
x(n)
0.1
0
–0.1
–20
–15
–10
–5
0
Contributing exponential coefficients
{X±n}, n = 0, 1, 3, 5, 7, 9, 11, 13, and 15
5
10
15
20
Sum of DC and three harmonics
(c)
FIGURE 7.10 Gibbs’ Phenomenon. The sum of a ﬁnite number of harmonics, N, of a rectangular pulse train converges
toward the value of the pulse as the number of harmonics increases, except at the pulse edges where the horns persist (due
to Gibbs’ phenomenon) as illustrated in this ﬁgure. The left column shows frequency representations of ﬁnite numbers of
harmonics of a square pulse [N = 1, 3, and 8, in (a), (b), and (c), respectively]. The sum of harmonics is shown by the
time functions in the right column. Increasing the number of harmonics from N = 1 (top row) to N = 3 (middle row) and
8 (bottom row) does not reduce the approximation error at the pulse edges. For a treatment of the theoretical foundation
of Gibbs’ phenomenon see Chapter 8.

408
CHAPTER 7
Fourier Series
7.16
Extension of Fourier Series to Transforms
Fourier series analysis may be extended to nonperiodic signals leading to the Fourier
transform. For an intuitive approach to the Fourier transform, consider the periodic
signal x(t) with period T which satisﬁes the Dirichlet conditions. x(t) and its Fourier
coefﬁcients are related by
Xn = 1
T

T
2
−T
2
x(t)e−j2πnt/T dt,
−∞< n < ∞
x(t) =
∞

−∞
Xne j2πnt/T
Now deﬁne a time-limited pulse h(t) to represent one cycle of x(t):
h(t) =
 x(t),
−T
2 < t < T
2
0,
elsewhere
The Fourier coefﬁcients Xn may be written in terms of h(t).
Xn = 1
T
 ∞
−∞
h(t)e−j2πnt/T dt,
−∞< n < ∞
Deﬁne f = n/T for −∞< n < ∞. Note that f is a discrete variable with f = 1/T .
Deﬁne
X( f ) = T Xn =
 ∞
−∞
h(t)e−j2π f tdt
Therefore,
x(t) =
∞

n=−∞
Xne j2πnt/T =
∞

f =−∞
X( f )e j2π f tf
Note that the summation is still taken over f = n
T , which is a discrete variable. If we
allow T to go to ∞, then x(t) = h(t) and Xn = 0. However, the variable f = n
T and the
product X( f ) = T Xn may converge to ﬁnite values. As T →∞, we have
x(t) →h(t) and X( f ) →H( f ),
f →d f, f becomes continuous and the sum becomes an integral,

→

As a result,
H( f ) =
 ∞
−∞
h(t)e−j2π f tdt
h(t) =
 ∞
−∞
H( f )e j2π f td f
The pair h(t) and H( f ) are called a Fourier transform pair. Note that in the above
discussion we required h(t) to satisfy the Dirichlet conditions. The above concepts are
illustrated in Figure 7.11.

Signals and Systems
409
x(t)
–14
–10
–6
–2
Time (msec)
(a)
0
2
6
14
10
0
1
0.4
0.3
|X(f)|
0.2
0.1
–2
–1.5
–1
–0.5
Frequency (kHz)
0
1
0.5
1.5
2
0
0.5
x(t)
–14
–10
–6
–2
Time (msec)
0
6
2
10
14
0
1
0.4
0.3
|X(f)|
0.2
0.1
–2
–1.5
–1
–0.5
Frequency (kHz)
0
1
0.5
1.5
2
0
0.5
(b)
(d)
x(t)
–15
–10
–5
0
Time (msec)
5
10
15
0
1
–15
–10
–5
0
5
10
15
0.4
0.3
|X(f)|
0.2
0.1
–2
–1.5
–1
–0.5
Frequency (kHz)
0
1
0.5
1.5
2
0
0.5
x(t)
Time (msec)
1
0
0.6
0.4
|X(f)|
0.2
–2
–1.5
–1
–0.5
Frequency (kHz)
0
1
0.5
1.5
2
0
0.8
(c)
FIGURE 7.11 See next page for ﬁgure legend.

410
CHAPTER 7
Fourier Series
FIGURE 7.11 Four periodic pulse trains x(t) are shown in the left column along with their representations in the
frequency domain in the right column, in the form of discrete lines. The periods of the pulses are T = 4, 8, 16, and
400 msec in (a), (b), (c), and (d), respectively. In all cases the pulse width is τ = 2 msec. The plots in the right column,
with their abscissa in Hz, show the magnitude of exponential Fourier coefﬁcients (|X( fn)|, where fn = n/T ), also called
spectral lines. The spectral lines represent Xn. They are located at f = n/T . As the period increases, the spectral lines
move closer to each other. (They also become smaller in magnitude. In this ﬁgure, the plots of Xn are normalized to the
same level.) The resolution in the frequency domain is the inverse of the period in the time domain. In this ﬁgure:
T = 4 msecf = 250 Hz
T = 8 msecf = 125 Hz
T = 16 msecf = 62.5 Hz
T = 400 msecf = 2.5 Hz
The envelope of the line spectrum X( fn) = T X(n/T ), however, remains relatively unchanged. At T = ∞, the frequency
f becomes continuous and the limit of the product of T Xn (Fourier series coefﬁcients) becomes X( f ), which is the
Fourier transform. See the next section.
7.17
Envelope of Fourier Coefficients
In this section we will show that the Fourier transform of one period of a periodic signal is
T times the envelope of Fourier series coefﬁcients of the periodic signal, with f = n/T .
A periodic signal x(t) with period T may be considered the result of convolving a time-
limited pulse h(t) with an inﬁnite train of unit impulses arriving every T seconds [to be
called s(t)]. See Figure 7.12.
x(t) = h(t) ⋆s(t) = h(t) ⋆
∞

n=−∞
δ(t −nT ) =
∞

n=−∞
h(t −nT )
where h(t) is one cycle of x(t):
h(t) =

x(t),
t0 < t < t0 + T
0,
elsewhere
The convolution in time between h(t) and s(t) can be performed as a product in
the frequency domain; that is, X( f ) = H( f )S( f ), where H( f ) and S( f ) are Fourier
transforms of h(t) and s(t), respectively. The transform of the impulse train is
S( f ) = 1
T
∞

n=−∞
δ( f −nf0)
where f0 = 1
T . Therefore,
X( f ) = H( f )
T
∞

n=−∞
δ( f −nf0) = 1
T
∞

n=−∞
H(nf0)δ( f −nf0) =
∞

n=−∞
Xnδ( f −nf0)

Signals and Systems
411
It is seen that the Fourier coefﬁcients of the periodic signal are samples of the Fourier
transform of a single cycle taken every f0 Hz and divided by T .
Xn = 1
T H( f )

f =nf0 = 1
T H( f )

f =n/T
(a) A single pulse in the time domain and the magnitude of its Fourier transform.
(b) A periodic pulse train and the magnitude of its Fourier transform with its envelope.
x(t)
–0.2
0
500
1,000
1,500
Time (s)
2,000
2,500
3,000
3,500
0
1
h(t)
–0.2
–1,500 –1,000
–500
0
Time (s)
500
1,000
1,500
0
1
|H(f)|
–12
–8
–4
0
Frequency (mHz)
4
8
12
0
1
|X(f)|
–12
–8
–4
0
Frequency (mHz)
4
8
12
0
0.001
FIGURE 7.12 A single pulse and the normalized magnitude of its Fourier transform are shown in (a). The Fourier
transform of the periodic pulse in (b) is made of impulses in the frequency domain. The envelope of the tip of the impulses
is the Fourier transform of the single pulse multiplied by 1/T . Time functions are in the left column and transforms
in the right. The period of the time function in this ﬁgure is T = 1000 seconds. It results in the frequency resolution
f = 1/T = 1 mHz.
7.18
Concluding Remarks
Through the Fourier series we express a periodic signal by an ensemble of orthogonal
functions called its harmonics. By knowing the frequency behavior of an LTI system (to
be called the frequency response and presented in Chapters 8 and 9), we can examine
the effect of passing each harmonic, and then the entire ensemble, through the system.
This chapter has emphasized the exponential form of the expansion because of its close
relationship with the Fourier transform. In fact, as will be seen in the next chapter,
by introducing impulse functions to represent periodic time functions in the frequency
domain, we will develop a uniﬁed form of the Fourier transform that will be applicable

412
CHAPTER 7
Fourier Series
to all signals. Computer software can be used to supplement analytical solutions. Such
a use is strongly recommended.
7.19
Problems
Notations
The Fourier series expansion of a waveform with period T is
x(t) = 1
2a0 +
∞

n=1
an cos(nωt) +
∞

n=1
bn sin(nωt), where ω = 2π
T ,
a0 = 2
T

T
0
x(t)dt,
an = 2
T

T
0
x(t) cos(nωt)dt,
bn = 2
T

T
0
x(t) sin(nωt)dt, n = 1, 2, . . .
in trigonometric form, and
x(t)=
∞

n=−∞
Xne j2πnt/T, Xn = 1
T

T
0
x(t)e−j2πnt/Tdt, −∞≤n ≤∞, n an integer,
in exponential form.
Relation Between Fourier Series Coefficients in Exponential
and Trigonometric Forms
Start with the exponential expansion
x(t) =
∞

n=−∞
Xne
j2πnt
T
= X0 +
∞

n=1
 
Xne
j2πnt
T
+ X−ne−j2πnt
T
!
Note that X−n is the complex conjugate of X−n [when x(t) is a real function of t as in our
case]. Therefore,
Xn = RE{Xn} + jIM{Xn}
and
X−n = RE{Xn} −jIM{Xn}
x(t) = X0 +
∞

n=1
[RE{Xn} + jIM{Xn}] e
j2πnt
T
+
∞

n=1
[RE{Xn} −jIM{Xn}] e−j2πnt
T
= X0 +
∞

n=1
2RE{Xn} cos

2πnt
T

+
∞

n=1
2 jIM{Xn} sin

2πnt
T

= a0
2 +
∞

n=1
an cos

2πnt
T

+
∞

n=1
bn sin

2πnt
T

a0 = 2X0, an = 2RE{Xn}
and
bn = 2 jIM{Xn}

Signals and Systems
413
Solved Problems
1. a. Find the exponential Fourier series expansion of the sawtooth waveform shown in Figure 7.13(a).
b. Describe how Fourier coefﬁcients of the waveforms shown in Figure 7.13(b) through (f) may be found from the
coefﬁcients of the waveform in Figure 7.13(a).
t
t
τ
(a)
(b)
(c)
(d)
(e)
(f)
T
2
T
T
t
t
τ
τ
τ
t
t
τ
FIGURE 7.13
Solution
a. Let T be the period and ±V0 represent the peak-to-peak value of the waveforms.
Xn = 1
T

T
2
−T
2
x(t)e−j2πnt
T
dt = 1
T

τ
2
−τ
2

V0
2 + V0
τ t

e−j2πnt
T
dt
= V0
2T

τ
2
−τ
2
e−j2πnt
T
dt + V0
T τ

τ
2
−τ
2
te−j2πnt
T
dt
= V0
2
sin( πnτ
T )
πn
+ V0
T τ

τ
2
−τ
2
te−αtdt, where α = j2πn
T
But

te−αtdt = −1
α e−αt

t + 1
α

,
Therefore,
Xn = V0
2
sin( πnτ
T )
πn
−
V0
αT τ

e−αt

t + 1
α
 τ
2
t=−τ
2
= V0
2
sin( πnτ
T )
πn
+ j V0
2πn

cos
πnτ
T

−
sin πnτ
T

πnτ
T


414
CHAPTER 7
Fourier Series
In summary
Xn = RE{Xn} + jIM{Xn}
RE{Xn} = V0
2
sin( πnτ
T )
πn
,
IM{Xn} =
V0
2πn

cos
πnτ
T

−
sin πnτ
T

πnτ
T

b. LetthewaveforminFigure7.13(a)be x(t)andthoseinFigure13(b)to(f)becalled yb(t), yc(t), yd(t), ye(t), yb(t),
and y f (t), respectively. To obtain Fourier coefﬁcients of the waveforms shown in Figure 7.13(b), ﬁrst construct
x(t + τ/2) + x(−t + τ/2), a triangular waveform with a base of 2τ. Find its Fourier coefﬁcients by applying time
shift, time-reversal, and superposition properties to Xn. Then, change τ to τ/2 to ﬁnd Yb (see problem 2). Then
again, in Yb let τ = T to ﬁnd Yc.
For Figure 7.13(d) to (f) we have:
yd(t) = x(t −τ/2) −x(t −3τ/2), and τ = T/2.
ye(t) = x(t −τ) −x(t −3τ)
y f (t) = yb(t −T/2) −yb(t)
2. Apply superposition, time-shift, and time-reversal properties of the Fourier series to the results of problem 1 to ﬁnd
the Fourier coefﬁcients of the triangular pulse train shown in Figure 7.13(b) (with the base = τ and height = V0).
Solution
Let x(t) be the real-valued periodic sawtooth pulse train shown in Figure 7.13(a). Then, x(t + τ/2) + x(−t + τ/2)
is a triangular pulse train with the base = 2τ and height = V0, similar to Figure 7.13(b) except for a base that is twice
as wide. To ﬁnd the Fourier coefﬁcints of the waveform of Figure 7.13(b), take the following steps:
x(t) ⇐⇒RE{Xn} + jIM{Xn}
Where,
RE{Xn} = V0
2
sin( πnτ
T )
πn
and
IM{Xn} =
V0
2πn

cos
πnτ
T

−
sin πnτ
T

πnτ
T

x(t + τ/2) ⇐⇒[RE{Xn} + jIM{Xn}] e jπnτ/T
x(−t + τ/2) ⇐⇒[RE{Xn} −jIM{Xn}] e−jπnτ/T
x(t + τ/2) + x(−t + τ/2) ⇐⇒RE{Xn} 
e jπnτ/T + e−jπnτ/T
+ jIM{Xn} 
e jπnτ/T −e−jπnτ/T
= 2RE{Xn} cos(πnτ/T ) −2IM{Xn} sin(πnτ/T )
= V0
πn sin
πnτ
T

cos
πnτ
T

−V0
πn

cos
πnτ
T

sin
πnτ
T

−
sin2  πnτ
T

πnτ
T

= V0T
τ

sin πnτ
T

πn
2
Finally, change τ to τ/2 to ﬁnd the Fourier coefﬁcients of the waveform of Figure 7.13(b):
Yb = 2V0T
τ

sin  πnτ
2T

πn
2
This is in agreement with the result obtained in Example 7.6.

Signals and Systems
415
3. Find the ﬁrst 10 coefﬁcients Xn, n = 1, 2 . . . , 10 in the exponential Fourier series expansion of a 1-kHz periodic
rectangular pulse train with a base-to-peak voltage of 0 to k volts and a pulse width k/10 msec for (a) k = 1, and
(b) k = 2. Choose time reference so that the pulse train is represented by an even function.
Solution
Xn = k
πn sin

πnk
10

a. k = 1
Xn = 1
πn sin
πn
10

= 10−4{1000
↑
, 984, 935, 858, 757, 637, 505, 368, 234, 109, 0}
b. k = 2
Xn = 2
πn sin
πn
5

= 10−4{4000
↑
, 3742, 3027, 2018, 935, 0, −624, −865, −757, −416, 0}
4. Matlab ﬁle for Example 7.1 is given below. Add commands to obtain and save all plots in Figure 7.10. Run the
program and reproduce the plots.
T=2; w=2*pi/T; N=1000; t=linspace(-T,T,2*N*T); z=0*t; tt=0;
for i=1:2*N*T/4;
tt(i)=t(i)+T;
end
for i=2*N*T/4+1:6*N*T/4;
tt(i)=t(i);
end
for i=6*N*T/4+1:2*N*T;
tt(i)=t(i)-T;
end
x1=(2/pi)*sin(w*t);
figure(1)
plot(t,x1,'r','LineWidth',2); hold on
plot(t,z,'b','LineWidth',1); plot(t,tt,'b','LineWidth',2); hold off
axis([-T/2 T/2 -1.2 1.2]); xlabel('Time(s)'); ylabel('x(t)');
title('Approximating a periodic sawtooth by the first harmonic.'); grid
print -dpsc
Ch7«Ex1«Fig1«a1.eps
e1=x1-tt; E1=e1.√(2); AE1=sum(E1)/(2*N*T);
%
x2=(2/pi)*(sin(w*t)-(1/2)*sin(2*w*t));
e2=x2-tt; E2=e2.√(2); AE2=sum(E2)/(2*N*T);
%
x3=(2/pi)*(sin(w*t)-(1/2)*sin(2*w*t)+(1/3)*sin(3*w*t));
e3=x3-tt; E3=e3.√(2); AE3=sum(E3)/(2*N*T);
%
x4=(2/pi)*(sin(w*t)-(1/2)*sin(2*w*t)+(1/3)*sin(3*w*t)-(1/4)*sin(4*w*t));
e4=x4-tt; E4=e4.√(2); AE4=sum(E4)/(2*N*T);
%
x5=(2/pi)*(sin(w*t)-(1/2)*sin(2*w*t)+(1/3)*sin(3*w*t)-(1/4)*sin(4*w*t)+(1/5)
*sin(5*w*t));
e5=x5-tt; E5=e5.√(2); AE5=sum(E5)/(2*N*T);

416
CHAPTER 7
Fourier Series
%
AE=[AE1 AE2 AE3 AE4 AE5]
5. Matlab ﬁle for Example 7.2 is given below. Add commands to obtain and save all plots in Figure 7.2. Run the
program and reproduce the plots.
T=2; w=2*pi/T; N=1000; t=linspace(-T,T,2*N*T); z=0*t; p=0*t;
for i=1:2*N*T/8;
p(i)=2;
end
for i=6*N*T/8+1:10*N*T/8 ;
p(i)=2;
end
for i=14*N*T/8+1:2*N*T;
p(i)=2;
end
tt=p-1;
%
x1=
(4/pi)*cos(w*t) ;
x2=
(4/pi)*(cos(w*t)-(1/3)*cos(3*w*t)) ;
x3=
(4/pi)*(cos(w*t)-(1/3)*cos(3*w*t)+(1/5)*cos(5*w*t)) ;
x4=
(4/pi)*(cos(w*t)-(1/3)*cos(3*w*t)+(1/5)*cos(5*w*t)-(1/7)*cos(7*w*t)) ;
x5=
(4/pi)*(cos(w*t)-(1/3)*cos(3*w*t)+(1/5)*cos(5*w*t)-(1/7)*cos(7*w*t)
+(1/9)
*cos(9*w*t)) ;
%
e1=x1-tt; E1=e1.√(2); AE1=sum(E1)/(2*N*T);
e2=x2-tt; E2=e2.√(2); AE2=sum(E2)/(2*N*T);
e3=x3-tt; E3=e3.√(2); AE3=sum(E3)/(2*N*T);
e4=x4-tt; E4=e4.√(2); AE4=sum(E4)/(2*N*T);
e5=x5-tt; E5=e5.√(2); AE5=sum(E5)/(2*N*T);
AE=[AE1 AE2 AE3 AE4 AE5]
Chapter Problems
6. Find the trigonometric Fourier series for a 1-kHz square wave with a peak-to-peak voltage spanning −1 to 1 volts
(0 DC value, 50% duty cycle). Choose the time origin so that the series contains (a) cosine terms only and (b) sine
terms only.
7. The four periodic signals shown in Figure 7.14(a), (b), (c), and (d) are to be expanded in trigonometric Fourier
series. For each signal determine if statements 1, 2, and 3 given below are true or false.
Statement 1. The time origin may be chosen such that an = 0, n ≥1.
Statement 2. The time origin may be chosen such that bn = 0, n ≥0.
Statement 3. The baseline (zero level) may be chosen such that a0 = 0.

Signals and Systems
417
t
t
(a)
t
t
(c)
(d)
(b)
FIGURE 7.14 (For Problem 7)
8. Consider a 1-kHz periodic rectangular pulse signal. For each case given below, determine pulse width τ in msec
such that the signal contains no harmonics at the listed frequencies (k is an integer).
a. No harmonics at 2k kHz.
b. No harmonics at 4k kHz.
c. No harmonics at 8k kHz.
9. a. Represent the waveform x(t) = sin t + sin(t + π/4) by its trigonometric Fourier series.
b. Let y(t) = x(t −t0). Specify a value for t0 so that the trigonometric representation of y(t) contains (i) an or (ii)
bn only.
10. Shift x(t) = A sin ω0t + B sin(ω0t −θ) by t0 seconds so that its trigonometric Fourier series contains (i) an or (ii)
bn only. In each case determine t0 as a function of A, B, ω0, and θ.
11. DescribethewaveformsshowninFigure7.15intermsofaperiodicrectangularwaveformandobtaintheirexponential
Fourier coefﬁcients. Assume period T and a peak-to-peak value of ±1.
τ
τ
τ
(a)
(b)
t
t
τ
τ
τ
FIGURE 7.15 (For Problem 11)

418
CHAPTER 7
Fourier Series
(c)
t
τ
τ
τ
FIGURE 7.15 (Continued)
12. Find the trigonometric Fourier coefﬁcients of a periodic rectangular voltage with T = 100 µs, τ = 40 µs, and a
peak-to-peak value of ±1 volt.
13. Effect of pulse width. Find the exponential Fourier coefﬁcients of a periodic rectangular waveform with period
T = 1 ms and a peak-to-peak value of ±1 volt for the following pulse width τ:
a. 500 µs.
b. 200 µs.
c. 100 µs.
d. 10 µs.
e. 1 µs.
14. Effect of pulse width. (i) Find the exponential coefﬁcients of Fourier expansion of a periodic rectangular waveform
with T = 1 ms and a peak-to-peak value of ±V0 volt for the following cases:
a. τ = 500 µs and V0 = 1 volt.
b. τ = 200 µs and V0 = 2.5 volts.
c. τ = 100 µs and V0 = 5 volts.
d. τ = 10 µs and V0 = 50 volts.
e. τ = 1 µs and V0 = 500 volts.
(ii) In each case determine which harmonic is the ﬁrst to be zero. Relate it to the pulse width τ.
15. Effect of period. Find the exponential coefﬁcients of Fourier expansion of a periodic rectangular waveform with
pulse duration of τ = 1 µs and a peak-to-peak value of ±1 volt, for the period T being:
a. 2 µs.
b. 5 µs.
c. 10 µs.
d. 100 µs.
e. 200 µs.
16. Effect of period. (i) Find the exponential Fourier coefﬁcients of a periodic rectangular waveform with pulse width
τ = 1 µs and a peak-to-peak value of ±V0 volt for the following cases:
a. T = 2 µs and V0 = 1 volt.
b. T = 5 µs and V0 = 2.5 volts.
c. T = 10 µs and V0 = 5 volts.
d. T = 100 µs and V0 = 50 volts.
e. T = 200 µs and V0 = 100 volts.
(ii) In each case determine which harmonic is the ﬁrst to be zero. Relate it to the pulse width τ.

Signals and Systems
419
17. Express, as a function of τ, the exponential Fourier coefﬁcients of a periodic rectangular waveform with T = 1 s, a
base-to-peak value of V0 volts and pulse width τ = 1/V0. Find lim
τ→0 Xn.
18. Find the exponential Fourier series for a 10-kHz periodic rectangular waveform with a base-to-peak voltage of 0 to
2 volts and a duty cycle of δ, changing from 10% to 90% in step of 10%. In all cases choose the time origin so that
the series results in even functions.
19. Repeat problem 18 but this time with a base-to-peak value of V0 = 1/τ so that the area of the pulse remains unity
independent of the duty cycle.
20. Find the exponential Fourier series coefﬁcients of a periodic even-square pulse signal (50% duty cycle, zero DC
value). Then shift the signal by a half-period and add its series coefﬁcients to those of the original signal. Verify that
the sum is zero for all values of n.
21. Find the exponential Fourier series coefﬁcients of a periodic square wave voltage having a 1 V base-to-peak value
(0.5 V DC level, 50% duty cycle). Then shift the signal by a half-period and add its series coefﬁcients to those of
the original signal. Verify that the sum is zero for all n, except at n = 0 for which it is 1.
22. Find the exponential Fourier coefﬁcients of a periodic signal x(t) made of rectangular pulses (height = V0, duration
= τ, period = T). Find and plot the envelope of Xn for
a. V0 = 1 V, τ = 1 msec, and T = 2 msec.
b. V0 = 5 V, τ = 1 msec, and T = 10 msec.
c. V0 = 100 V, τ = 1 msec, and T = 200 msec.
23. Consider a rectangular pulse train with a period of 4 µsec and a base-to-peak value of 1 V. Find the exponential
Fourier coefﬁcients of the pulse train when the duty cycle is (a) 25%, (b) 50%, and (c) 75%. In each case evaluate
the ﬁrst seven coefﬁcients Xn, n = 0, . . . , 6.
24. Find the trigonomteric Fourier series coefﬁcients of the periodic signals shown in Figure 7.13(a) to −f for T =
200 µs, τ = 20 µs, and a peak-to-peak value of 3 V. In each case anticipate the form of the series from the possible
symmetry property of the signal.
25. Find the exponential Fourier coefﬁcients Xn for the periodic rectangular waveform of Figure 7.15(a) with T =
2 msec, τ = 0.5 msec, and V0 = 1 V. Evaluate the magnitude and phase of the ﬁrst three non-zero coefﬁcients
Xn, n ≥0. Compute the DC power and average power in the ﬁrst two nonzero harmonics and give their percentage
share of the total power.
26. A periodic rectangular voltage pulse train (frequency = 1 kHz, amplitude = 1 V, pulse duration = 1 µs) is fed into a
series RC circuit (R = 100 , C = 10 nF). Find the DC value and amplitudes and phases of the ﬁrst six harmonics
appearing across the capacitor.
27. a. A 1-kHz periodic rectangular pulse train voltage is applied to a linear time-invariant circuit speciﬁed by the
frequency response H(ω) = 1/(1 + j5 × 10−6ω). Express the input and output voltages in Fourier series forms

n A cos(nω0t + α) and 
n B cos(nω0t + β), respectively.
b. Find the DC and the ﬁrst four harmonics of the input and output.
28. Find the Fourier series coefﬁcients of the periodic signals shown in Figure 7.16(a) and (b). Assume period T = 10,
τ = 3, τ1 = 1 (all in msec), and V0 = V1 = 1 V. Hint: Use the superposition property of the Fourier series.

420
CHAPTER 7
Fourier Series
t
t
V0
–V1
0
(a)
(b)
0
V0 + V1
V0
τ1
τ
τ
FIGURE 7.16 (For Problem 28)
29. Find the exponential Fourier series coefﬁcients of a half-wave rectiﬁed sinusoid with a base-to-peak voltage of 0 to
Vo volts and frequency f . See Figure 7.17(a). The time origin is chosen such that the waveform is represented by
an even function.
T
t
t
T
2
V0
0
(a)
(b)
0
V0
–V0
FIGURE 7.17 (For Problems 29–31)
30. Repeat problem 29 for (a) a full-wave rectiﬁed waveform and (b) the waveform of Figure 7.17(b).
31. Invert the half-wave rectiﬁed sinusoid (problem 29) and shift it by a half-period. Then determine its exponential
Fourier coefﬁcients and add them to the coefﬁcients of the original signal. Verify that the sum is zero for all n except
at n = 1, for which it is equal to half of the peak value of the sinusoid.
32. a. Find the exponential Fourier coefﬁcients of a chopped sinusoid described by
v(t) =

V0 sin  2πt
T −π
4

,
−T
8 < t ≤3T
8
0,
3T
8 < t ≤7T
8
, and v(t) = v(t −T )
b. Repeat for |v(t)| where v(t) is given in (a).
33. Use a computer to solve this problem.
a. Compute numerical values of the ﬁrst 10 exponential Fourier series coefﬁcients of a half-wave rectiﬁed circle
with a unity radius and period 2. Choose the time origin so that the waveform is represented by an even function.
b. Repeat for a full-wave rectiﬁed circle.
34. Power in a signal is controlled by applying a threshold level λ to a sinusoidal source with a peak value of V0 volts.
The signal is described by
x(t) =

sin ωt −λ,
if sin ωt > λ
0,
otherwise

Signals and Systems
421
Let V0 =
√
2 and λ = 1. Use a computer to obtain numerical values of:
a. the average power in x(t),
b. its exponential Fourier coefﬁcients Xn, n = 0, 1, . . . , 9,
c. the percentage of power in the principal harmonic.
35. A single pulse is made of the partial sinusoid and described by
x(t) =

V0 cos πt
T

,
T
2 −τ < t < T
2
0,
elsewhere
See Figure 7.18.
T
V0
0
τ
FIGURE 7.18 (For Problem 35)
Find exponential Fourier coefﬁcients of the following periodic functions made of the pulse of part
a. ya(t) =
∞

n=−∞
x(t −2nT )
b.
yb(t) =
∞

n=−∞
(−1)nx(t −nT )
Then, in each case ﬁnd the percentage of power in the principal harmonic.
36. Verify even-symmetry property of the periodic waveforms shown in Figure 7.19 and ﬁnd their trigonometric Fourier
series.
1
Amplitude
–2 –1.5
–0.5
0.5
1.5
2
1
–1
0
Time (s)
0
(a) An even half-circle pulse train
1
Amplitude
–6
–2
2
6
4
–4
0
Time (s)
0
(b) An even sinc function
1
Amplitude
–3
–1
1
3
2
–2
0
Time (s)
(c) An even bilateral exponential function
0
FIGURE 7.19 Waveforms with even symmetry: x(t) = x(−t).
37. Verify odd-symmetry property of the periodic waveforms shown in Figure 7.20 and ﬁnd their trigonometric Fourier
series.

422
CHAPTER 7
Fourier Series
1
Amplitude
–2
–1.5
–0.5
0.5
1.5
2
1
–1
0
Time (s)
0
(a) An odd sawtooth pulse train
–1
1
Amplitude
–1
–5
–3
1
5
4
–4
0
Time (s)
0
(b) Signum function
–2 –1
2
3
1
Amplitude
–1
–3
–1
1
3
2
–2
0
Time (s)
(c) An odd bilateral exponential function
0
FIGURE 7.20 Waveforms with odd symmetry: x(t) = −x(−t).
38. Verify half-wave symmetry property of the periodic waveforms shown in Figure 7.21 and ﬁnd their trigonometric
Fourier series.
1
Amplitude
–2 –1.5
–0.5
0.5
1.5
2
1
–1
0
Time (s)
0
(a) A half-symmetric function
–1
2
1.5
1
0.5
Amplitude
–0.5
–1
–1.5
–2
–2
–1
0.5
2
–1.5
0
Time (s)
0
(b) A half-symmetric function
–0.5
1
1.5
1
Amplitude
–1
–2
–1
0.5
2
1
–1.5
0
Time (s)
(c) An odd function that is half-symmetric
0
–0.5
1.5
FIGURE 7.21 Waveforms with half-wave symmetry: x(t) = −x(t + T/2).
39. Find the exponential Fourier coefﬁcients of x(t) = a(t) cos 2π fct, where fc = 100 Hz, for the two cases of a(t)
given below. In each case sketch the two-sided spectrum, label important points, and determine whether x(t) is
band-limited.
a. a(t) = cos 2π f1t + sin 2π f2t, f1 = 10 Hz and f2 = 20 Hz.
b. a(t) = 3 + 2 cos 2π f1t + cos 2π f2t, f1 = 15 Hz and f2 = 30 Hz.
40. The exponential Fourier series coefﬁcients of a periodic signal x(t) are
Xn =



1.57,
n = 0
0,
n even and ̸= 0
(−1)(n−1)/2
n
,
n odd
a. Find the DC power (n = 0), the average power in the fundamental frequency (n = 1), and the average power in
the third harmonic (n = 3).
b. Determine x(t) as a function of ω0t.
c. Find the total average power < x2(t) > and the number of harmonics that approximate the total power within a
1% error band.
41. An LTI system has a ﬁnite-duration unit-impulse response, lasting from t = 0 to τ. Given the exponential Fourier
series coefﬁcients of the system’s response to a train of unit impulses arriving every τ seconds, can you ﬁnd the
Fourier series coefﬁcients of its response to a train of unit impulses arriving every T > τ seconds? If the answer is
positive, show how that could be done. If the answer is negative, specify what additional information is needed.

Signals and Systems
423
42. The exponential Fourier series coefﬁcients of a periodic signal x(t) are Xn = (1/2)n, −∞< n < ∞. Find the
DC power (n = 0), average power in the fundamental frequency (n = 1), and the total average power < x2(t) >
or an approximation of it within an error band of less than 1%.
43. An ideal low-pass ﬁlter passes frequencies below 1 kHz without any change in their magnitude or phase, and
completely blocks frequencies above 1 kHz. The input to the ﬁlter is the periodic rectangular waveform shown in
Figure 7.4 with T = 8 and τ = 2 in msec. Find the exponential Fourier series coefﬁcients of the input and output
signals and their total average powers.
7.20
Project: Computer Explorations in Fourier
Analysis
Summary
In this project you will generate periodic time series (sine, periodic rectangular, and triangular pulses, etc.) by sampling
continuous-time signals and ﬁnding their Fourier transforms. Sampling interval T is called resolution in time. Its inverse
is Fs = 1/T and is called the sampling rate. By applying high sampling rates the discrete-time signals approximate
continuous-time signals. Computer-based software packages approximate the transform of a ﬁnite segment of the signal,
and after frequency scaling, plot it as the signal’s Fourier representation. The algorithm is called Discrete Fourier Transform
(DFT) or Fast Fourier Transform (FFT). The resolution in frequency is f = 1/T = 1/(NT ), where N is the number
of samples used in the DFT operation (i.e., T is the duration of the signal in time). By taking the DFT of long segments
of the signal you approximate the Fourier transform of the original continuous-time signal.
Notations
The following notations are used; f is the frequency in Hz, Fs is the sampling rate (samples/sec), and N is the number
of samples in a sequence.
Deliverable
The report will contain the following parts:
a. Simulation codes and resulting graphs (time and frequency plots).
b. Answers to questions and documentations of each section.
c. Your interpretation of results and observations.
d. Your conclusions.
Sinusoidal Signals
a. Generate and display one cycle of a 100-Hz sine wave at the sampling rate of Fs = 2 kHz (20 points). Note that
the time duration of the signal is N/Fs = 10 msec. This is equal to one period of the signal and generates one
full cycle of the 100-Hz sinusoid. Next, evaluate the Fourier transform (DFT) of the signal. In Matlab the FFT
command evaluates the DFT.
b. Repeat for N = 40, Fs = 2 kHz, f = 100 Hz.
c. Repeat for N = 40, Fs = 4 kHz, f = 100 Hz.
Document and interpret your results. Summarize your observations and conclusions and answer the following
questions:
a. How many lines do you see in the spectra of the signals?
b. How are the spectral lines related to the frequency and amplitude of the sinusoidal signals?

424
CHAPTER 7
Fourier Series
c. Observe similarities and differences of frequency scales in transform plots. Conclude a relationship between
sampling rate in the time domain and frequency range in the frequency domain.
Almost-Sinusoidal Signals
In this section you will generate three signals that are slightly longer than one cycle of a sinusoid. The periodic signals
will contain harmonics other than the fundamental frequency of the sine wave.
a. Generate a 100-Hz sine wave at the sampling rate of Fs = 2 kHz. Choose N = 21, which produces slightly more
than one cycle of the sinusoid. Find and display its transform.
b. Repeat for N = 22, Fs = 2 kHz, f = 100 Hz.
c. Repeat for N = 42, Fs = 4 kHz, f = 100 Hz.
As described in the summary, from the program’s point of view, the length of signals constitutes one period of operation.
The data length is T = NT , which is 10.5 msec in parts (a) and (c), and 11 msec in part (b). In either case, data length
is slightly greater than the period of the 100-Hz sinusoids. Repeating the signals a, b, and c creates almost-sinusoidal
signals with some harmonics. Summarize your observations and conclusions in order to provide answers to the following
questions:
a. How many lines do you see in the spectra of the signals?
b. Determine if the position of dominant spectral lines is related to the frequency and amplitude of the sinusoid.
c. Where are the additional frequency components located?
d. How are they inﬂuenced by the number of additional points in the time signals?
Rectangular Pulses: Effect of Pulse Width
In the following sections and throughout the rest of this project, pulse width is shown by τ.
a. Generate one cycle of a 100-Hz rectangular pulse (period T = 10 msec, pulse width τ = 5 msec) at the 20-kHz
sampling rate (producing N = 200 points) and ﬁnd its transform.
b. Repeat for T = 10 msec, τ = 2 msec, Fs = 20 kHz.
c. Repeat for T = 10 msec, τ = 1 msec, Fs = 20 kHz.
Rectangular Pulses: Effect of Period
a. Generate a rectangular pulse (period = 2 msec, pulse width = 1 msec) at a 100-kHz sampling rate. Find its
transform.
b. Repeat for T = 5, τ = 1, Fs = 100 kHz.
c. Repeat for T = 10, τ = 1, Fs = 100 kHz.
Time-Frequency Relationship
The pulses you used were speciﬁed by the following three variables in the time domain:
a. Pulse width τ, indicating concentration of energy in time.
b. Period T , indicating one cycle of the signal in time.
c. Sampling interval T = 1/Fs, indicating resolution in time.
Their transforms in the frequency domain exhibit three aspects:
a. Band width B, indicating concentration of energy in the frequency domain.
b. Frequency span F0 = Fs/2, indicating the frequency span; that is, the highest frequency in the signal.
c. Frequency increment f , indicating resolution in the frequency domain.
Note that the rectangular pulse signals contain low frequencies and the envelope of the Fourier coefﬁcients of the
rectangular pulse is approximately proportional to a ﬁnite section of the function X( f ) = sin(π f τ)
π f
sampled at frequency

Signals and Systems
425
intervals f =
1
T . The bandwidth may be deﬁned as the frequency of the ﬁrst zero crossing of X( f ), B = f0 = 1
τ . The
frequency span is F0 = Fs
2 and the frequency resolution is f = 1
T . In the above procedures you changed T, τ, and Fs in
the time domain and observed the effects on B, F0, and f in the frequency domain. Verify that your worksheets exhibit
such relationships between the above variables.
Triangular Pulses
Repeat the procedure of rectangular pulses for a train of triangular pulses. Compare the attenuation of harmonics in
rectangular and triangular pulses. Find the percentage of the total energy residing in the ﬁrst two harmonics of the
triangular pulse and compare to that for the ﬁrst two harmonics of the rectangular pulse.
Tone Burst
a. Modulate the amplitude of a 1-kHz sinusoidal signal by a rectangular pulse of width τ, sampled at the rate
of Fs = 10 kHz. Take 50 msec of the data and obtain its transform. Display the signal in time and frequency
domains. Show examples for τ = 5, 10, 20, and 50 msec.
b. Repeat for Hanning windows of width τ = 5, 10, 20, and 50 msec.
Observe and record the frequency shift and magnitude change of the spectra produced by amplitude modulation. Observe
and record the effect of the Hanning window on the bandwidth of modulated signals.
Conclusions
i. Describe the observations on the spread in spectrum of almost-sinusoidal signals.
ii. For the periodic rectangular pulse waveforms qualitatively describe relationship between line spectrum, pulse
width, and period.
iii. Repeat for triangular pulse.
iv. Describe your observations on the relationships between the Fourier series and Fourier transform.
v. Summarize your overall conclusions from this project.

Chapter8
Fourier Transform
Contents
Introduction and Summary
428
8.1
Fourier Transform of Energy Signals
429
8.2
Inverse Fourier Transform
430
8.3
Examples of Fourier Transform Pairs
430
8.4
Linearity Property
433
8.5
Conjugate Symmetry
434
8.6
Time Reversal
434
8.7
Waveform Symmetry
435
8.8
Even and Odd Parts of Functions
437
8.9
Causal Functions
439
8.10
Time-Frequency Duality
441
8.11
Time Shift
442
8.12
Frequency Shift
443
8.13
Differentiation and Integration
444
8.14
Convolution Property
444
8.15
Product Property
445
8.16
Parseval’s Theorem and Energy Spectral Density
446
8.17
Summary of Fourier Transform Properties
447
8.18
Time-Limited Signals
447
8.19
Windowing
450
8.20
Band-Limited Signals
452
8.21
Paley-Wiener Theorem
453
8.22
Gibbs’ Phenomenon
454
8.23
Fourier Transform of Power Signals
456
8.24
Fourier Transform of Generalized Functions
457
8.25
Impulse Function and Operations
458
8.26
Fourier Transform of Periodic Signals
460
8.27
Concluding Remarks
465
Appendix 8A A Short Table of Fourier Transform Pairs
465
8.28
Problems
467
8.29
Project: Spectral Analysis Using a Digital Oscilloscope
482
427

428
CHAPTER 8
Fourier Transform
Introduction and Summary
In the analysis of LTI systems, starting with a collection of known input-output pairs
made of
ξk(t) ⇒ηk(t)
we would like to ﬁnd the response to a new input. If the new input can be expressed
as a weighted sum of the members of the known input set, the output will then be the
weighted sum of the corresponding members of the output set

k
Xkξk(t) ⇒

k
Xkηk(t)
It is said that the input is expanded as a sum of signals ξk(t) within its function space
the same way that a vector is expanded as a sum of its components within its vector
space. In Chapter 7 we noted that for weighting coefﬁcients Xk to be easily calculated,
we would like the members of the set of ξk(t) to be orthogonal to each other. We chose
the exponentials e j2π f t as the building blocks for expanding a periodic signal and called
the resulting expansion the Fourier series of the signal. The choice of exponentials as the
building blocks (in addition to their orthogonality property) was motivated by the fact
that the exponentials are eigenfunctions of the linear systems. (The output has the same
functional form as the input except for a scale factor; the scale factor is easily obtained as
a function of the frequency.) The Fourier series, therefore, provides the tool necessary to
obtain the output given a periodic input signal. Moreover, the harmonics generated by the
Fourier series not only simplify the analysis, but also help us understand the operation
intuitively as they are associated with the actual frequency experienced by our senses
(auditory, visual, tactile, etc.) or by synthetic systems.
A similar reasoning applies to the case of nonperiodic signals, leading again to the
choice of exponentials as building blocks. In Chapter 7 we examined the limiting form
of the Fourier series coefﬁcients when the period of the signal is increased to inﬁnity.
Based on that, we developed the following expression for X( f ):
X( f ) =
 −∞
−∞
x(t)e−j2π f tdt
X( f ) obtained from the above integral is called the Fourier transform of x(t). Accord-
ingly, a nonperiodic signal is transformed from the time domain to the frequency domain
not in the form of a series but as a weighted integral transform. The transformation of
x(t) to X( f ) is more than a mere abstract mathematical operation that facilitates anal-
ysis and design. X( f ) reﬂects information about the physical frequency content of the
signal. It suggests that a nonperiodic function has a continuous spectrum; that is, the
signal contains a continuum of frequencies. The concept of a continuous spectrum may
seem novel and unfamiliar at ﬁrst but is easy to interpret. Instead of signal power being
concentrated at a discrete set of frequencies, such power is spread over a range of fre-
quencies. From X( f ) one can ﬁnd the power within a frequency band of a signal, its
interference with other signals, its vulnerability to noise, and so on. The Fourier transform
has widespread applications in engineering, in general, and in communications, control,

Signals and Systems
429
and signal processing, in particular. As in the case of the Fourier series, in addition to
providing a powerful and exact tool for quantitative analysis, the Fourier transform adds
an intuitive and qualitative component to understanding a process. It presents the out-
come of theoretical work as a tangible and measurable quantity. Because of the above
features, from its early inception it has been widely used and proven to be an essential
tool and the main instrument in frequency-domain analysis of signals and systems.
We note the parallels and similarities between the Fourier and Laplace transforms.
In the Laplace transform, we employ est and in the Fourier transform e jωt; that is, we
restrict s in the complex plane to the jω−axis. One may then question the need for
the Fourier transform. The answer is the same as in the case of the Fourier series: an
intimate and measurable connection between the new variable f in the Fourier transform
and the physical frequency. Although the Laplace transform provides a very powerful
analysis and design tool, it lacks such a property. The new variable s in the Laplace
transform (which is sometimes called the complex frequency) is a mathematical entity
not a transparent physical quantity.
This chapter starts with the Fourier transform of energy signals for which the integral
converges to a known value at each frequency. We ﬁrst explore the time-frequency
relationship for some continuous-time signals of common interest in signal processing.
The objective is to illustrate the practical correlates of the mathematical models of Fourier
analysis, to visualize the time-frequency relationships, and to provide the student with the
additional intuitive understanding often essential in applications. Single and repetitive
pulses of ﬁnite duration, such as rectangular and triangular pulses [as well as pulses
described by mathematical models of inﬁnite time duration such as sin(t)/t, exponential,
Gaussian, etc.], will be transformed into the frequency domain and their time-frequency
variations examined and interpreted.
With the introduction of singularities and generalized functions such as the Dirac δ
(or impulse) function, the Fourier integral may be extended to power signals as well,
resulting in the generalized Fourier transform. With this extension, the Fourier series
is viewed as a function, allowing us to treat periodic, nonperiodic, and random signals
by a uniﬁed formulation. This is a very useful and convenient tool when periodic and
nonperiodic functions are encountered simultaneously.
The project proposed at the end of the chapter can be implemented by either using
software or within the real time, in actual laboratory environment using equipment such
as a function generator, a digital oscilloscope, or a spectrum analyzer. Assuming access
to such a laboratory is available, the second approach is strongly recommended.
8.1
Fourier Transform of Energy Signals
The Fourier transform of a function x(t) is deﬁned as
FT {x(t)} ≡X( f ) =
 ∞
−∞
x(t)e−j2π f tdt
This deﬁnition requires the integral to converge for all f . For most functions of inter-
est in engineering (called “good functions” or “well-behaved functions”), the integral

430
CHAPTER 8
Fourier Transform
converges and the Fourier transform exists. One set of sufﬁcient conditions that guaran-
tees the convergence of the transform is called the Dirichlet conditions.
The ﬁrst Dirichlet condition requires that x(t) be absolutely integrable:
 ∞
−∞
| x(t) | dt < ∞
The second Dirichlet condition requires that x(t) have a ﬁnite number of discontinuities
and a ﬁnite number of maxima and minima during every ﬁnite interval.
Notation
In this book the time functions are real-valued (unless speciﬁed otherwise). X( f ) is
then a real function of the variable j2π f and, therefore, a complex function of f . For
simplicity, however, we use the notation X( f ) rather than the more informative notation
X( j2π f ).
In Cartesian form X( f ) is represented by its real and imaginary parts:
X( f ) = RE{X( f )} + jIM{X( f )}
It may also be represented in polar form by its magnitude and phase:
X( f ) = |X( f )|e j̸
X( f ) = |X( f )|̸ X( f ),
where
|X( f )| =

RE{X( f )}2 + IM{X( f )}2
and
̸ X( f ) = tan−1 IM{X( f )}
RE{X( f )}
X( f ) is said to represent the frequency components of the time function x(t), reminiscent
of harmonic analysis of periodic signals by the Fourier series.
8.2
Inverse Fourier Transform
If the Fourier integral converges, then x(t) is called the inverse Fourier transform of
X( f ) and is obtained from the following integral:
x(t) =
 ∞
−∞
X( f )e j2π f td f
More precisely,
lim
F→∞
 F
−F
X( f )e j2π f td f = x(t−) + x(t+)
2
Note the lack of rigor or conditions, such as the Dirichlet conditions, for the convergence
of the integral representing the inverse transform.
8.3
Examples of Fourier Transform Pairs
In this section we present three examples of transform pairs and observe some of their
properties.

Signals and Systems
431
Example
8.1
Rectangular and triangular pulses
Find the Fourier transforms of
a.
x(t) =

V0,
−τ
2 < t < τ
2
0,
elsewhere
b.
x(t) =

V1

1 −2 |t|
τ

,
−τ
2 < t < τ
2
0,
elsewhere
Solution
a.
X( f ) =
 τ/2
−τ/2
V0e−j2π f tdt =
V0
j2π f

e jπ f τ −e−jπ f τ
= V0
sin(π f τ)
π f
b.
X( f ) = V1
 0
−τ/2

1 + 2 t
τ
	
e−j2π f tdt + V1
 τ/2
0

1 −2 t
τ
	
e−j2π f tdt
= 2V1
τ

sin(π f τ/2)
π f
2
The pairs are plotted in Figure 8.1(a) and (b), respectively. The signals are even
functions: x(t) = x(−t). The transforms are real functions of f . The transforms of
these pulses will be discussed in more detail in section 8.18.
(a)
(b)
f
x(t)
X(f)
0
Time (s)
Frequency (Hz)
t
V1
t
2
t
–
2
t
t
2
4
t
V1
0
t
f
x(t)
V0
0
X(f)
V0
t
3
t
–
2
t
–
1
t
1
t
2
t
3
t
–
2
t
t
FIGURE 8.1 Two even time pulses (left column) and their Fourier transforms (right column). (a) Rectangular pulse. (b)
Triangular pulse.

432
CHAPTER 8
Fourier Transform
Example
8.2
Causal and anticausal exponential functions
Find the Fourier transforms of
a. x1(t) = e−atu(t),
a > 0
b. x2(t) = eatu(−t),
a > 0
Solution
Both functions are exponentials with a time constant τ = 1
a . They switch between zero
and one at t = 0. Otherwise, they are absolute-integrable, well-behaved functions.
Their transforms are
a. X1( f ) =
 ∞
0
e−ate−j2π f tdt =
1
a + j2π f ,
−∞< f < ∞
b. X2( f ) =
 0
−∞
eate−j2π f tdt =
1
a −j2π f ,
−∞< f < ∞
The functions and their Fourier transforms are plotted in Figure 8.2(a) and (b). Note
that x2(t) = x1(−t). The transforms are related by X2( f ) = X1(−f ).
(b)
x1(t)
1.2
1
0.8
0.6
0.4
0
–0.2
–4
–3
–2
–1
0
1
2
3
4
5
0.2
1.2
1
0.8
0.6
0.4
0
–0.2
0.2
–2.5 –2
–1.5 –1
0
1
1.5
2
2.5
0.5
–0.5
–2.5 –2
–1.5 –1
0
1
1.5
2
2.5
0.5
–0.5
X1(f)
X1(0)
(a)
x2(t)
1.2
1
0.8
0.6
0.4
0
–0.2
–4
–3
–2
–1
0
Time (s)
Frequency (Hz)
1
2
3
4
5
0.2
1.2
1
0.8
0.6
0.4
0
–0.2
0.2
X2(f)
X2(0)
FIGURE 8.2 (a) and (b). One-sided exponential time functions (left column) and normalized magnitudes of their Fourier
transforms (right column). (a) Causal function x1(t), (b) Anticausal function x2(t). The abscissa show times in seconds
and frequencies in Herz. The time constants of all exponentials are 1 second. See Example 8.2.

Signals and Systems
433
(c)
(d)
x3(t)
x4(t)
1
0.8
0.6
0.4
0.2
0
–0.2
Frequency (Hz)
Time (s)
1.5
1
0.5
0
–0.5
–1.5
–4
–3
–2
–1
0
1
2
3
4
5
–1
X4(f)
X4max
1.2
1
0.8
0.6
0.4
0
–0.2
–4
–3
–2
–1
0
1
2
3
4
5
0.2
1.2
1
0.8
0.6
0.4
0
–0.2
0.2
X3(f)
X3(0)
–2.5 –2
–1.5 –1
0
1
1.5
2
2.5
0.5
–0.5
–2.5 –2
–1.5 –1
0
1
1.5
2
2.5
0.5
–0.5
FIGURE 8.2 (c) and (d). Two-sided exponential time functions (left column) and normalized magnitudes of their Fourier
transforms (right column). (c) Even function x3(t) = x1(t) + x2(t). Odd function x4(t) = x1(t) + x2(t). Note that the
magnitude plot of the transform of the sum is narrower than the sum of the magnitudes of the transforms of its components.
The abscissa show times in seconds and frequencies in hertz. The time constants of all exponentials are 1 second. For
derivations of the transforms of the two-sided exponentials use linearity property; also see Examples 8.6 and 8.7.
8.4
Linearity Property
Linearity is an important property of the Fourier transform. It states that given
x(t) ⇐⇒X( f )
and
y(t) ⇐⇒Y( f )
then
ax(t) + by(t) ⇐⇒aX( f )+bY( f ), for any x, y, and constants a and b.
This property is derived from the deﬁnition of the Fourier transform.
Example
8.3
Find the Fourier transform of
x(t) =



2,
−2 < t < 2
−1,
2 < |t| < 4
0,
elsewhere

434
CHAPTER 8
Fourier Transform
Solution
Let x(t)=x1(t)−x2(t), where x1(t)=

3,
−2 < t < 2
0,
elsewhere
and x2(t)=

1,
−4 < t < 4
0,
elsewhere
Using the linearity property and the result of Example 8.1 we ﬁnd
X( f ) = X1( f ) −X2( f ) = 3sin(4π f )
π f
−sin(8π f )
π f
= sin(4π f )
π f
[3 −2 cos(4π f )]
8.5
Conjugate Symmetry
If x(t) is real, then
x(t) = x∗(t) ⇐⇒X( f ) = X∗(−f )
In other words, if x(t) is real then RE{X( f )} and |X( f )| are even functions of f ,
while IM{X( f )} and ̸ X( f ) are odd functions of f . Therefore, a real function x(t) is
completely speciﬁed from knowing X( f ) for f > 0. This knowledge could be in the
form of the real and imaginary parts of X( f ) or its magnitude and phase.
8.6
Time Reversal
Let the Fourier transform of x(t) be X( f ). Flip x(t) around the vertical axis at t = 0
and you get a new function x(−t). The Fourier transform of x(−t) is X(−f ). Reversing
a time function reverses its transform.
x(t) ⇐⇒X( f )
x(−t) ⇐⇒X(−f )
Proof
In the expression for the Fourier transform of y(t) = x(−t) change the variable t to −τ.
The result is X(−f ).
Y( f ) =
 ∞
−∞
y(t)e−j2π f tdt =
 ∞
−∞
x(−t)e−j2π f tdt =
 ∞
−∞
x(τ)e j2π f τdτ = X(−f )
Example
8.4
Fourier transform of even and odd parts of a
rectangular pulse
Find the Fourier transform of x(t) = u(t) −u(t −τ/2). Then, use time-reversal
property to ﬁnd Fourier transforms of its even and odd parts.

Signals and Systems
435
Solution
a.
x(t) =

1,
0 < t < τ
2
0,
elsewhere
X( f ) =

τ
2
0
e−j2π f tdt =
1
j2π f

1 −e−jπ f τ
= sin(π f τ)
2π f
−j sin2( π f τ
2 )
π f
b.
xe(t) = x(t) + x(−t)
2
,
Xe( f ) = X( f ) + X(−f )
2
= sin(π f τ)
2π f
}
c.
xo(t) = x(t) −x(−t)
2
,
Xo( f ) = X( f ) −X(−f )
2
= −j sin2( π f τ
2 )
π f
Example
8.5
Exponential functions revisited
Consider the exponential functions of Example 8.2.
x1(t) = e−atu(t),
a > 0
X1( f ) =
1
a + j2π f =
a
a2 + 4π2 f 2 −j
2π f
a2 + 4π2 f 2
=
1

a2 + 4π2 f 2
̸ −tan−1
2π f
a
	
x2(t) = eatu(−t),
a > 0
X2( f ) =
1
a −j2π f =
a
a2 + 4π2 f 2 + j
2π f
a2 + 4π2 f 2
=
1

a2 + 4π2 f 2
̸ tan−1
2π f
a
	
Note that in both cases RE{X( f )} and |X( f )| are even functions of f , while
IM{X( f )} and ̸ X( f ) are odd functions of f .
8.7
Waveform Symmetry
Even Function
A function x(t) is even if x(t) = x(−t). The Fourier transform of an even function is
X( f ) =
 ∞
−∞
x(t)e−j2π f tdt =
 ∞
0
x(t)[e j2π f t+e−j2π f t]dt = 2
 ∞
0
x(t) cos(2π f t)dt
If x(t) is real and even, its transform X( f ) is a real and even function of f .

436
CHAPTER 8
Fourier Transform
Example
8.6
Two-sided even exponential function
x(t) = e−a|t|,
a > 0
X( f ) =
 0
−∞
eate−j2π f tdt +
 ∞
0
e−ate−j2π f tdt
=
1
a −j2π f +
1
a + j2π f =
2a
a2 + 4π2 f 2
The Fourier transform pair is plotted in Figure 8.2(c). The function x(t) is related to
x1(t) and x2(t) in Example 8.2, and their transforms X1( f ) and X2( f ), by
x(t) = x1(t) + x2(t)
X( f ) = X1( f ) + X2( f )
In addition, note that X( f ) is a real and even function of f :
X( f ) = X(−f ). This
is to be expected as x(t) is an even function.
Odd Function
A function x(t) is said to be odd if x(t) = −x(−t). The Fourier transform of an odd
function is
X( f ) =
 ∞
−∞
x(t)e−j2π f tdt =
 ∞
0
x(t)

−e j2π f t + e−j2π f t
dt
= −2 j
 ∞
0
x(t) sin(2π f t)dt
If x(t) is real and odd, its transform X( f ) is purely imaginary and an odd function
of f .
Example
8.7
Two-sided odd exponential function
x(t) = e−atu(t) −eatu(−t), a > 0
X( f ) =
 0
−∞
−eate−j2π f tdt +
 ∞
0
e−ate−j2π f tdt
=
−1
a −j2π f +
1
a + j2π f =
−j4π f
a2 + 4π2 f 2
The Fourier transform pair is plotted in Figure 8.2(d). The function x(t) is related to
x1(t) and x2(t) in Example 8.2, and their transforms X1( f ) and X2( f ), by
x(t) = x1(t) −x2(t)
X( f ) = X1( f ) −X2( f )

Signals and Systems
437
Inaddition,notethat X( f )isanimaginaryandoddfunctionof f : X( f ) = −X(−f ).
This is to be expected as x(t) is an odd function.
Summary of Symmetry Property
x(t) is real and even
⇐⇒
X( f ) is real and even
x(t) is real and odd
⇐⇒
X( f ) is imaginary and odd
8.8
Even and Odd Parts of Functions
Anyfunction x(t)mayberepresentedbythesumoftwocomponents x(t) = xe(t)+xo(t),
where xe(t) is an even function [called the even part of x(t)] and xo(t) is an odd function
[called the odd part of x(t)]. The even and odd parts of a function are uniquely determined
from x(t) by
xe(t) = x(t) + x(−t)
2
xo(t) = x(t) −x(−t)
2
Example
8.8
Derive the expressions for xe(t) and xo(t) from x(t) and x(−t), and relate them in
the frequency domain.
Solution
Let x(t) = xe(t)+xo(t). Then, x(−t) = xe(−t)+xo(−t). But by deﬁnition, xe(−t) =
xe(t) and xo(−t) = −xo(t). Therefore, x(−t) = xe(t) −xo(t). By adding x(t)
and x(−t) we get x(t) + x(−t) = 2xe(t). By subtracting x(−t) from x(t) we get
x(t) −x(−t) = 2xo(t). These give the results that were stated before, that is
xe(t) = x(t) + x(−t)
2
xo(t) = x(t) −x(−t)
2
The even and odd parts of a real function are related to the real and imaginary parts
of its transform.
x(t)
⇐⇒
X( f ) = RE{X( f )} + jIM{X( f )}
x(−t)
⇐⇒
X(−f ) = RE{X( f )} −jIM{X( f )}
xe(t) = x(t) + x(−t)
2
⇐⇒
X( f ) + X(−f )
2
= RE{X( f )}
xo(t) = x(t) −x(−t)
2
⇐⇒
X( f ) −X(−f )
2
= jIM{X( f )}

438
CHAPTER 8
Fourier Transform
Example
8.9
Find the even and odd parts of the causal exponential function
x(t) = e−atu(t),
a > 0
Solution
We ﬁrst ﬁnd x(−t)
x(−t) = eatu(−t),
a > 0
from which
xe(t) = x(t) + x(−t)
2
= 1
2{e−atu(t) + eatu(−t)} = 1
2e−a|t|
xo(t) = x(t) −x(−t)
2
= 1
2

e−atu(t) −eatu(−t)

Example
8.10
Find the Fourier transform of the even part of the causal exponential function x(t) =
e−atu(t), a > 0.
xe(t) = x(t) + x(−t)
2
= 1
2e−a|t|
Solution
From Example 8.6 we ﬁnd the Fourier transform of xe(t) to be
Xe( f ) =
a
a2 + 4π2 f 2
The transforms are related by
Xe( f ) = X( f ) + X(−f )
2
= RE{X( f )}
Note that Xe( f ) is a real and even function of f :
Xe( f ) = Xe(−f ).
Example
8.11
Find the Fourier transform of the odd part of the causal exponential function x(t) =
e−atu(t), a > 0.
xo(t) = 1
2

e−atu(t) −eatu(−t)

Solution
From Example 8.7 we ﬁnd the Fourier transform of xo(t) to be
Xo( f ) =
−j2π f
a2 + 4π2 f 2
The transforms are related by
Xo( f ) = X( f ) −X(−f )
2
= jIM{X( f )}
Note that Xo( f ) is imaginary and an odd function of f : Xo( f ) = −Xo(−f ).

Signals and Systems
439
8.9
Causal Functions
Time Domain
A function that is zero for t < 0 is called causal. A causal function is completely speciﬁed
by its even or odd part. To ﬁnd the casual function x(t) in terms of xe(t) or xo(t), we
note that:
1.
For t < 0 we have
x(t) = xe(t) + xo(t) = 0 which gives
xe(t) = −xo(t), t < 0
2.
From summetry property we have
xe(t) = xe(−t) and
xo(t) = −xo(−t) for all t
3.
Combining the above results we get
xe(t) = xo(t), t > 0
x(t) =

2xe(t) = 2xo(t),
t > 0
0,
t < 0
Frequency Domain
In Example 8.8 it was observed that the even and odd parts of a (real) function are related
to the real and imaginary parts of its transform by the following:
x(t) ⇐⇒X( f ) = RE{X( f )} + jIM{X( f )}
xe(t) ⇐⇒RE{X( f )}
xo(t) ⇐⇒jIM{X( f )}
In addition, if the function is causal, the real and imaginary parts of the transform are not
independent from each other either. Given either one, the other may be found through a
trip to the time domain as shown in Example 8.12.
Example
8.12
Even and odd parts of a causal rectangular
pulse in time and frequency
a.
Find the even and odd parts of a causal rectangular pulse x(t)=

1,
0<t< τ
2
0,
elsewhere
b.
Find the Fourier transform of x(t).
c.
Find the Fourier transform of the even part of x(t) and verify its equivalence
with RE{X( f )}.
d.
Find the Fourier transform of the odd part of x(t) and verify its equivalence
with jIM{X( f )}.

440
CHAPTER 8
Fourier Transform
Solution
a. We ﬁrst ﬁnd
x(−t) =

1,
−τ
2 < t < 0
0,
elsewhere
from which
xe(t) = x(t) + x(−t)
2
=
 1
2,
−τ
2 < t < τ
2
0,
elsewhere
and
xo(t) = x(t) −x(−t)
2
=







−1
2,
−τ
2 < t < 0
1
2,
0 < t < τ
2
0,
elsewhere
b.
x(t) =

1,
0 < t < τ
2
0,
elsewhere
X( f ) =

τ
2
0
e−j2π f tdt =
1
j2π f

1 −e−jπ f τ
= sin(π f τ)
2π f
−j sin2( π f τ
2 )
π f
c. xe(t) =

1
2,
−τ
2 < t < τ
2
0,
elsewhere
Xe( f ) = 1
2

τ
2
−τ
2
e−j2π f tdt = sin(π f τ)
2π f
= RE{X( f )}
d. xo(t) =





−1
2,
−τ
2 < t < 0
1
2,
0 < t < τ
2
0,
elsewhere
Xo( f ) = −1
2
 0
−τ
2
e−j2π f tdt + 1
2

τ
2
0
e−j2π f tdt
= −j sin2( π f τ
2 )
π f
= jIM{X( f )}
Given Xe( f ) one can ﬁnd its inverse xe(t), from which one can then ﬁnd xo(t)
and the transform Xo( f ). By a similar process one can ﬁnd Xe( f ) from Xo( f ).
Example
8.13
Even and odd parts of a causal exponential
function in time and frequency
Repeat Example 8.12 for the causal exponential function x(t) = e−atu(t),
a > 0.
Solution
a.
x(t) = e−atu(t)
X( f ) =
1
a + j2π f =
a
a2 + 4π2 f 2 −j
2π f
a2 + 4π2 f 2
b.
xe(t) = 1
2e−a|t|
Xe( f ) =
a
a2 + 4π2 f 2 = RE{X( f )}
c.
xo(t) = 1
2

e−atu(t) −eatu(−t)

Xo( f ) = −j
2π f
a2 + 4π2 f 2 = jIM{X( f )}

Signals and Systems
441
As in Example 8.12, given Xe( f ) =
a
a2+4π2 f 2 one obtains xe(t) = 1
2e−a|t|, from which
one can then ﬁnd
xo(t) =

xe(t) = 1
2e−at
t > 0
−xe(t) = −1
2eat
t < 0
and Xo( f ) = −j
2π f
a2 + 4π2 f 2
By a similar process one can ﬁnd Xe( f ) from Xo( f ).
8.10
Time-Frequency Duality
The duality property of the Fourier transform states that
x(t) ⇐⇒X( f )
X(t) ⇐⇒x(−f )
To derive the duality property, start with the deﬁnition of the transform
X( f ) =
 ∞
−∞
x(τ)e−j2π f τdτ
and change variable f to t to get
X(t) =
 ∞
−∞
x(τ)e−j2πtτdτ
Then change τ to −f to obtain
X(t) =
 ∞
−∞
x(−f )e j2πt f d f
Now compare the above expression with the deﬁnition of the inverse transform to verify
that the function x(−f ) is the Fourier transform of X(t). This property allows us to
avoid evaluating complex integrals when deriving transform pairs. For examples see the
following pairs in Appendix 8A: (b and c), (k and ℓ), (q and r).
Example
8.14
Duality and rectangular pulse
Use the duality property to ﬁnd the transform of y(t) = sin(2π f0t)/(πt).
Solution
Start with
x(t) =

1,
−τ
2 < t < τ
2
0,
elsewhere
⇒X( f ) = sin(πτ f )
π f
Apply duality property: X(t) = sin(πτt)
πt
⇒x(−f ) =

1,
−τ
2< f <τ
2
0,
elsewhere
Let τ = 2 f0
y(t) = sin(2π f0t)
πt
⇒Y( f ) =
1,
−f0< f < f0
0,
elsewhere

442
CHAPTER 8
Fourier Transform
Example
8.15
Duality and exponential function
a.
By direct application of the deﬁnition ﬁnd the inverse transform of
Y( f ) = e−af u( f ).
b.
Show that the result is in agreement with duality property.
Solution
a.
y(t) =
 ∞
−∞
Y( f )e j2π f td f =
 ∞
0
e−af e j2π f td f
=
 ∞
0
e(−a+ j2πt) f d f =
1
a −j2πt , all t
b.
Start with
x(t) = eatu(−t)
⇒
X( f ) =
1
a −j2π f , all f
Apply duality property:
X(t) =
1
a −j2πt , all t
⇐
x(−f ) = e−af u( f )
The time function obtained through application of the duality property is the same as
that obtained by direct integration in part a. It is also noted that in this example y(t)
is a complex function of time.
8.11
Time Shift
A time delay, or time shift to the right, by t0 seconds adds a negative value −2π f t0 to
the phase of the Fourier transform of a function.
x(t −t0) ⇐⇒X( f )e−j2π f t0
The additional phase delay 2π f t0 is proportional to the frequency. Conversely, when
going from the frequency domain to the time domain, a linear phase in the frequency
domain translates into a constant time delay.
Example
8.16
Given
x(t) =

1,
−τ
4 < t < τ
4
0,
elsewhere
⇒X( f ) = sin(π f τ/2)
π f
shift x(t) to the right by τ/4 and ﬁnd its Fourier transform. Verify that the result is in
agreement with the result obtained in Example 8.12(b).

Signals and Systems
443
Solution
y(t) = x(t −τ/4) =
1,
0 < t < τ
2
0,
elsewhere
Y( f ) = X( f )e−jπ f τ/2 = sin(π f τ/2)
π f
e−jπ f τ/2
= sin(π f τ)
2π f
−j sin2( π f τ
2 )
π f
[same as in Example 8.12(b)]
8.12
Frequency Shift
Multiplication of a time signal x(t) by e j2π f0t shifts the transform by f0 to the right:
x(t)e j2π f0t ⇐⇒X( f −f0)
The function x(t)e j2π f0t is not a real signal. However, by shifting X( f ) to the left and
right and adding the results together, we obtain a real signal:
X( f )
⇐⇒
x(t)
X( f −f0)
⇐⇒
x(t)e j2π f0t
X( f + f0)
⇐⇒
x(t)e−j2π f0t
X( f −f0) + X( f + f0)
2
⇐⇒
x(t)

e j2π f0t + e−j2π f0t
2

= x(t) cos(2π f0t)
The signal x(t) cos(2π f0t) is an amplitude-modulated (AM) signal. The sinusoid is the
carrier of the information contained in x(t). The last line in the above list states that
amplitude modulation by x(t) shifts X( f ) to the left and right, centering it at ± f0 where
f0 is the frequency of the sinusoidal carrier.
Example
8.17
Find the Fourier transform of y(t) = x(t) cos(2π fct), where x(t) = sin(2π f0t)
πt
, and
obtain its frequency range if f0 = 3 kHz and fc = 1 MHz.
Solution
First use time-frequency duality, then frequency shift to obtain
x(t) = sin(2π f0t)
πt
⇐⇒X( f ) =
 −∞
−∞
sin(2π f0t)
πt
e−j2π f tdt =

1, −f0< f < f0
0, elsewhere
y(t) = x(t) cos(2π fct) ⇐⇒Y( f ) = X( f −f0) + X( f + f0)
2
=
 1
2,
fc −f0 < | f | < fc + f0
0,
elsewhere

444
CHAPTER 8
Fourier Transform
8.13
Differentiation and Integration
Differentiation and integration operations on signals and their effects in the time domain
were discussed in Chapter 1. Here we summarize their effects in the transform domain.
By direct application of differentiation and integration to the inverse Fourier transform
we get
dx
dt
⇐⇒j2π f X( f )
 t
−∞
x(τ)dτ ⇐⇒X( f )
j2π f + X(0)δ( f )
2
The above spectral observation states that the high-frequency components of a signal are
ampliﬁed by differentiation and attenuated by integration. Conversely, differentiation
suppresses the DC value of a signal and integration accumulates it, making it more
pronounced. These statements agree with direct observations in the time domain on
the effects of differentiation and integration. For example, differentiation of a signal
that contains high-frequency noise will degrade it because the noise is enhanced by the
operation, and integration smoothes the noise out. Similarly, a small DC bias in the
input of an op-amp integrator will build up in the output and will eventually saturate the
op-amp.
8.14
Convolution Property
Convolution in the time domain is equivalent to multiplication in the frequency domain:
x(t) ⋆y(t)
⇐⇒
X( f )Y( f )
Proof
Convolution of two functions x(t) and h(t) is deﬁned by
y(t) = x(t) ⋆h(t) =
 ∞
−∞
x(t −τ) h(τ)dτ
The Fourier transform of y(t) is
Y( f ) =
 ∞
−∞
y(t)e−j2π f tdt =
 ∞
−∞
 ∞
−∞
x(t −τ) h(τ) e−j2π f t dτ dt
To convert the double integral to two separate integrals with single variables we change
the variable t to a new variable θ by t = τ + θ, dt = dθ, and t −τ = θ. The terms
containing the variables θ and τ in the double integral are then separated
Y( f ) =

 ∞
−∞
x(θ) e−j2πθ f dθ

×

 ∞
−∞
h(τ) e−j2π f τ dτ

= X( f )H( f )

Signals and Systems
445
The convolution property is of great importance because it establishes the frequency-
domain relationship for LTI systems:
Y( f ) = X( f )H( f )
Y( f ), X( f ),and H( f )areFouriertransformsoftheoutput,input,andimpulseresponse,
respectively.
8.15
Product Property
The product property is the dual of the convolution property. It states that multiplication
in the time domain is equivalent to convolution in the frequency domain:
x(t)y(t)
⇐⇒
X( f ) ⋆Y( f )
In other words, the Fourier transform of the product of two time functions is the same
as the convolution of their Fourier transforms:
 ∞
−∞
x(t)y(t)e−j2π f tdt =
 ∞
−∞
X( f −ϕ)Y(ϕ)dϕ
A special case exists when y(t) = z∗(t + τ), in which case,
 ∞
−∞
x(t)z∗(t + τ)e−j2π f tdt =
 ∞
−∞
X( f −ϕ)Z∗(−ϕ)e j2πϕτdϕ
Changing the variable ϕ to −µ, we obtain the generalized product property
 ∞
−∞
x(t)z∗(t + τ)e−j2π f tdt =
 ∞
−∞
X( f + µ)Z∗(µ)e−j2πµτdµ
For example, the transform of amplitude-modulated signal x(t) cos(2π fct) is found
by using product property.
x(t)
⇒
X( f )
cos(2π fct)
⇒
δ( f −fc) + δ( f + fc)
2
(See section 8.25.)
x(t) cos(2π fct)
⇒
X( f ) ⋆

δ( f −fc) + δ( f + fc)
2

=
1
2 X( f −fc) + 1
2 X( f + fc)

446
CHAPTER 8
Fourier Transform
8.16
Parseval’s Theorem and Energy
Spectral Density
The energy in a square-integrable signal is
 ∞
−∞
|x(t)|2dt
Parseval’s theorem states that the expressions for energy in the time domain and the
frequency domain are numerically identical. That is,
 ∞
−∞
|x(t)|2dt =
 ∞
−∞
|X( f )|2d f
Parseval’s theorem may be derived from the generalized product property described in
section 8.15 by letting f = τ = 0 and x(t) = z(t). Then, x(t)z∗(t) = |x(t)|2 and
 ∞
−∞
|x(t)|2dt =
 ∞
−∞
|X( f )|2d f
For a square-integrable signal, |X( f )|2 is called the energy spectral density. The energy
at frequencies within a bandwidth of f centered at the frequency f is then 2|X( f )|2f .
The energy within the low-pass band of f < f0 is obtained from the integral

f0
−f0
|X( f )|2d f = 2

f0
0
|X( f )|2d f
Similarly, the energy within the band f1 < f < f2 is
2

f2
f1
|X( f )|2d f
Example
8.18
Using Parseval’s theorem compute the energy within the 0 →1 kHz band of a 1volt,
1µs rectangular pulse and compare with its total energy.
Solution
X( f ) = sin(π f 10−6)
π f
X( f )

f =1 kHz = sin(π10−3)
π103
≈10−6 = X(0)
Energy within the 0 →1 kHz band = 2
 1,000
0
|X( f )|2d f ≈2 × 10−9 J
Total energy in the pulse =
 ∞
−∞
x2(t)dt = 10−6 J
Energy within the 1-kHz band is 1/500 of the total energy in the pulse, as one may
estimate from Figure 8.1(a).

Signals and Systems
447
8.17
Summary of Fourier Transform Properties
Some important properties of the Fourier transform are listed in Table 8.1.
TABLE 8.1 Some Important Properties of the Fourier Transform
Property
Time Domain
⇐⇒
Frequency Domain
1
Deﬁnition
x(t) =

∞
−∞
X( f )e j2π f td f
⇐⇒
X( f ) =

∞
−∞
x(t)e−j2π f tdt
2
Linearity
ax(t) + by(t)
⇐⇒
aX( f ) + bY( f )
3
Zero time
x(0)
⇐⇒

∞
−∞
X( f )d f
4
Zero frequency

∞
−∞
x(t)dt
⇐⇒
X(0)
5
Real
x(t) = x∗(t)
⇐⇒
X( f ) = X ∗(−f )
6
Even
x(t) = x(−t)
⇐⇒
X( f ) = X(−f )
7
Odd
x(t) = −x(−t)
⇐⇒
X( f ) = −X(−f )
8
Duality
X(t)
⇐⇒
x(−f )
9
Time shift
x(t −t0)
⇐⇒
X( f )e−j2π f t0
10
Frequency shift
x(t)e j2π fot
⇐⇒
X( f −f0)
11
Modulation
x(t) cos(2π f0t)
⇐⇒
X( f −f0) + X( f + f0)
2
12
Scale change
x(at)
⇐⇒
1
|a| X  f
a

13
Time reversal
x(−t)
⇐⇒
X(−f )
14
Multiplication by t
tx(t)
⇐⇒
−1
j2π
d X( f )
d f
15
Integration

t
−∞
x(τ)dτ
⇐⇒
X( f )
j2π f + X(0)δ( f )
2
16
Differentiation
dx
dt
⇐⇒
j2π f X( f )
17
Convolution

∞
−∞
x(t −τ) y(τ)dτ
⇐⇒
X( f )Y( f )
18
Multiplication
x(t)y(t)
⇐⇒

∞
−∞
X( f −ϕ) Y(ϕ)dϕ
8.18
Time-Limited Signals
A signal is called time limited if its energy is concentrated within a ﬁnite time interval
(called its duration). In a strict sense, time-limited signals have zero value outside their
duration, that is,
x(t) =

f (t),
−t1 < t < t2
0,
elsewhere

448
CHAPTER 8
Fourier Transform
The transform of a strictly time-limited signal cannot be zero over a nonzero frequency
interval. Theoretically, a time-limited signal contains all frequency components and
occupies an inﬁnite bandwidth, no matter how smoothly it grows or declines at the
edges. The narrower the pulse is in the time domain, the wider its transform is in the
frequency domain and vice versa. Therefore, a signal may only approximately be both
time limited and band limited.
Time-limited signals are of much practical interest in communication and signal pro-
cessing. For example, the digits in digital communication systems are encoded into such
signals and then sent through the channel. Windows through which the data is selected
and processed are another class of time-limited signals. Because of this, we discuss in
detail the transforms of several such signals each containing a single pulse of duration τ.
The time origin is chosen such that the signals are even or odd functions of time. We
would like to see their transforms and how widespread their spectra are. This is signal
design and of much interest in digital signal processing and digital communications.
Example
8.19
Rectangular pulse revisited
The Fourier transform of a rectangular pulse was found in Example 8.1(a).
x(t) =

1,
−τ
2 < t < τ
2
0,
elsewhere
⇐⇒X( f ) = sin(π f τ)
π f
The Fourier transform pair is plotted in Figure 8.1(a). The nonzero segment of the time
signal is a rectangular pulse of height 1 and duration τ. It has abrupt discontinuities
at the two edges with an inﬁnite rate of change. The transform X( f ) contains the
following features.
1.
X( f ) is a real and even function of f . It extends over an inﬁnite frequency
range. It switches between positive and negative values, creating an inﬁnite
number of positive and negative lobes. The zero-crossing between two
neighboring lobes occurs at regular intervals f = n/τ, where n is an integer in
the range −∞< n < ∞, n ̸= 0.
2.
The main lobe extends over the range −1/τ < f < 1/τ which corresponds to
the frequency band from 0 to f0, where f0 = 1/τ. The major part of the energy
in the signal is concentrated at low frequencies within the main lobe.
3.
The value of the transform at f = 0 is X(0) = τ which is equal to the net area
under x(t). This compares with the periodic case, where X0 is equal to the DC
value of the signal.
4.
From the equation for the inverse transform we deduce that
 ∞
−∞
X( f )d f = x(0) = 1
The total area under X( f ) is equivalent to the area of the triangle encompassed
by the main lobe. See Figure 8.1(a).

Signals and Systems
449
Example
8.20
Triangular pulse revisited
Consider the isosceles triangle of height 1 and base τ.
x(t) =

1 −2 |t|
τ ,
−τ
2 < t < τ
2
0,
elsewhere
The Fourier transform of the triangular pulse is
X( f ) =
 0
−τ/2

1 + 2t
τ
	
e−j2π f tdt+
 τ/2
0

1 −2t
τ
	
e−j2π f tdt = 2
τ

sin(π f τ/2)
π f
2
The time function and its Fourier transform are plotted in Figure 8.1(b). The time
function is continuous but its derivatives at the corners are discontinuous without
being inﬁnite. The transform X( f ) exhibits the following characteristics.
1.
X( f ) is a real and even function of f extending over the inﬁnite frequency
range and containing an inﬁnite number of lobes which are all non-negative.
The zero tangents between two neighboring lobes occur at regular intervals
f = 2n/τ, where n is an integer −∞< n < ∞.
2.
The main lobe extends over the frequency range −2/τ < f < 2/τ.
3.
The value of the transform at f = 0 is X(0) = τ/2 which is equal to the total
area under the triangular pulse.
4.
Compared to the transform of the rectangular pulse of the same duration τ, the
mathematical expression of X( f ) for the triangular pulse indicates that the main
lobe is twice wider and lobes attenuate faster with frequency. See Figure 8.1(b).
Example
8.21
Raised cosine pulse
The raised cosine pulse is deﬁned by
x(t) =

1 + cos( 2πt
τ ),
−τ
2 < t < τ
2
0,
elsewhere
The nonzero segment of the function is one cycle of a raised cosine. The pulse is the
product of a uniform rectangular window of duration τ and a cosine function with
period τ and unity DC value. At the edges both the function and its derivatives are
continuous and zero. The transform is
X( f ) =
 τ/2
−τ/2

1 + cos
2πt
τ
	 
e−j2π f tdt = sin(π f τ)
π f
+0.5sin πτ( f −f0)
π( f −f0)
+ 0.5sin πτ( f + f0)
π( f + f0)
where f0 = 1/τ is the ﬁrst zero-crossing of the transform of the rectangular window.

450
CHAPTER 8
Fourier Transform
8.19
Windowing
A window is a ﬁnite-duration pulse through which we look at a data stream or function
and its Fourier transform. The role of the window is to create and shape a ﬁnite segment
of the sequence, be it data, a ﬁlter’s impulse response, or its frequency response, and
shape it in a way such that certain characteristics are met. Windows by deﬁnition have
ﬁnite duration and, therefore, inﬁnite bandwidth. Given the duration of the window, its
shape has an important role in the function it fulﬁlls.
The time functions for some familiar continuous-time windows and their Fourier
transforms are listed in Table 8.2. For simplicity, the time origin is centered so that the
windows are even functions. All windows are of width 2τ. The mathematical expressions
are given for −τ < t < τ. Elsewhere, windows have zero value. Plots of the functions
in the time and frequency domains are given in Figure 8.3. Note the effect of a window
shape on its side-band frequencies. A comparison between a rectangular and Hanning
window is shown in Figure 8.3(f ).
TABLE 8.2 Continuous-Time Windows and Their Fourier Transforms
Window
Time Function
⇐⇒
Fourier Transform
Rectangular
1
⇐⇒
sin(2π f τ)
π f
Bartlett∗
1 −|t|
τ
⇐⇒
1
τ

sin(π f τ)
π f
2
Hanning†
0.5 + 0.5 cos
πt
τ

⇐⇒
0.5sin(2π f τ)
π f
+ 0.25
sin 2πτ

f −1
2τ

π

f −1
2τ

+ 0.25
sin 2πτ

f + 1
2τ

π

f + 1
2τ

Hamming
0.54 + 0.46 cos
πt
τ

⇐⇒
0.54sin(2π f τ)
π f
+ 0.23
sin 2πτ

f −1
2τ

π

f −1
2τ

+ 0.23
sin 2πτ

f + 1
2τ

π

f + 1
2τ

Blackman
0.42 + 0.5 cos
πt
τ

+0.08 cos

2πt
τ
	
⇐⇒
0.42sin(2π f τ)
π f
+ 0.25
sin 2πτ

f −1
2τ

π

f −1
2τ

+ 0.25
sin 2πτ

f + 1
2τ

π

f + 1
2τ

+0.04
sin 2πτ

f −1
τ

π

f −1
τ

+ 0.04
sin 2πτ

f + 1
τ

π

f + 1
τ

∗A Bartlett window is triangular.
†A Hanning window is a raised cosine.

Signals and Systems
451
x1(t)
x2(t)
x3(t)
x4(t)
x5(t)
(a)
(b)
(c)
–2
–1
–0.5
–1.5
0
0.5
1
1.5
2
–2
–1
–0.5
–1.5
0
0.5
1
1.5
2
–2
–1
–0.5
–1.5
0
0.5
1
1.5
2
–2
–1
–0.5
–1.5
0
0.5
1
1.5
2
1.2
1
0.8
0.6
0.4
0.2
–0.2
–2.5
–1
–0.5
0
1
1.5
2.5
0
–2
–1.5
0.5
2
1.2
1
0.8
0.6
0.4
0.2
–0.2
–2.5
–1
–0.5
0
1
1.5
2.5
0
–2
–1.5
0.5
2
1.2
1
0.8
0.6
0.4
0.2
–0.2
–2.5
–1
–0.5
0
1
1.5
2.5
0
–2
–1.5
0.5
2
1.2
1
0.8
0.6
0.4
0.2
–0.2
–2.5
–1
–0.5
0
Time (s)
Frequency (Hz)
1
1.5
2.5
0
–2
–1.5
0.5
2
1.2
1
0.8
0.6
0.4
0.2
–0.2
0
1.2
1
0.8
0.6
0.4
0.2
–0.2
0
1.2
1
0.8
0.6
0.4
0.2
–0.2
0
1.2
1
0.8
0.6
0.4
0.2
–0.2
0
(d)
(e)
1.2
1
0.8
0.6
0.4
0.2
–0.2
–2
–1
–0.5
–1.5
0
0.5
1
1.5
2
0
1.2
1
0.8
0.6
0.4
0.2
–0.2
–2.5
–1
–0.5
0
1
1.5
2.5
0
–2
–1.5
0.5
2
X1(f)
X1(0)
X2(f)
X2(0)
X3(f)
X3(0)
X4(f)
X4(0)
X5(f)
X5(0)
FIGURE 8.3 (a) to (e). Five ﬁnite-duration time windows (left column) and magnitudes of their Fourier transforms (right
column). From the top: rectangular, Bartlett (triangular), Hanning (raised cosine), Hamming, and Blackman windows.
Distinction between the transforms becomes more pronounced when a decibel scale is used.

452
CHAPTER 8
Fourier Transform
X(f)
1.2
1
0.8
0.6
0.4
0.2
–0.2
–0.4
–30
–20
–10
0
Frequency (Hz)
10
20
Hanning
Rectangular
30
0
FIGURE 8.3 (f ). Comparison of the Fourier transforms of rectangular and Hanning windows. Both windows are 10
msec wide with 1-volt maxima. The Hanning window has a smoother frequency characteristic with smaller side bands.
For derivation of the Fourier transforms and a quantitative comparison see problem 7.
8.20
Band-Limited Signals
Low-Pass Signals
The Fourier transform of a strictly band-limited low-pass signal (also called a baseband
signal) is zero for | f | > f0. An example is the signal
x(t) = sin(2π f0t)
πt
It has ﬁnite energy spread over an inﬁnite duration. However, most of its energy is within
the main lobe. Therefore, it is called a sinc pulse. The Fourier transform of x(t) is
X( f ) =

1,
for −f0 < f < f0;
0,
elsewhere
The frequencies are limited to 0 to f0 and the signal is low pass.
Time-Limited, Band-Limited Signals
Strictly speaking, a signal can’t be both time limited and band limited. However, in some
applications, such as digital communication, we need time-limited signals with a small
amount of energy outside a given frequency range. These may be called time-limited,
band-limited signals. Examples of such low-pass signals are shown in Figure 8.3. The
pulses shown in Figure 8.3 are strictly time limited, but not band limited, as their Fourier
transforms extend to frequencies up to ∞. The magnitudes of the transforms diminish
and can be ignored at high frequencies. A similar discussion also applies to bandpass
signals as well.

Signals and Systems
453
Bandpass Signals
The frequency components of a bandpass signal are limited between f1 and f2 so that
X( f ) = 0 for f1 < | f | < f2. A bandpass signal can be converted to a low-pass
signal modulating the amplitude of a carrier. The low-pass signal is in general a complex
signal. It is real if the spectrum of the bandpass is symmetric around a center frequency
as described in section 8.12. (For further details refer to Chapter 10 on time-domain
sampling.)
Example
8.22
Consider the inﬁnite-duration toneburst and its Fourier transform
x(t) = sin(2π f0t)
πt
cos(2π fct),
fc > f0
X( f ) =

1/2,
| fc −f0| < | f | < | fc + f0|
0,
elsewhere
x(t) is a bandpass signal limited to the band of fc −f0 to fc + f0 with a bandwidth
of 2 f0.
8.21
Paley-Wiener Theorem
The Paley-Wiener theorem1 speciﬁes necessary and sufﬁcient conditions for a square-
integrable function |H( f )| to be the spectrum of a causal function. It states that if h(t)
is square-integrable and causal, then
 ∞
−∞
| ln |H( f )||
1 + f 2
d f < ∞
The above condition is necessary and sufﬁcient for an |H( f )| to be the magnitude of the
Fourier transform of a causal function (e.g., the impulse response of a realizable ﬁlter),
and if it is satisﬁed, a phase function θ( f ) may then be attached to |H( f )| to obtain
a causal h(t). Conversely, if |H( f )| is square-integrable but the above integral is not
bounded, then a causal h(t) may not be found regardless of the phase function associated
with H( f ). Consequently, if |H( f )| = 0 for a nonzero frequency band, then the above
integral becomes unbounded and the ﬁlter is not realizable.
Example
8.23
The frequency response of the ideal low-pass ﬁlter is
Ha( f ) =

1,
| f | < f0
0,
elsewhere
1See R.E.A.C. Paley and N. Wiener, Fourier Trans f orms in the Complex Domain, Vol. 19, American
Mathematical Society (New York: Colloquium Publications, 1934), p. 16.

454
CHAPTER 8
Fourier Transform
See Figure 8.4(a). The ﬁlter has a zero transition band. Show that the ﬁlter remains
unrealizable even if the transition band is increased to be from f0 to f1 as shown by
the example of the ﬁlter in Figure 8.4(b), (c), and (d ).
f
0
f
0
f0
Ha(t)
Hc(t)
1
1
f
0
Hd(t)
1
–f0
f0
–f0
–f0
f0
f1
–f1
2f0
2f0
f
0
f0
f1
Hb(t)
1
–f0
–f1
2f0
∆f
∆f
2f0
∆f
∆f
(a)
(b)
(c)
(d)
FIGURE 8.4 An ideal low-pass ﬁlter (a) remains unrealizable even if transition band is nonzero
(b,c, and d).
Solution
The ﬁlter in (a) is unrealizable. This can be veriﬁed from the fact that its unit-impulse
response is
ha(t) = sin(2π f0t)
πt
It extends from −∞to ∞and would not become a causal function regardless of
any amount of shift to the right. The ﬁlter in (b) may be constructed by subtracting
the output of two ﬁlters with triangular frequency responses, both of which are also
unrealizable by the same reason as (a). A smoother but ﬁnite-duration transition band
[such as the graph in (c) and (d) in which d X( f )/d f is continuous] cannot make
the ﬁlter causal either. The above conclusions are readily reached by applying the
Paley-Wiener theorem according to which all of the above ﬁlters are unrealizable
because ln |H( f )| = ∞over a nonzero range of frequency makes the integral given
in that theorem unbounded.
8.22
Gibbs’ Phenomenon
Consider a rectangular pulse x(t) of width T and its transform X( f ):
x(t) =
1,
−T
2 < t < T
2
0,
elsewhere
⇐⇒X( f ) = sin(π f T )
π f

Signals and Systems
455
The pulse contains all frequencies −∞< f < ∞, but most of its energy resides
in the frequency band of the main lobe of the transform, −1/T < f < 1/T . Choose
a ﬁnite segment of the transform, selected by a low-pass uniform window H( f ) in the
frequency domain limited to the frequencies −f0 < f < f0:
H( f ) =

1,
−f0 < f < f0
0,
elsewhere
Call the segment Y( f ) = H( f )X( f ). The signal y(t) may be found from Y( f ) by direct
application of the inverse transform. Since Y( f ) is band limited, the time function y(t)
is not time limited and it is not an exact replica of x(t). This is expected. However, there
is another observed effect, called Gibbs’ phenomenon, as evidenced by the presence of
horns at the edges of the pulse in y(t) as shown in Figure 8.5(d). The Gibbs’ phenomenon
1.2
1
0.8
0.6
0.4
0.2
–0.2
–0.4
–4
–3
–2
–1
1
2
3
4
(b)
(a)
(c)
(d)
0
0
5
–4
–3
–2
–1
1
2
3
4
0
5
0.6
0.5
0.4
0.3
0.2
0.1
–0.1
–4
–3
–2
–1
1
2
3
4
0
0
5
–4
–3
–2
–1
1
2
3
4
0
5
1.2
1
0.8
0.6
0.4
0.2
–0.2
0
0.6
0.5
0.4
0.3
0.2
0.1
–0.1
0
FIGURE 8.5 A sinc function h(t) shown in (a) and its integral g(t) in (b). Convolution of a rectangular pulse x(t)
shown in (c) and h(t) produces the pulse y(t) in (d) in which Gibbs’ phenomenon is observed. The abscissa show times
in seconds.
can be mathematically discerned if we ﬁnd y(t) from the convolution of h(t) with x(t),
where h(t) is the inverse Fourier transform of H( f ) (i.e., the impulse response of the
low-passﬁlter).Notethat x(t) = u(t+T/2)−u(t−T/2)and h(t) = sin(2π f0t)
πt
.Therefore,
y(t) = h(t) ⋆x(t) = h(t) ⋆[u(t + T/2) −u(t −T/2)]
= h(t) ⋆u(t + T/2) −h(t) ⋆u(t −T/2)
= g(t + T/2) −g(t −T/2)

456
CHAPTER 8
Fourier Transform
where g(t) = h(t) ⋆u(t) is the unit-step response of the ideal low-pass ﬁlter shown in
Figure 8.5(b).
g(t) =
 t
−∞
h(τ)dτ =
 t
−∞
sin(2π f0τ)
πτ
dτ
g(t) has undershoot and overshoot which cause ringing at transition instances in y(t).
As we increase the bandwidth of H( f ) by increasing f0, the ripples become narrower,
but their amplitudes do not diminish. They take the form of horns. In other words, y(t)
converges to x(t) everywhere except at the transition neighborhood. The limit of y(t) at
t = ±T/2 is 0.25 but the convergence is not uniform. The error cannot be reduced to
a desired value by increasing f0 and by considering a smaller transition neighborhood.
Despite the persistence of the horns, the rms of error between y(t) and x(t) decreases as
f0 increases, and approaches zero when f0 →∞.
8.23
Fourier Transform of Power Signals
Let x(t) be a signal with ﬁnite average power so that
lim
T →∞
1
2T
 T
−T
|x(t)|2dt < ∞
Examples are (1) periodic signals, and (2) signals in communication and control, which
are normally labeled as random signals and noise. The familiar version of the Fourier
transform for these signals does not exist because their Fourier integrals do not converge.
However,powersignalsmaystillberepresentedinthefrequencydomain.Fortheperiodic
signals this is done by employing singularity functions such as the impulse. For aperiodic
power signals the subject may be approached in several ways. As an example, power
signals are windowed in time and a ﬁnite segment is processed at a time, making it an
energy signal with a well-deﬁned Fourier transform. One case is processing of speech
signals where, for example, a 200-msec. segment is transformed to the frequency domain.
The Fourier integral, therefore, converges and a normalized Fourier transform for the
segment of data under processing is deﬁned by
X( f ) = 1
2T
 T
−T
x(t)e−j2π f tdt
The normalization of the integral by the length factor allows comparison in the frequency
domain, independent of the segment’s length. In the case of a power signal with inﬁnite
length, if we can ﬁnd an X( f ) by any means whose error, according to the following
expression, can be reduced to any desired small amount by increasing T , then we may
call that the Fourier transform of the signal x(t).
lim
T →∞
 ∞
−∞
X( f ) −1
2T
 T
−T
x(t)e−j2π f tdt

2
d f < ϵ

Signals and Systems
457
8.24
Fourier Transform of Generalized
Functions
In engineering, signals, waveforms, and functions are of interest for what they do. As long
as two functions result in the same effect, they are appreciated as the same. Therefore,
functions that differ by a ﬁnite value at a countably ﬁnite number of points are equivalent.
An example is the pair x1(t) and x2(t) below:
x1(t) = sin(ωt)
x2(t) =



1,
t = kT
sin(ωt),
elsewhere
where k is an integer and T is the period. By using generalized functions, such as
the Dirac delta function δ( f ), we can extend the Fourier transform to periodic signals
and also to those signals for which the integral does not converge in the conventional
sense.
The condition for existence of the generalized Fourier transform of a time function
x(t) is that
 ∞
−∞x(t)φ(t)dt be well deﬁned, where φ(t) is any inﬁnitely differentiable
function that vanishes faster than any power of t as t increases. With this generalization,
a function x(t) and its Fourier transform X( f ) form a unique pair with symmetrical
properties, including the guarantee that x(t) can be obtained from X( f ).
Accordingly, a Fourier transform pair x(t) and X( f ) is uniquely speciﬁed by either
one of the following relationships:
X( f ) =
 ∞
−∞
x(t)e−j2π f tdt
x(t) =
 ∞
−∞
X( f )e j2π f td f
Given the function in the time or frequency domain, the representation in the other
domain may be found by searching for a function that satisﬁes any one of the above
two equations. As expressed previously, this generalization allows us to specify Fourier
transforms of functions for which the integral does not converge. For example, the Fourier
transform of a periodic signal with period T is made of impulses in the frequency domain
at the location of its harmonics, where the impulses are separated by f0 = 1
T and T is
the period. The magnitude of each impulse is the same as the coefﬁcient of the Fourier
series of the corresponding harmonic Xn
X( f ) =
∞

n=−∞
Xnδ

f −n
T

, Xn = 1
T
 t0+T
t0
x(t)e−j2πnt/T dt

458
CHAPTER 8
Fourier Transform
8.25
Impulse Function and Operations
Impulse Function
The unit-impulse function (also called the Dirac delta, or δ, function) is deﬁned in several
ways. One is the limit of a narrow pulse with unit area, as pulse width is reduced to zero
and height is increased to ∞. Another deﬁnition is given by its operation in the following
integral:
 ∞
−∞
φ(τ)δ(τ −t)dτ = φ(t)
where φ(t) is an inﬁnitely differentiable function that vanishes faster than any power of
t as t increases. Accordingly, δ(t −t0) is a unit-impulse function located at t0.
Convolution with Impulse Function
Convolution of a function h(t) with δ(t −t0), a unit impulse at t0, is
h(t) ⋆δ(t −t0) =
 ∞
−∞
δ(t −t0 −τ)h(τ)dτ
But by deﬁnition of δ(t),
 ∞
−∞
h(t)δ(t −t0)dt = h(t0)
Therefore,
h(t) ⋆δ(t −t0) = h(t −t0)
Convolution of h(t) with a unit impulse located at t0 shifts h(t) by the amount t0.
Fourier Transform of an Impulse Function
Consider a rectangular pulse x(t) with unit area (width = τ, height = 1/τ), and its Fourier
transform X( f ). As the pulse becomes narrower, the transform becomes wider. At the
limit, the pulse becomes a unit impulse and its transform becomes equal to 1 for all f .
x(t) =
 1
τ ,
−τ
2 < t < τ
2
0,
elsewhere
⇐⇒
X( f ) = sin(π f τ)
π f τ
lim
τ→0 x(t) = δ(t)
⇐⇒
lim
τ→0 X( f ) = 1
Fourier Transform of a DC Signal
Consider a rectangular pulse x(t) (height 1, width τ) and its Fourier transform X( f ). As
τ increases, the pulse becomes wider and the transform becomes narrower. As τ →∞,

Signals and Systems
459
the pulse becomes a DC signal and its transform becomes a unit impulse δ( f ).
x(t) =

1
−τ
2 < t < τ
2
0,
elsewhere
⇐⇒
X( f ) = sin(π f τ)
π f
lim
τ→∞x(t) = 1
⇐⇒
lim
τ→∞X( f ) = δ( f )
Fourier Transform of Cosines and Sines
We use the time-shift property of the Fourier transform and the fact that the transform
of x(t) = 1 is a unit impulse δ( f ) to ﬁnd the Fourier transform of cos(2π f0t) and
sin(2π f0t).
1
⇐⇒
δ( f )
e j2π f0t
⇐⇒
δ( f −f0)
e−j2π f0t
⇐⇒
δ( f + f0)
cos(2π f0t) = 1
2[e j2π f0t + e−j2π f0t]
⇐⇒
1
2[δ( f −f0) + δ( f + f0)]
sin(2π f0t) = 1
2 j [e j2π f0t −e−j2π f0t]
⇐⇒
1
2 j [δ( f −f0) −δ( f + f0)]
Amplitude Modulation
Multiplication of a low-pass signal x(t) by a sinusoid with frequency f0 moves the
frequency content of x(t) upward by f0 Hz. In terms of the Fourier transform,
x(t) cos(2π f0t) ⇐⇒X( f −f0) + X( f + f0)
2
This can be veriﬁed by using the convolution/multiplication property of Fourier trans-
forms. Let x(t) and X( f ) be a Fourier transform pair. Then,
FT {cos(2π f0t)} = δ( f −f0) + δ( f + f0)
2
and from the product property,
FT

x(t) cos(2π f0t)

= X( f ) ⋆

δ( f −f0) + δ( f + f0)
2

= 1
2 X( f −f0) + 1
2 X( f + f0)
The above result can also be found from a frequency translation as described below.
Multiplication of a time signal x(t) by e j(2π f0t+φ) shifts the transform by f0.
x(t)

e j(2π f0t+φ) + e−j(2π f0t+φ)
⇒
e jφ X( f −f0) + e−jφ X( f + f0)
2x(t) cos(2π f0t + φ)
⇒
e jφ X( f −f0) + e−jφ X( f + f0)

460
CHAPTER 8
Fourier Transform
8.26
Fourier Transform of Periodic Signals
With help from the generalized functions and impulses, we can introduce the Fourier
transform of periodic signals. This will be done in three steps. First we will ﬁnd the
Fourier transform of a train of impulse. In the second step we generate a periodic signal
and its Fourier transform by passing an impulse train through an LTI system. Finally, in
the third step we derive the Fourier transform of the periodic signal.
Fourier Transform of a Periodic Impulse
Consider an inﬁnite train of unit impulses with period T :
x(t) =
∞

k=−∞
δ(t −kT )
For simplicity we have chosen the time origin such that one impulse occurs at t = 0.
In this section we will show that the Fourier transform of x(t) is a train of impulses of
strength 1/T at f = k/T = k f0 in the frequency domain. This will be done through
two approaches. The ﬁrst approach starts with the Fourier series expansion of a periodic
impulse:
From Chapter 7
∞

k=−∞
δ(t −kT ) = 1
T
∞

n=−∞
e j2πnt/T
But,
FT {1} = δ( f ) and FT {e j2πnt/T } = δ

f −n
T

Therefore,
FT

∞

k=−∞
δ(t −kT )

= FT

1
T
∞

n=−∞
e j2πnt/T

= 1
T
∞

n=−∞
δ

f −n
T

We observe that the Fourier transform of a periodic unit-impulse train with period T in
the time domain is a periodic impulse train of strengths 1/T in the frequency domain
with period 1/T .
The second approach, less mechanistic and more instructive, uses the limit method.
It starts with a ﬁnite segment of the time function containing 2M + 1 impulses shifted
by ±k/T (k = 0, 1, 2, . . . , M), to be called xM(t).
xM(t) =
M

k=−M
δ(t −kT )

Signals and Systems
461
Note that the Fourier transform of a shifted unit impulse is
δ(t −kT ) ⇐⇒e−j2kπ f T
The Fourier transform of xM(t) is then
xM(t) =
M

k=−M
δ(t −kT )
X M( f ) =
M

k=−M
e−j2kπ f T
= e j2π f MT + e j2π f (M−1)T + · · · + 1 + · · · + e−j2π f (M−1)T + e−j2π f MT
= e j2π f MT 
1 + e−j2π f T + · · · + e−j2π f MT + · · · + e−j4π f (M−1)T + e−j4π M f T 
= e j2π f MT

1 −e−j2π f (2M+1)T
1 −e−j2π f T

= sin[(2M + 1)π f T ]
sin(π f T )
xM(t) and its transform X M( f ) are drawn for T = 5 seconds and 2M +1 = 3, 5 and 11
in Figure 8.6(a), (b), and (c), respectively. X M( f ) is periodic with peaks of magnitude
(2M + 1) at f = k/T . Note that the location of the peaks is a function of T only (signal
period) and is independent of M. Between the peaks there are zero-crossings at multiples
of 1/[(2M + 1)T ], that is, at
f = ±
k
T (2M + 1), k = 0, 1, 2, . . .
As M grows the location of peaks remain the same (i.e., at f = k/T ) but their
magnitudes (2M+1) increases. The zero-crossings between the peaks also become more
frequent. The lobes associated with the peaks become narrower and taller. However, the
area associated with each lobe is 1/T as derived below.

1
2T
−1
2T
X M( f )d f =

1
2T
−1
2T

M

k=−M
e−j2πk f T

d f =
M

k=−M

1
2T
−1
2T
e−j2πk f T d f =

1
2T
−1
2T
d f = 1
T
If we let M →∞we get
lim
M→∞xM(t) = x(t)
lim
M→∞X M( f ) = X( f ) =
∞

k=−∞
1
T δ

f −k
T
	
The Fourier transform of a periodic train of unit impulses with period T in the time
domain is a train of impulses of strength 1/T at multiples of f0 = 1/T in the f -domain.
See Figure 8.7.

462
CHAPTER 8
Fourier Transform
(a)
3
2
1
Magnitude
0
–1
–0.5
–0.4
–0.3
–0.2
–0.1
Frequency (Hz)
0
0.1
0.2
0.3
0.4
0.5
t
T
xa(t)
–T
0
1
1
1
5
4
3
2
Magnitude
1
0
–1
–0.5
–0.4
–0.3
–0.2
–0.1
0
0.1
0.2
0.3
0.4
0.5
Frequency (Hz)
(b)
12
10
6
8
2
4
Magnitude
0
–2
–0.5
–0.4
–0.3
–0.2
–0.1
0
0.1
0.2
0.3
0.4
0.5
Frequency (Hz)
(c)
t
T
xb(t)
–T
–2T
2T
0
1
1
1
1
1
t
T
xc(t)
–T
–2T
–3T
–4T
–5T
2T
3T
4T
5T
0
1
1
1
1
1
1
1
1
1
1
1
FIGURE 8.6 Impulse trains (in the left column) and their Fourier transforms (in the right column). A train of three
impulses and its Fourier transform are shown in (a). The bottom two rows (b) and (c) show impulse trains containing 5
and 11 impulses, respectively, along with their Fourier transforms. The transforms are periodic and are made of pulses
positioned at k/T , T = 5 sec. The pulses in the frequency domain become narrower as the number of impulses in the
time domain increases.
T
x(t)
–T
–2T
–3T
–4T
–5T
2T
3T
4T
5T
0
(Time domain)
(Frequency domain)
1
1
1
1
1
1
1
1
1
1
1
X(f)
0
–
–
1
T
1
T
1
T
1
T
1
T
2
T
2
T
1
T
1
T
t
f
. . .
. . .
. . .
. . .
FIGURE 8.7 A periodic unit-impulse train with a period of T seconds (on the left) transforms into a periodic impulse
train of strength 1/T , spaced every 1/T Hz (on the right).

Signals and Systems
463
Example
8.24
Find the Fourier transform pairs given below.
a.
x(t) =
∞

n=−∞
δ(t −2n) ⇒X( f ) = 1
2
∞

k=−∞
δ

f −k
2
	
b.
x(t) =
∞

n=−∞
(−1)nδ(t −n) ⇒X( f ) = 1 −e−j2π f
2
∞

k=−∞
δ

f −k
2
	
=
∞

k=−∞
1 −e−jπk
2
	
δ

f −k
2
	
=
∞

k= odd
δ

f −k
2
	
=
∞

k=−∞
δ

f −k −1
2
	
Convolution of a Pulse with an Impulse Train
A periodic signal y(t) with period T may be obtained by the convolution of a time-limited
signal h(t) with an inﬁnite train x(t) of unit impulses located at every T seconds:
y(t) = h(t) ⋆x(t) = h(t) ⋆
∞

k=−∞
δ(t −k/T ) =
∞

k=−∞
h(t −k/T )
where h(t) is one cycle of y(t).
h(t) =
 y(t),
0 ≤t < T
0,
elsewhere
Representing Periodic Signals by Transforms
We use the observation made on convolution of a pulse with an impulse train and the
convolution property of the Fourier transform to ﬁnd the Fourier transform of a periodic
signal y(t). The Fourier transform of y(t) is found by multiplying the Fourier transforms
of h(t) and x(t) with each other:
X( f ) =
∞

n=−∞
1
T δ

f −n
T

Y( f ) = H( f )X( f ) = H( f )
∞

n=−∞
1
T δ

f −n
T

= 1
T
∞

n=−∞
H( f )

f = n
T δ

f −n
T


464
CHAPTER 8
Fourier Transform
But
H( f ) =
 ∞
−∞
h(t)e−j2π f tdt =
 T
0
y(t)e−j2π f tdt
and
Yn = 1
T
 T
0
y(t)e−j2πnt/T dt
Therefore
Yn = 1
T H( f )

f = n
T
Y( f ) =
∞

n=−∞
Ynδ

f −n
T

The Fourier transform of the periodic signal is obtained from the Fourier transform of a
single cycle of the signal by sampling the latter at f = 1/T intervals and multiplying the
samples by a factor 1/T , then representing them by impulses in the frequency domain
positioned at the frequencies of its harmonics, that is, at f = k/T ≡k f0, k an integer.
The strength of each impulse is the Fourier series coefﬁcient of the periodic signal. See
Figure 8.8.
–
0
H(f)
f
3
T
2
T
1
T
1
T
–2
T
–3
T
–4
T
4
T
FIGURE 8.8 Repetition of a time-domain pulse produces sampling of its transform in the fre-
quency domain. The samples are multiplied by a factor 1/T . They are presented by impulses,
if the Fourier transform formulation is used, or as the Fourier coefﬁcients, if the Fourier series
representation is used. This ﬁgure shows the Fourier transform, in the form of impulses, of a
periodic rectangular pulse with a period T and a 25% duty cycle (pulse duration = T/4). The
Fourier transform of the single rectangular pulse shapes the envelope of the impulses.
Example
8.25
a.
Determine the Fourier transform of the single rectangular pulse (width = τ,
height = 1).
b.
Repeat the pulse of part a every T seconds (T > τ) to generate the periodic
pulse train. Determine the exponential Fourier series coefﬁcients of the periodic
pulse train and its Fourier transform, and relate them to the Fourier transform of
the single pulse.

Signals and Systems
465
Solution
Let x(t) =

1,
−τ
2 < t < τ
2
0,
elsewhere,
and y(t) = x(t)⋆
∞

k=−∞
δ(t−kT ) =
∞

k=−∞
x(t−kT )
Then,
a.
X( f ) =

τ
2
−τ
2
e−j2π f tdt = sin(π f τ)
π f
b.
Yn = 1
T

τ
2
−τ
2
e−j2πnt
T dt = sin( πnτ
T )
πn
Y( f ) = X( f ) ×

1
T
∞

n=−∞
δ

f −n
T

=
∞

n=−∞
sin( πnτ
T )
πn
δ

f −n
T

=
∞

n=−∞
Ynδ

f −n
T

8.27
Concluding Remarks
The Laplace transform, as we saw in Chapter 6 and will further examine in Chapter 9,
provides a very powerful tool for the analysis and design of LTI systems. The Fourier
transform may be considered a special case of the Laplace transform in which s is re-
placed by j2π f . In fact, many results obtained in this chapter could be derived using
the Laplace transform. However, in one’s mind, one may form the impression that the
Fourier transform doesn’t capture the frequency components of nonperiodic signals, as
the Fourier series does for periodic signals. (Each coefﬁcient in the Fourier series repre-
sents a measurable physical harmonic.) One may, therefore, question the need for special
considerations accorded to the Fourier transform in frequency-domain analysis. The ex-
planation for needing such a transform resides in, among other factors, the following:
(1) Measurements and identiﬁcation of systems use sinusoids and their results are for-
mulated in terms of frequency spectra of signals and frequency responses of systems. (2)
Numerical computations, simulations, and operations of digital devices make extensive
use of Fourier transforms. This chapter introduced an analytic and theoretical basis for
the Fourier transform for such applications and provided a foundation for its extension
to the discrete-time domain.
Appendix 8A A Short Table of Fourier Transform Pairs
Time Domain
⇐⇒
Frequency Domain
a)
x(t) =

∞
−∞
X( f )e j2π f td f
⇐⇒
X( f ) =

∞
−∞
x(t)e−j2π f tdt
b)
1, all t
⇐⇒
δ( f )
c)
δ(t)
⇐⇒
1, all f
(Continued)

466
CHAPTER 8
Fourier Transform
Time Domain
⇐⇒
Frequency Domain
d)
cos(2π f0t)
⇐⇒
δ( f −f0) + δ( f + f0)
2
e)
sin(2π f0t)
⇐⇒
δ( f −f0) −δ( f + f0)
2 j
f)
u(t)
⇐⇒
δ( f )
2
+
1
j2π f
g)
u(−t)
⇐⇒
δ( f )
2
−
1
j2π f
h)
sgn(t) = u(t) −u(−t)
⇐⇒
1
jπ f
i)
e−αtu(t)
⇐⇒
1
α + j2π f , α > 0
j)
te−αtu(t)
⇐⇒
1
(α + j2π f )2
k)
e−α|t|
⇐⇒
2α
α2 + 4π 2 f 2
l)
2τ
τ 2 + 4π 2t2
⇐⇒
e−τ| f |, τ > 0
m)
e−αtu(t) −eαtu(−t)
⇐⇒
−j4πα2 f
α2 + 4π 2 f 2
n)
e−πt2
⇐⇒
e−π f 2
o)
e−αt cos(2π f0t)u(t)
⇐⇒
α + j2π f
(α + j2π f )2 + 4π 2 f 2
0
p)
∞

k=−∞
δ(t −kT )
⇐⇒
1
T
∞

k=−∞
δ( f −k/T )
T
2T
–2T
–3T
–T
0
3T
t
1
1
1
1
x(t)
1
1
1
. . .
. . .
–
0
f
X(f)
1
T
1
T
1
T
1
T
1
T
1
T
1
T
1
T
1
T
– 2
T
– 3
T
2
T
3
T
. . .
. . .
q)
 1,
−τ/2 < t < τ/2
0,
elsewhere
⇐⇒
sin(πτ f )
π f
1
x(t)
t
– t
2
t
2
t
0
X(f )
f
t
1
t
1
t
2
t
3
t
2
t
3
t
r)
sin(2π f0t)
πt
⇐⇒

1,
−f0 < f < f0
0,
elsewhere
x(t)
t
T
1
2f0
1
f0
1
2f0
2f0
–
1
f
X(f )
–f0
f0

Signals and Systems
467
8.28
Problems
Notations
Energy signal

∞
−∞
|x(t)|2dt < ∞.
Fourier transform of x(t)
X( f ) =

∞
−∞
x(t)e−j2π f tdt.
Inverse Fourier transform of X( f ) :
x(t) =

∞
−∞
X( f )e j2π f td f.
Energy in the signal

∞
−∞
|x(t)|2dt =

∞
−∞
|X( f )|2d f.
Energy within a band from f1 to f2
2

f2
f1
|X( f )|2d f.
Frequency response of an LTI system
H( f ) =

∞
−∞
h(t)e−j2π f tdt,
h(t) is the system’s unit-impulse response.
Useful Formulae

teαtdt = 1
α2 eαt(αt −1)

eαt sin(βt)dt =
eαt
α2 + β2 [α sin(βt) −β cos(βt]

eαt cos(βt)dt =
eαt
α2 + β2 [α cos(βt) + β sin(βt]

t sin(αt)dt = 1
α2 sin(αt) −t
α cos(αt)

t cos(αt)dt = 1
α2 cos(αt) + t
α sin(αt)
Solved Problems
1. a. Write the expression for the Fourier transform of a single even rectangular pulse of height V0 and width τ such
as that shown in Figure 8.1(a). The equation for the pulse is
x(t) =

V0,
for −τ
2 < t < τ
2
0,
elsewhere
Observe that X( f ) is a real and even function of f , in agreement with expectations based on x(t) being a real
and even function of time.
b. Plot X( f ) as a function of f and specify values for the locations of the zero-crossings and X(0).
c. Show that the total area under X( f ) is equal to the area of the triangle enclosed by the main lobe. From the
above result deduce that

∞
−∞
sin(αt)
t
dt = π
where α is a constant.

468
CHAPTER 8
Fourier Transform
d. Obtain the Fourier transform of the rectangular pulse of Figure 8.1(a) from
X( f ) = 2V0

τ
2
0
cos(2π f t) dt
and show that the Fourier transform of a real and even function of time may be obtained from
X( f ) = 2

∞
0
x(t) cos (2π f t) dt
Solution
a. X( f ) = V0
sin(π f τ)
π f
. It is observed that X( f ) is the ratio of two real and odd functions of f , therefore, it is a real
and even function of f .
b. See Figure 8.1(a). The zero-crossings of X( f ) are at sin(π f τ) = 0 or f = ±k/τ, where k is a nonzero integer.
At f = 0 we obtain X(0) = area under the time pulse = V0τ.
c. Using the property

∞
−∞
X( f )d f = x(0) we ﬁnd

∞
−∞
X( f )d f = V0. In other words the total (algebraic) area
under X( f ) of an even rectangular pulse is equal to the area of the shaded triangle enclosed by the main lobe in
Figure 8.1(a). From the above integral we ﬁnd

∞
−∞
V0
sin(π f τ)
π f
d f = V0 from which

∞
−∞
sin(αf )
f
d f = π.
d.
X( f ) = V0

τ
2
−τ
2
e−j2π f t dt = V0

τ
2
−τ
2
cos(2π f t) dt −jV0

τ
2
−τ
2
sin(2π f t) dt
= 2V0

τ
2
0
cos(2π f t) dt = V0

sin(2π f t)
π f
 τ
2
0
= V0
sin(π f τ)
π f
The above formulation can be generalized for any even function x(t) = x(−t):
X( f ) =

∞
−∞
x(t)e−j2π f t dt =

∞
−∞
x(t) cos(2π f t) dt −j

∞
−∞
x(t) sin(2π f t) dt
=

∞
−∞
x(t) cos(2π f t) dt = 2

∞
0
x(t) cos(2π f t) dt
2. Let y(t) = x(t +τ)+ x(t)+ x(t −τ), where x(t) =

V0,
−τ
2 < t < τ
2
0,
elsewhere
is the rectangular pulse of Figure 8.1(a).
Using the time shift and linearity properties of the Fourier transform, construct Y( f ) from X( f ). Show that
Y( f ) = 3X(3 f ) and observe that Y( f ) is the same as the Fourier transform of a rectangular pulse of the same
height as x(t) but three times as wide.
Solution
y(t) = x(t + τ) + x(t) + x(t −τ)
Y( f ) = X( f )e j2π f τ + X( f ) + X( f )e−j2π f τ = X( f ) [1 + 2 cos(2π f τ)]
But
X( f ) = V0
sin(π f τ)
π f
and 1 + 2 cos(2π f τ) = 3 cos2(π f τ) −sin2(π f τ)
Therefore,
Y( f ) = V0
3 cos2(π f τ) sin(π f τ) −sin3(π f τ)
π f
= V0
sin(3π f τ)
π f
= 3X(3 f )

Signals and Systems
469
3. a. Find the Fourier transforms of the causal rectangular pulse x(t) =

1
0 < t < τ
2
0
elsewhere
.
b. Find the Fourier transforms of xe(t) = x(t) + x(−t)
2
(the even part of x) and xo(t) = x(t) −x(−t)
2
(the odd
part of x) and verify their equivalence with the real and imaginary parts of X( f ), respectively.
Solution
a.
x(t) =

1,
0 < t < τ
2
0,
elsewhere
X( f ) =

τ
2
0
e−j2π f tdt = sin π f τ
2
π f
e−j π f τ
2
= sin(π f τ)
2π f
−j sin2( π f τ
2 )
π f
b.
xe(t) =

1
2,
−τ
2 < t < τ
2
0,
elsewhere
Xe( f ) = sin(π f τ)
2π f
= RE{X( f )}
xo(t) =





−1
2 ,
−τ
2 < t < 0
1
2,
0 < t < τ
2
0,
elsewhere
Xo( f ) = sin( π f τ
2 )
2π f

e−j π f τ
2 −e j π f τ
2

= −j sin2( π f τ
2 )
π f
= IM{X( f )}
4. Find the Fourier transform of the sawtooth pulse shown in Figure 8.9.
t
–t
2
t
2
0
V0
t
FIGURE 8.9
Solution
X( f ) =

τ
2
−τ
2
x(t)e−j2π f tdt =

τ
2
−τ
2

V0
2 + V0
τ t
	
e−j2π f tdt
= V0
2

τ
2
−τ
2
e−j2π f tdt + V0
τ

τ
2
−τ
2
te−j2π f tdt
= V0
2
sin(π f τ)
π f
+ V0
τ

τ
2
−τ
2
teαtdt, where α = −j2π f
But

teαtdt = 1
α2 eαt(αt −1)
Therefore,
X( f ) = V0
2
sin(π f τ)
π f
+ V0
ατ

eαt

t −1
α
	 τ
2
t=−τ
2
= V0
2
sin(π f τ)
π f
+ j V0
2

cos(π f τ)
π f
−1
τ
sin (π f τ)
(π f )2


470
CHAPTER 8
Fourier Transform
In summary
X( f ) = RE{X( f )} + jIM{X( f )}
RE{X( f )} = V0
2
sin(π f τ)
π f
,
IM{X( f )} = V0
2

cos(π f τ)
π f
−1
τ
sin (π f τ)
(π f )2

5. Find the Fourier transform of the time derivative of the x(t) in problem 4.
Solution
Using X( f ) found in problem 4 and applying the differentiation property of the Fourier transform (shown in
Table 8.1) we ﬁnd
Y( f ) = j2π f X( f ) = j2π f

V0
2
sin(π f τ)
π f
+ j V0
2

cos(π f τ)
π f
−1
τ
sin(π f τ)
(π f )2

= V0

sin(π f τ)
π f τ
−cos(π f τ)

+ jV0 sin(π f τ)
6. One may suppose that the time derivative of the sawtooth pulse of Figure 8.13 is the even rectangular pulse
yi(t) =
 V0
τ ,
−τ
2 < t < τ
2
0,
elsewhere
and expect to obtainY( f ) = Yi( f ) = V0
τ
sin(π f τ)
π f
(not in agreement with the
answer in problem 5). Show that the above supposition is incomplete and correct it.
Solution
The above supposition misses the negative impulse, with strength V0 at t = τ/2, in the derivative of x(t). The
sawtooth pulse x(t) shown in Figure 8.9 and the correct expressions for its derivative y(t) and Y( f ) are given below.
x(t) =
 V0
2 + V0
τ t,
−τ
2 < t < τ
2
0,
elsewhere
y(t) = dx
dt = yi(t) −V0δ

t −τ
2

where yi(t) =
 V0
τ ,
−τ
2 < t < τ
2
0,
elsewhere
Y( f ) = Yi( f ) −V0e−jπ f τ = V0
τ
sin(π f τ)
π f
−V0 cos(π f τ) + jV0 sin(π f τ)
Inclusion of the downward impulse has completed the expression for y(t) resulting in Y( f ) in agreement with
the answer obtained in problem 5.
7. Find the Fourier transform of the raised cosine pulse (also called Hanning window) τ seconds wide:
x(t) =

0.5(1 + cos 2π f0t),
−τ
2 < t < τ
2
0,
elsewhere
, where f0 = 1
τ
Solution
Deﬁne p(t) to be the rectangular pulse
p(t) =

1,
−τ
2 < t < τ
2
0,
elsewhere
and P( f ) = sin(πτ f )
π f
Then
x(t) = 0.5p(t)(1 + cos 2π f0t)
X( f ) = 0.5 [P( f ) + 0.5P( f + f0) + 0.5P( f −f0)]
= sin(πτ f )
2π f
+ sin πτ( f + f0)
4π( f + f0)
+ sin πτ( f −f0)
4π( f −f0)

Signals and Systems
471
But
sin πτ( f ± f0) = sin(πτ f ± π) = −sin(πτ f )
Therefore,
X( f ) = sin(πτ f )
2π f

1 −
f
2( f −f0) −
f
2( f + f0)

= sin(πτ f )
2π f

1
1 − f
f0
2

8. Find the time function whose Fourier transform is a raised cosine pulse given below (a 2 f0−Hz wide Hanning
window in the frequency domain):
X( f ) =
 0.5(1 + cos π f
f0 ),
| f | < f0
0,
elsewhere
Solution
Consider the time functionp(t) = sin(2π f0t)
πt
and P( f ) =

1,
−f0 < f < f0
0,
elsewhere
Then
X( f ) = 0.5P( f )

1 + cos π f
f0
	
x(t) = 0.5

p(t) + 0.5p

t + τ
2

+ 0.5p

t −τ
2

= sin(2π f0t)
2πt
+ sin 2π f0(t + τ
2)
4π(t + τ
2)
+ sin 2π f0(t −τ
2)
4π(t −τ
2)
, where τ = 1
f0
But
sin 2π f0

t ± τ
2

= sin 2π f0t ± π) = −sin(2π f0t)
Therefore,
x(t) = sin(2π f0t)
2πt

1 −
t
2
t + τ
2
 −
t
2
t −τ
2


= sin(2π f0t)
2π f

1
1 −(2 f0t)2

9. Fourier transform of a decaying sinusoid
The decaying sinusoid e−αt cos(2π f0t)u(t) is often used to model some signals and systems. Find its Fourier
transform.
Solution
The Fourier transform may be obtained by using the frequency shift property.
e−αtu(t) ⇒
1
α + j2π f
e−αt cos(2π f0t)u(t) ⇒
α + j2π f
(α + j2π f )2 + 4π 2 f 2
0
Note: The above function is absolutely integrable and so the Fourier transform can also be obtained from the
Laplace transform by replacing s with j2π f .
Chapter Problems
10. Determine the Fourier transform of a real and even rectangular pulse with height V0 and width τ/2.
11. Determine the Fourier transform of a real and even rectangular pulse with height V0 and width 2τ.

472
CHAPTER 8
Fourier Transform
12. Determine and sketch the Fourier transform of the rectangular pulse shown in Figure 8.1(a) for V0=10 V and the
following values of τ:
a. 100 msec
b. 10 msec
c. 1 msec
d. 100 µsec
e. 10 µsec
f. 1 µsec
13. Repeat problem 12 for the following values of τ and V0:
a. τ = 100 msec
and
V0 = 10 mV
d. τ = 100 µsec
and
V0 = 10 V
b. τ = 10 msec
and
V0 = 100 mV
e. τ = 10 µsec
and
V0 = 100 V
c. τ = 1 msec
and
V0 = 1 V
f. τ = 1 µsec
and
V0 = 1 kV
14. In Figure 8.1(a), determine values for τ that result in zero-crossings of X( f ) at (a) f = n kHz and (b) f = 10n kHz,
where n = 1, 2, 3 . . . .
15. In Figure 8.1(a), determine V0 so that X(0) = 2 × 10−3V × sec given (a) τ = 1 msec and (b) τ = 100 µs.
16. Determine the Fourier transform of the single rectangular pulse
x(t) =

1
τ ,
for −τ
2 < t < τ
2
0,
elsewhere
and verify that X(0) = 1 regardless of τ.
17. Determine the Fourier transform of the single rectangular pulse of problem 16 for the following values of τ:
a. 100 sec
b. 1 sec
c. 10 msec. Find lim
τ→0 X( f ).
18. Use the duality property of the Fourier transform and the fact that the transform of a unit impulse is 1 to show that
the Fourier transform of x(t) = 1 is δ( f ).
19. Show that
lim
τ→0

sin(π f τ)
π f τ

= 1 (Fourier transform of an impulse)
20. Show that
lim
τ→∞

sin(π f τ)
π f

= δ( f ) (Fourier transform of a DC signal)
21. Find the energy in the single rectangular pulse of Figure 8.1(a) for
a. V0 = 1 V and τ = 1 msec
b. V0 = 2 V and τ = 250 µsec
c. V0 = 5 V and τ = 40 µsec
22. Find the energy in the frequency band from 0 to 10 Hz in a single rectangular pulse [as in Figure 8.1(a)] for
a. V0 = 1 V and τ = 1 msec
b. V0 = 2 V and τ = 250 µsec
c. V0 = 5 V and τ = 40 µsec

Signals and Systems
473
23. Find the percentage of energy in the frequency band from 0 to 10 Hz in a single rectangular pulse [as in Figure 8.1(a)]
for
a. τ = 1 msec
b. τ = 250 µsec
c. τ = 40 µsec
24. Find the ratio of the amount of energy residing within the frequency range of the main lobe of the Fourier transform
of a rectangular pulse to the total energy in the pulse.
25. Generalize problem 2 to show that
y(t) =
k

n=−k
x(t −nτ) ⇒Y( f ) =

1 + 2
k

n=1
cos(2πnf τ)

X( f ) = (2k + 1)X[(2k + 1) f ]
26. Let x(t) be the rectangular pulse of Figure 8.1(a) with V0 = 1 V and τ = 100 msec. Find and plot the Fourier
transform of
y(t) =
k

n=−k
x(t −n)
for
a. k = 1
b. k = 2
c. k = 10
27. Repeat problem 26 for
y(t) =
k

n=−k
x(t −nT )
where T = 500 msec.
28. Let x(t) be the rectangular pulse of Figure 8.1(a) with V0 = 1 V and τ = 100 msec. Find and plot the Fourier
transform of
y(t) =
k

n=−k
(−1)nx(t −nτ)
for
a. k = 1
b. k = 2
c. k = 10
29. Let x(t) be the rectangular pulse of Figure 8.1(a) with V0 = 1 V and τ = 100 msec. Find and plot the Fourier
transform of
y(t) =
k

n=−k
(−1)nx(t −n)
for
a. k = 1
b. k = 2
c. k = 10

474
CHAPTER 8
Fourier Transform
30. Repeat problem 29 for
y(t) =
k

n=−k
(−1)nx(t −nT )
with T = 500 msec.
31. Let x(t) be the rectangular pulse of Figure 8.1(a) with V0 = 1 V and τ = 2 sec. A periodic waveform y(t) is
generated by repeating x(t) every T = 8 seconds. Find and plot the Fourier transform of y(t).
32. Repeat problem 31 for τ = 2 and T = 8, both in msec.
33. Let x(t) be the rectangular pulse of Figure 8.1(a) with V0 = 1 V and τ = 2 s. Find and plot the Fourier transform of
y(t) =
k=∞

n=−∞
(−1)nx(t −nT )
with T = 8 s.
34. Repeat problem 33 for τ = 2 and T = 8, both im msec.
35. A periodic waveform y(t) is generated by repeating the rectangular pulse of Figure 8.1(a) every T seconds, where
T > τ.
y(t) =
∞

n=−∞
x(t −nT )
Find a mathematical expression for the Fourier transform of y(t) in terms of V0, τ, and T .
36. Repeat problem 35 for
y(t) =
∞

n=−∞
(−1)nx(t −nT )
37. Find the peak and average power in the periodic rectangular pulse train with period T = 500 msec, for
a. V0 = 1 V and τ = 1 msec
b. V0 = 2 V and τ = 250 µsec
c. V0 = 5 V and τ = 40 µsec
38. Find the average power in the frequency band from 0 to 10 Hz for the periodic rectangular pulse train with period
T = 500 msec, for
a. V0 = 1 V and τ = 1 msec
b. V0 = 2 V and τ = 250 µsec
c. V0 = 5 V and τ = 40 µsec
39. Find the percentage of average power in the frequency band from 0 to 10 Hz for a periodic rectangular pulse train
with period T = 500 msec, for
a. τ = 1 msec
b. τ = 250 µsec
c. τ = 40 µsec
40. Find the Fourier transform of the step response of an ideal low-pass ﬁlter for which H( f ) = u( f + 1) −u( f −1).
Hint: Use the integration property of the Fourier transform.

Signals and Systems
475
41. Find the Fourier transform of the pulse x(t) in Figure 8.10, where τ = 1.1 msec, V0 = 1 V, τ1 = 100 µsec, and
V1 = 10 V. Sketch X( f ) and label its important points.
t1
t
t
0
V0
–V1
FIGURE 8.10
42. Find the Fourier transform of
y(t) =

t
−∞
x(t)dt
in which x(t) is the pulse shown in Figure 8.10 (with τ = 1.1 msec, V0 = 1 V, τ1 = 100 µsec, and V1 = 10 V).
Sketch Y( f ) and label its important points.
43. The unit-impulse response of an LTI system is
h(t) =
 1,
−1 < t < 1
−1,
−2 < t < −1 and 1 < t < 2
0,
elsewhere
Find and plot the magnitude function |H( f )|. Show that the system is a kind of high-pass ﬁlter that approximates a
differentiator within a frequencies range. Determine your criteria for the validity of the approximation and ﬁnd the
acceptable range of operating frequencies.
44. Find the Fourier transform of
x(t) =
 V0,
for −τ
2 < t < 0
−V0,
for 0 < t < τ
2
0,
elsewhere
See Figure 8.11(a). Verify that X( f ) is an imaginary and odd function of f , in agreement with expectations based
on x(t) being a real and odd function.
45. a. Verify that for the pulse of Figure 8.11(a), X(0) = 0 regardless of τ and V0 values.
b. Generalize the above observation to every x(t), which is a real and odd function of time.
t
2
0
(a)
(b)
t
V0
–V0
t
2
0
t
V1
t
FIGURE 8.11

476
CHAPTER 8
Fourier Transform
46. a. Show that the Fourier transform of the pulse of Figure 8.11(a) may be obtained from
X( f ) = 2 jV0

τ/2
0
sin(2π f t) dt
b. Assume an x(t) is a real and odd function of the real variable t. Show that its Fourier transform may be obtained
from
X( f ) = −2 j

∞
0
x(t) sin (2π f t) dt
47. Find the Fourier transform of an even triangular pulse of height V1 and base τ as in Figure 8.11(b). Sketch the
transform and label its important points.
48. a. Note that the convolution of a rectangular pulse with itself produces a triangular pulse. From the above observation
and using the convolution property of the Fourier transform, derive the Fourier transform of the triangular pulse
of height 1 and base τ and verify that it is in agreement with the result obtained by direct integration in
problem 47.
b. Find the percentage of the energy residing within the frequency range of the main lobe of the transform of a
triangular pulse. Compare with the percentage of energy residing within the frequency range of the main lobe
of the transform of a rectangular pulse of the same width.
49. Find the Fourier transform of an even triangular pulse of height V1 and base 2τ. Sketch the transform and label its
important points.
50. Assume the triangle of Figure 8.11(b) is the integral of the pulse in Figure 8.11(a).
a. Specify V1 [in Figure 8.11(b)] in terms of V0 and τ [in Figure 8.11(a)].
b. Verify that the answers obtained in problems 44 and 47 are in compliance with the derivative property of the
Fourier transform.
51. Find the Fourier transform of the sawtooth pulse shown in Figure 8.12(a).
t
t
t
t
t
t
2
0
(a)
(b)
(c)
V0
0
0
–
V0
V1
–V1
t
2
FIGURE 8.12
52. Find the Fourier transform of the even pulse shown in Figure 8.12(b).
53. Find the Fourier transform of the odd pulse shown in Figure 8.12(c).
54. Find the Fourier transform of the odd pulses shown in Figure 8.13(a).

Signals and Systems
477
t
t
t1
t1
t1
t
t1
0
(a)
(b)
0
V0
–V0
V1
t
FIGURE 8.13
55. Find the Fourier transform of the even trapezoidal pulse shown in Figure 8.13(b).
56. Assume the trapezoidal pulse of Figure 8.13(b) is the integral of the pulses in Figure 8.13(a).
a. Specify V1 [in Figure 8.13(b)] in terms of V0 and τ1 [in Figure 8.13(a)].
b. Verify that the answers obtained in problems 54 and 55 are in compliance with the derivative property of the
Fourier transform.
57. Find the Fourier transform of a single cycle of a sinusoidal pulse
y(t) =

−V0 sin 2πt
τ ,
for −τ
2 < t < τ
2
0,
elsewhere
as in Figure 8.14(a), where τ = 1 msec. Sketch Y( f ) and label its important points.
t
t
V0
V1
0
0
t
t
FIGURE 8.14
58. Find the Fourier transform of a single raised cosine pulse
y(t) =
 V1
2

1 + cos 2πt
τ

,
for −τ
2 < t < τ
2
0,
elsewhere
as in Figure 8.14(b), where τ = 1 msec. Sketch Y( f ) and label its important points.
59. Assume the pulse of Figure 8.14(b) is the integral of the pulse in Figure 8.14(a).
a. Specify V1 [in Figure 8.14(b)] in terms of V0 and τ [in Figure 8.14(a)].
b. Verify that the answers obtained in problems 57 and 58 are in compliance with the derivative property of the
Fourier transform.

478
CHAPTER 8
Fourier Transform
60. Find the Fourier transform of the waveform made of a pair of half-cycle sinusoidal pulses as shown in Figure 8.15(a).
t
t1
t1
t1
t1
t
t
t
V0
0
(a)
(b)
0
V1
FIGURE 8.15
61. Find the Fourier transform of the trapezoid-like pulse shown in Figure 8.15(b). The leading and trailing edges are
raised cosines.
62. Assume the trapezoidal pulse of Figure 8.15(b) is the integral of the pulses in Figure 8.15(a).
a. Specify V1 [in Figure 8.15(b)] in terms of V0 and τ1 [in Figure 8.15(a)].
b. Verify that the answers obtained in problems 60 and 61 are in compliance with the derivative property of the
Fourier transform.
63. a. Find the Fourier transform of a single pulse x(t) shown in Figure 8.16 with τ = 5 µs. Sketch X( f ) and label its
important points.
b. Find the Fourier series coefﬁcients of a periodic waveform generated by repeating the pulse of part a every
T = 50 µs. Hint: Use the superposition property of the Fourier transform.
t
T
0
1
2
t
FIGURE 8.16
64. Repeat problem 63 for τ = 1 msec and
a. T = 1 msec
b. T = 10 msec
c. T = 100 msec
65. Repeat problem 63 for T = 1 msec and
a. τ = 1 µsec
b. τ = 10 µsec
c. τ = 100 µsec

Signals and Systems
479
66. Verify the Fourier transforms of the continuous-time windows of Table 8.2 in section 8.19 of the text.
67. Find and plot the Fourier transforms of the pulses described below. All pulses are of width 2τ. The mathematical
expressions are given for −τ < t < τ. Elsewhere, the pulses have zero value.
a. A cosine pulse:
x(t) = cos πt
2τ

b. A parabolic pulse:
x(t) = 1 − t
τ
2
c. An arc pulse:
x(t) =
√
R2 −t2 −
√
R2 −τ 2
d. A dome pulse:
x(t) =  t
τ
4 −2 t
τ
2 + 1
Compare the results with the Fourier transforms of the windows of section 8.19.
68. Find the Fourier transform of x(t) = sin(100πt)
πt
.
69. Find and plot the Fourier transform of the Lanczos window given by
w(t) =

sin( πt
τ )/( πt
τ ),
−τ < t < τ
0,
elsewhere
Compare with the Fourier transforms of the windows of section 8.19.
70. Find the Fourier transforms of the time functions given below, where u(t) is the unit-step function and τ > 0. If a
transform does not exist, give a reason.
a. x(t) = 1, all t.
b. x(t) = u(t)
c. x(t) = 1
2

u(t) −u(−t)

d. x(t) = tu(t)
e. x(t) = |t|
f. x(t) =
1
√|t|
g. x(t) = e−t
τ u(t)
h. x(t) = te−t
τ u(t)
i. x(t) = e−| t
τ | = e−| fot|, where fo = 1
τ
j. x(t) =
2τ
τ 2 + 4π 2t2 =
2 fo
1 + 4π 2 f 2
o t2 , where fo = 1
τ
k. x(t) = e−t
τ u(t) −e
t
τ u(−t)
l. x(t) = e−πt2/τ2
71. Find the Fourier transforms of the following functions:
a. x(t) = sin(2π f0t) + cos(2π f0t)
b. x(t) = sin(2π f1t) + cos(2π f2t)
c. x(t) = 2
π

cos(ω0t) −1
3 cos(3ω0t) + 1
5 cos(5ω0t)

d. x(t) = e−t
τ cos(ω0t)u(t)
72. Find the Fourier transforms of
a. x(t) = sin(2π f0t)
πt
b. x(t) = 2

sin(2π f0t)
πt

cos(2π fct), where fc > f0
c. x(t) =

sin(2π f0t)
πt
2
d. x(t) = 2

sin(2π f0t)
πt
2
cos(2π fct), where fc > f0
73. Find the Fourier transform of
x(t) = 1
2 + 2
N

n=1

sin( πn
2 )
πn

cos(nω0t)
The above function is the sum of the ﬁrst N + 1 terms of the trigonometric Fourier series expansion of a periodic
square pulse with period T = 2π
ω0 .

480
CHAPTER 8
Fourier Transform
74. Find the Fourier transform of
x(t) = τ
T + 2
N

n=1

sin( πnτ
T )
πn

cos

2πnt
T
	
,
where T > τ
The above function is the sum of the ﬁrst N + 1 terms of the trigonometric Fourier series of a periodic rectangular
pulse with period T and pulse width τ.
75. One period of a periodic signal is x(t) =
√
100 −t2,
−10 ≤t ≤10. Find its Fourier transform.
76. Long-tone burst with a rectangular envelope.
a. Find the Fourier transform of x(t) = a(t) cos 2π fct, where a(t) is a single rectangular pulse as shown in Figure
8.1(a) with V0 = 1 V and τ = 10 msec and fc = 5 kHz. Sketch X( f ) and label important points.
b. Is x(t) band limited?
c. Find the total energy in x(t).
d. Find the percentage of the energy contained within the bandwidth from 4.9 kHz to 5.1 kHz.
77. Short-tone burst with a triangular envelope. Repeat problem 76 for a tone burst with a triangular envelope such as
that shown in Figure 8.1(b) with V1 = 1 V and τ = 1 msec.
78. Long-tone burst with a trapezoidal envelope. Repeat problem 76 for a tone burst with a trapezoidal envelope such as
shown in Figure 8.13(b) with rise and fall times of 0.5 msec each, a total tone duration of 11 msec, and a maximum
amplitude of V1 = 1 V.
79. Short-tone burst with a raised cosine envelope. Repeat problem 76 for a tone burst having a raised cosine envelope
such as that shown in Figure 8.14(b) with V1 = 1 V and τ = 1 msec.
80. Long-tone burst with raised cosine rise and fall times. Repeat problem 76 for a tone burst having rise and fall times
of 0.5 msec each in the shape of a raised cosine, a total tone duration of 11 msec, and a maximum amplitude of
V1 = 1 V. See Figure 8.15(b).
81. Two-tone signal. Consider two-tone signals x1(t) and x2(t) deﬁned below:
a. x1(t) = s1(t) cos(2π f1t), where s1(t) is a 1-V, 1-msec rectangular pulse and f1 = 1,070 Hz
b. x2(t) = s2(t) cos(2π f2t), where s2(t) is a 1-V, 3-msec rectangular pulse and f2 = 1,270 Hz.
Find the Fourier transforms of x1(t), x2(t), and y(t) = x1(t) ⋆x2(t) and plot them.
82. Repeat problem 81 for f1 = 2025 Hz and f2 = 2,225 Hz and compare with the results of that problem.
83. Find the Fourier transform of x(t) = a(t) cos(2π fct), where a(t) is a periodic rectangular pulse (1 V, 1 msec wide,
T = 5 msec) and fc = 100 kHz. Sketch X( f ) and label the important points. Find the average power in x(t) and
the percentage of power contained within the bandwidth from 99 kHz to 101 kHz.
84. Repeat problem 83 for x(t) = [a(t) + 1] cos(2π fct).
85. Find and plot the Fourier transform of
h(t) = 1
2δ(t + T ) + δ(t) + 1
2δ(t −T )
Hint: Use the shift property of the Fourier transform.
86. Find and plot the Fourier transform of
h(t) = δ(t + T ) + δ(t) + δ(t −T )

Signals and Systems
481
87. Find and plot the Fourier transform of a ﬁnite set of 2N + 1 unit impulses positioned every T seconds from −NT
to NT .
N(t) =
N

n=−N
δ(t −nT )
Hint: Use the shift property of the Fourier transform and the ﬁnite sum identity
2N

n=0
an = 1 −a2N+1
1 −a
88. Find and plot the Fourier transform of s(t), an inﬁnite train of alternating positive/negative unit impulses positioned
every T seconds from −∞to ∞.
s(t) =
∞

n=−∞
(−1)nδ(t −nT )
89. a. Find the Fourier transform of a single rectangular pulse x(t) as shown in Figure 8.1(a) with V0 = 1 V and
τ = 1 msec.
b. Pass x(t) through an LTI system with frequency response
H( f ) =

1,
for | f | < 10 Hz
0,
elsewhere
By way of approximation, ﬁnd and sketch y(t), the output of the ﬁlter, in the form of a time function.
90. a. A signal is modeled by x(t) = e−|t/τ|, where τ = 1 msec. The signal is passed through an ideal low-pass ﬁlter
with unity gain and cutoff frequency f0 = 10 Hz. Find the output y(t) as a time function. You may use reasonable
approximations.
b. The total energy in x(t) is  ∞
−∞|x(t)|2dt. Find the ratio of total energy in y(t) to total energy in x(t).
91. a. Find the Fourier series coefﬁcients of a periodic square pulse x(t) with period T = 1 msec and a 50% duty cycle
(τ = T/2, zero DC level and 1 volt peak-to-peak value).
b. Pass x(t) through a low-pass LTI system with cutoff frequency f0 = 10 Hz. Find the output of the system in the
form of a time function. Find the average power of the output.
92. Repeat part b of problem 91 if x(t) is a periodic triangular waveform with period T = 1 msec, a 50% duty cycle,
and 1 volt base-to-peak value.
93. Assume x(t) is a periodic square pulse with period T = 1 msec, zero DC level, and 1 volt peak-to-peak value.
Pass x(t) through an LTI system for which the Fourier transform of its unit-impulse response (called the frequency
response) is shown in Figure 8.4(b) with a transitional cutoff frequency from f0 = 9 Hz to f1 = 10 Hz. Find the
output of the ﬁlter in the form of a time function.
94. The frequency response of an LTI system is
H( f ) =

1,
for | f | < 1 kHz
0,
elsewhere
The input to the system is a periodic rectangular pulse train (τ = 2 and T = 8 both in msec, and V0 = 1 volt).
a. Find Xn and Yn. b. Find total average power in y(t).

482
CHAPTER 8
Fourier Transform
95. Repeat problem 94 for
H( f ) =
 1,
for 1 < | f | < 2 kHz
0,
elsewhere
96. A periodic function s(t) assumes integer values only and can switch from one value to another only at t = kτ where
k is an integer. One period of s(t) (with τ = 1 and T = 10 both in seconds) is represented by
s(t) = {0
↑, −1, −1, 2, 2, 2, 2, , −1, −1, 0}
Simliarly, another periodic function n(t) is represented by
n(t) = {−1
↑, 1, −1, −1, 1.5, 1.5, −1, −1, 1, −1}
In the above representations the ↑indicates the time origin.
a. Find Fourier series coefﬁcients of s(t), n(t) and x(t) = s(t) + n(t). Hint: Use the superposition property or a
computer.
b. Find the average powers Ps, Pn, and Px during one period.
c. Pass s(t), n(t), and x(t) through an ideal bandpass ﬁlter with a 0.1-Hz passband around the center frequency of
0.1n Hz (where n is an integer). Repeat part b for the outputs of ﬁlter with n = 1, 2, 3, 4. Determine n, which
maximizes the ratio of signal power to noise power at the output of the ﬁlter.
97. A full-wave rectiﬁer is connected through a diode to a parallel RC ﬁlter (with R = 10 k and C = 10 µF). See
Figure 8.17(a). The input voltage to the diode-ﬁlter combination is a full-wave rectiﬁed sinusoid with an rms value
of 15 V at 60 Hz. The threshold voltage for the diode is 0.7 V:
 i = 0,
if v < 0.7 V
v = 0.7 V,
if i > 0
The diode’s characteristic is shown in Figure 8.17(b). Find the percentage of power in the ﬁrst three nonzero
harmonics of the voltage at the output of the ﬁlter.
i
i
V2
V1
C
R
–
+
(a)
(b)
V
V
–
+
0
0.7
–
+
+
–
FIGURE 8.17
8.29
Project: Spectral Analysis Using a Digital
Oscilloscope
Summary
In this experiment you will measure the spectra of several signals and compare them with theory. Measurement is done on
a segment of the waveform observed and recorded through a window. The experiment may be performed by simulation
or in real time. For simulation one may use a computation engine such as Matlab, Mathcad, Spice, or a signal processing

Signals and Systems
483
software package. For real-time analysis one may use a general-purpose laboratory instrument such as an oscilloscope
with spectral analysis capability, or a special-purpose instrument such as a spectrum analyzer or a DSP board. Using an
oscilloscope is recommended in this project.
Important Reminder
Spectral analysis by digital tools (such as digital scope, spectrum analyzer, and digital computers) is done by ﬁnding the
DFT/FFT of the sampled signal. A high sampling rate (such as the rate used by the scope in this experiment) makes the
DFT/FFT a good measure of the Fourier transform of the continuous-time signal. In this experiment signals are sampled
by the digital oscilloscope at sufﬁciently high rates for them to be treated as if they were continuous-time signals. In all
plots, scales should be given in terms of the continuous-time frequency (Hz).
Preparation
Numerical Spectra of Single Pulses
Find the Fourier transforms H( f ) of single pulses speciﬁed in Table 8.3 and enter them in that table. Plot H( f ) in the
last column with labels and scales.
TABLE 8.3 Spectra of Single Pulses Vbase-to-peak = 1 V and Their Plots (To be completed by student)
h(t)
H( f )
Plot of H( f )
A single rectangular pulse,
duration = 500 µs
A single rectangular pulse,
duration = 200 µs
A single triangular pulse,
duration = 1 ms
Spectra of Periodic Pulses
Consider three periodic waveforms x1(t), x2(t), and x3(t) speciﬁed in Table 8.4. Note that each of these repetitive pulses
is produced by the convolution of a single pulse (from Table 8.4) with a train of unit inpulses every T seconds.
x(t) = h(t) ⋆
−∞

−∞
δ(t −nT )
X( f ) = H( f ) × 1
T
−∞

−∞
δ( f −n/T ) =
−∞

−∞
Xnδ( f −f0), where Xn = 1
T H(nf0)
where f0 = 1/T . Model each x(t) by an even function of time and ﬁnd the exponential form of its Fourier coefﬁcients
Xn. Show that Xn is a real and even function of n. Compute the ﬁrst nine exponential Fourier coefﬁcients Xn, 1 ≤n ≤9,
of the periodic waveforms in Table 8.4 and enter the results in that table. For each waveform overlay Xn (periodic) on the
graph of its corresponding H( f ) (single pulse). Show that because Xn is real we have
x(t) = X0 + 2
∞

n=1
Xn cos

2πn t
T


484
CHAPTER 8
Fourier Transform
TABLE 8.4 Exponential Fourier Coefficients of the First Nine Harmonics of Periodic Waveforms (To be com-
pleted by student)
x(t)
X1
X2
X3
X4
X5
X6
X7
X8
X9
Periodic square
Vbase-to-peak = 1 V
duration = 500 µs
period = 1 ms
Periodic rectangular
Vbase-to-peak = 1 V
duration = 200 µs
period = 1 ms
Periodic triangular
Vbase-to-peak = 1 V
duration = 1 ms
period = 1 ms
Measurements and Analysis
In this project you will use periodic signals (sine, rectangular, and triangular). Feed the signal from the function generator
to channel 1 of the scope and trigger the scope trace from that signal. Choose FFT under the Math menu. FFT ﬁrst
multiplies the data displayed on the scope by a window of the same size, takes its spectrum, and displays it on the scope
using a dB scale. You will choose the range of displayed frequencies, vertical gain (dB), and window type. Three window
types are offered (Hanning, Flat Top, and Rectangular). For each waveform you will choose appropriate parameters to
display the FFT, as illustrated in the following sections. Note that you may use the scope in the single trigger mode and
retain the data in its memory while you vary the sweep speed (in reality, the length of the displayed segment), adjust the
dB gain of the FFT and its offset level, and choose a new range of displayed frequencies, or a new window type.
Measuring the Spectrum of a Sinusoidal Wave
Prepare the following setup.
Signal:
sinusoidal, 1 kHz, Vpeak-to-peak = 5 V, VDC = 0 V
Sweep:
single, 5 ms/div, data length = 50 ms
FFT:
frequency span = 10 kHz, center frequency = 5 kHz, scale = 20 dB, offset = 0
Window:
Hanning
Set the sweep speed of the oscilloscope to 5 ms/div. Use a single sweep to capture 50 ms of input to channel 1. The
oscilloscope shows the spectrum in dB units, referenced to an rms value of 1 V. The readings are, therefore, referred to
as dB volt (or dBV). A sinusoidal waveform with an rms value of 1 V results in 0 dBV (or simply dB). For example:
v(t) =
√
2 cos(ωt)
⇒
Vrms = 1 V
⇒0 dBV
v(t) = 10
√
2 cos(ωt) ⇒
Vrms = 10 V
⇒20 dBV
v(t) = V0 cos(ωt)
⇒
Vrms = V0/
√
2 ⇒20 log V0 −3 dBV
v(t) = 2.5 cos(ωt)
⇒
Vrms = 1.77 V ⇒4.95 dBV

Signals and Systems
485
Record the location of the peak of the spectrum and its dB value. Enter them along with theoretical values in Table 8.5.
Compare with theory. Deﬁne the percentage relative difference ϵ by
ϵ (in %) = Measured value −Theory
Theory
× 100
TABLE 8.5 The Measured Spectrum of a 1 kHz Sinusoid and Its Comparison with Theory (To be completed
by student)
Measurement
Theory
Relative Difference ϵ
X1 in dBV
f1 in kHz
Measuring the Spectrum of a Periodic Square Wave
Repeat the above for a square wave. For this purpose you need to change only the function generator output from sinusoidal
to square. All other settings on the function generator and on the scope remain the same as before. The function generator
sends out a 1-kHz, square wave with and Vpeak-to-peak = 5 V, VDC = 0 V. Record the location of the ﬁrst nine peaks (in kHz)
and their value (in dB) corresponding to the nine harmonics. Note the negligible values of the even harmonics. Enter your
measurements along with theoretical values in Table 8.6. Compare measured values with theory. Note that the DC value
of the square wave is zero and is not included in Table 8.6 because its value displayed by the spectrum analyzer is not
reliable.
TABLE 8.6 The Measured Spectrum of a 1-kHz Square Wave and Its Comparison with Theory (To be completed
by student)
X1, f1
X2, f2
X3, f3
X4, f4
X5, f5
X6, f6
X7, f7
X8, f8
X9, f9
Measured
Theory
ϵX
ϵ f
Measuring the Spectrum of a Periodic Triangular Wave
Repeat the above for a 1-kHz triangular wave. Again, you need to change only the function generator output to a triangular
waveform. Record the values of the nine harmonics in the spectrum in dB and enter your measurements along with the
previously measured values for the square waveform in Table 8.7. Note the negligible values of the even harmonics and
the rapid decrease of the amplitude of odd harmonics (compared to the square wave). Relate these observations to the
theoretical relationship between the spectra of the square and triangular waves.

486
CHAPTER 8
Fourier Transform
TABLE 8.7 A Comparison of Harmonics in 1-kHz Triangular and Square Waves Measured by the Spectrum
Analyzer (To be completed by student)
Waveform
X1
X2
X3
X4
X5
X6
X7
X8
X9
Square wave
Triangular wave
Measuring the Spectrum of a Periodic Rectangular Wave
Capture the spectrum of a 1-kHz rectangular wave with Vpeak-to-peak = 5 V at 20% duty cycle. Use a 10-ms Hanning
window. Count the number of harmonics before the ﬁrst zero-crossing in the envelope of the spectrum and measure their
locations. Relate to theory. Enter the results in Table 8.8.
TABLE 8.8 The Measured Spectrum of a 1-kHz Rectangular Waveform at 20% Duty Cycle (To be completed
by student)
Number of Harmonics Before
Estimated Location of the
Theoretical Location of the
the First Zero-Crossing
First Zero-Crossing, in kHz
First Zero-Crossing, in kHz
Discussion and Conclusions
Average Power in Harmonics of a Periodic Square Wave
From the measured spectrum of the square wave determine the average power in the principal harmonic. What percentage
of the total power in the square wave resides in the principal harmonic? What percentage is in the third harmonic?
Average Power in Harmonics of a Periodic Triangular Wave
Repeat the above for the triangular waveform of “Measuring the Spectrun of a Periodic Triangular Wave.”
Approximate Bandwidth
Theoretically, the periodic square and triangular waves have inﬁnite bandwidth because their spectra continue to f = ∞.
From your measurements of the spectrum of a periodic square wave and of a periodic triangular wave, determine what
perecentage of the power of a 1-kHz square wave resides in frequencies above 10 kHz; what percentage of the power of
a 1-kHz triangular wave resides above 10 kHz?
Overall Conclusions
Summarize your overall conclusions drawn from this experiment, especially the relationship between the pulse width in
the time domain and its bandwidth. Illustrate by examples from the measurement results.

Chapter9
System Function, the
Frequency Response,
and Analog Filters
Contents
Introduction and Summary
488
9.1
What Is a System Function?
489
9.2
The Time Response May Be Obtained from H(s)
494
9.3
The Frequency Response H(ω)
496
9.4
Plotting H(ω)
500
9.5
Vectorial Interpretation of H(s) and H(ω)
515
9.6
Second-Order Systems
518
9.7
Dominant Poles
521
9.8
Stability and Oscillations
526
9.9
Analog Filters
528
9.10
First-Order Low-Pass Filters
531
9.11
Integrators
534
9.12
First-Order High-Pass Filters
536
9.13
Differentiators
537
9.14
First-Order All-Pass Phase Shifters
538
9.15
Lead and Lag Compensators
540
9.16
Summary of First-Order Filters
544
9.17
Second-Order Low-Pass Filters
544
9.18
Second-Order High-Pass Filters
549
9.19
Second-Order Bandpass Filters
551
9.20
Second-Order Notch Filters
554
9.21
Second-Order All-Pass Filters
556
487

488
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
9.22
Contribution from a Zero
556
9.23
Series and Parallel RLC Circuits
557
9.24
Summary of Second-Order Filters
559
9.25
Group and Phase Delay
560
9.26
Measurements, Identiﬁcation, and Modeling
565
9.27
System Interconnection
566
9.28
Feedback
568
9.29
Pole-Zero Cancellation
579
9.30
Inverse Systems
582
9.31
Concluding Remarks
584
9.32
Problems
584
9.33
Project 1: RC/CR Passive Bandpass Filter
606
Appendix 9A: Hyperbolic Functions
612
Appendix 9B: Bandpass System
612
9.34
Project 2: Active Bandpass Filter
613
9.35
Project 3: An Active Filter with Bandpass/Lowpass Outputs
618
9.36
Project 4: Examples of Modeling LTI Systems
621
Introduction and Summary
LTI systems may be analyzed in both the time and frequency domains. In the time
domain, the output is found by solving the input-output differential equation or by
convolution of the input with the unit-impulse response, y(t) = x(t) ⋆h(t).1 Earlier
we introduced an object called the system function and showed it by H(s). The formal
deﬁnition of H(s) was presented in Chapter 6 based on the Laplace transform operation.
We used the Laplace transform to convert the convolution y(t) = x(t) ⋆h(t) into a
multiplication of the transforms Y(s) = X(s)H(s). Likewise, the Laplace transform
was used to convert the differential equation in the time domain to a linear equation in
the s−domain. The operations involving the Laplace transform represent analysis in the
frequency domain. Both approaches are closely related and provide the same result. This
chapter discusses the analysis of LTI systems in the frequency domain. It is concerned
with H(s) and the parallels between the time and frequency domain solution methods.
First, it describes the system function and looks at it from several points of view in order
to learn about its overall place in system analysis. It reveals aspects of H(s) that bind
time and frequency analysis together. Speciﬁcally, it shows how the system function is
obtained, some of its properties and capabilities, its relationship with other features that
describe a system, and its applications. Second, it introduces the frequency response,
methods for plotting it, poles and zeros of the system, and its vectorial interpretation.
Second-order systems—dominant pair of poles, ﬁlters, and feedback system—are the
third topic covered. Examples are chosen from simple electrical systems that require
basic familiarity with linear circuits.
1The system may instead be characterized by its unit-step response. See Example 9.1.

Signals and Systems
489
9.1
What Is a System Function?
System Function H(s) is the Scale Factor for e st
This is a direct consequence of linearity and time-invariance properties, which make est
the eigenfunctions of LTI systems. (An eigenfunction of a system keeps its functional
form when passing through the sytem.) We have seen (Chapter 3, section 3.9) that the
response of an LTI system to an exponential input est is Hest, where the scale factor H
is, in general, a function of s:
est ⇒H(s)est
The fact that an exponential input est resulted in the response Hest was also obtained in
the case of linear differential equation with constant coefﬁcients. In either case H(s) is
called the system function and exists for almost all LTI systems2 (speciﬁcally, for all LTI
systems of interest in electrical engineering). When it exists, the system function totally
characterizes the system.
H(s) for Lumped and Distributed Systems
The class of LTI systems made of lumped discrete linear elements (such as linear circuits)
is speciﬁed by linear differential equations with constant coefﬁcients. In this case, the
system function becomes the ratio of two polynomials in s. Counter to these systems
is the class of systems with distributed elements such as transmission lines, or delay
systems. This chapter will mainly address cases in which the system function is a ratio
of polynomials.
How to Find H(s)
When it exists, the system function may be obtained from
1.
An input-output pair.3
2.
The system’s unit-impulse response.
3.
The input-output differential equation.
4.
The frequency response.
These methods are closely related to each other and produce the same result. They are
described below.
H(s) Is the Ratio Y (s)/X (s)
This is often presented as a formal deﬁnition of system function. Here are several more
examples.
2An example of an LTI system without a unit-impulse response or a system function is
y(t) = x(t) + x(−t)
2
3A sinusoidal input produces a sinusidal output with the same frequency but possibly a change in the
magnitude and phase. This information given at a ﬁxed frequency is not enough to describe the system, unless
it is provided for the full frequency range of 0 ≤f ≤∞, from which the frequency response is formed.

490
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Example
9.1
The response of a system to a unit-step input is measured and modeled by e−atu(t).
Assuming an LTI ﬁnd its H(s).
Solution
Laplace transforms will be used.
x(t) = u(t)
⇒
X(s) = 1
s
y(t) = e−atu(t)
⇒
Y(s) =
1
s + a
H(s) = Y(s)
X(s)
⇒
H(s) =
s
s + a
A Brief Table of Laplace Transform Pairs
The following is a table of some Laplace transform pairs for use in this chapter. x(t) is
deﬁned for −∞< t < ∞.
x(t) = L−1[X(s)]
⇐⇒
X(s) =  ∞
−∞x(t)e−stdt
Region of Convergence
1
δ(t)
⇐⇒
1
all s
2
u(t)
⇐⇒
1
s
RE[s] > 0
3
u(−t)
⇐⇒
−1
s
RE[s] < 0
4
eatu(t)
⇐⇒
1
s −a
RE[s] > a
5
ebtu(−t)
⇐⇒
−1
s −b
RE[s] < b
6
e−c|t|
⇐⇒
−2c
s2 −c2
−c < RE[s] < c
7
sin(ωt)u(t)
⇐⇒
ω
s2 + ω2
RE[s] > 0
8
cos(ωt)u(t)
⇐⇒
s
s2 + ω2
RE[s] > 0
9
sin(ωt)u(−t)
⇐⇒
−ω
s2 + ω2
RE[s] < 0
10
cos(ωt)u(−t)
⇐⇒
−s
s2 + ω2
RE[s] < 0
11
eat sin(ωt)u(t)
⇐⇒
ω
(s −a)2 + ω2
RE[s] > a

Signals and Systems
491
x(t) = L−1[X(s)]
⇐⇒
X(s) =  ∞
−∞x(t)e−stdt
Region of Convergence
12
eat cos(ωt)u(t)
⇐⇒
s −a
(s −a)2 + ω2
RE[s] > a
13
eat cos(ωt + θ)u(t)
⇐⇒
(s −a) cos θ −ω sin θ
(s −a)2 + ω2
RE[s] > a
14
ebt sin(ωt)u(−t)
⇐⇒
−
ω
(s −b)2 + ω2
RE[s] < b
15
ebt cos(ωt)u(−t)
⇐⇒
−
s −b
(s −b)2 + ω2
RE[s] < b
16
ebt cos(ωt + θ)u(−t)
⇐⇒
−(s −b) cos θ −ω sin θ
(s −b)2 + ω2
RE[s] < b
17
tneatu(t)
⇐⇒
n!
(s −a)n+1
RE[s] > a
H(s) is the Laplace Transform of h(t)
The system function is the Laplace transform of the unit-impulse response. This is a
consequence of H(s) being the ratio of the output transform to that of the input. The
Laplace transform of a unit impulse is 1, which makes H(s) the Laplace transform of
h(t).
Example
9.2
Find H(s) of the system with the unit-impulse response h(t) = te−atu(t).
Solution
From the table of Laplace transform pairs we ﬁnd
H(s) =
1
(s + a)2 ,
RE[s] > −a
Example
9.3
Find H(s) of the system with the unit-impulse response h(t) = e−|t|.
Solution
From the table of Laplace transform pairs we ﬁnd
H(s) =
−2
s2 −1,
−1 < RE[s] < 1
Example
9.4
Find the system function of the LTI system with the unit-impulse response
a.
ha(t) = e−|t| cos t
b.
hb(t) = e−|t| sin t

492
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Solution
From the table of Laplace transform pairs we have
a.
ha1(t) = e−t cos(t)u(t)
⇒Ha1(s) =
s + 1
(s + 1)2 + 1,
RE[s] > −1
ha2(t) = et cos(t)u(−t)
⇒Ha2(s) = −
s −1
(s −1)2 + 1,
RE[s] < 1
ha(t) = ha1(t) + ha2(t) = e−|t| cos(t) ⇒Ha(s) = Ha1(s) + Ha2(s) = −2s2 −2
s4 + 4, −1 < RE[s] < 1
b.
hb1(t) = e−t sin(t)u(t)
⇒Hb1(s) =
1
(s + 1)2 + 1,
RE[s] > −1
hb2(t) = et sin(t)u(−t)
⇒Hb2(s) = −
1
(s −1)2 + 1,
RE[s] < 1
hb(t) = hb1(t) + hb2(t) = e−|t| sin(t) ⇒Hb(s) = Hb1(s) + Hb2(s) =
−4s
s4 + 4,
−1 < RE[s] < 1
H(s) Is Found from the Differential Equation and Vice Versa
Consider the LTI differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = est
We have seen that the solution to the above equation is
y(t) =
1
sn + an−1sn−1 + · · · + a1s + a0
est
Extending the above observation, we noted that the response of the differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = bm
dmx
dtm + bm−1
dm−1x
dtm−1 + · · · + b1
dx
dt + b0x
to an exponential input is an exponential
X0est
⇒
H(s)X0est
where H(s) is the system function
H(s) = bmsm + bm−1sm−1 + · · · + b1s + b0
sn + an−1sn−1 + · · · + a1s + a0
H(s) is easily obtained from the differential equation by employing the notation s for a
ﬁrst-order derivative, s2 for a second-order derivative, and so on.
H(s) = B(s)
A(s)
B(s) = bmsm + bm−1sm−1 + · · · + b1s + b0
A(s) = sn + an−1sn−1 + · · · + a1s + a0
Conversely we can construct the differential equation and its block diagram from a given
H(s), the ratio of two polynomials in s.

Signals and Systems
493
Example
9.5
Find the input-output differential equation of the LTI system with the system function
H(s) = Y(s)
X(s) = 1 + s + s2
Y(s) = (1 + s + s2)X(s) = X(s) + sX(s) + s2X(s)
y(t) = x(t) + dx(t)
dt
+ dx2(t)
dt2
Example
9.6
Find the input-output differential equation of a causal LTI system with the system
function
H(s) = Y(s)
X(s) =
s −2
s2 + 2s + 5
Solution
(s2 + 2s + 5)Y(s) = (s −2)X(s)
d2y(t)
dt2
+ 2dy(t)
dt
+ 5y(t) = dx(t)
dt
−2x(t)
Poles and Zeros
In this book we are interested in LTI systems with H(s) = B(s)/A(s), where A(s) and
B(s) are polynomials in s. The roots of the numerator polynomial are called the zeros of
the system. Let zk be a zero of the system. At s = zk we have H(zk) = 0 and the input
x(t) = ezkt, for all t, will result in y(t) = 0.
Similarly, the roots of the denominator polynomial are called the poles of the system.
Let pk be a pole of the system. At s = pk we have H(pk) = ∞and the input x(t) = epkt
will result in y(t) = ∞.
Example
9.7
Find the zeros of the system described by H(s) = s2 + s + 1.
Solution
The zeros of the system are roots of
s2 + s + 1 = 0 ⇒z1,2 = −1
2 ± j
√
3
2
= e± j120◦
Example
9.8
Find the poles and zeros of the system described by
H(s) =
s
s2 + 2s + 2

494
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Solution
The zeros of the system are roots of s = 0
⇒z1 = 0
The poles of the system are roots of s2 + 2s + 2 = 0 ⇒p1,2 = −1 ± j
=
√
2e± j135◦
Example
9.9
Find the poles and zeros of the system described by
H(s) =
s −2
s2 + 2s + 5
Solution
The zeros of the system are roots of
s −2 = 0
⇒z1 = 2
The poles of the system are roots of
s2 + 2s + 5 = 0
⇒
p1,2 = −1 ± j2
=
√
5e± j116.6◦
Example
9.10
Findthesystemfunctionwithtwozerosat±1,apairofpolesatre± jθ,and|H(s)

s= jr =
1.
Solution
H(s) = k
(s + 1)(s −1)
(s −re jθ)(s −re−jθ) = k
s2 −1
s2 −(2r cos θ)s + r2
|H(s)

s= jr = k 1 + r2
2r2 cos θ = 1
⇒
k = 2r2 cos θ
1 + r2
Contribution of Poles and Zeros to the System Function
A zero at zk contributes (s−zk) to the numerator of the system function. Similarly, a pole
at pk contributes (s −pk) to its denominator. If the coefﬁcients of the system function
are real, the poles and zeros are either real or complex conjugates. A pair of complex
conjugate roots of the numerator or denominator at re± jθ contribute
(s −re jθ)(s −re−jθ) = s2 −(2r cos θ)s + r2
to the numerator or the denominator of the system function, respectively. The signiﬁcance
of poles and zeros locations becomes clear when we work with the frequency response.
9.2
The Time Response May Be Obtained
from H(s)
The time response of an LTI system is obtained either through convolution of the input
with the unit-impulse response or solution of the input-output differential equation, both
of which may be obtained from H(s). It is, therefore, expected that the system function

Signals and Systems
495
contain all the information needed to ﬁnd the time response to a given input. Clearly,
with a known input x(t) we can ﬁnd its Laplace transform X(s), multiply it by H(s) to
ﬁnd Y(s), from which y(t) can be found. In this section, without going through the above
steps, we will see how elements of the time response (natural frequencies, homogeneous
and particular responses, boundary values, and the total response) may be obtained from
H(s). This can be done, often without resorting to formal tools and systematic methods
[i.e., without ﬁnding h(t) to do convolution, or solving the differential equation, or using
the Laplace transform formulation].
We start with the observation that the system function provides the particular re-
sponse to an input expressed by a linear combination of exponentials with constant
weighting factors. (An example would be ﬁnding the AC steady-state response, where
the input comprises two complex exponentials.) We then additionally note that the de-
nominator of the system function contains the characteristic equation of the system
whose roots are the natural frequencies providing the homogeneous response. In fact,
the complete response to an exponential input may readily be written from the system
function, if the initial conditions are known. This property makes H(s) a powerful tool
in the analysis of LTI systems. In the following three examples we ﬁnd responses of the
ﬁrst-order LTI system H(s) = 1/(s + 0.6421) to three different inputs.
Example
9.11
Given H(s) = 1/(s + 0.6421), ﬁnd the system’s response to x(t) = cos t,
−∞< t < ∞.
Solution
Theresponseconsistsoftheparticularsolutiononly,whichinthiscaseisthesinusoidal
steady-state response. To ﬁnd it we note that the angular frequency of the sinusoidal
input is 1, which corresponds to s = j. The output is obtained from the input scaled
by the system function evaluated at s = j.
H(s)

s= j = H( j) =
1
0.6421 + j = 0.8415e−j
The input and the response may be written as
x(t) = cos(t) = RE{e jt}
H( j) =
1
0.6421 + j = 0.8415e−j
y(t) = RE{H( j)e jt}
= RE{0.8415e−j × e jt} = 0.8415 cos(t −1)
The system scales down the input amplitude by the factor 0.8415 and introduces a
1-second delay.

496
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Example
9.12
Given H(s) = 1/(s + 0.6421), ﬁnd the system’s response to x(t) = cos(t)u(t).
Solution
The particular solution was found in Example 9.11, yp(t) = 0.8415 cos(t −1). To
obtain the total response, we need to add the homogeneous solution (if any) to it.
The system has a single pole at s = −0.6421, which gives rise to the homogeneous
solution yh(t) = Ce−0.6421t, where C is a constant. The total response is
y(t) = yh(t) + yp(t) =

Ce−0.6421t + 0.8415 cos(t −1)

u(t)
Using the boundary condition y(0+) = C + 0.8415 cos(−57.3◦) = 0, we ﬁnd C =
−0.4547. The total response, therefore, is
y(t) =

−0.4547e−0.6421t + 0.8415 cos(t −1)

u(t)
Example
9.13
Given H(s) = 1/(s + 0.6421) and the input x(t) = αδ(t) + cos(t)u(t), ﬁnd the
constant α such that for t ≥0 the system’s response contains the sinusoidal steady-
state only.
Solution
The impulse of strength α evokes the additional response αe−0.6421tu(t). Using the
result of Example 9.12, we observe that α = 0.4547 will result in neutralization of
the homogeneous response.
Alternate Solution
In order to have no homogeneous response to the input cos(t)u(t) we need to create
the appropriate initial condition y(0+) = 0.4547 for it. This is achieved by the
impulse 0.4547δ(t), which arrives before the sinusoid and eliminates the need for the
homogeneous response.
9.3
The Frequency Response H (ω )
The response of an LTI system to a sinusoidal input is sinusoidal with the same frequency.
Generally, the system changes the magnitude and phase of the sinusoidal input and
the change is frequency dependent. The frequency response determines the changes in
magnitude and phase of the sinusoidal input when it goes through the LTI system. The
frequency response of an LTI system has two parts: a magnitude response and a phase
response, both of which are functions of the frequency ω. Therefore,
cos ωt ⇒|H(ω)| cos(ωt + θ)
The magnitude and phase of the frequency response can be combined as a complex
function and shown by H(ω) = |H(ω)|̸ θ.
From another point of view, the magnitude and phase of a sinusoidal function can be
shown by a complex number called the complex amplitude or the phasor. The sinusoidal

Signals and Systems
497
input x(t) and output y(t) are then represented by their complex amplitudes, or phasors,
X and Y. The frequency response may be deﬁned as the ratio of the output phasor to the
input phasor.
H(ω) =
Y
X = |H(ω)|e jθ(ω)
cos(ωt) ⇒|H(ω)| cos(ωt + θ)
The frequency response of an LTI system may be measured experimentally from si-
nusoidal input-output pairs, without knowledge of the system’s internal structure or its
mathematical model. It may also be obtained from the system function, the unit-impulse
response, or from the input-output differential equation.
H (ω) Characterizes the System
The frequency response isn’t just useful in ﬁnding a system’s response to a single sinu-
soid. It provides the system’s response to any input that can be expressed as a sum of
sinusoids (i.e., almost all signals of interest in engineering and sciences). In fact, from
the frequency response one can obtain the system function, the input-output differential
equation, and the response to any input in a causal system.
H (ω) May Be Obtained from H(s)4
The frequency response of an LTI system may be found from its system function H(s)
by setting s = jω
H(ω) = H(s)

s= jω = |H(ω)|e jθ(ω) = |H(ω)|̸ θ(ω)
To verify the above statement we observe the following:
1.
H(s) is the scale factor for the exponential input:
est ⇒H(s)est
2.
The real part of the response to an input is equal to the response of the system to
the real part of that input:
x(t)
⇒
y(t)
RE{x(t)}
⇒
RE{y(t)}
3.
A cosine signal is the real part of an exponential signal:
cos(ωt) = RE{e jωt}
4H(s) is a real function of the complex number s. H(ω) is a complex function of a real number ω. From the
substitution s = jω one can rightly conclude that the frequency response is a real function of jω and
represent it by H( jω), as done by some authors. For simplicity, we avoid this representation and show the
frequency response by H(ω), but remember that it is a complex function of ω. It is deﬁned on its own as a
characteristic of the system which shows the change in magnitude and phase of a sinusoid signal passing
through the system and not just a derivation from H(s). Because of its close relationship with the system
function, we use the symbol H doubly to represent both.

498
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
The above observations are summarized below:
e jωt
⇒
H(ω)e jωt
RE{e jωt}
⇒
RE{H(ω)e jωt}
⇓
⇓
⇓
⇓
⇓
⇓
cos(ωt)
⇒
|H(ω)| cos(ωt + θ)
Moreover, as will be seen below, the square of the magnitude of the frequency
response is found from
|H(ω)|2 = H(ω)H ∗(ω) = H(s)H(−s)|s= jω
where H ∗(ω) is the complex conjugate of H(ω).
Finding |H (ω)|2 from H (s) H (−s)
The square magnitude of the frequency response is |H(ω)|2 = H(ω)H ∗(ω). But
H(ω) = H(s)|s= jω
H ∗(ω) = H(s)|s=−jω = H(−s)|s= jω
|H(ω)|2 = H(ω)H ∗(ω) = H(s)H(−s)|s= jω
This provides an easy way to obtain the magnitude of the frequency response from the
system function.
Example
9.14
A zero (or a pole) at s = a contributes the term (s −a) to the numerator (or the
denominator if a pole) of H(s). Its contribution to the square of the magnitude of
H(ω) is
|H(ω)|2 = (s −a)(−s −a)

s= jω = (a2 −s2)

s= jω = a2 + ω2
Example
9.15
A pair of conjugate zeros (or poles) at re± jθ contribute the following terms to H(s).
(s −re jθ)(s −re−jθ) = s2 −(2r cos θ)s + r2
Their contribution to the square of the magnitude of H(ω) is
|H(ω)|2 = [s2 −(2r cos θ)s + r2][s2 + (2r cos θ)s + r2]

s= jω
= [s4 −(2r2 cos 2θ)s2 + r4]

s= jω
= ω4 + (2r2 cos 2θ)ω2 + r4
Symmetry Properties of H (ω)
Let H(ω) = |H|̸ θ, where |H| and θ are its magnitude and phase angle, respectively.
|H| is an even function and θ is an odd function of ω. Knowledge of |H| and θ for
ω > 0, therefore, provides full information about the system. Furthermore, if the system
is causal, the magnitude and phase are related to each other.

Signals and Systems
499
Example
9.16
Find and plot the magnitude and phase of
a.
H1(s) = 1/(s + 1).
b.
H2(s) = s/(s + 1). Verify that the magnitudes are even and phases are odd
functions of ω.
Solution
a. H1(s) =
1
s + 1, H1(ω) =
1
1 + jω,
|H1| =
1
√
1 + ω2 , ̸ H1 = −tan−1 ω
b. H2(s) =
s
s + 1, H2(ω) =
jω
1 + jω,
|H2| =

ω2
1 + ω2 , ̸ H2 =

π/2 −tan−1 ω
ω > 0
−π/2 −tan−1 ω
ω < 0
Plots in Figure 9.1 exhibit even symmetry of magnitude and odd symmetry of phase
angles. The symmetry properties may also be veriﬁed by observing that magnitude
–10
–8
–6
–4
–2
Angular frequency in rad/s
(a) H1 (s) = 1/(s + 1)
0
2
4
6
8
10
0
0.2
0.4
Magnitude
0.6
0.8
1
–10
–8
–6
–4
–2
Angular frequency in rad/s
Magnitude Plot
Phase Plot
Magnitude Plot
Phase Plot
0
2
4
6
8
10
–60
–80
0
Phase in degrees
20
–20
–40
60
40
80
–10
–8
–6
–4
–2
Angular frequency in rad/s
(b) H2 (s) = s/(s + 1)
0
2
4
6
8
10
0
0.2
0.4
Magnitude
0.6
0.8
1
–10
–8
–6
–4
–2
Angular frequency in rad/s
0
2
4
6
8
10
–60
–80
0
Phase in degrees
20
–20
–40
60
40
80
FIGURE 9.1 Symmetry properties of the frequency response. Magnitude and phase plots of the frequency response of
H1(s) = 1/(s + 1) are shown in the upper row for −10 < ω < 10 and those of H2(s) = s/(s + 1) in the lower row.
Magnitudes are aligned on the left side and phases on the right side to show their even and odd symmetry properties,
respectively.

500
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
is a function of ω2 (which is an even function of ω) and phase is a function of
tan−1(ω) (which is an odd function of ω). One may also reach the same conclusion
by substituting −ω for ω and observing no change in |H| and sign reversal in ̸ H.
Finding H (s) from |H (ω)|2
Given an |H(ω)| we can apply a reverse process to ﬁnd H(s) of the associated causal
stable system.
H(s)H(−s) = |H(ω)|2
ω=−js
The resulting product H(s)H(−s) has symmetrical poles in the LHP and RHP. By
choosing the LHP poles we obtain H(s) of the stable system whose magnitude frequency
response is |H(ω)|. 5
Example
9.17
Find the H(s) of a causal stable system whose magnitude-squared frequency response
is |H(ω)|2 = 1/(1 + ω4).
Solution
H(s)H(−s) =
1
1 + ω4

ω=−js =
1
1 + s4
The right-half plane (RHP) roots of the equation 1 + s4 = 0 are at s1,2 = e± jπ/4
The left-half plane (LHP) roots of the equation 1 + s4 = 0 are at s3,4 = e± j3π/4
The LHP roots will be chosen as the poles of the stable system. The system
function is
H(s) =
1
(s −e j3π/4)(s −e−j3π/4) =
1
s2 −(2 cos 3π
4 )s + 1 =
1
s2 +
√
2s + 1
This is called a second-order low-pass Butterworth ﬁlter.
9.4
Plotting H(ω )
H(ω) is a complex function of ω. (And in this book it is a real function of jω unless
speciﬁed otherwise.) Graphically, H(ω) can be shown in several ways, some of which
are
1.
The magnitude and phase plots as functions of ω.
2.
The magnitude and phase in the form of a polar plot.
3.
The plots of the real and imaginary parts as functions of ω.
We will do the magnitude and phase plots. The frequency axis ω may be in linear or log
scale. The magnitude |H| may be shown in linear or log scale [in 20 log |H| units called
5To obtain a unique solution, we also need to know whether the system’s zeros are in the LHP or RHP.

Signals and Systems
501
decibell (dB)]. The phase ̸ H is shown in degrees. The special case of the twin plots of
20 log |H(ω)| and ̸ H(ω) versus log ω is called the Bode plot, which we generally use
unless something different is required.
Computers and calculators provide the preferred methods for plotting, and due to
their convenience and speed they can also facilitate qualitative exploration of a system’s
performance under various conditions. But plotting by computer doesn’t provide much
insight into some interesting aspects of the system (e.g., approximations within a fre-
quency range, the asymptotic behavior, the effect of proximity to a pole or zero, the 3-dB
break points, and so on). A similar rational applies for the vectorial interpretation of the
frequency response, which is the subject of the next section. The present section uses
plotting H(ω) as a context for gaining such an insight. It starts with contribution from
a single pole or zero and concludes with sketching a Bode plot by hand, which requires
a better understanding of the role of the system’s elements in forming the frequency
response.
Bode Plot: What Is It?
The Bode plot of the frequency response H(ω) of an LTI system is the graph of
20 log |H(ω)| (magnitude in dB) and ̸ H(ω) (phase angle) both plotted versus log ω.
In some cases a reference level HR [e.g., |H(0)| or |Hmax|] is used in drawing the plot.
The magnitude of the Bode plot is then 20 log |H(ω)/HR|, where 0 dB indicates the
reference level. Because of the nature of the logarithm, contributions from individual
zeros add to and those of poles subtract from the plots. We start by examining the effect
of a single zero or pole on the Bode plot.
Bode Plot: A Single Zero
Consider the system function H(s) = 1 + s/ω0. Note that H(s) has a single zero at
s = −ωo. The frequency response, its magnitude (in dB), and its phase are
H(ω) = 1 + j(ω/ω0)
20 log |H(ω)| = 720 log |1 + j(ω/ω0)| = 10 log[1 + (ω/ω0)2]
̸ H(ω) = ̸ [1 + j(ω/ω0)] = tan−1(ω/ω0)
We want to plot 20 log |H(ω)| and ̸ H(ω) vs. log ω. At very low frequencies where
ω << ω0, we may drop j(ω/ω0) against 1.6 Then,
H(ω) ≈1,
20 log |H| ≈0,
̸ H ≈0
The low-frequency asymptote of the magnitude and phase are 0 dB and 0◦, respectively.
At very high frequencies where ω >> ω0, we may drop 1 against j(ω/ω0). Then,
H(ω) ≈j(ω/ω0),
20 log |H| ≈20 log(ω/ω0) dB,
̸ H ≈90◦
The high-frequency asymptotes of the magnitude and phase are 20 log(ω/ω0) dB and
90◦, respectively. The high-frequency asymptote of the magnitude plotted versus log ω
6For a better approximation at ω << ω0, see Table 9.1.

502
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
is a line with a 20-dB/decade slope (6 dB/ octave) which passes through 0 dB at ω = ω0.
At ω = ω0, called the break frequency, we have
H(ω0) = 1 + j =
√
2̸ 45◦, 20 log |H| = 3 dB,
̸ H = 45◦
Note that the break frequency is at the zero of H(s). Also note that at ω = ω0/2 and
ω = 2ω0, the magnitude is 20 log(5/4) = 1 dB and 20 log
√
5 = 7 dB, respectively,
each of which are 1 dB above the value of their respective asymptotes. The phases at
these frequencies are tan−1(1/2) = 26.5◦and tan−1{2} = 63.5◦, respectively. These
results, summarized in Table 9.1, can be used to sketch the magnitude and phase plots
of Figure 9.2.
TABLE 9.1 Magnitude and Phase of H(ω) = 1 + j(ω/ω0)
Frequency ω
0
ω << ω0
ω0/2
ω0
2ω0
ω >> ω0
∞
Magnitude, 20 log |H(ω)| in dB
0
≈4.343
 ω
ω0
2
1
3
7
≈20 log
 ω
ω0

∞
Phase, ̸ H(ω) in degrees
0
≈180
π
ω
ω0
26.5◦
45◦
63.5◦
≈
	
90◦−180
π
ωo
ω

90◦
10−2
10−1
100
101
102
0
5
10
15
20
25
30
35
40
Magnitude (dB)
Angular frequency (rad/s)
10−2
10−1
100
101
102
Angular frequency (rad/s)
(a)
(b)
0
10
20
30
40
50
60
70
80
90
Phase (degree)
FIGURE 9.2 Bode plots of the magnitude (a) and phase (b) of 1 + j(ω/ω0) versus ω/ω0 for the range
0.01 < ω/ω0 < 100. The low-frequency asymptote of the magnitude plot is a ﬂat 0-dB line. Its high-frequency
asymptote is the line with a slope of 20 dB per decade (6 dB per octave). These two asymptotes intersect at ω0 on the
frequency axis, called the break frequency, where the magnitude is 3 dB and the phase is 45◦. An examination of the
plots within the range 0.5 < ω/ω0 < 2 shows that at both ends of this range the magnitude is approximately 1 dB above
the asymptote and the phase is 26.6◦away from it. More exactly,
at ω = ω0/2
Magnitude = 0.969 dB,
phase = 26.56◦
at ω = 2ω0
Magnitude = 6.99 dB,
phase = 63.44◦

Signals and Systems
503
Note: Forω << ω0 wehaveapproximated20 log |H(ω)|byitsTaylorseriesexpansion.
ln(1 + x) = x −x2
2 + x3
3 −x4
4 + · · · + (−1)n−1 xn
n + · · ·
ln x = ln(10) × log x = 2.3 log x
10 log

1 +
	 ω
ω0

2
≈10
2.3
	 ω
ω0

2
≈4.343
	 ω
ω0

2
for ω << ω0
For example, let ω = 0.1 and ω0 = 1. By the above approximation we have 10 log[1 +
(ω/ω0)2] ≈0.04343. The exact value is 10 log(1 + 0.01) = 0.0432.
Bode Plot: A Single Pole
Consider a system with a single pole at s = −ωo. The system function and frequency
response are
H(s) =
1
1 + (s/ω0)
H(ω) =
1
1 + j(ω/ω0)
20 log |H(ω)| = −20 log |1 + j(ω/ω0)| = −10 log[1 + (ω/ω0)2]
̸ H(ω) = −̸ [1 + j(ω/ω0)] = −tan−1(ω/ω0)
The Bode plot of 1/[1+ j(ω/ω0)] is similar to that of 1+ j(ω/ω0) except for an opposite
sign. Flip the magnitude and phase plots of the system with a zero (Figure 9.2) downward
aroundtheω axistoseethecontributionfromapole.Thelow-frequencyasymptotesofthe
magnitude and phase are 0 dB and 0◦, respectively. The high-frequency asymptotes of the
magnitude and phase are −20 log(ω/ω0) dB and −90◦, respectively. The high-frequency
asymptote of the magnitude plotted versus log ω is a line with a −20 dB/decade slope.
At ω0 the magnitude is −3 dB and the phase is −45◦. At ω0/2 and 2ω0 the magnitude is
1 dB below the value of the respective asymptotes. The phase at those two frequencies
is −26.5◦and −63.5◦, respectively. These observations are summarized in Table 9.2.
TABLE 9.2 Magnitude and Phase of H(ω) =
1
1+ j(ω/ω0)
Frequency ω
0
ω << ω0
ω0/2
ω0
2ω0
ω >> ω0
∞
Magnitude, 20 log |H(ω)| in dB
0
≈−4.343
 ω
ω0
2
−1
−3
−7
≈−20 log
 ω
ω0

−∞
Phase, ̸ H(ω) in degrees
0
≈−180
π
ω
ω0
−26.5◦
−45◦
−63.5◦
≈
	
180
π
ωo
ω −90◦

−90◦

504
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Summary of Asymptotic Behavior
The asymptotic behavior of the Bode plot of a system with a single zero or a pole is
summarized below.
20 log |H(ω)| = ±10 log

1 +
	 ω
ω0

2
≈±







0
ω << ω0 (low-frequency asymptote)
3 dB
ω = ω0
(break frequency)
20 log
	 ω
ω0

ω >> ω0 (high-frequency asymptote)
̸ H(ω) = ± tan−1
	 ω
ω0

≈±









0
ω << ω0 (low-frequency asymptote)
±π
4
ω = ω0
(break frequency)
±π
2
ω >> ω0 (high-frequency asymptote)
in which the upper signs refer to a zero and the lower to a pole.
Example
9.18
Find and sketch the frequency response of an LTI system with a pole in the left half
of the s-plane at s = −σ, a zero at s = 0, and a high-frequency gain of 1.
−40
−35
−30
−25
−20
−15
−10
−5
0
Magnitude in dB
Angular frequency in rad/s, log scale
0
10
20
30
40
50
60
70
80
90
Angular frequency in rad/s, log scale
H(s) = s/(s + 1)
Phase in degrees
10−2
10−1
100
101
102
10−2
10−1
100
101
102
(a)
(b)
Magnitude Plot
Phase Plot
FIGURE 9.3 Magnitude (a) and phase (b) of H(s) = s/(s + 1) in log scales. The magnitude
plot shows 20 log |H(ω)| (in dB) and the phase plot shows ̸ H(ω) (in degrees). Both are plotted
versus log ω. This is called a Bode plot. The system is high-pass with a high-frequency gain of 1
(corresponding to 0 dB). Its half-power frequency is at ω = 1 rad/s where the magnitude plot shows
−3 dB. Compare the Bode plot with the linear plot given in Figure 9.1(b). Note the advantage of
the Bode plot over the linear plot in its ability to cover a larger range of frequency and provide
more detail at low frequencies. In addition, at the lower and higher limits of ω the magnitude plot
[20 log |H(ω)| versus log ω] becomes straight lines as seen in this ﬁgure. This property makes
Bode plot an attractive tool for visualization of the frequency response and will be used in the rest
of this chapter.

Signals and Systems
505
Solution
H(s) =
s
s + σ
H(ω) =
jω
jω + σ
|H(ω)|2 =
ω2
ω2 + σ 2
̸ H(ω) = 90◦−tan−1 ω
σ

The system is a high-pass ﬁlter with −3-dB frequency at ω = σ. Its frequency
response is plotted in Figure 9.3 (in log scale) for σ = 1. The linear-scale plots of the
same system were shown in Figure 9.1(b).
Bode Plot: A Pair of Poles
Consider the second-order stable system function with two complex poles at p1 and p2,
no ﬁnite zeros, and unity DC gain. The system function may be written in the form
H(s) =
ω2
0
s2 + 2ζω0s + ω2
0
where ω0 = √p1 p2 is called the undamped natural frequency and ζ = −(p1+p2)/(2ω0)
is called the damping ratio. Dividing the numerator and denominator by ω2
0 and substi-
tuting for s = jω we have
H(ω) =
1
1 −
 ω
ω0
2 + j2ζ
 ω
ω0

At very low frequencies where ω << ω0, H(ω) ≈1, which results in the low-frequency
asymptote of 20 log |H| = 0 dB and ̸ H = 0. At very high frequencies where ω >>
ω0, H(ω) ≈−(ω0/ω)2, which results in the high-frequency asymptote of 20 log |H| =
−40 log(ω/ω0) and ̸ H = −180◦. The high-frequency asymptote appears as a straight
line with a slope of −40 dB/decade when it is plotted versus log(ω/ω0). At the break
frequency ω = ω0, H(ω) = −j/(2ζ), which results in 20 log |H| = −20 log(2ζ) and
̸ H = −90◦.
In signal processing applications, the above system is speciﬁed by ω0 and the quality
factor Q = 1/(2ζ). The system function and frequency response may be written in terms
of ω0 and Q:
H(s) =
ω2
0
s2 + ω0
Q s + ω2
0
and
H(ω) =
1
1 −
 ω
ω0
2 +
j
Q
 ω
ω0


506
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
The break frequency and asymptotes are the same as before. The magnitude at ω0 is
|H(ω0)| = Q, equal to the quality factor, or, expressed in dB units, 20 log |H(ω0)| =
20 log Q dB.
The above formulations apply to the second-order system for all values of ζ or
Q (i.e., regardless of whether the poles are real or complex numbers). For the case of
complex conjugate poles p1,2 = −σ ± jωd, ω0 =

σ 2 + ω2
d, and ζ = σ/ω0. The
relationship between a pair of complex conjugate poles, the natural frequency ω0, the
damping ratio ζ, the quality factor Q, and the time responses is summarized in Figure 9.4
(see also sections 9.6 and 9.7 to 9.21).
poles
p1,2 = −σ ± jωd = ω0e± jθ
undamped natural frequency
ω0 =

σ 2 + ω2
d
system function
H(s) =
ω2
0
s2 + 2σs + ω2
0
ﬁltering and signal processing
H(s) =
ω2
0
s2 + ω0
Q s + ω2
0
quality factor
Q = ω0
2σ = 1
2ζ
damping state



overdamped
Q < 0.5, ζ > 1
critically damped
Q = 0.5, ζ = 1
underdamped
Q > 0.5, ζ < 1
control applications
H(s) =
ω2
0
s2 + 2ζω0s + ω2
0
damping ratio
ζ = σ
ω0
unit-step response
g(t) =

1 −
1

1 −ζ 2 e−σt cos(ωdt −φ)

u(t)
phase angle of step response φ
sin φ = ζ
percentage overshoot in g(t)
ρ = 100 × e
−
πζ
√
1−ζ2
unit-impulse response
h(t) =
ω0

1 −ζ 2 e−σt sin ωdt u(t)

Signals and Systems
507
−6
−5
−4
−3
−2
−1
0
1
−6
−4
−2
0
2
4
6
Pole  Plot of H (s) = 1/(s2 + 6s + 25)
Real
Imaginary
p1
p2
jω
ω0
−ω0
−σ
ωd
−ωd
0
FIGURE 9.4 Relationship between a pair of complex poles, H(s), ζ, Q, and the time responses.
This ﬁgure is plot of the poles of H(s) = 1/(s2 + 6s + 25).
Example
9.19
Plot the poles, and time and frequency responses of the following two second-order
systems:
H1(s) =
1
s2 + 5s + 1
and
H2(s) =
1
s2 + 0.1s + 1
Discuss the effect of poles locations on systems’ responses.
Solution
The poles, quality factor, damping ratio, and state of the systems are summarized in
the table below. The poles, step responses, and magnitude and phase Bode plots of
the second-order systems are shown in Figure 9.5.
System
Poles
Quality Factor
Damping Ratio
Damping State
H1(s) =
1
s2 + 5s + 1
−4.7913, −.2087
Q = 0.2
ζ = 2.5
overdamped
H2(s) =
1
s2 + 0.1s + 1
−0.05 ± j0.9987 = e± j92.8◦
Q = 10
ζ = 0.05
underdamped

508
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
−5 −4.5 −4 −3.5 −3 −2.5 −2 −1.5 −1 −0.5
0
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Real
Imaginary
10−2
10−1
100
101
102
10−2
10−1
100
101
102
−80
−70
−60
−50
−40
−30
−20
−10
0
10
20
Magnitude (dB)
Angular frequency (rad/s)
(a) Pole location for Q = 0.2 (two real poles) and
Q = 10 (two complex poles close to the jω  axis).
(b) Magnitude of the responses, Q = 0.2 and 10.
2
1
2
1
Angular frequency (rad/s)
0
5
10
15
20
25
30
35
40
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (s)
(d) Phase of the responses, Q = 0.2 and 10.
(c) Time response to a unit-impulse input, Q = 0.2 and 10.
Amplitude
−180
−160
−140
−120
−100
−80
−60
−40
−20
0
Angle (deg)
FIGURE 9.5 Pole plots and time/frequency responses of two second-order systems are superimposed. System 1 is
overdamped and functions as a low-pass ﬁlter. System 2 has a high Q and can function as a bandpass ﬁlter.
In H1 the poles are real and negative, Q is low, ζ is high, and the system is heavily
overdamped. The unit-impulse response shows no oscillations and the magnitude plot
of the frequency response remains below the low-frequency asymptote (DC level) at
all frequencies. In contrast, H2(s) has two complex conjugate poles at an angle close
to the jω axis, Q is high, and ζ is low. The system is greatly underdamped (damping
ratio ζ = 0.05) and the system is highly oscillatory. This is evidenced by oscillations
in its unit-impulse response and also a sharp and selective magnitude response around
ω = 1. The magnitude at ω = 1 is equal to 20 log Q = 20 dB. The magnitude goes
above the low-frequency asymptote.

Signals and Systems
509
Summary
A second-order system with two poles and no ﬁnite zeros is speciﬁed by its undamped
natural frequency ω0, quality factor Q, and DC gain K.
H(s) = K
ω2
0
s2 + ω0
Q s + ω2
0
The quality factor Q shapes the system’s time and frequency responses. If Q is low
(i.e., in an overdamped system with negative real poles) the system is low-pass. If Q is
high (i.e., in an underdamped system with complex conjugate poles at an angle close
to the jω axis) the system has a sharp and selective magnitude frequency response
around its undamped natural frequency, functioning as a resonator.
Bode Plot: Several Poles or Zeros
The system function of a realizable system made of lumped linear elements is in the form
of the ratio of two polynomials with real coefﬁcients. The poles and zeros of the system
function are, therefore, either real or complex conjugate pairs. The system function may
be written in the form of
H(s) = Ho
(s −z1)(s −z2) · · · (s −zk) · · · (s −zM)
(s −p1)(s −p2) · · · (s −pℓ) · · · (s −pN)
where zk and pℓare the zeros and poles, of the system, respectively. The magnitude (in
dB) and the phase are
20 log |H(ω)| = 20 log |Ho| +
M

i=1
20 log | jω −zk| −
N

i=1
20 log | jω −pℓ|
̸ H(ω) =
M

k=1
̸ ( jω −zk) −
N

ℓ=1
̸ ( jω −pℓ)
Contributions to Bode plots from zeros add, while those of poles subtract. Consequently,
the Bode plot of a system may be found by algebraically adding plots of its cascaded
subsystems Hi.
H = H1 × H2 × H3 · · · × Hi · · · × HT
Then
20 log |H| =
T

i=1
20 log |Hi| and
̸ H =
T

i=1
̸ Hi
where T is the total number of subsystems. Theoretically, one may partition a system
with M zeros and N poles into T = M + N subsystems, each made of a single zero or
pole. In practice, one may expand H(s) into its ﬁrst-order and second-order subsystems,
in which case case T ≤N. Example 9.20 illustrates construction of the Bode plot of a
third-order system from its subsystems.

510
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Example
9.20
Plot the magnitude and phase of
H(s) =
106
s3 + 200s2 + 2 × 104s + 106 =
106
(s + 100)(s2 + 100s + 10,000)
Solution
The system function may be expressed as H(s) = H1(s) × H2(s), where
H1(s) =
102
s + 100,
H1(ω) has a break point at ω0 = 100.
H2(s) =
104
s2 + 100s + 10,000,
H2(ω) has a break point at ω0 = 100 and Q = 1.
Using the procedures described previously, the individual Bode plots for each segment
of the system function may be constructed separately and the results added. See
Table 9.3 and Figure 9.6.
TABLE 9.3 Adding Bode Plots of Two Subsystems H1 and H2 to
Obtain the Bode Plot of the System H = H1 × H2
System
DC Gain
ω0
dB∗at ω0
High-Frequency Slope
H1
0 dB
100 r/s
−3 dB
−20 dB/decade
H2
0 dB
100 r/s
0 dB
−40 dB/decade
H1 × H2
0 dB
100 r/s
−3 dB
−60 dB/decade
∗Relative to the DC level.
−120
−100
−80
−60
−40
−20
0
Magnitude (dB)
100
101
102
103
104
−250
−200
−150
−100
−50
0
Angular frequency (rad/s)
100
101
102
103
104
Angular frequency (rad/s)
Phase
Magnitude
Phase (deg)
FIGURE 9.6 Bode plot of H =
106
s3 + 200s2 + 104s + 106 =
102
s + 100 ×
104
s2 + 100s + 104 may be obtained from the
plots of its cascaded subsystems. For details see Example 9.20.

Signals and Systems
511
Bode Plot: Graphing by Computer
Bode plots of a system (along with other characteristics such as step response, impulse
response, pole-zero plots, etc.) may be conveniently obtained through the use of a com-
puter software package. See Example 9.21 and problem 28.
Example
9.21
Given the system function
H(s) =
s + 3
(s + 15)(s + 500)
Find the magnitude and phase of its frequency response as functions of ω. Reduce
them to polynomial forms. Write a computer program to plot the above magnitude
and phase in the form of Bode plots.
Solution
H(s) =
s + 3
s2 + 515s + 7,500,
H(ω) =
jω + 3
7,500 −ω2 + j515ω
|H(ω)|2 =
ω2 + 9
ω4 + 250,225ω2 + 5,625 × 104 ,
̸ H(ω) = tan−1 ω
3

−tan−1
	
515ω
7,500 −ω2

H(s) =
s + 3
(s + 15)(s + 500),
H(ω) =
jω + 3
( jω + 15)( jω + 500)
20 log |H(ω)| = 10 log(ω2 + 9) −10 log(ω2 + 225) −10 log(ω2 + 250,000)
̸ H(ω) = tan−1 ω
3

−tan−1  ω
15

−tan−1  ω
500

Using the program given below one can plot 20 log |H(ω)| and ̸ H(ω) versus log ω.
clear
w=logspace( -1,4,1001);
s=i*w;
H=(s+3)./((s+15).*(s+500));
plot(log10(w),20*log10(abs(H)));
grid
plot(log10(w),angle(H));
grid
Other commands that can be more convenient or ﬂexible for generating Bode plots are
often used. The Bode plot for the current system function may also be generated by the
following program.

512
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
num=[1 3];
den=[1 515 7500];
sys=tf(num,den); %tf
constructs
the
transfer
(i.e.,
sys-
tem) function
grid
bode(sys)
The following set of commands can provide more ﬂexibility and is used for most Bode
plots in this chapter.
w=logspace( -1,4,1001);
num=[1 3];
den=[1 515 7500];
[mag,angle]=Bode(num,den,w);
semilogx(w,20*log10(mag));
semilogx(w,angle);
Bode Plot: Sketching by Hand
Bode plots of a system may be constructed and sketched readily based on contributions
from poles and zeros. For simplicity, we start with systems having real-valued poles and
zeros that are apart from each other. To sketch the Bode plot you may follow the steps
below.
Step 1.
Specify the poles and zeros of the system. Determine the desired range of the
frequency to be plotted.
Step 2.
Use semilog paper. The log scale will be used for the horizontal axis (frequency
ω inrad/sor f inHz).Theverticalaxiswillhaveauniformscale(formagnitude
in dB and phase in degrees or radians). Label the frequency axis from left to
right(representingincreasingfrequency)tosatisfythedesiredrangeoftheplot.
Label the vertical axes from bottom to top (representing increasing values) to
satisfy the desired range of the magnitude or angle. The magnitude and phase
may be plotted on separate graphs or share the same set of axes.
Step 3.
Mark the frequency axis at points corresponding to the value of the system’s
poles and zeros (or their absolute value if they are complex-valued). These
will constitute break points in the asymptotic plots produced by zeros and
poles. They will simply be called zeros and poles. Each will contribute to the
plot as explained previously. Their contributions in dB and radians will add or
subtract.
Step 4.
Starting from a low frequency, draw the asymptotic lines for the magnitude
plot. These are a series of lines with slopes of ±20k dB per dacade, k =
0, 1, 2, . . .. When encountering a break point corresponding to a zero, the
slope of the asymptote will increase by 20 dB/decade (6 dB/octave) over the
previous segment. A break point corresponding to a pole will pull down the

Signals and Systems
513
asymptote by 20 dB/decade. The change will double if a double pole or zero
(or a complex-valued pair) is encountered.
Step 5.
Similarly,sketchthephasecontributionofapoleorzerousing±90◦asymptotic
lines. Then add them algebraically. When encountering a zero the phase will
increase toward a 90◦asymptote. A pole will pull down the asymptote by
a −90◦asymptote. The change will double if a double pole or zero (or a
complex-valued pair) is encountered.
Step 6.
At a break point corresponding to a simple zero or pole the magnitude and
phase plots deviate from the asymptotes by ±3 dB and ±45◦, respectively. At
a break point corresponding to a pair of complex zeros or poles the magnitude
deviation from the asymptote is ±20 log Q dB.
Step 7.
The accuracy of the sketches can be improved by using the values of magnitude
and phase at frequencies half and twice the break frequencies: 1 dB above the
asymptote for a zero or 1 dB below it for a pole.
Example
9.22
Contributions to Bode plots
The system function H(s) = 50(s + 10)/[(s + 1)(s + 200)] has a zero at s = −10,
two poles at −1 and −200, and a gain factor 50. Plot its Bode diagram and graphically
show individual contributions from the zero and the poles to it.
Solution
The system function has a zero at s = −10, two poles at −1 and −200, and a gain
factor 50. The magnitude plots are shown in Figure 9.7(a). The line labeled 1 shows
contribution from 1/(s+1) (the ﬁrst pole at s = −1). It has a DC gain of 0 dB, a break
point at ω = 1, and a downward asymptote with −20-dB slope. Line number 2 is due
to s + 10 (the zero at s = 10). It has a DC gain of 20 log 10 = 20 dB, a break point at
ω = 10, and an upward asymptote with 20-dB slope. Contribution from 1/(s + 200)
(the second pole) has a DC gain of −20 log 200 = −46 dB, a break point at ω = 200,
and a −20 dB/decade asymptote. The line number 4 is the magnitude plot for H(s).
It is equal to the algebraic addition of lines 1, 2 and 3, plus 20 log 50 = 34 dB due to
the gain factor. The DC gain of the system is H(s)|s=0 = 2.5, corresponding to 8 dB.
This is equal to the algebraic sum of individual DC components from the poles, zero,
and the gain factor, 34 −0 + 20 −46 = 8 dB. In a similar way, contributions from
the poles and the zero to the phase plot are shown in Figure 9.7(b), labeled as in the
magnitude plot. Contribution from the ﬁrst pole at s = 1 is shown by line number
1, which goes from nearly 0 at low frequencies to nearly −90◦at high frequencies
(with −45◦dB at the break point ω = 1). The zero at s = 10 contributes line number
2, which grows from nearly 0 at low frequencies to nearly 90◦at high frequencies
(with 45◦dB at the break point ω = 10). The effect of the second pole is similar to
that of the ﬁrst pole except for a shift of 200 rad/s along the frequency axis. The gain
factor contributes zero to the phase. The total phase plot is shown by line number 4,
equal to the algebraic summation of 1, 2, and 3. In summary the frequency response
is obtained by algebraic addition of individual components. When the poles and the

514
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
zero are far enough from each other, this can be done visually and result in a sketch
by hand of the Bode plot, as shown in Example 9.23.
−60
−40
−20
0
20
40
60
Magnitude (dB)
10−1
100
101
102
103
104
−100
−80
−60
−40
−20
0
20
40
60
80
100
Angular frequency (rad/s)
10−1
100
2
2
3
4
1
4
1
3
101
102
103
104
Angular frequency (rad/s)
(b)
(a)
Angle (deg)
FIGURE 9.7 Contributions to the magnitude (a) and phase (b) of H(s) =
50(s+10)
(s+1)(s+200) (Example 9.22).
Example
9.23
Sketch the Bode plots for
H(s) =
104(s + 3)
(s + 50)(s + 600)
Solution
The system has a zero at s = −3 and two poles at s = −50 and −600. The break
frequencies are at ω = 3 rad/s (zero), and ω = 50, 600 rad/s (poles). The de-
sired range of frequency is taken to be 1 rad/s to 10 krad/s, requiring semilog paper
with a minimum of 4 decades. See Figure 9.8. The poles and the zero are distant
from each other, increasing the accuracy of the sketch. The magnitude is sketched
in Figure 9.8(a). The low-frequency magnitude asymptote is 0 dB. The magnitude
plot ﬁrst encounters the zero at ω = 3. The slope of the asymptote thus increases to
20 dB/decade (line number 1). At ω = 50, it encounters a pole and the slope is reduced
by 20 dB/decade, resulting in a ﬂat line (number 2). At ω = 600, it encounters the
second pole and the slope is reduced by another 20 dB/decade, resulting in a line with
a slope of −20 dB/decade, which forms the high-frequency asymptote (line number
3). These asymptotes are shown in Figure 9.8(a) by thin lines, marked 1, 2, and 3,
respectively.
At the ω = 1.5, 3, and 6 (related to the zero), the magnitude is 1, 3, and 6 + 1 =
7 dB, respectively. At the ω = 25, 50, and 100 (related to the ﬁrst pole), the magnitude
is below the asymptote by 1, 3, and 1 dB, respectively. Similarly, at ω = 300, 600,
and 1,200 (related to the second pole), the magnitude is below the asymptote by 1, 3,
and 1 dB, respectively, as shown in Figure 9.8(a). The above values are added and the
points are then connected by a smooth curve to form a sketch of the magnitude plot.
The phase plot is obtained by sketching the contributions from the poles and zeros
and adding them up. See Figure 9.8(b).

Signals and Systems
515
30
25
20
15
10
5
0
–5
Magnitude (dB)
10,000
1,000
100
(a)
(b)
10
3
1
2
3
1
50
600
90
80
60
40
20
–90
–80
–60
–40
–20
0
Phase (degrees)
10,000
w
w
1,000
100
Angular frequency (rad/s)
Angular frequency (rad/s)
10
3
1
2
3
1
50
600
FIGURE 9.8 Sketching the magnitude (a) and phase (b) of H(s) =
104(s+3)
(s+50)(s+600) based on its components.
9.5
Vectorial Interpretation of H (s) and H (ω )
A rational system function with M zeros and N poles may be written in terms of its
poles and zeros as follows:
H(s) = H0
k(s −zk)
ℓ(s −pℓ)
where zk with k = 1, 2, · · · M are zeros of the system, pℓwith ℓ= 1, 2, . . . , N are poles
of the system, and H0 is a gain factor. To simplify the discussion, assume H0 is a positive
number. A zero at zk contributes (s −zk) to the numerator of the system function. In
the s-plane this is a vector drawn from the point zk (the zero) to a point s (where the
system function is to be evaluated). Similarly, a pole at pℓcontributes (s −pℓ) to the
denominator of the system function. In the s-plane this is a vector drawn from the pole
at pℓto point s. Let Bk = (s −zk) designate the vector from zk to s, and Aℓ= (s −pℓ)
designate the vector from pℓto s. Then
H(s) = H0
B1 × B2 · · · × Bk · · · × B M
A1 × A2 · · · × Aℓ· · · × AN
= H0
k Bk
ℓAℓ
|H(s)| = H0
|B1| × |B2| · · · × |Bk| · · · × |B M|
|A1| × |A2| · · · × |Aℓ| · · · × |AN| = H0
k|Bk|
ℓ|Aℓ|
̸ H(s) =

̸ B1 + ̸ B2 · · · + ̸ Bk · · · + ̸ B M

−

̸ A1 + ̸ A2 · · · + ̸ Aℓ· · · + ̸ AN

=
M

k=1
̸ Bk −
N

ℓ=1
̸ Aℓ
The above method provides a graphical technique for evaluating H(s) at a desired point
in the s-plane, and also a qualitative observation of its properties.

516
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Determination of H (ω) Using Vectorial Interpretation
The frequency response is found by evaluating H(s) on the jω axis. Starting at the point
s = 0 (ω = 0) and moving upward toward ω = ∞, we can sketch H(ω) using its
vectorial interpretation. Because vectors from poles are in the denominator, the magni-
tude of the frequency response is increased when the operating frequency ω approaches
the neighborhood of a pole. Similarly, because the zero vectors are in the numerator,
the magnitude of the frequency response is decreased when the operating frequency
approaches a zero’s neighborhood. The qualitative insight obtained from the vectorial
interpretation of H(ω) is especially useful in approximating its behavior (e.g., its peak
and 3-dB bandwidth frequencies) near a pair of poles close to the jω axis. Example 9.24
illustrates this property.
Example
9.24
Consider a bandpass ﬁlter having a single zero at the origin and a pair of poles at
−0.1 ± j10. The ﬁlter is described by the system function
H(s) = K
s
s2 + 0.2s + 100
a.
Determine the constant factor K so that the maximum gain of |H(ω)| is 5.
b.
Set K = 1 and use the vectorial approach to determine or approximate
important features of H(ω) (e.g., the maximum value of the magnitude and its
frequency, the 3-dB lower and upper frequencies, and the 3-dB bandwidth).
c.
Compare the approximate values obtained from the vectorial representation
obtained in part b with their more exact values obtained by computation.
Solution
a.
The frequency response and its magnitude-squared function are
H(ω) =
j Kω
−ω2 + j0.2ω + 100
|H(ω)|2 =
K 2ω2
(100 −ω2)2 + (0.2ω)2
|H(ω)| attains its maximum at ω = 10, where |H|Max = 5K, resulting in
K = 1.
b.
The system has a pair of poles at −0.1 ± j10 (shown by A1 and A2 in
Figure 9.9) and a zero at the origin (shown by B). The frequency response,
evaluated for a frequency shown by point C on the jω axis, is obtained from
H(ω) =
BC
A1C × A2C
Examples of vectorial components of H(ω) are shown in Figure 9.9(a) (for
ω = 5) and Figure 9.9(b) (for ω = 10), while Figure 9.9(c) shows the vectors

Signals and Systems
517
−10
−5
0
5
10
Imaginary
A1
A2
B 
C 
9.9
9.95
10
10.05
10.1
Imaginary
A1
C
B 
A2
−0.15
−0.1
−0.05
0
0.05
9.9
9.95
10
10.05
10.1
Real
−0.15
−0.1
−0.05
0
0.05
Real
−0.15
−0.1
−0.05
0
0.05
Real
(a) Vector from poles and zero toward w = 5
(b) Vector from poles and zero toward w = 10
Imaginary
A1
C
C-high 
C-low
100
101
102
−40
−30
−20
−10
0
10
20
Magnitude (dB)
Angular frequency (rad/s)
100
101
102
Angular frequency (rad/s)
(c) Vector from A1 toward 9.9 < w  < 10.1
(d) Bode plots for H(s) = s/(s2 + 0.2s + 100)
−50
0
50
Angle (deg)
FIGURE 9.9 This ﬁgure analyzes and plots the frequency response of the bandpass system H(s) = s/(s2 + 0.2s + 100)
in relation to its vectorial interpretation. The system has two poles at −0.1 ± 10 j (shown by A1 and A2) and a zero at the
origin (shown by B). Point C represents the frequency at which H(ω) is evaluated. Then, H(ω) = BC/[A1C × A2C].
(a) shows the vectors’ conﬁguration for ω = 5. As one moves upward on the jω axis, the vector A1C decreases causing
|H(ω)| to increase, until at ω = 10 the vector A1C reaches its minimum of 0.1 [as seen from (b)] and |H(ω)| attains its
maximum of |HMax| = 5. At ω = 10 ± 0.1, (c), the length of A1C is increased by a factor of
√
2, causing |H(ω)| to be
reduced by that same factor, which brings it to 3 dB below its maximum. Therefore, the lower and upper 3-dB bandwidth
frequencies are ωℓ≈9.9 and ωh ≈10.1. The approximation is due to the fact that in the above process as ω moves
closer to the pole at A1, it gets farther away from the pole at A2, and the vector A2C grows slightly. The accuracy of the
approximation increases the closer the pole’s angle becomes to the jω axis (or, equivalently, at higher-quality factors).
At Q > 20, the approximation is considered acceptable. In the current case Q = 50, and 3-dB bandwidth of ω = 0.2 is
evenly divided between the lower and higher half-power frequencies. Computer-plotted magnitude and phase responses
are shown in (d) for 1 < ω < 100 rad/s. Note the sharp magnitude peak at ω = 10. See Example 9.24.

518
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
from A1 to ω = 10 and ω = 10 ± 0.1. To sketch H(ω) using vectorial
interpretation we start with point C at the origin ω = 0 and move upward
toward ω = ∞.
At ω = 0 we have BC = 0, which results in H(ω) = 0. As one moves
upward on the jω axis, BC grows and A1C becomes smaller, Figure 9.9(a),
resulting in the growth of |H(ω)|.7 The vector A1C is shortest at ω = 10 with a
length of 0.1. Because it is in the denominator of the H(s) it produces the
maximum of the magnitude response at that frequency. At ω = 10 ± 0.1 that
vector becomes 0.1
√
2 units long and produces the half-power points [see
Figure 9.9(c)]. The 3-dB bandwidth is, therefore, ω = 0.2 centered at
ω = 10, both in rad/s.
At ω = 10, Figure 9.9(b), we have
BC = 10̸ 90◦, A1C ≈0.1̸ 0◦and A2C ≈20̸ 90◦
H(10) =
10̸ 90◦
0.1̸ 0◦× 20̸ 90◦= 5
Note that despite the two approximations A1C and A2C at ω = 10, the
maximum value |HMax(ω)| = 5 and its location at ω = 10 are exact. In the
neighborhood of the pole (near ω = 10) the pole inﬂuences the frequency
response the most. As said before, the 3-dB band may be obtained from the
pole-zero plot by noting that at ω = 10 ± 0.1 the length of the vector AC from
the nearby pole is increased by a factor
√
2 from its minimum value of 0.1,
resulting in a 3-dB decrease in the magnitude. Thus,
ωℓ≈9.9, ωh ≈10.1,
and
ω = 0.2, all in radians/s
The exact values are found from a computer graph:
ωℓ= 9.9005, ωh = 10.1005,
and
ω = 0.2
The Bode plot of the system is given in Figure 9.9(d).
vector A1C is shortest at ω = 10
9.6
Second-Order Systems
In this section we consider a stable system with two poles in the left-half of the s-plane.
Contribution from the poles to the system function is represented by
H(s) =
b
s2 + 2as + b
where a and b are positive real numbers. The system has two poles at s1,2 = −a ±
√
a2 −b, which could be real or complex. The poles are in the left-half of the s-plane
and the system is stable. The position of the poles determines whether the system’s
7In this process A2C also grows but not enough to offset the reduction in A1C, except when we get close to
ω = 10.

Signals and Systems
519
unit-step response is oscillatory or not. Depending on the sign of a2 −b, we recognize
the following three cases.
Case 1.
a2 > b. The system has two distinct negative real poles on the negative real
axis at s1,2 = −ω1,2, where ω1,2 = a ±
√
a2 −b. Note that ω1ω2 = b and
ω1 + ω2 = 2a. The system function is called overdamped.
Case 2.
a2 = b. The system has a negative pole of order 2, that is, two identical poles
on the negative real axis at s = −ω0, where ω0 = a =
√
b. The system
function is called critically damped.
Case 3.
a2 < b. The system has two complex conjugate poles with negative real
parts, s1,2 = −σ ± jωd, where σ = a and ωd =
√
b −a2. Its step response
is oscillatory and the system function is called underdamped.
Because of their simplifying features, second-order systems are widely used in
modeling and analysis of systems. Consider the system having a pair of LHP poles and
no zeros, with input x(t), output y(t), unit-impulse response h(t), and unit-step response
g(t). The system may be represented in one of the following interrelated forms:
1.
Pole locations (p1,2)
2.
Undamped natural frequency and damping ratio (ω0, ζ) or
3.
Damped natural frequency and step response overshoot (ωd, ρ)
4.
Undamped natural frequency and quality factor (ω0, Q)
5.
Frequency response H(ω)
The ﬁrst three of these representations are given below for the case of a complex
conjugate pair of poles (see also Figure 9.4).
1.
By the location of the poles. Let the poles be at p1,2 = −σ ± jωd = ω0e± jθ. Then
H(s) =
ω2
0
(s+σ−jωd)(s+σ+ jωd) =
ω2
0
s2+2σs+ω2
0 , where ω2
0 = σ 2 + ω2
d
2.
By the undamped natural frequency ω0 and the damping ratio ζ. The system
function may be expressed as a function of the undamped natural frequency ω0
and damping ratio ζ:
H(s) =
b
s2 + 2as + b =
ω2
0
s2 + 2ζω0s + ω2
0
where ζ and ω0 are positive numbers. The system has a pair of complex conjugate
poles at p1,2 = −σ ± jωd, where
σ = ζω0 and ωd = ω0

1 −ζ 2
Note that by substitution we can verify that the undamped natural frequency is
σ 2 + ω2
d = ζ 2ω2
0 + (1 −ζ 2)ω2
0 = ω2
0
The poles are on a semicircle in the LHP with radius ω0, at an angle φ = sin−1 ζ
with the imaginary axis. See Figure 9.4. In the above formulation ω2
0 = b is called
the undamped natural frequency, ωd is called the damped natural frequency,

520
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
ζ = a/
√
b is called the damping ratio, and the poles are at
−ω0(ζ ±

ζ 2 −1). The value of ζ determines the damping state of the system
function:



ζ > 1,
overdamped
ζ = 1,
critically damped
ζ < 1,
underdamped
The response of the system to a unit-step input is
g(t) =

1 −
1

1 −ζ 2 e−σt cos(ωdt −φ)

u(t)
Note that φ, the phase angle of the step response, is the same as the angle of the
poles with the imaginary axis. The percentage overshoot in the step response is
ρ = 100 × e
−
πζ
√
1−ζ2
The unit-impulse response of the system is
h(t) = d
dt g(t) =
ω0

1 −ζ 2 e−σt sin ωdt u(t)
3.
By the undamped natural frequency ω0 and the quality factor Q. In signal
processing applications and ﬁlter design the above system function is expressed in
terms of the undamped natural frequency ω0 and quality factor Q, both of which
are real and positive numbers
H(s) =
b
s2 + 2as + b =
ω2
0
s2 + ω0
Q s + ω2
0
=
1

s
ω0
2
+ 1
Q
s
ω0 + 1
In the above formulation ω2
0 = b is the undamped natural frequency and Q =
√
b/(2a) is called the quality factor. The poles are at s1,2 = −ω0
2Q (1 ±

1 −4Q2),
which, depending on the value of Q, are either real or complex. It is seen that the
quality factor of a system is related to its damping ratio by the equation
Q = 1/(2ζ). This representation becomes helpful in the construction of Bode
plots and ﬁlter design. The quality factor Q speciﬁes the damping state of the
system and shapes the system’s responses in the time and frequency domains. The
following table summarizes the role of Q in determining the location of poles, and
whether the system is overdamped, critically damped, or underdamped
(oscillatory).
Q
Poles
System’s Step Response
Frequency Response
Q < 0.5
two distinct real poles
overdamped
low-pass
Q = 0.5
two identical real poles
critically damped
low-pass
Q > 0.5
two complex conjugate poles
underdamped
low-pass/bandpass

Signals and Systems
521
Bode Plot for a Second-Order System
In this section we plot the Bode diagram for the second-order system
H(s) =
ω2
0
s2 + ω0
Q s + ω2
0
and discuss the effect of the quality factor. As derived previously, the value of the
magnitude at ω0 is |H(ω0)| = Q, equal to the quality factor, or expressed in dB units,
20 log |H(ω0)| = 20 log Q dB. A higher Q produces a sharper peak at ω0. An example
is shown in Figure 9.10 for Q = 0.2, 0.707, 5, 10, and 50. For Q < 0.5, the poles
are real (the system is overdamped) and the magnitude doesn’t exceed the asymptote.
For Q = 0.5 the system is critically damped and has a double pole at −ω0 (the break
frequency), resulting in a −6-dB magnitude at that frequency. For Q > 0.5 the system
has a pair of complex conjugate poles at σ ± jωd (the system is underdamped). The
magnitude at ω0 is equal to 20 log Q (when Q is expressed in dB). If Q > 1, the plot
goes above the low-frequency asymptote. This phenomenon is present in other classes
of second-order systems (such as bandpass, high-pass, bandstop) which have a set of
zeros different from the above system function.
10−2
10−1
100
101
102
−80
−60
−40
−20
0
20
40
Magnitude (dB)
Angular frequency (rad/s)
10−2
10−1
100
101
102
Angular frequency (rad/s)
(a)
(b)
Q = 0.2
Q = 50
−180
−160
−140
−120
−100
−80
−60
−40
−20
0
Angle (deg)
Q = 50 
Q = 0.2 
FIGURE 9.10 Magnitude (a) and phase plots (b) of the low-pass second-order system H(s) = 1/(s2 +
1
Q s + 1) for
Q = 0.2, 0.707, 5, 10, and 50.
9.7
Dominant Poles
If the frequencies of signals that operate on the system are conﬁned to the neighborhood
of a pole pk (or a zero zk), the vector s −pℓ(or s −zk) will have the biggest rate of
change within that neighborhood and will inﬂuence and dominate the behavior of the
system most. The case of dominant poles is especially of interest in system modeling
because it allows us to reduce a complex system to a ﬁrst-order or a second-order model.
The simpliﬁed model will include only the dominant pole (and its conjugate if the pole
is complex), with a gain adjusted to match the original system.

522
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Single Dominant Pole
We ﬁrst examine the case of a single dominant pole that leads to a system model of
ﬁrst order. Consider a stable system containing M zeros and N + 1 poles, including a
negative pole at −σ in the LHP. The system function is
H(s) = H0
(s −z1)(s −z2) · · · (s −zk) · · · (s −zM)
(s −p1)(s −p2) · · · (s −pℓ) · · · (s −pN) ×
1
s + σ = HN(s) ×
1
s + σ
The multiplying factor HN(s) is the contribution from all poles and zeros other than
the pole at −σ. The above formulation, so far, uses no approximation. Now, let the
operating frequency s be near the pole −σ (and away from all other poles and zeros).
Then HN(s) ≈HN (in general, a complex number) may be considered almost a constant
factor and H(s) be simpliﬁed to
H(s) ≈
HN
s + σ
The new gain factor HN embodies the total effect of all other poles and zeros on H(s).
Those poles and zeros being away from the operating complex frequency s will exert
almost a ﬁxed effect, making HN nearly a constant. The complex system is then modeled
by a ﬁrst-order system.
Example
9.25
Modeling the 741 op-amp by its first-order pole
The 741 op-amp has a pole at f = 5 Hz and additional ones at higher frequencies,
with the second pole being at 1 MHz. The DC gain of the op-amp (called the open-
loop DC gain) is 2×105. At 5 Hz the gain is reduced by 3 dB. It attenuates at a rate of
20 dB per decade of frequency, such that at 1 MHz (the location of the second pole)
the gain is one. The op-amp is not used at high frequencies because its gain becomes
very low. Therefore, the ﬁrst-order pole dominates the operation of the op-amp and it
sufﬁces in the analysis and design of the circuit. To verify this, we plot and compare
the following frequency responses:
Model 1 (ﬁrst-order model):
H1( f ) = 200,000
1 + j f
5
Model 2 (second-order model):
H2( f ) =
200,000
(1 + j f
5 )(1 + j
f
106 )
Figure 9.11 shows the Bode plots and step responses of both models, superimposed
for comparison. The Bode plots are identical up to 1 MHz. The second pole at 1 MHz
introduces an additional attenuation of 20 dB per decade in the magnitude and a phase
angle which leads to an eventual phase of −180◦at ω = ∞. The step responses are
almost identical.

Signals and Systems
523
10−1
100
101
102
103
104
105
106
107
108
−50
0
50
100
Magnitude (dB)
Angular frequency (rad/s)
(c) Step responses or 741 op-amp: Model 1 (first-order) and Model 2 (second-order).
(a) Magnitude plots of 741 op-amp: Model 1 (first-order,
a pole at 5 Hz) and Model 2 (2nd-order,
two poles at 5 Hz and 1 MHz).
(b) Phase plots of 741 op-amp: Model 1 (first-order)
and Model 2 (second-order).
Model 1
Model 2
100
102
104
106
108
−180
−160
−140
−120
−100
−80
−60
−40
−20
0
Angular frequency (rad/s)
Angle (deg)
Model 1
Model 2
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
× 105
Time (s)
Amplitude
Model 1
Model 2
FIGURE 9.11 (Example 9.25). Bode plots and step responses of the single-pole model (at 5 Hz, Model 1) and the
two-poles model (at 5 Hz and 1 MHz, Model 2) of a 741 op-amp, superimposed for comparison. Adding the second pole
(at 1 MHz) doesn’t inﬂuence the system’s performance up to 1 MHz as seen from the Bode plots. Beyond 1 MHz, the
pole at 1 MHz introduces an additional attenuation of 20 dB per decade in the magnitude (a), and adds to the negative
phase angle leading to an eventual phase of −180◦at ω = ∞(b). The step responses are almost identical (c).
Pair of Complex Conjugate Dominant Poles
In a similar way, we derive the second-order model of a system with a complex conjugate
pair of dominant poles. Consider a stable physical system containing M zeros and N +2
poles, including a pair of poles at −σ ± jωd in the LHP. The system function is
H(s) = H0
(s −z1)(s −z2) · · · (s −zk) · · · (s −zM)
(s −p1)(s −p2) · · · (s −pℓ) · · · (s −pN) ×
1
s2 + 2σs + ω2
0
= HN(s) ×
1
s2 + 2σs + ω2
0
where ω2
0 = σ 2 + ω2
d

524
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
The gain factor HN(s) is the contribution from all poles and zeros other than the pair at
−σ ± jωd. Now, let the operating frequency s be near the poles −σ ± jωd (and away
from all other poles and zeros). Then HN(s) ≈HN may be considered almost a constant
factor and H(s) be simpliﬁed to
H(s) ≈
HN
s2 + 2σs + ω2
0
The new gain factor HN embodies the total effect of all other poles and zeros on H(s).
Those poles and zeros being away from the complex operating frequency s will exert
almost a ﬁxed effect, making HN nearly a constant (and, in general, a complex number).
Example
9.26
Modeling a third-order system by its dominant
pair of poles
Consider the bandpass ﬁlter having a single zero at the origin, two poles at −0.1± j10,
and a third pole at −50. The ﬁlter is described by the system function
H(s) = K
s
(s2 + 0.2s + 100)(s + 50)
a.
Find the constant factor K so that the maximum value of |H(ω)| is 5.
b.
Let K = 10
√
26. Create its pole-zero plot in the s-plane. Plot its step and
frequency responses. Determine the maximum gain, the frequency at which it
occurs, and the 3-dB bandwidth. Construct a second-order model ˆH(s) of the
ﬁlter made of its dominant pair of poles (and the zero at the origin), with a
maximum gain equal to that of the ﬁlter. Plot the step and frequency responses
of the model. Determine the frequency at which the gain is maximum, and the
3-dB bandwidth. Visually inspect the reponses of the two systems, then
comment on the validity of the second-order model.
Solution
a.
The system has a pair of poles at p1,2 = −0.1 ± j10, a remote pole at
p3 = −50 and a zero at z1 = 0. From the vectorial composition of H(ω) we
can conclude that |H|Max = 5 will be at ω = 10.
|H|Max = K

jω
(−ω2 + j0.2ω + 100)( jω + 50)

ω=10 =
K
2
√
26
= 5
from which K = 10
√
26.
b.
At frequencies near p1,2 = −0.1 ± j10 the poles dominate the behavior of the
system. The system function of the ﬁlter may be written as
H(s) =
K
s + 50 ×
s
s2 + 0.2s + 100
We will investigate the effect of the remote pole at −50 by using a vectorial
interpretation of H(s). Let C designate the location of s on the jω axis at which

Signals and Systems
525
H(ω) is being evaluated. The four vectors contributing to the system’s
frequency response are
s = BC,
s −p1 = A1C,
s −p2 = A2C,
s −p3 = A3C
The term s + 50 corresponds to the vector A3C from the pole at −50 to point C
on the jω axis. The vectorial representation of the system function on the jω
axis is
H(s) =
K
s + 50 ×
s
s2 + 0.2s + 100
H(ω) =
K
A3C ×
s
s2 + 0.2s + 100

s= jω
Within the neighborhood of ω ≈10 ± 0.1, the vector A3C varies slightly,
causing a negligible change in H(ω). Evaluating A3C at ω = 10 and
substituting in the above equation we obtain the second-order model
ˆH(ω) ≈
10
√
26
j10 + 50 ×
s
s2 + 0.2s + 100

s= jω
≈e−j0.0628π
s
s2 + 0.2s + 100

s= jω
The model’s step and frequency responses are superimposed on the system’s
responses in Figure 9.12.
100
101
102
103
−80
−70
−60
−50
−40
−30
−20
−10
0
10
20
Magnitude (dB)
Angular frequency (rad/s)
100
101
102
103
Angular frequency (rad/s)
(a) Magnitude plots of a third-order dynamical system
and its dominant-pole, second-order model.
(b) Phase plots of the third-order system and
its dominant-pole, second-order model.
Model
System
−200
−150
−100
−50
0
50
100
Angle (deg)
Model
System
FIGURE 9.12 (For Example 9.26). Responses of a third-order system H1(s) = 10
√
26 s/[(s + 50)(s2 + 0.2s + 100)]
and its dominant-poles model H2(s) = e−j11.3◦s/(s2 + 0.2s + 100) superimposed. The system has three poles at p1.2 =
−0.1 ± j10 and p3 = −50. The model with p1.2 = −0.1 ± j10 approximates the frequency response of the system
closely in the neighborhood of ω = 10 rad/s. The third pole at s = −50 produces a break point at ω = 50 and introduces
additional attenuation of 20 dB per decade in the magnitude (a), and adds to the negative phase angle leading to an
eventual phase of −180◦at ω = ∞(b). The step responses are almost identical (c).

526
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−0.1
−0.08
−0.06
−0.04
−0.02
0
0.02
0.04
0.06
0.08
0.1
Time (s)
(c) Step responses of the third-order system and its dominant-pole, second-order model.
Amplitude
Model 
System 
FIGURE 9.12 (Continued)
9.8
Stability and Oscillations
Stability
If bounded inputs to a linear system produce bounded outputs, the system is said to
be BIBO-stable. In other words, the system’s response to every bounded input would
remain bounded. No bounded input can make the output diverge to an inﬁnitely large
value. The zero input response (and the natural response) of a BIBO system diminishes
toward zero with time. A continuous-time LTI system is BIBO-stable if its poles (natural
frequencies) are in the left half of the s-plane. A related property is that the unit-impulse
response of a BIBO system is absolutely integrable.
 ∞
−∞
|h(t)|dt < M, where M is any large number
In the frequency domain, a pair of complex conjugate poles in the LHP causes the system
to be underdamped (oscillatory). Poles at an angle close to the jω axis make the system
more underdamped (smaller damping ratio) and more oscillatory. But until the poles
move out of the LHP the system remains stable. Poles on the jω axis produce sustained
oscillations in the absence of an input to the circuit (but initiated by noise), turning the
system into an oscillator. Poles in the RHP make the system unstable. See project 2 on
active bandpass ﬁlter at the end of this chapter.
Oscillators
A pair of complex conjugate poles at −σ ± jωd contributes the term Ae−σt cos(ωdt +θ)
to the natural response of the system. With the poles in the LHP, the above term decays
with the time constant 1/σ. Move the poles toward the imaginary axis (e.g., by feedback)
and oscillations last longer. The closer the poles get to the jω axis, the longer it takes
for the oscillations to die out. Place the poles on the jω axis and oscillations sustain
themselves. Example 9.27 illustrates the above concept.

Signals and Systems
527
Example
9.27
a.
In the circuit of Figure 9.13(a) (called the Wien-bridge or RC oscillator)
assume an ideal op-amp and ﬁnd V2/V1. Short the input and ﬁnd conditions for
sustained oscillation [i.e., v2(t) ̸= 0 when v1(t) = 0].
b.
Redraw the circuit as Figure 9.13(b) with the noninverting op-amp replaced by
its equivalent ideal ampliﬁer with gain K = 1 + R2/R1. Find conditions for
sustained oscillations in v2(t) (with v1(t) = 0) and ﬁnd its frequency.
R
R
B
A
V2
R2
R1
A
C
R
C
+
–
R
B
C
C
A
V1
Vd
(b)
(a)
V2
KVd
+
–
+
–
+
–
+
–
V1
+
–
FIGURE 9.13 Wien-bridge (RC) oscillator using an op-amp (a) and its equivalent circuit model (b).
Solution
a.
Let the impedances of the parallel RC and the series RC be
Z1 =
R
1 + RCs and Z2 = 1 + RCs
Cs
,
respectively. To obtain V2/V1 in Figure 9.13(a), we ﬁnd VA by dividing V2
between Z1 and Z2 and equating that to the division of V2 between R1 and R2.
Divide V2 between R1 and R2:
VA =
R1
R1 + R2
V2 = βV2, where β =
R1
R1 + R2
Divide V2 between Z1 and Z2:
VA =
Z1
Z1 + Z2V2 +
Z2
Z1 + Z2V1
Equate the above expressions for VA:
βV2 =
Z1
Z1 + Z2V2 +
Z2
Z1 + Z2V1
Resulting voltage transfer function:
V2
V1
=
(1 + RCs)2
β R2C2s2 + (3β −1)RCs + β
V2
V1
=
1
β

1 +
s
ω0
2
 s
ω0
2 + 1
Q
 s
ω0

+ 1
,
ω0 =
1
RC and Q =
β
3β−1

528
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
The circuit is a second-order system with an undamped natural frequency
ω0 = 1/RC and a quality factor Q = β/(3β −1). Note that the gain of the
noninverting op-amp is 1/β. As β →1/3, the quality factor becomes larger
and the poles move toward the jω axis. At β = 1/3 the poles become purely
imaginary at s = ± jω0 on the jω axis. The system oscillates at ω0 in the
absence of an input.
b.
In the circuit of Figure 9.13(b) set V1 = 0 and use voltage division to ﬁnd
VA =
Z1
Z1 + Z2
V2
But
VA = V2
K
Therefore,
V2[Z2 + Z1(1 −K)] = 0
Substitute for Z1 and Z2:
V2
R2C2s2 + RCS(3 −k) + 1
(1 + RCs)Cs
= 0
With K = 3 the numerator of the coefﬁcient of V2 in the above equation
becomes zero at s = j/RC, allowing oscillations with a frequency ω = 1/RC
to be established in v2(t) and sustained despite zero input.
9.9
Analog Filters
What Is a Filter?
Linear dynamical systems are, in general, frequency selective. Their response to a sinu-
soidal excitation is a sinusoid with the same frequency. The amplitude and phase of the
response depend on the frequency of excitation. This is in agreement with our experience
from physical linear systems such as electrical, mechanical, thermal, or other systems
with inertial or energy storage elements. The impedances of the elements of such systems
vary with frequency and the system may ﬁlter some frequencies with various degrees of
attenuation or ampliﬁcation. From this point of view, every linear system is a ﬁlter. How-
ever, the name ﬁlter is applied to circuits, devices, and systems speciﬁcally designed to
exhibit a prescribed frequency selectivity such as passing a certain range of frequencies
(called passband) or blocking another range of frequencies (called stopband).
Other ﬁlter types of interest are those with prescribed frequency characteristics used
as compensators (to improve the frequency characteristics of a system), equalizers (to
provide amplitude and phase equalization), active tone controllers (to boost or dampen
a range of frequencies), integrators or differentiators of signals (for control purposes),
and so on. Some examples of these ﬁlters will be included in this chapter.

Signals and Systems
529
Filter Description
Filters are generally described by their system function H(s) or frequency response
H(ω). The magnitude of the frequency response produces the gain or attenuation in
the amplitude of the signal and its phase produces delay. The gain is represented by
20 log |H(ω)| in dB units. Attenuation is given by −20 log |H(ω)|, also in dB units. A
plot of magnitude and phase versus the frequency is provided by the Bode diagram.
Filter Classification: The Magnitude Factor
From some applications’ point of view ﬁlters are classiﬁed based on their passband or
stopband properties. We recognize ﬁve basic classes of ﬁlters: all-pass, low-pass, high-
pass, bandpass, and bandstop. An all-pass ﬁlter passes all frequencies equally but with
different phase angles. A low-pass ﬁlter passes frequency components below a certain
range. A high-pass ﬁlter passes frequencies above a certain range. A bandpass ﬁlter
passes frequencies within a band, and a bandstop ﬁlter blocks frequencies within a band.
Ideally, this occurs in the passband H( f ) = 1 and in the stopband H( f ) = 0. Such
ﬁlters are called ideal ﬁlters as their frequency responses assume one of two levels with
a sharp vertical transition. They are not physically realizable.
The Phase Factor
In addition to changing the amplitude of a sinusoidal signal, a ﬁlter may also change
its phase (which translates into a delay if the ﬁlter is realizable; see below). Although
the magnitude change is often of primary consideration in ﬁlter applications, the phase
change also needs to be taken into account in order to avoid or assess signal distortion.
For example, a ﬁlter with a ﬂat magnitude within a signal’s bandwidth and a phase
proportional to frequency (to be called linear phase) will not cause distortion in the
signal but will rather delay it. If the phase is not linear, despite the zero magnitude
change, the signal may experience distortion. The phase change may become the primary
consideration and concern if the information carried by the signal is embedded in the
phase. Without speciﬁcation of the phase, the ﬁlters with an ideal magnitude response
are called brick-wall ﬁlters, which is more descriptive.
Linear Phase
The frequency response H(ω) = |H|e jθ with θ = τω, where τ is a constant for all
ω, is called linear phase. It changes the sinusoid A cos(ωt) into A|H| cos(ωt + θ) =
A|H| cos(ωt + τω) = A|H| cos ω(t + τ). The effect is a time-shift τ, which is in-
dependent of the frequency. In that case, all frequency components of the signal are
shifted by the same amount. If the ﬁlter is realizable, the time shifts produced by a
linear phase ﬁlter becomes a constant delay for all frequencies. In addition, if the mag-
nitude is constant, the signal will be delayed without any change. In more general cases,
where the delay created by the ﬁlter is frequency dependent, we express the phenomen
through group delay and phase delay. That subject is introduced in section 9.26 of this
chapter.

530
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Distortion
A signal passing through a system generally changes its shape. The change may be
caused by the nonlinearity of the ﬁlter, in which case additional frequency compo-
nents will appear at the output. This is called nonlinear distortion. In the case of an
LTI system, no additional frequency components may appear at the output. But, the
change in the magnitude and/or phase of frequency components of the signal may cause
distortion in the signal. This is called linear distortion. When the magnitude of the
frequency response is not constant over the signal’s bandwidth, various frequency com-
ponents will experience different amplitude gains, leading to magnitude distortion. Phase
distortion occurs when the phase of the frequency response is not proportional to the
frequency.
Realization and Synthesis
A ﬁlter whose unit-impulse response is zero for t < 0 is called realizable. An example
is a practical ﬁlter made of physical elements. The time-domain condition given above
translates into the frequency-domain condition for realizability by the Paley-Wiener
theorem, which is brieﬂy discussed in section 8.21 of Chapter 8. Based on that theorem,
the ideal ﬁlters are not realizable. But we can approximate the frequency response of
an ideal ﬁlter with that of a practical ﬁlter with any desired level of tolerance and
accuracy. Moreover, in practice we want the ﬁlter to be stable and buildable from lumped
physical elements. These conditions require that we approximate the frequency response
of the ideal ﬁlter by that of a system function, which is a ratio of two polynomials with
real coefﬁcients and poles in the LHP. Filter synthesis will not be addressed in this
textbook.
Practical Filters
The system function of a practical ﬁlter, which is made of lumped linear elements, is a
rational function (a ratio of two polynomials). The degree of the denominator polynomial
is called the order of the ﬁlter. Because of the practical importance of ﬁrst- and second-
order ﬁlters and their widespread applications, we discuss these two classes of ﬁlters in
detail and present examples of circuits to realize them. It is noted that ﬁrst- and second-
order ﬁlters are special cases of ﬁrst- and second-order LTI systems. The properties and
characteristics of these systems (such as impulse and step responses, natural frequencies,
damping ratio, quality factor, overdamping, underdamping, and critical damping) apply
to these ﬁlters as well and will be addressed.8
8For more information on active ﬁlter implementation see Sergio Franco, “Design with Operational
Ampliﬁers and Analog Integrated Circuits,” McGraw-Hill Series in Electrical Engineering, McGraw-Hill,
Inc. 2001.

Signals and Systems
531
9.10
First-Order Low-Pass Filters
The system function and frequency response of a ﬁrst-order, low-pass ﬁlter are
H(s) =
1
1 + τs =
1
1 +
s
ω0
H(ω) =
1
1 + jτω =
1
1 + j ω
ω0
The ﬁlter has a pole at s = −ω0. Table 9.4 gives the magnitude and phase of the frequency
response for ﬁve values of ω/ω0. The half-power frequency (also called 3-dB attenuation
frequency, corner frequency, break frequency, cutoff frequency, or break point) is equal to
the magnitude of the pole, ωo. The Bode diagram plots 20 log |H(ω)| on the vertical axis
in uniform scale of dB versus log ω on the horizontal axis. The low-frequency asymptote
of the plot is a horizontal line at 0 dB. The high-frequency asymptote is a line with a
slope of −20 dB per decade, corresponding to −6 dB per octave. These two asymptotes
intersect at ω0. At one octave below ω0 (i.e., at ω0/2), the gain is −1 dB, which is one dB
below the value of the asymptote. At one octave above ω0 (i.e., at 2ω0), the gain is −7
dB, which is one dB below the value of the asymptote. In summary, the actual gain at half
or twice the cutoff frequency deviates from the value of the asymptote at that frequency
by 1 dB. (For the low-pass ﬁlter it is below the asymptote and for the high-pass ﬁlter it
is above it.) The phase angle varies from 0◦at f = 0 to −90◦at f = ∞. The phase
at ω0 is −45◦. These numbers provide enough data to sketch the Bode plot with good
approximation.
TABLE 9.4 Measurements of the Magnitude
and Phase of the Frequency Response of a First-
Order Low-Pass Filter
ω
ω0
|H(ω)|
20 log |H(ω)| in dB
θ◦
0
1
0
0
1
2
0.89
−1
−26.6
1
√
2
2
−3
−45
2
0.45
−7
−63.4
∞
0
−∞
−90
Example
9.28
First-order low-pass ﬁlters may be constructed from a series RC circuit. RC ﬁlters are
common in low-pass ﬁltering. Here we discuss an example in detail. In the circuit of
Figure 9.14(a) input voltage v1(t) is connected to a series combination of an 800-
resistor and a 1-µF capacitor. The capacitor voltage v2(t) is connected to a voltage

532
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
C
R
+
–
(a) Circuit
v1
+
–
v2
Z
+
–
1200
1000
800
Amplitude
600
400
200
0
0
0.5
1
1.5
2
2.5
Time (s)
(b) Unit-impulse response
3
3.5
4
4.5
5
× 10–3
1
0.8
0.6
Amplitude
0.4
0.2
0
0
0.5
1
1.5
2
2.5
Time (s)
(c) Unit-step response
3
3.5
4
4.5
5
× 10–3
0
–5
Magnitude (dB)
–35
–30
–25
–20
–15
–10
101
102
103
104
Frequency (rad/s)
(d) Magnitude response
0
Angle (deg)
–90
–80
–70
–60
–50
–40
–30
–20
–10
101
102
103
104
Frequency (rad/s)
(e) Phase response
FIGURE 9.14 A ﬁrst-order low-pass RC ﬁlter with a buffer. (a) The circuit, (b) unit-impulse response, (c) unit-step
response, (d) magnitude plot of Bode diagram, and (e) phase plot of Bode diagram (dB and degrees vs. log ω, respectively).
follower (the noninverting input of an op-amp with the output of the op-amp short-
circuited to its inverting input). The ﬁlter’s output is picked up at the op-amp’s output.
Specify the ﬁltering operation on v1(t). Find the system function H(s) = V 2/V 1,
its poles and zeros, its responses to unit-impulse and unit-step inputs. its frequency
response and the cutoff frequency f0 in terms of R and C. Plot its Bode diagram and
ﬁnd its attenuation in dB at 10, 100, 200, 400, and 4,000 Hz.

Signals and Systems
533
Solution
Assuming that the op-amp is ideal, it functions as a voltage follower, preventing
the impedance Z from loading the RC circuit. The ideal op-amp, therefore, has no
effect on the frequency response of the RC circuit, and in this analysis we need not
consider it. At low frequencies the capacitor has a high impedance. It functions as
an open circuit. The current is small and the capacitor voltage is nearly the same as
the input voltage. At high frequencies the capacitor behaves as a short circuit and its
voltage is very small. The circuit is, therefore, a low-pass ﬁlter. The system function
H(s) = V 2/V 1 is found by dividing the input voltage between the impedances of
the capacitor and the resistor
H(s) =
1
Cs
R +
1
Cs
=
1
1 + τs , where τ = RC = 0.8 msec
The ﬁlter has a pole at
s = −1
τ = −106
800 = −1,250 rad/s
and no zero of ﬁnite value. The input-output differential equation and responses to
unit-impulse and unit-step inputs are given below.
Differential equation
dv2
dt +
1
RC v2 =
1
RC v1
The unit-impulse response
h(t) =
1
RC e−t/τu(t)
See Figure 9.14(b).
The unit-step response
g(t) = (1 −e−t/τ)u(t)
See Figure 9.14(c).
The frequency response is
H(ω) =
1
1 + j ω
ω0
,
ω0 = 1
τ = 1, 250 rad/s
The frequency response may also be written as
H( f ) =
1
1 + j f
f0
,
f0 = ω0
2π ≈199 Hz
The Bode diagram is given in Figure 9.14(d) and (e). The half-power frequency with
3-dB attenuation is at f0 = ω0/2π = 199 Hz. The DC attenuation is 0 dB. At 10 Hz,
which is far from the half-power frequency, the attenuation is still nearly zero. At 100 Hz,
which is half of the half-power frequency, the attenuation is 1 dB. At 400 Hz, which is
twice the half-power frequency, the value of the asymptote is 6 dB (remember that the
slope of the asymptote is −6 dB per octave) and the ﬁlter’s attenuation is 1 + 6 = 7 dB.
At 4,000 Hz, the attenuation is almost the same as the value of the asymptote, which is
6 + 20 = 26 dB.

534
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Hardware Implementation
Analog ﬁlters may be implemented by passive or active circuits. (Exceptions are cases
that require ampliﬁcation to achieve a certain gain.) In this way, ﬁlters are classiﬁed as
passive or active. Passive ﬁlters require no power source, are more robust and last longer,
but are vulnerable to loading effects and may require inductors which may become
bulky. Active ﬁlters can do without inductors, provide a better input impedance, and
separate the load from the ﬁlter by employing an op-amp. However, they require a power
source and are less robust. Examples of both types of implementations will be presented.
The ﬁrst-order low-pass system function of H(s) = 1/(1 + τs) may be realized by the
passive circuits of Figure 9.15(b) and (c), or by the active circuit of Figure 9.15(d).
v1
(d) Active RC
(c) Passive LR
(b) Passive RC
ω
ω0 = 
(a) Magnitude plot
1
τ
C
0 dB
20 log |H|
v2
v2
R
R
C
R
L
+
–
v1
+
–
v2
+
–
v1
+
–
R
+
–
FIGURE 9.15 First-order low-pass ﬁlters.
9.11
Integrators
The system function of an integrator is 1/s and its magnitude Bode plot looks like that in
Figure 9.16(a). Integration may be done by an RC (or RL) circuit and an op-amp. Here
are two implementations.
A Perfect RC Integrator
A capacitor accumulates electric charge and develops a voltage proportional to it. The
charge on a capacitor is proportional to the integral of the current that has passed
through it.
v(t) = 1
C
 t
−∞
i(θ)dθ = v(0+) + 1
C
 t
0+ i(θ)dθ

Signals and Systems
535
The capacitor may, therefore, function as an integrator of the input voltage if that voltage
is proportionally converted to a current and passed through the capacitor.
The RC circuit of Figure 9.15(b) is a perfect integrator of the input current but not of
the input voltage. The current in the circuit is proportional to the resistor voltage, which
is the difference between the input and output voltages. Therefore, when converting the
input voltage to the current, part of the input is withheld by the capacitor and the current
in the circuit is not proportional to the input voltage. To avoid this effect, we employ an
op-amp, which linearly converts the voltage signal to a current signal and sends it through
the capacitor for integration. The circuit is shown in Figure 9.16(b). The inverting input
of the op-amp is at ground potential and the current in the input resistor is proportional
to the input voltage, that is, i = v1/R. Because the inverting input of the op-amp draws
no current, all of the above current passes through the capacitor and is absorbed by the
op-amp output. The voltage at the op-amp’s output is the same as the capacitor voltage
and equals the integral of its current:
v2(t) = −1
C
 t
−∞
i(θ)dθ = −1
RC
 t
−∞
v1(θ)dθ
The circuit works as a perfect integrator for all frequencies. This behavior may also be de-
duced directly from the system function of the inverting op-amp circuits of Figure 9.16(b)
and (c), or from their frequency responses.
Hb(s) = −ZC
Z R
= −
1
RCs
Hc(s) = −Z R
ZL
= −R
Ls
Hb(ω) =
−1
j RCω = j ω0
ω = ω0
ω
̸ 90◦,
Hc(ω) = −R
j Lω = j ω0
ω = ω0
ω
̸ 90◦,
where ω0 =
1
RC ,
where ω0 = L
R .
v2
v1
(c) LR integrator
ω
ω0
(a) Magnitude plot
(b) RC integrator
0
+
–
+
–
R
L
dB
20 log |H|
–20 dB/decade
v2
v1
R
C
FIGURE 9.16 Integrators.
A Perfect LR Integrator
Similarly, a perfect integrator may be constructed from an RL circuit and an op-amp as
shown in Figure 9.16(c). The current in the inductor of Figure 9.16(c) is proportional to
the integral of the input voltage.
i(t) = 1
L
 t
−∞
v1(t)dt

536
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
If the op-amp is ideal, all of that current passes through the feedback resistor, which
converts it to v2(t).
v2(t) = −Ri(t) = −R
L
 t
−∞
v1(t)dt
9.12
First-Order High-Pass Filters
High-pass ﬁlters may be analyzed by an approach similar to that for low-pass ﬁlters. The
transfer function of a ﬁrst-order high-pass ﬁlter is
H(s) =
τs
1 + τs
The Bode magnitude plot is shown in Figure 9.17(a). The 3-dB break frequency is
ω0 = 1/τ. Attenuation at ω0/2 and 2ω0 is 1 dB above the attenuation value of the
asymptote. Examples of passive RL and CR ﬁrst-order high-pass ﬁlters are given in
Figure 9.17(b) and (c). The active high-pass ﬁlter is given in Figure 9.17(d).
v2
v1
v2
(d) Active high-pass filter
(b) and (c) Passive high-pass filters
ω
ω0 = 
(a) Magnitude plot
1
τ
R
R
L
R
C
+
–
v1
+
–
v2
+
–
v1
+
–
0 dB
20 dB/decade
20 log |H|
R
C
+
–
FIGURE 9.17 First-order high-pass ﬁlter.
Example
9.29
The high-pass ﬁlter transfer function H(s) = s/(1,000 + s) is realized by the circuit
of Figure 9.17(c) with C = 1 µF and R = 1 k. Let v1(t) = cos(2π f t). Find v2(t)
for a) f = 1 Hz, b) f = 10 kHz.
a.
f = 1 Hz, H( f ) = 0.00628̸ 89.6◦
v2(t) = −0.00628 cos(2π f t + 89.6◦) ≈0.00628 sin(2π f t) =
−1
1,000
dv1
dt
b.
f = 10 kHz, H( f ) = 0.99987̸ 0.9◦
v2(t) = −0.99987 cos(2π f t + 0.9◦) ≈−cos(2π f t) = −v1(t)

Signals and Systems
537
The normalized Bode plot of the high-pass ﬁlter (i.e., magnitude and phase plotted
versus ω/ω0) is given in Figure 9.3. Scaling up the frequency axis in that plot by factor
ω0 = 1,000 will provide the Bode diagram for the high-pass ﬁlter of Example 9.29.
Within the frequency neighborhood of 1 Hz, the ﬁlter of Example 9.29 functions
as a differentiator with 60-dB attenuation. Within the 10-kHz neighborhood it is an
all-pass ﬁlter with unity gain and zero phase shift. At 10 kHz, it passes the signal
without change in magnitude or phase. (The above conclusions may also be reached
by inspecting the RC circuit.) At 1 Hz, almost all of the input voltage goes to the
capacitor that dominates the impedance of the circuit. The capacitor current becomes
proportional to the derivative of the input voltage. Consequently, the output voltage
across the resistor becomes proportional to the derivative of the input voltage. At low
frequencies, therefore, the circuit behaves as a differentiator. At high frequencies the
capacitor behaves like a short-circuited path and all of the input voltage is transferred
to the output with no change. The circuit works like an all-pass ﬁlter.
9.13
Differentiators
A high-pass ﬁlter exhibits the differentiation property at low frequencies. However,
an ideal differentiator needs to operate perfectly over the whole frequency range. The
system function of an ideal differentiator is, therefore, H(s) = s. The magnitude fre-
quency response of an ideal differentiator is shown in Figure 9.18(a). The two circuits
in Figure 9.18(b) and (c) perform differentiation. Their input-output relationships are
CR differentiator:
v2(t) = −RC dv1
dt
RL differentiator:
v2(t) = −L
R
dv1
dt
v2
v1
(c) RL differentiator
(b) CR differentiator
+
–
L
R
v2
v1
+
–
R
C
ω
ω0
(a) Magnitude plot
dB
0
20 dB/decade
20 log |H|
FIGURE 9.18 Differentiators.

538
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
9.14
First-Order All-Pass Phase Shifters
The following ﬁlter has a constant gain H0 irrespective of the frequency. Its phase,
however, varies with frequency. It is called a phase shifter.
H(s) = H0
s −ω0
s + ω0
H(ω) = H0
j

ω
ω0

−1
j

ω
ω0

+ 1
The ﬁrst-order phase shifter is a stable system with a pole at −ω0 and a zero at ω0.
Figure 9.19(a) (on the left side) shows pole-zero plots for the case of ω0 = 1, 2, 5,
and 10. The vectorial interpretation of H(ω) shown on the ﬁgure reveals the all-pass
nature of the ﬁlter. Figure 9.19(b) (on the right side) shows phase versus frequency for
the above four cases. In all cases the phase shift is 90◦at ω0. Within the neighborhood
of ω0, a frequency perturbation ω proportionally results in a phase perturbation almost
proportional to −ω/ω0. This translates into a time-shift perturbation of 1/ω0.
10
8
6
Imaginary
4
2
0
–10
–8
–6
–4
–2
0
2
Real
4
6
8
10
w0 = 
1
2
5 10
180
160
140
120
100
80
60
40
20
Angle (deg)
0
10–2
10–1
100
101
102
103
Angular frequency (rad/s)
(a) Pole-zero plots
(b) Phase plots
FIGURE 9.19 Pole-zero and phase plots of ﬁrst-order phase shifter H(s) = (s −ω0)/s + ω0) for four pole locations:
ω0 = 1, 2, 5, and 10. Within the neighborhood of ω0 it functions as a delay element of τ = π/(2ω0).
The ﬁrst-order phase shifter may be implemented by a passive circuit as the one in
Figure 9.20(a) (with gain restriction), or by an active circuit as given in Figure 9.20(b).
Example
9.30
a.
Derive the input-output relationships in Figure 9.20(a) and (b) to show that:
Figure 9.20(a):
V2
V1
= 0.51 −RCS
1 + RCS
and Figure 9.20(b):
V2
V1
= 1 −RCs
1 + RCs

Signals and Systems
539
+
–
V2
V1
V2
V1
(b) Active phase shifter
(a) Passive phase shifter
+
–
–
+
R1
R
R
C
R
R
A
C
B
B
A
R1
FIGURE 9.20 Two circuits for the ﬁrst-order phase shifter.
b.
Consider the phase shifter V2/V1 = (1,000 −s)/(1,000 + s). Let
v1(t) = cos 995t + cos 1,000t + cos 1005t. Show that v2(t) ≈v1(t −τ) and
ﬁnd τ.
c.
Repeat for v1(t) = cos t cos 1,000t.
Solution
a.
Figure 9.20(a): VA=V1
2 ,
VB=
RCs
1 + RCs V1,
V2=VA −VB
= 0.51 −RCS
1 + RCS V1
Figure 9.20(b): VA=V1 + V2
2
, VB=
V1
1 + RCs ,
VA=VB, V2 = 1 −RCs
1 + RCs V1
b.
For the input v1(t) = cos(ωt), the output is
v2(t) = cos(ωt −θ) = cos ω(t −τ), where θ = 2 tan−1 
ω
1,000

and τ = θ/ω.
These are calculated and the results are given below.
Amplitude
1
1
1
ω (in radians/sec)
995
1,000
1,005
θ (in degrees)
90.287◦
90◦
89.714◦
θ (in radians)
1.575
1.570
1.565
τ = θ/ω (in µs)
1,583
1,570
1,558
v2(t) = cos 995(t −0.001583) + cos 1,000(t −0.001570)
+ cos 1005(t −0.001558) ≈v1(t −τ), τ = 1.57 msec
c.
v1(t) = cos t cos 1,000t = cos 999t + cos 1,001t
2
v2(t) = cos 999(t −τ) + cos 1,001(t −τ)
2
= cos(t −τ) cos 1,000(t −τ) = v1(t −τ)

540
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
9.15
Lead and Lag Compensators
Lead and lag compensators are ﬁrst-order ﬁlters with a single pole and zero, chosen
such that a prescribed phase lead and lag is produced in a sinusoidal input. In this way,
when placed in a control loop, they reshape an overall system function to meet desired
characteristics. Electrical lead and lag networks can be made of passive RLC elements, or
employ operational ampliﬁers. In this section we briefy describe their system functions
and frequency responses.
Lead Network
A lead network made of passive electrical elements is shown in Figure 9.21, along with
its pole-zero and Bode plots.
0
–5
–10
Phase (deg)
Magnitude (dB)
–15
–20
V2
R2
(a) Circuit
(c) Bode plot
+
V1
+
–
–
R1
C
50
40
30
20
10
101
102
Frequency (rad/s)
103
104
(b) Pole-zero plot
400
200
Imaginary part
–200
–400
0
–1000
–600
–200
0
Real part
FIGURE 9.21 Lead network, H(s) = α s + ω1
αs + ω1
, α < 1. This ﬁgure is for ω1 = 100 and α = 1/11. See Example 9.31.
The network’s input and output voltages are related by the following differential
equation:
1
α v2 + τ1
dv2
dt = v1 + τ1
dv1
dt
where
τ1 = R1C
and α =
R2
R1 + R2
From the above differential equation, as well as the system function, frequency response,
and the Bode plots, the network’s response to a sinusoidal input leads the input by a
positive phase angle at all frequencies, hence the lead network. The system function and

Signals and Systems
541
frequency response are
H(s) = V2
V1
= α 1 + τ1s
1 + ατ1s = α s + ω1
αs + ω1
, where ω1 = 1
τ1
H(ω) = α 1 + j(ω/ω1)
1 + jα(ω/ω1)
The DC gain is α = R2/(R1 + R2) and the high-frequency gain is unity (0 dB). Note
that α < 1 and, when expressed in dB, it is a negative number. We may also employ the
low-frequency attenuation factor 1/α and express it in dB by A = −20 log α (dB). The
system function has a zero at z = −ω1 and a pole at p = −ω1/α. The pole of the system
is located to the left of its zero, both being on the negative real axis in the s-plane (see
Figure 9.21b). The magnitude is normally expressed in dB.
20 log |H(ω)| = 20 log α + 20 log

1 + (ω/ω1)2 −20 log

1 + α2(ω/ω1)2
(dB)
One may sketch the magnitude of the frequency response in dB and its phase in degrees
on semilog paper [i.e., 20 log |H(ω)| and ̸ H(ω)| vs. log ω] by the following qualitative
argument. The low-frequency asymptote of the magnitude plot is the horizontal line at
20 log α dB. The high-frequency asymptote is the horizontal line at 0 dB. The magnitude
plot is a monotonically increasing curve. Traversing from low frequencies toward high
frequencies it ﬁrst encounters ω1 (the zero). The zero pushes the magnitude plot up
with a slope of 20 dB per decade. As the frequency increases it encounters ω1/α (the
pole). The pole pulls the magnitude plot down with a slope of −20 dB per decade
and, therefore, starts neutralizing the upward effect of the zero. The magnitude plot is
eventually stablized at the 0 dB level. The zero and the pole are the break frequencies
of the magnitude plot. If α << 1, the pole and the zero are far enough from each other
and constitute frequencies of 3-dB deviation from the asymptotes. At ω1 (the zero) the
magnitude is 3 dB above the low-frequency asymptote and the phase is 45◦. At ω1/α (the
pole) the magnitude is 3 dB below 0 dB (the high-frequency asymptote) and the phase is
90◦−45◦= 45◦. The maximum phase lead in the output occurs at ωm = ω1/√α, which
is the geometric mean of the two break frequencies. These are summarized in Table 9.5
in which A = −20 log α.
TABLE 9.5 Magnitude and Phase of the Frequency Responses of a Lead Network with a Large Pole-Zero
Separation
Frequency
ω << ω1
ω1
ω1/√α
ω1/α
ω >> ω1/α
Response
(low frequencies)
(the zero)
(geometric mean)
(the pole)
(high frequencies)
|H(ω)|
≈−A dB
≈−A + 3 dB
−A
2 dB
≈−3 dB
≈0 dB
̸ H(ω)
≈0
≈45◦
90◦−2 tan−1 √α
≈45◦
≈0
The phase of H(ω) varies from 0 (at low frequencies, ω = 0) to a maximum lead
of 90◦−2 tan−1 √α at ωm = ω1/√α and returns back to zero at high frequencies. For
derivation of the maximum phase see problems 10 and 46.

542
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Example
9.31
Consider the lead network of Figure 9.21(a) with R1 = 10 k, R2 = 1 k, and
C = 1 µF. Let v1 = cos ωt be the input and v2 = V2 cos(ωt + θ) be the output.
a.
Find V2 and θ for ω at 1, 100, 331.6, 1,100, and 105, all in rad/s.
b.
Find the system function. Show that the phase lead is maximum at
ωm = 100
√
11 = 331.6 rad/s and ﬁnd its value. Find the DC and
high-frequency gains (in dB), along with the break frequencies.
Solution
a.
Let V1 = 1 and V2 be the complex amplitudes of the input and output voltages,
respectively. Then by voltage division, we have
V2
V1
≡H(s)

s= jω =
R2
R2 + Z(s)

s= jω, where Z(s) =
1
1 + R1Cs
is the impedance of R1 and C in parallel. After substituting for R1, R2, C, and
V1 in the above, we have
|V2| = α ω2 + ω2
1
αω2 + ω2
1
θ = tan−1
	 ω
ω0

−tan−1
	αω
ω0

where
α =
R2
R1 + R2
= 1
11
and
ω1 =
1
R1C = 100 rad/s
The magnitude and phase of the sinusoidal response at the given frequencies
are shown in the table below.
ω (rad/s)
1
100
331.6
1,100
105
V2 (volts)
0.091
0.128
0.3015
0.71
1
θ (degrees)
0.5◦
39.8◦
56.4◦
39.8◦
0.5◦
b.
The system function is
H(s) = α s + ω1
αs + ω1
The DC gain is 20 log(1/11) = −48 dB. The maximum phase occurs at
ω = ω1/√α = 100/
√
11 = 331.66 rad/s. The value of the maximum lead is
90◦−2 tan−1 √α = 90◦−2 tan−1 √(1/11) = 56.44◦. The frequency response
is plotted in the form of a Bode plot. The network has a zero at −100 and a pole
at −1,100. See Figure 9.21(b) and (c). A vectorial interpretation of the system
function conﬁrms the above speciﬁcations.

Signals and Systems
543
Lag Network
A lag network is shown in Figure 9.22.
0
–5
–10
Magnitude (dB)
Phase (deg)
–15
–20
v2
R2
(a) Circuit
(c) Bode plot
+
v1
+
–
–
C
–10
–20
–30
–40
–50
101
102
Frequency (rad/s)
103
104
(b) Pole-zero plot
400
200
Imaginary part
–200
–400
–1000
–600
–200
0
0
Real part
R1
FIGURE 9.22 Lag network, H(s) = αs + ω2
s + ω2
, α < 1. This ﬁgure is for ω1 = 90.9 and α = 1/11. See Example 9.32.
In many respects characteristics of the lag network are mirror images of those of
the lead network. The input-output differential equation is
v2 + τ2
dv2
dt = v1 + ατ2
dv1
dt
where
τ2 = (R1 + R2)C
and α =
R2
R1 + R2
The system function and frequency response are
H(s) = V2
V1
= 1 + ατ2s
1 + τ2s = αs + ω2
s + ω2
, where ω2 = 1
τ2
H(ω) = 1 + jα(ω/ω2)
1 + j(ω/ω2)
The DC gain is unity (0 dB) and the high-frequency gain is α = R2/(R1 + R2). The
system has a pole at p = −ω2 and a zero at z = −ω2/α to the left of the pole, both
being on the negative real axis in the s-plane, [see Figure 9.22(b)]. The magnitude plot
of the lag network displays a horizontal ﬂip of that of the lead network, and the phase is
a vertical ﬂip of that of the lead the network. The magnitude and phase of the frequency
responses of a lag network with a large zero-pole separation are given below for several
frequencies of interest. Here, as for the lead network A = −20 log α.

544
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Frequency
ω << ω2
ω2
ω2/√α
ω2/α
ω >> ω2
Response
(low frequencies)
(the pole)
(geometric mean)
(the zero)
(high frequencies)
|H(ω)|
≈0 dB
≈−3 dB
−A
2 dB
≈−A + 3 dB
≈−A dB
̸ H(ω)
≈0
≈−45◦
2 tan−1 √α −90◦
≈−45◦
≈0
The phase of H(ω) varies from 0 (at low frequencies, ω = 0) to a minimum (i.e., a
maximum phase lag) of (2 tan−1 √α −90◦) at ωm = ω2/√α and returns back to zero at
high frequencies.
Example
9.32
Consider the lag network of Figure 9.22(a) with R1 = 10 k, R2 = 1 k, and
C = 1 µF. Let v1 = cos ωt be the input and v2 = V2 cos(ωt −θ) be the output.
Find V2 and θ for ω = 1, 90.9, 301.5, 1,000, and 105, all in rad/s. Plot the frequency
response in the form of Bode plot.
Solution
In this case we ﬁnd α = 1/11 and ω2 = 90.9 rad/s. The magnitude and phase of the
response are given in the table below.
ω rad/s
1
90.9
301.5
1,000
105
V2 volts
1
0.71
0.3015
0.128
0.091
θ degrees
0.5◦
39.8◦
56.4◦
39.8◦
0.5◦
The frequency response is plotted in the form of a Bode plot in Figure 9.22(c).
Parallels with the Bode diagram of Figure 9.21(c) are observed.
9.16
Summary of First-Order Filters
The transfer function H(s) of a ﬁrst-order stable ﬁlter has a single pole with a negative
real value. Table 9.6 summarizes characteristics of seven ﬁrst-order ﬁlter types: low-pass,
integrator, high-pass, differentiator, all-pass, lead, and lag ﬁlters.
9.17
Second-Order Low-Pass Filters
A second-order low-pass ﬁlter has two poles and no zeros at ﬁnite frequencies. Its system
function and frequency response are
H(s) =
b
s2 + 2as + b =
1
( s
ω0 )2 + 1
Q
s
ω0 + 1, where Q =
√
b
2a
and ω0 =
√
b
H(ω) =
b
b −ω2 + j2aω =
1
1 −( ω
ω0 )2 +
j
Q
ω
ω0

Signals and Systems
545
TABLE 9.6 Summary of First-Order Filters
Type
H(s)
H(ω)
Break Frequency
Pole-Zero
Asymptotic Bode Plot
a.
Low-pass
1
1 + τs
1
1 + j ω
ω0
ω0 = 1
τ
–w0
w
w0
0
dB
b.
Integrator
1
τs
−j ω0
ω
ω0 = 1
τ
w
w0
0
dB
c.
High-pass
τs
1 + τs
j ω
ω0
1 + j ω
ω0
ω0 = 1
τ
–w0
w
w0
0
dB
d.
Differentiator
τs
j ω
ω0
ω0 = 1
τ
w
w0
0
dB
e.
All-pass
1 −τs
1 + τs
1 −j ω
ω0
1 + j ω
ω0
none
w0
–w0
w
0
dB
f.
Lead
1 + bτs
1 + τs
1 + j ω
ω1
1 + j ω
ω2
ω1 = 1
bτ , ω2 = 1
τ
–w2
–w1
w
w1
w2
0
dB
g.
Lag
1 + τs
1 + bτs
1 + j ω
ω1
1 + j ω
ω2
ω1 = 1
τ , ω2 = 1
bτ
–w1
–w2
w
w2
w1
0
dB

546
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
The basic features of the above system function were brieﬂy discussed previously.9 The
second-order systems described in section 9.6 are low-pass (except when the quality
factor is high). Here we consider the frequency response behavior of such systems. As
before, based on the quality factor Q, we recognize three cases.
Q < 0.5
Theﬁlterhastwodistinctpolesonthenegativerealaxisats1,2 = −ω1,2 = −a±
√
a2 −b.
See Figure 9.23(a) (left). Note that ω1ω2 = b and ω1 + ω2 = 2a. This is an overdamped
second-order system. Its frequency response may be written as
H(ω) =
1
1 + j

ω
ω1
 ×
1
1 + j

ω
ω2

The ﬁlter is equivalent to the cascade of two ﬁrst-order low-pass ﬁlters with 3-dB fre-
quencies at ω1 and ω2, discussed previously. The magnitude Bode plot is shown on
Figure 9.23(a) (right). The plot has three asymptotic lines, with slopes of 0, −20, and
−40 dB/decade, for low, intermediate, and high frequencies, respectively.
Q = 0.5
The ﬁlter has a pole of order 2 on the negative real axis at s = −ω0, where ω0 = a =
√
b.
See Figure 9.23(b) (left). This is a critically damped system. The frequency response
may be written as
H(ω) =
1
1 −

ω
ω0
2
+ j2

ω
ω0
 =
1
1 + j

ω
ω0
 ×
1
1 + j

ω
ω0

The ﬁlter is equivalent to the cascade of two identical ﬁrst-order low-pass ﬁlters with
3-dB frequencies at ω0. The Bode plot is shown on Figure 9.23(b) (right). The low-
frequency asymptote is at 0 dB. The high-frequency asymptote is a line with a slope of
−40 dB per decade. The break frequency is at ω0. Attenuation at ω0 is 6 dB.
Q > 0.5
The ﬁlter has two complex conjugate poles with negative real parts, s1,2 = −σ ± jωd,
where σ = a and ωd =
√
b −a2. The frequency response may be written as
H(ω) =
1
1 −

ω
ω0
2
+ j

2a
ω0
 
ω
ω0

This is an underdamped system. Its poles are shown in Figure 9.23(c) (left) and its Bode
plot is on Figure 9.23(c) (right).
9For the representation of a second-order system by its natural frequency, damping ratio, quality factor, and
pole locations, along with the relationship of these entities to each other, see section 9.6 and Figure 9.4 in this
chapter.

Signals and Systems
547
20
10
–10
0
–20
Magnitude (dB)
–40
–30
101
10–2
Angular frequency (rad/s)
(b)
(a)
(c)
10–1
100
1
0.4
0
Imaginary
–1
–0.4
–5
Real
0
–1
–3
20
10
–10
0
–20
Magnitude (dB)
–40
–30
101
10–2
Angular frequency (rad/s)
10–1
100
20
10
–10
0
–20
Magnitude (dB)
–40
–30
1
0.4
0
Imaginary
–1
–0.4
–1
Real
0
–0.2
–0.6
101
10–2
Angular frequency (rad/s)
10–1
100
–1
Real
Magnitude plots
Pole-zero plots
0
–0.2
–0.6
1
0.4
0
Imaginary
–1
–0.4
FIGURE 9.23 Summary of second-order low-pass ﬁlter H(s) = 1/(s2 + 1
Q s + 1): (a) Q = 0.2, overdamped with two
distinct negative real poles at −4.7913 and −0.2087. (b) Q = 0.5, critically damped with a repeated negative real pole
at −1. (c) Q = 5, underdamped with a pair of complex conjugate poles at (−0.1 ± j0.995).
The above three situations may be analyzed in a uniﬁed manner using the ﬁlter’s Q
and ω0 model. The gain of the frequency response in dB is
20 log |H(ω)| = −20 log
1 −
	 ω
ω0

2
+ j
Q
ω
ω0

For ω << ω0, the terms ω/ω0 and (ω/ω0)2 may be dropped, and the gain is
20 log |H(ω)| ≈−20 log 1 = 0 dB
The low-frequency asymptote is, therefore, the 0 dB horizontal line.

548
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
For ω >> ω0, the terms ω/ω0 and 1 may be dropped and
20 log |H(ω)| ≈−40 log
	 ω
ω0

The high-frequency asymptote is, therefore, a line with a slope of −40 dB per decade.
At ω0 the gain is
20 log |H(ω0)| = −20 log 1
Q = 20 log Q,
which is equal to the quality factor expressed in dB. For Q =
√
2/2, the gain is
20 log(
√
2/2) = −3 dB. For Q > 1, the gain in dB becomes positive. For high Q
the gain peaks at ω0 and the ﬁlter exhibits a behavior similar to resonance. See Exam-
ple 9.33.
Example
9.33
The circuit of Figure 9.24(a) is called a Sallen-Key low-pass ﬁlter. In this example
we choose m = n = 1, making it an equal-component ﬁlter. The system function is
found by applying basic circuit theory. It is
V2
V1
= 1
β
1
 s
ω0
2 + 1
Q
 s
ω0

+ 1
,
where ω0 =
1
RC , β =
R1
R1 + R2
is the feedback factor, and Q =
β
3β −1.
V2
(a) Circuit
–
+
R2
R1
A
C
B
nC
mR
A
i
R
V1
Frequency (Hz)
(b) Magnitude response for Q = 0.5, 1, 20
Q = 20
Q = 0.5
Q = 1
105
104
103
102
101
–60
–80
0
Magnitude (dB)
20
–20
–40
40
+
–
FIGURE 9.24 An equal-component Sallen-Key low-pass ﬁlter and its magnitude frequency responses. (See Exam-
ple 9.33.)

Signals and Systems
549
Let R = 159  and C = 1 µF. Plot the magnitude response, 20 log |H( f )| ver-
sus log f , for Q = 0.5, 1, and 20. Examine the magnitude response for β =
1, 0.63, 0.5, 0.4, 0.35, 0.339, 0.335 and discuss the performance of the ﬁlter for
the above feedback factors. At what value of β does the circuit become a Butterworth
ﬁlter, that is, poles at
√
2
2 ω0(−1 ± j)?
Solution
With R = 159  and C = 1 µF the natural frequency is 1 kHz. The feedback factor
controls the location of the poles and, consequently, Q. See the results below.
β
1
0.63
0.5
0.4
0.35
0.339
0.335
Q
0.5
0.707
1
2
7
19.94
67
The superimposed magnitude plots are shown in Figure 9.24(b). The DC gain is 1/β.
At 1 kHz the value of the magnitude response is 20 log Q −20 log β = 20 log(Q/β) =
−20 log(3β −1). Note that an increase in the feedback factor causes an increase in Q but
decreases the DC gain. A higher Q produces a larger peak. For example, for β = 0.335
we have Q = 67 and the magnitude plot will read a peak of 46 ≈20 log Q −20 log β =
20 log (Q/β) dB. For a Butterworth ﬁlter Q =
√
2/2, which requires β =
1
3−
√
2 = 0.63.
For β = 1 we have Q = 0.5 and the ﬁlter is a critically damped, second-order system
with an attenuation of −20 log (Q/β) = 6 dB.
9.18
Second-Order High-Pass Filters
The system function and frequency response of a second-order high-pass ﬁlter may be
written as
H(s) =
s2
s2 + 2as + b =

s
ω0
2

s
ω0
2
+ 1
Q

s
ω0

+ 1
, where Q =
√
b
2a
and ω0 =
√
b
H(ω) =
−ω2
b −ω2 + j2aω =
−

ω
ω0
2
1 −

ω
ω0
2
+
j
Q
ω
ω0
The system has a double zero at s = 0 (DC) and two poles in the LHP. It works as the
opposite of the low-pass ﬁlter. The frequency response has a zero magnitude at ω = 0,
which grows to 1 at ω = ∞. The low-frequency magnitude asymptote is a line with a
slope of 40 dB per decade. The high-frequency asymptote is the 0 dB horizontal line.
Between the two limits (especially near ω0) the frequency response is shaped by the
location of the poles. As in any second-order system, we recognize the three cases of the
ﬁlter being overdamped, critically damped, and underdamped. Here again, the frequency
behavior of the ﬁlter may be analyzed in a uniﬁed way in terms of ω0 and Q. Results are
summarized in Table 9.7.

550
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
TABLE 9.7 Magnitude and Phase of the High-Pass Filter H(s) = s2/(s2 + ω0s/Q + ω2
0)
Frequency ω
0
ω << ω0
ω0
ω >> ω0
∞
Magnitude, 20 log |H(ω)| in dB
−∞
≈40 log
 ω
ω0

20 log Q
0
0
Phase, ̸ H(ω) in degrees
0
≈−180
90◦
0
0
Example
9.34
The circuit of Figure 9.25(a) is an equal-component Sallen-Key high-pass ﬁlter. By
applying circuit theory rules its system function is found to be
V2
V1
= 1
β
 s
ω0
2
 s
ω0
2 + 1
Q
 s
ω0

+ 1
,
where
ω0 =
1
RC , β =
R1
R1 + R2
is the feedback factor, and
Q =
β
3β −1.
Plot the magnitude response, 20 log |H( f )| versus log f , for Q = 0.5, 1, and 20.
Examine the magnitude response for β = 1, 0.63, 0.5, 0.4, 0.35, 0.339, 0.335 and
discuss the performance of the ﬁlter for the above feedback factors. At what value of
β does the circuit become a second-order Butterworth ﬁlter?
V2
(a) Circuit
–
+
R2
R1
A
R
R
B
C
A
i
V1
+
–
Frequency (Hz)
(b) Magnitude response for Q = 0.5, 1, 20
Q = 20
Q = 0.5
Q = 1
105
104
103
102
101
–60
–80
0
Magnitude (dB)
20
–20
–40
40
C
FIGURE 9.25 An equal-component Sallen-Key high-pass ﬁlter and its magnitude frequency responses. (See Exam-
ple 9.34.)

Signals and Systems
551
Solution
With R = 159  and C = 1 µF the natural frequency is 1 kHz. The feedback factor
controls the location of the poles and, consequently, Q. The superimposed magnitude
plots are shown in Figure 9.25(b). The high-frequency gain is 1/β. At 1 kHz the
value of the magnitude response is 20 log Q −20 log β = −20 log(3β −1). Note
that an increase in the feedback factor causes an increase in Q but decreases the high
frequencygain.Ahigher Q producesalargerpeak.Forexample,atβ = 0.335wehave
Q = 67 and the magnitude plot will read 46 ≈20 log Q −20 log β = 20 log (Q/β)
dB. For a Butterworth ﬁlter Q =
√
2/2, which requires β =
1
3−
√
2 = 0.63.
9.19
Second-Order Bandpass Filters
The system function and frequency response of the basic second-order bandpass ﬁlter are
H(s) =
2as
s2 + 2as + b =
1
Q

s
ω0


s
ω0
2
+ 1
Q

s
ω0

+ 1
, where Q =
√
b
2a
and ω0 =
√
b
H(ω) =
j2aω
b −ω2 + j2aω =
j
Q

ω
ω0

1 −

ω
ω0
2
+
j
Q

ω
ω0

The ﬁlter has a zero at s = 0 (DC) and two poles at s1,2 = −ω0
2Q

1 ±

1 −4Q2

,
which, depending on the value of Q, are either real or complex. The frequency response
has zero magnitude at ω = 0 and ∞. It attains its peak at ω0, sometimes called the
resonance frequency, where |H(ω0)| = 1. The half-power bandwidth ω is deﬁned as
the frequency range within which |H(ω)/H(ω0)| ≥
√
2/2 (i.e., the gain is within 3 dB
below its maximum, and thus called the 3-dB bandwidth). The lower and upper limits
of the half-power frequency band are
ωh,ℓ= ω0

1 +
1
4Q2 ± 1
2Q

= ω0
2Q

4Q2 + 1 ± 1

ω = ωh −ωℓ= ω0
Q
In the present analysis we observe parallels with the cases of low-pass and high-pass
ﬁlters, and, depending on the value of the quality factor Q (which controls the location
of a ﬁlter’s poles and thus its bandwidth), we recognize the three familiar states of
overdamped (Q < 0.5), critically damped (Q = 0.5), and underdamped (Q > 0.5). The
ﬁlter then becomes wideband (low Q) or narrowband (high Q). The sharpness of the
peak is determined by the quality factor Q. In what follows we will discuss the shape of
the Bode plot for three regions of Q values.

552
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Q < 0.5
The system has two distinct negative real poles at s1,2 = −ω0
Q (1±

1 −4Q2) = −ω1,2.
Note that ω1ω2 = ω2
0 and ω1 + ω2 = 2ω0
Q .
H(ω) = 1
Q
j(ω/ω0)
[1 + j(ω/ω1)][1 + j(ω/ω2)]
The slopes of the asymptotic lines in the magnitude Bode plot are 20, 0, and −20
dB/decade for low, intermediate, and high frequencies, respectively. The ﬁlter is a wide-
band bandpass ﬁlter. It is equivalent to the cascade of a ﬁrst-order high-pass ﬁlter and a
ﬁrst-order low-pass ﬁlter with separate break points.
Q = 0.5
The ﬁlter has a double pole at s = ω0. The frequency response may be written as
H(ω) =
2 j(ω/ω0)
1 −(ω/ω0)2 + j2(ω/ω0) = 2
j(ω/ω0)
1 + j(ω/ω0) ×
1
1 + j(ω/ω0)
The asymptotic slopes of the plot are 20 dB/decade (low frequencies) and −20 dB/decade
(high frequencies). The ﬁlter is bandpass, equivalent to the cascade of a ﬁrst-order high-
pass ﬁlter and a ﬁrst-order low-pass sharing the same break frequency ω0.
Q > 0.5
The ﬁlter has two complex conjugate poles with negative real parts s1,2 = −σ ± ωd,
where σ =
ω0
(2Q) and ωd =
ω0
(2Q)

4Q2 −1. Note that σ 2 + ω2
d = ω2
0. The asymptotic
slopes of the Bode plot are 20 dB/decade (low frequency) and −20 dB/decade (high
frequency).
High Q
For a bandpass system with high Q (e.g., Q ≥10) the high and low 3-dB frequencies
are approximately symmetrical on the upper and lower sides of the center frequency:
ωh,ℓ≈ω0 ± ω0
2Q
A vectorial interpretation of H(ω) is especially illuminating in observing the above
approximation.
Example
9.35
The circuit of Figure 9.26(a) is an inﬁnite gain, multiple feedback bandpass ﬁlter.
In this example we choose equal-value capacitors C1 = C2 = C. Find the system
function H(s) = V2/V1 and write it as a bandpass ﬁlter. Determine its quality factor

Signals and Systems
553
and center frequency as functions of circuit elements, and specify them for R1 =
159 , R2 = 100R1, and C = 0.1 µF. Plot the magnitude Bode plot 20 log |H( f )|
versus log f and discuss the effect of increasing R2.
+
–
V2
(a)
+
–
B
A
V1
Frequency (Hz)
(b)
Q = 20
Q = 0.5
Q = 1
105
104
103
102
101
–60
Magnitude (dB)
50
40
30
20
10
0
–10
–20
–30
–40
–50
R1
R2
C2
C1
FIGURE 9.26 (a) An inﬁnite gain, multiple feedback bandpass ﬁlter (a). (b) Magnitude responese of a bandpass ﬁlter
for Q = 0.5, 1, and 20.
Solution
The op-amp is operating in a noninverting conﬁguration with a gain of V2/VA =
1 + R2/R1 = 1/β. From the above observation and from KCL at nodes A and B we
obtain the following three equations:
KCL at node A:
(0 −VB)Cs + 0−V2
R2
= 0
KCL at node B:
(VB−V1)
R1
+ (VB −0)Cs + (VB −V2)Cs = 0
After eliminating VB between the above two equations we are left with
H(s) = V2
V1
= −
R2Cs
R1R2C2s2 + 2R1Cs + 1
= −G0
1
Q

s
ω0


s
ω0
2
+ 1
Q

s
ω0

+ 1
,
where G0 = 1
2
R2
R1
,
ω0 =
1
√R1R2C and Q = 1
2

R2
R1
.
With R1 = 159 , R2 = 100R1, and C = 0.1 µF the peak frequency is 1 kHz,
G0 = 50, and Q = 5. The magnitude plot of a band pass ﬁlter for Q = 0.5, 1, and
20 is shown in Figure 9.26(b). The quality factor and the peak value of the magnitude
plot both increase with increasing R2. The ﬁlter becomes more selective as shown.

554
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
9.20
Second-Order Notch Filters
The system function and frequency response of a second-order notch ﬁlter may be written
as
H(s) =
s2 + b
s2 + 2as + b =
( s
ω0 )2 + 1
( s
ω0 )2 + 1
Q ( s
ω0 ) + 1, where Q =
√
b
2a
and ω0 =
√
b
H(ω) =
b −ω2
b −ω2 + j2aω =
1 −( ω
ω0 )2
1 −( ω
ω0 )2 +
j
Q
ω
ω0
.
The ﬁlter has two zeros at ± jω0 (notch frequency) and two poles in the LHP. It works
as the opposite of the bandpass ﬁlter. The frequency response has a zero magnitude
at ω0. The low- and high-frequency magnitude asymptotes are 0-dB horizontal lines.
Between the two limits, especially near ω0, the frequency response is shaped by the
location of the poles. As in any second-order system, we recognize the three cases of
the ﬁlter being overdamped, critically damped, and underdamped. The sharpness of the
dip at the notch frequency is controlled by Q. Higher Qs produce narrower dips. As in
the case of bandpass ﬁlters we can deﬁne a 3-dB band for the dip. In this case the notch
band identiﬁes frequencies around ω0 within which the attenuation is greater than 3 dB.
The notch ﬁlter described above is functionally equivalent to subtracting the output of a
bandpass ﬁlter from the input signal traversing through a direct path as in Figure 9.27.
In
Out
+
–
High Q
bandpass
FIGURE 9.27 Functional block diagram and realization of a notch ﬁlter.
Example
9.36
The circuit of Figure 9.28(a) is an equal-component twin-T notch ﬁlter. Show that
the system function is
V2
V1
=
( s
ω0 )2 + 1
( s
ω0 )2 + 1
Q ( s
ω0 ) + 1,
where
ω0 =
1
RC , Q =
1
4(1 −β) and β =
R1
R1 + R2
is the feedback factor.
Let R = 159  and C = 1 µF. Plot 20 log |H( f )| versus log f for β = 0.5,
0.875, and 0.975. Discuss the performance of the ﬁlter for the above feedback factors.

Signals and Systems
555
V2
V1
(a) Circuit
–
+
–
+
# 1
# 2
R2
R/2
2C
R1
R
B
R
C
A
Frequency (Hz)
(b) Magnitude response for Q = 0.5, 2, and 10,
due to b = 0.5, 0.875, and 0.975, respectively
Q = 2
Q = 10
Q = 0.5
104
103
102
Magnitude (dB)
10
0
–10
–20
–30
–40
–50
O
C
FIGURE 9.28 An equal-component twin-T notch ﬁlter and its magnitude frequency responses.
Solution
Both op-amps are voltage followers. Op-amp 2 provides the voltage VO = V2 ×
R1/(R1 + R2) = βV2 at its output. From the above observation and from KCL at
nodes A, B, and the noninverting input of op-amp 1 we obtain the following four
equations:
Output of op-amp 2:
VO = βV2
KCL at node A:
VA −V1
R
+ VA −V2
R
+ (VA −VO)2Cs = 0
KCL at node B:
(VB −V1)Cs + (VB −V2)Cs + VB −VO
R/2
= 0
KCL at the noninverting input of op-amp 1:
V2 −VA
R
+ (V2 −VB)Cs = 0
After eliminating VA, VB, and VO between the above four equations we are left with
V2
V1
=
R2C2s2 + 1
R2C2s2 + 4(1 −β)RCs + 1
=
1 + ( s
ω0 )2
( s
ω0 )2 + 1
Q
s
ω0 + 1,
where ω0 =
1
RC , Q =
1
4(1 −β), and β =
R1
R1 + R2
With R = 159  and C = 1 µF the notch frequency is 1 kHz. As in Examples 9.33
and 9.34, the feedback factor controls the location of the poles and, consequently,
Q. The three feedback factors β = 0.5, 0.875, and 0.975, result in Q = 0.5, 2,
and 10, respectively. The superimposed magnitude plots are shown in Figure 9.28(b).
At 1 kHz the value of the magnitude response is always zero. Higher Qs produce
narrower 3-dB bandwidths.

556
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
9.21
Second-Order All-Pass Filters
The second-order all-pass ﬁlter has a constant gain H0 and a phase that varies with
frequency. The system function and frequency response are
H(s) =
( s
ω0 )2 −1
Q ( s
ω0 ) + 1
( s
ω0 )2 + 1
Q ( s
ω0 ) + 1
H(ω) =
1 −( ω
ω0 )2 −
j
Q ( ω
ω0 )
1 −( ω
ω0 )2 +
j
Q ( ω
ω0 )
The operation of the above all-pass ﬁlter may be realized by passing the input signal
through a bandpass ﬁlter (with a gain 2) and subtracting the output from the signal,
as in Figure 9.29. The ﬁlter has a pair of poles in the LHP and a pair of zeros in the
RHP mirror-imaging the poles with respect to the jω axis. Pole-zero location and phase
response depend on Q and ω0.
In
Out
+
–
Bandpass
gain = 2
FIGURE 9.29 Functional block diagram and realization of a second-order all-pass ﬁlter. The
system function of the block diagram is
H(s) = 1 −2
2as
s2 + 2as + b = s2 −2as + b
s2 + 2as + b
9.22
Contribution from a Zero
A zero at s = −ω0 contributes the normalized factor (1 + s/ω0) to the system function
and adds 10 log[1 + (ω/ω1)2] dB to the magnitude response. At high frequencies
this translates into +20 dB per decade. The effect of the zero’s contribution at low or
intermediate frequencies will depend on the location of the zero with respect to the poles
and the Q factor. In this section, by way of an example, we illustrate how a zero reshapes
the frequency response of a second-order system function.
Example
9.37
Consider the second-order ﬁlter with a zero at s = −ω1 characterized by
H(s) =
( s
ω1 ) + 1
( s
ω0 )2 + 1
Q
s
ω0 + 1
20 log |H(ω)| = 20 log
1 + j ω
ω1
 −20 log
1 −
	 ω
ω0

2
+ j
Q
ω
ω0


Signals and Systems
557
in which the DC gain is one. The introduction of the zero increases the magnitude
response by 10 log[1 + (ω/ω1)2] dB. At low frequencies (ω << ω1), the increase is
negligible and the frequency response remains the same as that of the system without
a zero. At ω = ω1, the increase is 3 dB. At high frequencies (ω >> ω1), the increase
is ≈20 log ω, which corresponds to 20 dB per decade, reducing the slope of the
high-frequency asymptote by that amount. How inﬂuential the magnitude increase is
in reshaping the frequency response at low and intermediate frequencies depends on
the location of the zero with respect to the poles, and the Q factor. This is illustrated
for zeros at ω1 = 0.01, 10, and ∞(no zero) in Figure 9.30(a) (Q = 0.1) and
Figure 9.30(b) (Q = 20). In all cases the undamped natural frequency of the system
is 1 rad/s.
−60
−80
−40
−20
0
20
40
Q = 0.1
Q = 20
w1 = .01
w1 = 0.01
w1 = 10
w1 = 10
No zero
No zero
60
Magnitude (dB)
−60
−80
−40
−20
0
20
40
60
Magnitude (dB)
Frequency (Hz)
10−2
10–1
100
101
102
103
10−2
10–1
100
101
102
103
Frequency (Hz)
(b) Effect of a zero located at w1 when Q = 20
(a) Effect of a zero located at w1 when Q = 0.1
FIGURE 9.30 Adding a zero to a second-order system (DC gain = 1, ω0 = 1, Q = 0.1 and 20) reshapes its magnitude
response. The zero is placed at ω1 = 10, 0.01, or ∞(no zero). The slope of the high-frequency asymptote is reduced
from −40 dB/ decade (for the system with no zero) to −20 dB/decade (for the system with a ﬁnite zero). A zero placed
far from the origin doesn’t inﬂuence the system’s behavior at low and intermediate frequencies. When the zero is close to
the origin the magnitude of the system’s frequency response is increased by 20 dB over most of the frequency range.
9.23
Series and Parallel RLC Circuits
A circuit made of three elements R, L, C and an input source constitutes a second-order
ﬁlter. The source-free circuit of the ﬁlter can have one of two conﬁgurations: RLC in
series or RLC in parallel. The input signal may come from a voltage source or a current
source. Depending on where in the circuit the input signal arrives and where the output
signal is picked up, we can have a low-pass, high-pass, or bandpass ﬁlter. In this section
we summarize the ﬁltering effect in two basic conﬁgurations: (1) RLC in series with a
voltage source and (2) RLC in parallel with a current source.
Consider an RLC circuit in series with a voltage source input as in Figure 9.31(a).
Three element voltages vR, vL, and vC constitute the low-pass, high-pass, and bandpass
outputs, respectively. To see this, we construct the three system functions summarized

558
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
(a) A voltage source feeds a
series RLC circuit
(b) A current source feeds a parallel RLC circuit
iS
iR
vC
vL
vR
+
+
–
–
+
–
v
+
–
iL
iC
FIGURE 9.31 Filtering by RLC circuits.
in Table 9.8(a). A similar situation arises when a current source (providing the input
signal) is placed in parallel with an RLC circuit. See Figure 9.31(b). Currents in R, L,
and C constitute the low-pass, high-pass and bandpass outputs, as summarized by the
system functions in Table 9.8b.
TABLE 9.8a. Filtering in a Series RLC Circuit [Figure 9.31(a)]
Filter Type
H(s)
Low-pass
HC(s) = Vc
Vs
=
1
LCs2 + RCs + 1 =
1
( s
ω0 )2 + 1
Q
s
ω0 + 1
High-pass
HL(s) = VL
Vs
=
LCs2
LCs2 + RCs + 1 =
( s
ω0 )2
( s
ω0 )2 + 1
Q
s
ω0 + 1
Bandpass
HR(s) = VR
Vs
=
RCs
LCs2 + RCs + 1 =
1
Q
s
ω0
( s
ω0 )2 + 1
Q
s
ω0 + 1
ω0 =
1
√
LC
and Q = 1
R

L
C
TABLE 9.8b. Filtering in a Parallel RLC Circuit [Figure 9.31(b)]
Filter Type
H(s)
Low-pass
HL(s) = IL
Is
=
1
LCs2 + L
R s + 1 =
1
( s
ω0 )2 + 1
Q
s
ω0 + 1
High-pass
HC(s) = IC
Is
=
LCs2
LCs2 + L
R s + 1 =
( s
ω0 )2
( s
ω0 )2 + 1
Q
s
ω0 + 1
Bandpass
HR(s) = IR
Is
=
L
R s
LCs2 + L
R s + 1 =
1
Q
s
ω0
( s
ω0 )2 + 1
Q
s
ω0 + 1
ω0 =
1
√
LC
and Q = R

C
L

Signals and Systems
559
Example
9.38
The frontal stage of a hypothetical AM radio receiver is modeled as a current source
feeding a parallel RLC circuit in resonance and generating a voltage signal. The RLC
circuit is used as a tuning device to select the signal from the desired station and
attenuate signals from other stations. This example explores the minimum frequency
separation between two adjacent stations if selection of the station is not enhanced
by other tuning or ﬁltering stages in the receiver.
An AM station, WGB1, broadcasts at the center frequency f1 = 1 MHz with a
3-dB bandwidth of 10 kHz bandwidth. A second AM station, WGB2, broadcasts at
the center frequency f2 with the same power and bandwidth as WGB1. The parallel
RLC circuit is used to tune to WGB1. It is desired that when the receiver is tuned to
WGB1, the f2 component of the voltage signal picked up by it be 60 dB below the
f1 component. Find the minimum frequency separation between the two stations.
Solution
From Table 9.8b the system function and frequency response of a parallel RLC circuit
are found to be
H(s) = V
Is
=
R
Q
s
ω0

s
ω0
2
+ 1
Q
s
ω0 + 1
|H( f )|2 =
R2
1 + Q2

f
f0 −f0
f
2
20 log |H( f )| = 20 log R −10 log

1 + Q2
	 f
f0
−f0
f

2
The quality factor of the RLC tuning curve of WGB1 is Q = f1/f = 100. Its
attenuation in dB at frequency f is
10 log

1 + Q2
	 f
f1
−f1
f

2
The minimum frequency separation between the two stations is found by setting
the above attenuation to 60 dB, which results in f2(low) = 0.1 f1 = 100 kHz and
f2(high) = 10.1 f1 = 10.1 MHz.
9.24
Summary of Second-Order Filters
The system function of a stable second-order ﬁlter is
H(s) =
B(s)
s2 + 2as + b
where, as before, a and b are positive real numbers, and B(s) is a polynomial in s of an
order not higher than 2. The pole-zero conﬁguration of the ﬁlter determines its type and

560
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
forms its frequency response. The polynomial B(s) produces zeros and results in the ﬁlter
becoming low-pass, high-pass, all-pass, bandpass, or bandstop. These are summarized
in Table 9.9 using the ω0 and Q model. Figure 9.32 shows superimposed magnitude and
phase responses of four basic types of second-order ﬁlters for Q = 0.7, 2, and 20.
TABLE 9.9 Second-Order Filters
Filter Type
H(s)
H(ω)
Low-pass
1
( s
ω0 )2 + 1
Q
s
ω0 + 1
1
1 −( ω
ω0 )2 +
j
Q
ω
ω0
High-pass
( s
ω0 )2
( s
ω0 )2 + 1
Q
s
ω0 + 1
( ω
ω0 )2
1 −( ω
ω0 )2 +
j
Q
ω
ω0
All-pass
( s
ω0 )2 −1
Q
s
ω0 + 1
( s
ω0 )2 + 1
Q
s
ω0 + 1
1 −( ω
ω0 )2 −
j
Q
ω
ω0
1 −( ω
ω0 )2 +
j
Q
ω
ω0
Bandpass
s
ω0
( s
ω0 )2 + 1
Q
s
ω0 + 1
jω
ω0
1 −( ω
ω0 )2 +
j
Q
ω
ω0
Notch
( s
ω0 )2 + 1
( s
ω0 )2 + 1
Q
s
ω0 + 1
1 −( ω
ω0 )2
1 −( ω
ω0 )2 +
j
Q
ω
ω0
9.25
Group and Phase Delay
The phase shift experienced by a sinusoid in passing through an LTI system is frequency
dependent. It is the phase of the frequency response of the system at that frequency. A
phase shift may be expressed as a time shift; cos(ωt ±θ) = cos ω(t ±τ), where ω is the
angular frequency of the sinusoid in rad/s and τ = θ/ω in seconds. If the LTI system is
physically realizable, the time shift becomes a delay. In a linear-phase system θ = τω,
which results in a constant delay at all frequencies. In a more general case, depending
on the phase function of the frequency response of the system through which a signal
passes, different frequency components experience different delays. Group delay tg and
phase delay tp, deﬁned below, can provide some measure of changes in the shape of
signals.
tg( f ) = −1
2π
dθ( f )
d f
and
tp( f ) = −1
2π
θ( f )
f
The following two examples illustrate simple cases of group delay.

Signals and Systems
561
Frequency (Hz)
101
100
10–1
Magnitude (dB)
5
0
–10
–5
–15
–25
–30
–35
–20
Frequency (Hz)
(d) Notch
101
100
10–1
Angle (degrees)
80
20
40
60
0
–40
–60
–80
–20
Frequency (Hz)
101
100
10–1
Magnitude (dB)
Magnitude (dB)
Magnitude (dB)
30
10
20
0
–20
–30
–40
–10
Frequency (Hz)
(c) Bandpass
101
100
10–1
Angle (degrees)
80
20
40
60
0
–40
–60
–80
–20
Frequency (Hz)
101
100
10–1
30
10
20
0
–20
–30
–40
–10
Frequency (Hz)
(b) High-pass
101
100
10–1
Angle (degrees)
180
120
140
160
100
60
40
20
0
80
Frequency (Hz)
101
100
Q = 20
Q = 20
Q = 2
Q = 2
Q = 0.7
Q = 0.7
10–1
30
10
20
0
–20
–30
–40
–10
Frequency (Hz)
(a) Low-pass
101
100
10–1
Angle (degrees)
0
–60
–40
–20
–80
–120
–140
–160
–180
–100
FIGURE 9.32 Superimposed frequency responses of four types of ﬁlters for Q = 0.7, 2, and 20. Magnitude plots are
in the left and phase plots in the right.

562
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Example
9.39
A linear, time-invariant, all-pass, unity-gain ﬁlter introduces a phase lag θ in a sinu-
soidal signal passing through it:
vi(t) = V cos ωt
⇒vo(t) = V cos(ωt −θ)
for all V and ω. Given vi(t) = (1+2 cos ω0t) cos ωct, where ω0 = 107 and ωc = 108,
ﬁnd vo(t) for the following three ﬁlters:
1.
Linear phase θ = 10−9ω.
2.
Constant phase θ = 10−1.
3.
Linear phase with a constant bias θ = (10−9ω + 10−1). θ and ω are in radians
and radians per second, respectively.
Solution
Assuming ωl = ωc −ω0 = 0.9 × 108 and ωh = ωc + ω0 = 1.1 × 108, the input
signal may be expanded into its sinusoidal components
vi(t) = cos ωlt + cos ωht + cos ωct
The output is
vo(t) = cos(ωlt −θl) + cos(ωht −θh) + cos(ωct −θc)
a.
In the case of a linear phase ﬁlter, θl = 10−9ωl, θh = 10−9ωh, and θc = 10−9ωc.
The output is
vo(t) = cos(ωlt −10−9ωl) + cos(ωht −10−9ωh) + cos(ωct −10−9ωc)
= cos ωl(t −10−9) + cos ωh(t −10−9) + cos ωc(t −10−9)
= vi(t −10−9)
Because of the linear phase property, the output is a delayed version of the
input. The delay is equal to the slope of the phase lag versus the ω curve, which
is equal to 10−9 seconds.
b.
In the case of a ﬁlter with constant phase, θl = θh = θc = 0.1.
vo(t) = cos(ωlt −0.1) + cos(ωht −0.1) + cos(ωct −0.1)
= cos ωl(t −1.11 × 10−9) + cos ωh(t −0.91 × 10−9) + cos ωc(t −10−9)
Because of the constant phase, the time delay depends on the frequency. Higher
frequencies experience smaller delays than lower frequencies, producing a
distortion. The time delays are given below.
ω in rad/s
delay in sec
ωℓ= 0.9 × 108
1.11 × 10−9
ωc = 108
10−9
ωh = 1.1 × 108
0.91 × 10−9

Signals and Systems
563
c.
In the case of a linear phase with a constant bias we have
vo(t) = cos(ωlt −θℓ) + cos(ωht −θh) + cos(ωct −θc)
where
θl = 10−9ωl + 0.1 = 0.19
θh = 10−9ωh + 0.1 = 0.21
θc = 10−9ωc + 0.1 = 0.2
Substituting for θ we get
vo(t) = cos(ωlt −0.19) + cos(ωht −0.21) + cos(ωct −0.2)
= cos ωl(t −2.11 × 10−9) + cos ωh(t −1.9 × 10−9)
+ cos ωc(t −2 × 10−9)
As in case b, the three frequency components in vo(t) undergo three different
delays as given below.
ω in rad/s
delay in sec
ωℓ= 0.9 × 108
2.11 × 10−9
ωc = 108
2 × 10−9
ωh = 1.1 × 108
1.9 × 10−9
By way of simpliﬁcation, one may consider that the total signal is delayed by
an average of 2 × 10−9 seconds. However, in this case, the nonuniformity in
delays doesn’t produce destructive distortion. By combining the low- and
high-frequency components in vo(t) we ﬁnd
vo(t) = [1 + 2 cos ω0(t −11 × 10−9)] cos ωc(t −2 × 10−9)
Note that the amplitude 1 + 2 cos ω0t is delayed by 11 nanoseconds, becoming
1 + 2 cos ω0(t −11 × 10−9), but experiences no distortion. The carrier cos ωct
is delayed by 2 nanoseconds and becomes cos ωc(t −2 × 10−9). This
phenomenon is generalized in the next example.
Example
9.40
A simple case of group delay
Consider a linear ﬁlter that has unity gain within the passband ωc±ω and introduces
a phase lag θ in a sinusoidal signal passing through it. In other words,
vi(t) = V cos(ωt)
⇒
vo(t) = V cos(ωt −θ)
for all V and (ωc −ω) < ω < (ωc + ω). Within the above band the phase lag is
θ = θc + τ0(ω −ωc). Let the input to the ﬁlter be an amplitude-modulated waveform
vi(t) = [1 + 2A cos(ω0t)] cos(ωct)

564
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
where cos(ωct) is the carrier and 1 + 2A cos(ω0t) is the modulating signal with
ω0 < ω. Find the output vo(t).
Solution
Expand the input signal into its sinusoidal components:
vi(t) = A cos(ωℓt) + A cos(ωht) + cos(ωct)
where
ωℓ= ωc −ω0
ωh = ωc + ω0
The input signal, therefore, falls within the passband. The output is
vo(t) = A cos(ωℓt −θℓ) + A cos(ωht −θh) + cos(ωct −θc)
where
θℓ= θc + τ0(ωℓ−ωc) = θc −τ0ω0
θh = θc + τ0(ωh −ωc) = θc + τ0ω0
Combining the ﬁrst two terms of vo(t) and noting that
ωc = ωh + ωℓ
2
ω0 = ωh −ωℓ
2
we get
vo(t) = 2A cos
	
ω0t −θh −θℓ
2

cos
	
ωct −θh + θℓ
2

+ cos(ωct −θc)
Deﬁne τc = θc/ωc. Then
θh + θℓ= 2θc = 2τcωc
θh −θℓ= 2θ0 = 2τ0ω0
Therefore,
vo(t) = 2A cos(ω0t −θ0) cos(ωct −θc) + cos(ωct −θc)
= 2A cos ω0(t −τ0) cos ωc(t −τc) + cos(ωct −τc)
= [1 + 2A cos ω0(t −τ0)] cos ωc(t −τc)
The modulating signal and the carrier are delayed by τ0 and τc, respectively. In
general, the modulating signal may contain many frequency components. As long
as they remain within the band 2ω, all will be delayed by the same amount τ0,
which makes the modulating signal undistorted. The carrier cos ωct is delayed by τc,
a different amount. This, however, doesn’t introduce any distortion in the modulating
signal. As a group, the total signal is delayed by an average of τc.

Signals and Systems
565
9.26
Measurements, Identification, and
Modeling
By measurement we can ﬁnd the magnitude and phase of the frequency response and
decide on break points if the system function is to be rational.
Example
9.41
Magnitude response of a ﬁlter is measured and plotted in Figure 9.33. Its salient
features are summarized below. Model it by using a rational system function.
Frequency, rad/s
DC
ωℓ= 3.75
ωMax = 5.612
ωh = 7
High frequency
Magnitude (dB)
0
3.3
6.3
3.3
−40 dB/decade
−80
–70
−60
−50
−40
−30
−20
−10
0
10
Magnitude (dB)
100
101
102
103
Angular frequency (rad/s)
(a) Bode magnitude plot
0
0.2
0.6
0.4
0.8
1
1.2
1.4
1.6
1.8
2
Magnitude in linear scale
0
10
20
30
40
50
60
70
80
90
100
Angular frequency in rad/s, linear scale
(b) Linear magnitude, full range
1.5
1.6
1.7
1.8
1.9
2
2.1
Magnitude in linear scale
4
4.5
5
5.5
6
6.5
7
Angular frequency in rad/s, linear scale
(c) Linear magnitude, 3-dB band
FIGURE 9.33 Magnitude measurement of the frequency response of a ﬁlter to be modeled by a rational function.

566
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Solution
The high-frequency asymptote of the magnitude response indicates that the ﬁlter has
two more poles than zeros. We start with the simplest model, which is a second-order
low-pass ﬁlter with no zeros in the ﬁnite s-plane shown by the normalized system
function
H(s) =
H0

s
ω0
2
+ 1
Q
s
ω0 + 1
and
H(ω) =
H0
1 −

ω
ω0
2
+
j
Q
ω
ω0
Using the values given in the above table and applying the above equation as a ﬁrst-
order approximation, we estimate Q = 2.066 and ω0 = 5.612. This is not a high Q
and the estimate is not satisfactory. We need to determine, in terms of Q and ω0, the
frequency that maximizes |H(ω)|2, or equivalently, minimizes its denominator. This
is done by ﬁnding the roots of
d
dω

x4 +
	 1
Q2 −2

x2 + 1

= 0,
where x = ω
ω0
from which we ﬁnd Q = 2.03 and ω0 = 5.986. We choose Q = 2 and ω0 = 6 and
the system function will then be
H(s) =
36
s2 + 3s + 36
TheabovemodelturnsouttobethesystemfunctionthatgeneratedplotsofFigure9.33.
Further modeling exercise is available in Project 4 at the end of this chapter.
9.27
System Interconnection
Several systems may be connected and combined to form a bigger system. The system
function of the combined system is found from a knowledge of its subsystems and their
interconnection. Three basic connections are recognized:
A Series Connection
This exists when two subsystems are cascaded. The output of the ﬁrst subsystem provides
the input to the second subsystem. The second subsystem doesn’t load the ﬁrst subsystem.
See Figure 9.34.
H(s) = H1(s) × H2(s) ⇐⇒
h(t) = h1(t) ⋆h2(t)
The series connection, in general, retains the poles and zeros of its subsystems except in
cases of pole-zero cancellation, examples of which will be given in the next section. The
magnitude and phase of the frequency responses are multiplied together when they are
expressed in linear scale. The magnitude responses are added together when expressed
in dB (i.e., log scale such as in Bode plots).

Signals and Systems
567
H1(s)
X(s)
X(s)
Y(s) = X(s) H1(s)
Z(s) = Y(s) H2(s)
Z(s) = X(s) H(s)
H(s) = H1(s) H2(s)
H2(s)
FIGURE 9.34 A series connection of two LTI systems H1 and H2 produces an equivalent LTI system with H(s) =
H1(s) × H2(s). The unit-impulse response of the equivalent system is h(t) = h1(t) ⋆h2(t).
A Parallel Connection
This exists when two subsystems receive the same input and their outputs are added
togethertoprovidetheoverallsystem’soutput.SeeFigure9.35.Thisarrangementdoesn’t
affect the performance of individual subsystems.
H(s) = H1(s) + H2(s) ⇐⇒
h(t) = h1(t) + h2(t)
The parallel combination retains the poles of its subsystems except in possible pole-zero
cancellation cases. The magnitudes and phases of the frequency responses, in general,
neither multiply nor add (except in special cases).
H1(s)
X(s)
Z(s)
+
+
Σ
X(s)
Z(s) = X(s) H(s)
H(s) = H1(s) + H2(s)
H2(s)
FIGURE 9.35 A parallel connection of two LTI systems H1 and H2 (left) produces an equivalent
LTI system with H(s) = H1(s) + H2(s) (right). The unit-impulse response of the equivalent
system is h(t) = h1(t) + h2(t).
A Feedback Connection
This is shown in Figure 9.36, and discussed in the next section.
X(s)
Y(s)
X(s)
Y(s) = X(s)H(s)
B(s)
A(s)
H(s) =
B(s)A(s)
1 + B(s)A(s)
+
–
Σ
FIGURE 9.36 A feedback system (left) and its equivalent (right). A(s) is the system function of
the forward path (also called the open-loop transfer function) and B(s) is the system function of
the feedback path. The closed-loop system function is H(s) = A(s)/[1 + B(s)A(s)].

568
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
A Note on Loading Effect
Loading may occur when subsystems are connected together. It is important to pay
attention to possible loading effects from one subsystem to another. Ideally, connecting
two subsystems should not modify their system functions and should not change their
individual performances. In electric circuits this is achieved by placing a buffer (normally
an op-amp) between the two subsystems. If this is not practical, the loading effect should
be taken into consideration when specifying the system function of each subsystem (e.g.,
termination effect in transmission lines).
9.28
Feedback10
A feedback system is shown in Figure 9.36. The closed-loop system function is found
by
Y(s) = [X(s) −Y(s)B(s)]A(s)
H(s) = Y(s)
X(s) =
A(s)
1 + B(s)A(s)
A(s) is called the forward path (or open-loop transfer function) and B(s) is the system
function of the feedback path. The product A(s)B(s) is called the loop gain. For large
loop gains we may appproximate H(s) by
H(s) =
A(s)
1 + B(s)A(s) ≈
1
B(s)
if |A(s)B(s)| >> 1
In such a case, the closed-loop system becomes less dependent on the system function
of the forward path and more dependent on the system function of the feedback path,
becoming approximately equal to its inverse. This fundamental property of negative
feedback allows us to control pole-zero locations according to desired speciﬁcations. In
this way we may:
1.
Reduce sensitivity to change in A(s) or its uncertainty.
2.
Increase the bandwidth.
3.
Improve the step response; for example, reduce its rise time, oscillations, and
overshoot.
4.
Control the system’s performance.
Another model of a feedback control system is shown in Figure 9.37, in which the
subsystem C(s) is called the controller. The overall system function of Figure 9.37 is
similarly found to be
H(s) =
A(s)C(s)
1 + A(s)C(s)
10For several historical accounts on the origin and history of feedback control see the following: Otto Mayr,
The Origins of Feedback Control (Cambridge: MIT. Press, 1970). Gordon S. Brown, in Scientiﬁc American,
1951. Stuart Bennet, “A Brief History of Automatic Control,” IEEE Control Systems, June 1996, pp. 17–25.

Signals and Systems
569
X(s)
Y(s)
X(s)
Y(s) = X(s)H(s)
Σ
C(s)
A(s)
H(s) =
C(s)A(s)
1 + C(s)A(s)
+
–
FIGURE 9.37 A feedback system with a controller (left) and its equivalent (right). The subsystem
C(s) is called the controller. The overall system function is H(s) = C(s)A(s)/[1 + C(s)A(s)].
A third feedback model is shown in Figure 9.38 which contains a feedback path B(s)
representing sensors and a controller C(s). The overall system function of Figure 9.38
is
H(s) =
A(s)C(s)
1 + A(s)B(s)C(s)
X(s)
E(s)
Y(s)
X
Y = HX
Σ
C(s)
A(s)
B(s)
Closed-loop feedback
Equivalent system
H =
AC
1 + ABC
+
–
FIGURE 9.38 A feedback control system with a sensor B(s) and controller C(s) (left). The
overall system function is H(s) = A(s)C(s)/[1 + A(s)B(s)C(s)] (right).
Feedback: Effect on Sensitivity
Negative feedback can reduce the sensitivity of the closed-loop system to variations in
the forward path. We will now illustrate this effect. The measure of sensitivity S of a
function y = f (x) to variations in x is deﬁned by
Sy
x = Percentage change produced in y
Percentage change in x
= dy/y
dx/x ≈y/y
x/x
Now consider a feedback system with forward gain A and feedback factor β. The closed-
loop gain of the system and its sensitivity to variations in A and β are
H
=
A
1 + β A
d H
= d A −A2dβ
(1 + β A)2
d H
H

β=constant
=
1
1 + β A
	d A
A

⇒SH
A = d H/H
d A/A =
1
1 + β A
d H
H

A=constant
=
−β A
1 + β A
	dβ
β

⇒SH
β = d H/H
dβ/β =
−β A
1 + β A

570
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Example
9.42
Let A = 2,000 and β = 0.0495 resulting in H = 2,000/(1+0.0495×2,000) = 20.
At that setting, the sensitivity of H to A is SH
A = 1/1 + 0.0495 × 2,000) ≈0.01.
That means a fractional change of ϵ% in A results in a fractional change of 0.01ϵ%
in H. For example, let A be increased from 2000 to 2001 (a fractional change of
100 × (2,001 −2,000)/2,000 = 0.05%). The result is an increase in H from 20 to
20.0001 (a fractional change of 100 × (20.0001 −20)/20 = 0.0005%).
Note that the sensitivity, as deﬁned above, applies to small changes (d H and d A).
For the effect of large changes (such as a doubling of A) one needs to devise an in-
tegration method if the above sensitivity index is used. Alternatively, one may use a
new measure (as in Examples 9.46 and 9.47). Two practical applications, illustrated in
Examples 9.43 and 9.44, measure performance of the feedback systems using the index
E = 100 × (H −Hd)/Hd which shows the percentage deviation of H from the desired
value Hd.
Example
9.43
A power amplifier
A power ampliﬁer has a nominal (and desired) gain of A = 20. But its actual gain
varies between 10 and 30 (a ±50% variation). See Figure 9.39(a). To reduce the above
variations, we place the power ampliﬁer in a feedback loop containing a sensor (with
a feedback factor B) and a proportional controller (preampliﬁer with a gain of C) as
shown in Figure 9.39(b). Determine B and C so as to bring down the variation in the
overall gain of the closed-loop system to less than 1% of the desired value.
X
(a) Open-loop amplifier
(b) Feedback amplifier
(c) Equivalent system
X
Y
Y
X
Y = HX
Σ
C
A
A
B
H =
AC
1 + ABC
+
–
FIGURE 9.39 A power ampliﬁer in open-loop and with feedback. Negative feedback reduces the sensitivity of the system
to variations in the power ampliﬁer’s gain. In this ﬁgure, Y/X = (AC)/(1 + ABC). For example, let the open-loop gain
of the power ampliﬁer be A = 20 ± 50%. It is desired to have a power gain of 20 ± 1% using the above power ampliﬁer.
The system of (b), with a feedback coefﬁcient of B = 0.0495 and a voltage preampliﬁer with a gain of C = 100, would
result in an overall gain of H = 2,000A/(20 + 99A). For A = 10, 20, 30 we will have H = 19.802, 20.000, 20.067,
respectively, which is within 20 ± 1%.
Solution
We start with the approximation that H = (AC)/(1 + ABC) ≈1/B = 20 if
ABC >> 1. We choose a feedback factor B = 0.0495. The gain of the preampliﬁer
C may then be computed from the expression for H or found by trial and error.
Choosing C = 100 will result in the following satisfactory values for H.

Signals and Systems
571
A
H
E%
10
19.802
−0.99
20
20
0
30
20.067
+0.335
where E = 100 × (H −20)/20 is the percentage deviation of H from the desired
gain of 20.
Example
9.44
Closed-loop operation of a noninverting amplifier
A noninverting op-amp circuit and its equivalent circuit are shown in Figure 9.40 a
and b, respectively.
a.
Find the closed-loop gain H = V2/V1 as a function of A, R1, and R2. Model it
as a feedback loop and specify its open-loop gain and the feedback factor.
b.
A closed-loop gain of 5 is desired regardless of A. Choose R1 = 1 and R2 = 4
both in K and evaluate H for
A = 5, 10, 100, 1,000, 10,000, 50,000, 100,000, ∞. Deﬁne
E = 100 × H −5
5
as the percentage deviation of H from the desired gain of 5. For each value of A
compute E and enter the results in a table. Comment on the effect of feedback
on the closed-loop gain and its sensitivity to variations in A.
Solution
a.
From Figure 9.40(b): Vd = V1 −βV2 and V2 = AVd, resulting in H =
A
1+β A,
where β =
R1
R1+R2 .
b.
β = .2, H =
A
1+0.2A, and E =
−100
1+0.2A%. The table below shows values of H and
E for given values of A.
A
5
10
100
1,000
10,000
50,000
100,000
∞
H
2.5
3.3333
4.7619
4.9751
4.9975
4.9995
4.9997
5.00
E%
−50%
−33.333%
−4.762%
-0.4975%
−0.04997%
−0.01%
−0.005%
0
As A increases, |E%| decreases. At high values of A, the closed-loop gain
changes very little even when A is increased considerably. For example a
ﬁvefold increase in A, from A = 10,000 to A = 50,000, increases H from
4.9975 (with a percentage relative error of E ≈−0.05%) to 4.9995 (with a
percentage relative error of E = −0.01%). Feedback reduces sensitivity of the
overall gain to variaitions in A by the factor 1 + β A.

572
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
(a) Noninverting amplifier
with feedback
+
v1
(c) System model
v2
H v1
–
+
+
+
–
–
+
–
+
–
+
–
v2
(b) Circuit model
v2
vd
A vd
v1
+
–
v1
R2
R1
R1
R2
–
–
+
–
FIGURE 9.40 (Example 9.44) The 741 op-amp is supplied with negative feedback to its inverting terminal through
the R1/R2 voltage divider. The ampliﬁer now may be modeled by a closed-loop system such as shown in Figure 9.36.
The feedback ratio is β = 0.1 (i.e., the input to the op-amp is now V1 −βV2). The new closed-loop system function is
H(s) = a1ω1/(s + ω1). The feedback moves the pole from 5 Hz to 1 MHz, thus reducing the time constant from 31.83
msec to 1.59 µsec. This increases the bandwidth 2 × 105 times at the cost of reducing the DC gain by that same factor.
Feedback: Effect on Frequency Response
Feedback can increase the bandwidth of a system.11 To illustrate the effect of feedback
on the frequency response, we examine the frequency response of a 741 op-amp, in both
open-loop and closed-loop conﬁgurations. The 741 op-amp is modeled by a DC gain of
2 × 105 and a pole at f = 5 Hz (3-dB bandwidth). The product DC gain × bandwidth
is 200,000 × 5 = 106. It is called the gain-bandwidth product (GBP) and comprises a
speciﬁcation of the op-amp. The GBP is the frequency at which the gain becomes one
(i.e., where the op-amp’s magnitude plot intersects the 0-dB level). Feedback pushes
the pole of the closed-loop system away from the jω axis, increasing the bandwidth
and reducing the gain. In the closed-loop feedback system of Example 9.45, the GBP
remains the same regardless of the feedback coefﬁcient.
Example
9.45
Open-loop frequency response of a 741 op-amp
Typically, a 741 op-amp (Figure 9.41a) has a DC gain of 2 × 105, a ﬁrst pole at
f = 5 Hz and a second pole at 1 MHz. It is modeled12 by the circuit of Figure 9.41b
having the system function
A(s) = V2
V1
=
a0
1 + ( s
ω0 ),
where a0 = 2 × 105 and ω0 = 10π rad/s (corresponding to 5 Hz)
The system model is shown in Figure 9.41(c). Find and sketch its Bode plot.
Solution
The frequency response, expressed as a function of frequency in Hz, is
A( f ) =
106
5 + j f = 200, 000
1 + j f/5
11For a brief historical background that led to development of feedback ampliﬁers see William Siebert,
Circuits, Signals and Systems (Cambridge: MIT Press, 1986): p. 145.
12See section 9.7 on approximation of a system function by its dominant pole(s).

Signals and Systems
573
(a) Open-loop
741 op-amp
C
R
(c) Voltage-dependent
system model
(b) First-order
RC circuit model
v2
G v1
–
+
+
–
+
v1
v2
A v1
–
+
+
–
+
–
+
–
v1
+
–
v2
v1
–
–
+
–
FIGURE 9.41 The 741 op-amp in open-loop conﬁguration. The ampliﬁer (a) is ap-
proximated by a ﬁrst-order model A(s) = a0ω0/(s + ω0) where a0 = 2 × 105 and
ω0 = 10π rad/s (corresponding to 5 Hz). The model may be shown by a dependent
current source feeding a parallel RC (b), or equivalently, by a dependent voltage source
with a frequency dependent gain of A(s) (c).
The Bode plots are shown in Figure 9.42(a) (magnitude) and Figure 9.42(b) (phase).
The curves are superimposed on the Bode plots of the closed-loop system of Figure
9.40(a) for comparison. The open-loop DC gain is 20 log 200,000 = 106 dB, which
constitutes the low-frequency asymptote. The break frequency is at 5 Hz, where the
magnitude is 3 dB below the DC gain; that is, at 106 −3 = 103 dB. The open-loop
3-dB bandwidth is 5 Hz. The GBP is 5 × 200,000 = 106.
10−1
100
101
102
103
104
105
106
107
0
20
40
60
80
100
Magnitude (dB)
Frequency in Hz, log scale
(a)
Open-loop
Closed-loop
10−1
100
101
102
103
104
105
106
107
–90
–80
–70
–60
–50
–40
–30
–20
–10
0
Phase (deg)
Frequency in Hz, log scale
(b)
Open-loop
Closed-loop
FIGURE 9.42 Frequency responses of 741 op-amp in open-loop and closed-loop conﬁguration. Bode plots for magnitude
(a) and phase (b) of a 741 op-amp in open-loop conﬁguration H( f ) = 106/(5 + j f ) versus f in Hz, DC gain = 106 dB,
BW = 5 Hz, discussed in Example 9.45. Curves for the closed-loop conﬁguration of the op-amp in the circuit of
Figure 9.40(a) (DC gain = 20 dB, BW = 100 kHz) are given for comparison. Gain-bandwidth product (GBP) of the
op-amp is 106.

574
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
The high-frequency asymptote of the magnitude Bode plot is a line with a −20 dB/
decade slope passing through the point with the coordinates (106 dB, 5 Hz). At
2.5 Hz and 10 Hz, the magnitude is −1 and −7 dB, respectively, 1 dB below the value
of the asymptote at these frequencies. The high-frequency asymptote reaches the
0-dB level (which corresponds to unity gain) at 1 MHz, which is the gain-bandwidth
product of the 741 op-amp. It is noted that the product of gain and frequency along
the segment of its magnitude plot with −20 dB slope (5 Hz to 1 MHz band) remains
constant at 106.
The phase plot shown in Figure 9.42(b) goes from 0◦to −90◦. The inﬂexion point
is at 5 Hz where the phase is −45◦. At 2.5 Hz and 10 Hz, the phase is −26.5◦and
−63.5◦, respectively. Note that Figure 9.42 plots 20 log |H( f )| and ̸ H( f ) versus
log f (labeled in Hz).The labels on the frequency axis could be changed to 2π f
without any other change in the graphs. The break frequency would then be 31.4 rad/s.
Example
9.46
Closed-loop frequency response of a 741 op-amp
in noninverting configuration
Find and plot the frequency response of the 741 op-amp circuit of Figure 9.40(a) in
the form of a Bode plot and compare with the frequency response of the open-loop
op-amp.
Solution
In linear circuits the op-amp is never used in the open-loop form. For one thing, the
linear model of Figure 9.41 is valid only when the output remains between saturation
levels ±V0. In the open-loop, because of the huge gain, the output immediately
saturates, swinging between the high and low saturation levels. For another thing,
the open-loop bandwidth is very small (≈5 Hz). Placing the op-amp in a feedback
loop trades the high gain for other desired features such as a broader bandwidth (or
equivalently a smaller time constant). In Figure 9.40(a) we already have seen a 741 op-
amp in a simple closed-loop with a resistive feedback to its inverting input. Its circuit
model is shown in Figure 9.40(b). The closed-loop system function may be derived
from Figure 9.40(b) by using circuit laws. It may also be derived from the feedback
model of Figure 9.36, with the feedback coefﬁcient being β = R1/(R1 + R2). The
resulting closed-loop system function of Figure 9.40(c) is
H(s) =
A(s)
1 + β A(s) ≈
a1
1 +
 s
ω1
, where β =
R1
R1 + R2
, a1 = 1
β and ω1 = a0βω0
The frequency response of the circuit of Figure 9.40(a), expressed as a function of f
(in Hz), is
H( f ) =
1
β
1 + j

f
a0β f0

where a0 and ω0 are the DC gain and the pole of the 741 op-amp, respectively, and
β = R1/(R1+ R2) is the feedback factor. As an example, let a0 = 2×105, ω0 = 10π,

Signals and Systems
575
R1 = 1 K and R2 = 9 K. Then β = 0.1 and the closed-loop system function
becomes
H(s) =
10
1 + ( s
ω1 )
ω1 = 200,000π
Feedback moves the pole to −ω1 = −200,000π (corresponding to 100 kHz).
The magnitude and phase plots of the closed-loop frequency response for β = 0.1
are superimposed on Figure 9.42, for comparison with the open-loop frequency response.
The 3-dB frequency of the closed-loop circuit is at f1 = a0β f0 = 2 × 105 × 0.1 × 5 =
105 Hz, which is the location of the new pole. Negative feedback has pushed away the
pole from the proximity of the origin and consequently has increased the 3-dB bandwidth
to 100 kHz. The price is a reduction of the passband gain from 106 dB to 20 dB. Note
that the gain-bandwidth product (GBP = DC gain × bandwidth = 10 × 105 = 106)
remains at 1 MHz, the same as in the open-loop conﬁguration.
Summary
The gain-bandwidth product of the ampliﬁers in Examples 9.45 and 9.46 remained the
same under open-loop and closed-loop conditions. The closed-loop system traded the
gain for higher bandwidth. These effects can be summarized as shown in the following:
Open-loop system:
A(ω) =
a0
1 + j( ω
ω0 ), GB Po = a0ω0
Closed-loop system:
H(ω) =
A(ω)
1 + β A(ω) =
ac
1 + j( ω
ωc )
ac =
a0
1 + βa0
, ωc = (1 + βa0)ω0,
GB Pc = acωc = a0ω0 = GB Po
Feedback: Effect on Time Response
By modifying the pole-zero conﬁguration, negative feedback can shape a system’s step
response toward a desired form. The following example shows how feedback reduces
the time constant and rise time.
Example
9.47
Find, plot, examine, and compare the step responses of a 741 op-amp in open-loop
(Figure 9.41a), and closed-loop (Figure 9.40a) conﬁgurations.
Open-loop
The 741 op-amp is modeled by the system function
A(s) = V2
V1
=
a0
1 + ( s
ω0 ),
where a0 = 2 × 105 and ω0 = 10π rad/s (corresponding to 5 Hz).

576
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Its response to a 5 µV step input voltage is an exponential function
g(t)openloop = (1 −e−t/τ0)u(t)
going from 0 to a ﬁnal steady-state value of 1 volt with a time constant of τ0 =
1/(10π) ≈31.8 msec. The 50% delay and the 10% to 90% rise time in the step
response are measured from the plot (generated by Matlab). They are 22 msec, and
70 msec, respectively. These are called the open-loop speciﬁcations.
Closed-loop
The 741 is conﬁgured as in Figure 9.40(a) with a resistive feedback to its inverting
input. The closed-loop system function was earlier found to be
H(s) =
A(s)
1 + β A(s) ≈
a1
1 + ( s
ω1 ), where a1 = 1
β
and ω1 = a0βω0
As an example, let R1 = 1 K and R2 = 9 K. Then β = 0.1 and the closed-loop
speciﬁcations become
System function:
H(s) =
10
1 + ( s
ω1 )
ω1 = 200,000π
Response to a 100-mV step:
g(t)closedloop = (1 −e−t/τ1)u(t),
where τ1 = 1/(200,000π) = 1.59µs
The 50% delay in the closed-loop step response is now 1.1 µsec. Similarly, the 10%
to 90% rise time is 3.5 µsec. These constitute speciﬁcations of the closed-loop circuit
and are in agreement with theoretical expectations from the feedback. The delay and
rise time in the step response are reduced by a factor of 20,000. The feedback reduced
the DC gain and increased the bandwidth by that factor.
Feedback: Effect on Pole-Zero Configuration
A control system is made of a sensor in the feedback path and a controller in the
forward path, as shown in Figure 9.38. Using these elements one can modify the
pole-zero conﬁguration of the system. This will change the system’s response in both
time and frequency domains. [In the time domain, the aim may be to shape the step
response toward a desired form; (e.g., reduce oscillations and rise time, and eliminate
overshoot.)] The following example shows the use of a controller to eliminate a 60%
overshoot in the step response of a system.
Example
9.48
Consider the system
A(s) = Y(s)
X(s) =
177
s2 + 4.25s + 177
a.
Find and plot its poles and unit-step response. Verify that the step response has
a 60% overshoot.

Signals and Systems
577
b.
To reduce the rise time and the overshoot, it is recommended that we place the
system in the feedback control loop of Figure 9.37 containing the PID controller
C(s) = kp + ki
s + kds
where kp, ki, and kd are constants called controller parameters. Using an
approach of your choice, determine the controller parameters such that the
overshoot/undershoot of the unit-step response and its rise time are reduced,
making it closer to a step. Suggestion: Start with kp = 4.1, ki = 3.8, and
kd = 1.5.13
c.
Improve the controller by ﬁne-tuning it.
Solution
a.
Poles are found from
s2 + 4.5s + 177 = 0, p1,2 = −2.25 ± j13.11 =
√
177e± j99.73◦
The poles are at an angle close to the jω axis, giving rise to a 60% overshoot in
the system’s unit-step response. The poles and the unit-step response of the
open-loop system are shown in Figure 9.43(a). The 60% overshoot is seen and
measured in the ﬁgure.
b.
We start with the suggested controller C1(s), resulting in the closed-loop
system function H1(s).
C1(s) = 4.1 + 3.8
s
+ 1.5s = 1.5s2 + 4.1s + 3.8
s
H1(s) =
C1(s)A(s)
1 + C1(s)A(s) =
265.5s2 + 725.7s + 672.6
s3 + 269.75s2 + 902.7s + 672.6
The closed-loop system has three negative real poles at −266.37, −2.26, and
−1.11, a pair of complex conjugate zeros at −1.37 ± j0.82, and a unity DC
gain. The pole-zero conﬁguration and the step response of the closed-loop
system are shown in Figure 9.43(b). The rise time in the step response is greatly
reduced and the overshoot is totally eliminated. An undershoot of about 15% is
present.
c.
To reduce deviations of the step response from the step function, we ﬁne-tune
the controller by trial and error and choose the following controller which
results in the closed-loop system function given below.
C2(s) = 200 + 200
s
+ 20s = 20s2 + 10s + 10
s
H2(s) =
C2(s)A(s)
1 + C2(s)A(s) = 3540
s2 + 10s + 10
s3 + 3,544s2 + 35,577s + 35,400
13See some papers on PID controller design, for example, those by Ziegler, Nichols, and Phillips.

578
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
−15
−10
−5
0
5
10
15
Imaginary
0
0.5
1
1.5
2
2.5
3
0
0.6
0.8
1
1.2
1.4
1.6
Time (s)
0
0.5
1
1.5
2
2.5
3
Time (s)
Amplitude
−3
−2.5
−2
−1.5
−1
−0.5
0
−1
−0.8
−0.4
0
0.4
0.8
1
Real
−3
−2.5
−2
−1.5
−1
−0.5
0
Real
Imaginary
0
0.8
0.9
1
Amplitude
(a)
(b) 
Open-loop pole-zero plot
Open-loop unit-step response
PID1: Closed-loop pole-zero plot
PID1: Closed-loop unit-step response
FIGURE 9.43 (a) The poles of A(s) = 177/(s2 + 4.25s + 177) at −2.125 ± j13.13 produce a 60% overshoot
in its step response.
(b)
With
PID1
controller
C1(s)
=
4.1 + 3.8/s + 1.5s
(Figure
9.37)
the
closed-loop
system
function becomes
H1(s) =
C1(s)A(s)
1 + C1(s)A(s) =
265.5s2 + 725.7s + 672.6
s3 + 269.75s2 + 902.7s + 672.6
with poles at −266.37, −2.26, −1.11, and zeros at −1.37 ± j0.82, with a reduced rise time and ≈
15%
undershoot.
The closed-loop system has three negative real poles at −3,534.2, −8.9, −1.1 , two
negative real zeros at −8.873, −1.127, and a unity DC gain. The pole at −3,534.2 is
far away from the origin and has very small effect on the system’s step response (except
at near transition time t = 0 where very high frequencies are developed). The other two
poles at 8.9 and −1.1 are nearly cancelled by the system’s zeros at −8.873 and −1.127.
This makes the unit-step response very close to a unit step, within a deviation limited

Signals and Systems         579
0
0.5
1
1.5
2
2.5
3
Time (s)
−1.13 
−1.12 
−1.11 
−1.1
−0.1
0
0.1
Real
Imaginary
0.99
0.996
0.998
1
1.002
1.01
Amplitude
(c) 
PID2: Closed-loop pole-zero plot 
PID2: Closed-loop unit-step response
FIGURE 9.43 (c) Fine-tuning the controller to PID2 with C2(s) = 200 + 200
s + 20s results in
H2(s) =
C2(s)A(s)
1 + C2(s)A(s) = 3,540
s2 + 10s + 10
s3 + 3,544s2 + 35,577s + 35,400
with poles at −3534.2, −8.9, −1.1, and zeros at −8.873, −1.127, which nearly cancel two of the poles. With the
third pole being far away, the step response becomes a step within a deviation of ±0.3%. See Example 9.48.
to ±0.3%. The pole-zero conﬁguration and the step response of the closed-loop
system with the above controller are shown in Figure 9.43(c).
9.29 Pole-Zero Cancellation
In combining two or more systems, a pole may be removed due to introduction of a zero. 
This is called pole-zero cancellation. A simple example is to place a system (s−s0)H1(s) 
in series with another system H2(s)/(s − s0). The ﬁrst system has a zero and the second 
system has a pole at s0. The system function of their cascaded combination is
H(s) = (s −s0)H1(s) × H2(s)
s −s0
= H1(s) × H2(s)
The zero and the pole at s0 have cancelled each other. This phenomenon may be shown
both in the time and s-domains, as illustrated in Examples 9.49 and 9.50.
Example
9.49
Pole-zero cancellation in an input impedance
a. 
Apply a unit-step voltage to the terminals of the circuit of Figure 9.44(a) and
ﬁnd the currents in the inductor, the capacitor, and the total current entering the 
circuit.

580
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
b.
Find conditions that the circuit elements must satisfy for the total current to be a
step function.
c.
Show that under the conditions found in part b, the circuit performs as a resistor
for all frequencies. Find the equivalent resistor.
(b)
(a)
v0
+
+
–
–
v2
+
–
R1
C1
C2
R2
v1
R1
R2
L
C
i
i1
i2
+
–
FIGURE 9.44 Pole-zero cancellation. (a) From its terminals the circuit appears as a resistor at all frequencies if R1 =
R2 =

L
C = R. Then Z = R. See Example 9.49. (b) The circuit functions as a resistive voltage divider at all frequencies
if R1C1 = R2C2. Then v2 = R2v0/(R1 + R2). See Example 9.50.
Solution
a.
The time constants of the capacitive and the inductive branches of the circuit
are, R1C and L/R2, respectively. The responses of the circuit to an applied
unit-step voltage are
i1 = 1
R1
e−
t
R1C u(t)
i2 = 1
R2

1 −e−R2
L t
u(t)
i = i1 + i2 = 1
R1
e−
t
R1C u(t) + 1
R2

1 −e−R2
L t
u(t)
b.
For the total current to be a unit-step function one needs

R1 = R2
R1C = L/R2
⇒
R1 = R2 =

L
C
c.
Using the impedance (or admittance) concept in the s-domain we can write
Impedance of the series RC branch
Z1 = R1 + 1
Cs = R1Cs + 1
Cs
Impedance of the series RL branch
Z2 = R2 + Ls
Admittance of the RC and RL
Y = 1
Z1
+ 1
Z2
=
Cs
R1Cs + 1 +
1
R2 + Ls
branches in parallel:
Y = 1
R1
×
LCs2 + (R1 + R2)Cs + 1
LCs2 + (R2C + L/R1)s + R2/R1

Signals and Systems
581
For Y to be a constant, the numerator should cancel the denominator. This happens
when

R1 = R2
(R1 + R2)C = R2C + L/R1
⇒
R1 = R2 =

L
C
In summary, the following conditions on element values make the two-terminal circuit
equivalent to a resistor at all frequencies.
R1 = R2 =

L
C = RZ = R
Example
9.50
Pole-zero cancellation in transfer functions
In the circuit of Figure 9.44(b) obtain the system functions V1/V0 and V2/V0, where v0
is the input, and v1 and v2 are two outputs. Find condition(s) that the circuit elements
must satisfy to make v1(t) = αv0(t) and v2(t) = βv0(t) for any arbitrary input.
Then ﬁnd α and β. Show that under those conditions the circuit behaves as a resistive
voltage divider for all frequencies.
Solution
We ﬁnd V1/V0 and V2/V0 from voltage division in the complex frequency domain
Z1 =
R1
1 + R1C1s
and
Z2 =
R2
1 + R2C2s
V1
V0
=
Z1
Z1 + Z2
=
R1(1 + R2C2s)
R1(1 + R2C2s) + R2(1 + R1C1s) =
R1(1 + τ2s)
R1(1 + τ2s) + R2(1 + τ1s)
V2
V0
=
Z2
Z1 + Z2
=
R2(1 + R1C1s)
R1(1 + R2C2s) + R2(1 + R1C1s)) =
R2(1 + τ1s)
R1(1 + τ2s) + R2(1 + τ1s)
where τ1 = R1C1 and τ2 = R2C2 are time constants of Z1 and Z2, respectively. For
v1(t) = αv0(t) and v2(t) = βv0(t), we need τ1 = τ2 and
R1C1 = R2C2
V1
V0
= α =
R1
R1 + R2
V2
V0
= β =
R2
R1 + R2
Note that α + β = 1 or, equivalently, v1(t) + v2(t) = v0(t).

582
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
9.30
Inverse Systems
Let a signal x(t) pass through a system with the unit-impulse response h(t), producing
the output y(t) = x(t)⋆h(t). Passing y(t) through a second system with the unit-impulse
response ˆh(t), such that h(t) ⋆ˆh(t) = δ(t), will reverse the effect of the ﬁrst system
resulting in the output x(t):
y(t) ⋆ˆh(t) = [x(t) ⋆h(t)] ⋆ˆh(t) = x(t) ⋆[h(t) ⋆ˆh(t)] = x(t) ⋆δ(t) = x(t)
See Figure 9.45. The two systems are said to be inverses of each other. In a sense, the
inverse system performs a deconvolution of x(t) and h(t). If the two systems are causal,
their system functions will be H(s) and 1/H(s), respectively. Then
H(s) ×
1
H(s) = 1
which correspondes to the overall unit-impulse response δ(t). In summary
h(t)
⇐⇒
H(s)
ˆh(t)
⇐⇒
1
H(s)
h(t) ⋆ˆh(t) = δ(t) ⇐⇒H(s) ×
1
H(s) = 1
X(s)
X(s)
System
Inverse system
Input
Output
X(s) H(s)
H(s)
1
H(s)
FIGURE 9.45 Two systems h(t) and ˆh(t) are inverses of each other if h(t) ⋆ˆh(t) = δ(t). One
system reverses the effect of the other. For causal systems this translates into system functions
H(s) and 1/H(s), respectively.
Example
9.51
The series CR in section a of Figure 9.46 with C = 1 µF and R = 1 M is a high-pass
ﬁlter. Apply an input voltage to it. The ﬁlter’s output is the voltage across the resistor.
Connect an inverse ﬁlter in series with the above to reverse its effect and determine
its element values.
Solution
The unit-impulse response and system functions of the high-pass and inverse ﬁlters
are
h(t) = δ(t) −e−tu(t)
⇒
H(s) = 1 −
1
s+1 =
s
s+1
⇓
⇓
⇓
ˆh(t) = δ(t) + u(t)
⇐
1
H(s) = 1 + 1
s

Signals and Systems
583
The inverse ﬁlter is realized in section c of Figure 9.46. It ampliﬁes, with an
appropriate gain, the low-frequency components of the signal which were attenuated
by the high-pass ﬁlter. Note that in the time domain we conﬁrm the same result as in
the frequency domain.
h(t) ⋆ˆh(t) =

δ(t) −e−tu(t)

⋆[δ(t) + u(t)]
= δ(t) ⋆[δ(t) + u(t)] −e−tu(t) ⋆[δ(t) + u(t)]
= δ(t) + u(t) −e−tu(t) + e−tu(t) ⋆u(t)
= δ(t) + u(t) −e−tu(t) + e−tu(t) −u(t)
= δ(t)
The cascade of the high-pass ﬁlter and its inverse is shown in Figure 9.46. The voltage
follower between the high-pass RC ﬁlter and its inverse acts as a buffer.
+
–
+
–
V2
V2
V1
R
C
C
C
R
V3 = – V1
(b) Buffer
(a) High-pass filter
(c) Inverse of high-pass filter
FIGURE 9.46 A high-pass CR ﬁlter with the system function H(s) = s/(s+α) (shown
in section a) is cascaded with its inverse with the system function 1/H(s) = 1 + α/s
(section c). The voltage follower (section b) provides a no-load buffer between the ﬁlter
and its inverse.
Example
9.52
A ﬁrst-order active low-pass ﬁlter (with time constant τ = RC) is cascaded with its
inverse. See Figure 9.47. Show that the overall system function is 1.
+
–
v2
v1
1
(a) Low-pass filter
(b) Inverse filter
+
–
2
v1
C
R
R
R
C
R
FIGURE 9.47 An active low-pass ﬁlter with the system function H1(s) = −1/(s +
α) (shown in section a) is cascaded with its inverse H2(s) = 1/H1(s) = −(s + α)
(section b). The overall system function is H(s) = H1(s) × H2(s) = 1.

584
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Solution
The op-amps are conﬁgured in inverting circuit conﬁguration. Their system functions
and the overall system functions are
H1(s) =
−1
s + α , where α =
1
RC = 1
τ
H2(s) = −(s + α)
H(s) = H1(s) × H2(s) =
 −1
s + α

× [−(s + α)] = 1
Seealsodiscussionsondeconvolutionandinversesystemsinthediscrete-timesystems.
9.31
Concluding Remarks
Performance of an LTI system may be analyzed in the time domain (using its unit-
impulse response, unit-step response, convolution, and the differential equation). The
analysis may also be done in the frequency domain (using the Laplace transform, system
function, and the frequency response). This chapter highlighted the relationship between
the above methods, emphasized the role of poles and zeros in building bridges between
them, and integrated those analysis methods. In addition to quantitative methods, the
chapter also provided some qualitative insights into the methods of analysis and design.
It presents a capstone chapter for several topics of interest in system analysis.
9.32
Problems
Solved Problems
1. In the circuit of Figure 9.48(a), R = 1 k, L = 1 H, and C = 1,000 µF.
a. Verify that the system function is
H(s) = V2
V1
=
s
s2 + s + 1,000
b. Plot the Bode diagram.
c. Let v1(t) be a 5-Hz periodic square pulse with a base-to-peak value of 1 V. Using the Bode diagram ﬁnd the
average power in v2(t) within the band of f < 30 Hz.
Solution
Assume x(t) = v1(t) is the input to the system and y(t) = v2(t) the output.
a.
H(s) = V2
V1
=
Z LC
R + Z LC
Z LC =
1
Cs + 1/(Ls) =
Ls
1 + LCs2
H(s) =
Ls
R(1 + LCs2) + Ls =
1
RC
s
s2 +
1
RC s +
1
LC
RC = 1, LC = 10−3
H(s) =
s
s2 + s + 1,000

Signals and Systems
585
−60
−50
−40
−30
−20
−10
0
10
Magnitude (dB)
100
101
102
103
Angular frequency (rad/s)
(b)
Phase (degrees)
−100
−50
0
50
100
100
101
102
103
Angular frequency (rad/s)
(c)
(a)
+
–
V1
+
–
V2
+
–
L
R
C
FIGURE 9.48 A narrowband RLC bandpass ﬁlter and its frequency characteristics. (a) The circuit. (b) Magnitude plot.
(c) Phase plot. The high Q = 31.6 results in a narrowband f = 0.159 Hz centered at f0 = 5.033 Hz. The ﬁlter is not
exactly tuned to the frequency of a 5-Hz square wave. The narrow bandwidth attenuates the principal harmonic of the
square wave input, hence reducing average power in v2(t).
b. H(ω) =
jω
−ω2 + jω + 1,000 =
j
Q ( ω
ω0 )
−( ω
ω0 )2 +
j
Q ( ω
ω0 ) + 1,
where Q = ω0 and ω2
0 = 1,000. Hence, ω0 = 31.62 rad/s or f0 = ω0/(2π) = 5.033 Hz.
The system has a quality factor of Q = √1,000 = 31.62 and a bandwidth of ω =
ω0
Q
= 1 rad/s or
f = 0.159 Hz. The low-frequency asymptote (at ω << ω0) is
20 log |H(ω)| ≈20 log
 ω
ω0

−20 log Q = 20 log
 ω
ω0

−30
The peak value (at ω = ω0) is 20 log |H(ω)| = 0 dB. The high-frequency asymptote (at ω >> ω0) is
20 log |H(ω)| ≈−20 log
 ω
ω0

−20 log Q = −20 log
 ω
ω0

−30
The low- and high-frequency asymptotes have slopes of ±20 dB/decade, respectively. They intercept ω0 at
20 log Q = 30 dB below the peak. The Bode diagram is shown on Figure 9.48.
c. Harmonics of x(t) are at fn = 5n Hz or ωn = 10πn with
Xn =

1
2
n = 0
sin( πn
2 )
πn
n ̸= 0
.
Harmonics of the output y(t) are Yn = Xn H(10πn). They are summarized below along with their power.

586
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
n
0
1
2
3
4
5
6
f (Hz)
0
5
10
15
20
25
30
Xn
1
2
1
π
0
−1
3π
0
1
5π
0
|H| (dB)
−∞
−0.69
−38.45
−43.56
|H| (linear)
0
0.9236
0.0119
0.0066
|Yn| = |Xn| × |H|
0
0.294
0
0.0013
0
0.0004
0
Pn = 2|Yn|2
0
0.17286
0
0.0000034
0
0.00000032
0
P =
5

n=−5
Pn ≈P1 = 0.17286 W
A simplifying approximation of f0 ≈5 Hz would assume 0-dB attenuation at 5 Hz. It would then result in
P ≈2
π 2 = 0.20264, and a percentage error of 20,264 −17,286
17,286
× 100% = 17.23%
The resulting high percentage error is due to the narrow bandwidth of f = 0.159 at f0 = ω0/(2π) = 5.033 Hz.
The Matlab commands given below plot the Bode diagram shown in Figure 9.48.
num=[1 0];
den=[1 1 1000];
sys=tf(num,den)
figure(1)
grid
bode(sys)
title('Bode plot of H= s/(s√2+s+1000)')
2. In the circuit of Figure 9.48(a), R = 1 k, L = 1 H, and C = 250 µF.
a. Verify that the system function is H(s) = V2
V1
=
4s
s2 + 4s + 4,000
b. Write a program to plot the Bode diagram.
c. Let v1(t) be a 10-Hz periodic square pulse with a 1-V base-to-peak value. Using the Bode diagram ﬁnd the
average power in v2(t) within the band of f < 60 Hz. Compare the results with those of problem 1.
Solution
As in problem 1 assume x(t) = v1(t) is the input to the system and y(t) = v2(t) the output.
a. H(s) = V2
V1
=
1
RC
s
s2 +
1
RC s +
1
LC
, RC = 0.25, LC = 0.25 × 10−3. Hence, H(s) =
4s
s2 + 4s + 4,000.
b. H(ω) =
j4ω
−ω2 + j4ω + 4,000 =
j4
ω0
 ω
ω0

− ω
ω0
2 +
j4
ω0
 ω
ω0

+ 1
=
j
Q
 ω
ω0

− ω
ω0
2 +
j
Q
 ω
ω0

+ 1
,
where Q = ω0
4 and ω2
0 = 4,000. Therefore, ω0 = 63.25 rad/s or f0 = ω0/(2π) = 10.066 Hz.
The system has a quality factor of Q = √4,000/4 = 15.81 and a bandwidth of ω =
ω0
Q = 4 rad/s or
f = 0.76 Hz. The low-frequency asymptote (at ω << ω0) is
20 log |H(ω)| ≈20 log
 ω
ω0

−20 log Q = 20 log
 ω
ω0

−23.98

Signals and Systems
587
The peak value (at ω = ω0) is 20 log |H(ω)| = 0 dB. The high-frequency asymptote (at ω >> ω0) is
20 log |H(ω)| ≈−20 log
 ω
ω0

−20 log Q = −20 log
 ω
ω0

−23.98
The low- and high-frequency asymptotes have slopes of ±20 dB/decade, respectively. They intercept ω0 at
20 log Q = 23.98 dB below the peak. The following modiﬁcation in the Matlab program of problem 1 plots the
Bode diagram.
num=[4 0];
den=[1 4 4000];
The plots are similar to the diagram for H(s) = s/(s2 + s + 1,000) (shown in Figure 9.48) in that it shows a
bandpass system with a relatively high Q of 15.81. But it differs from Figure 9.48 in that the location of the peak
is shifted to f0 = 10.066 Hz with a broader bandwidth of f = 0.76 Hz. The effect of the broader bandwidth
will be seen shortly in part c.
c. Harmonics of x(t) are at fn = 10n Hz or ωn = 20πn with
Xn =
 1
2
n = 0
sin( πn
2 )
πn
n ̸= 0
Harmonics of the output y(t) are Yn = Xn H(20πn). They are summarized below along with their power.
n
0
1
2
3
4
5
6
f (Hz)
0
10
20
30
40
50
60
Xn
1
2
1
π
0
−1
3π
0
1
5π
0
|H| (dB)
−∞
−0.1831
−32.4299
−37.5432
|H| (linear)
0
0.9791
0.0239
0.0133
|Yn| = |Xn| × |H|
0
0.3117
0.0000
−0.0025
−0.0000
0.0008
0.0000
Pn = 2|Yn|2
0
0.1943
0.0000
0.0000
0.0000
0.0000
0.0000
P =
5

n=−5
Pn ≈P1 = 0.1943 W
A simplifying approximation of f0 ≈10 Hz would assume 0-dB attenuation at 10 Hz. It would then result in
P ≈2
π 2 = 0.20264, and a percentage error of 20,264 −19,430
19,430
× 100% = 4.2%.
3. In the circuit of Figure 9.49,
a. ﬁnd the system function H(s) = V2
V1
b. determine element values that make it a second-order Butterworth ﬁlter with a 3-dB frequency at 1 kHz.
+
–
V1
+
–
V2
+
–
C
R
L
R
FIGURE 9.49 A passive second-order low-pass ﬁlter.

588
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Solution
a. Z1 = R + Ls
b.
2
LC = ω2
0 = (2π × 103)2
Z2 =
R
1 + RCs
R
L +
1
RC =
√
2ω0 = 2
√
2π × 103
V2
V1
=
Z2
Z2 + Z1
For a Butterworth ﬁlter H(s) = k
ω2
0
s2 +
√
2ω0s + ω2
0
=
R
(R + Ls)(1 + RCs) + R
For example R = 1k
=
1
LC
1
s2 +
	
R
L +
1
RC

s +
2
LC
L = 1/(
√
2π)H ≈225 mH, C = 1/(
√
2π) µF ≈225 nF
Note: The ﬁlter is passive. Its DC gain is −6 dB.
4. Graphing a system’s responses by computer. Qualitatively analyze the following second-order systems. Plot the
pole locations, the frequency response, and the unit-impulse response. (This problem revisits Example 9.19 in this
chapter.)
H1(s) =
1
s2 + 5s + 1 (with ω0 = 1 and Q = 0.2)
H2(s) =
1
s2 + 0.1s + 1 (with ω0 = 1 and Q = 10)
Solution
H1(s) has two negative real poles at −4.7913 and −0.2087. It is heavily overdamped (damping ratio ζ = 2.5). The
unit-impulse response shows no oscillations and the magnitude plot of the frequency response remains below the
DC level at all frequencies. In contrast, H2(s) has two complex conjugate poles at −0.05 ± j0.9987 = e± j116.6◦(at
an angle close to the jω axis). The system is greatly underdamped (damping ratio ζ = 0.05). This is evidenced
by oscillations in its unit-impulse response and also a sharp and selective magnitude response around ω = 1. Pole
plots, Bode plots, and step responses are shown in Figure 9.15. The Matlab program is given below.
t=linspace(0,40,1001);
w=logspace( -2,3,801);
%Second-order with Q=0.2 (overdamped, functions as a lowpass)
num1=[1];
den1=[1 5 1];
[poles1,zeros1]=pzmap(num1,den1)
[mag1,angle1]=Bode(num1,den1,w);
y1 =impulse(num1,den1,t);
%Second-order with Q=10 (underdamped, functions as a bandpass)
num2=[1];
den2=[1
0.1 1];
[poles2,zeros2]=pzmap(num2,den2)
[mag2,angle2]=Bode(num2,den2,w);
y2 =impulse(num2,den2,t);

Signals and Systems
589
%Plots
figure(1)
plot(real(poles1),imag(poles1),'x',real(zeros1),imag(zeros1),'o',...
real(poles2),imag(poles2),'x',real(zeros2),imag(zeros2),'o');
title('Pole-Zero Plot');
xlabel('Real');
ylabel('Imaginary');
axis([-5.1
0.05 -1.1
1.1]);
grid;
figure(2)
semilogx(w,20*log10(mag1),w,20*log10(mag2));
title('Magnitude of Bode Plot');
ylabel('Magnitude (dB)');
xlabel('Angular Frequency (rad/s)');
axis([0.01 100
-80 20]);
grid;
figure(3)
semilogx(w,angle1,w,angle2);
title('Phase of Bode Plot');
xlabel('Angular Frequency (rad/s)');
ylabel('Angle (deg)');
axis([0.01 100
-180
0]);
grid;
figure(4)
plot(t,y1,t,y2);
title('Impulse Response');
xlabel('Time (s)');
ylabel('Amplitude');
grid;
5. From a visual inspection of the Bode diagram plotted for the system
H(s) = 1,000
s + 3
(s + 15)(s + 500)
it may appear that the system function has a ﬂat magnitude and linear phase within the neighborhood of 60 < ω <
100. If the assumption is correct, a signal with frequency components within that neighborhood should experience
only a delay (and no distortion) when it passes through the system. Test the validity of the above assumption by
passing the signal x(t) = cos(20πt)+cos(25πt)+cos(30πt) through the above system and examining the output.
Solution
The sinusoidal input-output relationship is
cos(ωt) ⇒|H(ω)| cos(ωt + θ) = |H(ω)| cos ω(t + τ),
where θ = ̸ H and τ = θ/ω
Values of |H|, ̸ H, and τ are computed for f = 10, 12.5, and 15 Hz and entered in the table below.

590
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
f in Hz
|H|
θ in rad
τ in msec
10 Hz
1.93
0.0616
0.98
12.5 Hz
1.94
−0.0053
−0.067
15 Hz
1.94
−0.0603
−0.64
y(t) ≈1.94 [cos 20π(t + 0.98 msec) + cos 25π(t −0.067 msec) + cos 30π(t −0.64 msec)]
The assumption is, therefore, not true because the three sinusoids experience different delays.
6. The circuit of Figure 9.24(a) is a Sallen-Key low-pass ﬁlter.
a. Show that
V2
V1
=
H0
s2 + ω0
Q s + ω2
0
, where H0 =
k
mnR2C2 , k = 1 + R2
R1
, ω0 =
1
mnRC , and Q =
√mn
1 + m + (1 −k)mn
b. Compare with the equal-component circuit analyzed in Example 9.33.
Solution
a. From voltage division by the R1R2 feedback path we have
VA =
V2
1 + α where α = R2
R1
(1)
From KVL along the path B-A-ground we obtain
VA =
VB
1 + τs , where τ = RC
(2)
By combining (1) and (2) we ﬁnd
VB = 1 + τs
1 + α V2
(3)
Now write KCL at node B and collect terms:
VB

1
m + (1 + nτs) −
1
1 + τs

−V1
m −V2nτs = 0
(4)
Eliminate VB between (3) and (4) to obtain
V2
V1
=
	
1 + α
mnτ 2

1
s2 + 1+m−αmn
mnτ
s +
1
mnτ2
Compare with the low-pass system function
V2
V1
=
H0
s2 + ω0
Q s + ω2
0
to obtain
H0 =
	
1 + α
mnτ 2

, ω0 =
1
√mnτ
and
Q =
√mn
1 + m + −αmn
b. Compared with the equal-component circuit of Example 9.33, the above circuit provides an additional degree
of freedom to control G0, ω0, and Q.

Signals and Systems
591
7. The circuit of Figure 9.26(a) is an inﬁnite gain, multiple-feedback bandpass ﬁlter. In Example 9.35 we considered
the special case of equal-value capacitors. In this problem you will analyze the circuit by allowing for unequal
capacitors. Let R2 = aR1 and C2 = bC1.
a. Show that
H(s) = −H0
s
s2 + ω0
Q s + ω2
0
, where H0 =
1
RC , ω0 =
1
RC
√
ab
, and Q =
√
ab
1 + b
b. Compare with the case of b = 1 analyzed in Example 9.35. Find component values for a bandpass ﬁlter with
Q = 100 at 60 Hz.
Solution
a. Node A is at zero voltage because the noninverting input of the op-amp is grounded. The current in R2 is V2/R2
directed downward toward node A and going through C2 because the op-amp doesn’t draw any current. This
results in
VB = −
V2
R2C2s
Now write KCL at node B 	
V1 +
V2
R2C2s

1
R + V2
R2
+
	
V2 +
V2
R2C2s

C1s = 0
Let R1 = R, R2 = aR, C1 = C, C2 = bC, and collect terms to obtain
V2
V1
=
−RCs
R2C2s2 +  1+b
ab

RCs +
1
ab
, a ≥0, b ≥0
Rewriting it in the familiar form for a bandpass system function results in
H(s) = −H0
s
s2 + ω0
Q s + ω2
0
, where H0 =
1
RC , ω0 =
1
RC
√
ab
, and Q =
√
ab
1 + b
b. It may appear that unequal capacitors provide us with some advantages in choosing component values. This is
not always the case. An example is a bandpass ﬁlter with Q = 100 at 60 Hz. In order to minimize a we need to
choose b = 1 which results in a = 40,000 and RC = 13,263×10−9. We can choose C = 1 µF, R1 = 13.263 ,
and R2 = 530.5 k. But another choice is C = 100 nF, R1 = 132.63 , and R2 = 5.3 M.
8. Write and execute a Matlab program to plot the Bode diagrams for
H(s) =
s2 −1
s2 + 1
Q s + 1, Q = 0.01, 0.05, 0.2, 0.5,
√
2/2, 1, 2, 5, 10, 50
Explain the shape of the plots in terms of interconnection of two subsystems.
Solution
The following Matlab program superimposes the Bode plots for the given values of Q. The system function is
H = Hhp −Hℓp where Hhp and Hℓp are high-pass and low-pass second-order ﬁlters, respectively, having the same
quality factor and ω0 = 1 rad/s.
w=logspace(-2,3,801);
Q=[0.01 0.05 0.2 0.5
0.7 1 2 5 10 50];
num=[1 0 -1]; hold on
for i=1:10;
den=[1 1/Q(i) 1];

592
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Bode(num,den,w);
end
title('Bode Plots for H(s)=(s√2-1)/(s√2+s/Q+1), Q=.01, .05, .2, .5, .7,
1, 2, 5, 10, 50');
grid; hold off
9. A two-dimensional ultrasonic-sound-emitting device is composed of four transmitters placed in a two-dimensional
plane and operates at 30 kHz. Each transmitter receives a 30-kHz signal phase-shifted by θi, i = 0, 1, 2, 3.
The ﬁrst-order phase shifter circuit of Figure 9.20(b) is used to produce the shifts. Find the values of R and C
corresponding to the following shifts: 0, 105◦, 150◦, 175◦.
Solution
The system function and frequency response of the circuit of Figure 9.20(b) are
H(s) = 1 −RCs
1 + RCs , H( f ) = e−jθ, θ = 2 tan−1(2π f RC)
At f = 30 kHz RC =
1
2π f tan θ
2

= 530.5 × 10−8 tan θ
2

θ1 = 105◦, RC = 530.5 × 10−8 tan 52.5◦= 691 × 10−8, C = 10 nF, R = 691 
θ1 = 150◦, RC = 530.5 × 10−8 tan 75◦= 1980 × 10−8, C = 10 nF, R = 1, 980 
θ1 = 175◦, RC = 530.5 × 10−8 tan 87.5◦= 12150 × 10−8, C = 10 nF, R = 12, 150 
10. Proof of phase lead and lag location and its value by analytical approach.
a. Express the phase of the lead network of Figure 9.21(a) in one or more analytical forms.
b. Show that maximum value of the phase is 90◦−2 tan−1 √α at ωm = ω1/√α.
Solution
a. The system function is
H(s) = α
1 +
s
ω1
1 + α s
ω1
Without loss of generality (and for convenience), we work with the following normalized frequency response in
which the variable s represents s/ω0 for the ﬁlter of Figure 9.21(a).
H(s) = α 1 + s
1 + αs
H(ω) = α 1 + jω
1 + jαω = |H(ω)|e jθ
θ = θ1 −θ2, where θ1 = tan−1(ω) and θ2 = tan−1(αω)
But
tan θ = tan(θ1 −θ2) = tan θ1 −tan θ2
1 + tan θ1 tan θ2
Therefore,
tan θ = (1 −α)ω
1 + αω2
b. To obtain some insight into the variation of θ we need to look at its derivative with respect to ω. And to search
for the possible occurrence of a maximum value for θ we need to ﬁnd out if the derivative can be set to zero.

Signals and Systems
593
Sine tan θ is a monotonically increasing function of θ we start with its derivative with respect to ω.
d
dω (tan θ) = d
dω

(1 −α)ω
1 + αω2

=
1 −αω2
(1 + αω2)2
But
d
dω (tan θ) = d
dθ (tan θ) dθ
dω
and
d
dθ (tan θ) =
1
cos2 θ ̸= 0
Therefore, when
1 −αω2 = 0, or ω =
1
√α ,
then
dθ
dω = 0.
At that point
tan(θM) = 1
2

1
√α −√α

Alternatively,
θ = tan−1(ω) −tan−1(αω)
At the maximum
θM = tan−1
	
1
√α

−tan−1(√α)
But
tan−1
	
1
√α

= cot−1(√α) = 90◦−tan−1(√α)
Therefore,
θM = 90◦−2 tan−1(√α)
Denormalization brings the frequency of θM back at ωm = ω1/√α.
Yet Another Form
The maximum phase for the circuit of Figure 9.21(a) is equivalently speciﬁed by the following expression (see
problem 46 in this chapter):
sin(θM) = 1 −α
1 + α
To show the equivalence of the above expression with the previously derived ones, we note that:
cos(θM) = 2√α
1 + α ,
tan(θM) = 1 −α
2√α = 1
2

1
√α −√α


594
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
11. The frequency response of a ﬁrst-order low-pass ﬁlter is H( f ) = 1/(1 + j2πτ f ), where τ is the time constant of
the ﬁlter. Find the group and phase delays of the ﬁlter at the following frequencies and evaluate them for τ = 1
msec.
a. fa = 0.1
2πτ
b. fb =
1
2πτ
c. fc = 10
2πτ
Solution
θ = −tan−1(2π f τ),
dθ
d f = −
2πτ
1 + (2π f τ)2
tp = −θ
2π f = tan−1(2π f τ)
2π f
,
tg = −1
2π
dθ
d f =
τ
1 + (2π f τ)2
a. 2π faτ = 0.1
tp = tan−1(0.1)
0.1
τ ≈τ,
tg =
τ
1 + 0.01 ≈τ
b. 2π fbτ = 1
tp = π
4 τ ≈0.785τ,
tg = 0.5τ
c. 2π fcτ = 10
tp = tan−1(10)
10
τ ≈0.147τ,
tg =
τ
1 + 100 ≈0.01τ
Both delays decrease with frequency, but the group delay decreases faster than the phase delay. For a system with
a 1-msec. time constant, the delays are
a. fa ≈15.91 Hz
tp ≈1 msec
tg ≈1 msec
b. fb ≈159.1 Hz
tp = 785 µs
tg = 785 µs
c. fb ≈1,591 Hz
tp ≈147 µs
tg ≈10 µs
12. Let a narrowband signal x(t) = a(t) cos(2π f0t) with frequencies in the neighborhood of f0 pass through a ﬁlter
with the known frequency response H( f ) = |H( f )|e jθ( f ). Express y(t) in terms of x(t), tg, and tp.
Solution
The Fourier transform of x(t) is
X( f ) = A( f + f0) + A( f −f0)
2
Assume that within the signal’s bandwidth the frequency response is smooth enough so that |H( f )| may be
considered a constant and θ( f ) can be approximated by its ﬁrst-order Taylor series expansion.
|H( f )| ≈|H( f0)| = H0, θ( f ) = θ0 + θ ′
0( f −f0) where θ0 = θ( f0) and θ ′
0 = dθ( f )
d f

f = f0
The output of the ﬁlter is
Y( f ) = X( f )H( f ) ≈A( f + f0) + A( f −f0)
2
H0e jθ0+ jθ′
0( f −f0) = H0
A( f + f0) + A( f −f0)
2
e j(θ0−θ′
0 f0)e jθ′
0 f
Substituting for θ ′
0 = 2πtg and θ0 = 2π f0tp we obtain
Y( f ) = H0
A( f + f0) + A( f −f0)
2
e j2π f tge j2π f0(tp−tg), y(t) = H0a(t −tg) cos
2π f0(t −tp)

Signals and Systems
595
13. Feedback. The block diagram of a system is shown in Figure 9.50(a).
a. Determine the system function H1 = Y/X and ﬁnd the DC gain.
b. A disturbance w arrives at the system as shown in Figure 9.50(b). Find the overall system function that includes
the contributions from x and w. Note that Y = H1X + H2W. Then, with x and w assumed to be constants, ﬁnd
y as a function of w. Plot y versus w for x = 1, 2, 3, 4, and 5.
c. In order to reduce the effect of w on y, a feedback path β and an ampliﬁer k are added to the system as shown
in Figure 9.50(c). Find the new system function. Suggest values for β and k to demonstrate the new system can
reduce the effect of w. Then, plot the output y as a function of w.
d. Choose β and k in Figure 9.50(c) so that the effect of w on y is reduced by a factor of 0.02 compared to
Figure 9.50(b).
x
e
y
Σ
10
0.9
1/(1 + 3s)
(a)
+
–
x
w
e
y
Σ
10
0.9
1/(1 + 3s)
(b)
+
–
Σ
–
+
x
y
Σ
k
10
b
0.9
1/(1 + 3s)
(c)
+
–
Σ
+
–
w
Σ
+
–
w
y
(d)
5
4
3
2
1
10
20
30
40
50
x = 5
1
2
3
4
w
y
(e)
x0
0
100 x0
x = x0
FIGURE 9.50
Solution
a. H1(s) =
10
1+3s
1 +
9
1+3s
=
10
10 + 3s . DC gain = H(0) = 1.
b. With w = 0, the system is reduced back to Figure 9.50(a) for which we have found H1(s) = 10/10 + 3s. With
x = 0, the system will be reduced to a forward path of 1/(1 + 3s) and a negative feedback path of 9. Due to the

596
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
negative sign on the arrival point of w, the system function relating y to w becomes
H2(s) = Y(s)
W(s) = −
1
1+3s
1 +
9
1+3s
= −
1
10 + 3s
With both x and w present, the output is
Y(s) = H1(s)X(s) + H2(s)W(s) =
10
10 + 3s X(s) −
1
10 + 3s W(s)
At the DC steady state, s = 0 and, with both x and w being constants, we get y = x −1
10w [see Figure 9.50(d)].
c. The system function in Figure 9.50(c) is easily obtained as
Y(s) =
k
1 + βk X(s) −
1
10(1 + βk) W(s)
In the DC steady state:
y =
k
1 + βk x −
1
10(1 + βk)w
To keep a unity gain from x to y [as in the system of Figure 9.50(a)], let k/(1 + βk) = 1, which results in
k = 1/(1 −β). As long as βk > 1, the effect of the disturbance in Figure 9.50(c) compared to Figure 9.50(b)
is reduced. As an example, let βk = 9, k = 10, and β = 0.9. Then, at the DC steady state y = x −0.01w. See
Figure 9.50(e).
d.
1
10(1+βk)
0.1
=
1
1 + βk = 0.02, βk = 49. With
k
1 + βk = 1, we get k = 1+βk = 1+49 = 50 and β = 49
50 = 0.98.
Chapter Problems
Note: In the following problems circuit elements have constant values, unless speciﬁed otherwise.
14. In the series RLC circuit of Figure 9.51(a) L = 1 mH, C = 100 nF, vs(t) is the input and element voltages v1(t),
v2(t), and v3(t) (across R, L, and C, respectively) are the outputs.
a. Sketch by hand, in the form of Bode diagram, the magnitude and phase of three system functions
H1(s) = V1
Vs
,
H2(s) = V2
Vs
,
H3(s) = V3
Vs
for each of the following three cases
i) R = 2 k,
ii) R = 200 ,
iii) R = 20 
b. Repeat part a using a computer. Compare with the hand plots.
+
(a) For Problem 14
(b) For Problem 15
–
i
vs
+
–
vC
+
–
vR
+
–
vL
+
–
is
+
–
vC
vR
+
–
vL
FIGURE 9.51 Two circuits whose system functions have the same set of poles.
15. (a) In the series RLC circuit connect a current source is(t) in parallel with the resistor as shown in Figure 9.51(b) and
consider it to be the input. Let an element’s current or voltage be the output (six possible outputs). Apply element

Signals and Systems
597
values given in problem 14 and use a computer to plot the Bode diagram for each system function representing an
input-output pair. Examine the plots and relate your observations to the results of problem 14. (b) Place the input
current source in parallel with the inductor and repeat part a. (c) Place the input voltage source in parallel with the
capacitor and repeat part a.
16. In the parallel RLC circuit of Figure 9.52(a) L = 1 mH, C = 100 nF, is(t) is the input and the element currents
i1(t), i2(t), and i3(t) (in the resistor, inductor, and the capacitor, respectively) are the outputs.
a. Sketch by hand, in the form of Bode diagram, the magnitude and phase of three system functions
H1(s) = I1
Is
, H2(s) = I2
Is
, H3(s) = I3
Is
for each of the following three cases
i) R = 5 , ii) R = 50 , iii) R = 500 
b. Repeat part a using a computer. Compare with the hand plots.
(c) For Problem 18
+
–
v1
+
–
v2
L
i
R
C
(a) For Problem 16
+
+
–
–
+
–
is
i1
i1
i2
i2
v
i3
i3
(b) For Problem 17
vs
FIGURE 9.52 Three circuits whose system functions have the same set of poles.
17. (a) In the parallel RLC circuit connect a voltage source vs(t) in series with the resistor as shown in in of Figure
9.52(b) and consider it to be the input. Let an element’s current or voltage be the output (six possible outputs).
Apply element values given in problem 16 and use a computer to plot the Bode digram for each system function
representing an input-output pair. Examine the plots and relate your observations to the results of problem 16.
(b) Place the input voltage source in series with the inductor and repeat part (a). (c) Place the input voltage source
in series with the capacitor and repeat part a.
18. Consider the circuit of Figure 9.52(c) with R = 500 , L = 1 mH, and C = 10 µF. (a) Plot, by hand, the
magnitude and phase of the system function H(s) = V2/V1 in the form of Bode diagram. (b) The steady-state
response of the circuit to v1(t) = cos(ωt) is v2(t) = A cos(ωt −θ). Using the Bode plot estimate A and θ for
ω = 103, 5 × 103, 104, 2 × 104, and 105, all in rad/s and compare with actual values obtained from the system
function.
19. The only poles of an LTI system are at −1± j. The system has no zeros at ﬁnite values of s. Its steady-state response
to a unit-step input is 5.
a. Find the system function H(s) and plot its Bode diagram.
b. The response of the system to the input cos
√
2t is A cos(
√
2t −θ). Find A and θ.
c. Move the poles to new locations p1,2 = 2e± jφ while the DC steady-state response to unit step remains unchanged.
The response of the new system to the input cos ωt is A cos(ωt −θ), where A and θ are functions of ω. Choose
φ so that A attains its maximum of 14 dB at ω =
√
2. Then repeat part a.
20. a. A system H1(s) has a pair of poles at −1.25 ± j50, a zero at the origin, and |H1(ω)|Max = 1. Plot its magnitude
and phase and ﬁnd its −3 dB-band.

598
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
b. Another system H2(s) has two pairs of poles at −1.25 ± j49 and −1.25 ± j51, a double zero at the origin, and
|H2(ω)|Max = 1. Plot its magnitude and phase and ﬁnd its −3-dB band.
c. Compare H1(ω) and H2(ω) in the neighborhood of ω = 50.
21. a. A second-order bandpass system H1(s) has a zero at the origin, Q = 20, ω0 = 50, and |H1(ω)|Max = 1.
Determine its pole locations at −σ ± jωd, where ω2
0 = σ 2 +ω2
d. Plot its magnitude and phase and ﬁnd its −3-dB
band.
b. A fourth-order system H2(s) is constructed by cascading two second-order systems of the type in part a. but
with ω0 = 49 and ω0 = 51, respectively. Plot its magnitude and phase and ﬁnd its −3-dB band.
c. Compare H1(ω) and H2(ω) in the neighborhood of ω = 50.
22. Sketch the magnitude and phase of the frequency response of the following systems in the form of Bode plots.
a. H(s) =
s + 3
(s + 15)(s + 500)
b. H(s) =
100(s + 15)
(s + 3)(s + 500)
c. H(s) =
10(s + 15)
(s + 30)(s + 500)
23. For each system given below sketch the magnitude and phase of H(ω) in the form of Bode plots and estimate their
values at ω = 100, 200, 300, and 1,000. Compare with calculated values.
a. H(s) =
s + 1
(s + 15)(s + 100)
b. H(s) =
2,000(s + 1)
(s + 20)(s + 100)
c. H(s) =
20(s + 50)
(s + 10)(s + 100)
24. The unit-step response of an LTI system is (1 + e−2t)u(t). Find its system function and plot its Bode diagram.
25. Consider a ﬁrst LTI system with the unit-step response h1(t) = (1 + e−2t)u(t) and a second LTI system with the
unit-impulse response h2(t) = e−tu(t).
a. Find their system functions H1(s) and H2(s), their poles and zeros, and plot their frequency responses.
b. Place the two systems in cascade form, then ﬁnd the overall system function, its poles and zeros and frequency
response. Relate them to those of systems H1(s) and H2(s).
c. Discuss possible differences between the H1H2 and H2H1 conﬁgurations.
26. Given the system function
H(s) = 5
s + 20
s2 + 2s + 100
a. Find its poles and zeros.
b. Sketch the Bode plot of the frequency response H(ω).
c. Find and plot its unit-step response.
d. Examine the shape of the step response and relate its important characteristics to the frequency response.
27. Using a computer calculate the table entries in the solutions for problems 1 and 2.
28. Plot the magnitude and phase of the system H(s) = 50(s + 10)/(s + 1)(s + 200) using the following three Matlab
programs. Discuss advantages or shortcomings of each program.

Signals and Systems
599
%C9P28a.m
w=linspace(0.1,1000,10001);
s=i*w; H=50*(s+10)./((s+1).*(s+200));
mag=abs(H); phase=((atan(w/10)-atan(w)-atan(w/200))*180/pi;
figure(1); plot(log10(w),20*log10(mag)); grid
figure(2); plot(log10(w),phase); grid
%C9P28b.m
w=logspace(-1,3,10001);
s=j*w; H=50*(s+10)./((s+1).*(s+200));
mag=abs(H); phase=(atan(w/10)-atan(w)-atan(w/200))*180/pi;
figure(1); semilogx(w,20*log10(mag)); axis([0.1 1000 -30 10]); grid;
figure(2); semilogx(w,phase); axis([0.1 1000 -90 0]); grid;
%C9P28c.m
w=linspace(0, 100, 10000);
num=[1 10]; den=[1
201 200];
[H,w]=freqs(num,den,10001); %H=freqs(num,den,w);
plot(w,50*abs(H)); grid; axis([0 100 0 2.1 ])
ylabel('Magnitude in Linear Scale')
xlabel('Angular Frequency in rad/sec, Linear Scale')
title('Magnitude of (s+10)/(s√2+201s+200) in Linear Scale')
29. Illustrate individual contributions from each pole and zero of the system function H(s) = 50(s+10)/(s+1)(s+200)
to the Bode diagram of its frequency response. For each one verify that the break-point frequency and asymptotic
lines are in agreement with the analytic expression for the plot.
30. The signal x(t) passes through the sytem H(s), both are given below. Find and plot the output y(t).
x(t) = cos(2π fct) sin(2π f0t)
πt
,
fc = 60 Hz, f0 = 10 Hz, and H(s) =
s + 1
(s + 10)(s + 5,000)
31. A system has two poles at −1 ± j314, a zero at −1, and a DC gain of 0 dB.
a. Find H(s).
b. Plot the Bode plot of H(ω).
c. Using H(s), ﬁnd the system’s steady-state response to a 50-Hz sinusoid with 100-µV peak-to-peak amplitude.
d. Evaluate H(ω) at 50 Hz using the graphical method of vectorial components and use it to ﬁnd the answer of
part c.
e. Use a Bode plot to ﬁnd the answer of part c. Compare results in c, d, and e.
32. Sketch the magnitude and phase of the frequency responses of the following systems
a. H(s) =
2s
s2 + 2s + 2
b. H(s) =
s −10
(s + 10)(s2 + 2s + 101)
c. H(s) =
10,001
s2 + 2s + 10,001
33. a. Sketch Bode plots of the magnitude (with 1-dB accuracy) and phase of the frequency responses of the following
two systems:

600
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
(i) H1(s) =
400(s + 1)
(s + 4)(s2 + 2s + 101)
(ii) H2(s) = 2(s2 + 2s + 101)
(s + 2)(s + 101)
b. Estimate |H1(ω| at ω = 2 and ω = 300.
c. Estimate |H2(ω| at ω = 4 and ω = 200.
d. Compare the estimations with their corresponding calculated values.
Note: In the circuits of problems 34 to 41 the 741 op-amps are modeled by an open-loop DC gain of 2 × 105, a
pole at f = 5 Hz, inﬁnite input impedance, and zero output impedance.
34. The integrator of Figure 9.53(a) uses an input resistor R1 = 1 k. The feedback capacitor is 1 µF ≤C ≤10 µF
and can be adjusted in 1 µF steps. For the two cases given below ﬁnd H(s) =
V2
V1 , sketch the Bode plots, and
compare results: a. op-amp is ideal, b. op-amp is a 741 model.
V2
V1
(b) For Problem 35
+
–
R2
R1
C
(a) For Problem 34
V2
V1
+
–
R1
C
FIGURE 9.53 Integrators
35. TheleakyintegratorofFigure9.53(b)usesaninputresistor R1 = 1k,andafeedbackcapacitor1µF ≤C ≤10µF
(in 1 µF steps) in parallel with R2 = 10 k. For the two cases given below ﬁnd H(s) = V2
V1 , sketch the Bode plot,
and compare results: a. op-amp is ideal; b. op-amp is a 741 model.
36. The inverting ampliﬁer of Figure 9.54(a) uses a 741 op-amp, an input resistor R1 = 1 k, and a feedback resistor
R2. Find H(s) = V2/V1 for 1 k ≤R2 ≤10 k and sketch the Bode plot of the frequency response using 1 k
steps for R2.
V2
V1
(b) For Problem 37
+
–
R2
R1
(a) For Problem 36
V2
V1
+
–
R1
R2
FIGURE 9.54 Ampliﬁers
37. A noninverting ampliﬁer circuit uses a 741 op-amp, a grounding resistor R1 = 1 k, and a feedback resistor R2.
See Figure 9.54(b). Find H(s) = V2/V1 for 1 k ≤R2 ≤10 k and sketch the Bode plot using 1 k steps for R2.
38. a. Anoninvertingampliﬁerwitha64-dBDCgainusesa741op-ampandtworesistors R1 and R2.SeeFigure9.55(a).
Plot its magnitude response and determine the 3-dB bandwidth.
b. The 64-dB DC gain may also be realized by cascading two stages with gains of 26 dB and 38 dB, respectively, as
seen in Figure 9.55(b). Sketch the magnitude response plots for each stage and the cascaded system as a whole.
Determine the 3-dB bandwidth of the cascaded system and compare with part a.

Signals and Systems
601
(a)
(b)
v2
v2
v1
+
–
R1
R1
R2
v1
+
–
R3
R3
R4
+
–
R5
R5
R4
FIGURE 9.55 For Problem 38
39. A second-order system has a zero at the origin and two conjugate poles at 1̸ θ. Find H(s) in terms of θ. Sketch its
Bode plot for 90◦< θ < 180◦using 10◦steps. Discuss the correlation of these entities with those of section 9.20
and Figure 9.26.
40. Consider the circuit of Figure 9.56.
a. Write KCL equations at nodes A, B, and C. Show that
H(s) = V2
V1
=
τ2s
τ 2
1 τ2s3 + (τ 2
1 + 3τ1τ2 + ατ1τ2)s2 + (3τ1 + (1 + 2α)τ2)s + 1
where τ1 = R1C1, τ2 = R2C2, and α = R1/R2.
b. Let R1 = 470 , R2 = 4,700 , C1 = 10 nF, and C2 = 47 nF, ﬁnd H(s) and its poles. Sketch its Bode
magnitude and phase plots.
A
B
C
+
–
V2
R2
C1
C2
C1
V1
R1
R1
+
–
FIGURE 9.56 For Problem 40
41. In the circuit of Figure 9.57(a) show that V2/V1 = 1/(s2 +
√
2s + 1) using the following three approaches:
a. Circuit approach, by applying KCL to nodes at the inverting inputs of the op-amps.
b. System approach, by considering op-amps 1 and 2 as the forward path and op-amp 3 as the feedback. The system
model is shown in Figure 9.57(b).
c. Time-domain approach, by noting that the voltage at node B is −v′
2 and the circuit implements the differential
equation v′′
2 = v1 −
√
2 −v′
2 −v2.
V2(t)
V1(t)
+
–
1
(a)
(b)
1
1
1
1
1
A
2
C
+
–
3
–d V2/dt
+
–
1
1
B
1/√2
V2
V1
Σ
b
K
+
–
FIGURE 9.57 For Problem 41

602
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
42. Show that the circuits of Figure 9.58(a) and (b) have the same system function V2/V1 = 1/(s2 + 2s + 1).
V2
–
+
+
–
1
1
1
B
A
1
V2
1
+
–
V1
+
2
1
–
V1
+
–
(a)
(b)
+
–
+
–
FIGURE 9.58 For Problem 42
43. A three-terminal circuit N with transfer function β(s) = Vout
Vin
, as in Figure 9.59(a), is placed in the feedback path
of a noninverting ampliﬁer as in Figure 9.59(b). The op-amp is ideal except for having an open-loop gain of k.
a. Show that the system function of the overall system is
H(s) = V2
V1
=
k
1 + βk ≈1
β
if βk >> 1
b. Let k = 200,000 and N be the bandpass circuit as in Figure 9.59(c). Show that H(s) is a notch ﬁlter and ﬁnd
its notch frequency and the 3-dB bandwidth.
–
+
(a)
(b)
(c)
+
+
–
–
v2
B
C
A
N
vin
vout
–
+
v1
v1
–
+
v2
R1
R
R2
B
C
C
C
R
A
A
C
B
N
vin
vout
FIGURE 9.59 For Problem 43

Signals and Systems
603
44. The standard RIAA14 cartridge preampliﬁer boosts low frequencies to compensate for their attenuation in the process
of manufacturing records. It provides the following gains:
a. 17 dB (20 Hz to 50 Hz)
b. 0 dB (500 Hz to 2,120 Hz)
c. −13.7 dB at 10 kHz
Its frequency response may be considered to follow the asymptotic lines shown in Figure 9.60(a), with break points
at 50 Hz (a pole, drop 3 dB), 500 Hz (a zero, add 3 dB), 2,120 Hz (a pole, drop 3 dB), and a roll-off of 20 dB per
decade after that.
a. Show that the noninverting ampliﬁer of Figure 9.60(b) can approximate the above gain provided the impedance
of the feedback circuit is
z(s) = 10R
1 + τ2s
(1 + τ1s)(1 + τ3s),
where τ1 = 3 msec, τ2 = 300 µsec, and τ3 = 75 µsec.
b. Show that either of the two circuits in Figure 9.60(c) and (d ) can perform the desired preampliﬁcation.
100
101
102
103
104
105
−40
−30
−20
−10
0
10
20
30
 Magnitude (dB)
Frequency (Hz)
(a)
(b)
(c)
(d)
–
+
B
R
A
vin
vout
Z
A
B
R2
R1
C2
C1
A
B
R2
C2
R1
C1
FIGURE 9.60 For Problem 44
45. Find the unit-step responses of the lead and lag networks of, respectively, Figure 9.21(a) and Figure 9.22(a) with
R1 = 10 k, R2 = 1 k, and C = 1 µF. Compare the responses and relate their salient features to their frequency
responses.
46. Consider the lead compensator of Figure 9.21(a) with H(s) = α(s + ω1)/(αs + ω1). Draw its frequency response
H(ω) in polar form. Show that the plot is an upper half-circle with its center at (1 + α)/2 on the real axis. From
14Recording Industry Association of America.

604
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
the origin draw a tangent line to the circle and show that the angle between that tangent and the real axis is θM, the
maximum phase offered by the compensator, and that
sin(θM) = 1 −α
1 + α
47. Repeat problem 46 for the lag compensator network of Figure 9.22(a).
48. A ﬁnite-duration integrator is made of an integrator, a delay element T , and a subtractor. Its unit-impulse response
and system function are
h(t) = u(t) −u(t −T ) and H(s) = 1 −e−sT
s
The system function has a pole and a zero at the origin which cancel each other. Let the integrator’s duration be
T = 1 and its input x(t) = e−t.
a. Find the output y(t).
b. Expand H(s) by its Taylor series and approximate it by the ﬁrst n terms in the expansion. Find the approximate
y(t) for n = 1, 2, 3 · · · 8 and compare with the exact output of the ﬁnite integrator. Determine n if a relative
error of 1% in y is acceptable.
49. The ear canal functions as a resonant cavity for sound waves originating from the outside of the external ear and
impinging on the tympanic membrane (eardrum). Its typical contributions to pressure gain for a sound presented at
45◦azimuth at various frequencies are listed in the table below, with a maximum gain of 20 dB at 3 kHz.15
Frequency, kHz
0.2
0.7
1
1.2
2
3
5
10
Gain, dB
2
8
6
8
14
20
15
2
Construct a system function to approximate the above magnitude response and design a circuit to implement it.
50. Plot the frequency response of the systems below. In each case determine if the system is low-pass, bandpass,
bandstop, high-pass, or none of these. In the case of low-pass and high-pass systems, ﬁnd the 3-dB frequencies. In
the case of bandpass and bandstop systems, determine their 3-dB bands.
a.
i) H1(s) =
s2
s2 + 1.272s + 0.81
ii) H2(s) =
s2
s2 + 0.157s + 0.81
b.
i) H1(s) =
177
s2 + 4.25s + 177
ii) H2(s) =
265s2 + 725.7s + 672.6
s3 + 269.75S2 + 902.7s + 672.6
c.
i) H1(s) =
1
s2 + 1.99s + 1
ii) H2(s) =
1
s2 + 0.2s + 1
d.
i) H1(s) =
1
s2 + 5s + 1
ii) H2(s) =
1
s2 + 0.1s + 1
e.
i) H1(s) =
s
s2 + 0.1s + 1
ii) H2(s) =
106
(s + 100)(s2 + 100s + 10,000)
15The numbers are adopted from W.D. Keidel, W.D. Neff, eds. Handbook of Sensory Physiology (Vol. 1).
(New York: Springer-Verlag, 1974), p. 468.

Signals and Systems
605
51. A physical plant is modeled by the third-order system function
Model 1:
H(s) =
8,850
s3 + 55s2 + 380s + 8,850
a. Find its poles and recognize the dominant pair with regard to frequencies on the jω axis.
b. Construct a second-order model ˆH(s) made of the dominant pair of poles (to be called Model 2).
c. Plot the unit-step frequency response of Model 2 and visually compare it with that of Model 1.
d. By a qualitative inspection determine where (in the time and frequency domains) differences between the two
models are small and negligable, and where they are considerable and pronounced.
e. Qualitatively illustrate the effect of the third pole on the time and frequency responses by an example. Then
devise a measure to quantify the effect.
52. Find and sketch the frequency response of an LTI system with a pair of poles in the left-half plane at s1,2 = −σ ± jωd,
a zero at s = 0, and a maximum gain of HM.
53. Find the frequency response of an LTI system with two poles at 0.9e± j135◦, a double zero at the origin, and unity
gain at very high frequencies. Sketch its magnitude-squared |H(ω)|2 plot as a function of ω and evaluate it at ω = 0
(DC), ω = 0.9, and ω = ∞. Determine the −3-dB frequency (where |H(ω)|2 = 0.5).
54. Find the frequency response of an LTI system with two poles at 0.9e± j95◦= −0.0157 ± j0.8965, a double zero at
the origin, and a multiplying factor of unity in the expression for H(s). Sketch its magnitude-squared |H(ω)|2 plot
as a function of ω and evaluate it at ω = 0 (DC), ω = 0.9, and ω = ∞. Determine the −3-dB frequencies and its
bandwidth.
55. A causal system is described by the system function
H(s) =
s
s2 + 0.1s + 100
Use the vectorial interpretation of H(s) to evaluate H(ω). Show that the system is a bandpass ﬁlter. Find the
3-dB frequencies ωℓand ωh. Evaluate H(ω) at ω = 0, 10, ωℓ, ωh, and ∞. Sketch the magnitude and phase
of H(ω).
56. Find and sketch the frequency response of an LTI system with a pair of poles in the left-half plane at s1,2 = −σ ± jωd,
no ﬁnite zeros, and unity DC gain. Find H(s) and the frequency response. Plot magnitude and phase responses
(along with pole locations and the step response) for the following two sets of pole locations:
a. s1,2 = −0.995 ± j0.1 (away from the jω axis).
b. s1,2 = −0.1 ± j0.995 (close to the jω axis).
Explain the shape of each plot in terms of the vectorial interpretation of H(s) and the effect of pole-zero
location.
57. Two LTI systems are cascaded. System 1 is a second-order bandpass (with a pair of poles at p1,2 = 0.9e±θ, a zero
at the origin, and a unity peak gain). System 2 is a unity-gain differentiator. For θ = 100◦, 135◦, and 170◦obtain
the following responses, plot them, and compare.
a. The impulse and step responses of system 1.
b. The impulse and step responses of the cascaded systems.
c. The Bode plots of systems 1, 2, and their cascade.

606
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
9.33
Project 1: RC/CR Passive Bandpass Filter
I. Summary
II. Theory
III. Prelab
IV. Measurements and Analysis
V. Discussion and Conclusions
Appendix 9A: Hyperbolic Functions
Appendix 9B: Bandpass System
I. Summary
In this project you will measure and model the time and frequency responses of a passive bandpass system and compare
them with theory. The system is made of a low-pass RC stage cascaded by a high-pass CR stage. It has two poles on the
negative real axis in the left-half plane and a zero at the origin. You will note that the circuit remains always overdamped,
with no resonance. The quality factor of the ﬁlter remains low. You will explore, by analytic method and measurement,
the effect of the pole location on the system’s frequency and step responses. You will discover their relationship with the
system’s rise time, fall time, and bandwidth.
Equipment
One function generator
One oscilloscope
Resistors (15 k, 1.5 k, and 150 , two of each)
Two 10-nF capacitors
Software tools such as Matlab
Assignments and Reporting
(for a three-hour work) Read and do items 8 to 15 and 19 to 23 of this project.
II. Theory
This part summarizes the time and frequency responses of the passive RC/CR bandpass ﬁlter of Figure 9.61. Most of the
steps are already carried out and the results are shown for veriﬁcation.
A
VB
VA
+
–
V2
R
C
C
V1
R
+
+
+
–
–
–
FIGURE 9.61 A passive bandpass RC/CR ﬁlter.

Signals and Systems
607
1. System Function and State Variables
Show that
H(s) = V2
V1
=
( s
ω0 )
( s
ω0 )2 + 3( s
ω0 ) + 1
where ω0 = 1/RC. The system has two poles at s1,2 = (−α ± β)ω0, where α = 1.5 and β =
√
1.25. Substituting the
above values for α and β we get s1 = −0.382ω0 and s2 = −2.618ω0. The system has a zero at the origin. Show the
location of the poles and zero on the s-plane.
Let the capacitor voltages be VA and VB as shown in Figure 9.61. These two voltages determine the state of the
system at any moment. They are called state variables of the system. Show that their transfer functions are
HA(s) = VA
V1
=
1 +
s
ω0
( s
ω0 )2 + 3( s
ω0 ) + 1
HB(s) = VB
V1
=
1
( s
ω0 )2 + 3( s
ω0 ) + 1
HA(s) and HB(s) have the same two poles as H(s). The system’s output may be written in terms of its state variables:
v2 = va −vb. Note that va and vb are both low-pass signals whose transfer functions were previously found in the
experiment on second-order low-pass systems, which will not be repeated here. The present experiment will be limited
to the study of v2, a bandpass signal.
2. Frequency Response
Express the frequency response as a function of (ω/ω0) and show that
H(ω) =
j(ω/ω0)
1 −(ω/ω0)2 + j3(ω/ω0)
|H(ω)|2 =
(ω/ω0)2
1 + 7(ω/ω0)2 + (ω/ω0)4
̸ H(ω) =





90◦−tan−1
3(ω/ω0)
1−(ω/ω0)2
0 < ω/ωo < 1
0◦
ω/ωo = 1
−90◦−tan−1
3(ω/ω0)
1−(ω/ω0)2
1 < ω/ωo < ∞
Plot the magnitude response |H(ω)| versus (ω/ω0) for 0.1 ≤(ω/ω0) ≤10. Use a log scale for the frequency axis and a
linear scale for |H|, where Vpp = 10 V at the input.
3. Bode Plot
Express the frequency response in decibel (dB) and plot it in the form of a Bode plot. Show that
20 log |H(ω)| = 20 log(ω/ω0) −10 log[1 + 7(ω/ω0)2 + (ω/ω0)4]
Express the frequency response in a Bode diagram. Speciﬁcally, show that
20 log |H(ω)| =













20 log(ω/ω0)
low-frequency asymptote, ω << ω1 (break point at ω1 = 0.382ω0)
−12.5 dB
at ω = 0.303ω0, is 3 dB below HMax
−9.5 dB
at ω = ω0, is HMax
−12.5 dB
at ω = 3.303ω0, is 3 dB below HMax
−20 log(ω/ω0)
high-frequency asymptote, ω >> ω2 (break point at ω2 = 2.618ω0)

608
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Plot 20 log |H(ω)| (in dB) versus log(ω/ω0) for 0.1 ≤(ω/ω0) ≤10. Verify that the low-frequency asymptote is a line
whose slope is 20 dB per decade (terminating at the ﬁrst break frequency ω1); that the high-frequency asymptote is
also a line whose slope is −20 dB per decade (starting at the second break frequency ω2); and that attenuation at ω0 is
20 log 3 = 9.5 dB, where |H(ω)| is at its maximum value.16
4. Bandwidth
By convention, the 3-dB bandwidth (equivalently, the half-power bandwidth) is the frequency band within which the
magnitude response is less than 3 dB below its maximum. Show that the maximum magnitude of the frequency response
is at ω0; that the half-power frequencies (3 dB below the maximum) are ωℓ,h = (1.5 ±
√
3.25)ω0, or ωℓ= 0.303ω0 and
ωh = 3.303ω0; that the system’s 3-dB bandwidth is ω = ωh −ωℓ= 3ω0; and, its quality factor is Q = ω0/ω = 1/3.
5. Unit-Impulse Response
Argue, without solving the system’s input-output differential equation, that the unit-impulse response is h(t) = C1es1t +
C2es2t where s1 and s2 are system’s poles, s1,2 = (−α ± β)ω0, α = 1.5 and β =
√
1.25. Then by observing system’s
behavior during the transition from t = 0−to t = 0+ conclude that h(0+) = ω0 and dh(t)/dt|t=0+ = −3ω2
0. From these
boundary conditions17 ﬁnd
C1,2 = ω0
2β [β ± (α −3)]
h(t) = ω0
2β e−αω0t 
(β −α)eβω0t + (β + α)e−βω0t
u(t)
= ω0
β e−αω0t [β cosh(βω0t) −α sinh(βω0t)] u(t)
Substituting for α = 1.5 and β =
√
1.25 we get
h(t) = ω0
√
5
e−1.5ω0t 
(
√
1.25 −1.5)e
√
1.25ω0t + (
√
1.25 + 1.5)e−
√
1.25ω0t
u(t)
= 2ω0
√
5
e−1.5ω0t √
1.25 cosh(
√
1.25ω0t) −1.5 sinh(
√
1.25ω0t)
u(t)
= 2ω0
√
5
e−1.5ω0t sinh(
√
1.25ω0t + 0.9624)u(t)
= ω0

1.1708e−2.618ω0t −0.1708e−0.382ω0t
u(t)
Sketch h(t).
6. Unit-Step Response
Argue, without solving the system’s input-output differential equation, that the unit-step response is g(t) = D1es1t+D2es2t.
Then, by observing the system’s behavior during the transition from t = 0−to t = 0+, conclude that g(0+) = 0 and
dg(t)/dt|t=0+ = ω0. From these boundary conditions ﬁnd D1,2 = ±1/(2β) and
g(t) = 1
2β e−αω0t 
eβω0t −e−βω0t
u(t) = 1
β e−αω0t sinh(βω0t)u(t)
16For a general formulation of a bandpass system see Appendix 9B at the end of this project.
17The unit-impulse response may also be obtained by taking the inverse Laplace transform of H(s), yielding
C1,2 = ω0(β ∓α)/(2β) which is the same as the result obtained from applying the initial conditions.

Signals and Systems
609
Substituting for α = 1.5 and β =
√
1.25 we get
g(t) =
1
√
5
e−1.5ω0t 
e
√
1.25ω0t −e−
√
1.25ω0t
u(t)
=
2
√
5
e−1.5ω0t sinh(
√
1.25ω0t)u(t)
= 0.4472(e−0.382ω0t −e−2.618ω0t)u(t)
Plot or sketch the step response.
In summary,
Unit-Impulse response:
h(t) = ω0

1.1708e−2.618ω0t −0.1708e−0.382ω0t
u(t)
Unit-step response:
g(t) = 0.4472(e−0.382ω0t −e−2.618ω0t)u(t)
Note that g(t) =  t
−∞h(t)dt, or equivalently, h(t) =
d
dt [g(t)].18
7. Pulse Response, Rise Time, Fall Time, and Droop
The rise time Tr is the time it takes the pulse response to go from 10% to 90% of its ﬁnal value. Similarly, the fall time
T f is the time it takes the pulse response to be reduced from 90% to 10% of its height. Droop is the percentage amount
of sag the response shows during the pulse.
III. Prelab
8. Planning the Experiment
Read Parts IV and V and plan the experiment.
9. Derivation of System Function and Frequency Response
Show that in the circuit of Figure 9.61,
H(s) = V2
V1
=
( s
ω0 )
( s
ω0 )2 + 3( s
ω0 ) + 1
H(ω) =
j(ω/ω0)
1 −(ω/ω0)2 + j3(ω/ω0)
10. Finding |H|Max
For R = 15 k and C = 10 nF show that |H| obtains its maximum at f0 = 1,061 Hz. Then ﬁnd the maximum value,
also in dB.
11. Computing Theoretical dB Values of |V2/V1|
Given f0 = 1,061 Hz, compute theoretical values of |H( f )| = |V2/V1| in dB for the frequencies listed in Table 9.1 and
enter them in their appropriate places in that table.
IV. Measurements and Analysis
Construct the circuit of Figure 9.61 using R = 15 k and C = 10 nF. This will provide ω0 = 1/RC = 105/15 = 6,666.7
rad/s, corresponding to f0 = 1,061 Hz, and a 3-dB bandwidth f = 3 f0 = 3,183 Hz.
18Note that g(t)

bandpass =
1
ω0 h(t)

lowpass, both of second order.

610
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
12. Recording the Frequency Response
Record the responses of the circuit to sinusoidal inputs (Vpp = 10 V, VDC = 0) at f = 100 Hz to 10 kHz as identiﬁed
in Table 9.10. Measure magnitude and phase of the responses and compute the attenuation in dB. Enter measured and
computed values in Table 9.10. Plot the magnitude of the frequency response for the range 100 Hz ≤f ≤10 kHz. Use
log scale for the frequency axis and uniform scale for the magnitude axis. To obtain a plot of the magnitude response
you may program the sinusoidal generator to sweep through the desired frequency range using a log scale, and display a
single sweep of the output on the oscilloscope.
The numerical value of V2/V1 as a function of frequency is also obtainable from the screen. Accurately measure the
3-dB bandwidth. Compare the measured frequency response with theory (item 2). The comparison may be done by using
the relative difference between theory and measured values of V2/V1, deﬁned by:
Relative difference (%) = (measured −theory)
theory
× 100
The difference between theory and measured values of the frequency response may also be expressed in dB:
dB difference = |V2/V1|dB measured −|V2/V1|dB theory
The above measures are related to each other by
dB difference = 20 log10 [(relative difference) + 1]
Enter results in Table 9.10. Draw the measured frequency response in the form of a Bode plot.
TABLE 9.10 Measurements of Magnitude and Phase of the Frequency Responses and Comparison with Theory
Frequency
100 Hz
200 Hz
330 Hz
1 kHz
3.3 kHz
5 kHz
10 kHz
|V2| (volts) measured
|V2/V1| measured
|V2/V1| (dB) measured
(̸ V2 −̸ V1)◦measured
|V2/V1| theory
|V2/V1| (dB) theory
relative difference (%)
dB difference
13. Recording an Impulse Response
Record the system’s impulse response. For this purpose program the function generator to produce a train of very narrow
pulses (e.g., < 1% duty cycle) at a very low frequency f = 100 Hz. Measure its time constants. Model the impulse
response by a mathematical expression and compare with 5.
14. Recording a Step Response
Record the system’s step response and model it by a mathematical expression and compare with 6.
15. Recording a Pulse Response
Record the response to a single rectangular pulse (Vpp = 10 V, DC level = 0, duration = nτ, n = 1, 3, 5 where τ = RC).
Note that for R = 15 K and C = 10 nF we have τ = 150 ns. A pulse may be created as a repetitive rectangular wave at
a low-duty cycle (e.g., at 20%). In each case qualitatively verify that the pulse response is the superposition of responses

Signals and Systems
611
to a step and a delayed negative step. Measure the rise and fall time of the response in µs, and its droop in %. Droop is
deﬁned in item 7 in this project. Enter your answers in the space below.
Answers:
n
Tr in µs
T f in µs
Droop in %
1
3
5
16. Recording Response to Repetitive Square Pulses
Record one cycle of the time response to a repetitive train of square pulses (Vpp = 1 V, VDC = 0) at f = 100 Hz, 500 Hz,
1 kHz, 2 kHz, and 10 kHz. Observe and describe the trend in the response pattern as frequency increases.
17. Filtering White Noise
Pass a white noise through the system. Observe and qualitatively describe the ﬁltering effect on the frequency components
of the noise. Repeat for R = 150 k and 1.5 M.
18. Changing the Bandwidth
Change both resistors in the circuit of Figure 9.61 to R = 150 k. Capture the new step and frequency responses on the
scope. Measure the new bandwidth. Compare with theory.
V. Discussion and Conclusions
19. Poles/Zero Location and Step Response
From the pole-zero plot reason the validity of the shape of the step response.
20. Poles/Zero Location and Bandpass Property
From the pole-zero plot conclude that the system is a bandpass ﬁlter.
21. Bandwidth
The 3-dB bandwidth was deﬁned in item 4 in this project. From the frequency response measurements determine the
upper and lower 3-dB frequencies and the bandwidth. Compare with theory.
22. Transition Band
Deﬁne the transition band to be where −20 dB < 20 log |H(ω)| < −1 dB. Using the measured Bode plot, determine the
upper and lower transition bands of the ﬁlter.
23. Overall Conclusions
Summarize your overall conclusions drawn from this experiment, especially the relationship between the system function,
poles and zeros, frequency response, impulse response, step response, and pulse response.

612
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
APPENDIX 9A
Hyperbolic Functions
Deﬁne cosh(x) (pronounced cosine hyperbolic of x) and sinh(x) (sine hyperbolic of x) by the following equations

cosh(x) = ex +e−x
2
sinh(x) = ex −e−x
2
⇒

ex = cosh(x) + sinh(x)
e−x = cosh(x) −sinh(x)
The following properties are derived from the above deﬁnitions.

cosh(−x) = cosh(x)
sinh(−x) = −sinh(x)
and

cosh( jx) = cos(x)
sinh( jx) = j sin(x)
cosh(x + y) = cosh(x) cosh(y) + sinh(x) sinh(y)
sinh(x + y) = cosh(x) sinh(y) −sinh(x) cosh(y)
Example
Find θ in x(t) =
√
1.25 cosh(
√
1.25ω0t) −1.5 sinh(
√
1.25ω0t) = sinh(
√
1.25ω0t + θ).
Let
 √
1.25 = sinh(θ) and 1.5 = cosh(θ)
eθ = cosh(θ) + sinh(θ) = 1.5 +
√
1.25 = 2.62 ⇒θ = Ln[2.62] = 0.9624
Then
x(t) =
√
1.25 cosh(
√
1.25ω0t) −1.5 sinh(
√
1.25ω0t)
= sinh(θ) cosh(
√
1.25ω0t) −cosh(θ) sinh(
√
1.25ω0t)
= sinh(
√
1.25ω0t + θ) = sinh(
√
1.25ω0t + 0.9624)
APPENDIX 9B
Bandpass System
The system function
H(s) =
ks
s2 + bs + ω2
0
where b is a positive number, represents a bandpass system. The magnitude frequency response |H(ω)| reaches its
maximum at ω0 (center frequency), where |H|Max = |H(ω0)| = |k|/b. The 3-dB frequencies ωℓand ωh are deﬁned to be
the frequencies at which |H(ω)| = |H|Max/
√
2 = |k|/(
√
2b). The 3-dB bandwidth is ω = ωh −ωℓ= b. The quality
factor Q is deﬁned by Q = ω0/ω = ω0/b. The upper and lower 3-dB frequencies are
ωℓ,h = ∓b +

b2 + 4ω2
0
2
= ω0

∓1
2Q +

1 +
	
1
2Q

2

ω0 = √ωℓωh is the geometric mean of the 3-dB frequencies.

Signals and Systems
613
9.34
Project 2: Active Bandpass Filter
I. Summary
II. Theory
III. Prelab
IV. Measurements and Analysis
V. Discussion and Conclusions
I. Summary
In this experiment you will measure and model the time and frequency responses of a narrowband second-order active
ﬁlter and compare them with theory. By changing the gain of the ampliﬁer, you will be able to move the poles of the
system closer to or farther away from the jω axis, thus controlling the bandwidth (or the quality factor) of the ﬁlter. By
observing the time responses you will discover the relationship between the natural frequencies, step response, repetitive
pulse response, resonance, and the frequency response.
Equipment
One function generator
One oscilloscope
Three 15-k resistors
One 10-k resistor
One potentiometer (or variable resistor box), 0–50 k
Two 10-nF capacitors
One op-amp, LM148 or a similar one
One adjustable dual DC power supply for the op-amp, ±12 V
II. Theory
Consider the circuit of Figure 9.62 with R = 15 k, C = 10 nF, R1 = 10 k, and an adjustable R2. Note that the
circuit is constructed from a passive bandpass section (RC/CR) on the left, a noninverting ampliﬁer with gain k =
1 + R2
R1 [equivalently, R2 = (k −1)R1] and a resistive feedback path. In the prelab you will consider the circuit for
k = 1, 1.1715, 2.5, 3, 3.5, 3.9, 4, 4.1. At k = 1.1715 the circuit is critically damped. At k = 4 the poles are on the
jω axis and the circuit becomes an oscillator.
V2 (t)
V1 (t)
–
+
R
R
R2
R1
R
C
C
FIGURE 9.62 A second-order active bandpass ﬁlter.

614
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Note: You may simulate the circuit (using Spice, MicroCap, etc.) or use a computation package (Matlab, Mathcad,
Maple, etc.) to obtain the plots.
1. System Function
Find the system function H(s) = V2/V1 (e.g., by writing a KCL equation at node A). Show that
H(s) = V2/V1 =
kRCs
R2C2s2 + (4 −k)RCs + 2
=
k
√
2
 s
ω0

 s
ω0
2 + 1
Q
 s
ω0

+ 1
where
k = 1 + R2
R1
,
ω0 =
√
2
RC ,
and
Q =
√
2
4 −k
Note that when k < 4, the system is stable and the bandpass summary given in Appendix 9B of project 1 applies. In
doing the prelab, you may use the results given in that appendix to compute indicators of the frequency response such as
bandwidth and 3-dB frequencies.
2. Poles and Zero(s)
Find the system’s poles and zeros. Determine the natural frequencies s1,2 = −α ± jωd and ωo =

α2 + ω2
d. Show that
α = ω0
2Q and ωd = ω0
2Q

4Q2 −1
For k = 1, 1.1715, 2.5, 3, 3.5, 3.9, 4, 4.1 compute the locations of s1,2 and plot them on the s-plane. Note how the poles
migrate toward jω axis as k is increased. For the k values listed above ﬁnd R2, Q, s1,2 = α ± jωd, ω0 and enter your
answers in a table and call it Table 9.11.
TABLE 9.11 Quality Factor and Pole Locations for Eight Values of Feedback Gain
k
R2 (kΩ)
Q =

2/(4 −k)
ω0
s1,2
1
1.1715
2.5
3
3.5
3.9
4
4.1
3. Unit-Step Response
Let g(t) designate the unit-step response; that is, v2(t) = g(t), where v1(t) = u(t), a 1-V step. From item 2 above
conclude that
g(t) = Ae−αt cos(ωdt + θ)
Sketch, by hand or by computer, the ﬁrst 5 msec (0 ≤t ≤5 msec) of the unit-step response for the case of k = 3.9.

Signals and Systems
615
4. Sketch of the Frequency Response from the Pole-Zero Plot
Using the pole-zero plot at k = 3.9, and based on a vectorial interpretation of H(ω), sketch, by hand, the magnitude and
phase of the frequency response for 200π < ω < 104 × 2π (100 Hz to 10 kHz). You should obtain a bandpass frequency
response. Use log scale for ω (or f ) and uniform scale for |H|.
5. Frequency Response Indicators
Using H(s) given in item 1, ﬁnd the mathematical expression for the frequency response H(ω). Express the frequency
response as a function of ω/ω0 (or f/f0). You should obtain a bandpass frequency response. For k = 3.9, plot it using a
computer. You may use f = ω/2π for the frequency axis (i.e., to identify important points by f0, fℓ, fh, and,f = fh−fℓ).
Use log scale for ω (or f ) and uniform scale for |H|.
Show that for all k < 4 (stable system), |H|Max = k/(4 −k) and it occurs at ω0 =
√
2/RC (or f0 = ω0/2π).
Determine ω. For high Q approximate half-power frequencies ωℓand ωh and enter your answers in Table 9.12. You
may use the Appendix 9B at the end of project 1 in this chapter.
TABLE 9.12 Resonance Indicators for Eight Values of Feedback Gain
k
Q
|H|Max = k/(4k)
ω0
∆ω
ωℓ
ωh
1
1.1715
2.5
3
3.5
3.9
4
4.1
6. Stability
For k ≥4 discuss location of the poles, shape of step and impulse responses, and show that the system becomes unstable.
7. Filter Summary at k = 3.9
Important response characteristics of the circuit of Figure 9.62 at k = 3.9 are summarized in the table below for comparison
with measurement results.
k
R2, kΩ
Q
s1,2, neper
|H|Max
f0, Hz
∆f, Hz
fℓ, Hz
fh, Hz
3.9
29
14.14
−3,333.8 ± j8,819
39
1,500.53
106.1
1,447.5
1,553.6
III. Prelab
8. Planning the Experiment
Read Parts IV and V and plan the experiment.
9. Deriving the System Function
Derive the system function given in item 1.

616
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
10. Computing Q, ω0, and Pole Locations
Complete Table 9.11.
11. Computing |H|Max, ∆ω, ωℓ, and ωh
Complete Table 9.12.
IV. Measurements and Analysis
Use the circuit of Figure 9.62 with element values R = 15 k, C = 10 nF, R1 = 10 k, and an adjustable R2.
Measurement of response parameters is best done through the oscilloscope display. When required, capture responses
from the oscilloscope and include their prints in your report.
12. Recording the Step Response and Natural Frequencies
Set k = 3.9 and record the ﬁrst 5 msec of the step response (0 ≤t ≤5 msec). You may use a square-pulse input signal
(10 Hz, 200 mV). From the scope or the recorded step response specify the natural frequencies and compare with item 2.
Model the step response by a mathematical expression and compare with item 3. Describe their differences and explain
possible reasons behind them.
(a) Sweep = 500 µsec/div, Ch1 = 2 V/div. Ch2 = 1 V/div
(b) Sweep = 1 msec/div, Ch1 = 200 mV/div. Ch2 = 200 mV/div
(c) Sweep = 5 msec/div, Ch1 = 200 mV/div. Ch = 2 V/div
(d) Sweep = 5 msec/div, Ch1 = 500 mV/div. Ch2 = 2 V/div
FIGURE 9.63 Step responses of the bandpass ﬁlter. As the feedback gain increases the system’s poles (a pair of complex
conjugates in the LHP) move closer to the jω axis. Oscillations become more pronounced but are still decaying (from
a to b). In (c) the pair of complex poles have just moved to the RHP and oscillations grow rather than decay. In (d) the
amplitude of oscillations has grown to a constant value imposed by op-amp saturation voltage. Step inputs are on channel
1 and responses are on channel 2. The frequency of oscillations is 1.5 kHz.

Signals and Systems
617
13. Effect of the Gain on the Step Response
Starting from low gain (k = 1), gradually increase k and qualitatively observe and record its effect (DC steady state,
frequency of oscillations, damping ratio) on the unit-step response. Compare with Table 9.11. Examples of step response
for four values of feedback are given in Figure 9.63.
14. Recording the Frequency Response
Set k = 3.9. Measure and record the magnitude of the frequency response for the range 100 Hz ≤f ≤10 kHz. You may
use a sinusoidal input signal at a constant amplitude and measure the output. Plot |H(ω)|. Use log scale for the frequency
axis and uniform scale for the magnitude axis. Compare with the result in item 4. An example of the recording of the
frequency response is shown in Figure 9.64.
100 Hz
10 kHz
Logarithmic sweep
FIGURE 9.64 Sinusoidal output of the bandpass ﬁlter as a function of frequency obtained by a
single log sweep. Time scale: 500 msec/division.
15. Effect of the Gain on the Frequency Response
Starting from low gain (k = 1), gradually increase k and qualitatively observe and record its effect ( f0, fℓand fh, f
and Q) on the frequency response. Compare with Table 9.12.
16. Response to the Repetitive Square Pulse
At k = 3.9 measure and record the time response to a repetitive train of square pulses (Vpp = 200 mV, VDC = 0 V).
Sweep the frequency from f = 100 Hz to 10 kHz. Record responses to one cycle of the square pulse input at f0/10,
f0/5, f0/3, f0, and 2 f0 (5 records). Measure the gain at f0 and compare it with the gain of the frequency response at f0
(item 12).
17. Response to the Square Pulse Around f0 Hz
At k = 3.9 observe and visually examine the time response to a repetitive train of square pulses (Vpp = 200 mV,
VDC = 0 V) at the frequencies f0 ± 5 Hz. Relate your observations to the natural frequency of the system. See how the
oscillations merge to form a quasi-sinusoidal response.
18. Response to the Square Pulse Around f0/3 Hz
At k = 3.9 set the square pulse input at ≈f0/3 Hz and visually examine the response. Gradually and slowly change the
frequency of the input (within the range of f0/3 ± 50 Hz). You should see an increase in the response amplitude at f0/3.
Explain this effect by observing that f0, where the maximum of the magnitude of the frequency response occurs, is the
third harmonic of the square pulse input.

618
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
V. Discussion and Conclusions
19. Gain, Pole-Zero Locations, Bandpass Property, and Stability
Discuss the effect of the gain on the bandpass characteristics of the ﬁlter (center frequency, bandwidth, quality factor).
Discuss under what conditions the system becomes unstable and plot an example of the step response.
20. Overall Conclusions
Discuss the capabilities of the current active bandpass ﬁlter. Compare with the passive bandpass ﬁlter of Project 1.
9.35
Project 3: An Active Filter with
Bandpass/Lowpass Outputs
I. Summary
II. Theory
III. Prelab
IV. Measurements and Analysis
V. Discussion and Conclusions
I. Summary
In this experiment you will measure and model the time and frequency responses of a second-order system with one
input and two outputs (low-pass and bandpass). See the circuit of Figure 9.65. By adjusting a single feedback resistor in
the circuit you can move the poles of the system closer to or farther away from the jω axis and control the bandwidth
(or the quality factor) of the system. By analyzing time responses you will observe the system’s poles and discover the
relationship between the natural frequencies, step responses, repetitive pulse responses, resonance, and the frequency
responses.
VB
V1(t)
+
+
–
–
VA
+
–
C
R3
R3
R
R
R1
2
+
–
3
+
–
C
1
R2
Bandpass
Low-pass
FIGURE 9.65 Active ﬁlter with bandpass/low-pass outputs.
Equipment
One function generator (Agilent 33120A or a similar one)
One oscilloscope (Agilent 54622A or a similar one)
Three 15-k resistors
One 1.5-k resistor

Signals and Systems
619
Two identical resistors (e.g., 10 k) for unity gain inverting op-amp
One potentiometer (or variable resistor box), 0–50 k
Two 10-nF capacitors
Three op-amps, LM148 or similar
One adjustable dual DC power supply for the op-amp, ±12 V
Assignments and Reporting
Read and do items 7–10 and 13–19 in this project.
II. Theory
1. The System
The system is implemented by the circuit of Figure 9.65 which is made of three op-amps, all operating in the inverting
conﬁguration. Op-amp 1 is a summing leaky integrator and produces the bandpass output. It has two inputs: one through
the system’s input, the other through the feedback from the low-pass output. Op-amp 2 integrates the bandpass signal and
produces the low-pass output. Op-amp 3 is a unity-gain inverting ampliﬁer that feeds back the low-pass signal to op-amp
1 (the bandpass stage). The system has one input, v1(t), which arrives at the inverting terminal of op-amp 1. It has two
outputs: vA(t) (a bandpass signal) and vB(t) (a low-pass signal).
The system has two poles (natural frequencies) at s1,2 = −α ± jωd. They are observable throughout the system,
including at the bandpass and low-pass outputs. The undamped natural frequency is ωo =

α2 + ω2
d. By adjusting the
resistor R2 (in the feedback path of op-amp 1) you can place the poles of the system at desired locations, move them closer
to or farther away from the jω axis, and control the bandwidth (or the quality factor) of the system. In the prelab section,
we will use Q = 5, Q = 10, and 20. In the measurement section you will use Q = 10 (with the additional Q values of 5
and 20 optional).
2. System Functions
Consider the circuit of Figure 9.65 with R = 15 k, C = 10 nF, R1 = 1.5 k, and R2 = QR. Find the two system
functions HA(s) = VA/V1 and HB(s) = VB/V1. Show that
Bandpass system function: HA(s) = VA
V1
= −
	
R
R1

s
ω0
 s
ω0
2 + 1
Q
 s
ω0

+ 1
= −
	
R2
R1

1
Q
 s
ω0

 s
ω0
2 + 1
Q
 s
ω0

+ 1
Low-pass system function:
HB(s) = VB
V1
= −
1
RCs HA(s) =
	
R
R1

1
 s
ω0
2 + 1
Q
 s
ω0

+ 1
where ω0 =
1
RC , Q = R2
R
and |HA|,Max = R2
R1 , |HB|,Max = DC gain =
R
R1
Note: Items 3, 4, and 5 should be carried out for Q = 5, 10, and 20.
3. Poles and Zeros
Find the poles of the system. Note that the poles are the same in HA and HB. These are the system’s natural frequencies
which we show by s1,2 = −α ± jωd. Show that
α = ω0
2Q
ωd = ω0
2Q

4Q2 −1
ωo =

α2 + ω2
d

620
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
Compute s1,2 for Q = 5, 10, 20 and show them on the s-plane. Note what happens to the natural frequencies when Q
increases.
Find the zero(s) of HA and HB. Verify that they may be obtained directly from the circuit.
4. Unit-Step Responses
From item 2 conclude that the unit-step responses have the following form:
Ce−αt cos(ωdt + θ) + D
where D is the DC steady-state part of a response. Sketch, by hand or by computer, 10 msec of unit-step responses
(0 ≤t ≤10 msec). Note the effect of increasing Q on the responses.
5. Sketch of H(ω)
Based on a vectorial interpretation of H(ω), sketch by hand the magnitude and phase of the frequency responses. Use log
scale for ω and uniform scale for |H|.
6. Indicators of Frequency Responses
Using HA(s) and HB(s) given in part a, ﬁnd the mathematical expression for the bandpass and low-pass frequency
responses for Q = 5, 10, and 20. Show that the maximum of |HA| occurs at ω0 = 1/RC. For high Q approximate
half-power frequencies ωℓand ωh. Plot the frequency responses using a computer. Use log scale for ω and uniform scale
for |H|.
III. Prelab
7. Planning the Experiment
Read Parts IV and V and plan the experiment.
8. Deriving System Functions
Derive the system functions given in item 2.
9. Computing Frequency Response Indicators
Compute indicators of the frequency responses for Q = 10.
IV. Measurements and Analysis
Use the circuit of Figure 9.65 with element values R = 15 k, C = 10 nF, R1 = 1.5 k, and R2 = QR. Measurements
will be done at Q = 10.
10. Obtaining Step Responses
At Q = 10 record the step responses (at A and B) for 0 ≤t ≤10 msec. You may use a square pulse input signal (10 Hz,
100 mV). Observe that the two step responses have the same natural frequencies. From the record measure their natural
frequencies and compare with Part II. Model the step responses by mathematical expressions and compare with item 3.
11. Effect of Q on the Step Responses
Qualitatively observe and record the effect (DC steady state, ω0, α, and ωd) of increasing Q on the unit-step response.
Compare with theory.

Signals and Systems
621
12. Measuring Frequency Responses
At Q = 10 measure and record the magnitude of the frequency responses HA(ω) and HB(ω) for the range 100 Hz ≤f ≤
10 kHz. You may use a sinusoidal input signal at a constant amplitude and measure the output. Plot the magnitude and
phase of H(ω)A and HB(ω). Use log scale for the frequency axis and uniform scale for the magnitude axis. Compare with
the result in item 6.
13. Bandpass Output
At Q = 10 measure and record the magnitude of the frequency response HA(ω). From frequency response measurements
obtain the frequency at which |HA| is at its maximum and call it ω0. Obtain half-power frequencies ωℓand ωh. Compute
bandwidth ω = ωh −ωℓand Q = ω/ω. Find the phase shift at ωℓ, ω0, and ωh. Compare with the results obtained in
the prelab.
14. Lowpass Output
At Q = 10 measure and record the magnitude of the frequency response HB(ω). Obtain its 3-dB (half-power) frequency
and call it ωc. Find the phase shift at ωc. Compare with theory.
15. Effect of Q on Frequency Responses
Qualitatively observe and record the effect of increasing Q on the frequency responses (ω0, ωℓand ωh, ωc, ω and Q).
Compare with prelab.
16. Response to Repetitive Square Pulse
At Q = 10 measure and record 10 msec of time response to a repetitive train of square pulses (Vpp = 100 mV, VDC = 0 V).
Sweep the frequency from f = 100 Hz to 10 kHz and observe the trend in the response.
IV. Discussion and Conclusions
17. Conditions for Resonance
From the pole-zero plot determine the range of Q for which the system can resonate.
18. Interpretation of Pulse Response
Relate your observations in item 17 to the unit-step response, frequency response, and natural frequencies of the circuit.
19. Overall Conclusions
Summarize your overall conclusions drawn from this experiment, especially the relationship between the system function,
poles and zeros, frequency response, step response, and pulse response.
9.36
Project 4: Examples of Modeling LTI
Systems
Summary
This project explores modeling two LTI systems based on the magnitude of their frequency responses.

622
CHAPTER 9
System Function, the Frequency Response, and Analog Filters
System 1
The magnitude frequency response of a system is measured and recorded in Table 9.13.
TABLE 9.13 Measurements Giving Salient Frequency Features of a Realizable LTI System
Frequency in kHz
DC
5 Hz
1 kHz
2 kHz
3 kHz
5 kHz
10 kHz
20 kHz
50 kHz
|H( f )| in dB
−20
−19
−17
−13
−11
−7
−3
−1
−0.5
̸ H( f ) in degrees
Plot the magnitude response in the form of a Bode plot. Approximate the plot by asymptotic lines and identify possible
pole(s) and zero(s) of the system. From that approximation construct a causal stable rational system function H(s). Realize
the above H(s) as a voltage transfer function in a circuit with a minimum number of passive elements and ﬁnd their values.
System 2
The small-signal magnitude response of a single-stage transistor ampliﬁer is measured and plotted in Figure 9.66. Its
salient features are also summarized in Table 9.14. Using the above information, model the ampliﬁer by a rational system
function. Assume a realizable and stable system. Consider several possible phase functions. Discuss the order of the
system and the consequences of zero placement in the RHP and/or LHP, considering several phase functions. Fine-tune
the model by adjusting the zero(s) location to within 0.1 dB.
TABLE 9.14 Measurements Giving Salient Frequency Features of a Small-Signal Common-Emitter Amplifier
ω (rad/s)
< 106
3.2 × 107
109
4.5 × 109
1010
1.1 × 1011
1012
1014
Magnitude, dB
28
25
−1.7
−20
−29
−65
−88
−128
DC
suggested
suggested
suggested
very high
level
1st break point
2nd break point
3rd break point
frequency
Slope, dB/decade
0
−20
−40
−20
−20
106
107
108
109
1010
1011
1012
1013
1014
Angular frequency (rad/s)
–20
–40
–60
–80
–100
–120
0
Magnitude (dB)
20
40
FIGURE 9.66 Small-signal magnitude frequency response of the ampliﬁer obtained by measurement.

Chapter10
Time-Domain
Sampling and
Reconstruction
Contents
Introduction and Summary
623
10.1
Converting from Continuous Time to Discrete
624
10.2
Mathematical Representation of Sampling
627
10.3
Sampling and Reconstruction of Strictly Low-Pass Signals
632
10.4
Sample and Hold
635
10.5
Sampling Nearly Low-Pass Signals
638
10.6
Aliasing and Leakage
642
10.7
Frequency Downshifting
644
10.8
Summary of Sampling and Reconstruction Process
650
10.9
Complex Low-Pass Signals
651
10.10
Bandpass Signals and Their Sampling
653
10.11
Reconstruction of Bandpass Signals
658
Appendix 10A Additional Notes on Sampling
661
10.12
Problems
662
10.13
Project 1: Sampling Neuroelectric Signals
677
10.14
Project 2: Time-Domain Sampling
677
Introduction and Summary
The frequency band occupied by a signal provides some information about the way the
signal is expected to change from one moment to another. The value of the signal at any
time may be estimated with various amounts of error from a ﬁnite or inﬁnite number of
623

624
CHAPTER 10
Time-Domain Sampling and Reconstruction
observations. These observations are called samples. The chapter begins with the sam-
pling theorem for low-pass signals, developed in the frequency domain. The frequency-
domain presentation of the sampling process provides a simple and convenient method to
discuss phenomena such as aliasing and leakage, sampling nearly low-pass signals, effect
of the sampling rate, and nonideal reconstruction ﬁlters. These phenomena are discussed
and illustrated by a multitude of examples. The chapter then extends the discussion to
bandpass signals and their sampling. The ﬁrst project at the end of the chapter suggests
researching practical considerations and recommendations for professional standards
in sampling neuroelectric signals such as EEG, EMG, and EKG. The second project
experiments with and explores some real-time sampling and aliasing of signals.
10.1
Converting from Continuous Time
to Discrete
Many continuous-time signals are represented by their samples taken at regular intervals.
Traditional measurement and recording of atmospheric data (temperature, humidity, and
pressure) at weather stations are done at speciﬁed intervals of time. The Dow Jones
Industrial Average index (DJIA) is computed every minute and also obtained as the
daily, monthly, and annual values. Similar observations apply to examples presented in
Chapter 1 of this book, such as sunspot numbers, CO2 content of the air, and vibrations
of the earth. An intuitive commonsense rationale for recording the samples rather than
continuously is that such signals on average do not change in time faster than at a given
rate. Their frequency components are conﬁned within a band. The signals are band
limited. By sampling, a continuous-time function is converted to a sequence of numbers,
which represent the value of the function at sampling instances. When sampling is
done uniformly every T seconds, T is called sampling interval, and its inverse is called
sampling rate, Fs = 1/T in units of samples per seconds (also called Hz). The sequence
of samples is called the discrete-time signal.
A general requirement in sampling a continuous-time signal is that it can be re-
covered from its samples. The sampling theorem1 establishes the relationship between
the bandwidth of the signal and the minimum sampling rate which can provide recon-
struction of the original signal without distortion. For a low-pass signal with frequencies
not higher than f0 the acceptable sampling rate for signal recovery is greater than twice
the highest frequency present in the signal, Fs > 2 fo. (Fs = 2 f0 is called Nyquist
rate.) The theorem also provides method of reconstruction and states that the high-
est frequency in the reconstructed signal is less than or equal to Fs. Moreover, if the
Nyquist rate is not satisﬁed, not only frequencies higher than Fs/2 are lost (cannot be
1The sampling theorem is originally credited to H. Nyquist and C. Shannon. See the following two papers:
H. Nyquist, “Certain Topics in Telegraph Transmission Theory,” Transactions of the AIEE, Feb. 1928,
pp. 617–644. Reprinted in the Proceedings of the IEEE, 90, no. 2 (February 2002). C.E. Shannon,
“Communication in the Presence of Noise,” Proceedings of the IRE, 37, no. 1 (January 1949), pp. 10–21.
Reprinted in the Proceedings of the IEEE, 86, no. 2 (February 1998).

Signals and Systems
625
recovered by reconstruction process), but also these frequencies fold back as the low
end of the band (near DC) and produce a phenomenon called aliasing. Consequently,
another requirement for sampling is that the continuous-time signal be low-pass ﬁltered
to limit it to a frequency band, no more than the band that contains the information of
interest.
A familiar example in sampling is that of audio signals such as speech and music,
which are initially recorded in the form of continuous-time electrical waveform obtained
by a transducer such as a microphone. The information carried by normal speech (in-
cluding speaker recognition) is conﬁned to a band of less than 3 kHz. For that purpose the
sampling rate of 8 kHz can be used. A sampling rate of over 40 kHz preserves all audio
components that the human ear can hear. Another example in sampling is digital record-
ing of seismograms. They use sampling rates from 0.01 Hz to 0.1, 1, 40, 80, and 100 Hz.
Other examples of practical interest are digital recordings of neuroelectric signals. For
example, a frequency band of 0.5 to 50 Hz is satisfactory for routine examination of
electroencephalograms (EEG signals). The sampling rate, then, can be 100 Hz for that
purpose, while a higher bandwidth (called full-band EEG) would use a higher sampling
rate. Similar considerations apply to electrocardiograms (EKG, bandwidth = 1 Hz to
30 Hz) and electromyogram (EMG, bandwidth = 4 Hz to 2 kHz, also up to 20 kHz) and
other electrical signals recorded from the central nervous system.
Notations
Sampling a continuous-time function x(t) every T seconds generates a sequence of
numbers whose values are x(nT ). The sequence is called a discrete-time function. In
this book the sample sequence is shown by x(n). It is understood that x(n) represents a
function of the discrete variable n.
Example
10.1
Consider the continuous-time low-pass signal
x(t) = sin(2π f0t)
πt
,
f0 = 1 kHz, −∞< t < ∞
The signal is band limited to 1 kHz. Sample x(t) at the rate of Fs = 2(1 + α) f0
samples per second. List the sequence of the ﬁrst 13 samples (starting from t = 0)
rounded to the nearest integer for the following values of
a.
α = 1
b.
α = 3
Solution
Let the sampling interval be T = 1/Fs. Substitute t = nT in the expression for x(t)
to obtain
x(n) ≡x(t)|t=nT = sin(2π f0nT )
πnT
= 2 f0
sin
 πn
1+α

πn
1+α
,
−∞< n < ∞

626
CHAPTER 10
Time-Domain Sampling and Reconstruction
a.
α = 1, x(nT ) = 2,000sin
 πn
2

πn
2
x(n) = {2,000
↑
, 1,273, 0, −424, 0, 254, 0, −182, 0, 141, 0, −115, 0, · · ·}
b.
α = 3, x(nT ) = 2,000sin
 πn
4

πn
4
x(n) = {2,000
↑
, 1,800, 1,273, 600, 0, −360, −424, −257, 0, 200, 254, 164, 0, · · ·}
The sample values are shown as an array. The up-arrow under the ﬁrst sample
indicates n = 0. Because x(t) is an even function sample values for n < 0 are the
same as those for n > 0. For recovery of x(t) from x(n) see section 10.3.
Example
10.2
Sample the continuous-time low-pass signal
x(t) = sin(2π f0t)
πt
,
f0 = 1 kHz, −∞< t < ∞
at the rate of 2 f0 Hz. List the sequence of the ﬁrst 10 samples (starting from t = 0)
and argue that the original signal may not be reconstructed from its samples.
Solution
From Example 10.1 we have x(nT ) = 2,000sin(πn)
πn
, x(n) = {1
↑, 0, 0, 0, 0, 0, 0, 0, 0,
0 · · ·} =

1
n = 0
0
elsewhere Unless more exact information about the spectrum of x(t)
is known, it cannot be recovered from the above samples. A sampling rate greater
than 2 f0 is needed.
Example
10.3
Sampling a speech signal
Consider a nondeterministic signal such as speech. The value of the signal at a given
time may not be exactly speciﬁed from its past samples or even from its complete
past. Past history is used to derive some statistical averages. However, it is known
that on average the rate of change of the signal does not exceed a known limit and
the value of the signal at any moment may be estimated with some accuracy from
samples taken prior to that moment. Speech is such a signal. An example of sampled
speech is shown in Figure 1.7 of Chapter 1. The phrase a cup of hot tea is sampled at
the rate of 22,050 samples per second. The abscissa in that ﬁgure shows the time in
seconds. The trace in (a) is approximately 1.4 seconds long and shows the complete
phrase. The trace in (b) is 240 msec long and shows the signal produced from the

Signals and Systems
627
enunciation hot. Note the structure of the signal in (b): a sequence of similar but not
identical wavelets that may be modeled by sinusoids with decreasing amplitudes. Also
note that due to its low-pass property, the amplitude of speech signal is correlated
with its values within its neighborhood and may be estimated from past samples.
The correlation between neighboring samples is evident in trace (c), which exhibits
80 msec of the enunciation hot. Trace (d) shows the ﬁne structure of the signal.
Summary
For sampling a continuous-time signal and its reconstruction, two questions need to
be answered. The ﬁrst question is, what minimum sampling rate guarantees the error-
free reconstruction of the signal? As one may suspect, the minimum rate depends on
how fast the signal may change with time. Fast-changing signals need faster sampling
rates. This question is answered by the sampling theorem. The second question is,
how does the reconstruction error depend on the number of samples used, and the
weight given to each sample? This can be answered by the reconstruction method. In
this chapter we will examine the sampling process and reconstruction method applied
to the following three classes of signals:
1.
Strictly band limited low-pass signals
2.
Nearly low-pass signals (not strictly band limited)
3.
Bandpass signals
10.2
Mathematical Representation of Sampling
Sampling a continuous-time signal x(t) means registering the values of the function
at certain countable instances. This converts x(t) to the sequence of its values at the
sampling times, generally shown as x(n), a function of a discrete variable. Uniform
sampling of x(t) every T seconds (a sampling rate of Fs = 1/T Hz) generates the
sequence x(nT ). This sequence may be shown as a discrete-time signal x(n). In this
notation, it is understood that the discrete-time signal x(n) is equal to the values of x(t)
at sampling times, or x(n) ≡x(nT ).
Sampled Function in the Continuous Time
Samplesmayberepresentedasafunctionoftime(acontinuousvariable)asinFigure10.1.
Such a representation helps illuminate conditions for reconstruction of x(t) from its sam-
ples. To avoid confusion between the discrete-time function x(n) and the continuous-
time representations of the samples we will assign the name y(t) to the continuous-time
domain representation of the sampled function. Mathematically, uniform sampling may
be modeled as multiplication of x(t) by a sampling function s(t), a train of very narrow
pulses, ideally unit impulses, spaced every T seconds.
s(t) =
∞

n=−∞
δ(t −nT )

628
CHAPTER 10
Time-Domain Sampling and Reconstruction
The sampled function is
y(t) = x(t)s(t) = x(t)
∞

n=−∞
δ(t −nT ) =
∞

n=−∞
x(nT )δ(t −nT )
y(t) is a train of impulses spaced every T seconds. The strength of an impulse at t = nT
is equal to the magnitude of x(t) at that point. We would like to ﬁnd conditions and
methods for recovering x(t) from y(t).
x(t): a continuous-time signal
t
s(t) = sampling function
t
T
y(t) = sampled function
T
x(t)
y(t)
s(t)
(a)
(b)
(c)
(d)
t
FIGURE 10.1 Representation of sampling in the time domain. Sampling a continuous-time
signal, x(t) shown in (a), is mathematically equivalent to multiplying it with a train of unit
impulses called the sampling function s(t) shown in (b). The sampled signal y(t) is a train of
impulses whose strength assume values of x(t) at the sampling moments: y(t) = x(t)s(t), shown
in (c). The operation is represented in (d).
Fourier Transform of a Sampled Function
Multiplication of x(t) and s(t) in the time domain is equivalent to their convolution in
the frequency domain. That is, Y( f ) = X( f ) ⋆S( f ), where Y( f ), X( f ), and S( f ) are
Fourier transforms of y(t), x(t), and s(t), respectively.

Signals and Systems
629
f
–Fs
2
Fs
2
X( f )
^
^
1
0
(a)
S(f )
f
–Fs
–2Fs
Fs
2Fs
0
1
T
1
T
1
T
1
T
1
T
Y( f )
f
–Fs
Fs
2Fs
0
1
T
–2Fs
H( f )
x(t)
y(t)
fc
f
–fc
0
T
X( f )
f
–f0
f0
0
1
(b)
(c)
(d)
(e)
FIGURE 10.2 Representation of sampling in the frequency domain The Fourier transform of a
low-pass continuous-time signal is shown by X( f ) in (a). The sampling function s(t) is made
of a train of unit impulses with period T . Its Fourier transform is a train of impulses with period
Fs = 1/T in the frequency domain, shown by S( f ) in (b). The Fourier transform Y( f ) of the
sampled signal is obtained by convolving X( f ) with S( f ). Because of the periodicity of S( f ),
Y( f ) is also periodic with period Fs. Under certain conditions X( f ) can be recovered by low-pass
ﬁltering Y( f ). In this ﬁgure X( f ) extends beyond Fs/2 and may not be recovered from Y( f )
without error. The case of error-free recovery is presented in Figure 10.4.

630
CHAPTER 10
Time-Domain Sampling and Reconstruction
For illustration purposes, consider X( f ) shown in Figure 10.2(a). The Fourier transform
of a train of unit impulses spaced every T seconds in the time domain is a train of
impulses of strength 1/T , spaced every 1/T Hz in the frequency domain (Figure 10.2b).
Therefore,
s(t) =
∞

n=−∞
δ(t −nT ) ⇒
S( f ) = 1
T
∞

n=−∞
δ

f −n
T

and
Y( f ) = X( f ) ⋆S( f ) = X( f ) ⋆

1
T
∞

n=−∞
δ

f −n
T

But
X( f ) ⋆δ

f −n
T

= X

f −n
T

Therefore,
Y( f ) = 1
T
∞

n=−∞
X

f −n
T

See Figure 10.2(c). It is seen that the Fourier transform of y(t) is a periodic function
obtained by adding the periodic repetitions, every 1/T Hz, of (1/T )X( f ). The number
of samples per second is called the sampling rate and is shown by Fs = 1/T . Fs is the
period of Y( f ).
Example
10.4
Consider a continuous-time triangular pulse signal x(t) (1-volt height and 50-second
base). The signal and its magnitude-normalized Fourier transform X( f ) are shown in
Figure 10.3(a). The pulse is sampled every T seconds, corresponding to a rate of Fs =
1/T Hz. The sampled signal y(t) is shown in b, c, and d for three sampling rates (Fs =
0.125, 0.25, and 0.5 Hz, respectively), along with its Fourier transform. As expected
Y( f ) is periodic with period Fs, that provides separation between neighboring lobes
as shown in b, c, and d. As will be seen in the next section the above x(t) may not be
recovered error-free by sending y(t) through a low-pass ﬁlter with cutoff frequency
fc = Fs/2, regardless of how high the sampling rate is.

Signals and Systems
631
(a)
–30
–20
–10
0
10
20
30
0
1
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.4
0.3
0
1
(b)
(c)
(d)
–30
–20
–10
0
10
20
30
0
1
0
1
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.4
0.3
–30
–20
–10
0
10
20
30
0
1
0
1
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.4
0.3
–30
–20
–10
0
10
20
30
0
1
0
1
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.4
0.3
Time (s)
Frequency (Hz)
FIGURE 10.3 Sampling a nearly low-pass signal and its Fourier transform. A 50-second triangular pulse x(t) and its
magniutde-normalised Fourier transform are shown in (a), left and right sides, respectively. The major energy of the pulse
is concentrated in a main lobe within the low-pass band | f | < 0.04 Hz. The pulse is sampled at rates Fs = 0.125, 0.25,
and 0.5 Hz [shown in (b), (c), and (d), respectively, left column]. The Fourier transforms of sampled signals are normalized
in order to have the peak value 1 and are shown to the right of each signal. The transforms are Fs-periodic and exhibit
repetitions of the main lobe in the transform domain. A higher sampling rate pushes the main lobes away from each other
and results in lower reconstruction errors.
a.
The continuous-time signal, a 50-second triangular pulse.
b.
T = 8 seconds, Fs = 0.125 Hz, low separation between lobes results in the highest reconstruction error.
c.
T = 4 seconds, Fs = 0.25 Hz, higher separation between lobes results in a lower reconstruction error.
d.
T = 2 seconds, Fs = 0.5 Hz, highest separation between lobes results in the lowest reconstruction error.

632
CHAPTER 10
Time-Domain Sampling and Reconstruction
10.3
Sampling and Reconstruction of Strictly
Low-Pass Signals
Presentation in the Frequency Domain
The frequency components of a strictly band limited low-pass signal are limited to a
maximum frequency f0 so that X( f ) = 0 for | f | > f0. In the previous section we noted
that Y( f ) is periodic with a period Fs Hz. By choosing a sampling rate Fs > 2 f0 the
interference between each repetition of X( f −n
T ) and its neighbors in creating Y( f ) is
reduced to zero and
Y( f ) = 1
T X( f ),
−Fs
2 < f < Fs
2
An example is shown in Figure 10.4. In that ﬁgure, X( f ) is the Fourier transform of
the low-pass signal (a), S( f ) is the Fourier transform of the sampling function (b), and
Y( f ) = S( f ) ⋆X( f ) is the Fourier transform of the sampled signal (c). The original
signal x(t) can then be recovered by passing the sampled function y(t) through an ideal
low-pass ﬁlter with a gain of T and a cutoff at fc, where f0 < fc < (Fs −f0). The
ﬁlter extracts X( f ) from Y( f ) while eliminating its repetitions. The output of the ﬁlter is
x(t). Compare with Figure 10.2. For error-free reproduction, assuming an ideal low-pass
ﬁlter, the sampling rate has to be greater than the Nyquist rate, Fs > 2 f0.
Presentation in the Time Domain
In the time domain, the output, ˆx(t), of the reconstruction ﬁlter may be expressed as the
convolution of the sampled function y(t) with the ﬁlter’s impulse response h(t).
ˆx(t) = y(t) ⋆h(t)
The impulse response of an ideal low-pass ﬁlter with cutoff frequency at fc and gain
T is
h(t) = T sin(2π fct)
πt
Therefore,
ˆx(t) =
∞

−∞
T x(nT )sin 2π fc(t −nT )
π(t −nT )
Under the conditions Fs > 2 f0 and f0 < fc < (Fs −f0) we obtain ˆx(t) = x(t)
(see the frequency domain presentation in Figure 10.4). The above formula interpolates
x(t) from an inﬁnite number of its samples, past and present. The ﬁlter is sometimes
called the interpolation ﬁlter and the above equation is called interpolation formula.
We will call it reconstruction or recovery ﬁlter (rather than the interpolation ﬁlter) in
order to distinguish its function from the process of increasing number of samples by
interpolation from existing samples.2 The gain of the reconstruction ﬁlter is T and is
2Interpolation is brieﬂy introduced in Chapter 16.

Signals and Systems
633
X( f )
Y( f )
S( f )
H( f )
y(t)
x(t)
f
f
(a)
(b)
(c)
(d)
–f0
f0
–f0
f0
0
–Fs
–2Fs
Fs
2Fs
0
f
–Fs
Fs
fc
f
–fc
0
2Fs
0
1
T
1
T
1
T
1
T
1
T
1
T
–2Fs
–f0
f0
f
–Fs
Fs
2 Fs
0
–2 Fs
T
X( f )
1
(e)
1
FIGURE 10.4 Frequency-domain representation of sampling and error-free reconstruction pro-
cess. A strictly low-pass signal [X( f ) = 0,
| f | > f0] may be reconstructed (also said to be
recovered) from its samples by passing them through an ideal low-pass ﬁlter with cutoff frequency
at fc [H( f ) = 0, | f | > fc]. Reconstruction is error-free if samples are taken at a rate higher than
the Nyquist rate (Fs ≥2 f0), and if the cutoff frequency of the ideal ﬁlter is f0 ≤fc ≤(Fs −f0)
as seen in this ﬁgure. For practical reasons, one often chooses fc = Fs/2.
chosen to compensate for the gain 1/T introduced in y(t) by sampling. The cutoff
frequency of the reconstruction ﬁlter is generally chosen to be fc = Fs/2. In that case
h(t) = sin π Fst
π Fst
,
x(t) =
∞

−∞
x(n)sin π Fs(t −nT )
π Fs(t −nT )
The recovery formula states that x(t) may be built from blocks of x(n)h(t −nT ). The
building blocks are formed by shifting h(t) (whose central lobe is T seconds wide) by
nT units of time and multiplying it by sample values x(n). Note that the above structure
places the peak of each shifted h(t) at a sampling instance with its zero-crossings at the

634
CHAPTER 10
Time-Domain Sampling and Reconstruction
neighboring sampling instances:
h(t) =

1,
t = 0
0,
t = nT ̸= 0
Therefore, at t = nT the value of the above sum is exactly equal to the value of the
sample at that point. Figure 10.5 simulates the reconstruction process by such an ideal
ﬁlter in the time domain.
190
5
10
0
200
210
220
230
240
190
200
210
220
230
240
110
0
120
130
140
150
160
170
180
190
1
–0.2
5
10
0
5
10
0
40
50
60
70
80
90
(c) Time (s)
(a) Time (s)
(d) Time (s)
(b) Time (s)
FIGURE 10.5 Time-domain representation of reconstruction process. This ﬁgure illustrates, in the time domain, how
a signal is reconstructed from unit-impulse responses of the reconstructed ﬁlter, weighted by sample values and added
together. All abscissa are time in seconds. (a) the signal, (b) ﬁlter’s unit-impulse response, (c) the output of the ﬁlter, (d)
reconstruction of the signal by the building blocks.
The signal shown in (a) is sampled every 10 seconds, Fs = 0.1 Hz. The sam-
pled signal is made of impulses whose strengths are equal to the samples. The ideal
reconstruction ﬁlter is low-pass with cutoff at fc = Fs/2 = 0.05 Hz. The unit-impulse
response of such a ﬁlter is h(t) = 10 sin(0.1πt)/(πt). In the simulation, to make h(t)
realizable it is shifted by 150-second to the right as shown in (b). Note that the base of
the main lobe of h(t) is 20 seconds wide, corresponding to a cutoff frequency at 0.05 Hz.
The output of the ﬁlter is shown in (c), to be compared with the signal shown in (a). The
output is the sum of contributions from individual samples, which are formed by shifting
the unit-impulse response by nT units of time and multiplying it by sample values x(n),
which we will call the building blocks x(n)h(t −150 −nT ). These are shown in (d).
Note that the zero-crossings of each building block occur exactly at the locations of all
other samples. Therefore, at each sample time the output has one contribution, that of
its own sample. The reconstruction is therefore exact.

Signals and Systems
635
10.4
Sample and Hold
In the previous section we used an ideal ﬁlter to reconstruct the continuous-time signal
from its samples. The method produces the exact value of x(t) from its samples. It,
however, requires access to all samples during −∞< t < ∞. This is because the unit-
impulse response of the ideal low-pass ﬁlter used in that reconstruction process extends
from −∞to ∞. That unit-impulse response, in time and frequency domains, is shown
in Figure 10.6(a). Several other types of ﬁlter are used to reconstruct a continuous-time
signal from the samples. The simplest one, often used in digital-to-analog converters,
Frequency (kHz)
1
0
–6
–4
–2
0
2
4
6
–6
–4
–2
0
2
4
6
1
0
0
–3
3
–2
–1
2
1
0
3
–2
–3
–1
2
1
0
0
Frequency (kHz)
Time (msec)
(a)
(b)
10–3
10–3
Time (msec)
FIGURE 10.6 Reconstruction ﬁlters. The response characteristics of two types of reconstruction ﬁlters, intended for a
sampling rate Fs = 1 kH, are shown. The ﬁlters’ impulse responses are in the left-hand side and the normalized magnitude
of their Fourier transforms are in the right-hand side. Time is in msec and frequency is in KHz. The upper row shows
characteristics of an ideal low-pass ﬁlter with a cutoff frequency at Fs/2 = 500 Hz and the lower row shows those of a
1-msec S/H ﬁlter.
a.
Ideal low-pass ﬁlter
h(t) = sin(1000πt)
1000πt
H( f ) =

10−3,
−500 < f < 500
0,
elsewhere
b.
S/H ﬁlter
h(t) =

1,
0 < t < 1 msec
0,
elsewhere
H( f ) = sin(π f/1,000)
π f
e−jπ f/1,000

636
CHAPTER 10
Time-Domain Sampling and Reconstruction
is the method of sample and hold, shown by S/H. In the sample and hold method, instead
of an ideal reconstruction low-pass ﬁlter we use the ﬁlter with an impulse response of
h(t) =
1,
0 < t < T
0,
elsewhere
where T is the sampling interval. The frequency response of the sample and hold ﬁlter
is
H( f ) =
	 ∞
−∞
h(t)e−j2π f tdt =
	 T
0
e−j2π f tdt = sin(π f T )
π f
e−jπ f T where T = 1
Fs
The unit-impulse response and the frequency response of the sample and hold ﬁlter are
shown in Figure 10.6(b) and are to be compared with the ideal ﬁlter of Figure 10.6(a).
The signal produced by the S/H process will acquire a stepwise structure, as seen in the
lower trace of Figure 10.24(a), with sharp discontinuities that mainfest themselves as
high frequencies. The reconstructed signal, therefore, will contain high frequencies that
don’t exist in the original signal. These high frequencies may be reduced by increasing the
sampling rate (or by increasing the number of samples by a process called interpolation)
and by adding a low-pass ﬁlter following the sample and hold.
Example
10.5
Consider a sample and hold exercise where a 10-Hz sinusoidal signal, Figure 10.7(a),
is sampled at the rate of Fs. Samples are then passed through a hold ﬁlter followed by
a ﬁrst-order low-pass ﬁlter [time constant = 1 msec, Figure 10.7(b)] for smoothing.
Figure 10.7(c) shows the output of the hold ﬁlter (on the left-hand side) and that of
the low-pass smoothing ﬁlter (on the right-hand side) for Fs = 100 Hz. Doubling the
sampling rate to Fs = 200 Hz reduces the high frequencies in the output of the ﬁlters
as shown in Figure 10.7(d). Increasing sampling rate by a factor 5, to Fs = 500 Hz,
results in Figure 10.7(e), in which the reconstructed signal is closer to x(t) than in
Figure 10.7(c) and (d). The sampling and reconstructions in Figure 10.7 are summa-
rized by the following.
Original signal
x(t) = cos(20πt)
Figure 10.7(a)
Sampled signal
∞

−∞
cos(20πnT )δ(t −nT ),
T = 1
Fs
S/H ﬁlter
h1(t) = u(t) −u(t −T )
Low-pass ﬁlter
h2(t) = e−1000tu(t)
Figure 10.7(b)
S/H and the low-pass ﬁlter
h(t) = h1(t) ⋆h2(t)
Reconstructed signal
∞

−∞
cos(20πnT )h(t −nT )
Figure 10.7(c), Fs = 100 Hz
Figure 10.7(d), Fs = 200 Hz
Figure 10.7(e), Fs = 500 Hz

Signals and Systems
637
1
0.5
0
–1
–0.5
1
0
1
0.5
0
–1
–0.5
1
0.5
0
–1
–0.5
1
0.5
0
–1
–0.5
1
0.5
0
–1
–0.5
1
0.5
0
–1
–0.5
1
0.5
0
–1
–0.5
–30
–20
–10
0
10
20
30
–30
–20
–10
0
10
20
30
–30
–20
–10
0
10
20
30
–30
–20
–10
0
10
20
30
–30
–20
–10
0
10
20
30
–30
–20
–10
0
10
20
30
–30
–20
–10
0
10
20
30
–30
–20
–10
0
10
20
30
(a)
(b)
(c)
(d)
(e)
Time (msec)
Time (msec)
FIGURE 10.7 Sampling and reconstruction of a sinusoid by sample-and-hold followed by low-pass ﬁltering, for three
sampling rates. Increasing the number of samples reduces the high-frequency components generated in a sample and hold
(S/H) operation, and provides looser requirements for a low-pass ﬁlter to follow it. For detail see Example 10.5.

638
CHAPTER 10
Time-Domain Sampling and Reconstruction
10.5
Sampling Nearly Low-Pass Signals
Consider a signal x(t) in which the major frequency components, but not all of them,
are limited to below frequency f0. The signal is not strictly low-pass as it contains some
power in the frequency range beyond f0, which diminishes as the frequency increases.
Sample x(t) uniformly every T sec to obtain y(t). Can x(t) be recovered error-free from
its samples? Strictly speaking, as we have seen in the previous sections, the answer is
negative, as illustrated by Example 10.6 below.
Example
10.6
Consider a two-sided even exponential signal with a time constant of τ sec, and its
Fourier transform.
x(t) = e−|t|/τ,
X( f ) =
2τ
1 + 4π2τ 2 f 2
The signal is not strictly a band limited low-pass one. However, its Fourier transform
diminishes as the frequency increases. Sample x(t) uniformly every T sec, corre-
sponding to a sampling rate of Fs = 1/T Hz. The sampled function y(t) and its
Fourier transform, as derived in section 10.2, are
y(t) =
∞

n=−∞
e−T |n|
τ δ(t −nT ),
Y( f ) = 1
T
∞

n=−∞
X

f −n
T

Y( f ) is the scaled sum of periodic repetitions of X( f ) every Fs Hz. To recover the
original signal from its samples, y(t) is passed through an ideal low-pass ﬁlter with
gain T and cutoff frequency fc = Fs/2 Hz. The output of the ﬁlter is named z(t).
The Fourier transform of the output of the ﬁlter is
Z( f ) =
∞

n=−∞
X

f −n
T

, | f | < fc
= 0, elsewhere
Due to the interference by the tails of neighboring lobes in Y( f ) (which cannot be
totally eliminated by the ﬁlter), Z( f ) cannot be a duplicate of X( f ) and z(t) cannot
be an error-free reconstruction of x(t). For example, at fc = Fs/2 we will have
Z( fc) = 2RE{X( fc) + X(3 fc) + X(5 fc) + · · ·}
= 2τ

1
1 + β2 +
1
1 + 9β2 +
1
1 + 25β2 + · · ·

= 2τ
∞

n=1,n odd
1
1 + β2n2 , where β = πτ Fs
At sufﬁciently high sampling rates, however, the spacing Fs in the frequency domain
becomes large and the interference between the tails of repeated X( f −n/T ) be-
comes negligible, reducing the reconstruction error. A numerical example is shown in

Signals and Systems
639
Figure 10.8. A double-sided even exponential signal x(t) = e−|t|/4, along with its
normalized Fourier transform is shown in (a). The signal is sampled every 4 seconds,
corresponding to a rate of Fs = 0.25 Hz in (b). The sampled signal, y(t), is on the
left-hand side, where impulse samples are shown by arrows. The Fourier transform of
y(t) is shown on the right. As expected, the Fourier transform of y(t) is periodic in the
frequency domain, with period 0.25 Hz. The sampled function in (b) is passed through
an ideal low-pass ﬁlter with cutoff frequency at 0.125 Hz. The Fourier transform,
Z( f ),oftheﬁlter’soutputisshownontherightin (c).Thetime-domainrepresentation
of the ﬁlter’s output, z(t), is shown on the left, to be compared with the original signal
in (a). It is seen that recovery of the above low-pass signal (which is not strictly band
limited) contains errors even when the reconstruction ﬁlter is ideal.
1
0
–20
–15
–10
–5
0
5
10
15
20
1
0
–20
–15
–10
–5
0
5
10
15
20
1
0
–20
–15
–10
–5
0
5
10
15
20
1
0
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.3
0.4
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.3
0.4
–0.4 –0.3 –0.2
–0.1
0
0.1
0.2
0.3
0.4
1
0
1
0
Time (s)
Frequency (Hz)
(a)
(b)
(c)
FIGURE 10.8 Error in signal recovery. (a) A double-sided even exponential function x(t) and its Fourier transform. (b)
Sampled function y(t) and its Fourier transform. (c) Reconstructed signal z(t) and its Fourier transform. The reconstruction
has errors because x(t) is not strictly band limited and low-pass. See Example 10.6.

640
CHAPTER 10
Time-Domain Sampling and Reconstruction
Reducing Error in Signal Recovery by Increasing the
Sampling Rate
A low-pass signal, which is not strictly band limited, may be recovered with less error
if higher sampling rates are used. This is because higher sampling rates provide more
spacing in the frequency domain between the repeated segments of the Fourier transform
of the sampled signal, thus reducing overlap between neighboring segments. This is
illustrated in the following example.
Example
10.7
Revisiting Example 10.4
In Example 10.4 we sampled a 50-second continuous-time triangular pulse x(t) at
three different rates. Because the pulse is time limited, its transform is not band
limited. Theoretically, the signal may not be recovered from its samples error-free,
regardless of how high the sampling rate is. However, as the major share of the energy
in the signal is found in frequencies within the central lobe (below 0.04 Hz) and higher
sampling rates provide larger separations between the repetitions of the main lobe in
the frequency domain, the result is lower error at the output of the reconstruction ﬁlter,
which low-pass ﬁlters the central lobe in Y( f ) from its neighboring repetitions. This
is illustrated in Figure 10.9. The time functions are on the left with their normalized
Fourier transforms on the right. The x(t) and its Fourier transform are shown in (a).
The reconstruction error is considerable in (b) (sampled every 12 sec) but almost
negligible in (c) (sampled every 2 sec, six times faster than in (b)).
1
0
–30
–20
–10
0
10
20
30
1
0
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.3
0.4
(a)
FIGURE 10.9 Signal recovery at higher sampling rate. This ﬁgure, to be continued on the next page, samples a 50-second
triangular pulse, shown in (a), at intervals T = 12, and 2-second [shown in (b) and (c), respectively] and reconstructs it
by passing the samples through an ideal low-pass ﬁlter with cutoff frequency at Fs/2. It visually demonstrates the effect of
higher sampling rate in reducing recovery error. Time functions are shown in the left column with their Fourier transforms
in the right column. The magnitudes of the transforms are all normalized to have maxima 1. The time scale is in seconds
and the frequency scale is in Hz. The cutoff frequency of the low-pass reconstruction ﬁlter is Fs/2. The reconstruction
error is considerable in (b) but almost negligible in (c).

Signals and Systems
641
1
0
–0.4 –0.3 –0.2 –0.1
0
0.1
0.2
0.3
0.4
1
0
–30
–20
–10
0
10
20
30
1
0
–30
–20
–10
0
10
20
30
(b)
1
0
–0.5
–0.3
–0.4
–0.2 –0.1
0
0.1
0.2
0.3
0.4
1
0
–30
–20
–10
0
10
20
30
1
0
–0.3
–0.4
–0.2 –0.1
0
0.1
0.2
0.3
0.4
1
0
–30
–20
–10
0
10
20
30
(c)
1
0
–0.5
–0.3
–0.4
–0.2 –0.1
0
0.1
0.2
0.3
0.4
Time (s)
Frequency (Hz)
FIGURE 10.9 (Continued)

642
CHAPTER 10
Time-Domain Sampling and Reconstruction
10.6
Aliasing and Leakage
From an examination of the Fourier transform of the output of the reconstruction ﬁlter
we observe that the time function can become different from the original signal in two
respects. One possible difference is at low frequencies where some of the high-frequency
components of x(t) are shifted to lower frequencies. This is called aliasing. This effect
is due to the fact that the original signal is not band limited. The reconstruction ﬁlter,
even if it is ideal, cannot eliminate aliasing unless the original signal is band limited and
sampling rate is greater than or equal to the Nyquist rate.
The second possible difference between the reconstructed signal and the original
signal may be found at high frequencies where because of windowing operations the
spectra spread and the high frequencies leak back to the reconstructed signal. By making
the low-pass reconstruction ﬁlter close to an ideal ﬁlter and processing long segments of
data we can reduce the leakage.
In summary, for an error-free sampling and recovery operation, it is important that
two conditions be satisﬁed. One condition is that the signal be low pass and the sampling
rate be at least twice the highest frequency present in it (the Nyquist rate). If this condition
is not met, aliasing occurs. To eliminate aliasing, we make the signal strictly low pass by
passing it through a low-pass ﬁlter, called an anti-aliasing ﬁlter, before sampling. The
second condition is that the reconstruction operation be ideal, otherwise leakage occurs.
Example
10.8
Illustration in the frequency domain
A sinusoidal signal x(t) = 2 cos(2π f0t) is sampled at the rate Fs Hz. To recover the
signal, the samples are passed through an ideal low-pass ﬁlter with a gain T = 1/Fs
and cutoff frequency slightly greater than f0. Find the output of the ﬁlter for
a.
Fs = 4 f0
b.
Fs = 1.5 f0
c.
Fs = 1.1 fo
In each case, determine if aliasing has occurred or not.
Solution
Following the approach of sections 10.2 and 10.3 we ﬁrst observe the Fourier trans-
forms of the ﬁlter’s input and output.
x(t) = 2 cos 2π f0t,
X( f ) = δ( f + f0) + δ( f −f0),
Two unit impulses at ± f0,
s(t) =
∞

n=−∞
δ(t −nT ),
S( f ) = 1
T
∞

k=−∞
δ( f −kFs),
T = 1
Fs
,
Impulses at kFs, k integer
y(t) = x(t)s(t),
Y( f ) = X( f ) ⋆S( f ) = 1
T
∞

k=−∞
X( f −kFs),
Impulses at ± (kFs ± f0)

Signals and Systems
643
Convolution of X( f ) with S( f ) generates spectral line at (−2Fs ± fo), (−Fs ±
fo), ± f0, (Fs ± f0), (2Fs ± f0), . . .. The components that are at f0 or below it
pass through the ﬁlter and become parts of the reconstructed signal. The results are
summarized in the following table.
Fs
Frequency Components in y (t)
Output
Comments
a.
4 f0
± f0, ± 3 f0, ± 5 f0, ± 7 f0, · · ·
2 cos 2π f0t
Exact recovery,
see Figure 10.10(a).
b.
1.5 f0
±0.5 f0, ± f0, ± 2 f0, ± 2.5 f0, · · ·
2 cos π f0t + 2 cos 2π f0t
Aliasing,
see Figure 10.10(b).
c.
1.1 f0
±0.1 f0, ± f0, ± 1.2 f0, ± 2.1 f0, · · ·
2 cos 0.2π f0t + 2 cos 2π f0t
Aliasing.
H( f )
–f0
f0
f
0
–f0
f0
0
fc
f
–fc
0
1
T
1
T
1
T
1
T
T
1
1
X( f )
–f0
f0
f
0
1
1
1
1
X( f )
–Fs
Fs
–Fs
Fs
f
f
0
S( f )
Y( f )
H( f )
–f0
f0
f
0
0
fc
f
–fc
0
1
T
1
T
T
1
1
X( f )
–f0
f0
f
0
X( f )
–2Fs
–Fs
2Fs
Fs
–2Fs
2Fs
–Fs
Fs
f
f
0
S(f )
Y( f )
(a)
(b)
FIGURE 10.10 Sampling and reconstruction of cos(2π f0t). (a) The signal may be reconstructed from samples taken
at the rate Fs = 4 f0. (b) At the rate Fs = 1.5 f0 aliasing adds a low-frequency component at 0.5 f0. See Example 10.8.

644
CHAPTER 10
Time-Domain Sampling and Reconstruction
In all cases the ± f0 components of y(t) are due to convolution of X( f ) with the
impulse in S( f ) at the origin. The convolution of X( f ) with the impulses at ±Fs
generates two impulses at ±(Fs −f0). To avoid aliasing, these should not pass through
the reconstruction ﬁlter, that is Fs −f0 > f0 or Fs > 2 f0. This condition is satisﬁed
in part a, where Fs = 4 f0 and ±(Fs −f0) = 3 f0 (outside the ﬁlter’s range). In
part b, where Fs = 1.5 f0, ±(Fs −f0) = ±0.5 f0 passes through the ﬁlter and
contributes 2 cos π f0t to the reconstructed signal. Similarly, at the rate Fs = 1.1 f0
(part c) we have ±(Fs −f0) = ±0.1 f0 which appears as 2 cos 0.2π f0t in the output.
In the above discussion X( f ) was made of a pair of impulses representing x(t),
−∞< t < ∞. As for leakage, if the signal is windowed its spectrum spreads and
some of the high frequencies may then leak through the ﬁlter, resulting in non-ideal
reconstruction.
10.7
Frequency Downshifting
Low-sampling rates produce aliasing. In some cases this may be a desirable feature.
The aliasing produced by a low-sampling rate (i.e., lower than the Nyquist rate) may
be used to shift down the frequency band of a periodic signal. A sequential repetitive
sampling performed at much lower than the Nyquist rate downshifts the spectrum of a
high-frequency signal, allowing its observation and recording by instruments that have a
low bandwidth. Example 10.9 below illustrates the concept of frequency downshifting.
Frequency downshifting is further illustrated in Example 10.10 and problems 5, 8, and
9 at the end of this chapter.
Example
10.9
Consider the day/night temperature proﬁle at a given location. This may be measured
in one of two ways. In one approach measurements are taken every hour on the hour,
24 measurements in 24 hours. See Table 10.1(a) and Figure 10.11(a). The temperature
between the hours may then be estimated by a straight line interpolation of the two
neighboring measurements, or by a second-order polynomial interpolation using three
measurements, and so on.
In the second approach, 24 measurements may be taken starting at the 00 hour
with a 25-hour sampling interval, and taking a total of 24 days. In the absence of
a noticeable temperature trend during the 24-day measurement period, compressing
the time scale by a factor of 24 will yield a proﬁle similar to that of the ﬁrst approach.
See Table 10.1(b) and Figure 10.11(b).

Signals and Systems
645
TABLE 10.1a Sampling Temperature
Every Hour
Day, Hour
Temperature in C◦
1−00
20
1−01
19
1−02
18
1−03
18
1−04
19
1−05
19
1−06
20
1−07
20
1−08
21
1−09
22
1−10
24
1−11
26
1−12
28
1−13
30
1−14
32
1−15
32
1−16
31
1−17
30
1−18
29
1−19
27
1−20
25
1−21
23
1−22
21
1−23
20
TABLE 10.1b Sampling Temperature
Every 25 Hours
Day, Hour
Temperature in C◦
1−00
20
2−01
19
3−02
18
4−03
19
5−04
19
6−05
20
7−06
21
8−07
22
9−08
22
10−09
25
11−10
26
12−11
28
13−12
31
14−13
32
15−14
33
16−15
31
17−16
30
18−17
29
19−18
28
20−19
26
21−20
24
22−21
22
23−22
22
24−23
21
0
5
10
15
20
15
20
25
30
35
Temperature in Celsius
15
20
25
30
35
Temperature in Celsius
Time (Hour)
(a)
0
5
10
15
20
Time (Hour)
(b)
FIGURE 10.11 Sampling temperature. Temperature data given in Table 10.1 are plotted in this ﬁgure. (a) Temperature
measurements at a location sampled every hour show the 24-hour trend. (b) Under stable day-to-day weather conditions
the above trend may also be deduced from measurements taken at the much lower rate of one sample every 25 hours
during a period of 24 days. The sampling process shown in (b) illustrates the concept of frequency downshifting.

646
CHAPTER 10
Time-Domain Sampling and Reconstruction
Example
10.10
Frequency downshifting may be examined by sampling a sinusoidal signal at a low
rate and reconstructing it by low-pass-ﬁltering the samples (e.g., by connecting the
consecutive samples). Refer to Figure 10.12. Sample a sinusoidal signal (period = T0)
every T = (1 + α)T0 seconds. The time function and its sample values are
x(t) = sin
2πt
T0

t = nT = n(1 + α)T0
x(n) = x(t)

t=nT = sin
2πnT
T0

= sin[2π(1 + α)n] = sin(2παn)
–0.04
–1.5
–1
–0.5
–0.03
–0.02 
–0.01
0
0.01
0.02
0.03
0.04
0
0.5
1
1.0
–0.04
–1.5
–1
–0.5
–0.03
–0.02 
–0.01
0
0.01
0.02
0.03
0.04
0
0.5
1
1.0
Time (s)
(a)
(b)
FIGURE 10.12 Frequency downshifting. (a) A 100-Hz sinusoidal signal with period =
10 msec is sampled every 11 msec (Fs = 90.91 Hz). In this way the succeeding samples jump
one period plus 1 msec (away from the previous samples). After 10 samples are taken, the cycle
repeats, forming a periodic sequence with period 110 msec. (b) Sample values are identical with
those taken from a sinusoidal signal with period = 110 msec. The signal to be reconstructed from
the samples is a sinusoid with the frequency f = 100 −90.91 = 9.09 Hz (period = 110 msec).
In the above exercise, the frequency of the sinusoid is reduced by a factor α/(1 + α), α = 0.1.
The following two examples provide further illustrations, in the time and frequency domains, of
the effects of sampling a sinusoidal signal at a low rate.

Signals and Systems
647
In constructing a continuous-time signal from x(n) we revert to n = t/T .
x(n) = sin(2παn)
n = t
T
ˆx(t) = x(n)

n=t/T = sin
2παt
T

= sin

α
1 + α
2πt
T0

= x

α
1 + α t

Example
10.11
A 900-Hz continuous-time sinusoidal signal x(t) = cos(1,800πt) is sampled by a
periodic narrow rectangular pulse train (10 µs wide and 10 V base-to-peak) at the
rate of Fs = 1 kHz, which is less than twice its frequency. Samples are then passed
through an ideal low-pass ﬁlter with a DC gain of 10 and a cutoff frequency of
500 Hz. Show that the ﬁlter’s output is z(t) = cos(200πt).
Solution
The sampling pulse can be modeled by an impulse whose strength is 10 × 10−5 =
10−4. To sample x(t) we, therefore, multiply it by the sampling signal s(t) at the
1-kHz rate, producing the sampled function y(t). In the time domain
x(t) = cos(1,800πt)
s(t) = 10−4
∞

n=−∞
δ

t −
n
1,000

y(t) = x(t)s(t) = 10−4
∞

n=−∞
cos(1.8πn)δ

t −
n
1,000

In the frequency domain
X( f ) = 1
2 [δ( f −900) + δ( f + 900)]
S( f ) = 103 × 10−4
∞

k=−∞
δ( f −1,000k)
Y( f ) = X( f ) ⋆S( f ) = X( f ) ⋆10−1
∞

k=−∞
δ( f −1,000k)
= 1
20
∞

k=−∞
[δ( f −1,000k −900) −δ( f −1,000k + 900)]
The only component that passes through the low-pass ﬁlter with cutoff frequency at
500 Hz is the one at 100 Hz [to be called z(t)]. Other frequencies are all blocked. The
output of the low-pass ﬁlter is
Z( f ) = 10 × 1
20 [δ( f −100) + δ( f + 100)]
z(t) = cos(200πt)

648
CHAPTER 10
Time-Domain Sampling and Reconstruction
Example
10.12
An amplitude-modulated bandpass signal is modeled by
x(t) = a(t) cos(2000πt),
a(t) =

sin(100πt)
100πt
2
a.
Show that X( f ) = 0 for 900 < f < 1,100 Hz.
b.
The signal x(t) is sampled at the rate of 1 kHz and then passed through an ideal
low-pass ﬁlter with cutoff frequency at 500 Hz and 60 dB attenuation. Show
that the ﬁlter’s output is a(t).
Solution
a.
The Fourier transform A( f ) of a(t) is a triangle with the base −100< f <
100 Hz and height A(0) = 0.01. See Figure 10.13(a). The low-pass signal a(t)
modulates the 1-kHz sinusoidal carrier and produces x(t). The Fourier
transform of the carrier is made of two impulses at ±1,000 Hz. See Figure
10.13(b). Modulation shifts A( f ) to the locations of those two impulses
X( f ) = 1
2 [A( f −1,000) + A( f + 1,000)]
limiting its frequency band to (1,000 −100) < f < (1,000 + 100), or 900 to
1,100 Hz. See Figure 10.13(c).
b.
By sampling x(t) at the rate of 1 kHz, we obtain y(t) = x(t)s(t), where
s(t) =
∞

n=−∞
δ(t −
n
1,000)
S( f ) = 1,000
∞

k=−∞
δ( f −1,000k)
Y( f ) = X( f ) ⋆S( f ) = X( f ) ⋆

1,000
∞

k=−∞
δ( f −1,000k)

= 1,000
2
∞

k=−∞
[A( f −1,000 −1,000k) + A( f + 1,000 −1,000k)]
The ideal low-pass ﬁlter with cutoff at 500 Hz blocks all components of Y( f ) except
the triangle centered around origin generated from k = ±1. The ﬁlter’s output is,
therefore, a(t).

Signals and Systems
649
1
0
–20 –15 –10 –5
0
5
10
15
20
–20 –15 –10 –5
0
5
10
15
20
–20 –15 –10 –5
0
5
10
15
20
–20 –15 –10 –5
0
5
10
15
20
10–2
10–2
0
–100
0
100
0.5
0
–1,000
0
1,000
–1,000
0
1,000
(a)
1
0
–1
(b)
–100
0
100
0
0
1
0
(d)
1
0
–1
(c)
Frequency (Hz)
Time (msec)
10–2
2
FIGURE 10.13 Downshifting an AM signal. This ﬁgure illustrates downshifting the continuous spectrum of an
amplitude-modulated (AM) bandpass signal x(t).
x(t) = a(t) cos(2,000πt), where a(t) =

sin(100πt)
100πt
2
Time functions are shown in the left-hand column with the time scale in seconds. Transforms are normalized and are
shown in the right-hand column, across from their respective time functions, with the frequency scale in Hz.
a. The modulating waveform a(t) is a low-pass signal with a triangular spectrum, limited to | f | < 100 Hz.
b. The carrier signal is cos 2,000πt with two spectral lines at ±1 kHz.
c. The modulation operation shifts the spectrum of a(t) to center around ±1 kHz. The AM signal x(t) is, therefore,
bandpass limited to 1,000 ± 100 Hz.
d. To downshift the AM signal, x(t) is sampled at the rate Fs = 1 kHz and the sampled signal y(t) is passed through an
ideal low-pass ﬁlter. The output of the ﬁlter has a triangular spectrum identical with A( f ). The ﬁlter’s output is a(t), a
downshifted x(t).

650
CHAPTER 10
Time-Domain Sampling and Reconstruction
10.8
Summary of Sampling and Reconstruction
Process
A block diagram of sampling a low-pass signal and its reconstruction is shown in Figure
10.14(a). First, the signal to be sampled is passed through a low-pass ﬁlter to cutoff (or re-
duce) undesired high-frequency components (e.g., noise or high-frequency components
which carry no useful information). This ﬁlter helps set the sampling rate and prevents
aliasing, thus is called an anti-aliasing ﬁlter. It could be a simple ﬁrst-order RC (active
or passive) ﬁlter, and is found in almost all sampling devices such as analog-to-digital
(A/D) converters.
Next, the signal x(t) is multiplied by a train of unit impulses every T seconds, called
the sampling function and designated by s(t).
s(t) =
∞

n=−∞
δ(t −nT ), S( f ) = Fs ×
∞

k=−∞
δ( f −kFs)
where Fs = 1/T Hz is the sampling rate. The resulting sampled signal, which is a
continuous-time function, is designated by y(t).
y(t) = x(t) × s(t) = x(t) ×
∞

n=−∞
δ(t −nT ) =
∞

n=−∞
x(nT )δ(t −nT )
Y( f ) = X( f ) ⋆S( f ) = X( f ) ⋆

Fs ×
∞

k=−∞
δ( f −kFs)

= Fs ×
∞

k=−∞
X( f −kFs)
Impulse samples then pass through a low-pass ﬁlter with the unit-impulse response h(t).
The output of the ﬁlter is
z(t) = h(t) ⋆y(t) = h(t) ⋆
∞

n=−∞
x(nT )δ(t −nT ) =
∞

n=−∞
x(nT )h(t −nT )
Z( f ) = Fs × H( f ) ×
∞

k=−∞
X( f −kFs)
s(t)
A
D
D
A
x(t)
z(t) = x(t)
Interpolation
Digital Filter
Ideal Low-Pass
Analog Filter
x(t)
z(t) = x(t)
(a) Representation in the continuous-time domain.
(b) Representation in the digital domain employing
     A/D converter, digital filter, and D/A converter.
^
^
FIGURE 10.14 Block diagram summary of sampling and reconstruction process in continous- and discrete-time do-
mains. Reconstruction is done by passing y(t) through a ﬁlter with unit-impulse response h(t). Filter’s output is z(t).

Signals and Systems
651
Depending on the sampling rate and the reconstruction ﬁlter, z(t) may be equal or close
to x(t). We designate the rms of reconstruction error by E and deﬁne it by:
For energy signals:
E2 =
	 ∞
−∞
|x(t) −z(t)|2dt
For power signals:
E2 = lim
T →∞
1
2T
	 T
−T
|x(t) −z(t)|2dt
Note that the independent variable throughout the block diagram of Figure 10.14(a)
is continuous time. Each sample is represented by an impulse whose strength is equal
to the value of the sample. All functions [x(t), s(t), y(t), and z(t)] are functions of
continuous time and have generalized Fourier transforms. The analysis uses continuous-
time mathematics.
When processing the samples by digital devices such as computers, two additional
speciﬁcations enter the process. First, each sample is represented by a number equal
to its value. The sampled function is, therefore, represented by a sequence of numbers
called the discrete-time signal x(n). The independent variable is the discrete-time n,
which is also an integer. Second, the magnitude of x(n) is discretized and shown by a
binary word of length N (corresponding to 2N discrete levels). The resulting signal is
called a digital signal and the devices that perform the operation and its converse are
called analog-to-digital (A/D) and digital-to-analog (D/A) converters, respectively. The
process is shown in Figure 10.14(b). The digital ﬁlter included in Figure 10.14(b) can
perform decimation, interpolation, and ﬁltering. It can simplify the analog reconstruction
ﬁlter placed at the end of the process. The topic of A/D and D/A conversion will not be
discussed in the present chapter.
10.9
Complex Low-Pass Signals
We have seen that the Fourier transform of a real valued function v(t) holds the conjugate
symmetry: V ( f ) = V ∗(−f ). If V ( f ) ̸= V ∗(−f ), then v(t) is a complex function of
time and may be written as v(t) = vc(t) + jvs(t). A class of signals of practical interest
in communication and signal processing employ complex low-pass signal models to
represent more general bandpass signals, as will be seen in section 10.10. In this section
we illustrate the complex low-pass signal by way of an example.
Example
10.13
The Fourier transform of a complex low-pass signal v(t) is
V ( f ) =



a,
−fℓ< f < 0
b,
0 < f < fh
0,
elsewhere
The bandwidth is limited to −fℓ< f < fh as shown in Figure 10.15(a).
a.
Find v(t) and show how it may be written as v(t) = vc(t) + jvs(t).
b.
Find vc(t) and vs(t) when fℓ= fh = f0.

652
CHAPTER 10
Time-Domain Sampling and Reconstruction
V( f )
b
a
0
–f
fh
f
(a)
(b)
b/2
(a + b)/2
0
–fh
fh
–f
f
f
V( f) + V( –f )
V( f) – V( –f )
2
–b/2
b/2
(b – a)/2
(a – b)/2
0
–fh
fh
–f
f
f
2
FIGURE 10.15 Fourier transform of a complex-valued low-pass signal (a), and its even and odd
components (b).
Solution
a.
We ﬁnd v(t) by taking the inverse Fourier transform of V ( f )
v(t) = a
	 0
−fℓ
e j2π f td f + b
	
fh
0
e j2π f td f
= 1
πt

ae−jπ fℓt sin(π fℓt) + be jπ fht sin(π fht)

=
1
2πt [a sin(2π fℓt) + b sin(2π fht)] + j
πt

−a sin2(π fℓt) + b sin2(π fht)

Alternative Approach
Split V ( f ) into two components and take their inverse Fourier transforms as shown
below.
V1( f ) =
a,
−fℓ< f < 0
0,
elsewhere
⇒
v1(t) = a sin(π fℓt)
πt
e−jπ fℓt
V2( f ) =
b,
0 < f < fh
0,
elsewhere
⇒
v2(t) = bsin(π fht)
πt
e jπ fht
V ( f ) = V1( f ) + V2( f )
⇒
v(t) = v1(t) + v2(t)
b.
When fℓ= fh = f0 we have
v(t) = 1
πt (a + b) sin(π f0t) cos(π f0t) −j
πt (a −b) sin(π f0t) sin(π f0t)
= (a + b)sin(2π f0t)
2πt
−j(a −b)sin2(π f0t)
πt
from which
vc(t) = (b + a)sin(2π f0t)
2πt
vs(t) = (b −a)sin2(π f0t)
πt
v(t) = vc(t) + jvs(t)

Signals and Systems
653
Note: In this example vc(t) and vs(t) are also the inverse transforms of the odd and
even parts of V ( f ), respectively.
10.10
Bandpass Signals and Their Sampling
Bandpass Signals
The spectrum of a bandpass signal x(t) is limited to frequencies between fl and fh
X( f ) = 0, | f | < fℓand | f | > fh
In communication engineering, bandpass signals are also called narrowband signals.
Examples are amplitude-modulated signals and the general case of single side-band
signals.
Amplitude Modulation
Amplitude-modulated signals constitute a special case of narrowband signals. They are
represented by x(t) = a(t) cos(2π fct), where a(t) is a real-valued low-pass signal,
A( f ) = A∗(−f ), with frequencies limited to 0 ≤f ≤f0 and fc > f0. X( f ) is then
band limited to fc −f0 ≤| f | ≤fc + f0.
General Case
In general, a bandpass signal x(t) may be represented by two amplitude-modulated
components sharing the same center frequency fc but 90◦out of phase with each other:
x(t) = vc(t) cos(2π fct) −vs(t) sin(2π fct)
This is called the quadrature carrier description of the bandpass signal. The signal
v(t) = vc(t) + jvs(t) is called the complex low-pass signal. vc(t) and vs(t) modulate
the envelopes of the carriers (at fc) and are low-pass signals with bandwidth B/2 Hz,
where B = fh −fℓ. They are called the in-phase and the quadrature parts, respectively.
Alternately, a bandpass signal may be represented by an amplitude- and angle-
modulated carrier at fc
x(t) = a(t) cos[2π fct + φ(t)]
= a(t) cos φ(t) cos(2π fct) −a(t) sin φ(t) sin(2π fct)
= vc(t) cos(2π fct) −vs(t) sin(2π fct)
vc(t) = a(t) cos φ(t)
vs(t) = a(t) sin φ(t)
Finally, a bandpass signal may be represented as the real part of a complex exponential
(carrier) at fc whose amplitude is modulated by the complex baseband signal v(t):
x(t) = RE{v(t)e j2π fct}
where v(t) = vc(t) + jvs(t).

654
CHAPTER 10
Time-Domain Sampling and Reconstruction
Example
10.14
Let v(t) be a real-valued low-pass signal with V ( f ) = 0, | f | > f0. Show that the
amplitude-modulated signal x(t) = v(t) cos(2π fct) is a bandpass signal. Specify the
frequency band of x(t) if f0 = 3 and fc = 12, both in kHz.
Solution
V ( f ) = 0, | f | > f0
X( f ) = 1
2V ( f )⋆[δ( f + fc) + δ( f −fc)] = 1
2 [V ( f −fc) + V ( f + fc)] .
X( f ) = 0, | fc −f0| < | f | < | fc+ f0|. The frequency band is from fc−f0 to fc+ f0.
For f0 = 3 kHz and fc = 12 kHz the frequency band of x(t) is from 9 to 15 kHz.
Example
10.15
Consider the bandpass signal
x(t) = a1 cos(ω1t) + a2 cos(ω2t) + a3 cos(ω3t)
where ω1 < ω2 < ω3. Express x(t) in term of its quadrature components x(t) =
vc cos ωct −vs sin ωct.
Solution
The Fourier transform of x(t) is limited to ω1 ≤ω ≤ω3. Let ωc = (ω3 + ω1)/2
and ω0 = (ω3 −ω1)/2. Then, ω1 = ωc −ω0 and ω3 = ωc + ω0. In addition, let
ωd = ω2 −ωc. Then
x(t) = a1 cos(ω1t) + a2 cos(ω2t) + a3 cos(ω3t)
= a1 cos(ωc −ω0)t + a2 cos(ωc + ωd)t + a3 cos(ωc + ω0)t
= a1(cos ωct cos ω0t + sin ωct sin ω0t) + a2(cos ωct cos ωdt −sin ωct sin ωdt)
+a3(cos ωct cos ω0t −sin ωct sin ω0t)
= [(a1 + a3) cos ω0t + a2 cos ωdt] cos ωct
+[(a1 −a3) sin ω0t −a2 sin ωdt] sin ωct
= vc cos ωct −vs sin ωct
where
vc = (a3 + a1) cos ω0t + a2 cos ωdt
vs = (a3 −a1) sin ω0t + a2 sin ωdt
Example
10.16
Finding the quadrature components of a bandpass signal
The Fourier transform of a bandpass signal is
X( f ) =
 | f |−fℓ
fh−fℓ,
fℓ< | f | < fh
0,
elsewhere
See Figure 10.16(a). Express x(t) in the quadrature carrier form.

Signals and Systems
655
(a)
(b)
(c)
f
X( f)
–fh
–f
f
fc
fc = fh + f
2
fh
0
0
0
1
2
1
x1(t)
x2(t)
X1(f)
x(t)
x(t)
vs(t)
vc(t)
cos ω c t
sin ω c t
B
2
cos ω c t
sin ω c t
f c
f
–f c
f c
–f c
–f c
f c
B
2
B
B
1
2
1
2j
–
1
2j
1
2
1
2
1
2
B = fh – f
2
(d)
(e)
(f)
X2(f)
–f c
f c
f
B
Vs(f)
j
–j
f
B
1
2j
–
1
2j
j
2
–
1
2j
Vc(f)
f
1
B
FIGURE 10.16 A single-side-band signal X( f ) [shown in (a)] is constructed from an in-phase component Vc( f ) [shown
in (e)] and a quadrature-phase component Vs( f ) [shown in (f)]. See Example 10.16.

656
CHAPTER 10
Time-Domain Sampling and Reconstruction
Solution
Thesignalisbandlimitedto fℓ< f < fh.Itistobeshownby x(t) = vc(t) cos(2π fct)−
vs(t) sin(2π fct). It is not required for fc to be the center frequency of the bandwidth.
Presently, we choose fc = ( fh + fℓ)/2 and implement the sequence of operations
shown in Figure 10.16(b). The Fourier transforms of x1(t) = x(t) cos(2π fct) and
x2(t) = x(t) sin(2π fct) are shown in Figure 10.16(c) and (d), respectively. The
quadrature elements vc(t) and vs(t) are obtained at the outputs of low-pass ﬁl-
ters with gain 2. Their Fourier transforms are shown in Figure 10.16(e) and ( f ),
respectively.
Sampling Bandpass Signals
Obviously a bandpass signal x(t)
=
vc cos ωct −vs sin ωct can be faithfully
reconstructed from its samples taken at the rate of 2 fh, where fh is the highest fre-
quency in x(t). This is in general a high rate. In choosing it we are ignoring the
bandpass property of the signal; that is, the fact that X( f ) = 0 for | f | < fℓ. In this
section we summarize a method for sampling the bandpass signal x(t) = vc cos ωct −
vs sin ωct at the rate of 2B, where B is the signal’s bandwidth (or close to it) and
faithfully reconstructing it. The method described in this section assumes uniform
sampling.
To sample x(t) at the low rate one may ﬁrst downshift the in-phase and quadrature-
phase components of x(t) to obtain vc and vs. One then can sample each of the two signals
at their Nyquist rate of B Hz or a total of 2B samples per second. See Figure 10.17.
Alternately, one may sample x(t) directly at rates ranging from a certain minimum (close
to 2B) to its Nyquist rate of 2 fh. If x(t) is sampled directly, not all rates within the above
range are acceptable, as summarized below.
Low-Pass
Filter 
Low-Pass
Filter 
x1(t)
x2(t)
x(t)
vs(t)
vc(t)
cos ω 0 t
sin ω 0 t
A/D
Out 1
Out 2
Rate B
A/D
FIGURE 10.17 Sampling a bandpass signal by frequency downshifting.
Minimum Rate
To determine the minimum sampling rate we recognize the following two cases.
1.
If fh/B is an integer, then sample x(t) at the rate of 2B Hz to obtain the discrete-
time sequence x(nT ) where T = 1/(2B). In addition it can be shown that the even-
numbered samples of x(t) produce samples of vc and the odd-numbered samples
produce samples of vs. See the next item.

Signals and Systems
657
2.
If fh/B is not an integer, sample x(t) at the rate of (2 fh/N) Hz where N is the
integer part of fh/B. This is equivalent to increasing the bandwidth to B′ so that
fh/B′ = N becomes an integer and then sampling at the new rate of 2B′ Hz. The
new f ′
h and f ′
ℓare
f ′
h = fc + B′ and f ′
ℓ= fc −B′
The new center frequency f ′
c = fh −B′/2 is used in the interpolation formula to
ﬁnd x(t) from the samples.
Acceptable Rates
A bandpass signal with fl < | f | < fh and B = fh −fℓmay be sampled at a rate Fs
and reconstructed by passing the samples through a bandpass ﬁlter, if
2 fh
k
≤Fs ≤
2 fℓ
(k −1) k = 1, 2, . . . , N
where N is the integer part of fh/B. For k = N, the sampling rate becomes the minimum
rate derived previously. For k = 1, the sampling rate becomes the Nyquist rate of 2 fh.
In summary, it may be shown that the minimum sampling rate for the unique recon-
struction of a bandpass signal with bandwidth B is 2B < Fs < 4B.
Low-Pass Samples Are Obtained from Sampling Bandpass Signals
The bandpass signal x(t) with frequencies from fℓto fh has the bandwidth B = fh −fℓ
and the center frequency fc = ( fℓ+ fh)/2. The signal and its samples taken at the rate
of 2B (sampling interval T = 1/2B) are listed below.
x(t) = vc(t) cos(2π fct) −vs(t) sin(2π fct)
x(nT ) = vc(nT ) cos(2π fcnT ) −vs(nT ) sin(2π fcnT )
Consider the case where the upper frequency of the signal is a multiple of its bandwidth;
that is, fh/B = k is an integer.3 Then
fc = fℓ+ fh
2
= fh −B
2 =

k −1
2

B
Substituting for fc we get
x(nT ) = vc(nT ) cos πn(2k −1)
2
−vs(nT ) sin πn(2k −1)
2
=

(−1)n/2vc(nT )
n even
(−1)k+(n+3)/2vs(nT )
n odd
The even-numbered samples of x(t), taken at the rate of 2B, provide samples of vc(t)
and the odd-numbered samples of x(t) provide samples of vs(t).
3If that is not the case, we increase the bandwidth B to a new value B′ such that fh/B′ = k becomes an
integer.

658
CHAPTER 10
Time-Domain Sampling and Reconstruction
10.11
Reconstruction of Bandpass Signals
The bandpass signal x(t) described in section 10.10 may be recovered from its samples
x(nT ). To derive the recovery equation, we ﬁrst reconstruct the low-pass signals vc(t)
and vs(t) from their samples, which were provided by x(nT ) in the previous section:
x(nT ) =

(−1)n/2vc(nT ),
n even
(−1)k+(n+3)/2vs(nT ),
n odd
We then use the reconstructed vc(t) and vs(t) to ﬁnd x(t). The equation that gives
us x(t) in terms of its samples is
x(t) = vc(t) cos(2π fct) −vs(t) sin(2π fct)
=
∞

n=−∞
x(nT )sin π(t−nT )
2T
π(t−nT )
2T
cos 2π fc(t −nT )
where T = 1/(2B). Derivation of the above equation is left as an exercise.
Example
10.17
Find the minimum sampling rate for a bandpass signal with fc = 900 kHz and B =
8 kHz.
fℓ= fc −B
2 = 900 −8
2 = 896 kHz
fh = fc + B
2 = 900 + 8
2 = 904 kHz
Since fh/B = 904/8 = 113 is an integer, we sample x(t) at the rate of 2B = 16 kHz
or 16,000 samples per second.
Example
10.18
Find the minimum sampling rate for a bandpass signal with fc = 910 kHz and B =
8 kHz.
fℓ= 910 −8
2 = 906 kHz
and
fh = 910 + 8
2 = 914 kHz
Solution
fh/B = 914/8 = 114.25isnotaninteger.Wesampleattherateof2 fh/114 = 16,035
samples per second. The new bandwidth is B′ = fh/114 = 8.0175 kHz and as
expected the sampling rate is 2B′ = 16,035 samples per second. The new center
frequency is f ′
c = fh −B′/2 = 909.99 kHz.

Signals and Systems
659
Example
10.19
Find the minimum sampling rate for a bandpass signal with fℓ= 6 kHz and fh =
8 kHz. Construct the spectrum of a sampled signal. Reconstruct the original signal
by bandpass ﬁltering.
Solution
B = fh −fℓ= 2 kHz. fh/B = 8/2 = 4, which is an integer. The signal may be
sampled at the rate of 2 fh/4 = 4 kHz. The spectrum of the sampled signal is shown
in Figure 10.18. It is seen that bandpass ﬁltering will reproduce the original signal.
The center frequency of the recovery ﬁlter is 7 kHz.
f
(a)
0
kHz
–16
–12
–8
–4
4
8
12
16
f
(b)
0
kHz
–16
–12
–8
–4
4
8
12
16
f
(c)
0
kHz
–16
–12
–8
–4
4
8
12
16
1
1
1
FIGURE 10.18 Sampling and reconstructing a bandpass signal. A bandpass signal (6 kHz < f < 8 kHz) may be
recovered from its samples taken at the minimum rate of 4 kHz.
(a) S( f ) is the Fourier transform of s(t), a periodic train of impulses in the frequency domain spaced every Fs =
4 kHz.
(b) X( f ) is the Fourier transform of the continuous-time bandpass signal x(t) (6 kHz < f < 8 kHz).
(c) Y( f ) = X( f ) ⋆S( f ) is the Fourier transform of the sampled signal y(t) = x(t)s(t).
From the frequency-domain representations shown above, it is observed that x(t) may be recovered by passing y(t)
through a bandpass ﬁlter (6 kHz < f < 8 kHz).
Example
10.20
a.
Sample the bandpass signal of Example 10.19 at the rate of Fs = 5 kHz.
Examine the spectrum of the sampled signal and show that the original
continuous-time signal may not be faithfully reconstructed by bandpass
ﬁltering of samples taken at this rate.
b.
Repeat for Fs = 6 kHz and verify that the rate is acceptable.
c.
Repeat for Fs = 7 kHz and verify that the rate is not acceptable except when
the signal is a real-valued amplitude-modulated (AM) signal.

660
CHAPTER 10
Time-Domain Sampling and Reconstruction
Solution
All frequencies shown are in kHz. The constraint on Fs is
16
k
≤Fs ≤
12
(k −1), k = 1, 2, 3, 4
k = 1,
16 ≤Fs
k = 2,
8 ≤Fs ≤12
k = 3,
5.33 ≤Fs ≤6
k = 4,
4 ≤Fs ≤4
a.
The spectrum of the sampled signal is shown in Figure 10.19(a). Fs = 5 is not
acceptable.
b.
Fs =6 falls within the limits given above and is acceptable. See Figure 10.19(b)
for the spectrum of samples.
c.
Fs = 7 does not fall within the limits given above and the rate is not acceptable.
See Figure 10.19(c). The above rate is, however, acceptable in the case of an
AM signal. See Figure 10.19(d).
(i)
f
0
kHz
–15
–10
–8
–6 –5
5
6
8
10
15
1
(ii)
f
0
kHz
–15
–10
–5
5
10
15
1
(a)
(a) A bandpass signal (6 kHz < f < 8 kHz) may not always be recovered from samples taken at the rate of 5 kHz,
although this rate is higher than the minimum. The rate does not satisfy the condition for sampling (and recovery of) a
bandpass signal as described in the text. In this ﬁgure (and also in Figure 10.19b, c, and d) traces shown in (i) and (ii)
are X( f ) and Y( f ), respectively, as described in the legend of Figure 10.18. From the frequency domain representations
shown above, it is observed that passing y(t) through a bandpass ﬁlter (6 kHz < f < 8 kHz) will not produce x(t).
(i)
f
0
kHz
–18
–12
–8
–6
6
8
12
18
1
(ii)
18
f
0
kHz
–18
–12
–6
6
12
1
(b)
(b) The 6-kHz rate is acceptable for sampling (and recovery of) a bandpass signal (6 kHz < f < 8 kHz).
FIGURE 10.19 Sampling a bandpass signal (6 kHz < f < 8 kHz).

Signals and Systems
661
(i)
f
0
0.5
1
kHz
–8
–6
6
8
(ii)
f
0
1
kHz
–15
–13
–8
–6
6
8
13
15
(c)
(c) The 7-kHz rate is not always acceptable for sampling a bandpass signal with 6 kHz < f < 8 kHz [except when the
signal is amplitude modulated, see (d)].
(i)
f
0
kHz
–8
–6
6
8
1
(ii)
f
0
kHz
–15
–13
–8
–6
6
8
13
15
1
(d)
(d) The 7-kHz rate is acceptable for sampling an AM bandpass signal with 6 kHz < f < 8kHz.
FIGURE 10.19 (Continued)
Appendix 10A Additional Notes on Sampling
Nonuniform and Random Sampling
A band-limited signal may be recovered from its samples taken nonuniformly, provided
the average rate satisﬁes the Nyquist sampling criteria.
Samples may also be taken randomly. In some cases this becomes necessary in order
to eliminate biasing statistical averages of the signal when derived from its samples. As an
example consider a sinusoidal signal riding on a DC level, x(t) = A cos(2π f0t +θ)+ B.
The DC value B may be estimated from the average of N samples of x(t).
B ≈1
N
N

i=1
xi(t)
For the above to be an unbiased estimate, samples should be taken randomly. A similar
condition applies when x(t) is a stochastic process.
Random sampling may also be applied to reduce the sampling rate. An exam-
ple is found in random repetitive sampling, where high sampling rates (e.g., required
for signals with high bandwidth) are avoided by taking samples randomly, but repeat-
edly. The signal may then be reconstructed from the samples if a time reference (such

662
CHAPTER 10
Time-Domain Sampling and Reconstruction
as level triggering a digital scope by the signal to be sampled) can be applied to all
samples.
Sampling Stochastic Signals
We have developed a sampling and reconstruction process for deterministic signals. But,
by deﬁnition, the value of a deterministic signal at any moment is predictable once the
signal is determined. So why do we need to sample it further? The real application and
usefulness of a sampling process comes in play when signals are not predictable. Such
signals are called stochastic. Unlike deterministic signals, the value of a stochastic signal
is not predictable except statistically and in its average sense. In this section we brieﬂy
summarize the extension of sampling to certain classes of stochastic signals which are
classiﬁed as stationary processes.
Statistical averages of a stationary process x(t) are provided by its autocorrelation
γx,x(t) which is a deterministic function, or equivalently by its power density spectrum
x,x( f ) which is the Fourier transform of the autocorrelation. If the power density
spectrum of a stationary process is zero for frequencies above f0 the process is band
limited (which we have designated as low pass). Such a process may be represented by
ˆx(t) =
∞

n=−∞
x(nT )sin 2π f0(t −nT )
2π f0(t −nT )
where T = 1/(2 f0) is the sampling interval and f0 is the highest frequency present
in the autocorrelation function. The samples x(nT ) are random variables whose joint
probability density is described by the statistical averages of the process. The equivalence
shown by the above equation is in the sense that the expected value of the mean square
error between the two sides of the equation is zero.
E{|x(t) −ˆx(t)|2} = 0
10.12
Problems
Solved Problems
Note: For a block diagram of the sampling process, ﬁltering, reconstruction, and notations, see Figure 10.14.
1. A 1-kHz sinusoidal signal is sampled at t1 = 0 and t2 = 250 µs. The sample values are x1 = 0 and x2 = −1,
respectively. Find the signal’s amplitude and phase.
Solution
x(t) = A cos(2000πt + θ)
at t1
A cos(θ) = 0
at t2
A cos(π/2 + θ) = −A sin(θ) = −1
The answer: A = 1, θ = π
2

Signals and Systems
663
2. A continuous-time sinusoidal signal x(t) = cos(2π f0t) with unknown f0 is sampled at the rate of 1,000 samples
per second resulting in the discrete-time signal x(n) = cos(4πn/5). Find f0.
Solution
x(n) = x(t)

t=nt = cos(2π f0t)

t=10−3n = cos(2π f010−3n) = cos(4πn/5), f0 = 400 Hz
But
cos(4πn/5) = cos(2kπn + 4πn/5).
Therefore,
f0 = (1,000k + 400) Hz, k = 0, 1, 2, 3 · · ·
3. A continuous-time periodic signal x(t) with unknown period is sampled at the rate of 1,000 samples per second
resulting in the discrete-time signal x(n) = A cos(4πn/5). Can you conclude with certainty that x(t) is a single
sinusoid?
Solution
The answer is no. Sampling the sum of two sinusoids with frequencies 400 and 1,400 Hz at the 1-kHz rate produces
x(n) = A cos(4πn/5).
4. Consider a sinusoidal signal x(t) = A sin(2π f0t + θ) with a known frequency. Show that the signal may be
completely speciﬁed from two independent samples x1 and x2 taken at t1 and t2, respectively, during a period.
Solution
Given x1 and x2, the amplitude, A, and phase, θ, can be determined from the following equations:4
x1 = A sin(2π f0t1 + θ)
x2 = A sin(2π f0t2 + θ)
Several examples on sampling a sinusoidal signal at f0 = 100 MHz are discussed below.
a. x1 = 2.5 at 2π f0t1 = 0◦(at the time origin) and x2 = 2.5 at 2π f0t2 = 120◦. Then
A sin θ = 2.5
A sin(120◦+ θ) = 2.5
from which we ﬁnd A = 5, θ = 30◦, and x(t) = 5 sin(2π f0t + 30◦).
b. x1 = 1 at 2π f0t1 = 30◦and x2 = 2 at 2π f0t2 = 45◦. Then
A sin(30◦+ θ) = 1
A sin(45◦+ θ) = 2
from which we ﬁnd x ≈4.12 sin(2π f0t −16◦).
c. x1 = 2.5, x2 = 4.9, f0 = 100 MHz, and t2 −t1 = 2 ns. Let 2π f0t1 + θ = α. At 100 MHz, the 2 ns time lapse
between the two samples corresponds to 72◦. Then
at t1 :
A sin(2π f0t1 + θ) = A sin α = 2.5
at t2 :
A sin(2π f0t2 + θ) = A sin[2π f0t1 + θ + 2π f0(t2 −t1)] = A sin[α + 2π f0(t2 −t1)]
= A sin(α + 72◦) = 4.9
from which we ﬁnd x(t) = 5 sin(2π f0t + 30◦), where the time origin is set at the moment of the ﬁrst sample. If
the time origin is preset at another moment, then the phase angle may not be determined unless t1 is also speciﬁed.
4Exceptions are when x1 = x2 = 0 or t2 −t1 is a half-period, in which case the two samples don’t provide independent
information.

664
CHAPTER 10
Time-Domain Sampling and Reconstruction
d. x1 = 2.5, x2 = −2.5, f0 = 100 MHz, and t2 −t1 = 5 ns. At 100 MHz, the 5 ns time lapse between the two
samples corresponds to 180◦. Then
A sin α = 2.5
A sin(α + 180◦) = −2.5
The two samples don’t produce two independent equations and x(t) doesn’t have a unique answer.
5. Sequential repetitive sampling, revisited. A continuous-time signal x(t) = cos(2π f0t) with known frequency is
sampled uniformly every (1 + α)T seconds, where T = 1/f0 and α is a proper number α < 0.5.
a. Show that the sampling rate is Fs = f0/(1 + α) and sample values are given by x(n) = cos(2παn).
b. Impulse samples are passed through an ideal low-pass analog ﬁlter with unity gain and a cutoff frequency fc,
where

α
1 + α

f0 < fc <

1 −α
1 + α

f0
Find the output of the ﬁlter and show that it is a sinusoid at a frequency (
α
1+α ) f0.
c. Determine α so that the above sampling and reconstruction downshifts the frequency by a factor 10.
Solution
Continuous time:
x(t) = cos(2π f0t), X( f ) = 1
2 [δ( f + f0) + δ( f −f0)]
a. Sampling rate:
Fs =
1
(1 + α)T =
f0
(1 + α)
Discrete time:
x(n) = cos(2π f0t)

t=n/Fs
= cos

2π f0
n
Fs

= cos [2πn(1 + α)] = cos(2πnα)
b. Sampling function: s(t) =
∞

n=−∞
δ

t −n
Fs

, S( f ) = Fs
∞

k=−∞
δ( f −kFs)
Sampled function:
y(t) = x(t) × s(t), Y( f ) = X( f )⋆S( f )
= 1
2 Fs

∞

k=−∞
δ( f −kFs + f0) +
∞

k=−∞
δ( f −kFs −f0)

The Fourier transform of y(t) is made of impulses of strength Fs/2 located at
±
α
1 + α f0,
± 1 −α
1 + α f0,
± f0,
± 1 + 2α
1 + α f0,
± 2 −α
1 + α f0, . . . , ±k + 1 + α
1 + α
f0, . . . , k = 0, 1, 2, . . .
The output of the low-pass ﬁlter is
Z( f ) = 1
2 Fs

δ

f +
α
1 + α f0

+ δ

f −
α
1 + α f0

z(t) = Fs cos

2π
α
1 + α f0t

= Fsx

α
1 + α t

c.
α
1 + α = 0.1, α = 1
9
6. The signal x(t) = cos 500πt + cos 200πt is sampled by multiplying it with a train of unit impulses at the rate of
Fs impulses per second where Fs > 500. Impulse samples are then passed through a ﬁrst-order analog low-pass
RC ﬁlter with time constant τ = 2 msec. Since the analog ﬁlter is nonideal, its output z(t) contains components at

Signals and Systems
665
frequencies higher than 250 Hz, which cause distortion. Deﬁne a crosstalk index, η, to be the ratio of the power in
f > 250 Hz to the power in f < 250 Hz. Find the above index for
a. Fs = 1,000
b. Fs = 2,000
Interpret the differences in results of a and b.
Solution
The unit impulse and the frequency responses of the RC ﬁlter are:
h(t) = e−500tu(t), H(ω) =
1
500 + jω , H( f ) =
500−1
1 + j2π 
f
500
, |H( f )|2 =
500−2
1 + 4π 2 
f
500
2
The Fourier transform of the impulse-sampled signal is made of impulses with equal strength at the frequencies
below
a. Fs = 1,000,
f = 100, 250, 750, 900, 1,100, 1,250 Hz,
· · ·
b. Fs = 2,000,
f = 100, 250, 1,750, 1,900, 2,100, 2,250 Hz,
· · ·
The RC ﬁlter makes the powers proportional to |H( f )|2. Therefore,
a. Fs = 1,000 Hz, η ≈power in the 750 and 900 Hz
power in the 100 and 250 Hz
= 1/(1 + 4π 2 × 1.52) + 1/(1 + 4π 2 × 1.82)
1/(1 + 4π 2 × 0.22) + 1/(1 + 4π 2 × 0.52) ≈4% ≈−14 dB
b.
Fs = 2,000 Hz, η ≈power in the 1,750 and 1,900 Hz
power in the 100 and 250 Hz
= 1/(1 + 4π 2 × 3.52) + 1/(1 + 4π 2 × 3.82)
1/(1 + 4π 2 × 0.22) + 1/(1 + 4π 2 × 0.52) ≈0.8% ≈−21 dB
Doubling the sampling rate reduces the crosstalk index by a factor 5 (≈−7 dB). It should be noted that due to its
nonuniform gain over the frequency range, the RC ﬁlter introduces additional distortion in the recovery of x(t).
7. Bandpass sampling. The spectrum of a bandpass signal is shown in Figure 10.20(a) with fℓ= 7 kHz and
fh = 9 kHz.
a. Find the minimum sampling rate. Show the spectrum of the sampled signal and its reconstruction by bandpass
ﬁltering.
b. Find the range of acceptable sampling rates.
Solution
We proceed as in examples in section 10.11.
a. B = fh −fl = 2 kHz and fh/B = 9/2 = 4.5, the integer part of which is N = 4. The signal is sampled at
the rate of 2 fh/N = 18/4 = 4.5 kHz. See Figure 10.20. The spectrum of the sampled signal is shown in Figure
10.20(c). It is seen that bandpass ﬁltering ( fc = 8 kHz, B = 2 kHz) will reproduce the original signal.
b. The sampling rate should satisfy the following relationship:
18
k ≤Fs ≤
14
(k −1), k = 1, 2, 3, 4,







k = 1,
18 ≤Fs
k = 2,
9 ≤Fs ≤14
k = 3,
6 ≤Fs ≤7
k = 4,
4.5 ≤Fs ≤4.66

666
CHAPTER 10
Time-Domain Sampling and Reconstruction
^
f
(a)
0
kHz
–9
–7
7
9
X(f)
1
0.5
f
kHz
f
(b)
(c)
0
0
kHz
–9
–9
9
–4.5
4.5
–13.5
–13.5
–13.5
–4.5
4.5
13.5
9
S(f)
Y(f)
1
f
(e)
0
kHz
–9
–7
9
7
X(f)
1
0.5
1 0.5
f
(d)
0
kHz
–9
–7
9
7
H(f)
1
FIGURE 10.20 The minimum sampling rate for a bandpass signal and the characteristics of the reconstruction ﬁlter
can be derived from the spectrum of samples. This ﬁgure illustrates sampling and recovery of a bandpass signal x(t)
whose Fourier transform X( f ) (shown in a) is limited to 7 kHz < f < 9 kHz. When sampled at the rate of 4.5 kHz,
its Fourier transform is repeated at 4.5-kHz intervals. The Fourier transforms of the sampling function and the impulse
samples are shown in (b) and (c), respectively. To recover x(t), samples are sent through a bandpass ﬁlter H( f ) = 1,
limited to 7 kHz < f < 9 kHz, shown in (d). The Fourier transform of the ﬁlter’s output is shown in (e).
8. Sample a 1-Hz continuous-time sinusoidal signal x(t) = sin 2πt every T seconds. Reconstruct the signal from its
samples, take the Fourier transform of the reconstructed signal and display its magnitude for the following sampling
intervals:
a. T = 0.1
b. T = 0.65
c. T = 0.85
d. T = 0.95
Discuss the relationship between the position of spectral lines of the reconstructed signal with the sampling rate.
Solution
The sampled signal and the Fourier transform of the reconstructed signal, that is, the part of the transform of the
sampled function that is ﬁltered through a ±Fs/2 low-pass reconstructed ﬁlter are shown in Figure 10.21.
a. T = 0.1 s. The sampling rate is Fs = 10 Hz, which is more than twice the frequency of the signal. As expected,
the Fourier transform shows two spectral lines at ±1 Hz, Figure 10.21(a).
b. T = 0.65s.Thesamplingrateis Fs = 1.5385Hz,lessthantheNyquistrate.Thespectrallinesofthereconstructed
signal appear at |Fs −1| = 0.5385 Hz, Figure 10.21(b).

Signals and Systems
667
c. T = 0.85 s, Fs = 1.1765 Hz, and the reconstructed spectral lines are at |Fs −1| = 0.1765 Hz, Figure 10.21(c).
d. T = 0.95 s, Fs = 1.0526 Hz, and we observe two spectral lines at |Fs −1| = 0.0526 Hz, Figure 10.21(d).
0
–1
1
2
3
4
5
6
7
8
9
0
1
0
–4
–2
0
2
4
0.5
–0.6
–0.4
–0.2
0
0.5
0
10
20
30
40
50
60
–1
0
1
0
0.2
0.4
0.6
(a)
(b)
0
0.5
–0.4
–0.2
10
20
30
40
50
60
80
70
0
–1
0
1
10
20
30
40
50
60
90
80
70
0
–1
0
1
0
0.2
0.4
0
0.5
–0.4
–0.2
0
0.2
0.4
(c)
Time (s)
Frequency (Hz)
(d)
FIGURE 10.21 This ﬁgure is an illustration of frequency shift due to a low sampling rate. It shows a 1-Hz sinusoid
sampled at four different rates (left column) along with the resulting transforms (right column). Relevant information is
summarized below.

668
CHAPTER 10
Time-Domain Sampling and Reconstruction
The above observations are veriﬁed by convolution of the Fourier transforms of x(t) and the sampling impulse
train at the Fs rates.
Sampling Interval, T
Sampling Rate, Fs = 1/T
Reconstructed Frequency
(a)
100 msec
10 Hz
1 Hz
(b)
650 msec
1.5385 Hz
1.5385 −1 = 0.5385 Hz
(c)
850 msec
1.1765 Hz
1.1765 −1 = 0.1765 Hz
(d)
950 msec
1.0526 Hz
1.0526 −1 = 0.0526 Hz
Note that in case a, where the sampling rate is greater than 2 Hz, the frequency of the reconstructed signal is
the same as that of the original continuous-time signal at 1 Hz. But in cases b, c, and d, where the sampling rate is
less than 2 Hz, aliasing occurs and spectral lines appear at |Fs −1|.
9. Frequency downshifting. Take a continuous-time sinusoidal signal at the frequency f = 1 Hz.
a. Sample it every 0.01 second (equivalently, at the rate of 100 samples per second). Record 101 samples and plot
the sampled data versus time.
b. Repeat for a sampling interval of 1.01 seconds. Interpret the plots in light of the sampling rates.
Solution
The Matlab program to implement the above procedure is shown below.
t=linspace(0,1,101); x=sin(2*pi*t);
subplot(2,1,1); plot(t,x); grid
title('Plot of a 1 Hz sinusoid sampled every 10 msec., sampling rate=100 Hz.');
%
t=linspace(0,100,100); x=sin(2*pi*t);
subplot(2,1,2); plot(t,x); grid
title('Plot of a 1 Hz sinusoid sampled every 1.01 sec., sampling rate=0.99 Hz.');
a. Fs = 100 Hz. The command t = linspace(0, 1, 101) produces 101 sampling instances in 1 second (one sample
every 10 msec), including one sample at t = 0 and one sample at t = 1, for a total of 100 intervals. The sampling
interval is, therefore, 10 msec, corresponding to a sampling rate of 100 Hz. The resulting plot shows a 1-Hz
sinusoid.
b. Fs = 0.99 Hz. The command t = linspace(0, 100, 100) produces 100 sampling instances in 100 seconds,
including one sample at t = 0 and one sample at t = 100, for a total of 99 intervals. The sampling interval is,
therefore, 100/99 = 1.01 seconds, corresponding to a sampling rate of 0.99 Hz. The resulting plot shows a 0.01
Hz sinusoid.
The ﬁgure generated by the above program illustrates the sampling of a sinusoidal signal (with frequency
f0 Hz) at the rate Fs and reconstructing it by interpolation; for example, through the plot command in Matlab. It
shows, that when Fs < 2 f0, the reconstructed frequency is shifted to |Fs −f0|, causing aliasing. The 1-Hz sinusoid
x = sin(2πt) is sampled at the rates of Fs = 100 Hz in (a) and Fs = 0.99 Hz in (b). The frequency of the sinusoidal
plot in (b) is |0.99 −1| = 0.01 Hz. In summary, the plot in (a) shows one cycle of a 1-Hz sinusoid. The plot in
(b) is similar to (a) except for the time scale, which indicates a sinusoid at 0.01 Hz. Time has slowed down by
factor 100.

Signals and Systems
669
Chapter Problems
10. Sampling a sinusoid with known frequency. The frequency of a sinusoidal signal x(t) is known to be 1 kHz. The
signal is sampled at two instances t1 and t2 resulting in sample values x1 and x2, respectively. For the following
cases, express the signal in the form x(t) = A cos(2π f0t −θ) where A > 0.
a.
 t1 = 0
x1 = 1
t2 = 250 µs
x2 = 1.732
b.
 t1 = 0
x1 = 0
t2 = 583 µs
x2 = 1
c.
 t1 = 0
x1 = 0
t2 = 1,083 µs
x2 = 0.5
d.
 t1 = 250 µs
x1 = 1
t2 = 333 µs
x2 = 0
e.
 t1 = 100 µs
x1 = 3
t2 = 600 µs
x2 = −3
f.
 t1 = 50 µs
x1 = 2
t2 = 1,300 µs
x2 = −4
11. Extend problem 10 to formulate a general solution for possible determination of magnitude and phase of a sinusoidal
signal with known frequency from two samples taken at t1 and t2.
12. The frequency of a sinusoidal signal is known to be 1 kHz. The signal is sampled at two moments 250 microseconds
apart. Can you ﬁnd signal’s amplitude and/or its phase from the above two measurements? Show how to do it or
why it can’t be done.
13. Attenuation and path delay. A microwave ranging system transmits a sinusoidal signal s(t) = cos(2π f0t) with a
known frequency. The received signal is x(t) = As(t −τ) where A is the path attenuation and τ is the path delay.
The goal is to determine A and τ from a ﬁnite number of samples taken from x(t). Discuss possible strategies for
determination of A and τ in the following two measurement scenarios:
a. Two measurements of x1 and x2 taken at t1 and t2
b. One measurement of x1 at t1, and the time between consecutive zero-crossings of s(t) and x(t)
14. Modeling a periodic signal. A periodic signal x(t) of unknown period is to be modeled as ˆx(t) = A sin(2π f0t) by
choosing a zero-crossing as t = 0. The goal is to ﬁnd A and f0 from a ﬁnite set of measurements. For the following
three cases determine if the above goal may be achieved, and if so ﬁnd the model.
a.

t1 = 500 µs
x1 = 2.5
xMax = 5
b.

t1 = 166.7 µs
x1 = 0.5
t2 = 250 µs
x2 = 1
c.

t1 = 16.67 µs
x1 = 0.5
t2 = 500 µs
x2 = 1
15. A periodic signal x(t) with unknown period is to be modeled as ˆx(t) = A sin(2π f0t) by choosing a zero-crossing
as t = 0. Show that A and f0 may not always be uniquely determined from a ﬁnite number of samples taken
from x(t).
16. A periodic signal x(t) with an unknown period is to be modeled as ˆx(t) = A sin(2π f0t −θ). The goal is to ﬁnd
A, f0, and θ from a ﬁnite set of measurements. For the following three cases determine if the above goal may be
achieved, and if so ﬁnd the model.
a.

t1 = 0
x1 = 0 and dx
dt

t=0 = 5,000π V/s.
t2 = 250 µs
x2 = −1.4142

670
CHAPTER 10
Time-Domain Sampling and Reconstruction
b.

t1 = 0
x1 = 0
t2 = 583 µs
x2 = 1
c.

t1 = 0
x1 = 0
t2 = 1,083 µs
x2 = 0.5
17. Modeling an exponential signal. A signal decays exponentially from an unknown initial value to a zero ﬁnal value.
The decay rate and the initial value at t = 0 are not known. Two samples taken 1 msec apart result in x1 = 3 and
x2 = 1.
a. Find the time constant of the signal.
b. Can you ﬁnd the value of the signal at t = 0? If the answer is yes, ﬁnd it. If the answer is no, specify additional
information needed.
18. Impulse function. The unit-impulse function δ(t) is deﬁned by the distribution
φ(t0) =
	
∞
−∞
δ(t −t0)φ(t)dt for all t0
where φ(t) is any well-behaved (also called good) function. The above equation is called sifting property of δ(t).
a. Use the sifting property of δ(t) to prove or disprove the following equations.
δ(at) = δ(t)
|a| , a ̸= 0
δ(at + b) = δ(t −b/a)
|a|
, a ̸= 0
δ[(t −t1)(t −t2)] = δ(t −t1) + δ(t −t2)
|t1 −t2|
t1 ̸= t2
b. Prove or disprove that for an integer n
δ

sin 2πt
T

=
1
2π
∞

n=−∞
δ

t −nT
2

δ

cos 2πt
T

=
1
2π
∞

n=−∞
δ

t −(2n + 1)T
4

19. Impulse sampling. Prove or disprove that
x(t) ×
∞

n=−∞
δ(t −nT ) = 1
T x(t) + 2
T
∞

n=1
x(t) cos

2πnt
T

20. Sample the signal x(t) = cos 20πt at the rate of Fs. The resulting impulse samples are called y(t). For the following
rates ﬁnd and plot the time-domain and frequency-domain representation of y(t):
a. Fs = 30 Hz
b. Fs = 40 Hz
c. Fs = 50 Hz
21. The signal x(t) = cos(1,800πt −π/6) is sampled uniformly at the rate of 1 kHz and passed through an ideal
low-pass ﬁlter with a DC gain of 0.001 and a cutoff frequency of 500 Hz. Find the ﬁlter’s output.

Signals and Systems
671
22. a. The Fourier transform of a continuous-time signal is
X( f ) =

1
| f | < 1
0,
elsewhere
Find x(t) and plot it. Find the minimum sampling rate from which x(t) may be recovered. Determine sample
values x(nT ) for −5 ≤n ≤5.
b. Repeat for
X( f ) =
 1
2 + | f |,
0 < | f | < 1
2
0,
elsewhere
23. Ideal interpolation ﬁlter. Sample the signal x(t) = cos(2π f0t) at the rate Fs and pass the impulse samples y(t)
through a ﬁlter. For the following two sets of f0 and Fs determine the frequency response of the ﬁlter that would
reconstruct x(t) from the samples with no error:
a. f0 = 1.1 kHz and Fs = 1 kHz
b. f0 = 1 kHz and Fs = 1.1 kHz
24. Sample the signal x(t) = cos 2πt at the rate of Fs. Reconstruct the signal by sending the impulse samples y(t)
through an ideal low-pass ﬁlter with the cutoff frequency at Fs/2 and the gain= 1/Fs. The output of the ﬁlter is z(t).
For the following sampling rates ﬁnd and plot the time-domain and frequency-domain representations of y(t) and
z(t):
a. Fs = 3 Hz
b. Fs = 4 Hz
c. Fs = 5 Hz
Compare with problem 20.
25. First-order interpolation ﬁlter. Repeat problem 24 after replacing the ideal low-pass ﬁlter with a realizable ﬁrst-
order low-pass ﬁlter having 3-dB attenuation at 1 Hz and a DC gain =
√
2.
26. Second-order interpolation ﬁlter. Repeat problem 24 after replacing the ideal low-pass ﬁlter with a realizable
second-order low-pass Butterworth ﬁlter having 3-dB attenuation at 1 Hz and a DC gain =
√
2. The system function
for the ﬁlter is H(s) =
√
2/(s2 +
√
2s + 1).
27. nth-order interpolation ﬁlter. Sample x(t) = cos 2πt at the rate of 3 Hz and send the impulse samples through
a realizable nth-order Butterworth low-pass ﬁlter having 3-dB attenuation at 1 Hz and a DC gain =
√
2. Filter’s
output is z(t). Find the magnitude Fourier transform of z(t) for n = 2, 3, 4, 5. The magnitude frequency response
of the nth-order Butterworth ﬁlter is |H( f )|2 = 2/(1 + f 2n).
28. High-attenuation interpolation ﬁlter. Sample x(t) = cos 2πt at the rate of Fs and reconstruct it by sending the
impulse samples through a low-pass ﬁlter having a DC gain =
√
2, 3-dB attenuation at 1 Hz, and 140-dB attenuation
per decade beyond 1 Hz. For the following sampling rates ﬁnd the magnitude Fourier transforms of the reconstructed
signal z(t):
a. Fs = 3 Hz
b. Fs = 4 Hz
c. Fs = 5 Hz
29. Distortion. Sample x(t) = cos 2πt at the rate of Fs and send the impulse samples through a realizable 1st-order
low-pass ﬁlter having 3-dB attenuation at 1 Hz and a DC gain =
√
2. Filter’s output is z(t). Because the ﬁlter is
not ideal, z(t) contains distortions in the form of additional frequency components. Deﬁne the distortion index in
z(t) to be the ratio of the sum of power in frequencies higher than 1 Hz to the total power in z(t). Determine the
minimum sampling rate such that the distortion index in z(t) remains below 60 dB.

672
CHAPTER 10
Time-Domain Sampling and Reconstruction
30. Sample x(t) = cos 2πt at the rate of 3 Hz and send the impulse samples through a realizable nth-order Butterworth
low-pass ﬁlter having 3-dB attenuation at 1 Hz. Determine minimum ﬁlter order such that distortion index at the
output of the ﬁlter (deﬁned in problem 29) remains below 60 dB. The attenuation by the nth-order Butterworth ﬁlter
is 10 log(1 + f 2n) (dB).
31. A continuous-time analog signal x(t) = cos 500πt + cos 200πt is sampled at the rate of Fs samples per second.
The impulse samples are then passed through a low-pass analog ﬁlter with unity DC gain and cutoff frequency
fc = 260 Hz. Find the output of the ﬁlter and show its relationship to x(t) for
a. Fs = 600
b. Fs = 400
32. Frequency multiplication. Sample x(t) = cos 3πt at the rate of 4 Hz and send impulse samples through an
ideal low-pass ﬁlter with the cutoff frequency at fc and gain = 1/4. Find and plot the Fourier transform of the
reconstructed signal z(t) and its time expression for fc = 2, 3, 4, 5, 6 Hz.
33. Aliasing. Sample x(t) = cos(1.2πt) at the rate of Fs and send impulse samples through an ideal low-pass ﬁlter with
the cutoff frequency at Fs/2 and gain = 1/Fs. Find and plot the time-domain and frequency-domain expressions
for the sampled signal y(t) and the reconstructed signal z(t) for
a. Fs = 1 Hz
b. Fs = 3 Hz
34. Sample x(t) = cos(2π f0t) at the rate of 4 Hz and send impulse samples through an ideal low-pass ﬁlter with the
cutoff frequency at 2 Hz and gain = 0.25. Find the Fourier transform of the reconstructed signal z(t) and its time
expression for f0 = 1, 3, 4, 5 Hz.
35. A ﬁnite segment (0 ≤t ≤T ) of a continuous-time signal x(t) is sampled at the precise rate of 1,000 samples per
second resulting in a sequence of numbers x(n), n = 0, . . . 1,023. Using the ﬁnite set of the samples we want to
model x(t) within the interval 0 < t < T by a sinusoid ˆx(t) = A cos(2π f0t) such that the error deﬁned by the
following ϵ is minimized.
ϵ =
	
T
0
|x(t) −ˆx(t)|2dt
a. Show how A and f0 may be found and if the answer is unique.
b. Can you ﬁnd the smallest f0 with 100% certainty? In each case if the answer is no, describe why. If the answer is
yes, ﬁnd it.
36. Sampling a low-pass signal. A signal x(t) = sin(1,000πt)
πt
is sampled at the rate of Fs and sent through a unity-gain
ideal low-pass ﬁlter with the cutoff frequency at Fs/2. Find and plot the Fourier transform of the reconstructed
signal z(t) at ﬁlter’s output if
a. Fs = 20 kHz
b. Fs = 2 kHz
c. Fs = 1 kHz
d. Fs = 800 Hz
37. A signal x(t) = sin(1,000πt)
πt
is sampled at the rate of Fs and sent through a realizable ﬁrst-order low-pass ﬁlter having
3-dB attenuation at 500 Hz and a DC gain =
√
2. Find and plot the Fourier transform of the reconstructed signal
z(t) if
a. Fs = 20 kHz
b. Fs = 2 kHz

Signals and Systems
673
c. Fs = 1 kHz
d. Fs = 800 Hz
38. Reconstruction error. A signal x(t) =
sin(1,000πt)
πt
is sampled at the rate of Fs kHz and sent through a realizable
ﬁrst-order low-pass ﬁlter with a unity DC gain and 3-dB attenuation at 500 Hz. Find an expression for reconstruction
error (as deﬁned in section 10.8 of this chapter) for
a. Fs = 20 kHz
b. Fs = 2 kHz
Hint: Use Parseval’s theorem to compute the error.
39. Frequency downshifting. This problem extends problem 5 to sampling intervals being several times greater than
the period of the continuous-time signal. Sample x(t) = cos(2π f0t) uniformly every  = (M + α)T seconds
where M is a ﬁxed positive integer, α < 0.5, and T = 1/f0. Sampling instances are, therefore, at t = (M + α)nT .
a. Show that the sequence of samples x(n) is periodic and determine its period.
b. Determine the spectrum of impulse samples.
c. Let f0 = 100 GHz. Determine α and M so that the sampling and reconstruction downshifts the frequency of
x(t) to 100 MHz.
40. Extend problem 5 to the case of a band limited periodic continuous-time signal x(t) with period T . Let the highest
frequency component of the signal be fh and let the lowest frequency be fℓ. The aim is to sample the signal at a
much lower rate than the Nyquist rate and still obtain a representation in the form of x(t/g) where g is a frequency
downshift factor. Examine use of the sampling interval  = (1 + α)T which is higher than the period of the signal
by the amount αT where 0 < α < 1. Based on fℓand fh discuss conditions on α, fc, and the resulting frequency
downshift factor g.
41. Sample and hold. A signal x(t) is sampled every T seconds and is kept at that level until the next sample. The
operation is called sample and hold. Find the Fourier transform of the stepwise signal obtained by the sample and
hold operation.
42. Sample the signal x(t) = sin 200πt at intervals T and hold for the duration τ. The continuous signal generated by
sample and hold operation is called z(t). For T = τ = 1 msec:
a. Find and plot the spectrum of z(t).
b. Find the frequency response of a ﬁlter that would recover x(t) from z(t) (if that can be done).
43. Repeat problem 42 for the following cases and compare results.
a.
T = τ = 0.1 msec
b.
T = 1 and τ = 0.5 msec
c.
T = 0.1 and τ = 0.05 msec
44. Rectangular pulse. A continuous-time analog signal x(t) consists of a single 1-volt rectangular pulse lasting
slightly more than 3 msec. The signal is sampled at the rate of Fs samples per second by multiplying it with a train
of impulses. The samples are then passed through a second-order analog low-pass Butterworth ﬁlter with unity DC
gain and half-power frequency at 500 Hz. Find the output of the ﬁlter and the total energy difference compared to
the original analog pulse for
a. Fs = 1,000 Hz
b. Fs = 10,000 Hz
Compare results obtained in a and b and discuss the source of differences.

674
CHAPTER 10
Time-Domain Sampling and Reconstruction
45. Digital ﬁltering. A continuous-time pulse
x(t) =
 1,
−5.1 msec ≤t ≤5.1 msec
0,
elsewhere
is sampled at the rate of 200 samples per second with one sample at t = 0.
a. Show that the resulting continuous-time signal is represented by δ(t + T ) + δ(t) + δ(t −T ) where T = 5 msec
and that the above information may also be represented by x(n) = {1, 1
↑, 1}.
b. Impulse samples are passed through an LTI system with the unit-sample response h(t) = δ(t) + 2δ(t −T ) +
δ(t −2T ). Find the output of the LTI system.
c. The LTI system is followed by a hold ﬁlter with h(t) = u(t) −u(t −T ). Plot the output y(t) of the hold ﬁlter.
d. Show that the above analysis and results may be represented by discrete-time notations as follows:
x(n) = {1, 1
↑, 1}
h(n) = {1
↑, 2, 1}
y(n) = {1, 3
↑, 4, 3, 1}
In solving the succeeding problems you may use the above discrete-time representations.
46. A continuous-time analog signal x(t) = cos 500πt + cos 200πt is sampled at the rate of Fs samples per second.
The resulting discrete signal x(n) is passed through a digital ﬁlter with
h(n) = {1, 2, 3
↑, 2, 1}
Find the output y(n) and the reconstructed y(t) for
a. Fs = 1,000 Hz
b. Fs = 2,000 Hz
Compare y(n) obtained in a and b, and discuss sources of their possible differences.
47. An AM signal is given by x(t) = a(t) cos(2π fct) where a(t) is a low-pass signal band limited to [0, B] Hz and
fc > 2B. Show that the minimum sampling rate from which the signal can be recovered is 2B. Show how x(t)
may be recovered from its samples taken at the minimum rate. Interpret the results in both the time and frequency
domains.
48. AM signal. A signal is modeled by x(t) = a(t) cos(2π fct) where a(t) is a real-valued low-pass signal limited to
[0, 3] kHz and fc = 1 MHz. Devise a scheme for sampling the signal at the 6 kHz rate and its reconstruction, which
would result in x(t).
49. AM signal. A signal is modeled by x(t) = [A+µa(t)] cos(2π fct) where A and µ are constant, a(t) is a real-valued
low-pass signal limited to [0, 3] kHz and fc ≥500 kHz. Multiply x(t) by a sinusoidal signal at ( fc + 455) kHz
and pass it through an ideal bandpass ﬁlter (center frequency at 455 kHz, bandwidth = 6 kHz). Devise a sampling
scheme that results in x(t) independent of fc.
50. Bandpass signal. The amplitude-modulated signal
x(t) = a(t) cos(2,000πt),
a(t) =

sin 200πt
πt
2
is passed through an ideal low-pass ﬁlter with unity gain and cutoff at 1 kHz. Express the ﬁlter’s output as

Signals and Systems
675
y(t) = vc cos(2π fct) −vs sin(2π fct). Find fc, vc(t) and vs(t). Sample y(t) at the minimum required rate and
relate the samples to vc(t) and vs(t). Find and plot the sequence of samples y(n) for −15 ≤n ≤15.
51. Bandpass signal. The Fourier transform of a bandpass signal y(t) is
Y( f ) =

3
2 −| f |,
1
2 < | f | < 1
0,
elsewhere
a. Express y(t) in the form of y(t) = vc cos(2π fct) −vs sin(2π fct). Find fc, vc(t) and vs(t).
b. Sample y(t) at the minimum required rate and relate the samples to vc(t) and vs(t). Plot y(n) for −15 ≤n ≤15.
c. Given that y(t) is the output of an ideal low-pass ﬁlter with unity gain and the cutoff frequency at f = 1 Hz,
with input 2x(t) cos 2πt, ﬁnd x(t).
52. Bandpass signal. The Fourier transform of a bandpass signal is given by X( f ) in Figure 10.16(a).
a. Express it as x(t) = vc(t) cos(2π f0t) −vs(t) sin(2π f0t) where f0 = ( fh + fℓ)/2 and ﬁnd vc(t) and vs(t).
b. Specify the minimum and acceptable sampling rates for fℓ= 9 and fh = 12, both in kHz.
53. Bandpass signal. Assume the spectrum of the bandpass signal of Figure 10.16(a) is limited to fℓ= 9 and fh = 12,
both in kHz, and that the signal is described by x(t) = vc(t) cos(2π f0t) −vs(t) sin(2π f0t) with f0 = fℓ. Specify
the minimum and acceptable sampling rates for the bandpass signal and discuss its relation with the rates obtained
in problem 53.
54. A signal is modeled by
x(t) =
11

n=1
2n cos[2,000(n + 99)πt]
Find and plot its Fourier transform X( f ) and determine sampling schemes at low rate from which x(t) may be
reconstructed.
55. The Fourier transform of a periodic continuous-time signal is
X( f ) =
11

k=1
{kδ[ f −1,000(k + 99)] + (11 −k)δ[ f + 1,000(k + 99)]}
Plot X( f ). Express x(t) in the time domain and determine sampling rates from which x(t) may be reconstructed.
56. Complex-valued low-pass signals. Given the Fourier transforms express the time functions as x(t) = vc(t)+ jvs(t)
for the following cases.
a.
X( f ) = δ( f −1,000)
b.
X( f ) = δ( f + 1,000)
c.
X( f ) = δ( f −2,000) + δ( f + 1,000)
d.
X( f ) = δ( f −1,000) + δ( f + 2,000)
e.
X( f ) = δ( f −1,000) + 2δ( f + 2,000)
f.
X( f ) = 2δ( f −1,000) + δ( f + 1,000)

676
CHAPTER 10
Time-Domain Sampling and Reconstruction
57. A bandpass signal is given by x(t) = RE{a(t)e j2π fct} where a(t) is a complex-valued low-pass signal whose Fourier
transform is
A( f ) =

β + αf,
| f | < f0
0,
| f | > f0
in which α and β are constants.
a. Express the low-pass signal as a(t) = vc(t) + jvs(t).
b. For the following sets of parameter values determine acceptable sampling rates and sampling schemes. Show
how x(t) is recovered.
fc
f0
α
β
Set 1:
1 MHz
3 kHz
1
2
Set 2:
1 MHz
3 kHz
0
1
Set 3:
1 MHz
6 kHz
1
2
Set 4:
1 MHz
6 kHz
0
2
Set 5:
10 MHz
3 kHz
1
2
Set 6:
10 MHz
3 kHz
0
1
Set 7:
10 MHz
6 kHz
1
2
Set 8:
10 MHz
6 kHz
0
2
58. A bandpass signal is given by x(t) = RE{a(t)e j2π fct} where a(t) is a complex-valued low-pass signal whose Fourier
transform is
A( f ) =

1,
−fℓ< f < fh
0,
elsewhere
in which fℓand fh are positive constants.
a. Express the low-pass signal as a(t) = vc(t) + jvs(t).
b. For the following sets of parameter values determine acceptable sampling rates and sampling schemes. Show
how x(t) is recovered.
fc
fℓ
fh
Set 1:
1 MHz
1 kHz
2 kHz
Set 2:
1 MHz
0 kHz
2 kHz
Set 3:
10 MHz
1 kHz
2 kHz
Set 4:
10 MHz
0 kHz
2 kHz
59. A continuous-time function h(t) is known to be low pass so that its Fourier transform is zero for | f | > f0 .
a. Sampling h(t) at the Nyquist rate of 2 f0 produces h(n) = d(n). Find h(t).
b. Sampling h(t) at twice the Nyquist rate (i.e., at 4 f0 samples per second) yields
h(n) = sin( πn
2 )
πn
2
Find h(t). Show that the additional samples obtained in part b are not needed for recovering h(t).

Signals and Systems
677
10.13
Project 1: Sampling Neuroelectric Signals
In this project you will investigate bandwidths and sampling rate requirements for neuroelectric signals. See the sections
on EEG, EMG, EKG, and other neuroelectric signals in Chapter 1. For each signal type you start with a review of standards
currently used in conventional clinical applications. You then seek information on possible advantages in using broader
frequency bands (at the low and high frequencies) in a new system. The sources for your investigation are: (1) technical data
and speciﬁcations of the commercially available systems and devices; (2) recommendations by the relevant professional
societies; and (3) research papers about salient features of these signals and their relation to clinical applications. The
outcome of the project is the set of your recommendations to be considered in the design of a commercial system for
digital analysis of EEG, EMG, and EKG signals in clinical and research applications.
10.14
Project 2: Time-Domain Sampling
Summary
In this project you will ﬁrst sample the rotary motion of a fan that may be modeled as a single sinusoidal signal. Then, using
software and the computer, you will generate sampled versions of several continuous-time functions that model signals of
interest in signal processing and ﬁnd their Fourier representations. You will start with a high-sampling rate and examine
the effect of reducing it below the Nyquist rate. In this way you will investigate aliasing and frequency downshifting.
Finally, you will use a digital sampling device such as a digital oscilloscope, sound card, DFT spectrum analyzer, or a
DSP board to sample analog signals in real time and examine the effect of the sampling on the resulting signal.
Equipment and Tools
Variable-speed electric fan, circular disks, and auto transformer
Adjustable strobe light
Software package for signal processing
Hardware platform (PC, sound card or DSP board)
Function generator and spectrum analyzer (used in “Real-Time Sampling,
Reconstruction, and Aliasing”)
Introduction
Mathematical software packages as well as display and DSP packages can plot mathematical functions; for example,
y = f (t). In actuality, what is plotted is the discrete function y(n) = f (nt). For example, you may need to specify the
initial and ﬁnal value of t, and the number of sample points N within that range to be used in the plot. Alternatively, you
may need to specify the sampling interval (time resolution). Use the plot command to investigate the effect of sampling a
high-frequency signal at a low rate. The effect may be called frequency downshifting or aliasing. Plots of a continuous-time
sinusoidal signal made throughout this chapter as well as in problems show the above effect.
Prelab Exercises
Exercise 1. Sampling a Sinusoid at a Low Rate
Sample a 10-kHz sinusoid every t = 100/99 seconds (Fs = 0.99 Hz) and plot it. The following Matlab program
illustrates the above exercise.
t=linspace(0,100,100);
y=sin(20000*pi*t);
plot(t,y); grid;
ylabel('Magnitude'); xlabel('Time in Seconds');
title('Plot of 10 kHz sinusoid sampled at the rate of 0.99 Hz.');

678
CHAPTER 10
Time-Domain Sampling and Reconstruction
Analyze the above program, run it, and examine the output plot. Determine the frequency downshift and relate it to the
sampling rate.
Exercise 2. Sampling a Sinusoid at the Zero-Crossing Time
Examine the following Matlab ﬁle. Run it and interpret the output plot.
t=linspace(0,100,101);
y=sin(2*pi*t);
plot(t,y); grid;
ylabel('Magnitude'); xlabel('Time in Seconds');
Measurements and Analysis
Sampling the Rotary Motion of a Fan
In this section you use a strobe light to explore the effect of the sampling rate on the perceived rotary motion of a fan. A
circular disk marked by single or multiple spokes is mounted on the axis of the fan to observe the rotation and measure
its speed. The schematic block diagram of the experimental setup is shown in Figure 10.22. Do not look directly at the
strobe when it is ﬂashing.
Rotating
Device 
Human Observer
Strobe
Flash
FIGURE 10.22 Sampling a rotary motion by strobe light.
Single-Spoke Disk.
Mount the single-spoke circular disk on the axis of the fan. Set the auto transformer output that
feeds the fan to 120 volts and run the fan at the high-speed setting. Wait until the fan achieves its ﬁnal speed. Sample the
rotary motion by strobe. With the fan running at the constant speed, vary the rate of the strobe and explore your perception
of the disk’s speed and direction of its rotation. Measure the fan’s RPM by adjusting the strobe’s rate so that the disk
appears stationary. Describe your method. At what rate(s) do you see a single stationary spoke? At what rates do you see
two stationary spokes 180 degrees apart? At what rate do you have four spokes 90 degrees apart? Describe, quantitatively,
the perceived motion of the fan and its direction and speed in terms of the strobe rate.
Multiple-Spoke Disk.
Repeat for the multiple-spoke disk (marked by three spokes 120 degrees apart) with the fan at
the high-speed setting and the autotransformer output at 120 volts.
a. Monition. Beware of possible slippage of the cardboard disk on the shaft. The fan may not slow down immediately
or appreciably when you switch the setting (high, medium, low) because it is not under load from the air blades.
b. Reminiscense. Remember the backward-appearing motion of wagon wheels and airplane blades in the movies or
in reality.
Simulating the Fan/Strobe Experiment
Using a software package such as Matlab, simulate the fan/strobe experiment of section 1 at the highest rotation speed.

Signals and Systems
679
Sampling a Rectangular Pulse
Using a computer software package, sample a 1,200-msec rectangular pulse at three rates: Fs = 20, 10, and ﬁve samples
per second. Produce Figure 10.23 with two columns and three rows showing sampled signals (on the left-hand column)
and their Fourier transforms (on the right-hand side). The Fourier transform of a continuous-time rectangular pulse is a
sinc function with inﬁnite bandwidth. The Fourier transforms of the sampled pulses are periodic functions of frequency
with a period Fs. Show one cycle of each is shown on the right-hand side of Figure 10.23.
This ﬁgure has been masked so as to be recreated by the student.
FIGURE 10.23
Figure 10.23. Sampling a 1,200-msec rectangular pulse at three sampling rates and their transforms.
a. Fs = 20 samples per second
b. Fs = 10 samples per second
c. Fs = 5 samples per second
Examine the time and frequency plots in Figure 10.23 and satisfy yourself that they meet theoretical expectations.
Then, generate a rectangular pulse (pulse width τ = 500 msec, pulse period T = 8 seconds). Sample the signal at the
following rates. Find and plot the Fourier transform of each sampled signal.
W1: Fs = 256 samples/sec
W3: Fs = 64 samples/sec
W5: Fs = 16 samples/sec
W7: Fs = 8 samples/sec
Do the following and answer these questions:
1. In each case read (from the plots) the highest frequency content of the transform.
2. Double the data length to T = 16 seconds while keeping the pulse width at τ = 500 msec. What is the effect on
the transform? Does the highest frequency change? Does the frequency resolution change?
3. Verify the relationship between T, f, f0, and Fs.
Aliasing
Write a computer program to illustrate, in the time and frequency domains, observations of Example 10.7 in this chapter.
Run the program on the computer and summarize the result.
Aliasing
Write a computer program to sample a 1-kHz square wave every t, and take its transform. Do that for
a. t = 50 µS
b. t = 2 msec
Interpret the frequency representation of the sampled signals.
Real-Time Sampling, Reconstruction, and Aliasing
The concepts of time-domain sampling, signal reconstruction, and frequency aliasing may be experienced and illustrated
in real time by using a hardware device that has analog-to-digital and digital-to-analog converters. Examples of such
devices are computer sound cards, digital signal processing (DSP) boards, or data acquisition cards. Use a sound card or
a DSP board and a software program to sample signals in real time and ﬁlter them by digital ﬁlters. As a starting point,
sample a 12-kHz sinusoidal signal at the 5-kHz rate and run it through a ﬁrst-order low-pass ﬁlter. Change the frequency

680
CHAPTER 10
Time-Domain Sampling and Reconstruction
of the sine wave without changing the sampling rate or the cutoff frequency of the ﬁlter. Observe the analog output and
relate it to the sampling rate.
An example is shown in Figure 10.24, where the footprint of the reconstruction low-pass ﬁlter appears in the step-
wise output sinusoid. Figures 10.24, 10.25, and 10.26 illustrate aliasing and frequency downshifting. These ﬁgures were
produced by using Texas Instruments’ TMS320C6713 DSK board.
1 1.00V/
2   50   /
–380
mv
–32.0 mv
s
s
50.0  /
Stop
1
1
2
Ext
Edge
Trigger
Menu
(a) Ch1 1 V/div. Ch2 50 mV/div. Sweep 50 µsec/div.
1 1.00V/
2   50   /
0.00
mv
40.6 mv
s
500  /
Stop
2
1
2
Ext
Edge
Trigger
Menu
s
(b) Ch1 1 V/div. Ch2 50 mV/div. Sweep 500 µsec/div.
Source
2
Span
10.0kHz
FFT Sample Rate = 20.0kSa/s 
FFT Sample Rate = 20.0kSa/s 
Preset
Center
5.00kHz
Scale
10dB/
Offset
–55.0dB
Window
Hanning
More FFT
(c)
FIGURE 10.24 Sampling and reconstruction of a 4.25-kHz sinusoidal signal by the TMS320C6713 DSK board at the
rate of 8,000 samples per seconds (8 kHz). Time sweeps are shown in (a) (fast one) and (b) (slow one). In both cases,
upper traces show the sampled signal (the input to the board) and lower traces show the reconstructed signal (the output
of the board). Note the footprint of the low-pass reconstruction ﬁlter (sample and hold) in the form of steps in (a), to
be compared with Figure 10.7 in this chapter. Also note the beat frequency effect seen in (b), which is the time-domain
manifestation of the consequence of an insufﬁcient sampling rate. The effect can be seen more constructively through the
spectrum of the reconstructed signal, shown in (c). The spectral lines shown in (c) are at 4.25 kHz and 3.75 kHz. Note
the frequency difference between the input and the output (aliasing), which is the frequency-domain manifestation of the
consequence of insufﬁcient sampling rate. As seen, the reconstructed signal in fact contains two components: one at 4.25
kHz (the original frequency) and a second at 3.75 kHz (the difference between 4.25 kHz and 8 kHz). Note that in this
case, the downshifted frequency component is stronger than the component at the original frequency.

Signals and Systems
681
Source
2
Span
50.0kHz
FFT Sample Rate = 122kSa/s 
Preset
Center
25.0kHz
More FFT
–13.2
2 100   /
mv
–1.64ms
0.00V
Stop
1
s
FIGURE 10.25 Another illustration of aliasing due to an insufﬁcient sampling rate. A 25-kHz
sinusoid is sampled at the rate of 48 kHz and reconstructed by passing the samples through a
low-pass ﬁlter. The spectrum of the reconstructed signal, on the lower trace, shows one spectral
line at 25 kHz (the original frequency) and another at 23 kHz (the difference between 25 kHz and
48 kHz). The frequency axis is at 5 kHz/div, with the center frequency at 25 kHz. The time trace
(on the top) exhibits the beat effect.
Source
2
Span
10.0kHz
FFT Sample Rate = 20.0kSa/s 
Preset
Center
5.00kHz
More FFT
1.48
1 2.00V/ 2  50   /
mv
10.0   /
ms
0.00V
Stop
1
s
FIGURE 10.26 Aliasing leads to frequency downshifting. When a 4.5-kHz sinusoid is sampled
at the 8 kHz rate and reconstructed by the DSK board, the output is a 3.5-kHz sinusoid. The
original component at 4.5 kHz is totally eliminated by the low-pass reconstruction ﬁlter. The
output spectrum shows a single line at 3.5 kHz.
Discussion and Conclusions
Classify and summarize your observations from this project. Relate your observations and results to theory.

Chapter11
Discrete-Time
Signals
Contents
Introduction and Summary
684
11.1
Domain and Range of Discrete Signals
684
11.2
Actual Signals and Their Mathematical Models
685
11.3
Some Elementary Functions
686
11.4
Summary of Elementary Functions
691
11.5
Periodicity and Randomness
691
11.6
Examples of Periodic Signals
694
11.7
Sources of Discrete Signals
696
11.8
Representation of Discrete Signals
697
11.9
Digital Signals
699
11.10
Energy and Power Signals
700
11.11
Time Reversal
700
11.12
Time Shift
703
11.13
Combination of Time Reversal and Shift
704
11.14
Time Scaling and Transformation
706
11.15
Circular Shift
708
11.16
Even and Odd Functions
709
11.17
Windows
713
11.18
Signal Processing and Filtering
715
11.19
Problems
718
11.20
Project: An Introduction to Discrete-Time Signal Processing
728
683

684
CHAPTER 11
Discrete-Time Signals
Introduction and Summary
A discrete signal is a sequence of numbers {xn}, where the index n is an integer. In this
book a discrete signal is considered a function of the integer variable n, −∞< n < ∞,
and shown by x(n). This representation is applied to actual discrete signals and also to
the mathematical functions which model them. Many discrete signals are produced by
sampling a continuous-time signal at regular intervals. They are, appropriately, called
discrete-time signals. Some discrete signals are produced by sampling other variables,
such as space, or may be inherently discrete. However, for historical reasons, the term
discrete time is used for all discrete signals. In this book discrete signals and discrete-time
signals mean the same thing and the terms will be used interchangeably.
A discrete-time signal may be represented by a sequence of impulses in the
continuous-time domain and, in theory, be subject to the tools and techniques devel-
oped for analysis in that domain. A simpler and more efﬁcient approach, however, uses
tools specially developed for the discrete-time domain. Such tools stand on their own
and need not be derived from continuous-time domain. It may even appear advantageous
to start with the analysis of signals and systems in the discrete-time domain for several
reasons. First, discrete-time operations on signals are conceptually easier to understand.
Second, computer software and computational tools for discrete-time signals are easier
to use and more readily available. Third, digital hardware often constitute the platforms
to implement a design. Fourth, in many cases discrete-time systems provide more design
ﬂexibility. This book provides parallel paths for the two domains, bridged by Chapter 10
on time-domain sampling. This chapter introduces discrete-time signals not as a special
case of continuous-time functions but on an equal footing with them. It introduces basic
notations and some operations on discrete-time signals, which are then used within the
rest of the book. In addition, some examples and problems illustrate elementary forms
of the ﬁltering operation.
11.1
Domain and Range of Discrete Signals
The domain of discrete-time signals is the set of real integers −∞< n < ∞. In some
cases, the actual signal has a ﬁnite duration or we are only interested in a ﬁnite segment
of it. The ﬁnite-duration signal is then modeled by a mathematical function that (1) may
assign to it a zero value outside of its duration, (2) may repeat the signal in the form of a
periodic function, or (3) may keep the signal as is, a ﬁnite-sequence signal, and ignore
modeling it over the inﬁnite domain.
Therangeofdiscrete-timesignalsisthecontinuousspaceofrealorcomplexnumbers
−∞< x < ∞. In this book x is, in general, an analog real number, unless speciﬁed
otherwise. The range of actual signals is limited, but the model is not.

Signals and Systems
685
11.2
Actual Signals and Their
Mathematical Models
In this chapter, and throughout most of the book, we deal with mathematical mod-
els of actual signals. Models may be simple elementary functions, some of which are
summarized in the next section, or probabilistic models and stochastic processes. How
accurately do models represent the signals and how critical is the accuracy of the model?
The answer lies in the circumstances under which the signal and its model are used. In
fact, a simpliﬁed model of a complicated signal may be preferred to a more accurate one
if it does its intended job.
Example
11.1
A temperature profile
Temperature measurements taken at regular 6-hour intervals at a weather station for
a duration of 12 months are regarded as a discrete sequence. The temperature proﬁle
may be modeled by a periodic function that accounts for day-night and seasonal
variations. The model is often satisfactory, even though the temperature proﬁle itself
isnotdeterministicbutincludesarandomcomponent.SeeExample10.9inChapter10
for more details.
Example
11.2
Sunspots
The monthly recordings of the number of sunspots is an example of an actual discrete
signal of ﬁnite length. Sunspot numbers were recorded starting in the year 1700.
See Figure 1.1 in Chapter 1. The signal may be described by mathematical models
that exhibit some periodicity. But because of their random nature, the models cannot
accurately predict future numbers, but only probabilistically and in terms of statistical
averages.1
Example
11.3
Sampled speech signal
A speech signal is a continuous-time voltage recorded by a microphone. Its discrete-
time version is a sequence of samples taken at a speciﬁed rate. An example was given
in Chapter 1.
1For example, see the paper by A. J. Izenman, J. R. Wolf, and J. A. Wolfer, An Historical Note on the Zurich
Sunspot Relative Numbers, J. R. Statist. Soc., Part A, vol. 146, 1983, pp. 311–318. The data is often called
Wolfer numbers. For the data, models, and other references on sunspots, you may search Google under
wolfer+zurich+sunspots.

686
CHAPTER 11
Discrete-Time Signals
The above three examples illustrate actual discrete-time signals that exhibit some
randomness. They are modeled as stochastic processes (not to be discussed here). Once
a segment of such a signal is observed or recorded, the random property vanishes and
the signal becomes a known time series.
11.3
Some Elementary Functions
The unit-sample, unit-step, unit-ramp, sinusoidal, exponential, and sinc functions are
often used as the elementary building blocks for modeling signals.
Unit Sample
The unit-sample function d(n)2 is deﬁned by
d(n) =

1,
n = 0
0,
n ̸= 0
Unit Step
The unit-step function u(n) is deﬁned by
u(n) =

1,
n ≥0
0,
n < 0
Unit Ramp
The unit-ramp function r(n) is deﬁned by
r(n) =

n,
n ≥0
0,
n < 0
The unit-sample, unit-step, and unit-ramp functions are plotted in Figure 11.1(a), (b),
and (c), respectively.
Note: The unit-sample, unit-step, and unit-ramp functions are related to each other. One
way to express their relationship is by d(n) = u(n) −u(n −1) and r(n) = nu(n). Other
ways, which employ difference and summing operators, will be shown in Chapter 12.
Sinusoid
The sinusoidal function is deﬁned by x(n) = X0 cos(ωn + θ). It is periodic if ω =
2π/N, N being an integer, in which case N is the period. See Figure 11.2(a). A sinusoid
X0 cos(ωn + θ) is completely speciﬁed by three parameters X0, θ, and ω. X0 and θ are
combined as the complex amplitude X = X0e jθ = X0̸ θ, also called the phasor.
2The unit-sample function is sometimes shown by δ(n) and called the unit-impulse function (as in the
continuous-time domain). Such usage may cause confusion with a sample of inﬁnite value. In this book we
generally represent the unit-sample function by d(n).

Signals and Systems
687
0
–8
–6
–4
–2
0
(a)
2
4
6
8
1
0
–8
–6
–4
–2
0
(b)
2
4
6
8
1
0
–8
–6
–4
–2
0
(c)
2
4
6
8
1
FIGURE 11.1 (a) The unit-sample function d(n). (b) The unit-step function u(n). (c) The unit-
ramp function r(n).
Exponential
The exponential function is x(n) = X0eσn, where X0 and σ are constant real numbers.
It grows exponentially with increasing n if σ > 0, and decays if σ < 0. For σ = 0,
we have a DC-level function [x(n) = X0 for all n]. See Figure 11.2(b). Other examples
of exponential functions are found through the rest of this chapter; for example, see
Figures. 11.7 and 11.11.
Exponentially Growing or Decaying Sinusoid
A sinusoidal function whose amplitude varies exponentially is given by
x(n) = X0eσn cos(ωn + θ)

688
CHAPTER 11
Discrete-Time Signals
1.5
–1.5
–1
–0.5
0
0.5
–20
–15
–10
–5
0
(a)
5
10
15
20
25
1
–0.2
0
0.2
0.4
0.6
0.8
–20
–15
–10
–5
0
(b)
5
10
15
20
25
1
1.2
–0.6
–0.4
–0.2
0
0.2
0.4
0.6
0.8
–20
–15
–10
–5
0
(c)
5
10
15
20
25
1
1.2
FIGURE 11.2 (a)Theperiod of the sinusoidal function cos( πn
10 )is 20. (b) The one-sided decaying
exponential function shown is x(n) = e−n/10u(n) and has a time constant equal to 10. (c) Multipli-
cation of functions in (a) and (b) produces the causal function x(n) = e−n/10 cos(πn/10)u(n)
shown. Its envelope has a time constant equal to 10. The function may be expressed as
x(n) = RE{e0.1(−1+ jπ)n}u(n).
If σ > 0, the amplitude will grow exponentially. If σ < 0, the amplitude will decay
exponentially. See Figure 11.2(c). For σ = 0, the amplitude of the sinusoid is constant.
Complex Exponential
The complex exponential function is
x(n) = X0eσne j(ωn+θ)
where X0, σ, ω, and θ are constant real numbers. The ﬁrst part of the above expression,
X0eσn, represents an exponential amplitude. The second part of the expression, e j(ωn+θ),
represents the periodic behavior of the function. The exponential function may also be
written as
x(n) = X0e jθe(σ+ jω)n

Signals and Systems
689
Its real part
RE [x(n)] = X0eσn cos(ωn + θ)
is a sinusoid with exponential growth (if σ > 0) or decay (if σ < 0). For σ = 0, the
complex exponential function becomes
x(n) = Xe jωn
Its real and imaginary parts then become sinusoids with constant amplitudes.
The complex exponential function and its real part are completely speciﬁed by the
four parameters X0, θ, σ, and ω. These parameters are combined in pairs as the complex
amplitude X = X0e jθ, also called the phasor X = X0̸ θ, and the complex frequency
s = σ + jω.
Exponential and sinusoidal functions are important building blocks in the analysis
of signals and linear systems and are encountered frequently.
Sinc Function
The discrete-time unit-sinc function is deﬁned by sin n
n . It is an even function with a
maximum magnitude of x(0) = 1. The plot of the sinc function exhibits positive and
negative lobes of equal width but diminishing height as n increases, with the central lobe
being the biggest one. The central lobe (with nonzero values) extends over −3 ≤n ≤3.
The regular zero-crossings produce a sort of periodicity in the function. However, the
sinc function is not periodic.
A more general form of the discrete-time sinc function is
x(n) = sin(ωn)
ωn
,
−∞< n < ∞
where ω represents the angular frequency with which the function switches between
positive and negative values when creating lobes. In summary, a discrete sinc function
may be speciﬁed completely by (1) the number of samples in its main lobe and (2) a
scale factor, such as, x(0). Two sinc functions are plotted in Figure 11.3.
Example
11.4
A sinc function is given by
x(n) = sin(ωn)
ωn
,
−∞< n < ∞
a.
Let ω = 1. Show that the central lobe contains seven nonzero samples
(−3 ≤n ≤3).
b.
Let ω = 2π/M, where M is an integer. Show that the numerator is periodic
(period = M) but x(n) is not.
c.
Let ω = 2π/M, where M is an even integer. Show that the main lobe contains
M −1 nonzero samples, and the zero-crossings occur at n = ±kM/2.
d.
Let ω = 2π/M, where M is an odd integer. Show that the central lobe contains
M nonzero samples.

690
CHAPTER 11
Discrete-Time Signals
–0.4
–0.2
0.2
0
0.4
0.6
–15
–10
–5
0
(a)
5
10
15
0.8
1
–0.4
–0.2
0.2
0
0.4
0.6
–15
–10
–5
0
(b)
5
10
15
0.8
1
FIGURE 11.3 A discrete sinc function is speciﬁed completely by the number of samples in the
main lobe N and its value at n = 0. (a) The sinc function with N = 9 and x(0) = 1 contains
positive and negative lobes diminishing with 1/n. Regular zero-crossings occur at n = ±5,
±10, ±15, . . . ± 5k, where k is a nonzero integer. Mathematically, the function is x(n) =
sin(πn/5)/(πn/5). (b) A sinc function with N = 11 and x(0) = 1 is expressed by x(n) =
sin(2πn/11)/(2πn/11). Note that the location of the ﬁrst zero-crossing in the envelope is at
5 < n < 6.
Solution
a.
For sin n = 0 we need n = ±π. Because n needs to be an integer, the switch in
the sign occurs between n = 3 and 4 (similarly, between n = −3 and −4). The
central lobe contains seven samples.
b.
Assuming ω = 2π/M, the numerator of the sinc function becomes
sin(ωn)|ω=2π/M = sin(2πn/M) = sin(2π(n + M)/M)
showing a period of M. But sin(ωn)
ωn
decreases with n, making it nonperiodic.
c.
Zero-crossings occur at 2πn/M = ±kπ or n = ±kM/2, where k is an integer.
With M being even, n = ±kM/2 becomes an integer indicating zero-crossings
at n = ±kM/2. The central lobe with nonzero samples includes −M/2 ≤n ≤
M/2, for a total of M −1 samples.
d.
Asssuming M is an odd number, ±M/2 is not an integer and the switch in the
sign of x(n) occurs between n = (M −1)/2 and n = (M + 1)/2. The central
lobe will then contain 2 M−1
2
+ 1 = M samples.

Signals and Systems
691
11.4
Summary of Elementary Functions
Table 11.1 gives a summary of eight elementary functions often used as models for actual
signals.
TABLE 11.1 Several Elementary Functions
Signal
Mathematical Description
Unit Sample
d(n) =

1,
n = 0
0,
n ̸= 0
Unit Step
u(n) =

1,
n ≥0
0,
n < 0
Unit Ramp
r(n) =

n,
n ≥0
0,
n < 0
Sinusoid
x(n) = X0 cos

2πn
N
+ θ

, N is an integer and the period
Exponential
x(n) = X0eσn,
 σ < 0 (decaying)
σ = 0 (constant)
σ > 0 (growing)
Decaying Sinusoid
X0eσn cos(ωn + θ), σ < 0
Complex Exponential
x(n) = X0eσne j(ωn+θ)
e jωn = cos(ωn) + j sin(ωn)
Sinc Function
x(n) = sin(ωn)
ωn
11.5
Periodicity and Randomness
Discrete signals are classiﬁed as
Periodic
Almost-periodic
Nonperiodic
Random
The ﬁrst three groups are subclasses of deterministic signals.
Periodic Signals
A signal x(n) is periodic with period N if x(n) = x(n + N) for all n. The signal is then
referred to as N-periodic. See section 11.6 for examples.

692
CHAPTER 11
Discrete-Time Signals
Sum of Two Periodic Signals
The sum of two discrete-time periodic signals is periodic. The period is the least common
multiple of the two periods. This is in variance with the case of continuous-time signals
where the sum of two periodic signals may be nonperiodic.
Example
11.5
sin(πn/5) is 10-periodic and sin(2πn/15) is 15-periodic. Their sum
x(n) = sin
πn
5

+ sin
2πn
15

is 30-periodic.
Example
11.6
sin(πn/5) is 10-periodic and sin(2πn/11) is 11-periodic. Their sum
x(n) = sin
2πn
10

+ sin
2πn
11

is 110-periodic. Similarly, the signal
x(n) = sin
2πn
100

+ sin
2πn
101

is periodic with period N = 10,100.
Almost-Periodic Signals
A discrete-time signal may not be periodic, as no integer N may be found that would
satisfy the periodicity equation in its exact form, x(n) = x(n + N) for all n. However,
the signal may exhibit certain periodicity, such as in its envelope. We call such classes
of signals almost-periodic. Examples are discrete-time signals obtained by sampling a
continuous-time periodic signal at a rate such that the ratio of the sampling interval to
the period of the continuous-time signal is not a rational number.
Example
11.7
Consider x(n) = sin( n
M ), where M is an integer. For x(n) to be periodic with integer
period N we need x(n) = x(n + N) or
sin
n + N
M

= sin
 n
M

, ⇒N
M = 2π, or N = 2π M
This is not possible because both N and M are integers. However, as M becomes
large, the percentage difference between 2π M and the integer nearest to it becomes
small and sin( n
M ) looks more periodic. Examples of this phenomenon are found in
section 11.7.

Signals and Systems
693
Nonperiodic Signals
Most discrete-time signals are nonperiodic. Examples are the sinc function or a ﬁnite
pulse. They may have ﬁnite or inﬁnite energy.
Random Signals
A discrete-time signal obtained by sampling a random source (such as microphone
sound or hourly readings of weather temperature) is a random signal. Random signals
are modeled by their statistical averages and stochastic processes. An example is x(n) =
a sin(bn), where a and b are random variables.
Gaussian Random Signals
The random sequence x(n) = a, where a is a Gaussian random variable and the samples
are independent of each other, is called white Gaussian noise. An example is shown in
Figure 11.4(a). Filtering white Gaussian noise creates a correlation between the samples.
Figure 11.4(b) shows the sequence of Figure 11.4(a) passed through a low-pass ﬁlter
with cutoff at π/10 radians.
–3
–1
–2
0
1
160
180
200
220
240
260
280
300
320
340
(a)
360
2
3
–8
–4
–2
–6
0
2
160
180
200
220
240
260
280
300
320
340
(b)
360
4
6
FIGURE 11.4 The sequence in (a) is a section of a white Gaussian process. Each sample is a
Gaussian random variable (zero mean and unity variance) and the samples are independent of
each other. The sequence is called white Gaussian noise. Passing a white Gaussian noise through
a band-limited ﬁlter creates a correlation between the samples. The sequence shown in (b) is
produced by passing (a) through a low-pass digital ﬁlter with cutoff at π/10 radians.

694
CHAPTER 11
Discrete-Time Signals
11.6
Examples of Periodic Signals
In Examples 11.8, 11.9, and 11.10, one period of an N-periodic signal is speciﬁed.
Example
11.8
x(n) is a periodic rectangular pulse train with period N and pulse width M. See
Figure 11.5(a).
x(n) =

1,
for 0 ≤n < M
0,
for M ≤n < N
(deﬁned for 1 period)
Example
11.9
x(n) is a periodic exponential pulse.
x(n) =

0.5n,
for 0 ≤n < M
0,
for M ≤n < N
(deﬁned for 1 period)
Example
11.10
The repeated tone burst x(n) is N-periodic. See Figure 11.5(b).
x(n) =

sin(ω0n),
for 0 ≤n < M
0,
for M ≤n < N
(deﬁned for 1 period)
Example
11.11
The signal
x(n) = sin(2πn/5)
sin (πn/20)
is 40-periodic, x(n) = x(n + 40). See Figure 11.5(c). The signal seems like a
sinc function that repeats itself every 40 samples. However, it is not a periodic sinc
function.
Example
11.12
The signal x(n) given in Figure 11.5(d) is N-periodic; that is, x(n) = x(n + N). The
signal is the sum of identical sinc functions repeated at intervals of N samples each.
The mathematical expression of the signal is
x(n) =
∞

k=−∞
sin 2π(n−kN)
M
π(n −kN) ,
−∞< n < ∞

Signals and Systems
695
0
1
(a)
90
80
70
60
50
40
30
20
10
0
–1.5
–1
0
–0.5
0.5
1
(b)
90
80
70
60
50
40
30
20
10
0
1.5
–10
0
–5
5
(c)
90
80
70
60
50
40
30
20
10
0
10
–0.2
0
0.2
0.6
1
(d)
100
90
80
70
60
50
40
30
20
10
0
FIGURE 11.5 (a) A periodic pulse train, period = 20, pulsewidth = 8, duty cycle = 40%. (b) The repeated tone
burst shown in this ﬁgure is 33-periodic. The period of the tone is 6. (c) The signal is 40-periodic. It resembles a sinc
function that is repeated every 40 samples, alternating between positive and negative values. However, the signal is
not a periodic sinc function. It is generated from
x(n) = sin(2πn/5)
sin(πn/20)
The numerator sin(2πn/5) is 5-periodic and the denominator sin(πn/20) is 40-periodic. (d) The signal is 10-periodic.
It is generated from unit-sinc functions (with 3 samples in the main lobe) shifted 10 samples and added together.

696
CHAPTER 11
Discrete-Time Signals
11.7
Sources of Discrete Signals
Some discrete signals are produced by sampling a continuous-time signal x(t) every t
seconds, corresponding to the rate of Fs = 1/t samples per second (also called Hz).
The result is x(nt), which we designate as the discrete-time signal x(n). The above
class of discrete-time signals also includes signals that are functions of space.
Example
11.13
Continuous-time functions x(t) shown in Table 11.2 are sampled at the rate of 100 Hz
(every 10 msec, t = nt = n/100, with a sample at t = 0) to produce the discrete-
time functions x(n). In each case ﬁnd x(n), then specify whether the function is
periodic and, if it is, ﬁnd the period (in either domain).
Solution
See Table 11.2.
TABLE 11.2 Generating Discrete-Time Signals (For Example 11.13)
Continuous Time
Sampling
Discrete Time
x(t)
Periodic?
Period
Frequency
Rate in Hz
x(n)
Periodic?
Period
(sec)
(Hz)
=⇒
(N )
e−10tu(t)
no
—
—
100
e−n/10u(n)
no
—
sin t
t
no
—
—
100
100
n
sin
 n
100

no
—
sin(100πt)
100πt
no
—
—
100
sin(πn)
πn
no
—
sin(500πt)
yes
0.004
250
100
0
—
—
cos(500πt)
yes
0.004
250
100
(−1)n
yes
2
sin(100πt)
yes
0.02
50
100
0
—
—
cos(100πt)
yes
0.02
50
100
(−1)n
yes
2
sin(10πt)
yes
0.2
5
100
sin
πn
10

yes
20
cos(10πt)
yes
0.2
5
100
cos
πn
10

yes
20
sin(πt)
yes
2
0.5
100
sin
 πn
100

yes
200
sin
πt
10

yes
20
0.05
100
sin
 πn
1000

yes
2,000
sin(3t)
yes
2π/3
≈0.48
100
sin(0.03n)
almost
≈209
sin
 t
3

yes
6π
≈0.05
100
sin
 n
300

almost
≈1,885
sin(314t)
yes
2π/314
≈50
100
sin(3.14n)
almost
≈2
sin(3.14t)
yes
2π/3.14
≈0.5
100
sin(0.0314n)
almost
≈200

Signals and Systems
697
Example
11.14
Consider the continuous-time sinusoidal signal x(t) = sin
 2pt
T
	
. The signal is sam-
pled at the rate of Fs samples per second, where N = FsT is an integer. Examine the
effect of the following values of p on x(n).
1.
p = 3
2.
p = 3.14
3.
p = 3.1416
4.
p = π
Solution
The discrete-time signal is obtained by setting t = n/Fs:
x(n) = sin
2pn
TFs

= sin
2pn
N

x(n) is periodic with period N for p = π only. Otherwise, it is almost-periodic. As
p approaches π, x(n) appears closer to being periodic.
11.8
Representation of Discrete Signals
Discrete signals may be represented in one of several ways, such as in analytic closed
form or an array made of a string of numbers, as illustrated in the following examples.
Analytic Representation
A combination of elementary mathematical functions (such as the unit-sample, unit-
step, unit-ramp, sinusoidal, exponential, and similar functions) may be used to represent
discrete-time signals. (See section 11.3 for details on such elementary functions.) A
discrete-time signal may also be represented in a segmented form. For example,
x(n) = u(n) −2u(n −3) + u(n −6) =





1,
0 ≤n < 3
−1,
3 ≤n < 6
0,
elsewhere
Array Representation
A discrete-time signal may be represented by an array in the form of a string of numbers
x(n) = {. . . , x−5, x−4, x−3, x−2, x−1, x0
↑, x1, x2, x3, x4, x5, . . .}
where n is the domain of the signal and xk is the value of its kth element, xk = x(n)|n=k.
The underset up-arrow ↑indicates the location of the origin n = 0. Dots at the left and

698
CHAPTER 11
Discrete-Time Signals
right ends of a sequence represent continuation of the trend set by adjacent samples.
Here are two examples.
x(n) = {. . . , 1/16, 1/8, 1/4, 1/2, 1
↑, 1/2, 1/4, 1/8, 1/16, . . .} = 0.5|n|
x(n) = {. . . , 1/81, 1/27, 1/9, 1/3, 1
↑, 1/2, 1/4, 1/8, 1/16, . . .}
= 3nu(−n) + 0.5nu(n) −d(n)
For a one-sided signal, the side that is made of zeros may be truncated for simplicity as
shown in the following examples.
u(n + 1) = {1, 1
↑, 1, 1, 1, . . .}
u(−n + 2) = {. . . , 1, 1, 1, 1
↑, 1, 1}
0.5nu(n) = {1
↑, 0.5, 0.25, 0.125, . . .}
When the signal has a ﬁnite length N, the string representation may be further reduced
to the following:
x(n) = {x−k, x(−k+1), . . . , x−1, x0
↑, x1, . . . , x(ℓ−1), xℓ}, N = k + ℓ+ 1
The above string contains the values of x(n) for −k ≤n ≤ℓ. Its values outside the
above interval may be zero, a repetition of the given string, or of no interest. The state
of the signal outside the speciﬁed interval may be clariﬁed, if needed, either explicitly
by an additional statement or by the context of the problem. For example,
1.
x(n) = {8, 4, 2, 1
↑, 0.5, 0.25, 0.125} = 0.5n[u(n −4) −u(n −3)]
2.
x(n) = {1
↑, 2, 3, 2, 1} (and we don’t care about the outside interval)
3.
x(n) = {0
↑, 1, 2, 1, 0, −1, −2, −1} and x(n) = x(n + 8) (periodic)
Note that only periodic case 3 above requires an explicit statement. Otherwise, the ﬁnite
sequence by itself carries all the information of interest.
Example
11.15
The signal x(n) = u(n) −u(n −3), where u(n) is the unit-step function starting at
the origin can be stated as
x(n) =

1,
0 ≤n < 3
0,
elsewhere
The domain of x is −∞< n < ∞. x(n) can also be represented by x(n) =
{. . . , 0, 1
↑, 1, 1, 0, . . .} or by x(n) = {1
↑, 1, 1} and zero elsewhere.Theup-arrowiden-
tiﬁes the origin, n = 0.

Signals and Systems
699
Example
11.16
Thesignalh(n) = (0.5)nu(n)mayalsoberepresentedbyh(n) = {. . . , 0, 1
↑, 0.5, 0.25,
0.125, . . .}. The domain of h is −∞< n < ∞. The signal is causal (h(n) = 0 for
n < 0) and is reduced by a factor of 0.5 for each positive n increment. The signal
may also be shown by the array h(n) = {1
↑, .5, .25, .125, . . .}.
Circular Display
A ﬁnite sequence of length N (or a periodic signal) may also be represented by a circular
display of N numbers around a circle at 2π/N degree intervals. Figure 11.6 is the circular
display of the sequence in Example 11.17. The circular display is especially helpful in
visualizing circular shifts and convolutions. See Chapter 13.
2
1
16
8
4
FIGURE 11.6 Circular display of s(n) = {1
↑, 2, 4, 8, 16}, a ﬁnite sequence of length 5. The ﬁrst
element in the sequence corresponds to n = 0 and is placed at a zero angle on the circle. The
display increments n samples in the counterclockwise direction.
Example
11.17
The signal s(n) shown by the array s(n) = {1
↑, 2, 4, 8, 16} is a ﬁnite-power signal
of length 5. The status of the signal outside the interval is left open. The signal is
displayed in Figure 11.6. The ﬁrst element in the sequence corresponds to n = 0 and
is placed at a zero angle on the circle. The display increments the location of s(n) in
the counterclockwise direction by 2π/5 = 72◦.
11.9
Digital Signals
A discrete-time signal that can assume only discrete values is called a digital signal. In
signal processing we use digital signals, and digital signal processing (DSP) has become
synonymous with the processing of discrete-time signals. In practice, DSP is normally
performed by digital devices on binary numbers. Therefore, the bulk of digital signals is
represented by binary numbers.
Example
11.18
Consider a discrete-time signal whose amplitude varies between 0 and 1 volt, 0 ≤
x(n) < 1. The signal amplitude is digitized into four levels 0, 1, 2, and 3, and
represented as a two-bit binary number x(n) = y1y0, where y0 and y1 are the two bits
representing the digitized signal. See Table 11.3.

700
CHAPTER 11
Discrete-Time Signals
TABLE 11.3 Digitized Signal (For Example 11.18)
Signal Amplitude
Level Assignment
Binary Representation
0 ≤x(n) < 0.25
0
00
0.25 ≤x(n) < 0.5
1
01
0.5 ≤x(n) < 0.75
2
10
0.75 ≤x(n) < 1
3
11
Here is an example.
x(n)={0.81, 0.63, 0.32, 0.17, 0.92, 0.48, 0.54}10
digitized
	⇒
{11, 10, 01, 00, 11, 01, 10}2
A 3-bit word is needed to represent a signal that is digitized into eight levels. A
digital signal containing 256 levels needs an 8-bit word representation. An N-bit
word represents a signal with 2N discrete levels.
11.10
Energy and Power Signals
The total energy in a signal is deﬁned by
Total energy =
∞

n=−∞
x(n)x∗(n) =
∞

n=−∞
|x(n)|2
where x∗(n) is the complex conjugate of x(n). If the total energy is ﬁnite, the signal is
called an energy signal. Energy signals are not necessarily of ﬁnite length. Examples are
sinc functions and signals whose amplitudes are modulated by exponential decay.
The average power over a segment of length N, from n0 to (n0 + N −1), is deﬁned
by
Average power = 1
N
n0+N−1

n=n0
|x(n)|2
If a signal has inﬁnite energy, it might have ﬁnite power, in which case it is called a
power signal. Periodic signals are power signals. Random signals with inﬁnite duration
(and inﬁnite energy) are modeled as power signals. Nonperiodic signals can be power
signals, too.
11.11
Time Reversal
In the analysis of discrete-time signals and digital signal processing we often encounter
time reversal, which converts x(n) to x(−n), where n is the argument of the function.
When a signal x(n) is represented by a mathematical formula, change the sign of n
to −n and will you have the formula for x(−n). Time reversal ﬂips the plot of x(n)
around the origin, n = 0, to produce the plot of x(−n). A graphical visualization is
often helpful especially when time reversal and shift are combined. The following four
examples illustrate time reversal.

Signals and Systems
701
Example
11.19
Given x(n) = 2nu(−n) + 0.75nu(n), see Figure 11.7(a). Find and plot x(−n), and
compare with the plot of x(n).
0
0.2
0.4
0.6
Magnitude
–8
–6
–4
–2
0
6
4
2
8
Discrete Variable n
(a)
10
–10
0.8
1
0
0.2
0.4
0.6
Magnitude
–8
–6
–4
–2
0
6
4
2
8
Discrete Variable n
(b)
10
–10
0.8
1
FIGURE 11.7 (a) The two-sided exponential function x(n) = 2nu(−n) + 0.75nu(n) is shown. (b) Plot of the time-
reversed function x(−n) = 2−nu(n) + 0.75−nu(−n).
Solution
Changen to−n toﬁnd x(−n) = 2−nu(n)+0.75−nu(−n)ThisisplottedinFigure11.7(b).
Note that time reversal ﬂips the plot of the function around the vertical at n = 0.
Example
11.20
Five examples of time reversal are given in Table 11.4.
TABLE 11.4 Examples of Time Reversal
x(n) = 2−nu(n)
x(−n) = 2nu(−n)
x(n) =
 n,
n ≥3
0,
elsewhere
x(−n) =
 −n,
n ≤−3
0,
elsewhere
x(n) =
 0.5n,
n < −2
0,
elsewhere
x(−n) =
 0.5−n
n > 2
0,
elsewhere
x(n) =

cos n
2
	
,
2 ≤n ≤5
0,
elsewhere
x(−n) =

cos n
2
	
−5 ≤n ≤−2
0,
elsewhere
x(n) =





cos πn
8
	
,
0 ≤n ≤4
−cos πn
8
	
,
−4 ≤n < 0
0,
elsewhere
x(−n) =





cos πn
8
	
,
−4 ≤n ≤0
−cos πn
8
	
,
0 < n ≤4
0,
elsewhere

702
CHAPTER 11
Discrete-Time Signals
Example
11.21
Time reversal has no effect on the functions shown in Table 11.5. x(n) = x(−n). The
functions are called even.
TABLE 11.5 Time Reversing an Even Function Doesn’t Change It
x(n) = 2−|n|
x(−n) = 2−|n|
x(n) = 2nu(−n) + 2−nu(n)
x(−n) = 2−nu(n) + 2nu(−n)
x(n) =





−n,
n ≤−3
n,
n ≥3
0,
elsewhere
x(−n) =





n,
n ≥3
−n,
n ≤−3
0,
elsewhere
x(n) =
 cos πn
8
	
,
−4 ≤n ≤4
0,
elsewhere
x(−n) =
 cos πn
8
	
−4 ≤n ≤4
0,
elsewhere
x(n) =





sin πn
8
	
,
0 < n ≤4
−sin πn
8
	
,
−4 ≤n < 0
0,
elsewhere
x(−n) =





−sin πn
8
	
,
−4 ≤n < 0
sin πn
8
	
,
0 < n ≤4
0,
elsewhere
Example
11.22
Time reversal produces a sign change in the functions shown in Table 11.6. x(n) =
−x(−n). The functions are called odd.
TABLE 11.6 Time Reversing an Odd Function Changes Its Sign Only
x(n) = −2nu(−n) + 2−nu(n)
x(−n) = −2−nu(n) + 2nu(−n)
x(n) =



n,
n ≤−3
n,
n ≥3
0,
elsewhere
x(−n) =



−n,
n ≥3
−n,
n ≤−3
0,
elsewhere
x(n) =



1,
0 < n ≤3
−1,
−3 ≤n < 0
0,
elsewhere
x(−n) =



1,
−3 ≤n < 0
−1,
0 < n ≤3
0,
elsewhere
x(n) =

sin  πn
8
	
,
−4 ≤n ≤4
0,
elsewhere
x(−n) =

−sin πn
8
	
−4 ≤n ≤4
0,
elsewhere
x(n) =





cos πn
8
	
,
0 < n ≤4
−cos πn
8
	
,
−4 ≤n < 0
0,
elsewhere
x(−n) =





cos πn
8
	
,
−4 ≤n < 0
−cos πn
8
	
,
0 < n ≤4
0,
elsewhere
Summary
In the mathematical expression for x(n), change n to −n and you have a mathematical
expression for x(−n). Flip the graph of x(n) horizontally around n = 0 and you have
the graph for x(−n).

Signals and Systems
703
11.12
Time Shift
Substituting n by n −k in the mathematical expression for x(n) produces a shift of k
units in it. When k is a positive number the shift delays the signal by k units and slides
the plot of x(n) to the right by k units. A negative k advances it and slides the plot to the
left. For the case of sinusoidal functions, a time shift translates into a phase shift.
Example
11.23
Three examples of a time shift are given in Table 11.7.
TABLE 11.7 Examples of Time Shift
x(n) = 2−|n|
x(n −2) = 2−|n−2|
x(n) = 2−nu(n)
x(n + 3) = 2−n
8 u(n + 3)
x(n) =
 cos πn
8
	
,
−4 ≤n ≤4
0,
elsewhere
x(n −4) =
 sin  πn
8
	
0 ≤n ≤8
0,
elsewhere
A shift of four time units in cos(πn/8) (third part of Table 11.7) translated into
a 90◦phase shift and has converted it to sin(πn/8).
Example
11.24
Time shift in periodic signals
After N shifts a periodic signal with period N reverts to its original form. An example
is given for x(n) = cos(πn/2) in Table 11.8.
TABLE 11.8 Time Shifts in the Sinusoid cos(πn/2)
Function
Representation
x(n)
= cos
πn
2

= {. . . , −1, 0,
one period



1
↑, 0, −1, 0, 1, 0, . . . }
x(n −1)
= cos
πn
2 −π
2

= {. . . , 0, −1,
one period



0
↑, 1, 0, −1, 0, 1, . . . }
x(n −2)
= cos
πn
2 −π

= {. . . , 1, 0,
one period



−1
↑, 0, 1, 0, −1, 0, . . .}
x(n −3)
= cos

πn
2 −3π
2

= {. . . , 0, 1,
one period



0
↑, −1, 0, 1, 0, −1, . . .}
x(n −4)
= cos
πn
2 −2π

= {. . . , −1, 0,
one period



1
↑, 0, −1, 0, 1, 0, . . . }

704
CHAPTER 11
Discrete-Time Signals
It is easily seen that one only needs to attend to a ﬁnite segment of the signal seen
through a one-period-long window (e.g., from n = 0 to 3 as shown in Table 11.8). See
the close parallels with circular shift discussed in section 11.15.
11.13
Combination of Time Reversal and Shift
Some mathematical operations may require shifting a signal and reversing it. The order
according to which the operations are applied become important. In this section we begin
with examples and then provide guidelines.
Example
11.25
Several time shifts and time reversals of the unit-step function are given in Table 11.9.
Plots of the functions are found in Figure 11.8(a) to (f). Note that a delay shifts the
plot to the right and an advance shifts it to the left. Also note that the time-reversal
operation is pivoted around n = 0.
TABLE 11.9 Time Shifts and Time Reversals of the Unit-Step Function u(n)
Function
Description
Representation
Figure
u(n)
Unit step
{· · · 0, 0, 0, 0, 0, 0, 1
↑, 1, 1, 1, 1, 1, 1 · · ·} =
 1,
n ≥0
0,
n < 0
Figure 11.8(a)
u(−n)
Time reversal
{· · · 1, 1, 1, 1, 1, 1, 1
↑, 0, 0, 0, 0, 0, 0 · · ·} =
 1,
n ≤0
0,
n > 0
Figure 11.8(b)
u(n −3)
Delay (3 units)
{· · · 0, 0, 0, 0, 0, 0, 0
↑, 0, 0, 1, 1, 1, 1 · · ·} =
 1,
n ≥3
0,
n < 3
Figure 11.8(c)
u(−n −3)
Time reversal
{· · · 1, 1, 1, 1, 0, 0, 0
↑, 0, 0, 0, 0, 0, 0 · · ·} =
 1,
n ≤−3
0,
n > −3
Figure 11.8(d)
u(n + 4)
Advance (4 units)
{· · · 0, 0, 1, 1, 1, 1, 1
↑, 1, 1, 1, 1, 1, 1 · · ·} =
 1,
n ≥−4
0,
n < −4
Figure 11.8(e)
u(−n + 4)
Time reversal
{· · · 1, 1, 1, 1, 1, 1, 1
↑, 1, 1, 1, 1, 0, 0 · · ·} =
 1,
n ≤4
0,
n > 4
Figure 11.8(f)
The validity of the array representations in Table 11.9 and the plots of Figure 11.8
is checked by applying the deﬁnition of the unit-step function.
Exchanging the Order of Time Reversal and Shift
Note that changing the order of time shift and time reversal would lead to the same
result only if at the same time delay and advance are also interchanged. As an example,
u(−n−3) may be obtained by a delay/reversal sequence; ﬁrst introduce a three-unit delay
in u(n) (by changing n to n−3) to produce u(n−3), then reverse u(n−3) (by changing n
to −n) to obtain u(−n−3). Conversely, u(−n−3) may be obtained by a reversal/advance

Signals and Systems
705
0
–6
–4
–2
0
6
4
2
8
(a)
10
–8
1
0
–6
–4
–2
0
6
4
2
8
10
–8
1
0
–6
–8
–4
–2
0
6
4
2
(b)
8
–10
1
0
–6
–8
–4
–2
0
6
4
2
(d)
8
–10
1
(c)
0
–6
–4
–2
0
6
4
2
8
(e)
10
–8
1
0
–6
–8
–4
–2
0
6
4
2
(f)
8
–10
1
FIGURE 11.8 (a) u(n), (b) u(−n), (c) u(n −3), (d) u(−n −3), (e) u(n + 4), (f) u(−n + 4)
sequence; ﬁrst reverse u(n) (by changing n to −n) to obtain u(−n), then introduce a
three-unit advance (by changing n to n + 3) in it to get u(−(n + 3)) = u(−n −3).
Example
11.26
Shifts and reversals of a right-sided exponential function are given below.
a.
One-sided exponential function
x(n) = 2−nu(n) =

2−n,
n ≥0
0,
n < 0 = {· · · 0, 0, 0, 1
↑, 1/2, 1/4, 1/8, 1/16, 1/32, . . .}
b.
Its shift to the right by three units to produce a delay
x(n −3) = 2−(n−3)u(n −3) =

8 × 2−n,
n ≥3
0,
n < 3
= {· · · 0, 0, 0
↑, 0, 0, 1, 1/2, 1/4, 1/8, 1/16, 1/32, . . .}

706
CHAPTER 11
Discrete-Time Signals
c.
Its shift to the left by four units to produce an advance
x(n + 4) = 2−(n+4)u(n + 4) =
 2−n
16 ,
n ≥−4
0,
n < −4
= {· · · 0, 0, 1, 1/2, 1/4, 1/8, 1/16
↑
, 1/32, . . .}
d.
Reversal of x(n) around the point n = 0 to produce
x(−n) = 2nu(−n) =

2n,
n ≤0
0,
n > 0
= {· · · 1/32, 1/16, 1/8, 1/4, 1/2, 1
↑, 0, 0, 0 · · ·}
e.
Reversal of x(n −3) around the point n = 0 to produce
x(−n −3) = 2(n+3)u(−n −3) =

8 × 2n,
n ≤−3
0,
n > −3
= {· · · 1/32, 1/16, 1/8, 1/4, 1/2, 1, 0, 0, 0
↑, 0 · · ·}
f.
Reversal of x(n + 4) around the point n = 0 to produce
x(−n + 4) = 2(n−4)u(−n + 4) =
 2n
16,
n ≤4
0,
n > 4
= {· · · 1/32, 1/16
↑
, 1/8, 1/4, 1/2, 1, 0, 0, 0, 0 · · ·}
11.14
Time Scaling and Transformation
Time Scaling
Changing the variable n in the expression for a discrete-time function to an, where a
is a constant, generates a new function x(an). The operation is called time scaling. For
example, in the function x(n) = 2−nu(n) replace n by 2n and you will get the new
time-scaled function x(2n) = 2−2nu(2n) = 4−nu(n). Time scaling compresses the time
axis (if a > 1) or expands it (if a < 1).
Example
11.27
Given x(n) = {. . . , 0, 0, 1
↑, 1, 1, 1, 1, 1, 1, 0, 0, . . .}, ﬁnd y(n) = x(2n).
Solution
...
y(0) = x(0) = 1
y(1) = x(2) = 1
y(2) = x(4) = 1
y(3) = x(6) = 1
y(4) = x(8) = 0
...
y(n) = {. . . , 0, 0, 1
↑, 1, 1, 1, 0, 0, . . .}

Signals and Systems
707
Alternative Solution
Describe x(n) by the following expression and change n to 2n.
x(n) =

1,
0 ≤n ≤6
0,
elsewhere
x(2n) =

1,
0 ≤2n ≤6
0,
elsewhere
=

1,
0 ≤n ≤3
0,
elsewhere
Yet Another Solution
x(n) = u(n) −u(n −7)
x(2n) = u(2n) −u(2n −7) = u(n) −u(n −4)
Time Transformation
This operation converts the discrete variable n to another discrete variable m = an + b,
where a and b are constant numbers. The operation, therefore, combines the three oper-
ations of reversal, shift, and scaling through a single formula.
Example
11.28
Given
x(n) =

n,
0 ≤n ≤6
0,
elsewhere
ﬁnd y(n) = x(−2n + 3).
Solution
y(n) = x(−2n + 3) =

−2n + 3,
0 ≤−2n + 3 ≤6
0,
elsewhere
=

−2n + 3,
−1 ≤n ≤1
0,
elsewhere
=







5,
n = −1
3,
n = 0
1,
n = 1
0,
elsewhere
Alternative Solution
Let x(n) = n[u(n) −u(n −7)]. Then,
x(−2n + 3) = (−2n + 3) [u(−2n + 3) −u(−2n + 3 −7)]
= (−2n + 3) [u(−n + 1) −u(−n −2)] =







5,
n = −1
3,
n = 0
1,
n = 1
0,
elsewhere

708
CHAPTER 11
Discrete-Time Signals
Veriﬁcation
x(n) = {. . . , 0, 0, 0
↑, 1, 2, 3, 4, 5, 6, 0, 0, . . .}
y(n) = x(−2n + 3)
...
y(−2) = x(4 + 3) = 0
y(−1) = x(2 + 3) = 5
y(0) = x(3) = 3
y(1) = x(−2 + 3) = 1
y(2) = x(−4 + 3) = 0
...
y(n) = {. . . , 0, 5, 3
↑, 1, 0, 0, . . .}
11.15
Circular Shift
The circular shift operation is applied to ﬁnite-duration sequences. The idea behind it is
simple. The sequence is shifted to the right by the speciﬁed number of positions. Those
members of the sequence that “fall off” the tail end as a result of the shift are tacked
back on to the start of the sequence. As such, they “wrap around.” A similar situation
applies to a left shift. This is best illustrated by an example.
Example
11.29
Consider a ﬁnite-duration sequence such as x(n) = {1
↑, 2, 4, 8, 16} shown by the
circular display in Figure 11.9(a). A circular shift of the above sequence by k units
to the right produces a new sequence as shown in the table below for k = 1, . . . , 5.
k = 1,
x(n −1)|circular = {16
↑, 1, 2, 4, 8}
Figure 11.9(b)
k = 2,
x(n −2)|circular = {8
↑, 16, 1, 2, 4}
Figure 11.9(c)
k = 3,
x(n −3)|circular = {4
↑, 8, 16, 1, 2}
Figure 11.9(d)
k = 4,
x(n −4)|circular = {2
↑, 4, 8, 16, 1}
Figure 11.9(e)
k = 5,
x(n −5)|circular = {1
↑, 2, 4, 8, 16}
Figure 11.9(f)
2
1
16
{1, 2, 4, 8, 16}
(a)
↑
↑
↑
↑
↑
↑
8
4
1
16
8
{16, 1, 2, 4, 8}
(b)
4
2
16
8
4
{8, 16, 1, 2, 4}
(c)
2
1
8
4
2
{4, 8, 16, 1, 2}
(d)
1
16
4
2
1
{2, 4, 8, 16, 1}
(e)
16
8
2
1
16
{1, 2, 4, 8, 16}
(f )
8
4
FIGURE 11.9 Circular shift.

Signals and Systems
709
It is seen that a ﬁnite sequence with N samples reverts to its original form after
N circular shifts, as was seen for linear shift in a periodic signal with a period N
(Example 11.24). The circular shifts of s(n) = {1
↑, 2, 4, 8, 16} by k units to the right
are displayed in Figure 11.9 for k = 1, . . . 5. The ﬁfth shift reverts the signal to its
original form. Circular shift will be discussed in more detail in Chapter 17 along with
application.
11.16
Even and Odd Functions
A function x(n) is even if x(n) = x(−n) for all n. See Figure 11.10(a). Similarly, a
function x(n) is odd if x(n) = −x(−n) for all n. See Figure 11.10(b). Any function
x(n) may be represented by the sum of two components as x(n) = xe(n)+ xo(n), where
xe(n) is an even function, called the even part of x(n), and xo(n) is an odd function,
called the odd part of x(n). The functions in Figure 11.10(a) and (b) are the even and
odd parts of the function shown in Figure 11.10(c). The even and odd parts of a function
are uniquely determined from x(n) by the following:
xe(n) = x(n) + x(−n)
2
xo(n) = x(n) −x(−n)
2
Note: The value of an odd function at the origin is zero, xo(0) = 0.
The expressions given above for xe(n) and xo(n) can be derived by the following. Let
x(n) = xe(n) + xo(n). Then, x(−n) = xe(−n) + xo(−n). But by deﬁnition, xe(−n) =
xe(n) and xo(−n) = −xo(n). Therefore, x(−n) = xe(n) −xo(n). By adding x(n)
and x(−n) we get x(n) + x(−n) = 2xe(n). By subtracting x(−n) from x(n) we get
x(n) −x(−n) = 2xo(n). These give the results stated previously:
xe(n) = x(n) + x(−n)
2
xo(n) = x(n) −x(−n)
2
Example
11.30
Find the even and odd parts of x(n) = {2
↑, 2, 2} [x(n) = 0 outside the bracket].
Solution
We ﬁrst ﬁnd x(−n) = {2, 2, 2
↑}. Then,
xe(n) = x(n) + x(−n)
2
= {1, 1, 2
↑, 1, 1}
xo(n) = x(n) −x(−n)
2
= {−1, −1, 0
↑, 1, 1}

710
CHAPTER 11
Discrete-Time Signals
–1
0
1
5
4
3
2
6
–14
–12
–10
–8
–6
–4
–2
0
(a)
4
2
6
8
10
12
14
16
7
8
–8
–6
–4
4
2
0
–2
6
–14
–12
–10
–8
–6
–4
–2
0
(b)
4
2
6
8
10
12
14
16
8
–2
0
2
4
6
–14
–12
–10
–8
–6
–4
–2
0
(c)
4
2
6
8
10
12
14
16
16
8
10
12
14
FIGURE 11.10 (a) An even function. (b) An odd function. (c) The function whose even and
odd parts are shown in (a) and (b).
Example
11.31
Find the even and odd parts of h(n) = {1, 2, 3
↑, 2, 1} [h(n) = 0 outside the bracket].
Solution
h(n) is an even function because h(−n) = h(n) = {1, 2, 3
↑, 2, 1}. Therefore, ho(n) =
0. This result may also be derived from the equations
he(n) = h(n) + h(−n)
2
= {1, 2, 3
↑, 2, 1}
ho(n) = h(n) −h(−n)
2
= 0, all n

Signals and Systems
711
Example
11.32
Find the even and odd parts of x(n) = {1, 3
↑, 3, 2}.
Solution
We ﬁrst ﬁnd x(−n) = {2, 3, 3
↑, 1}. Then,
xe(n) = x(n) + x(−n)
2
= {1, 2, 3
↑, 2, 1}
xo(n) = x(n) −x(−n)
2
= {−1, −1, 0
↑, 1, 1}
Example
11.33
Find the even and odd parts of
h(n) =

0.5n,
for n ≥0
0,
for n < 0
Solution
We ﬁrst ﬁnd h(−n)
h(−n) =

0,
for n > 0
0.5−n,
for n ≤0
The even part is
he(n) = h(n) + h(−n)
2
=







1
2(0.5)n,
for n > 0
1,
for n = 0
1
2(0.5)−n,
for n < 0
and the odd part is
ho(n) = h(n) −h(−n)
2
=





1
2(0.5)n,
for n > 0
0,
for n = 0
−1
2(0.5)−n,
for n < 0
Note that he(n) + ho(n) = (0.5)nu(n).
Even and Odd Parts of a Causal Function
Signals that are zero for n < 0 are called causal (and those which are zero for n > 0
are anticausal). It can be veriﬁed that a causal discrete-time function h(n) is related to
its even or odd parts by the following equations:
h(n) = 2he(n)u(n) −he(0)d(n)
h(n) = 2ho(n)u(n) + h(0)d(n)

712
CHAPTER 11
Discrete-Time Signals
where u(n) and d(n) are the unit-step and unit-sample functions, respectively. From the
above equations we conclude that a causal function h(n) may be obtained from its even
part he(n) or from its odd part ho(n) and h(0). In other words, any one of the three
functions given below can specify the other two.
1.
h(n)
2.
he(n)
3.
ho(n) and h(0)
Example
11.34
The causal x(n) = e−n/3u(n) = (0.7163)nu(n) and the anticausal x(−n)=en/3u(−n)
=(0.7163)−nu(−n) exponential functions are shown in Figure 11.11 along with the
even and odd parts of x(n).
–6
–4
–2
0
6
4
2
(a)
8
–8
0
0.2
0.4
0.6
0.8
1
–6
–4
–2
0
6
4
2
(b)
8
–8
0
–0.2
0.2
0.4
0.6
0.8
1
–6
–4
–2
0
6
4
2
(c)
8
–8
0
0.2
0.4
0.6
0.8
1
–6
–4
–2
0
6
4
2
(d)
8
–8
–0.3
–0.4
–0.2
–0.1
0
0.1
0.2
0.3
FIGURE 11.11 (a) The causal exponential function x(n) = e−n/3u(n) = (0.7163)nu(n). (b) The anticausal expo-
nential function x(−n) = en/3u(−n) = (0.7163)−nu(−n). (c) The even part of x(n) is [x(n) + x(−n)] /2 = 0.5e−|n|/3.
(d) The odd part of x(n) is
[x(n) −x(−n)]/2
= 0.5e−|n|/3 × sgn(n) −0.5d(n)
where sgn(n) (pronounced as signum and standing for sign of) is deﬁned by
sgn(n) =

1,
for n ≥0
−1,
for n < 0

Signals and Systems
713
11.17
Windows
The domain of mathematical models of real signals is −∞< n < ∞. However, in
practice we process ﬁnite-length segments of a signal at a time. Mathematically, this
corresponds to multiplying the original signal by a window, which is nonzero within an
interval and zero outside that interval. A window is, therefore, a ﬁnite-duration pulse
through which we look at a data stream or function. The role of the window is to create
and shape a ﬁnite segment of the sequence in a way that certain characteristics are met.
Given the duration of the window, its shape has an important role in its function. Five
examples of even windows of length 2M + 1 are listed in Table 11.10.
TABLE 11.10 Five Commonly Used Discrete-Time Windows
−M ≤n ≤M
0 ≤n ≤N −1
Window Name
(Even Function)
(Causal Function)
Rectangular (uniform)
1
1
Triangular (Bartlett)
1 −|n|
M
1 −
2
n −N−1
2

N −1
Hanning
0.5 + 0.5 cos
πn
M

0.5 −0.5 cos

2πn
N −1

Hamming
0.54 + 0.46 cos
πn
M

0.54 −0.46 cos

2πn
N −1

Blackman
0.42 + 0.5 cos
πn
M

+ 0.08 cos

2πn
M

0.42 −0.5 cos

2πn
N −1

+ 0.08 cos

4πn
N −1

Example
11.35
a.
Shift the even Hanning, Hamming, and Blackman windows of Table 11.10 by
M units to the right to make them N-point causal functions with N = 2M + 1.
Find mathematical expressions for the shifted functions in terms of N and show
that they are in agreement with those given for the causal functions in that table.
b.
Write a computer program to evaluate the window functions in Table 11.10.
c.
Obtain numerical values of the even functions for M = 5 and the causal
functions for N = 11. Brieﬂy summarize their time-domain characteristics.
d.
Evaluate the causal functions of Table 11.10 for N = 10. Compare with the
values obtained in part c for N = 11 and observe their differences.

714
CHAPTER 11
Discrete-Time Signals
Solution
a.
Replace n by n −M. This generates N-point long causal functions, where
N = 2M + 1 or M = (N −1)/2.
cos
πn
M

, −M ≤n ≤M 	⇒cos
π(n −M)
M

= −cos
πn
M

= −cos
 2πn
N −1

, 0 ≤n ≤N −1
cos
2πn
M

, −M ≤n ≤M 	⇒cos
2π(n −M)
M

= cos
2πn
M

= cos
 4πn
N −1

, 0 ≤n ≤N−1
b.
See below.
% Even window functions (2M+1 points from -M to M)
M=5; n=0:M;
tri1=1-n/M
han1=0.5+0.5*cos(pi*n/M)
ham1=0.54+0.46*cos(pi*n/M)
blk1=0.42+0.5*cos(pi*n/M)+0.08*cos(2*pi*n/M)
%
% Causal window functions (N points
from 0 to N-1)
N=11; n=0:N-1;
tri2=1+2*(n-(N-1)/2)/(N-1)
han2=0.5-0.5*cos(2*pi*n/(N-1))
ham2=0.54-0.46*cos(2*pi*n/(N-1))
blk2=0.42-0.5*cos(2*pi*n/(N-1))+0.08*cos(4*pi*n/(N-1))
c.
The 11-point windows are symmetrical. The values for half of each window are
given below.
Triangular: 1
0.8
0.6
0.4
0.2
0
Hanning:
1
0.9045
0.6545
0.3455
0.0955
0
Hamming:
1
0.9121
0.6821
0.3979
0.1679
0.08
Blackman:
1
0.8492
0.5098
0.2008
0.0402
0
The triangular, Hanning, and Blackman windows all taper off to a zero value at
their edge. The Hamming window does not. The frequency characteristics of
these windows will be discussed in Chapter 16.
d.
Having an even number of samples, the windows now become half-symmetric
as observed below.
Triangular: 0
0.2222
0.4444
0.6667
0.8889
0.8889
0.6667
0.4444
0.2222
0
Hanning:
0
0.1170
0.4132
0.7500
0.9698
0.9698
0.7500
0.4132
0.1170
0
Hamming:
0.08
0.1876
0.4601
0.7700
0.9723
0.9723
0.7700
0.4601
0.1876
0.08
Blackman:
0
0.0509
0.2580
0.6300
0.9511
0.9511
0.6300
0.2580
0.0509
0

Signals and Systems
715
11.18
Signal Processing and Filtering
Signals are processed for various purposes such as ﬁltering, detection, prediction, range
measurement, image and speech recognition, medical and dignostic purposes, decision
making, and the like. These may require two types of operations: (1) algebraic operations
such as addition, subtraction, mutiplication, division; and (2) logic operations such as
AND, OR, NAND, NOR, and so on. In this book we concentrate on the ﬁrst category.
Since most processing is done by digital tools such as digital computers, we normally call
it digital signal processing (DSP). DSP tools and techniques allow us to handle complex
DSP problems from design to simulation, testing, and real-time processing. The basic
mathematical tools and techniques for working with discrete signals are covered in
the remainder of this book. The following examples illustrate some bare-bones signal
processing operations dealing with ﬁltering and smoothing.
Example
11.36
Consider the discrete-time sinusoidal signal x(n) = cos(αn), where α is a constant.
Show that
a.
x(n + k) + x(n −k)
2
= cos(αk) cos(αn) = cos(αk)x(n) = Hx(n)
b.
x(n) + x(n −2k)
2
= cos(αk) cos(αn −αk) = cos(αk)x(n −k) = Hx(n −k)
where H = cos(αk) is a constant.
Solution
To show a,
x(n + k) = cos[α(n + k)] = cos(αn) cos(αk) −sin(αn) sin(αk)
x(n −k) = cos[α(n −k)] = cos(αn) cos(αk) + sin(αn) sin(αk)
x(n + k) + x(n −k) = 2 cos(αk) cos(αn) = 2 cos(αk)x(n) = 2Hx(n)
To show b, in a let n + k = ℓ. Then, n = ℓ−k and
x(ℓ) + x(ℓ−2k) = 2 cos(αk) cos(αℓ−αk) = 2Hx(ℓ−k)
An appropriate choice of delay such that αk = π/2 (or odd multiples of π/2)
will result in H = 0 and allows us to ﬁlter out frequencies at α, as illustrated in
Examples 11.37 and 11.38.
Example
11.37
Theinformation-carryingsignaltobepickedupbyasensorisasinusoidatanunknown
frequency F < 600 Hz. The sensor also picks up a 60-Hz disturbance. The sensor’s
output is, therefore, x(t) = A cos(2πFt) + B cos(120πt). The ﬁrst term constitutes
the signal of interest and the second term is the undesired disturbance. Devise a simple
DSP operation that notches out the sinusoidal interference and keeps the signal.

716
CHAPTER 11
Discrete-Time Signals
Solution
We ﬁrst sample x(t) at the rate of 1,200 samples per second, twice the maximum
frequency of the information-carrying sinusoid to preserve the information in it (see
Chapter 10). By setting t = nt = n/1,200 in x(t) we obtain a discrete-time data
sequence x(n) = A cos(ωn) + B cos(αn), where ω = 2π F/1200 and α = π/10 are
the angular frequencies in the discrete domain. To ﬁlter out the cos(αn), we apply the
shift-and-add operation used in Example 11.36.
x(n) + x(n −2k)
2
= Acos(ωn) + cos(ωn −2ωk)
2
+ B cos(αn) + cos(αn −2αk)
2
= A cos(ωk) cos ω(n −k) + B cos(αk) cos α(n −k)
The operation delays both the signal and disturbance by k units and changes their
magnitudes by the constant values cos(ωk) and cos(αk), respectively. By choosing
k = 5 we will have αk = 5π/10 = π/2, which results in cos(αk) = 0. This
blocks the 60 Hz interference (i.e., notches it out). Then, the output of the digital ﬁlter
becomes y(n) = A cos(ωk) cos ω(n −5). The ﬁve-unit delay in the discrete signal
corresponsds to a delay of τ = 5/1,200 seconds or 416.6 µs in the continuous-time
domain and can be accommodated. But, more importantly, the ﬁlter attenuates the
signal by the factor cos(5ω), corresponding to cos(π F/120) in the continuous-time
domain. Unless F is known the strength of the signal, therefore, cannot be determined.
Moreover, the frequency-dependent amplitude change produced by the above ﬁltering
operation blocks the signal at F = 120 and 240 Hz.
Example
11.38
Consider a signal x(t) made of the sum of two sinusoids at frequencies F1 and F2.
x(t) = A1 cos(2πF1t) + A2 cos(2πF2t)
To block the F2 component and retain as much of the F1 component as possible,
we ﬁrst sample x(t) at the rate of Fs using an analog-to-digital converter (A/D) to
obtain x(n). We then use a shift-and-add operation (shown by the block diagram of
Figure 11.12) followed by a digital-to-analog converter (D/A). Find the amount of
shift necessary to block the component at F2. Then determine the ﬁlter’s effect on the
component at F1.
Solution
The discrete-time data is
x(n) = A1 cos(ω1n) + A2 cos(ω2n), where ω1 = 2π
 F1
Fs

and ω2 = 2π
 F2
Fs

Following the procedure used in Examples 11.36 and 11.37
x(n) + x(n −2k) = 2A1 cos(ω1k) cos[ω1(n −k)] + 2A2 cos(ω2k) cos[ω2(n −k)]

Signals and Systems
717
To block the ω2 component we need cos(ω2k) cos[ω2(n −k)] = 0 for all n, which is
achieved if
cos(ω2k) = 0,
ω2k = π
2 ,
k =
π
2ω2
= 1
4
Fs
F2
The component at ω1 will be multiplied by a factor
2 cos(ω1k)

k= π
2ω2
= 2 cos
π
2
ω1
ω2

= 2 cos
π
2
F1
F2

In summary, assuming unity gains for the A/D and D/A converters, the continuous-
time signal at the output of the system of Figure 11.12 will be
y(t) = 2A1 cos
π
2
F1
F2

cos [2π F1(t −τ)] where τ =
1
4F2
x(t)
x(n)
A
D
D
A
Z–1
Z–1
y(n)
Direct path
2k-units of delay
Digital Filter
y(t)
+
FIGURE 11.12 Block diagram of a digital signal processing system made of an A/D converter, a
simple digital ﬁlter, and a D/A converter. The ﬁlter has a direct and an indirect path of k-unit delay
(a unit delay is shown by the symbol z−1). Input and output signals are in the continuous-time
domain. Filtering is done in the discrete-time domain. See Example 11.38.
Summary of Examples 11.36--38
The simple digital ﬁlters discussed in Examples 11.36 to 11.38 are summarized below.
Example 11.36:
x(n) = cos(αn).
x(n) + x(n −2k)
2
= Hx(n −k),
where H = cos(αk)
Example 11.37:
x(t) = A cos(2π Ft) + B cos(120πt).
x(n) = A cos(ωn) + B cos(αn),
where ω = 2π
F
1,200 and α = π
10
x(n) + x(n −10)
2
= H A cos ω(n −5),
where H = cos(5ω)

718
CHAPTER 11
Discrete-Time Signals
Example 11.38:
x(t) = A cos(2πF1t) + B cos(2πF2t).
x(n) = A cos(ω1n) + B cos(ω2n),
where ω1 = 2π F1
Fs
, ω2 = 2π F2
Fs
.
x(n) + x(n −2k)
2
= HA cos ω1(n −k),
where H = cos
π
2
F1
F2

and k = 1
4
Fs
F2
y(t) = 2A1 cos
π
2
F1
F2

cos[2π F1(t −τ)], where τ =
1
4F2
11.19
Problems
Solved Problems
1. Write a Matlab program to generate u(n −N), N1 ≤n ≤N2, for N = 2, N1 = −5, and N2 = 10. Plot it as
stem and save the plot as an encapsulated postscript ﬁle.
Solution
N1=-5; N2=10; N=2; n=N1:N2;
x=[zeros(1,-N1+N),ones(1,N2-N+1)];
stem(n,x)
axis([N1
N2
-.2 1.2]); grid
print -dpsc Ch11«p1a.eps
2. Write a Matlab program to generate nu(n −N), N1 ≤n ≤N2, for N = −2, N1 = −5, and N2 = 10. Then
plot the result.
Solution
N1=-5; N2=10; N=-2; n=N1:N2;
x=n.*[zeros(1,-N1+N),ones(1,N2-N+1)];
stem(n,x)
axis([N1
N2+1
N-1 N2+1]); grid
3. Write a Matlab program to generate and plot cos(ω0n), −20 ≤n ≤50, for
a. ω0 = 0.125
b. ω0 = 0.25π
Solution
N1=-20; N2=50; n=N1:N2;
xa=cos(n/8);
figure;
stem(n,xa);
grid;
axis([N1 N2+1 -1.2 1.2]);
xb=cos(pi*n/4); figure;
stem(n,xb);
grid;
axis([N1 N2+1 -1.2 1.2]);
4. Write a Matlab program to generate 2−nu(n −N), N1 ≤n ≤N2, for N = 2, N1 = −5, and N2 = 10. Then
plot the result.
Solution
N1=-5; N2=10; N=2; n=N1:N2;
x=2.√(-n).*[zeros(1,-N1+N),ones(1,N2-N+1)];
stem(n,x); grid; axis([N1
N2
-.05 .3])

Signals and Systems
719
5. Write a Matlab program to generate and plot e−an cos(ωn + θ), N1 ≤n ≤N2, for a = 0.05, ω = 1/4, θ = π/3,
N1 = −10, and N2 = 50.
Solution
N1=-10; N2=50; n=N1:N2; a=.05; w=1/4; theta=pi/3;
x=exp(-a*n).*cos(w*n+theta);
stem(n,x); grid; axis([N1 N2 -1 1.5])
6. Write a Matlab program to generate and plot V0e−n/τ cos(ωn + θ)u(n), N1 ≤n ≤N2, for V0 = 1, τ = 20, ω =
0.25, θ = 0, N1 = −10, and N2 = 50.
Solution
clear; V0=1; N1=-10; N2=50; N=-N1+N2; tau=20; w=1/4; theta=0; n=N1:N2
for i=1:N+1
if n(i)ø=0;
x(i)=1;
else
x(i)=0;
end
end
v=V0*exp(-n/tau).*cos(w*n+theta); v1=v.*x;
stem(n,v1); axis([N1
N2 -1
V0+.5])
7. Write a Matlab program to generate and plot V0e−n/τ cos(ωn + θ)u(an + b), N1 ≤n ≤N2, for τ = 20, ω =
0.25, θ = 0, a = 1, b = 0, N1 = −10, and N2 = 50.
Solution
clear; V0=1; N1=-10; N2=50; N=-N1+N2; tau=20; w=1/4; theta=0; n=N1:N2;
a=1; b=0;
for i=1:N+1
if a*n(i)+b ø=0;
x(i)=1;
else
x(i)=0;
end
end
v=V0*exp(-n/tau).*cos(w*n+theta); v1=v.*x;
stem(n,v1); grid; axis([N1
N2 -1
V0+.5])
8. Write a Matlab program to generate and plot y(n) = x(2n−10), where x(n) = e−n/20 cos(0.25n+π/3)u(n), −10 ≤
n ≤50.
Solution
V0=1; N1=-10; N2=50; N=-N1+N2; tau=20; w=1/4; theta=pi/3; n=N1:N2
a=2; b=-10;
for i=1:N+1
if a*n(i)+b ø=0;
x(i)=1;
else
x(i)=0;
end

720
CHAPTER 11
Discrete-Time Signals
end
v=V0*exp(-(a*n+b)/tau).*cos(w*(a*n+b)+theta); v1=v.*x;
stem(n,v1); axis([N1
N2 -1
V0+.5])
9. Write a Matlab program to generate and plot y(n) = x(−3n + 10), where x(n) = e−n/20 cos(0.25n + π/3)u(n),
−10 ≤n ≤50.
Solution
In the solution given for problem 8, replace the second line with
a=-3; b=10
10. WriteaMatlabprogramtogenerateandplotthethreediscretewaveformswhoseenvelopesareshowninFigure11.13.
Each waveform contains two cycles of a periodic function with a period of N = 100.
a. A rectangular waveform with a base-to-peak value of 0 to 1 and a 40% duty cycle.
b. A sawtooth waveform with a peak-to-peak value of −1 to 1, spending 40% of the time in the state with positive
slope.
c. An exponentially varying waveform with a peak-to-peak value of −1 to 1, spending 40% of the time as 1.05−n
and 60% of the time as −(1.1)−n.
0
Magnitude
1
n
40
100
140
200
0
40
100
140
200
0
40
100
140
200
0
(a)
–1
–1
0
Magnitude
n
(b)
1
n
(c)
0
Magnitude
1
FIGURE 11.13
Solution
a. The following program generates and plots functions of Figure 11.13 sampled at the 1 Hz rate. Change the
command “plot” to “stem” to see the discrete-time display.
k2=2;
% Number of cycles
N=100;
% Period
d=0.4;
% Duty cycle
N1=N*d;
n1=0:N1-1;
N2=N*(1-d);
n2=0:N2-1;
n=0:k*N-1;
% a) Rectangular waveform:
x1=ones(1,N1); x2=zeros(1,N2); x=[x1, x2];
for j=1:k;
for i=1:N;

Signals and Systems
721
y(i+(j-1)*N)=x(i);
end
end
plot(n,y);
b. Repeat with
x1=n1.*ones(1,N1)/N1; x2=-n2.*ones(1,N2)/N2; x=[x1,x2];
c. Repeat with
x1=1.05.√(-n1); x2=-1.1.√(-n2); x=[x1,x2];
Chapter Problems
11. Sketch the following discrete-time signals as functions of n and express them in the following forms: (1) array and
(2) weighted sum of unit-sample functions.
a. x(n) =

2, −2 ≤n ≤4
0, elsewhere
b. x(n) =

1,
|n| ≤3
0, elsewhere
c. x(n) =

n,
|n| ≤3
0, elsewhere
d. x(n) =

2 −n,
|n| ≤3
0,
elsewhere
e. x(n) =

2, 0 ≤n ≤99
0, elsewhere
f. x(n) =
 0,
n ≤0
n, 1 ≤n ≤2
3,
n ≥3
g. x(n) =





0,
n < 0
2, 0 ≤n ≤5
3,
n > 5
h. x(n) =









0,
n < 0
n,
0 ≤n ≤5
10 −n, 6 ≤n ≤9
0,
n ≥10
12. Express the signals of problem 11 as sums of unit steps and unit ramps.
13. The signal x(n) = {1
↑, 1, 1, −1, −1, 1, −1} has seven samples at 0 ≤n ≤6 and is zero elsewhere.
a. Sketch x(n).
b. Show that x(n) may also be described by any of the following three forms.
(i) x(n) = d(n) + d(n −1) + d(n −2) −d(n −3) −d(n −4) + d(n −5) −d(n −6).
(ii) x(n) = u(n) −2u(n −3) + 2u(n −5) −2u(n −6) + u(n −7).
(iii) x(n) =



















0,
n < 0
1,
0 ≤n ≤2
−1,
3 ≤n ≤4
1,
n = 5
−1,
n = 6
0,
n > 6
c. Which of the above four representations is easiest for you to work with? Explain.

722
CHAPTER 11
Discrete-Time Signals
Problems 14--27
The discrete signals in problems 14 through 27 are represented by sequences of numbers, along with four possible
mathematical expressions of which only one (or none) is correct. Mark the correct answer.
14. x(n) = {2
↑, 1, 1, 1, 1, . . .}
a. d(n) + u(n −1)
b. d(n) + u(n)
c. 2u(n −1)
d. d(n −1)
e. None of the above
15. x(n) = {1, 1
↑, 1, 1, 1, . . .}
a. u(n + 1)
b. u(n −1)
c. d(n)
d. d(n −1)
e. None of the above
16. x(n) = {1
↑, 1, 2, 2, 2, . . .}
a. d(n)
b. 2d(n) + u(n −1)
c. u(n) + u(n −2)
d. u(n) + u(n −3)
e. None of the above
17. x(n) = {. . . , 1, 1, 1, 1
↑, 1}
a. u(−n)
b. u(n −1)
c. u(−n + 1)
d. u(−n −1)
e. None of the above
18. x(n) = {1, 1
↑}
a. d(n) + d(n −1)
b. u(n −1) −u(n)
c. u(n + 1) −u(n −1)
d. d(n + 1) + d(n −1)
e. None of the above
19. x(n) = {. . . , 8, 4, 2, 1
↑, 2, 4, 8, . . .}
a. 2nu(n) + 2−nu(−n) −d(n)
b. 2|n| + d(n)
c. 2n
d. 0.5n
e. None of the above
20. x(n) = {1, 1
↑, 2, 4, 8, . . .}
a. 0.5−nu(n) + d(n)
b. 0.5−nu(n + 1)
c. 2nu(n + 1)
d. 0.5(n+1)u(n + 1)
e. None of the above
21. x(n) = {. . . , 1/8, 1/4, 1/2, 1
↑}
a. 2−nu(n)
b. 0.5−nu(n)
c. 2nu(−n)
d. 0.5nu(−n)
e. None of the above
22. x(n) = {2, 1
↑, 1/2, 1/4, 1/8, . . .}
a. 0.5nu(n) + d(n)
b. 2 × (0.5)nu(n + 1)
c. 0.5nu(n + 1)
d. 0.5(n+1)u(n + 1)
e. None of the above
23. x(n) = {1
↑, 1/2, 1/4, 1/8, 1/16}
a. 0.5nu(n) + d(n)
b. 2 × (0.5)nu(n + 1)
c. 0.5nu(n + 1)
d. 0.5(n+1)u(n + 1)
e. None of the above
24. x(n) = {1
↑, −1/2, 1/4, −1/8, 1/16, −1/32, . . .}
a. 0.5nu(n) + d(n)
b. 2 × 0.5nu(n + 1)
c. 0.5nu(n + 1)
d. 0.5(n+1)u(n + 1)
e. None of the above

Signals and Systems
723
25. x(n) = {. . . , 1/8, 1/4, 1/2, 1
↑, 1/2, 1/4, 1/8, . . .}
a. 0.5−nu(n) + 0.5nu(−n)
b. 2−nu(n) + 2nu(−n)
c. 0.5nu(n) + 0.5−nu(−n)
d. 2nu(n) + 2−nu(−n)
e. None of the above
26. x(n) = {. . . , 1/27, 1/9, 1/3, 1
↑, 1/2, 1/4, 1/8, . . .}
a. 3nu(n) + (−3)nu(−n)
b. 3−nu(n) + 3nu(−n)
c. (1/3)nu(n) + (1/3)−nu(−n)
d. (1/3)nu(n) + (1/3)−nu(−n)
e. None of the above
27. x(n) = {1/27, 1/9, 1/3, 1
↑}
a. 3n[u(n + 4) −u(n)]
b. 3−n[u(n) + u(−n + 4)]
c. (1/3)nu(n) + (1/3)−nu(−n + 4)
d. (1/3)nu(n + 4) + (1/3)−nu(−n)
e. None of the above
28. Evaluate, sketch, and compare the following discrete-time ramp signals within the range −6 ≤n ≤6.
a. r(n) −r(n −3), where r(n) is a unit ramp.
b. r(n)[u(n) −u(n −4)]
c. [r(n) −r(n −3)][u(n) −u(n −4)]
d. r(n)[u(n) −u(n −3)]
29. Evaluate and sketch the following discrete-time signals within the range −6 ≤n ≤6.
a. cos n
b. cos(3n)
c. cos(πn/2)
d. cos(πn/3)
e. cos n + sin n
f. cos n + cos(3n)
g. cos(πn/2) + cos(πn/3)
h. cos n + cos(πn)
30. Evaluate and sketch the following discrete-time signals within the range −6 ≤n ≤6.
a. 3−nu(n −3)
b. (−0.3)nu(n + 3)
c. 0.4n sin(πn/6)u(n −3)
d. 0.4n cos(πn/6)u(n + 3)
31. Determine the function that models each discrete signal in Table 11.11A. Pick the number referring to the correct
formula from Table 11.11B.
TABLE 11.11A Signal
Letter
Signal
a.
{1, 1
↑, 1, 1, 1, . . .}
b.
{. . . , 1, 1, 1, 1
↑, 1}
c.
{1
↑, 1}
d.
{. . . , 1, 1, 1, 1
↑, 1, 1, 1, . . .}
e.
{1, 1, 1, 1
↑, 1}
f.
{1, 1
↑, 1, 1, 1}
g.
{1
↑, 2, 2, 2, 2, . . .}
TABLE 11.11B Function
Number
Function x(n)
1
u(n) + u(n −1)
2
u(n + 3) −u(n −2)
3
u(n + 1) −u(n −4)
4
u(−n + 1)
5
1
6
u(n −1)
7
d(n) + d(n −1)
8
u(n −1) −u(n)
9
u(n + 1) −u(n −1)
10
None of the above
32. Determine the function that models each discrete signal in Table 11.12A. Pick the number refering to the correct
formula from Table 11.12B.

724
CHAPTER 11
Discrete-Time Signals
TABLE 11.12A Signal
Letter
Signal
a.
{. . . , 1/16, 1/8, 1/4, 1/2, 1
↑}
b.
{. . . , 1/16, 1/8, 1/4, 1/2, 1
↑, 1/2, 1/4, 1/8, 1/16 · · ·}
c.
{1/8, 1/4, 1/2, 1
↑, 1/2, 1/4, 1/8}
d.
{1/8, 1/4, 1/2, 1
↑, 2, 4, 8}
e.
{1
↑, −1/2, 1/4, −1/8, 1/16, −1/32 · · ·}
f.
{2
↑, 4, 8, 16, . . .}
g.
{. . . , 1/16, 1/8, 1/4, 1/2, 2
↑, 1/2, 1/4, 1/8, 1/16, . . .}
TABLE 11.12B Function
Number
Function x(n)
1
2−|n|
2
0.5−nu(n)
3
2nu(−n)
4
0.5n[u(n + 3) −u(n −4)]
5
2n[u(n + 3) −u(n −4)]
6
(−0.5)nu(n)
7
2(n+1)u(n)
8
2−nu(n) + 2nu(−n)
9
2nu(n + 3)
10
None of the above
33. Evaluate and sketch the following discrete-time signals within the range −6 ≤n ≤6.
a. 2−nu(n −1)
b. (−0.5)nu(n + 1)
c. cos(πn/2)u(n)
d. cos(πn/4)u(n)
e. 0.5n sin(πn/3)u(−n)
f. 0.5n cos(πn/3)u(n)
g. 2n cos(πn/3)u(−n)
h. 2|n| cos(πn/3)
34. Evaluate and sketch the following discrete-time sinc signals within the range −6 ≤n ≤6.
a. sin n
n
b. sin(n/6)
n/6
c. sin(2n/5)
n
d. sin(πn/2)
πn/2
e. sin(2πn/5)
2πn/5
35. Evaluate and sketch the following sinc signals within the range −6 ≤n ≤6.
a. sin(n −3)
(n −3)
b.
∞

k=−∞
sin(n −3k)
(n −3k)
c.
∞

k=−∞
sin(n −4k)
(n −4k)
d. sin[π(n −3)/2]
(n −3)
e.
∞

k=−∞
sin[π(n −3k)/2]
(n −3k)
f.
∞

k=−∞
sin[2π(n −4k)/5]
(n −4k)
36. Evaluate and sketch the following signals within the range −6 ≤n ≤6.
a. sin(πn)
sin πn
8
	
b.
sin n
sin  πn
8
	
c.
sin n
sin  n
8
	
37. For each of the four sinc functions given below ﬁnd the locations of the samples at which (or closest to them) the
zero-crossings occur. Obtain the number of nonzero samples within each of the 10 lobes of the function for n > 0,
including the main lobe. Brieﬂy summarize your observations and conclusion on the pattern of the alternating lobes.
a. sin n
n
b. sin πn
n
c. sin πn/3
n
d. sin 2πn/5
n
38. Consider the discrete-time signal cos(ω0n), where ω0 is a constant. Evaluate and sketch it for 0 ≤n ≤12. Assume
a. ω0 = 1
b. ω0 = π/3
39. Show that the discrete-time signal cos(ω0n) is periodic only if ω0 = 2π/N, where N is an integer, in which case N
is the period of the signal.
40. Show that the discrete-time signal x(n) = e j2πkn/N, where k and N are integers, is periodic and ﬁnd its fundamental
period.

Signals and Systems
725
41. A continuous-time function x(t) is sampled every 1 msec resulting in the discrete-time function x(n). For the
following cases ﬁnd x(n) and determine if it is periodic:
a. x(t) = 2−1000tu(t)
b. x(t) = e−100tu(t)
c. x(t) = cos(5πt + π/4)
d. x(t) = sin(
√
2πt)
42. The following continuous-time functions are sampled every 1 msec. Find their discrete-time counterparts x1(n) and
x2(n). Compare results and explain the reason behind the possible similarities.
a. x1(t) = cos(200πt)
b. x2(t) = cos(2,000πt/9)
43. An analog periodic signal x(t) with period P is sampled every T seconds. Find the conditions on P and T that
produce a periodic x(n).
Suggestion and Hint
Use the Fourier transform of the sampled signal in the continous-time domain (see Chapter 10). Sampling is done
by multiplying x(t) by a periodic sampling function s(t) made of a train of unit impulses:
s(t) =
∞

n=−∞
δ(t −nT )
The sampled function
y(t) = x(t)s(t) =
∞

n=−∞
x(nT )δ(t −nT )
is a train of impulses each, with strength x(nT ) and spaced apart every T seconds. Examine Y( f ), the Fourier
transform of y(t), and test conditions for its periodicity.
44. a. Sample the continuous-time functions in Table 11.2 of this chapter at the rate of Fs = 10 Hz and compare the
resulting discrete-time functions with those found for Fs = 100 (Example 11.13).
b. Repeat for Fs = 1.
45. Consider the discrete-time signal x(n) = {1
↑, 2, 3, 4, 5, 4, 3, 2, 1}.
a. Sketch x(n).
b. Find and sketch y(n) = x(n) −x(n −2).
46. For the periodic pulse given below, ﬁnd and sketch x(n) −x(n −1). Interpret your results.
x(n) =

2,
0 ≤n ≤1
−1,
2 ≤n ≤5
deﬁned for one period and x(n) = x(n + 6)
47. Consider the sinusoidal signal x(n) = cos(2πn/N) and let y(n) = x(n)+ x(n −1)+ x(n −2). Evaluate and sketch
x(n) and y(n) for 0 ≤n ≤6. Assume
a. N = 2
b. N = 6

726
CHAPTER 11
Discrete-Time Signals
48. Consider the discrete-time periodic pulse x(n) given in problem 47. Let y(n) = x(n) + y(n −1) and y(0) = 0.
Find and sketch y(n). Hint: First note that
y(n) =
n

k=−∞
x(k)
49. Given x(n) = n[u(n) −u(n −4)], sketch and label the following functions, in which k is a positive integer.
a. x(n ± 3)
b. x(n ± k)
c. x(−n ± 3)
d. x(−n ± k)
50. Consider the discrete-time function x(n) = u(n) −2u(n −1) + d(n −3). Sketch and label
a. x[−(n −2)]
b. x(−n −2)
c. x(n)d(n −1)
51. Given x(n) = {1
↑, 2, 3, 4}, ﬁnd and sketch
a. x(n ± 1)
b. x(−n)
c. x(−n ± 1)
d. x(−n ± 2)
52. Given x(n) = 0.5nu(n), ﬁnd and sketch
a. x(n ± 1)
b. x(−n)
c. x(−n ± 1)
d. x(−n ± 2)
53. Given x(n) = 0.5n[u(n) −u(n −4)], ﬁnd and sketch
a. x(n ± 1)
b. x(−n)
c. x(−n ± 1)
d. x(−n ± 2)
54. Given x(n) = 0.5nu(n), sketch and label the following functions
a. x(n −3)
b. x(3 −n)
c. x(n + 3)
d. x(−n −3)
55. Given x(n) = 0.5nu(n) + 3nu(−n), sketch and label the following functions
a. x(n −1)
b. x(1 −n)
c. x(n + 1)
d. x(−n −1)
56. Given x(n) = 0.5−n2, ﬁnd and sketch the following functions for −4 ≤n ≤4.
a. x(n −1)
b. x(−n)
c. x(−n + 1)
d. x(−n −1)
57. Given x(n) = 0.5−|n|, ﬁnd and sketch the result of the following two operations:
a. First delay x(n) by 2 units, then time reverse.
b. Time reverse x(n) ﬁrst, then advance by 2 units.
58. Repeat problem 57 for the following functions:
a. x(n) = 0.5−nu(n) + 0.5nu(−n)
b. x(n) = 0.5−nu(n) −0.5nu(−n)
59. Using the graphical method, demonstrate that the following two operations on a discrete-time function x(n) are
equivalent, both resulting in x(−n + k).
a. First delay x(n) by k units, then time reverse.
b. Time reverse x(n) ﬁrst, then advance by k units.
60. Show that d(n) = d(−n). Therefore, d(n −k) = d(k −n), where k is an integer constant.

Signals and Systems
727
61. Show that d(kn) = d(n), where k is an integer constant.
62. Show that d(kn + a) = d(n + a/k), where k and a are integer constants.
63. Show that x(n)d(n −k) = x(k)d(n −k), where k is an integer constant.
64. Given x(n) = u(n) and h(n) = 0.5n[u(n) −u(n −3)],
a. Find, sketch, and label the following set of functions x(n)h(k −n),
k = −2, −1, 0, 1, 2, 3, 4, 5, 6.
b. Find, sketch, and label
y(k) =
∞

n=−∞
x(n)h(k −n),
k = −2, −1, 0, 1, 2, 3, 4, 5, 6
65. Let pk(n) = d(n)d(n −k), where k is an integer (shifting the unit sample to the left or right).
a. Find and sketch pk(n) for k = 0.
b. Repeat for k ̸= 0.
c. Using the collection of pk(n) sketches found in a and b, deﬁne a new function
ρ(k) =
∞

n=−∞
pk(n),
−∞< k < ∞
with k as the independent variable. Evaluate and sketch ρ(k) versus k.
66. Consider the single rectangular pulse x(n) = {. . . , 0, 0, 1, 1, 1
↑, 1, 1, 0, 0, . . .}.
a. Deﬁne a new discrete function pk(n) = x(n)x(n −k), where n is the independent variable and k is an integer,
−∞< k < ∞. Find and sketch the collection of pk(n) for −∞< k < ∞.
b. Deﬁne a new function
ρ(k) =
∞

n=−∞
pk(n)
with k as the independent variable. Evaluate and sketch ρ(k) versus k.
67. Repeat problem 66 for
a. x(n) = {. . . , 0, 0, 1
↑, 1, 1, 1, 0, 0, . . .}
b. x(n) = {. . . , 0, 0, 1
↑, 1, 1, −1, −1, 1, −1, 0, 0, . . .}
68. Repeat problem 66 for x(n) = u(n) and show that ρ(k) = ∞for all k.
69. Find the even and odd parts of h(n) = 0.5nu(n −1) and compare with those of h(n) = 0.5nu(n) found in
Example 11.33.
70. Let x(n) = e jω0n, k be an integer and A = cos(ω0k). Show that
x(n + k) + x(n −k)
2
= Ax(n)
x(n) + x(n −2k)
2
= Ax(n −k)

728
CHAPTER 11
Discrete-Time Signals
71. Let
x(n) =
∞

m=−∞
Xme jmω0n
where the Xm coefﬁcients are constant and m is an integer. Find y(n) =
x(n)+x(n−2k)
2
and determine conditions for
y(n) = x(n −k).
72. Consider the discrete-time signal x(n) = cos(πn/8). Let
y(n) = 0.25x(n) + 0.225[x(n −1) + x(n + 1)] + 0.159[x(n −2) + x(n + 2)] + 0.075[x(n −3) + x(n + 3)]
Find a closed form expression for y(n) in terms of x(n). Evaluate and sketch y(n).
73. Repeat problem 72 for (a) x(n) = cos(πn/4), (b) x(n) = cos(3πn/4).
11.20
Project: An Introduction to Discrete-Time
Signal Processing
Introduction and Summary
In section 11.18 a simple digital ﬁlter was used to notch out a sinusoidal disturbance, while attempting to keep the signal
of interest. The notching operation changed the amplitude of the signal (and blocked all frequencies that were harmonics
of the disturbance). In theory, if, as in Examples 11.36 and 11.37, the signals of interest were pure sinusoids at known
frequencies, the frequency-dependent amplitude change could be compensated for by a simple ampliﬁcation. In practice,
however, signals of interest are not made of simple sinusoids. Signal structure changes continually and unpredictably with
time.3 As a result, the frequency-dependent attenuation produces distortion in the signal and makes y(n) an unfaithful
representation of s(n). To reduce the distortion in s(n) while blocking the interference, we may employ a sharper notch
ﬁlter with a narrow bandwidth.
In this project you will explore ﬁltering operations that separate signals from noise or distrurbance. In the continuous-
time domain, the data is given by x(t) = s(t)+w(t). s(t) is the signal and w(t) is the noise or disturbance. After sampling,
it becomes x(n) = s(n) + w(n). The project includes two procedures. In the ﬁrst procedure, s(t) contains frequencies
from 0 to fc and w(t) is a sinusoid (to be called the disturbance) with known frequency 0 < f0 < fc. The aim is to block
(notch out) the disturbance by a digital notch ﬁlter with little distortion of the signal. Ideally, the ﬁlter’s output should
be Ks(n −k), where K and k are the constant gain and delay, respectively. The second procedure is concerned with
extracting a single sinusoid from the data, using a narrowband digital ﬁlter tuned to the frequency of the sinusoid. For
example, the signal s(t) is a single sinusoid embedded in a background noise w(t) and it is desired to extract the signal
from noise. Another example, which falls within the second procedure, is to separate a certain frequency component of a
signal or noise.
Procedure 1. Notching the Disturbance
A continuous-time signal s(t) is recorded together with a 60-Hz sinusoidal interference, resulting in x(t) = s(t) +
cos(120πt) (to be called the data). The bandwidth of s(t) is 0 to 600 Hz. It is desired to notch out the sinusoidal
interference from the data without doing excessive damage to s(t).
3Signals, in general, are stochastic and unpredictable.

Signals and Systems
729
A Simple Notch Filter
Sample x(t) at the rate of 1,200 samples per second, twice the bandwidth of s(t), and obtain a discrete-time data sequence
x(n) = s(n) + cos(αn), where α = π/10. To cancel cos(αn), we ﬁrst apply a simple shift-and-add notch ﬁlter as in
Example 11.36.
x(n) + x(n −2k)
2
= s(n) + s(n −2k)
2
+ cos(αn) + cos(αn −2αk)
2
= s(n) + s(n −2k)
2
+ cos(αk) cos(αn −αk)
= s(n) + s(n −2k)
2
+ A cos α(n −k)
Let A = cos(αk). By choosing k = 5 we will have αk = π/2, which results in A = 0, thus blocking (or notching out)
the 60-Hz interference. The above ﬁlter is not satisfactory because its gain, which affects the frequency components of
s(n), depends on frequency. The result is that even though the ﬁlter cancels the disturbance, its output s(n)+s(n−2k)
2
is not a
reproduction of the signal but rather a distortion of it.
Ideal Low-Pass Filter
To reduce signal distortion we use a ﬁlter with a narrow notch. For this purpose we introduce the ideal low-pass ﬁlter
and use it within the rest of the project. An ideal low-pass ﬁlter with a cutoff angular frequency ω0 has a constant gain at
frequencies below the cutoff frequency and a zero gain at frequencies above it. The ﬁlter is speciﬁed by the discrete-time
function h(n) (called the unit-sample response) given below.
h(n) = sin(ω0n)
πn
,
−∞< n < ∞
The ﬁlter performs the following operation on a signal x(n) and produces an output y(n):
y(n) =
∞

k=∞
x(k)h(n −k)
In practice, a ﬁnite segment of h(n), seen through a window, may be used. It is shifted to the right to make it causal and
realizable.
An Improved Notch Filter
Consider a discrete-time signal x(n) = s(n) + cos(7πn/16), where s(n) is the signal of interest and cos(7πn/16) is the
disturbance. The goal is to block or attenuate the disturbance by ﬁltering. For that purpose, use a notch ﬁlter with the
unit-sample response
h(n) = [h1(n) + d(n) −h2(n)] w(n)
where h1 and h2 are unit sample responses of ideal low-pass ﬁlters (see part a) with cutoff frequencies at ω1 = π/4 and
ω2 = 5π/8, respectively. w(n) is the M-tap window speciﬁed by
w(n) =

0.54 + 0.46 cos( 2πn
M ),
−N ≤n ≤N, M = 2N + 1
0,
elsewhere

730
CHAPTER 11
Discrete-Time Signals
The output of the ﬁlter is the sum of the weighted samples x(n −k), −N ≤k ≤N, according to the following:
y(n) =
N

k=−N
h(k)x(n −k)
= h0x(n)
+h1[x(n + 1) + x(n −1)]
+h2[x(n + 2) + x(n −2)]
+h3[x(n + 3) + x(n −3)]
+h4[x(n + 4) + x(n −4)]
+h5[x(n + 5) + x(n −5)]
· · ·
+h N[x(n + N) + x(n −N)]
1. Show that the ﬁlter is capable of blocking the sinusoidal disturbances at ω = 7π/16.
2. Examine the effect of the ﬁlter on the sinusoidal disturbance. For this purpose let x(n) = cos(7πn/16) (i.e., no
signal). Apply the ﬁlter and record the output. Devise a measure to evaluate the peformance of the ﬁlter in achieving
the goal. Explore the effect of ﬁlter length M on the output. Start with M = 11, 17, and 101. Compare with the
simple notch ﬁlter of part a.
3. Examine the effect of the ﬁlter on the signal. For this purpose let x(n) = cos(ωn) (i.e., no disturbance). Show
that y(n) = A cos(ωn + θ). Find and sketch A and θ as functions of 0 < ω < π. Compare with the plot for the
notch ﬁlter of part a. Conclude, by appropriate reasoning, that the ﬁlter discussed in this part is improved in that it
procduces less distortion in the signal compared with the simple notch ﬁlter of part a.
Suggestion
Use a computer. To evaluate the output you may use the Matlab command conv, which stands for convolution.
Procedure 2. Extracting the Principal Harmonic of a Signal
Let x(n) be the periodic pulse signal with period N = 5.
x(n) = {1
↑, 1, 1, 0, 0} and x(n) = x(n + 5)
The goal is to extract its principal harmonic by ﬁltering. Use a bandpass ﬁlter with the unit-sample response
h(n) = [h2(n) −h1(n)] w(n)
where h1 and h2 are unit-sample responses of ideal low-pass ﬁlters with cutoff frequencies at ω1 = 3π/10 and ω2 =
5π/10, respectively. w(n) is the M-tap window of procedure 1. The output of the ﬁlter is the sum of weighted samples
x(n −k), −N ≤k ≤N, as in Procedure 1.
Show that the ﬁlter is capable of blocking all frequencies except the sinusoidal at ω = 2π/5. Devise a measure to
evaluate the peformance of the ﬁlter in achieving the goal. Explore the effect of ﬁlter length M on the output. Start with
M = 11, 17, and 101. The mathematical explanation for the bandpass ﬁltering property of the above h(n) will be covered
in Chapter 16. The following Matlab ﬁle may be used:
% Procedure 1.
clear; N=8; M=2*N+1; n=-N:N; hamming=0.54+.46*cos(2*pi*n/M);
omega1=pi/4;;
h1=sin(omega1*n)./(pi*n);
h1(N+1)=omega1/pi;
omega2=5*pi/8; h2=-sin(omega2*n)./(pi*n);
h2(N+1)=1-omega2/pi;
h=(h2+h1).*hamming;

Signals and Systems
731
q=5; m=-q*N:q*N; x=cos(7*pi*m/16); y=conv(x,h);
%
% Procedure 2.
omega1=3*pi/10;;
h1=sin(omega1*n)./(pi*n);
h1(N+1)=omega1/pi;
omega2=5*pi/10;
h2=sin(omega2*n)./(pi*n);
h2(N+1)=omega2/pi;
h=(h2-h1).*hamming;
p=[1 1 1 0 0 ]; x=[p p p p p p p]; y=conv(x,h);

Chapter12
Linear
Time-Invariant
Discrete-Time
Systems
Contents
Introduction and Summary
733
12.1
Linear Time-Invariant (LTI) Discrete-Time Systems
734
12.2
The Unit-Sample Response
737
12.3
ResponseofLTIDiscrete-TimeSystemstoPowerSignalsandSinusoids
741
12.4
Some Properties and Classiﬁcations of Discrete-Time LTI Systems
743
12.5
Discrete LTI Operators and Difference Equations
745
12.6
Block Diagram Representation
747
12.7
Analysis and Solution Methods
751
12.8
Problems
752
12.9
Project: Deadbeat Control
758
Introduction and Summary
From a theoretical perspective, a discrete-time system may be considered to be a special
case of the continuous-time system which samples the continuous-time input, obtains
the output, and then keeps it until the next input sample. In such an approach, time would
still play the role of the independent variable and the analysis tools (such as the trans-
forms) would be derived from those in the continuous-time domain. Such an approach,
733

734
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
however, can easily be bypassed. Discrete-time systems may be analyzed, synthesized,
and designed without falling back on a background from the continuous-time domain.
The necessary analysis tools (such as the transform, system function, frequency response,
ﬁltering operations, signal processing, and feedback) may be developed on their own.
While from the operational point of view some degree of separation between the two
domains may be useful in reducing possible confusions in applying the tools and meth-
ods, a certain degree of connection does seem to enhance the intuitive understanding
of the basic concepts. The discussion in Chapter 3 introduced systems in general (and
LTI systems in particular) using such a connected approach. This chapter presents the
deﬁnitions and elements of discrete-time systems in stand-alone format in order to better
serve the operational aspect and analysis methods that are developed in future chapters.
After summarizing the linearity and time-invariance properties, the chapter intro-
duces the unit-sample response as an important tool for ﬁnding the output of the system
to any input, in the form of convolution sum. The convolution sum is discussed in detail
in the next chapter. Other system speciﬁcations such as responses to unit-step inputs,
power signals, sinusoids, and the description by difference equations are then brieﬂy
introduced. Discrete LTI operators and system classiﬁcations as FIR and IIR, recursive
and nonrecursive, are also introduced. The overview is intended to provide an introduc-
tion at this early stage of the discussion. These topics will be encountered again and in
more detail in later chapters.
12.1
Linear Time-Invariant (LTI)
Discrete-Time Systems
A discrete-time system is made of an input space, an output space, and a mapping
rule. Input, output, and internal states are functions of a discrete variable that assumes
only integer values. The system changes its output at a regular interval only and not
continuously. Many discrete systems are models of continuous-time systems that switch
their state at the time of a clock pulse. For such systems, the term discrete time seems
appropriate. However, this term is also applied to physical phenomena whose variables
are not time but other parameters such as space. Also, some physical phenomena are,
by their very nature, discrete. Nevertheless, in this book we use the terms discrete and
discrete time interchangeably.
The linearity and time-invariance properties of LTI systems have already been dis-
cussed in detail in Chapter 3. Here we summarize them for the discrete-time domain.
Linearity
Let two arbitrary inputs x1 and x2 produce y1 and y2, respectively. If the input x =
ax1 + bx2 produces y = ay1 + by2 for all constants a and b, the system is called linear.
x1(n)
⇒y1(n)
x2(n)
⇒y2(n)
ax1(n) + bx2(n) ⇒ay1(n) + by2(n)

Signals and Systems
735
Time Invariance
Let an arbitrary input x(n) produce the output y(n). If the input x(n −k) produces the
output y(n −k) for all k, the system is called time invariant.
x(n)
⇒y(n)
x(n −k) ⇒y(n −k)
Linear Time-Invariant (LTI) Discrete-Time Systems
A system that is both linear and time invariant is called LTI and satisﬁes the following
property for all x1, x2, a, b, k.
x1(n)
⇒y1(n)
x2(n)
⇒y2(n)
ax1(n −k) + bx2(n −k) ⇒ay1(n −k) + by2(n −k)
Example
12.1
Delay operator
The delay operator is deﬁned by the equation y(n) = x(n−N), where N is an integer
constant. The operation shifts the signal N units to the right if N > 0. For N < 0
the signal is shifted to the left by N units and is said to be advanced. The operation
is linear and time invariant as veriﬁed by the following.
x1(n)
⇒
y1(n) = x1(n −N)
x2(n)
⇒
y2(n) = x2(n −N)
ax1(n −k) + bx2(n −k) ⇒ax1(n −N −k) + bx2(n −N −k)
= ay1(n −k) + by2(n −k),
for all x1, x2, a, b, and k.
Example
12.2
A difference operator
The backward-difference operator is deﬁned by the equation
y(n) = x(n) −x(n −1)
Veriﬁcation of its linearity and time invariance is similar to that in Example 12.1.
The backward-difference operator is the counterpart of differentiation operation in
the continuous-time domain. As an example, application of the backward-difference
operator on the unit-step function results in the unit-sample function.
d(n) = u(n) −u(n −1)
As another example the backward difference operating on a unit-ramp function pro-
duces a delayed unit-step function,
u(n −1) = nu(n) −(n −1)u(n −1)

736
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
The backward-difference operator is also one approximation to differentiation opera-
tion in the continuous-time domain as shown in section 12.5 of this chapter, along with
several other discrete-time LTI operators and their block diagram representations.
Example
12.3
A moving average
An example of a discrete-time system is taking the average of samples of a discrete-
time signal within a window of ﬁxed size, assigning the average as the output, shifting
the window, and repeating the operation. One type of moving average may be de-
scribed as the following input-output relationship:
y(n) = 1
N
M+N−1

k=M
x(n −k)
in which x(n) is the input, y(n) is the output, M is the location of trailing edge
(beginning) of the window, and N is its width. For example, the weekly average price
of a certain item computed from
y(n) = 1
7
6

k=0
x(n −k)
gives the average price for today and the past six days. In the above system samples
are given equal weight. They inﬂuence the averaging result process uniformly. The
averaging window is called a uniform window and the operation may be labeled a
simple moving average. In another type of averaging, a weighting function may give
samples different weights. For example, the most recent samples may be consid-
ered more relevant and given an exponential weighting function. The system is then
described by the following relationship:
y(n) = 1
N
M+N−1

k=M
x(n −k)e−(k−M)
The above formulation, which still represents an LTI system, is also called convolution
of the input signal with system’s unit-sample response.
Example
12.4
A credit account
Pat has established a credit account with a bank that requires ﬁve monthly payments
of 0.25 dollars each for every dollar of purchase. Statements are issued at the end of
each month and the payments for charges during that month begin in the following
month. Let x(n) be the amount charged to the acount in the nth month and y(n) be
the amount due in that month. Express y(n) in terms of x(n).
Solution
y(n) = 0.25 [x(n −1) + x(n −2) + x(n −3) + x(n −4) + x(n −5)]. For a nu-
merical illustration of this system see Example 4.5 in Chapter 4.

Signals and Systems
737
Example
12.5
Testing a system for time invariance
A unit sample arriving at n = k to a linear system evokes the response 0.5nu(n −k).
Is the system time invariant?
Solution
The system is not time invariant, as shown by the following counterexample. Let
h0(n) be the response to d(n) and h1(n) be the response to d(n −1).
d(n)
⇒
h0(n) = 0.5nu(n)
d(n −1)
⇒
h1(n) = 0.5nu(n −1) = 1
2(0.5)n−1u(n −1)
Note that h1(n) ̸= h0(n −1). A one-unit shift in the input has produced a one-unit
shift in the output, plus a gain factor of 1
2.
Alternative Solution to Example 12.5
Using the array display notation we have:
d(n)
⇒
{0, 1
↑, 0.5, 0.25, 0.125, · · ·}
d(n −1) ⇒
{0, 0
↑, 0.5, 0.25, 0.125, · · ·}
It is observed that a unit shift in the input does not produce a unit shift in the system’s
response. The system is, therefore, not time invariant.
Example
12.6
Testing a system for time invariance
The response of a linear system to a unit sample arriving at n = k is h(n, k) =
0.5(n−k)u(n −k). Is the system time invariant?
Solution
The system is time invariant. This may be deduced directly from the observation
h(n, k) = h(n −k). To see how, let k2 = k1 + N and note that
d(n −k1)
⇒
h(n −k1)
d(n −k2) = d(n −k1 −N) ⇒
h(n −k2) = h(n −k1 −N)
A shift of N units in the input has produced a shift of N units in the output, and
nothing else.
12.2
The Unit-Sample Response
The unit-sample response is a most powerful description tool for linear systems. It
completely speciﬁes a linear system, whether time invariant or not. It is brieﬂy considered
here, through two examples for both time-variant and time-invariant linear systems. The
unit-sample response of LTI systems will be encountered throughout the rest of the book.

738
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
The Unit-Sample Response of Linear Systems, h(n, k)
A unit-sample function occurring at time k is shown by d(n −k). Let such a function
be the input to a linear system. Let the system’s output at time n to d(n −k) be called
h(n, k). Since any arbitrary input may be expressed as a weighted sum of unit samples,
the resulting output may be computed from the weighted sum of h(n, k). It is, therefore,
clear that if one knows the unit-sample responses of a linear system, one can compute
its output to any input.
Example
12.7
A unit sample arriving at n = k to a linear system evokes the response 0.5nu(n −k).
a.
Find its response y(n) to the input x(n) = d(n) + 4d(n −1) −2d(n −2).
b.
Given the above input ﬁnd a closed-form mathematical expression for y(n) for
n ≥2 and evaluate it at n = 2.
Solution
Using linearity property we ﬁnd
a.
y(n) = 0.5nu(n) + 4 × 0.5nu(n −1) −2 × 0.5nu(n −2)
= 0.5n [u(n) + 4u(n −1) −2u(n −2)]
= d(n) + 2.5d(n −1) + 3(0.5)nu(n −2)
b.
y(n) = 0.5n(1 + 4 −2) = 3(0.5)n, n ≥2
y(2) = 3 × 0.52 = 0.75
Alternative Solution to Example 12.7
Using the array display notation we have
d(n)
⇒
{0, 1
↑, 0.5, 0.25, 0.125, · · ·}
4d(n −1)
⇒
4 × {0, 0
↑, 0.5, 0.25, 0.125, · · ·}
−2d(n −2)
⇒−2 × {0, 0
↑, 0, 0.25, 0.125, · · ·}
d(n) + 4d(n −1) −2d(n −2) ⇒
{0, 1
↑, 2.5, 0.75, 0.375, · · ·}
The last array showing the total response may be written as d(n)+2.5d(n −1)+
3(0.5)nu(n −2).
The Unit-Sample Response of LTI Systems, h(n)
In the case of LTI systems h(n, k) depends on (n −k). The system can then be speciﬁed
completely by h(n), its response to d(n). Based on linearity and time-invariance prop-
erties the output of an LTI system may be computed from the weighted sum of shifted

Signals and Systems
739
h(n). Time invariance greatly facilitates this task. In this book we mainly deal with LTI
systems, representing the unit-sample response by h(n).
Example
12.8
Consider an LTI system having the unit-sample response h(n) = {1
↑, −1}. Find y(n)
for:
a.
x(n) = {1
↑, 1}
b.
x(n) = {1
↑, −1}
c.
x(n) = {1
↑, −1, −1}.
Solution
a.
x(n) = d(n) + d(n −1)
y(n) = h(n) + h(n −1) = {1
↑, −1} + {0
↑, 1, −1} = {1
↑, 0, −1}
b.
x(n) = d(n) −d(n −1)
y(n) = h(n) −h(n −1) = {1
↑, −1} −{0
↑, 1, −1} = {1
↑, −2, 1}
c.
x(n) = d(n) −d(n −1) −d(n −2)
y(n) = h(n) −h(n −1) −h(n −2) = {1
↑, −1} −{0
↑, 1, −1} −{0
↑, 0, 1, −1}
= {1
↑, −2, 0, 1}
Example
12.9
The response of an LTI system to a unit sample arriving at n = k is h(n, k) =
0.5(n−k)u(n −k).
a.
Find its response y(n) to the input x(n) = d(n) + 4d(n −1) −2d(n −2).
b.
Given the above input, for n≥2 express y(n) by a closed-form mathematical
formula, evaluate it at n = 2, and compare with the result obtained in Example
12.7.
Solution
a.
y(n) = 0.5nu(n) + 4 × 0.5n−1u(n −1) −2 × 0.5n−2u(n −2)
= 0.5n [u(n) + 8u(n −1) −8u(n −2)]
= d(n) + 4.5d(n −1) + (0.5)nu(n −2)
b.
y(n) = 0.5n, n ≥2
y(2) = 0.25

740
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
Alternative Solution to Example 12.9
As in Example 12.7, we use the array display notation to obtain:
d(n)
⇒
{0, 1
↑, 0.5, 0.25, 0.125, · · · , · · · , · · ·}
4d(n −1)
⇒
4 × {0, 0
↑, 1,
0.5,
0.25, 0.125, · · · , · · ·}
−2d(n −2)
⇒
−2 × {0, 0
↑, 0,
1,
0.5,
0.25, 0.125, · · ·}
d(n) + 4d(n −1) −2d(n −2)
⇒
{0, 1
↑, 4.5, 0.25, 0.125, · · · , · · · , · · ·}
Note that y(2) is smaller than its counterpart in Example 12.7, as one may expect
from the unit-sample responses.
Obtaining the Unit-Sample Response of an LTI System
from a Given Input-Output Pair
We have noted that an LTI system is completely speciﬁed by its unit-sample response,
h(n).1 Computation of the output from h(n) and x(n) is called convolution and will be
discussed in Chapter 13. Other methods include input-output difference equation and
representation of system structure by block diagram.
Equivalently, knowing a single input-output pair of an LTI system enables us to
predict the output to any input.2 This may be called reverse engineering as shown in the
following example.
Example
12.10
By using reverse calculation ﬁnd the unit-sample response of LTI systems for which
input-output pairs are given as
a.
An FIR system:
x(n) = {1
↑, −1} ⇒y(n) = {1
↑, 0, −1}
b.
An IIR system:
x(n) = {1
↑, −1} ⇒y(n) = d(n)
a.
y0 = h0x0
h0 × 1 = 1
−→
h0 = 1
y1 = h0x1 + h1x0
−1 + h1 = 0
−→
h1 = 1
y2 = h0x2 + h1x1 + h2x0
0 −1 + h2 = −1
−→
h2 = 0
y3 = h0x3 + h1x2 + h2x1 + h3x0
0 + 0 + 0 + h3 = 0
−→
h3 = 0
· · ·
· · · · · ·
the unit-sample response is
h(n) = {1
↑, 1}
b.
y0 = h0x0
h0 × 1 = 1
−→
h0 = 1
y1 = h0x1 + h1x0
−1 + h1 = 0
−→
h1 = 1
y2 = h0x2 + h1x1 + h2x0
0 −1 + h2 = 0
−→
h2 = 1
y3 = h0x3 + h1x2 + h2x1 + h3x0
0 + 0 −1 + h3 = 0
−→
h3 = 1
· · ·
· · · · · ·
the unit-sample response is
h(n) = {1
↑, 1, 1 · · ·} = u(n)
1There are exceptions, but they are of no interest to our present discussion.
2Except when the input is a power series.

Signals and Systems
741
Note that the output of an IIR system may be a ﬁnite sequence as shown in case
b of the present example.
12.3
Response of LTI Discrete-Time Systems
to Power Signals and Sinusoids
Using linearity and time invariance we can show that the input x(n) = zn, where z is a
constant, evokes the output y(n) = Hzn, where the scale factor H is a function of z.3
To show this, and to ﬁnd the scale factor H(z), start with the unit-sample response h(n)
(the ﬁrst entry in Table 12.1) and go through steps 2 to 8.
TABLE 12.1 Using LTI Properties to Derive System’s Response to Power Signals
Step
Operation
Property
Input
=⇒
Output
1
Unit-impulse response
d(n)
⇒
h(n)
2
Shift k units
Time invariance
d(n −k)
⇒
h(n −k)
3
Multiplication by zk
Proportionality
zkd(n −k)
⇒
zkh(n −k)
4
Add over k
Superposition
∞

k=−∞
zkd(n −k)
⇒
∞

k=−∞
zkh(n −k)
5
Let k = n −m
Change of variable
∞

m=−∞
z(n−m)d(m)
⇒
∞

m=−∞
z(n−m)h(m)
6
Factor out zk
zn
∞

m=−∞
z−md(m) ⇒
zn
∞

m=−∞
z−mh(m)
7
Sifting by d(m)
zn
⇒
zn
∞

m=−∞
z−mh(m)
8
H(z) =
∞

m=−∞
z−mh(m) Deﬁne H(z)
zn
⇒
H(z)zn
Note that the above result is derived directly from LTI system properties and not
from the z-transform. The latter is discussed in Chapter 15, where it is shown that H(z)
not only speciﬁes the system’s output to zn, but to any other input as well.
Example
12.11
The unit-sample response of an LTI system is h(n) = {1
↑, 2, 1}. Find its response to
x(n) = 0.5n.
3This is true for almost all LTI systems of interest in engineering and signal processing. Exceptions are those
systems that have no unit-sample response.

742
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
Solution
From Table 12.1 the output is
y(n) = 0.5n
2

m=0
0.5−mh(m) = 0.5n 
1 + 2 × 0.5−1 + 0.5−2
= 9 × 0.5n
The response is also obtained by superposition, using the linearity and time-invariance
property of the system.
y(n) = x(n) + 2x(n −1) + x(n −2) = 0.5n + 2 × 0.5n−1 + 0.5n−2 = 9 × 0.5n
Response to Sinusoids
Let z = e jω. The response to cos ωn is found from the following:
Input
=⇒
Output
zn
⇒
H(z)zn
e jωn
⇒
H(ω)e jωn
cos(ωn) = RE 
e jωn
⇒
RE 
H(ω)e jωn
= |H(ω)| cos(ωn + θ)
In the above
H(ω) = H(z)

z=e jω = |H(ω)|̸ θ
The response to a sinusoid is a sinusoid with the same frequency but possibly different
magnitude and phase. It should be noted that the scale factors H(z) and H(ω) are
two different functions. It is for convenience and simplicity that the same notation H
is used to represent the scale factor when we move from z to ω.
Example
12.12
The backward-difference operator was introduced in Example 12.2. Find its response
to the input cos(ωn).
Solution
The backward-difference operator and its sinusoidal response are given below.
Input
=⇒
Output
x(n)
⇒
x(n) −x(n −1)
e jωn
⇒
e jωn −e jω(n−1) = H(ω)e jωn, where H(ω) = (1 −e−jω) = 2 sin ω
2

e j( π
2 −ω
2 )
cos(ωn) = RE 
e jωn
⇒
RE 
H(ω)e jωn
= |H(ω)| cos(ωn + θ) = −2 sin ω
2

sin 
nω −ω
2

Note that for small ω the response is ≈−ω sin ωn, which is the derivative of the
input with respect to n. The above is an analysis of the backward-difference operator

Signals and Systems
743
in the frequency domain. A time-domain analysis, producing the same result, will be
given in section 12.5.
12.4
Some Properties and Classifications
of Discrete-Time LTI Systems
Two properties of an LTI system, which are of primary interest, are its causality and
stability. These are brieﬂy introduced below.
Causality
In a causal system the output at any time depends on the past and present values of the
input only. The future values of the input to a causal system do not affect its output.
For LTI systems this condition translates to h(n) = 0, t <0, which is a necessary and
sufﬁcient condition for causality. The causality deﬁned by the above criteria is a technical
deﬁnition only and should not be considered synonomous with physical reality. Only
when the independent variable n represents samples of real time, is any physical system
a causal system and vice versa. (Because of this connection a causal system is then
also called physically realizable.) A system that is not causal may still be physically
realizable. Examples are systems in which the independent variable represents factors
other than time (e.g., physical space or a location in a data sequence).
Stability
Stability implies that the value of the output doesn’t grow to inﬁnity if the input is
less than a ﬁxed ﬁnite valued and less. A system is called BIBO-stable (standing for
Bounded-Input Bounded-Output) if every bounded input results in a bounded output.
The BIBO stability condition for a discrete-time system is that the unit-sample response
be absolutely summable.
∞

n=−∞
|h(n)| < B, where B is any large number with a ﬁxed ﬁnite value.
Input-Output Integration Property
Integration of the input of an LTI system leads to integration of its output. For discrete-
time systems integration becomes summation
x(n) ⇒y(n)
n

−∞
x(k) ⇒
n

−∞
y(k)

744
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
As an example, the unit-step response g(n) may be obtained from the unit-sample
h(n) response by
d(n) ⇒h(n)
u(n) =
n

−∞
d(k) ⇒g(n) =
n

−∞
h(k)
The above property often simpliﬁes analysis and solution of LTI systems.
FIR and IIR Systems
An LTI system whose unit-sample response is a sequence with ﬁnite length is called a
Finite Impulse Response (FIR) system. In contrast, a system whose unit-sample response
is a sequence with inﬁnite length is called an Inﬁnite Impulse Response (IIR) system.
The distinction between these two types is seen throughout the analysis, design, and
implementation of discrete-time systems, especially in digital signal processing.
Example
12.13
The ﬁrst three LTI systems given below are FIR and the last three are IIR systems.
The systems represented by two-sided h(n) are not causal.
FIR:
h(n) =









u(n) −u(n −2) = {1
↑, 1, 1}
(−0.5)n [u(n) −u(n −4)] = {1
↑, −1/2, 1/4, −1/8}
(0.5)|n| [u(n + 3) −u(n −4)] = {1/8, 1/4, 1/2, 1
↑, 1/2, 1/4, 1/8}
IIR:
h(n) =













2u(n) −u(n −2) = {2
↑, 2, 1, 1, 1, 1, · · ·}
(−0.5)nu(n) = {1
↑, −1/2, 1/4, −1/8, 1/16, −1/32, · · ·}
(0.5)|n| = {· · · , 1/32, 1/16, 1/8, 1/4, 1/2, 1
↑, 1/2,
1/4, 1/8, 1/16, 1/32, · · ·}
Recursive and Nonrecursive Systems
Let a system be described by the difference equation
y(n) =
M

k=0
bkx(n −k) −
N

k=1
ak y(n −k)
where dependence of y(n) on its past values is expressed explicity through the terms
ak y(n −k). The system and the equation describing it, are called recursive. If coefﬁ-
cients ak, k = 1, 2, . . . are all zero then
y(n) =
M

k=0
bkx(n −k)
and the system is called nonrecursive. The distinction between these two types is also
reﬂected in the block diagram representation described in section 12.6.

Signals and Systems
745
12.5
Discrete LTI Operators
and Difference Equations
Operators are elementary systems that transform one discrete signal to another. The
following operators are some of the basic building blocks of discrete systems.
1.
The unit delay operator D[·] shifts the signal one unit to the right. It is also shown
by the symbol z−1.
Unit delay operator: D[x(n)] = x(n −1)
2.
The unit advance operator A[·] shifts the signal one unit to the left. It is also shown
by the symbol z.
Unit advance operator: A[x(n)] = x(n + 1)
3.
The gain operator G[·] multiplies all elements of the discrete signal by a factor G
(positive or negative).
Gain: G[x(n)] = G · x(n)
4.
The sum operator adds two discrete signals term by term.
The graphical symbols for the unit delay, unit advance, gain, and sum operator are
shown in Figure 12.1.
z–1
z
G
G
(a) Unit delay
(b) Unit advance
(c) Gain
(d) Sum
∑
FIGURE 12.1 Symbols for the (a) unit delay , (b) unit advance, (c) gain, and (d) sum operator.
5.
The difference operators described below evaluate increase (or decrease) in the
discrete-time signals.
The forward-difference operator [·] evaluates the increase in x(n + 1) over x(n).
x(n) = x(n + 1) −x(n)
The backward-difference operator ▽[·] evaluates the increase in x(n) over x(n −1).
▽x(n) = x(n) −x(n −1)
Difference operators may be applied to a signal repeatedly. The second-order forward-
difference operator 2 is
2x(n) = [x(n)] = [x(n + 1) −x(n)] = x(n + 1) −x(n)
= [x(n + 2) −x(n + 1)] −[x(n + 1) −x(n)]
= x(n + 2) −2x(n + 1) + x(n)

746
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
The second-order backward-difference operator ▽2 is
▽2x(n) = ▽[▽x(n)] = ▽[x(n) −x(n −1)] = ▽x(n) −▽x(n −1)
= [x(n) −x(n −1)] −[x(n −1) −x(n −2)]
= x(n) −2x(n −1) + x(n −2)
As seen, these operators are constructed from a combination of delay and advance
operators. Their graphical representation in the form of block diagrams, discussed in
section 12.6, are shown in Figure 12.2.
Example
12.14
Show that the forward- and backward-difference operators may be expressed in terms
of advance or delay operators in the following way:
Solution
 = A −1, and ▽= 1 −D
x(n) = x(n + 1) −x(n) = A[x(n)] −x(n) = [A −1]x(n)
▽x(n) = x(n) −x(n −1) = x(n) −D[x(n)] = [1 −D]x(n)
Example
12.15
Find the response of the backward-difference operator ▽to x(n) = cos(ωn).
Solution
▽x(n) = cos(ωn) −cos[ω(n −1)] = (1 −cos ω) cos(ωn) −sin ω sin(ωn)
= 2 sin
ω
2
 
sin
ω
2

cos(ωn) −cos
ω
2

sin(ωn)

= −2 sin
ω
2

sin

ωn −ω
2

. See also Example 12.12.
LTI Systems and Difference Equations
The linear constant-coefﬁcients difference equation, expressed in any of the following
three forms,
y(n) + a1y(n −1) · · · + aN y(n −N) = b0x(n) + b1x(n −1) · · · + bMx(n −M)
y(n) =
M

k=0
bkx(n −k) −
N

k=1
ak y(n −k)
N

k=0
ak y(n −k) =
M

k=0
bkx(n −k)

Signals and Systems
747
describes a linear time-invariant discrete-time system with x(n) being the input, y(n)
the output, and ak and bk constants (with a0 = 1). Most LTI discrete-time systems are
represented by linear difference equations with constant coefﬁcients such as the above.
For brevity the equation may be written as
DN[y(n)] = DM[x(n)]
DN[y(n)] = y(n) + a1y(n −1) · · · + aN y(n −N)
DM[x(n)] = b0x(n) + b1x(n −1) · · · + bMx(n −M)
DN and DM are linear difference operators made of shifts and gains operating on y(n)
and x(n), respectively. Using the symbol z−1 to represent unit delay, we represent these
operators by
DN = 1 + a1z−1 + · · · + aNz−N
DM = b0 + b1z−1 + · · · + bMz−M
The difference equation is then written as
[1 + a1z−1 + · · · + aNz−N]y(n) = [b0 + b1z−1 + · · · + bMz−M]x(n)
In the above equations, N terms of y and M terms of x are included in the N-th order
equation. Contributions from x(n) may be lumped together as q(n), with the quotation
written as
y(n) + a1y(n −1) · · · + aN y(n −N) = q(n)
q(n) = b0x(n) + b1x(n −1) · · · + bMx(n −M)
You can easily see that the difference equation is made of the basic discrete operators
described previously. Solution methods are provided in Chapter 14.
12.6
Block Diagram Representation
LTI discrete systems whose input-output relationships are given by difference equa-
tions may be represented by an interconnection of unit delays, gains, and adders, called
block diagram. Each connection node of the diagram is associated with an internal
variable. The gains are written on the paths that connect the nodes. A unit delay is
shown by a block of z−1. The input and output are indicated on the diagram. Conven-
tionally, the input enters from the left side and the output is picked up on the right
side of the block diagram. Block diagrams for difference operators are presented in
Figure 12.2. Flow of data in nonrecursive diagrams is in the forward direction only, from
left to right as illustrated by Example 12.18 (Figure 12.3a). Block diagram of recursive
systems contain both feedforward and feedback paths as illustrated by Example 12.19
(Figure 12.3b).

748
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
Example
12.16
Figure 12.2(a) to 12.2(d) show the block diagrams for the following operators:
a.
Forward-difference operator x(n) = x(n + 1) −x(n)
b.
Backward-difference operator ▽x(n) = x(n) −x(n −1)
c.
Second-order forward-difference operator 2x(n) = x(n + 2) −2x(n + 1) +
x(n)
d.
Second-order backward-difference operator ▽2x(n) = x(n) −2x(n −1) +
x(n −2)
FIGURE 12.2 (a), (b). The forward- (a) and backward- (b) difference operators.
z
–1
x(n)
∆x(n)
(a) The forward-difference operator
∆x(n) = x(n + 1) – x(n).
Σ
z–1
–1
x(n)
∇x(n)
(b) The backward-difference operator
∇x(n) = x(n) – x(n – 1).
Σ
FIGURE 12.2 (c), (d). The second-order forward- (c) and backward- (d) difference operators.
z
z
–2
x(n)
∆2x(n)
(c) The second-order forward-difference operator
∆2x(n) = x(n + 2) – (n + 1) + x(n).
Σ
Σ
–2
x(n)
∇2x(n)
(d) The second-order backward-difference operator
∇2x(n) = x(n) – 2x(n – 1) + x(n – 2).
∑
∑
z–1
z–1
Example
12.17
A discrete-time system is described by the nonrecursive equation y(n) = kx(n). The
block diagram of such a system was shown in Figure 12.1(c). The system provides
ampliﬁcation (or attenuation) in x(n). Note that an error in k proportionally causes
the same amount of error in the output. For example 1% error in k produces 1% error
in y.

Signals and Systems
749
Example
12.18
Figure 12.3(a) shows the block diagram for the nonrecursive difference equation
y(n) = x(n) + x(n −1)
2
The output at each moment is the average of the current and previous inputs. The
input reaches the output through two paths, both in the forward direction. This system
provides a smoothing operation on x(n).
Example
12.19
An LTI system is described by the recursive difference equation
y(n) = k[x(n) −βy(n −1)]
In this system the output sample is scaled by a factor β and feedback to the input.
The output is then formed by amplifying the difference signal x(n) −βy(n −1). The
system is shown by the block diagram of Figure 12.3(b) in which the input affects the
output through two paths, one direct and one through feedback, making the system
recursive. Establishing the feedback path reduces sensitivity of the output to variations
in k. Compare with the sensitivity in the ampliﬁer of Example 12.17.
FIGURE 12.3 Block diagram representations of (a) a nonrecursive and (b) a recursive LTI system.
x(n)
y(n)
∑
z–1
1
2
1
2
(a) Example 12.18. The LTI system y(n) =
x(n) + x(n −1)
2
shown by the block diagram is
nonrecursive. The input reaches the output through
two paths both in the forward direction. The value
of the output at each moment is the average of the
current input and its previous value. This system
provides smoothing on x(n).
k
y(n)
z–1
–β
x(n)
∑
(b) Example 12.19. Block diagram of the
LTI system y(n) = k{x(n) −βy(n −1)}
contains a direct path and one with feed-
back making the system recursive. Estab-
lishing the feedback path reduces sensiti-
vity of the input-output relationship to
variations in k.
Example
12.20
Figure 12.4 shows block diagrams made of unit delays, gains, and adders of the
following systems.
a.
y(n) = b0x(n) + b1x(n −1)
b.
y(n) + a1y(n −1) = b0x(n)
c.
y(n) + a1y(n −1) = b0x(n) + b1x(n −1)

750
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
b0
b1
x(n)
y(n)
(a) A nonrecursive system
y(n) = b0x(n) + b1x(n – 1).
z–1
∑
–a1
x(n)
y(n)
(b) A recursive system
y(n) + a1y(n – 1) = b0x(n).
∑
b0
z–1
FIGURE 12.4 Block diagram representations of three LTI systems.
b0
b1
–a1
x(n)
(c) A recursive system y(n) + a1y(n – 1) = b0x(n) + b1x(n – 1).
z–1
z–1
y(n)
∑
∑
Block diagram representation is not unique. A system may be represented by one of
several different block diagrams some of which use fewer elements. See Example
12.21 below. However, a block diagram speciﬁes the system uniquely.
Example
12.21
Verify that the input-output relationship of the system shown in Figure 12.5 is
y(n) + a1y(n −1) = b0x(n) + b1x(n −1)
(1)
Therefore, the two block diagrams of Figure 12.4(c) and Figure 12.5 represent the
same system.
Solution
Let v(n) designate the internal variable at the output of the ﬁrst adder on the diagram
of Figure 12.5. From the feedback loop on the left side of the block diagram we get:
v(n) = x(n) −a1v(n −1)
or
x(n) = v(n) + a1v(n −1)
(2)
From the feedforward loop on the right side of the block diagram we get:
y(n) = b0v(n) + b1v(n −1)
(3)
Substituting x(n) and y(n) from (2) and (3) in the two sides of the input-output
equation (1) we get
b0x(n) + b1x(n −1) = b0[v(n) + a1v(n −1)] + b1[v(n −1) + a1v(n −2)]
= b0v(n) + (a1b0 + b1)v(n −1) + a1b1v(n −2)
(4)

Signals and Systems
751
b1
b0
–a1
x(n)
v(n)
z–1
y(n)
∑
∑
FIGURE 12.5 The input-output relationship of the system shown by the block diagram is y(n)+
a1y(n −1) = b0x(n) + b1x(n −1). This is the same difference equation given in Example
12.20(c). Therefore, the two block diagrams of Figure 12.4(c) and Figure 12.5 represent the same
system.
y(n) + a1y(n −1) = [b0v(n) + b1v(n −1)] + a1[b0v(n −1) + b1v(n −2)]
= b0v(n) + (a1b0 + b1)v(n −1) + a1b1v(n −2)
(5)
The two sides are equal and the input-output equation is veriﬁed.
Example
12.22
Show that the following two input-output equations are equivalent.
y(n) = x(n) + x(n −1)
y(n) −y(n −1) = x(n) −x(n −2)
Substituting for y(n) from the ﬁrst equation into the second equation we verify that
y(n) −y(n −1) = [x(n) + x(n −1)] −[x(n −1) + x(n −2)] = x(n) −x(n −2)
12.7
Analysis and Solution Methods
One goal of systems analysis is to develop and apply methods for computing and pre-
dicting its response to inputs of interest. In the previous sections we have seen examples
of discrete-time systems, mostly described by their input-output relationship
f [y(n), y(n −1), . . . , x(n), x(n −1), . . .] = 0
Obviously, from the above equation we may evaluate y(n) from past values of y and x
by numerical methods. The numerical method may be applied regardless of the system
being linear or time invariant. Numerical methods may seem attractive, especially if
computers are being used, but rarely provide a broader insight. For LTI systems several
analyical methods are used to solve for the response, some of which were illustrated
through examples in this chapter. These methods are listed below.
1.
Time-domain solution by convolution. This method is based on direct application
of linearity property and uses the unit-sample response. The unit-sample response

752
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
of LTI systems will be encountered throughout the rest of the book. Discrete
convolution will be discussed in Chapter 13.
2.
Time-domain solution by difference equation. Difference equations and their
solution methods are discussed in Chapter 14.
3.
Frequency-domain solution by the z-transform.
4.
Frequency-domain solution by the Fourier transform.
Description of signals and systems in the frequency domain will be discussed in
Chapters 15–17 while, as a capstone, Chapter 18 provides an integration of multiple
methods.
12.8
Problems
Solved Problems
1. The response of a system to a unit sample arriving at time n = k is d(n −k) for all integers k.
d(n −k)
⇒
d(n −k),
−∞< k < ∞
It is, however, not known how the system would respond to an input made of more than one unit sample. Can it be
concluded that its response to a unit step is also a unit step?
Solution
The answer is negative. Only if the system is linear will its unit-step response be a unit step.
2. The response of a system to a sample of size x arriving at time n = k is known to be xh(n −k) for all k and x,
where k is an integer, −∞< k < ∞, and x is a number that can assume any value so that −∞< x < ∞.
xd(n −k)
⇒
xh(n −k)
Based on the above, can it be deduced that (1) the system is time invariant? (2) the system is linear?
Solution
The answers to both questions are negative. The shift property is valid in the case of an impulse input. This does
not mean that it holds true for all inputs. Similarly, the proportionality property doesn’t imply the superposition
property in the case of two inputs.
3. In problem 2 assume a linear system. Can it be deduced that the system is time invariant?
Solution
To test for time invariance, we shift an input x(n) and examine the output y(n). We ﬁrst express the input as a sum
of weighted samples.
x(n) =
∞

m=−∞
xmd(n −m)
⇒y(n) =
∞

m=−∞
xmh(n −m)
x2(n) = x(n −k) =
∞

m=−∞
xmd(n −m −k) ⇒y2(n) =
∞

m=−∞
xmh(n −m −k) = y(n −k) all k
The system is time invariant because a shift of k units in the input produces a shift of the same amount in the output
and nothing else.

Signals and Systems
753
4. In an LTI system, given h(n) = {1
↑, −1, 1}, ﬁnd the output for: a) x(n) = {1
↑, 1} and b) x(n) = {1
↑, −1}.
Solution
a.
x(n) = d(n) + d(n −1)
y(n) = h(n) + h(n −1) = {1
↑, −1, 1} + {0
↑, 1, −1, 1} = {1
↑, 0, 0, 1}
b.
x(n) = d(n) −d(n −1)
y(n) = h(n) −h(n −1) = {1
↑, −1, 1} −{0
↑, 1, −1, 1} = {1
↑, −2, 2, −1}
5. The unit-step response of an LTI system is (2 −2−n) u(n). Note that it takes a very long time (theoretically, n = ∞)
for the response to reach its steady-state value 2. It is desired to reduce the transition time to one sample. For this
purpose we ﬁrst convert the unit step to the following input:
x(n) =



a,
n = 0
1,
n ≥1
0,
n < 0
and then apply it to the system. Using the linearity and time-invariance properties, determine the parameter a such
that y(n) = 2 for n ≥1.
Solution
Designate the unit-step response by g(n)u(n), where g(n) = 2 −2−n. The unit-sample response is h(n) =
g(n)u(n) −g(n −1)u(n −1).
The input is
x(n) = ad(n) + u(n −1).
The output, given the above input, is
y(n) = ah(n) + g(n −1)u(n −1)
= ag(n)u(n) −ag(n −1)u(n −1) + g(n −1)u(n −1)
=

0,
n = 0
ag(n) + (1 −a)g(n −1),
n ≥1
Substitute g(n) = 2 −2−n into the above to ﬁnd
y(n) =

0,
n = 0
2 + (a −2)2−n,
n ≥1
For n ≥1, we want y(n) = 2, which requires a = 2. The ﬁrst sample ad(n) sets up the appropriate initial conditions
for the elimination of the transient part of the response.
6. Find the input-output relationship of the discrete-time system given in Figure 12.6.
2
3
2
0.5
x(n)
v(n)
w(n)
z–1
y(n)
∑
∑
∑
FIGURE 12.6 The input-output relationship of the system shown is y(n) −0.5y(n −1) =
5x(n) + x(n −1).

754
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
First Approach
Let w(n) designate the internal variable at the output of the second adder. Then,
from the block diagram,
y(n) = 2x(n) + w(n)
(6)
from Example 12.21,
w(n) = 0.5w(n −1) + 3x(n) + 2x(n −1)
(7)
To ﬁnd the relationship between x(n) and y(n), we need to eliminate w(n) and w(n −1).
from (6) and using time invariance,
w(n −1) = y(n −1) −2x(n −1)
(8)
from (7) in combination with (6),
w(n −1) = 2w(n) −6x(n) −4x(n −1)
= 2y(n) −10x(n) −4x(n −1)
(9)
By setting (8) = (9), we get
y(n) −0.5y(n −1) = 5x(n) + x(n −1)
Second Approach
Let v(n) designate the internal variable between the ﬁrst and second adders on the left side of Figure 12.6. Then,
from the forward loop on the left,
v(n) = x(n) + 0.5v(n −1)
(10)
from the feedback loop on the right,
y(n) = 3v(n) + 2x(n) + 2v(n −1)
(11)
To eliminate v(n) and v(n −1) from (10) and (11) we apply a method similar to the ﬁrst approach and obtain the
same result:
y(n) −0.5y(n −1) = 5x(n) + x(n −1)
The validity of the above relationship between x and y may be veriﬁed in a way similar to that used in Example 12.21.
Third Approach. Employing the z-Operator
The z operator introduced in sections 12.5 and 12.6 may be used as a tool for a systematic (and more convenient)
way of obtaining the input-output relationship. The formal approach is called the z-transform and is discussed in
Chapter 15. Here we brieﬂy demonstrate the use of z−1 in solving the present problem. We show the unit delay by
the operator z−1 and apply it to equations (6) and (7), transforming them into (6a) and (7a), respectively.
from the block diagram,
Y = 2X + W
(6a)
from the problem statement,
W = 0.5z−1W + 3X + 2z−1X
(7a)
By eliminating W from (6a) and (7a) and translating z−1 back to a unit delay in the n-domain we have
(1 −0.5z−1)Y = (5 + z−1)X
y(n) −0.5y(n −1) = 5x(n) + x(n −1)
In the second approach, applying the z−1 operator transforms equations (10) and (11) into (10a) and (11a), respec-
tively.
from the forward loop on the left,
V = X + 0.5z−1V
(10a)
from the feedback loop on the right,
Y = 3V + 2X + 2z−1V
(11a)
By eliminating V from (10a) and (11a) and translating z−1 back to a unit delay in the n-domain we get the same
result. In summary,
input-output relationship in the z-domain:
(1 −0.5z−1)Y = (5 + z−1)X
(12)
input-output relationship in the n-domain:
y(n) −0.5y(n −1) = 5x(n) + x(n −1)
(13)
This concludes three approaches to the solution of this problem.

Signals and Systems
755
Chapter Problems
7. Determine if the systems described by the following input-output relationships are linear or time invariant. If LTI,
ﬁnd their unit-sample responses.
a. y(n) = x(n −2)
b. y(n) = x(n) + x(−n)
c. y(n) = x(n) + u(n)
d. y(n) = x(n) + x(−n + 1)
e. y(n) = x(n) + 2x(n −1)
f. y(n) = x(n) −x(n −1)
g. y(n) = x(n)x(n −1) + x(n −2)
h. y(n) = 2x(n) −nx(n + 1)
i. y(n) = 2x(n) + n
j. y(n) = |x(n)|
k. y(n) = ny(n −1) + 2x(n)
l. y(n) = y(n −1) + nx(n)
m. y(n) = y(n −1) + 2x(n)
n. y(n) = x(n) + x(n −1)y(n −1)
8. Repeat problem 7 for the systems described by the following input-output relationships.
a. y(n) =
100

k=−1
(k −1)x(n −k)
b. y(n) = 2n
3

k=−2
x(n + k)
c. y(n) = (n −1)
5

k=0
x(n −k)
d. y(n) =
5

k=3
0.9kx(n + k)
e. y(n) =
0

k=−∞
x(k)
f. y(n) =
n

k=−∞
x(k)
g. y(n) =
n

k=0
x(k)
h. y(n) =
n+4

k=n
x(k)
i. y(n) =
n+4

k=n−4
x(k)
j. y(n) =
n

k=n−2
x(k)
k. y(n) =
n+4

k=1
x(k)
l. y(n) =
∞

k=−∞
x(k)
9. Let x(n) be the input and y(n) the output of discrete-time systems described by the following difference equations.
Determine if the systems are linear or time invariant. If linear, ﬁnd their unit-sample responses.
a. y(n) = y(n −1) + 2x(n)
b. y(n) = y(n −1) + x(n) + u(n)
c. y(n) = x(−n)
d. y(n) = x(n)y(n) −nx(n −1)
e. y(n) = x(n)d(n)
f. y(n) = 3nx(n) + x(n −1)
g. y(n) = x(n −1)d(n)
h. y(n) = −3ny(n) + x(n)
i. y(n) = y(n −1) + x(−n)
j. y(n) = −y(n −1) + 3nx(n) + x(n −1)
k. y(n) = nx(n)
l. y(n) = 3ny(n −1) + 3nx(n) + x(n −1)
m. y(n) = y(n −1) + nx(n)
n. y(n) = −(0.99)ny(n) + x(n)

756
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
10. Find the input-output difference equation and the unit-step response of an LTI system whose unit-sample response
is:
a. h(n) = {3
↑, 2, 1}
b. h(n) = {1
↑, 1, 1}
11. The input-output difference equation of a causal LTI system and its input are given below.
y(n) = 1.3y(n −1) −0.4y(n −2) + x(n) −2x(n −1)
x(n) = {1
↑, 5, −1, 3, 1, 2, −1, 3, 5, 5, 4, −5, · · ·}
Find the ﬁrst ﬁve nonzero samples of y(n) by recursive numerical method. Note that y(n) = 0, n < 0.
12. A causal LTI system is speciﬁed by the difference equation
y(n) = 3x(n) −2x(n −1) + x(n −2)
a. Sketch the system’s block diagram using gains and unit delays.
b. Find h(n).
c. For x(n) = {1
↑, 3, −1, 5, −2, 3, 1, −4} ﬁnd y(n), n ≤10.
13. The unit-sample response of an LTI system is h(n) = (0.5)nu(n). Find its response to:
a. x(n) = 2[d(n) −d(n −11)]
b. x(n) = 2[u(n) −u(n −11)]
14. A causal system is represented by the difference equation y(n) + 0.3y(n −1) −0.4y(n −2) = x(n).
a. Find the ﬁrst ﬁve terms in h(n).
b. Given x(n) = 9u(n), ﬁnd the ﬁrst ﬁve terms in y(n).
15. A causal system is represented by the difference equation y(n)−0.2y(n−1) = x(n), where x(n) = cos(ωn), −∞<
n < ∞. Show that y(n) = H cos(ωn + θ) and ﬁnd H and θ for:
a. ω = π
b. ω = π/2
16. The input to an LTI system with a unit-sample response h(n) = 3d(n) + 3d(n −1) is x(n) = {1, 1
↑, 1, 1}. Sketch
and label completely the system output y(n).
17. Consider the following discrete-time signal:
x(n) =





0
n < 0
2
0 ≤n ≤4
1
n > 4
a. Express x(n) as an algebraic sum of weighted discrete-time step functions u(n).
b. x(n) is the input to an LTI system with unit-sample response h(n) = u(n). Find its output.
18. Find the ﬁrst ﬁve terms in y(n), the output of a causal system given by y(n) −0.5y(n −1) = d(n).
19. Find the ﬁrst ﬁve terms in y(n), the output of a causal system given by y(n) −0.5y(n −1) = u(n).

Signals and Systems
757
20. The unit-step response of an LTI system is g(n) = (2 −0.5n) u(n). Find and sketch its response to x(n) =
d(n) + d(n −1).
21. Find the ﬁrst ﬁve terms in y(n), the output of a causal system given by the following difference equations and
compare results.
a. y(n) + 2y(n −1) = u(n)
b. y(n) −2y(n −1) = u(n)
c. y(n) + 0.5y(n −1) = u(n)
d. y(n) −0.5y(n −1) = u(n)
22. Find the ﬁrst ﬁve terms in y(n), the output of a causal system given by
a. y(n) + 2y(n −1) = u(n) −u(n −5)
b. y(n) −2y(n −1) = u(n) −u(n −5)
c. y(n) + 0.5y(n −1) = u(n) −u(n −5)
d. y(n) −0.5y(n −1) = u(n) −u(n −5)
23. For each LTI system speciﬁed by the difference equations given below determine if the system is FIR or IIR. Then
identify its block diagram from Figure 12.7, and place appropriate gains on the paths. If the block diagram of a
system is not found in Figure 12.7, draw it.
(i) y(n) = ax(n) + bx(n −1)
(ii) y(n) = ax(n) + bx(n −1) + cx(n −2)
(iii) y(n) + cy(n −1) = ax(n) + bx(n −1)
(iv) y(n) + cy(n −1) = ax(n) + x(n −2)
(v) y(n) + cy(n −1) = ax(n) + bx(n −1) + dx(n −2)
(vi) y(n) + cy(n −1) = ax(n) + bx(n −1) + x(n −2)
(vii) y(n) + cy(n −1) + y(n −2) = ax(n) + bx(n −1)
(viii) y(n) + cy(n −2) = ax(n) + bx(n −1) + cx(n −2)
(ix) y(n) + cy(n −1) + y(n −2) = ax(n) + bx(n −1)
(x) y(n) −cy(n −1) −dy(n −2) = ax(n) + bx(n −1)
(xi) y(n) + cy(n −1) + dy(n −3) = ax(n −1) + bx(n −2)
(xii) y(n) + cy(n −1) + dy(n −3) = ax(n) + bx(n −2)
x(n)
y(n)
(a)
z–1
∑
x(n)
(b)
z–1
y(n)
∑
∑
z–1
FIGURE 12.7 Block diagrams to be used in problem 23.

758
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
z–1
x(n)
y(n)
(c)
∑
x(n)
(d)
z–1
z–1
z–1
y(n)
∑
∑
∑
(e)
(f)
x(n)
z–1
z–1
y(n)
∑
∑
z–1
∑
x(n)
x(n)
z–1
z–1
y(n)
∑
∑
(g)
(h)
z–1
y(n)
∑
z–1
∑
z–1
y(n)
∑
z–1
∑
x(n)
z–1
z–1
∑
∑
FIGURE 12.7 (Continued)
12.9
Project: Deadbeat Control
Introduction and Summary
The discrete-time system introduced at the beginning of this project doesn’t go to rest (i.e., the internal variables of the
system and its output don’t become zero) even when the input has ceased to exist for a long time. Procedure 1 explores
the performance of the system and shows that the system is marginally stable (i.e., the output blows up for a certain group
of inputs even when the input is bounded). To make the system stable and have it return to a zero state in a ﬁnite number

Signals and Systems
759
of steps, a feedback path is suggested. Procedure 2 explores the effect of the feedback on performance of the system. It
shows that the system becomes a FIR system. (FIR systems are inherently stable.) At the end, the project ponders the
usability of the approach in making a broader class of systems stable.
Procedure 1
A single-input, single-output discrete-time system is described by the block diagram of Figure 12.8(a), where x(n) is the
input, y(n) is the output, and xi(n), i = 1, 2, 3, are the internal so-called state variables of the system which represent
its state. The system’s output is a linear combination of its state variables, y(n) = ax1(n) + bx2(n) + cx2(n). All connec-
tions within the block diagram have a unity gain. In this procedure you compute the output for several inputs and initial
conditions. For the purpose of numerical calculations, let a = b = c = 1. (It is recommended that you write a computer
program for doing the work.)
a. Obtain y(n) for the following inputs:
(i)
x(n) = d(n)
(ii)
x(n) = u(n) −u(n −k), k = 2, 5, 10, 20
b. Repeat for sinusoidal inputs:
(iii)
x(n) = cos(nπ)u(n)
(iv)
x(n) = cos nπ
2

u(n)
(v)
x(n) = cos 2πn
3

u(n)
c. Repeat for step and ramp inputs:
(vi)
x(n) = u(n)
(vii)
x(n) = nu(n)
d. Repeat for zero input:
(viii)
x(n) = 0, n ≥0, x1(0) ̸= 0, x2(0) ̸= 0, x3(0) ̸= 0
x(n)
z–1
z–1
z–1
y(n)
+
+
a
b
c
∑
∑
x2(n)
x1(n)
x3(n)
FIGURE 12.8(a) The original system.
Analysis and Conclusion for Procedure 1
Document and summarize your observations. Is the system stable? Is the system FIR or IIR? Under a zero-input condition,
how long does it take to go to a zero state (part d above)?

760
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
Procedure 2
In order to reduce the transition time in going to a zero state, it is suggested that we establish a negative feedback path
with unity gain from x3(n) to the input, as seen in Figure 12.8(b). Show that given such feedback, the system will be
reduced to the FIR block diagram of Figure 12.8(c). Then, repeat procedure 1. Show that the system would require only
three steps to go to a zero state.
x(n)
x2(n)
x1(n)
x3(n)
z–1
z–1
z–1
y(n)
∑
∑
∑
+
+
–
+
a
c
b
FIGURE 12.8(b) The system with negative feedback.
x(n)
x2(n)
x1(n)
x3(n)
z–1
z–1
z–1
y(n)
∑
a
c
b
FIGURE 12.8(c) An equivalent system for Figure 12.8(b).
Analysis and Conclusion
Is the feedback system stable? Under a zero-input condition, how long does it take to go to a zero state (input d in procedure
1)? The feedback approach in this project converts the IIR system of procedure 1 to an FIR system, which is inherently
stable. Discuss how the present approach (that of establishing a feedback path) could provide a general approach to a
broader class of unstable systems.4
4For further discussion, see the article by H. Seraji, “Deadbeat Control of Discrete-Time Systems Using Output Feedback,” Interna-
tional Journal of Control, 21, No. 2 (1975), pp. 213–23.

Signals and Systems
761
Addendum
The following Matlab code generates input-output plots used in procedure 1.
clear; k=100; n=1:k; x=0*n;
for i=5:5;
x(i)=1;
end
y=0*n;
for i=4:k;
y(i)= y(i-3)+x(i-3);
end
figure(1); stem(n,x); axis([0 30 -1 2]); grid;
figure(2); stem(n,y); axis([0 30 -1 2]); grid;
%
for i=5:15;
x(i)=1;
end
y=0*n;
for i=4:k;
y(i)= y(i-3)+x(i-3);
end
figure(3); stem(n,x); axis([0 30 -1 2]); grid;
figure(4); stem(n,y); axis([0 30 -1 5]); grid;
%
x=cos(pi*n);
for i=1:5;
x(i)=0;
end
y=0*n;
for i=4:k;
y(i)= y(i-3)+x(i-3);
end
figure(5); stem(n,x); axis([0 30 -2 2]); grid;
figure(6); stem(n,y); axis([0 30 -2 2]); grid;
%
x=cos(pi*n/2);
for i=1:5;
x(i)=0;
end
y=0*n;
for i=4:k;
y(i)= y(i-3)+x(i-3);
end
figure(7); stem(n,x); axis([0 30 -2 2]); grid;
figure(8); stem(n,y); axis([0 30 -2 2]); grid;
%
x=cos(2*pi*n/3);
for i=1:5;

762
CHAPTER 12
Linear Time-Invariant Discrete-Time Systems
x(i)=0;
end
y=0*n;
for i=4:k;
y(i)= y(i-3)+x(i-3);
end
figure(9);
stem(n,x); axis([0 30 -1 2]);
grid;
figure(10); stem(n,y); axis([0 30 -6 10]); grid;
%
x=0*n;
for i=6:k;
x(i)=1;
end
y=0*n;
for i=4:k;
y(i)= y(i-3)+x(i-3);
end
figure(11); stem(n,x); axis([0 30 -1 2]);
grid;
figure(12); stem(n,y); axis([0 30 -1 10]); grid;
%
x=n-5;
for i=1:5;
x(i)=0;
end
y=0*n;
for i=4:k;
y(i)= y(i-3)+x(i-3);
end
figure(13); stem(n,x); axis([0 30 -5 30]);
grid;
figure(14); stem(n,y); axis([0 30 -10 100]); grid;

Chapter13
Discrete
Convolution
Contents
Introduction and Summary
763
13.1
Linear Convolution and LTI Systems
764
13.2
Properties of Convolution
765
13.3
Solution by Numerical Method
766
13.4
Product Property
768
13.5
Solution by Analytical Method
771
13.6
Graphical Convolution
774
13.7
Convolution in Linear Time-Varying Systems
779
13.8
Deconvolution
783
13.9
Inverse Systems
784
13.10
Problems
787
13.11
Project: Deconvolution and Inverse Systems
792
Introduction and Summary
Convolution is a mathematical implementation of the superposition property. Given the
unit-sample response of a linear system, convolution enables us to obtain the response
to an arbitrary input. An arbitrary input can be expressed as a sum of weighted and
delayed unit samples. If a system is linear and time invariant, the response can also be
expressed by the sum of the unit-sample responses, weighted and delayed accordingly.
The summation operation that expresses the output is called convolution. Evaluation of
the convolution is done either in the time domain or the transform domain. This chapter
introduces time-domain methods. Transform methods will be discussed in later chapters
on the z-transform and Fourier transform.
763

764
CHAPTER 13
Discrete Convolution
The chapter begins with the deﬁnition of discrete convolution in LTI systems, and
then shows how the response to an arbitrary input is found by convolving it with the
system’s unit-sample response. Computation of the convolution sum is illustrated by the
numerical method (when the input signal is a time series) or the analytic method (when
the input signal is speciﬁed in analytic form). The chapter then presents the distributive,
associative, and commutative properties of convolution. The convolution of two ﬁnite-
length sequences is evaluated as the set of coefﬁcients in the product of two polynomials,
providing a bridge to the transform domain.
An example of convolution for a linear time-varying system is also included in
the chapter. The chapter project illustrates, by way of an example, recovery of a signal
through the concepts of deconvolution and inverse systems.
13.1
Linear Convolution and LTI Systems
Definition of Linear Convolution
The convolution of two discrete-time signals x(n) and h(n) is deﬁned by
y(n) =
∞

k=−∞
x(k)h(n −k)
and is shown by y(n) = x(n) ⋆h(n). The discrete convolution deﬁned by the above
sum is called linear convolution, to be distinguished from circular convolution, which
is performed circularly on two ﬁnite sequences.1 The discrete convolution is a linear
operation. It parallels convolution of continuous-time signals and shares its properties.
Application in Linear Systems Analysis
Let h(n) be the response of a discrete-time LTI system to a unit-sample input. The
response of the system to the input x(n) may be evaluated by convolution, that is,
y(n) = x(n) ⋆h(n). To show this, express x(n) as the sum of unit samples that are
shifted k units and weighted by x(k). Because of time invariance, a shift in the input
creates a similar shift in the output. Therefore, the response of the system to d(n −k) is
h(n −k). Similarly, because of linearity, the response to x(k)d(n −k) is x(k)h(n −k).
By superposition, the response to x(n) is, therefore,
y(n) =
∞

k=−∞
x(k)h(n −k)
These steps are summarized in Table 13.1.
1Circular convolution is used in conjunction with the discrete fourier transform (DFT) and will be discussed
in Chapter 17, along with its applications.

Signals and Systems
765
TABLE 13.1 Superposition of Sample Responses
Input
=⇒
Output
d(n)
⇒
h(n)
d(n −k)
⇒
h(n −k)
x(k)d(n −k)
⇒
x(k)h(n −k)
x(n) =
∞

−∞
x(k)d(n −k) ⇒
y(n) =
∞

−∞
x(k)h(n −k)
Special Cases
If the system is causal h(n −k) = 0 for k > n, then the upper limit of the sum will be n.
y(n) =
n

k=−∞
x(k)h(n −k)
Similarly, if the input is causal x(k) = 0 for k < 0, then the lower limit of the sum will
be 0.
y(n) =
∞

k=0
x(k)h(n −k)
The response of a causal system to a causal input is, therefore,
y(n) =
n

k=0
x(k)h(n −k)
13.2
Properties of Convolution
The following three important properties may be directly derived from the deﬁnition
of convolution. These properties apply equivalently to LTI systems, as illustrated in
Figure 13.1.
Convolution is commutative: x(n) ⋆h(n) = h(n) ⋆x(n). The order of x(n) and
h(n) in the convolution sum may be reversed and the result remains the same. To
verify this property, start with the convolution sum and then change the summing
variable k to a new variable p so that k = n −p and n −k = p. Substituting for k
and n −k, we have
y(n) =
∞

k=−∞
x(k)h(n −k) =
∞

p=−∞
x(n −p)h(p) =
∞

k=−∞
h(k)x(n −k)
Therefore, x(n) ⋆h(n) = h(n) ⋆x(n). In an LTI system, the unit-sample response
and the input may exchange places and produce the same output, as shown in
Figure 13.1(a).

766
CHAPTER 13
Discrete Convolution
x(n)
y(n)
h1(n)
h2(n)
x(n)
y(n)
h2(n)
h1(n)
(a) Cummutative property
(b) Associative property
(c) Distributive property
x(n)
y(n)
h(n)
y(n)
h(n)
x(n)
x(n)
y(n)
y(n)
h1(n)
x(n)
h(n) = h1(n) + h2(n) 
h2(n)
∑
+
+
FIGURE 13.1 Three properties of convolution.
Convolution is associative: [x(n) ⋆h1(n)] ⋆h2(n) = x(n) ⋆[h1(n) ⋆h2(n)]. Two
cascaded LTI systems are equivalent to an LTI system with h(n) = h1(n) ⋆h2(n) =
h2(n) ⋆h1(n). Consequently, the two systems can be interchanged, as shown in
Figure 13.1(b).
Convolution is distributive: x(n)⋆[h1(n)+ h2(n)] = x(n)⋆h1(n)+ x(n)⋆h2(n).
Consequently, two LTI systems that are in parallel are equivalent to one LTI
system with h(n) = h1(n) + h2(n), as shown in Figure 13.1(c).
13.3
Solution by Numerical Method
In this section we present the numerical method for computing the convolution. This
method may also be extended to linear time-variant systems as shown in section 13.7.
For simplicity, we assume that x(n) and h(n) are ﬁnite sequences of lengths N + 1 and
M + 1, respectively:
x(n) = {x0
↑, x1, x2, · · · , xN}
h(n) = {h0
↑, h1, h2, · · · , hM}
To ﬁnd y(n) = x(n) ⋆h(n), we ﬁrst write x(n) as
x(n) =
N

k=0
x(k)d(n −k)
We then ﬁnd the system’s response to each sample as shown in Table 13.2.

Signals and Systems
767
TABLE 13.2 Superposition of Responses to
Individual Input Samples
Input
=⇒
Output
x0d(n)
⇒
x0h(n)
x1d(n −1)
⇒
x1h(n −1)
x2d(n −2)
⇒
x2h(n −2)
x3d(n −3)
⇒
x3h(n −3)
...
...
...
x(N)d(n −N)
⇒
xNh(n −N)
x(n) =
N

0
xkd(n −k)
⇒
y(n) =
N

0
xkh(n −k)
In order to illustrate how y(n) is obtained by adding the elements in the nth column,
Table 13.3 expands the summation operation of Table 13.2. In summary,
y(n) = x0hn + x1hn−1 + · · · + xn−1h1 + xnh0
TABLE 13.3 Implementation of y(n)
= x(n) ⋆h(n)
= {x0
↑
, x1, x2, x3, · · ·} ⋆{h0
↑
, h1,
h2, h3, · · ·}
h0
h1
h2
h3
h4
h5
h6
· · ·
hM
x0
x0h0
x0h1
x0h2
x0h3
x0h4
x0h5
x0h6
· · ·
x0h M
x1
x1h0
x1h1
x1h2
x1h3
x1h4
x1h5
· · ·
x1h(M−1)
· · ·
x2
x2h0
x2h1
x2h2
x2h3
x2h4
· · ·
x2h(M−2)
· · ·
· · ·
x3
x3h0
x3h1
x3h2
x3h3
· · ·
x3h(M−3)
· · ·
· · ·
x4
x4h0
x4h1
x4h2
· · ·
x4h(M−4)
· · ·
· · ·
x5
x5h0
x5h1
· · ·
x5h(M−5)
· · ·
· · ·
x6
x6h0
· · ·
x6h(M−6)
· · ·
· · ·
...
· · ·
· · ·
· · ·
· · ·
xN
· · ·
· · ·
xNh M
y0
y1
y2
y3
y4
y5
y6
· · ·
yM
· · ·
yM+N
Sample Calculation
y6 = x0h6 + x1h5 + x2h4 + x3h3 + x4h2 + x5h1 + x6h0

768
CHAPTER 13
Discrete Convolution
Example
13.1
Find the linear convolution of y(n) = x(n) ⋆h(n) given
x(n) =





2
√
3 sin( πn
3 ),
0 ≤n ≤5
and h(n) = {1
↑, 2, 3, 2, 1}
0,
elsewhere
Solution
The input is the ﬁnite sequence x(n) = {0
↑, 1, 1, 0, −1, −1}. Table 13.4 implements
x(n)⋆h(n) where rows represent the output of the system to individual input samples.
TABLE 13.4 y(n)
= x(n) ⋆h(n)
= {0
↑
, 1, 1, 0, −1, −1, 0} ⋆
{1
↑
, 2, 3, 2, 1}
h0
h1
h2
h3
h4
h5
h6
h7
h8
h9
h10
1
2
3
2
1
0
0
0
0
0
0
x0 = 0
0
0
0
0
0
0
x1 = 1
0
1
2
3
2
1
0
x2 = 1
0
1
2
3
2
1
0
x3 = 0
0
0
0
0
0
0
0
x4 = −1
0
−1
−2
−3
−2
−1
0
x5 = −1
0
−1
−2
−3
−2
−1
0
x6 = 0
0
0
0
0
0
0
⇓
⇓
⇓
⇓
⇓
⇓
⇓
⇓
⇓
⇓
⇓
0
1
3
5
4
0
−4
−5
−3
−1
0
y0
y1
y2
y3
y4
y5
y6
y7
y8
y9
y10
Sample Calculation
y5 = x0h5 + x1h4 + x2h3 + x3h2 + x4h1 + x5h0 = 0 + 1 + 2 + 0 −2 −1 + 0 = 0
13.4
Product Property
In section 13.3 we found the elements of the output sequence produced by the convolution
of two ﬁnite sequences x(n) and h(n). These are listed in Table 13.5.
It is seen that yk is the sum of all products xi × h j for which i + j = k. Here is an
example:
y5 = x0h5 + x1h4 + x2h3 + x3h2 + x4h1 + x5h0

Signals and Systems
769
TABLE 13.5 Results of Convolving Two Finite Sequences
x(n) and h(n)
y0 = x0h0
y1 = x0h1 + x1h0
y2 = x0h2 + x1h1 + x2h0
y3 = x0h3 + x1h2 + x2h1 + x3h0
y4 = x0h4 + x1h3 + x2h2 + x3h1 + x4h0
y5 = x0h5 + x1h4 + x2h3 + x3h2 + x4h1 + x5h0
...
yN = x0h N + x1h(N−1) + x2h(N−2) + · · · + xNh0
...
y(N+M) = x0h(N+M) + x1h(N+M−1) + x2h(N+M−2) + · · · + x(N+M)h0
Momentary Diversion
Now consider two ﬁnite polynomials X(z−1) and H(z−1) of orders N and M, respec-
tively.
X(z−1) = x0 + x1z−1 + x2z−2 + x3z−3 + · · · + xNz−N
H(z−1) = h0 + h1z−1 + h2z−2 + h3z−3 + · · · + hMz−M
The product Y(z−1) is a polynomial of order (M+N)
Y(z−1) = X(z−1)H(z−1) =
N+M

n=0
y(n)z−n
Coefﬁcient y(k) is the sum of all products xi × h j for which i + j = k. In other words,
the coefﬁcient of z−k in the product Y(z−1) = X(z−1)H(z−1) are obtained from the
convolution of x(n)⋆h(n) and vice versa. This is illustrated in Table 13.6. This property
may be used to analytically evaluate the convolution.
TABLE 13.6 Product of X(z−1) and H(z−1)
h0
h1z−1
h2z−2
h3z−3
· · ·
hMz−M
x0
x0h0
x0h1z−1
x0h2z−2
x0h3z−3
· · ·
x0h Mz−M
x1z−1
x1h0z−1
x1h1z−2
x1h2z−3
x1h3z−4
· · ·
x1h Mz−(M+1)
x2z−2
x2h0z−2
x2h1z−3
x2h2z−4
x2h3z−5
· · ·
x2h Mz−(M+2)
x3z−3
x3h0z−3
x3h1z−4
x3h2z−5
x3h3z−6
· · ·
x3h Mz−(M+3)
x4z−4
x4h0z−4
x4h1z−5
x4h2z−6
x4h3z−7
· · ·
x4h Mz−(M+4)
...
· · ·
· · ·
· · ·
· · ·
· · · · · ·
xNz−N
xNh0z−N
xNh1z−(N+1) xNh2z−(N+2) xNh3z−(N+3) · · ·
xNh Mz−(M+N)
As an example, collecting the third-order terms we get
(x0h3 + x1h2 + x2h1 + x3h0) z−3 = y3z−3
(x0h3 + x1h2 + x2h1 + x3h0) = y3

770
CHAPTER 13
Discrete Convolution
Example
13.2
Find y(n) = {1
↑, 2, 3, 3, 2, 1} ⋆{1
↑, −1, 1, −1, 1, −1}.
Solution
Y(z−1) = H(z−1)X(z−1)
=

1 + 2z−1 + 3z−2 + 3z−3 + 2z−4 + z−5 
1 −z−1 + z−2 −z−3+z−4−z−5
= 1 + z−1 + 2z−2 + z−3 + z−4 −z−6 −z−7 −2z−8 −z−9 −z−10
y(n) = {1
↑, 1, 2, 1, 1, 0, −1, −1, −2, −1, −1}
Example
13.3
Find y(n) = x(n) ⋆h(n) when x(n) = anu(n) and h(n) = bnu(n) by applying the
product property in the z-domain.
Solution
X(z−1) =
∞

n=0
x(n)z−n =
∞

n=0
anz−n =
1
1 −az−1
H(z−1) =
∞

n=0
h(n)z−n =
∞

n=0
bnz−n =
1
1 −bz−1
Y(z−1) = X(z−1) × H(z−1) =
1
(1 −az−1)(1 −bz−1)
We can break Y(z−1) into two partial fractions:
Y(z−1) =
A
1 −az−1 +
B
1 −bz−1
A =
a
a −b and B =
−b
a −b
We expand the two fractional components of Y(z) into their inﬁnite series, from which
their time functions may be deduced.
Y1(z−1) =
A
1 −az−1 = A

1 + az−1 + a2z−2 + · · ·

= A
∞

n=0
(az−1)n
⇒y1(n) =
a
a −banu(n) = an+1
a −bu(n)
Y2(z−1) =
B
1 −bz−1 = B

1 + bz−1 + b2z−2 + · · ·

= B
∞

n=0
(bz−1)n
⇒y2(n) = −
b
a −bbnu(n) = −bn+1
a −bu(n)

Signals and Systems
771
By adding the two components we have (see Chapter 15 for the formal derivations)
y(n) = y1(n) + y2(n) =
1
(a −b)

a(n+1) −b(n+1)	
u(n)
13.5
Solution by Analytical Method
When x(n) and h(n) are expressed analytically, the convolution sum may be obtained
analytically and in a closed form, as shown in Examples 13.4 to 13.7.
Example
13.4
Convolution with the unit-sample function
Find (a) x(n) ⋆d(n) and (b) x(n) ⋆d(n −N), where d(n) =

1,
n = 0
0,
elsewhere ≡{1
↑}
is the unit-sample function and N is a constant integer.
Solution
a.
x(n) ⋆d(n) =
∞

k=−∞
x(k)d(n −k) = x(n)
b.
x(n) ⋆d(n −N) =
∞

k=−∞
x(k)d(n −k −N) = x(n −N)
Convolution of a discrete-time sequence with a unit sample positioned at N shifts the
sequence to the position of the unit sample.
Example
13.5
Find y(n) = x(n) ⋆h(n) when x(n) = sin
πn
2

and h(n) = {1
↑, 2, 1}.
Soution
Using the result of Example 13.4 we ﬁnd
y(n) = x(n) + 2x(n −1) + x(n −2) = sin
πn
2

+ sin
π(n −1)
2

+ sin
π(n −2)
2

= −2 cos
πn
2

Example
13.6
Find y(n) = x(n) ⋆h(n) when x(n) = anu(n) and h(n) = bnu(n).
Solution
y(n) =
∞

k=−∞
x(k)h(n −k) =
∞

k=−∞
aku(k)bn−ku(n −k)

772
CHAPTER 13
Discrete Convolution
But u(k) = 0 when k < 0 and u(n −k) = 0 when k > n. Therefore, because x and
h are both causal functions, the convolution summation will span the range 0 to n:
y(n) =
n

k=0
akb(n−k) = bn
n

k=0
akb−k
= bn
n

k=0
a
b
k
= bn 1 −
 a
b
n+1
1 −
 a
b
 , n ≥0
y(n) =
1
(a −b)

a(n+1) −b(n+1)	
u(n)
Example
13.7
Find y(n) = x(n) ⋆h(n) where x(n) = anu(−n) and h(n) = bnu(n).
Solution
The convolution sum is
y(n) =
∞

k=−∞
h(k)x(n −k) =
∞

k=−∞
bku(k)an−ku(−n + k)
But u(k) = 0 when k < 0. Therefore,
y(n) =
∞

k=0
bkan−ku(−n + k)
Also u(−n + k) = 0 when k < n. Therefore, the limits and result of the summation
become:
For n < 0
y(n) =
∞

k=0
bka(n−k) =
a
a −ban
For n ≥0
y(n) =
∞

k=n
bka(n−k) =
a
a −bbn
y(n) =
1
a −b

anu(−n) + bnu(n) −d(n)
	
The above results are valid only if a > b. Otherwise, the convolution sum becomes
unbounded.
Comment
Limits of the summation can also be obtained by the graphical method.
Example
13.8
Find y(n) = x(n) ⋆h(n), where x(n) = e−αnu(n) and h(n) = e−βnu(n).
Solution
From Example 13.6 we have
anu(n) ⋆bnu(n) =

a
a −ban +
b
b −a bn

u(n)

Signals and Systems
773
Let a = e−α and b = e−β. Then
e−αnu(n) ⋆e−βnu(n) =

1
1 −e(α−β) e−αn +
1
1 −e(β−α) e−βn

u(n)
Example
13.9
It is desired to ﬁnd y(n) = x(n) ⋆h(n), where x(n) = e−αnu(n) and h(n) =
e−βn cos(ωn)u(n). Note that h(n) = RE{e−(β+ jω)nu(n)}.
a.
Show that y(n) = RE{e−αnu(n) ⋆e−z0nu(n)}, where z0 = β + jω.
b.
Using the above property ﬁnd y(n) = e−nu(n) ⋆e−n cos(n)u(n).
Solution
a.
e−αnu(n) ⋆e−z0nu(n) = e−αnu(n) ⋆e−βn [cos(ωn) −j sin(ωn)] u(n)
= e−αnu(n) ⋆e−βn cos(ωn)u(n)
−je−αnu(n) ⋆e−βn sin(ωn)u(n)
Therefore,
e−αnu(n) ⋆e−βn cos(ωn)u(n) = RE{e−αnu(n) ⋆e−z0nu(n)}
b.
Using the results of Example 13.8 we ﬁnd
C(n) = e−nu(n) ⋆e−(1+ j)nu(n) =

1
1 −e−j e−n +
1
1 −e j e−(1+ j)n

u(n)
=

(0.5 −0.9152 j)e−n + (0.5 + 0.9152 j)e−(1+ j)n	
u(n)
y(n) = e−nu(n) ⋆e−n cos(n)u(n) = RE{C(n)}
= 0.5e−n(1 + cos n + 1.83 sin n)u(n)
= [0.5e−n + 1.043e−n sin(n + 28.6◦)]u(n)
Example
13.10
The unit-sample response of an LTI system is h(n) = 0.5nu(n). Find its response to
x(n) = 3−|n|.
Solution
The input can be expressed as x(n) = 3nu(−n) + 3−nu(n) −d(n). The elements of
the response corresponding to the above input components are, respectively,
y1(n) = 3nu(−n) ⋆0.5nu(n) = 1.2

3nu(−n) + 0.5nu(n) −d(n)

y2(n) = 3−nu(n) ⋆0.5nu(n) =

3 × 0.5n −2 × 3−n
u(n)
y3(n) = d(n) ⋆0.5nu(n) = 0.5nu(n)
y(n) = y1(n) + y2(n) −y3(n) = 1.2 × 3nu(−n) +

3.2 × 0.5n −2 × 3−n
u(n) −1.2d(n)
=

1.2 × 3n
n ≤0
3.2 × 0.5n −2 × 3−n
n ≥0

774
CHAPTER 13
Discrete Convolution
13.6
Graphical Convolution
The convolution
y(n) =
∞

k=−∞
x(k)h(n −k)
may be performed graphically by the ﬂip-shift-multiply-add method described below.
Step 1 :
Flip h(k) around k = 0 to obtain h(−k).
Step 2 :
Shift h(−k) by n units to obtain h(n −k). A positive n shifts h(−k) to the
right. A negative n shifts h(−k) to the left. Start with n = −∞. With n kept
ﬁxed, perform tasks in steps 3 and 4 for k ranging from its lowest to highest
value.
Step 3 :
Multiply h(n −k) by x(k) term by term. Obtain the product x(k)h(n −k)
for all k.
Step 4 :
Add x(k)h(n −k) for all k. Call the sum y(n) for the given n.
Step 5 :
Go back to step 2, increment n by one unit and repeat the cycle until y(n) is
found for all n.
The graphical method can also determine the limits when the convolution is evaluated
analytically.
Example
13.11
Find the convolution of
y(n) =
∞

k=−∞
h(k)x(n −k), where x(n) = u(n) −u(n −8), and h(n) = e−n
3 u(n)
by the graphical method and compare with the result obtained by the analytical
method.
Solution
The graphical method was implemented on a computer, resulting in the displays of
Figure 13.2.
The steps in Figure 13.2 are: (a) Display of h(k). (b) Display of x(k). (c)
Flip and shift x(k) by n units to obtain x(−n + k), here n = 4 units to the right.
(d) Multiply h(k) × x(n −k). (e) Add y(n) =  h(k)x(n −k). For example, the
sum of the sample values for n = 4, shown in (d) is y(4) = 2.8614. The values of
y(n) obtained by the computer and rounded to the nearest second decimal are
y(n) = {· · · , 0, 1
↑, 1.72, 2.23, 2.6, 2.86, 3.05, 3.19, 3.28, 2.35, 1.69, 1.17, 0.8,
0.54, 0.35, 0.22, 0.12, 0.05, 0, · · ·}

Signals and Systems
775
1
0
–8
–6
–4
–2
0
2
4
6
8
10
(a) h(k) = (0.7165)ku(k)
1
0
–8
–6
–4
–2
0
2
4
6
8
10
(b) x(k) = u(k) −u(k −8)
1
0
–8
–6
–4
–2
0
2
4
6
8
10
(c) x(−k + 4)
1
0
–8
–6
–4
–2
0
2
4
6
8
10
(d) h(k) × x(−k + 4)
4
3
2
1
0
–1
–15
–10
–5
0
5
10
15
20
(e) y(n) = h(n) ⋆x(n)
FIGURE 13.2 The graphical visualization of the convolution in Example 13.11 showing the
steps to ﬂip-shift-multiply-add. In this example, x(n) = u(n) −u(n −8), h(n) = e−n
3 u(n) and
y(n) = x(n) ⋆h(n).

776
CHAPTER 13
Discrete Convolution
Analytic Solution
The convolution result shown in (e) may be expressed analytically by
y(n) = y1(n) −y1(n −8)
y1(n) = u(n) ⋆e−n
3 u(n) =
n

k=0
e−n−k
3
=

3.5277 −2.5277e−n
3

u(n)
y(n) =









0,
n < 0
3.5277 −2.5277e−n
3 ,
0 ≤n ≤7
33.8511e−n
3 ,
n ≥8
The values obtained by the graphical method are in agreement with the analytic
method.
Example
13.12
Find y(n) = h(n) ⋆x(n) where
h(n) = {1
↑, 1, 1, −1, −1, 1, −1}
x(n) = {0
↑, 1, −1, 1, 1, −1, 1, −1, −1, 1, −1, −1, 1, 1, 1, −1, 1, 1, −1, −1, 1, 1, −1,
1, −1, −1, 1, 1, 1, 1, −1, −1, 1}
Solution
Table 13.7 displays the ﬁrst 16 elements of x(k). It reverses h(k), shifts it by n units,
and registers h(n −k) under x(k). For each n, y(n), obtained by multiplying x(k)
with h(n −k) and summing the elements in the product, is shown by the right-side
column of Table 13.7. The result is
y(n) = {0
↑, 1, 0, 1, 0, 1, 2, −5, 1, −1, −3, 3, −3, 1, 7, −1, −1, 1, 1,
−1, −5, 3, 3, −1, −3, 1, −1, −1, 7, 1, −1, −1, −3, 0, 3, −2, −1, 2, −1}
Sample Calculation
y7 =

k
x(k)h(7 −k) = x1h6 + x2h5 + x3h4 + x4h3 + x5h2 + x6h1 + x7h0
= (1)(−1) + (−1)(1) + (1)(−1) + (1)(−1) + (−1)(1) + (1)(1) + (−1)(1)
= −1 −1 −1 −1 −1 + 1 −1 = −5

Signals and Systems
777
TABLE 13.7 Implementation of the Convolution of Example 13.12
↓
x(k) ⇒
0
1 −1
1
1 −1
1 −1 −1
1 −1 −1
1 1 1 −1
n
h(n −k)
y(n)
↓⇓
⇓
0
h(−k)
·
1
1
1
0 ←
1
h(1 −k)
· −1
1
1
1
1
2
h(2 −k)
· −1 −1
1
1
1
0
3
h(3 −k)
·
1 −1 −1
1
1
1
1
4
h(4 −k)
−1
1 −1 −1
1
1
1
0
5
h(5 −k)
−1
1 −1 −1
1
1
1
1
6
h(6 −k)
−1
1 −1 −1
1
1
1
2
7
h(7 −k)
−1
1 −1 −1
1
1
1
−5
8
h(8 −k)
−1
1 −1 −1
1
1
1
1
9
h(9 −k)
−1
1 −1 −1
1
1
1
−1
10 h(10 −k)
−1
1 −1 −1
1
1
1
−3
11 h(11 −k)
−1
1 −1 −1
1
1
1
3
12 h(12 −k)
−1
1 −1 −1
1
1
1
−3
13 h(13 −k)
−1
1 −1 −1
1
1 1
1
14 h(14 −k)
−1
1 −1 −1
1 1 1
7
15 h(15 −k)
−1
1 −1 −1 1 1
1
−1
...
...
Example
13.13
Find y(n) = x(n) ⋆h(n), where x(n) = e−| n
3 | and h(n) = u(n) −u(n −5) =
{1
↑, 1, 1, 1, 1}, by the graphical method and compare with the result obtained by the
analytical method. The graphical method was implemented on a computer, resulting
in the displays of Figure 13.3, where a = e−1/3 = 1.3956.
Solution
The convolution sum is y(n) =
∞

k=−∞
x(k)h(n−k). It adds up the product x(k)h(n−k)
over the dummy variable k. To ﬁnd the limits of the summation and evaluate its value
ﬁrst plot x(k) and h(k) as a function of k as done in Figure 13.3(a) and (b). Then ﬂip
h(k) around the vertical axis to get h(−k), shift it by n units (right or left) to get

778
CHAPTER 13
Discrete Convolution
1
0
–10
–8
–6
–4
–2
0
2
4
6
8
10
(a) x(k) = a−|k|, a = 1.3956
–10
–8
–6
–4
–2
0
2
4
6
8
10
1
0
(b) h(k) = u(k) −u(k −5)
–10
–8
–6
–4
–2
0
2
4
6
8
10
1
0
(c) n ≤0
h(n −k), n = −2
1
0
–10
–8
–6
–4
–2
0
2
4
6
8
10
(d) 0 < n ≤4,
h(n −k), n = 2,
1
0
–10
–8
–6
–4
–2
0
2
4
6
8
10
(e) n > 4, h(n −k), n = 6,
4
3
2
1
0
–1
–10
–8
–6
–4
–2
0
2
4
6
8
10
( f ) y(n) = x(n) ⋆h(n)
FIGURE 13.3 The graphical visualization of the convolution in Example 13.13 showing the
steps to ﬂip-shift-multiply-add. In this example, x(n) = e−| n
3 |, h(n) = u(n) −u(n −5) and
y(n) = x(n) ⋆h(n).

Signals and Systems
779
h(n −k), multiply by x(k) to get x(k)h(n −k), and add the elements to get the value
of y(n) for the given shift. See Figure 13.3. In this example
y(n) =
n

k=n−4
x(k)
is a moving average of x(n) under a ﬁve-samples wide uniform window. We recognize
the following three regions:
(i)
n≤0
(shown in Figure 13.3c for n= −2), y(n)=
n

k=n−4
ak=2.8614an, n≤0
(ii) 0<n≤4 (shown in Figure 13.3d for n=2),
derivation is left as a problem
(iii) n>4
(shown in Figure 1.3e for n = 6),
y(n)=
n

k=n−4
a−k=10.8553a−n, n
Note: y(0) = y(4) = 2.8614, yMax = y(2) = 1 + 2(a−1 + a−2) = 3.46, and
y(n + 2) is an even function. The graphical method was implemented on a computer,
resulting in the displays of Figure 13.3. Readings off the computer output are in
agreement with the results obtained by analytical solution.
13.7
Convolution in Linear Time-Varying
Systems
A discrete-time system may be linear but change with time. Its unit-sample response
then depends on the arrival time of the unit sample. An example is a system represented
by a linear difference equation whose coefﬁcients are n-dependent. To illustrate the use
of convolution for linear time-varying systems, let the response of the system at time n
to a unit-sample input arriving at time k be designated by h(n, k). Using the linearity
property, the output y(n) may be computed as shown below.
Input
=⇒
Output
d(n −k)
⇒
h(n, k)
x(k)d(n −k)
⇒
x(k)h(n, k)
x(n) =
∞

k=−∞
x(k)d(n −k) ⇒
y(n) =
∞

k=−∞
x(k)h(n, k)
Convolution for linear time-variant systems is, therefore,
y(n) =
∞

k=−∞
x(k)h(n, k)

780
CHAPTER 13
Discrete Convolution
Example
13.14
In a linear time-varying system the response at time n to a unit-sample input arriving
at time k is given by
h(n, k) =

kanu(n −k),
k ≥0
0,
k < 0
Find g(n, k), the response at time n to a unit step arriving at time k > 0.
Solution
A unit step arriving at time k is shown by u(n −k). It may be expressed as a train of
unit samples starting from time n = k.
u(n −k) =
∞

p=k
d(n −p)
This is the sum of unit samples arriving at time p from p = k to p = ∞. Each sample
produces a response h(n, p). Since the system is linear, the response to u(n −k) is
found by superposition of the system response to the samples:
g(n, k) =
∞

p=k
h(n, p)
Having assumed a causal system, h(n, p) = 0 for n < p,
g(n, k) =
n

p=k
h(n, p)
To evaluate the sum, change the variable p to (n −q) so that q = (n −p) with q
being the new summation index. The lower and upper limits of the above summation
are found from
Variable:
p
⇒(n −q)
Lower limit:
k
⇒(n −k)
Upper limit:
n
⇒0
The summation becomes
g(n, k) =
0

q=n−k
h [n, (n −q)]
Reversing the order of summation we get
g(n, k) =
n−k

q=0
h [n, (n −q)]
Substituting for h(n, k) = kan we get
g(n, k) =
n−k

q=0
(n −q)an = an
n−k

q=0
(n −q)

Signals and Systems
781
This is a ﬁnite sum of (n −k + 1) elements that starts from n and decrements in steps
of one until it becomes equal to k. To evaluate the sum note that
i)
The value of the ﬁrst term is n.
ii)
The value of the last term is k.
iii)
There are (n −k + 1) terms in the sum.
iv)
The sum of the ﬁrst and last terms is n + k.
v)
The sum of the second and penultimate term is (n −1) + [n −(n −k −1)] =
n + k, etc.
vi)
Therefore,
n−k

q=0
(n −q) = (n −k + 1)(n + k)
2
vii)
Finally, the response of the system at time n to a unit step arriving at time
k > 0 is
g(n, k) = (n −k + 1)(n + k)
2
anu(n −k)u(k)
Alternative Solution
The time-varying convolution may also be evaluated from the array shown in
Table 13.8. The array has two dimensions indexed by k (for the rows, 0 ≤k < ∞) and
n (for the columns, 0 ≤n < ∞). Each array entry represents h(n, k), the system’s
response at time n to a unit sample arriving at time k.
TABLE 13.8 Implementation of Convolution for a Time-Varying System
Response at time n to a unit sample arriving at time k
0
1
2
3
4
5
6
· · ·
M
· · ·
d(n)
⇒
0
0
0
0
0
0
0
· · ·
0
· · ·
d(n −1) ⇒
a
a2
a3
a4
a5
a6
· · ·
aM
· · ·
d(n −2) ⇒
2a2
2a3
2a4
2a5
2a6
· · ·
2aM
· · ·
d(n −3) ⇒
3a3
3a4
3a5
3a6
· · ·
3aM
· · ·
d(n −4) ⇒
4a4
4a5
4a6
· · ·
4aM
· · ·
d(n −5) ⇒
5a5
5a6
· · ·
5aM
· · ·
d(n −6) ⇒
6a6
· · ·
6aM
· · ·
...
· · ·
· · ·
· · ·
d(n −N) ⇒
NaM
· · ·
The output at n0 to a step function arriving at k0 is the sum of the elements of the
vertical strip with n = n0 and k ≥k0. This strip is made of the elements of the n0-th
column for which k ≥k0. As an example, the response at time n = 5 to a step that

782
CHAPTER 13
Discrete Convolution
has arrived at k = 2 is the sum of the third through sixth elements, counting downward,
in the n = 5 column and is evaluated to be
g(n, k)

n=5,k=2 = 2a5 + 3a5 + 4a5 + 5a5
= a5(2 + 3 + 4 + 5) = 14a5
As another example, the response at time n = 6 to a step that has arrived at
k = 4 is
g(6, 4) = 4a6 + 5a6 + 6a6 = 15a6
The closed form of the response is
g(n, k) = kan + (k + 1)an + (k + 2)an + · · · + nan
= an
n

ℓ=k
ℓ= (n −k + 1)(n + k)
2
an, n ≥k ≥0
Example
13.15
Find y(n), the response of the linear time-varying system of Example 13.14 to the
pulse
x(n) =

1,
0 ≤n < N
0,
elsewhere
Solution
The pulse is N samples wide. It may be expressed as the sum of two steps x(n) =
u(n) −u(n −N). From Example 13.14 the response at time n to a unit step arriving
at time k is
g(n, k) = (n −k + 1)(n + k)
2
anu(n −k)
Because of linearity
y(n) = g(n, 0) −g(n, N)
= (n + 1)n
2
anu(n) −(n −N + 1)(n + N)
2
anu(n −N)
and so
y(n) =











0,
n < 0
n(n + 1)
2
an
0 ≤n < N
N(N −1)
2
an
n ≥N

Signals and Systems
783
13.8
Deconvolution
The convolution operation allows us to ﬁnd the output of an LTI system given its unit-
sample response and the input. Can the reverse be done? In other words, can we ﬁnd an
input that would produce a desired output? Can we recover the input by observing the
output? The answer is often yes, especially in the case of FIR systems, and is accom-
plished through deconvolution. Here we present the idea by a simple example. Formal
methods will be devised later on in Chapter 15. See also the project at the end of this
chapter.
Example
13.16
An input-output pair in a discrete-time LTI system is
{1
↑, 0, 1} ⇒{3
↑, 2, 4, 2, 1}
a.
Find the unit-sample response h(n).
b.
Find the input that produces {3
↑, 5, 3, 1} at the output.
Solution
a.
Using the information previously organized in Table 13.5, we ﬁnd that
h0 = y0/x0 = 3/1 = 3
h1 = (y1 −x1h0)/x0 = (2 −0 × 3)/1 = 2
h2 = (y2 −x1h1 −x2h0)/x0 = (4 −0 × 2 −1 × 3)/1 = 1
h3 = (y3 −x1h2 −x2h1 −x3h0)/x0 = (2 −0 × 1 −1 × 2)/1 = 0
h4 = (y4 −x1h3 −x2h2 −x3h1 −x4h0)/x0 = (1 −0 × 1 −1 × 1)/1 = 0
h5 = (y5 −x1h4 −x2h3 −x3h2 −x4h1 −x5h0)/x0 = 0
The result is h(n) = {3
↑, 2, 1}.
b.
Again, from Table 13.5 we ﬁnd
x0 = y0/h0 = 3/3 = 1
x1 = (y1 −x0h1)/h0 = (5 −1 × 2)/3 = 1
x2 = (y2 −x0h2 −x1h1)/h0 = (3 −1 × 1 −1 × 2)/3 = 0
x3 = (y3 −x0h3 −x1h2 −x2h1)/h0 = (1 −1 × 0 −1 × 1)/3 = 0
x4 = (y4 −x0h4 −x1h3 −x2h2 −x3h1)/h0 = 0
x5 = (y5 −x0h5 −x1h4 −x2h3 −x3h2 −x4h1)/h0 = 0
The result is x(n) = {1
↑, 1}.

784
CHAPTER 13
Discrete Convolution
Example
13.17
Use the product property, in the z-domain, of convolution to solve Example 13.16.
Solution
a.
X(z) = 1 + z−2
Y(z) = 3 + 2z−1 + 4z−2 + 2z−3 + z−4
H(z) = Y(z)/X(z) = 3 + 2z−1 + 4z−2 + 2z−3 + z−4
1 + z−2
= 3 + 2z−1 + z−2 (by long division)
h(n) = {3
↑, 2, 1}.
b.
X(z) = 3 + 5z−1 + 3z−2 + z−3
3 + 2z−1 + z−2
= 1 + z−1 (by long division)
x(n) = {1
↑, 1}.
13.9
Inverse Systems
It is sometimes desired to cancel the effect of a particular system. An example is the
equalizer inserted in an audio system to compensate for the weak frequency response
of a recording head. Another example is the averaging and smearing effects produced
by a sensor that has limited resolution. A third example is the degradation (blaring)
of an image due to the motion of the object. Still another example is the dynamics of
a transducer, such as a robotic arm, which converts a command signal into a desired
trajectory. In such cases one would like to eliminate the distortions and imperfections in
the system by neutralizing its dynamics (such as those of a microphone, a camera, or a
robotic arm). This is done by introducing an inverse effect.
Mathematically, given an LTI system with unit-sample response h(n), we search
for another LTI system with unit-sample response h(n) such that the overall unit-sample
response of their cascade arrangement becomes h(n) ⋆h(n) = d(n). h(n) is then called
the inverse of h(n). The concept of an inverse system is closely related to deconvolution.
We illustrate this concept by an example. More discussion will be presented later. See
also the project at the end of this chapter.
Example
13.18
The unit-sample response of a discrete-time LTI system is h(n) = (0.5)n(n). Find
the unit-sample response of its inverse system.
Solution
This problem may be formulated as in Example 13.16. That is, given the system with
an input-output pair
d(n) ⇒(0.5)nu(n)

Signals and Systems
785
ﬁnd the input that produces d(n) at the system’s output. Using the approach of
Example 13.5 we ﬁnd that {1
↑, −0.5} is such an input. If we construct an LTI sys-
tem with h(n) = {1
↑, −0.5} (to be called the inverse system) and place it in cascade
fashion in front of the original system (as shown in Figure 13.4), the overall unit-
sample response will be d(n). This may also be veriﬁed directly by evaluating
h(n) ⋆h(n) = (0.5)nu(n) ⋆{1
↑, −0.5} = (0.5)nu(n) −0.5(0.5)n−1u(n −1)
= (0.5)n[u(n) −u(n −1)] = d(n)
We will revisit inverse systems and deconvolution in the z-domain in Chapter 15.
x(n)
y(n)
h(n)
x(n)
y(n)
h(n)
h(n)
FIGURE 13.4 The two systems h(n) = (0.5)nu(n) and h(n) = {1
↑, −0.5} are inverses of
each other. Cascading them produces a system in which y(n) = x(n).
Example
13.19
Draw the block diagram of the cascade of the two systems of Example 13.18, h(n) =
{1
↑, −0.5} followed by h(n) = (0.5)nu(n), and show that the unit-sample response of
the overall system is d(n).
Solution
The ﬁrst system, with the unit-sample response h(n) = {1
↑, −0.5}, is described by
the difference equation w(n) = x(n) −0.5x(n −1), where x(n) is the input and
w(n) is the output. Its block diagram has a forward path. The second system, with
the unit-sample response h(n) = (0.5)nu(n) and input coming from the output of the
ﬁrst system, is described by y(n) = w(n) + 0.5y(n −1). Its block diagram has a
feedback path. Eliminating w(n) between the two difference equations, we obtain
y(n) −0.5y(n −1) = x(n) −0.5x(n −1) ⇒
y(n) = x(n)
The above derivations are summarized in the table below. See also Figure 13.5(a).
System
Unit-Sample Response
Input
Output
Difference Equation
1
h(n) = {1
↑, −0.5}
x(n)
w(n)
w(n) = x(n) −0.5x(n −1)
2
h(n) = (0.5)nu(n)
w(n)
y(n)
y(n) = w(n) + 0.5y(n −1)
1 →2
h(n) ⋆h(n) = d(n)
x(n)
y(n)
y(n) = x(n)

786
CHAPTER 13
Discrete Convolution
Example
13.20
Draw the block diagram of the cascade of the two systems of Example 13.18, h(n) =
(0.5)nu(n) followed by h(n) = {1
↑, −0.5}, and show that the unit-sample response of
the overall system is d(n). Then, conclude that the block diagram of Figure 13.5(a)
may be reduced to Figure 13.5(c).
(a) Cascading h(n) with h(n).
–0.5
0.5
x(n)
z–1
z–1
Σ
Σ
Σ
0.5
–0.5
x(n)
q(n)
w(n)
z–1
z–1
y(n) = x(n)
y(n) = x(n)
Σ
(c) Combining the unit delays in (b). The system is, therefore, equivalent to (a).
(d) Equivalent system for (a), (b), and (c).
0.5
–0.5
x(n)
q(n)
z–1
y(n) = x(n)
Σ
Σ
x(n)
y(n) = x(n)
(b) Cascading h(n) with h(n) is equivalent to the system in (a).
FIGURE 13.5 Cascading two inverse systems with unit-sample responses h(n) and h(n).
h(n) = 0.5nu(n)
h(n) = {1
↑, −0.5}
h(n) ⋆h(n) = h(n) ⋆h(n) = 0.5nu(n) −0.5 × 0.5(n−1)u(n −1) = d(n)
The three systems (a), (b), and (c) are equivalent to (d).

Signals and Systems
787
Solution
By an approach similar to that of Example 13.19 we write the difference equations
and construct the cascade block diagram of Figure 13.5(b).
q(n) = x(n) + 0.5q(n −1) from the feedback loop on the left side of Figure 13.5(b)
y(n) = q(n) −0.5q(n −1) from the feedforward loop on the right side of
Figure 13.5(b)
Eliminating q(n) between the two difference equations we obtain y(n) = x(n). By
combining the unit delays in Figure 13.5(b) we obtain Figure 13.5(c), which makes
it equivalent to Figure 13.5(a). The above derivations are summarized below.
System
Unit-Sample Response
Input
Output
Difference Equation
1
h(n) = (0.5)nu(n)
x(n)
q(n)
q(n) = x(n) + 0.5q(n −1)
2
h(n) = {1
↑, −0.5}
q(n)
y(n)
y(n) = q(n) −0.5q(n −1)
1 →2
h(n) ⋆h(n) = d(n)
x(n)
y(n)
y(n) = x(n)
13.10
Problems
Solved Problems
1. Given two ﬁnite-duration sequences x(n) = {1
↑, 2, 3, 2, 1} and h(n) = {1
↑, 0, 1}.
a. Compute the convolution y(n) = x(n) ⋆h(n) by superposition in the time domain.
b. Find y(n) by the product property in the z-domain.
Solution
a. By superposition y(n) = x(n) + x(n −2) and
x(n)
1 2 3 2 1 0 0
x(n −2) 0 0 1 2 3 2 1
y(n)
1 2 4 4 4 2 1
.
b. In the z-domain:
H(z) = 1 + z−2
X(z) = 1 + 2z−1 + 3z−2 + 2z−3 + z−4
Y(z) = H(z)X(z) = 
1 + z−2
1 + 2z−1 + 3z−2 + 2z−3 + z−4
= 1 + 2z−1 + 4z−2 + 4z−3 + 4z−4 + 2z−5 + z−6
y(n) = {1
↑, 2, 4, 4, 4, 2, 1}

788
CHAPTER 13
Discrete Convolution
2. Convolution of two cyclic causal functions. Find y(n) = x(n) ⋆h(n) where x(n) and h(n) are causal functions
given below.
x(n) = {1
↑, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0 · · ·} =

x(n + 6)
n ≥0
0
n < 0
h(n) = {1
↑, −1, 1, −1, 1, −1, · · ·} =

h(n + 2)
n ≥0
0
n < 0
Solution
y(n) =
∞

k=0
[x(n −k) −x(n −k −1)] = {1
↑, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0 · · ·}
3. Integration. Find y(n) = sin πn
4

u(n) ⋆u(n).
Solution
x(n) is 8-periodic with zero mean: x(n) = {0
↑, 0.707, 1, 0.707, 0, −0.707, −1, −0.707}
y(n) =
n

k=−∞
x(n) is 8-periodic:
y(n) = {0
↑, 0.707, 1.707, 2.414, 2.414, 1.707, 0.707, 0}
4. Initial conditions. The input to a discrete-time LTI system with the unit-sample response h(n) = anu(n), a < 1,
is x(n) = Ad(n + 1) + u(n). Determine the factor A so that y(n) is a constant for n ≥0.
Solution
y(n) = x(n) ⋆h(n) = Ah(n + 1) +
n

k=0
ak = Aan+1u(n + 1) + 1 −an+1
1 −a u(n)
For A =
1
1 −a we have y(n) =
1
1 −a , n ≥−1
5. The unit-sample response of a causal system is h1(n) = [5(0.5)n −4(0.4)n]u(n). Find h2(n) such that h(n) =
h1(n) ⋆h2(n) = d(n).
Solution
Apply the z operator to h1(n) and h(n) = h1(n) ⋆h2(n) = d(n), and use the product property.
H1(z−1) =
∞

n=0
h1(n)z−n =
5
1 −0.5z−1 −
4
1 −0.4z−1 =
1
1 −0.9z−1 + 0.2z−2
H(z−1) =
∞

n=0
h(n)z−n =
∞

n=0
[h1(n) ⋆h2(n)]z−n = H1(z−1)H2(z−1) = 1
Therefore,
H2(z−1) =
1
H1(z−1)] = 1 −0.9z−1 + 0.2z−2
h2(n) = d(n) −0.9d(n −1) + 0.2d(n −1)
Veriﬁcation:
h1(n) ⋆h2(n) = h1(n) −0.9h1(n −1) + 0.2h1(n −1) =

1
n = 0
0
elsewhere

Signals and Systems
789
Chapter Problems
6. In an LTI system x(n) is the input and h(n) is the unit-sample response. Find and sketch the output y(n) for the
following cases:
Input
Unit-Sample Response
x(n) = {1, 1, 1
↑, 1, 1}
and
h(n) = {1, 1, 1
↑, 1, 1}
x(n) = {1
↑, 1, 1}
and
h(n) = {1
↑, 1, 1}
x(n) = {1
↑, 2, 3, 2, 1}
and
h(n) = {1
↑, 2, 3, 2, 1}
x(n) = {1
↑, 1, 1, 1, 1}
and
h(n) = {1
↑, −1}
7. Repeat problem 6 for the following cases:
Input
Unit-Sample Response
x(n) = cos πn
6

u(n)
and
h(n) = {1
↑, −1}
x(n) = cos πn
6

and
h(n) = {1
↑, −1}
x(n) = cos πn
2

and
h(n) = {0.5
↑, 0.5}
x(n) = cos n
2

and
h(n) = {0.5
↑, 0, −0.5}
8. Repeat problem 6 for the following cases:
Input
Unit-Sample Response
x(n) = {1
↑, 2, 1}
and
h(n) = {1
↑, −0.5, 1}
x(n) = {1
↑, 1, 1}
and
h(n) = {1, 0
↑, 1}
x(n) = {1
↑, 1, 1}
and
h(n) = {1
↑, 0, 1}
x(n) = {1
↑, 2, 3, 2, 1}
and
h(n) = {1
↑, 0, 1}
9. Repeat problem 6 for the following cases:
Input
Unit-Sample Response
x(n) = cos πn
6

u(n)
and
h(n) = {1
↑, −1, 1}
x(n) = cos πn
6

and
h(n) = {1
↑, −1, 1}
x(n) = cos πn
2

and
h(n) = {1
↑, 2, 1}
x(n) = 1 + cos n
2

and
h(n) = {1
↑, 2, 1}

790
CHAPTER 13
Discrete Convolution
10. The unit-sample response of an LTI system is h(n) = {1, 2, 3
↑, 2, 1}. Find y(n) = x(n) ⋆h(n) for the following
inputs.
a. x(n) = {1
↑, 1, 1, 1, 1, 1, 1}
b. x(n) = {1
↑, 0, 1, 0, 1, 0, 1, 0, 1}
c. x(n) = {1
↑, −1, 1, −1, 1, −1, 1}
d. x(n) = {1
↑, 0, −1, 0, −1, 0, −1, 0, 1}
e. x(n) = {1
↑, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1}
f. x(n) = {1
↑, 0, 0, −1, 0, 0, 1, 0, 0, −1, 0, 0, 1}
g. x(n) = {1
↑, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1}
h. x(n) = {1
↑, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1}
i. x(n) = {1
↑, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1}
11. In an LTI system x(n) is the input and h(n) is the unit-sample response. Find and sketch the output y(n) for the
following cases:
Input
Unit-Sample Response
x(n) = 0.3nu(n)
and
h(n) = 0.4nu(n)
x(n) = 0.5nu(n)
and
h(n) = 0.6nu(n)
x(n) = 0.5|n|
and
h(n) = 0.6nu(n)
12. Repeat problem 11 for the following cases:
Input
Unit-Sample Response
x(n) = 2[u(n) −u(n −11)]
and
h(n) = 0.5nu(n)
x(n) = 2[u(n) −u(n −11)]
and
h(n) = (−0.5)nu(n)
x(n) = u(n) −u(n −5)
and
h(n) = 0.5|n|u(n)
x(n) = u(n) −u(n −5)
and
h(n) = (−0.5)|n|u(n)
13. Using the convolution properties show that
a. h(n) ⋆d(n) = h(n)
b. h(n) ⋆d(n −k) = h(n −k)
c. h(n) ⋆[d(n −k) + d(n −ℓ] = h(n −k) + h(n −ℓ)
d. h(n) ⋆
k2

ℓ=k1
d(n −ℓ) =
k2

ℓ=k1
h(n −ℓ)
where n, k, k1, k2, and ℓare all integers.

Signals and Systems
791
14. First show that
a. d(n −k) ⋆h(n) = h(n −k)
b. [x(k)d(n −k)] ⋆h(n) = x(k)h(n −k)
Then, using the above results, derive the convolution sum
x(n) ⋆h(n) =
∞

k=−∞
x(k)h(n −k)
15. A continuous-time analog signal x(t) = cos 500πt + cos 200πt is sampled at the rate of 1,000 samples per second.
a. Find x(n).
b. The resulting discrete signal x(n) is passed through a ﬁlter with unit-sample response h(n) = {1, 2, 3
↑, 2, 1}.
Find the output y(n) and its analog reconstruction y(t).
16. A discrete-time signal x(n) = 1+cos(ω0n) passes through a linear ﬁlter with unit-sample response h(n) = {1
↑, 1
2, 1}.
Find the output of the ﬁlter. For what value of ω0 will the output be zero?
17. An input x(n) = {1
↑, 1, 1, 1} passes through the following two ﬁlters.
h1(n) =

0.81n,
0 ≤n ≤2
0,
otherwise
and h2(n) =

0.9n,
0 ≤n ≤5
0,
otherwise
Find the outputs. What can you deduce about y2(n), given y1(n)?
18. Two groups of LTI systems are speciﬁed in the following table by their unit-sample responses. By pairing members
of the two groups, determine which pair can be inverse systems.
Group 1
Group 2
ha(n) = u(n)
h1(n) = d(n)
hb(n) = 0.5u(n) + 0.5u(n −2)
h2(n) = d(n) −d(n −1)
hc(n) = [1 −(−1)n
3 ]u(n) −1
3d(n)
h3(n) = 0.5d(n) −0.5d(n −2)
19. Given h(n) = {1
↑, 2, 3, 2, 1}, ﬁnd y(n) = x(n) ⋆h(n) for each x(n) given below.
a. Four unit samples spaced by seven zero samples,
x(n) = d(n) + d(n −8) + d(n −16) + d(n −24) =
3

k=0
d(n −8k).
b. Four unit samples spaced by N zero samples,
x(n) = d(n) + d(n −N) + d(n −2N) + d(n −3N) =
3

k=0
d(n −kN).

792
CHAPTER 13
Discrete Convolution
c. (ℓ+ 1) unit samples spaced by N zero samples,
x(n) = d(n) + d(n −N) + d(n −2N) + · · · + d(n −ℓN) =
ℓ

k=0
d(n −kN)
In each case compute average and total powers in the output.
20. In an LTI system h(n) = {−1
↑, 0, 2, 3, 4, 3, 2, 0, −1} and the input is a periodic rectangular pulse train with period
N and pulse width M. Find and plot y(n) = x(n) ⋆h(n) for the following cases.
a. N = 12,
M = 1,
x(n) =

 1,
n = 0
0,
1 ≤n ≤11
, deﬁned for 1 period
b. N = 8,
M = 1,
x(n) =

1,
n = 0
0,
1 ≤n ≤7
, deﬁned for 1 period
c. N = 6,
M = 1,
x(n) =

 1,
n = 0
0,
1 ≤n ≤5
, deﬁned for 1 period
d. N = 12,
M = 2,
x(n) =

 1,
n = 0, 1
0,
2 ≤n ≤11
, deﬁned for 1 period
e. N = 8,
M = 2,
x(n) =

 1,
n = 0, 1
0,
2 ≤n ≤7
, deﬁned for 1 period
f. N = 6,
M = 2,
x(n) =

 1,
n = 0, 1
0,
2 ≤n ≤5
, deﬁned for 1 period
13.11
Project: Deconvolution and Inverse Systems
Introduction and Summary
This project illustrates simple cases of signal recovery through the concept of deconvolution and inverse systems. It is
designed around the discussion in sections 13.8 and 13.9. It contains three procedures, the ﬁrst two of which are theoretical
(with possible applications). The third procedure simulates experiments in parallel with the theory. Effects of deviations
from theoretical requirements are explored qualitatively by visual displays in simulation. Such deviations can also be
quantitatively measured.
Procedure 1. A Thought Experiment in Deconvolution
Consider a hypothetical earth observation satellite that uses a digital camera with a pixel resolution of 100 × 100 m. This
means that the output at any moment of each charged coupled device (CCD element or pixel) is a voltage proportional
to the average of light intensity within the 100 × 100 meters square ﬁeld of view (to be called the receptive ﬁeld in this
procedure). If the camera were stationary with respect to the earth, the above resolution would correspond to a spatial
sampling rate of every 100 meters, and the averaging property of the CCD element would result in a permanent loss of
information below the speciﬁed resolution. In this procedure you will explore to see if by sweeping the camera over the
ﬁeld of view and taking overlapping pictures such that the consecutive receptive ﬁelds of each pixel overlap, one may
increase the resolution of the picture by deconvolution.

Signals and Systems
793
For simplicity, let us consider a camera containing a row of CCD elements with a spatial resolution of
X0 meters. The camera sweeps its footprint at a speed of ℓmeters per second in a direction perpendicular to its CCD
row and takes consecutive pictures every T seconds such that the distance X0 is swept by M pictures. The output of the
CCD row is called y(n). It is the average of light intensity in M neighboring subpixels. In summary, let the light intensity
within a subpixel be x(n) and a CCD element at each instance see M subpixels. Then, y(n) = x(n) ⋆h(n). We want to
recover x(n) from y(n).
Let h(n) = {1, 1
↑, 1}. Given y(n) and h(n), we may ﬁnd x(n), the light intensity within a subpixel. Following the
deconvolution process of section 13.8, obtain the input x(n) which produces the output y(n) = x(n) ⋆h(n) given below:
a. y(n) = {1
↑, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 2, 1, 1}
b. y(n) = {1
↑, 1, −1, 1, 2, 6, 4, 3, 0, −3, −3, −1, 4, 8, 8, 8, 3, 0, −3, −2}
Procedure 2. Inverse System, Signal Recovery, Deblurring
A digital camera takes a picture of a one-dimensional object described by x(n) = {x0
↑
, x1, x2, x3, x4, · · · , xN} where xk is
the sample average light intensity in the kth element. If the object were stationary, each sample in x(n) would map into a
single CCD element in the digital image. However, the object is moving to the right while the camera aperture is open.
As a result, M samples in x(n) pass in front of a CCD element which senses and registers their total average, causing
the picture to become blurred. The operation may be modeled by a digital ﬁlter with unit-sample response h(n) which
convolves with the input x(n) to produce y(n) = x(n) ⋆h(n) on the CCD array.
a. Assuming uniform motion and M = 3, show that h(n) = {1
↑, 1, 1}. Then ﬁnd camera outputs y1(n) and y2(n)
corresponding to (i) x1(n) = {1
↑, 1, 1, 1, 1} and (ii) x2(n) = {1
↑, 2, 1}, respectively.
b. Find the unit-sample response g(n) of an inverse system that would cancel the effect of the above h(n). The inverse
operation should satisfy the following equation x(n) = y(n) ⋆g(n). Proceed as follows:
(i) As a starting point, show that g(n) = {1
↑, −1, 0, 1, −1, 0, 1, −1, 0, 1, −1, 0 · · ·} inverts the output y1(n) =
{1
↑, 2, 3, 3, 3, 2, 1} to the input x1(n) = {1
↑, 1, 1, 1, 1}.
(ii) As a second test, apply the above g(n) to y2(n) to verify its inverse property.
(iii) Construct a new set of input-output pairs and test their inversion using the above g(n).
(iv) Derive the above g(n) by reverse computation of the convolution operation. However, this is a tedious process.
One may develop easier methods of ﬁnding inverse systems by using the z-transform (Chapter 15).
Procedure 3. Simulation and Display by Computer
In this procedure you will simulate the passage of discrete-time signals through a digital ﬁlter. You will then examine the
inverse of ﬁltering operation in order to recover the signal from the ﬁlter’s output. The unit-sample response of the ﬁlter
is h(n) = anu(n), a < 1. The inverse ﬁlter is g(n) = d(n) −ad(n −1). The following program convolves x(n) with a
truncated h(n) to ﬁnd y(n). It then convolves y(n) with g(n) to obtain the output z(n), to be compared with x(n). For a
quick and qualitative comparison of x and z, visual displays of x, y, and z can be provided through the Matlab command
image, as shown in the programs below.
a. Run the following program, analyze it, and examine the error between x(n) and z(n).
s=[1 2]; e=[0 0]; x=[e s e]; % Input
a=.8; k=2; n=1:k; h=a.√n;
% Filter
y=conv(h,x);
for i=2:length(y);
z(i)=y(i)-a*y(i-1);
end

794
CHAPTER 13
Discrete Convolution
mx=max(x); my=max(y); mz=max(z);
p=zeros(length(z)-length(x));
pad=p(1,:);
xpad=[x pad];
xyz=[xpad/mx; y/my; z/mz];
image(50*xyz)
b. In the above program, substitute [e s s e] for x and repeat part a. Then repeat with k = 5.
c. Repeat for the set of parameters in the table below and enter your brief comments in the last column.
Filter Length
Input
Comments on the Output
k = 5
x = [e s s s s e]
k = 10
x = [e s s s s e]
k = 10
x = [e s s s s s s e]
k = 15
x = [e s s s s s s e]
k = 20
x = [e s s s s s s s s e]
d. Replace the ﬁrst line in the program given in (a) by the following:
s=[1 2 3 4 5 ]; e=[0 0 0 0 ]; x=[e s s s s s e];
Each image created by the program is composed of three horizontal segments made of vertical color bands. They
represent three discrete signals. Each signal is a one-dimensional ﬁnite sequence x(n). Signal’s value is shown by
color. Horizontal axis is the discrete variable n. The upper segment in each ﬁgure visualizes the input to the FIR ﬁlter
speciﬁedbytheprogram.Theﬁlterisa20-tapFIRﬁlterwiththeunit-sampleresponse h(n) = 0.8n, n = 0, 1 · · · , 19.
Filter’s output is visualized on the middle segment. The signal is recovered from ﬁlter’s output by deconvolution
and is visualized on the lower segment. From a qualitative comparison of the upper segment with the lower segment
in each example one may conclude a satisfactory signal recovery operation or not. Run the program and comment
on the inverse output as an estimate of the initial input. Experiment with different lengths for the signal and ﬁlter.
Experiment with different values for the ﬁlter’s time constant. Create two ﬁgures to be called Figure A and B (not
shown here). The input x(n) for Figure A is
s=[1 2]; e=[0 0]; x=[e e s s s s s s s s s s s s s s s e e];
and for Figure B,
s=[1 2 3 4 5 ]; e=[0 0 0 0 ]; x=[e s s s s s e];
The ﬁgures you generate with the above parameters demonstrate possible signal recovery from ﬁlter’s output by
deconvolution. Comment on their performance.
e. Thefollowingprogramcreatestwo-dimensionalsignals.Analyzeandrunit.Passthesignalsthroughone-dimensional
ﬁlters such as those introduced in a, followed by the appropriate inverse ﬁlters, and compare the output with the
original signals.
m=50; n=1:m;
for i=1:2;
for j=1:m;
x(i,j)=n(j);
end
end
for i=3:4;
for j=1:m;
x(i,j)=m-n(j);

Signals and Systems
795
end
end
%
for i=1:2;
for j=1:m;
y(i,j)=(m+n(j))/2;
end
end
for i=3:4;
for j=1:m;
y(i,j)=m-n(j)/2;
end
end
figure(1); image(x)
figure(2); image(y)
xh=[x x x x]; yh=[y y y y];
figure(3); image(xh)
figure(4); image(yh)
figure(5); image([xh; xh; xh])
figure(6); image([yh; yh; yh])
Conclusions
Summarize your observations from each procedure. Combine your conclusions for the design of a satisfactory inverse
system.

Chapter14
LTI Difference
Equations
Contents
Introduction and Summary
797
14.1
What Is a Difference Equation?
798
14.2
Numerical Solution
799
14.3
Analytic Solution in the n-Domain
800
14.4
The Homogeneous Solution
801
14.5
The Particular Solution
802
14.6
The Total Solution
803
14.7
Special Cases, Repeated Roots
804
14.8
Properties of LTI Difference Equations
805
14.9
Response to zn
805
14.10
Response to the Complex Exponentials and Sinusoids
805
14.11
Unit-Step Response, g(n)
806
14.12
Unit-Sample Response, h(n)
807
14.13
Relation Between h(n) and g(n)
808
14.14
Use of Superposition
809
14.15
Zero-Input and Zero-State Responses
811
14.16
A Nonlinear Time-Varying Difference Equation
812
14.17
Problems
813
14.18
Project: Low-Pass Filtering by Difference Equation
825
Introduction and Summary
The input-output description of a discrete-time LTI system in the time domain is almost
always given by a linear difference equation with constant coefﬁcients (to be called
the LTI difference equation). The analytic method for those equations follows the same
797

798
CHAPTER 14
LTI Difference Equations
approach used for continuous-time LTI differential equations. In that approach we rec-
ognized the solution to be the sum of the particular solution (also called the forced
response, reﬂecting the effect of the input) and the homogeneous solution (also called
the natural response, made of the system’s natural frequencies and reﬂecting its initial
conditions). The role of the homogeneous solution was interpreted as accommodating
the initial conditions. Similar parallels are observed in the solution of difference equa-
tions. After the solution methods are discussed, the chapter considers inputs of common
interest such as the power, exponential, sinusoidal, unit-sample, and unit-step functions.
It also introduces, informally and independent of the frequency domain, the concept of a
system function as a scale factor that functions as the common thread relating the above
responses.
14.1
What Is a Difference Equation?
A difference equation is a relationship between present and past values of two discrete-
time signals x(n) and y(n). Most linear time-invariant discrete-time systems are de-
scribed by a linear difference equation with constant coefﬁcients
y(n) + a1y(n −1) · · · + aN y(n −N) = b0x(n) + b1x(n −1) · · · + bMx(n −M)
The equation is also written in the following two forms:
N

k=0
ak y(n −k) =
M

k=0
bkx(n −k)
y(n) =
M

k=0
bkx(n −k) −
N

k=1
ak y(n −k)
where x(n) is the input, y(n) is the output, and ak and bk are constants (with a0 = 1).
The above difference equation is of order N and is recursive. It may be realized by an
interconnection of unit delays, gains, and adders. If coefﬁcients ak, k = 1, 2, . . . , are all
zero, then
y(n) =
M

k=0
bkx(n −k)
and the equation is nonrecursive. For further details and examples see sections 12.4 and
12.6 in Chapter 12.
Solution Methods
To ﬁnd y(n), one needs to know all the past values of x(n), or know x(n) starting at a
given point plus the boundary conditions of y(n). In either case, the difference equation
may be solved through one of the following ways:
1.
Numerical method.
2.
Analytical method in the n-domain.

Signals and Systems
799
3.
Convolution method.
4.
z-transform method.
5.
Fourier transform method.
Here we will discuss solutions by the numerical and n-domain analytical meth-
ods. (Convolution, z-transform, and Fourier transform methods are discussed under the
broader topic of LTI systems, and apply to the difference equation as well.)
14.2
Numerical Solution
In this method, y(n) is calculated from the weighted sums of its own past and the input’s
present and past values:
y(n) = −
N

k=1
ak y(n −k) +
M

k=0
bkx(n −k)
Calculation is repeated iteratively for the desired range of n. The method is computation-
ally slow and the solution is not in closed form. However, it is applicable to nonlinear
and time-varying difference equations and when input data is given in the form of an
array of numbers.
Example
14.1
Response to unit sample
Using the numerical method ﬁnd the unit-sample response, h(n), of the difference
equation y(n) + 2y(n −1) = d(n).
Solution
The response at time n is y(n) = −2y(n −1)+d(n), which is the sum of −2y(n −1)
and d(n). We form the set of arrays shown below to calculate the above sum for
each n, incrementing n and iterating the calculation.
n
d(n)
−2y(n −1)
y(n) = d(n) −2y(n −1)
−2
0
0
0
−1
0
0
0
0
1
0
1
1
0
−2
−2
2
0
4
4
3
0
−8
−8
4
0
16
16
5
0
−32
−32
· · ·
· · ·
· · ·
· · ·
[The closed-form solution of the above difference equation found by the analytic
method in Example 14.3 is h(n) = (−2)nu(n).]

800
CHAPTER 14
LTI Difference Equations
Example
14.2
Response to unit step
Using the numerical method ﬁnd y(n) given
y(n) −2y(n −1) −y(n −2) = 3x(n) + 5x(n −1) and x(n) = u(n)
Solution
The solution is called the unit-step response of the system represented by the above
difference equation. It may be written as
y(n) = 2y(n −1) + y(n −2) + 3u(n) + 5u(n −1)
We form the set of arrays shown below to calculate the above sum for each n, incre-
menting n and iterating the calculation.
n
3u(n)
+5u(n −1)
+y(n −2)
+2y(n −1)
= y(n)
−2
0
0
0
0
0
−1
0
0
0
0
0
0
3
0
0
0
3
1
3
5
0
6
14
2
3
5
3
28
39
3
3
5
14
78
100
4
3
5
39
200
247
5
3
5
100
494
602
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
The closed-form solution of the above difference equation is found by the analytic
method in Example 14.8. The complete solution is
y(n) =

7.39(2.414)n −0.39(−0.414)n −4

u(n)
Note: The numerical method could be used, as easily, to solve nonlinear or time-
varying equations. See section 14.16 for an example.
14.3
Analytic Solution in the n-Domain
Consider the N-th order linear difference equation with constant coefﬁcients
y(n) + a1y(n −1) + · · · + aN y(n −N) = f (n), n ≥0
where f (n) represents the total contribution from x(n) and its derivatives and is called
the forcing function. The objective is to ﬁnd y(n) for n ≥0 so that (i) y(n) satisﬁes the
difference equation and (ii) y(n) and its past n −1 values are equal to a set of prescribed

Signals and Systems
801
initial conditions. The total solution is written as the sum of two parts:
y(n) = yh(n) + yp(n)
where yh(n) is the homogeneous solution and yp(n) is the particular solution. The ra-
tionale behind the above solution is similar to what was discussed in the case of linear
constant-coefﬁcient differential equations (see Chapter 5). The particular solution satis-
ﬁes the difference equation, but by itself does not necessarily meet the initial boundary
conditions. The homogeneous solution is the solution of the equation with no input. It
complements the particular solution in meeting the boundary conditions.
14.4
The Homogeneous Solution
The difference equation with a zero input
N

k=0
ak y(n −k) = 0
is called the homogeneous equation. One solution for the above equation is rn, where r
is found by substitution:
N−1

k=0
ak y(n −k) =
N

k=0
akr(n−k) = rn
N

k=0
akr−k = 0
For rn to be a solution of the homogeneous equation, r should be a solution of the
equation
N

k=0
akr−k = 0
which is called the characteristic equation. The characteristic equation has N roots ri,
i = 1, 2, . . . , N. Each term rn
i can satisfy the homogeneous equation by itself. However,
for the initial boundary conditions to be met, one needs all possible solutions in the form
of
yh(n) =
N

i=1
Cirn
i
CoefﬁcientsCi mustbesettocertainvaluessothatthetotalsolutionsatisﬁestheboundary
conditions.
Example
14.3
Find the unit-sample response, h(n), of the difference equation y(n) + 2y(n −1) =
d(n).
Solution
Assuming a causal system, we note that y(n) = 0, n < 0. The characteristic equation
is r + 2 = 0 with a root at r = −2. The homogeneous solution is yh(n) = C(−2)n.

802
CHAPTER 14
LTI Difference Equations
The input for n > 0 is zero and, therefore, the particular solution for n > 0 is zero.
The total solution is y(n) = yh(n) = C(−2)n,
n > 0. To determine C, we need
y(1), which is found from the difference equation.
y(n) = d(n) −2y(n −1)
y(0) = 1 −2y(−1) = 1
y(1) = 0 −2y(0) = −2
Substituting the above value of y(1) in the total solution at n = 1, we ﬁnd C = 1.
Combining the above results we ﬁnd the unit-sample response of the system to be
h(n) = (−2)nu(n).
Observation
By using a less rigorous argument we ﬁnd y(n) = yh(n) = C(−2)n,
n ≥0,
with the initial condition y(0) = x(0) −2y(−1) = 1, which yields C = 1 and
h(n) = (−2)nu(n).
14.5
The Particular Solution
The particular solution yp(n) is a function that satisﬁes the difference equation without
consideration for boundary value conditions. The main requirement is that
y(n) + a1y(n −1) · · · + aN y(n −N) = b0x(n) + b1x(n −1) · · · + bMx(n −M)
The form of the particular solution depends on the forcing function. Some commonly
encountered forcing functions and their corresponding particular solutions are given
in Table 14.1. The unspeciﬁed constants ki are found by substitution in the equation.
TABLE 14.1 A Short Table of Forcing Functions and Their Particular Solutions
Forcing Function x(n)
=⇒
Form of Particular Solution yp(n)
a
⇒
k
an [see note below]
⇒
kan
sin(ωn) or cos(ωn)
⇒
k1 sin(ωn) + k2 cos(ωn)
nm
⇒
k0 + k1n + · · · + kmnm
nman
⇒
an(k0 + k1n + · · · + kmnm)
an sin(ωn) or an cos(ωn)
⇒
an [k1 sin(ωn) + k2 cos(ωn)]
n sin(ωn) or n cos(ωn)
⇒
k1 sin(ωn) + k2 cos(ωn) + k3n sin(ωn) + k4n cos(ωn)
Note: If a is a root of the characteristic equation, repeated m times, the particular
solution is knman (see section 14.7).

Signals and Systems
803
14.6
The Total Solution
The total solution is
y(n) = yp(n) + yh(n) = yp(n) +
N

i=1
Cirn
i
The parameters Ci are to be chosen so that the above solution meets the boundary
conditions. For example, when x(n) is given for n ≥0, the conditions on y(n) for
n < 0 are y(−N), y(−N + 1), y(−N + 2), . . . , y(−1). From these conditions, and by
applying the difference equation, we derive values of y(n) for n ≥0; that is, y(0), y(1),
y(2), . . . , y(N −1). These values can then be inserted in the total solution to ﬁnd the
constants brought into it by the homogeneous part.
Example
14.4
Find the solution, to be called the unit-step response g(n), of the difference equation
given below.
y(n) + 2y(n −1) = u(n)
Solution
The homogeneous solution of this equation was found in Example 14.3 to be yh(n) =
C(−2)n. The particular solution for n ≥0 is a constant found by substitution yp(n) =
1/3. The total solution is
y(n) = yp(n) + yh(n) = [1/3 + C(−2)n]u(n)
with y(0) = 1 (found from the difference equation at n = 0). Applying the initial
condition we get
y(0) = 1/3 + C = 1, from which C = 2/3 and so g(n) = 1
3

1 + 2(−2)n
u(n)
Example
14.5
Given y(n) + 2y(n −1) = 1, n ≥0, and y(−1) = 1/3, ﬁnd y(n), n ≥0.
Solution
Using the results of Example 14.4, we have y(n) = 1/3 + C(−2)n, n ≥0, with
y(0) = 1/3 (found from the difference equation at n = 0). Applying the initial
condition we get
y(0) = 1/3 + C = 1/3, from which C = 0 and y(n) = 1
3 , n ≥0
Note that the homogeneous solution is zero.

804
CHAPTER 14
LTI Difference Equations
14.7
Special Cases, Repeated Roots
The previous sections contain the basic approach sufﬁcient to solve difference equations
in most typical cases. However, in special cases the method is extended or tailored to the
problem at hand. Some special cases are as follows:
1.
The characteristic equation has one or more repeated roots.
2.
The input is zn, exponential, or sinusoidal.
3.
The input contains power terms of roots of the characteristic equation.
Special treatment of the above cases often simpliﬁes the analysis as discussed below.
Repeated Roots
A root of an equation that is repeated p times is called a multiple root of the p-th order.
Contribution to the homogeneous solution from a multiple root rk of order p is
(Ck + Ck+1n + Ck+2n2 + · · · + Ck+p−1n p−1)rn
k
Example
14.6
Find y(n) given by the difference equation
y(n) −y(n −1) + 0.25y(n −2) = u(n)
Solution
The characteristic equation is r2 −r + 0.25 = 0. It has a repeated root at r1,2 = 0.5.
The homogeneous solution is yh(n) = (C1 + C2n)0.5n. The particular solution is
yp(n) = 4. The total solution is y(n) = {(C1 + C2n)0.5n + 4} u(n). To ﬁnd C1 and
C2 we need y(0) and y(1). From the difference equation and knowing y(−2) =
y(−1) = 0, we ﬁnd y(0) = 1 and y(1) = 1 + 1 = 2. Now, from the total solution
we have
 y(0) = C1 + 4
y(1) = 0.5(C1 + C2) + 4
which, after substituting for y(0) and y(1), translate into the following two equations:

C1 + 4 = 1
0.5(C1 + C2) + 4 = 2
From the above we ﬁnd C1 = −3 and C2 = −1. The complete solution is, therefore,
y(n) =

(C1 + C2n)0.5n + 4

u(n)
=

4 −(3 + n)0.5n
u(n)

Signals and Systems
805
14.8
Properties of LTI Difference Equations
A difference equation with constant real coefﬁcients represents the input-output relation-
ship of a linear time-invariant system. Some important properties of such an equation
are summarized in Table 14.2.
TABLE 14.2 Properties of LTI Difference Equations with Real
Coefficients
Property
Input, x(n)
⇒
Output, y(n)
1
Linearity
ax1(n) + bx2(n)
⇒
ay1(n) + by2(n)
2
Delay
x(n −n0)
⇒
y(n −n0)
3
Real
RE[x(n)]
⇒
RE[y(n)]
4
Imaginary
IM[x(n)]
⇒
IM[y(n)]
The above properties can be proved by substitution in the equation. Property 1 is
due to the lack of cross terms. Property 2 is due to the coefﬁcients of the equation being
constant. Properties 3 and 4 are due to the coefﬁcients being real-valued numbers.
14.9
Response to z n
The particular solution of the difference equation
y(n) + a1y(n −1) + · · · + aN y(n −N) = zn
is yp(n) = H × zn. In this situation, z is a number independent of n. See section 14.5.
The scale factor H is found by substituting H × zn into the equation.
H ×

1 + a1z−1 + · · · + aNzn−N
zn = zn
H =
1
1 + a1z−1 + · · · + aNzn−N
Regardlessofthetimeintervalduringwhichthedifferenceequationisvalid,theparticular
response is proportional to the input. If the interval is inﬁnite (steady-state condition), the
total response is made of the particular response only and the total solution is proportional
to the input. The proportionality factor depends on z and is shown by H. This is of special
interest in that zn plays the role of an Eigenfunction of the difference equation.
14.10
Response to the Complex Exponentials
and Sinusoids
Complex Exponential Inputs
The solution of the difference equation
y(n) + a1y(n −1) · · · + aN y(n −N) = e jωn

806
CHAPTER 14
LTI Difference Equations
is He jωn. The scale factor H is found by substitution
H =
1
1 + a1e−jω + · · · + aNe−jωN
The response is proportional to the input. The proportionality factor is a complex
number H, which depends on ω. Note that
H(ω) = H(z)

z=e jω
where H(z) was found in section 14.9. In polar form,
H(ω) = |H(ω)|e jθ
where |H(ω)| is the magnitude and θ = ̸ H(ω) is the phase.
Sinusoidal Inputs
The response to a sinusoidal input may be derived from the response to a complex
exponential input using the real property.
Input
⇒
Response
e jωn
⇒
H(ω)e jωn = |H(ω)|e j(ωn+θ)
cos ωn
⇒
|H(ω)| cos(ωn + θ)
The difference equation scales the magnitude of the sinusoidal input by the factor
|H(ω)| and adds θ = ̸ H(ω) to its phase angle. This is the steady-state response to a
sinusoidal input and is an important feature of LTI systems. Note that H(ω) was found
in section 14.10.
14.11
Unit-Step Response, g( n)
The response of the difference equation to a unit-step input is called the unit-step response
and shown by g(n).
y(n) + a1y(n −1) · · · + aN y(n −N) = u(n)
g(n) =

k0 +
N

k=1
Ckrn
k
	
u(n)
k0 =
1
1 + a1 + · · · + aN
The solution contains N unknown coefﬁcients Ck, k = 1, 2, . . . , N. These are found
from the N equations formed from the initial conditions g(0), g(1), g(2), . . . , g(N −1).
g(0) = k0 +
N

k=1
Ck

Signals and Systems
807
g(1) = k0 +
N

k=1
Ckrk
g(2) = k0 +
N

k=1
Ckr2
k
g(3) = k0 +
N

k=1
Ckr3
k
...
g(N −1) = k0 +
N

k=1
Ckr N−1
k
Values for g(0), g(1), g(2), . . . , g(N −1) are derived from
y(n) = −
N

k=1
ak y(n −k) + 1, n ≥0
using y(−1) = y(−2) = y(−3) = · · · = y(−N + 1) = 0 as shown below.
g(0) = 1
g(1) = 1 −a1y(0)
g(2) = 1 −a1y(0) −a2y(1)
g(3) = 1 −a1y(0) −a2y(1) −a3y(2)
...
g(N −1) = 1 −
N−1

k=1
ak y(k −1)
14.12
Unit-Sample Response, h( n)
The solution of the equation
y(n) + a1y(n −1) · · · + aN y(n −N) = d(n)
is called the unit-sample response. It is given by
h(n) =
N

k=1
Ckrn
k u(n)

808
CHAPTER 14
LTI Difference Equations
The solution contains N unknown coefﬁcients Ck, k = 1, 2, . . . , N. These are found
from the N equations formed from the initial conditions h(0), h(1), h(2), . . . , h(N −1).
These equations are
h(0) = 1 +
N

k=1
Ck
h(1) =
N

k=1
Ckrk
h(2) =
N

k=1
Ckr2
k
h(3) =
N

k=1
Ckr3
k
...
h(N −1) =
N

k=1
Ckr N−1
k
Values for h(0), h(1), h(2), . . . , h(N −1) are derived from
y(n) = −
N

k=1
ak y(n −k) + d(n)
using y(−1) = y(−2) = y(−3) · · · = y(−N + 1) = 0. Results are shown below.
h(0) = 1
h(1) = −a1y(0)
h(2) = −a1y(0) −a2y(1)
h(3) = −a1y(0) −a2y(1) −a3y(2)
...
h(N −1) = −
N−1

k=1
ak y(k −1)
14.13
Relation Between h(n) and g(n)
Based on the linearity and time-invariance properties, the unit-sample response h(n)
may be derived from the unit-step response and vice versa as summarized in Table 14.3.

Signals and Systems
809
TABLE 14.3 Relationship Between the Unit-Sample and Unit-Step Responses
From h(n) to g(n)
From g(n) to h(n)
Input
=⇒
Response
Input
=⇒Response
d(n)
⇒
h(n)
u(n)
⇒
g(n)
u(n) =
∞

k=0
d(n −k)
⇒
g(n) =
∞

k=0
h(n −k)
d(n) = u(n) −u(n −1)
⇒
h(n) = g(n) −g(n −1)
Example
14.7
In Examples 14.3 and 14.4 we found responses of y(n) + 2y(n −1) = x(n) to
unit-sample and unit-step inputs.
d(n)
⇒
h(n) = (−2)nu(n)
u(n)
⇒
g(n) = 1
3

1 + 2(−2)n
u(n)
Verify that g(n) −g(n −1) = h(n).
Solution
g(n) = 1
3

1 + 2(−2)n
u(n) = d(n) + 1
3

1 + 2(−2)n
u(n −1)
g(n −1) = 1
3

1 + 2(−2)n−1
u(n −1)
g(n) −g(n −1) = d(n) + 2
3

(−2)n −(−2)n−1
u(n −1) = d(n) + (−2)nu(n −1)
= (−2)nu(n) = h(n)
14.14
Use of Superposition
In sections 14.11 and 14.12 we found the solution of the difference equation when the
right side of the equation was a unit step or unit sample. Now let us consider an LTI
system (to be called the total system) described by the difference equation
y(n) + a1y(n −1) · · · + aN y(n −N) = b0x(n) + b1x(n −1) · · · + bMx(n −M)
To ﬁnd the response of the above system to x(n) we ﬁrst solve for the following sub-
system:
w(n) + a1w(n −1) · · · + aNw(n −N) = x(n)
We then use the linearity and time-invariance properties of the system to ﬁnd its response
in terms of w(n).
y(n) = b0w(n) + b1w(n −1) · · · + bMw(n −M)

810
CHAPTER 14
LTI Difference Equations
As an example, let the unit-step response of the subsystem be g(n) (as found in
section 14.11). The response of the total system to a unit-step input x(n) = u(n) is
then
y(n) = b0g(n) + b1g(n −1) · · · + bMg(n −M)
A similar approach may be employed to ﬁnd the unit-sample response of the total system
as a linear combination of the response of the subsystem to a unit-sample input.
Example
14.8
a.
Find the solution to the equation y(n) −2y(n −1) −y(n −2) = u(n) and call
it g(n).
b.
Now consider the difference equation y(n) −2y(n −1) −y(n −2) = 3x(n) +
5x(n −1), x(n) = u(n). The solution to this equation (derived by direct
method in solved problem 4 at the end of the chapter) is
y(n) = [7.3891(2.4142)n −0.3891(−0.4142)n −4]u(n)
Verify that the above solution is equal to 3g(n) + 5g(n −1), where g(n) is the
unit-step response of part a.
Solution
a.
The step response of the equation y(n) −2y(n −1) −y(n −2) = u(n) is
g(n) =

−1
2 + C1αn + C2βn

u(n) where α = 1 +
√
2 and β = 1 −
√
2.
C1 and C2 are found by applying the initial conditions y(0) and y(1), which are
found from the difference equation:
y(0) = 2y(−1) + y(−2) + 1 = 1
y(1) = 2y(0) + y(−1) + 1 = 3
Applying the initial conditions we get
C1,2 = 3 ± 2
√
2
4
b.
For n ≥1 we have
3g(n) + 5g(n −1) = −3
2 + 3C1αn + 3C2βn
−5
2 + 5C1α(n−1) + 5C2β(n−1)
= −4 + 36 + 25
√
2
4
(1 +
√
2)(n−1)
+36 −25
√
2
4
(1 −
√
2)(n−1)
= −4 + 7.3891(2.412)n −0.3891(−0.4142)n, n ≥1

Signals and Systems
811
The above expression also provides a correct value for 3g(0) + 5g(−1).
Therefore,
3g(n) + 5g(n −1) = [−4 + 7.3891(2.412)n −0.3891(−0.4142)n]u(n)
This is the same solution obtained directly in solved problem 4 at the end of the
chapter.
14.15
Zero-Input and Zero-State Responses
The superposition property (a consequence of linearity and time invariance) may be
applied to combine the contributions to the response from the initial state (with zero
input) and the input (with zero initial state). These are called zero-input and zero-state
responses. Therefore, the difference equation
y(n) + a1y(n −1) · · · + aN y(n −N) = b0x(n) + b1x(n −1) · · ·
+bMx(n −M), n ≥0
with nonzero initial conditions y(0), y(1), . . . y(N −1) can be divided into two equations
(Zero-input:)
y(n) + a1y(n −1) · · · + aN y(n −N) = 0, y(0), y(1), . . . y(N −1)
(Zero-state:)
y(n) + a1y(n −1) · · · + aN y(n −N) = [b0x(n) + b1x(n −1) · · ·
+bMx(n −M)]u(n)
Superposition of the solutions of the above two equations produces the complete solution
to the original equation.
Example
14.9
Given y(n) + 2y(n −1) = 1, n ≥0, and y(−1) = 1/3, ﬁnd the zero-input and
zero-state responses for n ≥0 and show that their superposition results in the total
response obtained in Example 14.5.
Solution
Zero-input response. The zero-input response is found from
y(n) + 2y(n −1) = 0, n ≥0, and y(−1) = 1/3
The solution is y(n) = C(−2)n, n ≥0, with y(0) = −2/3 (found from the difference
equation at n = 0). Applying the initial condition, we get C = −2/3 and
y1(n) = −(2/3)(−2)n, n ≥0 (zero-input response)

812
CHAPTER 14
LTI Difference Equations
Zero-state response. The zero-state response is found from
y(n) + 2y(n −1) = 1, n ≥0, and y(−1) = 0
The solution is the unit-step response already found in Example 14.4.
y2(n) = 1
3

1 + 2(−2)n
, n ≥0 (zero-state response)
The total solution is
y(n) = y1(n) + y2(n) = −(2/3)(−2)n + 1/3 + (2/3)(−2)n = 1/3, n ≥0
The total solution is the same as the answer found in Example 14.5.
14.16
A Nonlinear Time-Varying
Difference Equation
When an exact and closed-form solution is not needed, the response of a difference
equation can be obtained by numerical methods. The method was illustrated for LTI
difference equations in section 14.2 and the components of the solution were associated
with the particular and homogeneous response. The method can be applied to nonlinear
and time-varying equations, more conveniently as analytical solutions for many such
equations are complex or don’t exist. The response obtained by step-by-step computation
may not explicitly reﬂect the various factors that inﬂuence the shape of the response, but
computation can be carried out for a desired length of the response and its accuracy. The
following is an example.
Example
14.10
Find y(n) given the equation
y(n) −0.1ny(n −1) + y2(n −2) = x(n) n ≥0, y(−1) = 1, y(−2) = 1
where x(n) is given by
x(n) = {1
↑, 2, −1.2, 0, 3, −3, 5, 0, −2, . . .}.
Solution
This is a nonlinear and time-varying equation. The nonlinearity is due to y2(n −2).
The term 0.1ny(n −1) makes the equation time varying. The response at time n is
computed from the sum
y(n) = x(n) −y2(n −2) + 0.1ny(n −1) n ≥0, y(−1) = 1, y(−2) = 1
We form the following set of arrays and calculate y(n) iteratively.

Signals and Systems
813
n
y(n −2)
y(n −1)
x(n)
−y 2(n −2) +0.1ny(n −1) = y(n) (comments)
−3
−
−
−
−
−
−
(not given)
−2
−
−
−
−
−
1
(given)
−1
−
1
−
−
−
1
(given)
0
1
1
1
−1
0
0
(computed)
1
1
0
2
−1
0
1
”
2
0
1
−1.2
0
0.2
−1
”
3
1
−1
0
−1
−0.3
−1.3
”
4
−1
−1.3
3
−1
−0.52
1.48
”
5
−1.3
1.48
−3
−1.69
0.74
−3.95
”
6
1.48
−3.95
5
−2.19
−2.37
0.44
”
7
−3.95
0.44
0
−15.6
0.31
−15.29
”
8
0.44
−15.29
−2
−0.19
−12.23
−14.42
”
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
14.17
Problems
Solved Problems
1. Find the homogeneous solution of the difference equation y(n) + 2y(n −1) = x(n).
Solution
The characteristic equation is r + 2 = 0, or r = −2. The homogeneous solution is yh(n) = C(−2)n. The constant
C is determined from the forcing function and y(n) speciﬁed at a given time.
2. Fibonacci numbers y(n) are described by the following equation:
y(n) = y(n −1) + y(n −2), n ≥0,
y(−1) = 1, y(−2) = 0
Find a closed-form expression for y(n), n ≥0.
Solution
The characteristic equation is r 2 −r −1 = 0, or r1,2 = 0.5(1 ±
√
5). The solution is made of the homogeneous part
only which is y(n) = A(r1)n + B(r2)n, n ≥0. The constants A and B are found from the initial conditions:
y(0) = y(−1) + y(−2) = 1 and y(1) = y(0) + y(−1) = 2
By applying the initial conditions we ﬁnd A, B, and y(n).

y(0) = A + B = 1
y(1) = 0.5(1 +
√
5)A + 0.5(1 −
√
5)B = 2
⇒

A = 0.5 + 0.3
√
5
B = 0.5 −0.3
√
5
y(n) =

5 + 3
√
5
10

1 +
√
5
2
n
+

5 −3
√
5
10

1 −
√
5
2
n
, n ≥0

814
CHAPTER 14
LTI Difference Equations
3. Find the complete solution of the difference equation
y(n) + 1.5y(n −1) + 0.5y(n −2) = (0.3)n, n ≥0, y(−1) = y(−2) = 0.
Solution
The characteristic equation is r 2 + 1.5r + 0.5 = 0. The roots are r1,2 = −1 and −0.5. The homogeneous solution is
yh(n) = C1(−1)n + C2(−0.5)n
The total solution is y(n) = yh(n) + yp(n), where yp(n) = k(0.3)n, n ≥0. To determine k we put yp(n) into the
equation. Therefore,
k(0.3)n + 1.5k(0.3)n−1 + 0.5k(0.3)n−2 = (0.3)n
k(0.3)2 + 1.5k(0.3) + 0.5k = (0.3)2
or k = 9/104. The total solution is
y(n) = C1(−1)n + C2(−0.5)n +
9
104(0.3)n, n ≥0
To determine C1 and C2, we need y(0) and y(1) which are found from applying the difference equation at n = 0
and n = 1 along with the given values for y(−2) = y(−1) = 0.
y(n) = (0.3)n −1.5y(n −1) −0.5y(n −2), n ≥0
y(0) = 1 −1.5y(−1) −0.5y(−2) = 1
y(1) = 0.3 −1.5y(0) −0.5y(−1) = −1.2
Substituting the above values for y(0) and y(1) in the total solution we ﬁnd
y(0) = C1 + C2 +
9
104 = 1
y(1) = −C1 −0.5C2 +
9
104(0.3) = −1.2
from which we obtain
C1 = 480
312 ≈1.5385 and C2 = −195
312 = −0.625
The total solution is, therefore,
y(n) =
1
312

480 × (−1)n −195 × (−0.5)n + 27 × (0.3)n
, n ≥0
4. Find y(n) given by y(n) −2y(n −1) −y(n −2) = 3x(n) + 5x(n −1), x(n) = u(n).
Solution
The homogeneous solution is yh(n) = C1r n
1 +C2r n
2 , where r1,2 = 1±
√
2 are the roots of the characteristic equation
r 2 −2r −1 = 0.
The particular solution is yp(n) = k0, n ≥1, where k0 = −4 (by substitution). The total solution is then
y(n) = C1(1 +
√
2)n + C2(1 −
√
2)n −4, n ≥0
where C1 and C2 are found by applying the initial conditions y(1) and y(2). Assuming a causal system, we have
y(−1) = y(−2) = 0. The values of y(1) and y(2) are then found from the difference equation
y(0) = 2y(−1) + y(−2) + 3x(0) + 5x(−1) = 0 + 0 + 3 + 0 = 3
y(1) = 2y(0) + y(−1) + 3x(1) + 5x(0) = 6 + 0 + 3 + 5 = 14
y(2) = 2y(1) + y(0) + 3x(2) + 5x(1) = 28 + 3 + 3 + 5 = 39

Signals and Systems
815
Applying the initial conditions we get
y(1) = C1(1 +
√
2) + C2(1 −
√
2) −4 = 14
y(2) = C1(1 +
√
2)2 + C2(1 −
√
2)2 −4 = 39
From the above we ﬁnd C1 = 7.3891 and C2 = −0.3891. The complete solution is
y(n) = 7.3891(2.4142)n −0.3891(−0.4142)n −4, n ≥1
Note that the above expression also provides a correct value for y(0). Therefore,
y(n) = [7.3891(2.4142)n −0.3891(−0.4142)n −4]u(n)
(Revisit this equation in Examples 14.2 and 14.8, and problem 34.)
5. The Chebyshev polynomial Cn(x) is an nth-order polynomial of the continuous variable x. It is the solution to the
following difference equation
cn+1(x) = 2xcn(x) −cn−1(x), n ≥1, c0 = 1, and c1 = x
Find a closed-form expression for Cn(x).
Hint: You may rewrite the equation in the familiar form
c(n + 1) = 2xc(n) −c(n −1), n ≥1, c(0) = 1, and c(1) = x
Solution
The characteristic equation is r 2 −2xr + 1 = 0, or r1,2 = x ±
√
x2 −1. The solution is made of the homogeneous
part only, which is c(n) = A(r1)n + B(r2)n, n ≥1. The constants A and B are found from the initial conditions.
The initial conditions to be used for ﬁnding A and B are c(0) = 1 and c(1) = x. By substitution we get
c(0) = A + B = 1
c(1) = A 
x +
√
x2 −1
+ B 
x −
√
x2 −1
= x
From the above we ﬁnd A = B = 1
2. The closed-form expression for the Chebyshev polynomials of order n is
cn(x) = 1
2

x +
√
x2 −1n + 
x −
√
x2 −1n
, n ≥0
The ﬁrst six Chebyshev polynomials computed from the above solution are the following:
n
Cn(x)
0
1
1
x
2
2x2 −1
3
4x3 −3x
4
8x4 −8x2 + 1
5
16x5 −20x3 + 5x
6. Find the complete solution of the difference equation y(n) + 2y(n −1) = x(n) for the following forcing functions:
a. x(n) = 2u(n)
b. x(n) = 3nu(n)
c. x(n) = n2u(n)

816
CHAPTER 14
LTI Difference Equations
d. x(n) = (3n + 2)u(n)
e. x(n) = (3n + 1)u(n)
f. x(n) = (n2 + 1)u(n)
Solution
The total solution is y(n) = yh(n) + yp(n), where yh(n) = C(−2)n was found in problem 1. yp(n) is a polynomial
in n whose coefﬁcients are found by inserting it in the difference equation. The constant C in the homogeneous
solution is then found from the boundary value y(0). From the difference equation, y(0) = x(0) −2y(−1). But,
y(−1) = 0. Therefore, the boundary condition to be used for ﬁnding C is y(0) = x(0).
a. yp(n) = k0. By plugging yp(n) = k0 into the equation we obtain k0 + 2k0 = 2, or k0 = 2/3. The total solution is
y(n) =

C(−2)n + 2
3

u(n)
The initial condition to be applied is y(0) = 2−2y(−1) = 2. The constant C is found from y(0) = C +2/3 = 2,
or C = 4/3. Therefore, the complete solution is
y(n) = 2
3

1 + 2(−2)n

u(n)
b. yp(n) = k1n + k0. After plugging yp(n) into the equation, we get k1 = 1 and k0 = 2/3. The total solution is
y(n) =

C(−2)n + n + 2
3

u(n)
with y(0) = 0. The constant C is found from y(0) = C + 2
3 = 0, or C = −2
3. The complete solution is
y(n) = 2
3

1 + 3
2n −(−2)n

u(n)
c. yp(n) = k2n2 + k1n + k0. After plugging yp(n) into the equation, we get k2 = 1/3, k1 = 4/9, and k0 = 2/27.
The total solution is
y(n) =

C(−2)n + 1
3n2 + 4
9n + 2
27

u(n)
with the boundary value y(0) = 0. The constant C is found from y(0) = C + 2/27 = 0, or C = −2/27. The
complete solution is
y(n) = 1
3

n2 + 4
3n + 2
9 −2
9(−2)n

u(n)
d. yp(n) = k1n + k0. By plugging this into the equation, we obtain k1 = 1 and k0 = 4/3. The total solution is
y(n) =

C(−2)n + n + 4
3

u(n)
and y(0) = 2. The constant C is found from y(0) = C + 4/3 = 2, or C = 2/3. The complete solution is
y(n) = 2
3

(−2)n + 3
2n + 2

u(n)
e. yp(n) = k1n + k0. By plugging this into the equation, we obtain k1 = 1 and k0 = 1. The total solution is
y(n) =

C(−2)n + n + 1

u(n)

Signals and Systems
817
with the boundary value y(0) = 1. The constant C is found from y(0) = C + 1 = 1, or C = 0. The complete
solution is
y(n) = (n + 1)u(n)
The complete solution is made up of the particular part only. The particular solution meets the boundary conditions
by itself and there is no need for a homogeneous part.
f. yp(n) = k2n2 + k1n + k0. By plugging this into the equation, we obtain k2 = 1/3, k1 = 4/9, and k0 = 11/27.
The total solution is
y(n) =

C(−2)n + 1
3n2 + 4
9n + 11
27

u(n)
with the boundary value y(0) = 1. The constant C is found from y(0) = C + 11/27 = 1, or C = 16/27. The
complete solution is
y(n) = 1
3

n2 + 4
3n + 11
9 + 16
9 (−2)n

u(n)
The solution to parts d, e, and f may also be found from the solution to parts a, b, and c using the linearity
property of the difference equation. The answers are summarized in the table below.
x(n)
⇒
y(n)
x1(n)
= 2u(n)
⇒
y1(n)
= 2
3 [1 + 2(−2)n] u(n)
x2(n)
= 3nu(n)
⇒
y2(n)
= 2
3

1 + 3
2n −(−2)n

u(n)
x3(n)
= n2u(n)
⇒
y3(n)
= 1
3

n2 + 4
3n + 2
9 −2
9(−2)n

u(n)
x4(n)
= x1(n) + x2(n)
⇒
y4(n)
= y1(n) + y2(n)
= (2 + 3n)u(n)
= 2
3 {1 + 2(−2)n} u(n) + 2
3

1 + 3
2n −(−2)n

u(n)
= 2
3

(−2)n + 3
2n + 2

u(n)
x5(n)
= 0.5x1(n) + x2(n)
⇒
y5(n)
= 0.5y1(n) + y2(n)
= (1 + 3n)u(n)
= 1
3 {1 + 2(−2)n} u(n) + 2
3

1 + 3
2n −(−2)n

u(n)
= (n + 1)u(n)
x6(n)
= 0.5x1(n) + x3(n)
⇒
y6(n)
= 0.5y1(n) + y3(n)
= (1 + n2)u(n)
= 1
3 {1 + 2(−2)n} u(n) + 1
3

n2 + 4
3n + 2
9 −2
9(−2)n

u(n)
= 1
3

n2 + 4
3n + 11
9 −16
9 (−2)n

u(n)
7. Find the complete solution of the difference equation
y(n) + 1.5y(n −1) + 0.5y(n −2) = x(n) for

818
CHAPTER 14
LTI Difference Equations
a. x(n) = 5, n > 0, y(0) = y(−1) = 1.
b. x(n) = 5, n > 0. What values of y(0) and y(−1) result in yh(n) = 0?
c. x(n) = (−0.5)n, n > 0, y(0) = y(−1) = 0.
Solution
The characteristic equation is r 2 + 1.5r + 0.5 = 0. The roots are r1,2 = −1, −0.5. The homogeneous solution is
yh(n) = C1(−1)n + C2(−0.5)n
The total solution is y(n) = yh(n) + yp(n), where yp(n) for each case is as derived below.
a. The particular solution is yp(n) = k0, where k0 is found by substitution
k0 + 1.5k0 + 0.5k0 = 5, k0 = 5
3
y(n) = C1(−1)n + C2(−0.5)n + 5
3, n > 0
To ﬁnd C1 and C2 we need y(1) and y(2). These are found from
y(1) = 5 −1.5y(0) −0.5y(−1) = −C1 −.5C2 + 5
3 = 3
y(2) = 5 −1.5y(1) −0.5y(0) = C1 + 0.25C2 + 5
3 = 0
from which we obtain
C1 = −2 and C2 = 4
3
The complete solution is, therefore,
y(n) = −2(−1)n + 4
3(−0.5)n + 5
3, n > 0
b. The particular solution is yp(n) = 5
3. For n > 0, it is desired that y(n) = yp(n) = 5/3. Values of y(0) and y(−1)
that produce such a solution are found from
y(1) = −1.5y(0) −0.5y(−1) + 5 = 5
3
y(2) = −1.5y(1) −0.5y(0) + 5 = 5
3
Hence, y(0) = y(−1) = 5/3. We now check the complete solution for these conditions. The total solution is
y(n) = C1(−1)n + C2(−0.5)n + 5
3, n > 0
C1 and C2 are found from y(1) and y(2).
y(1) = −C1 −.5C2 + 5
3 = 5
3 and y(2) = C1 + 0.25C2 + 5
3 = 5
3
from which we obtain C1 = C2 = 0. The complete solution is, therefore, y(n) = 5/3.
c. yp(n) = kn(−0.5)n. By plugging yp(n) into the equation, we get
kn(−0.5)n + 1.5k(n −1)(−0.5)n−1 + 0.5k(n −2)(−0.5)n−2 = (−0.5)n
or k = −1. The total solution is
y(n) = yh(n) + yp(n) = C1(−1)n + C2(−0.5)n −n(−0.5)n, n > 0

Signals and Systems
819
The boundary conditions are
y(1) = −1.5y(0) −0.5y(−1) −0.5 = −0.5
y(2) = −1.5y(1) −0.5y(0) + 0.25 = 1
from which we obtain
y(1) = −C1 −0.5C2 + 0.5 = −0.5
y(2) = C1 + 0.25C2 −0.5 = 1
resulting in C1 = 2 and C2 = −2. The complete solution is then
y(n) = 2(−1)n −(2 + n)(−.5)n, n > 0
In summary:
a. y(n) = −2(−1)n + 4
3(−0.5)n + 5
3, n > 0
b. y(n) = 5/3, n > 0
c. y(n) = 2(−1)n −(2 + n)(−0.5)n, n > 0
8. Find the solution of the equation y(n) −y(n −1) + .5y(n −2) = 0, n ≥0, y(−1) = y(−2) = 1.
Solution
The characteristic equation is r 2 −r + 0.5 = 0. The roots are
r1,2 = 0.5(1 ± j) =
√
2
2 e± j π
4
y(n) = yh(n) = C1r n
1 + C2r n
2 . Since r1 and r2 are complex conjugates of each. C1 and C2 must also be complex
conjugates then: C1,2 = Ce± jθ, where C and θ are real constants. The response may be written as
y(n) = C1r n
1 + C2r n
2 = Ce jθ
√
2
2
n
e j π
4 n + Ce−jθ
√
2
2
n
e−j π
4 n
= C
√
2
2
n 
e j( π
4 n+θ) + e−j( π
4 n+θ)
= 2C
√
2
2
n
cos(π
4 n + θ)
The boundary conditions are
y(0) = y(−1) −0.5y(−2) = 1 −0.5 = 0.5 and y(1) = y(0) −0.5y(−1) = 0.5 −0.5 = 0
The constants C and θ are found from the boundary conditions
y(0) = 2C cos θ = 0.5 and y(1) = C
√
2 cos(π
4 + θ) = 0
C =
√
2
4 and θ = π
4 . The complete solution is, therefore,
y(n) =
√
2
2
n+1
cos
π
4 (n + 1)

, n ≥0
9. An LTI system is represented by y(n) + y(n −1) −y(n −2) = x(n). Determine the initial conditions y(−1) and
y(−2) so that for x(n) = 1, n ≥0, the response becomes y(n) = k0. Then ﬁnd k0.

820
CHAPTER 14
LTI Difference Equations
Solution
It is desired that the response be made of the particular solution only; that is, y(n) = yp(n) = k0. By plugging
yp(n) into the equation, we get y(n) = 1. We need to ﬁnd y(−1) and y(−2) that produce such a condition. From
an examination of the difference equation for n ≥0 we observe that y(n) = −y(n −1) + y(n −2) + x(n) But,
y(n) = 1 and x(n) = 1. Therefore, y(n −2) = y(n −1).
By applying the above at n = 1 and n = 0, we ﬁnd, respectively, y(−1) = y(0) = 1 and y(−2) = y(−1) = 1.
These are the conditions required of y(n) before the arrival of the input x(n) = 1 at n = 0.
To check the validity of the above conditions, we ﬁnd the total solution and determine the constants in the
homogeneous solution. The homogeneous solution is yh(n) = C1r n
1 + C2r n
2 , where r1 and r2 are the roots of the
characteristic equation r 2 + r −1 = 0:
r1,2 = −1 ±
√
5
2
The particular solution was found to be yp(n) = 1 and the total response is then y(n) = C1(r1)n + C2(r2)n + 1,
n ≥0. The boundary conditions y(0) and y(1) are derived by applying the difference equation y(n) = −y(n −
1) + y(n −2) + x(n) at n = 0 and 1, resulting in y(0) = y(1) = 1. Applying these conditions to the total response
we ﬁnd C1 and C2 as shown below:
y(0) = C1 + C2 + 1 = 1 and y(1) = C1r1 + C2r2 + 1 = 1
C1 + C2 = 0 and C1r1 + C2r2 = 0
C1 = 0 and C2 = 0
10. The response of a ﬁfth-order linear time-invariant discrete system to a DC input is represented by the difference
equation
y(n) + a1y(n −1) + a2y(n −2) + a3y(n −3) + a4y(n −4) + a5y(n −5) = 1, n ≥0
Determine values of y(−1), y(−2), y(−3), y(−4), and y(−5) that produce y(n) = k0, n ≥0; that is, make the
homogeneous part of the solution zero.
Solution
The particular solution is
yp(n) = k0 =

5

i=1
ai
	−1
, (with a0 = 1)
To ﬁnd y(n), n = −1, −2, −3, −4, −5, we need ﬁve independent equations. From the difference equation we note
that
a1y(n −1) + a2y(n −2) + a3y(n −3) + a4y(n −4) + a5y(n −5) = 1 −y(n) = 1 −k0, n ≥0
By applying the above at n = 0, 1, 2, 3, and 4, we get
n = 0,
a1y(−1)
+a2y(−2)
+a3y(−3)
+a4y(−4)
+a5y(−5)
= 1 −k0
n = 1,
a1y(0)
+a2y(−1)
+a3y(−2)
+a4y(−3)
+a5y(−4)
= 1 −k0
n = 2,
a1y(1)
+a2y(0)
+a3y(−1)
+a4y(−2)
+a5y(−3)
= 1 −k0
n = 3,
a1y(2)
+a2y(1)
+a3y(0)
+a4y(−1)
+a5y(−2)
= 1 −k0
n = 4,
a1y(3)
+a2y(2)
+a3y(1)
+a4y(0)
+a5y(−1)
= 1 −k0
Substituting for y(0) = y(1) = y(2) = y(3) = y(4) = k0, we get
a1y(−1) + a2y(−2) + a3y(−3) + a4y(−4) + a5y(−5) = 1 −k0
a2y(−1) + a3y(−2) + a4y(−3) + a5y(−4) = 1 −k0(1 + a1)

Signals and Systems
821
a3y(−1) + a4y(−2) + a5y(−3) = 1 −k0(1 + a1 + a2)
a4y(−1) + a5y(−2) = 1 −k0(1 + a1 + a2 + a3)
a5y(−1) = 1 −k0(1 + a1 + a2 + a3 + a4)
The answers are, therefore,
y(−1) = 1
a5
[1 −k0(1 + a1 + a2 + a3 + a4)]
y(−2) = 1
a5
[1 −k0(1 + a1 + a2 + a3) −a4y(−1)]
y(−3) = 1
a5
[1 −k0(1 + a1 + a2) −a3y(−1) −a4y(−2)]
y(−4) = 1
a5
[1 −k0(1 + a1) −a2y(−1) −a3y(−2) −a4y(−3)]
y(−5) = 1
a5
[1 −k0 −a1y(−1) −a2y(−2) −a3y(−3) −a4y(−4)]
Chapter Problems
In the following problems all systems are causal unless speciﬁed otherwise.
11. Find the homogeneous part of the solution of the following equations:
a. y(n) ± 0.5y(n −1) = x(n)
b. y(n) ± 2y(n −1) = x(n)
c. y(n) −0.9y(n −1) + 0.2y(n −2) = x(n)
d. y(n) −y(n −1) + y(n −2) = x(n)
12. An LTI system is described by y(n) −0.5y(n −1) = x(n). Given x(n) = 0, n ≥0 ﬁnd y(n) for n ≥0 if it is
known that
a. y(−1) = 2
b. y(−1) = 1
13. Given the input x(n) = 0, n ≥0 to an LTI system it is desired that the output becomes y(n) = 0.5n for n ≥0.
a. Find a difference equation that describes the system.
b. Determine y(−1) which produces the desired output.
14. Find the solution of the following equations given y(−1) = 1.
a. y(n) + 0.3y(n −1) = 0, n ≥0
b. y(n) + 2y(n −1) = 0, n ≥0
15. Find the solution of the following equations given y(−1) = 1.
a. y(n) −0.3y(n −1) = 0, n ≥0
b. y(n) −2y(n −1) = 0, n ≥0
16. Find the solution of the following equations given y(−2) = y(−1) = 1.
a. y(n) −0.9y(n −1) + 0.2y(n −2) = 0, n ≥0
b. y(n) −y(n −1) + y(n −2) = 0, n ≥0
c. y(n) −y(n −1) + .5y(n −2) = 0, n ≥0

822
CHAPTER 14
LTI Difference Equations
17. Find the unit-sample response of the LTI systems given by
a. h(n) + 2h(n −1) = d(n)
b. h(n) + 0.3h(n −1) −0.4h(n −2) = d(n)
c. h(n) + 1.3h(n −1) + 0.4h(n −2) = d(n)
d. h(n) −h(n −1) + 0.89h(n −2) = d(n)
e. h(n) −0.2h(n −1) + 0.17h(n −2) = d(n)
18. Find y(n) given by y(n) −1.5y(n −1) + 0.5y(n −2) = 1, n > 0 and y(0) = y(−1) = 0.
19. Find y(n) given y(n) + 0.3y(n −1) −0.4y(n −2) = 9u(n).
20. The unit-sample response of an LTI system is
h(n) = 10
13

(0.5)n+1 −(−0.8)n+1
u(n)
Find its response to x(n) = 9u(n) by convolution. Compare with the answer found for problem 19.
21. The unit-step response, g(n), of an LTI system is related to its unit-sample response, h(n), by g(n)−g(n−1) = h(n).
Find the unit-step response of an LTI system given its unit-sample response
h(n) = [(0.5)n+1 −(−0.8)n+1]u(n)
Compare with the result of problem 20.
22. Find y(n) given
a. y(n) + 2y(n −1) = 2, n > 0, y(0) = 0
b. y(n) + 10y(n −1) = 10n, n ≥0, y(0) = 0
c. y(n) + 1.5y(n −1) + 0.5y(n −2) = 6u(n)
23. Find the solution of the equation y(n) + ay(n −1) = x(n), y(0) = 1, a = −0.1 for
a. x(n) = 0, n ≥0
b. x(n) = 1, n ≥0
c. x(n) = n, n ≥0
24. Solve problem 23 with a = −0.2.
25. Solve problem 23 with a = −0.9.
26. Solve problem 23 with a = 0.9.
27. Find the solution of the equation y(n) −0.81y(n −2) = x(n), y(0) = y(1) = 1, for
a. x(n) = 0, n ≥0
b. x(n) = 1, n ≥0
c. x(n) = n, n ≥0
28. Find y(n) given by y(n) −y(n −1) + 0.09y(n −2) = x(n), y(0) = y(1) = 1, for
a. x(n) = 0, n ≥0
b. x(n) = 1, n ≥0
c. x(n) = n, n ≥0
29. Find the solution of the equation y(n) + 2y(n −1) = x(n) for
a. x(n) = 0.5nu(n)
b. x(n) = [3n + 2 + (0.5)n]u(n)
c. x(n) = (−2)nu(n)

Signals and Systems
823
30. Find the steady-state part of the solution of the equation y(n) + 2y(n −1) = cos(ωn)u(n) for
a. ω = π/10
b. ω = π/4
c. ω = π/2
d. ω = 3π/4
e. ω = 9π/10
31. Find the steady-state part of the solution of the equation y(n) + 1.5y(n −1) + 0.5y(n −2) = cos(ωn)u(n) for
a. ω = π/10
b. ω = π/4
c. ω = π/2
d. ω = 3π/4
e. ω = 9π/10
32. Find the steady-state part of y(n) given y(n)−2y(n −1)−y(n −2) = 3x(n)+5x(n −1) for x(n) = cos(ωn)u(n).
Write the answer as a function of ω.
33. An LTI system is represented by the equation y(n) + y(n −1) −y(n −2) = x(n). Determine initial conditions
y(−1) and y(−2) so that for x(n) = cos n, n ≥0, the response becomes y(n) = H cos(n + θ) where H and θ are
constants.
34. Find y(n) given
y(n) −2y(n −1) −y(n −2) = 3x(n) + 5x(n −1), y(−1) = y(−2) = 0,
with x(n) = 1, n ≥0, and x(−1) = 0
35. Find y(n) given by y(n) −0.25y(n −2) = x(n) for
a. x(n) = 0.5nu(n)
b. x(n) = (−0.5)nu(n)
36. Find y(n) given y(n) −0.5y(n −1) = 0.5n, n ≥0, and y(−1) = 1.
37. The response of an LTI system to a 1-volt DC input is given by the 2nd-order equation
y(n) + a1y(n −1) + a2y(n −2) = 1, n ≥0
where a1 and a2 are real constants. Determine values of y(−1), y(−2) which produce y(n) = k0, n ≥0; that is,
those values that make the homogeneous part of the solution zero. Then ﬁnd k0.
38. The response of an LTI system to a DC input is given by the Nth-order equation
y(n) + a1y(n −1) + a2y(n −2) + · · · + ai y(n −i) + · · · + aN y(n −N) = 1, n ≥0
Determine initial conditions y(−1), y(−2) · · · y(−i) · · · y(−N), which produce y(n) = k0 at n ≥0. Then ﬁnd k0.
39. a. Find the unit-step response, g(n), of the causal system described by the difference equation y(n) + 1.3y(n −1)
+ 0.4y(n −2) = u(n) using the following two methods:
(i) Direct solution of the difference equation.
(ii) Find the unit-sample response and then convolve it with u(n).
b. Check your results by verifying that h(n) = g(n) −g(n −1).
40. Find the solution of the equation y(n) −0.2y(n −1) = x(n) for
a. x(n) = 8d(n)

824
CHAPTER 14
LTI Difference Equations
b. x(n) = 8u(n)
c. x(n) = 0, n ≥0 and y(−1) = 10
d. x(n) = 8, n ≥0 and y(−1) = 10
Then
(i) Verify that the response in part b is equal to n
k=0 ya(k), where ya(n) is the response in part a. Explain why
this should be the case.
(ii) Verify that the response in part d is equal to the sum of the responses in parts b (called zero-state) and c (called
zero-input). Give reasons why this should be the case.
41. Find the solution of the equation y(n) −y(n −1) + y(n −2) = x(n) for
a. x(n) = d(n)
b. x(n) = u(n)
c. x(n) = 0, n ≥0 and y(−2) = y(−1) = 1
d. x(n) = 1, n ≥0 and y(−2) = y(−1) = 1
Then
(i) Verify that the response in part b is equal to n
k=0 ya(k), where ya(n) is the response in part a. Explain why
this should be the case.
(ii) Verify that the response in part d is equal to the sum of the responses in parts b (zero-state) and c (zero-input).
Give reason why this should be the case.
42. Find the solution of the equation y(n) −y(n −1) + 0.5y(n −2) = cos(ωn) for
a. ω = π/10
b. ω = π/4
c. ω = 9π/10
In each case ﬁnd y(−2) and y(−1).
43. Find the solution of the equation y(n) −y(n −1) + 0.5y(n −2) = cos(ωn)u(n) for
a. ω = π/10
b. ω = π/4
c.
ω = 9π/10
44. Find the solution of the equation y(n) −y(n −1) + 0.5y(n −2) = 0, n ≥0, given
a. y(−2) and y(−1) found in problem 42, part a
b. y(−2) and y(−1) found in problem 42, part b
c. y(−2) and y(−1) found in problem 42, part c
45. Find the solution of the equation y(n) −y(n −1) + 0.5y(n −2) = cos(ωn), n ≥0 for
a. ω = π/10 with y(−2) and y(−1) found in problem 42 part a
b. ω = π/4 with y(−2) and y(−1) found in problem 42 part b
c. ω = 9π/10 with y(−2) and y(−1) found in problem 42 part c
In each case verify that the response is the sum of the zero-state and zero-input responses found in problems 43 and
44, respectively.
46. Find the solution of the equation y(n) −0.6y(n −1) + 0.36y(n −2) = x(n) for
a. x(n) = cos(ωn)
with
(i) ω = π/12,
(ii) ω = π/6,
(iii) ω = 11π/12
b. x(n) = cos(ωn)u(n)
with
(i) ω = π/12,
(ii) ω = π/6,
(iii) ω = 11π/12

Signals and Systems
825
47. Repeat problem 46 for y(n) −0.6y(n −1) + 0.36y(n −2) = x(n) −x(n −1) + x(n −2)
48. Repeat problem 46 for y(n) −2y(n −1) + 4y(n −2) = x(n)
14.18
Project: Low-Pass Filtering by Difference
Equation
Summary
This project ﬁrst constructs a difference equation that describes a low-pass digital ﬁlter. The equation is then applied to a
sound ﬁle. The sequence of sound samples constitute the input to the equation. The project requires you to write a Matlab
program for numerically computing the output sequence. The ﬁltering effect of the equation is tested by comparing the
input and output spectra.
Procedure 1. Developing the Difference Equation
A second-order low-pass digital Butterworth ﬁlter can be constructed by transforming an analog counterpart (either
manually using paper and pencil or using a computer command). In this project it is desired to low-pass-ﬁlter a sound
ﬁle sampled at the rate of Fs = 22,050 Hz. The cutoff frequency of the ﬁlter is 1 kHz. For simplicity, a second-order
Butterworth ﬁlter is considered. Use the Matlab command butter to ﬁnd the system function H(z) of such a ﬁlter. From
the system function construct the difference equation.
Procedure 2. Applying the Difference Equation
Use a sound ﬁle (e.g., cht5.wav which has been used on other occasions in this book), to be called x(n), as the input to
the equation. The output y(n) is obtained from the linear combination of its past values and the input, as prescribed by
the difference equation. Write a Matlab program to iteratively compute the output and save it as a sound ﬁle.
Procedure 3. Changing the Cutoff Frequency and Filter Order
Repeat procedures 1–2 for a 500-Hz cutoff frequency employing a ﬁfth-order ﬁlter or higher.
Conclusions
Compare the input-output spectra, the sounds of the input and output, and summarize your observations.

Chapter15
The z-Transform and
Its Applications
Contents
Introduction and Summary
827
15.1
Deﬁnition of the z-Transform
828
15.2
Region of Convergence
829
15.3
More Examples
832
15.4
Properties of the z-Transform
836
15.5
Inverse z-Transform
842
15.6
Partial Fraction Expansion Method
843
15.7
Application to Difference Equations
848
15.8
Application to the Analysis of LTI Systems
850
15.9
One-Sided z-Transform
852
15.10
Evaluating the Inverse z-Transform by the Residue Method
854
15.11
Relationship Between the s- and z-Planes
859
Appendix 15A Table of z-Transform Properties and Theorems
865
Appendix 15B Table of z-Transform Pairs
866
15.12
Problems
867
15.13
Project 1: FIR Filter Design by Zero Placement
874
15.14
Project 2: IIR Filter Design by Pole/Zero Placement
877
Introduction and Summary
The z-transform of a discrete-time function is equivalent to the Laplace transform in
the continuous-time domain. It is a convenient and powerful tool for the solution of
difference equations and analysis of LTI systems. It converts the discrete convolution
into a product operation and, thus, simpliﬁes the analysis of discrete-time LTI systems,
especially when applied to several interacting subsystems. The main purpose of this
827

828
CHAPTER 15
The z-Transform and Its Applications
chapter is to introduce the method of the z-transform and its inverse, and to demonstrate
its use. It starts with the bilateral transform, its inverse, and properties. The chapter
then demonstrates applications such as evaluating a convolution, ﬁnding the unit-sample
response, and solving the difference equation. The power of the z-transform is best
manifested at the system level, for example, in relation to the system function, poles and
zeros, stability, and the frequency response. A few examples of system-level applications
are included in this chapter. More comprehensive and broader uses of the z-transform
in LTI system analysis are found in Chapter 18. The unilateral z-transform is presented
to illustrate application of the transform to system with initial conditions. Evaluating
the inverse z-transform by the residue method, and the relationship between the s- and
z-planes are given at the end. The chapter is appended by tables that summarize some
frequently encountered z-transform pairs, properties, and theorems. The chapter ends
with two projects on the design of digital notch ﬁlters in the z-domain.
15.1
Definition of the z-Transform
The two-sided (or bilateral) z-transform of a discrete sequence x(n) is deﬁned by
X(z) =
∞

n=−∞
x(n)z−n
where z is a complex variable.
Example
15.1
Rectangular pulse
Find the z-transform of x(n) = u(n) −u(n −6).
Solution
X(z) =
5

n=0
z−n = 1 + z−1 + z−2 + z−3 + z−4 + z−5, z ̸= 0
X(z) exists on the entire z-plane except at the origin.
Sum of a Geometric Series
The sum of an inﬁnite geometric series
S =
∞

n=0
an

Signals and Systems
829
is a ﬁnite number if |a| < 1. To ﬁnd the sum, we note that
S = 1+a+a2+a3+· · · = 1+a(1+a+a2+a3+· · ·) = 1+aS, S =
1
1 −a , |a| < 1
Similarly, the sum of a geometric series of ﬁnite length N is
S =
N−1

n=0
an = 1 + a + a2 + a3 + · · · + aN−1 = 1 −aN
1 −a
These identities are useful in evaluating z-transforms (and discrete-time Fourier trans-
forms) of discrete signals.
15.2
Region of Convergence
The z-transform does not exist if the sum becomes inﬁnite. For the sum to converge,
the variable z must be constrained to a region in the complex plane called the region of
convergence (ROC). In Examples 15.2, 15.3, and 15.4 we examine the z-transforms (and
their ROC) for a causal, an anticausal, and a double-sided sequence, respectively.
Example
15.2
Causal exponential sequence
Find the z-transform of x(n) = anu(n) and its ROC.
Solution
X(z) =
∞

n=0
anz−n = 1 + az−1 + a2z−2 + a3z−3 + · · ·
This is a geometric progression. For the sum to converge to a ﬁnite value, the magni-
tude of the elements of the series must diminish as n increases. This happens when
|az−1| < 1 or |z| > |a|. Then,
X(z) =
∞

n=0
(az−1)n =
1
1 −az−1 ,
|z| > |a|
The region of convergence of X(z) in the z-plane is outside the circle with radius
|a|. See Figure 15.1. Note that the series converges even for |a| > 1 (when an grows
with n). The function of the ROC is to attenuate anz−n, making it diminish rather
than grow, thus causing the series to converge.

830
CHAPTER 15
The z-Transform and Its Applications
–0.2
0
0.4
0.2
0.6
0.8
1
(a)
x(n)
n
10
1
a
Im[z]
Re[z]
2
4
6
8
–8
–6
–4
–2
0
1.2
(b)
Re[z]
10
2
4
6
8
–8
–6
–4
–2
0
–5
0
5
10
15
20
x(n)
n
1 a
Im[z]
25
FIGURE 15.1 (For Example 15.2) The ROC of a causal function containing is outside
a circle in the z-plane. This ﬁgure shows two causal exponential functions anu(n) and
their ROC being |z| > a. (a) A decaying function x(n) = e−n/3u(n) = (0.7165)nu(n)
with the ROC being |z| > 0.7165. (b) A growing function x(n) = [en/3 −1]u(n) =
[(1.3956)n −1]u(n) with the ROC being |z| > 1.3956. In both cases the time function is
a causal one. It results in the ROC being outside the circle. For the growing exponential
the radius of the circle becomes larger in order for the anz(−n) term to attenuate below a
magnitude of 1, making the z-transform series converge.
Example
15.3
Anticausal exponential sequence
Find the z-transform of x(n) = bnu(−n).
Solution
X(z) =
0

n=−∞
bnz−n =
∞

n=0
(b−1z)n =
1
1 −b−1z , |z| < |b|
The region of convergence of X(z) is inside the circle with radius |b|. See Figure 15.2.

Signals and Systems
831
(b)
8
2
4
6
–10
–8
–4
–6
–2
0
(a)
–0.2
0
0.2
0.4
0.8
0.6
1
x(n)
n
1
b
Im[z]
1.2
Re[z]
–5
x(n)
n
1
b
Im[z]
8
2
4
6
–10
–8
–4
–6
–2
0
25
0
5
10
15
20
Re[z]
FIGURE 15.2 (For Example 15.3) The ROC of an anticausal function is inside a circle in the
z plane. This ﬁgure shows two anticausal exponential functions containing bnu(−n) and their
ROC being |z| < b. For b = 0.7165 [decaying with n shown in (a)] the ROC is |z| < 0.7165
and for b = 1.3956 [growing with n, shown in (b)] the circle becomes larger, |z| < 1.3956.
Example
15.4
Two-sided exponential sequence
Find the z-transform of
x(n) =

an,
n > 1
bn,
n ≤0
Solution
X(z) =
0

n=−∞
bnz−n +
∞

n=1
anz−n
=
0

n=−∞
bnz−n +
∞

n=0
anz−n −1
= −
bz−1
1 −bz−1 +
1
1 −az−1 −1
=
(a −b)z−1
(1 −az−1)(1 −bz−1),
|a| < |z| < |b|

832
CHAPTER 15
The z-Transform and Its Applications
The region of convergence of X(z) is inside the band between two circles with radii
|a| and |b| and with |b| > |a|. See Figure 15.3. Note that the z-transform of x(n)
doesn’t exist if |b| ≤|a|.
10
2
4
6
8
–10
–8
–4
–6
–2
0
–0.2
0
0.2
0.4
0.8
0.6
1
1.2
b
a
Im[z]
Re[z]
FIGURE 15.3 (For Example 15.4) The ROC of anu(n −1) + bnu(−n) is a < |z| < b.
From Example 15.4 we conclude that the z-transform of x(n) = an,
−∞<
n < ∞doesn’t exist.
Summary
The ROC is a connected region in the z-plane. It is either outside a circle (for causal
sequences), inside a circle (for anticausal sequences), or limited to an annular region
between two circles (for two-sided signals). By deﬁnition, the ROC cannot include
a pole of X(z). The inner bound of the ROC of causal sequences is the circle whose
radius is the magnitude of the outermost pole (see Figure 15.1). Similarly, the outer
bound of the ROC of an anticausal sequence is the circle whose radius is the magnitude
of the innermost pole (see Figure 15.2). When the ROC is annular as in Figure 15.3,
the outer poles characterize the sequence for n < 0 and the inner poles characterize
it for n > 0.
15.3
More Examples
Example
15.5
Truncated exponential sequence
Find the z-transform of x(n) = an[u(n) −u(n −N)].
Solution
X(z) =
N−1

n=0
anz−n = 1 + az−1 + a2z−2 + a3z−3 + · · · + a(N−1)z−(N−1)
= 1 −aNz−N
1 −az−1 , z ̸= 0

Signals and Systems
833
This is a ﬁnite sum expressed in the form of the ratio of two polynomials. The
numerator polynomial has a zero at z = a which cancels the pole in the denominator.
Therefore, the ROC of X(z) is all of the z-plane except z = 0.
Example
15.6
Two-sided even exponential sequence
Find the z-transform of x(n) = β−|n| and show that the result is in agreement with
Example 15.4.
Solution
X(z) =
∞

n=−∞
β−|n|z−n
=
0

n=−∞
βnz−n +
∞

n=0
β−nz−n −1
=
−βz−1
1 −βz−1 +
1
1 −β−1z−1 −1
=
(β−1 −β)z−1
(1 −βz−1)(1 −β−1z−1),
| 1
β | < |z| < |β|
The region of convergence of X(z) is inside the band between two circles with radii
|1/β| and |β| and with |β| > 1. Note that the z-transform of x(n) = β−|n| doesn’t
exist if |β| < 1. These results can be derived from Example 15.4 by letting b = β
and a = 1/β.
Example
15.7
Causal sinusoidal sequence
Find the z-transform of x(n) = cos ωn u(n).
Solution
x(n) = e jωn + e−jωn
2
u(n)
X(z) = 1
2

1
1 −e jωz−1 +
1
1 −e−jωz−1

= 1
2
2 −(e jω + e−jω)z−1
1 −(e jω + e−jω)z−1 + z−2
=
1 −(cos ω)z−1
1 −2(cos ω)z−1 + z−2
The region of convergence is |z| > 1.

834
CHAPTER 15
The z-Transform and Its Applications
0.9
0.9
1.1
1.1
–0.4
0
–0.2
–20
–15
–10
5
0
–5
10
15
30
25
20
–30
–25
0.4
0.6
0.8
1
0.2
–0.6
1.2
Re[z]
Im[z]
–0.4
0
–0.2
–20
–15
–10
5
0
–5
10
15
30
25
20
–30
–25
0.4
0.6
0.8
1
0.2
–0.6
1.2
Re[z]
Im[z]
–0.4
0
–0.2
–20
–15
–10
5
0
–5
10
15
30
25
20
–30
–25
0.4
0.6
0.8
1
0.2
–0.6
1.2
Re[z]
Im[z]
(a) (Example 15.8) The causal function e–an cos(wn). Its ROC is outside the circle |z| = e–a = 0.9.
(b) (Example 15.9) The anticausal function ean cos(wn) u(–n). Its ROC is inside the circle |z| = ea = 1.1.
(c) The two-sided function e–a|n| cos(wn). Its ROC is within the ring 0.9 < |z| < 1.1.
FIGURE 15.4 (For Examples 15.8 and 15.9) Sinusoids at ω = 2π/15 rad/s with exponentially varying amplitudes. (a)
The causal function with exponentially decaying amplitude e−0.1n. Its ROC is outside the circle at |z| = e−0.1 = 0.9. (b)
The anticausal function with exponentially growing amplitude e0.1n. Its ROC is inside the circle at |z| = e0.1 = 1.1. (c)
The two-sided function. Its ROC is within the ring 0.9 < |z| < 1.1. The ROC of a causal sinusoid with constant amplitude
is |z| > 1, that of an anti-causal is |z| < 1. The function x(n) = cos(ωn) doesn’t have a z-transform.

Signals and Systems
835
Example
15.8
Causal exponential sinusoid
Find the z-transform of x1(n) = e−αn cos(ωn) u(n), Figure 15.4(a).
Solution
x1(n) = e−αn
e jωn + e−jωn
2

u(n) =
e(−α+ jω)n + e(−α−jω)n
2

u(n)
X1(z) = 1
2

1
1 −e(−α+ jω)z−1 +
1
1 −e(−α−jω)z−1

=
1 −e−α(cos ω)z−1
1 −2e−α(cos ω)z−1 + e−2αz−2
The region of convergence is |z| > e−α.
Example
15.9
Anticausal exponential sinusoid
Find the z-transform of x2(n) = eαn cos(ωn) u(−n), Figure 15.4(b).
Solution
x2(n) = eαn
e jωn + e−jωn
2

u(−n) =
e(α+ jω)n + e(α−jω)n
2

u(−n)
X2(z) = 1
2

1
1 −e−(α+ jω)z +
1
1 −e−(α−jω)z

=
1 −e−α(cos ω)z
1 −2e−α(cos ω)z + e−2αz2
The region of convergence is |z| < eα.
Note: The z-transform of x(n) = e−α|n| cos(ωn) may be derived from results of
Examples 15.8 and 15.9.
x(n) = x1(n) + x2(n) −d(n) ⇒X(z) =
∞

n=−∞
x(n)z−n
=
0

n=−∞
x1(n)z−n +
∞

n=0
x2(n)z−n −1
The region of convergence is the intersection of the ROC of X1(z) and X2(z), e−α <
|z| < eα.
ROC Summary
The region of convergence of the z-transform of a discrete-time function is contiguous
and contains no poles. See Figure 15.5.

836
CHAPTER 15
The z-Transform and Its Applications
1.
The ROC of a causal function is outside the circle bordering the outermost pole.
2.
The ROC of an anticausal function is inside the circle bordering the innermost pole.
3.
The ROC of a two-sided function is an annular ring containing no poles.
C
(a) ROC of a causal function
Im[z]
Re[z]
(b) ROC of an anticausal function
C
Im[z]
Re[z]
(c) ROC of a two-sided function
C
Im[z]
Re[z]
FIGURE 15.5 The three possible ROCs of a z-transform and the contour integrations for ﬁnding
the inverse. See section 15.10.
15.4
Properties of the z-Transform
The z-transform is a member of a class of linear transformations and has the properties of
that class. Here we brieﬂy summarize several properties that are often used to facilitate
taking the transform of new functions. The properties may be readily derived from the
deﬁnitionofthe z-transform.Thepropertiesalsoallowtheuseofatableoftransformpairs
as a practical way to ﬁnd the inverse transforms. [According to the uniqeness theorem, the
relation between x(n) and X(z), with the ROC included, is one-to-one.] Appendix 15A
summarizes properties and theorems of the z-transform. A table of transform pairs is
given in Appendix 15B.
Linearity
The linearity is the basic and most important property of the z-transform. It is described
below
x1(n)
⇐⇒
X1(z)
R1
x2(n)
⇐⇒
X2(z)
R2
ax1(n) + bx2(n)
⇐⇒
aX1(z) + bX2(z)
R1 ∩R2
where x1(n) and x2(n) are any two ﬁnctions, a and b are any constants, and R1 ∩R2 is
the intersection of R1 and R2. This property is derived directly from the deﬁnition of the
z-transform as shown below. Let y(n) = ax1(n) + bx2(n):
Y(z) =
∞

n=−∞
[ax1(n) + bx2(n)] z−n = a
∞

n=−∞
x1(n)z−n + b
∞

n=−∞
x2(n)z−n
= aX1(z) + bX2(z)
In the above derivation no restrictions was placed on x1(n), x2(n), a, and b.

Signals and Systems
837
Example
15.10
Two-sided odd exponential function
Use linearity property to ﬁnd the z-transform of x(n) = anu(n) −a−nu(−n).
Solution
x(n) is the difference between the two time functions anu(n) and a−nu(−n). Using
the results of Examples 15.2 and 15.3, along with the linearity property, we get (see
Figure 15.6)
anu(n)
⇐⇒
1
1 −az−1 , |z| > |a|
a−nu(−n)
⇐⇒
1
1 −az , |z| < 1
|a|
anu(n) −a−nu(−n)
⇐⇒
1
1 −az−1 −
1
1 −az
=
(z −z−1)
(z + z−1) −(a + a−1), |a| < |z| < 1
|a|
For this to exist, we must have |a| < 1.
1
a
8
2
4
6
–8
–4
–6
–2
0
–0.8
–0.6
–0.4
–0.2
0
0.2
0.4
0.6
0.8
a
Im[z]
Re[z]
C
FIGURE 15.6 (For Example 15.10) Using the linearity property, the z-transform of
x(n) = anu(n) −a−nu(−n) is found to be X(z) =
(z−z−1)
(z+z−1)−(a+a−1), |a| < |z| <
1
|a|. In
this ﬁgure a = 0.716.
Time Shift
Shifting x(n) by k units multiplies X(z) by z−k.
x(n −k) ⇐⇒
X(z)z−k
Conversely, multiplication of X(z) by z−k translates into k units of shift in the n-domain.
The above results apply to both positive values of k (corresponding to a delay of k units)
and negative values of k (corresponding to an advance of k units). To prove the shift

838
CHAPTER 15
The z-Transform and Its Applications
property let y(n) = x(n −k). Then
Y(z) =
∞

n=−∞
x(n −k)z−n. Let n = m + k, and, Y(z) =
∞

m=−∞
x(m)z−(m+k)
= z−k
∞

m=−∞
x(m)z−m = z−k X(z)
Example
15.11
Shifting an anticausal function
Consider the following two anticausal functions and their z-transforms. (See the table
of z-transform pairs in Appendix 15B.)
Item i in Appendix 15B:
x1(n) = anu(−n)
⇒X1(z) =
1
1 −a−1z , |z| < |a|
Item k in Appendix 15B:
x2(n) = −anu(−n −1) ⇒X2(z) =
1
1 −az−1 , |z| < |a|
Note that x2(n) = −a−1x1(n +1). Verify that by applying the linearity and time-shift
properties to X1(z) one obtains X2(z).
Solution
A unit shift to the left in the n-domain multiplies the transform by z. From this property
and scaling by −a−1 we expect X2(z) = −a−1zX1(z). To see if this is the case, we
rewrite the given X2(z) in the following form:
X2(z) =
1
1 −az−1 =
−a−1z
−a−1z + 1 = −a−1zX1(z),
|z| < |a|
which is in agreement with our expectation for X2(z) obtained from the application
of properties to X1(z).
Time Reversal
Reversing n converts x(n) to x(−n). The effect on the transform is
x(n)
⇐⇒
X(z)
x(−n) ⇐⇒
X(1/z)
If the ROC of X(z) is Rx, the ROC of X(1/z) is 1/Rx. To prove the time-reversal property
let y(n) = x(−n). Then
Y(z) =
∞

n=−∞
x(−n)z−n. Let n = −m, and, Y(z) =
−∞

m=∞
x(m)zm
=
∞

m=−∞
x(m)zm = X(1/z)

Signals and Systems
839
Example
15.12
Time-reversing a causal function
Consider the following two functions and their z-transforms. (See table of z-transform
pairs in Appendix 15B.)
Item h in Appendix 15B:
x1(n) = anu(n)
⇒X1(z) =
1
1 −az−1 , |z| > |a|
Item i in Appendix 15B:
x2(n) = anu(−n) ⇒X2(z) =
1
1 −a−1z , |z| < |a|
Note that x2(n) can be obtained from x1(n) by a time reversal followed by changing
a to a−1. Verify that X2(z) can be obtained by applying the above transformations to
X1(z).
Solution
Time reversal changes z to z−1. Apply it to x1(n), then change a to a−1 and the
following table of transform pairs are obtained:
anu(n)
⇒
1
1 −az−1 ,
|z| > |a|
a−nu(−n)
⇒
1
1 −az ,
|z| <
 1
a

anu(−n)
⇒
1
1 −a−1z ,
|z| < |a|
The last line in the above is in agreement with the given transform pair for x2(n).
Convolution
Convolution of two discrete-time functions is equivalent to multiplication of their
z-transforms.
x(n) ⋆y(n) ⇐⇒
X(z)Y(z)
To show this, note that:
y(n) = x(n) ⋆h(n) =
∞

k=−∞
x(n −k) h(k)
Y(z) =
∞

n=−∞
y(n)z−n =
∞

n=−∞
∞

k=−∞
x(n −k) h(k) z−n
To convert the double sum to two separate sums with single variables, we replace the
variable n by (k + p), or equivalently (n −k) = p. The terms containing the variables
p and k in the double sum are then separated
Y(z) =

∞

p=−∞
x(p) z−p
 
∞

k=−∞
h(k) z−k

= X(z)H(z)

840
CHAPTER 15
The z-Transform and Its Applications
The convolution property establishes the input-output relationship Y(z) = X(z)H(z),
where Y(z), X(z), and H(z) are z-transforms of the output, input, and unit-sample
response of an LTI system, respectively.
Example
15.13
The unit-sample response of an LTI system may be found from the unit-step response
by the difference equation h(n) = g(n)−g(n −1). This is a consequence of linearity
as shown below.
u(n)
⇒
g(n)
d(n) = u(n) −u(n −1)
⇒
h(n) = g(n) −g(n −1)
g(n) and h(n) are also related by the convolution g(n) = u(n) ⋆h(n). Using the
z-transform show that the two relationships are equivalent.
Solution
The difference equation that relates g(n) to h(n) can be derived from the convolution
as shown below.
g(n) = u(n) ⋆h(n)
⇒
G(z) =
H(z)
1 −z−1
H(z) = G(z)(1 −z−1) = G(z) −z−1G(z)
⇒
h(n) = g(n) −g(n −1)
Example
15.14
Find the unit-sample response h(n) of an LTI system having an input-output pair:
x(n) = [1
↑, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
y(n) = [0
↑, 1, 3, 6, 10, 15, 20, 25, 30, 35, 40, 45, 50, 42, 33, 23, 12]
Solution
X(z) = 1 + 2z−1 + 3z−2 + 4z−3 + · · · + 11z−10 + 12z−11
Y(z) = z−1 + 3z−2 + 6z−3 + 10z−4 + · · · + 23z−15 + 12z−16
H(z) = Y(z)
X(z) =
z−1 + 3z−2 + 6z−3 + · · · + 23z−15 + 12z−16
1 + 2z−1 + 3z−2 + 4z−3 + 10z−4 + · · · + 11z−10 + 12z−11
By long division:
H(z) = z−1 + z−2 + z−3 + z−4 + z−5
h(n) = [0
↑, 1, 1, 1, 1, 1]

Signals and Systems
841
Multiplication by n
Multiplying the time function by n results in the following transform pairs:
nx(n) ⇐⇒
−z d X(z)
dz
The ROC remains the same. To show the above, start with the derivative of X(z):
d X(z)
dz
= d
dz
∞

−∞
x(n)z−n = −
∞

−∞
nx(n)z(−n−1) = −z−1
∞

−∞
nx(n)z−n
and observe that
∞

−∞
nx(n)z−n = −z d X(z)
dz
Example
15.15
Given the transform pair
x(n) = anu(n)
⇒
X(z) =
1
1 −az−1 ,
|z| > |a|
ﬁnd the z-transform of y(n) = nanu(n) using the rule for multiplication by n.
Solution
X(z) =
1
1 −az−1 , |z| > |a|
Y(z) = −z d X(z)
dz
= −z d
dz

1
1 −az−1

=
az−1
(1 −az−1)2 , |z| > |a|
Multiplication by an Exponential an
Multiplying the time function by an results in the following transform pairs:
anx(n) ⇐⇒
X(a−1z)
The ROC becomes |a|Rx. The rule is derived through the following steps:
y(n) = anx(n) Y(z) =
∞

−∞
anx(n)z−n =
∞

−∞
x(n)
 z
a
	−n
= X
 z
a
	
Example
15.16
Revisiting Example 15.12, let
x1(n) = anu(n)
⇒
X1(z) =
1
1 −az−1 ,
|z| > |a|
x2(n) = anu(−n)
⇒
X2(z) =
1
1 −a−1z ,
|z| < |a|
Note that x2(n) can be obtained from x1(n) through a time reversal followed by a2n
multiplication. Verify that by applying the rules to X1(z) one obtains X2(z).

842
CHAPTER 15
The z-Transform and Its Applications
Solution
Apply time reversal and multiplication by an to obtain the following table of transform
pairs.
x(n) = anu(n)
⇒
1
1 −az−1 ,
|z| > |a|
Time reversal:
x(−n) = a−nu(−n)
⇒
1
1 −az ,
|z| <

1
a

Multiplication by a2n:
y(n) = a2nx(−n) = anu(−n)
⇒
Y(z) =
1
1 −a

 z
a2
 =
1
1 −a−1z ,
|z| < |a|
The last line in the above equations is in agreement with the given transform pair for
anu(−n).
15.5
Inverse z-Transform
A sequence x(n) may be obtained from its z-transform X(z) using the following contour
integral:
x(n) =
1
2π j

C
X(z)zn−1dz
(See section 15.10.) The integral is taken in the counterclockwise direction along a
closed path in the ROC of the z-plane, enclosing the origin (e.g., a circle centered at
z = 0). The contour integral may be evaluated using Cauchy’s residue theorem, hence
also called the residue method. The residue method will not be used as an operational
tool for ﬁnding the inverse transform. It, however, enlightens the underlying principles
used in other methods, such as when the ROC is an annular ring. Section 15.10 elaborates
on the residue method and can be consulted when a deeper understanding of the subject
is desired.
Another approach to ﬁnding the inverse of X(z), if it is a rational function of z−1, is
to expand it into a power series of z−1. The coefﬁcients of the series constitute the time
function. Expansion of a rational function may be done in one of several ways (e.g., by
long division).
Example
15.17
Find the inverse z-transform of the following X(z) by expanding it in terms of z−1.
X(z) =
3
(1 −z−1)(1 + 2z−1), |z| > 2
Solution
X(z) =
3
(1 −z−1)(1 + 2z−1) =
3z2
z2 + z −2

Signals and Systems
843
Using long division we obtain:
3 −3z−1 + 9z−2 −15z−3 + 33z−4 −63z−5 · · ·
z2 + z −2

3z2
3z2 + 3z −6
−3z + 6
−3z −3 + 6z−1
9 −6z−1
9 + 9z−1 −18z−2
−15z−1 + 18z−2
−15z−1 −15z−2 + 30z−3
33z−2 −30z−3
33z−2 + 33z−3 −66z−4
−63z−3 + 66z−4
· · ·
x(n) = {3
↑, −3, 9, −15, 33, −63, . . .}
The power series expansion method doesn’t produce the time function in a closed
form and is not an efﬁcient method, except in special cases where an approximation
is acceptable. The more powerful and popular method is by partial fraction expansion
to be discussed in the next section and used throughout the rest of the chapter.
15.6
Partial Fraction Expansion Method
According to the uniqeness theorem, the relationship between x(n) and X(z) (the ROC
included) is one-to-one: For each x(n) we have only one X(z), and, each X(z) cor-
responds to only one x(n). Therefore, the inverse of an X(z) may be found through
tables of transform pairs (Appendix 15B) in conjunction with a few basic properties and
rules (Appendix 15A). A practical way of ﬁnding the inverse is to expand X(z) into
simple forms for which the time function may be deduced by inspection or from tables
of transform pairs. Since the z-transform is a linear operation, the inverse of X(z) is the
sum of the inverses of its fractions. The method is similar to ﬁnding the inverse Laplace
transform by partial fraction expansion. In this section we assume X(z) is a rational
function. The denominator is a polynomial in terms of z−1 and roots are either real or
complex. The roots can also be repeated. [The roots of the denominator polynomial are
also called the poles of X(z).] We start with simple real-valued poles.
Remark
It is advantageous to write X(z) and its expansions in terms of z−1, rather than z, because
of the ease of recognizing the correspondence between an exponential function and

844
CHAPTER 15
The z-Transform and Its Applications
its transform:
anu(n) ⇒
1
1 −az−1 ,
|z| > |a|.
Simple Real-Valued Roots
Each pole produces an exponential time function. The function is causal (right-sided) if
the pole is encircled by the ROC. Otherwise, the function is anticausal (left-sided).
Example
15.18
Find the inverse z-transform of X(z) given below for three ROCs:
X(z) =
3
(1 −z−1)(1 + 2z−1)



a)
|z| > 2
b)
1 < |z| < 2
c)
|z| < 1
Solution
We expand X(z) into two fractions and determine the inverses according to the ROCs.
X(z) =
A
1 −z−1 +
B
1 + 2z−1
A = X(z)(1 −z−1)

z=1 =
3
1 + 2z−1

z=1
= 1
B = X(z)(1 + 2z−1)

z=−2 =
3
1 −z−1

z=−2
= 2
X(z) =
1
1 −z−1 +
2
1 + 2z−1
a.
xa(n) = u(n) + 2(−2)nu(n),
item h in Appendix 15B
b.
xb(n) = u(n) + (−2)n+1u(−n −1),
item k
c.
xc(n) = −u(−n −1) + (−2)n+1u(−n −1),
item k
Remark
When the degree of the numerator in z−1 is equal or higher than that of the denominator
we need to ﬁrst divide the denominator into the numerator, making the numerator of
lesser degree than the denominator, then expand it. Example 15.19 illustrates the point.
Example
15.19
Find the inverse z-transform of
X(z) =
1 −2z−1 + 4z−2
(1 −z−1)(1 + 2z−1), |z| > 2
Solution
We ﬁrst reduce the degree of the numerator by extracting the constant −2 from it.
X(z) = −2 +
3
(1 −z−1)(1 + 2z−1), |z| > 2

Signals and Systems
845
ThenweexpandtheremainingfractionintoitsfractionsaswasdoneinExample15.18.
X(z) = −2 +
A
1 −z−1 +
B
1 + 2z−1 , |z| > 2
= −2 +
1
1 −z−1 +
2
1 + 2z−1 , |z| > 2
x(n) = −2d(n) + u(n) + 2(−2)nu(n)
Remark
Standard tables of z-transform use polynomials of z−1. Partial fraction expansion of an
X(z) which is expressed by polynomilas of z will not produce fractions directly available
from the tables. In such a case, we expand X(z)/z instead, which can produce fractions
in the familiar forms found in tables. This is illustrated in Example 15.20.
Example
15.20
Express the X(z) in Example 15.18 in terms of positive powers of z and ﬁnd its inverse
by partial fraction expansion.
Solution
Expressing X(z) in terms of positive powers of z and then expanding it into fractions
(not recommended, even though it produces the correct inverse) we get:
X(z) =
3z2
(z −1)(z + 2) = 3 −
3z −6
z2 + z −2 = 3 +
1
z −1 −
4
z + 2, |z| > 2
The inverse functions for the second and the third terms in the above expansion are not
readily available in tabular form. Therefore, we expand X(z)/z and take the inverses:
X(z)
z
=
3z
(z −1)(z + 2) =
A
z −1 +
B
z + 2
A =
3z
z + 2

z=1
= 1, and B =
3z
z −1

z=−2
= 2
X(z) =
z
z −1 +
2z
z + 2 =
1
1 −z−1 +
2
1 + 2z−1 , |z| > 2
x(n) = u(n) + 2(−2)nu(n)
Complex Roots
The z-transform of the exponential function an is valid regardless of a being real or com-
plex. Therefore, an X(z) with complex roots may be expanded into its partial fractions
with each root treated individually. It is, however, preferable to combine each pair of
complex conjugate roots, as found in tables of transform pairs (Appendix 15B). This is
illustrated by the following two examples.

846
CHAPTER 15
The z-Transform and Its Applications
Example
15.21
Find the inverse of
X(z) =
1
1 + a2z−2 , |z| > |a|
Solution
By matching X(z) with item p in the table of Appendix 15B we easily ﬁnd x(n) =
an cos(πn/2)u(n).
Remark
In Example 15.21 we could alternatively expand X(z) in terms of the two poles and then
ﬁnd the inverses. This method gives a correct answer but is not recommended, except as
an exercise as done below.
X(z) =
1
1 + a2z−2 =
1
(1 −jaz−1)(1 + jaz−1) =
A
1 −jaz−1 +
B
1 + jaz−1 , |z| > |a|
A = X(z)(1 −jaz−1)

z= ja = 1
2
B = X(z)(1 + jaz−1)

z=−ja = 1
2
x(n) = 1
2

( ja)n + (−ja)n
u(n) = an
2

e jπn/2 + e−jπn/2
u(n) = an cos
πn
2
	
u(n)
Example
15.22
Find the inverse of
X(z) =
2 −2z−1 + 3z−2
1 −z−1 + 2z−2 + 4z−3 , |z| > 2
Solution
We ﬁrst ﬁnd the roots of the denominator.
1 −z−1 + 2z−2 + 4z−3 = 0, z1 = −1, z2,3 = 1 ± j
√
3
The denominator can be expanded as shown below.
X(z) =
2 −2z−1 + 3z−2
(1 + z−1)(1 −2z−1 + 4z−2), |z| > 2
By an inspection of the denominator we anticipate using the following two transform
pairs from Appendix 15B:
Item h in Appendix 15B
anu(n)
⇐⇒
1
1 −az−1 ,
|z| > a

Signals and Systems
847
Item p in Appendix 15B
an cos(ωn)u(n)
⇐⇒
1 −a(cos ω)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > a
Therefore, we expand X(z) in terms of the single pole z1 and the combination of the
complex conjugate pair z2,3 as shown below.
X(z) =
A
1 + z−1 +
Bz−1 + C
1 −2z−1 + 4z−2 , |z| > 2
A = X(z)(1 + z−1)

z=−1 = 2 −2z−1 + 3z−2
1 −2z−1 + 4z−2

z=−1 = 1
(Bz−1 + C)

z=1+ j
√
3 = X(z)(1 −2z−1 + 4z−2)

z=1+ j
√
3
= 2 −2z−1 + 3z−2
1 + z−1

z=1+ j
√
3 = 3 + j
√
3
4
By direct substitution:
(Bz−1 + C)

z=1+ j
√
3 = 1
4 −j
√
3
4
Therefore, B = −1 and C = 1
X(z) =
1
1 + z−1 +
1 −z−1
1 −2z−1 + 4z−2 , |z| > 2
x(n) =

(−1)n + 2n cos
πn
3
	
u(n)
Repeated Roots
A root that is repeated n times is called an nth order pole and contributes up to n fractions
to the expansion. This is illustrated by the following example for n = 2.
Example
15.23
Find the inverse of
X(z) =
1 −0.6z−1 + 0.06z−2
1 −1.7z−1 + 0.96z−2 −0.18z−3 , |z| > 0.6
Solution
We write X(z) as the ratio of two polynomials in z
X(z) = z
z2 −0.6z + 0.06
z3 −1.7z2 + 0.96z −0.18, |z| > 0.6

848
CHAPTER 15
The z-Transform and Its Applications
The roots of the denominator are at z1 = 0.5,
z2,3 = 0.6. The root at z = 0.6 is
repeated. We now expand X(z)/z into partial fractions.
X(z)
z
=
z2 −0.6z + 0.06
(z −0.5)(z −0.6)2 =
A
z −0.5 +
B
(z −0.6)2 +
C
z −0.6
A = X(z)
z
(z −0.5)

z=0.5 = z2 −0.6z + 0.06
(z −0.6)2

z=0.5 = 1
B = X(z)
z
(z −0.6)2
z=0.6 = z2 −0.6z + 0.06
z −0.5

z=0.6 = 0.6
C = d
dz
 X(z)
z
(z −0.6)2
 
z=0.6
= d
dz
z2 −0.6z + 0.06
z −0.5
 
z=0.6
= 0
X(z)
z
=
1
z −0.5 +
0.6
(z −0.6)2
X(z) =
1
1 −0.5z−1 +
0.6z−1
(1 −0.6z−1)2
x(n) =

(0.5)n + n(0.6)n
u(n)
(For more details on partial fraction expansion, including the case of multiple-order
poles, see related sections in the chapter on the Laplace transform.)
15.7
Application to Difference Equations
The z-transform may be applied to solve linear difference equations with constant coef-
ﬁcients. We start with the following class of difference equations
y(n) + a1y(n −1) · · · + aN y(n −N) = b0x(n) + b1x(n −1) · · · + bMx(n −M),
−∞< n < ∞
where x(n) is known for all n.1 Taking the bilateral z-transform of both sides and making
use of the shift property, we ﬁnd
Y(z) + a1z−1Y(z) · · · + aNz−NY(z) = b0X(z) + b1z−1X(z) · · · + bMz−M X(z)

1 + a1z−1 · · · + aNz−N
Y(z) =

b0 + b1z−1 · · · + bMz−M
X(z)
Y(z) = b0 + b1z−1 · · · + bMz−M
1 + a1z−1 · · · + aNz−N X(z)
Let
H(z) = b0 + b1z−1 · · · + bMz−M
1 + a1z−1 · · · + aNz−N
1One-sided z-transforms will be used to solve difference equations with initial conditions. See section 15.9.

Signals and Systems
849
Then, Y(z) = H(z)X(z), which could be reverted to the time domain and y(n), as
demonstrated by the following three examples.
Example
15.24
Use the z-transform to ﬁnd the solution to the difference equation
y(n) −0.2y(n −1) = x(n), where x(n) = 0.5nu(n)
Solution
Taking z-transforms of both sides of the difference equation, we get
Y(z)−0.2z−1Y(z) = X(z), Y(z) = H(z)X(z), where H(z) =
1
1 −0.2z−1 , |z| > 0.2
The z-transforms of x(n) and y(n) are
X(z) =
∞

n=0
0.5nz−n =
1
1 −0.5z−1 , |z| > 0.5
Y(z) = H(z)X(z) =
1
(1 −0.2z−1)(1 −0.5z−1), |z| > 0.5
Expanding Y(z) into its partial fractions and taking their inverses results in
Y(z) =
1
(1 −0.2z−1)(1 −0.5z−1) =
A
1 −0.2z−1 +
B
1 −0.5z−1
A = Y(z)(1 −0.2z−1)

z=0.2
=
1
1 −0.5z−1

z=0.2
= −2
3
B = Y(z)(1 −0.5z−1)

z=0.5
=
1
1 −0.2z−1

z=0.5
= 5
3
y(n) =
5
3

0.5n
−2
3

0.2n
u(n)
Example
15.25
Find y(n) in Example 15.24 if
x(n) =

0.5−n,
n < 0
0,
n ≥0
Solution
X(z) =
−1

−∞
0.5−nz−n =
−1
1 −2z−1 , |z| < 2
Y(z) = H(z)X(z) =
−1
(1 −2z−1)(1 −0.2z−1), 0.2 < |z| < 2

850
CHAPTER 15
The z-Transform and Its Applications
Expanding Y(z) into its partial fractions and taking their inverses, we have
Y(z) = 1
9
1
(1 −0.2z−1) −10
9
1
(1 −2z−1), 0.2 < |z| < 2
y(n) =




 1
9

0.2n,
n ≥0
−

 10
9

0.5−n,
n < 0
Example
15.26
Find y(n) in Example 15.24 if x(n) = 0.5|n|,
−∞< n < ∞.
Solution
X(z) =
−1

−∞
0.5−nz−n +
∞

0
0.5nz−n =
−1
1 −2z−1 +
1
1 −0.5z−1 , 0.5 < |z| < 2
Y(z) = H(z)X(z) =

−1
1 −2z−1 +
1
1 −0.5z−1
 
1
1 −0.2z−1

=
−1.5z−1
(1 −2z−1)(1 −0.5z−1)(1 −0.2z−1), 0.5 < |z| < 2
Expanding Y(z) into its partial fractions and taking their inverses, we have
Y(z) = −10
9
1
(1 −2z−1) + 5
3
1
(1 −0.5z−1) −5
9
1
(1 −0.2z−1), 0.5 < |z| < 2
y(n) =

 5
3

0.5n −

 5
9

0.2n,
n ≥0
−

 10
9

0.5−n,
n < 0
Due to the linearity property, the response of the difference equation in Example 15.26
is the sum of its responses in Examples 15.24 and 15.25.
15.8
Application to the Analysis of LTI Systems
The z-domain is appropriately named the frequency domain for analysis of LTI systems,
with H(z) a sufﬁcient instrument to describe the system. We have encountered H(z) pre-
viously as the scale factor to power signals, exponential signals, and sinusoids (Chapter
13). In this chapter we applied the z-transform to the input-output difference equation
and found Y(z) = H(z)X(z). It is easily seen that H(z) is the z-transform of the unit-
sample response. [Let x(n) = d(n), X(z) = 1 and get Y(z) = H(z).] It is, therefore, not
surprising that in the frequency domain H(z) plays the role of h(n) in the time domain.
Theoretically, H(z) and h(n) are on a par in describing the system. In practice, H(z)
offers a much more powerful analysis tool as it provides explicit and immediate infor-
mation about the system and the output. For example, take the case of a sinusoidal input.
Remember that z is a complex variable and can be represented in the complex plane by a
point z = ρe jω. For a sinusoidal signal with constant amplitude, z becomes restricted to

Signals and Systems
851
the unit circle and H(z) is reduced to the frequency response. Its magnitude and phase
provide the magnitude and phase change in a sinusoidal input. As another example of
the power of H(z), consider its poles. They are identical to the natural frequencies of the
system and provide information about the system’s stability. As a third example, we note
that H(z) provides a theoretical model for an LTI system whose unit-sample response
has been measured experimentally. Furthermore, H(z) is used to develop structures
for LTI system (including systems’ interconnections and feedback). Its relationships
with the Fourier transform is yet another factor that places the z-transform at the center
of frequency-domain analysis. These and many more related topics are addressed in
Chapter 18, to which the reader is referred. In this section, by way of Example 15.27,
we familiarize the reader with some of the features and capabilities of H(z).
Example
15.27
The unit-sample response of a causal discrete-time LTI system is measured and mod-
eled by h(n) = d(n) + u(n).
a.
Find H(z).
b.
Find the system’s input-output difference equation.
c.
Find the unit-step response using the z-transform.
d.
Using the z-transform, ﬁnd the response of the system to x(n) = cos(ωn) and
evaluate it for (i) ω = π and (ii) ω = π/2.
e.
Is the system BIBO stable?
Solution
a.
H(z) = 1 +
1
1 −z−1 = 2 −z−1
1 −z−1 = Y(z)
X(z)
b.
(1 −z−1)Y(z) = (2 −z−1)X(z)
y(n) −y(n −1) = 2x(n) −x(n −1)
c.
Y(z) = H(z)X(z) = 2 −z−1
1 −z−1 ×
1
1 −z−1 =
2 −z−1
(1 −z−1)2
Y(z) =
2 −z−1
(1 −z−1)2 =
A
(1 −z−1)2 +
B
1 −z−1
A = Y(z)(1 −z−1)2
z=1 = 2 −z−1
z=1 = 1
d
dz−1

B(1 −z−1)
 
z=1 =
d
dz−1

Y(z)(1 −z−1)2 
z=1
= d(2 −z−1)
dz−1

z=1 = −1, B = 1
Y(z) =
1
1 −z−1 +
1
(1 −z−1)2
y(n) = u(n) + (n + 1)u(n + 1) = 2u(n) + nu(n)

852
CHAPTER 15
The z-Transform and Its Applications
An alternative form of the partial fraction expansion for Y(z) is
Y(z) =
2
1 −z−1 +
z−1
(1 −z−1)2
which directly results in the time function y(n) = 2u(n) + nu(n).
d.
x(n) = cos(ωn) = RE{e jωn}, y(n) = RE{He jωn}
H = 2 −z−1
1 −z−1

z=e jω = 2 −e−jω
1 −e−jω = 3
2 −j
2 cot
ω
2
	
y(n) = RE
3
2 −j
2 cot
ω
2
	
[cos(ωn) + j sin(ωn)]

= 3
2 cos(ωn) + 1
2 cot
ω
2
	
sin(ωn)
ω = π, x(n) = cos(πn),
y(n) = 3
2 cos(πn)
ω = π
2 , x(n) = cos
πn
2
	
, y(n) = 3
2 cos
πn
2
	
+ 1
2 sin
πn
2
	
e.
The system is not BIBO-stable. The bounded input x(n) = u(n) gives rise to an
output that grows with n without any bound. An LTI discrete-time system is
BIBO-stable if its poles (natural frequencies) are inside the unit circle in the
complex plane. The system in this problem has a single pole that is on the unit
circle, making it not BIBO. At the same time its response to a sinusoid doesn’t
grow out of bounds, making it marginally stable. The relevant property in the
time domain is that for a BIBO system,

n
|h(n)| < M, where M is any (ﬁxed) large number,
which is not the case here.
15.9
One-Sided z-Transform
In some cases the input to a system is not known for −∞< n < ∞but only for n ≥0.
To ﬁnd the output of the system, in addition to the input for n ≥0, we need the state of
the system before the arrival of the input, for example, at n = −1, −2, . . .. In such a case
(where the two-sided z-transform is not applicable), we use the one-sided z-transform
deﬁned by
X(z) =
∞

n=0
x(n)z−n
It is noted that the one-sided z-transform is not limited to causal functions. It considers
only the values of the function for n ≥0. Therefore, two different functions with the
same right side have the same one-sided z-transform. An important difference between

Signals and Systems
853
the two-sided and the one-sided z-transforms is the shift property to the right. In the case
of the one-sided z-transform, a unit delay in time multiplies X(z) by z−1 but adds the
additionally shifted term x(−1) to the transform. Similarly, right-shifting x(n) by two
units multiplies X(z) by z−2 and adds the terms x(−1)z−1 + x(−2) to the transform and
so on.
x(n −1)
⇐⇒
X(z)z−1 + x(−1)
x(n −2)
⇐⇒
X(z)z−2 + x(−1)z−1 + x(−2)
· · ·
· · ·
· · ·
x(n −k)
⇐⇒
X(z)z−k + x(−1)z−(k−1) + · · · + x(−k)
This property is essential when solving difference equations by the one-sided z-transform
method, as it automatically takes into account the effect of initial conditions.
Example
15.28
Use the z-transform to ﬁnd the solution to the difference equation
y(n) −0.2y(n −1) = 0.5n, n ≥0, given y(−1) = 5
9
Solution
Taking the one-sided z-transforms of both sides of the equation we have
Y(z) −0.2

z−1Y(z) + y(−1)

= X(z)
Y(z) = H(z)X(z) + 0.2y(−1)H(z), where
H(z) =
1
1 −0.2z−1 , |z| > 0.2
X(z) =
1
1 −0.5z−1 , |z| > 0.5
Y(z) =
1
(1 −0.2z−1)(1 −0.5z−1) + 1
9
1
(1 −0.2z−1), |z| > 0.5
The above expression for Y(z) shows contributions from the input and the initial
condition. The term H(z)X(z) is the contribution from the input alone (zero-state
response). The term 0.2y(−1)H(z) is the contribution from the initial condition (zero-
input response). Expanding Y(z) into its partial fractions and taking their inverses,
we get
Y(z) = 5
3
1
1 −0.5z−1 −5
9
1
1 −0.2z−1 , |z| > 0.5
y(n) = 5
3

0.5n
−5
9

0.2n
, n ≥0
In this example the input for n ≥0 is the same as in Example 15.24. As expected,
the difference in the outputs is due to the nonzero initial condition.

854
CHAPTER 15
The z-Transform and Its Applications
15.10
Evaluating the Inverse z-Transform
by the Residue Method
A sequence x(n) may be obtained from its z-transform X(z) using the following contour
integral:
x(n) =
1
2π j

C
X(z)zn−1dz
The integral is taken in the counterclockwise direction along a closed path in the ROC,
enclosing the origin (e.g., a circle centered at z = 0).
Proof
In the following integral substitute for X(z). Then change the order of integration and
summation.
I ≡

C
X(z)zn−1dz =

C

∞

m=−∞
x(m)z−m

zn−1dz =
∞

m=−∞
x(m)

C
zn−m−1dz
Without loss of generality we let the integral contour to be a circle with radius ρ. On this
contour we will have
z = ρe jθ, dz = jρe jθdθ
I =
∞

m=−∞
jx(m)ρn−m
 2π
θ=0
e j(n−m)θdθ
But
 2π
θ=0
e j(n−m)θdθ =

2π,
m = n
0,
m ̸= n
Therefore
I = j2πx(n) and x(n) =
1
2π j

C
X(z)zn−1dz
Evaluating the Integral by Residue Method
The contour integral given above may be evaluated using Cauchy’s residue theorem,
hence also called the residue method. According to the Cauchy residue theorem, the
integral of a complex function F(z) along a closed path in its region of convergence in
the counterclockwise direction is equal to 2πj times the sum of the residues of F(z) at
the poles inside the area enclosed by the path.

C
F(z)dz = 2π j

[ residues of F(z) at its poles inside C ]
If F(z) has a simple pole at z0,
residue at z0 = F(z)(z −z0)

z=z0

Signals and Systems
855
If F(z) has a repeated pole of kth order at z0 its residue at that pole is
residue at z0 =
1
(k −1)!
dk−1 
F(z)(z −z0)k
dzk−1

z=z0
In applying the integral theorem to X(z)zn−1, we need to evaluate the integral for all
values −∞< n < ∞. We recognize the two cases
n > 0 and n < 0 separately and
examine the poles of X(z)zn−1 inside the contour. For n > 0, the poles of X(z)zn−1 are
the same as the poles of X(z). For n < 0, the function X(z)zn−1 has multiple poles at
the origin which have to be considered. The concluding result is that
x(n) =
1
2π j

C
X(z)zn−1dz
x(n) =

[ residues of X(z)zn−1 at poles inside C ] for n > 0
x(n) = −

[ residues of X(z)zn−1 at poles outside C ] for n < 0
See Figure 15.5. The value of the sequence at n = 0 is found by examining X(z) at the
origin. For a causal function,
X(z) =
∞

n=0
x(n)z−n = x(0) + x(1)z−1 + x(2)z−2 + x(3)z−3 + · · ·
from which x(0) = X(z)

z−1=0. For an anticausal function,
X(z) =
0

n=−∞
x(n)z−n = x(0) + x(−1)z + x(−2)z2 + x(−3)z3 + · · ·
from which x(0) = X(z)

z=0.
In the following examples we apply the residue method to ﬁnd the inverse of sev-
eral z-transforms and compare them with the results obtained in Examples 15.2, 15.3,
and 15.4.
Example
15.29
Causal function
Find the inverse z-transform of
X(z) =
1
1 −az−1 , |z| > |a|
Solution
x(n) =
1
2π j

C
X(z)zn−1dz =
1
2π j

C
zn−1
1 −az−1 dz

856
CHAPTER 15
The z-Transform and Its Applications
The contour of integration is in the ROC, that is, |z| > |a|. X(z) has a single pole at
z = a, which is inside the contour. The residue of X(z)zn−1 at that pole is
residue (at z = a) = zn−1(z −a)
1 −az−1

z=a
= (z −a)zn
z −a

z=a
= an
Therefore, x(n) = an, n > 0. At n = 0
x(0) =
1
1 −az−1

z−1=0
= 1
X(z) has no poles outside the contour resulting in x(n) = 0 for n < 0. In summary,
x(n) = anu(n). This is in agreement with the result of Example 15.2 (Figure 15.1).
Example
15.30
Causal function
Find the inverse z-transform of
X(z) =
az−1
1 −az−1 , |z| > |a|
Solution
As in Example 15.29, the contour of integration is within the region |z| > |a|. X(z)
has a single pole at z = a, which is enclosed by the contour, and the residue of
X(z)zn−1 at that pole is
residue (at z = a) = az−1zn−1(z −a)
1 −az−1

z=a
= a(z −a)zn−1
z −a

z=a
= an
Therefore, x(n) = an, n > 0. At n = 0
x(0) =
az−1
1 −az−1

z−1=0
= 0
X(z) has no poles outside the contour resulting in x(n) = 0 for n < 0. In summary,
x(n) = anu(n −1). See Figure 15.7.
10
8
2
4
6
–8
–4
–6
–2
0
–0.2
0
0.2
0.4
0.6
1.0
0.8
a
Im[z]
Re[z]
C
FIGURE 15.7 (For Example 15.30) The inverse of X(z) =
az−1
1−az−1 , |z| > |a|, is the
causal function x(n) = anu(n −1).

Signals and Systems
857
Example
15.31
Anticausal function
Find the inverse z-transform of X(z) =
1
1 −b−1z , |z| < |b|
Solution
x(n) =
1
2π j

C
zn−1
1 −b−1z dz
The contour of integration is in |z| < |b|. X(z) has no poles inside the contour
resulting in x(n) = 0 for n > 0. It has a single pole at z = b, which is outside the
contour. The residue of X(z)zn−1 at z = b is
residue (at z = b) = zn−1(z −b)
1 −b−1z

z=b
= −b(z −b)zn−1
z −b

z=b
= −bn
Therefore, x(n) = bn for n < 0. We also note that for this anticausal function
x(0) = X(0) = 1. In summary, x(n) = bnu(−n). This is in agreement with the result
of Example 15.3.
Example
15.32
Anticausal function
Find the inverse z-transform of
X(z) =
−1
1 −bz−1 , |z| < |b|
Solution
The contour of integration is in |z| < |b|. X(z) has no poles inside the contour
resulting in x(n) = 0,
n > 0. It has a single pole at z = b, which is outside the
contour. The residue of zn−1X(z) at z = b is
residue (at z = b) = −zn−1(z −b)
1 −bz−1

z=b
= −(z −b)zn
z −b

z=b
= −bn
Therefore, x(n) = bn, n < 0. We also note that for this anticausal function x(0) =
X(0) = 0. In summary, x(n) = bnu(−n −1). See Figure 15.8.
8
2
4
6
–8
–4
–6
–2
0
–0.1
0
0.2
0.3
0.1
0.4
0.5
0.6
0.7
0.8
b
Im[z]
Re[z]
C
FIGURE 15.8 (For Example 15.32) The inverse of X(z) =
−1
1−bz−1 , |z| < |b|, is the
anticausal function x(n) = bnu(−n −1).

858
CHAPTER 15
The z-Transform and Its Applications
Example
15.33
Two-sided function
Find the inverse z-transform of
X(z) =
(a −b)z−1
(1 −az−1)(1 −bz−1), |a| < |z| < |b|
Solution
For the ROC to exist, one must have |b| > |a|. The contour of integration is in the
annular region |a| < |z| < |b|. X(z) has a pole inside the contour at z = a and the
residue of X(z)zn−1 at that pole is
residue (at z = a) = (z −a)zn−1

(a −b)z−1
(1 −az−1)(1 −bz−1)

z=a
= an
Therefore, x(n) = an, n > 0. To ﬁnd x(n) for n < 0 we note that X(z) has a pole
outside the contour at z = b and the residue of X(z)zn−1 at that pole is
residue (at z = b) = (z −b)zn−1

(a −b)z−1
(1 −az−1)(1 −bz−1)

z=b
= −bn
Therefore, x(n) = bn, n < 0. To ﬁnd x(0) we expand X(z) into its causal and
anticausal fractions:
X(z) =
1
1 −az−1 −
1
1 −bz−1
The ﬁrst term here is the z-transform of the causal part of x(n) and the second term
is that of its anticausal part. By setting z = ∞in the causal part and z = 0 in the
anticausal part of X(z) we ﬁnd their contributions to x(0) to be
1
1 −az−1

z=∞
= 1, and
1
1 −bz−1

z=0
= 0
Consequently, x(0) = 1 + 0 = 1 and
x(n) =

an,
n ≥1
bn,
n < 0
which may be rewritten as x(n) = anu(n −1) + bnu(−n). This is in agreement with
the result of Example 15.4.
Example
15.34
Two-sided function
Find the inverse z-transform of
X(z) =
az−1
1 −az−1 −
1
1 −bz−1 , |a| < |z| < |b|. (See Figure 15.9).

Signals and Systems
859
8
2
4
6
–8
–4
–6
–2
0
–0.1
0
0.2
0.3
0.1
0.4
0.5
0.6
0.7
0.8
a
b
Im[z]
Re[z]
C
FIGURE 15.9 (For Example 15.34) The inverse of X(z) =
az−1
1−az−1 −
1
1−bz−1 , |a| <
|z| < |b|, is the two-sided function x(n) = anu(n −1) + bnu(−n −1) = anu(n) +
bnu(−n) −2d(n). In Figure 15.9 a = 1
b = 0.716.
Solution
X(z) has a pole at z = a (inside the integration contour) and a pole at z = b (outside
the integration contour).
Residue (at z = a) = (z −a)zn−1

az−1
1 −az−1 −
1
1 −bz−1

z=a
= an
Therefore, x(n) = an, n > 0. Also,
residue (at z = b) = (z −b)zn−1

az−1
1 −az−1 −
1
1 −bz−1

z=b
= −bn
Therefore, x(n) = bn, n < 0. To ﬁnd x(0) we examine the causal and anticausal parts
of the function.
From the causal part:
⇒
az−1
1 −az−1

z=∞
= 0
From the anticausal part:
⇒
1
1 −bz−1

z=0
= 0
In either case the value of the function at n = 0 is found to be zero. In summary,
x(n) =





an,
n > 0
bn,
n < 0
0,
n = 0
15.11
Relationship Between the s- and z-Planes
In this section we summarize the relationship between the Laplace transform of a
continuous-time function and the z-transform of its sampled sequence. We will use
 and F to represent continuous-time frequency.

860
CHAPTER 15
The z-Transform and Its Applications
The Laplace Transform
The two-sided Laplace transform of a continuous-time function x(t) is deﬁned by
X(s) =
 ∞
−∞
x(t)e−stdt
where s is a complex number normally written as s = σ + j. For X(s) to exist, s may
be limited to a region in the s-plane. An example of a Laplace transform pair is
x(t) = eatu(t), X(s) =
1
s −a , σ > a
The z-Transform
A continuous-time signal x(t) may be uniformly sampled every T seconds to produce
the discrete-time signal x(n) ≡x(nT ). The z-transform X(z) of the discrete-time signal
may be evaluated directly. As an example,
x(n) = eaT nu(n),
X(z)=
∞

n=−∞
x(n)z−n=
∞

n=0
eaT nz−n =
1
1 −eaT z−1 ,
|z| > eaT
Converting the Laplace Transform X (s) to the z-Transform X (z)
The z-transform of a causal discrete-time signal may also be obtained from the Laplace
transform of the continuous-time signal by
X(z) =
 
residues of
X(s)
1 −esT z−1 at all poles of X(s)

For the anticausal signals one may use the time reversal property of the z-transform to
ﬁnd X(z) (Appendix 15A).
Continuous-Time Representation of a Sampled Signal
The sampled signal may also be represented by a continuous-time function, ˆx(t), made
of a train of impulses spaced every T seconds and weighted by x(nT ):
ˆx(t) = x(nT )δ(t −nT )
Then, ˆX(s) may be obtained as
ˆX(s) = X(z)

z=esT
The Laplace transform of ˆx(t) is a function of e−sT = e−σ T e−jT . It is seen that ˆX(s)
is a periodic function of . In other words, ˆX(s) repeats itself over horizontal strips of
width 2π in the s-plane as shown in Figure 15.10. For further details, see Chapter 10 and
16.

Signals and Systems
861
s-Plane
jΩ
2p
s
2p
2p
FIGURE 15.10 2π-wide horizontal strips in the s-plane representing periodicity of the Fourier
transform of a sampled function in the continuous-time domain.
Mapping Regions of Convergences
Let

z = ρe jθ
(in the z-plane)
s = σ + j
(in the s-plane)
The s-to-z transformation produces the following equations







z = esT
ρe jθ = eσ T e jT
ρ = eσ T
θ = T
The left-half of the s-plane (LHP) maps onto the region inside the unit circle in the
z-plane, because for σ < 0 we have eσ T < 1. Similarly, the right-half s-plane (RHP)
maps onto the region outside the unit circle in the z-plane. The j axis in the s-plane
maps onto the unit circle in the z-plane with the origin s = 0 going to z = 1. The LHP
maps inside and the RHP outside the unit circle. The general mapping from the s-plane
onto the z-plane is shown in Figure 15.11.
Example
15.35
Given X(s) =
s + 1
(s + 3)(s + 4),
RE[s] > −3, ﬁnd the z-transform of the discrete
signal.
Solution
X(z) =
 
residues of
s + 1
(s + 3)(s + 4)(1 −esT z−1) at s = −3, −4

=
s + 1
(s + 4)(1 −esT z−1)

s=−3
+
s + 1
(s + 3)(1 −esT z−1)

s=−4
=
−2
1 −e−3T z−1 +
3
1 −e−4T z−1 , |z| > e−3T

862
CHAPTER 15
The z-Transform and Its Applications
(a)
Im[z]
Re[z]
eaT
Re[z]
s-Plane
a
jΩ
σ
z-Plane
esT
z
esT
z
esT
z
(b)
Im[z]
Re[z]
e–bT
s-Plane
–b
jΩ
σ
z-Plane
(c)
Im[z]
e–bT
s-Plane
–b
a
jΩ
σ
z-Plane
eaT
FIGURE 15.11 General mappings from the s-plane onto the z-plane: (a) anticausal function,
(b) causal function, (c) two-sided function.

Signals and Systems
863
Example
15.36
a.
Find the Laplace transform of x(t) =

−2e−3t + 3e−4t
u(t).
b.
Sample x(t) at the rate of 10 samples per second and obtain its z-transform
directly from x(n).
c.
Derive X(z) from X(s) and verify that it is the same result as in b.
Solution
a.
The Laplace transform:
X(s) =
 ∞
0
[−2e−3t + 3e−4t]e−stdt =
s + 1
(s + 3)(s + 4), RE[s] > −3
b.
The z-transform:
x(n) = x(t)

t=0.1n =

−2e−0.3n + 3e−0.4n
u(n)
=

−2(0.7408)n + 3(0.6703)n
u(n)
X(z) =
−2
1 −0.7408z−1 +
3
1 −0.6703z−1 , |z| > 0.7408
c.
The z-transform from the Laplace transform:
X(z) =
 
residues of
s + 1
(s + 3)(s + 4)(1 −esT z−1) at s = −3, −4

=
s + 1
(s + 4)(1 −esT z−1)

s=−3, T =0.1
+
s + 1
(s + 3)(1 −esT z−1)

s=−4, T =0.1
=
−2
1 −0.7408z−1 +
3
1 −0.6703z−1 , |z| > 0.7408
The expressions for the z-transform obtained in b and c are identical.
Example
15.37
Consider the bilateral signal
x(t) = e−a|t|, a > 0,
−∞< t < ∞
a.
Find the Laplace transform of x(t) and determine its region of convergence.
b.
Sample x(t) every T seconds to ﬁnd the discrete-time function x(n) ≡x(nT ).
Derive X(z) from X(s) and also by the direct method. Specify its ROC.

864
CHAPTER 15
The z-Transform and Its Applications
Solution
a.
X(s) =
 ∞
−∞
e−a|t|estdt =
−1
s −a +
1
s + a =
−2a
s2 −a2
−a < σ < a
b.
X+(z) =
 
residue of
1
(s + a)(1 −esT z−1) at s = −a

=
1
1 −e−aT z−1 ,
|z| > e−aT
X−(z) = X+
1
z

=
1
1 −e−aT z , |z| < eaT
(using time-reversal property of the z-transform, Appendix 15A)
X(z) = X+(z) + X−(z) −1 =
1
1 −e−aT z−1 +
1
1 −e−aT z −1
=
(e−aT −eaT )z−1
(1 −e−aT z−1)(1 −eaT z−1), e−aT < |z| < eaT
By direct method:
x(n) = e−aT nu(n) + eaT nu(−n) −d(n)
X(z) =
1
1 −e−aT z−1 +
1
1 −e−aT z −1
=
(e−aT −eaT )z−1
(1 −e−aT z−1)(1 −eaT z−1), e−aT < |z| < eaT

Signals and Systems
865
Appendix 15A Table of z-Transform Properties
and Theorems
Property
n-domain
⇐⇒
z-domain
ROC
1
Deﬁnition
x(n) =
1
2π j

X(z)zn−1dz
⇐⇒
X(z) =
∞

−∞
x(n)z−n
Rx
2
Linearity
ax(n) + by(n)
⇐⇒
aX(z) + bY(z)
Rx ∩Ry
3
Time shift
x(n −k)
⇐⇒
X(z)z−k
Rx
4
Time reversal
x(−n)
⇐⇒
X(1/z)
1/Rx
5
Multiplication by n
nx(n)
⇐⇒
−z d X(z)
dz
Rx
6
Conjugate
x∗(n)
⇐⇒
X ∗(z∗)
Rx
7
Real
RE[x(n)]
⇐⇒
1
2[X(z) + X ∗(z∗)]
Rx
8
Imaginary
IM[x(n)]
⇐⇒
1
2 j [X(z) −X ∗(z∗)]
Rx
9
Multiplication by an
anx(n)
⇐⇒
X(a−1z)
|a|Rx
10
Convolution
x(n) ⋆y(n)
⇐⇒
X(z)Y(z)
Rx ∩Ry
11
Multiplication
x(n)y(n)
⇐⇒
X(z) ⋆Y(z)
=
1
2π j

c
X(ν) Y(z/ν)ν−1dν
Rx ∩Ry
Theorems
Zero n, for causal functions:
x(0) = limz→∞X(z)
Zero n, for anticausal functions:
x(0) = limz→0 X(z)
Zero z:
X(0) =
∞

−∞
x(n)
Parseval’s theorem:
∞

−∞
|x(n)|2 =
1
2π j

c
X(z)X ∗(1/z∗)z−1dz
∞

−∞
x(n)y∗(n) =
1
2π j

c
X(z)Y ∗(1/z∗)z−1dz

866
CHAPTER 15
The z-Transform and Its Applications
Appendix 15B Table of z-Transform Pairs
x(n) =
1
2πj

C X (z)z n−1dz
⇐⇒
X (z) = ∞
−∞x(n)z −n
ROC
a.
d(n)
⇐⇒
1
all z
b.
d(n −n0)
⇐⇒
z−n0
z ̸= 0 (n0 > 0)
z ̸= ∞(n0 < 0)
c.

1,
0 ≤n ≤N −1
0,
elsewhere
⇐⇒
1 −z−N
1 −z−1
z ̸= 0
d.

1,
−M ≤n ≤M
0,
elsewhere
⇐⇒
zM −z−M
1 −z−1
z ̸= 0
e.

an,
0 ≤n ≤N −1
0,
elsewhere
⇐⇒
1 −aNz−N
1 −az−1
z ̸= 0
f.
u(n)
⇐⇒
1
1 −z−1
|z| > 1
g.
u(−n)
⇐⇒
−z−1
1 −z−1 =
1
1 −z
|z| < 1
h.
anu(n)
⇐⇒
1
1 −az−1
|z| > |a|
i.
anu(−n)
⇐⇒
1
1 −a−1z =
−az−1
1 −az−1
|z| < |a|
j.
−anu(n −1)
⇐⇒
1
1 −a−1z =
−az−1
1 −az−1
|z| > |a|
k.
−anu(−n −1)
⇐⇒
1
1 −az−1
|z| < |a|
l.
a−|n|u(n), |a| > 1
⇐⇒
1
1 −a−1z +
1
1 −a−1z−1 −1

1
a
 < |z| < |a|
m.
nanu(n)
⇐⇒
az−1
(1 −az−1)2
|z| > |a|
n.
cos(ωn)u(n)
⇐⇒
1 −(cos ω)z−1
1 −2(cos ω)z−1 + z−2
|z| > 1
o.
sin(ωn)u(n)
⇐⇒
(sin ω)z−1
1 −2(cos ω)z−1 + z−2
|z| > 1
p.
an cos(ωn)u(n)
⇐⇒
1 −a(cos ω)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > |a|
q.
an sin(ωn)u(n)
⇐⇒
a(sin ω)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > |a|
r.
an cos(ωn + θ)u(n)
⇐⇒
cos θ −a cos(ω −θ)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > |a|
s.
an sin(ωn + θ)u(n)
⇐⇒
sin θ + a sin(ω −θ)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > |a|

Signals and Systems
867
15.12
Problems
Solved Problems
1. a. Find the z-transform of x1(n) = 2nu(n) and indicate its region of convergence.
b. Find the z-transform of x2(n) = 2−nu(−n) and indicate its region of convergence.
c. Deﬁne x(n) = x1(n) + x1(n) = 2|n|. Does x(n) have a z-transform? If the answer is positive, ﬁnd X(z) and if
negative, state the reason why not.
d. Let x(n) = 2|n| pass through an LTI system with the unit-sample response h(n) = d(n) + d(n −1) + d(n −2).
Find the output and specify its value for −5 ≤n ≤7.
Solution
From the table of transform pairs of Appendix 15B we obtain
a. X1(z) =
1
1 −2z−1 , |z| > 2.
b. X2(z) =
1
1 −2−1z =
2
2 −z =
−2z−1
1 −2z−1 , |z| < 2.
c. x(n) doesn’t have a z-transform because the intersection of |z| > 2 and |z| < 2 is null.
d. y(n) = x(n) + x(n −1) + x(n −2) = 2|n| + 2|n−1| + 2|n−2|.
n
−5
−4
−3
−2
−1
0
1
2
3
4
5
6
7
x(n)
32
16
8
4
2
1
2
4
8
16
32
64
128
x(n −1)
64
32
16
8
4
2
1
2
4
8
16
32
64
x(n −2)
128
64
32
16
8
4
2
1
2
4
8
16
32
y(n)
224
112
56
28
14
7
5
7
14
28
56
112
224
Note: The lack of the z-transform of the input doesn’t lead to a lack of a well-deﬁned output.
2. Using a lookup table, ﬁnd the inverse of the following bilateral z-transforms
a. X1(z) =
z
1 −3z , ROC:|z| > 1
3
b. X2(z) =
z
1 −3z , ROC:|z| < 1
3
Verify your answers by taking their transforms through the deﬁnition.
Solution
The ROCs for x1(n) and x2(n) are outside and inside, respectively, the circle in the z-plane with radius 1/3, indicating
a right-sided x1(n) and a left-sided x2(n). Rewrite the transforms as shown below and ﬁnd their inverses using the
lookup table of Appendix 15B. [Also, consider the shift property in the case of X2(z).]
a. X1(z) =
z
1 −3z =
−3−1
1 −3−1z−1 ,
|z| > 1
3, right-sided time function
x1(n) = −3−(n+1)u(n)
b. X2(z) =
z
1 −3z ,
|z| < 1
3, left-sided time function
x2(n) = 3−(n+1)u(−n −1)

868
CHAPTER 15
The z-Transform and Its Applications
To validate the above answers, we take their z-transforms and observe that they agree with what was given originally.
a. X1(z) = −
∞

n=0
3−(n+1)z−n = −
∞

n=0
1
3(3z)−n = −1
3
1
1 −(3z)−1 =
z
1 −3z
b. X2(z) =
−1

n=−∞
3−(n+1)z−n = 1
3
∞

m=1
(3z)m = 1
3

1
1 −3z −1

=
z
1 −3z
3. Find all possible h(n) functions, which may correspond to
H(z) =
−3z
z2 −3z + 2
Solution
For convenience and ease of using the lookup table, we write H(z) as a function of z−1 and expand it into its partial
fractions.
H(z) =
−3z−1
1 −3z−1 + 2z−2 =
−3z−1
(1 −z−1)(1 −2z−1) =
3
1 −z−1 −
3
1 −2z−1
Then we recognize three possible regions of convergence in the z-plane, which yield the following three time
functions.
|z| > 2,
ROC is outside the circle. The function is right-sided:
h1(n) = 3 (1 −2n) u(n)
1 < |z| < 2,
ROC is an annular region. The function is two-sided:
h2(n) = 3u(n) + 3(2n)u(−n −1)
|z| < 1,
ROC is inside the circle. The function is left-sided:
h3(n) = −3u(−n) + 3(2n)u(−n).
4. The z-transform of the impulse response of a causal LTI system is
H(z) = 1
2
z−1
z−2 −4.5z−1 + 5
a. Identify the region of convergence.
b. Find h(n).
c. Is the system stable? Discuss it in the z-domain and n-domain.
d. Find an input x(n) that would produce the output y(n) = u(−n) + (0.5)nu(n).
Solution
a. and b.
H(z) = 1
2
z−1
z−2 −4.5z−1 + 5 =
0.1z−1
(1 −0.5z−1)(1 −0.4z−1) =
1
1 −0.5z−1 −
1
1 −0.4z−1 , z > 0.5
h(n) = [0.5n −0.4n]u(n)
c. The system is stable because the poles of the system function are inside the unit circle and, as a result, h(n) is
made of exponentially decaying exponentials.
d. We ﬁrst ﬁnd Y(z) and its ROC.
u(−n)
⇒
1
1 −z
|z| < 1
0.5nu(n)
⇒
1
1 −0.5z−1
|z| > 0.5
y(n) = u(−n) + 0.5nu(n) ⇒
Y(z) =
1
1 −z +
1
1 −0.5z−1 =
2 −0.5z−1 −z
(1 −z)(1 −0.5z−1)
0.5 < |z| < 1

Signals and Systems
869
X(z) = Y(z)
H(z) =
2 −0.5z−1 −z
(1 −z)(1 −0.5z−1) × (1 −0.5z−1)(1 −0.4z−1)
0.1z−1
= (2 −0.5z−1 −z)(1 −0.4z−1)
(1 −z) × 0.1z−1
= 10z −14 + 2z−1 −
3
z −1, |z| < 1
x(n) = 10d(n + 1) −14d(n) + 2d(n −1) + 3u(−n)
Should We Work with z or z −1?
In the z-domain analysis of discrete-time signals and systems, one may employ the variable z or z−1, whichever
makes the analysis easier. Below, we repeat problem 4 by employing polynomials of z.
H(z) =
z
10(z2 −0.9z + 0.2) =
z
10(z −0.5)(z −0.4) =
z
z −0.5 −
z
z −0.4, z > 0.5
h(n) = [0.5n −0.4n]u(n)
Y(z) =
−1
z −1 +
z
z −0.5 =
z2 −2z + 0.5
(z −1)(z −0.5)
X(z) = Y(z)
H(z) = 10(z2 −2z + 0.5)(z −0.4)
(z −1)z
= 10z3 −24z2 + 13z −2
z2 −z
= 10z −14 + 2z−1 −
3
z −1, |z| < 1
x(n) = 10d(n + 1) −14d(n) + 2d(n −1) + 3u(−n)
5. The unit-sample response of a causal discrete-time LTI system is measured and modeled by
h(n) = 0.4n cos
πn
4
	
u(n)
a. Find H(z).
b. Find the system’s input-output difference equation.
c. Find the unit-step response by solving the difference equation.
d. Find the unit-step response by the z-transform method.
Solution
a. From the lookup table,
an cos(ωn)u(n)
⇒
1 −a cos ωz−1
1 −2a cos ωz−1 + a2z−2
h(n) = 0.4n cos
 πn
4

u(n)
⇒
H(z) =
1 −0.2
√
2z−1
1 −0.4
√
2z−1 + 0.16z−2 = Y(z)
X(z)
b. From the unit-sample response,
Y(z)
1 −0.4
√
2z−1 + 0.16z−2
= X(z)
1 −0.2
√
2z−1
y(n) −0.4
√
2y(n −1) + 0.16y(n −2) = x(n) −0.2
√
2x(n −1)
c. The characteristic equation is r 2 −0.4
√
2r + 0.16 = 0. Its roots are r1,2 = 0.4e± jπ/4. The particular solution to
a unit-step input is
H(z)|z=1 =
1 −0.2
√
2
1 −0.4
√
2 + 0.16
= 1.207

870
CHAPTER 15
The z-Transform and Its Applications
The overall response to a unit-step input is
g(n) = 1.207 + C(0.4)n cos
πn
4 + θ
	
The constants C and θ are found by substituting the initial conditions into the solution. The initial conditions are
g(0) = 1 and g(1) = 1 −0.2
√
2 + 0.4
√
2 = 1 + 0.2
√
2.
Therefore,

g(0) = 1 = 1.207 + C cos(θ) = 1
g(1) = 1 + 0.2
√
2 = 1.207 + 0.4C cos( π
4 + θ)
⇒

C cos(θ) = −0.207
C cos( π
4 + θ) = 0.1896
⇒

θ = 66.4◦
C = −0.52
g(n) =

1.207 −0.52(0.4)n cos
πn
4 + 66.4◦	
u(n)
d. First, ﬁnd the z-transform of the unit-step response and expand it into partial fractions that could be matched
with some entries in the lookup table.
g(n) = h(n) ⋆u(n)
G(z) = H(z) ×
1
1 −z−1 =
1 −0.2
√
2z−1
(1 −z−1)(1 −0.4
√
2z−1 + 0.16z−2)
=
1.207
1 −z−1 +
−0.207 + 0.193z−1
1 −0.4
√
2z−1 + 0.16z−2
From the table,
an cos(ωn + θ)u(n)
⇒
cos θ −a cos(ω −θ)z−1
1 −2a cos ωz−1 + a2z−1
−0.52(0.4)n cos
πn
4 + 66.4◦	
⇐
−0.207 + 0.193z−1
1 −0.4
√
2z−1 + 0.16z−2
The unit-step response in the z and n domain is, therefore,
G(z) =
1.207
1 −z−1 +
−0.207 + 0.193z−1
1 −0.4
√
2z−1 + 0.16z−2
g(n) =

1.207 −0.52(0.4)n cos
πn
4 + 66.4◦	
u(n)
Chapter Problems
6. Find X(z) and the region of convergence for each x(n) given in Table 15.1. You may quote X(z) from Table 15.2
and the ROC from Table 15.3.
TABLE 15.1 Functions
x(n)
X(z)
ROC
anu(n)
a−nu(n)
anu(−n)
a−nu(−n)
TABLE 15.2 X(z)
X(z)
1
−az−1/(1 −az−1)
2
−a−1z−1/(1 −a−1z−1)
3
1/(1 −az−1)
4
1/(1 −a−1z−1)
TABLE 15.3 ROC
ROC
A
|z| > |a|
B
|z| > 1/|a|
C
|z| < |a|
D
|z| < 1/|a|

Signals and Systems
871
7. a. Find the z-transform of x1(n) = 6nu(n) and indicate its region of convergence on the z-plane.
b. Find the z-transform of x2(n) = 6−nu(−n) and indicate its region of convergence on the z-plane.
8. Find X(z) and the region of convergence for each x(n) function of Table 15.4. You may quote X(z) from Table
15.5 and the ROC from Table 15.6.
TABLE 15.4 Functions
x(n)
X(z) ROC
(0.5)nu(n)
(0.5)nu(−n)
(0.5)−nu(n)
(0.5)−nu(−n)
(−0.5)nu(n)
(−0.5)nu(−n)
(−0.5)−nu(n)
(−0.5)−nu(−n)
(2)nu(n)
(2)nu(−n)
(2)−nu(n)
(2)−nu(−n)
(−2)nu(n)
(−2)nu(−n)
(−2)−nu(n)
(−2)−nu(−n)
TABLE 15.5 X(z)
X(z)
1
2z−1/(1 + 2z−1)
2
1/(1 + 0.5z−1)
3
−0.5z−1/(1 −0.5z−1)
4
1/(1 −2z−1)
5
0.5z−1/(1 + 0.5z−1)
6
−2z−1/(1 −2z−1)
7
1/(1 + 2z−1)
8
1/(1 −0.5z−1)
9
None of the above
TABLE 15.6 ROC
ROC
A
|z| < 0.5
B
|z| > 0.5
C
|z| < 2
D
|z| > 2
9. Find H(z) for
a. h(n) = 0.3nu(n)
b. h(n) = 0.3−nu(−n)
10. Find the z-transform of x(n) = 2−3|n| and specify its region of convergence.
11. Consider the following discrete-time signal
x(n) =
 0,
n < 0
2,
0 ≤n ≤4
1,
n > 4
a. Express x(n) as an algebraic sum of weighted discrete-time step functions u(n).
b. Find X(z) as a function of z−1. Simplify your answer in the form of a ratio of two polynomials.
12. A discrete-time function x(n) is given by:
x(n) =
 0,
n < 0
1,
0 ≤n ≤4
2,
n > 4
a. Express x(n) as a sum of step functions.
b. Find X(z) in the form of the ratio of two polynomials and specify the region of convergence.

872
CHAPTER 15
The z-Transform and Its Applications
13. The unit-sample response h(n) of a digital ﬁlter is
h(n) =

1,
0 ≤n < N
0,
elsewhere
Find a closed-form expresion for H(z) and determine its ROC.
14. Given X(z) = −1/(3 −z−1), |z| < 1
3, ﬁnd its inverse z-transform x(n) and plot it for −5 ≤n ≤5.
15. Given
X(z) =
1 + 2z−1 + z−2
(1 −0.5z−1)(1 −z−1)
ﬁnd x(n) for the regions of convergence in Table 15.7. You may quote x(n) from Table 15.8.
TABLE 15.7 ROC
ROC
a
0.5 < |z| < 1
b
|z| > 1
c
|z| < 0.5
TABLE 15.8 Time Functions
x(n)
1
2d(n) −9(0.5)nu(n) + 8u(n)
2
2d(n) −9(0.2)nu(n) + 8u(n)
3
2d(n) + 9(0.5)nu(−n −1) −8u(−n −1)
4
2d(n) −9(0.5)nu(n) −8u(−n −1)
5
2d(n) −9(0.5)nu(n) + 8u(−n)
16. Find a causal signal x(n) whose z-transform is
X(z) =
1
1 −0.25z−2
17. Find h(n), the inverse z-transform of H(z), for
a. H(z) =
1
1 −0.25z−1 , |z| < 0.25
b. H(z) =
1
1 −0.25z−1 , |z| > 0.25
18. Determine, in closed form, the impulse response h(n) of a causal ﬁlter characterized by
H(z) =
1
1 −1.5z−1 + 0.5z−2
Draw the block diagram that implements the above ﬁlter.
19. Given
H(z) =
1
1 −0.5z−1 +
1
1 −0.4z−1
ﬁnd h(n) for the three ROC given below.
a. |z| > 0.5
b. |z| < 0.4
c. 0.4 < |z| < 0.5
20. The system function of a causal system is given by
H(z) =
z−1
1 −0.5z−1

Signals and Systems
873
a. Find the unit-sample response of the system, h(n).
b. Find the unit-step response of the system and its steady state value.
c. Find the unit-ramp response of the system and its steady state yss(n).
d. Find the response of the system to a left-sided unit step x(n) = u(−n).
21. Find the overall unit-sample response of the negative feedback system in which the unit-sample response of the
forward path is h1(n) = 0.3nu(n) and that of the feedback path is h2(n) = d(n −1).
22. Find the unit-sample response of the negative-feedback system made of h1(n) = 0.4nu(n) and h2(n) = d(n −1)
when
a. h1(n) is in the forward path and h2(n) is in the feedback path
b. h2(n) is in the forward path and h1(n) is in the feedback path.
23. The transfer function of a causal system is given by H(z) = z−1/(1 + z−1).
a. Find the response of the system to a unit step u(n).
b. Find the steady-state response of the above system to a sinusoidal input sin(ω0n).
24. The unit-sample response of an LTI system is h(n) = 0.5nu(n).
a. Find the transfer function of the system.
b. Examine the system’s stability using H(z).
c. Given an input x(n) = 0.3nu(n), ﬁnd Y(z) and y(n).
25. a. Find the z-transform of x(n) = 3−|n|, −∞< n < ∞.
b. The above x(n) passes through an LTI system with the unit-sample response h(n) = 0.5nu(n). Find y(n) for
all n.
26. The unit-sample response of an LTI system is h(n) = 2−nu(n).
a. Find the system function H(z).
b. For x(n) = u(n) ﬁnd Y(z), y(n), and yss(n).
27. The autocorrelation function, c(n), of a time function h(n) is deﬁned by
c(n) =
∞

k=−∞
h(k)h(k + n)
a. Let C(z) be the z-transform of c(n). Show that
C(z) = H(z)H(z−1)
b. Can you use the above to ﬁnd c(n) for h(n) = 2nu(n)?
c. Use the above to ﬁnd c(n) for h(n) =
√
3(0.5)nu(n).
d. Can you ﬁnd two different time functions that produce the same c(n)? If the answer is positive provide an
example, and if it is negative discuss why not.
28. The system function of a continuous-time LTI system is:
H(s) =
s + 1
s2 + 2s + 2
The unit-impulse response and unit-step response of the system are shown by h(t) and g(t), respectively. It is desired
to transform the above system function to a discrete-time system. The unit-sample and unit-step responses of the
discrete system will be shown by h(n) and g(n), respectively.

874
CHAPTER 15
The z-Transform and Its Applications
a. Sample the unit-impulse response to produce a discrete-time system for which h1(n) ≡h(nT ). Call its system
function H1(z). The method is called impulse-invariance transformation.
b. Sample the unit-step response to produce a discrete-system for which g2(n) ≡g(nT ). Call its system function
H2(z). The method is called step-invariance transformation.
c. Determine the unit-step response of the ﬁrst system g1(n) and the unit-sample response of the second system
h2(n). Remember the relation between unit-sample and unit-step responses.
g(n) =
n

k=−∞
h(k),
and g(t) =

t
−∞
h(τ)dτ
Which of the following statements are true? Explain.
(i) h1(n) = h2(n)
(ii) g1(n) = g2(n)
(iii) None of the above
29. The unit-impulse response of a continuous-time system is h(t) = etu(t). Find its Laplace transform and the region
of convergence. h(t) is sampled at the rate of 5 samples per sec producing the discrete-time unit-sample response
h(n). Find the z-transform H(z) and the region of convergence. Determine important features in mapping from s-
to z-domain.
30. The Laplace transform of a time function is given by
X(s) =
2s + 7
s2 + 7s + 12
along its region of convergence R. The time function is sampled at the rate of 100 samples per sec, producing the
discrete-time function x(n). Find the z-transform X(z) and its region of convergence for when
a. R is σ < −4
b. R is −4 < σ < −3
c. R is σ > −3
15.13
Project 1: FIR Filter Design by Zero
Placement
Summary
In this project you will design an FIR ﬁlter by placing a pair of zeros of the system function on the unit circle at the
discrete frequency corresponding to a 1-kHz continuous-time sinusoid, and explore the advantages and limitations of this
design method. The zeros block 1-kHz signals. The function of the ﬁlter is to extract the signal from the data by removing
additive sinusoidal disturbances at 1 kHz. The ﬁlter’s operation will be tested off-line on synthetic data and on sound
ﬁles sampled at 8 kHz using Matlab. The real-time operation of the ﬁlter will then be evaluated by running it on a DSP
platform such as the Texas Instruments’ Starter Kit, and its frequency response will be compared with theory.
Equipment and Tools
Software package for signal processing
Hardware platform (PC, sound card, or DSP board)
Microphone
Assignments and Reporting.
Read and do the Prelab, Filtering, and Discussion and Conclusions.

Signals and Systems
875
Theory
Contributions from the Zeros to the Frequency Response.
The frequency of a continuous-time sinusoidal
waveform is mapped onto the unit circle of the z-plane. To block a certain frequency, the ﬁlter should have a zero on the
unit circle at that frequency. Zeros of ﬁlters with real coefﬁcients are complex conjugates of each other and a pair of zeros
at e± jω0 will contribute the multiplier term
(1 −e jω0z−1)(1 −e−jω0z−1) = 1 −2 cos ω0z−1 + z−2
to H(z). If a ﬁlter has no poles, H(z) is a polynomial and the ﬁlter is an FIR ﬁlter. An FIR notch ﬁlter with real coefﬁcients
and zeros on the unit circle has linear phase.
Prelab
Generating a Gaussian Signal.
Using Matlab generate and save a 1,024-point-long signal made of a zero-mean
Gaussian random process with a variance of 1 V and uniform spectral density over the bandwidth 0 to 4 kHz. The sampling
rate should be 8 kHz.
Design of an FIR Notch Filter.
Design a 3-tap notch ﬁlter to meet the following analog speciﬁcations:
Filter: 3-tap FIR
Sampling rate = 8 kHz
Notch frequency = 1 kHz
High frequency gain = 1
Place a pair of conjugate zeros at z1,2 = e± jω0, where ω0 is the discrete notch frequency corresponding to 1 kHz. Find
H(z) and h(n). Plot its frequency response using the uniform and dB scales. Measure the 3-dB bandwidth. Compute the
percentage reduction in the power of the synthetic noise when it passes through the ﬁlter. (The Matlab ﬁle given below
may be used.)
Partial Solution.
Speciﬁcations of the digital ﬁlter are ω0 = 2π × 1,000/8,000 = π/4 and
H(z) = k(1 −2 cos(π/4)z−1 + z−2) = k(1 −
√
2z−1 + z−2), k = 1/(2 +
√
2)
The above H(z) has a pair of zeros at e± jπ/4 only and its high-frequency gain (at z = −1) is unity. The magnitude and
phase of the frequency response of the ﬁlter are computed and plotted in Figure 15.12 by the Matlab ﬁle given below. It
is noted that the 3-dB bandwidth of the ﬁlter is very large, making it in fact more like a high-pass ﬁlter.
w=linspace(0,pi,100);
z=exp(i*w); k=1/(2+sqrt(2));
H=k*(1-sqrt(2)*z.√(-1)+z.√(-2));
subplot(2,1,1);
plot(w/pi,abs(H)); grid
title('FIR notch filter, gk10d.m');
ylabel('Magnitude, linear scale');
xlabel('Angular frequency (normalized by Pi)');
subplot(2,1,2);
plot(w/pi,180/pi*angle(H)); grid
ylabel('Phase, degrees');
xlabel('Angular frequency (normalized by Pi)');

876
CHAPTER 15
The z-Transform and Its Applications
0
0.2
0.4
0.6
0.8
Magnitude, linear scale
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Angular frequency (normalized by Pi)
1
1
–50
0
50
100
Phase, degrees
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Angular frequency (normalized by Pi)
1
150
FIGURE 15.12 Magnitude and phase responses of the FIR notch ﬁlter with a pair of zeros at
e± jπ/4.
Filtering
Filtering Synthetic Data.
Using Matlab, generate a 1,024-point-long sequence of data made of a 1-kHz sinusoidal
disturbance (with rms = 0.1 V) added to a zero-mean Gaussian signal with a variance of 1 V and uniform spectral density
over the bandwidth 0 to 4 kHz (as you did above). The sampling rate should be 8 kHz. Pass the data through the ﬁlter.
Find the percentage rms difference between the output of the ﬁlter and its input.
Filtering Prerecorded Speech.
Repeat the section above using the prerecorded speech ﬁle.
Measuring the Frequency Response.
Load the ﬁlter coefﬁcients into the Starter Kit board and measure the mag-
nitude and phase of its frequency response from 0 to 4 kHz. Seven measurements taken at important points within the
above range would sufﬁce.
Filtering Live Speech.
Load the ﬁlter into the Starter Kit board and qualitatively explore its real-time performance
on live speech (to which sinusidal disturbance may be added). For this purpose, add a live speech signal coming out of the
microphone to a periodic disturbance obtained from the function generator. You may use an op-amp circuit. Normalize
the speech signal to 1 V rms and add the 1-kHz sinusoid at 0.1 V rms. Repeat for higher and lower signal-to-noise ratios.
Discussion and Conclusions
Effect of Sampling Rate.
Discuss the effect of the sampling rate on the performance of the 3-tap FIR notch ﬁlter. For
example, ﬁnd the 3-dB bandwidth of the ﬁlter if the sampling rate is reduced to 4 kHz.
Overall Conclusions.
Qualitatively describe the deﬁciencies of the 3-tap FIR notch ﬁlter in this experiment and
propose two other designs that would remedy them.

Signals and Systems
877
15.14
Project 2: IIR Filter Design by Pole/Zero
Placement
Summary
In this project you will design a digital IIR notch ﬁlter that, when run under an 8-kHz sampling rate, will block 1-kHz
sinusoids and have a bandwidth of 50 Hz. Blocking the sinusoid is accomplished by placing a pair of zeros at the notch
frequency. The narrow bandwidth is achieved by placing a pair of poles inside the unit circle. The ﬁlter’s operation will
be tested off-line on sound ﬁles sampled at 8 kHz, using Matlab. Real-time operation of the ﬁlter will then be evaluated
by running it on a DSP platform such as the Texas Instruments’ Starter Kit, and its frequency response will be compared
with the theory.
Equipment and Tools
Software package for signal processing
Hardware platform (PC, sound card, or DSP board)
Microphone
Assignments and Reporting.
Read and do the following.
Theory
Contributions from Zeros and Poles to the Frequency Response.
The frequency of a continuous-time sinusoidal
waveform is mapped onto the unit circle of the z-plane. To block a certain frequency, the ﬁlter should have a zero on the
unit circle at that frequency. Zeros of ﬁlters with real coefﬁcients are complex conjugates of each other and a pair of zeros
at e± jω0 will contribute the following multiplier term to the numerator of H(z):
(1 −e jω0z−1)(1 −e−jω0z−1) = 1 −2 cos ω0z−1 + z−2
The zeros at e± jω0 not only remove signals at the frequency ω0, but also greatly attenuate the neighboring frequencies.
This is because the bandwidth of the notch due to the zero is very wide. A pair of nearby poles at ρe± jω0 will contribute
(1 −ρe jω0z−1)(1 −ρe−jω0z−1) = 1 −2ρ cos ω0z−1 + ρ2z−2
to the denominator of the system function, narrowing the notch bandwidth. Recall the vectorial interpretation of the
frequency response: the closer the pole is to the unit circle, the narrower the bandwidth will become. The poles, however,
should be inside the unit circle because of stability conditions. The system function is, therefore,
H(z) = k
1 −2 cos ω0z−1 + z−2
1 −2ρ cos ω0z−1 + ρ2z−2
The factor k is chosen according to the desired gain at a given frequency (e.g., DC or high frequency).
Prelab
Design of an IIR Notch Filter.
Design an IIR notch ﬁlter to meet the following analog speciﬁcations:
Notch frequency = 1 kHz
3-dB attenuation bandwidth = 50 Hz
DC (or high frequency) gain = 1
Sampling rate = 8 kHz
First compute the frequency-domain notch frequency ω0 and the ﬁlter’s bandwidth ω0. To block the 1-kHz sinusoidal
distrurbance, place two zeros at z1,2 = e± jω0, where ω0 corresponds to 1 kHz. As seen in Project 1, the resulting FIR is not
satisfactory. The notch bandwidth of the ﬁlter may be reduced by placing two conjugate poles at ρe± jω0 near the zeros.
The poles are, therefore, at the same angles as the zeros but inside the unit circle. The example given below provides a
starting point for pole placement.

878
CHAPTER 15
The z-Transform and Its Applications
Partial Solution.
Speciﬁcations of the digital ﬁlter are
ω0 = 2π × 1,000/8,000 = π/4 and ω0 = 2π × 50/8,000 = π/80
To start, consider an IIR ﬁlter with a pair of zeros on the unit circle at e± jπ/4 and a pair of poles inside the unit circle at
ρe± jπ/4.
H(z) = k
1 −
√
2z−1 + z−2
1 −ρ
√
2z−1 + ρ2z−2
There exist systematic methods for determining ρ (e.g., transformation from an analog notch ﬁlter). Here, however, we
ﬁnd the appropriate ρ by trial and error, starting with ρ = 0.96757. The Matlab ﬁle for obtaining and ploting the magnitude
response is shown below. The resulting magnitude plot is shown in Figure 15.13.
–10
–20
–30
–40
–50
–60
–70
Gain (db)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Digital angular frequency (unit of Pi)
1
0
–3.5
–3
Gain (db)
0.23
0.235
0.24
0.245
0.25
0.255
0.26
0.265
Digital angular frequency (unit of Pi)
0.27
–2.5
FIGURE 15.13 The magnitude response of the notch ﬁlter with a pair of zeros at e± jπ/4 and
a pair of poles at 0.96757e± jπ/4 is shown in the upper part. The notch frequency is at π/4. The
magniﬁcation (lower section) shows the 3-dB bandwidth ω = 0.023 × π = 0.125 (desired to
be π/80 = 0.0125π ≈0.04 rad).
r=0.96757;
k=(1-sqrt(2)*r+r√2)/(2-sqrt(2));
num=[1 -sqrt(2) 1];
den=[1 -sqrt(2)*r r√2];
w=0:0.002*pi:pi;
H=k*freqz(num,den,w);
gain=20*log10(abs(H));
figure(1)
subplot(2,1,1)

Signals and Systems
879
plot(w/pi,gain); grid;
axis([0 1
-75 0])
title('magnitude plot');
xlabel('digital angular frequency (unit of pi)');
ylabel ('gain (db)');
subplot(2,1,2)
plot(w/pi,gain);grid;
axis([0.23 0.27
-3.5 -2.5])
%title('magnified plot')
xlabel('digital angular frequency (unit of pi)');
ylabel ('gain (db)');
It is noted that the 3-dB bandwidth of the above ﬁlter is greater than the desired speciﬁcation. The poles need to be
moved closer to the unit circle. Try ρ = 0.98, 0.982593, and 0.99. Determine your choice for the ρ value to be used in
the next part (Filtering). Plot its frequency response using the dB scale. Measure the 3-dB bandwidth.
Filtering
Filtering Synthetic Data.
Using a software tool (e.g., Matlab), generate a 1,024-point-long sequence of data made
of a 1-kHz sinusoidal disturbance (with rms = 0.1 V) added to a zero-mean Gaussian signal with a variance of 1 V and
uniform spectral density over the bandwidth 0 to 4 kHz. The sampling rate should be 8 kHz. Pass the data through the
ﬁlter. Find the percentage rms difference between the output of the ﬁlter and its input.
Filtering Prerecorded Speech.
Repeat the section above using the prerecorded speech ﬁle.
Measuring the Frequency Response.
Load the ﬁlter coefﬁcients into the computer (hardware or software) and
measure the magnitude and phase of its frequency response from 0 to 4 kHz. Seven measurements taken at important
points within the above range would sufﬁce.
Filtering Live Speech.
Load the ﬁlter into the computer and qualitatively explore its real-time performance on live
speech (to which sinusidal disturbance may be added). For this purpose, add a live speech signal coming out of the
microphone to a periodic disturbance obtained from the function generator. You may use an op-amp circuit. Normalize
the speech signal to 1 V rms and add the 1-kHz sinusoid at 0.1 V rms. Repeat for higher and lower signal-to-noise ratios.
Discussion and Conclusions
Effect of Sampling Rate.
Discuss the effect of the sampling rate on the performance of the IIR notch ﬁlter. For
example, ﬁnd the 3-dB bandwidth of the ﬁlter if the sampling rate is reduced to 4 kHz.
Overall Conclusions.
Qualitatively describe possible deﬁciencies of the IIR notch ﬁlter in this experiment and propose
other designs that would remedy them.

Chapter16
Discrete-Time
Fourier Transform
Contents
Introduction and Summary
881
16.1
Deﬁnitions
883
16.2
Examples of DTFT
885
16.3
The DTFT and the z-Transform
889
16.4
Examples of IDTFT
890
16.5
Rectangular Pulse
893
16.6
DTFT Theorems and Properties
895
16.7
Parseval’s Theorem and Energy Spectral Density
900
16.8
DTFT of Power Signals: The Limit Approach
902
16.9
DTFT of Periodic Signals: The Convolution Approach
906
16.10
Zero-Insertion
909
16.11
Decimation
912
16.12
Interpolation
918
16.13
How Rate Conversion Reshapes DTFT
920
Appendix 16A A Short Table of DTFT Pairs
923
Appendix 16B Symmetry Properties of the DTFT
924
Appendix 16C Summary of DTFT Theorems
925
16.17
Problems
926
16.18
Project 1: Windows
939
16.19
Project 2: Decimation and Frequency Downshifting
944
Introduction and Summary
The discrete-time Fourier transform (DTFT) is deﬁned for discrete signals. It is the tool
for the analysis and design of linear discrete-time systems in the frequency domain. For
example, the convolution between two signals in the discrete-time domain is equivalent
to the multiplication of their DTFTs in the frequency-domain. To take another example,
881

882
CHAPTER 16
Discrete-Time Fourier Transform
the frequency response of a digital ﬁlter is the DTFT of its unit-sample response. Yet
a third example is that the DTFT, in its sampled form,1 becomes the main tool for the
analysis, design, detection, and coding of digitized audio and video signals.
In Chapter 8 we discussed Fourier transform (FT) of continuous-time signals, and
in this chapter we present DTFT of discrete-time signals. As one may expect, the DTFT
of a discrete-time signal is closely related to the Fourier transform (FT) the continuous-
time signal from which the discrete signal was generated by sampling. Under certain
conditions, the FT of a continuous-time signal can be approximated from the DTFT of its
discrete counterpart. Conversely, the DTFT of the discrete signal may be obtained from
the FT of the continuous-time signal. The relationship between the DTFT and FT, when
applicable, is of great importance as it allows frequency analysis of real-world signals,
and will be illustrated later in this chapter. Note, however, that some signals are inherently
discrete, as for example, a sequence of numbers. The DTFT is, therefore, deﬁned on its
own merit. This chapter starts with the mathematical deﬁnition of the DTFT and its in-
verse, the inverse discrete-time Fourier transform (IDTFT), for energy signals, along with
relevant examples and properties. By allowing for Dirac delta functions in the frequency
domain, the DTFT is then extended to power signals. Some basic steps in rate conver-
sion (such as zero-insertion, interpolation, and decimation) and their effects on a signal’s
DTFT are also discussed. Two projects are then suggested at the end of the chapter.
The transforms may be expressed as functions of angular frequency ω (in rad/s)
or f (in Hz). These variables are not the same for the continuous-and discrete-time
domains. Nevertheless, for simplicity, throughout this book we almost always will use
lowercase letters for both time domains, as the context is clear and won’t lend itself
to confusion. However, to avoid confusion, when both domains are being discussed
simultaneously, uppercase letters (F and ) are used for continuous-time signals and
lowercase ones ( f and ω) for discrete-time signals. Accordingly, when dealing with FT
and DTFT simultaneously, we will use the following notations. The Fourier transform of
a continuous-time signal x(t), −∞< t < ∞, will be shown by X(F), where frequency
F is a continuous variable, −∞< F < ∞. The DTFT transforms a discrete-time signal
x(n), −∞< n < ∞, where n is an integer, into its frequency-domain representa-
tion X(ω),
−∞< ω < ∞, where ω is a continuous variable. X(ω) is, however,
2π-periodic [X( f ) is periodic with a period of 1 Hz]. Because of its periodicity, we ex-
amine only one period of X(ω); for example, for −π < ω < π [or −0.5 < f < 0.5 for
X( f )]. From an analysis and computational point of view, the inﬁnite-length discrete-
time domain −∞< n < ∞is transformed into the ﬁnite-length continuous-frequency
domain −π < ω < π. Hence, one can say that sampling in the time domain makes
representation in the frequency domain periodic.
When measuring the spectrum of a signal by a computer, the signal is sampled
and a ﬁnite number of them are used. This is performed through an operation called
discrete Fourier transform (DFT, to be distinguished from DTFT).2 The DFT (to be
1See Chapter 17 on the DFT.
2See R. B. Blackman and J. W. Tukey, The Measurment of Power Spectra (New York: Dover Publications,
1958).

Signals and Systems
883
discussed in Chapter 17) transforms a ﬁnite sequence x(n), n = 0, 1, 2, · · · , N −1, of
length N into another ﬁnite sequence X(k), k = 0, 1, 2, · · · , N −1, of the same length.
The elements of the sequence X(k) are samples of X(ω) [where X(ω) is the DTFT of
x(n), ∞< n < ∞] taken every 2π/N radians [i.e., N samples in one period of X(ω)].
The DFT, therefore, performs sampling in the frequency domain. By sampling the DTFT,
the DFT simpliﬁes spectral analysis of ﬁnite data sequences. Moreover, evaluation of
the DFT involves multiplications and additions only, which can be done efﬁciently both
in real-time operations and in simulations. Real-time DFT is performed efﬁciently by
DSP processors, with architectures speciﬁcally designed for such operations. The com-
putationally efﬁcient algorithm for evaluating the DFT and its inverse is the Fast Fourier
Transform (FFT and IFFT), which is also used in off-line signal processing applications.
16.1
Definitions
DTFT
The DTFT of a discrete-time signal x(n) is deﬁned by
X(ω) =
∞

n=−∞
x(n)e−jωn
(1)
where n is an integer and ω is a continuous real variable called the angular frequency.3
X(ω) is a complex function and can be represented by its magnitude and phase
X(ω) = |X(ω)|e jθ(ω),
where θ(ω) = ̸ X(ω)
The magnitude and phase of X(ω) are real functions of the real variable ω, which ranges
from −∞to ∞. However, the DTFT, X(ω), is periodic with period 2π because
e−j(ω+2π)n = e−jωne−j2πn = e−jωn
and, therefore, X(ω) is specifed for −π < ω < π.4
IDTFT
The inverse of the DTFT may be found from
x(n) = 1
2π
 π
−π
X(ω)e jωndω
(2)
3DTFT of x(n) may also be expressed in terms of the variable f = ω/2π. The DTFT pair would then be
X( f ) =
∞

n=−∞
x(n)e−j2π f n and x(n) =
 0.5
−0.5
X( f )e j2π f nd f
In some applications, such as digital ﬁlter design, it is customary to represent the frequency by ω (rad/s). On
the other hand, by using f (Hz) as the variable of the DTFT we are able to get rid of the factor 2π in many
equations and identities.
4When the DTFT is expressed in terms of f , the period is 1 Hz and X( f ) may be speciﬁed for −0.5< f <0.5.

884
CHAPTER 16
Discrete-Time Fourier Transform
To verify the above, substitute for X(ω) from (1) in the integral of (2) and switch the
order of summation/integration to ﬁnd
1
2π
 π
−π
X(ω)e jωndω = 1
2π
 π
−π

∞

m=−∞
x(m)e−jωm

e jωndω
= 1
2π
∞

m=−∞

x(m)
 π
−π
e−jω(m−n)dω

= 1
2π
∞

m=−∞
2πx(m)d(m −n) = x(n)
Note that e jnω and e jmω are orthogonal to each other.
The pair x(n) and X(ω) deﬁned by (1) and (2) are unique. To ﬁnd the inverse of
X(ω), we ﬁnd an x(n) so that when used in (1) the result is the given X(ω).
Convergence of X(ω)
For X(ω) to exist, the series in (1) should converge. If x(n) is absolutely summable, that
is,
∞

n=−∞
|x(n)| ≤∞
the series in (1) converges uniformly and the DTFT exists. For a square-summable signal
(also called an energy signal) we have
∞

n=−∞
|x(n)|2 < ∞
and the series in (1) converges and the DTFT exists. The convergence is, however, not
necessarily uniform. The case of periodic signals x(n), where the series in (1) does
not converge in the conventional sense but turns into impulses, will be discussed in
sections 16.8 and 16.9.
Closed-Form Expressions
It is often desirable to obtain the DTFT function in closed form. The following equations
may be used to ﬁnd the sum of some ﬁnite and inﬁnite series encountered in the evaluation
of the DTFT.
The sum of an inﬁnite geometric series converges if the magnitude of progression
factor a is less than one:
∞

n=0
an =
1
1 −a , if |a| < 1

Signals and Systems
885
The above equation may be obtained by a Taylor series expansion of 1/(1 −a) around
a ≈0. Likewise, the sum of the ﬁrst N terms of a geometric series may be found from
N−1

n=0
an = 1 −aN
1 −a
For a = e−jω,
N−1

n=0
e−jωn = 1 −e−j Nω
1 −e−jω = sin( Nω
2 )
sin
 ω
2
 e−j( N−1
2 )ω
Similarly,
M

n=−M
e−jωn = 1 + 2
M

n=1
cos(ωn) = sin(M + 1
2)ω
sin( ω
2 )
Note that while |e−jωn| = 1 is a constant, the magnitude of the above sums vary with ω.
16.2
Examples of DTFT
The following examples that derive DTFTs of several elementary functions also
illustrate a few of the properties. Because of periodicity plots of magnitude and phase
of X(ω) are given for −π < ω < π. More DTFT pairs are found in Appendix 16A.
Example
16.1
a.
Find X(ω) for x(n) = d(n).
b.
Find X(ω) and plot its magnitude given
x(n) =
	
1
2,
n = 1, −1
0,
elsewhere
Solution
a.
X(ω) =
∞

n=−∞
d(n)e−jωn = 1e−jωn

n=0 = 1
b.
X(ω) =
∞

n=−∞
x(n)e−jωn = 1
2e jω + 1
2e−jω = cos ω
See Figure 16.1(a). Within the period −π < ω < π the magnitude and phase of
X(ω) are
|X| = | cos ω|, and θ =
	
0,
|ω| < π
2
π,
|ω| > π
2

886
CHAPTER 16
Discrete-Time Fourier Transform
Example
16.2
Find X(ω) and plot its magnitude given
x(n) =





1,
n = 0
1
2,
n = 1, −1
0,
elsewhere
Solution
X(ω) =
∞

n=−∞
x(n)e−jωn = 1 + 1
2e jω + 1
2e−jω = 1 + cos ω
|X(ω)| = 1 + cos ω, and θ(ω) = 0 See Figure 16.1(b).
0.5
0
–8
–6
–4
–2
0
2
x(n)
|X(f)|
4
6
8
1
0
–8
–6
–4
–2
0
2
Time (s)
Frequency (Hz)
4
6
8
1
0
–0.5
(a)
(b)
–0.3
–0.1
0.1
0
0.3
0.5
1
0
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.1 Two discrete-time functions (on the left) and one period of the normalized magnitude of their DTFT plotted
for −0.5 < f < 0.5 (on the right, corresponding to −π < ω < π). (a) x(n) = {0.5, 0
↑, 0.5}. (b) x(n) = {0.5, 1
↑, 0.5}.
Example
16.3
a.
Find the DTFT of x(n) = anu(n), |a| < 1.
b.
Find the DTFT of h(n) = 2−nu(n) and plot its magnitude.

Signals and Systems
887
Solution
a.
X(ω) =
∞

n=0
ane−jωn =
∞

n=0
(ae−jω)n =
1
1 −ae−jω =
1
1 −a cos ω + ja sin ω
The magnitude and phase of X(ω) are
|X|2 =
1
1 + a2 −2a cos ω
and θ = −tan−1

a sin ω
1 −a cos ω

b.
X(ω) is found by setting a = 0.5 in part a.
X(ω) =
1
1 −1
2 cos ω + j 1
2 sin ω
The magnitude and phase of X(ω) are given below. See Figure 16.2(a).
|X|2 =
1
5/4 −cos ω
and θ = −tan−1

sin ω
2 −cos ω

Example
16.4
Find the DTFT of h(n) = (−0.5)nu(n) and plot its magnitude.
Solution
H(ω) =
∞

n=0
(−0.5)ne−jωn =
1
1 + 1
2e−jω =
1
1 + 1
2 cos ω −j 1
2 sin ω
The magnitude and phase of H(ω) are given below. See Figure 16.2(b).
|H|2 =
1
5/4 + cos ω
and θ = tan−1

sin ω
2 + cos ω

Example
16.5
Find the DTFT of x(n) = (0.8)n cos
 πn
2

u(n) and plot its magnitude.
Solution
The DTFT may be obtained by application of the deﬁnition.
x(n)=(0.8)n cos
πn
2

u(n) ⇒X(ω) =
∞

n=0
(0.8)n cos
πn
2

e−jωn
=
∞

n=0
1
2(0.8)n 
e j πn
2 + e−j πn
2

e−jωn
=
∞

n=0
1
2(0.8)n 
e−j(ω−π
2 )n + e−j(ω+ π
2 )n
= 1
2
∞

n=0

j0.8e−jωn +1
2
∞

n=0

−j0.8e−jωn

888
CHAPTER 16
Discrete-Time Fourier Transform
= 1
2

1
1 −j0.8e−jω +
1
1 + j0.8e−jω

=
1
1 + 0.64e−j2ω =
1
(1 + 0.64 cos 2ω) −j0.64 sin 2ω
The magnitude and phase of X(ω) are given below. See Figure 16.2(c).
|H|2 =
0.7813
1.1012 + cos 2ω
and θ = tan−1

sin 2ω
1.5625 + cos 2ω

1
0
4
2
0
–2
–4
–6
–8
6
8
(a)
(b)
1
0.4
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
1
0
4
2
0
–2
–4
–6
–8
6
8
1
0.4
x(n)
|X(f)|
Time (s)
Frequency (Hz)
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
–0.4
–0.2
0.2
0.4
(c)
1
0.5
0
–0.5
–1
4
2
Time (s)
Frequency (Hz)
0
–2
–4
–6
–8
6
8
1
0
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.2 Three discrete-time causal functions (on the left) and one period of the normalized magnitude of their
DTFT plotted for −0.5 < f < 0.5 (on the right, corresponding to −π < ω < π).
(a) x(n) = (0.5)nu(n). The magnitude plot shows the low-pass property of the function.
(b) x(n) = (−0.5)nu(n). The magnitude plot shows the high-pass property of the function.
(c) x(n) = (0.8)n cos  πn
2

u(n). The magnitude plot shows the bandpass property of the function.

Signals and Systems
889
16.3
The DTFT and the z-Transform
The discrete-time Fourier transform (DTFT) of a signal is closely related to its
z-transform by the following:
X(ω) =
∞

n=−∞
x(n)e−jωn
X(z) =
∞

n=−∞
x(n)z−n, ROC includes the unit circle.
X(ω) = X(z)|z=e jω
Existence of DTFT is contingent upon convergence of the sum. That condition requires
the ROC of X(z) to include the unit circle in the z-plane. In such a case, the DTFT
can be derived from X(z) simply by substituting z by e−jω. In Example 16.6 to follow
the DTFT of the decaying sinusoidal signal of Example 16.5 is derived from the z-
transform. The use of z-transform is recommended as an easier method. Example 16.7
discusses ﬁnding DTFT of a two-sided function from the z-transform and condition for its
existence.
Example
16.6
ObtaintheDTFTof x(n) = (0.8)n cos
 πn
2

u(n)(Example16.5)fromits z-transform.
Solution
The DTFT of x(n) is found from its z-transform by setting z = e jω as shown below.
From tables of the z-transform we have
x(n) = an cos(ω0n)u(n)
⇒
X(z) =
1 −a(cos ω0)z−1
1 −2a(cos ω0)z−1 + a2z−2 , |z|>a
x(n) = (0.8)n cos
πn
2

u(n)
⇒
X(z) =
1
1 + 0.64z−2 , |z| > 0.8
X(ω) = X(z)|z=e jω =
1
1 + 0.64e−2 jω
The result is the same that was found in Example 16.5. The signal x(n) and the nor-
malized magnitude |X(ω)|/|X Max| have been plotted in Figure 16.2(c). The poles of
X(z) are at z = ± j0.8. The maximum magnitude is at f = ±0.25 Hz (corresponding
to z = ± j which is the closest point on the unit circle to the pole).

890
CHAPTER 16
Discrete-Time Fourier Transform
Example
16.7
Usethe z-transformtoﬁndtheDTFTof x(n) = an cos
 πn
2

u(n)+b−n cos
 πn
2

u(−n)
and discuss the conditions when it doesn’t exist.
Solution
Let x(n) = x1(n) + x2(n), where x1(n) and x2(n) are the left- and right-sided
components of x(n). Find the z-transform, X1(z) and X2(z), of each component
and determine if the ROCs overlap. If X(z) exists and the ROC includes the unit-
circle in the z-plane, then substitute for z = e jω to obtain the DTFT. The above steps
are shown below.
a. x1(n) = an cos
πn
2

u(n)
⇒
X1(z) =
1
1 + a2z−2 , |z| > |a|
b. x2(n) = b−n cos
πn
2

u(−n)
⇒
X2(z) =
1
1 + b2z2 , |z| <


1
b


c. x(n) = x1(n) + x2(n)
⇒
X(z) = X1(z) + X2(z)
=
b2 + 2z−2 + a2z−4
b2 + (1 + a2b2)z−2 + a2z−4 , |a| < |z| <


1
b


X(ω) = X(z)|z=e jω
=
b2 + 2e−j2ω + a2e−j4ω
b2 + (1 + a2b2)e−j2ω + a2e−j4ω , |a| < 1 <


1
b


16.4
Examples of IDTFT
Example
16.8
Find the inverse DTFT of X(ω) =
	
1,
−ω0 ≤ω ≤ω0
0,
elsewhere
Solution
x(n) = 1
2π
 π
−π
X(ω)e jωndω = 1
2π
 ω0
−ω0
e jωndω
=
	 ω0
π ,
n = 0
sin(ω0n)
πn
,
n ̸= 0
See Figure 16.3.

Signals and Systems
891
1
0
0.5
(a)
(b)
(c)
(d)
0.1
0
–0.04
0
–20
20
–10
10
1
0
0.25
0
–0.1
0
–20
20
–10
10
1
0
0.5
0
–0.2
0
–20
–10
20
10
1
0
0.8
–0.2
0
0.4
0
–20
–10
20
10
Frequency (Hz)
Time (s)
|X( f)|
x(n)
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.3 Low-pass DTFT pairs, X( f ) on the left and x(n) on the right. Rows (a) to (d) show X( f ) and x(n)
for cutoff frequency f0 = 1/20, 1/8, 1/4, and 3/8 Hz, respectively. See Example 16.8.

892
CHAPTER 16
Discrete-Time Fourier Transform
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
1
0
(a)
1
0
–0.2
0
–20
20
–10
10
1
0
(b)
0.8
0.4
0
–0.4
0
–20
20
–10
10
|X( f)|
x(n)
1
0
(c)
0.4
0
–0.4
0
–20
20
–10
10
Time (s)
Frequency (Hz)
1
0
Frequency (Hz)
Time (s)
(d)
0.2
0
–0.2
0
–20
20
–10
10
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.4 High-pass DTFT pairs X( f ), on the left, and x(n), on the right. Rows (a) to (d) show X( f ) and x(n)
for cutoff frequencies f0 = 1/20, 1/8, 1/4, and 3/8 Hz, respectively. See Example 16.9.

Signals and Systems
893
Example
16.9
Find the inverse DTFT of
X(ω) =
0,
for −ω0 ≤ω ≤ω0
1,
elsewhere
Solution
x(n) = 1
2π
 π
−π
X(ω)e jωndω = 1
2π
 −ω0
−π
e jωndω +
 π
ω0
e jωndω

=
	
1 −ω0
π ,
n = 0
−sin(ω0n)
πn
,
n ̸= 0
See Figure 16.4.
16.5
Rectangular Pulse
Rectangular pulses are encountered frequently in signal processing. In Examples 16.8
and 16.9 we worked with rectangular pulses representing ideal ﬁlters and found their
corrsponding time-domain representations. In the time domain a rectangular pulse is
used for window averaging, or simply to select a ﬁnite length of a function. In this
section we examine frequency representation of a single time-domain rectangular pulse
in more detail. First, in Example 16.10 we discuss the DTFT of an even pulse. Then, in
Example 16.11 we consider a causal pulse.
Example
16.10
Find and analyze the DTFT of the even rectangular pulse of width N = 2M + 1
which starts at n = −M and ends at n = M, x(n) = u(n + M) −u(n −M −1), and
summarize its salient features.
Solution
X(ω) =
M

n=−M
e−jωn
= e jωM + e jω(M−1) · · · + e jω + 1 + e−jω · · · + e−jω(M−1) + e−jωM
= 1 + 2
M

n=1
cos(ωn) = Xr(ω)
Note that X(ω) is a real and even function [to be called Xr(ω)], which can have
positive and negative values. The phase of X(ω) is, therefore, either zero or ±π.
X(ω) of the even rectangular pulse may also be given by the following closed-form
expression (see solved problem 4 for derivation):
X(ω)=
M

n=−M
e−jωn=sin(M + 1
2)ω
sin( ω
2 )
=sin( Nω
2 )
sin( ω
2 ) =Xr(ω), where N = 2M +1 is odd

894
CHAPTER 16
Discrete-Time Fourier Transform
Expressed as a function of f , the DTFT of the even square pulse of length N = 2M+1
is
X( f ) = sin(π N f )
sin(π f )
Figure 16.5 Plots an even pulse of size N = 9 and its DTFT as a function of f for
−0.5 < f < 0.5 Hz. The DTFT is a real and even function with X(0) = N. It
contains a main lobe centered at f = 0 (and repeated at f = ±k) with height N,
base 2/N, and unit area. The ﬁrst zero-crossings occur at ±1/N. As pulse-width N
is increased, the main lobe of X( f ) becomes narrower and taller, with the area under
it remaining 1. At the limit N →∞(DC signal), the main lobe becomes an impulse
δ( f ) (and repeats at f = ±k).
1
0
–12 –10 –8
–6
–4
–2
0
Time (s)
2
4
6
8
10
12
10
8
6
4
2
0
–2
Frequency (Hz)
X( f)
x(n)
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.5 A rectangular pulse N unit samples long (here, N = 9) and its DTFT plotted as a function of f .
Example
16.11
Find the DTFT of the causal rectangular pulse x(n) = u(n) −u(n −N), and sum-
marizes its salient features.
Solution
X(ω) =
N−1

n=0
e−jωn = 1 −e−jωN
1 −e−jω = e−jω (N−1)
2
sin
 Nω
2

sin
 ω
2
 = Xre jθ
where
Xr = sin
 Nω
2

sin
 ω
2
 , and θ = −(N −1)
2
ω
The DTFT of a causal square pulse of length N is expressed as the product of a real-
valued function Xr(ω) and a phase-shift component e jθ. The real-valued function
Xr(ω) is the same as found in Example 16.10. Shifting the pulse of Example 16.10
by (N −1)/2 units makes the pulse causal. This contributes the phase shift component
e jθ to the DTFT.

Signals and Systems
895
Summary
1.
The DTFT of the even rectangular pulse made of N = 2M + 1 consecutive unit
samples is
x(n) = u(n + M) −u(n −M −1) ⇐⇒
X(ω) = 1 + 2
M

n=1
cos(ωn) = sin( Nω
2 )
sin( ω
2 ) = Xr(ω), X( f ) = sin(π N f )
sin(π f )
It is a real and even function of ω with X(0) = N. Because its period is 2π and
it is an even function of ω, we attend to it during the interval 0 ≤ω ≤π.
2.
The DTFT of the causal rectangular pulse made of N consecutive unit samples
is
x(n) = u(n) −u(n −N) ⇐⇒X(ω) = Xr(ω)e−jω (N−1)
2
The phase component is caused by a right-shift transforming the even pulse into
a causal one. (See section 16.6 on DTFT theorems and properties.)
3.
The denominator of the above Xr(ω) is periodic with a period of 4π. The
numerator is also periodic but with a shorter period of 4π/N. X(ω), therefore,
switches between positive and negative values with zero-crossings at
ω = ±2kπ/N, k = 1, 2, 3, 4, · · · , M, creating positive and negative lobes
(each 2π/N wide) that repeat at ω = ±2kπ/N intervals but diminish as
ω ⇒π (or f ⇒0.5). See Figure 16.5.
4.
The main lobe of Xr(ω) is centered at ω = 0 with X(0) = N. The ﬁrst zero
crossing occurs at ω = ±2π/N. The base of the lobe is, therefore, 4π/N units
wide. Consider the triangle under the main lobe [with apex at X(0) and the two
corners of the base at ±2π/N]. The area under the triangle is N
2 × 4π
N = 2π. As
pulse width N is increased, the main lobe of X(ω) becomes narrower and taller,
with the area under it remaining 2π. As N →∞, the main lobe becomes an
impulse 2πδ(ω).5
5.
Observe parallels with the Fourier transform (FT) of a single even rectangular
analog pulse of unit height in the continuous-time domain. The FT of such a
pulse is X(F) an even function of frequency with a its value at F = 0 equal to
the area of the time-domain pulse. It has alternating positive and negative lobes
which extend over the frequency range −∞≤F ≤∞, diminishing toward
zero with the increase in frequency. As pulse width increases, the FT becomes a
unit impulse in the F-domain.
16.6
DTFT Theorems and Properties
The discrete-time Fourier transform is a member of a family of linear transforms, which
includes the Fourier transform, the Laplace transform, and the z-transform. The DTFT,
5In the f -domain, the limit of X( f ) as N →∞is δ( f ).

896
CHAPTER 16
Discrete-Time Fourier Transform
therefore, shares many of their properties. Some of these theorems and properties are
described in this section and tabulated in Appendixes 16B and 16C, respectively.
Linearity
The DTFT of ax(n)+by(n) is aX(ω)+bY(ω) for any x(n) and y(n) and any constants
a and b.
x(n)
⇐⇒X(ω)
y(n)
⇐⇒Y(ω)
ax(n) + by(n) ⇐⇒aX(ω) + bY(ω)
Real Signals
If x(t) is real, then X(ω) = X∗(−ω). This is the conjugate symmetry property for real
signals and is shown by
x(n) = x∗(n) ⇐⇒X(ω) = X∗(−ω)
Waveform Symmetry
The DTFT of a real and even signal is a real and even function. Likewise, the DTFT of
a real and odd signal is a purely imaginary and odd function.
If x(n) is real and even: x(n) = x(−n)
⇐⇒then X(ω) is real and even:
X(ω) = X(−ω)
If x(n) is real and odd: x(n) = −x(−n) ⇐⇒then X(ω) is imaginary and odd:
X(ω) = −X(−ω)
Time and Frequency Reversal
Reversing time ﬂips the signal around n = 0 and converts x(n) to x(−n). The DTFTs
of x(n) and x(−n) are related by
x(n)
⇐⇒X(ω)
x(−n) ⇐⇒X(−ω)
The effect is symmetrical with respect to time and frequency. A reversal in the frequency
domain results in a reversal in the time domain.
Time Shift
A delay of k units in x(n) adds (−ωk) to the phase of its DTFT.
x(n)
⇐⇒X(ω)
x(n −k) ⇐⇒X(ω)e−jωk

Signals and Systems
897
Frequency Translation
Multiplication of x(n) by e jω0n shifts the transform by ω0.
x(n)
⇐⇒
X(ω)
x(n)e jω0n
⇐⇒
X(ω −ω0)
The product x(n)e jω0n is not a real signal. However, by shifting X(ω) to the left and to
the right by the same amount ω0 and adding the results together, one obtains the real
signal 2x(n) cos(ω0n) in which x(n) modulates the amplitude of cos(ω0n).
x(n)e jω0n
⇐⇒
X(ω −ω0)
x(n)e−jω0n
⇐⇒
X(ω + ω0)
x(n) cos(ω0n) ⇐⇒
1
2 {X(ω −ω0) + X(ω + ω0)}
Even and Odd Parts of a Signal
The even and odd parts of a real-valued signal are related to the RE and IM parts of
its DTFT.
x(n)
⇐⇒
X(ω) = RE{X(ω)} + jIM{X(ω)}
x(−n)
⇐⇒
X∗(ω) = RE{X(ω)} −jIM{X(ω)}
xe(n) = x(n) + x(−n)
2
⇐⇒
X(ω) + X∗(ω)
2
= RE{X(ω)}
xo(n) = x(n) −x(−n)
2
⇐⇒
X(ω) −X∗(ω)
2
= IM{X(ω)}
From the symmetry property and the above it follows that for real x(n)
RE{X(ω)} = x(0) + 2
∞

n=1
xe(n) cos(ωn)
IM{X(ω)} = −2
∞

n=1
xo(n) sin(ωn)
xe(n) = 1
π
 π
0
RE{X(ω)} cos(ωn)dω
xo(n) = −1
π
 π
0
IM{X(ω)} sin(ωn)dω
Causal Functions
A function that is zero for n < 0 is called causal. A causal discrete-time function is
completely speciﬁed by its even part xe(n), or by its odd part xo(n) and xe(0).
x(n) =





0,
n < 0
xe(0),
n = 0
2xe(n) = 2xo(n),
n > 0.

898
CHAPTER 16
Discrete-Time Fourier Transform
Proof
Let x(n) be a causal function. Then,
For n < 0,
xe(n) + xo(n) = 0,
therefore,
xe(n) = −xo(n), n < 0.
For n > 0,
xe(n) = xo(n),
therefore,
x(n) = 2xe(n) = 2xo(n), n > 0.
For n = 0,
xe(0) = x(0),
From the above results and the symmetry property of the DTFT, we observe the following
special relationships between a real-valued causal discrete-time signal x(n) and its DTFT
X(ω).
X(ω) =
∞

n=0
x(n)e jωn, for −∞< ω < ∞<
x(n) =



2
π
 π
0 RE{X(ω)} cos(ωn)dω = −2
π
 π
0 IM{X(ω)} sin(ωn)dω,
n > 0
1
π
 π
0 RE{X(ω)}dω,
n = 0
Convolution
Convolution of two discrete-time signals is equivalent to multiplication of their DTFTs
in the frequency domain. This is called the convolution property of the DTFT.
x(n) ⋆y(n) ⇐⇒X(ω)Y(ω)
This property may be proven by applying DTFT to the convolution sum. Convolution of
two functions x(n) and h(n) is deﬁned by
y(n) = x(n) ⋆h(n) =
∞

k=−∞
x(n −k) h(k)
The DTFT of y(n) is
Y(ω) =
∞

n=−∞
y(n)e−jωn =
∞

n=−∞
∞

k=−∞
x(n −k) h(k) e−jωn
The double sum may be converted to the product of two separate sums by changing the
variable n to a new variable m by n = k + m so that n −k = m. The terms containing
m and k in the double sum are then separated
Y(ω) =
 ∞

−∞
x(m) e−jωm

×
 ∞

−∞
h(k) e−jωk

= X(ω)H(ω)
This property is valuable in the analysis of LTI systems because it establishes the
frequency-domain relationship between output, input, and the unit-sample response.

Signals and Systems
899
Product of Two Signals
Multiplicationoftwodiscrete-timesignalsisequivalenttotheconvolutionoftheirDTFTs
in the frequency domain. This property, which is called the product property of the DTFT,
is the dual of the convolution property.
x(n)y(n) ⇐⇒
1
2π X(ω) ⋆Y(ω) = X( f ) ⋆Y( f )
In other words,
∞

−∞
x(n)y(n)e−jωn = 1
2π
 π
−π
X(ω −φ)Y(φ)dφ or equivalently,
∞

−∞
x(n)y(n)e−j2π f n =
 0.5
−0.5
X( f −φ)Y(φ)dφ
This property is used in the modulation and correlation analysis of signals and LTI
systems.
Example
16.12
Apply the product property to ﬁnd the DTFT of 0.5n cos(πn)u(n) and observe that
the answer is the same as that found in Example 16.4 for (−0.5)nu(n).
Solution
0.5nu(n)
⇒
1
1 −0.5e−jω
cos(πn)
⇒π [δ(ω + π) + δ(ω −π)]
0.5n cos(πn)u(n)
⇒
1
2π

1
1 −0.5e−jω

⋆π[δ(ω + π) + δ(ω −π)]
But
δ(ω + π) ⋆
1
1 −0.5e−jω
⇒
1
1 −0.5e−j(ω+π) =
1
1 + 0.5e−jω
and
δ(ω −π) ⋆
1
1 −0.5e−jω
⇒
1
1 −0.5e−j(ω−π) =
1
1 + 0.5e−jω
Therefore, 0.5n cos(πn)u(n)
⇒
1
1 + 0.5e−jω
Conjugate Symmetry
A complex function x(n) is conjugate symmetric if x(n) = x∗(−n). When x(n) is
real and conjugate symmetric, then x(n) = x(−n) and the function is even. It is seen
that the even property is a special case of the conjugate symmetric property.
Similarly,acomplexfunction x(n)isconjugate antisymmetric if x(n) = −x∗(−n).
When x(n) is real and conjugate antisymmetric, then x(n) = −x(−n) and the function
is odd. It is seen that the odd property is a special case of the conjugate antisymmetric
property.

900
CHAPTER 16
Discrete-Time Fourier Transform
A complex function x(n) may be written as the sum of a conjugate symmetric part
[shown by xe(n)] and an antisymmetric part [shown by xo(n)].
x(n) = xe(n) + xo(n)
xe(n) = x(n) + x∗(−n)
2
and xo(n) = x(n) −x∗(−n)
2
When x(n) is real,
xe(n) = x(n) + x(−n)
2
and xo(n) = x(n) −x(−n)
2
and xe(n) and xo(n) become the even and odd parts of x(n), respectively. The conjugate
symmetry property of the DTFT of complex and real signals is listed in Appendix 16B.
16.7
Parseval’s Theorem and Energy
Spectral Density
The quantity
∞

n=−∞
|x(n)|2
is called the energy in x(n). If the energy is ﬁnite, the signal is called square summable.
For square summable signals it may be shown that
∞

n=−∞
|x(n)|2 = 1
2π
 π
−π
|X(ω)|2dω =
 0.5
−0.5
|X( f )|2d f
This is called Parseval’s theorem for discrete signals. Hence, |X( f )|2 is called the energy
spectral density. When x(n) is a real function, X( f ) = X∗(−f ) and |X( f )|2 is an even
function of f . The total energy in x(n) may be found from
∞

n=−∞
|x(n)|2 = 2
 0.5
0
|X( f )|2d f
Compare this with the one-sided spectral density of continuous-time signals.
Example
16.13
Find the total energy in the causal exponential signal x(n) = anu(n), |a| < 1. Then
obtain an expression for the energy in the frequency band 0 to 0.01 Hz and ﬁnd its
value if a = 0.5.
Solution
The causal signal is given in Figure 16.6(a) for a = 0.5.
Etotal =
∞

n=0
a2n =
1
1 −a2 , E(0→0.01) = 2
 0.01
0
|X( f )|2d f

Signals and Systems
901
–12
–10
–8
–6
–4
–2
0
Time (s)
2
4
6
8
10
12
0
0.6
1
–0.4
–0.5
–0.3
–0.2
–0.1
0
Frequency (Hz)
(b)
(a)
0.1
0.2
0.3
0.4
0.5
0
2
4
–0.06
–0.04
–0.02
0.02
0.04
0.06
0
Frequency (Hz)
(c)
0
2
4
FIGURE 16.6 (a) The causal exponential signal x(n) = (0.5)nu(n). (b) One period of |X( f )|2.
(c) The shading shows a desired area under |X( f )|2, which is numerically equal to the energy
within the band −0.01 Hz < f < 0.01 Hz. See Example 16.13.
Substituting for |X( f )|2 [from Example 16.3(a)] we have
E(0→0.01) = 2
 0.01
0
1
1 + a2 −2a cos(2π f )d f
With a = 0.5, the values of the integrand at the lower and upper limits of the integral
are, respectively,
At f = 0,
|X( f )|2 =
1
1.25 −cos 0o = 4
At f = 0.01, |X( f )|2 =
1
1.25 −cos 3.6o = 3.968

902
CHAPTER 16
Discrete-Time Fourier Transform
We can obtain the energy in the frequency band 0 to 0.01 Hz by approximating the
area of the shaded region in Figure 16.6(c). The shaded region is approximated as a
rectangle with area
E = 2 × 0.01 × 4 + 3.968
2
≈0.08
This represents the total signal energy in the frequency band −0.01 < f < 0.01 Hz.
16.8
DTFT of Power Signals: The Limit Approach
Some signals may not be square summable, but their average power is ﬁnite.
lim
M→∞
1
2M + 1
M

n=−M
|x(n)|2 < ∞
These are called power signals. The sum representing their DTFT doesn’t converge
in the familiar sense. However, by employing singularity functions [such as δ(ω)] we
can generalize the DTFT deﬁnition to include power signals. The following three cases
illustrate the concept and provide examples.
DC Signal
To ﬁnd the DTFT of a DC signal we start with a rectangular pulse. In section 16.5 we
found the DTFT of an even rectangular pulse.
x(n) =
	
1,
−M ≤n ≤M
0,
elsewhere
X(ω) =
M

n=−M
e−jωn = sin(M + 1
2)ω
sin( ω
2 )
X(ω) contains major lobes centered at ω = ±2kπ, interlaced with minor lobes and
zero crossings at ω = ±2kπ/N. It was demonstrated that as the pulse in the time
domain becomes wider, the major lobes centered at ω = ±2kπ in the ω-domain become
narrower and taller, and the minor lobes become smaller (with more frequent zero-
crossings). As M →∞, x(n) →1 (a DC signal) and X(ω) becomes a train of impulses
of strength 2π at ω = ±2kπ; that is, a collection of 2πδ(ω −2kπ), −∞< k < ∞. See
Figure 16.7(a).
lim
M→∞x(n) = 1
lim
M→∞X(ω) = lim
M→∞
M

n=−M
e−jωn = lim
M→∞
sin(M + 1
2)ω
sin( ω
2 )
=
∞

k=−∞
2πδ(ω −2kπ)
lim
M→∞X( f ) =
∞

k=−∞
δ( f −k)

Signals and Systems
903
0
–2
–1
0
1
2
(a)
(b)
1
0
1
0
1
–2
–1
0
1
2
–12
–8
–4
0
4
8
12
1
0
–1
0.5
–0.4
–0.2
0
0.2
0.4
0
–50
–30
–10
Time (s)
Frequency (Hz)
0
10
30
50
–5
–10
–15
0
5
10
15
0
(c)
0.05
|X( f)|
x(n)
FIGURE 16.7 Three periodic discrete-time signals (left column) and their DTFT (right column). The DTFTs are made
of impulses in the frequency domain.
(a) The DTFT of the DC signal x(n) = 1, all n, is a train of unit impulses separated by 1 Hz.
x(n) =
∞

k=−∞
d(n −k) ⇐⇒
X( f ) =
∞

k=−∞
δ( f −k)
(b) The DTFT of a discrete-time sinusoidal signal with period N is a periodic pair of impulses positioned at the multiple
frequencies of the signal f = ±( f0 + k), where f0 = 1/N. In this ﬁgure N = 10 and f0 = 0.1 Hz. The strength of each
impulse in the ω-domain is π (for cos ω0n) or ± jπ (for sin ω0n). In the f -domain, the strengths of the impulses are 1/2
[for cos(2πn/N)] or ± j/2 [for sin(2πn/N)]. In summary, one cycle of the DTFTs is
cos(ω0n) = cos(2πn/N) ⇒
πδ(ω −ω0) + πδ(ω + ω0)
or 1
2[δ( f −f0) + δ( f + f0)]
sin(ω0n) = sin(2πn/N) ⇒−jπδ(ω −ω0) + jπδ(ω + ω0) or
1
2 j [δ( f −f0) −δ( f + f0)]
(c) The DTFT of an inﬁnite train of unit samples with period N and one sample per period in the n-domain (left side)
is a train of impulses of strength 2π/N at ω = 2kπ/N in the ω-domain or, equivalently, a train of impulses of strength
1/N at f = k/N in the f −domain (right side).
∞

k=−∞
d(n −kN) ⇐⇒2π
N
∞

k=−∞
δ

ω −2πk
N

= 1
N
∞

k=−∞
δ

f −k
N

This ﬁgure is generated with N = 20.

904
CHAPTER 16
Discrete-Time Fourier Transform
Sinusoid
Consider a discrete-time sinusoidal signal with period N
x(n) = cos(ω0n) = e jω0n + e−jω0n
2
, where ω0 = 2π
N
The DTFT of the sinusoidal signal is
X(ω) = lim
M→∞
M

n=−M
1
2e−jωn 
e jω0n + e−jω0n
= lim
M→∞
M

n=−M
1
2

e−j(ω−ω0)n + e−j(ω+ω0)n
= π
∞

k=−∞
[δ(ω −ω0 −2kπ) + δ(ω + ω0 + 2kπ)]
X( f ) = 1
2
∞

k=−∞
[δ( f −f0 −k) + δ( f + f0 + k)]
See Figure 16.7(b). The DTFT of a cosine is made of impulses of strength π at ω =
±(ω0 + 2kπ). For a sine, the strength of the impulses are −jπ (at ω = ω0) and jπ (at
ω = −ω0). One cycle of the DTFTs is given below:
cos(ω0n),
−∞< n < ∞
⇐⇒
πδ(ω + ω0) + πδ(ω −ω0)
sin(ω0n),
−∞< n < ∞
⇐⇒
−jπδ(ω + ω0) + jπδ(ω −ω0)
Note the special case of cos(πn).
Train of Unit Samples
Consider an inﬁnite train of unit samples, x(n), with period N and one sample per period,
Figure 16.7(c) (left side).
x(n) =
∞

k=−∞
d(n −kN)
For simplicity we have chosen the time origin such that one sample occurs at n = 0. We
will show that the DTFT of x(n) is a train of impulses, of strength 2π, at multiples of
π/N in the ω-domain.
To derive the DTFT of x(n), ﬁrst consider a segment of x(n) containing 2M + 1
periods (2M + 1 nonzero samples), to be called xM(n).
xM(n) =
M

k=−M
d(n −kN)
xM(n) is an energy signal and has a DTFT in the conventional sense. It contains 2M + 1

Signals and Systems
905
unit samples at n = ±kN, k = 0, 1, 2, · · · , M. Its DTFT is
X M(ω) =
∞

n=−∞
xM(n)e−jωn =
M N

n=−M N

M

k=−M
d(n −kN)e−jωn

=
M

n=−M
e−jωnN
= e jωM N + e jω(M−1)N · · · + 1 · · · + e−jω(M−1)N + e−jωM N
= e jωM N 
1 + e−jωN + e−2 jωN · · · + e−jω2M N
= e jωM N
1 −e−j(2M+1)ωN
1 −e−jωN

= sin
 ωN(2M+1)
2

sin( ωN
2 )
It is periodic and contains major lobes with peaks of magnitude (2M+1) centered at
ω = 2kπ/N. Note that the location of the peaks is a function of N only (signal period)
and independent of M. Between the major lobes there are minor lobes with zero-crossings
at
ω = ±
2kπ
N(2M + 1), k = 0, 1, 2, · · ·
As M grows, the locations of the peaks remain the same, that is, at ω = 2kπ/N, but
their magnitudes (2M+1) grow. The zero-crossings between the peaks also become
more frequent. The major lobes associated with the peaks become narrower and taller.
However, the area associated with each lobe is 2π
N as derived below.

π
N
−π
N
X M(ω)dω =

π
N
−π
N

M

k=−M
e−jωkN

dω =
M

k=−M

π
N
−π
N
e−jωkNdω =
 −π
N
−π
N
dω = 2π
N
If we let M →∞, we get
lim
M→∞xM(n) = x(n)
lim
M→∞X M(ω) = X(ω) = 2π
N
∞

k=−∞
δ

ω −2kπ
N

Therefore, the DTFT of a train of unit samples at multiples of N in the n-domain is a
train of impulses of strength 2π/N at ω = 2kπ/N in the ω-domain or, equivalently, a
train of impulses of strength 1/N at f = k/N in the f -domain.
∞

k=−∞
d(n −kN) ⇐⇒2π
N
∞

k=−∞
δ

ω −2πk
N

= 1
N
∞

k=−∞
δ

f −k
N

See Figure 16.7(c).

906
CHAPTER 16
Discrete-Time Fourier Transform
Example
16.14
Two examples of DTFT pairs are given below.
a. x(n) =
	
1,
n even
0,
n odd
⇐⇒
X(ω) =
∞

k=−∞
πδ(ω −kπ)
b. x(n) = (−1)n
⇐⇒
X(ω) =
∞

k=−∞
πδ(ω −kπ)

1 −e−jω
=
∞

k=−∞
2πδ[ω −(2k + 1)π]
16.9
DTFT of Periodic Signals: The Convolution
Approach
A periodic signal y(n) with period N is obtained by convolution of a time-limited signal
h(n) with an inﬁnite train x(n) of unit samples located at every multiple of N samples.
y(n) = h(n) ⋆x(n) = h(n) ⋆
∞

k=−∞
d(n −kN) =
∞

k=−∞
h(n −kN)
where h(n) is one cycle of y(n)
h(n) =
	
y(n),
0 ≤n < N
0,
elsewhere
The DTFT of y(n) is found by multiplying the DTFTs of h(n) and x(n)
Y(ω) = X(ω)H(ω)
In section 16.8 the DTFT of the train of unit samples was found to be
x(n) =
∞

k=−∞
d(n −k) ⇒
X(ω) = 2π
N
∞

k=−∞
δ

ω −2kπ
N

⇒
X( f ) = 1
N
∞

k=−∞
δ

f −k
N


Signals and Systems
907
Therefore,
Y(ω) = 2π
N H(ω)
∞

k=−∞
δ

ω −2kπ
N

= 2π
N
∞

k=−∞
H
2kπ
N

δ

ω −2kπ
N

Y( f ) = 1
N
∞

k=−∞
H
 k
N

δ

f −k
N

The DTFT of the periodic signal is obtained by sampling the DTFT of a single cycle at
f = k/N and representing the samples by impulse functions.
DTFT of a Periodic Rectangular Pulse
Let x(n) be a periodic rectangular pulse with period N. Each pulse has W samples. For
simplicity, assume x(n) is an even function of n. Here we ﬁnd its DTFT using f to
represent the frequency.
Let h(n) represent the single pulse centered at n = 0. Then,
h(n) =
M

k=−M
d(n −k) ⇒
H( f ) = sin(Wπ f )
sin(π f ) , where W = 2M + 1
x(n) =
∞

k=−∞
h(n −kN) ⇒
X( f ) = 1
N
∞

k=−∞
H
 k
N

δ( f −k/N)
= 1
N
∞

k=−∞
sin(Wπk/N)
sin(πk/N) δ( f −k/N)
Alternate Approach
X( f ) =
M

n=−M

e−j2πnf
N
∞

k=−∞
δ( f −k/N)

= 1
N
∞

k=−∞
δ( f −k/N)

M

n=−M
e−j2πnf

= 1
N
∞

k=−∞
sin(Wπk/N)
sin(πk/N) δ( f −k/N)
As expected, the DTFT of the periodic pulse train with period N is obtained by sampling
the DTFT of a single cycle (at ω = 2kπ/N or f = k/N) and representing the samples
by impulse functions, Figure 16.8.

908
CHAPTER 16
Discrete-Time Fourier Transform
1
0
–25 –20 –15 –10 –5
0
5
10
15
20
25
30
1
0.8
0.6
0.4
0.2
0
(a)
(b)
(c)
(d)
0.5
0.4
–0.3 –0.2
–0.4
–0.5
0.3
–0.1
0.1
0.2
0
0.5
0.4
–0.3 –0.2
–0.4
–0.5
0.3
–0.1
0.1
0.2
0
0.5
0.4
–0.3 –0.2
–0.4
–0.5
0.3
–0.1
0.1
0.2
0
0.5
0.4
–0.3 –0.2
–0.4
–0.5
0.3
–0.1
0.1
0.2
0
1
0
5
–5
0
10
–10
15
–15
20
–20
25
30
35
1
0.8
0.6
0.4
0.2
0
1
0
–30
–20
–10
0
Time (s)
Frequency (Hz)
10
20
30
1
0.8
0.6
0.4
0.2
0
1
0
–45 –40 –35 –30 –25 –20 –15 –10 –5
0
5
15
10
1
0.8
0.6
0.4
0.2
0
|X( f)|
x(n)
FIGURE 16.8 The DTFT of a periodic signal with period N (a, b, c) is derived by sampling the DTFT of a single
cycle (d) at f = k f0, where f0 = 1/N, and representing the samples by impulse functions. In this ﬁgure: (a) N = 8,
f0 = 0.125 Hz, (b) N = 16, f0 = 0.0625 Hz, and (c) N = 32, f0 = 31.25 mHz.

Signals and Systems
909
16.10
Zero-Insertion
Imagine stretching the time axis of a discrete-time signal x(n) in a way that it inserts N−1
zeros (N ≥1) at the newly generated spaces between neighboring samples, producing
a new signal y(n). An example of the effect of zero-insertion on x(n) = (0.6)nu(n) and
its DTFT for N = 2 is shown in Figure 16.9. Another example is shown in Figure 16.10
for the sinc-type signal6
x(n) =

sin( πn
2 )
( πn
2 )
2
for N = 5. It resembles stretching the time axis by a factor of 5.
1
0
–14–12–10
10 12 14
–8
8
–6
6
–4
4
–2
2
0
3
2
1
0
(a)
(b)
1
0
–14–12–10
10 12 14
–8
8
–6
6
–4
4
–2
Time (s)
Frequency (Hz)
2
0
3
2
1
0
|X( f)|
x(n)
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.9 Inserting a zero between successive samples of x(n) = (0.6)nu(n) and its effect on the DTFT.
Zero-insertion compresses the frequency axis by a factor of 2.
6For the deﬁnition of sinc signals see Chapter 10.

910
CHAPTER 16
Discrete-Time Fourier Transform
1
0
–20
–15
–10
–5
0
5
10
15
20
2
0
–0.5
(a)
(b)
–0.3
–0.1
0
0.1
0.3
0.5
1
0
–20
–15
–10
–5
0
5
10
15
20
Frequency (Hz)
Time (s)
2
0
–0.5
–0.3
–0.1
0
0.1
0.3
0.5
X( f)
x(n)
FIGURE 16.10 Inserting four zeros between successive samples of x(n) = sin2(πn/2)/(πn/2)2 and its effect on the
DTFT. It compresses the frequency axis by a factor of 5.
A zero-insertion process that is referenced at n = 0 may be summarized by:
...
y(−N −2) = 0
y(−N −1) = 0
y(−N)
= x(−1)
y(−N + 1) = 0
y(−N + 2) = 0
...
y(−2)
= 0
y(−1)
= 0
y(0)
= x(0)
y(1)
= 0
y(2)
= 0
...
y(N −2)
= 0
y(N −1)
= 0
y(N)
= x(1)

Signals and Systems
911
y(N + 1) = 0
y(N + 2) = 0
...
It can be shown that inserting (N −1) zeros between samples in x(n) that produces a
new function y(t) results in the following effect in the frequency domain:
x(n) ⇐⇒X(ω)
y(n) ⇐⇒Y(ω) = X(Nω)
The proof is shown below.
X(ω) =
∞

n=−∞
x(n)e−jωn
Y(ω) =
∞

n=−∞
y(n)e−jωn =
∞

k=−∞
y(kN)e−jωkN
=
∞

k=−∞
x(k)e−jωkN =
∞

k=−∞
x(k)e−j(Nω)k = X(Nω)
Inserting N −1 zeros between neighboring samples in the unit-sample response of a
digital ﬁlter shrinks (compresses) the frequency axis by a factor N and replicates the
frequency response. Knowing N, one can always unshrink Y(ω) and retrieve X(ω) from
it. No information is lost by inserting zeros. This is hardly surprising. By removing zeros
from y(n) one can always retrieve the original signal x(n).
Example
16.15
Take x(n) = (0.5)nu(n) and insert single zeros between its samples to create a new
signal y(n). Find Y(ω) and relate it to X(ω).
Solution
X(ω) =
∞

n=0
(0.5)ne−jωn =
1
1 −0.5e−jω
Y(ω) =
∞

n=0
(0.5)ne−j2ωn =
1
1 −0.5e−j2ω = X(2ω)
Example
16.16
Now consider h(n) = (−0.5)nu(n) and note that h(n) = y(n) −0.5y(n −1),
where y(n) is the signal generated by inserting single zeros between samples of
x(n) = (0.25)nu(n). Derive H(ω) from X(ω). Compare with the results obtained
directly.

912
CHAPTER 16
Discrete-Time Fourier Transform
Solution
x(n) = (0.25)nu(n)
⇒
X(ω) =
1
1 −0.25e−jω
y(n)
⇒
Y(ω) = X(2ω) =
1
1 −0.25e−j2ω
h(n) = y(n) −0.5y(n −1) ⇒
H(ω) = Y(ω) −0.5e−jωY(ω)
= (1 −0.5e−jω)Y(ω)
H(ω) =
1 −0.5e−jω
1 −0.25e−j2ω =
1
1 + 0.5e−jω
The above result may also be derived directly from the deﬁnition of the DTFT
H(ω) =
∞

n=0
(−0.5)ne−jωn =
∞

k=0
(0.5)2ke−j2kω −
∞

k=0
(0.5)2k+1e−j(2k+1)ω
=
∞

k=0

0.25e−j2ωk −0.5e−jω
∞

k=0

0.25e−j2ωk =
1 −0.5e−jω
1 −0.25e−j2ω
=
1
1 + 0.5e−jω
The result is in agreement with H(ω) found in Example 16.4.
16.11
Decimation
Decimation implies discarding some samples. For example, keeping every other sample
and dropping the sample that is in between is called decimation by a factor of 2. To
decimate by a factor of 10 (at which factor the expression is clearly appropriate), we
would keep every tenth sample. Decimation by a factor D of an existing signal x(n)
generates a new signal y(n) = x(Dn), where D is an integer greater than one. The
operation keeps a sample and drops the next D −1 samples in the original signal. It
reduces the number of samples available for reconstruction of the original continuous-
time signal. Mathematically it is equivalent to reducing the sampling rate by a factor
of D. It is used in multirate signal processing where two or more signals sampled at
different rates are being mixed with one another. It is also used in antialiasing ﬁltering
and frequency downshifting.
Decimation of a discrete-time signal may or may not cause aliasing. If a signal
is sampled at a sufﬁciently higher-than-minimum rate (for example, at a rate greater
than or equal to D-times the Nyquist rate), its decimation by a factor D doesn’t cause
aliasing. On the other hand, if a signal is sampled at the minimum (Nyquist) rate, its
decimation would mean the loss of samples required for its reconstruction and, hence,
aliasing occurs.

Signals and Systems
913
Another application of decimation is to reduce the complexity of the analog anti-
aliasing ﬁlter. For this purpose, a simple low-pass analog ﬁlter (such as a ﬁrst-order ﬁlter)
is used in conjunction with a sampling rate much higher than necessary. The samples
are then passed through a digital decimation/antialiasing ﬁlter.
As an example, consider the continuous-time signal
x(t) = cos(1,000πt) + cos(2,000πt) + cos(3,000πt) + cos(4,000πt)
The spectrum of x(t) has four spectral lines at 500, 1,000, 1,500, and 2,000 Hz. Sample
x(t) at the 10-kHz rate and produce the following sequence
x(n) = x(t)|t=10−4n = cos(πn/10) + cos(2πn/10) + cos(3πn/10) + cos(4πn/10)
Then decimate x(n) by a factor of 21 to obtain a new sequence of samples. Deci-
mation reduces the sampling rate to 10,000/21 = 476.2 and produces the sequence
y(n) = x(21n). Reconstruct a new time function y(t) from the decimated samples. Take
the Fourier transform of y(t) and examine the relationship between Y( f ) and X( f ).
Decimation downshifts the spectral lines to 23.8, 47.6, 71.4, and 95.23 Hz, respectively.
[You may save x(n) and y(n) in the form of *.wav ﬁles and play them back through a
sound card to examine the effect of frequency downshifting. For further exploration see
Project 2 at the end of this chapter.]
Examples of Decimation by a Factor D
Let a new signal y(n) be generated from a given signal x(n) according to the following
rule:
y(n) = x(Dn)
where D is an integer greater than one. This is a special type of compression of the
time axis of the discrete-time signal x(n) and is called decimation by a factor D. It is
equivalent to keeping a sample and dropping the next D −1 samples in the original
signal. A decimation process that is referenced at n = 0 may be summarized by
...
keep x(−D)
⇒call it y(−1)
drop x(−D + 1)
drop x(−D + 2)
...
drop x(−1)
keep x(0)
⇒call it y(0)
drop x(1)
drop x(2)
...
drop x(D −1)
keep x(D)
⇒call it y(1)

914
CHAPTER 16
Discrete-Time Fourier Transform
drop x(D + 1)
drop x(D + 2)
...
drop x(2D −1)
keep x(2D)
⇒call it y(2)
drop x(2D + 1)
drop x(2D + 2)
...
drop x(3D −1)
keep x(3D)
⇒call it y(3)
...
Decimating a signal resembles shrinking its time scale. An example of decimation
by factors 2 and 5 for x(n) = (0.6)nu(n) and its effect in the frequency domain
(with aliasing) are shown in Figure 16.11. Figure 16.12 shows decimation of x(n) =
sin2(πn/10)/(πn/10)2 by factors 2 and 4, which extend the DTFT of the newly gener-
ated signal to near the full range −0.5 < f < 0.5 (in Hz) with no aliasing. See Examples
16.17 and 16.18.
Loosely speaking, decimation expands the range of frequency components away
from the ﬁxed points ±kπ on the ω axis. Because of this, aliasing may occur, leading
to signal distortion and loss of information, in which case one cannot retrieve X(ω)
from Y(ω).
Decimating x(n) by a factor D will not lead to aliasing if x(n) is band limited
enough; that is, if |X(ω)| = 0, ω ≥π/D. For such a class of signals it can be shown
that decimation results in the following effect in the frequency domain:
x(n)
⇐⇒
X(ω)
y(n) = x(Dn) ⇐⇒
Y(ω) = 1
D X(ω/D)
The proof is shown below.
X(ω) =
∞

n=−∞
x(n)e−jωn
Y(ω) =
∞

n=−∞
y(n)e−jωn =
∞

n=−∞
x(Dn)e−jωn
= 1
D X
 ω
D

Therefore, x(n) may be retrieved from y(n) = x(Dn). These observations are not
surprising as elaborated in the following two cases.
Case 1
Sampled at the minimum (Nyquist) rate, the spectrum of the resulting x(n) occupies the
full range of −π < ω < π. Decimation of x(n) by a factor D expands the frequency

Signals and Systems
915
range of the signal in the discrete domain in both directions, leftward and rightward
simultaneously, around the ﬁxed points ±kπ on the ω-axis. Because the original signal
occupies the full frequency range, this causes aliasing. The spectrum X(ω) may not be
derivedfrom Y(ω).Decimationof x(n)meanslossofsamplesrequiredforreconstruction
of the original signal. It results in aliasing in the frequency domain. By removing samples
from x(n) one throws away valuable information that cannot be retrieved. As an example,
consider a continuous-time low-pass signal sampled at a rate 1.5 times the minimum
(Nyquist) rate. The result is x(n) whose DTFT X( f ) occupies the discrete frequency
range −0.333 < f < 0.333 Hz. Decimation of x(n) by a factor 2 expands the frequency
range of the signal in the discrete domain by factor 2, produces overlap with neighboring
segments, and causes aliasing.
Case 2
Sampled at a sufﬁciently higher-than-minimum rate (for example, at D-times the Nyquist
rate, to be called oversampling by a factor D), the spectrum of the resulting x(n) occupies
the range of −π/D < ω < π/D. Decimation of x(n) by a factor D expands the ω-
axis but doesn’t cause aliasing because of oversampling. The spectrum X(ω) may be
derived from Y(ω). Decimation of x(n) doesn’t result in the loss of samples required
for reconstruction of the original signal. By removing samples from x(n) one throws
away redundant information that still may be found in the remaing samples. As an
example, consider a continuous-time low-pass signal oversampled by a factor 5 (5 times
the Nyquist rate). The DTFT of the resulting x(n) occupies the discrete frequency range
−0.1 < f < 0.1 Hz. Decimation of x(n) by a factor 2 expands the plot of X( f ) to
−0.2 < f < 0.2 Hz but doesn’t cause aliasing. X( f ) may still be derived from the
DTFT of the decimated signal.
Example
16.17
The time constant of an exponentially decaying continuous-time function is 200 µsec.
It is sampled every 100 µ sec.
a.
Find x(n) and X(ω).
b.
Decimate x(n) by a factor 2 and call the new function y(n).
c.
Find Y(ω) and relate it to X(ω).
Can x(t) be reconstructed from y(n)?
Solution
x(n) = x(t)



t=10−4n = e−0.5nu(n) ≈(0.6)nu(n),
X(ω) =
∞

n=0
(0.6)ne−jωn =
1
1 −0.6e−jω
y(n) = x(2n) = (0.36)nu(n), Y(ω) =
∞

n=0
(0.36)ne−jωn =
1
1 −0.36e−jω ̸= X
ω
2


916
CHAPTER 16
Discrete-Time Fourier Transform
See Figure 16.11. Note that from a knowledge of Y(ω) [equivalently, y(n)] one
may not ﬁnd X(ω) exactly. Therefore, x(t) cannot be reconstructed from y(n).
1
0
–20
–15
–10
–5
0
5
10
15
20
1
0
(a)
(b)
(c)
1
0
–5
–4
–3
–2
–1
0
1
2
Time (s)
Frequency (Hz)
3
4
5
1
0
1
0
1
0
|X( f)|
x(n)
–10 –8
–6
–4
–2
0
2
4
6
8
10
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.11 Decimation of x(n) = (0.6)nu(n) (left column) by factors of 2 and 4 and its effect on the DTFT (right
column). Because X(ω) covers the full frequency range, decimation of x(n) produces aliasing. (a) shows the original
signal, while (b) and (c) give the decimated versions.
Example
16.18
Repeat Example 16.17 for the low-pass signal
x(t) = sin2(1,000πt)
(1,000πt)2
and show that in this case x(t) may be reconstructed from the decimated discrete-time
function.
Solution
x(n) = x(t)



t=10−4n =

sin
 πn
10

πn
10
2
See Figure 16.12(a) for X(ω).
y(n) = x(2n) =

sin
 πn
5

πn
5
2
[Except at n = 0 where y(0) = x(0)],
Y(ω) = 1
2 X
ω
2

. See Figure 16.12(b).

Signals and Systems
917
One may obtain X(ω) from Y(ω) [equivalently, x(n) from y(n)]. Therefore, an exact
x(t) can be reconstructed from y(n).
1
0
–10 –8
–6
–4
–2
0
2
4
8
6
10
1
0
–20
20
–15
15
–10
10
–5
5
0
10
0
(a)
(b)
(c)
1
0
–5
5
4
3
2
1
–4
–3
–2
–1
0
Time (s)
Frequency (Hz)
10
0
10
0
|X( f)|
x(n)
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.12 Decimation of x(n) = sin2(πn/10)/(πn/10)2 (left column) by factors of 2 and 4 and its effect on the
DTFT (right column). Because X(ω) covers one-ﬁfth of the full frequency range, decimation by a factor of 2 or 4
extends its frequency with no aliasing. (a) shows the original signal, while (b) and (c) give the decimated versions.
Example
16.19
Consider the low-pass signal
x(n) = sin(ω0n)
πn
⇐⇒
X(ω) =
	
1,
|ω| ≤ω0
0,
elsewhere
Assuming ω0 ≤π/4, decimate x(n) by a factor 2 to ﬁnd y(n) and its DTFT.
Solution
x(n) = sin( πn
4 )
πn
y(n) = x(2n) = sin( πn
2 )
2πn
Y(ω) =
 1
2,
|ω| ≤π/2
0,
elsewhere

918
CHAPTER 16
Discrete-Time Fourier Transform
Note that Y(ω) = 1
2 X
 ω
2

. For the special case of ω0 = π/2 we get
y(n) = 1
2d(n) ⇐⇒Y(ω) = 1
2
16.12
Interpolation
Interpolation may be viewed as the converse of decimation. It involves adding more
samples. For example, adding an additional sample between two existing samples is
called interpolation by a factor of 2. To interpolate by a factor 10 we would add 9
new samples for every existing one. Interpolation by factor I of an existing signal x(n)
generates a new signal y(n) such that x(n) = y(nI), where I is an integer greater than
one. The operation keeps a sample and adds I −1 new samples to the original signal.
The value of a newly generated sample is determined by an interpolation rule such as one
based on a linear or spline combination of the value of previously existing neighboring
samples.
1
0
–10
–8
–6
–4
–2
0
2
4
6
8
10
3
2
1
0
(a)
(b)
1
0
–10
–8
–6
–4
–2
0
Time (s)
Frequency (Hz)
2
4
6
8
10
3
2
1
0
|X( f)|
x(n)
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.13 Interpolation by a factor of 2 narrows the DTFT of x(n) = (0.6)nu(n) by 2. Note the reduction of
high frequencies in the DTFT. (a) shows the original signal, while (b) gives the interpolated version.

Signals and Systems
919
Interpolation increases the number of samples but is not exactly equivalent to having
thesamplingdoneatahigherrate.Thenewsamplescreatedbyinterpolationdon’taddany
information to the signal because they are derived from the samples already present in the
discrete-time signal, and not from the original signal in the continuous-time domain. In
that sense distortions caused by an initially inadequate sampling rate can’t be remedied by
interpolation. Nonetheless, in addition to satisfying several other needs (e.g., matching a
signal’s rate to that of a system), increasing number of samples can simplify the structure
of reconstruction ﬁlters as was shown in Example 10.5 of Chapter 10.
Examples of Interpolation by a Factor I
Visualize stretching the time axis of a discrete-time signal x(n) in a way that (I −1),
I ≥1, new samples between successive samples are generated, producing a new signal
y(n). Unlike the case of zero-insertion, the value of a newly generated sample is deter-
mined by an interpolation rule, such as one based on a linear or spline combination of
the values of previously existing neighboring samples. An example of interpolation of
x(n) = (0.6)nu(n) and its effect on X(ω) for I = 2 is shown in Figure 16.13. Another
example is shown in Figure 16.14 for the sinc-type signal x(n) = 3 sin(πn/3)/(πn) and
I = 5. It resembles compressing the frequency axis by a factor 5, while keeping the
1
0
–10
–8
–6
–4
–2
0
2
4
6
8
10
2
1
0
(a)
(b)
1
0
–10
–8
–6
–4
–2
Time (s)
0
2
4
6
8
10
1.6
1
0
Frequency (Hz)
|X( f)|
x(n)
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.14 Interpolation by a factor 5 applied on the sinc-type signal x(n) = 3 sin(πn/3)/(πn). The effect on the
DTFT is a compression of the frequency axis by a factor of 5 while the points at multiples of 0.5 Hz are kept ﬁxed.
(a) shows the original signal, while (b) gives the interpolated version.

920
CHAPTER 16
Discrete-Time Fourier Transform
points at multiples of 0.5 Hz ﬁxed. Because of this, repetitions of X(ω) don’t appear in
the newly generated DTFT (unlike zero-insertion).
Several methods are used to generate the new samples from the neighborhood of
the original samples. Examples are: linear, spline, or by increasing the sampling rate. In
general, interpolation and decimation may be viewed as converse operations on discrete
signals.
16.13
How Rate Conversion Reshapes DTFT
Decimation and interpolation of discrete-time signals (discussed in sections 16.11 and
16.12) are special cases of rate conversion. They become more meaningful when they
are considered within the framework of sampling and reconstruction of the continuous-
time signal from which the discrete-time signal originates. It is, therefore, constructive
to refer to Figures 10.2 and 10.4 in Chapter 10 (modiﬁed here as Figure 16.15). In this
section we represent the continuous-time frequency by F (in Hz).
Consider a continuous-time signal x(t) with the highest frequency at F0 [Figure
16.15(a)].7 LettheFouriertransformof x(t)beshownby X(F), X(F) = 0for|F| > F0.
Sample x(t) at the rate of Fs samples per second by multiplying it with the train of unit
impulses every T = 1/Fs seconds. The time domain representation of the sampled signal
is
x(t) = x(t)
∞

n=−∞
δ(t −nT ) =
∞

n=−∞
x(nT )δ(t −nT )
The Fourier transform of the sampled signal is
X(F) = 1
T
∞

n=−∞
X(F −nFs)
Figure 16.15(b) shows X(F) for Fs = 6F0 (i.e., oversampled by a factor of 3).
Decimating x(n) by a factor D corresponds to reducing the sampling rate to Fs/D
and may cause aliasing. This is illustrated in Figures 16.15(c) (D = 2, no aliasing) and
16.15(d) (D = 4, aliasing occurs).
Interpolation by a factor I corresponds to having increased the sampling rate to
Fs × I. If applied to the signal of Figure 16.15(d), it pulls the triangular lobes farther
apart (see Figure 16.16). Also note that while interpolation doesn’t produce aliasing,
distortion, or an irreversible change in the signal, it doesn’t add any new information to
it either. It can’t reverse an aliasing previously produced by a high decimation factor or
an inadequately low sampling rate.
7Sampling the signal at the rate 2F0 eliminates frequencies higher than F0 and causes aliasing if the
continuous-time signal contains frequencies greater than F0.

Signals and Systems
921
–F0
X(F)
F
(a)
F0
0
–F0
–3F0
–6F0
Y(F)
Decimation by a factor D
F
(c)
D = 2
F0
3F0
6F0
0
–F0
–6F0
–3F0
3F0
6F0
X(F)
F
(b)
(d)
F0
0
–F0
–3F0
–6F0
Y(F)
F
F0
3F0
6F0
0
FIGURE 16.15 (a) Fourier transform of x(t), a continuous-time low-pass signal with the highest frequency at F0. The
Nyquist rate for this signal is 2F0. (b) Sampling x(t) uniformly by a train of unit impulses at the rate Fs (every T = 1/Fs
sec) produces x(n). The sampled time function is x(t) = 
x(nT )δ(t −nT ). Its Fourier transform is shown for Fs = 6F0
(i.e., oversampled by a factor of 3). Because of the high sampling rate, no aliasing occurs. (c) Decimating x(n) by the
factor 2 corresponds to reducing the sampling rate to Fs = 3F0, causing no aliasing. (d) Decimating x(n) by the factor 4
corresponds to reducing the sampling rate to Fs = 1.5F0, causing aliasing.

922
CHAPTER 16
Discrete-Time Fourier Transform
Interpolation by a factor 2
–F0
–3F0
–6F0
Y(F)
F
F0
3F0
6F0
0
–F0
–3F0
–6F0
Z(F)
F
F0
3F0
6F0
0
FIGURE 16.16 Interpolation appears to pull the triangular lobes farther apart but cannot remove
aliasing. An interpolation by the factor 2 applied to the signal in (a) results in (b).
Note that in the above discussion the frequency axis represents the actual frequency
in the continuous-time domain. Decimation and interpolation don’t change the frequency
scale (assuming that the digital-to-analog conversion from the discrete to the continuous
domains remains at a ﬁxed rate). In Figures 16.15 and 16.16 it is Fs, which manipulates
the frequency components of the sampled signal. Many signal processing computer
packages contain decimation and interpolation tools, mostly labeling the frequency axis
in the continuous-time domain.

Signals and Systems
923
Appendix 16A A Short Table of DTFT Pairs
DTFT Pairs
−π ≤ω ≤π
−0.5 ≤f ≤0.5
x(n) = 1
2π

π
−π
X(ω)e jωndω
⇐⇒
X(ω) =
∞

−∞
x(n)e−jωn
X( f ) =
∞

−∞
x(n)e−j2π f n
=

0.5
−0.5
X( f )e j2π f nd f
1, all n
⇐⇒
2πδ(ω)
δ( f )
d(n)
⇐⇒
1, all ω
1, all f
d(n −n0)
⇐⇒
e−jn0ω
e−j2πn0 f

1, 0 ≤n < N
0, elsewhere
⇐⇒
sin Nω
2
sin ω
2
e−j( N−1
2
)ω
sin(Nπ f )
sin(π f ) e−j(N−1)π f

1,
−M ≤n ≤M
0,
elsewhere
⇐⇒
sin(M + 1
2)ω
sin(ω/2)
sin(2M + 1)π f
sin(π f )
sin(ω0n)
πn
⇐⇒

1,
−ω0 ≤ω ≤ω0
0,
elsewhere

1,
−f0 ≤f ≤f0,
f0 = ω0/(2π)
0,
elsewhere
u(n)
⇐⇒
1
1 −e−jω + πδ(ω)
1
1 −e−j2π f + 1
2δ( f )
u(−n)
⇐⇒
1
1 −e jω + πδ(ω)
1
1 −e j2π f + 1
2δ( f )
u(n) −u(−n)
⇐⇒
−
j sin ω
1 −cos ω
−
j sin(2π f )
1 −cos(2π f )
u(n) −u(−n) + d(n)
⇐⇒
1 −cos ω −j sin ω
1 −cos ω
1 −cos(2π f ) −j sin(2π f )
1 −cos(2π f )
u(n) −u(−n) −d(n)
⇐⇒
cos ω −j sin ω −1
1 −cos ω
cos(2π f ) −j sin(2π f ) −1
1 −cos(2π f )
cos(ω0n)
⇐⇒
π [δ(ω + ω0) + δ(ω −ω0)]
1
2[δ( f + f0) + δ( f −f0)],
f0 = ω0/(2π)
sin(ω0n)
⇐⇒
−jπ [δ(ω + ω0) −δ(ω −ω0)]
1
2 j [δ( f + f0) −δ( f −f0)],
f0 = ω0/(2π)
anu(n), |a| < 1
⇐⇒
1
1 −ae−jω
1
1 −ae−j2π f
a−nu(−n), |a| < 1
⇐⇒
1
1 −ae jω
1
1 −ae j2π f
a|n|, |a| < 1
⇐⇒
1 −a2
1 + a2 −2a cos ω
1 −a2
1 + a2 −2a cos(2π f )
nanu(n), |a| < 1
⇐⇒
ae−jω
(1 −ae−jω)2
ae−j2π f
(1 −ae−j2π f )2

924
CHAPTER 16
Discrete-Time Fourier Transform
Appendix 16B Symmetry Properties of the DTFT
Property
Time
⇔
Frequency
x(n) Is a Complex Function
Basic pair
x(n)
⇔
X(ω)
Time reversal
x(−n)
⇔
X(−ω)
Conjugation
x∗(n)
⇔
X ∗(−ω)
Real part of x(n)
RE{x(n)}
⇔
Xe(ω)
Imaginary part of x(n)
IM{x(n)}
⇔
−j Xo(ω)
Conjugate symm. part of x(n)
xe(n)
⇔
RE{X(ω)}
Conj. ant. symm. part of x(n)
xo(n)
⇔
jIM{X(ω)}
x(n) is a Real Function
Real function
x(n) = x∗(n)
⇔
X(ω) = X ∗(−ω)
(Hermitian symmetry)
Even function
x(n) = x(−n)
⇔
X(ω) is real
Odd function
x(n) = −x(−n)
⇔
X(ω) is imaginary
Even part of x(n)
xe(n) = x(n) + x(−n)
2
⇔
RE{X(ω)}
(real and even)
Odd part of x(n)
xo(n) = x(n) −x(−n)
2
⇔
jIM{X(ω)}
(real and odd)

Signals and Systems
925
Appendix 16C Summary of DTFT Theorems
Theorem
Time
⇔Frequency, ω
⇔Frequency, f
Deﬁnition
x(n) = 1
2π

π
−π
X(ω)e jωndω ⇔X(ω) =
∞

−∞
x(n)e−jωn
⇔X( f ) =
∞

−∞
x(n)e−j2π f n
x(n) =

π
−π
X( f )e j2π f nd f
Periodicity
x(n)
⇔X(ω) = X(ω + 2π)
⇔X( f ) = X( f + 1)
Linearity
ax(n) + by(n)
⇔aX(ω) + bY(ω)
⇔aX( f ) + bY( f )
Time shift
x(n −n0)
⇔e−jnoωX(ω)
⇔e−j2πno f X( f )
Frequency shift
e jωonx(n)
⇔X(ω −ω0)
⇔X( f −f0),
f0 = ω0/(2π)
Modulation
x(n) cos ω0n
⇔
X(ω −ω0) + X(ω + ω0)
2
⇔
X( f −f0) + X( f + f0)
2
Time reversal
x(−n)
⇔X(−ω)
⇔X(−f )
n-Multiplication
nx(n)
⇔
j d X(ω)
dω
⇔
j
2π
d X( f )
d f
Decimation
x(an)
⇔
1
a X(ω/a)
⇔
1
a X( f/a)
Conjugation
x∗(n)
⇔X ∗(−ω)
⇔X ∗(−f )
Multiplication
x(n)y(n)
⇔
1
2π X(ω) ∗Y(ω)
⇔X( f ) ∗Y( f )
= 1
2π

π
−π
X(φ)Y(ω −φ)dφ
=

0.5
−0.5
X(φ)Y( f −φ)dφ
Zero time
x(0) = 1
2π

π/2
−π/2
X(ω)dω =

0.5
−0.5
X( f )d f
Zero frequency
X(0) =
∞

−∞
x(n)
Parseval’s theorem
∞

−∞
|x(n)|2 = 1
2π

π
−π
|X(ω)|2dω =

0.5
−0.5
|X( f )|2d f
∞

−∞
x(n)y∗(n) = 1
2π

π
−π
X(ω)Y ∗(ω)dω =

0.5
−0.5
X( f )Y ∗( f )d f

926
CHAPTER 16
Discrete-Time Fourier Transform
16.14
Problems
Solved Problems
1. Find the DTFT of x(n) = d(n + 1) + d(n) + d(n −1) and plot its magnitude for −π < ω < π.
x(n) =
 1,
n = −1, 0, 1
0,
elsewhere
Solution
X(ω) = 1 + e jω + e−jω = 1 + 2 cos ω
Within the period −π < ω < π, the magnitude of X(ω) is given below. See Figure 16.17(a).
|X| =
	
2 cos ω + 1,
|ω| < 2π
3
2| cos ω| −1,
elsewhere
and θ =
	
0,
|ω| < 2π
3
π,
elsewhere
–8
1
0
–6
–4
–2
0
2
4
6
8
–0.5
–0.3
(a)
(b)
–0.1
–0.2
–0.4
0
0.1
0.3
0.5
0.4
0.2
3
2
1
0
–8
1
0
–6
–4
–2
0
2
Time (s)
4
6
8
–0.5
–0.3
–0.1
–0.2
–0.4
Frequency (Hz)
0
0.1
0.3
0.5
0.4
0.2
2
1
0
|X( f)|
x(n)
FIGURE 16.17 Two discrete-time signals (on the left) and their DTFT magnitudes (on the right). (a) x(n) = {1, 1
↑, 1}.
(b) x(n) = d(n + 6) + d(n −6).
2. Given h(n) = d(n + k) + d(n −k), ﬁnd H(ω) by applying the deﬁnition of the DTFT. Plot its magnitude for k = 6
and −π < ω < π. Determine its period and zero-crossings.

Signals and Systems
927
Solution
H(ω) = e jωk + e−jωk = 2 cos(kω). One period of H(ω) is 2π/k. Zero-crossings are at ω = ±mπ/(2k), where m
is an odd integer. For k = 6, see Figure 16.17(b). The zero-crossings are at ω = ±mπ/12, with m odd.
3. The unit-sample response of a discrete-time LTI system is h(n) = d(n) + d(n −8). A sinusoidal signal x(n) =
cos(2πn/N) is applied to the input. Find the output
a. by the frequency-domain method (DTFT)
b. by the time-domain method (convolution)
For what values of N does the ﬁlter block the input (i.e., the output is zero)?
Solution
a. DTFT:
H(ω) = 1 + e−j8ω = 2 cos(4ω)e−j4ω
x(n) = 1
2

e jω0n + e−jω0n
, where ω0 = 2π
N
X(ω) = π [δ(ω + ω0) + δ(ω −ω0)]
Y(ω) = X(ω)H(ω) = 2π cos(4ω0) 
e j4ω0δ(ω + ω0) + e−j4ω0δ(ω −ω0)
y(n) = 2 cos(4ω0) cos [ω0(n −4)]
b. Convolution: y(n) = x(n) + x(n −8) = cos(ω0n) + cos [ω0(n −8)]
However,
cos a + cos b = 2 cos

a + b
2

cos

a −b
2

Therefore,
y(n) = 2 cos(4ω0) cos [ω0(n −4)] .
The system multiplies the signal by the gain factor 2 cos(4ω0) and introduces a phase (lag) of −4ω0. The gain factor
is zero when ω0 = ±mπ/8, with m an odd integer. In the present case with ω0 = 2π/N, the blockage occurs when
N = 16.
4. Single rectangular pulse. Apply the deﬁnition to derive a closed-form expression for the DTFT of a single rectan-
gular pulse which is N unit samples long.
Solution
a. Causal pulse. Assume the pulse starts at n = 0.
x(n) =
 1,
0 ≤n < N
0,
otherwise
The DTFT of x(n) is
X(ω) =
N−1

n=0
e−jωn = 1 −e−j Nω
1 −e−jω = sin( Nω
2 )
sin( ω
2 ) e−j( N−1
2
)ω
Note that X(ω) may be written as
X(ω) = Xr(ω)e−j( N−1
2
)ω,
Xr(ω) = sin( Nω
2 )
sin( ω
2 )
where Xr(ω) is a real function. The magnitude and phase of X(ω) are
|X| = |Xr| =




sin( Nω
2 )
sin( ω
2 )




 ,
θ = −

N −1
2

ω ± kπ
The phase is a piecewise linear function of ω.

928
CHAPTER 16
Discrete-Time Fourier Transform
b. Even pulse. Shift the causal pulse of width N = 2M + 1 to the left by M units to obtain the even pulse. The
shift adds Mω = ( N−1
2 )ω to the phase of its DTFT, resulting in
X(ω) =
sin( Nω
2 )
sin( ω
2 ) e−j( N−1
2
)ω

× e j( N−1
2
)ω = sin( Nω
2 )
sin( ω
2 )
Figures 16.18(a) and (b) display x(n) for N = 5 and 31, respectively, and normalized |X( f )| for −0.5 < f <
0.5 Hz.
1
0
–20
–10
10
20
0
1
0
(a)
1
0
–20
–10
10
20
1
0
(b)
0
Time (s)
Frequency (Hz)
|X( f)|
x(n)
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
–0.5
–0.3
–0.1
0.1
0
0.3
0.5
–0.4
–0.2
0.2
0.4
FIGURE 16.18 (a), (b). Two rectangular pulses of width N and the normalized magnitudes of their DTFTs, |X( f )|,
for −0.5 < f < 0.5. (a) N = 5. (b) N = 31.
5. A triangular pulse. Find the DTFT of the even isosceles triangular pulse of height 1 and base N = 2M + 1 that
contains (N −2) = (2M −1) nonzero unit samples, the two extreme corners of the base having zero values.
Solution
The mathematical expression for the pulse is
x(n) =



1 +
n
M ,
−M ≤n ≤0
1 −
n
M ,
0 ≤n ≤M
0,
elsewhere
The DTFT of x(n) is
X(ω) =
M

n=−M
x(n)e−jωn = 1 + 2
M

n=1
(1 −n
M ) cos(ωn)
Note that X(ω) = Xr(ω) ≥0 and θ(ω) = 0. For M = 2, we get X(ω) = 1 + cos ω, as was derived in Example
16.2 directly. Figure 16.19 displays Xr(ω) for M = 15.

Signals and Systems
929
Alternate Approach
X(ω) may also be found in closed form by noting that the triangular pulse may be generated by convolving an even
rectangular pulse of width M with itself. The DTFT of the triangular pulse is, therefore, the square of the DTFT of
the rectangular pulse. X(ω) is a real and even function of ω with period 2π. Within one period it contains 2N lobes,
which are all nonnegative, but become tangent to the ω-axis at regular intervals ω = ±2πk/N. See Figure 16.19
1
0
–25
–20
–15
–10
–5
Time (s)
0
5
10
15
20
25
16
12
8
6
4
0
–0.4
–0.5
–0.3
–0.2
–0.1
0
Frequency (Hz)
0.1
0.2
0.3
0.4
0.5
X( f)
x(n)
FIGURE 16.19 An even isosceles triangular pulse of height 1 and base N = 2M + 1 is expressed by
x(n) =



1 +
n
M ,
−M ≤n ≤0
1 −
n
M ,
0 ≤n ≤M
0,
elsewhere
The pulse contains (N −2) = (2M −1) nonzero unit samples, the two extreme corners of the base having zero values.
The DTFT of x(n) is
X(ω) = 1 + 2
M

n=1
(1 −n
M ) cos(ωn)
Note that X(ω)=Xr(ω) ≥0 and θ(ω)=0. The DTFT is nonnegative and its ﬁrst zero occurs at f = ± 1/(2N) (compare
with the DTFT of a rectangular pulse). The DTFT of the triangular pulse is also equal to the square of the DTFT of a
rectangular pulse of length M. Expressed as a function of f , it can, therefore, be written as
X( f ) = sin2(π M f )
sin2(π f )
This ﬁgure displays X( f ), −0.5 < f < 0.5, for M = 15.

930
CHAPTER 16
Discrete-Time Fourier Transform
Chapter Problems
6. Find the DTFT of the following single rectangular pulses.
a. x(n) = d(n) + d(n −1) ≡{· · · 0, 1
↑, 1, 0, · · ·}
b. x(n) = d(n) + d(n −1) + d(n −2) ≡{· · · 0, 1
↑, 1, 1, 0, · · ·}
c. x(n) = d(n) + d(n −1) + d(n −2) + d(n −3) ≡{· · · 0, 1
↑, 1, 1, 1, 0, · · ·}
7. Find the DTFT of the following single rectangular pulses.
a. x(n) = {· · · 0, 0.5
↑, 1.5, 2, 1.5, 0.5, 0, · · ·}
b. x(n) = {· · · 0, 0.5
↑, 1, 1.5, 2, 1.5, 1, 0.5, 0, · · ·}
8. Find the DTFT of the following single rectangular pulses.
a. x(n) = {· · · 0, 0.5
↑, 1.5, 2, 2, 1.5, 0.5, 0, · · ·}
b. x(n) = {· · · 0, 0.5
↑, 1, 1.5, 2, 2, 1.5, 1, 0.5, 0, · · ·}
9. Find the DTFT of x(n) =

1,
0 ≤n < N
0,
elsewhere
and plot |X(ω)| for
a. N = 16
b. N = 17
c. N = 30
10. Find the DTFT of x(n) =

a−n,
0 ≤n < N
0,
elsewhere
, a = 1.396, and plot |X(ω)| for
a. N = 3
b. N = 4
c. N = 30
11. Find the DTFT of x(n) =

e−n
5 ,
0 ≤n < N
0,
elsewhere
and plot |X(ω)| for
a. N = 3
b. N = 4
c. N = 30
12. Find the DTFT of x(n) = αnu(n) and plot its magnitude and phase for
a. α = 0.95
b. α = 0.8
c. α = 0.5
13. Find the DTFT of x(n) = e−n
5 u(n) and plot its magnitude and phase.
14. Find the DTFT of x(n) = (α)n cos(ω0n)u(n) and plot its magnitude and phase for the following parameters:
a. α = 0.5 and ω0 = π
4
b. α = 0.5 and ω0 = π
2
c. α = 0.5 and ω0 = 3π
4
d. α = 0.5 and ω0 = π
e. α = 0.9 and ω0 = π
4
f. α = 0.9 and ω0 = π
2
g. α = 0.9 and ω0 = 3π
4
h. α = 0.9 and ω0 = π

Signals and Systems
931
i.
α = 0.95 and ω0 = π
4
j.
α = 0.95 and ω0 = π
2
k.
α = 0.95 and ω0 = 3π
4
l.
α = 0.95 and ω0 = π
m. α = 0.99 and ω0 = π
4
n. α = 0.99 and ω0 = π
2
o.
α = 0.99 and ω0 = 3π
4
p. α = 0.99 and ω0 = π
15. Discrete-time windows. A window is a ﬁnite-duration pulse. Some familiar windows of interest are the following:
rectangular, triangular (or Bartlett), Blackman, Hamming, and Hanning. Their time functions are listed in the table
below. Find their DTFT and plot their magnitude using dB scale.
Mathematical expressions for discrete-time windows. All windows are N samples wide and
speciﬁed for 0 ≤n < N. Elsewhere, the windows have zero values.
Window Type
Mathematical Expression in the Time Domain, 0 ≤n < N
Rectangular
w(n) = 1
Triangular
w(n) =
	
2n
N−1,
0 ≤n < N−1
2
2 −
2n
N−1,
N−1
2
≤n < N
Hanning
w(n) = 0.5 −0.5 cos

2πn
N −1

Hamming
w(n) = 0.54 −0.46 cos

2πn
N −1

Blackman
w(n) = 0.42 −0.5 cos

2πn
N −1

+ 0.08 cos

4πn
N −1

16. Trapezoid window. In Figure 16.20 let τ1 = 100 and τ = 800, both in msec. Sample the functions shown in (a)
and (b) at the rate of 100 samples per second. Find their DTFT and plot their magnitude. Note that the window in
Figure 16.20(b) is the integral of the function in (a). Can you relate the two DTFTs? What is their relationship?
V0
t
t
τ1
τ
–V0
(a)
(b)
0
τ1
τ1
τ1
V1
0
τ
FIGURE 16.20

932
CHAPTER 16
Discrete-Time Fourier Transform
17. Sample x(n) and y(n) in Figure 16.21 at the rate of 20 samples per second, with one sample at t = 0. Obtain their
DTFT and ﬁnd a relationship between them.
(a)
x(t) =







sin 2πt,
0 ≤t < 0.5
0,
0.5 ≤t < 1.5
sin 2πt,
1.5 ≤t < 2
0,
elsewhere
1
Magnitude
0
–1
–1
–0.5
0
0.5
1
1.5
Time (s)
2
2.5
3
3.5
4
(b)
y(t) =

t
−∞
x(t)dt
=









1
2π (1 −cos 2πt) , 0 ≤t < 0.5
1
π ,
0.5 ≤t < 1.5
1
2π (1 −cos 2πt), 1.5 ≤t < 2
0,
elsewhere
Time (s)
0.4
0.3
0.2
0.1
0
Magnitude
–0.1
–1
0
–0.5
0.5
1
1.5
2
2.5
3
3.5
4
FIGURE 16.21
18. Construct the DTFT of x(n) = 1 + 2 cos(πn) from its components to show
X( f ) =
1

k=−1
δ( f −k/2)
19. Find the DTFT of cos(2πn/N) for
a. N = 2
b. N = 4
20. Verify the DTFT pairs given below.
a.

k
d(n −k) ⇒

k
δ( f −k)

Signals and Systems
933
b.

k
d(n −kN)
⇒
1
N

k
δ( f −k/N)
c. cos(πn)
⇒
1
2

k odd
δ( f −k/2)
21. Waveforms with even symmetry. Three periodic waveforms having even symmetry are shown in Figure 16.22.
Sample them at the rate of 5 samples per second with a sample taken at t = 0 and ﬁnd the DTFT of the discrete-time
functions.
(b) An even half-circle pulse train,
period = 2 seconds.
Amplitude
1
0
–2
0
1
–1
Time (s)
2
Amplitude
Time (s)
(a) An even square pulse train,
period = 4 seconds.
1
0
–5
0
–1
1
3
–3
5
(c) An even triangular pulse train,
period = 3 seconds.
Amplitude
1
0
–4
–2
0
–1
1
2
4
Time (s)
FIGURE 16.22 Three waveforms with even symmetry: x(t) = x(−t).
22. Waveforms with odd symmetry. Three periodic waveforms having odd symmetry are shown in Figure 16.23.
Sample them at the rate of 5 samples per second with a sample taken at t = 0 and ﬁnd the DTFT of the discrete-time
functions.
1
Amplitude
–1
0
–2
0
1
2
–1
Time (s)
(b) An odd sine wave,
period = 4 seconds.
(c) An odd sawtooth pulse train,
period = 2 seconds.
1
Amplitude
–1
0
–2
0
1
–1
Time (s)
2
1
Amplitude
–1
0
–3
–2
–1
0
1
2
Time (s)
(a) An odd square pulse train,
period = 2 seconds.
3
FIGURE 16.23 Three waveforms with odd symmetry: x(t) = −x(−t).
23. Half-wave symmetry. A function x(t) is said to have half-wave symmetry if x(t) = −x(t + T/2), where T is the
period. The periodical waveforms shown in Figure 16.24 have half-wave symmetry. Sample them at the rate of 5
samples per second with a sample taken at t = 0 and ﬁnd the DTFT of the discrete-time functions. Find if the DTFT
Xn = 0 for n even, and the DTFT contains only odd harmonics.

934
CHAPTER 16
Discrete-Time Fourier Transform
1
Magnitude
–1
0
–2
–1
0
1
Time (s)
(a) A half-symmetric function,
period = 2 seconds.
2
1.5
0.5
0
–0.5
–1.5
Magnitude
–2
–1
0
1
Time (s)
(b) A half-symmetric function,
period = 2 seconds.
2
1
0
–1
Magnitude
–2
–1
0
1
Time (s)
(c) An odd function,
is half-symmetric.
2
FIGURE 16.24 Three waveforms with half-wave symmetry: x(t) = −x(t + T/2).
24. Five periodic functions xi(t), i = 1, · · · , 5 shown in Figure 16.25(a) to (e), respectively, are speciﬁed by T = 10
msec, τ = 1 msec, and V0 = 5 V.
a. Sample them at the rate of 5 kHz, with one sample at t = 0, and ﬁnd their DTFTs.
b. Deﬁne ζ(t) (pronounced zeta of t) to be a single 1-msec rectangular pulse with a height of 1.
ζ(t) =

1,
0 ≤t < 1 msec
0,
elsewhere
V0
–V0
T
T
T
0
t
τ
τ
(b)
(c)
(d)
(e)
–V0
V0
0
t
τ
τ
τ
τ
τ
–V0
0
t
V0
–V0
–V0
0
t
T
τ
τ
τ
V0
T
0
t
(a)
τ
τ
τ
V0
FIGURE 16.25

Signals and Systems
935
Similarly, sample ζ(t) with one sample at t = 0, call it ζ(n) and ﬁnd its DTFT. Express each sampled function in
Figure 16.25 in terms of ζ(n). Then investigate the relationships between their DTFT and DTFT of ζ(n).
25. In the periodic waveforms of Figure 16.25 let V0 = 1 and τ = 100 msec. Sample them at the rate of 1 kHz with a
sample taken at t = 0 and ﬁnd the DTFT of the discrete-time functions for
a. T = 10τ
b. T = 20τ
26. Three periodic functions x1(t), x2(t), and x3(t) shown in Figure 16.26(a), (b), and (c), respectively, are speciﬁed by
T = 10 msec, τ = 1 msec, and V0 = 5 V.
a. Sample the functions at the rate of 5 kHz with one sample at t = 0. Call the sampled functions x1(n), x2(n), and
x3(n) and ﬁnd their DTFTs.
b. Deﬁne ξ(t) (pronounced cai of t) to be a single right-angle triangular pulse with a height of 1 and a base of τ:
ξ(t) =
 t/τ,
0 ≤t < τ
0,
elsewhere
Similarly, sample ξ(t) with one sample at t = 0, call it ξ(n) and ﬁnd its DTFT. Express each sampled function in
Figure 16.26 in terms of ξ(n). Then investigate the relationships between the DTFTs of the sampled functions and
DTFT of ξ(n).
0
V0
T
t
τ
(a)
τ
0
V0
t
T
2
T
2
–V0
(b)
t
0
V0
τ
–V0
(c)
FIGURE 16.26
27. a. Sample the half-wave rectifed sinusoid with a base-to-peak voltage of 0 to Vo volts and frequency f (Fig-
ure 16.27a) at the rate of 20 f Hz. Choose the time origin so that the function is even with one sample at t = 0.
Find the DTFT of the sampled function.
b. Repeat for the full-wave rectiﬁed waveform [Figure 16.27(b)].
c. Repeat again for the waveform of Figure 16.27(c).
t
V0
0
T
t
V0
0
T
(a)
(b)
(c)
T
V0
0
–V0
t
FIGURE 16.27

936
CHAPTER 16
Discrete-Time Fourier Transform
28. In the periodic waveforms of Figure 16.28 let T = 1 sec. Sample them at the rate of 25 samples per second with a
sample taken at t = 0 and ﬁnd the DTFT of the discrete-time functions for
a. τ = 400 msec
b. τ = 500 msec
c. τ = 600 msec
(c)
V0
0
t
T
τ
(a)
V0
0
t
T
τ
(b)
V0
0
t
T
FIGURE 16.28
29. The periodical waveforms of Figure 16.29 have T = 2 and τ = 0.5 seconds. Sample them at the rate of 10 samples
per second with a sample taken at t = 0 and ﬁnd the DTFT of the discrete-time functions.
(a)
(b)
V0
–V0
0
T
t
T
2
t
V0
–V0
0
τ
T
2
FIGURE 16.29
30. Find h(n) of an FIR ﬁlter with H(ω) = 0 at ω = ±1050, ±1350, and ±1650. The FIR systems were introduced in
Chapter 11.
31. Find h(n) of an FIR ﬁlter with H(ω) = 0 at ω = ±300, ±600, and ±900.
32. Find H(ω) = Hr(ω)e j(ω) and plot |H(ω)| for the 21-term FIR deﬁned by
h(n) = {4
↑, 0, −5, 0, 6, 0, −11, 0, 32, 0, −50, 0, 32, 0, −11, 0, 6, 0, −5, 0, 4}
33. The system function of a discrete LTI ﬁlter H(z) = Y(z)
X(z) has two poles at p1,2 = ρe± jω0 and no zeros.
a. Write the expression for H(z) as a function of z−1.
b. Find H(ω) = Hr(ω)e jθ(ω) and plot Hr(ω) and θ(ω) for ω0 =
π
4 and ρ = 0.6, 0.8, 0.9, and 0.95. Specify
magnitude and phase of H(ω) at ω = π
4 . For each ρ, determine the maximum of the magnitude.
34. The H(z) of a discrete LTI ﬁlter has two poles at p1,2 = .95e± j π
4 and two zeros at z = 1, −1.
a. Write the expression for H(z) as a function of z−1.
b. Find and plot H(ω) = Hr(ω)e jθ(ω).
c. Discuss the differences between this ﬁlter and that of problem 33.

Signals and Systems
937
35. Let h(n) = b−nu(n), where b = 1.369.
a. Find H(ω).
b. Deﬁne
h1(n) =
 b−n,
for 0 ≤n < M
0,
elsewhere
Sketch h1(n) for M = 2 and M = 30.
c. Find H1(ω) as a function of M.
d. Compare |H1(ω)| and |H(ω)| for low M (M = 2) and high M (M = 30).
e. Deﬁne h2(n) = b−n for 0 ≤n < M and h2(n + M + 1) = h2(n) for all n. Plot h2(n) for M = 2 and M = 30.
f. Compare |H2(ω)| and |H(ω)| for low M (M = 2) and high M (M = 30).
36. Given the two ﬁlters:
	 Filter 1:
h1(n) = {0
↑, 1, 1, 1}
Filter 2:
h2(n) = {0
↑, 1, 0, 1, 0, 1}
a. Find H1(z−1) and H2(z−1).
b. Find and plot their frequency responses H1(ω) and H2(ω) in the form of H(ω) = Hre jθ. In each case evaluate
Hr(ω) and θ for ω = 0, π/4, π/2, 3π/4, and π.
c. What is the relationship between H1(ω) and H2(ω)?
d. The above ﬁlters operate with A/D and D/A at a 48-kHz sampling rate. The analog input is x(t) = cos(2π f t).
Find the analog outputs y1(t) and y2(t) for (i) f = 6 kHz, (ii) f = 12 kHz.
37. Four FIR ﬁlters are speciﬁed by their unit-sample responses given below.













Filter 1: h1(n) = {1
↑, −1}
Filter 2: h2(n) = {1
↑, 1}
Filter 3: h3(n) = {1
↑, −1, 1}
Filter 4: h4(n) = {1
↑, 1, 1}
Find the DTFT of each ﬁlter and plot its magnitude and phase. Comment on the type of each ﬁlter.
38. The continuous-time signal x(t) = 1 + cos(10πt) + cos(20πt) is sampled at the rate of 40 Hz and passed through
a ﬁlter characterized by the system function H(z). The ﬁlter’s output, y(n), is converted back to a continuous-time
signal at the same sampling rate of 40 Hz, to become y(t). Find y(n) and y(t) for the following systems:
a. H1(z) =
1 −z−1
1 −0.5z−1
b. H2(z) = 1 + z−1 + z−2
39. The unit-sample response of a digital ﬁlter is h(n) = {1
↑, 2, 1}.
a. Find H(ω) = Hr(ω)e−jθ(ω). Sketch Hr(ω) and θ(ω), −π < ω < π.
b. A continuous-time rectangular pulse
x(t) =
 1
for −5.1 msec < t < 5.1 msec
0
elsewhere
is sampled uniformly such that one sample occurs at t = 0. The resulting discrete signal x(n) is passed through
the above ﬁlter. The output y(n) is then converted to an analog signal. The same sampling rate R samples per

938
CHAPTER 16
Discrete-Time Fourier Transform
second (Hz) is used in A/D and D/A conversion. Find and sketch y(n) and y(t) for (i) R = 200 Hz and (ii)
R = 2,000 Hz. Observe and discuss their similarities to x(n) and x(t).
c. Repeat part b for a discrete-time sinusoidal input generated by sampling cos(1,000πt) at the rate of (i) R = 200
Hz and (ii) R = 2,000 Hz.
40. The unit-sample response of an FIR ﬁlter is h(n) = {1
↑, 0, −2, 0, 3, 4, 3, 0, −2, 0, 1}.
a. Find H(ω) and determine the ﬁlter’s type (low-pass, bandpass, band-stop, or high-pass).
b. Is the ﬁlter linear phase? Why or why not?
c. Determine the time delay produced in a sinusoidal signal sampled at the rate of 8 kHz and passed through the
ﬁlter.
41. Two FIR ﬁlters are speciﬁed by the unit-sample responses h1(n) and h2(n), where
h1(n) =
	
(0.64)n
0 ≤n < 3
0
otherwise
and h2(n) =
	
(0.8)n
0 ≤n < 5
0
otherwise
Discuss similarities and differences between H1(ω) and H2(ω). What can you deduce from H1(ω) about H2(ω)?
42. An FIR ﬁlter is speciﬁed by
h(n) =
	
(0.9)n,
for 0 ≤n < N;
0,
elsewhere.
Find H(ω). Plot |H(ω)|2 for N = 5 and N = 10. Compare results. What happens to the frequency response when
N goes to inﬁnity?
43. In a perfect integrator y(t) = 
x(t)dt. Three digital integrators approximate the above by
a. y(n) = x(n) + y(n −1)
b. y(n) = 0.5x(n) + 0.5x(n −1) + y(n −1)
c. y(n) = 0.333x(n) + 1.333x(n −1) + 0.333x(n −2) + y(n −2)
In each case ﬁnd H(w). Plot its magnitude and phase. Compare with the frequency response of a perfect integrator.
44. In a perfect differentiator y(t) = dx(t)
dt . Two digital differentiators approximate the above by
a. y(n) = x(n) −x(n −1)
b. y(n) = 0.5x(n) −0.5x(n −2)
Ineachcaseﬁnd H(w).Plotitsmagnitudeandphase.Comparewiththefrequencyresponseofaperfectdifferentiator.
45. The impulse response of an analog ﬁlter is h(t) = e−1,000tu(t). Sample it at the rate of Fs = 10 kHz.
a. Find the resulting h(n).
b. Find H(z) and determine its poles and zeros.
c. Find |H(ω)| and the 3-dB attenuation digital frequency.
d. Let the above digital ﬁlter be connected to A/D and D/A operating at the same rate of Fs = 10 kHz to ﬁlter analog
signals. Find the corresponding 3-dB attenuation analog frequency and compare it with the 3-dB attenuation
frequency of the original analog ﬁlter [i.e., the ﬁlter with h(t) = e−1,000tu(t).]
46. A continuous-time analog signal x(t) = cos 500πt + cos 200πt is sampled at the rate of 1,000 samples per second.
a. Find x(n).
b. The resulting discrete signal x(n) is passed through a ﬁlter with unit-sample response h(n) = {1, 2, 3
↑, 2, 1}.
Find the output y(n) and its analog reconstruction y(t).

Signals and Systems
939
16.15
Project 1: Windows
Introduction and Summary
1. Objectives
In this project you will explore the basic features of some popular windows used in digital signal processing and ﬁltering.
You will then specify some quantitative characteristics of the windows and use them in a comparative analysis of the
windows’ effects in digital signal processing. To review the windows and their transforms you may refer to the project in
Chapter 7 titled “Computer Explorations in Fourier Analysis” or the project in Chapter 8 called “Spectral Analysis Using
a Digital Oscilloscope.”
2. Simulation Tools
You may use Matlab, Scilab, or other packages for simulation purposes. The software packages contain commands that
create familiar discrete-time windows of desired lengths. For a higher resolution in the frequency domain, you need to
pad the windows with additional zeros, thus increasing data length T and reducing f = 1/T .
3. Reporting and Deliverables
During this project you will generate Figures A–E. Your report should contain the results of items 6-14.
Theory
4. What Is a Window?
A window is a ﬁnite-duration pulse through which we look at a time function or its Fourier transform. The role of a
window is to create and shape a ﬁnite segment of the sequence (be it data, a ﬁlter’s impulse response, or its frequency
response) and do so in a way that certain characteristics are met. By deﬁnition, time windows have ﬁnite duration and,
therefore, inﬁnite bandwidth. Given the duration of the window, its shape has an important role in its function.
From the theory of the Fourier integral it is known that the transform of a time-limited signal cannot be zero over
a nonzero frequency interval. Theoretically, a time-limited signal contains all frequency components and occupies an
inﬁnite bandwidth. The narrower the pulse is in the time domain, the wider its transform is in the frequency domain and
viceversa. Therefore, a signal may only approximately be both time-limited and bandlimited.
5. Time-Frequency Relationship
Consider a time function x(t) and a time window w(t) [with Fourier transforms X( f ) and W( f ), respectively]. Windowing
x(t) by w(t) produces a ﬁnite duration time function x(t) × w(t). The Fourier transform of the windowed function is
X( f ) ⋆W( f ), where ⋆represents the convolution operation.
x(t) × w(t) ⇐⇒X( f ) ⋆W( f )
A similar result is obtained when the Fourier transform of a time function is windowed by a W( f ) with ﬁnite bandwidth.
X( f ) × W( f ) ⇐⇒x(t) ⋆w(t)
6. Continuous-Time Windows
The time functions for some familiar continuous-time windows and their Fourier transforms are listed in Table 16.1.
For simplicity, the time origin is centered so that the windows are even functions. All windows are τ msec wide. The

940
CHAPTER 16
Discrete-Time Fourier Transform
mathematical expressions are given for −τ/2 < t < τ/2. Elsewhere, windows have zero values. Plot ﬁve time windows
and their transforms and label them Figure A.
TABLE 16.1 Continuous-Time Windows and Their Fourier Transforms
Window
Time Function,−τ/2 < t < τ/2
⇐⇒
Fourier Transform
Rectangular
1
⇐⇒
sin(π f τ)
π f
Bartlett
1 −2|t|
τ
⇐⇒
2
τ

sin(π f τ/2)
π f τ/2
2
Hanning
0.5 + 0.5 cos

2πt
τ

⇐⇒
0.5sin(π f τ)
π f
+ 0.25sin πτ( f −1
τ )
π( f −1
τ )
+0.25sin πτ( f + 1
τ )
π( f + 1
τ )
Hamming
0.54 + 0.46 cos

2πt
τ

⇐⇒
0.54sin(π f τ)
π f
+ 0.23sin πτ( f −1
τ )
π( f −1
τ )
+0.23sin πτ( f + 1
τ )
π( f + 1
τ )
Blackman
0.42 + 0.5 cos

2πt
τ

+ 0.08 cos

4πt
τ

⇐⇒
0.42sin(π f τ)
π f
+ 0.25sin πτ( f −1
τ )
π( f −1
τ )
+0.25sin πτ( f + 1
τ )
π( f + 1
τ )
+ 0.04sin πτ( f −2
τ )
π( f −2
τ )
+0.04sin πτ( f + 2
τ )
π( f + 2
τ )
7. Frequency Response of the Hanning Window
In this section we derive the Fourier transform of a continuous-time Hanning window of duration τ. The window is deﬁned
by the raised cosine pulse given by
x(t) =
 1 + cos( 2πt
τ ),
−τ
2 < t < τ
2
0,
elsewhere
The pulse is the product of a uniform rectangular window of duration τ and a cosine function with period τ and unity DC
value. At the edges, the window function and its derivatives are continuous and zero. The transform is
X( f ) =

τ/2
−τ/2

1 + cos

2πt
τ

e−j2π f tdt = sin(π f τ)
π f
+ 0.5sin πτ( f −f0)
π( f −f0)
+ 0.5sin πτ( f + f0)
π( f + f0)
where f0 = 1/τ is the ﬁrst zero-crossing of the transform of the rectangular window. Note that the Fourier transform of
the above window is not band limited. Plot three Hanning windows (5, 2, and 1 msec wide) and their Fourier transforms
and label them Figure B. Observe that, as expected, narrower windows have wider bandwidths.

Signals and Systems
941
8. Discrete-Time Windows
The domain of discrete-time signals is −∞< n < ∞, where n is an integer. In practice, however, we process ﬁnite-length
segments of a signal at any given time. Mathematically, this corresponds to multiplying the original signal by a discrete-time
window of ﬁnite length. Five examples of discrete-time windows are listed in Table 16.2 (left column). In practice, windows
are causal functions as speciﬁed in the right-hand column. The central column speciﬁes the noncausal symmetric version
of the windows with 2M + 1 samples (the time origin is chosen at the center to make the windows even functions of n).
Plot three discrete-time windows (rectangular, triangular, and Hanning) nine samples wide, along with their transforms.
TABLE 16.2 Discrete-Time Windows
Window Name
Even Function, −M ≤n ≤M
Causal Function, 0 ≤n ≤N −1
Rectangular
1
1
Bartlett
1 −|n|
M
1 −
2


n −N −1
2


N −1
Hanning
0.5 + 0.5 cos
πn
M

0.5 −0.5 cos

2πn
N −1

Hamming
0.54 + 0.46 cos
πn
M

0.54 −0.46 cos

2πn
N −1

Blackman
0.42 + 0.5 cos
πn
M

+ 0.08 cos

2πn
M

0.42 −0.5 cos

2πn
N −1

+ 0.08 cos

4πn
N −1

Measurements and Analysis
9. Operation of Time-Domain Windows
a. Produce a worksheet to show a rectangular window nine samples wide (in the left-hand column) along with the
magnitude of its transform (in the right-hand column). Label it Figure C, part a.
b. Create a triangular window of the same size as in a and repeat part a. Label it Figure C, part b.
c. Create a Hanning window of the same width and repeat part a. Label it Figure C, part c.
d. Qualitatively compare the side-lobes in the above three windows.
e. Develop a quantitative index (or indices) for measuring the effect of a window in the frequency domain, to be
used throughout this project.
Suggestion.
One such measure may be developed by deﬁning passband and stop-band attenuations, then ﬁnding the
passband, stop-band, and transition band frequencies for each window. Another measure could be the relative amount of
power (or energy) in each band.
10. Gibbs’ Phenomenon.
a. Use the Fourier series coefﬁcients of a periodic rectangular pulse to obtain the sum of its ﬁrst N nonzero harmonics.
This corresponds to a windowing operation in the frequency domain. Note that as the size of the window increases,
the sum of harmonics approach the rectangular form, except at the transition instances, where it exhibits horns.
This is called Gibbs’ phenomenon. Can you get rid of the horns by adding more harmonics? By changing the
size of the window, produce several examples (label them Figure D) and observe the persistence of the Gibbs’
phenomenon.

942
CHAPTER 16
Discrete-Time Fourier Transform
b. Investigate the effect of applying the Hanning window in reducing Gibbs’ phenomenon (label them Figure E).
Determine the cost of reducing the horns by increasing the transition band deﬁned in item 9 “Operation of Time
Domain Windows” of this project.
c. Repeat part b by applying a Hamming window.
11. Mathematical Interpretation of Gibbs’ Phenomenon
Consider the following three time-functions: (1) an inﬁnite-duration sinc function x(t), (2) a ﬁnite-width rectangular
window w(t) which is 2τ seconds wide, and (3) their convolution y(t) = x(t) ⋆w(t).
x(t) = sin(2π f0t)
πt
, −∞< t < ∞
w(t) = u(t + τ) −u(t −τ) =
 1,
−τ < t < τ
0,
elsewhere
y(t) = x(t) ⋆w(t)
= x(t) ⋆
u(t + τ) −u(t −τ)
= x(t) ⋆u(t + τ) −x(t) ⋆u(t −τ)
=

t
−∞
x(θ + τ)dθ −

t
−∞
x(θ −τ)dθ
The above derivation is illustrated in Figure 16.30. The horns seen in y(t) are interpreted as manifestations of Gibbs’
phenomenon (due to multiplication of the low-pass X( f ) by W( f ) of the rectangular window). In this section we look
into the root cause of the horns that appear in y(t).
a. Examine the above equations, then note that the convolution of x(t) with a unit-step function located at ±τ
amounts to its integral shifted by ±τ. This is because (1) a unit-step is the integral of a unit-impulse and (2)
convolution of x(t) with a unit-impulse results in shifting x(t) to the location of the unit-impulse.
b. Note that integration of the sinc function unavoidably produces ripples that are more pronounced around the
transition instances (in this discussion, at ±τ). The ripples become narrower for a narrower sinc function x(t) but
never disappear, especially in the neighborhood where they remain pronounced. Therefore, increasing the width
of w(t) smoothens the convolution pulse except at the transition times ±τ where horns persist.
c. Now look at the situation in the frequency domain. Examine the Fourier transforms X( f ), W( f ), Y( f ), and their
relationship.
X( f ) = u(t + f0) −u( f −f0) =
 1,
−f0 < f < f0
0,
elsewhere
W( f ) = sin(2π f τ)
π f
, −∞< f < ∞
Y( f ) = X( f ) × W( f ) =
 sin(2π f τ)
π f
,
−f0 < f < f0
0,
elsewhere
Y( f ) is produced through windowing W( f ) by the rectangular window X( f ). Because of Gibbs’ phenomenon,
its inverse y(t) is expected to contain horns, as in fact it does.
d. In summary, the horns are developed by the integration of x(t). They are interpreted as consequences of windowing
by the rectangular window X( f ) in the frequency domain. The result is Gibbs’ phenomenon in the time domain.

Signals and Systems
943
1
0
–250
250
–150
150
–50
50
0
(a)
(b)
1
0
–250
250
–150
150
–50
50
0
10
0
–500
–400
–300
–200
–100
0
100
200
300
400
500
(c)
FIGURE 16.30 Manifestation of Gibbs’ phenomenon due to convolution of a sinc function with a rectangular window.
(a) A discrete-time sinc function x(n) = sin(2πn/19)
2πn/19 . (b) An even rectangular window w(n) = u(n + 151) −u(n −151)
that is 301 samples long. (c) y(n) = x(n) ⋆w(n) corresponding to multiplication X( f ) × W( f ) creates horns. For
interpretation see the text.
12. Operation of Frequency-Domain Windows
a. Create hd(n) = sin(πn/4)/(πn), −∞< n < ∞. This is the unit-sample response of an ideal (and desired)
low-pass ﬁlter with the DTFT speciﬁed by
Hd(ω) =

1,
−π
4 < ω < π
4
0,
elsewhere
b. Take a ﬁnite segment of hd(n) of length 2M + 1
h(n) =
 sin(πn/4)
πn
,
−M ≤n ≤M
0,
elsewhere
and obtain its DTFT. Do you see Gibbs’ phenomenon in the frequency domain due to the ﬁnite length of h(n)?
Report your observations.
c. Construct h(n) for M = 15 and convolve it with the speech ﬁle cht5.wav. What does it do to the speech ﬁle?
What is the cutoff frequency?

944
CHAPTER 16
Discrete-Time Fourier Transform
Discussion and Conclusions
13. Summary of Windows’ Effects
Summarize the pay-off obtained by applying a window and the cost associated with it. Use the indices you deﬁned in
item 9 “Operation of Time-Domain Windows” (e.g., based on the shape of the frequency response of a window and its
effect on increasing the transition band).
14. Conclusions
In 50 words or less summarize the need, cost, and criteria for the choice of window type.
16.16
Project 2: Decimation and Frequency
Downshifting
1. Introduction and Summary
This project illustrates the decimation effect in the frequency domain. It can be reproduced using a computer program
following the steps described below. Reconstruction of the signal from the samples is assumed to be done through
an ideal low-pass ﬁlter with a cutoff frequency equal to half the sampling rate. The project contains three steps. The
three ﬁgures to be produced at the completion of the project illustrate how decimation of a sampled signal may cause
frequency downshifting. You will sample sinusoidal signals and tones, compute their Fourier transforms, and display their
magnitudes. You will then decimate the signals and observe the effect on their transforms.
2. Step a. Generating Tones
Start with four continuous-time sinusoids x(t) = cos(1,000πkt), k = 1, 2, 3, 4. Sample them at the sampling rate of
Fs = 10,000 samples per second, or 10 kHz (i.e., set t = n/10,000), to generate four sequences xk(n). Then compute
their Fourier transforms.
x(t)
x(n)
=⇒
X ( f )
x1(t) = cos(1,000πt),
cos(πn/10)
⇒
1
2[δ( f −500) + δ( f + 500)]
x2(t) = cos(2,000πt),
cos(2πn/10)
⇒
1
2[δ( f −1,000) + δ( f + 1,000)]
x3(t) = cos(3,000πt),
cos(3πn/10)
⇒
1
2[δ( f −1,500) + δ( f + 1,500)]
x4(t) = cos(4,000πt),
cos(4πn/10)
⇒
1
2[δ( f −2,000) + δ( f + 2,000)]
When a computer is used, computation is done on ﬁnite sequences of length N and the Fourier transforms are
approximated by discrete Fourier transforms. As expected, the spectral lines should occur at 500, 1,000, 1,500, and
2,000 Hz. Produce Figure A with two columns and four rows showing the sampled signals (on the left-hand column) and
their Fourier transforms (on the right-hand side). The Fourier transforms of the sampled signals are periodic functions of
frequency with a period Fs. Show one cycle of each on the right-hand side of Figure A.

Signals and Systems
945
This ﬁgure has been masked so as to be recreated by the student.
FIGURE A Sinusoids sampled at a high rate. In Figure A four continuous-time sinusoids x(t) =
cos(1,000πkt), k = 1, 2, 3, 4, corresponding to 500, 1,000, 1,500, and 2,000 Hz, are sampled
at the rate of Fs = 10 kHz, generating four sequences xk(n), shown in the left column. The
transforms of the sampled signals are shown in the right column. The time scale is in seconds and
the frequency scale is in Hz. Transforms are computed from ﬁnite sequences (10,000 samples) and
show spectral lines at 500, 1,000, 1,500, and 2,000 Hz, as expected. Also observe that the spectral
lines are singular with no sidebands because in all four cases the data sequence is windowed by a
rectangular window that contains an integer number of full cycles of the sinusoids.
3. Step b. Concatenation of Tones and Decimation by a Factor of 3
Construct a new time series x5(n) by concatenating x1(n), x2(n), x3(n), and x4(n), and then take its Fourier transform to
obtain X5( f ). Note that x5(n) contains 4N samples but the sampling rate is still 10 kHz. Its Fourier transform contains
spectral lines at 500, 1000, 1500, and 2000 Hz with the same magnitudes as found in step a. Produce Figure B with two
columns and two rows, showing x5(n) and X5( f ) in the upper row. (The lower row will show the decimated signal and
its transform, as described below.)
Starting from its beginning, decimate x5(n) by a factor of 3 to obtain a new sequence x6(n). This effectively reduces
the sampling rate to 10 kHz/3 = 3,333 Hz. Compute the Fourier transform of x6(n) and identify its frequency components
(locations and amplitudes). Pay attention to frequency components which don’t exist in x5(n). Note that spectral lines
at 500, 1,000, 1,500 Hz remain where they were, but the fourth line (originally at 2,000 Hz) is now shifted down to
3,333 −2,000 = 1,333 Hz.
You may also listen to the effect of decimation by saving x5(n) and x6(n) and playing them back through the sound
card. The ﬁles may be saved as sound ﬁles in the *.wav format. The audio effect shows shifting of the 2-kHz tone to
1,333 Hz.
This ﬁgure has been masked so as to be recreated by the student.
FIGURE B Decimation by a factor of 3. Construct Figure B in the following form:
1. The upper row shows the time series x5(n) [on the left-hand side, generated by concatenating
x1(n), x2(n), x3(n), and x4(n)] and its transform (on the right-hand side). The transform
shows spectral lines at 500, 1,000, 1,500, and 2,000 Hz, with the same magnitudes as found in
Figure A. Note that the spectral lines are not singular anymore, but have developed sidebands
due to a windowing effect.
2. The lower row shows a new sequence x6(n) and its transform, obtained from decimating x5(n)
by a factor of 3. This decimation effectively reduces the sampling rate to 10 kHz/3 = 3,333
Hz. The new sampling rate still remains greater than twice the frequencies 500, 1,000, 1,500
Hz, leaving the location of their spectral lines unchanged. However, the fourth line (originally
at 2,000 Hz) is now shifted down to 3,333 −2,000 = 1,333 Hz.

946
CHAPTER 16
Discrete-Time Fourier Transform
4. Step c. Summing the Tones and Decimation by a Factor of 7
Construct a new time series x7(n) = x1(n)+x2(n)+x3(n)+x4(n). Note that x7(n) contains N samples at the 10-kHz rate.
Take its Fourier transform to obtain X7( f ) and relate it (magnitude and locations of its peaks) to Xk( f ), k = 1, 2, 3, 4.
Decimate x7(n) by a factor of 7 to obtain a new sequence x8(n). This effectively reduces the sampling rate to
10
7 kHz = 1,428.5 Hz. Compute the Fourier transform of x8(n) and identify its frequency components (magnitude and
locations of its peaks). Note that the spectral lines are now at 71.5, 428.5, 500, and 571.5 Hz. Again, for audio examination,
you may save x7(n) and x8(n) in the form of a *.wav ﬁle and play them back through the sound card.
This ﬁgure has been masked so as to be recreated by the student.
FIGURE C Decimation by a factor of 7. Construct Figure C in the following form:
1. The upper row shows a new time series x7(n) = x1(n)+ x2(n)+ x3(n)+ x4(n) (left-hand side),
and its transform (right-hand side). Again, the transform shows spectral lines at 500, 1,000,
1,500, and 2,000 Hz.
2. The lower row shows a new sequence x8(n) (in the left-hand side) obtained from decimating
x7(n) by the factor 7. This decimation effectively reduces the sampling rate to 10 kHz/7 =
1,428.5 Hz. The transform of x8(n) is shown in the right-hand side. Note that the spectral lines
are now centered at 71.5, 428.5, 500, and 571.5 Hz, as summarized in the table below.
Original
Effective
Reconstructed
Signal
Frequency f0
Sampling Rate
Frequency
x1
500Hz
1,428.5Hz
500Hz
x2
1,000Hz
1,428.5Hz
|1,428.5 −1,000| = 428.5Hz
x3
1,500Hz
1,428.5Hz
|1,428.5 −1,500| = 71.5Hz
x4
2,000Hz
1,428.5Hz
|1,428.5 −2,000| = 571.5Hz
Note that when 2 f0 < 1428.5, the frequency of the reconstructed signal is the same as that of the
original continuous-time signal ( f0). But when 2 f0 > 1,428.5, aliasing occurs and spectral lines
appear at |1,428.5 −f0|.
5. Conclusions
For each of the above decimations examine the magnitudes and locations of the spectral lines. Observe and measure
aliasing. Calculate expected aliasing in terms of the decimation factor and convince yourself that they meet theoretical
expectations. Note that reconstruction ﬁlters eliminate frequency components which are above half of the sampling rate.

Chapter17
Discrete Fourier
Transform
Contents
Introduction and Summary
947
17.1
Deﬁnitions
948
17.2
Examples of the DFT
948
17.3
Examples of the IDFT
954
17.4
Time Reversal and Circular Shift
956
17.5
Circular Convolution
961
17.6
Properties of the DFT
963
17.7
Relation Between the DFT and DTFT
968
17.8
Fast Fourier Transform (FFT)
971
17.9
Linear Convolution from Circular
974
17.10
DFT in Matrix Form
978
17.11
Conclusions: FS, FT, DTFT, and DFT
981
17.12
Problems
983
17.13
Project: DFT Spectral Analysis
993
Introduction and Summary
The discrete Fourier transform (DFT) operates on a ﬁnite set of numbers or a ﬁnite
segment of a discrete signal. Physically, the DFT of a discrete-time function x(n) may
be viewed as its frequency-domain representation and used as a tool to approximate
the DTFT, FT, or the spectrum of the continuous-time function x(t) [from which x(n)
is produced]. Mathematically, the DFT may be formulated by extending the classical
Fourier transform of continuous-time signals to a ﬁnite-length discrete-time sequence
through sampling and windowing. Such an approach may appear logical and attractive,
but it draws in nonessential discussions and details that are marginal to the subject.
947

948
CHAPTER 17
Discrete Fourier Transform
Alternatively, the DFT can be introduced as an operation speciﬁed by a transformation
matrix that converts a sequence x(n) to another sequence X(k) of the same length. Par-
allels with the classical Fourier transform and physical interpretations can be introduced
after sufﬁcient familiarity with the subject has been acquired. The present chapter ap-
proaches the DFT through the latter avenue. It starts with the deﬁnitions of the DFT
and its inverse, followed by examples. One goal is to bring to the student’s attention
the importance and advantages of the DFT (and its implementation by the fast Fourier
transform [FFT]) in practical signal analysis, speciﬁcally in speeding up the processing.
The DFT’s important application is in performing circular convolution by FFT, from
which linear convolution is obtained. To that effect, the chapter discusses the circu-
lar convolution of two time-domain signals and its implementation through the DFT.
Mathematical properties of the DFT and its relation with the DTFT are then described.
The principles behind the FFT and its efﬁcient method of performing DFT are brieﬂy
discussed. Finally, the four methods of Fourier analysis—Fourier series (FS), Fourier
transform (FT), discrete-time Fourier transform (DTFT), and discrete Fourier transform
(DFT)—are brought together at the end of this chapter.
17.1
Definitions
The DFT transforms a ﬁnite-length sequence x(n),
0 ≤n ≤(N −1), into another
sequence X(k), 0 ≤k ≤(N −1), of the same length, where
X(k) =
N−1

n=0
x(n)e−j2πnk/N, k = 0, 1, 2, . . . N −1
(17.1)
Both sequences are N points long. X(k) is called the N-point DFT of x(n) and x(n) is
called the inverse discrete Fourier transform (IDFT) of X(k). The latter may be recovered
from X(k) by
x(n) = 1
N
N−1

k=0
X(k)e j2πkn/N, n = 0, 1, 2, . . . N −1
(17.2)
Customarily, x(n) represents a function in the time domain and X(k) is referred to as
its representation in the frequency domain. The sequences x(n) and X(k) always begin
with the zeroth term. They may be real-valued or complex numbers. In this chapter we
will focus mostly on a real-valued x(n).
17.2
Examples of the DFT
The examples in this section demonstrate the summation method of ﬁnding the DFT.
They also demonstrate some properties that are summarized at the end of the section.
The reader may want to consult these properties while doing the examples.

Signals and Systems
949
Example
17.1
Find the DFT of the following sequences:
a.
x(n) = {1
↑, 1, 0}
b.
x(n) = {1
↑, 1, 0, 0}
These are called the 3-point and 4-point DFT, respectively, of the sequence {1
↑, 1}.
Solution
a.
x(n) = {1
↑, 1, 0}
X(k) =
1

n=0
e−j2πnk/3 = 1 + e−j2πk/3 = e−jπk/3 
e jπk/3 + e−jπk/3
= 2 cos
πk
3

e−jπk/3, k = 0, 1, 2
= {2
↑, e−jπ/3, e jπ/3} =

2
↑, 1 −
√
3 j
2
, 1 +
√
3 j
2

Note that X(0) = 2 and X(1) = X∗(2).
b.
x(n) = {1
↑, 1, 0, 0}
X(k) =
1

n=0
e−j2πnk/4 = 1 + e−jπk/2 = e−jπk/4 
e jπk/4 + e−jπk/4
= 2 cos
πk
4

e−jπk/4, k = 0, 1, 2, 3
= {2
↑,
√
2e−jπ/4, 0,
√
2e jπ/4} = {2
↑, (1 −j), 0, (1 + j)}
Note that X(0) = 2 and X(1) = X∗(3).
Example
17.2
Find the 3-point DFT of
a.
x(n) = {1
↑, 0, 1}
b.
x(n) = {1
↑, 0, −1}
Solution
a.
x(n) = {1
↑, 0, 1}
X(k) =
2

n=0
x(n)e−j2πnk/3 = 1 + e−j4πk/3 = 2 cos
2πk
3

e−j2πk/3, k = 0, 1, 2
= {2
↑, −e−j2π/3, −e j2π/3} =

2
↑, 1 +
√
3 j
2
, 1 −
√
3 j
2


950
CHAPTER 17
Discrete Fourier Transform
Note that X(0) = 2 and X(1) = X∗(2).
b.
x(n) = {1
↑, 0, −1}
X(k) =
2

n=0
x(n)e−j2πnk/3 = 1 −e−j4πk/3 = 2 j sin
2πk
3

e−j2πk/3, k = 0, 1, 2
= {0
↑, j
√
3e−j2π/3, −j
√
3e j2π/3} =

0
↑, 3 −j
√
3
2
, (3 + j
√
3
2

Note that X(0) = 0 and X(1) = X∗(2).
Example
17.3
Even and odd sequences
Find the 3-point DFT of
a.
x(n) = {0
↑, 1, 1}
b.
x(n) = {0
↑, 1, −1}
Solution
a.
x(n) = {0
↑, 1, 1} (an even sequence)
X(k) =
2

n=0
x(n)e−j2πnk/3 = e−j2πk/3 + e−j4πk/3
= 2 cos
πk
3

e−jπk, k = 0, 1, 2
=

2
↑, −1, −1
	
Note that X(0) = 2 and X(1) = X(2).
b.
x(n) = {0
↑, 1, −1} (an odd sequence)
X(k) =
2

n=0
x(n)e−j2πnk/3 = e−j2πk/3 −e−j4πk/3
= 2 j sin
πk
3

e−jπk, k = 0, 1, 2
=

0
↑, −j
√
3, j
√
3
	
Note that X(0) = 0 and X(1) = −X(2).
For the deﬁnitions of even and odd sequences and their DFT properties see
section 17.6

Signals and Systems
951
Example
17.4
Zero padding
This example illustrates the effect of padding a sequence with additional zeros on the
right side to make it N elements long. Find the 8-point and 16-point DFTs of x(n)
in Example 17.1, plot their magnitudes, and comment on the effect of increasing the
DFT length.
Solution
a.
The 8-point DFT of the sequence is obtained as follows. See Figure 17.1(a).
x(n) = {1
↑, 1, 0, 0, 0, 0, 0, 0}
X(k) =
1

n=0
e−j2πnk/8 = 1 + e−jπk/4 = e−jπk/8 
e jπk/8 + e−jπk/8
= 2 cos
πk
8

e−jπk/8, k = 0, 1, 2, . . . , 7
= {2
↑, (1.707 −j0.707), (1 −j), (0.293 −j0.707), 0, (0.293 + j0.707), (1 + j), (1.707 + j0.707)}
1
0
0
2
4
6
8
10
12
14
16
2
0
0.5
1
1.5
0
2
4
6
8
10
12
14
16
x(n) = {1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}
|X(k)|, Magnitude of the 16-point DFT
(b)
↑
2
|X(k)|, Magnitude of the 8-point DFT
(a)
x(n) = {1, 1, 0, 0, 0, 0, 0, 0}
↑
1
0
–1
0
1
3
4
5
6
7
8
–1
2
0
0.5
1
1.5
0
1
2
3
4
5
6
7
8
FIGURE 17.1 x(n) (in the left column) and its N-point DFT (in the right column). (a) N = 8. (b) N = 16.

952
CHAPTER 17
Discrete Fourier Transform
b.
The 16-point DFT of the sequence is obtained as follows. See Figure 17.1(b).
x(n) = {1
↑, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}
X(k) =
1

n=0
e−j2πnk/16 = 1 + e−jπk/8 = e−jπk/16 
e jπk/16 + e−jπk/16
= 2 cos
πk
16

e−jπk/16, k = 0, 1, 2, . . . , 15
Note that in both cases, X(0) = 2. Also note the conjugate property X(n) =
X∗(N −n) [because x(n) is real]. Zero padding has increased resolution in the
frequency domain without affecting the envelope.
Example
17.5
Increasing the number of samples
a.
Find the N-point DFT of a rectangular pulse that is 3 samples wide
b.
Find the N-point DFT of a rectangular pulse that is M samples wide (N ≥M).
c.
Plot its magnitude for M = 3, 4 and N = 32 and observe the effect of
increasing the number of samples in the pulse.
Solution
a. X(k) = 1 + e−j2πk/N + e−j4πk/N = e−j2πk/N 
e j2πk/N + 1 + e−j2πk/N
=

1 + 2 cos 2πk
N

e−j 2πk
N ,
k = 0, 1, 2, . . . , N −1 (frequently-used simpliﬁcation method)
b. X(k) =
M−1

n=0
e−j2πnk/N = 1 −e−j2π Mk/N
1 −e−j2πk/N
= sin(π Mk/N)
sin(πk/N) e−j π(M−1)k
N
, k = 0, 1, . . . N −1
c. See Figure 17.2.
Example 17.5 illustrates the effect of the number of samples in the pulse on the DFT.
We will discuss this effect later in the chapter in light of the sampling rate. Here it
sufﬁces to mention that a higher sampling rate allows higher frequencies to appear in
the DFT. The center represents higher frequencies (see section 17.7). Matlab code for
computation and plotting of the DFT of a rectangular pulse is provided in problem
10 in order to explore the effect of varying its parameters.

Signals and Systems
953
1
0
0
5
10
15
20
25
30
3
2.5
2
0
0.5
1
1.5
0
5
10
15
20
25
30
|X(k)|, Magnitude of the 32-point DFT
x(n) = {1, 1, 1}
↑
1
0
0
5
10
15
20
25
30
4
0
0.5
1
1.5
2
2.5
3
3.5
0
5
10
15
20
25
30
|X(k)|, Magnitude of the 32-point DFT
x(n) = {1, 1, 1, 1}
↑
FIGURE 17.2 Rectangular pulses 3 and 4 samples wide (left) and plots of the magnitude of their 32-point DFT’s (right).
Example
17.6
Exponential pulse
Find the N-point DFT of h(n) = an, 0 ≤n ≤(N −1).
Solution
X(k) =
N−1

n=0
ane−j2πnk/N =
1 −aN
1 −ae−j2πk/N , k = 0, 1, . . . , N −1
(The pulse may be expressed as an exponential function e−n/θ.) In problem 10 you
will use a Matlab program to compute and plot the DFT of an exponential pulse. You
will explore the effect of varying the pulse parameters.
Example
17.7
Sinusoids
Find the 6-point DFT of
a.
cos(2πn/3)
b.
cos(πn/3)

954
CHAPTER 17
Discrete Fourier Transform
Solution
a.
5

n=0
cos
2πn
3

e−j2πkn/6
=
1


n=0
+ cos(2π/3)e−jπk/3



n=1
+ cos(4π/3)e−j2πk/3



n=2
+ e−jπk

  
n=3
+ cos(8π/3)e−j4πk/3



n=4
+ cos(10π/3)e−j5πk/3



n=5
=
1


n=0
+ cos(2π/3)e−jπk/3 + cos(10π/3)e−j5πk/3



n=1 and 5
+ cos(4π/3)e−j2πk/3 + cos(8π/3)e−j4πk/3



n=2 and 4
+ e−jπk

  
n=3
= 1 −cos(πk/3) −cos(2πk/3) + cos(πk), k = 0, 1, . . . , 5
=

0
↑, 0, 3, 0, 3, 0

b.
5

n=0
cos
πn
3

e−j2πkn/6
=
1


n=0
+ cos(π/3)e−jπk/3



n=1
+ cos(2π/3)e−j2πk/3



n=2
−e−jπk

  
n=3
+ cos(4π/3)e−j4πk/3



n=4
+ cos(5π/3)e−j5πk/3



n=5
=
1


n=0
+ cos(π/3)e−jπk/3 + cos(5π/3)e−j5πk/3



n=1 and 5
+ cos(2π/3)e−j2πk/3 + cos(4π/3)e−j4πk/3



n=2 and 4
−e−jπk

  
n=3
= 1 + cos(πk/3) −cos(2πk/3) −cos(πk), k = 0, 1, . . . , 5
=

0
↑, 3, 0, 0, 0, 3

17.3
Examples of the IDFT
Example
17.8
Find the 6-point IDFT of
a.
X(k) =

0
↑, 0, 3, 0, 3, 0

b.
X(k) =

0
↑, 3, 0, 0, 0, 3


Signals and Systems
955
Solution
a.
x(n) = 1
6
5

k=0
X(k)e j2πkn/6
= 1
2e j2πn/3



k=2
+ 1
2e j4πn/3



k=4
= cos(2πn/3),
n = 0, 1, . . . , 5
b.
x(n) = 1
6
5

k=0
X(k)e j2πkn/6
= 1
2e jπn/3

  
k=1
+ 1
2e j5πn/3



k=5
= cos(πn/3),
n = 0, 1, . . . , 5
Example
17.9
Determine coefﬁcients h(n) of a low-pass linear-phase FIR ﬁlter of length 16 for
which samples of the frequency response at regular intervals of 2πk/16 are
|H(k)| =





1,
k = 0, 1, 2
0.5,
k = 3
0,
k = 4, 5, 6, 7
Note that for this problem you need to complete the above sequence in a way such that
its inverse DFT produces a real h(n). It requires conjugate symmetry to satisfy the real-
valued condition of the inverse function and a phase angle of e−jπk (corresponding to
an 8-unit shift in time). For the above two considerations we start with the following:
|H(k)| = {1
↑, 1, 1, .5, 0, 0, 0, 0, 0, 0, 0, 0, 0, .5, 1, 1}
H(k) = {1
↑, −1, 1, −.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, −.5, 1, −1}
Solution
h(n) = 1
16
15

k=0
X(k)e j2πkn/16
= 1
16

1


k=0
−e jπn/8

  
k=1
+ e jπn/4

  
k=2
−0.5e j3πn/8



k=3
−0.5e j13πn/8



k=13
+ e j7πn/4

  
k=14
−e j15πn/8

  
k=15


= 1
16

1


k=0
−e jπn/8 −e j15πn/8



k=1 and 15
+ e jπn/4 + e j7πn/4



k=2 and 14
−0.5e j3πn/8 −0.5e j13πn/8



k=3 and 13


= 1
16

1 −2 cos
πn
8

+ 2 cos
πn
4

−cos
3πn
8

, n = 0, 1, . . . , 15

956
CHAPTER 17
Discrete Fourier Transform
= {0
↑, 0.011486, 0.018306, −0.015981, −0.0625, −0.035795, 0.106694,
0.290291, 0.375, 0.290291, 0.106694, −0.035795, −0.0625,
−0.015981, 0.018306, 0.011486}
For further elaboration on this example see problem 11.
Summary of Some Observations on DFT Pairs
1.
In all cases, X(0) is the sum of the samples in the sequence (corresponding to the
DC level).
2.
When the time sequence x(n) is real valued (as in the above examples),
X(k) = X∗(N −k) (conjugate property). In such a case half of the X(k) sequence
is enough to specify the entire DFT.
3.
When x(n) is real and even, X(k) = X(N −k). When it is real and odd,
X(k) = −X(N −k) (symmetry property). The symmetry property of a sequence
is deﬁned with reference to n = 0.
4.
Zero padding in the time domain increases the number of samples and brings a
higher frequency resolution to the DFT. However, it doesn’t change its envelope or
the frequency range.
5.
A higher sampling rate increases the number of samples and results in a higher
frequency range for the DFT.
17.4
Time Reversal and Circular Shift
Time reversal and shift operations are encountered often in the analysis of LTI systems.
For ﬁnite-length sequences, the domain is restricted to n = 0, . . . , N −1 and analysis
in the frequency domain is performed by DFT. In such cases, time reversal and shift
are deﬁned with reference to the circular display as shown in this section. Alternatively,
they may be interpreted as time reversal and shift of signals with inﬁnite domain (as
illustrated in Examples 17.10 and 17.11).
Time Reversal
Time reversal of a discrete signal x(n) is done by changing n to −n. This ﬂips the display
of the sequence around the origin. The present chapter is concerned with ﬁnite-duration
signals constrained to n = 0, . . . N −1. The signals are shown by a circular display with
the positive direction for n being the counterclockwise direction. Time reversal ﬂips the
circular display around n = 0 (the point at the zeroth angle). The time-reversed sequence
is found from the original sequence by x(N −n).
Example
17.10
Given x(n) = {1
↑, 2, 3, 4, 5, 6, 7, 8}, ﬁnd x(−n) and its circular display. (Circular
display of a ﬁnite-length sequence was introduced in section 11.8 of Chapter 11.)

Signals and Systems
957
Solution
x(−n) = {1
↑, 8, 7, 6, 5, 4, 3, 2}. See the circular display in Figure 17.3. Note that
x(−n) = x(8 −n).
3
2
n = 0
1
8
7
6
5
4
7
8
n = 0
1
2
3
4
5
6
x(n) = {1, 2, 3, 4, 5, 6, 7, 8}
↑
x(–n) = x(8 – n) = {1, 8, 7, 6, 5, 4, 3, 2}
↑
FIGURE 17.3 The sequence x(n) = {1
↑, 2, 3, 4, 5, 6, 7, 8} (left) and its time-reversal
x(−n) = {1
↑, 8, 7, 6, 5, 4, 3, 2} (right).
Alternative Visualization of Time Reversal
Assume an N-periodic signal speciﬁed in one period by x(n) and displayed linearly.
Time-reverse the periodic signal around the origin and take the segment that is seen
through the ﬁnite-duration window n = 0, . . . N −1. The lines shown below use this
alternative approach to obtain the time reversal of the sequence of Example 17.10. The
result is x(−n) = x(N −n), the same as obtained by using the circular display.
Assumed 8-periodic signal:
{· · · 1, 2, 3, 4, 5, 6, 7, 8, 1
↑, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1 · · ·}
Its time reversal:
{· · · 1, 8, 7, 6, 5, 4, 3, 2, 1
↑, 8, 7, 6, 5, 4, 3, 2, 1, 8, 7, 6, 5, 4, 3, 2, 1 · · ·}
x(−n) = x(8 −n):
{1
↑, 8, 7, 6, 5, 4, 3, 2}
Circular Shift
An N-point sequence is circularly (or cyclically) shifted m units to the right if all items in
the sequence are shifted to the right by m units and the rightmost overﬂowing m elements
arefedbackintothenewlycreatedleftmostm emptyspaces.Table17.1illustratescircular
shifts to the right and left.
Similarly, x(n) is circularly shifted m units to the left if all items in the sequence
are shifted to the left by m units and the leftmost overﬂowing m elements are fed back
into the newly created rightmost m empty spaces.

958
CHAPTER 17
Discrete Fourier Transform
TABLE 17.1(a) Circular Shifts to the Right for the Sequence x(n)
x(n) = {x0,
x1,
x2,
x3,
· · ·
x(N−2),
x(N−1)}
↑
x(n −1) = {x(N−1), x0,
x1,
x2,
· · ·
x(N−3),
x(N−2)}
↑
x(n −2) = {x(N−2), x(N−1),
x0,
x1,
· · ·
x(N−4),
x(N−3)}
↑
x(n −3) = {x(N−3), x(N−2),
x(N−1),
x0,
· · ·
x(N−5),
x(N−4)}
↑
x(n −m) = {x(N−m), x(N−m+1), x(N−m+2), x(N−m+3) · · ·
x(N−m−2), x(N−m−1)}
↑
TABLE 17.1(b) Circular Shifts to the Left for the Sequence x(n)
x(n) = {x0,
x1,
x2,
· · ·
x(N−3),
x(N−2),
x(N−1)}
↑
x(n + 1) = {x1,
x2,
x3,
· · ·
x(N−2),
x(N−1),
x0}
↑
x(n + 2) = {x2,
x3,
x4,
· · ·
x(N−1),
x0,
x1}
↑
x(n + 3) = {x3,
x4,
x5,
· · ·
x0,
x1,
x2}
↑
x(n + m) = {xm,
x(m+1),
x(m+2),
· · ·
x(m−3),
x(m−2)
x(m−1)}
↑
TABLE 17.1(c) Shifting x(n) by m Units to the Right and Left
x(n) =
x0
x1
x2
· · ·
xm
· · ·
x(N−2)
x(N−1)
↑
x(n −m) =
x(N−m) x(N−m+1)
· · ·
x(N−1)
x0
x1
· · ·
x(N−m−1)
↑
x(n + m) =
xm
x(m+1)
· · ·
x(N−m−2) x(N−m−1) x(N−m)
· · ·
x(m−1)
↑
In summary, a shift to the right by m units results in x(n −m). An opposite shift to
the left produces x(n + m). After N shifts, a sequence of length N becomes the same as
it was initially: x(n + N) = x(n) = x(n −N).
Example
17.11
Given x(n) = {1
↑, 2, 3, 4, 5, 6, 7, 8}
a.
Circularly shift it 3 units to the right to obtain x(n −3)
b.
Circularly shift it 3 units to the left to obtain x(n + 3)

Signals and Systems
959
Solution
See Figure 17.4.
a.
x(n −3) = {6
↑, 7, 8, 1, 2, 3, 4, 5}
b.
x(n + 3) = {4
↑, 5, 6, 7, 8, 1, 2, 3}
6
5
n = 0
4
3
2
1
8
7
3
2
n = 0
1
8
7
6
5
4
x(n + 3) = {4, 5, 6, 7, 8, 1, 2, 3}
↑
x(n) = {1, 2, 3, 4, 5, 6, 7, 8}
↑
8
7
n = 0
6
5
4
3
2
1
x(n – 3) = {6, 7, 8, 1, 2, 3, 4, 5}
↑
FIGURE 17.4 Circularly shifting x(n) = {1
↑, 2, 3, 4, 5, 6, 7, 8} (center) to the left by 3 units produces x(n + 3) =
{4
↑, 5, 6, 7, 8, 1, 2, 3} (left). A 3-unit circular shift to the right produces x(n −3) = {6
↑, 7, 8, 1, 2, 3, 4, 5} (right).
Alternative Visualization of Circular Shift
Given a ﬁnite-duration sequence x(n), n = 0, . . . N −1, assume an N-periodic signal
speciﬁed in one period by x(n) and displayed linearly. Shift the periodic signal by ±m
units. The segment that is seen through the ﬁnite-duration window n = 0, . . . N −1
is the circularly shifted x(n ± m). The lines shown below use this alternative approach
to ﬁnd circular shifts of the sequence of Example 17.11. The result is the same as that
obtained by using the circular display.
Assume 8-periodic signal:
{· · · 1, 2, 3, 4, 5, 6, 7, 8, 1
↑, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1 · · ·}
3-unit shift to the right:
{· · · 6, 7, 8, 1, 2, 3, 4, 5, 6
↑, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6 · · ·}
x(n −3):
{6
↑, 7, 8, 1, 2, 3, 4, 5}
3-unit shift to the left:
{· · · 4, 5, 6, 7, 8, 1, 2, 3, 4
↑, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4 · · ·}
x(n + 3):
{4
↑, 5, 6, 7, 8, 1, 2, 3}

960
CHAPTER 17
Discrete Fourier Transform
Example
17.12
Find one complete cycle of x(n) = {1
↑, 1, 1, 1, 0, 0, 0, 0} shifted to the right and in
steps of one.
x(n) = {1
↑, 1, 1, 1, 0, 0, 0, 0}
x(n −1) = {0
↑, 1, 1, 1, 1, 0, 0, 0}
x(n −2) = {0
↑, 0, 1, 1, 1, 1, 0, 0}
x(n −3) = {0
↑, 0, 0, 1, 1, 1, 1, 0}
x(n −4) = {0
↑, 0, 0, 0, 1, 1, 1, 1}
x(n −5) = {1
↑, 0, 0, 0, 0, 1, 1, 1}
x(n −6) = {1
↑, 1, 0, 0, 0, 0, 1, 1}
x(n −7) = {1
↑, 1, 1, 0, 0, 0, 0, 1}
x(n −8) = {1
↑, 1, 1, 1, 0, 0, 0, 0}
After eight unitary shifts to the right, x(n −8) = x(n) and the sequence becomes the
same as it was initially.
Example
17.13
Find one complete cycle of x(n) = {x0, x1, x2, x3, x4, x5, x6, x7} shifted to the left,
in steps of one, so that x(n + 8) = x(n).
x(n) = {x0, x1, x2, x3, x4, x5, x6, x7}
x(n + 1) = {x1, x2, x3, x4, x5, x6, x7, x0}
x(n + 2) = {x2, x3, x4, x5, x6, x7, x0, x1}
x(n + 3) = {x3, x4, x5, x6, x7, x0, x1, x2}
x(n + 4) = {x4, x5, x6, x7, x0, x1, x2, x3}
x(n + 5) = {x5, x6, x7, x0, x1, x2, x3, x4}
x(n + 6) = {x6, x7, x0, x1, x2, x3, x4, x5}
x(n + 7) = {x7, x0, x1, x2, x3, x4, x5, x6}
x(n + 8) = {x0, x1, x2, x3, x4, x5, x6, x7}
After eight unitary shifts to the left, x(n + 8) = x(n), and the sequence becomes the
same as it was initially.

Signals and Systems
961
17.5
Circular Convolution
The circular convolution of two sequences x(n) and h(n) of ﬁnite length N is deﬁned
by
y(n) = x(n) ⊗h(n) =
N−1

k=0
x(k)h(n −k)
where h(n−k) is found by time reversal and circular shift. Circular convolution is shown
by the symbol ⊗. The evaluation of the circular convolution requires steps similar to
linear convolution. These steps are the following:
1.
Time reversal of h(k) to produce h(−k)
2.
A circular shift to produce h(n −k)
3.
Multiplication of x(k) by h(n −k)
4.
Summation of the N terms
These steps may be visualized and carried out more conveniently by a circular
display of the two signals as illustrated in the following example.
Example
17.14
Find y(n) = x(n) ⊗h(n), where x(n) = {1
↑, 1, 0, 0} and h(n) = {1
↑, 1, −1, −1}.
Solution
Using the circular display as a tool, we compute y(n):
y(0) = 1 −1 + 0 + 0 = 0 [See Figure 17.5(a).]
y(1) = 1 + 1 + 0 + 0 = 2 [See Figure 17.5(b).]
y(2) = −1 + 1 + 0 + 0 = 0 [See Figure 17.5(c).]
y(3) = −1 −1 + 0 + 0 = −2 [See Figure 17.5(d).]
The output sequence is y(n) = {0
↑, 2, 0, −2}.
1
–1
1
k
k = 0
1
0
1
0
–1
y(0) = 1 – 1 + 0 + 0 = 0
(a)
(b)
(c)
(d)
1
1
1
–1
0
–1
0
1
y(2) = –1 + 1 + 0 + 0 = 0
1
1
1
1
0
–1
0
–1
y(1) = 1 + 1 + 0 + 0 = 2
1
–1
1
–1
0
1
0
1
y(3) = –1 – 1 + 0 + 0 = –2
FIGURE 17.5 This ﬁgure displays steps in circular convolution y(n) = x(n) ⊗h(n) = N−1
k=0 x(k)h(n −k), where
x(n) = {1
↑, 1, 0, 0} and h(n) = {1
↑, 1, −1, −1}. x(k) is displayed on the outside and h(n −k) is displayed inside the
circle for n = 0, 1, 2, and 3. They are multiplied term by term and added to produce y(n).

962
CHAPTER 17
Discrete Fourier Transform
Zero Padding
When one sequence is longer than the other, the shorter sequence should be padded with
enough zeros on the right side to make it the same size as the longer sequence.
Example
17.15
Find y(n) = x(n) ⊗h(n), where
x(n) = {1
↑, 1, 0, 0, 0, 0}
and
h(n) = {1
↑, 1, −1, −1}.
Solution
x(n) has six samples and h(n) has four. x(n)⊗h(n) is a 6-point circular convolution.
We ﬁrst pad h(n) with two zeros on the right to make it 6 points long, then perform
circular convolution (following steps similar to Figure 17.5) to ﬁnd
y(n) = {1
↑, 1, 0, 0, 0, 0} ⊗{1
↑, 1, −1, −1, 0, 0} = {1
↑, 2, 0, −2, −1, 0}.
DFT and Circular Convolution
The circular convolution of two time-domain signals is equivalent to multiplication of
their DFTs in the frequency domain.
x(n) ⊗y(n) ⇐⇒
X(k)Y(k)
This may be proved by taking the DFT of the circular convolution sum. Let
y(n) = x(n) ⊗h(n) =
N−1

k=0
x(k)h(n −k)
Taking the DFT of y(n) results in
Y(k) =
N−1

n=0
y(n)e−j2πnk/N =
N−1

n=0
N−1

m=0
x(m)h(n −m)e−j2πnk/N
The double sum may be converted to a product of two separate sums by changing the
variable n to a new variable p such that n = m + p. The terms containing the variables
p and m in the double sum are then separated and so
Y(k) =
N−1

m=0
x(m)e−j2πmk/N ×
N−1

p=0
h(p)e−j2πpk/N = X(k)H(k)
This property is of great importance because DFT operations, when done through the
fast Fourier transform (FFT) algorithm, are completed much faster than convolutions.
(See Example 17.20.)
Obtaining Linear Convolution from Circular Convolution
The circular convolution of two ﬁnite sequences may be performed by multiplying their
DFTs in the frequency domain and then taking the IDFT of the result. This becomes very

Signals and Systems
963
efﬁcient and fast if the DFTs are obtained through FFT algorithm. However, the output
of a discrete-time LTI system is not the circular convolution of the input sequence with
the sequence of the unit-sample response, but rather the linear convolution of the two.
When both sequences are ﬁnite and approximately the same length, we can pad both of
them with enough zeros on both sides and perform circular convolution (through DFT
and IDFT). With enough zero padding, the result of circular convolution will be the same
as linear convolution.
Example
17.16
a.
Using the linear convolution operation ﬁnd y(n) = x(n) ⋆h(n), where
x(n) = {0
↑, 0.1678, 0.6821, 1, 1, 0.6821, 0.1678} and
h(n) = {0
↑, −0.2122, 0, 0.6366, 1, 0.6366, 0, −0.2122}
b.
Minimally pad x(n) and h(n) to ﬁnd y(n) from x(n) ⊗h(n) using the DFT.
Solution
a.
x(n) has 7 samples and h(n) has eight. Their linear convolution will have
14 samples.
y(n) = x(n) ⋆h(n)
= {0
↑, 0, −0.03562, −0.1448, −0.1053, 0.3899,
1.2809, 2.0353, 2.0353, 1.2809, 0.3899, −0.1053, −0.1448, −0.0356}
b.
The circular convolution should have at least 14 samples. To use the DFT, we
pad x(n) with 7 zeros and h(n) with 6 zeros [to get ψ(n) and ζ(n),
respectively]. Using DFT/IDFT we ﬁnd the same result as the linear
convolution.
ψ(n) ⊗ζ(n) = {0
↑, 0, −0.03562, −0.1448, −0.1053, 0.3899, 1.2809, 2.0353,
2.0353, 1.2809, 0.3899, −0.1053, −0.1448, −0.0356}
Padding sequences with large numbers of zeros reduces the efﬁcacy of convolution
through DFT and is not recommended. Instead, when one sequence is short and the
other is long (or inﬁnite), we obtain the output of an LTI system y(n) = x(n) ⋆h(n)
from the circular convolution of short segments. Two such methods are described in
section 17.9.
17.6
Properties of the DFT
The discrete Fourier transform is a member of the family of linear transforms that
includes theFourier transform, Laplacetransform, z-transform,and discrete-timeFourier
transform. It, therefore, shares many of their properties. Some of these properties are
described below and summarized in Table 17.2.

964
CHAPTER 17
Discrete Fourier Transform
Linearity Property
The N-point DFT of ax(n)+by(n) is aX(k)+bY(k) for any x(n) and y(n) of the same
length N and any constants a and b.
x(n)
⇐⇒
X(k)
y(n)
⇐⇒
Y(k)
ax(n) + by(n) ⇐⇒aX(k) + bY(k)
Periodicity
The DFT and IDFT operations are concerned with ﬁnite-length sequences. Therefore,
x(n) and X(k) are not periodic functions per se. However, because the summations in
(1) and (2) contain e−j2πnk/N and e j2πkn/N, which are periodic with period N, one can
talk of a cyclic property for x(n) and X(k) and consider the following periodic functions
that extend beyond the ﬁnite length of the sequence:
x(n) = x(n + N), for all n, and X(k) = X(k + N), for all k.
The circular shift of the ﬁnite sequence would then become a linear shift of the newly
considered periodic function. A linear display of the periodic function may be generated
by rolling the wheel of the circular display of the function along a linear axis (picture the
impressions left by a cylindrical seal rolling on a ﬂat piece of paper). The circular display
of x(n) or X(k) introduced in the previous section is nonetheless helpful in visualizing
the concepts of cyclicity, circular shift, and circular convolution.
Time Reversal
Reversing time ﬂips the signal around n = 0 and produces x(−n) = x(N −n) (due to
its periodicity). The effect in the frequency domain is
x(−n) = x(N −n)
⇐⇒
X(−k) = X(N −k)
To prove the above relationship, start with
DFT {x(−n)} =
N−1

n=0
x(N −n)e−j2πnk/N
and let N −n = m. Then,
DFT {x(−n)}=
N

m=1
x(m)e−j2π(N−m)k/N =
N

m=1
x(m)e−j2πm(−k)/N = X(−k) = X(N −k)
Time-Domain Conjugate Property
The DFT of the complex conjugate of a signal is related to the DFT of the signal by
x∗(n) ⇐⇒X∗(−k) = X∗(N −k)

Signals and Systems
965
The above may be derived by applying the DFT deﬁnition
DFT {x∗(n)} =
N−1

n=0
x∗(n)e−j2πnk/N =
N−1

n=0
x∗(n)e j2πn(−k)/N
=
N−1

n=0
x(n)e−j2πn(−k)/N
 ∗
= X∗(−k)
DFT of a Real-Valued Signal
From the time-domain conjugate property we deduce that when x(n) is real then X(k) =
X∗(−k).
x(n) = x∗(n)
⇐⇒
X(k) = X∗(N −k)
In such a case, the real part of X(k) (also its magnitude) is an even function and its
imaginary part (also its phase) is an odd function. The signal can be completely speciﬁed
by X(k), k = 0, 1, . . . (N/2 + 1) (N even) or (N + 1)/2 (N odd).
Circular Shift
Circular shift of m units multiplies X(k) by e−j2πmk/N and, therefore, subtracts 2πmk/N
from its phase.
x(n −m)
⇐⇒
X(k)e−j2πmk/N
Frequency Shift
Multiplication of x(n) by e j2πnp/N shifts its DFT by p units to the right.
x(n)e j2πnp/N
⇐⇒
X(k −p)
Modulation
The n-domain signal corresponding to a shift to the left or the right in the frequency
domain is not a real signal. However, by shifting X(k) to the left and the right and adding
the results, we obtain a real signal modulated by a carrier.
x(n)e j2πnp/N
⇐⇒
X(k −p)
x(n)e−j2πnp/N
⇐⇒
X(k + p)
x(n) cos
2πnp
N

⇐⇒
X(k −p) + X(k + p)
2
Waveform Symmetry
The symmetry properties of a function introduce features in its DFT, which simplify
calculations. Two such symmetry properties are listed below.

966
CHAPTER 17
Discrete Fourier Transform
Even Sequence
If a sequence is symmetric about point 0 on the circular display, then it is called an even
sequence, in which case x(N −n) = x(n).
Odd Sequence
If a sequence is antisymmetric about point 0 on the circular display, then it is called an
odd sequence, in which case x(N −n) = −x(n).
The DFT of a real and even sequence is a real and even sequence. Likewise, the
DFT of a real and odd sequence is a purely imaginary and odd sequence.
Real and even sequence: x(N −n) = x(n)
⇐⇒
X(k) = X(−k)
Real and odd sequence: x(N −n) = −x(n) ⇐⇒
X(k) = −X(−k)
Circular Convolution and Product Property
The DFT of the circular convolution of two sequences was shown (section 17.5) to be
equal to the product of the DFTs:
x(n) ⊗y(n) ⇐⇒
X(k)Y(k)
Similarly, the DFT of the product of two time sequences can be obtained from the circular
convolution of their DFTs:
x(n)y(n) ⇐⇒
X(k) ⊗Y(k) = 1
N
N−1

m=0
X(m)Y(k −m)
Parseval’s Theorem
The energy in a discrete-time signal x(n), n = 0, 1, . . . , N −1, is deﬁned by
Ex =
N−1

n=0
|x(n)|2
Parseval’s theorem expresses Ex in terms of the DFT coefﬁcients X(k). It states that
N−1

n=0
|x(n)|2 = 1
N
N−1

k=0
|X(k)|2
The above summations are referred to as the energy in the time and frequency domains,
respectively. |X(k)|2 may be called the energy density spectrum (spectrum of energy
density, energy spectral density). The time signal can be a complex-valued function of
n and, therefore, in general |x(n)|2 = x(n)x∗(n). Parseval’s theorem is one of the set of
relations between the time- and frequency-domain representations of two ﬁnite-length
sequences.
N−1

n=0
x(n)y(n) = 1
N
N−1

k=0
X(k)Y(−k)
and
N−1

n=0
x(n)y∗(n) = 1
N
N−1

k=0
X(k)Y ∗(k)

Signals and Systems
967
ToderiveParseval’s relations,expresstheDFToftheproduct x(n)y(n)astheconvolution
of their DFTs.
DFT{x(n)y(n)}
= X(k) ⊗Y(k)
⇓
⇓
N−1

n=0
x(n)y(n)e−j2πkn/N = 1
N
N−1

m=0
X(m)Y(k −m)
Then set k = 0 to ﬁnd
⇓
⇓
N−1

n=0
x(n)y(n)
= 1
N
N−1

m=0
X(m)Y(−m)
For y(n) = x∗(n) we have Y(m) = X∗(−m), Y(−m) = X∗(m), and
N−1

n=0
x(n)x∗(n) = 1
N
N−1

m=0
X(m)X∗(m)
N−1

n=0
|x(n)|2 = 1
N
N−1

m=0
|X(m)|2
Example
17.17
Verify Parseval’s theorem for the sequences in Example 17.1.
Solution
a.
x(n) = {1
↑, 1, 0}

⇒
2

n=0
|x(n)|2 = 2
X(k) =

2
↑, 1 −
√
3 j
2
, 1 +
√
3 j
2


⇒1
3
2

k=0
|X(k)|2 = 1
3[4 + 1 + 1] = 2
Parseval’s theorem:
2

n=0
|x(n)|2 = 1
3
2

k=0
|X(k)|2 = 2
b.
x(n) = {1
↑, 1, 0, 0}

⇒
3

n=0
|x(n)|2 = 2
X(k) = {2
↑, (1 −j), 0, (1 + j)} 
⇒1
4
3

k=0
|X(k)|2 = 1
4[4 + 2 + 0 + 2] = 2
Parseval’s theorem:
3

n=0
|x(n)|2 = 1
4
3

k=0
|X(k)|2 = 2

968
CHAPTER 17
Discrete Fourier Transform
TABLE 17.2 Summary of DFT Properties
Definition
x(n) = 1
N
N−1

k=0
X(k)ej2πkn/N
⇐⇒
X(k) =
N−1

n=0
x(n)e−j2πnk/N
Linearity
ax(n) + by(n)
⇐⇒
aX(k) + bY(k)
Conjugation
x∗(n)
⇐⇒
X ∗(−k) = X ∗(N −k)
Real
x(n) = x∗(n)
⇐⇒
X(k) = X ∗(−k)
Real and even
x(N −n) = x(n)
⇐⇒
X(k) = X(−k)
Real and odd
x(N −n) = −x(n)
⇐⇒
X(k) = −X(−k)
Time reversal
x(−n) = x(N −n)
⇐⇒
X(−k) = X(N −k)
Circular shift
x(n −m)
⇐⇒
X(k)e−j2πmk/N
Frequency shift
x(n)e j2πnp/N
⇐⇒
X(k −p)
Modulation
x(n) cos

2πnp
N

⇐⇒
X(k −p) + X(k + p)
2
Circular convolution
x(n) ⊗y(n) =
N−1

m=0
x(m)y(n −m)
⇐⇒
X(k)Y(k)
Product property
x(n)y(n)
⇐⇒
X(k) ⊗Y(k) = 1
N
N−1

m=0
X(m)Y(k −m)
Parseval’s Theorem
N−1

n=0
x(n)y(n) = 1
N
N−1

k=0
X(k)Y(−k)
and
N−1

n=0
x(n)y∗(n) = 1
N
N−1

k=0
X(k)Y ∗(k)
N−1

n=0
|x(n)|2 = 1
N
N−1

k=0
|X(k)|2
17.7
Relation Between the DFT and DTFT
The DFT is the sampled version of the DTFT. The N-point DFT of a sequence x(n), n =
0, 1, 2, . . . N −1, generates samples of the DTFT of x(n), zero-padded to extend it to
−∞< n < ∞. The samples are taken every 1/N Hz in the f -domain over the span of
1 Hz. The DFT is, therefore, analogous to a sampling instrument in the frequency domain.
Example
17.18
A ﬁnite-duration sequence x(n),
n = 0, 1, 2, . . . , N −1, [and, consequently, its
N-point DFT sequence X(k)] is given.
a.
Zero-pad x(n) in both directions in order to extend it to −∞< n < ∞and call
the result y(n). Relate Y(ω), the DTFT of y(n), to X(k).

Signals and Systems
969
b.
Repeatedly append x(n) to itself to obtain the periodic signal z(n) shown below.
z(n) = x(n), n = 0, 1, 2, . . . , N −1
z(n + N) = z(n),
−∞< n < ∞
Relate Z(ω), the DTFT of z(n), to the DFT of x(n).
Solution
a.
X(k) =
N−1

n=0
x(n)e−j2πnk/N, k = 0, 1, 2, . . . N −1
Y(ω) =
∞

n=−∞
y(n)e−jωn =
N−1

n=0
x(n)e−jωn
X(k) = Y(ω)
!!
ω= 2πk
N , k = 0, 1, 2, . . . N −1
Remember that Y(ω) is 2π−periodic and, therefore, there is no need to sample
it outside the DFT window. The X(k) elements are samples of Y(ω) taken at
2πk
N , k = 0, 1, 2, . . . N −1 [during the ﬁrst period of Y(ω)]. In addition, Y(ω)
doesn’t contain any information beyond sample values available as X(k).1 The
zero padding doesn’t add any new information either.
b.
Z(ω) = Y(ω) ⋆
∞

k=−∞
2π
N δ

ω −2kπ
N

=
∞

k=−∞
2π
N Y
2kπ
N

δ

ω −2kπ
N

=
∞

k=−∞
2π
N X(k)δ

ω −2kπ
N

Z(ω), the DTFT of z(n), is an N-periodic sequence of impulses of strength
2π
N X(k) located at ω = 2kπ/N.
Example
17.19
a.
Find Y(ω), the DTFT of y(n) = {. . . , 0, 0, 0, 1
↑, 1, 1, 1, 1, 0, 0, 0, . . .} and plot
its magnitude as a function of f = ω/(2π) for −0.25 < f < 1.25.
b.
Find X(k), the 20-point DFT of x(n) = {1
↑, 1, 1, 1, 1, }. Plot its magnitude for
0 ≤k ≤19 and note its relation with the frequency f , which ranges from 0 to 1.
c.
Compare plots in a and b and verify that X(k) = Y(ω)|ω=πk/10.
Solution
a.
Y(ω) =
4

n=0
e−jωn = 1 −e−j5ω
1 −e−jω = sin
 5ω
2

sin
 ω
2
 e−j2ω. See Figure 17.6(a).
1The fact that X(k) completely speciﬁes Y(ω) is a consequence of the sampling theorem applied to Y(ω).
See the sampling theorem in C. E. Shannon, “Communication in the Presence of Noise,” Proceedings of
the IRE, vol. 37, no. 1, pp. 10–21, January 1949. Reprinted in the Proceedings of the IEEE, vol. 86, no. 2,
February 1998.

970
CHAPTER 17
Discrete Fourier Transform
b.
X(k) =
4

n=0
e−j2πnk/20 = 1 −e−jπk/2
1 −e−jπk/10 = sin
 πk
4

sin
 πk
20
e−j( πk
5 )
= Y(ω)
!!!
ω=πk/10, k = 0, . . . , 19. See Figure 17.6(b).
c.
k
ω
f
X(k) = Y(ω)
0
0
0
5
1
0.1π
0.05
4.5201̸ −36◦
2
0.2π
0.1
3.2360̸ −72◦
· · ·
m
m π/10
0.05m
See parts a and b above.
· · ·
18
1.8π
0.9
3.2360̸ 72◦
19
1.9π
0.95
4.5201̸ 36◦
Note that X(k) = X ∗(20 −k)
Frequency (Hz)
(a)
k-Domain
(b)
6
5
4
3
2
1
0
–1
1.2
–0.2
–0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1.1
6
5
4
3
2
1
0
–1
0
2
4
6
8
10
12
14
16
18
20
|X(f)| (DTFT)
|Xk| (20-point DFT)
FIGURE 17.6 (a) Magnitude plot of the DTFT of the time function y(n) = {. . . , 0, 0, 0, 1
↑, 1, 1, 1, 1, 0, 0, 0, . . .}.
(b) Magnitude plot of the 20-point DFT of the sequence x(n) = {1
↑, 1, 1, 1, 1} (padded with 15 zeros) is superimposed
on |Y( f )|. The DTFT magnitude is the envelope of the magnitude of the DFT sequence. The elements of X(k) are
samples of Y( f ) taken every 1/20 Hz (that is, at f = k/20, k = 0, . . . 19). The transforms were obtained and plotted
by computer.

Signals and Systems
971
17.8
Fast Fourier Transform (FFT)
Direct computation of the sum in (1) for a single value of k takes N multiplications and
N −1 additions. Computation of the entire N-point DFT for k = 0, . . . , N −1 would
take N 2 multiplications and N(N −1) additions. The above numbers can be reduced
by making use of the periodic property of the DFT. An approach that dramatically
reduces the number of multiplications and additions needed to compute the DFT is
called the fast Fourier transform (FFT). For example, the FFT reduces the total number
of multiplications and additions by factors of 683 and 341, respectively, for a 4,096-point
data sequence. The FFT motif is a repeated DFT operation on small sequences (down to
2-point DFT) and combination of the results to produce the N-point DFT of the original
sequence. The following introduces an FFT concept which uses decimation-in-time and
assumes N is a power of 2.
Start with the deﬁnition of DFT:
X(k) =
N−1

n=0
x(n)e−j2πnk/N =
N−1

n=0
x(n)W nk
N , where WN = e−j2π/N and W nk
N ≡(WN)nk
Split x(n) into its even-numbered and odd-numbered points and call them a(n) and b(n),
respectively:
a(n) = x(2n)
(the even-numbered points), n = 0, 1, . . . , N
2 −1
b(n) = x(2n + 1)
(the odd-numbered points), n = 0, 1, . . . , N
2 −1
For example, split x(n) = {1
↑, 2, 3, 4} into a(n) = {1
↑, 3} and b(n) = {2
↑, 4}, see
Figure 17.7(a). Splitting x(n) divides the DFT summation into two parts with con-
tributions from the even-numbered and odd-numbered points, respectively.
X(k) =
N/2−1

n=0
a(n)W 2nk
N
+
N/2−1

n=0
b(n)W (2n+1)k
N
, k = 0, 1, 2, . . . N −1
Since W 2
N = WN/2 the above equation becomes
X(k) =
N/2−1

n=0
a(n)W nk
N/2 + W k
N
N/2−1

n=0
b(n)W nk
N/2, k = 0, 1, 2, . . . N −1
The ﬁrst summation on the right side of the above equation is N/2-point DFT of a(n),
to be designated as A(k). Similarly, the second summation is N/2-point DFT of b(n),
to be designated as B(k). Then,
X(k) = A(k) + W k
N B(k), k = 0, 1, 2, . . . N −1
Because
A(k) = A(k + N/2), B(k) = B(k + N/2),
and W k+N/2
N
= −W k
N

972
CHAPTER 17
Discrete Fourier Transform
the equation for X(k) can be separated into
X(k) = A(k) + W k
N B(k), k = 0, 1, 2, . . . N/2 −1
X(k + N/2) = A(k) −W k
N B(k), k = 0, 1, 2, . . . N/2 −1
The N-point DFT of x(n) can be obtained by combining the N/2-point DFTs of a(n)
and b(n). The butterﬂy ﬂowgraph for the combination is shown in Figure 17.7(b).
(a) Splitting x(n) into
a(n) and b(n).
1
1
3
2
4
2
3
4
A
B
A(k)
B(k)
–1
(b) A butterfly flowgraph for obtaining X(k),
the DFT of x(n), from A(k) and B(k),
the DFTs of a(n) and b(n).
WN
X(k + N/2)
X(k)
k
Layer 0
Layer 1
Layer 2
C
D
E
F
(c) Consecutive splitting of x(n).
1
2
3
4
1
3
1
5
A
B
3
7
2
6
4
8
5
7
2
4
6
8
5
6
7
8
FIGURE 17.7 Layering in FFT algorithm.
Further splitting of a(n) and b(n) into even- and odd-numbered sequences, and
applying the butterﬂy ﬂowgraph to their DFT would save more computation time as
smaller sequences need less computation time for their DFT. For example, layer 1
in Figure 17.7(c) shows splitting the sequence x(n) = {1
↑, 2, 3, 4, 5, 6, 7, 8} into the
odd-numbered sequence a(n) = {1
↑, 3, 5, 7} and the even-numbered sequence b(n) =
{2
↑, 4, 6, 8}. Layer 2 repeats the process and produces c(n) = {1
↑, 5}, d(n) = {3
↑, 7}, and,
e(n) = {2
↑, 6}, f (n) = {4
↑, 8}, respectively, each only two elements long. In this way
X(k) can be found by applying butterﬂy ﬂowgraph to smaller sequences, taking less
time to compute. See problem 13 in this chapter.
Computational Savings
Direct computation of N-point DFT requires N 2 multiplications. If obtained by the ﬂow-
graph of Figure 17.7 the total number of multiplications will be reduced to

Signals and Systems
973
2 × (N/2)2 + N/2 = N 2/2 + N/2, which is a reduction by a factor 2 for large N.
From another angle, having obtained the N/2-point DFTs of a(n) and b(n) we would
need only N more additions and N/2 more multiplications to obtain the N-point DFT
of x(n). Further reduction can be achieved by applying the above procedure to a(n) and
b(n) and starting with four N/4-point DFTs. By repeatedly dividing the time sequence
to smaller size one can start with 2-point DFT (called radix 2), achieving a maximum
computational saving. Table 17.3 shows the number of multiplications and additions
required for the DFT and FFT operations on sequences of data ranging in length from 4
to 4,096 points.
TABLE 17.3 Comparing the DFT and FFT Operations2
Data Length
Multiplications
Additions
N
DFT
FFT
DFT
FFT
4
16
4
12
8
8
64
12
56
24
16
256
32
240
64
32
1,024
80
992
160
64
4,096
192
4,032
384
128
16,384
448
16,256
896
256
65,536
1,024
65,280
2,048
512
262,144
2,304
261,632
4,608
1,024
1,048,576
5,102
1,047,552
10,240
2,048
4,194,304
11,264
4,192,256
22,528
4,096
16,777,216
24,576
16,773,120
49,152
Example
17.20
Measure, as accurately as you can, and compare computation times needed to perform
the DFT and FFT on a ﬁnite sequence.
Solution
Results from an experiment carried out on a personal computer running at 400-MHz
speed under Windows 7 are shown below.
w1=gnorm(8192,1,0,1)%Generates 8192 random numbers, N(0,1).
w2=fft(w1)
%Takes FFT of w1 (about a split second).
w3=dft(w1)
%Takes DFT of w2 (about 13 seconds).
2M. T. Jong, Methods of Discrete Signals and System Analysis (New York: McGraw-Hill Book Company,
1982).

974
CHAPTER 17
Discrete Fourier Transform
17.9
Linear Convolution from Circular
Two methods for obtaining linear convolution by using circular convolution are described
below.
Method 1
One recipe for obtaining the linear convolution of x(n) with h(n) by way of their circular
convolution is the following (also called “overlap and save”):
1.
Choose a segment of x(n) of ﬁnite length L. (For the FFT operation, L needs to be
a power of two. However, the present method does not require that.)
2.
Let h(n) be N samples long. Pad it with L −N zeros to make it L samples long.
Call the padded sequence g(n).
g(n) = h(n),
n = 0, 1, 2, . . . , N −1
g(n) = 0,
n = N, N + 1, . . . , L −1
3.
Partition x(n) into segments of length L such that the ﬁrst N −1 samples in a
segment overlap the last N −1 samples in the previous segment. Segments are
then indexed by the superscript i to form the collection xi(n):
xi(n),
n = 0, 1, 2, . . . , (L −1), i = 0, 1, 2, . . . , ∞
4.
Apply circular convolution to obtain yi(n) = h(n) ⊗xi(n). This may be done by
calculation of the convolution sum in the n-domain or by multiplication of DFTs
and the taking of the inverse transform of the results. The resulting output segment
yi(n) has L samples. Discard the ﬁrst N −1 samples as they do not belong to
x(n)⋆h(n). Save the last (L −N + 1) samples.
yi(n) = {yi(0), yi(1), yi(2), . . . , yi(N −2)



discard
, yi(N −1), yi(N), . . . , yi(L −1)



save
}
The last (L −N + 1) samples in yi(n) are placed serially in a sequence to form
y(n) (linear convolution). This is the contribution of the i-th segment in x(n) to
y(n). Arrange these contribution in series to form y(n).
Example
17.21
Find y(n) = x(n) ⋆h(n) by (a) direct calculation of the linear convolution sum
and (b) circular convolution applying the “overlap and save” method. The input and
unit-sample functions are
h(n) = {a0, a1, a2} and x(n) = {b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, · · ·}

Signals and Systems
975
Solution
a.
The result of the linear convolution is
y(n) =
n

k=0
h(k)x(n −k)
y(0) = a0b0
y(1) = a0b1 + a1b0
y(2) = a0b2 + a1b1 + a2b0
y(3) = a0b3 + a1b2 + a2b1
...
y(i) = a0bi + a1bi−1 + a2bi−2
b.
To obtain the above results by circular convolution, we ﬁrst partition x(n) into
segments of length L ≥3. In this example we want to perform circular convo-
lution directly and not through FFT. Therefore, L does not have to be a power
of 2. Let L = 3. Because h(n) is also 3 samples long, no padding is necessary.
We now partition x(n) into segments each of length 3 with a 2-point overlap
between two consecutive sequences.
Segment
Samples
0
x0(n) = {0, 0, b0}
1
x1(n) = {0, b0, b1}
2
x2(n) = {b0, b1, b2}
3
x3(n) = {b1, b2, b3}
...
...
i
xi(n) = {bi−2, bi−1, bi}
...
...
We perform circular convolution of
h(n) ⊗xi(n) =
N−1

k=0
h(k)xi(n −k)
where xi(n −k) is found by time reversal and circular shift, starting with the
ﬁrst segment x0(n).
From segment 0 we get
y0(0) = a1b0
y0(1) = a2b0
"
throw away
y0(2) = a0b0

keep as y(0).

976
CHAPTER 17
Discrete Fourier Transform
From segment 1 we get
y1(0) = a1b1 + a2b0
y1(1) = a0b0 + a2b1
"
throw away
y1(2) = a0b1 + a1b0

keep as y(1).
...
From segment i we get
yi(0) = · · · · · · · · ·
yi(1) = · · · · · · · · ·
"
throw away
yi(2) = a0bi + a1bi−1 + a2bi−2

keep as y(i).
...
The result is y(n) = {y0(2), y1(2), y2(2), y3(2), y4(2), . . . , yi(2), · · ·}, where
y(0) = y0(2) = a0b0
y(1) = y1(2) = a0b1 + a1b0
y(2) = y2(2) = a0b2 + a1b1 + a2b0
y(3) = y3(2) = a0b3 + a1b2 + a2b1
...
y(i) = yi(2) = a0bi + a1bi−1 + a2bi−2
...
This is the same result obtained through linear convolution in part a.
Note: To make L a power of 2 (e.g., 4, 8, 16, 32, 64, . . .), pad the shorter sequence
h(n) with the required number of zeros.
Method 2
Another recipe for obtaining linear convolution of x(n) with h(n) by way of their circular
convolution is the following (called “overlap and add”):
1.
Construct the xi(n) segments by taking (L −N + 1) samples for each segment
from the long sequence x(n) and padding them with (N −1) zeros on the right
side. You will then get a sequence of L samples, the last N −1 of which are zeros.
2.
Pad h(n) with (L −N) zeros on the right side to make it L samples long, the last
(L −N) of which are zeros.
3.
Apply circular convolution to the two sequences.
4.
Place the ﬁrst (L −N + 1) samples in the output.
5.
The remaining (N −1) samples overlap the (N −1) samples of the subsequent
segment and are added to it.

Signals and Systems
977
Example
17.22
Apply the “overlap and add” method and circular convolution to ﬁnd the linear con-
volution y(n) = x(n) ⋆h(n), where
h(n) = {a0, a1, a2}
and
x(n) = {b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, · · ·}
Solution
We have N = 3, L = 3, L −N +1 = 1. To form the input segments take one sample
from the long sequence and pad it with two zeros. Do not pad h(n).
Segment
Samples
0
x0(n) = {b0, 0, 0}
1
x1(n) = {b1, 0, 0}
2
x2(n) = {b2, 0, 0}
3
x3(n) = {b3, 0, 0}
...
...
i
xi(n) = {bi, 0, 0}
· · ·
· · ·
Now perform the circular convolution yi(n) = h(n) ⊗xi(n) starting with the ﬁrst
segment x0(n).
Segment 0 is x0(n) = {b0, 0, 0}, from which we get:
y0(0) = a0b0
(keep)
y0(1) = a1b0
(add to the next)
y0(2) = a2b0
(add to the element after that)
Segment 1 is x1(n) = {b1, 0, 0}, from which we get:
y1(0) = a0b1
(keep)
y1(1) = a1b1
(add to the next)
y1(2) = a2b1
(add to the element after that)
...
Segment i is xi(n) = {bi, 0, 0}, from which we get:
yi(0) = a0bi
(keep)
yi(1) = a1bi
(add to the next)
yi(2) = a2bi
(add to the element after that)
...

978
CHAPTER 17
Discrete Fourier Transform
The result is y(n) = {y(0), y(1), y(2), y(3), y(4), . . . , y(i), · · ·}, where
y(0) = y0(0) = a0b0
y(1) = y0(1) + y1(0) = a1b0 + a0b1
y(2) = y0(2) + y1(1) + y2(0) = a2b0 + a1b1 + a0b2
y(3) = y1(2) + y2(1) + y3(0) = a2b1 + a1b2 + a0b3
...
y(i) = yi−2(2) + yi−1(1) + yi(0) = a2bi−2 + a1bi−1 + a0bi
This is the same result obtained through the method 1 and the direct linear convo-
lution operation.
17.10
DFT in Matrix Form
The DFT relationship
X(k) =
N−1

n=0
x(n)e−j2πnk/N, k = 0, 1, 2, . . . N −1
may also be given in matrix form. Let x and X be vectors, both of size N, representing
the signal in the time (n) and frequency (k) domains, respectively. Their relationship in
matrix form is given by
X = WN × x
The transformation matrix WN is an N ×N matrix whose elements are deﬁned as follows:
wn,k = e−j2πnk/N = wnk, where w = e−j2π/N
WN =


1
1
1
. . .
1
1
w
w2
. . .
w(N−1)
...
1
wi
w2i
. . .
w(N−1)i
...
1 wN−1 w2(N−1) . . . w(N−1)(N−1)


Note that wnk is periodic with period N. The transformation matrix, therefore,
contains a repetition within its structure, which can be used for an efﬁcient compu-
tation algorithm. The following examples illustrate the transformation matrix and its
application.

Signals and Systems
979
Example
17.23
Construct W4 and use it to ﬁnd the 4-point DFT of x(n) = {1
↑, 1, 0, 0}.
Solution
The elements of the 4 × 4 DFT matrix are
wnk = e−jπnk/2 = (−j)nk
w0 = w4 = w8 = 1
w1 = w5 = w9 = −j
w2 = w6 = −1
w3 = w7 = j
See Figure 17.8(a). Note the periodicity. The transformation matrix is
W4 =


1
1
1
1
1
w
w2
w3
1
w2
w4
w6
1
w3
w6
w9

=


1
1
1
1
1
−j
−1
j
1
−1
1
−1
1
j
−1
−j


The DFT vector is
X(k) =


X(0)
X(1)
X(2)
X(3)

=


1
1
1
1
1
−j
−1
j
1
−1
1
−1
1
j
−1
−j

×


1
1
0
0

=


2
(1 −j)
0
(1 + j)


w3
w0
w2
w1
(a) 4-point DFT
(b) 6-point DFT
(c) 8-point DFT
w0
w1
w2
w3
w4
w5
w6
w7
w0
w1
w2
w3
w4
w5
FIGURE 17.8 Elements of DFT transformation.
Example
17.24
Construct W6 and use it to ﬁnd the DFT of the 6-point window
x(n) = {0.31
↑, 0.77, 1, 1, 0.77, 0.31}

980
CHAPTER 17
Discrete Fourier Transform
Solution
Let w = e−jπ/3 = (1 −j
√
3)/2. See Figure 17.8(b). The elements of the transfor-
mation matrix are
w0 = w6 = w12 = w18 = w24 = w30 = 1
w1 = w7 = w13 = w19 = w25 = w31 = e−jπ/3 = 1 −j
√
3
2
w2 = w8 = w14 = w20 = w26 = w32 = e−j2π/3 = −1 −j
√
3
2
w3 = w9 = w15 = w21 = w27 = w33 = e−jπ = −1
w4 = w10 = w16 = w22 = w28 = w34 = e−j4π/3 = −1 + j
√
3
2
w5 = w11 = w17 = w23 = w29 = w35 = e−j5π/3 = 1 + j
√
3
2
The DFT vector is
X(k) =


1
1
1
1
1
1
1
w
w2
−1
w4
w5
1
w2
w4
1
w2
w4
1
−1
1
−1
1
−1
1
w4
w2
1
w4
w2
1
w5
w4
−1
w2
w


×


0.31
0.77
1
1
0.77
0.31


=


4.16
1.195̸ −150◦
0.23̸ −120◦
0
0.23̸ 120◦
1.195̸ 150◦


Example
17.25
Construct W8 and use it to ﬁnd the DFT of the 8-point window
x(n) = {0.146
↑
, 0.5, 0.853, 1, 1, 0.853, 0.5, 0.146}
Solution
Let w = e−jπ/4 =
√
2(1 −j)/2. See Figure 17.8(c). The elements of the transfor-
mation matrix are
w0 = w8 = w16 = w24 = w32 = w40 = w48 = 1
w1 = w9 = w17 = w25 = w33 = w41 = w49 = e−jπ/4 =
√
2
2 (1 −j)
w2 = w10 = w18 = w26 = w34 = w42 = e−jπ/2 = −j
w3 = w11 = w19 = w27 = w35 = w43 = e−j3π/4 = −
√
2
2 (1 + j)
w4 = w12 = w20 = w28 = w36 = w44 = e−jπ = −1
w5 = w13 = w21 = w29 = w37 = w45 = e−j5π/4 =
√
2
2 (−1 + j)
w6 = w14 = w22 = w30 = w38 = w46 = e−j3π/2 = j
w7 = w15 = w23 = w31 = w39 = w47 = e−j7π/4 =
√
2
2 (1 + j)

Signals and Systems
981
The DFT vector is
X(k) =


1
1
1
1
1
1
1
1
1
w
−j
w3
−1
w5
j
w7
1
−j
−1
j
1
−j
−1
j
1
w3
j
w
−1
w7
−j
w5
1
−1
1
−1
1
−1
1
−1
1
w5
−j
w7
−1
w
j
w3
1
j
−1
−j
1
j
−1
−j
1
w7
j
w5
−1
w3
−j
w


×


0.146
0.5
0.853
1
1
0.853
0.5
0.146


=


5
1.85̸ −157.5◦
0.293̸ −135◦
0
0
0
0.293̸ 135◦
1.85̸ 157.5◦


17.11
Conclusions: FS, FT, DTFT, and DFT
We have discussed Fourier analysis in four forms for four types of signals. These are
listed in Table 17.4. The table also illustrates relationships between the signal and its
various transforms.
TABLE 17.4 Signals in the Time and Frequency Domains, and Their
Relationships
Time-Domain Signals
Transform
Continuous time, periodic signals
Fourier series (FS)
Continuous-time signals
Fourier transform (FT)
Discrete-time signals
Discrete-time Fourier transform (DTFT)
Finite sequences
Discrete Fourier transform (DFT)
Fourier Series (FS)
⇐⇒
Fourier Transform (FT)
⇑
↖
↗
⇑
Signal
⇓
↙
↘
⇓
Discrete Fourier Transform
⇐⇒
Discrete-Time Fourier Transform
(DFT)
(DTFT)

982
CHAPTER 17
Discrete Fourier Transform
The transforms may be expressed as functions of angular frequency ω (in rad/s) or f
(in Hz). These variables are not the same for the continuous- and discrete-time domains.
To avoid confusion, especially when both domains are being discussed simultaneously,
uppercase letters (F and ) are often used for continuous-time signals and lowercase
letters ( f and ω) are allocated to discrete-time signals. Throughout our discussions we
almost always have used lowercase letters for both time domains, as the context was
clear and didn’t lend itself to confusion.
The exponential Fourier series expansion transforms periodic continuous-time sig-
nals x(t), −∞< t < ∞, into Fourier series with coefﬁcients Xk, where k is an integer,
−∞< k < ∞. In the new domain, integers k represent harmonics or the discrete-
frequency domain.
The Fourier transform converts nonperiodic, continuous-time signals x(t), −∞<
t < ∞, into X(F), where frequency F is a continuous variable, −∞< F < ∞. Under
Dirichlet conditions and for energy signals, the transform is a bounded function and
exists. By admitting the singularity function δ(F) into the picture, the Fourier trans-
form is generalized to include power and periodic signals. Under this generalization,
the Fourier transform of a periodic signal consisting of a train of impulses in the F-
domain placed at F = kF0, −∞< k < ∞, where k is an integer, F0 = 1/T is the
principal frequency of the periodic function, and T is its period. The strength of the
impulse at F = kF0 is Xk, the exponential Fourier series coefﬁcient at that harmonic.
The frequency domain is continuous, but the spectrum is made of discrete lines at the
harmonics. In summary, sampling in the frequency domain makes the time function
periodic.
The DTFT transforms a discrete-time signal x(n), −∞< n < ∞, where n is an
integer, into its frequency domain representation X(ω), −∞< ω < ∞, where ω is
a continuous variable. X(ω) is, however, 2π-periodic [X( f ) is periodic with a period
of 1 Hz]. Because of its periodicity, we only examine one period of X(ω), for example,
for −π < ω < π [or −0.5 < f < 0.5 for X( f )]. From an analysis and computational
point of view, the inﬁnite-length discrete-time domain −∞< n < ∞is transformed
into the ﬁnite-length continuous-frequency domain −π < ω < π. Hence, one can
say that sampling in the time domain makes representation in the frequency domain
periodic.
The DFT transforms a ﬁnite sequence x(n), n = 0, 1, 2, . . . , N −1, of length
N into another ﬁnite sequence X(k), k = 0, 1, 2, . . . , N −1, of the same length.
The elements of the sequence X(k) are samples of X(ω) [where X(ω) is the DTFT
of x(n), ∞< n < ∞] taken every 2π/N radians [i.e., N samples in one period of
X(ω)]. The DFT, therefore, performs sampling in the frequency domain. By sampling the
DTFT, the DFT simpliﬁes spectral analysis of ﬁnite data sequences. Moreover, evaluation
of the DFT involves multiplications and additions only, which can be done efﬁciently
both in real-time operations and in simulations. Real-time DFT is performed efﬁciently
by DSP processors, with architectures speciﬁcally designed for such operations. The
computationally efﬁcient algorithm for evaluating the DFT and its inverse is the fast
Fourier transform (FFT and IFFT), which is also used in off-line signal processing
applications.

Signals and Systems
983
17.12
Problems
Solved Problems
1. Find the following DFTs:
a. 7-point DFT of x1(n) = {1
↑, 1, 1, 0, 0, 0, 0}
b. 8-point DFT of x2(n) = {1
↑, 1, 1, 0, 0, 0, 0, 0}
c. 9-point DFT of x3(n) = {1
↑, 1, 1, 0, 0, 0, 0, 0, 0}
d. N-point DFT of x4(n) = {1
↑, 1, 1}
Solution
a. X1(k) =
2

n=0
e−j2πnk/7 = 1 + e−j2πk/7 + e−j4πk/7 =

1 + 2 cos 2πk
7

e−j2πk/7,
k = 0, 1, . . . , 6
b. X2(k) =
2

n=0
e−j2πnk/8 = 1 + e−jπk/4 + e−jπk/2 =

1 + 2 cos πk
4

e−jπk/4,
k = 0, 1, . . . , 7
c. X3(k) =
2

n=0
e−j2πnk/9 = 1 + e−j2πk/9 + e−j4πk/9 =

1 + 2 cos 2πk
9

e−j2πk/9,
k = 0, 1, . . . , 8
d. X4(k) =
2

n=0
e−j2πnk/N = 1 + e−j2πk/N + e−j4πk/N =

1 + 2 cos 2πk
N

e−j2πk/N,
k = 0, 1, . . . , N −1
2. Find the N-point DFT of x(n) = {1
↑, 1, 1, 1}.
Solution
X(k) =
3

n=0
e−j2πnk/N = 1 + e−j2πk/N + e−j4πk/N + e−j6πk/N
= 2

cos πk
N + cos 3πk
N

e−j3πk/N = 4 cos

πk
N

cos

2πk
N

e−j3πk/N, k = 0, 1, 2, . . . , N −1
3. Find DFTs of the following triangular windows with even symmetry.
a. 7-point DFT of x1(n) = 
0
↑, 0.5, 1.5, 2, 1.5, 0.5, 0
b. 9-point DFT of x2(n) = 
0
↑, 0.5, 1, 1.5, 2, 1.5, 1, 0.5, 0
Solution
a.
X1(k) =
6

n=0
x(n)e−j2πnk/7
= 0.5e−j2πk/7 + 1.5e−j4πk/7 + 2e−j6πk/7 + 1.5e−j8πk/7 + 0.5e−j10πk/7
= e−j6πk/7(0.5e j4πk/7 + 1.5e j2πk/7 + 2 + 1.5e−j2πk/7 + 0.5e−j4πk/7)
=

2 + 3 cos 2πk
7
+ cos 4πk
7

e−j6πk/7

984
CHAPTER 17
Discrete Fourier Transform
b. X2(k) =
8

n=0
x(n)e−j2πnk/9
= 0.5e−j2πk/9 + e−j4πk/9 + 1.5e−j6πk/9 + 2e−j8πk/9 + 1.5e−j10πk/9 + e−j12πk/9 + 0.5e−j14πk/9
= e−j8πk/9 
0.5e j6πk/9 + e j4πk/9 + 1.5e j2πk/9 + 2 + 1.5e−j2πk/9 + e−j4πk/9 + 0.5e−j6πk/9
=

2 + 3 cos 2πk
9
+ 2 cos 4πk
9
+ cos 6πk
9

e−j8πk/9
4. Find DFTs of the following windows with even symmetry.
a. 8-point DFT of x1(n) = 
0
↑, 0.5, 1.5, 2, 2, 1.5, 0.5, 0
b. 10-point DFT of x2(n) = 
0
↑, 0.5, 1, 1.5, 2, 2, 1.5, 1, 0.5, 0
Solution
a. X1(k) =
7

n=0
x(n)e−j2πnk/8
= 0.5e−jπk/4 + 1.5e−j2πk/4 + 2e−j3πk/4 + 2e−j4πk/4 + 1.5e−j5πk/4 + 0.5e−j6πk/4
= e−j7πk/8 
0.5e j5πk/8 + 1.5e j3πk/8 + 2e jπk/8 + 2e−jπk/8 + 1.5e−j3πk/8 + 0.5e−j5πk/8
=

4 cos πk
8 + 3 cos 3πk
8
+ cos 5πk
8

e−j7πk/8
b.
X2(k) =
9

n=0
x(n)e−j2πnk/10
= 0.5e−jπk/5 + e−j2πk/5 + 1.5e−j3πk/5 + 2e−j4πk/5 + 2e−j5πk/5 + 1.5e−j6πk/5 + e−j7πk/5 + 0.5e−j8πk/5
= e−j9πk/10 
0.5e j7πk/10+ e j5πk/10+ 1.5e j3πk/10+ 2e jπk/10+ 2e−jπk/10+ 1.5e−j3πk/10+ e−j5πk/10+0.5e−j7πk/10
=

4 cos πk
10 + 3 cos 3πk
10 + 2 cos 5πk
10 + cos 7πk
10

e−j9πk/10
5. Find the 128-point DFT of
a. x1(n) =
# 1, 0 ≤n ≤15
0, 16 ≤n ≤127
b. x2(n) =
# 1,
0 ≤n ≤16
0,
17 ≤n ≤127
Solution
a.
X1(k) =
15

n=0
e−j2πnk/128 = 1 −e−jπk/4
1 −e−jπk/64 =
sin(πk/8)
sin(πk/128)e−j15πk/128
b.
X2(k) =
16

n=0
e−j2πnk/128 = 1 −e−jπ17k/64
1 −e−jπk/64 = sin(17πk/128)
sin(πk/128) e−jπk/8

Signals and Systems
985
6. Find the N-point DFT of the following x(n) for N = 60, 120, and 240.
x(n) =
# 1,
0 ≤n ≤29
0,
30 ≤n ≤N −1
Solution
X(k) =
29

n=0
e−j2πnk/N = 1 −e−j60πk/N
1 −e−j2πk/N = sin(30πk/N)
sin(πk/N) e−j29πk/N
7. Find the 3-point DFT of h(n) = a−n, 0 ≤n ≤2, for a = 1.369.
Solution
H(k) =
2

n=0
1.369−ne−j2πkn/3, k = 0, 1, 2
H(0) =
2

n=0
1.369−n = 1 + 0.73 + 0.533 = 2.263
H(1) =
2

n=0
1.369−ne−j2πn/3 = 1 + 0.73e−j2π/3 + 0.533e−j4π/3 = 0.369 −j0.17 = 0.406̸ −24.7◦
H(2) =
2

n=0
1.369−ne−j4πn/3 = 1 + 0.73e−j4π/3 + 0.533e−j8π/3 = 0.369 + j0.17 = 0.406̸ 24.7◦
Note that H(2) = H ∗(1).
8. Find the N-point DFT of h(n) = e−n
5 , 0 ≤n ≤N, for
a. N = 3
b. N = 30
Solution
a. For N = 3,
H(k) =
2

n=0
e−n
5 e−j2πnk/3
H(0) =
2

n=0
e−n
5 = 1 + 0.8187 + 0.6703 = 2.489
H(1) =
2

n=0
e−n
5 e−j2πn/3 = 1 + 0.8187e−j2π/3 + 0.6703e−j4π/3 = 0.2555 −j0.1285 = 0.286̸ −26.7◦
H(2) =
2

n=0
e−n
5 e−j4πn/3 = 1 + 0.8187e−j4π/3 + 0.6703e−j8π/3 = 0.2555 + j0.1285 = 0.286̸ 26.7◦
Note that H(1) = H ∗(2).

986
CHAPTER 17
Discrete Fourier Transform
b. For 0 ≤n ≤29 we use the approach taken in Example 17.6. Here, h(n) = e−n
5 = a−n with a = e
1
5 = 1.2214.
Hence,
H(k) =
29

n=0
a−ne−j2πnk/30 =
1 −a−30
1 −a−1e−j2πk/30 =
0.9975
1 −(0.8187)e−j2πk/30
9. The following Matlab code computes the 3-point DFT of h(n) = 
0
↑, 1, 1
and displays h(n) and |H(k)|,
k = 0, 1, 2.
h=[0,1,1]; H=fft(h)
N=length(h); n=0:N-1; M=max(H);
figure(1); stem(n,h); axis([-1 N -.2 1.2]); grid
figure(2); stem(n,abs(H)); axis([-1 N -.2 M+.2]); grid
10. The Matlab codes in this problem compute the N-point DFTs of rectangular and exponential functions that are
M-samples long. The functions and their transforms are then displayed in the time and frequency domains. Run the
programs and explore the results for various values of M and N.
Rectangular Pulse
M=6; N=100;
h=[ones(1,M) zeros(1, N-M)];
H1=fft(h); H2=fftshift(H1); n=0:N-1;
figure(1); stem(n,h);
axis([-1 N -.2 1.2]);
grid
figure(2); stem(n,abs(H1)); axis([-1 N -.2 M+.2]); grid
figure(3); stem(n,abs(H2)); axis([-1 N -.2 M+.2]); grid
Alternatively, use the following commands to generate h and H1. Then mask ﬁgure (1).
h=ones(1,M); H1=fft(h,N)
Exponential Function
M=16; N=16; m=0:M-1; n=0:N-1; a=2; %a=1+j;
h=[a.√(-m/10) zeros(1,N-M)]; H=fft(h);
figure(1); stem(n,abs(h)); axis([0 N -.2 1.2]); grid
figure(2); stem(n,abs(H)); axis([0 N -.2 abs(max(H))+.2]); grid
11. The following Matlab code obtains the IDFT of the 16-point H(k) in Example 17.9 by three methods. It then pads
the h(n) by 30 zeros and takes its 46-point DFT. See Figure 17.9.
clear
H=[1 -1 1 -0.5 zeros(1,9) -0.5 1 -1];
% Method 1. Inverse of H by ifft command.
h=ifft(H);
% Method 2. Inverse of H by summation.
h1=zeros(1,16);
for n=1:16
hh=0;

Signals and Systems
987
for k=1:16
hh=hh+H(k)*exp(i*pi*(k-1)*(n-1)/8);
end
h1(n)=hh/16;
end
% Method 3. Inverse of H by analytic expression.
n=0:15; h2=(1-2*cos(pi*n/8)+2*cos(pi*n/4)-cos(3*pi*n/8))/16;
h3=sin(pi*(n-8)/2)./(pi*(n-8)); h3(9)=1/2;
% Computing differences
e1=h1-h; e2=h2-h; e3=h3-h;
% Padding h for a better frequency resolution.
hp=[h zeros(1,30)]; k=0:45; HP=fft(hp);
% Plots
figure(1); stem(n,real(h));
axis([0 16 -.2 .5]);
grid
figure(2); stem(n,H);
axis([0 16 -1.2 1.2]); grid
figure(3); stem(k,real(HP)); axis([0 46 -1.2 1.2]); grid
figure(4); stem(k,abs(HP));
axis([0 46 -.2 1.2]);
grid
figure(5); stem(n,h3);
axis([0 16 -.2 1.2]);
grid
a. Run the program and compare the results obtained by the three methods.
b. Change H in the second line of the program to
H=[1, 1, 1, 0.5, zeros(1,9), 0.5, 1, 1]
and run the program. Describe the results and explain the reason for choosing the initial vector for H.
0.5
0
0
2
4
6
8
10
12
14
16
45
40
30
25
20
15
10
5
0
1
0
35
FIGURE 17.9 A 16-tap low-pass ﬁlter h(n) (left) and the magnitude of H(k) the 46-point DFT of padded h(n) (right).
Padding with zeros is done to increase the frequency resolution. See Example 17.9 and problem 11.
12. Parseval’s theorem. Given x(n) = {0
↑, 1, 1} and y(n) = {0
↑, j, −j}, verﬁy that
2

n=0
x(n)y(n) = 1
3
2

k=0
X(k)Y(−k)
and
2

n=0
x(n)y∗(n) = 1
3
2

k=0
X(k)Y ∗(k)

988
CHAPTER 17
Discrete Fourier Transform
Solution
From Example 17.3 we have X(k) = 2 cos πk
3

e−jπk and Y(k) = −2 sin πk
3

e−jπk, k = 0, 1, 2.
x(n)y(n) = {0
↑, j, −j}

⇒
2

n=0
x(n)y(n) = 0
x(n)y∗(n) = {0
↑, −j, j}

⇒
2

n=0
x(n)y∗(n) = 0
X(k)Y(−k) = 2 sin

2πk
3


⇒
1
3
2

k=0
X(k)Y(−k) = 1
3(0 +
√
3 −
√
3) = 0
X(k)Y ∗(k) = −2 sin

2πk
3


⇒
1
3
2

k=0
X(k)Y(−k) = 1
3(0 −
√
3 +
√
3) = 0
13. FFT algorithm. Consider the ﬁnite sequence x(n) = {1
↑, 1, 0, 0}.
a. Find X(k), the 4-point DFT of x(n).
b. Show how an FFT algorithm would evaluate the DFT.
c. Apply the algorithm to x(n) and obtain the same results as in part a.
Solution
a. X(k) = 3
n=0 x(n)e−jπnk/2 = 1 + e−jπk/2, k = 0, 1, 2, 3, X(k) = {2
↑, (1 −j), 0, (1 + j)}
b. Split x(n) of length N into two sequences a(n) = x(2n) and b(n) = x(2n + 1), each of length N/2. Let
A(k) = DFT [a(n)]
B(k) = DFT [b(n)]
Then
X(k) = A(k) + e−j2πk/N B(k) k = 0, 1, . . . , N
2 −1
X(N/2 + k) = A(k) −e−j2πk/N B(k), k = 0, 1, . . . , N
2 −1
In this problem N = 4, X(k) = A(k) + e−jπk/2B(k), k = 0, 1 and X(2 + k) = A(k) −e−jπk/2B(k), k = 0, 1
a(n) = {1
↑, 0}
A(k) = DFT {1
↑, 0} = {1
↑, 1}
b(n) = {1
↑, 0}
B(k) = DFT {1
↑, 0} = {1
↑, 1}
k = 0,
X0 = 1 + e0 = 2
k = 1,
X1 = 1 + e−jπ/2 = 1 −j
k = 2,
X2 = 1 −e−jπ = 0
k = 3,
X3 = 1 −e−j3π/2 = 1 + j
Chapter Problems
14. Find the 4-point DFTs of the sequences given below.
a. x1(n) = {1
↑, 0, 0, 0}
b. x2(n) = {1
↑, 1, 0, 0}
c. x3(n) = {1
↑, 1, 1, 0}
d. x4(n) = {1
↑, 1, 1, 1}

Signals and Systems
989
15. Find the 5-point DFTs of the sequences given below.
a. x1(n) = {1
↑, 1, 0, 0, 0}
b. x2(n) = {1
↑, 1, 1, 0, 0}
c. x3(n) = {1
↑, 1, 1, 1, 0}
d. x4(n) = {1
↑, 1, 1, 1, 1}
16. Find the 9-point DFTs of the sequences given below.
a. x1(n) = {1
↑, 2, 1, 0, 0, 0, 0, 0, 0}
b. x2(n) = {1
↑, 2, 3, 2, 1, 0, 0, 0, 0}
c. x3(n) = {1
↑, 2, 3, 4, 3, 2, 1, 0, 0}
d. x3(n) = {1
↑, 2, 3, 4, 5, 4, 3, 2, 1}
17. From the deﬁnition ﬁnd the 5-point DFT of xe(n), xo(n) and x(n) given below. In each case observe that (i)
x(n) = xe(n) + xo(n), (ii) Xe(k) is real-valued and Xo(k) is imaginary. Find the relation between X(k), Xe(k),
Xo(k).
a. xe(n) = {1
↑, 5, −2, −2, 5}
xo(n) = {0
↑, 5, −2, 2, −5}
x(n) = {1
↑, 10, −4, 0, 0}
b. xe(n) = {2
↑, 7, 7, 7, 7}
xo(n) = {0
↑, −3, −1, 1, 3}
x(n) = {2
↑, 4, 6, 8, 10}
c. xe(n) = {2
↑, 7, 7, 7, 7}
xo(n) = {0
↑, 3, 1, −1, −3}
x(n) = {2
↑, 10, 8, 6, 4}
18. For each x(n) given below do the following:
a. Fnd X(k) = DFT {x(n)}.
b. Take the inverse of its real part and examine it to see if the inverse is equal to xe(n) = x(n)+x(−n)
2
.
c. Take the inverse of its imaginary part and examine it to see if the inverse is equal to xo(n) = x(n)−x(−n)
2
.
a. x(n) = {1
↑, 1, 1, 1}
b. x(n) = {2
↑, 3, 4, 3, 2}
c. x(n) = {1
↑, 2, 3, 4, 3, 2, 1}
19. An LTI system is speciﬁed by the unit-sample response h(n) and an input x(n).
a. Find the DFTs of h(n) = {1
↑, −1, 1, 0} and x(n) = {1
↑, 2, 2, 1}.
b. Let Y(k) = X(k) × H(k). Find y(n) the IDFT of Y(k).
c. Note that y(n) is the circular convolution of x(n) and h(n). Discuss and show why it is not the output of the LTI
system.
d. Show that padding with a single zero and taking 5-point DFT/IDFT of the functions involved doesn’t provide
the output. Determine the minimum padding for which the result of the circular convolution becomes equal to
linear convolution.
20. a. Find Xa(k) and Xb(k), the DFTs of xa(n) = {1
↑, 1, 0, 0} and xb(n) = {1
↑, 0, 0, 1}.
b. Find the relationship between the magnitudes of Xa(k) and Xb(k) and discuss the reason behind it.
21. a. Find DTFT of x(n) = {· · · 0, 0, 1
↑, 2, 1, 0, 0 · · ·}. Call it X(ω).
b. Find 3-point DFT of {1
↑, 2, 1}. Call it X(k) = {X0
↑
, X1, X2}.
c. Explain and verify the relationship between x(ω) and X(k).
22. The unit-sample response of a ﬁlter is h(n) = {· · · 0, 0, 1
↑, 1, 1, 1, 0, 0 · · ·}.
a. Find the system’s frequency response H(ω) = DT FT {h(n)} = Hr(ω)e j	(ω).
b. Sketch Hr(ω) and 	(ω) for −π < ω < π.

990
CHAPTER 17
Discrete Fourier Transform
c. Let H(k) be the 4-point DFT of the ﬁnite sequence {1
↑, 1, 1, 1}. It is expected that H(k) = H(ω)
!!
ω=πk =
[4, 0, 0, 0]. Obtain H(k) by applying the DFT deﬁnition and verify that it is in agreement with samples of H(ω).
d. Let the input to the ﬁlter be x(n) = cos( πn
3 ). Find the system’s steady-state response in the form of y(n) =
A cos(ω0n + 	).
23. Find the N-point DFT of {1
↑, 1} for N = 6, 8, 10, and 64. Plot their magnitude and discuss the effect of
increasing N.
24. Obtain a closed-form expression for the N-point DFT of
x(n) =
# an,
0 ≤n ≤(M −1)
0,
M ≤n ≤(N −1)
Plot the magnitude of the DFT for the following parameter values:
a. N = M = 2, 3, 4, 10, 100
b. N = 100 and M = 2, 3, 4, 10
25. Obtain a closed-form expression for the DFT of
x(n) =
# cos(2πn/3),
0 ≤n ≤3
0,
4 ≤n ≤(N −1)
Plot x(n) and the magnitude of the DFT for N = 4, 6, 8. Discuss the reason behind possible differences between
the DFTs in this problem and Example 17.7a.
26. Obtain a closed-form expression for the DFT of
x(n) =

cos(2πn/3),
0 ≤n ≤(M −1)
0,
M ≤n ≤(N −1)
Plot x(n) and the magnitude of the DFT for the following parameter values:
a. N = M = 2, 5, 8, 11
b. N = 101 and M = 2, 5, 8, 11.
27. Low-pass ﬁlter. Obtain a closed-form expression for the DFT of
h(n) =

sin$ π
2 (n −3)%
/π(n −3),
0 ≤n ≤6
0,
7 ≤n ≤(N −1)
Plot x(n) and the magnitude of the DFT for the following:
a. N = 7
b. N = 120
Hint: Examine the following Matlab code and use it to plot the DFT magnitudes.
M=7; m=1:M; omega=pi/2;
p=sin(omega*(m -(M+1)/2))./(pi*(m-(M+1)/2)); p((M+1)/2)=omega/pi;
N=120; n=0:N-1;
h=[p zeros(1,N-M)];
H=fft(h);
figure(1); stem(n,h); axis([-1 M+1 -.2 1.2]); grid
figure(2); stem(n,abs(H)); axis([-1 N -.2 max(abs(H))+.2]); grid

Signals and Systems
991
28. Replace the ﬁrst two lines in the Matlab code of problem 27 by the following two lines and run it.
M=6; m=1:M; omega=pi/2;
p=sin(omega*(m -M/2))./(pi*(m-M/2)); p(M/2)=omega/pi;
Comment on the plots.
29. Use the Matlab code given in problem 27 to plot the magnitude of the DFT of h(n) in that problem for the following:
a. M = 11 and ω0 = π
4
b. M = 11 and ω0 = 3π
4
c. M = 21 and ω0 = π
4
d. M = 21 and ω0 = 3π
4
e. M = 31 and ω0 = π
4
f. M = 31 and ω0 = 3π
4
30. Bandpass ﬁlter. Obtain the DFT of
h(n) =



sin[ω2(n −3)]
π(n −3)
−sin[ω1(n −3)]
π(n −3)
,
0 ≤n ≤6
0,
7 ≤n ≤(N −1)
where ω1 = 5π/12 and ω2 = 7π/12. Plot x(n) and the magnitude of its DFT for
a. N = 7
b. N = 120
Hint: Examine the following Matlab code and use it to plot the DFT magnitudes.
M=7; m=1:M; omega0=pi/2; domega=pi/6;
omega1=omega0-domega/2; omega2=omega0+domega/2;
p1=sin(omega1*(m -(M+1)/2))./(pi*(m-(M+1)/2)); p1((M+1)/2)=omega1/pi;
p2=sin(omega2*(m -(M+1)/2))./(pi*(m-(M+1)/2)); p2((M+1)/2)=omega2/pi;
p=p2-p1;
N=120; n=0:N-1;
h=[p zeros(1,N-M)];
H=fft(h);
figure(1); stem(n,h); axis([-1 M+1 -.2 .2]); grid
figure(2); stem(n,abs(H)); axis([-1 N -.2 max(abs(H))+.2]); grid
31. a. Replace the ﬁrst line in the Matlab code of problem 30 by the following line and run it. Comment on the changes
you see in the plots.
M=21; m=1:M; omega0=pi/2; domega=pi/6;
b. Repeat for M = 49.
32. a. Replace the ﬁrst line in the Matlab code of problem 30 by the following line and run it. Comment on the changes
you see in the plots.
M=21; m=1:M; omega0=pi/4; domega=pi/6;
b. Repeat for M = 49.

992
CHAPTER 17
Discrete Fourier Transform
33. a. Replace the ﬁrst line in the Matlab code of problem 30 by the following line and run it. Comment on the changes
you see in the plots.
M=21; m=1:M; omega0=3pi/4; domega=pi/6;
b. Repeat for M = 49.
34. This problem designs a linear-phase bandpass FIR ﬁlter with nine taps using rectangular window method. The
desired frequency response within the range −π < ω < π is
Hd(ω) =
# 1
π/5 ≤|ω| ≤π/3
0
elsewhere
For simplicity we represent the unit-sample response in the noncausal form shown below.
h(n) = {h4, h3, h2, h1, h0
↑
, h1, h2, h3, h4}
Follow steps described below.
a. Find ha(n) of a linear-phase 9-tap low-pass FIR ﬁlter with cutoff frequency at ωa = π/5.
b. Find hb(n) of a linear-phase 9-tap low-pass FIR ﬁlter with cutoff frequency at ωb = π/3.
c. Using ha(n) and hb(n) ﬁnd h(n).
d. Obtain and plot DFT of h(n). Compare with desired frequency response.
e. Increase the number of taps and observe how it brings the DFT of h(n) closer to the desired frequency response
except at the cutoff frequency. Explain the reason and suggest a solution.
35. Using the approach of problems 28 and 31 write a Matlab code to design M-tap high-pass digital ﬁlters with cutoff
frequency at ω0. Find h(n) and plot |H(k)| for following sets of parameters:
a. M = 11 and ω0 = π
4
b. M = 11 and ω0 = π
2
c. M = 11 and ω0 = 3π
4
d. M = 21 and ω0 = π
4
e. M = 21 and ω0 = π
2
f. M = 21 and ω0 = 3π
4
g. M = 31 and ω0 = π
4
h. M = 31 and ω0 = π
2
i. M = 31 and ω0 = 3π
4
36. Obtain the N-point DFTs of the following three functions deﬁned for n = 0, 1, . . . , N −1.
a. x1(n) = cos

2πn
N

b. x2(n) = sin

2πn
N

c. x3(n) = e j2πn/N
37. Windows. Obtain the N-point DFTs of the following windows: rectangular, Bartlett, Hanning, Hamming, and
Blackman. All windows are deﬁned for 0 ≤n ≤N −1. Window functions are found in section 11.17 of Chapter 11.
38. Obtain a closed-form expression for the N-point DFT of
h(n) = ρn cos(ω0n), 0 ≤n ≤(N −1)
Plot x(n) and the magnitude of the DFT for the following parameter values:
a. ρ = 0.9, ω0 = π/4
b. ρ = 0.95, ω0 = π/4
c. ρ = 0.9, ω0 = π/2
d. ρ = 0.95, ω0 = π/2
e. ρ = 0.9, ω0 = 3π/4
f. ρ = 0.95, ω0 = 3π/4

Signals and Systems
993
39. Circular convolution. Obtain the circular convolution of h(n) = {1
↑, 1, 1, 1} with itself.
40. Circular convolution. Obtain the circular convolution between h(n) = {1
↑, 1, 1, 1, 1} and x(n) = {1
↑, −1, 1, −1, 1}.
41. Circular convolution. Obtain the circular convolution between h(n) = 0.8n, n = 0, 1, . . . 7 and x(n) = {1
↑, −1}
padded by 6 zeros.
42. Linear convolution from circular. Apply the “overlap and save” method and circular convolution to ﬁnd the linear
convolution y(n) = x(n) ⋆h(n), where
h(n) = {a0, a1, a2, a3}
and
x(n) = {b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, . . .}
43. Linear convolution from circular. Apply the “overlap and add” method and circular convolution to ﬁnd the linear
convolution y(n) = x(n) ⋆h(n), where
h(n) = {a0, a1, a2, a3}
and
x(n) = {b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, . . .}
44. FFT algorithm. Repeat problem 13 for the ﬁnite-length sequence xn = {1
↑, 2, 3, 4}.
17.13
Project: DFT Spectral Analysis
Summary
In this project you will use a special-purpose instrument called a spectrum analyzer to obtain and measure the spectrum of
signals in real time. Measurement is done on a segment of the waveform observed and recorded through a window. Three
types of windows are used: uniform (rectangular), Hanning, and ﬂat-top. You will examine and investigate the effect of
the window on the spectrum and develop insights into their choice.
Equipment
1 function generator
1 oscilloscope
1 spectrum analyzer
Assignments and Reporting
This project has 26 items. Read and do items 12–16, 22(c)–24.
Theory
You need to be familiar with the theory of Fourier analysis for periodic and aperiodic signals summarized below.
1. Fourier Transform
The Fourier transform of a continuous-time function x(t) is deﬁned by
X( f ) =
&
∞
−∞
x(t)e−j2π f t dt
⇐⇒
x(t) =
&
∞
−∞
X( f )e j2π f td f
In practice, the following two factors affect the computation of X( f ):
i. The integral is evaluated by a digital device. The continuous-time signal x(t) is sampled and converted to a discrete-
time signal x(n) and the integral is replaced by a sum.

994
CHAPTER 17
Discrete Fourier Transform
ii. The summation cannot be extended to future values of x(n) because the future hasn’t arrived. It cannot include all
the past values of x(n) because of limitations on acceptable delay, memory, and computation time. The summation
is, therefore, done over a ﬁnite segment of the data.
In summary, the inﬁnite Fourier integral is replaced by a ﬁnite sum. A similar situation arises when taking the inverse
transform; X( f ) is sampled and a ﬁnite number of samples are used. These operations are performed by the discrete
Fourier transform (DFT) and the inverse discrete Fourier transform (IDFT).
2. Windows
As we have stated, the domain of the mathematical models of a real signal is −∞< t < ∞. However, in practice
we process ﬁnite-length segments of a signal at any given time. Mathematically, this corresponds to multiplying the
original signal by a window that is nonzero within an interval and zero outside that interval. A window is, therefore, a
ﬁnite-duration pulse through which we look at a data stream or function. It may be a time window or a frequency window.
The role of a time window is to create and shape a ﬁnite segment of the data or a ﬁlter’s impulse response in a way that
certain characteristics are met. The narrower the window is in the time domain, the wider its transform is in the frequency
domain and vice versa. Given the duration of a window, its shape has an important role in its function. The time functions
for some familiar continuous-time windows and their Fourier transforms are listed in Table 17.5 below. For simplicity,
the time origin in the continuous-time windows is chosen such that the windows are even functions of time.
TABLE 17.5 Mathematical Expressions for Continuous-Time Windows and Their Fourier Transforms. All
windows are τ seconds wide and are specified for −τ/2 < t < τ/2. Elsewhere, the windows have zero values.
Window
Time Function
⇐⇒
Fourier Transform
Rectangular 1
⇐⇒sin(π f τ)
π f
Bartlett
1 −2|t|
τ
⇐⇒2
τ

sin(π f τ/2)
π f
2
Hanning
0.5 + 0.5 cos

2πt
τ

⇐⇒0.5sin(π f τ)
π f
+ 0.25sin πτ( f −1
τ )
π( f −1
τ )
+ 0.25sin πτ( f + 1
τ )
π( f + 1
τ )
Blackman
0.42 + 0.5 cos

2πt
τ

+ 0.08 cos

4πt
τ

⇐⇒0.42sin(π f τ)
π f
+ 0.25sin πτ( f −1
τ )
π( f −1
τ )
+0.25sin πτ( f + 1
τ )
π( f + 1
τ )
+0.04sin πτ( f −2
τ )
π( f −2
τ )
+ 0.04sin πτ( f + 2
τ )
π( f + 2
τ )
3. Fourier Transform of a Windowed Signal
Let y(t) = x(t) × w(t) be a ﬁnite segment of a signal x(t) seen through a window w(t). The Fourier transform of y(t)
is obtained from the convolution of the Fourier transforms of x and w. Y( f ) = X( f ) ⋆W( f ). These are summarized in
Table 17.6 along with an example of a tone burst signal.
Mathematically, windowing modulates the amplitude of a sinusoid, shifting its spectrum to the location of the
frequency of the sinusoid.

Signals and Systems
995
TABLE 17.6 Windowed Signals in Time and Frequency
Function
Time Domain
Frequency Domain
Signal
x(t)

⇒
X( f )
Window
w(t)

⇒
W( f )
Windowed signal
y(t) = x(t)w(t)

⇒
Y( f ) = X( f ) ⋆W( f )
Tone
x(t) = 2 cos(2π f0t)

⇒
X( f ) = δ( f + f0) + δ( f −f0)
Tone burst
y(t) = 2w(t) cos(2π f0t)

⇒
Y( f ) = W( f + f0) + W( f −f0)
Rectangular window, τ sec w(t) =
# 1,
−τ/2 < t < τ/2
0,
elsewhere

⇒
W( f ) = sin(π f τ)
π f
Rectangular tone burst
y(t) =
# 2 cos(2π f0t),
−τ/2 < t < τ/2
0,
elsewhere

⇒
Y( f ) = sin[πτ( f + f0)]
π( f + f0)
+sin[πτ( f −f0)]
π( f −f0)
4. Comparative Analysis of Windows
The spectrum analyzer allows you to choose one of three windows: Hanning, ﬂat-top, and rectangular. The Hanning
window produces a sharper peak at the harmonics and is used for best accuracy in measuring the frequency of a peak. The
ﬂat-top window is a special feature of the spectral analyzer. It produces, as the name implies, a broader peak and is preferred
for best accuracy in measuring the value of the peak. All of these windows are called low-pass windows because they have
a low-pass spectrum. The spectra may be roughly speciﬁed by their 3-dB bandwidths, where 20 log |W( f )/W(0)| = −3
dB, and by the ﬁrst frequency zero-crossing, where W( f ) = 0. These speciﬁcations depend on the window’s size and
shape. Table 17.7 summarizes these speciﬁcations for rectangular, Bartlett, Hanning, Blackman, and ﬂat-top windows.
A ﬂat-top window is speciﬁc to the spectrum analyzer. Note that from here on a window’s width in the continuous-time
domain is shown by T , which produces a frequency resolution f = 1/T .
TABLE 17.7 Comparing the salient features of five windows (height = 1, size = T sec-
onds): G0 in dB = window’s DC gain, ∆G in dB = drop in gain at the second lobe with
reference to the peak gain at f = 0, f0 = the first zero-crossing, BW = 3-dB bandwidth.
Window Type
G0
∆G
f0
3-db BW
Rectangular
0 dB
−13.35 dB
1
T
0.44
T
Bartlett
−6 dB
−26.7 dB
2
T
0.44
T
Hanning
−6 dB
−31.37 dB
2
T
0.72
T
Blackman
−7.54 dB
−58.5 dB
3
T
0.44
T
Flat-top
−90 dB
5
T
1.8
T

996
CHAPTER 17
Discrete Fourier Transform
The magnitude frequency responses of four discrete-time windows are shown in Figure 17.10. Abscissa is discrete
frequency in Hz. Ordinate is magnitude in dB. The Matlab ﬁle for generating Figure 17.10 is given in Attachment A at
the end of this project.
(a) 16-point windows
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Magnitude (dB)
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Rectangular
Bartlett
Magnitude (dB)
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Magnitude (dB)
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Hanning
Blackman
Magnitude (dB)
FIGURE 17.10 Spectra of four discrete-time windows: rectangular, Bartlett, Hanning, and Blackman. Abscissa’s unit
is Fs/2 Hz. The ordinate unit is dB.
5. Obtaining a Fourier Transform by Digital Hardware (DFT)
The spectrum of a continuous-time signal may be obtained by using a digital device such as a general-purpose digital
computer, special-purpose digital signal processing hardware (DSP chips and boards), or by a stand-alone digital instru-
ment such as the spectrum analyzer used in this experiment. The spectrum analyzer is a digital instrument that computes
and displays the DFT of a signal in real time. This involves the following three steps:
(a) Sampling.
Theincomingcontinuous-timesignal x(t)issampledattherateof Fs samplespersecond(orequivalently
with a sampling interval t = 1/Fs seconds). This results in a discrete-time sequence x(n). Any frequency content of
x(t) that is greater than Fs/2 Hz is not recoverable from x(n). The sampling rate, therefore, should be twice the highest
frequency present in x(t). If this condition is not met, the higher frequencies are reﬂected back, causing aliasing.

Signals and Systems
997
(b) 32-point windows
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Magnitude (dB)
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Magnitude (dB)
Hanning
Blackman
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Magnitude (dB)
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Frequency (Hz)
Magnitude (dB)
Rectangular
Bartlett
FIGURE 17.10 (Continued)
(b) Windowing.
A ﬁnite segment of length N of the discrete signal x(n) is chosen and labeled xn, n = 0, 1, 2 . . . , (N −
1). This operation is equivalent to windowing by a rectangular window of size N. Other windows, such as a Hanning
window, multiply the sequence xn by their corresponding weighting function. The result is saved in the memory of the
digital device for computation. An N-point discrete signal corresponds to a segment of length T = Nt seconds of the
signal in the continuous-time domain.
(c) Computation.
The following sum is evaluated and labeled as Xk:
Xk =
N−1

n=0
x(n)e−j2πkn/N, k = 0, 1, 2 · · · (N −1)
Xk is called the discrete Fourier transform (DFT) of x(n). k = 0 corresponds to the DC value of the spectrum and
k = N −1 corresponds to the highest frequency Fs/2. The frequency resolution is, therefore, f = Fs/N.

998
CHAPTER 17
Discrete Fourier Transform
6. Fast Fourier Transform
When window size N is a power of 2 (such as N = 128, 256, 512, 1,024, . . .) a fast algorithm is employed to evaluate the
DFT, in which case the operation is called the fast Fourier transform (FFT). Note that if xn is a sequence of real numbers
(as real-time functions are), Xk will be complex with a magnitude and phase. The spectrum analyzer computes both the
magnitude and phase of the spectrum.
7. Time and Frequency Resolution
By sampling every t seconds (or equivalently at the rate of Fs = 1/t samples per seconds), the spectrum analyzer
converts a continuous-time signal to a discrete-time signal. The time resolution is t = 1/Fs. An N-point discrete signal
corresponds to a segment of length T = Nt = N/Fs of the signal in the continuous-time domain. On the other hand,
as shown in item 5(c) of this project, the frequency resolution is f = Fs/N. In summary
f = 1
T ,
t = 1
Fs
The highest frequency in the computed spectrum is Fs/2. To increase the frequency span of the spectrum we need to use
a higher sampling rate.
The lowest frequency, past the DC component, in the computed spectrum is f = 1/T , where T is the size of the
window (length of data used for computation of the spectrum). For a better frequency resolution (lower f ), a wider
window is needed; that is, we need to take in a longer segment of the signal.
8. Periodicity in Time and Frequency
Mathematically, sampling in time creates periodicity in the frequency domain. Similarly, the DFT creates a discrete
frequency domain, corresponding to a periodicity in the time domain. It is, therefore, sometimes said that sampling in
one domain creates periodicity in the other.
9. The Spectrum Analyzer
The spectrum analyzer samples the signal at the rate of Fs = 4.096 × frequency span, twice the minimum rate (called
the Nyquist rate), and windows it. The time window has 1,024 points. It then computes both the magnitude and phase
of Xk, where k = 0, 1, 2, . . . (N −1)/2, corresponding to frequencies f = 0, f, 2f, 3f, . . . Fs/2. Fs/2 is the
frequency span chosen on the front panel and is the highest frequency in the sampled signal. The screen display shows
the magnitude and phase of the one-sided spectrum of the periodic extension of the windowed signal. The display is,
therefore, made of a set of discrete points. The display labels the frequency axis in Hz. The displayed magnitude value
at each frequency represents the amplitude of the component of the signal at that frequency. The numerical values of the
display at each point can be estimated from the screen. Their more accurate values are also readable through a marker
that can give their value in linear scale (volts, rms) or dBV (2 dB or 10-dB scales). In summary, the spectrum analyzer
shows the magnitudes Vk and phases θk of the periodic signal v(t)
v(t) = V0 +
(N−1)/2

k=1
Vk cos

2πkt
T
+ θk

in which Vk = 2|Xk|, θk = ̸ Xk, and one period of v(t) is captured by a sweep of length T .
10. The DFT of Windowed Signals
The spectrum analyzer computes the discrete Fourier transform (DFT) of the discrete-time window. DFT is a discrete
representation in the frequency domain. It is computed directly as explained in the “Comparative Analysis of Windows”
section above, but is also obtained by sampling the Fourier transform of the continuous-time signal at f = 1/T Hz,
where T is the window size. Consequently, the spectrum of a sinusoid at frequency f0 obtained by the spectrum analyzer

Signals and Systems
999
under a window size T is made of lines that are sample values of the continuous spectra. See Figure 17.11 in Attachment
B at the end of this project. In the case of the uniform window all samples of the spectrum are zero except for a single
line at f0. Under a Hanning window, the DFT of the sinusoid displays three spectral lines (at f0 ± f ). The Blackman
window will have ﬁve lines at f0 ±kf, k = 1, 2 Hz. The ﬂat-top window has nine lines at f0 ±kf, k = 1, , 2, 3, 4 Hz.
These are veriﬁed by measurements shown in Table 17.10 in Attachment B.
11. Real-Time Signal Processing
Strictly speaking, a real-time signal processing system would operate on the input sample immediately and have it
contribute to the processing before the next sample arrives to the processor. An example is a window averager that, after
the arrival of a sample, computes the average of the past M-samples, places the result in the output, and waits for the next
sample to arrive. In conjunction with an analog-to-digital and a digital-to-analog converter, the above system performs
similar to the real-time operation of an analog system.
Digital signal processing operations that are based on an analysis in the frequency domain ﬁrst store an array of
consecutive N incoming samples in a buffer, multiply the array by a window of the same size, and then take the DFT of
the windowed signal for further processing. As time progresses, both the windowing of the incoming signal (with some
overlap between neighboring windows) and the DFT operation are repeated. For example, in a typical Linear Predictive
Coding (LPC) scheme of speech, signal windows are 80 msec long and consecutive windows may have 20-msec overlaps.
In a sense and strictly speaking, such a frequency domain processing is not done in real time. However, it is called real-time
processing. We, therefore, consider the operation of the spectrum anayzer to be in real time.
Prelab
12. The rms and dBV Values of a Sinusoid
Let v(t) = V0 cos(2π f t + θ). The rms and dBV (decibel volt) values of v(t) are deﬁned by
Vrms = 1
T
&
t0+T
t0
v2(t)dt and VdBV = 20 log Vrms
where T is a multiple of the period of the sinusoid. From the above deﬁnition, for the sinusoidal waveform we ﬁnd that
Vrms = V0/
√
2. Find the rms and dB values corresponding to the amplitudes given in Table 17.8. Complete the table.
TABLE 17.8 The rms and dB Values of a Sinusoid Com-
puted from Its Amplitude V0
V0 (V ) =⇒1
2
5
10
20
Vrms 
⇒
VdBV 
⇒
13. Spectrum of a Windowed Sinusoid
Multiply the sinusoidal signal (Vrms = 1 V, f = 1 kHz) by a window (peak = 1, T = 20 msec) to obtain x(n) =
w(t) × cos(2000πt). Find the spectrum of x(t) for three windows: (1) Uniform, (2) Hanning, (3) Blackman. Plot the
three x(t) and their spectra.

1000
CHAPTER 17
Discrete Fourier Transform
Measurements and Analysis
14. Setting Up the Spectrum Analyzer
Feed the signal from the function generator to channel A of the spectrum analyzer. Start with the following settings on
the spectrum analyzer.
Input:
Channel A, AC coupling
Trigger:
Repetitive, free run
Window:
Uniform
Average:
Off
Frequency span
0–25 kHz
Sensitivity (and Vernier):
30 dBV (Vernier on Cal.)
Display:
Channel A, Magnitude
Scale:
10 dB/DIV
Amplitude reference level:
Normal
Marker:
On
The above numerical settings appear on the spectrum analyzer display. In addition, the display shows the location of
the marker on the frequency axis (in Hz). You are able to move the marker along the frequency axis using the knob. With
the frequency span set at 25 kHz, the marker’s frequency increment setting will be 100 Hz and is shown on the screen. At
this setting answer the following questions:
1. What is the frequency resolution f ?
2. How many discrete points are displayed on the frequency (horizontal) axis?
3. What is the sampling rate (number of samples per second)?
4. What is the sampling interval t?
15. Measuring the Spectrum of a Sinusoid
Set the function generator to 1 kHz, 2 Vpeak-to-peak sinusoidal signal with VDC = 0. The mathematical expression for the
above signal is v(t) = cos(2π f0t + α), where f0 = 1,000 Hz and α depends on the time reference (trigger moment). By
pressing the Time button and holding it down observe the time display of the sinusoidal signal and answer the following
questions.
1. How many cycles of the sinusoid do you see on the screen?
2. How many “msec” of the signal is displayed?
3. How many points on the horizontal axis are displayed on the screen?
16. Magnitude of the Spectrum
The spectrum analyzer display is set on channel A, magnitude only, at 10 dB per division. A single bar appears at 1 kHz,
representing the magnitude of the sinusoidal input in dBV. The dBV value (which can also be picked up by the marker
and displayed on the screen) is with reference to an rms value of 1 V. A sinusoidal waveform with an rms value of 1
V results in 0 dBV (or simply 0 dB). Note that the magnitude display is stable and doesn’t change from one trigger to
another. Note also that the peak of the spectrum is expected to be located at 1 kHz and its value is expected to be −3 dB
(registered by the marker on the screen).
17. Doubling the Amplitude of the Sinusoid
Double the amplitude of the sinusoidal input and observe the change in the dBV of the peak of its spectrum. Compare
with what you expect from theory.

Signals and Systems
1001
18. Effect of Window Type
Change the window from uniform to Hanning, and then to ﬂat-top. Note the change in the shape of the spectrum. The
Hanning window broadens the spectral line. The ﬂat-top window makes it even broader. Along with each window, an
additional number called BW in Hz (standing for 3-dB bandwidth) appears at the lower-right corner of the screen. For
each window ﬁnd the following quantities and record them in Table 17.9:
1. Peak value, in dBV.
2. Peak location, in kHz.
3. Displayed BW, in Hz.
The two additional columns in Table 17.9 record the measured 3-dB bandwidth and the uncertainty in measured
frequency. These are described below.
19. Measuring the 3-dB Bandwidth
The frequency resolution at the current setting (25-kHz frequency span) is 100 Hz. Therefore, it may not be possible
to measure the 3-dB bandwith of the spectrum by simply moving the marker to a location 3 dB below its peak value
(at −6 dB, see “Magnitude of the Spectrum,” above). Instead, keep the marker ﬁxed at 1,000 Hz and slowly reduce
(or increase) the frequency of the signal generator away from the 1-kHz point, and watch the dBV read by the marker
reduced. The frequencies f1,2, at which the marker reads −6 dBV (at 3 dB below its peak value), are the low and high
3-dB attenuation frequencies. The 3-dB bandwidth is, therefore, BW = f2 −f1. This value is expected to be close to
the displayed BW. In this manner measure the 3-dB bandwidth of each window and enter results in Table 17.9. For an
example see Attachment B.
20. Uncertainty in Frequency
The frequency resolution in the current setting (25-kHz frequency span) is 100 Hz. The peak of the spectrum at 1 kHz
does not necessarily indicate the actual frequency of the signal. The 100-Hz resolution creates an uncertainty in frequency
measurement, or error, ϵ f . To measure the frequency uncertainty, keep the marker at 1-kHz and slowly reduce (or increase)
the frequency of the signal generator away from the 1-kHz point, and watch the dBV read by the marker remain unchanged.
The limit frequencies fa,b at which the marker still remains at the original value of −3 dBV, are the low and high end
points of the range of frequencies which are taken to be 1 kHz, and ϵ f = | fa −fb| is deﬁned as the frequency uncertainty
(absolute value) in Hz. It is expected that the uncertainty in frequency measurement be less than or equal to the displayed
frequency resolution, which at the current setting is 100 Hz. Measure the uncertainty in frequency for each window and
enter results in Table 17.9.
TABLE 17.9 Salient Features of the Spectrum of a 1-kHz Sinusoidal Wave Under Three Windows, Displayed
and Measured Bandwidths, and Uncertainty in Measured Frequency
Window
Peak Value, dBV
Peak Location, kHz
Displayed BW, Hz
Measured BW, Hz
ϵ f, Hz
Uniform
Hanning
Flat-top
21. Increasing Frequency Resolution
Change the frequency span setting of the spectrum analyzer to 0–2.5 kHz. This will reduce f to 10 Hz. All other settings
remain as in the “Prelab.” Repeat the procedures described in this section (items 13–16).

1002
CHAPTER 17
Discrete Fourier Transform
22. Measuring the Phase of a Sinusoid
Phase is a relative quantity. It depends on the time reference. The phase computed and displayed by the spectrum analyzer
depends on the starting point of the captured trace (trigger moment). Because of the free-run triggering, the phase display
does not remain stable and changes from one sweep to another. To be able to read a stable phase, we can change the
repetitive trigger from free run to level, where the captured data is the same from one sweep to the next. Alternatively,
we can use a single trigger (free run or level) and capture one set of data only. Examine the following three cases.
Repetitive Triggering at Peak Level.
Set the spectum analyzer display on channel A, phase only. Other settings
remain as in the “Prelab.” To capture a stable phase, change the trigger from free run to level. If the signal starts at the
exact moment of its positive peak, the captured segment of the data is nearly a cosine function and the phase is zero. For
this purpose, set the trigger level at the highest level of the signal such that just above that level it will not trigger. To
visually examine the time waveform captured by the spectrum analyzer, momentarily press down the Time button on its
front panel. Notice that phase is constant. Record the phase at the frequency where the spectrum is at its maximum.
Repetitive Triggering at Near-Zero Level.
Trigger at a level near zero with positive slope to capture a sine function
and visually examine the captured time function. This gives rise to a stable 90◦phase. Measure the phase at the frequency
where the spectrum is at its maximum.
A Single Trigger Under Free Run.
Change the free-run trigger from repetitive to single. The spectrum analyzer
captures the 1,024 samples (window size = 10 msec; explain the reason) in a single sweep, and then computes and
displays the spectrum. Because the trigger is set on free run, the starting point of the windowed sinusoid is random and
the phase is also a random number between ±180◦. See the “Theory” and “Prelab” sections. Record the phase at the
location of the magnitude peak, and repeat 10 times.
Discussion and Conclusions
23. Conclusions of Prelab and Measurements and Analysis
Based on the work done in the “Prelab” and “Measurements and Analysis” sections, compare the salient features of each
window along with their advantages and disadvantages. Develop criteria for choosing an appropriate window for various
spectral measurement and signal processing situations.
24. Overall Conclusions
Summarize your overall conclusions drawn from this experiment.
25. Attachment A
The Matlab ﬁle for generating Figure 17.10 is listed below.
%Spectra of four windows: Boxcar, Bartlett, Hanning, Blackman
n = 32;
w1=boxcar(n); w2=bartlett(n); w3=hanning(n); w4=blackman(n);
[w1,f]=freqz(w1/sum(w1),1,512,2);
[w2,f]=freqz(w2/sum(w2),1,512,2);
[w3,f]=freqz(w3/sum(w3),1,512,2);
[w4,f]=freqz(w4/sum(w4),1,512,2);
%The following figure overlays the 4 spectra
figure
plot(f,20*log10(abs([w1,w2,w3,w4])));
%The following figure creates 4 separate plots.
figure

Signals and Systems
1003
subplot(2,2,1);
plot(f,20*log10(abs(w1))), title('32-points rectangular window');
subplot(2,2,2);
plot(f,20*log10(abs(w2))),title('32-point bartlett window');
subplot(2,2,3);
plot(f,20*log10(abs(w3))),title('32-point hanning window');
subplot(2,2,4);
plot(f,20*log10(abs(w4))),title('32-point blackman window');
26. Attachment B. Spectral Profiles of Windows
The DFT of a discrete-time window may be obtained by sampling the spectrum of its corresponding continuous-time
window at a frequency spacing f = 1/T , where T is the window size. Figure 17.11 shows the spectral proﬁles (DFT) of
four discrete-time windows superimposed on the spectral proﬁles of their corresponding continuous-time windows. The
left column shows four windows and the right column shows their spectra. From the top: uniform (rectangular), Hanning,
Blackman, and Bartlett (triangular). All windows are 10 msec wide. Under the DFT operation, the 10-msec data produces
a sampling interval f = 1/(10 msec) = 100 Hz in the frequency domain, also shown on the spectra. Note that in the
case of the uniform window the 100-Hz sampling interval results in a single spectral line at the center frequency ( f = 0
in this ﬁgure). Table 17.10 gives measured spectral proﬁles of the windows used by the spectrum analyzer.
TABLE 17.10 Measured Spectral Profiles, in dBV, of the Windows Used by the Spectrum Analyzer Operating
on a Sinusoid (Vpeak-to-peak = 2 V, f = 1 kHz). The star ⋆indicates off-scale values.
Frequency (Hz) ⇒
500
600
700
800
900
1,000
1,100
1,200
1,300
1,400
1,500
Uniform window
⋆
−3.1
⋆
Hanning window
⋆
−9.1
−3.1
−9.1
⋆
Flat-top window
⋆
−37.2
−17.0
−7.1
−3.5
−3
−3.5
−7.1
−17
−37.2
⋆

1004
CHAPTER 17
Discrete Fourier Transform
(a) Rectangular
1
0
4
1
0.01
0.0001
1e-006
–6
–8
–6
–4
–2
0
2
4
6
8
–5
–4
–3
–2
–1
0
1
2
3
4
5
6
Time (msec)
Frequency (units of 100 Hz)
(d) Bartlett
(b) Hanning
(c) Blackman
1
0
1
0.0001
2.56e-006
1
0
1
0.0001
2.56e-006
1
Time (msec)
Frequency (units of 100 Hz)
0
1
0.001
1e-006
–8
–6
–4
–2
0
2
4
6
8
–8
–6
–4
–2
0
2
4
6
8
–8
–6
–4
–2
0
2
4
6
8
–6
–5
–4
–3
–2
–1
0
1
2
3
4
5
6
–6
–5
–4
–3
–2
–1
0
1
2
3
4
5
6
–6
–5
–4
–3
–2
–1
0
1
2
3
4
5
6
FIGURE 17.11 Spectral proﬁles (DFT) of four discrete-time windows superimposed on the spectral proﬁles (DTFT) of
their corresponding continuous-time windows. Sampling DTFT at intervals f results in DFT. In this ﬁgure the windows
are 10 msec wide, resulting in a sampling interval f = 1/(10 msec) = 100 Hz in the frequency domain. Note that
in the case of the uniform window the 100-Hz sampling interval leaves only a single spectral line intact. The windows
are (a) rectangular, (b) Hanning, (c) Blackman, (d) Bartlett. The numbers on the ordinates in the right-hand column are
normalized magnitudes of the Fourier transforms of corresponding windows on the left.

Chapter18
System Function, the
Frequency Response,
and Digital Filters
Contents
Introduction and Summary
1005
18.1
The System Function H(z)
1006
18.2
Poles and Zeros
1011
18.3
The Frequency Response H(ω)
1015
18.4
Vectorial Interpretation of H(z) and H(ω)
1025
18.5
Transforming Continuous Time to Discrete Time
1029
18.6
Digital Filters
1036
18.7
Simple Filters
1039
18.8
Filter Design
1044
18.9
Filter Design by Pole-Zero Placement
1046
18.10
FIR Filter Design
1047
18.11
IIR Filter Design
1052
18.12
Filter Structures
1055
18.13
Problems
1060
18.14
Project 1: FIR Filter, Design by Windowing
1081
18.15
Project 2: Discrete-Time Modeling and Control of a Dynamic System
1084
18.16
Project 3: Modeling a Random Trace Generator
1090
Introduction and Summary
LTI systems may be analyzed in both time and frequency domains. In the time do-
main, the output is found by convolution of the input with the unit-sample response,
y(n) = x(n) ⋆h(n), or by solving the input-output difference equation. In the frequency
1005

1006
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
domain, one uses the z-transform to convert the convolution y(n) = x(n) ⋆h(n) into a
multiplication of transforms Y(z) = X(z)H(z). Both approaches are closely related and
provide the same result. In this chapter we expand on the properties and capabilities of
H(z) and the parallels between the time and frequency-domain solutions. The chapter
starts with a new look at the system function from a different, but familiar, perspective.
It discusses the effects of poles and zeros in forming the system function, inﬂuencing
its characteristics, and shaping the system’s time response. The chapter then presents
the frequency response, its relation to the system function, and the DTFT of the unit-
sample response. The frequency response is the characteristic of an LTI system most
closely encountered in practical and experimental applications. The chapter attends to
this characteristic and its relationship to the continuous-time domain. In that respect,
the discussion forms a basis for digital ﬁltering and design which follows the discussion
on the frequency response and is illustrated by several solved problems at the end of
the chapter. As another application of the system function, system stability and inverse
systems are briefy discussed. Three projects at the end of the chapter provide application
examples.
18.1
The System Function
H( z)
The System Function H (z) Is the Scale Factor for z n
We have seen (Chapter 12) that the response of an LTI system to the input zn
0 is Hzn
0,
where z0 is a constant and the scale factor H is, in general, a function of z0:
zn
0
⇒
H(z0)zn
0
H(z) is called the system function. It may be found from the unit-sample response,
from an input-output pair, or from the input-output difference equation. These will be
described below.
H (z) Is the z-Transform of h (n)
The system function is the z-transform of the unit-sample response. (See Chapter 15.)
Example
18.1
The unit-sample response of an LTI system is
h(n) =

1,
0 ≤n < M
0,
elsewhere
Find its system function.
Solution
H(z) =
M−1

n=0
z−n = 1 −z−M
1 −z−1

Signals and Systems
1007
Example
18.2
Find the system function of the LTI system with the unit-sample response h(n) =
an cos(ωn)u(n).
Solution
From the table of z-transform pairs in Chapter 15 (a portion of which is reproduced
below), we ﬁnd
H(z) =
1 −a(cos ω)z−1
1 −2a(cos ω)z−1 + a2z−2
A Minitable of z-Transform Pairs
The following minitable of z-transform pairs will be used in this chapter.
x(n)
⇐⇒
X(z)
ROC
u(n)
⇐⇒
1
1 −z−1
|z| > 1
anu(n)
⇐⇒
1
1 −az−1
|z| > |a|
an cos(ωn)u(n)
⇐⇒
1 −a(cos ω)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > |a|
an sin(ωn)u(n)
⇐⇒
a(sin ω)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > |a|
an cos(ωn + θ)u(n)
⇐⇒
cos θ −a cos(ω −θ)z−1
1 −2a(cos ω)z−1 + a2z−2
|z| > |a|
H (z) Is the Ratio Y (z)/X (z)
The system function is also the ratio of the z-transform of the output to the z-transform
of the input. See Chapter 15.
Example
18.3
Find the system function of the LTI system with the given input-output pair.
x(n) = {1
↑, 1, 1} ⇒y(n) = {1
↑, 3, 4, 3, 1}
Solution
In the z-domain the input-output pair is
X(z) = 1 + z−1 + z−2 ⇒Y(z) = 1 + 3z−1 + 4z−2 + 3z−3 + z−4
By long division we get
H(z) = Y(z)
X(z)
= 1 + 3z−1 + 4z−2 + 3z−3 + z−4
1 + z−1 + z−2
= 1 + 2z−1 + z−2

1008
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Example
18.4
Find the system function of the LTI system with the unit-step response
y(n) =

1.1908 −0.67864 × 0.5n cos(πn/4 + 73.67◦)

u(n)
Solution
Using the minitable of z-transform pairs given above we ﬁnd the z-transforms of the
unit-step input, the unit-step response, and their ratio to be
X(z) =
1
1 −z−1
Y(z) = 1.1908
1 −z−1 −0.67864cos(73.67◦) −0.5 cos(π/4 −73.67◦)z−1
1 −cos(π/4)z−1 + 0.25z−2
= 1.1908
1 −z−1 −
0.1908 −0.2977z−1
1 −0.7071z−1 + 0.25z−2
=
1 −0.3535z−1
(1 −z−1)(1 −0.7071z−1 + 0.25z−2)
H(z) = Y(z)
X(z) =
1 −0.3535z−1
1 −0.7071z−1 + 0.25z−2
H (z) Is Found from the Difference Equation and Vice Versa
We have seen (Chapter 14) that the solution of the LTI difference equation
y(n) + a1y(n −1) · · · + aN y(n −N) = zn
0
is Y zn
0, where
Y =
1
1 + a1z−1
0 · · · + aNz−N
0
In the above, the variable n represents the discrete time and constitutes the variable of
the difference equation, z0 is a constant number and zn
0 is expressing powers of z0 in
terms of the variable n. Extending the above observation, we conclude that the response
of the difference equation
y(n) + a1y(n −1) · · · + aN y(n −N) = b0x(n) + b1x(n −1) · · · + bN x(n −M)
to x(n) = X0zn is y(n) = Y0zn. By substituting the above input-output pair in the
equation we ﬁnd Y0 = H(z)X0, where H(z) is the system function. For systems described
by an LTI difference equation such as the equation shown above, H(z) is the ratio of
two polynomials in z:
H(z) = b0 + b1z−1 + b2z−2 · · · + bMz−M
1 + a1z−1 + a2z−2 · · · + aNz−N
H(z) is easily obtained from the difference equation by employing the notation z−1 for

Signals and Systems
1009
a unit delay. The difference equation is then written as
DN[y(n)] = DM[x(n)]
where DN and DM are linear delay operators acting on y(n) and x(n), respectively. They
are constructed from sums of z−k, where z−k represents a delay of k units.
DM = b0 + b1z−1 + b2z−2 + · · · + bMz−M
DN = 1 + a1z−1 + a2z−2 + · · · + aNz−N
In light of the above, we can conversely construct the difference equation and its block
diagram from a given H(z), which is the ratio of two polynomials in z−1.
Example
18.5
Find the input-output difference equation of the LTI system with the system function
H(z) = Y(z)
X(z) = 1 + z−1 + z−2
Solution
Y(z) = (1 + z−1 + z−2)X(z)
= X(z) + z−1X(z) + z−2X(z)
y(n) = x(n) + x(n −1) + x(n −2)
Example
18.6
Find the input-output difference equation of an LTI system with the system function
H(z) = Y(z)
X(z) =
1 −0.3535z−1
1 −0.7071z−1 + 0.25z−2
Solution
(1 −0.7071z−1 + 0.25z−2)Y(z) = (1 −0.3535z−1)X(z)
y(n) −0.7071y(n −1) + 0.25y(n −2) = x(n) −0.3535x(n −1)
The Time Response May Be Found from H (z)
The response of an LTI system is obtained either through convolution of the input with
the unit-sample response or solution of the input-output difference equation, both of
which may be obtained from H(z). It is, therefore, expected that the system function
contains all the information needed to ﬁnd the response to a given input. In this section we
will see how each component of the time response (natural frequencies, homogeneous
and particular responses, boundary values, and total time response) may be derived
from H(z), often without resorting to the formal tools and systematic methods [i.e.,
without ﬁnding h(n) to do convolution, or solving the difference equation, or using the
z-transform formulation].

1010
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
We start with the observation that the system function provides the particular re-
sponse to an input expressed by a linear combination of power series (with constant
weighting factors). An example is the AC steady-state response. We then additionally
note that the denominator of the system function contains the characteristic equation
of the system, which provides the natural frequencies and determines the homogeneous
response. In fact, the complete response may readily be written from the system function
if the input is given as a power series and the initial conditions are known. This property
makes H(z) a powerful tool in discrete-time LTI system analysis. In the following three
examples we ﬁnd responses of the ﬁrst-order LTI system H(z) = (1 + z−1)/(1 −z−1)
to various inputs using the system function.
Example
18.7
Given H(z) = (1+z−1)/(1−z−1), ﬁnd the system’s response to x(n) = cos(πn/2),
−∞< n < ∞.
Solution
The response consists of the particular solution only, which, in this case, is the sinu-
soidal steady-state response. To ﬁnd it, we note that the frequency of the sinusoidal
input is ω = π/2, which corresponds to z = j (because z = e jω = e jπ/2 = j). The
value of H(z) at z = j is
H(z)|z= j = 1 + z−1
1 −z−1

z= j = 1 −j
1 + j = −j
The input and the response may be written as
x(n) = cos(πn/2)
= RE{X0e jωn}, X0 = 1, ω = π/2
= RE{X0zn}, z = e jω = e jπ/2 = j
y(n) = RE{H(z)X0zn}

z= j = RE{ j × 1 × e jπn/2} = cos[π(n −1)/2] = sin(πn/2)
Example
18.8
Given H(z) = (1+z−1)/(1−z−1),ﬁndthesystem’sresponseto x(n) = cos(πn/2)u(n).
Solution
The particular solution was found in Example 18.7 to be yp(n) = sin(πn/2). We
need to add to it the homogeneous solution (if any). The system has a single pole at
p = 1, which gives rise to the homogeneous solution yh(n) = C(1)n = C. The total
solution is y(n) = yh(n) + yp(n) = C + sin(πn/2). To ﬁnd the constant C we need
boundary value y(0), which is obtained from the difference equation:
y(n) = y(n −1) + x(n) + x(n −1)
y(0) = y(−1) + x(0) + x(−1) = 0 + 1 + 0 = 1
y(n) = C + sin(πn/2)

Signals and Systems
1011
y(0) = 1 = C
y(n) = 1 + sin(πn/2)
Therefore, y(n) = [1 + sin(πn/2)]u(n).
Example
18.9
Given H(z) = (1+z−1)/(1−z−1) and the input x(n) = αd(n+1)+cos(πn/2)u(n),
ﬁnd the constant α such that for n ≥0 the system’s response contains only the
sinusoidal steady state.
Solution
In order to have no homogeneous solution to the input cos(πn/2)u(n), we need to cre-
ate the appropriate initial condition(s) which, following the solution of Example 18.7,
would be y(0) = 0. But, from the difference equation, we have
x(−1) = α, x(0) = 1, y(−1) = α
y(0) = y(−1) + x(0) + x(−1) = α + 1 + α = 2α + 1
By setting 2α + 1 = 0 we get α = −0.5. In other words, the input sample αd(n + 1)
arriving before the sinusoid is going to produce a zero initial condition at n = 0 if
α = −0.5.
18.2
Poles and Zeros
In this book we are interested in LTI systems with H(z) = A(z)/B(z), where A(z) and
B(z) are polynomials in z. The roots of the numerator polynomial are called the zeros
of the system. Let z0 be a zero of the system. At z0 we have H(z0) = 0 and the input
x(n) = zn
0 will result in y(n) = 0 for all n.
Similarly, the roots of the denominator polynomial are called the poles of the system.
Let p0 be a pole of the system. At p0 we have H(p0) = ∞and the input x(n) = pn
0 will
result in y(n) = ∞for all n.
Example
18.10
Find the poles and zeros of the system described by H(z) = 1 + z−1 + z−2.
Solution
The system function is H(z) = (z2 + z + 1)/z2. The zeros and poles of the system
are the roots of the numerator and denominator, respectively.
zeros:
z2 + z + 1 = 0
⇒z1,2 = −1
2 ± j
√
3
2 = e± j120◦
poles:
z2 = 0
⇒
p1,2 = 0

1012
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Example
18.11
Find the poles and zeros of the system described by
H(z) =
1 −0.3535z−1
1 −(
√
2/2)z−1 + 0.25z−2 =
z(z −0.3535)
z2 −(
√
2/2)z + 0.25
Solution
zeros of the system are roots of z(z −0.3535) = 0
⇒z1 = 0.3535, z2 = 0
poles of the system are roots of z2 −(
√
2/2)z + 0.25 = 0
⇒
p1,2 =
√
2
4 ± j
√
2
4
= 1
2e± j45◦
Example
18.12
An LTI system has one pair of poles at p1,2 = ρe± jθ, two zeros at z1,2 = ±1, and
H(z)

z=e jθ = 1. Find the system function.
Solution
H(z) = k
(1 −z−1)(1 + z−1)
(1 −ρe jθz−1)(1 −ρe−jθz−1)
= k
1 −z−2
1 −2ρ(cos θ)z−1 + ρ2z−2
To ﬁnd k we note
H(e jθ) = k
(1 −e−jθ)(1 + e−jθ)
(1 −ρe jθe−jθ)(1 −ρe−jθe−jθ)
= k
1 −e−j2θ
(1 −ρ)(1 −ρe−j2θ) = 1
from which
k = (1 −ρ)1 −ρe−j2θ
1 −e−j2θ
Contribution of Poles and Zeros to the System Function
We are interested in systems described by the ratio of two polynomials in z:
H(z) = b0 + b1z−1 + b2z−2 · · · + bMz−M
1 + a1z−1 + a2z−2 · · · + aNz−N
For such systems a zero at z0 contributes (z −z0) = z(1 −z0z−1) to the numerator of
the system function. This may be easily veriﬁed by setting z = z0 in the expression for
H(z). Similarly, a pole at p0 contributes (z −p0) = z(1 −p0z−1) to the denominator. It
is often desirable to express the system function in terms of z−1 rather than z. A system

Signals and Systems
1013
with M zeros at zk, k = 1, 2, · · · M, and N poles at pk, k = 1, 2, · · · N, is then
described by
H(z) = H0z(M−N) (1 −z1z−1)(1 −z2z−1) · · · (1 −zMz−1)
(1 −p1z−1)(1 −p2z−1) · · · (1 −pNz−1)
When N > M, the system has N −M poles at the origin.
When N < M, the system has M −N zeros at the origin.
When N = M, the system has no poles or zeros at the origin.
In the above expression, H0 is a constant gain. The signiﬁcance of poles and zeros at the
origin, or their diminished role, will be seen in section 18.4.
Poles of FIR Systems Are at the Origin
By deﬁnition, the unit-sample response of an FIR system has a ﬁnite number of samples.
The z-transform of h(n), therefore, is a polynomial in z−1. The poles are all at z = 0.
If H(z) of an FIR system is presented as the ratio of two polynomials in z−1 with
some apparent nonzero poles, they will be canceled by the zeros of the numerator. See
Example 18.13.
Example
18.13
The unit-sample response of an LTI system is h(n) = 2n[u(n) −u(n −4)]. Find the
system function and its zeros. Determine if it has any nonzero poles.
Solution
H(z) =
1
1 −2z−1 −
24z−4
1 −2z−1 = 1 −24z−4
1 −2z−1
Roots of the numerator are obtained from 1 −24z−4 = 0. They are z = 2, j2, −2,
and −j2. The denominator has a single root at z = 2, which is canceled by a zero,
leaving the system with three zeros at j2, −2, and −j2.
Remark
The zeros of the above system may also be found directly from
h(n) = {1
↑, 2, 4, 8}
H(z) = 1 + (2z)−1 + (2z)−2 + (2z)−3 = 0
To ﬁnd the roots of the above equation, we employ the auxiliary variable x = (2z)−1
and obtain x3 + x2 + x + 1 = 0, the roots of which are x = −1 and ± j. The zeros
of the system are, therefore, at z = −2 and ± j2. The system has no poles.

1014
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Example
18.14
The unit-sample response of an LTI system is h(n) = (0.9)n[u(n)−u(n −10)]. Find
the system function and its zeros. Determine if it has any poles.
Solution
H(z) =
1
1 −0.9z−1 −(0.9)10z−10
1 −0.9z−1 = 1 −(0.9)10z−10
1 −0.9z−1
Roots of the numerator are obtained from the equation
1 −0.910z−10 = 0 or z10 = (0.9)10
which gives z = 0.9e± j2kπ/10, k = 0, 1, 2, · · · , 5. These are uniformly distributed
on the circle with radius 0.9, starting at z = 0.9 and spaced every 36◦. The zero at
z = 0.9 (corresponding to k = 0) is canceled by the pole at that location, leaving the
system with 9 zeros at 0.9e± j36◦, 0.9e± j72◦, 0.9e± j108◦, 0.9e± j144◦, and −0.9.
Explanation
The roots of the numerator polynomial are obtained from
1 −(0.9)10z−10 = 0
1 −(0.9z−1)10 = 0
(0.9z−1)10 = 1 = e j2kπ
0.9z−1 = e j2kπ/10
z = 0.9e−j2kπ/10, k = 0, 1, 2, · · · , 9
System Stability and Pole Location
If bounded inputs to a linear system produce bounded outputs, the system is said to be
BIBO-stable. The natural (zero-input) response of a BIBO system diminishes with time.
An LTI discrete-time system is BIBO-stable if its poles (natural frequencies) are inside
the unit circle in the complex plane. A related property is that in a BIBO system,

n
|h(n)| < M, where M is any number (as large as one wishes it to be).
Inverse Causal Systems H(z) and 1/H(z)
Let a signal x(n) pass through a system with the unit-sample response h(n), producing
the output y(n) = x(n) ⋆h(n). Passing y(n) through a second system with the unit-
sample response h(n) such that h(n) ⋆h(n) = d(n), will reverse the effect of the ﬁrst
system resulting in the output x(n):
y(n) ⋆h(n) = [x(n) ⋆h(n)] ⋆h(n) = x(n) ⋆[h(n) ⋆h(n)] = x(n) ⋆d(n) = x(n)

Signals and Systems
1015
See Figure 18.1. The two systems are said to be inverses of each other. In a sense,
the inverse system performs a deconvolution of x(n) with h(n), which was analyzed in
Chapter 13, sections 13.8 and 13.9.
x(n)
y(n)
h(n)
h(n)
x(n)
y(n)
h(n)
h(n)
x(n)
y(n)
h(n) * h(n) 
FIGURE 18.1 Two systems h(n) and h(n) are inverses of each other if h(n) ⋆h(n) = d(n).
In that case, y(n) = x(n). One system reverses the effect of the other. For causal systems this
translates into system functions H(z) and 1/H(z).
If the two systems are causal, the system functions of h(n) and h(n) will be H(z)
and 1/H(z), respectively.
H(z)×
1
H(z) = 1, which corresponds to the z-transform of unit-sample responsed(n).
Example
18.15
In Chapter 13, section 13.9 we considered the LTI system h(n) = 0.5nu(n). By
applying deconvolution we found its inverse to be h(n) = {1
↑, −0.5}. In this example
we apply the system function to obtain the same result.
h(n) = 0.5nu(n)
⇒
H(z) =
1
1−0.5z−1
⇓
⇓
h(n) = {1
↑, −0.5}
⇐ 1/H(z) = 1 −0.5z−1
Note that
h(n) ⋆h(n) = 0.5nu(n) ⋆{1
↑, −0.5} = 0.5nu(n) −0.5nu(n −1) =
1, n = 0
0, elsewhere
18.3
The Frequency Response H(ω)
We have seen (Chapter 14) that the response of an LTI system, which is described
by a linear differential equation with real constant coefﬁcients, to a sinusoidal input
is a sinusoid. The frequency response determines the relative changes in magnitude
and phase of a sinusoid when it goes through an LTI system. It is expressed by its
magnitude and phase, both of which are functions of the frequency ω. The magnitude

1016
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
and phase of the frequency response are combined as a complex function and shown by
H(ω) = |H(ω)|̸ θ. Therefore,
cos ωn
⇒
|H(ω)| cos(ωn + θ)
We often combine the magnitude and phase of a sinusoidal function into a complex
number and call it the complex amplitude or phasor. The sinusoidal input x(n) and
output y(n) are then represented by their complex amplitudes, or phasors, X and Y,
respectively. The frequency response then may be deﬁned as the ratio of the output
phasor to the input phasor.
H(ω) = Y
X = |H(ω)|e jθ(ω)
The frequency response of an LTI system may be measured experimentally without
knowledge of its internal structure or its mathematical model. It may also be obtained
from the system function, the unit-sample response, or the input-output difference equa-
tion, as will be seen in this chapter.
Frequency Response of a Uniform Window
The FIR system with an h(n) made of a uniform window of M samples of size 1/M
each is frequently encountered in the analysis of discrete-time systems. The system
takes an average of M input samples within the window and assigns it as the output, then
slides the window one sample and repeats the operation. The operation is called moving
window averaging. In this section we review and summarize its properties in the z- and
ω-domains. For simplicity, we set aside the division by M and consider the LTI system
with the uniform window containing M unit samples to be the unit-sample response.
For brevity, we call the system a uniform or rectangular window. It is frequently applied
to signals when processing them in ﬁnite segments. The unit-sample response, output,
system function, and frequency response of the uniform window of size M are listed
below.
h(n) =
M−1

k=0
d(n −k)
y(n) =
M−1

k=0
x(n −k)
H(z) =
M−1

n=0
z−n = 1 + z−1 + z−2 + z−3 + · · · + z−(M−1) = 1 −z−M
1 −z−1
H(ω) =
M−1

n=0
e−jnω = 1 + e−jω + e−j2ω + e−j3ω + · · · + e−j(M−1)ω = 1 −e−j Mω
1 −e−jω
= sin(Mω/2)
sin(ω/2) e−jω (M−1)
2
= Hr(ω)e jθω, whereHr(ω) is a real function of ω.
The uniform window has no poles. (Poles at origin are not considered.) Its zeros are
equally spaced around the circumference of the unit circle starting at z = 1. The Hrω

Signals and Systems
1017
component of the frequency response is a real function of ω, made of alternating positive
andnegativelobes,whichdiminishinmagnitudeasω increases.Thezero-crossingsoccur
at
ω = 2kπ
M
As expected, H(0) = M. Plots of H(ω) for windows consisting of 2, 3, and 20 unit
samples are shown in Figure 18.2(a), (b), and (c), respectively. In Examples 18.16 and
18.17 we derive H(z) and H(ω) for narrow windows made of three and four unit samples,
respectively. An example of a wide window (20 samples wide) is given in Example 18.18.
Example
18.16
Find and plot the frequency response of the uniform window h(n) = {1
↑, 1, 1}.
Solution
H(z) = 1 + z−1 + z−2
H(ω) = 1 + e−jω + e−j2ω = e−jω 
e jω + 1 + e−jω
= (1 + 2 cos ω)e−jω
See Figure 18.2(b). Note that there are zero-crossings at ω = ±2π/3. In the above
expressions, H(z) and H(ω) are written as sums because a small window size results
in a small number of terms. They may equally be written in fractional form:
H(z) = 1 −z−3
1 −z−1 and H(ω) = sin(3ω/2)
sin(ω/2) e−jω
For large windows the fractional form is recommended. The fractional form also
explicitly exhibits the zeros of the system.
Example
18.17
Find the frequency response of the uniform window h(n) = {1
↑, 1, 1, 1}.
Solution
H(z) = 1 + z−1 + z−2 + z−3
H(ω) = 1 + e−jω + e−j2ω + e−j3ω
= e−j3ω/2 
e3 jω/2 + e jω/2 + e−jω/2 + e−3 jω/2
= 2 [cos(ω/2) + cos(3ω/2)] e−j3ω/2
The zero-crossings occur at ω = ±π/2, ± π. In fractional form,
H(z) = 1 −z−4
1 −z−1 and H(ω) = sin(2ω)
sin(ω/2)e−j3ω/2

1018
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
–8
–10
–6
–4
–2
0
1
0
2
4
6
8
10
12
–3 –2.5 –2 –1.5
–0.5
–1
0
0.5
1
1.5
2
2.5
3
Discrete time (n)
h(n)
0
0.5
1
1.5
2
2.5
–0.5
Frequency ω (rad/s)
(a)
Hr(ω)
(b)
(c)
–8
–10
–6
–4
–2
0
1
0
2
4
6
8
10
12
–3 –2.5 –2 –1.5
–0.5
–1
0
0.5
1
1.5
2
2.5
3
Discrete time (n)
–1
0
1
2
3
4
–2
Frequency ω (rad/s)
–2
0
1
0
2
4
6
8
10
12
14
16
18
20
–3 –2.5 –2 –1.5
–0.5
–1
0
0.5
1
1.5
2
2.5
3
Discrete time (n)
0
5
10
15
20
25
–5
Frequency ω (rad/s)
FIGURE 18.2 The unit-sample response h(n) and the frequency response H(ω) of a uniform window that starts at
n = 0 and consists of M unit samples are
h(n) =

1,
0 ≤n < M
0,
elsewhere,
H(ω) = 1 −e−j Mω
1 −e−jω = sin(Mω/2)
sin(ω/2) e−jω (M−1)
2
= Hr(ω)e jθ(ω)
Hr(ω) is a real function of ω. It can assume positive or negative values with alternating positive and negative lobes that
diminish as ω increases. Its zero-crossings are at ω = 2kπ/M. This ﬁgure shows three h(n) (left column) and their Hr(ω)
(right column) for a 2-sample window (a), a 3-sample window (b), and a 20-sample window (c). The frequency axis is
−π < ω < π in rad/s.

Signals and Systems
1019
Example
18.18
Find the frequency response of the uniform window containing 20 unit samples,
h(n) = u(n) −u(n −20).
Solution
H(z) = 1 −z−20
1 −z−1
and H(ω) = sin(10ω)
sin(ω/2)e−j10ω
The zero-crossings of H(ω) occur at ω = ±kπ/10, k being a nonzero integer.
Observation
Zero-crossings of the frequency response of a uniform window of size M occur at
±2kπ/M), k ̸= 0. The main lobe of the frequency response is 4π/M rad/s wide. A
wide window has a narrower lobe and vice versa. See Figure 18.2.
H (ω) May Be Obtained from H (z )
So far, we have developed H(z) and H(ω) independently from each other. Note that
we have used the same notation, H, for both the frequency response and the system
function. This is no accident or oversight. As one can see from their deﬁnitions, the
frequency response and the system function of an LTI system are related to each other.
The frequency response H(ω) of a discrete-time system is a special case of H(z) and,
therefore, may be obtained from it by setting z = e jω.
H(ω) = H(z)

z=e jω
To derive the above result, observe that
1.
H(z) is the complex scale factor for zn inputs.
2.
cos ωn = RE{e jωn}
3.
The real part of the response to an input is the response to the real part of that
input: RE{x(n)} ⇒RE{y(n)}.
These observations are summarized below:
zn
⇒
H(z)zn
e jωn
⇒
H(ω)e jωn, where H(ω) = H(z)|z=e jω
cos(ωn) = RE{e jωn}
⇒
RE{H(ω)e jωn} = |H(ω)| cos(ωn + θ)
H(z) is, therefore, a convenient representation of H(ω). They both represent the system
in the frequency domain.

1020
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Example
18.19
Find the frequency response of an FIR system with the system function H(z) =
1 + z−1 + z−2 + z−3. Find the response of the system to the input x(n) = cos(ωn).
At what frequency is the above response zero?
Solution
H(ω) = 1 + e−jω + e−j2ω + e−j3ω
= e−j3ω/2 
e j3ω/2 + e jω/2 + e−jω/2 + e−j3ω/2
= 2e−j3ω/2 [cos(3ω/2) + cos(ω/2)]
= 4e−j3ω/2 cos(ω) cos(ω/2) = Hr(ω)e jθ(ω)
Hr(ω) = 4 cos(ω) cos(ω/2) and θ(ω) = −3ω/2
The output is
y(n) = Hr(ω) cos(ωn +θ) = 4 cos(ω) cos(ω/2) cos(ωn −3ω/2)
The system blocks sinusoids at ω = π/2 and π, where Hr(ω) = 0.
Example
18.20
Find the frequency response of an IIR system with two poles at 0.9e± j45◦and a double
zero at the origin. See Figure 18.3(a). Find the square of its magnitude, |H(ω)|2, at
ω = 0 (DC), ω = π/4 (closest to the poles), and ω = π (farthest away from the
poles). Determine the 3-dB bandwidth. Sketch |H(ω)|2 versus ω.
Solution
Let the poles be at ρe± jθ. First ﬁnd H(z), then set z = e jω to ﬁnd H(ω). Assuming
a unity gain factor, we have
H(z) =
1
(1 −ρe jθz−1)(1 −ρe−jθz−1) =
1
1 −2ρ cos θz−1 + ρ2z−2
H(ω) =
1
1 −2ρ cos θ(cos ω −j sin ω) + ρ2(cos 2ω −j sin 2ω)
=
1
(1 −2ρ cos θ cos ω + ρ2 cos 2ω) + j(2ρ cos θ sin ω −ρ2 sin 2ω)
|H(ω)|2 =
1
(1 −2ρ cos θ cos ω + ρ2 cos 2ω)2 + (2ρ cos θ sin ω −ρ2 sin 2ω)2
=
1
(1 + 4ρ2 cos2 θ + ρ4) −4ρ(1 + ρ2) cos θ cos ω + 2ρ2 cos(2ω)

Signals and Systems
1021
With ρ = 0.9 and θ = 45◦:
|H(ω)|2 =
1
3.2761 −4.6075 cos ω + 1.62 cos 2ω
|H(0)|2 =
1
3.2761 −4.6075 + 1.62 = 3.465
|H(π/4)|2 =
1
3.2761 −4.6075(
√
2/2) + 0
= 55.2318
|H(π)|2 =
1
3.2761 + 4.6075 + 1.62 = 0.1052
The maximum of |H| occurs at ω = 45◦. The 3-dB bandwidth is ω = ωh −ωℓ,
where ωh and ωℓare the upper and lower half-power frequencies, respectively.
|H(ωh)|2 = |H(ωℓ)|2 = 1
2|HMax|2 = 55.2318/2 = 27.6159
ωh and ωℓare then the roots of the equation
1
3.2761 −4.6075 cos ω + 1.62 cos(2ω) = 27.6159
cos ω −0.3516 cos(2ω) = 0.7032
Because the poles are close to the unit circle, the behavior of H(ω) near a pole (i.e.,
in the vicinity of ω = 45◦) is governed mainly by that pole. In that neighborhood,
variations in H(ω) can be approximated by variations in its distance from the pole,
(1 −p1z−1), as seen in Figure 18.3(b). For details of this approximate analysis see
section 18.4 in this chapter, “Vectorial Interpretation of H(z) and H(ω).” Therefore,
an approximate solution of the above equation will give us ωℓ, h ≈π/4±0.1 rad/s =
45◦± 5.73◦= 39.27◦and 50.73◦, where 0.1 = (1 −0.9) is the shortest distance
between a pole and the unit circle. The 3-dB bandwidth is ω ≈0.2 rad/s = 50.73◦−
39.27◦= 11.46◦. More exact values are:
ωl = 38.2162◦, ωh = 50.4865◦, ω = ωh −ωl = 12.2703◦
H (ω) Is 2π-Periodic
The frequency response is a function of e jω as shown by
H(ω) = H(z)

z=e jω
But e jω = e j(ω+2π), and, therefore, H(ω) = H(ω+2π). Consequently, H(ω) is periodic
with period 2π. In our analysis we consider H(ω) for −π < ω < π (which covers one
period).

1022
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
ωl
ωh
ωh = 50.73°
ω0 = 45°
ωl = 29.27°
ω
55.2
27.6
3.4
0
π
4
π
2 
π
4
3
π
|H(ω)|2
(c)
Unit circle
Re[z]
Im[z]
P1
P2
P1 = 0.9∠45°
P2 = 0.9∠–45°
P2 = P1*
ω = 45°
–ω = 45°
ωh
P1
ω0
ωl
0.1 2
0.1
(a)
(b)
FIGURE 18.3 The system described by H(z) = 1/(1 −0.9
√
2z−1 + 0.81z−2) has two poles
at 0.9e± j45◦and a double zero at the origin, as seen in (a). |H(ω)|2 is plotted versus ω in (c).
The maximum of |H| occurs at ω = 45◦, nearest the pole. The 3-dB bandwidth is approximately
ω = 2(1 −0.9) = 0.2 rad/s = 11.46◦, where (1 −0.9) is the shortest distance between each
pole and the unit circle. Because the poles are close to the unit circle, the 3-dB bandwidth is
almost evenly divided between the two sidebands, resulting in the lower and higher half-power
frequencies ωℓ= 45 −11.46/2 = 39.27◦and ωh = 45 + 11.46/2 = 50.73◦. See (b). The double
zero at the origin has no effect on |H(ω)|2. For details see Example 18.20.

Signals and Systems
1023
Example
18.21
Examinetheperiodicityofthefrequencyresponse H(ω) = 4e−j3ω/2 cos(ω) cos(ω/2)
obtained in Example 18.19.
Solution
H(ω + 2π) = 4e−j3(ω+2π)/2 cos(ω + 2π) cos[(ω + 2π)/2]
= 4e−j3ω/2e−j3π cos(ω + 2π) cos(ω/2 + π)
= −4e−j3ω/2 cos(ω + 2π) cos(ω/2 + π)
= 4e−j3ω/2 cos(ω) cos(ω/2) = H(ω)
Finding |H (ω)|2 from H (z)H (z−1)
The square of the magnitude of the frequency response is |H(ω)|2 = H(ω)H ∗(ω),
where H ∗(ω) is the complex conjugate of H(ω). However,
H(ω) = H(z)|z=e jω
H ∗(ω) = H(z)|z=e−jω = H(z−1)|z=e jω
|H(ω)|2 = H(ω)H ∗(ω) = H(z)H(z−1)|z=e jω
The above equation provides an easy way of obtaining the magnitude of the frequency
response from the system function.
Example
18.22
A zero (or pole) at z = a contributes (1 −az−1) to the numerator (or denominator, if
a pole) of H(z). The contribution to the square of the magnitude of H(ω) is
|H|2 = (1 −az−1)(1 −az)|z=e jω
= 1 + a2 −a(z + z−1)|z=e jω
= 1 + a2 −2a cos ω
Example
18.23
A pair of conjugate zeros (or poles) at ρe± jθ contribute the following to H(z):
(1 −ρe jθz−1)(1 −ρe−jθz−1) = 1 −2ρ cos θz−1 + ρ2z−2

1024
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Their contribution to |H(ω)|2 is
(1 −2ρ cos θz−1 + ρ2z−2)(1 −2ρ cos θz + ρ2z2)|z=e jω =
1 + 4ρ2 cos2 θ + ρ4 −2ρ(1 + ρ2) cos θ(z + z−1) + ρ2(z2 + z−2)|z=e jω =
(1 + 4ρ2 cos2 θ + ρ4) −4ρ(1 + ρ2) cos θ cos ω + 2ρ2 cos(2ω)
This is in agreement with the result derived directly in Example 18.20, where we can
see the contributions of the conjugate zeros and poles.
Trajectory of ω in the z-Plane
The frequency response is obtained by H(ω) = H(z)|z=e jω. In this substitution, the locus
of z = e jω is the unit circle in the z-plane because |z| = |e jω| = 1. The point representing
z = 1 corresponds to ω = 0 and z = −1 corresponds to ω = ±π. Conversely, a point
at ω = 0 on the unit circle is represented by z = 1 and ω = ±π is represented by
z = −11. See Figure 18.4. As ω sweeps from 0 to π, its trajectory in the z-plane will be
the upper-half of the unit circle, from z = 1 to z = −1, traversed in the counterclockwise
direction. Likewise, as ω goes from 0 to −π, its trajectory will be the lower-half of the
unit circle, from z = 1 to z = −1, traversed in the clockwise direction.
Example
18.24
Some examples of ω (in rad/s) and their corresponding z-values on the unit circle are
listed below.
ω
⇐⇒
z
±π/6
⇐⇒
e± jπ/6
=
√
3/2 ± j1/2
±π/4
⇐⇒
e± jπ/4
=
√
2/2(1 ± j)
±π/2
⇐⇒
e± jπ/2
= ± j
±2π/3
⇐⇒
e± j2π/3 = −1/2 ± j
√
3/2
±3π/4
⇐⇒
e± j3π/4 =
√
2/2(−1 ± j)
±5π/4
⇐⇒
e± j5π/4 =
√
2/2(−1 ± j)
±9π/4
⇐⇒
e± j9π/4 =
√
2/2(1 ± j)
1This property also illustrates the periodicity of the frequency response.

Signals and Systems
1025
Unit circle
Re[z]
Im[z]
z = j
z = – j
z = –1
z = 1
π
2 
ω =
π
2 
ω = –
π 
–π 
ω = π
ω = 0
ω = –π
z-plane
ω
ω
+
–
0
+
–
ω
|H(ω) = H(z)|z=e jω (on the unit circle)
FIGURE 18.4 Visualization of z and ω in the z-plane under the transformation z = e jω. The
point z = 1 corresponds to ω = 0 and z = −1 corresponds to ω = ±π. Conversely, the point
at ω = 0 on the unit circle is represented by z = 1 and ω = ±π is represented by z = −1. As
ω sweeps from 0 toward π, its trajectory in the z-plane will be the upper-half of the unit circle,
from z = 1 to z = −1, traversed in the counterclockwise direction. Likewise, as ω goes from 0 to
−π, its trajectory will be the lower-half of the unit circle, from z = 1 to z = −1, traversed in the
clockwise direction.
18.4
Vectorial Interpretation of H (z) and H (ω)
A rational system function with M zeros and N poles may be written in terms of its
poles and zeros:
H(z) = H0
	k(z −zk)
	ℓ(z −pℓ)
where zk, k = 1, 2, · · · M, are zeros of the system, pℓ, ℓ= 1, 2, · · · N, are poles of
the system, and H0 is a gain factor. To simplify the discussion, assume H0 is a positive
number. A zero at zk contributes (z −zk) to the numerator of the system function. In
the z-plane this is a vector drawn from the point zk (the zero) to a point z (where the
system function is to be evaluated). Similarly, a pole at pℓcontributes (z −pℓ) to the
denominator of the system function. In the z-plane this is a vector drawn from the pole

1026
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
at pℓto point z. See Figure 18.5. Let Bk = (z −zk) designate the vector from zk to z
and Aℓ= (z −pℓ) designate the vector from pℓto z. Then,
H(z) = H0
B1 × B2 × B3 · · · × B M
A1 × A2 × A3 · · · × AN
= H0
	k Bk
	ℓAℓ
|H(z)| = H0
|B1| × |B2| × |B3| · · · × |B M|
|A1| × |A2| × |A3| · · · × |AN| = H0
	k|Bk|
	ℓ|Aℓ|
̸ H(z) =

̸ B1 + ̸ B2 + ̸ B3 · · · + ̸ B M

−

̸ A1 + ̸ A2 + ̸ A3 · · · + ̸ AN

=
M

k=1
̸ Bk −
N

ℓ=1
̸ Aℓ
The above interpretation provides a graphical technique to qualitatively derive some
properties of H(z) or to evaluate its exact value at desired points in the z-plane. In the
next section we apply the above interpretation to the points on the unit circle where the
frequency response is found.
Re[z]
Im[z]
z
A0 = z – p0
B0 = z – z0
z0
θ1
θ2
p0
FIGURE 18.5 Vectorial interpretation of H(z), with a zero at z0 and a pole at p0, using the
pole- zero plot. The zero contributes (z −z0), the vector B0 drawn from the zero to z, to the
numerator of the system function. Similarly, the pole contributes (z −p0), the vector A0 drawn
from the pole to z, to the denominator.
B0 = (z −z0) and A0 = (z −p0)
H(z) = H0
z −z0
z −p0
= H0
1 −z0z−1
1 −p0z−1 = H0
B0
A0
|H(z)| = H0
|B0|
|A0| and
̸ H(z) = θ1 −θ2, assuming H0 is a positive number.
This interpretation provides a graphical technique for evaluation of H(z) and its qualitative
analysis.

Signals and Systems
1027
Determination of H (ω) from the Pole-Zero Plot
The frequency response is found by evaluating H(z) on the unit circle. Starting at the
point z = 1 (ω = 0) and moving counterclockwise on the unit circle toward the point
z = −1 (ω = π), we can obtain a complete picture of H(ω) from the pole-zero plot.
Because vectors from poles are in the denominator, the magnitude of the frequency
response is increased when the point on the unit circle representing that frequency
approaches the neighborhood of a pole. Similarly, because the zero vectors are in the
numerator, the magnitude of the frequency response is decreased when its representative
point on the unit circle approaches a zero or its neighborhood. The following example
illustrates the utility of the vectorial interpretation and its graphical technique.
Example
18.25
A discrete-time causal system is described by the system function
H(z) =
1 + z−1
1 −0.9
√
2z−1 + 0.81z−2
Use the vectorial interpretation of H(z) to evaluate H(ω). Show that the system
is a bandpass ﬁlter. Find the 3-dB frequencies ωℓand ωh. Evaluate H(ω) at ω =
0, ωℓ, π/4, ωh, π/2, 3π/4, and π. Sketch the magnitude and phase of H(ω).
Solution
The system function is
H(z) =
1 + z−1
1 −0.9
√
2z−1 + 0.81z−2
=
1 + z−1
(1 −0.9e jπ/4z−1)(1 −0.9e−jπ/4z−1)
=
z(z + 1)
(z −0.9e jπ/4)(z −0.9e−jπ/4)
Ithasapairofpolesat p1,2 = 0.9e± jπ/4 [shownbypoints A1 and A2 onFigure18.6(a)]
and two zeros at z = 0 and z = −1 (shown by points B0 and B1, respectively). Let
C designate the location of z on the unit circle at which H(ω) is evaluated. Then, at
z = e jω we have
z = B0C,
z + 1 = B1C,
z −0.9e jπ/4 = A1C,
z −0.9e−jπ/4 = A2C
H(ω) = H(z)

z=e jω = B0C × B1C
A1C × A2C
|H(ω)| = |B1C|/(|A1C| × A2C|)
̸ H(ω) = [ω + ̸ B1C] −[̸ A1C + ̸ A2C]

1028
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
ω1
–θ(ω)0
ωh
ω
ω
13.77
9.76
3.73
0
0
π
4
π
2 
π
4
3
π
|H(ω)|
Unit circle
Re[z]
Im[z]
A1
A2
ωh = 50.73°
ω
A1
C1(ω 0 = 45°) 
ω1 = 39.37° 
0.1 2
0.1
C3
C2
C1
C0
C
C4
B1
B0
Pole
Pole
Zeros
A1 = 0.9∠45°
A2 = 0.9∠–45°
z0 = 0
z1 = –1
Poles
Zeros
(a)
64.5
19.5
109.5
126.5
109.5
90
(b)
(c)
FIGURE 18.6 Evaluation of the frequency response of a system having a pair of poles at p =
0.9e± jπ/4 and two zeros at z = 0 and z = −1, using the vectorial interpretation: (a) Pole-zero plot;
(b) ﬁnding the 3-dB frequency; (c) sketch of the frequency response. See Example 18.25.
At ω = π/4 the magnitude of the vector A1C = 0.1̸ 45◦is at its minimum,
producing |H(ω)|Max as |H(π/4)| = 13.74̸ −64.5◦. In the vicinity of ω = π/4 the
vector A1C is the most inﬂuential of the four vectors in shaping H(ω). The other
three vectors (B0C, B1C, and A2C) don’t change appreciably, and their contributions

Signals and Systems
1029
to H(ω) remain almost at a constant value.2 A 3-dB frequency is where A1C =
√
2 × 0.1. See Figure 18.6(b). There exist two such points, ωℓand ωh, located at
ω = π/4 ± 0.1 rad/s. More generally, we may conclude that in the neighborhood of
ω = π/4 (which includes the 3-dB frequencies ωℓand ωh) we will have
H(ω) = 1.38̸ −19.5◦
A1C
and H(π/4) = 1.38̸ −19.5◦
0.1̸ 45◦
= 13.8̸ −64.5
|A1Cℓ,h| ≈0.1 ×
√
2
ωℓ,h ≈π/4 ± 0.1 rad = 39.3◦, and 50.7◦
|H(ωℓ,h)| ≈9.76
̸ H(ωℓ,h) ≈−64.5 ± 45◦= −19.5◦and −109.5◦
From the graphical representation of Figure 18.6(a) and (b) we have the following
approximations:
Location of z
ω
H(ω)
|H(ω)|
̸ H(ω)
Comments
C0
0◦
B0C0 × B1C0/(A1C0 × A2C0)
3.73
0◦
Cℓ
39.3◦
B0Cℓ× B1Cℓ/(A1Cℓ× A2Cℓ)
9.76
−19.5◦
Lower 3-dB frequency, |H| = |HMax|
√
2
C1
45◦
B0C1 × B1C1/(A1C1 × A2C1)
13.77
−64.5◦
Near a pole, |HMax| = 13.77
Ch
50.7◦
B0Ch × B1Ch/(A1Ch × A2Ch)
9.76
−109.5◦
Upper 3-dB frequency, |H| = |HMax|
√
2
C2
90◦
B0C2 × B1C2/(A1C2 × A2C2)
1.1
−126.5
C3
135◦
B0C3 × B1C3/(A1C3 × A2C3)
0.3
−109.5◦
C4
180◦
B0C4 × B1C4/(A1C4 × A2C4)
0
−90◦
Zero of the system
The frequency response is sketched in Figure 18.6(c).
18.5
Transforming Continuous Time to
Discrete Time
In many applications, including digital signal processing, digital control, or digital com-
munication, one may require to convert an existing continuous-time system to a discrete
one, or design a new system in the discrete-time domain based on a design in the
2At ω = π/4 we can ﬁnd (B0C × B1C)/A2C ≈1.38̸ −19.5◦. However, to ﬁnd the 3-dB frequency we
don’t need to know this value.

1030
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
continuous-time domain. In this migration one needs to determine transformation of
both the signals and the systems. The sampling theorem provides us with the guidelines
to convert a continuous-time signal to discrete time. The correspondence between the
frequencies in these domains have been described and exempliﬁed. In this section, using
three examples, we ﬁrst refresh the subject of mapping the frequency from continuous
time to discrete time, as a result of uniform time-domain sampling.
With regard to systems we need to detemine how to convert or construct a discrete-
time system that exhibits characteristics identical to or similar to its continuous-time
counterpart. LTI systems are described by H(s) (in the continuous-time domain) and
H(z) (in the discrete-time domain). Mathematically expressed, we need to determine
mappingfromthes-domaintothe z-domain.Thetransformationshouldanswerquestions
such as the following: What becomes of the continuous-time differential and integral
operators? Do the discrete-time difference operators approximate time-derivative in the
continuous-time domain satisfactorily? Does the j
 axis in the s-plane (i.e., the fre-
quency in the continuous-time) maps onto the unit circle in the z-plane (the frequency in
the discrete time), and if so, is the mapping linear and uniform? How do the parameters
of the transformation (e.g., sampling rate) affect the pole-zero locations and stability
of the system? Does the left-half plane in the s-domain map onto the inside of the unit
circle in the z-plane? In Chapter 15 (section 15.11) the relationship between the Laplace
transform of a continuous-time function and the z-transform of its sampled sequence
was discussed. This section ﬁrst discusses the frequency mapping from 
 to ω (using

 and F for continuous time, and ω and f for the discrete, respectively). It then brieﬂy
introduces impulse invariant and bilinear transformations to provide a window through
which some light is shed on the subject. These two transformations will be used later in
this chapter in relation to design of digital ﬁlters.
Mapping the Frequency from Continuous Time to Discrete Time
The frequency response of discrete-time systems is 2π-periodic in ω. Therefore, it is
enough to consider it for one period, normally −π < ω < π. What does this range
mean in terms of the actual frequency in the continuous-time domain? The relation
between the frequencies in the continuous-time (shown by 
) and discrete-time (shown
by ω) domains depends on the sampling scheme used and the transformation from
continuous-time to discrete-time signals and systems. Here it sufﬁces to say that under
uniform sampling (e.g., at the rate of Fs samples per second, or Hz) the transformation
from 
 (the continuous-time signal) to ω (the resulting discrete-time signal) is linear,

 = Fsω, such that ω = 0 in the discrete-time analysis corresponds to a DC signal in
the continuous-time domain and ω = 2π corresponds to a continuous-time sinusoidal
signal at 
 = 2π Fs rad/s. Similarly, using F (the continuous-time signal) and f (the
resulting discrete-time signal) we will have F = Fs f , such that f = 0 in the discrete-
time analysis corresponds to a DC signal in the continuous-time domain and f = 1
corresponds to a continuous-time sinusoidal signal at F = Fs (all in Hz).
The answer to the question posed at the beginning of this section may now be
summarized as follows. The range −π < ω < π rad/s maps onto −π Fs < 
 < π Fs
(equivalently, −0.5 < f < 0.5 Hz maps onto −Fs/2 < F < Fs/2). Sampling a

Signals and Systems
1031
continuous-time signal at the rate of Fs downshifts the frequency components above
Fs/2. In this book the ratio F/Fs will be called the normalized frequency.
Example
18.26
The recording of a continuous-time voltage x(t) contains a signal of interest s(t) along
with a 60-Hz disturbance x(t) = s(t) + α cos(120πt + φ). x(t) is sampled at the
rate of Fs samples per second and the samples are sent through a three-sample-wide
window. Determine Fs so that the 60-Hz disturbance is eliminated in the output of
the window.
Solution
The unit-sample response, system function, and frequency response of the discrete-
time window are given below.
h(n) = {1
↑, 1, 1}
H(z) = 1 + z−1 + z−2, H(ω) = 1 + e−jω + e−j2ω = (1 + 2 cos ω)e−jω
The frequency response has only 1 zero at ω = 2π/3. The 60-Hz component (
 =
120π) will be eliminated if its ω in the discrete-time domain falls on the location of
the zero of H(ω). The relationship between 
 (in continuous time) and ω (in discrete
time) is 
 = Fsω. Therefore, one needs 120π = Fs(2π/3), which yields Fs = 180
Hz.
Example
18.27
Extend Example 18.26 to the case where, when recording x(t), a 60-Hz disturbance
and its two harmonics are added to the desired signal s(t).
x(t) = s(t) +
3

k=1
αk cos(120kπt + φk)
x(t) is sampled at the rate of Fs and the samples are sent through a discrete-time
system with the unit-sample response h(n). Show that by choosing Fs = 420 Hz and
h(n) = {1, 1, 1, 1
↑, 1, 1, 1} one blocks the disturbances at 60, 120, and 180 Hz from
reaching the output. Discuss parallels with Example 18.26.
Solution
For simplicity, we examine a noncausal window. This will not affect our solution of
this example as we are interested in the magnitude of the frequency response only.
The frequency response H(ω) of the seven-point uniform window is found below.
H(z) = z3 + z2 + z + 1 + z−1 + z−2 + z−3 = z3 −z−4
1 −z−1
H(ω) = e j3ω + e j2ω + e jω + 1 + e−jω + e−j2ω + e−j3ω = sin(7ω/2)
sin(ω/2)

1032
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
From the above representation of H(ω) by the ratio of sinusoids, it is easily seen that
the frequency response has 3 zeros at ω = 2π/7, 4π/7 and 6π/7.3 But, 
 = Fs × ω
and at Fs = 420 Hz the zeros of H(ω) translate to 
 = 120π, 240π, and 360π,
which correspond to 60, 120, and 180 Hz. The given ﬁlter blocks disturbances at the
above harmonics.
Example
18.28
Now consider another case of signal plus disturbance, similar to Example 18.26,
where the recorded data is x(t) = w(t) + α cos(
t + φ) and 
 = 120π. However,
in contrast to Example 18.26, here the signal of interest is the 60-Hz component and
w(t) is the disturbance to be reduced by ﬁltering. The aim is to ﬁlter x(t) such that
w(t) is attenuated and cos(
t +φ) is enhanced. Here again x(t) is sampled at the rate
of Fs samples per second. The samples are then sent through a discrete-time system
with a pair of poles at 0.9e± jθ and 2 zeros at ±1. Find Fs for θ = π/6, π/4, π/3,
and π/2. Discuss the choice of θ.
Solution
The discrete-time signal, system function, and frequency response are
x(n) = w(n) + α cos(ωn + φ), where ω = 
Fs
H(z) =
(1 −z−1)(1 + z−1)
(1 −0.9e jθz−1)(1 −0.9e−jθz−1) =
1 −z−2
1 −1.8(cos θ)z−1 + 0.81z−2
H(ω) =
1 −e−j2ω
1 −1.8(cos θ)e−jω + 0.81e−j2ω
The magnitude of the frequency response is at a maximum when ω = θ (see Examples
18.20 and 18.25), which translates to 
 = Fsθ, from which Fs = 
/θ. But 
 =
120π. Therefore, Fs = 120π/θ. For θ = π/6, π/4, π/3, and π/2 we will have
Fs = 720, 480, 360, and 240 Hz, respectively. The corresponding values of the
frequency response are
θ
π/6
π/4
π/3
π/2
|H|
10.4828
10.5118
10.5215
10.5263
̸ H
5.2087◦
3.0128◦
1.7405◦
0.0000◦
The ﬁlter with θ = π/2 introduces zero phase shift and will be chosen.
Sampling the Unit-Impulse Response: Impulse-Invariance
Transformation
A continuous-time LTI system may be converted to a discrete-time system by sampling
its time responses. The sampled time-response will then describe the discrete system.
3The alternate representation is H(ω) = 1 + 2 cos ω + 2 cos(2ω) + 2 cos(3ω).

Signals and Systems
1033
For example, sampling the unit-impulse response produces an impulse-invariant trans-
formation. Here is an example.
Example
18.29
The unit-impulse response h(t) = e−tu(t) of a continuous-time system is sampled
every T sec. Find the system function H(z) of the resulting discrete-time system and
determine the location of its pole for T = 3, 2, 1, 0.5, 0.1, 0.01, and 0.001 sec.
Solution
h(n) = h(t)

t=nT = e−nT u(n) = anu(n), where a = e−T .
Note that a < 1 for T > 0.
H(z) =
1
1 −az−1 , where |z| < a is inside the circle.
The discrete-time system has a pole at z = a < 1. The location of the pole depends on
the sampling rate as shown below. For all sampling rates, the pole remains inside the
unit circle indicating that h(n) diminishes as n increases, making the discrete system
stable.
T = 1 msec
pole at 0.999
T = 10 msec
pole at 0.99
T = 100 msec
pole at 0.905
T = 500 msec
pole at 0.607
T = 1 sec
pole at 0.368
T = 2 sec
pole at 0.135
T = 3 sec
pole at 0.05
Remark
H(z) may also be found directly from H(s) as described in Chapter 15, section 15.11.
Approximating Derivatives by Difference Operators
An LTI differential equation may be converted to a difference equation by sampling
the time and then approximating the derivatives by difference operators. The pole-zero
locations of the resulting discrete system will depend on the sampling scheme and its
rate. Here are two examples.
Example
18.30
Approximation by the forward-difference operator
The differential equation
dy(t)
dt
+ y(t) = x(t)
may be converted to a difference equation by sampling x(t) and y(t) every T seconds
(i.e., by letting t = nT ) and approximating the derivative by the following expression

1034
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
representing the forward-difference operator:
dy(t)
dt
≈y(t + T ) −y(t)
T
The differential equation then becomes
y(t + T ) −y(t)
T
+ y(t) = x(t)
y(t + T ) −(1 −T )y(t) = T x(t)
With t = nT , we obtain the difference equation and system function
y(n + 1) −(1 −T )y(n) = T x(n)
zY(z) −(1 −T )Y(z) = T X(z)
H(z) =
T z−1
1 −αz−1 , where α = 1 −T
The discrete-time system has a pole, here at z = 1 −T . The location of the pole
depends on the sampling rate as given below. However, at low sampling rates the pole
may move outside the unit circle, indicating that h(n) grows as n increases, making
the discrete system unstable.
T = 1 msec
pole at 0.999
T = 10 msec
pole at 0.99
T = 100 msec
pole at 0.9
T = 500 msec
pole at 0.5
T = 1 sec
pole at 0
T = 2 sec
pole at −1
T = 3 sec
pole at −2
Remark
The forward-difference approximation of the derivative in this example is satisfactory
at high sampling rates, but unacceptable at low rates.
Example
18.31
Approximation by the backward-difference operator
The continuous-time differential equation
dy(t)
dt
+ y(t) = x(t)
may also be converted to a difference equation by sampling x(t) and y(t) every T
seconds and approximating the derivative by the backward-difference operator:
dy
dt ≈y(n) −y(n −1)
T

Signals and Systems
1035
Following the approach of Example 18.30 we obtain the following system function.
H(z) =
T z
βz −1,
where β = 1 + T
The resulting discrete-time system has a pole inside the unit circle and is stable at all
sampling rates.
Approximating Integral: The Case of The Bilinear Transformation
The following mapping from s to z
s = 2
T
1 −z−1
1 + z−1
(where T is the sampling interval) is called a bilinear tranformation. It is used as a main
tool in the design of digital ﬁlters and control systems. An example of IIR ﬁlter design
by bilinear transformation is given in section 18.10. The following example illustrates
how the bilinear transformation is obtained by approximating an integral by the area of
a trapezoid.
Example
18.32
An example of bilinear transformation
Consider the differential equation
Time domain:
dy(t)
dt
+ ay(t) = bx(t)
(18.1a)
Frequency domain:
sY(s) + aY(s) = bX(s)
(18.1b)
System function:
H(s) = Y(s)
X(s) =
b
s + a
(18.1c)
In Examples 18.30 and 18.31 we approximated derivatives of y(t) by difference
operators. In this example we approximate an integral element by a trapezoid. Start
with
y(t) =
	 t
t0
y′(τ)dτ + y(t0)
(18.2a)
y(nT ) =
	 nT
(n−1)T
y′(τ)dτ + y(nT −T ) (18.2b)
Approximatethevalueoftheintegralinequation(18.2b)bytheareaofatrapezoid
ABCD. See Figure 18.7.
	 nT
(n−1)T
y′(τ)dτ ≈

y′(nT ) + y′(nT −T )
T
2
(18.3)
Plug (18.3) in (18.2b) to ﬁnd
y(nT ) = y′(nT ) + y′(nT −T )
2
T + y(nT −T ) (18.4)

1036
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
y'
D
C
t
(n – 1)T
nT
A
B
FIGURE 18.7 Approximating an integral element by the area of the trapezoid.
But from the differential equation we have
y′(nT ) = bx(nT ) −ay(nT )
(18.5a)
y′(nT −T ) = bx(nT −T ) −ay(nT −T )
(18.5b)
Now plug (18.5) in (18.4) and note that x(nT ) ≡x(n), y(nT ) ≡y(n).
y(n) = T
2

bx(n) −ay(n) + bx(n −1) −ay(n −1)

+ y(n −1) (18.6)
Collect the y terms on the left side and x terms on the right.
Time domain

aT
2 + 1

y(n) +

aT
2 −1

y(n −1) = b T
2 [x(n) + x(n −1)]
(18.7a)
Frequency domain

aT
2 + 1

Y(z) +

aT
2 −1

Y(z)z−1 = b T
2 (1 + z−1)X(z)
(18.7b)
System function
H(z) = Y(z)
X(z) =
b
2
T
1 −z−1
1 + z−1

+ a
(18.7c)
Compare equation (18.7c) with (18.1c) to derive the following s to z transforma-
tion
s = 2
T
1 −z−1
1 + z−1 = 2
T
z −1
z + 1
Bilnear transformation is commonly used in digital ﬁlter design.
18.6
Digital Filters
The name digital ﬁlter applies to a discrete-time system that performs one or more
(possibly interrelated) operations such as:
Frequency selection
Smoothing

Signals and Systems
1037
Separating a signal from disturbances
Reducing noise
Analyzing time-series data
Producing a certain phase shift or delay
Detecting presence of a known signal by template matching
Detecting random signals embedded in noise
The operation of a ﬁlter may also be related to some optimality or adaptation in such
tasks as:
Prediction
Modeling and identiﬁcation
Statistical analysis and estimation
This chapter provides an introduction to digital ﬁlters as frequency-selective systems
with the input shown by x(n) and the output by y(n). The frequency response is used as
the main tool for analysis and synthesis.
Filter Types
The ﬁlters discussed in this chapter are LTI discrete-time systems classifed based on
the frequency response, H(ω).4 As in the analog case, we consider ﬁve types of ﬁlters:
(1) low-pass, (2) high-pass, (3) bandpass, (4) bandstop, and (5) all-pass. Ideally
H(ω) =

1, within the passband
0, within the stopband
In addition to the above, we will also consider some other ﬁlter types such as differentia-
tors. Note that the frequency response of the digital ﬁlter is periodic in ω with a period
of 2π. Therefore, we consider only one period of H(ω), normally for −π ≤ω ≤π.
As in the analog case, ideal digital ﬁlters are not realizable because of their brickwall
frequency response shape. They are approximated and realizable by practical ﬁlters.
Filter Description
Any one of the following functions can completely describe a digital ﬁlter.
1.
Input-output difference equation
2.
System function H(z)
3.
Frequency response H(ω)
4.
Unit-sample response h(n)
5.
Pole-zero locations plus a gain factor
4To be mathematically precise, the frequency response of a discrete-time LTI system should be written as
H(e jω) or H(e j2π f ). However, whether choosing ω or f as the frequency variable, throughout this textbook
we show the frequency response function by H(ω) or H( f ).

1038
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Of the above, the frequency response H(ω) explicitly exhibits the characteristics
normally considered to be of interest in a ﬁlter. The unit-sample response h(n) serves
as the end result in the design of a ﬁlter. The difference equation, system function H(z),
and the pole-zero map serve as analysis and design tools. A zero of H(z) at z0, which
is close to the unit circle, will pull down the magnitude response for frequencies on the
unit circle that are close to z0. A pole pulls up the magnitude of the frequency response
in its neighborhood. To block a certain frequency, the ﬁlter should have a zero on the
unit circle at that frequency, and to enhance it, the ﬁlter should have a pole inside the
unit circle near that frequency. Examples of simple low-pass and bandpass ﬁlters will
be given in the next two sections. Examples of simple high-pass ﬁlter are found at the
end of this chapter in the solved problems. In addition to the projects at the end of this
chapter, several other chapters include projects on ﬁltering. These are: an introduction to
discrete-time signal processing in Chapter 11, low-pass ﬁltering by difference equation
in Chapter 14, and FIR and IIR notch ﬁlter design in Chapter 15.
Filter’s Pole-Zero Locations and the Frequency Response
From the previous discussions about system function of an LTI system we have drawn
qualitative observations concerning the effect of the locations of poles and zeros on the
frequency response. In this section we discuss quantitatively the role poles and zeros
play in shaping the ﬁlter’s frequency response, suggesting some insight into the function
and structure of ﬁlters and also tools for their design.
The system function H(z) provides a ﬁlter’s z-domain input-output relationship
Y(z) = H(z)X(z). Alternatively, it provides the scale factor, a more physically tangible
measure in the time domain, for the input signal x(n) = zn to pass through the ﬁlter,
resulting in the output y(n) = H(z)zn. The complex number z = ρe jω, called the
complex frequency, is represented by a point in the z-plane. For a discrete-time sinusoidal
signal x(n) = RE{e jωn} we have z = e jω and the signal is represented by a point on
a circle with the radius ρ = 1, called the unit circle.5 Hence, the unit circle plays a
signiﬁcant role in the analysis and design of LTI digital ﬁlters. Based on the above
explanation we can explore the role played by poles and zeros on a ﬁlter’s frequency
response.
Effects of Zeros
Let z0 be a zero of the system function; that is, H(z0) = 0. The presence of the zero at z0
prevents passage of the signal x(n) = zn
0 through the ﬁlter. To block a certain frequency,
the ﬁlter should have a zero on the unit circle at that frequency. The zero at z0 = e± jω0
not only notches out the signal at the frequency ω0, but also attenuates signals at the
neighboring frequencies. [See the vectorial interpretation of H(z).] The bandwidth of
the notch will be wide unless it is compensated by nearby poles.
5Stated differently, the frequency of a continuous-time sinusoidal waveform is mapped onto the unit circle of
the z-plane.

Signals and Systems
1039
Effects of Poles
A pole pulls up the magnitude of the frequency response in its neighborhood. Poles
are never placed on the unit circle or outside of it because of stability considerations. A
pole placed nearby a zero reduces the attenuative effect of the zero. Therefore, one or
more poles placed near a notching zero (the zero being on the unit circle but the poles
inside it) narrow the notch bandwidth.
Contributions to the Frequency Response
Zeros (and poles) are the roots of the numerator (and denominator) of the system function.
For a ﬁlter with real-valued coefﬁcients, zeros (and poles) are either real-valued numbers
or complex conjugate pairs. A real-valued zero at ρ multiplies the system function by
1 −ρz−1 and a pole divides by it. A pair of zeros at ρe± jω0 contributes the following
multiplier term to the numerator (or to the denominator in case of poles) of the system
function.
(1 −ρe jω0z−1)(1 −ρe−jω0z−1) = 1 −2ρ cos ω0z−1 + ρ2z−2
A pair of zeros on the unit circle at e± jω0 multiplies the system function by 1 −
2 cos ω0z−1 + z−2.
A Dominant Pair of Poles
A pair of poles at ρe± jω0 close to the unit circle (ρ being nearly one) will dominate the
frequency response in its neighborhood such that
H(ω) ≈H0
1
1 −2ρ cos ω0z−1 + ρ2z−2
which is similar to a second-order system (see parallels with the discussion on modeling
an analog system with a pair of dominant poles, Chapter 9). The multiplier H0 represents
the effect of other poles and zeros, and will be almost a constant as long as the other
poles and zeros remain far away. The dominant pole then pulls up the magnitude of the
frequency response. The closer the pole is to the unit circle, the sharper the frequency
response becomes in the neighborhood.
18.7
Simple Filters
Simple Low-Pass Filters
A simple low-pass ﬁlter can be constructed from a zero at z = −1 (which corresponds
to ω = π and thus blocks high frequencies), a pole near z = 1 (which corresponds
to DC, thus boosts up low frequencies), or their combinations. Three such examples
are discussed below. Their graphical characteristics (i.e., the frequency response, unit-
sample response, and pole-zero plot) visualize the basic features of low-pass ﬁlters. The

1040
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
examples also illustrate how the passband and stopband-edge frequencies are determined
from the given attenuations Ap and As, respectively.
Example
18.33
A low-pass filter with a single zero
A realizable digital ﬁlter is described by y(n) = x(n) + x(n −1).
a.
Find the ﬁlter’s H(z), H(ω), h(n), pole-zero locations, magnitude response,
and the DC gain in dB.
b.
Find the passband and stopband edge frequencies for Ap = 3 and As = 20,
both in dB.
c.
Repeat for Ap = 1 and As = 40.
Solution
a.
H(z) = 1 + z−1
A single zero at z = −1. (The pole at z = 0 has no effect on the frequency
response and is ignored.)
H(ω) = 1 + e−jω = 2 cos
ω
2

e−jω/2
h(n) = d(n) + d(n −1)
20 log |H(ω)| = 20 log

2 cos
ω
2

≈6 + 20 log cos
ω
2

dB
DC gain ≈6 dB
b.
Ap =3 dB,
6 + 20 log cos
ωp
2

= 6 −3,
cos
ωp
2

=
√
2
2 , ωp = 90◦
As =20 dB, 6 + 20 log cos
ωs
2

= 6 −20,
cos
ωs
2

= 0.1,
ωs = 168.52◦
c.
Ap =1 dB,
6 + 20 log cos
ωp
2

= 6 −1,
cos
ωp
2

= 0.8912, ωp = 53.94◦
As =40 dB, 6 + 20 log cos
ωs
2

= 6 −40,
cos
ωs
2

= 0.01, ωs = 178.85◦
Example
18.34
A low-pass filter with a single pole
Repeat Example 18.33 for the realizable digital ﬁlter described by y(n) −0.9y
(n −1) = x(n).

Signals and Systems
1041
Solution
a. H(z) =
1
1 −0.9z−1
A single pole at z = 0.9. (The zero at z = 0 has no effect on the frequency
response and is ignored.)
H(ω) =
1
1 −0.9e−jω =
1
(1 −0.9 cos ω) + j0.9 sin ω
=
1
√1.81 −1.8 cos ωe−jθ, where θ = tan−1

0.9 sin ω
1 −0.9 cos ω

h(n) = (0.9)nu(n)
20 log |H(ω)| = −10 log(1.81 −1.8 cos ω) dB
DC gain = −10 log 0.01 = 20 dB
b.
Ap = 3 dB,
−10 log(1.81 −1.8 cos ωp) = 20 −3 = 17,
cos ωp = 0.99447, ωp = 6.03◦
As = 20 dB,
−10 log(1.81 −1.8 cos ωs) = 20 −20 = 0,
cos ωs = 0.45, ωs = 63.25◦
c.
Ap = 1 dB,
−10 log(1.81 −1.8 cos ωp) = 20 −1 = 19,
cos ωp = 0.99856, ωp = 3.07◦
As = 40 dB,
−10 log(1.81 −1.8 cos ωs) = 20 −40 = −20,
No answer; see below.
With regard to the no-answer in part c, having only a single pole at z = 0.9, the
maximum attenuation provided by the ﬁlter to occur at z = −1 (corresponding to
ω = π), at which point H(z) =
1
1.9 = 0.5263 (or −5.57 dB), which is still greater
than the −20 dB required by the As = −40-dB criterium in part c. In other words, the
maximum high-frequency attenuation is 25.57 dB (below the DC gain) and doesn’t
reach the As = 40-dB level.
Example
18.35
A low-pass filter with a zero and a pole
Repeat Example 18.33 for the realizable digital ﬁlter described by y(n) −0.9y
(n −1) = x(n) + x(n −1).

1042
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Solution
a. H(z) =
1 + z−1
1 −0.9z−1
A zero at z = −1 and a pole at z = 0.9.
H(ω) =
1 + e−jω
1 −0.9e−jω =
2 cos
 ω
2

√1.81 −1.8 cos ωe−jθ,
where θ = ω
2 + tan−1

0.9 sin ω
1 −0.9 cos ω

.
h(n) = [d(n) + d(n −1)] ⋆(0.9)nu(n) = (0.9)nu(n) + (0.9)n−1u(n −1)
= d(n) + 1.9 × (0.9)n−1u(n −1)
20 log |H(ω)| = 10 log

4 cos2  ω
2

1.81 −1.8 cos ω

= 6 + 20 log cos
ω
2

−10 log(1.81 −1.8 cos ω) dB
DC gain = 6 −10 log 0.01 = 26 dB
b. 20 log |H(ω)| = 10 log

2(1 + cos ω)
1.81 −1.81 cos ω

Ap = 3 dB, 10 log

2(1 + cos ωp)
1.81 −1.8 cos ωp

= 26 −3 = 23,
cos ωp = 0.99445, ωp = 6.04◦
As = 20 dB, 10 log

2(1 + cos ωs)
1.81 −1.8 cos ωs

= 26 −20 = 6,
cos ωs = 0.56794, ωs = 55.39◦
c. Ap = 1 dB, 10 log

2(1 + cos ωp)
1.81 −1.8 cos ωp

= 26 −1 = 25,
cos ωp = .99853, ωp = 3.1◦
As = 40 dB, 10 log

2(1 + cos ωs)
1.81 −1.8 cos ωs

= 26 −40= −14, cos ωs = −0.9306, ωs = 158.53◦
Adding a zero at z = −1 has pegged the magnitude response to zero at ω = π, and
pulled it down at other frequencies, making it possible to achieve −40-dB attenuation
within the range of 0 < ω < π.
Simple Bandpass Filters
A simple bandpass ﬁlter can be constructed by placing a pair of complex conjugate
poles inside and near the unit circle [see vectorial interpretation of H(z) in this chapter].

Signals and Systems
1043
Adding two zeros at z = ±1 (corresponding to ω = 0 and π) will completely block the
DC and high frequencies. Such a simple bandpass ﬁlter will be of second-order and have
a narrowband. The bandwidth may be increased by employing several poles within the
desired passband, making it a higher-order ﬁlter. An example of a simple bandpass ﬁlter
is given below.
Example
18.36
A bandpass filter
A digital ﬁlter has a pair of complex conjugate poles at z = ± jρ, where ρ < 1, 2
zeros at z = ±1, and H(z)|z=∞= 1.
a.
Find H(z) and H(ω) = |H(ω)|̸ H(ω). Specify the ﬁlter’s important values
[maximum value of |H(ω)|, 3-dB frequencies (ωℓand ωh], and the bandwidth
ω = ωh −ωℓin terms of ρ, the pole’s distance from the origin].
b.
Repeat a for ρ = 0.8, 0.9, 0.95, and 0.99. Determine the limiting values for
ωℓ, ωh, and ω as the poles approach the unit circle.
c.
Plot |H(ω)| and ̸ H(ω) versus ω for ρ = 0.8, 0.95, and 0.99.
Solution
a.
H(z) =
(1 −z−1)(1 + z−1)
(1 −jρz−1)(1 + jρz−1) =
1 −z−2
1 + ρ2z−2
H(ω) =
1 −e−j2ω
1 + ρ2e−j2ω = ( j2 sin ω)e−jω
1 + ρ2e−j2ω
=
j2 sin ω
e jω + ρ2e−jω
=
j2 sin ω
(1 + ρ2) cos ω + j(1 −ρ2) sin ω =
2| sin ω|

(1 −ρ2)2 + 4ρ2 cos2 ω
e jθ
where |H(ω)| =
2| sin ω|

(1 −ρ2)2 + 4ρ2 cos2 ω
, and
θ =



−tan−1 
1−ρ2
1+ρ2 tan ω

+ π
2 ,
0 < ω < π
−tan−1 
1−ρ2
1+ρ2 tan ω

−π
2 , −π < ω < 0
|HMax| = H(z)

z= j =
2
1 −ρ2
|H(ωℓ)| = |H(ωh)| = |HMax|
√
2
=
√
2
1 −ρ2
Find ωℓ,h from |H(ω)|2 =
4 sin2 ω
(1 −ρ2)2 + 4ρ2 cos2 ω =
2
(1 −ρ2)2
The answer is
cos(ωℓ,h) = ±
(1 −ρ2)

2(1 + ρ4)

1044
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
b. ρ = 0.8,
H(ω)

Max = 5.56,
ωℓ= 77.62◦, ωh = 102.38◦, and ω = 24.76◦= 0.4321 rad/s
ρ = 0.9,
H(ω)

Max = 10.52,
ωℓ= 84.00◦, ωh = 95.99◦, and ω = 11.99◦= 0.2092 rad/s
ρ = 0.95,
H(ω)

Max = 20.51,
ωℓ= 87.07◦, ωh = 92.93◦, and ω = 5.87◦= 0.1024 rad/s
ρ = 0.99,
H(ω)

Max = 100.50,
ωℓ= 89.42◦, ωh = 90.58◦, and ω = 1.16◦= 0.0202 rad/s
As the poles approach the unit circle, ρ →1 and
cos(ωℓ,h) = ±(1 −ρ)(1 + ρ)

2(1 + ρ4)
→± (1 −ρ), ω →2(1 −ρ)
See Figure 18.8.
0
1
−10
−5
0
5
10
15
20
25
30
35
40
45
0.8
0.95
Magnitude (dB)
Angular frequency (rad/s, in units of π)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
(a) Magnitude in dB
0
1
Angular frequency (rad/s, in units of π)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
(b) Phase
r = 0.99
−100
−80
−60
−40
−20
0
20
40
60
80
100
r = 0.8
0.95
0.99
Phase (degrees)
FIGURE 18.8 (For Example 18.36) Frequency response for the bandpass ﬁlter H(z) = (1 −z−2)/(1 −ρ2z−2). Plots are
for ρ = 0.8, 0.95, and 0.99. Magnitudes are shown in (a) (dB units) and phase is in (c). The magnitude peak (always
at ω = 90◦) grows and becomes narrower as the poles approach the unit circle.
18.8
Filter Design
In ﬁlter design, one often begins with a desired frequency response Hd(ω) or some
speciﬁcations related to it (e.g., the ﬁlter’s passband and stopband frequencies and their
attenuations, Ap and As, respectively). The conditions to be satisﬁed will be called design
criteria. The aim is to ﬁnd the h(n) of a realizable ﬁlter (FIR or IIR), which meets some
design criteria. The h(n) and H(ω) are DTFT pairs as shown below.
H(ω) =
∞

n=0
h(n)e−jωn
⇐⇒h(n) = 1
2π
	 π
−π
H(ω)e jωdω

Signals and Systems
1045
The acceptability of the design outcome may be given in terms of satisfying the de-
sired speciﬁcation (Ap and As) or a measure of error (such as the rms of error be-
tween the magnitude responses). The following sections brieﬂy present some of the
most commonly used methods in ﬁlter design. A method applicable to both FIR and
IIR design is pole-zero placement. This method will be illustrated in the next section.
Other methods speciﬁc to FIR or IIR cases are also used. Design methods to be dis-
cussed in the remainder of this chapter provide approximations to the desired ﬁlters. The
following methods are not meant to provide an exhaustive picture of design methods
and processes. They are to illustrate, by way of examples, some basic aspects of the
design process. In FIR design we ﬁnd the ﬁnite-length h(n) such that the ﬁlter approxi-
mates the desired one and complies with constraints. The following two methods will be
discussed.
FIR design

a. Windowing method (also called truncating Fourier method)
b. Frequency sampling method
In IIR design we ﬁnd the system function H(z) by transforming the H(s) of an analog
ﬁlter. The following two transformations will be discussed.
IIR design

a. Impulse-invariance transformation from analog to digital
b. Bilinear transformation
Ideal Low-Pass Filter
In ﬁlter design by windowing we begin with the unit-sample response of an ideal ﬁlter.
A low-pass type is normally chosen. The frequency response of an ideal low-pass ﬁlter
with the cutoff at ω0 is
HLP(ω) =

1,
−ω0 < ω < ω0
0,
elsewhere
The unit-sample response of the ﬁlter is obtained by taking the inverse DTFT of H(ω).
h(n) = 1
2π
	 π
−π
H(ω)e jωndω = 1
2π
	 ω0
−ω0
e jωndω =
 sin(ω0n)
πn
,
n ̸= 0
ω0
π ,
n = 0
The above h(n) produces zero phase. Shift h(n) to the right by k units of time to produce
h(n) = h(n −k) and its transform H(ω). The pair are
h(n) = h(n−k) =
 sin[ω0(n−k)]
π(n−k)
n ̸= k
ω0
π
n = k
⇒
H(ω) =

e−jkω
−ω0 < ω < ω0
0,
elsewhere
The shifted unit sample response is still symmetric (around k) and has a linear phase. It
still is, however, inﬁnitely long and no amount of shift to the right would make it causal.
The ideal ﬁlter is, therefore, unrealizable. The design methods to be described in this
chapter approximate an unrealizable ideal ﬁlter by a realizable one in which h(n) = 0
for n < 0.

1046
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
An ideal high-pass ﬁlter can be constructed by HHP(ω) = 1 −HLP(ω), which, in
the time domain, translates into hHP(n) = d(n) −hLP(n). Similarly, ideal bandpass and
bandstop ﬁlters can be constructed from ideal low-pass ﬁlters.
18.9
Filter Design by Pole-Zero Placement
A zero of H(z) at z0 that is close to the unit circle will pull down the magnitude response
for frequencies close to z0, and a pole will pull up the magnitude response in its neigh-
borhood. To block a certain frequency, the ﬁlter should have a zero on the unit circle
at that frequency, and to enhance it, the ﬁlter should have a pole inside the unit circle
near that frequency. These properties can be used to design a ﬁlter. Poles and zeros will
be placed at such locations that the frequency response satisﬁes the design criteria. A
good example is the design of notch ﬁlters. Examples of FIR and IIR notch ﬁlters are the
subject of projects in Chapter 15 (also see problems 16 and 17 in this chapter). These
examples show how adding poles can improve the ﬁlter’s performance in meeting the
design objectives and controlling the bandwidth. Example 18.36 discussed a narrow-
band band-pass ﬁlter with a pair of poles. The following example illustrates a wideband
bandpass ﬁlter design by the method of pole-zero placement.
Example
18.37
The objective is to design a wideband bandpass ﬁlter with a passband of π/4 < ω <
3π/4, by placing poles in the vicinity of the passband and zeros within or nearby the
stopband.
Solution
a.
We place 10 zeros on the unit circle at e± jωk, where ωk = ±(1 + 2k)π/40,
k = 0, 1, 2, 3, and 4. The zeros on the right-half side of the circle produce a
stopband from ω = 0 to π/4. The mirror images, with respect to the j axis (the
axis of ω = π/2), of those zeros produce a stopband from ω = 3π/4 to π. To
provide the passband we place 10 poles at 0.9e± jωk, where ωk = π/2 ± (1 + 2k)
π/40, , k = 0, 1, 2, 3, and 4. These poles, in conjunction with their complex
conjugates, provide the passband from ω = π/4 to 3π/4. The pole-zero
constellation and the resulting magnitude response are shown in Figure 18.9(a)
(upper row). Because the zeros are located on the unit circle, the magnitude plot
has 10 zeros (shown by an inﬁnite dB attenuation).
b.
We move the zeros of part a inside the unit circle to a distance of 0.7 from the
origin and maintain the same angles as before. We also add 10 more zeros
which are their mirror images with respect to the unit circle (at a distance of
1/0.7 from the origin). The poles are kept inside the circle at their previous
locations. There are no zeros on the unit circle. See Figure 18.9(b) (lower row).
The Matlab program used to design the above ﬁlter can also be used to explore
the effect on the ﬁlter’s performance, of changing the number of poles or zeros
and their distances from the origin.

Signals and Systems
1047
−1
0
1
−1
0
1
Real parts
Imaginary parts
0
1
−200
−180
−160
−140
−120
−100
−80
−60
−40
−20
0
Digital angular frequency (rad/s, in units of π)
Gain (dB)
−200
−180
−160
−140
−120
−100
−80
−60
−40
−20
0
Gain (dB)
−1.5
−0.5
0.5
1.5
−1
0
1
−1.5
−0.5
0.5
1.5
−1.5
−0.5
0.5
1.5
−1
0
1
Imaginary parts
−1.5
−0.5
0.5
1.5
(a)
(b)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
1
Digital angular frequency (rad/s, in units of π)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
20
Real parts
FIGURE 18.9 Two bandpass ﬁlters designed by the pole-zero placement method. See Example 18.37.
18.10
FIR Filter Design
The unit-sample response of an FIR ﬁlter has a ﬁnite length and its system function
has no poles (poles at the origin are not considered). FIR ﬁlters may be designed based
on one of three methods: (1) placing zeros of the system function at the desired loca-
tions in the z-plane (and no poles), (2) windowing a desired unit-sample response, and
(3) sampling a desired frequency response. Examples of FIR ﬁlter design by zero-
placement have already been given. In this section we introduce the two other methods.

1048
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
FIR Filter Design by Windowing
In FIR design by windowing one takes the inverse DTFT of a desired frequency response
(e.g., an ideal low-pass ﬁlter) and multiplies it by a ﬁnite-duration window. Truncating
the unit-sample response of an ideal ﬁlter to make it of ﬁnite length is mathematically
equivalent to multiplying it with a rectangular window of ﬁnite length M, the simplest of
windows. It could be easily shown that for a given window length, a rectangular window
minimizes the rms of error between the ideal and practical frequency responses. But
the rectangular window has drawbacks and, therefore, other types are considered (with
trade-offs). The rectangular window’s major drawback is the ringing at the transition
frequencies due to Gibbs’ phenomenon, which cannot be overcome by increasing the
window length. Therefore, in FIR design by windowing, given desired speciﬁcations
(e.g., Ap, ωp and As, ωs) two questions are considered:
1.
How long should the window be?
2.
What type of window should be used?
Consideration of the above two factors requires a measure of error and a set of
speciﬁcations to judge the performance of the actual ﬁlter compared with the desired
frequency response.
Theory
Let h(n) and H(ω) be the unit-sample and frequency responses of the desired ﬁlter,
respectively. Let h(n) = h(n) × w(n) be a ﬁnite segment of h(n) seen and weighted
through a window w(n) of length M. The frequency response of the FIR ﬁlter is obtained
from the convolution of the frequency response of the window with that of the desired
ﬁlter.
H(ω) = 1
2π H(ω) ⋆W(ω)
As an example, consider an ideal low-pass ﬁlter h(n) with cutoff frequency at ω0 and
k units of delay. An M-tap low-pass FIR ﬁlter is obtained by multiplying h(n) with a
rectangular window of length M, k = (M −1)/2. The following table summarizes the
unit-sample and frequency responses of the ideal ﬁlter, the rectangular window, and the
resulting FIR ﬁlter.
An M-Tap Low-Pass FIR Filter Under a Rectangular Window
Ideal low-pass delayed ﬁlter
h(n) = sin[ω0(n−k)]
π(n−k)
H(ω) =
 e−jkω
−ω0 < ω < ω0
0,
elsewhere
delay: k = (M −1)/2
M-tap rectangular window
w(n) =
 1,
0 ≤n ≤M −1
0,
elsewhere
W(ω) =
sin( ωM
2 )
sin( ω
2 ) e−jkω
M-tap low-pass FIR ﬁlter
h(n) =
 sin[ω0(n−k)]
π(n−k)
,
0 ≤n ≤M −1
0,
elsewhere
H(ω) =
1
2π H(ω) ⋆W(ω)

Signals and Systems
1049
Figure 18.10 shows, in the time and frequency domains, the ideal ﬁlter, the rectan-
gular window, and the resulting FIR ﬁlter for ω = π/5 and M = 31. Note the Gibbs’
effect at the transition band of the FIR ﬁlter.
–15
–20
–10
–5
0.25
0
0
5
10
15
20
Discrete time (n)
–15
–20
–10
–5
1
0
0
5
10
15
20
Discrete time (n)
–0.4
–0.5
–0.3 –0.2 –0.1
0
1
0
0.1
0.2
0.3
0.4
0.5
Frequency f(Hz)
(a)
(b)
Hr(f)
–0.4
–0.5
–0.3 –0.2 –0.1
40
30
20
10
0
–10
0
0.1
0.2
0.3
0.4
0.5
Frequency f(Hz)
h(n)
–15
–20
–10
–5
0.25
0
0
5
10
15
20
Discrete time (n)
(c)
–0.4
–0.5
–0.3 –0.2 –0.1
1
0
0
0.1
0.2
0.3
0.4
0.5
Frequency f(Hz)
Time domain
Frequency domain
FIGURE 18.10 A discrete-time ideal low-pass ﬁlter with cutoff frequency at 0.1 Hz (top row); a 31-tap rectangular
window (middle row); the resulting 31-tap FIR ﬁlter (bottom row) based on the rectangular window. Time-domain
characteristics are shown in the left column. The frequency-domain characteristics (in the right column) are shown by
H(ω) = Hr(ω)e jθ. Because of no time shift and even symmetry in h(n), we have θ = 0 and H(ω) = Hr(ω).
In summary, the unit-sample response of the FIR ﬁlter is found by multiplying the
unit-sample response of the corresponding ideal ﬁlter with a window of ﬁnite length M.

1050
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Several windows of interest in digital signal processing have been introduced already.
Each window type provides a trade-off between attenuation in the stopband, ripples in
the passband, and the length of the transition bandwidth. For example, a rectangular
window has a sharp transition but contains ringing (Gibbs’ effect). As M →∞, the
transition band narrows and the frequency response of the FIR ﬁlter approaches that of
the ideal ﬁlter except at the neighborhood of the cutoff frequency ω0. The ringings persist
regardless of how wide the window is. To remedy this, one may use a window type such
as Hanning, Hamming, Blackman, or Kaiser, which eliminate the ringing but widen
the transition band. Example 18.38 and Figure 18.11 illustrate the contrast between the
rectangular and Hamming windows.
0
1
Magnitude (linear scale)
0
1
−60
−50
−40
−30
−20
−10
0
Magnitude (dB)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Angular frequency (rad/s, in units of π)
−80
−70
−60
−50
−40
−30
−20
−10
0
Magnitude (dB)
0
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Angular frequency (rad/s, in units of π)
Angular frequency (rad/s, in units of π)
(a) 31-tap rectangular window
(b) 31-tap hamming window
Angular frequency (rad/s, in units of π)
0
1
Magnitude (linear scale)
FIGURE 18.11 (For Example 18.38) Magnitude responses of two low-pass FIR ﬁlters designed through window-
ing the unit-sample response of an ideal ﬁlter. Filter 1 (left column) uses a rectangular window and ﬁlter 2 uses the
Hamming window. Both are 31 samples long. The top row shows the magnitudes in linear scale and the bottom in dB.
Gibbs’ phenomenon, which manifested itself in ﬁlter 1 (rectangular window), disappears in ﬁlter 2 (Hamming window).
The transition band is enlarged when using a Hamming window.

Signals and Systems
1051
Example
18.38
Two low-pass FIR ﬁlters were designed by windowing the unit-sample response of
an ideal ﬁlter with cutoff frequency at ω0 = π
2 . Filter 1 (left column in Figure 18.11)
uses the rectangular window and ﬁlter 2 uses the Hamming window, both 31 samples
long. Magnitude responses of the two ﬁlters are shown in Figure 18.11 (linear scale
on the top row, and dB scale on the bottom). The ringing in the rectangular window
shows the contrast between the two windows. Gibbs’ phenomenon, which manifests
itself in ﬁlter 1 (rectangular window), disappears in ﬁlter 2 (Hamming window). The
transition band is enlarged under the Hamming window.
FIR Filter Design by the Frequency Sampling Method
The frequency response, being the DTFT of the unit-sample response, is a function of
continuous variable ω and is periodic with a period 2π. For an FIR ﬁlter of length M, it
is found from the expression
H(ω) =
M−1

n=0
h(n)e−jωn
where h(n) is the unit-sample response of the ﬁlter. Consider samples of H(ω) taken
uniformly every 2π
M rad/s at the following equally spaced frequencies:
ωk = 2πk
M ,

k = 0, 1, · · · , M−1
2 ,
M odd
k = 0, 1, · · · , M
2 ,
M even
Call these Hk. This provides M samples within the range of ω = 0 to 2π. Then,
Hk ≡H(ωk) =
M−1

n=0
h(n)e−jωkn =
M−1

n=0
h(n)e−j 2πkn
M , k = 0, 1, · · · , M −1
The sampling produces M samples within the range of ω = 0 to 2π, with the ﬁrst one
starting at ω = 0 and the last one at 2π −2π/M. By knowing M sample values Hk we
have M independent equations that can be solved for h(n), n = 1, 2, · · · , M. In fact,
the equation relating Hk to h(n) is the M-point DFT operation on h(n). Taking the IDFT
of the sequence of samples will give us h(n).
h(n) = 1
M
M−1

k=0
Hke j 2πkn
M , n = 0, 1, · · · , M −1
Needless to say, if the unit-sample response of the ﬁlter is to be real valued, the set of
Hk should possess properties expected from the DFT of a real-valued sequence. Also,
needless to say that the frequency response of the design outcome is
Hs(ω) =
M−1

n=0
h(n)e−jωn
which is a function of the continuous variable ω. The values of Hs(ω) at ω = 2πk
M are

1052
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
equal to the given sample values. At other frequencies, however, Hs(ω) differs from the
values of H(ω).
18.11
IIR Filter Design
The unit-sample response of an IIR ﬁlter has an inﬁnite length and its system function
contains poles (and possibly zeros). An IIR ﬁlter may be designed by choosing the
location of its poles and zeros such that the resulting frequency response acquires the
desired characteristics. This method was illustrated in section 18.9 and has been used
in some examples previously. An IIR ﬁlter is also designed by transforming an analog
counterpart to the discrete-time domain. Two such methods will be presented in the
following.
IIR Filter Design by Impulse-Invariant Transformation
In the impulse-invariant transformation from s to z, the continuous-time angular fre-
quency 
 (asssociated with the prototype ﬁlter) and the discrete-time angular frequency
ω (associated with the design objective) are related through the following linear rela-
tionship:

 = ω × Fs,
where Fs is the sampling rate
Consequently, the prototype analog ﬁlter is the same as a ﬁlter made of the digital ﬁlter
operating along with the A/D and D/A converters working at the sampling rate of Fs.
In the impulse-invariant transformation method, the unit-sample response of the digital
ﬁlter is found by sampling the unit-impulse response of the analog ﬁlter every T second
(a sampling rate of Fs = 1/T Hz). To distinguish between the two domains, a subscript is
added (c for continuous time and d for discrete time) in the time and frequency domains.
Therefore, hd(n) = hc(nT ), where hd(n) is the unit-sample response of the digital ﬁlter
and hc(t) is that of the analog ﬁlter. The system function of the digital ﬁlter Hd(z) is
then found by taking the z-transform of hd(n). Hd(z) can also be found directly from
Hc(s). For this purpose, start with the example of exponential function
Continuous time: hc(t) = eatu(t)
Hc(s) =
1
s −a , σ > a
Discrete time:
hd(n) = eaT nu(n)
Hd(z) =
∞

n=−∞
hd(n)z−n =
∞

n=0
eaT nz−n =
1
1 −eaT z−1 , |z| > eaT

Signals and Systems
1053
An H(s) of higher order can be expanded into its fractions and then transformed as
above.
Example
18.39
Find hd(n) and Hd(z) of a ﬁrst-order low-pass digital IIR ﬁlter, which is to have a
0-dB DC gain and a 3-db attenuation frequency of 4.8 kHz when interfaced with an
ensemble of A/D and D/A converters operating at a 48-kHz sampling rate.
Solution
The 3-dB attenuation angular frequency of the digital ﬁlter is ω0 = 
0/Fs = (2π ×
4.8)/48 = 0.2π. The performance of the ensemble is equivalent to the performance
of an analog ﬁlter with
H(s) =

0
s + 
0
, where 
0 = 2π × 4,800 = 9,600π
Consequently, the prototype analog ﬁlter has the same system function as the equiv-
alent ﬁlter.
Hc(s) =

0
s + 
0
,
hc(t) = 
0e−
0tu(t)
By sampling hc(t) every T =
1
48 msec we ﬁnd
hc(nT ) = 
0e−ω0nu(n), where ω0 =

0
48,000
If the overall gain is adjusted through AD/DA segments, then the unit-sample response
of the digital ﬁlter is
hd(n) = e−ω0nu(n), with Hd(z) =
1
1 −z0z−1 ,
where z0 = e−ω0
Note that a direct transformation of Hc(s) will result in the above Hd(z).
IIR Filter Design by Bilinear Transformation
The bilinear tranformation from s to z is given by
s = 2
T
1 −z−1
1 + z−1
In the case of real frequencies, s = j
 and z = e jω. The effect of the bilinear transfor-
mation on real frequencies is, therefore, obtained by substituting the above values for s
and z in the transformation equation.
j
 = 2
T
1 −e−jω
1 + e−jω = j 2
T tan
ω
2


1054
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Asseenbelow,thebilineartranformationconvertsthecontinuous-timeangularfrequency

 to the discrete-time angular frequency ω by the following nonlinear relationships:

 = 2
T tan
ω
2

(to be called frequency warping)
ω = 2 tan−1

T
2

,
where T is the sampling interval.
Consequently, the H(s) that is be transformed needs to account for the aforementioned
nonlinear effect by setting different speciﬁcations (e.g., a new 3-dB analog frequency 
0
for a ﬁrst-order ﬁlter) while keeping the same functional form as the desired equivalent
analog ﬁlter. This is illustrated in Example 18.40.
Example
18.40
Bilinear transformation of a first-order filter
In the present case, the 3-dB attenuation angular frequency of the digital ﬁlter is
ωd = 0.2π. The warped 3-dB frequency is

0 = 2
T tan
ωd
2

= 2
T tan(0.1π)
At this stage we refrain from substituting for T . Soon it will be noted that use of
frequency warping and the bilinear transformation causes T to be canceled. The
H(s) to be transformed is, therefore,
H(s) =

0
s + 
0
We next transform the above H(s) to H(z) by the following steps:
s = 2
T
1 −z−1
1 + z−1
H(z) = H(s)

s= 2
T
1−z−1
1+z−1
=

0
2
T
1−z−1
1+z−1 + 
0
=
2
T tan(0.1π)
2
T
1−z−1
1+z−1 + 2
T tan(0.1π)
=
(1 + z−1) tan(0.1π)
(1 −z−1) + (1 + z−1) tan(0.1π)
= 0.2452
1 + z−1
1 −0.5095z−1
We can see that in contrast with the impulse-invariant transformation, frequency
speciﬁcations of the digital ﬁlter are independent of the sampling rate under which
the ﬁlter operates.

Signals and Systems
1055
18.12
Filter Structures
A ﬁlter processes the input and obtains the output through three types of operations:
delay, multiplication, and addition, as evidenced from the difference equation, system
function, or convolution sum. These operations are done by three elements that are
either physical or conceptual, or implemented through hardware or software tools. The
elements are represented in Figure 18.12.
x(n)
x(n – 1)
z–1
A + B
∑
(a) A unit delay
x(n)
a x(n)
(b) A multiplier
(c) An adder
A
a
B
FIGURE 18.12 Processing elements in a discrete-time system.
Implementation of a ﬁlter (as a hardware or by a software program) requires an
interconnected set, or network, of the above elements, which according to the ﬁlter’s
description produces the output y(n) to an incoming x(n). Such a network is called
ﬁlter’s structure. Implementation may be achieved through different structures. Each
structure is associated with the memory requirements, computational complexity, and
accuracy limitations (i.e., the effect of ﬁnite-word length). Such considerations play
a central role in choosing a structure that is best suited for a situation. An analysis
of resources or design processes that would determine the best structure for a ﬁlter
are not addressed in what follows. The aim is limited to presenting several commonly
used structures for FIR and IIR ﬁlters, and brieﬂy pointing out some obvious choice
criteria.
FIR Filter Structure
The output of a causal FIR ﬁlter with a unit-sample response of length M may be obtained
by convolving the input and the unit-sample response
y(n) =
N

k=0
h(k)x(n −k)
where N = M −1 is the order of the ﬁlter, or equally by applying the system function
H(z) =
N

k=0
h(k)z−k
In this section we present two types of structures for implementing FIR ﬁlters. These are
1.
Direct-form structures (Figures 18.13, 18.14, and 18.15).
2.
Cascade structures (Figure 18.16).

1056
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Direct-Form Structure for FIR Filters
This form directly implements a ﬁlter’s equation. The multipliers in the structure are
coefﬁcients of the system function. The implementation is also called a tapped delay
line or a transversal ﬁlter. Figure 18.13 is a direct-form structure for a ﬁlter
H(z) = h(0) + h(1)z−1 + h(2)z−2 + · · · + h(N −1)z−(N−1) + h(N)z−N
where N = M −1 is the order of the ﬁlter. They employ M −1 delay elements, M
multipliers, and M −1 two-input adders.
x(n)
y(n)
z–1
z–1
h(0)
h(1)
h(2)
∑
∑
z–1
h(3)
∑
h(M – 2)
∑
z–1
h(M – 1)
∑
FIGURE 18.13 Realization of FIR ﬁlter of length M by a direct-form structure.
Example
18.41
The two structures shown in Figure 18.14(a) and (b) implement the FIR ﬁlter with
h(n) = {3
↑, 5, 3} and the two structures shown in Figure 18.14(c) and (d) implement
h(n) = {3
↑, 5, 5, 3}.
x(n)
y(n)
y(n)
z–1
z–1
3
5
3
∑
∑
x(n)
x(n)
z–1
z–1
3
5
5
∑
∑
y(n)
z–1
3
∑
z–1
z–1
3
5
∑
∑
y(n)
x(n)
z–1
z–1
z–1
3
∑
∑
∑
5
(a) Direct-from structure for
y(n) = 3x(n) + 5x(n – 1) + 3x(n – 2).
(c) Direct-from structure for
y(n) = 3x(n) + 5x(n – 1) + 5x(n – 2) + 3x(n – 3).
(b) A more efficient structure for (a).
(d) A more efficient structure for (c).
FIGURE 18.14 Direct-form structures for the FIR ﬁlters of Example 18.41.

Signals and Systems
1057
Cascade Structure for FIR Filters
The system function of an FIR ﬁlter may be factored as the product of smaller subsystems
such as ﬁrst-order and second-order sections.
H(z) = H0(1 + α1z−1 + β1z−2)(1 + α2z−1 + β2z−2) · · · (1 + αK z−1 + βK z−2)
Each subsystem can be realized by a direct-form structure and placed in cascade of each
other. See Figure 18.15.
x(n)
y(n)
z–1
∑
∑
∑
z–1
∑
α1
β1
z–1
z–1
∑
α2
β2
z–1
z–1
∑
αk
βk
FIGURE 18.15 Cascade structure for FIR ﬁlter.
IIR Filter Structure
An IIR ﬁlter of order N is described by the difference equation
y(n) = −
N

k=1
ak y(n −k) +
M−1

k=0
bkx(n −k)
or by the system function
H(z) =
M−1

k=0
bkz−k
 
1 +
N

k=1
akz−k

Two types of structures will be presented here to implement IIR ﬁlters. These are
1.
Direct-form structures (Figures 18.16 and 18.17).
2.
Cascade structures (Figure 18.18).
Direct-Form Structure for IIR Filters
The difference equation describing an IIR ﬁlter is
y(n) +
N

k=1
ak y(n −k) =
M−1

k=0
bkx(n −k) ≡w(n)

1058
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
where each side of the equation is also represented by a new variable w(n). From the
right-hand side we obtain the FIR equation
w(n) =
M−1

k=0
bkx(n −k)
whichcanbeimplementedbytheforwardstructureshownontheleftsideofFigure18.16.
From the left-hand side we obtain the IIR equation
y(n) +
N

k=1
ak y(n −k) = w(n)
which can be implemented by the feedback structure shown on the right side of
Figure 18.16. The two subsystems of Figure 18.16(a) are transposed and combined
to form the structures of Figure 18.16(b) and (c).
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
z–1
∑
∑
∑
∑
z–1
z–1
z–1
z–1
∑
∑
∑
∑
x(n)
y(n)
w(n)
∑
∑
∑
∑
∑
∑
∑
x(n)
y(n)
∑
∑
∑
∑
x(n)
b0
–a1
b1
–a2
b2
–a3
b3
–a4
b4
y(n)
∑
∑
∑
∑
(a)
(b)
(c)
∑
FIGURE 18.16 (a) Realization of an IIR ﬁlter by a set of feed-forward loops (left side) and feedback loops (right side)
produces the direct-form I structure shown here. Transposing the two segments in (a) produces the structure shown in
(b). The two sets of unit delays in the forward and feedback segments of the structure in (b) may be combined, resulting
in a smaller number of delay units as well as adders (c).

Signals and Systems
1059
Example
18.42
An IIR ﬁlter is described by
y(n) + a1y(n −1) = b0x(n) + b1x(n −1)
Construct the block diagram of the right side of the equation as a feed-forward loop
and that of the left side as a feedback loop. Cascade them as shown in Figure 18.17(a)
and you have direct-form I structure of the IIR ﬁlter. Transpose the feed-forward and
feedback equivalent block diagrams of the above ﬁlter.
Solution
Let the output of the ﬁrst adder in Figure 18.17(a) be w(n). The IIR ﬁlter consists of
the following LTI systems in series.
Feed-forward system: w(n) = b0x(n) + b1x(n −1),
H1(z) = W(z)
X(z) = b0 + b1z−1
Feedback system:
y(n) = −a1y(n −1) + w(n),
H2(z) = Y(z)
W(z) =
1
1 + a1z−1
The IIR ﬁlter:
y(n) = −a1y(n −1) + b0x(n) + b1x(n −1), H(z) = Y(z)
X(z) = b0 + b1z−1
1 + a1z−1
H(z) = H1(z)H2(z) = H2(z)H1(z)
x(n)
y(n)
w(n)
z–1
∑
∑
z–1
b1
–a1
b0
x(n)
y(n)
v(n)
z–1
∑
∑
z–1
b1
–a1
b0
x(n)
v(n)
y(n)
z–1
∑
∑
–a1
b1
b0
(a)
(b)
(c)
FIGURE 18.17 (a), (b), (c). Direct-form I structure for realizations of the IIR ﬁlter y(n) + a1y(n −1) = b0x(n) +
b1x(n −1). See Example 18.42.

1060
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
The order of H1 and H2 may be exchanged resulting in Figure 18.17(b). This result
may also be derived directly through convolution. Let h1(n) and h2(n) be the unit-
sample responses of the feed-forward and the feedback segments, respectively. Then,
Feed-forward system:
w(n) = x(n) ⋆h1(n)
Feedback system:
y(n) = w(n) ⋆h2(n)
The IIR ﬁlter:
y(n) = [x(n) ⋆h1(n)] ⋆h2(n) = [x(n) ⋆h2(n)] ⋆h1(n)
Due to the associative property of the convolution the order of the feed-forward and the
feedback
segments
may
be
exchanged
producing
the
block
diagram
of
Figure 18.17(b). The two unit delays in Figure 18.17(b) perform a redundant func-
tion to Figure 18.1(b). They may be replaced by a single unit delay resulting in
Figure 18.17(c). See also Example 12.21 in Chapter 12.
Cascade Structure for IIR Filters
An IIR system function can be written as a cascade of subsystems of lower order. This
is done by factoring its numerator and denominator into polynomials of ﬁrst or second
order. As in the case of FIR, each subsystem can be implemented by a direct-form
structure. Figure 18.18 shows implementation of
H(z) =
b01 + b11z−1
1 + a11z−1
 b02 + b12z−1 + b22z−2
1 + a12z−1 + a22z−2
 b03 + b13z−1 + b23z−2
1 + a13z−1 + a23z−2

x(t)
y(t)
z–1
∑
∑
–a11
b11
b02
b01
z–1
∑
∑
–a12
b12
z–1
∑
∑
–a22
b22
b03
z–1
∑
∑
–a13
b13
z–1
∑
∑
–a23
b23
FIGURE 18.18 Cascade structure of a ﬁfth-order IIR ﬁlter.
18.13
Problems
Solved Problems
Note: It is highly recommended that in doing the problems in this chapter, analytic solutions be supplemented
with the use of computer code (such as Matlab) to facilitate further analysis, exploration, and design.

Signals and Systems
1061
1. A causal LTI system is described by the input-output difference equation
y(n) −0.3y(n −1) −0.4y(n −2) = x(n)
a. Draw its block diagram as a direct-form structure.
b. Use the block diagram to determine the values of its unit-sample response h(n) for n = 0, 1, 2, 3, and 4.
c. Determine its system function, pole(s), and zero(s).
d. Find a closed-form expression for h(n) using the z-transform.
e. Do part d by solving the difference equation in the time domain.
Solution
a. In Figure 18.16(c), let b0 = 1, bk = 0, k ≥1, a1 = −0.3, a2 = −0.4, and ak = 0, k ≥3.
b. h(n) =















n < 0, x(n) = 0,
h(n) = 0
n = 0, x(0) = 1,
h(0) = x(0) = 1
n = 1, x(1) = 0,
h(1) = 0.3h(0) = 0.3000
n = 2, x(2) = 0,
h(2) = 0.3h(1) + 0.4h(0) = 0.4900
n = 3, x(3) = 0,
h(3) = 0.3h(2) + 0.4h(1) = 0.2670
n = 4, x(4) = 0,
h(4) = 0.3h(3) + 0.4h(2) = 0.2761
c. Y(z) −0.3z−1Y(z) −0.4z−2Y(z) = X(z), H(z) = Y(z)
X(z) =
1
1 −0.3z−1 −0.4z−2
Poles: p2 −0.3p −0.4 = 0, p1 = 0.8, p2 = −0.5
Zeros: z0 = 0
d.
H(z) =
1
1 −0.3z−1 −0.4z−2 =
A
1 −0.8z−1 +
B
1 + 0.5z−1
A = H(z)(1 −0.8z−1)

z=0.8 =
1
1 + 0.5z−1

z=0.8 = 8
13 = 0.6154
B = H(z)(1 + 0.5z−1)

z=−0.5 =
1
1 −0.8z−1

z=−0.5 = 5
13 = 0.3846
h(n) = 
0.6154(0.8)n + 0.3846(−0.5)n
u(n)
e.
h(n) −0.3h(n −1) −0.4h(n −2) = d(n)
h(0) = 0.3h(−1) + 0.4h(−2) + 1 = 1
h(1) = 0.3h(0) + 0.4h(−1) = 0.3
h(n) = A(0.8)n + B(−0.5)n, n ≥0, h(0) = 1, h(1) = 0.3
A and B:
 n = 0,
A + B = 1
n = 1,
0.8A −0.5B = 0.3
⇒
A = 8
13, B = 5
13
y(n) = 0.6154(0.8)n + 0.3846(−0.5)n, n ≥0
2. Consider the causal system y(n) −0.3y(n −1) −0.4y(n −2) = x(n) described in problem 1.
a. Given y(−2) = 19/16, y(−1) = 7/4, and x(n) = 0, n ≥0, use the block diagram to compute y(n) for
n = 0, 1, 2, 3, and 4.

1062
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
b. Given the conditions in (part a) ﬁnd a closed-form expression for y(n), n ≥0, using the z-transform.
c. Do part b by solving the difference equation in the time domain.
Solution
a. y(n) =

























n = −2
y(−2) = 19
16
n = −1
y(−1) = 7
4
n = 0
y(0) = 0.3y(−1) + 0.4y(−2) = 0.3 × 7
4 + 0.4 × 19
16 = 1
n = 1
y(1) = 0.3y(0) + 0.4y(−1) = 0.3 + 0.4 × 7
4 = 1
n = 2
y(2) = 0.3y(1) + 0.4y(0) = 0.3 + 0.4 = 0.7
n = 3
y(3) = 0.3y(2) + 0.4y(1) = 0.21 + 0.4 = 0.61
n = 4
y(4) = 0.3y(3) + 0.4y(2) = 0.183 + 0.28 = 0.463
b. y(n) −0.3y(n −1) −0.4y(n −2) = 0, n ≥0
Y(z) −0.3[z−1Y(z) + y(−1)] −0.4[z−2Y(z) + y(−1)z−1 + y(−2)] = 0
Y(z) −0.3

z−1Y(z) + 7
4

−0.4

z−2Y(z) + 7
4 z−1 + 19
16

= 0
Y(z) =
1 + 0.7z−1
1 −0.3z−1 −0.4z−2 =
1 + 0.7z−1
(1 −0.8z−1)(1 + 0.5z−1) =
A
1 −0.8z−1 +
B
1 + 0.5z−1
A = Y(z)(1 −0.8z−1)

z=0.8 = 1 + 0.7z−1
1 + 0.5z−1

z=0.8 = 15
13 = 1.1538
B = Y(z)(1 + 0.5z−1)

z=−0.5 = 1 + 0.7z−1
1 −0.8z−1

z=−0.5 = −2
13 = −0.1538
y(n) = 1.1538(0.8)n −0.1538(−0.5)n, n ≥0
c. r 2 −0.3r −0.4 = 0, r = 0.8,
−0.5
y(n) = A(0.8)n + B(−0.5)n, n ≥0, y(0) = y(1) = 1
Finding A and B:

n = 0,
A + B = 1
n = 1,
0.8A −0.5B = 1
⇒
A = 15
13 = 1.1538, B = −2
13 = −0.1538
y(n) = 1.1538(0.8)n −0.1538(−0.5)n, n ≥0
3. Consider again the causal system of problem 1, y(n) −0.3y(n −1) −0.4y(n −2) = x(n). Let it be known that
(i) y(n) = 0 for n < −1, (ii) y(−1) = 1, and (iii) x(n) = 0, for n ≥0.
a. Find y(0) and y(1).
b. Determine y(n).
c. Argue that x(n) = d(n + 1) and, therefore, we expect y(n) = h(n + 1).
d. Verify that y(n) = h(n + 1), where h(n) is the unit-sample response obtained in problem 1.

Signals and Systems
1063
Solution
a. y(0) = 0.3y(−1) + 0.4y(−2) = 0.3
y(1) = 0.3y(0) + 0.4y(−1) = 0.49
b. y(n) = A(0.8)n + B(−0.5)n, n ≥0, y(0) = 0.3, y(1) = 0.49
A and B:
 n = 0,
A + B = 0.3
n = 1,
0.8A −0.5B = 0.49
⇒
A = 64
130 = 0.4923, B = −25
130 = −0.1923
y(n) =



0,
n < −1
1,
n = −1
0.4923(0.8)n −0.1923(−0.5)n, n ≥0
c. Fromthesystem’scausalityandthegiveninformationthat y(n) = 0forn < 1,weconcludethat x(n) = 0, n < 1.
It is also given that x(n) = 0, n ≥1. Therefore, x(n) = X0d(n + 1) and y(n) = X0h(n + 1). To determine X0
we note that y(−1) = 1 and h(0) = 1. Therfore, X0 = 1.
d. y(n) = d(n + 1) + [0.4923(0.8)n −0.1923(−0.5)n] u(n)
h(n) = 
0.6154(0.8)n + 0.3846(−0.5)n
u(n) from problem 1.
h(n + 1) = (0.6154 + 0.3846)d(n + 1) + 
0.8 × 0.6154(0.8)n −0.5 × 0.3846(−0.5)n
u(n + 1)
= d(n + 1) + 
0.4923(0.8)n −0.1923(−0.5)n
u(n) = y(n)
4. A discrete-time system is described by the system function H(z) = 1−z−1. Use the vectorial interpretation of H(z)
to evaluate H(ω) at ω = 0, π/4, π/2 , 3π/4, and π. Sketch the magnitude and phase of H(ω).
Solution
The system function is H(z) = 1−z−1 = (z −1)/z. It has a pole at z = 0 (shown by point A on Figure 18.19a) and
a zero at z = 1 (shown by point B). Let C designate the location of z on the unit circle at which H(ω) is evaluated.
Then, H(ω) = BC/AC and from the graphical representation of Figure 18.19(a) we have the follwing:
Location of z ω
H(ω) = BC/AC
|H(ω)| = |BC|
̸ H(ω) = ̸ BC −ω
Comments
C0
0
BC0/AC0
0
90◦
Zero of the system
C1
π/4
BC1/AC1
0.8
67.5◦
C2
π/2
BC2/AC2
√
2
45◦
3-dB frequency, |H| = |HMax |
√
2
C3
3π/4
BC3/AC3
1.84
22.5◦
C4
π
BC4/AC4
2
0◦
|HMax| = 2
The frequency response is plotted in Figure 18.19(b). The 3-dB (half-power) frequency is at ω = π/2.
Remark
The system of problem 4 is a difference operator, h(n) = d(n) −d(n −1). In the frequency domain, it can exhibit
high-pass ﬁltering, a property shared by continuous-time differentiators.

1064
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Unit circle
Re[z]
Im[z]
C3
C2
C1
C0
C
C4
B
A
Pole
Zero
(a)
(b)
1
2
0
w
p
2 
p
4
p
4
3
p
|H(w)|
90°
45°
0
w
p
2 
p
4
p
4
3
p
q(w)
FIGURE 18.19 (For problem 4) Evaluation of the frequency response of the system H(z) =
1 −z−1 at ω = 0, π/4, π/2 , 3π/4, and π using the vectorial interpretation: (a) Pole-zero plot,
(b) sketch of H(ω).
5. A discrete-time causal system is described by the system function
H(z) =
1 + z−1
1 −1.8z−1 + 0.81z−2
Use the vectorial interpretation of H(z) to evaluate H(ω). Show that the system is a low-pass ﬁlter. Find the 3-dB
frequency ωα. Evaluate H(ω) at ω = 0, ωα, π/4, π/2, 3π/4, and π. Sketch the magnitude and phase of H(ω).
Solution
The system function is
H(z) =
1 + z−1
1 −1.8z−1 + 0.81z−2 =
1 + z−1
(1 −0.9z−1)2 = z(z + 1)
(z −0.9)2
It has repeated poles at p = 0.9 (shown by point A on Figure 18.20a) and two zeros at z = 0 and z = −1 (shown
by points B0 and B1, respectively). Let C designate the location of z on the unit circle at which H(ω) is evaluated.

Signals and Systems
1065
Then, at z = e jω we have
z = B0C,
z + 1 = B1C,
z −0.9 = AC
H(ω) = H(z)

z=e jω = B0C × B1C
AC
2
|H(ω)| = |B1C|
|AC|2
̸ H(ω) = ω + ̸ B1C −2̸ AC
It is clear from the pole-zero plot that |H(ω)| is at its maximum when ω = 0, where H(0) = 200. Nearby, in the
vicinity of ω = 0, the zero vectors B0C and B1C don’t change appreciably, and their contribution to H(ω) remains
almost at a constant value: B0C × B1C ≈2. Therefore, for small ω [which includes the 3-dB frequency ωα, see
Figure 18.20(b)] we will have
H(ω) =
2
AC
2 , and H(0) =
2
0.12 = 200
H(ωα) =
2
ACα
2 = 200
√
2
|ACα| ≈0.11892
|C0Cα| ≈ωα = 3.9◦
|H(ωα)| ≈141.42
̸ H(ωα) ≈−2 tan−1[ωα/(1 −0.9)] = −65.5◦
From the graphical representation of Figure 18.20(a) we complete the table below [see Figure 18.20(c) and (d)].
Location of z
ω
H(ω)
|H(ω)|
̸ H(ω)
Comments
C0
0
B0C0 × B1C0/AC0
2
200
0◦
|HMax| = 200
Cα
3.90
B0Cα × B1Cα/ACα
2
141.42
−63.8◦
|H| = |HMax |
√
2 , 3-dB frequency
C1
45◦
B0C1 × B1C1/AC1
2
3.44
−143◦
C2
90◦
B0C2 × B1C2/AC2
2
0.78
−129◦
C3
135◦
B0C3 × B1C3/AC3
2
0.25
−110◦
C4
180◦
B0C4 × B1C4/AC4
2
0
−90◦
Zero of the system

1066
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Unit circle
Im[z]
C3
C2
C1
C
C4
C0
B1
(zero)
B0
(zero)
A
(double pole)
Re[z]
Re[z]
C0
ωα = 3.9°
Cα (3.9°)
B1 and B0
(distant zeros)
A
(double pole at z = 0.9)
32°
π
4
π
2 
π
4
3
π
|H(ω)|
ωα 
ω
3.44
0
100
141.41
200
θ(ω)°
π
4
π
2 
π
4
3
π
ωα 
–63.8
–90
–90
–110
–109
–129
–129
–143
–143
ω
(a)
(b)
(c)
(d)
FIGURE 18.20 (For problem 5) Evaluation of the frequency response of a system having a repeated pole at p = 0.9
and two zeros at z = 0 and z = −1, by the vectorial approach: (a) Pole-zero plot; (b) ﬁnding the 3-dB frequency;
(c) and (d) sketch of the frequency response.
Comparison with Theory
The square of the magnitude of the frequency response of the system of problem 5 is
|H(ω)|2 =
2(1 + cos ω)
(1.81 −1.8 cos ω)2
The 3-dB frequency may be found, approximately, from
1.81 −1.8 cos ωα =
√
2 × 10−2
⇒ωα = 3.9◦
The frequency response is shown in Figure 18.20(c) and (d).
6. The system of Example 18.25 has a zero at the origin. Move it to z = 1 to obtain a new system described by the
system function
H(z) =
1 −z−2
1 −0.9
√
2z−1 + 0.81z−2
Use the vectorial interpretation of H(z) to evaluate H(ω). Reason that |H(ω)| is at its maximum when ω = π/4.

Signals and Systems
1067
Find the 3-dB frequencies ωℓand ωh. Evaluate H(ω) at ω = 0, ωℓ, π/4, ωh, π/2 , 3π/4, and π. Compare with
the frequency response obtained in Example 18.25.
Solution
The system function is
H(z) =
(z −1)(z + 1)
(z −0.9e jπ/4)(z −0.9e−jπ/4)
As in Example 18.25, this system has a pair of poles at pa,2 = 0.9e± jπ/4 but its zeros are at z = ±1. By using the
pole-zero plot and an analysis similar to Example 18.25 we ﬁnd
H(ω) = B1C × C0C
A1C × A2C
See Figure 18.6
|H(ω)| = |B1C| × |C0C|
|A1C| × |A2C|
̸ H(ω) = [̸ B1C + ̸ C0C] −
̸ A1C + ̸ A2C
H(π/4) = 10.5̸ 3◦
ωℓ,h ≈π/4 ± 0.1 rad = 39.3◦, and 50.7◦
|H(ωℓ,h)| ≈7.4
̸ H(ωℓ,h) ≈3◦± 45◦= 48◦and −42◦
From a vectorial representation similar to that of Figure 18.6 we have the following approximations:
ω
|H(ω)|
̸ H(ω)
Comments
0◦
0
90◦
Zero of the system
ωℓ≈39.3◦
7.4
48◦
Lower 3-dB frequency, |H| = |HMax |
√
2
45◦
10.9
3◦
|HMax| = 10.9
ωh ≈50.7◦
7.4
−42◦
Upper 3-dB frequency, |H| = |HMax |
√
2
90◦
1.55
−81.5◦
135◦
0.55
−87◦
180◦
0
−90◦
Zero of the system
More exact values are
ωℓ
ω0
ωh
ω
0
39.61◦
45◦
51.64◦
90◦
135◦
180◦
|H|
0
7.43
10.51
7.43
1.55
1.55
0
̸ |H|◦
0
45.12
3.01
45.1
−81.5
−87
−90

1068
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Comparison with Example 18.25
The peak of the frequency response is still at ω = π/4 (as was the case in Example 18.25). The zero at ω = 0,
however, has pulled down the frequency response in its neighborhood, reducing |H|Max from 13.77 (Example 18.25)
to 10.9 (problem 6).
The following two problems illustrate parallels between the continuous-time and discrete-time operation of a
ﬁnite integrator, and possible errors associated with it.
7. A continuous-time ﬁnite-duration integrator. Consider the continuous-time LTI system with the unit-impulse
response consisting of an even square pulse lasting 2τ.
ha(t) =
 1,
for −τ ≤t ≤τ
0,
elsewhere
where the subscript a stands for analog. The system may be called a noncausal ﬁnite-duration analog integrator.
Given τ = 1 msec, ﬁnd its frequency response Ha(
)6 and determine its value at F = 0, 100, 400, 500, 600, 900,
and 1,000 Hz. Find its response to the input
xa(t) = 1 + cos(200πt) + cos(800πt) + cos(1,000πt) + cos(1,200πt) + cos(1,800πt) + cos(2,000πt) V.
Solution
Ha(
) =
	
∞
−∞
ha(t)e−j
tdt =
	
τ
−τ
e−j
tdt = 2sin(
τ)


τ=10−3 = 2sin(
/1,000)

See Figure 18.21(a). The input components at F = 0, 100, 400, 500, 600, 900, and 1,000 Hz correspond to angular
frequencies 
 = 2π F = 0, 200π, 800π, 1,000π, 1,200π, 1,800π, and 2,000π, respectively, and result in the
following values for the frequency response and the output.
F (Hz)
Ω= 2πF
Input (V)
Ha = 2 sin(Ω/1,000)/Ω
Output (µV)
0
0
1
0.002
−→
2,000
100
200π
cos(200πt)
2 sin(0.2π)/(200π) = 1,871 × 10−6
−→
1,871 cos(200πt)
400
800π
cos(800πt)
2 sin(0.8π)/(800π) = 468 × 10−6
−→
468 cos(800πt)
500
1,000π
cos(1,000πt)
2 sin(π)/(1,000π) = 0
−→
0
600
1,200π
cos(1,200πt)
2 sin(1.2π)/(1,200π) = −312 × 10−6
−→
−312 cos(1,200πt)
900
1,800π
cos(1,800πt)
2 sin(1.8π)/(1,800π) = −208 × 10−6
−→
−208 cos(1,800πt)
1,000
2,000π
cos(2,000πt)
2 sin(2π)/(2,000π) = 0
−→
0
The system’s output is ya(t) = 2,000 + 1,871 cos(200πt) + 468 cos(800πt) −312 cos(1,200πt) −
208 cos(1,800πt)µV. The components at 500 Hz and 1 kHz [located at the zeros of H(
)] are eliminated.
6In order to distinguish the continuous-time frequency from the discrete-time frequency, we use uppercase
letters (F and 
 = 2π F) for the continuous-time domain.

Signals and Systems
1069
–8
–6
–4
–2
0
1
0
2
4
6
8
Discrete time
h(n)
h(t)
–π
0
0
5
π
Discrete-time frequency w (rad/s)
H(w)
Continuous time
–t
t  = 1 msec
–1.25p
1.25p
0
t
Continuous-time frequency Ω (krad/s)
0
0.002
0
(a)
(b)
1
H(Ω)
Ω
w
FIGURE 18.21 (a) (Problem 7) A noncausal, ﬁnite-duration, continuous-time integrator. Its unit-impulse response
(shown on the left) consists of an even square pulse lasting slightly more than 2τ = 2 msec. ha(t) = u(t + τ)u(t −τ).
Its frequency response (shown on the right) is Ha(
) = 2 sin(
/1,000)/
, −∞< ω < ∞. Frequency axis is 
 in
rad/s and displays the segment −1,250π to 1,250π. (b) (Problem 8). A noncausal, ﬁnite-duration, discrete-time
integrator. Its unit-sample response, which consists of an even square pulse with 5 samples, is h(n) = {1, 1, 1
↑, 1, 1}. Its
frequency response is H(ω) = 1 + 2 cos ω + 2 cos(2ω) = [sin(5ω/2)/ sin(ω/2)], −∞<ω<∞. H(ω) is, however,
2π-periodic. Frequency axis is ω in rad/s, showing one period of H(ω) from −π to π. Compare with the
continuous-time integrator of (a), nothing that ω = 2,000 ω
8. A Discrete-time ﬁnite-duration integrator. The unit-impulse response of the continuous-time ﬁnite-duration
integrator in problem 7 (lasting slightly more than 2 msec) and its input are sampled at the rate of Fs = 2,000
samples per sec (every 0.5 msec, t = n/2,000, with a sample at t = 0). The unit-sample response of the resulting
discrete-time system is h(n) = {1, 1, 1
↑, 1, 1}. Likewise, the resulting discrete-time input is
x(n) = 1 + cos(0.1πn) + cos(0.4πn) + cos(0.5πn) + cos(0.6πn) + cos(0.9πn) + cos(πn)
Find the frequency response H(ω) of the discrete-time system and its response to x(n).
Solution
H(z) = z−2 + z−1 + 1 + z1 + z2
H(ω) = e−j2ω + e−jω + 1 + e jω + e j2ω
= 1 + 2 cos ω + 2 cos(2ω)

1070
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
See Figure 18.21(b). The input components at ω = 0, 0.1π, 0.4π, 0.5π, 0.6π, 0.9π, and π (corresponding
to discrete frequencies f = 0, 0.05, 0.2, 0.25, 0.3, 0.45, and 0.5 Hz)7 result in the following values for the
frequency response and the output.
f (Hz)
ω = 2πf
Input (V)
H = 1 + 2 cos ω + 2 cos(2ω)
Output (V)
0
0
1
5
−→
5
0.05
0.1π
cos(0.1πn)
1 + 2 cos(0.1π) + 2 cos(0.2π) = 4.52
−→
4.52 cos(0.1πn)
0.2
0.4π
cos(0.4πn)
1 + 2 cos(0.4π) + 2 cos(0.8π) = 0
−→
0
0.25
0.5π
cos(0.5πn)
1 + 2 cos(0.5π) + 2 cos(π) = −1
−→
−cos(0.5πn)
0.3
0.6π
cos(0.6πn)
1 + 2 cos(0.6π) + 2 cos(1.2π) = −1.236
−→
−1.236 cos(0.6πn)
0.45
0.9π
cos(0.9πn)
1 + 2 cos(0.9π) + 2 cos(1.8π) = 0.716
−→
0.716 cos(0.9πn)
0.5
π
cos(πn)
1 + 2 cos(π) + 2 cos(2π) = 1
−→
cos(πn)
The output of the discrete-time system is y(n). After going through a digital-to-analog converter operating at
2 kHz, y(n) will be converted to an analog (continuous-time) signal yd(t). The lines below list y(n) and yd(t). For
comparison, ya(t) the analog output of the continuous-time system of problem 7, ya(t) is also listed.
y(n) = 5 + 4.52 cos(0.1πn) −cos(0.5πn) −1.2366 cos(0.6πn) + 0.716 cos(0.9πn) + cos(πn)V
yd(t) = 5 + 4.52 cos(200πt) −cos(1000πt) −1.2366 cos(1200πt) + 0.716 cos(1800πt) + cos(2000πt) V
ya(t) = 2000 + 1871 cos(200πt) + 468 cos(800πt) −312 cos(1200πt) −208 cos(1800πt) µV
The effect of aliasing is seen at higher frequencies and is especially pronounced at 500 Hz and 1 kHz.
9. Consider the discrete-time system
H(z) = 0.51 + z−1
1 −z−1
A continuous-time signal x(t) = cos(20πt) + cos(60πt) (with components at 10 Hz and 30 Hz) is sampled at the
rate of Fs samples per second and the resulting discrete-time signal x(n) is passed through H(z). Find the output of
the system for the following three sampling rates: (1) Fs = 300 Hz, (2) 600 Hz, and (3) 1,200 Hz. Note in all cases
that the sampling rate is greater than twice the highest frequency in the signal, satisfying the Nyquist criteria. (In
problem 10 you will compare these outputs with the output of a continuous-time integrator.)
Solution
The frequency response of the discrete-time system is
H(ω) = 0.51 + z−1
1 −z−1

z=e jω = −j0.5 cot(ω/2) = 0.5 cot(ω/2)̸ −90◦
The discrete inputs at the three sampling rates are
a. Fs = 300 Hz
−→
xa(n) = cos(πn/15) + cos(πn/5)
b. Fs = 600 Hz
−→
xb(n) = cos(πn/30) + cos(πn/10)
c. Fs = 1,200 Hz −→
xc(n) = cos(πn/60) + cos(πn/20)
7Note that F = 2,000 × f .

Signals and Systems
1071
The output components corresponding to each input component are found and given in the table below.
Input
ω
H(ω) = 0.5 cot(ω/2) ̸ −90◦
−→
Output
cos(πn/60)
π/60
19.095̸ −90◦
−→
19.095 sin(πn/60)
cos(πn/30)
π/30
9.541̸ −90◦
−→
9.541 sin(πn/30)
cos(πn/20)
π/20
6.353̸ −90◦
−→
6.353 sin(πn/20)
cos(πn/15)
π/15
4.757̸ −90◦
−→
4.757 sin(πn/15)
cos(πn/10)
π/10
3.157̸ −90◦
−→
3.157 sin(πn/10)
cos(πn/5)
π/5
1.539̸ −90◦
−→
1.539 sin(πn/5)
Sample calculation:
x(n) = cos(πn/60), ω = π/60, H(ω) = 0.5 cot(π/120)̸ −90◦= 19.095̸ −90◦
y(n) = |H| cos(πn/60 + ̸ H) = 19.095 cos(πn/60 −90◦) = 19.095 sin(πn/60)
The system’s output and the ratio of the low- to high-frequency amplitudes are listed below for each rate.
a. Fs = 300
Hz −→
x(n) = cos(πn/15) + cos(πn/5)
y(n) = 4.757 sin(πn/15) + 1.539 sin(πn/5)
Ra = low-frequency to high-frequency ratio = 4.757/1.539 = 3.091
b. Fs = 600
Hz −→
x(n) = cos(πn/30) + cos(πn/10)
y(n) = 9.541 sin(πn/30) + 3.157 sin(πn/10)
Rb = low-frequency to high-frequency ratio = 9.541/3.157 = 3.022
c. Fs = 1, 200 Hz −→
x(n) = cos(πn/60) + cos(πn/20)
y(n) = 19.095 sin(πn/60) + 6.353 sin(πn/20)
Rc = low-frequency to high-frequency ratio = 19.095/6.353 = 3.006
Note in all cases that the sampling rate is greater than twice the highest frequency in the signal. The differences
observed in a to c are due to H(z) being an approximation of a continuous-time integral. [At high sampling rates,

/Fs = ω becomes small and the above system-frequency response becomes H(ω) ≈(1/ω)̸ −90◦.]
10. The system of problem 9
H(z) = 0.51 + z−1
1 −z−1
is a discrete-time integrator that approximates (with a scale factor) the continuous-time integrator
y(t) =
	
t
−∞
x(t)dt
In problem 9 the continuous-time signal x(t) = cos(20πt) + cos(60πt) was sampled by analog-to-digital (A/D)

1072
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
converters operating under three sampling rates and these produced three discrete-time signals xa(n), xb(n), and
xc(n). The discrete-time signals were then passed through the discrete-time integrator. Let the discrete-time outputs
ya(n), yb(n), and yc(n) be converted back to analog signals ya(t), yb(t), and yc(t) by digital-to-analog (D/A)
converters which in each case use the original sampling rate and produce analog signals proportional to the discrete
signal. Compare ya(t), yb(t), and yc(t) with the output of the continuous-time integrator.
Solution
a.
A/D and D/A at Fs = 300 Hz:
ya(t) = −4.757 sin(20πt) −1.539 sin(60πt)
Ra = 3.091
b.
A/D and D/A at Fs = 600 Hz:
yb(t) = −9.541 sin(20πt) −3.159 sin(60πt)
Rb = 3.020
c.
A/D and D/A at Fs = 1,200 Hz:
yc(t) = −19.095 sin(20πt) −6.353 sin(60πt)
Rc = 3.006
d.
Analog Integration:
y(t) = (1/20π) sin(20πt) + (1/60π) sin(60πt)
R = 3
11. Filter description. Any one of the following functions can completely describe a digital ﬁlter.
a. The input-output difference equation
b. The system function H(z)
c. The frequency response H(ω)
d. The unit-sample response h(n)
e. The pole-zero locations plus a gain factor.
Express the above functions in mathematical terms and relate them to each other.
Solution
a. Input-output equation: y(n) + a1y(n −1) + · · · + aN y(n −N) = b0x(n) + b1x(n −1) + · · · + bMx(n −M)
y(n) = −
N

k=1
ak y(n −k) +
M

k=0
bkx(n −k)
b. Unit-sample response: x(n) = d(n), h(n) = {· · · , h−k, · · · , h−2, h−1, h0
↑
, h1, h2, · · · , hk, · · ·} ≡
∞

−∞
hkd(n −k)
h(n) = −
N

k=1
akh(n −k) +
M

k=0
bkd(n −k)
c. System function:
H(z) = B(z−1)
A(z−1) = b0 + b1z−1 + · · · + bMz−M
1 + a1z−1 + · · · + aNz−N
=
∞

k=−∞
hkz−k
d. Frequency response:
H(ω) =
∞

k=−∞
hke−jkω = H(z)

z=e jω
e. Pole-zero locations:
poles [roots of A(z) = 0], zeros [roots of B(z) = 0].
12. Four types of FIR ﬁlters designed by windowing
a. Design a 31-sample-long linear-phase low-pass FIR ﬁlter with a cutoff frequency at ω0 = π/4. Plot its magni-
tude frequency response and determine its passband and stopband frequencies (ωp and ωs, respectively) given
Ap = 1 dB and As = 30 dB. Plot zeros and the unit-sample response of the ﬁlter and observe that they exhibit
characteristics of a linear-phase ﬁlter.
The following Matlab codes determine the unit-sample response, the frequency response, and the plot ﬁlter
characteristics.
w=0:0.002*pi:pi;
den=[1];
m=15;

Signals and Systems
1073
M=2*m+1;
k=0:1:M-1;
zerostemline=0*k;
n=-m:m;
window=hamming(M)';
% window=0.54+0.46*cos(pi*n/m);% Constructs a Hamming window.
%
% a) Linear phase lowpass filter, Hamming window.
w0=pi/4;
num=window.*sin(w0*n)./(pi*n);
num(m+1)= w0/pi;
H=freqz(num,den,w);
gain=20*log10(abs(H));
%
% Magnitude plot in linear scale.
figure
plot(w/pi,abs(H),'linewidth',2);
axis([0 1 -0.1 1.1]);
grid
title('Magnitude response of a linear phase lowpass FIR filter (Hamming win-
dow, M=31)');
ylabel('Magnitude (linear scale)');
xlabel('Angular frequency (rad/s, in units of Pi)');
%
% Magnitude plot in dB scale.
figure
plot(w/pi,gain,'linewidth',2);
axis([0 1 -80 5]);
grid
title('Magnitude response of a linear phase lowpass FIR filter (Hamming win-
dow, M=31)');
ylabel('Magnitude (dB)');
xlabel('Angular frequency (rad/s, in units of Pi)');
%
% Phase plot
figure
plot(w/pi,180/pi*angle(H),'linewidth',2);
grid
title('Magnitude response of a linear phase lowpass FIR filter (Hamming win-
dow, M=31)');
ylabel('Phase (degrees)');
xlabel('Angular frequency (rad/s, in units of Pi)');
%
% PZ plot
figure
zplane(num,den);
axis([-1.75 1.75 -1.75 1.75]);
title('Pole-zero plot of a linear phase lowpass FIR filter (Hamming win-
dow, M=31)');

1074
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
xlabel('Real parts');
ylabel('Imaginary parts');
%
% Unit-sample response plot
figure
hold on
stem(num,'fill','b');
plot(k,zerostemline,'b');
axis([0 M -0.05 1.1*num(m+1)]);
title('Unit
sample
response
of
a
linear
phase
lowpass
FIR
filter
(Ham-
ming window, M=31)');
xlabel('n');
ylabel('h(n)');
hold off
b. Repeat part a for a high-pass ﬁlter with a cutoff frequency at ω0 = 3π/4.
By substituting the following Matlab codes for the corresponding lines in the program of part a, one obtains the
unit-sample response and the frequency response of the high-pass ﬁlter.
% b) Linear phase highpass filter, Hamming window.
w0=3*pi/4;
num=-window.*sin(w0*n)./(pi*n);
num(m+1)=1-w0/pi;
H=freqz(num,den,w);
c. Repeat part a for a bandpass ﬁlter with a center frequency at ω0 = π/2 and a bandwidth ω = π/2.
By substituting the following Matlab codes for the corresponding lines in the program of part a, one obtains the
unit-sample response and the frequency response of the bandpass ﬁlter.
% c) Linear phase bandpass filter.
w1=pi/4;
num1=window.*sin(w1*n)./(pi*n);
num1(m+1)= w1/pi;
w2=3*pi/4;
num2=window.*sin(w2*n)./(pi*n);
num2(m+1)= w2/pi;
num=num2-num1;
H=freqz(num,den,w);
d. Repeat part a for a bandstop ﬁlter with a center frequency at ω0 = π/2 and a bandwidth ω = π/2.
By substituting the following Matlab codes for the corresponding lines in the program of part a, one obtains the
unit-sample response and the frequency response of the bandstop ﬁlter.
% c) Linear phase bandstop filter.
w1=pi/4;
num1=window.*sin(w1*n)./(pi*n);
num1(m+1)= w1/pi;
w2=3*pi/4;
num2=window.*sin(w2*n)./(pi*n);
num2(m+1)= w2/pi;
num=num1-num2;

Signals and Systems
1075
num(m+1)=1+num1(m+1)-num2(m+1);
H=freqz(num,den,w);
13. Given the unit-sample response of a ﬁlter h(n) = {1
↑, 2, 1} ﬁnd its output to the following inputs:
a. A single sinusoidal signal x(n) = cos(ωn).
b. A rectangular periodic pulse signal with the period N = 8 and a duty cycle 25%. A cycle of the signal is shown
by
x(n) =

{1
↑, 1, 0, 0, 0, 0, 0, 0}
0 ≤n ≤7
x(n + 8)
elsewhere
Solution
a. The frequency response of the ﬁlter is
H(ω) = 1 + 2e−jω + e−j2ω = 2(1 + cos ω)e−jω
The phase function, −ω, is a linear function of ω which translates into a unit delay in the sinusoid, regardless of
its frequency. The output is y(n) = 2(1 + cos ω) cos[ω(n −1)].
b. The output is a periodic signal with the period N = 8. One period of the signal is {1
↑, 3, 3, 1, 0, 0, 0, 0}.
14. Filtering in time and frequency domains. An 8-point time-series x(n) (generated by a Gaussian random noise
generator with zero mean and unity variance given below) passes through the three-tap FIR ﬁlter speciﬁed by
the unit-sample response h(n) = {1
↑, −1.5, 1}. Predict ﬁlter’s output by (a) linear convolution and (b) circular
convolution (i.e., DFT and IDFT), and compare the two predictions.
Solution
In the time domain the output is predicted by applying linear convolution
y1(n) =
9

k=0
x(k)h(n −k) = x(n) −1.5x(n −1) + x(n −2)
y1(n) is 10 points long and constitutes the true output. In the frequency domain the output is found by ﬁrst padding
h(n) by 5 zeros to make it 8 points long. Then by taking its 8-point DFT, multiplying the DFT by the 8-point DFT
of x(n), and taking the IDFT to obtain y2(n). y2(n) is 8 points long and deviates from the output at the edges, too.
These are shown below.
(i) Input x(n) = {−0.854258
↑
, 0.622873, 0.934505, −1.500489, −0.513985, 1.357851, −0.592673,
0.546175}
(ii) Filter h(n) = {1
↑, −1.5, 1}
(iii) Output by convolution, y1(n) = {−0.284753
↑
, 0.634753, −0.284688, −0.759791, 0.890418, 0.209447,
−1.047811, 0.931012, −0.470645, 0.182058}
(iv) Output by DFT-IDFT, y2(n) = {−0.755398
↑
, 0.816812, −0.284688, −0.759791, 0.890418, 0.209447,
−1.047811, 0.931012}
(v) Difference, y1(n) −y2(n) = {−0.470645
↑
, 0.182059, 0, 0, 0, 0, 0, 0, −0.470645, 0.182058}

1076
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
15. Example 18.36 in this chapter illustrated a simple bandpass ﬁlter with its center frequency at π/2. Example 18.37
illustrated design of a wideband bandpass ﬁlter by pole-zero placement. It placed 10 pairs of poles inside the unit
circle all at the radius 0.9 on both sides of the center frequency ±ω = π/2 equally distanced from each other. The
angular distance between two neighboring poles is 9◦. Similarly, it placed 10 pairs of zeros on the unit circle around
z = 1 and z = −1. The pole-zero plot and the resulting magnitude plot are shown in Figure 18.9(a). To avoid
zeros on the unit circles, the zeros are moved inside the unit circle to a radius 0.7 from the origin, and their mirror
images with respect to the unit circle (at the same angles but at a radius
1
0.7 ) are added. Their pole-zero plots and
the resulting magnitude plots are shown in Figure 18.9(b).
To ﬂatten the top of the passband segment of the frequency response the poles are ﬂipped vertically. The
zeros remain as before. The pole-zero plot and the resulting magnitude plot are shown in Figure 18.22(a) and (b),
correponding to Figure 18.9(a) and (b).
−140
−120
−100
−80
−60
−40
−20
0
Gain (dB)
Digital angular frequency (rad/s, in units of π)
0
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
−140
−120
−100
−80
−60
−40
−20
0
Gain (dB)
Digital angular frequency (rad/s, in units of π)
0
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
−1
0
1
Imaginary parts
−1.5
−0.5
0.5
1.5
−1
0
1
−1.5
−0.5
0.5
1.5
Real parts
−1
0
1
Imaginary parts
−1.5
−0.5
0.5
1.5
−1
0
1
−1.5
−0.5
0.5
1.5
Real parts
20
(a)
(b)
FIGURE 18.22 (For problem 15)

Signals and Systems
1077
16. An FIR notch ﬁlter has 2 zeros at z1,2 = ± j. We add to it two pairs of poles on both sides of the zeros at distances
of π/20 rad/s, inside the unit circle at a distance of 0.1. The result is a ﬁlter with:
Two zeros at z = ± j and two pairs of poles at p1,2 = 0.9e± j9π/20, p3,4 = 0.9e± j11π/20
The DC gain of the ﬁlter is one. A continuous-time signal x(t) = 1+cos(4,500πt)+cos(5,000πt)+cos(5,500πt)
is sampled at the rate of 10 kHz and the samples are passed through the above ﬁlter. The ﬁlter’s output is converted
back into the continuous-time using a unity-gain A/D converter. Find the resulting signal in the form of y(t) =
A0 + A1 cos(4,500πt −θ1) + A2 cos(5,000πt −θ2) + A3 cos(5,500πt −θ3).
Hint: A pair of poles at ρe± jθ contributes
1
(1 −ρe jθz−1)(1 −ρe−jθz−1) =
1
1 −2ρ cos θz−1 + ρ2z−2
to a ﬁlter’s system function. See Figure 18.23.
Ans.
Filter
A0
A1
θ1
A2
θ2
A3
θ3
FIR
1
0.1564 −1.4137
0
−1.5708 0.1564
1.4137
IIR
1.
9.5192 −0.3135
0
−1.5708 9.5192
0.3135
–50
0
–40
–30
–20
–10
0
10
20
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Normalized frequency in rad/s, linear scale
–50
0.4
–40
–30
–20
–10
0
10
20
0.42
0.44
0.46
0.48
0.5
0.52
0.54
0.56
0.58
0.6
Normalized frequency in rad/s, linear scale
Amplitude in dB
Amplitude in dB
FIGURE 18.23 (For problem 16)

1078
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
17. Notch ﬁlter. The m ﬁle for a notch ﬁlter design is given below. Run the program and measure the performance of
the ﬁlter at the neighborhood of the notch.
r=0.96757;
k=( 2-sqrt(2)*r+r√2)/(2-sqrt(2));
num=[1 -sqrt(2) 1];
den=[1 -sqrt(2)*r r√2];
w=0:0.002*pi:pi;
H=k*freqz(num,den,w);
gain=20*log10(abs(H));
figure(1)
subplot(2,1,1)
plot(w/pi,gain); grid;
axis([0 1
-75 0])
title('magnitude plot');
xlabel('digital angular frequency (unit of pi)');
ylabel ('gain (db)');
subplot(2,1,2)
plot(w/pi,gain);grid;
axis([0.23 0.27
-3.5 -2.5])
%title('magnified plot');
xlabel('digital angular frequency (unit of pi)');
ylabel ('gain (db)');
Chapter Problems
All systems are discrete. Plots of H(ω) are to be done for −π < ω < π rad/s or −0.5 < f < 0.5 Hz.
18. A discrete signal x(n) = cos πn
6 is passed through a linear ﬁlter with h(n) = {1
↑, −1, 1}. Find the output y(n).
19. The poles of a causal discrete-time LTI system are at p1 = 2, p2 = 0.5, and p3 = 0.1. The system has no zeros.
The steady-state response to a unit step is −10/9.
a. Find the system function.
b. Find the system’s unit-sample response.
c. Is the system stable? Support your answer by an appropriate argument.
d. Find the difference equation that gives y(n) for n > 0 and sketch a block diagram made of gains and unit delays
to represent the system.
e. Given the initial conditions y(0) = 1,
y(−1) = 1 and y(−2) = 1, use the analytic method to solve the
difference equation and ﬁnd a closed-form expression for y(n), n ≥0, given x(n) = 0 , n > 0.
f. Repeat part e for x(n) = 1, n > 0.
g. Repeat parts e and f using the z-transform method.
20. a. Find the system function given the following difference equation:
y(n) −0.2y(n −1) = x(n)
b. Find the steady-state response to x(n) = cos(πn).
c. Find the magnitude and phase of the frequency response for ω = π.
d. Obtain b from c.

Signals and Systems
1079
21. The unit-sample response of a digital ﬁlter is h(n) = {1, 2
↑, 1}.
a. Find and plot H(ω).
b. The discrete signal x(n) = 1 + cos n
2 is passed through the above ﬁlter. Find the output y(n).
22. A continuous-time analog signal x(t) = cos 500πt + cos 200πt is sampled at the rate of 1,000 samples per second.
a. Find x(n).
b. The resulting discrete signal x(n) is passed through a ﬁlter with unit sample response h(n) = {1, 2, 3
↑, 2, 1}.
Find the output y(n) and its analog reconstruction y(t).
23. A linear time-invariant analog ﬁlter is speciﬁed by its unit-impulse response ha(t) = e−tu(t). Sample ha(t) at the
rate of ﬁve samples per second and obtain h(n). Find H(z) and H(ω). Plot H(ω) and ﬁnd the 3-dB discrete-time
frequency.
24. The unit-sample response h(n) of a digital ﬁlter is
h(n) =

0.5n,
0 ≤n < N
0,
elsewhere
Is the ﬁlter FIR? Is it linear phase? Find H(z) in the form of the ratio of two polynomial functions of z−1 with real
coefﬁcients. How many poles and zeros does the ﬁlter have? Find them for the case of N = 3.
25. Determine the magnitude and phase of the frequency response of the following systems.
a. y(n) = x(n) + x(n + 1)
b. y(n) = x(n) + x(n −1)
c. y(n) = x(n −1) + 2x(n) + x(n + 1)
26. Find the shortest linear-phase unit-sample response whose H(z) has a zero at 0.8e j π
4 .
27. a. Sample the analog signal h(t) = sin(1,000πt)/(πt) at the rate of 1,000 samples per second in a way that one
sample is at t = 0. Find h(n) and H(ω). Sketch H(ω). For what purpose, or application, may such a signal be
used?
b. Repeat part a for the rates of (i) 2,000 and (ii) 5,000 samples per second.
28. a. The unit-sample response of a digital ﬁlter is h(n) = {1, 0
↑, 1}. Find H(z) and H(ω). Sketch magnitude and
phase of H(ω), including scales and labels. Discuss properties of the ﬁlter. Repeat for h(n) = {1
↑, −1, 1}.
b. A continuous-time pulse
x(t) =

1,
−5.1 msec ≤t ≤5.1 msec
0,
elsewhere
is sampled at the rate of 200 samples per second in a way that one sample is at t = 0. The resulting discrete-time
function is x(n). Find X(z) and X(ω).
c. The x(n) of part b is passed through a ﬁlter with h(n) = {1, 0
↑, 1}. Using the method(s) of your choice ﬁnd the
output y(n) of the ﬁlter. Compare y(n) with x(n) and discuss their differences.
d. Repeat parts b and c for the rate of 2,000 samples per second.
29. a. A discrete-time LTI system has three zeros at z = ± j and −1. Find H(z) and H(ω) (magnitude and phase).
Plot |H(ω)| and ﬁnd the 3-dB bandwidth.
b. Add a zero at z = 1
3 and another zero at z = 3. Repeat part a.
30. a. A discrete-time LTI system has 4 zeros at z = ± j and e± j150◦. Find H(z) and H(ω) (magnitude and phase). Plot
|H(ω)| and ﬁnd the 3-dB bandwidth.
b. Add a zero at z = 1
3 and another zero at z = 3. Repeat part a.

1080
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
31. A discrete-time LTI system has two poles at 0.9e± j45◦. Find H(z) and H(ω) (magnitude and phase). Plot |H(ω)|
and ﬁnd the 3-dB bandwidth.
32. a. An LTI system has two zeros at z = ±1 and two poles at 0.9e± j45◦. Find H(z) and H(ω) (magnitude and phase).
Plot |H(ω)| and ﬁnd the 3-dB bandwidth.
33. A discrete-time LTI system has two poles at p1,2 = 0.9e± j π
4 and two zeros on the unit circle at z1,2 = e± j π
4 .
a. Write the expression for H(z) as a function of z−1.
b. Find and plot H(ω) = Hr(ω)e j(ω).
34. The system function H(z) of a discrete LTI ﬁlter has two poles at 0.8e± j π
4 and a double zero at z = 0. Find H(z)
in the form of the ratio of two polynomial functions of z−1 with real coefﬁcients.
35. An FIR ﬁlter has 2 zeros at z = 1
2 and z = 2. Find H(z) and |H(ω)| in the form of Hr(ω)e j(ω). Plot Hr(ω) and
label important points on the plot. Specify if the ﬁlter is low-pass, high-pass, bandpass, or bandstop.
36. The following three systems approximate an integrator.
a. y(n) = x(n) + y(n −1)
b. y(n) = 0.5x(n) + 0.5x(n −1) + y(n −1)
c. y(n) = 0.333x(n) + 1.333x(n −1) + 0.333x(n −2) + y(n −2)
In each case ﬁnd H(ω). Plot its magnitude and phase. Compare with the performance of a perfect integrator.
37. The following two systems approximate a differentiator.
a. y(n) = x(n) −x(n −1)
b. y(n) = 0.5x(n) −0.5x(n −2).
In each case ﬁnd H(ω). Plot its magnitude and phase. Compare with the performance of a perfect differentiator.
38. A discrete-time LTI system has two poles at p1,2 = ρe± jω0 and 2 zeros at z = ±1.
a. Write the expression for H(z) as a function of z−1.
b. Find H( jω) = Hr(ω)e j(ω).
c. Find and plot Hr(ω) and (ω) for ρ = 0.6, 0.8, 0.9, 0.95 and ω0 =
π
12, π
4 , π
2 .
In each case specify the maximum of the magnitude and the angular frequency at which it is reached.
39. a. Find H(z) as a function of z−1 for the following two ﬁlters.
(i) Filter 1 has two poles at 0.95e± j π
4 , 2 zeros at e± j π
4 and a double zero at the origin.
(ii) Filter 2 has two poles at 0.95e± j π
4 , 2 zeros at 1.05e± j π
4 and a double zero at the origin.
b. Plot |H(ω)|, ﬁnd the 3-dB points and determine if each ﬁlter is low-pass, high-pass, bandpass, or bandstop.
40. Filtering in time and frequency domains. Generate a 64-point Gaussian random signal with zero mean and
unity variance by a random noise generator. Pass it through the 3-tap FIR ﬁlter with h(n) = {1
↑, −1.5, 1}. Obtain
ﬁlter’s output by (a) linear convolution and (b) circular convolution (i.e., DFT and IDFT), and compare the two
predictions.
41. Effect of zeros on the bandwidth of an IIR bandpass ﬁlter. A digital ﬁlter has a pair of complex conjugate poles
at p1,2 = ± j0.95 and a set of 4 zeros at z1,2,3,4 = ±e± jθ.
a. Find H(z) and H(ω) = |H(ω)|̸ H(ω) as a function of θ.
b. Specify important values [maximum value, 3-dB frequencies (ωℓand ωh), and the bandwidth ω = ωh −ωℓ]
for θ = kπ/8, k = 1, 2, 3. Plot magnitude response of the ﬁlter for the above three values of θ. Compare results
with Example 18.36 in the chapter.

Signals and Systems
1081
42. Effect of poles on the bandwidth of an IIR bandpass ﬁlter. A digital ﬁlter has a set of four poles at p1,2,3,4 =
± j0.95e± jθ and 2 zeros at z = ±1.
a. Find H(z) and H(ω) = |H(ω)|̸ H(ω) as a function of θ.
b. Specify important values [maximum value, 3-dB frequencies (ωℓand ωh), and the bandwidth ω = ωh −ωℓ]
for θ = kπ/32, k = 1, 2, 3. Plot magnitude response of the ﬁlter for the above three values of θ. Compare
results with Example 18.37 in the text.
18.14
Project 1: FIR Filter, Design by Windowing
Objective and Summary
In this project you will design three low-pass FIR ﬁlters (9-tap, 31-tap, and 61-tap) based on the windowing method,
and measure their theoretical performance through simulation by Matlab or other software tools. You will then apply the
ﬁlters to a recorded speech signal off-line and compare with theory. You will compare the ﬁlters performance with theory
and with each other. If digital hardware is available, you then will run the ﬁlters in real time on a digital platform such as
DSP board and measure their frequency responses. Using the microphone as the input device you will let the board ﬁlter
your speech in real time and qualitatively observe its ﬁltering effect.
Design
A Nine-Tap Low-Pass FIR Filter
Obtain the unit-sample response of a linear-phase low-pass digital FIR
h(n) = {h0
↑
, h1, h2, h3, h4, h3, h2, h1, h0}
based on an ideal ﬁlter with a cutoff frequency corresponding to 1 kHz in the continuous-time domain. The ﬁlter is
to operate on the signals listed in the ﬁltering section of this project with Fs = 22,050 Hz. First determine the cutoff
frequency ω0 of the digital ﬁlter. Then consider the ideal low-pass ﬁlter with
h(n) = sin(ω0n)
πn
Shift h(n) to the right by four units and multiply it by a nine-tap Hanning window (0 ≤n ≤8) to obtain h(n) and its
frequency response H(ω). Call the ﬁlter FIR1. Plot magnitude and phase of H(ω). Save the computer code for later use
in this experiment.
A 31-Tap Low-Pass FIR Filter
Using an approach similar to that of the above, design a 31-tap low-pass ﬁlter and call it FIR2. Plot the magnitude and
phase of H(ω).
A 61-Tap Low-Pass FIR Filter
Repeat for a 61-tap low-pass ﬁlter according to the following steps:8
8The ARRL Handbook for Radio Amateurs, 2002, Chapter 18 and its appendix, published by ARRL-the National Association for
Amateur Radio.

1082
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
–0.4
–15
–10
–5
0
0.4
0.8
0
5
10
15
–0.2
–15
–10
–5
0.2
0.6
1
0
5
10
15
–0.3
–0.4
–0.2
–0.1
0.01
1
0.1
0.2
0.3
0.4
–0.2
–15
–10
–5
0.2
0.6
1
0
5
10
15
h(n)
0
–0.3
–0.4
–0.2
–0.1
0.001
1
0.1
0.2
0.3
0.4
0
|H(f)|, Frequency is in Hz.
–0.3
–0.4
–0.2
–0.1
0.0001
1
0.1
0.2
0.3
0.4
0
FIGURE 18.24 Constructing the 61-tap FIR3 ﬁlter to approximate an ideal low-pass ﬁlter with cutoff frequency at 0.125
Hz. Top row is a 31-tap FIR ﬁlter under rectangular window. Middle row is a 31-tap FIR ﬁlter under Blackman window.
Bottom row is a 61-tap FIR ﬁlter created by the convolution of the two ﬁlters above. Unit-sample responses are shown in
the left column and frequency responses in the right column.
1. Consider the ideal low-pass ﬁlter
h(n) = sin(ω0n)
πn
2. Multiply h(n) by a 31-tap uniform window to obtain h1(n) and its frequency response H1(ω).
3. Multiply h(n) by a 31-tap Blackman window to obtain h2(n) and its frequency response H2(ω).
4. Convolve h1(n) and h2(n) and normalize the result to obtain the new unit-sample and frequency responses h3(n)
and H3(ω).
h3(n) = h1(n) ⋆h2(n)
Max(h1 ⋆h2)
⇐⇒
H3(ω) = H1(ω) × H2(ω)
Max(h1 ⋆h2)
h3(n) is your design result and will be used in the rest of this experiment. Call it FIR3. An example is shown in
Figure 18.24.
Filter Specifications
1. Find the attenuation of ﬁlters at the cutoff frequency ω0 in dB below their DC gain, and their phase at that frequency.
In the continuous-time domain, the corresponding cutoff frequency will be f0 = 1 kHz.
2. Deﬁne the passband of the low-pass ﬁlters to be ω < ωp, where the gain is less than 1 dB below the DC gain.
Deﬁne the stopband to be ω > ωs, where the gain is more than 20 dB below the DC gain. Find ωp and ωs for the
FIR1, FIR2, and FIR3 ﬁlters. Call them ωp1, ωs1, ωp2, ωs2, ωp3, and ωs3, respectively. In the continuous-time
domain and at the sampling frequency of Fs = 22,050 Hz the passband and stopband frequencies will be called
f p and fs. Enter your results in Table 18.1.

Signals and Systems
1083
TABLE 18.1
Specifications
for
the
Three Linear-Phase Low-Pass Filters
fp, Hz
f0, Hz
fs, Hz
FIR1
FIR2
FIR3
Filtering
Filtering Sinusoids
Sample the sinusoidal signal x(t) = cos(2π f t) at the rate of Fs = 22,050 Hz and pass it through the nine-tap ﬁlter.
For the frequency values given in Table 18.2 ﬁnd magnitude A, phase θ, and time delay τ in the ﬁlter’s output y(t) =
A cos(2π f t −θ) = Ax(t −τ). Repeat for the 31-tap and 61-tap ﬁlters. Enter your results in Table 18.2.
TABLE 18.2 Output Values for Three Linear-Phase Low-Pass Filters at
Various Frequencies
Frequency f, Hz
100
fp1
fp2
f0
fs2
fs1
9,000
FIR1
 A, volts
θ, radian
τ, msec
FIR2
 A, volts
θ, radian
τ, msec
FIR3
 A, volts
θ, radian
τ, msec
Filtering a Speech Signal
Pass the speech ﬁle a cup of hot tea (cht5.wav) through the nine-tap low-pass FIR ﬁlter you designed previously
[convolving it with h(n)] and save it as a *.wav ﬁle. Compare the spectra of the input and output ﬁles. Play both of them
and compare with each other.
You will notice that for the high sampling rate of 22 kHz used in cht5.wav, the nine-tap ﬁlter is inadequate. Apply
the 31-tap ﬁlter (as shown in Figure 18.25) to the speech ﬁle cht5.wav and compare with the output obtained from the
nine-tap ﬁlter. Repeat using the 61-tap ﬁlter. Obtain the input and output spectra and their power. Compare with theory.
Real-Time Filtering
In this section you will use a digital platform such as a DSP board for testing the real-time operation of the ﬁlters. First
apply a sinusoidal input to the board to measure its frequency response. Then program the ﬁlters and load them onto the
digital platform. Now apply the sinusoid to measure the frequency response of ﬁlters. Finally, apply the microphone as
the input and let the board ﬁlter your speech. Qualitatively observe the effect.
Discussion and Conclusions
Design Methodology
Suggest a methodology for designing a low-pass FIR ﬁlter for which
Passband attenuation ≤Ap within the band ω ≤ωp,
Stopband attenuation ≥As within the band ω ≥ωs,
where Ap , ωp, As, and ωs are known.

1084
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
2,000
4,000
6,000
8,000 10,000 12,000 14,000 16,000
–30
–20
–10
0
10
20
30
2,000
4,000
6,000
8,000 10,000 12,000 14,000 16,000
–20
–10
0
10
20
30
–0.4
–0.3
–0.2
–0.1
0
0.1
0.2
0.4
–0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.5
–0.4
–0.5
–0.3
–0.2
–0.1
0
0.1
0.2
0.4
–0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.5
–0.4
–0.3
–0.2
–0.1
0
0.1
0.2
0.4
–4
–2
0
2
4
6
8
10
0.3
–30 –25 –20 –15
–10
–5
–0.4
0
0.4
0.8
1.2
0
5
10
15
20
25
30
Discrete time (n)
Frequency  (Hz)
FIGURE 18.25 Low-pass ﬁltering of the speech ﬁle cht5.wav by the 31-tap FIR2 ﬁlter. Time sequences are on the
left. The magnitude spectra are on the right.
Is Filtered Speech Intelligible?
How intelligible is ﬁltered speech? Compare the outputs of FIR1, FIR2, and FIR3.
Speaker Recognition in Filtered Speech
Can you recognize the speaker by listening to ﬁltered speech used in this experiment? Compare the outputs of FIR1,
FIR2, and FIR3 in terms of speaker recognition.
Overall Conclusions
Summarize your observations and methods to design other classes of FIR ﬁlters (high-pass, bandpass, bandstop, · · ·)
close to a desired characteristic.
18.15
Project 2: Discrete-Time Modeling and
Control of a Dynamic System
Objectives and Summary
In this project you will explore digital control of a physical plant modeled by a linear time-invariant system. The
plant is speciﬁed by measurements of its time and frequency responses. The project consists of two procedures. Pro-
cedure 1 is concerned with the open-loop system. First, you will model the system by a continuous-time second-order

Signals and Systems
1085
model and transform the model from the continuous- to the discrete-time domain. You will verify the validity of the
discrete-time system as an operational model for the actual physical plant by comparing the step and frequency responses
in both domains. This is carried out off-line and all responses are obtained by simulations. The comparison will be done
mathematically. You will then implement the open-loop discrete-time system on a digital device (such as a computer or
a digital signal processing board) and conﬁrm the validity of the model by running it in real time with an analog input
and output.
In procedure 2 you add feedback to the system to reduce the overshoot in its step response from a maximum of
60% to below 10%. First, you will design and simulate an analog closed-loop control system made of the second-order
continuous-time system and an analog PID controller. You will then convert it to a closed-loop digital control system and
test its performance both off-line, by simulation, and in real time on a digital platform. Finally, you will construct a hybrid
system made of an analog plant (an op-amp electronic circuit) and a digital controller (on the digital device), all working
together in real time. Again, the controller’s task is to reduce the overshoot in the step-response from a maximum of 60%
to below 10%. You will then run the hybrid system in real time with analog inputs and outputs and test the performance
of the controller.
The tools needed for the project consist of software and a digital platform for real-time operation of the digital
controller. These can be a DSP board embedded in a PC (or existing on its own) or a digital computer. (For this purpose
a Texas Instruments’s DSP board was used.) The dynamic system that is to be controlled is an electronic op-amp circuit.
Procedure 1 Open-Loop System
In this procedure you construct a discrete-time model of a continuous-time system.
Modeling the Plant
Consider a physical plant (Figure 18.26; e.g., a simple pendulum with small displacements) to be modeled as an LTI
system. The response of the plant to a unit-step input is recorded and shown in Figure 18.26(a). Note the 60% overshoot.
The frequency response is also given in Figure 18.26(b). (The quantitative values of the step and frequency responses
may be found from the Matlab program given in “Simulation of the Discrete-Time System” below.)
Amplitude
0
1
2
3
4
5
6
0
1
Time (sec)
×10−4
×105
1.6
1.4
1.2
0.8
0.6
0.4
0.2
0
1
2
3
−30
−25
−20
−15
−10
−5
0
5
10
15
Gain in dB
Angular frequency in rad/s
0.5
1.5
2.5
(a) Unit-step response
(b) Frequency response
FIGURE 18.26 Measured time and frequency responses of the plant. (The plant is a third-order system. The above
plots were generated by the Matlab program given in the next section of this project. This information, however, is not
known by the project.)

1086
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Model the plant by a second-order linear time-invariant system:
H(s) =
ω2
0
s2 + 2ζω0s + ω2
0
In the above equation, ω0 is the undamped natural frequency and ζ is the damping ratio. From the step response of
Figure 18.26(a), ﬁnd ω0 and ζ. (Determine ζ from the overshoot in the unit-step response. See the next section for a
refresher on second-order systems.) Compare your ﬁndings with the following values: ω0 = 62,832 and ζ = 0.16. (From
here on, for the sake of uniformity, use the above model parameters.) Plot the unit-step response and the frequency response
of the model. Compare, qualitatively and quantitatively, the model’s responses with the measured plots in Figure 18.26.
For a more detailed mathematical analysis of the model and its responses, refer to Chapter 9.
Transformation from the Continuous- to Discrete-Time Domain
The differential equation relating a continuous-time system’s input x(t) to its output y(t) is
y′′ + 2ζω0y′ + ω2
0y = x(t)
where
y′′ = d2 y(t)
dt2
and y′ = d y(t)
dt
The continuous-time system may be transformed to an equivalent discrete-time system by sampling it at intervals of T . The
above differential equation is then converted to a difference equation. The transformation is done in one of several ways.
1. Forward rectangular rule using the forward-difference formula:
dy(t)
dt
|t=nT ≈y(nT + T ) −y(nT )
T
⇒s ≈z −1
T
2. Backward rectangular rule using the backward-difference formula:
dy(t)
dt
|t=nT ≈y(nT ) −y(nT −T )
T
⇒s ≈z −1
T z
3. Impulse-invariant transformation:
h(n) = h(t)|t=nT ⇒H(z) =

residues of
H(s)
1 −esT z−1 at poles of H(s)

4. Bilinear transformation using the trapezoidal integration formula:
g(t) =
	
t
−∞
h(τ)dτ
g(nT + T ) = g(nT ) + T
2 [h(nT + T ) + h(nT )] ⇒s ≈2
T
z −1
z + 1
The aim is to obtain an H(z) that would emulate the continuous-time system when used along with A/D and D/A con-
verters. Discuss the choice of transformation method and sampling rate, and summarize the advantages and disadvantages
of each of the above methods. Then use the bilinear rule to transform H(s) to H(z).
Simulation of the Discrete-Time System
Use a mathematical software package to simulate the second-order discrete-time model and plot its step and frequency
responses. Compare the unit-step response of the discrete-time model with that of the plant and then comment. Examine
the following Matlab program. You may use this program or write one of your own.

Signals and Systems
1087
zeta=0.16; f0=10000; w0=2*pi*f0
num1=[w0√2]; den1=[1 2*zeta*w0 w0√2];
r1=roots(den1); r2=[-4*w0
r1'];
num2=[4*w0√3]; den2=poly(r2);
Ts= 0.0002; Fs= 1/Ts;
%
printsys(num1,den1); printsys(num2,den2);
figure(1); step(num1,den1); grid; print -dpsc PID«V5«Figxa.eps;
figure(2); step(num2,den2); grid; print -dpsc PID«V5«Fig2a.eps;
%
[H1,w]=freqs(num1,den1);[H2,w]=freqs(num2,den2);
figure(3); plot(w,20*log10(abs(H1))); grid
axis([0,300000,-30,15]); title('simulated frequency response of the model')
ylabel('Gain in dB'); xlabel('Angular frequency in rad/s')
print -dpsc PID«V5«Figxb.eps;
figure(4); plot(w,20*log10(abs(H2))); grid
axis([0,300000,-30,15]); title('Measured frequency response of the plant')
ylabel('Gain in dB'); xlabel('Angular frequency in rad/s')
print -dpsc PID«V5«Fig2b.eps;
[num1d, den1d] = BILINEAR(num1, den1, Fs); printsys(num1d, den1d,'z');
[num2d, den2d] = BILINEAR(num2, den2, Fs); printsys(num2d, den2d,'z');
The above program also prints out system functions of the plant and the model.
The model:
H(s) =
ω2
0
s2 + 2ζω0s + ω2
0
H(z) = 0.92914z2 + 1.8583z + 0.92914
z2 + 1.8112z + 0.90536
The plant:
H(s) =
4ω3
0
(s + 4ω0)(s2 + 2ζω0s + ω2
0)
H(z) = 0.89359z3 + 2.6808z2 + 2.6808z + 0.89359
z3 + 2.7347z2 + 2.578z + 0.83607
Real-Time Operation of the Discrete-Time System
Implement the discrete-time model on a digital platform and run it in real time. Discuss your choice of sampling rate in
A/D and D/A converters and its effect on the real-time performance of the discrete-time model.
Procedure 2 Closed-Loop System
In this procedure you produce digital control of the dynamic system.
Design of a PID Controller9
Use the control loop of Figure 18.27. The PID controller has three parallel paths (a proportional path kp, an integral path
ki, and a derivative path kd) and an adder. Its transfer function is
Gc(s) = kp + ki
s + kds
9Another design example for a PID control system is found in Example 9.48 of Chapter 9.

1088
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
∑
Analog
reference
Analog
output
Error
PID
Plant
Feedback
+
–
FIGURE 18.27 Simulation of analog control of the analog system.
Design of the controller requires determination of kp, ki, and kd. This can be done by the root locus method, placing
the poles of the closed-loop system at acceptable locations, or by writing a computer program that iteratively adjusts the
coefﬁcients in a search for an answer.10 You also need to pay attention to the steady-state error produced by the controller.
Simulate the analog (continuous-time) closed-loop control system. See Figure 18.27.
Digital Control of the Digital System
1. Transform the analog control loop to the discrete-time (digital) domain by bilinear transformation [see
Figure 18.28(a)] and simulate it. In doing this, the whole control loop is digital.
2. Implement the closed-loop digital control system of Figure 18.28(b) on a digital platform (e.g., a digital signal pro-
cessing board; Texas Instruments DSKboard) and run it in real time. Compare to the continuous-time control system.
∑
Reference
Output
Error
PID
Plant
Feedback
+
–
(a)
∑
Analog
reference
Analog
output
Error
PID
Plant
Feedback
+
–
(b)
A/D
D/A
FIGURE 18.28 (a) Simulation of digital control of the digital system. (b) Real-time implemen-
tation of digital control of digital system.
Digital Control of the Analog System
In this part of the project the plant to be controlled is an analog electronic low-pass system and the controller is digital.
See Figure 18.29(a). To construct the analog plant we express it in terms of its quality factor Q and undamped natural
10The coefﬁcients will not be unique. For more, see a book on control systems design.

Signals and Systems
1089
(a)
(b)
Reference
Output
Error
Digital PID
Feedback
+
–
A/D
D/A
Plant
Analog Subtractor
(Op-Amp)
Analog Circuit
(Op-Amp)
Digital Controller
(DSK)
Reference
Output
Digital PID
on DSK
+
–
+
–
C2
C1
The Plant
Controller
Negative Feedback
R
R
R
R
R
R1
Feedback Path
FIGURE 18.29 (a) The closed-loop control system with a digital PID controller and analog plant
that is made of op-amp circuits. (b) Digital control (with external feedback) of the analog plant.
Feedback is provided by the external voltage path and the summing op-amp circuit. The digital
controller is implemented on the DSK board. The analog plant is modeled by the second-order
low-pass 741 op-amp circuit with R = 100 K
, C1 = 4.7 µF, and C2 = 120 nF. Feedback
coefﬁcient can be adjusted through R1.
frequency ω0:
H(s) =
1

s
ω0
2
+ 1
Q

s
ω0

+ 1
where Q = 1/(2ζ) = 3.125. Use a unity-gain Sallen-Key low-pass ﬁlter to realize the above system. An example is
shown in Figure 18.29(b). Simulate the analog electronic circuit using a circuit simulation package such as Spice. Test
the unit-step response of the physical circuit to verify its compliance with the desired speciﬁcations.
Load the digital controller onto the digital platform and place it in the control loop. Use an op-amp circuit to subtract
the output (feedback signal) from the reference signal as shown in Figure 18.29(b). Run the system in real time. Record
its unit-step response. Measure its rise time, percentage overshoot, natural frequency, and damping ratio. Compare with
those of the plant in open-loop state. Compare with theory.

1090
CHAPTER 18
System Function, the Frequency Response, and Digital Filters
Comparison and Conclusions
Find the three poles of the third-order LTI system used in this project as the plant (see “Real-Time Operation of the
Discrete-Time System” in this project). Compare them with the poles of the second-order model. Why is the effect of the
third pole (necessarily being a negative real pole) on the unit-step response small? At what frequency range do you expect
the effect to be pronounced? Illustrate the effect of the third pole on the frequency response.
Draw your conclusions from this project and include them in the report.
18.16
Project 3: Modeling a Random Trace
Generator
Summary
Figure 18.30 shows consecutive traces drawn by a human subject on paper using a pen. The abscissa is time and the
ordinate is the trace generated by the motion of the pen. The subject was instructed to generate the traces as randomly as
possible. The six traces shown in the ﬁgure are consecutive in time. This project is concerned with characterizing such
time series and producing a mathematical model for their generation. The project consists of two procedures.
Procedure 1
InthisprocedureyouwillﬁrstsamplethetracesinFigure18.30andconverteachtoadiscrete-timesignal.Fornormalization
purposes, let t in the ﬁgure be 1 msec (not the actual value). You will then compute the DTFT of each signal. You will
100
200
300
400
500
600
0
100
200
300
400
500
Time 
∆t
FIGURE 18.30 Randomly generated traces by a human subject. See procedure 1 in this project.

Signals and Systems
1091
investigate the transform to see if the spectrum contains peaks (indicating the presence of resonators) and determine the
complex frequencies associated with such possible peaks. A model for the generation of the traces is then constructed,
which includes a random generator and a number of digital resonators. The performance of the model will be compared
with the given data and a measure of error (such as the average rms of differences) will evaluate the model.
Procedure 2
In this procedure 2 you will generate your own traces following the same instructions and repeat the steps described in
procedure 1.

Appendix
Electric Circuits
A.1 Circuit Elements, Laws, and
Formulation of Equations
Circuit Elements
An electric circuit is made of interconnected elements or devices (resistors, capacitors,
inductors, switches, diodes, transistors, ampliﬁers, sensors, transducers, signal, and en-
ergy sources, etc.). In this book we consider circuits in which elements and devices are
interconnected through their terminals. If a device with more than two terminals is em-
bedded in a circuit, we model it by an interconnection of two-terminal elements. With
a two-terminal element are associated two algebraic quantities: current i and voltage
v, called the terminal variables. By convention, the terminal where the current enters
the element is labeled with a positive voltage sign with respect to the terminal where
the current leaves the element. See Figure 1(a). The element is deﬁned by its i −v
relationship, also called terminal characteristic. The voltage and current generally vary
with time. Either i or v could constitute the input, while the other would be the output.
The electric power entering an element is deﬁned as p(t) = v(t)i(t), also a function of
time.
Circuit Laws
The interconnection of elements creates nodes and loops. Nodes are connection points
where two or more elements come together as in Figure 1(b). Loops are closed paths
formed by several elements as in Figure 1(c). Elements’ currents and voltages constitute
the circuit variables. In addition to the elements’ terminal characteristics, the circuits are
constrained by two additional laws called Kirchhoff’s current law (KCL) and Kirchhoff’s
voltage law (KVL). These laws apply regardless of elements types. They are
KCL: Algebraic sum of currents arriving at a node is zero.

k
ik = 0. See Figure 1(b).
KVL: Algebraic sum of voltages around a loop is zero.

ℓ
vℓ= 0. See Figure 1(c).
1093

1094
APPENDIX A
Electric Circuits
i
+
–
v
i1
i3
i2
i4
i
+
–
v
R
i
+
–
v
L
i
+
–
v
C
i
+
–
v
+
–
+
–
+
–
v4
v2
v1
v3
+
+
–
+
–
–
+
–
+
–
(d)
(e)
(f)
(c)
(b)
(a)
FIGURE 1 (a) A two-terminal circuit element. (b) An illustration of Kirchhoff’s current law (KCL), i1 + i2 + i3 +
i4 = 0. (c) An illustration of Kirchhoff’s voltage law (KVL), v1 + v2 + v3 + v4 = 0. (d) Three linear models R, L, and
C of passive elements. (e) Signal and energy sources. From left: an independent voltage source, an independent current
source, a dependent voltage source, a dependent current source, and a battery. (f) More circuit elements and symbols.
From left: a diode, a switch, a short circuit, an open circuit, ground (reference point for node voltages), and an operati-
onal ampliﬁer.
Passive Elements
A passive element dissipates electrical energy (in the form of heat, light, mechanical
work, chemical transformation, etc.) or stores it (in the form of electric and magnetic
ﬁelds). On average, and on a net basis, it does not supply energy to the rest of the circuit.
Resistors, capacitors, inductors, and diodes are examples of passive elements.
Linear Elements
In a two-terminal element (or device), the terminal voltage and current constitute the
input-output pair. If their relationship is a linear one, the element is called linear. Three
elements are modeled as linear. They are as follows: R (resistor), L (inductor), and C
(capacitor). Their terminal i-v characteristics are
Resistor R in units of ohm, 
v = Ri
Inductor L in units of henry, H
v = L di
dt
Capacitor C in units of farad, F
v = 1
C
 t
−∞
i(τ)dτ

Signals and Systems
1095
In this textbook we mainly consider linear circuits. The symbols for R, L, and C are
shown in Figure 1(d).
Signal and Energy Sources
Sources of electric signals and energy such as batteries, generators, sensors, and transduc-
ers are complex physical devices and systems. They are modeled by electric circuits that
contain, among other elements, two idealized model elements called a voltage source and
a current source. Ideal voltage and current sources are two-terminal elements character-
ized by their voltage or current. In an ideal voltage source, the voltage is set independently
from the current that is drawn from it (or passes through it). The voltage may be constant
(DC) or may vary with time according to a time function. In an ideal current source, the
current is set independently of the voltage across it. Again, the current may be constant
(DC) or time varying.
If the voltage between the terminals of a voltage source is controlled by the voltage or
current in another element, the source is called a dependent (or controlled) voltage source.
Similarly then, the current through a source may be under the control of another circuit
variable, in which case it is called a dependent current source. Ampliﬁers are examples
of controlled sources. The voltage and current sources deﬁned above are called active
elements as opposed to passive elements. The circuit symbols for voltage and current
sources are shown in Figure 1(e).
Switch, Short Circuit, and Open Circuit
A switch is a two-terminal device with only two states: on (closed) and off (open). In the
on state, v = 0. In the off state, i = 0. The i-v characteristic of the switch is, therefore,
shown by v = 0 (on) and i = 0 (off). The switch may be considered a nonlinear
resistor with two values, R = 0 (on state) and R = ∞(off state). In the on state, the
switch is said to produce a “short circuit” between its two terminals. In the off state, the
switch produces an “open circuit” between its terminals. The “short circuit” and “open
circuit” states are also shown by a “direct connection” and “no connection,” respectively.
See Figure 1( f ).
Formulation of Equations
Given the element values, voltages and currents throughout the circuit can be found by
applying the following three sets of equations: (i) the elements’ i-v characteristics, (ii)
KCL, and (iii) KVL. In general, the result will be in the form of a set of differential
equations containing the elements variables. The number of equations may be reduced,
limiting them to the variables of interest only. See Example A.1.
Example
A.1
In the circuit of Figure 2, formulate the equation from which the capacitor voltage
v2(t) may be found.

1096
APPENDIX A
Electric Circuits
+
+
iC
iL
v2
v1
i
–
R
FIGURE 2
Solution
Let i, iC, and iL be the currents in the resistor, capacitor, and inductor, respectively.
Then,
KVL around the loop:
v1 = Ri + v2
KCL at the RLC node:
i = iC + iL
Capacitor (i, v) characteristic:
iC = C dv2
dt
Inductor (i, v) characteristic:
iL = 1
L
 t
−∞
v2dτ
Eliminate currents from the above equations:
RC dv2
dt +
 t
−∞
R
L v2dt + v2 = v1
Differentiate both sides:
d2v2
dt2 +
1
RC
dv2
dt +
1
LC v2 =
1
RC
dv1
dt
Solution methods for differential equations have been discussed in Chapters 5 and 6.
However, use of the phasor and impedance concepts provide simplifying approaches
to the formulation of equations and their solutions. These are discussed below.
A.2 AC Steady State
What Is the AC Steady-State?
AC is an abreviation for alternating current.1 In an AC (also called AC circuit) regime, the
circuit variables (i.e., element currents and voltages) are periodic functions of time. Since
any periodic function of time can be expanded as the sum of its harmonics (sinusoids),
and since the circuit is linear, the superposition effect of harmonics applies. Therefore,
without loss of generality, the analysis in the AC steady state can be reduced to an analysis
of the circuit in the sinusoidal steady state. A sinusoidal steady state develops when a
sinusoidal source is applied to a linear circuit. After passage of enough time, all voltages
1At the dawn of the electric century (i.e., at the turn of the 20th century), the usability of alternating current
was under question. Wouldn’t a current in one direction potentially undo what it had done in the opposite
direction?

Signals and Systems
1097
and currents in the circuit eventually become sinusoidal with the same frequency but
possibly different amplitudes and phase angles. This is because the circuit equations are
linear differential equations with constant coefﬁcients and, as we know, the response of
such equations to a sinusoid is a sinusoid. We start with response of R, L, and C to a
sinusoidal voltage.
Response of R, L, and C to a Sinusoid
Let a sinusoidal voltage v(t) = V cos(ωt) feed a circuit element. The current in the
element is
For a resistor:
i = v
R = V
R cos(ωt) = I cos(ωt),
where I = V
R
For an inductor: i = 1
L
 t
−∞
vdt = 1
L
 t
−∞
V cos(ωt)dt
= I cos(ωt −90◦),
where I =
V
Lω
For a capacitor: i = C dv
dt = C d
dt [V cos(ωt)] = I cos(ωt + 90◦), where I = CωV
AC Analysis
All voltages and currents in an AC circuit have the same functional form. They are all
sinusoidal with the same frequency. The analysis of the circuit will become simpler if
the sinusoidal variation with time is left out until the last stage. The analysis concerns
itself with the amplitude and phase of the currents and voltages only. This is done by
noting that a real-valued sinusoid is the real part of a complex exponential function:
v(t) = V cos(ωt + θ) = RE{V e jωt}
The complex amplitude V = V e jθ is called the phasor representation of v(t) and is also
shown by V ̸ θ. The phasor notation can represent the terminal characteristics of R, L,
and C in the AC steady-state condition, thus, by eliminating time as a variable, it reduces
the differential equations to algebraic operations on amplitudes and phases. This is called
the phasor method. The phasor method combines the amplitude and phase of a sinusoid
in the form of a vector. Graphical methods and phasor diagrams would then perform the
algebraic operations without resorting to any complex number algebra. This method
was successfully used for the analysis and design of electric motors, transformers, and
power transmission lines for several decades before Charles Steinmetz introduced the
use of complex numbers in AC analysis in the early part of the 20th century.2 Sinusoidal
voltages and currents represented by phasors may be added and subtracted using the
familiar vector addition and subtraction. Kirchhoff’s laws may be applied to the vectors
2Charles P. Steinmetz, Theoretical Elements of Electrical Engineering, 2nd. ed. (New York: McGraw-Hill
Publishing, 1905). See also C. P. Steinmetz, Lectures on Electrical Engineering in three volumes, P. L. Alger
ed., (Dover Publications, 1971).

1098
APPENDIX A
Electric Circuits
numerically or graphically. The diagram obtained by this method is called the phasor
diagram and can be used to solve circuit equations or even as a tool for design. Before the
advent of electronic calculators and computers, phasor diagrams were used extensively
as effective tools for the analysis and design of AC circuits, devices, and systems. Phasor
diagrams still provide valuable visualization tools and can illustrate the functioning and
operation of AC circuits.
The relationship between the phasor representations of the terminal variables are
given below.
Resistor:
v(t) = V cos(ωt) = Re{V e jωt}, i(t) = V
R cos(ωt)
= Re{Ie jωt} ⇒I = V
R
Inductor: v(t) = V cos(ωt) = Re{V e jωt}, i(t) = V
Lω cos(ωt −90o)
= Re{Ie jωt} ⇒I =
V
j Lω
Capacitor: v(t) = V cos(ωt) = Re{V e jωt}, i(t) = VCω cos(ωt + 90o)
= Re{Ie jωt} ⇒I = jCωV
Impedance and Admittance
The impedance and admittance of a two-terminal circuit (given by Z and Y, respectively)
are deﬁned by
Z = V
I
and Y = I
V
Admittance is the inverse of impedance. In general, both are complex numbers and
frequency-dependent.
The standard unit of impedance is the Ohm (shown by ) and the standard unit of
admittance is the Siemens (shown by S, where 1 S = 1 −1). The concept of impedance
applies to any linear circuit (containing RLC and dependent sources) operating in the
sinusoidal steady-state. The i-v relationship for linear circuits in the time and phasor
domains are summarized below.
v(t) = V cos(ωt) = RE[V e jωt]
where
V = V ̸ 0
i(t) = I cos(ωt −θ) = RE[Ie jωt]
where
I = I ̸ −θ
V = Z I,
I = Y V ,
Z = V /I
where Z = |Z|̸ θ
Note that the angle θ represents the phase of the impedance. Impedances combine
like resistors. Two impedances in series are equivalent to an impedance whose value
is the sum of the two. Two admittances in parallel are equivalent to an admittance whose
value is the sum of the two. A phasor voltage applied to a series combination of two
impedances is divided between them proportionally. A phasor current applied to two
parallel admittances is divided between them proportionally.

Signals and Systems
1099
Names and Notations
The impedance Z = R+ j X and admittance Y = G+ jW are complex numbers, with R,
X, G and W being real functions of frequency. At a given frequency, R, X, G and W are
constants. R is called resistance and X is called reactance. If X is a positive number, the
circuit is said to be inductive (X being inductance). If X is a negative number, the circuit is
referred to as capacitive (X being capacitance). Similarly, the real part G of an admittance
is called conductance and its imaginary part W is susceptance. The unit of impedance
(Z, R, and X) is the Ohm (). The unit of admittance (Y, G, and W) is the Siemens.
Kirchhoff’s Laws in the Phasor Domain
In the AC steady-state Kirchhoff’s laws apply to phasor currents and voltages.
N

k=1
ik =
N

k=1
RE[I ke jωt] = RE

e jωt
N

k=1
Ik

= 0 →
N

k=1
I k = 0
N

k=1
vk =
N

k=1
RE[Vke jωt] = RE

e jωt
N

k=1
V k

= 0 →
N

k=1
V k = 0
Circuit Analysis in the Phasor Domain
Consequent to the application of KVL, KCL, and the i-v relationship in the phasor
domain,branchvoltagesandcurrentsarefoundbysolvingasetofsimultaneousequations
of ﬁrst order. Solution techniques are similar to those of resistive circuits, except for the
fact that currents, voltages, and element values are phasors (i.e., complex numbers). The
following three examples illustrate the application of the loop current and node voltage
methods.
Example
A.2
In the circuit of Figure 2, let R = 50 , L = 1 H, C = 10−2 F, and v1(t) = cos ωt.
Find v2(t) for
a.
ω = 9
b.
ω = 10
c.
ω = 11
Solution
From voltage division in the phasor domain we have
V2 = V1
ZLC
R + ZLC
, where ZLC =
ZL ZC
ZL + ZC
, ZL = jωL, and ZC =
1
jωC
The following Matlab program implements the above for three values of ω.
R=50; L=1; C=0.01; V1=1; w=[9 10.0000001 11];
z1=j*L*w; z2=1./(j*C*w); z=(z1.*z2)./(z1+z2);

1100
APPENDIX A
Electric Circuits
V2=V1*z./(R+z);
abs(V2)
angle(V2)*180/pi
The capacitor voltage v2 is
a.
0.6877 cos(9t + 46.5◦)
b.
cos(10t)
c.
0.7234 cos(9t −43.67◦)
Example
A.3
Find the capacitor voltage v(t) and inductor current i(t) in the circuit of Figure 3.
The current source is is(l) = 10 cos(1,000t). Element values are R1 = 3k, R2 =
2k, L = 1 H, and C = 1 µF.
+
–
is
v
i
R1
R2
C
L
A
FIGURE 3
Solution
The phasor representation of the current source is Is = 10̸ 0◦A. The impedances of
the inductor and capacitor at ω = 1,000 rad/s are j103 and −j103, respectively. The
source current I s is divided between the series RL and parallel RC combinations,
where
Z RL = (3 + j)103  and Z RC = 2,000
1 + j2 = 400(1 −j2) 
Using current division,
I = Is
Z RC
Z RC + Z RL
= 10
400(1 −j2)
400(1 −j2) + (3 + j)103 = 2.626̸ −66.8◦A
V = I Z RL = (2.626̸ −66.8◦) × (3 + j)103 = 8.304̸ −48.4◦V
The time expressions for the inductor current and capacitor voltage are
i(t) = 2.626 cos(1,000t −66.8◦) and v(t) = 8.304 cos(1,000t −48.4◦)
Quality Factor Q
Capacitors and inductors store energy. Resistors consume energy. The quality f actor
of a passive linear circuit or a linear device that both stores and dissipates energy is

Signals and Systems
1101
deﬁned by
Q ≡2π
Maximum energy stored
Total energy dissipated per cycle
A quality factor generally depends on the operating frequency.
A.3 Complex Frequency and
Generalized Impedance
The Complex Frequency
The phasor analysis of the sinusoidal steady state may be extended to broader classes
of signals (e.g., sinusoids with exponentially growing or decaying amplitudes). This is
done by employing the exponential function V est, where both V and s may be complex
numbers. V is called the complex amplitude (or generalized phasor) and s is called the
complex frequency. Parallels between derivations related to the complex frequency (such
as the generalized impedance and phasor analyses) and those related to the sinusoidal
steady state can be seen throughout this section. This is expected, as the sinusoidal
steady state is a special case of the complex frequency. The generalization from jω to
s = σ + jω is valuable not only in providing a mathematical model for broader classes
of real signals, but, more importantly, because complex exponentials are eigenfunctions
of linear circuits (i.e., they elicit responses with the same complex frequency).
Sources that are complex functions of the complex frequency are in general not
realizable. It may appear at ﬁrst that the s-plane analysis has limited application. This
is not the case, however. A real source may be represented by the real part of a complex
source or as a sum of complex sources. Also, the response of a circuit made of real-valued
linear elements is equal to the real part of its response to the complex source.
Generalized Phasor and R, L, C Responses
Let v(t) = V eσt cos(ωt+θ) be a real function of time. Consider the complex exponential
function
V est, where V = V e jθ
and s = σ + jω
Note that
V est = V e jθe(σ+ jω)t = V eσte j(ωt+θ) = V eσt[cos(ωt + θ) + j sin(ωt + θ)]
from which
v(t) = Re{V est}
The function V est, often called the complex exponential signal, is completely speciﬁed
by its complex amplitude, or phasor, V and the complex frequency s. Responses of R,

1102
APPENDIX A
Electric Circuits
L, and C to such a voltage are
Resistor:
v(t) = Re{V est},
i(t) = v(t)
R
= Re{Iest}
⇒
I = V
R
Inductor:
v(t) = Re{V est},
i(t) = 1
L
 t
−∞
vdt = Re{Iest}
⇒
I = V
Ls
Capacitor:
v(t) = Re{V est},
i(t) = C dv
dt = Re{Iest}
⇒
I = CsV
Generalized Impedance and Admittance
The i-v relationships for R,L,C in the phasor domain may be summarized by V = Z I,
where Z is called the generalized impedance of the element. Conversely, the relation
between I and V maybeshownby I = Y V ,whereY iscalledthegeneralizedadmittance.
These are generalized forms of the impedance and admittance previously deﬁned for the
sinusoidal steady state. The concept of generalized impedance can be extended to any
linear circuit. The concepts of series and parallel combinations (as well as voltage and
current division) apply equally to the generalized impedance. The latter simpliﬁes the
analysis of circuits. More importantly, it leads to a circuit’s dynamical equations being
expressed in terms of s as a substitute for the time domain.
Example
A.4
a.
Use the concept of generalized impedance in the circuit of Figure 2 to ﬁnd the
differential equation relating v2 to v1.
b.
Let R = 50 , L = 1 H, C = 10−2 F, and v1 = cos ωt. Find v2.
Solution
a. Phasor-domain voltage division:
H(s) ≡V2
V1
=
zLC
R + zLC
=
Ls
1+LCs2
R +
Ls
1+LCs2
=
1
RC
s
s2 +
1
RC s +
1
LC
Reverting to the time domain:
d2v2
dt2 +
1
RC
dv2
dt +
1
LC v2 =
1
RC
dv1
dt
b. H(s) =
2s
s2 + 2s + 100,
H(ω) = H(s)|s= jω =
j2ω
100 −ω2 + j2ω
v2 = |H| cos(ωt + φ)
|H| =
2ω

(100 −ω2)2 + 4ω2 , and
φ = 90o −tan−1
2ω
100 −ω2
Observe parallels between the above H(s) and the system function deﬁned for the
input-output pair (v1, v2). In fact, the H(s) obtained by applying the circuit laws to

Signals and Systems
1103
generalized impedances becomes the Laplace transform of the unit-impulse response
of the system if we assign to it a pole-free region of convergence in the RHP of the
s-plane.
A.4 Amplifiers and Op-Amp Circuits 3
An ampliﬁer is a two-port device, one port being the input and the other the output. As
the name implies, it ampliﬁes a signal or the power it can deliver. The signal can be in
the form of a voltage or a current. A simple model of a voltage ampliﬁer is shown in
Figure 4(a) with its input-output connections. The ampliﬁer is the segment of the circuit
within the dashed box in the center. It receives input from the signal source such as the
voltage source v1(t) in series with resistor Rℓshown in the dashed box on the left. It feeds
theloadsuchastheresistor Rℓshowninthedashedboxontheright.Thedependentsource
ampliﬁes the input signal and is a required element. The input and output impedances
[shown in Figure 4(a) by resistors Ri and Ro, respectively] are ideally inﬁnity and zero,
respectively. The open-loop gain of the ampliﬁer is k. The voltage gain in the circuit of
Figure 4(a) is
v2
v1
=
Ri
Ri + R1
×
Rℓ
Rℓ+ Ro
k
R1
vd
Ri
+
–
Ro
KVd
R
v2
+
–
v2
+
–
R1
R2
vd
+
–
KVd
(a)
(b)
+
v1 –
+
v1 –
+
–
+
–
FIGURE 4 (a) The ampliﬁer circuit shows a voltage source in series with a resistor interfacing with an ampliﬁer
(enclosed within the dashed box in the center), which feeds the load Rℓ. The overall gain is affected by the gain of the
ampliﬁer and the interfacing circuits. (b) The negative feedback path across a high-gain inverting ampliﬁer (i.e., k very
large) sets the gain of the circuit at nearly −R2/R1.
3For a more detailed treatment of this subject the reader is referred to Nahvi and Edminister, Electric
Circuits, 5th ed., Schaum’s Outlines, (New York: McGraw-Hill, 2011).

1104
APPENDIX A
Electric Circuits
The gain is less than k and depends on the connection with the rest of the circuit. A
negative feedback path such as the one shown in the circuit of Figure 4(b) can reduce the
sensitivity of the gain to the above factors. More importantly, under certain conditions,
it can set the overall gain to a desired value.
Feedback Amplifier
In Figure 4(b) a feedback path is established from the output of the ampliﬁer to its input.
For simplicity, we set Ri = Rℓ= ∞and Ro = 0. We will show that for a high-gain
ampliﬁer,theexternalcircuitsetstheoverallgain.Fromtheampliﬁerwehavev2 = −kvd.
From the output-input voltage divison we have vd = (v1R2+v2R1)/(R1+R2). Substitute
vd from the ﬁrst equation into the second to ﬁnd
v2
v1
= −R2
R1
k
k + (1 + R2
R1 ) ≈−R2
R1
, if k >>

1 + R2
R1

Operational Amplifiers (Op-Amps)
Electronic devices called op-amps have the ampliﬁer property described above. An op-
amp is an active device, most often in the form of an integrated circuit chip, with two input
terminals and one output. These constitute the input and output signal ports, respectively.
The input terminals are labeled inverting and noninverting. The op-amp has connections
to a DC power supply. It also has a pair of terminals for adjustment. It doesn’t have a
terminal for ground connection. The ground is provided by the power supply and signal
sources as a common ground for the whole circuit. See Figure 5(a).
Op-amps normally have a low-output impedance. At low frequencies, their in-
put impedance and open-loop gain are very high. As a consequence of the high-input
impedance, the current through the inverting and noninverting terminals are very low.
They are normally considered zero. When the op-amp is working in the linear range the
voltage at the output terminal is proportional to the differential input, vo = k(v+−v−) ≡
kvd. k is the open-loop gain of the op-amp. All voltages are referenced with respect to
ground. In the linear range, output voltage doesn’t deviate from a window deﬁned by
voltage supply. A consequence of k being high is that when the op-amp is working in
the linear range vd ≈0. In that state, the circuit elements that are external to the op-amp
Ro
vo
inverting
input
noninverting
input
k(v+ – v–)
–
+
(a)
(b)
R1
v2
v1
R2
–
+
C
+
–
v–
v+
Ri
FIGURE 5 (a) An op-amp model. (b) A leaky integrator circuit using an op-amp.

Signals and Systems
1105
force vd near zero. A high vd would send the output voltage into high or low levels set
by the power supply. The op-amp is said to go into high or low saturation and, therefore,
would not be working as a linear ampliﬁer anymore.
Assuming the circuit is operating linearly, the analysis of a circuit containing one or
more op-amps becomes simple by the following approximations: (i) the op-amp has zero
input voltage, vd = 0, and (ii) the op-amp terminals don’t draw any current, i+ = i−= 0.
Such assumptions have often been used throughout this book. Example A.5 reviews the
method. At higher frequencies when the input impedance cannot be considered high
(due to capacitive effects), a basic model such as that of Figure 4(a) may be used.
Example
A.5
In the circuit of Figure 5(b) ﬁnd H(s) = V2/V1.
Solution
The noninverting terminal is at ground. Assuming a linear operation, the inverting
terminal is, therefore, at a virtual ground. By applying KCL at the inverting terminal
and noting that the op-amp doesn’t draw any current, we obtain
V1
R1
+ V2

CS + 1
R2

= 0,
V2
V1
= −R2
R1
1
1 + R2Cs

INDEX
A
abscissa, 122
of phasor V, 136
AC. See alternating current
acceptable sampling rate, 657
acoustic systems
echo in, 161
loudspeakers in, 174–175
reverberation in, 161
in room, 174–175
action potentials
dendrites and, 187
with EEG, 27
extracellular, 31, 31f
intracellular, 32, 33f
active ﬁlters, 534
frequency response of, 620
poles of, 620
project with, 618–621
system function of, 619
unit-step response of, 620
zeros of, 620
active tone controllers, frequency and, 528
A/D. See analog-to-digital converter
adaptive systems, 184, 184f
adders, in discrete-time systems,
1055f
admittance, 1099
AC and, 1098
generalized, 1102–1103
advance, 51
phase lead from, 130
time reversal and, 87
advanced unit-step functions, 39f
air pressure, voice and speech signals
and, 14
algebraic equations, from differential
equations, 314
aliasing
frequency domain and, 642–644
frequency downshifting and, 680f
real-time, 679–680
reconstruction ﬁlters and, 642
sampling and, 625, 642–644
sampling rate and, 682f
in voice and speech signals, 295
Al-kasi, 125n1
all-pass ﬁlters, 529, 545t
ﬁrst-order high-pass ﬁlters and, 537
second-order, 556, 556f
all-pass phase shifters, ﬁrst-order
input-output pairs and, 538–539
phase and, 538f
poles and, 538f
zeros and, 538f
almost-periodic signals, 35
sampling interval and, 692
discrete-time signals and, 692
almost-sinusoidal signals, 424
alpha, with EEG, 26
alphabet, noise and, 34
alternating current (AC)
admittance and, 1098
analysis of, 1097–1098
impedance and, 1098
quality factor Q and, 1100–1101
steady-state for, 495, 1096–1101
AM. See amplitude-modulated signal
American Standard Code (ASCII), 116
ampliﬁers, 1103–1104, 1103f
feedback with, 570–571, 570f, 1104
inverting, 169
noninverting, 571–572
amplitude
of beat frequency, 132
complex exponential functions and, 44
EMG and, 25
equalizers and, 528
exponential functions and, 81
FS and, 425
noise and, 34
of phasor V, 131
sinusoidal functions and, 44, 142–143
amplitude, complex, 129
in sinusoidal functions, 136
in two-sided spectrum, 136
waveforms and, 132
amplitude-modulated signal (AM), 443
bandpass signals and, 653–654
frequency downshifting, 648–649, 649f
FT and, 459
multilevel, 20
QAMs, 20–21, 21f
sampling, 653
1107

1108
Index
analog ﬁlters, 487–622. See also speciﬁc types
problems/solutions for, 584–618
projects for, 618–622
analog signals
differentiators of, 74–76, 75f
digital signals versus, 4
analog systems, 161
analog-to-digital converter (A/D), 158
angles. See also phase angle
of right triangle, 123–124, 124f
sinusoidal functions and, 123–124, 124f
angular frequency, 526f
phase shift and, 560
angular velocity, sinusoidal functions and, 129
antialiasing ﬁlter, 295
anticausal exponential functions, 712f
FT of, 432, 432f–433f
sinusoidal functions and, 835–836, 836f
z-transform of, 830, 831f, 835–836, 836f
anticausal functions
inverse z-transform and, 857, 857f
zeros and, 711
aperiodic functions. See nonperiodic functions
approximation error, sampling interval
and, 109
ASCII. See American Standard Code
associative property, of convolution, 224, 766
asymptotic behavior, of Bode plots, 505
atmosphere, CO2 in, 6–10, 9f
attenuation frequency
of ﬁrst-order low-pass ﬁlters, 531
of second-order notch ﬁlter, 554
audio signals, sampling of, 625
augmented voltage—left foot (AVL), 23
augmented voltage—right foot (AVR), 23
autocorrelation, 233–237
of energy signals, 233, 234, 240–241, 241t
even functions and, 233
integrators and, 234
multipliers and, 234
of power signal, 233, 234
of sunspots, 250–251
average power
in harmonics, 135, 486
in loudspeakers, 144, 145f
in one-sided linear spectrum, 135
in sinusoidal functions, 143
in waveforms, 133–134
AVL. See augmented voltage—left foot
AVR. See augmented voltage—right foot
axon collateral, 186
B
backward approximation method, 299–300
backward-difference operator, 742–743, 748f
approximation of, 1034–1035
differential equation for, 1034
band-limited signals
FT and, 452–453
sampling, 661
bandpass ﬁlters, 529
frequency response for, 1044f
pole-zero and, 1046, 1047f, 1076, 1076f
RLC circuits and, 558t, 585f
bandpass ﬁlters, second-order, 551–553
Bode plot of, 553f
frequency response of, 551
op-amp circuit and, 553
quality factor Q of, 551–552
system function of, 551
zeros and, 551
bandpass ﬁlters, simple, 1043–1044, 1044f
complex conjugate poles and, 1043–1044
bandpass signals
AM and, 653–654
FT and, 453
minimum sampling rate of, 656–657, 665, 666f
quadrature carrier and, 655f, 656
reconstruction, 658–661, 659f
sampling, 653–657, 656f, 659f, 665, 666f
sampling rate of, 659
uniform sampling of, 656
bandpass system, frequency response of, 516–518, 517f
bandstop ﬁlters, 529
bandwidth
with EEG, 26
with EMG, 25
feedback and, 568
FT and, 486
noise and, 34
Barker code, 113
Bartlett window, 450t, 451f, 714f
DFT and, 994t, 995t, 996f
beat frequency, in sinusoidal functions, 131–132
beats per minute (BPM), 22, 23f
beta, with EEG, 26
BIBO-stable. See bounded inputs-bounded output-stable
system
bilateral Laplace transform, 315–316, 343–346
convolution of, 349t
differentiation property of, 349t
of exponential functions, 344
integration of, 349t

Index
1109
inverse of, 350–353, 351f, 353f
of left-sided functions, 344
linearity of, 349t
multiplication by eat of, 349t
multiplication by t of, 349t
of one-sided functions, 345, 345t
properties of, 349–350, 349t
region of convergence of, 343, 345t, 346–349
of right-sided functions, 344
of sinusoidal functions, 345, 345t
time shift of, 349t, 350
transform pairs of, 354t
of two-sided exponential functions, 344, 346
unilateral Laplace transform and, 316
uniqueness theorem of, 349t
of unit-impulse functions, 329, 344
of unit-step functions, 344
bilinear transformation, 1035–1036, 1036f, 1086
ﬁrst-order ﬁlters and, 1054
IIR ﬁlters and, 1054
binary signals, noise and, 116–119
bioelectric signals, 22n7
bird song, waveforms of, 15f–16f, 16
bit rate
multilevel amplitude-modulation signals and, 20
in QPSK, 19
Blackman window, 451f, 714f
DFT and, 994t, 995t, 996f
Gibbs’ phenomenon and, 1050
Bode plots
asymptotic behavior of, 505
computer graphing of, 511–512
contributions to, 513–514, 514f
of dominant poles, 523f
of ﬁlters, 591–592
of ﬁrst-order high-pass ﬁlters, 536f
of ﬁrst-order low-pass ﬁlters, 532f
of frequency response, 501–514, 502f,
504f, 510f
of poles, 503, 509–510
of second-order bandpass ﬁlters, 553f
of second-order electric circuit, 521
sketching by hand, 512–513, 515f
of subsystems, 509
of third-order system, 509–510, 510f
of zeros, 501–503, 509–510
body waves, 13
bounded inputs-bounded output-stable system
(BIBO-stable), 526
in LTI discrete-time systems, 743
BPM. See beats per minute
break frequency, 506
with ﬁrst-order low-pass ﬁlters, 531
brick-wall ﬁlters, 529
Butterworth ﬁlter, 500, 825
with cutoff frequency, 143n3
C
capacitors
DC and, 321
in ﬁrst-order low-pass ﬁlters, 533
in loudspeakers, 144
unit-impulse functions and, 43f
unit-step functions and, 42–44, 43f
capacitor-resistor circuit (CR)
differentiators of, 75, 75f, 537, 537f
inverse systems and, 582–583, 583f
capacitor voltage
of electric circuits, 167–168
FS and, 390
Laplace transform and, 321
square waves and, 390
time average of, 210–211, 211f
carbon dioxide (CO2), 6–10, 9f
cascade structure
for FIR ﬁlters, 1057, 1057f
for IIR ﬁlters, 1060, 1060f
Cauchy’s theorem, 329, 349
causal exponential functions, 712f
convolution of, 219–220
even parts of, 438, 440–441
frequency and, 440–441
FT of, 432, 432f–433f
odd parts of, 438, 440–441
sinusoidal functions and, 834, 834f–835f
time and, 440–441
z-transform of, 834, 834f–835f, 836f
causal functions
convolution of, 788
convolution sum and, 772
of DTFT, 897–898
even parts of, 711–712, 712f
frequency domain and, 439
FT and, 439–441
inverse z-transform of, 855–856, 856f
Laplace transform of, 314
odd parts of, 711–712, 712f
of rectangular pulse, 439–440, 469
time domain and, 439
zeros and, 711
z-transform of, 833, 867–868

1110
Index
causality, in LTI discrete-time systems, 743
causal signals
even functions of, 59–60
even parts of, 60–61
odd functions of, 59–60
odd parts of, 60–61
causal systems, 162
differential equations and, 285
frequency response and, 498
inverse, 1014–1015
inverse systems and, 582
noncausal, 162, 315
unit-sample response of, 788
central nervous system (CNS), 184–185
CF. See climbing ﬁbers
characteristic equation, 274
of differential equations, 301–304
characteristic functions. See eigenfunctions
Chebyshev polynomial, 815
circuits. See electric circuits
circular convolution
DFT and, 764, 961–963, 961f, 966, 974–978
linear convolution from, 962–963, 974–978
circular convolution sum, 962
circular shift
DFT and, 956–960, 958t, 959f, 965
discrete-time signals and, 708–709
circular trajectory, of sinusoidal functions,
151, 152f
climbing ﬁbers (CF), 185f
closed-form expressions, 884–885
closed-loop system, 567f, 568, 1085–1088,
1089f
frequency response of, 574–575
of noninverting ampliﬁer, 571–572
op-amp circuit as, 573f, 574–575
CNS. See central nervous system
CO2. See carbon dioxide
coarse structure, noise and, 34–35
communication signals, 16–21
commutative property, of convolution, 223, 765
comparators, with feedback, 161
compensators, 528. See also lag compensators
complete solutions
differential equations and, 275–279
for LTI difference equations, 814, 815–819
natural frequency and, 275
complex amplitude, 129
in sinusoidal functions, 136
in two-sided spectrum, 136
waveforms and, 132
complex conjugate poles
natural frequency and, 276, 506
second-order low-pass ﬁlters and, 546
simple bandpass ﬁlter and, 1043–1044
underdamped system function and,
509, 526
complex exponential functions, 44
derivatives of, 73
discrete-time signals and, 688–689
LTI difference equations and, 805–806
complex frequency
eigenfunctions and, 1101
generalized impedance and, 1101–1103
in Laplace transform, 429
RLC circuits and, 1101–1102
complex low-pass signals
FT of, 651–653, 652f
sampling, 651–653
complex roots, z-transform and, 845–847
complex systems, 183–184
components
of signals, 314
of systems, 158
view of, 158
compression waves, in seismic signals, 12
conditional stimulus (CS), 29
conductance, 1099
conjugate poles, complex
natural frequency and, 276, 506
second-order low-pass ﬁlters and, 546
simple bandpass ﬁlter and, 1043–1044
underdamped system function and,
509, 526
conjugate symmetry
in differential equations, 299
in DTFT, 899–900, 924
even functions and, 434
in FS, 395
in FT, 434, 651
constants
for differential equations, 260, 264–265
DTFT and, 896
Laplace transform of, 317
linearity and, 162, 317, 734, 836, 896
in LTI difference equations, 798
partial fraction expansion and, 331
in RC circuit, 308
unit-impulse response and, 230
constant bias
frequency and, 141
linear phase with, 140–141, 562, 563

Index
1111
constant phase, 140
delay and, 562
distortion with, 141
in ﬁlters, 562
frequency and, 141
continuous signals, discrete-time signals versus, 3, 5f
continuous-space systems, 161
continuous spectrum, FT and, 428
continuous-time domain, discrete-time signals in, 684
continuous-time functions
convolution of, 203–204
FT and, 450, 450t
Laplace transform of, 859–864
LTI and, 526
waveforms of, 208–209
windows and, 450, 450t
continuous-time signals
discrete-time signals and, 624–627, 1029–1036, 1068n6
ﬁnite duration integration and, 1068, 1069f
frequency downshifting, 647, 667–668
FS and, 981t
FT and, 981t, 993–994
low-pass signals and, 625–626
matched ﬁlters and, 228, 229
sampling, 624–627, 696, 860
sampling interval and, 692
time series of, 423
triangular pulse and, 630
continuous-time systems, 161
Fourier analysis and, 182
continuous-time windows, DTFT and, 939–940, 940t
contour integrals, 329–330, 349
region of convergence for, 836f
z-transform and, 836f, 842, 854
controllers
active tone, 528
feedback of, 576
PID, 1084–1090
proportional, 570
as subsystems, 568, 569f
convergence of X(ω), 884
convolution, 54n11, 203–258. See also deconvolution
associative property of, 224, 766
of bilateral Laplace transform, 349t
of causal exponential functions, 219–220
of causal functions, 788
commutative property of, 223, 765
of continuous-time functions, 203–204
correlation and, 240–241
delay and, 251–252
differential equations and, 293–295
distributive property of, 223–224, 766
of DTFT, 898, 907–908, 909f
energy and, 228
of exponential functions, 245–246, 326–327
ﬁlters and, 226–228
in frequency domain, 628
of FT, 444–445, 447t, 458
graphical, 217–222, 218f, 774–779, 775f, 777t, 778f–779f
input-output pairs and, 326
inverse systems and, 784–787
of Laplace transform, 325–326, 336t, 359
of left-sided functions, 245
of LTI, 203–204, 779–782, 781t
matched ﬁlters and, 228–231, 229f, 230t
problems/solutions for, 242–255, 787–792
project for, 255–258, 792–795
properties of, 222–226, 765–766
of right-sided functions, 216, 245–246
sampling and, 628
of sinusoidal functions, 226–228
of square waves, 227, 227f
subsystems and, 204
superposition and, 767t
in time domain, 325, 444–445
time series and, 764
of two-sided exponential functions, 245–246
of unit-impulse functions, 458
of unit-impulse response, 219–220, 230, 293–295,
298, 488
of unit-sample function, 771
zero-state responses and, 298
in z-plane, 864
of z-transform, 839–840
convolution, circular
DFT and, 764, 961–963, 961f, 966, 974–978
linear convolution from, 962–963, 974–978
convolution, discrete, 763–795
analytic solution of, 771–773
numerical solution of, 766–768, 767t
product property of, 768–771
z-transform and, 827
convolution, linear
from circular convolution, 962–963, 974–978
DFT and, 962–963, 974–978
LTI and, 764–765, 765t
convolution integral, 214–217, 215f
evaluation and plotting of, 245, 246, 247f–249f
convolution sum, 765
causal functions and, 772
circular, 962
computation of, 764

1112
Index
convolution sum (continued)
for DFT, 962
for digital ﬁlters, 1055
for DTFT, 898
linear, 974
for LTI system, 212–214
in n-domain, 974
scale factor and, 214
time invariance and, 213
corner frequency, with ﬁrst-order low-pass
ﬁlters, 531
correlation, 203–258. See also autocorrelation;
cross-correlation
convolution and, 240–241
cross-correlation, 237–239
detection of, 238, 240
problems/solutions for, 242–255
cosine. See also raised cosine pulse; rectiﬁed
cosine pulse
Fourier coefﬁcient of, 390
FS and, 387
FT of, 459
phasor V and, 127, 129
in right triangle, 122, 123f
series approximation of, 124–125
sine and, 128
sinusoidal functions and, 122, 123f, 124–127
trigonometric relationships with, 125f, 126f
cosine functions
integrators of, 69f
time constant of, 69f
covariance functions (COV)
of sunspots, 235–236, 236f, 250
of unemployment, 236, 237f
CR. See capacitor-resistor circuit
critically damped system function, 519
cross-correlation, 237–239
of energy signals, 237
of sinusoidal functions, 238
templates and, 238
cross-covariance, of unemployment, 239, 239f, 251
CS. See conditional stimulus
cutoff frequency
Butterworth ﬁlter with, 143n3
for DTFT, 891f
for ﬁrst-order low-pass ﬁlters, 531
for Gaussian random signals, 693
for ideal ﬁlter, 633f
for low-pass ﬁlter, 630, 632, 633f, 640f–641f, 642, 647,
648, 729–730, 825, 891f, 1048
LTI difference equations and, 825
D
D/A. See digital-to-analog converter
damping ratio, 200, 1086
second-order systems and, 546n9
system function and, 504
undamped natural frequency and, 519–520
DC, 49
capacitors and, 321
decomposition and, 32
energy, 1095
exponential functions and, 687
signals, 1095
steady-state for, 66, 177, 264, 342
decay
discrete-time functions and, 687–688
of exponential functions, 40–41, 41f, 42f, 45f,
70–71
FT and, 471
of one-sided functions, 345, 345t
of sinusoidal functions, 85–86, 85f, 319, 471, 687–688,
688f
of two-sided exponential functions, 346
of unit pulse, 192
decimation
for DTFT, 912–918, 916f, 917f, 921f, 925, 943–946
time transformation for, 56f
decomposition, DC and, 32
deconvolution, 231–233, 783–784
input-output pairs and, 231, 232f
inverse systems and, 582, 792–795
successive calculations from, 232t, 233
unit-impulse response and, 231, 232f
degrees, of angles, 123
delay. See also group delay
constant phase and, 562
convolution and, 251–252
in discrete-time systems, 1055f
group, 141–142
of Laplace transform, 336t
with linear phase, 529
of LTI difference equations, 805t
of LTI discrete-time systems, 735
of phase, 529, 560–564
phase lag and, 130
phase shift and, 140–141
time reversal and, 53, 87
time shift from, 130
unit-step functions and, 39f, 53, 251–252
delta, with EEG, 26
dendrites, 185, 185f, 186f
action potentials and, 187

Index
1113
depolarization, of neurons, 30–31
derivatives
of complex exponential functions, 73
of differential equations, 299
with exponential functions, 73–74
of rectangular pulse, 73
of steplike time functions, 73, 74f
of unit-impulse functions, 176
of unit-step functions, 176
derivative properties
of differential equations, 299
of Laplace transform, 320–322
of LTI, 166
deterministic functions
for signals, 76
for systems, 76
deterministic signals
matched ﬁlters of, 255
versus random signals, 4–6
deterministic systems, 183
DFT. See discrete Fourier transform
difference equations
differential equations to, 1033
H(z) and, 1008–1009
for IIR ﬁlters, 1057
z-transform and, 848–850
difference equations, LTI, 797–825
complete solutions for, 814, 815–819
complex exponential functions and, 805–806
constants in, 798
cutoff frequency and, 825
deﬁnition of, 798–799
delay of, 805t
discrete-time signals and, 798
eigenfunctions of, 805
ﬁlters and, 825
frequency domain and, 798
g(n) and, 806–807
h(n) and, 807–809
homogeneous solutions for, 801–802, 813, 814–815
linearity of, 805t
low-pass ﬁlters by, 825
LTI discrete-time systems and, 745–747, 797–820
multiple roots and, 804
n-domain and, 800–801
numerical solution for, 799–800
particular solutions and, 802
problems/solutions for, 813–825
project for, 825
properties of, 805, 805t
sinusoidal functions and, 805–806
superposition and, 809–811
time-varying, 812–813
total solutions and, 803
unit-sample response and, 799
unit-step response and, 800, 806–809
zero-input responses and, 811–812
zero-state responses and, 811–812
zn and, 805
differential equations
algebraic equations from, 314
for backward approximation operator, 1034
characteristic equation of, 301–304
complete solutions and, 275–279
conjugate symmetry in, 299
constants for, 260, 264–265
convolution and, 293–295
derivatives in, 299
derivative properties of, 299
to difference equations, 1033
discontinuities and, 286
of electric circuit, 261
exponential inputs and, 282–283
formulation of, 260–270
for forward-difference operator, 1033
H(s) and, 492
homogeneous solutions for, 274–275, 277, 281–282,
301–304
of hydraulic system, 264–266
initial conditions of, 301–304
of input-output pairs, 261
integration of, 299
of interest rate modeling, 268–269
Laplace transform and, 314, 358–361, 488
linear equations from, 314
linearity of, 296, 299
LTI and, 259–311, 290f
of measurement system modeling, 269
of mechanical system, 263
of mixing process modeling, 266–267
multiple roots and, 279–280
natural frequency and, 280–281, 301–304
particular solutions and, 272–274, 273t, 286, 301–304
of piecewise linear system, 262–263
of population growth modeling, 267–268
problems/questions of, 301–304–310
project for, 310–311, 310f
properties of, 299
for second-order low-pass Butterworth ﬁlter, 825
of second-order systems, 269–270
for sinusoidal functions, 284–285
sinusoidal steady-state response and, 284–285, 304–305

1114
Index
differential equations (continued)
solving by numerical methods, 299–300
subsystems and, 260
system function and, 283–284, 304
systems of, 310–311, 310f
of thermal systems, 263–264
of time domain, 270–272
total solutions for, 278, 301–304
unit-impulse response and, 288–290
of unit jump, 290–292
unit-step response and, 285–288, 290f
zero-input responses and, 295–298
zero-state responses and, 295–298
differentiation
of bilateral Laplace transform, 349t
of FT, 444, 447t
of Laplace transform, 315, 320–322, 336t
of LTI discrete-time systems, 735–736
differentiators, 545t
of analog signals, 74–76, 75f
of CR, 75, 75f, 537, 537f
as ﬁlters, 528
of high-frequency limitations, 75f, 76
input-output pairs and, 537
op-amp circuit as, 74, 75f
of RL circuit, 537, 537f
of signals, 73–78
digital ﬁlters, 1036–1039. See also speciﬁc types
convolution sum for, 1055
description of, 1037–1038, 1072
design of, 1044–1046
discrete-time systems and, 1036
in frequency domain, 1075
frequency response and, 1037, 1039
gain factor and, 1037
poles and, 1039
pole-zero and, 1037, 1038, 1046, 1047f
problems/solutions for, 1060–1081
projects for, 1081–1084, 1082f, 1083t, 1085f
simple, 1039–1044
structures of, 1055–1060
system function and, 1037
time domain and, 1075
types of, 1037
unit-sample response and, 1037
zeros and, 1038
digital signal processing (DSP), 699
system of, 158
digital signals
versus analog signals, 4
pulses and, 47
systems of, 161
discrete-time signals and, 699–700, 700f
voice and speech signals as, 14
digital systems, 161
digital-to-analog converter (D/A), 158
sampling, 635–636
Dirac’s delta function
FT and, 457
unit-impulse functions and, 36, 291
direct-form structure
for FIR ﬁlters, 1056, 1056f, 1057f
for IIR ﬁlters, 1057–1060, 1058f
Dirichlet conditions
FS and, 385–386
FT and, 430
inverse FT and, 430
periodic functions and, 385–386
of periodic signals, 408
discontinuities
differential equations and, 286
Dirichlet conditions and, 385–386
forcing functions and, 290–292
FS and, 404
initial conditions and, 260
Laplace transform and, 314
smoothing of, 61–62
discrete convolution, 763–795
analytic solution of, 771–773
numerical solution of, 766–768, 767t
product property of, 768–771
z-transform and, 827
discrete equations, 299
discrete-event systems, 161
discrete Fourier transform (DFT), 947–1004
Bartlett window and, 994t, 995t, 996f
Blackman window and, 994t, 995t, 996f
circular convolution and, 764, 961–963, 961f, 966,
974–978
circular shift and, 956–960, 958t, 959f, 965
convolution sum for, 962
deﬁnition of, 948
by digital hardware, 995–996
of discrete-time function, 947
DTFT and, 968–970, 970f
even sequences and, 950, 966
even symmetry and, 983–984
examples of, 948–954
of exponential functions, 986
of exponential pulse, 953
FFT and, 948, 972–973, 973t
frequency shift and, 965

Index
1115
Hanning window and, 994t
linear convolution and, 962–963, 974–978
linearity of, 964
in matrix form, 978–981, 979f
modulation and, 965
n-domain and, 965
odd sequences and, 950, 966
Parseval’s theorem and, 966–967, 987–988
periodicity of, 964, 998
problems/solutions for, 983–993
project for, 993–1004, 994t, 995t, 996f, 999t, 1001t,
1003t, 1004t
properties of, 963–968, 968t
real-valued signals and, 965
of rectangular pulse, 952, 953f, 986
rectangular window and, 994t, 995t, 996f
sampling for, 882–883, 998
of sinusoidal functions, 953–954
spectrum analyzer and, 993–1004
time domain and, 964–965, 981t
time reversal and, 956–960, 957f, 964
tone burst and, 994t
transformation matrix and, 948
for triangular window, 983–984
waveform symmetry and, 965
windows and, 994–996, 994t, 995t
zero-padding and, 951–952, 951f, 962, 986–987, 986f
discrete-time Fourier transform (DTFT), 881–946. See also
inverse discrete-time Fourier transform
causal functions of, 897–898
conjugate symmetry for, 899–900, 924
constants and, 896
continuous-time windows and, 939–940, 940t
convolution of, 898, 907–908, 909f
convolution sum for, 898
cutoff frequency for, 891f
decimation for, 912–918, 916f, 917f, 921f, 925, 943–946
deﬁnition of, 883
DFT and, 968–970, 970f
discrete-time signals and, 981t
discrete-time windows and, 941, 941t
energy spectral density for, 900–902, 901f
even functions for, 924
even parts of, 897, 924
examples of, 885–888
frequency domain and, 927, 943
frequency domain windows and, 943
frequency downshifting for, 943–946
frequency shift for, 925
frequency translation of, 896–897
Gibbs’ phenomenon and, 941–943, 943f
Hanning window and, 940
input-output pairs for, 923
interpolation and, 918–919, 918f, 919f, 922f
linearity of, 896, 925
low-pass signal and, 917–918
magnitude and, 885–888, 886f, 888f, 926–927, 926f
modulation for, 925
multiplication by n for, 925
odd functions for, 924
odd parts of, 897, 924
Parseval’s theorem and, 900–902, 925
of periodic signals, 906–907, 908f
of power signals, 902–906
problems/solutions for, 926–938
product of two functions, 899
product property of, 898
projects for, 939–946
properties of, 895–900, 924
rate conversion and, 920–922
of rectangular pulse, 893–895, 894f, 908, 927–928, 928f
of sinusoidal functions, 904
theorems for, 895–900, 925
time constant for, 915
of discrete-time signals, 902–904, 903f
time domain and, 927, 981t
time reversal of, 896, 924, 925
time shift of, 896, 925
of triangular pulse, 928–929, 929f
of unit-sample function, 904–906
unit-sample response for, 927
waveforms of, 896
windows and, 939–944
zeros and, 909–912, 909f, 910f
z-transform and, 889–890
discrete-time functions, 625
DFT of, 947
exponential functions and, 687
sinusoidal functions and, 687–688
z-transform of, 827
discrete-time signals, 683–731, 686f
analytic representation of, 697
array representation of, 697–698
circular display of, 699, 699f
circular shift and, 708–709
complex exponential functions and, 688–689
versus continuous signals, 3, 5f
in continuous-time domain, 684
continuous-time signals and, 624–627, 1068n6
domain of, 684
DTFT and, 981t
even functions and, 709–712, 710f

1116
Index
discrete-time signals (continued)
ﬁlters and, 715–718
ﬁnite duration integration and, 1069
Gaussian random signals and, 693, 693f
generation of, 696f
ideal ﬁlters and, 729
LTI difference equations and, 798
nonperiodic signals and, 693
notch ﬁlters and, 728–730
odd functions and, 709–712, 710f
periodic signals and, 691–692
problems/solutions for, 718–728
processing of, 715–718
project for, 728–731
random signals and, 693
range of, 684
representation of, 697–699
sampling rate of, 34
sinc functions and, 689–690, 690f
sources of, 696–697
time reversal and, 700–702, 701f
time scaling with, 706–707
time series and, 686
time shift and, 703–704, 703t
time transformation with, 707–708
voice and speech signals and, 685
windows and, 713–715, 714f
discrete-time systems, 161
adders in, 1055f
delay in, 1055f
digital ﬁlters and, 1036
frequency response for, 1063, 1064f, 1069–1070
H(z) and, 1063, 1064f
modeling of, 1084–1090, 1085f, 1089f
multipliers in, 1055f
processing elements in, 1055f
sampling rate for, 1069–1070
simulation of, 1086–1087
discrete-time systems, LTI, 733–795
analysis and solution methods of, 751–752
BIBO-stable in, 743
block diagram representation of, 747–751, 749f, 750f,
751f
causality in, 743
classiﬁcation of, 743–744
delay of, 735
differentiation of, 735–736
input-output pairs and, 740–741, 743–744, 747, 753–755,
797
integration in, 743–744
linearity of, 734
LTI difference equations and, 745–747, 797–820
moving average of, 736
power signals and, 741–743
problems/solutions for, 752–757
project for, 757–762, 758f, 759f
properties of, 743–744
sinusoidal functions and, 741–743
stability in, 743
time domain and, 797
unit-sample response of, 737–741, 784–785
discrete-time windows, DTFT and, 941, 941t
distortion
with constant phase, 141
ﬁlters and, 530
linear, 530
linear phase and, 529
nonlinear, 530
sampling rate and, 34
distributed systems, H(s) of, 489
distributive property, of convolution, 223–224, 766
DJIA. See Dow Jones Industrial Average
dominant poles, 521–526
Bode plots of, 523f
frequency response and, 524
gain factor and, 522, 524
LHP and, 522
op-amp circuit and, 522–523
second-order systems and, 523–525
s-plane and, 524
system function and, 523–534
third-order system and, 524–525, 526f
vectors and, 525
zeros and, 522
Dow Jones Industrial Average (DJIA), 13, 624
DSP. See digital signal processing
DTFT. See discrete-time Fourier transform
DTMF. See dual-tone multi-frequency signal
duality
exponential functions and, 442
of FT, 441–442, 447t
rectangular pulse and, 441
dual-tone multi-frequency signal (DTMF), 18, 19f
duration. See also window averaging
noise and, 34
QRT, with EKG, 25
in time-limited signals, 447
dynamic equations
in electric circuits, 166
Laplace transform of, 340–343
of pendulum, 173
of systems, 161

Index
1117
dynamic systems, 161
ﬁlters in, 528
E
earth-center theory, plant movements and, 13n5
earthquakes, 11–12, 11f, 12f
ECG. See electrocorticogram
echo, in acoustic systems, 161
EEG. See electroencephalogram
effective value
for interest rate modeling, 268n2
RMS and, 49
eigenfunctions, 33, 177
complex frequency and, 1101
of LTI, 181n2
of LTI difference equations, 805
repertoire set and, 378
sinusoidal functions and, 181n2
for zn, 805
EKG. See electrocardiogram
electric circuits, 1093–1103. See also speciﬁc types
capacitor voltage of, 167–168
differential equations of, 261
dynamic equations of, 166
elements of, 1093
energy of, 1095
equations of, 1095
equilibrium in, 166
examples of, 166–172
inputs of, 167, 170
integrators and, 169
of inverting ampliﬁer, 169
Laplace transform of, 338–340
laws governing, 1093, 1094f
linear elements in, 1094–1095
multi-input, 170, 172
multi-output, 172
outputs of, 167, 170–171
passive elements in, 1094
signals of, 1095
sinusoidal functions and, 155, 156f
state-variables of, 167, 171–172
switches in, 1095
electrocardiogram (EKG), 4, 22–25, 23f
interpretation of, 24f–25f, 25
sampling of, 625
electrocorticogram (ECG), 28–29, 29f
electroencephalogram (EEG), 26–27
sampling of, 625
of sleep, 28f
electromagnetic waves
frequency range of, 128
polarization of, 153–156
electromyogram (EMG), 25–26, 27f, 30f
sampling of, 625
elementary functions, 36–48
elliptical trajectory, of sinusoidal functions, 151–152, 152f
EMG. See electromyogram
energy
convolution and, 228
DC, 1095
of electric circuits, 1095
time average of, 48–49
energy signals, 18
autocorrelation of, 233, 234, 240–241, 241t
cross-correlation of, 237
FT of, 429–430
discrete-time signals and, 700
energy spectral density
for DTFT, 900–902, 901f
Parseval’s theorem and, 446
energy storage elements, in systems, 161
envelope of Fourier coefﬁcients, 410–411, 411f
EPSP. See excitatory postsynaptic potentials
equal-component twin-T notch ﬁlter, 554–555, 555f
equalizers, 528
equilibrium, in electric circuits, 166
est
H(s) and, 489
LTI and, 489
eta, 213
Euler algorithm. See backward approximation method
even functions
autocorrelation and, 233
of causal signals, 59–60
conjugate symmetry and, 434
discrete-time signals and, 709–712, 710f
of DTFT, 924
of FT, 434, 435–436
problems/solutions for, 94
rectangular pulse as, 431
of sawtooth pulse, 59f
of signals, 58–61
two-sided exponential functions and, 833
z-transform of, 833
even parts, 58
of causal exponential functions, 438, 440–441
of causal signals, 60–61
of DTFT, 897, 924
frequency and, 439–441
of FS, 393t

1118
Index
even parts (continued)
of FT, 437–438, 447t
of rectangular pulse, 439–440
time and, 439–440
even sequences, DFT and, 950, 966
even symmetry
DFT and, 983–984
of FS, 393t, 396
evoked signal, with EEG, 26
excitatory postsynaptic potentials (EPSP),
32, 187
expansion by partial fractions, 314
exponential functions. See also ﬁnite
exponential
amplitude and, 81
bilateral Laplace transform of, 344
convolution of, 245–246, 326–327
DC and, 687
decay of, 40–41, 41f, 42f, 45f, 70–71
derivatives with, 73–74
DFT of, 986
discrete-time functions and, 687
duality and, 442
FS and, 383, 391–393, 412, 415
FT and, 428, 435, 436–437, 484t, 639f
Laplace transform of, 318
plotting of, 81–85
repertoire set and, 378
sinusoidal functions and, 44, 45f
sum of two, 82–85, 83f, 318
time constant of, 81, 82, 82f, 432f
time reversal of, 53
time shift of, 52
transform pairs of, 345t
truncated, 832–833
weighted integration of, 70–71
window averaging of, 94f
z-transform of, 833–836
exponential functions, anticausal, 712f
FT of, 432, 432f–433f
sinusoidal functions and, 835–836, 836f
z-transform of, 829–836, 830, 831f, 836f
exponential functions, causal, 712f
convolution of, 219–220
even parts of, 438, 440–441
frequency and, 440–441
FT of, 432, 432f–433f
odd parts of, 438, 440–441
sinusoidal functions and, 834, 834f–835f
time and, 440–441
z-transform of, 834, 834f–835f, 836f
exponential functions, complex, 44
derivatives of, 73
discrete-time signals and, 688–689
LTI difference equations and, 805–806
exponential functions, two-sided
bilateral Laplace transform of, 344, 346
convolution of, 245–246
decay of, 346
even functions and, 833
FT and, 436–437
region of convergence of, 348
z-transform of, 831–832, 832f, 833
exponential inputs
differential equations and, 282–283
LTI and, 176–178, 214f
for sinusoidal functions, 285
sinusoidal steady-state responses from, 285
time response to, 495
exponential pulse, 37, 38f
DFT of, 953
periodic signals and, 694
exponential time functions. See eigenfunctions
extracellular action potentials, 31, 31f
F
fast Fourier transform (FFT), 971–973, 972f
DFT and, 948, 972–973, 973t
time domain and, 981t
f-domain, 895, 895n5
feedback, 594–597, 595f
in adaptive systems, 184
in ampliﬁers, 570–571, 570f, 1104
bandwidth and, 568
comparators with, 161
of controllers, 576
frequency response and, 572
in IIR ﬁlters, 1058f, 1060
Laplace transform and, 314
negative, 569, 572f
in public address sound system, 174
second-order high-pass ﬁlters and, 551
subsystems and, 569f
in systems, 161–162, 162f, 567, 567f, 568–579, 569f
time response and, 575–576
unit-step response and, 568
FFT. See fast Fourier transform
Fibonacci numbers, 813
ﬁlters. See also speciﬁc types
Bode plots of, 591–592
classiﬁcation of, 529

Index
1119
constant phase in, 562
convolution and, 226–228
deﬁnition of, 528
description of, 529
differentiators as, 528
discrete-time signals and, 715–718
distortion and, 530
in dynamic systems, 528
frequency and, 226, 528
in frequency domain, 228
frequency response and, 529, 561f
FS of, 389–390
H(s) and, 529
integrators as, 528
interpolation, 632
linear phase and, 529
LTI difference equations and, 825
magnitude of, 529, 565–566, 565f
order of, 530
Paley-Wiener theorem and, 454
parallel RLC circuits and, 557–559, 558f, 558t
passband and, 529
phase and, 529
realization and, 530
reconstruction, 635f, 642
series RLC circuits and, 557–559, 558f
simple, 1039–1044
sinusoidal functions and, 140, 226–228, 528, 1083–1084,
1085f
stopband and, 529
synthesis and, 530
system function and, 529
in time domain, 226
for voice and speech signals, 1083–1084, 1084f
zeros and, 556–557
z-transform for, 874–879
ﬁlters, analog, 487–622. See also speciﬁc ﬁlters
problems/solutions for, 584–618
projects for, 618–622
ﬁlters, digital, 1036–1039. See also speciﬁc ﬁlters
convolution sum for, 1055
description of, 1037–1038, 1072
design of, 1044–1046
discrete-time systems and, 1036
in frequency domain, 1075
frequency response and, 1037, 1039
gain factor and, 1037
poles and, 1039
pole-zero and, 1037, 1038, 1046, 1047f
problems/solutions for, 1060–1081
projects for, 1081–1084, 1082f, 1083t, 1085f
simple, 1039–1044
structures of, 1055–1060
system function and, 1037
time domain and, 1075
types of, 1037
unit-sample response and, 1037
zeros and, 1038
ﬁlters, ﬁrst-order
by bilinear transformation, 1054
summary of, 545t
transfer function of, 544
ﬁnal-value theorem, of Laplace transform, 327
ﬁne structure, noise and, 34–35
ﬁnite duration integration. See window averaging
ﬁnite exponential, 48f
RMS of, 50
time average of, 50
Finite Impulse Response (FIR), 744
design of, 874–876, 1049f, 1050f
IDFT and, 955–956
IDTFT and, 1048
notch ﬁlters and, 874–876, 1077, 1077f
poles of, 1013
rectangular window and, 1048, 1049f
sampling and, 1051–1052
subsystems and, 1057
uniform windows of, 1016
unit-sample response of, 1013
zeros and, 874–876
z-transform and, 874–876
Finite Impulse Response (FIR), ﬁlters, 874–876
cascade structure for, 1057, 1057f
design of, 1047–1052
direct-form structure for, 1056, 1056f, 1057f
low-pass ﬁlter and, 1081–1082, 1082f, 1083t
project with, 1081–1084, 1082f, 1083t
structures of, 1056–1057
unit-sample response for, 1055
windows and, 1072–1075, 1081–1084,
1082f, 1083t
ﬁnite sum, of FS, 405–406
FIR. See Finite Impulse Response
ﬁrst-order all-pass phase shifters
input-output pairs and, 538–539
phase and, 538f
poles and, 538f
zeros and, 538f
ﬁrst-order ﬁlters
by bilinear transformation, 1054
summary of, 545t
transfer function of, 544

1120
Index
ﬁrst-order high-pass ﬁlters, 536–537
Bode plot of, 536f
H(s) and, 536
inputs in, 537
outputs in, 537
ﬁrst-order low-pass ﬁlters, 531–534
attenuation frequency with, 531
Bode plot of, 532f
break frequency with, 531
capacitors in, 533
corner frequency with, 531
cutoff frequency with, 531
frequency response of, 594
high-frequency asymptote and, 531
op-amp circuit and, 533
RC circuit and, 531–533, 532f
ﬂip-ﬂops, 161
ﬂip-shift-multiply-integrate recipe, 217
forced response. See particular solutions
forcing functions, 273t, 277
discontinuities and, 290–292
inputs as, 272
Laplace transform and, 314
particular responses and, 802, 802t
forward-difference operator, 748f
approximation of, 1033–1034
differential equation for, 1033
second-order, 748f
forward path, system function of, 567f, 568
4PSK. See quadrature-phase-shift-keyed signal
Fourier, Jean Baptiste Joseph, 33
on sinusoidal functions, 122
Fourier analysis, 33–34
computer explorations in, 423–425
continuous-time system and, 182
LTI and, 181–182
Fourier coefﬁcient, 378
of cosine, 390
envelope of, 410–411, 411f
generalized, 384–385
of harmonics, 484t
Fourier series (FS), 182, 377–425
almost-sinusoidal signals and, 424
amplitude and, 425
capacitor voltage and, 390
conjugate symmetry in, 395
continuous-time signals and, 981t
convergence of, 404
cosine and, 387
Dirichlet conditions and, 385–386
discontinuities and, 404
even parts of, 393t
even symmetry of, 393t, 396
expansion of, 122, 383–384
exponential functions and, 383, 391–393, 412, 415
ﬁlters of, 389–390
ﬁnite sum of, 405–406
frequency and, 378, 424-425
FT and, 428
fundamental frequency and, 383, 386
generalized, 384–385
Gibbs’ phenomenon and, 406, 407f
half-wave symmetry of, 393t, 397
harmonics and, 383
impulses of, 392, 398–404
input-output pairs of, 377–378
linearity of, 377
of LTI, 384
odd parts of, 393t
odd symmetry of, 393t, 396
Parseval’s theorem and, 393, 398
periodic signals and, 981t
problems/solutions for, 412–423
project for, 423–425
properties of, 393, 393t
pulses and, 398–404
RC circuit and, 390f
real-valued functions of, 393t, 414–415
rectangular pulse of, 388–389, 390f, 391, 399, 400t, 424
sampling and, 628–630, 631f
sawtooth pulse and, 380f, 413–414
signals and, 379–383
sine and, 387
sinusoidal functions and, 424
square wave and, 390
superposition of, 393t, 414–415
time and, 425
time average of, 397–398
time domain and, 981t
time reversal of, 393t, 394–395, 414–415
time shift of, 393t, 394–395, 414–415
tone burst and, 425
to transforms, 408–410
of triangular pulse, 392, 401, 402f, 425
trigonometric relationships and, 386–390, 412
vectors and, 384–385
waveform symmetry of, 396–397
Fourier transform (FT), 192, 427–486. See also discrete
Fourier transform; discrete-time Fourier transform; fast
Fourier transform; inverse Fourier transform
AM and, 459
of anticausal exponential functions, 432, 432f–433f

Index
1121
band-limited signals and, 452–453
bandpass signals and, 453
bandwidth and, 486
of causal exponential functions, 432, 432f–433f
causal functions and, 439–441
of complex low-pass signals, 651–653, 652f
conjugate symmetry of, 434, 651
continuous spectrum and, 428
continuous-time functions and, 450, 450t
continuous-time signals and, 981t, 993–994
convolution of, 444–445, 447t, 458
of cosine, 459
decay and, 471
differentiation of, 444, 447t
Dirac’s delta function and, 457
Dirichlet conditions and, 430
duality of, 441–442, 447t
of energy signals, 429–430
even functions and, 434, 435–436
even parts of, 437–438, 447t
exponential functions and, 428, 435, 436–437, 484t, 639f
formulae of, 467
frequency domain and, 439, 442, 638–639
frequency shift of, 443, 447t
FS and, 428
of generalized functions, 457
Gibbs’ phenomenon and, 454–456, 455f
harmonics and, 457
inputs of, 428
input-output pairs of, 428
integration of, 444
inverse, 430
Laplace transform and, 429
linearity of, 433–434, 447t, 468
linear phase and, 442
of low-pass ﬁlter, 638–639
of low-pass signals, 452, 632
modulation of, 447t
multiplication by t of, 447t
of nonperiodic signals, 428
notations of, 467
odd functions and, 436–437
odd parts of, 437–438, 447t
oscilloscope and, 482–486
of outputs, 428
Paley-Wiener theorem and, 453–454, 454f
Parseval’s theorem and, 446
as periodic functions, 630
of periodic signals, 428, 460–465, 464f
of periodic square wave, 485
of power signals, 456
problems/solutions for, 467–482
product property of, 445
project for, 482–486
properties of, 447t
of quantitative analysis, 429
raised cosine pulse of, 449
real-valued functions and, 430
of rectangular pulse, 431, 431f, 434–435, 448, 467–470
of sampled function, 628–630
sampling interval for, 423
of sawtooth pulse, 469–470
scale factor of, 447t
of sine, 459
of sinusoidal functions, 471, 484–485, 666–667
of sinusoidal waveforms, 484–485
time average and, 458–459
time constant and, 432
time domain and, 439, 464f, 981t
time-limited signals and, 447–449, 452
time reversal of, 434–435, 447t
time shift of, 442–443, 447t, 468
transform pairs of, 430–433, 465–466
of triangular pulse, 449, 485
two-sided exponential functions and, 436–437
unit-impulse functions and, 458–462, 462f
of voice and speech signals, 456
waveform symmetry of, 435–437
windows in, 450, 450t, 452f, 470–471
window averaging and, 451f
zero frequency of, 447t
zero time of, 447t
frequency. See also speciﬁc types
active tone controllers and, 528
bandpass signals and, 453
break, 506
causal exponential functions and, 440–441
constant bias and, 141
constant phase and, 141
in continuous-time to discrete-time conversion,
1030–1032
with CR differentiator, 75
of decaying sinusoidal functions, 85
of electromagnetic waves, 128
even parts and, 439–441
ﬁlters and, 226, 528
FS and, 378, 425
linear phase and, 141
LTI and, 178
noise and, 34
Nyquist rate and, 624–625
odd parts and, 439–440

1122
Index
frequency (continued)
passband and, 528
periodic functions and, 131
physical frequency count, 428
of rectangular pulse, 439–440
sampling rate and, 636
in seismic signals, 11
sinusoidal functions and, 44, 128, 137, 142–143
time-limited signals and, 448
frequency domain
aliasing and, 642–644
causal functions and, 439
convolution in, 628
digital ﬁlters in, 1075
DTFT and, 927, 943
ﬁlters in, 228
FT and, 439, 442, 638–639
harmonics in, 457
Laplace transform and, 488
LHP and, 526
linear phase in, 442
low-pass ﬁlters and, 632
LTI and, 488
LTI difference equations and, 798
power signals and, 456
reconstruction, 633f, 643f
sampling of, 631f, 643f
time domain and, 464f
windows and, 943
frequency downshifting, 644–649
aliasing and, 680f
AM, 648–649, 649f
continuous-time signals, 647, 667–668
for DTFT, 943–946
sinusoidal functions, 646–647, 646f, 667–668
temperature data, 644, 645f
frequency response H(ω), 487–622, 1015–1029
of active ﬁlters, 620
of bandpass ﬁlter, 1044f
of bandpass system, 516–518, 517f
Bode plots of, 501–514, 502f, 504f, 510f
causal systems and, 498
of closed-loop system, 574–575
digital ﬁlters and, 1037, 1039
of discrete-time systems, 1063, 1064f, 1069–1070
dominant poles and, 524
feedback and, 572
ﬁlters and, 529, 561f
of ﬁrst-order low-pass ﬁlter, 594
from H(z), 1019–1021
H(s) and, 489, 497–498, 497n4
of IIR, 1020–1021
of lag compensators, 541
of lag network, 544
Laplace transform and, 314
of lead compensators, 541
of lead network, 541f
of LTI, 1037n4
magnitude of, 496, 498, 499f, 502t, 503t, 565–566, 565f,
1015–1016
notation for, 1037n4
in open-loop system, 572–574
phase of, 496, 498, 499f, 502t, 503t
phasors and, 496–497
plotting, 500–514
poles and, 503
pole-zero and, 1027–1029, 1028f, 1029t
problems/solutions for, 584–618, 1060–1081
projects for, 618–622
quality factor Q and, 621
of second-order all-pass ﬁlters, 556
of second-order bandpass ﬁlters, 551
of second-order high-pass ﬁlters, 549
second-order low-pass ﬁlters and, 544
of second-order notch ﬁlters, 554
of sinusoidal functions, 496, 497n4
symmetry properties of, 498–500, 499f
systems and, 497
2π-period and, 1021–1024, 1022f
of uniform windows, 1016–1019, 1018f
vectors and, 515–518, 1025–1029, 1028f
zeros and, 501–503, 556, 557f
in z-plane, 1024, 1025f
frequency shift
of DFT, 965
of DTFT, 925
of FT, 443, 447t
frequency translation, of DTFT, 896–897
FS. See Fourier series
FT. See Fourier transform
functions. See also speciﬁc types
odd parts of, 437–438
plotting of, 76–78, 79f–80f
signals and, 3
fundamental frequency
FS and, 383, 386
in sinusoidal functions, 131
G
g(n), LTI difference equations and, 806–807
gain-bandwidth product (GBP), 573, 573f

Index
1123
gain factor, 513, 515, 927
digital ﬁlters and, 1037
dominant poles and, 522, 524
poles and, 524
zeros and, 524
Gaussian density functions, 47
Gaussian functions, 46–47
Gaussian pulse, 37, 38f
Gaussian random signals, 693, 693f
GBP. See gain-bandwidth product
GDP. See gross domestic product
generalized admittance, 1102–1103
generalized Fourier coefﬁcients, 384–385
generalized Fourier series, 384–385
generalized functions, FT of, 457
generalized impedance, complex frequency and, 1101–1103
Gibbs’ phenomenon
DTFT and, 941–943, 943f
FS and, 406, 407f
FT and, 454–456, 455f
with rectangular window, 1050
sinc functions and, 455f
good functions, 429
grad unit, 123n1
graphical convolution, 217–222, 218f, 774–779, 775f, 777t,
778f–779f
gross domestic product (GDP), 13n6
gross potential
with ECG, 28–29, 29f
with extracellular action potentials, 31f
group delay, 560–564
linear phase and, 529
sinusoidal functions and, 141–142
guess and test, 272
H
H(ω). See frequency response
h(n), LTI difference equations and, 807–809
H(s)
differential equations and, 492
distributed systems of, 489
est and, 489
ﬁlters and, 529
ﬁrst-order high-pass ﬁlters and, 536
frequency response and, 497–498, 497n4
Laplace transform and, 353–356, 491–492
LHP and, 500
of lumped systems, 489
RHP and, 500
as scale factor, 489
s-plane and, 515
time response and, 494–496
vectors and, 515–518
h(t), Laplace transform and, 355–356, 491–492
H(z)
difference equations and, 1008–1009
discrete-time systems and, 1063, 1064f
frequency response from, 1019–1021
inverse causal systems and, 1014–1015
system function, 1006–1011
time response and, 1009–1011
as vectors, 1025–1029, 1026f
zn and, 1006
z-transform and, 850, 1006–1007
half-wave symmetry, of FS, 393t, 397
Hamming window, 450t, 451f, 714f
Gibbs’ phenomenon and, 1050
Hanning window, 450, 452f, 470–471, 714f
DFT and, 994t, 995t, 996f
DTFT and, 940
Gibbs’ phenomenon and, 1050
harmonics. See also principal harmonic
average power in, 135, 486
Fourier coefﬁcient of, 484t
in frequency domain, 457
FS and, 383
FT and, 457
in one-sided linear spectrum, 134–135
of periodic functions, 484t
of periodic waveforms, 484t, 486
power in, 486
sawtooth pulse and, 380f
in sinusoidal functions, 131
of square waves, 381–383, 383f, 486
time average of, 390
in two-sided spectrum, 136
hermitian symmetry. See conjugate symmetry
high-frequency asymptote
ﬁrst-order low-pass ﬁlters and, 531
magnitude and, 566
poles and, 566
second-order low-pass ﬁlters and, 548
zeros and, 557f, 566
high-frequency limitations, differentiators of, 75f, 76
high-pass ﬁlters, 529, 545t
inverse systems and, 582–583, 583f
RLC circuits and, 558t
Sallen-Key, 550, 550f
high-pass ﬁlters, ﬁrst-order, 536–537
Bode plot of, 536f
H(s) and, 536

1124
Index
high-pass ﬁlters, ﬁrst-order (continued)
inputs in, 537
outputs in, 537
high-pass ﬁlters, second-order, 549–551
feedback and, 551
frequency response of, 549
LHP and, 549
magnitude of, 550t
phase of, 550t
poles and, 549
system function of, 549
homogeneous solutions
for differential equations, 274–275, 277, 281–282,
301–304
initial conditions and, 798
for Laplace transform, 322
for LTI difference equations, 801–802, 813,
814–815
natural frequency and, 798
hydraulic system, differential equations of,
264–266
hyperbolic functions, Laplace transform of, 320
hyperpolarization, of neurons, 30
hypotenuse, 122, 123f, 124, 124f
I
ideal ﬁlters, 529, 632
cutoff frequency of, 633f
design of, 1045–1046
discrete-time signals and, 729
IDFT. See inverse discrete Fourier transform
IDTFT. See inverse discrete-time Fourier transform
IIR. See Inﬁnite Impulse Response
impedance
AC and, 1098
generalized, 1101–1103
impulses. See also unit-impulse functions; unit-impulse
response
of FS, 392, 398–404
Laplace transform and, 314
Inﬁnite Impulse Response (IIR), 746
frequency response of, 1020–1021
z-transform and, 876–879
Inﬁnite Impulse Response (IIR), ﬁlters, 876–879
cascade structure for, 1060, 1060f
design of, 1052–1054, 1052–1055
difference equations for, 1057
direct-form structure for, 1057–1060, 1058f
feedback in, 1058f, 1060
structure of, 1057–1060
information
in random signals, 4n2
signals and, 2
inhibitory postsynaptic potentials (IPSP), 32, 187
initial conditions
of differential equations, 301–304
discontinuities and, 260
homogeneous solutions and, 798
Laplace transform and, 314
natural frequency and, 798
system function and, 495
for unilateral Laplace transform, 315
unit jump and, 290
unit-sample response and, 788
unit-step response and, 286
zero-input responses and, 295–296
zero-state responses and, 296
z-transform and, 828
initial conditions, nonzero, 288, 811
Laplace transform and, 314
outputs and, 853
initial-value theorem, of Laplace transform, 327
inputs. See also bounded inputs-bounded
output-stable system; exponential inputs;
zero-input responses
of acoustic system, 174–175
bounded, 525
of electric circuits, 167, 170
in ﬁrst-order high-pass ﬁlters, 537
as forcing functions, 272
of FT, 428
of lag network, 544
of lead network, 542
of LTI, 179
phasors, 497
pole-zero cancellation in, 579–581, 580f
in probabilistic systems, 183
of public address sound system, 174
repertoire set and, 378
step, 175–176
of systems, 159–160
time shift of, 162–163
unit jumps in, 290–291
input-output pairs
convolution and, 326
deconvolution and, 231, 232f
differential equation of, 261
differentiators and, 537
for DTFT, 923
ﬁrst-order all-pass phase shifters and, 538–539
of FS, 377–378

Index
1125
of FT, 428
H(s) and, 489
integration of, 743–744
of Laplace transform, 490–491
of LTI, 204, 206, 231, 260
of LTI discrete-time systems, 740–741, 743–744, 747,
753–755, 797
outputs and, 205f, 206f, 207f
s-domain and, 326
sinusoidal functions and, 489n3
of systems, 159–160
system function and, 493–494
unit-sample response and, 740–741, 1075
for z-transform, 865–866
instantaneous power, 133
integration
of bilateral Laplace transform, 349t
of differential equations, 299
of FT, 444, 447t
of input-output pairs, 743–744
of Laplace transform, 320–322
of LTI, 166
in LTI discrete-time systems, 743–744
integrators, 545t
autocorrelation and, 234
of cosine functions, 69f
electric circuits and, 169
as ﬁlters, 528
leakage in, 64f, 65–66, 67f
op-amp circuit of, 63, 64f, 67f
problems/solutions for, 94–95
in RC circuit, 63, 64f, 65, 534–535
in RL circuit, 535–536
s-domain and, 65–66
of signals, 61–67
smoothing with, 61–67, 62f
time domain and, 66
interest rate modeling
differential equations of, 268–269
effective value for, 268n2
nominal value for, 268n2
periodicity with, 236
International Morse Code, 115n13
interpolation
DTFT and, 918–919, 918f, 919f, 922f
ﬁlter, 632
formula, 632
sampling rate and, 636
time transformation for, 56f
intracellular action potentials, 32, 33f
inverse causal systems, 1014–1015
inverse discrete Fourier transform (IDFT)
examples of, 954–956
FIR and, 955–956
inverse discrete-time Fourier transform (IDTFT)
deﬁnition of, 883–884
examples of, 890–892, 891f, 892f–893f
FIR and, 1048
inverse Fourier transform, 430
inverse Laplace transform, 314, 329–331, 361–363
region of convergence of, 329
inverse of bilateral Laplace transform, 349–353
region of convergence of, 351, 350f, 353f
inverse systems, 582–584, 582f
causal systems and, 582
convolution and, 784–787
CR and, 582–583, 583f
deconvolution and, 582
high-pass ﬁlters and, 582–583, 583f
unit-impulse response and, 582
unit-sample response in, 784–785
inverse z-transform, 842–843
anticausal functions and, 857, 857f
causal functions and, 855–856, 856f
residue method for, 854–859
two-sided functions and, 858–859, 859f
inverting ampliﬁer, 169
IPSP. See inhibitory postsynaptic potentials
K
Kaiser window, Gibbs’ phenomenon and, 1050
Kirchhoff’s current law (KCL), 65, 166–167, 1093, 1094f
phasors and, 1099
Kirchhoff’s voltage law (KVL), 65, 166–167, 1093, 1094f
Laplace transform and, 321
phasors and, 1099
L
lag compensators, 540–544, 545t
frequency response of, 541
poles and, 540
zeros and, 540
lag network, 543–544, 543f
frequency response of, 544
inputs of, 544
outputs of, 544
Laplace transform, 177. See also inverse Laplace transform
applications of, 313–376
causal functions and, 314

1126
Index
Laplace transform (continued)
complex frequency in, 429
of constants, 317
of continuous-time functions, 859–864
convolution of, 325–326, 336t, 359
deﬁnition of, 315–316
derivative properties of, 320–322
differential equations and, 314,
358–361, 488
differentiation of, 315, 320–322, 336t
discontinuities and, 314
of dynamic equations, 340–343
of electric circuits, 338–340
examples of, 356–361
of exponential functions, 318
ﬁnal-value theorem of, 327
forcing functions and, 314
frequency domain and, 488
FT and, 429
H(s) and, 354–356, 491–493
h(t) and, 355–356, 491–493
of hyperbolic functions, 320
impulses and, 314
initial conditions and, 314
initial-value theorem of, 327
input-output pairs of, 490–491
integration of, 320–322
inverse, 314, 329–331, 361–363
linearity of, 317
LTI and, 293, 314, 363–365
models of, 338f, 338t
multiplication by eat of, 324, 336t
multiplication by t of, 323, 336t
nonzero initial conditions and, 314
partial fraction expansion of, 331–335
problems/solutions for, 361–375
project for, 375–376
properties of, 336t
of pulse-shaping circuit, 375–376
of rectangular pulse, 318, 325
region of convergence of, 316, 326,
490–491
scale factor of, 325, 336t
s-domain and, 324
of sinusoidal functions, 319, 320f
steady-state and, 366
superposition and, 360–361
systems and, 314
system function and, 314, 354–356
theorems of, 336t
time domain and, 338, 357–360
time shift of, 324–325
trigonometric relationships and, 319
uniqueness theorem of, 316
of unit-impulse functions, 328–329
of unit-impulse response, 364–365
z-transform from, 860
Laplace transform, bilateral, 315–316, 343–346
convolution of, 349t
differentiation property of, 349t
of exponential functions, 344
integration of, 349t
inverse of, 349–353
of left-sided functions, 344
linearity of, 349t
multiplication by eat of, 349t
multiplication by t of, 349t
of one-sided functions, 345, 345t
properties of, 348–349, 349t
region of convergence of, 343, 345t, 346–349
of right-sided functions, 344
of sinusoidal functions, 345, 345t
time shift of, 349t, 349
transform pairs of, 353t
of two-sided exponential functions, 344, 346
unilateral Laplace transform and, 316
uniqueness theorem of, 349t
of unit-impulse functions, 329, 344
of unit-step functions, 344
Laplace transform, inverse, 329
Laplace transform, unilateral, 315
bilateral Laplace transform and, 316
examples of, 317–320
initial conditions for, 315
lower limit of integration in, 328
time in, 330f
transform pairs of, 337t
lead compensators, 540–544, 545t
frequency response of, 541
poles and, 540
zeros and, 540
lead network, 540, 540f
frequency response of, 541f
inputs of, 542
outputs of, 542
phase of, 541f
system function of, 542
leads, on EKG, 22
leakage
in integrators, 64f, 65–66, 67f
sampling and, 642–644
windows and, 644

Index
1127
left-half plane (LHP)
dominant poles and, 522
frequency domain and, 526
h(s) and, 500
poles in, 518–521
in region of convergence, 346
second-order high-pass ﬁlters and, 549
of s-plane, 518–521, 526, 861
underdamped system function and, 525
zeros in, 500n5
left-sided functions
bilateral Laplace transform of, 344
convolution of, 245
LHP. See left-half plane
linear convolution
from circular convolution, 962–963, 974–978
DFT and, 962–963, 974–978
LTI and, 764–765, 765t
linear convolution sum, 974
linear distortion, 530
linear equations
from differential equations, 314
in s-domain, 488
linearity
of bilateral Laplace transform, 349t
constants and, 162, 317, 734, 836, 896
of DFT, 964
of differential equations, 296, 299
distributive property and, 223
of DTFT, 896, 925
of FS, 377
of FT, 433–434, 447t, 468
of Laplace transform, 317, 336t
of LTI, 162–165
of LTI difference equations, 805t
of LTI discrete-time systems, 734
proportionality from, 162
rectangular pulse and, 210
superposition and, 204, 809
testing of, 188, 189
time shift and, 162–163
unit-step response and, 288
for z-plane, 864
of z-transform, 836–837
linear phase
with constant bias, 140–141, 562, 563
delay with, 529
distortion and, 529
ﬁlters and, 529
frequency and, 141
in frequency domain, 442
FT and, 442
group delay and, 529
time shift and, 529
linear time-invariant systems (LTI), 158,
162–165
analysis and solution methods of, 182
complex exponential functions and, 44
continuous-time differential equations for, 798
continuous-time functions and, 525
convolution of, 203–204, 779–782, 781t
convolution sum of, 212–214
deconvolution and, 231
derivative properties of, 166
differential equations and, 259–311, 290f
discrete-time systems of, 733–795
eigenfunctions of, 181n2
est and, 489
exponential inputs and, 176–178, 214f
Fourier analysis and, 181–182
frequency and, 178
frequency domain and, 488
frequency response of, 1037n4
FS of, 384
inputs of, 179
input-output pairs of, 204, 206, 231, 260
integration of, 166
Laplace transform and, 293, 314, 363–365
linear convolution and, 764–765, 765t
linearity of, 162–165
modeling of, 622
outputs of, 179, 223
parallel connection of, 567f
rectangular pulse in, 214–215
scale factors of, 178
series connection of, 567f
sinusoidal functions and, 33–34, 122,
178–179, 496
step inputs and, 175–176
superposition of, 179–181
system function of, 489
time average and, 177–178
time domain and, 488
time response of, 494–496
time shift of, 560
transfer function for, 182
unit-impulse functions and, 175–176
unit-impulse response of, 180–181, 188–189, 192,
206–209, 219–220, 242, 293, 364–365
unit-sample response of, 773, 1013–1014
unit-square pulse in, 191
z-transforms and, 850–851

1128
Index
linear time-invariant systems (LTI), difference equations of
complete solutions for, 814, 815–819
complex exponential functions and, 805–806
constants in, 798
cutoff frequency and, 825
deﬁnition of, 798–799
delay of, 805t
discrete-time signals and, 798
eigenfunctions of, 805
ﬁlters and, 825
frequency domain and, 798
g(n) and, 806–807
h(n) and, 807–809
homogeneous solutions for, 801–802, 813, 814–815
linearity of, 805t
low-pass ﬁlters by, 825
LTI discrete-time systems and, 745–747, 797–820
multiple roots and, 804
n-domain and, 800–801
numerical solution for, 799–800
particular solutions and, 802
problems/solutions for, 813–825
project for, 825
properties of, 805, 805t
sinusoidal functions and, 805–806
superposition and, 809–811
time-varying, 812–813
total solutions and, 803
unit-sample response and, 799
unit-step response and, 800, 806–809
zero-input responses and, 811–812
zero-state responses and, 811–812
zn and, 805
linear time-invariant systems (LTI), discrete-time systems of
analysis and solution methods of, 751–752
BIBO-stable in, 743
block diagram representation of, 747–751, 749f, 750f,
751f
causality in, 743
classiﬁcation of, 743–744
delay of, 735
differentiation of, 735–736
input-output pairs and, 740–741, 743–744, 747,
753–755, 797
integration in, 743–744
linearity of, 734
LTI difference equations and, 745–747, 797–820
moving average of, 736
power signals and, 741–743
problems/solutions for, 752–757
project for, 757–762, 758f, 759f
properties of, 743–744
sinusoidal functions and, 741–743
stability in, 743
time domain and, 797
unit-sample response of, 737–741, 784–785
linear trajectory, of sinusoidal functions, 151,
152f, 155
Lissajous patterns, of sinusoidal functions, 151–156,
152f, 154f
longitudinal waves, in seismic signals, 11–12
loudspeakers
in acoustic system, 174–175
average power in, 144, 145f
capacitors in, 144
Love waves, in seismic signals, 13
lower limit of integration, in unilateral Laplace
transform, 328
low-frequency asymptote, 501, 502f, 504–505,
508, 521
low-pass ﬁlters, 529, 545t, 825
cutoff frequency for, 630, 632, 633f, 640f–641f,
642, 647, 648, 729–730, 825, 891f, 1048
design of, 1045–1046
FIR ﬁlters and, 1081–1082, 1082f, 1083t
frequency domain and, 632
FT of, 638–639
of Gaussian random signals, 693
LTI difference equations and, 825
passive second-order, 587f
RLC circuits and, 558t
Sallen-Key, 287, 548–549, 590
sampled function through, 632
simple, 1039–1044
of time-discrete signals, 729
time domain and, 632–634
unit-step response of, 456
low-pass ﬁlters, ﬁrst-order, 531–534
attenuation frequency with, 531
Bode plot of, 532f
break frequency with, 531
capacitors in, 533
corner frequency with, 531
cutoff frequency with, 531
frequency response of, 594
high-frequency asymptote and, 531
op-amp circuit and, 533
RC circuit and, 531–533, 532f
low-pass ﬁlters, second-order, 544–549
Butterworth, 500, 825
complex conjugate poles and, 546
frequency response and, 544

Index
1129
high-frequency asymptote and, 548
overdamped system function and, 547f
poles and, 544
quality factor Q of, 546–548
system function and, 544
underdamped system function and, 546
zeros and, 544
low-pass signals
bandpass signals and, 453
continuous-time signals and, 625–626
DTFT and, 917–918
FT and, 452, 632
reconstruction of, 632–634
sampling of, 632–634, 638–640
time constant of, 638
LTI. See linear time-invariant systems
LTI difference equations, low-pass ﬁlters and, 825
lumped systems, H(s) of, 489
L-waves, in seismic signals, 13
M
magnitude
DTFT and, 885–888, 886f, 888f, 926–927, 926f
of ﬁlters, 529, 565–566, 565f
of frequency response, 496, 498, 499f, 502t, 503t,
565–566, 565f, 1015–1016
high-frequency asymptote and, 566
of second-order high-pass ﬁlters, 550t
M-ary phase-shift-keyed signal (MPSK), 19
matched ﬁlters
convolution and, 228–231, 229f, 230t
of deterministic signals, 255
outputs and, 231
project for, 256f
Receiver Operating Curve and, 256
SNR and, 255, 256, 257f
unit-impulse response and, 230
measurement system modeling, differential equations
of, 269
mechanical system, differential equations of, 263
memory, in systems, 161
microelectrodes, 31
minimum sampling rate, 657
of bandpass signal, 656–657, 665, 666f
mixing process modeling, differential equations
of, 266–267
modulation. See also amplitude-modulated signal
of DFT, 965
of DTFT, 925
of FT, 447t
Morse, Samuel, 115n13
Morse code, 115, 115n13
mossy ﬁbers, 185f
moving average
of LTI discrete-time systems, 736
simple, 736
in window averaging, 71–72, 72f
MPSK. See M-ary phase-shift-keyed signal
multi-input systems, 170, 183
multi-output systems with, 172
multilevel amplitude-modulation
signals, 20
multi-output systems, 170–171, 183
with multi-input systems, 172
multiple roots
differential equations and, 279–280
LTI difference equations and, 804
z-transform and, 847–848
multiplication by an
for z-plane, 864
for z-transform, 841–842
multiplication by eat
for bilateral Laplace transform, 349t
for Laplace transform, 324, 336t
multiplication by n
for DTFT, 925
for z-plane, 864
for z-transform, 841
multiplication by t
for bilateral Laplace transform, 349t
for FT, 447t
for Laplace transform, 323, 336t
multipliers
autocorrelation and, 234
in discrete-time systems, 1055f
multivariable systems, 183
N
natural frequency, 272
complete solutions and, 275
complex conjugate poles and, 276, 506
differential equations and, 280–281, 301–304
homogeneous solutions and, 798
initial conditions and, 798
Laplace transform and, 314
second-order systems and, 546n9
natural frequency, undamped, 1086
damping ratio and, 519–520
quality factor Q and, 520

1130
Index
natural frequency, undamped (continued)
second-order systems with, 528
system function and, 504
natural response. See homogeneous solutions
natural signals, examples of, 6–13
n-domain
convolution sum in, 974
DFT and, 965
LTI difference equations and, 800–801
negative deﬂection, in ECG, 29f
negative feedback, of op-amp circuit, 572f
nerve impulses. See action potentials
neuroelectric signals, 22n7
from neurons, 30–32
sampling, 677
neurons, 185–186
modeling of, 187–188
neuroelectric signals from, 30–32
polarization in, 187, 187f
systems of, 184–188
noise. See also signal-to-noise ratio
binary signals and, 116–119
signals and, 34–35
white Gaussian, 693f
nominal value, for interest rate modeling,
268n2
noncausal systems, 162
bilateral Laplace transform of, 315
noninverting ampliﬁer, 571–572
nonlinear distortion, 530
nonlinear time-varying LTI difference
equations, 812–813
nonperiodic functions, 137
nonperiodic signals
discrete-time signals and, 693
FT of, 182, 428
power signals and, 456
nonrecursive systems, 744
nonuniform sampling, 661–662
nonzero initial conditions, 288, 811
Laplace transform and, 314
outputs and, 853
Northridge earthquake, 12f
notch ﬁlters, 1078
discrete-time signals and, 728–730
equal-component twin-T, 554–555, 555f
FIR and, 874–876, 1077, 1077f
notch ﬁlters, second-order, 554–555
attenuation frequency of, 554
frequency response of, 554
system function of, 554
Nyquist, H., 624n1
Nyquist rate, 34, 921f
frequency and, 624–625
sampling and, 642
O
odd functions
of causal signals, 59–60
discrete-time signals and, 709–712, 710f
of DTFT, 924
FT and, 436–437
problems/solutions for, 94
of sawtooth pulse, 59f
of signals, 58–61
odd parts, 58
of causal exponential functions, 438, 440–441
of causal functions, 711–712, 712f
of causal signals, 60–61
of DTFT, 897, 924
frequency and, 439–440
of FS, 393t
of FT, 437–438, 447t
of functions, 437–438
of rectangular pulse, 439–440
time and, 439–441
odd sequences, DFT and, 950, 966
odd symmetry, of FS, 393t, 396
off-line, 5, 53
one-sided functions
bilateral Laplace transform of, 345, 345t
decay of, 345, 345t
problems/solutions for, 92–93
z-transforms and, 852–853
one-sided linear spectrum
average power in, 135
peak-to-peak value in, 135
power in, 134
sinusoidal functions and, 134–135
waveforms in, 135
op-amp circuit, 1104–1103, 1104f
as closed-loop system, 573f, 574–575
as differentiator, 74, 75f
dominant poles and, 522–523
ﬁrst-order low-pass ﬁlters and, 533
of integrators, 63, 64f, 67f
negative feedback of, 572f
as open-loop system, 573
second-order bandpass ﬁlters and, 553
state-variables of, 171f
Wien-bridge oscillator and, 527f

Index
1131
open circuits, 1095
open-loop control project, 200–201, 201f
open-loop system, 1084–1085
frequency response in, 572–574
op-amp circuit as, 573
open-loop transfer function, 567f
ordinate, 122
oscillations, of systems, 526–528, 527f
oscilloscope, 155
FT and, 482–486
outputs. See also bounded inputs-bounded output-stable
system; input-output pairs; multi-output systems
of acoustic system, 174–175
bounded, 525
commutative property and, 223
of electric circuits, 167, 170–171
in ﬁrst-order high-pass ﬁlters, 537
FT of, 428
input-output pairs and, 205f, 206f, 207f
of lag network, 544
of lead network, 542
of LTI, 179, 223
matched ﬁlters and, 231
nonzero initial conditions and, 853
phasors, 497
in probabilistic systems, 183
superposition and, 215
of systems, 159–160
time shift of, 162–163
overdamped system function, 519
second-order low-pass ﬁlter and, 547f
P
Paley-Wiener theorem
ﬁlters and, 454
FT and, 453–454, 454f
parallel connection
of LTI, 567f
of systems, 567
parallel RLC circuits, ﬁlters and, 557–559, 558f, 558t
Parseval’s theorem
DFT and, 966–967, 987–988
DTFT and, 900–902, 925
energy spectral density and, 446
FS and, 393, 398
FT and, 446
of rectangular pulse, 446
partial fraction expansion
constants and, 331
of inverse of bilateral Laplace transform, 352–353
of Laplace transform, 331–335
of z-transform, 843–848
particular solutions
of differential equations, 272–274, 273t, 286, 301–304
of LTI continuous-time differential equations, 798
of LTI difference equations, 802
passband, 142
ﬁlters and, 529
frequency and, 528
passive ﬁlters, 534
passive second-order low-pass ﬁlter, 587f
peak-to-peak value, in one-sided linear spectrum, 135
pendulum
dynamic equations of, 173
systems of, 172–173, 173f
time invariance of, 173
periodic functions
combinations of, 132, 137
Dirichlet conditions and, 385–386
frequency and, 131
FT as, 630
harmonics of, 484t, 486
nonperiodic functions and, 137
of rectangular pulse, 485, 486t
sawtooth waveform and, 380f
sinusoidal functions and, 127–128, 131, 132, 137
square wave and, 381–383, 382f, 485
sum of, 35
triangular pulse and, 485
waveforms from, 132, 484t
periodicity, 3
of DFT, 964, 998
of interest rate modeling, 236
in s-plane, 861f
of sunspots, 685
of unemployment, 13
zero-crossing and, 689
periodic signals. See also almost-periodic signals
Dirichlet conditions of, 408
discrete-time signals and, 691–692
DTFT of, 906–907, 908f
examples of, 694, 695f
exponential pulse and, 694
FS and, 981t
FT of, 182, 428, 460–465, 464f
sinc functions and, 694, 695f
sum of two, 692
time shift and, 703–704, 703t
tone burst and, 694, 695f
as transforms, 463–464
unit-impulse functions and, 460–462, 462f

1132
Index
phase
delay of, 529, 560–564
equalizers and, 528
ﬁlters and, 529
ﬁrst-order all-pass phase shifters and, 538f
of frequency response, 496, 498, 499f, 502t, 503t
of lead network, 541f
of second-order high-pass ﬁlters, 550t
phase, constant, 140
delay and, 562
distortion with, 141
in ﬁlters, 562
frequency and, 141
phase, linear
with constant bias, 140–141, 562, 563
delay with, 529
distortion and, 529
ﬁlters and, 529
frequency and, 141
in frequency domain, 442
FT and, 442
group delay and, 529
time shift and, 529
phase angle
of decaying sinusoidal functions, 85
of unit-step response, 520
phase lag
from delay, 130
proof of, 592–593
of sinusoidal functions, 81, 129, 129f, 130f
phase lead
from advance, 130
proof of, 592–593
of sinusoidal functions, 129, 129f, 130f
phase shift. See also ﬁrst-order all-pass phase shifters
angular frequency and, 560
delay and, 140–141
of public address sound system, 174
of sinusoidal functions, 130
phase-shift keyed signals (PSK), 19–20, 20f
phasors
frequency response and, 496–497
inputs, 497
KCL and, 1099
KVL and, 1099
method, 1097
outputs, 497
phasor V, 44
abscissa of, 136
amplitude of, 131
cosine and, 127, 129
sinusoidal functions and, 127, 129, 129f
sums of, 130–131, 131f
as vector, 136
physical frequency content, 428
physiologic signals, 21–22. See also electrocardiogram;
electrocorticogram; electroencephalogram;
electromyogram; neuroelectric signals
applications of, 32
PID controller, 1084–1090
piecewise linear system, differential equations
of, 262–263
plant movements, earth-center theory and, 13n5
plotting. See also Bode plots
of exponential functions, 81–85
of functions, 76–78, 79f–80f
of sinusoidal functions, 80–81, 81f, 85–86, 85f
polarization
of electromagnetic waves, 153–156
in neurons, 187, 187f
poles. See also complex conjugate poles; dominant
poles
of active ﬁlters, 620
Bode plot of, 503, 509–510
digital ﬁlters and, 1039
of FIR, 1013
ﬁrst-order all-pass phase shifters and, 538f
frequency response and, 503
gain factor and, 524
high-frequency asymptote and, 566
lag compensators and, 540
Laplace transform and, 314, 331
lead compensators and, 540
in LHP, 518–521
partial fraction expansion and, 331
relationship between, 507f
second-order high-pass ﬁlters and, 549
second-order low-pass ﬁlters and, 544
second-order systems and, 546n9
simple low-pass ﬁlters and, 1040–1043
s-plane and, 515
stability and, 1014
of systems, 493–494
of system function, 494, 509, 1011–1015
unit-step response and, 518–519
vectors from, 516
zeros and, 556
z-transform and, 876–879
pole-zero
bandpass ﬁlters and, 1046, 1047f, 1076, 1076f
digital ﬁlters and, 1037, 1038, 1046, 1047f
frequency response from, 1027–1029, 1028f, 1029t

Index
1133
pole-zero cancellation
in inputs, 579–581, 580f
in RC circuit, 580
in RL circuit, 580
in transfer functions, 581
population growth modeling, differential equations of,
267–268
positive deﬂections, in ECG, 29f
postsynaptic potentials, 32
power
in harmonics, 486
in one-sided linear spectrum, 134
RMS of, 49
in sinusoidal functions, 133–134
superposition of, 133, 134
time average of, 48–49
in waveforms, 133
power, average
in harmonics, 135, 486
in loudspeakers, 144, 145f
in one-sided linear spectrum, 135
in sinusoidal functions, 143
in waveforms, 133–134
power signals
autocorrelation of, 233, 234
DTFT of, 902–906
frequency domain and, 456
FT of, 456
LTI discrete-time systems and, 741–743
nonperiodic signals and, 456
time-discrete signals and, 700
PP interval, 25
practical ﬁlters, 530
primary waves, in seismic signals, 12
principal harmonic
extraction of, 730–731
of square wave, 228
PR interval, in EKG, 25
probabilistic systems, 183, 183f
product property
of discrete convolution, 768–771
of DTFT, 898
of FT, 445
proportional controller, 570
proportionality, from linearity, 162
PSK. See phase-shift keyed signals
public address sound system, 174
pulses, 47–48, 48f. See also speciﬁc types
FS and, 398–404
time and, 47–48
pulse-shaping circuit, Laplace transform of, 375–376
Purkinje cells, 185, 185f, 186f
pyramidal cells, 185f
Q
QAMs. See quadrature amplitude modulation signals
QP interval, in EKG, 25
QPSK. See quadrature-phase-shift-keyed signal
QRT duration, in EKG, 25
quadrature amplitude modulation signals (QAMs), 20–21,
21f
quadrature axis, 21
quadrature carrier, bandpass signals and, 655f, 656
quadrature-phase-shift-keyed signal (QPSK, 4PSK), 19–20,
20f
quality factor Q, 506
AC and, 1100–1101
frequency response and, 621
of second-order bandpass ﬁlters, 551–552
of second-order low-pass ﬁlters, 546–548
second-order systems and, 546n9
undamped natural frequency and, 520
unit-step responses and, 621
zeros and, 556–557
R
radians, of angles, 123
radiating, voice and speech signals and, 14
raised cosine pulse
FT of, 449
RMS of, 50
time average of, 50
time-limited signals and, 449
raised cosine window, 48f
random repetitive sampling, 662
random sampling, 661–662
random signals
deterministic signals versus, 4–6
in deterministic systems, 183
discrete-time signals and, 693
Gaussian, 693, 693f
information in, 4n2
problems/solutions for, 95, 96f
random trace generator, 1090–1091, 1090f
rate conversion, DTFT and, 920–922
rate of change, noise and, 34
Rayleigh waves, in seismic signals, 13
RC circuits
constants in, 308
ﬁrst-order low-pass ﬁlters and, 531–533, 532f

1134
Index
RC circuits (continued)
FS and, 390f
integrators of, 63, 64f, 65, 534–535
pole-zero cancellation in, 580
sinusoidal functions and, 178–179
unit-impulse response in, 175–176
reactance, 1099
realization, ﬁlters and, 530
real-time sampling, reconstruction, and aliasing, 679–680
real-valued functions
of FS, 393t, 414–415
of FT, 430
of systems, 158–159
of time, 158–159
real-valued signals, 378
DFT and, 965
Receiver Operating Curve (ROC), 256
recession
GDP and, 13n6
unemployment and, 13, 14f
reconstruction
aliasing and, 642
bandpass signals, 658–661, 659f
ﬁlters, 635f, 642
frequency domain, 633f, 643f
of low-pass signals, 632–634
problems/solutions for, 662–676
projects for, 677–681
real-time, 679–680
time domain, 623–681, 634f
unit-impulse response and, 635f
rectangular pulse, 37, 38f
causal functions of, 439–440, 469
derivatives of, 73
DFT of, 952, 953f, 986
DTFT of, 893–895, 894f, 908, 927–928, 928f
duality and, 441
as even functions, 431
even parts of, 439–440
frequency of, 439–440
FS of, 388–389, 390f, 391, 399, 400t, 424–425
FT of, 431, 431f, 434–435, 448, 467–470
graphical convolution of, 220–221
Laplace transform of, 318, 325
linearity and, 210
in LTI system, 214–215
odd parts of, 439–440
Parseval’s theorem of, 446
periodic functions of, 485, 486t
RMS of, 50
sampling, 679–680
time of, 439–440
time average of, 50
time invariance and, 210
time-limited signals and, 448
rectangular window, 714f
DFT and, 994t, 995t, 996f
FIR and, 1048, 1049f
Gibbs’ phenomenon with, 1050
rectiﬁed cosine pulse, 48f
RMS of, 50
time average of, 50
recursive systems, 744
region of convergence (ROC)
of bilateral Laplace transform, 343, 345t, 346–349
for contour integrals, 836f
of inverse Laplace transform, 329
of inverse of bilateral Laplace transform, 350f, 351, 353f
of Laplace transform, 316, 326, 490–491
LHP in, 346
RHP in, 346
of two-sided exponential functions, 348
of z-transform, 829–832, 830f, 835–836, 836f, 866
relative power spectral density, of square wave, 135, 135t
repeated roots. See multiple roots
repertoire set, 378
residue method, for inverse z-transform, 854–859
resistance, 1099
responses, superposition of, 204–211
reverberation, in acoustic system, 161
right-half plane (RHP)
H(s) and, 500
in region of convergence, 346
of s-plane, 861
system stability and, 525
zeros in, 500n5
right-sided functions
bilateral Laplace transform of, 344
convolution of, 216, 245–246
problems/solutions for, 92
time reversal of, 92
time shift of, 92
right triangle
angles of, 123–124, 124f
cosine in, 122, 123f
sine in, 122, 123f
RLC circuits
bandpass ﬁlters and, 585f
complex frequency and, 1101–1102
parallel, 557–559, 558f
series, 557–559, 558f
sinusoidal functions and, 1097

Index
1135
RL circuits, 1100
differentiators of, 537, 537f
integrators in, 535–536
pole-zero cancellation in, 580
RMS. See root-mean squared
ROC. See Receiver Operating Curve; region of
convergence
root-mean squared (RMS)
calculations of, 49–50
of sinusoidal functions, 133
rotary motion of fan, sampling, 678
RR interval, in EKG, 25
S
Sallen-Key high-pass ﬁlter, 550, 550f
Sallen-Key low-pass ﬁlter, 287, 548–549, 590
sample and hold ﬁlters (S/H), of sinusoidal
functions, 636, 637f
sampled function
FT of, 628–630
through low-pass ﬁlter, 632
sampling
aliasing and, 625, 642–644
AM, 653
of audio signals, 625
of band-limited signals, 661
of bandpass signals, 653–657, 656f, 659f, 665, 666f
of complex low-pass signals, 651–653
of continuous signals, 4
of continuous-time signals, 624–627, 696, 860
of continuous-time to discrete-time conversion,
1032–1036
convolution and, 628
D/A, 635–636
DFT and, 882–883, 998
of EEG, 625
of EKG, 625
of EMG, 625
FIR and, 1051–1052
of frequency domain, 631f, 643f
FS and, 628–630, 631f
leakage and, 642–644
of low-pass signals, 632–634, 638–640
mathematical representation of, 627–630, 628f
of neuroelectric signals, 677
nonuniform, 661–662
Nyquist rate and, 642
problems/solutions for, 662–676
projects for, 677–681
random, 661–662
random repetitive, 661
real-time, 679–680
rectangular pulse, 679–680
rotary motion of fan, 678
sequential repetitive, 644, 664
of sinusoidal functions, 661, 662–663, 667–668,
680f
of stochastic signals, 662
strobe light and, 678, 678f
of temperature data, 645f
time and, 627–628
time domain, 623–681, 628f
uniform, 627, 656, 1030
of unit-impulse functions, 664–665
of voice and speech signals, 295, 625, 626–627
of zero-crossing, 678
sampling interval, 624
almost-periodic signals and, 692
approximation error and, 109
continuous-time signals and, 692
for FT, 423
sinusoidal functions, 666–667
sampling rate, 624
acceptable, 657
aliasing and, 682f
of bandpass signal, 659
for discrete-time systems, 1069–1070
frequency and, 636
interpolation and, 636
minimum, 656–657, 657, 665, 666f
noise and, 34
reducing error with, 640, 640f–641f
for sinusoidal functions, 154–155, 666–667,
667f
for triangular pulse, 640f–641f
sampling theorem, 624, 624n1
San Andreas fault, 11f
sawtooth pulse, 48f
even functions of, 59f
FS of, 380f, 413–414
FT of, 469–470
harmonics and, 380f
odd functions of, 59f
RMS of, 50
time average of, 50, 86–87
time compression of, 56f
time reversal of, 53f, 54f
time shift of, 52f, 54f
time transformation of, 86–87
waveform of, 380f

1136
Index
scalar, voice and speech signals and, 14
scale factor
convolution sum and, 214
of FT, 447t
H(s) as, 489
of Laplace transform, 325, 336t
of LTI, 178
of time, 56
of zn, 805, 1006
Schmitt triggers, 161
s-domain
complex exponential functions and, 44
input-output pairs and, 326
integrators and, 65–66
Laplace transform and, 324
linear equations in, 488
time domain and, 325
second-order all-pass ﬁlters, 556, 556f
second-order backward-difference operator, 748f
second-order bandpass ﬁlters, 551–553
Bode plot of, 553f
frequency response of, 551
op-amp circuit and, 553
quality factor Q of, 551–552
system function of, 551
zeros and, 551
second-order forward difference operator, 748f
second-order high-pass ﬁlters, 549–551
feedback and, 551
frequency response of, 549
LHP and, 549
magnitude of, 550t
phase of, 550t
poles and, 549
system function of, 549
second-order low-pass Butterworth ﬁlter, 500
differential equation for, 825
second-order low-pass ﬁlters, 544–549
complex conjugate poles and, 546
frequency response and, 544
high-frequency asymptote and, 548
overdamped system function and, 547f
poles and, 544
quality factor Q of, 546–548
system function and, 544
underdamped system function and, 546
zeros and, 544
second-order notch ﬁlters, 554–555
attenuation frequency of, 554
frequency response of, 554
system function of, 554
second-order systems
Bode plot of, 521
damping ratio and, 546n9
differential equations of, 269–270
dominant poles and, 523–526
natural frequency and, 546n9
poles and, 546n9
quality factor Q and, 546n9
system function and, 518–521
with undamped natural frequency, 528
zeros and, 556, 557f
seismic signals, 10–13
seismographs, 11f
sequential repetitive sampling, 644, 664
series connection
of LTI, 567f
of systems, 566–567
series RLC circuits, ﬁlters
and, 557–559, 558f, 558t
S/H. See sample and hold ﬁlters
Shannon, C. E., 624n1, 969n1
sheer waves (S-waves), in seismic signals, 13
short circuits, 1095
sieving, 37
signals. See also speciﬁc types and relevant topics
characterization of, 32–35
components of, 314
DC, 1095
decomposition of, 32–35
deterministic functions for, 76
differentiators of, 73–78
of electric circuits, 1095
even functions of, 58–61
FS and, 379–383
functions and, 3
information and, 2
integrators of, 61–67
mathematical representations of, 35–48
meaning and, 2
noise and, 34–35
odd functions of, 58–61
operations on, 51
problems/solutions for, 76–120
processing of, 715–718
projects for, 116–120
smoothing of, 61–67, 62f
time and, 314
time averages with, 48–50
as time series, 686
as vectors, 384–385
waveforms and, 2–3

Index
1137
weighted integration of, 68–71
window averaging of, 71–72
signal constellation, of QAMs, 21
signal-to-noise ratio (SNR), 255, 256, 257f
simple bandpass ﬁlter, 1043–1044, 1044f
complex conjugate poles and, 1043–1044
simple ﬁlters, 1039–1044
simple low-pass ﬁlter, 1039–1044
simple moving average, 736
simple real-valued roots, z-transform and, 844–845
sinc functions, 45–46, 45f
discrete-time signals and, 689–690, 690f
Gibbs’ phenomenon and, 455f
periodic signals and, 694, 695f
sinc pulse, 37, 38f
sine
cosine and, 128
FS and, 387
FT of, 459
in right triangle, 122, 123f
series approximation of, 124–125
sinusoidal functions and, 122, 123f, 124–127
trigonometric relationships with, 125f, 126f
sinusoidal functions, 40, 121–156
almost-sinusoidal functions, 424
amplitude and, 142–143
angles and, 123–124, 124f
angular velocity and, 129
anticausal exponential functions and, 835–836, 836f
average power in, 143
beat frequency in, 131–132
bilateral Laplace transform of, 345, 345t
causal exponential functions and, 834, 834f–835f
circular trajectory of, 151, 152f
combinations of, 131–132
complex amplitude in, 136
complex exponential functions and, 44
complex representation of, 136
convolution of, 226–228
cosine and, 122, 123f, 124–127
cross-correlation of, 238
decay of, 85–86, 85f, 319, 320f, 471, 687–688,
688f
DFT of, 953–954
differential equations for, 284–285, 304–305
discrete-time functions and, 687–688
DTFT of, 902–904
eigenfunctions and, 181n2
electric circuits and, 155, 156f
electromagnetic wave polarization and, 153–156
elliptical trajectory of, 151–152, 152f
exponential functions and, 44, 45f
exponential inputs for, 285
ﬁlters and, 140, 226–228, 528, 1083–1084, 1085f
Fourier, Jean Baptiste Joseph on, 122
frequency and, 127–128, 137, 142–143
frequency downshifting, 646–647, 646f, 667–668
frequency response of, 496, 497n4
FS of, 424
FT of, 471, 484–485, 666–667
fundamental frequency in, 131
group delay and, 141–142
harmonics in, 131
input-output pairs and, 489n3
Laplace transform of, 319
linear trajectory of, 151, 152f, 155
Lissajous patterns of, 151–156, 152f, 154f
LTI and, 33–34, 122, 178–179, 496
LTI difference equations and, 805–806
LTI discrete-time systems and, 741–743
multilevel amplitude-modulation signals and, 20
one-sided linear spectrum and, 134–135
periodic functions and, 127–128, 131, 132, 137
phase lag of, 81, 129, 129f, 130f
phase lead of, 129, 129f, 130f
phase shift with, 130
phasor V and, 127, 129, 129f
plotting of, 80–81, 81f, 85–86, 85f
power in, 133–134
problems/solutions for, 137–150
projects for, 151–156
in public address sound system, 174
QPSK and, 19
RC circuits and, 178–179
RLC circuits and, 1097
RMS of, 133
sampling, 661, 662–663, 667–668, 680f
sampling interval, 667
sampling rate of, 154–155, 667, 667f
S/H of, 636, 637f
sine and, 122, 123f, 124–125, 128
steady-state for, 284–285, 304–305
sums of, 132, 136, 137, 142–143
time average in, 143
time shift with, 130
trajectories of, 151–156
trigonometric relationships with, 125f, 126f
two-sided spectrum and, 136, 136f
vectors in, 127f
waveforms by, 126–127, 484–485
zero-crossing and, 678
z-transform of, 833–836

1138
Index
sleep, EEG of, 28f
smoothing
with integrators, 61–67, 62f
of signals, 61–67, 62f
SNR. See signal-to-noise ratio
societal signals, 13
spectrum analyzer, DFT and, 993–1004
speech signals. See voice and speech signals
spikes. See action potentials
s-plane
dominant poles and, 524
H(s) and, 515
LHP of, 518–521, 525, 861
mapping of, 862f
periodicity in, 861f
poles and, 515
RHP of, 861
system function and, 515
vectors in, 515
z-plane and, 859–864
spontaneous signals, with EEG, 26
square waves
capacitor voltage and, 390
convolution of, 227, 227f
FS and, 390
harmonics of, 381–383, 383f, 486
periodic functions and, 381–383, 382f, 485
principal harmonic of, 228
relative power spectral density of, 135, 135t
stability. See also bounded inputs-bounded output-stable
system
in ﬁrst-order all-pass phase shifters, 538
in LTI discrete-time systems, 743
poles and, 1014
state-variables
of electric circuits, 167, 171–172
of op-amp circuit, 171f
of systems, 160
static systems, 161
steady-state
for AC, 495, 1096–1101
for DC, 66, 177, 264, 342
Laplace transform and, 366
for sinusoidal functions, 284–285, 304–305
for zn, 805
Steinmetz, Charles, 1097
step inputs, LTI systems and, 175–176
steplike time functions, derivatives of, 73, 74f
stochastic signals, sampling, 662
stopband, 529
strobe light, sampling and, 678, 678f
subsystems
analysis of, 158
Bode plots of, 509
controllers as, 568, 569f
convolution and, 204
differential equations and, 260
feedback and, 569f
FIR and, 1057
loading, 568
transfer function of, 174
z-transform and, 827
sunspots, 6, 7f–8f
autocorrelation of, 250–251
covariance functions of, 235–236, 236f, 250
discrete-time signals of, 685
periodicity with, 685
time series for, 235
superposition, 203–258, 208t
convolution and, 767t
of FS, 393t, 414–415
Laplace transform and, 360–361
linearity and, 204, 809
of LTI, 179–181
LTI difference equations and, 809–811
outputs and, 215
of power, 133, 134
problems/solutions for, 242–255
of responses, 204–211
in time domain, 360–361
time invariance and, 809
zero-input responses and, 811
zero-state responses and, 811
surface waves, in seismic signals, 11
susceptance, 1099
S-waves. See sheer waves
switches, in electric circuits, 1095
symmetry. See also conjugate symmetry; even symmetry;
waveform symmetry
half-wave, 393t, 397
synapses, 187
synthesis, ﬁlters and, 530
systems, 157–201, 161. See also electric circuits; speciﬁc
types and relevant topics
adaptive, 184, 184f
classiﬁcation of, 160–162
components and, 158
deﬁnition of, 158
deterministic functions for, 76
of differential equations, 310–311, 310f
of DSP, 158
dynamic equations of, 161

Index
1139
energy storage elements in, 161
equation formulation of, 159–160
feedback with, 161–162, 162f, 567, 567f, 568–579, 569f
frequency response and, 497
inputs of, 159–160
input-output pairs of, 159–160
interconnection of, 566–568
Laplace transform and, 314
memory in, 161
of neurons, 184–188
oscillations of, 526–528, 527f
outputs of, 159–160
parallel connection of, 567
of pendulum, 172–173, 173f
poles of, 493–494
problems/solutions for, 188–200
projects for, 200–201, 201f
real-valued functions and, 158–159
response graphing of, 588–589
series connection of, 566–567
state-variables of, 160
time invariance of, 162–165
view of, 158
system function, 487–622, 1005–1015
of active ﬁlters, 619
critically damped, 519
damping ratio and, 504
deﬁnition of, 489–494
differential equations and, 283–284, 304
digital ﬁlters and, 1037
dominant poles and, 523–534
ﬁlters and, 529
of forward path, 567f, 568
H(z), 1006–1011
initial conditions and, 495
input-output pairs and, 493–494
Laplace transform and, 314, 353–356
of lead network, 542
of LTI, 489
overdamped, 519
poles of, 494, 509, 1011–1015
as practical ﬁlter, 530
problems/solutions for, 584–618, 1060–1081
projects for, 618–622
of second-order all-pass ﬁlters, 556
of second-order bandpass ﬁlters, 551
of second-order high-pass ﬁlters, 549
of second-order low-pass ﬁlters, 544
of second-order notch ﬁlters, 554
second-order systems and, 518–521
s-plane and, 515
undamped natural frequency and, 504
zeros and, 494, 509, 556, 1011–1015
system function, underdamped, 519
complex conjugate poles and, 509, 525
LHP and, 525
second-order low-pass ﬁlters and, 546
T
Taylor series expansion, 191
Tejon earthquake, 11f
temperature data
discrete-time signals of, 685
frequency downshifting, 644, 645f
sampling, 645f
templates, cross-correlation and, 238
thermal systems, differential equations of, 263–264
theta, with EEG, 26
Thevenin’s equivalent, 145f
third-order system
Bode plot of, 509–510, 510f
dominant poles and, 524–525, 526f
time. See also frequency
causal exponential functions and, 440–441
compression, 56, 56f
even parts and, 439–440
FS and, 425
odd parts and, 439–440, 440–441
pulses and, 47–48
real-valued functions of, 158–159
of rectangular pulse, 439–440
sampling and, 627–628
scale factor of, 56
signals and, 314
in unilateral Laplace transform, 330f
unit-step functions and, 90
voice and speech signals and, 14
time average
calculations of, 49–50
of capacitor voltage, 210–211, 211f
FS and, 397–398
FT and, 458–459
of harmonics, 390
Laplace transform and, 321
LTI system and, 177–178
of power, 48–49
problems/solutions for, 86–87
of sawtooth pulse functions, 86–87
of signals, 48–50
of sinusoidal functions, 143

1140
Index
time constant
of cosine functions, 69f
of DTFT, 915
of exponential functions, 41, 81, 82, 82f, 432f
of FT, 432
of low-pass signal, 638
of postsynaptic potentials, 32
time shift and, 52
of unit-impulse response, 192
weighted integration and, 69f, 70–71
discrete-time signals
almost-periodic signals and, 692
digital signals and, 699–700, 700f
DTFT of, 902–904, 903f
energy signals and, 700
low-pass ﬁlter of, 729
power signals and, 700
time domain
bandpass signals and, 453
causal functions and, 439
convolution of, 325, 444–445
DFT and, 964–965, 981t
differential equations of, 270–272
digital ﬁlters and, 1075
DTFT and, 927, 981t
FFT and, 981t
ﬁlters in, 226
frequency domain and, 464f
FS and, 981t
FT and, 439, 464f, 981t
integrators and, 66
Laplace transform and, 338, 357–360
low-pass ﬁlters and, 632–634
LTI and, 488
LTI discrete-time systems and, 797
problems/solutions for, 662–676
projects for, 677–681
reconstruction, 623–681, 634f
sampling, 623–681, 628f
s-domain and, 325
superposition in, 360–361
time-limited signals and, 448
windows and, 941
time-invariance. See also linear time-invariant systems
convolution sum and, 213
of pendulum, 173
rectangular pulse and, 210
repertoire set and, 378
superposition and, 809
testing of, 188, 189, 737, 752
time inversion. See time reversal
time-limited signals
duration in, 447
frequency and, 448
FT and, 447–449, 452
raised cosine pulse and, 449
rectangular pulse and, 448
time domain and, 448
triangular pulse and, 449
windows and, 450
time response
to exponential inputs, 495
feedback and, 575–576
H(s) and, 494–496
H(z) and, 1009–1011
of LTI system, 494–496
time reversal
advance and, 87
delay with, 87
of DFT, 956–960, 957f, 964
discrete-time signals and, 700–702, 701f
of DTFT, 896, 924, 925
of FS, 393t, 394–395, 414–415
of FT, 434–435, 447t
problems/solutions for, 87, 88f–89f
of right-sided functions, 92
of sawtooth pulse, 53f, 54f
time shift with, 53–55, 54f, 54n11, 87–89, 88f–89f,
704–706, 705f
unit-step functions and, 53
of z-transform, 838–839, 864
time scaling, with discrete-time signals, 706–707
time series
of continuous-time signals, 423
convolution and, 764
discrete-time signals and, 686
signals as, 686
for sunspots, 235
time shift, 51
of bilateral Laplace transform, 349t, 349
from delay, 130
discrete-time signals and, 703–704, 703t
of DTFT, 896, 925
of FS, 393t, 394–395, 414–415
of FT, 442–443, 447t, 468
of input, 162–163
of Laplace transform, 324–325
linearity and, 162–163
linear phase and, 529
of LTI, 560
of output, 162–163
of periodic signals, 703–704, 703t

Index
1141
problems/solutions for, 87, 88f–89f
of right-sided functions, 92
of sawtooth pulse, 52f, 54f
of sinusoidal functions, 130
with time reversal, 53–55, 54f, 54n11, 87–89, 88f–89f,
704–706, 705f
time reversal with, 704–706, 705f
for z-plane, 864
of z-transform, 837–838
time transformation, 57f, 88f–89f
for decimation, 56f
with discrete-time signals, 707–708
general form of, 56–57
for interpolation, 56f
problems/solutions for, 86–87, 93–94
of sawtooth pulse functions, 86–87
of signals, 51–57
tone burst
DFT and, 994t
FS and, 425
periodic signals and, 694, 695f
torque, of pendulum, 172–173
total solutions
for differential equations, 278, 301–304
for LTI difference equations, 803
transducers
of physiologic signals, 21
voice and speech signals and, 14
transfer function
of ﬁrst-order ﬁlters, 544
for LTI system, 182
open-loop, 567f
pole-zero cancellation in, 581
of subsystems, 174
transforms. See also speciﬁc transforms
FS expansion to, 408–410
periodic signals as, 463–464
transformation matrix, DFT and, 948
transform pairs, 316
of bilateral Laplace transform, 353t
of exponential functions, 345t
of FT, 430–433, 465–466
of unilateral Laplace transform, 337t
transverse waves, in seismic signals, 12, 13
triangular pulse
continuous-time signals and, 630
DTFT for, 928–929, 929f
FS of, 392, 401, 402f, 425
FT of, 449
from graphical convolution, 220–221
periodic functions and, 485
RMS of, 50
sampling rate of, 640f–641f
time average of, 50
time-limited signals and, 449
triangular window, 48f, 714f
DFT for, 983–984
trigonometric relationships
with cosine, 125f, 126f
FS and, 386–390, 412
Laplace transform and, 319
with sine, 125f, 126f
with sinusoidal functions, 125f, 126f
truncated exponential function, 832–833
z-transform of, 832–833
2π-period, frequency response and, 1021–1024, 1022f
2PSK. See two-state phase-shift-keyed signal
two-sided exponential functions
bilateral Laplace transform of, 344, 346
convolution of, 245–246
decay of, 346
even functions and, 833
FT and, 436–437
region of convergence of, 348
z-transform of, 831–832, 832f, 833, 836f
two-sided functions, inverse z-transform and, 858–859, 859f
two-sided spectrum
complex amplitude in, 136
harmonics in, 136
sinusoidal functions and, 136, 136f
waveforms and, 136
two-state phase-shift-keyed signal (2PSK), 19
U
undamped natural frequency, 505, 1086
damping ratio and, 519–520
quality factor Q and, 520
second-order systems with, 528
system function and, 504
underdamped system function, 519
complex conjugate poles and, 509, 526
LHP and, 525
second-order low-pass ﬁlters and, 546
undetermined coefﬁcients, 272n5
unemployment
covariance functions of, 236, 237f
cross-covariance of, 239, 239f, 251
periodicity of, 13
recession and, 13, 14f
uniform sampling, 627, 656, 1030

1142
Index
uniform windows, 736
of FIR, 1016
frequency response of, 1016–1019, 1018f
unilateral Laplace transform, 315
bilateral Laplace transform and, 316
examples of, 317–320
initial conditions for, 315
lower limit of integration in, 328
time in, 330f
transform pairs of, 337t
uniqueness theorem
of bilateral Laplace transform, 349t
of Laplace transform, 316
unit-impulse functions, 36–37, 38f, 39f, 687n2
bilateral Laplace transform of, 329, 344
capacitors and, 42–44, 43f
convolution of, 458
deﬁnition of, 90–92
derivatives of, 176
Dirac’s delta function and, 36, 291
FT and, 458–459, 460–462, 462f
Laplace transform of, 328–329
LTI and, 175–176
periodic signals and, 460–462, 462f
sampling, 664–665
unit jump and, 291
unit-impulse response. See also Finite Impulse Response;
Inﬁnite Impulse Response
constants and, 230
in continuous-time to discrete-time conversion,
1032–1036
convolution of, 219–220, 230, 293–295, 298, 488
deconvolution and, 231, 232f
differential equations and, 288–290
H(s) and, 489
inverse systems and, 582
Laplace transform and, 364–365
of LTI system, 164, 180–181, 188–189, 192, 206–209,
219–220, 242, 293, 364–365
matched ﬁlter and, 230
RC circuit and, 175–176
reconstruction and, 635f
time constant of, 192
unit jump
differential equations of, 290–292
in inputs, 290–291
unit pulse, decay of, 192
unit-ramp function, 686f, 687
unit-sample function, 686f, 687, 687n2
convolution with, 771
DTFT of, 904–906
unit-sample response
of causal systems, 788
digital ﬁlters and, 1037
of DTFT, 927
of FIR, 1013
of FIR ﬁlters, 1055
initial conditions and, 788
input-output pairs and, 740–741, 1075
in inverse systems, 784–785
of LTI, 773, 1013–1014
of LTI difference equations, 799
of LTI discrete-time systems, 737–741, 784–785
z-transform for, 868–870
unit-square pulse, in LTI system, 191
unit-step functions, 686f, 687
advanced, 39f
bilateral Laplace transform of, 344
capacitors and, 42–44, 43f
delay and, 39f, 53, 251–252
derivatives of, 176
problems/solutions for, 90
time and, 90
time reversal and, 53
time reversal/time shift of, 55
unit jump and, 291
unit-step response
of active ﬁlters, 620
differential equations and, 285–288, 290f
feedback and, 568
initial conditions and, 286
linearity and, 288
of low-pass ﬁlter, 456
LTI difference equations and, 800, 806–809
phase angle of, 520
poles and, 518–519
quality factor Q and, 621
V
vectors
dominant poles and, 525
frequency response and, 515–518, 1025–1029, 1028f
FS and, 384–385
H(s) and, 515–518
H(z) as, 1025–1029, 1026f
phasor V as, 136
from poles, 516
signals as, 384–385
in sinusoidal functions, 127f
in s-plane, 515
zeros and, 516

Index
1143
voice and speech signals, 14–16
aliasing in, 295
discrete-time signals and, 685
ﬁlters for, 1083, 1084f
FT of, 456
sampling of, 295, 625, 626–627
waveform of, 17f–18f
W
waveforms
average power in, 133–134
of bird song, 15f–16f, 16
complex amplitude and, 132
of continuous-time functions, 208–209
of DTFT, 896
in one-sided linear spectrum, 135
from periodic functions, 132, 484t
power in, 133
of sawtooth pulse, 380f
signals and, 2–3
by sinusoidal functions, 126, 484–485
two-sided spectrum and, 136
of voice and speech signals, 17f–18f
waveform symmetry
of DFT, 965
of FS, 396–397
of FT, 435–437
weighted integration
of exponential functions, 70–71
of signals, 68–71
time constants and, 69f, 70–71
weighting functions, 64f, 68–70, 72, 736
well-behaved functions, 429
white Gaussian noise, 693f
Wien-bridge oscillator, op-amp circuit and, 527f
windows, 47–48, 48f. See also speciﬁc types
continuous-time functions and, 450, 450t
DFT and, 994–996, 994t, 995t
discrete-time signals and, 713–715, 714f
DTFT and, 939–944
FIR ﬁlters and, 1072–1075, 1081–1084, 1082f, 1083t
frequency domain and, 943
in FT, 450, 450t, 452f, 470–471
leakage and, 644
time domain and, 941
time-limited signals and, 450
uniform, 736
window averaging
continuous-time signals and, 1068, 1069f
discrete-time signals and, 1069
of exponential functions, 94f
FT and, 451f
matched ﬁlters and, 229
moving average in, 71–72, 72f
of signals, 71–72
X
XCOV. See cross-covariance
xi, 213
Z
zeros
of active ﬁlters, 620
anticausal functions and, 711
Bode plot of, 501–503, 509–510
causal functions and, 711
digital ﬁlters and, 1038
dominant poles and, 522
DTFT and, 909–912, 909f, 910f
ﬁlters and, 556–557
FIR and, 874–876
ﬁrst-order all-pass phase shifters and, 538f
frequency response and, 501–503, 556, 557f
gain factor and, 524
high-frequency asymptote and, 557f, 566
lag compensators and, 540
Laplace transform and, 314
lead compensators and, 540
in LHP, 500n5
poles and, 556
quality factor Q and, 556–557
in RHP, 500n5
second-order bandpass ﬁlters and, 551
second-order low-pass ﬁlters and, 544
second-order systems and, 556, 557f
simple low-pass ﬁlters and, 1040–1043
of systems, 493–494
system function and, 494, 509, 556,
1011–1015
vectors and, 516
z-transform and, 874–879
zero-crossing
periodicity and, 689
sampling of, 678
with sinc functions, 45–46, 45f
sinusoidal functions and, 678
zero frequency, of FT, 447t

1144
Index
zero-input responses
differential equations and, 295–298
LTI difference equations and, 811–812
superposition and, 811
zero-padding, DFT and, 951–952, 951f, 962, 986–987,
986f
zero-state responses
convolution and, 298
differential equations and, 295–298
LTI difference equations and, 811–812
superposition and, 811
zero time, of FT, 447t
zeta, 212
zn
H(z) and, 1006
LTI difference equations and, 805
scale factor of, 805, 1006
z-plane
frequency response in, 1024, 1025f
mapping of, 862f
s-plane and, 859–864
z-transform, 741. See also inverse z-transform
of anticausal exponential functions, 830, 831f, 835–836,
836f
applications of, 827–879
of causal exponential functions, 834, 834f–835f, 836f
of causal functions, 867–868
complex roots and, 845–847
contour integrals and, 836f, 842, 854
convolution of, 839–840
deﬁnition of, 828–829
difference equations and, 848–850
discrete convolution and, 827
of discrete-time functions, 827
DTFT and, 889–890
of even functions, 833
of exponential functions, 829–836
for ﬁlters, 874–879
FIR and, 874–876
H(z) and, 850, 1006–1007
IIR and, 876–879
initial conditions and, 828
input-output pairs for, 865–866
from Laplace transform, 860
linearity of, 836–837
LTI and, 850–851
multiple roots and, 847–848
multiplication by an for, 841–842
multiplication by n for, 841
one-sided functions and, 852–853
partial fraction expansion of, 843–848
poles and, 876–879
problems/solutions for, 866–873
projects for, 874–879
properties of, 836–842, 864
region of convergence of, 829–832, 830f, 835–836, 836f,
866
simple real-valued roots and, 844–845
of sinusoidal functions, 833–836
subsystems and, 827
theorems for, 865
time reversal of, 838–839
time shift of, 837–838
of truncated exponential function, 832–833
of two-sided exponential functions, 831–832, 832f,
833, 836f
for unit-sample response, 868–870
zeros and, 874–879

