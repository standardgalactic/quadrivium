

INTRODUCTION TO
COMPUTATION AND
MODELING FOR
DIFFERENTIAL
EQUATIONS


INTRODUCTION TO
COMPUTATION AND
MODELING FOR
DIFFERENTIAL
EQUATIONS
Second Edition
LENNART EDSBERG
Department of Numerical Analysis and Computing Science
KTH - Royal Institute of Technology
Stockholm, Sweden

Copyright © 2016 by John Wiley & Sons, Inc. All rights reserved
Published by John Wiley & Sons, Inc., Hoboken, New Jersey
Published simultaneously in Canada
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or
by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should
be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ
07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in
preparing this book, they make no representations or warranties with respect to the accuracy or
completeness of the contents of this book and specifically disclaim any implied warranties of
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales
representatives or written sales materials. The advice and strategies contained herein may not be suitable
for your situation. You should consult with a professional where appropriate. Neither the publisher nor
author shall be liable for any loss of profit or any other commercial damages, including but not limited to
special, incidental, consequential, or other damages.
For general information on our other products and services or for technical support, please contact our
Customer Care Department within the United States at (800) 762-2974, outside the United States at
(317) 572-3993 or fax (317) 572-4002.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may
not be available in electronic formats. For more information about Wiley products, visit our web site at
www.wiley.com.
Library of Congress Cataloging-in-Publication Data:
Edsberg, Lennart, 1946–
Introduction to computation and modeling for differential equations / Lennart Edsberg. – Second
edition.
pages cm
Includes bibliographical references and index.
ISBN 978-1-119-01844-5 (cloth)
1. Differential equations–Data processing. 2. Mathematical models. I. Title.
QA371.5.D37E37 2016
515′.350285–dc23
2015018724
Typeset in 10/12pt TimesLTStd by SPi Global, Chennai, India
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1
1
2016

CONTENTS
Preface
xi
1
Introduction
1
1.1 What is a Differential Equation? 1
1.2 Examples of an Ordinary and a Partial Differential Equation, 2
1.3 Numerical Analysis, a Necessity for Scientific Computing, 5
1.4 Outline of the Contents of this Book, 8
Bibliography, 10
2
Ordinary Differential Equations
11
2.1 Problem Classification, 11
2.2 Linear Systems of ODEs with Constant Coefficients, 16
2.3 Some Stability Concepts for ODEs, 19
2.3.1
Stability for a Solution Trajectory of an ODE System, 20
2.3.2
Stability for Critical Points of ODE Systems, 23
2.4 Some ODE models in Science and Engineering, 26
2.4.1
Newton’s Second Law, 26
2.4.2
Hamilton’s Equations, 27
2.4.3
Electrical Networks, 27
2.4.4
Chemical Kinetics, 28
2.4.5
Control Theory, 29
2.4.6
Compartment Models, 29

vi
CONTENTS
2.5 Some Examples From Applications, 30
Bibliography, 36
3
Numerical Methods For Initial Value Problems
37
3.1 Graphical Representation of Solutions, 38
3.2 Basic Principles of Numerical Approximation of ODEs, 40
3.3 Numerical Solution of IVPs with Euler’s method, 41
3.3.1
Euler’s Explicit Method: Accuracy, 43
3.3.2
Euler’s Explicit Method: Improving the Accuracy, 46
3.3.3
Euler’s Explicit Method: Stability, 48
3.3.4
Euler’s Implicit Method, 53
3.3.5
The Trapezoidal Method, 55
3.4 Higher Order Methods for the IVP, 56
3.4.1
Runge–Kutta Methods, 56
3.4.2
Linear Multistep Methods, 60
3.5 Special Methods for Special Problems, 62
3.5.1
Preserving Linear and Quadratic Invariants, 62
3.5.2
Preserving Positivity of the Numerical Solution, 64
3.5.3
Methods for Newton’s Equations of Motion, 64
3.6 The Variational Equation and Parameter Fitting in IVPs, 66
Bibliography, 69
4
Numerical Methods for Boundary Value Problems
71
4.1 Applications, 73
4.2 Difference Methods for BVPs, 78
4.2.1
A Model Problem for BVPs, Dirichlet’s BCs, 79
4.2.2
A Model Problem for BVPs, Mixed BCs, 83
4.2.3
Accuracy, 86
4.2.4
Spurious Solutions, 87
4.2.5
Linear Two-Point BVPs, 89
4.2.6
Nonlinear Two-Point BVPs, 91
4.2.7
The Shooting Method, 92
4.3 Ansatz Methods for BVPs, 94
4.3.1
Starting with the ODE Formulation, 95
4.3.2
Starting with the Weak Formulation, 96
4.3.3
The Finite Element Method, 100
Bibliography, 103
5
Partial Differential Equations
105
5.1 Classical PDE Problems, 106
5.2 Differential Operators Used for PDEs, 110
5.3 Some PDEs in Science and Engineering, 114
5.3.1
Navier–Stokes Equations for Incompressible Flow, 114

CONTENTS
vii
5.3.2
Euler’s Equations for Compressible Flow, 115
5.3.3
The Convection–Diffusion–Reaction Equations, 116
5.3.4
The Heat Equation, 117
5.3.5
The Diffusion Equation, 117
5.3.6
Maxwell’s Equations for the Electromagnetic Field, 117
5.3.7
Acoustic Waves, 118
5.3.8
Schrödinger’s Equation in Quantum Mechanics, 119
5.3.9
Navier’s Equations in Structural Mechanics, 119
5.3.10 Black–Scholes Equation in Financial Mathematics, 120
5.4 Initial and Boundary Conditions for PDEs, 121
5.5 Numerical Solution of PDEs, Some General Comments, 121
Bibliography, 122
6
Numerical Methods for Parabolic Partial Differential Equations
123
6.1 Applications, 125
6.2 An Introductory Example of Discretization, 127
6.3 The Method of Lines for Parabolic PDEs, 130
6.3.1
Solving the Test Problem with MoL, 130
6.3.2
Various Types of Boundary Conditions, 134
6.3.3
An Example of the Use of MoL for a Mixed Boundary
Condition, 135
6.4 Generalizations of the Heat Equation, 136
6.4.1
The Heat Equation with Variable Conductivity, 136
6.4.2
The Convection – Diffusion – Reaction PDE, 138
6.4.3
The General Nonlinear Parabolic PDE, 138
6.5 Ansatz Methods for the Model Equation, 139
Bibliography, 140
7
Numerical Methods for Elliptic Partial Differential Equations
143
7.1 Applications, 145
7.2 The Finite Difference Method, 150
7.3 Discretization of a Problem with Different BCs, 154
7.4 Ansatz Methods for Elliptic PDEs, 156
7.4.1
Starting with the PDE Formulation, 156
7.4.2
Starting with the Weak Formulation, 158
7.4.3
The Finite Element Method, 159
Bibliography, 164
8
Numerical Methods for Hyperbolic PDEs
165
8.1 Applications, 171
8.2 Numerical Solution of Hyperbolic PDEs, 174
8.2.1
The Upwind Method (FTBS), 175
8.2.2
The FTFS Method, 177

viii
CONTENTS
8.2.3
The FTCS Method, 178
8.2.4
The Lax–Friedrichs Method, 178
8.2.5
The Leap-Frog Method, 179
8.2.6
The Lax–Wendroff Method, 179
8.2.7
Numerical Method for the Wave Equation, 181
8.3 The Finite Volume Method, 183
8.4 Some Examples of Stability Analysis for Hyperbolic PDEs, 185
Bibliography, 187
9
Mathematical Modeling with Differential Equations
189
9.1 Nature Laws, 190
9.2 Constitutive Equations, 192
9.2.1
Equations in Heat Transfer Problems, 192
9.2.2
Equations in Mass Diffusion Problems, 193
9.2.3
Equations in Mechanical Moment Diffusion Problems, 193
9.2.4
Equations in Elastic Solid Mechanics Problems, 194
9.2.5
Equations in Chemical Reaction Engineering Problems, 194
9.2.6
Equations in Electrical Engineering Problems, 195
9.3 Conservative Equations, 195
9.3.1
Some Examples of Lumped Models, 196
9.3.2
Some Examples of Distributed Models, 197
9.4 Scaling of Differential Equations to Dimensionless Form, 201
Bibliography, 204
10
Applied Projects on Differential Equations
205
Project 1
Signal propagation in a long electrical conductor, 205
Project 2
Flow in a cylindrical pipe, 206
Project 3
Soliton waves, 208
Project 4
Wave scattering in a waveguide, 209
Project 5
Metal block with heat sourse and thermometer, 210
Project 6
Deformation of a circular metal plate, 211
Project 7
Cooling of a chrystal glass, 212
Project 8
Rotating fluid in a cylinder, 212
Appendix A
Some Numerical and Mathematical Tools
215
A.1 Newton’s Method for Systems of Nonlinear Algebraic Equations, 215
A.1.1
Quadratic Systems, 215
A.1.2
Overdetermined Systems, 218
A.2 Some Facts about Linear Difference Equations, 219
A.3 Derivation of Difference Approximations, 223
Bibliography, 225
A.4 The Interpretations of Grad, Div, and Curl, 225
A.5 Numerical Solution of Algebraic Systems of Equations, 229

CONTENTS
ix
A.5.1
Direct Methods, 229
A.5.2
Iterative Methods for Linear Systems of Equations, 233
A.6 Some Results for Fourier Transforms, 237
Bibliography, 239
Appendix
B
Software for Scientific Computing
241
B.1 MATLAB, 242
B.1.1
Chapter 3: IVPs, 242
B.1.2
Chapter 4: BVPs, 244
B.1.3
Chapter 6: Parabolic PDEs, 245
B.1.4
Chapter 7: Elliptic PDEs, 246
B.1.5
Chapter 8: Hyperbolic PDEs, 246
B.2 COMSOL MULTIPHYSICS, 247
Bibliography and Resources, 249
Appendix C
Computer Exercises to Support the Chapters
251
C.1 Computer Lab 1 Supporting Chapter 2, 251
C.1.1
ODE Systems of LCC Type and Stability, 251
C.2 Computer Lab 2 Supporting Chapter 3, 254
C.2.1
Numerical Solution of Initial Value Problems, 254
C.3 Computer Lab 3 Supporting Chapter 4, 257
C.3.1
Numerical Solution of a Boundary Value Problem, 257
C.4 Computer Lab 4 Supporting Chapter 6, 258
C.4.1
Partial Differential Equation of Parabolic Type, 258
C.5 Computer Lab 5 Supporting Chapter 7, 261
C.5.1
Numerical Solution of Elliptic PDE Problems, 261
C.6 Computer Lab 6 Supporting Chapter 8, 263
C.6.1
Numerical Experiments with the Hyperbolic Model PDE
Problem, 263
Index
265


PREFACE
In the Second Edition of this book, corrections and a large number of additions and
modifications have been made. Chapter 3 contains a new section with special methods
for special problems. The emphasis is on the numerical preservation of invariants of
the solution, such as positivity and quadratic expressions of, e.g., energy. Chapters
4 and 7 have new sections presenting the weak formulations of ordinary differential
equations and partial differential equations as starting point for Galerkin’s method
followed by the finite element method. Chapter 8 has a new section on the finite
volume method that presents the wave equation with clear connections to Chapter
3 where the leap-frog method with staggered grid is discussed. Chapter 10 has been
newly added in this edition where well-tested student projects are presented for use in,
e.g., a course based on this book. The projects have been used at KTH, Stockholm, for
many years, and the projects have been developed and modified for several decades
by my colleague Gerd Eriksson who has given me the permission to publish them
in this new edition. I would like to extend my sincere thanks to her and also to my
colleague Jesper Oppelstrup who has contributed with many valuable comments and
suggestions concerning the new stuff of this book for the past many years.
Lennart Edsberg
KTH
Stockholm
August 2015


1
INTRODUCTION
It is probably no exaggeration to say that differential equations are the most common
and important mathematical model in science and engineering. Whenever we want
to model a system where the state variables vary with time and/or space, differential
equations are the natural tool for describing its behavior. The construction of a differ-
ential equation model demands a thorough understanding of what takes place in the
process we want to describe.
However, setting up a differential equation model is not enough, we must also
solve the equations. The process of finding useful solutions of a differential equation
is much a symbiosis of modeling, mathematics and choosing a method, analytical or
numerical. Therefore,when you are requested to solve a differential equation problem
from some application, it is useful to know facts about its modeling background, its
mathematical properties, and its numerical treatment. The last part involves choosing
appropriate numerical methods, adequate Software, and appealing ways of visualiz-
ing the result.
The interaction among modeling, mathematics, numerical methods, and program-
ming is nowadays referred to as scientific computing and its purpose is to perform
simulations of processes in science and engineering.
1.1
WHAT IS A DIFFERENTIAL EQUATION?
A differential equation is a relation between a function and its derivatives. If the func-
tion u depends on only one variable t, i.e., u = u(t), the differential equation is called
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

2
INTRODUCTION
ordinary. If u depends on at least two variables t and x, i.e., u = u(x, t), the differential
equation is called partial.
1.2
EXAMPLES OF AN ORDINARY AND A PARTIAL DIFFERENTIAL
EQUATION
An example of an elementary ordinary differential equation (ODE) is
du
dt = au
(1.1)
where a is a parameter, in this case a real constant. It is frequently used to model, e.g.,
the growth of a population (a > 0) or the decay of a radioactive substance (a < 0).
The ODE (1.1) is a special case of differential equations called linear with constant
coefficients (see Chapter 2).
The differential equation (1.1) can be solved analytically, i.e., the solution can be
written explicitly as an algebraic formula. Any function of the form
u(t) = Ceat
(1.2)
where C is an arbitrary constant satisfies (1.1) and is a solution. The expression (1.2)
is called the general solution. If C is known to have a certain value, however, we get
a unique solution, which, when plotted in the (t, u)-plane, gives a trajectory (solution
curve). This solution is called a particular solution.
The constant C can be determined, e.g., by selecting a point (t0, u0) in the
(t, u)-plane through which the solution curve shall pass. Such a point is called an
initial point and the demand that the solution shall go through this point is called the
initial condition. A differential equation together with an initial condition is called
an initial value problem (IVP) (Figure 1.1).
0
0.5
1
1.5
2
−2
−1
0
1
2
t
u(t)
Some solutions of du/dt = −u
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
t
u(t)
Solution of du/dt = −u, u(0) = 1
Figure 1.1
General and particular solution

EXAMPLES OF AN ORDINARY AND A PARTIAL DIFFERENTIAL EQUATION
3
Observe that the differential equation alone does not define a unique solution, we
also need an initial condition or other conditions. A plot of all trajectories, i.e., all
solutions of the ODE (1.1) in the (t, u)-plane will result in a graph that is totally black
as there are infinitely many solution curves filling up the whole plane.
In general, it is not possible to find analytical solutions of a differential equation.
The “simple” differential equation
du
dt = t2 + u2
(1.3)
cannot be solved analytically. If we want to plot some of its trajectories, we have to
use numerical methods.
An example of an elementary partial differential equation (PDE) is
𝜕u
𝜕t + a𝜕u
𝜕x = 0
(1.4)
where a is a parameter, in this case a real constant. The solution of (1.4) is a function
of two variables u = u(x, t). This differential equation is called the 1D (one space
dimension, x) advection equation. Physically it describes the evolution of a scalar
quantity, e.g., temperature u(x, t) carried along the x-axis by a flow with constant
velocity a. It is also known as the linear convection equation and is an example of a
hyperbolic PDE (see Chapter 5).
The general solution of this differential equation is (see Exercise 1.2.4)
u(x, t) = F(x −at)
(1.5)
where F is any arbitrary differentiable function of one variable. This is indeed a large
family of solutions! The three functions
u(x, t) = x −at,
u(x, t) = e−(x−at)2,
u(x, t) = sin(x −at)
are just three solutions out of the infinitely many solutions of this PDE.
To obtain a unique solution for t > 0 we need an initial condition. If the differen-
tial equation is valid for all x, i.e., −∞< x < ∞and u(x, t) is known for t = 0, i.e.,
u(x, 0) = u0(x) where u0(x) is a given function, the initial value function, we get the
particular solution (Figure 1.2)
u(x, t) = u0(x −at)
(1.6)
Physically, (1.6) corresponds to the propagation of the initial function u0(x) along
the x-axis with velocity |a|. The propagation is to the right if a > 0 and to the left if
a < 0.
The graphical representation can alternatively be done in 3D (Figure 1.3).
When a PDE is formulated on a semi-infinite or finite x-interval, boundary condi-
tions are needed in addition to initial conditions to specify a unique solution.

4
INTRODUCTION
−3
−2
−1
0
1
2
3
4
5
6
7
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
u(x, t)
x
exp(–(x – t)2) at t = 0 and t = 4
Figure 1.2
Propagation of a solution of the advection equation
0
1
2
3
4
−4
−2
0
2
4
6
8
0
0.2
0.4
0.6
0.8
1
t
x
u(x, t)
3D-graph of u(x, t) = exp (–(x – at)2) when a = 1
Figure 1.3
3D graph of a propagating solution

NUMERICAL ANALYSIS, A NECESSITY FOR SCIENTIFIC COMPUTING
5
Most PDEs can only be solved with numerical methods. Only for very special
classes of PDE problems it is possible to find an analytic solution, often in the form
of an infinite series.
Exercise 1.2.1. If a is a complex constant a = 𝜇+ i𝜔what is the real and imaginary
part of eat?
Exercise 1.2.2. What conditions are necessary to impose on 𝜇and 𝜔if Re(eat) for
t > 0 is to be
a) exponentially decreasing,
b) exponentially increasing,
c) oscillating with constant amplitude,
d) oscillating with increasing amplitude,
e) oscillating with decreasing amplitude?
Exercise 1.2.3. If a is a complex constant what condition on a is needed if eat is to
be bounded for t ≥0?
Exercise 1.2.4. Show that the general solution of ut + aux = 0 is u(x, t) = F(x −at)
by introducing the transformation
𝜉= x + at,
𝜂= x −at
Transform the original problem to a PDE in the variables 𝜉and 𝜂, and solve this PDE.
Sketch the two coordinate systems in the same graph.
Exercise 1.2.5. Show that a solution of (1.4) starting at t = 0, x = x0 is constant
along the straight line x −at = x0. This means that the initial value u(x0, 0) = u0(x0)
is transported unchanged along this line, which is called a characteristic of the hyper-
bolic PDE (1.4).
1.3
NUMERICAL ANALYSIS, A NECESSITY FOR SCIENTIFIC
COMPUTING
In scientific computing, the numerical methods used to solve mathematical models
should be robust, i.e., they should be reliable and give accurate values for a large range
of parameter values. Sometimes, however, a method may fail and give unexpected
results. Then, it is important to know how to investigate why an erroneous result has
occurred and how it can be remedied.
Two basic concepts in numerical analysis are stability and accuracy. When
choosing a method for solving a differential equation problem, it is necessary to

6
INTRODUCTION
have some knowledge about how to analyze the result of the method with respect to
these concepts. This necessity has been well expressed by the late Prof. Germund
Dahlquist, famous for his fundamental research in the theory of numerical treatment
of differential equations: “There is nothing as practical as a little good theory.”
As an example of what may be unexpected results, choose the well-known vibra-
tion equation, occurring in, e.g., mechanical vibrations, electrical vibrations, and
sound vibrations. The form of this equation with initial conditions is
md2u
dt2 + cdu
dt + ku = f(t),
u(0) = u0, du
dt (0) = v0
(1.7)
In mechanical vibrations, m is the mass of the vibrating particle, c the damping coef-
ficient, k the spring constant, f(t) an external force acting on the particle, u0 the initial
position, and v0 the initial velocity of the particle. The five quantities m, c, k, u0, v0 are
referred to as the parameters of the problem.
Solving (1.7) numerically for a set of values of the parameters is an example of
simulation of a mechanical process and it is desirable to choose a robust method, i.e., a
method for which the results are reliable for a large range of values of the parameters.
The following two examples based on the vibration equation show that unexpected
results depending on instability and/or bad accuracy may occur.
Example 1.1.
Assume that f(t) = 0 (free vibrations) and the following values of
the parameters: m = 1, c = 0.4, k = 4.5, u0 = 1, v0 = 0. Without too much knowledge
about mechanics, we would expect the solution to be oscillatory and damped, i.e.,
the amplitude of the vibrations is decreasing. If we use the simple Euler method with
constant stepsize h = 0.1 (see Chapter 3), we obtain the following numerical solution,
visualized together with the exact solution (Figure 1.4).
The graph shows a numerical solution that is oscillatory but unstable with increas-
ing amplitude. Why? The answer is given in Chapter 3. For the moment just accept
that insight in stability concepts and experience in handling unexpected results are
needed for successful simulations.
Example 1.2.
When the parameters in equation (1.7) are changed to m = 1,
c = 10, k = 103, u0 = 0, v0 = 0, and f(t) = 10−4 sin(40t) (forced vibrations) we
obtain the following numerical result with a method from a commercial software
product for solving differential equations (Figure 1.5).
The graph shows that the numerical result is not correct. Why? In this example
there is an accuracy problem. The default accuracy used in the method is not suffi-
cient; the corresponding numerical parameter must be tuned appropriately. Accuracy
for ODEs is discussed in Chapter 3.
Numerical solution of PDEs can also give rise to unexpected results. As an
example consider the PDE (1.4), which has the property of propagating the initial
function along the x-axis. One important application of this equation occurs in gas
dynamics where simulation of shock waves is essential. A simple 1D model of a

NUMERICAL ANALYSIS, A NECESSITY FOR SCIENTIFIC COMPUTING
7
0
1
2
3
4
5
6
7
8
9
10
−1.5
−1
−0.5
0
0.5
1
1.5
t(s)
u(m)
Numerical solution
Exact solution
Figure 1.4
An example of numerical instability
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−5
−4
−3
−2
−1
0
1
2
3
4
5 × 10−7 Exact solution (solid curve) and numerical solution (dotted curve)
Figure 1.5
An example of insufficient accuracy

8
INTRODUCTION
−0.2 −0.1
0
0.1
0.2
0.3
−0.5
0
0.5
1
1.5
2
Initial function = stepfunction
x
u(x, 0)
−0.2 −0.1
0
0.1
0.2
0.3
−0.5
0
0.5
1
1.5
2
x
u(x, 2)
−0.2 −0.1
0
0.1
0.2
0.3
−0.5
0
0.5
1
1.5
2
x
u(x, 1)
Numerical solution at t = 2
Numerical solution at t = 1
−0.5
0
0.5
0
1
2
0
1
2
3
x
3D plot of the numerical solution
t
u(x, t)
Figure 1.6
Numerical solution of the advection equation
shockwave is a stepfunction. Assume the initial function u0(x) is a stepfunction
(Figure 1.6). In the exact solution of (1.4) with a stepfunction as initial condition,
the solution propagates along the x-axis without changing shape.
However, using a numerical method, where simple difference approximations are
used in both the t- and the x-direction, wiggles are generated as the solution prop-
agates (see the graphs in Figure 1.6). The shape of the initial function is distorted.
Why? Answers will be given in Chapter 8.
1.4
OUTLINE OF THE CONTENTS OF THIS BOOK
After this introductory chapter, the text is organized so that ODEs are treated first, fol-
lowed by PDEs. The aim of this book is to be an introduction to scientific computing.
Therefore, not only numerical methods are presented but also
1. how to set up a mathematical model in the form of an ODE or a PDE;
2. an outline of the mathematical properties of differential equation problems and
explicit analytical solutions (when they exist); and
3. examples of how results are presented with proper visualization.
The ODE part starts in Chapter 2 presenting some mathematical properties of ODEs,
first the basic and important problem class of ODE systems which are linear with

OUTLINE OF THE CONTENTS OF THIS BOOK
9
constant coefficients applied to important models from classical mechanics, electrical
networks, and chemical kinetics. This is followed by numerical treatment of ODE
problems in general, following the classical subdivision into IVPs in Chapter 3, and
boundary value problems, BVPs, in Chapter 4. For IVPs, the finite difference method
(FDM) is described starting with the elementary Euler method. Important concepts
brought up for ODEs are accuracy and stability which is followed up also for PDEs
in later chapters. For BVPs, both the FDM and the finite element method (FEM) are
described.
Important application areas where ODEs are used as mathematical model are pre-
sented, selected examples are described in the chapters and exercises, sometimes
suitable for computer labs, are inserted into the text.
PDEs are introduced in Chapter 5, which deals with some mathematical proper-
ties of their solutions. There is also a presentation of several of the important PDEs
of science and engineering, such as the equations of Navier–Stokes, Maxwell and
Schrödinger.
The three chapters to follow are devoted to the numerical treatment of PDEs
following the classical subdivision into parabolic, elliptic, and hyperbolic problems.
Concepts from the ODE chapters such as accuracy and stability are treated for
time-dependent, parabolic and hyperbolic PDEs. For stationary problems (ellip-
tic PDEs), sparse linear systems of algebraic equations are essential and hence
discussed.
Selected models introduced in Chapters 2, 5, and 9 are used as illustrations of
the different methods introduced. Models are taken from mechanics, fluid dynam-
ics, electromagnetics, reaction engineering, biochemistry, control theory, quantum
mechanics, solid mechanics, etc. and are suitable for computer labs.
In Chapter 9, an outline of mathematical modeling is brought up with the intention
of giving a feeling of the principles used when a differentialequation (ODE or PDE) is
set up from conservation laws and constitutive relations. It is also shown by examples
how a general differential equation model can be simplified by suitable assumptions.
This chapter can be studied in parallel with Chapters 3, 4, 6, 7, and 8 if the reader
wants to see how the models are constructed.
In a number of Appendices (A.1–A.6), different parts of mathematics and numer-
ical mathematics that are essential for numerical treatment of differential equations
are presented as summaries.
Appendix B gives an overview of existing software for scientific computing with
emphasis on the use of MATLAB® for programming and COMSOL Multiphysics®
for modeling and parameter studies. Many of the exercises in this chapter and in
Chapters 2–8 are solved with MATLAB programs in this appendix.
Appendix C contains a number of computer exercises to support the chapters con-
taining numerical solution of ODEs and PDEs.
In Chapter 10, a numberof projects are suggested. These projects involveproblems
where knowledge from several chapters and appendices are needed to compute a
solution.

10
INTRODUCTION
BIBLIOGRAPHY
1. G. Dahlquist and Å Björck, “Numerical Methods”, Dover, 2003
2. L. Råde, B. Westergren, “Mathematics Handbook for Science and Engineering”,
Studentlitteratur 1998

2
ORDINARY DIFFERENTIAL
EQUATIONS
This chapter is not intended to be a thorough treatment of mathematical properties
of ordinary differential equations (ODEs). It is rather an overview of some impor-
tant definitions and concepts such as problem classification and properties of linear
ODE systems with constant coefficients and stability. These matters are important for
numerical analysis of methods solving ODE problems. For a more extensive treat-
ment of ODEs, it is recommended to consult some mathematical textbook, e.g., one
of those referenced at the end of this chapter.
2.1
PROBLEM CLASSIFICATION
A general way of formulating a first-order scalar ODE is
du
dt = f(t, u)
(2.1)
where t is defined in some interval, bounded or unbounded,and u(t) is a solution if u(t)
satisfies (2.1) for all t in the interval. The variable t is called the independent variable
and u is called the dependent variable. The derivative du∕dt can also be denoted ̇u
or ut.
As we have already pointed out, the general solution u = u(t, C) of (2.1) contains
an arbitrary constant C. Hence, the general solution is a family of infinitely many
solutions.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

12
ORDINARY DIFFERENTIAL EQUATIONS
If we prescribe an initial condition (IC) u(t0) = u0, the constant C is determined
and we get a unique solution, a particular solution.
A scalar ODE of second order can be written as
d2u
dt2 = f
(
t, u, du
dt
)
(2.2)
The general solution of (2.2) contains two arbitrary constants C1 and C2, i.e., u =
u(t, C1, C2). Therefore,we need two conditions to determine C1 and C2 to get a unique
solution. These conditions can be given in various ways. One way is to specify u at
two different values of t, i.e., at t = a and t = b:
u(a) = 𝛼
u(b) = 𝛽
(2.3)
This way of specifying boundary conditions (BCs) to the second-order ODE (2.2)
is called a boundary value formulation, and (2.2) and (2.3) define a boundary value
problem (BVP). Other possible types of BCs will be shown in Chapter 4.
Another way to specify conditions is by ICs. Equation (2.2) can be written as a
system of two first-order ODEs by introducing the auxiliary variable v = du∕dt:
du
dt = v
(2.4a)
dv
dt = f(t, u, v)
(2.4b)
Hence, we get two differential equations of type (2.1) and a unique solution can
be obtained by specifying the initial values for the two ODEs
u(a) = u0
v(a) = v0
(2.5)
In the original formulation (2.2), the ICs (2.5) correspond to u(a) = u0 and u′(a) = v0.
Specifying ICs in this way together with an ODE system (2.4) defines an initial
value problem (IVP) (Figure 2.1).
For a system of ODEs
du1
dt = f1(t, u1, u2, … , un)
du2
dt = f2(t, u1, u2, … , un)
.
(2.6)
.
dun
dt = fn(t, u1, u2, … , un)

PROBLEM CLASSIFICATION
13
0
1
2
3
4
0
1
2
3
4
Boundary value problem
x
u
a, α
b, β
0
1
2
3
4
0
1
2
3
4
Initial value problem
x
u
a, u0
Slope v0
Figure 2.1
A BVP compared to an IVP
it is convenient to use column vector formulation
du
dt = f(t, u)
(2.7)
where the dependent variables and the right hand sides are collected in the vectors u
and f
u = (u1, u2, … , un)T,
f = (f1, f2, … , fn)T
Observe that there are as many dependent variables as differential equations.
The general solution u = u(t, C), where C is an arbitrary constant vector in Rn, is
a family of solution curves in [t0, tend] × Rn, where [t0, tend] is the time interval where
we want the solution. If C is determined, e.g., by the IC u(t0) = u0, we get a unique
solution, a particular solution. Numerical methods are for most problems necessary
to produce graphs or tables of solutions.
The standard general formulation of an IVP is
du
dt = f(t, u),
u(t0) = u0,
t ∈[t0, tend]
(2.8)
and a fairly general formulation for a BVP is
du
dt = f(t, u),
g1(u(a)) = 0,
g2(u(b)) = 0,
t ∈[a, b]
(2.9)
where g1 and g2 together make up n BC equations.
A scalar ODE of order n
dnu
dtn = f
(
t, u, du
dt , d2u
dt2 , … , dn−1u
dtn−1
)
(2.10)

14
ORDINARY DIFFERENTIAL EQUATIONS
can be written as a system of ODEs by introducing auxiliary variables u1 = u, u2 =
du∕dt, u3 = d2u∕dt2, … , un = dn−1u∕dtn−1:
du1
dt = u2
du2
dt = u3
.
(2.11)
.
dun
dt = f(t, u1, u2, … , un)
A particular solution is obtained either by specifying an initial vector u0 or by speci-
fying n BCs for u. We will not present the general case here but give different ways
of specifying BCs together with problems from applications in Chapters 3 and 4.
For the IVP (2.8) to have a unique solution, there is a condition on the right hand
side f(t, u) of the ODE to be differentiable with respect to t and u. This means that fi
is differentiable with respect to t and uj (i, j = 1, 2, … , n) for all t ∈[t0, tend] and for
all points u in a certain domain that contains u0 as an interior point. This condition
is a little stronger than Lipschitz continuity (see a mathematical textbook on ODEs).
For a BVP, the question of a uniquesolution is morecomplicated.However,unicity
for BVPs is not a big issue as many such problems occurring in applications can have
several solutions which all make sense (see Example 2.3 in Section 2.5).
Exercise 2.1.1. Given the linear differential equation ̇u = −tu.
a) Find the general solution of the ODE. Observe that the arbitrary constant C
enters linearly in the solution.
b) Find the particular solution satisfying the IC u(0) = 1.
Exercise 2.1.2. Given the nonlinear differential equation ̇u = −u2.
a) Give the general solution of the ODE. Observe that the arbitrary constant C
enters nonlinearly in the solution.
b) Find the particular solution satisfying u(0) = 1.
c) Find the particular solution satisfying u(0) = 0.
Exercise 2.1.3. Given the linear second-order ODE u′′ + 2u′ −3u = 0
a) Find the general solution of the ODE. Observe that the arbitrary constants enter
linearly.
b) Find the particular solution satisfying the following IC u(0) = 1, u′(0) = −1.

PROBLEM CLASSIFICATION
15
c) Find the particular solution satisfying the following BC u(0) = 0, u(1) = 1.
d) Find the particular solution satisfying the following BC u(0) = 1, u(∞) = 0.
Exercise 2.1.4. A particle is thrown vertically upwards. During its motion, it is
influenced by two forces: gravity and air resistance. The following second- order
ODE models the motion along the y-axis:
m̈y = −mg −c ̇y| ̇y|,
y(0) = y0,
̇y(0) = v0
Rewrite this problem as a system of two ODEs.
Exercise 2.1.5. The following system of two second-orderODEs models the vibra-
tions of a mechanical system with two degrees of freedom.
(m1
0
0
m2
)
d2x
dt2 +
(d𝜈1 + d𝜈2
−d𝜈2
−d𝜈2
d𝜈2
)
dx
dt +
(𝜅1 + 𝜅2
−𝜅2
−𝜅2
𝜅2
)
x =
(
0
̂F2 sin(𝜔t)
)
At the initial point t = 0, the ICs are
x(0) = 0,
dx
dt (0) = 0
Formulate these differential equations as a system of first-order ODEs on vector
form.
Exercise 2.1.6. The following BVP models the concentration of a chemical sub-
stance in a long cylindrical catalyst pellet
1
r
d
dr
(
rdc
dr
)
= kc2,
dc
dr (0) = 0,
c(R) = c0
The parameters k, R, and c0 are positive parameters. The point r = 0 is a singular
point as the left hand side term is not defined there. Use l’Hôpital’s rule to find the
form of the ODE at that point.
Exercise 2.1.7. The following mixture of an ODE system and a system of algebraic
equations is called a DAE system (Differential Algebraic Equations)
dx
dt = f(x, y),
x(0) = x0
0 = g(x, y)
Assume that x, f ∈Rn1 and y, g ∈Rn2, where n1 + n2 = n, the number of unknowns
of the system.

16
ORDINARY DIFFERENTIAL EQUATIONS
Formulate this DAE system as an ODE system with corresponding initial values.
Hint: Differentiate the algebraic system with respect to t. Assume that the matrix
𝜕g∕𝜕y is nonsingular. This DAE system is called an index-1 system, as a standard
IVP can be obtained by differentiating part of the system only once.
2.2
LINEAR SYSTEMS OF ODES WITH CONSTANT COEFFICIENTS
There is one type of ODE system that can be treated by analytical tools namely linear
systems with constant coefficients. This problem class is very important in engineer-
ing and scientific applications, such as mechanical vibrations, electric circuits, and
first-order chemical kinetics. Linear ODE systems with constant coefficients (LCC
systems) take the following form:
du
dt = Au + g(t),
u(0) = u0
(2.12)
where A is a constant n × n matrix and g(t) is a vector of n functions of t called the
driving function.
If g(t) ≡0, the system is homogeneous, i.e.,
du
dt = Au,
u(0) = u0
(2.13)
Otherwise, it is inhomogeneous.
In the homogeneous case, n = 1, i.e., the scalar equation
du
dt = au,
u(0) = u0
we know that the solution is (see Section 1.2)
u(t) = eatu0
where u0 is the initial value. A generalization of this algebraic solution form to a
system leads us to the following solution formula for (2.13):
u(t) = eAtu0
(2.14)
However, what is eAt, e raised to the power of the matrix At?
Let’s assume that a solution to (2.13) can be written
u(t) = ce𝜆t
(2.15)
where c and 𝜆are to be determined. Inserting this expression into (2.13) gives the
following relation to be fulfilled for all t:
c𝜆e𝜆t = Ace𝜆t

LINEAR SYSTEMS OF ODES WITH CONSTANT COEFFICIENTS
17
This leads to the eigenvalue problem:
Ac = 𝜆c
or
(A −𝜆I)c = 0
(2.16)
We are interested in solutions where c ≠0 (c = 0 gives us the trivial solution u = 0).
This is possible only if
det(A −𝜆I) = 0
(2.17)
This equation is called the characteristic equation and its roots are known as the
eigenvalues of the matrix A. If A is an n × n matrix, (2.17) is a polynomial equation
of degree n, and consequently has n roots 𝜆1, 𝜆2, .... 𝜆n. The roots can be real or
complex, single or multiple.
When an eigenvalue 𝜆i is known, we compute the corresponding eigenvector ci by
solving the homogeneous linear equation system
(A −𝜆iI)ci = 0
(2.18)
The solution ci is not unique; ci is determined only up to a scalar factor. In addition,
ci can be complex even if A is real. If A is real and symmetric, however, both 𝜆i and
ci are real.
From now on, we assume that the n eigenvectors of the matrix A are linearly inde-
pendent. Such a matrix is called a diagonalizable or nondefective matrix. (If A has
fewer than n linearly independent eigenvectors, it is called defective). For a nonde-
fective matrix, the relation (2.18) can be written in the form
Aci = 𝜆ici →AS = SΛ →A = SΛS−1
or
S−1AS = Λ
where S is a matrix composed of the eigenvectors as columns and Λ is a diagonal
matrix of the eigenvalues:
S = (c1, c2, … , cn),
Λ = diag(𝜆1, 𝜆2, … , 𝜆n)
Going back to (2.15), we now have n solutions to (2.13)
ui(t) = cie𝜆it, i = 1, 2, … , n
(2.19)
As (2.13) is a linear homogeneous problem, the solutions (2.19) can be superposed,
i.e., linearly combined to a general solution:
u(t) =
n
∑
i=1
𝛼icie𝜆it
(2.20)
where 𝛼i are arbitrary constants. Formula (2.20) can also be written in matrix form:
u(t) = SeΛt𝛼
(2.21)

18
ORDINARY DIFFERENTIAL EQUATIONS
eΛt is a diagonal matrix with e𝜆it as diagonal elements:
eΛt = diag(e𝜆1t, e𝜆2t, … , e𝜆nt)
and 𝛼is an arbitrary column vector with components 𝛼1, 𝛼2, ... 𝛼n. When the initial
vector u(0) = u0 is known, we get by inserting t = 0 into (2.21):
u(0) = S𝛼= u0
→
𝛼= S−1u0
and (2.21) can be written
u(t) = SeΛtS−1u0
(2.22)
Hence, comparing with (2.14), we define eAt, the exponential matrix, as
eAt = SeΛtS−1
(2.23)
The expression (2.23) can be used only if S has an inverse (S is nonsingular). It can be
shown that if all eigenvaluesof A are single (all 𝜆i are different)then A is nondefective.
This is true also when A is symmetric.
However, there exist matrices that are defective. In that case, the formula (2.22)
does not make sense as S has no inverse, but we can always use the Taylor series
expansion as definition of eAt:
eAt = I + At + t2
2!A2 + t3
3!A3 + · · · + tn
n!An + …
(2.24)
It can be shown that if S has an inverse, the two definitions (2.23) and (2.24) are
equivalent.
If the ODE system is LCC and inhomogeneous, i.e., the right hand side contains
a driving function g(t) as in equation (2.12)
du
dt = Au + g(t),
u(0) = u0
we obtain the analytic solution in the form of an integral, the Duhamel formula:
u(t) = eAtu0 + ∫
t
0
eA(t−𝜏)g(𝜏)d𝜏
(2.25)
In case the driving vector function g(t) is a constant vector g, the integral can be
solved and the solution of the ODE system is (if A has an inverse)
u(t) = eAtu0 + A−1(eAt −I)g
(2.26)

SOME STABILITY CONCEPTS FOR ODEs
19
Exercise 2.2.1. Compute the eigenvalues and eigenvectors of the matrix
A =
(−2
1
−4
3
)
Exercise 2.2.2. Compute eAt for the matrix given in Exercise 2.1.1.
Exercise 2.2.3. Solve the differential equation ̇u = Au,
u0 = (1, 1)T, where A is
the matrix in Exercise 2.2.1, using the result obtained in Exercise 2.2.2.
Exercise 2.2.4. Compute eigenvalues and eigenvectors of the matrix
A =
(
0
1
−5
2
)
Exercise 2.2.5. Solve the differential equation ̇u = Au,
u0 = (1, 1)T, where A is
the matrix in Exercise 2.2.4.
Exercise 2.2.6. Verify that the matrices
A =
⎛
⎜
⎜⎝
−1
0
0
1
−1
0
0
1
−1
⎞
⎟
⎟⎠
,
B =
⎛
⎜
⎜⎝
0
1
1
0
0
1
0
0
0
⎞
⎟
⎟⎠
are defective. Verify also that B is nilpotent, i.e., Bk = 0, k = 3, 4, ....
Exercise 2.2.7. Compute eAt and eBt for the matrices given in Exercise 2.2.6.
Exercise 2.2.8. Verify the solution formula (2.25) for the inhomogeneous LCC
problem (2.12).
Exercise 2.2.9. Modify the formulas (2.14) and (2.25) to the case where the initial
value is u(t0) = u0, i.e., u is known in the initial point t = t0.
Exercise 2.2.10. In what sense is the system (2.13) and its solutions linear?
2.3
SOME STABILITY CONCEPTS FOR ODEs
The goal of stability analysis is to investigate if small perturbations in a system
will cause large changes in the behavior of the system, in which case the system

20
ORDINARY DIFFERENTIAL EQUATIONS
is unstable. In this chapter, we present two definitions of stability for ODE systems.
The first definition refers to what is meant by a stable solution trajectory and the sec-
ond concerns the stability of the special solutions called critical points (also called
equilibrium points). In this textbook, let us call these two stability concepts analytical
stability.
Another stability concept deals with the stability of numerical solutions. It
is important to distinguish between analytical stability and numerical stability.
Numerical stability is introduced in Chapter 3.
2.3.1
Stability for a Solution Trajectory of an ODE System
As already mentioned, analytic solution of a nonlinear ODE system (2.7) is not pos-
sible in general. However, for small perturbations, the stability analysis can be based
on a linear approximation leading to an LCC system. First we need a definition
of stability. In the definition below we restrict ourselves to autonomous systems,
i.e., ODE systems of the form
du
dt = f(u)
(2.27)
Definition 1: A solution u(t) of (2.27) is stable if every solution that starts suffi-
ciently close to u(t) at t = t0 remains close to u(t) for all t > t0. The solution u(t) is
unstable if there exists at least one solution starting close to u(t) at t = t0, which does
not remain close to u(t) for all t > t0. ♢
The stability question can be completely answered for LCC systems
du
dt = Au
(2.28)
Consider first the scalar ODE
du
dt = 𝜆u
(2.29)
Assume that u(t) is a solution of (2.29). At the point (t0, u0) on the solution trajectory,
a small perturbation 𝛿u0 takes us to a new solution trajectory u(t) + 𝛿u(t) starting at
(t0, u0 + 𝛿u0). This trajectory is followed for t > t0. As the perturbed solution satisfies
the ODE
d(u + 𝛿u)
dt
= 𝜆(u + 𝛿u)
(2.30)
(2.30) is reduced to an ODE for the perturbation only (t0 = 0):
d𝛿u
dt = 𝜆𝛿u,
𝛿u(t0) = 𝛿u0
(2.31)

SOME STABILITY CONCEPTS FOR ODEs
21
As the constant 𝜆can be complex, i.e., 𝜆= 𝜇+ i𝜔, where i =
√
−1, the solution of
the scalar ODE (2.31) can be written as (assume that t0 = 0).
𝛿u(t) = e𝜆t𝛿u0 = e𝜇tei𝜔t𝛿u0 = e𝜇t(cos(𝜔t) + i sin(𝜔t))𝛿u0
(2.32)
The only part in the expression (2.32) that can increase infinitely as t increases is e𝜇t.
Hence, we see that the solution is stable iff 𝜇= Re(𝜆) ≤0. To be more specific, if
Re(𝜆) < 0, the perturbation 𝛿u(t) →0 as t →∞. This is called asymptotic stability.
If Re(𝜆) = 0, the perturbation 𝛿u(t) will stay close to u(t) as t →∞but 𝛿u(t) will not
vanish, see Figure 2.2 where a perturbation is introduced at the point marked o.
A similar analysis of (2.28) gives the following LCC system for the perturbation
𝛿u, (t0 = 0)
d𝛿u
dt = A𝛿u,
𝛿u(t0) = 𝛿u0
(2.33)
From the explicit solution formula (2.20), where t0 = 0, it is clear that stability
depends on the eigenvalues 𝜆i, i = 1, 2, … , n of the matrix A. Hence, the LCC
system (2.33) is asymptotically stable if Re(𝜆i) < 0 for i = 1, 2, … n.
If Re(𝜆i) = 0, the system is stable if 𝜆i is simple. If Re(𝜆i) = 0 and 𝜆i is a multi-
ple eigenvalue, the stability problem is more intricate. The solution can be stable or
unstable and each case must be investigated separately. We will not treat this case
here (see Exercise 2.3.7 for an example).
If we plot the eigenvalues of A in the complex plane, asymptotic stability means
that the eigenvalues are situated in the left half of the complex plane.
Example 2.1.
The eigenvalues of the matrices
A =
⎛
⎜
⎜⎝
−1
0
0
3
1
−2
2
2
−2
⎞
⎟
⎟⎠
B =
⎛
⎜
⎜⎝
−1
0
0
3
1
−2
2
2
1
⎞
⎟
⎟⎠
have the following location in the complex plane (Figure 2.3).
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
du/dt = λ u, λ < 0
u
0
5
10
15
20
−1.5
−1
−0.5
0
0.5
1
1.5
du/dt = λ u, Re(λ) = 0
Im(u)
Figure 2.2
Asymptotic stability and stability

22
ORDINARY DIFFERENTIAL EQUATIONS
−1.5
−1
−0.5
0
0.5
1
−1.5
−1
−0.5
0
0.5
1
1.5
Eigenvalues of the matrix A
Stable system
−1.5
−1
−0.5
0
0.5
1
1.5
−2
−1
0
1
2
Eigenvalues of the matrix B
Unstable system
Figure 2.3
Eigenvalues in the complex plane
For the nonlinear autonomous system (2.27), the stability of a solution can be
examined if the system is approximated by an LCC system. Assume that u(t) is a
solution of (2.27). At time t = t0, where u = u(t0), a small perturbation 𝛿u0 brings us
to a new solution trajectory, u(t) + 𝛿u(t), which is followed for t > t0. The perturbed
solution satisfies the ODE system
d(u + 𝛿u)
dt
= f(u + 𝛿u)
(2.34)
Taylor expansion of the right hand side up to the first-order term gives
du
dt + d𝛿u
dt
= f(u) + 𝜕f
𝜕u𝛿u + O(∥𝛿u∥2)
(2.35)
In (2.35), the jacobian is introduced
J(u) = 𝜕f
𝜕u =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
𝜕f1
𝜕u1
𝜕f1
𝜕u2
…
𝜕f1
𝜕un
𝜕f2
𝜕u1
𝜕f2
𝜕u2
…
𝜕f2
𝜕un
..
..
…
..
..
..
…
..
𝜕fn
𝜕u1
𝜕fn
𝜕u2
…
𝜕fn
𝜕un
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
(2.36)
As u is a solution of (2.27) we obtain, after neglecting the higher order term, the
(linearized) variational equation
d𝛿u
dt
= J(u)𝛿u,
𝛿u(t0) = 𝛿u0
(2.37)

SOME STABILITY CONCEPTS FOR ODEs
23
If the jacobian is frozen at t = t0 to a constant matrix J0, i.e.,
J0 = 𝜕f
𝜕u(u(t0))
(2.38)
we can use the stability results for LCC systems above to answer questions about
the stability of solution trajectories in a close neighborhood of a given solution
trajectory.
2.3.2
Stability for Critical Points of ODE Systems
For an autonomousnonlinearODE system (2.27),it is of special interest to investigate
the stability of critical points, i.e., points satisfying the algebraic equation
f(u) = 0
(2.39)
Critical points are also called the stationary or steady-state solutions, as such solutions
do not change with time t.
Let u∗be a critical point of (2.39). We want to investigate if this point is stable.
The stability concept has to be modified a little for a critical point, as it is a constant
vector.
Definition 2: Assume the critical point u∗is perturbed to a solution u∗+ 𝛿u(t) in
the neighborhood of u∗. If all perturbed solutions converge to the critical point u∗,
this point is said to be asymptotically stable. If at least one perturbed solution diverges
away from the critical point, it is unstable (Figure 2.4). ♢
If the perturbation 𝛿u is small, we can approximate f(u) close to the point u∗using
Taylor expansion up to the first-order term:
f(u∗+ 𝛿u) = f(u∗) + J(u∗)𝛿u + O(∥𝛿u∥2)
(2.40)
−1
–0.5
0
0.5
1
−1
−0.5
0
0.5
1
Stable critical point
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
>
<
<
Unstable critical point
<
<
>
Figure 2.4
Stability of critical points

24
ORDINARY DIFFERENTIAL EQUATIONS
The perturbed solution satisfies the differential equation, i.e.,
du∗
dt + d𝛿u
dt
= f(u∗) + J(u∗)𝛿u
(2.41)
where we have neglected the higher order terms in (2.40). As u∗is a constant and
f(u∗) = 0, we get an ODE system, the variational equation, for the perturbation term
𝛿u:
d𝛿u
dt
= J(u∗)𝛿u
(2.42)
This is an LCC system of type (2.28). The perturbed solution will converge to the
critical point u∗if the eigenvalues of J(u∗) are situated in the left half plane of the
complex plane, so the behavior of solutions close to a critical point can be described
in the same way as the solutions of an LCC problem.
Hence, to investigate the stability of a critical point, proceed as follows:
1. Compute a critical point u∗by solving f(u) = 0 with algebraic tools or with
Newton’s method (see Appendix A.1).
2. Form the jacobian J(u) and compute J∗= J(u∗).
3. Compute the eigenvalues 𝜆i of J∗and check if Re(𝜆i) < 0.
Example 2.2.
A famous ODE system called the Lotka–Volterra differential
equations or the predator–prey model is
dx
dt = ax −bxy
dy
dt = −cy + dxy
where a, b, c, and d are positive parameters.
The critical points of this system are (0, 0) and (c∕d, a∕b). The jacobian of the
system is
J =
(a −by
−bx
dy
−c + dx
)
and the values of the jacobian at the critical points are
J(0, 0) =
(
a
0
0
−c
)
,
J(c∕d, a∕b) =
(
0
−bc∕d
da∕b
0
)
The eigenvalues of J(0, 0)are a and −c, i.e., one eigenvaluesis positive and the critical
point (0, 0) is unstable.
The eigenvalues of J(c∕d, a∕b) are ±i
√
ac. They have a zero real part but are
simple, which implies that the linearized system at the critical point (c∕d, a∕b) is
stable.

SOME STABILITY CONCEPTS FOR ODEs
25
Exercise 2.3.1. Given the following ODE system
̇u = Au,
A =
(
−2
1
−4
3
)
Find the critical points and characterize the stability properties of the critical
points.
Exercise 2.3.2. What is the critical point xcr of the ODE system (A is
nonsingular)?
̇x = Ax −b
Introduce the variable y = x −xcr. Derive the ODE for y. This shows that stability
does not depend on b.
Exercise 2.3.3. Find the critical points and the solution of the ODE system
dw
dt = kt
(−1
1
1
−1
)
w + ki
(1
0
)
,
w(0) =
(0
0
)
The parameters kt and ki are both positive. What about the stability of the critical
points?
Exercise 2.3.4. Given the following ODE
du
dt = 1 −u2
a) Find the critical points of the ODE.
b) Decide for each critical point if it is stable or not.
Exercise 2.3.5. Given the second-order ODE, known as it van der Pol’s equation
d2x
dt2 + 𝜖(x2 −1)dx
dt + x = 0
where the parameter 𝜖> 0.
a) Find the critical point of the ODE system.
b) Is the critical point stable or unstable? Hint: Rewrite as a system of first
order.

26
ORDINARY DIFFERENTIAL EQUATIONS
Exercise 2.3.6. Consider the homogenous vibration equation (see Section 1.3)
md2y
dt2 + d𝜈
dy
dt + ky = 0
The parameters m, d𝜈and k are positive.
a) Find the critical point.
b) Sketch how the eigenvalues at the critical point ‘move’ in the complex plane
as the parameter k changes in the interval (0, ∞). Is the critical point always
stable?
Exercise 2.3.7. Given the ODE system ̇u = Au,
A =
(
0
1
0
0
)
.
Show, by solving the system, that the critical points are unstable!
Hence, when two eigenvalues = 0 (0 is a double root), the solution can be
unstable.
2.4
SOME ODE MODELS IN SCIENCE AND ENGINEERING
Mathematical models based on ODE systems occur frequently in science and engi-
neering. The independent variable usually denotes time t or space x.
A time-dependent ODE system is often referred to as a dynamic system. As such
a model does not take into account any space variations of the dependent variables, it
is sometimes called a lumped model. A space-dependent ODE system involves only
one space variable but does not take time into account. Such models often occur by
simplifying a stationary PDE model in several space variables into a one-dimensional
(1D) space- dependent problem.
In mathematical models of processes in science and engineering, it is important to
define the units of the variables and parameters, e.g., density 𝜌(kg/m3), flow Q (m3/s),
and gravitational acceleration g (m/s2). In this textbook, SI units will be used in most
presentations of Laws of Nature, examples, and exercises.
2.4.1
Newton’s Second Law
A system of moving particles with masses m1, m2, ... ,mn (kg) move according to:
mïri = Fi(t, r1, r2, … , rn, ̇r1, ̇r2, … , ̇rn),
i = 1, 2, … , n
(2.43)
Here ri = (xi, yi, zi)T (m) denotes the position of particle i, ̇ri (m/s) its velocity, and
̈ri its acceleration ( m∕s2). Fi (N) is the total force acting on particle i. The system
(2.43) consists of 3n second-order ODEs.
This equation was formulated by the English mathematician and scientist Isaac
Newton in his work Principia (Mathematical Principles of Science) from 1687.

SOME ODE MODELS IN SCIENCE AND ENGINEERING
27
Engineering applications of (2.43) occur in, e.g., mechanical vibrations. One
important model consists of a system of masses connected by dampers and springs:
M̈x + D𝜈̇x + Kx = F(t)
(2.44)
Here M denotes the mass matrix, D𝜈the damping matrix, and K the spring or stiffness
matrix. x is a vector of displacements of the masses along the x direction. F is a vector
of external forces often of the form F(t) = ̂Fsin(𝜔t), where 𝜔is the angular velocity,
see Exercise 2.1.5 for an example. Observe that the ODE system (2.44) is an LCC
system.
2.4.2
Hamilton’s Equations
A conservative mechanical system is defined as a system where the total energy is
conserved. In such a system, the motions can, as an alternative to Newton’s equations,
be described by a scalar hamiltonian function H invented by the Irish mathematician
W.R.Hamilton in 1835.
H is the sum of the kinetic energy T (J) and the potential energy U (J) of the
system. For a system of n particles in 3D, the hamiltonian has the form:
H = T + U = H(q1, q2, … , qn, p1, p2, … pn),
(2.45)
where the qi denote the generalized coordinates and pi are the generalized momenta.
Hamilton’s equations of motion take the form
dqi
dt = 𝜕H
𝜕pi
,
dpi
dt = −𝜕H
𝜕qi
,
i = 1, 2, … , n
(2.46)
The ODE system (2.45) consists of 6n first-order ODEs.
2.4.3
Electrical Networks
An electrical network consists of passive elements such as resistors, capacitors and
inductors and active elements such as voltage and current sources. The model of a
network is obtained using Kichhoff’s laws and current–voltage relations owing to
Ohm’s law for all elements. If all elements are assumed to have constant impedance
values, a linear DAE system of the following form can be set up, with an algorithm
called modified nodal analysis (2.47):
⎛
⎜
⎜
⎜⎝
ACCAT
C
0
0
0
L
0
0
0
0
⎞
⎟
⎟
⎟⎠
d
dt
⎛
⎜
⎜
⎜⎝
e
iL
iV
⎞
⎟
⎟
⎟⎠
+
⎛
⎜
⎜
⎜⎝
ARGAT
R
AL
AV
−AT
L
0
0
AT
V
0
0
⎞
⎟
⎟
⎟⎠
⎛
⎜
⎜
⎜⎝
e
iL
iV
⎞
⎟
⎟
⎟⎠
=
⎛
⎜
⎜
⎜⎝
−AII
𝟎
E
⎞
⎟
⎟
⎟⎠
(2.47)
where C (F), L (H), and G (Ω−1) are diagonal matrices with the capacitances,
inductances, and conductances (inverses of resistances). AC, AR, AL, AV, and AI are

28
ORDINARY DIFFERENTIAL EQUATIONS
(reduced) incidence matrices, i.e., sparse matrices (see Appendix A.4) consisting of
the integers −1, 0, 1. The vector I (A) consists of the current source values and E (V)
the voltage source values.
The DAE system (2.47) consists of differentialequations for e (V) (the node poten-
tials) and iL (A) (vector of branch currents through the inductors) and additional
algebraic equations for iV (A) (vector of branch currents through voltage sources).
Linear DAE systems in general have the following form (special case of the DAE
system formulated in Exercise 2.1.7):
A ̇u = Bu + b(t)
(2.48)
where A and B are n × n matrices. If A is singular, the system has “index” ≥1: at
least one differentiation is required to produce an ODE system.
2.4.4
Chemical Kinetics
Consider a mixture of N chemical substances A1, A2, … , AN reacting with each other
in M reactions, where the substance concentrations change with time
N
∑
j=1
𝛼ijAj →
N
∑
j=1
𝛽ijAj,
i = 1, 2, … , M
where 𝛼ij and 𝛽ij are integer numbers called the stoichiometric coefficients. The
time-dependent substance concentrations c1, c2, … , cN (mol∕m3) of A1, A2, … , AN
are obtained from the ODE system
dc
dt = Sr(c)
(2.49)
In (2.49), S is the stoichiometric matrix of integers, a sparse N × M matrix, and
r(c) [ mol∕( m3 ⋅s)] an M × 1 vector of reaction rates. In a model by the Norwe-
gian chemists Guldberg and Waage from 1879 called the mass action law, ri has the
form
ri = ki
N
∏
j=1
c
𝛼ij
j ,
i = 1, 2, … , M
(2.50)
where ki (the unit depends on N and 𝛼ij is called the rate constant, which is tempera-
ture dependent according to Arrhenius’ equation k = Ae−E∕RT, where A is called pre-
exponential factor, E (J/mol) is the activation energy, R = 8.314472 [ J∕( K ⋅mol)]
the gas constant, and T (K) the temperature. Svante Arrhenius was a Swedish chemist
and Nobel laureate active about 100 years ago. The ODE system (2.49) is generally
nonlinear. With slight modifications, it can be used to model reactors of great impor-
tance in applications.

SOME ODE MODELS IN SCIENCE AND ENGINEERING
29
2.4.5
Control Theory
A common model used in control theory is the state space model
dx
dt = Ax + Bu
(2.51a)
y = Cx + Du
(2.51b)
where x are internal state variables of the system studied, u are control variables, and
y are observed variables. A, B, C, and D are constant matrices. Of special interest
is the study of stability properties of control systems. Another important problem in
control theory is the identification problem, i.e., from measurements of the observed
variables determine some of the parameters of the system.
In control theory, the models are often described by block diagrams, which can be
translated into ODE systems of type (2.51).
Models in control theory can also be nonlinear ODE systems of type
dx
dt = f(x, u, p)
(2.52a)
y = g(x, u, p)
(2.52b)
where p is a parameter vector.
2.4.6
Compartment Models
Compartment models are frequently used in applications where simplified models of
flows of gases or fluids are studied. Examples are found in biomedicine, pharmacoki-
netics, and air pollution. The model consists of a system of first-order ODEs, describ-
ing the exchange of substances between the compartments of the model. Assume the
model has n compartments, which can be regarded as “boxes”. If xi is the amount
of some substance in compartment i, the model is formulated as an IVP, based on
the balance principle for the amounts of the substances called the continuity equation
(see Chapter 9):
dxi
dt = QI
i +
n
∑
j=1
QI
ij −
n
∑
j=1
QO
ij −QO
i ,
xi(0) = xi0
(2.53)
where the inflow consists of QI
i, which is the flow from the environment to compart-
ment i and QI
ij the flow to compartment i from compartment j. The outflow consists
of QO
i , which is the flow from compartment i to the environment and QO
ij being the
flow from compartment i to compartment j. The initial value xi0 is the initial amount
of the substance in compartment i.
If the flows are modeled as QI
ij = kI
ijxj, QO
ij = kO
ij xi, and QI
i, QO
i are constant or time
dependent, the resulting ODE system will be an LCC system.

30
ORDINARY DIFFERENTIAL EQUATIONS
2.5
SOME EXAMPLES FROM APPLICATIONS
In this part of the chapter, some ODE applications are shown, exemplifying the mod-
els presented in Section 2.4. The examples will be referred to in Chapters 3 and 4,
where numerical methods for IVPs and BVPs are described. To each example, some
exercises are given. They are mainly intended for repetition of analytic treatment of
ODEs and also to demonstrate analytic preprocessing necessary before numerical
treatment of the problems should be performed.
Example 2.3. Particle dynamics
The following differential equation is a model of the motion in the xy-plane of a
particle released with a certain initial velocity from a point and then moving under the
influence of gravity and a force generated by the air resistance, which is proportional
to the square of the velocity (see Exercise 2.1.4 for the corresponding 1D problem).
md2r
dt2 = −mgey −c‖‖‖‖
dr
dt
‖‖‖‖2
dr
dt ,
r(0) = y0ey,
dr
dt (0) = v0
(2.54)
where m (kg) is the mass of the particle, r (m) is the position of the particle, g (m∕s2)
gravitational acceleration, c (N ⋅s2∕m2) air resistance coefficient, y0 (m) initial
height of the particle, and v0 (m/s) the initial velocity vector, which has an elevation
angle 𝛼> 0 with the horizontal plane (see Figure 2.5).
The formulation (2.54) of the problem is an IVP. The computational task is to
integrate step by step until the particle hits the ground (y = 0). However, this problem
can also be formulated as a BVP if the task is to determine the elevation angle that
causes the particle to hit a given point x0 on the ground for a given value of the initial
velocity. The ICs are replaced by BCs:
r(0) = y0ey,
r(T) = x0ex
(2.55)
where T (s) is the time when the particle hits the ground in the point (x0, 0).
By adjusting the elevation angle 𝛼, the BC at x = x0 can be satisfied. It turns
0
2
4
6
8
10
−1
0
1
2
3
4
5
6
Particle motion as IVP
r (t)
x
y
y0
v0
0
2
4
6
8
10
12
−2
0
2
4
6
x
y
y0
x0
r (t), α = 58.5°
r (t), α = 20.2°
Particle motion as BVP
Figure 2.5
Particle dynamics in 2D

SOME EXAMPLES FROM APPLICATIONS
31
out that this BVP has two solutions, for certain values of the parameters, see
Figure 2.5.
Exercise 2.5.1. Solve analytically the IVP and the BVP in the case c = 0.
Exercise 2.5.2. Rewrite the IVP as an ODE system of first order, i.e., in the
form (2.8).
Example 2.4. Planetary motion
Consider the motion of a single planet about a heavy sun. The assumption heavy sun
means that the sun influences the motion of the planet, but the relatively small mass
of the planet has an influence on the sun that is negligible. Let r(t) = (x(t), y(t))T (m)
denote the coordinates of the planet with the sun in the origin. The only force act-
ing on the planet is the gravitational force from the sun having the magnitude Fr =
𝛾Mm∕∥r ∥2
2 (N), where 𝛾= 6.6742 ⋅10−11 ( N ⋅m2∕kg2) is the gravitational con-
stant, M (kg) the mass of the sun, and m the mass of the planet.
Newton’s equation (2.43) takes the form (for illustration, see Figure 2.6):
md2r
dt2 = −𝛾Mm
∥r ∥2
2
er
(2.56)
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Figure 2.6
Planetary motion in 2D

32
ORDINARY DIFFERENTIAL EQUATIONS
Exercise 2.5.3. Write Newton’s equation (2.56) in component form, i.e., one
second-order ODE for x(t) and another for y(t). Also write (2.56) as a system of
first-order ODEs.
Exercise 2.5.4. For planetary motion, the hamiltonian can be written
H(q, p) = T + U = 1
2m(p2
1 + p2
2) −
𝛾Mm
√
q2
1 + q2
2
(2.57)
where q and p are the (generalized) coordinates and momenta
q = r,
p = mdr
dt
a) Show that H, i.e., the total energy (sum of kinetic and potential energy) is con-
served. Also show that the angular momentum L = q × p is conserved. Hint:
Form dH∕dt and dL∕dt.
b) Show that Hamilton’s equations applied to (2.57) imply Newton’s equation.
Example 2.5. A simple RLC circuit
Consider the following electrical network (Figure 2.7), consisting of two resistors,
one capacitance, one inductance, one voltage source, and one current source.
R1
R2
L
C
I
E
Figure 2.7
A simple electrical network
The DAE system corresponding to this electrical network is (2.58)
⎛
⎜
⎜
⎜
⎜⎝
C
−C
0
0
0
−C
C
0
0
0
0
0
0
0
0
0
0
0
L
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟⎠
d
dt
⎛
⎜
⎜
⎜
⎜⎝
e1
e2
e3
iL
iV
⎞
⎟
⎟
⎟
⎟⎠
+
⎛
⎜
⎜
⎜
⎜⎝
1∕R1
0
0
0
0
0
1∕R2
0
1
0
0
0
0
−1
1
0
−1
1
0
0
0
0
1
0
0
⎞
⎟
⎟
⎟
⎟⎠
⎛
⎜
⎜
⎜
⎜⎝
e1
e2
e3
iL
iV
⎞
⎟
⎟
⎟
⎟⎠
=
⎛
⎜
⎜
⎜
⎜⎝
0
−I
0
0
E
⎞
⎟
⎟
⎟
⎟⎠
(2.58)
In a linear DAE system, there are linear relations between the dependent variables
and the initial values must be consistent with these relations.

SOME EXAMPLES FROM APPLICATIONS
33
Exercise 2.5.5. Verify that the following linear algebraic relations are valid for a
solution of the DAE system above:
⎧
⎪
⎨
⎪⎩
R−1
1 e1 + R−1
2 e2 + iL = −I
iL = iV
e3 = E
and that the following IC is consistent with these algebraic relations: u0 =
(0, 0, E, −I, −I)T
Exercise 2.5.6. Find the steady-state solution of (2.58).
Example 2.6. Biochemical reaction
The following reaction system, consisting of two reversible reactions, occurs fre-
quently in biochemistry
E + S ⇐⇒C ⇐⇒E + P
In the reaction formula, E stands for enzyme, S for substrate, C for complex, and P
for product. The respective concentrations are denoted by c1, c2, c3, and c4. The ODE
system modeling the kinetic behavior of the reaction system is
dc
dt =
⎛
⎜
⎜
⎜
⎜⎝
−1
1
1
−1
−1
1
0
0
1
−1
−1
1
0
0
1
−1
⎞
⎟
⎟
⎟
⎟⎠
⎛
⎜
⎜
⎜
⎜⎝
k1c1c2
k2c3
k3c3
k4c1c4
⎞
⎟
⎟
⎟
⎟⎠
,
c0 =
⎛
⎜
⎜
⎜
⎜⎝
E0
S0
0
0
⎞
⎟
⎟
⎟
⎟⎠
(2.59)
where k1, k2, k3, and k4 are the rate constants of the reactions and E0 > 0 and S0 > 0
are the initial concentrations of E and S.
Exercise 2.5.7. Verify that c1(t) + c3(t) = E0 and c2(t) + c3(t) + c4(t) = S0.
When the reactions have come to chemical equilibrium, the concentrations satisfy
the following nonlinear algebraic system of equations
f(c) =
⎛
⎜
⎜
⎜
⎜⎝
−1
1
1
−1
−1
1
0
0
1
−1
−1
1
0
0
1
−1
⎞
⎟
⎟
⎟
⎟⎠
⎛
⎜
⎜
⎜
⎜⎝
k1c1c2
k2c3
k3c3
k4c1c4
⎞
⎟
⎟
⎟
⎟⎠
= 0
(2.60)
One solution of this system is obviously c = (0, 0, 0, 0)T, which, however, cannot
be the equilibrium concentrations as the relations in Exercise 2.5.7 are not fulfilled.
Using Newton’s method (see Appendix 1) to solve the system of equations (2.60)

34
ORDINARY DIFFERENTIAL EQUATIONS
will not work, as the matrix is singular, which implies that the jacobian will also be
singular.
Exercise 2.5.8. Preprocess the equilibrium problem so that Newton’s method can
be used.
Example 2.7. Stability of a regulator
Consider a servo mechanism where the output signal y(t) depends on an input signal
u(t). In an application, u(t) can be the torsion angle of the steering wheel of a boat
and y(t) the torsion angle of the boat’s rudder. The purpose of servo is to strengthen
the torsion moment from a small value to a large value.
The following control system models a feedback regulator consisting of an elec-
tromechanical system described with a block diagram (Figure 2.8):
+
G1:
v = k1e
G2:
Ri + L di
dt = v
G3:
M = k2i
G4: J d2y
dt 2 +
dν
dy
dt = M
u
e
v
i
M
y
−
+
Figure 2.8
Block diagram of a servo mechanism
In mathematical terms, the model is formulated in the following way:
⊕∶e(t) = u(t) −y(t), the difference (error) between u(t) and y(t)
G1∶v(t) = k1e(t), amplification of e(t) into a voltage value
G2∶Ri(t) + L di
dt = v(t), induced current in a motor driving an axis.
G3∶M(t) = k2i(t), torsion moment of the axis.
G4∶J d2y
dt2 + d𝜈
dy
dt = M(t), the moment drives a load (the rudder) having moment
of inertia J and damping coefficient d𝜈.
Exercise 2.5.9. Write the equations above in state space form (2.51) with x(t) =
(i(t), z(t), y(t))T, where z(t) = dy∕dt, u(t) = (u(t), 0, 0)T, and y(t) = y(t). Hint: Elimi-
nate e(t), v(t), and M(t). Note that the resulting ODE system is of LCC type.
Exercise 2.5.10. Verify that the equations above can also be written as a third-order
ODE (of LCC type):
LJ
R
d3y
dt3 +
(Ld𝜈
R + J
) d2y
dt2 + d𝜈
dy
dt + Ky = Ku(t),
K = k1k2
R
(2.61)
The properties of this regulator model can be simulated in a parameter study. Particu-
larly important is the parameter K, which is proportional to the amplification factors
of the model.

SOME EXAMPLES FROM APPLICATIONS
35
To answer the question, if the system is stable for all values of K, it is enough to
study the homogeneous version of (2.61), i.e., the case where u = 0
LJ
R
d3y
dt3 +
(Ld𝜈
R + J
) d2y
dt2 + d𝜈
dy
dt + Ky = 0
(2.62)
If the parameter L = 0, (2.62) turns into a second-order ODE of the same type as in
Exercise 2.3.6 and therefore stable for all values of K. However, what happens if the
parameter L ≠0?
Exercise 2.5.11. Assume the following values of the parameters: J = 0.4, d𝜈= 1,
R = 100, L = 10. Write a program that makes a graph (root locus) of the curves gen-
erated by the eigenvalues of (2.62) as K varies in the interval [0, 20]. For which values
of K is the system unstable?
Example 2.8. Drug kinetics
The following two-compartment model is an example from pharmacokinetics.
Assume a drug, which has been taken orally, is present in the intestine during a
certain time interval. The drug is absorbed with the constant flow rate q (mmol/s)
into the first compartment, the blood plasma. In the blood plasma, the concentration
of the drug is c1(t) (mmol/l). The second compartment is the organ where the drug
is active. Between the first and second compartments, there is an drug exchange
with rate k1c1(t) (mmol/l/s) leading to the drug concentration c2(t) in the second
compartment. In the organ, the drug is consumed with the rate kbc2(t) (mmol/s)
and the surplus is sent back to the blood with the rate k2c2(t) (mmol/s). From the
blood, finally, there is an elimination of the drug through the kidneys with the rate
kec1(t) (mmol/s). Figure 2.9 illustrates the blood–organ compartment model of drug
distribution:
blood
c1(t)
organ
c2(t)
q
k1c1
k2c2
kbc2
kec1
Figure 2.9
A simple compartment model
The ODE system (2.53) takes the following form in this case:
dc1
dt = −k1c1 + k2c2 −kec1 + q,
c1(0) = 0
dc2
dt = k1c1 −k2c2 −kbc2,
c2(0) = 0

36
ORDINARY DIFFERENTIAL EQUATIONS
The steady-state solution, i.e., the solution obtained when the time derivatives are
zero, is obtained from the algebraic linear system of equations:
(
k1 + ke
−k2
−k1
k2 + kb
) (
c1
c2
)
=
(
q
0
)
Exercise 2.5.12. Formulate the analytical solution of the ODE system using
Duhamel’s formula (2.25).
BIBLIOGRAPHY
1. D. Zill and M. Cullen, “Differential Equations with Boundary Value Problems”, 5th edition,
Brooks and Cole, 2005
2. W. Boyce and R. DiPrima, “Elementary Differential Equations and Boundary Values Prob-
lems”, 8th edition, Wiley, 2005
The following textbook is older but elementary and well-structured
3. M. Braun, “Differential Equations and Their Applications”, Springer, 1975
An old classical textbook, extensive and theoretical is
4. E. Coddington and N. Levinson,
“Theory of Ordinary Differential Equations”,
McGraw-Hill, 1955
References to special application areas of ODEs
Particle dynamics: H.Goldstein et al, “Classical Mechanics”, Addison Wesley, 2004
Electrical networks: J.D.Irwin, “Basic Engineering Circuit Analysis”, Prentice Hall, 2005
Chemical kinetics: P.Erdi, J.Toth, “Mathematical models of chemical reactions”, Manchester
University Press, 1989
Control theory: L.Ljung, T.Glad, “Modeling of Dynamical Systems, Prentice Hall, 1994
Compartment models: K.Godfrey, “Compartmental Models and Their Application”, Academic
Press, 1983

3
NUMERICAL METHODS FOR INITIAL
VALUE PROBLEMS
As we have seen in Chapters 1 and 2, ordinary differential equation(ODE) prob-
lems occur in numerous applications and therefore important for modeling processes
whose evolution depends on one variable, usually time t or one spatial variable x.
In this chapter, we treat the initial value problem (IVP).
The general formulation of an IVP is
du
dt = f(t, u),
u(t0) = u0,
t0 < t ≤tend
(3.1)
Often the solution depends on parameters, denoted by the vector p, that occur in the
right hand side function:
du
dt = f(t, u, p),
u(t0) = u0,
t0 < t ≤tend
(3.2)
The initial values u0 can also be regarded as parameters in case the dependence of
the initial values is studied: u = u(t, p, u0)
Example 3.1. (Newton’s law for a particle)
In Exercise 2.1.4, the following IVP was introduced
m̈y = −mg −c ̇y| ̇y|,
y(0) = y0,
̇y(0) = v0
(3.3)
This ODE models a particle thrown vertically from the position y0 and with initial
velocity v0. The particle is influenced by gravity and an air resistance force being
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

38
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
proportional to the square of the velocity. When the solution is studied as a function
of, e.g., c, we make a parameter study of the problem. The solution of this problem
depends on t and the parameters m, c, g, y0, and v0, i.e., y = y(t, m, c, g, y0, v0).
This example indicates that there are several questions that can be posed concern-
ing the solution of an IVP:
• How does the solution behave on a time interval [t0, tend] for a given p?
• How does the solution depend on parameters p in the problem?
• Which are the critical points and what are the stability properties of the critical
points (stability analysis)?
• How sensitive is the solution with respect to the parameters (sensitivity
analysis)?
• When a parameter varies over an interval, does the solution change character
for some value of the parameter in this interval (bifurcation analysis)?
• When measurements (tk, u∗
k), k = 1, 2, … , M, of the process are given from
experiments, how do we estimate unknown parameters in the model (parameter
estimation)?
To be able to answer the questions, it is necessary to have an accurate, efficient, and
robust numerical solver for the IVP (3.1).
3.1
GRAPHICAL REPRESENTATION OF SOLUTIONS
To get a better understanding of the behavior of solutions to ODE problems, it is
necessary to visualize the solutions graphically. This can be done in different ways:
• plot trajectories, i.e., u(t) is plotted as function of t in a coordinate system. A
trajectory is appropriate when we want to study the time evolution of a process.
Depending on the size of variables, it should be judged what scales should be
used for the different coordinate axis, linear or logarithmic.
• plot phase portraits showing two componentsof the solution, ui(t) and uj(t) with
t as a parameter along the curve (ui(t), uj(t)) plotted in a coordinate system. A
phase portrait is appropriate when one wants to study how solutions behave as
function of initial values, especially in the neighborhood of critical points. In
3D graphics, a phase portrait with three components can be plotted.
There are other types of graphical representation, e.g., the root locus plot, often
used in control theory to visualize the stability properties of an ODE system, see
Example 2.7.

GRAPHICAL REPRESENTATION OF SOLUTIONS
39
10−3
10−2
10−1
100
101
102
103
104
105
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
S, E, C, P
t
The ESCEP–problem
S
E
P
C
Figure 3.1
Example of solution trajectories
Example 3.2. (The kinetics of a biochemical reaction system).
The following reactions and the corresponding ODE system was introduced in
Example 2.6:
E + S ⇐⇒C ⇐⇒E + P
The kinetics of the reaction system is modeled by the ODE system (2.59). In
this example, the following values of the parameters are given: k1 = 10, k2 = 0.1,
k3 = 1, k4 = 10. With the initial values E0 = 0.1, S0 = 1, C0 = 0, and P0 = 0 we
get the following trajectories. Note that it is appropriate for this problem to use
logarithmic scale on the t-axis (Figure 3.1).
Example 3.3. (A problem with an oscillating solution: Van der Pol’s equation).
Van der Pol’s equation (see Exercise 2.3.5) occurs, e.g., in modeling of nonlinear
electrical circuits:
d2y
dt2 + 𝜖(y2 −1)dy
dt + y = 0,
y(0) = 1,
dy
dt (0) = 0
(3.4)
The numerical solution of this ODE problem is described in Section 3.3. The results
are preferably visualized as a phase portrait. If the parameter 𝜖is given the val-
ues 𝜖= 0.1, 1, 10, 100, the following phase portraits are drawn in a parameter study

40
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
–2
–1
0
1
2
–1.5
–1
–0.5
0
0.5
1
1.5
y
dy/dt
–3
–2
–1
1
0
2
–3
–2
–1
0
1
2
3
y
dy/dt
van der Pol, eps = 0.1
van der Pol, eps = 1
–4
–2
0
2
4
–15
–10
–5
0
5
10
15
y
dy/dt
–4
–2
2
0
4
–150
–100
–50
0
50
100
150
y
dy/dt
van der Pol, eps = 10
van der Pol, eps = 100
Figure 3.2
Example of phase portraits
(Figure 3.2). Obviously the solutions are oscillating. After an initial transient, the
phase portrait approaches a closed curve, a limit cycle. In the graph, the point o rep-
resents the initial value point.
3.2
BASIC PRINCIPLES OF NUMERICAL APPROXIMATION OF ODEs
The solution of an ODE problem (3.1) is a vector-valued function u(t). An approx-
imate numerical solution can be obtained with a discretization method, such as the
finite difference method (FDM) or an ansatz method, e.g., the finite element method
(FEM) or the finite volume method (FVM). In this chapter, the FDM is presented.
With an FDM, we obtain a sequence of points (t1, u1), (t2, u2), … , (tN, uN). These
points approximate the exact solution, i.e., uk ≈u(tk). Examples of well-known
FDMs are Euler’s method and Runge–Kutta’s method.
With an ansatz method, a function uh(x) ≈u(x) is obtained. The approximating
function has the form uh(t) = ∑cj𝜑j(x), where 𝜑j(x) are given basis functions and cj
are coefficients chosen in such a way that the approximation is as accurate as possi-
ble in some sense. The FEM is an example of such a method, see Sections 4.3, 6.5,
and 7.4.

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
41
The FVM is a method for solving certain PDEs approximated by ODE systems.
Similar to the FDM approximate values, u1, u2, … , uN are calculated at discrete
space points x1, x2, … , xN, see Section 8.3.
When different methods for the IVP are discussed, we can without loss of gener-
ality restrict ourselves to the scalar case, i.e.,
du
dt = f(t, u),
u(0) = u0,
0 < t ≤tend
(3.5)
The exact solution of this problem is denoted by u(t). All numerical formulas in this
chapter will be given for the scalar case, unless otherwise is stated.
3.3
NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
The basic idea in an FDM is that the derivative in (3.5) at time tk is approximated by a
difference formula using a few u values … uk−1, uk, uk+1 … in the neighborhood of
uk. The difference hk between two consecutive t points, i.e., hk = tk+1 −tk, is called
the stepsize. Most numerical methods use variable stepsize, i.e., hk takes different
values as the solution is computed along the t-axis. Methods where variable stepsize
is implemented are also called adaptive methods.
However, constant stepsize h can also be used, especially when we want to have
better control of the truncation errors (approximation errors) of the uk values. In that
case, the tk points are equidistantly spaced along the t-axis.
The discretized formulation of the ODE problem changes the differential equation
into a difference equation and the numerical solution is computed as a sequence
of uk values; the uk values are generated by a recursion formula. Linear difference
equations are fundamental for understanding numerical stability of FDMs. A short
overview is given in Appendix A.2.
The derivative in (3.5) can be approximated by various difference formulas, e.g.,
the Euler forward (3.6) or the Euler backward (3.7) approximations:
du
dt (tk) = u(tk+1) −u(tk)
h
+ O(h)
(3.6)
du
dt (tk) = u(tk) −u(tk−1)
h
+ O(h)
(3.7)
Both formulas are of first order,i.e., the truncation error is approximatelyproportional
to h provided h is sufficiently small. Leonard Euler was a Swiss mathematician active
in the 18th century and one of the most productive ever. He was one of the first to
write a textbook in analysis: “Introductio in analysin infinitorum” from 1748.
Another possible approximation would be to use the central difference approxi-
mation formula, which is of second order:
du
dt (tk) = u(tk+1) −u(tk−1)
2h
+ O(h2)
(3.8)

42
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
It may seem that the formula (3.8) is better to use instead of (3.6) and (3.7) as it
is of second order and therefore more accurate. There are disadvantages, however,
using (3.8) for the IVP, related to numerical instability, see Section 3.4.2. For certain
problems, however, (3.8) works well, see Section 3.5.
Consider first the constant stepsize case. Applying (3.6) to the IVP (3.5) gives
Euler’s explicit method (also called Euler’s forward method)
{
uk = uk−1 + hf(tk−1, uk−1),
u0 = u(0)
tk = tk−1 + h,
t0 = 0,
k = 1, 2, … , N
(3.9)
When (3.7) is used, we get Euler’s implicit method (also called Euler’s backward
method).
{
uk = uk−1 + hf(tk, uk),
u0 = u(0)
tk = tk−1 + h,
t0 = 0,
k = 1, 2, … , N
(3.10)
It can be shown that both methods give first-order accuracy in the uk values, i.e., the
truncation error, for IVPs also called the global error, ek, fulfills
ek = u(tk) −uk = O(h)
(3.11)
For both methods, we see that when (tk−1, uk−1) is given as input, the next point
(tk, uk) is computed as output, hence Euler’s explicit and implicit methods are both
one-step methods.
However, in explicit Euler, uk is computed just by inserting (tk−1, uk−1) into
the right hand side, while in implicit, Euler uk is computed by solving a nonlinear
equation. For that reason, we call (3.9) an explicit method, while (3.10) is an implicit
method.
As an implicit method will be more complicated to compute, one may immediately
ask: Why use implicit Euler when the computational work is so much larger? The
answer is that for certain problems called stiff problems, implicit Euler is much more
advantageous for numerical stability reasons. This will be shown in Section 3.3.4.
The two Euler methods usually have too low order of accuracy to be of practical
importance.However,they are very useful fordemonstrationof principles of the FDM
when applied to an IVP. We will therefore show some basic properties using these two
methods before we continue to higher order methods in Section 3.4.
Exercise 3.3.1. Show that the difference approximations (3.6) and (3.7) both have
first-order accuracy.
Exercise 3.3.2. Show that the difference approximation (3.8) is of second order.

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
43
Exercise 3.3.3. Set up the recursion formula when Euler’s explicit method (3.9) is
applied to the scalar model problem for IVPs
du
dt = 𝜆u,
u(0) = u0
where 𝜆is a constant complex parameter. Show that uk = (1 + h𝜆)ku0.
Exercise 3.3.4. The following method is sometimes used for solving problems in
Newtonian mechanics. For the ODE system
dv
dt = a(x, v),
dx
dt = v
the Euler–Cromer method (see also Section 3.5) is defined as
vk+1 = vk + ha(xk, vk),
xk+1 = xk + hvk+1
What is the order of this method? Try an analytical approach or make a numerical
experiment (see Section 3.3.1).
3.3.1
Euler’s Explicit Method: Accuracy
We first show how explicit Euler is used to solve Van der Pol’s equation (3.4)
d2y
dt2 + 𝜖(y2 −1)dy
dt + y = 0,
y(0) = 1,
dy
dt (0) = 0
This second-order ODE is written as a system of two first-order ODEs by introducing
a vector u with the components u1 = y, u2 = dy∕dt:
⎧
⎪
⎨
⎪⎩
du1
dt = u2,
u1(0) = 1
du2
dt = −𝜖(u2
1 −1)u2 −u1,
u2(0) = 0
When the explicit Euler method is applied to this system, we get the recursion
formulas:
⎧
⎪
⎨
⎪⎩
u1,k = u1,k−1 + hu2,k−1,
u1,0 = 1
u2,k = u2,k−1 + h(−𝜖(u2
1,k−1 −1)u2,k−1 −u1,k−1),
u2,0 = 0
tk = tk−1 + h,
t0 = 0

44
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Recall that u1,k ≈u1(tk) = y(tk). How does the global error e1,k = u1(tk) −u1,k
depend on the stepsize h? The numerical experiment presented in the example below
gives an answer to that question.
Example 3.4. Numerical experiment to determine the order of accuracy
For Van der Pol’s equation (3.4), let 𝜖= 1 and calculate y(1) with explicit Euler.
Discretize the t-axis on the interval [0, 1] with constant stepsize h, using N steps.
Table 3.1 shows the result obtained with the explicit Euler method.
As we observe in the table, the convergence is very slow. When h is halved, the
global error u1,N −y(1) is also halved, hence e1,N ≈Ch
From a logarithmicplot, the orderof accuracy can be estimated graphically.Taking
the logarithm of the general error relation e ≈Chp gives log e ≈log C + p log h,
which is a straight line in a loglog diagram. The slope of that line is p. In Figure 3.3,
the slope is 1, hence the order of explicit Euler is p = 1.
The error defined by (3.11) is called the global error. Another concept important
for error estimation and variable stepsize control in adaptive methods is the local
error, l(t, h), which is defined as the residual obtained when the exact solution is
inserted into the explicit Euler method
l(tk, h) = u(tk) −u(tk−1) −hf(tk−1, u(tk−1))
(3.12a)
Hence, the local error can be regarded as the truncation error committed in one step.
With Taylor’s expansion, we see that
l(tk, h) = h2
2
d2u
dt2 (𝜏k),
tk−1 < 𝜏k < tk
(3.12b)
In Figure 3.4, it is shown how the global and local errors propagate when one step is
taken from tk−1 to tk.
TABLE 3.1
Numerical Solution of Van der Pol’s Equation Using
Explicit Euler
N
h
u1,N
u1,N −y(1)
16
1∕16
0.5231
0.0254
32
1∕32
0.5100
0.0123
64
1∕64
0.5037
0.0060
128
1∕128
0.5006
0.0029
256
1∕256
0.4991
0.0014
512
1∕512
0.4984
0.0007
1024
1∕1024
0.4980
0.0003
2048
1∕2048
0.4978
0.0001

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
45
10−4
10−3
10−2
10−1
100
10−4
10−3
10−2
10−1
100
Stepsize h
Truncation error
Loglog–diagram of error as function of h
Figure 3.3
Loglog diagram showing the order of accuracy for explicit Euler
tk–1
tk
t
u(tk–1)
u(tk)
uk–1
uk
ek–1
ek
ℓk
Figure 3.4
Graphical definition of the local and global errors
The global error ek can be regarded as the accumulated effect of all local errors
from t1 up to tk. However, it is not true in general that the global error is the sum of
the local errors, as the following analysis shows:
Euler’s explicit method can be written:
0 = −uk + uk−1 + hf(tk−1, uk−1)
If this equality is added to (3.12) we obtain, after using Taylor’s expansion on the
second argument u in f(t, u), a global error recursion relation

46
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
ek = ek−1 + h 𝜕f
𝜕u(tk−1, uk−1 + 𝜃(u(tk−1) −uk−1))ek−1 + l(tk, h),
e0 = 0
(3.13)
where 0 < 𝜃< 1. From this equality, we see that only if 𝜕f∕𝜕u ≡0, i.e., if f(t, u) does
not depend on u, the global error is the sum of the local errors. If this is not the case,
assume that
𝜕f
𝜕u ≤𝜇⇒1 + h 𝜕f
𝜕u ≤1 + h𝜇≤eh𝜇
in the neighborhood of the solution, where 𝜇can be a negative number. Insert the
expression (3.12b) into the global error formula (3.13) and we get
ek ≤(1 + h𝜇)ek−1 + h2
2
d2u
dt2 (𝜏k)
With the assumption h𝜇> −1 and
max
1≤k≤n |d2u
dt2 (𝜏k)| ≤M
we obtain the inequality
|ek| ≤(1 + h𝜇)|ek−1| + h2
2 M
which gives the following estimate for the global error (e0 = 0)
|ek| ≤h2
2 M etk𝜇−1
h𝜇
= O(h)
(3.14)
Hence, the global error for Euler’s explicit method is of first order. We see from
(3.12b) and (3.14) that the local error is one order larger than the global error. In
general, this is true for most FDM. If the local error l(tk, h) is O(hp+1), the global
error ek is O(hp).
3.3.2
Euler’s Explicit Method: Improving the Accuracy
Instead of decreasing the stepsize h in explicit Euler to get better accuracy, the method
can be improved by calculating the solution with two stepsizes, h and h∕2, combined
with extrapolation. Take a step from tk−1 to tk = tk−1 + h in the following way:
1. Take one Eulerstep of size h: u∗
k = uk−1 + hf(tk−1, uk−1)
2. Take two Eulersteps of size h∕2:
uk−1
2 = uk−1 + h
2f(tk−1, uk−1),
u∗∗
k = uk−1
2 + h
2f(tk−1
2 , uk−1
2 )

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
47
3. The value uk is obtained by extrapolation:
uk = 2u∗∗
k −u∗
k
The method described in the steps 1–3 above can be shown to be a second-order
method. With a numerical experiment on Van der Pol’s equation (3.4), this statement
can be verified empirically (Table 3.2):
TABLE 3.2
Numerical Solution of Van der Pol’s
Equation Using Runge’s Second-Order Method
N
h
u1,N
u1,N −y(1)
4
1∕4
0.4991
0.0015
8
1∕8
0.4980
0.0004
16
1∕16
0.4977
0.0001
As is seen in Table 3.2, the errors decrease quadratically, i.e., eN = O(h2). Hence,
the convergence of improved Euler is much faster than explicit Euler and therefore
more efficient as fewer steps have to be taken to achieve a certain accuracy. The
improved Euler method is equivalent to a Runge–Kutta method (more about these
methods in Section 3.4) known as Runge’s second-order method:
k1 = f(tk−1, uk−1), k2 = f(tk−1 + h∕2, uk−1 + hk1∕2), uk = uk−1 + hk2
Exercise 3.3.5. Show that improved Euler is a second-order method. Hint: use the
following error expansion valid for explicit Euler: ek = c1h + c2h2 + c3h3 + … and
extrapolation according to 3).
Exercise 3.3.6. Verify that improved Euler and Runge’s second-order method are
the same one-step method.
Exercise 3.3.7. The following method, Heun’s method, is another variant of
explicit Euler.
u∗
k = uk−1 + hf(tk−1, uk−1),
uk = uk−1 + h
2(f(tk−1, uk−1) + f(tk, u∗
k))
Verify, by solving Van der Pol’s equation numerically (write a program) that this
method is of second order.
Exercise 3.3.8. Verify that the local error (3.12b) for explicit Euler is given by
l(tk, h) = h2
2
d2u
dt2 (tk) + O(h3)

48
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Hence, the local error is O(h2), while the global error is O(h). Write a programto make
a numerical experiment on the scalar test equation defined in Exercise 3.3.3. Let
𝜆= −1, u0 = 1, t0 = 0, tend = 1, and h = 0.05. Compute the global and the
local errors (neglect the O(h3) term) and write a table showing k, tk, uk,
l(tk, h) = h2u′′(tk)∕2, and ek = u(tk) −uk.
3.3.3
Euler’s Explicit Method: Stability
In the previous part of this chapter, it is shown how explicit Euler behaves when the
stepsize h is small. But what happens if large steps are taken?
Recall first the example of instability in Section 1.3, where the explicit Euler gives
an erroneous result with increasing amplitudes in the numerical solution of the vibra-
tion equation, although the analytic solution has decreasing amplitudes. What is the
reason for this difference in numerical and analytical behavior?
Example 3.5.
The following example from chemical kinetics, known as Robert-
son’s problem, shows that explicit Euler gives wrong results unless the stepsize is
small enough.
The following three irreversible reactions are given:
A →B,
B + C →A + C
2B →B + C
The following ODE system can be formulated based on the mass action law:
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪⎩
du1
dt = −k1u1 + k2u2u3,
u1(0) = 1
du2
dt = k1u1 −k2u2u3 −k3u2
2,
u2(0) = 0
du3
dt = k3u2
2,
u3(0) = 0
(3.15)
where k1 = 0.04, k2 = 104, k3 = 3⋅107 are the rate constants of the reactions and u1,
u2, and u3 are scaled concentrations of A, B, and C.
If we use the explicitEuler method on this problem,we get the followingnumerical
result, shown in Table 3.3, for u(1) using different constant stepsizes h:
TABLE 3.3
Stability Depending on
the Stepsize
N
h
u(1)
10
0.1
NaN
100
0.01
NaN
1000
0.001
NaN
104
10−4
ok

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
49
In Table 3.3, NaN (Not a Number) means that the method has generated numbers
that are too large to be stored in the computer memory,also called overflow.The result
of the calculation is acceptable (but not very accurate) when h = 10−4. However,
the solution is interesting to study on the time interval [0, 1000]. Using the stepsize
h = 10−4 on the whole time interval means that we have to take 107 time steps, which
is very inefficient.
The solution of the problem is shown in the graph in Figure 3.5 drawn in both
linear and logarithmic scales:
0
200
400
600
800
1000
0
0.2
0.4
0.6
0.8
1
Robertson problem
t
A, B, C
A
B
C
100
10−5
100
t
A, B, C
A
B
C
Figure 3.5
Solution of Robertson’s problem, in linear and logarithmic diagrams
From the behavior of the solution curves, there seems to be no need for very small
stepsizes; the solution is very smooth after a short transient phase in the time interval
(0, 10−2), where u2(t) passes a maximum.
Two relevant questions in connection to this problem are
• Why are such small stepsizes needed when explicit Euler is used on this prob-
lem?
• Are there other methods better suited to solve this problem?
These questions and their answers are fundamental for understanding the numerical
stability problems when solving both ODE and PDE problems by discretization.
To investigate the numerical stability of methods, some results for LCC systems
(see Section 2.2) are needed.
We start with the scalar model problem introduced in Exercise 3.3.3. Then we
generalize to the LCC problem and finally to a nonlinear system. This is the same
increase of complexity as in the analytic stability analysis in Section 2.3.
du
dt = 𝜆u,
→
du
dt = Au,
→
du
dt = f(u)
(3.16)
Recall that the scalar model problem has the analytic solution u(t) = e𝜆tu0, which is
stable for t ≥0 if Re(𝜆) ≤0.

50
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Explicit Euler applied to the scalar model problem gives the following recursion
formula (see Exercise 3.3.3):
uk = uk−1 + h𝜆uk−1 = (1 + h𝜆)uk−1 = (1 + h𝜆)2uk−2 = · · · = (1 + h𝜆)ku0
The uk-sequence is numerically stable (bounded) if
|1 + h𝜆| ≤1
(3.17)
If 𝜆is real and negative, the inequality can be written:
−1 ≤1 + h𝜆≤1 ⇒h ≤2
−𝜆= 2
|𝜆| = hmax
(3.18)
If 𝜆is a complex number, the geometrical correspondence to the inequality (3.17)
is a disc in the complex h𝜆-plane with radius 1 and center in h𝜆= −1. We denote
this region in the complex h𝜆-plane by SEE, the stability region for Euler’s explicit
formula (Figure 3.6).
Hence, Euler’s explicit method gives stable solutions to the scalar model problem
if
h𝜆∈SEE
(3.19)
It is important at this stage to observe and understand the difference between analytic
stability and numerical stability of the model problem ̇u = 𝜆u.
0
1
2
3
−1
−2
−3
−4
−5
Re (hλ)
0
1
2
3
−1
−2
−3
Im (hλ)
SEE
Figure 3.6
Stability region of Euler’s explicit method

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
51
• Analytic stability applies to the differential equation ̇u = 𝜆u and the stability
criterion is formulated for 𝜆only: Re(𝜆) ≤0.
• Numerical stability applies to the difference equation obtained with the
method, i.e., for explicit Euler uk = uk−1 + h𝜆uk−1 and the stability criterion is
formulated for the product h𝜆as follows: h𝜆∈SEE. Observe that if Re(𝜆) > 0,
the analytic solution of the model problem is unstable and the solution is
unbounded as t →∞. In this case, the explicit Euler method also gives
unbounded numerical solutions as h𝜆is situated in the right half plane.
For an LCC system of ODEs
du
dt = Au,
u(0) = u0
we know that the analytic solution is stable for t ≥0 if Re(𝜆i) ≤0 (assuming there
are no multiple eigenvalues with Re(𝜆i) = 0).
Applying the explicit Euler method to this system gives as numerical solution a
vector sequence uk:
uk = uk−1 + hAuk−1 = (I + hA)uk−1
(3.20)
The discussion of numerical stability is easier if we assume that the matrix A is diag-
onalizable, i.e.,
A = SΛS−1
or
S−1AS = Λ
where the columns of S are the eigenvectors of A and Λ is a diagonal matrix with the
eigenvalues of A in the diagonal, see Section 2.2.
Define another vector sequence zk through the relation uk = Szk. Insert this into
(3.20):
Szk = Szk−1 + hASzk−1
(3.21)
Multiply both sides by S−1
zk = zk−1 + hS−1ASzk−1 = (I + hΛ)zk−1
(3.22)
In the sequence (3.22) of vectors zk, the ith component z(i)
k is uncoupled from the
other components as I + hΛ is diagonal
z(i)
k = (1 + h𝜆i)z(i)
k−1
(3.23)
Hence, the stability criterion for the explicit Euler solution is the same as for the scalar
model equation:
|1 + h𝜆i| ≤1,
i = 1, 2, … , n
(3.24)

52
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
The geometrical interpretation of these inequalities is that all products h𝜆i must be
situated in the stability region SEE, i.e.,
h𝜆i ∈SEE,
i = 1, 2, … , n
(3.25)
In the special case that all 𝜆i are real and 𝜆n ≤𝜆n−1 ≤· · · ≤𝜆1 < 0, we get the
stability condition:
h ≤
2
|𝜆n| = hmax
(3.26)
i.e., the stepsize must be adjusted to the fastest timescale of the system. This may
seem contradictory: The fastest component e𝜆nt decreases very quickly to zero and
its value is very soon completely negligible. All the same, this component puts the
severest restriction to the stepsize!
For a nonlinear autonomous system of ODEs
du
dt = f(u),
u(0) = u0
the numerical stability analysis can be performed in a small neighborhood of a point
(a, b) on a solution trajectory (t, u(t)). We want to see how stepsizes can be chosen
at this point. To apply the results from the previous LCC problem, approximate the
nonlinear ODE system with an LCC system of ODEs. Let u = b + 𝛿u, where 𝛿u(t)
is a perturbation function. Insert this u into the ODE:
d𝛿u
dt
= f(b + 𝛿u) = f(b) + 𝜕f
𝜕u(b)𝛿u + hot
(3.27)
Denote f(b) by c and the jacobian evaluated at b by J. If higher order terms are
neglected, the system of ODEs for the perturbation can be written
d𝛿u
dt
= J𝛿u + c
(3.28)
The constant c does not affect the stability analysis (see Exercise 3.3.10). Therefore,
we have the (approximate) result that the explicit Euler method is stable if
h𝜆i(J) ∈SEE
(3.29)
Let us test this result on Robertson’s problem introduced in the beginning of this
section. The jacobian of the system is
J =
⎛
⎜
⎜⎝
−k1
k2u3
k2u2
k1
−k2u3 −2k3u2
−k2u2
0
2k3u2
0
⎞
⎟
⎟⎠

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
53
TABLE 3.4
Eigenvalues of the Jacobian of (3.15)
Along the Solution Trajectory
t
𝜆1
𝜆2
𝜆3
1
0
−0.16
−1090
10
0
−0.06
−1210
100
0
−0.008
−1950
1000
0
−0.0004
−3670
From the solution trajectory, we choose the solution points u(1), u(10), u(100), and
u(1000) and compute the eigenvalues of the jacobian in these points. The result is
shown in Table 3.4.
As all eigenvalues are real and nonpositive, the stability criterion (3.26) applies, so
we concludethat a maximal stepsize hmax for Euler’s explicit method would be hmax =
2∕3670 ≈5⋅10−4 for this problem in accordance with the numerical experiment in
the beginningof this section. Using an adaptive variant of the method will not increase
the efficiency as the stepsize must be kept very small on the whole time interval.
Robertson’s problem is an example of a stiff ODE system. Such a system is char-
acterized by the location in the complex plane of the eigenvalues 𝜆i, i = 1, 2, … , n
of the jacobian. The system is stiff if
• 𝜆i are situated in the left half complex plane, i.e., Re(𝜆i) ≤0.
• Re(𝜆i) are of very different size, i.e., the system contains time constants of
widely varying sizes.
The conclusion is that Euler’s explicit method is not suited for stiff ODE problems.
Exercise 3.3.9. Show the instability of explicit Euler in Example 1.1 by verifying
that the values h𝜆i are not inside the stability region of explicit Euler for the stepsize
used, h = 0.1. Which is the largest stepsize giving decreasing oscillations for this
problem?
Exercise 3.3.10. Verify that the constant vector c in (3.28) does not affect the sta-
bility analysis, i.e., the stability results are the same as for the homogeneous ODE
system. Hint: Let 𝛿v = 𝛿u + J−1c and formulate (3.28) for 𝛿v.
Exercise 3.3.11. Write a program to compute and plot the stability region SH for
Heun’s method presented in Exercise 3.3.7.
3.3.4
Euler’s Implicit Method
As Euler’s explicit method is very inefficient on stiff problems, the question is if there
are other methods that are better suited for these problems.
Apply Euler’s implicit method on the scalar model problem:
uk = uk−1 + h𝜆uk
(3.30)

54
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
0
1
2
3
−1
−2
−3
−4
−5
Re (hλ)
0
1
2
3
−1
−2
−3
Im (hλ)
SEI
Figure 3.7
Stability region for Euler’s implicit method
We solve this equation with respect to uk and obtain
uk =
1
1 −h𝜆uk−1
(3.31)
The sequence is stable if
|1 −h𝜆| ≥1
(3.32)
The stability region of the implicit Euler method is shown in the graph in Figure 3.7.
Hence, the stability region SEI consists of almost the whole complex plane; just
the interior of the disc with radius 1 and center in h𝜆= 1 is not in the stability region.
Therefore, the whole left half plane belongs to the stability region. This method is
appropriate for stiff systems as h𝜆i belongs to the stability region for all h > 0. Such
a method is called an A-stable method. However, Euler’s implicit method is only a
first-order method and will therefore be inefficient for accuracy reasons: the stepsize
h must be small in order to meet a certain error tolerance. In addition, there is another
price to pay. For a system of nonlinear ODEs, the following nonlinear algebraic sys-
tem of equations must be solved with respect to uk in every time step:
uk = uk−1 + hf(tk, uk)
(3.33)
This can be done with Newton’s method (see Section A.1), which, however,consumes
much computer time. An efficient method for stiff ODE systems must be based on
the following:

NUMERICAL SOLUTION OF IVPs WITH EULER’s METHOD
55
• an implicit higher order method,
• variable stepsize technique,
• use of the sparsity (see Section A.5) of the jacobian.
Exercise 3.3.12. Assume that Re(𝜆) > 0 in the scalar model problem, i.e., the ana-
lytical solution is unstable as t →∞. Find out if the numerical solution with implicit
Euler is unstable or stable for a fixed 𝜆-value as the stepsize h increases from zero to
larger values.
3.3.5
The Trapezoidal Method
The trapezoidal method can be regarded as a symmetric combination of Euler’s
explicit and implicit methods
uk = uk−1 + h
2(f(tk−1, uk−1) + f(tk, uk))
(3.34)
The trapezoidal method is a one-step implicit method and has Second-orderaccuracy:
ek = u(tk) −uk = O(h2)
The stability region STM of the trapezoidal method is exactly the left half part of the
complex plane (Figure 3.8).
0
1
2
3
−1
−2
−3
−4
−5
Re (hλ)
0
1
2
3
−1
−2
−3
Im (hλ)
STM
Figure 3.8
Stability region for the trapezoidal method

56
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
An advantage with the trapezoidal method is that the region of analytic stability
coincideswith STM. However,the solutions of the scalar modelequation obtained with
this method will contain oscillations that are damped out very slowly when 𝜆<< 0.
Therefore, the method is not recommended for very stiff problems, use instead BDF
methods (see Section 3.4.2).
Exercise 3.3.13. Write a program that visualizes the numerical solution of the
trapezoidal method applied to the scalar model equation for some negative values
of 𝜆.
3.4
HIGHER ORDER METHODS FOR THE IVP
3.4.1
Runge–Kutta Methods
The improved Euler method (see Section 3.3.2), also called Runge’s second- order
method, is an example from the Runge–Kutta family of methods (RK methods). The
most well-known member of this family is the classical RK4 method:
uk = uk−1 + h
6(k1 + 2k2 + 2k3 + k4)
(3.35)
tk = tk−1 + h,
i = 1, 2, … , N
where
k1 = f(tk−1, uk−1)
k2 = f(tk−1 + h∕2, uk−1 + hk1∕2)
k3 = f(tk−1 + h∕2, uk−1 + hk2∕2)
k4 = f(tk−1 + h, uk−1 + hk3)
Like Euler’s method, this is a one-step method, i.e., it is enough to know one point
(tk−1, uk−1) in order to compute the next point (tk, uk). The term (k1 + 2k2 + 2k3 +
k4)∕6 in (3.35) can be regarded as a weighted mean value of slopes evaluated in
four different points in order to obtain an accurate representation of the slope of the
solution between (tk−1, uk−1) and (tk, uk). The RK4 method is a fourth-order method,
i.e., the truncation error ek satisfies
ek = u(tk) −uk = O(h4)
(3.36)
Carl Runge and Wilhelm Kutta were German mathematicians active in the beginning
of the 20th century.
Applying the RK4 method to Van der Pol’s equation to compute y(1), just as we
did for Euler’s method, results in Table 3.5:

HIGHER ORDER METHODS FOR THE IVP
57
TABLE 3.5
Numerical Solution of Van der Pol’s Equation
Using the RK4 Method
N
h
u1,N
u1,N −y(1)
1
1
0.5052
0.0076
2
1∕2
0.4981
0.0005
4
1∕4
0.4976
<10−4
8
1∕8
0.4976
<10−4
0
1
2
3
−1
−2
−3
−4
−5
Re (hλ)
0
1
2
3
−1
−2
−3
Im (hλ)
SRK
Figure 3.9
Stability region for the RK4 method
Hence, we obtain four digit accuracy for N = 4, which is much more efficient than
the explicit Euler method.
Just like the explicit Euler method, the RK4 method has a certain stability region,
defined by applying the method to the scalar model equation. It is an algebraic
exercise to show that the stability region for the RK4 method satisfies the inequality
corresponding to the graph in Figure 3.9.
|1 + h𝜆+ h2𝜆2
2
+ h3𝜆3
6
+ h4𝜆4
24 | ≤1
(3.37)
As the stability region of RK4 is bounded and the order of accuracy is high, the
RK4 method is well suited for nonstiff problems.
A more general formula for an explicit RK method is given by the following
scheme of an s-stage RK method:
uk = uk−1 + h(b1k1 + b2k2 + · · · + bsks)
(3.38)

58
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
tk = tk−1 + h,
k = 1, 2, … , N
k1 = f(xk−1, uk−1)
k2 = f(xk−1 + c2h, uk−1 + ha21k1)
.........
ks = f(xk−1 + csh, uk−1 + h(as1k1 + as2k2 + · · · + ass−1ks−1))
In schematic form, the formula can be described by a matrix tableau, the Butcher
tableau, of the form
(
c
A
bT
)
=
⎛
⎜
⎜
⎜
⎜⎝
0
c2
a21
.
.
.
cs
as1
as2
…
ass−1
b1
b2
…
bs−1
bs
⎞
⎟
⎟
⎟
⎟⎠
(3.39)
The tableau (3.39) represents the formula for an explicit Runge–Kutta method. The
matrix A is then lower triangular. Implicit Runge–Kutta methods can also be defined.
In that case, the matrix A in the tableau is full.
John Butcher is a numerical analyst from New Zeeland still active.
With this formalism, the modified Euler method can be written as
⎛
⎜
⎜⎝
0
1∕2
1∕2
0
1
⎞
⎟
⎟⎠
and the RK4 method as
⎛
⎜
⎜
⎜
⎜⎝
0
1∕2
1∕2
1∕2
0
1∕2
1
0
0
1
1∕6
1∕3
1∕3
1∕6
⎞
⎟
⎟
⎟
⎟⎠
Adaptive methods can be constructed from embedded RK methods. An embedded
RK method uses the same c and A part of the matrix tableau but consists of two
different b vectors. The first one, denoted by b (giving a method of order p), is used
to compute the next value uk. The second one denoted ̂b (giving a method of order
p + 1) computes a ̂uk used just for error estimation:
⎛
⎜
⎜⎝
c
A
bT
̂bT
⎞
⎟
⎟⎠
=
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
c2
a21
.
.
.
cs
as1
as2
…
ass−1
b1
b2
…
bs−1
bs
̂b1
̂b2
…
̂bs−1
̂bs
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
(3.40)

HIGHER ORDER METHODS FOR THE IVP
59
Assume that the local error (see Section 3.3.1) of the method corresponding to b
satisfies
l(tk, h) ≈Chp+1
(3.41)
Assume also that ̂uk is much more accurate than uk, so that 𝛿= |̂uk −uk| is an estimate
of l(tk, h) for the step taken from tk−1 to tk.
If tol is a given error tolerancevalue for the absolute error,we can use the following
stepsize strategy when taking a step h from tk−1 to tk:
Algorithm 3.1. (Stepsize control)
1. accept the step (uk is accepted) if 𝛿≤tol
The new step hnext should satisfy tol = Chp+1
next, hence hnext = h( tol
𝛿)1∕(p+1).
2. reject the step (uk is rejected) if 𝛿> tol
Start again from tk−1 with the new stepsize hnew = h∕2, return to 1.
One well-known embedded Runge–Kutta method is the Bogacki–Shampine order 2/3
pair, used in, e.g., ode23 in the MATLAB-library
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
1∕2
1∕2
3∕4
0
3∕4
1
2∕9
3∕9
4∕9
0
2∕9
3∕9
4∕9
0
7∕24
6∕24
8∕24
3∕24
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
Here ̂b corresponds to a second-order method, while b is of order three.
Exercise 3.4.1. Formulate the RK method associated with the following tableau
⎛
⎜
⎜
⎜
⎜⎝
0
1
1
1∕2
1∕4
1∕4
1∕6
1∕6
4∕6
1∕2
1∕2
0
⎞
⎟
⎟
⎟
⎟⎠
Apply this method to the test problem ̇u = 𝜆u and deduce from that result the order
of the method giving the solution values and also the order of the method used for
error estimation.
Exercise 3.4.2. Show the inequality (3.37) for the stability of the RK4 method.
Exercise 3.4.3. Write a program for plotting the graph of the stability area of the
RK4 method.

60
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Exercise 3.4.4. Write a program for simulation of the particle motion problem
described in Example 2.3. Use the RK4 method with constant stepsize. The following
values of the model parameters can be used: g = 10 m∕s2, ‖v0‖ = 10 m∕s, y0 = 2 m,
c = 0.01 N⋅s2∕m, m = 1 kg, 𝛼= 20∘, and 𝛼= 60∘. Make a plot of the two particle
trajectories showing the motion from the initial point to the point where the particle
hits the ground.
3.4.2
Linear Multistep Methods
In linear multistep methods, information is used not only from the previous step
(tk−1, uk−1) but also from earlier steps (tk−2, uk−2), (tk−3, uk−3), ....., (tk−p, uk−p).
A simple example of a two-step method is the explicit midpoint method, also
known as the leap-frog method based on the central difference approximation (3.5)
{
uk = uk−2 + 2hf(tk−1, uk−1)
tk = tk−1 + h,
k = 2, 3, ... ,N
(3.42)
Inserting k = 2 in the formula, we see that the method is not self-starting, i.e., apart
from u0, the initial value, we also need a value of u1. This could be obtained, e.g.,
using the explicit Euler method, i.e., u1 = u0 + hf(t0, u0).
The midpoint method is a second-order method, but unfortunately it is not suited
for most kinds of IVPs (see, however, Section 3.5) which the following example
shows:
Example 3.6.
Consider the explicit midpoint method applied to the scalar model
problem. We get the difference equation:
uk = uk−2 + 2h𝜆uk−1,
u0 = 1,
u1 = 1 + h𝜆
The results for h = 0.1,𝜆= −1 and 𝜆= −2 are shown in the graphs in Figure 3.10.
The analytic solution is the smooth curve and the numerical solution is the oscil-
lating curve with increasing amplitude. This method is unstable regardless of the
stepsize h. It does not help to decrease the stepsize; the oscillations will occur sooner
or later. Hence, the explicit midpoint method is not suited for solving IVP in general
but can be designed to work for mechanical problems, see Section 3.5. The stability
region is derived in Section A.2.
The general definition of a linear p step method is
uk = 𝛼1uk−1 + 𝛼2uk−2 … 𝛼puk−p + h(𝛽0 fk + 𝛽1 fk−1 + … 𝛽p fk−p)
(3.43)
where fk = f(tk, uk). To start such a method, we need apart from u0 also u1, u2, ... up−1.
These values can be calculated with some one-step method, e.g., the RK4 method.
If 𝛽0 = 0 the method is explicit, if 𝛽0 ≠0 the method is implicit. Some well-known
classical multistep methods are, e.g.,

HIGHER ORDER METHODS FOR THE IVP
61
0
1
2
3
4
−0.5
0
0.5
1
0
1
2
3
4
−0.5
0
0.5
1
Figure 3.10
Numerical instability for the leap-frog method
• Adams–Bashforth (explicit):
uk = uk−1 + h
(
fk−1 + 1
2∇fk−1 + 5
12∇2fk−1 + …
)
(3.44)
• Adams–Moulton (implicit)
uk = uk−1 + h
(
fk + 1
2∇fk −1
12∇2fk + …
)
(3.45)
• Backward Differentiation Formulas (also called BDF-p or Gear’s method of
order p and well suited for stiff IVPs)
∇uk + 1
2∇2uk + · · · + 1
p∇puk = hfk,
p ≤6
(3.46)
where
∇fk = fk −fk−1
∇2fk = fk −2fk−1 + fk−2
(3.47)
∇3fk = fk −3fk−1 + 3fk−2 −fk−3
J. Adams was a British mathematician active in the middle of the 19th century.
F. Bashforth and F. Moulton were scientists active around 1900 and W. Gear is an
American numerical analyst who published his method around 1970.
Automatic stepsize control can be designed in a way similar to RK methods. For
linear multistep methods, the local error l(tk, h) (see Section 3.3.1) is estimated as
follows:
l(tk, h) = Cu(p+1)(tk)hp+1
(3.48)
where C is a known constant depending on the method. The derivative can be esti-
mated from some difference approximation, see Appendix A.3. As an example for

62
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Adams–Bashforth method, p = 1, (which is in fact explicit Euler) the local error is
estimated from
l(tk, h) = 1
2
∇2uk
h2 h2 = ∇2uk
2
(3.49)
and the algorithm for stepsize control now follows Algorithm 3.1.
Exercise 3.4.5. Present in the form (3.43), the first- and second-order methods of
Adams–Bashforth, Adams–Moulton, and Gear.
Exercise 3.4.6. Compute the stability region of BDF-2.
Exercise 3.4.7. Compute the solution of the ESCEP problem described in Example
2.6. Use BDF-2 with stepsize h = 0.01. (It is of course more effective to use variable
stepsize).
3.5
SPECIAL METHODS FOR SPECIAL PROBLEMS
In many physical and chemical problems, it is important in numerical simulations to
preserve certain invariants, such as the total energy, the total mass, and/or the positiv-
ity of the solution components. Many important classes of models possess invariants
that are linear and quadratic expressions in the solution components u1, u2, … un. In
numerical calculations, we cannot expect the invariants to be preserved exactly but
should be preserved to within rounding errors.
3.5.1
Preserving Linear and Quadratic Invariants
Linear invariants occurring, e.g., in the conservation of mass of a system, are pre-
served by most methods solving the IVP. For an ODE system, assume that a number
of linear relations are time invariant
du
dt = f(t, u), u(0) = u0,
Bu(t) = Bu0
where B is an m × n, m < n matrix. By differentiating the linear relation with respect
to t, we obtain
Bdu
dt = Bf(t, u) = 0
When using, e.g., explicit Euler, we get after multiplication by B
Buk = Buk−1 + hBf(tk−1, uk−1) = Buk−1 = … Bu1 = Bu0
Hence, the linear relations are preserved along the approximate solution trajectory
u1, u2, … un. It is easy to conclude the same property for, e.g., classical Runge–Kutta
methods and linear multistep methods. Observe that even if the components of the
solution vector u are computed with a global error of say 10−4, the computed linear
invariants will hold an accuracy on rounding error level, typically 10−15.

SPECIAL METHODS FOR SPECIAL PROBLEMS
63
Example 3.7.
In the biochemical system presented in Example 2.6, the matrix S
in the right hand side of the ODE system (2.59) has rank 2, hence there are two linear
relations between the rows of S, see Exercise 2.5.7.
Bf(c) =
(
1
0
1
0
0
1
1
1
) ⎛
⎜
⎜
⎜⎝
−1
1
1
−1
−1
1
0
0
1
−1
−1
1
0
0
1
−1
⎞
⎟
⎟
⎟⎠
r(c) = 0
for all vectors c, hence Bc = Bc0.
In general, quadratic invariants are not preserved,but there is one method, a variant
of the trapezoidal method, called the implicit midpoint method
uk = uk−1 + hf
(
tk−1 + h
2, uk−1 + uk
2
)
(3.50)
that preserves the relation uTCu = uT
0 Cu0, where C is a symmetric matrix. By time
differentiation of the quadratic relation and dividing by 2, we get
uTCdu
dt = uTCf(t, u) = 0
Multiply (3.50) first by uT
k−1C, then by uT
k C, add these two equalities and you find
that uT
k Cuk = uT
k−1Cuk−1, hence the quadratic relation is preserved.
Exercise 3.5.1. Given the parameter representation of a circle of radius 1
x = cos(𝜑),
y = sin(𝜑),
0 ≤𝜑≤2𝜋
and the corresponding ODE system where u1 = x and u2 = y.
du
d𝜑=
(0
−1
1
0
)
u,
u(0) =
(1
0
)
Write a program showing graphs of the phase portraits (u1, u2) obtained with the (i)
explicit Euler, (ii) implicit Euler, and (iii) implicit midpoint method. Conclude that
explicit Euler gives a growing spiral, implicit Euler gives a shrinking spiral, and the
implicit midpoint method gives an ellipse. Try also to verify this by mathematical
proofs.

64
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
3.5.2
Preserving Positivity of the Numerical Solution
In the numerical simulation of physical and chemical systems, there is a demand
for positivity for certain solution components. A concentration or a pressure, e.g.,
can never take negative values. Apart from being unphysical, negativity may also
make the ODE system unstable and totally ruin the whole solution. A simple remedy
would be, e.g., to set a negative concentration component to zero, which, however,
will destroy the mass balances (linear invariants) of the system.
Preserving numerical positivity when solving an ODE system with solution com-
ponents ui(t) > 0 as long as ui(0) ≥0 is harder. One way can be to utilize the special
form of the right hand side of the ODE system. As an example, take the system (2.49)
being a model for chemical kinetics. We can write this system in the alternative form
dc
dt = K(c)c,
c(0) = c0
(3.51)
where K(c) is an N × N matrix. Using implicit Euler on this usually stiff ODE system
gives the algebraic equation system
ck = ck−1 + hK(ck)ck →(I −hK(ck))ck = ck−1
For the special matrices K(c) occurring in chemical kinetics, it can be shown that
if ck−1 > 0 (all components of ck−1 are positive), the inverse of I −hK(ck−1) has all
elements positive, thus ck > 0, and positivity will be preserved if the initial value c0 is
nonnegative.Now, if the nonlinear equation system is solved with an iteration method
of type
(I −hK(c(i)
k ))c(i+1)
k
= ck−1
then positivity is preserved. On the other hand that iteration scheme does not give
quadratic convergence. Newton’s method (see Appendix A.1) does but will not
always produce positive iterates, at least not for chemical kinetics ODEs.
3.5.3
Methods for Newton’s Equations of Motion
For conservative mechanical systems, the total energy is preserved. One very impor-
tant application is molecular dynamics, where the physical movements of interacting
molecules are simulated by numerically solving Newton’s equation of motion (2.43).
The Hamiltonian (2.46) for such a system of n particles can be written as the sum of
the kinetic energy T and the potential energy U
H = T + U =
n
∑
i=1
‖pi‖2
2mi
−
n
∑
j=1,i≠j
𝛾mimj
‖ri −rj‖
(3.52)
Newton’s equation will be
mïri = −
∑
j=1,i≠j
𝛾mimj(ri −rj)
‖ri −rj‖3
,
i = 1, 2, … , n

SPECIAL METHODS FOR SPECIAL PROBLEMS
65
Another important application of a mechanical system is a system of masses and
springs introduced in (2.44) (with D𝜈= 0 and F = 0) and for which Newton’s
equations take the form
M̈x + Kx = 0,
x(0) = x0,
̇x(0) = v0
For this ODE system, the hamiltonian H (quadratic form) is invariant
H = 1
2 ̇xTM ̇x + 1
2xTKx
(3.53)
For Newton’s equation of motion, special numerical methods have been devel-
oped and much used, e.g., the leap-frog method and Verlet’s method, which are both
of second-order accuracy, but do not belong to the Runge–Kutta or linear multi-
step methods. One reason for using special methods for Newton’s equation is that
Runge–Kutta and linear multistep methods do not preserve the total energy of a con-
servative mechanical system but allow the energy to drift away from its constant value
as time increases. The Verlet method has its name from the French physicist Loup
Verlet, who rediscovered the method for computer simulation of molecular dynamics
in the 1960s.
If we write Newton’s equation of motion on scalar form as a first-order system
̇r = v,
r(0) = r0
̈r = a(r),
v(0) = v0
(3.54)
where a(r) depends only on the position r, Verlet’s method for the position and the
velocity is
{
vk = (rk+1 −rk−1)∕2h
rk+1 = 2rk −rk−1 + h2a(rk)
(3.55)
As is seen from (3.55), the derivative approximations are based on the symmetric
central difference formulas (3.8) and (4.24). The method has second-order accuracy.
It is also explicit and needs only one evaluation of the right hand side function a(r)
per time step. If just the positions r0, r1, … rk, ... are wanted only the second of the
two formulas are needed. This method also goes under the name Störmer’s method,
after the Norwegian mathematician Carl Störmer, active in the first part of the 20th
century.
Verlet’s method is not self-starting meaning that the initial conditions r0 = r(0)
and v0 = v(0) are not enough to start the recursion. Here r1 is also needed and can be
computed from some approximation of the first step taken, e.g.,
r1 = r0 + hv0 + h2
2 a(r0)
(3.56)
The order of computation will then be r0, v0, r1, r2, v1,r3,v2, etc.

66
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
νk–1
rk
rk+2
rk+4
νk+1
νk+3
tk–1
tk
tk+2
tk+4
tk+1
tk+3
Figure 3.11
Steps taken by different variables on a staggered grid
The leap-frog method is based on the following representation of Newton’s
equations of motion: ̇v = a(r),
v(0) = v0,
r = v,
r(0) = r0
{
vk+1 = vk−1 + 2ha(rk)
rk+2 = rk + 2hvk+1
(3.57a)
which can also be written with midpoint values
{
vk+1∕2 = vk−1∕2 + ha(rk)
rk+1 = rk + hvk+1∕2
(3.57b)
This method is also based on the symmetric approximation of the derivatives. It has a
strong resemblance with the Euler–Cromer method (see Exercise 3.3.4), which, how-
ever, is based on the Euler forward approximation giving only first- order accuracy,
while the leap-frog method is of second order. In the beginning of Section 3.4.2, the
leap-frog method was tested on the scalar model problem ̇u = 𝜆u and found to be
useless when, e.g., 𝜆= −1. However, for hamiltonian systems in mechanics, it turns
out to be both effective and reliable, just like Verlet’s method. Here we also need a
way to start the method, e.g., with (3.56). The order of computation will be r0, v0,
r1, v2, r3, v4, r5, etc. From this sequence and Figure 3.11, we see that velocities v
are evaluated at a grid staggered with respect to the positions r. In general, a stag-
gered grid method means that different variables are computed on different grids, see
further Section 8.2.7.
3.6
THE VARIATIONAL EQUATION AND PARAMETER FITTING
IN IVPs
The variational equation (VE) was introduced in Chapter 2 as a tool for analytic sta-
bility analysis of solution curves and critical points. The aim was to see if a perturbed
curve in the neighborhood of a given solution trajectory will converge to the given
curve. Hence, analytical stability is investigated by perturbing the initial values in the
problem (see Section 2.3.1).

THE VARIATIONAL EQUATION AND PARAMETER FITTING IN IVPs
67
Another version of the VE occurs in sensitivity analysis, i.e., when we want to
compute how sensitive a solution is with respect to parameters in the right hand side.
Sensitivity analysis is based on the IVP formulation (3.2)
du
dt = f(t, u, p),
u(0) = u0(p)
(3.58)
To investigate the sensitivity, assume that the solution trajectory u(t, p) has been com-
puted for a given value of the parameter vector p and the task is to study a neighboring
solution trajectory u(t, p + 𝛿p). Taylor expansion gives
u(t, p + 𝛿p) = u(t, p) + 𝜕u
𝜕p(t, p)𝛿p + hot
(3.59)
Hence, we need the sensitivity matrix S(t, p) defined as
S(t, p) = 𝜕u
𝜕p
(3.60)
S(t, p) is obtained as the solution of the matrix differential equation derived by dif-
ferentiating (3.58) with respect to p:
dS
dt = 𝜕f
𝜕uS + 𝜕f
𝜕p,
S(0, p) = 𝜕u0
𝜕p
(3.61)
The sensitivity matrix can be used for parameter estimation. Assume we want to
fit the parameter vector p in (3.58) to measured data (tk, u∗
k), k = 1, 2, … , M of the
state variable u(t). The residual vector at each measurement point is defined as
rk = u(tk, p) −u∗
k ≈0,
k = 1, 2, … , M
Also define the global sensitivity matrix S(p), the global measurement vector u∗and
the global residual vector r(p) according to
S(p) =
⎛
⎜
⎜
⎜
⎜⎝
S(t1, p)
S(t2, p)
.
.
S(tM, p)
⎞
⎟
⎟
⎟
⎟⎠
,
u∗=
⎛
⎜
⎜
⎜
⎜
⎜⎝
u∗
1
u∗
2
.
.
u∗
M
⎞
⎟
⎟
⎟
⎟
⎟⎠
,
r =
⎛
⎜
⎜
⎜
⎜⎝
r1
r2
.
.
rM
⎞
⎟
⎟
⎟
⎟⎠
Gauss–Newton’s method can be used (see Section A.1). Assume p(i) is an iterate in a
sequence p(0), p(1), … , p(i). Given a start parameter vector p(0), iterate according to
{
S(p(i))𝛿p(i) = −r(i)
p(i+1) = p(i) + 𝛿p(i)
until the correction ‖𝛿p(i)‖ is small enough.

68
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Example 3.8.
Consider the following system of ODEs containing three parame-
ters k1, k2, and k3:
dy1
dt = k1y1 −k2y1y2,
y1(0) = 1.0
dy2
dt = k2y1y2 −k3y2,
y2(0) = 0.3
Assume we have measurements of y1 and y2 according to the matrix
Ymsr =
( 1
1.1
1.3
1.1
0.9
0.7
0.5
0.6
0.7
0.8
1
0.3
0.35
0.4
0.5
0.5
0.4
0.3
0.25
0.25
0.3
0.35
)
at time points tk = k⋅0.5, k = 0, 1, 2, … 10. We want to estimate the unknown param-
eters k1, k2, and k3 from the measurements using the algorithm described in Section
3.6. For that we need the following jacobians:
J(y) =
(
k1 −k2y2
−k2y1
k2y2
k2y1 −k3
)
,
𝜕f
𝜕p =
(
y1
−y1y2
0
0
y1y2
−y2
)
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0
0.5
1
1.5
2
2.5
Solution for initial values k0
Time t
y (t, k0) and ymeasured
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
y (t, kest) and ymeasured
Time t
Solution for final values kest
Figure 3.12
Measurements and solution curves before and after the Gauss–Newton method

BIBLIOGRAPHY
69
The initial guess for the parameter vector is k0 = (1, 1, 1)T. After a few iterations
with the Gauss–Newton method, the iterations have converged (Figure 3.12) to
kest = (0.86, 2.08, 1.81).
BIBLIOGRAPHY
1. G. Dahlquist, Å. Björck, “Numerical Methods”, Chapter 8, Dover, 2003
2. G. Golub, J. Ortega, “Scientific Computing and Differential Equations”, Chapter 2,
Academic Press, 1992
3. C. Moler, “Numerical Computing with MATLAB”, Chapter 7, SIAM, 2004
A textbook with many physical applications
4. A.L. Garcia, “Numerical Methods for Physics”, 2nd ed, chapter 2-3, Prentice Hall, 2000
Extensive treatment of the IVP is found in the textbooks
5. U. Ascher, L. Petzold, “Computer Methods for ODEs and DAEs”, SIAM, 1998
6. J.C. Butcher, “Numerical Methods for Ordinary Differential Equations”, Wiley, 2003
7. E. Hairer, S. Nörset, G. Wanner, “Solving Ordinary Differential Equations I: Non-stiff
problems”, Springer 2009
8. E. Hairer, G. Wanner, “Solving Ordinary Differential Equations II: Stiff and
Differential-Algebraic Problems”, Springer 2010
9. A. Iserles, “A First Course in the Numerical Analysis of Differential Equations”, Cam-
bridge University Press, 1996
10. L. Shampine, “Numerical Solution of ODEs”, Chapman and Hall, 1994


4
NUMERICAL METHODS FOR
BOUNDARY VALUE PROBLEMS
In this chapter, numerical methods for boundary value problems (BVPs) are
described. Most of the methods are presented for second-order ordinary differential
equations (ODEs) as such problems are very common in applications. However,
generalization to higher order ODEs and other types of BVP formulations are also
presented in various application problems. The independent variable is changed
from t to x, as many BVPs are formulated for 1D space-dependent problems.
A nonlinear second-order ODE
d2u
dx2 = f
(
x, u, du
dx
)
(4.1)
has a general solution that depends on two arbitrary constants C1 and C2
u = u(x, C1, C2)
(4.2)
In general, we cannot find the analytic solution. Hence, there is no explicit expres-
sion of the solution in the form (4.2) in which values of the constants C1 and C2
can be inserted. To obtain a unique solution, we therefore need two conditions. In
Chapter 3, these conditions were given as initial conditions. In this chapter, we show
how appropriate boundary conditions (BCs) define a solution that can be computed
approximately with numerical methods.
Just like an initial value problem (IVP), a BVP usually contains a number of
parameters occurring both in the right hand side function f(x, u, u′) and/or in the BCs.
As a consequence, parameter studies are needed for BVPs, too. Hence, it is necessary
to have accurate, efficient, and robust methods.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

72
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
In case the ODE is linear, e.g.,
d2u
dx2 + a(x)du
dx + b(x)u = c(x)
(4.3)
the arbitrary constants C1 and C2 enter linearly in the general solution
u(x) = upart(x) + C1Φ1(x) + C2Φ2(x)
where upart(x) is a particular solution and Φ1(x), Φ2(x) are two linearly independent
solutions of the homogeneous ODE (the ODE with c(x) ≡0). However, even for lin-
ear problems of type (4.3), analytic solutions cannot be found in general.
BCs can be formulated in various ways. As was stated in Chapter 2, a unique
solution is determined by specifying initial conditions which can be regarded as a
special case of BCs. An initial value formulation of (4.1) is obtained by rewriting the
second-order ODE as a system of two first-order ODEs (see Section 2.1) and then
selecting two initial values u(x0) and u′(x0). Let y1 = u and y2 = u′
dy1
dx = y2,
y1(x0) = u(x0)
(4.4a)
dy2
dx = f(x, y1, y2),
y2(x0) = u′(x0)
(4.4b)
Frequent forms of BCs to a second-order ODE are named after Peter Dirichlet and
Carl Neumann, German mathematicians active in the middle of the 19th century.
1. Dirichlet’s BC specifies the solution u(x) at an endpoint of an x interval (a, b),
say
u(a) = ua
and/or
u(b) = ub
(4.5)
where ua and/or ub are known values.
2. Neumann’s BC specifies the derivative u′(x) at an endpoint
du
dx(a) = u′
a
and/or
du
dx(b) = u′
b
(4.6)
where u′
a and/or u′
b are known values.
3. Robin’s BC or mixed BC or generalized Neumann’s BC specifies a linear com-
bination of u(x) and u′(x) at an endpoint, e.g.,
du
dx(a) = 𝛼1u(a) + 𝛽1
and/or
du
dx(b) = 𝛼2u(b) + 𝛽2
(4.7)
where 𝛼1, 𝛼2, 𝛽1, and/or 𝛽2 are known values.

APPLICATIONS
73
Any combination of two of the BCs (4.5), (4.6), and (4.7) can be given as BCs
to (4.1). They can be compactly written in the form
𝛾1
du
dx(a) = 𝛼1u(a) + 𝛽1,
𝛾2
du
dx(b) = 𝛼2u(b) + 𝛽2
(4.8)
where the parameters 𝛾i, 𝛼i, and 𝛽i, i = 1, 2, 3 are chosen appropriately.The BCs (4.8)
are linear.
Yet another type of BC is a periodic BC that is formulated when the solution is to
be continued periodically outside the interval (a, b), e.g.,
u(a) = u(b),
du
dx(a) = du
dx(b)
(4.9)
4.1
APPLICATIONS
To illustrate various formulations of BVPs, a number of application problems are
presented in the examples below. Some of them are solved numerically later in this
chapter. The mathematical modeling background to some examples is presented in
Chapter 9.
Example 4.1. (Stationary flow of a hot fluid in a pipe).
Consider a pipe of length L (m) with a cylindrical cross section of radius R (m).
A hot fluid is transported through the pipe. Exchange of heat with the environment
takes place through the wall of the pipe (Figure 4.1). This process can be modeled
with the following BVP:
−d
dz
(
𝜅dT
dz
)
+ 𝜌CvdT
dz + 2h
R (T −Tout) = 0,
0 < z < L
(4.10a)
T(0) = T0,
−𝜅dT
dz (L) = k(T(L) −Tout)
(4.10b)
This BVP is a model of the thermal energy balance of the fluid in the pipe. In
Chapter 9, Example 9.6, this ODE is derived from physical assumptions, where the
three terms in the ODE (4.10a) represent, respectively,
1. heat conduction,
2. heat convection, and
3. heat loss through the wall.
0
L
z
υ
T (z)
T0
Tout
Figure 4.1
Steady heat transport by a fluid through a pipe

74
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
There can also be terms modeling heat sources. Such a term is represented in (4.10a)
as a source term f(T) in the ODE.
The BCs (4.10b) correspond to constant temperature T0 at the inlet of the pipe and,
at the outlet, heat flux is proportional to the difference between the fluid temperature
at the outlet T(L) and the ambient temperature Tout.
In (4.10), z (m) is the length coordinate, T = T(z) (K) the temperature along the
pipe, 𝜅[ J∕( K⋅m⋅s)] the heat conduction coefficient of the fluid, v (m/s) the flow
velocity, 𝜌( kg∕m3) the density of the fluid, C [ J∕( K⋅kg)] the heat capacity, and
h and k [ J∕( K⋅m2 ⋅s)] are the heat transfer coefficients between the fluid and the
environment. Here, h is associated with heat loss through the wall of the pipe and k
with the heat transfer at the right end. T0 (K) is the inlet temperature, Tout (K) is the
ambient temperature at the wall and outside the endpoint at z = L. If all parameters
L, R, 𝜅, 𝜌, C, v, h, k, Tout, and T0 in the model (4.10) are constant, the BVP is linear
with constant coefficients. Even for this simple problem, there are as many as 10
parameters of which the solution T(z) is dependent. In Chapter 9, it is shown how a
scaling procedure will reduce the number of parameters to 3.
A nonlinear formulation of the ODE is obtained if some of the parameters, e.g.,
𝜅, are temperature dependent, i.e., 𝜅= 𝜅(T).
The nonlinearity may also occur in a BC, e.g., as a radiation formulation at the
right endpoint
−𝜅dT
dz (L) = 𝜎(T(L)4 −T4
out)
where 𝜎[ J∕( K4 ⋅m2 ⋅s)] is the heat transfer coefficient for radiation.
Note that this problem will appear in other variants of the model in Chapters 6,
7, and 9.
Example 4.2. (Concentration profile in a spherical catalyst particle).
In a spherical porous catalyst particle with radius R (m), the concentration c(r)
( mol∕m3) of a substance diffusing into the particle where it reacts with the catalyst
is modeled by the BVP
D
(
d2c
dr2 + 2
r
dc
dr
)
= kc p,
0 < r < R
(4.11a)
dc
dr (0) = 0,
c(R) = c0
(4.11b)
where D ( m2∕s) is the diffusion coefficient, kcp [mol∕( m3 ⋅s)] the rate expression
of the chemical reaction, and c0 ( mol∕m3) the concentration of the substance on the
surface of the particle (see Figure 4.2). In the rate expression, k is the rate constant
and p, a positive integer, is the order of the reaction. Observe that the ODE is not
defined at r = 0. The form of the ODE valid at this particular point can be derived
with l’Hopital’s rule (see Exercise 2.1.6 in Chapter 2).

APPLICATIONS
75
0
r
R
c0
c (r)
Figure 4.2
Concentration profile in a spherical catalyst particle
Higher order BVPs are also common in applications. A fourth-order ODE
describes transversal bending of an elastic beam.
Example 4.3. (Transversally loaded beam).
The transversal deformation u(x) (m) of a beam of length L (m) can be modeled by
the ODE
d2
dx2
(
EI(x)d2u
dx2
)
= f(x),
0 < x < L
(4.12a)
where E ( N∕m2] is the elasticity module, I(x) ( m4) the cross section moment of
inertia, and f(x) (N/m) the load acting transversally on the beam (Figure 4.3). For
this ODE, four BCs are needed to specify a unique solution, e.g.,
u(0) = 0,
du
dx(0) = 0,
d2u
dx2 (L) = 0,
d3u
dx3 (L) = 0
(4.12b)
BVPs can also be formulated as systems of ODEs of first order, e.g.,
du
dx = f(x, u, v),
u(a) = ua
(4.13)
dv
dx = g(x, u, v),
v(b) = vb
0
L
x
f (x)
Figure 4.3
Displacement of a loaded beam

76
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Example 4.4. (Counterflow heat exchanger).
Consider a heat exchanger consisting of two pipes of length L (m) exchanging energy
and with counterflow streams of hot and cold water
uH
dH
dx = −a(H −C),
H(0) = H0,
0 < x < L
(4.14a)
−uC
dC
dx = a(H −C),
C(L) = C0
(4.14b)
where H (K) is the temperature of the hot water, C (K) the temperature of the cold
water, uH and uC (m/s) the fluid velocities, and a (1/s) a temperature transfer coeffi-
cient describing the heat flow between the two pipes (Figure 4.4).
0
L
x
H0
C0
C (x)
H (x)
uC
uH
Figure 4.4
Counter flow heat exchange
A general formulation of a two-point BVP is
du
dx = f(x, u),
g(u(a), u(b)) = 0
(4.15a)
Often in applications g is linear, in which case the BCs can be written:
B0u(a) + B1u(b) = b
(4.15b)
Example 4.5. (Blasius’ boundary layer equation in fluid dynamics).
The nonlinear third-order ODE
2 d3f
d𝜂3 + f d2f
d𝜂2 = 0,
0 < 𝜂< ∞
(4.16a)
with BCs
f(0) = 0,
df
d𝜂(0) = 0,
df
d𝜂(∞) = 1
(4.16b)
is a classical problem in fluid dynamics.
From the solution f(𝜂), the velocity components u(x, y) (m/s) and v(x, y) (m/s) of
the stream close to a plane wall (see Figure 4.5) can be computed:
u(x, y) = u∞
df
d𝜂(𝜂),
v(x, y) =
√𝜈u∞
4x (𝜂df
d𝜂(𝜂) −f(𝜂)),
𝜂= y
√u∞
𝜈x

APPLICATIONS
77
x
y
u0
υ (x, y)
u (x, y)
Figure 4.5
Blasius’ boundary layer flow
where u∞(m/s) is the free stream velocity far from the wall and 𝜈(m2∕s) is the
kinematic viscosity. Observe that one of the BCs is given at 𝜂= ∞.
As was pointed out at the end of Section 2.1, uniqueness of a solution to a BVP
is more complicated than for an IVP. The following two examples show what can
happen.
Example 4.6. (An eigenvalue problem).
The eigenfrequencies of a circular membrane are the frequencies for which the mem-
brane can oscillate without the influence of external forces. The fundamental model
for an oscillatory system is the wave equation (see Section 5.1)
𝜕2u
𝜕t2 = c2
(
𝜕2u
𝜕x2 + 𝜕2u
𝜕y2
)
where u (m) is the deflection of the membrane, t (s) time, and c (m/s) the velocity of
the wave.
We look at time harmonic solutions of angular frequency 𝜔,
u(x, y, t) = ei𝜔tv(x, y)
Insert into the wave equation to obtain the Helmholtz equation
c2
(
𝜕2v
𝜕x2 + 𝜕2v
𝜕y2
)
+ 𝜔2v = 0
(4.17)
Now let the membrane be fixed along the boundary of the circle. We wish to find
values of 𝜔such that the BVP with homogeneous BC v = 0 on the boundary has
nontrivial solutions. This is an eigenvalue problem for the Laplace equation, see also
Problem (5) in Section 5.1. Hermann von Helmholtz was a German scientist active
around the end of the 19th century.
For a circular membrane of radius R (m), use polar coordinates (r, 𝜑). Assume
there is no angular dependence and we obtain the BVP
−1
r
d
dr
(
rdv
dr
)
= 𝜆v,
dv
dr (0) = 0, v(R) = 0
(4.18)

78
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
The first eigenfunctions of the membrane problem
r
v(r)
Figure 4.6
Some eigensolutions of the circular membrane problem
where 𝜆= (𝜔∕c)2. This BVP has infinitely many solutions, see Figure 4.6 for the
eigenfunctions corresponding to the smallest eigenvalues.
Example 4.7. (A nonlinear BVP with two solutions).
Another example of a BVP not having a unique solution is
u′′ + eu+1 = 0,
u(0) = u(1) = 0,
0 < x < 1
(4.19)
This problem has exactly two solutions, plotted in the graph in Figure 4.7.
The two Examples 4.6 and 4.7 show that the question of uniqueness of a solution
to a BVP is not as transparent as for an IVP.
4.2
DIFFERENCE METHODS FOR BVPs
The numerical way of treating a BVP is different from the way of solving an IVP.
An IVP is solved with a marching technique starting from given initial values, then
proceeding step by step forward until the final time point is reached.
In a BVP, there are not enough initial values to start the marching technique.
Instead, in the discretization of a BVP, a matching technique leads to coupled alge-
braic equations. Hence, a finite difference method (FDM) for numerical solution of a
BVP transforms the ODE problem into a system of algebraic equations. The system

DIFFERENCE METHODS FOR BVPs
79
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.5
1
1.5
2
2.5
The 2 solutions of d2u/dx2 + exp (u + 1) = 0, u(0) = u(1) = 0
x
u
Figure 4.7
Example showing non-uniqueness for a BVP
will be linear or nonlinear depending on whether the BVP is linear or nonlinear. The
algebraic equations will generally be sparse and should therefore be solved by sparse
direct methods or by iterative methods (see Section A.5).
4.2.1
A Model Problem for BVPs, Dirichlet’s BCs
As a model problem for numerical solution of a BVP, we take the elementary linear
problem
−d2u
dx2 = f(x),
0 < x < 1
(4.20a)
u(0) = 0,
u(1) = 0
(4.20b)
The general solution of the ODE is
u(x) = C1 + C2x −∫
x
0
F(s)ds
(4.21)
where C1 and C2 are arbitrary constants and F(s) = ∫s
0 f(t)dt. Integrating by parts
gives
∫
x
0
F(s)ds = [sF(s)]x
0 −∫
x
0
sF′(s)ds = ∫
x
0
(x −s)f(s)ds
Inserting the BCs (4.20b) gives
C1 = 0,
C2 = ∫
1
0
(1 −s)f(s)ds

80
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
and the solution can be written
u(x) = x ∫
1
0
(1 −s)f(s)ds −∫
x
0
(x −s)f(s)ds
(4.22a)
or
u(x) = ∫
1
0
G(x, s)f(s)ds
where
G(x, s) =
{
s(1 −x),
0 ≤s ≤x
x(1 −s),
x ≤s ≤1
(4.22b)
G(x, s) is called the Green’s function after the British mathematician George Green
active in the beginning of the 19th century (Figure 4.8).
Observe that if f(x) ≥0, 0 ≤x ≤1, then the solution u(x) ≥0.
The principleof the FDM (see Section 3.2) is to discretize the continuousvariablex
and to replace the derivatives by difference approximations. The following algorithm
transforms the ODE problem into an algebraic system of equations:
DG = Discretize the interval to a Grid,
DD = Discretize the Differential equation,
DB = Discretize the BCs.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.05
0.1
0.15
0.2
0.25
Example of Green functions
s
G
G(0.4, s) −>
<− G(0.7, s)
Figure 4.8
Green’s function for the model problem

DIFFERENCE METHODS FOR BVPs
81
This algorithm is now illustrated on the model problem (4.20).
DG—discretize the x interval and introduce a numbering of the grid points:
0
h
1
x0
x1
xi – 1
xi
xN
xN + 1
x
We call this basic grid G. If the stepsize h is constant, then the discretization above
gives the following relation between h and N, the number of inner points in the
interval [0, 1]:
h(N + 1) = 1
DD—choose difference approximations for the derivatives. In Chapter 3, we have
already introduced a second-order formula for the first derivative, the central
difference approximation:
du
dx(xi) = u(xi+1) −u(xi−1)
2h
+ O(h2)
(4.23)
For the second derivative, there is a similar second-order formula:
d2u
dx2 (xi) = u(xi+1) −2u(xi) + u(xi−1)
h2
+ O(h2)
(4.24)
Use (4.24) to discretize (4.20a) at an arbitrary inner gridpoint xi:
−ui+1 −2ui + ui−1
h2
= f(xi)
(4.25)
This relation is valid at all the inner points, i.e., i = 1, 2, … , N.
DB—as u is given at the two endpoints also being gridpoints, the Dirichlet BCs
(4.20b) can be represented exactly:
u0 = 0,
uN+1 = 0
(4.26)
The BCs (4.26) are inserted into the first and last equation of (4.25). The result
of the whole discretization procedure is the following system of N unknowns
u1, u2, … , uN and N equations:
−u2 −2u1
h2
= f(x1)
−ui+1 −2ui + ui−1
h2
= f(xi),
i = 2, 3, … , N −1
(4.27)
−−2uN + uN−1
h2
= f(xN)

82
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
The system is written in matrix form:
Au = f
(4.28)
where
A =
⎛
⎜
⎜
⎜
⎜⎝
2 −1
0
0
…
−1
2
−1
0
…
…
…
0
−1
2
−1
…
0
0
−1
2
⎞
⎟
⎟
⎟
⎟⎠
,
f = h2
⎛
⎜
⎜
⎜
⎜⎝
f(x1)
f(x2)
.
f(xN−1)
f(xN)
⎞
⎟
⎟
⎟
⎟⎠
(4.29)
The N × N matrix A is symmetric, positive definite, and tridiagonal. This will not be
the case for BVPs in general; the matrix can be both unsymmetric and have another
structure than tridiagonal. In most cases, however, the matrix has some banded struc-
ture. A in (4.29) can also be written A = tridiag(−1, 2, −1).
The matrix A in (4.29)plays an importantrole forinsight into the numericalproper-
ties of methods for both ODEs and partial differential equations (PDEs). In particular,
the eigenvalues 𝜆j are important. They can be computed exactly (see Section A.2):
𝜆j = 4 sin2
(
𝜋j
2(N + 1)
)
,
j = 1, 2, … , N
(4.30)
We see that all eigenvalues are positive and that
𝜆min ≈𝜋2∕(N + 1)2,
𝜆max ≈4
(4.31)
It can be shown that A−1 has only positive elements. Hence, if f(x) ≥0 on the inter-
val
0 ≤x ≤1, then the discrete solution u will be positive just as the analytic
solution (4.22a).
The tridiagonality of A can be utilized computationally in two ways:
• Computer storage: if only the nonzero diagonals of A are stored, much less
storage is needed than storing a full matrix.
• Computer time: the number of floating point operations (flops) needed to solve
Au = b is much less for a tridiagonal matrix than for a full matrix.
In fact, if A is treated as a full matrix, N2 elements must be stored, while if A is stored
in a sparse way, only 3N −2 elements need to be stored. In addition, if A is treated
as a full matrix, Gaussian elimination needs about N3∕3 flops to solve Au = b, while
a tridiagonal version needs only about 5N flops (see Section A.5).
These observations concerning computing efficiency for 1D problems become
more important when solving BVPs in 2D or 3D (see Chapter 7).
As the accuracy of the difference approximation(4.24) is of second order, it should
be expected that the accuracy of the numerical solution ui = ui(h) also is of second
order. The following numerical experimentverifies this statement. For a mathematical
proof, see Section 4.2.3.

DIFFERENCE METHODS FOR BVPs
83
TABLE 4.1
Numerical Solution of (4.20) Using
Central Difference Approximations
N
h
ui(h), x = 0.5
e(h)
3
1∕4
0.1067
5.37⋅10−3
7
1∕8
0.1026
1.31⋅10−3
15
1∕16
0.1017
3.26⋅10−4
31
1∕32
0.1014
8.14⋅10−5
63
1∕64
0.1013
2.03⋅10−5
127
1∕128
0.1013
5.09⋅10−6
Example 4.8.
The following numerical experiment verifies that the discretization
of (4.20) gives second-order approximation to the solution. With f(x) = sin(𝜋x), the
analytic solution is u(x) = sin(𝜋x)∕𝜋2. The following result was obtained for con-
stant stepsizes h = 1∕2, 1∕4, 1∕8,.... In Table 4.1, the truncation error e(h) = ui(h) −
u(xi) at the point xi = 0.5 for the different stepsizes is shown. A loglog graph of e(xi)
as function of h shows that the order of accuracy is two.
Exercise 4.2.1. Calculate the matrix A and the vector b in the case that the stepsize
hi = xi+1 −xi is not constant. All approximationsshould have second-order accuracy.
4.2.2
A Model Problem for BVPs, Mixed BCs
What modifications must be made if the BCs in (4.20) are changed? We illustrate by
treating the following BVP:
−d2u
dx2 = f(x),
0 < x < 1
du
dx(0) = 0, −du
dx(1) = u(1) −1
(4.32)
Introduce an equidistant grid with the following numbering of the points:
0
h
1
x1
x2
xi − 1
xi
xN
xN − 1
x
We call this grid G0. Use Euler’s method to approximation to the BCs:
u2 −u1
h
= 0,
−uN −uN−1
h
= uN −1
(4.33)
The disadvantage with this discretization, however, is that the first-order approxima-
tions in the BCs will give only first-order accuracy in all points of the grid (although
the ODE is discretized to second order).
Exercise 4.2.2. Verify first-order accuracy at x = 0.5 of the problem given in (4.32)
when using the Euler approximations (4.33) in the BCs by writing a program similar
to the one in Example 4.8.

84
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
To obtain second-order accuracy, there are various possibilities:
G1—modify the grid and the indexing by incorporating two outer points
(ghost points) x0 = −h and xN+1 = 1 + h. The inner points are now
x1 = 0, x2 = h, … , xN = 1.
x0
x1
x2
0
h
1
xi − 1
xN − 1
xN
xN + 1
xi
x
G2—modify the grid so that an endpoint with a derivative condition is located
in the middle between two gridpoints. The Euler approximation u′(0) = (u1 −
u0)∕h is a symmetric approximationfor this grid and has thereforesecond-order
accuracy.
0
h
2
h
2
h
1
x0
x1
xi − 1
xi
xN
xN + 1
h
2
h
2
x
G3—use the original grid G0 but apply second-order unsymmetric difference
approximation for the BCs, e.g.,
du
dx(0) = −u(2h) + 4u(h) −3u(0)
2h
+ O(h2)
(4.34a)
and, at the other end of the interval,
du
dx(1) = 3u(1) −4u(1 −h) + u(1 −2h)
2h
+ O(h2)
(4.34b)
With this grid and these difference approximations, no points outside the inter-
val [0, 1] are needed. Hence, we can use the grid G0.
We illustrate a second-order method for solving (4.32) using the grid modification
G1 given above. Following the three steps DG,DD, and DB from above:
DG—use the grid G1, but observe that now h(N −1) = 1.
DD—the ODE is now valid also at the inner points x1 = 0 and xN = 1.
−ui+1 −2ui + ui−1
h2
= f(xi),
i = 1, 2, … , N
(4.35a)
DB—the BC approximations are
u2 −u0
2h
= 0,
−uN+1 −uN−1
2h
= uN −1
(4.35b)

DIFFERENCE METHODS FOR BVPs
85
Hence, we get N + 2 equations for the N + 2 unknowns, u0, u1, … , uN+1 and the
matrix A is modified to an (N + 2) × (N + 2) matrix. The system of equations is
A =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
1
0
−𝟏
0
…
−1
2
−1
0
…
0
−1
2
−1
…
…
0
−1
2
−1
…
0
−𝟏
2h
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
f = h2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
f(x1)
f(x2)
f(xN−1)
f(xN)
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
+ 2h
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
0
0
0
0
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
The matrix A corresponds to the difference approximations of u′ and u′′. The right
hand side vector f consists of one term originating from f(x) and the other term from
the BCs.
We see that the matrix is almost tridiagonal; the two boldface −𝟏elements in the
first and last row make the matrix pentadiagonal. However, by eliminating u0 and
uN+1, i.e., solving the first and last equation with respect to u0 and uN+1, respectively,
u0 = u2
uN+1 = uN−1 −2h(uN −1)
(4.36)
and inserting these expressions into the equations for i = 1 and i = N
−−2u1 + 2u2
h2
= f(x1)
−2uN−1 −(2 + 2h)uN
h2
= f(xN) + 2
h
(4.37)
gives a tridiagonal linear system of N equations for the N unknowns (u1, … , uN)
with the tridiagonal N × N matrix:
A =
⎛
⎜
⎜
⎜
⎜⎝
2
−2
0
…
−1
2
−1
…
…
0
−1
2
−1
…
0
0
−2
2 + 2h
⎞
⎟
⎟
⎟
⎟⎠
(4.38)
The reduction to tridiagonal form, however, is not necessary from computational
point of view. On the contrary, it is easier to put the BCs (4.35b) as the first and last
equations in Au = b and the equations (4.35a) in between.
Exercise 4.2.3. Write programs for solution of (4.32) using the two grids G2
and G3 above. Make the discretization, set up the equations, formulate on matrix
form, and solve the linear system of equations giving the approximate solution.
Verify second-order accuracy.

86
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Exercise 4.2.4. Use Taylor expansion to show that the difference formulas in (4.24)
and (4.34) are of second order.
Exercise 4.2.5. If the grid G2 is used, how do we compute u(0) and u(1) with for-
mulas giving second-order accuracy from the computed values u0, u1, … , uN+1?
4.2.3
Accuracy
In order to discuss the truncation errors in the numerical solution of (4.20), we define
the local discretization error, the residual obtained when the exact solution is inserted
into the discretization (4.25)
l(x, h) = −u(x + h) −2u(x) + u(x −h)
h2
−f(x)
(4.39)
Using Taylor expansion, it is easy to show that
l(x, h) = 1
12u(4)(x + 𝜃h)h2,
0 < 𝜃< 1,
(4.40)
i.e., the local error is of second order.
Define the global error at the point xi as
e(xi, h) = u(xi) −ui
(4.41)
where u(x) is the analytic solution of (4.20) and ui is the numerical solution obtained
from (4.28).
At the point x = xi the following two relations are valid:
l(xi, h) = −u(xi + h) −2u(xi) + u(xi −h)
h2
−f(xi)
0 = −ui+1 −2ui + ui−1
h2
−f(xi)
(4.42)
Subtract the second equality from the first:
l(xi, h) = −e(xi+1, h) −2e(xi, h) + e(xi−1, h)
h2
(4.43)
As there is no error in the BCs, we also have
e(x0, h) = e(xN+1, h) = 0
(4.44)
Hence, the global error satisfies the following linear system of equations:
Ae = h2l →e = h2A−1l
(4.45)

DIFFERENCE METHODS FOR BVPs
87
where l and e are the vectors of local and global errors at the discretization points,
respectively. Taking the norm of both sides, we get
‖e‖ ≤h2‖A−1‖‖l‖
(4.46)
where the norm is chosen as the max-norm, i.e., ‖.‖ = ‖.‖∞. The matrix A−1 can be
computed and its max-norm shown to be
‖A−1‖∞≤N2
4
(4.47)
For the global error, we thus obtain second-order accuracy
max
i
|e(xi, h)| = ‖e‖∞≤
1
(N + 1)2
N2
4 ‖l‖∞< h2
48 max
0<x<1 |u(4)(x)| = O(h2)
4.2.4
Spurious Solutions
In the previous section in this chapter, it was shown how the FDM behaves when the
stepsize h is small. But what happens if large steps are taken?
For the discussion of this question, we change the model problem (4.20) to con-
tain a first derivative term. This model equation is known as the advection–diffusion
equation and is a slight modification of the model problem (with f(x) = 0)
−𝜖d2u
dx2 + du
dx = 0,
0 < x < 1,
u(0) = 0, u(1) = 1
(4.48)
The first term in (4.48) corresponds to diffusion transport, while the second term
describes convection transport (see also Chapter 9). The parameter 𝜖is a positive
constant. The general solution of this LCC problem is
u(x) = C1 + C2ex∕𝜖
Imposing BCs gives
u(x) = ex∕𝜖−1
e1∕𝜖−1
(4.49)
If 𝜖>> 1, u(x) ≈x, which is the straight line between (0,0) and (1,1).
If 0 < 𝜖<< 1, however,u(x) ≈e−(1−x)∕𝜖, which is almost equal to zero everywhere
except in the neighborhood of x = 1 where u(1) = 1. Hence, the solution u(x) almost
makes a jump at x = 1. We say that the problem has a boundary layer at x = 1 and
the problem is an example of a singular perturbation problem.
For a problem having a solution with this almost discontinuous behavior in a very
small part on the interval [0, 1],we might expect numerical difficulties unless the step-
size is appropriately adjusted. Discretize the ODE using the FDM with second-order
difference approximations on the grid G
−𝜖ui+1 −2ui + ui−1
h2
+ ui+1 −ui−1
2h
= 0,
i = 1, 2, … N
(4.50)

88
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
This difference equation with the BCs u0 = 0, uN+1 = 1 can be solved according to
the method in Section A.2 and the solution is
ui =
1 −
(
1+Pe
1−Pe
)i
1 −
(
1+Pe
1−Pe
)N+1 ,
i = 0, 1, … , N + 1
(4.51)
where the numerical Peclet number Pe (Jean Peclet was a French physicist active in
the first half of the 19th century) is defined as
Pe = h
2𝜖
(4.52)
We note that if Pe > 1, the solution ui is oscillatory, which is not the case in the ana-
lytical solution (Figure 4.9). The amplitude of the spurious oscillations increases with
the stepsize h. This numerical phenomenon might be regarded as a kind of instability,
but, unlike the IVP, the amplitude cannot increase unboundedly, as the largest step
h that can be taken is the size of the whole interval, which is finite in a numerical
computation.
If Pe < 1, there will be no oscillations (see Figure 4.9). However, if 𝜖is very small,
the stepsize h must also be very small to meet the condition Pe < 1. On the other hand,
for a very small 𝜖, the analytic solution is almost zero in the whole interval [0, 1]
except in the boundary layer where the solution steeply goes to one. This numerical
phenomenon resembles stiffness introduced for IVPs in Chapter 3. For stiff IVPs,
implicit methods can be used to avoid very small stepsizes. So, what is the remedy
here?
Approximatethe first derivativewith a backward difference.This leads to the FDM
−𝜖ui+1 −2ui + ui−1
h2
+ ui −ui−1
h
= 0,
i = 1, 2, … , N
(4.53)
This approximation of the first derivative is also called the upwind difference and is
of great importance in Chapter 8 on hyperbolic PDEs. This method postpones the
oscillations but has the disadvantage of giving only first-order accuracy. What this
FDM actually does is to increase the 𝜖value in (4.48). As the upwind difference can
be written
ui −ui−1
h
= ui+1 −ui−1
2h
−h
2
ui+1 −2ui + ui−1
h2
(4.54)
we obtain the following FDM equivalent to (4.53)
−𝜖h
ui+1 −2ui + ui−1
h2
+ ui+1 −ui−1
2h
= 0,
i = 1, 2, … N
(4.55)
where 𝜖h = 𝜖(1 + Pe). Hence, in the original ODE (4.48), the diffusion parameter
𝜖has been increased: we have added a term called artificial diffusion (or artificial

DIFFERENCE METHODS FOR BVPs
89
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
x
u
oscillating curve: h = 0.1, Pe = 5, 2nd order method
dotted curve: h = 0.1, Pe = 5, upwind method
smooth curve: h = 0.01, Pe = 0.5, 2nd order method
Figure 4.9
Spurious oscillations in the advection-diffusion Equation
viscosity) to the problem and the discretization (4.55) corresponds to the perturbed
BVP
−𝜖h
d2u
dx2 + du
dx = 0,
0 < x < 1,
u(0) = 0, u(1) = 1
(4.56)
4.2.5
Linear Two-Point BVPs
The BVP (4.3), now formulated in a way suited for many applications is
−d
dx(𝜅(x)du
dx) + p(x)du
dx + q(x)u = f(x),
a < x < b
(4.57a)
with BCs
𝜅(a)du
dx(a) = 𝛼1u(a) + 𝛽1
(4.57b)
𝜅(b)du
dx(b) = 𝛼2u(b) + 𝛽2
(4.57c)
represent a linear BVP with linear Neumann or mixed BCs, depending on the values
of 𝛼i, and 𝛽i, i = 1, 2. A Dirichlet condition at, e.g., the left boundary is implemented
by setting u(a) = ua instead of (4.57b). With the grid G1 and the central difference
approximations of the derivatives, we obtain
𝜅(x1)u2 −u0
2h
−𝛼1u1 = 𝛽1
(4.58a)

90
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
−1
h(𝜅(xi+1∕2)ui+1 −ui
h
−𝜅(xi−1∕2)ui −ui−1
h
)
+ p(xi)ui+1 −ui−1
2h
+ q(xi)ui = f(xi), i = 1, … , N
(4.58b)
𝜅(xN)uN+1 −uN−1
2h
−𝛼2uN = 𝛽2
(4.58c)
where x0, xN+1 are ghostpoints, x1 = a, xN = b, and h(N −1) = b −a. This is a linear
algebraic system Au = b with a pentadiagonal matrix.
For a Dirichlet BC at, say, the left boundary point, i.e., u(a) = ua, equation (4.58a)
takes the form u1 = ua and no ghost point x0 is needed.
The system can be reduced to a tridiagonal system if u0 and uN+1 are eliminated,
but this is not necessary, as the reduction to a tridiagonal system is not easier from a
programming point of view. The matrix A and the right hand side b is easier to set up
if we start from (4.58). The generation of the linear system of these equations can be
easily automatized if we skip the elimination of ghost points.
Example 4.9. (Interface problem in heat conduction)
In Example4.1, we have assumed that the heat conductioncoefficient 𝜅is constant for
the fluid. However, for heat conduction in a long metal rod composed of two different
materials, the heat conductivity will be different in the two regions (0, 𝜉) and (𝜉, L),
where 𝜉is the interface point. The following mathematical model consisting of two
coupled BVPs can be formulated assuming there are no convection terms
−d
dz
(
𝜅1
dT1
dz
)
+ 2h
R (T1 −Tout) = 0,
0 < z < 𝜉
(4.59a)
with the BC at the left endpoint T1(0) = T0
−d
dz
(
𝜅2
dT2
dz
)
+ 2h
R (T2 −Tout) = 0,
𝜉< z < L
(4.59b)
with the BC at the right endpoint −𝜅dT2
dz (L) = k(T2(L) −Tout). At the interface point,
the temperature and the heat flux are continuous, i.e.,
T1(𝜉) = T2(𝜉)
−𝜅1
dT1
dz (𝜉) = −𝜅2
dT2
dz (𝜉)
(4.59c)
Hence in the interface point, we have a discontinuity in the first derivative and the
second derivative does not exist at that point. The formulation of this problem with
the finite element method (FEM) is found in Example 4.12.

DIFFERENCE METHODS FOR BVPs
91
4.2.6
Nonlinear Two-Point BVPs
The problem (4.1), i.e., a nonlinear second-order ODE
d2u
dx2 = f
(
x, u, du
dx
)
a < x < b
(4.60a)
with nonlinear BCs:
g1
(
a, u(a), du
dx(a)
)
= 0
(4.60b)
g2
(
b, u(b), du
dx(b)
)
= 0
(4.60c)
gives a nonlinear BVP.
With the grid G1, the following equations are obtained after discretization:
g1
(
a, u1, u2 −u0
2h
)
= 0
ui+1 −2ui + ui−1
h2
−f
(
xi, ui, ui+1 −ui−1
2h
)
= 0,
i = 1, … , N
g2
(
b, uN, uN+1 −uN−1
2h
)
= 0
(4.61)
This can be written as a nonlinear system of algebraic equations
F(u) = 0
where
F(u) =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
g1(a, u0, u1, u2)
…
ui+1 −2ui + ui−1
h2
−f(xi, ui−1, ui, ui+1)
…
g2(b, uN−1, uN, uN+1)
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
u =
⎛
⎜
⎜
⎜
⎜⎝
u0
u1
..
uN
uN+1
⎞
⎟
⎟
⎟
⎟⎠
(4.62)
This system can be solved with Newton’s method, see Section A.1. The jacobian is
almost tridiagonal, hence in each Newton-iteration a banded system is to be solved.
Exercise 4.2.6. Discretize the BVP in Example 4.1 with the FDM. Use the follow-
ing values of the parameters in the problem: L = 10, 𝜅= 0.5, h = 5, k = 10, 𝜌= 1,
C = 1, R = 1, T0 = 400, and TL = 300
a) Let v = 0 (no convection term, only conduction). Plot the discretized solution
Ti approximating T(zi) using the grid size N = 10, 20, 40, 80 in the same graph.
Note the convergence of the solution curves.

92
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
b) Vary v in a parameter study using the grid size N = 40. Choose the values
v = 0.1, 0.5, 1, 10 and plot the solutions in the same graph. Note the spurious
oscillations when v = 10! Investigate if the oscillations decrease if the grid size
N is increased.
Exercise 4.2.7. Discretize the BVP in Example 4.2 with the FDM. Use the param-
eter values D = 1, k = 1, R = 1, and c0 = 1.
a) First solve the problem for p = 1 giving a linear BVP. Write a program solv-
ing the linear system of equations and choose in the discretization suitable grid
size N. Plot the numerical solution for different values of N showing the con-
vergence.
b) Change the reaction order parameter to p = 2. The BVP is now nonlinear.
Formulate the nonlinear algebraic system of equation (4.62) for this problem
and find the jacobian of the system. Write a program implementing Newton’s
method for this problem, see Section A.1.
Exercise 4.2.8. The fourth-order ODE in Example 4.3 with modified BCs can be
written as a system of two second-order ODEs:
d2M(x)
dx2
= f(x),
M(L) = 0
d2u
dx2 = M(x)
EI(x),
u(0) = 0,
u′(0) = 0,
u(L) = 0
The function M(x) is the moment acting on the beam. Choose simple values for the
parameters: L = 1, E = 1, I = 1, and f = 1.
a) Using the FDM, formulate the two algebraic systems of equations corre-
sponding to the two BVPs. They are coupled through the discretized moment
vector M.
b) Write a program that solves the systems of equations in a) and plots the numer-
ical solution ui in a graph. Choose suitable values of the grid parameter N.
4.2.7
The Shooting Method
In the shooting method, the BVP is treated as an IVP in an iterative way. We illustrate
the shooting method on the nonlinear formulation (4.60a)
d2u
dx2 = f
(
x, u, du
dx
)
,
a < x < b
with Dirichlet’s BCs
u(a) = 𝛼,
u(b) = 𝛽
(4.63)

DIFFERENCE METHODS FOR BVPs
93
We write this BVP as an IVP
dy1
dx = y2,
y1(a) = u(a)
(4.64a)
dy2
dx = f(x, y1, y2),
y2(a) = du
dx(a)
(4.64b)
In the formulation above, u(a) is known u(a) = 𝛼, but u′(a) is unknown. If we intro-
duce the unknown slope at x = a as a parameter s, the shooting parameter, we can
illustrate geometrically in Figure 4.10 the meaning of changing s:
0
0.2
0.4
0.6
0.8
1
1.2
0
0.5
1
1.5
Point to hit
Slope = s0
Slope = s1
u(1, s0)
u(1, s1)
x
x
u
The shooting method
Figure 4.10
Graph showing the idea behind the shooting method
The computational task is to device a systematic method that computes s so that
the BC at the right endpoint is met. When s is varied, the value of u(b) at the right
endpoint x = b is changed, i.e., u(b) is a function of s: u(b) = u(b, s). We want to find
the value of s for which u(b, s) = 𝛽, i.e., we have to solve the following equation with
respect to s:
u(b, s) −𝛽= 0
(4.65)
This is a nonlinearscalar equation in s. It has to be solved numerically as the analytical
solution u(x, s) is not known. This excludes Newton’s method as in general we cannot
form 𝜕u∕𝜕s needed in Newton’s method.
The method to be used here is instead the secant method. The secant method
applied to the general problem F(z) = 0 is
zi+1 = zi −F(zi)(zi −zi−1)
F(zi) −F(zi−1),
i = 1, 2, …
(4.66)

94
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
where z0 and z1 are given initial guesses. Hence, by applying the secant method to
the BVP (4.64) with F(s) = u(b, s) −𝛽we have the shooting method.
Example 4.10. (Blasius’ boundary layer equation in fluid dynamics).
The nonlinear third-order ODE in Example 4.5
2 d3f
d𝜂3 + f d2f
d𝜂2 = 0,
0 < 𝜂< ∞
with BCs
f(0) = 0,
df
d𝜂(0) = 0,
df
d𝜂(∞) = 1
is formulated as a first-order system of ODEs. Let u1 = f, u2 = F′, u3 = F′′
du1
d𝜂= u2,
u1(0) = 0
du2
d𝜂= u3,
u2(0) = 0
du3
d𝜂= −1
2u1u3,
u3(0) = s
where s, the shooting parameter, is to be computed so that u2(s, L) = 1, where L is a
large number.
Exercise 4.2.9. Write a program solving the BVP in Example 4.10. Try different
values of L (say L = 10,20,40) and check the convergence of the f(𝜂) curve.
4.3
ANSATZ METHODS FOR BVPs
Ansatz methods applied to BVPs will result in systems of algebraic equations to be
solved just as the FDM. They are linear or nonlinear depending on whether the BVP
is linear or nonlinear.
As a model problem for ansatz methods, we use the same BVP as before
(4.20), i.e.,
−d2u
dx2 = f(x),
0 < x < 1,
u(0) = 0,
u(1) = 0
The solution u(x) is approximated by an ansatz uh(x):
u(x) ≈uh(x) =
N
∑
j=1
cj𝜑j(x)
(4.67)

ANSATZ METHODS FOR BVPs
95
where 𝜑j(x) are given basis functions and cj are coefficients to be determined so that
uh(x) is a “good” approximation in some sense. We assume here that the basis func-
tions satisfy the BCs, i.e.,
𝜑j(0) = 0,
𝜑j(1) = 0,
j = 1, 2, … , N
(4.68)
Hence, the ansatz solution uh(x) satisfies the BCs of the model problem, i.e., uh(0) =
0, uh(1) = 0.
The subscript h in uh(x) refers to the fact that the basis functions are defined from
some sort of discretization of the interval (0, 1).
4.3.1
Starting with the ODE Formulation
Insert the ansatz into the BVP and we obtain a residual function r(x):
r(x) = d2uh
dx2 + f(x) ≠0
(4.69)
We want the residual function to be small in some sense.
If r(x) ≡0 for all x in the interval 0 ≤x ≤1, then uh(x) is the exact solution
of (4.20). Of course we cannot expect uh(x) to be exact in a general case, but a small
residual can be achieved in various ways:
1. r(xi) = 0, i = 1, 2, … N, i.e., the residual is zero in points xi ∈[0, 1], the collo-
cation method
2. r(x) is orthogonal to 𝜑i(x), i.e., ∫1
0 r(x)𝜑i(x)dx = 0, i = 1, 2, … , N, Galerkin’s
method
Boris Galerkin was a Russian engineer and mathematician active in the first half of
the 20th century.
Galerkin’s method is demonstrated here. Insert r(x) into the integral conditions:
∫
1
0
( N
∑
j=1
cj
d2𝜑j
dx2 + f(x)
)
𝜑idx = 0,
i = 1, 2, … , N
(4.70)
As cj are independent of x, we can move them outside the integral:
N
∑
j=1
cj ∫
1
0
d2𝜑j
dx2 𝜑idx + ∫
1
0
f(x)𝜑idx = 0
(4.71)
Now use integration by parts on the first integral
∫
1
0
d2𝜑j
dx2 𝜑idx =
[d𝜑j
dx 𝜑i
]1
0
−∫
1
0
d𝜑i
dx
d𝜑j
dx dx
(4.72)

96
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Because of the BCs, the first term on the right hand side is equal to zero and we get
N
∑
j=1
cj ∫
1
0
d𝜑i
dx
d𝜑j
dx dx = ∫
1
0
f(x)𝜑idx
(4.73)
which is a linear system of equations
Ac = f,
Aij = ∫
1
0
d𝜑i
dx
d𝜑j
dx dx,
fi = ∫
1
0
f(x)𝜑idx
(4.74)
where the matrix A is N × N, symmetric, and positive definite. Observe that so far
we cannot say anything about the sparsity of A. That depends on the choice of basis
functions 𝜑i(x), i = 1, 2, … , N, see Section 4.3.3.
4.3.2
Starting with the Weak Formulation
4.3.2.1
The Model Problem The analytical solution (4.22) to the ODE
problem (4.20) is referred to as the strong (or classical) solution, meaning
that u(x) must be twice piecewise continuously differentiable and fulfill the BCs to
satisfy the BVP.
There is, however, an alternative formulation, the weak (or variational) formula-
tion, based on an integral relation to which the BCs are coupled. This formulation
requires u(x) to be only once piecewise continuously differentiable and is called the
weak solution.
The weak solution is obtained by multiplying the ODE by a test function v(x)
fulfilling the BCs v(0) = v(1) = 0, integrate over the interval (0, 1) and then use inte-
gration by parts
−∫
1
0
u′′(x)v(x)dx = −[u′(x)v(x)]1
0 + ∫
1
0
u′(x)v′(x)dx = ∫
1
0
f(x)v(x)dx
The outintegrated term vanishes as v(0) = v(1) = 0 and the original ODE
problem (4.20) can now be stated in weak form: Find u(x) ∈U such that
∫
1
0
u′(x)v′(x)dx = ∫
1
0
f(x)v(x)dx,
for all v(x) ∈U
(4.75)
Both u(x) and v(x) belong to the same function space, U ≡PC1
[0,1](0, 1), which means
all functions that are once piecewise continuously differentiable on the interval (0, 1)
and zero at the boundary points [0] and [1]. We use the notation PC as C in most
textbooks is reserved for functions that are continuously differentiable up to a certain
order.
If the BVP (4.20) is given with another BC
−d2u
dx2 = f(x),
u(0) = 0,
u′(1) = 0
(4.76)

ANSATZ METHODS FOR BVPs
97
the weak formulation must be modified. As before multiply with a test function v(x),
integrate, and then integrate by parts. The outintegrated term is
−u′(1)v(1) + u′(0)v(0) = u′(0)v(0) = 0
if
v(0) = 0
and the weak formulation will be: Find u(x) ∈U such that
∫
1
0
u′(x)v′(x)dx = ∫
1
0
f(x)v(x)dx,
for all v(x) ∈U
where U = PC1
[0](0, 1). Hence, the BC u(0) = 0 is imposed into the function space U,
while the BC u′(1) = 0 comes out from the weak formulation. BCs that are imposed
explicitly to the function space U (here u(0) = 0) are called essential BCs, while
BCs that comes out from the weak formulation are called natural BCs. Most often
Dirichlet BCs are essential, while Neumann’s and mixed BCs are natural.
Comment. It should be noted that there is also a third way of formulating (4.20)
called Ritz’ method or the minimization formulation
minv(x)∈U ∫
1
0
(1
2(v′(x))2 −f(x)v(x))dx
where U ≡PC1
[0,1](0, 1). The function giving the minimum value to the integral
expression is denoted by u(x) and is the same function that solves the variational
problem (4.75). This technique, however, belongs to variational calculus and is not
taken up here. End of comment.
It may seem like magic that the weak formulation works, i.e., that (4.20) and (4.75)
give the same solution and that a method can be based on a relation that is satisfied for
infinitely many functions! The following analogy with a linear system of algebraic
equations shows that “although this be madness, yet there is method in it” (Shake-
speare, Hamlet, Act 2). Assume that A is an arbitrary N × N matrix and let u ∈RN
be the solution of
Au = b
Multiply both sides by vT, an arbitrary (row) vector in RN
vT(Au −b) = 0
for all v ∈RN
(4.77)
and we obtain the weak formulation. On the other hand, if (4.77) is true, choose from
RN N linearly independent vectors, put them as columns in the N × N matrix W, and
we obtain
WT(Au −b) = 0
As W is nonsingular, we can multiply by the inverse of WT giving
Au −b = 0 →Au = b

98
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Now, back to the weak formulation (4.75). A well-known approximation
method is Galerkin’s method already mentioned in Section 4.3.1. This method
is based on projection of u(x) onto a finite dimensional linear subspace Uh of
U. Assume this subspace is built up by basis functions 𝜑i(x), where 𝜑i(0) = 0,
𝜑i(1) = 0, i = 1, 2, … , N. We now look for an ansatz approximation uh(x) that
belongs to the subspace Uh
uh(x) =
N
∑
j=1
cj𝜑j(x)
and satisfies the weak formulation in the subspace, i.e., find uh(x) ∈Uh such that
∫
1
0
duh
dx
dvh
dx dx = ∫
1
0
f(x)vhdx,
for all vh ∈Uh
(4.78)
In Galerkin’s method, the basis functions 𝜑i(x) are used as test functions vh(x) and
we obtain
N
∑
j=1
cj ∫
1
0
d𝜑i
dx
d𝜑j
dx dx = ∫
1
0
f(x)𝜑idx,
i = 1, 2, … N
(4.79)
which is the same linear system of equations as (4.74), where we started with the
differential equation. The trick in both cases is to use partial integration to get rid of
the second derivative.
4.3.2.2
A Linear Two-Point BVP Now, let us generalize Galerkin’s method to the
linear two-point BVP defined by (4.57). This generalization is helpful to have as a
background to Chapter 7 where elliptic PDEs are studied. As before, multiply (4.57a)
with a test function v(x)
∫
b
a
(
−d
dx
(
𝜅(x)du
dx
)
v(x)dx + p(x)du
dxv(x) + q(x)u(x)v(x)
)
dx = ∫
b
a
f(x)v(x)dx
(4.80)
Use integration by parts on the first term
−∫
b
a
d
dx
(
𝜅(x)du
dx
)
v(x)dx = −
[
𝜅(x)du
dxv(x)
]b
a + ∫
b
a
𝜅(x)du
dx
dv
dxdx
(4.81)
Using (4.57b) and (4.57c), the outintegrated term can be written
𝜅(a)du
dx(a)v(a) −𝜅(b)du
dx(b)v(b) = (𝛼1u(a) + 𝛽1)v(a) −(𝛼2u(b) + 𝛽2)v(b)
(4.82)
With the BCs given here, we cannot restrict u(x) or v(x) to be zero at x = a or x = b.
Instead the values of u(x) and v(x) at the boundary points will come out from the
following weak formulation: Find u(x) ∈U such that

ANSATZ METHODS FOR BVPs
99
∫
b
a
(𝜅(x)du
dx
dv
dx + p(x)du
dxv(x) + q(x)u(x)v(x))dx + (𝛼1u(a)v(a) −𝛼2u(b)v(b))
= ∫
b
a
f(x)v(x)dx −(𝛽1v(a) −𝛽2v(b))
for all v(x) ∈U
(4.83)
where U is PC1(0, 1), i.e., all functions once piecewise continuously differentiable
on (0, 1). Hence, the BCs in (4.57) are not explicitly given but comes out as a conse-
quence of the weak formulation, hence the BCs are natural. Note that terms contain-
ing u, du∕dx and v, dv∕dx occur in the left hand side as quadratic terms, while terms
containing only v are collected in the right hand side.
Example 4.11.
The weak formulation of problem (4.32) is formulated as follows.
Starting from (4.78), the outintegrated term is
−u′(1)v(1) + u′(0)v(0) = (u(1) −1)v(1)
Hence, the weak formulation has the form: Find u(x) ∈U such that
∫
1
0
u′v′dx + u(1)v(1) = ∫
1
0
f(x)v(x)dx + v(1),
for all v(x) ∈U
where U = PC1(0, 1). Both BCs are natural.
Now, use Galerkin’s method on the weak formulation (4.83), i.e., let
uh(x) =
N
∑
j=1
cj𝜑j(x),
vh(x) = 𝜑i(x), i = 1, 2, … N
The coefficients cj are obtained from a linear system of algebraic equations
(A𝜅+ P + Q + B)c = f
(4.84)
where the elements of the N × N matrices A𝜅, P, Q, B are
A𝜅ij = ∫
b
a
𝜅(x)d𝜑i
dx
d𝜑j
dx dx,
Pij = ∫
b
a
p(x)𝜑i
d𝜑j
dx dx
Qij = ∫
b
a
q(x)𝜑i(x)𝜑j(x)dx,
Bij = 𝛼1𝜑i(a)𝜑j(a) −𝛼2𝜑i(b)𝜑j(b)
(4.85)
and the right hand side is the N × 1 vector f with the elements
fi = ∫
b
a
f(x)𝜑i(x)dx −𝛽1𝜑i(a) + 𝛽2𝜑i(b)
(4.86)

100
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
If 𝜅(x) > 0, q(x) > 0, 𝛼1 > 0, 𝛼2 < 0, and p(x) ≡0, the linear system of equations
(4.84) is symmetric and positive definite. This special case is very common in appli-
cations and is found in, e.g., heat conduction, structural mechanics, diffusion, and
electromagnetics. Linear systems of equations with a symmetric and positive system
matrix can be solved with, e.g., Cholesky’s method or some conjugate gradient-based
method, see Section A.5.
If p(x) ≠0, the linear equation system (4.84) is unsymmetric and other meth-
ods must be used, e.g., Gaussian elimination or the iterative GMRES method, see
Section A.5.
Example 4.12.
The interface problem in Example 4.10 is formulated in weak
form. Let T(z) = u(z) + T0. With this transformation, we obtain the essential BC
u(0) = 0. Find u(z) ∈U such that
∫
L
0
𝜅du
dz
dv
dzdz + ∫
L
0
2h
R u(z)v(z)dz + (u(L) + T0 −Tout)v(L)
= ∫
L
0
2h
R Toutv(z)dz −(T0 −Tout)v(L)
for all v ∈U, where U = PC1
[0](0, 1). The parameter 𝜅takes different values in the
two regions, i.e., 𝜅= 𝜅1, 0 < z < 𝜉, and 𝜅= 𝜅2,
𝜉< z < L. Observe that the inter-
face BCs (4.59c) are automatically “built in” in the weak formulation.
In this section, we have stated the weak formulation and Galerkin’s method with
integral expressions. A general, abstract way of formulation is based on Sobolev
spaces, see reference 4 in the bibliography.
Exercise 4.3.1. Given the BVP −u′ = f(x),
u′(0) = 0,
u(1) = 0
0 < x < 1
present the weak formulation of the problem. Which BC is natural and which is
essential?
Exercise 4.3.2. Given the BVP −u′ = f(x),
u(0) = a,
u′(1) = b
0 < x < 1.
Here the BC’s are inhomogeneous. Present the weak formulation of this prob-
lem. Hint: Introduce the help function w(x) through u(x) = w(x) + a + bx, where
w(0) = 0, w′(1) = 0
Exercise 4.3.3. Given the BVP −u′ = f(x),
u(0) = a,
u(1) = b
0 < x < 1.
Present the weak formulation of this problem. Hint: Find a transformation similar to
the one in Exercise 4.3.2.
4.3.3
The Finite Element Method
This section is not an extensive treatment of the FEM for solving BVPs in 1D. Instead
it is intended to be an overview of a method that can be generalized to problems in
2D (see Section 7.4).

ANSATZ METHODS FOR BVPs
101
So far we have not said anything about the basis functions. Obviously they influ-
ence the structure of the matrix A. When the FDM (4.27) is used, the matrix A is a
tridiagonal matrix. We should come down to something similar for the ansatz method,
if the methods are to be comparable with respect to computer storage and computer
time needed to solve Ac = b.
If we choose the ansatz solution to be a polynomial of degree N, e.g.,
̃u(x) =
N−1
∑
j=1
cjxj(x −1)
(4.87)
where the basis functions are 𝜑j(x) = xj(x −1) fulfilling the BCs. It is easy to show
that this choice of basis functions will give a full matrix A, i.e., most elements Ai,j ≠0.
Assume we want our ansatz function to be a piecewise polynomial of degree one,
i.e., a function that is put together from straight lines in a continuous way at the nodes
xi, i = 1, 2, … , N as in the graph in Figure 4.11, where the stepsize hi can be variable
or constant, i.e., ∑N
i=0 hi = 1 or h(N + 1) = 1.
The basis functions of the ansatz uh(x) = ∑n
j=1 cj𝜑j will also be piecewise polyno-
mials. If we want cj = uh(xj), we see that 𝜑j must fulfill
𝜑j(xi) =
{
1,
if i = j
0,
if i ≠j
(4.88)
Hence, the ansatz function uh(x) will be a piecewise linear interpolation polynomial
through the points (xi, uh(xi)). A graph of this basis function looks like the one shown
in Figure 4.12.
The derivative 𝜑′
j(x) of the basis function has the graph shown in Figure 4.13.
x0
x1
x2
x3
xN − 1
xN + 1
xN
x
˜u
Figure 4.11
A piecewise linear ansatz function
h
h
xj − 1
xj
xj + 1
x
0
1
φj
Figure 4.12
A piecewise linear basis function, a roof function

102
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
h
h
xj − 1
xj 
xj + 1
x
0
−1
h
1
h
φ′j
Figure 4.13
The derivative of a roof function
A few simple calculations using (4.74) give as result
Aij = −1
h,
j = i −1, j = i + 1
Aii = 2
h
(4.89)
Hence, the N × N matrix A, the ‘stiffness matrix’ is the same as in (4.29) (apart from
the factor 1∕h).
A = 1
h
⎛
⎜
⎜
⎜
⎜⎝
2
−1
0
0
…
−1
2
−1
0
…
…
…
0
−1
2
−1
…
0
0
−1
2
⎞
⎟
⎟
⎟
⎟⎠
Stiffness is here related to a material property and not the concept “stiff ” in connec-
tion with certain ODE problems (see Section 3.3.3). The right hand side vector f is
often called the load vector.
The computation of the right hand side f where
fi = ∫
xi+h
xi−h
f(x)𝜑i(x)dx
can be done approximately with, e.g., the trapezoidal method:
fi ≈hf(xi)
(4.90)
Hence, for the model problem (4.20), we get exactly the same system of linear
equations (4.29) for the FDM and the FEM. This, however, is not true in general.
Exercise 4.3.4. Modify the calculations leading to A and f in the case that the step-
size is not constant, i.e., hi = xi+1 −xi.
Exercise 4.3.5. Given the BVP (4.57) with 𝜅(x) = 1, p(x) = 1, q(x) = 1, compute
the elements A𝜅i,j, Pi,j, and Qi,j in (4.84).

BIBLIOGRAPHY
103
Exercise 4.3.6. Write a program to solve the BVP (4.32) with the FEM. Compare
with the FDM solution of the same problem.
BIBLIOGRAPHY
1. C. Moler, “Numerical Computing with MATLAB”, Chapter 8, SIAM, 2004
2. G. Golub, J. Ortega, “Scientific Computing and Differential Equations”, Chapter 3, Aca-
demic Press, 1992
3. H.B. Keller, “Numerical Methods for Two-point Boundary Value Problems”, Blaisdell,
London, 1968
4. K. Eriksson, D. Estep, P. Hansbo, C. Johnson, “Computational Differential Equations”,
Studentlitteratur, 1996


5
PARTIAL DIFFERENTIAL EQUATIONS
This chapter is not intended to be an extensive treatment of mathematical properties
of partial differential equations (PDEs) but rather a survey of important definitions,
concepts, and results. For a more careful description, the reader may consult some of
the mathematical textbooks on PDEs referenced in the end of this chapter.
A general formulation of a system of PDEs expressed in vector form is
𝜕u
𝜕t = f
(
t, x, y, z, u, 𝜕u
𝜕x , 𝜕u
𝜕y , 𝜕u
𝜕z , 𝜕2u
𝜕x2 , 𝜕2u
𝜕y2 , 𝜕2u
𝜕z2 ,…
)
(5.1)
The variables t, x, y, z, the independent variables, are defined in some region, bounded
or unbounded and the variable u, the dependent variable, is a solution of (5.1) if it
satisfies the PDEs for all t, x, y, z in the region. Among the independent variables,
t is used to denote time and x, y, z denote the space variables. If time is among the
independent variables, the PDE problem is called a time-dependent or an evolution
problem, if not the problem is called an equilibrium or a steady-state problem.
The solution of a PDE is called a field, a function that depends on time and space
or just space. The field is scalar valued if the PDE (5.1) is scalar and vector valued
if (5.1) is a system of PDEs.
A problem formulated in three space dimensions x, y, z is called a 3D problem
(three dimension).The mathematical and numerical treatment of a PDE is often easier
when formulated in 2Ds x, y or 1D x.
As was illustrated in Chapter 1, a PDE has infinitely many solutions. To obtain a
unique solution, we need to have initial and boundary conditions. It depends on the
character of the PDE what conditions should be given in order to have a well-posed
problem, i.e., a problem the solution of which is stable with respect to perturbations
in boundary and initial data.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

106
PARTIAL DIFFERENTIAL EQUATIONS
5.1
CLASSICAL PDE PROBLEMS
The classical PDEs presented in most textbooks are given below as problems (1–5).
They are all scalar linear PDEs with constant coefficients. They will be used as model
problems for numerical methods presented in later chapters.
1. Parabolic PDE in 1D (heat equation or diffusion equation):
𝜕u
𝜕t = 𝜅𝜕2u
𝜕x2 ,
0 < x < 1,
0 < t ≤tend
(5.2)
where 𝜅is a constant positive parameter.
Initial condition: u(x, 0) = u0(x), a known function of x.
Boundary conditions: u(0, t) = 𝛼(t), u(1, t) = 𝛽(t), where 𝛼(t) and 𝛽(t) are
known functions of t.
2. Hyperbolic PDE in 1D (wave equation):
𝜕2u
𝜕t2 = c2 𝜕2u
𝜕x2 ,
0 < x < 1,
0 < t ≤tend
(5.3)
where c is a constant parameter.
Initial conditions: u(x, 0) = u0(x), 𝜕u
𝜕t (x, 0) = v0(x)
Boundary conditions: u(0, t) = 𝛼(t), u(1, t) = 𝛽(t)
3. Hyperbolic first-order PDE in 1D (advection equation):
𝜕u
𝜕t + a𝜕u
𝜕x = 0,
0 < x < 1,
0 < t ≤tend
(5.4)
where a is a constant positive parameter.
Initial condition: u(x, 0) = u0(x)
Boundary condition: u(0, t) = 𝛼(t)
4. Elliptic PDE in 2D (Poisson’s equation on the unit square)
𝜕2u
𝜕x2 + 𝜕2u
𝜕y2 = f(x, y),
(x, y) ∈Ω = {(x, y) ∶0 < x, y < 1}
(5.5)
Boundary condition: u = 0 on 𝜕Ω, the boundary of Ω
The important special case when f(x, y) ≡0 in (5.5) is called Laplace’s
equation.
5. Eigenvalue problem in 2D: (Helmholtz’ equation on the unit square)
𝜕2u
𝜕x2 + 𝜕2u
𝜕y2 = 𝜆u,
(x, y) ∈Ω = {(x, y) ∶0 < x, y < 1}
(5.6)
Boundary condition: u = 0 on 𝜕Ω.

CLASSICAL PDE PROBLEMS
107
The equations above are special cases of a general linear second-order PDE:
a𝜕2u
𝜕x2 + 2b 𝜕2u
𝜕x𝜕y + c𝜕2u
𝜕y2 + d1
𝜕u
𝜕x + d2
𝜕u
𝜕y + eu = f(x, y)
(5.7)
which is called, assuming that at least one of a, b, c is ≠0
hyperbolic
if
b2 −ac > 0
parabolic
if
b2 −ac = 0
elliptic
if
b2 −ac < 0
If a = b = c = 0, but d1 ≠0 and d2 ≠0, the PDE is hyperbolic.
In a linear PDE of type (5.7), the coefficients a, b, c, d1, d2, e are constant or depend
on (x, y). For a time-dependent PDE, change y to t. If f(x, y) ≡0, (5.7) is homogenous,
otherwise inhomogeneous.
Example 5.1. (The Euler–Tricomi PDE).
𝜕2u
𝜕x2 = x𝜕2u
𝜕y2
This is an example where the coefficient depends on (x, y). The PDE is hyperbolic
when x > 0 and elliptic when x < 0. Francesco Tricomi was an Italian mathematician
active in the middle of the 20th century.
Example 5.2. (The Prandtl–Glauert equation).
Compressible, inviscid flow over a thin airfoil can be modeled in 2D by the PDE
(1 −M2
∞)𝜕2Φ
𝜕x2 + 𝜕2Φ
𝜕y2 = 0
where M∞is the Mach number and Φ is the velocity potential. This PDE is hyperbolic
if M∞> 1 (supersonic flow) and elliptic if M∞< 1 (subsonic flow). Ludwig Prandtl
was a German and Hermann Glauert was a British physicist active in the first half of
the 20th century.
Example 5.3.
A fundamental solution of the wave equation (5.3) is obtained from
the ansatz (compare with Example 4.6)
u(x, t) = ei𝜔tv(x)
Insert this ansatz into (5.3) and the following ODE for v(x) is obtained
d2v
dx2 + k2v = 0

108
PARTIAL DIFFERENTIAL EQUATIONS
where k = 𝜔∕c is called the wave number. A particular solution of (5.3) can then be
written
u(x, t) = ei(𝜔t±kx) = ei𝜔(t±cx)
which is a traveling wave, a very common model for, e.g., energy transfer in physics,
such as mechanical, electromagnetic, or quantum mechanical waves.
In an extended definition, the space-derivative terms are modified in a way that
admits nonlinear versions of the generic PDEs:
1. Nonlinear heat (or diffusion) equation in 1D:
𝜕u
𝜕t = 𝜕
𝜕x
(
𝜅(u)𝜕u
𝜕x
)
(5.8)
2. Nonlinear wave equation in 1D:
𝜕2u
𝜕t2 = c2(u)𝜕2u
𝜕x2
(5.9)
3. Nonlinear advection equation in 1D:
𝜕u
𝜕t + a(u)𝜕u
𝜕x = 0
(5.10)
4. Nonlinear Laplace’s equation in 2D:
𝜕
𝜕x
(
𝜅x(u)𝜕u
𝜕x
)
+ 𝜕
𝜕y
(
𝜅y(u)𝜕u
𝜕y
)
= 0
(5.11)
Analytic solutions to PDEs can seldom be found but exist for the linear model
problems.Usually analytic solutions are complicated consisting of, e.g., infinite series
expansions or integral expressions.
For Cauchy formulations (initial values are given for −∞< x < ∞) of the
time-dependent problems (1–3) analytic solutions can be formulated. For Laplace’s
equation, analytic solutions exist when the region Ω has a simple geometry, e.g., a
square or a circle.
Augustin Louis Cauchy,Pierre Simon de Laplace, and Simeon Denis Poisson were
French mathematicians active in the beginning of the 19th century.
1. The heat equation, with Cauchy conditions
𝜕u
𝜕t = 𝜅𝜕2u
𝜕x2 , u(x, 0) = u0(x), −∞< x < ∞, t > 0
The solution can be written as an integral
u(x, t) =
1
2
√
𝜋𝜅t ∫
+∞
−∞
e−(x−s)2∕4𝜅tu0(s)ds
(5.12)

CLASSICAL PDE PROBLEMS
109
−1
−0.5
0
0.5
1
0
0.5
1
1.5
2
2.5
3
x
u
t = 0.01
t = 0.05
t = 0.2
−1
0
1
0
0.1
0.2
0
1
2
3
x
t
u(x, t)
Figure 5.1
The fundamental solution of the heat equation, 𝜅= 1
provided the integral exists for the given function u0(x). In the special case,
u0(x) = 𝛿(x), i.e., the Dirac delta-function at x = 0, we obtain the fundamental
solution (Figure 5.1)
u(x, t) =
1
2
√
𝜋𝜅t
e−x2∕4𝜅t
(5.13)
The problem is well posed if t > 0 and ill posed if t < 0.
2. The wave equation with Cauchy conditions
𝜕2u
𝜕t2 = c2 𝜕2u
𝜕x2 , u(x, 0) = u0(x), 𝜕u
𝜕t (x, 0) = v0(x), −∞< x < ∞
has the following solution, also called d’Alambert’s solution
u(x, t) = 1
2(u0(x −ct) + u0(x + ct)) + 1
2c ∫
x+ct
x−ct
v0(s)ds
(5.14)
For the initial values u0(x) = e−x2, v0(x) = 0 and the parameter value c = 1, the
solution is (see Figure 5.2)
u(x, t) = 1
2
(
e−(x−t)2 + e−(x+t)2)
This problem is well posed in both t directions, i.e., both t > 0 and t < 0.
3. The advection equation and its solution are presented in Chapter 1.
4. Laplace’s equation on the unit square
𝜕2u
𝜕x2 + 𝜕2u
𝜕y2 = 0,
(x, y) ∈Ω = {(x, y) ∶0 < x, y < 1}

110
PARTIAL DIFFERENTIAL EQUATIONS
−5
0
5
0
0.2
0.4
0.6
0.8
1
x
u
t = 4
t = 2
t = 4
t = 2
t = 0
–>
<–
−5
0
5
0
2
4
0
0.5
1
x
t
u(x, t)
Figure 5.2
D’Alembert’s solution of the wave equation, c = 1
with the following boundary conditions (one of which is nonhomogeneous)
u(0, y) = u(1, y) = 0, 0 < y < 1,
u(x, 0) = 0, u(x, 1) = g(x), 0 ≤x ≤1
has the following infinite series solution obtained with the analytic method sep-
aration of variables
u(x, t) =
∞
∑
k=1
ck sin(k𝜋x) sinh(k𝜋y)
(5.15)
where ck are coefficients given by integral expressions. With the principle of
superposition, the analytic solution of Laplace’s equation with all four bound-
aries having nonhomogeneous boundary conditions can be written as the sum
of four sums of type (5.15).
5.2
DIFFERENTIAL OPERATORS USED FOR PDES
The PDEs of science and engineering are formulated in 3D and often complicated to
present in component form. Therefore, it is convenient to use differential operators to
make the notation more compact. The frequently used differential operators are the
gradient, the divergence, the rotation (curl), and the laplacian.
Let Φ = Φ(x, y, z) be a scalar field, F = (P(x, y, z), Q(x, y, z), R(x, y, z))T be a vector
field, and (x, y, z) the usual cartesian coordinates. The differential operator ∇(nabla)
is defined as
∇=
(
𝜕
𝜕x,
𝜕
𝜕y, 𝜕
𝜕z
)T
The differential operators are defined as
grad Φ = ∇Φ =
(
𝜕Φ
𝜕x , 𝜕Φ
𝜕y , 𝜕Φ
𝜕z
)T
(5.16)

DIFFERENTIAL OPERATORS USED FOR PDES
111
div F = ∇⋅F = 𝜕P
𝜕x + 𝜕Q
𝜕y + 𝜕R
𝜕z
(5.17)
curl F = ∇× F =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
𝜕R
𝜕y −𝜕Q
𝜕z
𝜕P
𝜕z −𝜕R
𝜕x
𝜕Q
𝜕x −𝜕P
𝜕y
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
(5.18)
div grad Φ = ΔΦ = 𝜕2Φ
𝜕x2 + 𝜕2Φ
𝜕y2 + 𝜕2Φ
𝜕z2
(5.19)
where Δ is known as the laplacian, which can also be written as ∇⋅∇or ∇2.
Observe that the notations ∇and ∇2 are also used as operators for backward dif-
ferentiation approximations, see Section 3.4.
In 2D, the correspondingoperators have to be modified.Let Φ = Φ(x, y) be a scalar
field and F = (P(x, y), Q(x, y))T be a vector field. Then,
grad Φ = ∇Φ =
(
𝜕Φ
𝜕x , 𝜕Φ
𝜕y
)T
(5.20)
div F = ∇⋅F = 𝜕P
𝜕x + 𝜕Q
𝜕y
(5.21)
curl F = ∇× F = 𝜕Q
𝜕x −𝜕P
𝜕y
(5.22)
div grad Φ = ΔΦ = 𝜕2Φ
𝜕x2 + 𝜕2Φ
𝜕y2
(5.23)
Two important results from vector analysis are
If curl F = 0, there exists a potential function Φ satisfying F = ∇Φ.
If div F = 0, there exists a vector potential A satisfying F = curl A.
The operators grad, div, and curl have physical interpretations. The gradient ∇Φ is
a measure of the steepness of Φ is in the x,y, and z directions, the div-operator can
be interpreted as the source strength of the field F and the curl-operator corresponds
to the rotation strength of a velocity field v. For further discussion on these three
operators, see Section A.4.
All definitions (5.16)–(5.23) are formulated in cartesian coordinates (x, y, z). In
applications, however, it is sometimes suitable to use
cylindrical coordinates (r, 𝜑, z): x = r cos(𝜑), y = r sin(𝜑), z = z
spherical
coordinates
(r, 𝜃, 𝜑):
x = r sin(𝜃) cos(𝜑),
y = r sin(𝜃) sin(𝜑),
z = r cos(𝜃).

112
PARTIAL DIFFERENTIAL EQUATIONS
ˆn
∇u
∂u
∂n
Figure 5.3
The geometrical meaning of the normal derivative
We refer to mathematical textbooks for deriving the transformations leading to the
forms of the operators expressed in these coordinates. For use in coming chapters,
however, the laplacian in 3D is presented for the three coordinate systems:
ΔΦ = 𝜕2Φ
𝜕x2 + 𝜕2Φ
𝜕y2 + 𝜕2Φ
𝜕y2
(5.24a)
ΔΦ = 1
r
𝜕
𝜕r
(
r𝜕Φ
𝜕r
)
+ 1
r2
𝜕2Φ
𝜕𝜑2 + 𝜕2Φ
𝜕z2
(5.24b)
ΔΦ = 1
r2
𝜕
𝜕r
(
r2 𝜕Φ
𝜕r
)
+
1
r2 sin(𝜃)
𝜕
𝜕𝜃
(
sin(𝜃)𝜕Φ
𝜕𝜃
)
+
1
r2sin2(𝜃)
𝜕2Φ
𝜕𝜑2
(5.24c)
Observe that the coefficients depend on r and r, 𝜃respectively, hence they are vari-
able, but the PDEs are still linear.
Another differential operator used in 2D and 3D boundaryconditions is the normal
derivative. It is defined as the projection of the gradient in a boundary point onto the
outward normal unit vector ̂n from that point (see Figure 5.3).
𝜕u
𝜕n = (∇u) ⋅̂n
(5.25)
Exercise 5.2.1. Given the following PDEs. Investigate for each one if it is
parabolic, hyperbolic, or elliptic.
a) 𝜕u
𝜕t = 𝜕2u
𝜕x2 + u, b) 𝜕2u
𝜕x2 + 𝜕2u
𝜕y2 = −1, c) 𝜕u
𝜕t + u𝜕u
𝜕x = 0, d) 𝜕u
𝜕t + 𝜕u
𝜕x = 𝜕2u
𝜕x2 + u
Exercise 5.2.2. Given the PDE problem
𝜕u
𝜕t + 𝜕u
𝜕x = 𝜕2u
𝜕x2 ,
u(0, t) = 1, u(1, t) = 0, u(x, 0) = u0(x)
Show that the first-order space-derivative term in the PDE can be eliminated by
choosing 𝛼appropriately in the transformation u = ve𝛼x. Formulate the PDE for the
variable v and the corresponding initial and boundary conditions.

DIFFERENTIAL OPERATORS USED FOR PDES
113
Exercise 5.2.3. Verify that Laplace’s equation in 2D polar coordinates(r, 𝜑), where
x = r cos 𝜑, y = r sin 𝜑, is
𝜕2u
𝜕r2 + 1
r
𝜕u
𝜕r + 1
r2
𝜕2u
𝜕𝜑2 = 0
Show that that the sum of the first two terms can be written
1
r
𝜕
𝜕r
(
r𝜕u
𝜕r
)
Exercise 5.2.4. Show that the first term in the spherical laplacian can be written
1
r2
𝜕
𝜕r
(
r2 𝜕u
𝜕r
)
= 𝜕2u
𝜕r2 + 2
r
𝜕u
𝜕r = 1
r
𝜕2(ru)
𝜕r2
Exercise 5.2.5. Spherical waves from a point source are modeled by the PDE
𝜕2u
𝜕t2 = c2
(
𝜕2u
𝜕r2 + 2
r
𝜕u
𝜕r
)
Show that this PDE is equivalent to the PDE
𝜕2(ru)
𝜕t2
= c2 𝜕2(ru)
𝜕r2
that has the general solution
u(r, t) = 1
r (f(r −ct) + g(r + ct))
where f(r) and g(r) are arbitrary twice differentiable functions.
Exercise 5.2.6. Show that the fundamental solution (5.13) satisfies the heat
equation.
Exercise 5.2.7. Show that d’Alembert’s solution (5.14) satisfies the wave equation.
Show it first for v0 ≡0.
Exercise 5.2.8. Use separation of variables to show that the solution of problem (4)
has the series solution (5.15). Derive the integral expressions for the coefficients ck.
Exercise 5.2.9. Show
that
u(x, y) = sin(i𝜋x) sin(j𝜋y), i = 1, 2,… j = 1, 2,…
are solutions (eigenfunctions) to model problem (5). Calculate the corresponding
eigenvalues.

114
PARTIAL DIFFERENTIAL EQUATIONS
Exercise 5.2.10. Show the following differential operator relations:
a) div (∇u) = Δu
b) div (curl u) = 0, i.e., the divergence of a rotation equals zero.
c) curl (∇u) = 0, i.e., the rotation of a gradient equals zero.
d) div (𝜌u) = 𝜌div u + ∇𝜌⋅u
e) (u ⋅∇)u = 1
2∇(u ⋅u) + (curl u) × u
f) Δu = ∇(div u) −(curl (curl u))
g) div (uuT) = u(div u) + (u ⋅∇)u. The divergence of the matrix uuT is a vector
where component i is the divergence of row i in uuT
5.3
SOME PDEs IN SCIENCE AND ENGINEERING
In this section, some well-known PDEs from different applications in science and
engineeringare presented. These equationsexhibit a mathematicalbeauty in the sense
that they can be written compactly on a few lines. However, they are complicated to
treat both analytically and numerically and usually they have to be simplified both
geometrically (from 3D to 2D or even 1D) and analytically (by introducing simpli-
fying modeling assumptions ) before numerical treatment is possible.
In this section, initial and boundary conditions are omitted as they can be of very
many different types. Examples of initial and boundary conditions are shown in the
chapters to follow.
5.3.1
Navier–Stokes Equations for Incompressible Flow
Navier–Stokes equations are fundamental in aerodynamics, hydrodynamics,
meteorology, and other applications where the flow of a gas or a liquid is modeled.
They are based on Newton’s second law for deformable bodies together with a
constitutive equation stating that the shear stresses are proportional to the velocity
gradients. The equations are complicated in their most general form. Therefore, they
are here presented under the condition that the density 𝜌(kg∕m3) and the dynamic
viscosity 𝜇(N ⋅s∕m2) of the fluid are constant:
div u = 0
(5.26a)
𝜌
(𝜕u
𝜕t + (u ⋅∇)u
)
= 𝜌g −∇p + 𝜇Δu
(5.26b)
In the PDEs (5.26), u = (u1, u2, u3)T (m∕s) is the velocity field of the flow, p (N∕m2)
the pressure in the flow, and g (m∕s2) the gravitational acceleration.
The first equation expresses conservation of mass and the second conservation of
linear momentum (Newton’s second law).
The equations (5.26) constitute four PDEs for the four unknowns u, v, w, and p in
incompressible flow (𝜌constant). The incompressible Navier–Stokes equations are

SOME PDEs IN SCIENCE AND ENGINEERING
115
nonlinear PDEs classified as mixed hyperbolic–parabolic. They were first derived by
the French physicist Louis Navier and the Irish mathematician George Stokes in the
beginning of the 19th century.
Associated with Navier–Stokes equation is Reynolds number Re, an important
dimensionless parameter Re = L ⋅U ⋅𝜌∕𝜇introduced by the Irish engineer Osborne
Reynolds in the second half of the 19th century. In the formula, L is a characteristic
length of the region and U a characteristic velocity. Reynolds number gives a charac-
terization of the flow. For small Re, say Re < 1, we have laminar flow while a large
Re number corresponds to turbulent flow. The numerical treatment of Navier–Stokes
equations for large Re-numbers is difficult as both turbulence and moving transition
layers make it tricky to resolve the equations with a numerical method.
Depending on the physical assumptions, Navier–Stokes equations can be simpli-
fied to less complex PDEs. For a small Reynolds number corresponding to, e.g., slow
velocity or large viscosity, the Navier–Stokes equations in steady (time-independent)
flow are reduced to Stokes equations
𝜇Δu −∇p + 𝜌g = 0,
div u = 0
(5.27)
This is an elliptic problem consisting of four equations for the four unknowns
u = (u, v, w)T and p.
In case the flow can be regarded as irrotational, nonviscous, and steady, it is called
potential flow. The reason is that if curl u = 0, there is a potential function Φ such
that u = ∇Φ. This relation together with div u = 0 gives Laplace equation for Φ
ΔΦ = 0
(5.28)
When appropriate BCs has been added to (5.28), the flow field is obtained from the
solution Φ from u = ∇Φ. We see that the pressure p is not present in this flow model.
In 2D, a lot of analysis has been donewith conformalmapping,i.e., transformationsin
the complex plane. An example of potential flow is given in Chapter 7, Example 7.2.
Yet another simplification of Navier–Stokes equations is obtained for steady, non-
viscous, and irrotational flow with Bernoulli’s equation
1
2𝜌U2 + p = constant
(5.29)
This often used model for, e.g., large pipe systems where the wall-friction is neglected
is not even a differential equation. It gives no information about the flow field, just
the size of the velocity U. Newton’s second law is not needed to derive this equation,
just hydrostatical relations.
5.3.2
Euler’s Equations for Compressible Flow
Often variants of the Navier–Stokes equations are used depending on the physical
process to be modeled. For a compressible gas (𝜌not constant) and inviscid (without
inner friction, i.e., 𝜈= 0), we have the compressible Euler equations:
𝜕𝜌
𝜕t + div(𝜌u) = 0
(5.30a)

116
PARTIAL DIFFERENTIAL EQUATIONS
𝜕(𝜌u)
𝜕t
+ div(𝜌uuT) + ∇p = 0
(5.30b)
𝜕E
𝜕t + div((E + p)u) = 0
(5.30c)
E =
p
𝛾−1 + 1
2𝜌(u2
1 + u2
2 + u2
3)
(5.30d)
where uuT is the outer product, u = (u1, u2, u3)T, and (uu)ij = uiuj. The quantity
E (J∕m3) is the total energy density and 𝛾is a constant depending on the gas studied
(𝛾= 1.4 for air).
The equations (5.26) constitute five PDEs and one algebraic equation for the six
unknowns 𝜌, u1, u2, u3, E, and p. The equations were first derived by Leonard Euler in
1755. They are hyperbolic and the solutions can contain propagating shocks, narrow
regions separating continuous flow regions. Across the shock, there are rapid changes
in pressure, velocity, and density. The resolution of shocks puts special demands on
the numerical methods.
5.3.3
The Convection–Diffusion–Reaction Equations
The convection–diffusion–reaction equations (CDR equations) model processes
where the transport of chemical substances and energy is governed by convection,
diffusion, and reactions. Coupled to the mass conservation equations, expressed in
units of concentrations, there is an energy conservation equation formulated for the
temperature.
𝜕c
𝜕t + div (cuT) = div (D∇c) + Sr(c, T)
(5.31a)
𝜌C
(𝜕T
𝜕t + div (Tu)
)
= div (𝜅∇T) + ΔHT Sr(c, T)
(5.31b)
In the CDR equations (5.31), c (mol∕m3) is a vector of concentrations of the chemical
substances taking part in a set of reactions, u (m/s) the velocity field (usually assumed
to be known, otherwise the CDR equations must be coupled to the Navier–Stokes
equations), 𝜌(kg∕m3) the density of the mixture, D (m2∕s) the diffusion coefficient
(or the diffusion matrix), r[mol∕(m3 ⋅s)] the reaction rate terms (see Chapter 2),
S the stoichiometric matrix, T(K) the temperature, C[J∕(kg ⋅K)] the heat capacity,
𝜅[J∕(m ⋅K ⋅s)] the heat conduction coefficient and ΔH(J∕mol) the enthalpies of the
reactions, ΔHi < 0 if the reaction is endotermic (energy consuming), and ΔHi > 0 if
the reaction is exotermic (energy producing).
The CDR equations model processes in chemical engineering, e.g., combustion,
industrial reactors,and environmentalprocesses such as atmosphericchemistry.From
these equations, the variations in substance concentrations and temperature of a pro-
cess can be computed. The PDEs are parabolic–hyperbolic and often stiff and non-
linear with a jacobian being large and sparse.

SOME PDEs IN SCIENCE AND ENGINEERING
117
5.3.4
The Heat Equation
The heat equation is a special case of the CDR equations above.
𝜕T
𝜕t = div (𝛼∇T) + Q(x, y, z)
(5.32)
where 𝛼(m2∕s) is the thermal diffusivity and Q(x, y, z) (K∕s) a source or sink term
that accounts for the heat production or consumption in the medium.
The heat equation was formulated in 1807 by the French physicist Joseph Fourier.
He also invented a method for analytical solution of this equation in some cases,
known as the Fourier method, published 1822.
5.3.5
The Diffusion Equation
The diffusion equation is mathematically similar to the heat equation, also being a
special case of the CDR equations.
𝜕c
𝜕t = div (D∇c) + q(x, y, z)
(5.33)
where c (mol∕m3) is the concentration of the substance being diffused, D (m2∕s) the
diffusion coefficient, and q(x, y, z) [mol∕(m3 ⋅s)] a source or sink term that accounts
for substance production or consumption.
The diffusion equation, also called Fick’s second law, was formulated in 1855 by
the German physicist Adolf Fick.
5.3.6
Maxwell’s Equations for the Electromagnetic Field
Maxwell’s equations model the relation between the electric and magnetic fields gen-
erated by electric charges.
curl H = j + 𝜕D
𝜕t
(5.34a)
curl E = −𝜕B
𝜕t
(5.34b)
In the PDEs (5.34), H is the magnetic field strength (A∕m), E the electric field
strength (V/m), B the magnetic flux density (Vs/m2), D the electric flux den-
sity (As/m2), and j the current density (A/m2). Maxwell’s equations consist of
6 equations and 12 unknowns, H, E, B, and D. The missing equations are 6
constitutive equations, i.e., the relation between the electric variables and the
magnetic variables, e.g., the equations valid in vacuum D = 𝜖0E and B = 𝜇0H,
where 𝜖0 and 𝜇0 are the electric permittivity and magnetic permeability. If j is
given, Maxwell’s equations can be solved assuming suitable ICs and BCs are
provided.

118
PARTIAL DIFFERENTIAL EQUATIONS
The equations (5.34) were first invented by the Scottish physicist James Maxwell
in 1867. Maxwell’s equations are hyperbolic.
The following equation, known as the charge continuity equation, is fundamental
𝜕𝜌
𝜕t + div j = 0
(5.35)
where 𝜌is the electric charge density (As/m3).
Two more equations are usually associated with Maxwell’s equations
div B = 0
(5.36a)
div D = 𝜌
(5.36b)
These equations are consequences of (5.34) and (5.35) under suitable assumptions.
The force acting on an electric particle with charge q in an electromagnetic field
is given by the Lorentz-force expression
F = q(E + v × B)
(5.37)
If j = 0, Maxwell’s equations in vacuum are
curl H = 𝜖0
𝜕E
𝜕t
(5.38a)
curl E = −𝜇0
𝜕H
𝜕t
(5.38b)
From these two equations, the following PDE is derived
ΔE −1
c2
𝜕2E
𝜕t2 = 0
(5.39)
and a similar equation for H. The parameter c (m/s) is the wave propagation speed
c = (𝜖0𝜇0)−1∕2, speed of light 299792458m/s. The equation (5.39) is called the vector
wave equation and is a system of hyperbolic PDEs. The solutions are usually smooth,
but numerical methods are time consuming as very many periods have to be computed
to follow the rays and each period must be accurately enough represented.
5.3.7
Acoustic Waves
The propagation equation for acoustic waves has the form
Δp −1
c2
𝜕2p
𝜕t2 = 0
(5.40)
where p (N/m2) is the pressure and c (m/s) the speed of sound.
Equation (5.40) is a scalar wave equation, a hyperbolic PDE. It is similar to the
equation for a vibrating string, presented in Chapter 9.

SOME PDEs IN SCIENCE AND ENGINEERING
119
5.3.8
Schrödinger’s Equation in Quantum Mechanics
Schrödinger’s equation models the wave nature of small particles, e.g., electrons and
atoms.
−ℏ2
2mΔΨ + V(r, t)Ψ = iℏ𝜕Ψ
𝜕t
(5.41)
where ℏ= h∕2𝜋, h is the Planck’s constant = 6.626068m2 ⋅kg/s, m the mass of the
particle, and V(r, t) a potential function that affects the movement of the particle.
This equation is hyperbolic and was first proposed by the Austrian physicist Erwin
Schrödinger in 1926.
In (5.41), Ψ(r, t) is a complex wavefunction, representing a propagating wave for
a particle. This function is used to compute the probability of finding the particle in
a certain domain in space. The solutions of the Schrödinger equation are oscillating
and usually very smooth. The computational complexity increases immensely with
the number of particles studied.
Often the interest is not directed to the wave function Ψ itself but rather to the
possible energy levels E of the particle,e.g., the electron states of an atom or molecule,
leading to eigenvalue problems of the type
(
−ℏ2
2mΔ + V(r)
)
Ψ = EΨ
(5.42)
The computation of the E values must be done with high accuracy in order to be able
to distinguish between the energy levels. This puts certain requirements on the grid
used in the discretization of (5.42).
5.3.9
Navier’s Equations in Structural Mechanics
Navier’s equations are the fundamental PDEs in elasticity theory. They model the
deformations of a linearly elastic body that is exposed to external forces
𝜌𝜕2u
𝜕t2 =
E
2(1 + 𝜈)
(
Δu +
1
1 −2𝜈∇(div u
)
+ f
(5.43)
These equations are hyperbolic and were formulated by Louis Navier in France 1821.
In case the problem is time independent, the equations are elliptic.
In (5.43), u is the displacement vector, i.e., u = (u, v, w)T, where u (m) is the dis-
placement in the x direction, v (m) in the y direction, and w (m) in the z direction. E
(N/m2) is the elasticity module, 𝜈[] the contraction parameter (also called Poisson’s
number), f (N/m3) the force field acting on the body responsible for the displace-
ments, and 𝜌(kg/m3) the density of the body.

120
PARTIAL DIFFERENTIAL EQUATIONS
5.3.10
Black–Scholes Equation in Financial Mathematics
The Black–Scholes equation presented in 1973 models the value u of a European
stock option
𝜕u
𝜕t + 1
2𝜎2x2 𝜕2u
𝜕x2 + rx𝜕u
𝜕x −ru = 0
(5.44)
where x is the underlying asset value, r the continually compounding interest rate,
and 𝜎the volatility (standard deviation of the rate of return of the asset).
Exercise 5.3.1. Verify that Navier–Stokes equation (5.26) in 1D is
𝜌
(𝜕u
𝜕t + u𝜕u
𝜕x
)
= −𝜕p
𝜕x + 𝜇𝜕2u
𝜕x2 + 𝜌f
Exercise 5.3.2. In case p = 0 and f = 0 in Exercise 5.3.1, we obtain Burger’s
equation
𝜕u
𝜕t + u𝜕u
𝜕x = 𝜈𝜕2u
𝜕x2
where the parameter 𝜈= 𝜇∕𝜌is the kinematic viscosity.
a) Is this PDE elliptic, parabolic, or hyperbolic?
b) If 𝜕u
𝜕t = 0, the problem is time independent. Solve the ODE with the BCs
u(0) = 1,
du
dx(0) = 0
c) With the transformation
u = −2𝜈1
v
𝜕v
𝜕x,
the nonlinear PDE is transformed into a linear PDE
𝜕v
𝜕t = 𝜈𝜕2v
𝜕x2 + C(t)v.
Exercise 5.3.3. Formulate Euler’s equations (5.30) in 1D.
Exercise 5.3.4. Formulate the CDR equation in 1D assuming that there is only one
chemical substance with concentration c involved, T is constant, and the rate function
is given by r(c) = kc, where k is the rate constant. In chemical engineering,this model
is known as the tubular reactor model.

NUMERICAL SOLUTION OF PDES, SOME GENERAL COMMENTS
121
Exercise 5.3.5. Formulate the heat equation in 2D, cylindrical coordinates.
Exercise 5.3.6. Show that Maxwell’s equation (5.38a) and (5.38b) for plane waves
propagating in the x direction with the only components Ez ≠0 and Hy ≠0 satisfy
the PDE system
𝜕Hy
𝜕t
= 1
𝜇0
𝜕Ez
𝜕x
𝜕Ez
𝜕t = 1
𝜖0
𝜕Hy
𝜕x
Also show that both Ez and Hy satisfy the wave equation.
5.4
INITIAL AND BOUNDARY CONDITIONS FOR PDEs
The PDEs presented in Section 5.3 have all been given without initial or boundary
conditions. Such conditions are needed for a unique solution and hence necessary for
numerical computation. Initial conditions define the state of a system at time t = 0.
Boundary conditions specify the state of a problem against the environment. If the
space domain is infinite, a Cauchy problem, it must be truncated to a finite domain
before numerical treatment.
Boundary conditions can be of different types, e.g., Dirichlet, Neuman, mixed,
periodic, numerical, absorbing, and reflecting. Examples of such conditions are pre-
sented in the chapters to follow.
For a given PDE, the initial and boundary conditions cannot be given arbitrarily;
they should be given so that the problem is well posed. This means that the solution
is continuous with respect to the given conditions.
5.5
NUMERICAL SOLUTION OF PDES, SOME GENERAL COMMENTS
When solving ODEs, there are some general methods, e.g., explicit and implicit
Runge–Kutta methods, that could be applied to most problems, nonstiff and stiff ODE
systems. The situation is different with PDEs. The classification (parabolic, elliptic,
hyperbolic) determines the type of method that should be used. Some comments on
numerical properties for linear PDEs are given below. For nonlinear PDEs, there will
be additional difficulties of various types.
A parabolic PDE can be approximated by an ODE system, being large, sparse, and
stiff, i.e., implicit methods are needed where the sparsity must be taken into account.
An elliptic PDE can be approximated by a large system of algebraic equations,
being very sparse, i.e., numerical methods specially designed for such equations are
needed.
A hyperbolic PDE needs special attention as a solution may contain a propagating
discontinuity. Special methods are needed to capture the discontinuity and to properly
conserve different quantities.

122
PARTIAL DIFFERENTIAL EQUATIONS
BIBLIOGRAPHY
Mathematical textbooks on PDEs
1. S.J. Farlow, “Partial Differential Equations for Scientists and Engineers”, Wiley, 1982
2. F. John, “Partial Differential Equations”, Springer, 1991
3. A.D. Snider, “Partial Differential Equations, Sources and Solutions”, Prentice Hall, 1999
4. H.F. Davis, A.D. Snider, “Introduction to Vector Analysis”, Quantum, 1995
Textbooks on mathematics and mathematical models in science and engineering
5. Courant, Hilbert, “Methods of Mathematical Physics”, Interscience, 1955
6. K. Eriksson, D. Estep, C. Johnson, “Applied Mathematics: Body and Soul I-III, Springer,
2004
7. Lin, Segel, “Mathematics Applied to Deterministic Problems in the Natural Sciences”,
Macmilan, 1974

6
NUMERICAL METHODS FOR
PARABOLIC PARTIAL
DIFFERENTIAL EQUATIONS
Parabolic partial differential equations (PDEs) are frequently encountered in mathe-
matical models for heat transfer and diffusion. Their solutions reflect the underlying
physics, such as the dissipative nature of heat transfer.
A fundamental property of solutions to parabolic PDEs is that information travels
with infinite speed in the sense that an initial value immediately effects the solution
in other space points. Solutions to parabolic PDEs are stable and initial peaks are
smoothed out when integrated in one of the t-directions (say t > 0) but ill posed in
the other direction (t < 0).
Parabolic PDEs have a natural coupling to systems of ordinary differential
equations (ODEs). Discretization of the space derivatives with the finite difference
method (FDM) or with the finite element method (FEM) leads to stiff ODE systems.
In Chapter 5, the generic parabolic PDE problem in 1D was introduced. In this
chapter, this PDE is used as a model problem for various numerical methods, i.e.,
𝜕u
𝜕t = 𝜅𝜕2u
𝜕x2 ,
0 < x < 1,
0 < t ≤tend,
𝜅> 0
(6.1a)
with Dirichlet boundary conditions (BCs)
u(0, t) = 𝛼(t),
u(1, t) = 𝛽(t)
(6.1b)
and an initial condition (IC)
u(x, 0) = u0(x)
(6.1c)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

124
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
0
0.5
1
x
0
0.05
t
u (x, 0) = u0 (x)
u (0, t) = α(t)
u (1, t) = β(t)
Ω
Figure 6.1
Region of definition, Ω, in the x – t plane
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0
0.2
0.4
0.6
0.8
1
x
u (x, t)
t
Figure 6.2
3D visualization of a solution u(x, t) of the heat equation
Geometrically the solution u(x, t) will be a surface above the region of defini-
tion Ω = {(x, t),
0 ≤x ≤1,
0 ≤t ≤tend} (see Figure 6.1). With the IC function
u0(x) = sin(𝜋x) and the BC functions 𝛼(t) = 0 and 𝛽(t) = 0, the graph of the solution
(for 𝜅= 1) is shown in Figure 6.2.

APPLICATIONS
125
An important generalization of (6.1) is to include space dependence in the heat
conduction coefficient 𝜅(x) and a driving function f(x, t) (or f(x)) in the right hand
side. We then have the inhomogeneous heat equation
𝜕u
𝜕t = 𝜕
𝜕x
(
𝜅(x)𝜕u
𝜕x
)
+ f(x, t),
0 ≤x ≤1,
t ≥0
(6.2)
The steady-state solution of (6.2) is obtained when t →∞. In the steady-state case,
there is no time variation in the solution. Therefore, the steady-state solution satisfies
the boundary value problem (BVP)
−d
dx
(
𝜅(x)du
dx
)
= f(x),
u(0) = 𝛼0,
u(1) = 𝛽0
(6.3)
where 𝛼0 and 𝛽0 are constants and f(x) a function that is time independent. Compare
with the model problem in (4.20).
6.1
APPLICATIONS
The occurrence of parabolic PDEs in application problems is now demonstrated on
some examples.
Example 6.1.
(Time-dependent 1D flow in a pipe). Consider the boundary value
problems (BVP) in Example 4.1. Now assume that the temperature of the fluid has
not come to a steady state (Figure 6.3) but is passing through a time-dependent tran-
sient from a given IC. The model for the temperature T(z, t) (K) is changed into
the PDE
𝜌C𝜕T
𝜕t + 𝜌Cv𝜕T
𝜕z = 𝜕
𝜕z
(
𝜅𝜕T
𝜕z
)
−2h
R (T −Tout),
0 < z < L,
t > 0
(6.4)
with IC
T(z, 0) = Tinit(z)
and BCs
T(0, t) = T0,
−𝜅𝜕T
𝜕z (L) = k(T(L) −Tout)
z
A
A
T (z, t)
Figure 6.3
Hot flow in a cylindrical pipe

126
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
The only new variable and parameter introduced in this model compared to the model
in Example 4.1 is time t (s) and the initial value Tinit(z) (K). We see that when steady
state is reached (t →∞), the first term drops out, the IC is not necessary, and the PDE
problem turns into the BVP (4.10).
Example 6.2.
(Time-dependent 2D flow in a pipe). Consider again the flow in a
pipe model but now assume that heat is transported by diffusion both in the z- and in
the r directions. The model for the temperature T(z, r, t) (K) is modified to
𝜌C𝜕T
𝜕t + 𝜌Cv𝜕T
𝜕z = 𝜅𝜕2T
𝜕z2 + 𝜅
r
𝜕
𝜕r
(
r𝜕T
𝜕r
)
,
0 < z < L, 0 < r < R, t > 0
(6.5)
with IC
T(z, r, 0) = Tinit(z, r),
0 ≤z ≤L, 0 ≤r ≤R
and BCs for z = 0 and z = L
T(0, r, t) = T0,
T(L, r, t) = Tout,
0 ≤r ≤R, t ≥0
and BCs for r = 0 and r = R (Figure 6.4)
𝜕T
𝜕r (z, 0, t) = 0,
−𝜅𝜕T
𝜕r (z, R, t) = k(T(z, R, t) −Tout),
0 ≤z ≤L, t ≥0
Note that the heat loss through the wall is now implemented as a BC at r = R.
Exercise 6.1.1. Formulate the steady-state problem of the PDE (6.5). The solution
will depend on z and r, i.e., T = T(z, r). Classify the PDE, i.e., is it parabolic, elliptic,
or hyperbolic?
0
0.5L
L
z
0
R
r
k = ∂r
∂T (z, R, t) = k (T (z, R, t) − Tout)
T (0, r, t) = T0
T (L, r, t) = Tout
∂r
∂T (z, 0, t) = 0
−
Figure 6.4
2D model of time-dependent flow in a pipe

AN INTRODUCTORY EXAMPLE OF DISCRETIZATION
127
Example 6.3.
(Time-dependent 1D tubular reactor model). Consider again a
cylindrical pipe but this time it is called a tube in accordance with the nomen-
clature in chemical engineering. A fluid is transported through the tube of
length L (m) with an exothermal reaction going on in it. Simplifying the general
convection-diffusion-reaction(CDR) equations in Section 5.3.3 to only one chemical
species concentration c (mol/m3) and a given constant flow speed v (m/s) gives the
following system of two PDEs:
𝜕c
𝜕t + v𝜕c
𝜕z = 𝜕
𝜕z
(
D𝜕c
𝜕z
)
−Ae−E∕RTc
(6.6a)
𝜌C𝜕T
𝜕t + 𝜌Cv𝜕T
𝜕z = 𝜕
𝜕z
(
𝜅𝜕T
𝜕z
)
+ ΔHAe−E∕RTc
(6.6b)
where units of the variables c, T, z, t and parameters v, 𝜌, C, D, 𝜅, ΔH, A, E, and R
are explained in Sections 2.4.4 and 5.3.3. The PDE system (6.6) is nonlinear due to
the term Ae−E/RTc.
In addition to the PDE (6.6), suitable ICs and BCs have to be given, e.g.,
c(z, 0) = cinit(z),
T(z, 0) = Tinit(z)
and
c(0, t) = c0, T(0, t) = T0,
𝜕c
𝜕z (L, t) = 0, 𝜕T
𝜕z (L, t) = 0
Exercise 6.1.2. Formulate the steady-state problem of (6.6) with suitable BCs.
If the steady-0 state model is reduced further so that T is assumed to be constant,
formulate the corresponding BVP with BCs.
6.2
AN INTRODUCTORY EXAMPLE OF DISCRETIZATION
When using the FDM to solve the parabolic problem (6.1) for 𝜅= 1, we can follow
the workscheme introduced in Chapter 4, i.e.,
DG—Discretize the region of definition Ω by using the stepsize hx for the x-axis
and the stepsize ht for the t-axis:
xi = ihx,
i = 0, 1, 2, … , N + 1,
tk = kht,
k = 0, 1, 2, …
A rectangular grid is defined (see Figure 6.5).
DD—Discretize the differential equation (6.1). Denote by ui, k the numerical solu-
tion of the problem at the point (xi, tk), i.e., u(xi, tk) ≈ui, k. Use the explicit

128
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
0
0.5
1
x
0
0.05
t
hx
ht
Figure 6.5
2D grid of Ω
Euler approximation for the time derivative
𝜕u
𝜕t (xi, tk) =
ui,k+1 −ui,k
ht
+ ht
(6.7)
and the central difference approximation for the space derivative
𝜕2u
𝜕x2 (xi, tk) =
ui+1,k −2ui,k + ui−1,k
h2
x
+ h2
x
(6.8)
and we obtain the following recursion formula for the heat equation:
ui,k+1 −ui,k
ht
=
ui+1,k −2ui,k + ui−1,k
h2x
(6.9)
This FDM can also be referred to as the FTCS method (forward-time-central-
space).
Introduce the stepsize parameter 𝜎= ht∕h2
x and (6.9) can be written as
ui,k+1 = 𝜎ui−1,k + (1 −2𝜎)ui,k + 𝜎ui+1,k
(6.10)
There is an appealing visualization of this formula as a stencil (also called a
difference star or computational molecule) (see Figure 6.6). For FDMs, there
is always such a stencil showing which ui, k values at the time level k (and/or
earlier time levels) that are to be combined to give the ui, k+1 values at the time
level k + 1.

AN INTRODUCTORY EXAMPLE OF DISCRETIZATION
129
1−
2σ
σ
σ
Figure 6.6
Stencil for the heat equation
DB—Discretize the IC and BCs. For problem(6.1),the IC and BCs are represented
exactly
ui,0 = u0(xi),
u0,k = 𝛼(tk),
uN+1,k = 𝛽(tk)
(6.11)
In Figure 6.1, the corresponding grid points where these conditions are given
are situated on the boundary 𝜕Ω.
Observe, however, that if we have BCs containing derivatives, they have to be
represented approximately (see Section 6.3).
After this discretization, the stencil is moved along the grid pattern from the lower
left corner row by row from left to right up to the upper right corner according to
Figure 6.7. After this computation,the ui, k values can be plotted above the grid, hence
visualizing the solution just as in the solution graph (6.2). Observe that all values at
the new time level can be computed simultaneously.
Exercise 6.2.1. Write a program giving the solution in Figure 6.2 using the method
(6.10). Use the stepsizes hx = 0.1, ht = 0.001.
0
.
0.5
1
x
0
0.05
t
1–
2σ
σ
σ
Figure 6.7
Stencil moving along the grid

130
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
6.3
THE METHOD OF LINES FOR PARABOLIC PDES
The Method of Lines (MoL) is based on the FDM and can be characterized as a gen-
eral method for numerical solution of time-dependent PDEs. In the MoL, the space
derivatives are discretized, but the time derivatives are kept. This principle of approx-
imation is referred to as semi-discretization.
6.3.1
Solving the Test Problem with MoL
For the generic parabolic problem (6.1), semi-discretization means that u(xi, t) ≈ui(t)
where ui(t) is a time-dependent solution function associated to the space point xi,
where the ui(t) function satisfies the ODE (𝜅= 1)
dui(t)
dt
= ui+1(t) −2ui(t) + ui−1(t)
h2
x
,
ui(0) = u0(xi),
i = 1, 2, … , N
(6.12)
For i = 1 and i = N, the BCs enter as driving functions
du1(t)
dt
= u2(t) −2u1(t) + 𝛼(t)
h2
x
,
u1(0) = u0(x1)
(6.13)
duN(t)
dt
= 𝛽(t) −2uN(t) + uN−1(t)
h2x
,
uN(0) = u0(xN)
(6.14)
In Figure 6.8, the lines of definition for the solution curves are shown.
The ODEs (6.12)–(6.14) above can be written in matrix form
du
dt = Tu + b(t),
u(0) = u0
(6.15)
0
0.5
1
x
0
0.5
t
u (0, t) = α(t)
u (x1, t) = u1(t)
u (x2, t) = u2(t)
u (xi, t) = ui(t)
u (1, t) = β(t)
Figure 6.8
Grid for a MoL discretization

THE METHOD OF LINES FOR PARABOLIC PDES
131
where
T = 1
h2
x
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
−2
1
0
…
0
1
−2
1
⋱
⋮
0
⋱
⋱
⋱
0
⋮
⋱
1
−2
1
0
…
0
1
−2
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
(6.16)
and
b(t) = 1
h2
x
⎛
⎜
⎜
⎜
⎜⎝
𝛼(t)
0
0
⋮
𝛽(t)
⎞
⎟
⎟
⎟
⎟⎠
,
u(0) =
⎛
⎜
⎜
⎜
⎜⎝
(u0x1
u0(x2)
u0(x3)
⋮
u0(xN)
⎞
⎟
⎟
⎟
⎟⎠
(6.17)
Hence, the ODE system is linear with constant coefficients. The tridiagonal matrix T
differs from the tridiagonal matrix A in (4.29) by a scalar factor
T = −1
h2x
A = 1
h2x
tridiag(1, −2, 1)
(6.18)
where the notation tridiag is also used in Section 4.2.
In Section A.2, the eigenvalues of A are calculated exactly and the values are
𝜆j(A) = 4sin2
(
j𝜋
2(N + 1)
)
Hence, the eigenvalues of T are
𝜆j(T) = −4
h2
x
sin2
(
j𝜋
2(N + 1)
)
,
j = 1, 2, … , N
(6.19)
Since the x interval is discretized with constant stepsize hx according to hx(N + 1) = 1,
𝜆j(T) can be written as
𝜆j(T) = −4
h2
x
sin2
(j𝜋hx
2
)
,
j = 1, 2, … , N
(6.20)
We see that all eigenvalues of T are real, negative, and of very different magnitude in
the range from approximately −𝜋2 (for j = 1) to −4∕h2
x (for j = N). Hence, (6.15) is
a stiff system of ODEs.
If Euler’s explicit method is used to solve (6.15), we get the recursion formula
uk+1 = uk + ht(Tuk + b(tk)),
u0 = u(0)
(6.21)
Figure 6.2 is generated with Euler’s explicit method, which is equivalent to the stencil
method based on formula (6.10).

132
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
In Chapter 3, the stability areas of some methods for IVP are shown. For the
explicit Euler method, the stepsize in time, here denoted by ht, must fulfill the
condition
ht 𝜆j ∈SEE,
→
ht
4
h2
x
≤2,
→
ht
h2
x
≤1
2
(6.22)
Hence, the time step ht must be quadratically smaller than the space step hx, which
puts a very severe restriction on ht, making the explicit Euler method very inefficient
for parabolic PDEs.
Violating this stepsize criterion will give a very dramatic numerical solution,
which is wrong of course (see Figure 6.9). The stability result (6.22) is based on the
eigenvalues of the matrix T and is therefore called eigenvalue stability. In Section
8.3, another method based on Fourier analysis is presented. This kind of stability
analysis is called von Neumann stability, named after the Hungarian-American
mathematician John von Neumann, active in the middle of the 20th century. The
results from the von Neumann stability analysis are the same as the eigenvalue
stability for parabolic PDEs (see Section A.6). However, in Chapter 8, hyperbolic
PDEs, the von Neumann analysis is the only adequate stability analysis.
Using a stiff method gives stable numerical solutions for large time steps
ht. For the implicit Euler method (also called the BTCS method from
u(x, t)
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
−1
−0.5
0
0.5
1
x
t
Figure 6.9
Unstable numerical solution of the heat equation

THE METHOD OF LINES FOR PARABOLIC PDES
133
backward-time-central-space), we get the recursion formula
uk+1 = uk + ht(Tuk+1 + b(tk+1)),
u0 = u(0)
(6.23)
After rearrangement, we get a linear system of equations to solve
(I −htT)uk+1 = uk + htb(tk+1)
(6.24)
The matrix (I −htT) is tridiagonal, symmetric, and positive definite
I −htT = tridiag(−𝜎, 1 + 2𝜎, −𝜎)
(6.25)
where 𝜎= ht∕h2
x. However, the accuracy in the uk values is poor, since implicit Euler
is only first order.
An often-used method for the heat/diffusion equation is Crank – Nicolson’s
method. John Crank and Phyllis Nicolson were British mathematicians and the
method was introduced around 1950. The Crank – Nicolson method is of second
order in both the x and the t directions. In fact, this method is based on the trapezoidal
method for solving (6.15)
uk+1 = uk + ht
2 (Tuk + b(tk) + Tuk+1 + b(tk+1)),
u0 = u(0)
(6.26)
On inspection, we see that the trapezoidal method can be regarded as a combination
of the explicit and the implicit Euler methods. The trapezoidal method will also give
a tridiagonal system of linear algebraic equations to be solved in each time step
(
I −ht
2 T
)
uk+1 =
(
I + ht
2 T
)
uk + ht
2 (b(tk+1) + b(tk))
(6.27)
Crank – Nicolson’s method is stable for all time steps ht and spacesteps hx, but if ht is
too large compared to hx, there will be damped oscillations in the numerical solution
as is seen in the Figure 6.10(a). If ht is small enough, we get a smooth solution (b).
Exercise 6.3.1. Give the stencils corresponding to the implicit Euler method and
the Crank – Nicolson method.
Exercise 6.3.2. Consider the following system of parabolic PDEs:
𝜕c1
𝜕t = D11
𝜕2 c1
𝜕x2
+ D12
𝜕2 c2
𝜕x2
𝜕c2
𝜕t = D21
𝜕2 c1
𝜕x2
+ D22
𝜕2 c2
𝜕x2

134
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
0
5
10
0
0.5
1
−1
0
1
0
0.5
1
0
0.5
1
0
0.5
1
t
x
(a)
(b)
Figure 6.10
Crank – Nicolson’s method
with ICs
c1(x, 0) = c10,
c2(x, 0) = c20
and BCs
c1(0, t) = 1, c2(0, t) = 1,
𝜕c1
𝜕x (1, t) = 0, 𝜕c2
𝜕x (1, t) = 0
The parameters Dij, i = 1, 2, j = 1, 2 are constants. Use the MoL to discretize the
PDE system into a system of ODEs. Follow the DG, DD, and DB recipe and give the
answer in the form
dc
dt = Ac + b,
c(0) = c0
The structure of A depends on in which order the components of c1 and c2 are sorted.
Try to find the way of sorting that gives the smallest bandwidth of A.
A more effective way to solve the ODE system (6.15) is to use some higher order
method for stiff ODEs, such as the BDF method, described in Chapter 3. Parabolic
PDEs are often solved in this way and the efficiency is taken into account by utilizing
the sparse structure of the jacobian (often tridiagonal) of the ODE system obtained
after space discretization.
6.3.2
Various Types of Boundary Conditions
Common BCs for parabolic PDEs are of the same type as the BCs for a second-order
BVP (see Chapter 4). Assume that x = a is a boundary point:
• If u is specified at x = a, we have a Dirichlet condition
u(a, t) = 𝛼(t)
(6.28)

THE METHOD OF LINES FOR PARABOLIC PDES
135
• If 𝜕u/𝜕x is specified at x = a, we have a Neumann condition
𝜕u
𝜕x (a, t) = 𝛾(t)
(6.29)
• If a linear combination of u and 𝜕u/𝜕x is specified at x = a, we have a Robin
condition (also called mixed or generalized Neumann condition)
𝜕u
𝜕x (a, t) = 𝜇(u(a, t) −uout(t))
(6.30)
where 𝜇is a constant and uout(t) is a given function.
• An example of a nonlinear BC is the heat radiation condition
𝜕u
𝜕x (a, t) = 𝜆(u4(a, t) −u4
out(t))
(6.31)
In connection with the heat equation, all the BCs given above have a physical
meaning in terms of the temperature:
• The Dirichlet BC means that the temperature 𝛼(t) is known at the boundary
point x = a.
• The Neumann condition means that the heat flux is known at the boundarypoint.
The special case
𝜕u
𝜕x (a, t) = 0
(6.32)
means that the point x = a is isolated from the environment.
• The mixed condition means that the heat flux is proportional to the temperature
difference u(a, t) −uout(t).
• The nonlinear BC given above corresponds to heat radiation at the point x = a
according to Stefan – Boltzmann’s law.
6.3.3
An Example of the Use of MoL for a Mixed Boundary Condition
The handling of BCs containing derivatives for parabolic PDE problems is similar to
their treatment for two-point BVPs.
Given the model problem (6.1a), 𝜅= 1, with one Dirichlet and one mixed BC
𝜕u
𝜕t = 𝜕2u
𝜕x2 ,
u(0, t) = 𝛼(t),
𝜕u
𝜕x (1, t) = 𝜇(u(1, t) −uout(t))
(6.33)
we make a discretization with the MoL. Introduce an extra grid point after the right
boundary point
0
hx
1
x0
x1
xi−1
xi
xN−1
xN
xN+1
x
Hence, xi = ihx, i = 0, 1, 2, … , N + 1, where hx = 1/N.

136
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
The ODE system is as in (6.12)
dui
dt = 1
h2
x
(ui+1 −2ui + ui−1),
i = 1, 2, … , N
At the point x1 = h, we get after inserting the BC (6.13)
du1
dt = 1
h2
x
(u2 −2u1 + 𝛼(t))
At the last point xN = 1, we have both an ODE and a discretized BC
duN
dt
= 1
h2x
(uN+1 −2uN + uN−1)
(6.34)
uN+1 −uN−1
2hx
= 𝜇(uN −uout(t))
(6.35)
If uN+1 is eliminated, the last ODE is
duN
dt
= 1
h2
x
(2uN−1 −(2 −2hx𝜇)uN −2hx𝜇uout(t))
(6.36)
We now have a system of N ODEs for the N dependent variables u1, u2, … , uN. ICs
must be given, i.e., ui(0) = u0(xi)
Exercise 6.3.3. Formulate the ODE system in Section 6.3 on the form
⋅u = Tu + b(t), i.e., find T and b.
a) The matrix T is not symmetric. Find a diagonal transformation u = Dv so that
the matrix D−1TD is symmetric.
b) Write a program for solving the ODE system in Section 6.3. Plot the solution.
6.4
GENERALIZATIONS OF THE HEAT EQUATION
6.4.1
The Heat Equation with Variable Conductivity
As indicated in (6.2), the parameter 𝜅cannot always be assumed to be constant in
applications. It can be, e.g., space dependent 𝜅= 𝜅(x)
𝜕u
𝜕t = 𝜕
𝜕x
(
𝜅(x)𝜕u
𝜕x
)
(6.37)

GENERALIZATIONS OF THE HEAT EQUATION
137
or temperature dependent 𝜅= 𝜅(u)
𝜕u
𝜕t = 𝜕
𝜕x
(
𝜅(u)𝜕u
𝜕x
)
(6.38)
In equation (6.37), the PDE is still linear, but in the (6.38), we have a nonlinear PDE
to solve.
In the linear case, we discretize the space-dependent part of the PDE with the
following second-order difference approximation:
𝜕
𝜕x
(
𝜅(x)𝜕u
𝜕x
)
(xi) = 1
hx
(
𝜅(xi+1∕2)ui+1 −ui
hx
−𝜅(xi−1∕2)ui −ui−1
hx
)
+ h2
x
= 1
h2
x
(
𝜅(xi+1∕2)ui+1 −(k(xi+1∕2) + 𝜅(xi−1∕2))ui + k(xi−1∕2)ui−1
)
+ h2
x
Hence, after applying MoL, we obtain the following system of ODEs:
du
dt = 1
h2
x
tridiag(𝜅(xi−1∕2) , −(𝜅(xi−1∕2) + 𝜅(xi+1∕2)) , 𝜅(xi+1∕2))u
(6.39)
i.e., a linear ODE system with a tridiagonal matrix.
In the nonlinear case, we use the same space discretization
𝜕
𝜕x
(
𝜅(u)𝜕u
𝜕x
)
(xi) = 1
hx
(
𝜅(ui+1∕2)ui+1 −ui
hx
−𝜅(ui−1∕2)ui −ui−1
hx
)
+ h2
x
= 1
h2x
(𝜅(ui+1∕2)ui+1 −(𝜅(ui+1∕2) + 𝜅(ui−1∕2))ui + 𝜅(ui−1∕2)ui−1
)
+ h2
x
The u values ui−1/2 and ui+1/2 are, according to the notation, values that are not given in
grid points. Therefore, we have to approximate them somehow. A simple symmetric
approximation giving second-order accuracy is to set them to the mean values of the
neighboring points, i.e.,
ui−1∕2 = ui−1 + ui
2
,
ui+1∕2 = ui + ui+1
2
Applying the MoL gives the following nonlinear ODE system:
du
dt = 1
h2x
tridiag
(
𝜅
(ui−1 + ui
2
)
, −
(
𝜅
(ui−1 + ui
2
)
+ 𝜅
(ui+1 + ui
2
))
,
𝜅
(ui+1 + ui
2
))
u(3)
(6.40)

138
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
When this system is discretized with a stiff method, e.g., implicit Euler, we obtain
a nonlinear system of algebraic equations to be solved at each time step, which is
accomplished with Newton’s method. In each iteration, the jacobian is tridiagonal.
6.4.2
The Convection – Diffusion – Reaction PDE
The following equation occurs frequently in chemical technology and is a hyper-
bolic – parabolic PDE (see Chapter 5) the CDR equations:
𝜕u
𝜕t + v𝜕u
𝜕x = D𝜕2u
𝜕x2 + r(u)
(6.41)
If v = 0, we have a parabolic problem. If D = 0 the problem is hyperbolic.
If the MoL is used to discretize the PDE, we obtain (with central differences)
du
dt = Tu + b(u),
u(0) given
(6.42)
where T is an unsymmetric tridiagonal matrix
T = tridiag
(
D
h2x
+
v
2hx
, −2D
h2x
, D
h2x
−
v
2hx
)
(6.43)
6.4.3
The General Nonlinear Parabolic PDE
A general formulation of a nonlinear scalar parabolic PDE is
𝜕u
𝜕t = f
(
x, t, u, 𝜕u
𝜕x, 𝜕2u
𝜕x2
)
,
t ≥0,
0 ≤x ≤1
(6.44)
Assuming Dirichlet conditions u(0, t) = g1(t), u(1, t) = g2(t), the MoL can be used
to discretize the problem to a system of nonlinear ODEs
dui
dt = f
(
xi, t, ui, ui+1 −ui−1
2h
, ui+1 −2ui + ui−1
h2
)
,
i = 1, 2, … , N
(6.45)
This system is of the form
du
dt = F(t, u),
u(0) = u0
(6.46)
and has a tridiagonal character, since the jacobian of the right hand side function is a
tridiagonal N × N matrix.

ANSATZ METHODS FOR THE MODEL EQUATION
139
6.5
ANSATZ METHODS FOR THE MODEL EQUATION
Ansatz methods can be applied to time-dependent PDEs. As for the heat equation,
we illustrate the ansatz method on the model problem
𝜕u
𝜕t = 𝜕2u
𝜕x2 + f(x),
u(0, t) = u(1, t) = 0,
u(x, 0) = u0(x)
(6.47)
The ansatz, uh(x, t), is based on a time-dependent linear combination of basis func-
tions
u(x, t) ≈uh(x, t) =
N
∑
j=1
cj(t)𝜑j(x)
(6.48)
where 𝜑j(x) are given functions fulfilling the BCs 𝜑j(0) = 0, 𝜑j(1) = 0. The coeffi-
cients cj(t) are to be computed so that uh(x, t) is a “good” approximation of u(x, t).
Inserting uh(x, t) into the PDE gives a residual function
r(x, t) = 𝜕uh
𝜕t −𝜕2uh
𝜕x2 −f(x)
=
N
∑
j=1
dcj
dt 𝜑j(x) −
N
∑
j=1
cj(t)
d2𝜑j
dx2 −f(x) ≠0
(6.49)
Now impose the condition that the residual function is orthogonal to the basis
functions for all t
∫
1
0
r(x, t)𝜑i(x) dx = 0,
i = 1, 2, … , N
(6.50)
This gives
N
∑
j=1
dcj
dt ∫
1
0
𝜑i(x)𝜑j(x) dx −
N
∑
j=1
cj(t) ∫
1
0
d2𝜑j
dx2 𝜑i(x) dx −∫
1
0
f(x)𝜑i(x) dx = 0
By partial integration, we obtain
−∫
1
0
d2𝜑j
dx2 𝜑i(x) dx = −
[
𝜑i
d𝜑j
dx
]1
0
+ ∫
1
0
d𝜑i
dx
d𝜑j
dx dx
Since 𝜑i(0) = 𝜑i(1) = 0, the outintegrated term disappears and we finally get the
Galerkin formulation
M dc
dt + Ac = f
(6.51)

140
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
This is a system of ODEs where
Mij = ∫
1
0
𝜑i(x)𝜑j(x) dx,
Aij = ∫
1
0
d𝜑i
dx
d𝜑j
dx dx,
fi = ∫
1
0
f(x)𝜑i(x)dx
(6.52)
The ICs are obtained from
u0(x) ≈uh(x, 0) =
N
∑
i=1
ci(0)𝜑i(x)
(6.53)
Multiply this relation with 𝜑j(x), integrate over [0, 1] and we obtain the initial values
c(0) from the linear system of equations
Mc(0) = u0
(6.54)
where
u0,i = ∫
1
0
u0(x)𝜑i(x) dx.
Now, choose as basis functions the roof functions introduced in Chapter 4. Inserting
the basis functions into (6.52), we obtain
M = hx
6
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
4
1
0
…
0
1
4
1
⋱
⋮
0
⋱
⋱
⋱
0
⋮
⋱
1
4
1
0
…
0
1
4
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
,
A = 1
hx
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
2
−1
0
…
0
−1
2
−1
⋱
⋮
0
⋱
⋱
⋱
0
⋮
⋱
−1
2
−1
0
…
0
−1
2
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
(6.55)
Observe that (6.51) is not presented in standard form du∕dt = f(t, u). We can
achieve that by multiplying both sides with M−1
dc
dt + M−1Ac = M−1f
(6.56)
If we do that, however, the tridiagonal structure of the matrices in (6.55) is destroyed,
since M−1 is a full matrix. By keeping the tridiagonal form, a stiff method, e.g., the
implicit Euler method applied to (6.51) gives a tridiagonal system of linear equations
to be solved at each time step
M(ck+1 −ck) + htAck+1 = ht fk+1 ⇒(M + htA)ck+1 = Mck + ht fk+1
BIBLIOGRAPHY
The classical textbook on numerical solution of PDEs is:
1. G.D. Smith, Numerical Solution of Partial Differential Equations, 3rd ed, Oxford University
Press, 1986

BIBLIOGRAPHY
141
A modern book, more mathematical, on numerical analysis of ODEs and PDEs:
2. A. Iserles, A First Course in the Numerical Analysis of Differential Equations, Cambridge
University Press, 1996
A book with several applications:
3. K.W. Morton, D.F. Myers, Numerical Solution of Partial Differential Equations, Cambridge
University Press, 2005


7
NUMERICAL METHODS FOR
ELLIPTIC PARTIAL DIFFERENTIAL
EQUATIONS
Elliptic partial differential equations (PDEs) arise in equilibrium or steady-state prob-
lems, i.e., PDE problems that are time independent.
The solution of an elliptic PDE is often related to minimization of the total energy
of a system formulated as an integral that depends on a state function and its deriva-
tives. The minimization of this integral with respect to the state function is known
as variational calculus and often leads to an elliptic PDE (or ordinary differential
equation (ODE) if there is only one independent variable) and corresponding bound-
ary conditions (BCs). Variational calculus is not taken up in this text but is referred
to in some of the textbooks mentioned at the end of this chapter.
The BCs usually specify either the value of the solution function on the boundary
or the value of its normal derivative or a combination of both.
The model problem for a 2D elliptic PDE problem is Poisson’s equation,
−𝜕2u
𝜕x2 −𝜕2u
𝜕y2 = f(x, y),
(x, y) ∈Ω
(7.1a)
u = 0,
(x, y) ∈𝜕Ω
(7.1b)
where Ω is assumed to be a bounded region in R2 with a smooth (or at least piece-
wise smooth) boundary 𝜕Ω. When f(x, y) ≡0 in equation (7.1a), the PDE is called
Laplace’s equation and its solutions are called harmonic functions.
Different types of BCs can be given, just as in the case of 1D boundary value
problems (see Chapter 4). The following common examples of BCs are linear
• Dirichlet’s BC
u = g(x, y)
(x, y) ∈𝜕Ω
(7.2)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

144
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
• Neumann’s BC
𝜕u
𝜕n = h(x, y),
(x, y) ∈𝜕Ω
(7.3)
Observe that Poisson’s equation with a Neumann BD has a solution that is deter-
mined only up to an additive constant. To obtain a unique solution, a Dirichlet
(or mixed) condition is needed in at least some part of 𝜕Ω. Observe also that
with Neumann’s BC, the following relation must be fulfilled
∫𝜕Ω
𝜕u
𝜕nds = ∫
∫Ω
f(x, y)dxdy
• Mixed BC (also referred to as Robin’s BC):
𝜕u
𝜕n = 𝛼u + g(x, y)
(x, y) ∈𝜕Ω
(7.4)
where 𝛼is a known constant and g(x, y) a known function.
• The three BCs given above are linear but nonlinear BCs can also be formulated
for elliptic PDEs.
At each point on the boundary 𝜕Ω, only one type of BC can be given, but along the
boundary the type of BC can shift, from, e.g., Dirichlet type to, e.g., Neumann type.
However, at boundary points where either the BCs change or where the boundary is
not smooth, singularities may occur in the solution’s derivatives, which will imply
difficulties in the numerical treatment when discretization methods are used.
The 1D correspondence to equation (7.1) is the following boundary value problem
(BVP) with Dirichlet BCs, presented as the model equation in Chapter 4:
−d2u
dx2 = f(x),
0 < x < 1,
u(0) = u(1) = 0
(7.5)
Many of the numerical properties of the discretized version of equation (7.5) will
be preserved for PDE problems in 2D and 3D. In Section 4.2, it was stated that in the
discretization of a BVP a matching technique leads to a coupled system of algebraic
equations. This is true also for elliptic problems in 2D and 3D but the size of the
systems will increase immensely. Examples of such numerical properties are
• For a linear elliptic PDE with linear BCs, discretization with finite difference
method (FDM) or finite element method (FEM), leads to a linear algebraic sys-
tem of equations to be solved: Au = b.
• The matrix A will be sparse.
For 1D and 2D problems, the solution of the linear system is usually performed
with a sparse version of a direct method, e.g., sparse Gaussian elimination. For a
3D problem, the size of the linear system is usually so large that an iterative method
is preferred (when it works), (see Appendix A.5).

APPLICATIONS
145
Exercise 7.0.1. Given Poisson’s equation with inhomogeneous BC:
−𝜕2u
𝜕x2 −𝜕2u
𝜕y2 = f(x, y),
(x, y) ∈Ω
u = g(x, y),
(x, y) ∈𝜕Ω
Assume that g(x, y) is twice differentiable in the region Ω. Let v = u −g(x, y). Find
the Poisson equation and the BCs that v satisfies.
Exercise 7.0.2. The forms of Laplace’s equation for cartesian, cylindrical, and
spherical coordinates are shown in equations (5.24a), (5.24b).
1. Assume that the solution to Laplace’s equation in cylindrical coordinates
depends only on the variable r (cylinder symmetry). Find the general solution.
2. The same as in (1) but for spherical coordinates (spherical symmetry).
7.1
APPLICATIONS
Poisson’s and Laplace’s equations occur in a great variety of applications in science
and engineering. Some examples are given in Table 7.1.
To each one of the elliptic PDE problems given in Table 7.1, appropriate BCs have
to be given in order to specify a unique solution.
Laplace’s and Poisson’s equations are not the only elliptic problems. The examples
below show some other types of elliptic PDEs, e.g., a higher order PDE, an eigenvalue
problem, a nonlinear PDE, and a system of two PDEs. For some of these examples,
the numerical solution is demonstrated in Section 7.3.
Example 7.1. (Stationary heat conduction).
Consider a thin, metallic, homogeneous, flat, rectangular plate of length a (m)
and width b (m). The plate has no heat sources. When the plate is placed in an
TABLE 7.1
Applications of Poisson’s Equation
Application
Variable
PDE
Right Hand Side
Heat conduction
T = temperature
−div(𝜅∇T) = Q
Heat source/sink
Diffusion
c = concentration
−div(D∇c) = q
Mass source/sink
Electrostatics
V = el potential
−div(𝜖∇V) = 𝜌
Charge density
Gravity
𝜓= grav potential
−Δ𝜓= 𝜌
Mass density
Membrane deflection
u = deformation
−div(∇u) = f ∕E
Pressure
Torsion of a cylinder
𝜙= stress function
−Δ𝜙= 2𝜃G
Torsion module
Fluid dynamics
Φ = velocity potential
ΔΦ = 0

146
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
y
∂Ω2
∂Ω3
Ω
∂Ω1
∂Ω4
x
Figure 7.1
Region and boundaries for a rectangular heat conduction problem
xy-coordinate system, it covers the rectangular region Ω. Heat is conducted isotrop-
ically in the plate and the heat fluxes are subject to different BCs given on 𝜕Ω. Let
T(x, y) (K) be the temperature in a point (x, y) in Ω or on 𝜕Ω. T(x, y) is determined
by the heat equation, in this case Laplace’s equation and appropriate BCs
−∇(𝜅∇T) = 0
where 𝜅is the heat conduction coefficient [J∕( K⋅m⋅s)] (Figure 7.1).
Along 𝜕Ω1, the temperature is given by a function g(x, y), i.e.
T(x, y) = g1(y),
(x, y) ∈𝜕Ω1
(7.6)
hence leading to a Dirichlet BC on this part of the boundary.
Along 𝜕Ω2, assume that the plate is warmer than the environment. Hence, heat is
leaking out through this part of the boundary and a mixed BC is appropriate
−𝜅𝜕T
𝜕n = k(T −Tout),
(x, y) ∈𝜕Ω2
(7.7)
where k [J∕( K⋅m2 ⋅s)] is the convection heat transfer coefficient.
Along 𝜕Ω3, the boundary is assumed to be heat insulated against the environment,
which leads to a Neumann BC
𝜅𝜕T
𝜕n = 0
(7.8)
Finally along Ω4, the temperature is given by a function g2(y), i.e., a Dirichlet BC just
as along 𝜕Ω1. For a solution of this problem, see Section 7.3. Compare this example
with example 6.2.
Example 7.2. (Steady, incompressible, nonviscous, irrotational flow).
If a flow is irrotational, i.e., the velocity field u = (ux, uy) satisfies curlu = 0, there
exists a potential function Φ such that u = −∇Φ. As the flow is incompressible we

APPLICATIONS
147
x
0
a
y
ux = U
Figure 7.2
The flow around a circular obstacle
also have divu = 0. Combining these two equations we find that Φ satisfies Laplace’s
equation
ΔΦ = 0
The physical assumptions needed to justify this model is that the effects of viscosity
are neglected.
By specifying suitable BCs, the flow is determined. In this example, we consider
a flow in the xy-plane that originally is parallel with the x-axis and then passing a
cylinder with the symmetry axis perpendicular to the xy-plane. We want to compute
the flowlines as the flow passes the cylinder.
Assume the 2D flow far away from the cylinder (x << 0) has the velocity compo-
nents ux = U and uy = 0. The radius of the cylinder is a and the symmetry axis goes
through the origin (Figure 7.2).
For this problem, it is natural to use cylindrical coordinates. As the z-coordinate
plays no part in the solution, the potential function Φ satisfies Laplace’s equation in
polar coordinates
𝜕2Φ
𝜕r2 + 1
r
𝜕Φ
𝜕r + 1
r2
𝜕2Φ
𝜕𝜑= 0
(7.9)
From Φ, the cylindrical velocity components ur and u𝜑are computed from
ur = −𝜕Φ
𝜕r ,
u𝜑= −1
r
𝜕Φ
𝜕𝜑
(7.10)
To solve Laplace’s equation, BCs are needed in the region Ω yet to be defined. Owing
to symmetry,it is enough to formulateBCs in the half plane 0 ≤𝜑≤𝜋. In a numerical
formulation based on the FDM, the region must be bounded. This can be achieved
by restricting the r-variable to be bounded by a ≤r ≤R, where R >> a. Hence, Ω is
a large half disc from which a small half disc has been cut out: Ω = (r, 𝜑), a ≤r ≤
R, 0 ≤𝜑≤𝜋.
1. On the boundary 𝜕Ω1, the small half circle we have ur = 0, i.e., no radial veloc-
ity component.

148
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
x
y
u
f (x, y)
Ω
Figure 7.3
Deformation of an elastic plate by a transversal load
2. Along the boundary 𝜕Ω2 and 𝜕Ω4, the two parts on the x-axis between the small
and the big half circle, we have u𝜑= 0 from the symmetry of the problem.
3. Far away from the cylinder, the flow is unaffected, i.e. ux = U and uy = 0.
Hence, on the boundary 𝜕Ω3 the big half circle, the following Dirichlet con-
dition satisfies the BC: Φ = −Ux = −Ur cos(𝜑).
Example 7.3. (Deformation of an elastic plate by a transversal load).
Consider a thin, metallic, homogeneousflat plate (see Figure 7.3).When it is placed in
an xy-coordinate system, it covers the region Ω. We want to study small deformations
imposed by a transversal pressure f(x, y) (N∕m2). The deformation u (m) satisfies the
biharmonic equation
Δ2u = 𝜕4u
𝜕x4 + 2 𝜕4u
𝜕x2𝜕y2 + 𝜕4u
𝜕y4 = f(x, y)
D
,
(x, y) ∈Ω
(7.11a)
where D ( N⋅m) is the flexural rigidity. For a clamped plate, the following BCs are
valid
u = 0,
𝜕u
𝜕n = 0,
(x, y) ∈𝜕Ω
(7.11b)
Equation (7.11a)is a fourth-orderelliptic problem.The corresponding1D problem
is the ODE modeling the deformation of a beam clamped between two walls and
transversally loaded by f(x) (N/m)
EI d4u
dx4 = f(x),
u(0) = du
dx(0) = 0,
u(L) = du
dx(L) = 0
(7.12)
Example 7.4. (Eigenvalue problem).
In different engineering applications, one is often interested in the frequencies allow-
ing a system to vibrate by itself without influence of external forces. Such prob-
lems occur in, e.g., mechanical and electrical problems and such frequencies are

APPLICATIONS
149
called eigenfrequencies. They would vibrate for ever only in idealized situations,
when damping forces are neglected. Nevertheless, these eigenfrequencies are impor-
tant in engineering. The reason is that we want to avoid them, as external forces
vibrating with the same frequency as an eigenfrequency introduces resonance effects
that will increase the amplitudeof the vibrations of the system and may cause damage.
Consider an elastic membrane that is first deformed and then left to itself to
perform vibrations with amplitude u(x, y). The vibrations v(x, y, t) satisfy the wave
equation (see Chapter 5)
𝜕2v
𝜕t2 = c2Δv,
(x, y) ∈Ω
(7.13a)
v = 0,
(x, y) ∈𝜕Ω
(7.13b)
For vibrations with the angular frequency 𝜔, we make the following ansatz for the
time-dependent solution
v = u(x, y)ei𝜔t
(7.14)
Inserting this ansatz into the wave equation gives the following elliptic PDE problem
for the amplitude (Helmholtz’ equation), also called the eigenvalue problem for the
vibrating membrane
−Δu = 𝜆u,
(x, y) ∈Ω
(7.15a)
u = 0,
(x, y) ∈𝜕Ω
(7.15b)
where
𝜆=
(𝜔
c
)2
(7.16)
Observe that u(x, y) is determined only up to a multiplicative constant, see also
example 4.6.
Example 7.5. (Minimal surface problem, a nonlinear elliptic PDE).
Consider a closed curve 𝜕ΩS in 3D. Such a curve can be defined by u = g(x, y) eval-
uated along a closed curve 𝜕Ω enclosing the region Ω in the xy-plane. The problem
is to find the minimal surface S and the corresponding function u(x, y) with 𝜕ΩS as
boundary (Figure 7.4).
This can be stated as a minimization problem
S = min
u(x,y) ∫Ω
√
1 + (∇u)2dxdy
(7.17a)
subject to the constraint
u = g(x, y),
(x, y) ∈𝜕Ω
(7.17b)

150
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
Ω
x
y
u
S
∂ΩS
∂Ω
Figure 7.4
Minimal surface problem
With variational calculus, it can be shown that equation (7.17) is equivalent to solving
the following nonlinear elliptic PDE
div
{
∇u
√
1 + (∇u)2
}
= 0,
(x, y) ∈Ω
(7.18a)
with Dirichlet BC
u = g(x, y),
(x, y) ∈𝜕Ω
(7.18b)
This problem is also known as the soap film problem, as the PDE (7.18) describes
how the shape of a soap film will adjust itself when it is fastened to a metallic wire
with a given shape, defined by 𝜕ΩS.
Example 7.6. (Deformation of an elastic plate in a plane).
Plane strain of an elastic plate in 2D is modeled by two coupled elliptic PDEs
𝜕2u
𝜕x2 + 1 −𝜈
2
𝜕2u
𝜕y2 + 1 + 𝜈
2
𝜕2v
𝜕x𝜕y = −1 −𝜈2
E2
f(x, y)
(7.19a)
𝜕2v
𝜕y2 + 1 −𝜈
2
𝜕2v
𝜕x2 + 1 + 𝜈
2
𝜕2u
𝜕x𝜕y = −1 −𝜈2
E2
g(x, y)
(7.19b)
where u and v are the displacements in the x and y directions. E is the elasticity
module and 𝜈is Poisson’s number. The deformation forces in the x and y directions
are, respectively, f(x, y) and g(x, y). With appropriate BCs, this is a system of two
elliptic PDEs.
7.2
THE FINITE DIFFERENCE METHOD
When the FDM is used, the algorithm for solving an elliptic PDE problem can be
divided into three steps, just as for BVPs in Chapter 4. Hence, the steps are

THE FINITE DIFFERENCE METHOD
151
x0
x1
x2
xi
xN xN +1
x
y0
y1
y2
yj
yN
yN +1
y
(1, 1)
Figure 7.5
2D grid
1. discretize the region to a grid
2. discretize the PDE
3. discretize the BCs
To illustrate the algorithm, we apply it to the model problem (7.1) in the case Ω is the
region {(x, y), 0 ≤x ≤1, 0 ≤y ≤1}.
DG Discretize the region to a grid
Discretize the x- and the y-axis with the same stepsize h corresponding to N × N
inner points equidistantly distributed over the two axis, h(N + 1) = 1 giving xi, i =
1, 2, … N and yj = jh, j = 1, 2, … N (Figure 7.5).
DD Discretize the PDE
Use the well-known difference formula for the second derivative:
𝜕2u
𝜕x2 (xi, yj) =
ui+1,j −2ui,j + ui−1,j
h2
+ O(h2)
(7.20a)
𝜕2u
𝜕y2 (xi, yj) =
ui,j+1 −2ui,j + ui,j−1
h2
+ O(h2)
(7.20b)
We get the following difference approximation of Poisson’s equation:
4ui,j −ui−1,j −ui+1,j −ui,j−1 −ui,j+1 = h2f(xi, yj)
(7.21)
DB The BCs are represented exactly for the given Dirichlet conditions:
u0,j = 0,
uN+1,j = 0,
ui,0 = 0,
ui,N+1 = 0
(7.22)
We can illustrate the left hand side of equation (7.21) by the five-point stencil h2Δh
5
(Figure 7.6).

152
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
1
−4
1
1
1
Figure 7.6
Stencil for discretized laplacian
x0 x1
x2
xi
xN xN+1
x
y0
y1
y2
yj
yN
yN+1
y
(1, 1)
1
2
3
N
N+1
2N
jN
N2
Figure 7.7
Ordering of unknowns
The difference equations (7.21) can be set up in all N2 inner points (xi, yj). giving
N2 equations for N2 unknowns ui,j. By introducing the matrix U for the unknowns, it
might seem reasonable that equations (7.21) and (7.22) can be formulated as a linear
matrix equation:
AU = B
with appropriate elements in the A and B matrices. This, however, is NOT possible!
Instead we have to represent the matrix of unknownsU as a long vector u. One way
to do this is to enumerate the unknowns and the gridpoints row-wise (also known as
natural ordering)according to the Figure 7.7: corresponding to the following ordering
of the ui,j values:
u = (u1,1, u2,1, … , uN,1, u1,2, u2,2, … , uN,2, …… u1,N, u2,N, … uN,N)T
With this enumeration, the linear system of equations will be
Au = b

THE FINITE DIFFERENCE METHOD
153
where A is a sparse symmetric positive definite N2 × N2 matrix and b is an N2 × 1
column vector.
In the case N = 3, A and b are
A =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
4
−1
0
−1
0
0
0
0
0
−1
4
−1
0
−1
0
0
0
0
0
−1
4
0
0
−1
0
0
0
−1
0
0
4
−1
0
−1
0
0
0
−1
0
−1
4
−1
0
−1
0
0
0
−1
0
−1
4
0
0
−1
0
0
0
−1
0
0
4
−1
0
0
0
0
0
−1
0
−1
4
−1
0
0
0
0
0
−1
0
−1
4
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
,
b = h2f = h2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
f1,1
f2,1
f3,1
f1,2
f2,2
f3,2
f1,3
f2,3
f3,3
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
The matrix A is symmetric and positive definite (compare with the matrix A in (4.29))
and has the structure of a block tridiagonal matrix
A = tridN(−I, T, −I),
where
T = tridN(−1, 4, −1)
(7.23)
The matrix A is very sparse, only five diagonals have nonzero elements. On the other
hand, the bandwidth is 2N −1 and (see Section A.5) in the Cholesky factorization,
A = LLT, there will be “fill-in” in L, i.e., the zeros inside the band between the outer
and inner diagonals will be filled with nonzero elements denoted by x:
AL =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
x
0
0
0
0
0
0
0
0
x
x
0
0
0
0
0
0
0
0
x
x
0
0
0
0
0
0
x
0
0
x
0
0
0
0
0
0
x
0
x
x
0
0
0
0
0
0
x
0
x
x
0
0
0
0
0
0
x
0
0
x
0
0
0
0
0
0
x
0
x
x
0
0
0
0
0
0
x
0
x
x
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
−> L =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
x
0
0
0
0
0
0
0
0
x
x
0
0
0
0
0
0
0
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
where AL is the lower triangular part of A. For more comments on the solution of large
sparse systems with different methods, see Section A.5. Observe the increasing com-
plexity as the problem is changed from 1D to 2D and 3D. If the x-axis is discretized
into N inner points for 1D the problem (7.5), the matrix A will be tridiagonal, N × N
and the solution time O(N).
With a similar discretization for the 2D problem (7.1) with Ω being a quadrangle
(N inner points in both the x and the y directions), A is N2 × N2 with bandwidth O(N)
and solution time O(N4)
In the 3D case, A is N3 × N3 with bandwidth O(N2) and solution time O(N7).

154
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
Exercise 7.2.1. Use the five-point stencil to compute an approximation of u(0, 0),
where u(x, y) satisfies the PDE
Δu = u,
(x, y) ∈Ω
u = |x| + |y|,
(x, y) ∈𝜕Ω
where Ω is the square (x, y), −1 ≤x ≤1, −1 ≤y ≤1. Use the stepsizes, h = 1 and
h = 1∕2. Use extrapolation to improve the result.
Exercise 7.2.2. Find the stencil obtained with central differenceapproximationsfor
the following PDE expressions. Assume that the stepsize h in the x and y directions
is the same.
𝜕2u
dx2 + 𝜕2u
𝜕y2 + 𝜕2u
𝜕x𝜕y
𝜕2u
dx2 + 𝜕2u
𝜕y2 + 𝜕u
𝜕x + 𝜕u
𝜕y
Exercise 7.2.3. When the boundary 𝜕Ω is curved and intersects the quadratic grid
at points that are not grid points, the five-point stencil h2Δh
5 must be modified when
applied to Dirichlet BC.
Assume the stencil is positioned with the midpoint in (xi, yj), which is situated
inside the region Ω. The point on the curve above the midpoint is situated 𝛼h, 𝛼< 1
from the midpoint. The point to the right of the midpoint has the distance 𝛽h, 𝛽< 1
from the midpoint. The points below and to the left of the midpoint are both situated
inside the region and therefore at distance h from the midpoint.
The parameters 𝛼and 𝛽in the unsymmetric stencil are chosen so that it fits the
boundary points correctly. Derive the coefficients a, b, c, d, e (they depend on 𝛼and
𝛽) in the difference approximation
Δu(xi, yj) =
auij−1 + bui−1j + cuij + dui+1j + euij+1
h2
+ O(hp)
so that the order of approximation is as high as possible. Show the result as a stencil.
7.3
DISCRETIZATION OF A PROBLEM WITH DIFFERENT BCs
Based on the FDM, the problems in Examples 7.1–7.5 can be solved, essentially using
the same three step algorithm as outlined in Section 7.2. We present here a discretized
solution technique for Example 7.1.
Assume that the region Ω is a rectangle placed in an xy-coordinate system with
the corners on (0, 0), (a, 0), (0, b) and (a, b).

DISCRETIZATION OF A PROBLEM WITH DIFFERENT BCs
155
x0
x1
x2
xi
xM−1 xM
x
y1
y2
y3
yj
yN −1
yN
yN +1
y
(a, b)
Figure 7.8
The region discretized with the FDM
1. DG—Discretize Ω using a stepsize h, which is assumed to be the same in both
the x and the y directions, according to Mh = a, (N −1)h = b (Figure 7.8).
Having the type of BCs in mind, the points are numbered according to
xi = ih, i = 0, 1, … M, x0 = 0, xM = a
and
yj = (j −1)h, j = 0, 1, … , N +
1, y0 = −h, yN+1 = b + h. The four corner points of the grid, however, are
not included. This gives (M + 1)(N + 2) −4 = MN + 2M + N −2 grid points.
This is also the number of unknowns Ti,j of the discretized problem.
2. DD Discretize the PDE. The following equations are valid at the inner points:
4Ti,j −Ti−1,j −Ti+1,j −Ti,j−1 −Ti,j+1 = 0,
where i = 1, 2, … , M −1, j = 1, 2, … , N giving a total of (M −1)N equations.
3. DB Discretize the BCs along the four boundaries.
On 𝜕Ω1, there is a Dirichlet BC: T0,j = g(0, yj), j = 1, 2, … , N giving N
equations.
On 𝜕Ω2, there is a mixed BC: −𝜅(Ti,N+1 −Ti,N−1)∕2h = k(Ti,N −Tout), i =
1, 2, … , M −1 giving M −1 equations.
On 𝜕Ω3, there is a Neumann BC: (Ti,0 −Ti,2)∕2h = 0, i = 1, 2, … , M −1 giv-
ing M −1 equations.
On 𝜕Ω4, there is a Dirichlet BC: TM,j = g(a, yj), j = 1, 2, … , N giving N
equations.
The total number of equations in (2) + (3) is (M −1)N + N + M −1 + M −1 + N =
MN + 2M + N −2. Hence, there are as many equations as unknownsand a linear sys-
tem of equations can be set up when the unknownTi,j elements have been renumbered
into a vector Ti, i = 1, 2, … , MN + 2M + N −2.

156
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
Exercise 7.3.1. Discretize the Laplace equation in polar coordinates presented in
Example 7.2. Follow the recipe DG,DD,DB. Observe that the region Ω is a rectangle
in the (r, 𝜑)-space. Find second-order approximations to the PDE and the BCs.
Exercise 7.3.2. Discretize the eigenvalue problem in Example 7.4 assuming the
region Ω is a square with side length = 1. Formulate the corresponding algebraic
eigenvalue problem Au = 𝜆u.
7.4
ANSATZ METHODS FOR ELLIPTIC PDEs
So far we have demonstrated the FDM on problems defined on rectangular domains.
However, real problems often involve domains with irregular shapes. To demonstrate
the FEM, we apply the method to Poisson’s problem (7.1), but assume that the region
Ω has a more complicated shape (not a square) (Figure 7.9).
7.4.1
Starting with the PDE Formulation
Instead of the FDM we now choose an ansatz for the approximatesolution of equation
(7.1), i.e.,
−𝜕2u
𝜕x2 −𝜕2u
𝜕y2 = f(x, y),
(x, y) ∈Ω
u = 0,
(x, y) ∈𝜕Ω
and use Galerkin’s method. The generalization of the 1D problem to a 2D problem is
straightforward: change ∫to ∫∫and d∕dx to grad and repeat the formulas in Section
4.3 to the 2D case. Denote by uh(x, y) the ansatz function
uh(x, y) =
N
∑
j=1
cj𝜑j(x, y)
(7.24)
where the basis functions 𝜑j(x, y) are chosen to satisfy the BCs, i.e.
𝜑j(x, y)|𝜕Ω = 0,
j = 1, 2, … , N
(7.25)
When uh(x, y) is inserted into the PDE, we obtain a residual function r(x, y):
r(x, y) =
N
∑
j=1
cjΔ𝜑j(x, y) + f(x, y) ≠0
(7.26)
In order to make r(x, y) “small”, we use Galerkin’s method, which means that r(x, y)
is orthogonal to 𝜑i(x, y), i = 1, 2, … , N:
∫∫Ω
r(x, y)𝜑i(x, y)dxdy = 0
(7.27)

ANSATZ METHODS FOR ELLIPTIC PDEs
157
x
y
Ω
Figure 7.9
A region to be discretized with the FEM
∫∫Ω
(
N
∑
j=1
cjΔ𝜑j(x, y) + f(x, y))𝜑i(x, y)dxdy = 0
N
∑
j=1
cj ∫∫Ω
𝜑iΔ𝜑jdxdy + ∫∫Ω
f(x, y)𝜑idxdy = 0
Now use integration “by parts” in 2D
∫∫Ω
𝜑iΔ𝜑jdxdy = ∮𝜕Ω
𝜑i
𝜕𝜑j
𝜕n ds −∫∫Ω
∇𝜑i ⋅∇𝜑jdxdy
(7.28)
Compare this formula with the corresponding integration by parts in 1D
∫
1
0
𝜑i𝜑′′
j dx = [𝜑i𝜑′
j]1
0 −∫
1
0
𝜑′
i𝜑′
jdx
As 𝜑i = 0 on 𝜕Ω this integral = 0, and we finally obtain
N
∑
j=1
cj ∫∫Ω
∇𝜑i ⋅∇𝜑jdxdy = ∫∫Ω
f(x, y)𝜑idxdy,i = 1, 2, … , N
(7.29)
which is an N × N linear system of equations for the coefficients cj:
Ac = f
where
Ai,j = ∫∫Ω
∇𝜑i ⋅∇𝜑jdxdy,
fi = ∫∫Ω
f(x, y)𝜑idxdy
(7.30)
A is called the stiffness matrix, where stiffness is related to a material property and
not the concept “stiff” in connection with certain ODE problems (see Chapter 3). The
right hand side vector f is called the load vector.

158
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
7.4.2
Starting with the Weak Formulation
The analytical solution of equation (7.1) is referred to as the strong (or classical)
solution, but for PDEs, in general, there is also a weak (or variational) formulation
just as for the 1D problems in Section 4.3. The weak formulation is demonstrated on
a slightly more general PDE than (7.1).
−div(𝜅∇u) + p⋅∇u + qu = f(x, y)
in
Ω
(7.31a)
𝜅𝜕u
𝜕n = 𝛼u + g(x, y)
on
𝜕Ω
(7.31b)
where 𝜅, p, and q can be constants or depend on (x, y). This PDE with the BC is linear
and corresponds to a generalization of the BVP problem (4.57) to 2D.
For the weak formulation, multiply equation (7.31a) with a test function
v = v(x, y) ∈U and integrate over the region Ω
∫∫Ω
(−div(𝜅∇u) + p⋅∇u + qu)vdxdy = ∫∫Ω
fvdxdy
(7.32)
Use integration “by parts” in 2D on the first term
−∫∫Ω
div(𝜅∇u)vdxdy = −∮𝜕Ω
𝜅𝜕u
𝜕nvds + ∫∫Ω
𝜅∇u⋅∇vdxdy
(7.33)
Using the BC (7.31b) in equation (7.33), we obtain the weak formulation: Find u ∈U
so that
∫∫Ω
(𝜅(∇u⋅∇v) + (p⋅∇u)v + quv)dxdy −∮𝜕Ω
𝛼uvds = ∫∫Ω
fvdxdy + ∮𝜕Ω
gvds
(7.34)
for all v ∈U, where U = C1(Ω). In equation (7.34), the quadratic terms are collected
in the left hand side and the linear terms in the right hand side.
When there are different types of BCs on 𝜕Ω, the weak formulation must be
changed accordingly, e.g., if we have both mixed and Dirichlet conditions
𝜅𝜕u
𝜕n = 𝛼1u + g1(x, y),
(x, y) ∈𝜕Ω1
u = 0,
(x, y) ∈𝜕Ω2
Then equation (7.34) is changed to: Find u ∈U such that
∫∫Ω
(𝜅(∇u⋅∇v) + p⋅∇uv + quv)dxdy −∮𝜕Ω1
𝛼uvds = ∫∫Ω
fvdxdy + ∮𝜕Ω1
gvds
(7.35)
for all v ∈U, where U = C1
[0](Ω) and [0] means v = 0, on 𝜕Ω2.

ANSATZ METHODS FOR ELLIPTIC PDEs
159
Now, use Galerkin’s method on the weak formulation (7.34), i.e., let
uh(x, y) =
N
∑
j=1
cj𝜑j(x, y),
vh(x, y) = 𝜑i(x, y), i = 1, 2, … , N
For the coefficients cj, we obtain the linear system of equations
(A𝜅+ P + Q + B)c = f
where
A𝜅ij = ∫∫Ω
𝜅∇𝜑i ⋅∇𝜑jdxdy,
Pij = ∫∫Ω
𝜑ip⋅∇𝜑jdxdy,
Qij = ∫∫Ω
q𝜑i𝜑jdxdy
Bij = ∫∫𝜕Ω
𝛼𝜑i𝜑jds
fi = ∫∫Ω
f(x, y)𝜑idxdy + ∮𝜕Ω
g𝜑ids
Exercise 7.4.1. Modify the weak formulation to Poisson’s equation with a nonho-
mogeneous BC
−𝜕2u
𝜕x2 −𝜕2u
𝜕y2 = f(x, y),
(x, y) ∈Ω
u = g(x, y),
(x, y) ∈𝜕Ω
Hint: Make a transformation similar to the one in Exercise 7.0.1 to obtain a homoge-
neous BC.
7.4.3
The Finite Element Method
Up to now nothing has been said about the basis functions 𝜑j. We want the matrix
A to be sparse, in order to be competitive with the FDM. In the 1D case, 𝜑j(x) were
chosen as “roof functions” (see Section 4.3) defined on a grid of subintervals.
In the 2D case, the grid is defined by subdivision of Ω into triangles Tk, k =
1, 2, … , M (Figure 7.10).
It is seen from the example above that the boundary 𝜕Ω will not be exactly rep-
resented, unless the boundary consists of straight lines coinciding with the triangle
sides. Hence
Ω ≈ΩT = ∪M
1 Tk
However, by making the triangles sufficiently small, the boundary can be accurately
enough represented. In connection with this modification of Ω, we also change the
BCs of 𝜑j(x, y) to
𝜑j(x, y)|𝜕ΩT = 0,
j = 1, 2, … , N
For the definition of the triangular grid, we must define a numbering of both the
inner nodes Pj, j = 1, 2, … , N and the triangles Tk, k = 1, 2, … , M. Hence, for an
arbitrary triangle Tk, there are three nodes (corners).

160
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
x
y
Figure 7.10
Triangular discretization of a region
x
y
1
u
𝜑j(x, y)
Figure 7.11
A pyramid function
When the grid has been defined for the region ΩT, the basis functions can be
defined by associating to each node j a “pyramid” function 𝜑j(x, y) (Figure 7.11).
The side of a pyramid is a triangle, hence every basis function 𝜑i(x, y) consists
of a number of triangular parts of planes and can, therefore, be given an analytical
description, which, however, is rather extensive, so we refrain from this. Instead, a
splitting technique of the integrals is used.
Aij = ∫∫ΩT
∇𝜑i ⋅∇𝜑jdxdy,
fi = ∫∫ΩT
f(x, y)𝜑idxdy
The matrix elements consist of double integrals evaluated over the whole region ΩT.
A trick simplifying this computation is to split this integral into a sum of integrals
where each integral is computed over each triangle:
Aij =
M
∑
k=1 ∫∫Tk
∇𝜑i∇𝜑jdxdy,
fi =
N
∑
k=1 ∫∫Tk
f(x, y)𝜑idxdy
(7.36)

ANSATZ METHODS FOR ELLIPTIC PDEs
161
Tk
K1
(x1, y1)
K3
(x3, y3)
K2 (x2, y2)
Figure 7.12
Local numbering of the nodes of a linear element
Assume that triangle Tk has the nodes K1, K2, and K3. To simplify the notation,
introduce a local numbering of the nodes for the triangle Tk: node 1, 2, and 3 with
coordinates (x1, y1), (x2, y2), and (x3, y3) (Figure 7.12).
In the triangle Tk, there are three nonzero basis functions, namely those associated
with node i = 1, 2, and 3. These basis functions have the form
𝜑i(x, y) = ai + bix + ciy,
(x, y) ∈Tk,
i = 1, 2, 3
Furthermore, as all the basis functions have the property
𝜑i(xj, yj) =
{1,
if i = j
0,
if i ≠j
the coefficients ai, bi, ci satisfy the linear system of equations
⎛
⎜
⎜⎝
1
x1
y1
1
x2
y2
1
x3
y3
⎞
⎟
⎟⎠
⎛
⎜
⎜⎝
a1
a2
a3
b1
b2
b3
c1
c2
c3
⎞
⎟
⎟⎠
=
⎛
⎜
⎜⎝
1
0
0
0
1
0
0
0
1
⎞
⎟
⎟⎠
and therefore
⎛
⎜
⎜⎝
a1
a2
a3
b1
b2
b3
c1
c2
c3
⎞
⎟
⎟⎠
=
⎛
⎜
⎜⎝
1
x1
y1
1
x2
x3
1
x3
y3
⎞
⎟
⎟⎠
−1
In addition, as
∇𝜑i =
(
bi
ci
)
we obtain
∫∫Tk
∇𝜑i ⋅∇𝜑jdxdy = (bibj + cicj)YTk
(7.37)
where YTk is the area of Tk. Note that the elements of A are here computed analytically
with an explicit formula.
Hence, each triangle Tk contributes with a 3 × 3 matrix Aloc
k , the local stiffness
matrix. However, as the true node numbers are K1, K2, and K3, the elements of Aloc
k

162
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
are spread out to the corresponding positions in a sparse N × N matrix Ak:
Aloc
k
=
⎛
⎜
⎜⎝
x
x
x
x
x
x
x
x
x
⎞
⎟
⎟⎠
→
Ak =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
.....
.....
.....
.....
....x
....x
....x
.....
.....
.....
.....
.....
....x
....x
....x
.....
.....
.....
.....
.....
....x
....x
....x
.....
.....
.....
.....
.....
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
As the BC in equation (7.1) is homogeneous, triangles with nodes on the boundary
will be treated separately. For a triangle having two nodes on the boundary, there will
be only one element ≠0 in Aloc
k
and if there is one node on the boundary, there will
be four elements ≠0 in the local stiffness matrix.
When Aloc
k
for triangle Tk has been computed it is added, or rather assembled to
the stiffness matrix
A = 0,
for
k = 1 ∶M
A = A + Ak
end
The load vector f is computed in the same way. Each triangle Tk contributes with
a local load vector floc
k
being 3 × 1 and the components of which are spread out to the
true positions in a sparse N × 1 vector fk:
floc
k
=
⎛
⎜
⎜⎝
x
x
x
⎞
⎟
⎟⎠
→
fk =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
.
x
.
x
.
x
.
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
These vectors are assembled to the load vector f:
f = 0,
for
k = 1 ∶M
f = f + fk
end
The components of fk should be computed numerically as f(x, y) may be complicated
and therefore not possible to compute the integral analytically.
When the linear system
Ac = f
has been solved with some sparse direct (or possibly iterative) method, the coeffi-
cients cj are known and hence the ansatz function
uh(x, y) =
N
∑
j=1
cj𝜑j(x, y)

ANSATZ METHODS FOR ELLIPTIC PDEs
163
can be computed at any point (x, y) ∈ΩT. The ansatz solution is a piecewise linear
function in x and y with the property
uh(xj, yj) = cj
(7.38)
When (x, y) ∈Tk, uh(x, y) is computed as a linear function obtained by linear inter-
polation through the node points of the triangle.
Observe that this discussion of the FEM is based on homogeneous BCs, i.e., u = 0
on the boundary 𝜕Ω. If the BCs are nonhomogeneous, i.e., u = g(x, y) on the bound-
ary, the ansatz must be modified to
uh(x, y) =
∑
IP
cIP
j 𝜑IP
j (x, y) +
∑
BP
g(xBP
j , yBP
j )𝜑BP
j (x, y)
(7.39)
where IP are the inner points and BP are the boundary points.
The FEM can be generalized to
• other PDEs
• other BCs
• other basis functions giving higher accuracy
• 3D problems
• time-dependent problems
Hence, FEM is a very flexible, accurate, and stable method for solving PDE prob-
lems of different types. FEM was first applied to problems in solid mechanics but
is nowadays used to solve all kinds of PDE models in science and engineering. The
Comsol Multiphysics program is designed for scientific computing of such models
(see Section B.2).
Exercise 7.4.2. In equation (7.37), the elements of the local stiffness matrix Aloc
k
for triangle Tk
(Aloc
k )ij = ∫∫Tk
∇𝜑i ⋅∇𝜑jdxdy
were computed. Derive a corresponding formula or suggest a numerical integration
method for the elements of a local mass matrix Qloc
k
for the triangle Tk.
(Qloc
k )ij = ∫∫Tk
𝜑i𝜑jdxdy
Exercise 7.4.3. Derive the linear system of equations Ac = f in the case the BCs
are nonhomogeneous (7.2). The ansatz function is given in equation (7.39).

164
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
BIBLIOGRAPHY
1. G.D. Smith, “Numerical solution of partial differential equations”, 3rd ed, 1986, Oxford
University Press.
2. A. Iserles, “A first course in the numerical analysis of differential equations”, 1996, Cam-
bridge University Press
3. K. Eriksson, D. Estep, P. Hansbo, C. Johnson: Computational differential equations”, 2004,
Studentlitteratur

8
NUMERICAL METHODS FOR
HYPERBOLIC PDEs
Hyperbolic partial differential equations (PDEs) occur as mathematical models of
conservation laws and are found in, e.g., transport process and wave propagation
problems. Information travels with finite speed in contrast to parabolic PDEs where
an initial value immediately effects the solution in all other space points.
A fundamental property of hyperbolic PDEs is that geometric features such as
steep fronts and discontinuities in the solution (in the weak sense, see below), are
propagated with time. For linear problems, jumps come from the initial data, while
in nonlinear cases, discontinuities can develop in the solution even from smooth ini-
tial data. Therefore, for hyperbolic PDEs, we are not only interested in the order of
accuracy of a method but also in the treatment of discontinuities. Important concepts
in the description of the conservation properties are dissipation (loss of energy) and
dispersion (distorted phase relations owing to variable wave speed).
The classical hyperbolic PDE is the wave equation (see Chapter 5):
𝜕2u
𝜕t2 −c2 𝜕2u
𝜕x2 = 0,
−∞< x < ∞,
t > 0
(8.1)
The general solution of this equation, the d’Alembert solution, is
u(x, t) = f(x −ct) + g(x + ct)
(8.2)
where f(x) and g(x) are arbitrary twice differentiable functions. The solution u(x, t)
corresponds to two waves, traveling along the x-axis, one to the left with speed −c
and one to the right with speed c (see Figure 8.1)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

166
NUMERICAL METHODS FOR HYPERBOLIC PDEs
−4
−3
−2
−1
0
1
2
3
4
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
u(x, 0) = f(x) + g(x)
f(x − ct)
g(x + ct)
c −>
<− c
x
u
Figure 8.1
Solution of the wave equation
The wave equation (8.1) is a second-order PDE and can be written as a system of
two first-order PDEs. Let y be a vector and let
y1 = 𝜕u
𝜕t ,
y2 = c𝜕u
𝜕x
Inserting these new variables into (8.1) and using the fact that utx = uxt, we get the
first-order system
𝜕y
𝜕t + A𝜕y
𝜕x = 0
(8.3)
where A is the matrix
A = −c
(
0
1
1
0
)
(8.4)
Note that the eigenvalues of A, −c, and c, are the velocities of the waves in the general
solution.
Definition 1: A system of first-order PDEs
𝜕u
𝜕t + A𝜕u
𝜕x = 0
(8.5)
is hyperbolic if the real matrix A is diagonalizable with real eigenvalues.

NUMERICAL METHODS FOR HYPERBOLIC PDEs
167
−4
−3
−2
−1
0
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
u0(x)
a −>
x
u
u(x,t) = u0(x − at)
Figure 8.2
Solution of the advection equation
If the matrix A consists of only one element a, we get the following scalar hyper-
bolic homogeneous PDE, used as model problem:
𝜕u
𝜕t + a𝜕u
𝜕x = 0,
−∞< x < ∞,
t > 0
(8.6)
This equation is known as the advection equation (see Chapter 1) and is also called
the transport equation or the one-way wave equation. With an initial condition given
on the whole x-axis (Cauchy’s problem)
u(x, 0) = u0(x),
−∞< x < ∞
(8.7)
the solution is a traveling wave
u(x, t) = u0(x −at)
(8.8)
Hence, the initial data is simply advected with constant velocity a to the right if a > 0
(see Figure 8.2). The equation (8.6) is the simplest hyperbolic PDE, being linear and
with a constant coefficient.
A scalar conservation law is a nonlinear hyperbolic PDE
𝜕u
𝜕t + 𝜕
𝜕xf(u) = 0,
(8.9a)
defined by the function f(u), called the flux function. The form (8.9a) is called the
conservative formulation of the PDE.

168
NUMERICAL METHODS FOR HYPERBOLIC PDEs
If f(u) is differentiable, the PDE can be written
𝜕u
𝜕t + a(u)𝜕u
𝜕x = 0
(8.9b)
where a(u) = f ′(u). The form (8.9b) is called the nonconservative formulation. From
numerical point of view, it is important if (8.9a) or (8.9b) is used as starting point for
numerical solution, see Section 8.3.
A special case is
𝜕u
𝜕t + u𝜕u
𝜕x = 0
(8.10a)
known as the nonconservative formulation of the inviscid Burgers’ equation often
used as a model problem for a nonlinear hyperbolic PDE. This equation will produce
solutions with shocks even for smooth initial data. The conservative form of (8.10a)
is
𝜕u
𝜕t + 1
2
𝜕u2
𝜕x = 0
(8.10b)
Compare (8.10a) with Burgers’ viscous PDE where a diffusive term has been
added
𝜕u
𝜕t + u𝜕u
𝜕x = 𝜈𝜕2u
𝜕x2
(8.11)
This equation is much easier to solve numerically than (8.10), see also Exercise
5.3.2. Jan Burgers was a Dutch physicist active in the first half of the 20th
century.
An important concept for hyperbolic PDEs is the characteristic.
Definition 2: The characteristics of (8.9) are the curves in the (x, t)-plane defined
by the ordinary differential equation (ODE)
dx
dt = a(u(x(t), t))
(8.12)
Along a characteristic the solution u(x, t) is constant, which is seen from
du(x(t), t)
dt
= 𝜕u
𝜕t + dx(t)
dt
𝜕u
𝜕x = 𝜕u
𝜕t + a(u(x(t), t))𝜕u
𝜕x = 0
As u(x, t) has a constant value uC along a characteristic, we see that (8.12)
fulfills
dx(t)
dt
= a(uC) = aC →x(t) = aCt + C
Hence, the characteristics of (8.9) are straight lines (see Figure 8.3):

NUMERICAL METHODS FOR HYPERBOLIC PDEs
169
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Examples of characteristics of a scalar hyperbolic differential equation
Figure 8.3
Characteristics for the nonlinear advection equation
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Examples of characteristics of a scalar linear hyperbolic differential equation
0
0.2
0.4
0.6
0.8
1
Figure 8.4
Characteristics for the linear advection equation
For the advection equation (8.6), a(u) = a = constant and all characteristics have
the same slope (see Figure 8.4).
The characteristics can also converge to a point in the (x, t)-plane thereby creating
a shock in the solution, see Section 8.2.1 for numerical solution of Burger’s equation
(8.10).

170
NUMERICAL METHODS FOR HYPERBOLIC PDEs
In case the initial function is defined for x ≥0 only, a semi-infinite problem, a
boundary function is needed for x = 0, i.e., u(0, t) = 𝛼(t). The solution of the model
problem then takes the form
u(x, t) =
{
𝛼(t −x∕a)
if x −at < 0
u0(x −at)
if x −at ≥0
Hence, the initial and boundary values are advected along the characteristics.
For a bounded region 0 ≤x ≤1, BCs are needed together with an IC. For the
hyperbolic model problem (8.6), the formulation is
𝜕u
𝜕t + a𝜕u
𝜕x = 0,
0 < x < 1,
t > 0
(8.13)
IC ∶u(x, 0) = u0(x), 0 ≤x ≤1
BC ∶u(0, t) = 𝛼(t),
t > 0
if
a > 0
BC ∶u(1, t) = 𝛽(t),
t > 0
if
a < 0
Observe that BC for problem (8.13) can be imposed only on the boundary x = 0
(not x = 1) if a > 0 as the characteristics are emanating from that boundary. If a < 0,
however, the BC has to be given for x = 1.
Consider the wave equation (8.1) (which can also be written as the first-order
system (8.3)) defined on the finite interval [0, 1]. For this problem, there are char-
acteristics in both directions. Hence, BCs are needed both for x = 0 and x = 1.
An interesting property of the advection equation is that discontinuities in the ini-
tial function u0(x) are propagated along the x-axis when t increases.
Assume that the initial condition for (8.7) is a stepfunction (also called a Riemann
initial condition):
u0(x) =
{
1,
x < 0
0,
x ≥0
(8.14)
The solution u0(x −at) is propagated without distortion by the advection equation.
Hence at a later time t = T > 0, the solution has moved to x = aT and the shape of
the solution curve remains the same as the initial function u0(x). Bernhard Riemann
was a German mathematician, active in the middle of the 19th century.
Now, discontinuous functions cannot be solutions of differential equations. The
function u0(x) must be continuously differentiable on −∞< x < ∞. However, if
u0(x) is a discontinuous function, we can still talk about u(x, t) = u0(x −at) as a
solution in the weak sense, i.e., an integrated version of the PDE is satisfied for all
smooth functions 𝜑(x, t)
∫
∞
0
∫
∞
−∞
u𝜑t + au𝜑xdxdt + ∫
∞
−∞
u0(x, 0)𝜑(x, 0)dx = 0
(8.15)

APPLICATIONS
171
This relation is obtained by multiplying (8.6) by a smooth function 𝜑(x, t), integrate
over the (x, t) region and then integrate by parts. Compare this technique with the
Galerkin method in Chapter 4, where weak solutions for ODEs are treated.
In applications, e.g., gas dynamics, the moving jump is called a shock wave or
contact discontinuity, depending on which quantities jump. The following relation,
known as Rankine–Hugoniot’s theorem, gives the speed with which the shock prop-
agates: Assume that a discontinuity is moving with speed s and that the value of u to
the left of the jump is uL and to the right uR. Then the following relation holds for the
scalar conservation law (8.9a):
s(uL −uR) = f(uL) −f(uR)
(8.16)
Macquorn Rankine was a Scotish physicist and Pierre-Henri Hugoniot was a
French mathematician both active in the 19th century.
The generalization of the scalar conservation law (8.9) to a system of nonlinear
hyperbolic PDEs is
𝜕u
𝜕t + 𝜕
𝜕xf(u) = 0,
−∞< x < ∞,
t > 0
(8.17)
If the spatial derivation is performed, we get the nonconservative form
𝜕u
𝜕t + A(u)𝜕u
𝜕x = 0
(8.18)
where A(u) is the jacobian of f(u). The system is hyperbolic if A(u) is diagonalizable
and has real eigenvalues.
8.1
APPLICATIONS
Example 8.1. (Time-dependent hot flow in a pipe revisited)
As a first example of a hyperbolic first-order PDE, consider Example 6.1. Assume
that transport by diffusion is negligible, i.e., 𝜅= 0. The PDE then takes the form
𝜕T
𝜕t + v𝜕T
𝜕x + 2h
𝜌CR(T −Tcool) = 0,
0 < x < L,
t > 0
(8.19)
We need an initial condition T(x, 0) = Tinit(x) and a boundary condition T(0, t) =
T0(t), where Tinit(x) and T0(t) are known functions.
Example 8.2. (Time-dependent counterflow heat exchanger)
In Example 4.4, a heat exchanger is presented. If the temperature profiles have
not come to a steady state, the following system of hyperbolic PDEs model the

172
NUMERICAL METHODS FOR HYPERBOLIC PDEs
corresponding time-dependent problem on the x interval 0 < x < L:
𝜕H
𝜕t + uH
𝜕H
𝜕x = −a(H −C),
H(0, t) = H0,
H(x, 0) = H0(x)
(8.20)
𝜕C
𝜕t −uC
𝜕C
𝜕x = a(H −C),
C(L, t) = C0,
C(x, 0) = C0(x)
(8.21)
Example 8.3. (Wave equation)
Another example of a hyperbolic PDE is a model of the movements u(x, t) of a vibrat-
ing string
𝜕2u
𝜕t2 −c2 𝜕2u
𝜕x2 = 0,
0 < x < L,
t > 0
(8.21a)
where the parameter c is the velocity of the wave. For this equation, we need two ICs,
u(x, 0) = u0(x)
𝜕u
𝜕t (x, 0) = v0(x),
0 ≤x ≤L
and two BCs
u(0, t) = 0
u(L, t) = 0,
t ≥0
In Example 9.2, the wave equation is derived for a vibrating string of length L
(m), density 𝜌( kg∕m3), cross-section area A (m2), and string tension F (N). These
parameters are related to c through c2 = F∕𝜌A. The total energy of the string is the
sum of the kinetic and the potential energy
Etot = ∫
L
0
(
1
2𝜌A
(𝜕u
𝜕t
)2
+ 1
2F
(𝜕u
𝜕x
)2)
dx
(8.21b)
By differentiating Etot with respect to t we obtain dEtot∕dt = 0, hence the total energy
is conserved.
The PDE (8.21a) is also valid for plane electromagnetic waves traveling in the x
direction. The variable u then represents the components of the orthogonal electric
and magnetic fields and c is the speed of light. Other types of initial and boundary
conditions are usually imposed.
Example 8.4. (Shock propagation in Euler’s equations)
As was mentioned in Chapter 5, hyperbolic PDEs occur in fluid dynamics modeled
by the Euler equations. Euler’s equations model shocks and contact discontinuities,
i.e., thin transition layers where the pressure, density, and speed of the fluid changes
significantly.
An example of a hyperbolic model sometimes used in gas dynamics is the com-
pressible isothermal Euler equations for a perfect gas in 1D, formulated as
𝜕𝜌
𝜕t + 𝜕(𝜌u)
𝜕x
= 0
(8.22a)

APPLICATIONS
173
0
0.5
1
1.5
2
2.5
3
0
0.5
1
ρ0
0
0.5
1
1.5
2
2.5
3
0
1
2
ρ
0
0.5
1
1.5
2
2.5
3
0
200
400
u
x
Figure 8.5
Evolution of density and velocity for Euler’s 1D model
𝜕(𝜌u)
𝜕t
+ 𝜕(𝜌u2 + p)
𝜕x
= 0
(8.22b)
p = K𝜌𝛾
(8.22c)
There are three nonlinear equations (one is algebraic) for the three unknowns 𝜌
( kg∕m3) (density), u (m/s) (velocity), and p ( N∕m2) (pressure).
In the so-called shock-tube problem, both ends of the tube are closed and a
diaphragm is separating two regions, one with high pressure and the other with low
pressure.
The ICs for density is
𝜌(x, 0) =
{
𝜌0,
x ≤L∕2
𝜌1,
x > L∕2 ,
u(x, 0) = 0
(8.23a)
and for velocity, it is u(x, 0) = 0
As BCs we have
u(0, t) = u(L, t) = 0
(8.23b)
For 𝜌(0, t), numerical BCs are used (see Section 8.2.6), i.e., the value of 𝜌at the
boundaries is extrapolated from the values of 𝜌inside the tube. The evolution of 𝜌
and u is sketched in Figure 8.5.

174
NUMERICAL METHODS FOR HYPERBOLIC PDEs
For 𝛾= 2, the equations also model the flow of a thin layer of fluid under grav-
ity, the “shallow water equations.” The problem above then becomes a model of a
“dam-break” simulation if 𝜌is exchanged to h (m), the height of the water.
Exercise 8.1.1. Verify that Etot in (8.21b) is constant in time.
Exercise 8.1.2. Verify that the Euler equations in (8.22) can be written in the form
(8.18). Find the jacobian A(u) and calculate the eigenvalues of the jacobian. Verify
that the system is hyperbolic.
8.2
NUMERICAL SOLUTION OF HYPERBOLIC PDEs
Hyperbolic PDEs can be solved numerically with finite difference, finite volume,
or finite element methods. In this chapter, the first two discretization methods are
presented. We use (8.13) as model problem.
When the method of lines (MoL), see Section 6.3.1, is applied to (8.13),we start by
discretizing the x interval 0 ≤x ≤1 into a grid x0, x1, … , xN, where x0 = 0, xN = 1,
and xi = ihx, hx = 1∕N. At the point x = xi, we discretize the PDE to an ODE with
Euler’s implicit method:
dui
dt = −aui −ui−1
hx
,
a > 0,
i = 1, 2, … N
We get the following ODE system:
du
dt = a
hx
Au + a
hx
f(t),
u(0) = u0
(8.24)
where
A =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
−1
0
0
…
0
1
−1
0
…
0
0
1
−1
…
0
.
.
.
…
0
.
.
.
…
0
0
0
0
…
−1
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
, f(t) =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
𝛼(t)
0
0
.
.
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
, u0 =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
u0(x1)
u0(x2)
u0(x3)
.
.
u0(xN)
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
(8.25)
The eigenvalues of the matrix (a∕hx)A are all 𝜆i = −a∕hx. Hence, they are all negative
and the system is stable.
If Euler’s explicit method is used to solve the time-dependent ODE system (8.24),
we know from Chapter 3 that the time step ht must fulfill the following condition to
obtain a numerically stable solution
ht𝜆i ∈SEE
→
a ht
hx
≤2
(8.26)

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
175
With a numerical test on (8.24) with Euler’s explicit method, we notice, however,
that when aht∕hx = 1.1, the numerical solution is unstable.
Hence, the theoretical stability result based on eigenvalue analysis as presented
for ODE systems in Chapter 3 is not correct for this semidiscretized hyperbolic PDE
model problem! The reason is that the matrix A in (8.25) is not diagonalizable! This
implies that the solution of the ODE system will have a strong initial polynomial
growth of size tN−1e−t. The difference equation system obtained with Euler’s method
will have a similar behavior. We therefore need another type of stability concept for
hyperbolic problems. In Section 8.4, the von Neumann analysis based on Fourier
analysis is presented.
Unless anything else is stated, the methods presented in this section are applied to
the model problem (8.13) only.
8.2.1
The Upwind Method (FTBS)
The method formulated above can be written as a difference equation, the FTBS
method (Forward-Time-Backward-Space):
ui,k+1 −ui,k
ht
= −a
ui,k −ui−1,k
hx
(8.27)
or
ui,k+1 = (1 −𝜎)ui,k + 𝜎ui−1,k
where 𝜎is defined as
𝜎= a ht
hx
(8.28)
The FTBS method (8.27) can also be illustrated by a stencil (see Figure 8.6).
The FTBS method, also called the upwind (or upstream) method, has first-order
accuracy in both space and time and the stability condition (see Section 8.4)
0 < 𝜎≤1
(8.29)
This inequality is known as the Courant–Friedrich–Lewy condition or simply the
CFL condition, from 1928 and 𝜎is called the Courant number. Richard Courant,
1 − σ
σ
Figure 8.6
Stencil for the FTBS method

176
NUMERICAL METHODS FOR HYPERBOLIC PDEs
−0.2
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
x
u(x, 0.5)
u(x, 0.5)
−0.2
0
0.2
0.4
0.6
0.8
1
−10
−5
0
5
10
x
Figure 8.7
Stable and unstable numerical solution of the advection equation
Kurt Friedrichs, and Hans Lewy were German American mathematicians, active
in the 20th century. Courant was the founder of the famous Courant Institute in
New York.
Applying the upwind method (8.27) to the model problem (8.13) with the IC
u(x, 0) = 0, x > 0 and the BC u(0, t) = 1, t > 0, i.e., a stepfunction, gives a numeri-
cal solution shown as a graph in Figure 8.7. In the figure, the stepsize combinations
ht = 0.8hx∕a and ht = 1.1hx∕a have been used. For the larger stepsize ht, the solution
will be unstable (the amplitude of the oscillations increases as time t increases).
With the “magic stepsize combination” ht = hx∕a, i.e., 𝜎= 1, however, it turns
out that the stepfunction will be perfectly preserved, moving along the positive x-axis
with speed a! See the modified equation (8.30) for an explanation.
For the smaller stepsize, we see that the numerical solution is smoothed out com-
pared to the exact solution. To understand this dissipation phenomenon, we can use
the modified equation, the PDE that is exactly satisfied by the numerical solution ui,k.
It can be derived using Taylor’s expansion. However, the modified PDE will be a
series having an infinite number of terms. If the series is truncated after a few terms,
we obtain a PDE from which information about the nature of its analytical solution
can be found.
To find the modified equation, replace ui,k by the function v = v(xi, tk) and Taylor
expand
v(xi, tk+1) = v(xi, tk) + ht
𝜕v
𝜕t (xi, tk) + h2
t
2
𝜕2v
𝜕t2 (xi, tk) + …

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
177
v(xi−1, tk) = v(xi, tk) −hx
𝜕v
𝜕x(xi, tk) + h2
x
2
𝜕2v
𝜕x2 (xi, tk) + …
Insert these expansions into (8.27) and the following PDE at the point (xi, tk) is found:
𝜕v
𝜕t + a𝜕v
𝜕x + ht
2
𝜕2v
𝜕t2 −ahx
2
𝜕2v
𝜕x2 + · · · = 0
Use the PDE (8.13) to obtain the following relations:
𝜕2v
𝜕t2 = −a 𝜕2v
𝜕x𝜕t = a2 𝜕2v
𝜕x2
Hence, replace vtt by a2vxx and we obtain the following modified equation after having
neglected higher order terms:
𝜕v
𝜕t + a𝜕v
𝜕x = ahx
2 (1 −𝜎)𝜕2v
𝜕x2
(8.30)
The right hand side term is a diffusion term and this causes the solution to be smoothed
out. Hence, the upwind method introducesdissipation into the numerical solution. We
see also that when 𝜎= 1, there is no diffusion term and no dissipation.
In the beginning of this chapter, Burgers’ inviscid equation (8.10) was presented.
The following example shows how a shock can develop from smooth initial data.
Example 8.5. (Burgers’ equation with the upwind method)
We choose the conservative form of Burgers’ equation, see also Example 8.5.
𝜕u
𝜕t + 𝜕u2
𝜕x = 0,
0 < x < 1,
t > 0
With IC u(x, 0) = cos(2𝜋x) + 1 and periodic BC u(0, t) = u(1, t), the upwind method
gives the following graph after a number of steps (Figure 8.8).
Exercise 8.2.1. Write a program or convince yourself by some hand calculations
that the upstream method with 𝜎= 1, the “magic stepsize combination” applied to
the model problem (8.13) with a step function as IC will preserve the step function
for t > 0.
8.2.2
The FTFS Method
When the parameter a in the advection equation (8.13)is negative,the upwind method
gives unstable solutions. Instead the FTFS method (Forward-Time-Forward-Space)
can be used
ui,k+1 −ui,k
ht
= −a
ui+1,k −ui,k
hx
i.e.,
ui,k+1 −ui,k = −𝜎(ui+1,k −ui,k)
(8.31)

178
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
x
u(x, 0), u(x, T)
Burgers equation with smooth initial function and developing shock
Initial function –>
<– Shock
Figure 8.8
Burger’s equation with smooth initial function and developing shock
8.2.3
The FTCS Method
To increase the accuracy, we try central differences in space, giving the FTCS method
(Forward-Time-Central-Space):
ui,k+1 −ui,k
ht
= −a
ui+1,k −ui−1,k
2hx
(8.32)
i.e.,
ui,k+1 = ui,k −𝜎
2 (ui+1,k −ui−1,k)
(8.33)
This method, however, turns out to be unstable for all ht, hx, see Section 8.3.
8.2.4
The Lax–Friedrich Method
Another method used in practice is the Lax–Friedrich method, which is first order in
time, second order in space, and symmetric, hence insensitive to the sign of a
ui,k+1 =
ui−1,k + ui+1,k
2
−𝜎
2 (ui+1,k −ui−1,k),
(8.34)
The Lax–Friedrich method is stable for −1 ≤𝜎≤1. The only difference compared
with the FTCS method is that ui,k in the right hand side of (8.33) is replaced by the
mean value of ui−1,k and ui+1,k in (8.34)

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
179
Exercise 8.2.2. Write a program or convince yourself by some hand calculations
that the Lax–Friedrich method with 𝜎= 1 applied to the model problem (8.13) with
a stepfunction as IC will preserve the stepfunction for t > 0.
Just like the upwind method, the Lax–Friedrich method also introduces smoothing
in the numerical solution. This can be explained by the modified equation.
Peter Lax is a Hungarian mathematician, now Prof.Em. at the Courant Institute.
He received the prestigious Abel price in 2005.
Exercise 8.2.3. Show that the modified equation for Lax–Friedrichs’ method
applied to (8.13) is
𝜕v
𝜕t + a𝜕v
𝜕x = a2ht
2
( 1
𝜎2 −1
) 𝜕2v
𝜕x2
Hence when 𝜎= ±1, there is no diffusion term.
8.2.5
The Leap-Frog Method
The leap-frog method (see Section 3.4)
ui,k+1 −ui,k−1
2ht
+ a
ui+1,k −ui−1,k
2hx
= 0
(8.35)
is second order in both time and space. It is stable for all values of 𝜎and does
not involve any diffusivity. For nonlinear problems, however, this method becomes
unstable for the model problem (8.13).
8.2.6
The Lax–Wendroff Method
Yet another method second order in both time and space is the Lax-Wendroff method.
This method is based on a trick, where derivatives in t are expressed as derivatives in
x. Start with Taylor expansion at the point (xi, tk):
u(xi, tk+1) = u(xi, tk) + ht
𝜕u
𝜕t (xi, tk) + h2
t
2
𝜕2u
𝜕t2 (xi, tk) + O(h3
t )
(8.36)
Use the PDE (8.13) to obtain the relations:
𝜕u
𝜕t = −a𝜕u
𝜕x,
𝜕2u
𝜕t2 = −a 𝜕2u
𝜕x𝜕t = a2 𝜕2u
𝜕x2
Insert space derivatives instead of time derivatives into the Taylor expansion, dis-
cretize and we obtain:
ui,k+1 = ui,k −𝜎
2 (ui+1,k −ui−1,k) + 𝜎2
2 (ui+1,k −2ui,k + ui−1,k)
(8.37)
The method is stable for −1 ≤𝜎≤1. When the Lax–Wendroff method is used there
is a problem at the right boundary. As there are no BCs at x = 1, we have to impose

180
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
–0.2
0
0.2
0.4
0.6
0.8
1
1.2
x
u(x, 1)
Figure 8.9
The model problem with Lax-Wendroff’s method, dispersion effects
artificial numerical boundaryconditionsin orderto be able to use the stencil. A simple
way to construct values at xN = 1 is to extrapolate the numerical solution by linear
extrapolation
uNk = uN−1,k + uN−1,k −uN−2,k = 2uN−1,k −uN−2,k
(8.38)
or, even better, quadratic extrapolation
When the Lax–Wendroff method is applied to the model problem with a step func-
tion as initial function, we obtain the result seen in Figure 8.9.
In Figure 8.9, we see that the Lax–Wendroff method generates spurious oscil-
lations. This is typical of a method being second order in time and is related to a
dispersion error introduced by the numerical method.
Burton Wendroff is an American mathematician still active.
If we let hx, ht →0 in the Lax–Wendroff discretization, we get the PDE expression
(8.13) in the left hand side and a diffusion term in the right hand side
𝜕u
𝜕t + a𝜕u
𝜕x = a2h2
t
2
𝜕2u
𝜕x2
(8.39)
Hence, the original hyperbolic PDE is approximated by a parabolic PDE, and the
solution can no longer contain discontinuities. Just as for the previous methods, this
is an example of artificial dissipation. Other methods with similar numerical behavior
are obtained if the test problem (8.13) is replaced by the PDE
𝜕u
𝜕t + a𝜕u
𝜕x = 𝜖𝜕2u
𝜕x2
where 𝜖is a small positive quantity.

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
181
λ
2(1 − λ)
λ
−1
Figure 8.10
Stencil for central differences applied to the wave equation
8.2.7
Numerical Method for the Wave Equation
A special case of hyperbolicPDE is the wave equation in Example 8.3. It is reasonable
to believe that there are special methods, efficient and accurate for this PDE. The
numerical treatment can be based on central difference approximations in both x and
t giving the following difference equation
ui,k+1 −2ui,k + ui,k−1
h2
t
= c2 ui+1,k −2ui,k + ui−1,k
h2x
This can be written as
ui,k+1 = 𝜎2ui+1,k + 2(1 −𝜎2)ui,k + 𝜎2ui−1,k −ui,k−1
(8.40a)
where 𝜎= cht∕hx. The corresponding stencil is shown in Figure 8.10, where 𝜆= 𝜎2.
This method gives stable solutions for −1 ≤𝜎≤1.
For the magic stepsize ht = hx∕c, a traveling wave u(x, t) = f(x −ct) with exact
initial values ui,0 = f(ihx),
ui,1 = f(ihx −cht), i = 0, 1, 2, … is exactly preserved
(in exact arithmetic) when 𝜎= 1 in (8.40a)
ui,k+1 = ui+1,k + ui−1,k −ui,k−1
(8.40b)
Example 8.6. (Wave equation with the magic stepsize)
Consider the wave equation in Example 8.3 (see also Example 5.3) with the parameter
values c = 1, L = 3, and initial conditions u0(x) = −sin(kx), v0(x) = 𝜔cos(kx) where
𝜔= 2𝜋and k = 2𝜋. Discretization according to (8.40b) with hx = L∕50, ht = hx∕c
and taking N = 10 time steps gives the numerical solution (Figure 8.11).
The wave equation is closely connected to Maxwell’s equations described in
Section 5.3.6. A simple form of these equations is (see Exercise 5.3.6)
𝜕Hy
𝜕t
= 1
𝜇0
𝜕Ez
𝜕x

182
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.5
1
1.5
2
2.5
3
−1.5
−1
−0.5
0
0.5
1
1.5
Wave equation with central differences
x
u
−> c 
Figure 8.11
Numerical solution of the wave equation
𝜕Ez
𝜕t = 1
𝜖0
𝜕Hy
𝜕x
One possible way to compute Ez and Hy would be to solve the two wave equations
for the two components. A better and more efficient way, however, is to use Yee’s
method on the first-order PDE system. That method is based on staggered grids (see
Section 3.5.3) in both the x and the t direction and is demonstrated on the system
(8.3), which is equivalent to the Maxwell equation system above
y2k+1∕2
i+1∕2 = y2k−1∕2
i+1∕2 + c ht
hx
(y1k
i+1 −y1k
i )
y1k+1
i
= y1k
i + c ht
hx
(y2k+1∕2
i+1∕2 −y2k+1∕2
i−1∕2 )
Hence, the two components y1 and y2 are computed on different grids. A compar-
ison with (3.57) shows that the method is based on the leap-frog method and has
second-orderaccuracy.It can also be shown to preservethe energyof the wave (8.21b)
if the energy is defined from a trapezoidal expression instead of the integral itself.
Exercise 8.2.4. Formulate the upwind method for the inhomogeneous advection
equation, i.e.,
𝜕u
𝜕t + a𝜕u
𝜕x = g(x, t)

THE FINITE VOLUME METHOD
183
Exercise 8.2.5. Give the stencil corresponding to the FTFS method in (8.31).
Exercise 8.2.6. Formulate a suitable difference approximation based on FTBS and
FTFS to solve numerically the counterflow heat problem in Example 8.2.
Exercise 8.2.7. Give the stencils corresponding to Lax–Friedrich’s method and
Lax–Wendroff’s method.
Exercise 8.2.8. As the method (8.40) is a two-step method, we need two ICs to
start up the difference equation. Use the ICs given in Example 8.3. Work out the
discretized ICs needed.
Exercise 8.2.9. Consider the wave equation in Example 8.3.
a) Discretize the x interval according to xi = ihx, i = 0, 1, 2, .., N + 1, where hx =
L∕(N + 1). With the MoL and central differences, a system of second-order
ODEs is obtained.
d2u
dt2 = Au,
u(0) = u0,
du
dt (0) = v0
Find the values of the matrix A and the vectors u0 and v0.
b) Write the system in (a) as a system of first-order ODEs
dw
dt = Bw,
w(0) = w0
Give the values of B and w0.
c) Calculate the eigenvalues of B.
d) If the explicit midpoint method (3.42) is used on the first-order system in (b),
for which time steps ht is the numerical solution stable?
8.3
THE FINITE VOLUME METHOD
In this section, the finite volume method (FVM) is treated. Just like the FDM and the
FEM, solution values are calculated at discrete grid points. In the FVM, each grid
point is surrounded by a control volume or cell. What the FVM has in advantage
compared to the other two methods is that the FVM gives approximate u values that
satisfy a discretized version of the integrated form of the conservation law (8.9a), i.e.,
∫
xi+1
xi
(u(x, tk+1) −u(x, tk))dx = ∫
tk+1
tk
(f(u(xi, t) −f(u(xi+1, t)))dt
(8.41)
where f(u(x, t)) is the flux function. The relation (8.41) simply means that the change
of a quantity u(x, t) accumulated in the “volume” [xi, xi+1] balances the net influx, i.e.,

184
NUMERICAL METHODS FOR HYPERBOLIC PDEs
the difference between influx to and outflux from the volume during the time interval
[tk, tk+1].
To explain the FVM in 1D, introduce a grid with grid points xi and the stepsize hx.
Also introduce control “volumes” Vi defined by the intervals [xi−1∕2, xi+1∕2], where
xi±1∕2 = (xi±1 + xi)∕2.
Now consider the conservation law (8.9)
𝜕u
𝜕t + 𝜕
𝜕x f(u) = 0
The volume average of u(x, t) at time tk in the volume Vi is
ui(tk) =
1
xi+1∕2 −xi−1∕2 ∫
xi+1∕2
xi−1∕2
u(x, tk)dx
(8.42)
and similar for t = tk+1. Now integrate (8.9) over the volume Vi
∫
xi+1∕2
xi−1∕2
𝜕u
𝜕t dx = f(ui−1∕2) −f(ui+1∕2)
where f(ui±1∕2) = f(u(xi±1∕2, t)) are the fluxes at the cell interfaces. Changing the
order of integration and differentiation gives
dui
dt = 1
hx
(f(ui−1∕2) −f(ui+1∕2))
(8.43)
which is an exact relation for the volume averages, i.e., no approximations have
been made so far. The ODE system (8.43) resembles the MoL, see Section 6.3.1,
but the right hand side contains expressions of u that are not known. If the explicit
Euler method with time step ht is used to approximate the time derivate and ui is
approximated by ui, we obtain the following conservative method, where ui±1∕2 can
be computed with, e.g., interpolation of the ui values.
ui,k+1 = ui,k + ht
hx
(f(ui−1∕2) −f(ui+1∕2))
(8.44)
By rearranging terms in (8.44) and summing over i, we obtain
hx
N
∑
i=1
(ui,k+1 −ui,k) = ht(f(u1∕2) −f(uN+1∕2))
which is the discrete version of the integral balance (8.41), equivalent to the basic
conservation law (8.9a).

SOME EXAMPLES OF STABILITY ANALYSIS FOR HYPERBOLIC PDEs
185
Example 8.7. (Numerical solution of Burgers’ equation, revisited)
Consider Burgers’ equation on conservative form
𝜕u
𝜕t + 1
2
𝜕u2
𝜕x = 0, −∞< x < ∞,
t > 0
with IC
u(x, 0) =
{
2,
x < 0
1,
x ≥0
and BC
u(0, t) =
{
1,
t = 0
2,
t > 0
Hence, the problem describes a shock coming in at x = 0 and moving in the positive
x direction.
Here the flux function is f(u) = u2∕2 and the upwind method gives
ui,k+1 = ui,k −ht
2hx
(u2
i,k −u2
i−1,k)
which is conservative in this form. Make a grid of the x interval [0, 2.5] using the
stepsize hx = 0.025 and of the t interval [0, 1] using the time step ht = 0.0125. Owing
to Rankine–Hugoniot’s relation (8.16), the speed s of the shock is s = 1.5. Hence, at
time t = 1, the shock has reached the x value x = s⋅1 = 1.5, which is in agreement
with Figure 8.10.
However,if the nonconservativeform of Burgers’ equation (8.10a)is used together
with the upwind scheme
ui,k+1 = ui,k −ht
hx
ui,k(ui,k −ui−1,k)
and the same values of the numerical parameters hx and ht, the shock speed is lower
than the speed obtained with the conservative form of the method, see Figure 8.12.
8.4
SOME EXAMPLES OF STABILITY ANALYSIS FOR HYPERBOLIC
PDEs
As was pointed out earlier and shown in an example, eigenvalue analysis is not ade-
quate for investigation of the stability of numerical solutions of hyperbolic PDEs.
As the wave equation generates periodic solutions, the appropriate tool for stability
analysis should be based on Fourier analysis.

186
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.5
1
1.5
2
2.5
1
1.2
1.4
1.6
1.8
2
x
u(x, 1)
Burgers equation on conservativs form and nonconservative form
Nonconservative form −>
<− Conservative form
Figure 8.12
Numerical computation of shock waves
As hyperbolic equations preserve waveforms, it seems natural to make the follow-
ing ansatz for the analytical solution:
u(x, t) = q(t)ej𝜔x
(8.45)
where j =
√
−1, 𝜔is a spatial frequency (wave number) and q(t) is a complex ampli-
tude function.
Hence, for the numerical solution ui,k, we make the ansatz:
ui,k = qkej𝜔xi
(8.46)
Insert this ansatz into the FTBS method in Section 8.2.1:
qk+1ej𝜔xi = (1 −𝜎)qkej𝜔xi + 𝜎qkej𝜔(xi−hx),
𝜎= a ht
hx
(8.47)
qk+1 = (1 −𝜎+ 𝜎e−j𝜔hx)qk = G(𝜎)qk
(8.48)
The absolute value of the complex factor G(𝜎) must be ≤1 for stability:
|G(𝜎)|2 = (1 −𝜎+ 𝜎cos(𝜔hx))2 + (𝜎sin(𝜔hx))2 = 1 −4𝜎(1 −𝜎)sin2(𝜔hx) (8.49)
We see that
|G(𝜎)| ≤1,
if
0 < 𝜎≤1

BIBLIOGRAPHY
187
i.e.,
0 < a ht
hx
≤1
Hence, we get a smaller stability interval by this analysis called von Neumann anal-
ysis than with the eigenvalues analysis! For hyperbolic problems, the von Neumann
analysis is the adequate one to use for stability investigations.
For the FTCS method in Section 8.2.3
ui,k+1 = ui,k −𝜎
2 (ui+1,k −ui−1,k)
the von Neumann analysis gives the formulas:
qk+1 = G(𝜎)qk
where
|G(𝜎)|2 = 1 + 𝜎2sin2(𝜔hx) > 1
Hence, the FCTS method is always unstable.
BIBLIOGRAPHY
1. A. Iserles, “A First Course in the Numerical Analysis of Differential Equations”, Cambridge
University Press, 1996
2. R. LeVeque, “Numerical Methods for Conservation Laws”, 1992
3. R.M.M. Mattheij, S.W. Rienstra, J.H.M. ten Thije Boonkkamp, “Partial Differential
Equations Modeling, Analysis, Computation”, Chapter 13, SIAM, 2005
4. G.D. Smith, “Numerical Solution of Partial Differential Equations”, Chapter 4, 3rd ed,
Oxford University Press, 1986
5. J.C. Strikwerda, “Finite Difference Schemes and Partial Differential Equations”, Chapman
and Hall, 1989
6. R. Vichnevetsky, J.B. Bowles, “Fourier Analysis of Numerical Approximations of Hyper-
bolic Equations”, SIAM, 1982


9
MATHEMATICAL MODELING WITH
DIFFERENTIAL EQUATIONS
When a differential equation is presented in a textbook, you may sometimes ask your-
self how it is derived. Are there any basic principles to follow when a differential
equation is set up? Can you perform the modeling of an engineering problem your-
self? There is no general answer to that question. Modeling is much of an art and
the result obtained depends on what type of problem you want to model and which
simplifying assumptions you make. In an area such as chemical engineering, it is
customary to set up differential equation models from conservation principles, i.e.,
you derive the model yourself. In electromagnetic field theory, on the other hand,
it is common to start from Maxwell’s equations in general form, impose simplifying
assumptions for your special problem to obtain a simpler differential equation model.
In control theory, it is customary to describe a model with a block diagram, which
can be translated into an ordinary differential equation (ODE) system.
To give an overview discussion of the art of modeling, it may be helpful to divide
differential equations occurring in applications into the following classes:
1. differential equations considered as nature laws
2. constitutive differential equations
3. conservative differential equations
With these mathematical tools, it is possible to set up models for many scientific
and engineeringproblems.In this chapter,we give an overviewof derivingdifferential
equation models in one space dimension, 1D. Some generalizations to 2D problems
and simplifications of general differential equations to less complex problems are also
shown.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

190
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
As before, in mathematical modeling, we stress upon using the units of the
variables, e.g., density (kg/m3), flow (kg/s), flux [kg/(m2 ⋅s)], and parameters,
e.g., g (m/s2).
9.1
NATURE LAWS
A nature law expressed as a differential equation is a mathematical relation that can-
not be derived from physical facts. Its validity depends on observations and the fact
that no experiment has been designed that contradicts the law. Examples of such laws
are Newton’s law for the motion of a particle, Maxwell’s laws for the electromagnetic
field, and Schrödinger’s equation in quantum mechanics.
To show how a mathematical model can be built on a nature law, we present here
Newton’s law for particle dynamics
md2r
dt2 = F
(9.1)
where F (N) is the force acting on the particle, m (kg) its mass, r (m) the position,
t (s) the time, and ⃗a = d2r∕dt2, the acceleration (m/s2) of the particle.
Example 9.1.
(Particle dynamics in 1D). A particle with the mass m (kg) is part of
a system consisting of a spring, a viscous damper, and the particle (see Figure 9.1).
The spring has the stiffness constant k (N/m) and the damper has the damping coef-
ficient c (N ⋅s/m).
The system is at rest, when the particle is in the position y = y0 relative to a y-axis
pointing vertically downwards. The particle is then forced to the position y1 > y0 and
left to move freely along the y-axis. If the position of the particle at time t is y(t), the
differential equation for the particle motion can be set up with the help of Newton’s
second law of motion
m̈y = F1 + F2 + F
k
c
m
y0
y(t)
y
F
Figure 9.1
Spring-damper system

NATURE LAWS
191
In the right hand side, we have the sum of
• the viscous force F1 = −cy
• the spring force F2 = −ky and
• the external force F
giving the following ODE model, known as the vibration equation:
md2y
dt2 + cdy
dt + ky = F
(9.2)
To get a unique solution, we need to specify the position and the velocity of the
particle at time t = 0, e.g., y(0) = y1, ̇y(0) = 0.
The external force can be of different types, e.g.,
a constant force, e.g., gravity: F = mg
an oscillating force: F = F0 sin (𝜔t)
Example 9.2.
(The vibrating string, a distributed model). An elastic string (e.g.,
a rubber band) with cross-section area A (m2) and density 𝜌(kg/m3) is tensely
fastened between two fixed points at the distance L (m) from each other. The
tension of the string is F (N). At time t = 0, the string is moved vertically from the
equilibrium position along the x-axis to a form given by the initial value function
u (x,0) = f(x), 0 ≤x ≤L and then released to move freely. Let the vertical distance
from the x-axis at a point P on the string be u(x, t). Let Q be another point where the
vertical distance to the x-axis is u(x + Δx, t) (Figure 9.2).
In this simplified model, the points P and Q can only move vertically. Hence we
have no motion in the x-direction and Newton’s second law for horizontal and vertical
motion can be written
−F1 cos 𝛼+ F2 cos 𝛽= 0
⇒
F1 cos 𝛼= F2 cos 𝛽= F
𝜌AΔxd2u
dt2 = −F1 sin 𝛼+ F2 sin 𝛽
0
x
x + Δx
L
x
F2
F1
P
Q
u (x)
Figure 9.2
The vibrating string

192
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
Elimination of F1 and F2 gives
𝜌AΔxd2u
dt2 = F(tan 𝛽−tan 𝛼)
As tan 𝛼= 𝜕u
𝜕x (x, t) and tan 𝛽= 𝜕u
𝜕x (x + Δx, t), we get
𝜌A
F
𝜕2u
𝜕t2 =
𝜕u
𝜕x(x + Δx, t) −𝜕u
𝜕x(x, t)
Δx
Let Δx →0 and we obtain the partial differential equation, the wave equation
𝜕2u
𝜕t2 = c2 𝜕2u
𝜕x2
(9.3)
where c2 = F/𝜌A. The parameter c (m/s) is the velocity of the wave.
To get a unique solution, we need boundaryconditions (BCs) and initial conditions
(ICs). The endpoints of the string are fixed, hence the BCs are
u(0, t) = 0,
u(L, t) = 0,
t ≥0
The ICs originate from the state of the string at t = 0, i.e., the string has a given form
and initial velocity zero, hence
u(x, 0) = f(x)
𝜕u
𝜕t (x, 0) = 0,
0 ≤x ≤L
9.2
CONSTITUTIVE EQUATIONS
A constitutive equation is a mathematical model of the physical properties of a gas,
fluid, or solid and can be either a differential equation or an algebraic equation. A
constitutive equation is usually the mathematical result of very many observations
of a phenomenon or measurements of an experiment and is therefore of empirical
nature.
We give here some examples of constitutive equations formulated in 1D.
9.2.1
Equations in Heat Transfer Problems
Fourier’s law of heat diffusion
q = −𝜅dT
dx
(9.4)
This is a relation between heat flux q [J/(m2 ⋅s)] and temperaturegradient. The param-
eter 𝜅[J/(K ⋅m ⋅s)] is the thermal conductivityof the material. Observe the minus sign
(the heat flow travels from higher to lower temperatures)!

CONSTITUTIVE EQUATIONS
193
This can also be written as a law for diffusion of thermal energy E = 𝜌CpT
q = −𝛼dE
dx
(9.5)
where q is the heat flux [J/(m2 ⋅s)], 𝛼thermal diffusivity (m2/s), 𝜌the density (kg/m3),
and Cp the heat capacity at constant pressure [J/(K ⋅kg)].
Newton’s law of cooling
Q = −kA(T0 −T)
(9.6)
This is a relation between the heat flow Q (J/s) from a region with temperature T to
an environment with temperature T0. The regions are separated by a wall of area A
(m2) with convection heat transfer coefficient k [J/(m2 ⋅s ⋅K)].
Stefan–Boltzmann’s law for temperature radiation loss
Q = −Ae𝜎(T4
0 −T4)
(9.7)
Radiation comes into account for high temperatures. Q (J/s) is the heat flow, A (m2)
the area of radiation, e a material constant, and 𝜎= 5.67⋅10−8 [J/(m2 ⋅s ⋅K4)] the
Boltzmann’s constant
9.2.2
Equations in Mass Diffusion Problems
Fick’s law of mass diffusion
f = −Dd𝜌
dx
(9.8)
This is a relation between mass flux f [kg/(m2 ⋅s)] and the density gradient. The
parameter D is the mass diffusivity (m2/s). There is also a derivative-free version
of Fick’s law (cf Newton’s cooling law)
F = −𝜇A
l (𝜌0 −𝜌)
(9.9)
This is a relation between the mass flow F (kg/s) from a region with density 𝜌to
an environment with density 𝜌0. The regions are separated by a wall through which
particles can diffuse. The diffusivity is 𝜇(m2/s), the area is A (m2), and the thickness
is l (m).
9.2.3
Equations in Mechanical Moment Diffusion Problems
Newton’s law of viscosity
𝜏xy = −𝜇dvx
dy
(9.10)
This is a relation between the shear stress 𝜏xy (N/m2) in a plane parallel to the direction
of the flow with velocity vx (m/s) along the x-axis and orthogonal to the y-axis and the

194
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
velocity gradient along the y-axis. The parameter 𝜇(N ⋅s/m2) is called the dynamic
viscosity.
If we write this law in the form
𝜏xy = −𝜈d(𝜌vx)
dy
(9.11)
the parameter 𝜈(m2/s) is called the kinematic viscosity (can also be regarded as the
diffusion coefficient of the mechanical moment).
9.2.4
Equations in Elastic Solid Mechanics Problems
Hooke’s law for an elastic bar
𝜎= E𝜖,
𝜖= du
dx
(9.12)
This is a relation between stress 𝜎(N/m2) and strain 𝜖[ ] (no dimension), where the
strain is the displacement u (m) per unit length of the bar. The parameter E is the
elasticity module (Young’s module) (N/m2).
9.2.5
Equations in Chemical Reaction Engineering Problems
The mass action law in chemical kinetics
r = k
m
∏
i=1
c𝛼i
i
(9.13)
This algebraic relation gives the rate r [mol/(m3 ⋅s)] of the reaction
𝛼1 A1 + … + 𝛼m Am →𝛽1 B1 + … + 𝛽n Bn
The reactants Ai, i = 1, … , m and the products Bi, i = 1, … , n are measured in con-
centrations ci (mol/m3) and the unit of the rate constant k depends on 𝛼1, … , 𝛼m. The
rate constant k is temperature dependent according to Arrhenius’ law
k = Ae−E
RT
(9.14)
where A [ ] is the preexponential factor, E (J/mol) the activation energy, T (K) the
temperature, and R = 8.314 J/(K ⋅mol) the gas constant.
The general gas law
pV = nRT
(9.15)
This is a relation between the pressure p (N/m2), the volume V (m3), the number of
moles n (mol), the temperature T (K), and the gas constant R.

CONSERVATIVE EQUATIONS
195
9.2.6
Equations in Electrical Engineering Problems
Ohm’s law in electromagnetics
j = 𝜎E
(9.16)
where j (A/m2) is the electrical current density, 𝜎[A/(V ⋅m)] the conductivity, and E
(V/m) the electric field strength. Lorentz’ law
F = q(E + v × B)
(9.17)
where F is the force (N) exerted on a charged particle with electric charge q (C) in
an electric field (V/m) and a magnetic field B (V ⋅s/m2). v (m/s) the velocity of the
particle.
9.3
CONSERVATIVE EQUATIONS
Conservation equations are based on the principle that physical quantities, such as
mass, moment, and energy, are conserved in a system. Assume we study the changes
of some quantity in a control volume that is fixed in space. From a purely logical
point of view, the following balance principle must hold for the quantity during a
given time interval:
ΔAcc = In −Out + Prod −Cons
(9.18)
where
• ΔAcc = the change of amount of the accumulated quantity
• In = the amount of the quantity that has flowed in
• Out = the amount of the quantity that has flowed out
• Prod = the amount of the quantity produced and
• Cons = the amount of the quantity consumed
In scientific and engineering contexts, quantities usually change smoothly with
time. Let M(t) be a differentiable function denoting the amount of a quantity at
time t. We then define the flow Q(t) as
Q(t) = dM
dt
(9.19)
The flow is measured in amount per unit time.
Define in, out, prod, and cons as the flows of In, Out, Prod, and Cons. Using (9.18)
during the time interval [t, t + Δt] gives the following relation:
ΔAcc = ∫
t+Δt
t
(in(t) −out(t) + prod(t) −cons(t)) dt
(9.20)

196
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
Divide by Δt, let Δt →0 and we obtain
dAcc
dt
= in −out + prod −cons
(9.21)
This relation is often referred to as the continuity equation. Here it is expressed as an
ODE, but if the amount of the quantity depends on both time and space, the continuity
equation will be a partial differential equation (PDE).
A conservation principle leading to an ODE with time as independent variable is
called a lumped model. Such a model does not take into account any space variations
of the quantities. A conservation law leading to a PDE in time and space is called a
distributed model.
We show in a number of examples how this principle can be used to derive differ-
ential equations for the conservation of a given quantity.
9.3.1
Some Examples of Lumped Models
Example 9.3.
(Model for the water contents in a tank). Assume we have a tank
which is filled with water from a pipe delivering the flow Q1 (m3/s) (see Figure 9.3).
It is drained at the bottom through another pipe with the flow Q2 (m3/s).
Let V (m3) be the amount of water accumulated in the tank. Application of the
continuity principle (9.18) during the time interval [t, t + Δt] gives the following
equality:
ΔV = Q1 ⋅Δt −Q2 ⋅Δt
corresponding to
ΔAcc = In −Out
Divide this relation by Δt, let Δt →0 and we obtain the following ODE:
dV
dt = Q1 −Q2
corresponding to
dAcc
dt
= in −out
Q1
Q2
V1
Figure 9.3
Tank filled with water

CONSERVATIVE EQUATIONS
197
Qin
c
V
Figure 9.4
Continuously stirred tank reactor
If the volume is known at t = 0, we also have an IC. Denote the initial volume by
V0 (m3). We now have the initial value problem (IVP)
dV
dt = Q1 −Q2,
V(0) = V0
(9.22)
Example 9.4.
(A continuously stirred tank reactor). A continuously stirred tank
reactor is a chemical reactor where chemical species are stirred together from inflow
of reactants to a homogeneous mix (see Figure 9.4). In this mix, the reactions take
place and products are formed. Assume the inflow to the reactor is Qin (m3/s) and that
the concentration of A in the inflow is c0 (mol/m3). In the reactor, A reacts according
to A →B and is thereby consumed with the rate kc, where k (s−1) is the rate constant
of the reaction and c (mol/m3) is the concentration of A in the reactor. Assume there
is no outflow from the reactor. Then the volume will be increasing. The concentration
of A in the reactor at time t = 0 is c(0) = 0 and the volume at t = 0 is V(0) = V0. Using
the conservation law for the number of moles cV of A in the reactor and the volume
V of the mix, we obtain
d(cV)
dt
= Qin c0 −kcV,
c(0) = 0
(9.23a)
dV
dt = Qin,
V(0) = V0
(9.23b)
9.3.2
Some Examples of Distributed Models
Example 9.5.
(The continuity equation in 1D). Assume we have a pipe with
cross-section area A (m2) through which some fluid flows (see Figure 9.5). The
density of the fluid is 𝜌(x, t) (kg/m3) and the flux is q(x, t) [kg/(s⋅m2)]. We use the
relation (9.21) to derive the continuity equation. Consider the small volume ΔV
between x and x + Δx. At the left end, the flux is q(x, t) and the density is 𝜌(x, t). At
the right end, the flux is q (x + Δx, t) and the density is 𝜌(x + Δx, t).

198
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
x
x
A
A
x + Δx
ρ (x + Δx, t)
q (x + Δx, t)
ρ (x, t)
q (x, t)
Figure 9.5
Illustration of the continuity equation
The accumulated amount of mass in ΔV at time t is ∫x+Δx
x
𝜌(x, t)A dx. The conti-
nuity equation (9.21) gives
d
dt ∫
x+Δx
x
𝜌(x, t) A dx = q(x, t)A −q(x + Δx, t)A
(9.24)
Using the mean value theorem of integral calculus gives
Δxd𝜌(x + 𝜃Δx, t)
dt
= −(q(x + Δx, t) −q(x, t)),
0 < 𝜃< 1
Dividing by Δx, and letting Δx →0 gives
𝜕𝜌
𝜕t + 𝜕q
𝜕x = 0
(9.25)
which is the PDE of mass conservation called the continuity equation in 1D.
However, (9.25)is mathematically insufficient. There are two dependentvariables,
𝜌and q, but only one equation. Hence, we need one more equation, e.g., a constitutive
equation giving a second relation between 𝜌and q. The following alternatives are
possible:
1. mass flow according to a general nonlinear flux function q = f(𝜌)
2. mass flow with constant velocity v (m/s) through the pipe: q = v𝜌
3. mass flow governed by mass diffusion: q = −D d𝜌
dx
4. a combination of (2) and (3): q = v𝜌−D d𝜌
dx
Inserting (1) into (9.25) gives
𝜕𝜌
𝜕t + 𝜕f(𝜌)
𝜕x
= 0
(9.26)
This equation is often called the scalar conservation law and is a nonlinear hyperbolic
PDE (see Chapter 8).
Inserting (2) into (9.25) gives
𝜕𝜌
𝜕t + v𝜕𝜌
𝜕x = 0
(9.27)

CONSERVATIVE EQUATIONS
199
Hence, we obtain the advection equation (1.4) presented in Chapter 1. This is a linear
hyperbolic PDE.
Inserting (3) into (9.25) gives
𝜕𝜌
𝜕t = D𝜕2𝜌
𝜕x2
(9.28)
This equation we recognize as the diffusion equation, which is a parabolic PDE (see
Chapter 6).
Inserting (4) into (9.25) gives
𝜕𝜌
𝜕t + v𝜕𝜌
𝜕x = D𝜕2𝜌
𝜕x2
(9.29)
This equation we recognize as the convection-diffusion equation, classified as a
hyperbolic–parabolic PDE.
If there is also production of the substance in the pipe (through, e.g., chemical
reaction) with the rate r(c) [mol/(m3 ⋅s)] depending on the concentration c, we obtain
a PDE known as the convection–diffusion–reaction equation
𝜕c
𝜕t + v𝜕c
𝜕x = D𝜕2c
𝜕x2 + r(c)
(9.30)
Example 9.6.
(Energy conservation in a cooled cylindrical pipe).
Assume a hot fluid is flowing through a cylindrical pipe with radius R (m) in the
z-direction according to Figure 9.6. The temperature T(z, t) of the fluid at time t and
at the space point z changes as the pipe is cooled on the outside. The temperature
of the cooling medium is constant and has the value Tout. The thermal energy flux
through the pipe is q(z, t) [J/(m2 ⋅s)]. The density of the fluid is 𝜌(kg/m3), the heat
capacity is C [J/(K ⋅kg)], and the convection heat transfer coefficient of the wall is
k [J/(K ⋅m2 ⋅s)]. The four parameters 𝜌, C, k, and Tout are constants, while the state
variables temperature T(z, t) and energy flux q(z, t) of the fluid vary with time t and
space z. Following the balance principle (9.24), we get
d
dt ∫
z+Δz
z
T(z, t)𝜌C𝜋R2 dz = q(z, t)𝜋R2 −q(z + Δz, t)𝜋R2
−k(T −Tout)2𝜋RΔz(1)
(9.31)
Taking limit values with Δz →0, we obtain the PDE
𝜌C𝜕T
𝜕t = −𝜕q
𝜕z −2k
R (T −Tout)
(9.32)
However, we have only one equation but two unknowns T(z, t) and q (z, t). The miss-
ing equation is obtained from a constitutive equation that relates the flux q to the

200
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
z
A
A
T (z, t) 
Figure 9.6
Hot fluid in a cylindrical pipe
temperature T. If we assume that the heat transport takes place through convection
and Diffusion, we have
q = v𝜌CT −𝜅dT
dz
Inserting this expression into the PDE, we finally obtain
𝜌C𝜕T
𝜕t + v𝜌C𝜕T
𝜕z = 𝜅𝜕2T
𝜕z2 −2k
R (T −Tout)
(9.33)
which is the PDE presented in Example 6.1, where an IC and two BCs are added to
this parabolic PDE.
If the problem is time independent, we obtain the BVP in Example 4.1.
If we reducethe modelfurtherby assuming that the diffusiontransportis negligible
compared to the convective transport, we obtain the first-order ODE
v𝜌CdT
dz = −2k
R (T −Tout)
(9.34)
for which we need only one condition, an IC.
If we assume that the heat leaking out of the wall is negligible (k = 0), the problem
is reduced to the simple ODE
v𝜌CdT
dz = 0
(9.35)
which with the IC T(0) = T0 gives the solution T = T0. Hence, by increasing the
number of reduction assumptions, the model soon becomes uninteresting!
On the other hand, the model can be made more complex by taking into account
transport in more than one space dimension. If we assume that heat is transported by
diffusion also in the r-direction, we have to add a corresponding term to (9.33) and
move the heat loss through the wall to a BC
𝜌C𝜕T
𝜕t + v𝜌C𝜕T
𝜕z = 𝜅𝜕2T
𝜕z2 + 𝜅1
r
𝜕
𝜕r
(
r𝜕T
𝜕r
)
(9.36)
This time-dependent 2D parabolic PDE is also presented in Example 6.2. Now the
flow in a pipe problem has reached a level detail, which may be unnecessarily high for

SCALING OF DIFFERENTIAL EQUATIONS TO DIMENSIONLESS FORM
201
being an engineering problem.Hence, modeling is also about how to choose sufficient
complexity in the model.
Exercise 9.3.1. Derive the time-dependent counterflow heat exchanger model in
Example 8.2
9.4
SCALING OF DIFFERENTIAL EQUATIONS TO DIMENSIONLESS
FORM
When the differentialequation of a scientific or engineeringprocessis formed through
modeling, it is natural to think of all variables introduced in the model as phys-
ical or chemical quantities. Hence, the variables have some dimension, i.e., they
are expressed in units such as kg, J/(m2 ⋅s), and mol/(m3 ⋅s). The parameters in the
model, coming, e.g., from the constitutive equations, have dimensions as well.
Observe that the word dimension has many meanings: (i) the dimension of a vector
is the number of elements in the vector, (ii) the dimension of space can be modeled
in 1D, 2D, and 3D, (iii) the dimension of a physical variable or parameter is a com-
bination of elementary units, s.a. m, s, kg, etc.
However, when the model is to be treated mathematically and/or numerically, it is
often advantageous to scale the variables of the model to dimensionless form. This
means that for the variable x with dimension (m), we introduce a dimensionless vari-
able 𝜉= x/L, where L (m) is a characteristic length of the problem. Likewise, the
time variable t (s) is scaled to dimensionless time through 𝜏= t/t0, where t0 is a
characteristic time of the problem.
Through the scaling, the derivatives of the original model will be transformed to
derivatives of the dimensionless variables. We show here how the first and second
derivatives are changed.
dx
dt = d(L𝜉)
d(t0𝜏) = L
t0
d𝜉
d𝜏
(9.37)
d2x
dt2 = d
dt
(dx
dt
)
=
d
d(t0𝜏)
(
L
t0
d𝜉
d𝜏
)
= L
t2
0
d2𝜉
d𝜏2
(9.38)
We see that a consequence of scaling is that certain parameter combinations will
appear in the scaled model. Usually these combinations can be arranged so that
dimensionless combinations are formed.
Scaling of the original differential equation model can have several advantages:
• If the scaling is done correctly, i.e., with scaling factors characteristic of the
problem, the new dimensionless variables for, e.g., length and time will be of
order 1.
• The number of parameters in the scaled model will be smaller than in the orig-
inal model.

202
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
• When comparing the size of the individual terms of the differential equation
model, it is easier to judge which terms are important and which can be
neglected in the scaled model. This may help to reduce the original model to a
model that is mathematically simpler.
Example 9.7.
The continuously stirred tank reactor model in Example 9.4. The
following differential equation model is given:
d(cV)
dt
= qin c0 −kcV,
c(0) = 0
(9.39a)
dV
dt = qin,
V(0) = V0
(9.39b)
The units of the variables and parameters are
c,c0
V,V0
t
qin
k
(mol/m3)
(m3)
(s)
(m3/s)
(s−1)
Introduce the scaled dimensionless variables x, y, and 𝜏
x = c∕c0,
y = V∕V0,
𝜏= t∕T
where T is a characteristic time of the problem, yet to be determined. Express the
original problem (9.23) in the scaled variables
c0 V0
T
d(xy)
d𝜏
= qin c0 −kc0 V0xy,
x(0) = 0
V0
T
dy
dt = qin,
y(0) = 1
Multiply the first ODE by T/c0V0 and the second ODE by T/V0
d(xy)
d𝜏
= qinT
V0
−kTxy,
x(0) = 0
dy
d𝜏= qinT
V0
,
V0y(0) = V0
We see that there are two possibilities to make time dimensionless: either T = V0/qin
or T = 1/k. The first choice leads to the ODE system
d(xy)
d𝜏
= 1 −a1xy,
x(0) = 0
dy
d𝜏= 1,
y(0) = 1
where a1 is the dimensionless parameter a1 = V0k/qin.

SCALING OF DIFFERENTIAL EQUATIONS TO DIMENSIONLESS FORM
203
The other possibility, T = 1/k, leads to the ODE system
d(xy)
d𝜏
= a2 −xy,
x(0) = 0
dy
d𝜏= a2,
y(0) = 1
where a2 = V0k/qin. We see that in both Cases, the original number of parameters is
reduced from four (c0, V0, qin, k) to only one (a1 or a2).
Exercise 9.4.1. A 1D version of Navier–Stokes equations is
𝜌
(𝜕v
𝜕t + v𝜕v
𝜕x
)
= −𝜕p
𝜕x + 𝜇𝜕2v
𝜕x2 + 𝜌g
(9.40)
with appropriate ICs and BCs. In (9.40), 𝜌is the density, v the velocity, p the pres-
sure, 𝜇the dynamic viscosity, and g the gravitational constant. The variables and the
parameters have the following units:
𝜌
v
t
x
p
𝜇
g
(kg/m3)
(m/s)
(s)
(m)
(N/m2)
(N ⋅s/m2)
(m/s2)
Introduce dimensionless variables: v* = v/V, x* = x/L, p* = (p −p0)/𝜌V2, t* = tV/L,
where V is a characteristic velocity, L a characteristic length, and p0 is a reference
pressure. All the parameters are assumed to be constant. The original differential
equation will be expressed in the dimensionless variables and the dimensionless
parameters Reynold’s number Re = LV𝜌∕𝜇and Froude’s number Fr = V2∕gL
Exercise 9.4.2. A model for stationary 1D heat transport presented in Example 4.1
is the following differential equation:
𝜌CpvdT
dz = 𝜅d2T
dz2 −2k
R (T −Tout)
T(0) = T0, T(L) = Tout
(9.41)
The units of the variables and parameters are
T, T0, Tout
z, L
v
𝜅
𝜌
Cp
(K)
(m)
(m/s)
[J/(K ⋅m ⋅s)]
(kg/m3)
[J/(K ⋅kg)]
Introduce the scaling
u = T∕Tout,
𝜉= z∕L
and bring the differential equation on dimensionless form. Which dimensionless
parameter combinations will appear in the scaled model?

204
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
Exercise 9.4.3. Given the vibration equation in mechanics
md2u
dt2 + cdu
dt + ku = F sin(𝜔t)
(9.42)
where all parameters m, c, k, F, and 𝜔are positive quantities. Which are the dimen-
sions of the variables and the parameters? Let 𝜔0 =
√
k∕m, c0 = 2
√
km 𝛼= c/c0,
and 𝛽= 𝜔/𝜔0. Introduce dimensionless time 𝜏= 𝜔0t and dimensionless deviation
y = u/u0, where u0 is a suitable combination of some parameters in (9.42).
Find this scaling factor u0 and show that in the new variables y and 𝜏, the differ-
ential equation (9.42) can be written (𝛼is called the damping factor)
d2y
d𝜏2 + 2𝛼dy
d𝜏+ y = sin(𝛽𝜏)
Exercise 9.4.4. The following chemical reactions occur in enzyme catalysis:
S + E ←→C −→P + E
The kinetics of the system is modeled by the ODE system
̇S = −k1SE + k−1C,
S(0) = S0
̇E = −k1SE + k−1C + k2C,
E(0) = E0
̇C = k1SE −k−1C −k2C,
C(0) = 0
̇P = k2C,
P(0) = 0
where S, E, C, and P represent the concentrations (mol/m3) of the four species taking
part in the reactions. The parameters k1 [m3/(mol⋅s)] k−1 (1/s) and k2 (1/s) are the rate
constants of the reactions. Note first that there are linear relationships between the
right hand side expressions, so we need differential equations for only two variables,
say S and C, the other two variables depend linearly on these.
1. Find the ODE system for S and C (eliminate E and P).
2. Transform by scaling of S, C, and t the system in (1) into dimensionless form.
Use the scaled variables s = S/S0 and c = C/E0. The time t should be scaled
to dimensionless time 𝜏as 𝜏= t/T, where T is chosen so that the scaled ODE
system contains as few parameters as possible.
BIBLIOGRAPHY
1. E. Baltram, Mathematics for Dynamic Modeling, Academic Press, 1987
2. N. Fawkes, J. Mahony, An Introduction to Mathematical Modeling, Wiley, 1994
3. J.D. Logan, Applied Mathematics, Wiley, 1997

10
APPLIED PROJECTS ON
DIFFERENTIAL EQUATIONS
The following projects have been used for a long time in a first advanced course on
Numerical Solution of Differential Equations at KTH, Stockholm. Most of the
projects have been developed and modified during several years by my colleague
Gerd Eriksson, and I have her permission to present them in updated form in this
book. Projects 4 and 5 are taken from one of the early manuals of COMSOL
MULTIPHYSICS®, see also Appendix B.2. They have kindly given me permission
to publish them in updated form.
Project 1. Signal propagation in a long electrical conductor
Given a 10 km long conductor with resistance R, inductance L, and capacitance
C. From x = 0, signals of amplitude 1V are sent frequently during time intervals of
different lengths. Denote this time-dependent voltage by u0(t). The voltage in the
conductor is a function u(x, t) of the position x on the conductor and time t and is
modeled by the following hyperbolic partial differential equation (PDE)
𝜕2u
𝜕t2 + R
L
𝜕u
𝜕t = 1
LC
𝜕2u
𝜕x2 ,
0 ≤x ≤X,
t > 0
which is the wave equation with damping. At t = 0, the initial conditions (ICs) are
u(x, 0) = 0,
𝜕u
𝜕t (x, 0) = 0,
0 < x ≤X
where X = 104.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

206
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
The boundary condition (BC) at x = 0 is the given signal u0(t), i.e.,
u(0, t) = u0(t)
At x = X, the conductor is open, i.e., the signal is not reflected but disappears out.
The BC fulfilling this condition is the advection equation, i.e.,
𝜕u
𝜕t (X, t) +
1
√
LC
𝜕u
𝜕x (X, t) = 0
Discretize the conductor into 100 subintervals and use central difference
approximations for the space and time derivatives in the damped wave equation.
As for the approximation of the BC at x = X, the upwind method Forward-Time-
Backward-Space (FTBS) is appropriate.
For the conductor, the following parameter values are given: R = 0.004 ohm,
L = 10−6 H, and C = 0.25 ⋅10−8 F. Simulate the signal propagation during a
sufficiently long time, e.g., during 3 ms. First use the maximum allowed time step
fulfilling the stability condition, then use a time step being 80% of the maximum
time step. What is your comments on the result of the two time steps that have been
used? Is the smoothing of the solution the effect of damping or of the method used?
Start your simulations by testing u0(t) with the MATLAB function given below. It
corresponds to three short signals repeatedly sent with a period of 0.0004s.
function usignal=uzero(t)
tau=rem(t,0.0004);
T0=0; T1=0.00005; T2= 0.00010; T3= 0.00013; T4= 0.00018; T5= 0.00025;
u0=1;
m=length(t);u1=zeros(m,1);
ind=find(t0<=tau & tau<=T1 | T2<=tau & tau <=T3 | T4<=tau & tau<=T5);
u1(ind)=u0*ones(size(ind));
usignal=u1;
You can of course try your own signal sequences.
Project 2. Flow in a cylindrical pipe
In a long straight pipe with circular cross section with radius R, a fluid is streaming
and we want to find out how the flow velocity varies in the pipe. Let the velocity
vector be (u, v)T where u is the velocity in the length direction of the pipe and v the
velocity in the radial direction. The flow is assumed to be circular symmetric, i.e., in
cylindrical coordinates u(r, z) and v(r, z) depend only on r and z, not 𝜑.
At the inlet z = 0, the velocity of the fluid is u0 = 0.1 m∕s in the z direction, i.e.,
u(r, 0) = u0, v(r, 0) = 0, 0 ≤r ≤R. The radius R = 0.05 m. The fluid has density
𝜌= 1000 kg∕m3 and the viscosity is 𝜈= 10−5 m2∕s. In fluid problems, the Reynolds
number Re = u0R∕𝜈is an important constant. When Re >> 1, which is the case here,
it is possible to simplify the complicated Navier–Stokes PDEs that are used to model
u(r, z) and v(r, z).

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
207
In this flow problem, Navier–Stokes equations are approximated by
u𝜕u
𝜕z = 𝜈
(
𝜕2u
𝜕r2 + 1
r
𝜕u
𝜕r
)
−v𝜕u
𝜕r −1
𝜌
dp
dz
(10.1)
𝜕u
𝜕z + 1
r
𝜕(vr)
𝜕r
= 0
(10.2)
The pressure p is only z dependent. At z = 0, p = p0, where p0 = 104 Pa. At r = 0,
we have the following BC
𝜕u
𝜕r (0, z) = 0,
v(0, z) = 0
At the wall of the pipe, the two velocities are zero, i.e.,
u(R, z) = 0,
v(R, z) = 0
Far away in the pipe, several meters from the inlet, the velocity will have a sta-
tionary distribution with parabolic shape
u = 2u0
(
1 −
( r
R
)2)
,
v = 0
(10.3)
The task is to compute how the velocities vary with r and z. It is also included
to compute how far away from the inlet the stationary distribution (10.3) is attained
with an acceptable tolerance.
The differential equations (10.1) and (10.2) must be treated specially at r = 0
where both are singular. Show that with l’Hospital’s rule they turn into
u𝜕u
𝜕z = 2𝜈𝜕2u
𝜕r2 −1
𝜌
dp
dz ,
𝜕u
𝜕z + 2𝜕v
𝜕r = 0,
at
r = 0
For numerical treatment, the MoL with n = 50 subintervals in the r direction
is used. Then there will be 2n unknown variables being functions of z. These
are u1(z), u2(z),…, un(z), 𝜎(z), v2(z), v3(z),…, vn(z). u1(z) and v1(z) are velocity
functions at r = 0. We know that v1(z) = 0, hence this component is not among the
unknowns. The variable 𝜎is defined as
𝜎(z) = 1
𝜌
dp
dz
With difference approximations of all derivatives in the r direction, we will have
n ODEs (ordinary differential equations) each of (10.1) and (10.2), hence 2n in total.
To solve, these Euler’s implicit method shall be used with stepsize hz. The equations
(10.1) and (10.2) will then be approximated by
ui
ui −uold
i
hz
−Fi(ui−1, ui, ui+1, 𝜎, vi) = 0,
ui −uold
i
hz
+ Gi(vi−1, vi, vi+1) = 0

208
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
where ui and vi denote the unknownvelocity componentsat z + hz and uold
i
denotes the
already computed velocity component at the previous value z. Find the expressions
for Fi and Gi.
At the end of the day, there will be a nonlinear system of 2n algebraic equations
to be solved at each step in the z direction. This is done with Newton’s method. If the
unknowns are written in the order u1, u2,…, un, 𝜎, v2, v3,…, vn, the jacobian J will
have a block structure consisting of four n × n matrices
J =
(
J1
J2
J3
J4
)
where J1 is tridiagonal, J2 has nonzero elements only in the first column and in the
diagonal, J3 is diagonal, and J4 is tridiagonal (perhaps with exception of the first row,
depending on the difference approximation of 2(𝜕v∕𝜕r)r=0).
Close to the inlet, there will be large variations in the velocities. The first steps
should be hz = 0.001 up to z = 0.005. Continue with hz = 0.005 to z = 0.04. Further
up in the pipe, the step hz can be successively larger. Continue the calculations of u
and v and the pressure p up to the value of z where the velocity has approximately
has attained its stationary distribution. Present the result graphically!
Project 3. Soliton waves
From Wikipedia, we get the following information about soliton waves:
“In mathematics and physics, a soliton is a self-reinforcing solitary wave (a wave
packet or pulse) that maintains its shape while it travels at constant speed. Solitons
are caused by a cancellation of nonlinear and dispersive effects in the medium. (The
term dispersive effects refers to a property of certain systems where the speed of the
waves varies according to frequency.) Solitons arise as the solutions of a widespread
class of weakly nonlinear dispersive partial differential equations describing physical
systems.”
The soliton phenomenon was first described in 1834 by John Scott Russell
(1808–1882) who observed a solitary wave in the Union Canal in Scotland. He
reproduced the phenomenon in a wave tank and named it the “Wave of Translation”.
Solitons are modeled by the following nonlinear PDE formulated by Korteweg
and de Vries in 1895
𝜕u
𝜕t = −6u𝜕u
𝜕x −𝜕3u
𝜕x3
We study the x interval −12 ≤x ≤12 with periodic BCs
u(12, t) = u(−12, t),
𝜕ku
𝜕xk (12, t) = 𝜕ku
𝜕xk (−12, t), k = 1, 2, ...
For a soliton to appear, the IC must have a special form and amplitude. The following
IC can be used
u(x, 0) =
27
cosh(x) + cosh(3x)

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
209
Use the Method of Lines with 240 subintervals for the discretization of the x interval.
The problem then turns into a system of ODEs
du
dt = F(u)
Perform computer simulations from t = 0 to tend = 1.2 with the Runge–Kutta
classical method RK4 with the time step ht = 0.001.
Show and explain what happens if you take a larger step ht = 0.002.
Test how sensitive the soliton wave is when the amplitude of the IC is changed.
How much enlargement/reduction in the amplitude is allowed for keeping the soliton
effect?
An implicit method like the trapezoidal method is an alternative to RK4. What are
the advantages and disadvantages when using this method?
Project 4. Wave scattering in a waveguide
A plane wave is sent into a waveguideat the left end. Due to reflexes fromthe walls,
the plane wave is scattered. We want to investigate how the bend of the waveguide
affects the wave for different frequencies at the end of the waveguide.
The waves are modeled by the 2D wave equation
𝜕2U
𝜕t2 = 𝜕2U
𝜕x2 + 𝜕2U
𝜕y2
The time dependence is eliminated if the wave is monochromatic with a given
wavelength 𝜆. Let 𝜔= 2𝜋∕𝜆and make the ansatz
U(x, y, t) = u(x, y)ei𝜔t
The wave equation is then reduced to Helmholtz’ equation
𝜕2u
𝜕x2 + 𝜕2u
𝜕y2 = −𝜔2u
with appropriate BCs. On the reflective walls of metal, there are no waves, hence
u = 0 at the walls. At the exit of the waveguide, we have an absorbing BC, which
means that the wave disappears out from the guide. This is modeled by the advection
equation
𝜕U
𝜕t + 𝜕U
𝜕y = 0
if the y-axis is directed downwards. If the time dependence is eliminated, the BC at
y = yout is
𝜕u
𝜕y + i𝜔u = 0

210
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
At the inlet of the guide where x = 0, the wave U(0, y, t) consists of two parts, one
incoming plane wave ei𝜔(t−x) and one representing reflections from the interior,
V = U(0, y, t) −ei𝜔(t−x). For the wave part V, there is the same kind of absorbing BC
as at the exit, i.e.,
𝜕V
𝜕t −𝜕V
𝜕x = 0
Inserting the expression for V gives after some formula manipulation the BC at x = 0
𝜕u
𝜕x −i𝜔u + 2i𝜔= 0
We now have a 2D elliptic PDE with mixed Dirichlet and Neumann conditions.
The geometrical form of the waveguide is inserted into a square with the side
0.20 m. The width of the waveguide is 0.04 m . The contour of the waveguide
is obtained from the following (x, y) coordinates, where the y-axis is directed
downwards
x=[0,0.16,0.20,0.20,0.16,0.16,0.14,0]
y=[0,0,0.04,0.20,0.20,0.06,0.04,0.04]
It is interesting to investigate cases where the wavelength of the incoming wave has
about the same size as the width of the waveguide. Experiment with wavelengths 𝜆
in the region 30 to 80 mm.
Use first the stepsize hx = hy = 0.005 then hx = hy = 0.0025. What advantages
and disadvantages are there with another halving of the stepsize?
The probleminvolvescomplex-valuedquantities, which implies that the numerical
solution components ui,j have complex values. In the graphical presentation plot the
real part of u, which can be interpreted as the wave propagation in the waveguide at
a frozen time point.
Project 5. Metal block with heat source and thermometer
Given a homogeneous metal block with rectangular cross section 0.30 × 0.20 m2.
In the block, there is a stationary heat distribution modeled by Poisson’s equation in
2D with appropriate BCs. Inside the block, there is a heat source with cross section
0.04 × 0.04 m2 with its left side situated 0.04 m from the left side of the rectangle
and symmetrically positioned in the y direction. The metal block has heat exchange
with the environment through its left wall (x = 0) through a thin layer of glass.
The remaining three walls are heat insulated.
The task here is to compute the temperature distribution in the metal block at
stationary conditions. The temperature u(x, y) is modeled by Poisson’s equation
𝛽
(
𝜕2u
𝜕x2 + 𝜕2u
𝜕y2
)
= −q(x, y)
where 𝛽= 45 [W∕(m ⋅K)] is the thermal conductivity of the metal. This value is
also valid in the quadratic region with the heat source. We assume that the heat

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
211
source gives an evenly distributed heat flow of q(x, y) = 20,000∕0.042 W∕m3 inside
the quadratic region. Outside of this region q(x, y) = 0. In grid points on the boundary
of the quadratic region, half the q value is used.
The temperature of the environment is uout = 20∘C. The heat transfer coefficient
of the glass layer is Kc = 900. Hence, the BC at x = 0 is
𝛽𝜕u
𝜕x (0, y) = −Kc(uout −u(0, y))
The isolated walls of the metal block gives the BCs 𝜕u∕𝜕y = 0 at the upper (y = 0.20)
and the lower (y = 0) wall and 𝜕u∕𝜕x = 0 at the right wall (x = 0.30).
Discretize the problem with three different stepsizes, hx = hy = 0.02, 0.01, and
0.005. Plot contour curves of the temperature distribution and note specially the
maximumtemperatureof the metal block (which is found inside the quadraticregion).
Also note the temperature at the position of the thermometer, which is the point
(0.16, 0.10).
Project 6. Deformation of a circular metal plate
A circular metal plate with thickness t = 5 m and the radius R = 50 mm is simply
supported on a circular frame with the same radius. The plate is loaded transversally
with an equally distributed pressure q (Pa). In this problem, there is no 𝜑dependence
in the deformation u(r, 𝜑), when described in polar coordinates. Hence, the dependent
variable in the ODE modeling the deformation is r.
d4u
dr4 + 2
r
d3u
dr3 −𝛾2
r2
d2u
dr2 + 𝛾2
r3
du
dr = −q
Dr
,
Dr = t3
12
Er
(1 −𝜈2
𝜑r∕𝛾2)
The material constants are E𝜑= 40, 000 MPa, Er = 10, 000 MPa, 𝛾2 = E𝜑∕Er, 𝜈𝜑r =
0.24. The load pressure is constant q = 0.15.
The BCs of this fourth-order ODE is at r = 0 u′(0) = 0, u′′′(0) = 0. At r = R, the
deformation and the moment Mr are both zero. Since Mr = −Dr(u′′ + 𝜈𝜑ru′∕r), we
have the BCs u(R) = 0 and u′′(R) + 𝜈𝜑ru′(R)∕R = 0.
Discretize the problem in N subintervals and approximate all derivatives in the
problem with difference quotients of second order. This will lead to a linear system
of equations with a band matrix of band width five. Use the symmetry of the problem,
i.e., that u−1 = u1 and u−2 = u2. Start with N = 50 giving the stepsize h = R∕N and
continue with the stepsizes h∕2 and h∕4. Plot the result in a graph showing the three
stepsize approximations of u(r) in the same figure. To solve the linear system of
equations use sparse technique available in, e.g., MATLAB(R).
The ODE is singular at r = 0. Use l’Hopital’s rule to find the form of the ODE at
r = 0.
In the problem, discretizations of u′′′(0) and uIV(ri) are needed. Use the ansatz
u′′′(0) = au(2h) + bu(h) + cu(0) + du(−h) + eu(2h)
h3

212
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
and determine the coefficients a, b, c, d, e so that the difference quotient is of second
order. Make a similar ansatz to approximate the fourth derivative.
Project 7. Cooling of a crystal ball
The cooling of crystal glass needs attention in the production process. Quick
cooling is wanted to keep the cost lower but may cause the glass to break. A crystal
ball with radius R shall be cooled down from 980∘C to room temperature. The
temperature lowering in the oven takes place in a controlled way and depends on the
adjusted temperature parameter T that starts at t = 0 until t = T according to
f(t) = 980e−3.9t∕T
For t > T, we have f(t) = 980e−3.9 = 19.8, hence normal room temperature.
The heat equation for a homogeneous sphere follows the PDE
𝜕u
𝜕t = D
r
𝜕2(ru)
𝜕r2 ,
0 < r < R,
t > 0
The thermal diffusivity for crystal glass is D = 4.0 ⋅10−7 m2∕s. At r = 0, we have
the BC 𝜕u
𝜕r = 0. Hence, at this Boundary, the heat equation takes the form
𝜕u
𝜕t = 3D𝜕2u
𝜕r2
Prove this with the help of l’Hopital’s rule. The BC at r = R is u(R, t) = f(t). When
the cooling starts, the temperature of the ball is 980∘C.
Of special interest is the temperature gradient in the r direction—the glass may
break if ||
𝜕u
𝜕r || is too large. In our case, we assume that the glass will break if the gradient
on any occasion exceeds 6000∘C, which will happen if the cooling is too quick. Make
numerical experiments with the parameter T and find the smallest value of T in the
cases R = 6, 12, and 18 cm.
Compute the temperature u(r, t) in the glass ball from t = 0 until its surface has
cooled down to room temperature.
Try discretization with 60 intervals in the r direction. Use the MoL and an appro-
priate ODE solver or use the implicit Euler method with small time steps in the
beginning and then increase the time step.
Visualize the result graphically.
Project 8. Rotating fluid in a cylinder
In a cylinder, there is a viscous fluid. The radius of the cylinder is R = 40 mm.
The cylinder with its content is rotating with an angular velocity 𝜔, so that u𝜑= 𝜔r,
0 ≤r ≤R. The fluid has no velocity in the r or z direction, only the velocity
component u = u𝜑.

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
213
Suddenly at t = 0, the cylinder stops. The movement of the fluid for t > 0 is
modeled by the PDE
𝜕u
𝜕t = 𝜈
(
1
r
𝜕
𝜕r
(
r𝜕u
𝜕r
)
−u
r2 + 𝜕2u
𝜕z2
)
,
0 < r < R,
0 < z < H
where H is the height of the cylinder and 𝜈is the viscosity coefficient. The BCs are
u = 0 at r = 0 and r = R. Also u = 0 at z = 0 and z = H. The parameter 𝜈has the
value 10−6 m2∕s (the value for water). The angular velocity has the value 𝜔= 1.
We want to compute and plot curves to see how the velocity u(r, z, t) of the fluid
changes with time.
1. Assume that the cylinder is very high. Then the velocity is independent of z.
This model simplification makes the PDE depend on only t and r and hence
1D in space. Use, e.g., the Crank–Nicolson method to compute the velocity
distribution u(r, t) in the fluid. Plot curves with the velocity of the fluid as
function of the radius at different time points.
2. Now assume the cylinder has the height H = 8 cm. The fact that the velocity is
zero at z = 0 and z = H will influence the velocity distribution in the cylinder.
Use, e.g., the Crank–Nicolson method again for the numerical solution of this
2D problem. Plot the velocity distribution at different time points with the
contourf command in MATLAB (R). Discuss the difference of the two
results.


APPENDIX A
SOME NUMERICAL AND
MATHEMATICAL TOOLS
A.1
NEWTON’S METHOD FOR SYSTEMS OF NONLINEAR
ALGEBRAIC EQUATIONS
A.1.1
Quadratic Systems
Numerical solution of the nonlinear system of equations
f(u) = 0
(A.1)
can be achieved with Newton’s method.
Assume that f ∶ℝn →ℝn and that f is twice continuously differentiable. A solu-
tion u∗is called a root of (A.1). Often there are several roots to a nonlinear system.
The jacobian J(u) of f(u) is a quadratic matrix
J(u) = 𝜕f
𝜕u =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
𝜕f1
𝜕u1
𝜕f1
𝜕u2
…
𝜕f1
𝜕un
𝜕f2
𝜕u1
𝜕f2
𝜕u2
…
𝜕f2
𝜕un
⋮
⋮
…
⋮
𝜕fn
𝜕u1
𝜕fn
𝜕u2
…
𝜕fn
𝜕un
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
(A.2)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

216
SOME NUMERICAL AND MATHEMATICAL TOOLS
Newton’s method is based on successive approximation using Taylor’s expansion
formula at a point u(i)
f(u) = f(u(i)) + J(u(i))(u −u(i)) + hot
(A.3)
where hot denotes higher order terms. The point u(i) should be regarded as an approx-
imation of u∗and the aim is to find a more accurate approximation.
If the term hot is neglected, (A.3) corresponds to a linear approximation of f(u)
in the neighborhood of the point u(i), i.e.,
f(u) ≈f(u(i)) + J(u(i))(u −u(i))
(A.4)
If f(u) in (A.1) is replaced by the right hand side of (A.4), we obtain
f(u(i)) + J(u(i))(u −u(i)) = 0
(A.5)
This is a linear system of equations, the solution u(i+1) of which can be written as
u(i+1) = u(i) −
(
J(u(i))
)−1f(u(i))
(A.6)
The formula (A.6) together with a start value u(0) defines an iterative sequence
for finding an approximate solution to u∗and is called Newton’s method. The iter-
ation formula (A.6) is based on inversion of the jacobian. Since matrix inversion is
more inefficient and more sensitive to rounding errors than Gaussian elimination, one
iteration step is instead computed in two computational steps
u(i+1) = u(i) + h(i)
(A.7)
where h(i), the correction term, is obtained by solving the linear system of equations
J(u(i))h(i) = −f(u(i))
(A.8)
by Gaussian elimination.
By using the Matlab operator \, the two steps (A.7) and (A.8) can be written in one
step (Gaussian elimination is used by the operator \).
u(i+1) = u(i) −J(u(i))∖f(u(i))
(A.9)
The iteration is proceeded (i) until some convergence criterium like ‖h(i)‖ < 𝜖is
fulfilled or (ii) until some maximum number of iterations have been reached or (iii)
until the iterates u(i) have become too large in value. In the cases (ii) and (iii), the
sequence is assumed to diverge.
One important reason for divergence is that the start value u(0) is not close enough
to the root we want to determine. Finding a start value is often not trivial.You can
try to neglect the nonlinear terms and/or neglect terms with small coefficients to see

NEWTON’S METHOD FOR SYSTEMS OF NONLINEAR ALGEBRAIC EQUATIONS
217
whether a simpler system occurs. You may also try some “standard” values, e.g.,
u(0) = (0, 0, … , 0)T or u(0) = (1, 1, … , 1)T or try to utilize the applicational back-
ground to find a suitable start value.
Example A.1.
Solve the following system of equations with Newton’s method:
f(u) =
⎛
⎜
⎜⎝
+15u1
+u2
+u2
3
−30
−u1
+30u2
+u3
−30
−u2
1
+u2
+100u3
−20
⎞
⎟
⎟⎠
= 0
For this example, a start value can be obtained by neglecting nonlinear terms and
terms with small coefficients, which gives
15u1 = 30,
30u2 = 30,
100u3 = 20
=⇒
u1 = 2,
u2 = 1,
u3 = 0.2
We obtain
u0 =
⎛
⎜
⎜⎝
2
1
0.2
⎞
⎟
⎟⎠
,
=⇒
f0 =
⎛
⎜
⎜⎝
1.04
−1.8
−3
⎞
⎟
⎟⎠
,
J0 =
⎛
⎜
⎜⎝
15
1
0.4
−1
30
1
−4
1
100
⎞
⎟
⎟⎠
The linear system of equations to be solved in the first iteration is
⎛
⎜
⎜⎝
15
1
0.4
−1
30
1
−4
1
100
⎞
⎟
⎟⎠
⎛
⎜
⎜⎝
h1
h2
h3
⎞
⎟
⎟⎠
= −
⎛
⎜
⎜⎝
1.04
−1.8
−3
⎞
⎟
⎟⎠
Solving this system gives the first correction h0 and the first iterate u1
h0 =
⎛
⎜
⎜⎝
−0.0738
0.0567
0.0265
⎞
⎟
⎟⎠
,
=⇒
u1 = u0 + h0 =
⎛
⎜
⎜⎝
1.9262
1.0567
0.2265
⎞
⎟
⎟⎠
After two more iterations, the sequence has converged to four decimal accuracy
u∗= (1.9251, 1.0717, 0.2263)T.
When the start value is close to the solution, the convergence is very fast.
Newton’s method has quadratic convergence, which means that the correction terms
‖h(i)‖ behave as
‖h(i+1)‖ ≈C‖h(i)‖2
(A.10)

218
SOME NUMERICAL AND MATHEMATICAL TOOLS
A.1.2
Overdetermined Systems
Newton’s method can be modified to solve overdetermined systems of nonlinear
equations
r(p) ≈0
(A.11)
where r ∈ℝm, p ∈ℝn, and m > n. Hence, there are more equations than unknowns
so we have to specify in what sense the solution is wanted. Note that the notation has
been changed. The reason for this change is that overdetermined systems often occur
in least squares problems, where we want to minimize the Euclidean length of the
residual vector r with respect to the components of a parameter vector p.
The algorithm described here, Gauss–Newton’s method, will converge (when it
converges) to a solution in the least squares sense, i.e., to a point p∗giving a (local)
minimum to the sum of squares of the residuals r(p)Tr(p).
Systems of type (A.11) occur, e.g., in curve-fitting problems when a parameter
vector p in a nonlinear algebraic model g(p, t) is to be fitted to measurements (tk, gk)
g(p, tk) ≈gk,
k = 1, 2, … , m
(A.12)
which can also be written in the form (A.11)
r(p) ≡g(p) −g ≈0
(A.13)
where g(p) = (g(p, t1), g(p, t2), … , g(p, tm))T. The linear approximation of r(p) at the
point p(i) is of the same form as (A.4), but the jacobian is now a rectangular m × n
matrix. Replacing the left hand side of (A.11) by its linear approximation gives an
overdetermined linear system of equations
r(p(i)) + J(p(i))(p −p(i)) ≈0
(A.14)
This system is solved in the least squares sense giving the solution p(i+1)
p(i+1) = p(i) −(J(p(i)))+r(p(i))
(A.15)
where J(p))+ is the pseudoinverse of the jacobian
(J(p))+ = (J(p)TJ(p))−1J(p)T
(A.16)
The iterative method (A.15) is called Gauss–Newton’s method for solution of the
nonlinear least squares problem.
The iteration formula (A.15) can be written without the pseudoinverse using the
Matlab operator \ as in (A.9)
p(i+1) = p(i) −J(p(i))∖r(p(i))
(A.17)
Like quadratic systems it is important to have a good start value p(0) for convergence
of Gauss–Newton’s method. Note, however, that Gauss–Newton’s method has only
linear convergence.

SOME FACTS ABOUT LINEAR DIFFERENCE EQUATIONS
219
A.2
SOME FACTS ABOUT LINEAR DIFFERENCE EQUATIONS
When a discretization method is used to solve a differential equation, the ordinary
differential equation (ODE) or the partial differential equation (PDE) is approxi-
mated by a difference equation, i.e., a relation between successive solution points
u0, u1, … , un, un+1, … where n takes only integer values. As an example, we
can take the second-order backward differentiation formula (BDF) method (see
Chapter 3)
∇un + 1
2∇2 un = hfn
(A.18)
If we use the definitions
∇un = un −un−1
∇2 un = un −2un−1 + un−2
(A.19)
we can also write the method as a relation between un values
3
2un −2un−1 + 1
2un−2 = hfn
(A.20)
called a difference equation (or recurrence equation).
A general definition of a kth-order difference equation (Δ-eqn) is
F(n, un, un−1, un−2, … , un−k) = 0
(A.21)
The general solution of such an equation will depend on n and contain k arbitrary
constants, i.e.,
un = f(n, C1, C2, … , Ck)
(A.22)
where C1, C2, … , Ck are determined from the initial or boundary conditions (BCs)
of the Δ-eqn.
An important special case of (A.21) is a linear Δ-eqn with constant coefficients.
We show first the homogeneous form
un + a1un−1 + a2un−2 + … + akun−k = 0
(A.23)
Associate with this Δ-eqn, the characteristic equation
𝜇k + a1𝜇k−1 + a2𝜇k−2 + … + ak = 0
(A.24)
The roots of this polynomial equation of degree k are denoted by
𝜇1, 𝜇2, … , 𝜇k
(A.25)

220
SOME NUMERICAL AND MATHEMATICAL TOOLS
If all the roots are different, the general solution of (A.23) is
un = C1𝜇n
1 + C2𝜇n
2 + … + Ck𝜇n
k
(A.26)
where C1, C2, … , Ck are arbitrary constants (note that they enter linearly). Compare
the technique of solving a linear Δ-eqn with constant coefficients with the technique
for a linear ODE with constant coefficients. The fundamental solutions for the Δ-eqn
is 𝜇n
i , for the ODE it is e𝜇ix.
If there are multiple roots, the general solution expression must be modified. Say,
e.g., that 𝜇1 = 𝜇2 (double root). Then the general solution is
un = (C1 + C2n)𝜇n
1 + C3𝜇n
3 + … + Ck𝜇n
k
(A.27)
The inhomogeneous form of (A.23) is
un + a1un−1 + a2un−2 + … + akun−k = bn
(A.28)
Just as in the ODE case, we first have to find a particular solution pn satisfying (A.28).
The general solution is then (provided the characteristic roots are all different)
un = pn + C1𝜇n
1 + C2𝜇n
2 + … + Ck𝜇n
k
(A.29)
From the general solution (A.26), we see that un is stable, i.e., the un values are
bounded as n →∞, if
|𝜇i| ≤1
(A.30)
If 𝜇i is a multiple root, the stability condition must be modified to
|𝜇i| < 1
(A.31)
Example A.2.
Given the difference equation
un + 3un−1 + 2un−2 = 0,
u0 = 1, u1 = 2
By inserting n = 2, 3, 4, … we get u2 = −8, u3 = 20, u4 = −44, … . What is un in
general, i.e., a formula of type un = f(n)?
Solve first the characteristic equation
𝜇2 + 3𝜇+ 2 = 0
with the solution
𝜇1 = −1,
𝜇2 = −2
Hence, the general solution is
un = C1(−1)n + C2(−2)n

SOME FACTS ABOUT LINEAR DIFFERENCE EQUATIONS
221
Insert the initial conditions
u0 = C1 + C2 = 1
u1 = −C1 −2C2 = 2
which gives C1 = 4, C2 = −3 and the solution is
un = 4(−1)n −3(−2)n
Example A.3.
What is the stability area of the explicit midpoint method?
Apply the method to u′ = 𝜆u and we get the Δ-eqn
un+1 = un−1 + 2h𝜆un
and the characteristic equation is
𝜇2 −2𝜆h𝜇−1 = 0
where 𝜆is a complex-valued parameter.
Write one root on polar form 𝜇1 = rei𝜙. Since 𝜇1𝜇2 = −1, we get 𝜇2 =
−(1∕r)e−i𝜙.
For a stable solution, we must have r = 1. Since 𝜇1 + 𝜇2 = 2𝜆h, we get ei𝜙−e−i𝜙=
2𝜆h, i.e.,
𝜆h = i sin 𝜙
Hence, the stability area of the explicit midpoint method is the interval [−i, i] on the
imaginary axis.
Example A.4.
Compute the eigenvalues of the tridiagonal matrix
A = tridiagn(−1, 2, −1) =
⎛
⎜
⎜
⎜
⎜⎝
2
−1
0
…
0
−1
2
−1
⋱
⋮
0
⋱
⋱
⋱
0
⋮
⋱
−1
2
−1
0
…
0
−1
2
⎞
⎟
⎟
⎟
⎟⎠
The eigenvalue problem Au = 𝜆u for this problem is formulated as a Δ-eqn
−uk−1 + 2uk −uk+1 = 𝜆uk,
k = 1, 2, … , n
Since there are no u0- or un+1 components in u, we set these components to zero and
obtain a boundary value problem for a Δ-eqn
uk+1 + (𝜆−2)uk + uk−1 = 0,
u0 = 0,
un+1 = 0

222
SOME NUMERICAL AND MATHEMATICAL TOOLS
The roots of the characteristic equation
𝜇2 + (𝜆−2)𝜇+ 1 = 0
are denoted by 𝜇1 and 𝜇2. The roots fulfill the relations
𝜇1𝜇2 = 1,
𝜇1 + 𝜇2 = 2 −𝜆
Hence, if 𝜇1 = rei𝜙, then 𝜇2 = (1∕r)e−i𝜙if we use the polar form. The general solu-
tion of the Δ-eqn (if 𝜇1 ≠𝜇2) is
uk = C1𝜇k
1 + C2𝜇k
2
Insert the BCs
u0 = C1 + C2 = 0 →C2 = −C1
un+1 = C1𝜇n+1
1
+ C2𝜇n+1
2
= 0
The condition C2 = −C1 above is used and we get
C1𝜇n+1
1
= C1𝜇n+1
2
We want a nontrivial solution, i.e., C1 ≠0, which gives
(𝜇1
𝜇2
)n+1
= 1
or if we use the polar form of 𝜇1 and 𝜇2
r2e2i𝜙(n+1) = 1
which gives
r = 1,
2i𝜙(n + 1) = 2𝜋ik,
k = 1, 2, … , n
𝜙k =
𝜋k
n + 1,
k = 1, 2, … , n
The values k = 0 and k = n + 1 must be excluded in the formula above, since we
then obtain 𝜇1 = 𝜇2 = 1 or 𝜇1 = 𝜇2 = −1, respectively, i.e., double roots, in which
case uk = (C1 + C2k)→C1 = C2 = 0, i.e., the trivial solution.
As a final result, we obtain
2 −𝜆= 𝜇1 + 𝜇2 = ei𝜙+ e−i𝜙= 2 cos 𝜙

DERIVATION OF DIFFERENCE APPROXIMATIONS
223
Hence, the eigenvalues are
𝜆k = 2(1 −cos 𝜙k) = 4sin2(𝜙k∕2),
k = 1, 2, … , n
The smallest eigenvalue is obtained from k = 1: 𝜆1 ≈𝜋2/(n + 1)2 and the largest for
k = n: 𝜆n ≈4.
A.3
DERIVATION OF DIFFERENCE APPROXIMATIONS
Difference approximation of derivative terms in ODEs and BCs are based on Taylor’s
formula
f(x + h) = f(x) + hf ′(x) + h2
2 f ′′(x) + h3
6 f ′′′(x) + h4
24f (4)(x) + h5
(A.32)
The Taylor expansion is suitable since a difference approximation should be valid
locally in the neighborhood of a point x.
We have already seen the following examples of central difference approxima-
tions:
du
dx(x) = u(x + h) −u(x −h)
2h
+ h2
(A.33)
d2u
dx2 (x) = u(x + h) −2u(x) + u(x −h)
h2
+ h2
(A.34)
How are similar formulas derived when approximationsto higher order derivatives
or unsymmetric formulas for the derivatives are needed? As a first example, assume
we need a difference approximation to f ′(x) when the function values f(x), f(x + h),
and f(x + 2h) are available. Make the following linear ansatz:
f ′(x) = af(x) + bf(x + h) + cf(x + 2h) + hp
(A.35)
where a, b, and c are to be determined so that the approximation order p is as high as
possible. Use Taylor’s formula on f(x + h) and f(x + 2h)
f ′(x) = af(x) + b(f(x) + hf ′(x) + h2
2 f ′′(x)) + c(f(x)
+ 2hf ′(x) + (2h)2
2
f ′′(x)) + h3
Since there are three unknown coefficients a, b, and c to determine, we need three
equations. They are obtained by identifying coefficients in front of f(x), f ′(x),
f ′′(x), … in the left and right hand side
a + b + c = 0
hb + 2hc = 1
h2
2 b + (2h)2
2
c = 0

224
SOME NUMERICAL AND MATHEMATICAL TOOLS
The solution is
⎛
⎜
⎜⎝
a
b
c
⎞
⎟
⎟⎠
= 1
2h
⎛
⎜
⎜⎝
−3
4
−1
⎞
⎟
⎟⎠
Hence, the unsymmetric difference approximation is
f ′(x) = −3f(x) + 4f(x + h) −f(x + 2h)
2h
+ e(x)
(A.36)
where e(x) is the approximation error. What is the approximation order p? Look at
the next term in the Taylor expansion and insert the solution a, b, and c
e(x) =
(
bh3
6 + c(2h)3
6
)
f ′′′(x) = −h2
3 f ′′′(x) = h2
(A.37)
Hence, the approximation (A.36) is of second order.
With the same technique, the following difference approximations can be derived:
f ′′′(x) = f(x + 2h) −2f(x + h) + 2f(x −h) −f(x −2h)
2h3
+ h2
f (4)(x) = f(x + 2h) −4f(x + h) + 6f(x) −4f(x −h) + f(x −2h)
h4
+ h2
Deriving difference approximations based on Taylor’s formula can be systemized
with an elegant technique called operator calculus, see [1]. Define the following
operators
Ef(x) = f(x + h)
(A.38)
Δf(x) = f(x + h) −f(x)
(A.39)
∇f(x) = f(x) −f(x −h)
(A.40)
Df(x) = f ′(x)
(A.41)
Taylor’s formula can be written
Ef(x) =
(
1 + hD + (hD)2
2
+ (hD)3
6
+ …
)
f(x)
(A.42)
i.e.,
E = ehD
(A.43)
Since E = Δ + 1, we have
hD = log(1 + Δ) = Δ −Δ2
2 + Δ3
3 + …
(A.44)

THE INTERPRETATIONS OF GRAD, DIV, AND CURL
225
With this operator formalism, (A.36) can be derived by retaining only the first two
terms in (A.44)
D ≈1
h
(
Δ −Δ2
2
)
= 1
h
(
E −1 −1
2(E −1)2)
f ′(x) ≈1
h
(
f(x + h) −f(x) −1
2(f(x + 2h) −2f(x + h) + f(x))
)
= −3f(x) + 4f(x + h) −f(x + 2h)
2h
The approximation error is obtained from the first neglected term in (A.44)
e(x) = 1
h
Δ3
3 f(x) = 1
3h(ehD −1)3f(x) = … = −h2
3 f ′′′(x)
The algebra of operator calculus can be generalized to inversion. Since
Enf(x) = f(x + nh) →E−1f(x) = f(x −h)
we get
∇= 1 −E−1
(A.45)
With this relation, we can derive other approximations to f ′(x) from
hD = −log(1 −∇) = ∇+ ∇2
2 + ∇3
3 + …
(A.46)
Retaining only the first two terms gives
D ≈1
h
(
∇+ ∇2
2
)
= 3f(x) −4f(x −h) + f(x −2h)
2h
BIBLIOGRAPHY
1. G. Dahlquist and Å. Björck, “Numerical Methods,” Dover, 2003
A.4
THE INTERPRETATIONS OF GRAD, DIV, AND CURL
The gradient. Let Φ(r) be a scalar-valued field, where r = (x, y)T. From a fixed point
r0, let d be a vector of unit length 1, i.e., ‖d‖2
2 = dTd = 1, defining a direction from
r0. With Taylor expansion, we obtain
Φ(r0 + d) = Φ(r0) + ∇dΦ(r0) + hot

226
SOME NUMERICAL AND MATHEMATICAL TOOLS
x
y
Contour curves of z = 2x2 + 4y4 − 4xy − 4x + 8
−1
0
1
2
3
4
5
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
Figure A.1
Contour curves with a gradient inserted
where ∇dΦ = dT∇Φ is called the direction derivative of Φ in the direction d. ∇dΦ
can be interpreted as the velocity with which Φ changes when moving away from r0
in the direction d. The largest values of the velocity is obtained for d = ±∇Φ(r0).
Hence, Φ increases fastest in the direction of the gradient and decreases fastest in
the direction of the negative gradient, also called the steepest descent direction, see
Section A.5.2 (Figure A.1).
A contour curve of Φ is a curve along which the function has a constant value. The
gradient at a point is always orthogonal to the contour curve through that point. In a
point where the direction d is orthogonal to ∇Φ(r0), i.e., ∇dΦ(r0) = 0, Φ does not
change (if hot is neglected). This direction is in fact the tangent of the contour curve
at the point.
The divergence. Let 𝜕Ω be a positively oriented curve enclosing the region Ω in
R2. Let P(x, y) and Q(x, y) be two continuously differentiable functions in Ω. Then
use Green’s theorem
∮𝜕Ω
Pdx + Qdy = ∫
∫Ω
(𝜕Q
𝜕x −𝜕P
𝜕y
)
dxdy
How can this theorem be used? To be a little more precise, assume that the boundary
curve is defined by the vector r(s), where the parameter s is the arclength of the curve
measured from some initial point r0 = r(0). When s is increased, the curve moves
counterclockwise (see Figure A.2).

THE INTERPRETATIONS OF GRAD, DIV, AND CURL
227
F(s)
s
x
y
et
en
x′(s)
y′(s)
y′(s)
−x′(s)
x
y
∂Ω
Ω
Figure A.2
Tangent and normal directions at a point on a curve
The unit vector in the tangent direction, et, is
et = dr
ds = (x′(s), y′(s))T
The unit vector in the normal direction pointing out of Ω, en, is
en = (y′(s), −x′(s))T
We now show the meaning of the operator div applied to heat flow:
Assume there is a heat flux F = (P(x, y), Q(x, y))T, measured in J∕(m2 ⋅s), in a thin
plate of thickness h (m). The shape of the plate corresponds to the region Ω. The total
flow of heat out of Ω is obtained if we sum the contributions of flow out from each
little area section hds along 𝜕Ω. The heat flow, measured in J∕s, in the outward normal
direction from such a section is F ⋅en ⋅h ⋅ds. The net heat flow, i.e., the difference
between the outflow out of Ω and the inflow into Ω is (Figure A.3)
h∮𝜕Ω
F ⋅en ds
Using Green’s theorem on this integral, we arrive at Gauss’ theorem:
∮𝜕Ω
F ⋅en ds = ∮𝜕Ω
(Py′(s) −Qx′(s))ds
= ∫∫Ω
(
𝜕P
𝜕x + 𝜕Q
𝜕y
)
dxdy = ∫∫Ω
div F dxdy
Hence, if div F = 0 in the whole of Ω, the net flow of heat out of Ω is zero, in other
words: the heat flow into Ω = the heat flow out of Ω. What is the interpretation if

228
SOME NUMERICAL AND MATHEMATICAL TOOLS
en
F
F•en
ds
x
y
∂Ω
Ω
Figure A.3
Flux vector at a point on the boundary projected to the normal direction
div F ≠0? Apply Gauss’ theorem to a small area A of Ω, so small that div F can be
considered constant in A. The net flow out of the small volume hA is
h∮𝜕A
F ⋅en ds ≈hA div F ⇒
div F ≈1
hAh∮𝜕A
F ⋅en ds
Hence, div F can be interpreted as the amount of heat energy produced (div F > 0) or
consumed (div F < 0) per unit time and unit volume [J∕(m3 ⋅s)] by the vector field
F in Ω. Hence, div F is the source strength of the field F.
The curl (rotation). In a similar way, curl can be given an interpretation if we
apply Green’s theorem on a velocity field v(x, y) = (P(x, y), Q(x, y))T defined on a
small circle Cr with radius r in Ω, i.e.,
∮𝜕Cr
v ⋅et ds = ∮𝜕Cr
(Px′(s) + Qy′(s))ds = ∮𝜕Cr
Pdx + Qdy = ∫∫Cr
curl v dxdy
If the circle is so small that curl v is approximately constant in Cr, we get
∮𝜕Cr
v ⋅et ds ≈𝜋r2 curl v
The mean value of vt, the tangential component of v along 𝜕Cr, is (Figure A.4)
vtmean =
1
2𝜋r∮𝜕Cr
vt ds
Since vt = r𝜔, where 𝜔is the angular velocity, ̇𝜑, the mean value of the angular
velocity along 𝜕Cr is
𝜔mean ≈
1
2𝜋r∮𝜕Cr
vt
r ds =
1
2𝜋r2 ∮𝜕Cr
v ⋅et ds ≈1
2curl v

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
229
Cr
∂Cr
𝜑
et
v
v•et
ds
x
y
Figure A.4
Velocity vector at a point on the boundary projected to the tangential direction
Hence, curl v is interpreted as the vorticity strength of the velocity field v.
A.5
NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF
EQUATIONS
Numerical solution of systems of equations occurs frequently as part of the numerical
treatment of differential equations. The system can be linear
Au = b,
where
A
is n × n
or nonlinear
f(u) = 0,
where the jacobian
J(u) = 𝜕f
𝜕u
is n × n
For a nonlinear system, an iterative method must be used. If Newton’s method (see
Section A.1) is chosen, a linear system of equations has to be solved in each iteration.
The parameter n is the number of unknowns = the number of equations. When A
has no special structure, it is called a full matrix. For a full matrix, all n2 elements
must be stored.
However, when differential equations are solved numerically, sparse systems of
equations occur frequently. The system is sparse if A (or J) has a small number
nz ≪n2 of nonzero elements. Often in a sparse system, there are a few unknowns
in each equations, i.e., nz = (n). Hence, all elements of a sparse matrix must not be
stored but essentially only those which are nonzero.
For efficiency reasons, it is important to utilize the sparsity of the system, both
when it is comes to how the storage is organized and how the solution algorithm is
designed.
A.5.1
Direct Methods
A.5.1.1
Some Facts about Gaussian Elimination The standard method for
solving Au = b is Gaussian elimination with row pivoting. The algorithm gives both
the solution u and the LU factorization of A. If no pivoting is needed, we obtain

230
SOME NUMERICAL AND MATHEMATICAL TOOLS
A = LU, where L is lower triangular with ones in the main diagonal and U is upper
triangular. The computational work to compute the solution and the factorization
amounts to about n3∕3 flops.
If row pivoting is necessary, the LU factorization is valid for a row permuted A,
i.e., PA = LU, where P is a permutation matrix.
If A is symmetric and positive definite (SPD), A = AT and 𝜆i(A) > 0, i =
1, 2, … , n, the factorization can be written A = LLT, also called the Cholesky
factorization of A, and is achieved in n3∕6 flops.
A.5.1.2
Direct Methods for Sparse Linear Systems For sparse matrices, there are
modified versions of Gaussian elimination that give the solution more efficiently than
Gaussian elimination for a full matrix.
A.5.1.2.1
Methods for Band Structured Matrices. A common sparse structure is
the band structure with bandwidth p, e.g.,
A =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
a11
a12
0
0
0
0
a21
a22
a23
0
0
0
a31
a32
a33
a34
0
0
0
a42
a43
a44
a45
0
0
0
a53
a54
a55
a56
0
0
0
a64
a65
a66
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
,
p = 4
The number of bands is called the bandwidth of A. A bandmatrix with bandwidth p
can be stored as p columns in an n × p matrix B in the following way:
B =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
0
a11
a12
0
a21
a22
a23
a31
a32
a33
a34
a42
a43
a44
a45
a53
a54
a55
a56
a64
a65
a66
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
Hence, np elements are needed to store the elements of A instead of n2. The LU
factorization is computed in np2 flops and stored in the same matrix by overwriting
the elements of B
(L, U) =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
0
r11
r12
0
l21
r22
r23
l31
l32
r33
r34
l42
l43
r44
r45
l53
l54
r55
r56
l64
l65
r66
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
Since the elements in the main diagonal of L are ones, there is no need to store that
diagonal.

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
231
If the matrix A is symmetric, only the main diagonal and the diagonals below need
to be stored in B. The Cholesky factorization can be done on the same matrix space as
B and the result, the band-stored L-matrix, overwrites the original B-matrix. Observe
that the Cholesky factor L has a main diagonal with elements not equal to one. Hence,
this diagonal must also be stored. The number of flops needed is np2/2. Following is
an example:
B =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
0
a11
0
a21
a22
a31
a32
a33
a42
a43
a44
a53
a54
a55
a64
a65
a66
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
,
L =
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
0
l11
0
l21
l22
l31
l32
l33
l42
l43
l44
l53
l54
l55
l64
l65
l66
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
Band matrices occur, e.g., when the finite difference method (FDM) or finite element
method (FEM) is used to discretize a PDE problem defined on a rectangular region,
e.g., Poisson’s equation defined on a square (see Chapter 7).
A special but important type of band matrix is the tridiagonal n × n matrix A
A = tridiagn(a, d, c)
where a and c are vectors of dimension n −1 (the sub- and superdiagonals) and d a
vector of dimension n (the main diagonal). Tridiagonal matrices occur when FDM or
FEM is used to solve boundary value problem (BVP) (see Chapter 4).
Obviously much computational work can be saved if a sparse matrix A can be
transformed into a bandmatrix with small bandwidth. The transformations must be
done in an economic way in order not to waste flops on this part of the algorithm.
Examples of simple “cheap” transformations are permutations of rows and columns.
Let P and Q be permutation matrices. The effect of multiplying A from the left with
P is changing the order of the rows of A, and multiplying A from the right with Q will
change the order of the columns of A, e.g.,
PA =
⎛
⎜
⎜
⎜⎝
−
a2 −
−
a4 −
−
a1 −
−
a3 −
⎞
⎟
⎟
⎟⎠
,
AQ =
⎛
⎜
⎜⎝
|
|
|
|
a3
a1
a4
a2
|
|
|
|
⎞
⎟
⎟⎠
Do the following series of transformations of the system Au = b:
PAu = Pb,
u = Qv,
PAQv = Pb
The ordering of rows and columns in A, resulting in a matrix PAQ that has a
smaller bandwidth than A, can be done with different algorithms. Examples of such
algorithms are the minimum degree permutation or the reverse Cuthill MacKee
permutation (see the Bibliography for more information).

232
SOME NUMERICAL AND MATHEMATICAL TOOLS
A.5.1.2.2
Methods for Profile Structured Matrices. An alternative way of storage,
applicable for an SPD matrix A, is the profile storage of the main diagonal and the
lower part of A. The profile is the border for which all elements to the left of the border
are zero-elements. Profile structured matrices occur, e.g., when FEM is applied to an
elliptic PDE problem defined on an irregular region.
It can be shown that the profile of the Cholesky factorized L-matrix has the same
profile as the original matrix, i.e., the profile is invariant under Cholesky factorization
A =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
,
L =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
It is not efficient to store A as a full matrix. Instead, only the nonzeros of A are stored
in a vector a together with a pointer vector p the elements of which show the locations
of the diagonal elements of A. See the example below:
A =
⎛
⎜
⎜
⎜
⎜⎝
25
3
21
0
2
23
0
4
0
22
0
0
1
0
20
⎞
⎟
⎟
⎟
⎟⎠
a = (25, 3, 21, 2, 23, 4, 0, 22, 1, 0, 20)
p = (1, 3, 5, 8, 11)
A.5.1.2.3
Methods for General Sparse Matrices. A general way of storing a sparse
matrix A is to store only its nonzero elements in a vector together with two index
vectors containing the row and column indices of the nonzero elements.
A =
⎛
⎜
⎜
⎜
⎜⎝
a11
0
a13
0
a15
a21
0
0
a24
0
0
a32
0
0
a35
0
a42
0
a44
0
a51
0
0
a54
0
⎞
⎟
⎟
⎟
⎟⎠
is stored in the three vectors
a = (a11, a13, a15, a21, a24, a32, a35, a42, a44, a51, a54)
ia = (1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
ja = (1, 3, 5, 1, 4, 2, 5, 2, 4, 1, 4)

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
233
Observe that storing this matrix A as a band matrix is not efficient, since the full
matrix then must be stored.
The solution and factorization of a general sparse system Au = b is more compli-
cated, since the sparseness structure in A will not be preserved in L and U after the
Gaussian elimination process. Usually L and U will be much less sparse than A. For
more information, see the Bibliography.
A.5.2
Iterative Methods for Linear Systems of Equations
An alternative method for solving Au = b, where A is n × n matrix, is to use an
iterative method. For such a method to be more efficient than a direct method the
matrix A should fulfill the following requirements:
• it is “cheap” to form Ax (number of flops ≪n2)
• the iterative method is “fast” (number of iterations ≪n)
The first property originsfrom the structure of A, while the second property is alge-
braic; the convergence rate depends on the eigenvalues of A. The iterative methods
can be divided into stationary and search methods.
A.5.2.1
Stationary Iterative Methods The general idea with an iterative method
is based on splitting of the matrix A
A = M −N
(A.47)
The iteration method is then defined as
Muk+1 = Nuk + b
(A.48)
where u0 is a given start vector. The iterations are continued until ‖uk+1 −uk‖ is small
enough,where ‖.‖ is some norm, e.g., the maximumnorm or the Euclidean norm. The
method is called stationary if M and N are constant matrices. The iteration formula
can also be written
uk+1 = Guk + M−1b
(A.49)
where G = M−1N is the iteration matrix. As usual, however, inversion should not
be used in numerical methods for solving systems of equations. Let u∗be the exact
solution of Au = b. The error in uk is defined as
ek = u∗−uk
(A.50)
and satisfies the iteration formula
ek+1 = Gek
(A.51)

234
SOME NUMERICAL AND MATHEMATICAL TOOLS
The residual at uk is defined as
rk = b −Auk
(A.52)
and the relation between the error and the residual is
rk = Aek
(A.53)
The iteration method converges if ek →0 as k →∞. The condition for convergence
is
𝜌(G) < 1,
where
𝜌(G) = max
i
|𝜆i(G)|
(A.54)
Convergenceis fast if 𝜌(G) ≪1, slow if 𝜌(G) ≈1 −𝜖, where 0 < 𝜖≪1, and divergent
if 𝜌(G) > 1. 𝜌(G) is called the spectral radius of G.
If the convergence is fast, i.e., the number of iterations needed to achieve a given
accuracy is small, an iterative method is more efficient than a direct method. Observe
that in a method based on splitting, as above, the number of flops in each iteration is
essentially nz if the matrix-vector multiplication is performed in a sparse way and M
is a matrix that is cheap to “invert.”
The splitting can be done in different ways. Classical methods are
• Jacobi’s method, A = D −B, where D is the diagonal of A and B is the outer
diagonal part of A. Hence, the iteration scheme is
Duk+1 = Buk + b
(A.55)
• Gauss–Seidel’s method, A = D −L −U, where L is strictly lower triangular and
U is strictly upper triangular. The iterative scheme is
(D −L)uk+1 = Uuk + b
(A.56)
The classical methods above are usually not efficient on problems from ODEs and
PDEs. Extensions of these methods to SOR (successive overelaxation) and SSOR
(symmetric successive overelaxation SOR) have better convergence properties but
are not competitive with modern methods. However, as preconditioners (see later)
both Jacobi and SSOR are very useful. For further description of these methods, see
the Bibliography.
A.5.2.2
Search Methods for SPD Matrices In this part of the appendix, we
restrict the description to systems of equations Au = b, where A is an SPD matrix.
For such matrices, the solution of the linear system of equations is equivalent to the
minimization problem
min
u F(u)
(A.57)
where the object function F(u) is
F(u) = 1
2uTAu −uTb
(A.58)

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
235
In the context of numerical methods for minimization, it is appropriate to design
search methods to find the minimum point u∗. Such methods are defined by
uk+1 = uk + 𝛼kdk
(A.59)
where dk is the search direction and 𝛼is the step length taken in this direction. The
step length is usually chosen so that F(u) is minimized along the search direction dk.
This minimization is performed with respect to 𝛼≥0 and it is easy to show that the
optimal value of 𝛼is
𝛼k =
rT
k dk
dT
k Adk
(A.60)
What differs between methods is the choice of the search direction. Two
well-known methods are
• steepest descent (SD) method, where dk = rk, u0 = 0
• conjugate gradient (CG) method, where dk is updated according to
dk+1 = rk+1 + 𝛽kdk,
where
𝛽k =
rT
k+1rk+1
rT
k rk
,
u0 = 0,
d0 = r0
(A.61)
It can be shown that the residuals r0, r1, … , rk generated by CG are orthogonal
and that both the residuals and the search directions d0, d1, … , dk span the so-called
Krylov space
Kk+1 = [b, Ab, A2b, … , Akb]
(A.62)
What is most remarkable about the CG method is that, in the absence of rounding
errors, it gives the exact solution after less than or equal to n iterations. In a way,
therefore, CG could be classified as a direct method. However, often the convergence
is so fast that only few iterations are needed to achieve sufficient accuracy.
Both SD and CG are descent methods, i.e., F(uk+1) < F(uk) but CG converges
faster to u∗than SD.
It can be shown that the convergence rate for search methods depends on the con-
dition number 𝜅(A), defined as
𝜅(A) = maxi𝜆i(A)
mini𝜆i(A)
(A.63)
For a large condition number the convergenceis slow. The smallest condition number
that can be achieved for all matrices A is equal to 1, and in that case the exact solution
is obtained after 1 iteration. It can be shown that convergence to a specified accuracy
can be expected in (𝜅(A)) iterations for SD and in 
(√
𝜅(A)
)
iterations for CG.

236
SOME NUMERICAL AND MATHEMATICAL TOOLS
If the condition number is large, it can be reduced by preconditioning. Introduce
the nonsingular n × n matrix E and the variable substitution v = Eu. The function
F(u) in (A.58) is then changed to
̃F(v) = F(u) = F(E−1v) = 1
2vT ̃Av −vT ̃b
where
̃A = E−TAE−1,
̃b = E−Tb
(A.64)
How should E be chosen so that 𝜅(̃A) ≪𝜅(A)? In case E = I, ̃A = A and nothing
has been gained. If E = LT, where L is the Cholesky factor of A, ̃A = L−1AL−T =
L−1LLTL−T = I, and ̃A is perfectly conditioned. However, using Cholesky factoriza-
tion of A to get a preconditioner would be equivalent to using a direct method, which
we wanted to avoid. In between E = I and E = LT, however, there are many good
working preconditioners C, where C = ETE is called the preconditioning matrix.
A simple choice of the matrix C is C = diag(A), which is similar to Jacobi’s method
and eii = √aii.
Another often-used preconditioner is the incomplete Cholesky factorization, ̃L̃LT,
where ̃L is a modified Cholesky factor, allowed to have nonzeros only in positions
where A has nonzeros. Hence, E = ̃LT and C = ̃L̃LT.
To make the preconditioning methods efficient, it is not possible to form the
̃A-matrix in (A.64) explicitly before the search method is started. This would involve
inverting E and, as usual, the inverse should never be formed in numerical operations,
but, e.g., ̃b should be computed by solving ET ̃b = b.
Below it is shown how SD with preconditioning is designed efficiently. The SD
iterations for the vk sequence (A.64) is
vk+1 = vk + 𝛼k(̃b −̃Avk)
Express this iteration as a sequence in the uk values
Euk+1 = Euk + 𝛼k(̃b −̃AEuk)
Multiply by E−1
uk+1 = uk + 𝛼kE−1(E−Tb −E−TAE−1Euk)
which can be written
uk+1 = uk + 𝛼kC−1(b −Auk)
where C = ETE is the preconditioner.
In the discretization of PDEs on a fine grid, the systems of equations are huge.
However, if the same problem is solved on a course grid, we have a small system to
solve. The idea of switching between coarser and finer grids has developed to a class
of methods called multigrid methods, where the number of flops needed to solve the
system is (n).

SOME RESULTS FOR FOURIER TRANSFORMS
237
A.5.2.3
Search Methods for General Matrices When the matrix A is sparse but
unsymmetric and/or semidefinite, there is no suitable corresponding minimization
problem. If the system of equations is multiplied by AT, we obtain a SPD system
ATAu = ATb
This system, however, has an even worse condition number, since
𝜅(ATA) = 𝜅(A)2
and is therefore not always sufficiently effective. This method is known as the CGN,
CG to normal equations.
An alternative widely used method is GMRES, the generalized minimum resid-
ual method. Like CG it generates a sequence of search directions dk but requires all
previous search vectors d1, d2, … , dk to form dk+1 in contrast to CG, where dk+1 is
formed from dk−1 and dk only.
For more information about these methods, see the Bibliography.
A.6
SOME RESULTS FOR FOURIER TRANSFORMS
Fourier analysis is the common term for Fourier transforms and Fourier series, named
after the French mathematician Joseph Fourier, active in the beginning of the 19th
century.
Assume that u(x) is defined on the entire real axis. The continuous Fourier trans-
form ̂u(𝜔) of u(x) is defined as the integral
̂u(𝜔) =
1
√
2𝜋∫
+∞
−∞
u(x)e−i𝜔xdx
The inverse transform is
u(x) =
1
√
2𝜋∫
+∞
−∞
̂u(𝜔)ei𝜔xd𝜔
Here 𝜔= 2𝜋f, where 𝜔is the angular frequency and f the frequency. The second
formula can be interpreted as a superposition of waves ei𝜔x with the corresponding
amplitudes ̂u(𝜔).
If the function u(x) is known only at discrete equally spaced points xj = jh, j = … ,
−2, −1, 0, 1, 2, … the discrete Fourier transform is defined as
̂u(𝜔) =
1
√
2𝜋
j=+∞
∑
j=−∞
u(xj)e−i𝜔xjh

238
SOME NUMERICAL AND MATHEMATICAL TOOLS
with the inverse
u(xj) =
1
√
2𝜋∫
+𝜋∕h
−𝜋∕h
̂u(𝜔)ei𝜔xjd𝜔
The transforms exist if the original function u(x) is square integrable, i.e., for the
continuous and discrete case, respectively,
∫
+∞
−∞
|u(x)|2dx < ∞
+∞
∑
−∞
|u(xj)|2 < ∞
The following relations between the original function and its transform are called
Parseval’s equalities:
∫
+∞
−∞
|u(x)|2dx = ∫
+∞
−∞
|̂u(𝜔)|2d𝜔
+∞
∑
−∞
|u(xj)|2h = ∫
+𝜋∕h
−𝜋∕h
|̂u(𝜔)|2d𝜔
When the Fourier transform is applied to the heat equation
ut = 𝜅uxx,
u(x, 0) = u0(x),
−∞< x < +∞
we obtain the following ODE for the continuous Fourier transform ̂u(𝜔, t) of the
solution u(x, t):
d̂u
dt = −𝜅𝜔2̂u,
̂u(𝜔, 0) = ̂u0(𝜔)
with the solution
̂u(𝜔, t) = e−𝜅𝜔2t ̂u0(𝜔)
Applying the inverse transform
u(x, t) =
1
√
2𝜋∫
+∞
−∞
e−𝜅𝜔2t ̂u0(𝜔)ei𝜔td𝜔
we see that higher frequencies are quickly damped out as time increases.
When the FTCS method is applied to the heat equation, a sequence of values uj,k
values are obtained, where uj,k ≈u(xj, tk). Applying the inverse transform gives
uj,k =
1
√
2𝜋∫
𝜋∕h
−𝜋∕h
̂u(𝜔, tk)ei𝜔xjd𝜔

BIBLIOGRAPHY
239
This can be interpreted as a superposition of waves ei𝜔xj with amplitude ̂u(𝜔, tk).
Hence, the following ansatz for the discretized solution is motivated:
uj,k = qkei𝜔xj
Inserting this ansatz into the FTCS method gives
qk+1ei𝜔xj = qkei𝜔xj + qk
ht
h2x
(ei𝜔(xj+hx) −2ei𝜔xj + ei𝜔(xj−hx))
qk+1 = qk
(
1 −2ht
h2
x
(1 + cos(𝜔hx))
)
The second factor in this relation can be seen as an amplification factor. The qk
sequence is bounded this factor fulfills the inequality
−1 ≤1 −2ht
h2
x
(1 + cos(𝜔hx)) ≤1
Since −1 ≤cos(𝜔hx) ≤1 this inequality leads to the stability condition
ht
h2
x
≤1
2
This stability analysis is called von Neumann analysis and gives the same result for
the heat equation as the eigenvalue analysis in Chapter 6. This is not true, however,
for hyperbolic PDEs.
BIBLIOGRAPHY
1. L. Trefethen, D. Bau, “Numerical Linear Algebra,” SIAM, 1997
2. G. Dahlquist, Å. Björck, “Numerical Methods,” Chapter 5, Dover, 2003


APPENDIX B
SOFTWARE FOR SCIENTIFIC
COMPUTING
During the last decades, a lot of software has been developed for modeling and sim-
ulation of processes in science and engineering. The software can roughly be divided
into the following three categories:
1. General programming languages suitable for construction of programs with
optimal performance behavior on various computer architectures, e.g., vector
or parallel architecture. Examples are Fortran90, C, and C++. Many numerical
subroutine libraries written in these languages can be found as public domain
code on the net, e.g., Netlib. There are also several textbooks containing sub-
routines written in Fortran, Pascal, C, C++, Python, etc.
2. Programming languages specially designed for general numerical calculations
and symbolic mathematics. Examples of such tools are MATLAB®, Simulink,
Maple, and Mathematica. Within this category can also be placed COMSOL
MULTIPHYSICS®, which is a gui-based (graphicaluser interface) environment
for simulation of processes modeled by partial differential equations (PDEs)
from very many scientific and engineering applications.
3. Toolboxes for various applications often implemented for one specific area, e.g.,
fluid dynamics and designed in a way of communicating indata and outdata that
is familiar for the user in the specific application area.
As was mentioned in the Preface, this textbook is based on a course where the labs
and exercises are solved with MATLAB and COMSOL MULTIPHYSICS. Therefore,
these software products will be given special attention.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

242
SOFTWARE FOR SCIENTIFIC COMPUTING
B.1
MATLAB
MATLAB is a programming language designed for scientific and engineering
computation. The original MATrix LABoratory was developed by Prof. Cleve Moler
some 30 years ago for interactive computer labs in linear algebra. In the middle of the
1980s, MATLAB became a commercial product manufactured by the US company
MathWorks, founded by Cleve Moler and since then a continued success story,
now having more than 1000 employees. Products from the MATLAB and Simulink
family are spread all over the world, widely used by universities, industries, and
high-tech companies.
One of the strengths of MATLAB is the fact that there is a large subroutine library
with all kinds of high-quality numerical functions that can be used in your own pro-
grams. Another strength is the easy-to-use graphical routines for visualization and
animation in 2D and 3D.
What further makes MATLAB a suitable programming language for scientific
computing is the built-in vector/matrix facilities which make it easy to write com-
pact and efficient programs without for-loops. Indeed, MATLAB is very convenient
for making numerical experiments involving, e.g.,
• variation of stepsize/grids or tolerance parameters
• change of methods having different order of accuracy
• questions regarding numerical stability
• different algorithms, e.g., direct or iterative methods for solving linear systems
of equations
• robustness of a method
MATLAB is good for solving moderately sized problems. For large problems
requiring fast number crunching, it is more efficient to use a traditional programming
language such as Fortran90 or C.
We will not give a detailed description of MATLAB in this book, but we show here
some MATLAB codes, which can be used as example programs in the construction
of similar programs. For a detailed description of MATLAB we refer the reader to
some textbooks and manuals accessible on the Internet (see the Bibliography).
The templates presented here show solutions of some model problems taken from
the chapters of this book.
B.1.1
Chapter 3: IVPs
In the MATLAB library, there are several functions solving initial value problems
(IVPs). To mention a few, there are ode23, ode45, and ode113 for nonstiff prob-
lems and ode23s and ode15s for stiff problems.
B.1.1.1
Runge–Kuttas Fourth-Order Method, Constant Stepsize
The following
program solves Van der Pol’s equation:

MATLAB
243
%Program rkstep.m for Runge-Kutta’s 4th order method
%Model problem is Van der Pol’s equation, stored
%in fvdp.m
global epsilon
%parameter used in both script
%and fvdp
epsilon=1;
%parameter in VdPs equation
t0=0;tend=10;
%time interval for the solution
u0=[1 0]’;
%initial value
N=100;
%number of steps
h=(tend-t0)/N;
%stepsize
result=[u0’];
%collecting solution values
time=[t0];
%collecting time points
u=u0;t=t0;
%initialization of RK’s method
for k=1:N
k1=fvdp(t,u);
k2=fvdp(t+h/2,u+h*k1/2);
k3=fvdp(t+h/2,u+h*k2/2);
k4=fvdp(t+h,u+h*k3);
u=u+h*(k1+2*k2+2*k3+k4)/6;
t=t+h;
result=[result;u’];
time=[time;t];
end
plot(time,result(:,1),’o’,time,result(:,2),’+’)
title(’Van der Pols equation’)
xlabel(’time t’)
ylabel(’u (o) and du/dt (+)’)
grid
The function file fvdp.m containing the right hand side of Van der Pol’s equation:
%right hand side of Van der Pol’s equation
function rhs=fvdp(t,u)
global epsilon
%parameter in VdPs equation
rhs=[u(2);
-epsilon*(u(1)*u(1)-1)*u(2)-u(1)];
B.1.1.2
MATLAB’s ODE Function ode45 The same problem solved with one of
MATLAB’s ordinary differential equation (ODE) functions using adaptive stepsize
control:
%Program showing the use of Matlabs ode45 function
%Model problem is Van der Pol’s equation, stored in
%fvdp.m
global epsilon
epsilon=1;
%parameter in VdPs equation
t0=0;tend=10;
\%time interval for the solution
u0=[1 0]’;
\%initial value
[time,result]=ode45(@fvdp,[t0,tend],u0);
plot(time,result(:,1),’o’,time,result(:,2),’+’)
title(’Van der Pols equation’)
xlabel(’time t’)
ylabel(’u (o) and du/dt (+)’)
grid

244
SOFTWARE FOR SCIENTIFIC COMPUTING
B.1.1.3
Change of Tolerance Parameters When the default tolerance in a
MATLAB ODE function is not enough, the relative and absolute tolerance can be
changed from the preset values 10−3 and 10−6, respectively,
%Example 1.2 in chapter 1. The vibration equation
%demo of tolerance parameter settings
global m c k f0 w
m=1;c=10;k=1e3;f0=1e-4;w=40;
t0=0;tend=5;
u0=[0 0]’;
[time,result]=ode45(@fvib,[t0,tend],u0);
%not enough accuracy
options=odeset(’RelTol’,1e-6,’AbsTol’,1e-9);
%set tolerances
[t,res]=ode45(@fvib,[t0,tend],u0,options);
%accurate solution
plot(time,result(:,1),’.’,t,res(:,1))
title(’Accurate and bad solution of the vibration
equuation’)
xlabel(’time t’)
ylabel(’vibration y(t)’)
The corresponding right hand side function:
%Right hand side of vibration equation in chapter 1
function rhs=fvib(t,u)
global m c k f0 w
rhs=[u(2);
-(c/m)*u(2)-(k/m)*u(1)+(f0/m)*sin(w*t)];
B.1.2
Chapter 4: BVPs
Solution of the model problem in Example 4.8:
%Solution of the model problem BVP with FDM,
%constant stepsize h
%-u"=f(x), u(0)=u(1)=0, f(x)=sin(pi*x)
a=0;b=1;
%interval bounds
N=63;
%N+1=number of steps
h=(b-a)/(N+1);
%stepsize
xp=a:h:b;
%DG, discretize interval to grid
x=a+h:h:b-h;
%inner points generated
f=h*h*[sin(pi*x)]’;
%right hand side generated
A=zeros(N,N);
%start generation of the full
%matrix A
for i=1:N-1
A(i,i)=2;
A(i,i+1)=-1;
A(i+1,i)=-1;
end
A(N,N)=2;
%full matrix A generated
u=A\f;
%solution of linear system of
%equations

MATLAB
245
up=[0,u’,0];
%add the BCs to the solution
%vector
plot(xp,up)
title(’Solution of -u"=sin(\pi *x), u(0)=u(1)=0’)
xlabel(’x’)
ylabel(’u’)
grid
Example of a sparse version of the A matrix generation:
e=ones(N,1);
a=spdiags([-e 2*e -e],-1:1,N,N);
%sparse storage of A
u=a\f;
%sparse solution of Au=f
B.1.3
Chapter 6: Parabolic PDEs
Solution of the parabolic model problem with the MoL:
%Solution of u_t=u_xx, u(x,0)=sin(pi*x),
%u(0,t)=u(1,t)=0
%using the MoL. Discretized system stored in fpar.m
global N hx
%discretization parameters
N=10
%number of inner x-points
hx=1/(N+1);
%stepsize in x-direction
x=hx:hx:1-hx;
%inner points
u0=[sin(pi*x)]’; %initial values
t0=0;tend=0.25;
%time interval
[time,result]=ode23s(@fpar,[t0,tend],u0);
%stiff ode-solver
resultp=[zeros(size(time)) result zeros(size(time))]
%add BCs
xp=0:hx:1;
%add boundary points
mesh(xp,time,resultp)
title(’Solution of u_t=u_xx, u(x,0)=sin(\pi *x), ...
u(0,t)=u(1,t)=0 using MoL’)
xlabel(’space variable x’)
ylabel(’time variable t’)
zlabel(’solution variable u(x,t)’)
The MoL discretized PDE is stored in the MATLAB function file fpar.m:
%Right hand side of the MoL discretized model
%problem
function rhs=fpar(t,u);
global N hx
%discretization parameters
rhs=zeros(N,1);
rhs(1)=(-2*u(1)+u(2))/(hx*hx);
rhs(2:N-1)=(u(1:N-2)-2*u(2:N-1)+u(3:N))/(hx*hx);
rhs(N)=(u(N-1)-2*u(N))/(hx*hx);

246
SOFTWARE FOR SCIENTIFIC COMPUTING
B.1.4
Chapter 7: Elliptic PDEs
Solution of the elliptic model problem with the finite difference method (FDM):
%Numerical solution of the elliptic PDE Laplace u=1
%on the quadrangle Omega={(x,y),0<=x<=1,0<=y<=1}
%BC is u=0 on the boundary of Omega
N=100;
%number of inner x and
%y-points
hx=1/(N+1); hy=1/(N+1); %stepsize in x- and
%y-direction
x=0:hx:1; y=0:hy:1;
%gridpoints
d=4*ones(N*N,1);
%main diagonal of A
d_1=-ones(N*N,1);
d1=-ones(N*N,1);
for i=N:N:N*N-1
%sub- and superdiagonals
d_1(i)=0;
d1(i+1)=0;
end
d_2=-ones(N*N,1);
%subdiagonal from unit matrix
d2=-ones(N*N,1);
%superdiagonal
a=spdiags([d_2 d_1 d d1 d2],[-N,-1:1,N],N*N,N*N);
%sparse matrix A generated
f=ones(N*N,1);
%right hand side
uinner=a\f;
%solution at inner points
Uinner=zeros(N,N);
for i=1:N
%inner solution as a matrix
Uinner(i,1:N)=uinner((i-1)*N+[1:N]);
end
U=zeros(N+2,N+2);
%add BCs to inner solution
for i=1:N
U(i+1,2:N+1)=Uinner(i,1:N);
end
mesh(x,y,U)
%3D plot of the solution
title(’Solution of \Laplace u = 1 on the unit
square’) ...
xlabel(’x’)
ylabel(’y’)
zlabel(’u(x,y)’)
B.1.5
Chapter 8: Hyperbolic PDEs
Solution of the hyperbolic PDE model problem:
%Solution of the hyperbolic model problem
%u_t+u_x=0, u(x,0)=0, 0<x<=1, u(0,t)=1, t>=0
%Upwind method is used
clear,clf,hold off
%clear variables and graph
N=100;
%number of gridpoints
hx=1/N;
%stepsize in x-direction
x=hx:hx:1;
%x-grid, inner points
xp=[0 x];
%x-grid plus boundary point
ht=0.01;
%timestep, try also 0.008 and 0.011

COMSOL MULTIPHYSICS
247
sigma=ht/hx;
%Courant number
u0=zeros(N,1);
%IV at inner points
up=[1;u0];
%IV+BV
plot(xp,up)
title(’Initial state for the advection equation’)
xlabel(’x’)
ylabel(’u(x,t)’)
u(1:N,1)=u0;
%initialization of upwind
for k=1:100
%take 100 timesteps with upwind
u(1,k+1)=(1-sigma)*u(1,k)+sigma*1;%*1 is *BC
u(2:N,k+1)=(1-sigma)*u(2:N,k)+sigma*u(1:N-1,k);
up=[1;u(:,k+1)];
plot(xp,up) %plot the front for each timestep
hold on
%keep the previous plots
pause(0.1)
end
B.2
COMSOL MULTIPHYSICS
While MATLAB is good for numerical computation of moderately sized problems,
COMSOL MULTIPHYSICS is designed for model experimentation of problems
from various applications. Its development started some twenty years ago by a
Swedish provider company called COMSOL®. COMSOL was founded by Dr. H.C.
Svante Littmarck and Farhad Saeidi and is another example of a success story within
scientific computing. COMSOL has now around 420 employees and branch offices
in several countries, including the United States.
COMSOL MULTIPHYSICS is an interactive program for simulation of
time-dependent or stationary scientific/engineering PDE models in 1D, 2D, or 3D.
The user and the program communicates with the help of a graphical user interface
(gui), which provides advanced tools for geometric modeling. The models are based
on three forms of PDEs, the coefficient form (for linear or quasi-linear PDEs), the
general form (for nonlinear PDEs)
e𝜕2u
𝜕t2 + d 𝜕u
𝜕t + ∇⋅(−c∇u −𝛼u + 𝛾) + 𝛽⋅∇u + au = f
and
d 𝜕u
𝜕t + ∇⋅Γ = F
and the weak form (see section 7.4.2). Simulations can be done in one single appli-
cation, e.g., heat transfer, and also in coupled models where several applications are
mixed in an almost arbitrary way, e.g., heat conduction and electrical current strength.
There are several physics interfaces that can be studied alone or in combination with
others, e.g.,
• equation-base modeling
• chemical engineering

248
SOFTWARE FOR SCIENTIFIC COMPUTING
Max: 500
Min: 299.681
300
320
340
360
380
400
420
440
460
480
500
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1.2
−0.8
−0.4
Time = 1 Surface: u
0
0.4
0.8
Figure B.1
Solution of heat conduction problem with COMSOL Multiphysics
• electromagnetics
• heat transfer
• structural mechanics
• acoustics
The solution process of a problem proceeds in short in the following way:
1. choose application mode and space dimensionality 1D, 2D, or 3D
2. generate the geometry
3. enter global parameter values and initial values
4. give the parameters of the PDE
5. give the boundary conditions
6. generate the grid
7. compute and solve
8. inspect the solution with the postprocessing facilities
After having completed the steps (1) – (8), you can go back to any step earlier to
modify the model see Figure B.1 for a heat conduction simulation.
The underlying numerical method is based on the finite element method. For
time-dependent problems, finite element method (FEM) is combined with a stiff
ODE solver. The discretization is done with a grid generator that automatically
produces a grid whose appearance depends on the geometry of the problem. By
option, the grid can also be generated adaptively depending on the solution.
For more examples, see Ref. 1 and the webpage of this textbook http://www.csc.
kth.se/∼edsberg.

BIBLIOGRAPHY AND RESOURCES
249
BIBLIOGRAPHY AND RESOURCES
1. COMSOL MULTIPHYSICS®, http://www.comsol.com
2. Introduction to Matlab, http//www.maths.dundee.ac.uk/ ftp/na-reports/MatlabNotes.pdf
3. Matlab, http://www.mathworks.com
4. D. J. Higham and N. J. Higham, Matlab Guide, 2000, SIAM
5. Netlib, http://www.netlib.org/
6. Numerical Recipes, W. Press, B. Flannery, S. Teukolsky, W. Vetterling, Cambridge
University Press, 1986


APPENDIX C
COMPUTER EXERCISES TO SUPPORT
THE CHAPTERS
C.1
COMPUTER LAB 1 SUPPORTING CHAPTER 2
C.1.1
ODE Systems of LCC Type and Stability
In this exercise, the following problems are treated:
• linear ordinary differential equation (ODE) systems with constant coefficients
(LCC systems)
• stability of trajectories and critical points
LCC systems can be solved analytically (see Chapter 2). Hence, no numerical method
is needed, so the problem class is suitable for a refresher in MATLAB programming.
We start by illustrating a MATLAB program for solution of an LCC problem.
Given the following second-order differential equation:
d2y
dt2 + 2dy
dt + 5y = 0,
y(0) = 0, dy
dt (0) = 1
compute the solution of this ODE problem on a suitable t interval. First rewrite this
scalar problem to the standard form, i.e., as a system of first-order ODEs. This ODE
system is of LCC type
du
dt = Au,
u(0) = u0
which is solved analytically with the expm-function. Input data to the MATLAB
program consists of the matrix A, the initial vector u(0), and grid point data h and
N for the points ti = ih, i = 0, 1, 2, … , N, where the solution shall be computed
and plotted. The output from the program is the graph of the solution at these grid
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

252
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
points.In the MATLAB programbelow,the solutionu(t) is stored in a resulting matrix
result of size (N + 1) × 2. Each row in result corresponds to the solution vector
at a grid point ti. The first row is the initial vector u(0)
A=[0 1;-5 -2];
u0=[0 1]’;t0=0;
h=0.1;N=60;
result=[u0’];time=[t0];
for k=1:N
t=k*h;
u=expm(A*t)*u0;
result=[result; u’];
time=[time; t];
end
plot(time,result)
This MATLAB program plots two curves. The first column in the result-matrix
corresponds to the solution y(t), while the second column corresponds to the deriva-
tive of the solution z(t) = dy
dt (t). The initial values of y and z are different in this case
so it is easy to see which curve corresponds to which variable. Otherwise you can use
different plot symbols for different curves.
Observe that the time step h must be chosen with some care if the plotted curve
is to be smooth. When h = 0.1 is used as stepsize, the resulting curve is smooth, but
with h = 1, however, the line segments building up the curves are clearly seen and
the curve gets rough.
With too small time steps, on the other hand, say h = 0.001, the computation of the
result-matrix will take an unreasonably long time. Hence, it is advisable to work
out the grid point spacing interactively. For other problems, it may also be better to
use loglog, semilogx, or semilogy instead of plot to display the important
qualitative features of solution curves.
C.1.1.1
Solution of ODE Systems with Constant Coefficients
C.1.1.1.1
Electric Circuit. Given the following simple electric circuit with a volt-
age source of size E, a resistance R, an inductance L, and a capacitance C. The
components are coupled in series (see Figure C.1). Assume that the circuit is first
at rest. The switch is activated at t = 0 and a current i starts to go through the circuit.
Introduce the variable q defined by the relation ̇q = i, and the following differential
equation can be set up:
L̈q + R ̇q + 1
Cq = E,
q(0) = 0,
̇q(0) = 0
Rewrite this scalar ODE as a system of first-order ODEs and then write a MATLAB
programto solve the problem for the following parameter values: E = 10, L = C = 0.1,
R = 0.01, 0.1, 1, 10. Observe that this ODE system is inhomogeneous.

COMPUTER LAB 1 SUPPORTING CHAPTER 2
253
R
L
C
E
Figure C.1
Simple electric circuit
Plot the solutions i(t) on suitable time intervals and with suitable time steps. Use
the subplot-command to obtain the four graphs in the same figure.
C.1.1.2
Stability of ODE Systems and Equilibrium Points
C.1.1.2.1
Stability of the Solutions of an ODE System of LCC Type. In many tech-
nical applications where a differential equation is used to model a dynamic process,
it is important to see how the solution curves change as a parameter in the model is
changed. For a control system, it is of great interest to investigate how the stability
properties change as a parameter is changed continuously.
Given the following third-order differential equation:
d3y
dt3 + 3d2y
dt2 + 2dy
dt + Ky = 0,
y(0) = 1, dy
dt (0) = 1, d2y
dt2 (0) = 1
Investigate how the solution y(t) behaves for values K ≥0.
Rewrite this third-order ODE as a system of first-order ODEs. We then obtain a
system
du
dt = A(K)u,
u(0) = (1, 1, 1)T
Write a MATLAB program showing the solutions y(t) for K = 0, 1, 4, 8. Use sub-
plot to plot the four graphs in the same figure. Estimate from these plots an approx-
imate value of K for which the solution becomes unstable.
The stability properties can also be shown in a so-called root locus, often used in
control theory to visualize the stability properties for a regulator modeled by an ODE
of LCC type. A root locus is a graph showing the paths of the eigenvalues in the com-
plex plane as a parameter varies. Assume that all eigenvaluesstart in the left half plane
for say K = 0, where we have a stable system. When K then increases, the eigenvalues
will follow continuous paths and for a certain value of K a few eigenvalues eventually
enter the right half plane and the system becomes unstable.
Write a MATLAB program that plots the root locus when 0 ≤K ≤10. Compute
with two decimal accuracy the smallest value of K that gives an unstable system.

254
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
C.1.1.2.2
Stability of the Critical Points of a Nonlinear ODE System. Given the
following system of nonlinear ordinary differential equations:
du1
dt = 5u1 + 4u2 −u1 u3
du2
dt = u1 + 4u2 −u2 u3
du3
dt = u2
1 + u2
2 −89
Write a MATLAB program where all critical points of the ODE system are computed.
Also compute which of these critical points are stable.
Hint: use Newton’s method to compute the critical points with at least five signif-
icant digits. There are four critical points and they are situated in the neighborhood
of the following points in R3: (8, −5, 2), ( −8, 5, 2), (9, 3, 7), and ( −9, −3, 7).
C.2
COMPUTER LAB 2 SUPPORTING CHAPTER 3
C.2.1
Numerical Solution of Initial Value Problems
In this lab, initial value problems (IVPs) are solved numerically and the following
items are studied:
• accuracy and stability
• constant stepsize and adaptive (variable) stepsize
• stiff and nonstiff problems
• parameter study of the solutions of a system of ODEs
C.2.1.1
Accuracy of a Runge–Kutta Method In Chapter 3, different Runge–Kutta
methods are presented. Make a numerical experiment to find the order of accuracy of
the following RK method:
uk = uk−1 + h
6(K1 + K2 + 4K3),
tk = tk−1 + h,
k = 1, 2, … , N
K1 = f(tk−1, uk−1)
K2 = f(tk−1 + h, uk−1 + hK1)
K3 = f(tk−1 + h∕2, uk−1 + hK1∕4 + hK2∕4)
Implement the method on Van der Pol’s differential equation
d2y
dt2 + (y2 −1)dy
dt + y = 0,
y(0) = 1, dy
dt (0) = 0,
𝜖= 1,
t ∈[0, 1]
Run the problem with constant stepsizes using N = 10, 20, 40, 80, 160, and
320 steps in the t interval [0, 1]. Estimate the error at t = 1 by computation of

COMPUTER LAB 2 SUPPORTING CHAPTER 3
255
eN = yN −y(1),N = 10, 20, 40, 80, 160. Since y(1) is not known exactly, use the
approximation y(1) ≈yNmax, where Nmax = 320. Make a loglog-plot of |eN| as a
function of h and estimate the order of accuracy from the graph.
Hint 1: Treat the problem as a system on vector form, both when you rewrite the
second-order differential equation to a system of two first-order ODEs and when you
program the method.
Hint 2: Be careful to take the correct number of steps to reach t = 1. If you get the
answer order = 1, there is some mistake in your MATLAB code!
C.2.1.2
Stability Investigation of a Runge–Kutta Method The stability of a
numerical method for IVPs is important when we want to solve stiff problems. The
following ODE system modeling the kinetics of a set of three reactions, known as
Robertson’s problem, is studied here:
A →B
(k1)
B + C →A + C
(k2)
2B →B + C
(k3)
In the reactions above k1, k2, and k3 denote the rate constants of the three reactions.
The following set of ODEs describe the evolution of (scaled) concentrations of A, B,
and C as a function of time t:
dx1
dt = −k1 x1 + k2 x2 x3,
x1(0) = 1
dx2
dt = k1 x1 −k2 x2 x3 −k3 x2
2,
x2(0) = 0
dx3
dt = k3 x2
2,
x3(0) = 0
The rate constants have the values: k1 = 0.04, k2 = 104, k3 = 3 ⋅107.
C.2.1.2.1
Constant Stepsize Experiment. If Robertson’s problem is solved with
an explicit method, the stepsize has to be very small to avoid numerical instability.
Use the Runge–Kutta method given on Robertson’s problem when the t interval is
[0, 1]. Run the problem with constant stepsizes corresponding to N = 125, 250, 500,
1000, 2000 steps and find the smallest number of steps (from the 5 given) needed
to obtain a stable solution. Plot the solution trajectory in a loglog-diagram for the
solution computed with the smallest step.
C.2.1.2.2
AdaptiveStepsize Experiment Using MATLAB Functions. There are sev-
eral IVP solvers in MATLAB. Use the command »help funfun to see which are
available. To get more information about one of them, say ode23, give the command
»help ode23. In order to control, e.g., accuracy parameters you also need to read
about the function odeset. When the problem is stiff, you need a stiff IVP solver,
e.g., ode23s.
There are several ways to find demo examples in Matlab. If you give the command
»demo and follow the path MATLAB, Numerics, Differential Equations, you find a

256
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
number of examples to look at, e.g., vdpode and rigidode. You can run the demo
programs and see the graphical output and you can also see the MATLAB code.
Make the following numerical experiments on Robertson’s problem:
• Use the nonstiff IVP solver ode23 on the t interval [0, 1] for different relative
tolerances: RelTol = 10−3, 10−4, 10−5, 10−6 and record the number of steps
taken by ode23. Make a graph of the stepsize h as function of t for one of the
tolerances.
• Run the stiff IVP solver ode23s on the t interval [0, 1000] for the same relative
tolerances as above and record the number of steps taken by ode23s. Make a
graph of the stepsize h as function of t for one of the tolerances.
C.2.1.3
Parameter Study of Solutions of an ODE System Make a parameterstudy
for the following problems taken from applications. Choose a method (order of accu-
racy must be at least two) yourself. Present the result graphically in a suitable way.
Think about the following possibilities and choose what you think is best:
• one or several graphs (using subplot) in the figure window?
• linear or logarithmic scales?
• in the graphs: title, x-label, y-label
C.2.1.3.1
Problem 1: Particle Flow Past a Cylinder. A long cylinder with radius
R = 2 is placed in an incompressible fluid streaming in the direction of the positive
x-axis. The axis of the cylinder is perpendicular to the direction of the flow. The
position (x(t), y(t)) of a flow particle at time t is determined by the start position (x(0),
y(0)) and the ODE system:
dx
dt = 1 −R2(x2 −y2)
(x2 + y2)2 ,
dy
dt = −
2xyR2
(x2 + y2)2
At t = 0, there are four flow particles at x = −4 with the y-positions 0.2, 0.6, 1.0, and
1.6. Compute and make a graph of the flow curves of the particles in the t interval
[0, 10]. Use axis equal in the graph!
C.2.1.3.2
Problem 2: Motion of a Particle. A particle is thrown from the position
(0, 1.5) with an elevation angle 𝛼and the velocity v0 = 20. The trajectory of the
particle depends on 𝛼, the air resistance coefficient k, and the ODE system
d2x
dt2 = −kdx
dt
√
(dx
dt
)2
+
(dy
dt
)2
,
x(0) = 0,
dx
dt (0) = 20 cos(𝛼)
d2y
dt2 = −9.81 −k
||||
dy
dt
||||
√
(dx
dt
)2
+
(dy
dt
)2
,
y(0) = 1.5,
dy
dt (0) = 20 sin(𝛼)

COMPUTER LAB 3 SUPPORTING CHAPTER 4
257
For two different values of k, say k = 0.020 and 0.065, the solution trajectories for
𝛼= 30∘, 45∘, and 60∘. For the graphical presentation, observe that the model is valid
only until the particle touches the ground, i.e., it is valid only while y ≥0. The graph
should show the motion in a xy-coordinate system with t as a parameter.
C.3
COMPUTER LAB 3 SUPPORTING CHAPTER 4
C.3.1
Numerical Solution of a Boundary Value Problem
Consider a long pipe of length L with small cylindrical cross section (Figure C.2). In
the pipe, there is a fluid heated by an electric coil. The heat is spreading along the pipe
and the temperature T(z) at steady state is determined by the diffusion–convection
ODE
−d
dz
(
𝜅dT
dz
)
+ v𝜌CdT
dz = Q(z)
(∗)
where all parameters are constant: 𝜅is the heat conduction coefficient, v the fluid
velocity in the z direction through the pipe, 𝜌the fluid density, and C the heat capacity
of the fluid. The driving function Q(z), modeling the electric coil, is defined as
Q(z) =
⎧
⎪
⎨
⎪⎩
0
if 0 ≤z ≤a
Q0 ⋅sin
(
z−a
z−b𝜋
)
if a ≤z ≤b
0
if b ≤z ≤L
(C.1)
At z = 0, the fluid has the inlet temperature T0
T(0) = T0
At z = L, heat is leaking out to the exterior, having temperature Tout. This assumption
gives the following boundary condition (BC):
−𝜅dT
dz (L) = k(T(L) −Tout)
where k is a constant heat convection coefficient.
Discretize this boundary value problem (BVP) with the finite difference (FD)
method using constant stepsize and write a Matlab program that solves the problem.
Use the following values of the parameters in the problem: L = 10, a = 1, b = 3,
Q0 = 50, 𝜅= 0.5, k = 10, 𝜌= 1, C = 1, Tout = 300, T0 = 400, and v = 0, 0.1, 0.5, 1,
10. The case v = 0 corresponds to no convection, only diffusion.
0
a
b
L
z
υ
T (z)
Figure C.2
Pipe with fluid heated by an electric coil

258
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
Discretize the z interval [0, L] with constant stepsize and use a node-numbering
where z0 = 0 and zN = L.
Discretize the ODE and the BCs. A sparse system of linear equations is obtained.
Plot of the solution T(z) for v = 0, N = 10, 20, 40, 80 in the same graph. Note the
convergence of the curves in the graph.
N = 40 gives a solution that is accurate enough for our purposes. Use this dis-
cretization to solve the problem for v = 0.1, 0.5, 1, 10 in the same graph. When v = 10,
spurious oscillations occur! Make another plot when v = 10, showing the solution for
N = 10, 20, 40 in the same graph. The oscillations become more pronounced when
h is increasing. We have a spurious oscillation problem! How do we get rid of these
oscillations?
C.4
COMPUTER LAB 4 SUPPORTING CHAPTER 6
C.4.1
Partial Differential Equation of Parabolic Type
A metallic rod of length L (m) is initially of temperature T = 0 (C). At time t = 0,
a heat pulse of temperature T = T0 and duration tP (s) hits the left end (at x = 0) of
the rod. At the right end (at x = L), the rod is isolated. After some time, the rod will
therefore be warmer in the right end and then cool off again. The following partial
differential equation can be set up for the heat diffusion process through the rod:
𝜌Cp
𝜕T
𝜕t = k𝜕2T
𝜕x2 ,
t > 0,
0 < X < L,
The BCs are
T(0, t) =
{
T0 if 0 ≤t ≤tP
0
if t > tP
,
𝜕T
𝜕x (L, t) = 0
(C.2)
and the initial condition (IC) is
T(x, 0) =
{
T0
if
x = 0
0
if
0 < x ≤L
(C.3)
In the partial differentialequation (PDE), 𝜌is the density [kg/m3], CP the heat capacity
[J/(kg⋅C)], and k the thermal conductivity [J/(m⋅s⋅C)] of the rod.
The purpose of this lab is to
• scale the problem to dimensionless form
• discretize the scaled problem with the Method of Lines (MoL)
• investigate stability properties of Euler’s explicit method
• comparison between an explicit and an implicit adaptive method
• show how an implicit method can be made more efficient
• visualize the result in a two- and three-dimensional plot

COMPUTER LAB 4 SUPPORTING CHAPTER 6
259
1. Show that with the new variables u, 𝜉, and 𝜏defined by
T = T0u,
x = L𝜉,
t = tP𝜏
the problemcan be transformed (scaled) into the following dimensionlessform:
𝜕u
𝜕𝜏= a𝜕2u
𝜕𝜉2 ,
𝜏> 0,
0 < 𝜉< 1
with BCs
u(0, 𝜏) =
{1 if 0 ≤𝜏≤1
0 if 𝜏> 1
,
𝜕u
𝜕𝜉(1, 𝜏) = 0
(C.4)
and IC
u(𝜉, 0) =
{
1 if 𝜉= 0
0 if 0 < 𝜉≤1
(C.5)
Show that the only remaining parameter a is dimensionless. From now on
assume that a has the numerical value a = 1.
2. Discretize in space (the 𝜉-variable) using constant stepsize h and central differ-
ences to obtain an ODE system
du
d𝜏= Au + b(𝜏),
u(0) = u0,
where u0 is the zero vector. Show the dimensions and structures of A, b(𝜏), and
u0. Show also the discretized grid of the 𝜉-axis you have used and how the grid
points are numbered.
3. Numerical part: Discretize the ODE system in (2) with Euler’s explicit method.
Use constant time step Δt. To make your calculations efficient, you should write
your code so that the vector Au + b is formed directly, not from component
form. Store the whole approximate solution (including ICs and BCs) in a large
matrix U, as
U =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
x
x
x
…
x
0
x
x
x
…
x
0
x
x
x
…
x
.
.
.
.
…
x
.
.
.
.
…
x
.
.
.
.
…
x
0
x
x
x
…
x
1
1
1
1
…
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
Graphical part: Use, e.g., surf to draw a 3D plot of the solution. Experiment
with different values of the discretization step h and Δt and study stability.
Make one graph showing a stable solution and one graph with an unstable
solution. Present the values of h, Δt, and Δt/h2 in the two cases.

260
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
4. In this part of the lab, you shall compare the explicit method in ode23 and the
implicit method in ode23s, suitable for stiff problems, in the Matlab library.
The two functions shall be run under similar conditions (same problem, same
tolerance) and for three values of the stepsize h corresponding to N = 10, 20,
40 grid points on the 𝜉-axis.
The comparison shall comprise
a) the number of time steps needed to reach 𝜏= 2
b) the cpu time needed to do each computation
c) the maximal time step that each method could take
Collect your statistics in three tables:
Time Steps
CPU −Time
Δ tmax
N
ode23
ode23s
ode23
ode23s
ode23
ode23s
10
20
40
5. The conclusion from (4) is that the number of time steps is considerably smaller
when using a stiff method. However, the default implementation is not efficient
for stiff problems coming from parabolic PDEs. The main reason is that all the
linear systems of equations Ax = b that are to be solved in each time step need
a lot of number crunching since they are based on using the backslash opera-
tor, i.e., Gaussian elimination on a full matrix is performed each time Ax = b
is solved. However, the system matrix of these equations is tridiagonal, which
is not considered in the default implementation of ode23s. With the Matlab
function odeset, options can be set by the user in order to make the computa-
tion more efficient. Do help odeset and study the options for “Jacobian,”
and “Jpattern.” Also do help odefile and look at the example. With the
help of these options, the number of flops can be reduced considerably. Exper-
iment with these three options and collect statistics regarding the cpu time as
was done in (4).
6. Visualize the result of a successful computation from (3) in graphs. One graph
shall show two-dimensionalplots of u(𝜏, 𝜉) 0 ≤𝜉≤1 at fourtime points 𝜏≈0.5,
1, 1.5, 2. Another graph shall show a three-dimensional plot of u as function of
𝜏and 𝜉.
Conclude your results by answering the following questions. If we want
efficient numerical calculations for parabolic problems:
1. What type of ODE method should be used, stiff or nonstiff?
2. What structure does the jacobian of the ODE system have, banded or sparse
in another way?
3. What type of linear equation solver should be used in the implicit ODE
method, solver for full matrices or for sparse matrices?

COMPUTER LAB 5 SUPPORTING CHAPTER 7
261
C.5
COMPUTER LAB 5 SUPPORTING CHAPTER 7
C.5.1
Numerical Solution of Elliptic PDE Problems
This lab is an exercise in solving an elliptic PDE, the applicational background of
which is stationary heat conduction in 2D.
The physical background is as follows: Heat is conducted through a rectangular
metal block,being the region Ω = [0 ≤x ≤4, 0 ≤y ≤2] when placed in a xy-coordinate
system (see Figure C.3). Depending on the BCs, the temperature distribution T(x, y)
in the block will be different.
The following elliptic problem is formulated:
T = 0,
(x, y) ∈Ω
T(0, y) = 300,
T(4, y) = 600,
0 ≤y ≤2
𝜕T
𝜕y (x, 0) = 0, 𝜕T
𝜕y (x, 2) = 0,
0 ≤x ≤4
1. Solve the elliptic partial differential equation problem. Use the finite difference
method as described in Chapter 7. Discretize the rectangular domain into a
quadratic mesh with the following two step sizes: h = 0.2, i.e., N = 19, M = 11,
and h = 0.1, i.e., N = 39, M = 21 (see Figure C.4). Solve the problem for these
two stepsizes and visualize the solution T(x, y) with colors, using the MATLAB
function imagesc. What is the T value at (2, 1) for the two stepsizes? Derive
the analytic solution. Why is the numerical solution almost exact. Hint: From
the graph of T(x, y) make a suitable ansatz of the analytic solution and prove
that it satisfies the PDE and the BCs.
2. Solve the same problem with COMSOL MULTIPHYSICS®. General recom-
mendation: if the session turns out to be too messy, start the session again.
Check your numerical result from (1): what is the T value at the point (2, 1)?
How many nodes and triangles have been generated in the mesh? Make a refine-
ment of the grid and find again T(2, 1). How many nodes and triangles are there
now? Make the whole session again: draw geometry, impose boundary values,
set the PDE values, initialize the mesh, solve the problem, and plot a 2D graph
of the solution.
0
2
4
x
0
1
2
y
∂n(x, y) = 0
T (x, y) = 600
T (x, y) = 300
∂T
Ω
Figure C.3
Region and boundaries for a rectangular heat problem

262
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
x1
x2
xN
x
y1
y2
yM
y
Figure C.4
Discretization of the rectangular region
T (x, y) = 600
T (x, y) = 300
∂n(x, y) = 0
∂T
0
1
2
x
0
1
2
y
Ω
Figure C.5
Region and boundary conditions for the L-shaped area
3. Go back to COMSOL MULTIPHYSICS and generate the following L-shaped
area with the Geometry builder. Impose the BCs. In Figure C.5, the walls are
heat insulated, i.e., the normal derivative is equal to zero along these bound-
aries. Set the PDE parameters and initialize the mesh. How many nodes and
triangles are generated? Solve the problem. What is the value of T in the points
(1, 1) and (2, 2)? Refine the mesh and solve again. How many nodes and trian-
gles? What is T(1, 1) and T(2, 2)?
Initialize the mesh again and then refine the mesh only in the area around the
point (2, 2). What is T(1, 1) and T(2, 2)?

COMPUTER LAB 6 SUPPORTING CHAPTER 8
263
C.6
COMPUTER LAB 6 SUPPORTING CHAPTER 8
C.6.1
Numerical Experiments with the Hyperbolic Model PDE Problem
Given the model problem for a hyperbolic PDE
𝜕u
𝜕t + a𝜕u
𝜕x = 0,
a > 0,
0 < x < 2,
t > 0
with IC u(x, 0) = 0,
0 < x ≤2. As for the BC at x = 0, assume a square wave is
entering from the left, i.e.,
u(0, t) =
⎧
⎪
⎨
⎪⎩
1,
−(n + 1) T
2 < t ≤−n T
2,
n = 0, 2, 4, …
−1,
−(n + 1) T
2 < t ≤−n T
2 ,
n = 1, 3, 5, …
where T is the period time.
Make a numerical experiment showing how the (i) upwind, (ii) Lax–Friedrich,
and (iii) Lax–Wendroff methods behave on this PDE problem. Discretize the x inter-
val into N equidistant subintervals and define grid points xi = ihx, i = 0, 1, 2, … , N,
where hx = 2∕N. The Courant number 𝜎is 𝜎= aht∕hx.
1. Write programs and run the three methods on the time interval (0, 2T). Let
N = 100, T = 1, and a = 1. Present the results in graphs with u(x, 2T) as a
function of x. Show graphs for the 𝜎values: 𝜎= 0.8, 1, and 1.1. In all, there
are nine graphs to be presented. Are your experimental results in agreement
with the theoretical stability results? Which methods will smooth the solution
and which will introduce spurious oscillations?
2. In this part, the exchanger in Example 8.1 is studied. A fluid of temperature
T(x, t) is flowing with constant speed v in a pipe. Outside the pipe, there is a
cooling medium that keeps a constant low temperature Tcool. The temperature
of the fluid in the pipe is initially cool, i.e., T = Tcool but within a short time
period hot fluid enters the pipe. The task is to study how the temperature T(x, t)
of the fluid in the pipe depends on x and t.
The following PDE model is given:
𝜕T
𝜕t + v𝜕T
𝜕x + a(T −Tcool) = 0,
0 < x < L,
t > 0
with the IC
T(x, 0) = Tcool

264
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
and the BC
T(0, t) =
⎧
⎪
⎨
⎪⎩
Tcool + (Thot −Tcool
) sin(𝜋t)
0 ≤t ≤0.5
Thot
0.5 ≤t ≤4
Thot + Tcoolsin(𝜋(t −4))
t > 4
The length of the heat exchanger is L = 3. The heat exchange parameter a = 0.1, the
velocity of the fluid v = 1, the cooling temperature Tcool = 5, and the hot temperature
Thot = 100.
a) Use the upwind method to simulate the temperaturein the pipe. Choose suitable
stepsizes hx and ht and present the result in a 3D graph.
b) Work out a difference formula of Lax–Wendroff type that solves the PDE prob-
lem in (2). Present the result as a difference formula of the type
ui,k+1 = c1ui−1,k + c2ui,k + c3ui+1,k + c4
where the coefficients c1, c2, c3 and c4 are to be determined by you.
c) Program the Lax–Wendroff formula in (b), run it for a suitable choice of hx
and ht and present the result in a 3D plot. Make a comparison with the graph
from (a).

INDEX
A-stability, 54
Accuracy, 6, 43, 86
first order, 42
higher order, 56
second order, 46, 54
Acoustic wave see Equation(s)
Adaptive see Method
Advection, 3, 106, 167
Advection-diffusion, 87
Algorithm, 80
stepsize control, 59
Analysis
bifurcation, 38
eigenvalue, 132, 175
Fourier, 132, 175
sensitivity, 38, 67
stability, 20, 23, 38, 49
von Neumann, 132, 175, 187
Analytical stability see Stability
Ansatz, 94, 139, 156, 186
method, 40
Approximation, 40
difference, 41, 223
error, 225
symmetric, 84
unsymmetric, 84
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
Assemble, 162
Autonomous, 20
Bandwidth, 153, 230
Basis functions, 95, 139, 156
BC(s), 3
Dirichlet, 72, 128, 134
essential, 97
generalized Neumann, 72
linear, 73, 143
mixed, 72, 135, 144
natural, 97
Neumann, 72, 135, 144
nonlinear, 74, 135
numerical, 180
periodic, 73
Robin, 72, 135, 144
BDF see Method
Beam, 75, 148
Biharmonic see Equation(s)
Black–Scholes see Equation(s)
Blasius, 76
Boundary condition see BC(s)
Boundary layer, 87
Boundary value(s), 12
Boundary value problem see BVP

266
INDEX
BTCS, 132
Burger see Equation(s)
Butcher tableau, 58
BVP, 71–103
linear, 89
nonlinear, 91
Calculus
operator, 224
variational, 143
Cauchy problem, 167
CDR see Equation(s)
CFL condition, 175
CG, 235
Characteristic, 5, 168 see also Equations(s)
Chemical kinetics see Kinetics
Cholesky
factorization, 153, 231
incomplete, 236
Coefficient(s), 95, 139
conduction, 73, 146
convection, 73, 146
heat transfer, 74, 192
stoichiometric, 28, 116
Collocation, 95
COMSOL Multiphysics, 247–8
Concentrations, 28, 33, 116, 194
Condition
boundary see BC(s)
initial see IC(s)
Conduction, 67, 145
Conservation equation see Equation(s)
Conservative form, 167, 185
Constitutive equation see Equation(s)
Continuity equation see Equation(s)
Control theory, 29
Convection-diffusion, 73, 138, 199
Convection-diffusion-reaction, 116, 138, 199
Convergence, 216, 234
linear, 218
quadratic, 217
Coordinates
cartesian, 110,
cylindrical, 111
spherical, 111
Critical point(s), 20, 23
curl, 111, 228
DAE, 15, 28
Damping see Matrix
Descent see Method
Dependent see Variable
Derivative
normal, 112
Descent, 235
Diagonalizable see Matrix
Difference, 41, 223
backward, 41
central, 41, 60, 81
equation, 41, 219
formula, 41
forward, 41
Differential operator, 110
Differential-algebraic equation(s) see DAE
Diffusion see also Equation(s)
artificial, 88
coefficient, 74, 193
heat, 193
mass, 193
Dimension(s), 3, 105, 201 see also Unit
Dimensionless, 201
Direct method, 144, 229
Direction
search, 234
Dirichlet BC see BC(s)
Discretization, 40, 154
Dispersion, 165
Dissipation, 165
Distributed see Model
div, 111, 226
Diverge, 216, 234
Divergence, 110
Driving function, 16, 130
Duhamel see Formula
Dynamic system, 26
Eigenfrequencies, 77, 149
Eigenvalue(s), 17
analysis, 132, 175, 185
multiple, 21
single, 21
Eigenvalue problem, 17, 77, 149
Eigenvector, 17
Elliptic PDEs, 143–64
Equation(s)
advection, 3, 106, 167
advection-diffusion, 87
acoustic wave, 118
Bernoulli, 115
Black–Scholes, 120
biharmonic, 148
Burger, 168
CDR, 116, 138, 199
characteristic, 17, 219
charge continuity, 118
conservation, 9, 167, 190, 195
constitutive, 9, 189, 192
continuity, 30, 196, 198

INDEX
267
convection-diffusion, 199
convection-diffusion-reaction, 116, 138,
199
difference, 41, 223
differential-algebraic see DAE
diffusion, 106, 117, 199
Euler, 41, 115
heat, 106, 117
Helmholtz, 77, 106, 149
homogeneous, 16, 107, 219
inhomogeneous, 16, 107, 125, 220
Laplace’s 106, 143
Lotka–Volterra, 24
Maxwell, 117
modified, 176
model see Problem
molecular dynamics, 64
Navier, 119
Navier–Stokes, 114
Poisson’s, 106, 143, 145
scalar conservation, 167, 198
scalar wave, 106, 118, 165, 172
Schrödinger, 119
Stokes, 115
structural mechanics, 119
Van der Pol, 39, 43
variational, 23
vector wave, 118
vibration, 6
wave, 106, 165, 192
Equation system
linear, 229
nonlinear, 229
overdetermined, 218
quadratic, 215
Equidistant see Grid
Equilibrium points, 20
Equilibrium problem, 105
Error
approximation, 224
global, 44, 86
local, 44, 59
local discretization, 86
truncation, 42
Euler equations
compressible, 115, 172
Euler’s method
backward, 42
explicit, 42
forward, 42
implicit, 42
improved, 47
Evolution problem, 105
Explicit see Method
Explicit midpoint see Method
Extrapolation, 46
FDM, 40, 78, 154
FEM, 40, 100, 159
Fick see Law
Field, 105
scalar, 105, 110
vector, 105, 110
Fill-in, 153
Finite difference method see FDM
Finite element method see FEM
Finite volume method see FVM
Flop(s), 82, 230, 231
Flow, 114, 115, 195
compressible, 115
incompressible, 114
irrotational, 146
laminar, 115
potential, 115
turbulent, 115
Formula
algebraic, 2
difference, 41
Duhamel, 18
recursion, 41, 43, 219
Fourier
analysis, 132, 185 see also Transform(s)
law, 192
FTBS see Method
FTCS see Method
FTFS see Method
Full see Matrix
Function(s)
basis, 40, 95, 139, 160
Dirac delta, 109
Green, 80
Hamiltonian, 27
harmonic, 143
initial value, 3
pyramid, 160
residual, 95, 139, 156
roof, 101, 140
space, 96
FVM, 183
Galerkin see Method
Gas see Law
Gauss–Newton see Method
Gaussian Elimination, 229
General see Solution
Ghost point, 84
Global error see Error
grad, 110

268
INDEX
Gradient, 110, 225
conjugate, 235
Green see Function
Grid
equidistant, 41
staggered, 66, 182
variable stepsize, 41
Hamiltonian see Function
Heat see Equation(s)
Homogeneous see Equation(s)
Hooke see Law
Hyperbolic, 3, 107, 165
Hyperbolic PDEs, 165–87
IC(s), 2, 3, 105, 121
Riemann, 170
Identification, 29
Ill-posed see Problem
Implicit see Method
Implicit midpoint see Method
Incomplete see Cholesky
Incompressible, 114
Independent see Variable(s)
Inhomogeneous see Equation(s)
Initial condition see IC(s)
Initial values, 2, 3, 12, 72
Initial value problem see IVP
Inner points, 81, 84
Instability, 20
numerical, 42
Invariant
linear, 62
quadratic, 62
Inviscid see Burger
Iteration, 216, 233
Iterative method, 144, 233
IVP, 2, 37–69
Jacobian, 22, 215
Kinetics
chemical, 28, 48, 194
drug, 35
Krylov space, 235
Laplace see Equation(s)
Laplacian, 111
Law(s),
Arrhenius, 194
conservation, 10, 167, 195
Fick, 193
Fourier, 193
gas, 194
Hooke, 194
Lorentz, 195
mass action, 28, 194
Newton, 26, 190, 193
Ohm, 195
scalar conservation, 167, 195
Stefan–Boltzmann, 193
Layer
boundary, 88
transition, 115
LCC see System
Leap-frog see Method
Least-squares, 218
Limit cycle, 40
Linear, 16, 73, 107 see also ODE(s), PDE(s),
BC(s)
piecewise, 101
Load vector, 102, 162
Local error see Error
Locus
root, 38
Lorentz force, 118 see also Law
Lotka–Volterra, 24
LU-factorization, 230
Lumped see Model
Mass see Matrix
Mass action see Law
MATLAB, 242–7
Matrix
band, 230
damping, 27
defective, 17
diagonalizable, 17
exponential, 18
full, 140, 229
iteration, 233
local stiffness, 161
mass, 27
nilpotent, 19
nondefective, 17
positive definite, 82, 230
preconditioning, 236
profile, 232
rectangular, 218
sensitivity, 67
sparse, 229
SPD, 230
spring, 27
stiffness, 27, 102, 161
stoichiometric, 28, 116
symmetric, 82, 230
Maxwell see Equation(s)
Method
explicit midpoint, 60

INDEX
269
Method see also Algorithm
Adams–Bashforth, 61
Adams–Moulton, 61
adaptive, 41, 58
ansatz, 40
BDF, 61
Bogacki–Shampine, 59
conjugate gradient, 235
Crank–Nicolson, 133
descent, 235
direct, 144, 229
discretization, 40
explicit, 42, 60, 131,
Euler, 41, 42
Euler–Cromer, 43, 66
finite difference see FDM
finite element see FEM
finite volume see FVM
FTBS, 132, 186
FTCS, 128, 178, 187
FTFS, 177
Galerkin, 95, 98, 151, 159
Gauss–Newton, 67, 218
Gauss–Seidel, 234
Gear, 61
implicit, 42, 60, 132
implicit midpoint, 63
iterative, 233
Jacobi, 234
Lax–Friedrich, 178
Lax–Wendroff, 179
leap-frog, 60, 65, 66
linear multistep, 66
of lines, 130, 174
multigrid, 236
Newton, 215
one-step, 42
RK4 see Runge–Kutta
robust, 5
Runge–Kutta, 56
shooting, 92
search, 234
secant, 93
stationary iterative, 233
Störmer, 65
trapezoidal, 55
two-step, 60
unstable, 60, 178
upwind, 88, 175
Verlet, 65
Model see also Equation(s)
compartment, 29
dynamic, 26
distributed, 197
lumped, 26, 196
mathematical, 9, 190–204
ODE, 26
PDE, 114
Modeling
mathematical, 9, 190–204
MoL, 130, 174
Molecular dynamics see Equation(s)
nabla, 110
Navier see Equation(s)
Navier–Stokes see Equation(s)
Networks
electrical, 28
Neumann boundary conditions see BC(s)
Newton, 26 see also Law, Method
Node(s), 101, 159
Nonconservative form, 168, 185
Non-defective see Matrix
Nonlinear, 65, 91, 108, 138, 150, 167 see also
ODE(s), PDE(s) and BC(s)
Non-stiff, 57
Numbering, 159
local, 161
Numerical boundary condition see BC(s)
Numerical stability see Stability
ODE(s), 2, 11–36
Ohm see Law
Operator
differential, 110
calculus, 224
nabla, 110
One-step see Method
Order, 12, 41
accuracy, 42, 87
Ordinary differential equation(s) see ODE(s)
Oscillations, 6
numerical, 60
spurious, 88
Overflow, 49
Parabolic PDE(s), 123–41
Parameter(s), 2, 3, 6, 67
estimation, 38, 67
numerical, 6
sensitivity, 67
study, 38, 39
Partial differential equation(s) see PDE(s)
Particle dynamics, 30
Particular see Solution
PDE(s), 3, 105–22
elliptic, 107, 143–64
hyperbolic, 107, 165–87

270
INDEX
PDE(s), (Continued)
linear, 107
nonlinear, 108, 127, 150, 167
parabolic, 107, 123–41
Peclet number, 88
Pentadiagonal, 85
Periodic see BC(s)
Phase portrait, 38
Pipe, 73, 125, 126, 171, 199
Plate, 148
Positive definite see Matrix
Positivity, 64
Preconditioner, 236
Preconditioning see Matrix
Predator-prey, 24
Poisson see Equation(s)
Problem see also Equation(s)
eigenvalue, 17
equilibrium, 105
evolution, 105
ill-posed, 123
model, 49, 79, 106, 123, 143, 167
singular perturbation, 87
steady-state, 105
stiff, 53, 131
time-dependent, 105
well-posed, 105, 121
Profile, 232
Pseudoinverse, 218
Quadratic see Equation system
Radiation, 74, 135
Rate constant, 28, 194
Reactor
tank, 197,
tubular, 127
Recursion see Formula
Region see Stability
Residual, 218, 234 see also Function(s)
Resonance, 149
Reynold’s number, 115
Riemann see IC(s)
Robin see BC(s)
Robust see Method
Roof see Function(s)
Root locus, 38
Rotation, 111
Runge–Kutta see also Method
classical, 56
embedded, 58
explicit, 58
implicit, 58
s-stage, 57
Scalar conservation law see Law
Scalar model problem see Problem
Schrödinger see Equation(s)
Scientific computing, 1, 5
Search
direction, 235
method, 234
Semi-discretization, 130
Sensitivity see Analysis, Matrix
Separation of variables, 110
Shock wave(s), 8, 116, 172, 178
SI see Unit
Simulation, 1, 6
Singular perturbation see Problem
Soap film, 150
Sobolev, 100
Solution
bounded, 50
d’Alembert, 109, 165
classical, 96
general, 2, 3, 11, 13, 17, 71, 72
particular, 3, 13, 72
stable, 20
strong, 96
trajectory, 20
unstable, 20, 132, 176
variational, 96
weak, 96
Source strength, 111, 228
Sparse see Matrix, System
SPD see Matrix
Spring see Matrix
SOR, 234
SSOR, 234
Splitting, 233
Stability, 20, 29, 34
analysis, 20, 38
analytical, 20, 51
asymptotic, 21
eigenvalue, 132, 174, 187
numerical, 50, 132, 176
region of, 50, 54, 55, 57
von Neumann, 132, 175, 187
Staggered see Grid
State-space, 29
Steady-state see Problem
Steepness, 111
Stefan–Boltzmann see Law
Stencil, 129, 152, 175, 181
Step length, 235
Stepfunction, 7, 170
Stepsize, 6, 41
constant, 41

INDEX
271
control, 59
variable, 41
Stiff see Problem
Stiffness see Matrix
Stoichiometric see Coefficient(s)
Störmer see Method
Superposition, 17, 110
Symmetric see Matrix
System
dynamic, 26
hyperbolic, 166, 171
LCC, 16
ODE, 12
PDE, 105, 127, 150
sparse, 82, 153, 229
stiff, 53, 123, 131
uncoupled, 51
Time dependent see Problem
Timescales, 52
Trajectory, 38
Transform(s)
Fourier, 237–9
Transition see Layer
Tridiag, 82, 131, 231
Tridiagonal, 82, 153, 231
Truncation error see Error
Tune, 6
Turbulent see Flow
Two-step see Method
Uncoupled see System
Unit(s), 26, 190
Unstable see Solution
Upwind see Method
Value(s) see Boundary value(s), Initial value(s)
Variable(s)
dependent, 11, 105
independent, 11, 105
separation of, 110
Variational see also Calculus, Equation(s)
formulation, 96
Vector
load, 102, 162
local load, 162
Vector wave see Equation(s)
Verlet see Method
Vibration see Equation(s)
Viscosity
artificial, 88
dynamic, 194
kinematic, 76, 194
Visualization, 8
Visualize, 38
von Neumann see Analysis, Stability
Vorticity strength, 229
Wave equation see Equation(s)
Wave number, 108
Weak, 96, 157, 170
Well-posed see Problem

WILEY END USER LICENSE AGREEMENT
Go to www.wiley.com/go/eula to access Wiley’s ebook EULA.

