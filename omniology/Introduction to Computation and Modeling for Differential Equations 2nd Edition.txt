

INTRODUCTION TO
COMPUTATION AND
MODELING FOR
DIFFERENTIAL
EQUATIONS


INTRODUCTION TO
COMPUTATION AND
MODELING FOR
DIFFERENTIAL
EQUATIONS
Second Edition
LENNART EDSBERG
Department of Numerical Analysis and Computing Science
KTH - Royal Institute of Technology
Stockholm, Sweden

Copyright Â© 2016 by John Wiley & Sons, Inc. All rights reserved
Published by John Wiley & Sons, Inc., Hoboken, New Jersey
Published simultaneously in Canada
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or
by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should
be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ
07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permissions.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in
preparing this book, they make no representations or warranties with respect to the accuracy or
completeness of the contents of this book and specifically disclaim any implied warranties of
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales
representatives or written sales materials. The advice and strategies contained herein may not be suitable
for your situation. You should consult with a professional where appropriate. Neither the publisher nor
author shall be liable for any loss of profit or any other commercial damages, including but not limited to
special, incidental, consequential, or other damages.
For general information on our other products and services or for technical support, please contact our
Customer Care Department within the United States at (800) 762-2974, outside the United States at
(317) 572-3993 or fax (317) 572-4002.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may
not be available in electronic formats. For more information about Wiley products, visit our web site at
www.wiley.com.
Library of Congress Cataloging-in-Publication Data:
Edsberg, Lennart, 1946â€“
Introduction to computation and modeling for differential equations / Lennart Edsberg. â€“ Second
edition.
pages cm
Includes bibliographical references and index.
ISBN 978-1-119-01844-5 (cloth)
1. Differential equationsâ€“Data processing. 2. Mathematical models. I. Title.
QA371.5.D37E37 2016
515â€².350285â€“dc23
2015018724
Typeset in 10/12pt TimesLTStd by SPi Global, Chennai, India
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1
1
2016

CONTENTS
Preface
xi
1
Introduction
1
1.1 What is a Differential Equation? 1
1.2 Examples of an Ordinary and a Partial Differential Equation, 2
1.3 Numerical Analysis, a Necessity for Scientific Computing, 5
1.4 Outline of the Contents of this Book, 8
Bibliography, 10
2
Ordinary Differential Equations
11
2.1 Problem Classification, 11
2.2 Linear Systems of ODEs with Constant Coefficients, 16
2.3 Some Stability Concepts for ODEs, 19
2.3.1
Stability for a Solution Trajectory of an ODE System, 20
2.3.2
Stability for Critical Points of ODE Systems, 23
2.4 Some ODE models in Science and Engineering, 26
2.4.1
Newtonâ€™s Second Law, 26
2.4.2
Hamiltonâ€™s Equations, 27
2.4.3
Electrical Networks, 27
2.4.4
Chemical Kinetics, 28
2.4.5
Control Theory, 29
2.4.6
Compartment Models, 29

vi
CONTENTS
2.5 Some Examples From Applications, 30
Bibliography, 36
3
Numerical Methods For Initial Value Problems
37
3.1 Graphical Representation of Solutions, 38
3.2 Basic Principles of Numerical Approximation of ODEs, 40
3.3 Numerical Solution of IVPs with Eulerâ€™s method, 41
3.3.1
Eulerâ€™s Explicit Method: Accuracy, 43
3.3.2
Eulerâ€™s Explicit Method: Improving the Accuracy, 46
3.3.3
Eulerâ€™s Explicit Method: Stability, 48
3.3.4
Eulerâ€™s Implicit Method, 53
3.3.5
The Trapezoidal Method, 55
3.4 Higher Order Methods for the IVP, 56
3.4.1
Rungeâ€“Kutta Methods, 56
3.4.2
Linear Multistep Methods, 60
3.5 Special Methods for Special Problems, 62
3.5.1
Preserving Linear and Quadratic Invariants, 62
3.5.2
Preserving Positivity of the Numerical Solution, 64
3.5.3
Methods for Newtonâ€™s Equations of Motion, 64
3.6 The Variational Equation and Parameter Fitting in IVPs, 66
Bibliography, 69
4
Numerical Methods for Boundary Value Problems
71
4.1 Applications, 73
4.2 Difference Methods for BVPs, 78
4.2.1
A Model Problem for BVPs, Dirichletâ€™s BCs, 79
4.2.2
A Model Problem for BVPs, Mixed BCs, 83
4.2.3
Accuracy, 86
4.2.4
Spurious Solutions, 87
4.2.5
Linear Two-Point BVPs, 89
4.2.6
Nonlinear Two-Point BVPs, 91
4.2.7
The Shooting Method, 92
4.3 Ansatz Methods for BVPs, 94
4.3.1
Starting with the ODE Formulation, 95
4.3.2
Starting with the Weak Formulation, 96
4.3.3
The Finite Element Method, 100
Bibliography, 103
5
Partial Differential Equations
105
5.1 Classical PDE Problems, 106
5.2 Differential Operators Used for PDEs, 110
5.3 Some PDEs in Science and Engineering, 114
5.3.1
Navierâ€“Stokes Equations for Incompressible Flow, 114

CONTENTS
vii
5.3.2
Eulerâ€™s Equations for Compressible Flow, 115
5.3.3
The Convectionâ€“Diffusionâ€“Reaction Equations, 116
5.3.4
The Heat Equation, 117
5.3.5
The Diffusion Equation, 117
5.3.6
Maxwellâ€™s Equations for the Electromagnetic Field, 117
5.3.7
Acoustic Waves, 118
5.3.8
SchrÃ¶dingerâ€™s Equation in Quantum Mechanics, 119
5.3.9
Navierâ€™s Equations in Structural Mechanics, 119
5.3.10 Blackâ€“Scholes Equation in Financial Mathematics, 120
5.4 Initial and Boundary Conditions for PDEs, 121
5.5 Numerical Solution of PDEs, Some General Comments, 121
Bibliography, 122
6
Numerical Methods for Parabolic Partial Differential Equations
123
6.1 Applications, 125
6.2 An Introductory Example of Discretization, 127
6.3 The Method of Lines for Parabolic PDEs, 130
6.3.1
Solving the Test Problem with MoL, 130
6.3.2
Various Types of Boundary Conditions, 134
6.3.3
An Example of the Use of MoL for a Mixed Boundary
Condition, 135
6.4 Generalizations of the Heat Equation, 136
6.4.1
The Heat Equation with Variable Conductivity, 136
6.4.2
The Convection â€“ Diffusion â€“ Reaction PDE, 138
6.4.3
The General Nonlinear Parabolic PDE, 138
6.5 Ansatz Methods for the Model Equation, 139
Bibliography, 140
7
Numerical Methods for Elliptic Partial Differential Equations
143
7.1 Applications, 145
7.2 The Finite Difference Method, 150
7.3 Discretization of a Problem with Different BCs, 154
7.4 Ansatz Methods for Elliptic PDEs, 156
7.4.1
Starting with the PDE Formulation, 156
7.4.2
Starting with the Weak Formulation, 158
7.4.3
The Finite Element Method, 159
Bibliography, 164
8
Numerical Methods for Hyperbolic PDEs
165
8.1 Applications, 171
8.2 Numerical Solution of Hyperbolic PDEs, 174
8.2.1
The Upwind Method (FTBS), 175
8.2.2
The FTFS Method, 177

viii
CONTENTS
8.2.3
The FTCS Method, 178
8.2.4
The Laxâ€“Friedrichs Method, 178
8.2.5
The Leap-Frog Method, 179
8.2.6
The Laxâ€“Wendroff Method, 179
8.2.7
Numerical Method for the Wave Equation, 181
8.3 The Finite Volume Method, 183
8.4 Some Examples of Stability Analysis for Hyperbolic PDEs, 185
Bibliography, 187
9
Mathematical Modeling with Differential Equations
189
9.1 Nature Laws, 190
9.2 Constitutive Equations, 192
9.2.1
Equations in Heat Transfer Problems, 192
9.2.2
Equations in Mass Diffusion Problems, 193
9.2.3
Equations in Mechanical Moment Diffusion Problems, 193
9.2.4
Equations in Elastic Solid Mechanics Problems, 194
9.2.5
Equations in Chemical Reaction Engineering Problems, 194
9.2.6
Equations in Electrical Engineering Problems, 195
9.3 Conservative Equations, 195
9.3.1
Some Examples of Lumped Models, 196
9.3.2
Some Examples of Distributed Models, 197
9.4 Scaling of Differential Equations to Dimensionless Form, 201
Bibliography, 204
10
Applied Projects on Differential Equations
205
Project 1
Signal propagation in a long electrical conductor, 205
Project 2
Flow in a cylindrical pipe, 206
Project 3
Soliton waves, 208
Project 4
Wave scattering in a waveguide, 209
Project 5
Metal block with heat sourse and thermometer, 210
Project 6
Deformation of a circular metal plate, 211
Project 7
Cooling of a chrystal glass, 212
Project 8
Rotating fluid in a cylinder, 212
Appendix A
Some Numerical and Mathematical Tools
215
A.1 Newtonâ€™s Method for Systems of Nonlinear Algebraic Equations, 215
A.1.1
Quadratic Systems, 215
A.1.2
Overdetermined Systems, 218
A.2 Some Facts about Linear Difference Equations, 219
A.3 Derivation of Difference Approximations, 223
Bibliography, 225
A.4 The Interpretations of Grad, Div, and Curl, 225
A.5 Numerical Solution of Algebraic Systems of Equations, 229

CONTENTS
ix
A.5.1
Direct Methods, 229
A.5.2
Iterative Methods for Linear Systems of Equations, 233
A.6 Some Results for Fourier Transforms, 237
Bibliography, 239
Appendix
B
Software for Scientific Computing
241
B.1 MATLAB, 242
B.1.1
Chapter 3: IVPs, 242
B.1.2
Chapter 4: BVPs, 244
B.1.3
Chapter 6: Parabolic PDEs, 245
B.1.4
Chapter 7: Elliptic PDEs, 246
B.1.5
Chapter 8: Hyperbolic PDEs, 246
B.2 COMSOL MULTIPHYSICS, 247
Bibliography and Resources, 249
Appendix C
Computer Exercises to Support the Chapters
251
C.1 Computer Lab 1 Supporting Chapter 2, 251
C.1.1
ODE Systems of LCC Type and Stability, 251
C.2 Computer Lab 2 Supporting Chapter 3, 254
C.2.1
Numerical Solution of Initial Value Problems, 254
C.3 Computer Lab 3 Supporting Chapter 4, 257
C.3.1
Numerical Solution of a Boundary Value Problem, 257
C.4 Computer Lab 4 Supporting Chapter 6, 258
C.4.1
Partial Differential Equation of Parabolic Type, 258
C.5 Computer Lab 5 Supporting Chapter 7, 261
C.5.1
Numerical Solution of Elliptic PDE Problems, 261
C.6 Computer Lab 6 Supporting Chapter 8, 263
C.6.1
Numerical Experiments with the Hyperbolic Model PDE
Problem, 263
Index
265


PREFACE
In the Second Edition of this book, corrections and a large number of additions and
modifications have been made. Chapter 3 contains a new section with special methods
for special problems. The emphasis is on the numerical preservation of invariants of
the solution, such as positivity and quadratic expressions of, e.g., energy. Chapters
4 and 7 have new sections presenting the weak formulations of ordinary differential
equations and partial differential equations as starting point for Galerkinâ€™s method
followed by the finite element method. Chapter 8 has a new section on the finite
volume method that presents the wave equation with clear connections to Chapter
3 where the leap-frog method with staggered grid is discussed. Chapter 10 has been
newly added in this edition where well-tested student projects are presented for use in,
e.g., a course based on this book. The projects have been used at KTH, Stockholm, for
many years, and the projects have been developed and modified for several decades
by my colleague Gerd Eriksson who has given me the permission to publish them
in this new edition. I would like to extend my sincere thanks to her and also to my
colleague Jesper Oppelstrup who has contributed with many valuable comments and
suggestions concerning the new stuff of this book for the past many years.
Lennart Edsberg
KTH
Stockholm
August 2015


1
INTRODUCTION
It is probably no exaggeration to say that differential equations are the most common
and important mathematical model in science and engineering. Whenever we want
to model a system where the state variables vary with time and/or space, differential
equations are the natural tool for describing its behavior. The construction of a differ-
ential equation model demands a thorough understanding of what takes place in the
process we want to describe.
However, setting up a differential equation model is not enough, we must also
solve the equations. The process of finding useful solutions of a differential equation
is much a symbiosis of modeling, mathematics and choosing a method, analytical or
numerical. Therefore,when you are requested to solve a differential equation problem
from some application, it is useful to know facts about its modeling background, its
mathematical properties, and its numerical treatment. The last part involves choosing
appropriate numerical methods, adequate Software, and appealing ways of visualiz-
ing the result.
The interaction among modeling, mathematics, numerical methods, and program-
ming is nowadays referred to as scientific computing and its purpose is to perform
simulations of processes in science and engineering.
1.1
WHAT IS A DIFFERENTIAL EQUATION?
A differential equation is a relation between a function and its derivatives. If the func-
tion u depends on only one variable t, i.e., u = u(t), the differential equation is called
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

2
INTRODUCTION
ordinary. If u depends on at least two variables t and x, i.e., u = u(x, t), the differential
equation is called partial.
1.2
EXAMPLES OF AN ORDINARY AND A PARTIAL DIFFERENTIAL
EQUATION
An example of an elementary ordinary differential equation (ODE) is
du
dt = au
(1.1)
where a is a parameter, in this case a real constant. It is frequently used to model, e.g.,
the growth of a population (a > 0) or the decay of a radioactive substance (a < 0).
The ODE (1.1) is a special case of differential equations called linear with constant
coefficients (see Chapter 2).
The differential equation (1.1) can be solved analytically, i.e., the solution can be
written explicitly as an algebraic formula. Any function of the form
u(t) = Ceat
(1.2)
where C is an arbitrary constant satisfies (1.1) and is a solution. The expression (1.2)
is called the general solution. If C is known to have a certain value, however, we get
a unique solution, which, when plotted in the (t, u)-plane, gives a trajectory (solution
curve). This solution is called a particular solution.
The constant C can be determined, e.g., by selecting a point (t0, u0) in the
(t, u)-plane through which the solution curve shall pass. Such a point is called an
initial point and the demand that the solution shall go through this point is called the
initial condition. A differential equation together with an initial condition is called
an initial value problem (IVP) (Figure 1.1).
0
0.5
1
1.5
2
âˆ’2
âˆ’1
0
1
2
t
u(t)
Some solutions of du/dt = âˆ’u
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
t
u(t)
Solution of du/dt = âˆ’u, u(0) = 1
Figure 1.1
General and particular solution

EXAMPLES OF AN ORDINARY AND A PARTIAL DIFFERENTIAL EQUATION
3
Observe that the differential equation alone does not define a unique solution, we
also need an initial condition or other conditions. A plot of all trajectories, i.e., all
solutions of the ODE (1.1) in the (t, u)-plane will result in a graph that is totally black
as there are infinitely many solution curves filling up the whole plane.
In general, it is not possible to find analytical solutions of a differential equation.
The â€œsimpleâ€ differential equation
du
dt = t2 + u2
(1.3)
cannot be solved analytically. If we want to plot some of its trajectories, we have to
use numerical methods.
An example of an elementary partial differential equation (PDE) is
ğœ•u
ğœ•t + ağœ•u
ğœ•x = 0
(1.4)
where a is a parameter, in this case a real constant. The solution of (1.4) is a function
of two variables u = u(x, t). This differential equation is called the 1D (one space
dimension, x) advection equation. Physically it describes the evolution of a scalar
quantity, e.g., temperature u(x, t) carried along the x-axis by a flow with constant
velocity a. It is also known as the linear convection equation and is an example of a
hyperbolic PDE (see Chapter 5).
The general solution of this differential equation is (see Exercise 1.2.4)
u(x, t) = F(x âˆ’at)
(1.5)
where F is any arbitrary differentiable function of one variable. This is indeed a large
family of solutions! The three functions
u(x, t) = x âˆ’at,
u(x, t) = eâˆ’(xâˆ’at)2,
u(x, t) = sin(x âˆ’at)
are just three solutions out of the infinitely many solutions of this PDE.
To obtain a unique solution for t > 0 we need an initial condition. If the differen-
tial equation is valid for all x, i.e., âˆ’âˆ< x < âˆand u(x, t) is known for t = 0, i.e.,
u(x, 0) = u0(x) where u0(x) is a given function, the initial value function, we get the
particular solution (Figure 1.2)
u(x, t) = u0(x âˆ’at)
(1.6)
Physically, (1.6) corresponds to the propagation of the initial function u0(x) along
the x-axis with velocity |a|. The propagation is to the right if a > 0 and to the left if
a < 0.
The graphical representation can alternatively be done in 3D (Figure 1.3).
When a PDE is formulated on a semi-infinite or finite x-interval, boundary condi-
tions are needed in addition to initial conditions to specify a unique solution.

4
INTRODUCTION
âˆ’3
âˆ’2
âˆ’1
0
1
2
3
4
5
6
7
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
u(x, t)
x
exp(â€“(x â€“ t)2) at t = 0 and t = 4
Figure 1.2
Propagation of a solution of the advection equation
0
1
2
3
4
âˆ’4
âˆ’2
0
2
4
6
8
0
0.2
0.4
0.6
0.8
1
t
x
u(x, t)
3D-graph of u(x, t) = exp (â€“(x â€“ at)2) when a = 1
Figure 1.3
3D graph of a propagating solution

NUMERICAL ANALYSIS, A NECESSITY FOR SCIENTIFIC COMPUTING
5
Most PDEs can only be solved with numerical methods. Only for very special
classes of PDE problems it is possible to find an analytic solution, often in the form
of an infinite series.
Exercise 1.2.1. If a is a complex constant a = ğœ‡+ iğœ”what is the real and imaginary
part of eat?
Exercise 1.2.2. What conditions are necessary to impose on ğœ‡and ğœ”if Re(eat) for
t > 0 is to be
a) exponentially decreasing,
b) exponentially increasing,
c) oscillating with constant amplitude,
d) oscillating with increasing amplitude,
e) oscillating with decreasing amplitude?
Exercise 1.2.3. If a is a complex constant what condition on a is needed if eat is to
be bounded for t â‰¥0?
Exercise 1.2.4. Show that the general solution of ut + aux = 0 is u(x, t) = F(x âˆ’at)
by introducing the transformation
ğœ‰= x + at,
ğœ‚= x âˆ’at
Transform the original problem to a PDE in the variables ğœ‰and ğœ‚, and solve this PDE.
Sketch the two coordinate systems in the same graph.
Exercise 1.2.5. Show that a solution of (1.4) starting at t = 0, x = x0 is constant
along the straight line x âˆ’at = x0. This means that the initial value u(x0, 0) = u0(x0)
is transported unchanged along this line, which is called a characteristic of the hyper-
bolic PDE (1.4).
1.3
NUMERICAL ANALYSIS, A NECESSITY FOR SCIENTIFIC
COMPUTING
In scientific computing, the numerical methods used to solve mathematical models
should be robust, i.e., they should be reliable and give accurate values for a large range
of parameter values. Sometimes, however, a method may fail and give unexpected
results. Then, it is important to know how to investigate why an erroneous result has
occurred and how it can be remedied.
Two basic concepts in numerical analysis are stability and accuracy. When
choosing a method for solving a differential equation problem, it is necessary to

6
INTRODUCTION
have some knowledge about how to analyze the result of the method with respect to
these concepts. This necessity has been well expressed by the late Prof. Germund
Dahlquist, famous for his fundamental research in the theory of numerical treatment
of differential equations: â€œThere is nothing as practical as a little good theory.â€
As an example of what may be unexpected results, choose the well-known vibra-
tion equation, occurring in, e.g., mechanical vibrations, electrical vibrations, and
sound vibrations. The form of this equation with initial conditions is
md2u
dt2 + cdu
dt + ku = f(t),
u(0) = u0, du
dt (0) = v0
(1.7)
In mechanical vibrations, m is the mass of the vibrating particle, c the damping coef-
ficient, k the spring constant, f(t) an external force acting on the particle, u0 the initial
position, and v0 the initial velocity of the particle. The five quantities m, c, k, u0, v0 are
referred to as the parameters of the problem.
Solving (1.7) numerically for a set of values of the parameters is an example of
simulation of a mechanical process and it is desirable to choose a robust method, i.e., a
method for which the results are reliable for a large range of values of the parameters.
The following two examples based on the vibration equation show that unexpected
results depending on instability and/or bad accuracy may occur.
Example 1.1.
Assume that f(t) = 0 (free vibrations) and the following values of
the parameters: m = 1, c = 0.4, k = 4.5, u0 = 1, v0 = 0. Without too much knowledge
about mechanics, we would expect the solution to be oscillatory and damped, i.e.,
the amplitude of the vibrations is decreasing. If we use the simple Euler method with
constant stepsize h = 0.1 (see Chapter 3), we obtain the following numerical solution,
visualized together with the exact solution (Figure 1.4).
The graph shows a numerical solution that is oscillatory but unstable with increas-
ing amplitude. Why? The answer is given in Chapter 3. For the moment just accept
that insight in stability concepts and experience in handling unexpected results are
needed for successful simulations.
Example 1.2.
When the parameters in equation (1.7) are changed to m = 1,
c = 10, k = 103, u0 = 0, v0 = 0, and f(t) = 10âˆ’4 sin(40t) (forced vibrations) we
obtain the following numerical result with a method from a commercial software
product for solving differential equations (Figure 1.5).
The graph shows that the numerical result is not correct. Why? In this example
there is an accuracy problem. The default accuracy used in the method is not suffi-
cient; the corresponding numerical parameter must be tuned appropriately. Accuracy
for ODEs is discussed in Chapter 3.
Numerical solution of PDEs can also give rise to unexpected results. As an
example consider the PDE (1.4), which has the property of propagating the initial
function along the x-axis. One important application of this equation occurs in gas
dynamics where simulation of shock waves is essential. A simple 1D model of a

NUMERICAL ANALYSIS, A NECESSITY FOR SCIENTIFIC COMPUTING
7
0
1
2
3
4
5
6
7
8
9
10
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
t(s)
u(m)
Numerical solution
Exact solution
Figure 1.4
An example of numerical instability
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
âˆ’5
âˆ’4
âˆ’3
âˆ’2
âˆ’1
0
1
2
3
4
5 Ã— 10âˆ’7 Exact solution (solid curve) and numerical solution (dotted curve)
Figure 1.5
An example of insufficient accuracy

8
INTRODUCTION
âˆ’0.2 âˆ’0.1
0
0.1
0.2
0.3
âˆ’0.5
0
0.5
1
1.5
2
Initial function = stepfunction
x
u(x, 0)
âˆ’0.2 âˆ’0.1
0
0.1
0.2
0.3
âˆ’0.5
0
0.5
1
1.5
2
x
u(x, 2)
âˆ’0.2 âˆ’0.1
0
0.1
0.2
0.3
âˆ’0.5
0
0.5
1
1.5
2
x
u(x, 1)
Numerical solution at t = 2
Numerical solution at t = 1
âˆ’0.5
0
0.5
0
1
2
0
1
2
3
x
3D plot of the numerical solution
t
u(x, t)
Figure 1.6
Numerical solution of the advection equation
shockwave is a stepfunction. Assume the initial function u0(x) is a stepfunction
(Figure 1.6). In the exact solution of (1.4) with a stepfunction as initial condition,
the solution propagates along the x-axis without changing shape.
However, using a numerical method, where simple difference approximations are
used in both the t- and the x-direction, wiggles are generated as the solution prop-
agates (see the graphs in Figure 1.6). The shape of the initial function is distorted.
Why? Answers will be given in Chapter 8.
1.4
OUTLINE OF THE CONTENTS OF THIS BOOK
After this introductory chapter, the text is organized so that ODEs are treated first, fol-
lowed by PDEs. The aim of this book is to be an introduction to scientific computing.
Therefore, not only numerical methods are presented but also
1. how to set up a mathematical model in the form of an ODE or a PDE;
2. an outline of the mathematical properties of differential equation problems and
explicit analytical solutions (when they exist); and
3. examples of how results are presented with proper visualization.
The ODE part starts in Chapter 2 presenting some mathematical properties of ODEs,
first the basic and important problem class of ODE systems which are linear with

OUTLINE OF THE CONTENTS OF THIS BOOK
9
constant coefficients applied to important models from classical mechanics, electrical
networks, and chemical kinetics. This is followed by numerical treatment of ODE
problems in general, following the classical subdivision into IVPs in Chapter 3, and
boundary value problems, BVPs, in Chapter 4. For IVPs, the finite difference method
(FDM) is described starting with the elementary Euler method. Important concepts
brought up for ODEs are accuracy and stability which is followed up also for PDEs
in later chapters. For BVPs, both the FDM and the finite element method (FEM) are
described.
Important application areas where ODEs are used as mathematical model are pre-
sented, selected examples are described in the chapters and exercises, sometimes
suitable for computer labs, are inserted into the text.
PDEs are introduced in Chapter 5, which deals with some mathematical proper-
ties of their solutions. There is also a presentation of several of the important PDEs
of science and engineering, such as the equations of Navierâ€“Stokes, Maxwell and
SchrÃ¶dinger.
The three chapters to follow are devoted to the numerical treatment of PDEs
following the classical subdivision into parabolic, elliptic, and hyperbolic problems.
Concepts from the ODE chapters such as accuracy and stability are treated for
time-dependent, parabolic and hyperbolic PDEs. For stationary problems (ellip-
tic PDEs), sparse linear systems of algebraic equations are essential and hence
discussed.
Selected models introduced in Chapters 2, 5, and 9 are used as illustrations of
the different methods introduced. Models are taken from mechanics, fluid dynam-
ics, electromagnetics, reaction engineering, biochemistry, control theory, quantum
mechanics, solid mechanics, etc. and are suitable for computer labs.
In Chapter 9, an outline of mathematical modeling is brought up with the intention
of giving a feeling of the principles used when a differentialequation (ODE or PDE) is
set up from conservation laws and constitutive relations. It is also shown by examples
how a general differential equation model can be simplified by suitable assumptions.
This chapter can be studied in parallel with Chapters 3, 4, 6, 7, and 8 if the reader
wants to see how the models are constructed.
In a number of Appendices (A.1â€“A.6), different parts of mathematics and numer-
ical mathematics that are essential for numerical treatment of differential equations
are presented as summaries.
Appendix B gives an overview of existing software for scientific computing with
emphasis on the use of MATLABÂ® for programming and COMSOL MultiphysicsÂ®
for modeling and parameter studies. Many of the exercises in this chapter and in
Chapters 2â€“8 are solved with MATLAB programs in this appendix.
Appendix C contains a number of computer exercises to support the chapters con-
taining numerical solution of ODEs and PDEs.
In Chapter 10, a numberof projects are suggested. These projects involveproblems
where knowledge from several chapters and appendices are needed to compute a
solution.

10
INTRODUCTION
BIBLIOGRAPHY
1. G. Dahlquist and Ã… BjÃ¶rck, â€œNumerical Methodsâ€, Dover, 2003
2. L. RÃ¥de, B. Westergren, â€œMathematics Handbook for Science and Engineeringâ€,
Studentlitteratur 1998

2
ORDINARY DIFFERENTIAL
EQUATIONS
This chapter is not intended to be a thorough treatment of mathematical properties
of ordinary differential equations (ODEs). It is rather an overview of some impor-
tant definitions and concepts such as problem classification and properties of linear
ODE systems with constant coefficients and stability. These matters are important for
numerical analysis of methods solving ODE problems. For a more extensive treat-
ment of ODEs, it is recommended to consult some mathematical textbook, e.g., one
of those referenced at the end of this chapter.
2.1
PROBLEM CLASSIFICATION
A general way of formulating a first-order scalar ODE is
du
dt = f(t, u)
(2.1)
where t is defined in some interval, bounded or unbounded,and u(t) is a solution if u(t)
satisfies (2.1) for all t in the interval. The variable t is called the independent variable
and u is called the dependent variable. The derivative duâˆ•dt can also be denoted Ì‡u
or ut.
As we have already pointed out, the general solution u = u(t, C) of (2.1) contains
an arbitrary constant C. Hence, the general solution is a family of infinitely many
solutions.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

12
ORDINARY DIFFERENTIAL EQUATIONS
If we prescribe an initial condition (IC) u(t0) = u0, the constant C is determined
and we get a unique solution, a particular solution.
A scalar ODE of second order can be written as
d2u
dt2 = f
(
t, u, du
dt
)
(2.2)
The general solution of (2.2) contains two arbitrary constants C1 and C2, i.e., u =
u(t, C1, C2). Therefore,we need two conditions to determine C1 and C2 to get a unique
solution. These conditions can be given in various ways. One way is to specify u at
two different values of t, i.e., at t = a and t = b:
u(a) = ğ›¼
u(b) = ğ›½
(2.3)
This way of specifying boundary conditions (BCs) to the second-order ODE (2.2)
is called a boundary value formulation, and (2.2) and (2.3) define a boundary value
problem (BVP). Other possible types of BCs will be shown in Chapter 4.
Another way to specify conditions is by ICs. Equation (2.2) can be written as a
system of two first-order ODEs by introducing the auxiliary variable v = duâˆ•dt:
du
dt = v
(2.4a)
dv
dt = f(t, u, v)
(2.4b)
Hence, we get two differential equations of type (2.1) and a unique solution can
be obtained by specifying the initial values for the two ODEs
u(a) = u0
v(a) = v0
(2.5)
In the original formulation (2.2), the ICs (2.5) correspond to u(a) = u0 and uâ€²(a) = v0.
Specifying ICs in this way together with an ODE system (2.4) defines an initial
value problem (IVP) (Figure 2.1).
For a system of ODEs
du1
dt = f1(t, u1, u2, â€¦ , un)
du2
dt = f2(t, u1, u2, â€¦ , un)
.
(2.6)
.
dun
dt = fn(t, u1, u2, â€¦ , un)

PROBLEM CLASSIFICATION
13
0
1
2
3
4
0
1
2
3
4
Boundary value problem
x
u
a, Î±
b, Î²
0
1
2
3
4
0
1
2
3
4
Initial value problem
x
u
a, u0
Slope v0
Figure 2.1
A BVP compared to an IVP
it is convenient to use column vector formulation
du
dt = f(t, u)
(2.7)
where the dependent variables and the right hand sides are collected in the vectors u
and f
u = (u1, u2, â€¦ , un)T,
f = (f1, f2, â€¦ , fn)T
Observe that there are as many dependent variables as differential equations.
The general solution u = u(t, C), where C is an arbitrary constant vector in Rn, is
a family of solution curves in [t0, tend] Ã— Rn, where [t0, tend] is the time interval where
we want the solution. If C is determined, e.g., by the IC u(t0) = u0, we get a unique
solution, a particular solution. Numerical methods are for most problems necessary
to produce graphs or tables of solutions.
The standard general formulation of an IVP is
du
dt = f(t, u),
u(t0) = u0,
t âˆˆ[t0, tend]
(2.8)
and a fairly general formulation for a BVP is
du
dt = f(t, u),
g1(u(a)) = 0,
g2(u(b)) = 0,
t âˆˆ[a, b]
(2.9)
where g1 and g2 together make up n BC equations.
A scalar ODE of order n
dnu
dtn = f
(
t, u, du
dt , d2u
dt2 , â€¦ , dnâˆ’1u
dtnâˆ’1
)
(2.10)

14
ORDINARY DIFFERENTIAL EQUATIONS
can be written as a system of ODEs by introducing auxiliary variables u1 = u, u2 =
duâˆ•dt, u3 = d2uâˆ•dt2, â€¦ , un = dnâˆ’1uâˆ•dtnâˆ’1:
du1
dt = u2
du2
dt = u3
.
(2.11)
.
dun
dt = f(t, u1, u2, â€¦ , un)
A particular solution is obtained either by specifying an initial vector u0 or by speci-
fying n BCs for u. We will not present the general case here but give different ways
of specifying BCs together with problems from applications in Chapters 3 and 4.
For the IVP (2.8) to have a unique solution, there is a condition on the right hand
side f(t, u) of the ODE to be differentiable with respect to t and u. This means that fi
is differentiable with respect to t and uj (i, j = 1, 2, â€¦ , n) for all t âˆˆ[t0, tend] and for
all points u in a certain domain that contains u0 as an interior point. This condition
is a little stronger than Lipschitz continuity (see a mathematical textbook on ODEs).
For a BVP, the question of a uniquesolution is morecomplicated.However,unicity
for BVPs is not a big issue as many such problems occurring in applications can have
several solutions which all make sense (see Example 2.3 in Section 2.5).
Exercise 2.1.1. Given the linear differential equation Ì‡u = âˆ’tu.
a) Find the general solution of the ODE. Observe that the arbitrary constant C
enters linearly in the solution.
b) Find the particular solution satisfying the IC u(0) = 1.
Exercise 2.1.2. Given the nonlinear differential equation Ì‡u = âˆ’u2.
a) Give the general solution of the ODE. Observe that the arbitrary constant C
enters nonlinearly in the solution.
b) Find the particular solution satisfying u(0) = 1.
c) Find the particular solution satisfying u(0) = 0.
Exercise 2.1.3. Given the linear second-order ODE uâ€²â€² + 2uâ€² âˆ’3u = 0
a) Find the general solution of the ODE. Observe that the arbitrary constants enter
linearly.
b) Find the particular solution satisfying the following IC u(0) = 1, uâ€²(0) = âˆ’1.

PROBLEM CLASSIFICATION
15
c) Find the particular solution satisfying the following BC u(0) = 0, u(1) = 1.
d) Find the particular solution satisfying the following BC u(0) = 1, u(âˆ) = 0.
Exercise 2.1.4. A particle is thrown vertically upwards. During its motion, it is
influenced by two forces: gravity and air resistance. The following second- order
ODE models the motion along the y-axis:
mÌˆy = âˆ’mg âˆ’c Ì‡y| Ì‡y|,
y(0) = y0,
Ì‡y(0) = v0
Rewrite this problem as a system of two ODEs.
Exercise 2.1.5. The following system of two second-orderODEs models the vibra-
tions of a mechanical system with two degrees of freedom.
(m1
0
0
m2
)
d2x
dt2 +
(dğœˆ1 + dğœˆ2
âˆ’dğœˆ2
âˆ’dğœˆ2
dğœˆ2
)
dx
dt +
(ğœ…1 + ğœ…2
âˆ’ğœ…2
âˆ’ğœ…2
ğœ…2
)
x =
(
0
Ì‚F2 sin(ğœ”t)
)
At the initial point t = 0, the ICs are
x(0) = 0,
dx
dt (0) = 0
Formulate these differential equations as a system of first-order ODEs on vector
form.
Exercise 2.1.6. The following BVP models the concentration of a chemical sub-
stance in a long cylindrical catalyst pellet
1
r
d
dr
(
rdc
dr
)
= kc2,
dc
dr (0) = 0,
c(R) = c0
The parameters k, R, and c0 are positive parameters. The point r = 0 is a singular
point as the left hand side term is not defined there. Use lâ€™HÃ´pitalâ€™s rule to find the
form of the ODE at that point.
Exercise 2.1.7. The following mixture of an ODE system and a system of algebraic
equations is called a DAE system (Differential Algebraic Equations)
dx
dt = f(x, y),
x(0) = x0
0 = g(x, y)
Assume that x, f âˆˆRn1 and y, g âˆˆRn2, where n1 + n2 = n, the number of unknowns
of the system.

16
ORDINARY DIFFERENTIAL EQUATIONS
Formulate this DAE system as an ODE system with corresponding initial values.
Hint: Differentiate the algebraic system with respect to t. Assume that the matrix
ğœ•gâˆ•ğœ•y is nonsingular. This DAE system is called an index-1 system, as a standard
IVP can be obtained by differentiating part of the system only once.
2.2
LINEAR SYSTEMS OF ODES WITH CONSTANT COEFFICIENTS
There is one type of ODE system that can be treated by analytical tools namely linear
systems with constant coefficients. This problem class is very important in engineer-
ing and scientific applications, such as mechanical vibrations, electric circuits, and
first-order chemical kinetics. Linear ODE systems with constant coefficients (LCC
systems) take the following form:
du
dt = Au + g(t),
u(0) = u0
(2.12)
where A is a constant n Ã— n matrix and g(t) is a vector of n functions of t called the
driving function.
If g(t) â‰¡0, the system is homogeneous, i.e.,
du
dt = Au,
u(0) = u0
(2.13)
Otherwise, it is inhomogeneous.
In the homogeneous case, n = 1, i.e., the scalar equation
du
dt = au,
u(0) = u0
we know that the solution is (see Section 1.2)
u(t) = eatu0
where u0 is the initial value. A generalization of this algebraic solution form to a
system leads us to the following solution formula for (2.13):
u(t) = eAtu0
(2.14)
However, what is eAt, e raised to the power of the matrix At?
Letâ€™s assume that a solution to (2.13) can be written
u(t) = ceğœ†t
(2.15)
where c and ğœ†are to be determined. Inserting this expression into (2.13) gives the
following relation to be fulfilled for all t:
cğœ†eğœ†t = Aceğœ†t

LINEAR SYSTEMS OF ODES WITH CONSTANT COEFFICIENTS
17
This leads to the eigenvalue problem:
Ac = ğœ†c
or
(A âˆ’ğœ†I)c = 0
(2.16)
We are interested in solutions where c â‰ 0 (c = 0 gives us the trivial solution u = 0).
This is possible only if
det(A âˆ’ğœ†I) = 0
(2.17)
This equation is called the characteristic equation and its roots are known as the
eigenvalues of the matrix A. If A is an n Ã— n matrix, (2.17) is a polynomial equation
of degree n, and consequently has n roots ğœ†1, ğœ†2, .... ğœ†n. The roots can be real or
complex, single or multiple.
When an eigenvalue ğœ†i is known, we compute the corresponding eigenvector ci by
solving the homogeneous linear equation system
(A âˆ’ğœ†iI)ci = 0
(2.18)
The solution ci is not unique; ci is determined only up to a scalar factor. In addition,
ci can be complex even if A is real. If A is real and symmetric, however, both ğœ†i and
ci are real.
From now on, we assume that the n eigenvectors of the matrix A are linearly inde-
pendent. Such a matrix is called a diagonalizable or nondefective matrix. (If A has
fewer than n linearly independent eigenvectors, it is called defective). For a nonde-
fective matrix, the relation (2.18) can be written in the form
Aci = ğœ†ici â†’AS = SÎ› â†’A = SÎ›Sâˆ’1
or
Sâˆ’1AS = Î›
where S is a matrix composed of the eigenvectors as columns and Î› is a diagonal
matrix of the eigenvalues:
S = (c1, c2, â€¦ , cn),
Î› = diag(ğœ†1, ğœ†2, â€¦ , ğœ†n)
Going back to (2.15), we now have n solutions to (2.13)
ui(t) = cieğœ†it, i = 1, 2, â€¦ , n
(2.19)
As (2.13) is a linear homogeneous problem, the solutions (2.19) can be superposed,
i.e., linearly combined to a general solution:
u(t) =
n
âˆ‘
i=1
ğ›¼icieğœ†it
(2.20)
where ğ›¼i are arbitrary constants. Formula (2.20) can also be written in matrix form:
u(t) = SeÎ›tğ›¼
(2.21)

18
ORDINARY DIFFERENTIAL EQUATIONS
eÎ›t is a diagonal matrix with eğœ†it as diagonal elements:
eÎ›t = diag(eğœ†1t, eğœ†2t, â€¦ , eğœ†nt)
and ğ›¼is an arbitrary column vector with components ğ›¼1, ğ›¼2, ... ğ›¼n. When the initial
vector u(0) = u0 is known, we get by inserting t = 0 into (2.21):
u(0) = Sğ›¼= u0
â†’
ğ›¼= Sâˆ’1u0
and (2.21) can be written
u(t) = SeÎ›tSâˆ’1u0
(2.22)
Hence, comparing with (2.14), we define eAt, the exponential matrix, as
eAt = SeÎ›tSâˆ’1
(2.23)
The expression (2.23) can be used only if S has an inverse (S is nonsingular). It can be
shown that if all eigenvaluesof A are single (all ğœ†i are different)then A is nondefective.
This is true also when A is symmetric.
However, there exist matrices that are defective. In that case, the formula (2.22)
does not make sense as S has no inverse, but we can always use the Taylor series
expansion as definition of eAt:
eAt = I + At + t2
2!A2 + t3
3!A3 + Â· Â· Â· + tn
n!An + â€¦
(2.24)
It can be shown that if S has an inverse, the two definitions (2.23) and (2.24) are
equivalent.
If the ODE system is LCC and inhomogeneous, i.e., the right hand side contains
a driving function g(t) as in equation (2.12)
du
dt = Au + g(t),
u(0) = u0
we obtain the analytic solution in the form of an integral, the Duhamel formula:
u(t) = eAtu0 + âˆ«
t
0
eA(tâˆ’ğœ)g(ğœ)dğœ
(2.25)
In case the driving vector function g(t) is a constant vector g, the integral can be
solved and the solution of the ODE system is (if A has an inverse)
u(t) = eAtu0 + Aâˆ’1(eAt âˆ’I)g
(2.26)

SOME STABILITY CONCEPTS FOR ODEs
19
Exercise 2.2.1. Compute the eigenvalues and eigenvectors of the matrix
A =
(âˆ’2
1
âˆ’4
3
)
Exercise 2.2.2. Compute eAt for the matrix given in Exercise 2.1.1.
Exercise 2.2.3. Solve the differential equation Ì‡u = Au,
u0 = (1, 1)T, where A is
the matrix in Exercise 2.2.1, using the result obtained in Exercise 2.2.2.
Exercise 2.2.4. Compute eigenvalues and eigenvectors of the matrix
A =
(
0
1
âˆ’5
2
)
Exercise 2.2.5. Solve the differential equation Ì‡u = Au,
u0 = (1, 1)T, where A is
the matrix in Exercise 2.2.4.
Exercise 2.2.6. Verify that the matrices
A =
â›
âœ
âœâ
âˆ’1
0
0
1
âˆ’1
0
0
1
âˆ’1
â
âŸ
âŸâ 
,
B =
â›
âœ
âœâ
0
1
1
0
0
1
0
0
0
â
âŸ
âŸâ 
are defective. Verify also that B is nilpotent, i.e., Bk = 0, k = 3, 4, ....
Exercise 2.2.7. Compute eAt and eBt for the matrices given in Exercise 2.2.6.
Exercise 2.2.8. Verify the solution formula (2.25) for the inhomogeneous LCC
problem (2.12).
Exercise 2.2.9. Modify the formulas (2.14) and (2.25) to the case where the initial
value is u(t0) = u0, i.e., u is known in the initial point t = t0.
Exercise 2.2.10. In what sense is the system (2.13) and its solutions linear?
2.3
SOME STABILITY CONCEPTS FOR ODEs
The goal of stability analysis is to investigate if small perturbations in a system
will cause large changes in the behavior of the system, in which case the system

20
ORDINARY DIFFERENTIAL EQUATIONS
is unstable. In this chapter, we present two definitions of stability for ODE systems.
The first definition refers to what is meant by a stable solution trajectory and the sec-
ond concerns the stability of the special solutions called critical points (also called
equilibrium points). In this textbook, let us call these two stability concepts analytical
stability.
Another stability concept deals with the stability of numerical solutions. It
is important to distinguish between analytical stability and numerical stability.
Numerical stability is introduced in Chapter 3.
2.3.1
Stability for a Solution Trajectory of an ODE System
As already mentioned, analytic solution of a nonlinear ODE system (2.7) is not pos-
sible in general. However, for small perturbations, the stability analysis can be based
on a linear approximation leading to an LCC system. First we need a definition
of stability. In the definition below we restrict ourselves to autonomous systems,
i.e., ODE systems of the form
du
dt = f(u)
(2.27)
Definition 1: A solution u(t) of (2.27) is stable if every solution that starts suffi-
ciently close to u(t) at t = t0 remains close to u(t) for all t > t0. The solution u(t) is
unstable if there exists at least one solution starting close to u(t) at t = t0, which does
not remain close to u(t) for all t > t0. â™¢
The stability question can be completely answered for LCC systems
du
dt = Au
(2.28)
Consider first the scalar ODE
du
dt = ğœ†u
(2.29)
Assume that u(t) is a solution of (2.29). At the point (t0, u0) on the solution trajectory,
a small perturbation ğ›¿u0 takes us to a new solution trajectory u(t) + ğ›¿u(t) starting at
(t0, u0 + ğ›¿u0). This trajectory is followed for t > t0. As the perturbed solution satisfies
the ODE
d(u + ğ›¿u)
dt
= ğœ†(u + ğ›¿u)
(2.30)
(2.30) is reduced to an ODE for the perturbation only (t0 = 0):
dğ›¿u
dt = ğœ†ğ›¿u,
ğ›¿u(t0) = ğ›¿u0
(2.31)

SOME STABILITY CONCEPTS FOR ODEs
21
As the constant ğœ†can be complex, i.e., ğœ†= ğœ‡+ iğœ”, where i =
âˆš
âˆ’1, the solution of
the scalar ODE (2.31) can be written as (assume that t0 = 0).
ğ›¿u(t) = eğœ†tğ›¿u0 = eğœ‡teiğœ”tğ›¿u0 = eğœ‡t(cos(ğœ”t) + i sin(ğœ”t))ğ›¿u0
(2.32)
The only part in the expression (2.32) that can increase infinitely as t increases is eğœ‡t.
Hence, we see that the solution is stable iff ğœ‡= Re(ğœ†) â‰¤0. To be more specific, if
Re(ğœ†) < 0, the perturbation ğ›¿u(t) â†’0 as t â†’âˆ. This is called asymptotic stability.
If Re(ğœ†) = 0, the perturbation ğ›¿u(t) will stay close to u(t) as t â†’âˆbut ğ›¿u(t) will not
vanish, see Figure 2.2 where a perturbation is introduced at the point marked o.
A similar analysis of (2.28) gives the following LCC system for the perturbation
ğ›¿u, (t0 = 0)
dğ›¿u
dt = Ağ›¿u,
ğ›¿u(t0) = ğ›¿u0
(2.33)
From the explicit solution formula (2.20), where t0 = 0, it is clear that stability
depends on the eigenvalues ğœ†i, i = 1, 2, â€¦ , n of the matrix A. Hence, the LCC
system (2.33) is asymptotically stable if Re(ğœ†i) < 0 for i = 1, 2, â€¦ n.
If Re(ğœ†i) = 0, the system is stable if ğœ†i is simple. If Re(ğœ†i) = 0 and ğœ†i is a multi-
ple eigenvalue, the stability problem is more intricate. The solution can be stable or
unstable and each case must be investigated separately. We will not treat this case
here (see Exercise 2.3.7 for an example).
If we plot the eigenvalues of A in the complex plane, asymptotic stability means
that the eigenvalues are situated in the left half of the complex plane.
Example 2.1.
The eigenvalues of the matrices
A =
â›
âœ
âœâ
âˆ’1
0
0
3
1
âˆ’2
2
2
âˆ’2
â
âŸ
âŸâ 
B =
â›
âœ
âœâ
âˆ’1
0
0
3
1
âˆ’2
2
2
1
â
âŸ
âŸâ 
have the following location in the complex plane (Figure 2.3).
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
du/dt = Î» u, Î» < 0
u
0
5
10
15
20
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
du/dt = Î» u, Re(Î») = 0
Im(u)
Figure 2.2
Asymptotic stability and stability

22
ORDINARY DIFFERENTIAL EQUATIONS
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
Eigenvalues of the matrix A
Stable system
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
âˆ’2
âˆ’1
0
1
2
Eigenvalues of the matrix B
Unstable system
Figure 2.3
Eigenvalues in the complex plane
For the nonlinear autonomous system (2.27), the stability of a solution can be
examined if the system is approximated by an LCC system. Assume that u(t) is a
solution of (2.27). At time t = t0, where u = u(t0), a small perturbation ğ›¿u0 brings us
to a new solution trajectory, u(t) + ğ›¿u(t), which is followed for t > t0. The perturbed
solution satisfies the ODE system
d(u + ğ›¿u)
dt
= f(u + ğ›¿u)
(2.34)
Taylor expansion of the right hand side up to the first-order term gives
du
dt + dğ›¿u
dt
= f(u) + ğœ•f
ğœ•uğ›¿u + O(âˆ¥ğ›¿uâˆ¥2)
(2.35)
In (2.35), the jacobian is introduced
J(u) = ğœ•f
ğœ•u =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
ğœ•f1
ğœ•u1
ğœ•f1
ğœ•u2
â€¦
ğœ•f1
ğœ•un
ğœ•f2
ğœ•u1
ğœ•f2
ğœ•u2
â€¦
ğœ•f2
ğœ•un
..
..
â€¦
..
..
..
â€¦
..
ğœ•fn
ğœ•u1
ğœ•fn
ğœ•u2
â€¦
ğœ•fn
ğœ•un
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
(2.36)
As u is a solution of (2.27) we obtain, after neglecting the higher order term, the
(linearized) variational equation
dğ›¿u
dt
= J(u)ğ›¿u,
ğ›¿u(t0) = ğ›¿u0
(2.37)

SOME STABILITY CONCEPTS FOR ODEs
23
If the jacobian is frozen at t = t0 to a constant matrix J0, i.e.,
J0 = ğœ•f
ğœ•u(u(t0))
(2.38)
we can use the stability results for LCC systems above to answer questions about
the stability of solution trajectories in a close neighborhood of a given solution
trajectory.
2.3.2
Stability for Critical Points of ODE Systems
For an autonomousnonlinearODE system (2.27),it is of special interest to investigate
the stability of critical points, i.e., points satisfying the algebraic equation
f(u) = 0
(2.39)
Critical points are also called the stationary or steady-state solutions, as such solutions
do not change with time t.
Let uâˆ—be a critical point of (2.39). We want to investigate if this point is stable.
The stability concept has to be modified a little for a critical point, as it is a constant
vector.
Definition 2: Assume the critical point uâˆ—is perturbed to a solution uâˆ—+ ğ›¿u(t) in
the neighborhood of uâˆ—. If all perturbed solutions converge to the critical point uâˆ—,
this point is said to be asymptotically stable. If at least one perturbed solution diverges
away from the critical point, it is unstable (Figure 2.4). â™¢
If the perturbation ğ›¿u is small, we can approximate f(u) close to the point uâˆ—using
Taylor expansion up to the first-order term:
f(uâˆ—+ ğ›¿u) = f(uâˆ—) + J(uâˆ—)ğ›¿u + O(âˆ¥ğ›¿uâˆ¥2)
(2.40)
âˆ’1
â€“0.5
0
0.5
1
âˆ’1
âˆ’0.5
0
0.5
1
Stable critical point
âˆ’1
âˆ’0.5
0
0.5
1
âˆ’1
âˆ’0.5
0
0.5
1
>
<
<
Unstable critical point
<
<
>
Figure 2.4
Stability of critical points

24
ORDINARY DIFFERENTIAL EQUATIONS
The perturbed solution satisfies the differential equation, i.e.,
duâˆ—
dt + dğ›¿u
dt
= f(uâˆ—) + J(uâˆ—)ğ›¿u
(2.41)
where we have neglected the higher order terms in (2.40). As uâˆ—is a constant and
f(uâˆ—) = 0, we get an ODE system, the variational equation, for the perturbation term
ğ›¿u:
dğ›¿u
dt
= J(uâˆ—)ğ›¿u
(2.42)
This is an LCC system of type (2.28). The perturbed solution will converge to the
critical point uâˆ—if the eigenvalues of J(uâˆ—) are situated in the left half plane of the
complex plane, so the behavior of solutions close to a critical point can be described
in the same way as the solutions of an LCC problem.
Hence, to investigate the stability of a critical point, proceed as follows:
1. Compute a critical point uâˆ—by solving f(u) = 0 with algebraic tools or with
Newtonâ€™s method (see Appendix A.1).
2. Form the jacobian J(u) and compute Jâˆ—= J(uâˆ—).
3. Compute the eigenvalues ğœ†i of Jâˆ—and check if Re(ğœ†i) < 0.
Example 2.2.
A famous ODE system called the Lotkaâ€“Volterra differential
equations or the predatorâ€“prey model is
dx
dt = ax âˆ’bxy
dy
dt = âˆ’cy + dxy
where a, b, c, and d are positive parameters.
The critical points of this system are (0, 0) and (câˆ•d, aâˆ•b). The jacobian of the
system is
J =
(a âˆ’by
âˆ’bx
dy
âˆ’c + dx
)
and the values of the jacobian at the critical points are
J(0, 0) =
(
a
0
0
âˆ’c
)
,
J(câˆ•d, aâˆ•b) =
(
0
âˆ’bcâˆ•d
daâˆ•b
0
)
The eigenvalues of J(0, 0)are a and âˆ’c, i.e., one eigenvaluesis positive and the critical
point (0, 0) is unstable.
The eigenvalues of J(câˆ•d, aâˆ•b) are Â±i
âˆš
ac. They have a zero real part but are
simple, which implies that the linearized system at the critical point (câˆ•d, aâˆ•b) is
stable.

SOME STABILITY CONCEPTS FOR ODEs
25
Exercise 2.3.1. Given the following ODE system
Ì‡u = Au,
A =
(
âˆ’2
1
âˆ’4
3
)
Find the critical points and characterize the stability properties of the critical
points.
Exercise 2.3.2. What is the critical point xcr of the ODE system (A is
nonsingular)?
Ì‡x = Ax âˆ’b
Introduce the variable y = x âˆ’xcr. Derive the ODE for y. This shows that stability
does not depend on b.
Exercise 2.3.3. Find the critical points and the solution of the ODE system
dw
dt = kt
(âˆ’1
1
1
âˆ’1
)
w + ki
(1
0
)
,
w(0) =
(0
0
)
The parameters kt and ki are both positive. What about the stability of the critical
points?
Exercise 2.3.4. Given the following ODE
du
dt = 1 âˆ’u2
a) Find the critical points of the ODE.
b) Decide for each critical point if it is stable or not.
Exercise 2.3.5. Given the second-order ODE, known as it van der Polâ€™s equation
d2x
dt2 + ğœ–(x2 âˆ’1)dx
dt + x = 0
where the parameter ğœ–> 0.
a) Find the critical point of the ODE system.
b) Is the critical point stable or unstable? Hint: Rewrite as a system of first
order.

26
ORDINARY DIFFERENTIAL EQUATIONS
Exercise 2.3.6. Consider the homogenous vibration equation (see Section 1.3)
md2y
dt2 + dğœˆ
dy
dt + ky = 0
The parameters m, dğœˆand k are positive.
a) Find the critical point.
b) Sketch how the eigenvalues at the critical point â€˜moveâ€™ in the complex plane
as the parameter k changes in the interval (0, âˆ). Is the critical point always
stable?
Exercise 2.3.7. Given the ODE system Ì‡u = Au,
A =
(
0
1
0
0
)
.
Show, by solving the system, that the critical points are unstable!
Hence, when two eigenvalues = 0 (0 is a double root), the solution can be
unstable.
2.4
SOME ODE MODELS IN SCIENCE AND ENGINEERING
Mathematical models based on ODE systems occur frequently in science and engi-
neering. The independent variable usually denotes time t or space x.
A time-dependent ODE system is often referred to as a dynamic system. As such
a model does not take into account any space variations of the dependent variables, it
is sometimes called a lumped model. A space-dependent ODE system involves only
one space variable but does not take time into account. Such models often occur by
simplifying a stationary PDE model in several space variables into a one-dimensional
(1D) space- dependent problem.
In mathematical models of processes in science and engineering, it is important to
define the units of the variables and parameters, e.g., density ğœŒ(kg/m3), flow Q (m3/s),
and gravitational acceleration g (m/s2). In this textbook, SI units will be used in most
presentations of Laws of Nature, examples, and exercises.
2.4.1
Newtonâ€™s Second Law
A system of moving particles with masses m1, m2, ... ,mn (kg) move according to:
miÌˆri = Fi(t, r1, r2, â€¦ , rn, Ì‡r1, Ì‡r2, â€¦ , Ì‡rn),
i = 1, 2, â€¦ , n
(2.43)
Here ri = (xi, yi, zi)T (m) denotes the position of particle i, Ì‡ri (m/s) its velocity, and
Ìˆri its acceleration ( mâˆ•s2). Fi (N) is the total force acting on particle i. The system
(2.43) consists of 3n second-order ODEs.
This equation was formulated by the English mathematician and scientist Isaac
Newton in his work Principia (Mathematical Principles of Science) from 1687.

SOME ODE MODELS IN SCIENCE AND ENGINEERING
27
Engineering applications of (2.43) occur in, e.g., mechanical vibrations. One
important model consists of a system of masses connected by dampers and springs:
MÌˆx + DğœˆÌ‡x + Kx = F(t)
(2.44)
Here M denotes the mass matrix, Dğœˆthe damping matrix, and K the spring or stiffness
matrix. x is a vector of displacements of the masses along the x direction. F is a vector
of external forces often of the form F(t) = Ì‚Fsin(ğœ”t), where ğœ”is the angular velocity,
see Exercise 2.1.5 for an example. Observe that the ODE system (2.44) is an LCC
system.
2.4.2
Hamiltonâ€™s Equations
A conservative mechanical system is defined as a system where the total energy is
conserved. In such a system, the motions can, as an alternative to Newtonâ€™s equations,
be described by a scalar hamiltonian function H invented by the Irish mathematician
W.R.Hamilton in 1835.
H is the sum of the kinetic energy T (J) and the potential energy U (J) of the
system. For a system of n particles in 3D, the hamiltonian has the form:
H = T + U = H(q1, q2, â€¦ , qn, p1, p2, â€¦ pn),
(2.45)
where the qi denote the generalized coordinates and pi are the generalized momenta.
Hamiltonâ€™s equations of motion take the form
dqi
dt = ğœ•H
ğœ•pi
,
dpi
dt = âˆ’ğœ•H
ğœ•qi
,
i = 1, 2, â€¦ , n
(2.46)
The ODE system (2.45) consists of 6n first-order ODEs.
2.4.3
Electrical Networks
An electrical network consists of passive elements such as resistors, capacitors and
inductors and active elements such as voltage and current sources. The model of a
network is obtained using Kichhoffâ€™s laws and currentâ€“voltage relations owing to
Ohmâ€™s law for all elements. If all elements are assumed to have constant impedance
values, a linear DAE system of the following form can be set up, with an algorithm
called modified nodal analysis (2.47):
â›
âœ
âœ
âœâ
ACCAT
C
0
0
0
L
0
0
0
0
â
âŸ
âŸ
âŸâ 
d
dt
â›
âœ
âœ
âœâ
e
iL
iV
â
âŸ
âŸ
âŸâ 
+
â›
âœ
âœ
âœâ
ARGAT
R
AL
AV
âˆ’AT
L
0
0
AT
V
0
0
â
âŸ
âŸ
âŸâ 
â›
âœ
âœ
âœâ
e
iL
iV
â
âŸ
âŸ
âŸâ 
=
â›
âœ
âœ
âœâ
âˆ’AII
ğŸ
E
â
âŸ
âŸ
âŸâ 
(2.47)
where C (F), L (H), and G (Î©âˆ’1) are diagonal matrices with the capacitances,
inductances, and conductances (inverses of resistances). AC, AR, AL, AV, and AI are

28
ORDINARY DIFFERENTIAL EQUATIONS
(reduced) incidence matrices, i.e., sparse matrices (see Appendix A.4) consisting of
the integers âˆ’1, 0, 1. The vector I (A) consists of the current source values and E (V)
the voltage source values.
The DAE system (2.47) consists of differentialequations for e (V) (the node poten-
tials) and iL (A) (vector of branch currents through the inductors) and additional
algebraic equations for iV (A) (vector of branch currents through voltage sources).
Linear DAE systems in general have the following form (special case of the DAE
system formulated in Exercise 2.1.7):
A Ì‡u = Bu + b(t)
(2.48)
where A and B are n Ã— n matrices. If A is singular, the system has â€œindexâ€ â‰¥1: at
least one differentiation is required to produce an ODE system.
2.4.4
Chemical Kinetics
Consider a mixture of N chemical substances A1, A2, â€¦ , AN reacting with each other
in M reactions, where the substance concentrations change with time
N
âˆ‘
j=1
ğ›¼ijAj â†’
N
âˆ‘
j=1
ğ›½ijAj,
i = 1, 2, â€¦ , M
where ğ›¼ij and ğ›½ij are integer numbers called the stoichiometric coefficients. The
time-dependent substance concentrations c1, c2, â€¦ , cN (molâˆ•m3) of A1, A2, â€¦ , AN
are obtained from the ODE system
dc
dt = Sr(c)
(2.49)
In (2.49), S is the stoichiometric matrix of integers, a sparse N Ã— M matrix, and
r(c) [ molâˆ•( m3 â‹…s)] an M Ã— 1 vector of reaction rates. In a model by the Norwe-
gian chemists Guldberg and Waage from 1879 called the mass action law, ri has the
form
ri = ki
N
âˆ
j=1
c
ğ›¼ij
j ,
i = 1, 2, â€¦ , M
(2.50)
where ki (the unit depends on N and ğ›¼ij is called the rate constant, which is tempera-
ture dependent according to Arrheniusâ€™ equation k = Aeâˆ’Eâˆ•RT, where A is called pre-
exponential factor, E (J/mol) is the activation energy, R = 8.314472 [ Jâˆ•( K â‹…mol)]
the gas constant, and T (K) the temperature. Svante Arrhenius was a Swedish chemist
and Nobel laureate active about 100 years ago. The ODE system (2.49) is generally
nonlinear. With slight modifications, it can be used to model reactors of great impor-
tance in applications.

SOME ODE MODELS IN SCIENCE AND ENGINEERING
29
2.4.5
Control Theory
A common model used in control theory is the state space model
dx
dt = Ax + Bu
(2.51a)
y = Cx + Du
(2.51b)
where x are internal state variables of the system studied, u are control variables, and
y are observed variables. A, B, C, and D are constant matrices. Of special interest
is the study of stability properties of control systems. Another important problem in
control theory is the identification problem, i.e., from measurements of the observed
variables determine some of the parameters of the system.
In control theory, the models are often described by block diagrams, which can be
translated into ODE systems of type (2.51).
Models in control theory can also be nonlinear ODE systems of type
dx
dt = f(x, u, p)
(2.52a)
y = g(x, u, p)
(2.52b)
where p is a parameter vector.
2.4.6
Compartment Models
Compartment models are frequently used in applications where simplified models of
flows of gases or fluids are studied. Examples are found in biomedicine, pharmacoki-
netics, and air pollution. The model consists of a system of first-order ODEs, describ-
ing the exchange of substances between the compartments of the model. Assume the
model has n compartments, which can be regarded as â€œboxesâ€. If xi is the amount
of some substance in compartment i, the model is formulated as an IVP, based on
the balance principle for the amounts of the substances called the continuity equation
(see Chapter 9):
dxi
dt = QI
i +
n
âˆ‘
j=1
QI
ij âˆ’
n
âˆ‘
j=1
QO
ij âˆ’QO
i ,
xi(0) = xi0
(2.53)
where the inflow consists of QI
i, which is the flow from the environment to compart-
ment i and QI
ij the flow to compartment i from compartment j. The outflow consists
of QO
i , which is the flow from compartment i to the environment and QO
ij being the
flow from compartment i to compartment j. The initial value xi0 is the initial amount
of the substance in compartment i.
If the flows are modeled as QI
ij = kI
ijxj, QO
ij = kO
ij xi, and QI
i, QO
i are constant or time
dependent, the resulting ODE system will be an LCC system.

30
ORDINARY DIFFERENTIAL EQUATIONS
2.5
SOME EXAMPLES FROM APPLICATIONS
In this part of the chapter, some ODE applications are shown, exemplifying the mod-
els presented in Section 2.4. The examples will be referred to in Chapters 3 and 4,
where numerical methods for IVPs and BVPs are described. To each example, some
exercises are given. They are mainly intended for repetition of analytic treatment of
ODEs and also to demonstrate analytic preprocessing necessary before numerical
treatment of the problems should be performed.
Example 2.3. Particle dynamics
The following differential equation is a model of the motion in the xy-plane of a
particle released with a certain initial velocity from a point and then moving under the
influence of gravity and a force generated by the air resistance, which is proportional
to the square of the velocity (see Exercise 2.1.4 for the corresponding 1D problem).
md2r
dt2 = âˆ’mgey âˆ’câ€–â€–â€–â€–
dr
dt
â€–â€–â€–â€–2
dr
dt ,
r(0) = y0ey,
dr
dt (0) = v0
(2.54)
where m (kg) is the mass of the particle, r (m) is the position of the particle, g (mâˆ•s2)
gravitational acceleration, c (N â‹…s2âˆ•m2) air resistance coefficient, y0 (m) initial
height of the particle, and v0 (m/s) the initial velocity vector, which has an elevation
angle ğ›¼> 0 with the horizontal plane (see Figure 2.5).
The formulation (2.54) of the problem is an IVP. The computational task is to
integrate step by step until the particle hits the ground (y = 0). However, this problem
can also be formulated as a BVP if the task is to determine the elevation angle that
causes the particle to hit a given point x0 on the ground for a given value of the initial
velocity. The ICs are replaced by BCs:
r(0) = y0ey,
r(T) = x0ex
(2.55)
where T (s) is the time when the particle hits the ground in the point (x0, 0).
By adjusting the elevation angle ğ›¼, the BC at x = x0 can be satisfied. It turns
0
2
4
6
8
10
âˆ’1
0
1
2
3
4
5
6
Particle motion as IVP
r (t)
x
y
y0
v0
0
2
4
6
8
10
12
âˆ’2
0
2
4
6
x
y
y0
x0
r (t), Î± = 58.5Â°
r (t), Î± = 20.2Â°
Particle motion as BVP
Figure 2.5
Particle dynamics in 2D

SOME EXAMPLES FROM APPLICATIONS
31
out that this BVP has two solutions, for certain values of the parameters, see
Figure 2.5.
Exercise 2.5.1. Solve analytically the IVP and the BVP in the case c = 0.
Exercise 2.5.2. Rewrite the IVP as an ODE system of first order, i.e., in the
form (2.8).
Example 2.4. Planetary motion
Consider the motion of a single planet about a heavy sun. The assumption heavy sun
means that the sun influences the motion of the planet, but the relatively small mass
of the planet has an influence on the sun that is negligible. Let r(t) = (x(t), y(t))T (m)
denote the coordinates of the planet with the sun in the origin. The only force act-
ing on the planet is the gravitational force from the sun having the magnitude Fr =
ğ›¾Mmâˆ•âˆ¥r âˆ¥2
2 (N), where ğ›¾= 6.6742 â‹…10âˆ’11 ( N â‹…m2âˆ•kg2) is the gravitational con-
stant, M (kg) the mass of the sun, and m the mass of the planet.
Newtonâ€™s equation (2.43) takes the form (for illustration, see Figure 2.6):
md2r
dt2 = âˆ’ğ›¾Mm
âˆ¥r âˆ¥2
2
er
(2.56)
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
2
2.5
3
3.5
âˆ’2
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
2
Figure 2.6
Planetary motion in 2D

32
ORDINARY DIFFERENTIAL EQUATIONS
Exercise 2.5.3. Write Newtonâ€™s equation (2.56) in component form, i.e., one
second-order ODE for x(t) and another for y(t). Also write (2.56) as a system of
first-order ODEs.
Exercise 2.5.4. For planetary motion, the hamiltonian can be written
H(q, p) = T + U = 1
2m(p2
1 + p2
2) âˆ’
ğ›¾Mm
âˆš
q2
1 + q2
2
(2.57)
where q and p are the (generalized) coordinates and momenta
q = r,
p = mdr
dt
a) Show that H, i.e., the total energy (sum of kinetic and potential energy) is con-
served. Also show that the angular momentum L = q Ã— p is conserved. Hint:
Form dHâˆ•dt and dLâˆ•dt.
b) Show that Hamiltonâ€™s equations applied to (2.57) imply Newtonâ€™s equation.
Example 2.5. A simple RLC circuit
Consider the following electrical network (Figure 2.7), consisting of two resistors,
one capacitance, one inductance, one voltage source, and one current source.
R1
R2
L
C
I
E
Figure 2.7
A simple electrical network
The DAE system corresponding to this electrical network is (2.58)
â›
âœ
âœ
âœ
âœâ
C
âˆ’C
0
0
0
âˆ’C
C
0
0
0
0
0
0
0
0
0
0
0
L
0
0
0
0
0
0
â
âŸ
âŸ
âŸ
âŸâ 
d
dt
â›
âœ
âœ
âœ
âœâ
e1
e2
e3
iL
iV
â
âŸ
âŸ
âŸ
âŸâ 
+
â›
âœ
âœ
âœ
âœâ
1âˆ•R1
0
0
0
0
0
1âˆ•R2
0
1
0
0
0
0
âˆ’1
1
0
âˆ’1
1
0
0
0
0
1
0
0
â
âŸ
âŸ
âŸ
âŸâ 
â›
âœ
âœ
âœ
âœâ
e1
e2
e3
iL
iV
â
âŸ
âŸ
âŸ
âŸâ 
=
â›
âœ
âœ
âœ
âœâ
0
âˆ’I
0
0
E
â
âŸ
âŸ
âŸ
âŸâ 
(2.58)
In a linear DAE system, there are linear relations between the dependent variables
and the initial values must be consistent with these relations.

SOME EXAMPLES FROM APPLICATIONS
33
Exercise 2.5.5. Verify that the following linear algebraic relations are valid for a
solution of the DAE system above:
â§
âª
â¨
âªâ©
Râˆ’1
1 e1 + Râˆ’1
2 e2 + iL = âˆ’I
iL = iV
e3 = E
and that the following IC is consistent with these algebraic relations: u0 =
(0, 0, E, âˆ’I, âˆ’I)T
Exercise 2.5.6. Find the steady-state solution of (2.58).
Example 2.6. Biochemical reaction
The following reaction system, consisting of two reversible reactions, occurs fre-
quently in biochemistry
E + S â‡â‡’C â‡â‡’E + P
In the reaction formula, E stands for enzyme, S for substrate, C for complex, and P
for product. The respective concentrations are denoted by c1, c2, c3, and c4. The ODE
system modeling the kinetic behavior of the reaction system is
dc
dt =
â›
âœ
âœ
âœ
âœâ
âˆ’1
1
1
âˆ’1
âˆ’1
1
0
0
1
âˆ’1
âˆ’1
1
0
0
1
âˆ’1
â
âŸ
âŸ
âŸ
âŸâ 
â›
âœ
âœ
âœ
âœâ
k1c1c2
k2c3
k3c3
k4c1c4
â
âŸ
âŸ
âŸ
âŸâ 
,
c0 =
â›
âœ
âœ
âœ
âœâ
E0
S0
0
0
â
âŸ
âŸ
âŸ
âŸâ 
(2.59)
where k1, k2, k3, and k4 are the rate constants of the reactions and E0 > 0 and S0 > 0
are the initial concentrations of E and S.
Exercise 2.5.7. Verify that c1(t) + c3(t) = E0 and c2(t) + c3(t) + c4(t) = S0.
When the reactions have come to chemical equilibrium, the concentrations satisfy
the following nonlinear algebraic system of equations
f(c) =
â›
âœ
âœ
âœ
âœâ
âˆ’1
1
1
âˆ’1
âˆ’1
1
0
0
1
âˆ’1
âˆ’1
1
0
0
1
âˆ’1
â
âŸ
âŸ
âŸ
âŸâ 
â›
âœ
âœ
âœ
âœâ
k1c1c2
k2c3
k3c3
k4c1c4
â
âŸ
âŸ
âŸ
âŸâ 
= 0
(2.60)
One solution of this system is obviously c = (0, 0, 0, 0)T, which, however, cannot
be the equilibrium concentrations as the relations in Exercise 2.5.7 are not fulfilled.
Using Newtonâ€™s method (see Appendix 1) to solve the system of equations (2.60)

34
ORDINARY DIFFERENTIAL EQUATIONS
will not work, as the matrix is singular, which implies that the jacobian will also be
singular.
Exercise 2.5.8. Preprocess the equilibrium problem so that Newtonâ€™s method can
be used.
Example 2.7. Stability of a regulator
Consider a servo mechanism where the output signal y(t) depends on an input signal
u(t). In an application, u(t) can be the torsion angle of the steering wheel of a boat
and y(t) the torsion angle of the boatâ€™s rudder. The purpose of servo is to strengthen
the torsion moment from a small value to a large value.
The following control system models a feedback regulator consisting of an elec-
tromechanical system described with a block diagram (Figure 2.8):
+
G1:
v = k1e
G2:
Ri + L di
dt = v
G3:
M = k2i
G4: J d2y
dt 2 +
dÎ½
dy
dt = M
u
e
v
i
M
y
âˆ’
+
Figure 2.8
Block diagram of a servo mechanism
In mathematical terms, the model is formulated in the following way:
âŠ•âˆ¶e(t) = u(t) âˆ’y(t), the difference (error) between u(t) and y(t)
G1âˆ¶v(t) = k1e(t), amplification of e(t) into a voltage value
G2âˆ¶Ri(t) + L di
dt = v(t), induced current in a motor driving an axis.
G3âˆ¶M(t) = k2i(t), torsion moment of the axis.
G4âˆ¶J d2y
dt2 + dğœˆ
dy
dt = M(t), the moment drives a load (the rudder) having moment
of inertia J and damping coefficient dğœˆ.
Exercise 2.5.9. Write the equations above in state space form (2.51) with x(t) =
(i(t), z(t), y(t))T, where z(t) = dyâˆ•dt, u(t) = (u(t), 0, 0)T, and y(t) = y(t). Hint: Elimi-
nate e(t), v(t), and M(t). Note that the resulting ODE system is of LCC type.
Exercise 2.5.10. Verify that the equations above can also be written as a third-order
ODE (of LCC type):
LJ
R
d3y
dt3 +
(Ldğœˆ
R + J
) d2y
dt2 + dğœˆ
dy
dt + Ky = Ku(t),
K = k1k2
R
(2.61)
The properties of this regulator model can be simulated in a parameter study. Particu-
larly important is the parameter K, which is proportional to the amplification factors
of the model.

SOME EXAMPLES FROM APPLICATIONS
35
To answer the question, if the system is stable for all values of K, it is enough to
study the homogeneous version of (2.61), i.e., the case where u = 0
LJ
R
d3y
dt3 +
(Ldğœˆ
R + J
) d2y
dt2 + dğœˆ
dy
dt + Ky = 0
(2.62)
If the parameter L = 0, (2.62) turns into a second-order ODE of the same type as in
Exercise 2.3.6 and therefore stable for all values of K. However, what happens if the
parameter L â‰ 0?
Exercise 2.5.11. Assume the following values of the parameters: J = 0.4, dğœˆ= 1,
R = 100, L = 10. Write a program that makes a graph (root locus) of the curves gen-
erated by the eigenvalues of (2.62) as K varies in the interval [0, 20]. For which values
of K is the system unstable?
Example 2.8. Drug kinetics
The following two-compartment model is an example from pharmacokinetics.
Assume a drug, which has been taken orally, is present in the intestine during a
certain time interval. The drug is absorbed with the constant flow rate q (mmol/s)
into the first compartment, the blood plasma. In the blood plasma, the concentration
of the drug is c1(t) (mmol/l). The second compartment is the organ where the drug
is active. Between the first and second compartments, there is an drug exchange
with rate k1c1(t) (mmol/l/s) leading to the drug concentration c2(t) in the second
compartment. In the organ, the drug is consumed with the rate kbc2(t) (mmol/s)
and the surplus is sent back to the blood with the rate k2c2(t) (mmol/s). From the
blood, finally, there is an elimination of the drug through the kidneys with the rate
kec1(t) (mmol/s). Figure 2.9 illustrates the bloodâ€“organ compartment model of drug
distribution:
blood
c1(t)
organ
c2(t)
q
k1c1
k2c2
kbc2
kec1
Figure 2.9
A simple compartment model
The ODE system (2.53) takes the following form in this case:
dc1
dt = âˆ’k1c1 + k2c2 âˆ’kec1 + q,
c1(0) = 0
dc2
dt = k1c1 âˆ’k2c2 âˆ’kbc2,
c2(0) = 0

36
ORDINARY DIFFERENTIAL EQUATIONS
The steady-state solution, i.e., the solution obtained when the time derivatives are
zero, is obtained from the algebraic linear system of equations:
(
k1 + ke
âˆ’k2
âˆ’k1
k2 + kb
) (
c1
c2
)
=
(
q
0
)
Exercise 2.5.12. Formulate the analytical solution of the ODE system using
Duhamelâ€™s formula (2.25).
BIBLIOGRAPHY
1. D. Zill and M. Cullen, â€œDifferential Equations with Boundary Value Problemsâ€, 5th edition,
Brooks and Cole, 2005
2. W. Boyce and R. DiPrima, â€œElementary Differential Equations and Boundary Values Prob-
lemsâ€, 8th edition, Wiley, 2005
The following textbook is older but elementary and well-structured
3. M. Braun, â€œDifferential Equations and Their Applicationsâ€, Springer, 1975
An old classical textbook, extensive and theoretical is
4. E. Coddington and N. Levinson,
â€œTheory of Ordinary Differential Equationsâ€,
McGraw-Hill, 1955
References to special application areas of ODEs
Particle dynamics: H.Goldstein et al, â€œClassical Mechanicsâ€, Addison Wesley, 2004
Electrical networks: J.D.Irwin, â€œBasic Engineering Circuit Analysisâ€, Prentice Hall, 2005
Chemical kinetics: P.Erdi, J.Toth, â€œMathematical models of chemical reactionsâ€, Manchester
University Press, 1989
Control theory: L.Ljung, T.Glad, â€œModeling of Dynamical Systems, Prentice Hall, 1994
Compartment models: K.Godfrey, â€œCompartmental Models and Their Applicationâ€, Academic
Press, 1983

3
NUMERICAL METHODS FOR INITIAL
VALUE PROBLEMS
As we have seen in Chapters 1 and 2, ordinary differential equation(ODE) prob-
lems occur in numerous applications and therefore important for modeling processes
whose evolution depends on one variable, usually time t or one spatial variable x.
In this chapter, we treat the initial value problem (IVP).
The general formulation of an IVP is
du
dt = f(t, u),
u(t0) = u0,
t0 < t â‰¤tend
(3.1)
Often the solution depends on parameters, denoted by the vector p, that occur in the
right hand side function:
du
dt = f(t, u, p),
u(t0) = u0,
t0 < t â‰¤tend
(3.2)
The initial values u0 can also be regarded as parameters in case the dependence of
the initial values is studied: u = u(t, p, u0)
Example 3.1. (Newtonâ€™s law for a particle)
In Exercise 2.1.4, the following IVP was introduced
mÌˆy = âˆ’mg âˆ’c Ì‡y| Ì‡y|,
y(0) = y0,
Ì‡y(0) = v0
(3.3)
This ODE models a particle thrown vertically from the position y0 and with initial
velocity v0. The particle is influenced by gravity and an air resistance force being
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

38
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
proportional to the square of the velocity. When the solution is studied as a function
of, e.g., c, we make a parameter study of the problem. The solution of this problem
depends on t and the parameters m, c, g, y0, and v0, i.e., y = y(t, m, c, g, y0, v0).
This example indicates that there are several questions that can be posed concern-
ing the solution of an IVP:
â€¢ How does the solution behave on a time interval [t0, tend] for a given p?
â€¢ How does the solution depend on parameters p in the problem?
â€¢ Which are the critical points and what are the stability properties of the critical
points (stability analysis)?
â€¢ How sensitive is the solution with respect to the parameters (sensitivity
analysis)?
â€¢ When a parameter varies over an interval, does the solution change character
for some value of the parameter in this interval (bifurcation analysis)?
â€¢ When measurements (tk, uâˆ—
k), k = 1, 2, â€¦ , M, of the process are given from
experiments, how do we estimate unknown parameters in the model (parameter
estimation)?
To be able to answer the questions, it is necessary to have an accurate, efficient, and
robust numerical solver for the IVP (3.1).
3.1
GRAPHICAL REPRESENTATION OF SOLUTIONS
To get a better understanding of the behavior of solutions to ODE problems, it is
necessary to visualize the solutions graphically. This can be done in different ways:
â€¢ plot trajectories, i.e., u(t) is plotted as function of t in a coordinate system. A
trajectory is appropriate when we want to study the time evolution of a process.
Depending on the size of variables, it should be judged what scales should be
used for the different coordinate axis, linear or logarithmic.
â€¢ plot phase portraits showing two componentsof the solution, ui(t) and uj(t) with
t as a parameter along the curve (ui(t), uj(t)) plotted in a coordinate system. A
phase portrait is appropriate when one wants to study how solutions behave as
function of initial values, especially in the neighborhood of critical points. In
3D graphics, a phase portrait with three components can be plotted.
There are other types of graphical representation, e.g., the root locus plot, often
used in control theory to visualize the stability properties of an ODE system, see
Example 2.7.

GRAPHICAL REPRESENTATION OF SOLUTIONS
39
10âˆ’3
10âˆ’2
10âˆ’1
100
101
102
103
104
105
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
S, E, C, P
t
The ESCEPâ€“problem
S
E
P
C
Figure 3.1
Example of solution trajectories
Example 3.2. (The kinetics of a biochemical reaction system).
The following reactions and the corresponding ODE system was introduced in
Example 2.6:
E + S â‡â‡’C â‡â‡’E + P
The kinetics of the reaction system is modeled by the ODE system (2.59). In
this example, the following values of the parameters are given: k1 = 10, k2 = 0.1,
k3 = 1, k4 = 10. With the initial values E0 = 0.1, S0 = 1, C0 = 0, and P0 = 0 we
get the following trajectories. Note that it is appropriate for this problem to use
logarithmic scale on the t-axis (Figure 3.1).
Example 3.3. (A problem with an oscillating solution: Van der Polâ€™s equation).
Van der Polâ€™s equation (see Exercise 2.3.5) occurs, e.g., in modeling of nonlinear
electrical circuits:
d2y
dt2 + ğœ–(y2 âˆ’1)dy
dt + y = 0,
y(0) = 1,
dy
dt (0) = 0
(3.4)
The numerical solution of this ODE problem is described in Section 3.3. The results
are preferably visualized as a phase portrait. If the parameter ğœ–is given the val-
ues ğœ–= 0.1, 1, 10, 100, the following phase portraits are drawn in a parameter study

40
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
â€“2
â€“1
0
1
2
â€“1.5
â€“1
â€“0.5
0
0.5
1
1.5
y
dy/dt
â€“3
â€“2
â€“1
1
0
2
â€“3
â€“2
â€“1
0
1
2
3
y
dy/dt
van der Pol, eps = 0.1
van der Pol, eps = 1
â€“4
â€“2
0
2
4
â€“15
â€“10
â€“5
0
5
10
15
y
dy/dt
â€“4
â€“2
2
0
4
â€“150
â€“100
â€“50
0
50
100
150
y
dy/dt
van der Pol, eps = 10
van der Pol, eps = 100
Figure 3.2
Example of phase portraits
(Figure 3.2). Obviously the solutions are oscillating. After an initial transient, the
phase portrait approaches a closed curve, a limit cycle. In the graph, the point o rep-
resents the initial value point.
3.2
BASIC PRINCIPLES OF NUMERICAL APPROXIMATION OF ODEs
The solution of an ODE problem (3.1) is a vector-valued function u(t). An approx-
imate numerical solution can be obtained with a discretization method, such as the
finite difference method (FDM) or an ansatz method, e.g., the finite element method
(FEM) or the finite volume method (FVM). In this chapter, the FDM is presented.
With an FDM, we obtain a sequence of points (t1, u1), (t2, u2), â€¦ , (tN, uN). These
points approximate the exact solution, i.e., uk â‰ˆu(tk). Examples of well-known
FDMs are Eulerâ€™s method and Rungeâ€“Kuttaâ€™s method.
With an ansatz method, a function uh(x) â‰ˆu(x) is obtained. The approximating
function has the form uh(t) = âˆ‘cjğœ‘j(x), where ğœ‘j(x) are given basis functions and cj
are coefficients chosen in such a way that the approximation is as accurate as possi-
ble in some sense. The FEM is an example of such a method, see Sections 4.3, 6.5,
and 7.4.

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
41
The FVM is a method for solving certain PDEs approximated by ODE systems.
Similar to the FDM approximate values, u1, u2, â€¦ , uN are calculated at discrete
space points x1, x2, â€¦ , xN, see Section 8.3.
When different methods for the IVP are discussed, we can without loss of gener-
ality restrict ourselves to the scalar case, i.e.,
du
dt = f(t, u),
u(0) = u0,
0 < t â‰¤tend
(3.5)
The exact solution of this problem is denoted by u(t). All numerical formulas in this
chapter will be given for the scalar case, unless otherwise is stated.
3.3
NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
The basic idea in an FDM is that the derivative in (3.5) at time tk is approximated by a
difference formula using a few u values â€¦ ukâˆ’1, uk, uk+1 â€¦ in the neighborhood of
uk. The difference hk between two consecutive t points, i.e., hk = tk+1 âˆ’tk, is called
the stepsize. Most numerical methods use variable stepsize, i.e., hk takes different
values as the solution is computed along the t-axis. Methods where variable stepsize
is implemented are also called adaptive methods.
However, constant stepsize h can also be used, especially when we want to have
better control of the truncation errors (approximation errors) of the uk values. In that
case, the tk points are equidistantly spaced along the t-axis.
The discretized formulation of the ODE problem changes the differential equation
into a difference equation and the numerical solution is computed as a sequence
of uk values; the uk values are generated by a recursion formula. Linear difference
equations are fundamental for understanding numerical stability of FDMs. A short
overview is given in Appendix A.2.
The derivative in (3.5) can be approximated by various difference formulas, e.g.,
the Euler forward (3.6) or the Euler backward (3.7) approximations:
du
dt (tk) = u(tk+1) âˆ’u(tk)
h
+ O(h)
(3.6)
du
dt (tk) = u(tk) âˆ’u(tkâˆ’1)
h
+ O(h)
(3.7)
Both formulas are of first order,i.e., the truncation error is approximatelyproportional
to h provided h is sufficiently small. Leonard Euler was a Swiss mathematician active
in the 18th century and one of the most productive ever. He was one of the first to
write a textbook in analysis: â€œIntroductio in analysin infinitorumâ€ from 1748.
Another possible approximation would be to use the central difference approxi-
mation formula, which is of second order:
du
dt (tk) = u(tk+1) âˆ’u(tkâˆ’1)
2h
+ O(h2)
(3.8)

42
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
It may seem that the formula (3.8) is better to use instead of (3.6) and (3.7) as it
is of second order and therefore more accurate. There are disadvantages, however,
using (3.8) for the IVP, related to numerical instability, see Section 3.4.2. For certain
problems, however, (3.8) works well, see Section 3.5.
Consider first the constant stepsize case. Applying (3.6) to the IVP (3.5) gives
Eulerâ€™s explicit method (also called Eulerâ€™s forward method)
{
uk = ukâˆ’1 + hf(tkâˆ’1, ukâˆ’1),
u0 = u(0)
tk = tkâˆ’1 + h,
t0 = 0,
k = 1, 2, â€¦ , N
(3.9)
When (3.7) is used, we get Eulerâ€™s implicit method (also called Eulerâ€™s backward
method).
{
uk = ukâˆ’1 + hf(tk, uk),
u0 = u(0)
tk = tkâˆ’1 + h,
t0 = 0,
k = 1, 2, â€¦ , N
(3.10)
It can be shown that both methods give first-order accuracy in the uk values, i.e., the
truncation error, for IVPs also called the global error, ek, fulfills
ek = u(tk) âˆ’uk = O(h)
(3.11)
For both methods, we see that when (tkâˆ’1, ukâˆ’1) is given as input, the next point
(tk, uk) is computed as output, hence Eulerâ€™s explicit and implicit methods are both
one-step methods.
However, in explicit Euler, uk is computed just by inserting (tkâˆ’1, ukâˆ’1) into
the right hand side, while in implicit, Euler uk is computed by solving a nonlinear
equation. For that reason, we call (3.9) an explicit method, while (3.10) is an implicit
method.
As an implicit method will be more complicated to compute, one may immediately
ask: Why use implicit Euler when the computational work is so much larger? The
answer is that for certain problems called stiff problems, implicit Euler is much more
advantageous for numerical stability reasons. This will be shown in Section 3.3.4.
The two Euler methods usually have too low order of accuracy to be of practical
importance.However,they are very useful fordemonstrationof principles of the FDM
when applied to an IVP. We will therefore show some basic properties using these two
methods before we continue to higher order methods in Section 3.4.
Exercise 3.3.1. Show that the difference approximations (3.6) and (3.7) both have
first-order accuracy.
Exercise 3.3.2. Show that the difference approximation (3.8) is of second order.

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
43
Exercise 3.3.3. Set up the recursion formula when Eulerâ€™s explicit method (3.9) is
applied to the scalar model problem for IVPs
du
dt = ğœ†u,
u(0) = u0
where ğœ†is a constant complex parameter. Show that uk = (1 + hğœ†)ku0.
Exercise 3.3.4. The following method is sometimes used for solving problems in
Newtonian mechanics. For the ODE system
dv
dt = a(x, v),
dx
dt = v
the Eulerâ€“Cromer method (see also Section 3.5) is defined as
vk+1 = vk + ha(xk, vk),
xk+1 = xk + hvk+1
What is the order of this method? Try an analytical approach or make a numerical
experiment (see Section 3.3.1).
3.3.1
Eulerâ€™s Explicit Method: Accuracy
We first show how explicit Euler is used to solve Van der Polâ€™s equation (3.4)
d2y
dt2 + ğœ–(y2 âˆ’1)dy
dt + y = 0,
y(0) = 1,
dy
dt (0) = 0
This second-order ODE is written as a system of two first-order ODEs by introducing
a vector u with the components u1 = y, u2 = dyâˆ•dt:
â§
âª
â¨
âªâ©
du1
dt = u2,
u1(0) = 1
du2
dt = âˆ’ğœ–(u2
1 âˆ’1)u2 âˆ’u1,
u2(0) = 0
When the explicit Euler method is applied to this system, we get the recursion
formulas:
â§
âª
â¨
âªâ©
u1,k = u1,kâˆ’1 + hu2,kâˆ’1,
u1,0 = 1
u2,k = u2,kâˆ’1 + h(âˆ’ğœ–(u2
1,kâˆ’1 âˆ’1)u2,kâˆ’1 âˆ’u1,kâˆ’1),
u2,0 = 0
tk = tkâˆ’1 + h,
t0 = 0

44
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Recall that u1,k â‰ˆu1(tk) = y(tk). How does the global error e1,k = u1(tk) âˆ’u1,k
depend on the stepsize h? The numerical experiment presented in the example below
gives an answer to that question.
Example 3.4. Numerical experiment to determine the order of accuracy
For Van der Polâ€™s equation (3.4), let ğœ–= 1 and calculate y(1) with explicit Euler.
Discretize the t-axis on the interval [0, 1] with constant stepsize h, using N steps.
Table 3.1 shows the result obtained with the explicit Euler method.
As we observe in the table, the convergence is very slow. When h is halved, the
global error u1,N âˆ’y(1) is also halved, hence e1,N â‰ˆCh
From a logarithmicplot, the orderof accuracy can be estimated graphically.Taking
the logarithm of the general error relation e â‰ˆChp gives log e â‰ˆlog C + p log h,
which is a straight line in a loglog diagram. The slope of that line is p. In Figure 3.3,
the slope is 1, hence the order of explicit Euler is p = 1.
The error defined by (3.11) is called the global error. Another concept important
for error estimation and variable stepsize control in adaptive methods is the local
error, l(t, h), which is defined as the residual obtained when the exact solution is
inserted into the explicit Euler method
l(tk, h) = u(tk) âˆ’u(tkâˆ’1) âˆ’hf(tkâˆ’1, u(tkâˆ’1))
(3.12a)
Hence, the local error can be regarded as the truncation error committed in one step.
With Taylorâ€™s expansion, we see that
l(tk, h) = h2
2
d2u
dt2 (ğœk),
tkâˆ’1 < ğœk < tk
(3.12b)
In Figure 3.4, it is shown how the global and local errors propagate when one step is
taken from tkâˆ’1 to tk.
TABLE 3.1
Numerical Solution of Van der Polâ€™s Equation Using
Explicit Euler
N
h
u1,N
u1,N âˆ’y(1)
16
1âˆ•16
0.5231
0.0254
32
1âˆ•32
0.5100
0.0123
64
1âˆ•64
0.5037
0.0060
128
1âˆ•128
0.5006
0.0029
256
1âˆ•256
0.4991
0.0014
512
1âˆ•512
0.4984
0.0007
1024
1âˆ•1024
0.4980
0.0003
2048
1âˆ•2048
0.4978
0.0001

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
45
10âˆ’4
10âˆ’3
10âˆ’2
10âˆ’1
100
10âˆ’4
10âˆ’3
10âˆ’2
10âˆ’1
100
Stepsize h
Truncation error
Loglogâ€“diagram of error as function of h
Figure 3.3
Loglog diagram showing the order of accuracy for explicit Euler
tkâ€“1
tk
t
u(tkâ€“1)
u(tk)
ukâ€“1
uk
ekâ€“1
ek
â„“k
Figure 3.4
Graphical definition of the local and global errors
The global error ek can be regarded as the accumulated effect of all local errors
from t1 up to tk. However, it is not true in general that the global error is the sum of
the local errors, as the following analysis shows:
Eulerâ€™s explicit method can be written:
0 = âˆ’uk + ukâˆ’1 + hf(tkâˆ’1, ukâˆ’1)
If this equality is added to (3.12) we obtain, after using Taylorâ€™s expansion on the
second argument u in f(t, u), a global error recursion relation

46
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
ek = ekâˆ’1 + h ğœ•f
ğœ•u(tkâˆ’1, ukâˆ’1 + ğœƒ(u(tkâˆ’1) âˆ’ukâˆ’1))ekâˆ’1 + l(tk, h),
e0 = 0
(3.13)
where 0 < ğœƒ< 1. From this equality, we see that only if ğœ•fâˆ•ğœ•u â‰¡0, i.e., if f(t, u) does
not depend on u, the global error is the sum of the local errors. If this is not the case,
assume that
ğœ•f
ğœ•u â‰¤ğœ‡â‡’1 + h ğœ•f
ğœ•u â‰¤1 + hğœ‡â‰¤ehğœ‡
in the neighborhood of the solution, where ğœ‡can be a negative number. Insert the
expression (3.12b) into the global error formula (3.13) and we get
ek â‰¤(1 + hğœ‡)ekâˆ’1 + h2
2
d2u
dt2 (ğœk)
With the assumption hğœ‡> âˆ’1 and
max
1â‰¤kâ‰¤n |d2u
dt2 (ğœk)| â‰¤M
we obtain the inequality
|ek| â‰¤(1 + hğœ‡)|ekâˆ’1| + h2
2 M
which gives the following estimate for the global error (e0 = 0)
|ek| â‰¤h2
2 M etkğœ‡âˆ’1
hğœ‡
= O(h)
(3.14)
Hence, the global error for Eulerâ€™s explicit method is of first order. We see from
(3.12b) and (3.14) that the local error is one order larger than the global error. In
general, this is true for most FDM. If the local error l(tk, h) is O(hp+1), the global
error ek is O(hp).
3.3.2
Eulerâ€™s Explicit Method: Improving the Accuracy
Instead of decreasing the stepsize h in explicit Euler to get better accuracy, the method
can be improved by calculating the solution with two stepsizes, h and hâˆ•2, combined
with extrapolation. Take a step from tkâˆ’1 to tk = tkâˆ’1 + h in the following way:
1. Take one Eulerstep of size h: uâˆ—
k = ukâˆ’1 + hf(tkâˆ’1, ukâˆ’1)
2. Take two Eulersteps of size hâˆ•2:
ukâˆ’1
2 = ukâˆ’1 + h
2f(tkâˆ’1, ukâˆ’1),
uâˆ—âˆ—
k = ukâˆ’1
2 + h
2f(tkâˆ’1
2 , ukâˆ’1
2 )

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
47
3. The value uk is obtained by extrapolation:
uk = 2uâˆ—âˆ—
k âˆ’uâˆ—
k
The method described in the steps 1â€“3 above can be shown to be a second-order
method. With a numerical experiment on Van der Polâ€™s equation (3.4), this statement
can be verified empirically (Table 3.2):
TABLE 3.2
Numerical Solution of Van der Polâ€™s
Equation Using Rungeâ€™s Second-Order Method
N
h
u1,N
u1,N âˆ’y(1)
4
1âˆ•4
0.4991
0.0015
8
1âˆ•8
0.4980
0.0004
16
1âˆ•16
0.4977
0.0001
As is seen in Table 3.2, the errors decrease quadratically, i.e., eN = O(h2). Hence,
the convergence of improved Euler is much faster than explicit Euler and therefore
more efficient as fewer steps have to be taken to achieve a certain accuracy. The
improved Euler method is equivalent to a Rungeâ€“Kutta method (more about these
methods in Section 3.4) known as Rungeâ€™s second-order method:
k1 = f(tkâˆ’1, ukâˆ’1), k2 = f(tkâˆ’1 + hâˆ•2, ukâˆ’1 + hk1âˆ•2), uk = ukâˆ’1 + hk2
Exercise 3.3.5. Show that improved Euler is a second-order method. Hint: use the
following error expansion valid for explicit Euler: ek = c1h + c2h2 + c3h3 + â€¦ and
extrapolation according to 3).
Exercise 3.3.6. Verify that improved Euler and Rungeâ€™s second-order method are
the same one-step method.
Exercise 3.3.7. The following method, Heunâ€™s method, is another variant of
explicit Euler.
uâˆ—
k = ukâˆ’1 + hf(tkâˆ’1, ukâˆ’1),
uk = ukâˆ’1 + h
2(f(tkâˆ’1, ukâˆ’1) + f(tk, uâˆ—
k))
Verify, by solving Van der Polâ€™s equation numerically (write a program) that this
method is of second order.
Exercise 3.3.8. Verify that the local error (3.12b) for explicit Euler is given by
l(tk, h) = h2
2
d2u
dt2 (tk) + O(h3)

48
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Hence, the local error is O(h2), while the global error is O(h). Write a programto make
a numerical experiment on the scalar test equation defined in Exercise 3.3.3. Let
ğœ†= âˆ’1, u0 = 1, t0 = 0, tend = 1, and h = 0.05. Compute the global and the
local errors (neglect the O(h3) term) and write a table showing k, tk, uk,
l(tk, h) = h2uâ€²â€²(tk)âˆ•2, and ek = u(tk) âˆ’uk.
3.3.3
Eulerâ€™s Explicit Method: Stability
In the previous part of this chapter, it is shown how explicit Euler behaves when the
stepsize h is small. But what happens if large steps are taken?
Recall first the example of instability in Section 1.3, where the explicit Euler gives
an erroneous result with increasing amplitudes in the numerical solution of the vibra-
tion equation, although the analytic solution has decreasing amplitudes. What is the
reason for this difference in numerical and analytical behavior?
Example 3.5.
The following example from chemical kinetics, known as Robert-
sonâ€™s problem, shows that explicit Euler gives wrong results unless the stepsize is
small enough.
The following three irreversible reactions are given:
A â†’B,
B + C â†’A + C
2B â†’B + C
The following ODE system can be formulated based on the mass action law:
â§
âª
âª
âª
â¨
âª
âª
âªâ©
du1
dt = âˆ’k1u1 + k2u2u3,
u1(0) = 1
du2
dt = k1u1 âˆ’k2u2u3 âˆ’k3u2
2,
u2(0) = 0
du3
dt = k3u2
2,
u3(0) = 0
(3.15)
where k1 = 0.04, k2 = 104, k3 = 3â‹…107 are the rate constants of the reactions and u1,
u2, and u3 are scaled concentrations of A, B, and C.
If we use the explicitEuler method on this problem,we get the followingnumerical
result, shown in Table 3.3, for u(1) using different constant stepsizes h:
TABLE 3.3
Stability Depending on
the Stepsize
N
h
u(1)
10
0.1
NaN
100
0.01
NaN
1000
0.001
NaN
104
10âˆ’4
ok

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
49
In Table 3.3, NaN (Not a Number) means that the method has generated numbers
that are too large to be stored in the computer memory,also called overflow.The result
of the calculation is acceptable (but not very accurate) when h = 10âˆ’4. However,
the solution is interesting to study on the time interval [0, 1000]. Using the stepsize
h = 10âˆ’4 on the whole time interval means that we have to take 107 time steps, which
is very inefficient.
The solution of the problem is shown in the graph in Figure 3.5 drawn in both
linear and logarithmic scales:
0
200
400
600
800
1000
0
0.2
0.4
0.6
0.8
1
Robertson problem
t
A, B, C
A
B
C
100
10âˆ’5
100
t
A, B, C
A
B
C
Figure 3.5
Solution of Robertsonâ€™s problem, in linear and logarithmic diagrams
From the behavior of the solution curves, there seems to be no need for very small
stepsizes; the solution is very smooth after a short transient phase in the time interval
(0, 10âˆ’2), where u2(t) passes a maximum.
Two relevant questions in connection to this problem are
â€¢ Why are such small stepsizes needed when explicit Euler is used on this prob-
lem?
â€¢ Are there other methods better suited to solve this problem?
These questions and their answers are fundamental for understanding the numerical
stability problems when solving both ODE and PDE problems by discretization.
To investigate the numerical stability of methods, some results for LCC systems
(see Section 2.2) are needed.
We start with the scalar model problem introduced in Exercise 3.3.3. Then we
generalize to the LCC problem and finally to a nonlinear system. This is the same
increase of complexity as in the analytic stability analysis in Section 2.3.
du
dt = ğœ†u,
â†’
du
dt = Au,
â†’
du
dt = f(u)
(3.16)
Recall that the scalar model problem has the analytic solution u(t) = eğœ†tu0, which is
stable for t â‰¥0 if Re(ğœ†) â‰¤0.

50
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Explicit Euler applied to the scalar model problem gives the following recursion
formula (see Exercise 3.3.3):
uk = ukâˆ’1 + hğœ†ukâˆ’1 = (1 + hğœ†)ukâˆ’1 = (1 + hğœ†)2ukâˆ’2 = Â· Â· Â· = (1 + hğœ†)ku0
The uk-sequence is numerically stable (bounded) if
|1 + hğœ†| â‰¤1
(3.17)
If ğœ†is real and negative, the inequality can be written:
âˆ’1 â‰¤1 + hğœ†â‰¤1 â‡’h â‰¤2
âˆ’ğœ†= 2
|ğœ†| = hmax
(3.18)
If ğœ†is a complex number, the geometrical correspondence to the inequality (3.17)
is a disc in the complex hğœ†-plane with radius 1 and center in hğœ†= âˆ’1. We denote
this region in the complex hğœ†-plane by SEE, the stability region for Eulerâ€™s explicit
formula (Figure 3.6).
Hence, Eulerâ€™s explicit method gives stable solutions to the scalar model problem
if
hğœ†âˆˆSEE
(3.19)
It is important at this stage to observe and understand the difference between analytic
stability and numerical stability of the model problem Ì‡u = ğœ†u.
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
âˆ’4
âˆ’5
Re (hÎ»)
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
Im (hÎ»)
SEE
Figure 3.6
Stability region of Eulerâ€™s explicit method

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
51
â€¢ Analytic stability applies to the differential equation Ì‡u = ğœ†u and the stability
criterion is formulated for ğœ†only: Re(ğœ†) â‰¤0.
â€¢ Numerical stability applies to the difference equation obtained with the
method, i.e., for explicit Euler uk = ukâˆ’1 + hğœ†ukâˆ’1 and the stability criterion is
formulated for the product hğœ†as follows: hğœ†âˆˆSEE. Observe that if Re(ğœ†) > 0,
the analytic solution of the model problem is unstable and the solution is
unbounded as t â†’âˆ. In this case, the explicit Euler method also gives
unbounded numerical solutions as hğœ†is situated in the right half plane.
For an LCC system of ODEs
du
dt = Au,
u(0) = u0
we know that the analytic solution is stable for t â‰¥0 if Re(ğœ†i) â‰¤0 (assuming there
are no multiple eigenvalues with Re(ğœ†i) = 0).
Applying the explicit Euler method to this system gives as numerical solution a
vector sequence uk:
uk = ukâˆ’1 + hAukâˆ’1 = (I + hA)ukâˆ’1
(3.20)
The discussion of numerical stability is easier if we assume that the matrix A is diag-
onalizable, i.e.,
A = SÎ›Sâˆ’1
or
Sâˆ’1AS = Î›
where the columns of S are the eigenvectors of A and Î› is a diagonal matrix with the
eigenvalues of A in the diagonal, see Section 2.2.
Define another vector sequence zk through the relation uk = Szk. Insert this into
(3.20):
Szk = Szkâˆ’1 + hASzkâˆ’1
(3.21)
Multiply both sides by Sâˆ’1
zk = zkâˆ’1 + hSâˆ’1ASzkâˆ’1 = (I + hÎ›)zkâˆ’1
(3.22)
In the sequence (3.22) of vectors zk, the ith component z(i)
k is uncoupled from the
other components as I + hÎ› is diagonal
z(i)
k = (1 + hğœ†i)z(i)
kâˆ’1
(3.23)
Hence, the stability criterion for the explicit Euler solution is the same as for the scalar
model equation:
|1 + hğœ†i| â‰¤1,
i = 1, 2, â€¦ , n
(3.24)

52
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
The geometrical interpretation of these inequalities is that all products hğœ†i must be
situated in the stability region SEE, i.e.,
hğœ†i âˆˆSEE,
i = 1, 2, â€¦ , n
(3.25)
In the special case that all ğœ†i are real and ğœ†n â‰¤ğœ†nâˆ’1 â‰¤Â· Â· Â· â‰¤ğœ†1 < 0, we get the
stability condition:
h â‰¤
2
|ğœ†n| = hmax
(3.26)
i.e., the stepsize must be adjusted to the fastest timescale of the system. This may
seem contradictory: The fastest component eğœ†nt decreases very quickly to zero and
its value is very soon completely negligible. All the same, this component puts the
severest restriction to the stepsize!
For a nonlinear autonomous system of ODEs
du
dt = f(u),
u(0) = u0
the numerical stability analysis can be performed in a small neighborhood of a point
(a, b) on a solution trajectory (t, u(t)). We want to see how stepsizes can be chosen
at this point. To apply the results from the previous LCC problem, approximate the
nonlinear ODE system with an LCC system of ODEs. Let u = b + ğ›¿u, where ğ›¿u(t)
is a perturbation function. Insert this u into the ODE:
dğ›¿u
dt
= f(b + ğ›¿u) = f(b) + ğœ•f
ğœ•u(b)ğ›¿u + hot
(3.27)
Denote f(b) by c and the jacobian evaluated at b by J. If higher order terms are
neglected, the system of ODEs for the perturbation can be written
dğ›¿u
dt
= Jğ›¿u + c
(3.28)
The constant c does not affect the stability analysis (see Exercise 3.3.10). Therefore,
we have the (approximate) result that the explicit Euler method is stable if
hğœ†i(J) âˆˆSEE
(3.29)
Let us test this result on Robertsonâ€™s problem introduced in the beginning of this
section. The jacobian of the system is
J =
â›
âœ
âœâ
âˆ’k1
k2u3
k2u2
k1
âˆ’k2u3 âˆ’2k3u2
âˆ’k2u2
0
2k3u2
0
â
âŸ
âŸâ 

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
53
TABLE 3.4
Eigenvalues of the Jacobian of (3.15)
Along the Solution Trajectory
t
ğœ†1
ğœ†2
ğœ†3
1
0
âˆ’0.16
âˆ’1090
10
0
âˆ’0.06
âˆ’1210
100
0
âˆ’0.008
âˆ’1950
1000
0
âˆ’0.0004
âˆ’3670
From the solution trajectory, we choose the solution points u(1), u(10), u(100), and
u(1000) and compute the eigenvalues of the jacobian in these points. The result is
shown in Table 3.4.
As all eigenvalues are real and nonpositive, the stability criterion (3.26) applies, so
we concludethat a maximal stepsize hmax for Eulerâ€™s explicit method would be hmax =
2âˆ•3670 â‰ˆ5â‹…10âˆ’4 for this problem in accordance with the numerical experiment in
the beginningof this section. Using an adaptive variant of the method will not increase
the efficiency as the stepsize must be kept very small on the whole time interval.
Robertsonâ€™s problem is an example of a stiff ODE system. Such a system is char-
acterized by the location in the complex plane of the eigenvalues ğœ†i, i = 1, 2, â€¦ , n
of the jacobian. The system is stiff if
â€¢ ğœ†i are situated in the left half complex plane, i.e., Re(ğœ†i) â‰¤0.
â€¢ Re(ğœ†i) are of very different size, i.e., the system contains time constants of
widely varying sizes.
The conclusion is that Eulerâ€™s explicit method is not suited for stiff ODE problems.
Exercise 3.3.9. Show the instability of explicit Euler in Example 1.1 by verifying
that the values hğœ†i are not inside the stability region of explicit Euler for the stepsize
used, h = 0.1. Which is the largest stepsize giving decreasing oscillations for this
problem?
Exercise 3.3.10. Verify that the constant vector c in (3.28) does not affect the sta-
bility analysis, i.e., the stability results are the same as for the homogeneous ODE
system. Hint: Let ğ›¿v = ğ›¿u + Jâˆ’1c and formulate (3.28) for ğ›¿v.
Exercise 3.3.11. Write a program to compute and plot the stability region SH for
Heunâ€™s method presented in Exercise 3.3.7.
3.3.4
Eulerâ€™s Implicit Method
As Eulerâ€™s explicit method is very inefficient on stiff problems, the question is if there
are other methods that are better suited for these problems.
Apply Eulerâ€™s implicit method on the scalar model problem:
uk = ukâˆ’1 + hğœ†uk
(3.30)

54
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
âˆ’4
âˆ’5
Re (hÎ»)
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
Im (hÎ»)
SEI
Figure 3.7
Stability region for Eulerâ€™s implicit method
We solve this equation with respect to uk and obtain
uk =
1
1 âˆ’hğœ†ukâˆ’1
(3.31)
The sequence is stable if
|1 âˆ’hğœ†| â‰¥1
(3.32)
The stability region of the implicit Euler method is shown in the graph in Figure 3.7.
Hence, the stability region SEI consists of almost the whole complex plane; just
the interior of the disc with radius 1 and center in hğœ†= 1 is not in the stability region.
Therefore, the whole left half plane belongs to the stability region. This method is
appropriate for stiff systems as hğœ†i belongs to the stability region for all h > 0. Such
a method is called an A-stable method. However, Eulerâ€™s implicit method is only a
first-order method and will therefore be inefficient for accuracy reasons: the stepsize
h must be small in order to meet a certain error tolerance. In addition, there is another
price to pay. For a system of nonlinear ODEs, the following nonlinear algebraic sys-
tem of equations must be solved with respect to uk in every time step:
uk = ukâˆ’1 + hf(tk, uk)
(3.33)
This can be done with Newtonâ€™s method (see Section A.1), which, however,consumes
much computer time. An efficient method for stiff ODE systems must be based on
the following:

NUMERICAL SOLUTION OF IVPs WITH EULERâ€™s METHOD
55
â€¢ an implicit higher order method,
â€¢ variable stepsize technique,
â€¢ use of the sparsity (see Section A.5) of the jacobian.
Exercise 3.3.12. Assume that Re(ğœ†) > 0 in the scalar model problem, i.e., the ana-
lytical solution is unstable as t â†’âˆ. Find out if the numerical solution with implicit
Euler is unstable or stable for a fixed ğœ†-value as the stepsize h increases from zero to
larger values.
3.3.5
The Trapezoidal Method
The trapezoidal method can be regarded as a symmetric combination of Eulerâ€™s
explicit and implicit methods
uk = ukâˆ’1 + h
2(f(tkâˆ’1, ukâˆ’1) + f(tk, uk))
(3.34)
The trapezoidal method is a one-step implicit method and has Second-orderaccuracy:
ek = u(tk) âˆ’uk = O(h2)
The stability region STM of the trapezoidal method is exactly the left half part of the
complex plane (Figure 3.8).
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
âˆ’4
âˆ’5
Re (hÎ»)
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
Im (hÎ»)
STM
Figure 3.8
Stability region for the trapezoidal method

56
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
An advantage with the trapezoidal method is that the region of analytic stability
coincideswith STM. However,the solutions of the scalar modelequation obtained with
this method will contain oscillations that are damped out very slowly when ğœ†<< 0.
Therefore, the method is not recommended for very stiff problems, use instead BDF
methods (see Section 3.4.2).
Exercise 3.3.13. Write a program that visualizes the numerical solution of the
trapezoidal method applied to the scalar model equation for some negative values
of ğœ†.
3.4
HIGHER ORDER METHODS FOR THE IVP
3.4.1
Rungeâ€“Kutta Methods
The improved Euler method (see Section 3.3.2), also called Rungeâ€™s second- order
method, is an example from the Rungeâ€“Kutta family of methods (RK methods). The
most well-known member of this family is the classical RK4 method:
uk = ukâˆ’1 + h
6(k1 + 2k2 + 2k3 + k4)
(3.35)
tk = tkâˆ’1 + h,
i = 1, 2, â€¦ , N
where
k1 = f(tkâˆ’1, ukâˆ’1)
k2 = f(tkâˆ’1 + hâˆ•2, ukâˆ’1 + hk1âˆ•2)
k3 = f(tkâˆ’1 + hâˆ•2, ukâˆ’1 + hk2âˆ•2)
k4 = f(tkâˆ’1 + h, ukâˆ’1 + hk3)
Like Eulerâ€™s method, this is a one-step method, i.e., it is enough to know one point
(tkâˆ’1, ukâˆ’1) in order to compute the next point (tk, uk). The term (k1 + 2k2 + 2k3 +
k4)âˆ•6 in (3.35) can be regarded as a weighted mean value of slopes evaluated in
four different points in order to obtain an accurate representation of the slope of the
solution between (tkâˆ’1, ukâˆ’1) and (tk, uk). The RK4 method is a fourth-order method,
i.e., the truncation error ek satisfies
ek = u(tk) âˆ’uk = O(h4)
(3.36)
Carl Runge and Wilhelm Kutta were German mathematicians active in the beginning
of the 20th century.
Applying the RK4 method to Van der Polâ€™s equation to compute y(1), just as we
did for Eulerâ€™s method, results in Table 3.5:

HIGHER ORDER METHODS FOR THE IVP
57
TABLE 3.5
Numerical Solution of Van der Polâ€™s Equation
Using the RK4 Method
N
h
u1,N
u1,N âˆ’y(1)
1
1
0.5052
0.0076
2
1âˆ•2
0.4981
0.0005
4
1âˆ•4
0.4976
<10âˆ’4
8
1âˆ•8
0.4976
<10âˆ’4
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
âˆ’4
âˆ’5
Re (hÎ»)
0
1
2
3
âˆ’1
âˆ’2
âˆ’3
Im (hÎ»)
SRK
Figure 3.9
Stability region for the RK4 method
Hence, we obtain four digit accuracy for N = 4, which is much more efficient than
the explicit Euler method.
Just like the explicit Euler method, the RK4 method has a certain stability region,
defined by applying the method to the scalar model equation. It is an algebraic
exercise to show that the stability region for the RK4 method satisfies the inequality
corresponding to the graph in Figure 3.9.
|1 + hğœ†+ h2ğœ†2
2
+ h3ğœ†3
6
+ h4ğœ†4
24 | â‰¤1
(3.37)
As the stability region of RK4 is bounded and the order of accuracy is high, the
RK4 method is well suited for nonstiff problems.
A more general formula for an explicit RK method is given by the following
scheme of an s-stage RK method:
uk = ukâˆ’1 + h(b1k1 + b2k2 + Â· Â· Â· + bsks)
(3.38)

58
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
tk = tkâˆ’1 + h,
k = 1, 2, â€¦ , N
k1 = f(xkâˆ’1, ukâˆ’1)
k2 = f(xkâˆ’1 + c2h, ukâˆ’1 + ha21k1)
.........
ks = f(xkâˆ’1 + csh, ukâˆ’1 + h(as1k1 + as2k2 + Â· Â· Â· + assâˆ’1ksâˆ’1))
In schematic form, the formula can be described by a matrix tableau, the Butcher
tableau, of the form
(
c
A
bT
)
=
â›
âœ
âœ
âœ
âœâ
0
c2
a21
.
.
.
cs
as1
as2
â€¦
assâˆ’1
b1
b2
â€¦
bsâˆ’1
bs
â
âŸ
âŸ
âŸ
âŸâ 
(3.39)
The tableau (3.39) represents the formula for an explicit Rungeâ€“Kutta method. The
matrix A is then lower triangular. Implicit Rungeâ€“Kutta methods can also be defined.
In that case, the matrix A in the tableau is full.
John Butcher is a numerical analyst from New Zeeland still active.
With this formalism, the modified Euler method can be written as
â›
âœ
âœâ
0
1âˆ•2
1âˆ•2
0
1
â
âŸ
âŸâ 
and the RK4 method as
â›
âœ
âœ
âœ
âœâ
0
1âˆ•2
1âˆ•2
1âˆ•2
0
1âˆ•2
1
0
0
1
1âˆ•6
1âˆ•3
1âˆ•3
1âˆ•6
â
âŸ
âŸ
âŸ
âŸâ 
Adaptive methods can be constructed from embedded RK methods. An embedded
RK method uses the same c and A part of the matrix tableau but consists of two
different b vectors. The first one, denoted by b (giving a method of order p), is used
to compute the next value uk. The second one denoted Ì‚b (giving a method of order
p + 1) computes a Ì‚uk used just for error estimation:
â›
âœ
âœâ
c
A
bT
Ì‚bT
â
âŸ
âŸâ 
=
â›
âœ
âœ
âœ
âœ
âœ
âœâ
0
c2
a21
.
.
.
cs
as1
as2
â€¦
assâˆ’1
b1
b2
â€¦
bsâˆ’1
bs
Ì‚b1
Ì‚b2
â€¦
Ì‚bsâˆ’1
Ì‚bs
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
(3.40)

HIGHER ORDER METHODS FOR THE IVP
59
Assume that the local error (see Section 3.3.1) of the method corresponding to b
satisfies
l(tk, h) â‰ˆChp+1
(3.41)
Assume also that Ì‚uk is much more accurate than uk, so that ğ›¿= |Ì‚uk âˆ’uk| is an estimate
of l(tk, h) for the step taken from tkâˆ’1 to tk.
If tol is a given error tolerancevalue for the absolute error,we can use the following
stepsize strategy when taking a step h from tkâˆ’1 to tk:
Algorithm 3.1. (Stepsize control)
1. accept the step (uk is accepted) if ğ›¿â‰¤tol
The new step hnext should satisfy tol = Chp+1
next, hence hnext = h( tol
ğ›¿)1âˆ•(p+1).
2. reject the step (uk is rejected) if ğ›¿> tol
Start again from tkâˆ’1 with the new stepsize hnew = hâˆ•2, return to 1.
One well-known embedded Rungeâ€“Kutta method is the Bogackiâ€“Shampine order 2/3
pair, used in, e.g., ode23 in the MATLAB-library
â›
âœ
âœ
âœ
âœ
âœ
âœâ
0
1âˆ•2
1âˆ•2
3âˆ•4
0
3âˆ•4
1
2âˆ•9
3âˆ•9
4âˆ•9
0
2âˆ•9
3âˆ•9
4âˆ•9
0
7âˆ•24
6âˆ•24
8âˆ•24
3âˆ•24
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
Here Ì‚b corresponds to a second-order method, while b is of order three.
Exercise 3.4.1. Formulate the RK method associated with the following tableau
â›
âœ
âœ
âœ
âœâ
0
1
1
1âˆ•2
1âˆ•4
1âˆ•4
1âˆ•6
1âˆ•6
4âˆ•6
1âˆ•2
1âˆ•2
0
â
âŸ
âŸ
âŸ
âŸâ 
Apply this method to the test problem Ì‡u = ğœ†u and deduce from that result the order
of the method giving the solution values and also the order of the method used for
error estimation.
Exercise 3.4.2. Show the inequality (3.37) for the stability of the RK4 method.
Exercise 3.4.3. Write a program for plotting the graph of the stability area of the
RK4 method.

60
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Exercise 3.4.4. Write a program for simulation of the particle motion problem
described in Example 2.3. Use the RK4 method with constant stepsize. The following
values of the model parameters can be used: g = 10 mâˆ•s2, â€–v0â€– = 10 mâˆ•s, y0 = 2 m,
c = 0.01 Nâ‹…s2âˆ•m, m = 1 kg, ğ›¼= 20âˆ˜, and ğ›¼= 60âˆ˜. Make a plot of the two particle
trajectories showing the motion from the initial point to the point where the particle
hits the ground.
3.4.2
Linear Multistep Methods
In linear multistep methods, information is used not only from the previous step
(tkâˆ’1, ukâˆ’1) but also from earlier steps (tkâˆ’2, ukâˆ’2), (tkâˆ’3, ukâˆ’3), ....., (tkâˆ’p, ukâˆ’p).
A simple example of a two-step method is the explicit midpoint method, also
known as the leap-frog method based on the central difference approximation (3.5)
{
uk = ukâˆ’2 + 2hf(tkâˆ’1, ukâˆ’1)
tk = tkâˆ’1 + h,
k = 2, 3, ... ,N
(3.42)
Inserting k = 2 in the formula, we see that the method is not self-starting, i.e., apart
from u0, the initial value, we also need a value of u1. This could be obtained, e.g.,
using the explicit Euler method, i.e., u1 = u0 + hf(t0, u0).
The midpoint method is a second-order method, but unfortunately it is not suited
for most kinds of IVPs (see, however, Section 3.5) which the following example
shows:
Example 3.6.
Consider the explicit midpoint method applied to the scalar model
problem. We get the difference equation:
uk = ukâˆ’2 + 2hğœ†ukâˆ’1,
u0 = 1,
u1 = 1 + hğœ†
The results for h = 0.1,ğœ†= âˆ’1 and ğœ†= âˆ’2 are shown in the graphs in Figure 3.10.
The analytic solution is the smooth curve and the numerical solution is the oscil-
lating curve with increasing amplitude. This method is unstable regardless of the
stepsize h. It does not help to decrease the stepsize; the oscillations will occur sooner
or later. Hence, the explicit midpoint method is not suited for solving IVP in general
but can be designed to work for mechanical problems, see Section 3.5. The stability
region is derived in Section A.2.
The general definition of a linear p step method is
uk = ğ›¼1ukâˆ’1 + ğ›¼2ukâˆ’2 â€¦ ğ›¼pukâˆ’p + h(ğ›½0 fk + ğ›½1 fkâˆ’1 + â€¦ ğ›½p fkâˆ’p)
(3.43)
where fk = f(tk, uk). To start such a method, we need apart from u0 also u1, u2, ... upâˆ’1.
These values can be calculated with some one-step method, e.g., the RK4 method.
If ğ›½0 = 0 the method is explicit, if ğ›½0 â‰ 0 the method is implicit. Some well-known
classical multistep methods are, e.g.,

HIGHER ORDER METHODS FOR THE IVP
61
0
1
2
3
4
âˆ’0.5
0
0.5
1
0
1
2
3
4
âˆ’0.5
0
0.5
1
Figure 3.10
Numerical instability for the leap-frog method
â€¢ Adamsâ€“Bashforth (explicit):
uk = ukâˆ’1 + h
(
fkâˆ’1 + 1
2âˆ‡fkâˆ’1 + 5
12âˆ‡2fkâˆ’1 + â€¦
)
(3.44)
â€¢ Adamsâ€“Moulton (implicit)
uk = ukâˆ’1 + h
(
fk + 1
2âˆ‡fk âˆ’1
12âˆ‡2fk + â€¦
)
(3.45)
â€¢ Backward Differentiation Formulas (also called BDF-p or Gearâ€™s method of
order p and well suited for stiff IVPs)
âˆ‡uk + 1
2âˆ‡2uk + Â· Â· Â· + 1
pâˆ‡puk = hfk,
p â‰¤6
(3.46)
where
âˆ‡fk = fk âˆ’fkâˆ’1
âˆ‡2fk = fk âˆ’2fkâˆ’1 + fkâˆ’2
(3.47)
âˆ‡3fk = fk âˆ’3fkâˆ’1 + 3fkâˆ’2 âˆ’fkâˆ’3
J. Adams was a British mathematician active in the middle of the 19th century.
F. Bashforth and F. Moulton were scientists active around 1900 and W. Gear is an
American numerical analyst who published his method around 1970.
Automatic stepsize control can be designed in a way similar to RK methods. For
linear multistep methods, the local error l(tk, h) (see Section 3.3.1) is estimated as
follows:
l(tk, h) = Cu(p+1)(tk)hp+1
(3.48)
where C is a known constant depending on the method. The derivative can be esti-
mated from some difference approximation, see Appendix A.3. As an example for

62
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Adamsâ€“Bashforth method, p = 1, (which is in fact explicit Euler) the local error is
estimated from
l(tk, h) = 1
2
âˆ‡2uk
h2 h2 = âˆ‡2uk
2
(3.49)
and the algorithm for stepsize control now follows Algorithm 3.1.
Exercise 3.4.5. Present in the form (3.43), the first- and second-order methods of
Adamsâ€“Bashforth, Adamsâ€“Moulton, and Gear.
Exercise 3.4.6. Compute the stability region of BDF-2.
Exercise 3.4.7. Compute the solution of the ESCEP problem described in Example
2.6. Use BDF-2 with stepsize h = 0.01. (It is of course more effective to use variable
stepsize).
3.5
SPECIAL METHODS FOR SPECIAL PROBLEMS
In many physical and chemical problems, it is important in numerical simulations to
preserve certain invariants, such as the total energy, the total mass, and/or the positiv-
ity of the solution components. Many important classes of models possess invariants
that are linear and quadratic expressions in the solution components u1, u2, â€¦ un. In
numerical calculations, we cannot expect the invariants to be preserved exactly but
should be preserved to within rounding errors.
3.5.1
Preserving Linear and Quadratic Invariants
Linear invariants occurring, e.g., in the conservation of mass of a system, are pre-
served by most methods solving the IVP. For an ODE system, assume that a number
of linear relations are time invariant
du
dt = f(t, u), u(0) = u0,
Bu(t) = Bu0
where B is an m Ã— n, m < n matrix. By differentiating the linear relation with respect
to t, we obtain
Bdu
dt = Bf(t, u) = 0
When using, e.g., explicit Euler, we get after multiplication by B
Buk = Bukâˆ’1 + hBf(tkâˆ’1, ukâˆ’1) = Bukâˆ’1 = â€¦ Bu1 = Bu0
Hence, the linear relations are preserved along the approximate solution trajectory
u1, u2, â€¦ un. It is easy to conclude the same property for, e.g., classical Rungeâ€“Kutta
methods and linear multistep methods. Observe that even if the components of the
solution vector u are computed with a global error of say 10âˆ’4, the computed linear
invariants will hold an accuracy on rounding error level, typically 10âˆ’15.

SPECIAL METHODS FOR SPECIAL PROBLEMS
63
Example 3.7.
In the biochemical system presented in Example 2.6, the matrix S
in the right hand side of the ODE system (2.59) has rank 2, hence there are two linear
relations between the rows of S, see Exercise 2.5.7.
Bf(c) =
(
1
0
1
0
0
1
1
1
) â›
âœ
âœ
âœâ
âˆ’1
1
1
âˆ’1
âˆ’1
1
0
0
1
âˆ’1
âˆ’1
1
0
0
1
âˆ’1
â
âŸ
âŸ
âŸâ 
r(c) = 0
for all vectors c, hence Bc = Bc0.
In general, quadratic invariants are not preserved,but there is one method, a variant
of the trapezoidal method, called the implicit midpoint method
uk = ukâˆ’1 + hf
(
tkâˆ’1 + h
2, ukâˆ’1 + uk
2
)
(3.50)
that preserves the relation uTCu = uT
0 Cu0, where C is a symmetric matrix. By time
differentiation of the quadratic relation and dividing by 2, we get
uTCdu
dt = uTCf(t, u) = 0
Multiply (3.50) first by uT
kâˆ’1C, then by uT
k C, add these two equalities and you find
that uT
k Cuk = uT
kâˆ’1Cukâˆ’1, hence the quadratic relation is preserved.
Exercise 3.5.1. Given the parameter representation of a circle of radius 1
x = cos(ğœ‘),
y = sin(ğœ‘),
0 â‰¤ğœ‘â‰¤2ğœ‹
and the corresponding ODE system where u1 = x and u2 = y.
du
dğœ‘=
(0
âˆ’1
1
0
)
u,
u(0) =
(1
0
)
Write a program showing graphs of the phase portraits (u1, u2) obtained with the (i)
explicit Euler, (ii) implicit Euler, and (iii) implicit midpoint method. Conclude that
explicit Euler gives a growing spiral, implicit Euler gives a shrinking spiral, and the
implicit midpoint method gives an ellipse. Try also to verify this by mathematical
proofs.

64
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
3.5.2
Preserving Positivity of the Numerical Solution
In the numerical simulation of physical and chemical systems, there is a demand
for positivity for certain solution components. A concentration or a pressure, e.g.,
can never take negative values. Apart from being unphysical, negativity may also
make the ODE system unstable and totally ruin the whole solution. A simple remedy
would be, e.g., to set a negative concentration component to zero, which, however,
will destroy the mass balances (linear invariants) of the system.
Preserving numerical positivity when solving an ODE system with solution com-
ponents ui(t) > 0 as long as ui(0) â‰¥0 is harder. One way can be to utilize the special
form of the right hand side of the ODE system. As an example, take the system (2.49)
being a model for chemical kinetics. We can write this system in the alternative form
dc
dt = K(c)c,
c(0) = c0
(3.51)
where K(c) is an N Ã— N matrix. Using implicit Euler on this usually stiff ODE system
gives the algebraic equation system
ck = ckâˆ’1 + hK(ck)ck â†’(I âˆ’hK(ck))ck = ckâˆ’1
For the special matrices K(c) occurring in chemical kinetics, it can be shown that
if ckâˆ’1 > 0 (all components of ckâˆ’1 are positive), the inverse of I âˆ’hK(ckâˆ’1) has all
elements positive, thus ck > 0, and positivity will be preserved if the initial value c0 is
nonnegative.Now, if the nonlinear equation system is solved with an iteration method
of type
(I âˆ’hK(c(i)
k ))c(i+1)
k
= ckâˆ’1
then positivity is preserved. On the other hand that iteration scheme does not give
quadratic convergence. Newtonâ€™s method (see Appendix A.1) does but will not
always produce positive iterates, at least not for chemical kinetics ODEs.
3.5.3
Methods for Newtonâ€™s Equations of Motion
For conservative mechanical systems, the total energy is preserved. One very impor-
tant application is molecular dynamics, where the physical movements of interacting
molecules are simulated by numerically solving Newtonâ€™s equation of motion (2.43).
The Hamiltonian (2.46) for such a system of n particles can be written as the sum of
the kinetic energy T and the potential energy U
H = T + U =
n
âˆ‘
i=1
â€–piâ€–2
2mi
âˆ’
n
âˆ‘
j=1,iâ‰ j
ğ›¾mimj
â€–ri âˆ’rjâ€–
(3.52)
Newtonâ€™s equation will be
miÌˆri = âˆ’
âˆ‘
j=1,iâ‰ j
ğ›¾mimj(ri âˆ’rj)
â€–ri âˆ’rjâ€–3
,
i = 1, 2, â€¦ , n

SPECIAL METHODS FOR SPECIAL PROBLEMS
65
Another important application of a mechanical system is a system of masses and
springs introduced in (2.44) (with Dğœˆ= 0 and F = 0) and for which Newtonâ€™s
equations take the form
MÌˆx + Kx = 0,
x(0) = x0,
Ì‡x(0) = v0
For this ODE system, the hamiltonian H (quadratic form) is invariant
H = 1
2 Ì‡xTM Ì‡x + 1
2xTKx
(3.53)
For Newtonâ€™s equation of motion, special numerical methods have been devel-
oped and much used, e.g., the leap-frog method and Verletâ€™s method, which are both
of second-order accuracy, but do not belong to the Rungeâ€“Kutta or linear multi-
step methods. One reason for using special methods for Newtonâ€™s equation is that
Rungeâ€“Kutta and linear multistep methods do not preserve the total energy of a con-
servative mechanical system but allow the energy to drift away from its constant value
as time increases. The Verlet method has its name from the French physicist Loup
Verlet, who rediscovered the method for computer simulation of molecular dynamics
in the 1960s.
If we write Newtonâ€™s equation of motion on scalar form as a first-order system
Ì‡r = v,
r(0) = r0
Ìˆr = a(r),
v(0) = v0
(3.54)
where a(r) depends only on the position r, Verletâ€™s method for the position and the
velocity is
{
vk = (rk+1 âˆ’rkâˆ’1)âˆ•2h
rk+1 = 2rk âˆ’rkâˆ’1 + h2a(rk)
(3.55)
As is seen from (3.55), the derivative approximations are based on the symmetric
central difference formulas (3.8) and (4.24). The method has second-order accuracy.
It is also explicit and needs only one evaluation of the right hand side function a(r)
per time step. If just the positions r0, r1, â€¦ rk, ... are wanted only the second of the
two formulas are needed. This method also goes under the name StÃ¶rmerâ€™s method,
after the Norwegian mathematician Carl StÃ¶rmer, active in the first part of the 20th
century.
Verletâ€™s method is not self-starting meaning that the initial conditions r0 = r(0)
and v0 = v(0) are not enough to start the recursion. Here r1 is also needed and can be
computed from some approximation of the first step taken, e.g.,
r1 = r0 + hv0 + h2
2 a(r0)
(3.56)
The order of computation will then be r0, v0, r1, r2, v1,r3,v2, etc.

66
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Î½kâ€“1
rk
rk+2
rk+4
Î½k+1
Î½k+3
tkâ€“1
tk
tk+2
tk+4
tk+1
tk+3
Figure 3.11
Steps taken by different variables on a staggered grid
The leap-frog method is based on the following representation of Newtonâ€™s
equations of motion: Ì‡v = a(r),
v(0) = v0,
r = v,
r(0) = r0
{
vk+1 = vkâˆ’1 + 2ha(rk)
rk+2 = rk + 2hvk+1
(3.57a)
which can also be written with midpoint values
{
vk+1âˆ•2 = vkâˆ’1âˆ•2 + ha(rk)
rk+1 = rk + hvk+1âˆ•2
(3.57b)
This method is also based on the symmetric approximation of the derivatives. It has a
strong resemblance with the Eulerâ€“Cromer method (see Exercise 3.3.4), which, how-
ever, is based on the Euler forward approximation giving only first- order accuracy,
while the leap-frog method is of second order. In the beginning of Section 3.4.2, the
leap-frog method was tested on the scalar model problem Ì‡u = ğœ†u and found to be
useless when, e.g., ğœ†= âˆ’1. However, for hamiltonian systems in mechanics, it turns
out to be both effective and reliable, just like Verletâ€™s method. Here we also need a
way to start the method, e.g., with (3.56). The order of computation will be r0, v0,
r1, v2, r3, v4, r5, etc. From this sequence and Figure 3.11, we see that velocities v
are evaluated at a grid staggered with respect to the positions r. In general, a stag-
gered grid method means that different variables are computed on different grids, see
further Section 8.2.7.
3.6
THE VARIATIONAL EQUATION AND PARAMETER FITTING
IN IVPs
The variational equation (VE) was introduced in Chapter 2 as a tool for analytic sta-
bility analysis of solution curves and critical points. The aim was to see if a perturbed
curve in the neighborhood of a given solution trajectory will converge to the given
curve. Hence, analytical stability is investigated by perturbing the initial values in the
problem (see Section 2.3.1).

THE VARIATIONAL EQUATION AND PARAMETER FITTING IN IVPs
67
Another version of the VE occurs in sensitivity analysis, i.e., when we want to
compute how sensitive a solution is with respect to parameters in the right hand side.
Sensitivity analysis is based on the IVP formulation (3.2)
du
dt = f(t, u, p),
u(0) = u0(p)
(3.58)
To investigate the sensitivity, assume that the solution trajectory u(t, p) has been com-
puted for a given value of the parameter vector p and the task is to study a neighboring
solution trajectory u(t, p + ğ›¿p). Taylor expansion gives
u(t, p + ğ›¿p) = u(t, p) + ğœ•u
ğœ•p(t, p)ğ›¿p + hot
(3.59)
Hence, we need the sensitivity matrix S(t, p) defined as
S(t, p) = ğœ•u
ğœ•p
(3.60)
S(t, p) is obtained as the solution of the matrix differential equation derived by dif-
ferentiating (3.58) with respect to p:
dS
dt = ğœ•f
ğœ•uS + ğœ•f
ğœ•p,
S(0, p) = ğœ•u0
ğœ•p
(3.61)
The sensitivity matrix can be used for parameter estimation. Assume we want to
fit the parameter vector p in (3.58) to measured data (tk, uâˆ—
k), k = 1, 2, â€¦ , M of the
state variable u(t). The residual vector at each measurement point is defined as
rk = u(tk, p) âˆ’uâˆ—
k â‰ˆ0,
k = 1, 2, â€¦ , M
Also define the global sensitivity matrix S(p), the global measurement vector uâˆ—and
the global residual vector r(p) according to
S(p) =
â›
âœ
âœ
âœ
âœâ
S(t1, p)
S(t2, p)
.
.
S(tM, p)
â
âŸ
âŸ
âŸ
âŸâ 
,
uâˆ—=
â›
âœ
âœ
âœ
âœ
âœâ
uâˆ—
1
uâˆ—
2
.
.
uâˆ—
M
â
âŸ
âŸ
âŸ
âŸ
âŸâ 
,
r =
â›
âœ
âœ
âœ
âœâ
r1
r2
.
.
rM
â
âŸ
âŸ
âŸ
âŸâ 
Gaussâ€“Newtonâ€™s method can be used (see Section A.1). Assume p(i) is an iterate in a
sequence p(0), p(1), â€¦ , p(i). Given a start parameter vector p(0), iterate according to
{
S(p(i))ğ›¿p(i) = âˆ’r(i)
p(i+1) = p(i) + ğ›¿p(i)
until the correction â€–ğ›¿p(i)â€– is small enough.

68
NUMERICAL METHODS FOR INITIAL VALUE PROBLEMS
Example 3.8.
Consider the following system of ODEs containing three parame-
ters k1, k2, and k3:
dy1
dt = k1y1 âˆ’k2y1y2,
y1(0) = 1.0
dy2
dt = k2y1y2 âˆ’k3y2,
y2(0) = 0.3
Assume we have measurements of y1 and y2 according to the matrix
Ymsr =
( 1
1.1
1.3
1.1
0.9
0.7
0.5
0.6
0.7
0.8
1
0.3
0.35
0.4
0.5
0.5
0.4
0.3
0.25
0.25
0.3
0.35
)
at time points tk = kâ‹…0.5, k = 0, 1, 2, â€¦ 10. We want to estimate the unknown param-
eters k1, k2, and k3 from the measurements using the algorithm described in Section
3.6. For that we need the following jacobians:
J(y) =
(
k1 âˆ’k2y2
âˆ’k2y1
k2y2
k2y1 âˆ’k3
)
,
ğœ•f
ğœ•p =
(
y1
âˆ’y1y2
0
0
y1y2
âˆ’y2
)
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0
0.5
1
1.5
2
2.5
Solution for initial values k0
Time t
y (t, k0) and ymeasured
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
y (t, kest) and ymeasured
Time t
Solution for final values kest
Figure 3.12
Measurements and solution curves before and after the Gaussâ€“Newton method

BIBLIOGRAPHY
69
The initial guess for the parameter vector is k0 = (1, 1, 1)T. After a few iterations
with the Gaussâ€“Newton method, the iterations have converged (Figure 3.12) to
kest = (0.86, 2.08, 1.81).
BIBLIOGRAPHY
1. G. Dahlquist, Ã…. BjÃ¶rck, â€œNumerical Methodsâ€, Chapter 8, Dover, 2003
2. G. Golub, J. Ortega, â€œScientific Computing and Differential Equationsâ€, Chapter 2,
Academic Press, 1992
3. C. Moler, â€œNumerical Computing with MATLABâ€, Chapter 7, SIAM, 2004
A textbook with many physical applications
4. A.L. Garcia, â€œNumerical Methods for Physicsâ€, 2nd ed, chapter 2-3, Prentice Hall, 2000
Extensive treatment of the IVP is found in the textbooks
5. U. Ascher, L. Petzold, â€œComputer Methods for ODEs and DAEsâ€, SIAM, 1998
6. J.C. Butcher, â€œNumerical Methods for Ordinary Differential Equationsâ€, Wiley, 2003
7. E. Hairer, S. NÃ¶rset, G. Wanner, â€œSolving Ordinary Differential Equations I: Non-stiff
problemsâ€, Springer 2009
8. E. Hairer, G. Wanner, â€œSolving Ordinary Differential Equations II: Stiff and
Differential-Algebraic Problemsâ€, Springer 2010
9. A. Iserles, â€œA First Course in the Numerical Analysis of Differential Equationsâ€, Cam-
bridge University Press, 1996
10. L. Shampine, â€œNumerical Solution of ODEsâ€, Chapman and Hall, 1994


4
NUMERICAL METHODS FOR
BOUNDARY VALUE PROBLEMS
In this chapter, numerical methods for boundary value problems (BVPs) are
described. Most of the methods are presented for second-order ordinary differential
equations (ODEs) as such problems are very common in applications. However,
generalization to higher order ODEs and other types of BVP formulations are also
presented in various application problems. The independent variable is changed
from t to x, as many BVPs are formulated for 1D space-dependent problems.
A nonlinear second-order ODE
d2u
dx2 = f
(
x, u, du
dx
)
(4.1)
has a general solution that depends on two arbitrary constants C1 and C2
u = u(x, C1, C2)
(4.2)
In general, we cannot find the analytic solution. Hence, there is no explicit expres-
sion of the solution in the form (4.2) in which values of the constants C1 and C2
can be inserted. To obtain a unique solution, we therefore need two conditions. In
Chapter 3, these conditions were given as initial conditions. In this chapter, we show
how appropriate boundary conditions (BCs) define a solution that can be computed
approximately with numerical methods.
Just like an initial value problem (IVP), a BVP usually contains a number of
parameters occurring both in the right hand side function f(x, u, uâ€²) and/or in the BCs.
As a consequence, parameter studies are needed for BVPs, too. Hence, it is necessary
to have accurate, efficient, and robust methods.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

72
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
In case the ODE is linear, e.g.,
d2u
dx2 + a(x)du
dx + b(x)u = c(x)
(4.3)
the arbitrary constants C1 and C2 enter linearly in the general solution
u(x) = upart(x) + C1Î¦1(x) + C2Î¦2(x)
where upart(x) is a particular solution and Î¦1(x), Î¦2(x) are two linearly independent
solutions of the homogeneous ODE (the ODE with c(x) â‰¡0). However, even for lin-
ear problems of type (4.3), analytic solutions cannot be found in general.
BCs can be formulated in various ways. As was stated in Chapter 2, a unique
solution is determined by specifying initial conditions which can be regarded as a
special case of BCs. An initial value formulation of (4.1) is obtained by rewriting the
second-order ODE as a system of two first-order ODEs (see Section 2.1) and then
selecting two initial values u(x0) and uâ€²(x0). Let y1 = u and y2 = uâ€²
dy1
dx = y2,
y1(x0) = u(x0)
(4.4a)
dy2
dx = f(x, y1, y2),
y2(x0) = uâ€²(x0)
(4.4b)
Frequent forms of BCs to a second-order ODE are named after Peter Dirichlet and
Carl Neumann, German mathematicians active in the middle of the 19th century.
1. Dirichletâ€™s BC specifies the solution u(x) at an endpoint of an x interval (a, b),
say
u(a) = ua
and/or
u(b) = ub
(4.5)
where ua and/or ub are known values.
2. Neumannâ€™s BC specifies the derivative uâ€²(x) at an endpoint
du
dx(a) = uâ€²
a
and/or
du
dx(b) = uâ€²
b
(4.6)
where uâ€²
a and/or uâ€²
b are known values.
3. Robinâ€™s BC or mixed BC or generalized Neumannâ€™s BC specifies a linear com-
bination of u(x) and uâ€²(x) at an endpoint, e.g.,
du
dx(a) = ğ›¼1u(a) + ğ›½1
and/or
du
dx(b) = ğ›¼2u(b) + ğ›½2
(4.7)
where ğ›¼1, ğ›¼2, ğ›½1, and/or ğ›½2 are known values.

APPLICATIONS
73
Any combination of two of the BCs (4.5), (4.6), and (4.7) can be given as BCs
to (4.1). They can be compactly written in the form
ğ›¾1
du
dx(a) = ğ›¼1u(a) + ğ›½1,
ğ›¾2
du
dx(b) = ğ›¼2u(b) + ğ›½2
(4.8)
where the parameters ğ›¾i, ğ›¼i, and ğ›½i, i = 1, 2, 3 are chosen appropriately.The BCs (4.8)
are linear.
Yet another type of BC is a periodic BC that is formulated when the solution is to
be continued periodically outside the interval (a, b), e.g.,
u(a) = u(b),
du
dx(a) = du
dx(b)
(4.9)
4.1
APPLICATIONS
To illustrate various formulations of BVPs, a number of application problems are
presented in the examples below. Some of them are solved numerically later in this
chapter. The mathematical modeling background to some examples is presented in
Chapter 9.
Example 4.1. (Stationary flow of a hot fluid in a pipe).
Consider a pipe of length L (m) with a cylindrical cross section of radius R (m).
A hot fluid is transported through the pipe. Exchange of heat with the environment
takes place through the wall of the pipe (Figure 4.1). This process can be modeled
with the following BVP:
âˆ’d
dz
(
ğœ…dT
dz
)
+ ğœŒCvdT
dz + 2h
R (T âˆ’Tout) = 0,
0 < z < L
(4.10a)
T(0) = T0,
âˆ’ğœ…dT
dz (L) = k(T(L) âˆ’Tout)
(4.10b)
This BVP is a model of the thermal energy balance of the fluid in the pipe. In
Chapter 9, Example 9.6, this ODE is derived from physical assumptions, where the
three terms in the ODE (4.10a) represent, respectively,
1. heat conduction,
2. heat convection, and
3. heat loss through the wall.
0
L
z
Ï…
T (z)
T0
Tout
Figure 4.1
Steady heat transport by a fluid through a pipe

74
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
There can also be terms modeling heat sources. Such a term is represented in (4.10a)
as a source term f(T) in the ODE.
The BCs (4.10b) correspond to constant temperature T0 at the inlet of the pipe and,
at the outlet, heat flux is proportional to the difference between the fluid temperature
at the outlet T(L) and the ambient temperature Tout.
In (4.10), z (m) is the length coordinate, T = T(z) (K) the temperature along the
pipe, ğœ…[ Jâˆ•( Kâ‹…mâ‹…s)] the heat conduction coefficient of the fluid, v (m/s) the flow
velocity, ğœŒ( kgâˆ•m3) the density of the fluid, C [ Jâˆ•( Kâ‹…kg)] the heat capacity, and
h and k [ Jâˆ•( Kâ‹…m2 â‹…s)] are the heat transfer coefficients between the fluid and the
environment. Here, h is associated with heat loss through the wall of the pipe and k
with the heat transfer at the right end. T0 (K) is the inlet temperature, Tout (K) is the
ambient temperature at the wall and outside the endpoint at z = L. If all parameters
L, R, ğœ…, ğœŒ, C, v, h, k, Tout, and T0 in the model (4.10) are constant, the BVP is linear
with constant coefficients. Even for this simple problem, there are as many as 10
parameters of which the solution T(z) is dependent. In Chapter 9, it is shown how a
scaling procedure will reduce the number of parameters to 3.
A nonlinear formulation of the ODE is obtained if some of the parameters, e.g.,
ğœ…, are temperature dependent, i.e., ğœ…= ğœ…(T).
The nonlinearity may also occur in a BC, e.g., as a radiation formulation at the
right endpoint
âˆ’ğœ…dT
dz (L) = ğœ(T(L)4 âˆ’T4
out)
where ğœ[ Jâˆ•( K4 â‹…m2 â‹…s)] is the heat transfer coefficient for radiation.
Note that this problem will appear in other variants of the model in Chapters 6,
7, and 9.
Example 4.2. (Concentration profile in a spherical catalyst particle).
In a spherical porous catalyst particle with radius R (m), the concentration c(r)
( molâˆ•m3) of a substance diffusing into the particle where it reacts with the catalyst
is modeled by the BVP
D
(
d2c
dr2 + 2
r
dc
dr
)
= kc p,
0 < r < R
(4.11a)
dc
dr (0) = 0,
c(R) = c0
(4.11b)
where D ( m2âˆ•s) is the diffusion coefficient, kcp [molâˆ•( m3 â‹…s)] the rate expression
of the chemical reaction, and c0 ( molâˆ•m3) the concentration of the substance on the
surface of the particle (see Figure 4.2). In the rate expression, k is the rate constant
and p, a positive integer, is the order of the reaction. Observe that the ODE is not
defined at r = 0. The form of the ODE valid at this particular point can be derived
with lâ€™Hopitalâ€™s rule (see Exercise 2.1.6 in Chapter 2).

APPLICATIONS
75
0
r
R
c0
c (r)
Figure 4.2
Concentration profile in a spherical catalyst particle
Higher order BVPs are also common in applications. A fourth-order ODE
describes transversal bending of an elastic beam.
Example 4.3. (Transversally loaded beam).
The transversal deformation u(x) (m) of a beam of length L (m) can be modeled by
the ODE
d2
dx2
(
EI(x)d2u
dx2
)
= f(x),
0 < x < L
(4.12a)
where E ( Nâˆ•m2] is the elasticity module, I(x) ( m4) the cross section moment of
inertia, and f(x) (N/m) the load acting transversally on the beam (Figure 4.3). For
this ODE, four BCs are needed to specify a unique solution, e.g.,
u(0) = 0,
du
dx(0) = 0,
d2u
dx2 (L) = 0,
d3u
dx3 (L) = 0
(4.12b)
BVPs can also be formulated as systems of ODEs of first order, e.g.,
du
dx = f(x, u, v),
u(a) = ua
(4.13)
dv
dx = g(x, u, v),
v(b) = vb
0
L
x
f (x)
Figure 4.3
Displacement of a loaded beam

76
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Example 4.4. (Counterflow heat exchanger).
Consider a heat exchanger consisting of two pipes of length L (m) exchanging energy
and with counterflow streams of hot and cold water
uH
dH
dx = âˆ’a(H âˆ’C),
H(0) = H0,
0 < x < L
(4.14a)
âˆ’uC
dC
dx = a(H âˆ’C),
C(L) = C0
(4.14b)
where H (K) is the temperature of the hot water, C (K) the temperature of the cold
water, uH and uC (m/s) the fluid velocities, and a (1/s) a temperature transfer coeffi-
cient describing the heat flow between the two pipes (Figure 4.4).
0
L
x
H0
C0
C (x)
H (x)
uC
uH
Figure 4.4
Counter flow heat exchange
A general formulation of a two-point BVP is
du
dx = f(x, u),
g(u(a), u(b)) = 0
(4.15a)
Often in applications g is linear, in which case the BCs can be written:
B0u(a) + B1u(b) = b
(4.15b)
Example 4.5. (Blasiusâ€™ boundary layer equation in fluid dynamics).
The nonlinear third-order ODE
2 d3f
dğœ‚3 + f d2f
dğœ‚2 = 0,
0 < ğœ‚< âˆ
(4.16a)
with BCs
f(0) = 0,
df
dğœ‚(0) = 0,
df
dğœ‚(âˆ) = 1
(4.16b)
is a classical problem in fluid dynamics.
From the solution f(ğœ‚), the velocity components u(x, y) (m/s) and v(x, y) (m/s) of
the stream close to a plane wall (see Figure 4.5) can be computed:
u(x, y) = uâˆ
df
dğœ‚(ğœ‚),
v(x, y) =
âˆšğœˆuâˆ
4x (ğœ‚df
dğœ‚(ğœ‚) âˆ’f(ğœ‚)),
ğœ‚= y
âˆšuâˆ
ğœˆx

APPLICATIONS
77
x
y
u0
Ï… (x, y)
u (x, y)
Figure 4.5
Blasiusâ€™ boundary layer flow
where uâˆ(m/s) is the free stream velocity far from the wall and ğœˆ(m2âˆ•s) is the
kinematic viscosity. Observe that one of the BCs is given at ğœ‚= âˆ.
As was pointed out at the end of Section 2.1, uniqueness of a solution to a BVP
is more complicated than for an IVP. The following two examples show what can
happen.
Example 4.6. (An eigenvalue problem).
The eigenfrequencies of a circular membrane are the frequencies for which the mem-
brane can oscillate without the influence of external forces. The fundamental model
for an oscillatory system is the wave equation (see Section 5.1)
ğœ•2u
ğœ•t2 = c2
(
ğœ•2u
ğœ•x2 + ğœ•2u
ğœ•y2
)
where u (m) is the deflection of the membrane, t (s) time, and c (m/s) the velocity of
the wave.
We look at time harmonic solutions of angular frequency ğœ”,
u(x, y, t) = eiğœ”tv(x, y)
Insert into the wave equation to obtain the Helmholtz equation
c2
(
ğœ•2v
ğœ•x2 + ğœ•2v
ğœ•y2
)
+ ğœ”2v = 0
(4.17)
Now let the membrane be fixed along the boundary of the circle. We wish to find
values of ğœ”such that the BVP with homogeneous BC v = 0 on the boundary has
nontrivial solutions. This is an eigenvalue problem for the Laplace equation, see also
Problem (5) in Section 5.1. Hermann von Helmholtz was a German scientist active
around the end of the 19th century.
For a circular membrane of radius R (m), use polar coordinates (r, ğœ‘). Assume
there is no angular dependence and we obtain the BVP
âˆ’1
r
d
dr
(
rdv
dr
)
= ğœ†v,
dv
dr (0) = 0, v(R) = 0
(4.18)

78
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
âˆ’0.25
âˆ’0.2
âˆ’0.15
âˆ’0.1
âˆ’0.05
0
0.05
0.1
0.15
0.2
The first eigenfunctions of the membrane problem
r
v(r)
Figure 4.6
Some eigensolutions of the circular membrane problem
where ğœ†= (ğœ”âˆ•c)2. This BVP has infinitely many solutions, see Figure 4.6 for the
eigenfunctions corresponding to the smallest eigenvalues.
Example 4.7. (A nonlinear BVP with two solutions).
Another example of a BVP not having a unique solution is
uâ€²â€² + eu+1 = 0,
u(0) = u(1) = 0,
0 < x < 1
(4.19)
This problem has exactly two solutions, plotted in the graph in Figure 4.7.
The two Examples 4.6 and 4.7 show that the question of uniqueness of a solution
to a BVP is not as transparent as for an IVP.
4.2
DIFFERENCE METHODS FOR BVPs
The numerical way of treating a BVP is different from the way of solving an IVP.
An IVP is solved with a marching technique starting from given initial values, then
proceeding step by step forward until the final time point is reached.
In a BVP, there are not enough initial values to start the marching technique.
Instead, in the discretization of a BVP, a matching technique leads to coupled alge-
braic equations. Hence, a finite difference method (FDM) for numerical solution of a
BVP transforms the ODE problem into a system of algebraic equations. The system

DIFFERENCE METHODS FOR BVPs
79
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.5
1
1.5
2
2.5
The 2 solutions of d2u/dx2 + exp (u + 1) = 0, u(0) = u(1) = 0
x
u
Figure 4.7
Example showing non-uniqueness for a BVP
will be linear or nonlinear depending on whether the BVP is linear or nonlinear. The
algebraic equations will generally be sparse and should therefore be solved by sparse
direct methods or by iterative methods (see Section A.5).
4.2.1
A Model Problem for BVPs, Dirichletâ€™s BCs
As a model problem for numerical solution of a BVP, we take the elementary linear
problem
âˆ’d2u
dx2 = f(x),
0 < x < 1
(4.20a)
u(0) = 0,
u(1) = 0
(4.20b)
The general solution of the ODE is
u(x) = C1 + C2x âˆ’âˆ«
x
0
F(s)ds
(4.21)
where C1 and C2 are arbitrary constants and F(s) = âˆ«s
0 f(t)dt. Integrating by parts
gives
âˆ«
x
0
F(s)ds = [sF(s)]x
0 âˆ’âˆ«
x
0
sFâ€²(s)ds = âˆ«
x
0
(x âˆ’s)f(s)ds
Inserting the BCs (4.20b) gives
C1 = 0,
C2 = âˆ«
1
0
(1 âˆ’s)f(s)ds

80
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
and the solution can be written
u(x) = x âˆ«
1
0
(1 âˆ’s)f(s)ds âˆ’âˆ«
x
0
(x âˆ’s)f(s)ds
(4.22a)
or
u(x) = âˆ«
1
0
G(x, s)f(s)ds
where
G(x, s) =
{
s(1 âˆ’x),
0 â‰¤s â‰¤x
x(1 âˆ’s),
x â‰¤s â‰¤1
(4.22b)
G(x, s) is called the Greenâ€™s function after the British mathematician George Green
active in the beginning of the 19th century (Figure 4.8).
Observe that if f(x) â‰¥0, 0 â‰¤x â‰¤1, then the solution u(x) â‰¥0.
The principleof the FDM (see Section 3.2) is to discretize the continuousvariablex
and to replace the derivatives by difference approximations. The following algorithm
transforms the ODE problem into an algebraic system of equations:
DG = Discretize the interval to a Grid,
DD = Discretize the Differential equation,
DB = Discretize the BCs.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.05
0.1
0.15
0.2
0.25
Example of Green functions
s
G
G(0.4, s) âˆ’>
<âˆ’ G(0.7, s)
Figure 4.8
Greenâ€™s function for the model problem

DIFFERENCE METHODS FOR BVPs
81
This algorithm is now illustrated on the model problem (4.20).
DGâ€”discretize the x interval and introduce a numbering of the grid points:
0
h
1
x0
x1
xi â€“ 1
xi
xN
xN + 1
x
We call this basic grid G. If the stepsize h is constant, then the discretization above
gives the following relation between h and N, the number of inner points in the
interval [0, 1]:
h(N + 1) = 1
DDâ€”choose difference approximations for the derivatives. In Chapter 3, we have
already introduced a second-order formula for the first derivative, the central
difference approximation:
du
dx(xi) = u(xi+1) âˆ’u(xiâˆ’1)
2h
+ O(h2)
(4.23)
For the second derivative, there is a similar second-order formula:
d2u
dx2 (xi) = u(xi+1) âˆ’2u(xi) + u(xiâˆ’1)
h2
+ O(h2)
(4.24)
Use (4.24) to discretize (4.20a) at an arbitrary inner gridpoint xi:
âˆ’ui+1 âˆ’2ui + uiâˆ’1
h2
= f(xi)
(4.25)
This relation is valid at all the inner points, i.e., i = 1, 2, â€¦ , N.
DBâ€”as u is given at the two endpoints also being gridpoints, the Dirichlet BCs
(4.20b) can be represented exactly:
u0 = 0,
uN+1 = 0
(4.26)
The BCs (4.26) are inserted into the first and last equation of (4.25). The result
of the whole discretization procedure is the following system of N unknowns
u1, u2, â€¦ , uN and N equations:
âˆ’u2 âˆ’2u1
h2
= f(x1)
âˆ’ui+1 âˆ’2ui + uiâˆ’1
h2
= f(xi),
i = 2, 3, â€¦ , N âˆ’1
(4.27)
âˆ’âˆ’2uN + uNâˆ’1
h2
= f(xN)

82
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
The system is written in matrix form:
Au = f
(4.28)
where
A =
â›
âœ
âœ
âœ
âœâ
2 âˆ’1
0
0
â€¦
âˆ’1
2
âˆ’1
0
â€¦
â€¦
â€¦
0
âˆ’1
2
âˆ’1
â€¦
0
0
âˆ’1
2
â
âŸ
âŸ
âŸ
âŸâ 
,
f = h2
â›
âœ
âœ
âœ
âœâ
f(x1)
f(x2)
.
f(xNâˆ’1)
f(xN)
â
âŸ
âŸ
âŸ
âŸâ 
(4.29)
The N Ã— N matrix A is symmetric, positive definite, and tridiagonal. This will not be
the case for BVPs in general; the matrix can be both unsymmetric and have another
structure than tridiagonal. In most cases, however, the matrix has some banded struc-
ture. A in (4.29) can also be written A = tridiag(âˆ’1, 2, âˆ’1).
The matrix A in (4.29)plays an importantrole forinsight into the numericalproper-
ties of methods for both ODEs and partial differential equations (PDEs). In particular,
the eigenvalues ğœ†j are important. They can be computed exactly (see Section A.2):
ğœ†j = 4 sin2
(
ğœ‹j
2(N + 1)
)
,
j = 1, 2, â€¦ , N
(4.30)
We see that all eigenvalues are positive and that
ğœ†min â‰ˆğœ‹2âˆ•(N + 1)2,
ğœ†max â‰ˆ4
(4.31)
It can be shown that Aâˆ’1 has only positive elements. Hence, if f(x) â‰¥0 on the inter-
val
0 â‰¤x â‰¤1, then the discrete solution u will be positive just as the analytic
solution (4.22a).
The tridiagonality of A can be utilized computationally in two ways:
â€¢ Computer storage: if only the nonzero diagonals of A are stored, much less
storage is needed than storing a full matrix.
â€¢ Computer time: the number of floating point operations (flops) needed to solve
Au = b is much less for a tridiagonal matrix than for a full matrix.
In fact, if A is treated as a full matrix, N2 elements must be stored, while if A is stored
in a sparse way, only 3N âˆ’2 elements need to be stored. In addition, if A is treated
as a full matrix, Gaussian elimination needs about N3âˆ•3 flops to solve Au = b, while
a tridiagonal version needs only about 5N flops (see Section A.5).
These observations concerning computing efficiency for 1D problems become
more important when solving BVPs in 2D or 3D (see Chapter 7).
As the accuracy of the difference approximation(4.24) is of second order, it should
be expected that the accuracy of the numerical solution ui = ui(h) also is of second
order. The following numerical experimentverifies this statement. For a mathematical
proof, see Section 4.2.3.

DIFFERENCE METHODS FOR BVPs
83
TABLE 4.1
Numerical Solution of (4.20) Using
Central Difference Approximations
N
h
ui(h), x = 0.5
e(h)
3
1âˆ•4
0.1067
5.37â‹…10âˆ’3
7
1âˆ•8
0.1026
1.31â‹…10âˆ’3
15
1âˆ•16
0.1017
3.26â‹…10âˆ’4
31
1âˆ•32
0.1014
8.14â‹…10âˆ’5
63
1âˆ•64
0.1013
2.03â‹…10âˆ’5
127
1âˆ•128
0.1013
5.09â‹…10âˆ’6
Example 4.8.
The following numerical experiment verifies that the discretization
of (4.20) gives second-order approximation to the solution. With f(x) = sin(ğœ‹x), the
analytic solution is u(x) = sin(ğœ‹x)âˆ•ğœ‹2. The following result was obtained for con-
stant stepsizes h = 1âˆ•2, 1âˆ•4, 1âˆ•8,.... In Table 4.1, the truncation error e(h) = ui(h) âˆ’
u(xi) at the point xi = 0.5 for the different stepsizes is shown. A loglog graph of e(xi)
as function of h shows that the order of accuracy is two.
Exercise 4.2.1. Calculate the matrix A and the vector b in the case that the stepsize
hi = xi+1 âˆ’xi is not constant. All approximationsshould have second-order accuracy.
4.2.2
A Model Problem for BVPs, Mixed BCs
What modifications must be made if the BCs in (4.20) are changed? We illustrate by
treating the following BVP:
âˆ’d2u
dx2 = f(x),
0 < x < 1
du
dx(0) = 0, âˆ’du
dx(1) = u(1) âˆ’1
(4.32)
Introduce an equidistant grid with the following numbering of the points:
0
h
1
x1
x2
xi âˆ’ 1
xi
xN
xN âˆ’ 1
x
We call this grid G0. Use Eulerâ€™s method to approximation to the BCs:
u2 âˆ’u1
h
= 0,
âˆ’uN âˆ’uNâˆ’1
h
= uN âˆ’1
(4.33)
The disadvantage with this discretization, however, is that the first-order approxima-
tions in the BCs will give only first-order accuracy in all points of the grid (although
the ODE is discretized to second order).
Exercise 4.2.2. Verify first-order accuracy at x = 0.5 of the problem given in (4.32)
when using the Euler approximations (4.33) in the BCs by writing a program similar
to the one in Example 4.8.

84
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
To obtain second-order accuracy, there are various possibilities:
G1â€”modify the grid and the indexing by incorporating two outer points
(ghost points) x0 = âˆ’h and xN+1 = 1 + h. The inner points are now
x1 = 0, x2 = h, â€¦ , xN = 1.
x0
x1
x2
0
h
1
xi âˆ’ 1
xN âˆ’ 1
xN
xN + 1
xi
x
G2â€”modify the grid so that an endpoint with a derivative condition is located
in the middle between two gridpoints. The Euler approximation uâ€²(0) = (u1 âˆ’
u0)âˆ•h is a symmetric approximationfor this grid and has thereforesecond-order
accuracy.
0
h
2
h
2
h
1
x0
x1
xi âˆ’ 1
xi
xN
xN + 1
h
2
h
2
x
G3â€”use the original grid G0 but apply second-order unsymmetric difference
approximation for the BCs, e.g.,
du
dx(0) = âˆ’u(2h) + 4u(h) âˆ’3u(0)
2h
+ O(h2)
(4.34a)
and, at the other end of the interval,
du
dx(1) = 3u(1) âˆ’4u(1 âˆ’h) + u(1 âˆ’2h)
2h
+ O(h2)
(4.34b)
With this grid and these difference approximations, no points outside the inter-
val [0, 1] are needed. Hence, we can use the grid G0.
We illustrate a second-order method for solving (4.32) using the grid modification
G1 given above. Following the three steps DG,DD, and DB from above:
DGâ€”use the grid G1, but observe that now h(N âˆ’1) = 1.
DDâ€”the ODE is now valid also at the inner points x1 = 0 and xN = 1.
âˆ’ui+1 âˆ’2ui + uiâˆ’1
h2
= f(xi),
i = 1, 2, â€¦ , N
(4.35a)
DBâ€”the BC approximations are
u2 âˆ’u0
2h
= 0,
âˆ’uN+1 âˆ’uNâˆ’1
2h
= uN âˆ’1
(4.35b)

DIFFERENCE METHODS FOR BVPs
85
Hence, we get N + 2 equations for the N + 2 unknowns, u0, u1, â€¦ , uN+1 and the
matrix A is modified to an (N + 2) Ã— (N + 2) matrix. The system of equations is
A =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
1
0
âˆ’ğŸ
0
â€¦
âˆ’1
2
âˆ’1
0
â€¦
0
âˆ’1
2
âˆ’1
â€¦
â€¦
0
âˆ’1
2
âˆ’1
â€¦
0
âˆ’ğŸ
2h
1
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
f = h2
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
0
f(x1)
f(x2)
f(xNâˆ’1)
f(xN)
0
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
+ 2h
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
0
0
0
0
0
1
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
The matrix A corresponds to the difference approximations of uâ€² and uâ€²â€². The right
hand side vector f consists of one term originating from f(x) and the other term from
the BCs.
We see that the matrix is almost tridiagonal; the two boldface âˆ’ğŸelements in the
first and last row make the matrix pentadiagonal. However, by eliminating u0 and
uN+1, i.e., solving the first and last equation with respect to u0 and uN+1, respectively,
u0 = u2
uN+1 = uNâˆ’1 âˆ’2h(uN âˆ’1)
(4.36)
and inserting these expressions into the equations for i = 1 and i = N
âˆ’âˆ’2u1 + 2u2
h2
= f(x1)
âˆ’2uNâˆ’1 âˆ’(2 + 2h)uN
h2
= f(xN) + 2
h
(4.37)
gives a tridiagonal linear system of N equations for the N unknowns (u1, â€¦ , uN)
with the tridiagonal N Ã— N matrix:
A =
â›
âœ
âœ
âœ
âœâ
2
âˆ’2
0
â€¦
âˆ’1
2
âˆ’1
â€¦
â€¦
0
âˆ’1
2
âˆ’1
â€¦
0
0
âˆ’2
2 + 2h
â
âŸ
âŸ
âŸ
âŸâ 
(4.38)
The reduction to tridiagonal form, however, is not necessary from computational
point of view. On the contrary, it is easier to put the BCs (4.35b) as the first and last
equations in Au = b and the equations (4.35a) in between.
Exercise 4.2.3. Write programs for solution of (4.32) using the two grids G2
and G3 above. Make the discretization, set up the equations, formulate on matrix
form, and solve the linear system of equations giving the approximate solution.
Verify second-order accuracy.

86
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Exercise 4.2.4. Use Taylor expansion to show that the difference formulas in (4.24)
and (4.34) are of second order.
Exercise 4.2.5. If the grid G2 is used, how do we compute u(0) and u(1) with for-
mulas giving second-order accuracy from the computed values u0, u1, â€¦ , uN+1?
4.2.3
Accuracy
In order to discuss the truncation errors in the numerical solution of (4.20), we define
the local discretization error, the residual obtained when the exact solution is inserted
into the discretization (4.25)
l(x, h) = âˆ’u(x + h) âˆ’2u(x) + u(x âˆ’h)
h2
âˆ’f(x)
(4.39)
Using Taylor expansion, it is easy to show that
l(x, h) = 1
12u(4)(x + ğœƒh)h2,
0 < ğœƒ< 1,
(4.40)
i.e., the local error is of second order.
Define the global error at the point xi as
e(xi, h) = u(xi) âˆ’ui
(4.41)
where u(x) is the analytic solution of (4.20) and ui is the numerical solution obtained
from (4.28).
At the point x = xi the following two relations are valid:
l(xi, h) = âˆ’u(xi + h) âˆ’2u(xi) + u(xi âˆ’h)
h2
âˆ’f(xi)
0 = âˆ’ui+1 âˆ’2ui + uiâˆ’1
h2
âˆ’f(xi)
(4.42)
Subtract the second equality from the first:
l(xi, h) = âˆ’e(xi+1, h) âˆ’2e(xi, h) + e(xiâˆ’1, h)
h2
(4.43)
As there is no error in the BCs, we also have
e(x0, h) = e(xN+1, h) = 0
(4.44)
Hence, the global error satisfies the following linear system of equations:
Ae = h2l â†’e = h2Aâˆ’1l
(4.45)

DIFFERENCE METHODS FOR BVPs
87
where l and e are the vectors of local and global errors at the discretization points,
respectively. Taking the norm of both sides, we get
â€–eâ€– â‰¤h2â€–Aâˆ’1â€–â€–lâ€–
(4.46)
where the norm is chosen as the max-norm, i.e., â€–.â€– = â€–.â€–âˆ. The matrix Aâˆ’1 can be
computed and its max-norm shown to be
â€–Aâˆ’1â€–âˆâ‰¤N2
4
(4.47)
For the global error, we thus obtain second-order accuracy
max
i
|e(xi, h)| = â€–eâ€–âˆâ‰¤
1
(N + 1)2
N2
4 â€–lâ€–âˆ< h2
48 max
0<x<1 |u(4)(x)| = O(h2)
4.2.4
Spurious Solutions
In the previous section in this chapter, it was shown how the FDM behaves when the
stepsize h is small. But what happens if large steps are taken?
For the discussion of this question, we change the model problem (4.20) to con-
tain a first derivative term. This model equation is known as the advectionâ€“diffusion
equation and is a slight modification of the model problem (with f(x) = 0)
âˆ’ğœ–d2u
dx2 + du
dx = 0,
0 < x < 1,
u(0) = 0, u(1) = 1
(4.48)
The first term in (4.48) corresponds to diffusion transport, while the second term
describes convection transport (see also Chapter 9). The parameter ğœ–is a positive
constant. The general solution of this LCC problem is
u(x) = C1 + C2exâˆ•ğœ–
Imposing BCs gives
u(x) = exâˆ•ğœ–âˆ’1
e1âˆ•ğœ–âˆ’1
(4.49)
If ğœ–>> 1, u(x) â‰ˆx, which is the straight line between (0,0) and (1,1).
If 0 < ğœ–<< 1, however,u(x) â‰ˆeâˆ’(1âˆ’x)âˆ•ğœ–, which is almost equal to zero everywhere
except in the neighborhood of x = 1 where u(1) = 1. Hence, the solution u(x) almost
makes a jump at x = 1. We say that the problem has a boundary layer at x = 1 and
the problem is an example of a singular perturbation problem.
For a problem having a solution with this almost discontinuous behavior in a very
small part on the interval [0, 1],we might expect numerical difficulties unless the step-
size is appropriately adjusted. Discretize the ODE using the FDM with second-order
difference approximations on the grid G
âˆ’ğœ–ui+1 âˆ’2ui + uiâˆ’1
h2
+ ui+1 âˆ’uiâˆ’1
2h
= 0,
i = 1, 2, â€¦ N
(4.50)

88
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
This difference equation with the BCs u0 = 0, uN+1 = 1 can be solved according to
the method in Section A.2 and the solution is
ui =
1 âˆ’
(
1+Pe
1âˆ’Pe
)i
1 âˆ’
(
1+Pe
1âˆ’Pe
)N+1 ,
i = 0, 1, â€¦ , N + 1
(4.51)
where the numerical Peclet number Pe (Jean Peclet was a French physicist active in
the first half of the 19th century) is defined as
Pe = h
2ğœ–
(4.52)
We note that if Pe > 1, the solution ui is oscillatory, which is not the case in the ana-
lytical solution (Figure 4.9). The amplitude of the spurious oscillations increases with
the stepsize h. This numerical phenomenon might be regarded as a kind of instability,
but, unlike the IVP, the amplitude cannot increase unboundedly, as the largest step
h that can be taken is the size of the whole interval, which is finite in a numerical
computation.
If Pe < 1, there will be no oscillations (see Figure 4.9). However, if ğœ–is very small,
the stepsize h must also be very small to meet the condition Pe < 1. On the other hand,
for a very small ğœ–, the analytic solution is almost zero in the whole interval [0, 1]
except in the boundary layer where the solution steeply goes to one. This numerical
phenomenon resembles stiffness introduced for IVPs in Chapter 3. For stiff IVPs,
implicit methods can be used to avoid very small stepsizes. So, what is the remedy
here?
Approximatethe first derivativewith a backward difference.This leads to the FDM
âˆ’ğœ–ui+1 âˆ’2ui + uiâˆ’1
h2
+ ui âˆ’uiâˆ’1
h
= 0,
i = 1, 2, â€¦ , N
(4.53)
This approximation of the first derivative is also called the upwind difference and is
of great importance in Chapter 8 on hyperbolic PDEs. This method postpones the
oscillations but has the disadvantage of giving only first-order accuracy. What this
FDM actually does is to increase the ğœ–value in (4.48). As the upwind difference can
be written
ui âˆ’uiâˆ’1
h
= ui+1 âˆ’uiâˆ’1
2h
âˆ’h
2
ui+1 âˆ’2ui + uiâˆ’1
h2
(4.54)
we obtain the following FDM equivalent to (4.53)
âˆ’ğœ–h
ui+1 âˆ’2ui + uiâˆ’1
h2
+ ui+1 âˆ’uiâˆ’1
2h
= 0,
i = 1, 2, â€¦ N
(4.55)
where ğœ–h = ğœ–(1 + Pe). Hence, in the original ODE (4.48), the diffusion parameter
ğœ–has been increased: we have added a term called artificial diffusion (or artificial

DIFFERENCE METHODS FOR BVPs
89
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
âˆ’0.8
âˆ’0.6
âˆ’0.4
âˆ’0.2
0
0.2
0.4
0.6
0.8
1
x
u
oscillating curve: h = 0.1, Pe = 5, 2nd order method
dotted curve: h = 0.1, Pe = 5, upwind method
smooth curve: h = 0.01, Pe = 0.5, 2nd order method
Figure 4.9
Spurious oscillations in the advection-diffusion Equation
viscosity) to the problem and the discretization (4.55) corresponds to the perturbed
BVP
âˆ’ğœ–h
d2u
dx2 + du
dx = 0,
0 < x < 1,
u(0) = 0, u(1) = 1
(4.56)
4.2.5
Linear Two-Point BVPs
The BVP (4.3), now formulated in a way suited for many applications is
âˆ’d
dx(ğœ…(x)du
dx) + p(x)du
dx + q(x)u = f(x),
a < x < b
(4.57a)
with BCs
ğœ…(a)du
dx(a) = ğ›¼1u(a) + ğ›½1
(4.57b)
ğœ…(b)du
dx(b) = ğ›¼2u(b) + ğ›½2
(4.57c)
represent a linear BVP with linear Neumann or mixed BCs, depending on the values
of ğ›¼i, and ğ›½i, i = 1, 2. A Dirichlet condition at, e.g., the left boundary is implemented
by setting u(a) = ua instead of (4.57b). With the grid G1 and the central difference
approximations of the derivatives, we obtain
ğœ…(x1)u2 âˆ’u0
2h
âˆ’ğ›¼1u1 = ğ›½1
(4.58a)

90
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
âˆ’1
h(ğœ…(xi+1âˆ•2)ui+1 âˆ’ui
h
âˆ’ğœ…(xiâˆ’1âˆ•2)ui âˆ’uiâˆ’1
h
)
+ p(xi)ui+1 âˆ’uiâˆ’1
2h
+ q(xi)ui = f(xi), i = 1, â€¦ , N
(4.58b)
ğœ…(xN)uN+1 âˆ’uNâˆ’1
2h
âˆ’ğ›¼2uN = ğ›½2
(4.58c)
where x0, xN+1 are ghostpoints, x1 = a, xN = b, and h(N âˆ’1) = b âˆ’a. This is a linear
algebraic system Au = b with a pentadiagonal matrix.
For a Dirichlet BC at, say, the left boundary point, i.e., u(a) = ua, equation (4.58a)
takes the form u1 = ua and no ghost point x0 is needed.
The system can be reduced to a tridiagonal system if u0 and uN+1 are eliminated,
but this is not necessary, as the reduction to a tridiagonal system is not easier from a
programming point of view. The matrix A and the right hand side b is easier to set up
if we start from (4.58). The generation of the linear system of these equations can be
easily automatized if we skip the elimination of ghost points.
Example 4.9. (Interface problem in heat conduction)
In Example4.1, we have assumed that the heat conductioncoefficient ğœ…is constant for
the fluid. However, for heat conduction in a long metal rod composed of two different
materials, the heat conductivity will be different in the two regions (0, ğœ‰) and (ğœ‰, L),
where ğœ‰is the interface point. The following mathematical model consisting of two
coupled BVPs can be formulated assuming there are no convection terms
âˆ’d
dz
(
ğœ…1
dT1
dz
)
+ 2h
R (T1 âˆ’Tout) = 0,
0 < z < ğœ‰
(4.59a)
with the BC at the left endpoint T1(0) = T0
âˆ’d
dz
(
ğœ…2
dT2
dz
)
+ 2h
R (T2 âˆ’Tout) = 0,
ğœ‰< z < L
(4.59b)
with the BC at the right endpoint âˆ’ğœ…dT2
dz (L) = k(T2(L) âˆ’Tout). At the interface point,
the temperature and the heat flux are continuous, i.e.,
T1(ğœ‰) = T2(ğœ‰)
âˆ’ğœ…1
dT1
dz (ğœ‰) = âˆ’ğœ…2
dT2
dz (ğœ‰)
(4.59c)
Hence in the interface point, we have a discontinuity in the first derivative and the
second derivative does not exist at that point. The formulation of this problem with
the finite element method (FEM) is found in Example 4.12.

DIFFERENCE METHODS FOR BVPs
91
4.2.6
Nonlinear Two-Point BVPs
The problem (4.1), i.e., a nonlinear second-order ODE
d2u
dx2 = f
(
x, u, du
dx
)
a < x < b
(4.60a)
with nonlinear BCs:
g1
(
a, u(a), du
dx(a)
)
= 0
(4.60b)
g2
(
b, u(b), du
dx(b)
)
= 0
(4.60c)
gives a nonlinear BVP.
With the grid G1, the following equations are obtained after discretization:
g1
(
a, u1, u2 âˆ’u0
2h
)
= 0
ui+1 âˆ’2ui + uiâˆ’1
h2
âˆ’f
(
xi, ui, ui+1 âˆ’uiâˆ’1
2h
)
= 0,
i = 1, â€¦ , N
g2
(
b, uN, uN+1 âˆ’uNâˆ’1
2h
)
= 0
(4.61)
This can be written as a nonlinear system of algebraic equations
F(u) = 0
where
F(u) =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
g1(a, u0, u1, u2)
â€¦
ui+1 âˆ’2ui + uiâˆ’1
h2
âˆ’f(xi, uiâˆ’1, ui, ui+1)
â€¦
g2(b, uNâˆ’1, uN, uN+1)
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
u =
â›
âœ
âœ
âœ
âœâ
u0
u1
..
uN
uN+1
â
âŸ
âŸ
âŸ
âŸâ 
(4.62)
This system can be solved with Newtonâ€™s method, see Section A.1. The jacobian is
almost tridiagonal, hence in each Newton-iteration a banded system is to be solved.
Exercise 4.2.6. Discretize the BVP in Example 4.1 with the FDM. Use the follow-
ing values of the parameters in the problem: L = 10, ğœ…= 0.5, h = 5, k = 10, ğœŒ= 1,
C = 1, R = 1, T0 = 400, and TL = 300
a) Let v = 0 (no convection term, only conduction). Plot the discretized solution
Ti approximating T(zi) using the grid size N = 10, 20, 40, 80 in the same graph.
Note the convergence of the solution curves.

92
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
b) Vary v in a parameter study using the grid size N = 40. Choose the values
v = 0.1, 0.5, 1, 10 and plot the solutions in the same graph. Note the spurious
oscillations when v = 10! Investigate if the oscillations decrease if the grid size
N is increased.
Exercise 4.2.7. Discretize the BVP in Example 4.2 with the FDM. Use the param-
eter values D = 1, k = 1, R = 1, and c0 = 1.
a) First solve the problem for p = 1 giving a linear BVP. Write a program solv-
ing the linear system of equations and choose in the discretization suitable grid
size N. Plot the numerical solution for different values of N showing the con-
vergence.
b) Change the reaction order parameter to p = 2. The BVP is now nonlinear.
Formulate the nonlinear algebraic system of equation (4.62) for this problem
and find the jacobian of the system. Write a program implementing Newtonâ€™s
method for this problem, see Section A.1.
Exercise 4.2.8. The fourth-order ODE in Example 4.3 with modified BCs can be
written as a system of two second-order ODEs:
d2M(x)
dx2
= f(x),
M(L) = 0
d2u
dx2 = M(x)
EI(x),
u(0) = 0,
uâ€²(0) = 0,
u(L) = 0
The function M(x) is the moment acting on the beam. Choose simple values for the
parameters: L = 1, E = 1, I = 1, and f = 1.
a) Using the FDM, formulate the two algebraic systems of equations corre-
sponding to the two BVPs. They are coupled through the discretized moment
vector M.
b) Write a program that solves the systems of equations in a) and plots the numer-
ical solution ui in a graph. Choose suitable values of the grid parameter N.
4.2.7
The Shooting Method
In the shooting method, the BVP is treated as an IVP in an iterative way. We illustrate
the shooting method on the nonlinear formulation (4.60a)
d2u
dx2 = f
(
x, u, du
dx
)
,
a < x < b
with Dirichletâ€™s BCs
u(a) = ğ›¼,
u(b) = ğ›½
(4.63)

DIFFERENCE METHODS FOR BVPs
93
We write this BVP as an IVP
dy1
dx = y2,
y1(a) = u(a)
(4.64a)
dy2
dx = f(x, y1, y2),
y2(a) = du
dx(a)
(4.64b)
In the formulation above, u(a) is known u(a) = ğ›¼, but uâ€²(a) is unknown. If we intro-
duce the unknown slope at x = a as a parameter s, the shooting parameter, we can
illustrate geometrically in Figure 4.10 the meaning of changing s:
0
0.2
0.4
0.6
0.8
1
1.2
0
0.5
1
1.5
Point to hit
Slope = s0
Slope = s1
u(1, s0)
u(1, s1)
x
x
u
The shooting method
Figure 4.10
Graph showing the idea behind the shooting method
The computational task is to device a systematic method that computes s so that
the BC at the right endpoint is met. When s is varied, the value of u(b) at the right
endpoint x = b is changed, i.e., u(b) is a function of s: u(b) = u(b, s). We want to find
the value of s for which u(b, s) = ğ›½, i.e., we have to solve the following equation with
respect to s:
u(b, s) âˆ’ğ›½= 0
(4.65)
This is a nonlinearscalar equation in s. It has to be solved numerically as the analytical
solution u(x, s) is not known. This excludes Newtonâ€™s method as in general we cannot
form ğœ•uâˆ•ğœ•s needed in Newtonâ€™s method.
The method to be used here is instead the secant method. The secant method
applied to the general problem F(z) = 0 is
zi+1 = zi âˆ’F(zi)(zi âˆ’ziâˆ’1)
F(zi) âˆ’F(ziâˆ’1),
i = 1, 2, â€¦
(4.66)

94
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
where z0 and z1 are given initial guesses. Hence, by applying the secant method to
the BVP (4.64) with F(s) = u(b, s) âˆ’ğ›½we have the shooting method.
Example 4.10. (Blasiusâ€™ boundary layer equation in fluid dynamics).
The nonlinear third-order ODE in Example 4.5
2 d3f
dğœ‚3 + f d2f
dğœ‚2 = 0,
0 < ğœ‚< âˆ
with BCs
f(0) = 0,
df
dğœ‚(0) = 0,
df
dğœ‚(âˆ) = 1
is formulated as a first-order system of ODEs. Let u1 = f, u2 = Fâ€², u3 = Fâ€²â€²
du1
dğœ‚= u2,
u1(0) = 0
du2
dğœ‚= u3,
u2(0) = 0
du3
dğœ‚= âˆ’1
2u1u3,
u3(0) = s
where s, the shooting parameter, is to be computed so that u2(s, L) = 1, where L is a
large number.
Exercise 4.2.9. Write a program solving the BVP in Example 4.10. Try different
values of L (say L = 10,20,40) and check the convergence of the f(ğœ‚) curve.
4.3
ANSATZ METHODS FOR BVPs
Ansatz methods applied to BVPs will result in systems of algebraic equations to be
solved just as the FDM. They are linear or nonlinear depending on whether the BVP
is linear or nonlinear.
As a model problem for ansatz methods, we use the same BVP as before
(4.20), i.e.,
âˆ’d2u
dx2 = f(x),
0 < x < 1,
u(0) = 0,
u(1) = 0
The solution u(x) is approximated by an ansatz uh(x):
u(x) â‰ˆuh(x) =
N
âˆ‘
j=1
cjğœ‘j(x)
(4.67)

ANSATZ METHODS FOR BVPs
95
where ğœ‘j(x) are given basis functions and cj are coefficients to be determined so that
uh(x) is a â€œgoodâ€ approximation in some sense. We assume here that the basis func-
tions satisfy the BCs, i.e.,
ğœ‘j(0) = 0,
ğœ‘j(1) = 0,
j = 1, 2, â€¦ , N
(4.68)
Hence, the ansatz solution uh(x) satisfies the BCs of the model problem, i.e., uh(0) =
0, uh(1) = 0.
The subscript h in uh(x) refers to the fact that the basis functions are defined from
some sort of discretization of the interval (0, 1).
4.3.1
Starting with the ODE Formulation
Insert the ansatz into the BVP and we obtain a residual function r(x):
r(x) = d2uh
dx2 + f(x) â‰ 0
(4.69)
We want the residual function to be small in some sense.
If r(x) â‰¡0 for all x in the interval 0 â‰¤x â‰¤1, then uh(x) is the exact solution
of (4.20). Of course we cannot expect uh(x) to be exact in a general case, but a small
residual can be achieved in various ways:
1. r(xi) = 0, i = 1, 2, â€¦ N, i.e., the residual is zero in points xi âˆˆ[0, 1], the collo-
cation method
2. r(x) is orthogonal to ğœ‘i(x), i.e., âˆ«1
0 r(x)ğœ‘i(x)dx = 0, i = 1, 2, â€¦ , N, Galerkinâ€™s
method
Boris Galerkin was a Russian engineer and mathematician active in the first half of
the 20th century.
Galerkinâ€™s method is demonstrated here. Insert r(x) into the integral conditions:
âˆ«
1
0
( N
âˆ‘
j=1
cj
d2ğœ‘j
dx2 + f(x)
)
ğœ‘idx = 0,
i = 1, 2, â€¦ , N
(4.70)
As cj are independent of x, we can move them outside the integral:
N
âˆ‘
j=1
cj âˆ«
1
0
d2ğœ‘j
dx2 ğœ‘idx + âˆ«
1
0
f(x)ğœ‘idx = 0
(4.71)
Now use integration by parts on the first integral
âˆ«
1
0
d2ğœ‘j
dx2 ğœ‘idx =
[dğœ‘j
dx ğœ‘i
]1
0
âˆ’âˆ«
1
0
dğœ‘i
dx
dğœ‘j
dx dx
(4.72)

96
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Because of the BCs, the first term on the right hand side is equal to zero and we get
N
âˆ‘
j=1
cj âˆ«
1
0
dğœ‘i
dx
dğœ‘j
dx dx = âˆ«
1
0
f(x)ğœ‘idx
(4.73)
which is a linear system of equations
Ac = f,
Aij = âˆ«
1
0
dğœ‘i
dx
dğœ‘j
dx dx,
fi = âˆ«
1
0
f(x)ğœ‘idx
(4.74)
where the matrix A is N Ã— N, symmetric, and positive definite. Observe that so far
we cannot say anything about the sparsity of A. That depends on the choice of basis
functions ğœ‘i(x), i = 1, 2, â€¦ , N, see Section 4.3.3.
4.3.2
Starting with the Weak Formulation
4.3.2.1
The Model Problem The analytical solution (4.22) to the ODE
problem (4.20) is referred to as the strong (or classical) solution, meaning
that u(x) must be twice piecewise continuously differentiable and fulfill the BCs to
satisfy the BVP.
There is, however, an alternative formulation, the weak (or variational) formula-
tion, based on an integral relation to which the BCs are coupled. This formulation
requires u(x) to be only once piecewise continuously differentiable and is called the
weak solution.
The weak solution is obtained by multiplying the ODE by a test function v(x)
fulfilling the BCs v(0) = v(1) = 0, integrate over the interval (0, 1) and then use inte-
gration by parts
âˆ’âˆ«
1
0
uâ€²â€²(x)v(x)dx = âˆ’[uâ€²(x)v(x)]1
0 + âˆ«
1
0
uâ€²(x)vâ€²(x)dx = âˆ«
1
0
f(x)v(x)dx
The outintegrated term vanishes as v(0) = v(1) = 0 and the original ODE
problem (4.20) can now be stated in weak form: Find u(x) âˆˆU such that
âˆ«
1
0
uâ€²(x)vâ€²(x)dx = âˆ«
1
0
f(x)v(x)dx,
for all v(x) âˆˆU
(4.75)
Both u(x) and v(x) belong to the same function space, U â‰¡PC1
[0,1](0, 1), which means
all functions that are once piecewise continuously differentiable on the interval (0, 1)
and zero at the boundary points [0] and [1]. We use the notation PC as C in most
textbooks is reserved for functions that are continuously differentiable up to a certain
order.
If the BVP (4.20) is given with another BC
âˆ’d2u
dx2 = f(x),
u(0) = 0,
uâ€²(1) = 0
(4.76)

ANSATZ METHODS FOR BVPs
97
the weak formulation must be modified. As before multiply with a test function v(x),
integrate, and then integrate by parts. The outintegrated term is
âˆ’uâ€²(1)v(1) + uâ€²(0)v(0) = uâ€²(0)v(0) = 0
if
v(0) = 0
and the weak formulation will be: Find u(x) âˆˆU such that
âˆ«
1
0
uâ€²(x)vâ€²(x)dx = âˆ«
1
0
f(x)v(x)dx,
for all v(x) âˆˆU
where U = PC1
[0](0, 1). Hence, the BC u(0) = 0 is imposed into the function space U,
while the BC uâ€²(1) = 0 comes out from the weak formulation. BCs that are imposed
explicitly to the function space U (here u(0) = 0) are called essential BCs, while
BCs that comes out from the weak formulation are called natural BCs. Most often
Dirichlet BCs are essential, while Neumannâ€™s and mixed BCs are natural.
Comment. It should be noted that there is also a third way of formulating (4.20)
called Ritzâ€™ method or the minimization formulation
minv(x)âˆˆU âˆ«
1
0
(1
2(vâ€²(x))2 âˆ’f(x)v(x))dx
where U â‰¡PC1
[0,1](0, 1). The function giving the minimum value to the integral
expression is denoted by u(x) and is the same function that solves the variational
problem (4.75). This technique, however, belongs to variational calculus and is not
taken up here. End of comment.
It may seem like magic that the weak formulation works, i.e., that (4.20) and (4.75)
give the same solution and that a method can be based on a relation that is satisfied for
infinitely many functions! The following analogy with a linear system of algebraic
equations shows that â€œalthough this be madness, yet there is method in itâ€ (Shake-
speare, Hamlet, Act 2). Assume that A is an arbitrary N Ã— N matrix and let u âˆˆRN
be the solution of
Au = b
Multiply both sides by vT, an arbitrary (row) vector in RN
vT(Au âˆ’b) = 0
for all v âˆˆRN
(4.77)
and we obtain the weak formulation. On the other hand, if (4.77) is true, choose from
RN N linearly independent vectors, put them as columns in the N Ã— N matrix W, and
we obtain
WT(Au âˆ’b) = 0
As W is nonsingular, we can multiply by the inverse of WT giving
Au âˆ’b = 0 â†’Au = b

98
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
Now, back to the weak formulation (4.75). A well-known approximation
method is Galerkinâ€™s method already mentioned in Section 4.3.1. This method
is based on projection of u(x) onto a finite dimensional linear subspace Uh of
U. Assume this subspace is built up by basis functions ğœ‘i(x), where ğœ‘i(0) = 0,
ğœ‘i(1) = 0, i = 1, 2, â€¦ , N. We now look for an ansatz approximation uh(x) that
belongs to the subspace Uh
uh(x) =
N
âˆ‘
j=1
cjğœ‘j(x)
and satisfies the weak formulation in the subspace, i.e., find uh(x) âˆˆUh such that
âˆ«
1
0
duh
dx
dvh
dx dx = âˆ«
1
0
f(x)vhdx,
for all vh âˆˆUh
(4.78)
In Galerkinâ€™s method, the basis functions ğœ‘i(x) are used as test functions vh(x) and
we obtain
N
âˆ‘
j=1
cj âˆ«
1
0
dğœ‘i
dx
dğœ‘j
dx dx = âˆ«
1
0
f(x)ğœ‘idx,
i = 1, 2, â€¦ N
(4.79)
which is the same linear system of equations as (4.74), where we started with the
differential equation. The trick in both cases is to use partial integration to get rid of
the second derivative.
4.3.2.2
A Linear Two-Point BVP Now, let us generalize Galerkinâ€™s method to the
linear two-point BVP defined by (4.57). This generalization is helpful to have as a
background to Chapter 7 where elliptic PDEs are studied. As before, multiply (4.57a)
with a test function v(x)
âˆ«
b
a
(
âˆ’d
dx
(
ğœ…(x)du
dx
)
v(x)dx + p(x)du
dxv(x) + q(x)u(x)v(x)
)
dx = âˆ«
b
a
f(x)v(x)dx
(4.80)
Use integration by parts on the first term
âˆ’âˆ«
b
a
d
dx
(
ğœ…(x)du
dx
)
v(x)dx = âˆ’
[
ğœ…(x)du
dxv(x)
]b
a + âˆ«
b
a
ğœ…(x)du
dx
dv
dxdx
(4.81)
Using (4.57b) and (4.57c), the outintegrated term can be written
ğœ…(a)du
dx(a)v(a) âˆ’ğœ…(b)du
dx(b)v(b) = (ğ›¼1u(a) + ğ›½1)v(a) âˆ’(ğ›¼2u(b) + ğ›½2)v(b)
(4.82)
With the BCs given here, we cannot restrict u(x) or v(x) to be zero at x = a or x = b.
Instead the values of u(x) and v(x) at the boundary points will come out from the
following weak formulation: Find u(x) âˆˆU such that

ANSATZ METHODS FOR BVPs
99
âˆ«
b
a
(ğœ…(x)du
dx
dv
dx + p(x)du
dxv(x) + q(x)u(x)v(x))dx + (ğ›¼1u(a)v(a) âˆ’ğ›¼2u(b)v(b))
= âˆ«
b
a
f(x)v(x)dx âˆ’(ğ›½1v(a) âˆ’ğ›½2v(b))
for all v(x) âˆˆU
(4.83)
where U is PC1(0, 1), i.e., all functions once piecewise continuously differentiable
on (0, 1). Hence, the BCs in (4.57) are not explicitly given but comes out as a conse-
quence of the weak formulation, hence the BCs are natural. Note that terms contain-
ing u, duâˆ•dx and v, dvâˆ•dx occur in the left hand side as quadratic terms, while terms
containing only v are collected in the right hand side.
Example 4.11.
The weak formulation of problem (4.32) is formulated as follows.
Starting from (4.78), the outintegrated term is
âˆ’uâ€²(1)v(1) + uâ€²(0)v(0) = (u(1) âˆ’1)v(1)
Hence, the weak formulation has the form: Find u(x) âˆˆU such that
âˆ«
1
0
uâ€²vâ€²dx + u(1)v(1) = âˆ«
1
0
f(x)v(x)dx + v(1),
for all v(x) âˆˆU
where U = PC1(0, 1). Both BCs are natural.
Now, use Galerkinâ€™s method on the weak formulation (4.83), i.e., let
uh(x) =
N
âˆ‘
j=1
cjğœ‘j(x),
vh(x) = ğœ‘i(x), i = 1, 2, â€¦ N
The coefficients cj are obtained from a linear system of algebraic equations
(Ağœ…+ P + Q + B)c = f
(4.84)
where the elements of the N Ã— N matrices Ağœ…, P, Q, B are
Ağœ…ij = âˆ«
b
a
ğœ…(x)dğœ‘i
dx
dğœ‘j
dx dx,
Pij = âˆ«
b
a
p(x)ğœ‘i
dğœ‘j
dx dx
Qij = âˆ«
b
a
q(x)ğœ‘i(x)ğœ‘j(x)dx,
Bij = ğ›¼1ğœ‘i(a)ğœ‘j(a) âˆ’ğ›¼2ğœ‘i(b)ğœ‘j(b)
(4.85)
and the right hand side is the N Ã— 1 vector f with the elements
fi = âˆ«
b
a
f(x)ğœ‘i(x)dx âˆ’ğ›½1ğœ‘i(a) + ğ›½2ğœ‘i(b)
(4.86)

100
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
If ğœ…(x) > 0, q(x) > 0, ğ›¼1 > 0, ğ›¼2 < 0, and p(x) â‰¡0, the linear system of equations
(4.84) is symmetric and positive definite. This special case is very common in appli-
cations and is found in, e.g., heat conduction, structural mechanics, diffusion, and
electromagnetics. Linear systems of equations with a symmetric and positive system
matrix can be solved with, e.g., Choleskyâ€™s method or some conjugate gradient-based
method, see Section A.5.
If p(x) â‰ 0, the linear equation system (4.84) is unsymmetric and other meth-
ods must be used, e.g., Gaussian elimination or the iterative GMRES method, see
Section A.5.
Example 4.12.
The interface problem in Example 4.10 is formulated in weak
form. Let T(z) = u(z) + T0. With this transformation, we obtain the essential BC
u(0) = 0. Find u(z) âˆˆU such that
âˆ«
L
0
ğœ…du
dz
dv
dzdz + âˆ«
L
0
2h
R u(z)v(z)dz + (u(L) + T0 âˆ’Tout)v(L)
= âˆ«
L
0
2h
R Toutv(z)dz âˆ’(T0 âˆ’Tout)v(L)
for all v âˆˆU, where U = PC1
[0](0, 1). The parameter ğœ…takes different values in the
two regions, i.e., ğœ…= ğœ…1, 0 < z < ğœ‰, and ğœ…= ğœ…2,
ğœ‰< z < L. Observe that the inter-
face BCs (4.59c) are automatically â€œbuilt inâ€ in the weak formulation.
In this section, we have stated the weak formulation and Galerkinâ€™s method with
integral expressions. A general, abstract way of formulation is based on Sobolev
spaces, see reference 4 in the bibliography.
Exercise 4.3.1. Given the BVP âˆ’uâ€² = f(x),
uâ€²(0) = 0,
u(1) = 0
0 < x < 1
present the weak formulation of the problem. Which BC is natural and which is
essential?
Exercise 4.3.2. Given the BVP âˆ’uâ€² = f(x),
u(0) = a,
uâ€²(1) = b
0 < x < 1.
Here the BCâ€™s are inhomogeneous. Present the weak formulation of this prob-
lem. Hint: Introduce the help function w(x) through u(x) = w(x) + a + bx, where
w(0) = 0, wâ€²(1) = 0
Exercise 4.3.3. Given the BVP âˆ’uâ€² = f(x),
u(0) = a,
u(1) = b
0 < x < 1.
Present the weak formulation of this problem. Hint: Find a transformation similar to
the one in Exercise 4.3.2.
4.3.3
The Finite Element Method
This section is not an extensive treatment of the FEM for solving BVPs in 1D. Instead
it is intended to be an overview of a method that can be generalized to problems in
2D (see Section 7.4).

ANSATZ METHODS FOR BVPs
101
So far we have not said anything about the basis functions. Obviously they influ-
ence the structure of the matrix A. When the FDM (4.27) is used, the matrix A is a
tridiagonal matrix. We should come down to something similar for the ansatz method,
if the methods are to be comparable with respect to computer storage and computer
time needed to solve Ac = b.
If we choose the ansatz solution to be a polynomial of degree N, e.g.,
Ìƒu(x) =
Nâˆ’1
âˆ‘
j=1
cjxj(x âˆ’1)
(4.87)
where the basis functions are ğœ‘j(x) = xj(x âˆ’1) fulfilling the BCs. It is easy to show
that this choice of basis functions will give a full matrix A, i.e., most elements Ai,j â‰ 0.
Assume we want our ansatz function to be a piecewise polynomial of degree one,
i.e., a function that is put together from straight lines in a continuous way at the nodes
xi, i = 1, 2, â€¦ , N as in the graph in Figure 4.11, where the stepsize hi can be variable
or constant, i.e., âˆ‘N
i=0 hi = 1 or h(N + 1) = 1.
The basis functions of the ansatz uh(x) = âˆ‘n
j=1 cjğœ‘j will also be piecewise polyno-
mials. If we want cj = uh(xj), we see that ğœ‘j must fulfill
ğœ‘j(xi) =
{
1,
if i = j
0,
if i â‰ j
(4.88)
Hence, the ansatz function uh(x) will be a piecewise linear interpolation polynomial
through the points (xi, uh(xi)). A graph of this basis function looks like the one shown
in Figure 4.12.
The derivative ğœ‘â€²
j(x) of the basis function has the graph shown in Figure 4.13.
x0
x1
x2
x3
xN âˆ’ 1
xN + 1
xN
x
Ëœu
Figure 4.11
A piecewise linear ansatz function
h
h
xj âˆ’ 1
xj
xj + 1
x
0
1
Ï†j
Figure 4.12
A piecewise linear basis function, a roof function

102
NUMERICAL METHODS FOR BOUNDARY VALUE PROBLEMS
h
h
xj âˆ’ 1
xj 
xj + 1
x
0
âˆ’1
h
1
h
Ï†â€²j
Figure 4.13
The derivative of a roof function
A few simple calculations using (4.74) give as result
Aij = âˆ’1
h,
j = i âˆ’1, j = i + 1
Aii = 2
h
(4.89)
Hence, the N Ã— N matrix A, the â€˜stiffness matrixâ€™ is the same as in (4.29) (apart from
the factor 1âˆ•h).
A = 1
h
â›
âœ
âœ
âœ
âœâ
2
âˆ’1
0
0
â€¦
âˆ’1
2
âˆ’1
0
â€¦
â€¦
â€¦
0
âˆ’1
2
âˆ’1
â€¦
0
0
âˆ’1
2
â
âŸ
âŸ
âŸ
âŸâ 
Stiffness is here related to a material property and not the concept â€œstiff â€ in connec-
tion with certain ODE problems (see Section 3.3.3). The right hand side vector f is
often called the load vector.
The computation of the right hand side f where
fi = âˆ«
xi+h
xiâˆ’h
f(x)ğœ‘i(x)dx
can be done approximately with, e.g., the trapezoidal method:
fi â‰ˆhf(xi)
(4.90)
Hence, for the model problem (4.20), we get exactly the same system of linear
equations (4.29) for the FDM and the FEM. This, however, is not true in general.
Exercise 4.3.4. Modify the calculations leading to A and f in the case that the step-
size is not constant, i.e., hi = xi+1 âˆ’xi.
Exercise 4.3.5. Given the BVP (4.57) with ğœ…(x) = 1, p(x) = 1, q(x) = 1, compute
the elements Ağœ…i,j, Pi,j, and Qi,j in (4.84).

BIBLIOGRAPHY
103
Exercise 4.3.6. Write a program to solve the BVP (4.32) with the FEM. Compare
with the FDM solution of the same problem.
BIBLIOGRAPHY
1. C. Moler, â€œNumerical Computing with MATLABâ€, Chapter 8, SIAM, 2004
2. G. Golub, J. Ortega, â€œScientific Computing and Differential Equationsâ€, Chapter 3, Aca-
demic Press, 1992
3. H.B. Keller, â€œNumerical Methods for Two-point Boundary Value Problemsâ€, Blaisdell,
London, 1968
4. K. Eriksson, D. Estep, P. Hansbo, C. Johnson, â€œComputational Differential Equationsâ€,
Studentlitteratur, 1996


5
PARTIAL DIFFERENTIAL EQUATIONS
This chapter is not intended to be an extensive treatment of mathematical properties
of partial differential equations (PDEs) but rather a survey of important definitions,
concepts, and results. For a more careful description, the reader may consult some of
the mathematical textbooks on PDEs referenced in the end of this chapter.
A general formulation of a system of PDEs expressed in vector form is
ğœ•u
ğœ•t = f
(
t, x, y, z, u, ğœ•u
ğœ•x , ğœ•u
ğœ•y , ğœ•u
ğœ•z , ğœ•2u
ğœ•x2 , ğœ•2u
ğœ•y2 , ğœ•2u
ğœ•z2 ,â€¦
)
(5.1)
The variables t, x, y, z, the independent variables, are defined in some region, bounded
or unbounded and the variable u, the dependent variable, is a solution of (5.1) if it
satisfies the PDEs for all t, x, y, z in the region. Among the independent variables,
t is used to denote time and x, y, z denote the space variables. If time is among the
independent variables, the PDE problem is called a time-dependent or an evolution
problem, if not the problem is called an equilibrium or a steady-state problem.
The solution of a PDE is called a field, a function that depends on time and space
or just space. The field is scalar valued if the PDE (5.1) is scalar and vector valued
if (5.1) is a system of PDEs.
A problem formulated in three space dimensions x, y, z is called a 3D problem
(three dimension).The mathematical and numerical treatment of a PDE is often easier
when formulated in 2Ds x, y or 1D x.
As was illustrated in Chapter 1, a PDE has infinitely many solutions. To obtain a
unique solution, we need to have initial and boundary conditions. It depends on the
character of the PDE what conditions should be given in order to have a well-posed
problem, i.e., a problem the solution of which is stable with respect to perturbations
in boundary and initial data.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

106
PARTIAL DIFFERENTIAL EQUATIONS
5.1
CLASSICAL PDE PROBLEMS
The classical PDEs presented in most textbooks are given below as problems (1â€“5).
They are all scalar linear PDEs with constant coefficients. They will be used as model
problems for numerical methods presented in later chapters.
1. Parabolic PDE in 1D (heat equation or diffusion equation):
ğœ•u
ğœ•t = ğœ…ğœ•2u
ğœ•x2 ,
0 < x < 1,
0 < t â‰¤tend
(5.2)
where ğœ…is a constant positive parameter.
Initial condition: u(x, 0) = u0(x), a known function of x.
Boundary conditions: u(0, t) = ğ›¼(t), u(1, t) = ğ›½(t), where ğ›¼(t) and ğ›½(t) are
known functions of t.
2. Hyperbolic PDE in 1D (wave equation):
ğœ•2u
ğœ•t2 = c2 ğœ•2u
ğœ•x2 ,
0 < x < 1,
0 < t â‰¤tend
(5.3)
where c is a constant parameter.
Initial conditions: u(x, 0) = u0(x), ğœ•u
ğœ•t (x, 0) = v0(x)
Boundary conditions: u(0, t) = ğ›¼(t), u(1, t) = ğ›½(t)
3. Hyperbolic first-order PDE in 1D (advection equation):
ğœ•u
ğœ•t + ağœ•u
ğœ•x = 0,
0 < x < 1,
0 < t â‰¤tend
(5.4)
where a is a constant positive parameter.
Initial condition: u(x, 0) = u0(x)
Boundary condition: u(0, t) = ğ›¼(t)
4. Elliptic PDE in 2D (Poissonâ€™s equation on the unit square)
ğœ•2u
ğœ•x2 + ğœ•2u
ğœ•y2 = f(x, y),
(x, y) âˆˆÎ© = {(x, y) âˆ¶0 < x, y < 1}
(5.5)
Boundary condition: u = 0 on ğœ•Î©, the boundary of Î©
The important special case when f(x, y) â‰¡0 in (5.5) is called Laplaceâ€™s
equation.
5. Eigenvalue problem in 2D: (Helmholtzâ€™ equation on the unit square)
ğœ•2u
ğœ•x2 + ğœ•2u
ğœ•y2 = ğœ†u,
(x, y) âˆˆÎ© = {(x, y) âˆ¶0 < x, y < 1}
(5.6)
Boundary condition: u = 0 on ğœ•Î©.

CLASSICAL PDE PROBLEMS
107
The equations above are special cases of a general linear second-order PDE:
ağœ•2u
ğœ•x2 + 2b ğœ•2u
ğœ•xğœ•y + cğœ•2u
ğœ•y2 + d1
ğœ•u
ğœ•x + d2
ğœ•u
ğœ•y + eu = f(x, y)
(5.7)
which is called, assuming that at least one of a, b, c is â‰ 0
hyperbolic
if
b2 âˆ’ac > 0
parabolic
if
b2 âˆ’ac = 0
elliptic
if
b2 âˆ’ac < 0
If a = b = c = 0, but d1 â‰ 0 and d2 â‰ 0, the PDE is hyperbolic.
In a linear PDE of type (5.7), the coefficients a, b, c, d1, d2, e are constant or depend
on (x, y). For a time-dependent PDE, change y to t. If f(x, y) â‰¡0, (5.7) is homogenous,
otherwise inhomogeneous.
Example 5.1. (The Eulerâ€“Tricomi PDE).
ğœ•2u
ğœ•x2 = xğœ•2u
ğœ•y2
This is an example where the coefficient depends on (x, y). The PDE is hyperbolic
when x > 0 and elliptic when x < 0. Francesco Tricomi was an Italian mathematician
active in the middle of the 20th century.
Example 5.2. (The Prandtlâ€“Glauert equation).
Compressible, inviscid flow over a thin airfoil can be modeled in 2D by the PDE
(1 âˆ’M2
âˆ)ğœ•2Î¦
ğœ•x2 + ğœ•2Î¦
ğœ•y2 = 0
where Mâˆis the Mach number and Î¦ is the velocity potential. This PDE is hyperbolic
if Mâˆ> 1 (supersonic flow) and elliptic if Mâˆ< 1 (subsonic flow). Ludwig Prandtl
was a German and Hermann Glauert was a British physicist active in the first half of
the 20th century.
Example 5.3.
A fundamental solution of the wave equation (5.3) is obtained from
the ansatz (compare with Example 4.6)
u(x, t) = eiğœ”tv(x)
Insert this ansatz into (5.3) and the following ODE for v(x) is obtained
d2v
dx2 + k2v = 0

108
PARTIAL DIFFERENTIAL EQUATIONS
where k = ğœ”âˆ•c is called the wave number. A particular solution of (5.3) can then be
written
u(x, t) = ei(ğœ”tÂ±kx) = eiğœ”(tÂ±cx)
which is a traveling wave, a very common model for, e.g., energy transfer in physics,
such as mechanical, electromagnetic, or quantum mechanical waves.
In an extended definition, the space-derivative terms are modified in a way that
admits nonlinear versions of the generic PDEs:
1. Nonlinear heat (or diffusion) equation in 1D:
ğœ•u
ğœ•t = ğœ•
ğœ•x
(
ğœ…(u)ğœ•u
ğœ•x
)
(5.8)
2. Nonlinear wave equation in 1D:
ğœ•2u
ğœ•t2 = c2(u)ğœ•2u
ğœ•x2
(5.9)
3. Nonlinear advection equation in 1D:
ğœ•u
ğœ•t + a(u)ğœ•u
ğœ•x = 0
(5.10)
4. Nonlinear Laplaceâ€™s equation in 2D:
ğœ•
ğœ•x
(
ğœ…x(u)ğœ•u
ğœ•x
)
+ ğœ•
ğœ•y
(
ğœ…y(u)ğœ•u
ğœ•y
)
= 0
(5.11)
Analytic solutions to PDEs can seldom be found but exist for the linear model
problems.Usually analytic solutions are complicated consisting of, e.g., infinite series
expansions or integral expressions.
For Cauchy formulations (initial values are given for âˆ’âˆ< x < âˆ) of the
time-dependent problems (1â€“3) analytic solutions can be formulated. For Laplaceâ€™s
equation, analytic solutions exist when the region Î© has a simple geometry, e.g., a
square or a circle.
Augustin Louis Cauchy,Pierre Simon de Laplace, and Simeon Denis Poisson were
French mathematicians active in the beginning of the 19th century.
1. The heat equation, with Cauchy conditions
ğœ•u
ğœ•t = ğœ…ğœ•2u
ğœ•x2 , u(x, 0) = u0(x), âˆ’âˆ< x < âˆ, t > 0
The solution can be written as an integral
u(x, t) =
1
2
âˆš
ğœ‹ğœ…t âˆ«
+âˆ
âˆ’âˆ
eâˆ’(xâˆ’s)2âˆ•4ğœ…tu0(s)ds
(5.12)

CLASSICAL PDE PROBLEMS
109
âˆ’1
âˆ’0.5
0
0.5
1
0
0.5
1
1.5
2
2.5
3
x
u
t = 0.01
t = 0.05
t = 0.2
âˆ’1
0
1
0
0.1
0.2
0
1
2
3
x
t
u(x, t)
Figure 5.1
The fundamental solution of the heat equation, ğœ…= 1
provided the integral exists for the given function u0(x). In the special case,
u0(x) = ğ›¿(x), i.e., the Dirac delta-function at x = 0, we obtain the fundamental
solution (Figure 5.1)
u(x, t) =
1
2
âˆš
ğœ‹ğœ…t
eâˆ’x2âˆ•4ğœ…t
(5.13)
The problem is well posed if t > 0 and ill posed if t < 0.
2. The wave equation with Cauchy conditions
ğœ•2u
ğœ•t2 = c2 ğœ•2u
ğœ•x2 , u(x, 0) = u0(x), ğœ•u
ğœ•t (x, 0) = v0(x), âˆ’âˆ< x < âˆ
has the following solution, also called dâ€™Alambertâ€™s solution
u(x, t) = 1
2(u0(x âˆ’ct) + u0(x + ct)) + 1
2c âˆ«
x+ct
xâˆ’ct
v0(s)ds
(5.14)
For the initial values u0(x) = eâˆ’x2, v0(x) = 0 and the parameter value c = 1, the
solution is (see Figure 5.2)
u(x, t) = 1
2
(
eâˆ’(xâˆ’t)2 + eâˆ’(x+t)2)
This problem is well posed in both t directions, i.e., both t > 0 and t < 0.
3. The advection equation and its solution are presented in Chapter 1.
4. Laplaceâ€™s equation on the unit square
ğœ•2u
ğœ•x2 + ğœ•2u
ğœ•y2 = 0,
(x, y) âˆˆÎ© = {(x, y) âˆ¶0 < x, y < 1}

110
PARTIAL DIFFERENTIAL EQUATIONS
âˆ’5
0
5
0
0.2
0.4
0.6
0.8
1
x
u
t = 4
t = 2
t = 4
t = 2
t = 0
â€“>
<â€“
âˆ’5
0
5
0
2
4
0
0.5
1
x
t
u(x, t)
Figure 5.2
Dâ€™Alembertâ€™s solution of the wave equation, c = 1
with the following boundary conditions (one of which is nonhomogeneous)
u(0, y) = u(1, y) = 0, 0 < y < 1,
u(x, 0) = 0, u(x, 1) = g(x), 0 â‰¤x â‰¤1
has the following infinite series solution obtained with the analytic method sep-
aration of variables
u(x, t) =
âˆ
âˆ‘
k=1
ck sin(kğœ‹x) sinh(kğœ‹y)
(5.15)
where ck are coefficients given by integral expressions. With the principle of
superposition, the analytic solution of Laplaceâ€™s equation with all four bound-
aries having nonhomogeneous boundary conditions can be written as the sum
of four sums of type (5.15).
5.2
DIFFERENTIAL OPERATORS USED FOR PDES
The PDEs of science and engineering are formulated in 3D and often complicated to
present in component form. Therefore, it is convenient to use differential operators to
make the notation more compact. The frequently used differential operators are the
gradient, the divergence, the rotation (curl), and the laplacian.
Let Î¦ = Î¦(x, y, z) be a scalar field, F = (P(x, y, z), Q(x, y, z), R(x, y, z))T be a vector
field, and (x, y, z) the usual cartesian coordinates. The differential operator âˆ‡(nabla)
is defined as
âˆ‡=
(
ğœ•
ğœ•x,
ğœ•
ğœ•y, ğœ•
ğœ•z
)T
The differential operators are defined as
grad Î¦ = âˆ‡Î¦ =
(
ğœ•Î¦
ğœ•x , ğœ•Î¦
ğœ•y , ğœ•Î¦
ğœ•z
)T
(5.16)

DIFFERENTIAL OPERATORS USED FOR PDES
111
div F = âˆ‡â‹…F = ğœ•P
ğœ•x + ğœ•Q
ğœ•y + ğœ•R
ğœ•z
(5.17)
curl F = âˆ‡Ã— F =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
ğœ•R
ğœ•y âˆ’ğœ•Q
ğœ•z
ğœ•P
ğœ•z âˆ’ğœ•R
ğœ•x
ğœ•Q
ğœ•x âˆ’ğœ•P
ğœ•y
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
(5.18)
div grad Î¦ = Î”Î¦ = ğœ•2Î¦
ğœ•x2 + ğœ•2Î¦
ğœ•y2 + ğœ•2Î¦
ğœ•z2
(5.19)
where Î” is known as the laplacian, which can also be written as âˆ‡â‹…âˆ‡or âˆ‡2.
Observe that the notations âˆ‡and âˆ‡2 are also used as operators for backward dif-
ferentiation approximations, see Section 3.4.
In 2D, the correspondingoperators have to be modified.Let Î¦ = Î¦(x, y) be a scalar
field and F = (P(x, y), Q(x, y))T be a vector field. Then,
grad Î¦ = âˆ‡Î¦ =
(
ğœ•Î¦
ğœ•x , ğœ•Î¦
ğœ•y
)T
(5.20)
div F = âˆ‡â‹…F = ğœ•P
ğœ•x + ğœ•Q
ğœ•y
(5.21)
curl F = âˆ‡Ã— F = ğœ•Q
ğœ•x âˆ’ğœ•P
ğœ•y
(5.22)
div grad Î¦ = Î”Î¦ = ğœ•2Î¦
ğœ•x2 + ğœ•2Î¦
ğœ•y2
(5.23)
Two important results from vector analysis are
If curl F = 0, there exists a potential function Î¦ satisfying F = âˆ‡Î¦.
If div F = 0, there exists a vector potential A satisfying F = curl A.
The operators grad, div, and curl have physical interpretations. The gradient âˆ‡Î¦ is
a measure of the steepness of Î¦ is in the x,y, and z directions, the div-operator can
be interpreted as the source strength of the field F and the curl-operator corresponds
to the rotation strength of a velocity field v. For further discussion on these three
operators, see Section A.4.
All definitions (5.16)â€“(5.23) are formulated in cartesian coordinates (x, y, z). In
applications, however, it is sometimes suitable to use
cylindrical coordinates (r, ğœ‘, z): x = r cos(ğœ‘), y = r sin(ğœ‘), z = z
spherical
coordinates
(r, ğœƒ, ğœ‘):
x = r sin(ğœƒ) cos(ğœ‘),
y = r sin(ğœƒ) sin(ğœ‘),
z = r cos(ğœƒ).

112
PARTIAL DIFFERENTIAL EQUATIONS
Ë†n
âˆ‡u
âˆ‚u
âˆ‚n
Figure 5.3
The geometrical meaning of the normal derivative
We refer to mathematical textbooks for deriving the transformations leading to the
forms of the operators expressed in these coordinates. For use in coming chapters,
however, the laplacian in 3D is presented for the three coordinate systems:
Î”Î¦ = ğœ•2Î¦
ğœ•x2 + ğœ•2Î¦
ğœ•y2 + ğœ•2Î¦
ğœ•y2
(5.24a)
Î”Î¦ = 1
r
ğœ•
ğœ•r
(
rğœ•Î¦
ğœ•r
)
+ 1
r2
ğœ•2Î¦
ğœ•ğœ‘2 + ğœ•2Î¦
ğœ•z2
(5.24b)
Î”Î¦ = 1
r2
ğœ•
ğœ•r
(
r2 ğœ•Î¦
ğœ•r
)
+
1
r2 sin(ğœƒ)
ğœ•
ğœ•ğœƒ
(
sin(ğœƒ)ğœ•Î¦
ğœ•ğœƒ
)
+
1
r2sin2(ğœƒ)
ğœ•2Î¦
ğœ•ğœ‘2
(5.24c)
Observe that the coefficients depend on r and r, ğœƒrespectively, hence they are vari-
able, but the PDEs are still linear.
Another differential operator used in 2D and 3D boundaryconditions is the normal
derivative. It is defined as the projection of the gradient in a boundary point onto the
outward normal unit vector Ì‚n from that point (see Figure 5.3).
ğœ•u
ğœ•n = (âˆ‡u) â‹…Ì‚n
(5.25)
Exercise 5.2.1. Given the following PDEs. Investigate for each one if it is
parabolic, hyperbolic, or elliptic.
a) ğœ•u
ğœ•t = ğœ•2u
ğœ•x2 + u, b) ğœ•2u
ğœ•x2 + ğœ•2u
ğœ•y2 = âˆ’1, c) ğœ•u
ğœ•t + uğœ•u
ğœ•x = 0, d) ğœ•u
ğœ•t + ğœ•u
ğœ•x = ğœ•2u
ğœ•x2 + u
Exercise 5.2.2. Given the PDE problem
ğœ•u
ğœ•t + ğœ•u
ğœ•x = ğœ•2u
ğœ•x2 ,
u(0, t) = 1, u(1, t) = 0, u(x, 0) = u0(x)
Show that the first-order space-derivative term in the PDE can be eliminated by
choosing ğ›¼appropriately in the transformation u = veğ›¼x. Formulate the PDE for the
variable v and the corresponding initial and boundary conditions.

DIFFERENTIAL OPERATORS USED FOR PDES
113
Exercise 5.2.3. Verify that Laplaceâ€™s equation in 2D polar coordinates(r, ğœ‘), where
x = r cos ğœ‘, y = r sin ğœ‘, is
ğœ•2u
ğœ•r2 + 1
r
ğœ•u
ğœ•r + 1
r2
ğœ•2u
ğœ•ğœ‘2 = 0
Show that that the sum of the first two terms can be written
1
r
ğœ•
ğœ•r
(
rğœ•u
ğœ•r
)
Exercise 5.2.4. Show that the first term in the spherical laplacian can be written
1
r2
ğœ•
ğœ•r
(
r2 ğœ•u
ğœ•r
)
= ğœ•2u
ğœ•r2 + 2
r
ğœ•u
ğœ•r = 1
r
ğœ•2(ru)
ğœ•r2
Exercise 5.2.5. Spherical waves from a point source are modeled by the PDE
ğœ•2u
ğœ•t2 = c2
(
ğœ•2u
ğœ•r2 + 2
r
ğœ•u
ğœ•r
)
Show that this PDE is equivalent to the PDE
ğœ•2(ru)
ğœ•t2
= c2 ğœ•2(ru)
ğœ•r2
that has the general solution
u(r, t) = 1
r (f(r âˆ’ct) + g(r + ct))
where f(r) and g(r) are arbitrary twice differentiable functions.
Exercise 5.2.6. Show that the fundamental solution (5.13) satisfies the heat
equation.
Exercise 5.2.7. Show that dâ€™Alembertâ€™s solution (5.14) satisfies the wave equation.
Show it first for v0 â‰¡0.
Exercise 5.2.8. Use separation of variables to show that the solution of problem (4)
has the series solution (5.15). Derive the integral expressions for the coefficients ck.
Exercise 5.2.9. Show
that
u(x, y) = sin(iğœ‹x) sin(jğœ‹y), i = 1, 2,â€¦ j = 1, 2,â€¦
are solutions (eigenfunctions) to model problem (5). Calculate the corresponding
eigenvalues.

114
PARTIAL DIFFERENTIAL EQUATIONS
Exercise 5.2.10. Show the following differential operator relations:
a) div (âˆ‡u) = Î”u
b) div (curl u) = 0, i.e., the divergence of a rotation equals zero.
c) curl (âˆ‡u) = 0, i.e., the rotation of a gradient equals zero.
d) div (ğœŒu) = ğœŒdiv u + âˆ‡ğœŒâ‹…u
e) (u â‹…âˆ‡)u = 1
2âˆ‡(u â‹…u) + (curl u) Ã— u
f) Î”u = âˆ‡(div u) âˆ’(curl (curl u))
g) div (uuT) = u(div u) + (u â‹…âˆ‡)u. The divergence of the matrix uuT is a vector
where component i is the divergence of row i in uuT
5.3
SOME PDEs IN SCIENCE AND ENGINEERING
In this section, some well-known PDEs from different applications in science and
engineeringare presented. These equationsexhibit a mathematicalbeauty in the sense
that they can be written compactly on a few lines. However, they are complicated to
treat both analytically and numerically and usually they have to be simplified both
geometrically (from 3D to 2D or even 1D) and analytically (by introducing simpli-
fying modeling assumptions ) before numerical treatment is possible.
In this section, initial and boundary conditions are omitted as they can be of very
many different types. Examples of initial and boundary conditions are shown in the
chapters to follow.
5.3.1
Navierâ€“Stokes Equations for Incompressible Flow
Navierâ€“Stokes equations are fundamental in aerodynamics, hydrodynamics,
meteorology, and other applications where the flow of a gas or a liquid is modeled.
They are based on Newtonâ€™s second law for deformable bodies together with a
constitutive equation stating that the shear stresses are proportional to the velocity
gradients. The equations are complicated in their most general form. Therefore, they
are here presented under the condition that the density ğœŒ(kgâˆ•m3) and the dynamic
viscosity ğœ‡(N â‹…sâˆ•m2) of the fluid are constant:
div u = 0
(5.26a)
ğœŒ
(ğœ•u
ğœ•t + (u â‹…âˆ‡)u
)
= ğœŒg âˆ’âˆ‡p + ğœ‡Î”u
(5.26b)
In the PDEs (5.26), u = (u1, u2, u3)T (mâˆ•s) is the velocity field of the flow, p (Nâˆ•m2)
the pressure in the flow, and g (mâˆ•s2) the gravitational acceleration.
The first equation expresses conservation of mass and the second conservation of
linear momentum (Newtonâ€™s second law).
The equations (5.26) constitute four PDEs for the four unknowns u, v, w, and p in
incompressible flow (ğœŒconstant). The incompressible Navierâ€“Stokes equations are

SOME PDEs IN SCIENCE AND ENGINEERING
115
nonlinear PDEs classified as mixed hyperbolicâ€“parabolic. They were first derived by
the French physicist Louis Navier and the Irish mathematician George Stokes in the
beginning of the 19th century.
Associated with Navierâ€“Stokes equation is Reynolds number Re, an important
dimensionless parameter Re = L â‹…U â‹…ğœŒâˆ•ğœ‡introduced by the Irish engineer Osborne
Reynolds in the second half of the 19th century. In the formula, L is a characteristic
length of the region and U a characteristic velocity. Reynolds number gives a charac-
terization of the flow. For small Re, say Re < 1, we have laminar flow while a large
Re number corresponds to turbulent flow. The numerical treatment of Navierâ€“Stokes
equations for large Re-numbers is difficult as both turbulence and moving transition
layers make it tricky to resolve the equations with a numerical method.
Depending on the physical assumptions, Navierâ€“Stokes equations can be simpli-
fied to less complex PDEs. For a small Reynolds number corresponding to, e.g., slow
velocity or large viscosity, the Navierâ€“Stokes equations in steady (time-independent)
flow are reduced to Stokes equations
ğœ‡Î”u âˆ’âˆ‡p + ğœŒg = 0,
div u = 0
(5.27)
This is an elliptic problem consisting of four equations for the four unknowns
u = (u, v, w)T and p.
In case the flow can be regarded as irrotational, nonviscous, and steady, it is called
potential flow. The reason is that if curl u = 0, there is a potential function Î¦ such
that u = âˆ‡Î¦. This relation together with div u = 0 gives Laplace equation for Î¦
Î”Î¦ = 0
(5.28)
When appropriate BCs has been added to (5.28), the flow field is obtained from the
solution Î¦ from u = âˆ‡Î¦. We see that the pressure p is not present in this flow model.
In 2D, a lot of analysis has been donewith conformalmapping,i.e., transformationsin
the complex plane. An example of potential flow is given in Chapter 7, Example 7.2.
Yet another simplification of Navierâ€“Stokes equations is obtained for steady, non-
viscous, and irrotational flow with Bernoulliâ€™s equation
1
2ğœŒU2 + p = constant
(5.29)
This often used model for, e.g., large pipe systems where the wall-friction is neglected
is not even a differential equation. It gives no information about the flow field, just
the size of the velocity U. Newtonâ€™s second law is not needed to derive this equation,
just hydrostatical relations.
5.3.2
Eulerâ€™s Equations for Compressible Flow
Often variants of the Navierâ€“Stokes equations are used depending on the physical
process to be modeled. For a compressible gas (ğœŒnot constant) and inviscid (without
inner friction, i.e., ğœˆ= 0), we have the compressible Euler equations:
ğœ•ğœŒ
ğœ•t + div(ğœŒu) = 0
(5.30a)

116
PARTIAL DIFFERENTIAL EQUATIONS
ğœ•(ğœŒu)
ğœ•t
+ div(ğœŒuuT) + âˆ‡p = 0
(5.30b)
ğœ•E
ğœ•t + div((E + p)u) = 0
(5.30c)
E =
p
ğ›¾âˆ’1 + 1
2ğœŒ(u2
1 + u2
2 + u2
3)
(5.30d)
where uuT is the outer product, u = (u1, u2, u3)T, and (uu)ij = uiuj. The quantity
E (Jâˆ•m3) is the total energy density and ğ›¾is a constant depending on the gas studied
(ğ›¾= 1.4 for air).
The equations (5.26) constitute five PDEs and one algebraic equation for the six
unknowns ğœŒ, u1, u2, u3, E, and p. The equations were first derived by Leonard Euler in
1755. They are hyperbolic and the solutions can contain propagating shocks, narrow
regions separating continuous flow regions. Across the shock, there are rapid changes
in pressure, velocity, and density. The resolution of shocks puts special demands on
the numerical methods.
5.3.3
The Convectionâ€“Diffusionâ€“Reaction Equations
The convectionâ€“diffusionâ€“reaction equations (CDR equations) model processes
where the transport of chemical substances and energy is governed by convection,
diffusion, and reactions. Coupled to the mass conservation equations, expressed in
units of concentrations, there is an energy conservation equation formulated for the
temperature.
ğœ•c
ğœ•t + div (cuT) = div (Dâˆ‡c) + Sr(c, T)
(5.31a)
ğœŒC
(ğœ•T
ğœ•t + div (Tu)
)
= div (ğœ…âˆ‡T) + Î”HT Sr(c, T)
(5.31b)
In the CDR equations (5.31), c (molâˆ•m3) is a vector of concentrations of the chemical
substances taking part in a set of reactions, u (m/s) the velocity field (usually assumed
to be known, otherwise the CDR equations must be coupled to the Navierâ€“Stokes
equations), ğœŒ(kgâˆ•m3) the density of the mixture, D (m2âˆ•s) the diffusion coefficient
(or the diffusion matrix), r[molâˆ•(m3 â‹…s)] the reaction rate terms (see Chapter 2),
S the stoichiometric matrix, T(K) the temperature, C[Jâˆ•(kg â‹…K)] the heat capacity,
ğœ…[Jâˆ•(m â‹…K â‹…s)] the heat conduction coefficient and Î”H(Jâˆ•mol) the enthalpies of the
reactions, Î”Hi < 0 if the reaction is endotermic (energy consuming), and Î”Hi > 0 if
the reaction is exotermic (energy producing).
The CDR equations model processes in chemical engineering, e.g., combustion,
industrial reactors,and environmentalprocesses such as atmosphericchemistry.From
these equations, the variations in substance concentrations and temperature of a pro-
cess can be computed. The PDEs are parabolicâ€“hyperbolic and often stiff and non-
linear with a jacobian being large and sparse.

SOME PDEs IN SCIENCE AND ENGINEERING
117
5.3.4
The Heat Equation
The heat equation is a special case of the CDR equations above.
ğœ•T
ğœ•t = div (ğ›¼âˆ‡T) + Q(x, y, z)
(5.32)
where ğ›¼(m2âˆ•s) is the thermal diffusivity and Q(x, y, z) (Kâˆ•s) a source or sink term
that accounts for the heat production or consumption in the medium.
The heat equation was formulated in 1807 by the French physicist Joseph Fourier.
He also invented a method for analytical solution of this equation in some cases,
known as the Fourier method, published 1822.
5.3.5
The Diffusion Equation
The diffusion equation is mathematically similar to the heat equation, also being a
special case of the CDR equations.
ğœ•c
ğœ•t = div (Dâˆ‡c) + q(x, y, z)
(5.33)
where c (molâˆ•m3) is the concentration of the substance being diffused, D (m2âˆ•s) the
diffusion coefficient, and q(x, y, z) [molâˆ•(m3 â‹…s)] a source or sink term that accounts
for substance production or consumption.
The diffusion equation, also called Fickâ€™s second law, was formulated in 1855 by
the German physicist Adolf Fick.
5.3.6
Maxwellâ€™s Equations for the Electromagnetic Field
Maxwellâ€™s equations model the relation between the electric and magnetic fields gen-
erated by electric charges.
curl H = j + ğœ•D
ğœ•t
(5.34a)
curl E = âˆ’ğœ•B
ğœ•t
(5.34b)
In the PDEs (5.34), H is the magnetic field strength (Aâˆ•m), E the electric field
strength (V/m), B the magnetic flux density (Vs/m2), D the electric flux den-
sity (As/m2), and j the current density (A/m2). Maxwellâ€™s equations consist of
6 equations and 12 unknowns, H, E, B, and D. The missing equations are 6
constitutive equations, i.e., the relation between the electric variables and the
magnetic variables, e.g., the equations valid in vacuum D = ğœ–0E and B = ğœ‡0H,
where ğœ–0 and ğœ‡0 are the electric permittivity and magnetic permeability. If j is
given, Maxwellâ€™s equations can be solved assuming suitable ICs and BCs are
provided.

118
PARTIAL DIFFERENTIAL EQUATIONS
The equations (5.34) were first invented by the Scottish physicist James Maxwell
in 1867. Maxwellâ€™s equations are hyperbolic.
The following equation, known as the charge continuity equation, is fundamental
ğœ•ğœŒ
ğœ•t + div j = 0
(5.35)
where ğœŒis the electric charge density (As/m3).
Two more equations are usually associated with Maxwellâ€™s equations
div B = 0
(5.36a)
div D = ğœŒ
(5.36b)
These equations are consequences of (5.34) and (5.35) under suitable assumptions.
The force acting on an electric particle with charge q in an electromagnetic field
is given by the Lorentz-force expression
F = q(E + v Ã— B)
(5.37)
If j = 0, Maxwellâ€™s equations in vacuum are
curl H = ğœ–0
ğœ•E
ğœ•t
(5.38a)
curl E = âˆ’ğœ‡0
ğœ•H
ğœ•t
(5.38b)
From these two equations, the following PDE is derived
Î”E âˆ’1
c2
ğœ•2E
ğœ•t2 = 0
(5.39)
and a similar equation for H. The parameter c (m/s) is the wave propagation speed
c = (ğœ–0ğœ‡0)âˆ’1âˆ•2, speed of light 299792458m/s. The equation (5.39) is called the vector
wave equation and is a system of hyperbolic PDEs. The solutions are usually smooth,
but numerical methods are time consuming as very many periods have to be computed
to follow the rays and each period must be accurately enough represented.
5.3.7
Acoustic Waves
The propagation equation for acoustic waves has the form
Î”p âˆ’1
c2
ğœ•2p
ğœ•t2 = 0
(5.40)
where p (N/m2) is the pressure and c (m/s) the speed of sound.
Equation (5.40) is a scalar wave equation, a hyperbolic PDE. It is similar to the
equation for a vibrating string, presented in Chapter 9.

SOME PDEs IN SCIENCE AND ENGINEERING
119
5.3.8
SchrÃ¶dingerâ€™s Equation in Quantum Mechanics
SchrÃ¶dingerâ€™s equation models the wave nature of small particles, e.g., electrons and
atoms.
âˆ’â„2
2mÎ”Î¨ + V(r, t)Î¨ = iâ„ğœ•Î¨
ğœ•t
(5.41)
where â„= hâˆ•2ğœ‹, h is the Planckâ€™s constant = 6.626068m2 â‹…kg/s, m the mass of the
particle, and V(r, t) a potential function that affects the movement of the particle.
This equation is hyperbolic and was first proposed by the Austrian physicist Erwin
SchrÃ¶dinger in 1926.
In (5.41), Î¨(r, t) is a complex wavefunction, representing a propagating wave for
a particle. This function is used to compute the probability of finding the particle in
a certain domain in space. The solutions of the SchrÃ¶dinger equation are oscillating
and usually very smooth. The computational complexity increases immensely with
the number of particles studied.
Often the interest is not directed to the wave function Î¨ itself but rather to the
possible energy levels E of the particle,e.g., the electron states of an atom or molecule,
leading to eigenvalue problems of the type
(
âˆ’â„2
2mÎ” + V(r)
)
Î¨ = EÎ¨
(5.42)
The computation of the E values must be done with high accuracy in order to be able
to distinguish between the energy levels. This puts certain requirements on the grid
used in the discretization of (5.42).
5.3.9
Navierâ€™s Equations in Structural Mechanics
Navierâ€™s equations are the fundamental PDEs in elasticity theory. They model the
deformations of a linearly elastic body that is exposed to external forces
ğœŒğœ•2u
ğœ•t2 =
E
2(1 + ğœˆ)
(
Î”u +
1
1 âˆ’2ğœˆâˆ‡(div u
)
+ f
(5.43)
These equations are hyperbolic and were formulated by Louis Navier in France 1821.
In case the problem is time independent, the equations are elliptic.
In (5.43), u is the displacement vector, i.e., u = (u, v, w)T, where u (m) is the dis-
placement in the x direction, v (m) in the y direction, and w (m) in the z direction. E
(N/m2) is the elasticity module, ğœˆ[] the contraction parameter (also called Poissonâ€™s
number), f (N/m3) the force field acting on the body responsible for the displace-
ments, and ğœŒ(kg/m3) the density of the body.

120
PARTIAL DIFFERENTIAL EQUATIONS
5.3.10
Blackâ€“Scholes Equation in Financial Mathematics
The Blackâ€“Scholes equation presented in 1973 models the value u of a European
stock option
ğœ•u
ğœ•t + 1
2ğœ2x2 ğœ•2u
ğœ•x2 + rxğœ•u
ğœ•x âˆ’ru = 0
(5.44)
where x is the underlying asset value, r the continually compounding interest rate,
and ğœthe volatility (standard deviation of the rate of return of the asset).
Exercise 5.3.1. Verify that Navierâ€“Stokes equation (5.26) in 1D is
ğœŒ
(ğœ•u
ğœ•t + uğœ•u
ğœ•x
)
= âˆ’ğœ•p
ğœ•x + ğœ‡ğœ•2u
ğœ•x2 + ğœŒf
Exercise 5.3.2. In case p = 0 and f = 0 in Exercise 5.3.1, we obtain Burgerâ€™s
equation
ğœ•u
ğœ•t + uğœ•u
ğœ•x = ğœˆğœ•2u
ğœ•x2
where the parameter ğœˆ= ğœ‡âˆ•ğœŒis the kinematic viscosity.
a) Is this PDE elliptic, parabolic, or hyperbolic?
b) If ğœ•u
ğœ•t = 0, the problem is time independent. Solve the ODE with the BCs
u(0) = 1,
du
dx(0) = 0
c) With the transformation
u = âˆ’2ğœˆ1
v
ğœ•v
ğœ•x,
the nonlinear PDE is transformed into a linear PDE
ğœ•v
ğœ•t = ğœˆğœ•2v
ğœ•x2 + C(t)v.
Exercise 5.3.3. Formulate Eulerâ€™s equations (5.30) in 1D.
Exercise 5.3.4. Formulate the CDR equation in 1D assuming that there is only one
chemical substance with concentration c involved, T is constant, and the rate function
is given by r(c) = kc, where k is the rate constant. In chemical engineering,this model
is known as the tubular reactor model.

NUMERICAL SOLUTION OF PDES, SOME GENERAL COMMENTS
121
Exercise 5.3.5. Formulate the heat equation in 2D, cylindrical coordinates.
Exercise 5.3.6. Show that Maxwellâ€™s equation (5.38a) and (5.38b) for plane waves
propagating in the x direction with the only components Ez â‰ 0 and Hy â‰ 0 satisfy
the PDE system
ğœ•Hy
ğœ•t
= 1
ğœ‡0
ğœ•Ez
ğœ•x
ğœ•Ez
ğœ•t = 1
ğœ–0
ğœ•Hy
ğœ•x
Also show that both Ez and Hy satisfy the wave equation.
5.4
INITIAL AND BOUNDARY CONDITIONS FOR PDEs
The PDEs presented in Section 5.3 have all been given without initial or boundary
conditions. Such conditions are needed for a unique solution and hence necessary for
numerical computation. Initial conditions define the state of a system at time t = 0.
Boundary conditions specify the state of a problem against the environment. If the
space domain is infinite, a Cauchy problem, it must be truncated to a finite domain
before numerical treatment.
Boundary conditions can be of different types, e.g., Dirichlet, Neuman, mixed,
periodic, numerical, absorbing, and reflecting. Examples of such conditions are pre-
sented in the chapters to follow.
For a given PDE, the initial and boundary conditions cannot be given arbitrarily;
they should be given so that the problem is well posed. This means that the solution
is continuous with respect to the given conditions.
5.5
NUMERICAL SOLUTION OF PDES, SOME GENERAL COMMENTS
When solving ODEs, there are some general methods, e.g., explicit and implicit
Rungeâ€“Kutta methods, that could be applied to most problems, nonstiff and stiff ODE
systems. The situation is different with PDEs. The classification (parabolic, elliptic,
hyperbolic) determines the type of method that should be used. Some comments on
numerical properties for linear PDEs are given below. For nonlinear PDEs, there will
be additional difficulties of various types.
A parabolic PDE can be approximated by an ODE system, being large, sparse, and
stiff, i.e., implicit methods are needed where the sparsity must be taken into account.
An elliptic PDE can be approximated by a large system of algebraic equations,
being very sparse, i.e., numerical methods specially designed for such equations are
needed.
A hyperbolic PDE needs special attention as a solution may contain a propagating
discontinuity. Special methods are needed to capture the discontinuity and to properly
conserve different quantities.

122
PARTIAL DIFFERENTIAL EQUATIONS
BIBLIOGRAPHY
Mathematical textbooks on PDEs
1. S.J. Farlow, â€œPartial Differential Equations for Scientists and Engineersâ€, Wiley, 1982
2. F. John, â€œPartial Differential Equationsâ€, Springer, 1991
3. A.D. Snider, â€œPartial Differential Equations, Sources and Solutionsâ€, Prentice Hall, 1999
4. H.F. Davis, A.D. Snider, â€œIntroduction to Vector Analysisâ€, Quantum, 1995
Textbooks on mathematics and mathematical models in science and engineering
5. Courant, Hilbert, â€œMethods of Mathematical Physicsâ€, Interscience, 1955
6. K. Eriksson, D. Estep, C. Johnson, â€œApplied Mathematics: Body and Soul I-III, Springer,
2004
7. Lin, Segel, â€œMathematics Applied to Deterministic Problems in the Natural Sciencesâ€,
Macmilan, 1974

6
NUMERICAL METHODS FOR
PARABOLIC PARTIAL
DIFFERENTIAL EQUATIONS
Parabolic partial differential equations (PDEs) are frequently encountered in mathe-
matical models for heat transfer and diffusion. Their solutions reflect the underlying
physics, such as the dissipative nature of heat transfer.
A fundamental property of solutions to parabolic PDEs is that information travels
with infinite speed in the sense that an initial value immediately effects the solution
in other space points. Solutions to parabolic PDEs are stable and initial peaks are
smoothed out when integrated in one of the t-directions (say t > 0) but ill posed in
the other direction (t < 0).
Parabolic PDEs have a natural coupling to systems of ordinary differential
equations (ODEs). Discretization of the space derivatives with the finite difference
method (FDM) or with the finite element method (FEM) leads to stiff ODE systems.
In Chapter 5, the generic parabolic PDE problem in 1D was introduced. In this
chapter, this PDE is used as a model problem for various numerical methods, i.e.,
ğœ•u
ğœ•t = ğœ…ğœ•2u
ğœ•x2 ,
0 < x < 1,
0 < t â‰¤tend,
ğœ…> 0
(6.1a)
with Dirichlet boundary conditions (BCs)
u(0, t) = ğ›¼(t),
u(1, t) = ğ›½(t)
(6.1b)
and an initial condition (IC)
u(x, 0) = u0(x)
(6.1c)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

124
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
0
0.5
1
x
0
0.05
t
u (x, 0) = u0 (x)
u (0, t) = Î±(t)
u (1, t) = Î²(t)
Î©
Figure 6.1
Region of definition, Î©, in the x â€“ t plane
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0
0.2
0.4
0.6
0.8
1
x
u (x, t)
t
Figure 6.2
3D visualization of a solution u(x, t) of the heat equation
Geometrically the solution u(x, t) will be a surface above the region of defini-
tion Î© = {(x, t),
0 â‰¤x â‰¤1,
0 â‰¤t â‰¤tend} (see Figure 6.1). With the IC function
u0(x) = sin(ğœ‹x) and the BC functions ğ›¼(t) = 0 and ğ›½(t) = 0, the graph of the solution
(for ğœ…= 1) is shown in Figure 6.2.

APPLICATIONS
125
An important generalization of (6.1) is to include space dependence in the heat
conduction coefficient ğœ…(x) and a driving function f(x, t) (or f(x)) in the right hand
side. We then have the inhomogeneous heat equation
ğœ•u
ğœ•t = ğœ•
ğœ•x
(
ğœ…(x)ğœ•u
ğœ•x
)
+ f(x, t),
0 â‰¤x â‰¤1,
t â‰¥0
(6.2)
The steady-state solution of (6.2) is obtained when t â†’âˆ. In the steady-state case,
there is no time variation in the solution. Therefore, the steady-state solution satisfies
the boundary value problem (BVP)
âˆ’d
dx
(
ğœ…(x)du
dx
)
= f(x),
u(0) = ğ›¼0,
u(1) = ğ›½0
(6.3)
where ğ›¼0 and ğ›½0 are constants and f(x) a function that is time independent. Compare
with the model problem in (4.20).
6.1
APPLICATIONS
The occurrence of parabolic PDEs in application problems is now demonstrated on
some examples.
Example 6.1.
(Time-dependent 1D flow in a pipe). Consider the boundary value
problems (BVP) in Example 4.1. Now assume that the temperature of the fluid has
not come to a steady state (Figure 6.3) but is passing through a time-dependent tran-
sient from a given IC. The model for the temperature T(z, t) (K) is changed into
the PDE
ğœŒCğœ•T
ğœ•t + ğœŒCvğœ•T
ğœ•z = ğœ•
ğœ•z
(
ğœ…ğœ•T
ğœ•z
)
âˆ’2h
R (T âˆ’Tout),
0 < z < L,
t > 0
(6.4)
with IC
T(z, 0) = Tinit(z)
and BCs
T(0, t) = T0,
âˆ’ğœ…ğœ•T
ğœ•z (L) = k(T(L) âˆ’Tout)
z
A
A
T (z, t)
Figure 6.3
Hot flow in a cylindrical pipe

126
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
The only new variable and parameter introduced in this model compared to the model
in Example 4.1 is time t (s) and the initial value Tinit(z) (K). We see that when steady
state is reached (t â†’âˆ), the first term drops out, the IC is not necessary, and the PDE
problem turns into the BVP (4.10).
Example 6.2.
(Time-dependent 2D flow in a pipe). Consider again the flow in a
pipe model but now assume that heat is transported by diffusion both in the z- and in
the r directions. The model for the temperature T(z, r, t) (K) is modified to
ğœŒCğœ•T
ğœ•t + ğœŒCvğœ•T
ğœ•z = ğœ…ğœ•2T
ğœ•z2 + ğœ…
r
ğœ•
ğœ•r
(
rğœ•T
ğœ•r
)
,
0 < z < L, 0 < r < R, t > 0
(6.5)
with IC
T(z, r, 0) = Tinit(z, r),
0 â‰¤z â‰¤L, 0 â‰¤r â‰¤R
and BCs for z = 0 and z = L
T(0, r, t) = T0,
T(L, r, t) = Tout,
0 â‰¤r â‰¤R, t â‰¥0
and BCs for r = 0 and r = R (Figure 6.4)
ğœ•T
ğœ•r (z, 0, t) = 0,
âˆ’ğœ…ğœ•T
ğœ•r (z, R, t) = k(T(z, R, t) âˆ’Tout),
0 â‰¤z â‰¤L, t â‰¥0
Note that the heat loss through the wall is now implemented as a BC at r = R.
Exercise 6.1.1. Formulate the steady-state problem of the PDE (6.5). The solution
will depend on z and r, i.e., T = T(z, r). Classify the PDE, i.e., is it parabolic, elliptic,
or hyperbolic?
0
0.5L
L
z
0
R
r
k = âˆ‚r
âˆ‚T (z, R, t) = k (T (z, R, t) âˆ’ Tout)
T (0, r, t) = T0
T (L, r, t) = Tout
âˆ‚r
âˆ‚T (z, 0, t) = 0
âˆ’
Figure 6.4
2D model of time-dependent flow in a pipe

AN INTRODUCTORY EXAMPLE OF DISCRETIZATION
127
Example 6.3.
(Time-dependent 1D tubular reactor model). Consider again a
cylindrical pipe but this time it is called a tube in accordance with the nomen-
clature in chemical engineering. A fluid is transported through the tube of
length L (m) with an exothermal reaction going on in it. Simplifying the general
convection-diffusion-reaction(CDR) equations in Section 5.3.3 to only one chemical
species concentration c (mol/m3) and a given constant flow speed v (m/s) gives the
following system of two PDEs:
ğœ•c
ğœ•t + vğœ•c
ğœ•z = ğœ•
ğœ•z
(
Dğœ•c
ğœ•z
)
âˆ’Aeâˆ’Eâˆ•RTc
(6.6a)
ğœŒCğœ•T
ğœ•t + ğœŒCvğœ•T
ğœ•z = ğœ•
ğœ•z
(
ğœ…ğœ•T
ğœ•z
)
+ Î”HAeâˆ’Eâˆ•RTc
(6.6b)
where units of the variables c, T, z, t and parameters v, ğœŒ, C, D, ğœ…, Î”H, A, E, and R
are explained in Sections 2.4.4 and 5.3.3. The PDE system (6.6) is nonlinear due to
the term Aeâˆ’E/RTc.
In addition to the PDE (6.6), suitable ICs and BCs have to be given, e.g.,
c(z, 0) = cinit(z),
T(z, 0) = Tinit(z)
and
c(0, t) = c0, T(0, t) = T0,
ğœ•c
ğœ•z (L, t) = 0, ğœ•T
ğœ•z (L, t) = 0
Exercise 6.1.2. Formulate the steady-state problem of (6.6) with suitable BCs.
If the steady-0 state model is reduced further so that T is assumed to be constant,
formulate the corresponding BVP with BCs.
6.2
AN INTRODUCTORY EXAMPLE OF DISCRETIZATION
When using the FDM to solve the parabolic problem (6.1) for ğœ…= 1, we can follow
the workscheme introduced in Chapter 4, i.e.,
DGâ€”Discretize the region of definition Î© by using the stepsize hx for the x-axis
and the stepsize ht for the t-axis:
xi = ihx,
i = 0, 1, 2, â€¦ , N + 1,
tk = kht,
k = 0, 1, 2, â€¦
A rectangular grid is defined (see Figure 6.5).
DDâ€”Discretize the differential equation (6.1). Denote by ui, k the numerical solu-
tion of the problem at the point (xi, tk), i.e., u(xi, tk) â‰ˆui, k. Use the explicit

128
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
0
0.5
1
x
0
0.05
t
hx
ht
Figure 6.5
2D grid of Î©
Euler approximation for the time derivative
ğœ•u
ğœ•t (xi, tk) =
ui,k+1 âˆ’ui,k
ht
+ îˆ»ht
(6.7)
and the central difference approximation for the space derivative
ğœ•2u
ğœ•x2 (xi, tk) =
ui+1,k âˆ’2ui,k + uiâˆ’1,k
h2
x
+ îˆ»h2
x
(6.8)
and we obtain the following recursion formula for the heat equation:
ui,k+1 âˆ’ui,k
ht
=
ui+1,k âˆ’2ui,k + uiâˆ’1,k
h2x
(6.9)
This FDM can also be referred to as the FTCS method (forward-time-central-
space).
Introduce the stepsize parameter ğœ= htâˆ•h2
x and (6.9) can be written as
ui,k+1 = ğœuiâˆ’1,k + (1 âˆ’2ğœ)ui,k + ğœui+1,k
(6.10)
There is an appealing visualization of this formula as a stencil (also called a
difference star or computational molecule) (see Figure 6.6). For FDMs, there
is always such a stencil showing which ui, k values at the time level k (and/or
earlier time levels) that are to be combined to give the ui, k+1 values at the time
level k + 1.

AN INTRODUCTORY EXAMPLE OF DISCRETIZATION
129
1âˆ’
2Ïƒ
Ïƒ
Ïƒ
Figure 6.6
Stencil for the heat equation
DBâ€”Discretize the IC and BCs. For problem(6.1),the IC and BCs are represented
exactly
ui,0 = u0(xi),
u0,k = ğ›¼(tk),
uN+1,k = ğ›½(tk)
(6.11)
In Figure 6.1, the corresponding grid points where these conditions are given
are situated on the boundary ğœ•Î©.
Observe, however, that if we have BCs containing derivatives, they have to be
represented approximately (see Section 6.3).
After this discretization, the stencil is moved along the grid pattern from the lower
left corner row by row from left to right up to the upper right corner according to
Figure 6.7. After this computation,the ui, k values can be plotted above the grid, hence
visualizing the solution just as in the solution graph (6.2). Observe that all values at
the new time level can be computed simultaneously.
Exercise 6.2.1. Write a program giving the solution in Figure 6.2 using the method
(6.10). Use the stepsizes hx = 0.1, ht = 0.001.
0
.
0.5
1
x
0
0.05
t
1â€“
2Ïƒ
Ïƒ
Ïƒ
Figure 6.7
Stencil moving along the grid

130
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
6.3
THE METHOD OF LINES FOR PARABOLIC PDES
The Method of Lines (MoL) is based on the FDM and can be characterized as a gen-
eral method for numerical solution of time-dependent PDEs. In the MoL, the space
derivatives are discretized, but the time derivatives are kept. This principle of approx-
imation is referred to as semi-discretization.
6.3.1
Solving the Test Problem with MoL
For the generic parabolic problem (6.1), semi-discretization means that u(xi, t) â‰ˆui(t)
where ui(t) is a time-dependent solution function associated to the space point xi,
where the ui(t) function satisfies the ODE (ğœ…= 1)
dui(t)
dt
= ui+1(t) âˆ’2ui(t) + uiâˆ’1(t)
h2
x
,
ui(0) = u0(xi),
i = 1, 2, â€¦ , N
(6.12)
For i = 1 and i = N, the BCs enter as driving functions
du1(t)
dt
= u2(t) âˆ’2u1(t) + ğ›¼(t)
h2
x
,
u1(0) = u0(x1)
(6.13)
duN(t)
dt
= ğ›½(t) âˆ’2uN(t) + uNâˆ’1(t)
h2x
,
uN(0) = u0(xN)
(6.14)
In Figure 6.8, the lines of definition for the solution curves are shown.
The ODEs (6.12)â€“(6.14) above can be written in matrix form
du
dt = Tu + b(t),
u(0) = u0
(6.15)
0
0.5
1
x
0
0.5
t
u (0, t) = Î±(t)
u (x1, t) = u1(t)
u (x2, t) = u2(t)
u (xi, t) = ui(t)
u (1, t) = Î²(t)
Figure 6.8
Grid for a MoL discretization

THE METHOD OF LINES FOR PARABOLIC PDES
131
where
T = 1
h2
x
â›
âœ
âœ
âœ
âœ
âœ
âœâ
âˆ’2
1
0
â€¦
0
1
âˆ’2
1
â‹±
â‹®
0
â‹±
â‹±
â‹±
0
â‹®
â‹±
1
âˆ’2
1
0
â€¦
0
1
âˆ’2
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
(6.16)
and
b(t) = 1
h2
x
â›
âœ
âœ
âœ
âœâ
ğ›¼(t)
0
0
â‹®
ğ›½(t)
â
âŸ
âŸ
âŸ
âŸâ 
,
u(0) =
â›
âœ
âœ
âœ
âœâ
(u0x1
u0(x2)
u0(x3)
â‹®
u0(xN)
â
âŸ
âŸ
âŸ
âŸâ 
(6.17)
Hence, the ODE system is linear with constant coefficients. The tridiagonal matrix T
differs from the tridiagonal matrix A in (4.29) by a scalar factor
T = âˆ’1
h2x
A = 1
h2x
tridiag(1, âˆ’2, 1)
(6.18)
where the notation tridiag is also used in Section 4.2.
In Section A.2, the eigenvalues of A are calculated exactly and the values are
ğœ†j(A) = 4sin2
(
jğœ‹
2(N + 1)
)
Hence, the eigenvalues of T are
ğœ†j(T) = âˆ’4
h2
x
sin2
(
jğœ‹
2(N + 1)
)
,
j = 1, 2, â€¦ , N
(6.19)
Since the x interval is discretized with constant stepsize hx according to hx(N + 1) = 1,
ğœ†j(T) can be written as
ğœ†j(T) = âˆ’4
h2
x
sin2
(jğœ‹hx
2
)
,
j = 1, 2, â€¦ , N
(6.20)
We see that all eigenvalues of T are real, negative, and of very different magnitude in
the range from approximately âˆ’ğœ‹2 (for j = 1) to âˆ’4âˆ•h2
x (for j = N). Hence, (6.15) is
a stiff system of ODEs.
If Eulerâ€™s explicit method is used to solve (6.15), we get the recursion formula
uk+1 = uk + ht(Tuk + b(tk)),
u0 = u(0)
(6.21)
Figure 6.2 is generated with Eulerâ€™s explicit method, which is equivalent to the stencil
method based on formula (6.10).

132
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
In Chapter 3, the stability areas of some methods for IVP are shown. For the
explicit Euler method, the stepsize in time, here denoted by ht, must fulfill the
condition
ht ğœ†j âˆˆSEE,
â†’
ht
4
h2
x
â‰¤2,
â†’
ht
h2
x
â‰¤1
2
(6.22)
Hence, the time step ht must be quadratically smaller than the space step hx, which
puts a very severe restriction on ht, making the explicit Euler method very inefficient
for parabolic PDEs.
Violating this stepsize criterion will give a very dramatic numerical solution,
which is wrong of course (see Figure 6.9). The stability result (6.22) is based on the
eigenvalues of the matrix T and is therefore called eigenvalue stability. In Section
8.3, another method based on Fourier analysis is presented. This kind of stability
analysis is called von Neumann stability, named after the Hungarian-American
mathematician John von Neumann, active in the middle of the 20th century. The
results from the von Neumann stability analysis are the same as the eigenvalue
stability for parabolic PDEs (see Section A.6). However, in Chapter 8, hyperbolic
PDEs, the von Neumann analysis is the only adequate stability analysis.
Using a stiff method gives stable numerical solutions for large time steps
ht. For the implicit Euler method (also called the BTCS method from
u(x, t)
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
âˆ’1
âˆ’0.5
0
0.5
1
x
t
Figure 6.9
Unstable numerical solution of the heat equation

THE METHOD OF LINES FOR PARABOLIC PDES
133
backward-time-central-space), we get the recursion formula
uk+1 = uk + ht(Tuk+1 + b(tk+1)),
u0 = u(0)
(6.23)
After rearrangement, we get a linear system of equations to solve
(I âˆ’htT)uk+1 = uk + htb(tk+1)
(6.24)
The matrix (I âˆ’htT) is tridiagonal, symmetric, and positive definite
I âˆ’htT = tridiag(âˆ’ğœ, 1 + 2ğœ, âˆ’ğœ)
(6.25)
where ğœ= htâˆ•h2
x. However, the accuracy in the uk values is poor, since implicit Euler
is only first order.
An often-used method for the heat/diffusion equation is Crank â€“ Nicolsonâ€™s
method. John Crank and Phyllis Nicolson were British mathematicians and the
method was introduced around 1950. The Crank â€“ Nicolson method is of second
order in both the x and the t directions. In fact, this method is based on the trapezoidal
method for solving (6.15)
uk+1 = uk + ht
2 (Tuk + b(tk) + Tuk+1 + b(tk+1)),
u0 = u(0)
(6.26)
On inspection, we see that the trapezoidal method can be regarded as a combination
of the explicit and the implicit Euler methods. The trapezoidal method will also give
a tridiagonal system of linear algebraic equations to be solved in each time step
(
I âˆ’ht
2 T
)
uk+1 =
(
I + ht
2 T
)
uk + ht
2 (b(tk+1) + b(tk))
(6.27)
Crank â€“ Nicolsonâ€™s method is stable for all time steps ht and spacesteps hx, but if ht is
too large compared to hx, there will be damped oscillations in the numerical solution
as is seen in the Figure 6.10(a). If ht is small enough, we get a smooth solution (b).
Exercise 6.3.1. Give the stencils corresponding to the implicit Euler method and
the Crank â€“ Nicolson method.
Exercise 6.3.2. Consider the following system of parabolic PDEs:
ğœ•c1
ğœ•t = D11
ğœ•2 c1
ğœ•x2
+ D12
ğœ•2 c2
ğœ•x2
ğœ•c2
ğœ•t = D21
ğœ•2 c1
ğœ•x2
+ D22
ğœ•2 c2
ğœ•x2

134
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
0
5
10
0
0.5
1
âˆ’1
0
1
0
0.5
1
0
0.5
1
0
0.5
1
t
x
(a)
(b)
Figure 6.10
Crank â€“ Nicolsonâ€™s method
with ICs
c1(x, 0) = c10,
c2(x, 0) = c20
and BCs
c1(0, t) = 1, c2(0, t) = 1,
ğœ•c1
ğœ•x (1, t) = 0, ğœ•c2
ğœ•x (1, t) = 0
The parameters Dij, i = 1, 2, j = 1, 2 are constants. Use the MoL to discretize the
PDE system into a system of ODEs. Follow the DG, DD, and DB recipe and give the
answer in the form
dc
dt = Ac + b,
c(0) = c0
The structure of A depends on in which order the components of c1 and c2 are sorted.
Try to find the way of sorting that gives the smallest bandwidth of A.
A more effective way to solve the ODE system (6.15) is to use some higher order
method for stiff ODEs, such as the BDF method, described in Chapter 3. Parabolic
PDEs are often solved in this way and the efficiency is taken into account by utilizing
the sparse structure of the jacobian (often tridiagonal) of the ODE system obtained
after space discretization.
6.3.2
Various Types of Boundary Conditions
Common BCs for parabolic PDEs are of the same type as the BCs for a second-order
BVP (see Chapter 4). Assume that x = a is a boundary point:
â€¢ If u is specified at x = a, we have a Dirichlet condition
u(a, t) = ğ›¼(t)
(6.28)

THE METHOD OF LINES FOR PARABOLIC PDES
135
â€¢ If ğœ•u/ğœ•x is specified at x = a, we have a Neumann condition
ğœ•u
ğœ•x (a, t) = ğ›¾(t)
(6.29)
â€¢ If a linear combination of u and ğœ•u/ğœ•x is specified at x = a, we have a Robin
condition (also called mixed or generalized Neumann condition)
ğœ•u
ğœ•x (a, t) = ğœ‡(u(a, t) âˆ’uout(t))
(6.30)
where ğœ‡is a constant and uout(t) is a given function.
â€¢ An example of a nonlinear BC is the heat radiation condition
ğœ•u
ğœ•x (a, t) = ğœ†(u4(a, t) âˆ’u4
out(t))
(6.31)
In connection with the heat equation, all the BCs given above have a physical
meaning in terms of the temperature:
â€¢ The Dirichlet BC means that the temperature ğ›¼(t) is known at the boundary
point x = a.
â€¢ The Neumann condition means that the heat flux is known at the boundarypoint.
The special case
ğœ•u
ğœ•x (a, t) = 0
(6.32)
means that the point x = a is isolated from the environment.
â€¢ The mixed condition means that the heat flux is proportional to the temperature
difference u(a, t) âˆ’uout(t).
â€¢ The nonlinear BC given above corresponds to heat radiation at the point x = a
according to Stefan â€“ Boltzmannâ€™s law.
6.3.3
An Example of the Use of MoL for a Mixed Boundary Condition
The handling of BCs containing derivatives for parabolic PDE problems is similar to
their treatment for two-point BVPs.
Given the model problem (6.1a), ğœ…= 1, with one Dirichlet and one mixed BC
ğœ•u
ğœ•t = ğœ•2u
ğœ•x2 ,
u(0, t) = ğ›¼(t),
ğœ•u
ğœ•x (1, t) = ğœ‡(u(1, t) âˆ’uout(t))
(6.33)
we make a discretization with the MoL. Introduce an extra grid point after the right
boundary point
0
hx
1
x0
x1
xiâˆ’1
xi
xNâˆ’1
xN
xN+1
x
Hence, xi = ihx, i = 0, 1, 2, â€¦ , N + 1, where hx = 1/N.

136
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
The ODE system is as in (6.12)
dui
dt = 1
h2
x
(ui+1 âˆ’2ui + uiâˆ’1),
i = 1, 2, â€¦ , N
At the point x1 = h, we get after inserting the BC (6.13)
du1
dt = 1
h2
x
(u2 âˆ’2u1 + ğ›¼(t))
At the last point xN = 1, we have both an ODE and a discretized BC
duN
dt
= 1
h2x
(uN+1 âˆ’2uN + uNâˆ’1)
(6.34)
uN+1 âˆ’uNâˆ’1
2hx
= ğœ‡(uN âˆ’uout(t))
(6.35)
If uN+1 is eliminated, the last ODE is
duN
dt
= 1
h2
x
(2uNâˆ’1 âˆ’(2 âˆ’2hxğœ‡)uN âˆ’2hxğœ‡uout(t))
(6.36)
We now have a system of N ODEs for the N dependent variables u1, u2, â€¦ , uN. ICs
must be given, i.e., ui(0) = u0(xi)
Exercise 6.3.3. Formulate the ODE system in Section 6.3 on the form
â‹…u = Tu + b(t), i.e., find T and b.
a) The matrix T is not symmetric. Find a diagonal transformation u = Dv so that
the matrix Dâˆ’1TD is symmetric.
b) Write a program for solving the ODE system in Section 6.3. Plot the solution.
6.4
GENERALIZATIONS OF THE HEAT EQUATION
6.4.1
The Heat Equation with Variable Conductivity
As indicated in (6.2), the parameter ğœ…cannot always be assumed to be constant in
applications. It can be, e.g., space dependent ğœ…= ğœ…(x)
ğœ•u
ğœ•t = ğœ•
ğœ•x
(
ğœ…(x)ğœ•u
ğœ•x
)
(6.37)

GENERALIZATIONS OF THE HEAT EQUATION
137
or temperature dependent ğœ…= ğœ…(u)
ğœ•u
ğœ•t = ğœ•
ğœ•x
(
ğœ…(u)ğœ•u
ğœ•x
)
(6.38)
In equation (6.37), the PDE is still linear, but in the (6.38), we have a nonlinear PDE
to solve.
In the linear case, we discretize the space-dependent part of the PDE with the
following second-order difference approximation:
ğœ•
ğœ•x
(
ğœ…(x)ğœ•u
ğœ•x
)
(xi) = 1
hx
(
ğœ…(xi+1âˆ•2)ui+1 âˆ’ui
hx
âˆ’ğœ…(xiâˆ’1âˆ•2)ui âˆ’uiâˆ’1
hx
)
+ îˆ»h2
x
= 1
h2
x
(
ğœ…(xi+1âˆ•2)ui+1 âˆ’(k(xi+1âˆ•2) + ğœ…(xiâˆ’1âˆ•2))ui + k(xiâˆ’1âˆ•2)uiâˆ’1
)
+ îˆ»h2
x
Hence, after applying MoL, we obtain the following system of ODEs:
du
dt = 1
h2
x
tridiag(ğœ…(xiâˆ’1âˆ•2) , âˆ’(ğœ…(xiâˆ’1âˆ•2) + ğœ…(xi+1âˆ•2)) , ğœ…(xi+1âˆ•2))u
(6.39)
i.e., a linear ODE system with a tridiagonal matrix.
In the nonlinear case, we use the same space discretization
ğœ•
ğœ•x
(
ğœ…(u)ğœ•u
ğœ•x
)
(xi) = 1
hx
(
ğœ…(ui+1âˆ•2)ui+1 âˆ’ui
hx
âˆ’ğœ…(uiâˆ’1âˆ•2)ui âˆ’uiâˆ’1
hx
)
+ îˆ»h2
x
= 1
h2x
(ğœ…(ui+1âˆ•2)ui+1 âˆ’(ğœ…(ui+1âˆ•2) + ğœ…(uiâˆ’1âˆ•2))ui + ğœ…(uiâˆ’1âˆ•2)uiâˆ’1
)
+ îˆ»h2
x
The u values uiâˆ’1/2 and ui+1/2 are, according to the notation, values that are not given in
grid points. Therefore, we have to approximate them somehow. A simple symmetric
approximation giving second-order accuracy is to set them to the mean values of the
neighboring points, i.e.,
uiâˆ’1âˆ•2 = uiâˆ’1 + ui
2
,
ui+1âˆ•2 = ui + ui+1
2
Applying the MoL gives the following nonlinear ODE system:
du
dt = 1
h2x
tridiag
(
ğœ…
(uiâˆ’1 + ui
2
)
, âˆ’
(
ğœ…
(uiâˆ’1 + ui
2
)
+ ğœ…
(ui+1 + ui
2
))
,
ğœ…
(ui+1 + ui
2
))
u(3)
(6.40)

138
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
When this system is discretized with a stiff method, e.g., implicit Euler, we obtain
a nonlinear system of algebraic equations to be solved at each time step, which is
accomplished with Newtonâ€™s method. In each iteration, the jacobian is tridiagonal.
6.4.2
The Convection â€“ Diffusion â€“ Reaction PDE
The following equation occurs frequently in chemical technology and is a hyper-
bolic â€“ parabolic PDE (see Chapter 5) the CDR equations:
ğœ•u
ğœ•t + vğœ•u
ğœ•x = Dğœ•2u
ğœ•x2 + r(u)
(6.41)
If v = 0, we have a parabolic problem. If D = 0 the problem is hyperbolic.
If the MoL is used to discretize the PDE, we obtain (with central differences)
du
dt = Tu + b(u),
u(0) given
(6.42)
where T is an unsymmetric tridiagonal matrix
T = tridiag
(
D
h2x
+
v
2hx
, âˆ’2D
h2x
, D
h2x
âˆ’
v
2hx
)
(6.43)
6.4.3
The General Nonlinear Parabolic PDE
A general formulation of a nonlinear scalar parabolic PDE is
ğœ•u
ğœ•t = f
(
x, t, u, ğœ•u
ğœ•x, ğœ•2u
ğœ•x2
)
,
t â‰¥0,
0 â‰¤x â‰¤1
(6.44)
Assuming Dirichlet conditions u(0, t) = g1(t), u(1, t) = g2(t), the MoL can be used
to discretize the problem to a system of nonlinear ODEs
dui
dt = f
(
xi, t, ui, ui+1 âˆ’uiâˆ’1
2h
, ui+1 âˆ’2ui + uiâˆ’1
h2
)
,
i = 1, 2, â€¦ , N
(6.45)
This system is of the form
du
dt = F(t, u),
u(0) = u0
(6.46)
and has a tridiagonal character, since the jacobian of the right hand side function is a
tridiagonal N Ã— N matrix.

ANSATZ METHODS FOR THE MODEL EQUATION
139
6.5
ANSATZ METHODS FOR THE MODEL EQUATION
Ansatz methods can be applied to time-dependent PDEs. As for the heat equation,
we illustrate the ansatz method on the model problem
ğœ•u
ğœ•t = ğœ•2u
ğœ•x2 + f(x),
u(0, t) = u(1, t) = 0,
u(x, 0) = u0(x)
(6.47)
The ansatz, uh(x, t), is based on a time-dependent linear combination of basis func-
tions
u(x, t) â‰ˆuh(x, t) =
N
âˆ‘
j=1
cj(t)ğœ‘j(x)
(6.48)
where ğœ‘j(x) are given functions fulfilling the BCs ğœ‘j(0) = 0, ğœ‘j(1) = 0. The coeffi-
cients cj(t) are to be computed so that uh(x, t) is a â€œgoodâ€ approximation of u(x, t).
Inserting uh(x, t) into the PDE gives a residual function
r(x, t) = ğœ•uh
ğœ•t âˆ’ğœ•2uh
ğœ•x2 âˆ’f(x)
=
N
âˆ‘
j=1
dcj
dt ğœ‘j(x) âˆ’
N
âˆ‘
j=1
cj(t)
d2ğœ‘j
dx2 âˆ’f(x) â‰ 0
(6.49)
Now impose the condition that the residual function is orthogonal to the basis
functions for all t
âˆ«
1
0
r(x, t)ğœ‘i(x) dx = 0,
i = 1, 2, â€¦ , N
(6.50)
This gives
N
âˆ‘
j=1
dcj
dt âˆ«
1
0
ğœ‘i(x)ğœ‘j(x) dx âˆ’
N
âˆ‘
j=1
cj(t) âˆ«
1
0
d2ğœ‘j
dx2 ğœ‘i(x) dx âˆ’âˆ«
1
0
f(x)ğœ‘i(x) dx = 0
By partial integration, we obtain
âˆ’âˆ«
1
0
d2ğœ‘j
dx2 ğœ‘i(x) dx = âˆ’
[
ğœ‘i
dğœ‘j
dx
]1
0
+ âˆ«
1
0
dğœ‘i
dx
dğœ‘j
dx dx
Since ğœ‘i(0) = ğœ‘i(1) = 0, the outintegrated term disappears and we finally get the
Galerkin formulation
M dc
dt + Ac = f
(6.51)

140
NUMERICAL METHODS FOR PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS
This is a system of ODEs where
Mij = âˆ«
1
0
ğœ‘i(x)ğœ‘j(x) dx,
Aij = âˆ«
1
0
dğœ‘i
dx
dğœ‘j
dx dx,
fi = âˆ«
1
0
f(x)ğœ‘i(x)dx
(6.52)
The ICs are obtained from
u0(x) â‰ˆuh(x, 0) =
N
âˆ‘
i=1
ci(0)ğœ‘i(x)
(6.53)
Multiply this relation with ğœ‘j(x), integrate over [0, 1] and we obtain the initial values
c(0) from the linear system of equations
Mc(0) = u0
(6.54)
where
u0,i = âˆ«
1
0
u0(x)ğœ‘i(x) dx.
Now, choose as basis functions the roof functions introduced in Chapter 4. Inserting
the basis functions into (6.52), we obtain
M = hx
6
â›
âœ
âœ
âœ
âœ
âœ
âœâ
4
1
0
â€¦
0
1
4
1
â‹±
â‹®
0
â‹±
â‹±
â‹±
0
â‹®
â‹±
1
4
1
0
â€¦
0
1
4
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
,
A = 1
hx
â›
âœ
âœ
âœ
âœ
âœ
âœâ
2
âˆ’1
0
â€¦
0
âˆ’1
2
âˆ’1
â‹±
â‹®
0
â‹±
â‹±
â‹±
0
â‹®
â‹±
âˆ’1
2
âˆ’1
0
â€¦
0
âˆ’1
2
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
(6.55)
Observe that (6.51) is not presented in standard form duâˆ•dt = f(t, u). We can
achieve that by multiplying both sides with Mâˆ’1
dc
dt + Mâˆ’1Ac = Mâˆ’1f
(6.56)
If we do that, however, the tridiagonal structure of the matrices in (6.55) is destroyed,
since Mâˆ’1 is a full matrix. By keeping the tridiagonal form, a stiff method, e.g., the
implicit Euler method applied to (6.51) gives a tridiagonal system of linear equations
to be solved at each time step
M(ck+1 âˆ’ck) + htAck+1 = ht fk+1 â‡’(M + htA)ck+1 = Mck + ht fk+1
BIBLIOGRAPHY
The classical textbook on numerical solution of PDEs is:
1. G.D. Smith, Numerical Solution of Partial Differential Equations, 3rd ed, Oxford University
Press, 1986

BIBLIOGRAPHY
141
A modern book, more mathematical, on numerical analysis of ODEs and PDEs:
2. A. Iserles, A First Course in the Numerical Analysis of Differential Equations, Cambridge
University Press, 1996
A book with several applications:
3. K.W. Morton, D.F. Myers, Numerical Solution of Partial Differential Equations, Cambridge
University Press, 2005


7
NUMERICAL METHODS FOR
ELLIPTIC PARTIAL DIFFERENTIAL
EQUATIONS
Elliptic partial differential equations (PDEs) arise in equilibrium or steady-state prob-
lems, i.e., PDE problems that are time independent.
The solution of an elliptic PDE is often related to minimization of the total energy
of a system formulated as an integral that depends on a state function and its deriva-
tives. The minimization of this integral with respect to the state function is known
as variational calculus and often leads to an elliptic PDE (or ordinary differential
equation (ODE) if there is only one independent variable) and corresponding bound-
ary conditions (BCs). Variational calculus is not taken up in this text but is referred
to in some of the textbooks mentioned at the end of this chapter.
The BCs usually specify either the value of the solution function on the boundary
or the value of its normal derivative or a combination of both.
The model problem for a 2D elliptic PDE problem is Poissonâ€™s equation,
âˆ’ğœ•2u
ğœ•x2 âˆ’ğœ•2u
ğœ•y2 = f(x, y),
(x, y) âˆˆÎ©
(7.1a)
u = 0,
(x, y) âˆˆğœ•Î©
(7.1b)
where Î© is assumed to be a bounded region in R2 with a smooth (or at least piece-
wise smooth) boundary ğœ•Î©. When f(x, y) â‰¡0 in equation (7.1a), the PDE is called
Laplaceâ€™s equation and its solutions are called harmonic functions.
Different types of BCs can be given, just as in the case of 1D boundary value
problems (see Chapter 4). The following common examples of BCs are linear
â€¢ Dirichletâ€™s BC
u = g(x, y)
(x, y) âˆˆğœ•Î©
(7.2)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

144
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
â€¢ Neumannâ€™s BC
ğœ•u
ğœ•n = h(x, y),
(x, y) âˆˆğœ•Î©
(7.3)
Observe that Poissonâ€™s equation with a Neumann BD has a solution that is deter-
mined only up to an additive constant. To obtain a unique solution, a Dirichlet
(or mixed) condition is needed in at least some part of ğœ•Î©. Observe also that
with Neumannâ€™s BC, the following relation must be fulfilled
âˆ«ğœ•Î©
ğœ•u
ğœ•nds = âˆ«
âˆ«Î©
f(x, y)dxdy
â€¢ Mixed BC (also referred to as Robinâ€™s BC):
ğœ•u
ğœ•n = ğ›¼u + g(x, y)
(x, y) âˆˆğœ•Î©
(7.4)
where ğ›¼is a known constant and g(x, y) a known function.
â€¢ The three BCs given above are linear but nonlinear BCs can also be formulated
for elliptic PDEs.
At each point on the boundary ğœ•Î©, only one type of BC can be given, but along the
boundary the type of BC can shift, from, e.g., Dirichlet type to, e.g., Neumann type.
However, at boundary points where either the BCs change or where the boundary is
not smooth, singularities may occur in the solutionâ€™s derivatives, which will imply
difficulties in the numerical treatment when discretization methods are used.
The 1D correspondence to equation (7.1) is the following boundary value problem
(BVP) with Dirichlet BCs, presented as the model equation in Chapter 4:
âˆ’d2u
dx2 = f(x),
0 < x < 1,
u(0) = u(1) = 0
(7.5)
Many of the numerical properties of the discretized version of equation (7.5) will
be preserved for PDE problems in 2D and 3D. In Section 4.2, it was stated that in the
discretization of a BVP a matching technique leads to a coupled system of algebraic
equations. This is true also for elliptic problems in 2D and 3D but the size of the
systems will increase immensely. Examples of such numerical properties are
â€¢ For a linear elliptic PDE with linear BCs, discretization with finite difference
method (FDM) or finite element method (FEM), leads to a linear algebraic sys-
tem of equations to be solved: Au = b.
â€¢ The matrix A will be sparse.
For 1D and 2D problems, the solution of the linear system is usually performed
with a sparse version of a direct method, e.g., sparse Gaussian elimination. For a
3D problem, the size of the linear system is usually so large that an iterative method
is preferred (when it works), (see Appendix A.5).

APPLICATIONS
145
Exercise 7.0.1. Given Poissonâ€™s equation with inhomogeneous BC:
âˆ’ğœ•2u
ğœ•x2 âˆ’ğœ•2u
ğœ•y2 = f(x, y),
(x, y) âˆˆÎ©
u = g(x, y),
(x, y) âˆˆğœ•Î©
Assume that g(x, y) is twice differentiable in the region Î©. Let v = u âˆ’g(x, y). Find
the Poisson equation and the BCs that v satisfies.
Exercise 7.0.2. The forms of Laplaceâ€™s equation for cartesian, cylindrical, and
spherical coordinates are shown in equations (5.24a), (5.24b).
1. Assume that the solution to Laplaceâ€™s equation in cylindrical coordinates
depends only on the variable r (cylinder symmetry). Find the general solution.
2. The same as in (1) but for spherical coordinates (spherical symmetry).
7.1
APPLICATIONS
Poissonâ€™s and Laplaceâ€™s equations occur in a great variety of applications in science
and engineering. Some examples are given in Table 7.1.
To each one of the elliptic PDE problems given in Table 7.1, appropriate BCs have
to be given in order to specify a unique solution.
Laplaceâ€™s and Poissonâ€™s equations are not the only elliptic problems. The examples
below show some other types of elliptic PDEs, e.g., a higher order PDE, an eigenvalue
problem, a nonlinear PDE, and a system of two PDEs. For some of these examples,
the numerical solution is demonstrated in Section 7.3.
Example 7.1. (Stationary heat conduction).
Consider a thin, metallic, homogeneous, flat, rectangular plate of length a (m)
and width b (m). The plate has no heat sources. When the plate is placed in an
TABLE 7.1
Applications of Poissonâ€™s Equation
Application
Variable
PDE
Right Hand Side
Heat conduction
T = temperature
âˆ’div(ğœ…âˆ‡T) = Q
Heat source/sink
Diffusion
c = concentration
âˆ’div(Dâˆ‡c) = q
Mass source/sink
Electrostatics
V = el potential
âˆ’div(ğœ–âˆ‡V) = ğœŒ
Charge density
Gravity
ğœ“= grav potential
âˆ’Î”ğœ“= ğœŒ
Mass density
Membrane deflection
u = deformation
âˆ’div(âˆ‡u) = f âˆ•E
Pressure
Torsion of a cylinder
ğœ™= stress function
âˆ’Î”ğœ™= 2ğœƒG
Torsion module
Fluid dynamics
Î¦ = velocity potential
Î”Î¦ = 0

146
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
y
âˆ‚Î©2
âˆ‚Î©3
Î©
âˆ‚Î©1
âˆ‚Î©4
x
Figure 7.1
Region and boundaries for a rectangular heat conduction problem
xy-coordinate system, it covers the rectangular region Î©. Heat is conducted isotrop-
ically in the plate and the heat fluxes are subject to different BCs given on ğœ•Î©. Let
T(x, y) (K) be the temperature in a point (x, y) in Î© or on ğœ•Î©. T(x, y) is determined
by the heat equation, in this case Laplaceâ€™s equation and appropriate BCs
âˆ’âˆ‡(ğœ…âˆ‡T) = 0
where ğœ…is the heat conduction coefficient [Jâˆ•( Kâ‹…mâ‹…s)] (Figure 7.1).
Along ğœ•Î©1, the temperature is given by a function g(x, y), i.e.
T(x, y) = g1(y),
(x, y) âˆˆğœ•Î©1
(7.6)
hence leading to a Dirichlet BC on this part of the boundary.
Along ğœ•Î©2, assume that the plate is warmer than the environment. Hence, heat is
leaking out through this part of the boundary and a mixed BC is appropriate
âˆ’ğœ…ğœ•T
ğœ•n = k(T âˆ’Tout),
(x, y) âˆˆğœ•Î©2
(7.7)
where k [Jâˆ•( Kâ‹…m2 â‹…s)] is the convection heat transfer coefficient.
Along ğœ•Î©3, the boundary is assumed to be heat insulated against the environment,
which leads to a Neumann BC
ğœ…ğœ•T
ğœ•n = 0
(7.8)
Finally along Î©4, the temperature is given by a function g2(y), i.e., a Dirichlet BC just
as along ğœ•Î©1. For a solution of this problem, see Section 7.3. Compare this example
with example 6.2.
Example 7.2. (Steady, incompressible, nonviscous, irrotational flow).
If a flow is irrotational, i.e., the velocity field u = (ux, uy) satisfies curlu = 0, there
exists a potential function Î¦ such that u = âˆ’âˆ‡Î¦. As the flow is incompressible we

APPLICATIONS
147
x
0
a
y
ux = U
Figure 7.2
The flow around a circular obstacle
also have divu = 0. Combining these two equations we find that Î¦ satisfies Laplaceâ€™s
equation
Î”Î¦ = 0
The physical assumptions needed to justify this model is that the effects of viscosity
are neglected.
By specifying suitable BCs, the flow is determined. In this example, we consider
a flow in the xy-plane that originally is parallel with the x-axis and then passing a
cylinder with the symmetry axis perpendicular to the xy-plane. We want to compute
the flowlines as the flow passes the cylinder.
Assume the 2D flow far away from the cylinder (x << 0) has the velocity compo-
nents ux = U and uy = 0. The radius of the cylinder is a and the symmetry axis goes
through the origin (Figure 7.2).
For this problem, it is natural to use cylindrical coordinates. As the z-coordinate
plays no part in the solution, the potential function Î¦ satisfies Laplaceâ€™s equation in
polar coordinates
ğœ•2Î¦
ğœ•r2 + 1
r
ğœ•Î¦
ğœ•r + 1
r2
ğœ•2Î¦
ğœ•ğœ‘= 0
(7.9)
From Î¦, the cylindrical velocity components ur and uğœ‘are computed from
ur = âˆ’ğœ•Î¦
ğœ•r ,
uğœ‘= âˆ’1
r
ğœ•Î¦
ğœ•ğœ‘
(7.10)
To solve Laplaceâ€™s equation, BCs are needed in the region Î© yet to be defined. Owing
to symmetry,it is enough to formulateBCs in the half plane 0 â‰¤ğœ‘â‰¤ğœ‹. In a numerical
formulation based on the FDM, the region must be bounded. This can be achieved
by restricting the r-variable to be bounded by a â‰¤r â‰¤R, where R >> a. Hence, Î© is
a large half disc from which a small half disc has been cut out: Î© = (r, ğœ‘), a â‰¤r â‰¤
R, 0 â‰¤ğœ‘â‰¤ğœ‹.
1. On the boundary ğœ•Î©1, the small half circle we have ur = 0, i.e., no radial veloc-
ity component.

148
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
x
y
u
f (x, y)
Î©
Figure 7.3
Deformation of an elastic plate by a transversal load
2. Along the boundary ğœ•Î©2 and ğœ•Î©4, the two parts on the x-axis between the small
and the big half circle, we have uğœ‘= 0 from the symmetry of the problem.
3. Far away from the cylinder, the flow is unaffected, i.e. ux = U and uy = 0.
Hence, on the boundary ğœ•Î©3 the big half circle, the following Dirichlet con-
dition satisfies the BC: Î¦ = âˆ’Ux = âˆ’Ur cos(ğœ‘).
Example 7.3. (Deformation of an elastic plate by a transversal load).
Consider a thin, metallic, homogeneousflat plate (see Figure 7.3).When it is placed in
an xy-coordinate system, it covers the region Î©. We want to study small deformations
imposed by a transversal pressure f(x, y) (Nâˆ•m2). The deformation u (m) satisfies the
biharmonic equation
Î”2u = ğœ•4u
ğœ•x4 + 2 ğœ•4u
ğœ•x2ğœ•y2 + ğœ•4u
ğœ•y4 = f(x, y)
D
,
(x, y) âˆˆÎ©
(7.11a)
where D ( Nâ‹…m) is the flexural rigidity. For a clamped plate, the following BCs are
valid
u = 0,
ğœ•u
ğœ•n = 0,
(x, y) âˆˆğœ•Î©
(7.11b)
Equation (7.11a)is a fourth-orderelliptic problem.The corresponding1D problem
is the ODE modeling the deformation of a beam clamped between two walls and
transversally loaded by f(x) (N/m)
EI d4u
dx4 = f(x),
u(0) = du
dx(0) = 0,
u(L) = du
dx(L) = 0
(7.12)
Example 7.4. (Eigenvalue problem).
In different engineering applications, one is often interested in the frequencies allow-
ing a system to vibrate by itself without influence of external forces. Such prob-
lems occur in, e.g., mechanical and electrical problems and such frequencies are

APPLICATIONS
149
called eigenfrequencies. They would vibrate for ever only in idealized situations,
when damping forces are neglected. Nevertheless, these eigenfrequencies are impor-
tant in engineering. The reason is that we want to avoid them, as external forces
vibrating with the same frequency as an eigenfrequency introduces resonance effects
that will increase the amplitudeof the vibrations of the system and may cause damage.
Consider an elastic membrane that is first deformed and then left to itself to
perform vibrations with amplitude u(x, y). The vibrations v(x, y, t) satisfy the wave
equation (see Chapter 5)
ğœ•2v
ğœ•t2 = c2Î”v,
(x, y) âˆˆÎ©
(7.13a)
v = 0,
(x, y) âˆˆğœ•Î©
(7.13b)
For vibrations with the angular frequency ğœ”, we make the following ansatz for the
time-dependent solution
v = u(x, y)eiğœ”t
(7.14)
Inserting this ansatz into the wave equation gives the following elliptic PDE problem
for the amplitude (Helmholtzâ€™ equation), also called the eigenvalue problem for the
vibrating membrane
âˆ’Î”u = ğœ†u,
(x, y) âˆˆÎ©
(7.15a)
u = 0,
(x, y) âˆˆğœ•Î©
(7.15b)
where
ğœ†=
(ğœ”
c
)2
(7.16)
Observe that u(x, y) is determined only up to a multiplicative constant, see also
example 4.6.
Example 7.5. (Minimal surface problem, a nonlinear elliptic PDE).
Consider a closed curve ğœ•Î©S in 3D. Such a curve can be defined by u = g(x, y) eval-
uated along a closed curve ğœ•Î© enclosing the region Î© in the xy-plane. The problem
is to find the minimal surface S and the corresponding function u(x, y) with ğœ•Î©S as
boundary (Figure 7.4).
This can be stated as a minimization problem
S = min
u(x,y) âˆ«Î©
âˆš
1 + (âˆ‡u)2dxdy
(7.17a)
subject to the constraint
u = g(x, y),
(x, y) âˆˆğœ•Î©
(7.17b)

150
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
Î©
x
y
u
S
âˆ‚Î©S
âˆ‚Î©
Figure 7.4
Minimal surface problem
With variational calculus, it can be shown that equation (7.17) is equivalent to solving
the following nonlinear elliptic PDE
div
{
âˆ‡u
âˆš
1 + (âˆ‡u)2
}
= 0,
(x, y) âˆˆÎ©
(7.18a)
with Dirichlet BC
u = g(x, y),
(x, y) âˆˆğœ•Î©
(7.18b)
This problem is also known as the soap film problem, as the PDE (7.18) describes
how the shape of a soap film will adjust itself when it is fastened to a metallic wire
with a given shape, defined by ğœ•Î©S.
Example 7.6. (Deformation of an elastic plate in a plane).
Plane strain of an elastic plate in 2D is modeled by two coupled elliptic PDEs
ğœ•2u
ğœ•x2 + 1 âˆ’ğœˆ
2
ğœ•2u
ğœ•y2 + 1 + ğœˆ
2
ğœ•2v
ğœ•xğœ•y = âˆ’1 âˆ’ğœˆ2
E2
f(x, y)
(7.19a)
ğœ•2v
ğœ•y2 + 1 âˆ’ğœˆ
2
ğœ•2v
ğœ•x2 + 1 + ğœˆ
2
ğœ•2u
ğœ•xğœ•y = âˆ’1 âˆ’ğœˆ2
E2
g(x, y)
(7.19b)
where u and v are the displacements in the x and y directions. E is the elasticity
module and ğœˆis Poissonâ€™s number. The deformation forces in the x and y directions
are, respectively, f(x, y) and g(x, y). With appropriate BCs, this is a system of two
elliptic PDEs.
7.2
THE FINITE DIFFERENCE METHOD
When the FDM is used, the algorithm for solving an elliptic PDE problem can be
divided into three steps, just as for BVPs in Chapter 4. Hence, the steps are

THE FINITE DIFFERENCE METHOD
151
x0
x1
x2
xi
xN xN +1
x
y0
y1
y2
yj
yN
yN +1
y
(1, 1)
Figure 7.5
2D grid
1. discretize the region to a grid
2. discretize the PDE
3. discretize the BCs
To illustrate the algorithm, we apply it to the model problem (7.1) in the case Î© is the
region {(x, y), 0 â‰¤x â‰¤1, 0 â‰¤y â‰¤1}.
DG Discretize the region to a grid
Discretize the x- and the y-axis with the same stepsize h corresponding to N Ã— N
inner points equidistantly distributed over the two axis, h(N + 1) = 1 giving xi, i =
1, 2, â€¦ N and yj = jh, j = 1, 2, â€¦ N (Figure 7.5).
DD Discretize the PDE
Use the well-known difference formula for the second derivative:
ğœ•2u
ğœ•x2 (xi, yj) =
ui+1,j âˆ’2ui,j + uiâˆ’1,j
h2
+ O(h2)
(7.20a)
ğœ•2u
ğœ•y2 (xi, yj) =
ui,j+1 âˆ’2ui,j + ui,jâˆ’1
h2
+ O(h2)
(7.20b)
We get the following difference approximation of Poissonâ€™s equation:
4ui,j âˆ’uiâˆ’1,j âˆ’ui+1,j âˆ’ui,jâˆ’1 âˆ’ui,j+1 = h2f(xi, yj)
(7.21)
DB The BCs are represented exactly for the given Dirichlet conditions:
u0,j = 0,
uN+1,j = 0,
ui,0 = 0,
ui,N+1 = 0
(7.22)
We can illustrate the left hand side of equation (7.21) by the five-point stencil h2Î”h
5
(Figure 7.6).

152
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
1
âˆ’4
1
1
1
Figure 7.6
Stencil for discretized laplacian
x0 x1
x2
xi
xN xN+1
x
y0
y1
y2
yj
yN
yN+1
y
(1, 1)
1
2
3
N
N+1
2N
jN
N2
Figure 7.7
Ordering of unknowns
The difference equations (7.21) can be set up in all N2 inner points (xi, yj). giving
N2 equations for N2 unknowns ui,j. By introducing the matrix U for the unknowns, it
might seem reasonable that equations (7.21) and (7.22) can be formulated as a linear
matrix equation:
AU = B
with appropriate elements in the A and B matrices. This, however, is NOT possible!
Instead we have to represent the matrix of unknownsU as a long vector u. One way
to do this is to enumerate the unknowns and the gridpoints row-wise (also known as
natural ordering)according to the Figure 7.7: corresponding to the following ordering
of the ui,j values:
u = (u1,1, u2,1, â€¦ , uN,1, u1,2, u2,2, â€¦ , uN,2, â€¦â€¦ u1,N, u2,N, â€¦ uN,N)T
With this enumeration, the linear system of equations will be
Au = b

THE FINITE DIFFERENCE METHOD
153
where A is a sparse symmetric positive definite N2 Ã— N2 matrix and b is an N2 Ã— 1
column vector.
In the case N = 3, A and b are
A =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
4
âˆ’1
0
âˆ’1
0
0
0
0
0
âˆ’1
4
âˆ’1
0
âˆ’1
0
0
0
0
0
âˆ’1
4
0
0
âˆ’1
0
0
0
âˆ’1
0
0
4
âˆ’1
0
âˆ’1
0
0
0
âˆ’1
0
âˆ’1
4
âˆ’1
0
âˆ’1
0
0
0
âˆ’1
0
âˆ’1
4
0
0
âˆ’1
0
0
0
âˆ’1
0
0
4
âˆ’1
0
0
0
0
0
âˆ’1
0
âˆ’1
4
âˆ’1
0
0
0
0
0
âˆ’1
0
âˆ’1
4
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
,
b = h2f = h2
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
f1,1
f2,1
f3,1
f1,2
f2,2
f3,2
f1,3
f2,3
f3,3
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
The matrix A is symmetric and positive definite (compare with the matrix A in (4.29))
and has the structure of a block tridiagonal matrix
A = tridN(âˆ’I, T, âˆ’I),
where
T = tridN(âˆ’1, 4, âˆ’1)
(7.23)
The matrix A is very sparse, only five diagonals have nonzero elements. On the other
hand, the bandwidth is 2N âˆ’1 and (see Section A.5) in the Cholesky factorization,
A = LLT, there will be â€œfill-inâ€ in L, i.e., the zeros inside the band between the outer
and inner diagonals will be filled with nonzero elements denoted by x:
AL =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
x
0
0
0
0
0
0
0
0
x
x
0
0
0
0
0
0
0
0
x
x
0
0
0
0
0
0
x
0
0
x
0
0
0
0
0
0
x
0
x
x
0
0
0
0
0
0
x
0
x
x
0
0
0
0
0
0
x
0
0
x
0
0
0
0
0
0
x
0
x
x
0
0
0
0
0
0
x
0
x
x
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
âˆ’> L =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
x
0
0
0
0
0
0
0
0
x
x
0
0
0
0
0
0
0
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
0
0
0
0
0
0
x
x
x
x
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
where AL is the lower triangular part of A. For more comments on the solution of large
sparse systems with different methods, see Section A.5. Observe the increasing com-
plexity as the problem is changed from 1D to 2D and 3D. If the x-axis is discretized
into N inner points for 1D the problem (7.5), the matrix A will be tridiagonal, N Ã— N
and the solution time O(N).
With a similar discretization for the 2D problem (7.1) with Î© being a quadrangle
(N inner points in both the x and the y directions), A is N2 Ã— N2 with bandwidth O(N)
and solution time O(N4)
In the 3D case, A is N3 Ã— N3 with bandwidth O(N2) and solution time O(N7).

154
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
Exercise 7.2.1. Use the five-point stencil to compute an approximation of u(0, 0),
where u(x, y) satisfies the PDE
Î”u = u,
(x, y) âˆˆÎ©
u = |x| + |y|,
(x, y) âˆˆğœ•Î©
where Î© is the square (x, y), âˆ’1 â‰¤x â‰¤1, âˆ’1 â‰¤y â‰¤1. Use the stepsizes, h = 1 and
h = 1âˆ•2. Use extrapolation to improve the result.
Exercise 7.2.2. Find the stencil obtained with central differenceapproximationsfor
the following PDE expressions. Assume that the stepsize h in the x and y directions
is the same.
ğœ•2u
dx2 + ğœ•2u
ğœ•y2 + ğœ•2u
ğœ•xğœ•y
ğœ•2u
dx2 + ğœ•2u
ğœ•y2 + ğœ•u
ğœ•x + ğœ•u
ğœ•y
Exercise 7.2.3. When the boundary ğœ•Î© is curved and intersects the quadratic grid
at points that are not grid points, the five-point stencil h2Î”h
5 must be modified when
applied to Dirichlet BC.
Assume the stencil is positioned with the midpoint in (xi, yj), which is situated
inside the region Î©. The point on the curve above the midpoint is situated ğ›¼h, ğ›¼< 1
from the midpoint. The point to the right of the midpoint has the distance ğ›½h, ğ›½< 1
from the midpoint. The points below and to the left of the midpoint are both situated
inside the region and therefore at distance h from the midpoint.
The parameters ğ›¼and ğ›½in the unsymmetric stencil are chosen so that it fits the
boundary points correctly. Derive the coefficients a, b, c, d, e (they depend on ğ›¼and
ğ›½) in the difference approximation
Î”u(xi, yj) =
auijâˆ’1 + buiâˆ’1j + cuij + dui+1j + euij+1
h2
+ O(hp)
so that the order of approximation is as high as possible. Show the result as a stencil.
7.3
DISCRETIZATION OF A PROBLEM WITH DIFFERENT BCs
Based on the FDM, the problems in Examples 7.1â€“7.5 can be solved, essentially using
the same three step algorithm as outlined in Section 7.2. We present here a discretized
solution technique for Example 7.1.
Assume that the region Î© is a rectangle placed in an xy-coordinate system with
the corners on (0, 0), (a, 0), (0, b) and (a, b).

DISCRETIZATION OF A PROBLEM WITH DIFFERENT BCs
155
x0
x1
x2
xi
xMâˆ’1 xM
x
y1
y2
y3
yj
yN âˆ’1
yN
yN +1
y
(a, b)
Figure 7.8
The region discretized with the FDM
1. DGâ€”Discretize Î© using a stepsize h, which is assumed to be the same in both
the x and the y directions, according to Mh = a, (N âˆ’1)h = b (Figure 7.8).
Having the type of BCs in mind, the points are numbered according to
xi = ih, i = 0, 1, â€¦ M, x0 = 0, xM = a
and
yj = (j âˆ’1)h, j = 0, 1, â€¦ , N +
1, y0 = âˆ’h, yN+1 = b + h. The four corner points of the grid, however, are
not included. This gives (M + 1)(N + 2) âˆ’4 = MN + 2M + N âˆ’2 grid points.
This is also the number of unknowns Ti,j of the discretized problem.
2. DD Discretize the PDE. The following equations are valid at the inner points:
4Ti,j âˆ’Tiâˆ’1,j âˆ’Ti+1,j âˆ’Ti,jâˆ’1 âˆ’Ti,j+1 = 0,
where i = 1, 2, â€¦ , M âˆ’1, j = 1, 2, â€¦ , N giving a total of (M âˆ’1)N equations.
3. DB Discretize the BCs along the four boundaries.
On ğœ•Î©1, there is a Dirichlet BC: T0,j = g(0, yj), j = 1, 2, â€¦ , N giving N
equations.
On ğœ•Î©2, there is a mixed BC: âˆ’ğœ…(Ti,N+1 âˆ’Ti,Nâˆ’1)âˆ•2h = k(Ti,N âˆ’Tout), i =
1, 2, â€¦ , M âˆ’1 giving M âˆ’1 equations.
On ğœ•Î©3, there is a Neumann BC: (Ti,0 âˆ’Ti,2)âˆ•2h = 0, i = 1, 2, â€¦ , M âˆ’1 giv-
ing M âˆ’1 equations.
On ğœ•Î©4, there is a Dirichlet BC: TM,j = g(a, yj), j = 1, 2, â€¦ , N giving N
equations.
The total number of equations in (2) + (3) is (M âˆ’1)N + N + M âˆ’1 + M âˆ’1 + N =
MN + 2M + N âˆ’2. Hence, there are as many equations as unknownsand a linear sys-
tem of equations can be set up when the unknownTi,j elements have been renumbered
into a vector Ti, i = 1, 2, â€¦ , MN + 2M + N âˆ’2.

156
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
Exercise 7.3.1. Discretize the Laplace equation in polar coordinates presented in
Example 7.2. Follow the recipe DG,DD,DB. Observe that the region Î© is a rectangle
in the (r, ğœ‘)-space. Find second-order approximations to the PDE and the BCs.
Exercise 7.3.2. Discretize the eigenvalue problem in Example 7.4 assuming the
region Î© is a square with side length = 1. Formulate the corresponding algebraic
eigenvalue problem Au = ğœ†u.
7.4
ANSATZ METHODS FOR ELLIPTIC PDEs
So far we have demonstrated the FDM on problems defined on rectangular domains.
However, real problems often involve domains with irregular shapes. To demonstrate
the FEM, we apply the method to Poissonâ€™s problem (7.1), but assume that the region
Î© has a more complicated shape (not a square) (Figure 7.9).
7.4.1
Starting with the PDE Formulation
Instead of the FDM we now choose an ansatz for the approximatesolution of equation
(7.1), i.e.,
âˆ’ğœ•2u
ğœ•x2 âˆ’ğœ•2u
ğœ•y2 = f(x, y),
(x, y) âˆˆÎ©
u = 0,
(x, y) âˆˆğœ•Î©
and use Galerkinâ€™s method. The generalization of the 1D problem to a 2D problem is
straightforward: change âˆ«to âˆ«âˆ«and dâˆ•dx to grad and repeat the formulas in Section
4.3 to the 2D case. Denote by uh(x, y) the ansatz function
uh(x, y) =
N
âˆ‘
j=1
cjğœ‘j(x, y)
(7.24)
where the basis functions ğœ‘j(x, y) are chosen to satisfy the BCs, i.e.
ğœ‘j(x, y)|ğœ•Î© = 0,
j = 1, 2, â€¦ , N
(7.25)
When uh(x, y) is inserted into the PDE, we obtain a residual function r(x, y):
r(x, y) =
N
âˆ‘
j=1
cjÎ”ğœ‘j(x, y) + f(x, y) â‰ 0
(7.26)
In order to make r(x, y) â€œsmallâ€, we use Galerkinâ€™s method, which means that r(x, y)
is orthogonal to ğœ‘i(x, y), i = 1, 2, â€¦ , N:
âˆ«âˆ«Î©
r(x, y)ğœ‘i(x, y)dxdy = 0
(7.27)

ANSATZ METHODS FOR ELLIPTIC PDEs
157
x
y
Î©
Figure 7.9
A region to be discretized with the FEM
âˆ«âˆ«Î©
(
N
âˆ‘
j=1
cjÎ”ğœ‘j(x, y) + f(x, y))ğœ‘i(x, y)dxdy = 0
N
âˆ‘
j=1
cj âˆ«âˆ«Î©
ğœ‘iÎ”ğœ‘jdxdy + âˆ«âˆ«Î©
f(x, y)ğœ‘idxdy = 0
Now use integration â€œby partsâ€ in 2D
âˆ«âˆ«Î©
ğœ‘iÎ”ğœ‘jdxdy = âˆ®ğœ•Î©
ğœ‘i
ğœ•ğœ‘j
ğœ•n ds âˆ’âˆ«âˆ«Î©
âˆ‡ğœ‘i â‹…âˆ‡ğœ‘jdxdy
(7.28)
Compare this formula with the corresponding integration by parts in 1D
âˆ«
1
0
ğœ‘iğœ‘â€²â€²
j dx = [ğœ‘iğœ‘â€²
j]1
0 âˆ’âˆ«
1
0
ğœ‘â€²
iğœ‘â€²
jdx
As ğœ‘i = 0 on ğœ•Î© this integral = 0, and we finally obtain
N
âˆ‘
j=1
cj âˆ«âˆ«Î©
âˆ‡ğœ‘i â‹…âˆ‡ğœ‘jdxdy = âˆ«âˆ«Î©
f(x, y)ğœ‘idxdy,i = 1, 2, â€¦ , N
(7.29)
which is an N Ã— N linear system of equations for the coefficients cj:
Ac = f
where
Ai,j = âˆ«âˆ«Î©
âˆ‡ğœ‘i â‹…âˆ‡ğœ‘jdxdy,
fi = âˆ«âˆ«Î©
f(x, y)ğœ‘idxdy
(7.30)
A is called the stiffness matrix, where stiffness is related to a material property and
not the concept â€œstiffâ€ in connection with certain ODE problems (see Chapter 3). The
right hand side vector f is called the load vector.

158
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
7.4.2
Starting with the Weak Formulation
The analytical solution of equation (7.1) is referred to as the strong (or classical)
solution, but for PDEs, in general, there is also a weak (or variational) formulation
just as for the 1D problems in Section 4.3. The weak formulation is demonstrated on
a slightly more general PDE than (7.1).
âˆ’div(ğœ…âˆ‡u) + pâ‹…âˆ‡u + qu = f(x, y)
in
Î©
(7.31a)
ğœ…ğœ•u
ğœ•n = ğ›¼u + g(x, y)
on
ğœ•Î©
(7.31b)
where ğœ…, p, and q can be constants or depend on (x, y). This PDE with the BC is linear
and corresponds to a generalization of the BVP problem (4.57) to 2D.
For the weak formulation, multiply equation (7.31a) with a test function
v = v(x, y) âˆˆU and integrate over the region Î©
âˆ«âˆ«Î©
(âˆ’div(ğœ…âˆ‡u) + pâ‹…âˆ‡u + qu)vdxdy = âˆ«âˆ«Î©
fvdxdy
(7.32)
Use integration â€œby partsâ€ in 2D on the first term
âˆ’âˆ«âˆ«Î©
div(ğœ…âˆ‡u)vdxdy = âˆ’âˆ®ğœ•Î©
ğœ…ğœ•u
ğœ•nvds + âˆ«âˆ«Î©
ğœ…âˆ‡uâ‹…âˆ‡vdxdy
(7.33)
Using the BC (7.31b) in equation (7.33), we obtain the weak formulation: Find u âˆˆU
so that
âˆ«âˆ«Î©
(ğœ…(âˆ‡uâ‹…âˆ‡v) + (pâ‹…âˆ‡u)v + quv)dxdy âˆ’âˆ®ğœ•Î©
ğ›¼uvds = âˆ«âˆ«Î©
fvdxdy + âˆ®ğœ•Î©
gvds
(7.34)
for all v âˆˆU, where U = C1(Î©). In equation (7.34), the quadratic terms are collected
in the left hand side and the linear terms in the right hand side.
When there are different types of BCs on ğœ•Î©, the weak formulation must be
changed accordingly, e.g., if we have both mixed and Dirichlet conditions
ğœ…ğœ•u
ğœ•n = ğ›¼1u + g1(x, y),
(x, y) âˆˆğœ•Î©1
u = 0,
(x, y) âˆˆğœ•Î©2
Then equation (7.34) is changed to: Find u âˆˆU such that
âˆ«âˆ«Î©
(ğœ…(âˆ‡uâ‹…âˆ‡v) + pâ‹…âˆ‡uv + quv)dxdy âˆ’âˆ®ğœ•Î©1
ğ›¼uvds = âˆ«âˆ«Î©
fvdxdy + âˆ®ğœ•Î©1
gvds
(7.35)
for all v âˆˆU, where U = C1
[0](Î©) and [0] means v = 0, on ğœ•Î©2.

ANSATZ METHODS FOR ELLIPTIC PDEs
159
Now, use Galerkinâ€™s method on the weak formulation (7.34), i.e., let
uh(x, y) =
N
âˆ‘
j=1
cjğœ‘j(x, y),
vh(x, y) = ğœ‘i(x, y), i = 1, 2, â€¦ , N
For the coefficients cj, we obtain the linear system of equations
(Ağœ…+ P + Q + B)c = f
where
Ağœ…ij = âˆ«âˆ«Î©
ğœ…âˆ‡ğœ‘i â‹…âˆ‡ğœ‘jdxdy,
Pij = âˆ«âˆ«Î©
ğœ‘ipâ‹…âˆ‡ğœ‘jdxdy,
Qij = âˆ«âˆ«Î©
qğœ‘iğœ‘jdxdy
Bij = âˆ«âˆ«ğœ•Î©
ğ›¼ğœ‘iğœ‘jds
fi = âˆ«âˆ«Î©
f(x, y)ğœ‘idxdy + âˆ®ğœ•Î©
gğœ‘ids
Exercise 7.4.1. Modify the weak formulation to Poissonâ€™s equation with a nonho-
mogeneous BC
âˆ’ğœ•2u
ğœ•x2 âˆ’ğœ•2u
ğœ•y2 = f(x, y),
(x, y) âˆˆÎ©
u = g(x, y),
(x, y) âˆˆğœ•Î©
Hint: Make a transformation similar to the one in Exercise 7.0.1 to obtain a homoge-
neous BC.
7.4.3
The Finite Element Method
Up to now nothing has been said about the basis functions ğœ‘j. We want the matrix
A to be sparse, in order to be competitive with the FDM. In the 1D case, ğœ‘j(x) were
chosen as â€œroof functionsâ€ (see Section 4.3) defined on a grid of subintervals.
In the 2D case, the grid is defined by subdivision of Î© into triangles Tk, k =
1, 2, â€¦ , M (Figure 7.10).
It is seen from the example above that the boundary ğœ•Î© will not be exactly rep-
resented, unless the boundary consists of straight lines coinciding with the triangle
sides. Hence
Î© â‰ˆÎ©T = âˆªM
1 Tk
However, by making the triangles sufficiently small, the boundary can be accurately
enough represented. In connection with this modification of Î©, we also change the
BCs of ğœ‘j(x, y) to
ğœ‘j(x, y)|ğœ•Î©T = 0,
j = 1, 2, â€¦ , N
For the definition of the triangular grid, we must define a numbering of both the
inner nodes Pj, j = 1, 2, â€¦ , N and the triangles Tk, k = 1, 2, â€¦ , M. Hence, for an
arbitrary triangle Tk, there are three nodes (corners).

160
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
x
y
Figure 7.10
Triangular discretization of a region
x
y
1
u
ğœ‘j(x, y)
Figure 7.11
A pyramid function
When the grid has been defined for the region Î©T, the basis functions can be
defined by associating to each node j a â€œpyramidâ€ function ğœ‘j(x, y) (Figure 7.11).
The side of a pyramid is a triangle, hence every basis function ğœ‘i(x, y) consists
of a number of triangular parts of planes and can, therefore, be given an analytical
description, which, however, is rather extensive, so we refrain from this. Instead, a
splitting technique of the integrals is used.
Aij = âˆ«âˆ«Î©T
âˆ‡ğœ‘i â‹…âˆ‡ğœ‘jdxdy,
fi = âˆ«âˆ«Î©T
f(x, y)ğœ‘idxdy
The matrix elements consist of double integrals evaluated over the whole region Î©T.
A trick simplifying this computation is to split this integral into a sum of integrals
where each integral is computed over each triangle:
Aij =
M
âˆ‘
k=1 âˆ«âˆ«Tk
âˆ‡ğœ‘iâˆ‡ğœ‘jdxdy,
fi =
N
âˆ‘
k=1 âˆ«âˆ«Tk
f(x, y)ğœ‘idxdy
(7.36)

ANSATZ METHODS FOR ELLIPTIC PDEs
161
Tk
K1
(x1, y1)
K3
(x3, y3)
K2 (x2, y2)
Figure 7.12
Local numbering of the nodes of a linear element
Assume that triangle Tk has the nodes K1, K2, and K3. To simplify the notation,
introduce a local numbering of the nodes for the triangle Tk: node 1, 2, and 3 with
coordinates (x1, y1), (x2, y2), and (x3, y3) (Figure 7.12).
In the triangle Tk, there are three nonzero basis functions, namely those associated
with node i = 1, 2, and 3. These basis functions have the form
ğœ‘i(x, y) = ai + bix + ciy,
(x, y) âˆˆTk,
i = 1, 2, 3
Furthermore, as all the basis functions have the property
ğœ‘i(xj, yj) =
{1,
if i = j
0,
if i â‰ j
the coefficients ai, bi, ci satisfy the linear system of equations
â›
âœ
âœâ
1
x1
y1
1
x2
y2
1
x3
y3
â
âŸ
âŸâ 
â›
âœ
âœâ
a1
a2
a3
b1
b2
b3
c1
c2
c3
â
âŸ
âŸâ 
=
â›
âœ
âœâ
1
0
0
0
1
0
0
0
1
â
âŸ
âŸâ 
and therefore
â›
âœ
âœâ
a1
a2
a3
b1
b2
b3
c1
c2
c3
â
âŸ
âŸâ 
=
â›
âœ
âœâ
1
x1
y1
1
x2
x3
1
x3
y3
â
âŸ
âŸâ 
âˆ’1
In addition, as
âˆ‡ğœ‘i =
(
bi
ci
)
we obtain
âˆ«âˆ«Tk
âˆ‡ğœ‘i â‹…âˆ‡ğœ‘jdxdy = (bibj + cicj)YTk
(7.37)
where YTk is the area of Tk. Note that the elements of A are here computed analytically
with an explicit formula.
Hence, each triangle Tk contributes with a 3 Ã— 3 matrix Aloc
k , the local stiffness
matrix. However, as the true node numbers are K1, K2, and K3, the elements of Aloc
k

162
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
are spread out to the corresponding positions in a sparse N Ã— N matrix Ak:
Aloc
k
=
â›
âœ
âœâ
x
x
x
x
x
x
x
x
x
â
âŸ
âŸâ 
â†’
Ak =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
.....
.....
.....
.....
....x
....x
....x
.....
.....
.....
.....
.....
....x
....x
....x
.....
.....
.....
.....
.....
....x
....x
....x
.....
.....
.....
.....
.....
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
As the BC in equation (7.1) is homogeneous, triangles with nodes on the boundary
will be treated separately. For a triangle having two nodes on the boundary, there will
be only one element â‰ 0 in Aloc
k
and if there is one node on the boundary, there will
be four elements â‰ 0 in the local stiffness matrix.
When Aloc
k
for triangle Tk has been computed it is added, or rather assembled to
the stiffness matrix
A = 0,
for
k = 1 âˆ¶M
A = A + Ak
end
The load vector f is computed in the same way. Each triangle Tk contributes with
a local load vector floc
k
being 3 Ã— 1 and the components of which are spread out to the
true positions in a sparse N Ã— 1 vector fk:
floc
k
=
â›
âœ
âœâ
x
x
x
â
âŸ
âŸâ 
â†’
fk =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
.
x
.
x
.
x
.
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
These vectors are assembled to the load vector f:
f = 0,
for
k = 1 âˆ¶M
f = f + fk
end
The components of fk should be computed numerically as f(x, y) may be complicated
and therefore not possible to compute the integral analytically.
When the linear system
Ac = f
has been solved with some sparse direct (or possibly iterative) method, the coeffi-
cients cj are known and hence the ansatz function
uh(x, y) =
N
âˆ‘
j=1
cjğœ‘j(x, y)

ANSATZ METHODS FOR ELLIPTIC PDEs
163
can be computed at any point (x, y) âˆˆÎ©T. The ansatz solution is a piecewise linear
function in x and y with the property
uh(xj, yj) = cj
(7.38)
When (x, y) âˆˆTk, uh(x, y) is computed as a linear function obtained by linear inter-
polation through the node points of the triangle.
Observe that this discussion of the FEM is based on homogeneous BCs, i.e., u = 0
on the boundary ğœ•Î©. If the BCs are nonhomogeneous, i.e., u = g(x, y) on the bound-
ary, the ansatz must be modified to
uh(x, y) =
âˆ‘
IP
cIP
j ğœ‘IP
j (x, y) +
âˆ‘
BP
g(xBP
j , yBP
j )ğœ‘BP
j (x, y)
(7.39)
where IP are the inner points and BP are the boundary points.
The FEM can be generalized to
â€¢ other PDEs
â€¢ other BCs
â€¢ other basis functions giving higher accuracy
â€¢ 3D problems
â€¢ time-dependent problems
Hence, FEM is a very flexible, accurate, and stable method for solving PDE prob-
lems of different types. FEM was first applied to problems in solid mechanics but
is nowadays used to solve all kinds of PDE models in science and engineering. The
Comsol Multiphysics program is designed for scientific computing of such models
(see Section B.2).
Exercise 7.4.2. In equation (7.37), the elements of the local stiffness matrix Aloc
k
for triangle Tk
(Aloc
k )ij = âˆ«âˆ«Tk
âˆ‡ğœ‘i â‹…âˆ‡ğœ‘jdxdy
were computed. Derive a corresponding formula or suggest a numerical integration
method for the elements of a local mass matrix Qloc
k
for the triangle Tk.
(Qloc
k )ij = âˆ«âˆ«Tk
ğœ‘iğœ‘jdxdy
Exercise 7.4.3. Derive the linear system of equations Ac = f in the case the BCs
are nonhomogeneous (7.2). The ansatz function is given in equation (7.39).

164
NUMERICAL METHODS FOR ELLIPTIC PARTIAL DIFFERENTIAL EQUATIONS
BIBLIOGRAPHY
1. G.D. Smith, â€œNumerical solution of partial differential equationsâ€, 3rd ed, 1986, Oxford
University Press.
2. A. Iserles, â€œA first course in the numerical analysis of differential equationsâ€, 1996, Cam-
bridge University Press
3. K. Eriksson, D. Estep, P. Hansbo, C. Johnson: Computational differential equationsâ€, 2004,
Studentlitteratur

8
NUMERICAL METHODS FOR
HYPERBOLIC PDEs
Hyperbolic partial differential equations (PDEs) occur as mathematical models of
conservation laws and are found in, e.g., transport process and wave propagation
problems. Information travels with finite speed in contrast to parabolic PDEs where
an initial value immediately effects the solution in all other space points.
A fundamental property of hyperbolic PDEs is that geometric features such as
steep fronts and discontinuities in the solution (in the weak sense, see below), are
propagated with time. For linear problems, jumps come from the initial data, while
in nonlinear cases, discontinuities can develop in the solution even from smooth ini-
tial data. Therefore, for hyperbolic PDEs, we are not only interested in the order of
accuracy of a method but also in the treatment of discontinuities. Important concepts
in the description of the conservation properties are dissipation (loss of energy) and
dispersion (distorted phase relations owing to variable wave speed).
The classical hyperbolic PDE is the wave equation (see Chapter 5):
ğœ•2u
ğœ•t2 âˆ’c2 ğœ•2u
ğœ•x2 = 0,
âˆ’âˆ< x < âˆ,
t > 0
(8.1)
The general solution of this equation, the dâ€™Alembert solution, is
u(x, t) = f(x âˆ’ct) + g(x + ct)
(8.2)
where f(x) and g(x) are arbitrary twice differentiable functions. The solution u(x, t)
corresponds to two waves, traveling along the x-axis, one to the left with speed âˆ’c
and one to the right with speed c (see Figure 8.1)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

166
NUMERICAL METHODS FOR HYPERBOLIC PDEs
âˆ’4
âˆ’3
âˆ’2
âˆ’1
0
1
2
3
4
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
u(x, 0) = f(x) + g(x)
f(x âˆ’ ct)
g(x + ct)
c âˆ’>
<âˆ’ c
x
u
Figure 8.1
Solution of the wave equation
The wave equation (8.1) is a second-order PDE and can be written as a system of
two first-order PDEs. Let y be a vector and let
y1 = ğœ•u
ğœ•t ,
y2 = cğœ•u
ğœ•x
Inserting these new variables into (8.1) and using the fact that utx = uxt, we get the
first-order system
ğœ•y
ğœ•t + Ağœ•y
ğœ•x = 0
(8.3)
where A is the matrix
A = âˆ’c
(
0
1
1
0
)
(8.4)
Note that the eigenvalues of A, âˆ’c, and c, are the velocities of the waves in the general
solution.
Definition 1: A system of first-order PDEs
ğœ•u
ğœ•t + Ağœ•u
ğœ•x = 0
(8.5)
is hyperbolic if the real matrix A is diagonalizable with real eigenvalues.

NUMERICAL METHODS FOR HYPERBOLIC PDEs
167
âˆ’4
âˆ’3
âˆ’2
âˆ’1
0
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
u0(x)
a âˆ’>
x
u
u(x,t) = u0(x âˆ’ at)
Figure 8.2
Solution of the advection equation
If the matrix A consists of only one element a, we get the following scalar hyper-
bolic homogeneous PDE, used as model problem:
ğœ•u
ğœ•t + ağœ•u
ğœ•x = 0,
âˆ’âˆ< x < âˆ,
t > 0
(8.6)
This equation is known as the advection equation (see Chapter 1) and is also called
the transport equation or the one-way wave equation. With an initial condition given
on the whole x-axis (Cauchyâ€™s problem)
u(x, 0) = u0(x),
âˆ’âˆ< x < âˆ
(8.7)
the solution is a traveling wave
u(x, t) = u0(x âˆ’at)
(8.8)
Hence, the initial data is simply advected with constant velocity a to the right if a > 0
(see Figure 8.2). The equation (8.6) is the simplest hyperbolic PDE, being linear and
with a constant coefficient.
A scalar conservation law is a nonlinear hyperbolic PDE
ğœ•u
ğœ•t + ğœ•
ğœ•xf(u) = 0,
(8.9a)
defined by the function f(u), called the flux function. The form (8.9a) is called the
conservative formulation of the PDE.

168
NUMERICAL METHODS FOR HYPERBOLIC PDEs
If f(u) is differentiable, the PDE can be written
ğœ•u
ğœ•t + a(u)ğœ•u
ğœ•x = 0
(8.9b)
where a(u) = f â€²(u). The form (8.9b) is called the nonconservative formulation. From
numerical point of view, it is important if (8.9a) or (8.9b) is used as starting point for
numerical solution, see Section 8.3.
A special case is
ğœ•u
ğœ•t + uğœ•u
ğœ•x = 0
(8.10a)
known as the nonconservative formulation of the inviscid Burgersâ€™ equation often
used as a model problem for a nonlinear hyperbolic PDE. This equation will produce
solutions with shocks even for smooth initial data. The conservative form of (8.10a)
is
ğœ•u
ğœ•t + 1
2
ğœ•u2
ğœ•x = 0
(8.10b)
Compare (8.10a) with Burgersâ€™ viscous PDE where a diffusive term has been
added
ğœ•u
ğœ•t + uğœ•u
ğœ•x = ğœˆğœ•2u
ğœ•x2
(8.11)
This equation is much easier to solve numerically than (8.10), see also Exercise
5.3.2. Jan Burgers was a Dutch physicist active in the first half of the 20th
century.
An important concept for hyperbolic PDEs is the characteristic.
Definition 2: The characteristics of (8.9) are the curves in the (x, t)-plane defined
by the ordinary differential equation (ODE)
dx
dt = a(u(x(t), t))
(8.12)
Along a characteristic the solution u(x, t) is constant, which is seen from
du(x(t), t)
dt
= ğœ•u
ğœ•t + dx(t)
dt
ğœ•u
ğœ•x = ğœ•u
ğœ•t + a(u(x(t), t))ğœ•u
ğœ•x = 0
As u(x, t) has a constant value uC along a characteristic, we see that (8.12)
fulfills
dx(t)
dt
= a(uC) = aC â†’x(t) = aCt + C
Hence, the characteristics of (8.9) are straight lines (see Figure 8.3):

NUMERICAL METHODS FOR HYPERBOLIC PDEs
169
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Examples of characteristics of a scalar hyperbolic differential equation
Figure 8.3
Characteristics for the nonlinear advection equation
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Examples of characteristics of a scalar linear hyperbolic differential equation
0
0.2
0.4
0.6
0.8
1
Figure 8.4
Characteristics for the linear advection equation
For the advection equation (8.6), a(u) = a = constant and all characteristics have
the same slope (see Figure 8.4).
The characteristics can also converge to a point in the (x, t)-plane thereby creating
a shock in the solution, see Section 8.2.1 for numerical solution of Burgerâ€™s equation
(8.10).

170
NUMERICAL METHODS FOR HYPERBOLIC PDEs
In case the initial function is defined for x â‰¥0 only, a semi-infinite problem, a
boundary function is needed for x = 0, i.e., u(0, t) = ğ›¼(t). The solution of the model
problem then takes the form
u(x, t) =
{
ğ›¼(t âˆ’xâˆ•a)
if x âˆ’at < 0
u0(x âˆ’at)
if x âˆ’at â‰¥0
Hence, the initial and boundary values are advected along the characteristics.
For a bounded region 0 â‰¤x â‰¤1, BCs are needed together with an IC. For the
hyperbolic model problem (8.6), the formulation is
ğœ•u
ğœ•t + ağœ•u
ğœ•x = 0,
0 < x < 1,
t > 0
(8.13)
IC âˆ¶u(x, 0) = u0(x), 0 â‰¤x â‰¤1
BC âˆ¶u(0, t) = ğ›¼(t),
t > 0
if
a > 0
BC âˆ¶u(1, t) = ğ›½(t),
t > 0
if
a < 0
Observe that BC for problem (8.13) can be imposed only on the boundary x = 0
(not x = 1) if a > 0 as the characteristics are emanating from that boundary. If a < 0,
however, the BC has to be given for x = 1.
Consider the wave equation (8.1) (which can also be written as the first-order
system (8.3)) defined on the finite interval [0, 1]. For this problem, there are char-
acteristics in both directions. Hence, BCs are needed both for x = 0 and x = 1.
An interesting property of the advection equation is that discontinuities in the ini-
tial function u0(x) are propagated along the x-axis when t increases.
Assume that the initial condition for (8.7) is a stepfunction (also called a Riemann
initial condition):
u0(x) =
{
1,
x < 0
0,
x â‰¥0
(8.14)
The solution u0(x âˆ’at) is propagated without distortion by the advection equation.
Hence at a later time t = T > 0, the solution has moved to x = aT and the shape of
the solution curve remains the same as the initial function u0(x). Bernhard Riemann
was a German mathematician, active in the middle of the 19th century.
Now, discontinuous functions cannot be solutions of differential equations. The
function u0(x) must be continuously differentiable on âˆ’âˆ< x < âˆ. However, if
u0(x) is a discontinuous function, we can still talk about u(x, t) = u0(x âˆ’at) as a
solution in the weak sense, i.e., an integrated version of the PDE is satisfied for all
smooth functions ğœ‘(x, t)
âˆ«
âˆ
0
âˆ«
âˆ
âˆ’âˆ
uğœ‘t + auğœ‘xdxdt + âˆ«
âˆ
âˆ’âˆ
u0(x, 0)ğœ‘(x, 0)dx = 0
(8.15)

APPLICATIONS
171
This relation is obtained by multiplying (8.6) by a smooth function ğœ‘(x, t), integrate
over the (x, t) region and then integrate by parts. Compare this technique with the
Galerkin method in Chapter 4, where weak solutions for ODEs are treated.
In applications, e.g., gas dynamics, the moving jump is called a shock wave or
contact discontinuity, depending on which quantities jump. The following relation,
known as Rankineâ€“Hugoniotâ€™s theorem, gives the speed with which the shock prop-
agates: Assume that a discontinuity is moving with speed s and that the value of u to
the left of the jump is uL and to the right uR. Then the following relation holds for the
scalar conservation law (8.9a):
s(uL âˆ’uR) = f(uL) âˆ’f(uR)
(8.16)
Macquorn Rankine was a Scotish physicist and Pierre-Henri Hugoniot was a
French mathematician both active in the 19th century.
The generalization of the scalar conservation law (8.9) to a system of nonlinear
hyperbolic PDEs is
ğœ•u
ğœ•t + ğœ•
ğœ•xf(u) = 0,
âˆ’âˆ< x < âˆ,
t > 0
(8.17)
If the spatial derivation is performed, we get the nonconservative form
ğœ•u
ğœ•t + A(u)ğœ•u
ğœ•x = 0
(8.18)
where A(u) is the jacobian of f(u). The system is hyperbolic if A(u) is diagonalizable
and has real eigenvalues.
8.1
APPLICATIONS
Example 8.1. (Time-dependent hot flow in a pipe revisited)
As a first example of a hyperbolic first-order PDE, consider Example 6.1. Assume
that transport by diffusion is negligible, i.e., ğœ…= 0. The PDE then takes the form
ğœ•T
ğœ•t + vğœ•T
ğœ•x + 2h
ğœŒCR(T âˆ’Tcool) = 0,
0 < x < L,
t > 0
(8.19)
We need an initial condition T(x, 0) = Tinit(x) and a boundary condition T(0, t) =
T0(t), where Tinit(x) and T0(t) are known functions.
Example 8.2. (Time-dependent counterflow heat exchanger)
In Example 4.4, a heat exchanger is presented. If the temperature profiles have
not come to a steady state, the following system of hyperbolic PDEs model the

172
NUMERICAL METHODS FOR HYPERBOLIC PDEs
corresponding time-dependent problem on the x interval 0 < x < L:
ğœ•H
ğœ•t + uH
ğœ•H
ğœ•x = âˆ’a(H âˆ’C),
H(0, t) = H0,
H(x, 0) = H0(x)
(8.20)
ğœ•C
ğœ•t âˆ’uC
ğœ•C
ğœ•x = a(H âˆ’C),
C(L, t) = C0,
C(x, 0) = C0(x)
(8.21)
Example 8.3. (Wave equation)
Another example of a hyperbolic PDE is a model of the movements u(x, t) of a vibrat-
ing string
ğœ•2u
ğœ•t2 âˆ’c2 ğœ•2u
ğœ•x2 = 0,
0 < x < L,
t > 0
(8.21a)
where the parameter c is the velocity of the wave. For this equation, we need two ICs,
u(x, 0) = u0(x)
ğœ•u
ğœ•t (x, 0) = v0(x),
0 â‰¤x â‰¤L
and two BCs
u(0, t) = 0
u(L, t) = 0,
t â‰¥0
In Example 9.2, the wave equation is derived for a vibrating string of length L
(m), density ğœŒ( kgâˆ•m3), cross-section area A (m2), and string tension F (N). These
parameters are related to c through c2 = Fâˆ•ğœŒA. The total energy of the string is the
sum of the kinetic and the potential energy
Etot = âˆ«
L
0
(
1
2ğœŒA
(ğœ•u
ğœ•t
)2
+ 1
2F
(ğœ•u
ğœ•x
)2)
dx
(8.21b)
By differentiating Etot with respect to t we obtain dEtotâˆ•dt = 0, hence the total energy
is conserved.
The PDE (8.21a) is also valid for plane electromagnetic waves traveling in the x
direction. The variable u then represents the components of the orthogonal electric
and magnetic fields and c is the speed of light. Other types of initial and boundary
conditions are usually imposed.
Example 8.4. (Shock propagation in Eulerâ€™s equations)
As was mentioned in Chapter 5, hyperbolic PDEs occur in fluid dynamics modeled
by the Euler equations. Eulerâ€™s equations model shocks and contact discontinuities,
i.e., thin transition layers where the pressure, density, and speed of the fluid changes
significantly.
An example of a hyperbolic model sometimes used in gas dynamics is the com-
pressible isothermal Euler equations for a perfect gas in 1D, formulated as
ğœ•ğœŒ
ğœ•t + ğœ•(ğœŒu)
ğœ•x
= 0
(8.22a)

APPLICATIONS
173
0
0.5
1
1.5
2
2.5
3
0
0.5
1
Ï0
0
0.5
1
1.5
2
2.5
3
0
1
2
Ï
0
0.5
1
1.5
2
2.5
3
0
200
400
u
x
Figure 8.5
Evolution of density and velocity for Eulerâ€™s 1D model
ğœ•(ğœŒu)
ğœ•t
+ ğœ•(ğœŒu2 + p)
ğœ•x
= 0
(8.22b)
p = KğœŒğ›¾
(8.22c)
There are three nonlinear equations (one is algebraic) for the three unknowns ğœŒ
( kgâˆ•m3) (density), u (m/s) (velocity), and p ( Nâˆ•m2) (pressure).
In the so-called shock-tube problem, both ends of the tube are closed and a
diaphragm is separating two regions, one with high pressure and the other with low
pressure.
The ICs for density is
ğœŒ(x, 0) =
{
ğœŒ0,
x â‰¤Lâˆ•2
ğœŒ1,
x > Lâˆ•2 ,
u(x, 0) = 0
(8.23a)
and for velocity, it is u(x, 0) = 0
As BCs we have
u(0, t) = u(L, t) = 0
(8.23b)
For ğœŒ(0, t), numerical BCs are used (see Section 8.2.6), i.e., the value of ğœŒat the
boundaries is extrapolated from the values of ğœŒinside the tube. The evolution of ğœŒ
and u is sketched in Figure 8.5.

174
NUMERICAL METHODS FOR HYPERBOLIC PDEs
For ğ›¾= 2, the equations also model the flow of a thin layer of fluid under grav-
ity, the â€œshallow water equations.â€ The problem above then becomes a model of a
â€œdam-breakâ€ simulation if ğœŒis exchanged to h (m), the height of the water.
Exercise 8.1.1. Verify that Etot in (8.21b) is constant in time.
Exercise 8.1.2. Verify that the Euler equations in (8.22) can be written in the form
(8.18). Find the jacobian A(u) and calculate the eigenvalues of the jacobian. Verify
that the system is hyperbolic.
8.2
NUMERICAL SOLUTION OF HYPERBOLIC PDEs
Hyperbolic PDEs can be solved numerically with finite difference, finite volume,
or finite element methods. In this chapter, the first two discretization methods are
presented. We use (8.13) as model problem.
When the method of lines (MoL), see Section 6.3.1, is applied to (8.13),we start by
discretizing the x interval 0 â‰¤x â‰¤1 into a grid x0, x1, â€¦ , xN, where x0 = 0, xN = 1,
and xi = ihx, hx = 1âˆ•N. At the point x = xi, we discretize the PDE to an ODE with
Eulerâ€™s implicit method:
dui
dt = âˆ’aui âˆ’uiâˆ’1
hx
,
a > 0,
i = 1, 2, â€¦ N
We get the following ODE system:
du
dt = a
hx
Au + a
hx
f(t),
u(0) = u0
(8.24)
where
A =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
âˆ’1
0
0
â€¦
0
1
âˆ’1
0
â€¦
0
0
1
âˆ’1
â€¦
0
.
.
.
â€¦
0
.
.
.
â€¦
0
0
0
0
â€¦
âˆ’1
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
, f(t) =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
ğ›¼(t)
0
0
.
.
0
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
, u0 =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
u0(x1)
u0(x2)
u0(x3)
.
.
u0(xN)
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
(8.25)
The eigenvalues of the matrix (aâˆ•hx)A are all ğœ†i = âˆ’aâˆ•hx. Hence, they are all negative
and the system is stable.
If Eulerâ€™s explicit method is used to solve the time-dependent ODE system (8.24),
we know from Chapter 3 that the time step ht must fulfill the following condition to
obtain a numerically stable solution
htğœ†i âˆˆSEE
â†’
a ht
hx
â‰¤2
(8.26)

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
175
With a numerical test on (8.24) with Eulerâ€™s explicit method, we notice, however,
that when ahtâˆ•hx = 1.1, the numerical solution is unstable.
Hence, the theoretical stability result based on eigenvalue analysis as presented
for ODE systems in Chapter 3 is not correct for this semidiscretized hyperbolic PDE
model problem! The reason is that the matrix A in (8.25) is not diagonalizable! This
implies that the solution of the ODE system will have a strong initial polynomial
growth of size tNâˆ’1eâˆ’t. The difference equation system obtained with Eulerâ€™s method
will have a similar behavior. We therefore need another type of stability concept for
hyperbolic problems. In Section 8.4, the von Neumann analysis based on Fourier
analysis is presented.
Unless anything else is stated, the methods presented in this section are applied to
the model problem (8.13) only.
8.2.1
The Upwind Method (FTBS)
The method formulated above can be written as a difference equation, the FTBS
method (Forward-Time-Backward-Space):
ui,k+1 âˆ’ui,k
ht
= âˆ’a
ui,k âˆ’uiâˆ’1,k
hx
(8.27)
or
ui,k+1 = (1 âˆ’ğœ)ui,k + ğœuiâˆ’1,k
where ğœis defined as
ğœ= a ht
hx
(8.28)
The FTBS method (8.27) can also be illustrated by a stencil (see Figure 8.6).
The FTBS method, also called the upwind (or upstream) method, has first-order
accuracy in both space and time and the stability condition (see Section 8.4)
0 < ğœâ‰¤1
(8.29)
This inequality is known as the Courantâ€“Friedrichâ€“Lewy condition or simply the
CFL condition, from 1928 and ğœis called the Courant number. Richard Courant,
1 âˆ’ Ïƒ
Ïƒ
Figure 8.6
Stencil for the FTBS method

176
NUMERICAL METHODS FOR HYPERBOLIC PDEs
âˆ’0.2
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
x
u(x, 0.5)
u(x, 0.5)
âˆ’0.2
0
0.2
0.4
0.6
0.8
1
âˆ’10
âˆ’5
0
5
10
x
Figure 8.7
Stable and unstable numerical solution of the advection equation
Kurt Friedrichs, and Hans Lewy were German American mathematicians, active
in the 20th century. Courant was the founder of the famous Courant Institute in
New York.
Applying the upwind method (8.27) to the model problem (8.13) with the IC
u(x, 0) = 0, x > 0 and the BC u(0, t) = 1, t > 0, i.e., a stepfunction, gives a numeri-
cal solution shown as a graph in Figure 8.7. In the figure, the stepsize combinations
ht = 0.8hxâˆ•a and ht = 1.1hxâˆ•a have been used. For the larger stepsize ht, the solution
will be unstable (the amplitude of the oscillations increases as time t increases).
With the â€œmagic stepsize combinationâ€ ht = hxâˆ•a, i.e., ğœ= 1, however, it turns
out that the stepfunction will be perfectly preserved, moving along the positive x-axis
with speed a! See the modified equation (8.30) for an explanation.
For the smaller stepsize, we see that the numerical solution is smoothed out com-
pared to the exact solution. To understand this dissipation phenomenon, we can use
the modified equation, the PDE that is exactly satisfied by the numerical solution ui,k.
It can be derived using Taylorâ€™s expansion. However, the modified PDE will be a
series having an infinite number of terms. If the series is truncated after a few terms,
we obtain a PDE from which information about the nature of its analytical solution
can be found.
To find the modified equation, replace ui,k by the function v = v(xi, tk) and Taylor
expand
v(xi, tk+1) = v(xi, tk) + ht
ğœ•v
ğœ•t (xi, tk) + h2
t
2
ğœ•2v
ğœ•t2 (xi, tk) + â€¦

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
177
v(xiâˆ’1, tk) = v(xi, tk) âˆ’hx
ğœ•v
ğœ•x(xi, tk) + h2
x
2
ğœ•2v
ğœ•x2 (xi, tk) + â€¦
Insert these expansions into (8.27) and the following PDE at the point (xi, tk) is found:
ğœ•v
ğœ•t + ağœ•v
ğœ•x + ht
2
ğœ•2v
ğœ•t2 âˆ’ahx
2
ğœ•2v
ğœ•x2 + Â· Â· Â· = 0
Use the PDE (8.13) to obtain the following relations:
ğœ•2v
ğœ•t2 = âˆ’a ğœ•2v
ğœ•xğœ•t = a2 ğœ•2v
ğœ•x2
Hence, replace vtt by a2vxx and we obtain the following modified equation after having
neglected higher order terms:
ğœ•v
ğœ•t + ağœ•v
ğœ•x = ahx
2 (1 âˆ’ğœ)ğœ•2v
ğœ•x2
(8.30)
The right hand side term is a diffusion term and this causes the solution to be smoothed
out. Hence, the upwind method introducesdissipation into the numerical solution. We
see also that when ğœ= 1, there is no diffusion term and no dissipation.
In the beginning of this chapter, Burgersâ€™ inviscid equation (8.10) was presented.
The following example shows how a shock can develop from smooth initial data.
Example 8.5. (Burgersâ€™ equation with the upwind method)
We choose the conservative form of Burgersâ€™ equation, see also Example 8.5.
ğœ•u
ğœ•t + ğœ•u2
ğœ•x = 0,
0 < x < 1,
t > 0
With IC u(x, 0) = cos(2ğœ‹x) + 1 and periodic BC u(0, t) = u(1, t), the upwind method
gives the following graph after a number of steps (Figure 8.8).
Exercise 8.2.1. Write a program or convince yourself by some hand calculations
that the upstream method with ğœ= 1, the â€œmagic stepsize combinationâ€ applied to
the model problem (8.13) with a step function as IC will preserve the step function
for t > 0.
8.2.2
The FTFS Method
When the parameter a in the advection equation (8.13)is negative,the upwind method
gives unstable solutions. Instead the FTFS method (Forward-Time-Forward-Space)
can be used
ui,k+1 âˆ’ui,k
ht
= âˆ’a
ui+1,k âˆ’ui,k
hx
i.e.,
ui,k+1 âˆ’ui,k = âˆ’ğœ(ui+1,k âˆ’ui,k)
(8.31)

178
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
x
u(x, 0), u(x, T)
Burgers equation with smooth initial function and developing shock
Initial function â€“>
<â€“ Shock
Figure 8.8
Burgerâ€™s equation with smooth initial function and developing shock
8.2.3
The FTCS Method
To increase the accuracy, we try central differences in space, giving the FTCS method
(Forward-Time-Central-Space):
ui,k+1 âˆ’ui,k
ht
= âˆ’a
ui+1,k âˆ’uiâˆ’1,k
2hx
(8.32)
i.e.,
ui,k+1 = ui,k âˆ’ğœ
2 (ui+1,k âˆ’uiâˆ’1,k)
(8.33)
This method, however, turns out to be unstable for all ht, hx, see Section 8.3.
8.2.4
The Laxâ€“Friedrich Method
Another method used in practice is the Laxâ€“Friedrich method, which is first order in
time, second order in space, and symmetric, hence insensitive to the sign of a
ui,k+1 =
uiâˆ’1,k + ui+1,k
2
âˆ’ğœ
2 (ui+1,k âˆ’uiâˆ’1,k),
(8.34)
The Laxâ€“Friedrich method is stable for âˆ’1 â‰¤ğœâ‰¤1. The only difference compared
with the FTCS method is that ui,k in the right hand side of (8.33) is replaced by the
mean value of uiâˆ’1,k and ui+1,k in (8.34)

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
179
Exercise 8.2.2. Write a program or convince yourself by some hand calculations
that the Laxâ€“Friedrich method with ğœ= 1 applied to the model problem (8.13) with
a stepfunction as IC will preserve the stepfunction for t > 0.
Just like the upwind method, the Laxâ€“Friedrich method also introduces smoothing
in the numerical solution. This can be explained by the modified equation.
Peter Lax is a Hungarian mathematician, now Prof.Em. at the Courant Institute.
He received the prestigious Abel price in 2005.
Exercise 8.2.3. Show that the modified equation for Laxâ€“Friedrichsâ€™ method
applied to (8.13) is
ğœ•v
ğœ•t + ağœ•v
ğœ•x = a2ht
2
( 1
ğœ2 âˆ’1
) ğœ•2v
ğœ•x2
Hence when ğœ= Â±1, there is no diffusion term.
8.2.5
The Leap-Frog Method
The leap-frog method (see Section 3.4)
ui,k+1 âˆ’ui,kâˆ’1
2ht
+ a
ui+1,k âˆ’uiâˆ’1,k
2hx
= 0
(8.35)
is second order in both time and space. It is stable for all values of ğœand does
not involve any diffusivity. For nonlinear problems, however, this method becomes
unstable for the model problem (8.13).
8.2.6
The Laxâ€“Wendroff Method
Yet another method second order in both time and space is the Lax-Wendroff method.
This method is based on a trick, where derivatives in t are expressed as derivatives in
x. Start with Taylor expansion at the point (xi, tk):
u(xi, tk+1) = u(xi, tk) + ht
ğœ•u
ğœ•t (xi, tk) + h2
t
2
ğœ•2u
ğœ•t2 (xi, tk) + O(h3
t )
(8.36)
Use the PDE (8.13) to obtain the relations:
ğœ•u
ğœ•t = âˆ’ağœ•u
ğœ•x,
ğœ•2u
ğœ•t2 = âˆ’a ğœ•2u
ğœ•xğœ•t = a2 ğœ•2u
ğœ•x2
Insert space derivatives instead of time derivatives into the Taylor expansion, dis-
cretize and we obtain:
ui,k+1 = ui,k âˆ’ğœ
2 (ui+1,k âˆ’uiâˆ’1,k) + ğœ2
2 (ui+1,k âˆ’2ui,k + uiâˆ’1,k)
(8.37)
The method is stable for âˆ’1 â‰¤ğœâ‰¤1. When the Laxâ€“Wendroff method is used there
is a problem at the right boundary. As there are no BCs at x = 1, we have to impose

180
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
â€“0.2
0
0.2
0.4
0.6
0.8
1
1.2
x
u(x, 1)
Figure 8.9
The model problem with Lax-Wendroffâ€™s method, dispersion effects
artificial numerical boundaryconditionsin orderto be able to use the stencil. A simple
way to construct values at xN = 1 is to extrapolate the numerical solution by linear
extrapolation
uNk = uNâˆ’1,k + uNâˆ’1,k âˆ’uNâˆ’2,k = 2uNâˆ’1,k âˆ’uNâˆ’2,k
(8.38)
or, even better, quadratic extrapolation
When the Laxâ€“Wendroff method is applied to the model problem with a step func-
tion as initial function, we obtain the result seen in Figure 8.9.
In Figure 8.9, we see that the Laxâ€“Wendroff method generates spurious oscil-
lations. This is typical of a method being second order in time and is related to a
dispersion error introduced by the numerical method.
Burton Wendroff is an American mathematician still active.
If we let hx, ht â†’0 in the Laxâ€“Wendroff discretization, we get the PDE expression
(8.13) in the left hand side and a diffusion term in the right hand side
ğœ•u
ğœ•t + ağœ•u
ğœ•x = a2h2
t
2
ğœ•2u
ğœ•x2
(8.39)
Hence, the original hyperbolic PDE is approximated by a parabolic PDE, and the
solution can no longer contain discontinuities. Just as for the previous methods, this
is an example of artificial dissipation. Other methods with similar numerical behavior
are obtained if the test problem (8.13) is replaced by the PDE
ğœ•u
ğœ•t + ağœ•u
ğœ•x = ğœ–ğœ•2u
ğœ•x2
where ğœ–is a small positive quantity.

NUMERICAL SOLUTION OF HYPERBOLIC PDEs
181
Î»
2(1 âˆ’ Î»)
Î»
âˆ’1
Figure 8.10
Stencil for central differences applied to the wave equation
8.2.7
Numerical Method for the Wave Equation
A special case of hyperbolicPDE is the wave equation in Example 8.3. It is reasonable
to believe that there are special methods, efficient and accurate for this PDE. The
numerical treatment can be based on central difference approximations in both x and
t giving the following difference equation
ui,k+1 âˆ’2ui,k + ui,kâˆ’1
h2
t
= c2 ui+1,k âˆ’2ui,k + uiâˆ’1,k
h2x
This can be written as
ui,k+1 = ğœ2ui+1,k + 2(1 âˆ’ğœ2)ui,k + ğœ2uiâˆ’1,k âˆ’ui,kâˆ’1
(8.40a)
where ğœ= chtâˆ•hx. The corresponding stencil is shown in Figure 8.10, where ğœ†= ğœ2.
This method gives stable solutions for âˆ’1 â‰¤ğœâ‰¤1.
For the magic stepsize ht = hxâˆ•c, a traveling wave u(x, t) = f(x âˆ’ct) with exact
initial values ui,0 = f(ihx),
ui,1 = f(ihx âˆ’cht), i = 0, 1, 2, â€¦ is exactly preserved
(in exact arithmetic) when ğœ= 1 in (8.40a)
ui,k+1 = ui+1,k + uiâˆ’1,k âˆ’ui,kâˆ’1
(8.40b)
Example 8.6. (Wave equation with the magic stepsize)
Consider the wave equation in Example 8.3 (see also Example 5.3) with the parameter
values c = 1, L = 3, and initial conditions u0(x) = âˆ’sin(kx), v0(x) = ğœ”cos(kx) where
ğœ”= 2ğœ‹and k = 2ğœ‹. Discretization according to (8.40b) with hx = Lâˆ•50, ht = hxâˆ•c
and taking N = 10 time steps gives the numerical solution (Figure 8.11).
The wave equation is closely connected to Maxwellâ€™s equations described in
Section 5.3.6. A simple form of these equations is (see Exercise 5.3.6)
ğœ•Hy
ğœ•t
= 1
ğœ‡0
ğœ•Ez
ğœ•x

182
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.5
1
1.5
2
2.5
3
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
Wave equation with central differences
x
u
âˆ’> c 
Figure 8.11
Numerical solution of the wave equation
ğœ•Ez
ğœ•t = 1
ğœ–0
ğœ•Hy
ğœ•x
One possible way to compute Ez and Hy would be to solve the two wave equations
for the two components. A better and more efficient way, however, is to use Yeeâ€™s
method on the first-order PDE system. That method is based on staggered grids (see
Section 3.5.3) in both the x and the t direction and is demonstrated on the system
(8.3), which is equivalent to the Maxwell equation system above
y2k+1âˆ•2
i+1âˆ•2 = y2kâˆ’1âˆ•2
i+1âˆ•2 + c ht
hx
(y1k
i+1 âˆ’y1k
i )
y1k+1
i
= y1k
i + c ht
hx
(y2k+1âˆ•2
i+1âˆ•2 âˆ’y2k+1âˆ•2
iâˆ’1âˆ•2 )
Hence, the two components y1 and y2 are computed on different grids. A compar-
ison with (3.57) shows that the method is based on the leap-frog method and has
second-orderaccuracy.It can also be shown to preservethe energyof the wave (8.21b)
if the energy is defined from a trapezoidal expression instead of the integral itself.
Exercise 8.2.4. Formulate the upwind method for the inhomogeneous advection
equation, i.e.,
ğœ•u
ğœ•t + ağœ•u
ğœ•x = g(x, t)

THE FINITE VOLUME METHOD
183
Exercise 8.2.5. Give the stencil corresponding to the FTFS method in (8.31).
Exercise 8.2.6. Formulate a suitable difference approximation based on FTBS and
FTFS to solve numerically the counterflow heat problem in Example 8.2.
Exercise 8.2.7. Give the stencils corresponding to Laxâ€“Friedrichâ€™s method and
Laxâ€“Wendroffâ€™s method.
Exercise 8.2.8. As the method (8.40) is a two-step method, we need two ICs to
start up the difference equation. Use the ICs given in Example 8.3. Work out the
discretized ICs needed.
Exercise 8.2.9. Consider the wave equation in Example 8.3.
a) Discretize the x interval according to xi = ihx, i = 0, 1, 2, .., N + 1, where hx =
Lâˆ•(N + 1). With the MoL and central differences, a system of second-order
ODEs is obtained.
d2u
dt2 = Au,
u(0) = u0,
du
dt (0) = v0
Find the values of the matrix A and the vectors u0 and v0.
b) Write the system in (a) as a system of first-order ODEs
dw
dt = Bw,
w(0) = w0
Give the values of B and w0.
c) Calculate the eigenvalues of B.
d) If the explicit midpoint method (3.42) is used on the first-order system in (b),
for which time steps ht is the numerical solution stable?
8.3
THE FINITE VOLUME METHOD
In this section, the finite volume method (FVM) is treated. Just like the FDM and the
FEM, solution values are calculated at discrete grid points. In the FVM, each grid
point is surrounded by a control volume or cell. What the FVM has in advantage
compared to the other two methods is that the FVM gives approximate u values that
satisfy a discretized version of the integrated form of the conservation law (8.9a), i.e.,
âˆ«
xi+1
xi
(u(x, tk+1) âˆ’u(x, tk))dx = âˆ«
tk+1
tk
(f(u(xi, t) âˆ’f(u(xi+1, t)))dt
(8.41)
where f(u(x, t)) is the flux function. The relation (8.41) simply means that the change
of a quantity u(x, t) accumulated in the â€œvolumeâ€ [xi, xi+1] balances the net influx, i.e.,

184
NUMERICAL METHODS FOR HYPERBOLIC PDEs
the difference between influx to and outflux from the volume during the time interval
[tk, tk+1].
To explain the FVM in 1D, introduce a grid with grid points xi and the stepsize hx.
Also introduce control â€œvolumesâ€ Vi defined by the intervals [xiâˆ’1âˆ•2, xi+1âˆ•2], where
xiÂ±1âˆ•2 = (xiÂ±1 + xi)âˆ•2.
Now consider the conservation law (8.9)
ğœ•u
ğœ•t + ğœ•
ğœ•x f(u) = 0
The volume average of u(x, t) at time tk in the volume Vi is
ui(tk) =
1
xi+1âˆ•2 âˆ’xiâˆ’1âˆ•2 âˆ«
xi+1âˆ•2
xiâˆ’1âˆ•2
u(x, tk)dx
(8.42)
and similar for t = tk+1. Now integrate (8.9) over the volume Vi
âˆ«
xi+1âˆ•2
xiâˆ’1âˆ•2
ğœ•u
ğœ•t dx = f(uiâˆ’1âˆ•2) âˆ’f(ui+1âˆ•2)
where f(uiÂ±1âˆ•2) = f(u(xiÂ±1âˆ•2, t)) are the fluxes at the cell interfaces. Changing the
order of integration and differentiation gives
dui
dt = 1
hx
(f(uiâˆ’1âˆ•2) âˆ’f(ui+1âˆ•2))
(8.43)
which is an exact relation for the volume averages, i.e., no approximations have
been made so far. The ODE system (8.43) resembles the MoL, see Section 6.3.1,
but the right hand side contains expressions of u that are not known. If the explicit
Euler method with time step ht is used to approximate the time derivate and ui is
approximated by ui, we obtain the following conservative method, where uiÂ±1âˆ•2 can
be computed with, e.g., interpolation of the ui values.
ui,k+1 = ui,k + ht
hx
(f(uiâˆ’1âˆ•2) âˆ’f(ui+1âˆ•2))
(8.44)
By rearranging terms in (8.44) and summing over i, we obtain
hx
N
âˆ‘
i=1
(ui,k+1 âˆ’ui,k) = ht(f(u1âˆ•2) âˆ’f(uN+1âˆ•2))
which is the discrete version of the integral balance (8.41), equivalent to the basic
conservation law (8.9a).

SOME EXAMPLES OF STABILITY ANALYSIS FOR HYPERBOLIC PDEs
185
Example 8.7. (Numerical solution of Burgersâ€™ equation, revisited)
Consider Burgersâ€™ equation on conservative form
ğœ•u
ğœ•t + 1
2
ğœ•u2
ğœ•x = 0, âˆ’âˆ< x < âˆ,
t > 0
with IC
u(x, 0) =
{
2,
x < 0
1,
x â‰¥0
and BC
u(0, t) =
{
1,
t = 0
2,
t > 0
Hence, the problem describes a shock coming in at x = 0 and moving in the positive
x direction.
Here the flux function is f(u) = u2âˆ•2 and the upwind method gives
ui,k+1 = ui,k âˆ’ht
2hx
(u2
i,k âˆ’u2
iâˆ’1,k)
which is conservative in this form. Make a grid of the x interval [0, 2.5] using the
stepsize hx = 0.025 and of the t interval [0, 1] using the time step ht = 0.0125. Owing
to Rankineâ€“Hugoniotâ€™s relation (8.16), the speed s of the shock is s = 1.5. Hence, at
time t = 1, the shock has reached the x value x = sâ‹…1 = 1.5, which is in agreement
with Figure 8.10.
However,if the nonconservativeform of Burgersâ€™ equation (8.10a)is used together
with the upwind scheme
ui,k+1 = ui,k âˆ’ht
hx
ui,k(ui,k âˆ’uiâˆ’1,k)
and the same values of the numerical parameters hx and ht, the shock speed is lower
than the speed obtained with the conservative form of the method, see Figure 8.12.
8.4
SOME EXAMPLES OF STABILITY ANALYSIS FOR HYPERBOLIC
PDEs
As was pointed out earlier and shown in an example, eigenvalue analysis is not ade-
quate for investigation of the stability of numerical solutions of hyperbolic PDEs.
As the wave equation generates periodic solutions, the appropriate tool for stability
analysis should be based on Fourier analysis.

186
NUMERICAL METHODS FOR HYPERBOLIC PDEs
0
0.5
1
1.5
2
2.5
1
1.2
1.4
1.6
1.8
2
x
u(x, 1)
Burgers equation on conservativs form and nonconservative form
Nonconservative form âˆ’>
<âˆ’ Conservative form
Figure 8.12
Numerical computation of shock waves
As hyperbolic equations preserve waveforms, it seems natural to make the follow-
ing ansatz for the analytical solution:
u(x, t) = q(t)ejğœ”x
(8.45)
where j =
âˆš
âˆ’1, ğœ”is a spatial frequency (wave number) and q(t) is a complex ampli-
tude function.
Hence, for the numerical solution ui,k, we make the ansatz:
ui,k = qkejğœ”xi
(8.46)
Insert this ansatz into the FTBS method in Section 8.2.1:
qk+1ejğœ”xi = (1 âˆ’ğœ)qkejğœ”xi + ğœqkejğœ”(xiâˆ’hx),
ğœ= a ht
hx
(8.47)
qk+1 = (1 âˆ’ğœ+ ğœeâˆ’jğœ”hx)qk = G(ğœ)qk
(8.48)
The absolute value of the complex factor G(ğœ) must be â‰¤1 for stability:
|G(ğœ)|2 = (1 âˆ’ğœ+ ğœcos(ğœ”hx))2 + (ğœsin(ğœ”hx))2 = 1 âˆ’4ğœ(1 âˆ’ğœ)sin2(ğœ”hx) (8.49)
We see that
|G(ğœ)| â‰¤1,
if
0 < ğœâ‰¤1

BIBLIOGRAPHY
187
i.e.,
0 < a ht
hx
â‰¤1
Hence, we get a smaller stability interval by this analysis called von Neumann anal-
ysis than with the eigenvalues analysis! For hyperbolic problems, the von Neumann
analysis is the adequate one to use for stability investigations.
For the FTCS method in Section 8.2.3
ui,k+1 = ui,k âˆ’ğœ
2 (ui+1,k âˆ’uiâˆ’1,k)
the von Neumann analysis gives the formulas:
qk+1 = G(ğœ)qk
where
|G(ğœ)|2 = 1 + ğœ2sin2(ğœ”hx) > 1
Hence, the FCTS method is always unstable.
BIBLIOGRAPHY
1. A. Iserles, â€œA First Course in the Numerical Analysis of Differential Equationsâ€, Cambridge
University Press, 1996
2. R. LeVeque, â€œNumerical Methods for Conservation Lawsâ€, 1992
3. R.M.M. Mattheij, S.W. Rienstra, J.H.M. ten Thije Boonkkamp, â€œPartial Differential
Equations Modeling, Analysis, Computationâ€, Chapter 13, SIAM, 2005
4. G.D. Smith, â€œNumerical Solution of Partial Differential Equationsâ€, Chapter 4, 3rd ed,
Oxford University Press, 1986
5. J.C. Strikwerda, â€œFinite Difference Schemes and Partial Differential Equationsâ€, Chapman
and Hall, 1989
6. R. Vichnevetsky, J.B. Bowles, â€œFourier Analysis of Numerical Approximations of Hyper-
bolic Equationsâ€, SIAM, 1982


9
MATHEMATICAL MODELING WITH
DIFFERENTIAL EQUATIONS
When a differential equation is presented in a textbook, you may sometimes ask your-
self how it is derived. Are there any basic principles to follow when a differential
equation is set up? Can you perform the modeling of an engineering problem your-
self? There is no general answer to that question. Modeling is much of an art and
the result obtained depends on what type of problem you want to model and which
simplifying assumptions you make. In an area such as chemical engineering, it is
customary to set up differential equation models from conservation principles, i.e.,
you derive the model yourself. In electromagnetic field theory, on the other hand,
it is common to start from Maxwellâ€™s equations in general form, impose simplifying
assumptions for your special problem to obtain a simpler differential equation model.
In control theory, it is customary to describe a model with a block diagram, which
can be translated into an ordinary differential equation (ODE) system.
To give an overview discussion of the art of modeling, it may be helpful to divide
differential equations occurring in applications into the following classes:
1. differential equations considered as nature laws
2. constitutive differential equations
3. conservative differential equations
With these mathematical tools, it is possible to set up models for many scientific
and engineeringproblems.In this chapter,we give an overviewof derivingdifferential
equation models in one space dimension, 1D. Some generalizations to 2D problems
and simplifications of general differential equations to less complex problems are also
shown.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

190
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
As before, in mathematical modeling, we stress upon using the units of the
variables, e.g., density (kg/m3), flow (kg/s), flux [kg/(m2 â‹…s)], and parameters,
e.g., g (m/s2).
9.1
NATURE LAWS
A nature law expressed as a differential equation is a mathematical relation that can-
not be derived from physical facts. Its validity depends on observations and the fact
that no experiment has been designed that contradicts the law. Examples of such laws
are Newtonâ€™s law for the motion of a particle, Maxwellâ€™s laws for the electromagnetic
field, and SchrÃ¶dingerâ€™s equation in quantum mechanics.
To show how a mathematical model can be built on a nature law, we present here
Newtonâ€™s law for particle dynamics
md2r
dt2 = F
(9.1)
where F (N) is the force acting on the particle, m (kg) its mass, r (m) the position,
t (s) the time, and âƒ—a = d2râˆ•dt2, the acceleration (m/s2) of the particle.
Example 9.1.
(Particle dynamics in 1D). A particle with the mass m (kg) is part of
a system consisting of a spring, a viscous damper, and the particle (see Figure 9.1).
The spring has the stiffness constant k (N/m) and the damper has the damping coef-
ficient c (N â‹…s/m).
The system is at rest, when the particle is in the position y = y0 relative to a y-axis
pointing vertically downwards. The particle is then forced to the position y1 > y0 and
left to move freely along the y-axis. If the position of the particle at time t is y(t), the
differential equation for the particle motion can be set up with the help of Newtonâ€™s
second law of motion
mÌˆy = F1 + F2 + F
k
c
m
y0
y(t)
y
F
Figure 9.1
Spring-damper system

NATURE LAWS
191
In the right hand side, we have the sum of
â€¢ the viscous force F1 = âˆ’cy
â€¢ the spring force F2 = âˆ’ky and
â€¢ the external force F
giving the following ODE model, known as the vibration equation:
md2y
dt2 + cdy
dt + ky = F
(9.2)
To get a unique solution, we need to specify the position and the velocity of the
particle at time t = 0, e.g., y(0) = y1, Ì‡y(0) = 0.
The external force can be of different types, e.g.,
a constant force, e.g., gravity: F = mg
an oscillating force: F = F0 sin (ğœ”t)
Example 9.2.
(The vibrating string, a distributed model). An elastic string (e.g.,
a rubber band) with cross-section area A (m2) and density ğœŒ(kg/m3) is tensely
fastened between two fixed points at the distance L (m) from each other. The
tension of the string is F (N). At time t = 0, the string is moved vertically from the
equilibrium position along the x-axis to a form given by the initial value function
u (x,0) = f(x), 0 â‰¤x â‰¤L and then released to move freely. Let the vertical distance
from the x-axis at a point P on the string be u(x, t). Let Q be another point where the
vertical distance to the x-axis is u(x + Î”x, t) (Figure 9.2).
In this simplified model, the points P and Q can only move vertically. Hence we
have no motion in the x-direction and Newtonâ€™s second law for horizontal and vertical
motion can be written
âˆ’F1 cos ğ›¼+ F2 cos ğ›½= 0
â‡’
F1 cos ğ›¼= F2 cos ğ›½= F
ğœŒAÎ”xd2u
dt2 = âˆ’F1 sin ğ›¼+ F2 sin ğ›½
0
x
x + Î”x
L
x
F2
F1
P
Q
u (x)
Figure 9.2
The vibrating string

192
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
Elimination of F1 and F2 gives
ğœŒAÎ”xd2u
dt2 = F(tan ğ›½âˆ’tan ğ›¼)
As tan ğ›¼= ğœ•u
ğœ•x (x, t) and tan ğ›½= ğœ•u
ğœ•x (x + Î”x, t), we get
ğœŒA
F
ğœ•2u
ğœ•t2 =
ğœ•u
ğœ•x(x + Î”x, t) âˆ’ğœ•u
ğœ•x(x, t)
Î”x
Let Î”x â†’0 and we obtain the partial differential equation, the wave equation
ğœ•2u
ğœ•t2 = c2 ğœ•2u
ğœ•x2
(9.3)
where c2 = F/ğœŒA. The parameter c (m/s) is the velocity of the wave.
To get a unique solution, we need boundaryconditions (BCs) and initial conditions
(ICs). The endpoints of the string are fixed, hence the BCs are
u(0, t) = 0,
u(L, t) = 0,
t â‰¥0
The ICs originate from the state of the string at t = 0, i.e., the string has a given form
and initial velocity zero, hence
u(x, 0) = f(x)
ğœ•u
ğœ•t (x, 0) = 0,
0 â‰¤x â‰¤L
9.2
CONSTITUTIVE EQUATIONS
A constitutive equation is a mathematical model of the physical properties of a gas,
fluid, or solid and can be either a differential equation or an algebraic equation. A
constitutive equation is usually the mathematical result of very many observations
of a phenomenon or measurements of an experiment and is therefore of empirical
nature.
We give here some examples of constitutive equations formulated in 1D.
9.2.1
Equations in Heat Transfer Problems
Fourierâ€™s law of heat diffusion
q = âˆ’ğœ…dT
dx
(9.4)
This is a relation between heat flux q [J/(m2 â‹…s)] and temperaturegradient. The param-
eter ğœ…[J/(K â‹…m â‹…s)] is the thermal conductivityof the material. Observe the minus sign
(the heat flow travels from higher to lower temperatures)!

CONSTITUTIVE EQUATIONS
193
This can also be written as a law for diffusion of thermal energy E = ğœŒCpT
q = âˆ’ğ›¼dE
dx
(9.5)
where q is the heat flux [J/(m2 â‹…s)], ğ›¼thermal diffusivity (m2/s), ğœŒthe density (kg/m3),
and Cp the heat capacity at constant pressure [J/(K â‹…kg)].
Newtonâ€™s law of cooling
Q = âˆ’kA(T0 âˆ’T)
(9.6)
This is a relation between the heat flow Q (J/s) from a region with temperature T to
an environment with temperature T0. The regions are separated by a wall of area A
(m2) with convection heat transfer coefficient k [J/(m2 â‹…s â‹…K)].
Stefanâ€“Boltzmannâ€™s law for temperature radiation loss
Q = âˆ’Aeğœ(T4
0 âˆ’T4)
(9.7)
Radiation comes into account for high temperatures. Q (J/s) is the heat flow, A (m2)
the area of radiation, e a material constant, and ğœ= 5.67â‹…10âˆ’8 [J/(m2 â‹…s â‹…K4)] the
Boltzmannâ€™s constant
9.2.2
Equations in Mass Diffusion Problems
Fickâ€™s law of mass diffusion
f = âˆ’DdğœŒ
dx
(9.8)
This is a relation between mass flux f [kg/(m2 â‹…s)] and the density gradient. The
parameter D is the mass diffusivity (m2/s). There is also a derivative-free version
of Fickâ€™s law (cf Newtonâ€™s cooling law)
F = âˆ’ğœ‡A
l (ğœŒ0 âˆ’ğœŒ)
(9.9)
This is a relation between the mass flow F (kg/s) from a region with density ğœŒto
an environment with density ğœŒ0. The regions are separated by a wall through which
particles can diffuse. The diffusivity is ğœ‡(m2/s), the area is A (m2), and the thickness
is l (m).
9.2.3
Equations in Mechanical Moment Diffusion Problems
Newtonâ€™s law of viscosity
ğœxy = âˆ’ğœ‡dvx
dy
(9.10)
This is a relation between the shear stress ğœxy (N/m2) in a plane parallel to the direction
of the flow with velocity vx (m/s) along the x-axis and orthogonal to the y-axis and the

194
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
velocity gradient along the y-axis. The parameter ğœ‡(N â‹…s/m2) is called the dynamic
viscosity.
If we write this law in the form
ğœxy = âˆ’ğœˆd(ğœŒvx)
dy
(9.11)
the parameter ğœˆ(m2/s) is called the kinematic viscosity (can also be regarded as the
diffusion coefficient of the mechanical moment).
9.2.4
Equations in Elastic Solid Mechanics Problems
Hookeâ€™s law for an elastic bar
ğœ= Eğœ–,
ğœ–= du
dx
(9.12)
This is a relation between stress ğœ(N/m2) and strain ğœ–[ ] (no dimension), where the
strain is the displacement u (m) per unit length of the bar. The parameter E is the
elasticity module (Youngâ€™s module) (N/m2).
9.2.5
Equations in Chemical Reaction Engineering Problems
The mass action law in chemical kinetics
r = k
m
âˆ
i=1
cğ›¼i
i
(9.13)
This algebraic relation gives the rate r [mol/(m3 â‹…s)] of the reaction
ğ›¼1 A1 + â€¦ + ğ›¼m Am â†’ğ›½1 B1 + â€¦ + ğ›½n Bn
The reactants Ai, i = 1, â€¦ , m and the products Bi, i = 1, â€¦ , n are measured in con-
centrations ci (mol/m3) and the unit of the rate constant k depends on ğ›¼1, â€¦ , ğ›¼m. The
rate constant k is temperature dependent according to Arrheniusâ€™ law
k = Aeâˆ’E
RT
(9.14)
where A [ ] is the preexponential factor, E (J/mol) the activation energy, T (K) the
temperature, and R = 8.314 J/(K â‹…mol) the gas constant.
The general gas law
pV = nRT
(9.15)
This is a relation between the pressure p (N/m2), the volume V (m3), the number of
moles n (mol), the temperature T (K), and the gas constant R.

CONSERVATIVE EQUATIONS
195
9.2.6
Equations in Electrical Engineering Problems
Ohmâ€™s law in electromagnetics
j = ğœE
(9.16)
where j (A/m2) is the electrical current density, ğœ[A/(V â‹…m)] the conductivity, and E
(V/m) the electric field strength. Lorentzâ€™ law
F = q(E + v Ã— B)
(9.17)
where F is the force (N) exerted on a charged particle with electric charge q (C) in
an electric field (V/m) and a magnetic field B (V â‹…s/m2). v (m/s) the velocity of the
particle.
9.3
CONSERVATIVE EQUATIONS
Conservation equations are based on the principle that physical quantities, such as
mass, moment, and energy, are conserved in a system. Assume we study the changes
of some quantity in a control volume that is fixed in space. From a purely logical
point of view, the following balance principle must hold for the quantity during a
given time interval:
Î”Acc = In âˆ’Out + Prod âˆ’Cons
(9.18)
where
â€¢ Î”Acc = the change of amount of the accumulated quantity
â€¢ In = the amount of the quantity that has flowed in
â€¢ Out = the amount of the quantity that has flowed out
â€¢ Prod = the amount of the quantity produced and
â€¢ Cons = the amount of the quantity consumed
In scientific and engineering contexts, quantities usually change smoothly with
time. Let M(t) be a differentiable function denoting the amount of a quantity at
time t. We then define the flow Q(t) as
Q(t) = dM
dt
(9.19)
The flow is measured in amount per unit time.
Define in, out, prod, and cons as the flows of In, Out, Prod, and Cons. Using (9.18)
during the time interval [t, t + Î”t] gives the following relation:
Î”Acc = âˆ«
t+Î”t
t
(in(t) âˆ’out(t) + prod(t) âˆ’cons(t)) dt
(9.20)

196
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
Divide by Î”t, let Î”t â†’0 and we obtain
dAcc
dt
= in âˆ’out + prod âˆ’cons
(9.21)
This relation is often referred to as the continuity equation. Here it is expressed as an
ODE, but if the amount of the quantity depends on both time and space, the continuity
equation will be a partial differential equation (PDE).
A conservation principle leading to an ODE with time as independent variable is
called a lumped model. Such a model does not take into account any space variations
of the quantities. A conservation law leading to a PDE in time and space is called a
distributed model.
We show in a number of examples how this principle can be used to derive differ-
ential equations for the conservation of a given quantity.
9.3.1
Some Examples of Lumped Models
Example 9.3.
(Model for the water contents in a tank). Assume we have a tank
which is filled with water from a pipe delivering the flow Q1 (m3/s) (see Figure 9.3).
It is drained at the bottom through another pipe with the flow Q2 (m3/s).
Let V (m3) be the amount of water accumulated in the tank. Application of the
continuity principle (9.18) during the time interval [t, t + Î”t] gives the following
equality:
Î”V = Q1 â‹…Î”t âˆ’Q2 â‹…Î”t
corresponding to
Î”Acc = In âˆ’Out
Divide this relation by Î”t, let Î”t â†’0 and we obtain the following ODE:
dV
dt = Q1 âˆ’Q2
corresponding to
dAcc
dt
= in âˆ’out
Q1
Q2
V1
Figure 9.3
Tank filled with water

CONSERVATIVE EQUATIONS
197
Qin
c
V
Figure 9.4
Continuously stirred tank reactor
If the volume is known at t = 0, we also have an IC. Denote the initial volume by
V0 (m3). We now have the initial value problem (IVP)
dV
dt = Q1 âˆ’Q2,
V(0) = V0
(9.22)
Example 9.4.
(A continuously stirred tank reactor). A continuously stirred tank
reactor is a chemical reactor where chemical species are stirred together from inflow
of reactants to a homogeneous mix (see Figure 9.4). In this mix, the reactions take
place and products are formed. Assume the inflow to the reactor is Qin (m3/s) and that
the concentration of A in the inflow is c0 (mol/m3). In the reactor, A reacts according
to A â†’B and is thereby consumed with the rate kc, where k (sâˆ’1) is the rate constant
of the reaction and c (mol/m3) is the concentration of A in the reactor. Assume there
is no outflow from the reactor. Then the volume will be increasing. The concentration
of A in the reactor at time t = 0 is c(0) = 0 and the volume at t = 0 is V(0) = V0. Using
the conservation law for the number of moles cV of A in the reactor and the volume
V of the mix, we obtain
d(cV)
dt
= Qin c0 âˆ’kcV,
c(0) = 0
(9.23a)
dV
dt = Qin,
V(0) = V0
(9.23b)
9.3.2
Some Examples of Distributed Models
Example 9.5.
(The continuity equation in 1D). Assume we have a pipe with
cross-section area A (m2) through which some fluid flows (see Figure 9.5). The
density of the fluid is ğœŒ(x, t) (kg/m3) and the flux is q(x, t) [kg/(sâ‹…m2)]. We use the
relation (9.21) to derive the continuity equation. Consider the small volume Î”V
between x and x + Î”x. At the left end, the flux is q(x, t) and the density is ğœŒ(x, t). At
the right end, the flux is q (x + Î”x, t) and the density is ğœŒ(x + Î”x, t).

198
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
x
x
A
A
x + Î”x
Ï (x + Î”x, t)
q (x + Î”x, t)
Ï (x, t)
q (x, t)
Figure 9.5
Illustration of the continuity equation
The accumulated amount of mass in Î”V at time t is âˆ«x+Î”x
x
ğœŒ(x, t)A dx. The conti-
nuity equation (9.21) gives
d
dt âˆ«
x+Î”x
x
ğœŒ(x, t) A dx = q(x, t)A âˆ’q(x + Î”x, t)A
(9.24)
Using the mean value theorem of integral calculus gives
Î”xdğœŒ(x + ğœƒÎ”x, t)
dt
= âˆ’(q(x + Î”x, t) âˆ’q(x, t)),
0 < ğœƒ< 1
Dividing by Î”x, and letting Î”x â†’0 gives
ğœ•ğœŒ
ğœ•t + ğœ•q
ğœ•x = 0
(9.25)
which is the PDE of mass conservation called the continuity equation in 1D.
However, (9.25)is mathematically insufficient. There are two dependentvariables,
ğœŒand q, but only one equation. Hence, we need one more equation, e.g., a constitutive
equation giving a second relation between ğœŒand q. The following alternatives are
possible:
1. mass flow according to a general nonlinear flux function q = f(ğœŒ)
2. mass flow with constant velocity v (m/s) through the pipe: q = vğœŒ
3. mass flow governed by mass diffusion: q = âˆ’D dğœŒ
dx
4. a combination of (2) and (3): q = vğœŒâˆ’D dğœŒ
dx
Inserting (1) into (9.25) gives
ğœ•ğœŒ
ğœ•t + ğœ•f(ğœŒ)
ğœ•x
= 0
(9.26)
This equation is often called the scalar conservation law and is a nonlinear hyperbolic
PDE (see Chapter 8).
Inserting (2) into (9.25) gives
ğœ•ğœŒ
ğœ•t + vğœ•ğœŒ
ğœ•x = 0
(9.27)

CONSERVATIVE EQUATIONS
199
Hence, we obtain the advection equation (1.4) presented in Chapter 1. This is a linear
hyperbolic PDE.
Inserting (3) into (9.25) gives
ğœ•ğœŒ
ğœ•t = Dğœ•2ğœŒ
ğœ•x2
(9.28)
This equation we recognize as the diffusion equation, which is a parabolic PDE (see
Chapter 6).
Inserting (4) into (9.25) gives
ğœ•ğœŒ
ğœ•t + vğœ•ğœŒ
ğœ•x = Dğœ•2ğœŒ
ğœ•x2
(9.29)
This equation we recognize as the convection-diffusion equation, classified as a
hyperbolicâ€“parabolic PDE.
If there is also production of the substance in the pipe (through, e.g., chemical
reaction) with the rate r(c) [mol/(m3 â‹…s)] depending on the concentration c, we obtain
a PDE known as the convectionâ€“diffusionâ€“reaction equation
ğœ•c
ğœ•t + vğœ•c
ğœ•x = Dğœ•2c
ğœ•x2 + r(c)
(9.30)
Example 9.6.
(Energy conservation in a cooled cylindrical pipe).
Assume a hot fluid is flowing through a cylindrical pipe with radius R (m) in the
z-direction according to Figure 9.6. The temperature T(z, t) of the fluid at time t and
at the space point z changes as the pipe is cooled on the outside. The temperature
of the cooling medium is constant and has the value Tout. The thermal energy flux
through the pipe is q(z, t) [J/(m2 â‹…s)]. The density of the fluid is ğœŒ(kg/m3), the heat
capacity is C [J/(K â‹…kg)], and the convection heat transfer coefficient of the wall is
k [J/(K â‹…m2 â‹…s)]. The four parameters ğœŒ, C, k, and Tout are constants, while the state
variables temperature T(z, t) and energy flux q(z, t) of the fluid vary with time t and
space z. Following the balance principle (9.24), we get
d
dt âˆ«
z+Î”z
z
T(z, t)ğœŒCğœ‹R2 dz = q(z, t)ğœ‹R2 âˆ’q(z + Î”z, t)ğœ‹R2
âˆ’k(T âˆ’Tout)2ğœ‹RÎ”z(1)
(9.31)
Taking limit values with Î”z â†’0, we obtain the PDE
ğœŒCğœ•T
ğœ•t = âˆ’ğœ•q
ğœ•z âˆ’2k
R (T âˆ’Tout)
(9.32)
However, we have only one equation but two unknowns T(z, t) and q (z, t). The miss-
ing equation is obtained from a constitutive equation that relates the flux q to the

200
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
z
A
A
T (z, t) 
Figure 9.6
Hot fluid in a cylindrical pipe
temperature T. If we assume that the heat transport takes place through convection
and Diffusion, we have
q = vğœŒCT âˆ’ğœ…dT
dz
Inserting this expression into the PDE, we finally obtain
ğœŒCğœ•T
ğœ•t + vğœŒCğœ•T
ğœ•z = ğœ…ğœ•2T
ğœ•z2 âˆ’2k
R (T âˆ’Tout)
(9.33)
which is the PDE presented in Example 6.1, where an IC and two BCs are added to
this parabolic PDE.
If the problem is time independent, we obtain the BVP in Example 4.1.
If we reducethe modelfurtherby assuming that the diffusiontransportis negligible
compared to the convective transport, we obtain the first-order ODE
vğœŒCdT
dz = âˆ’2k
R (T âˆ’Tout)
(9.34)
for which we need only one condition, an IC.
If we assume that the heat leaking out of the wall is negligible (k = 0), the problem
is reduced to the simple ODE
vğœŒCdT
dz = 0
(9.35)
which with the IC T(0) = T0 gives the solution T = T0. Hence, by increasing the
number of reduction assumptions, the model soon becomes uninteresting!
On the other hand, the model can be made more complex by taking into account
transport in more than one space dimension. If we assume that heat is transported by
diffusion also in the r-direction, we have to add a corresponding term to (9.33) and
move the heat loss through the wall to a BC
ğœŒCğœ•T
ğœ•t + vğœŒCğœ•T
ğœ•z = ğœ…ğœ•2T
ğœ•z2 + ğœ…1
r
ğœ•
ğœ•r
(
rğœ•T
ğœ•r
)
(9.36)
This time-dependent 2D parabolic PDE is also presented in Example 6.2. Now the
flow in a pipe problem has reached a level detail, which may be unnecessarily high for

SCALING OF DIFFERENTIAL EQUATIONS TO DIMENSIONLESS FORM
201
being an engineering problem.Hence, modeling is also about how to choose sufficient
complexity in the model.
Exercise 9.3.1. Derive the time-dependent counterflow heat exchanger model in
Example 8.2
9.4
SCALING OF DIFFERENTIAL EQUATIONS TO DIMENSIONLESS
FORM
When the differentialequation of a scientific or engineeringprocessis formed through
modeling, it is natural to think of all variables introduced in the model as phys-
ical or chemical quantities. Hence, the variables have some dimension, i.e., they
are expressed in units such as kg, J/(m2 â‹…s), and mol/(m3 â‹…s). The parameters in the
model, coming, e.g., from the constitutive equations, have dimensions as well.
Observe that the word dimension has many meanings: (i) the dimension of a vector
is the number of elements in the vector, (ii) the dimension of space can be modeled
in 1D, 2D, and 3D, (iii) the dimension of a physical variable or parameter is a com-
bination of elementary units, s.a. m, s, kg, etc.
However, when the model is to be treated mathematically and/or numerically, it is
often advantageous to scale the variables of the model to dimensionless form. This
means that for the variable x with dimension (m), we introduce a dimensionless vari-
able ğœ‰= x/L, where L (m) is a characteristic length of the problem. Likewise, the
time variable t (s) is scaled to dimensionless time through ğœ= t/t0, where t0 is a
characteristic time of the problem.
Through the scaling, the derivatives of the original model will be transformed to
derivatives of the dimensionless variables. We show here how the first and second
derivatives are changed.
dx
dt = d(Lğœ‰)
d(t0ğœ) = L
t0
dğœ‰
dğœ
(9.37)
d2x
dt2 = d
dt
(dx
dt
)
=
d
d(t0ğœ)
(
L
t0
dğœ‰
dğœ
)
= L
t2
0
d2ğœ‰
dğœ2
(9.38)
We see that a consequence of scaling is that certain parameter combinations will
appear in the scaled model. Usually these combinations can be arranged so that
dimensionless combinations are formed.
Scaling of the original differential equation model can have several advantages:
â€¢ If the scaling is done correctly, i.e., with scaling factors characteristic of the
problem, the new dimensionless variables for, e.g., length and time will be of
order 1.
â€¢ The number of parameters in the scaled model will be smaller than in the orig-
inal model.

202
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
â€¢ When comparing the size of the individual terms of the differential equation
model, it is easier to judge which terms are important and which can be
neglected in the scaled model. This may help to reduce the original model to a
model that is mathematically simpler.
Example 9.7.
The continuously stirred tank reactor model in Example 9.4. The
following differential equation model is given:
d(cV)
dt
= qin c0 âˆ’kcV,
c(0) = 0
(9.39a)
dV
dt = qin,
V(0) = V0
(9.39b)
The units of the variables and parameters are
c,c0
V,V0
t
qin
k
(mol/m3)
(m3)
(s)
(m3/s)
(sâˆ’1)
Introduce the scaled dimensionless variables x, y, and ğœ
x = câˆ•c0,
y = Vâˆ•V0,
ğœ= tâˆ•T
where T is a characteristic time of the problem, yet to be determined. Express the
original problem (9.23) in the scaled variables
c0 V0
T
d(xy)
dğœ
= qin c0 âˆ’kc0 V0xy,
x(0) = 0
V0
T
dy
dt = qin,
y(0) = 1
Multiply the first ODE by T/c0V0 and the second ODE by T/V0
d(xy)
dğœ
= qinT
V0
âˆ’kTxy,
x(0) = 0
dy
dğœ= qinT
V0
,
V0y(0) = V0
We see that there are two possibilities to make time dimensionless: either T = V0/qin
or T = 1/k. The first choice leads to the ODE system
d(xy)
dğœ
= 1 âˆ’a1xy,
x(0) = 0
dy
dğœ= 1,
y(0) = 1
where a1 is the dimensionless parameter a1 = V0k/qin.

SCALING OF DIFFERENTIAL EQUATIONS TO DIMENSIONLESS FORM
203
The other possibility, T = 1/k, leads to the ODE system
d(xy)
dğœ
= a2 âˆ’xy,
x(0) = 0
dy
dğœ= a2,
y(0) = 1
where a2 = V0k/qin. We see that in both Cases, the original number of parameters is
reduced from four (c0, V0, qin, k) to only one (a1 or a2).
Exercise 9.4.1. A 1D version of Navierâ€“Stokes equations is
ğœŒ
(ğœ•v
ğœ•t + vğœ•v
ğœ•x
)
= âˆ’ğœ•p
ğœ•x + ğœ‡ğœ•2v
ğœ•x2 + ğœŒg
(9.40)
with appropriate ICs and BCs. In (9.40), ğœŒis the density, v the velocity, p the pres-
sure, ğœ‡the dynamic viscosity, and g the gravitational constant. The variables and the
parameters have the following units:
ğœŒ
v
t
x
p
ğœ‡
g
(kg/m3)
(m/s)
(s)
(m)
(N/m2)
(N â‹…s/m2)
(m/s2)
Introduce dimensionless variables: v* = v/V, x* = x/L, p* = (p âˆ’p0)/ğœŒV2, t* = tV/L,
where V is a characteristic velocity, L a characteristic length, and p0 is a reference
pressure. All the parameters are assumed to be constant. The original differential
equation will be expressed in the dimensionless variables and the dimensionless
parameters Reynoldâ€™s number Re = LVğœŒâˆ•ğœ‡and Froudeâ€™s number Fr = V2âˆ•gL
Exercise 9.4.2. A model for stationary 1D heat transport presented in Example 4.1
is the following differential equation:
ğœŒCpvdT
dz = ğœ…d2T
dz2 âˆ’2k
R (T âˆ’Tout)
T(0) = T0, T(L) = Tout
(9.41)
The units of the variables and parameters are
T, T0, Tout
z, L
v
ğœ…
ğœŒ
Cp
(K)
(m)
(m/s)
[J/(K â‹…m â‹…s)]
(kg/m3)
[J/(K â‹…kg)]
Introduce the scaling
u = Tâˆ•Tout,
ğœ‰= zâˆ•L
and bring the differential equation on dimensionless form. Which dimensionless
parameter combinations will appear in the scaled model?

204
MATHEMATICAL MODELING WITH DIFFERENTIAL EQUATIONS
Exercise 9.4.3. Given the vibration equation in mechanics
md2u
dt2 + cdu
dt + ku = F sin(ğœ”t)
(9.42)
where all parameters m, c, k, F, and ğœ”are positive quantities. Which are the dimen-
sions of the variables and the parameters? Let ğœ”0 =
âˆš
kâˆ•m, c0 = 2
âˆš
km ğ›¼= c/c0,
and ğ›½= ğœ”/ğœ”0. Introduce dimensionless time ğœ= ğœ”0t and dimensionless deviation
y = u/u0, where u0 is a suitable combination of some parameters in (9.42).
Find this scaling factor u0 and show that in the new variables y and ğœ, the differ-
ential equation (9.42) can be written (ğ›¼is called the damping factor)
d2y
dğœ2 + 2ğ›¼dy
dğœ+ y = sin(ğ›½ğœ)
Exercise 9.4.4. The following chemical reactions occur in enzyme catalysis:
S + E â†â†’C âˆ’â†’P + E
The kinetics of the system is modeled by the ODE system
Ì‡S = âˆ’k1SE + kâˆ’1C,
S(0) = S0
Ì‡E = âˆ’k1SE + kâˆ’1C + k2C,
E(0) = E0
Ì‡C = k1SE âˆ’kâˆ’1C âˆ’k2C,
C(0) = 0
Ì‡P = k2C,
P(0) = 0
where S, E, C, and P represent the concentrations (mol/m3) of the four species taking
part in the reactions. The parameters k1 [m3/(molâ‹…s)] kâˆ’1 (1/s) and k2 (1/s) are the rate
constants of the reactions. Note first that there are linear relationships between the
right hand side expressions, so we need differential equations for only two variables,
say S and C, the other two variables depend linearly on these.
1. Find the ODE system for S and C (eliminate E and P).
2. Transform by scaling of S, C, and t the system in (1) into dimensionless form.
Use the scaled variables s = S/S0 and c = C/E0. The time t should be scaled
to dimensionless time ğœas ğœ= t/T, where T is chosen so that the scaled ODE
system contains as few parameters as possible.
BIBLIOGRAPHY
1. E. Baltram, Mathematics for Dynamic Modeling, Academic Press, 1987
2. N. Fawkes, J. Mahony, An Introduction to Mathematical Modeling, Wiley, 1994
3. J.D. Logan, Applied Mathematics, Wiley, 1997

10
APPLIED PROJECTS ON
DIFFERENTIAL EQUATIONS
The following projects have been used for a long time in a first advanced course on
Numerical Solution of Differential Equations at KTH, Stockholm. Most of the
projects have been developed and modified during several years by my colleague
Gerd Eriksson, and I have her permission to present them in updated form in this
book. Projects 4 and 5 are taken from one of the early manuals of COMSOL
MULTIPHYSICSÂ®, see also Appendix B.2. They have kindly given me permission
to publish them in updated form.
Project 1. Signal propagation in a long electrical conductor
Given a 10 km long conductor with resistance R, inductance L, and capacitance
C. From x = 0, signals of amplitude 1V are sent frequently during time intervals of
different lengths. Denote this time-dependent voltage by u0(t). The voltage in the
conductor is a function u(x, t) of the position x on the conductor and time t and is
modeled by the following hyperbolic partial differential equation (PDE)
ğœ•2u
ğœ•t2 + R
L
ğœ•u
ğœ•t = 1
LC
ğœ•2u
ğœ•x2 ,
0 â‰¤x â‰¤X,
t > 0
which is the wave equation with damping. At t = 0, the initial conditions (ICs) are
u(x, 0) = 0,
ğœ•u
ğœ•t (x, 0) = 0,
0 < x â‰¤X
where X = 104.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

206
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
The boundary condition (BC) at x = 0 is the given signal u0(t), i.e.,
u(0, t) = u0(t)
At x = X, the conductor is open, i.e., the signal is not reflected but disappears out.
The BC fulfilling this condition is the advection equation, i.e.,
ğœ•u
ğœ•t (X, t) +
1
âˆš
LC
ğœ•u
ğœ•x (X, t) = 0
Discretize the conductor into 100 subintervals and use central difference
approximations for the space and time derivatives in the damped wave equation.
As for the approximation of the BC at x = X, the upwind method Forward-Time-
Backward-Space (FTBS) is appropriate.
For the conductor, the following parameter values are given: R = 0.004 ohm,
L = 10âˆ’6 H, and C = 0.25 â‹…10âˆ’8 F. Simulate the signal propagation during a
sufficiently long time, e.g., during 3 ms. First use the maximum allowed time step
fulfilling the stability condition, then use a time step being 80% of the maximum
time step. What is your comments on the result of the two time steps that have been
used? Is the smoothing of the solution the effect of damping or of the method used?
Start your simulations by testing u0(t) with the MATLAB function given below. It
corresponds to three short signals repeatedly sent with a period of 0.0004s.
function usignal=uzero(t)
tau=rem(t,0.0004);
T0=0; T1=0.00005; T2= 0.00010; T3= 0.00013; T4= 0.00018; T5= 0.00025;
u0=1;
m=length(t);u1=zeros(m,1);
ind=find(t0<=tau & tau<=T1 | T2<=tau & tau <=T3 | T4<=tau & tau<=T5);
u1(ind)=u0*ones(size(ind));
usignal=u1;
You can of course try your own signal sequences.
Project 2. Flow in a cylindrical pipe
In a long straight pipe with circular cross section with radius R, a fluid is streaming
and we want to find out how the flow velocity varies in the pipe. Let the velocity
vector be (u, v)T where u is the velocity in the length direction of the pipe and v the
velocity in the radial direction. The flow is assumed to be circular symmetric, i.e., in
cylindrical coordinates u(r, z) and v(r, z) depend only on r and z, not ğœ‘.
At the inlet z = 0, the velocity of the fluid is u0 = 0.1 mâˆ•s in the z direction, i.e.,
u(r, 0) = u0, v(r, 0) = 0, 0 â‰¤r â‰¤R. The radius R = 0.05 m. The fluid has density
ğœŒ= 1000 kgâˆ•m3 and the viscosity is ğœˆ= 10âˆ’5 m2âˆ•s. In fluid problems, the Reynolds
number Re = u0Râˆ•ğœˆis an important constant. When Re >> 1, which is the case here,
it is possible to simplify the complicated Navierâ€“Stokes PDEs that are used to model
u(r, z) and v(r, z).

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
207
In this flow problem, Navierâ€“Stokes equations are approximated by
uğœ•u
ğœ•z = ğœˆ
(
ğœ•2u
ğœ•r2 + 1
r
ğœ•u
ğœ•r
)
âˆ’vğœ•u
ğœ•r âˆ’1
ğœŒ
dp
dz
(10.1)
ğœ•u
ğœ•z + 1
r
ğœ•(vr)
ğœ•r
= 0
(10.2)
The pressure p is only z dependent. At z = 0, p = p0, where p0 = 104 Pa. At r = 0,
we have the following BC
ğœ•u
ğœ•r (0, z) = 0,
v(0, z) = 0
At the wall of the pipe, the two velocities are zero, i.e.,
u(R, z) = 0,
v(R, z) = 0
Far away in the pipe, several meters from the inlet, the velocity will have a sta-
tionary distribution with parabolic shape
u = 2u0
(
1 âˆ’
( r
R
)2)
,
v = 0
(10.3)
The task is to compute how the velocities vary with r and z. It is also included
to compute how far away from the inlet the stationary distribution (10.3) is attained
with an acceptable tolerance.
The differential equations (10.1) and (10.2) must be treated specially at r = 0
where both are singular. Show that with lâ€™Hospitalâ€™s rule they turn into
uğœ•u
ğœ•z = 2ğœˆğœ•2u
ğœ•r2 âˆ’1
ğœŒ
dp
dz ,
ğœ•u
ğœ•z + 2ğœ•v
ğœ•r = 0,
at
r = 0
For numerical treatment, the MoL with n = 50 subintervals in the r direction
is used. Then there will be 2n unknown variables being functions of z. These
are u1(z), u2(z),â€¦, un(z), ğœ(z), v2(z), v3(z),â€¦, vn(z). u1(z) and v1(z) are velocity
functions at r = 0. We know that v1(z) = 0, hence this component is not among the
unknowns. The variable ğœis defined as
ğœ(z) = 1
ğœŒ
dp
dz
With difference approximations of all derivatives in the r direction, we will have
n ODEs (ordinary differential equations) each of (10.1) and (10.2), hence 2n in total.
To solve, these Eulerâ€™s implicit method shall be used with stepsize hz. The equations
(10.1) and (10.2) will then be approximated by
ui
ui âˆ’uold
i
hz
âˆ’Fi(uiâˆ’1, ui, ui+1, ğœ, vi) = 0,
ui âˆ’uold
i
hz
+ Gi(viâˆ’1, vi, vi+1) = 0

208
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
where ui and vi denote the unknownvelocity componentsat z + hz and uold
i
denotes the
already computed velocity component at the previous value z. Find the expressions
for Fi and Gi.
At the end of the day, there will be a nonlinear system of 2n algebraic equations
to be solved at each step in the z direction. This is done with Newtonâ€™s method. If the
unknowns are written in the order u1, u2,â€¦, un, ğœ, v2, v3,â€¦, vn, the jacobian J will
have a block structure consisting of four n Ã— n matrices
J =
(
J1
J2
J3
J4
)
where J1 is tridiagonal, J2 has nonzero elements only in the first column and in the
diagonal, J3 is diagonal, and J4 is tridiagonal (perhaps with exception of the first row,
depending on the difference approximation of 2(ğœ•vâˆ•ğœ•r)r=0).
Close to the inlet, there will be large variations in the velocities. The first steps
should be hz = 0.001 up to z = 0.005. Continue with hz = 0.005 to z = 0.04. Further
up in the pipe, the step hz can be successively larger. Continue the calculations of u
and v and the pressure p up to the value of z where the velocity has approximately
has attained its stationary distribution. Present the result graphically!
Project 3. Soliton waves
From Wikipedia, we get the following information about soliton waves:
â€œIn mathematics and physics, a soliton is a self-reinforcing solitary wave (a wave
packet or pulse) that maintains its shape while it travels at constant speed. Solitons
are caused by a cancellation of nonlinear and dispersive effects in the medium. (The
term dispersive effects refers to a property of certain systems where the speed of the
waves varies according to frequency.) Solitons arise as the solutions of a widespread
class of weakly nonlinear dispersive partial differential equations describing physical
systems.â€
The soliton phenomenon was first described in 1834 by John Scott Russell
(1808â€“1882) who observed a solitary wave in the Union Canal in Scotland. He
reproduced the phenomenon in a wave tank and named it the â€œWave of Translationâ€.
Solitons are modeled by the following nonlinear PDE formulated by Korteweg
and de Vries in 1895
ğœ•u
ğœ•t = âˆ’6uğœ•u
ğœ•x âˆ’ğœ•3u
ğœ•x3
We study the x interval âˆ’12 â‰¤x â‰¤12 with periodic BCs
u(12, t) = u(âˆ’12, t),
ğœ•ku
ğœ•xk (12, t) = ğœ•ku
ğœ•xk (âˆ’12, t), k = 1, 2, ...
For a soliton to appear, the IC must have a special form and amplitude. The following
IC can be used
u(x, 0) =
27
cosh(x) + cosh(3x)

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
209
Use the Method of Lines with 240 subintervals for the discretization of the x interval.
The problem then turns into a system of ODEs
du
dt = F(u)
Perform computer simulations from t = 0 to tend = 1.2 with the Rungeâ€“Kutta
classical method RK4 with the time step ht = 0.001.
Show and explain what happens if you take a larger step ht = 0.002.
Test how sensitive the soliton wave is when the amplitude of the IC is changed.
How much enlargement/reduction in the amplitude is allowed for keeping the soliton
effect?
An implicit method like the trapezoidal method is an alternative to RK4. What are
the advantages and disadvantages when using this method?
Project 4. Wave scattering in a waveguide
A plane wave is sent into a waveguideat the left end. Due to reflexes fromthe walls,
the plane wave is scattered. We want to investigate how the bend of the waveguide
affects the wave for different frequencies at the end of the waveguide.
The waves are modeled by the 2D wave equation
ğœ•2U
ğœ•t2 = ğœ•2U
ğœ•x2 + ğœ•2U
ğœ•y2
The time dependence is eliminated if the wave is monochromatic with a given
wavelength ğœ†. Let ğœ”= 2ğœ‹âˆ•ğœ†and make the ansatz
U(x, y, t) = u(x, y)eiğœ”t
The wave equation is then reduced to Helmholtzâ€™ equation
ğœ•2u
ğœ•x2 + ğœ•2u
ğœ•y2 = âˆ’ğœ”2u
with appropriate BCs. On the reflective walls of metal, there are no waves, hence
u = 0 at the walls. At the exit of the waveguide, we have an absorbing BC, which
means that the wave disappears out from the guide. This is modeled by the advection
equation
ğœ•U
ğœ•t + ğœ•U
ğœ•y = 0
if the y-axis is directed downwards. If the time dependence is eliminated, the BC at
y = yout is
ğœ•u
ğœ•y + iğœ”u = 0

210
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
At the inlet of the guide where x = 0, the wave U(0, y, t) consists of two parts, one
incoming plane wave eiğœ”(tâˆ’x) and one representing reflections from the interior,
V = U(0, y, t) âˆ’eiğœ”(tâˆ’x). For the wave part V, there is the same kind of absorbing BC
as at the exit, i.e.,
ğœ•V
ğœ•t âˆ’ğœ•V
ğœ•x = 0
Inserting the expression for V gives after some formula manipulation the BC at x = 0
ğœ•u
ğœ•x âˆ’iğœ”u + 2iğœ”= 0
We now have a 2D elliptic PDE with mixed Dirichlet and Neumann conditions.
The geometrical form of the waveguide is inserted into a square with the side
0.20 m. The width of the waveguide is 0.04 m . The contour of the waveguide
is obtained from the following (x, y) coordinates, where the y-axis is directed
downwards
x=[0,0.16,0.20,0.20,0.16,0.16,0.14,0]
y=[0,0,0.04,0.20,0.20,0.06,0.04,0.04]
It is interesting to investigate cases where the wavelength of the incoming wave has
about the same size as the width of the waveguide. Experiment with wavelengths ğœ†
in the region 30 to 80 mm.
Use first the stepsize hx = hy = 0.005 then hx = hy = 0.0025. What advantages
and disadvantages are there with another halving of the stepsize?
The probleminvolvescomplex-valuedquantities, which implies that the numerical
solution components ui,j have complex values. In the graphical presentation plot the
real part of u, which can be interpreted as the wave propagation in the waveguide at
a frozen time point.
Project 5. Metal block with heat source and thermometer
Given a homogeneous metal block with rectangular cross section 0.30 Ã— 0.20 m2.
In the block, there is a stationary heat distribution modeled by Poissonâ€™s equation in
2D with appropriate BCs. Inside the block, there is a heat source with cross section
0.04 Ã— 0.04 m2 with its left side situated 0.04 m from the left side of the rectangle
and symmetrically positioned in the y direction. The metal block has heat exchange
with the environment through its left wall (x = 0) through a thin layer of glass.
The remaining three walls are heat insulated.
The task here is to compute the temperature distribution in the metal block at
stationary conditions. The temperature u(x, y) is modeled by Poissonâ€™s equation
ğ›½
(
ğœ•2u
ğœ•x2 + ğœ•2u
ğœ•y2
)
= âˆ’q(x, y)
where ğ›½= 45 [Wâˆ•(m â‹…K)] is the thermal conductivity of the metal. This value is
also valid in the quadratic region with the heat source. We assume that the heat

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
211
source gives an evenly distributed heat flow of q(x, y) = 20,000âˆ•0.042 Wâˆ•m3 inside
the quadratic region. Outside of this region q(x, y) = 0. In grid points on the boundary
of the quadratic region, half the q value is used.
The temperature of the environment is uout = 20âˆ˜C. The heat transfer coefficient
of the glass layer is Kc = 900. Hence, the BC at x = 0 is
ğ›½ğœ•u
ğœ•x (0, y) = âˆ’Kc(uout âˆ’u(0, y))
The isolated walls of the metal block gives the BCs ğœ•uâˆ•ğœ•y = 0 at the upper (y = 0.20)
and the lower (y = 0) wall and ğœ•uâˆ•ğœ•x = 0 at the right wall (x = 0.30).
Discretize the problem with three different stepsizes, hx = hy = 0.02, 0.01, and
0.005. Plot contour curves of the temperature distribution and note specially the
maximumtemperatureof the metal block (which is found inside the quadraticregion).
Also note the temperature at the position of the thermometer, which is the point
(0.16, 0.10).
Project 6. Deformation of a circular metal plate
A circular metal plate with thickness t = 5 m and the radius R = 50 mm is simply
supported on a circular frame with the same radius. The plate is loaded transversally
with an equally distributed pressure q (Pa). In this problem, there is no ğœ‘dependence
in the deformation u(r, ğœ‘), when described in polar coordinates. Hence, the dependent
variable in the ODE modeling the deformation is r.
d4u
dr4 + 2
r
d3u
dr3 âˆ’ğ›¾2
r2
d2u
dr2 + ğ›¾2
r3
du
dr = âˆ’q
Dr
,
Dr = t3
12
Er
(1 âˆ’ğœˆ2
ğœ‘râˆ•ğ›¾2)
The material constants are Eğœ‘= 40, 000 MPa, Er = 10, 000 MPa, ğ›¾2 = Eğœ‘âˆ•Er, ğœˆğœ‘r =
0.24. The load pressure is constant q = 0.15.
The BCs of this fourth-order ODE is at r = 0 uâ€²(0) = 0, uâ€²â€²â€²(0) = 0. At r = R, the
deformation and the moment Mr are both zero. Since Mr = âˆ’Dr(uâ€²â€² + ğœˆğœ‘ruâ€²âˆ•r), we
have the BCs u(R) = 0 and uâ€²â€²(R) + ğœˆğœ‘ruâ€²(R)âˆ•R = 0.
Discretize the problem in N subintervals and approximate all derivatives in the
problem with difference quotients of second order. This will lead to a linear system
of equations with a band matrix of band width five. Use the symmetry of the problem,
i.e., that uâˆ’1 = u1 and uâˆ’2 = u2. Start with N = 50 giving the stepsize h = Râˆ•N and
continue with the stepsizes hâˆ•2 and hâˆ•4. Plot the result in a graph showing the three
stepsize approximations of u(r) in the same figure. To solve the linear system of
equations use sparse technique available in, e.g., MATLAB(R).
The ODE is singular at r = 0. Use lâ€™Hopitalâ€™s rule to find the form of the ODE at
r = 0.
In the problem, discretizations of uâ€²â€²â€²(0) and uIV(ri) are needed. Use the ansatz
uâ€²â€²â€²(0) = au(2h) + bu(h) + cu(0) + du(âˆ’h) + eu(2h)
h3

212
APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
and determine the coefficients a, b, c, d, e so that the difference quotient is of second
order. Make a similar ansatz to approximate the fourth derivative.
Project 7. Cooling of a crystal ball
The cooling of crystal glass needs attention in the production process. Quick
cooling is wanted to keep the cost lower but may cause the glass to break. A crystal
ball with radius R shall be cooled down from 980âˆ˜C to room temperature. The
temperature lowering in the oven takes place in a controlled way and depends on the
adjusted temperature parameter T that starts at t = 0 until t = T according to
f(t) = 980eâˆ’3.9tâˆ•T
For t > T, we have f(t) = 980eâˆ’3.9 = 19.8, hence normal room temperature.
The heat equation for a homogeneous sphere follows the PDE
ğœ•u
ğœ•t = D
r
ğœ•2(ru)
ğœ•r2 ,
0 < r < R,
t > 0
The thermal diffusivity for crystal glass is D = 4.0 â‹…10âˆ’7 m2âˆ•s. At r = 0, we have
the BC ğœ•u
ğœ•r = 0. Hence, at this Boundary, the heat equation takes the form
ğœ•u
ğœ•t = 3Dğœ•2u
ğœ•r2
Prove this with the help of lâ€™Hopitalâ€™s rule. The BC at r = R is u(R, t) = f(t). When
the cooling starts, the temperature of the ball is 980âˆ˜C.
Of special interest is the temperature gradient in the r directionâ€”the glass may
break if ||
ğœ•u
ğœ•r || is too large. In our case, we assume that the glass will break if the gradient
on any occasion exceeds 6000âˆ˜C, which will happen if the cooling is too quick. Make
numerical experiments with the parameter T and find the smallest value of T in the
cases R = 6, 12, and 18 cm.
Compute the temperature u(r, t) in the glass ball from t = 0 until its surface has
cooled down to room temperature.
Try discretization with 60 intervals in the r direction. Use the MoL and an appro-
priate ODE solver or use the implicit Euler method with small time steps in the
beginning and then increase the time step.
Visualize the result graphically.
Project 8. Rotating fluid in a cylinder
In a cylinder, there is a viscous fluid. The radius of the cylinder is R = 40 mm.
The cylinder with its content is rotating with an angular velocity ğœ”, so that uğœ‘= ğœ”r,
0 â‰¤r â‰¤R. The fluid has no velocity in the r or z direction, only the velocity
component u = uğœ‘.

APPLIED PROJECTS ON DIFFERENTIAL EQUATIONS
213
Suddenly at t = 0, the cylinder stops. The movement of the fluid for t > 0 is
modeled by the PDE
ğœ•u
ğœ•t = ğœˆ
(
1
r
ğœ•
ğœ•r
(
rğœ•u
ğœ•r
)
âˆ’u
r2 + ğœ•2u
ğœ•z2
)
,
0 < r < R,
0 < z < H
where H is the height of the cylinder and ğœˆis the viscosity coefficient. The BCs are
u = 0 at r = 0 and r = R. Also u = 0 at z = 0 and z = H. The parameter ğœˆhas the
value 10âˆ’6 m2âˆ•s (the value for water). The angular velocity has the value ğœ”= 1.
We want to compute and plot curves to see how the velocity u(r, z, t) of the fluid
changes with time.
1. Assume that the cylinder is very high. Then the velocity is independent of z.
This model simplification makes the PDE depend on only t and r and hence
1D in space. Use, e.g., the Crankâ€“Nicolson method to compute the velocity
distribution u(r, t) in the fluid. Plot curves with the velocity of the fluid as
function of the radius at different time points.
2. Now assume the cylinder has the height H = 8 cm. The fact that the velocity is
zero at z = 0 and z = H will influence the velocity distribution in the cylinder.
Use, e.g., the Crankâ€“Nicolson method again for the numerical solution of this
2D problem. Plot the velocity distribution at different time points with the
contourf command in MATLAB (R). Discuss the difference of the two
results.


APPENDIX A
SOME NUMERICAL AND
MATHEMATICAL TOOLS
A.1
NEWTONâ€™S METHOD FOR SYSTEMS OF NONLINEAR
ALGEBRAIC EQUATIONS
A.1.1
Quadratic Systems
Numerical solution of the nonlinear system of equations
f(u) = 0
(A.1)
can be achieved with Newtonâ€™s method.
Assume that f âˆ¶â„n â†’â„n and that f is twice continuously differentiable. A solu-
tion uâˆ—is called a root of (A.1). Often there are several roots to a nonlinear system.
The jacobian J(u) of f(u) is a quadratic matrix
J(u) = ğœ•f
ğœ•u =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
ğœ•f1
ğœ•u1
ğœ•f1
ğœ•u2
â€¦
ğœ•f1
ğœ•un
ğœ•f2
ğœ•u1
ğœ•f2
ğœ•u2
â€¦
ğœ•f2
ğœ•un
â‹®
â‹®
â€¦
â‹®
ğœ•fn
ğœ•u1
ğœ•fn
ğœ•u2
â€¦
ğœ•fn
ğœ•un
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
(A.2)
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

216
SOME NUMERICAL AND MATHEMATICAL TOOLS
Newtonâ€™s method is based on successive approximation using Taylorâ€™s expansion
formula at a point u(i)
f(u) = f(u(i)) + J(u(i))(u âˆ’u(i)) + hot
(A.3)
where hot denotes higher order terms. The point u(i) should be regarded as an approx-
imation of uâˆ—and the aim is to find a more accurate approximation.
If the term hot is neglected, (A.3) corresponds to a linear approximation of f(u)
in the neighborhood of the point u(i), i.e.,
f(u) â‰ˆf(u(i)) + J(u(i))(u âˆ’u(i))
(A.4)
If f(u) in (A.1) is replaced by the right hand side of (A.4), we obtain
f(u(i)) + J(u(i))(u âˆ’u(i)) = 0
(A.5)
This is a linear system of equations, the solution u(i+1) of which can be written as
u(i+1) = u(i) âˆ’
(
J(u(i))
)âˆ’1f(u(i))
(A.6)
The formula (A.6) together with a start value u(0) defines an iterative sequence
for finding an approximate solution to uâˆ—and is called Newtonâ€™s method. The iter-
ation formula (A.6) is based on inversion of the jacobian. Since matrix inversion is
more inefficient and more sensitive to rounding errors than Gaussian elimination, one
iteration step is instead computed in two computational steps
u(i+1) = u(i) + h(i)
(A.7)
where h(i), the correction term, is obtained by solving the linear system of equations
J(u(i))h(i) = âˆ’f(u(i))
(A.8)
by Gaussian elimination.
By using the Matlab operator \, the two steps (A.7) and (A.8) can be written in one
step (Gaussian elimination is used by the operator \).
u(i+1) = u(i) âˆ’J(u(i))âˆ–f(u(i))
(A.9)
The iteration is proceeded (i) until some convergence criterium like â€–h(i)â€– < ğœ–is
fulfilled or (ii) until some maximum number of iterations have been reached or (iii)
until the iterates u(i) have become too large in value. In the cases (ii) and (iii), the
sequence is assumed to diverge.
One important reason for divergence is that the start value u(0) is not close enough
to the root we want to determine. Finding a start value is often not trivial.You can
try to neglect the nonlinear terms and/or neglect terms with small coefficients to see

NEWTONâ€™S METHOD FOR SYSTEMS OF NONLINEAR ALGEBRAIC EQUATIONS
217
whether a simpler system occurs. You may also try some â€œstandardâ€ values, e.g.,
u(0) = (0, 0, â€¦ , 0)T or u(0) = (1, 1, â€¦ , 1)T or try to utilize the applicational back-
ground to find a suitable start value.
Example A.1.
Solve the following system of equations with Newtonâ€™s method:
f(u) =
â›
âœ
âœâ
+15u1
+u2
+u2
3
âˆ’30
âˆ’u1
+30u2
+u3
âˆ’30
âˆ’u2
1
+u2
+100u3
âˆ’20
â
âŸ
âŸâ 
= 0
For this example, a start value can be obtained by neglecting nonlinear terms and
terms with small coefficients, which gives
15u1 = 30,
30u2 = 30,
100u3 = 20
=â‡’
u1 = 2,
u2 = 1,
u3 = 0.2
We obtain
u0 =
â›
âœ
âœâ
2
1
0.2
â
âŸ
âŸâ 
,
=â‡’
f0 =
â›
âœ
âœâ
1.04
âˆ’1.8
âˆ’3
â
âŸ
âŸâ 
,
J0 =
â›
âœ
âœâ
15
1
0.4
âˆ’1
30
1
âˆ’4
1
100
â
âŸ
âŸâ 
The linear system of equations to be solved in the first iteration is
â›
âœ
âœâ
15
1
0.4
âˆ’1
30
1
âˆ’4
1
100
â
âŸ
âŸâ 
â›
âœ
âœâ
h1
h2
h3
â
âŸ
âŸâ 
= âˆ’
â›
âœ
âœâ
1.04
âˆ’1.8
âˆ’3
â
âŸ
âŸâ 
Solving this system gives the first correction h0 and the first iterate u1
h0 =
â›
âœ
âœâ
âˆ’0.0738
0.0567
0.0265
â
âŸ
âŸâ 
,
=â‡’
u1 = u0 + h0 =
â›
âœ
âœâ
1.9262
1.0567
0.2265
â
âŸ
âŸâ 
After two more iterations, the sequence has converged to four decimal accuracy
uâˆ—= (1.9251, 1.0717, 0.2263)T.
When the start value is close to the solution, the convergence is very fast.
Newtonâ€™s method has quadratic convergence, which means that the correction terms
â€–h(i)â€– behave as
â€–h(i+1)â€– â‰ˆCâ€–h(i)â€–2
(A.10)

218
SOME NUMERICAL AND MATHEMATICAL TOOLS
A.1.2
Overdetermined Systems
Newtonâ€™s method can be modified to solve overdetermined systems of nonlinear
equations
r(p) â‰ˆ0
(A.11)
where r âˆˆâ„m, p âˆˆâ„n, and m > n. Hence, there are more equations than unknowns
so we have to specify in what sense the solution is wanted. Note that the notation has
been changed. The reason for this change is that overdetermined systems often occur
in least squares problems, where we want to minimize the Euclidean length of the
residual vector r with respect to the components of a parameter vector p.
The algorithm described here, Gaussâ€“Newtonâ€™s method, will converge (when it
converges) to a solution in the least squares sense, i.e., to a point pâˆ—giving a (local)
minimum to the sum of squares of the residuals r(p)Tr(p).
Systems of type (A.11) occur, e.g., in curve-fitting problems when a parameter
vector p in a nonlinear algebraic model g(p, t) is to be fitted to measurements (tk, gk)
g(p, tk) â‰ˆgk,
k = 1, 2, â€¦ , m
(A.12)
which can also be written in the form (A.11)
r(p) â‰¡g(p) âˆ’g â‰ˆ0
(A.13)
where g(p) = (g(p, t1), g(p, t2), â€¦ , g(p, tm))T. The linear approximation of r(p) at the
point p(i) is of the same form as (A.4), but the jacobian is now a rectangular m Ã— n
matrix. Replacing the left hand side of (A.11) by its linear approximation gives an
overdetermined linear system of equations
r(p(i)) + J(p(i))(p âˆ’p(i)) â‰ˆ0
(A.14)
This system is solved in the least squares sense giving the solution p(i+1)
p(i+1) = p(i) âˆ’(J(p(i)))+r(p(i))
(A.15)
where J(p))+ is the pseudoinverse of the jacobian
(J(p))+ = (J(p)TJ(p))âˆ’1J(p)T
(A.16)
The iterative method (A.15) is called Gaussâ€“Newtonâ€™s method for solution of the
nonlinear least squares problem.
The iteration formula (A.15) can be written without the pseudoinverse using the
Matlab operator \ as in (A.9)
p(i+1) = p(i) âˆ’J(p(i))âˆ–r(p(i))
(A.17)
Like quadratic systems it is important to have a good start value p(0) for convergence
of Gaussâ€“Newtonâ€™s method. Note, however, that Gaussâ€“Newtonâ€™s method has only
linear convergence.

SOME FACTS ABOUT LINEAR DIFFERENCE EQUATIONS
219
A.2
SOME FACTS ABOUT LINEAR DIFFERENCE EQUATIONS
When a discretization method is used to solve a differential equation, the ordinary
differential equation (ODE) or the partial differential equation (PDE) is approxi-
mated by a difference equation, i.e., a relation between successive solution points
u0, u1, â€¦ , un, un+1, â€¦ where n takes only integer values. As an example, we
can take the second-order backward differentiation formula (BDF) method (see
Chapter 3)
âˆ‡un + 1
2âˆ‡2 un = hfn
(A.18)
If we use the definitions
âˆ‡un = un âˆ’unâˆ’1
âˆ‡2 un = un âˆ’2unâˆ’1 + unâˆ’2
(A.19)
we can also write the method as a relation between un values
3
2un âˆ’2unâˆ’1 + 1
2unâˆ’2 = hfn
(A.20)
called a difference equation (or recurrence equation).
A general definition of a kth-order difference equation (Î”-eqn) is
F(n, un, unâˆ’1, unâˆ’2, â€¦ , unâˆ’k) = 0
(A.21)
The general solution of such an equation will depend on n and contain k arbitrary
constants, i.e.,
un = f(n, C1, C2, â€¦ , Ck)
(A.22)
where C1, C2, â€¦ , Ck are determined from the initial or boundary conditions (BCs)
of the Î”-eqn.
An important special case of (A.21) is a linear Î”-eqn with constant coefficients.
We show first the homogeneous form
un + a1unâˆ’1 + a2unâˆ’2 + â€¦ + akunâˆ’k = 0
(A.23)
Associate with this Î”-eqn, the characteristic equation
ğœ‡k + a1ğœ‡kâˆ’1 + a2ğœ‡kâˆ’2 + â€¦ + ak = 0
(A.24)
The roots of this polynomial equation of degree k are denoted by
ğœ‡1, ğœ‡2, â€¦ , ğœ‡k
(A.25)

220
SOME NUMERICAL AND MATHEMATICAL TOOLS
If all the roots are different, the general solution of (A.23) is
un = C1ğœ‡n
1 + C2ğœ‡n
2 + â€¦ + Ckğœ‡n
k
(A.26)
where C1, C2, â€¦ , Ck are arbitrary constants (note that they enter linearly). Compare
the technique of solving a linear Î”-eqn with constant coefficients with the technique
for a linear ODE with constant coefficients. The fundamental solutions for the Î”-eqn
is ğœ‡n
i , for the ODE it is eğœ‡ix.
If there are multiple roots, the general solution expression must be modified. Say,
e.g., that ğœ‡1 = ğœ‡2 (double root). Then the general solution is
un = (C1 + C2n)ğœ‡n
1 + C3ğœ‡n
3 + â€¦ + Ckğœ‡n
k
(A.27)
The inhomogeneous form of (A.23) is
un + a1unâˆ’1 + a2unâˆ’2 + â€¦ + akunâˆ’k = bn
(A.28)
Just as in the ODE case, we first have to find a particular solution pn satisfying (A.28).
The general solution is then (provided the characteristic roots are all different)
un = pn + C1ğœ‡n
1 + C2ğœ‡n
2 + â€¦ + Ckğœ‡n
k
(A.29)
From the general solution (A.26), we see that un is stable, i.e., the un values are
bounded as n â†’âˆ, if
|ğœ‡i| â‰¤1
(A.30)
If ğœ‡i is a multiple root, the stability condition must be modified to
|ğœ‡i| < 1
(A.31)
Example A.2.
Given the difference equation
un + 3unâˆ’1 + 2unâˆ’2 = 0,
u0 = 1, u1 = 2
By inserting n = 2, 3, 4, â€¦ we get u2 = âˆ’8, u3 = 20, u4 = âˆ’44, â€¦ . What is un in
general, i.e., a formula of type un = f(n)?
Solve first the characteristic equation
ğœ‡2 + 3ğœ‡+ 2 = 0
with the solution
ğœ‡1 = âˆ’1,
ğœ‡2 = âˆ’2
Hence, the general solution is
un = C1(âˆ’1)n + C2(âˆ’2)n

SOME FACTS ABOUT LINEAR DIFFERENCE EQUATIONS
221
Insert the initial conditions
u0 = C1 + C2 = 1
u1 = âˆ’C1 âˆ’2C2 = 2
which gives C1 = 4, C2 = âˆ’3 and the solution is
un = 4(âˆ’1)n âˆ’3(âˆ’2)n
Example A.3.
What is the stability area of the explicit midpoint method?
Apply the method to uâ€² = ğœ†u and we get the Î”-eqn
un+1 = unâˆ’1 + 2hğœ†un
and the characteristic equation is
ğœ‡2 âˆ’2ğœ†hğœ‡âˆ’1 = 0
where ğœ†is a complex-valued parameter.
Write one root on polar form ğœ‡1 = reiğœ™. Since ğœ‡1ğœ‡2 = âˆ’1, we get ğœ‡2 =
âˆ’(1âˆ•r)eâˆ’iğœ™.
For a stable solution, we must have r = 1. Since ğœ‡1 + ğœ‡2 = 2ğœ†h, we get eiğœ™âˆ’eâˆ’iğœ™=
2ğœ†h, i.e.,
ğœ†h = i sin ğœ™
Hence, the stability area of the explicit midpoint method is the interval [âˆ’i, i] on the
imaginary axis.
Example A.4.
Compute the eigenvalues of the tridiagonal matrix
A = tridiagn(âˆ’1, 2, âˆ’1) =
â›
âœ
âœ
âœ
âœâ
2
âˆ’1
0
â€¦
0
âˆ’1
2
âˆ’1
â‹±
â‹®
0
â‹±
â‹±
â‹±
0
â‹®
â‹±
âˆ’1
2
âˆ’1
0
â€¦
0
âˆ’1
2
â
âŸ
âŸ
âŸ
âŸâ 
The eigenvalue problem Au = ğœ†u for this problem is formulated as a Î”-eqn
âˆ’ukâˆ’1 + 2uk âˆ’uk+1 = ğœ†uk,
k = 1, 2, â€¦ , n
Since there are no u0- or un+1 components in u, we set these components to zero and
obtain a boundary value problem for a Î”-eqn
uk+1 + (ğœ†âˆ’2)uk + ukâˆ’1 = 0,
u0 = 0,
un+1 = 0

222
SOME NUMERICAL AND MATHEMATICAL TOOLS
The roots of the characteristic equation
ğœ‡2 + (ğœ†âˆ’2)ğœ‡+ 1 = 0
are denoted by ğœ‡1 and ğœ‡2. The roots fulfill the relations
ğœ‡1ğœ‡2 = 1,
ğœ‡1 + ğœ‡2 = 2 âˆ’ğœ†
Hence, if ğœ‡1 = reiğœ™, then ğœ‡2 = (1âˆ•r)eâˆ’iğœ™if we use the polar form. The general solu-
tion of the Î”-eqn (if ğœ‡1 â‰ ğœ‡2) is
uk = C1ğœ‡k
1 + C2ğœ‡k
2
Insert the BCs
u0 = C1 + C2 = 0 â†’C2 = âˆ’C1
un+1 = C1ğœ‡n+1
1
+ C2ğœ‡n+1
2
= 0
The condition C2 = âˆ’C1 above is used and we get
C1ğœ‡n+1
1
= C1ğœ‡n+1
2
We want a nontrivial solution, i.e., C1 â‰ 0, which gives
(ğœ‡1
ğœ‡2
)n+1
= 1
or if we use the polar form of ğœ‡1 and ğœ‡2
r2e2iğœ™(n+1) = 1
which gives
r = 1,
2iğœ™(n + 1) = 2ğœ‹ik,
k = 1, 2, â€¦ , n
ğœ™k =
ğœ‹k
n + 1,
k = 1, 2, â€¦ , n
The values k = 0 and k = n + 1 must be excluded in the formula above, since we
then obtain ğœ‡1 = ğœ‡2 = 1 or ğœ‡1 = ğœ‡2 = âˆ’1, respectively, i.e., double roots, in which
case uk = (C1 + C2k)â†’C1 = C2 = 0, i.e., the trivial solution.
As a final result, we obtain
2 âˆ’ğœ†= ğœ‡1 + ğœ‡2 = eiğœ™+ eâˆ’iğœ™= 2 cos ğœ™

DERIVATION OF DIFFERENCE APPROXIMATIONS
223
Hence, the eigenvalues are
ğœ†k = 2(1 âˆ’cos ğœ™k) = 4sin2(ğœ™kâˆ•2),
k = 1, 2, â€¦ , n
The smallest eigenvalue is obtained from k = 1: ğœ†1 â‰ˆğœ‹2/(n + 1)2 and the largest for
k = n: ğœ†n â‰ˆ4.
A.3
DERIVATION OF DIFFERENCE APPROXIMATIONS
Difference approximation of derivative terms in ODEs and BCs are based on Taylorâ€™s
formula
f(x + h) = f(x) + hf â€²(x) + h2
2 f â€²â€²(x) + h3
6 f â€²â€²â€²(x) + h4
24f (4)(x) + îˆ»h5
(A.32)
The Taylor expansion is suitable since a difference approximation should be valid
locally in the neighborhood of a point x.
We have already seen the following examples of central difference approxima-
tions:
du
dx(x) = u(x + h) âˆ’u(x âˆ’h)
2h
+ îˆ»h2
(A.33)
d2u
dx2 (x) = u(x + h) âˆ’2u(x) + u(x âˆ’h)
h2
+ îˆ»h2
(A.34)
How are similar formulas derived when approximationsto higher order derivatives
or unsymmetric formulas for the derivatives are needed? As a first example, assume
we need a difference approximation to f â€²(x) when the function values f(x), f(x + h),
and f(x + 2h) are available. Make the following linear ansatz:
f â€²(x) = af(x) + bf(x + h) + cf(x + 2h) + îˆ»hp
(A.35)
where a, b, and c are to be determined so that the approximation order p is as high as
possible. Use Taylorâ€™s formula on f(x + h) and f(x + 2h)
f â€²(x) = af(x) + b(f(x) + hf â€²(x) + h2
2 f â€²â€²(x)) + c(f(x)
+ 2hf â€²(x) + (2h)2
2
f â€²â€²(x)) + îˆ»h3
Since there are three unknown coefficients a, b, and c to determine, we need three
equations. They are obtained by identifying coefficients in front of f(x), f â€²(x),
f â€²â€²(x), â€¦ in the left and right hand side
a + b + c = 0
hb + 2hc = 1
h2
2 b + (2h)2
2
c = 0

224
SOME NUMERICAL AND MATHEMATICAL TOOLS
The solution is
â›
âœ
âœâ
a
b
c
â
âŸ
âŸâ 
= 1
2h
â›
âœ
âœâ
âˆ’3
4
âˆ’1
â
âŸ
âŸâ 
Hence, the unsymmetric difference approximation is
f â€²(x) = âˆ’3f(x) + 4f(x + h) âˆ’f(x + 2h)
2h
+ e(x)
(A.36)
where e(x) is the approximation error. What is the approximation order p? Look at
the next term in the Taylor expansion and insert the solution a, b, and c
e(x) =
(
bh3
6 + c(2h)3
6
)
f â€²â€²â€²(x) = âˆ’h2
3 f â€²â€²â€²(x) = îˆ»h2
(A.37)
Hence, the approximation (A.36) is of second order.
With the same technique, the following difference approximations can be derived:
f â€²â€²â€²(x) = f(x + 2h) âˆ’2f(x + h) + 2f(x âˆ’h) âˆ’f(x âˆ’2h)
2h3
+ îˆ»h2
f (4)(x) = f(x + 2h) âˆ’4f(x + h) + 6f(x) âˆ’4f(x âˆ’h) + f(x âˆ’2h)
h4
+ îˆ»h2
Deriving difference approximations based on Taylorâ€™s formula can be systemized
with an elegant technique called operator calculus, see [1]. Define the following
operators
Ef(x) = f(x + h)
(A.38)
Î”f(x) = f(x + h) âˆ’f(x)
(A.39)
âˆ‡f(x) = f(x) âˆ’f(x âˆ’h)
(A.40)
Df(x) = f â€²(x)
(A.41)
Taylorâ€™s formula can be written
Ef(x) =
(
1 + hD + (hD)2
2
+ (hD)3
6
+ â€¦
)
f(x)
(A.42)
i.e.,
E = ehD
(A.43)
Since E = Î” + 1, we have
hD = log(1 + Î”) = Î” âˆ’Î”2
2 + Î”3
3 + â€¦
(A.44)

THE INTERPRETATIONS OF GRAD, DIV, AND CURL
225
With this operator formalism, (A.36) can be derived by retaining only the first two
terms in (A.44)
D â‰ˆ1
h
(
Î” âˆ’Î”2
2
)
= 1
h
(
E âˆ’1 âˆ’1
2(E âˆ’1)2)
f â€²(x) â‰ˆ1
h
(
f(x + h) âˆ’f(x) âˆ’1
2(f(x + 2h) âˆ’2f(x + h) + f(x))
)
= âˆ’3f(x) + 4f(x + h) âˆ’f(x + 2h)
2h
The approximation error is obtained from the first neglected term in (A.44)
e(x) = 1
h
Î”3
3 f(x) = 1
3h(ehD âˆ’1)3f(x) = â€¦ = âˆ’h2
3 f â€²â€²â€²(x)
The algebra of operator calculus can be generalized to inversion. Since
Enf(x) = f(x + nh) â†’Eâˆ’1f(x) = f(x âˆ’h)
we get
âˆ‡= 1 âˆ’Eâˆ’1
(A.45)
With this relation, we can derive other approximations to f â€²(x) from
hD = âˆ’log(1 âˆ’âˆ‡) = âˆ‡+ âˆ‡2
2 + âˆ‡3
3 + â€¦
(A.46)
Retaining only the first two terms gives
D â‰ˆ1
h
(
âˆ‡+ âˆ‡2
2
)
= 3f(x) âˆ’4f(x âˆ’h) + f(x âˆ’2h)
2h
BIBLIOGRAPHY
1. G. Dahlquist and Ã…. BjÃ¶rck, â€œNumerical Methods,â€ Dover, 2003
A.4
THE INTERPRETATIONS OF GRAD, DIV, AND CURL
The gradient. Let Î¦(r) be a scalar-valued field, where r = (x, y)T. From a fixed point
r0, let d be a vector of unit length 1, i.e., â€–dâ€–2
2 = dTd = 1, defining a direction from
r0. With Taylor expansion, we obtain
Î¦(r0 + d) = Î¦(r0) + âˆ‡dÎ¦(r0) + hot

226
SOME NUMERICAL AND MATHEMATICAL TOOLS
x
y
Contour curves of z = 2x2 + 4y4 âˆ’ 4xy âˆ’ 4x + 8
âˆ’1
0
1
2
3
4
5
âˆ’2.5
âˆ’2
âˆ’1.5
âˆ’1
âˆ’0.5
0
0.5
1
1.5
2
2.5
Figure A.1
Contour curves with a gradient inserted
where âˆ‡dÎ¦ = dTâˆ‡Î¦ is called the direction derivative of Î¦ in the direction d. âˆ‡dÎ¦
can be interpreted as the velocity with which Î¦ changes when moving away from r0
in the direction d. The largest values of the velocity is obtained for d = Â±âˆ‡Î¦(r0).
Hence, Î¦ increases fastest in the direction of the gradient and decreases fastest in
the direction of the negative gradient, also called the steepest descent direction, see
Section A.5.2 (Figure A.1).
A contour curve of Î¦ is a curve along which the function has a constant value. The
gradient at a point is always orthogonal to the contour curve through that point. In a
point where the direction d is orthogonal to âˆ‡Î¦(r0), i.e., âˆ‡dÎ¦(r0) = 0, Î¦ does not
change (if hot is neglected). This direction is in fact the tangent of the contour curve
at the point.
The divergence. Let ğœ•Î© be a positively oriented curve enclosing the region Î© in
R2. Let P(x, y) and Q(x, y) be two continuously differentiable functions in Î©. Then
use Greenâ€™s theorem
âˆ®ğœ•Î©
Pdx + Qdy = âˆ«
âˆ«Î©
(ğœ•Q
ğœ•x âˆ’ğœ•P
ğœ•y
)
dxdy
How can this theorem be used? To be a little more precise, assume that the boundary
curve is defined by the vector r(s), where the parameter s is the arclength of the curve
measured from some initial point r0 = r(0). When s is increased, the curve moves
counterclockwise (see Figure A.2).

THE INTERPRETATIONS OF GRAD, DIV, AND CURL
227
F(s)
s
x
y
et
en
xâ€²(s)
yâ€²(s)
yâ€²(s)
âˆ’xâ€²(s)
x
y
âˆ‚Î©
Î©
Figure A.2
Tangent and normal directions at a point on a curve
The unit vector in the tangent direction, et, is
et = dr
ds = (xâ€²(s), yâ€²(s))T
The unit vector in the normal direction pointing out of Î©, en, is
en = (yâ€²(s), âˆ’xâ€²(s))T
We now show the meaning of the operator div applied to heat flow:
Assume there is a heat flux F = (P(x, y), Q(x, y))T, measured in Jâˆ•(m2 â‹…s), in a thin
plate of thickness h (m). The shape of the plate corresponds to the region Î©. The total
flow of heat out of Î© is obtained if we sum the contributions of flow out from each
little area section hds along ğœ•Î©. The heat flow, measured in Jâˆ•s, in the outward normal
direction from such a section is F â‹…en â‹…h â‹…ds. The net heat flow, i.e., the difference
between the outflow out of Î© and the inflow into Î© is (Figure A.3)
hâˆ®ğœ•Î©
F â‹…en ds
Using Greenâ€™s theorem on this integral, we arrive at Gaussâ€™ theorem:
âˆ®ğœ•Î©
F â‹…en ds = âˆ®ğœ•Î©
(Pyâ€²(s) âˆ’Qxâ€²(s))ds
= âˆ«âˆ«Î©
(
ğœ•P
ğœ•x + ğœ•Q
ğœ•y
)
dxdy = âˆ«âˆ«Î©
div F dxdy
Hence, if div F = 0 in the whole of Î©, the net flow of heat out of Î© is zero, in other
words: the heat flow into Î© = the heat flow out of Î©. What is the interpretation if

228
SOME NUMERICAL AND MATHEMATICAL TOOLS
en
F
Fâ€¢en
ds
x
y
âˆ‚Î©
Î©
Figure A.3
Flux vector at a point on the boundary projected to the normal direction
div F â‰ 0? Apply Gaussâ€™ theorem to a small area A of Î©, so small that div F can be
considered constant in A. The net flow out of the small volume hA is
hâˆ®ğœ•A
F â‹…en ds â‰ˆhA div F â‡’
div F â‰ˆ1
hAhâˆ®ğœ•A
F â‹…en ds
Hence, div F can be interpreted as the amount of heat energy produced (div F > 0) or
consumed (div F < 0) per unit time and unit volume [Jâˆ•(m3 â‹…s)] by the vector field
F in Î©. Hence, div F is the source strength of the field F.
The curl (rotation). In a similar way, curl can be given an interpretation if we
apply Greenâ€™s theorem on a velocity field v(x, y) = (P(x, y), Q(x, y))T defined on a
small circle Cr with radius r in Î©, i.e.,
âˆ®ğœ•Cr
v â‹…et ds = âˆ®ğœ•Cr
(Pxâ€²(s) + Qyâ€²(s))ds = âˆ®ğœ•Cr
Pdx + Qdy = âˆ«âˆ«Cr
curl v dxdy
If the circle is so small that curl v is approximately constant in Cr, we get
âˆ®ğœ•Cr
v â‹…et ds â‰ˆğœ‹r2 curl v
The mean value of vt, the tangential component of v along ğœ•Cr, is (Figure A.4)
vtmean =
1
2ğœ‹râˆ®ğœ•Cr
vt ds
Since vt = rğœ”, where ğœ”is the angular velocity, Ì‡ğœ‘, the mean value of the angular
velocity along ğœ•Cr is
ğœ”mean â‰ˆ
1
2ğœ‹râˆ®ğœ•Cr
vt
r ds =
1
2ğœ‹r2 âˆ®ğœ•Cr
v â‹…et ds â‰ˆ1
2curl v

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
229
Cr
âˆ‚Cr
ğœ‘
et
v
vâ€¢et
ds
x
y
Figure A.4
Velocity vector at a point on the boundary projected to the tangential direction
Hence, curl v is interpreted as the vorticity strength of the velocity field v.
A.5
NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF
EQUATIONS
Numerical solution of systems of equations occurs frequently as part of the numerical
treatment of differential equations. The system can be linear
Au = b,
where
A
is n Ã— n
or nonlinear
f(u) = 0,
where the jacobian
J(u) = ğœ•f
ğœ•u
is n Ã— n
For a nonlinear system, an iterative method must be used. If Newtonâ€™s method (see
Section A.1) is chosen, a linear system of equations has to be solved in each iteration.
The parameter n is the number of unknowns = the number of equations. When A
has no special structure, it is called a full matrix. For a full matrix, all n2 elements
must be stored.
However, when differential equations are solved numerically, sparse systems of
equations occur frequently. The system is sparse if A (or J) has a small number
nz â‰ªn2 of nonzero elements. Often in a sparse system, there are a few unknowns
in each equations, i.e., nz = îˆ»(n). Hence, all elements of a sparse matrix must not be
stored but essentially only those which are nonzero.
For efficiency reasons, it is important to utilize the sparsity of the system, both
when it is comes to how the storage is organized and how the solution algorithm is
designed.
A.5.1
Direct Methods
A.5.1.1
Some Facts about Gaussian Elimination The standard method for
solving Au = b is Gaussian elimination with row pivoting. The algorithm gives both
the solution u and the LU factorization of A. If no pivoting is needed, we obtain

230
SOME NUMERICAL AND MATHEMATICAL TOOLS
A = LU, where L is lower triangular with ones in the main diagonal and U is upper
triangular. The computational work to compute the solution and the factorization
amounts to about n3âˆ•3 flops.
If row pivoting is necessary, the LU factorization is valid for a row permuted A,
i.e., PA = LU, where P is a permutation matrix.
If A is symmetric and positive definite (SPD), A = AT and ğœ†i(A) > 0, i =
1, 2, â€¦ , n, the factorization can be written A = LLT, also called the Cholesky
factorization of A, and is achieved in n3âˆ•6 flops.
A.5.1.2
Direct Methods for Sparse Linear Systems For sparse matrices, there are
modified versions of Gaussian elimination that give the solution more efficiently than
Gaussian elimination for a full matrix.
A.5.1.2.1
Methods for Band Structured Matrices. A common sparse structure is
the band structure with bandwidth p, e.g.,
A =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
a11
a12
0
0
0
0
a21
a22
a23
0
0
0
a31
a32
a33
a34
0
0
0
a42
a43
a44
a45
0
0
0
a53
a54
a55
a56
0
0
0
a64
a65
a66
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
,
p = 4
The number of bands is called the bandwidth of A. A bandmatrix with bandwidth p
can be stored as p columns in an n Ã— p matrix B in the following way:
B =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
0
0
a11
a12
0
a21
a22
a23
a31
a32
a33
a34
a42
a43
a44
a45
a53
a54
a55
a56
a64
a65
a66
0
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
Hence, np elements are needed to store the elements of A instead of n2. The LU
factorization is computed in np2 flops and stored in the same matrix by overwriting
the elements of B
(L, U) =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
0
0
r11
r12
0
l21
r22
r23
l31
l32
r33
r34
l42
l43
r44
r45
l53
l54
r55
r56
l64
l65
r66
0
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
Since the elements in the main diagonal of L are ones, there is no need to store that
diagonal.

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
231
If the matrix A is symmetric, only the main diagonal and the diagonals below need
to be stored in B. The Cholesky factorization can be done on the same matrix space as
B and the result, the band-stored L-matrix, overwrites the original B-matrix. Observe
that the Cholesky factor L has a main diagonal with elements not equal to one. Hence,
this diagonal must also be stored. The number of flops needed is np2/2. Following is
an example:
B =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
0
0
a11
0
a21
a22
a31
a32
a33
a42
a43
a44
a53
a54
a55
a64
a65
a66
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
,
L =
â›
âœ
âœ
âœ
âœ
âœ
âœâ
0
0
l11
0
l21
l22
l31
l32
l33
l42
l43
l44
l53
l54
l55
l64
l65
l66
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
Band matrices occur, e.g., when the finite difference method (FDM) or finite element
method (FEM) is used to discretize a PDE problem defined on a rectangular region,
e.g., Poissonâ€™s equation defined on a square (see Chapter 7).
A special but important type of band matrix is the tridiagonal n Ã— n matrix A
A = tridiagn(a, d, c)
where a and c are vectors of dimension n âˆ’1 (the sub- and superdiagonals) and d a
vector of dimension n (the main diagonal). Tridiagonal matrices occur when FDM or
FEM is used to solve boundary value problem (BVP) (see Chapter 4).
Obviously much computational work can be saved if a sparse matrix A can be
transformed into a bandmatrix with small bandwidth. The transformations must be
done in an economic way in order not to waste flops on this part of the algorithm.
Examples of simple â€œcheapâ€ transformations are permutations of rows and columns.
Let P and Q be permutation matrices. The effect of multiplying A from the left with
P is changing the order of the rows of A, and multiplying A from the right with Q will
change the order of the columns of A, e.g.,
PA =
â›
âœ
âœ
âœâ
âˆ’
a2 âˆ’
âˆ’
a4 âˆ’
âˆ’
a1 âˆ’
âˆ’
a3 âˆ’
â
âŸ
âŸ
âŸâ 
,
AQ =
â›
âœ
âœâ
|
|
|
|
a3
a1
a4
a2
|
|
|
|
â
âŸ
âŸâ 
Do the following series of transformations of the system Au = b:
PAu = Pb,
u = Qv,
PAQv = Pb
The ordering of rows and columns in A, resulting in a matrix PAQ that has a
smaller bandwidth than A, can be done with different algorithms. Examples of such
algorithms are the minimum degree permutation or the reverse Cuthill MacKee
permutation (see the Bibliography for more information).

232
SOME NUMERICAL AND MATHEMATICAL TOOLS
A.5.1.2.2
Methods for Profile Structured Matrices. An alternative way of storage,
applicable for an SPD matrix A, is the profile storage of the main diagonal and the
lower part of A. The profile is the border for which all elements to the left of the border
are zero-elements. Profile structured matrices occur, e.g., when FEM is applied to an
elliptic PDE problem defined on an irregular region.
It can be shown that the profile of the Cholesky factorized L-matrix has the same
profile as the original matrix, i.e., the profile is invariant under Cholesky factorization
A =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
,
L =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
It is not efficient to store A as a full matrix. Instead, only the nonzeros of A are stored
in a vector a together with a pointer vector p the elements of which show the locations
of the diagonal elements of A. See the example below:
A =
â›
âœ
âœ
âœ
âœâ
25
3
21
0
2
23
0
4
0
22
0
0
1
0
20
â
âŸ
âŸ
âŸ
âŸâ 
a = (25, 3, 21, 2, 23, 4, 0, 22, 1, 0, 20)
p = (1, 3, 5, 8, 11)
A.5.1.2.3
Methods for General Sparse Matrices. A general way of storing a sparse
matrix A is to store only its nonzero elements in a vector together with two index
vectors containing the row and column indices of the nonzero elements.
A =
â›
âœ
âœ
âœ
âœâ
a11
0
a13
0
a15
a21
0
0
a24
0
0
a32
0
0
a35
0
a42
0
a44
0
a51
0
0
a54
0
â
âŸ
âŸ
âŸ
âŸâ 
is stored in the three vectors
a = (a11, a13, a15, a21, a24, a32, a35, a42, a44, a51, a54)
ia = (1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5)
ja = (1, 3, 5, 1, 4, 2, 5, 2, 4, 1, 4)

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
233
Observe that storing this matrix A as a band matrix is not efficient, since the full
matrix then must be stored.
The solution and factorization of a general sparse system Au = b is more compli-
cated, since the sparseness structure in A will not be preserved in L and U after the
Gaussian elimination process. Usually L and U will be much less sparse than A. For
more information, see the Bibliography.
A.5.2
Iterative Methods for Linear Systems of Equations
An alternative method for solving Au = b, where A is n Ã— n matrix, is to use an
iterative method. For such a method to be more efficient than a direct method the
matrix A should fulfill the following requirements:
â€¢ it is â€œcheapâ€ to form Ax (number of flops â‰ªn2)
â€¢ the iterative method is â€œfastâ€ (number of iterations â‰ªn)
The first property originsfrom the structure of A, while the second property is alge-
braic; the convergence rate depends on the eigenvalues of A. The iterative methods
can be divided into stationary and search methods.
A.5.2.1
Stationary Iterative Methods The general idea with an iterative method
is based on splitting of the matrix A
A = M âˆ’N
(A.47)
The iteration method is then defined as
Muk+1 = Nuk + b
(A.48)
where u0 is a given start vector. The iterations are continued until â€–uk+1 âˆ’ukâ€– is small
enough,where â€–.â€– is some norm, e.g., the maximumnorm or the Euclidean norm. The
method is called stationary if M and N are constant matrices. The iteration formula
can also be written
uk+1 = Guk + Mâˆ’1b
(A.49)
where G = Mâˆ’1N is the iteration matrix. As usual, however, inversion should not
be used in numerical methods for solving systems of equations. Let uâˆ—be the exact
solution of Au = b. The error in uk is defined as
ek = uâˆ—âˆ’uk
(A.50)
and satisfies the iteration formula
ek+1 = Gek
(A.51)

234
SOME NUMERICAL AND MATHEMATICAL TOOLS
The residual at uk is defined as
rk = b âˆ’Auk
(A.52)
and the relation between the error and the residual is
rk = Aek
(A.53)
The iteration method converges if ek â†’0 as k â†’âˆ. The condition for convergence
is
ğœŒ(G) < 1,
where
ğœŒ(G) = max
i
|ğœ†i(G)|
(A.54)
Convergenceis fast if ğœŒ(G) â‰ª1, slow if ğœŒ(G) â‰ˆ1 âˆ’ğœ–, where 0 < ğœ–â‰ª1, and divergent
if ğœŒ(G) > 1. ğœŒ(G) is called the spectral radius of G.
If the convergence is fast, i.e., the number of iterations needed to achieve a given
accuracy is small, an iterative method is more efficient than a direct method. Observe
that in a method based on splitting, as above, the number of flops in each iteration is
essentially nz if the matrix-vector multiplication is performed in a sparse way and M
is a matrix that is cheap to â€œinvert.â€
The splitting can be done in different ways. Classical methods are
â€¢ Jacobiâ€™s method, A = D âˆ’B, where D is the diagonal of A and B is the outer
diagonal part of A. Hence, the iteration scheme is
Duk+1 = Buk + b
(A.55)
â€¢ Gaussâ€“Seidelâ€™s method, A = D âˆ’L âˆ’U, where L is strictly lower triangular and
U is strictly upper triangular. The iterative scheme is
(D âˆ’L)uk+1 = Uuk + b
(A.56)
The classical methods above are usually not efficient on problems from ODEs and
PDEs. Extensions of these methods to SOR (successive overelaxation) and SSOR
(symmetric successive overelaxation SOR) have better convergence properties but
are not competitive with modern methods. However, as preconditioners (see later)
both Jacobi and SSOR are very useful. For further description of these methods, see
the Bibliography.
A.5.2.2
Search Methods for SPD Matrices In this part of the appendix, we
restrict the description to systems of equations Au = b, where A is an SPD matrix.
For such matrices, the solution of the linear system of equations is equivalent to the
minimization problem
min
u F(u)
(A.57)
where the object function F(u) is
F(u) = 1
2uTAu âˆ’uTb
(A.58)

NUMERICAL SOLUTION OF ALGEBRAIC SYSTEMS OF EQUATIONS
235
In the context of numerical methods for minimization, it is appropriate to design
search methods to find the minimum point uâˆ—. Such methods are defined by
uk+1 = uk + ğ›¼kdk
(A.59)
where dk is the search direction and ğ›¼is the step length taken in this direction. The
step length is usually chosen so that F(u) is minimized along the search direction dk.
This minimization is performed with respect to ğ›¼â‰¥0 and it is easy to show that the
optimal value of ğ›¼is
ğ›¼k =
rT
k dk
dT
k Adk
(A.60)
What differs between methods is the choice of the search direction. Two
well-known methods are
â€¢ steepest descent (SD) method, where dk = rk, u0 = 0
â€¢ conjugate gradient (CG) method, where dk is updated according to
dk+1 = rk+1 + ğ›½kdk,
where
ğ›½k =
rT
k+1rk+1
rT
k rk
,
u0 = 0,
d0 = r0
(A.61)
It can be shown that the residuals r0, r1, â€¦ , rk generated by CG are orthogonal
and that both the residuals and the search directions d0, d1, â€¦ , dk span the so-called
Krylov space
Kk+1 = [b, Ab, A2b, â€¦ , Akb]
(A.62)
What is most remarkable about the CG method is that, in the absence of rounding
errors, it gives the exact solution after less than or equal to n iterations. In a way,
therefore, CG could be classified as a direct method. However, often the convergence
is so fast that only few iterations are needed to achieve sufficient accuracy.
Both SD and CG are descent methods, i.e., F(uk+1) < F(uk) but CG converges
faster to uâˆ—than SD.
It can be shown that the convergence rate for search methods depends on the con-
dition number ğœ…(A), defined as
ğœ…(A) = maxiğœ†i(A)
miniğœ†i(A)
(A.63)
For a large condition number the convergenceis slow. The smallest condition number
that can be achieved for all matrices A is equal to 1, and in that case the exact solution
is obtained after 1 iteration. It can be shown that convergence to a specified accuracy
can be expected in îˆ»(ğœ…(A)) iterations for SD and in îˆ»
(âˆš
ğœ…(A)
)
iterations for CG.

236
SOME NUMERICAL AND MATHEMATICAL TOOLS
If the condition number is large, it can be reduced by preconditioning. Introduce
the nonsingular n Ã— n matrix E and the variable substitution v = Eu. The function
F(u) in (A.58) is then changed to
ÌƒF(v) = F(u) = F(Eâˆ’1v) = 1
2vT ÌƒAv âˆ’vT Ìƒb
where
ÌƒA = Eâˆ’TAEâˆ’1,
Ìƒb = Eâˆ’Tb
(A.64)
How should E be chosen so that ğœ…(ÌƒA) â‰ªğœ…(A)? In case E = I, ÌƒA = A and nothing
has been gained. If E = LT, where L is the Cholesky factor of A, ÌƒA = Lâˆ’1ALâˆ’T =
Lâˆ’1LLTLâˆ’T = I, and ÌƒA is perfectly conditioned. However, using Cholesky factoriza-
tion of A to get a preconditioner would be equivalent to using a direct method, which
we wanted to avoid. In between E = I and E = LT, however, there are many good
working preconditioners C, where C = ETE is called the preconditioning matrix.
A simple choice of the matrix C is C = diag(A), which is similar to Jacobiâ€™s method
and eii = âˆšaii.
Another often-used preconditioner is the incomplete Cholesky factorization, ÌƒLÌƒLT,
where ÌƒL is a modified Cholesky factor, allowed to have nonzeros only in positions
where A has nonzeros. Hence, E = ÌƒLT and C = ÌƒLÌƒLT.
To make the preconditioning methods efficient, it is not possible to form the
ÌƒA-matrix in (A.64) explicitly before the search method is started. This would involve
inverting E and, as usual, the inverse should never be formed in numerical operations,
but, e.g., Ìƒb should be computed by solving ET Ìƒb = b.
Below it is shown how SD with preconditioning is designed efficiently. The SD
iterations for the vk sequence (A.64) is
vk+1 = vk + ğ›¼k(Ìƒb âˆ’ÌƒAvk)
Express this iteration as a sequence in the uk values
Euk+1 = Euk + ğ›¼k(Ìƒb âˆ’ÌƒAEuk)
Multiply by Eâˆ’1
uk+1 = uk + ğ›¼kEâˆ’1(Eâˆ’Tb âˆ’Eâˆ’TAEâˆ’1Euk)
which can be written
uk+1 = uk + ğ›¼kCâˆ’1(b âˆ’Auk)
where C = ETE is the preconditioner.
In the discretization of PDEs on a fine grid, the systems of equations are huge.
However, if the same problem is solved on a course grid, we have a small system to
solve. The idea of switching between coarser and finer grids has developed to a class
of methods called multigrid methods, where the number of flops needed to solve the
system is îˆ»(n).

SOME RESULTS FOR FOURIER TRANSFORMS
237
A.5.2.3
Search Methods for General Matrices When the matrix A is sparse but
unsymmetric and/or semidefinite, there is no suitable corresponding minimization
problem. If the system of equations is multiplied by AT, we obtain a SPD system
ATAu = ATb
This system, however, has an even worse condition number, since
ğœ…(ATA) = ğœ…(A)2
and is therefore not always sufficiently effective. This method is known as the CGN,
CG to normal equations.
An alternative widely used method is GMRES, the generalized minimum resid-
ual method. Like CG it generates a sequence of search directions dk but requires all
previous search vectors d1, d2, â€¦ , dk to form dk+1 in contrast to CG, where dk+1 is
formed from dkâˆ’1 and dk only.
For more information about these methods, see the Bibliography.
A.6
SOME RESULTS FOR FOURIER TRANSFORMS
Fourier analysis is the common term for Fourier transforms and Fourier series, named
after the French mathematician Joseph Fourier, active in the beginning of the 19th
century.
Assume that u(x) is defined on the entire real axis. The continuous Fourier trans-
form Ì‚u(ğœ”) of u(x) is defined as the integral
Ì‚u(ğœ”) =
1
âˆš
2ğœ‹âˆ«
+âˆ
âˆ’âˆ
u(x)eâˆ’iğœ”xdx
The inverse transform is
u(x) =
1
âˆš
2ğœ‹âˆ«
+âˆ
âˆ’âˆ
Ì‚u(ğœ”)eiğœ”xdğœ”
Here ğœ”= 2ğœ‹f, where ğœ”is the angular frequency and f the frequency. The second
formula can be interpreted as a superposition of waves eiğœ”x with the corresponding
amplitudes Ì‚u(ğœ”).
If the function u(x) is known only at discrete equally spaced points xj = jh, j = â€¦ ,
âˆ’2, âˆ’1, 0, 1, 2, â€¦ the discrete Fourier transform is defined as
Ì‚u(ğœ”) =
1
âˆš
2ğœ‹
j=+âˆ
âˆ‘
j=âˆ’âˆ
u(xj)eâˆ’iğœ”xjh

238
SOME NUMERICAL AND MATHEMATICAL TOOLS
with the inverse
u(xj) =
1
âˆš
2ğœ‹âˆ«
+ğœ‹âˆ•h
âˆ’ğœ‹âˆ•h
Ì‚u(ğœ”)eiğœ”xjdğœ”
The transforms exist if the original function u(x) is square integrable, i.e., for the
continuous and discrete case, respectively,
âˆ«
+âˆ
âˆ’âˆ
|u(x)|2dx < âˆ
+âˆ
âˆ‘
âˆ’âˆ
|u(xj)|2 < âˆ
The following relations between the original function and its transform are called
Parsevalâ€™s equalities:
âˆ«
+âˆ
âˆ’âˆ
|u(x)|2dx = âˆ«
+âˆ
âˆ’âˆ
|Ì‚u(ğœ”)|2dğœ”
+âˆ
âˆ‘
âˆ’âˆ
|u(xj)|2h = âˆ«
+ğœ‹âˆ•h
âˆ’ğœ‹âˆ•h
|Ì‚u(ğœ”)|2dğœ”
When the Fourier transform is applied to the heat equation
ut = ğœ…uxx,
u(x, 0) = u0(x),
âˆ’âˆ< x < +âˆ
we obtain the following ODE for the continuous Fourier transform Ì‚u(ğœ”, t) of the
solution u(x, t):
dÌ‚u
dt = âˆ’ğœ…ğœ”2Ì‚u,
Ì‚u(ğœ”, 0) = Ì‚u0(ğœ”)
with the solution
Ì‚u(ğœ”, t) = eâˆ’ğœ…ğœ”2t Ì‚u0(ğœ”)
Applying the inverse transform
u(x, t) =
1
âˆš
2ğœ‹âˆ«
+âˆ
âˆ’âˆ
eâˆ’ğœ…ğœ”2t Ì‚u0(ğœ”)eiğœ”tdğœ”
we see that higher frequencies are quickly damped out as time increases.
When the FTCS method is applied to the heat equation, a sequence of values uj,k
values are obtained, where uj,k â‰ˆu(xj, tk). Applying the inverse transform gives
uj,k =
1
âˆš
2ğœ‹âˆ«
ğœ‹âˆ•h
âˆ’ğœ‹âˆ•h
Ì‚u(ğœ”, tk)eiğœ”xjdğœ”

BIBLIOGRAPHY
239
This can be interpreted as a superposition of waves eiğœ”xj with amplitude Ì‚u(ğœ”, tk).
Hence, the following ansatz for the discretized solution is motivated:
uj,k = qkeiğœ”xj
Inserting this ansatz into the FTCS method gives
qk+1eiğœ”xj = qkeiğœ”xj + qk
ht
h2x
(eiğœ”(xj+hx) âˆ’2eiğœ”xj + eiğœ”(xjâˆ’hx))
qk+1 = qk
(
1 âˆ’2ht
h2
x
(1 + cos(ğœ”hx))
)
The second factor in this relation can be seen as an amplification factor. The qk
sequence is bounded this factor fulfills the inequality
âˆ’1 â‰¤1 âˆ’2ht
h2
x
(1 + cos(ğœ”hx)) â‰¤1
Since âˆ’1 â‰¤cos(ğœ”hx) â‰¤1 this inequality leads to the stability condition
ht
h2
x
â‰¤1
2
This stability analysis is called von Neumann analysis and gives the same result for
the heat equation as the eigenvalue analysis in Chapter 6. This is not true, however,
for hyperbolic PDEs.
BIBLIOGRAPHY
1. L. Trefethen, D. Bau, â€œNumerical Linear Algebra,â€ SIAM, 1997
2. G. Dahlquist, Ã…. BjÃ¶rck, â€œNumerical Methods,â€ Chapter 5, Dover, 2003


APPENDIX B
SOFTWARE FOR SCIENTIFIC
COMPUTING
During the last decades, a lot of software has been developed for modeling and sim-
ulation of processes in science and engineering. The software can roughly be divided
into the following three categories:
1. General programming languages suitable for construction of programs with
optimal performance behavior on various computer architectures, e.g., vector
or parallel architecture. Examples are Fortran90, C, and C++. Many numerical
subroutine libraries written in these languages can be found as public domain
code on the net, e.g., Netlib. There are also several textbooks containing sub-
routines written in Fortran, Pascal, C, C++, Python, etc.
2. Programming languages specially designed for general numerical calculations
and symbolic mathematics. Examples of such tools are MATLABÂ®, Simulink,
Maple, and Mathematica. Within this category can also be placed COMSOL
MULTIPHYSICSÂ®, which is a gui-based (graphicaluser interface) environment
for simulation of processes modeled by partial differential equations (PDEs)
from very many scientific and engineering applications.
3. Toolboxes for various applications often implemented for one specific area, e.g.,
fluid dynamics and designed in a way of communicating indata and outdata that
is familiar for the user in the specific application area.
As was mentioned in the Preface, this textbook is based on a course where the labs
and exercises are solved with MATLAB and COMSOL MULTIPHYSICS. Therefore,
these software products will be given special attention.
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

242
SOFTWARE FOR SCIENTIFIC COMPUTING
B.1
MATLAB
MATLAB is a programming language designed for scientific and engineering
computation. The original MATrix LABoratory was developed by Prof. Cleve Moler
some 30 years ago for interactive computer labs in linear algebra. In the middle of the
1980s, MATLAB became a commercial product manufactured by the US company
MathWorks, founded by Cleve Moler and since then a continued success story,
now having more than 1000 employees. Products from the MATLAB and Simulink
family are spread all over the world, widely used by universities, industries, and
high-tech companies.
One of the strengths of MATLAB is the fact that there is a large subroutine library
with all kinds of high-quality numerical functions that can be used in your own pro-
grams. Another strength is the easy-to-use graphical routines for visualization and
animation in 2D and 3D.
What further makes MATLAB a suitable programming language for scientific
computing is the built-in vector/matrix facilities which make it easy to write com-
pact and efficient programs without for-loops. Indeed, MATLAB is very convenient
for making numerical experiments involving, e.g.,
â€¢ variation of stepsize/grids or tolerance parameters
â€¢ change of methods having different order of accuracy
â€¢ questions regarding numerical stability
â€¢ different algorithms, e.g., direct or iterative methods for solving linear systems
of equations
â€¢ robustness of a method
MATLAB is good for solving moderately sized problems. For large problems
requiring fast number crunching, it is more efficient to use a traditional programming
language such as Fortran90 or C.
We will not give a detailed description of MATLAB in this book, but we show here
some MATLAB codes, which can be used as example programs in the construction
of similar programs. For a detailed description of MATLAB we refer the reader to
some textbooks and manuals accessible on the Internet (see the Bibliography).
The templates presented here show solutions of some model problems taken from
the chapters of this book.
B.1.1
Chapter 3: IVPs
In the MATLAB library, there are several functions solving initial value problems
(IVPs). To mention a few, there are ode23, ode45, and ode113 for nonstiff prob-
lems and ode23s and ode15s for stiff problems.
B.1.1.1
Rungeâ€“Kuttas Fourth-Order Method, Constant Stepsize
The following
program solves Van der Polâ€™s equation:

MATLAB
243
%Program rkstep.m for Runge-Kuttaâ€™s 4th order method
%Model problem is Van der Polâ€™s equation, stored
%in fvdp.m
global epsilon
%parameter used in both script
%and fvdp
epsilon=1;
%parameter in VdPs equation
t0=0;tend=10;
%time interval for the solution
u0=[1 0]â€™;
%initial value
N=100;
%number of steps
h=(tend-t0)/N;
%stepsize
result=[u0â€™];
%collecting solution values
time=[t0];
%collecting time points
u=u0;t=t0;
%initialization of RKâ€™s method
for k=1:N
k1=fvdp(t,u);
k2=fvdp(t+h/2,u+h*k1/2);
k3=fvdp(t+h/2,u+h*k2/2);
k4=fvdp(t+h,u+h*k3);
u=u+h*(k1+2*k2+2*k3+k4)/6;
t=t+h;
result=[result;uâ€™];
time=[time;t];
end
plot(time,result(:,1),â€™oâ€™,time,result(:,2),â€™+â€™)
title(â€™Van der Pols equationâ€™)
xlabel(â€™time tâ€™)
ylabel(â€™u (o) and du/dt (+)â€™)
grid
The function file fvdp.m containing the right hand side of Van der Polâ€™s equation:
%right hand side of Van der Polâ€™s equation
function rhs=fvdp(t,u)
global epsilon
%parameter in VdPs equation
rhs=[u(2);
-epsilon*(u(1)*u(1)-1)*u(2)-u(1)];
B.1.1.2
MATLABâ€™s ODE Function ode45 The same problem solved with one of
MATLABâ€™s ordinary differential equation (ODE) functions using adaptive stepsize
control:
%Program showing the use of Matlabs ode45 function
%Model problem is Van der Polâ€™s equation, stored in
%fvdp.m
global epsilon
epsilon=1;
%parameter in VdPs equation
t0=0;tend=10;
\%time interval for the solution
u0=[1 0]â€™;
\%initial value
[time,result]=ode45(@fvdp,[t0,tend],u0);
plot(time,result(:,1),â€™oâ€™,time,result(:,2),â€™+â€™)
title(â€™Van der Pols equationâ€™)
xlabel(â€™time tâ€™)
ylabel(â€™u (o) and du/dt (+)â€™)
grid

244
SOFTWARE FOR SCIENTIFIC COMPUTING
B.1.1.3
Change of Tolerance Parameters When the default tolerance in a
MATLAB ODE function is not enough, the relative and absolute tolerance can be
changed from the preset values 10âˆ’3 and 10âˆ’6, respectively,
%Example 1.2 in chapter 1. The vibration equation
%demo of tolerance parameter settings
global m c k f0 w
m=1;c=10;k=1e3;f0=1e-4;w=40;
t0=0;tend=5;
u0=[0 0]â€™;
[time,result]=ode45(@fvib,[t0,tend],u0);
%not enough accuracy
options=odeset(â€™RelTolâ€™,1e-6,â€™AbsTolâ€™,1e-9);
%set tolerances
[t,res]=ode45(@fvib,[t0,tend],u0,options);
%accurate solution
plot(time,result(:,1),â€™.â€™,t,res(:,1))
title(â€™Accurate and bad solution of the vibration
equuationâ€™)
xlabel(â€™time tâ€™)
ylabel(â€™vibration y(t)â€™)
The corresponding right hand side function:
%Right hand side of vibration equation in chapter 1
function rhs=fvib(t,u)
global m c k f0 w
rhs=[u(2);
-(c/m)*u(2)-(k/m)*u(1)+(f0/m)*sin(w*t)];
B.1.2
Chapter 4: BVPs
Solution of the model problem in Example 4.8:
%Solution of the model problem BVP with FDM,
%constant stepsize h
%-u"=f(x), u(0)=u(1)=0, f(x)=sin(pi*x)
a=0;b=1;
%interval bounds
N=63;
%N+1=number of steps
h=(b-a)/(N+1);
%stepsize
xp=a:h:b;
%DG, discretize interval to grid
x=a+h:h:b-h;
%inner points generated
f=h*h*[sin(pi*x)]â€™;
%right hand side generated
A=zeros(N,N);
%start generation of the full
%matrix A
for i=1:N-1
A(i,i)=2;
A(i,i+1)=-1;
A(i+1,i)=-1;
end
A(N,N)=2;
%full matrix A generated
u=A\f;
%solution of linear system of
%equations

MATLAB
245
up=[0,uâ€™,0];
%add the BCs to the solution
%vector
plot(xp,up)
title(â€™Solution of -u"=sin(\pi *x), u(0)=u(1)=0â€™)
xlabel(â€™xâ€™)
ylabel(â€™uâ€™)
grid
Example of a sparse version of the A matrix generation:
e=ones(N,1);
a=spdiags([-e 2*e -e],-1:1,N,N);
%sparse storage of A
u=a\f;
%sparse solution of Au=f
B.1.3
Chapter 6: Parabolic PDEs
Solution of the parabolic model problem with the MoL:
%Solution of u_t=u_xx, u(x,0)=sin(pi*x),
%u(0,t)=u(1,t)=0
%using the MoL. Discretized system stored in fpar.m
global N hx
%discretization parameters
N=10
%number of inner x-points
hx=1/(N+1);
%stepsize in x-direction
x=hx:hx:1-hx;
%inner points
u0=[sin(pi*x)]â€™; %initial values
t0=0;tend=0.25;
%time interval
[time,result]=ode23s(@fpar,[t0,tend],u0);
%stiff ode-solver
resultp=[zeros(size(time)) result zeros(size(time))]
%add BCs
xp=0:hx:1;
%add boundary points
mesh(xp,time,resultp)
title(â€™Solution of u_t=u_xx, u(x,0)=sin(\pi *x), ...
u(0,t)=u(1,t)=0 using MoLâ€™)
xlabel(â€™space variable xâ€™)
ylabel(â€™time variable tâ€™)
zlabel(â€™solution variable u(x,t)â€™)
The MoL discretized PDE is stored in the MATLAB function file fpar.m:
%Right hand side of the MoL discretized model
%problem
function rhs=fpar(t,u);
global N hx
%discretization parameters
rhs=zeros(N,1);
rhs(1)=(-2*u(1)+u(2))/(hx*hx);
rhs(2:N-1)=(u(1:N-2)-2*u(2:N-1)+u(3:N))/(hx*hx);
rhs(N)=(u(N-1)-2*u(N))/(hx*hx);

246
SOFTWARE FOR SCIENTIFIC COMPUTING
B.1.4
Chapter 7: Elliptic PDEs
Solution of the elliptic model problem with the finite difference method (FDM):
%Numerical solution of the elliptic PDE Laplace u=1
%on the quadrangle Omega={(x,y),0<=x<=1,0<=y<=1}
%BC is u=0 on the boundary of Omega
N=100;
%number of inner x and
%y-points
hx=1/(N+1); hy=1/(N+1); %stepsize in x- and
%y-direction
x=0:hx:1; y=0:hy:1;
%gridpoints
d=4*ones(N*N,1);
%main diagonal of A
d_1=-ones(N*N,1);
d1=-ones(N*N,1);
for i=N:N:N*N-1
%sub- and superdiagonals
d_1(i)=0;
d1(i+1)=0;
end
d_2=-ones(N*N,1);
%subdiagonal from unit matrix
d2=-ones(N*N,1);
%superdiagonal
a=spdiags([d_2 d_1 d d1 d2],[-N,-1:1,N],N*N,N*N);
%sparse matrix A generated
f=ones(N*N,1);
%right hand side
uinner=a\f;
%solution at inner points
Uinner=zeros(N,N);
for i=1:N
%inner solution as a matrix
Uinner(i,1:N)=uinner((i-1)*N+[1:N]);
end
U=zeros(N+2,N+2);
%add BCs to inner solution
for i=1:N
U(i+1,2:N+1)=Uinner(i,1:N);
end
mesh(x,y,U)
%3D plot of the solution
title(â€™Solution of \Laplace u = 1 on the unit
squareâ€™) ...
xlabel(â€™xâ€™)
ylabel(â€™yâ€™)
zlabel(â€™u(x,y)â€™)
B.1.5
Chapter 8: Hyperbolic PDEs
Solution of the hyperbolic PDE model problem:
%Solution of the hyperbolic model problem
%u_t+u_x=0, u(x,0)=0, 0<x<=1, u(0,t)=1, t>=0
%Upwind method is used
clear,clf,hold off
%clear variables and graph
N=100;
%number of gridpoints
hx=1/N;
%stepsize in x-direction
x=hx:hx:1;
%x-grid, inner points
xp=[0 x];
%x-grid plus boundary point
ht=0.01;
%timestep, try also 0.008 and 0.011

COMSOL MULTIPHYSICS
247
sigma=ht/hx;
%Courant number
u0=zeros(N,1);
%IV at inner points
up=[1;u0];
%IV+BV
plot(xp,up)
title(â€™Initial state for the advection equationâ€™)
xlabel(â€™xâ€™)
ylabel(â€™u(x,t)â€™)
u(1:N,1)=u0;
%initialization of upwind
for k=1:100
%take 100 timesteps with upwind
u(1,k+1)=(1-sigma)*u(1,k)+sigma*1;%*1 is *BC
u(2:N,k+1)=(1-sigma)*u(2:N,k)+sigma*u(1:N-1,k);
up=[1;u(:,k+1)];
plot(xp,up) %plot the front for each timestep
hold on
%keep the previous plots
pause(0.1)
end
B.2
COMSOL MULTIPHYSICS
While MATLAB is good for numerical computation of moderately sized problems,
COMSOL MULTIPHYSICS is designed for model experimentation of problems
from various applications. Its development started some twenty years ago by a
Swedish provider company called COMSOLÂ®. COMSOL was founded by Dr. H.C.
Svante Littmarck and Farhad Saeidi and is another example of a success story within
scientific computing. COMSOL has now around 420 employees and branch offices
in several countries, including the United States.
COMSOL MULTIPHYSICS is an interactive program for simulation of
time-dependent or stationary scientific/engineering PDE models in 1D, 2D, or 3D.
The user and the program communicates with the help of a graphical user interface
(gui), which provides advanced tools for geometric modeling. The models are based
on three forms of PDEs, the coefficient form (for linear or quasi-linear PDEs), the
general form (for nonlinear PDEs)
eğœ•2u
ğœ•t2 + d ğœ•u
ğœ•t + âˆ‡â‹…(âˆ’câˆ‡u âˆ’ğ›¼u + ğ›¾) + ğ›½â‹…âˆ‡u + au = f
and
d ğœ•u
ğœ•t + âˆ‡â‹…Î“ = F
and the weak form (see section 7.4.2). Simulations can be done in one single appli-
cation, e.g., heat transfer, and also in coupled models where several applications are
mixed in an almost arbitrary way, e.g., heat conduction and electrical current strength.
There are several physics interfaces that can be studied alone or in combination with
others, e.g.,
â€¢ equation-base modeling
â€¢ chemical engineering

248
SOFTWARE FOR SCIENTIFIC COMPUTING
Max: 500
Min: 299.681
300
320
340
360
380
400
420
440
460
480
500
1
0.8
0.6
0.4
0.2
0
âˆ’0.2
âˆ’0.4
âˆ’0.6
âˆ’0.8
âˆ’1.2
âˆ’0.8
âˆ’0.4
Time = 1 Surface: u
0
0.4
0.8
Figure B.1
Solution of heat conduction problem with COMSOL Multiphysics
â€¢ electromagnetics
â€¢ heat transfer
â€¢ structural mechanics
â€¢ acoustics
The solution process of a problem proceeds in short in the following way:
1. choose application mode and space dimensionality 1D, 2D, or 3D
2. generate the geometry
3. enter global parameter values and initial values
4. give the parameters of the PDE
5. give the boundary conditions
6. generate the grid
7. compute and solve
8. inspect the solution with the postprocessing facilities
After having completed the steps (1) â€“ (8), you can go back to any step earlier to
modify the model see Figure B.1 for a heat conduction simulation.
The underlying numerical method is based on the finite element method. For
time-dependent problems, finite element method (FEM) is combined with a stiff
ODE solver. The discretization is done with a grid generator that automatically
produces a grid whose appearance depends on the geometry of the problem. By
option, the grid can also be generated adaptively depending on the solution.
For more examples, see Ref. 1 and the webpage of this textbook http://www.csc.
kth.se/âˆ¼edsberg.

BIBLIOGRAPHY AND RESOURCES
249
BIBLIOGRAPHY AND RESOURCES
1. COMSOL MULTIPHYSICSÂ®, http://www.comsol.com
2. Introduction to Matlab, http//www.maths.dundee.ac.uk/ ftp/na-reports/MatlabNotes.pdf
3. Matlab, http://www.mathworks.com
4. D. J. Higham and N. J. Higham, Matlab Guide, 2000, SIAM
5. Netlib, http://www.netlib.org/
6. Numerical Recipes, W. Press, B. Flannery, S. Teukolsky, W. Vetterling, Cambridge
University Press, 1986


APPENDIX C
COMPUTER EXERCISES TO SUPPORT
THE CHAPTERS
C.1
COMPUTER LAB 1 SUPPORTING CHAPTER 2
C.1.1
ODE Systems of LCC Type and Stability
In this exercise, the following problems are treated:
â€¢ linear ordinary differential equation (ODE) systems with constant coefficients
(LCC systems)
â€¢ stability of trajectories and critical points
LCC systems can be solved analytically (see Chapter 2). Hence, no numerical method
is needed, so the problem class is suitable for a refresher in MATLAB programming.
We start by illustrating a MATLAB program for solution of an LCC problem.
Given the following second-order differential equation:
d2y
dt2 + 2dy
dt + 5y = 0,
y(0) = 0, dy
dt (0) = 1
compute the solution of this ODE problem on a suitable t interval. First rewrite this
scalar problem to the standard form, i.e., as a system of first-order ODEs. This ODE
system is of LCC type
du
dt = Au,
u(0) = u0
which is solved analytically with the expm-function. Input data to the MATLAB
program consists of the matrix A, the initial vector u(0), and grid point data h and
N for the points ti = ih, i = 0, 1, 2, â€¦ , N, where the solution shall be computed
and plotted. The output from the program is the graph of the solution at these grid
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.

252
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
points.In the MATLAB programbelow,the solutionu(t) is stored in a resulting matrix
result of size (N + 1) Ã— 2. Each row in result corresponds to the solution vector
at a grid point ti. The first row is the initial vector u(0)
A=[0 1;-5 -2];
u0=[0 1]â€™;t0=0;
h=0.1;N=60;
result=[u0â€™];time=[t0];
for k=1:N
t=k*h;
u=expm(A*t)*u0;
result=[result; uâ€™];
time=[time; t];
end
plot(time,result)
This MATLAB program plots two curves. The first column in the result-matrix
corresponds to the solution y(t), while the second column corresponds to the deriva-
tive of the solution z(t) = dy
dt (t). The initial values of y and z are different in this case
so it is easy to see which curve corresponds to which variable. Otherwise you can use
different plot symbols for different curves.
Observe that the time step h must be chosen with some care if the plotted curve
is to be smooth. When h = 0.1 is used as stepsize, the resulting curve is smooth, but
with h = 1, however, the line segments building up the curves are clearly seen and
the curve gets rough.
With too small time steps, on the other hand, say h = 0.001, the computation of the
result-matrix will take an unreasonably long time. Hence, it is advisable to work
out the grid point spacing interactively. For other problems, it may also be better to
use loglog, semilogx, or semilogy instead of plot to display the important
qualitative features of solution curves.
C.1.1.1
Solution of ODE Systems with Constant Coefficients
C.1.1.1.1
Electric Circuit. Given the following simple electric circuit with a volt-
age source of size E, a resistance R, an inductance L, and a capacitance C. The
components are coupled in series (see Figure C.1). Assume that the circuit is first
at rest. The switch is activated at t = 0 and a current i starts to go through the circuit.
Introduce the variable q defined by the relation Ì‡q = i, and the following differential
equation can be set up:
LÌˆq + R Ì‡q + 1
Cq = E,
q(0) = 0,
Ì‡q(0) = 0
Rewrite this scalar ODE as a system of first-order ODEs and then write a MATLAB
programto solve the problem for the following parameter values: E = 10, L = C = 0.1,
R = 0.01, 0.1, 1, 10. Observe that this ODE system is inhomogeneous.

COMPUTER LAB 1 SUPPORTING CHAPTER 2
253
R
L
C
E
Figure C.1
Simple electric circuit
Plot the solutions i(t) on suitable time intervals and with suitable time steps. Use
the subplot-command to obtain the four graphs in the same figure.
C.1.1.2
Stability of ODE Systems and Equilibrium Points
C.1.1.2.1
Stability of the Solutions of an ODE System of LCC Type. In many tech-
nical applications where a differential equation is used to model a dynamic process,
it is important to see how the solution curves change as a parameter in the model is
changed. For a control system, it is of great interest to investigate how the stability
properties change as a parameter is changed continuously.
Given the following third-order differential equation:
d3y
dt3 + 3d2y
dt2 + 2dy
dt + Ky = 0,
y(0) = 1, dy
dt (0) = 1, d2y
dt2 (0) = 1
Investigate how the solution y(t) behaves for values K â‰¥0.
Rewrite this third-order ODE as a system of first-order ODEs. We then obtain a
system
du
dt = A(K)u,
u(0) = (1, 1, 1)T
Write a MATLAB program showing the solutions y(t) for K = 0, 1, 4, 8. Use sub-
plot to plot the four graphs in the same figure. Estimate from these plots an approx-
imate value of K for which the solution becomes unstable.
The stability properties can also be shown in a so-called root locus, often used in
control theory to visualize the stability properties for a regulator modeled by an ODE
of LCC type. A root locus is a graph showing the paths of the eigenvalues in the com-
plex plane as a parameter varies. Assume that all eigenvaluesstart in the left half plane
for say K = 0, where we have a stable system. When K then increases, the eigenvalues
will follow continuous paths and for a certain value of K a few eigenvalues eventually
enter the right half plane and the system becomes unstable.
Write a MATLAB program that plots the root locus when 0 â‰¤K â‰¤10. Compute
with two decimal accuracy the smallest value of K that gives an unstable system.

254
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
C.1.1.2.2
Stability of the Critical Points of a Nonlinear ODE System. Given the
following system of nonlinear ordinary differential equations:
du1
dt = 5u1 + 4u2 âˆ’u1 u3
du2
dt = u1 + 4u2 âˆ’u2 u3
du3
dt = u2
1 + u2
2 âˆ’89
Write a MATLAB program where all critical points of the ODE system are computed.
Also compute which of these critical points are stable.
Hint: use Newtonâ€™s method to compute the critical points with at least five signif-
icant digits. There are four critical points and they are situated in the neighborhood
of the following points in R3: (8, âˆ’5, 2), ( âˆ’8, 5, 2), (9, 3, 7), and ( âˆ’9, âˆ’3, 7).
C.2
COMPUTER LAB 2 SUPPORTING CHAPTER 3
C.2.1
Numerical Solution of Initial Value Problems
In this lab, initial value problems (IVPs) are solved numerically and the following
items are studied:
â€¢ accuracy and stability
â€¢ constant stepsize and adaptive (variable) stepsize
â€¢ stiff and nonstiff problems
â€¢ parameter study of the solutions of a system of ODEs
C.2.1.1
Accuracy of a Rungeâ€“Kutta Method In Chapter 3, different Rungeâ€“Kutta
methods are presented. Make a numerical experiment to find the order of accuracy of
the following RK method:
uk = ukâˆ’1 + h
6(K1 + K2 + 4K3),
tk = tkâˆ’1 + h,
k = 1, 2, â€¦ , N
K1 = f(tkâˆ’1, ukâˆ’1)
K2 = f(tkâˆ’1 + h, ukâˆ’1 + hK1)
K3 = f(tkâˆ’1 + hâˆ•2, ukâˆ’1 + hK1âˆ•4 + hK2âˆ•4)
Implement the method on Van der Polâ€™s differential equation
d2y
dt2 + (y2 âˆ’1)dy
dt + y = 0,
y(0) = 1, dy
dt (0) = 0,
ğœ–= 1,
t âˆˆ[0, 1]
Run the problem with constant stepsizes using N = 10, 20, 40, 80, 160, and
320 steps in the t interval [0, 1]. Estimate the error at t = 1 by computation of

COMPUTER LAB 2 SUPPORTING CHAPTER 3
255
eN = yN âˆ’y(1),N = 10, 20, 40, 80, 160. Since y(1) is not known exactly, use the
approximation y(1) â‰ˆyNmax, where Nmax = 320. Make a loglog-plot of |eN| as a
function of h and estimate the order of accuracy from the graph.
Hint 1: Treat the problem as a system on vector form, both when you rewrite the
second-order differential equation to a system of two first-order ODEs and when you
program the method.
Hint 2: Be careful to take the correct number of steps to reach t = 1. If you get the
answer order = 1, there is some mistake in your MATLAB code!
C.2.1.2
Stability Investigation of a Rungeâ€“Kutta Method The stability of a
numerical method for IVPs is important when we want to solve stiff problems. The
following ODE system modeling the kinetics of a set of three reactions, known as
Robertsonâ€™s problem, is studied here:
A â†’B
(k1)
B + C â†’A + C
(k2)
2B â†’B + C
(k3)
In the reactions above k1, k2, and k3 denote the rate constants of the three reactions.
The following set of ODEs describe the evolution of (scaled) concentrations of A, B,
and C as a function of time t:
dx1
dt = âˆ’k1 x1 + k2 x2 x3,
x1(0) = 1
dx2
dt = k1 x1 âˆ’k2 x2 x3 âˆ’k3 x2
2,
x2(0) = 0
dx3
dt = k3 x2
2,
x3(0) = 0
The rate constants have the values: k1 = 0.04, k2 = 104, k3 = 3 â‹…107.
C.2.1.2.1
Constant Stepsize Experiment. If Robertsonâ€™s problem is solved with
an explicit method, the stepsize has to be very small to avoid numerical instability.
Use the Rungeâ€“Kutta method given on Robertsonâ€™s problem when the t interval is
[0, 1]. Run the problem with constant stepsizes corresponding to N = 125, 250, 500,
1000, 2000 steps and find the smallest number of steps (from the 5 given) needed
to obtain a stable solution. Plot the solution trajectory in a loglog-diagram for the
solution computed with the smallest step.
C.2.1.2.2
AdaptiveStepsize Experiment Using MATLAB Functions. There are sev-
eral IVP solvers in MATLAB. Use the command Â»help funfun to see which are
available. To get more information about one of them, say ode23, give the command
Â»help ode23. In order to control, e.g., accuracy parameters you also need to read
about the function odeset. When the problem is stiff, you need a stiff IVP solver,
e.g., ode23s.
There are several ways to find demo examples in Matlab. If you give the command
Â»demo and follow the path MATLAB, Numerics, Differential Equations, you find a

256
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
number of examples to look at, e.g., vdpode and rigidode. You can run the demo
programs and see the graphical output and you can also see the MATLAB code.
Make the following numerical experiments on Robertsonâ€™s problem:
â€¢ Use the nonstiff IVP solver ode23 on the t interval [0, 1] for different relative
tolerances: RelTol = 10âˆ’3, 10âˆ’4, 10âˆ’5, 10âˆ’6 and record the number of steps
taken by ode23. Make a graph of the stepsize h as function of t for one of the
tolerances.
â€¢ Run the stiff IVP solver ode23s on the t interval [0, 1000] for the same relative
tolerances as above and record the number of steps taken by ode23s. Make a
graph of the stepsize h as function of t for one of the tolerances.
C.2.1.3
Parameter Study of Solutions of an ODE System Make a parameterstudy
for the following problems taken from applications. Choose a method (order of accu-
racy must be at least two) yourself. Present the result graphically in a suitable way.
Think about the following possibilities and choose what you think is best:
â€¢ one or several graphs (using subplot) in the figure window?
â€¢ linear or logarithmic scales?
â€¢ in the graphs: title, x-label, y-label
C.2.1.3.1
Problem 1: Particle Flow Past a Cylinder. A long cylinder with radius
R = 2 is placed in an incompressible fluid streaming in the direction of the positive
x-axis. The axis of the cylinder is perpendicular to the direction of the flow. The
position (x(t), y(t)) of a flow particle at time t is determined by the start position (x(0),
y(0)) and the ODE system:
dx
dt = 1 âˆ’R2(x2 âˆ’y2)
(x2 + y2)2 ,
dy
dt = âˆ’
2xyR2
(x2 + y2)2
At t = 0, there are four flow particles at x = âˆ’4 with the y-positions 0.2, 0.6, 1.0, and
1.6. Compute and make a graph of the flow curves of the particles in the t interval
[0, 10]. Use axis equal in the graph!
C.2.1.3.2
Problem 2: Motion of a Particle. A particle is thrown from the position
(0, 1.5) with an elevation angle ğ›¼and the velocity v0 = 20. The trajectory of the
particle depends on ğ›¼, the air resistance coefficient k, and the ODE system
d2x
dt2 = âˆ’kdx
dt
âˆš
(dx
dt
)2
+
(dy
dt
)2
,
x(0) = 0,
dx
dt (0) = 20 cos(ğ›¼)
d2y
dt2 = âˆ’9.81 âˆ’k
||||
dy
dt
||||
âˆš
(dx
dt
)2
+
(dy
dt
)2
,
y(0) = 1.5,
dy
dt (0) = 20 sin(ğ›¼)

COMPUTER LAB 3 SUPPORTING CHAPTER 4
257
For two different values of k, say k = 0.020 and 0.065, the solution trajectories for
ğ›¼= 30âˆ˜, 45âˆ˜, and 60âˆ˜. For the graphical presentation, observe that the model is valid
only until the particle touches the ground, i.e., it is valid only while y â‰¥0. The graph
should show the motion in a xy-coordinate system with t as a parameter.
C.3
COMPUTER LAB 3 SUPPORTING CHAPTER 4
C.3.1
Numerical Solution of a Boundary Value Problem
Consider a long pipe of length L with small cylindrical cross section (Figure C.2). In
the pipe, there is a fluid heated by an electric coil. The heat is spreading along the pipe
and the temperature T(z) at steady state is determined by the diffusionâ€“convection
ODE
âˆ’d
dz
(
ğœ…dT
dz
)
+ vğœŒCdT
dz = Q(z)
(âˆ—)
where all parameters are constant: ğœ…is the heat conduction coefficient, v the fluid
velocity in the z direction through the pipe, ğœŒthe fluid density, and C the heat capacity
of the fluid. The driving function Q(z), modeling the electric coil, is defined as
Q(z) =
â§
âª
â¨
âªâ©
0
if 0 â‰¤z â‰¤a
Q0 â‹…sin
(
zâˆ’a
zâˆ’bğœ‹
)
if a â‰¤z â‰¤b
0
if b â‰¤z â‰¤L
(C.1)
At z = 0, the fluid has the inlet temperature T0
T(0) = T0
At z = L, heat is leaking out to the exterior, having temperature Tout. This assumption
gives the following boundary condition (BC):
âˆ’ğœ…dT
dz (L) = k(T(L) âˆ’Tout)
where k is a constant heat convection coefficient.
Discretize this boundary value problem (BVP) with the finite difference (FD)
method using constant stepsize and write a Matlab program that solves the problem.
Use the following values of the parameters in the problem: L = 10, a = 1, b = 3,
Q0 = 50, ğœ…= 0.5, k = 10, ğœŒ= 1, C = 1, Tout = 300, T0 = 400, and v = 0, 0.1, 0.5, 1,
10. The case v = 0 corresponds to no convection, only diffusion.
0
a
b
L
z
Ï…
T (z)
Figure C.2
Pipe with fluid heated by an electric coil

258
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
Discretize the z interval [0, L] with constant stepsize and use a node-numbering
where z0 = 0 and zN = L.
Discretize the ODE and the BCs. A sparse system of linear equations is obtained.
Plot of the solution T(z) for v = 0, N = 10, 20, 40, 80 in the same graph. Note the
convergence of the curves in the graph.
N = 40 gives a solution that is accurate enough for our purposes. Use this dis-
cretization to solve the problem for v = 0.1, 0.5, 1, 10 in the same graph. When v = 10,
spurious oscillations occur! Make another plot when v = 10, showing the solution for
N = 10, 20, 40 in the same graph. The oscillations become more pronounced when
h is increasing. We have a spurious oscillation problem! How do we get rid of these
oscillations?
C.4
COMPUTER LAB 4 SUPPORTING CHAPTER 6
C.4.1
Partial Differential Equation of Parabolic Type
A metallic rod of length L (m) is initially of temperature T = 0 (C). At time t = 0,
a heat pulse of temperature T = T0 and duration tP (s) hits the left end (at x = 0) of
the rod. At the right end (at x = L), the rod is isolated. After some time, the rod will
therefore be warmer in the right end and then cool off again. The following partial
differential equation can be set up for the heat diffusion process through the rod:
ğœŒCp
ğœ•T
ğœ•t = kğœ•2T
ğœ•x2 ,
t > 0,
0 < X < L,
The BCs are
T(0, t) =
{
T0 if 0 â‰¤t â‰¤tP
0
if t > tP
,
ğœ•T
ğœ•x (L, t) = 0
(C.2)
and the initial condition (IC) is
T(x, 0) =
{
T0
if
x = 0
0
if
0 < x â‰¤L
(C.3)
In the partial differentialequation (PDE), ğœŒis the density [kg/m3], CP the heat capacity
[J/(kgâ‹…C)], and k the thermal conductivity [J/(mâ‹…sâ‹…C)] of the rod.
The purpose of this lab is to
â€¢ scale the problem to dimensionless form
â€¢ discretize the scaled problem with the Method of Lines (MoL)
â€¢ investigate stability properties of Eulerâ€™s explicit method
â€¢ comparison between an explicit and an implicit adaptive method
â€¢ show how an implicit method can be made more efficient
â€¢ visualize the result in a two- and three-dimensional plot

COMPUTER LAB 4 SUPPORTING CHAPTER 6
259
1. Show that with the new variables u, ğœ‰, and ğœdefined by
T = T0u,
x = Lğœ‰,
t = tPğœ
the problemcan be transformed (scaled) into the following dimensionlessform:
ğœ•u
ğœ•ğœ= ağœ•2u
ğœ•ğœ‰2 ,
ğœ> 0,
0 < ğœ‰< 1
with BCs
u(0, ğœ) =
{1 if 0 â‰¤ğœâ‰¤1
0 if ğœ> 1
,
ğœ•u
ğœ•ğœ‰(1, ğœ) = 0
(C.4)
and IC
u(ğœ‰, 0) =
{
1 if ğœ‰= 0
0 if 0 < ğœ‰â‰¤1
(C.5)
Show that the only remaining parameter a is dimensionless. From now on
assume that a has the numerical value a = 1.
2. Discretize in space (the ğœ‰-variable) using constant stepsize h and central differ-
ences to obtain an ODE system
du
dğœ= Au + b(ğœ),
u(0) = u0,
where u0 is the zero vector. Show the dimensions and structures of A, b(ğœ), and
u0. Show also the discretized grid of the ğœ‰-axis you have used and how the grid
points are numbered.
3. Numerical part: Discretize the ODE system in (2) with Eulerâ€™s explicit method.
Use constant time step Î”t. To make your calculations efficient, you should write
your code so that the vector Au + b is formed directly, not from component
form. Store the whole approximate solution (including ICs and BCs) in a large
matrix U, as
U =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
âœâ
0
x
x
x
â€¦
x
0
x
x
x
â€¦
x
0
x
x
x
â€¦
x
.
.
.
.
â€¦
x
.
.
.
.
â€¦
x
.
.
.
.
â€¦
x
0
x
x
x
â€¦
x
1
1
1
1
â€¦
0
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸâ 
Graphical part: Use, e.g., surf to draw a 3D plot of the solution. Experiment
with different values of the discretization step h and Î”t and study stability.
Make one graph showing a stable solution and one graph with an unstable
solution. Present the values of h, Î”t, and Î”t/h2 in the two cases.

260
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
4. In this part of the lab, you shall compare the explicit method in ode23 and the
implicit method in ode23s, suitable for stiff problems, in the Matlab library.
The two functions shall be run under similar conditions (same problem, same
tolerance) and for three values of the stepsize h corresponding to N = 10, 20,
40 grid points on the ğœ‰-axis.
The comparison shall comprise
a) the number of time steps needed to reach ğœ= 2
b) the cpu time needed to do each computation
c) the maximal time step that each method could take
Collect your statistics in three tables:
Time Steps
CPU âˆ’Time
Î” tmax
N
ode23
ode23s
ode23
ode23s
ode23
ode23s
10
20
40
5. The conclusion from (4) is that the number of time steps is considerably smaller
when using a stiff method. However, the default implementation is not efficient
for stiff problems coming from parabolic PDEs. The main reason is that all the
linear systems of equations Ax = b that are to be solved in each time step need
a lot of number crunching since they are based on using the backslash opera-
tor, i.e., Gaussian elimination on a full matrix is performed each time Ax = b
is solved. However, the system matrix of these equations is tridiagonal, which
is not considered in the default implementation of ode23s. With the Matlab
function odeset, options can be set by the user in order to make the computa-
tion more efficient. Do help odeset and study the options for â€œJacobian,â€
and â€œJpattern.â€ Also do help odefile and look at the example. With the
help of these options, the number of flops can be reduced considerably. Exper-
iment with these three options and collect statistics regarding the cpu time as
was done in (4).
6. Visualize the result of a successful computation from (3) in graphs. One graph
shall show two-dimensionalplots of u(ğœ, ğœ‰) 0 â‰¤ğœ‰â‰¤1 at fourtime points ğœâ‰ˆ0.5,
1, 1.5, 2. Another graph shall show a three-dimensional plot of u as function of
ğœand ğœ‰.
Conclude your results by answering the following questions. If we want
efficient numerical calculations for parabolic problems:
1. What type of ODE method should be used, stiff or nonstiff?
2. What structure does the jacobian of the ODE system have, banded or sparse
in another way?
3. What type of linear equation solver should be used in the implicit ODE
method, solver for full matrices or for sparse matrices?

COMPUTER LAB 5 SUPPORTING CHAPTER 7
261
C.5
COMPUTER LAB 5 SUPPORTING CHAPTER 7
C.5.1
Numerical Solution of Elliptic PDE Problems
This lab is an exercise in solving an elliptic PDE, the applicational background of
which is stationary heat conduction in 2D.
The physical background is as follows: Heat is conducted through a rectangular
metal block,being the region Î© = [0 â‰¤x â‰¤4, 0 â‰¤y â‰¤2] when placed in a xy-coordinate
system (see Figure C.3). Depending on the BCs, the temperature distribution T(x, y)
in the block will be different.
The following elliptic problem is formulated:
T = 0,
(x, y) âˆˆÎ©
T(0, y) = 300,
T(4, y) = 600,
0 â‰¤y â‰¤2
ğœ•T
ğœ•y (x, 0) = 0, ğœ•T
ğœ•y (x, 2) = 0,
0 â‰¤x â‰¤4
1. Solve the elliptic partial differential equation problem. Use the finite difference
method as described in Chapter 7. Discretize the rectangular domain into a
quadratic mesh with the following two step sizes: h = 0.2, i.e., N = 19, M = 11,
and h = 0.1, i.e., N = 39, M = 21 (see Figure C.4). Solve the problem for these
two stepsizes and visualize the solution T(x, y) with colors, using the MATLAB
function imagesc. What is the T value at (2, 1) for the two stepsizes? Derive
the analytic solution. Why is the numerical solution almost exact. Hint: From
the graph of T(x, y) make a suitable ansatz of the analytic solution and prove
that it satisfies the PDE and the BCs.
2. Solve the same problem with COMSOL MULTIPHYSICSÂ®. General recom-
mendation: if the session turns out to be too messy, start the session again.
Check your numerical result from (1): what is the T value at the point (2, 1)?
How many nodes and triangles have been generated in the mesh? Make a refine-
ment of the grid and find again T(2, 1). How many nodes and triangles are there
now? Make the whole session again: draw geometry, impose boundary values,
set the PDE values, initialize the mesh, solve the problem, and plot a 2D graph
of the solution.
0
2
4
x
0
1
2
y
âˆ‚n(x, y) = 0
T (x, y) = 600
T (x, y) = 300
âˆ‚T
Î©
Figure C.3
Region and boundaries for a rectangular heat problem

262
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
x1
x2
xN
x
y1
y2
yM
y
Figure C.4
Discretization of the rectangular region
T (x, y) = 600
T (x, y) = 300
âˆ‚n(x, y) = 0
âˆ‚T
0
1
2
x
0
1
2
y
Î©
Figure C.5
Region and boundary conditions for the L-shaped area
3. Go back to COMSOL MULTIPHYSICS and generate the following L-shaped
area with the Geometry builder. Impose the BCs. In Figure C.5, the walls are
heat insulated, i.e., the normal derivative is equal to zero along these bound-
aries. Set the PDE parameters and initialize the mesh. How many nodes and
triangles are generated? Solve the problem. What is the value of T in the points
(1, 1) and (2, 2)? Refine the mesh and solve again. How many nodes and trian-
gles? What is T(1, 1) and T(2, 2)?
Initialize the mesh again and then refine the mesh only in the area around the
point (2, 2). What is T(1, 1) and T(2, 2)?

COMPUTER LAB 6 SUPPORTING CHAPTER 8
263
C.6
COMPUTER LAB 6 SUPPORTING CHAPTER 8
C.6.1
Numerical Experiments with the Hyperbolic Model PDE Problem
Given the model problem for a hyperbolic PDE
ğœ•u
ğœ•t + ağœ•u
ğœ•x = 0,
a > 0,
0 < x < 2,
t > 0
with IC u(x, 0) = 0,
0 < x â‰¤2. As for the BC at x = 0, assume a square wave is
entering from the left, i.e.,
u(0, t) =
â§
âª
â¨
âªâ©
1,
âˆ’(n + 1) T
2 < t â‰¤âˆ’n T
2,
n = 0, 2, 4, â€¦
âˆ’1,
âˆ’(n + 1) T
2 < t â‰¤âˆ’n T
2 ,
n = 1, 3, 5, â€¦
where T is the period time.
Make a numerical experiment showing how the (i) upwind, (ii) Laxâ€“Friedrich,
and (iii) Laxâ€“Wendroff methods behave on this PDE problem. Discretize the x inter-
val into N equidistant subintervals and define grid points xi = ihx, i = 0, 1, 2, â€¦ , N,
where hx = 2âˆ•N. The Courant number ğœis ğœ= ahtâˆ•hx.
1. Write programs and run the three methods on the time interval (0, 2T). Let
N = 100, T = 1, and a = 1. Present the results in graphs with u(x, 2T) as a
function of x. Show graphs for the ğœvalues: ğœ= 0.8, 1, and 1.1. In all, there
are nine graphs to be presented. Are your experimental results in agreement
with the theoretical stability results? Which methods will smooth the solution
and which will introduce spurious oscillations?
2. In this part, the exchanger in Example 8.1 is studied. A fluid of temperature
T(x, t) is flowing with constant speed v in a pipe. Outside the pipe, there is a
cooling medium that keeps a constant low temperature Tcool. The temperature
of the fluid in the pipe is initially cool, i.e., T = Tcool but within a short time
period hot fluid enters the pipe. The task is to study how the temperature T(x, t)
of the fluid in the pipe depends on x and t.
The following PDE model is given:
ğœ•T
ğœ•t + vğœ•T
ğœ•x + a(T âˆ’Tcool) = 0,
0 < x < L,
t > 0
with the IC
T(x, 0) = Tcool

264
COMPUTER EXERCISES TO SUPPORT THE CHAPTERS
and the BC
T(0, t) =
â§
âª
â¨
âªâ©
Tcool + (Thot âˆ’Tcool
) sin(ğœ‹t)
0 â‰¤t â‰¤0.5
Thot
0.5 â‰¤t â‰¤4
Thot + Tcoolsin(ğœ‹(t âˆ’4))
t > 4
The length of the heat exchanger is L = 3. The heat exchange parameter a = 0.1, the
velocity of the fluid v = 1, the cooling temperature Tcool = 5, and the hot temperature
Thot = 100.
a) Use the upwind method to simulate the temperaturein the pipe. Choose suitable
stepsizes hx and ht and present the result in a 3D graph.
b) Work out a difference formula of Laxâ€“Wendroff type that solves the PDE prob-
lem in (2). Present the result as a difference formula of the type
ui,k+1 = c1uiâˆ’1,k + c2ui,k + c3ui+1,k + c4
where the coefficients c1, c2, c3 and c4 are to be determined by you.
c) Program the Laxâ€“Wendroff formula in (b), run it for a suitable choice of hx
and ht and present the result in a 3D plot. Make a comparison with the graph
from (a).

INDEX
A-stability, 54
Accuracy, 6, 43, 86
first order, 42
higher order, 56
second order, 46, 54
Acoustic wave see Equation(s)
Adaptive see Method
Advection, 3, 106, 167
Advection-diffusion, 87
Algorithm, 80
stepsize control, 59
Analysis
bifurcation, 38
eigenvalue, 132, 175
Fourier, 132, 175
sensitivity, 38, 67
stability, 20, 23, 38, 49
von Neumann, 132, 175, 187
Analytical stability see Stability
Ansatz, 94, 139, 156, 186
method, 40
Approximation, 40
difference, 41, 223
error, 225
symmetric, 84
unsymmetric, 84
Introduction to Computation and Modeling for Differential Equations, Second Edition. Lennart Edsberg.
Â© 2016 John Wiley & Sons, Inc. Published 2016 by John Wiley & Sons, Inc.
Assemble, 162
Autonomous, 20
Bandwidth, 153, 230
Basis functions, 95, 139, 156
BC(s), 3
Dirichlet, 72, 128, 134
essential, 97
generalized Neumann, 72
linear, 73, 143
mixed, 72, 135, 144
natural, 97
Neumann, 72, 135, 144
nonlinear, 74, 135
numerical, 180
periodic, 73
Robin, 72, 135, 144
BDF see Method
Beam, 75, 148
Biharmonic see Equation(s)
Blackâ€“Scholes see Equation(s)
Blasius, 76
Boundary condition see BC(s)
Boundary layer, 87
Boundary value(s), 12
Boundary value problem see BVP

266
INDEX
BTCS, 132
Burger see Equation(s)
Butcher tableau, 58
BVP, 71â€“103
linear, 89
nonlinear, 91
Calculus
operator, 224
variational, 143
Cauchy problem, 167
CDR see Equation(s)
CFL condition, 175
CG, 235
Characteristic, 5, 168 see also Equations(s)
Chemical kinetics see Kinetics
Cholesky
factorization, 153, 231
incomplete, 236
Coefficient(s), 95, 139
conduction, 73, 146
convection, 73, 146
heat transfer, 74, 192
stoichiometric, 28, 116
Collocation, 95
COMSOL Multiphysics, 247â€“8
Concentrations, 28, 33, 116, 194
Condition
boundary see BC(s)
initial see IC(s)
Conduction, 67, 145
Conservation equation see Equation(s)
Conservative form, 167, 185
Constitutive equation see Equation(s)
Continuity equation see Equation(s)
Control theory, 29
Convection-diffusion, 73, 138, 199
Convection-diffusion-reaction, 116, 138, 199
Convergence, 216, 234
linear, 218
quadratic, 217
Coordinates
cartesian, 110,
cylindrical, 111
spherical, 111
Critical point(s), 20, 23
curl, 111, 228
DAE, 15, 28
Damping see Matrix
Descent see Method
Dependent see Variable
Derivative
normal, 112
Descent, 235
Diagonalizable see Matrix
Difference, 41, 223
backward, 41
central, 41, 60, 81
equation, 41, 219
formula, 41
forward, 41
Differential operator, 110
Differential-algebraic equation(s) see DAE
Diffusion see also Equation(s)
artificial, 88
coefficient, 74, 193
heat, 193
mass, 193
Dimension(s), 3, 105, 201 see also Unit
Dimensionless, 201
Direct method, 144, 229
Direction
search, 234
Dirichlet BC see BC(s)
Discretization, 40, 154
Dispersion, 165
Dissipation, 165
Distributed see Model
div, 111, 226
Diverge, 216, 234
Divergence, 110
Driving function, 16, 130
Duhamel see Formula
Dynamic system, 26
Eigenfrequencies, 77, 149
Eigenvalue(s), 17
analysis, 132, 175, 185
multiple, 21
single, 21
Eigenvalue problem, 17, 77, 149
Eigenvector, 17
Elliptic PDEs, 143â€“64
Equation(s)
advection, 3, 106, 167
advection-diffusion, 87
acoustic wave, 118
Bernoulli, 115
Blackâ€“Scholes, 120
biharmonic, 148
Burger, 168
CDR, 116, 138, 199
characteristic, 17, 219
charge continuity, 118
conservation, 9, 167, 190, 195
constitutive, 9, 189, 192
continuity, 30, 196, 198

INDEX
267
convection-diffusion, 199
convection-diffusion-reaction, 116, 138,
199
difference, 41, 223
differential-algebraic see DAE
diffusion, 106, 117, 199
Euler, 41, 115
heat, 106, 117
Helmholtz, 77, 106, 149
homogeneous, 16, 107, 219
inhomogeneous, 16, 107, 125, 220
Laplaceâ€™s 106, 143
Lotkaâ€“Volterra, 24
Maxwell, 117
modified, 176
model see Problem
molecular dynamics, 64
Navier, 119
Navierâ€“Stokes, 114
Poissonâ€™s, 106, 143, 145
scalar conservation, 167, 198
scalar wave, 106, 118, 165, 172
SchrÃ¶dinger, 119
Stokes, 115
structural mechanics, 119
Van der Pol, 39, 43
variational, 23
vector wave, 118
vibration, 6
wave, 106, 165, 192
Equation system
linear, 229
nonlinear, 229
overdetermined, 218
quadratic, 215
Equidistant see Grid
Equilibrium points, 20
Equilibrium problem, 105
Error
approximation, 224
global, 44, 86
local, 44, 59
local discretization, 86
truncation, 42
Euler equations
compressible, 115, 172
Eulerâ€™s method
backward, 42
explicit, 42
forward, 42
implicit, 42
improved, 47
Evolution problem, 105
Explicit see Method
Explicit midpoint see Method
Extrapolation, 46
FDM, 40, 78, 154
FEM, 40, 100, 159
Fick see Law
Field, 105
scalar, 105, 110
vector, 105, 110
Fill-in, 153
Finite difference method see FDM
Finite element method see FEM
Finite volume method see FVM
Flop(s), 82, 230, 231
Flow, 114, 115, 195
compressible, 115
incompressible, 114
irrotational, 146
laminar, 115
potential, 115
turbulent, 115
Formula
algebraic, 2
difference, 41
Duhamel, 18
recursion, 41, 43, 219
Fourier
analysis, 132, 185 see also Transform(s)
law, 192
FTBS see Method
FTCS see Method
FTFS see Method
Full see Matrix
Function(s)
basis, 40, 95, 139, 160
Dirac delta, 109
Green, 80
Hamiltonian, 27
harmonic, 143
initial value, 3
pyramid, 160
residual, 95, 139, 156
roof, 101, 140
space, 96
FVM, 183
Galerkin see Method
Gas see Law
Gaussâ€“Newton see Method
Gaussian Elimination, 229
General see Solution
Ghost point, 84
Global error see Error
grad, 110

268
INDEX
Gradient, 110, 225
conjugate, 235
Green see Function
Grid
equidistant, 41
staggered, 66, 182
variable stepsize, 41
Hamiltonian see Function
Heat see Equation(s)
Homogeneous see Equation(s)
Hooke see Law
Hyperbolic, 3, 107, 165
Hyperbolic PDEs, 165â€“87
IC(s), 2, 3, 105, 121
Riemann, 170
Identification, 29
Ill-posed see Problem
Implicit see Method
Implicit midpoint see Method
Incomplete see Cholesky
Incompressible, 114
Independent see Variable(s)
Inhomogeneous see Equation(s)
Initial condition see IC(s)
Initial values, 2, 3, 12, 72
Initial value problem see IVP
Inner points, 81, 84
Instability, 20
numerical, 42
Invariant
linear, 62
quadratic, 62
Inviscid see Burger
Iteration, 216, 233
Iterative method, 144, 233
IVP, 2, 37â€“69
Jacobian, 22, 215
Kinetics
chemical, 28, 48, 194
drug, 35
Krylov space, 235
Laplace see Equation(s)
Laplacian, 111
Law(s),
Arrhenius, 194
conservation, 10, 167, 195
Fick, 193
Fourier, 193
gas, 194
Hooke, 194
Lorentz, 195
mass action, 28, 194
Newton, 26, 190, 193
Ohm, 195
scalar conservation, 167, 195
Stefanâ€“Boltzmann, 193
Layer
boundary, 88
transition, 115
LCC see System
Leap-frog see Method
Least-squares, 218
Limit cycle, 40
Linear, 16, 73, 107 see also ODE(s), PDE(s),
BC(s)
piecewise, 101
Load vector, 102, 162
Local error see Error
Locus
root, 38
Lorentz force, 118 see also Law
Lotkaâ€“Volterra, 24
LU-factorization, 230
Lumped see Model
Mass see Matrix
Mass action see Law
MATLAB, 242â€“7
Matrix
band, 230
damping, 27
defective, 17
diagonalizable, 17
exponential, 18
full, 140, 229
iteration, 233
local stiffness, 161
mass, 27
nilpotent, 19
nondefective, 17
positive definite, 82, 230
preconditioning, 236
profile, 232
rectangular, 218
sensitivity, 67
sparse, 229
SPD, 230
spring, 27
stiffness, 27, 102, 161
stoichiometric, 28, 116
symmetric, 82, 230
Maxwell see Equation(s)
Method
explicit midpoint, 60

INDEX
269
Method see also Algorithm
Adamsâ€“Bashforth, 61
Adamsâ€“Moulton, 61
adaptive, 41, 58
ansatz, 40
BDF, 61
Bogackiâ€“Shampine, 59
conjugate gradient, 235
Crankâ€“Nicolson, 133
descent, 235
direct, 144, 229
discretization, 40
explicit, 42, 60, 131,
Euler, 41, 42
Eulerâ€“Cromer, 43, 66
finite difference see FDM
finite element see FEM
finite volume see FVM
FTBS, 132, 186
FTCS, 128, 178, 187
FTFS, 177
Galerkin, 95, 98, 151, 159
Gaussâ€“Newton, 67, 218
Gaussâ€“Seidel, 234
Gear, 61
implicit, 42, 60, 132
implicit midpoint, 63
iterative, 233
Jacobi, 234
Laxâ€“Friedrich, 178
Laxâ€“Wendroff, 179
leap-frog, 60, 65, 66
linear multistep, 66
of lines, 130, 174
multigrid, 236
Newton, 215
one-step, 42
RK4 see Rungeâ€“Kutta
robust, 5
Rungeâ€“Kutta, 56
shooting, 92
search, 234
secant, 93
stationary iterative, 233
StÃ¶rmer, 65
trapezoidal, 55
two-step, 60
unstable, 60, 178
upwind, 88, 175
Verlet, 65
Model see also Equation(s)
compartment, 29
dynamic, 26
distributed, 197
lumped, 26, 196
mathematical, 9, 190â€“204
ODE, 26
PDE, 114
Modeling
mathematical, 9, 190â€“204
MoL, 130, 174
Molecular dynamics see Equation(s)
nabla, 110
Navier see Equation(s)
Navierâ€“Stokes see Equation(s)
Networks
electrical, 28
Neumann boundary conditions see BC(s)
Newton, 26 see also Law, Method
Node(s), 101, 159
Nonconservative form, 168, 185
Non-defective see Matrix
Nonlinear, 65, 91, 108, 138, 150, 167 see also
ODE(s), PDE(s) and BC(s)
Non-stiff, 57
Numbering, 159
local, 161
Numerical boundary condition see BC(s)
Numerical stability see Stability
ODE(s), 2, 11â€“36
Ohm see Law
Operator
differential, 110
calculus, 224
nabla, 110
One-step see Method
Order, 12, 41
accuracy, 42, 87
Ordinary differential equation(s) see ODE(s)
Oscillations, 6
numerical, 60
spurious, 88
Overflow, 49
Parabolic PDE(s), 123â€“41
Parameter(s), 2, 3, 6, 67
estimation, 38, 67
numerical, 6
sensitivity, 67
study, 38, 39
Partial differential equation(s) see PDE(s)
Particle dynamics, 30
Particular see Solution
PDE(s), 3, 105â€“22
elliptic, 107, 143â€“64
hyperbolic, 107, 165â€“87

270
INDEX
PDE(s), (Continued)
linear, 107
nonlinear, 108, 127, 150, 167
parabolic, 107, 123â€“41
Peclet number, 88
Pentadiagonal, 85
Periodic see BC(s)
Phase portrait, 38
Pipe, 73, 125, 126, 171, 199
Plate, 148
Positive definite see Matrix
Positivity, 64
Preconditioner, 236
Preconditioning see Matrix
Predator-prey, 24
Poisson see Equation(s)
Problem see also Equation(s)
eigenvalue, 17
equilibrium, 105
evolution, 105
ill-posed, 123
model, 49, 79, 106, 123, 143, 167
singular perturbation, 87
steady-state, 105
stiff, 53, 131
time-dependent, 105
well-posed, 105, 121
Profile, 232
Pseudoinverse, 218
Quadratic see Equation system
Radiation, 74, 135
Rate constant, 28, 194
Reactor
tank, 197,
tubular, 127
Recursion see Formula
Region see Stability
Residual, 218, 234 see also Function(s)
Resonance, 149
Reynoldâ€™s number, 115
Riemann see IC(s)
Robin see BC(s)
Robust see Method
Roof see Function(s)
Root locus, 38
Rotation, 111
Rungeâ€“Kutta see also Method
classical, 56
embedded, 58
explicit, 58
implicit, 58
s-stage, 57
Scalar conservation law see Law
Scalar model problem see Problem
SchrÃ¶dinger see Equation(s)
Scientific computing, 1, 5
Search
direction, 235
method, 234
Semi-discretization, 130
Sensitivity see Analysis, Matrix
Separation of variables, 110
Shock wave(s), 8, 116, 172, 178
SI see Unit
Simulation, 1, 6
Singular perturbation see Problem
Soap film, 150
Sobolev, 100
Solution
bounded, 50
dâ€™Alembert, 109, 165
classical, 96
general, 2, 3, 11, 13, 17, 71, 72
particular, 3, 13, 72
stable, 20
strong, 96
trajectory, 20
unstable, 20, 132, 176
variational, 96
weak, 96
Source strength, 111, 228
Sparse see Matrix, System
SPD see Matrix
Spring see Matrix
SOR, 234
SSOR, 234
Splitting, 233
Stability, 20, 29, 34
analysis, 20, 38
analytical, 20, 51
asymptotic, 21
eigenvalue, 132, 174, 187
numerical, 50, 132, 176
region of, 50, 54, 55, 57
von Neumann, 132, 175, 187
Staggered see Grid
State-space, 29
Steady-state see Problem
Steepness, 111
Stefanâ€“Boltzmann see Law
Stencil, 129, 152, 175, 181
Step length, 235
Stepfunction, 7, 170
Stepsize, 6, 41
constant, 41

INDEX
271
control, 59
variable, 41
Stiff see Problem
Stiffness see Matrix
Stoichiometric see Coefficient(s)
StÃ¶rmer see Method
Superposition, 17, 110
Symmetric see Matrix
System
dynamic, 26
hyperbolic, 166, 171
LCC, 16
ODE, 12
PDE, 105, 127, 150
sparse, 82, 153, 229
stiff, 53, 123, 131
uncoupled, 51
Time dependent see Problem
Timescales, 52
Trajectory, 38
Transform(s)
Fourier, 237â€“9
Transition see Layer
Tridiag, 82, 131, 231
Tridiagonal, 82, 153, 231
Truncation error see Error
Tune, 6
Turbulent see Flow
Two-step see Method
Uncoupled see System
Unit(s), 26, 190
Unstable see Solution
Upwind see Method
Value(s) see Boundary value(s), Initial value(s)
Variable(s)
dependent, 11, 105
independent, 11, 105
separation of, 110
Variational see also Calculus, Equation(s)
formulation, 96
Vector
load, 102, 162
local load, 162
Vector wave see Equation(s)
Verlet see Method
Vibration see Equation(s)
Viscosity
artificial, 88
dynamic, 194
kinematic, 76, 194
Visualization, 8
Visualize, 38
von Neumann see Analysis, Stability
Vorticity strength, 229
Wave equation see Equation(s)
Wave number, 108
Weak, 96, 157, 170
Well-posed see Problem

WILEY END USER LICENSE AGREEMENT
Go to www.wiley.com/go/eula to access Wileyâ€™s ebook EULA.

