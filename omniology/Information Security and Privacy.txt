Ernest Foo
Douglas Stebila (Eds.)
 123
LNCS 9144
20th Australasian Conference, ACISP 2015
Brisbane, QLD, Australia, June 29 – July 1, 2015
Proceedings
Information Security 
and Privacy
www.ebook3000.com

Lecture Notes in Computer Science
9144
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison
Lancaster University, Lancaster, UK
Takeo Kanade
Carnegie Mellon University, Pittsburgh, PA, USA
Josef Kittler
University of Surrey, Guildford, UK
Jon M. Kleinberg
Cornell University, Ithaca, NY, USA
Friedemann Mattern
ETH Zurich, Zürich, Switzerland
John C. Mitchell
Stanford University, Stanford, CA, USA
Moni Naor
Weizmann Institute of Science, Rehovot, Israel
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Bernhard Steffen
TU Dortmund University, Dortmund, Germany
Demetri Terzopoulos
University of California, Los Angeles, CA, USA
Doug Tygar
University of California, Berkeley, CA, USA
Gerhard Weikum
Max Planck Institute for Informatics, Saarbrücken, Germany

More information about this series at http://www.springer.com/series/7410
www.ebook3000.com

Ernest Foo
• Douglas Stebila (Eds.)
Information Security
and Privacy
20th Australasian Conference, ACISP 2015
Brisbane, QLD, Australia, June 29 – July 1, 2015
Proceedings
123

Editors
Ernest Foo
Queensland University of Technology
Brisbane, QLD
Australia
Douglas Stebila
Queensland University of Technology
Brisbane, QLD
Australia
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Computer Science
ISBN 978-3-319-19961-0
ISBN 978-3-319-19962-7
(eBook)
DOI 10.1007/978-3-319-19962-7
Library of Congress Control Number: 2015940421
LNCS Sublibrary: SL4 – Security and Cryptology
Springer Cham Heidelberg New York Dordrecht London
© Springer International Publishing Switzerland 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, express or implied, with respect to the material contained herein or for any errors or
omissions that may have been made.
Printed on acid-free paper
Springer International Publishing AG Switzerland is part of Springer Science+Business Media
(www.springer.com)
www.ebook3000.com

Preface
This volume contains the papers presented at ACISP 2015: the 20th Australasian
Conference on Information Security and Privacy held from June 29 to July 1, 2015, in
Brisbane, Australia. The conference was hosted by the Institute for Future Environ-
ments at the Queensland University of Technology, who provided the wonderful
facilities and material support. The local Organizing Committee was led by the ACISP
2015 general chair, Josef Pieprzyk, with administration led by Cindy Mayes. We
appreciate the support of Ed Dawson and Seyit Camtepe in the conference organiza-
tion. We made use of the excellent EasyChair submission and reviewing software.
There were 112 submissions. Each submission was allocated to three Program
Committee members and each paper received on average 2.9 reviews. The committee
decided to accept 28 papers. Accepted papers came from 13 countries with the largest
proportions coming from Australia (6), Japan (6), India (5), China (4), and Germany
(2). Other authors are from Belgium, Canada, France, Luxembourg, The Netherlands,
New Zealand, Singapore, and the USA. We would like to extend our sincere thanks to
all authors who submitted papers to ACISP 2015.
The program also included three excellent and informative invited talks. One
of these was from an eminent cryptography researcher and the other two were from
highly experienced security practitioners: Professor Colin Boyd, from the Norwegian
University of Science and Technology (NTNU); Jason Smith, from CERT Australia;
and Simon Pope, from the Microsoft Security Response Center.
We would like to thank the team of experts who made up the Program Committee.
Their names are listed overleaf. The Program Committee was assisted by an even larger
team of people who reviewed papers in their area of expertise. The list of these
reviewers is also included. Finally, we would like to thank Springer for their help with
the production of these conference proceedings and their commitment to the ACISP
conference for the last 20 years. We look forward to many more years of ACISP.
June 2015
Ernest Foo
Douglas Stebila

Organization
Program Committee
Joonsang Baek
Khalifa University of Science, Technology
and Research, UAE
Paulo Barreto
University of São Paulo, Brazil
Alex Biryukov
University of Luxembourg, Luxembourg
Colin Boyd
Norwegian University of Science and Technology
(NTNU), Norway
Xavier Boyen
Queensland University of Technology, Australia
Jean Camp
Indiana University, USA
Kim-Kwang Raymond
Choo
University of South Australia, Australia
K.P. Chow
University of Hong Kong, SAR China
Craig Costello
Microsoft Research
Cas Cremers
University of Oxford, UK
Marc Fischlin
Technical University of Darmstadt, Germany
Ernest Foo
Queensland University of Technology, Australia
Praveen Gauravaram
Queensland University of Technology, Australia
Joanne L. Hall
Queensland University of Technology, Australia
Jiankun Hu
University of New South Wales at ADFA, Australia
Tancrède Lepoint
CryptoExperts
Sachin Lodha
Tata Consultancy Services
Mark Manulis
University of Surrey, UK
Atsuko Miyaji
Japan Advanced Institute of Science and Technology,
Japan
Yi Mu
University of Wollongong, Australia
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Udaya Parampalli
University of Melbourne, Australia
Rei Safavi-Naini
University of Calgary, Canada
Palash Sarkar
Indian Statistical Institute, India
Jennifer Seberry
University of Wollongong, Australia
Leonie Simpson
Queensland University of Technology, Australia
Douglas Stebila
Queensland University of Technology, Australia
Suriadi Suriadi
Massey University, New Zealand
Willy Susilo
University of Wollongong, Australia
Tsuyoshi Takagi
Kyushu University, Japan
Berkant Ustaoglu
NTT Information Sharing Platform Laboratories
Vijay Varadharajan
Macquarie University, Australia
Kan Yasuda
NTT Secure Platform Laboratories
Jianying Zhou
Institute for Infocomm Research, Singapore
www.ebook3000.com

Additional Reviewers
Abdelraheem, Mohamed
Ahmed
Aditya, Riza
Alkhzaimi, Hoda
Aoki, Kazumaro
Bagheri, Nasour
Baignères, Thomas
Bouzefrane, Samia
Bringer, Julien
Chalamala, Srinivas
Chen, Jiageng
Cheng, Shu
D’Orazio, Christian
Damavandinejadmonfared,
Sepehr
Dawson, Ed
Delerablée, Cécile
Derbez, Patrick
Deva Selvi, Sharmila
Dilruba, Raushan
Dong, Xinshu
Dong, Zheng
Dowling, Benjamin
Dunkelman, Orr
Emmadi, Nitesh
Fan, Jia
Fehr, Victoria
Futa, Yuichi
Gagliardoni, Tommaso
Garratt, Luke
Guo, Fuchun
Han, Jinguang
Henricksen, Matt
Hitchens, Michael
Hou, Shuhui
Huang, Kun
Huang, Qiong
Jhawar, Mahavir Jhawar
Jindal, Arun
Kamara, Seny
Karande, Shirish
Khovratovich, Dmitry
Kojima, Tetsuya
Kumari, Rashmi
Laarhoven, Thijs
Liang, Kaitai
Lin, Fuchun
Liu, Joseph
Liu, Zhenhua
Longa, Patrick
Lopez-Alt, Adriana
Luykx, Atul
Manjunath, R. Sumesh
Marson, Giorgia Azzurra
Min, Byungho
Mittelbach, Arno
Mouha, Nick
Naehrig, Michael
Narumanchi, Harika
Neves, Samuel
Nikova, Svetla
Ohtake, Go
Omote, Kazumasa
Perrin, Léo Paul
Poettering, Bertram
Pustogarov, Ivan
Radke, Kenneth
Roy, Sujoy Sinha
Sadeghian, Saeed
Sasaki, Yu
Shull, Adam
Simplicio Jr, Marcos
Soltani Panah, Arezou
Su, Chunhua
Syed, Habeeb
Tanaka, Satoru
Teske-Wilson, Edlyn
Todo, Yosuke
Tupakula, Uday
Tupsamudre, Harshal
Udovenko, Aleksei
Velichkov, Vesselin
Wang, Pengwei
Wu, Wei
Xu, Jia
Xu, Rui
Yang, Guomin
Yasuda, Masaya
Yasuda, Takanori
Zhang, Hui
Zhang, Mingwu
Zhou, Lan
VIII
Organization

Contents
Symmetric Cryptanalysis
Weak-Key and Related-Key Analysis of Hash-Counter-Hash Tweakable
Enciphering Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Zhelei Sun, Peng Wang, and Liting Zhang
Cryptanalysis of Reduced-Round Whirlwind . . . . . . . . . . . . . . . . . . . . .
20
Bingke Ma, Bao Li, Ronglin Hao, and Xiaoqian Li
Improving the Biclique Cryptanalysis of AES . . . . . . . . . . . . . . . . . . . . . .
39
Biaoshuai Tao and Hongjun Wu
Public Key Cryptography
A New General Framework for Secure Public Key Encryption
with Keyword Search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
Rongmao Chen, Yi Mu, Guomin Yang, Fuchun Guo, and Xiaofen Wang
Dynamic Threshold Public-Key Encryption with Decryption Consistency
from Static Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
Yusuke Sakai, Keita Emura, Jacob C.N. Schuldt, Goichiro Hanaoka,
and Kazuo Ohta
Sponge Based CCA2 Secure Asymmetric Encryption for Arbitrary
Length Message . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
Tarun Kumar Bansal, Donghoon Chang, and Somitra Kumar Sanadhya
Trade-Off Approaches for Leak Resistant Modular Arithmetic in RNS . . . . .
107
Christophe Negre and Guilherme Perin
Identity-Based Encryption
Towards Forward Security Properties for PEKS and IBE. . . . . . . . . . . . . . .
127
Qiang Tang
IBE Under k-LIN with Shorter Ciphertexts and Private Keys. . . . . . . . . . . .
145
Kaoru Kurosawa and Le Trieu Phong
Improved Identity-Based Online/Offline Encryption . . . . . . . . . . . . . . . . . .
160
Jianchang Lai, Yi Mu, Fuchun Guo, and Willy Susilo
www.ebook3000.com

Constructions of CCA-Secure Revocable Identity-Based Encryption . . . . . . .
174
Yuu Ishida, Yohei Watanabe, and Junji Shikata
Digital Signatures
Linkable Message Tagging: Solving the Key Distribution Problem
of Signature Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
Felix Günther and Bertram Poettering
Generic Transformation to Strongly Existentially Unforgeable Signature
Schemes with Continuous Leakage Resiliency . . . . . . . . . . . . . . . . . . . . . .
213
Yuyu Wang and Keisuke Tanaka
Constant Size Ring Signature Without Random Oracle . . . . . . . . . . . . . . . .
230
Priyanka Bose, Dipanjan Das, and Chandrasekharan Pandu Rangan
Security Protocols
Constant-Round Leakage-Resilient Zero-Knowledge Argument
for NP from the Knowledge-of-Exponent Assumption. . . . . . . . . . . . . . . . .
251
Tingting Zhang, Hongda Li, and Guifang Huang
Modelling Ciphersuite and Version Negotiation in the TLS Protocol . . . . . .
270
Benjamin Dowling and Douglas Stebila
VisRAID: Visualizing Remote Access for Intrusion Detection . . . . . . . . . . .
289
Leliel Trethowen, Craig Anslow, Stuart Marshall, and Ian Welch
BP-XACML an Authorisation Policy Language for Business Processes. . . . .
307
Khalid Alissa, Jason Reid, Ed Dawson, and Farzad Salim
Symmetric Cryptanalysis
How TKIP Induces Biases of Internal States of Generic RC4 . . . . . . . . . . .
329
Ryoma Ito and Atsuko Miyaji
Preventing Fault Attacks Using Fault Randomization with a Case Study
on AES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
343
Shamit Ghosh, Dhiman Saha, Abhrajit Sengupta,
and Dipanwita Roy Chowdhury
Analysis of Rainbow Tables with Fingerprints . . . . . . . . . . . . . . . . . . . . . .
356
Gildas Avoine, Adrien Bourgeois, and Xavier Carpent
X
Contents

Privacy Protocols
A New Public Remote Integrity Checking Scheme with User Privacy. . . . . .
377
Yiteng Feng, Yi Mu, Guomin Yang, and Joseph K. Liu
Efficient Dynamic Provable Data Possession with Public Verifiability
and Data Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
395
Clémentine Gritti, Willy Susilo, and Thomas Plantard
Privately Computing Set-Union and Set-Intersection Cardinality
via Bloom Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
413
Rolf Egert, Marc Fischlin, David Gens, Sven Jacob, Matthias Senker,
and Jörn Tillmanns
Symmetric Constructions
Generalizing PMAC Under Weaker Assumptions . . . . . . . . . . . . . . . . . . . .
433
Nilanjan Datta and Kan Yasuda
sp-AELM: Sponge Based Authenticated Encryption Scheme for Memory
Constrained Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
451
Megha Agrawal, Donghoon Chang, and Somitra Sanadhya
Homomorphic Encryption and Obfuscation
Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption . . .
471
Masaya Yasuda, Takeshi Shimoyama, Jun Kogure, Kazuhiro Yokoyama,
and Takeshi Koshiba
Bad Directions in Cryptographic Hash Functions . . . . . . . . . . . . . . . . . . . .
488
Daniel J. Bernstein, Andreas Hülsing, Tanja Lange,
and Ruben Niederhagen
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
509
Contents
XI
www.ebook3000.com

Symmetric Cryptanalysis

Weak-Key and Related-Key Analysis
of Hash-Counter-Hash Tweakable
Enciphering Schemes
Zhelei Sun1,2,3, Peng Wang1,2(B), and Liting Zhang4
1 State Key Laboratory of Information Security, Institute of Information
Engineering, Chinese Academy of Sciences, Beijing 100093, China
{zhlsun,wp}@is.ac.cn
2 Data Assurance and Communication Security Research Center,
Chinese Academy of Sciences, Beijing 100093, China
3 University of Chinese Academy of Sciences, Beijing, China
4 Institute of Software, Chinese Academy of Sciences,
Beijing, People’s Republic of China
zhangliting@is.iscas.ac.cn
Abstract. We analyze three tweakable enciphering schemes (TES)
XCB, HCTR and HCH, which all consist of polynomial evaluation hash
function as their ﬁrst and third layers and CTR mode in the middle.
The weak keys of polynomial evaluation hash in message authentication
code and authenticated encryption have been thoroughly analyzed, but
have never applied in TES. We point out that XCB, HCTR and HCH
(and two variations of HCH: HCHp and HCHfp) can not resist distin-
guishing attack, key-recovery attack and plaintext-recovery attack once
the weak key is recognized. We also analyze the security of related-key
attacks against these schemes, showing that HCTR, HCHp and HCHfp
suﬀer related-key attack and XCB and HCH can resist related-key attack
under the assumption that the underlying block cipher resists related-key
attack.
Keywords: Universal hash function · Tweakable enciphering scheme ·
Weak keys · Related-key attack
1
Introduction
XCB [1], HCTR [2] and HCH [3] are three tweakable enciphering schemes (TES)
following the hash-counter-hash approach. Tweakable enciphering schemes are
generalized block ciphers with extra input of tweaks and more variable block
lengths. It takes as input a key K, a tweak (or associated data) T and a plaintext
P, and outputs a ciphertext C. We write it as
ET
K(P) = C,
where the lengths of P and C are the same and for any K and T the transforma-
tion ET
K(·) is a permutation. TES is specially suitable for disk sector encryption
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 3–19, 2015.
DOI: 10.1007/978-3-319-19962-7 1
www.ebook3000.com

4
Z. Sun et al.
(where the sector number can be regarded as the “tweak”) [4] and other length-
preserving encryptions. TES can also be turned into an authenticated encryption
scheme like AEZ [5], Deoxys, Joltik, and KIASU proposed in CAESAR [6]. AEZ
is built on EME [7], which is a TES constructed by two layers of ECB encryption
and a mix layer in between. Deoxys, Joltik, and KIASU are direct TES designs
which can resist related-key attack and have variable size key and tweak. In
addition to this XCB has been included in the IEEE Security in Storage Work-
ing Group for wide-block encryption for shared storage media [4]. HCTR is the
most eﬃcient scheme in hardware among existing TESes so far [8].
The constructions of XCB, HCTR and HCH all consist of universal hash
function as their ﬁrst and third layer and CTR mode in the middle. The universal
hash function [9] is a polynomial in which the variables are the key of the function
and the coeﬃcients are made up of message blocks such as hH(M) =  MiHi
where H is the key and Mi is a message block. This kind of universal hash
function is called polynomial evaluation hash in literature, which has been widely
used to construct message authentication code (MAC) [10–12], authenticated
encryption (AE), TES [1–3] and other cryptographic schemes. CTR uses the
block cipher to generate the key stream used in the message encryption: eK(Si),
i = 1, 2, · · · , where K is the key of block cipher and Si is the number generated
by a counter.
XCB is one of ﬁrst constructions of the hash-counter-hash type. HCTR is
constructed based on XCB with less block cipher invocations than XCB. HCH
is similar to the structure of HCTR with a goal of obtaining a quadratic bound
while maintaining the eﬃciency of HCTR, although HCTR later was proved to
also have quadratic bound but not previous cubic bound [13]. There are two vari-
ations of HCH: HCHp and HCHfp. HCHp is designed to utilize pre-computation
by using a separate hash key. HCHfp works for ﬁxed length messages, which can
also utilize pre-computation and further reduces one block cipher invocation. All
three schemes are proved to be secure in the sense that they are indistinguish-
able from a family of independent random permutations labeled by tweaks if the
underlying block cipher is a pseudorandom permutation (PRP).
WEAK-KEY. In recent years, a serial research focused on the weak keys of
the polynomial evaluation hash function in MAC and AE, trying to ﬁnd more
classes of weak keys, which can be applied to forgery and key-recovery attacks
once weak keys are detected. Handschuh et al. [14] pointed out that 0 is the weak
key of the polynomial evaluation hash in MAC. Saarinen’s work [15] showed other
weak key classes for GHASH besides 0 and applied these weak keys in forgery
attack against GCM. Then Gordon et al. promoted this work [16], analyzed the
underlying algebraic structure of the polynomial evaluation hash, which provided
a more general attack on GHASH and expanded the number of weak keys.
Bo Zhu et al. [17] improved forgery attacks against MAC based on polynomial
evaluation hash and put forward that all non-singleton subsets of keys are weak
keys. We notice that the weak-key analysis has never been applied in TES.
RELATED-KEY. Related-key attacks were ﬁrstly introduced by Biham and
Knudsen for block ciphers in [18,19], and they can be turned into key-recovery

Weak-Key and Related-Key Analysis
5
attacks [20] or distinguishing attacks [21], the security against related-key attack
has become a basic and mandatory requirement for block ciphers. Bellare and
Kohn [22] ﬁrstly gave a theoretical related-key security model for block ciphers,
and Bhattacharyya and Roy presented related-key security analysis also applied
to encryption schemes, MACs [23] and other cryptographic objects. TESes are
generalized block ciphers, therefore it is natural to consider the related-key secu-
rity of TES. But as far as know, few related-key analysis has been presented on
TES.
In this paper, we analyze XCB, HCTR and HCH from the above two aspects.
We show that XCB, HCTR and HCH suﬀer the trouble of weak keys of polyno-
mial evaluation hash, which leads to distinguishing attack, key-recovery attack
and plaintext-recovery attack once weak keys are detected. Meanwhile we show
that XCB and HCH can resist related-key attack under the assumption that the
underlying block cipher resists related-key attack; HCTR, HCHp and HCHfp
cannot resist related-key attack, which turns into distinguishing attack with two
queries.
The paper is organized as follows. Section 2 gives the notations throughout
the paper, a brief description of universal hash function, the security of block
cipher and TES, and weak keys in MAC and AE based on polynomial evaluation
hash. Sections 4, 5 and 6 present the analyses of XCB, HCTR and HCH from
the two aspects: related-key and weak-key respectively and section 6 concludes
the full paper at last.
2
Preliminaries
2.1
Notations
Let {0, 1}n denote the set of all strings of length n. Let {0, 1}∗be the set of
all bit strings. For a string X ∈{0, 1}∗, len(X) denotes the bit-length of string
X. Let 0w and 1w denote strings of w zeros and w ones respectively, where w
is a nonnegative integer. |D| means the number of members of set D. If X, Y ∈
{0, 1}∗, X∥Y is their concatenation. For a ﬁnite set D, if d is uniformly chosen
from D we write d
$←−D. Throughout this paper the block cipher, and operations
of ﬁnite ﬁeld are done over blocks and the block length is ﬁxed as w bits.
2.2
Universal Hash Function
Universal hash functions are widely used in the design of cryptographic schemes.
Almost universal [9] and almost xor universal [24] hash functions are deﬁned
as follows.
Deﬁnition 1. h : K × D →R is ϵ-almost-universal if for all M, M ′ ∈D and
M ̸= M ′,
PrH∈K[hH(M) = hH(M ′)] ≤ϵ.
www.ebook3000.com

6
Z. Sun et al.
Deﬁnition 2. h : K × D →R is ϵ-almost-xor-universal if for all M, M ′ ∈D,
M ̸= M ′, c ∈R,
PrH∈K[hH(M) ⊕hH(M ′) = c] ≤ϵ.
Clearly, if h is ϵ-AXU, it is also ϵ-AU, for ϵ-AU is a special case of ϵ-AXU where
c = 0.
Polynomial Evaluation Hash. Polynomial evaluation hash is one of the
method to realize ϵ-AXU (or ϵ-AU) function, for H ∈{0, 1}n, M = M1 · · · Mm ∈
{0, 1}mn, Mi ∈{0, 1}n, 1 ≤i ≤m, we deﬁne,
hH(M) =
m

i=1
MiHi−1.
Clearly, it is (m −1)/2n-AU. H · hH(M) = H · m
i=1 MiHi−1 = m
i=1 MiHi is
m/2n-AXU.
2.3
Block Cipher and Tweakable Enciphering Scheme Security
We consider the pseudorandom permutation (PRP) [25] security of blook cipher
as the indistinguishability between it and an ideal “random permutation” π,
chosen randomly from the set of permutations over {0, 1}w,
π
$←−Perm(w),
under chosen plaintext attack (CPA). The strong pseudorandom permutation
(SPRP) security is similar with PRP except that the block cipher is under the
chosen ciphertext attack (CCA).
We can similarly utilize the above descriptions to deﬁne tweakable PRP
(TPRP) [26], strong tweakable TPRP (STPRP) security of tweakable encipher-
ing scheme (TES) [27] as the indistinguishability between it and an “tweakable
random permutation” π (a family of independent random permutations labeled
by the tweak T. For each T, we let πT ←Perm(w), where πT is a randomly
chosen permutation labeled by T) under CPA and CCA respectively.
While considering the security under related-key attacks (RKA), the adver-
sary can apply related-key transformations φ to change the key and observe the
output under the modiﬁed keys [22]. Here we only consider the transformation
that exclusive-or (xor) diﬀerences on key K (one of the most common way):
⊕Δ(K) = K ⊕Δ.
We consider the PRP secure against RKA (PRP-RKA) [22] and SPRP secure
against RKA (SPRP-RKA) of block cipher as the indistinguishability between
it on the target key as well as on some related-keys and a family of random
permutations labeled by the target key as well as on some related-keys under
CPA and CCA respectively. For each K, we let πK ←Perm(w), where πK is a
randomly chosen permutation labeled by K.

Weak-Key and Related-Key Analysis
7
We consider the TPRP secure against RKA (TPRP-RKA) and STPRP
secure against RKA (STPRP-RKA) of TES as the indistinguishability between
it on the target key as well as on some related-keys and a family of tweakable
random permutations labeled by the target key as well as on some related-keys
under CPA and CCA respectively. For each tuple (T, K), we let πT
K ←Perm(w)
where πT
K is a randomly chosen permutation labeled by (T, K).
More speciﬁcally, the advantage function of the adversary is deﬁned as:
AdvT ype
Object(A) = Pr[AReal ⇒1] −Pr[AIdeal ⇒1],
where Type is one of the above PRP, SPRP, TPRP, STPRP, PRP-RKA, SPRP-
RKA, TPRP-RKA, or STPRP-RKA, Object is the block cipher or TES, Real is
the real oracle and Ideal is the ideal oracle. As to SPRP, STPRP, SPRP-RKA,
STPRP-RKA, the objects and oracles are listed as following:
Type
Object
Real
Ideal
SPRP
E
EK(·), E−1
K (·)
π(·), π−1(·)
STPRP
E
E(·)
K (·), E−1(·)
K
(·)
π(·)(·), π−1(·)(·)
SPRP-RKA
E
EK⊕(·)(·), E−1
K⊕(·)(·) πK⊕(·)(·), π−1
K⊕(·)(·)
STPRP
E
E(·)
K⊕(·)(·), E−1(·)
K⊕(·)(·) π(·)
K⊕(·)(·), π−1(·)
K⊕(·)(·)
2.4
Weak Keys in MAC and AE Based on Polynomial Evaluation
Hash
In recent years, a lot of works have been proposed to analyze the weak keys of
polynomial evaluation hash in MAC and AE. How to ﬁnd, detect and utilize the
weak keys is a serial of problems in weak-key analysis.
The Deﬁnition of Weak Keys. In 2008, Handschuh and Preneel [14] gave
the following deﬁnition of weak keys :
a class of keys is called a weak key class if for the members of that class
the algorithm behaves in an unexpected way and if it is easy to detect
whether a particular unknown key belongs to this class. For a MAC
algorithm, the unexpected behavior can be that the forgery probability
for this key is substantially larger than average. Moreover, if a weak key
class is of size C, one requires that identifying that a key belongs to this
class requires testing fewer than C keys by exhaustive search and fewer
than C veriﬁcation queries.
According to this deﬁnition, a lot of work have been proposed which ana-
lyzed the security of MAC and AE based on polynomial evaluation hash, espe-
cially for GCM. Handschuh and Preneel regarded 0 as the only weak key for all
polynomial-evaluation-hash based schemes. However, Markku-Juhani et al. [15]
showed that there exist wider classes of weak keys besides 0 for GCM. Later,
www.ebook3000.com

8
Z. Sun et al.
Gordon Procter et al. expanded the number of weak keys and showed that almost
every subset of the keyspace is a weak key class [16] in GCM. D is composed of
GCM authentication keys, then
D is a weak key class for GCM, if 0 ∈D and |D| ≥2, or |D| ≥3.
Then Bo Zhu et al. [17] gave a further deﬁnition of weak keys which can be
described as follows:
D is a weak key class for GCM, if |D| ≥2.
Utilize the Weak Keys to Analyze the Security of GCM. D = {H1,
H2, · · · , Hr} where Hi is chosen from {0, 1}w for 1 ≤i ≤r, r ≥2. According
to the previous discussion [16,17], D is a weak key class for authentication key
of GCM. Next we show how to analyze the security of GCM if the unknown
authentication key H falls into D∪0. Similar methods will be used in the follow-
ing analyses. We construct a polynomial q(x) = x
r
i=1
(x ⊕Hi) =
r+1

i=1
qixi, where
qi is the coeﬃcient of xi. Let Q = q1∥q2∥· · · ∥qr+1. Assume H ∈D ∪0 (or we say
q(x) is valid for H and q(H) = 0), then a successful forgery will occur, implying
a collision of polynomial evaluation hash,
hH(C) = hH(C) ⊕q(H) = hH(C ⊕Q),
where we xor coeﬃcients of q(x)’s terms with C. The probability of a successful
GCM forgery is directly related to the choice of D: #roots of q(x)
2w
. Once we ﬁnd
a valid q(x) for H, we say H is recognized as weak key. Furthermore we can
utilize the valid q(x) to make more forgery attacks and even recover H [16,17].
Meanwhile, we adopt the method in [16] to avoid the eﬀect brought by modifying
the length information when q(x) has a high degree: if q(H) = 0, then aq(H) = 0
for any a ∈{0, 1}w, then
hH(C) = hH(C) ⊕aq(H) = hH(C ⊕aQ),
where aQ = aq1∥aq2∥· · · . So we can choose a diﬀerential between the original
message and the forged message at the location of length information to avoid the
eﬀect brought by modifying the length information. Else, we set q(x) = xq(x) to
avoid modifying the length block. The two methods will be applied appropriately
to analysis below by default.
3
Analysis of XCB
XCB is an STPRP under the assumption that the underlying block cipher is an
SPRP [28].1
1 Here we only discuss the initial version of XCB. The standardized version [28] is a
little diﬀerent from the initial one that there is only one single hash key. In addition
to this, the inputs to the hash function and the plaintexts are arranged diﬀerently
from the initial version. Even so, the analysis on the initial version applies to the
standardized one.

Weak-Key and Related-Key Analysis
9
3.1
Deﬁnition of XCB
XCB is comprised of a block cipher e (d is the inverse function of e), a polynomial
evaluation hash function h, and a CTR function c, where c is similar to the one
presented in introduction. XCB drives ﬁve sub-keys (K0, K1, K2, K3, K4) from
the master key by the encryption of ﬁve constants. Three of them (K0,K2,K4)
are used as the keys of the underlying block cipher, the rest two keys (K1,K3)
are used as the keys of polynomial evaluation hash:
K0 ←eK(0w), K1 ←eK(0w−1∥1), K2 ←eK(0w−2∥1∥0),
K3 ←eK(0w−2∥12), K4 ←eK(0w−3∥1∥02).
Polynomial Evaluation Hash. hH(A, C) : {0, 1}w × {0, 1}m × {0, 1}n →{0, 1}w,
where m = len(A) ∈[w, 239], n = len(C) ∈[0, 239]. len(A) = w(p −1) +
m1, len(C) = w(q −1) + n1 for 1 ≤m1, n1 ≤w. Partition A and C into
A1∥A2∥· · · ∥Ap and C1∥C2∥· · · ∥Cq respectively, where len(Ai) = w for 1 ≤i ≤
p −1, len(Ci) = w for 1 ≤i ≤q −1,
Bi =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
Ai
for 1 ≤i ≤p −1,
Ai∥0w−m1
for i = p,
Ci
for p + 1 ≤i ≤p + q −1,
Ci∥0w−n1
for i = p + q,
len(A)∥len(C)
for i = p + q + 1,
the computation is deﬁned as
p+q+1

i=1
BiHp+q+2−i.
The encryption process and decryption process of XCB are written as
XCB.EncT
K(M) and XCB.DecT
K(C) respectively. See more in Appendix A.
3.2
Weak-Key Analysis of XCB
We show that if the sub-key K1 or K3 for polynomial evaluation hash h is
identiﬁed as a weak key, we can utilize the similar method used in GCM to
analyze XCB. Contrary to creating a successful forgery in GCM, here we create
same key streams generated by the CTR mode c. Moreover, the identiﬁcation
of weak keys lead to more powerful attacks: distinguishing attack, key-recovery
attack and plaintext-recovery attack against XCB more than forgery attack.
Identify Weak Key. For XCB, D is a weak key class if 0 ∈D and |D| ≥2, or
|D| > 2. For we cannot full control the output of eK0(A), we can only consider the
collision of universal evaluation hash which has no constant term. If D contains
0, we only need to set q(x) = 
L∈D
(x⊕L), which requires at least one query. Else
www.ebook3000.com

10
Z. Sun et al.
if 0 /∈D, we need to set q(x) = x 
L∈D
(x ⊕L). We ﬁrst test whether H ∈D ∪0,
which needs at least one query. Then consider whether H = 0. The whole process
needs at least two queries.
We choose such a D = {H1, H2, · · · , Hr} meeting the requirement, where
Hi is chosen from {0, 1}w for 1 ≤i ≤r. We will show how to test whether
K1 ∈D ∪0 (the case for K3 is similar to the one for K1).
Assume (A, B, T, G, E) obtained by querying the encryption process (see
Figure 1). Firstly, we construct a polynomial q(x) = x
r
i=1
(x ⊕Hi) =
r+1

i=1
qixi,
where Q = q1∥q2 · · · ∥qr+1. We set A′ = A, (B′, T ′) = (B, T) ⊕Q, which means
xor coeﬃcients of q(x)’s terms with the message B∥T. Then send (A′, B′, T ′)
to the encryption oracle and get a new ciphertext (G′, E′). Considering the
hash-counter-hash construction of XCB, we will obtain the same key streams:
B ⊕E = B′ ⊕E′ if q(K1) = 0. This holds because:
hK1(B, T) = hK1(B, T) ⊕q(K1) = hK1((B, T) ⊕Q) = hK1(B′, T ′),
A = A′ ⇒C = C′.
Then O = O′, which are the initial counter values of the CTR mode c. Clearly
the key streams c generates are the same.
The identiﬁcation goes as follows:
1. Obtain a tuple (A, B, T, G, E) by querying the encryption process as illus-
trated in Figure 1;
2. Construct q(x) = x
r
i=1
(x ⊕Hi);
3. Perform an encryption querying for (A, (B, T) ⊕Q), if we observe the same
key streams (B ⊕E = B′ ⊕E′), we identify the key K1 as a weak key, which
is a root of q(x) and a member of D ∪0.
Owing to the hash-counter-hash construction of XCB, once observing the
same key streams, q(x) is valid for K1. Then we can utilize q(x) to attack XCB.
Distinguishing Attack Against XCB. Once that K1 or K3 is recognized as
weak key, we can make a distinguishing attack against XCB. Assume q(x) is valid
for K1. We query two tuples (A, B, T) and (A, (B, T)⊕Q), then B⊕E = B′⊕E′,
which can be used to distinguish XCB from tweakable random permutation. The
case is same to K3 for the symmetry of the structure of XCB.
Plaintext-Recovery Attack Against XCB. We can utilize the decryption
querying of XCB to recover plaintext if we have a valid q(x) for K1 or K3.
For obtaining the plaintext of the ciphertext (G∗, E∗) with the tweak T ∗, we
ﬁrstly try to recover part of the plaintext, where q(x) is valid only for K3. We set
G′ = G∗and (E′, T ′) = (E∗, T ∗) ⊕Q. Send (G′, E′) with T ′ to the decryption
oracle, obtain the plaintext (A′, B′). Obviously we get:
B∗⊕E∗= B′ ⊕E′.

Weak-Key and Related-Key Analysis
11
This can be proved as follows. From line 18 in Algorithm 1 we can see that
F ∗= F ′. Along with q(x) is valid for K3, then hK3(E∗, T ∗) = hK3(E′, T ′),
leading to O∗= O′. Clearly the key streams c generates are the same.
Furthermore, we could recover all the plaintext under the special restriction
to q(x), for example, q(x) = I(x)·J(x), where K1 is the root of polynomial I(x)
and K3 is the root of polynomial J(x), then, we will obtain the output:
A∗= A′,
B∗⊕E∗= B′ ⊕E′.
As q(x) is also valid for K1, hK1(B∗, T ∗) = hK1(B′, T ′), along with the result
that O∗= O′, we would obtain the output:
C∗= C′ ⇒A∗= A′.
Key-Recovery Attack Against XCB.
Once we ﬁnd a valid q(x) for K1,
namely K1 ∈D ∪0, we can utilize binary tree search to determine the value
of K1. Divide D
= {H1, H2, · · · , Hr} into two parts: {H1, H2, · · · , Hj} and
{Hj+1, H2, · · · , Hr} (where j = ⌈i
2⌉). Construct two polynomials x
r
t=j+1
(x⊕Ht)
and x
j
t=1
(x⊕Ht). Apply them to the process of identifying weak key respectively.
K1 = 0 if both are valid for K1. Otherwise, keep the successful one, and repeat
above steps log2r times, until ﬁnd the exact key value. Then we recover the key
K1 of XCB. Owing to the structure symmetry, we can recover K3 similar to K1.
From above analysis, we conclude that once the key K1 or K3 of XCB are
recognized as weak keys, namely, we successfully ﬁnd a valid polynomial for
the key K1 or K3, we can make distinguishing attack, key-recovery attack and
plaintext-recovery attack against XCB.
3.3
Related-Key Analysis of XCB
We show that XCB can resist related-key attacks if the underlying block cipher
e is an SPRP-RKA. Assume that ⊕Δ(K) is the related-key transformation to
map K to K ⊕Δ, and that there are t diﬀerent values Δ1, · · · , Δt used in the
related-key transformation when the adversary query the encryption or decryp-
tion oracle. For each Δi (1 ≤i ≤t), the sub-keys are generated like this:
KΔi
0
←eK⊕Δi(0w), KΔi
1
←eK⊕Δi(0w−1∥1), KΔi
2
←eK⊕Δi(0w−2∥1∥0),
KΔi
3
←eK⊕Δi(0w−2∥12), KΔi
4
←eK⊕Δi(0w−3∥1∥02),
where KΔi
j
means the jth sub-key (1 ≤i ≤t). For e is an SPRP-RKA, then
each eK⊕Δi is an independent SPRP, which result in:
(KΔi
0 , KΔi
1 , KΔi
2 , KΔi
3 , KΔi
4 ) is independent for 1 ≤i ≤t, and each one
of them is indistinguishable from the output of random permutation,
which is uniformly random.
Therefore each XCB decided by (KΔi
0 , KΔi
1 , KΔi
2 , KΔi
3 , KΔi
4 ) is not only an
STPRP [1,28,29], but also independent. All in all, XCB is an STPRP-RKA.
www.ebook3000.com

12
Z. Sun et al.
4
Analysis of HCTR
HCTR is an STPRP under the assumption that the underlying block cipher is
an SPRP [2].
4.1
Deﬁnition of HCTR
HCTR is similar to the structure of XCB, hence we use the same notations to
describe it. HCTR is comprised of a block cipher e (d is the inverse function of
e), a polynomial evaluation hash function h, and a CTR function c (similar to
the CTR function in XCB). Diﬀerent from XCB, HCTR has two master keys: K
and H, where K is for block cipher e and H is for polynomial evaluation hash
function h.
Polynomial Hash Function. hH(X) : {0, 1}w × {0, 1}∗→{0, 1}w, len(X) =
w(p−1)+q for 1 ≤q ≤w. Partition X into X1∥X2∥· · · ∥Xp, where len(Xi) = w
for 1 ≤i ≤p −1, 0w−q are appended at the end of X to complete the block,
hH(X) =

H,
if X is an empty string,
X1Hp+1 ⊕· · · ⊕(Xp∥0w−q)H2 ⊕len(X)H,
else.
HCTR is described into two parts: the encryption process HCTR.
EncT
K,H(M) and the decryption part HCTR.DecT
K,H(M), where K ∈{0, 1}k
and H ∈{0, 1}w. See more in Appendix A.
4.2
Weak-Key Analysis of HCTR
In consequence of the hash-counter-hash structure, HCTR suﬀers the same prob-
lems as XCB. According to the previous discussion, D is a weak key class for
HCTR if |D| ≥2 [17]. We can take similar distinguishing attack and key-
recovery attack against HCTR. In addition, the same universal hash key H
for the two layer polynomial evaluation hashes unlike XCB results in a more
simple plaintext-recovery attack than that in XCB.
For obtaining the plaintext of the ciphertext (E∗, D∗) with tweak T ∗. We set
E′ = E∗and (D′, T ′) = (D∗, T ∗) ⊕Q. Send (E′, D′) with T ′ to the decryption
oracle as illustrated in Figure 2, where q(x) is valid for the hash key H, and
obtain the plaintext (A′, B′). We get the following equations:
A∗= A′, B∗⊕D∗= B′ ⊕D′.
This can be proved as follows. From line 16 in Algorithm 2, we can know
that O∗= O′ and C∗= C′ for E′ = E∗and q(x) is valid for H. Clearly the key
streams CTR mode generates are the same for S∗= S′. So B∗⊕D∗= B′ ⊕D′.
Also A∗= A′ for q(x) is valid for H.

Weak-Key and Related-Key Analysis
13
4.3
Related-Key Analysis of HCTR
HCTR can not resist related-key attack. We can distinguish HCTR from a tweak-
able random permutation under the related-key attack within two queries. Next
we present the related-key analysis of HCTR in two diﬀerent cases.
Case 1: B is an Empty String and 0 < len(T ) ≤w. Let A and A′ be two
messages to be encrypted by H and H′ = H ⊕Δ with the same T respectively.
Let A′ = A ⊕T ′Δ2 ⊕len(T)Δ, where T ′ = T∥0w−len(T ). The ciphertexts are E
and E′ respectively.
Then, we get:
C′ = A′ ⊕hH′(T)
= A ⊕T ′Δ2 ⊕len(T)Δ ⊕T ′H′2 ⊕len(T)H′
= A ⊕T ′Δ2 ⊕len(T)Δ ⊕T ′(H ⊕Δ)2 ⊕len(T)(H ⊕Δ)
= A ⊕T ′H2 ⊕len(T)H
= A ⊕hH(T)
= C.
In a similar way, E ⊕E′ = T ′Δ2 ⊕len(T)Δ.
In our attack, T ′Δ2 ⊕len(T)Δ is a constant value we choose. We see that
the ciphertext of A has a speciﬁc relationship with the ciphertext of A′ under
the encryption keys H and H′ respectively, which is a successful related-key
distinguishing attack against HCTR.
In addition to this, we can conduct a plaintext-recovery attack using the
related key. Assume that the plaintext of E with T is needed under the key H,
where D is an empty string. Send E′ = E ⊕T ′Δ2 ⊕len(T)Δ with T to the
decryption oracle under H′(= H ⊕Δ) and obtain the plaintext,
A = A′ ⊕T ′Δ2 ⊕len(T)Δ.
Case 2: T is an Empty String and 0 < len(B) ≤w. Similar to case 1,
we choose M and M ′ to be the two messages encrypted by H and H′ = H ⊕Δ
respectively, where M = (A, B) and M ′ = (A′, B′) = (A ⊕(B∥0w−len(B))Δ2 ⊕
len(B)Δ, B). (E, D) and (E′, D′) are the corresponding ciphertexts. Then, we
draw a conclusion as follows:
E ⊕E′ = (D∥0w−len(B))Δ2 ⊕len(B)Δ,
D = D′.
In our attack, (B∥0w−len(B))Δ2 ⊕len(B)Δ is a constant value that we choose.
Moreover, (D∥0w−len(B))Δ2 ⊕len(B)Δ is also a deterministic value after the
encryption of M. We see that the ciphertext of M has a speciﬁc relationship with
the ciphertext of M ′ under the encryption keys H and H′ = H ⊕Δ respectively,
which is a successful related-key distinguishing attack against HCTR.
www.ebook3000.com

14
Z. Sun et al.
This time, we can also conduct a plaintext-recovery under the related-key
attack. Assume that the plaintext of (E, D) (where 0 < len(D) ≤w) under key
H is needed. Then we send (E′, D′) = (E ⊕(D∥0w−len(D))Δ2 ⊕len(D)Δ, D)
under the key H′ = H ⊕Δ to the decryption oracle, and get the plaintext
(A′, B′):
A = A′ ⊕(B∥0w−len(B))Δ2 ⊕len(B)Δ,
B = B′.
5
Analysis of HCH
HCH [3] is another TES similar to HCTR. More speciﬁcally, HCH has an extra
block cipher call e before the CTR mode c and derive the keys of universal hash
function by using master key encrypting two values like XCB does, T is the
tweak, l is the message length in bits:
R ←eK(T), Q ←eK(R ⊕l).
The polynomial evaluation hash function in HCH is deﬁned as follows,
hR,Q(X1∥X2∥· · · ∥Xp) = Q ⊕X1Rp ⊕X2Rp−1 ⊕· · · ⊕Xp−1R2 ⊕XpR.
See more in Appendix A. There are two variations of HCH: HCHp and HCHfp.
HCHp is designed to utilize pre-computation by using a separate hash key.
HCHfp works for ﬁxed length messages, which can also utilize pre-computation
and further reduce one block cipher invocation. All three schemes are proved to
be secure in the sense that they are indistinguishable from a family of indepen-
dent random permutations labeled by tweaks if the underlying block cipher is a
pseudorandom permutation (PRP).
Owing to the hash-counter-hash structure similar to HCTR, HCH, HCHp
and HCHfp, suﬀer distinguishing attack, key-recovery attack, plaintext-recovery
attack when the key R of polynomial evaluation hash is recognized as weak
key. According to the previous discussion, D is a weak key class for HCH if
|D| ≥2 [17].
HCHp and HCHfp can not resist related-key attack for the similar reason
with HCTR. However HCH can resist related-key attack if the underlying block
cipher eK is an SPRP-RKA. HCH has already been proved to be an STPRP [3].
Also use ⊕Δ(K) as a related-key transformation map K to K ⊕Δ. Assume that
⊕Δ(K) is the related-key transformation to map K to K ⊕Δ, and that there are
t diﬀerent values Δ1, · · · , Δt used in the related-key transformation when the
adversary query the encryption or decryption oracle. For eK is an SPRP-RKA,
then each eK⊕Δi (1 ≤i ≤t) is an independent SPRP, which results in that each
HCH decided by eK⊕Δi is an independent STPRP. So we conclude that HCH is
an STPRP-RKA.

Weak-Key and Related-Key Analysis
15
6
Conclusion
In this paper, we focus on three hash-counter-hash tweakable enciphering scheme
XCB, HCTR and HCH. We point out that once the key of polynomial evalua-
tion hash in these schemes is identiﬁed as weak key, we can make several powerful
attacks on XCB, HCTR and HCH (including two variations of HCH: HCHp and
HCHfp): distinguishing attack, key-recovery attack and plaintext-recovery attack.
Moreover, HCTR, HCHp and HCHfp suﬀer related-key attack, which turns into
distinguishing attack within two queries. We also show that XCB and HCH can
resist related-key attack if the underlying block cipher is related-key secure.
The identiﬁcation of weak key can lead to a lot of serious consequences, like
forgery attack against GCM and distinguishing attack, key-recovery attack and
plaintext-recovery attack presented in this paper. But the process of identiﬁca-
tion is not an easy task. The probability of a successfully identiﬁcation is limited
by the size of the weak-key class. Usually the probability is small enough to be
ignored if the key is uniformly distributed. We stress that the weak-key analysis
does not break the security bounds which have been proved, but it indeed pro-
vides us an alternative way to analyze such schemes once the key for polynomial
evaluation hash is recognized as weak key.
Through the related-key analysis of XCB, HCTR and HCH, we can draw
a conclusion that XCB and HCH provide two typical methods to “inherit” the
related-key security of underlying block cipher, which can be extended to other
schemes. 1) Sub-key generation method. XCB uses a master key to generate sub-
keys by encryptions of block cipher and can be proved to be secure when the
sub-keys are uniformly random. Once a related key is derived by the adversary,
the related-key security of block cipher guarantee that the sub-keys are random
and independent, which lead to an independent scheme with new sub-keys. This
method can turn any secure multiple-key scheme into related-key secure one.
For example if we generate the two key in HCTR using a master key K as
K′ = EK(0w) and H = EK(1w), HCTR is also a related-key secure TES. 2)
Identical one key method. HCH is an one-key scheme and the key is also the key
of underlying block cipher. HCH can be proved to be secure when the underlying
block cipher is secure. Once a related key is derived by the adversary, the related-
key security of block cipher guarantee that diﬀerent related key corresponds to a
new independent PRP, which also leads to an independent scheme. This applies
to some TESes like EME [7], PEP [30], HEH [31], HMCH [32], HOH [32], some
AEes like GCM [33], OCB [34], some MACes like PMAC [35] and OMAC [36].
Acknowledgments. The authors would like to thank the anonymous reviewers for
their helpful comments and suggestions. The work of this paper is supported by the
National Key Basic Research Program of China (2014CB340603), the National Natural
Science Foundation of China (Grants 61272477, 61472415, 61272476), the Strategic
Priority Research Program of Chinese Academy of Sciences under Grant XDA06010702.
www.ebook3000.com

16
Z. Sun et al.
References
1. McGrew, D.A., Fluhrer, S.R.: The extended codebook (XCB) mode of operation.
IACR Cryptology ePrint Archive 2004, 278 (2004)
2. Wang, P., Feng, D., Wu, W.: HCTR: a variable-input-length enciphering mode.
In: Feng, D., Lin, D., Yung, M. (eds.) CISC 2005. LNCS, vol. 3822, pp. 175–188.
Springer, Heidelberg (2005)
3. Chakraborty, D., Sarkar, P.: HCH: a new tweakable enciphering scheme using the
hash-encrypt-hash approach. In: Barua, R., Lange, T. (eds.) INDOCRYPT 2006.
LNCS, vol. 4329, pp. 287–302. Springer, Heidelberg (2006)
4. IEEE Std 1619.2-2010. IEEE standard for wide-block encryption for shared storage
media. IEEE Computer Society (2011)
5. Hoang, V.T., Krovetz, T., Rogaway, P.: Robust authenticated-encryption: AEZ
and the problem that it solves. IACR Cryptology ePrint Archive 2014, 793 (2014)
6. CAESAR: Competition for authenticated encryption: Security, applicability, and
robustness. http://competitions.cr.yp.to/caesar.html
7. Halevi, S., Rogaway, P.: A parallelizable enciphering mode. In: Okamoto, T. (ed.)
CT-RSA 2004. LNCS, vol. 2964, pp. 292–304. Springer, Heidelberg (2004)
8. Mancillas-L´opez, C., Chakraborty, D., Rodr´ıguez-Henr´ıquez, F.: Eﬃcient imple-
mentations of some tweakable enciphering schemes in reconﬁgurable hardware. In:
Srinathan, K., Rangan, C.P., Yung, M. (eds.) INDOCRYPT 2007. LNCS, vol. 4859,
pp. 414–424. Springer, Heidelberg (2007)
9. Carter, L., Wegman, M.N.: Universal classes of hash functions. J. Comput. Syst.
Sci. 18(2), 143–154 (1979)
10. Brassard, G.: On computationally secure authentication tags requiring short secret
shared keys. In: Chaum, D., Rivest, R.L., Sherman, A.T. (eds.) Advances in Cryp-
tology: Proceedings of CRYPTO 1982, pp. 79–86. Plenum Press, New York (1982)
11. Wegman, M.N., Carter, L.: New hash functions and their use in authentication
and set equality. J. Comput. Syst. Sci. 22(3), 265–279 (1981)
12. McGrew, D.A., Viega, J.: The galois/counter mode of operation (GCM) (2004)
13. Chakraborty, D., Nandi, M.: An improved security bound for HCTR. In:
Nyberg, K. (ed.) FSE 2008. LNCS, vol. 5086, pp. 289–302. Springer, Heidelberg
(2008)
14. Handschuh, H., Preneel, B.: Key-recovery attacks on universal hash function
based MAC algorithms. In: Wagner, D. (ed.) CRYPTO 2008. LNCS, vol. 5157,
pp. 144–161. Springer, Heidelberg (2008)
15. Saarinen, M.-J.O.: Cycling attacks on GCM, GHASH and other polynomial MACs
and hashes. In: Canteaut, A. (ed.) FSE 2012. LNCS, vol. 7549, pp. 216–225.
Springer, Heidelberg (2012)
16. Procter, G., Cid, C.: On weak keys and forgery attacks against polynomial-based
MAC schemes. In: Moriai, S. (ed.) FSE 2013. LNCS, vol. 8424, pp. 287–304.
Springer, Heidelberg (2014)
17. Zhu, B., Tan, Y., Gong, G.: Revisiting MAC forgeries, weak keys and provable
security of galois/counter mode of operation. In: Abdalla, M., Nita-Rotaru, C.,
Dahab, R. (eds.) CANS 2013. LNCS, vol. 8257, pp. 20–38. Springer, Heidelberg
(2013)
18. Biham, E.: New types of cryptanalytic attacks using related keys. J. Cryptology
7(4), 229–246 (1994)
19. Knudsen, L.R.: Cryptanalysis of LOKI91. In: Zheng, Y., Seberry, J. (eds.)
AUSCRYPT 1992. LNCS, vol. 718, pp. 196–208. Springer, Heidelberg (1993)

Weak-Key and Related-Key Analysis
17
20. Biham, E., Dunkelman, O., Keller, N.: Related-key boomerang and rectangle
attacks. In: Cramer, R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 507–525.
Springer, Heidelberg (2005)
21. Biryukov, A., Dunkelman, O., Keller, N., Khovratovich, D., Shamir, A.: Key recov-
ery attacks of practical complexity on AES-256 variants with up to 10 rounds. In:
Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 299–319. Springer,
Heidelberg (2010)
22. Bellare, M., Kohno, T.: A theoretical treatment of related-key attacks: RKA-PRPs,
RKA-PRFs, and applications. In: Biham, E. (ed.) EUROCRYPT 2003. LNCS, vol.
2656, pp. 491–506. Springer, Heidelberg (2003)
23. Bhattacharyya, R., Roy, A.: Secure message authentication against related-key
attack. In: Moriai, S. (ed.) FSE 2013. LNCS, vol. 8424, pp. 305–324. Springer,
Heidelberg (2014)
24. Krawczyk, H.: LFSR-based hashing and authentication. In: Desmedt, Y.G. (ed.)
CRYPTO 1994. LNCS, vol. 839, pp. 129–139. Springer, Heidelberg (1994)
25. Bellare, M., Desai, A., Jokipii, E., Rogaway, P.: A concrete security treatment of
symmetric encryption. In: 38th Annual Symposium on Foundations of Computer
Science, FOCS 1997, pp. 394–403. IEEE Computer Society, Miami Beach, 19–22
October 1997
26. Liskov, M., Rivest, R.L., Wagner, D.: Tweakable block ciphers. J. Cryptology
24(3), 588–613 (2011)
27. Halevi, S., Rogaway, P.: A tweakable enciphering mode. In: Boneh, D. (ed.)
CRYPTO 2003. LNCS, vol. 2729, pp. 482–499. Springer, Heidelberg (2003)
28. Chakraborty, D., Hernandez-Jimenez, V., Sarkar, P.: Another look at XCB. IACR
Cryptology ePrint Archive 2013, 823 (2013)
29. McGrew, D.A., Fluhrer, S.R.: The security of the extended codebook (XCB) mode
of operation. IACR Cryptology ePrint Archive 2007, 298 (2007)
30. Chakraborty, D., Sarkar, P.: A new mode of encryption providing a tweakable
strong pseudo-random permutation. In: Robshaw, M. (ed.) FSE 2006. LNCS, vol.
4047, pp. 293–309. Springer, Heidelberg (2006)
31. Sarkar, P.: Improving upon the TET mode of operation. In: Nam, K.-H., Rhee, G.
(eds.) ICISC 2007. LNCS, vol. 4817, pp. 180–192. Springer, Heidelberg (2007)
32. Sarkar, P.: Eﬃcient tweakable enciphering schemes from (block-wise) universal
hash functions. IEEE Transactions on Information Theory 55(10), 4749–4760
(2009)
33. McGrew, D.A., Viega, J.: The security and performance of the galois/counter mode
(GCM) of operation. In: Canteaut, A., Viswanathan, K. (eds.) INDOCRYPT 2004.
LNCS, vol. 3348, pp. 343–355. Springer, Heidelberg (2004)
34. Rogaway, P., Bellare, M., Black, J.: OCB: A block-cipher mode of operation for
eﬃcient authenticated encryption. ACM Trans. Inf. Syst. Secur. 6(3), 365–403
(2003)
35. Rogaway, P.: Eﬃcient instantiations of tweakable blockciphers and reﬁnements to
modes OCB and PMAC. In: Lee, P.J. (ed.) ASIACRYPT 2004. LNCS, vol. 3329,
pp. 16–31. Springer, Heidelberg (2004)
36. Iwata, T., Kurosawa, K.: OMAC: one-key CBC MAC. In: Johansson, T. (ed.) FSE
2003. LNCS, vol. 2887, pp. 129–153. Springer, Heidelberg (2003)
www.ebook3000.com

18
Z. Sun et al.
A
Illustrations of XCB, HCTR and HCH
The following illustrations show XCB, HCTR and HCH.
Algorithm 1. XCB
1: procedure XCB.EncT
K(M)
2:
Partition M into M[1] · · · M[m]
3:
K0 ←eK(0w)
4:
K1 ←eK(0w−1∥1)
5:
K2 ←eK(0w−2∥1∥0)
6:
K3 ←eK(0w−2∥12)
7:
K4 ←eK(0w−3∥1∥02)
8:
A ←M[1]
9:
B ←M[2] · · · M[m]
10:
C ←eK0(A)
11:
O ←C ⊕hK1(B, T)
12:
E ←B ⊕cK2(O)
13:
F ←O ⊕hK3(E, T)
14:
G ←dK4(F)
15:
return G∥E
16: end procedure
17: procedure XCB.DecT
K(C)
18:
Partition C into C[1] · · · C[c]
19:
K0 ←eK(0w)
20:
K1 ←eK(0w−1∥1)
21:
K2 ←eK(0w−2∥1∥0)
22:
K3 ←eK(0w−2∥12)
23:
K4 ←eK(0w−3∥1∥02)
24:
G ←C[1]
25:
E ←C[2] · · · C[c]
26:
F ←eK4(G)
27:
O ←F ⊕hK3(E, T)
28:
B ←E ⊕cK2(O)
29:
C ←O ⊕hK1(B, T)
30:
A ←dK0(C)
31:
return A∥B
32: end procedure
Algorithm 2. HCTR
1: procedure HCTR.EncT
K,H(M)
2:
Partition M into M[1] · · · M[m]
3:
A ←M[1]
4:
B ←M[2] · · · M[m]
5:
C ←A ⊕hH(B∥T)
6:
O ←eK(C)
7:
S ←C ⊕O
8:
D ←cK(S) ⊕B
9:
E ←O ⊕hH(D∥T)
10:
return E∥D
11: end procedure
12: procedure HCTR.DecT
K,H(C)
13:
Partition C into C[1] · · · C[c]
14:
E ←C[1]
15:
D ←C[2] · · · C[c]
16:
O ←E ⊕hH(D∥T)
17:
C ←dK(O)
18:
S ←C ⊕O
19:
B ←D ⊕cK(S)
20:
A ←C ⊕hH(B∥T)
21:
return A∥B
22: end procedure

Weak-Key and Related-Key Analysis
19
Fig. 1. XCB
Fig. 2. HCTR
Fig. 3.
HCH(xQ
=
xQ(x)mod τ(x), τ(x) is
an irreducible polynomial
of degree w)
www.ebook3000.com

Cryptanalysis of Reduced-Round Whirlwind
Bingke Ma1,2,3(B), Bao Li1,2, Ronglin Hao1,2,4, and Xiaoqian Li1,2,3
1 State Key Laboratory of Information Security, Institute of Information
Engineering, Chinese Academy of Sciences, Beijing 100093, China
{bkma,lb,xqli}@is.ac.cn
2 Data Assurance and Communication Security Research Center,
Chinese Academy of Sciences, Beijing 100093, China
3 University of Chinese Academy of Sciences, Beijing, China
4 Department of Electronic Engineering and Information Science,
University of Science and Technology of China, Hefei 230027, China
haorl@mail.ustc.edu.cn
Abstract. The Whirlwind hash function, which outputs a 512-bit
digest, was designed by Barreto et al. and published by Design, Codes
and Cryptography in 2010. In this paper, we provide a thorough crypt-
analysis on Whirlwind. Firstly, we focus on security properties at the
hash function level by presenting (second) preimage, collision and dis-
tinguishing attacks on reduced-round Whirlwind. In order to launch
the preimage attack, we have to slightly tweak the original Meet-in-
the-Middle preimage attack framework on AES-like compression func-
tions by partially ﬁxing the values of the state. Based on this slightly
tweaked framework, we are able to construct several new and interesting
preimage attacks on reduced-round Whirlpool and AES hashing modes
as well. Secondly, we investigate security properties of the reduced-round
components of Whirlwind, including semi-free-start and free-start (near)
collision attacks on the compression function, and a limited-birthday dis-
tinguisher on the inner permutation. As far as we know, our results are
currently the best cryptanalysis on Whirlwind.
Keywords: Cryptanalysis · Hash function · Whirlwind · Whirlpool ·
AES · PGV
1
Introduction
Cryptographic hash functions are widely acknowledged as the Swiss Army Knife
of modern cryptography thanks to its versatility and numerous applications.
A secure hash function should at least preserve three basic security properties,
namely, collision resistance, preimage resistance and second preimage resistance.
Several other security properties are also concerned, such as the limited-birthday
distinguisher on hash functions [11].
This work was supported by the National High Technology Research and Develop-
ment Program of China (863 Program, No.2013AA014002) and the National Natural
Science Foundation of China (No.61379137).
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 20–38, 2015.
DOI: 10.1007/978-3-319-19962-7 2

Cryptanalysis of Reduced-Round Whirlwind
21
In order to hash an input message, many state-of-the-art hash functions divide
the message into many blocks and process each block iteratively with the inner
components. The Merkle-Damg˚ard construction [8,23] is one of the most classi-
cal constructions following this principle, and the underlying component which
processes the message block in the Merkle-Damg˚ard construction is called the
compression function. Security properties of the compression function often have
great impacts on the hash function, thus cryptanalysis of the compression func-
tion is important and meaningful. For the compression function, there are security
notions such as semi-free-start (near) collision, free-start (near) collision 1 and
(pseudo) preimage. Most of the compression functions used in practice are con-
structed with cryptographic permutations adopting proper modes of operation
such as the PGV modes [26]. Security evaluations of the underlying permutation
are quite necessary and helpful in order to know the potential weaknesses, the
security margins which are crucial especially in the design of new primitives and
the validity of the security proofs. A noted example is the limited-birthday distin-
guisher on permutations [9] which has been applied to many symmetric primitives,
including [9,12,13], to name but a few.
The Whirlwind hash function [5] was designed by Barreto et al. and published
by Design, Codes and Cryptography in 2010. It takes messages up to 2256 bits as
inputs and outputs a 512-bit digest. At the high level construction, Whirlwind
adopts a Merkle-Damg˚ard construction with a ﬁnal output transformation. At
the compression function level, it employs an AES-like [7,24] design embedded in
a Davies-Meyer-like mode. The state of the compression function can be seen as
an 8×8 array of 16-bit elements, while the left (resp. right) half of the input state
array is the 512-bit chaining value (resp. message block). Besides the high level
structure of Whirlwind, it has some unique underlying components, i.e., the
interesting 16-bit SBox and the linear layer which are friendly to both software
and hardware implementations. Actually some of its novelty design philosophies
have inﬂuences on several recent works, e.g., its linear layer design based on
the strategy of subﬁeld construction has been further investigated in [1] and
[15]. Although Whirlwind contributes many heuristic and inspiring ideas to the
design of symmetric cryptographic primitives, its concrete security properties
are less evaluated in literature. Besides the analyses provided by the designers
at the compression function level in [5], Riham et al. recently presented second
preimage attacks on 5 and 6 rounds of Whirlwind [2].
Our Contributions. We present a thorough cryptanalysis on Whirlwind.
Firstly, we focus on security properties at the hash function level by present-
ing several attacks on reduced-round versions of the 12-round Whirlwind hash
function, including improved second preimage attack reduced to 6 rounds, the
preimage attack reduced to 4 rounds, the collision attack reduced to 5 rounds,
1 A semi-free-start collision attack aims to ﬁnd two distinct messages (M, M ′) and an
identical chaining value h0 satisfying CF(h0, M) = CF(h0, M ′). A free-start collision
attack searches for two messages (M, M ′) and two chaining values (h0, h′
0) satisfying
CF(h0, M) = CF(h′
0, M ′), and h0 = h′
0 and M0 = M ′
0 do not hold concurrently.
www.ebook3000.com

22
B. Ma et al.
and the limited-birthday distinguisher reduced to 6 rounds. Secondly, security
properties of the reduced-round inner components of Whirlwind are evaluated.
More precisely, we launch semi-free-start collision and free-start near collision
attacks on 6-round and 7-round Whirlwind compression function, and build a
multiple limited-birthday distinguisher [14] on the inner permutation reduced to
9 rounds. Our attacks show that Whirlwind oﬀers a quite comfortable security
margin with respect to existing attacks. The results are summarized in Table 1.
In order to launch the preimage attacks on 4-round Whirlwind, we need
to slightly tweak the original Meet-in-the-Middle preimage attack framework
on AES-like compression functions by partially ﬁxing the values of the state.
Although this small tweak is rather simple, it has several further applications. For
instance, we present two new preimage attacks on 5 and 6 rounds of Whirlpool
[6,10], which signiﬁcantly reduce the preimage lengths compared with previous
attacks [29] (though our attacks require higher time complexities). We also show
the ﬁrst preimage attacks on several PGV hashing modes instantiated with 6-
round AES at the hash function level.
Table 1. Summary of results on Whirlwind †
Target
Attack Type
Rounds
Time
Memory
Ideal
Reference
Hash
Function
(12 rounds)
Preimage
4
2496
2255
2512
Section 3
2497
2208
Second Preimage
5
2449
2128
2512
[2]
6
2505
2112
2512
[2]
6
2497
2128
2512
Section 3
Collision
5
2240
2128
2256
Section 4
4
2128
2128
Full Version [19]
LBD Distinguisher ♦
6
2353
2160
2449
Full Version [19]
Compression
Function
(12 rounds)
SFS. Near Collision ♥
5.5
2176
232
2224
[5]
SFS. Collision ♥
4.5
264
232
2256
[5]
6
2128
2128
2256
Full Version [19]
FS. Near Collision ♣
7
2224
2128
2448
Full Version [19]
Inner
Permutation
MLBD Distinguisher ♠
9
2730
2128
2763
Full Version [19]
(12 rounds)
† : We do not consider the attacks starting from a middle round.
♦: Limited-birthday distinguisher on the hash function.
♥: Semi-free-start (near) collision on the compression function.
♣: Free-start near collision (896 colliding bits out of 1024 bits) on the compression function with
no truncation.
♠: Multiple limited-birthday distinguisher on the permutation.
Structure. The remainder of this paper is organized as follows: Section 2 pro-
vides a brief description of the Whirlwind hash function, and the techniques
utilized in this paper. We present the (second) preimage attacks and the colli-
sion attacks on reduced-round Whirlwind in Section 3 and Section 4 respectively.
Section 5 concludes and summarizes the paper. Due to the space limit, we will
report the additional analyses on reduced-round Whirlwind and its components,
as well as the slightly tweaked Meet-in-the-Middle preimage attack framework

Cryptanalysis of Reduced-Round Whirlwind
23
on AES-like compression functions without truncation and its applications on
Whirlpool and AES hashing modes in the full version of this paper [19].
2
Preliminaries
2.1
The Whirlwind Hash Function
The Whirlwind hash function takes any message up to 2256 bits as input, and out-
puts a 512-bit digest. It adopts the Merkle-Damg˚ard construction with an output
transformation, and the padding algorithm of Whirlwind is MD-strengthening
with a 256-bit length padding L.
The compression function of Whirlwind is an AES-like design and has a
1024-bit state which can be represented by an 8 × 8 array of 16-bit elements.
As depicted in Fig. 1, the compression function CF takes a 512-bit chaining
value ht and a 512-bit message block M t as inputs, and performs the round
function 12 times to derive the 512-bit output chaining value ht+1, namely,
ht+1 = CF(ht, M t). Each round function consists of four maps, which are as
follows:
– SubBytes(γ): process each cell of the state with the 16-bit SBox.
– MixRows(θ): multiply each row of the state array by a matrix.
– Transposition(τ): transpose the k-th column to be the k-th row for k =
0, 1, 2, ..., 7, i.e., transposition of the state array.
– AddRoundConstant(σr): XOR the 1024-bit constant of the r-th round
to the state array.
The designers also provide an alternative understanding for the concatenation
of θ and τ, namely, τ ◦θ as:
– θR: multiply each row of the state array by a matrix in even rounds.
– θC: multiply each column of the state array by a matrix in odd rounds.
Fig. 1. The compression function of Whirlwind
For the remainder of this paper, we will adopt this alternative understanding of
the round function. Now we give detailed algorithm of the compression function
CF.
1. Initialize the state array S0 with the input chaining value ht and the input
message block M t:
S0
i,j = ht
i,j
S0
i+4,j = M t
i,j
, for 0 ≤i < 4, 0 ≤j < 8.
www.ebook3000.com

24
B. Ma et al.
2. Apply 12 iterations of the round function to the initial state S0, and derive
the ﬁnal state S12:
Sk+1 =

(σk ◦θR ◦γ)(Sk), k is even,
(σk ◦θC ◦γ)(Sk), k is odd,
for 0 ≤k < 12.
3. Truncate the ﬁnal state S12 and perform the feed-forward to derive the output
chaining value ht+1:
ht+1
i,j = ht
i,j ⊕S12
i,j, for 0 ≤i < 4, 0 ≤j < 8.
After all message blocks have been processed with the compression function
iteratively, the output transformation is performed to avoid trivial length exten-
sion attacks. Suppose the output chaining value of the last message block is
hLAST, then the ﬁnal 512-bit digest hX is computed as:
hX = CF(hLAST, 0),
with the message block equal to the 8 × 4 null matrix.
2.2
The Meet-in-the-Middle Preimage Attack
The Meet-in-the-Middle (MitM) preimage attack was ﬁrst introduced by Aoki
and Sasaki in their preimage attacks against MD4 and 63-step MD5 [4]. The basic
idea of this technique, which is known as splice-and-cut, aims to divide the target
cipher into two sub-ciphers which can be computed independently. Due to the
feed-forward operations in hash functions, the MitM attack can then be applied.
Several advanced techniques to further improve the basic attack are developed,
such as partial matching [4], partial ﬁxing [4], initial structure [28], indirect
partial matching [3], bicliques [16] and diﬀerential MitM attack [17].
In [27], Sasaki proposed the ﬁrst MitM preimage attack on AES-like compres-
sion functions. Two main techniques were presented, namely, initial structure
in an AES-like compression function and indirect partial matching through an
MixColumn layer. This work was later improved by Wu et al. in [30]. Thanks
to the delicate descriptions of the MitM preimage attack framework on AES-like
compression functions presented in [30], the chunk separations can be easily rep-
resented by introducing several essential integer parameters, and the best attack
parameters can be easily derived through an exhaustive search. In [29], Sasaki
et al. introduced the guess-and-determine approach to extend the basic attack
by one more round.
2.3
The Rebound Attack and the SuperSBox Technique
The rebound attack was ﬁrst introduced by Mendel et al. in their attacks against
reduced-round Whirlpool and Grøstl [20]. It aims to ﬁnd a pair of inputs satis-
fying some unique properties for some speciﬁc (truncated) diﬀerential character-
istics faster than the ideal case. There are two main procedures of the rebound

Cryptanalysis of Reduced-Round Whirlwind
25
attack, namely, the inbound phase and the outbound phase. Let C and D denote
the certain non-full-active diﬀerential forms (normally with very few active cells)
in the inbound phase, and F denote the full-active diﬀerential form, then the
diﬀerentials in the inbound phase of the basic rebound attack can be denoted as
C →F ←D. The available freedom degrees are used to connect these middle
rounds with relatively small amount of computations using the match-in-the-
middle technique. In the outbound phase, solutions from the inbound phase are
propagated both forwards and backwards to connect the diﬀerentials in both
directions.
The SuperSBox technique for the rebound attack was independently intro-
duced in [9,18]. This technique exploits the fact that the non-linear layers
between two rounds, i.e., SB, SR, MC, AC, SB can be computed for each col-
umn independently. Therefore, by constructing the look-up tables for each indi-
vidual column, the SuperSBox technique is able to cover one more full-active
state in the inbound phase, namely, C →F ↔F ←D. The look-up tables built
are hence called the SuperSBoxes.
3
(Second) Preimage Attacks on Reduced-Round
Whirlwind
Firstly, we present the second preimage attack on 6-round Whirlwind with the aid
of the plain MitM preimage attack on AES-like compression functions. Then the
preimage attack on 4-round Whirlwind is illustrated. The whole preimage attack
consists of four steps. In some steps of the attack partial values of the initial state
are ﬁxed, and the plain MitM preimage attack framework on AES-like compression
functions cannot be directly applied under this scenario. Fortunately, we slightly
tweak the original attack framework by partially ﬁxing the values of the state, and
make the preimage attack feasible. Despite the simplicity of this small tweak, its
eﬀectiveness are further stated with several new and interesting preimage attacks
on reduced-round Whirlpool and AES hashing modes.
3.1
Second Preimage Attack on 6-Round Whirlwind
Before describing all attacks, we stress that a single compression function com-
putation (resp. the state bit size of the compression function) is used as the
basic unit of time (resp. memory) throughout this paper. The second preimage
attack on 6-round Whirlwind is less complex and more traditional. As depicted
in Fig. 2, suppose we expect to ﬁnd a second preimage of M1||M2||...||Ms, the
attack procedures can be divided into two phases. In the ﬁrst phase, we ﬁnd
suﬃcient pseudo preimages and derive a set of h′
t+1s for a chaining value in the
middle ht+2. In the second phase, we launch the traditional MitM method [22,
Fact9.99] to convert the pseudo preimages into a second preimage. More pre-
cisely, we choose random values of Mt to compute a set of ht+1s from ht, and
search for a match of ht+1 in the set of h′
t+1s. A second preimage is successfully
constructed if a match is derived.
www.ebook3000.com

26
B. Ma et al.
Fig. 2. Second preimage attack on 6-round Whirlwind
The main task lies in the ﬁrst phase where suﬃcient pseudo preimages have to
be generated. This can be done by utilizing the MitM preimage attack framework
on AES-like compression functions which have been extensively investigated in
[27,29,30]. Without loss of generality, we introduce the plain attack framework
with the MitM preimage attack on 6-round Whirlwind compression function,
and Fig. 3 depicts the basic chunk separation of this attack. Before more details
are illustrated, we deﬁne several notations which are used throughout this paper.
n
Bit size of the digest.
Nc
Bit size of the cell.
Nt
Number of columns (or rows) in the state.
b
Number of blue columns (or rows) in the initial structure, and
r
Number of red columns (or rows) in the initial structure.
c
Number of constant cells in each column (or row) corresponding to
the red column (or row) in the initial structure.
g
Number of guessed rows (or columns, in purple) in the backward
(or forward) computation.
Db
Freedom degrees of the blue chunk in bits.
Dr
Freedom degrees of the red chunk in bits.
Dg
Bit size of the guessed cells.
Dm
Bit size of the match point.
T
Time complexity of the attack.
M
Memory requirement of the attack.
The attack procedures of the ﬁrst phase can be further divided into ﬁve
steps which are elaborated as follows, and the interested readers are referred to
[27,29,30] for more detailed descriptions.
Step 1. Initial Structure. The purpose of the initial structure is to use sev-
eral consecutive rounds as the starting point and divide the target cipher into
two sub-ciphers which can be independently computed. For this purpose, as
shown in Fig. 3, we choose random values for the constants (in grey) which
are used in the linear transformations between states #1 ↔#2, and states
#3 ↔#4. Following the linear relations of the θC and θR operations, com-
pute the values in the initial structure for the forward chunk (in blue) which
has Db freedom degrees and the backward chunk (in red) which has Dr free-
dom degrees. After this step, the compression function is divided into two
independent chunks thanks to the initial structure.

Cryptanalysis of Reduced-Round Whirlwind
27
Step 2. Forward Computation. For all the blue and grey cells at state #4,
the forward chunk can be computed forwards independently until state #5.
Step 3. Backward Computation. For all the red cells at #1, the backward
chunk can be computed backwards independently until state #7. In order
to proceed the backward computation by one more round, the guess-and-
determine strategy is applied at state #6 by guessing the value of g rows.
Step 4. Indirect-Partial-Matching through the MixRow Layer. We
have partial information of the red and blue cells from both directions, and
linear relations of the θC operation can be further exploited at the match
point to perform the indirect-partial-matching between states #5 ↔#7.
Step 5. Recheck. Check whether the guessed cells of the partial match derived
in step 4 are guessed correctly. If so, check whether the partial match is also
a full match. Repeat the above steps 1-5 until a preimage is found.
Fig. 3. Chunk separation for the 6-round pseudo preimage attack
Deriving the Attack Parameters. As studied in [29,30], the attack param-
eters, e.g., (Db, Dr, Dg, Dm) can be easily represented with several predeﬁned
integer parameters (b, r, c, g) as shown in Fig. 3. The attack complexities can be
denoted as follows:
T = 2n(2−Dr + 2Dg−Db + 2Dg−Dm),
M = min{2Dr+Dg, 2Db}.
(1)
We can derive the optimal attack parameters by enumerating all possible values
of (b, r, c, g).
Complexity Analysis. Fig. 3 gives the optimal chunk separation for the pseudo
preimage attack on the compression function, and it requires 2480 time and 2128
memory. In order to balance the overall complexities, we generate 216 pseudo
preimages in the ﬁrst phase. In the second phase of the attack, we compute 2496
ht+1s, and ﬁnd a match with the pseudo preimages generated in the ﬁrst phase
with a high probability. Finally, it would require 2497 time and 2128 memory to
launch a second preimage attack on 6-round Whirlwind.
3.2
Overview of the 4-Round Preimage Attack
Due to the strong impacts introduced by the truncation operation and the par-
tially ﬁxed state of Whirlwind (especially by the output transformation), our
www.ebook3000.com

28
B. Ma et al.
preimage attack can only work up to 4 rounds. The gap between the attacked
rounds of preimage and second preimage attacks demonstrates that the adop-
tions of the truncation operation and the partially ﬁxed state do strengthen
Whirlwind in terms of preimage resistance.
Before describing the details, we give a brief overview of the 4-round preim-
age attack. As depicted in Fig. 4, the three-block preimage attack on 4-round
Whirlwind consists of four steps. In the ﬁrst step, the attack is carried out on the
output transformation, and the given challenge digest hX is inverted. In the sec-
ond step, we invert the chaining value h3, and derive the value of the last message
block M3 which contains the padding part. In the third step, we generate several
pseudo preimages h′
1, and suﬃcient values for the second last message block M2
are obtained simultaneously. In the last step, the traditional MitM method [22,
Fact9.99] which converts pseudo preimages in to a preimage is launched, and we
expect to ﬁnd a match between h1s and h′
1s. If all steps succeed, the three-block
message M1||M2||M3 is a preimage for 4-round Whirlwind.
Fig. 4. Overview of the preimage attack on 4-round Whirlwind
3.3
The Slightly Tweaked MitM Preimage Attack on AES-like
Compression Functions
The main bottlenecks of the preimage attack lie in step 1 and step 2 where
partial values of the initial states are already ﬁxed before launching the attack.
More precisely, in step 1 the rightmost 4 columns of the state are ﬁxed to 0 in the
output transformation. As in step 2, since the preimage we try to build consists
of 3 blocks, and the last block contains 255 message bits and 257 padding bits
according to the MD-strengthening padding algorithm, the rightmost 2 columns
of the state are ﬁxed to the value 512+512+255 = 1279. The plain MitM preim-
age attack framework on AES-like compression functions described in Section 3.1
seems inapplicable in this scenario. Luckily, we can apply a small and simple
tweak which partially ﬁxes the values of the state, and thus make the original
attack framework feasible.
The Tweaked Attack Framework with Truncation. There are two main
diﬀerences in the tweaked attack framework compared to the plain framework,
namely, the partially ﬁxed input state before the ﬁrst round and the truncation
operation carried after the last round. Also notice that the ﬁrst and the last
rounds are connected by the feed-forward operation, thus the initial structure in
the tweaked framework needs to be located carefully between the ﬁrst and the
last rounds. Without loss of generality, we use the attack on 4-round Whirlwind
compression function as an instance to elaborate the tweaked framework, and

Cryptanalysis of Reduced-Round Whirlwind
29
Fig. 5 depicts the basic chunk separation of this attack. Following the deﬁnitions
in Section 3.1, several additional notations need to be speciﬁed before provid-
ing more details. Since the half truncation is performed in Whirlwind, we will
describe the slightly tweaked attack framework under the setting that the output
chaining value is truncated in the following part.
tr
Number of columns (or rows) truncated in the output chaining value.
fi
Number of columns (or rows) ﬁxed in the initial state before the attack.
b1
Number of blue columns (or rows) with partial freedom degrees in the
initial structure.
b2
Number of blue columns (or rows) with full freedom degrees in the
initial structure, we haveb = b1 + b2.
Db1
Freedom degrees of the blue chunk with partial freedom degrees in bits.
Db2
Freedom degrees of the blue chunk with full freedom degrees in bits,
we have Db = Db1 + Db2.
Fig. 5. The tweaked MitM preimage attack framework with truncation
For the sake of simplicity, we only consider the cases where full columns (or
rows) are ﬁxed (resp. truncated) in the initial state (resp. the output chaining
value). Given a speciﬁc attack target, the values of (fi, tr) are preﬁxed before
the attack, and the values of (b1, b2, r, c, g) can be chosen by the attacker in order
to derive optimal attacks. The attack procedures are as follows:
Step 1. Initialization. Set the fi yellow columns in the initial state to the
preﬁxed values, and denote the target digest as hX.
Step 2. Initial Structure. Randomly choose values for the constants which
are denoted in grey in the initial structure. According to the preﬁxed values
in step 1 and the chosen constants in step 2, compute all values for the blue
and red cells in the initial structure. After this step, the compression function
is divided into two independent chunks.
Step 3. Backward Computation. In order to perform the backward compu-
tation, we have to apply the guess-and-determine strategy by guessing g
rows which are denoted in purple at state #1. For all values of the red and
guessed purple cells, compute backwards to the matching point at state #6
and store all partial matching values in a sorted table TL (e.g. hash table).
Step 4. Forward Computation. The blue cells in the forward computation
can be further classiﬁed into two categories. For the b1 columns, their values
are constrained by the constant values in the initial structure, and there are
www.ebook3000.com

30
B. Ma et al.
overall 2Db1 values for these blue cells. Due to the truncation, we have to
ensure r + b1 ≤Nt −tr. For the b2 columns, they can take all 2Db2 possi-
ble values of these blue cells. Combining these two categories, the freedom
degrees in the blue cells are 2Db = 2Db1+Db2. For all values of the blue cells,
compute forwards to the matching point at state #5.
Step 5. Indirect-Partial-Matching. Check whether the partial matching
values derived in step 4 is also in the table TL built in step 3.
Step 6. Recheck. Check whether the guessed cells of the partial match derived
in step 5 are guessed correctly. If so, check whether the partial match is also
a full match. Repeat the above steps 2-6 until a preimage is found.
Complexity Analysis. Note that we can also swap the orders of step 3 and
step 4, and the selection depends on which step requires less memory. Similar
to the plain framework described in Section 3.1, the complexities of the tweaked
attack are as follows:
T = 2n(2−Dr + 2Dg−Db + 2Dg−Dm),
M = min{2Dr+Dg, 2Db}.
We do not provide detailed deductions, but it is convenient to check that the
quartet (Db, Dr, Dg, Dm) can be represented with the integer variables deﬁned
as given in Fig. 5. The optimal attack parameters can be easily achieved by an
exhaustive search for all valid values of (b1, b2, r, c, g) with a preﬁxed (fi, tr).
3.4
Details of the 4-Round Preimage Attack
Step 1. In this step, we need to invert the output transformation and derive
the chaining value h3. Since the right half of the input state #1 is ﬁxed to 0,
and the right half of the output state #2 is truncated, we have to utilize the
tweaked MitM preimage attack framework with truncation under the parameters
(fi, tr) = (4, 4). As shown in Fig. 6, we derive the optimal chunk separation with
parameters (b1, b2, r, c, g) = (3, 0, 1, 7, 3) after an exhaustive search. Finally, it
requires 2496 time and 2208 memory to invert the output transformation of 4-
round Whirlwind. Note that since we need to match a 512-bit target digest, but
there are only 2512 freedom degrees in the input chaining value h3, step 1 will
succeed with probability 1 −e−1.
Fig. 6. Step 1. Invert the output transformation

Cryptanalysis of Reduced-Round Whirlwind
31
Step 2. In this step, given the value of h3, we have to invert the compression
function in order to derive the input chaining value h2 and the last message
block M3 which contains the padding part. Since we aim to build a three-block
preimage, according to the MD-strengthening padding algorithm, the last 257
bits of M3 are ﬁxed to the padding value. Consequently, the 2 rightmost columns
of the initial state are preﬁxed as denoted with yellow in Fig. 7. Note that since
the 256-th bit of M3 has to be ’1’ due to the padding, we lose one bit free-
dom degree of the blue chunks. We utilize the tweaked MitM preimage attack
framework with truncation under the parameters (fi, tr) = (2, 4), and exhaus-
tively search for all valid values of (b1, b2, r, c, g). The chunk separation with
(b1, b2, r, c, g) = (0, 2, 4, 7, 3) as shown in Fig. 7 is the best result achieved. As
a result, step 2 requires 2449 time and 2255 memory. Since step 2 requires much
less computations than step 1, one can also carry out step 2 with parameters
(b1, b2, r, c, g) = (3, 2, 1, 7, 3) to minimize the memory requirement. The corre-
sponding complexities are (T, M) = (2496, 2208).
Fig. 7. Step 2. Derive the last message block
Step 3. In this step, given the value of h2, we have to invert the compression
function in order to derive the value of the second message block M2 and the
input chaining value h1. The only constraint of this step is the ﬁnal truncation,
thus the traditional MitM preimage attack can be launched. We omit these
details. As depicted in Fig. 8, with parameters (b, r, c) = (5, 3, 4), the attack
is optimized with complexities (T, M) = (2320, 2192). Since we will perform the
traditional MitM procedure [22, Fact9.99] to convert the pseudo preimages into
a preimage in step 4, we have to generate and store multiple say 2x pairs of
(h1, M2), which require 2320+x time and 2x memory.
Fig. 8. Step 3. Generate suﬃcient values for the second last message block
Step 4. In this step, we launch the traditional MitM method to connect the
values of h′
1 generated in step 3. More precisely, we choose random values of M1
and compute the corresponding output chaining values h1, then match it with
the values of h′
1 generated in step 3. After choosing 2512−x distinct values of M1,
we expect to ﬁnd a match and ﬁnally derive a preimage of 4-round Whirlwind.
Since each h1 can be checked on the ﬂy, the memory requirement for step 4 is
www.ebook3000.com

32
B. Ma et al.
negligible. We choose x = 96 to minimize the overall time complexity for step 3
and step 4 which is 2512−96 + 2320+96 = 2417.
Complexity Analysis. Now to sum up, the time complexity is dominated by
step 1, and the memory requirement is dominated by step 2. Finally, the com-
plexities for the 4-round preimage attack are (T, M) = (2496, 2255). One can also
minimize the memory requirement by adopting the alternative attack parameters
provided in step 2, which results in complexities of (T, M) = (2497, 2208).
4
Collision Attacks on Reduced-Round Whirlwind
This section presents the collision attack on 4- and 5-round Whirlwind hash func-
tion. Due to the Davies-Meyer-like mode of Whirlwind, it is feasible to launch
semi-free-start or free-start collision attacks on the reduced-round compression
function with the rebound attack, but deriving a collision attack at the hash
function level seems diﬃcult. Fortunately, with the aid of the multi-block strat-
egy, we are able to launch collision attacks on 4 and 5 rounds of the Whirlwind
hash function. We only describe the 5-round attack, and the 4-round attack is
reported in the full version of this paper [19].
4.1
Overview of the 5-Round Collision Attack
The previous collision attacks on Grindahl [25] and Grøstl [21] generate col-
liding messages which contain several consecutive message blocks. The general
strategy in these attacks is after introducing the diﬀerences into the chaining
values, the diﬀerences are gradually cancelled with the posterior message blocks,
and eventually lead to collisions by eliminating the diﬀerences in the output
chaining values. Our attack is based on a similar multi-step process which grad-
ually introduces, restricts and ﬁnally cancels the diﬀerences. As shown in Fig. 9,
the overall attack consists of three steps and outputs a 3-block colliding pair,
and each step targets on a certain message block.
Before providing more detailed descriptions of the collision attack, it is
necessary to specify several notations used. As depicted in Fig. 9, we use
ΔSt = St⊕St′ to denote the diﬀerence between two states St and St′. LEFT(St)
and RIGHT(St) denote the left half and the right half of the state St respectively.
Also note that in the ﬁgures of the collision attacks, active (resp. inactive) cells
are denoted in grey (resp. white). The red cells correspond to the input message
blocks which can be freely controlled by the attacker, and the green cells in the
output chaining value of the compression function are truncated. The overall
collision attack consists of three steps, and the collision pair has three blocks,
i.e., (M1||M2||M3, M1||M ′
2||M ′
3).

Cryptanalysis of Reduced-Round Whirlwind
33
Fig. 9. Collision attack on 5-round Whirlwind
Step 1. Provide the freedom degrees. The purpose of the ﬁrst step is to
provide suﬃcient freedom degrees for the subsequent two steps. We randomly
choose the values of the ﬁrst message block M1 and compute the output
chaining values LEFT(T1).
Step 2. Introduce the input diﬀerences and restrict the outpu diﬀer-
ences. We introduce the input diﬀerences by choosing diﬀerent values for
the second message block, i.e., (M2, M ′
2), such that the diﬀerence of the
output chaining values for the second compression function call, namely,
LEFT(ΔT2), satisﬁes that LEFT(ΔT2) = LEFT(ΔQ2), where ΔQ2 = θR(ΔP2)
and the diﬀerence of P2 only lies in the ﬁrst column.
Step 3. Cancel the output diﬀerences. We need to generate the message
block pair (M3, M ′
3), such that the output diﬀerence of the permutation
for the third compression function call, namely, LEFT(ΔQ3), satisﬁes that
ΔQ3 = θR(ΔP3), where the diﬀerence of P3 only lies in the ﬁrst column. It
is clear that the values of ΔQ2 and ΔQ3 are in the same subspace thanks
to their unique diﬀerential forms, and moreover, if ΔP2 = ΔP3 is satisﬁed,
we can directly deduct that ΔQ2 = ΔQ3 due to the linear properties of
θR. Consequently, the output diﬀerence of the third compression function
call, namely, LEFT(ΔT3) will be 0, since we have LEFT(ΔT3) = LEFT(ΔT2) ⊕
LEFT(ΔQ3) = LEFT(ΔQ2) ⊕LEFT(ΔQ3) due to the feed-forward operation.
Finally, appending any identical message blocks which satisfy padding to
(M1||M2||M3, M1||M ′
2||M ′
3) will lead to a collision on the hash function.
4.2
Impacts of the Partially Fixed States
As shown in Fig. 9, partial values of the input states are ﬁxed in the last two
steps of the attack. More precisely, the left half of S2 is ﬁxed to LEFT(T1) in
the second step of the attack, and the left half of the paired values S3 are ﬁxed
www.ebook3000.com

34
B. Ma et al.
to LEFT(T2) and LEFT(T ′
2) in the last step of the attack. Since the SuperSBox
technique is utilized at the input states of the last two steps, it is essential to
discuss the impacts brought by the partially ﬁxed states.
Fig. 10. Illustrations of the tweaked SuperSBox technique with partially ﬁxed states
Without loss of generality, we use the inbound phase of step 3 which con-
nects S3 and U3 as an instance to discuss a similar and generalized problem as
depicted in Fig. 10. Suppose that both the diﬀerences and the values of the Nf
grey columns in S3 are ﬁxed, and the diﬀerences and the values of the Nt −Nf
remaining red columns in S3 can be freely chosen. According to the SuperSBox
technique, the three layers γ →θR →γ can be seen as Nt parallel row-wise
SuperSBoxes, namely, SSB0, SSB1, ..., SSBNt−1. Regarding some of the deﬁni-
tions in Section 3.1, the exact attack steps of the tweaked SuperSBox technique
with partially ﬁxed states are as follows:
1. From the forward direction, for every diﬀerence of the red cells in SSB0,
we enumerate all 2Nc(Nt−Nf ) possible values conforming to this diﬀerence,
and compute the corresponding values and diﬀerences in γ(W3). We save
them in a sorted table. Since we can enumerate all 2Nc(Nt−Nf ) diﬀerences
in SSB0, so the lookup table of SSB0 has at most 22Nc(Nt−Nf ) entries. For
the remaining Nt −1 SuperSBoxes, the procedures are similar.
2. From the backward direction, we select a random diﬀerence of U3, and com-
pute it backwards to get the value of θ−1
C (ΔU3). We match this diﬀerence
with the Nt SuperSBox tables built in step 1. Since a NcNt-bit diﬀerence
needs to be matched for each SuperSBox, two diﬀerent cases need to be
considered:
Case 1. The number of entries in each table is insuﬃcient to derive a NcNt-
bit match, namely, 2Nc(Nt −Nf) < NcNt (equivalent to 2Nf > Nt).
In this case, we have to compute 2NcNt−2Nc(Nt−Nf ) = 2Nc(2Nf −Nt)
diﬀerences of θ−1
C (ΔU3) to derive a match for a single SuperSBox. Con-
sequently, in order to derive a match for all Nt SuperSBoxes simultane-
ously, we have to choose 2NcNt(2Nf −Nt) diﬀerent values of θ−1
C (ΔU3).
Since there are overall 2NcNt possible diﬀerences of U3, if NcNt <
NcNt(2Nf −Nt) which is equivalent to 2Nf > Nt + 1, we are not able
to derive a match for all the SuperSBoxes at the same time.
Case 2. The number of entries in each table is suﬃcient to derive a match,
namely, 2Nc(Nt −Nf) ≥NcNt (equivalent to 2Nf ≤Nt). In this case,
instead enumerating all diﬀerences and values of the red cells in each
row of S3, we only need to select suﬃecient say 2X diﬀerences of the
red cells, and exhaust all 2X+Nc(Nt−Nf ) corresponding values for each

Cryptanalysis of Reduced-Round Whirlwind
35
SuperSBox. We choose X + Nc(Nt −Nf) = NcNt (equivalent to X =
NcNf), because we only need to match a NcNt-bit diﬀerence for each
SuperSBox. It requires 2NcNt time and memory to generate and store the
Nt SuperSBoxes tables. Given a speciﬁc diﬀerence θ−1
C (ΔU3), we expect
to get a match for each of the Nt SuperSBoxes simultaneously, thus derive
a solution for the inbound phase. After exhausting all 2NcNt diﬀerences
of U3, we expect to get 2NcNt solutions for the inbound phase with
2NcNt time and memory. Since there are overall 22NcNt(Nt−Nf ) diﬀerences
and corresponding values of the red cells S3, and Nt active cells in U3,
we can generate at most 22NcNt(Nt−Nf )−NcNt(Nt−1) = 2NcNt(Nt−2Nf +1)
solutions for the inbound phase.
To summarize the above analysis, if 2Nf ≤Nt, we can generate 2NcNt
solutions for the inbound phase with 2NcNt time and memory, and at most
2NcNt(Nt−2Nf +1) solutions can be generated for the inbound phase. Otherwise if
2Nf > Nt, the attack would be infeasible due to the lack of freedom degrees.
4.3
Details of the Collision Attack
For Whirlwind, Nc = 16, Nt = 8, Nf = 4 which satisﬁes the condition discussed
in Section 4.2, and the SuperSBox technique can be adapted. We illustrate the
detailed procedures of the 5-round collision attack as shown in Fig. 9.
Step 1. From the speciﬁed IV , we choose a random value for the ﬁrst message
block M1, and compute its output chaining value which is LEFT(T1) due to
the truncation.
Step 2. From LEFT(T1), we utilize the SuperSBox technique by exploiting the
freedom degrees in both the values and the diﬀerences of M2 in the inbound
phase (in red). We get 2128 solutions for the inbound phase with 2128 time
and 2128 memory. Based on the analysis in Section 4.2, the overall num-
ber of solutions for the inbound phase is 2128. The probability of the out-
bound phase (in blue) is 2−16×7 = 2−112, thus we expect to get 216 pairs of
(M2, M ′
2).
Step 3. From a speciﬁc pair of LEFT(T2) and LEFT(T ′
2) which is generated in
step 2, we utilize the SuperSBox technique by exploiting the freedom degrees
in both the values and the diﬀerences of M3 in the inbound phase (in red).
We get 2128 solutions for the inbound phase with 2128 time and 2128 memory.
The probability of the outbound phase (in blue) is 2−16×7 = 2−112, and we
need to guarantee ΔP3 = ΔP2 which happens with probability 2−16×8 =
2−128 in order to eliminate the diﬀerence. So we need 2240 solutions from
the inbound phase of step 3, and the freedom degrees seem insuﬃcient. By
choosing 296 diﬀerent values of M1 in step 1, and combining the 216 solutions
(LEFT(T2), LEFT(T ′
2)) generated in step 2 for each value of M1, the overall
number of solutions reaches 296+16+128 = 2240, and we expect to derive a
collision.
www.ebook3000.com

36
B. Ma et al.
Complexity Analysis. As illustrated above, it requires 2240 compression func-
tion computations to generate a collision for 5-round Whirlwind. The memory
requirement is 2128 due to the SuperSBox technique.
5
Conclusion
We provide a thorough security analysis of Whirlwind. Firstly, we focus on
security properties at the hash function level, and present 6-round second preim-
age, 4-round preimage, 5-round collision and 6-round distinguishing attacks out
of the 12-round hash function. Then we investigate security properties of the
Whirlwind components with several reduced-round attacks on the compression
function and the underlying permutation.
Moreover, we show how to generate preimages with signiﬁcantly reduced
lengths for reduced-round versions of Whirlpool, and also present the ﬁrst
preimage attacks at the hash function level for several PGV modes instantiated
with 6-round AES.
Acknowledgments. We would like to thank the anonymous reviewers of ACISP 2015
for their valuable comments and suggestions.
References
1. Albrecht, M.R., Driessen, B., Kavun, E.B., Leander, G., Paar, C., Yal¸cın, T.: Block
ciphers – focus on the linear layer (feat. PRIDE). In: Garay, J.A., Gennaro, R.
(eds.) CRYPTO 2014, Part I. LNCS, vol. 8616, pp. 57–76. Springer, Heidelberg
(2014)
2. AlTawy, R., Youssef, A.: Second preimage analysis of whirlwind. In: Lin, D.,
Yung, M., Zhou, J. (eds.) Inscrypt 2014. LNCS, vol. 8957, pp. 311–328. Springer,
Switzerland (2015)
3. Aoki, K., Guo, J., Matusiewicz, K., Sasaki, Y., Wang, L.: Preimages for step-
reduced SHA-2. In: Matsui, M. (ed.) ASIACRYPT 2009. LNCS, vol. 5912,
pp. 578–597. Springer, Heidelberg (2009)
4. Aoki, K., Sasaki, Y.: Preimage attacks on one-block MD4, 63-step MD5 and
more. In: Avanzi, R.M., Keliher, L., Sica, F. (eds.) SAC 2008. LNCS, vol. 5381,
pp. 103–119. Springer, Heidelberg (2009)
5. Barreto, P., Nikov, V., Nikova, S., Rijmen, V., Tischhauser, E.: Whirlwind: a
new cryptographic hash function. In: Designs, Codes and Cryptography, vol. 56,
pp. 141–162. Springer, US (2010)
6. Barreto, P., Rijmen, V.: The Whirlpool Hashing Function. Submitted to NESSIE
(2000). http://www.larc.usp.br/pbarreto/WhirlpoolPage.html
7. Daemen, J., Rijmen, V.: The Design of Rijndael: AES - the Advanced Encryption
Standard. Springer, Heidelberg (2002)
8. Damg˚ard, I.B.: A design principle for hash functions. In: Brassard, G. (ed.)
CRYPTO 1989. LNCS, vol. 435, pp. 416–427. Springer, Heidelberg (1990)
9. Gilbert, H., Peyrin, T.: Super-sbox cryptanalysis: improved attacks for AES-
like permutations. In: Hong, S., Iwata, T. (eds.) FSE 2010. LNCS, vol. 6147,
pp. 365–383. Springer, Heidelberg (2010)

Cryptanalysis of Reduced-Round Whirlwind
37
10. International Organization for Standardization: ISO/IEC 10118–1:2004: Informa-
tion technology - Security techniques - Hash-functions - Part 3: Dedicated hash-
functions (2004)
11. Iwamoto, M., Peyrin, T., Sasaki, Y.: Limited-birthday distinguishers for hash func-
tions. In: Sako, K., Sarkar, P. (eds.) ASIACRYPT 2013, Part II. LNCS, vol. 8270,
pp. 504–523. Springer, Heidelberg (2013)
12. Jean, J., Naya-Plasencia, M., Peyrin, T.: Improved rebound attack on the ﬁnalist
grøstl. In: Canteaut, A. (ed.) FSE 2012. LNCS, vol. 7549, pp. 110–126. Springer,
Heidelberg (2012)
13. Jean, J., Naya-Plasencia, M., Peyrin, T.: improved cryptanalysis of AES-like per-
mutations. In: J. Cryptology, pp. 1–27. Springer, US (2013)
14. Jean, J., Naya-Plasencia, M., Peyrin, T.: Multiple limited-birthday distinguishers
and applications. In: Lange, T., Lauter, K., Lisonˇek, P. (eds.) SAC 2013. LNCS,
vol. 8282, pp. 533–550. Springer, Heidelberg (2014)
15. Khoo, K., Peyrin, T., Poschmann, A.Y., Yap, H.: FOAM: searching for hardware-
optimal SPN structures and components with a fair comparison. In: Batina,
L., Robshaw, M. (eds.) CHES 2014. LNCS, vol. 8731, pp. 433–450. Springer,
Heidelberg (2014). http://eprint.iacr.org/2014/530
16. Khovratovich, D., Rechberger, C., Savelieva, A.: Bicliques for preimages: attacks
on skein-512 and the SHA-2 family. In: Canteaut, A. (ed.) FSE 2012. LNCS,
vol. 7549, pp. 244–263. Springer, Heidelberg (2012)
17. Knellwolf, S., Khovratovich, D.: New preimage attacks against reduced SHA-1. In:
Safavi-Naini, R., Canetti, R. (eds.) CRYPTO 2012. LNCS, vol. 7417, pp. 367–383.
Springer, Heidelberg (2012)
18. Lamberger, M., Mendel, F., Rechberger, C., Rijmen, V., Schl¨aﬀer, M.: Rebound dis-
tinguishers: results on the full whirlpool compression function. In: Matsui, M. (ed.)
ASIACRYPT 2009. LNCS, vol. 5912, pp. 126–143. Springer, Heidelberg (2009)
19. Ma, B., Li, B., Hao, R., Li, X.: Cryptanalysis of Reduced-Round Whirlwind. Cryp-
tology ePrint Archive (2015)
20. Mendel, F., Rechberger, C., Schl¨aﬀer, M., Thomsen, S.S.: The rebound attack:
cryptanalysis of reduced whirlpool and grøstl. In: Dunkelman, O. (ed.) FSE 2009.
LNCS, vol. 5665, pp. 260–276. Springer, Heidelberg (2009)
21. Mendel, F., Rijmen, V., Schl¨aﬀer, M.: Collision attack on 5 rounds of grøstl. In:
Cid, C., Rechberger, C. (eds.) FSE 2014. LNCS, vol. 8540, pp. 509–521. Springer,
Heidelberg (2015)
22. Menezes, A.J., Van Oorschot, P.C., Vanstone, S.A.: Handbook of Applied Cryp-
tography. CRC Press (2010)
23. Merkle, R.C.: One way hash functions and DES. In: Brassard, G. (ed.) CRYPTO
1989. LNCS, vol. 435, pp. 428–446. Springer, Heidelberg (1990)
24. National Institute of Standards and Technology (NIST): FIPS-197: Advanced
Encryption Standard. Federal Information Processing Standards Publication 197,
U.S. Department of Commerce, November 2001. http://csrc.nist.gov/publications/
ﬁps/ﬁps197/ﬁps-197.pdf
25. Peyrin, T.: Cryptanalysis of grindahl. In: Kurosawa, K. (ed.) ASIACRYPT 2007.
LNCS, vol. 4833, pp. 551–567. Springer, Heidelberg (2007)
26. Preneel, B., Govaerts, R., Vandewalle, J.: Hash functions based on block ciphers:
a synthetic approach. In: Stinson, D.R. (ed.) CRYPTO 1993. LNCS, vol. 773,
pp. 368–378. Springer, Heidelberg (1994)
27. Sasaki, Y.: Meet-in-the-middle preimage attacks on AES hashing modes and
an application to whirlpool. In: Joux, A. (ed.) FSE 2011. LNCS, vol. 6733,
pp. 378–396. Springer, Heidelberg (2011)
www.ebook3000.com

38
B. Ma et al.
28. Sasaki, Y., Aoki, K.: Finding preimages in full MD5 faster than exhaustive search.
In: Joux, A. (ed.) EUROCRYPT 2009. LNCS, vol. 5479, pp. 134–152. Springer,
Heidelberg (2009)
29. Sasaki, Y., Wang, L., Wu, S., Wu, W.: Investigating fundamental security require-
ments on whirlpool: improved preimage and collision attacks. In: Wang, X.,
Sako, K. (eds.) ASIACRYPT 2012. LNCS, vol. 7658, pp. 562–579. Springer,
Heidelberg (2012)
30. Wu, S., Feng, D., Wu, W., Guo, J., Dong, L., Zou, J.: (Pseudo) Preimage attack on
round-reduced grøstl hash function and others. In: Canteaut, A. (ed.) FSE 2012.
LNCS, vol. 7549, pp. 127–145. Springer, Heidelberg (2012)

Improving the Biclique Cryptanalysis of AES
Biaoshuai Tao(B) and Hongjun Wu(B)
Nanyang Technological University, Singapore, Republic of Singapore
taob0001@e.ntu.edu.sg, wuhj@ntu.edu.sg
Abstract. Biclique attack is currently the only key-recovery attack on
the full AES with a single key. Bogdanov et al. applied it to all the three
versions of AES by constructing bicliques with size 28 × 28 and reducing
the number of S-boxes computed in the matching phase. Their results
were improved later by better selections of diﬀerential characteristics in
the biclique construction. In this paper, we improve the biclique attack
by increasing the biclique size to 216×28 and 216×216. We have a biclique
attack on each of the following AES versions:
– AES-128 with time complexity 2126.13 and data complexity 256,
– AES-128 with time complexity 2126.01 and data complexity 272,
– AES-192 with time complexity 2189.91 and data complexity 248, and
– AES-256 with time complexity 2254.27 and data complexity 240.
Our results have the best time complexities among all the existing key-
recovery attacks with data less than the entire code book.
Keywords: AES · Biclique attack · Large biclique
1
Introduction
Rijndael was selected as the Advanced Encryption Standard (AES) in 2001 [13].
AES is widely used today since it is strong in security and eﬃcient in both soft-
ware and hardware. AES was designed to resist diﬀerential, linear cryptanalysis
and square attacks. The best impossible diﬀerential attack (ﬁrst introduced in
[2]) can break 7-round AES-128 [22], and the best square attack can break 8-
round AES-192 [14]. The recent meet-in-the-middle (MITM) attack can break
9-round AES-192 and AES-256 [20]. The related-key attacks are powerful against
AES [3–6,15,17], but the related-key attacks have limited impact on the security
of AES when the secret keys in AES are generated securely.
The ﬁrst key-recovery attack on the full AES with single key is the biclique
attack [9]. Biclique attack on AES is faster than brute force by a factor of three
to four. Biclique attack can be considered as an enhanced version of the meet-
in-the-middle (MITM) attack. It was ﬁrst introduced in the preimage attacks
against hash functions Skein and SHA-2 [19]. After being applied to AES, the
biclique attack was applied to attack other block ciphers, such as ARIA [1,11],
Hight [16], IDEA [18], Piccolo [23], SQUARE [21], Twine [12].
Although the idea in [9] is revolutionary, both the time complexities and the
data complexities of the attacks in [9] have room for improvement by better
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 39–56, 2015.
DOI: 10.1007/978-3-319-19962-7 3
www.ebook3000.com

40
B. Tao and H. Wu
selections of diﬀerential characteristics in the biclique construction. This has
been illustrated in [1,7,8].
The independent-biclique paradigm can be further improved in time com-
plexity by the sieve-in-the-middle (SIM) technique [10], a clever way to further
speed up the matching computation by precomputing and storing the possible
transitions for the middle superbox in a table of size 232, but with the extra cost
of accessing large lookup tables is introduced.
In this paper, we improve the independent-biclique paradigm in [9] by using
larger bicliques. We improve the time complexities for all the three AES versions.
We also obtain improvements in data complexity for AES-128. Our results are
summarized in Table 1 with comparison to the previous results. Among all the
existing attacks which have data complexities that are less than 2128, our results
have minimum time complexities. Notice that our results can be naturally com-
bined with sieve-in-the-middle (SIM) technique as shown in Table 1, which is
further discussed in Sect. 7.
Table 1. Summary of our results
algorithm
data
computation
memory
computation
memory
reference
without SIM
in bytes
with SIM
in bytes
288
2126.21
214.32
-
-
[9]
24
2126.89
214.32
-
-
[8]
AES-128
272
2126.72
214.32
-
-
[1]
previous results
-
-
-
2126.01 (2125.69)1
264
[10]
2
2126.67
214.32
2126.59
264
[7]2
264
2126.16
214.32
2126.01
264
[7]
AES-128
256
2126.13
222.07
2125.99
264
Sect. 4
our results
272
2126.01
226.14
2125.87
264
Appendix A
280
2190.16(2189.74)3
214.39
-
-
[9]
AES-192
248
2190.28
214.39
-
-
[1]
previous results
-
-
-
2190.04
264
[10]
2
2190.9
214.39
2190.83
264
[7]
248
2190.16
214.39
2190.05
264
[7]
AES-192
our results
248
2189.91
222.27
2189.76
264
Appendix B
240
2254.58(2254.42)4
214.54
-
-
[9]
AES-256
264
2254.53
214.54
-
-
[1]
previous results
-
-
-
2254.51
264
[10]
3
2255
214.54
2254.94
264
[7]
240
2254.31
214.54
2254.24
264
[7]
AES-256
our results
240
2254.27
222.61
2254.18
264
Appendix B
1 Our analysis shows that the time complexity to be 2126.01 instead of 2125.69 claimed in [10],
based on the same criteria used in Sect. 4.5.
2 The results with data complexity 2128 in [7] are not shown here, as we do not discuss the attack
with entire code book in this paper.
3 The accurate result is 2190.16 instead of 2189.74 originally claimed, as already corrected in [1].
4 The accurate result is 2254.58 instead of 2254.42 originally claimed, as already corrected in [7].

Improving the Biclique Cryptanalysis of AES
41
This paper is organized as follows. The biclique attack on AES is introduced
in Sect. 2. Section 3 gives an overview of our biclique attack on AES. Our detailed
biclique attack on AES-128 is given in Sect. 4. Section 5 gives comparisons with
our results to the previous ones. We verify our results in Sect. 6, and combine
our results to the sieve-in-the-middle technique in Sect. 7. Section 8 concludes
the paper.
2
The Biclique Attack
In this section, we give the general description of the biclique attack against
block ciphers.
2.1
The Biclique
Consider a block cipher e which maps plaintext P to ciphertext C. Assume that
the cipher can be decomposed as e = g2 ◦f ◦g1:
e : P −→
g1 S −→
f
T −→
g2 C.
Consider 2d1 intermediate states {Si : i = 0, 1, . . . , 2d1 −1}, 2d2 interme-
diate states {Tj : j = 0, 1, . . . , 2d2 −1} and 2d1+d2 keys {K[i, j]}. The 3-
tuple ({Si}, {Tj}, {K[i, j]}) is called a biclique, if Si
K[i,j]
−−−−→
f
Tj for all i ∈
{0, 1, . . . , 2d1 −1} and all j ∈{0, 1, . . . , 2d2 −1}. Here K[i, j] maps the state
Si to the state Tj by the subcipher f.
In most of the attacks against AES as well as ours, bicliques are constructed
“at the end”, in which case g2 is the identity map and {Tj} becomes ciphertexts
set {Cj}. Correspondingly, the biclique takes the form ({Si}, {Cj}, {K[i, j]}).
Bicliques “in the middle” are also considered in [7]. However, attacks based on
such bicliques usually require extremely high data complexities, as the diﬀerences
in {Tj} will propagate to ciphertexts (refer to [7] for examples in AES).
Deﬁne the length of a biclique be the number of rounds covered by f, and
the size be 2d1 × 2d2. In the original attack [9] and most of the subsequent
improvements, bicliques of size 28 × 28 are constructed in all the three versions
of AES. In [7], bicliques of size 216 ×1, i.e. stars, are also considered. The attack
with stars only requires minimal data, but the time complexity becomes higher
(refer to Table 1, the rows with data complexities 2 or 3). In our attack, the size
of bicliques is enlarged to 216 × 28, and even to 216 × 216 for AES-128.
2.2
Outline of the Biclique Attack
As mentioned in the last section, we focus on the attack with g2 being the identity
map in which the biclique is “at the end”. In this case, the biclique attack can
be sketched as follows:
1. Partition: Partition 2n keys into 2n−(d1+d2) sets of size 2d1+d2.
www.ebook3000.com

42
B. Tao and H. Wu
2. Biclique Construction: For each partition {K[i, j]}, construct biclique
({Si}, {Cj}, {K[i, j]}).
3. Oracle Decryption: Decrypt 2d2 ciphertexts {Cj} by the oracle with the
secret key to obtain the corresponding 2d2 plaintexts {Pj}.
4. Matching: for each pair (Pj, Si), if Pj
K[i,j]
−−−−→
g1
Si, K[i, j] is a candidate.
In the following sections, we introduce in details how the bicliques can be
constructed, and how we can reduce the time complexity for the matching step
(Step 4) by using a technique called matching with precomputation in [9].
2.3
Constructing Bicliques from Independent Related-Key
Diﬀerentials
Two biclique attack paradigms are shown in [9], long biclique and indepen-
dent biclique. We will only focus on independent biclique, as long-biclique-based
attack currently cannot work for full AES.
Fix a tuple (S0, C0, K[0, 0]) where K[0, 0] maps S0 to C0, and we aim to ﬁll
in the other 2d1 −1 intermediate states, 2d2 −1 ciphertexts and 2d1+d2 −1 keys
to get a biclique. Consider the following two sets of related-key diﬀerentials with
respect to the base computation S0
K[0,0]
−−−−→
f
C0:
– Δj-diﬀerential: It maps a zero input diﬀerence to an output diﬀerence Δj
under a key diﬀerence ΔK
j :
0
ΔK
j
−−→
f
Δj with ΔK
0 = 0 and Δ0 = 0, where j = 0, 1, . . . , 2d2 −1;
– ∇i-diﬀerential: It maps an input diﬀerence ∇i to a zero output diﬀerence
under a key diﬀerence ∇K
i :
∇i
∇K
i
−−→
f
0 with ∇K
0 = 0 and ∇0 = 0, where i = 0, 1, . . . , 2d1 −1.
According to [9], if the characteristics of Δj-diﬀerentials do not share active
nonlinear components (which are S-boxes in our case of AES) with the charac-
teristics of ∇i-diﬀerentials, then the tuple (S0, C0, K[0, 0]) will conform to all
the 2d1+d2 combined (Δj, ∇i)-diﬀerentials:
∇i
ΔK
j ⊕∇K
i
−−−−−−→
f
Δj for i ∈{0, 1, . . . , 2d1 −1} and j ∈{0, 1, . . . , 2d2 −1},
which means
S0 ⊕∇i
K[0,0]⊕ΔK
j ⊕∇K
i
−−−−−−−−−−−→
f
C0 ⊕Δj.
Finally, we obtain the biclique by putting
Si = S0 ⊕∇i,
Cj = C0 ⊕Δj
and
K[i, j] = K[0, 0] ⊕ΔK
j ⊕∇K
i ,
where we require ΔK
j ̸= ∇K
i
whenever i + j > 0, as we want all the 2d1+d2 keys
in {K[i, j]} to be distinct.

Improving the Biclique Cryptanalysis of AES
43
In the attack, an attacker ﬁrst ﬁnds the key group {K[i, j]} satisfying the
above independent diﬀerentials property, then computes all the Cj from S0 by
Δj-diﬀerentials, and all the Si from C0 by ∇i-diﬀerentials. This requires at most
2d1 + 2d2 computations of f.
In the case of the independent-biclique attack against AES, the cost of con-
structing a biclique turns out to be low, compared to the matching part (Step
4) which requires almost 2d1+d2 computations of g1. Naturally, we aim to con-
struct bicliques as long as possible in order to reduce the number of rounds of
g1. In [9], the biclique of length 3 is constructed for AES-128, and of length 4 for
AES-192 and AES-256. Unfortunately, we cannot enlarge these lengths due to
the extremely fast diﬀusion of AES, otherwise this will yield a decent improve-
ment in time complexity. Instead, we increase the biclique size as mentioned.
This reduces the time complexity in the matching part, as will be shown later.
2.4
Matching with Precomputations
In the last step, i.e. the matching step, an attacker needs to check whether Pj is
mapped to Si by the key K[i, j] through g1. To speed up the attack, instead of
matching on a full state, an attacker considers matching variable v, which can
be a single byte in the case of AES:
Pj
K[i,j]
−−−−→v
K[i,j]
←−−−−Si.
This involves 2d1+d2 computations for g1. However, for ﬁxed j and two diﬀerent
i1, i2, some parts of the states in the forward computation Pj
K[i1,j]
−−−−→v and
Pj
K[i2,j]
−−−−→v are still the same, for which we only need to compute once. It is
similar for v
K[i,j1]
←−−−−Si and v
K[i,j2]
←−−−−Si in the backward computation. The
matching with precomputation technique, introduced in [9], makes use of this
observation. It precomputes and stores those parts that are neutral to diﬀerent i
values in forward direction, and those parts that are neutral to diﬀerent j values
in backward direction. As a result, we only need to recompute those unneutral
parts in the matching step, and look up from the stored precomputation for
neutral parts.
3
Overview of Our Biclique Attacks on AES
We construct bicliques with sizes 216 × 28 and 216 × 216 to improve the biclique
attack against AES. In this section, we give an overview of our technique.
3.1
The Bicliques in Our Attacks
In our attacks, the state sets {Si} are increased by a factor of 28:
({Si1,i2}, {Cj}, {K[i1, i2, j]}) for all i1, i2, j ∈{0, 1, . . . , 28 −1},
www.ebook3000.com

44
B. Tao and H. Wu
where
Si1,i2
K[i1,i2,j]
−−−−−−→
f
Cj.
Note that this biclique is now of size 216 × 28:
|{Si1,i2}| = 216,
|{Cj}| = 28,
and
|K[i1, i2, j]| = 224.
To construct such a biclique, we ﬁrst ﬁx the base computation S0,0
K[0,0,0]
−−−−−→
f
C0. We then look for
– Δj-diﬀerentials which maps input diﬀerence 0 to an output diﬀerence Δj;
– ∇i1-diﬀerentials and ∇i2-diﬀerentials which map input diﬀerences ∇i1
and ∇i2 respectively to the output diﬀerence 0.
To make the biclique valid, we only need to make sure that there is no
common active nonlinear components, the S-boxes in the case of AES, in either
pair of diﬀerential characteristics: (Δj, ∇i1) and (Δj, ∇i2). To get the actual
biclique, we need 3 × 28 computations of f for each of the three diﬀerentials
above.
We have also designed a second attack speciﬁcally for AES-128 which con-
siders even larger biclique ({Si1,i2}, {Cj1,j2}, {K[i1, i2, j1, j2]}), in which the size
of the ciphertext sets {Cj} is further increased by a factor of 28. Correspond-
ingly, we look for Δj1, Δj2, ∇i1, ∇i2 diﬀerentials such that none of (Δj1, ∇i1),
(Δj2, ∇i1), (Δj1, ∇i2) and (Δj2, ∇i2) shares active nonlinear components. As a
result, a total of 4 × 28 computations of f is needed.
3.2
Less Parts Being Recomputed in the Matching Step
After decrypting each Cj by the oracle, we obtain 28 plaintexts {Pj}. In the
matching step, we apply subcipher g1 to each Pj with key K[i1, i2, j] to check
whether we could get exactly Si1,i2. If so, K[i1, i2, j] is proposed as a candidate.
We again match only the matching variable v:
Pj
K[i1,i2,j]
−−−−−−→v
K[i1,i2,j]
←−−−−−−Si1,i2.
In the precomputation phase, we store the following 3 × 216 computations:
Computation 1. Pj
K[0,i2,j]
−−−−−−→v for i2, j ∈{0, 1, . . . , 28 −1},
Computation 2. Pj
K[i1,0,j]
−−−−−−→v for i1, j ∈{0, 1, . . . , 28 −1},
Computation 3. v
K[i1,i2,0]
←−−−−−−Si1,i2 for i1, i2 ∈{0, 1, . . . , 28 −1}.
Same as in Sect. 2.4, in the recomputation phase when we match Pj to
Si1,i2 on v, we only need to recompute those unneutral parts. The advantage
of our technique is that less parts are needed to be recomputed. In the forward
computation, we only need to recompute those parts which are unneutral to both
i1 and i2. In other words, we can look up from two computations (Computation

Improving the Biclique Cryptanalysis of AES
45
1 and Computation 2 above) for the forward recomputation, instead of only one
in the original attack, which causes less parts being recomputed and thus less
time complexity in recomputation phase. Since the recomputation phase is the
computational bottleneck, this advantage will reduce the total time complexity.
In our second attack on AES-128 with the biclique of size 216×216 taking the
form ({Si1,i2}, {Cj1,j2}, {K[i1, i2, j1, j2]}), we decrypt each Cj1,j2 to get Pj1,j2.
In this case, we need to store 4×224 computations in the precomputation phase:
Computation 1. Pj1,j2
K[0,i2,j1,j2]
−−−−−−−−→v for i2, j1, j2 ∈{0, 1, . . . , 28 −1},
Computation 2. Pj1,j2
K[i1,0,j1,j2]
−−−−−−−−→v for i1, j1, j2 ∈{0, 1, . . . , 28 −1},
Computation 3. v
K[i1,i2,0,j2]
←−−−−−−−−Si1,i2 for i1, i2, j2 ∈{0, 1, . . . , 28 −1},
Computation 4. v
K[i1,i2,j1,0]
←−−−−−−−−Si1,i2 for i1, i2, j1 ∈{0, 1, . . . , 28 −1}.
The time complexity is further reduced as we also have two diﬀerent references
for the backward recomputation to looked up, namely, Computation 3 and 4.
However, this improvement in time complexity does have disadvantages. Besides
the obviously higher cost of memory, this attack may also pay extra cost on data
complexity, as the additional Δj2-diﬀerential may corrupt the extra neutral bytes
in ciphertext.
4
The Improved Biclique Attacks Against AES
In this section, we describe our biclique attack against AES-128 by using the
216 × 28 biclique. The attack on AES-128 with 216 × 216 biclique is given in
Appendix A, while the attacks on AES-192 and AES-256 with 216 ×28 bicliques
are illustrated with ﬁgures in Appendix B. Refer to Table 1 for all the results.
In this section and the two Appendix sections, we will use $0, $1, $2, . . . to
denote the round keys. Bytes within a state and a round key are enumerated as
follow, and byte i in state Q is denoted as Qi.
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
4.1
Key Partitioning
We deﬁne the key space with respect to the round key $8 (the same as that in
[9]). This deﬁnition is valid as the AES-128 key schedule bijectively maps each
key to $8. The base keys K[0, 0, 0] are all the possible 2104 16-byte values with
three bytes, $80, $81, $86, ﬁxed to 0, whereas the remaining 13 bytes run over
all values. The keys {K[i1, i2, j]} in a group are enumerated by all possible byte
diﬀerences i1, i2 and j with respect to the base key K[0, 0, 0]. The space of the
round key $8 (and hence the AES key space) is thus partitioned into 2104 sets
of size 224.
www.ebook3000.com

46
B. Tao and H. Wu
0
0
0
i1
i2
j
i1
i2
4.2
3-round Biclique of Size 216 × 28
In the next step, we construct a 3-round biclique by following the steps in Sect. 3.
Figure 1 illustrates the Δj, ∇i1, ∇i2 diﬀerentials, from which we can easily verify
that (Δj, ∇i1) and (Δj, ∇i2) shares no common active S-box.
Round 8
Round 9
Round 10
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
Δj-diﬀerentials
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
∇i1-diﬀerentials
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
∇i2-diﬀerentials
Only 9 bytes of the ciphertext
are aﬀected by Δj diﬀerentials.
Fig. 1. All the Δj, ∇i1, ∇i2 diﬀerentials: AES-128
4.3
Computing Round Keys
Now for each round key K[i1, i2, j] of round 8, we calculate its corresponding
round keys $0, $1, . . . , $7. At the ﬁrst glance, it requires 224 operations of the
AES key schedule. However, the calculation can be speed up with the precompu-
tation technique introduced earlier. We will apply this technique only on the ﬁrst
column of each round key, as the rest three columns require only xor operations
to be computed which has negligible time complexity.
In the precomputation phase, we compute all the 8 round keys for the fol-
lowing:
– K[0, i2, j] for all i2, j ∈{0, 1, . . . , 28 −1};
– K[i1, 0, j] for all i1, j ∈{0, 1, . . . , 28 −1}.
This requires at most 2 × 216 8-round computations of key schedule.

Improving the Biclique Cryptanalysis of AES
47
In the recomputation phase when we are calculating K[i1, i2, j] (for all the 8
round keys from $7 all the way down to $0), we only need cheap xor and lookup
operations (no S-box operation in particular) by storing all the bytes with ∗and
the S-box substitution values of all the bytes with ◦in Fig. 2.
For example, to compute the ﬁrst byte of $7, we have $70 = $80 ⊕s($713) ⊕
roundConst, where s($713) has the same value for K[0, i2, j] and K[i1, i2, j]
and we already store the one for K[0, i2, j]. For the second and the third bytes
$71, $72, we look them up directly from K[0, i2, j], and we lookup from K[i1, 0, j]
for the forth byte $73. After we obtain the ﬁrst column of $7, we compute the
rest 12 bytes and get the entire $7. After we recover the full $7, we do the same
to compute $6 and so on.
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
∗
◦◦◦
◦
◦◦
◦
◦
◦◦
◦
◦
◦◦
◦
◦
◦
◦: byte whose S-box substitution value needed to be stored
∗: byte needed to be stored
$0
$1
$2
$3
$4
$5
$6
$7
Diﬀerence between K[i1, 0, j] and K[i1, i2, j]
$0
$1
$2
$3
$4
$5
$6
$7
Diﬀerence between K[0, i2, j] and K[i1, i2, j]
Fig. 2. Precomputation and recomputation of round keys: AES-128
4.4
Matching Over 7 Rounds
Now we check whether the secret key belongs to the key group {K[i1, i2, j]}. As
shown in Fig. 3 and Fig. 4, we match the ﬁrst byte in the state after Round 2,
which is the same as [9]. So we only need to compute 4 bytes in Round 2, 1 byte
in Round 3 and 4 bytes in Round 4. Additionally, beneﬁting from the matching
with precomputation technique (Sect. 2.4), we only need to compute very few
bytes in Round 1 and Round 7 in the recomputation phase. Speciﬁcally, we only
need to compute 5 bytes in Round 1 (Fig. 3) and 8 bytes in Round 7 (Fig. 4).
4.5
Complexity of the Attack
Now we evaluate the time complexity, data complexity and memory complexity
of our attack.
Time Complexity. Similar to the original biclique attack [9], we count the
number of S-boxes computations to determine the time complexity. Note that
there are 200 S-boxes in one full AES-128 (160 for encryption/decryption, 40
for key schedule). We measure the time complexity in terms of the full AES-128
operations, so the overall time complexity will be given as the total number of
S-boxes in our attack divided by 200.
www.ebook3000.com

48
B. Tao and H. Wu
AK
SB
SR
MC
AK
Round 1
SB
SR
MC
AK
Round 2
Pj
Byte need to be recomputed (Cells with light color are not needed as we match on only 1 byte.)
AK
SB
SR
MC
AK
Round 1
SB
SR
MC
AK
Round 2
Pj
Diﬀerence between the forward computations of Pj using K[i1, i2, j] and K[i1, 0, j]
AK
SB
SR
MC
AK
Round 1
SB
SR
MC
AK
Round 2
Pj
Diﬀerence between the forward computations of Pj using K[i1, i2, j] and K[0, i2, j]
Fig. 3. Forward recomputation in matching: AES-128
AK
MC
SR
SB
Round 7
AK
MC
SR
SB
Round 6
AK
MC
SR
SB
Round 5
AK
MC
SR
SB
Round 4
AK
MC
SR
SB
Round 3
Si1,i2
Byte need to be recomputed (Cells with light color are not needed as we match on only 1 byte.)
AK
MC
SR
SB
Round 7
AK
MC
SR
SB
Round 6
AK
MC
SR
SB
Round 5
AK
MC
SR
SB
Round 4
AK
MC
SR
SB
Round 3
Si1,i2
Diﬀerence between the backward computations of Si1,i2 using K[i1, i2, j] and K[i1, i2, 0]
Fig. 4. Backward recomputation in matching: AES-128
For the search in a single key group {K[i1, i2, j]}, the time complexity consists
of the following components:
1. Cbiclique: The complexity of constructing the biclique. (Sect. 4.2)
2. Coracle: The complexity for the decryption of each Cj by the oracle.
3. Ckeys: The complexity of computing all the round keys for key K[i1, i2, j]
in the set {K[i1, i2, j]}. (Sect. 4.3)
4. Cprec: The complexity of precomputation phase. (Sect. 4.4)
5. Crec: The complexity of recomputation phase. (Sect. 4.4)
6. Cfalsep: The complexity generated from false positives.
The time complexity for biclique construction is merely the 3 × 28 compu-
tations of 3 rounds subcipher f which is 56 S-boxes (including 2 rounds key
schedule). This complexity is given as
Cbiclique = 3 × 28 × 56/200 = 27.75.
We need to decrypt all the 28 ciphertexts {Cj}:
Coracle = 28.
The time complexity of computing all the round keys includes the precompu-
tation phase and recomputation phase. As mentioned in Sect. 4.3, the recompu-
tation of round keys require only xor and lookup operations, which correspond

Improving the Biclique Cryptanalysis of AES
49
to 0 S-box operation. As for precomputation, we need to compute those 8 round
keys (equivalent to 32 S-boxes) for both groups K[0, i2, j] and K[i1, 0, j], and
each group is of size 216. The time complexity of round key computation is
Ckeys = 2 × 216 × 32/200 = 214.36.
In the precomputation phase of matching, we only need to compute one
round for Computation 1, 2 and 3 in Sect. 3.2. This is because all the 16 bytes
of each state become diﬀerent except for Round 1 and 7 (refer to Fig. 3 and
Fig. 4), so the precomputation of other rounds provides no information for the
recomputation at all, which we do not need to store. Since exactly 20 S-boxes
are included in a round, we have
Cprec = 3 × 216 × 20/200 = 214.26.
In the recomputation state, as shown in Fig. 3 and 4, we need to recompute 9
S-boxes in the forward direction and 45 S-boxes in the backward direction. There
are 54 S-boxes in total, and it is needed for each of the 224 keys {K[i1, i2, j]}.
Crec = 224 × 54/200 = 222.11.
We performed 224 matchings on a single byte with 28 possible values, the
number of false positives is approximately 224−8 = 216. We eliminate the false
positives by matching them on a full 16-byte state, which require 3 rounds com-
putation (i.e. Round 2, 3 and 4), so 48 S-boxes are needed.
Cfalsep = 216 × 48/200 = 213.94.
Summing up all the above, we have the total time complexity:
2104(27.75 + 28 + 214.36 + 214.26 + 222.11 + 213.94) = 2126.13.
Note that with the above time complexity, the secret key of AES-128 is obtained
with success rate 1.
Data Complexity. According to Fig. 1, Δj-diﬀerential aﬀect only 9 bytes of the
ciphertext, and all the ciphertexts have constant values at bytes C0,4,7,8,10,11,15.
Furthermore, the ciphertext bytes C1, C5 and C13 of those 9 bytes always
maintain the same diﬀerence. As a result, the data complexity does not exceed
2(9−3+1)×8 = 256.
Memory Complexity. We need to store the biclique, as well as the precom-
putations for both round keys and states. Note that we do not need to store all
the 224 sets of round keys, as it can be computed in runtime whenever needed.
For the biclique storage, we need to store 216 states {Si1,i2} and 28 ciphertexts
{Cj}, with size 16 bytes for each. The total memory complexity for biclique
storage is (28 + 216) × 16 bytes.
www.ebook3000.com

50
B. Tao and H. Wu
For the precomputations for round keys and states, we only store the bytes
that are looked up in the recomputation stage (those neutral bytes not aﬀected
by the diﬀerential charactertistic). For the round key precomputation, as shown
in Fig. 2, we need to store a total of 216 × 32 bytes (all the ∗and ◦) which
includes 216 × 23 bytes from K[0, i2, j] and 216 × 9 bytes from K[i1, 0, j].
Similarly, for the storage of states used in the matching, we only need to store
11 bytes in the state after the SubBytes operation in Round 1, and 8 bytes in
the state between Round 6 and Round 7, which is 216(11+8) = 216 ×19 (bytes).
Finally, the total memory complexity is
(28 + 216) × 16 + 216 × 32 + 216 × 19 = 222.07 (bytes).
We used the same criteria to analyze the memory complexities for all the
previous attacks as well, and obtain these data in Table 1 (the forth column).
5
Comparing with the Previous Biclique Attacks
As mentioned in Sect. 3.2, the main advantage of our technique is reducing the
number of S-boxes being recomputed in the matching step. Table 2 compares the
number of S-boxes needed in the recomputation, and it shows that our attack
requires least S-boxes to be recomputed (with data complexity less than the full
code book).
Table 2. Comparison of the numbers of S-boxes recomputed
our results with
our results with
[9]
[7]
216 × 28 bicliques 216 × 216 bicliques (original attack) (prev. best results)
AES-128
54
50
57
55
AES-192
52
-
61
62
AES-256
83
-
101
86
It is illuminating to compare the two results for AES-128. With larger
bicliques, the number of S-boxes computed can be further reduced from 54 to 50
which leads an improvement of time complexity from 2126.13 to 2126.01 (Table 1).
However, by applying larger biclique, the data complexity and memory complex-
ity increase signiﬁcantly (Table 1).
6
Veriﬁcation in Experiment
In our attack against all the three AES versions, the whole key space is parti-
tioned into 2104/2168/2232 sets with sizes 224 (or 296 sets with size 232 in the
second attack of AES-128). We wrote a program to search the key in a single
partition. The secret key is found if it was set in the searched partition. This
program proves the correctness of our attack algorithm, including the validity of

Improving the Biclique Cryptanalysis of AES
51
bicliques and the correctness of the diﬀerential characteristics. The program also
counts the number of S-boxes calculated in the search of a full partition, and
outputs the time complexities in terms of equivalent full AES computations. The
memory complexity is also veriﬁed in the experiment by checking the memory
usage of the process. We veriﬁed the attacks on all the three versions of AES,
and the experimental results are even slightly better than our theoretical results.
7
Combination with the Sieve-in-the-Middle Technique
Sieve-in-the-Middle (SIM) technique by Canteaut et al. [10] is a variant of the
Meet-in-the-Middle (MITM) technique. In its application to the biclique attack
against AES, it can save another 5 S-boxes in recomputation during the matching
step, by storing 232 lookup tables of size 232 bytes each. With a large increment
in memory complexities, all the numbers shown in Table 2 can be reduced by 5,
which results in further improvements in time complexities (see Table 1). The
reader can also refer to Sect. 8 of [7] for more details.
8
Conclusion
In this paper, we improved the independent-biclique paradigm of the biclique
attack [9] by increasing the biclique size. Our technique enhances the matching-
with-precomputation technique in [9] by reducing the number of S-boxes being
recomputed. The data complexities in the attacks against AES-128 are also
reduced. Our attacks are currently the fastest with moderate data complexities.
A
Biclique Attack on AES-128 with 216 × 216 Biclique
A.1
Key Partitioning
We again deﬁne the key space with respect to the round key $8. Fix $80, $81, $87
and $88 to 0. The keys {K[i1, i2, j1, j2]} in a group are enumerated by all possible
byte diﬀerences i1, i2, j1 and j2 with respect to the base key K[0, 0, 0, 0]. The
AES key space is thus partitioned into the 296 sets of size 232.
0
0
0
0
i1
i2
j2
i1 ⊕j1
i2
The fact that $88 is shared by the byte diﬀerences i1 and j1 does not inval-
idate the biclique, as this shared diﬀerence has not passed into any non-linear
S-box operation (refer to Fig. 5).
www.ebook3000.com

52
B. Tao and H. Wu
A.2
3-round Biclique of Size 216 × 216
Figure 5 illustrates the Δj1, Δj2, ∇i1, ∇i2 diﬀerentials, from which we can easily
verify that each of the two Δ diﬀerentials share no active S-boxes to each of the
two ∇diﬀerentials.
Round 8
Round 9
Round 10
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
Δj1-diﬀerentials
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
Δj2-diﬀerentials
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
∇i1-diﬀerentials
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
∇i2-diﬀerentials
Only 11 bytes of the ciphertext
are aﬀected by Δj1 and Δj2 diﬀerentials.
Fig. 5. All the Δj1, Δj2, ∇i1, ∇i2 diﬀerentials: AES-128
A.3
Computation of Round Keys
For each round key K[i1, i2, j1, j2] of round 8, we calculate its corresponding
round keys $0, $1, . . . , $7. In the precomputation phase, we compute and store
all the 8 round keys for the following:
– K[0, i2, j1, j2] for all i2, j1, j2 ∈{0, 1, . . . , 28 −1};
– K[i1, 0, j1, j2] for all i1, j1, j2 ∈{0, 1, . . . , 28 −1}.
This requires at most 2 · 224 8-round computations of key schedule.
Since we are using exactly the same ∇i1, ∇i2 diﬀerential characteristics, the
key diﬀerential patterns of the above two computations are the same to those in
Fig. 2. For the same reason, we only need to store those marked bytes, and the
recomputation of round keys require no S-box computation. The only diﬀerence
is that each ∗or ◦now corresponds to 224 bytes in memory, instead of 216 bytes.
A.4
Matching Over 7 Rounds
Due to larger size bicliques, even less bytes need to be recomputed. We need to
recompute 9 S-boxes in the forward direction and 41 S-boxes in the backward
direction, which only gives us 50 in total. Refer to Fig. 6 and Fig. 7 for details.

Improving the Biclique Cryptanalysis of AES
53
AK
SB
SR
MC
AK
Round 1
SB
SR
MC
AK
Round 2
Pj1,j2
Bytes need to be recomputed (Cells with light color are not needed as we match on only 1 byte.)
AK
SB
SR
MC
AK
Round 1
SB
SR
MC
AK
Round 2
Pj1,j2
Diﬀerence between the forward computations of Pj1,j2 using K[i1, i2, j1, j2] and K[i1, 0, j1, j2]
AK
SB
SR
MC
AK
Round 1
SB
SR
MC
AK
Round 2
Pj1,j2
Diﬀerence between the forward computations of Pj1,j2 using K[i1, i2, j1, j2] and K[0, i2, j1, j2]
Fig. 6. Forward recomputation in matching: AES-128
AK
MC
SR
SB
Round 7
AK
MC
SR
SB
Round 6
AK
MC
SR
SB
Round 5
AK
MC
SR
SB
Round 4
AK
MC
SR
SB
Round 3
Si1,i2
Bytes need to be recomputed (Cells with light color are not needed as we match on only 1 byte.)
AK
MC
SR
SB
Round 7
AK
MC
SR
SB
Round 6
AK
MC
SR
SB
Round 5
AK
MC
SR
SB
Round 4
AK
MC
SR
SB
Round 3
Si1,i2
Diﬀerence between the backward computations of Si1,i2 using K[i1, i2, j1, j2] and K[i1, i2, j1, 0]
AK
MC
SR
SB
Round 7
AK
MC
SR
SB
Round 6
AK
MC
SR
SB
Round 5
AK
MC
SR
SB
Round 4
AK
MC
SR
SB
Round 3
Si1,i2
Diﬀerence between the backward computations of Si1,i2 using K[i1, i2, j1, j2] and K[i1, i2, 0, j2]
Fig. 7. Backward recomputation in matching: AES-128
A.5
Complexity of the Attack
The evaluation of time and data complexities is similar to those in Sect. 4.5, and
thus are omitted here. Refer to Table 1 for the results.
Memory Complexity. Fig. 8 illustrates the bytes need to be stored in the
matching phase, which suggests a total of 23 × 224 bytes needs to be stored.
Coupled with a total of 32×224 bytes in the round key (those ∗and ◦in Fig. 2),
it seems the total memory complexity is more than 23 × 224 + 32 × 224 = 229.78
bytes. This complexity can be reduced if we ﬁxed the value of j1 ﬁrst, and do
the precomputation and recomputation with each ﬁxed j1.
To be speciﬁc, for each ﬁxed j1, we need to stores 7 bytes for each diﬀerent
value i2, j2 (the ﬁrst row in Fig. 8), 4 bytes for each diﬀerent value i1, j2 (the
second row in Fig. 8) and 8 bytes for each diﬀerent value i1, i2 (the last row in
Fig. 8); when j1 varies to the next value, we store the values of all those bytes
again for the updated j1 value. Thus, the memory complexity used for storing
state bytes is
Mstates = 7 × 216 + 4 × 216 + 4 × 224 + 8 × 216 = 226.03 (bytes).
We can do the same for key bytes storage. According to Fig. 2, for each
ﬁxed j1, we need to stores 23 bytes for each diﬀerent value i2, j2 and 9 bytes for
www.ebook3000.com

54
B. Tao and H. Wu
∗
∗∗∗
∗∗∗
∗
∗∗∗
AK
SB
SR
MC
AK
SB
SR
MC
AK
Pj1,j2
The forward computations of Pj1,j2 using K[i1, 0, j1, j2]
AK
SB
SR
MC
AK
SB
SR
MC
AK
Pj1,j2
The forward computations of Pj1,j2 using K[0, i2, j1, j2]
∗
∗∗
∗
∗∗
∗
∗∗
∗
∗
∗
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
Si1,i2
The backward computations of Si1,i2 using K[i1, i2, j1, 0]
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
Si1,i2
The backward computations of Si1,i2 using K[i1, i2, 0, j2]
Fig. 8. Bytes to be stored in states: AES-128
Round 8
Round 7
Round 6
Round 5
Round 4
Si1,i2
Backward recomputation: 45 bytes
AK
Round 1
Round 2
Round 3
Pj
Bytes need to be recomputed:
AK
Round 1
Round 2
Round 3
Pj
Diﬀerence between the computations of Pj by K[i1, i2, j] and K[i1, 0, j]
AK
Round 1
Round 2
Round 3
Pj
Diﬀerence between the computations of Pj by K[i1, i2, j] and K[0, i2, j]
Forward recomputation: 7 bytes
Key enumeration K6 = ($9||$10L)
i1
i1
j
i2
i2
The 4-round biclique
Data complexity: 248
∗bytes having the same diﬀerence
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
SR
SB
Round 12
Round 11
Round 10
Round 9
Δj-diﬀerential ∇i1-diﬀerential ∇i2-diﬀerential
Fig. 9. Illustration for AES-192
each diﬀerent value i1, j2, which has total memory complexity 32 × 216. Adding
2 × 216 × 16 bytes memory needed to store a biclique, we have total memory
complexity to be
2 × 216 × 16 + 226.03 + 32 × 216 = 226.11 (bytes).
B
The Improved Attacks Against AES-192 and AES-256
The attacks against AES-192 and AES-256 with 216 ×28 bicliques are similar to
the one for AES-128 discussed in Sect. 4. Here, we give only ﬁgures illustrations
Fig. 9 and Fig. 10 showing details of key enumerations, biclique constructions

Improving the Biclique Cryptanalysis of AES
55
Round 10
Round 9
......
Round 5
Round 4
Si1,i2
Backward recomputation: 77 bytes
AK
Round 1
Round 2
Round 3
Pj
Bytes need to be recomputed:
AK
Round 1
Round 2
Round 3
Pj
Diﬀerence between the computations of Pj by K[i1, i2, j] and K[i1, 0, j]
AK
Round 1
Round 2
Round 3
Pj
Diﬀerence between the computations of Pj by K[i1, i2, j] and K[0, i2, j]
Forward recomputation: 6 bytes
Key enumeration K6 = ($12||$13)
i1 i1
j
i2 i2
The 4-round biclique
Data complexity: 240
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
MC
SR
SB
AK
SR
SB
Round 14
Round 13
Round 12
Round 11
Δj-diﬀerential ∇i1-diﬀerential ∇i2-diﬀerential
Fig. 10. Illustration for AES-256
and recomputations in both directions. Following Sect. 4, the reader can easily
verify the results in Table 1 from these ﬁgures.
References
1. Abed, F., Forler, C., List, E., Lucks, S., Wenzel, J.: A framework for automated
independent-biclique cryptanalysis. In: Moriai, S. (ed.) FSE 2013. LNCS, vol. 8424,
pp. 561–582. Springer, Heidelberg (2014)
2. Bahrak, B., Aref, M.R.: Impossible diﬀerential attack on seven-round AES-128.
Information Security, IET 2(2), 28–32 (2008)
3. Biham, E., Dunkelman, O., Keller, N.: Related-key impossible diﬀerential attacks
on 8-round AES-192. In: Pointcheval, D. (ed.) CT-RSA 2006. LNCS, vol. 3860, pp.
21–33. Springer, Heidelberg (2006)
4. Biryukov, A., Dunkelman, O., Keller, N., Khovratovich, D., Shamir, A.: Key recov-
ery attacks of practical complexity on AES-256 variants with up to 10 rounds. In:
Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 299–319. Springer,
Heidelberg (2010)
5. Biryukov, A., Khovratovich, D.: Related-key cryptanalysis of the full AES-192
and AES-256. In: Matsui, M. (ed.) ASIACRYPT 2009. LNCS, vol. 5912, pp. 1–18.
Springer, Heidelberg (2009)
6. Biryukov, A., Khovratovich, D., Nikoli´c, I.: Distinguisher and related-key attack
on the full AES-256. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol. 5677, pp.
231–249. Springer, Heidelberg (2009)
7. Bogdanov, A., Chang, D., Ghosh, M., Sanadhya, S.K.: Bicliques with minimal data
and time complexity for AES. In: Lee, J., Kim, J. (eds.) Information Security and
Cryptology-ICISC 2014. LNCS, pp. 160–174. Springer, Heidelberg (2015)
www.ebook3000.com

56
B. Tao and H. Wu
8. Bogdanov, A., Kavun, E., Paar, C., Rechberger, C., Yalcin, T.: Better than brute-
force–optimized hardware architecture for eﬃcient biclique attacks on AES-128.
In: ECRYPT Workshop, SHARCS-Special Purpose Hardware for Attacking Cryp-
tographic Systems (2012)
9. Bogdanov, A., Khovratovich, D., Rechberger, C.: Biclique cryptanalysis of the full
AES. In: Lee, D.H., Wang, X. (eds.) ASIACRYPT 2011. LNCS, vol. 7073, pp.
344–371. Springer, Heidelberg (2011)
10. Canteaut, A., Naya-Plasencia, M., Vayssi`ere, B.: Sieve-in-the-middle: improved
MITM attacks. In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013, Part I. LNCS,
vol. 8042, pp. 222–240. Springer, Heidelberg (2013)
11. Chen, Sz, Xu, Tm: Biclique attack of the full ARIA-256. IACR Cryptology ePrint
Archive 2012, 11 (2012)
12. C¸oban, M., Karako¸c, F., Bozta¸s,
¨O.: Biclique cryptanalysis of TWINE. In:
Pieprzyk, J., Sadeghi, A.-R., Manulis, M. (eds.) CANS 2012. LNCS, vol. 7712,
pp. 43–55. Springer, Heidelberg (2012)
13. Daemen, J., Rijmen, V.: The design of Rijndael: AES - the advanced encryption
standard. Springer Science & Business Media (2002)
14. Dunkelman, O., Keller, N., Shamir, A.: Improved single-key attacks on 8-round
AES-192 and AES-256. In: Abe, M. (ed.) ASIACRYPT 2010. LNCS, vol. 6477, pp.
158–176. Springer, Heidelberg (2010)
15. Gorski, M., Lucks, S.: New related-key boomerang attacks on AES. In: Chowdhury,
D.R., Rijmen, V., Das, A. (eds.) INDOCRYPT 2008. LNCS, vol. 5365, pp. 266–278.
Springer, Heidelberg (2008)
16. Hong, D., Koo, B., Kwon, D.: Biclique attack on the full HIGHT. In: Kim, H. (ed.)
ICISC 2011. LNCS, vol. 7259, pp. 365–374. Springer, Heidelberg (2012)
17. Jakimoski, G., Desmedt, Y.: Related-key diﬀerential cryptanalysis of 192-bit key
AES variants. In: Matsui, M., Zuccherato, R.J. (eds.) SAC 2003. LNCS, vol. 3006,
pp. 208–221. Springer, Heidelberg (2004)
18. Khovratovich, D., Leurent, G., Rechberger, C.: Narrow-bicliques: cryptanalysis of
full IDEA. In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012. LNCS,
vol. 7237, pp. 392–410. Springer, Heidelberg (2012)
19. Khovratovich, D., Rechberger, C., Savelieva, A.: Bicliques for preimages: attacks
on skein-512 and the SHA-2 family. In: Canteaut, A. (ed.) FSE 2012. LNCS, vol.
7549, pp. 244–263. Springer, Heidelberg (2012)
20. Li, L., Jia, K., Wang, X.: Improved single-key attacks on 9-round AES-192/256. In:
Cid, C., Rechberger, C. (eds.) FSE 2014. LNCS, vol. 8540, pp. 127–146. Springer,
Heidelberg (2015)
21. Mala, H.: Biclique-based cryptanalysis of the block cipher SQUARE. Information
Security, IET 8(3), 207–212 (2014)
22. Mala, H., Dakhilalian, M., Rijmen, V., Modarres-Hashemi, M.: Improved impos-
sible diﬀerential cryptanalysis of 7-round AES-128. In: Progress in Cryptology-
INDOCRYPT 2010, pp. 282–291. Springer (2010)
23. Wang, Y., Wu, W., Yu, X.: Biclique cryptanalysis of reduced-round piccolo block
cipher. In: Ryan, M.D., Smyth, B., Wang, G. (eds.) ISPEC 2012. LNCS, vol. 7232,
pp. 337–352. Springer, Heidelberg (2012)

Public Key Cryptography
www.ebook3000.com

A New General Framework for Secure Public
Key Encryption with Keyword Search
Rongmao Chen1,2(B), Yi Mu1(B), Guomin Yang1, Fuchun Guo1,
and Xiaofen Wang1,3
1 Centre for Computer and Information Security Research,
School of Computing and Information Technology,
University of Wollongong, Wollongong, Australia
{rc517,ymu,gyang,fuchun}@uow.edu.au, wangxuedou@sina.com
2 College of Computer, National University of Defense Technology,
Changsha, China
3 Department of Computer Science and Engineering,
University of Electronic Science and Technology of China, Chengdu, China
Abstract. Public Key Encryption with Keyword Search (PEKS), intro-
duced by Boneh et al. in Eurocrypt’04, allows users to search encrypted
documents on an untrusted server without revealing any information.
This notion is very useful in many applications and has attracted a lot
of attention by the cryptographic research community. However, one lim-
itation of all the existing PEKS schemes is that they cannot resist the
Keyword Guessing Attack (KGA) launched by a malicious server. In this
paper, we propose a new PEKS framework named Dual-Server Public
Key Encryption with Keyword Search (DS-PEKS). This new framework
can withstand all the attacks, including the KGA from the two untrusted
servers, as long as they do not collude. We then present a generic con-
struction of DS-PEKS using a new variant of the Smooth Projective
Hash Functions (SPHFs), which is of independent interest.
Keywords: Dual-server public key encryption with keyword search ·
Smooth projective hash function
1
Introduction
To enable encrypted documents searchable on an untrusted server without
revealing any information, Boneh et al. [10] introduced the notion of public key
encryption with keyword search (PEKS) in Eurocrypt’04. A PEKS system has
many potential applications including private databases and data mining where
the users are concerned about their data privacy. In a PEKS system, a sender
attaches some encrypted keywords (referred to as PEKS ciphertexts) with the
encrypted data. The receiver then sends the trapdoor of a to-be-searched key-
word to the server for data searching. Given the trapdoor and the PEKS cipher-
text, the server can test whether the keyword underlying the PEKS ciphertxt
is equal to the one selected by the receiver. If so, the server sends the matching
encrypted data to the receiver.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 59–76, 2015.
DOI: 10.1007/978-3-319-19962-7 4

60
R. Chen et al.
Inside Keyword Guessing Attack. A PEKS scheme is considered secure if it
reveals no information about the data to the server. To be more precise, the server
can only locate the message speciﬁed by the receiver but cannot learn anything
else. Nevertheless, none of the existing PEKS schemes is secure against Keyword
Guessing Attack (KGA) launched by a malicious server, which is also known as
inside KGA. Speciﬁcally, given a trapdoor, the adversarial server can choose a
guessing keyword from the keyword space and then use the keyword to generate
a PEKS ciphertext. The server then can test whether the guessing keyword is
the one underlying the trapdoor. This guessing-then-testing procedure can be
repeated until the correct keyword is found. Such a guessing attack has also
been considered in many password-based systems. However, the attack can be
launched more eﬃciently against PEKS since the keyword space is roughly the
same as a normal dictionary (e.g., all the meaningful English words), which has
a much smaller size than a password dictionary (e.g., all the words containing 6
alphanumeric characters).
Unfortunately, we see that the inside KGA is an inherent vulnerability of the
existing PEKS framework which only involves one server. This is essentially due
to the following facts.
– Public Generation of PEKS Ciphertexts. The generation of a PEKS
ciphertext only involves public information; hence the server can generate
the PEKS ciphertext for any keyword.
– Stand-alone Testing. The server can independently check whether a PEKS
ciphertext is consistent with a trapdoor from the receiver.
– Correctness/consistency of PEKS. The correctness required by PEKS
ensures that the test function always outputs the correct answer.
It is obvious that we should not sacriﬁce the correctness of PEKS; otherwise we
will essentially lose the search functionality. One possible solution to overcome
the problem is to disable the public generation of PEKS ciphertexts, which
means the PEKS encryption performed by a sender should also take as input
some secret information only known by the sender (e.g., the sender’s private
key). However, this solution is not practical either, since the receiver will need
to embed some information of the sender (e.g., the public key) in the generation
of a trapdoor. But the receiver may not be aware of the identity of the sender
when performing the search, and multiple trapdoors for a keyword need to be
generated for all the potential senders in the system.
Our Contributions. The contributions of this paper are two-fold. Firstly, based
on the above observations, we propose to overcome the inside KGA by disallow-
ing the stand-alone testing performed by a server. Speciﬁcally, we formally deﬁne
a new PEKS framework named Dual-Server Public Key Encryption with Key-
word Search (DS-PEKS). Secondly, we show a generic construction of DS-PEKS
using a newly deﬁned variant of Smooth Projective Hash Function (SPHF) which
maybe of independent interest.
Overview of Techniques. The key idea of the new framework is to split the
testing functionality of the PEKS system into two parts which are handled by
www.ebook3000.com

A New General Framework for Secure PEKS
61
two independent servers: front server and back server. Upon receiving a query
from the receiver, the front server pre-processes the trapdoor and all the PEKS
ciphertexts using its private key, and then sends some internal testing-states to
the back server with the corresponding trapdoor and PEKS ciphertexts hidden.
The back server can then decide which documents are queried by the receiver
using its private key and the received internal testing-states from the front server.
We show that under such a setting neither the front server nor the back server
can launch the keyword guessing attack. It is worth noting that in the above
process, we require that the two servers do not collude since otherwise it goes
back to the one-server setting in which inside KGA cannot be prevented.
Smooth Projective Hash Function (SPHF) is originally introduced by by
Cramer and Shoup [13] for construction of CCA-secure public key encryption
schemes. Roughly speaking, an SPHF can be deﬁned based on a domain X and
an NP language L, where L ⊂X. The key property of SPHF is that the pro-
jection key uniquely determines the hash value of any word in the language L
(projective) but gives almost no information about the hash value of any point
in X \ L (smooth). In our paper, the SPHF used is based on the hard-on-the-
average NP-language and hence is also pseudo-random [15]. That is, given a
word W ∈L, without the corresponding witness and the secret hashing key,
the distribution of its hash value is computationally indistinguishable from a
uniform distribution. Our newly deﬁned variant, named Lin-Hom SPHF, addi-
tionally requires the underlying language and the hash function to be linear
and homomorphic. In a generic DS-PEKS construction, to generate the PEKS
ciphertext of a keyword, the sender picks a word randomly from L and computes
its two hash values using the witness and the public key (projection key) of the
front and back servers respectively. The keyword is then concealed with these
two hash values in the PEKS ciphertext. One can see that due to the pseudo-
randomness of the SPHF, given a PEKS ciphertext, the two servers cannot learn
any information about the underlying keyword individually as they do not know
the witness or the private key (secret hashing key) of each other. The receiver
generates the trapdoor in the same way and hence security of the trapdoor can
also be guaranteed. In the pre-processing stage, the front server ﬁrst removes
the pseudo-random hash values in the trapdoor and the PEKS ciphertext for the
back server using its private key. Due to the linear and homomorphic properties
of Lin-Hom SPHF, the front server can re-randomise the internal testing-state
to preserve the keyword privacy from the back server who can only determine
whether the two keywords underlying the internal testing-state are the same or
not. We can see that in this way, the security of DS-PEKS against inside keyword
guessing attack can be obtained.
1.1
Related Work
Following Boneh et al.’s seminal work [10], Abdalla et al. [1] formalized anony-
mous IBE (AIBE) and presented a generic construction of searchable encryption
from AIBE. They also showed how to transfer a hierarchical IBE (HIBE) scheme
into a public key encryption with temporary keyword search (PETKS) where

62
R. Chen et al.
the trapdoor is only valid in a speciﬁc time interval. Waters [22] showed that
the PEKS schemes based on bilinear map could be applied to build encrypted
and searchable auditing logs. In order to construct a PEKS secure in the stan-
dard model, Khader [19] proposed a scheme based on the k-resilient IBE and
also gave a construction supporting multiple-keyword search. The ﬁrst PEKS
scheme without pairings was introduced by Crescenzo and Saraswat [14]. The
construction is derived from Cock’s IBE scheme [12] which is not very practical.
Byun et al. [11] introduced the oﬀ-line keyword guessing attack against PEKS
as keywords are chosen from a much smaller space than passwords and users usu-
ally use well-known keywords for searching documents. They also pointed out
that the scheme proposed in Boneh et al. [10] was susceptible to keyword guessing
attack. Inspired by the work of Byun et al. [11], Yau et al. [23] demonstrated that
outside adversaries that capture the trapdoors sent in a public channel can reveal
the encrypted keywords through oﬀ-line keyword guessing attacks and they also
showed oﬀ-line keyword guessing attacks against the (SCF-)PEKS schemes in
[4,5]. The ﬁrst PEKS scheme secure against outside keyword guessing attacks
was proposed by Rhee et al. [21]. In [20], the notion of trapdoor indistinguisha-
bility was proposed and the authors showed that trapdoor indistinguishability
is a suﬃcient condition for preventing outside keyword-guessing attacks.
Nevertheless, all the schemes mentioned above are found to be vulnera-
ble to keyword guessing attacks from a malicious server (i.e., inside keyword
guessing attacks). Jeong et al. [17] showed a negative result that the consis-
tency/correctness of PEKS implies insecurity to inside keyword guessing attacks
in PEKS. Their result indicates that constructing secure and consistent PEKS
schemes against inside keyword guessing attacks is impossible under the original
framework.
1.2
Organization
In Section 2, we propose the new framework, namely DS-PEKS, and present its
formal deﬁnition and security models. We then deﬁne a new variant of smooth
projective hash function (SPHF), which satisﬁes the linear and homomorphic
properties, for a special class of NP languages in Section 3. A generic construc-
tion of DS-PEKS from LH-SPHF is shown in Section 4 with formal correctness
analysis and security proofs. We then give a conclusion in Section 5.
2
Dual-Server Public Key Encryption with Keyword
Search
In this section, we formally deﬁne the Dual-Server Public Key Encryption with
Keyword Search (DS-PEKS) and its security model.
2.1
Overview of DS-PEKS
As introduced in [10], a traditional PEKS scheme is deﬁned by a tuple of algo-
rithms (KeyGen, PEKS, Trapdoor, Test). The KeyGen algorithm is used for the
www.ebook3000.com

A New General Framework for Secure PEKS
63
generation of public/private key pair for the receiver. The sender runs PEKS
to generate keyword ciphertexts which are attached to the data. A receiver
then uses Trapdoor to generate the trapdoor for any keyword he/she wants
the server to search for. Given the trapdoors, the server can run the algo-
rithm Test to locate the data containing the keywords speciﬁed by the receiver.
As shown previously, it is impossible to construct a PEKS scheme secure
against keyword guessing attack from the malicious server if we follow the tra-
ditional PEKS framework due to the public generation of PEKS ciphertexts,
stand-alone testing, and the correctness of PEKS. In our proposed framework,
namely DS-PEKS, we disallow the stand-alone testing to obtain the security
against inside keyword guessing attacks. Roughly speaking, DS-PEKS consists
of (KeyGen, DS-PEKS, DS-Trapdoor, FrontTest, BackTest). To be more precise, the
KeyGen algorithm generates the public/private key pairs of the front and back
servers instead of that of the receiver. Moreover, the trapdoor generation algo-
rithm DS-Trapdoor deﬁned here is public while in the traditional PEKS deﬁnition
[5,10], the algorithm Trapdoor takes as input the receiver’s private key. Such a
diﬀerence is due to the diﬀerent structures used by the two systems. In the tradi-
tional PEKS, since there is only one server, if the trapdoor generation algorithm
is public, then the server can launch an oﬀ-line guessing attack against a key-
word ciphertext to recover the encrypted keyword. As a result, it is impossible
to achieve the semantic security as deﬁned in [5,10]. However, as we will show
later, under the DS-PEKS framework, we can still achieve semantic security
when the trapdoor generation algorithm is public. Another diﬀerence between
the traditional PEKS and our proposed DS-PEKS is that the test algorithm is
divided into two algorithms, FrontTest and BackTest run by two independent
servers. This is essential for achieving security against the inside keyword guess-
ing attacks.
2.2
Deﬁnition
Syntax. A DS-PEKS scheme is deﬁned by the following algorithms.
– Setup(1λ). Takes as input the security parameter λ, generates the system
parameters P;
– KeyGen(P). Takes as input the systems parameters P, outputs the pub-
lic/secret key pairs (pkF S, skF S), and (pkBS, skBS) for the front server, and
the back server respectively;
– DS-PEKS(P, pkF S, pkBS, kw1). Takes as input P, the front server’s public
key pkF S, the back server’s public key pkBS and the keyword kw1, outputs
the PEKS ciphertext CTkw1 of kw1;
– DS-Trapdoor(P, pkF S, pkBS, kw2). Takes as input P, the front server’s public
key pkF S, the back server’s public key pkBS and the keyword kw2, outputs
the trapdoor Tkw2;
– FrontTest(P, skF S, CTkw1, Tkw2). Takes as input P, the front server’s secret
key skF S, the PEKS ciphertext CTkw1 and the trapdoor Tkw2, outputs the
internal testing-state CIT S;

64
R. Chen et al.
– BackTest(P, skBS, CIT S). Takes as input P, the back server’s secret key skBS
and the internal testing-state CIT S, outputs the testing result 0 or 1;
Correctness. It is required that for any keyword kw1, kw2, and CTkw1 ←
DS-PEKS(P, pkF S, pkBS, kw1), Tkw2 ←DS-Trapdoor(P, pkF S, pkBS, kw2), we
have that BackTest(P, skBS, CIT S) = 1 if kw1 = kw2, otherwise 0.
2.3
Security Models
In this subsection, we formalise the security models for DS-PEKS. We deﬁne
the following security models for a DS-PEKS scheme against the adversarial
front and back servers, respectively. We should note that the following security
models also imply the security guarantees against the outside adversaries which
have less capability compared to the servers.
Adversarial Front Server. In this part, we deﬁne the security against an
adversarial front server. Precisely, we introduce two games, namely semantic-
security against chosen keyword attack and indistinguishability against key-
word guessing attack1 to capture the security of PEKS ciphertext and trapdoor,
respectively.
Semantic-Security against Chosen Keyword Attack (SS-CKA). In the following, we
deﬁne the semantic-security against chosen keyword attack which guarantees
that no adversary is able to distinguish a keyword from another one given the
corresponding PEKS ciphertext. That is, the PEKS ciphertext does not reveal
any information about the underlying keyword to any adversary.
– Setup. The challenger runs the KeyGen(λ) algorithm to generate key pairs
(pkF S, skF S) and (pkBS, skBS). It gives (pkF S, skF S, pkBS) to the attacker;
– Test query-I. The attacker can adaptively make the test query for any key-
word and any PEKS ciphertext of its choice. The challenger returns 1 or 0
as the test result to the attacker;
– Challenge. The attacker sends the challenger two keywords kw0, kw1. The
challenger picks b
$←{0, 1} and generates
CT ∗
kw ←DS-PEKS(P, pkF S, pkBS, kwb).
The challenger then sends CT ∗
kw to the attacker;
– Test query-II. The attacker can continue the test query for any keyword and
any PEKS ciphertext of its choice except of the challenge keywords kw0, kw1.
The challenger returns 1 or 0 as the test result to the attacker;
– Output. Finally, the attacker outputs its guess b′ ∈{0, 1} on b and wins the
game if b = b′.
1 In this paper, we use two diﬀerent terms, namely semantic security and indistin-
guishability, to deﬁne the security for the keyword ciphertext and the trapdoor,
respectively. However, as for normal public key encryption, these two terms are
equivalent.
www.ebook3000.com

A New General Framework for Secure PEKS
65
We refer to such an adversarial front server A in the above game as an SS-CKA
adversary and deﬁne its advantage as
AdvSS-CKA
FS,A (λ) = Pr[b = b′] −1/2.
Indistinguishability against Keyword Guessing Attack (IND-KGA). This model cap-
tures that the trapdoor reveals no information about the underlying keyword to
the adversarial front server. We deﬁne the security model as follows.
– Setup. The challenger runs the KeyGen(λ) algorithm to generate key pairs
(pkF S, skF S) and (pkBS, skBS). It gives (pkF S, skF S, pkBS) to the attacker;
– Test query-I. The attacker can adaptively make the test query for any key-
word and any PEKS ciphertext of its choice. The challenger returns 1 or 0
as the test result to the attacker;
– Challenge. The attacker sends the challenger two keywords kw0, kw1. The
challenger picks b
$←{0, 1} and generates
T ∗
kw ←DS-Trapdoor(P, pkF S, pkBS, kwb).
The challenger then sends T ∗
kw to the attacker;
– Test query-II. The attacker can continue issue the test query for any keyword
and any PEKS ciphertext of its choice except of the challenge keywords
kw0, kw1. The challenger returns 1 or 0 as the test result to the attacker;
– Output. Finally, the attacker outputs its guess b′ ∈{0, 1} on b and wins the
game if b = b′.
We refer to such an adversarial front server A in the above game as an IND-KGA
adversary and deﬁne its advantage as
AdvIND-KGA
FS,A
(λ) = Pr[b = b′] −1/2.
Adversarial Back Server. The security models of SS-CKA and IND-KGA in
terms of an adversarial back server are similar to those against an adversarial
front server.
Semantic-Security against Chosen Keyword Attack. Here the game against an
adversarial back server is the same as the one against an adversarial front server
except that the adversary is given the private key of the back server instead of
that of the front server. We omit the details here for simplicity.
We refer to the adversarial back server A in the SS-CKA game as an SS-CKA
adversary and deﬁne its advantage as AdvSS-CKA
BS,A (λ) = Pr[b = b′] −1/2.
Indistinguishability against Keyword Guessing Attack.
Similarly,
this
security
model aims to capture that the trapdoor does not reveal any information to
the back server and hence is the same as that against the front server except
that the adversary owns the private key of the back server instead of that of the
front server. Therefore, we also omit the details here.
We refer to the adversarial back server A in the IND-KGA game as an
IND-KGA adversary and deﬁne its advantage as AdvIND-KGA
BS,A
(λ) = Pr[b = b′]−1/2.

66
R. Chen et al.
Indistinguishability against Keyword Guessing Attack-II (IND-KGA-II). Apart from
the above two security models, we should also guarantee that the internal testing-
state does not reveal any information about the keyword to the back server.
We hence deﬁne another type of keyword guessing attack to capture such a
requirement. The security, namely Indistinguishability against Keyword Guess-
ing Attack-II guarantees that the back server cannot learn any information about
the keywords from the internal testing-state. The security model is deﬁned as
follows.
– Setup. The challenger runs the KeyGen(λ) algorithm to generates key pairs
(pkF S, skF S) and (pkBS, skBS). It gives (pkF S, pkBS, skBS) to the attacker.
– Challenge. The attacker sends the challenger three diﬀerent keywords
kw0, kw1,
kw2. The challenger picks {b1, b2} ⊂{0, 1, 2} randomly and computes
CT ∗
kw ←DS-PEKS(P, pkF S, pkBS, kwb1),
T ∗
kw ←DS-Trapdoor(P, pkF S, pkBS, kwb2),
C∗
IT S ←FrontTest(P, skF S, CT ∗
kw, T ∗
kw).
The challenger then sends C∗
IT S to the attacker.
– Output. Finally, the attacker outputs its guess on {b1, b2} as {b′
1, b′
2} ⊂
{0, 1, 2} and wins the game if {b′
1, b′
2} = {b1, b2}.
We refer to such an adversary A in the above two games as a IND-KGA-II adver-
sary and deﬁne its advantage as,
AdvIND-KGA-II
BS,A
(λ) = Pr[{b′
1, b′
2} = {b1, b2}] −1/3.
We should remark that in the above game, b1 and b2 can be equivalent. In
this case, the adversary (i.e., back server) will know that the same keyword has
been used in the generation of the PEKS ciphertext and the trapdoor, and the
adversary’s goal is to guess which keyword among the three has been used.
Based on the security models deﬁned above, we give the following security
deﬁnition for a DS-PEKS scheme.
Deﬁnition 1. We say that a DS-PEKS is secure if for any polynomial
time attacker Ai (i = 1, . . . , 5), we have that AdvSS-CKA
BS,A1 (λ),AdvSS−CKA
BS,A2 (λ),
AdvIND-KGA
FS,A3 (λ), AdvIND-KGA
BS,A4
(λ) and AdvIND-KGA-II
BS,A5
(λ) are all negligible functions
of the security parameter λ.
3
Smooth Projective Hash Functions
A central element of our construction for dual-server public key encryption with
keyword search is smooth projective hash function (SPHF), a notion introduced
by Cramer and Shoup [13] and extended for construction of many cryptographic
primitives [2,8,15,16,18]. We start with the original deﬁnition of an SPHF.
www.ebook3000.com

A New General Framework for Secure PEKS
67
3.1
SPHF
Syntax. An SPHF can be deﬁned based on a domain X and an NP language
L, where L contains a subset of the elements of the domain X, i.e., L ⊂X. An
SPHF system over a language L ⊂X, onto a set Y, is deﬁned by the following
ﬁve algorithms (SPHFSetup, HashKG, ProjKG, Hash, ProjHash):
– SPHFSetup(1λ): generates the global parameters param and the description
of an NP language instance L;
– HashKG(L, param): generates a hashing key hk for L;
– ProjKG(hk, (L, param)): derives the projection key hp from the hashing key
hk;
– Hash(hk, (L, param), W): outputs the hash value hv ∈Y for the word W from
the hashing key hk;
– ProjHash(hp, (L, param), W, w): outputs the hash value hv′ ∈Y for the word
W from the projection key hp and the witness w for the fact that W ∈L.
Property. A smooth projective hash function SPHF should satisfy the follow-
ing properties,
– Correctness. If a word W ∈L with w the witness, then for all hashing key
hk and projection key hp, we have
Hash(hk, (L, param), W) = ProjHash(hp, (L, param), W, w).
– Smoothness. Let a point W be not in the language, i.e., W ∈X\L. Then the
following two distributions are statistically indistinguishable :
V1 = {(L, param, W, hp, hv)|hv = Hash(hk, (L, param), W)},
V2 = {(L, param, W, hp, hv)|hv
$←Y},
To be more precise, the quantity of 
v∈Y | PrV1[hv = v] −PrV2[hv = v]| is
negligible.
In this paper, we require another important property of smooth projective
hash functions that was introduced in [15].
– Pseudo-Randomness. If a word W ∈L, then without the corresponding
witness w, the distribution of the hash output is computationally indistin-
guishable from a uniform distribution in the view of any polynomial-time
adversary A. That is, A can only win in the PR-game deﬁned below with
negligible probability.
• Setup.
The
challenger
runs
SPHFSetup, HashKG, ProjKG,
generates
param,
hk, hp, L and sends the adversary (param, L, hp).
• Challenge. The challenger picks W
$←L, b
$←{0, 1} and generates
hv =

Hash(hk, (L, param), W)
b = 1,
v
$←Y
b = 0.
The challenger then sends (W, hv) to A.

68
R. Chen et al.
• Output. Finally, A outputs its guess b′ ∈{0, 1} on b and wins the game
if b = b′.
We deﬁne the advantage of A in the above game as,
AdvPR
SPHF,A(λ) = Pr[b = b′] −1/2.
We say SPHF is pseudo-random if for any polynomial time adversary A,
we have that AdvPR
SPHF,A(λ) is a negligible function.
3.2
Lin-Hom SPHF
In this paper, we consider a new variant of smooth projective hash function.
We consider two new properties: linear and homomorphic, which are deﬁned
below. It is worth noting that Abdalla et al. [3] introduced conjunction and
disjunction of languages for smooth projective hashing that were later used in
the construction of blind signature [7,9], oblivious signature-based envelops [9],
and authenticated key exchange protocols for algebraic languages [6]. As shown
in the following, our deﬁnition for the new SPHF here is diﬀerent from their work
since we consider the operations on the words belonging to the same language,
whereas theirs considers operations among diﬀerent languages.
Let SPHF=(SPHFSetup, HashKG, ProjKG, Hash, ProjHash) be a smooth pro-
jective hash function over the language L ⊂X onto the set Y and W be the
witness space of L. We ﬁrst describe the operations on the sets < L, Y, W > as
follows.
– ⊚: L × L →L. For any W1 ∈L, W2 ∈L, W1 ⊚W2 ∈L;
– ⊛: Y × Y →Y. For any y1 ∈Y, y2 ∈Y, y1 ⊛y2 ∈Y;
– ⊙, ⊕: W ×W →W. For any w1 ∈W, w2 ∈W, w1 ⊙w2 ∈W and w1 ⊕w2 ∈
W;
– ⊗: W × L →L. For any w ∈W, W ∈L, w ⊗W ∈L;
– • : W × Y →Y. For any w ∈W, y ∈Y, w • y ∈Y.
Moreover, for any element y ∈Y, we deﬁne y⊛y−1 = 1Y which is the identity
element of Y.
Our new SPHF requires the underlying language to be also linear and homo-
morphic language, which is deﬁned below.
Deﬁnition 2 (Linear and Homomorphic Language). A language L is linear
and homomorphic if it satisﬁes the following properties.
– For any word W ∈L with witness w and Δw ∈W, there exists a word
W ∗∈L such that Δw ⊗W = W ∗with the witness w∗= Δw ⊙w.
– For any two words W1, W2 ∈L with the witness w1, w2 ∈W respectively,
there exists a word W ∗∈L such that W1 ⊚W2 = W ∗with the witness
w∗= w1 ⊕w2.
We then give the deﬁnition of Lin-Hom SPHF as follows.
Deﬁnition 3 (Lin-Hom SPHF (LH-SPHF)). We say SPHF is a Lin-Hom
SPHF (LH-SPHF) if the underlying language L is a linear and homomorphic
language and SPHF satisﬁes the following properties.
www.ebook3000.com

A New General Framework for Secure PEKS
69
– For any word W ∈L with the witness w ∈W and Δw ∈W, we have
Hash(hk, (L, param), Δw ⊗W) = Δw • Hash(hk, (L, param), W).
In other words, suppose Δw ⊗W = W ∗, we have,
ProjHash(hp, (L, param), W ∗, w∗) = Δw • ProjHash(hp, (L, param), W, w),
where w∗= Δw ⊙w.
– For any two words W1, W2 ∈L with the witness w1, w2 ∈W, we have
Hash(hk, (L, param), W1 ⊚W2) =
Hash(hk, (L, param), W1) ⊛Hash(hk, (L, param), W2).
In other words, suppose W1 ⊚W2 = W ∗, we have,
ProjHash(hp, (L, param), W ∗, w∗) =
ProjHash(hp, (L, param), W1, w1)⊛ProjHash(hp, (L, param), W2, w2)
where w∗= w1 ⊕w2.
In this paper, we also assume that the LH-SPHF has the following property:
for any y ∈Y, W ∈L and the witness w ∈W of W, there exists a projection
key hp such that ProjHash(hp, (L, param), W, w) = y.
4
Generic Construction of DS-PEKS Using LH-SPHF
In this section, we show how to generically construct a Dual-Server Public Key
Encryption with keyword search based on Lin-Hom Smooth Projective Hash
Functions.
4.1
Generic Construction
Suppose SPHF
= (SPHFSetup, HashKG, ProjKG, Hash, ProjHash) is an LH-
SPHF over the language L onto the set Y. Let W be the witness space of the
language L and KW be the keyword space. Our generic construction DS-PEKS
works as follows.
Setup(1λ). Take as input the security parameter λ, run SPHFSetup algorithm
and generate the global parameters param, the description of the language L
and a collision-resistant hash function Γ : KW →Y. Set the system parameter
P =< param, L, Γ >.
KeyGen(P). Take as input P, run the algorithms < HashKG, ProjHash > to gen-
erate the public/private key pairs (pkF S, skF S), (pkBS, skBS) for the front server
and the back server respectively.
pkF S ←HashKG(P), skF S = ProjKG(P, pkF S),

70
R. Chen et al.
pkBS ←HashKG(P), skBS = ProjKG(P, pkBS).
DS-PEKS(P, pkF S, pkBS, kw1). Take as input P, pkF S, pkBS and the keyword
kw1, pick a word W1 ∈L randomly with the witness w1 and generate the PEKS
ciphertext CTkw1 of kw1 as following.
x1 = ProjHash(P, pkF S, W1, w1),
y1 = ProjHash(P, pkBS, W1, w1),
C1 = x1 ⊛y1 ⊛Γ(kw1).
Set CTkw1 =< W1, C1 > and return CTkw1 as the keyword ciphertext.
DS-Trapdoor(P, pkF S, pkBS, kw2). Take as input P, pkF S, pkBS and the keyword
kw2, pick a word W2 ∈L randomly with the witness w2 and generate the
trapdoor Tkw2 of kw2 as follows.
x2 = ProjHash(P, pkF S, W2, w2),
y2 = ProjHash(P, pkBS, W2, w2),
C2 = x2 ⊛y2 ⊛Γ(kw2)−1.
Set Tkw2 =< W2, C2 > and return Tkw2 as the trapdoor.
FrontTest(P, skF S, CTkw, Tkw). Takes as input P, the front server’s secret key
skF S, the PEKS ciphertext CTkw1 =< W1, C1 > and the trapdoor Tkw2 =<
W2, C2 >, pick Δw ∈W randomly, generate the internal testing-state CIT S as
follows.
W = W1 ⊚W2,
x = Hash(P, skF S, W),
C = C1 ⊛C2 ⊛x−1,
W ∗= Δw ⊗W, C∗= Δw • C.
Set CIT S =< W ∗, C∗> and return CIT S as the internal testing-state.
BackTest(P, skBS, CIT S). Takes as input P, the back server’s secret key skBS
and the internal testing-state CIT S =< W ∗, C∗> , test as follows.
Hash(P, skBS, W ∗)
?= C∗
If yes output 1, else output 0.
Correctness Analysis. One can see that the correctness of this construction
is guaranteed by the important properties of the LH-SPHF. To be more precise,
we give the analysis as follows.
www.ebook3000.com

A New General Framework for Secure PEKS
71
For the algorithm FrontTest, we have
x = Hash(P, skF S, W)
= Hash(P, skF S, W1 ⊙W2)
= Hash(P, skF S, W1) ⊛Hash(P, skF S, W2)
= ProjHash(P, pkF S, W1, w1) ⊛ProjHash(P, pkF S, W2, w2)
= x1 ⊛x2.
Therefore,
C = C1 ⊛C2 ⊛x−1
= x1 ⊛y1 ⊛Γ(kw1) ⊛x2 ⊛y2 ⊛Γ(kw2)−1 ⊛(x1 ⊛x2)−1
= y1 ⊛y2 ⊛Γ(kw1) ⊛Γ(kw2)−1.
For the algorithm BackTest, we have
Hash(P, skBS, W ∗)
= Hash(P, skBS, Δw ⊗W)
= Δw • Hash(P, skBS, W)
= Δw • Hash(P, skBS, W1 ⊚W2).
= Δw • (Hash(P, skBS, W1) ⊛Hash(P, skBS, W2))
= Δw • (ProjHash(P, pkBS, W1, w1) ⊛ProjHash(P, pkBS, W2, w2))
= Δw • (y1 ⊛y2).
It is easy to see that if kw1 = kw2, then Hash(P, skBS, W ∗) = Δw • C = C∗.
Otherwise, Hash(P, skBS, W ∗) ̸= C∗due to the collision-resistant property of
the hash function Γ.
4.2
Security of DS-PEKS
In this subsection, we analyse the security of the above generic construction.
Theorem 1. The generic construction DS-PEKS is semantically secure under
chosen keyword attacks.
The above theorem can be obtained from the following two lemmas.
Lemma 1. For any polynomial-time adversary A, AdvSS-CKA
FS,A (λ) is a negligible
function.
Proof. We deﬁne a sequence of games as follows.
Game0. This is the original SS-CKA game against the adversarial front server.
– Setup. The challenger runs the Setup, KeyGen to generate system parameter
P, key pairs (pkF S, skF S) and (pkBS, skBS). It then gives adversary A the
key pair (P, pkF S, skF S, pkBS).

72
R. Chen et al.
– Test Query-I. The adversary makes a query on < kw, CT >. Suppose CT =
(W, C), the challenger computes the following.
T ←DS-Trapdoor(P, pkF S, pkBS, kw),
CIT S ←FrontTest(P, skF S, C, T).
The challenger then runs the algorithm BackTest(P, skBS, CIT S) and returns
the output to the adversary.
– Challenge. A chooses two keywords kw0, kw1 and sends kw0, kw1 to the chal-
lenger. The challenger ﬁrst picks b
$←{0, 1}, and then picks a word W1 ∈L
randomly with the witness w1 and generates the PEKS ciphertext CT ∗
kw of
kwb as follows.
x1 = ProjHash(P, pkF S, W1, w1), y1 = ProjHash(P, pkBS, W1, w1),
C1 = x1 ⊛y1 ⊛Γ(kwb).
The challenger sets CT ∗
kw =< W1, C1 > as the keyword ciphertext and sends
CT ∗
kw to A.
– Test Query-II. The procedure is the same as that in Test Query-I.
– Output. Finally, A outputs its guess b′ ∈{0, 1} on b and wins the game if
b = b′.
We deﬁne the advantage of A in Game0 as AdvGame0
FS,A(λ) and have that
AdvGame0
FS,A(λ) = AdvSS−CKA
FS,A
(λ)
as Game0 strictly follows the SS-CKA model.
Game1. Let Game1 be the same game as Game0, except that the challenger
chooses y1
$←Y instead of computing y1 as ProjHash(P, pkBS, W1, w1). Due
to the correctness and pseudo-randomness of SPHF, that is, the distribution
{(P, W1, pkBS, y1)|y1 = ProjHash(P, pkBS, W1, w1)} is computationally indistin-
guishable from the distribution {(P, W1, pkBS, y1)|y1
$←Y}, we have that
|AdvGame1
FS,A(λ) −AdvGame0
FS,A(λ)| ≤AdvPR
SPHF,A(λ).
Game2. Let Game2 be the same game as Game1, except that the challenger
chooses C1
$←Y instead of computing C1 = x1 ⊛y1 ⊛Γ(kwb). We can see that
AdvGame2
FS,A(λ) = AdvGame1
FS,A(λ).
It is easy to see that the adversary in Game2 can only win with probability
1/2 as C1 is independent of b. Therefore, we have that AdvGame2
DS-PEKS,A(λ) = 0.
Therefore, from Game0, Game1 and Game2, we have that
|AdvGame2
FS,A(λ) −AdvSS-CKA
FS,A (λ)| ≤AdvPR
SPHF,A(λ).
As AdvGame2
FS,A(λ) = 0 and AdvPR
SPHF,A(λ) is negligible, we have that AdvSS-CKA
FS,A (λ)
is also negligible, which completes the proof.
www.ebook3000.com

A New General Framework for Secure PEKS
73
Lemma 2. For any polynomial-time adversary A, AdvSS-CKA
BS,A (λ) is a negligible
function.
The proof of Lemma 2. can be easily obtained by following the proof of
Lemma 1., and hence is omitted.
Theorem 2. The generic construction DS-PEKS is secure against keyword
guessing attack.
The above theorem can be obtained from the following lemmas.
Lemma 3. For any polynomial-time adversary A, AdvIND-KGA
FS,A
(λ) is a negligible
function.
Lemma 4. For any polynomial-time adversary A, AdvIND-KGA
BS,A
(λ) is a negligible
function.
The proofs of Lemma 3. and Lemma 4. are similar to those of Lemma 1.
and Lemma 2. as the generation of a trapdoor is the same as that of a PEKS
ciphertext, and the security model of IND-KGA is also similar to that of SS-
CKA. Therefore, we omit the proof details here. For the security against the
keyword guessing attack-II, we have the following lemma.
Lemma 5. For any polynomial-time adversary A, AdvIND-KGA-II
BS,A
(λ) is a negligi-
ble function.
Proof. In the IND-KGA-II game, if b1 = b2, then it is easy to see that the
adversary has no advantage since the two keywords are canceled out in the
internal testing-state CIT S, which means CIT S is independent of the keywords.
In the following, we focus on the case that b1 ̸= b2.
Here, we use the game-hopping technique again to prove this lemma. We
deﬁne a sequence of attack games as follows.
Game0. Let the original IND-CKA game be Game0.
– Setup. The challenger runs the Setup, KeyGen to generate system parameter
P, key pairs (pkF S, skF S) and (pkBS, skBS). It gives adversary A the key
pairs (P, pkF S, pkBS, skBS).
– Challenge. A chooses challenge keywords kw0, kw1, kw2 adaptively and sends
them to the challenger. The challenger ﬁrstly picks {b1, b2} ⊂{0, 1, 2} ran-
domly.
The challenger picks two words W1, W2 ∈L randomly with the witness
w1, w2 respectively and generates the internal testing-state CIT S as follows.
x1 = ProjHash(P, pkF S, W1, w1), y1 = ProjHash(P, pkBS, W1, w1),
x2 = ProjHash(P, pkF S, W2, w2), y2 = ProjHash(P, pkBS, W2, w2),
W = W1 ⊚W2, x = Hash(P, skF S, W),
C = x1 ⊛x2 ⊛y1 ⊛y2 ⊛x−1 ⊛Γ(kwb1) ⊛Γ(kwb2)−1,
W ∗= Δw ⊗W, C∗= Δw • C.
Set C∗
IT S =< W ∗, C∗> and return C∗
IT S to A.

74
R. Chen et al.
– Output. Finally, A outputs its guess on {b1, b2} as {b′
1, b′
2} ⊂{0, 1, 2} and
wins the game if {b′
1, b′
2} = {b1, b2}.
We deﬁne the advantage of A in Game0 as AdvGame0
BS,A (λ) and have that
AdvGame0
BS,A (λ) = AdvIND-KGA-II
BS,A
(λ)
as Game0 strictly follows the IND-KGA-II model.
Game1. Let Game1 be the same game as Game0, except that the challenger
chooses y
$←Y and computes C∗as follows.
C∗= (x1 ⊛x2 ⊛y1 ⊛y2 ⊛x−1) ⊛y.
In other words, the challenger replaces the part Δw·(Γ(kwb1)⊛Γ(kwb2)−1) with
a random chosen element y ∈Y during the generation of C∗. We now prove that
the replacement in this way can make at most a negligible diﬀerence, that is,
Claim.
For any polynomial-time adversary A,
|AdvGame1
BS,A (λ) −AdvGame0
BS,A (λ)| ≤AdvPR
SPHF,A(λ).
Proof. Since the language L is a linear and homomorphic language, we have that
the witness of W ∗is w∗= Δw ⊗w where w is the witness of W. Then based on
our deﬁnition of LH-SPHF there exists a projection key hp′ that
ProjHash(P, hp′, W, w) = Γ(kwb1) ⊛Γ(kwb2)−1.
As SPHF is a Lin-Hom SPHF, we have that
ProjHash(P, hp′, W ∗, w∗) = Δw • ProjHash(P, hp′, W, w)
= Δw • (Γ(kwb1) ⊛Γ(kwb2)−1).
Moreover, the distribution {(P, W ∗, hp′, y)|y = ProjHash(P, hp′, W ∗, w∗)} is
computationally indistinguishable from the distribution {(P, W ∗, hp′, y)|y
$←Y}
due to the correctness and pseudo-randomness of SPHF. Therefore, we have
that
|AdvGame1
BS,A (λ) −AdvGame0
BS,A (λ)| ≤AdvPR
SPHF,A(λ).
Game2. Let Game2 be the same game as Game1, except that the challenger
chooses C∗
$←Y . We can see that
AdvGame2
BS,A (λ) = AdvGame1
BS,A (λ).
It is easy to see that the adversary can only win in the Game2 with probability
1/3 as C∗is independent of b1, b2. Therefore, we have that AdvGame2
BS,A (λ) = 0.
Therefore, from Game0, Game1 and Game2, we have that
|AdvGame2
BS,A (λ) −AdvIND-KGA-II
BS,A
(λ)| ≤AdvPR
SPHF,A(λ).
As
AdvGame2
BS,A (λ)
=
0
and
AdvPR
SPHF,A(λ)
is
negligible,
we
have
that
AdvIND-KGA-II
BS,A
(λ) is also a negligible function, which proves the lemma.
www.ebook3000.com

A New General Framework for Secure PEKS
75
5
Conclusion
In this paper, we proposed a new framework, named Dual-Server Public Key
Encryption with Keyword Search (DS-PEKS), that can prevent the inside key-
word guessing attack which is an inherent vulnerability of the traditional PEKS
framework. We then introduced a new Smooth Projective Hash Function (SPHF)
and used it to construct a generic DS-PEKS scheme. The new variant of SPHF
introduced in this paper is of independent interest.
References
1. Abdalla, M., et al.: Searchable encryption revisited: consistency properties, relation
to anonymous IBE, and extensions. In: Shoup, V. (ed.) CRYPTO 2005. LNCS, vol.
3621, pp. 205–222. Springer, Heidelberg (2005)
2. Abdalla, M., Benhamouda, F., Blazy, O., Chevalier, C., Pointcheval, D.: SPHF-
friendly non-interactive commitments. In: Sako, K., Sarkar, P. (eds.) ASIACRYPT
2013, Part I. LNCS, vol. 8269, pp. 214–234. Springer, Heidelberg (2013)
3. Abdalla, M., Chevalier, C., Pointcheval, D.: Smooth projective hashing for condi-
tionally extractable commitments. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol.
5677, pp. 671–689. Springer, Heidelberg (2009)
4. Baek, J., Safavi-Naini, R., Susilo, W.: On the integration of public key data encryp-
tion and public key encryption with keyword search. In: Katsikas, S.K., L´opez, J.,
Backes, M., Gritzalis, S., Preneel, B. (eds.) ISC 2006. LNCS, vol. 4176, pp. 217–232.
Springer, Heidelberg (2006)
5. Baek, J., Safavi-Naini, R., Susilo, W.: Public key encryption with keyword
search revisited. In: Gervasi, O., Murgante, B., Lagan`a, A., Taniar, D., Mun,
Y., Gavrilova, M.L. (eds.) ICCSA 2008, Part I. LNCS, vol. 5072, pp. 1249–1259.
Springer, Heidelberg (2008)
6. Ben Hamouda, F., Blazy, O., Chevalier, C., Pointcheval, D., Vergnaud, D.: Eﬃcient
UC-secure authenticated key-exchange for algebraic languages. In: Kurosawa, K.,
Hanaoka, G. (eds.) PKC 2013. LNCS, vol. 7778, pp. 272–291. Springer, Heidelberg
(2013)
7. Ben Hamouda, F., Blazy, O., Chevalier, C., Pointcheval, D., Vergnaud, D.: New
smooth projective hash functions and one-round authenticated key exchange. IACR
Cryptology ePrint Archive 2013, 34 (2013)
8. Benhamouda, F., Blazy, O., Chevalier, C., Pointcheval, D., Vergnaud, D.: New
techniques for SPHFs and eﬃcient one-round PAKE protocols. In: Canetti, R.,
Garay, J.A. (eds.) CRYPTO 2013, Part I. LNCS, vol. 8042, pp. 449–475. Springer,
Heidelberg (2013)
9. Blazy, O., Pointcheval, D., Vergnaud, D.: Round-optimal privacy-preserving proto-
cols with smooth projective hash functions. In: Cramer, R. (ed.) TCC 2012. LNCS,
vol. 7194, pp. 94–111. Springer, Heidelberg (2012)
10. Boneh, D., Di Crescenzo, G., Ostrovsky, R., Persiano, G.: Public key encryption
with keyword search. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004.
LNCS, vol. 3027, pp. 506–522. Springer, Heidelberg (2004)
11. Byun, J.W., Rhee, H.S., Park, H.-A., Lee, D.-H.: Oﬀ-line keyword guessing attacks
on recent keyword search schemes over encrypted data. In: Jonker, W., Petkovi´c,
M. (eds.) SDM 2006. LNCS, vol. 4165, pp. 75–83. Springer, Heidelberg (2006)

76
R. Chen et al.
12. Cocks, C.: An identity based encryption scheme based on quadratic residues. In:
Honary, B. (ed.) Cryptography and Coding 2001. LNCS, vol. 2260, pp. 360–363.
Springer, Heidelberg (2001)
13. Cramer, R., Shoup, V.: Universal hash proofs and a paradigm for adaptive chosen
ciphertext secure public-key encryption. In: Knudsen, L.R. (ed.) EUROCRYPT
2002. LNCS, vol. 2332, pp. 45–64. Springer, Heidelberg (2002)
14. Di Crescenzo, G., Saraswat, V.: Public key encryption with searchable key-
words based on jacobi symbols. In: Srinathan, K., Rangan, C.P., Yung, M. (eds.)
INDOCRYPT 2007. LNCS, vol. 4859, pp. 282–296. Springer, Heidelberg (2007)
15. Gennaro, R., Lindell, Y.: A framework for password-based authenticated key
exchange. In: Biham, Eli (ed.) EUROCRYPT 2003. LNCS, vol. 2656, pp.
524–543. Springer, Heidelberg (2003)
16. Halevi, S., Kalai, Y.T.: Smooth projective hashing and two-message oblivious
transfer. J. Cryptology 25(1), 158–193 (2012)
17. Jeong, I.R., Kwon, J.O., Hong, D., Lee, D.H.: Constructing PEKS schemes secure
against keyword guessing attacks is possible? Computer Communications 32(2),
394–396 (2009)
18. Katz, J., Vaikuntanathan, V.: Round-optimal password-based authenticated key
exchange. In: Ishai, Y. (ed.) TCC 2011. LNCS, vol. 6597, pp. 293–310. Springer,
Heidelberg (2011)
19. Khader, D.: Public key encryption with keyword search based on K-resilient IBE.
In: Gavrilova, M.L., Gervasi, O., Kumar, V., Tan, C.J.K., Taniar, D., Lagan´a, A.,
Mun, Y., Choo, H. (eds.) ICCSA 2006. LNCS, vol. 3982, pp. 298–308. Springer,
Heidelberg (2006)
20. Rhee, H.S., Park, J.H., Susilo, W., Lee, D.H.: Trapdoor security in a searchable
public-key encryption scheme with a designated tester. Journal of Systems and
Software 83(5), 763–771 (2010)
21. Rhee, H.S., Susilo, W., Kim, H.: Secure searchable public key encryption scheme
against keyword guessing attacks. IEICE Electronic Express 6(5), 237–243 (2009)
22. Waters, B.R., Balfanz, D., Durfee, G., Smetters, D.K.: Building an encrypted and
searchable audit log. In: Proceedings of the Network and Distributed System Secu-
rity Symposium, NDSS 2004, San Diego, California, USA (2004)
23. Yau, W.-C., Heng, S.-H., Goi, B.-M.: Oﬀ-line keyword guessing attacks on recent
public key encryption with keyword search schemes. In: Rong, C., Jaatun, M.G.,
Sandnes, F.E., Yang, L.T., Ma, J. (eds.) ATC 2008. LNCS, vol. 5060, pp. 100–105.
Springer, Heidelberg (2008)
www.ebook3000.com

Dynamic Threshold Public-Key Encryption
with Decryption Consistency
from Static Assumptions
Yusuke Sakai1(B), Keita Emura2, Jacob C.N. Schuldt1,
Goichiro Hanaoka1, and Kazuo Ohta3
1 National Institute of Advanced Industrial Science and Technology (AIST),
Tsukuba, Japan
yusuke.sakai@aist.go.jp
2 National Institute of Information and Communications Technology (NICT),
Koganei, Japan
3 The University of Electro-Communications, Chofu, Japan
Abstract. Dynamic threshold public-key encryption (dynamic TPKE)
is a natural extension of ordinary TPKE which allows decryption servers
to join the system dynamically after the system is set up, and allows
the sender to dynamically choose the authorized set and the decryption
threshold at the time of encryption. Currently, the only known dynamic
TPKE scheme is a scheme proposed by Delerabl´ee and Pointcheval
(CRYPTO 2008). This scheme is proven to provide message conﬁden-
tiality under a q-type assumption, but to achieve decryption consistency,
a random oracle extension is required.
In this paper we show conceptually simple methods for constructing
dynamic TPKE schemes with decryption consistency from only static
assumptions (e.g., the decisional linear assumption in bilinear groups)
without relying on random oracles. Our ﬁrst construction is a purely
generic construction from public-key encryption with non-interactive
opening (PKENO) formalized by Damg˚ard et al. (CT-RSA 2008). How-
ever, this construction achieves a slightly weaker notion of decryption
consistency compared to the random oracle extension of the Delerabl´ee
and Pointcheval scheme, which satisﬁes the notion deﬁned by Boneh,
Boyen and Halevi (CT-RSA 2005). Our second construction uses a spe-
ciﬁc PKENO scheme based on the decisional linear assumption in com-
bination with the eﬃcient zero-knowledge proofs by Groth and Sahai. In
contrast to our ﬁrst construction, our second construction achieves the
stronger notion of decryption consistency deﬁned by Boneh, Boyen and
Halevi.
1
Introduction
Dynamic Threshold Encryption. Threshold public-key encryption (TPKE)
[4,7,9,24] is an extension of ordinary public-key encryption which distributes the
secret key among several (say, n) decryption servers such that arbitrary k servers
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 77–92, 2015.
DOI: 10.1007/978-3-319-19962-7 5

78
Y. Sakai et al.
are required to cooperate to successfully decrypt a ciphertext. This is desirable,
for example, when attempting to hedge against key exposure. In this paper,
we consider non-interactive TPKE schemes, which means that each decryption
server is able to produce its “decryption share” without interacting with other
parties, and any k decryption shares from k diﬀerent servers can be combined
successfully to produce the correct plaintext.
In addition to (a threshold variant of) chosen-ciphertext security, TPKE
schemes are required to satisfy decryption consistency [3,24]. This security prop-
erty requires that even if a sender and the decryption servers collude, they cannot
create two diﬀerent sets of k decryption shares which respectively produce dif-
ferent plaintexts when honestly combined. This property forces a sender to com-
mit to the message being encrypted. More speciﬁcally, decryption consistency
prevents a malicious sender from creating “equivocal” ciphertexts essentially
corresponding to the encryption of two diﬀerent messages, and then, at a later
stage, deciding what message the ciphertext should be decrypted to by forcing
a speciﬁc set of servers to participate in the decryption process.
Many TPKE schemes have the limitation that the set of authorized decryp-
tion servers (i.e. the servers allowed to participate in the decryption process) and
the threshold are required to be ﬁxed at the setup time of the scheme. In addi-
tion, decryption servers cannot join the system after the system is set up. This
restricts the ﬂexibility of these schemes, and potentially limits their applications.
To address these restrictions, Delerabl´ee and Pointcheval [8] proposed
dynamic TPKE. A dynamic TPKE scheme allows a decryption server to join the
system after the setup, and furthermore allows a sender to choose the thresh-
old k and the authorized set of servers, among which any k servers can suc-
cessfully decrypt the ciphertext when they cooperate. However, their scheme is
proven secure under a q-type assumption called the multi-sequence of exponent
Diﬃe-Hellman (MSE-DDH) assumption, and the proof of decryption consistency
furthermore relies on the random oracle model. In summary, the only known
dynamic TPKE with decryption consistency relies on both a q-type assumption
and the random oracle model.
Our Contribution. In this paper, we propose new dynamic TPKE schemes
supporting decryption consistency without relying on random oracles or q-
type assumptions. More precisely we propose two constructions of dynamic
TPKE, both of which use public-key encryption with non-interactive opening
(PKENO) [5] as a core component. PKENO is an extension of ordinary public-
key encryption that allows the receiver to prove the validity of the decryption
result without revealing the decryption key. Note that PKENO can be con-
structed from any group signature satisfying standard security notions [11], and
thus our result also implies that TPKE (satisfying a strong security notion) can
be obtained from any group signature. Furthermore, it is known that we can con-
struct a PKENO scheme from the decisional linear (DLIN) or decisional bilinear
Diﬃe-Hellman (DBDH) assumptions [12,13]. This also implies that it is possible
to construct a dynamic TPKE scheme with decryption consistency from any of
these assumptions.
www.ebook3000.com

Dynamic Threshold Public-Key Encryption with Decryption Consistency
79
Our ﬁrst construction uses a PKENO scheme in a black-box manner i.e. it is
a generic construction of dynamic TPKE from PKENO. More speciﬁcally, this
construction converts any PKENO scheme (satisfying standard security notions)
to a dynamic TPKE scheme with a relatively weaker notion of decryption con-
sistency. Our construction combines the Dodis-Katz multiple encryption tech-
nique [10] and veriﬁable secret sharing [1,2] to ensure decryption consistency.
By applying this generic construction to existing PKENO schemes such as [13]
and [12], we can obtain dynamic TPKE schemes with decryption consistency
which are secure under the DLIN and DBDH assumptions, respectively, with-
out relying on random oracles. Our construction implies a ciphertext overhead
proportional to n2, where n is the number of decryption servers.
Our second construction improves upon the ﬁrst construction by providing a
stronger notion of decryption consistency, which is achieved by relying on a direct
construction. This is the ﬁrst dynamic TPKE scheme with strong decryption
consistency which is proven secure under the DLIN assumption without using
random oracles. This scheme provides decryption consistency which is similar in
strength to that of the (non-dynamic) Boneh-Boyen-Halevi scheme [3]. Further-
more, it also achieves an asymptotically shorter ciphertext overhead than the
ﬁrst generic construction; the ciphertext overhead is proportional to the number
of decryption servers n.
Our results highlight the usefulness of PKENO to construct TPKE schemes,
as both of the above constructions make use of PKENO as a central building
block. Note that the usability of PKENO for constructing TPKE has been con-
jectured by [13], although the conjecture has not been explored in detail in the
literature. The subtleties in the conjecture is evidenced by the fact that neither
of our two constructions are straightforward combinations of existing techniques
(e.g. [10]) and PKENO, and still do not simultaneously achieve strong decryption
consistency and the property of being a black-box construction from PKENO.
Our schemes are shown secure in a dynamic extension of the Boneh-Boyen-
Halevi security model [3]. Hence, like [3], we consider a static corruption model
in which the set of corrupt users are ﬁxed in the beginning of the security game.
Note that while Delerabl´ee-Pointcheval presented an adaptive corruption model
in [8], their scheme is only shown secure in a static model. It remains an open
problem to construct a dynamic TPKE scheme secure in an adaptive corrup-
tion model, or a dynamic TPKE scheme with constant ciphertext size, which
maintains the security properties of our constructed schemes (without relying
on random oracles).
Diﬃculty. Our approach is to enhance the Dodis-Katz multiple encryption
technique [10] to obtain the ability to detect malicious behavior of both sender
and decryption servers. Using the Dodis-Katz multiple encryption technique,
a TPKE scheme can be constructed from an ordinary PKE scheme. In this
construction, each decryption server is assigned a key pair of a PKE scheme. To
encrypt a plaintext, the sender divides the plaintext into multiple shares using
a k-out-of-n secret sharing scheme, and each share is then encrypted for one
of the decryption servers. Using this construction, we might easily implement a

80
Y. Sakai et al.
dynamic TPKE without decryption consistency, as each decryption server can
generate its own key pair to join the system, and to specify the authorized set
dynamically, a sender simply encrypts for the public keys of the servers that
the sender wants to be authorized. More speciﬁcally, the sender will generate a
ciphertext by simply dividing the plaintext into shares of a secret sharing scheme
(with an appropriated threshold), and encrypting these shares one by one using
each of the servers’ public keys.
The problem with this approach is the diﬃculty of ensuring consistency
among the shares. Namely, if we combine Shamir’s k-out-of-n scheme with the
Dodis-Katz multiple encryption, the encrypted n shares should correspond to
points on a degree-(k −1) polynomial, since otherwise diﬀerent k shares may
result in diﬀerent decryption results, which will violate decryption consistency.
However, ensuring this presents a problem since the shares are encrypted. In
particular, some k servers only see k shares but not the other n −k shares,
and thus, these k servers are not able to check the consistency of the all shares.
This is the reason the straightforward application of PKENO to the Dodis-Katz
construction will not provide decryption consistency.
Our Technique. The ﬁrst construction combines the Dodis-Katz construction
with techniques from veriﬁable secret sharing [1,2], which is a classical technique
in multiparty computation for providing consistency between shares. We make
use of this technique in our context to ensure decryption consistency.
The second scheme is fairly simple. We use a non-interactive zero-knowledge
proof to ensure consistency between the encrypted shares. This simplicity will
be obtained at the cost of eﬃciency, or very restricted instantiation options.
That is, the only known eﬃcient instantiation of non-interactive zero-knowledge
proofs is restricted to certain relations in bilinear groups (i.e. the Groth-Sahai
proofs [15]). The alternative is to employ non-interactive zero-knowledge proof
for general NP-languages in a non-black-box construction. While this is feasible,
it will not provide eﬃcient instantiations.
We additionally show that a black-box construction of (non-dynamic) TPKE
with strong decryption consistency from any PKENO is possible. This construc-
tion uses techniques from multiple-assignment secret sharing [16], which was
originally developed for constructing secret sharing schemes supporting gen-
eral access structures. Interestingly, these techniques are also useful for ensuring
decryption consistency. The basic idea of the construction is to allow any coali-
tion of k servers to decrypt the entire ciphertext. However, this approach only
allows a small number (logarithmic in the security parameter) of decryption
servers. The details of this construction will be given in the full version of this
paper. We remark that this black-box construction can be seen as conﬁrmation
of the conjecture by [13]. Although not formally stated, the conjecture more
speciﬁcally claims that for constructing threshold PKE from PKENO, it is suﬃ-
cient to simply follow the Dodis-Katz multiple encryption, replacing the ordinary
PKE scheme with a PKENO scheme (supporting labels).
www.ebook3000.com

Dynamic Threshold Public-Key Encryption with Decryption Consistency
81
Related Work. Decryption consistency was formalized by Shoup and Gen-
naro [24]. In the same paper, they also proposed two TPKE schemes that achieve
this notion. These schemes both rely on random oracles. Boneh, Boyen, and
Halevi [3] proposed a non-dynamic TPKE scheme with decryption consistency
which is shown secure in the standard model.
Dodis and Katz proposed the multiple encryption technique that preserves
chosen-ciphertext security of the underlying encryption scheme, and apply this
technique to construct a TPKE scheme [10]. They formalized several notions of
message privacy. These security notions are regarding secrecy of the plaintext,
rather than resilience of the decryption process against maliciously behaving
sender and receivers (decryption servers), and thus are independent notions from
decryption consistency. In the same paper the authors also discuss decryption
robustness which is related to decryption consistency. This notion deals with a
similar requirement to decryption consistency, but assumes that the ciphertext
is honestly generated. The notion then dictates that, if some of the decryption
shares are generated maliciously, it should be possible to detect these shares,
and successfully obtain the correct decryption result. Our decryption consistency
notion considers a diﬀerent scenario. Namely, even for a maliciously generated
ciphertext, the decryption result will be uniquely determined, regardless of which
decryption servers participate in the decryption procedure.
Delerabl´ee and Pointcheval [8] proposed the notion of dynamic TPKE and
a concrete instantiation. One of the advantages of their scheme, especially com-
pared with our proposed schemes, is constant-size ciphertext. However, their
scheme relies on both a q-type assumption and the random oracle model for
decryption consistency. In addition, the Delerabl´ee-Pointcheval scheme can be
easily extended to the identity-based setting, while our proposed scheme is only
in the public-key setting. Daza et al. [6] proposed another extension of TPKE
called broadcast threshold encryption. Although this notion is similar to dynamic
TPKE, in their scheme decryption consistency is not addressed.
Qin et al. [22], Libert and Yung [18,19], and Gan et al. [14] proposed TPKE
schemes allowing adaptive corruption. In contrast to these scheme, all other
known schemes and our proposed schemes do not allow this type of corruption.
Such schemes require the set of corrupted servers to be ﬁxed at the security
game, especially before the adversary obtains the public keys.
2
Deﬁnitions of Dynamic TPKE and PKENO
In the deﬁnitions and descriptions in this paper, we denote by [n] the set
{1, . . . , n} for any positive integer n. Deﬁnitions of several standard crypto-
graphic primitives and hardness assumptions, which are used in this paper, are
given in Appendix A.
2.1
Dynamic Threshold Public-Key Encryption
We now give a formal deﬁnition of dynamic TPKE. The deﬁnition basi-
cally follows the deﬁnition given by Delerabl´ee and Pointcheval [8] with the

82
Y. Sakai et al.
known-secret-keys extension. However, our syntax is modiﬁed to describe the
public-key setting, rather than the identity-based setting.
We deﬁne two diﬀerent variants of decryption consistency, namely weak and
strong decryption consistency. While the stronger notion follows the deﬁnition in
[3], the weaker notion is introduced to capture the type of decryption consistency
achieved by one of our proposed schemes. To be able to deﬁne this weaker notion,
our deﬁnition of a TPKE scheme allows the DVerify algorithm, which veriﬁes
validity of a decryption share, to have three possible outputs, ⊤valid, ⊤invalid,
and ⊥, rather than just binary values 1 and 0.
A dynamic TPKE scheme consists of the following probabilistic polynomial-
time algorithms:
DSetup(1λ). The setup algorithm DSetup takes as input the security parameter
1λ and outputs the public parameter pp.
DKg(pp). The key generation algorithm takes as input the public parameter pp,
and outputs a pair (pk, sk) of the public and secret keys for a new user. We
assume that the user public key pk is made publicly available.
DEnc(pp, pk 1, . . . , pk n, k, m). The encryption algorithm DEnc take as input the
public parameter pp, n public keys pk 1, . . ., pk n, the threshold k, and the
plaintext m to be encrypted and outputs a ciphertext C.
DDec(pp, pk, sk, C). The partial decryption algorithm DDec takes as input the
public parameter pp, the public and secret keys of some user, and a ciphertext
C and outputs the decryption share (pk, μ).
DVerify(pp, pk, C, μ). The veriﬁcation algorithm DVerify takes as input the pub-
lic parameter pp, the public key pk of some user, a ciphertext C, and its
decryption share μ by (the owner of) pk and outputs either ⊤valid, ⊤invalid,
or ⊥.
DCombine(pp, C, μ1, . . . , μk). The combining algorithm DCombine takes as input
the security parameter pp, a ciphertext C and k decryption shares μ1, . . .,
μk and outputs a plaintext m or ⊥.
We require dynamic TPKE schemes to satisfy the following correctness condi-
tions: for any integer n and k (n ≥k), any honestly generated pp ←DSetup(1λ),
and any n honestly generated users’ key pair (pk 1, sk 1) ←DKg(pp), . . .,
(pk n, sk n) ←DKg(pp), it is required that
– for
any
plaintext
m,
honestly
generated
ciphertext
C ←DEnc(pp, pk 1, . . . , pk n, k, m), and any size-k subset {ι1, . . . , ιk} ⊂[n],
if one honestly computes decryption shares as μi ←DDec(pp, pk ιi, sk ιi, C)
(1 ≤i ≤k), then we have that DCombine(pp, C, μ1, . . . , μk) = m, and
– for an arbitrary ciphertext C and any 1 ≤i ≤n, if one honestly com-
putes a decryption share μ ←DDec(pp, pk i, sk i, C), then we have that
DVerify(pp, pk, C, μ) is either ⊤valid or ⊤invalid.
We ﬁrstly describe the secrecy requirement by the following game between
a challenger and an adversary (in this game N and ˜N respectively denote the
numbers of uncorrupted and corrupted servers):
www.ebook3000.com

Dynamic Threshold Public-Key Encryption with Decryption Consistency
83
Setup. The challenger runs pp ←DSetup(1λ). The challenger generates N
public/secret keys (pk i, sk i) ←DKg(pp) for uncorrupted users and
˜N
keys ( ˜pk i, ˜sk i) ←DKg(pp) for corrupted users. The challenger sends
(pp, (pk i)1≤i≤N, ( ˜pk i, ˜sk i)i∈[1≤i≤˜
N]) to the adversary.
Query I. The adversary A is allowed to issue decryption queries of the form
(pk, C) in which pk should be one of pk 1, . . ., pk N. The challenger computes
the decryption share μ by running DDec(pp, pk i, sk i, C) with the correspond-
ing secret key sk i of pk = pk i.
Challenge. The adversary A submits two (equal-length) plaintexts m0 and
m1, a set of authorized users S
= {pk ∗
1, . . . , pk ∗
n} which is a subset
of {pk 1, . . . , pk N, ˜pk 1, . . . , ˜pk ˜
N}, and a threshold k. The set S should
include (at most) k −1 corrupted public keys. The challenger randomly
chooses a bit b ∈{0, 1}, computes the challenge ciphertext C∗by running
DEnc(pp, pk ∗
1, . . . , pk ∗
n, k, mb), and sends C∗to the adversary.
Query II. The adversary again issues decryption queries, and the challenger
responds as in the previous phase. In addition to the Query I phase, in
this phase the adversary is not allowed to submit a query (pk, C) such that
C = C∗.
Guess. Finally the adversary outputs a guess b′ ∈{0, 1}. The adversary’s
advantage is deﬁned by the diﬀerence between the probability that b = b′
and 1/2.
Deﬁnition 1. A dynamic TPKE scheme is said to be chosen-ciphertext secure
if for any probabilistic polynomial-time adversary A and any N and ˜N ∈N, the
advantage of the adversary is negligible in λ.
We then deﬁne the decryption consistency requirement by the following game.
This deﬁnition is of the “known secret keys” variant.
Setup. The challenger obtains pp by running DSetup(1λ) and obtains ˜N keys
( ˜pk 1, ˜sk 1), . . ., ( ˜pk ˜
N, ˜sk ˜
N) by running ( ˜pk i, ˜sk i) ←DKg(pp) for all 1 ≤i ≤
˜N. The challenger sends (pp, ( ˜pk i, ˜sk i)1≤i≤˜
N)) to the adversary A.
Forge. The adversary outputs (C, S, S′) in which C is a ciphertext S and S′
are respectively sets of k decryption shares. The adversary wins if one of the
following conditions holds:
1. both S and S′ consists of k decryption shares from k distinct servers,
S and S′ are not equal to each other as sets, all shares μ ∈S ∪S′
satisfy DVerify(pp, pk, C, μ) = ⊤valid where pk is the user public key of
the corresponding decryption servers of μ, and DCombine(pp, C, S) ̸=
DCombine(pp, C, S′), or
2. there exists μ, μ′ ∈S ∪S′ which are both attributed to the same decryp-
tion server, DVerify(pp, pk, C, μ) = ⊤valid, and DVerify(pp, pk, C, μ′) =
⊤invalid, in which pk is the user public key of the decryption server of μ
and μ′.
The advantage of the adversary is deﬁned by the probability that the adver-
sary wins.

84
Y. Sakai et al.
Deﬁnition 2. A dynamic TPKE scheme is said to have weak decryption con-
sistency if for any probabilistic polynomial-time adversary A and any ˜N ∈N the
advantage of the adversary is negligible in λ.
We further introduce a stronger deﬁnition of decryption consistency called
strong decryption consistency. It requires the DVerify algorithm to output either
⊤valid or ⊥but never output ⊤invalid. The strong decryption consistency is actu-
ally equivalent to the decryption consistency deﬁned by Boneh, Boyen, and
Halevi [3] except for the “known secret key” extension. The formal deﬁnition
is as follows.
Deﬁnition 3. A dynamic TPKE scheme is said to have strong decryption
consistency if in addition to the weak decryption consistency it satisﬁes the
following condition: for any (pp, ( ˜pk i, ˜sk i)1≤i≤˜
N)) generated as in the Setup
phase, any ciphertext C ∈{0, 1}∗, and any decryption shares μ ∈{0, 1}∗,
DVerify(pp, pk, C, μ) outputs either ⊤valid or ⊥.
2.2
Public-Key Encryption with Non-interactive Opening
We deﬁne syntax and security of public-key encryption with non-interactive
opening. We require the underlying PKENO scheme to support labels (or to be
tag-based) [17,20,21,23], whose formal deﬁnition is as follows.
A public-key encryption scheme with non-interactive opening consists of the
following ﬁve algorithms.
Kg(1λ). The key generation algorithm Kg(1λ) takes as input a security parame-
ter 1λ and outputs a pair (ek, dk) of the encryption key and the decryption
key.
Enc(ek, L, m). The encryption algorithm Enc(ek, L, m) takes as input the
encryption key ek, a label L, and a plaintext m. It outputs a ciphertext
c.
Dec(dk, L, c). The decryption algorithm Dec(dk, L, c) takes as input the decryp-
tion key dk, a label L, and a ciphertext c. It outputs a plaintext m or a
special symbol ⊥.
Prove(dk, L, c). The proof algorithm Prove(dk, L, c) takes as input the decryp-
tion key dk, a label L, and a ciphertext c. It outputs a proof π.
Verify(ek, L, c, m, π). The veriﬁcation algorithm Verify(ek, L, c, m, π) takes as
input the encryption key ek, a label L, a ciphertext c, a plaintext m, and a
proof π, and outputs a bit 1 or 0, indicating the proof is respectively valid
or invalid.
As the correctness condition, the labeled PKENO scheme is required to sat-
isfy the following conditions.
– For any (ek, dk) ←Kg(1λ), any plaintext m ∈{0, 1}∗and any label L ∈
{0, 1}∗, it holds that Dec(dk, L, Enc(pk, L, m)) = m.
– For any (ek, dk) ←Kg(1λ), any ciphertext c ∈{0, 1}∗, and any label L ∈
{0, 1}∗, it holds that Verify(ek, L, c, Dec(dk, L, c), Prove(dk, L, c)) = 1.
www.ebook3000.com

Dynamic Threshold Public-Key Encryption with Decryption Consistency
85
Notice that in the latter conditions the ciphertext c is not restricted to the
legitimate output of the encryption algorithm Enc(ek, L, m) with some L and
m, and hence Dec(dk, L, c) could potentially be ⊥.
We require the labeled PKENO scheme to be selective-label weak chosen-
ciphertext secure and strongly committing. Although the former requirement for
PKENO schemes has not been formally stated in the literature, it is a straight-
forward adoption of the similar requirement for ordinary (tag-based) public-key
encryption schemes formalized by Kiltz [17]. The latter requirement is originally
formalized by Galindo et al. [13]. More precisely our deﬁnition is a slightly weaker
variant than that of Galindo et al.[13], as our deﬁnition requires the target key
pair to be generated honestly. It is also worth noting that the requirement of
proof soundness, which is deﬁned by Damg˚ard et al., is implied by our deﬁnition.
The requirement of selective-label weak chosen-ciphertext security is deﬁned
by the following game between challenger and the adversary A.
Initialize. The adversary outputs a label L∗∈{0, 1}∗, which will be used to
compute the challenge ciphertext.
Setup. The challenger generates a pair (ek, dk) of encryption and decryption
keys by running the key generation algorithm (ek, dk) ←Kg(1λ). The chal-
lenger sends ek to the adversary.
Query I. The adversary issues decryption-and-proof queries (L, c) to the chal-
lenger, where L ̸= L∗. The challenger responds with a pair (m, π) where
m ←Dec(dk, L, c) and π ←Prove(dk, L, c). The adversary is not allowed to
issue a query (c, L∗) with any c.
Challenge. The adversary submits two messages m0 and m1 of same length.
The challenger picks a random bit b ∈{0, 1}, computes a challenge ciphertext
c∗←Enc(pk, L∗, mb), and sends c∗to the adversary.
Query II. The adversary again issues decryption-and-proof queries, which are
responded by the challenger as in the Query I phase. The same restriction
of forbidding queries with the label L∗is also applied in this phase.
Guess. Finally the adversary outputs a bit b′. The adversary’s advantage is
deﬁned by |Pr[b = b′] −1/2|.
Deﬁnition 4. A labeled PKENO scheme is said to be selective-label weakly
chosen-ciphertext secure if for any probabilistic polynomial-time adversary A,
the advantage of the adversary in the above game is negligible in λ.
The committing requirement is deﬁned by the following game.
Setup. The challenger generates (ek, dk) ←Kg(1λ) and sends (ek, dk) to the
adversary.
Forge. The adversary outputs a tuple (L, c, m, π, m′, π′), where m, m′ ∈
{0, 1}∗∪{⊥}. The adversary’s advantage is deﬁned by the proba-
bility that the conditions m
̸=
m′, Verify(pk, L, c, m, π)
=
1, and
Verify(pk, L, c, m′, π′) = 1.
Deﬁnition 5. A labeled PKENO scheme is said to be strongly committing if
for any probabilistic polynomial-time A, the advantage of the adversary in the
above game is negligible in λ.

86
Y. Sakai et al.
3
Generic Construction of Dynamic Threshold PKE
In this section we present the ﬁrst proposed construction which combines the
Dodis-Katz construction with techniques from veriﬁable secret sharing [1,2].
The diﬃculty is to ensure consistency among the shares. In our construction,
we adopt a technique from veriﬁable secret sharing [1,2] to resolve this problem.
In particular, the scheme will encrypt a plaintext by dividing the plaintext with
a secret sharing scheme and encrypting each share. Furthermore, the shares
includes redundancy for verifying consistency between the shares.
DSetup(1λ). Generate the commitment parameter ck as ck ←ComKg(1λ), set
pp = ck, and output pp.
DKg(pp). Generate the public and secret keys (ek, dk) of the PKENO scheme
by running (ek, dk) ←Kg(1λ). Set (pk, sk) = (ek, dk) and output (pk, sk).
DEnc(pp, pk 1, . . . , pk n, k, m). Let ck be pp and ek i be pk i for all i ∈[n], and
proceed as follows:
– Generate a key pair (vk sots, sk sots) ←SigK(1λ) for the one-time signature
scheme.
– Choose a random bivariate polynomial f(x, y) = k−1
i=0
k−1
j=0 ai,jxiyj of
degree k −1 with a0,0 = m and f(i, j) = f(j, i) for all i and j.
– Compute commitments and their decommitments of f(i, j) for 1 ≤i ≤
j ≤n as (ci,j, ri,j) ←Commit(ck, f(i, j)).
– Let cj,i = ci,j and rj,i = ri,j for 1 ≤i < j ≤n.
– Compute
PKENO
ciphertext
as
Ci = Enc(pk i, vk sots, ⟨f(i, 1), . . . , f(i, n), ri,1, . . . , ri,n⟩) for i = 1, . . . , n.
– σsots ←SigS(sk sots, ⟨k, (pk i)1≤i≤n, (ci,j)1≤i≤j≤n, (Ci)1≤i≤n⟩).
– Output C = (vk sots, k, (pk i)1≤i≤n, (ci,j)1≤i≤j≤n, (Ci)1≤i≤n, σsots).
DDec(pp, pk, sk, C). Parse C as (vk sots, k, (pk i)1≤i≤n, (ci,j)1≤i≤j≤n, (Ci)1≤i≤n,
σsots) and ﬁnd i such that pk i = pk. If no such i is found, output (pk, ⊥).
Otherwise, proceed as follows.
– Output (pk, ⊥) if SigV(vk sots, ⟨k, (pk i)1≤i≤n, (ci,j)1≤i≤j≤n, (Ci)1≤i≤n⟩,
σsots) = 0.
– Decrypt Ci as ˆm ←Dec(sk, vk sots, Ci).
– Compute a proof π as π ←Prove(sk, vk sots, Ci).
– Output μi = (pk, ( ˆm, π)).
DVerify(pp, vk, C, μ). Parse C as (vk sots, k, (pk i)1≤i≤n, (ci,j)1≤i≤j≤n, (Ci)1≤i≤n,
σsots)
and
parse
μ
as
(pk, ˆμ).
Find
i
satisfying
pk
=
pk i.
If
no
such
i
exists,
output
⊥
immediately.
If
such
i
exists,
run
SigV(vk sots, ⟨k, (pk i)1≤i≤n, (ci,j)1≤i≤j≤n, (Ci)1≤i≤n⟩, σsots) to verify the one-
time signature σsots and proceeds as follows.
– If the one-time signature is invalid and ˆμ = ⊥, output ⊤valid.
– If
the
one-time
signature
is
valid,
ˆμ
is
parsed
as
( ˆm, π),
and
Verify(pk i, Ci, ˆm, π) = 1, further verify the following three conditions:
• ˆm is parsed as ⟨f1, . . . , fn, r1, . . . , rn⟩,
• ComVerify(ck, ci,j, fj, rj) = 1 (or ComVerify(ck, cj,i, fj, rj,i) = 1 for
j < i) for all j ∈[n], and
www.ebook3000.com

Dynamic Threshold Public-Key Encryption with Decryption Consistency
87
• (f1, . . . , fn) deﬁnes a degree-(k −1) polynomial.
If all of the three conditions holds, output ⊤valid. Otherwise output
⊤invalid.
– If neither two conditions hold, output ⊥.
DCombine(pp, vk, C, μ1, . . . , μk). Parse C as (vk sots, k, (pk i)1≤i≤n, (ci,j)1≤i≤j≤n,
(Ci)1≤i≤n, σsots) and μi as ( ˆpk i, ˆμi) for all 1 ≤i ≤k.
– If there is at least one μi that is ⊥, output ⊥.
– Otherwise if all ˆμi are parsed as ((fi,1, . . . , fi,1, ri,1, . . . , ri,n), πi), proceed
as follows:
• ﬁnd ti satisfying pk ti = ˆpk i for all i,
• interpolate (t1, fti,t1), . . ., (tk, fti,tk) to obtain a polynomial gti(x)
for all i,1
• interpolate (t1, gt1(0)), . . ., (tk, gtk(0)) to obtain a polynomial g(y),
and
• output g(0).
Security. Security of the above construction is as follows. The proofs appears
in the full version of this paper.
Theorem 1. The construction is chosen-ciphertext secure if the PKENO
scheme is selective-label weakly chosen-ciphertext secure, the commitment
scheme is (computationally) hiding, and the one-time signature scheme is
strongly unforgeable.
Theorem 2. The construction has the weak decryption consistency if the
PKENO scheme is strongly committing and that the commitment scheme is
(computationally) binding.
3.1
Instantiating the Generic Construction.
To instantiate the generic construction, we need a “labeled” PKENO scheme.
Fortunately, this is relatively easy to obtain by extending existing PKENO
schemes. In the full version of the paper, we provide the description and security
proofs of two labeled PKENO schemes based on the decisional linear assumption
and the decisional bilinear Diﬃe-Hellman assumption, respectively.
If we instantiate the generic construction with the PKENO scheme from
the decisional linear assumption, we obtain the ﬁrst dynamic TPKE scheme
from a static assumption which achieves weak decryption consistency without
relying random oracles. However, note that our generic construction of dynamic
1 One might think that the DVerify algorithm, instead of the DCombine algorithm,
could perform this interpolation. We still choose this, simply for following the syntax
of (dynamic) threshold PKE in an exact sense. Namely, the DVerify algorithm is
required to output a ternary value ⊤valid, ⊤invalid, or ⊥, but is not allowed to output
further additional information passed to the DCombine algorithm. If the DVerify
algorithm is allowed to output some additional information, the DVerify algorithm
will perform this interpolation, and will pass the result to the DCombine algorithm.

88
Y. Sakai et al.
TPKE is not as eﬃcient as the Delerabl´ee-Pointcheval scheme or the Daza et al.
scheme, as our construction has a ciphertext size proportional to the square of the
number of the authorized servers, while the previous schemes have constant size
ciphertexts. Furthermore, our scheme only achieves weak decryption consistency
rather than the strong notion.
4
Dynamic Threshold PKE from the Decisional Linear
Assumption
In this section, we propose a dynamic TPKE scheme which, in contrast to the
generic scheme above, provides strong decryption consistency. The idea of the
construction is replacing the ordinary PKE scheme in the Dodis-Katz scheme
with a PKENO scheme, and using non-interactive zero-knowledge proofs (in
particular Groth-Sahai proofs) to provide decryption consistency.
DSetup(1λ). Run the parameter generation algorithm2 G(1λ) for the bilin-
ear groups to set up the bilinear group parameter (p, G, GT , e, g). Choose
a common reference string (f 1, f 2, f 3) ∈(G3)3 for the binding setting,
where f 1 = (f1, 1, g), f 2 = (1, f2, g), and f 3 = f 1ζ1f 2ζ2 for random f1,
f2 ∈G \ { 1 } and random ζ1, ζ2 ∈Zp. Set pp = (p, G, GT , e, g, f 1, f 2, f 3),
and output pp.
DKg(pp). Generate public and secret keys of the PKENO scheme. by choosing
random x, y ←Zp and random U, V ←G and setting u = gx and v = gy.
Set pk = (u, v, U, V ) and sk = (x, y) and output (pk, sk).
DEnc(pp, pk 1, . . . , pk n, k, m). Parse pk i as (ui, vi, Ui, Vi) for all i ∈[n]. Gener-
ate veriﬁcation and signing keys (vk, sk) for a one-time signature scheme
by running SigK(1λ). Choose random integers r1, . . ., rn, s1, . . ., sn,
a1, . . ., ak−1
←Zp and compute ci,1
←uiri, ci,2
←visi, ci,3
←
(gvkUi)ri, ci,4 ←(gvkVi)si, and ci,5 ←gri+simga1i+a2i2+···+ak−1ik−1 for
all i
∈
[n]. Then compute a Groth-Sahai proof πzk which demon-
strates that the equations: ci,1
=
uiri, ci,2
=
visi, and ci,5
=
grigsi(gik−1)ak−1 · · · (gi2)a2(gi)a1m for all i ∈[n] with witness m ∈G and
r1, . . ., rn, s1, . . ., sn, a1, . . ., ak−1 ∈Zp. Finally compute a one-time signa-
ture σ by running SigS(sk, ⟨(pk i)i∈[n], k, (ci,1, . . . , ci,5)i∈[n], πzk⟩) and output
C = (vk, (pk i)i∈[n], k, (ci,1, . . . , ci,5)i∈[n], πzk, σ).
DDec(pp, pk, sk, C). Parse
C
as
(vk, (pk i)i∈[n], k, (ci,1, . . . , ci,5)i∈[n], πzk, σ).
Find i ∈[n] such that pk = pk i and output (pk, ⊥) if no such i exists.
Otherwise proceed as follows. Firstly verify that the one-time signature σ
is valid, the Groth-Sahai proof πzk is valid, and for all i ∈[n] the equa-
tions e(ui, ci,3) = e(ci,1, gvkUi) and e(vi, ci,4) = e(ci,2, gvkVi) hold. If any
of the above does not holds, output (pk, ⊥) immediately. If all of them
holds, compute π(u) = c1/x
i,1 , π(v) = c1/y
i,2 , and ˆm = ci,5/π(u)π(v), and outputs
μ = (pk, ( ˆm, π(u), π(v))).
2 Details are given in Appendix A.2.
www.ebook3000.com

Dynamic Threshold Public-Key Encryption with Decryption Consistency
89
DVerify(pp, pk, C, μ). Parse
C
as
(vk, (pk i)i∈[n], k, (ci,1, . . . , ci,5)i∈[n], πzk, σ).
Then verify the following conditions: no i ∈[n] does not satisfy pk = pk i, the
one-time signature σ is invalid, the Groth-Sahai proof πzk is invalid, or for
some i ∈[n] one of e(ui, ci,3) = e(ci,1, gvkUi) and e(vi, ci,4) = e(ci,2, gvkVi)
does not hold. If at least one of the above does not hold and μ is parsed
as (pk, ⊥), output ⊤valid. Otherwise, if all of the above do hold, μ is
parsed as (pk, ( ˆm, π(u), π(v))), and the three equations e(u, π(u)) = e(ci,1, g),
e(v, π(v)) = e(ci,2, g), and ci,5 = ˆmπ(u)π(v) hold, output ⊤valid. In any other
cases, output ⊥.
DCombine(pp, C, μ1, . . . , μk). Parse C
as (vk, (pk i)i∈[n], k, (ci,1, . . . , ci,5)i∈[n],
πzk, σ). If there is at least one μi that is parsed as (pk, ⊥), output ⊥. Oth-
erwise, parse μi as ( ˆpk i, ( ˆmi, ˆπ(u)
i
, ˆπ(v)
i
)), ﬁnd ti satisfying pk ti = ˆpk i for all
i ∈[k], compute m = ˆm1λ1 · · · ˆmkλk in which λi = 
j∈[k]\{ i } −tj/(ti −tj),
and output m.
Security. This scheme is proven to be secure under the decisional linear assump-
tion. Detailed proofs are given in the full version of this paper.
Theorem 3. The scheme is chosen-ciphertext secure if the decisional linear
assumption holds with respect to G.
Theorem 4. The scheme satisﬁes strong decryption consistency.
5
Conclusion
We presented two constructions of TPKE with decryption consistency. The ﬁrst
scheme is a generic construction from PKENO with weak decryption consistency.
The second scheme is a direct construction providing a shorter ciphertext length
than the ﬁrst scheme as well as strong decryption consistency. These two schemes
are the ﬁrst dynamic TPKE with (weak or strong) decryption consistency which
do not rely on q-type assumptions or random oracles. In the full version of the
paper, we furthermore show that a generic construction of TPKE with strong
decryption consistency is possible, albeit at the cost of the scheme being a non-
dynamic scheme and allowing only a smaller (logarithmic) number of decryption
servers.
References
1. Backes, M., Kate, A., Patra, A.: Computational veriﬁable secret sharing revisited.
In: Lee, D.H., Wang, X. (eds.) ASIACRYPT 2011. LNCS, vol. 7073, pp. 590–609.
Springer, Heidelberg (2011)
2. Ben-Or, M., Goldwasser, S., Wigderson, A.: Completeness theorems for non-
cryptographic fault-tolerant distributed computation (extended abstract). In: Pro-
ceedings of the 20th Annual ACM Symposium on Theory of Computing, pp. 1–10.
ACM (1988)

90
Y. Sakai et al.
3. Boneh, D., Boyen, X., Halevi, S.: Chosen ciphertext secure public key threshold
encryption without random oracles. In: Pointcheval, D. (ed.) CT-RSA 2006. LNCS,
vol. 3860, pp. 226–243. Springer, Heidelberg (2006)
4. Canetti, R., Goldwasser, S.: An eﬃcient threshold public key cryptosystem secure
against adaptive chosen ciphertext attack. In: Stern, J. (ed.) EUROCRYPT 1999.
LNCS, vol. 1592, pp. 90–106. Springer, Heidelberg (1999)
5. Damg˚ard, I., Hofheinz, D., Kiltz, E., Thorbek, R.: Public-key encryption with
non-interactive opening. In: Malkin, T. (ed.) CT-RSA 2008. LNCS, vol. 4964, pp.
239–255. Springer, Heidelberg (2008)
6. Daza, V., Herranz, J., Morillo, P., R`afols, C.: CCA2-secure threshold broadcast
encryption with shorter ciphertexts. In: Susilo, W., Liu, J.K., Mu, Y. (eds.) ProvSec
2007. LNCS, vol. 4784, pp. 35–50. Springer, Heidelberg (2007)
7. De Santis, A., Desmedt, Y., Frankel, Y., Yung, M.: How to share a function securely.
In: Proceedings of the Twenty-sixth Annual ACM Symposium on Theory of Com-
puting, pp. 522–533. ACM (1994)
8. Delerabl´ee, C., Pointcheval, D.: Dynamic threshold public-key encryption. In: Wag-
ner, D. (ed.) CRYPTO 2008. LNCS, vol. 5157, pp. 317–334. Springer, Heidelberg
(2008)
9. Desmedt,
Y.:
Threshold
cryptosystems.
In:
Seberry,
J.,
Zheng,
Y.
(eds.)
AUSCRYPT 1992. LNCS, vol. 718, pp. 1–14. Springer, Heidelberg (1993)
10. Dodis, Y., Katz, J.: Chosen-ciphertext security of multiple encryption. In: Kilian,
J. (ed.) TCC 2005. LNCS, vol. 3378, pp. 188–209. Springer, Heidelberg (2005)
11. Emura, K., Hanaoka, G., Sakai, Y., Schuldt, J.C.N.: Group signature implies
public-key encryption with non-interactive opening. International Journal of Infor-
mation Security 13(1), 51–62 (2014)
12. Galindo, David: Breaking and repairing damg˚ard et al. public key encryption
scheme with non-interactive opening. In: Fischlin, Marc (ed.) CT-RSA 2009. LNCS,
vol. 5473, pp. 389–398. Springer, Heidelberg (2009)
13. Galindo, D., Libert, B., Fischlin, M., Fuchsbauer, G., Lehmann, A., Man-
ulis, M., Schr¨oder, D.: Public-key encryption with non-interactive opening: new
constructions and stronger deﬁnitions. In: Bernstein, D.J., Lange, T. (eds.)
AFRICACRYPT 2010. LNCS, vol. 6055, pp. 333–350. Springer, Heidelberg (2010)
14. Gan, Y., Wang, L., Wang, L., Pan, P., Yang, Y.: Eﬃcient threshold public key
encryption with full security based on dual pairing vector spaces. International
Journal of Communication Systems 27(12), 4059–4077 (2014)
15. Groth, J., Sahai, A.: Eﬃcient non-interactive proof systems for bilinear groups. In:
Smart, N.P. (ed.) EUROCRYPT 2008. LNCS, vol. 4965, pp. 415–432. Springer,
Heidelberg (2008)
16. Ito, M., Saito, A., Nishizeki, T.: Multiple assignment scheme for sharing secret.
Journal of Cryptology 6(1), 15–20 (1993)
17. Kiltz, E.: Chosen-ciphertext security from tag-based encryption. In: Halevi, S.,
Rabin, T. (eds.) TCC 2006. LNCS, vol. 3876, pp. 581–600. Springer, Heidelberg
(2006)
18. Libert, B., Yung, M.: Adaptively secure non-interactive threshold cryptosystems.
In: Aceto, L., Henzinger, M., Sgall, J. (eds.) ICALP 2011, Part II. LNCS, vol. 6756,
pp. 588–600. Springer, Heidelberg (2011)
19. Libert, B., Yung, M.: Non-interactive CCA-secure threshold cryptosystems with
adaptive security: new framework and constructions. In: Cramer, R. (ed.) TCC
2012. LNCS, vol. 7194, pp. 75–93. Springer, Heidelberg (2012)
www.ebook3000.com

Dynamic Threshold Public-Key Encryption with Decryption Consistency
91
20. Lim, C.H., Lee, P.J.: Another method for attaining security against adaptively
chosen ciphertext attacks. In: Stinson, D.R. (ed.) CRYPTO 1993. LNCS, vol. 773,
pp. 420–434. Springer, Heidelberg (1994)
21. MacKenzie, P., Reiter, M.K., Yang, K.: Alternatives to non-malleability: deﬁni-
tions, constructions, and applications. In: Naor, M. (ed.) TCC 2004. LNCS, vol.
2951, pp. 171–190. Springer, Heidelberg (2004)
22. Qin, B., Wu, Q., Zhang, L., Domingo-Ferrer, J.: Threshold public-key encryption
with adaptive security and short ciphertexts. In: Soriano, M., Qing, S., L´opez, J.
(eds.) ICICS 2010. LNCS, vol. 6476, pp. 62–76. Springer, Heidelberg (2010)
23. Shoup, V., Gennaro, R.: Securing threshold cryptosystems against chosen cipher-
text attack. In: Nyberg, K. (ed.) EUROCRYPT 1998. LNCS, vol. 1403, pp. 1–16.
Springer, Heidelberg (1998)
24. Shoup, V., Gennaro, R.: Securing threshold cryptosystems against chosen cipher-
text attack. Journal of Cryptology 15(2), 75–96 (2002)
A
Omitted Deﬁnitions and Notations
A.1
Standard Primitives
Commitment. A commitment scheme consists of the three algorithms ComKg,
Commit, and ComVerify. The algorithm ComKg takes the security parameter 1λ
and outputs a parameter ck. The commitment algorithm takes as input the
parameter ck and a string m, and outputs a pair (c, r), where c is the com-
mitment string for m and r is the corresponding decommitment string. The
decommitment algorithm ComVerify takes as input the security parameter 1λ,
a commitment string c, a string m, and a decommitment string r and out-
puts 0 or 1, indicating the decommitment is valid or invalid. It is required that
for any ck output by ComKg(1λ), any m ∈{0, 1}∗, and any (c, r) output by
Commit(ck, m), it holds that ComVerify(ck, c, m, r) = 1. As the hiding prop-
erty it is required that for any probabilistic polynomial-time adversary A the
probability |Pr[b ←{0, 1}; ck
←ComKg(1λ); b′ ←AOb(ck) : b = b′] −
1/2| is negligible in λ, where the oracle Ob, when receives a pair (m0, m1) as
input, runs Commit(ck, mb) to obtain (c, r) and returns c. As the binding prop-
erty it is required that for any probabilistic polynomial-time adversary A the
probability Pr[ck
←
ComKg(1λ); (c, m, r, m′, r′)
←
A(ck)
:
m
̸=
m′ ∧
ComVerify(ck, c, m, r) = 1 ∧ComVerify(ck, c, m′, r′) = 1] is negligible in λ.
One-Time Signature. A one-time signature scheme consists of the three algo-
rithm SigK, SigS, and SigV. The algorithm SigK takes the security parameter 1λ
and generates a key pair (vk sots, sk sots). The algorithm SigS takes the singing key
sk sots and a message m and generates a one-time signature σsots. The veriﬁcation
algorithm SigV takes the veriﬁcation key vk sots, a message m, and a signature
σsots and outputs a bit 1 or 0. We require as correctness the following condition:
for all λ and all m ∈{0, 1}∗, all (vk sots, sk sots) generated by running SigK(1λ),
it holds that SigV(vk sots, m, SigS(sk sots, m)) = 1. We also require the one-time

92
Y. Sakai et al.
signature scheme to be strongly unforgeable. This property requires that for any
probabilistic polynomial-time adversary A, when given a veriﬁcation key vk sots
generated by running the key generation algorithm SigK(1λ) and an signature σ
on arbitrary message m chosen by the adversary after seeing vk sots, the adver-
sary outputs a forgery (m∗, σ∗) ̸= (m, σ) which satisﬁes SigV(vk sots, m∗, σ∗) = 1
only with negligible probability.
A.2
Bilinear Groups and Hardness Assumptions
Here we introduce the bilinear groups and hardness assumptions on which our
speciﬁc instantiations of PKENO are based.
The algorithm G(1λ), which generates a parameter of bilinear group, takes
the security parameter 1λ and outputs (p, G, GT , e, g) where p is a prime, G and
GT are order-p groups, e: G × G →GT is a bilinear map, and g is a generator
of the group G. We needs the following two hardness assumptions.
Deﬁnition 6. We say that the decision bilinear Diﬃe-Hellman (DBDH)
assumption with respect to G
holds if for any probabilistic polynomial-
time algorithm A, it holds that Pr[(p, G, GT , e, g)
←
G(1λ);
α, β, γ
←
Zp
:
A(p, G, GT , e, g, gα, gβ, gγ, e(g, g)αβγ)
=
1] −Pr[(p, G, GT , e, g)
←
G(1λ); α, β, γ, δ ←Zp : A(p, G, GT , e, g, gα, gβ, gγ, e(g, g)δ) = 1] is negligible
in λ.
Deﬁnition 7. We say that the decisional linear assumption (DLIN) with
respect to G holds if for any probabilistic polynomial-time algorithm A,
it
holds
that
Pr[(p, G, GT , e, g)
←
G(1λ);
g1, g2, h
←
G;
α, β
←
Zp
:
A(p, G, GT , e, g1, g2, h, gα
1 , gβ
2 , hα+β)
=
1] −Pr[(p, G, GT , e, g)
←
G(1λ); g1, g2, h ←G; α, β, δ ←Zp : A(p, G, GT , e, g1, g2, h, gα
1 , gβ
2 , hδ) = 1] is
negligible in λ.
A.3
The Groth-Sahai Proof System
Groth and Sahai presented an eﬃcient zero-knowledge proof system for bilinear
groups, which can be based on the decisional linear assumption. The proof system
has two types of the common reference string, the soundness string and the
witness-indistinguishability string. For both types the string consists of three
vectors f 1, f 2, and f 3 of G3, in which f 1 = (f1, 1, g), f 2 = (1, f2, g) with
random f1, f2 ∈G \ { 1 } for both types. For the soundness string, the last
vector f 3 is set to f 3 = f 1ζ1f 2ζ2, whereas for the witness-indistinguishability
string, it is set to f 3 = f 1ζ1f 2ζ2(1, 1, g)−1. On the soundness string, the Groth-
Sahai proof system provides perfect soundness of the proof system, while on the
witness-indistinguishability string the proof system can provide a zero-knowledge
simulation for certain types of a statement (that include the statement that we
used in this paper).
www.ebook3000.com

Sponge Based CCA2 Secure Asymmetric
Encryption for Arbitrary Length Message
Tarun Kumar Bansal(B), Donghoon Chang,
and Somitra Kumar Sanadhya
Indraprastha Institute of Information Technology, Delhi (IIIT-D),
New Delhi, India
{tarunb,donghoon,somitra}@iiitd.ac.in
Abstract. OAEP and other similar schemes proven secure in Random-
Oracle Model require one or more hash functions with output size larger
than those of standard hash functions. In this paper, we show that by
utilizing popular Sponge constructions in OAEP framework, we can elim-
inate the need of such hash functions. We provide a new scheme in OAEP
framework based on Sponge construction and call our scheme Sponge
based asymmetric encryption padding (SpAEP). SpAEP is based on 2
functions: Sponge and SpongeWrap, and requires only standard output
sizes proposed and standardized for Sponge functions. Our scheme is
CCA2 secure for any trapdoor one-way permutation in the ideal permu-
tation model for arbitrary length messages. Our scheme utilizes the versa-
tile Sponge function to enhance the capability and eﬃciency of the OAEP
framework. SpAEP with any trapdoor one-way permutation can also be
used as a key encapsulation mechanism and a tag-based key encapsula-
tion mechanism for hybrid encryption. Our scheme SpAEP utilizes the
permutation model eﬃciently in the setting of public key encryption in
a novel manner.
Keywords: OAEP · Sponge function · Public key encryption · Hybrid
encryption · CCA2 security
1
Introduction
The Optimal Asymmetric Encryption Padding (OAEP), proposed by Bellare
and Rogaway at Eurocrypt ‘94 [11], is a technique for converting the RSA trap-
door permutation into a chosen ciphertext secure system in the random oracle
model (ROM). In Crypto ’01, Shoup described a modiﬁcation to OAEP, called
OAEP+, that provably converts any trapdoor one way permutation (f) into
a chosen ciphertext secure system in the random oracle model. In 2003, Phan
and Pointcheval [33,34] introduced OAEP-3R which is RCCA secure (“relaxed
CCA” [34] equivalent to “replayable CCA” [19]- a slightly weaker notion than
general CCA2) with any trapdoor one way permutation (f) in ROM. Let “cipher-
text overhead” [4] stand for the diﬀerence between the length of ciphertext and
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 93–106, 2015.
DOI: 10.1007/978-3-319-19962-7 6

94
T.K. Bansal et al.
plaintext. OAEP-3R was shown to have only t-bit ciphertext overhead, whereas
OAEP and OAEP+ have 3t-bit ciphertext overhead, where t stands for security
requirement in bits1. In 2008, Abe, Kiltz and Okamoto [4] showed that security
reduction of OAEP-3R forces ciphertext overhead to be 2t. A new scheme called
OAEP-4X was introduced in [4] which provides CCA2 security for any trapdoor
one way permutation in ROM. OAEP-4X has only t-bit ciphertext overhead
which was shown to be optimal (lowest achievable bound). In OAEP-4X, reduc-
tion of t-bit ciphertext overhead with respect to OAEP-3R has only limited
practical application such as in a highly bandwidth constrained network. There-
fore, for general applications ciphertext overhead reduction by t-bits is a less
interesting case.
Number of hash functions used in OAEP is 2 and these are used in a 2 round
structure. OAEP+ is also 2 round structure but uses 3 hash functions (2 hash
function can run in parallel while encryption). OAEP-3R is 3 round structure
that uses 3 hash functions and OAEP-4X is 4 round structure that uses 4 hash
functions. Each of these schemes (OAEP, OAEP+, OAEP-3R and OAEP-4X),
proven secure in ROM, requires one or more hash functions with arbitrary size
output. For example, for RSA-2048 (or RSA-3072) trapdoor one-way permuta-
tion, minimum number of hash function with arbitrary size output required in
OAEP, OAEP+, OAEP-3R and OAEP-4X are 1, 1, 2 and 2 respectively.
Currently, no cryptographic standard speciﬁes an instantiation for hash func-
tion of arbitrary size. However, some instantiations are implicit in PKCS #1
v2.1 [27], because RSA-OAEP [11] is standardized. For example, RSA-OAEP
requires two random hash functions G and H with small input size (less than
the RSA modulus) and arbitrary size output. Both G and H are both instanti-
ated in PKCS by the MGF1 PRNG [27]. MGF1 uses a hash function in counter
mode: MGF1(x) = h(x⟨count0⟩)||h(x⟨count1⟩)||h(x⟨count2⟩)|| . . ., where h is
either SHA-1 or a SHA-2. Because MGF1 is not a regular standardized hash
function, we use a term “non-standard hash function” for such functions, which
instantiate a hash function of arbitrary output size by utilizing standard ﬁxed
length hash functions (e.g., SHA-1, SHA-2) to generate arbitrary hash output.
Similarly, in other OAEP-type schemes, instantiation of such hash functions is
done by using similar “non-standard hash function”.
OAEP-type schemes (OAEP, OAEP+,OAEP-3R) discussed above, work only
for restricted message length (less than input size of trapdoor one-way permuta-
tion) except OAEP-4X, which works for long messages (more than input size of
trapdoor one-way permutation) as well. To encrypt lengthy messages, OAEP-4X
uses one extra hash function and a passively secure symmetric encryption scheme
along with 4 hash functions. In OAEP-4X, the ability of handling long messages
is the result of utilizing well known Tag-KEM/DEM framework [3,18]. Tag-
KEM/DEM is considered a hybrid encryption scheme [3,7,21,22,24–26,31]. In
hybrid paradigm, an asymmetric key encapsulation mechanism (KEM) combines
with a symmetric data encapsulation mechanism (DEM). Traditionally, KEM is
1 A security requirement of t-bit implies that at-least 2t queries are required to break
the scheme with probability close to 1.
www.ebook3000.com

Sponge Based CCA2 Secure Asymmetric Encryption
95
a probabilistic algorithm that produces a random symmetric key and an asym-
metric encryption of that key as the key encapsulation. DEM is a deterministic
algorithm that takes a symmetric key, generated by KEM, and encrypts the
message under that key. In Tag-KEM/DEM framework, KEM takes a feedback,
referred to as the ‘tag’, from DEM part and then generates key encapsulation.
Final ciphertext results from concatenation of key encapsulation and encryption
of message. This traditional hybrid paradigm suﬀers from high ciphertext over-
head (diﬀerence between plaintext and ciphertext length) equivalent to the size
of asymmetric encryption of key.
In 2007, Bjørstad et.al. [18] introduced KEMs (RKEM and Tag-RKEM)
with partial message input/recovery. These KEMs help in signiﬁcant reduc-
tion of ciphertext overhead in hybrid constructions. [18] also showed that the
Tag-RKEM is more space eﬃcient than the RKEM in terms of the ciphertext
overhead. For construction of RKEMs, [18] focuses over those asymmetric
encryption schemes which can recover the random variable used in encryption,
during the decryption, like in OAEP-type schemes. Therefore, [18] provided the
use of RSA-OAEP in RKEMs as an example. OAEP-4X has also utilized the
same idea proposed in [18] along with some improvement in Tag-KEM part.
This signiﬁes that the OAEP-type schemes are good candidates for constructing
RKEMs and successive improvements which took place in OAEP-type schemes
helped in the instantiation of the RKEMs also.
Motivation: Almost all previous public key cryptography literature dealing
with OAEP-based encryption, requires a perfect random function (a Random
oracle) over an arbitrary domain, whereas in practice one is given a random
function or permutation over a relatively small domain: practical block-cipher,
hash functions and permutations have smaller block size and ﬁxed output length.
Therefore, for generating lengthy hash output, RSA-Full Domain Hash [10,12,20]
or the Mask Generation Function (MGF1) [27] in RSA-OAEP are currently
implemented with a complex construction of ﬁxed length hashes and counters.
For m blocks input and n blocks hash output, a ﬁxed length hash function
has to run approximately m × n times. All of above mentioned schemes (OAEP,
OAEP+, OAEP-3R, OAEP-4X) proven secure in ROM require one or more hash
functions with output size larger than standard sizes (e.g., SHA-1, SHA-512). [28]
showed that the hash function instantiation proposed in the literature for such
cases are weaker than a random oracle, where hash functions are assumed to
behave like random oracle in the security analysis. The “non-standard hash
function” (like MGF1) are not well analyzed in literature, have complex con-
struction of ﬁxed length hash functions with counter and are also proven weaker
than random oracle. This raises a question on the possibility of modifying the
OAEP framework which does not require any “non-standard hash function” and
where all the computations are performed in standardized input-output settings.
Development of schemes from OAEP to OAEP-4X shows diﬀerences in the
number of rounds, depending upon calls to the hash functions used. OAEP
and OAEP+ is considered as 2 round structure, OAEP-3R as 3 round and

96
T.K. Bansal et al.
OAEP-4X as 4 round. This naturally poses a question on the possibility of fur-
ther development of the OAEP-type scheme and reduce the number of rounds.
We have seen OAEP-type construction are good candidate in hybrid encryp-
tion for constructing KEMs like in [18] and improvements in OAEP-type con-
struction helps the RKEMs and hybrid encryption also.
Presently, major existing and proposed crypto-systems are based on standard
assumptions or proven secure in random oracle model for public key cryptog-
raphy. The crypto-systems based on permutations, proven secure in ideal per-
mutation model, and using them eﬃciently are yet to be explored to develop
new outlooks and techniques that can cross-pollinate and advance cryptography
as a whole. An open problem mentioned in [3] about having a hybrid construc-
tion from diﬀerent primitives like permutation, also helps us to pursue in this
direction.
Interestingly, popular Sponge constructions [15], based on iterative per-
mutation, are found to be a suitable solution of all the questions mentioned
above. Sponge constructions work in standardized input-output settings [14–17]
and are useful for encryption, Authentication Encryption (AE), variable length
input/output and for MAC generations [5]. In a Sponge function, for m blocks
input and n blocks hash output, roughly m+n calls of internal primitive permu-
tation are required. Other than that, number of permutation calls in a Sponge
function [15], used as hash function, and SpongeWrap [16], a modiﬁcation of
Sponge function used as AE, is equal in general. Therefore, versatility of Sponge
function encourages the designers to come up with more useful and eﬃcient
design. The glimpse of popularity of Sponge functions can be seen clearly in
CAESAR [1] and PHC [2] competition. Therefore, it is interesting to consider a
permutation based or more concretely a Sponge construction based OAEP-type
scheme having a security proof in ideal permutation model which can also be
utilized in hybrid encryption.
Our Contribution: In this work, we introduce a Sponge based Asymmetric
Encryption Padding scheme (SpAEP), a novel way to use the SpongeWrap [16]
and the Sponge function [15] to encrypt arbitrary length messages in Asymmet-
ric key cryptography. Each function (SpongeWrap and Sponge) iterates a pub-
lic invertible permutation as a primitive function. Permutation calls in Sponge
function and in a SpongeWrap are generally the same for equal number of input-
output data blocks.
– We provide new direction for constructing asymmetric key cryptographic sche-
mes in ideal permutation model by utilizing permutations, having smaller or
practical domain, in SpAEP. Almost all previous public key cryptography
literature dealing with OAEP-based encryption requires hash functions (or a
random function) over an arbitrary domain.
– SpAEP uses the Sponge function and the SpongeWrap in standard input-
output settings, proposed for “Sponge functions” [14–17], as per security
requirement. Therefore, SpAEP remove the requirement of having “non-
standard hash function”, which is required in OAEP, OAEP+, OAEP-3R
www.ebook3000.com

Sponge Based CCA2 Secure Asymmetric Encryption
97
and OAEP-4X for generating hash output of diﬀerent sizes than standard size
(“non-standard output size”).
– In SpAEP, both functions (Sponge function and SpongeWrap) are used in
parallel during encryption to speed-up the process. Therefore, we consider
SpAEP as 1 round structure in comparison to other OAEP-type schemes. By
functions in parallel we refer to potential parallelism properties of Sponge
functions, where output of permutation calls of Sponge function feed into
permutation calls of SpongeWrap as input in pipe-lined fashion. Let Sponge
function and SpongeWrap have n, n > 0, permutation calls respectively, then
output of nth permutation of SpongeWrap is feed into (n + 1)th permutation
of SpongeWrap and partial output in nth permutation of Sponge function.
This means (n + 1)th permutation of SpongeWrap and nth permutation of
Sponge function can be processed in parallel. However, the functions are not
parallelized during decryption.
Features of SpAEP and Comparison with other OAEP-type schemes
– Although the permutation used in Sponge is invertible, we do not use this fact
for our construction and provide inverse-freeness. Therefore our construction
allows using permutations which are ineﬃcient to invert but eﬃcient in the
forward direction. That is, computation time, implementation or memory eﬃ-
ciency of the forward direction of the permutation can be exploited by user
in our design. Moreover, our design allows using a non-invertible mapping in
the Sponge function.
– Conceptually, our approach is similar to the scheme Tag-KEM with partial
ciphertext recovery [18] but in our case the message can be directly recovered.
Therefore, our scheme can be used as a Tag-KEM with partial message recov-
ery. (We do not pursue this line in this paper due to the space limitation). This
Tag-KEM version of our scheme is similar to OAEP-4X, which trivially take
us to the comparison among OAEP-4X and SpAEP and other OAEP-type
schemes.
– Let f be a trapdoor one-way permutation then we denote the instantiation of
our scheme with f by f-SpAEP. The f-SpAEP can process arbitrary length
messages. Our scheme is CCA2 secure when used with any trapdoor one-way
permutation.
– We provide a formal security proof of f-SpAEP in adaptive chosen ciphertext
attack (CCA-2) notion in the ideal permutation model. Instead of directly
using security proof, in ROM, of sponge construction, we prefer a dedicated
proof from scratch in ideal permutation model to avoid multi-stage game prob-
lem [6,30]. Although [33] introduced an eﬃcient scheme in ideal permutation
model with full domain permutation encryption, still it remained impracti-
cal because having such big permutation size equivalent to trapdoor one-way
permutation size is itself hard. Similar problem of output size occurs when a
scheme requires hash output diﬀerent (generally larger) than standard sizes.

98
T.K. Bansal et al.
In Table 1, we compare OAEP [11], OAEP+ [36], OAEP-3R [33] and
OAEP-4X [4] with SpAEP. In Table 1 cipher text overhead values are taken
from Table 1 [4].
OAEP, OAEP+ and OAEP-3R can only handle messages of length less
than input size of trapdoor one-way permutation unlike OAEP-4X and SpAEP
can handle any message size.
In Table 1, for OAEP, number of functions run in parallel during encryp-
tion is zero, both hash function run sequentially. Similarly in the case of
OAEP-3R, all three hash function calls are sequential. OAEP+ uses three
hash functions, out of which only two function calls can run in parallel. In
OAEP-4X, for messages having size less than input size of trapdoor one-way
permutation, only 4 hash function calls are required sequentially. For long mes-
sages(message size more than input size of trapdoor one-way permutation),
OAEP-4X uses 5 hash functionss (H1, H2, H3, H4, G) calls and one symmetric
encryption scheme (E). Initially only two hash function calls run in parallel
(H1,G) then H2 and E runs parallel, and then H3 and H4 runs sequentially.
Overall in OAEP-4X, for long messages, only two functions calls can run in
parallel at instant. From Table 1, we can clearly see that SpAEP is a simple
and eﬃcient scheme in comparison to other schemes. Although SpAEP has
t-bit extra ciphertext overhead with respect to OAEP-4X, yet as explained
earlier this is a minor concern in general applications.
Table 1. Comparison of OAEP, OAEP+, OAEP-3R, SpAEP, OAEP-4X Here t is the
security requirements in term of number of bits. In order to break the scheme with
probability 1 number of queries required are 2t. ℓis input-output size of trapdoor one
way permutation f.
OAEP [11]
OAEP+ [36] OAEP-3R [33] OAEP-4X [4]
SpAEP
Ciphertext-
overhead
3t
3t
2t
t
2t
# Function
calls
2 Hash
3 Hash
3 Hash
5
Hash,
1
Sym-
metric
Encryp-
tion (E)
1 SpongeWrap,
1 Sponge func-
tion
# Function
calls
Sequential or
Parallel
(Encryption)
Sequential
2 parallel,
1
sequen-
tial
Sequential
Mixed
Parallel
Trapdoor
Perm.-f
RSA, Rabin
Any f
Any-f
Any f
Any-f
Max. Message
size with f
ℓ−3t
ℓ−3t
ℓ−2t
Any
Any
One may argue that in OAEP based schemes, for ﬁnal encryption and decryp-
tion, trapdoor one-way permutation show dominance in computation time
www.ebook3000.com

Sponge Based CCA2 Secure Asymmetric Encryption
99
with respect to OAEP type structure. This makes each and every scheme in-
advantageous over other schemes in terms of computation eﬃciency. We hope
this may not be the case always or in future. Recent development in lattice based
cryptography [13,29,32] shows up that computation time of trapdoor function
can reduce signiﬁcantly compared to existing traditional trapdoor permutation.
Therefore, it is fruitful to have OAEP type schemes that are better than existing
one and compatible with latest trends.
In summary, we are proposing an asymmetric padding scheme which is more
simple and eﬃcient in terms of structure and functionality than other existing
OAEP-type schemes.
2
Preliminaries
We discuss some preliminaries in this section.
Ideal Permutation: An permutation π is a bijective function on a ﬁnite domain
D and ﬁnite range R with D = R. An ideal permutation is a permutation chosen
uniformly at random from all the available permutations. Let D = R = {0, 1}b,
then π ←−Perm(D, D), where Perm(D, D) is the collection of all permutations
on D. Mathematically, π : D →R is a permutation, if for every y ∈R there is
one and only one x ∈D such that π(x) = y.
Trapdoor One-Way Permutations and Their Security: We recall the
security notion of a trapdoor one way permutation scheme. This scheme requires
a trapdoor permutation generator. This is a PPT algorithm F such that F(1ℓ)
outputs a pair of deterministic algorithms (f, f −1) specifying a permutation and
its inverse on {0, 1}ℓ. We associate to F an evaluation time tF(·): for all l, all
(f, f −1) ∈[F(1ℓ)] and all C ∈{0, 1}ℓ, the time to compute f(C) (given f and
C) is tF(ℓ). Note that the evaluation time depends on the setting: for example
on whether or not there is hardware available to compute f.
We will be interested in two attributes of a (possibly non-uniform) algorithm
B trying to invert F(1ℓ)-distributed permutations; namely its running time and
its success probability.
Deﬁnition 1. Let F be a trapdoor permutation generator. We say that f is a
one-way trapdoor permutation if for any eﬃcient adversary B trying to invert F
such that
Advowtp
F
(B)=Pr[(f, f −1)←F(1ℓ); y ←−{0, 1}ℓ: B(f, y) = C s.t. f(C) = y]≤ϵ,
where ϵ is negligible in ℓ.
CCA, CCA2 Security: For probabilistic public key scheme (PKE), indis-
tinguishability is deﬁned by the following experiment between an adversary A
and a challenger. For schemes based on computational security, the adversary
is modeled by a probabilistic polynomial time Turing machine, meaning that it

100
T.K. Bansal et al.
must complete the game and output a guess within a polynomial number of time
steps. The scheme PKE comprise (G, Epk, Dsk). Secret/Private keys (pk, sk) is
the generated by G and s is the auxiliary information collected by A using ora-
cle O1. Epk(M) represents the encryption of a message M under the public key
pk and Dsk represents the decryption of ciphertext y under secret key sk.
Experiment: Expind−atk−d
P KE,A
(ℓ)
1. (pk,sk)←−G(1ℓ); (M0, M1, s) ←AO1(·); y ←Epk(Md);
2. d′ ←AO2(·)(M0, M1, y, s);
3. return d′;
where |M0| = |M1| and y cannot be queried to O2 oracle, and
atk=CCA-1 :
O1(·) = Dsk(·) and O2(·) = Epk
atk=CCA-2 :
O1(·) = Dsk(·) and O2(·) = Dsk(·)
The scheme is IND-CCA1/IND-CCA2 [9] secure if adversary A has a non-
negligible advantage in winning (d′ = d) the above game. The deﬁnition of
security we have presented here is from [35]. It is known to be equivalent to
other notions, such as non-malleability [9,23] , which is called NM-CCA-2 in [9].
Pr[Expind−cca2−d
P KE,A
(ℓ) = d | d ←−{0, 1}] ≤negl(ℓ) + 1
2.
3
General View of OAEP+
In this section we provide a general view2 of the OAEP+ with f as the trapdoor
one way permutation in an informal way. This helps us to elaborate the basis of
the design of our scheme. This general view is shown in Figure 2, 3. It has three
parts:
1. One time Authenticated Encryption (OAE): This is a one time authentication
encryption that uses a one time key R and generates an encoded message
C and Tag T1 of message M. Message will be padded to suitable length
according to OAE.
2. Hash: This is a deterministic hashing algorithm. The concatenation of the
outputs of OAE with a one time key R is the input of this hashing algorithm.
It outputs T2.
3. Trapdoor one way Permutation: This is a trapdoor one way permutation
f : {0, 1}ℓ→{0, 1}ℓ, which takes the concatenation of the outputs of OAE
and Hash and produces the ﬁnal encryption.
2 This informal general view helps in understanding our scheme.
www.ebook3000.com

Sponge Based CCA2 Secure Asymmetric Encryption
101
y
TrapdoorPermutation-f
l
||
M
R
G
H′
H
Hash
(C||T1)
T2
OAE
⊕
l0
⊕
Fig. 1. OAEP+ with f
y
Encryption
Hash
TrapdoorPermutation-f
M
l
l0
R
Authenticated
r
One-Ti me
(OAE )
(C||T1)
T2
⊕
Fig. 2. General View of
Fig. 1
y
Sponge
TrapdoorPermutation-f
M
l
l0
R
r
(C||T1)
T2
⊕
SpongeWrap
Function
Fig. 3. Sponge based view of
Fig. 2
Figure 1 shows OAEP+ construction with f as the trapdoor one way permu-
tation. G, H′ and H are the hash functions used in OAEP+. If we map OAEP+
on our general view then the combination of G and H′ is OAE while H is the
Hash part. G provides a kind of one time pad encryption (OTE) to message M,
H′ provides hash tag T1 of M and H produces hash tag T2 of OTE and tag T1.
In this work, we provide f-SpAEP as an example of this general view where
the f-SpAEP scheme uses SpongeWrap as OAE and a Sponge function as Hash
part with diﬀerent IV.
One can view and use our scheme in hybrid encryption model and can also
utilize in key/data encapsulation method. But in this paper we are more focused
over sponge applicability in OAEP framework.
4
SpAEP-Sponge Based Asymmetric Encryption Padding
SpAEP is a Sponge function based construction. SpAEP iterates a ﬁxed permu-
tation π : {0, 1}bi × {0, 1}bc →{0, 1}bi × {0, 1}bc in a exact way to the Sponge
construction and SpongeWrap [15–17].
The bit length of input and output of π, called bit rate, is b = bi + bc.
The term bi is called input rate and the term bc is called capacity rate. The
permutation π is the only underlying cryptographic primitive used by SpAEP.
For using SpAEP for asymmetric key setting, one can use any trapdoor one
way permutation f : {0, 1}ℓ→{0, 1}ℓsuch as RSA. The resulting scheme is
called f-SpAEP. The output of function f is y ∈{0, 1}ℓand the trapdoor of f is
represented by f −1. ⌊x⌋r represents the ﬁrst r bit of x or we can say it r-bit chop
function. Similarly, ⌈x⌉represents the last r bit of x. See Figure 4 for graphical
presentation.

102
T.K. Bansal et al.
SpAEP handles the arbitrary length message and π is ﬁxed length permuta-
tion of input rate bi. SpAEP uses a reversible padding function pad(·) to generate
bi-bit length blocks. For scheme to be compatible with f, scheme uses pad(·) to
divided the message into two parts(M n, M e). First part should have minimum
n-block message where each block is of bi-bit length such that ℓ= n ∗bi + 2r,
ℓ≥bi and n ≥1. SpAEP process this n-block message M n = m1|| . . . ||mn and
gives output c1|| . . . ||cn which is the input of f. SpAEP process the second part
of the message M e = mn+1|| . . . ||me and gives output Ce = cn+1|| . . . ||ce. If
M e is an empty string, then Ce will also remain as empty string. SpAEP also
outputs r-bit tag T1 and T2 which is also the input of f. Final output of the
f-SpAEP will be y||Ce, where y = f(Cf = c1|| . . . ||cn||T1||T2). In case (ℓ, bi, r)
are chosen such that n is not an integer value, then ⌈cn⌉|Cf |−ℓbits removes
and append to Ce to ensure |Cf| = ℓ. Then Cf = c1|| . . . ||⌊cn⌋(bi−(|c[1,n]|−ℓ))
and Ce = ⌈cn⌉(|c[1,n]|−ℓ)||cn+1|| . . . ||ce. In paper we will consider n as inte-
ger only which means |Cf| = ℓ. Accordingly, Encryption : SpAEP −Eπ
f and
Decryption : SpAEP −Dπ
f −1 of f-SpAEP are described in Algorithms 1 and 2
respectively.
The encryption and decryption procedures of SpAEP use forward direction
of the permutation. Therefore we can have a permutation that is more eﬃcient
in forward direction than in inverse.
CCA2 Security of f-SpAEP3: Next we provide a formal proof of CCA2
security of f-SpAEP. As described in Section 2, the experiment of adversary A
for f-SpAEP is the following.
Experiment: Expind−cca2−d
F−SpAEP π,A(ℓ)
– ( f

pk
, f −1

sk
) ←−F;
– (M0, M1, s) ←Aπ(·),SpAEP −Dπ
f−1(·);
– y∗||Ce∗←SpAEP −Eπ
f (Md);
. . .
one time encryption query
– d′ ←Aπ(·),SpAEP −Dπ
f−1(·)(M0, M1, y∗||Ce∗, s);
– return d′;
where SpAEP −Dπ
f −1(·) is decryption oracle and SpAEP −Eπ
f (·) is
encryption algorithm.
3 In this paper for security proof, f-SpAEP and F-SpAEPπ refer to same thing. In f-
SpAEP, f and its trapdoor f −1 is generated by F like f, f −1 ←F and F is trapdoor
permutation generator.
www.ebook3000.com

Sponge Based CCA2 Secure Asymmetric Encryption
103
IV1
f
cn
c2
c1
. ..
R
m1
m2
mn
π
π
π
π
bi
bc
IV2
c2
π
π
π
π
bi
bc
IV3
IV1
c1
cn
cn+1
. ..
π
mn+1
π
. ..
.. .
me
ce
T1
T2
y
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
π
⊕
T1
T2
cn+1
. ..
ce
r
˜
r
R
⊕
⊕
π
10∗1
HAS H
OAE
0bi−r
˜
Fig. 4. SpAEP with any trapdoor one way permutation f and public invertible per-
mutation π : {0, 1}bi × {0, 1}bc ←{0, 1}bi × {0, 1}bc. SpAEP accepts message M and
internally OAE call pad(M)=m1|| . . . ||mn||mn+1|| . . . ||me such that n = (ℓ−2r)/bi,
|pad(M)| ≥(ℓ−2r) and each message bock is of length bi where ℓis size of trapdoor
permutation-f and |R| = |T1| = |T2| = r. The symbol ∼
⃝represents taking r-bit output
from bi-bit input. The symbol ||⃝represent concatenation.
Theorem 1. The success probability of any adversary A for CCA2 attack in
ideal permutation π on F−SpAEPπ is
Pr[Expind−cca2−d
F−SpAEP π,A(ℓ) = d|d ←−{0, 1}] ≤1
2 + (q −1)q
2b+1
+ q(q + 1)
2bc
+ 5qD
2r
+ qπA + qπ−1
2r
+ Advowtp
f
(BA)
+ (qπA + qπ−1)
min(2r, 2bc) ,
where q is the total number of (π and π−1) queries, qπ and qπ−1 are the
number of π and π−1 queries, qπA is the number of π queries by A, qD is the
number of decryption queries and b, bc, r are the same as deﬁned earlier, B is an
adversary that ﬁnds the complete input Cf of trapdoor one way permutation f
given y ←−{0, 1}ℓsuch that y = f(Cf), without having knowledge of f −1. Adver-
sary B uses A as a subroutine internally. Advowtp
F
(BA) is the success advantage
that a particular adversary B has in breaking the trapdoor one-way permutation
f. The time and space requirements of B are related to A as follows:
Time(B) = O(Time(A) + (qπA + qπ−1) · tf + (qπA + qπ−1 + qD) · ℓ);
(1)
Space(B) = O(Space(A) + (qπA + qπ−1) · ℓ).
(2)
Here, tf is the time required to compute f, and space is measured in the number
of storage bits.
Proof 1. Proof can be found in full version of this paper over e-print [8].

104
T.K. Bansal et al.
Algorithm 1. Encryption:
SpAEP −Eπ
f (M) = y||Ce
1 Initialization:
IV1 = 0bi,IV2 = 0bc,IV3 =
IV2 ⊕1, w = IV2, x = IV1
2 Random Nonce:
R ←−{0, 1}r
3 pad(M) =
m1||m2|| . . . ||me, where
|mi| = bi ∀1 ≤i ≤e
4 x = x ⊕R||0br−r
5 for i = 1 →e do
6
(x||w) = π(x||w)
7
x = x ⊕mi
8
ci = x
9 (x||w) = π(x||w);
T1 = ⌊x⌋r
10 x = IV1 and w = IV3
11 for i = 1 →e do
12
x = x ⊕ci
13
(x||w) = π(x||w)
14 x = x ⊕T1||0br−r
15 (x||w) = π(x||w)
16 T2 = ⌊x⌋r ⊕R
17 Cf =
c1||c2|| . . . ||cn||T1||T2;
Ce = cn+1|| . . . ||ce
18 y = f(Cf)
19 Return: y||Ce
Algorithm 2. Decryption:
SpAEP −Dπ
f−1(y||Ce) = M or ⊥
1 Initialization:
IV1 = 0bi,IV2 = 0bc,IV3 = IV2 ⊕1,
w = IV3, x = IV1
2 Cf = c1||c2|| . . . ||cn||T1||T2 = f −1(y);
cn+1|| . . . ||ce = Ce
3 C′ =
c1||c2|| . . . ||cn||T1||T2||cn+1|| . . . ||ce,
where |ci| = bi, |T1| = |T2| = r for
1 ≤i ≤e
4 for i = 1 →e do
5
x = x ⊕ci
6
(x||w) = π(x||w)
7 x = x ⊕T1||0br−r
8 (x||w) = π(x||w); R = ⌊x⌋r ⊕T2
9 x = R||0br−r; w = IV2
10 for i = 1 →e do
11
(x||w) = π(x||w)
12
mi = x ⊕ci
13
x = ci
14 (x||w) = π(x||w); T ′
1 = ⌊x⌋r
15 if T1 = T ′
1 then
16
if ∃M s.t.
M = unpad(m1|| . . . ||me) then
17
Return:M
18
else
19
Return: Invalid
20 else
21
Invalid.
5
Conclusion
We presented a new variant, SpAEP, of OAEP using Sponge constructions that
does not require hash output of arbitrary length, whereas all previous OAEP
based encryption proven secure in random-oracle model require one or more hash
output of arbitrary length. Versatility of Sponge construction helps us to reduce
number of round function as compared to previous OAEP-type schemes (OAEP,
OAEP+, OAEP-3R, OAEP-4X) and in constructing KEMs that require a PKC
scheme with ability of randomness recovery. Ability of handling long messages
enables the use of SpAEP with any trapdoor one-way permutation as hybrid
encryption.
www.ebook3000.com

Sponge Based CCA2 Secure Asymmetric Encryption
105
Acknowledgments. We thank the Cryptography Research Group (CRG) at IIIT-
Delhi, India for fruitful comments and the discussion about the results of this paper.
We also thank anonymous reviewers for comments, which helped to improve the paper.
References
1. Competition for Authenticated Encryption: Security, Applicability, and Robust-
ness(CAESAR) (2014). https://competitions.cr.yp.to/caesar.html
2. Password Hashing Competition (PHC) (2014). https://password-hashing.net/
index.html
3. Abe, M., Gennaro, R., Kurosawa, K.: Tag-KEM/DEM: A New Framework for
Hybrid Encryption. J. Cryptology 21(1), 97–130 (2008)
4. Abe, M., Kiltz, E., Okamoto, T.: Chosen Ciphertext Security with Optimal Cipher-
text Overhead. IEICE Transactions 93–A(1), 22–33 (2010)
5. Andreeva, E., Bilgin, B., Bogdanov, A., Luykx, A., Mennink, B., Mouha, N.,
Yasuda, K.: APE: authenticated permutation-based encryption for lightweight
cryptography. In: Cid, C., Rechberger, C. (eds.) FSE 2014. LNCS, vol. 8540,
pp. 168–186. Springer, Heidelberg (2015)
6. Baecher, P., Brzuska, C., Mittelbach, A.: Reset indiﬀerentiability and its conse-
quences. In: Sako, K., Sarkar, P. (eds.) ASIACRYPT 2013, Part I. LNCS, vol. 8269,
pp. 154–173. Springer, Heidelberg (2013)
7. Baek, J., Susilo, W., Liu, J.K., Zhou, J.: A new variant of the cramer-shoup KEM
secure against chosen ciphertext attack. In: Abdalla, M., Pointcheval, D., Fouque,
P.-A., Vergnaud, D. (eds.) ACNS 2009. LNCS, vol. 5536, pp. 143–155. Springer,
Heidelberg (2009)
8. Bansal, T.K., Chang, D., Sanadhaya, S.K.: Sponge based CCA2 secure asymmet-
ric encryption for arbitrary length message. Cryptology ePrint Archive, Report
2015/330 (2015). https://eprint.iacr.org/2015/330.pdf
9. Bellare, M., Desai, A., Pointcheval, D., Rogaway, P.: Relations among notions of
security for public-key encryption schemes. In: Krawczyk, H. (ed.) CRYPTO 1998.
LNCS, vol. 1462, pp. 26–45. Springer, Heidelberg (1998)
10. Bellare, M.,Rogaway, P.: Random oracles are practical: a paradigm for designing
eﬃcient protocols. In: Proceedings of the 1st ACM Conference on Computer and
Communications Security, CCS 1993, pp. 62–73. ACM, New York (1993)
11. Bellare, M., Rogaway, P.: Optimal asymmetric encryption. In: De Santis, A. (ed.)
EUROCRYPT 1994. LNCS, vol. 950, pp. 92–111. Springer, Heidelberg (1995)
12. Bellare, M., Rogaway, P.: The exact security of digital signatures - how to sign
with RSA and rabin. In: Maurer, U.M. (ed.) EUROCRYPT 1996. LNCS, vol. 1070,
pp. 399–416. Springer, Heidelberg (1996)
13. Bendlin, R., Krehbiel, S., Peikert, C.: How to share a lattice trapdoor: threshold
protocols for signatures and (H)IBE. In: Jacobson, M., Locasto, M., Mohassel,
P., Safavi-Naini, R. (eds.) ACNS 2013. LNCS, vol. 7954, pp. 218–236. Springer,
Heidelberg (2013)
14. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: The Sponge Functions Cor-
ner. http://sponge.noekeon.org/
15. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: Sponge functions, ECRYPT
Hash Function Workshop (2007)
16. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: Duplexing the sponge: single-
pass authenticated encryption and other applications. In: Miri, A., Vaudenay, S.
(eds.) SAC 2011. LNCS, vol. 7118, pp. 320–337. Springer, Heidelberg (2012)

106
T.K. Bansal et al.
17. Bertoni, G., Peeters, M., Daemen, J., Van Assche, G.: Permutation-based encryp-
tion, authentication and authenticated encryption. Directions in Authenticated
Ciphers (2012)
18. Bjørstad, T.E., Dent, A.W., Smart, N.P.: Eﬃcient KEMs with partial mes-
sage recovery. In: Galbraith, S.D. (ed.) Cryptography and Coding 2007. LNCS,
vol. 4887, pp. 233–256. Springer, Heidelberg (2007)
19. Canetti, R., Krawczyk, H., Nielsen, J.B.: Relaxing chosen-ciphertext security.
In: Boneh, D. (ed.) CRYPTO 2003. LNCS, vol. 2729, pp. 565–582. Springer,
Heidelberg (2003)
20. Coron, J.-S.: On the exact security of full domain hash. In: Bellare, M. (ed.)
CRYPTO 2000. LNCS, vol. 1880, pp. 229–235. Springer, Heidelberg (2000)
21. Cramer, R., Shoup, V.: Design and Analysis of Practical Public-Key Encryption
Schemes Secure against Adaptive Chosen Ciphertext Attack. IACR Cryptology
ePrint Archive 2001, 108 (2001). http://eprint.iacr.org/2001/108
22. Dent, A.W.: A designer’s guide to KEMs. In: Paterson, K.G. (ed.) Cryptography
and Coding 2003. LNCS, vol. 2898, pp. 133–151. Springer, Heidelberg (2003)
23. Dolev, D., Dwork, C., Naor, M.: Non-Malleable Cryptography (Extended Abst-
ract). In: Koutsougeras, C., Vitter, J.S. (eds.) STOC, pp. 542–552. ACM (1991)
24. Hofheinz, D., Kiltz, E.: Secure hybrid encryption from weakened key encapsulation.
In: Menezes, A. (ed.) CRYPTO 2007. LNCS, vol. 4622, pp. 553–571. Springer,
Heidelberg (2007)
25. Kiltz, E.: Chosen-ciphertext security from tag-based encryption. In: Halevi, S.,
Rabin, T. (eds.) TCC 2006. LNCS, vol. 3876, pp. 581–600. Springer, Heidelberg
(2006)
26. Kurosawa, K., Desmedt, Y.: A new paradigm of hybrid encryption scheme. In:
Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp. 426–442. Springer,
Heidelberg (2004)
27. RSA Laboratories. PKCS #1 v2.1: RSA cryptography standard, June 2002
28. Leurent, G., Nguyen, P.Q.: How risky is the random-oracle model? In: Halevi, S.
(ed.) CRYPTO 2009. LNCS, vol. 5677, pp. 445–464. Springer, Heidelberg (2009)
29. Micciancio, D., Peikert, C.: Trapdoors for lattices: simpler, tighter, faster, smaller.
In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237,
pp. 700–718. Springer, Heidelberg (2012)
30. Mittelbach, A.: Salvaging indiﬀerentiability in a multi-stage setting. In: Nguyen,
P.Q., Oswald, E. (eds.) EUROCRYPT 2014. LNCS, vol. 8441, pp. 603–621.
Springer, Heidelberg (2014)
31. Okamoto, T.: Authenticated key exchange and key encapsulation in the standard
model. In: Kurosawa, K. (ed.) ASIACRYPT 2007. LNCS, vol. 4833, pp. 474–484.
Springer, Heidelberg (2007)
32. Peikert, C.: Lattice cryptography for the internet. In: Mosca, M. (ed.) PQCrypto
2014. LNCS, vol. 8772, pp. 197–219. Springer, Heidelberg (2014)
33. Phan, D.H., Pointcheval, D.: Chosen-ciphertext security without redundancy.
In: Laih, C.-S. (ed.) ASIACRYPT 2003. LNCS, vol. 2894, pp. 1–18. Springer,
Heidelberg (2003)
34. Phan, D.H., Pointcheval, D.: OAEP 3-round:a generic and secure asymmetric
encryption padding. In: Lee, P.J. (ed.) ASIACRYPT 2004. LNCS, vol. 3329,
pp. 63–77. Springer, Heidelberg (2004)
35. Rackoﬀ, C., Simon, D.R.: Non-interactive zero-knowledge proof of knowledge and
chosen ciphertext attack. In: Feigenbaum, J. (ed.) CRYPTO 1991. LNCS, vol. 576,
pp. 433–444. Springer, Heidelberg (1992)
36. Shoup, V.: OAEP Reconsidered. J. Cryptology 15(4), 223–249 (2002)
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant
Modular Arithmetic in RNS
Christophe Negre1,2(B) and Guilherme Perin3
1 Team DALI, Universit´e de Perpignan, Perpignan, France
christophe.negre@univ-perp.fr
2 LIRMM, UMR 5506, Universit´e Montpellier 2 and CNRS, Montpellier, France
3 Riscure, Delft, The Netherlands
Abstract. On an embedded device, an implementation of cryptographic
operation, like an RSA modular exponentiation [12], can be attacked by
side channel analysis. In particular, recent improvements on horizontal
power analysis [3,10] render ineﬀective the usual counter-measures which
randomize the data at the very beginning of the computations [2,4]. To
counteract horizontal analysis it is necessary to randomize the computa-
tions all along the exponentiation. The leak resistant arithmetic (LRA)
proposed in [1] implements modular arithmetic in residue number system
(RNS) and randomizes the computations by randomly changing the RNS
bases. We propose in this paper a variant of the LRA in RNS: we propose
to change only one or a few moduli of the RNS basis. This reduces the
cost of the randomization and makes it possible to be executed at each
loop of a modular exponentiation.
Keywords: Leak resistant arithmetic · Randomization · Modular mul-
tiplication · Residue number system · RSA
1
Introduction
Nowadays, the RSA cryptosystem [12] is constantly used in e-commerce and
credit card transactions. The main operation in RSA protocols is an exponenti-
ation xK mod N where N is a product of two primes N = pq. The secret data
are the two prime factors of N and the private exponent K used to decrypt or
sign a message. The actual recommended size for N is around 2000-4000 bits to
insure the intractability of the factorization of N. The basic approach to perform
eﬃciently the modular exponentiation is the square-and-multiply algorithm: it
scans the bits ki of the exponent K and performs a sequence of squarings fol-
lowed by a multiplication only when ki is equal to one. Thus the cryptographic
operations are quite costly since they involve a few thousands of multiplications
or squarings modulo a large integer N.
A cryptographic computation performed on an embedded device can be
threaten by side channel analysis. These attacks monitor power consumption
or electromagnetic emanation leaked by the device to extract the secret data.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 107–124, 2015.
DOI: 10.1007/978-3-319-19962-7 7

108
C. Negre and G. Perin
The simplest attack is the simple power analysis (SPA) [8] which applies when
the power trace of a modular squaring and a modular multiplication are diﬀer-
ent. This makes it possible to read the sequence of operations on the power trace
of an exponentiation and then derive the key bits of the exponent. This attack
is easily overcome by using an exponentiation algorithm like the Montgomery-
ladder [6] which render the sequence of operation uncorrelated to the key bits.
A more powerful attack, the diﬀerential power analysis (DPA) [8], makes this
counter-measure against SPA ineﬃcient. Speciﬁcally, DPA uses a large number
of traces and correlate the intermediate values with the power trace: it then track
the intermediate value all along the computation and then guess the bits of the
exponent. Coron in [4] has shown that the exponentiation can be protected from
DPA by randomizing the exponent and by blinding the integer x. Recently the
horizontal attacks presented in [3,13] require only one power trace of an expo-
nentiation, and threaten implementations which are protected against SPA and
DPA with the method of Coron [4]. The authors in [3] explains that the best
approach to counteract horizontal attack is to randomize the computations all
along the exponentiation.
One popular approach to randomize modular arithmetic is the leak-resistant
approach presented in [1] based on residue number system (RNS). Indeed, in [1],
the authors noticed that the mask induced by Montgomery modular multipli-
cation can be randomized in RNS by permuting the moduli of the RNS bases.
In this paper we investigate an alternative method to perform this permutation
of bases. Our method changes only one modulus at a time. We provide formula
for this kind of randomization along with the required updates of the constants
involved in RNS computations. The complexity analysis shows that this app-
roach can be advantageous for a lower level of randomization compared to [1].
In other words this provides a trade-oﬀbetween eﬃciency and randomization.
The remainder of the paper is organized as follows. In Section 2 we review
modular exponentiation methods and modular arithmetic in RNS. We then
recall in Section 3 the leak resistant arithmetic in RNS of [1]. In Sections 4 and
Appendix A we present our methods for randomizing the modular arithmetic in
RNS. We then conclude the paper in Section 5 by a complexity comparison and
some concluding remarks.
2
Review of Modular Exponentiation in RNS
2.1
Modular Exponentiation
The basic operation in RSA protocols is the modular exponentiation: given an
RSA modulus N, an exponent K and a message x ∈{0, 1, . . . , N −1}, a modular
exponentiation consists to compute
z = xK
mod N.
This exponentiation can be performed eﬃciently with the square-and-multiply
algorithm. This method scans the bits ki of the exponent K = (kℓ−1, . . . , k0)2
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
109
from left to right and performs a sequence of squarings followed by multiplica-
tions by x if the bit ki = 1 as follows:
r ←1
for i from ℓ−1 downto 0 do
r ←r2 mod N
if ki = 1 then
r ←r × x mod N
end if
end for
The complexity of this approach is, in average, ℓsquarings and ℓ/2 multiplica-
tions.
Koche et al. in [8] showed that the square-and-multiply exponentiation is
weak against simple power analysis. Indeed, if a squaring and a multiplication
have diﬀerent power traces, an eavesdropper can read on the trace of a modular
exponentiation the exact sequence of squarings and multiplications, and then
deduce the corresponding bits of K. It is thus recommended to perform an
exponentiation using, for example, the Montgomery-ladder [6] which computes
xK mod N through a regular sequence of squarings and multiplications. This
method is detailed in Algorithm 1. The regularity of the exponentiation prevents
an attacker to directly read the key bits on a single trace.
Algorithm 1. Montgomery-ladder [6]
Require: x ∈{0, . . . , N −1} and K = (kℓ−1, . . . , k0)2
1: r0 ←1
2: r1 ←x
3: for i from ℓ−1 downto 0 do
4:
if ki = 0 then
5:
r1 ←r1 × r0
6:
r0 ←r2
0
7:
end if
8:
if ki = 1 then
9:
r0 ←r0 × r1
10:
r1 ←r2
1
11:
end if
12: end for
13: return (r0)
Some more sophisticated attacks can threaten a naive implementation of
Montgomery-ladder exponentiation. For example diﬀerential power analysis [8]
makes it necessary to randomize the exponent and blind the integer x by random
mask as explained in [4]. Horizontal approaches [3,13] are even more powerful
since they require only a single trace to complete the attack and is eﬀective even
if the exponent K is masked and the data x is blinded. The authors in [3] propose
to counteract horizontal power analysis by randomizing each multiplication and

110
C. Negre and G. Perin
squaring using some temporary mask. In this paper we deal with the problem
of randomizing modular multiplications and squarings: we will use the residue
number system (RNS) to represent integers and perform eﬃciently modular
operations.
2.2
Montgomery Multiplication in RNS
Let N be a modulus and let x, y be two integers such that 0 ≤x, y < N. One
of the most used methods to perform modular multiplication x × y mod N is
the method of Montgomery in [9]. This approach avoids Euclidean division as
follows: it uses an integer A such that A > N and gcd(A, N) = 1 and computes
z = xyA−1 mod N as follows:
q ←−xyN −1
mod A
z ←(xy + qN)/A
(1)
To check the validity of the above method we notice that (xy+qN) mod A = 0,
this means that the division by A is exact in the computation of z and then
z = xyA−1 mod N. The integer z is almost reduced modulo N since z =
(xy + qN)/A < (N 2 + AN)/A < 2N: if z > N, with a single subtraction of
N we can have z < N. In practice the integer A is often taken as a power of 2
in order to have almost free reduction and division by A.
For a long sequence of multiplications, the use of the so-called Montgomery
representation is used
x = (x × A)
mod N.
(2)
Indeed, the Montgomery multiplication applied to x and y output z = xyA
mod N, i.e., the Montgomery representation of the product of x and y.
Residue Number System. In [11] the authors showed that the use of residue
number system (RNS) makes it possible to perform Montgomery multiplication
eﬃciently with an alternative choice for A. Let a1, . . . , at be t coprime integers.
In the residue number system an integer x such that 0 ≤x < A = 
i=1 ai is
represented by the t residues
xi = x
mod ai for i = 1, . . . , t.
Moreover, x can be recovered from its RNS expression using the Chinese remain-
der theorem (CRT) as follows
x =

t

i=1

xi × A−1
i

ai × Ai

mod A
(3)
where Ai = t
j=1,j̸=i ai and the brackets [ · ]ai denotes a reduction modulo ai.
The set A = {a1, . . . , at} is generally called an RNS basis.
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
111
Let x = (x1, . . . , xt)A and y = (y1, . . . , yt)A be two integers given in an RNS
basis A. Then, the CRT provides that an integer addition x+y or multiplication
x × y in RNS consists in t independent additions/multiplications modulo ai
x + y = ([x1 + y1]a1, . . . , [xt + yt]at),
x × y = ([x1 × y1]a1, . . . , [xt × yt]at).
The main advantage is that these operations can be implemented in parallel since
each operation modulo ai are independent from the others. Only comparisons
and Euclidean divisions are not easy to perform in RNS and require partial
reconstruction of the integers x and y.
Montgomery Multiplication in RNS. In [11] Posch and Posch notice that
the Montgomery multiplication can be eﬃciently implemented in RNS: they use
the fact that we can modify the second step of the Montgomery multiplication (1)
as
z ←(xy + qN)A−1
mod B
where B is an integer coprime with A and N and greater than 2N. Furthermore,
Posch and Posch propose to perform this modiﬁed version of the Montgomery
multiplication in RNS. Speciﬁcally, they choose two RNS bases A = (a1, . . . , at)
and B = (b1, . . . , bt) such that gcd(ai, bj) = 1 for all i, j. They perform z =
xyA−1 mod N as it is shown in Algorithm 2: the multiplications modulo A are
done in the RNS basis A and the operations modulo B are done in B.
Algorithm 2. Basic-MM-RNS(x, y, A, B)
Require: x, y in A ∪B
Ensure: xyA−1 mod N in A ∪B
1: [q]A ←[−xyN −1]A
2: BEA→B([q]A)
3: [z]B ←[(xy + qN)A−1]B
4: BEB→A([z]B)
5: return (zA∪B)
The second and fourth steps are necessary since if we want to compute z ←
(xy+qN)A−1 mod B in B we need to convert the RNS representation of q from
the basis A to the basis B: the base extension (BE) performs this conversion.
The fourth step is also necessary to have z represented in both bases A and B.
Base Extension. This is the most costly step in the RNS version of the Mont-
gomery multiplication (Algorithm 2). We review the best known method to
perform such RNS base extension. Let x = (x1, . . . , xt)A be the representation
of an integer x in the RNS basis A, the CRT 3 reconstructs x as follows:
ˆxai =

xai × A−1
i

ai for i = 1, . . . , t,
(4)
x
=
	
t
i=1 ˆxai × Ai

−αA
(5)

112
C. Negre and G. Perin
The correcting term −αA corresponds to the reduction modulo A in (3). We
get the RNS representation [x]bj for j = 1, . . . , t of x in B by simply reducing
modulo bj the expression in (5):
x∗
bj =

t
i=1 ˆxai × Ai

bj
, for j = 1, . . . , t,
[x]bj =

x∗
bj −αA

bj
for j = 1, . . . , t.
(6)
We give some details on how to perform the above computations.
• Computations of x∗
bj. If the constants [Ai]bj are precomputed then x∗
bj for
j = 1, . . . , t can be computed as
x∗
bj =

t

i=1
ˆxai × [Ai]bj

bj
.
There is an alternative method proposed by Garner in [5] which computes
x∗
bj, but we will not use it in this paper, so we do not recall it here. The
reader may refer to [5] to further details on this method.
• Computations of α. The base extension in (6) necessitates also to compute
α. We arrange (5) as follows
t

i=1
ˆxai × Ai = x + αA =⇒
t

i=1
ˆxai
ai
= x
A + α =⇒α =

t

i=1
ˆxai
ai

(7)
since when 0 < x < A we have 0 < x/A < 1.
The MM-RNS Algorithm. Following [7] we inject in Algorithm 2 the formu-
las (4), (5) and (7) corresponding to the computations of the base extensions.
We obtain the Montgomery multiplication in RNS (MM-RNS) shown in Algo-
rithm 3 after some modiﬁcations. Speciﬁcally, the base extension of q and the
computation of z are merged as follows
zbi ←[(sbi +
t

j=1
qajAjN −αAN)A−1]bi = [sbiA−1 + (
t

j=1
qaja−1
j
−α)N]bi.
In the second base extension BEB→A we rewrite [Bj]ai = [b−1
j B]ai.
The complexity of each step of the MM-RNS algorithm is given in terms of
the number of additions and multiplications modulo ai or bi. These complexities
are detailed in Table 1. For the computation of α and β we assume that each ai
and bi can be approximated by 2w which simpliﬁes the computations in Step 6
and Step 10 as a sequence of additions (cf. [7] for further details).
Constants Used in MM-RNS. In Algorithm 3, an important number of
constants take part of the computations:
[N −1]A, [N]B,
[b−1
j ]ai, [a−1
j ]bi for i, j = 1, . . . , t,
[B]ai, [B−1
i
]bi for i = 1, . . . , t,
[A−1]bi, [A−1
i ]ai for i = 1, . . . , t.
(8)
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
113
Algorithm 3. MM-RNS(x, y, A, B)
Require: x, y in A ∪B for two RNS bases A = {a1, . . . , at} and B = {b1, . . . , bt} s.t.
A = t
i=1 ai, B = t
i=1 bi, gcd(A, B) = 1, 1 ≤x, y ≤N, B ≥4N et A > 2N.
Ensure: xyA−1 mod N in A ∪B
1: Precomputations in B: [N]B, [A−1]B, [b−1
j ]B for j = 1, . . . , t and [B−1
i
]bi for
i = 1, . . . , t
2: Precomputations in A: [N −1]A and [a−1
j ]A, [A−1
j ]aj for j = 1, . . . , t and [B]A
3: s = [x · y]A∪B
4: //- - - - - - - - - base extension A →B - - - - - -
5: qai ←[sai × (−N −1) × A−1
i
]ai for i = 1 to t
6: α ←
t
i=1 qai/ai

7: zbi ←[sbiA−1 + (t
j=1 qaja−1
j
−α)N]bi for i = 1 to t
8: //- - - - - - - - - base extension B →A - - - - - - -
9: qbi ←[zbi × B−1
i
]bi for i = 1 to t
10: β ←
t
i=1 qbi/bi

11: zai ←[(t
j=1 qbjb−1
j
−β)B]ai for i = 1 to t
Table 1. Complexity of MM-RNS
Step #Mult.
#Add.
3
2t
0
5
2t
0
6
0
t −1
7
t(t + 2)
t(t + 1)
9
t
0
10
0
t −1
11
t(t + 1)
t2
Total t(2t + 8) t(2t + 3) −2
Only, the constants [B−1]ai, [B−1
i
]bi, [A]bi and [A−1
i ]ai are susceptible to change
and to be updated during the run of a modular exponentiation if the bases A
and B are modiﬁed.
3
Leak Resistant Arithmetic in RNS
The authors in [1] notice that the use of RNS facilitates the randomization of the
representation of an integer and consequently the randomization of a modular
multiplication. Indeed, if a modular exponentiation xK mod N is computed
with MM-RNS the element is set in Montgomery representation
x = x × A
mod N
and in the RNS bases A and B, i.e., [x]A∪B. The Montgomery representation
induces a multiplicative masking of the data x by the factor A. The authors
in [1] propose to randomly construct the basis A to get a random multiplicative
mask A on the data.

114
C. Negre and G. Perin
Speciﬁcally, the authors in [1] propose two levels of such randomization: ran-
dom initialization of the bases A and B at the very beginning of a modular
exponentiation and random permutations of RNS bases A and B all along the
modular exponentiation.
Random Initialization of the Bases A and B and x. We assume that we
have a set of 2t moduli M = {m1, . . . , m2t}. At the beginning of the computa-
tions we randomly set
A ←−{t random distinct elements in M}
B ←−M\A
(9)
Note that we always have A ∪B = M.
Then the input of x of the modular exponentiation algorithm is ﬁrst set in
the residue number system M = A ∪B by reducing x modulo each ai and bi
[x]A∪B = ([x]a0, . . . , [x]at, [x]b0, . . . , [x]bt).
Then we need to compute the Montgomery representation [x]A∪B from [x]A∪B.
The authors in [1] give a method which simpliﬁes this computation. They assume
that the RNS representation of
M
mod N = (2t
i=1 mi)
mod N
= A × B
mod N
is precomputed. They compute [x]A∪B from [x]A∪B by a single MM-RNS with
bases B and A in reverse order:
MM-RNS([x]A∪B, [(M mod N)]A∪B, B, A)
The output of this multiplication is the expected value:
[(x × M × B−1 mod N)]A∪B = [(x × A mod N)]A∪B = [x]A∪B.
Random Change of the Bases A and B. The authors in [1] propose to
change the bases A and B during the RSA exponentiation as follows:
Anew ←−{t random distinct elements in M}
Bnew ←−M\Anew
(10)
The bases A and B change all along the exponentiation, this implies to perform
the base extension (BE) in MM-RNS using the approach of Garner [5] instead of
the CRT formula. Otherwise the constants Ai and Bi would have to be updated
which can be expensive.
The update of the bases A and B implies to also update the Montgomery
representation x = x×Aold mod N of x from the old bases Aold∪Bold to the new
representation x = x×Anew mod N in the new bases Anew∪Bnew. The proposed
approach in [1] consists in two modular multiplications (cf. Algorithm 4).
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
115
Algorithm 4. Update of x
Require: xold and Anew, Bnew, Aold, Bold and [M mod N]M
Ensure: xnew
1: temp ←MM-RNS(xold, (M mod N), Bnew, Anew)
2: xnew ←MM-RNS(temp, 1, Aold, Bold)
We can easily check the validity of Algorithm 4: Step 1 computes temp =
(xAold)×(Anew ×Bnew)×B−1
new mod N and Step 2 correctly computes xnew =
(xAoldAnew) × A−1
old mod N = xAnew mod N in the required RNS bases.
The main drawback of this technique is that it is a bit costly: it requires
two MM-RNS multiplications to perform the change of RNS representation.
Consequently, using Table 1, we deduce that the amount of computation involved
in this approach is as follows
#Mult. = 2t(2t + 8) and #Add. = 2t(2t + 3) −4.
4
Random Update of the RNS Bases with a Set of Spare
Moduli
In this section, our goal is to provide a cheaper variant of the leak resistant
arithmetic in RNS proposed in [1] and reviewed in Section 3.
4.1
Proposed Update of the Bases and Montgomery Representation
We present a ﬁrst strategy which modiﬁes only one modulus in A while keeping
B unchanged during each update of the RNS bases. We need an additional set
A′ of spare moduli where we randomly pick the new modulus for A. We have
three sets of moduli:
• The ﬁrst RNS basis A = {a1, . . . , at+1} which is modiﬁed after each loop
iteration.
• The set A′ = {a′
1, . . . , a′
t+1} of spare moduli.
• The second RNS basis B = {b1, . . . , bt+1} which is ﬁxed at the beginning of
the exponentiation.
The integers ai, bi and a′
i are all pairwise co-prime and are all of the form 2w −
μi where w is the same for all moduli and μi < 2w/2. We will state later in
Subsection 4.2 how large A and B have to be compared to N to render the
proposed approach eﬀective. But to give an insight A and B are roughly w-bits
larger than N which means that the considered RNS bases contain t+1 moduli.
Update of the Base A. Updating the basis A is quite simple: we just swap
one element of A with one element of A′ as follows
• r ←random in {1, . . . , t, t + 1}

116
C. Negre and G. Perin
• r′ ←random in {1, . . . , t, t + 1}
• ar,new ←a′
r′,old
• ar′,new ←ar,old
In the sequel we will denote Aold and Anew the base A before and after the
update, we will use similar notation for other updated data.
Update of the Montgomery-RNS Representation. The modiﬁcation of the
basis requires at the same time the corresponding update of the Montgomery rep-
resentation of x. Indeed we need to compute xnew = [(xAnew mod N)]Anew∪B
from its old Montgomery representation xold = [(xAold mod N)]Aold∪B. The
following lemma establishes how to perform this update.
Lemma 1. We consider two RNS bases A and B and let A′ be the set of spare
moduli. We consider an integer x modulo N given by its RNS-Montgomery rep-
resentation [x]A∪B = [(x × A mod N)]A∪B where A = a1a2 · · · at+1. Let r and
r′ be two random integers in {1, . . . , t, t + 1} and Anew and A′
new be the two set
of moduli obtained after exchanging ar,old et a′
r′,old. Then the new Montgomery-
RNS representation of x in Anew ∪B can be computed as follows:
λ = [−xar,old × N −1]ar,old,
xnew = [(xold + λ × N) × a−1
r,old × ar,new]Anew∪B
(11)
and satisﬁes xnew = (x × Anew) mod N given in the bases Anew ∪B.
Proof. We ﬁrst notice that s1 = xold + λN satisﬁes s1 ≡xold mod N and that
[s1]ar,old = [xold + λ × N]ar,old
=

xold −[x]ar,old × N −1 × N

ar,old
= 0.
In other words s1 can be divided by ar,old and then multiplied by ar,new
xnew = ((xold + λN)/ar,old)ar,new.
which satisﬁes
xnew
mod N = ((xold + λN)/ar,old)ar,new
mod N
= xAolda−1
r,oldar,new
mod N
= xAnew
mod N
The value of xnew is computed in the RNS basis Anew ∪B by replacing the
division by ar,old by a multiplication by a−1
r,old and by noticing that its value
modulo ar,new is equal to 0. This leads to (11).
■
Update of the Constants. If we want to apply MM-RNS (Algorithm 3) after
the update of the basis A and the Montgomery-RNS representation of x, we need
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
117
also to update the constants involved in Algorithm 3. The constants considered
are the one listed in (8) along with the following additional set of constants
associated to the set of moduli A′:
[−N −1]a′
i i= 1,. . . ,t+1,
[A−1]a′
i, [B]a′
i i= 1,. . . ,t+1,
[b−1
j ]a′
i, [a′−1
j
]bi i,j= 1,. . . ,t+1,
[a−1
j ]a′
i, [a′−1
j
]ai i,j= 1,. . . ,t+1.
These constants are updated as follows:
• Constant −N −1. The constants [−N −1]ai only changes when i = r and
[−N −1]a′
i only change when i = r′. Then this update consists only in a
single swap
swap([−N −1]ar, [−N −1]a′
r′ ).
• Constant N. The constants [N]bi, i = 1, . . . , t + 1 do not change when the
base A is updated.
• Constants A−1
i
and A−1. The constants [A−1
i ]ai and [A−1]a′
i and [A−1]bi are
updated as follows:
[A−1
i ]ai ←[[A−1
i ]ai × a−1
r,new × ar,old]ai for i ̸= r,
[A−1]a′
i ←[[A−1]a′
i × a−1
r,new × ar,old]a′
i for i ̸= r′,
[A−1]bi ←[[A−1]bi × a−1
r,new × ar,old]bi for i ̸= r′,
and the two remaining special cases are:
[A−1
r ]ar,new ←[[A−1]a′
r′,old × ar,old]ar′,old
(Note that a′
r′,old = ar,new),
[A−1]a′
r′,new ←[[A−1
r ]ar,old × a−1
r,new]ar,old
(Note that ar,old = a′
r′,new).
• Constants [B−1
i
]bi, [B]ai and [B]a′
i. The constants [Bi]bi and [B]ai for i ̸= r
and [B]a′
i for i ̸= r′ are not aﬀected by the modiﬁcation on A. The only
required modiﬁcation is the following swap
swap([B]ar, [B]a′
r′ ).
• Constants [b−1
j ]ai, [b−1
j ]a′
i, [a−1
j ]ai, [a−1
j ]a′
i, [a′−1
j
]ai, and [a′−1
j
]a′
i. The con-
stants which evolve are the ones corresponding to ar and a′
r′ and require
only swaps:
swap([b−1
j ]ar, [b−1
j ]a′
r′)
for j = 1, . . . , t + 1,
swap([a−1
r ]bj, [a′−1
r′ ]bj)
for j = 1, . . . , t + 1,
swap([a−1
j ]ar, [a−1
j ]a′
r′ )
for j = 1, . . . , t + 1 and j ̸= r,
swap([a′−1
j
]ar, [a′−1
j
]a′
r′ ) for j = 1, . . . , t + 1 and j ̸= r′.
Complexity of the Updates. We evaluate the complexity of the above random
change of the basis A: the update of x and the update of the constants. We do
not consider swap operations since they do not require any computations. The
cost of the update of the Montgomery representation x of x contributes to 6t+4
multiplications and 2t + 1 additions and the contribution of the update of the
constants is equal to 6t + 2 multiplications.

118
C. Negre and G. Perin
Table 2. Complexity of the updates when using a set of spare moduli
Operation
#Mult. #Add.
Updates of x
6t + 4
2t + 1
Updates of the constants 6t + 2
0
4.2
Proposed Randomized Montgomery-Ladder and Its Validity
We present the modiﬁed version of the Montgomery-ladder: compared to the
original Montgomery-ladder (Algorithm 1), this version inserts an update of
the RNS bases and related constants along with an update of the data at the
beginning of the loop iteration. This approach is shown in Algorithm 5. For the
sake of simplicity, conversions between RNS and regular integer representation
are skipped.
Algorithm 5. Randomized-Montgomery-ladder
Require: x ∈{0, . . . , N −1} and K = (kℓ−1, . . . , k0)2, three RNS bases A, A′, B
1: r0 ←[1]A∪B
2: r1 ←[x]A∪B
3: for i from ℓ−1 downto 0 do
4:
UpdateBases(A, A′)
5:
UpdateMontRep( r0)
6:
UpdateMontRep( r1)
7:
if ki = 0 then
8:
r1 ←MM-RNS( r1, r0)
9:
r0 ←MM-RNS( r0, r0)
10:
end if
11:
if ki = 1 then
12:
r0 ←MM-RNS( r1, r0)
13:
r1 ←MM-RNS( r1, r1)
14:
end if
15: end for
16: return (r0)
Now, we establish that the above algorithm correctly outputs the expected
result xK mod N. Indeed, during the execution of the algorithm an overﬂow
could occur: some data could become larger than A or B. To show that no
overﬂow occurs we ﬁrst establish the growing factor produced by an update of
the Montgomery representation.
Lemma 2. Let Aold, A′
old, Bold, Anew, A′
new and Bnew be the new and the old
RNS bases. Let aimax,old the largest modulus in Aold and aimax,new the largest
modulus in Anew. Assume that xold < Naimax,old and let ar and a′
r′ be the two
moduli swapped in A and A′. Then we have
xnew < 4Naimax,new
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
119
Proof. From Lemma 1 we have the following expression of xnew
xnew = ((xold + λN)/ar) × a′
r′.
(12)
We then notice that λ < aimax,old. We use the fact that xold < Naimax,old and
we expand the product in (12), this gives:
xnew < (Naimax,old + aimax,oldN) ×
1
ar × a′
r′
≤2N × aimax,old
ar
× a′
r′.
(13)
We then use that ai = 2w −μi with 0 ≤μi < 2w/2, which implies that for any
i, j
0 < ai
aj = 2w−μi
2w−μj = 2w−μj+μj−μi
2w−μj
= 1 + μj−μi
2w−μj
< 1 +
2w/2
2w−μj < 2.
In particular for i = imax and j = r we have 0 < aimax,old
ar
< 2. We use this to
arrange (13) as follows:
xnew < 4Na′
r′ ≤4Naimax,new.
■
Knowing the growing factor induced by the update of the Montgomery rep-
resentation helps us to state a suﬃcient condition to prevent an overﬂow in
Algorithm 5.
Lemma 3. Let Amin be the product of the t smallest moduli in A∪A′. Let aimax
be the largest modulus of A. If N satisﬁes
N < Amin
32
(14)
and if B is larger than any A then the following assertions hold:
i) The data r0 and r1 in Algorithm 5 are < Naimax at the end of each loop.
ii) Algorithm 5 correctly computes r0 = xK mod N.
Proof.
i) Let us prove that an update of the base A followed by a modular
multiplication with MM-RNS keeps the data in the interval [0, Naimax]. We
consider xold < Naimax,old and yold < Naimax,old. Then, from Lemma 2, we
know that the updates on xold and yold provide:
xnew < 4Naimax,new and ynew < 4Naimax,new.
If we execute an MM-RNS algorithm with inputs xnew, ynew and bases Anew
and B we obtain a z satisfying
z = (xnew × ynew + qN)/Anew
< (16N 2a2
imax,new + AnewN)/Anew
< N(
16N
Anew/aimax,new × aimax,new + 1)

120
C. Negre and G. Perin
Now, since
Anew
aimax,new is the product of t moduli of A ∪A′ it satisﬁes Amin ≤
Anew
aimax,new . Then using (14) we obtain that
32N
Anew/aimax,new
× aimax,new
2
< aimax,new
2
and consequently z < aimax,newN, as required.
ii) At the beginning of each loop r0 and r1 are in [0, Naimax] then, from i), they
are in [0, Naimax] at the end of the loop. Consequently all the computations
in the algorithm are done without overﬂow and which then correctly outputs
r0 = xK mod N.
■
5
Complexity Comparison and Conclusion
In Appendix A we present a variant of the proposed randomization. This variant
avoids the use of the set of spare moduli A′: the modiﬁed modulus in A is
randomly picked in B. The complexity of the update of the RNS bases A, B and
the update of the Montgomery representation are sightly larger compared to the
approach of Section 4, but the memory requirement is reduced and the number
of moduli is also reduced.
In Table 3 we report the complexity of the randomization in the Montgomery-
ladder exponentiation for the two following cases:
1. Only one modulus is modiﬁed in the basis A. In this case, for each loop turn,
the proposed approach in Section 4 and Appendix A requires an update of
the constant and an update of r0 and r1 as shown in Algorithm 5.
2. s moduli are modiﬁed in A. At each loop turn, we perform s consecutive
updates of the RNS bases A, A′ and the data following the strategy of
Section 4: this requires s updates of the constants and s updates of r0 and
r1. In this case, since an update of ri multiply by 4 (cf. Lemma 2) at the
end of the s the two data r0 and r1 are multiplied by 4s. This requires to
expand the three bases A, A′ and B with an additional modulus assuming
that 2 × 42s < 2w in order to prevent an overﬂow in Algorithm 5. The
resulting complexity of this randomization is given in Table 3.
For comparison purpose we provide in Table 3 the complexity when the
randomization of [1] is performed at each loop turn in a Montgomery ladder.
The complexity can be easily deduced from the complexity results of Section 3.
The above complexities show that we get a cheaper randomization by chang-
ing only one modulus, at a cost of a lower level of randomization. We can increase
this level by changing more than one modulus at each loop turn, resulting in a
trade-oﬀbetween randomization and complexity. For the average randomization
of s = t/2 moduli changed per loop turn, our method requires 6t2+O(t) multipli-
cations and 2t2 + 3t additions: this is better than the complexity of [1]. Another
advantage of our technique is that it works in the cox-rower architecture [7]
which is the most popular architecture for RNS implementation.
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
121
Table 3. Cost of the randomization in one loop iteration of randomized Montgomery-
ladder
Randomization
Method
# Mul.
# Add.
Memory
1 modulus per loop
Section 4
18t + 10
4t + 2
8t2 + 24t + 18
1 modulus per loop Appendix A
24t + 26
4t + 4
8t2 + 19t + 20
s moduli per loop
s× Section 4 s(12t + 20) + 6t + 8
s(4t + 6)
8t2 + 42t + 52
t/2 moduli per loop
[1]
8t2 + 32t
8t2 + 12t −4
8t2
(in average)
Acknowledgments. This work was partly supported by PAVOIS ANR 12 BS02 002
02. Part of this work was initiated when G. Perin was doing his PhD thesis at the
LIRMM.
References
1. Bajard, J.-C., Imbert, L., Liardet, P.-Y., Teglia, Y.: Leak resistant arithmetic.
In: Joye, M., Quisquater, J.-J. (eds.) CHES 2004. LNCS, vol. 3156, pp. 62–75.
Springer, Heidelberg (2004)
2. Ciet, M., Joye, M.: (Virtually) free randomization techniques for elliptic curve
cryptography. In: Qing, S., Gollmann, D., Zhou, J. (eds.) ICICS 2003. LNCS, vol.
2836, pp. 348–359. Springer, Heidelberg (2003)
3. Clavier, C., Feix, B., Gagnerot, G., Roussellet, M., Verneuil, V.: Horizontal corre-
lation analysis on exponentiation. In: Soriano, M., Qing, S., L´opez, J. (eds.) ICICS
2010. LNCS, vol. 6476, pp. 46–61. Springer, Heidelberg (2010)
4. Coron, J.-S.: Resistance against diﬀerential power analysis for elliptic curve cryp-
tosystems. In: Ko¸c, C¸.K., Paar, C. (eds.) CHES 1999. LNCS, vol. 1717, pp. 292–302.
Springer, Heidelberg (1999)
5. Garner, H.L.: The Residue Number System. IRE Trans. on Elctronic Computers
8, 140–147 (1959)
6. Joye, M., Yen, S.-M.: The Montgomery Powering Ladder. In: Kaliski, B.S., Ko¸c,
K., Paar, C. (eds.) Cryptographic Hardware and Embedded Systems - CHES 2002.
LNCS, vol. 2523, pp. 291–302. Springer, Heidelberg (2003)
7. Kawamura, S., Koike, M., Sano, F., Shimbo, A.: Cox-rower architecture for fast par-
allel montgomery multiplication. In: Preneel, B. (ed.) EUROCRYPT 2000. LNCS,
vol. 1807, pp. 523–538. Springer, Heidelberg (2000)
8. Kocher, P.C., Jaﬀe, J., Jun, B.: Diﬀerential power analysis. In: Wiener, M. (ed.)
CRYPTO 1999. LNCS, vol. 1666, pp. 388–397. Springer, Heidelberg (1999)
9. Montgomery, P.: Modular Multiplication Without Trial Division. Math. Compu-
tation, 519–521 (1985)
10. Perin, G., Imbert, L., Torres, L., Maurine, P.: Attacking randomized exponentia-
tions using unsupervised learning. In: Prouﬀ, E. (ed.) COSADE 2014. LNCS, vol.
8622, pp. 144–160. Springer, Heidelberg (2014)
11. Posch, K.C., Posch, R.: Modulo Reduction in Residue Number Systems. IEEE
Trans. Parallel Distrib. Syst. 6(5), 449–454 (1995)
12. Rivest, R.L., Shamir, A., Adleman, L.: A Method for Obtaining Digital Signatures
and Public-Key Cryptosystems. Communications of the ACM 21, 120–126 (1978)

122
C. Negre and G. Perin
13. Walter, C.D.: Sliding windows succumbs to big mac attack. In: Ko¸c, C¸.K., Nac-
cache, D., Paar, C. (eds.) CHES 2001. LNCS, vol. 2162, pp. 286–299. Springer,
Heidelberg (2001)
A
Random Update of the Basis without a Set of Spare
Moduli
In this appendix we present a second approach for a low cost update of the RNS
basis A. We still want to modify the basis A by changing only one modulus.
But we do not use a set of spare moduli A′. The proposed approach exchanges a
random modulus picked in A with a random modulus picked in B. Additionally
to the two RNS bases A and B we will need an additional modulus c:
– A = {a1, . . . , at+1},
– B = {b1, . . . , bt+1},
– and an additional modulus {c}.
We use the following slightly modiﬁed version of the Basic-MM-RNS algorithm
(Algorithm 2):
Require: x, y in A ∪B
Ensure: xyA−1 mod N in A ∪{c} ∪B
[q]A ←[−xyN −1]A
BEA→B([q]A)
[z]B ←[(xy + qN)A−1]B
BEB→A∪{c}([z]B) // modiﬁed operation
return (zA∪B)
Only the last step is modiﬁed: we compute z in A ∪{c} instead of A. This can
be performed by modifying the last step of Algorithm 3 as follows
[z]A∪{c} ←[(
t

j=1
qbjb−1
j
−β)B]A∪{c}.
The random update of the bases A, {c} and B is performed as follows:
r ←random in {1, . . . , t + 1},
r′ ←random in {1, . . . , t + 1},
ar,new ←br′,old,
br′,new ←cold,
cnew ←ar,old.
(15)
Update of the Montgomery representation. The update of the bases A, {c}
and B requires also to update the representation of xold = xAold mod N given
in Aold ∪{cold} ∪Bold to the new value xnew = xAnew mod N in Anew ∪Bnew.
The following lemma establishes how to perform this update.
www.ebook3000.com

Trade-OﬀApproaches for Leak Resistant Modular Arithmetic in RNS
123
Lemma 4. We consider two RNS bases A and B and an additional modulus
{c} which are updated as speciﬁed in (15). We consider an integer x given by
its Montgomery representation xold = xAold mod N in Aold ∪{cold}∪Bold. We
obtain xnew by ﬁrst performing
xai,new ←xai,old, for i ̸= r,
xar,new ←xbr′,old,
xbi,new ←xbi,old, for i ̸= r′,
xbr′,new ←xc,old,
xc,new ←xar,old.
(16)
and then computes
λ = [−[xold]ar,old × N −1]ar,old,
xnew = [(xold + λ × N) × a−1
r,old × ar,new]Anew∪B.
(17)
Proof. The ﬁrst set of operations in (16) re-expresses xold in Anew ∪Bnew by
permuting the coeﬃcients of xold based on the update of the bases in (15). The
second set of operations (17) consists to ﬁrst compute s1 = xold + λN which
satisﬁes s1 ≡xold mod N and
[s1]ar,old = [xold + λ × N]ar,old
=

xold −[x]ar,old × N −1 × N

ar,old
= 0.
Then the operation ((xold + λN)/ar,old) × ar,new involves an exact division by
ar,old and a multiplication by ar,new and produces x × Anew modulo N. Since
ar,old is invertible in Anew ∪Bnew we replace the division by a multiplication
with the inverse a−1
r,old in Anew ∪Bnew and a multiplication by ar,new which leads
to (17).
■
Update of the constants. In order to apply the MM-RNS algorithm after
the update of the bases A ∪{c} ∪B and of [x]A∪B we need to also update the
constants involved in Algorithm 3. These constants are listed in (8), but we need
to consider also the following additional set of constants relative to the modulus
c:
[a−1
i ]c, [b−1
i ]c for i = 1, . . . , t + 1,
[c−1]ai, [c−1]bi for i = 1, . . . , t + 1,
[N]c, [N −1]c, [A]c, [A−1]c, [B]c, [B−1]c.
Moreover since a modulus in A is susceptible to become a modulus in B and
reciprocally, we need to also maintain the following constants:
[A]bi, [A−1]bi for i = 1, . . . , t + 1,
[B]ai, [B−1]ai for i = 1, . . . , t + 1.
The proposed updates of the constants are listed below:
• Constants N, N −1, a−1
i , b−1
i , c−1. The update of the constants only consists
in permutation, and does not require any computation.

124
C. Negre and G. Perin
• Constants A−1 and A−1
i . We update these constants as follows:
[A−1]Bnew ←[A−1
old × ar,old × a−1
r,new]Bnew,
[A−1]cnew ←[[A−1
r,old]ar,old × a−1
r,new]cnew( since cnew = ar,old),
[A−1
j ]aj ←[[A−1
j ]aj × a−1
r,new × ar,old]aj for j ̸= r,
[A−1
r ]ar,new ←[[A−1
old]br′,old × ar,old]ar,new( since br′,old = ar,new).
• Constants B and Bi. The updates work as follows:
[Bnew]ai ←[Bold × b−1
r′,old × br′,new]ai for i ̸= r,
[Bnew]ar,new ←[[Br′,old]br′,old × br′,new]ar,new( since ar,new = br′,old),
[Bnew]cnew ←[[Bold]ar,old × b−1
r′,old × br′,new]cnew( since cnew = ar,old),
[Bj,new]bj ←[[Bj]bj × b−1
r′,old × br′,new]bj for j ̸= r′,
[Br′,new]br′,new ←[[Bold]cold × b−1
r′,old]br′,new( since cold = br′,new).
• Constants B−1 and B−1
i
. We update these constants as follows:
[B−1
new]ai ←[B−1
old × br′,old × b−1
r′,new]ai, for i ̸= r
[B−1
new]ar,new ←[[B−1
r′,old]br′ × b−1
r′,new]ar,new, ( since ar,new = br′,old),
[B−1
new]cnew ←[[B−1
old]ar,old × br′,old × b−1
r′,new]cnew, ( since cnew = ar,old),
[B−1
j,new]bj ←[[B−1
j ]bj × br′,old × b−1
r′,new]bj, for j ̸= r′,
[B−1
r′,new]br′,new ←[[B−1
old]cold × br′,old]br′,new( since cold = br′,new).
The complexity of the update of the Montgomery representation (Lemma 4)
and the updates of the constants can be directly deduced from the above formu-
las. Theses complexities are given in the table below.
Operation
#Mult. #Add.
Updates of x
6t + 7
2t + 2
Updates of the constants 12t + 12
0
www.ebook3000.com

Identity-Based Encryption

Towards Forward Security Properties
for PEKS and IBE
Qiang Tang(B)
SnT, University of Luxembourg 6, rue Richard Coudenhove-Kalergi,
L-1359 Walferdange, Luxembourg
qiang.tang@uni.lu
Abstract. In cryptography, forward secrecy is a well-known property
for key agreement protocols. It ensures that a session key will remain
private even if one of the long-term secret keys is compromised in the
future. In this paper, we investigate some forward security properties
for Public-key Encryption with Keyword Search (PEKS) schemes, which
allow a client to store encrypted data and delegate search operations to
a server. The proposed properties guarantee that the client’s privacy is
protected to the maximum extent even if his private key is compromised
in the future. Motivated by the generic transformation from anonymous
Identity-Based Encryption (IBE) to PEKS, we correspondingly propose
some forward security properties for IBE, in which case we assume the
attacker learns the master secret key. We then study several existing
PEKS and IBE schemes, including a PEKS scheme by Nishioka, an
IBE scheme by Boneh, Raghunathan and Segev, and an IBE scheme
by Arriaga, Tang and Ryan. Our analysis indicates that the proposed
forward security properties can be achieved by some of these schemes if
the attacker is RO-non-adaptive (the attacker does not deﬁne its distri-
butions based on the random oracle). Finally, we propose the concept of
correlated-input indistinguishable hash function and show how to extend
the Boyen-Waters anonymous IBE scheme to achieve the forward secu-
rity properties against adaptive attackers.
1
Introduction
In the seminal work [8], Boneh et al. proposed the concept of Public-key Encryp-
tion with Keyword Search (PEKS) and formulated it as a cryptographic primi-
tive with four algorithms (KeyGen, Encrypt, TrapGen, Test). PEKS is a two-party
(i.e. client-server) primitive aiming at protecting a client’s, say Alice’s, privacy
in the following encrypted email routing scenario. Alice runs the KeyGen algo-
rithm to generate a key pair (PK, SK) and publishes PK. When any user, say
Bob, sends an email to Alice, he can generate a tag Encrypt(x, PK) for a key-
word x and attach it to the email (the email should be encrypted independently
and the detail is omitted here). In the view of the email server, it has a list of
emails indexed by Encrypt(x1, PK), Encrypt(x2, PK), · · · respectively. If Alice
wants to retrieve those emails indexed with a keyword y, she sends a trapdoor
TrapGen(y, SK) to the email server, which can then run an algorithm Test on the
input (TrapGen(y, SK), Encrypt(xi, PK)) for every i ≥1 to see whether y = xi.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 127–144, 2015.
DOI: 10.1007/978-3-319-19962-7 8
www.ebook3000.com

128
Q. Tang
1.1
Problem Statement
With a PEKS scheme implemented, the server receives a list of tags from message
senders and a list of trapdoors from the client. As a result of the desired search
functionality, the server can try to match any tag with any trapdoor. Therefore,
the server can categorize the possessed tags and trapdoors into three scenarios.
– Scenario 1: the tags, which do not match any trapdoor. The seminal work [8]
and all follow-ups have considered the privacy of keywords in this scenario.
It is worth noting that most of these papers only consider this property.
– Scenario 2: the tags and trapdoors, which match at least one trapdoor or
tag. In [9] and its full version [10], Boneh, Raghunathan and Segev deﬁned
(enhanced) function privacy properties for the keywords in this scenario. It is
worth noting that the property for PEKS is not explicitly deﬁned in [9,10],
but it is implied by their discussions (in fact, they use it to motivate the
property deﬁnitions for IBE).
– Scenario 3: the trapdoors, which do not match any tag. In [4], Arriaga,
Tang, and Ryan deﬁned search pattern privacy properties which captures
the privacy of keywords in this scenario.
It is clear that the above scenarios are mutually independent and their secu-
rity properties will not be comparable (as already indicated in [4]). As such, a
PEKS scheme should provide maximal protection for the keywords in all three
scenarios. Unfortunately, the security properties deﬁned in [4,9] are rather weak
and do not capture realistic threats. In the enhanced function privacy deﬁni-
tion from [9], there is a min-entropy restriction on the distribution of keywords.
It basically requires that if the keyword in a trapdoor TrapGen(yi, SK) is dif-
ferent from those in TrapGen(y1, SK), · · · , TrapGen(yi−1, SK), then it should
be infeasible to guess yi given y1, · · · , yi−1. This restriction seems artiﬁcial and
unrealistic. Taking the encrypted email routing scenario as an example, at a cer-
tain time period, the client may submit queries about a certain topic (e.g. work,
family, or friends) and the keywords in the trapdoors might be highly corre-
lated. This implies that, if some keywords are disclosed, it might be easy for the
attacker to infer others. In the search pattern privacy property deﬁnition from
[4], the distribution of keywords in the trapdoors is assumed to be uniform. This
restriction is clearly unrealistic. Taking the encrypted email routing scenario as
an example, it reasonable to expect the client to submit more queries with high-
priority keywords such as ”urgent” than low-priority ones such as ”ordinary”,
which implies that the keywords are not uniformly distributed.
Furthermore, it is possible that the client’s private key may get compromised
at some point. If this happens, the client may still want the privacy of keywords
in the tags and trapdoors to be preserved. This is similar to the forward secrecy
requirement in key agreement protocols [19,22]. However, no literature work has
touched upon this property for PEKS.

Towards Forward Security Properties for PEKS and IBE
129
1.2
Our Contribution
In this paper, we ﬁrst introduce two new forward security properties for PEKS.
One is forward-secure function privacy, which aims at protecting the privacy of
keywords in Scenario 2. The other is forward-secure trapdoor unlinkability, which
aims at protecting the privacy of keywords in Scenario 3. These two properties
are much stronger than those from [9] and [4], in the sense that we not only
allow the attacker to compromise the long-term secret key but also give it more
ﬂexibility to deﬁne the keyword distribution in the attack games. We analyse
a PEKS scheme by Nishioka [28] and show that it only achieves our properties
against RO-non-adaptive attackers (which can not choose the keyword distribu-
tions based on the random oracle).
We then introduce two new forward security properties for IBE, namely msk-
forward-secure function privacy and msk-forward-secure key unlinkability, and
they are augmented variants of those from [9] and [4] respectively. Naturally, the
new properties directly lead to those forward security properties for PEKS as a
result of the generic transformation proposed in [1]. We analyse the IBEDLIN2
scheme by Boneh et al. [10], and show that it does not achieve the msk-forward-
secure function privacy property. We also analyse an IBE scheme by Arriaga
et al. [4], and show that it achieves our properties against RO-non-adaptive
attackers. These msk-forward security properties are diﬀerent from the existing
forward security notions, see Section 7.
Finally, we introduce the concept of correlated-input indistinguishable hash
function, which can be regarded as an enhanced variant of the correlated-input
secure hash functions proposed by Goyal, O’Neil, and Rao [21]. By pre-processing
the identities with such a hash function, an IBE scheme automatically achieves
the msk-forward-secure function privacy property against adaptive attackers. In
contrast to the “extract-augment-combine” approach from [9], there is no need to
tweak the encryption and decryption algorithms of the underlying IBE scheme.
We then take Boyen-Waters anonymous IBE scheme [13] as an example, and
extend it with composite order bilinear groups to achieve msk-forward-secure
key unlinkability.
The proofs for lemmas and theorems appear in the report [32].
1.3
Organization
The rest of this paper is organized as follows. In Section 2, we present preliminar-
ies on notation and hardness assumptions. In Section 3, we present an enhanced
security model for PEKS with a focus on the forward security properties, and
analyse the Nishioka scheme. In Section 4, we propose some forward security
properties for IBE. In Section 5, we analyse an IBE scheme by Boneh et al.
and an IBE scheme by Arriaga et al.. In Section 6, we introduce the concept of
correlated-input indistinguishable hash function and extend the Boyen-Waters
scheme. In Section 7, we review some related work. In Section 8, we conclude
the paper.
www.ebook3000.com

130
Q. Tang
2
Preliminary
2.1
Notation
– x||y means the concatenation of x and y, P.P.T. stands for probabilistic
polynomial time.
– x
$←AO1,O2,···(m1, m2, · · · ) means that x is the output of the algorithm A
which runs with the input m1, m2, · · · and has access to oracles O1, O2, · · · .
– When X is a set, x
$←X means that x is chosen from X uniformly at
random, and |X| means the size of X. When D is a distribution on the set
X, x
D←X means that x is a value sampled from X according to D.
– We use bold letter, such as X, to denote a vector or matrix. Given a vector
X, we use X(i) to denote the i-th element in the vector. When g is a group
element, we use gX to denote a new vector or matrix, whose elements are
exponentiations of the corresponding elements in X. For two vectors (or
matrices) Y and Z whose elements are from a group, we use Y ⊗Z to
denote the new vector (or matrix) after pairwise group operations.
– A function P(λ) : Z →R is said to be negligible with respect to λ if, for
every polynomial f(λ), there exists an integer Nf such that P(λ) <
1
f(λ) for
all λ ≥Nf. When P(λ) is negligible, then we say 1 −P(λ) is overwhelming.
– A random variable V
has min-entropy λ, namely H∞(V )
=
λ, if
maxv Pr[V = v] = 2−λ, or equivalently λ = −log maxv Pr[V = v]. If V has
min-entropy at least λ, then V is a λ source. Given two random variables V
and W, the conditional min-entropy of V with respect to W is deﬁned to be
minw H∞(V |W = w), or equivalently −log maxv,w Pr[V = v|W = w].
2.2
Pairing Over Composite-Order Groups
A composite-order bilinear group generator is an algorithm GC
(pq) that takes as
input a security parameter λ and outputs Γ = (p, q, G, GT , ˆe, gp, gq) where:
– G and GT are groups of order n = pq, where p and q are primes, with
eﬃciently computable group laws.
– gp is a randomly-chosen generator of the subgroup Gp of order p, and gq is
a randomly-chosen generator of the subgroup Gq of order q.
– ˆe is an eﬃciently-computable bilinear pairing ˆe : G × G →GT , i.e., a map
satisfying the following properties for g ̸= 1 ∈G:
• Bilinearity: ˆe(ga, gb) = ˆe(g, g)ab for all a, b ∈Zpq;
• Non-degeneracy: ˆe(g, g) ̸= 1.
Instead of setting the order of G to be the product of two primes (i.e. pq), we
can set the order to be the product of multiple primes, e.g. [25,26,28]. In [28]
and recapped in Section 3.2, the generator GC
(pqw) generates G with the order
of three primes (i.e. pqw).

Towards Forward Security Properties for PEKS and IBE
131
Let Γ = (p, q, G, GT , ˆe, gp, gq) be the output by GC
(pq)(λ), and Γ ∗= (pq, G,
GT , ˆe, gp, gq). We say the Composite-DDH assumption [4] holds if, for every
P.P.T. attacker A, its advantage | Pr[b′ = b] −1
2| is negligible in the game,
deﬁned in Fig. 1.
1. Γ
=
(p, q, G, GT , ˆe, gp, gq)
$←
GC
(pq)(λ)
2. a1, a2, b1, b2, b3, r
$←Zpq
3. Γ ∗= (pq, G, GT , ˆe, gp, gq)
4. X0 = (Γ ∗, ga1
p ·gb1
q , ga2
p ·gb2
q , ga1a2
p
·
gb3
q )
X1 = (Γ ∗, ga1
p ·gb1
q , ga2
p ·gb2
q , gr
p·gb3
q )
5. b
$←{0, 1}
6. b′
$←A(Xb)
Fig. 1. Composite-DDH assumption
1. Γ = (p, q, G, GT , ˆe, gp, gq)
$←GC
(pq)(λ)
2. a1, a2, a3, b1, b2, b3, b4, r
$←Zpq
3. Γ ∗= (pq, G, GT , ˆe, gp, gq)
4. X0
=
(Γ ∗, ga1
p
· gb1
q , ga2
p
· gb2
q , ga1a3
p
·
gb3
q , ga2a3
p
· gb4
q )
X1 = (Γ ∗, ga1
p ·gb1
q , ga2
p ·gb2
q , ga1a3
p
·gb3
q , gr
p·
gb4
q )
5. b
$←{0, 1}
6. b′
$←A(Xb)
Fig. 2. Weak Composite-DDH assumption
We say the Weak Composite-DDH assumption holds if, for every P.P.T. attacker
A, its advantage | Pr[b′ = b] −1
2| is negligible in the game, deﬁned in Fig. 2.
Both assumptions are strictly weaker than the C3DH assumption by Boneh and
Waters [12] because the attacker is given strictly more information in the C3DH
attack game.
2.3
New Assumptions
In [15], Canetti proposed the DDH-II assumption which diﬀers from the standard
DDH assumption in that one exponent is chosen from a wide spread distribution
instead of a uniform one. Damg˚ard, Hazay and, Zottarel [18] showed that this
assumption holds in the generic group model, and stated that it is a useful tool
in leakage resilient cryptography.
Next, we introduce a new assumption for bilinear groups. The philosophy is
similar to the case of Composite-DDH: although it is trivial to solve DDH-
II problem in bilinear groups, adding an additional layer of randomization
makes it diﬃcult even with the help of the bilinear map. Formally, we say the
Composite-DDH-II assumption holds if, for every P.P.T. attacker A, its advan-
tage | Pr[b′ = b]−1
2| is negligible in the game, deﬁned in Fig. 3. In the game, the
distribution D from the attacker should guarantee that a1 has min-entropy not
smaller than λ, i.e. a1 is wide spread according to Canetti [15]. Further, we say
the Correlated Composite-DDH-II assumption holds if, for every P.P.T. attacker
A, its advantage | Pr[b′ = b] −1
2| is negligible in the game, deﬁned in Fig. 4. In
the game, the distribution D from the attacker should guarantee that ai for any
1 ≤i ≤L has min-entropy not smaller than λ. Compared to the Composite-
DDH-II assumption, on one hand the values ga1
p , · · · , gaL
p
are not given to the
attacker (not even in the randomized form), but on the other hand the attacker
is given multiple incomplete DH pairs.
www.ebook3000.com

132
Q. Tang
1. Γ = (p, q, G, GT , ˆe, g, gp, gq)
$←
GC
(pq)(λ)
2. Γ ∗= (pq, G, GT , ˆe, g, gp, gq)
3. D
$←A(Γ ∗)
4. a1
D←Zp
5. b1, s1, s2, s3, r
$←Zpq
6. X0
=
(Γ ∗, ga1
p
· gs1
q , gb1
p
·
gs2
q , ga1b1
p
· gs3
q )
X1 = (Γ ∗, ga1
p · gs1
q , gb1
p · gs2
q , gr
p ·
gs3
q )
7. b
$←{0, 1}
8. b′
$←A(Xb, D)
Fig. 3. Composite-DDH-II assump-
tion
1. Γ = (p, q, G, GT , ˆe, g, gp, gq)
$←GC
(pq)(λ)
2. Γ ∗= (pq, G, GT , ˆe, g, gp, gq)
3. D
$←A(Γ ∗)
4. (a1, · · · , aL)
D←ZL
p
5. b1, · · · bL, r1, · · · , rL, s1, · · · , sL,
t1, · · · , tL
$←Zpq
6. X0 = (Γ ∗, gb1
p
· gs1
q , ga1b1
p
· gt1
q , · · · , gbL
p
·
gsL
q , gaLbL
p
· gtL
q )
X1
=
(Γ ∗, gb1
p
· gs1
q , gr1
p
· gt1
q , · · · , gbL
p
·
gtL
q , grL
p
· gtL
q )
7. b
$←{0, 1}
8. b′
$←A(Xb, D)
Fig. 4. Correlated Composite-DDH-II assump-
tion
As to the two new assumptions, it is not clear how to reduce one to the other.
Nevertheless, we have the following lemma.
Lemma 1. Suppose any P.P.T. attacker has at most the advantage ϵ in the
Composite-DDH-II assumption. Then, any P.P.T. attacker has at most the
advantage L·ϵ in the Correlated Composite-DDH-II assumption in the following
two scenarios.
1. a1, a2, · · · , aL are independent according to D.
2. a1 = a2 = · · · = aL according to D.
3
Forward Security Properties for PEKS
A PEKS scheme involves a client, a server, and senders which can be any entity.
Let λ be the security parameter, a PEKS scheme has the following algorithms.
– KeyGen(λ): Run by the client, this probabilistic algorithm outputs a pub-
lic/private key pair (PK, SK), where PK should deﬁne a message space
W.
– Encrypt(x, PK): Run by a sender, this probabilistic algorithm outputs a
ciphertext (or, tag) Cx for a message (or, keyword) x ∈W.
– TrapGen(y, SK): Run by the client, this probabilistic algorithm generates a
trapdoor Ty for the message y ∈W.
– Test(Cx, Ty, PK): Run by the server, this deterministic algorithm returns 1
if x = y and 0 otherwise.
Boneh et al. [8] deﬁned ciphertext privacy property for PEKS, and Abdala
et al. [1] deﬁned computational consistency property. Next, we present the new
forward security properties.

Towards Forward Security Properties for PEKS and IBE
133
3.1
Forward Security Properties for PEKS
The forward-secure trapdoor unlinkability says that any P.P.T. attacker cannot
determine the links among trapdoors as long as the underlying keywords are
sampled according to distributions with min-entropy not smaller than λ. This
property is an augmented variant of the strong search pattern privacy property
from [4] in two aspects. (1) The attacker is given SK in the attack game, and
this brings in the forward security ﬂavor; (2) The attacker can adaptively specify
the keyword distributions based on the public parameters, while the challenger
samples the keywords uniformly from the keyword space in [4].
Deﬁnition 1. A PEKS scheme achieves forward-secure trapdoor unlinkability
if any P.P.T. attacker A’s advantage |Pr[b′ = b] −1
2| is negligible in the game
shown in Fig. 5. In the game, D0 is the joint distribution of L (dependent) λ-
source random variables, while D1 deﬁnes L independent random variables with
uniform distribution. Chosen by the attacker, the integer L is a polynomial in λ.
1. (PK, SK)
$←KeyGen(λ)
2. (D0, D1, L, state)
$←ATrapGen(PK)
3. b
$←{0, 1},
xb
Db
←WL,
T b =
TrapGen(xb, SK)
4. b′
$←A( SK , state, T b)
Fig. 5.
Forward-Secure
Trapdoor
Unlinkability
1. (PK, SK)
$←KeyGen(λ)
2. (D0, D1, L, state)
$←ATrapGen(PK)
3. b
$←
{0, 1},
xb
Db
←
WL,
T b
=
TrapGen(xb, SK), Cb = Encrypt(xb, PK)
4. b′
$←ATrapGen,Encrypt( SK , state, T b, Cb)
Fig. 6. Forward-Secure Function Privacy
We use TrapGen(xb, SK) to denote (TrapGen(x(1)
b , SK), · · · , TrapGen(x(L)
b
, SK))
in Fig. 5. Such notation is also used in Fig. 6 and deﬁnitions in Section 4.1.
The forward-secure function privacy property says that any P.P.T. attacker
cannot determine the links among (tag, trapdoor) pairs, as long as the under-
lying keywords are sampled according to distributions with min-entropy not
smaller than λ. This property is an augmented variant of the enhanced function
privacy property from [9] in two aspects. (1) The attacker is given SK in the
attack game, and this brings in the forward security ﬂavor; (2) We get rid of the
restriction in the enhanced function privacy property deﬁnition from [9], namely
the conditional min-entropy of x(i)
0
given x(1)
0 , · · · , x(i−1)
0
is required to be at
least λ, for all 2 ≤i ≤L.
Deﬁnition 2. A PEKS scheme achieves forward-secure function privacy if any
P.P.T. attacker A’s advantage |Pr[b′ = b] −1
2| is negligible in the game shown
in Fig. 6. In the game, D0 and D1 are deﬁned in the same way as in Deﬁnition
1, but with the following restriction: for x0 = (x(1)
0 , x(2)
0 , · · · , x(L)
0
)
D0
←WL and
any 1 ≤i ̸= j ≤L, the probability Pr[x(i)
0
= x(j)
0 ] is negligible.
In practice, the client may submit search queries for the same keyword mul-
tiple times. However, the ”Real-or-Random” deﬁnition approach does not allow
www.ebook3000.com

134
Q. Tang
us to straightforwardly capture this given that the attacker gets access to (tag,
trapdoor) pairs. If we allow the sampled keywords to be equal according to
D0, then an attacker can win the game trivially (by cross testing the trapdoors
and the ciphertexts) because D1 samples the keywords uniformly at random.
To bridge the gap, we give the attacker access to TrapGen and Encrypt oracles
in Step 4 of the above game, to capture the fact that the attacker can access
multiple trapdoors and tags for the same keywords. In a TrapGen oracle query,
the attacker has an index 1 ≤i ≤L as input and receives TrapGen(x(i)
b , SK).
In an Encrypt oracle query, the attacker has an index 1 ≤j ≤L as input and
receives Encrypt(x(j)
b , PK).
3.2
Analysis of Nishioka Scheme
In [28], Nishioka modeled trapdoor unlinkability for a very restricted setting:
the attacker is non-adaptive, the unlinkability is only for two trapdoors, and
the model seems to be selective since the challenge keywords are chosen before
the generation of other parameters (in the SPP experiment). We found a minor
inconsistency in the original Nishioka scheme (referred to as Instance 3 in [28]),
namely r1 is deﬁned to be r1
$←Zp for the TrapGen algorithm but p is not
included in the SK. There are two ways to get rid of this inconsistency. One is
to include p in SK. This will make the scheme fail to achieve the forward-secure
trapdoor unlinkability property even against RO-non-adaptive attackers. The
other is to set r1
$←Zpqw, and the scheme works in the same way as in the case
of r1
$←Zp. This leads to the description in Fig. 7.
KeyGen(λ)
TrapGen(y, SK)
(p, q, w, G, GT , ˆe, gp, gq, gw)
$←GC
(pqw)(λ)
r1
$←Zpqw
g†
q
$←Gq, g = gp · g†
q
g′
w, g′′
w
$←Gw
W = {0, 1}∗, H : {0, 1}∗→Gp
T1 = gr1
p · g′
w
PK = (pqw, G, GT , ˆe, gq, gw, g, W, H)
T2 = H(y)r1 · g′′
w
SK = (PK, gp)
Ty = (T1, T2)
Encrypt(x, PK)
Test(Cx, Ty, PK)
r2
$←Zpqw, g′
q, g′′
q
$←Gq
if ˆe(T1, C2) = ˆe(T2, C1), output 1
C1 = gr2 · g′
q, C2 = H(x)r2 · g′′
q , Cx = (C1, C2) otherwise, output 0
Fig. 7. Nishioka Scheme (with modiﬁcation)
In Deﬁnition 1 and 2, we assume the attacker to be fully adaptive in the
sense that it can choose the distribution D0 based on everything. An immediate
relaxation on these deﬁnitions is to make the attacker RO-non-adaptive, which
means that the attacker can choose the distribution D0 based on everything
except for the random oracle (i.e. the hash function). In practice, the keywords
in search queries might be related to the system parameters in some manner,

Towards Forward Security Properties for PEKS and IBE
135
but it is hard to imagine a scenario where the keywords would depend on the
behavior of a random function. Following Theorem 6.1 from [10], based on the
fact that the keywords are hashed in both the TrapGen and Encrypt algorithms,
the scheme trivially achieves the forward-secure function privacy property in
the random oracle model against RO-non-adaptive atatckers. However, it is not
trivial for the forward-secure trapdoor unlinkability property, due to the fact
that the attacker can let D0 output identical keywords and exploit this in the
attack. We have the following theorem.
Theorem 1. The scheme in Fig. 7 achieves the forward-secure trapdoor
unlinkability property against RO-non-adaptive attackers based on the Weak
Composite-DDH assumption in the random oracle model.
Note that the Weak Composite-DDH assumption deﬁned in Fig. 2 is for
bilinear composite-order group of the order pq, in the above theorem we assume
this assumption holds for any composite-order subgroup (i.e. Gpq, Gpwand Gqw)
of the bilinear group G with the order pqw.
4
IBE and Its Security Properties
An IBE scheme is speciﬁed by four algorithms (Setup, Extract, Enc, Dec), deﬁned
in Fig. 8. Let the message space be M and the identity space be I. The generic
transformation from IBE to PEKS, proposed in [1], works as in Fig. 9. Note that
the message space W of the resulted PEKS scheme is the public-key space I of
the IBE scheme.
1. (Msk, params)
=
Setup(λ)
2. skid = Extract(Msk, id)
3. C = Enc(m, id)
4. Dec(C, skid) = m or ⊥
Fig. 8. IBE
1.
KeyGen(λ) = Setup(λ)
2.
Encrypt(x, PK) = (m, Enc(m, x)), for m
$←M
3.
TrapGen(y, SK) = Extract(Msk, y)
4.
Test(Cx, Ty, PK) = 1iﬀm = Dec(Enc(m, x), Ty)
Fig. 9. Resulted PEKS
The standard IND-CPA and anonymity properties for IBE can be found in
[1], and we deﬁne two new forward security properties for IBE in the next subsec-
tion. Under our deﬁnitions, the generic transformation leads to the the following
property mapping. The reductions between properties are straightforward, so
that we skip them here.
PEKS Properties
IBE Properties
computational consistency
IND-CPA
ciphertext privacy
anonymity
forward-secure trapdoor unlinkability msk-forward-secure key unlinkability
forward-secure function privacy
msk-forward-secure function privacy
www.ebook3000.com

136
Q. Tang
4.1
Forward Security Properties of IBE
The following msk-forward-secure key unlinkability property says that any P.P.T.
attacker cannot determine the links among private keys if the underlying identi-
ties are sampled according to distributions with min-entropy not smaller than λ,
even with the knowledge of the master secret key. This property is an augmented
variant of the strong key unlinkability property from [4], where the augmenta-
tion lies in two aspects. (1) The attacker is given Msk in the attack game, and
this gives the forward security ﬂavor; (2) The attacker is allowed to adaptively
choose the identity distribution D0 based on the public parameters, while the
challenger samples the identities uniformly at random (according to certain pat-
terns deﬁned by the attacker) from the identity space in [4].
Deﬁnition 3. An IBE scheme achieves msk-forward-secure key unlinkability if
any P.P.T. attacker A’s advantage |Pr[b′ = b] −1
2| is negligible in the game
shown in Fig. 10. In the game, D0 is the joint distribution of L (dependent) λ-
source random variables, while D1 deﬁnes L independent random variables with
uniform distribution. Chosen by the attacker, the integer L is a polynomial in λ.
1. (Msk, params)
$←Setup(λ)
2. (D0, D1, L, state)
$←
AExtract(params)
3. b
$←{0, 1},
idb
Db
←IL,
skb =
Extract(Msk, idb)
4. b′
$←A( Msk , state, skb)
Fig. 10.
msk-Forward-Secure
Key
Unlinkability
1. (PK, SK)
$←Setup(λ)
2. (D0, D1, L, state)
$←AExtract(params)
3. b
$←
{0, 1},
idb
Db
←
IL,
skb
=
Extract(Msk, idb),
mb
$←ML, Cb = Enc(mb, idb)
4. b′
$←AExtract,Enc( Msk , state, skb, Cb)
Fig. 11.
msk-Forward-Secure
Function
Privacy
The following msk-forward-secure function privacy property says that any
P.P.T. attacker cannot determine the links among (private key, ciphertext) pairs
if the underlying identities are sampled according to distributions with min-
entropy not smaller than λ, even with the knowledge of the master secret key.
This property is an augmented variant of the enhanced function privacy property
from [9], where the augmentation lies in two aspects. (1) The attacker is given
Msk in the attack game, and this gives the forward security ﬂavor; (2) We get rid
of this restriction in the enhanced function privacy property deﬁnition from [9],
namely the conditional min-entropy of id(i)
0
given id(1)
0 , · · · , id(i−1)
0
is required
to be at least λ, for all 2 ≤i ≤L.
Deﬁnition 4. An IBE scheme achieves msk-forward-secure function privacy if
any P.P.T. attacker A’s advantage |Pr[b′ = b]−1
2| is negligible in the game shown
in Fig. 11. In the game, D0 and D1 are deﬁned in the same way as in Deﬁnition
3, but with the following restriction: for id0 = (id(1)
0 , id(2)
0 , · · · , id(L)
0
)
D0
←IL and
any 1 ≤i ̸= j ≤L, the probability Pr[id(i)
0
= id(j)
0 ] is negligible.

Towards Forward Security Properties for PEKS and IBE
137
We use Enc(mb, idb) to denote (Enc(m(1)
b , id(1)
b ), · · · , Enc(m(L)
b
, idb)(L)) for
the simplicity of notation. Similar to the deﬁnition of forward-secure function
privacy for PEKS (i.e. Deﬁnition 2), the attacker is given access to the Extract
and Enc oracles in Step 4 of the above game. In an Extract oracle query, the
attacker has an index 1 ≤i ≤L as input and receives Extract(Msk, id(i)
b ).
In an Enc oracle the attacker has an index 1 ≤j ≤L as input and receives
Enc(m, id(j)
b ) for m
$←M.
5
Analysis of Two Existing IBE Schemes
In this section, we analyse an IBE scheme by Boneh et al. [10] and an IBE
scheme by Arriaga et al. [4] in our security model.
Setup(λ)
Extract(Msk, id)
Γ = (G, GT , ˆe, g, p) = GP(λ)
id = (id1, id2, · · · , idn) ∈{0, 1}n
A0, B, A1, · · · , An
$←Z2×m
p
S
$←Zm×2
p
u
$←Z2
p, M = GT , I = {0, 1}n
F id,S = [A0|BS + (

1≤j≤n
idjAj)S]
Msk = (A0, B, A1, · · · , An, u)
v
$←{x | F id,S · x = u (mod p)}
params = (Γ, gA0, B, gA1, · · · , gAn, gu,
z = gv ∈Gm+2, skid = (S, z)
M, I)
Enc(m, id)
Dec(C, skid)
id = (id1, id2, · · · , idn) ∈{0, 1}n, m ∈GT dT = [c0
T |(c1
T )S] = grT F id,S
D(id) =

1≤j≤n
idjAj, r
$←Z2
p
ˆe(d, z) = ˆe(g, g)rT (F id,S·v) = ˆe(g, g)rT u
c0
T = grT A0, c1
T = grT [B+D(id)]
m = c2 · ˆe(d, z)−1
c2 = m · ˆe(g, g)rT u, C = (c0, c1, c2)
Fig. 12. Boneh-Raghunathan-Segev IBEDLIN2 Scheme
5.1
Boneh-Raghunathan-Segev IBEDLIN2 Scheme
According to their deﬁnitions, the IBEDLIN2 scheme achieves enhanced function
privacy based on the DLIN assumption (see deﬁnition in [10]) in the standard
model. Next, we show that this scheme does not achieve msk-forward-secure
function privacy, namely an attacker wins the attack game in Fig. 11 with over-
whelming probability. Note that this does not conﬂict with the claims from [10]
because our security model is stronger. The following attack makes use of the
fact that, with Msk, the attacker can transform a ciphertext under an identity
id into a ciphertext under another identity id′, for some carefully chosen id and
id′. In an attack, in step 2 and 4 of the game, the attacker performs as follows.
– In step 2, the attacker sets L = 2, which means D0 and D1 are the joint
distribution of two identity variables. The attacker deﬁnes D0 as follows:
www.ebook3000.com

138
Q. Tang
id(1)
0
= (id1, id2, · · · , idn) is deﬁned as (id1, id2, · · · , idn−1)
$←{0, 1}n−1 and
idn = 0; id(2)
0
equals id(1)
0
except its idn = 1.
– In step 4, the attacker ﬁrstly obtains Msk = (A0, B, A1, · · · , An, u). Then,
the attacker computes X ∈Zm×m
p
such that An = A0X. Recall that the
challenge is (skb, Cb). The ﬁrst ciphertext in Cb, namely C(1)
b
= (c0, c1, c2),
is in the following form: c0T = grT A0, c1T = grT [B+D(id(1)
b
)], c2 = m ·
ˆe(g, g)rT u. The attacker has a new ciphertext C′ = (c0, c′
1, c2), where
c′
1
T = c1
T ⊗(c0
T )X = grT [B+D(id(1)
b
)] ⊗grT A0X = grT [B+D(id(1)
b
)] ⊗grT An
Let the secret keys in the challenge skb be denoted as (skid(1)
b , skid(2)
b ). The
attacker outputs 0 if Dec(C′, skid(2)
b ) = Dec(C(1)
b , skid(1)
b ), and outputs 1
otherwise.
Recall that, ⊗is an operator for pairwise group operations between two the new
vectors or matrices. It is clear that if b = 0 then we have c′
1
T = grT [B+D(id(2)
b
)]
and the equality Dec(C(1)
b , skid(1)
b ) = Dec(C′, skid(2)
b ) holds. But, this equality
holds with a negligible probability if b = 1. As a result, our attack works.
5.2
Arriaga-Tang-Ryan IBE Scheme
The following scheme (in Fig. 13) was proposed by Arriaga et al. [4], based on an
anonymous IBE scheme by Boyen and Waters [13]. This scheme has been proven
secure with respect to the strong key unlinkability property (under the deﬁnition
in [4]) in the random oracle model. Compared with our msk-forward-secure key
unlinkability property, their deﬁnition is weaker in three aspects: (1) the attacker
is not allowed to adaptively choose the identity distribution D0 and it can only
specify the identity patterns (i.e. which identities are equal); (2) according to
the patterns, the challenger samples the identities uniformly at random from the
identity space; (3) there is no forward security.
Similar to the discussions in Section 3.2, an immediate relaxation on Deﬁ-
nition 3 and 4 is to make the attacker RO-non-adaptive, which means that the
attacker can choose the distribution D0 based on everything except for the ran-
dom oracle (i.e. the hash function). Following Theorem 6.1 from [10], it is trivial
to show that the scheme achieves msk-forward-secure function privacy property
in the random oracle model. However, it is non-trivial for the msk-forward-secure
key unlinkability property. We have the following theorem. Note that this result
is stronger than Lemma 3 from [4] based on a weaker assumption.
Theorem 2. The scheme achieves the msk-forward-secure key unlinkability
property against RO-non-adaptive attackers based on the Weak Composite-DDH
assumption in the random oracle model.

Towards Forward Security Properties for PEKS and IBE
139
Setup(λ)
Extract(Msk, id)
Γ = (p, q, G, GT , ˆe, g, gp, gq) = GC(λ)
r
$←Zn
Γ ∗= (n = pq, G, GT , ˆe, g, gp, gq)
x0, x1, x2
$←Gq
x, t1, t2
$←Zn
d0 = x0 · grt1t2
p
Ω = ˆe(gp, gp)xt1t2, v1 = gt1
p , v2 = gt2
p
d1 = x1 · g−xt2
p
· H(id)−rt2
M = GT , I = {0, 1}∗, H : {0, 1}∗→Gp
d2 = x2 · g−xt1
p
· H(id)−rt1
Msk = (x, t1, t2), params = (Γ ∗, Ω, v1, v2, M, I, H) skid = (d0, d1, d2)
Enc(m, id)
Dec(C, skid)
s, s1
$←Zn
e0 = ˆe(c0, d0), e1 = ˆe(c1, d1)
ˆc = Ωsm, c0 = H(id)s, c1 = vs−s1
1
, and c2 = vs1
2
e2 = ˆe(c2, d2),
C = (ˆc, c0, c1, c2)
m = ˆc · e0 · e1 · e2
Fig. 13. Arriaga-Tang-Ryan IBE Scheme
6
msk-Forward-Secure IBE Construction
The “extract-combine-augment” concept from [9] is an elegant idea, but it has
two drawbacks. One is that it introduces the unrealistic conditional min-entropy
restriction on identity distribution when deﬁning enhanced function privacy. The
other is that it requires speciﬁc modiﬁcations to both encryption and decryption
algorithms of the underlying IBE scheme. Such modiﬁcations may not be an easy
task. Moreover, it may introduce good algebraic structures into the ciphertexts.
This partially makes it possible for us to show that the IBEDLIN2 scheme does
not achieve msk-forward-secure function privacy in Section 5.1.
In the following, we ﬁrst introduce the concept of correlated-input indis-
tinguishable hash function, which serves as a building block to pre-process
identities for any IBE scheme. Similar to the “extract” step in the “extract-
combine-augment” approach, such a hash function aims at eliminating the cor-
relations among diﬀerent inputs so that msk-forward-secure function privacy can
be straightforwardly achieved. The advantage is that there is no need to modify
the underlying IBE algorithms. We then take the Boyen-Waters scheme [13] as
an example to show how to make it msk-forward-secure.
6.1
Correlated-Input Indistinguishable Hash Function
Goyal et al. [21] introduced the concept of correlated-input secure hash func-
tions and gave a few security deﬁnitions and instantiations. Unfortunately, their
security property deﬁnitions are selective and assume certain speciﬁc correla-
tions among the inputs (i.e. the inputs are related by polynomials over the input
space). Such restrictions conﬂict with our needs, because we want the inputs to
be arbitrarily correlated and full security. Moreover, we want a property which
is subtly diﬀerent from correlated-input pseudorandomness. Very informally, the
pseudorandomness property guarantees that the outputs of a hash function look
random with respect to correlated inputs, while our desired property is supposed
to guarantee that the outputs of a hash function look the same with respect to
www.ebook3000.com

140
Q. Tang
correlated inputs and random inputs. It seems that our property is weaker than
a pseudorandomness property with full security and arbitrary input correlations.
We leave the details for future work. Formally, we deﬁne the new property as
follows.
Deﬁnition 5. A hash function H : X →Y is correlated-input indistinguishable
if the attacker’s advantage | Pr[b′ = b]−1
2| is negligible in the attack game, shown
in Fig. 14. In the game, D0 is the joint distributions of L (dependent) λ-source
random variables over X, while D1 deﬁnes L independent random variables with
uniform distribution over X. It is required that, for (x(1)
0 , x(2)
0 , · · · , x(L)
0
)
D0
←X L
and any 1 ≤i ̸= j ≤L, the probability Pr[x(i)
0
= x(j)
0 ] is negligible. L can be a
polynomial of the security parameter.
1. (D0, D1, L, state)
$←A(H)
2. b
$←{0, 1}, xb
Db
←X L, yb = (H(x(1)
b ), · · · , H(x(L)
b
))
3. b′
$←A(state, yb)
Fig. 14. Correlated-Input Indistinguishability
Due to the diﬀerent security objectives, it is easy to verify that the con-
struction from [21] is not correlated-input indistinguishable. Bellare, Hoang,
and Keelveedhi [6] introduced the concept of Universal Computational Extrac-
tors(UCEs) and showed how to use this concept to construct selective correlated-
input secure hash functions according to the deﬁnitions from [21]. However,
they noted that UCEs do not guarantee adaptive/full security. It seems diﬃcult
to construct correlated-input indistinguishable hash functions based on UCEs.
Unseeded deterministic extractors also seem to be a related primitive, but the
existing security models do not take into account correlated inputs.
On the positive side, we can instantiate correlated-input indistinguishable
hash function based on deterministic encryption (DE) schemes, a primitive pro-
posed in [5]. More speciﬁcally, the instantiation should be based on adaptively
secure DE schemes, e.g. that from [29]. In a nutshell, an adaptively secure DE
scheme guarantees that an attacker cannot distinguish the ciphertexts of arbi-
trarily correlated plaintexts and random plaintexts. The instantiation has two
steps: (1) given an input from domain X, encrypt it with the DE scheme to
obtain a ciphertext; (2) hash the ciphertext with a collision-resistant hash func-
tion to get an output for the domain Y.
6.2
Example msk-Forward-Secure IBE Construction
With a correlated-input indistinguishable hash function H, we describe an
extended variant for the Boyen-Waters scheme [13] in Fig. 15. The extension
is from two aspects: (1) pre-processing identities with H; (2) employ composite-
order bilinear groups.

Towards Forward Security Properties for PEKS and IBE
141
Setup(λ)
Extract(Msk, id)
Γ = (p, q, G, GT , ˆe, gp, gq) = GC(λ)
r1, r2
$←Zn,
Γ ∗= (n = pq, G, GT , ˆe, gp, gq)
x0, x1, x2, x3, x4
$←Gq
x, t1, t2, t3, t4
$←Zn
d0 = x0 · gr1t1t2+r2t3t4
p
Ω = ˆe(gp, gp)xt1t2, g0, g1
$←Gp
d1 = x1 · g−xt2
p
· (g0gH(id)
1
)−r1t2
v1 = gt1
p , v2 = gt2
p , v3 = gt3
p , v4 = gt4
p
d2 = x2 · g−xt1
p
· (g0gH(id)
1
)−r1t1
M = GT , I = Zn, H : I →I
d3 = x3 · (g0gH(id)
1
)−r2t4
Msk = (x, t1, t2, t3, t4)
d4 = x4 · (g0gH(id)
1
)−r2t3
params = (Γ ∗, g0, g1, Ω, v1, v2, v3, v4, M, I, H) skid = (d0, d1, d2, d3, d4)
Enc(m, id)
Dec(C, skid)
s, s1, s2
$←Zn
e0 = ˆe(c0, d0), e1 = ˆe(c1, d1)
ˆc = Ωsm, c0 = (g0gH(id)
1
)s, c1 = vs−s1
1
e2 = ˆe(c2, d2),e3 = ˆe(c3, d3)
c2 = vs1
2 , c3 = vs−s2
3
, c4 = vs2
4
e4 = ˆe(c4, d4)
C = (ˆc, c0, c1, c2, c3, c4)
m = ˆc · e0 · e1 · e2 · e3 · e4
Fig. 15. Extended Boyen-Waters Scheme
If H is correlated-input indistinguishable and collision-resistant, it is straight-
forward to verify that the extended scheme is IND-CPA, anonymous, and
achieves msk-forward-secure function privacy. Next, we prove the scheme also
achieves msk-forward-secure key unlinkability.
Theorem 3. The extended Boyen-Waters scheme achieves msk-forward-secure
key unlinkability based on the correlated Composite-DDH-II assumption, given
that H is correlated-input indistinguishable and collision-resistant.
7
Related Work
In the seminal deﬁnition [8], PEKS only supports equality testing of keywords. To
support more types of search queries, a number of extensions have been proposed.
Among them, [12,23,24] support search queries with conjunctive keywords, [12,
31] support subset and range queries, and [25] supports disjunctions, polynomial
equations, and inner products. In contrast to the large number of follow-up works
to extend the PEKS functionality, very little has been done to investigate its full
security capabilities and the only few we know are [4,9,10,28,30], where [30]
only aims at a designated tester.
Forward secrecy is a well-known property for key agreement protocols [19,22],
and it ensures that a session key will remain secure even if one of the long-term
secret keys is compromised in the future. This concept has also been applied to
other primitives, such as signature schemes [3,7] and hierarchical identity based
encryption (HIBE) schemes [16,27,33]. It is worth noting that the adapted for-
ward secrecy notions in [3,7,16,27,33] focus on the key evolution problem. In the
case of HIBE schemes [16,27,33], the focus is on the secret keys for certain identi-
ties instead of the master secret key. The forward security properties, introduced
www.ebook3000.com

142
Q. Tang
in Section 4, stem from [19,22], and diﬀers from that [16,27,33] in two aspects:
the attacker has access to the master secret key and no key evolution is consid-
ered. For identity-based cryptography, how to avoid the key escrow problem has
been an interesting question, see e.g. [2,20]. Among all, a particularly interesting
security notion is the anonymous ciphertext indistinguishability (ACI) property
from [17]. The ACI property guarantees that an attacker cannot determine the
public key (or, identity) behind a ciphertext even with the knowledge of the
master secret key. It is related to the enhanced function privacy property from
[9], but they are not comparable.
8
Concluding Remarks
In this paper, we have deﬁned some forward security properties for PEKS and
IBE respectively. We have also analyzed several existing PEKS and IBE schemes,
and extended the Boyen-Waters anonymous IBE scheme by using a new build-
ing block (i.e. correlated-input indistinguishable hash function). Our analysis
shows that it is relatively easy to achieve our properties against RO-non-adaptive
attackers while it is quite hard to construct secure schemes against adaptive
attackers (in particular in the standard model). Our work has motivated many
interesting open problems. As to the concept of correlated-input indistinguish-
able hash function, we only know one method to instantiate it. It is a very
interesting task to construct correlated-input indistinguishable hash functions in
other ways, e.g. taking into account recent advances in constructing correlated-
input secure hash functions [14]. Moreover, it is also useful to investigate the
relationships between our deﬁnition and those in [21]. Both PEKS and IBE are
special types of functional encryption [11]. Hence, the concept of forward security
is also valuable for other functional encryption schemes, including other PEKS
variants and searchable encryption schemes in the symmetric-key setting.
Acknowledgments. The author is partially supported by a CORE grant from the
National Research Fund, Luxembourg. The author appreciates the valuable comments
from the ACISP reviewers and will address them in more details in the report [32].
References
1. Abdalla, M., Bellare, M., Catalano, D., Kiltz, E., Kohno, T., Lange, T., Malone-
Lee, J., Neven, G., Paillier, P., Shi, H.: Searchable encryption revisited: Consistency
properties, relation to anonymous ibe, and extensions. J. Cryptol. 21(3), 350–391
(2008)
2. Al-Riyami, S.S., Paterson, K.G.: Certiﬁcateless public key cryptography. In: Laih,
C.-S. (ed.) ASIACRYPT 2003. LNCS, vol. 2894, pp. 452–473. Springer, Heidelberg
(2003)
3. Anderson, R.: Two remarks on public key cryptology. Technical Report UCAM-
CL-TR-549. Cambridge University (1997)
4. Arriaga, A., Tang, Q., Ryan, P.: Trapdoor privacy in asymmetric searchable
encryption schemes. In: Pointcheval, D., Vergnaud, D. (eds.) AFRICACRYPT.
LNCS, vol. 8469, pp. 31–50. Springer, Heidelberg (2014)

Towards Forward Security Properties for PEKS and IBE
143
5. Bellare, M., Boldyreva, A., O’Neill, A.: Deterministic and eﬃciently searchable
encryption. In: Menezes, A. (ed.) CRYPTO 2007. LNCS, vol. 4622, pp. 535–552.
Springer, Heidelberg (2007)
6. Bellare, M., Hoang, V.T., Keelveedhi, S.: Instantiating random oracles via UCEs.
In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013, Part II. LNCS, vol. 8043, pp.
398–415. Springer, Heidelberg (2013)
7. Bellare, M., Miner, S.K.: A forward-secure digital signature scheme. In: Wiener, M.
(ed.) CRYPTO 1999. LNCS, vol. 1666, pp. 431–448. Springer, Heidelberg (1999)
8. Boneh, D., Di Crescenzo, G., Ostrovsky, R., Persiano, G.: Public key encryption
with keyword search. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004.
LNCS, vol. 3027, pp. 506–522. Springer, Heidelberg (2004)
9. Boneh, D., Raghunathan, A., Segev, G.: Function-private identity-based encryp-
tion: hiding the function in functional encryption. In: Canetti, R., Garay, J.A.
(eds.) CRYPTO 2013, Part II. LNCS, vol. 8043, pp. 461–478. Springer, Heidelberg
(2013)
10. Boneh, D., Raghunathan, A., Segev, G.: Function-private identity-based encryp-
tion: Hiding the function in functional encryption (2013). http://eprint.iacr.org/
2013/283.pdf
11. Boneh, D., Sahai, A., Waters, B.: Functional encryption: deﬁnitions and challenges.
In: Ishai, Y. (ed.) TCC 2011. LNCS, vol. 6597, pp. 253–273. Springer, Heidelberg
(2011)
12. Boneh, D., Waters, B.: Conjunctive, subset, and range queries on encrypted
data. In: Vadhan, S.P. (ed.) TCC 2007. LNCS, vol. 4392, pp. 535–554. Springer,
Heidelberg (2007)
13. Boyen, X., Waters, B.: Anonymous hierarchical identity-based encryption (without
random oracles). In: Dwork, C. (ed.) CRYPTO 2006. LNCS, vol. 4117, pp. 290–307.
Springer, Heidelberg (2006)
14. Brzuska, C., Mittelbach, A.: Using indistinguishability obfuscation via UCEs.
In: Sarkar, P., Iwata, T. (eds.) ASIACRYPT 2014, Part II. LNCS, vol. 8874,
pp. 122–141. Springer, Heidelberg (2014)
15. Canetti, R.: Towards realizing random oracles: hash functions that hide all par-
tial information. In: Kaliski Jr., B.S. (ed.) CRYPTO 1997. LNCS, vol. 1294,
pp. 455–469. Springer, Heidelberg (1997)
16. Canetti, R., Halevi, S., Katz, J.: A forward-secure public-key encryption scheme.
In: Biham, E. (ed.) Advances in Cryptology - EUROCRYPT 2003. LNCS,
vol. 2656, pp. 255–271. Springer, Heidelberg (2003)
17. Chow, S.S.M.: Removing escrow from identity-based encryption. In: Jarecki, S.,
Tsudik, G. (eds.) PKC 2009. LNCS, vol. 5443, pp. 256–276. Springer, Heidelberg
(2009)
18. Damg˚ard, I., Hazay, C., Zottarel, A.: Short paper on the generic hardness of DDH-
II, May, 2014. http://cs.au.dk/angela/Hardness.pdf
19. Diﬃe, W., Oorschot, P.C., Wiener, M.J.: Authentication and authenticated key
exchanges. Designs, Codes and Cryptography 2(2), 107–125 (1992)
20. Goyal, V.: Reducing trust in the PKG in identity based cryptosystems. In: Menezes,
A. (ed.) CRYPTO 2007. LNCS, vol. 4622, pp. 430–447. Springer, Heidelberg (2007)
21. Goyal, V., O’Neill, A., Rao, V.: Correlated-input secure hash functions. In: Ishai,
Y. (ed.) TCC 2011. LNCS, vol. 6597, pp. 182–200. Springer, Heidelberg (2011)
22. G¨unther, C.G.: An Identity-based key-exchange protocol. In: Quisquater, J.-J.,
Vandewalle, J. (eds.) EUROCRYPT 1989. LNCS, vol. 434, pp. 29–37. Springer,
Heidelberg (1990)
www.ebook3000.com

144
Q. Tang
23. Hwang, Y.-H., Lee, P.J.: Public key encryption with conjunctive keyword search
and its extension to a multi-user system. In: Takagi, T., Okamoto, T., Okamoto, E.,
Okamoto, T. (eds.) Pairing 2007. LNCS, vol. 4575, pp. 2–22. Springer, Heidelberg
(2007)
24. Iovino, V., Persiano, G.: Hidden-vector encryption with groups of prime order. In:
Galbraith, S.D., Paterson, K.G. (eds.) Pairing 2008. LNCS, vol. 5209, pp. 75–88.
Springer, Heidelberg (2008)
25. Katz, J., Sahai, A., Waters, B.: Predicate encryption supporting disjunctions, poly-
nomial equations, and inner products. In: Smart, N.P. (ed.) EUROCRYPT 2008.
LNCS, vol. 4965, pp. 146–162. Springer, Heidelberg (2008)
26. Lewko, A., Waters, B.: New techniques for dual system encryption and fully secure
HIBE with short ciphertexts. In: Micciancio, D. (ed.) TCC 2010. LNCS, vol. 5978,
pp. 455–479. Springer, Heidelberg (2010)
27. Gonz´alez Nieto, J.M., Manulis, M., Sun, D.: Forward-secure hierarchical predi-
cate encryption. In: Abdalla, M., Lange, T. (eds.) Pairing 2012. LNCS, vol. 7708,
pp. 83–101. Springer, Heidelberg (2013)
28. Nishioka, M.: Perfect keyword privacy in PEKS systems. In: Takagi, T., Wang,
G., Qin, Z., Jiang, S., Yu, Y. (eds.) ProvSec 2012. LNCS, vol. 7496, pp. 175–192.
Springer, Heidelberg (2012)
29. Raghunathan, A., Segev, G., Vadhan, S.: Deterministic public-key encryption for
adaptively chosen plaintext distributions. In: Johansson, T., Nguyen, P.Q. (eds.)
EUROCRYPT 2013. LNCS, vol. 7881, pp. 93–110. Springer, Heidelberg (2013)
30. Rhee, H.S., Park, J.H., Susilo, W., Lee, D.H.: Trapdoor security in a search-
able public-key encryption scheme with a designated tester. J. Syst. Softw. 83(5),
763–771 (2010)
31. Shi, E., Bethencourt, J., Chan, T-H.H., Song, D., Perrig, A.: Multi-dimensional
range query over encrypted data. In: Proceedings of the 2007 IEEE Symposium
on Security and Privacy, pp. 350–364. IEEE Computer Society (2007)
32. Tang, Q.: Towards forward security properties for peks and ibe. Cryptology ePrint
Archive: Report 2014/560 (2014)
33. Yao, D., Fazio, N., Dodis, Y., Lysyanskaya, A.: Id-based encryption for complex
hierarchies with applications to forward security and broadcast encryption. In:
Atluri, V., Pﬁtzmann, B., McDaniel, P.D. (eds.) Proceedings of the 11th ACM
Conference on Computer and Communications Security, CCS 2004, pp. 354–363.
ACM (2004)

IBE Under k-LIN with Shorter Ciphertexts
and Private Keys
Kaoru Kurosawa1 and Le Trieu Phong2(B)
1 Ibaraki University, Ibaraki, Japan
kurosawa@mx.ibaraki.ac.jp
2 NICT, Tokyo, Japan
phong@nict.go.jp
Abstract. Many identity-based encryption schemes under the k-LIN
assumption contain 2k + 1 group elements in the ciphertext overhead
and private keys. In this paper,
• We push the limit further by constructing an IBE scheme under the
k-LIN assumption with 2k group elements in the ciphertext overhead
and private keys.
• Our technique additionally expands to the scheme of Boneh, Raghu-
nathan, and Segev (CRYPTO 2013) to yield more eﬃcient function-
private IBE under the DLIN assumption.
The shortened size inherently leads to less exponentiations and pairings
in encryption and decryption, and hence yielding schemes with better
computational eﬃciency under k-LIN.
Keywords: Identity-based encryption · k-LIN assumption · Function
privacy
1
Introduction
1.1
Background
The k-LIN assumption is a gold mine for cryptographers. It is well known that
when k = 2, the assumption (aka, decision linear) generically holds even in bilin-
ear groups, enabling the usage of bi-linear maps in cryptographic constructions.
In general, the k-LIN assumption generically holds even when k-linear maps
exist.
We are interested in the use of k-LIN in identity-based encryption. In the
literature, the constructions using dual systems [12] in [7,10] need at least
2k + 2 group elements in the ciphertext overhead and private keys when in
prime-order groups. The construction in [9], not involving dual systems, also
requires 2k + 2 group elements. Recently, the work of [3] improves that limit to
2k + 1.
Function-private IBE (FP-IBE) [5] considers an additional tier of security
demanding the private key of each identity leaks no information on that identity
(to the extent possible). Under the 2-LIN assumption and in the standard model,
the work [5] builds a FP-IBE with 6 (namely 2k + 2 with k = 2) group elements
in the ciphertext overhead and private keys.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 145–159, 2015.
DOI: 10.1007/978-3-319-19962-7 9
www.ebook3000.com

146
K. Kurosawa and L.T. Phong
1.2
Our Contributions
In this paper, we show that the current barrier 2k + 1 set by [3] can be reduced
further. Speciﬁcally, we propose both IBE and FP-IBE schemes which have 2k
group elements in the ciphertext overhead and private keys, and 2k pairings
in decryption, under the k-LIN assumption in the standard model. Concrete
comparisons with previous works are postponed in Table 1 and Table 3.
Technical Outline. We start from the 2-LIN-based IBE scheme of [9], which
has the number 2k + 2 (with k = 2). The proof in [9] ensures the scheme has
semantic security, and additionally shows it is leakage-resilient. When consider-
ing semantic security only, we realize that both the scheme and the proof can be
changed so that the employing matrices can be of size k×k instead of k×(k+1)
as in [9]. Specifying a little deeper, we develop a neat way of using the matrix
of size k × (k + 1) from k-LIN instances in which only a k × k sub-matrix aﬀects
the size of ciphertexts and private keys, which is totally diﬀerent from the proof
in [9]. Therefore we obtain schemes under k-LIN with 2k group elements in the
ciphertext overhead and private keys, and 2k pairings in decryption.
Our technique of proving semantic security extends to the FP-IBE schemes
of [5], as it does not interfere with information-theoretic techniques [5] for proving
function privacy.
1.3
More Related Works
Bellare et al. [1, AppendixA] presented an IBE scheme under the 2-LIN assump-
tion and the decisional Bilinear Diﬃe-Hellman assumption (DBDH) with 4 group
elements in the ciphertext overhead and private keys. It is unclear and non-
trivial to extend this scheme to the k-LIN assumption since DBDH and k-LIN
are generically incompatible as soon as k > 2 [2].
2
Notations and Assumptions
Denote a
$←A as the process of taking element a randomly from a set A. Vectors
and matrices will be in boldface. Let Zm×n
q
be the matrices of size m×n over Zq.
Pairing Groups. Let q be a prime. We call PG = (G, GT , g, ˆe : G × G →GT )
a pairing group if G and GT are cyclic groups of order q. The element g is a
generator of G, and the mapping ˆe satisﬁes the following properties: ˆe(g, g) ̸= 1,
and ˆe(ga, gb) = ˆe(g, g)ab.
The k-LIN Assumption. For u1, . . . , uk
$←Zq, with following matrix and
vectors
Lk =
⎡
⎢⎢⎢⎣
u1 0 · · · 0 1
0 u2 · · · 0 1
...
...
...
...
0
0 · · · uk 1
⎤
⎥⎥⎥⎦∈Zk×(k+1)
q
, z
$←Z1×k
q
, r
$←Z1×(k+1)
q
(1)

IBE Under k-LIN with Shorter Ciphertexts and Private Keys
147
the k-LIN assumption asserts that tuples

gLk, gz·Lk	
and

gLk, gr	
are computationally indistinguishable. More precisely, for any poly-time distin-
guisher D, the advantage
Advk−LIN
PG
(D) =







Pr
⎡
⎢⎣b′ = b :
Lk as in (1), z
$←Z1×k
q
t0 = z · Lk ∈Z1×(k+1)
q
, t1
$←Z1×(k+1)
q
b
$←{0, 1}, b′ ←D(PG, gLk, gtb)
⎤
⎥⎦−1
2







is negligible under the k-LIN assumption. When k = 2, the 2-LIN assumption
becomes the decision linear assumption originated in [4].
A Remark. Escala et al. [8] generalized the k-LIN assumption to matrix Diﬃe-
Hellman assumptions, and examined their relations. In particular, they showed
that one can take u1 = · · · = uk in Lk without aﬀecting the generic hardness
of the assumption (newly called symmetric k-cascade assumption, or k-SCasc,
in [8]). In this paper context, under the k-SCasc assumption, the size of pub-
lic parameter in our schemes will be additionally reduced by k −1 elements
(compared to the k-LIN-based counterparts described in the following sections).
3
IBE and Security Deﬁnitions
IBE. The scheme consists of algorithms (Setup, Extract, Enc, Dec). Setup gen-
erates the public parameters and master key (pp, msk). The public parameter
pp is the input to all other algorithms. Extract, on input msk and an identity
id, returns the private key skid. Enc, on input id and a message m, returns a
ciphertext c, which will be decrypted by an identity holding skid, yielding m.
Deﬁnition 1 (IND-sID-CPA security). An IBE scheme is IND-sID-CPA
secure if any poly-time adversary succeeds in the following game with probability
negligibly close to 1/2.
1. Identity selection: the adversary decides and sends the target identities
id∗to the challenger. Then the challenger runs Setup to generate (msk, pp),
and sends pp to the adversary.
2. Query set 1: the adversary makes extract queries id ̸= id∗. The challenger
returns skid ←Extract(msk, id) to the adversary.
3. Challenge: the adversary gives equal-length m0, m1 to the challenger, who
computes and sends back c∗←Enc(id∗, mb) for b
$←{0, 1}.
4. Query set 2: the adversary issues additional extract queries id with id ̸= id∗
to which the challenger answers in the same manner as above.
5. Finish: Finally, the adversary outputs a bit b′ ∈{0, 1}. It succeeds if b′ = b.
www.ebook3000.com

148
K. Kurosawa and L.T. Phong
Table 1. Comparison of some fully secure IBE schemes
Scheme Size of ciphertext
Size
Main computation cost
Assum.
(C, E)
|skid|
in Enc
in Dec
[10]
6|G| + |GT |
6|G|
6 expG + 1 expGT
6 pr
2-LIN
[9]
6|G| + |GT |
6|G|
6 mexpG + 1 expGT
6 pr
2-LIN
[3]
(2k + 1)|G| + |GT | (2k + 1)|G| (2k + 1) mexpG + 1 expGT 2k + 1 pr k-LIN
Sect.4.2
2k|G| + |GT |
2k|G|
2k mexpG + 1 expGT
2k pr
k-LIN
The
identity
space
ID
=
{0, 1}n
where
n
≥
1.
Moreover,
(m)exp
=
(multi)exponentiation, pr = pairing. |G| and |GT | denote the number of bits to repre-
sent one element in those groups.
Deﬁnition 2 (IND-ID-CPA security). An IBE scheme is IND-ID-CPA
secure if any poly-time adversary succeeds in the following game with probability
negligibly close to 1/2.
1. Initially, the challenger runs Setup to generate (msk, pp), and sends pp to
the adversary.
2. Query set 1: the adversary makes extract queries id. The challenger gen-
erates and returns skid ←Extract(msk, id) to the adversary.
3. Identity selection: the adversary decides and sends the target identity id∗
to the challenger. It is required that id∗does not appear in extract queries
above.
4. Challenge: the adversary gives m0, m1 of equal length to the challenger,
who computes and sends back c∗←Enc(id∗, mb) for b
$←{0, 1}.
5. Query set 2: the adversary can ask more of extract queries id ̸= id∗.
6. Finish: Finally the adversary outputs a bit b′ ∈{0, 1}. It succeeds if b′ = b.
4
IBE Schemes Under k-LIN
We begin with a basic IBE scheme to illustrate the main ideas in Sect.4.1. Then
we show how to extend the basic one to a fully secure scheme in Sect.4.2, which
is used to compare with some previous schemes in Table 1. All schemes have
their own key encapsulation mechanism (identity-based KEM) versions in which
|GT | is not counted in the encapsulation size.
4.1
Basic Scheme: Selectively Secure IBE
Consider the matrix Lk at (1) and split it as follows
Lk =
⎡
⎢⎢⎢⎣
u1 0 · · · 0 1
0 u2 · · · 0 1
...
...
...
...
0
0 · · · uk 1
⎤
⎥⎥⎥⎦=

A0

k×k



 D

k×1

∈Zk×(k+1)
q
.
(2)
The IBE scheme is described below.

IBE Under k-LIN with Shorter Ciphertexts and Private Keys
149
– Setup: The public parameters are pp = (gA0, gA1, gD), where A0 ∈Zk×k
q
and
D ∈Zk×1
q
are as in (2) and A1
$←Zk×k
q
.
The master secret key is msk = (A0, A1). For an identity id ∈{0, 1}∗, let
F(id) = [A0|A1 + H(id) · Ik] ∈Zk×2k
q
where H : {0, 1}∗→Zq is a collision-resistant hash function and Ik is the
k × k identity matrix.
– Extract: On input id, return skid = gv where v ∈Z2k×1
q
is a random vector
such that
F(id) · v = D (mod q).
– Enc: On input id and M ∈GT , take z
$←Z1×k
q
and compute
C = gz·F(id), E = ˆe(g, g)z·D · M.
Return (C, E) as the ciphertext.
– Dec: On input skid = gv and C = gc, compute K = ˆe(g, g)c·v and M =
EK−1, using the bi-linearity of ˆe, and return M.
Theorem 1. Under the k-LIN assumption, the IBE scheme is IND-sID-CPA-
secure.
Proof. Let Game0 be the real attack game against the IBE scheme (recalled
in Sect.3). We will make small subsequent changes on the challenge ciphertext
depicted in Table 2.
Table 2. Changes of games in the proof of Theorem 1
Game
Challenge ciphertext
Notes
Game0 : C∗= gz∗F(id∗), E∗= ˆe(g, g)z∗D · Mb
z∗
$
←Z1×k
q
by the challenger
Game1 : C∗= gz∗F(id∗), E∗= ˆe(g, g)z∗F(id∗)v∗· Mb F(id∗)v∗= D ∈Zk×1
q
Game2 : C∗= gz∗F(id∗), E∗= R · Mb
R
$
←GT by the challenger
Note that
– The change from Game0 to Game1 is syntactical since F(id∗)v∗= D ∈
Zk×1
q
.
– The change from Game1 to Game2 is under the k-LIN assumption, proved
below. Moreover, the challenge bit b is completely hidden in Game2, so that
the theorem follows.
We now show that Game1 and Game2 are indistinguishable under the k-LIN
assumption, whose formulation using matrices is in Section 2. Given an adversary
A against the IBE scheme, we build B with input gLk (Lk as in (1)) and gt
telling whether t is random in Z1×(k+1)
q
or t = z∗· Lk for random z∗∈Z1×k
q
.
www.ebook3000.com

150
K. Kurosawa and L.T. Phong
After A announces the target identity id∗, B sets up the public parameter pp =
(gA0, gA1, gD) as follows. Firstly, set
[A0 | D] = Lk.
Then B chooses R∗
$←Zk×k
q
, and mentally sets
A1 = A0R∗−H(id∗)Ik
(3)
so that gA1 can be computed from gA0. Note that by the above,
F(id) = [A0|A0R∗+ (H(id) −H(id∗)Ik] and F(id∗) = [A0|A0R∗]
(4)
B then simulates A as follows.
• On extract query id ̸= id∗, B chooses w
$←Zk×1
q
and mentally considers
following
x = (H(id) −H(id∗))−1 · (D −A0w) ∈Zk×1
q
so that gx is computable from gA0, gD. Let
v =

w −R∗x
x

∈Z2k×1
q
(5)
and set skid = gv, which is the private key for identity id since
F(id) · v = [A0|A0R∗+ (H(id) −H(id∗))Ik] ·
w −R∗x
x

= A0(w −R∗x) + (A0R∗+ (H(id) −H(id∗))Ik)x
= A0w + (H(id) −H(id∗)) · x
= D ∈Zk×1
q
and v via the freedom of w comes from a subspace of dimension k, as
expected.
• On challenge query (M0, M1), take b
$←{0, 1}, and return
(C∗, E∗) =

g[(y1,...,yk)|(y1,...,yk)R∗], ˆe(g, g)yk+1Mb

(6)
where (y1, . . . , yk+1) = t ∈Z1×(k+1)
q
is from the input of B.
Finally, A outputs b′. If b′ = b, B bets that t = z∗Lk. Otherwise, it
guesses t is random. We will show that (C∗, E∗) is the ciphertext in Game1
if t = z∗Lk; while it is in Game2 if t is random. First suppose that t = z∗Lk,
namely (y1, . . . , yk+1) = z∗[A0|D] so that (y1, . . . , yk) = z∗A0 and yk+1 = z∗D.
Therefore
[(y1, . . . , yk)|(y1, . . . , yk)R∗] = [z∗A0|z∗A0R∗] = z∗[A0|A0R∗] = z∗F(id∗)
yk+1 = z∗F(id∗)v∗
showing that (C∗, E∗) is exactly the ciphertext in Game1.
Now suppose that t = (y1, . . . , yk+1) is random in Z1×(k+1)
q
which particularly
means that yk+1 is random independently of other elements. Set R = ˆe(g, g)yk+1,
then (C∗, E∗) is the ciphertext in Game2 as claimed.
⊓⊔

IBE Under k-LIN with Shorter Ciphertexts and Private Keys
151
4.2
Fully Secure Scheme Under DLIN
For an identity id expressed as a bit sequence id = (id1, . . . , idn), consider the
KEM in the previous section, yet employing the matrix
F(id) =

A0



A′
0 +
n

i=1
idiAi

∈Zk×2k
q
(7)
where A0 is as in (2), and A1, . . . , An, A′
0 ∈Zk×k
q
are random matrices employed
as the master secret key. In the public parameters, the matrices are given in the
exponents. Namely, for additional D as in (2),
pp = gA0, gA1, . . . , gAn, gA′
0, gD
msk = A0, A1, . . . , An, A′
0, D.
Theorem 2. Employing the above F(id), the IBE scheme in Section 4.1 is IND-
ID-CPA-secure under the DLIN assumption.
Proof. We consider identical games as in the proof of Theorem 1, in which func-
tion F(·) is replaced by (7). The only diﬀerence is in showing that Game1 and
Game2 are computationally indistinguishable under the k-LIN assumption from
the view of the adversary. Concretely, we construct simulator B against DLIN
as follows. B ﬁrst sets J = 4Q, where Q is the total number of extract queries of
the adversary. B chooses k
$←{0, . . . , n} and hi
$←ZJ for i = 0, 1, . . . , n. B then
constructs the matrices A′
0 and each Ai (excluding A0) as
A′
0 = A0R0 + (q −kJ + h0)Ik, Ai = A0Ri + hiIk (i ≥1)
(8)
where Ri ←Zk×k
q
, so that
F(id) =

A0



A0

R0 +
n

i=1
idiRi

+

q −kJ + h0 +
n

i=1
idihi

Ik

Let α(id) = q −kJ +h0 +n
i=1 idihi, so that B can succeed if α(id∗) = 0 mod q,
and for all extract query id ̸= id∗, α(id) ̸= 0 mod q. This probability λ is lower
bounded by λ ≥
1
(n+1)J

1 −2 Q
J

similarly to [11, Sect.5.2,eq.(1k)], which is
recapped in Appendix A for completeness. With probability λ, and id∗
i as the
bits of id∗,
F(id∗) =

A0



A0

R0 +
n

i=1
id∗
i Ri

,
so that the proof proceeds identically with that of Theorem 1 by letting
R∗= R0 +
n

i=1
id∗
i Ri.
www.ebook3000.com

152
K. Kurosawa and L.T. Phong
Moreover, algorithms B works as follows.
• The simulation of extract queries id: here we expect α(id) ̸= 0, and the
corresponding v is set to
v =
w −(R0 + n
i=1 idiRi)x
x

in which w ∈Zk×1
q
is random and x = α(id)−1 · (D −A0w) ∈Zk×1
q
. Thus
skid = gv can be computed and returned to the IBE’s adversary A.
• On challenge query id∗and (M0, M1), let y = (y1, y2) and b
$←{0, 1}, and
return
(C∗, E∗) =

g[(y1,...,yk)|(y1,...,yk)R∗], ˆe(g, g)yk+1Mb

where (y1, . . . , yk+1) = t ∈Z1×(k+1)
q
is from the k-LIN instance.
⊓⊔
5
Function-Private IBE Schemes
Function-private IBE provides an additional layer of security for IBE, requiring
that the private key skid unconditionally leaks no information on id. Boneh,
Raghunathan and Segev [5] proposed the concept and, among other construc-
tions, provided (selective and full) 2-LIN-based IBE schemes having function
privacy. Below we revisit their schemes and show that they can be made more
eﬃcient using our technique of exploiting the k-LIN assumption when k = 2.
Concrete comparisons are provided in Table 3.
Table 3. Comparison of 2-LIN-based, function-private IBE schemes
Scheme
Ciphertext
Private key
Public
Main computation cost in
Security
skid
parameter
Enc
Dec
[5, Sect.5.1] 3(ℓ+ 1)|G| + |GT | 6|G| + ℓ|Zq| 6ℓ|G| + 15|G| 3(ℓ+ 1) mexpG + 1 expGT 1 mexpG + 6 pr selective
Ours
2(ℓ+ 1)|G| + |GT | 4|G| + ℓ|Zq| 4ℓ|G| + 3|G| 2(ℓ+ 1) mexpG + 1 expGT 1 mexpG + 4 pr selective
[5, Sect.5.3]
6|G| + |GT |
5|G| + 6|Zq| 6n|G| + 15|G|
6 mexpG + 1 expGT
2 mexpG + 5 pr
full
Ours
4|G| + |GT |
4|G| + 4|Zq| 4n|G| + 7|G|
4 mexpG + 1 expGT
2 mexpG + 4 pr
full
In the selective schemes, the identity space ID = Zℓ
q where ℓ≥2 (to prove function
privacy), while in the full schemes ID = {0, 1}n where n ≥1. Moreover, (m)exp =
(multi)exponentiation, pr = pairing.
5.1
Our Function-Private, Selectively Secure IBE
– Setup: Fix ℓ≥2. The public parameters are
pp = (gA0, gD, gA1, . . . , gAℓ)
where the matrices are as follows
A0 =

u 0
0 v

∈Z2×2
q
, D =

1
1

∈Z2×1
q
, and A1, . . . , Aℓ
$←Z2×2
q
where u, v
$←Zq.

IBE Under k-LIN with Shorter Ciphertexts and Private Keys
153
The master secret key is msk = (A0, A1, . . . , Aℓ). For an identity id =
(id1, . . . , idℓ) ∈Zℓ
q, let
F(id, s1, . . . , sℓ) =

A0



ℓ

i=1
siAi +
ℓ

i=1
siidi · I2

∈Z2×4
q
– Extract: on input id
∈
Zℓ
q, take s1, . . . , sℓ
$←Zq, and return skid
=
(s1, . . . , sℓ, gv) where v ∈Z4×1
q
is a random vector such that
F(id, s1, . . . , sℓ) · v = D (mod q).
– Enc: on input id and M ∈GT , take z
$←Z1×2
q
and compute
C = gz·[A0|A1+id1I2|···|Aℓ+idℓI2], E = ˆe(g, g)z·D · M.
Return (C, E) as the ciphertext.
– Dec: On input skid = (s1, . . . , sℓ, gv) and C = g[c0|c1|···|cℓ], compute gc =
g[c0|s1c1+···+sℓcℓ] and K = ˆe(g, g)c·v using the bi-linearity of ˆe, and return
M = EK−1.
Correctness. Note that if c0 = zA0 and ci = z[Ai + idiI2] then c =
z[A0| ℓ
i=1 siAi + ℓ
i=1 siidi · I2] = zF(id, s1, . . . , sℓ), and the completeness
follows.
Intuition on Function Privacy. Recall that we need to show that skid leaks
no information on id. The bottom line here is that id needs to be unpredictable,
as discussed in [5]. Indeed, if an adversary can predict that id ∈S for a small
set S of identities, then it can fully recover id as follows: for a ﬁx message m, it
computes CT = Enc(id′, m) for all id′ ∈S and then uses skid for decryption; if
the decrypted message is m, it decides that id′ = id.
Now as id is assumed unpredictable, it has suﬃcient entropy. The function
F(id, s1, . . . , sℓ) contains Exts1...,sℓ(id1, . . . , idℓ) = ℓ
i=1 siidi which is a ran-
domness extractor, so the output is statistically close to uniform when id =
(id1, . . . , idℓ) has enough entropy by the left-over-hash lemma. As (s1, . . . , sℓ) is
independent of id, and F(id, s1, . . . , sℓ) contains almost no information on the
identity, so is the extracted secret skid. The formal proof will be identical to [5,
Fullversion,Lemma5.5].
Intuition on IND-sID-CPA Security. Mimicking (3), for challenge identity
id∗= (id1, . . . , idℓ) ∈Zℓ
q, set
Ai = A0R∗
i −id∗
i I2
(9)
where R∗
i
$←Z2×2
q
, 1 ≤i ≤ℓ, so that
F(id, s1, . . . , sℓ) =

A0



ℓ

i=1
si (A0R∗
i −id∗
i I2) +
ℓ

i=1
siidi · I2

=

A0



A0
ℓ

i=1
siR∗
i +
ℓ

i=1
si(idi −id∗
i ) · I2

www.ebook3000.com

154
K. Kurosawa and L.T. Phong
which is similar to (4) when putting R = ℓ
i=1 siR∗
i , which enables the simula-
tion of extract queries id ̸= id∗as in (5). Moreover,
C∗= gz∗·[A0|A1+id∗
1I2|···|Aℓ+id∗
ℓI2] = gz∗·[A0|A0R∗
1|···|A0R∗
ℓ]
so that the challenge ciphertext can be simulated as in (6).
Theorem 3. The above scheme is IND-sID-CPA-secure under the 2-LIN
assumption.
Proof. Game chain is in Table 4 in which the ﬁrst change is notational. We now
Table 4. Changes of games in the proof of Theorem 3
Game
Challenge ciphertext
Notes
Game0 : C∗= gz∗·[A0|A1+id∗
1I2|···|An+id∗
ℓI2]
z∗
$
←Z1×2
q
by the challenger
E∗= ˆe(g, g)z∗D · Mb
Game1 : C∗= g[c∗
0|c∗
1|···|c∗
ℓ]
c∗
0 = z∗A0
E∗= ˆe(g, g)[c∗
0|s∗
1c∗
1+···+s∗
ℓc∗
ℓ]v∗· Mb c∗
i = z∗(Ai + id∗
i I2) for 1 ≤i ≤ℓ
[c∗
0|s∗
1c∗
1 + · · · + s∗
ℓc∗
ℓ]v∗= z∗D
Game2 : C∗= g[c∗
0|c∗
1|···|c∗
ℓ], E∗= R · Mb
R
$
←GT by the challenger
show that Game1 and Game2 are indistinguishable under the DLIN assump-
tion. Given an adversary A against the IBE scheme, we build B with input
gL2 (L2 as in (1) taking k = 2) and gt telling whether t is random in Z1×3
q
or t = z∗· L2 for random z∗∈Z1×2
q
. After A announces the target identities
id∗
0 and id∗
1, B sets up the public parameter pp = (gA0, gD, gA1, . . . , gAℓ) using
A0 = L2 and Ai as in (9). The simulation of B is as follows.
• On extract query id ̸= id∗, B takes s1, . . . , sℓ
$←Zq and random w ∈Z2×1
q
and mentally considers the following
x = δ−1 · (D −A0w) ∈Z2×1
q
, v =

w −Rx
x

∈Z4×1
q
with δ = ℓ
i=1 si(idi −id∗
i ) where id∗
i is the i-th component of id∗∈Zℓ
q
and R = ℓ
i=1 siR∗
i . Then skid = (s1, . . . , sℓ, gv) is returned to A. Note δ−1
exists since δ ̸= 0 (mod q) with overwhelming 1 −1/q probability.
• The challenge ciphertext is
(C∗, E∗) =

g[(y1,y2)|(y1,y2)R∗
1|···|(y1,y2)R∗
ℓ], ˆe(g, g)y3 · Mb

where B’s input t = (y1, y2, y3) ∈Z1×3
q
.

IBE Under k-LIN with Shorter Ciphertexts and Private Keys
155
If t = z∗· L2, namely (y, y3) = z∗[A0|D], or equivalently y = z∗A0 and
y3 = z∗D, we have
[y|yR∗
1| · · · |yR∗
ℓ] = z∗· [A0|A0R∗
1| · · · |A0R∗
ℓ]
= z∗· [A0|A1 + id∗
1I2| · · · |Aℓ+ id∗
ℓI2]
as expected, so that the challenge ciphertext is as in Game1.
If t is random, by R = ˆe(g, g)y3, the challenge ciphertext is as in Game2. In
this ﬁnal game, the challenge bit b is perfectly hidden, ending the proof.
⊓⊔
5.2
Our Function-Private, Fully Secure IBE
– Setup: Let the identity space be {0, 1}n. The public parameters are
pp = (gA0, gA′
0, gD, gA1, . . . , gAn)
where the matrices are as follows
A0 =

u 0
0 v

∈Z2×2
q
, D =

1
1

∈Z2×1
q
, and A′
0, A1, . . . , Aℓ
$←Z2×2
q
where u, v
$←Zq.
The master secret key is msk = (A0, A′
0, A1, . . . , Aℓ). For an identity id ∈
{0, 1}n, let
F(id, S) =

A0



A′
0S +
 n

i=1
idi · Ai

S

∈Z2×4
q
– Extract: on input id ∈{0, 1}n, take S
$←Z2×2
q
, and return skid = (S, gv)
where v ∈Z4×1
q
is a random vector such that
F(id, S) · v = D (mod q).
– Enc: on input id ∈{0, 1}n and M ∈GT , take z
$←Z1×2
q
and compute
C = gz·[A0|A′
0+id1A1+···+idnAn], E = ˆe(g, g)z·D · M.
Return (C, E) as the ciphertext.
– Dec: On input skid = (S, gv) and C = g[c0|c1], compute gc = g[c0|c1S] and
K = ˆe(g, g)c·v using the bi-linearity of ˆe, and return M = EK−1.
Correctness. Directly via [c0|c1S] = [zA0|z(A′
0 + id1A1 + · · · + idnAn)S] =
z · F(id, S).
Intuition on Function Privacy. This is similar to the counterpart above,
yet is more involved by showing that ExtS(id) = (n
i=1 idiAi)S functions as a
randomness extractor with overwhelmingly high probability over the choice of
www.ebook3000.com

156
K. Kurosawa and L.T. Phong
A1, . . . , An, which is proved in [5, Claim5.21]. (The change in sizes of A1, . . . , An
and S does not aﬀect the proof by inspection.)
Intuition on IND-ID-CPA Security. Setting up A′
0, A1, . . . , An as in (8),
we have
F(id, S) =

A0



A0

R0 +
n

i=1
idiRi

S +

q −kJ + h0 +
n

i=1
idihi

S

(10)
and
F(id∗, S∗) =

A0



A0R∗S∗
for R∗=

R0 +
n

i=1
id∗
i Ri

(11)
in which (10) enables the simulation of extract queries, while (11) is used in the
challenge query, so that the proof goes along the lines of that of Theorem 2.
Below is the details.
Theorem 4. The above scheme is IND-ID-CPA-secure under the DLIN
assumption.
Proof. The game chain is as in Table 5.
Table 5. Changes of games in the proof of Theorem 4
Game
Challenge ciphertext
Notes
Game0 : C∗= gz∗·[A0|A′
0+id∗
1A1+···+id∗
nAn] z∗
$
←Z1×2
q
by the challenger
E∗= ˆe(g, g)z∗D · Mb
Game1 : C∗= g[c∗
0|c∗
1]
c∗
0 = z∗A0
E∗= ˆe(g, g)[c∗
0|c∗
1S∗]v∗· Mb
c∗
1 = z∗(A′
0 + id∗
1A1 + · · · + id∗
nAn)
[c∗
0|c∗
1S∗]v∗= z∗F(id∗, S∗)v∗= z∗D
Game2 : C∗= g[c∗
0|c∗
1], E∗= R · Mb
R
$
←GT by the challenger
As the ﬁrst change is notational, we will show that Game1 and Game2 are
computationally indistinguishable under the DLIN assumption from the view of
the adversary. Concretely, we construct simulator B against DLIN as follows. B
has inputs gL2 (L2 as in (1) taking k = 2) and gt and it will tell whether t is
random in Z1×3
q
or t = z∗· L2 for random z∗∈Z1×2
q
. Let A0 = L2 ∈Z2×2
q
and mentally set A′
0, A1, . . . , An as in (8) so that the public parameters can be
computable by B and we have (10) and (11). Moreover, algorithms B works as
follows.
• The simulation of extract queries id: here we expect α(id) = q −kJ + h0 +
n
i=1 idihi ̸= 0 (mod q). Take S
$←Z2×2
q
and the corresponding v is set to
v =

w −(R0 + n
i=1 idiRi)Sx
x

∈Z4×1
q

IBE Under k-LIN with Shorter Ciphertexts and Private Keys
157
in which w ∈Z2×1
q
is random and x = α(id)−1S−1 · (D −A0w) ∈Z2×1
q
,
which is computable as α(id) ̸= 0 (mod q) and random S ∈Z2×2
q
is invertible
with overwhelming probability. Thus skid = (S, gv) can be computed and
returned to the IBE’s adversary A.
• On challenge query id∗and (M0, M1), take b
$←{0, 1}, and return
(C∗, E∗) =

g[(y1,y2)|(y1,y2)R∗], ˆe(g, g)y3Mb

where t = (y1, y2, y3) ∈Z1×3
q
is from the DLIN instance and R∗is in (11).
We claim that, if t = z∗L2, the challenge ciphertext is as in Game1; if t is
random, it is as in Game2. Indeed,
– If t = z∗L2, namely (y1, y2, y3) = z∗[A0|D], we have (y1, y2) = z∗A0 and
y3 = z∗D so that
(C∗, E∗) =

g[z∗A0|z∗A0R∗], ˆe(g, g)z∗DMb

=

g[c∗
0|c∗
1], ˆe(g, g)[c∗
0|c∗
1S∗]v∗· Mb

where c∗
0 = z∗A0, c∗
1 = z∗A0R∗.
– If t is random, we have (y1, y2) and y3 are independently random. Put R =
ˆe(g, g)y3 we obtain the challenge ciphertext in Game2.
The challenge ciphertext in the ﬁnal game contains no information on chal-
lenge bit b, ending the proof.
⊓⊔
6
Conclusion and Open Question
We have showed that IBE schemes and function-private ones can have 2k group
elements in the ciphertext overhead and private keys, and 2k pairings in decryp-
tion under the k-LIN assumption. In short, under k-LIN, the number is 2k which
becomes the state-of-the-art.
It is known that public key encryption (PKE) having semantic security under
k-LIN has k group elements in the ciphertext overhead. Is the gap between k
and 2k inherent from the diﬀerence of PKE and IBE, or can it be shortened
further? This open question is left for future works.
References
1. Bellare, M., Kiltz, E., Peikert, C., Waters, B.: Identity-based (lossy) trapdoor func-
tions and applications. Cryptology ePrint Archive, Report 2011/479 (2011). http://
eprint.iacr.org/. Full version of an extended abstract in Eurocrypt 2012
2. Benson, K., Shacham, H., Waters, B.: The k-bdh assumption family: Bilinear map
cryptography from progressively weaker assumptions. Cryptology ePrint Archive,
Report 2012/687 (2012). http://eprint.iacr.org/. Full version of an extended
abstract in CT-RSA 2013
www.ebook3000.com

158
K. Kurosawa and L.T. Phong
3. Blazy, O., Kiltz, E., Pan, J.: (Hierarchical) identity-based encryption from aﬃne
message authentication. In: Garay, J.A., Gennaro, R. (eds.) CRYPTO 2014,
Part I. LNCS, vol. 8616, pp. 408–425. Springer, Heidelberg (2014). Full version
at http://eprint.iacr.org/2014/581.pdf
4. Boneh, D., Boyen, X., Shacham, H.: Short group signatures. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 41–55. Springer, Heidelberg (2004)
5. Boneh, D., Raghunathan, A., Segev, G.: Function-private identity-based encryp-
tion: hiding the function in functional encryption. In: Canetti, R., Garay, J.A.
(eds.) CRYPTO 2013, Part II. LNCS, vol. 8043, pp. 461–478. Springer, Heidelberg
(2013). Full version at http://eprint.iacr.org/2013/283
6. Canetti, R., Garay, J.A. (eds.) Advances in Cryptology - CRYPTO 2013 - Proceed-
ings of the 33rd Annual Cryptology Conference, Santa Barbara, CA, USA, August
18–22, 2013, Part II, vol. 8043. Lecture Notes in Computer Science. Springer (2013)
7. Chen, J., Wee, H.: Fully, (almost) tightly secure IBE and dual system groups.
In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013, Part II. LNCS, vol. 8043,
pp. 435–460. Springer, Heidelberg (2013)
8. Escala, A., Herold, G., Kiltz, E., R`afols, C., Villar, J.: An algebraic framework
for Diﬃe-Hellman assumptions. In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013,
Part II. LNCS, vol. 8043, pp. 129–147. Springer, Heidelberg (2013)
9. Kurosawa, K., Trieu Phong, L.: Leakage resilient IBE and IPE under the DLIN
assumption. In: Jacobson, M., Locasto, M., Mohassel, P., Safavi-Naini, R. (eds.)
ACNS 2013. LNCS, vol. 7954, pp. 487–501. Springer, Heidelberg (2013)
10. Lewko, A.: Tools for simulating features of composite order bilinear groups in the
prime order setting. In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012.
LNCS, vol. 7237, pp. 318–335. Springer, Heidelberg (2012)
11. Waters, B.: Eﬃcient identity-based encryption without random oracles. In:
Cramer, R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 114–127. Springer,
Heidelberg (2005)
12. Waters, B.: Dual system encryption: realizing fully secure IBE and HIBE under
simple assumptions. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol. 5677,
pp. 619–636. Springer, Heidelberg (2009)
A
The Probability λ in Artiﬁcial Abort
First deﬁne a binary function β(id) =

0 if h0 + n
i=1 idihi = 0 mod J
1 otherwise
, and
note that since q is exponential compared to nJ, we have
α(id) = 0 mod q ⇔h0 +
n

i=1
idihi = kJ mod q ⇔h0 +
n

i=1
idihi = kJ
⇒h0 +
n

i=1
idihi = 0 mod J ⇔β(id) = 0
Since hi are random in ZJ, Pr[β(id) = 0] = 1/J. Abusing the notation a little,
from now on let id1, . . . , idQ be the extract queries, and note that the events

IBE Under k-LIN with Shorter Ciphertexts and Private Keys
159
β(idj) = 0 and β(id∗) = 0 are pairwise independent for all idj ̸= id∗, we have
λ = Pr

∧Q
j=1α(idj) ̸= 0 mod q

∧α(id∗) = 0 mod q

= Pr

∧Q
j=1β(idj) = 1

∧
m

i=1
id∗[i]hi = kJ

=
1
m + 1 Pr

∧Q
j=1β(idj) = 1

∧β(id∗) = 0

=
1
m + 1 Pr

∧Q
j=1β(idj) = 1

Pr

β(id∗) = 0




∧Q
j=1β(idj) = 1

=
1
m + 1

1 −Pr

∨Q
j=1β(idj) = 0

Pr

β(id∗) = 0




∧Q
j=1β(idj) = 1

≥
1
m + 1
⎛
⎝1 −
Q

j=1
Pr [β(idj) = 0]
⎞
⎠Pr

β(id∗) = 0




∧Q
j=1β(idj) = 1

=
1
m + 1
 
1 −Q
J
!
Pr

β(id∗) = 0




∧Q
j=1β(idj) = 1

=
1
m + 1
 
1 −Q
J
!
Pr [β(id∗) = 0]
Pr

∧Q
j=1β(idj) = 1
 Pr

∧Q
j=1β(idj) = 1



β(id∗) = 0

≥
1
(m + 1)
 
1 −Q
J
! 1
J Pr

∧Q
j=1β(idj) = 1



β(id∗) = 0

≥
1
(m + 1)J
 
1 −Q
J
!2
≥
1
(m + 1)J
 
1 −2Q
J
!
,
as stated.
www.ebook3000.com

Improved Identity-Based Online/Oﬄine
Encryption
Jianchang Lai(B), Yi Mu, Fuchun Guo, and Willy Susilo
Centre for Computer and Information Security Research,
School of Computing and Information Technology, University of Wollongong,
Wollongong, NSW 2522, Australia
{jl967,ymu,fuchun,wsusilo}@uow.edu.au
Abstract. The notion of online/oﬄine encryption was put forth by Guo,
Mu and Chen (FC 2008), where they proposed an identity-based scheme
called identity-based online/oﬄine encryption (IBOOE). An online/
oﬄine encryption separates an encryption into two stages: oﬄine
and online. The oﬄine phase carries much more computational load than
the online phase, where the oﬄine phase does not require the information
of the message to be encrypted and the identity of the receiver. Subse-
quently, many applications of IBOOE have been proposed in the litera-
ture. As an example, Hobenberger and Waters (PKC 2014) have recently
applied it to attribute-based encryption. In this paper, we move one step
further and explore a much more eﬃcient variant. We propose an eﬃcient
semi-generic transformation to obtain an online/oﬄine encryption from a
tradition identity-based encryption (IBE). Our transformation provides
a new method to separate the computation of receiver’s identity into
oﬄine and online phases. The IBOOE schemes using our transformation
saves one group element in both oﬄine and online phases compared to
other IBOOE schemes in identity computing. The transformed scheme
still maintains the same level of security as in the original IBE scheme.
Keywords: Identity-based encryption · Online/oﬄine encryption
1
Introduction
Identity based encryption (IBE) was ﬁrst introduced by Shamir in 1984 [14]. In
an IBE system, each user’s public key can be an arbitrary string binding the
user’s identity, such as an email address or a telephone number. IBE removes
the necessity of complex certiﬁcate management that exists in traditional public
key cryptography. The need to incorporate certiﬁcates has been elimiated, and
hence, it removes complicated and costly certiﬁcate veriﬁcation processes. If a
new user wants to join the network in a network system based on IBE, there
is no need for other users in the network to verify its certiﬁcate in order to
communicate securely.
One of the main concerns in cryptography is the eﬃciency of computa-
tion. However, most IBE schemes [2,7,17] in cryptography involve computations
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 160–173, 2015.
DOI: 10.1007/978-3-319-19962-7 10

Improved Identity-Based Online/Oﬄine Encryption
161
including pairings over points on elliptic cure and exponentiations (point multi-
plications) in groups. These operations are regarded as the most costly compu-
tations in cryptography, which might be too costly to be applied in lightweight
devices. One elegant way to solve the problem was proposed to reduce the compu-
tational overhead of digital signature schemes by Even, Goldreich and Micali [6],
where a signing process is split into two phases. The ﬁrst phase is called the oﬄine
phase and is performed prior to obtaining the message to be signed. The sec-
ond phase is called the online phase and is executed when the message becomes
available. All the heavy computations in signing phase are pre-computed in the
oﬄine phase. In the online phase, it only performs the light computations such
as modular multiplication.
The notion of online/oﬄine encryption was ﬁrst introduced by Guo, Mu
and Chen [8] in 2008, where they proposed an identity-based construction. The
motivation of online/oﬄine encryption is to improve the eﬃciency of encryption.
In the oﬄine phase, most of the heavy computations are conducted without the
need to know the recipient’s identity and the message to be encrypted. When
the recipient’s identity and the message become available, the online phase can
be accomplished with great eﬃciency. This seminal work has attracted a lot of
attention.
Guo, Mu and Chen [8] constructed the ﬁrst two identity-based IBOOE
schemes based on the IBE schemes of Boneh and Boyen [2] and Gentry [7].
Both IBOOE schemes were proven to be secure against chosen ciphertext attack
(CCA) without random oracle. Subsequently, a more eﬃcient IBOOE scheme
than Guo et al.’s scheme [8] was proposed by Liu and Zhou [10]. They proved
that their proposed scheme was CCA-secure in the random oracle model. How-
ever, Selvi, Vivek and Rangan [12,13] found that the scheme proposed by Liu
and Zhou [10] actually was not CCA secure and gave a concrete example of an
attack on conﬁdentiality. The adversary could easily forge a ciphertext and dis-
tinguish the challenge message in the security proof. The authors also proposed
a possible ﬁx for the weakness in [10]. This notion has been extended to various
areas such as attribute based encryption [9] and signcryption [18].
In an IBE system, the message space is quite limited such as in a cyclic group.
To optimize the encryption system for any arbitrary message, one can make use of
hybrid encryption. A useful tool called key encapsulation mechanism (KEM) was
proposed by Cramer and Shoup [5] to build a hybrid encryption scheme. A KEM
is similar to a public key encryption scheme, except that it encrypts a session
key K instead of a message. The message is encrypted using the session key with
a symmetry encryption system. Identity-based online/oﬄine key encapsulation
mechanism (IBOOKEM) is suﬃcient for practical applications. Therefore, with
IBOOKEM, the main work is how to split the encryption into oﬄine phase and
online phase, where the identity of receiver only appears in the online phase.
The IBOOKEM was ﬁrst proposed by Chow, Liu and Zhou [3]. It naturally
requires that the KEM is able to divide into online phase and oﬄine phase.
Based on their IBOOKEM, they presented a CCA secure IBOOE scheme in
the random oracle model and gave the general transformation from a one-way
www.ebook3000.com

162
J. Lai et al.
IBOOKEM scheme into a CCA IBOOE scheme. However, Selvi, Vivek and
Rangan [13] showed that there was one weakness in the proof of CCA secu-
rity in [3], and hence, the scheme is insecure. Selvi, Vivek and Rangan [12,13]
proposed a new provably CCA secure and eﬃcient IBOOE scheme in the ran-
dom oracle model. Subsequently, they revisited their IBOOE and constructed
signcryption schemes [13]. A practical IBOOE scheme for wireless sensor net-
work in the selective ID model was proposed by Chu et al. [4]. Recently, Hohen-
berger and Waters [9] proposed the ﬁrst online/oﬄine attribute based encryption
(OOABE) scheme. Both schemes in their paper were selective chosen plaintext
attack (CPA) secure.
A more eﬃcient way to complete encryption and signature at the same time is
signcryption. An, Dodis and Rabin [1] proposed online/oﬄine signcryption. But
they only gave the general security proof notions and did not give their construc-
tions. Sun et al. [15] provided the deﬁnition of the identity-based online/oﬄine
signcryption and the corresponding security model. Based on the work by Sun
et al., several online/oﬄine signcryption schemes have been proposed in the lit-
erature [13,16,18,19].
1.1
Our Contribution
In this paper, we introduce a new semi-generic transformation to split the com-
putation of identity into online and oﬄine. Our transformation is more eﬃcient
than the previous transformation through the comparison in encryption com-
putation and the ciphertext size. All the previous IBOOE schemes [3,10,12,13]
applied the technique introduced by Guo, Mu and Chen [8]. To deal with iden-
tity, they require at least two group elements in G and one element in Z∗
p while
we only need one group element in G and one element in Z∗
p. We reduce one
exponentiation operation in oﬄine computation and save one group element in
G both in oﬄine storage and ciphertext length. We provide the security proof of
our semi-generic transformation. We claim that the IBOOE schemes using our
semi-generic transformation hold the same security level as in the original IBE
schemes. Then we show a natural extension of IBE of Sakai and Kasahara [11],
Boneh and Boyen [2], Gentry [7] and Waters [17] applying our transformation.
Organization of the Paper. In Section 2, we review some preliminaries includ-
ing the deﬁnition of bilinear, identity-based online/oﬄine encryption and the
security model of IBOOE. Our semi-generic transformation, its security proof
and a comparison are provided in Section 3. Four examples of IBOOE schemes
converted by our transformation from the classical IBE schemes and our conclu-
sion are presented in Section 4 and Section 5, respectively.
2
Preliminaries
In this section, we deﬁne bilinear pairing and identity-based online/oﬄine
encryption and then review the deﬁnition of security model for an IBOOE sys-
tem. For simplicity, in this paper, we deﬁne an IBOOE as an IBOOKEM.

Improved Identity-Based Online/Oﬄine Encryption
163
2.1
Bilinear Pairing
Let G be a cyclic group of prime order p and GT be a multiplicative cyclic group
of the same prime order p. Let g be a generator of G. A bilinear pairing is a map
e : G × G →GT with the following properties:
1. Bilinear: For all u, v ∈G and a, b ∈Z∗
p, we have e

ua, vb
= e(u, v)ab.
2. Non-degeneracy: e (g, g) ̸= 1.
3. Computability: It is eﬃcient to compute e (u, v) for all u, v ∈G.
2.2
Identity-Based Online/Oﬄine Encryption
An identity-based online/oﬄine encryption scheme consists of the following ﬁve
algorithms:
Setup(λ): Taking a security parameter λ as input and returns the system
parameters mpk and the master key msk. The system parameters mpk includes
the descriptions of a ﬁnite key space K, a ﬁnite message space M and a ﬁnite
ciphertext space CT . The system parameters are publicly known, while the mas-
ter key is kept secretly and known to generator (PKG) only.
KeyGen(mpk, msk, ID): Taking mpk, msk and an arbitrary ID ∈{0, 1}∗as
input, returns a private key dID for ID. Here ID is an arbitrary string which
will be used as a public key.
Oﬀ-Encrypt(mpk): Taking the system parameter mpk as input, outputs a pair

Coﬀ, K

where Coﬀis called oﬄine ciphertext and K as the message encryption
key.
On-Encrypt(mpk, Coﬀ, ID): Taking the system parameters mpk, oﬄine
ciphertext Coﬀand an identity ID ∈{0, 1}∗as input, returns a ciphertext
CT for K.
Decrypt(mpk, CT, dID): Taking the system parameters mpk, ciphertext CT
and the private key dID as input, outputs the session key K or a reject symbol ⊥.
For correctness we require that if for every (mpk, msk) returned by Setup(λ),
every dID returned by KeyGen(mpk, msk, ID), every

Coﬀ, K

returned by
Oﬀ-Encrypt(mpk) and every CT returned by On-Encrypt(mpk, Coﬀ, ID),
then Decrypt(mpk, CT, dID) = K.
2.3
Security for IBOOE
The semantic security between a challenger and an adversary is deﬁned as
follows.
Setup: The challenger takes as input a secure parameter λ and runs the Setup
algorithm. It gives the adversary A the system public parameters mpk.
www.ebook3000.com

164
J. Lai et al.
Phase 1: A issues polynomially private key queries q1, . . . , qm. The challenger
responds by running key generation algorithm KeyGen to generate the private
key dIDi corresponding to IDi. It sends dIDi to A. These queries may be asked
adaptively, that is, each query qi may depend on the replies to q1, . . . , qi−1.
Challenge: Once A decides that Phase 1 is over, it outputs an identity ID∗
on which it wishes to be challenged. A did not request a private key for ID∗
in Phase 1. The challenger chooses a random bit b ∈{0, 1} and computes a
challenge ciphertext CT ∗and a session key K∗
0 corresponding to ID∗. If b = 0,
the challenger sends (CT ∗, K∗
0) to A. Otherwise, the challenger sends (CT ∗, K∗
1)
to A, where K∗
1 is a random section key from key space.
Phase 2: A issues more private key queries qm+1, . . . , qn on one restriction that
IDi ̸= ID∗. The challenger responds the same as in Phase 1.
Guess: Finally, A outputs a guess b′ ∈{0, 1} of b and wins the game if b′ = b
We deﬁne adversary A’s advantage in attacking the above game is
AdvA (λ) =
Pr[b = b′] −1
2
 .
Deﬁnition 1. An IBOOE system is semantically secure if for any polynomial
time adversary A, the function AdvA (λ) is negligible.
3
Semi-Generic Transformation
In IBE system, the identity in ciphertext is embedded in some group elements.
We refer to those group elements containing identity as ID header. Therefore,
the ciphertext of IBE can be written as CT = (Hdr, C) where Hdr is called ID
header and C is the other components of ciphertext excluding ID header.
The IBE schemes in the literature [2,7,11,17] have the same ID headers in
the ciphertext, if we do not consider the group which the ID headers belong to.
Their ID headers are deﬁned as

g1gIDs,
where g1, g are group elements of mpk and s ∈Z∗
p is the random number chosen
by the encryptor.
Without loss of generality, the encryption algorithm in IBE system can be
written as follow:
Hdr =

g1gIDs,
(C, K) ←E (mpk, s) ,
CT = (Hdr, C) =

g1gIDs, C

,
where K is the message encryption key and E is the encryption algorithm without
the computation of ID header.

Improved Identity-Based Online/Oﬄine Encryption
165
Based on the above scheme, we have the main task of IBOOE is to achieve the
online/oﬄine computation on the ID header. Obviously, there is a trivial method
to achieve online/oﬄine from IBE. We can compute C1 = gs
1, C2 = gs in the
oﬄine phase and perform C3 = C1 · C2
ID after one has obtained the identity
in the online phase. However, one exponentiation operation is required in the
online phase to achieve the online/oﬄine encryption, which is still ineﬃcient.
In the following parts of this session, we ﬁrst revisit the online/oﬄine com-
putation on the ID header with structure Hdr =

g1gIDs. Then we give our
improved semi-generic transformation that only needs two elements to deal with
the ID header to achieve online/oﬄine.
3.1
Previous Method of Transformation
We review how the authors dealt with the online/oﬄine computation of the ID
header in previous IBOOE schemes [3,8,12,13].
Oﬀ-Encrypt: Randomly choose α, β, s ∈Z∗
p and compute
C1 = (g1gα)s,
C2 = gsβ,
(C, K) ←E (mpk, s) .
Then output the oﬄine ciphertext Coﬀ=

C1, C2, α, β−1, C

and the message
encryption key K.
On-Encrypt: Upon receiving ID ∈Z∗
p, compute
C3 = β−1 (ID −α) mod p.
The ID header is Hdron = (C1, C2, C3). Then output the ciphertext
CT = (Hdron, C) = (C1, C2, C3, C) .
In the decryption algorithm, the receiver ﬁrst recoves the general ID header
in the traditional IBE scheme from the ID header as below:
C1 · C2
C3 = (g1gα)s ·

gsββ−1(ID−α) =

g1gIDs.
It is the same as the ID header in IBE. Then, the receiver follows the gen-
eral decryption procedures using its private key as in the traditional encryption
scheme to obtain the key K. It needs three elements to handle the ID header.
3.2
Our Method of Transformation
We describe our method to achieve the online/oﬄine encryption, where only two
elements are required to deal with the ID header. It saves one group element
compared to the previous method.
www.ebook3000.com

166
J. Lai et al.
Oﬀ-Encrypt: Randomly choose s, w ∈Z∗
p and compute
C1 = (g1gw)s,
(C, K) ←E (mpk, s) .
Then output the oﬄine ciphertext Coﬀ= (C1, w, s, C) and the message encryp-
tion key K.
On-Encrypt: Upon receiving ID ∈Z∗
p, compute
C2 = s (ID −w) mod p.
The ID header is Hdron = (C1, C2). Then output the ciphertext
CT = (Hdron, C) = (C1, C2, C) .
Correctness: Given the ID header Hdron = (C1, C2), compute
C1gC2 = (g1gw)s · gs(ID−w) =

g1gIDs.
After recovering the original ID header, the recipient follows the general decryp-
tion procedures using its private key as in traditional identity-based encryption
schemes to obtain the key K.
3.3
Security
Theorem 1. The identity-based online/oﬄine encryption scheme converted
with our transformation is secure if the original identity-based encryption scheme
is secure.
Proof. Let A be an adversary that has advantage ε (λ) against the IBOOE
scheme converted using our transformation. Then, there is a simulator B that
has advantage ε (λ) against the original IBE.
We show how to construct a simulator B that uses A to gain advantage ε (λ)
against IBE in Fig.1. Here, we refer the IBE as the oracle. The IBE and the
simulator B start the game with the IBE ﬁrst running the Setup algorithm of
IBE to generate the system public key mpk. As usual, G is a cyclic groups of
prime order p, and g is the generator of G. Random secret a ∈Z∗
p is the master
key and g1 = ga. The IBE gives mpk to simulator B. Simulator B is supposed to
output an identity ID∗and expects to receive back the IBE challenge ciphertext
CT ∗and the challenger session key K∗under mpk. Simulator B outputs its guess
b ∈{0, 1} on K∗.
Simulator B works by interacting with adversary A as follows (B simulates
the challenger for A):
Setup: Simulator B gives mpk to A as the IBOOE system parameter.
Phase 1: The adversary A issues polynomially private key queries q1, . . . , qm.
For the query on IDi from A, B queries its private key to IBE, then forwards
the results from IBE to A. These queries may be asked adaptively.

Improved Identity-Based Online/Oﬄine Encryption
167
IBE
B
A
1. (mpk, msk) ←Setup (λ)
mpk
−−−−−−−→
mpk
−−−−−−−→
IDi
←−−−−−−−
IDi
←−−−−−−−
2. Generate dIDi by running
dIDi
−−−−−−−−→
dIDi
−−−−−−−−→
KeyGen (mpk, msk, IDi)
ID∗
←−−−−−−−−
ID∗
←−−−−−−−−
3. Output (CT ∗, K∗) where
(CT ∗,K∗)
−−−−−−−−−−→
Choose k ∈Z∗
p
(CT ∗ch,K∗)
−−−−−−−−−−→
CT ∗= (Hdr∗, C∗)
C∗
1 = Hdr∗· g−k
C∗
2 = k
Hdr∗
ch = (C∗
1 , C∗
2 )
CT ∗
ch =

Hdr∗
ch, C∗
b
←−−−−−−−−
b
←−−−−−−−−
Fig. 1. Security Proof
Challenge: Once adversary A decides that Phase 1 is over, it outputs an ID∗
on which it wishes to be challenged. Simulator B responds as follows:
1. B gives IBE the challenge identity ID∗. IBE responds with challenge cipher-
text CT ∗and the corresponding message encryption key K∗where
CT ∗= (Hdr∗, C∗) =

g1gID∗s
, C∗
.
2. Next, B randomly chooses k ∈Z∗
p and computes the challenge ID header:
Hdr∗
ch = (C∗
1, C∗
2) =

Hdr∗· g−k, k

=

g1gID∗s
g−k, k

.
Then, set the online/oﬄine challenge ciphertext as CT ∗
ch =

Hdr∗
ch, C∗
. B
responds to A with the online/oﬄine challenge ciphertext

CT ∗
ch, K∗
.
Note that CT ∗
ch is a valid IBOOE ciphertext under the identity ID∗. To see this,
let w = ID∗−k
s , we have
C∗
1 =

g1gID∗s
g−k = (g1gw)s,
C∗
2 = k = s (ID∗−w) .
Therefore,
Hdr∗
ch = (C∗
1, C∗
2) =

(g1gw)s, s (ID∗−w)

is a valid online/oﬄine challenge ID header for the challenge identity ID∗.
www.ebook3000.com

168
J. Lai et al.
Phase 2: A issues more private key queries qm+1, . . . , qn on one restriction that
IDi ̸= ID∗. B responds as in Phase 1.
Guess: Finally, A outputs a guess b ∈{0, 1} on K∗. Simulator B outputs b as
its guess.
It is obvious that if the adversary A has advantage ε (λ) to break the IBOOE
scheme converted by our transformation, simulator B has advantage ε (λ) to
break the original IBE scheme.
3.4
Comparison
In an IBOOKEM system, there is no message to be encrypted. Therefore, it
is important that how to eﬃciently compute ID header from KEM system to
achieve IBOOKEM, which greatly aﬀects the eﬃciency of IBOOKEM system.
Here, we provide a comparison of computation cost of computing ID header and
the ID header size among the traditional IBE, previous transformation and our
transformation. We denote by E the exponentiation in group G and mc the
modular multiplication in Z∗
p.
Table 1. Comparison of Computing ID header for IBOOE
Traditional IBE
[8],[3],[12],[13]
[10]
Ours
Oﬄine computation
⧸
3E
5E
2E
Online computation
2E
1mc
2mc
1mc
Oﬄine storage
⧸
2G + 2Zp
3G + 4Zp
1G + 2Zp
Ciphertext size
1G
2G + 1Zp
3G + 2Zp
1G + 1Zp
From Table 1, it is clear that the online/oﬄine encryption has a larger
size of ID header than traditional IBE. However, the online/oﬄine method
can greatly reduce the online computation which is the motivation to use the
online/oﬄine encryption. Our semi-generic transformation of computing the ID
deader is more eﬃcient than the previous transformation to achieve identity-
based online/oﬄine encryption. The previous transformation requires two group
elements in G and one element in Z∗
p to deal with identity while we only need
one group element in G and one element in Z∗
p. We reduce one exponentia-
tion operation in the oﬄine computation and save one group element in G
both in oﬄine storage and ciphertext length. We claim that the identity-based
encryption schemes with this kind of ID header can be eﬃciently converted to
online/oﬄine encryption schemes by our method.
4
Identity Based Online/Oﬄine Encryption Schemes
In this section, we give four examples applying our transformation to achieve the
online/oﬄine encryption from the classical identity-based encryption schemes

Improved Identity-Based Online/Oﬄine Encryption
169
[2,7,11,17]. Four IBOOE schemes are given in the form of key encapsulation.
Their security are easy to prove according to the original schemes. We omit
their security proofs here. We also claim that the ﬁrst example is a CPA-
secure identity-based online/oﬄine key encapsulation mechanism scheme with
the shortest ciphertext.
4.1
IBOOE from Sakai-Kasahara IBE [11]
Setup: The system parameters are generated as follow. The PKG randomly
chooses α ∈Z∗
p and sets g1 = gα. Let H1 : {0, 1}∗→Z∗
p be the cryptographic
hash function. The public parameters mpk and msk are given by
mpk = (G, GT , q, g, g1, H1) ,
msk = α.
KeyGen: To generate the private key for ID ∈{0, 1}∗, PKG computes
dID = g
1
H1(ID)+α .
Oﬀ-Encrypt: Randomly choose x, y ∈Z∗
p and compute
K = e(g, g)x,
C1 = (g1gy)x.
Output the oﬄine ciphertext Coﬀ= (C1, x, y) and the session key K. Note that
e (g, g) can be pre-computed by the PKG in Setup phase as part of the public
parameters mpk. Thus, there is no pairing to be computed in the oﬄine phase.
On-Encrypt: To generate a ciphertext for ID, compute
C2 = x (H1 (ID) −y) mod p.
Output the ciphertext CT = (C1, C2) corresponding to the session key K.
Decrypt: Upon receiving the ciphertext CT = (C1, C2), to recover the session
key, the recipient decrypts the ciphertext using the private key dID and computes
K = e

C1 · gC2, dID

.
According to our transformation, it is easy to check its correctness
e

C1 · gC2, dID

= e

g1gH1(ID)x
, g
1
H1(ID)+α

= e(g, g)x = K.
4.2
IBOOE from Boneh-Boyen IBE [2]
Setup: PKG randomly chooses a secret a ∈Zp, generators g, g2, h1 ∈G and
sets g1 = ga. The system public parameters mpk and master key msk are
mpk = (g, g1, g2, h1) ,
msk = ga
2.
www.ebook3000.com

170
J. Lai et al.
KeyGen: To generate the private key for ID ∈Zp, PKG picks a random r ∈Zp
and computes
dID = (d1, d2) =

ga
2

h1gID
1
r, gr
.
Oﬀ-Encrypt: Randomly chooses w, s ∈Zp, compute
K = e(g1, g2)s,
C1 = (h1gw
1 )s,
C2 = gs.
Output the oﬄine ciphertext Coﬀ= (C1, C2, w, s) and session key K.
On-Encrypt: To generate a ciphertext for an identity ID ∈Zp , compute
C3 = s (ID −w) mod p.
Then output the ciphertext CT = (C1, C2, C3) corresponding to the session
key K.
Decrypt: To decrypt the ciphertext CT = (C1, C2, C3) for ID ∈Zp and recover
the session key, the receiver uses its private key dID and computes
C0 = C1 · gC3
1
=

h1gID
1
s,
K = e (d1, C2)
e (C0, d2).
For a valid ciphertext, we have
e (d1, C2)
e (C0, d2) = e

ga
2

h1gID
1
r, gs
e

h1gID
1
s, gr
= e(g1, g2)s = K.
4.3
IBOOE from Gentry IBE [7]
Setup: PKG randomly chooses a ∈Zp and generators g, h ∈G and sets g1 = ga.
The system parameters mpk and the master key msk are
mpk = (g, g1, h) ,
msk = a.
KeyGen: To generate the private key for ID ∈Zp, PKG picks a random r ∈Zp
and outputs
dID = (d1, d2) =

r,

hg−r
1
a−ID 
.
Oﬀ-Encrypt: Randomly choose w, s ∈Zp and compute
K = e(g, h)−s,
C1 =

g1g−ws,
C2 = e(g, g)s.
Then output the oﬄine ciphertext Coﬀ= (C1, C2, w, s) and session key K.
On-Encrypt: To generate a ciphertext for an identity ID ∈Zp, the sender
computes
C3 = s (w −ID) mod p.
Then output the ciphertext CT = (C1, C2, C3) corresponding to the session
key K.

Improved Identity-Based Online/Oﬄine Encryption
171
Decrypt: To decrypt the ciphertext CT = (C1, C2, C3) with ID and recover
the session key, the recipient computes
C0 = C1 · gC3 =

g1g−ws · gs(w−ID) =

g1g−IDs,
K =
1
e (C0, d2) · C2
d1 .
4.4
IBOOE from Waters’ Dual System IBE [17]
Setup: Let G be a group of prime order p. The PKG chooses generators g, v, v1,
v2, w, u, h ∈G and a1, a2, b, α ∈Zp. Let τ1 = vva1
1 , τ2 = vva2
2 . The system public
parameters mpk and the master key msk are
mpk =

gb, ga1, ga2, gb·a1, gb·a2, τ1, τ2, τ b
1, τ b
2, w, u, h, e(g, g)α·a1·b
,
msk = {g, gα, gα·a1, v, v1, v2} .
KeyGen: To generate the private key for identity ID ∈Zp, the PKG randomly
chooses r1, r2, z1, z2, tagk ∈Zp. Let r = r1 + r and computes
D1 = gα·a1vr,
D2 = g−αvr
1gz1,
D3 =

gb−z1,
D4 = vr
2gz2,
D5 =

gb−z2,
D6 = gr2·b,
D7 = gr1,
R =

uIDwtagkh
r1.
The private key is
dID = (D1, . . . , D7, R, tagk) .
Oﬀ-Encrypt: Choose random s1, s2, t, x, tagc ∈Zp and let s = s1 + s2 and
compute:
K =

e(g, g)α·a1·bs2
,
C1 =

gbs1+s2,
C2 =

gb·a1s1,
C3 = (ga1)s1,
C4 =

gb·a2s2, C5 = (ga2)s2,
C6 = τ s1
1 τ s2
2 ,
C7 =

τ b
1
s1
τ b
2
s2w−t,
E1 =

uxwtagch
t,
E2 = gt.
Then output the oﬄine ciphertext
Coﬀ= (C1, . . . , C7, E1, E2, tagc)
and the session key K.
On-Encrypt: To generate a ciphertext for an identity ID ∈Zp, compute
C8 = t (ID −x) mod p.
www.ebook3000.com

172
J. Lai et al.
Then output the ciphertext CT = (C1, . . . , C8, E1, E2, tagc) corresponding to
the session key K.
Decrypt: To decrypt the ciphertext CT = (C1, . . . , C8, E1, E2, tagc) with ID,
the receiver ﬁrst checks tagc, if tagc = tagk, outputs invalid. Otherwise, the
receiver computes
E3 = E1 · uC8 =

uxwtagch
t · ut(ID−x) =

uIDwtagch
t,
A1 = e (C1, D1) · e (C1, D1) · e (C1, D1) · e (C1, D1) · e (C1, D1)
= e(g, g)α·a1·b·s2e(v, g)b(s1+s2)re(v1, g)a1bs1re(v2, g)a2bs2r
Since r = r1 + r2, we have
A2 =e (C6, D6)·e (C7, D7) = e(v, g)b(s1+s2)re(v1, g)a1bs1re(v2, g)a2bs2re(g, w)−r1t,
A3 = A1
A2
= e(g, g)α·a1·b·s2e(g, w)r1t,
A4 =
	e (E3, D7)
e (E2, R)

1
tagc−tagk = e(g, w)r1t.
Finally, the receiver can recover the session key by computing
K = A3
A4
.
5
Conclusion
We proposed a semi-generic transformation to transform IBE into IBOOE. Our
transformation is applicable to those IBE schemes whose ID header is

g1gIDs.
In comparison with traditional IBOOE schemes, our transformation saves one
group element in both oﬄine storage and ciphertext length and reduces one
exponentiation operation in oﬄine computation. We proved that our transfor-
mation is secure if the IBE scheme is secure. We presented four examples of IBE
of Sakai and Kasahara [11], Boneh and Boyen [2], Gentry [7] and Waters [17] by
applying our transformation.
References
1. An, J.H., Dodis, Y., Rabin, T.: On the security of joint signature and encryp-
tion. In: Knudsen, L.R. (ed.) EUROCRYPT 2002. LNCS, vol. 2332, pp. 83–107.
Springer, Heidelberg (2002)
2. Boneh, D., Boyen, X.: Eﬃcient selective-id secure identity-based encryption with-
out random oracles. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004.
LNCS, vol. 3027, pp. 223–238. Springer, Heidelberg (2004)

Improved Identity-Based Online/Oﬄine Encryption
173
3. Chow, S.S.M., Liu, J.K., Zhou, J.: Identity-based online/oﬄine key encapsulation
and encryption. In: Proceedings of the 6th ACM Symposium on Information, Com-
puter and Communications Security, ASIACCS 2011, pp. 52–60 (2011)
4. Chu, C., Liu, J.K., Zhou, J., Bao, F., Deng, R.H.: Practical id-based encryption
for wireless sensor network. In: Proceedings of the 5th ACM Symposium on Infor-
mation, Computer and Communications Security, ASIACCS, pp. 337–340 (2010)
5. Cramer, R., Shoup, V.: Design and analysis of practical public-key encryption
schemes secure against adaptive chosen ciphertext attack. SIAM J. Comput. 33(1),
167–226 (2003)
6. Even, S., Goldreich, O., Micali, S.: On-line/oﬀ-line digital signatures. J. Cryptology
9(1), 35–67 (1996)
7. Gentry, C.: Practical identity-based encryption without random oracles. In:
Vaudenay, S. (ed.) EUROCRYPT 2006. LNCS, vol. 4004, pp. 445–464. Springer,
Heidelberg (2006)
8. Guo, F., Mu, Y., Chen, Z.: Identity-based online/oﬄine encryption. In: Tsudik, G.
(ed.) FC 2008. LNCS, vol. 5143, pp. 247–261. Springer, Heidelberg (2008)
9. Hohenberger, S., Waters, B.: Online/oﬄine attribute-based encryption. In:
Krawczyk, H. (ed.) PKC 2014. LNCS, vol. 8383, pp. 293–310. Springer, Heidelberg
(2014)
10. Liu, J.K., Zhou, J.: An eﬃcient identity-based online/oﬄine encryption scheme.
In: Abdalla, M., Pointcheval, D., Fouque, P.-A., Vergnaud, D. (eds.) ACNS 2009.
LNCS, vol. 5536, pp. 156–167. Springer, Heidelberg (2009)
11. Sakai, R., Kasahara, M.: ID based cryptosystems with pairing on elliptic curve.
IACR Cryptology ePrint Archive 2003, 54 (2003)
12. Selvi, S.S.D., Vivek, S.S., Rangan, C.P.: Identity based online/oﬄine encryption
scheme. IACR Cryptology ePrint Archive 2010, 178 (2010)
13. Selvi, S.S.D., Vivek, S.S., Rangan, C.P.: Identity based online/oﬄine encryption
and signcryption schemes revisited. In: Joye, M., Mukhopadhyay, D., Tunstall, M.
(eds.) InfoSecHiComNet 2011. LNCS, vol. 7011, pp. 111–127. Springer, Heidelberg
(2011)
14. Shamir, A.: Identity-based cryptosystems and signature schemes. In: Blakely, G.R.,
Chaum, D. (eds.) CRYPTO 1984. LNCS, vol. 196, pp. 47–53. Springer, Heidelberg
(1985)
15. Sun, D., Huang, X., Mu, Y., Susilo, W.: Identity-based on-line/oﬀ-line signcryp-
tion. In: IFIP International Conference on Network and Parallel Computing, NPC,
pp. 34–41 (2008)
16. Sun, D., Mu, Y., Susilo, W.: A generic construction of identity-based online/oﬄine
signcryption. In: IEEE International Symposium on Parallel and Distributed Pro-
cessing with Applications, ISPA, pp. 707–712 (2008)
17. Waters, B.: Dual system encryption: realizing fully secure IBE and HIBE under
simple assumptions. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol. 5677,
pp. 619–636. Springer, Heidelberg (2009)
18. Yan, F., Chen, X., Zhang, Y.: Eﬃcient online/oﬄine signcryption without key
exposure. IJGUC 4(1), 85–93 (2013)
19. Zhao, J., Zhao, X., Shi, Y.: Certiﬁcateless signcryption with online/oﬄine tech-
nique. Journal of Computer Applications 34, 2659–2663 (2014)
www.ebook3000.com

Constructions of CCA-Secure Revocable
Identity-Based Encryption
Yuu Ishida(B), Yohei Watanabe, and Junji Shikata
Graduate School of Environment and Information Sciences,
Yokohama National University, Yokohama, Japan
{ishida-yuu-xg,watanabe-yohei-xs}@ynu.jp,
shikata@ynu.ac.jp
Abstract. Key revocation functionality is important for identity-based
encryption (IBE) to manage users dynamically. Revocable IBE (RIBE)
realizes such revocation functionality with scalability. In PKC 2013, Seo
and Emura ﬁrst considered decryption key exposure resistance (DKER)
as a new realistic threat, and proposed the ﬁrst RIBE scheme with
DKER. Their RIBE scheme is adaptively secure against chosen plain-
text attacks (CPA), and there is no concrete RIBE scheme adaptively
secure against chosen ciphertext attacks (CCA) even without DKER
so far. In this paper, we ﬁrst propose two constructions of adaptively
CCA-secure RIBE schemes with DKER. The ﬁrst scheme is based on an
existing transformation, which is called a BCHK transformation, that a
CPA-secure hierarchical IBE scheme can be transformed into a CCA-
secure scheme. The second scheme is constructed via the KEM/DEM
framework. Speciﬁcally, we newly propose a revocable identity-based
key encapsulation mechanism (RIB-KEM), and we show a generic con-
struction of a CCA-secure RIBE scheme from the RIB-KEM and a data
encapsulation mechanism (DEM). The second scheme is more eﬃcient
than the ﬁrst one in terms of the ciphertext size.
1
Introduction
Identity-based encryption (IBE for short) is a type of public key encryption (PKE
for short) to be able to use any string, such as an e-mail address, as a public key.
The ability to use identities as public keys eliminates the need for a public key
infrastructure (PKI for short). Since Boneh and Franklin have proposed the ﬁrst
secure and practical IBE scheme [6], IBE has been investigated and has become
one of the important cryptographic primitives. Revocation functionality in the
IBE setting (i.e. without PKIs) is one of the most important issue. For example,
in a situation where secret keys of some receivers have to be revoked as soon as
possible, when their secret keys are compromised. In the PKE setting, a PKI
informs the senders that receivers’ keys are revoked or expired via certiﬁcate
revocation lists and digital certiﬁcates. However, in the IBE setting, we have
to achieve such revocation functionality without PKIs. Boneh and Franklin [6]
ﬁrst consider a naive solution to such a revocation problem as follows. A key
generation center (KGC for short), which is a trusted authority whose role is
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 174–191, 2015.
DOI: 10.1007/978-3-319-19962-7 11

Constructions of CCA-Secure Revocable Identity-Based Encryption
175
Table 1. Eﬃciency comparison for two proposed RIBE schemes and the Seo–Emura
RIBE. G is a cyclic group and |G| denotes the size of a group element in G. |vk|
and |σ| denote sizes of a veriﬁcation key and a signature of the underlying one-time
signature. An identity space in all schemes is {0, 1}n. In computational cost analysis,
[·, ·, ·, ·] means the number of [pairing, multi-exponentiation, regular exponentiation,
ﬁxed-based exponentiation]. Computational costs of the underlying target collision
resistant hash function and DEM do not be taken into account here. For comparison
we mention that relative tunings for the various operations are as follows: [pairing≈
5, multi-exp≈1.5, regular-exp≈1, ﬁxed-based-exp≪0.2], and computational costs
of the underlying Waters hashing and Boneh–Boyen hashing are approximately one,
respectively (description of these hash functions will be given in Section 2). All schemes
are secure under the DBDH assumption.
Scheme
Security
Ciphertext
Overhead
Public Key
Size
Encryption
Cost
Decryption
Cost
KEM-based RIBE
(Section 5)
CCA
4|G|
(n + 8)|G|
[0, 1, 4, 1]
[4, 1, 2, 3]
BCHK-based RIBE
(Section 4)
CCA
4|G| +|vk| + |σ| (n + 8)|G|
[0, 0, 6, 1]
+Sign
[4, 0, 1, 1]
+Vrfy
Seo–Emura RIBE [20]
CPA
3|G|
(n + 6)|G|
[0, 0, 4, 1]
[3, 0, 0, 0]
to generate users’ secret keys and to distribute them via secure channels, gen-
erates a secret key skID∥T as a secret key of each non-revoked user ID at each
time period T, and distributes them to only corresponding non-revoked users via
secure channels at every time period. However, this solution does not scale well
since the overhead of the KGC is proportional to the number of the non-revoked
users, namely, the KGC has to generate (N −R) secret keys, where N is the
number of users and R is the number of revoked users. To achieve both the revo-
cation functionality and scalability in IBE, researchers have studied revocable
IBE (RIBE for short) schemes [2,7,16,17,19,20] so far.
Related Work. Boldyreva et al. [2] ﬁrst formalized the security model of RIBE
and proposed the ﬁrst scalable RIBE scheme with selective security against cho-
sen plaintext attack, which we call selective CPA-security in this paper. In their
scheme, a KGC generates a long-term secret key skID and sends it to a user
via a secure channel as in IBE, and the KGC broadcasts key update kuT at
each time period T. Note that no secure channel is required for broadcast-
ing kuT . By using a complete subtree (CS for short) method [18], they suc-
ceeded in reducing the overhead of the KGC, speciﬁcally, the KGC generates
only O(R log(N/R)) number of key update at each time period when R ≥N/2.
Such a technique for reducing revocation costs is used in all the previous RIBE
schemes [7,17,19,20] except for [16]. Lee et al. [16] adopted a subset diﬀerence
(SD) method [18] and a layered SD method [10] instead of the CS method, and
consequently, they achieve O(R) number of key update at each time period.
However, their RIBE scheme achieves only selective CPA-security or requires
more strong assumption to achieve adaptive CPA-security compared to other
www.ebook3000.com

176
Y. Ishida et al.
adaptively secure RIBE schemes [17,20]. Libert and Vergnaud [17] proposed the
ﬁrst adaptively CPA-secure RIBE scheme. Seo and Emura [20] captured secu-
rity for a new realistic threat, which is called decryption key exposure resistance
(DKER for short), and proposed an adaptively CPA-secure RIBE scheme with
DKER. DKER means that exposure of a decryption key dkID,T for a user ID at
time period T give no information on other decryption keys for the ID at other
time periods. Even though the CPA-security with DKER1 is a stronger security
notion than the traditional CPA-security of RIBE [2,17], their RIBE scheme,
which we call a Seo–Emura RIBE, is most eﬃcient in all existing (CPA-secure)
RIBE schemes under the same computational assumption, i.e., decisional bilin-
ear Diﬃe–Hellman (DBDH for short) assumption. In all previous RIBE schemes
before the Seo–Emura RIBE, a long-term secret key and key update at the cur-
rent time are used in a decryption algorithm. To capture DKER, Seo and Emura
introduced a decryption key generation algorithm, and hence, a decryption algo-
rithm requires the decryption key at the current time, which is derived from a
long-term secret key and key update. Note that such non-interactive updating
functionality can be also seen in key-insulated encryption (KIE for short) [8], in
particular, identity-based (hierarchical) KIE [11]. However, the main purposes of
those schemes are diﬀerent since the purpose of KIE is to minimize the impact
of key leakage, whereas that of RIBE is to revoke users eﬃciently and securely.
Our Contribution. In this paper, we propose two constructions of CCA-
secure RIBE schemes through diﬀerent approaches, which we call a BCHK
transformation-based approach and a KEM-based approach. The former app-
roach is based on a BCHK transformation [3], which can transform CPA-secure
(ℓ+ 1)-level hierarchical IBE (HIBE for short) to a CCA-secure ℓ-level scheme.
Although no formal description is given, the former approach was already men-
tioned in [20] as a way to lifting the Seo–Emura RIBE to a CCA-secure scheme.
Therefore, we can say the former seems to be a naive solution. However, it is
actually not so straightforward due to its DKER property. Hence, we clarify
what the important point to securely construct the CCA-secure scheme via this
approach is, and show a concrete construction by applying this approach to
the Seo-Emura RIBE [20]. Next, we propose a more eﬃcient construction in
terms of the ciphertext size than the ﬁrst (naive) construction through the lat-
ter approach. We ﬁrst formalize a revocable IB-KEM (RIB-KEM for short), and
propose a construction of RIB-KEM. Then, we construct a CCA-secure RIBE
scheme from our RIB-KEM and a CCA-secure data encapsulation mechanism
(DEM for short). For the above reason, the latter is called the KEM-based app-
roach.
More speciﬁcally, the latter approach is as follows. The Seo–Emura RIBE
is based on a CPA-secure IBE scheme proposed by Waters in [21], which we
call a Waters IBE. Thus, the security of the Seo–Emura RIBE is proved under
the that of Waters IBE, and hence the Seo–Emura RIBE is secure under the
DBDH assumption. Their proof technique is simple and elegant, and hence,
1 Throughout this paper, we consider CPA-security (and CCA-security) with DKER,
and we omit “with DKER” in the following.

Constructions of CCA-Secure Revocable Identity-Based Encryption
177
we take a similar approach. Namely, our aim is to provide a security reduc-
tion from our RIBE scheme to some concrete CCA-secure IBE scheme under
the DBDH assumption. Therefore, we adopt an identity-based key encapsula-
tion mechanism (IB-KEM for short) proposed by Kiltz and Galindo in [13,14]
(which we call a Kiltz–Galindo IB-KEM) as the underlying scheme since an IBE
scheme from their IB-KEM is most eﬃcient in all of the existing CCA-secure
IBE schemes under the DBDH assumption. Hence, we ﬁrst give a model and
security deﬁnition of RIB-KEM, and we would like to propose a construction of
an RIB-KEM so that its security can be proved under that of the Kiltz–Galindo
IB-KEM. However, the Kiltz–Galindo IB-KEM is insuﬃcient to provide a secu-
rity reduction from our proposed RIB-KEM, though the Waters IBE can give a
security reduction from the Seo–Emura RIBE. Therefore, we modify the Kiltz–
Galindo IB-KEM appropriately, and consider a variant of the Kiltz–Galindo
IB-KEM. Then, we propose a construction of an RIB-KEM based on the vari-
ant scheme, and thus, we show a security reduction from the RIB-KEM to the
variant scheme. Finally, we construct a CCA-secure RIBE scheme through the
KEM/DEM framework even in the RIBE setting. Namely, we propose a generic
construction of a CCA-secure RIBE scheme from our RIB-KEM and a CCA-
secure DEM.
Comparison. For the ﬁrst time, we propose CCA-secure RIBE schemes. An
eﬃciency comparison between our two RIBE schemes and the Seo–Emura RIBE
is given in Table 1. Note that the Seo–Emura RIBE is CPA-secure. We can
say that public key sizes, encryption costs, and decryption costs between two
our schemes are roughly the same. It is noteworthy that ciphertext size in the
KEM-based construction is shorter than that in the BCHK transformation-based
construction, and we require only one more group element for the ciphertext in
the KEM-based construction compared with that in the Seo–Emura RIBE.
2
Preliminaries
Notation. In this paper, “probabilistic polynomial-time” is abbreviated as
“PPT”. If we write (y1, y2, . . . , ym) ←A(x1, x2, . . . , xn) for an algorithm A hav-
ing n inputs and m outputs, it means to input x1, x2, . . . , xn into A and to get the
resulting output y1, y2, . . . , ym. We write (y1, y2, . . . , ym) ←AO(x1, x2, . . . , xn)
to indicate that an algorithm A that is allowed to access an oracle O takes
x1, x2, . . . , xn as input and outputs (y1, y2, . . . , ym). If X is a set, we write x
$←X
to mean the operation of picking an element x of X uniformly at random. If x
is a string, then |x| denotes its bit-length. We use λ as a security parameter.
M, I, T , and K denote sets of plaintexts, IDs, time periods, and session keys,
respectively, which are determined by a security parameter λ.
Bilinear Group. A bilinear group generator G is an algorithm that takes a
security parameter λ as input and outputs a bilinear group (p, G, GT , e), where
p is a prime such that 22λ < p, G and GT are multiplicative cyclic groups of
order p, and ˆe is an eﬃciently computable and non-degenerate bilinear map
www.ebook3000.com

178
Y. Ishida et al.
ˆe : G × G →GT with the following bilinear property: For any u, u′, v, v′ ∈G,
ˆe(uu′, v) = ˆe(u, v)ˆe(u′, v) and ˆe(u, vv′) = ˆe(u, v)ˆe(u, v′), and for any u, v ∈G
and any a ∈Zp, ˆe(ua, v) = ˆe(u, va) = ˆe(u, v)a (for more details, see [6]).
Decisional Bilinear Diﬃe–Hellman (DBDH) Assumption. Security of
all schemes described in this paper are proved under the DBDH problem. In
the security proof of our RIBE construction, we provide a reduction from our
IND-RID-CCA RIBE scheme to the DBDH problem. We give the deﬁnition of
the DBDH assumption below. Let A be a PPT adversary and we consider A’s
advantage against the DBDH problem as follows.
AdvDBDH
G,A
(λ, N) :=

Pr
⎡
⎢⎣β′ = β
(p, G, GT , ˆe) ←G, a, b, c
$←Zp,
β
$←{0, 1}, if β = 1 then W := ˆe(g, g)abc,
else W
$←GT , β′ ←A(λ, g, ga, gb, gc, W)
⎤
⎥⎦−1
2

.
Deﬁnition 1 (DBDH assumption). The DBDH assumption relative to a
generator G holds if for all PPT adversaries A, AdvDBDH
G,A
is negligible in λ.
Target Collision Resistant Hash Function (TCRHF). For simplicity, we
consider a non-keyed hash function TCR : D →R that takes x ∈D as input and
outputs y ∈R, where |D| ≥|R|.
Deﬁnition 2 (TCRHF). A hash function TCR is said to be target collision
resistant if for all PPT adversaries A, the following advantage is negligible in λ:
AdvT CR
TCR,A(λ) := Pr[(x, x∗) ∈D2 ∧x ̸= x∗∧TCR(x) = TCR(x∗) | x
$←D, x∗←
A(λ, x)].
Waters Hashing and Boneh–Boyen Hashing. We describe two hash func-
tions used in IBE schemes proposed in [21] and [4], respectively. In this paper,
we call the former a Waters hashing, and the latter a Boneh–Boyen hashing.
For ID = (b1, . . . , bn) ∈{0, 1}n and u0, u1, . . . , un
$←G, the Waters hashing
FW : {0, 1}n →G is deﬁned by FW(ID) = u0
n
i=1 uibi; and for T ∈Zp and
v, v′
$←G, the Boneh-Boyen hashing FBB : Zp →G is deﬁned by FBB(T) = v′vT .
KUNode Algorithm. To reduce costs of a revocation process, we use a binary
tree structure and apply the following KUNode algorithm as in the previous
RIBE schemes [2,17,20]. KUNode(BT, RL, T) takes as input a binary tree BT,
a revocation list RL, and a time period T ∈T , and outputs a set of nodes. When
η is a non-leaf node, then we write ηL and ηR as the left and right child of η,
respectively. When η is a leaf node, Path(η) denotes the set of nodes on the path
from η to the root. Each user is assigned to a leaf node. If a user who is assigned
to η is revoked on a time period T ∈T , then (η, T) ∈RL. KUNode(BT, RL, T)
is executed as follows. It sets X := ∅and Y := ∅. For any (ηi, Ti) ∈RL, if Ti ≤T
then it adds Path(ηi) to X (i.e., X := X ∪Path(ηi)). Then, for any η ∈X, if
ηL /∈X, then it adds ηL to Y. If ηR /∈X, then it adds ηR to Y. Finally, it
outputs Y if Y ̸= ∅. If Y = ∅, then it adds root to Y and outputs Y. For the

Constructions of CCA-Secure Revocable Identity-Based Encryption
179
Fig. 1. Example of KUNode algorithm (when u5 is revoked)
understanding of readers, we give an example in Fig 1 to understand KUNode
algorithm easily. In the example, we suppose that a user u5(assigned to η12) is
revoked. Then X = Path(η12) = {η12, η6, η3, root = η1}, and Y = {η2, η7, η13}.
Intuitively, all users, except u5, have a node η ∈Y that is contained in the set of
nodes on the path from their assigned node to root: e.g., η2 for u1, u2, u3 and u4,
η7 for u7 and u8, and η13 for u6, whereas Y ∩Path(η12) = ∅. When a user joins
the system, KGC assigns it to the leaf node η of a complete binary tree, and
issues a set of keys, wherein each key is associated with each node on Path(η).
At time period T, KGC publishes key updates for a set KUNode(BT, RL, T).
Then, only non-revoked users have at least one key corresponding to a node in
KUNode(BT, RL, T) and are able to generate decryption keys on time T.
3
Revocable Identity-Based Encryption (RIBE)
A revocable identity-based encryption (RIBE) scheme ΠRIBE consists of seven-
tuple algorithms (Setup, PKG, KeyUp, DKG, REnc, RDec, Revoke) deﬁned as
follows:
– (mpk, msk, RL, st) ←Setup(λ, N): A probabilistic algorithm for setup. It
takes a security parameter λ and the number of users N as input and outputs
a master public key mpk, a master secret key msk, an initial revocation list
RL = ∅and a state st.
– (skID, st) ←PKG(mpk, msk, ID, st): An algorithm for private key genera-
tion. It takes mpk, msk, an identity ID ∈I, and st as input and outputs a
secret key skID associated with ID and an updated state st.
– kuT ←KeyUp(mpk, msk, T, RL, st): An algorithm for key update genera-
tion. It takes mpk, msk, a time period T ∈T , a current revocation list RL,
and st as input and then outputs a key update kuT .
www.ebook3000.com

180
Y. Ishida et al.
– dkID,T or ⊥←DKG(mpk, skID, kuT ): A probabilistic algorithm for decryp-
tion key generation. It takes mpk, skID and kuT as input and then outputs
a decryption key dkID,T at T or ⊥if ID has been revoked.
– CT ←REnc(mpk, ID, T, M): A probabilistic algorithm for encryption. It
takes mpk, (ID, T) ∈I × T , and M ∈M as input and then outputs a
ciphertext CT.
– M or ⊥←RDec(mpk, dkID,T , CT): A deterministic algorithm for decryp-
tion. It takes mpk, dkID,T and CT as input and then outputs M or ⊥if CT
is an invalid ciphertext.
– RL ←Revoke(ID, T, RL, st): An algorithm for revocation. It takes (ID, T) ∈
I×T , the current revocation list RL, and a state st as input and then outputs
an updated revocation list RL.
In the above model, we assume that ΠRIBE meets the following correctness prop-
erty: For all security parameter λ, all (mpk, msk, RL, st) ←Setup(λ, N), all M ∈
M, if ID ∈I is not revoked on T ∈T , it holds that M = RDec(mpk, dkID,T , REnc
(mpk, ID, T, M)), where (skID, st) ←PKG(mpk, msk, ID, st), kuT ←KeyUp
(mpk, msk, T, RL, st) and dkID,T ←DKG(mpk, skID, kuT ).
We describe the notion of indistinguishability against chosen ciphertext
attack for RIBE (IND-RID-CCA) with DKER, which was ﬁrst captured in [20].
Note that the decryption key exposure can be considered for realistic threats,
therefore we consider RIBE schemes having DKER in addition to CCA-security.
Let A be a PPT adversary, and A’s advantage against IND-RID-CCA security
is deﬁned by
AdvIND-RID-CCA
ΠRIBE,A
(λ, N) :=

Pr
⎡
⎢⎢⎣β′ = β
(mpk, msk, RL, st) ←Setup(λ, N),
(M ∗
0 , M ∗
1 , ID∗, T ∗, st) ←AO(·)(ﬁnd, mpk, RL, st),
β
$←{0, 1}, CT ∗←REnc(mpk, ID∗, T ∗, M ∗
β),
β′ ←AO(·)(guess, CT ∗, st)
⎤
⎥⎥⎦−1
2

.
Here, O is a set of oracles {PKG(·), KeyUp(·), Revoke(·, ·), DKG(·, ·),
RDec(·, ·, ·)} deﬁned as follows.
PKG(·): For a query ID ∈I, it stores and returns skID by running PKG(mpk,
msk, ID, st) (if skID was already generated and stored by DKG or RDec,
then PKG returns the stored skID).
KeyUp(·): For
a
query
T
∈
T ,
it
stores
and
returns
KeyUp(mpk, msk, T, RL, st).
Revoke(·, ·): For a query ((ID, T) ∈I×T ), it updates and returns a revocation
list RL by running Revoke(ID, T, RL, st).
DKG(·, ·): For a query ((ID, T) ∈I ×T ), it returns DKG(mpk, skID, kuT ) and
stores it unless it is ⊥(if dkID,T was already generated and stored by RDec,
then DKG returns the stored dkID,T ).
RDec(·, ·, ·): For a query (ID, T, CT), it returns RDec(mpk, dkID,T , CT). Note
that in DKG and RDec, skID and/or dkID,T may not have been generated

Constructions of CCA-Secure Revocable Identity-Based Encryption
181
yet. If not, they are generated and stored by running PKG and/or DKG,
respectively.
A is allowed to access the above oracles with the following restrictions.
1. KeyUp(·) and Revoke(·, ·) can be queried at a time period which is later than
or equal to that of all previous queries.
2. Revoke(·, ·) cannot be queried at a time period T if KeyUp(·) was queried at
T.
3. If PKG(ID∗) was queried, then Revoke(ID∗, T) must be queried at T ≤T ∗.
4. DKG(·, ·) and RDec(·, ·, ·) cannot be queried before KeyUp(·) was queried at
time T.
5. DKG(ID∗, T ∗) cannot be queried.
6. RDec(ID∗, T ∗, CT ∗) cannot be queried.
Deﬁnition 3 (CCA-security of RIBE). An RIBE scheme ΠRIBE is said to
be IND-RID-CCA secure if for all PPT adversaries A, AdvIND-RID-CCA
ΠRIBE,A
(λ, N)
is negligible in λ.
4
Naive Approach to Constructing CCA-Secure RIBE
First, we show a naive approach based on the BCHK transformation [3], which
can transform Hierarchical IBE (HIBE for short) from a CPA-secure (ℓ+1)-level
scheme and a one-time signature (OTS for short) to a CCA-secure ℓ-level scheme,
and in this paper it is called the BCHK transformation-based approach. In [20],
Seo and Emura also mentioned that a CCA-secure RIBE scheme may be easily
obtained through the BCHK transformation-based approach above, however, we
show that it is actually not so straightforward as expected. Therefore, in this
section we clarify an important point to apply the BCHK transformation-based
approach and show a concrete construction based on this approach.
The BCHK Transformation. We recall the BCHK transformation [3]. In par-
ticular, we here consider the BCHK transformation from a CPA-secure 2-level
HIBE scheme and an OTS. In the 2-level HIBE, a user id1 having a secret key
skid1 can generate a secret key sk(id1,id2) for his descendant (id1, id2) (note that
the descendant cannot generate his descendant’s secret key). In the BCHK trans-
formation, a fresh key-pair (sk, vk) of an OTS is generated in each encryption.
We regard vk as not only a veriﬁcation key of the OTS but also a part of an
identity (by being encoded as an n-bit string). Then, a ciphertext C is generated
by the encryption algorithm of the CPA-secure HIBE and the identity (ID, vk).
Hence, the resulting ciphertext is (C, vk, σ), where σ is a signature of C. For
decryption, a user having a secret key skID generates sk(ID,vk) and decrypts C
after validity checking of C by the veriﬁcation algorithm of the OTS.
Details of the BCHK Transformation-Based Approach (Also Men-
tioned in [20]). The Seo–Emura RIBE is based on the Waters IBE [21], and
consequently, the CPA security of the Seo–Emura RIBE is proved by a
www.ebook3000.com

182
Y. Ishida et al.
polynomial-time reduction to that of the Waters IBE. In [20, Section6], Seo
and Emura referred to the BCHK transformation-based approach as follows:
“Due to the property of the underlying Waters IBE scheme, we can extend our
RIBE scheme to a HIBE scheme with eﬃcient revocation only for the ﬁrst level
users. There is a well-known transformation from a two-level HIBE scheme to a
CCA-secure IBE scheme [3]. Therefore, we can obtain CCA-secure RIBE scheme
by applying this transformation.”
Since any CPA-secure 2-level HIBE with selective security regarding the second
level of the hierarchy and adaptive security regarding the ﬁrst level is suﬃcient
to obtain a CCA-secure IBE scheme (showed in [3,21]), we brush up the above
approach by eﬃciently constructing the underlying 2-level HIBE scheme from
the Boneh–Boyen IBE [4] and the Waters IBE [21]. For convenience, such a CPA-
secure 2-level HIBE scheme using the Boneh–Boyen IBE at the second level and
the Waters IBE at the ﬁrst level is called a Hybrid HIBE scheme in this paper.
Important Point to Apply the BCHK Transformation-Based App-
roach. The reason why the BCHK transformation-based approach cannot be
easily applied is due to its DKER property, namely, the existence of the DKG
algorithm.
We give intuition of an important point to construct a secure RIBE scheme
through this approach. Suppose that a ciphertext C is encrypted by using a 2-
dimensional ID-vector (ID, vk) at a time period T, and the resulting ciphertext
CT is (C, vk, σ). Therefore, dk(ID,vk),T is needed to decrypt C. As a natural way
of trying to take this approach, one may come up with the following approach:
First, a secret key at the second level of hierarchy (i.e. sk(ID,vk)) is generated,
then a decryption key at T is generated from it (i.e. dk(ID,vk),T ). This means
that the DKG algorithm takes skID and kuT as input and outputs dkID,T :=
(skID, kuT ) directly. However, it is obvious that the resulting RIBE scheme is
insecure since an adversary can obtain both skID and kuT by querying dkID∗,T
and dkID,T ∗to the DKG oracle, respectively, in the IND-RID-CCA game. For
the above reason, we take the following approach: As in the Seo–Emura RIBE,
a decryption key at the ﬁrst level at T (i.e. dkID,T ) is generated in the DKG
algorithm, and then dk(ID,vk),T is calculated from dkID,T and vk in the RDec
algorithm. As seen above, we have to pay attention to such a generating ﬂow of
decryption keys. Taking into account above, we construct a CCA-secure RIBE
scheme based on the BCHK transformation-based approach as follows.
Let T := Zp, I := {0, 1}n, and M := GT . Let ΠOTS = (Setup, Sign, Ver) be a
one-time signature.2 Let FW : {0, 1}n →G be the Waters hashing which consists
of u0, u1, . . . , un ∈G, and F(i)
BB : Zp →G (i = 1, 2) be two Boneh-Boyen hashing
which consist of v1, v′
1 ∈G and v2, v′
2 ∈G, respectively. To avoid confusion, we
denote them by F(i)
BB(x) := v′
ivx
i . We assume vk is appropriately encoded as an
element of Zp when it is used in F(1)
BB.
2 We omit description of an OTS (and a DEM, which will appear in Section 5.4) since
we believe readers are familiar with it.

Constructions of CCA-Secure Revocable Identity-Based Encryption
183
– Setup(λ, N): First, it gets (p, G, GT , ˆe) ←G(λ). Let g be a generator of G. It
chooses g2, u0, u1, . . . , un, v′
1, v1, v′
2, v2
$←G and α
$←Zp, and sets g1 := gα.
It outputs mpk := (g, g1, g2, u0, u1, . . . , un, v′
1, v1, v′
2, v2), msk := α, RL := ∅
and st := BT where BT is a binary tree with N leaves.
– PKG(mpk, msk, ID, st): It randomly chooses an unassigned leaf η from BT,
and stores ID in the node η. For each node θ ∈Path(η), it recalls gθ if it was
deﬁned. Otherwise, it chooses gθ
$←G and stores gθ in the node θ. Then, it
chooses rθ
$←Zp and computes
(D(0)
θ , D(1)
θ ) = (gα
θ FW(ID)rθ, grθ).
Finally, it outputs skID :=

(θ, D(0)
θ , D(1)
θ )

θ∈Path(η) and st := BT.
– KeyUp(mpk, msk, T, RL, st): Parse st as st := BT. For each node θ ∈
KUNode(BT, RL, T), it computes as follows. It retrieves gθ and computes
˜gθ := w1/gθ. Note that gθ is always pre-deﬁned in PKG. It chooses sθ
$←Zp
and computes
( ˜D(0)
θ , ˜D(1)
θ ) := (˜gα
θ FW(ID)sθ, gsθ).
Finally, it outputs kuT :=

(θ, ˜D(0)
θ , ˜D(1)
θ )

θ∈KUNode(BT,RL,T ).
– DKG(mpk, skID, kuT ): Parse skID as skID = {(θ, D(0)
θ , D(1)
θ )}θ∈Θsk and kuT
as kuT = {(θ, ˜D(0)
θ , ˜D(1)
θ )}θ∈Θku. If Θsk ∩Θku = ∅, then it outputs ⊥.
Otherwise, it chooses θ ∈Θsk ∩Θku and r, s
$←Zp, and outputs
dkID,T = (D(0)
θ
˜D(0)
θ FW(ID)rF(2)
BB(T)s, D(1)
θ gr, ˜D(1)
θ gs)
= (wα
1 FW(ID)r+rθF(2)
BB(T)s+sθ, gr+rθ, gs+sθ).
– REnc(mpk, ID, T, M) : It ﬁrst runs (vk, sk) ←Setup(λ). It chooses t
$←Zp
and computes
C0 := M · ˆe(g1, g2)t, C1 := g−t, C2 := FW(ID)t, C3 := F(1)
BB (vk)t, C4 := F(2)
BB (T)t.
It also runs σ
←
Sign(sk, (C0, C1, . . . , C4)) and outputs CT
:=
(vk, C0, C1, . . . , C4, σ).
– RDec(mpk, dkID,T , CT): Parse dkID,T as dkID,T = (DK1, DK2, DK3) and
CT as CT = (vk, C0, C1, . . . , C4, σ). If Ver(vk, C0, . . . , C4, σ) →0, then it
outputs ⊥. Otherwise, it chooses ˜r
$←Zp and computes
dk(ID,vk),T = (D1, D2, D3, D4)
= (DK1 · F(1)
BB(vk)˜r, DK2, g˜r, DK3)
= (gα
2 FW(ID)r+rθF(1)
BB(vk)˜r · F(2)
BB(T)s+sθ, gr+rθ, g˜r, gs+sθ).
Finally, it outputs M = C0
4
i=1 ˆe(Ci, Di).
www.ebook3000.com

184
Y. Ishida et al.
– Revoke(mpk, ID, T, RL, st) : Let η be a leaf node associated with ID. It
updates the revocation list by RL ←RL∪{(η, T)} and outputs the updated
revocation list RL.
We obtain the following theorem. Due to space limitation, the proof will
appear in the full version of this paper.
Theorem 1. If the underlying 2-level Hybrid HIBE scheme is IND-ID-CPA
secure and ΠOTS is OT-sEUF-CMA secure, then our RIBE scheme constructed
above is IND-RID-CCA secure.
In general, the BCHK transformation is one of generic transformations,
whereas the above construction is a direct one (i.e. a construction from scratch).
Therefore, there seem to be some redundant points. In particular, due to the
underlying OTS, the ciphertext contains vk and σ, and hence the overhead
seems to be a redundant length. Thus, in the next section, we propose a more
eﬃcient CCA-secure RIBE scheme by taking another approach.
5
KEM-Based Approach: CCA-Secure Revocable
ID-Based KEM
We introduce a revocable identity-based key encapsulation mechanism (RIB-
KEM for short), and show a construction of a CCA-secure RIB-KEM. As
mentioned earlier, in [20], Seo–Emura RIBE scheme is proved to be IND-RID-
CPA secure under the DBDH assumption through the reduction to the Waters
IBE [21]. The proof technique is simple and elegant, and further, their construc-
tion based on the Waters IBE and the Boneh–Boyen IBE [4,5] is also simple and
most eﬃcient among all existing CPA-secure RIBE schemes (under the DBDH
assumption). Therefore, we would like to use a similar approach so that security
of our RIBE scheme is proved under that of a certain concrete CCA-secure IBE
scheme, and for doing so, we consider a CCA-secure IBE scheme from the Kiltz–
Galindo IB-KEM [13,14]. The Kiltz–Galindo IB-KEM is based on the Waters
IBE and is the most eﬃcient construction among existing CCA-secure IB-KEMs
(and IBE schemes) under the DBDH assumption.3 However, we cannot apply Seo
and Emura’s proof technique to the original Kiltz–Galindo IB-KEM, whereas
it can be applied to the Waters IBE. Therefore, we ﬁrst consider a variant of
the Kiltz–Galindo IB-KEM in such a way that it suits our aim (i.e., to be able
to give a reduction from the security of our RIB-KEM), and show the result-
ing IB-KEM is also IND-ID-CCA secure under the DBDH assumption (i.e. the
same as the original one). Then, we construct a CCA-secure RIB-KEM based
on the variant IB-KEM. Finally, we construct a CCA-secure RIBE scheme from
our CCA-secure RIB-KEM and a CCA-secure DEM via the KEM/DEM frame-
work in the RIBE setting. Therefore, as a by-product we will show that the
KEM/DEM framework works well in the RIBE setting.
3 Of course we may construct more eﬃcient IBE schemes than the Kiltz–Galindo
scheme if we allow to use more strong assumptions or add other assumptions (e.g.
[9,15,22]). However, we consider the DBDH assumption only in this paper, since it
is the standard assumption used for utilizing pairing techniques in cryptography.

Constructions of CCA-Secure Revocable Identity-Based Encryption
185
5.1
Syntax of Revocable IB-KEM
An RIB-KEM, which is based on RIBE [20] and IB-KEMs [1,13,14], is deﬁned
as follows. An RIB-KEM ΠRIB-KEM consists of seven-tuple algorithms (Setup,
PKG, KeyUp, DKG, REncaps, RDecps, Revoke). All algorithms except for REncaps
and RDecaps are the same as those of RIBE. Therefore, we here describe only
these two algorithms.
– (C, K) ←REncaps(mpk, ID, T): A probabilistic algorithm for encapsulation.
It takes mpk, ID ∈I, T ∈T and as input and then outputs a session key
K ∈K and a ciphertext C.
– K ←RDecaps(mpk, ID, T, dkID,T , C): A deterministic algorithm for decap-
sulation. It takes mpk, dkID,T and C as input and then outputs K.
We assume that ΠRIB-KEM meets the following correctness property: For all
security parameter λ, all (mpk, msk, RL, st) ←Setup(λ, N), and all (C, K) ←
REncaps (mpk, ID, T), if ID ∈I is not revoked at time T ∈T , it holds that
K ←RDecaps(mpk, dkID,T , C), where (skID, st) ←PKG(mpk, msk, ID, st),
kuT ←KeyUp(mpk, msk, T, RL, st) and dkID,T ←DKG(mpk, skID, kuT ).
We describe a KEM-version of the IND-RID-CCA security. Let A be a PPT
adversary and A’s advantage for IND-RID-CCA security is deﬁned by
Adv
IND-RID-CCA
ΠRIB-KEM,A(λ, N) :=

Pr
⎡
⎢⎢⎢⎢⎢⎣
β′ = β
(mpk, msk, RL, st) ←Setup(λ, N),
(ID∗, T ∗, st) ←AO(·)(ﬁnd, mpk, RL, st),
K∗
0
$←K,
(C∗, K∗
1) ←REncaps(mpk, ID∗, T ∗),
β
$←{0, 1}, β′ ←AO(·)(guess, K∗
β, C∗, st)
⎤
⎥⎥⎥⎥⎥⎦
−1
2

.
Here, O is a set of oracles {PKG(·), KeyUp(·, ·), Revoke(·), DKG(·), RDe-
caps(·, ·, ·)}, which are the same as those in the case of RIBE except for RDe-
caps(·, ·, ·). For a query (ID, T, C), RDecaps(·, ·, ·) returns K by running skID ←
PKG(mpk, msk, ID, st), dkID,T ←DKG(mpk, skID, kuT ) (or taking stored skID
and dkID,T if they have been already generated), and K ←RDecaps(mpk, ID, T,
dkID,T , C). Restrictions on queries for oracles are also the same as those of RIBE
by replacing the RDec oracle with the RDecaps oracle.
Deﬁnition 4 (CCA-security of RIB-KEM). An RIB-KEM ΠRIB-KEM is
said to be IND-RID-CCA secure if for all PPT adversaries A, A’s advantage
AdvIND-RID-CCA
ΠRIB-KEM,A
(λ, N) is negligible in λ.
5.2
A Variant of the Kiltz–Galindo IB-KEM
We modify the Kiltz–Galindo IB-KEM [13,14]. Let TCR : G →Zp be a target
collision resistant hash function and FW : {0, 1}n →G be the Waters hash-
ing which consists of u0, u1, . . . , un. We construct an IB-KEM ΠvKG = {KGvKG,
www.ebook3000.com

186
Y. Ishida et al.
ExtractvKG, EncapsvKG, DecapsvKG} with I := {0, 1}n, and K := GT as follows. In
this construction, we say that a tuple (g, u, v, w) ∈G4 is a DH tuple if it satisﬁes
ˆe(g, w) = ˆe(v, u).
- KGvKG(λ): First, it gets (p, G, GT , ˆe) ←G(λ). Let g be a generator of G. It
chooses α
$←Zp, w1, w2, u0, u1, . . . , un
$←G, and sets g1 := gα and z :=
ˆe(g, w1)α. It outputs mpk := (g, g1, w1, w2, u0, u1, . . . , un, z) and msk := α.
- ExtractvKG(mpk, msk, ID): It chooses s
$←Zp and computes SKID :=
(wα
1 FW (ID)s, gs).
- EncapsvKG(mpk, ID): It chooses r
$←Zp and computes c1 := gr, c2 :=
FW(ID)r, c3 := (wt
1w2)r, where t ←TCR(c1). It also computes a random ses-
sion key K := zr ∈GT . Finally, it outputs a session key K and a ciphertext
C := (c1, c2, c3).
- DecapsvKG(mpk, ID, SKID, C): Parse C and SKID as C = (c1, c2, c3) and
SKID = (d1, d2) respectively. It ﬁrst runs t ←TCR(c1) and checks whether
(g, c1, wt
1w2, c3) and (g, c1, FW(ID), c2) are DH tuples. If both of them are
DH tuples, then it outputs K = ˆe(c1, d1)/ˆe(c2, d2). Otherwise, it outputs
K
$←GT .
The above scheme satisﬁes the following correctness property: For all λ ∈N, all
ID ∈I, all (mpk, msk) ←KGvKG(λ), all SKID ←ExtractvKG(mpk, msk, ID),
and all (C, K) ←EncapsvKG(mpk, ID), it holds that K ←DecapsvKG(mpk, ID,
SKID, C).
Roughly speaking, the important point for this modiﬁcation is that we add
a one element of G (i.e., g1 := gα) to a public parameter of the original scheme
and then replace a secret key α ∈Zp with α ∈G. The reason why the above
modiﬁcation is needed is that in the security proof of our RIB-KEM, an adversary
of IB-KEM needs to embed information on a secret key into a key update kuT
without knowing the secret key msk = α and he/she has to answer a query from
an adversary of RIB-KEM. To achieve this, we need to add information on α
as exponent in the public parameter (i.e. g1), and we can prove the following
theorem.
Theorem 2. The above IB-KEM ΠvKG is IND-ID-CCA secure under the DBDH
assumption.
Proof (Sketch). We can give the proof in a similar way to that of the original
scheme [14] with a slight modiﬁcation. Due to space limitation, we here give
intuition about the proof. We can construct an adversary B against the DBDH
problem by using an adversary A against the IND-RID-CCA security. After
receiving g, ga, gb, gc, and W, where W = ˆe(g, g)abc or W
$←GT , A sets
w1 := ga, w2, u0, u1, . . . , un
$←G, z := ˆe(ga, gb), and g1 := gb. When receiving
a challenge query ID∗, B chooses β
$←{0, 1} and sets a challenge ciphertext
c∗
1 := gc, c∗
2 := FW(ID∗)c, c∗
3 := (wt∗
1 w2)c and a session key Kβ := W (if β = 0
then W is a random element of GT , otherwise W = zc), where t∗←TCR(c∗
1).
Since c∗
2 and c∗
3 have to be computed without knowing the exact value of c, we

Constructions of CCA-Secure Revocable Identity-Based Encryption
187
need to change values of c∗
2 and c∗
3 by a sequence of games. We can also prove
that diﬀerences between games are negligible.
⊓⊔
5.3
Proposed CCA-Secure RIB-KEM
A basic idea of our construction is similar to that in the Seo–Emura RIBE
scheme [20]. Namely, we consider a simple 2-level hierarchical IB-KEM (without
delegating property), and we assign the ﬁrst level of hierarchy for identities and
the second level for time periods. Interestingly, a 2-level hierarchical IB-KEM
with our adaptively CCA-secure variant scheme ΠvKG (as seen in the previous
subsection) at the ﬁrst level and the selectively CPA-secure Boneh-Boyen IBE
at the second level is suﬃcient for constructing a CCA-secure RIB-KEM. We
propose a construction of an RIB-KEM ΠRIB-KEM ={Setup, PKG, KeyUp, DKG,
REncaps, RDecaps, Revoke} with T := Zp, I := {0, 1}n, and K := GT as follows.
Let TCR : G →Zp be a target collision resistant hash function, FW : {0, 1}n →G
be the Waters hashing which consists of u0, u1, . . . , un, and FBB : Zp →G be the
Boneh-Boyen hashing which consists of v, v′.
- Setup(λ, N): First, it gets (p, G, GT , ˆe) ←G(λ). Let g be a generator of G.
It chooses α
$←Zp, w1, w2, u0, u1, . . . , un, v′, v
$←G, g1 := gα and z :=
ˆe(g, w1)α. It outputs mpk := (g, g1, w1, w2, u0, u1, . . . , un, v′, v, z), msk := α,
RL := ∅, st := BT where BT is a binary tree with N leaves.
- PKG(mpk, msk, ID, st): It randomly chooses an unassigned leaf η from BT,
and stores ID in the node η. For each node θ ∈Path(η), it recalls gθ if it was
deﬁned. Otherwise, it chooses gθ
$←G and stores gθ in the node θ. Then, it
chooses ˆrθ
$←Zp and it computes
(D(0)
θ , D(1)
θ ) = (gα
θ FW(ID)ˆrθ, gˆrθ).
Finally, it outputs skID :=

(θ, D(0)
θ , D(1)
θ )

θ∈Path(η) and st := BT.
- KeyUp(mpk, msk, T, RL, st): For each node θ ∈KUNode(BT, RL, T), it com-
putes as follows. It retrieves gθ and computes ˜gθ := w1/gθ. Note that gθ is
always pre-deﬁned in PKG. It chooses ˆsθ
$←Zp and computes
( ˜D(0)
θ , ˜D(1)
θ ) = (˜gα
θ FW(ID)ˆsθ, gˆsθ).
Finally, it outputs kuT =

(θ, ˜D(0)
θ , ˜D(1)
θ )

θ∈KUNode(BT,RL,T ).
- DKG(mpk, skID, kuT ): Parse skID and kuT as skID = {(θ, D(0)
θ , D(1)
θ )}θ∈Θsk
and kuT = {(θ, ˜D(0)
θ , ˜D(1)
θ )}θ∈Θku, respectively. If Θsk ∩Θku = ∅, then it
outputs ⊥. Otherwise, it chooses θ ∈Θsk ∩Θku, ˆr, ˆs
$←Zp and outputs
dkID,T = (D(0)
θ
· ˜D(0)
θ
· FW(ID)ˆr · FBB(T)ˆs, D(1)
θ
· gˆr, ˜D(1)
θ
· gˆs)
= (wα
1 FW(ID)ˆr+ˆrθFBB(T)ˆs+ˆsθ, gˆr+ˆrθ, gˆs+ˆsθ).
www.ebook3000.com

188
Y. Ishida et al.
- REncaps(mpk, ID, T): It chooses r
$←Zp and computes
c1 := gr, c2 := FW(ID)r, c3 := FBB(T)r, c4 := (wt
1w2)r, K := zr ∈GT ,
where t ←TCR(c1). It outputs K and C := (c1, c2, c3, c4).
- RDecaps(mpk, ID, dkID,T , C): Parse dkID,T and C as dkID,T = (d1, d2, d3)
and C = (c1, c2, c3, c4), respectively. It computes t ←TCR(c1) and chooses
r1, r2, r3
$←Zp. Then, it computes
K = ˆe(c1, d1 · (wt
1w2)r1 · FW(ID)r2 · FBB(T)r3)
ˆe(c3, d3 · gr3)ˆe(c2, d2 · gr2)ˆe(gr1, c4)
.
- Revoke(mpk, ID, T, RL, st): Let η be a leaf node associated with ID. It
updates the revocation list by RL ←RL∪{(η, T)} and outputs the updated
revocation list RL.
First, we show the correctness of our ΠRIB-KEM. Before that, we show that the
above RDecaps algorithm always outputs a random group element of GT if C is
not a valid ciphertext. In fact, we have
K = ˆe(c1, d1 · (wt
1w2)r1 · FW(ID)r2 · FBB(T)r3)
ˆe(c3, d3 · gr3)ˆe(c2, d2 · gr2)ˆe(gr1, c4)
= ˆe(c1, d1)ˆe(c1, (wt
1w2)r1)ˆe(c1, FW(ID)r2)ˆe(c1, FBB(T)r3)
ˆe(c3, d3)ˆe(c2, d2)ˆe(gr1, c4)ˆe(c2, gr2)ˆe(c3, gr3)
=
ˆe(c1, d1)
ˆe(c3, d3)ˆe(c2, d2) · ˆe(c1, (wt
1w2)r1)
ˆe(gr1, c4)
· ˆe(c1, FW(ID)r2)
ˆe(c2, gr2)
· ˆe(c1, FBB(T)r3)
ˆe(c3, gr3)
=
ˆe(c1, d1)
ˆe(c3, d3)ˆe(c2, d2) · Δ1(C)r1 · Δ2(C)r2 · Δ3(C)r3,
where Δ1(C) := ˆe(c1,(wt
1w2))
ˆe(g,c4)
, Δ2(C) := ˆe(c1,FW(ID))
ˆe(c2,g)
, and Δ3(C) := ˆe(c1,FBB(T ))
ˆe(c3,g)
.
Then, Δ1(C) = Δ2(C) = Δ3(C) = 1 if and only if C is valid ciphertext, and
therefore, K is a random group element of GT if C is not valid. Such an implicit
rejection technique can be also seen in [12,14]. We then show that ΠRIB-KEM sat-
isﬁes the correctness. Suppose that dkID,T = (d1, d2, d3) is a correctly-generated
decryption key of a non-revoked user ID at T, and that C = (c1, c2, c3, c4) is a
valid ciphertext for the user ID. Then, we have
ˆe(c1, d1)
ˆe(c3, d3)ˆe(c2, d2) =
ˆe(gr, wα
1 FW(ID)ˆr+ˆrθFBB(T)ˆs+ˆsθ)
ˆe(FBB(T)r, gˆs+ˆsθ)ˆe(FW(ID)r, gˆr+ˆrθ)
= ˆe(gr, wα
1 )ˆe(gr, FW(ID)ˆr+ˆrθ)ˆe(gr, FBB(T)ˆs+ˆsθ)
ˆe(FBB(T)r, gˆs+ˆsθ)ˆe(FW(ID)r, gˆr+ˆrθ)
= zr.
Next, we show security of our ΠRIB-KEM as follows. The formal proof will appear
in the full version of this paper.

Constructions of CCA-Secure Revocable Identity-Based Encryption
189
Theorem 3. If the IB-KEM ΠvKG described in Section 5.2 is IND-ID-CCA
secure, then our proposed ΠRIB-KEM is IND-RID-CCA secure.
Proof (Sketch). We can prove it through a similar approach of the security
proof in [20]. We construct adversary B who breaks IND-ID-CCA security for
ΠvKG using an adversary A who breaks IND-RID-CCA security for ΠRIB-KEM.
CH denotes the challenger of IND-ID-CCA game of ΠvKG. First, B receives
g, g1, w1, w2, u0, u1, . . . , un, z as a public parameter of ΠvKG from CH. Then, B
chooses ν, ν′
$←Zp and computes v = g1gν and v′ = g−T ∗
1
gν′, and B sends
mpk := (g, g1, w1, w2, u0, u1, . . . , un, v′, v, z) to A. Next, we need to consider two
types of adversaries for simulating PKG, KeyUp and DKG oracles.
– Type-1 adversary: A can issue a query for skID∗to the PKG oracle, however,
then ID∗will be revoked before T ∗. (For T ̸= T ∗, A may query dkID∗,T .)
– Type-2 adversary: A does not query skID∗, however A may issue dkID∗,T
for T ̸= T ∗.
We omit how B simulates them since we can take a similar approach to that in
[20]. Therefore, we here describe how B simulates the RDecaps oracle. When B
receives (ID, T, CT = (c1, c2, c3, c4)) from A, it checks whether a form of c3 is
vaild or not. Namely, B checks whether (g, c1, FBB(T), c3) is a DH tuple or not.
If not so, then B returns a random element of GT to A. Otherwise, B sends
(c1, c2, c4) to the Decaps oracle of the IND-ID-CCA game for ΠvKG. Then, the
ciphertext (c1, c2, c4) is the same form as that in ΠvKG if the ciphertext is valid.
Therefore, B can perfectly simulate the RDecaps oracle by transferring a session
key K received from the Decaps oracle.
⊓⊔
5.4
Proposed CCA-Secure RIBE Based on the KEM/DEM
Framework
We show that the KEM/DEM framework works well even in the RIBE setting
though it is known that the framework works well in the PKE setting and the IBE
setting. Speciﬁcally, a CCA-secure RIBE scheme ΠRIBE = (Setup, PKG, KeyUp,
DKG, REnc, RDec, Revoke) can be constructed from a CCA-secure RIB-KEM
ΠRIB-KEM = (Setup, PKG, KeyUp, DKG, REncaps, RDecaps, Revoke) and a CCA-
secure DEM ΠDEM = (E, D). The construction is simple. All algorithms except
for REnc and RDec can be constructed by algorithms with the same name.
- Enc(mpk, ID, T, M): It executes (K, C) ←REncaps(mpk, ID, T) and C′ ←
E(M, K). It outputs CT := (C, C′).
- Dec(mpk, dkID,T , CT): It executes K ←RDecaps(mpk, dkID,T , C), and then
outputs M or ⊥←D(C′, K).
Security of the resulting RIBE scheme can be shown as follows. The proof
will appear in the full version of this paper.
Theorem 4. If an RIB-KEM ΠRIB-KEM is IND-RID-CCA secure and a DEM
ΠDEM is IND-CCA secure, then the resulting RIBE scheme ΠRIBE is IND-RID-
CCA secure.
www.ebook3000.com

190
Y. Ishida et al.
6
Concluding Remarks
We ﬁrst proposed two adaptively CCA-secure RIBE constructions with DKER.
The ﬁrst one is constructed through a naive approach based on the BCHK
transformation. The second one is constructed through a KEM-based approach.
Speciﬁcally, we newly proposed an RIB-KEM, and we showed a generic construc-
tion of a CCA-secure RIBE scheme from the RIB-KEM and a DEM. As seen in
Section 1, it is noteworthy that ciphertext size in the KEM-based construction
is shorter than that in the BCHK transformation-based construction.
Acknowledgments. We would like to thank anonymous referees for their helpful
comments. We would also like to thank Keita Emura for his valuable comments for the
preliminary version of this paper. The second author is supported by JSPS Research
Fellowships for Young Scientists.
References
1. Bentahar, K., Farshim, P., Malone-Lee, J., Smart, N.: Generic constructions of
identity-based and certiﬁcateless kems. Journal of Cryptology 21(2), 178–199
(2008)
2. Boldyreva, A., Goyal, V., Kumar, V.: Identity-based encryption with eﬃcient revo-
cation. In: Proceedings of the 15th ACM conference on Computer and communi-
cations security, pp. 417–426. ACM, New York (2008)
3. Boneh, D., Canetti, R., Halevi, S., Katz, J.: Chosen ciphertext security from iden-
tity based encryption. SIAM Journal on Computing 36(5), 1301–1328 (2007)
4. Boneh, D., Boyen, X.: Eﬃcient selective-ID secure identity-based encryption with-
out random oracles. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004.
LNCS, vol. 3027, pp. 223–238. Springer, Heidelberg (2004)
5. Boneh, D., Boyen, X.: Eﬃcient selective identity-based encryption without random
oracles. Journal of Cryptology 24(4), 659–693 (2011)
6. Boneh, D., Franklin, M.: Identity-based encryption from the Weil pairing. In: Kil-
ian, J. (ed.) CRYPTO 2001. LNCS, vol. 2139, pp. 213–229. Springer, Heidelberg
(2001)
7. Chen, J., Lim, H.W., Ling, S., Wang, H., Nguyen, K.: Revocable identity-based
encryption from lattices. In: Susilo, W., Mu, Y., Seberry, J. (eds.) ACISP 2012.
LNCS, vol. 7372, pp. 390–403. Springer, Heidelberg (2012)
8. Dodis, Y., Katz, J., Xu, S., Yung, M.: Key-insulated public key cryptosystems. In:
Knudsen, L.R. (ed.) EUROCRYPT 2002. LNCS, vol. 2332, pp. 65–82. Springer,
Heidelberg (2002)
9. Gentry, C.: Practical identity-based encryption without random oracles. In: Vau-
denay, S. (ed.) EUROCRYPT 2006. LNCS, vol. 4004, pp. 445–464. Springer,
Heidelberg (2006)
10. Halevy, D., Shamir, A.: The LSD broadcast encryption scheme. In: Yung, M. (ed.)
CRYPTO 2002. LNCS, vol. 2442, pp. 47–60. Springer, Heidelberg (2002)
11. Hanaoka, Y., Hanaoka, G., Shikata, J., Imai, H.: Identity-based hierarchical
strongly key-insulated encryption and its application. In: Roy, B. (ed.) ASI-
ACRYPT 2005. LNCS, vol. 3788, pp. 495–514. Springer, Heidelberg (2005)

Constructions of CCA-Secure Revocable Identity-Based Encryption
191
12. Kiltz, E.: Chosen-ciphertext security from tag-based encryption. In: Halevi, S.,
Rabin, T. (eds.) TCC 2006. LNCS, vol. 3876, pp. 581–600. Springer, Heidelberg
(2006)
13. Kiltz, E., Galindo, D.: Direct chosen-ciphertext secure identity-based key encap-
sulation without random oracles. In: Batten, L.M., Safavi-Naini, R. (eds.) ACISP
2006. LNCS, vol. 4058, pp. 336–347. Springer, Heidelberg (2006)
14. Kiltz, E., Galindo, D.: Direct chosen-ciphertext secure identity-based key encapsu-
lation without random oracles. Theoretical Computer Science 410(47–49), 5093–
5111 (2009)
15. Kiltz, E., Vahlis, Y.: CCA2 secure IBE: Standard model eﬃciency through authen-
ticated symmetric encryption. In: Malkin, T. (ed.) CT-RSA 2008. LNCS, vol. 4964,
pp. 221–238. Springer, Heidelberg (2008)
16. Lee, K., Lee, D.H., Park, J.H.: Eﬃcient revocable identity-based encryption via
subset diﬀerence methods. Cryptology ePrint Archive, Report 2014/132 (2014).
http://eprint.iacr.org/
17. Libert, B., Vergnaud, D.: Adaptive-ID secure revocable identity-based encryption.
In: Fischlin, M. (ed.) CT-RSA 2009. LNCS, vol. 5473, pp. 1–15. Springer, Heidel-
berg (2009)
18. Naor, D., Naor, M., Lotspiech, J.: Revocation and tracing schemes for stateless
receivers. In: Kilian, J. (ed.) CRYPTO 2001. LNCS, vol. 2139, pp. 41–62. Springer,
Heidelberg (2001)
19. Seo, J.H., Emura, K.: Revocable identity-based encryption with rejoin functional-
ity. IEICE Transactions 97–A(8), 1806–1809 (2014)
20. Seo, J.H., Emura, K.: Revocable identity-based encryption revisited: security
model and construction. In: Kurosawa, K., Hanaoka, G. (eds.) PKC 2013.
LNCS, vol. 7778, pp. 216–234. Springer, Heidelberg (2013). http://eprint.iacr.
org/2013/016.pdf
21. Waters, B.: Eﬃcient identity-based encryption without random oracles. In: Cramer,
R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 114–127. Springer, Heidelberg
(2005)
22. Waters, B.: Dual system encryption: realizing fully secure IBE and HIBE under
simple assumptions. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol. 5677,
pp. 619–636. Springer, Heidelberg (2009)
www.ebook3000.com

Digital Signatures

Linkable Message Tagging: Solving the Key
Distribution Problem of Signature Schemes
Felix G¨unther1(B) and Bertram Poettering2
1 Cryptoplexity Group, Technische Universit¨at Darmstadt, Darmstadt, Germany
guenther@cs.tu-darmstadt.de
2 Foundations of Cryptography, Ruhr-Universit¨at Bochum, Bochum, Germany
http://www.foc.rub.de
Abstract. Digital signatures guarantee practical security only if the
corresponding veriﬁcation keys are distributed authentically; however,
arguably, satisfying solutions for the latter haven’t been found yet. This
paper introduces a novel approach for cryptographic message authen-
tication where this problem does not arise: A linkable message tagging
scheme (LMT) identiﬁes pairs of messages and accompanying authenti-
cation tags as related if and only if these tags were created using the same
secret key. Importantly, our primitive fully avoids public keys, and hence
elegantly sidesteps the key distribution problem of signature schemes.
As an application of LMT we envision an email authentication sys-
tem with minimal user interaction. Email clients could routinely equip
all outgoing messages with corresponding tags and verify for incoming
messages whether they indeed originate from the same entity as previ-
ously or subsequently received messages with identical sender address.
As technical contributions we formalize the notions of LMT and its
(more eﬃcient) variant CMT (classiﬁable message tagging), including
corresponding notions of unforgeability. For both variants we propose
a range of provably secure constructions, basing on diﬀerent hardness
assumptions, with and without requiring random oracles.
Keywords: Message authentication · Key distribution problem ·
Message tagging · Digital signatures
1
Introduction
Digital Signature Schemes. Digital signatures are an omnipresent cryptographic
primitive in today’s security landscape. Most prominently they ﬁnd application
as building blocks in message authentication, entity authentication, and in estab-
lishing trust relations in hierarchical public key infrastructures (PKIs). The ﬁrst
formal treatment of the security of signature schemes was given in 1984 when
Goldwasser, Micali, and Rivest coined the notion of existential unforgeability,
requiring that it be infeasible for any adaptive forging adversary to come up
with a valid signature on a fresh message, even in the presence of a signing
oracle. Despite the apparent strength of this notion, research eﬀort in the past
30 years resulted in a wide range of eﬃcient and provably secure constructions
available today.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 195–212, 2015.
DOI: 10.1007/978-3-319-19962-7 12
www.ebook3000.com

196
F. G¨unther and B. Poettering
Public Key Infrastructures. A remaining challenge for the practical security of
signature schemes is the authentic distribution of veriﬁcation keys: Trustwor-
thy authentication of messages or entities via signatures seems out of reach if
assurances on the genuineness of available veriﬁcation keys cannot be provided.
Indeed, if the adversary manages to replace real veriﬁcation keys by keys of its
own, all security is lost.
A variety of proposals to resolve this challenge exist. As a prime exam-
ple, hierarchical PKIs like those building on the X.509 standard [10] provide
certiﬁcate-based attestation that a given public key belongs to a certain real-
world user. Social PKIs, like the ‘web of trust’ underlying OpenPGP [5], consti-
tute an alternative approach towards the authentic distribution of keys. Here,
putting trust into centralized CAs is not required; instead, users establish trust
relationships by deciding on the genuineness of keys with the help and judgment
of ‘socially close’ other users.
Practical Obstacles in Email Authentication. On ﬁrst sight the two discussed
approaches towards the authentic distribution of cryptographic keys appear
sound and reliable. Moreover, when considering authentic email communication,
software implementations based on the S/MIME (i.e., X.509) and OpenPGP
standards are freely available as plugins for all modern mail clients. However, in
practice, large-scale deployment of email authentication for individuals, i.e., out-
side of organizations, fails to appear. Indeed, only a negligible fraction of Internet
users secures their email correspondence using cryptography. Partly responsible
for this might be the following technical and social obstacles:
– In respect to hierarchical PKIs: a practically unmanageable number of root
CAs, unclear trust relations to the CAs (see the compromises of DigiNotar
in 2011 [7], TURKTRUST in 2013 [17], and National Informatics Centre
of India in 2014 [8]), unclear authentication procedures during certiﬁcate
requests, and unclear revocation procedures.
– In respect to social PKIs: barriers introduced by time-consuming and error-
prone authentication procedures (e.g., in ‘key-signing parties’), complicated
user guidance in encryption software [19], and the privacy problem intro-
duced by publicly revealing social relationships on the key servers.
To summarize, all currently established approaches towards strong email authen-
tication come with speciﬁc usability barriers that seem insurmountable by the
broader public in practice.
A Novel Approach: History-Based Message Authentication. Assume a setting
in which two users, Alice and Bob, routinely communicate via email and at
some point have accumulated a communication history of, say, one year. Assume
further that an adversary wants to intervene in this communication by injecting
her own messages and making Bob accept them as originating from Alice. Such
an attack could clearly be recognized and thwarted if Alice would sign all her
outgoing messages and Bob would validate all incoming ones using an authentic
copy of Alice’s public key; however, motivated by the discussion above, in the

Linkable Message Tagging: Solving the Key Distribution Problem
197
following we abstain from assuming that Alice and Bob actively exchange any
veriﬁcation keys or follow any comparable explicit setup routine.
Our new concept of history-based message authentication builds on the idea
that the strong authentication of regularly occurring message transmissions can
be boot-strapped from a single authentic delivery (even if it is not known which
out of many transmissions the authentic one is). These preconditions are met
in the context of email communication where, arguably, a large fraction of mes-
sages reaches its destination in unmodiﬁed form. As we will elaborate, our new
paradigm of authentication does not involve any kind of interaction between
computer and user (except, possibly, if identiﬁed forgeries shall be reported),
and in particular does not require an explicit exchange of veriﬁcation keys. As
our method completely side-steps the obstacles of key distribution discussed
above, we envision that our new authentication model could contribute to make
email authentication practically accessible to the masses.
Theoretical Contributions. We explore the concept of history-based message
authentication by introducing the notion of linkable message tagging (LMT).
Brieﬂy, such schemes allow users holding a tagging key to equip given mes-
sages with corresponding tags; a dedicated linking predicate can then be used to
decide whether any two message-tag pairs originate from the same (anonymous)
sender, i.e., were created using the same key. Importantly, and in contrast to
signature schemes, users of LMT schemes do not have explicit identities, e.g., in
the form of public keys. However, if required, LMT schemes can be ‘upgraded’ to
the functionality and security properties of signature schemes by authentically
exchanging a speciﬁc reference token (that takes precisely the role of a veriﬁ-
cation key). Observe that this can be done at any time and seems particularly
helpful to resolve cases where LMT schemes identify forged messages.
An interesting subclass of LMT is given by classiﬁable message tagging
(CMT). Corresponding schemes are optimized for situations where messages
shall be automatically classiﬁed according to their origin. More concretely, in
CMT schemes, a dedicated algorithm computes for messages-tag pairs a cor-
responding class identiﬁer; the LMT linking predicate then reports matching
origins if and only if the respective class identiﬁers match. As we argue below,
this extended functionality is attractive in applications like email authentication.
To model security of LMT and CMT, we formalize notions of unforgeability:
Intuitively, schemes are unforgeable if no adversary can create, for any message
of its choosing, a tag that is identiﬁed by the scheme as originating from the
same source as a genuinely crafted message-tag pair.
Practical Contributions. On the constructive side we unveil tight connections
between the new primitives on the one hand and signature schemes on the other
(this might be surprising at ﬁrst sight, as the new primitives per se do not
involve public keys). These connections not only allow for generic constructions of
LMT and CMT schemes from signature schemes and vice versa, but also explain
notable similarities between our constructions and some well-known signature
schemes.
www.ebook3000.com

198
F. G¨unther and B. Poettering
signature
LMT
CMT
(Sec. 4.2)
(2)
(3)
(4)
(5)
Type Scheme
Setting
Assumption Model
LMT BLS-LMT (1)
Pairing
CDH
ROM
CMT Waters-CMT (FV) Pairing
CDH
CRS
CMT Schnorr-CMT (6)
Cyclic group DLP
ROM
LMT Sig-LMT (2)
as signature euf-cma
STD
CMT Sig-CMT (4)
as signature euf-cma
STD
Fig. 1. The ﬁgure on the left shows the conceptual relationship between signature
schemes, LMT schemes, and CMT schemes. The table on the right gives an overview
over the proposed direct (top) and generic (bottom) LMT and CMT constructions,
indicating whether proofs are in the standard (STD), random oracle (ROM), or com-
mon reference string (CRS) model. The numbers in parentheses indicate the respective
constructions (Waters-CMT is only deﬁned in the full version [9]).
We additionally put forward a couple of direct constructions of LMT and
CMT schemes, with and without random oracles, based on diﬀerent hardness
assumptions. An overview over our direct constructions and the (less eﬃcient)
generic signature-based constructions is given in Figure 1.
Envisioned Application: Automated Email Authentication. We consider the con-
cept of linkable message tagging valuable for implementing easy-to-use and fully-
automated cryptographic authentication of email communication; notably, LMT
and CMT do not rely on trusted third parties or on veriﬁcation keys exchanged
a priori. More concretely, we envision that email client software would automat-
ically setup tagging keys upon its ﬁrst execution, equip all outgoing emails with
corresponding LMT tags, and visually group together incoming emails according
to their origin (e.g., by color or position) without requiring any user interaction.
By consequence, adversarially crafted or manipulated emails would be displayed
diﬀerently than the authentic ones.
Pitfalls with na¨ıve Constructions Using Signature Schemes. We discuss why the
following ad-hoc approach towards linkable message tagging is insecure in gen-
eral: Using a regular signature scheme, users sign all outgoing emails and append
the signatures to the messages; after some time, users additionally disclose to
each other their respective veriﬁcation keys. Authenticity of these keys is then
veriﬁed by checking the validity of all signatures received so far; if all signatures
are valid, the corresponding key is considered authentic. What might at ﬁrst seem
to be a sound approach is in fact not: (strongly) unforgeable signature schemes
can be vulnerable to so-called duplicate-signature key selection (DSKS) attacks
in which the adversary aims at ﬁnding veriﬁcation keys that are valid for given
message-signature pairs [3,11,13]. Clearly, a DSKS-vulnerable signature scheme
will not yield a secure LMT scheme when employed in the construction just
described.
Related Work. Cryptographic solutions for message authentication in settings
without pre-shared keys are generally based on signature schemes [6], most often
in conjunction with hierarchical or non-hierarchical PKIs (like in X.509 [10]

Linkable Message Tagging: Solving the Key Distribution Problem
199
or OpenPGP [5]). As argued above, such approaches suﬀer from a variety of
usability problems, particularly when used outside of organizations [19].
An alternative to public-key-based message authentication is given by
identity-based signatures [16] that side-step the key distribution problem by
replacing participants’ veriﬁcation keys by just their identities. Problematic here,
however, is the required trustworthiness of the central authority (CA) that issues
the private keys: the key escrow problem, namely that the CA can compute
secret keys for any identity and thus impersonate it, is inherent to id-based
cryptography.
Certiﬁcateless signatures [1] can be seen as hybrid between PKI-based and
identity-based signatures, avoiding both the use of certiﬁcates and the key escrow
problem. Here, the CA issues only partial private keys; these need to be comple-
mented by the corresponding user to obtain the actual private/public key pair.
The public key can then be distributed non-authentically.
We note that the concept of message recognition [12,18] partially aims in the
direction of linkable message tagging. It was coined for settings where devices
with low computational power and communication bandwidth should, after
exchanging a small amount of authentic data, be able to afterwards recognize
each other’s messages. Comparable goals were also approached in ad-hoc net-
works based on location-limited side channels [2]. Note that both these notions
require an a priori or side-channel-based exchange of authenticated data.
2
Preliminaries
Notation. Let A, B be sets. For Q ⊆A × B and a ∈A we write (a, ·) ∈Q if
∃b ∈B : (a, b) ∈Q; we write (a, ·) ̸∈Q if ∀b ∈B : (a, b) ̸∈Q.
Fact 1 (Equivalence Kernel). Let A, B be sets and let f : A →B be a func-
tion. The equivalence relation ∼f on A deﬁned by a1 ∼f a2 ⇔f(a1) = f(a2) is
said to be the equivalence kernel of f. For all equivalence relations ∼on A we
observe that ∼is the equivalence kernel of projection A →A/∼; a 
→[a], where
[a] denotes the equivalence class of a.
Deﬁnition 1 (Reﬂexive Closure). Let A be a set and let R ⊆A × A be a
relation on A. We deﬁne Fix(A) = {(a, a) : a ∈A} and say that R ∪Fix(A) is
the reﬂexive closure of R.
We refer to the full version of this paper [9] for the notions of digital signature
schemes Σ = (KGen, Sign, Ver). Among others, we introduce symbols for the
message space M = {0, 1}∗, the signature space Sig, and the veriﬁcation key
space VK, and recall the security notions of (strong) existential unforgeability
under chosen-message attacks (euf-cma/suf-cma security).
3
Linkable Message Tagging Schemes
Our central contribution is the introduction of linkable message tagging (LMT)
schemes. This novel cryptographic primitive allows users, after having generated
www.ebook3000.com

200
F. G¨unther and B. Poettering
a (secret) tagging key, to take arbitrary messages and compute corresponding
LMT tags; other users can test for any two such message-tag pairs whether
they have the same origin, i.e., were generated using the same key. Notably,
this veriﬁcation is done without any further (public or secret) inputs. Brieﬂy
speaking, security requires that tags be unforgeable, i.e., no adversary can ﬁnd
a message-tag pair that appears to have the same origin as a genuine one.
3.1
Syntax and Security
We formalize LMT schemes by specifying their syntax, correctness, and security
properties.
Deﬁnition 2 (LMT Scheme). A linkable message tagging (LMT) scheme L =
(KGen, Tag, Link) consists of a message space M = {0, 1}∗, a tag space T , and
the following eﬃcient algorithms:
KGen(1λ): On input the security parameter, this probabilistic algorithm outputs
a tagging key tk.
Tag(tk, m): On input a tagging key tk and message m ∈M, this algorithm
outputs a tag τ ∈T .
Link(m1, τ1, m2, τ2): On input message-tag pairs (m1, τ1), (m2, τ2) ∈M × T ,
this deterministic algorithm outputs either 0 or 1. As a shortcut, we write
(m1, τ1) ∼(m2, τ2) if Link(m1, τ1, m2, τ2) = 1, otherwise (m1, τ1) ̸∼(m2, τ2).
An LMT scheme shall oﬀer a meaningful way to partition messages-tag pairs
according to their origin. We hence require that the Link algorithm deﬁnes an
equivalence relation on M × T , and that all message-tag pairs created using a
ﬁxed tagging key belong to the same equivalence class.
Deﬁnition 3 (Correctness of LMT Schemes). An LMT scheme L is cor-
rect if (a) for all λ ∈N, all tk ←R KGen(1λ), all m1, m2 ∈M, and all
τ1 ←R Tag(tk, m1) and τ2 ←R Tag(tk, m2), we have (m1, τ1) ∼(m2, τ2), i.e.,
Link(m1, τ1, m2, τ2) = 1, and (b) the Link algorithm deﬁnes an equivalence rela-
tion on M × T , i.e., if for all (m1, τ1), (m2, τ2), (m3, τ3) ∈M × T we have
– (m1, τ1) ∼(m1, τ1)
(Reﬂexivity)
– (m1, τ1) ∼(m2, τ2) ⇔(m2, τ2) ∼(m1, τ1)
(Symmetry)
– (m1, τ1) ∼(m2, τ2)∧(m2, τ2) ∼(m3, τ3) ⇒(m1, τ1) ∼(m3, τ3) (Transitivity)
The essential security property of LMT schemes is unforgeability: Given a
collection Q of genuine message-tag pairs, it shall be impossible to come up with a
tag τ ∗on a fresh message m∗such that (m∗, τ ∗) ∼(m, τ) for any pair (m, τ) ∈Q.
Akin to the security notions for signature schemes, we distinguish between two
variants of unforgeability: lmt-euf, and the (strictly) stronger lmt-suf.
Deﬁnition 4 (Unforgeability of LMT Schemes). An LMT scheme L is
(strongly) unforgeable ( lmt-euf, respectively lmt-suf) if for all eﬃcient adver-
saries A the success probability Succlmt-euf
L,A
(resp., Succlmt-suf
L,A
) is a negligible func-
tion where
Succlmt-euf
L,A
(λ) = Pr

Exptlmt-euf
L,A
(1λ) = 1

, Succlmt-suf
L,A
(λ) = Pr

Exptlmt-suf
L,A
(1λ) = 1


Linkable Message Tagging: Solving the Key Distribution Problem
201
Exptlmt-euf
L,A
(1λ):
(a) tk ←R KGen(1λ)
(b) (m∗, τ ∗) ←R AOTag(1λ)
(c) Return 1 iﬀall hold:
– (m∗, ·) ̸∈Q
– ∃(m, τ) ∈Q : (m∗, τ ∗) ∼(m, τ)
Exptlmt-suf
L,A
(1λ):
(a) tk ←R KGen(1λ)
(b) (m∗, τ ∗) ←R AOTag(1λ)
(c) Return 1 iﬀall hold:
– (m∗, τ ∗) ̸∈Q
– ∃(m, τ) ∈Q : (m∗, τ ∗) ∼(m, τ)
Processing of OTag(m):
(a) τ ←R Tag(tk, m)
(b) Q ←Q ∪{(m, τ)}
(c) Return τ
Fig. 2. Experiments for (strong) unforgeability of LMT schemes. We assume that
queries to OTag oracle are answered as speciﬁed on the right, and that set Q is ini-
tialized as Q ←∅.
are deﬁned in respect to the experiments from Figure 2, and the probabilities are
taken over the random coins of the respective experiment and the adversary.
3.2
A Direct LMT Construction
We show the existence of LMT schemes by giving a simple yet eﬃcient example.
Our construction is loosely related to the BLS signature scheme by Boneh, Lynn,
and Shacham [4] (cf. Figure 3) which enjoys strong unforgeability under the CDH
assumption in a pairing-friendly group, in the random oracle model.
Construction 1 (LMT Scheme BLS-LMT). The LMT scheme BLS-LMT is
deﬁned in respect to a (symmetric) bilinear group G and a hash function H: M →
G \ {1}. More precisely, for a set (G, GT , q, g, e) it is assumed that G = ⟨g⟩is a
cyclic group of prime order q and that e: G × G →GT is a bilinear map. The
tag space of BLS-LMT is T = G, and its algorithms are speciﬁed in Figure 3.
Proof of Correctness. Consider function f : M × T →Zq; (m, τ) 
→logH(m)(τ).
For arbitrary (m1, τ1), (m2, τ2) ∈M × T let α = f(m1, τ1) and β = f(m2, τ2),
i.e., τ1 = H(m1)α and τ2 = H(m2)β. By bilinearity and symmetry of e we
obtain
(m1, τ1) ∼(m2, τ2) ⇔e(H(m1), H(m2))β = e(H(m2), H(m1))α ⇔α = β.(1)
Together with Fact 1 this characterization of the Link algorithm allows an imme-
diate veriﬁcation of the requirements from Deﬁnition 3.
⊓⊔
We next analyze the security properties of BLS-LMT.
Theorem 1 (Security of BLS-LMT). The LMT scheme BLS-LMT is strongly
unforgeable ( lmt-suf) if the CDH assumption holds in G and H is modeled as a
random oracle. By consequence, the scheme is also unforgeable ( lmt-euf).
Proof. We reduce the strong unforgeability of the BLS-LMT scheme to the
strong unforgeability of the BLS signature scheme (deﬁned over the same bilinear
group). Together with Fact 2 below, this establishes the statement.
www.ebook3000.com

202
F. G¨unther and B. Poettering
KGen(1λ):
x ←R Zq
X ←gx
Output (sk, vk) = (x, X)
Sign(sk, m):
Output σ = H(m)x
Ver(vk, m, σ):
If e(σ, g) = e(H(m), X)
output 1,
else output 0
KGen(1λ):
x ←R Zq
Output tk = x
Tag(tk, m):
Output τ = H(m)x
Link(m1, τ1, m2, τ2):
If e(H(m1), τ2) = e(H(m2), τ1)
output 1,
else output 0
Fig. 3. Signature scheme BLS (top) and LMT scheme BLS-LMT (bottom). For further
details see Construction 1.
From an eﬃcient adversary A against lmt-suf of BLS-LMT we construct an
eﬃcient adversary B against suf-cma of BLS. Concretely, B(vk) runs A(1λ) as a
subroutine. Each oracle query OTag(m) posed by A is forwarded by B as OSign(m)
to its own oracle, and the result is relayed to A (observe that this is a perfect
simulation). Finally, when A outputs a candidate tag forgery (m∗, τ ∗), B outputs
the same pair and stops.
Assume A is successful, i.e., (m∗, τ ∗) is a valid tag forgery. By deﬁnition we
then have e(H(m∗), H(m)x) = e(H(m), τ ∗) for x = logg vk and some m. This
equation can only hold if τ ∗= H(m∗)x, i.e., τ ∗is a valid BLS signature on m∗.
Further on, as τ ∗is not the result of an OTag(m∗) query, this signature was also
not output on input m∗by B’s OSign oracle, i.e., adversary B is successful in
forging a signature. We hence have Succsuf-cma
BLS,B (λ) = Succlmt-suf
BLS-LMT,A(λ). As the
left-hand side is negligible by assumption, this completes the proof.
⊓⊔
Fact 2 (Unforgeability of BLS Signature Scheme [4]). The BLS signa-
ture scheme is existentially unforgeable (euf-cma) if the CDH assumption holds
in G and H is modeled as a random oracle. Moreover, the scheme has unique
signatures and is hence strongly unforgeable (suf-cma).
3.3
On the Generic Relation Between Signature and LMT Schemes
We now explore the relationship between signature schemes and LMT schemes.
Perhaps surprisingly, from an engineer’s point of view, the notions are quite
close: LMT schemes and signature schemes can be constructed from each other,
and the corresponding transformations are natural and eﬃcient. On the other
side of the coin this tight connection implies that there is little hope to obtain
practical LMT constructions from just symmetric primitives like blockciphers,
hash functions, or PRFs, although LMT schemes per se do not require public
keys.
We begin with transforming signature schemes into LMT schemes. The idea
behind our construction is to use signing keys as tagging keys and signatures
with attached veriﬁcation keys as tags, i.e., T = Sig × VK; precisely, a tag for
a message m is a pair τ = (σ, vk) such that σ is a signature on m in respect to

Linkable Message Tagging: Solving the Key Distribution Problem
203
veriﬁcation key vk. Intuitively, in order to test whether two message-tag pairs are
in LMT relation, one checks that the veriﬁcation keys match and both signatures
are valid. This minimum requirement on the Link algorithm is formally expressed
by binary relation RM, deﬁned on M × T = M × Sig × VK as follows:
(m1,σ1,vk1)RM (m2,σ2,vk2) ⇔vk1 =vk2 ∧Ver(vk1,m1,σ1)=1=Ver(vk2,m2,σ2).
Observe that this relation is symmetric and transitive. However, it is not
reﬂexive, and hence does not induce a correct LMT scheme, as message-tag
pairs with invalid signatures are not in relation to themselves. Fixing this prob-
lem by adding further elements to RM requires special care: intuitively, LMT
security is diluted by putting valid and invalid tags into relation. Generic can-
didate elements that can be safely added to RM seem to be those from binary
relation R0, deﬁned on M × Sig × VK such that
(m1, σ1, vk1) R0 (m2, σ2, vk2)
⇔
Ver(vk1, m1, σ1) = 0 = Ver(vk2, m2, σ2).
Concluding, we say that an equivalence relation R on M×Sig×VK is admissible
if RM ⊆R ⊆RM ∪R0. Many such relations exist in general, but two natural
choices for R are
– R1:1
M = RM ∪Fix(M × Sig × VK), i.e., the reﬂexive closure of RM (see
Deﬁnition 1). This is the ﬁnest possible admissible relation, where no invalid
message-tag pair is related to any other (valid or invalid) message-tag pair.
– R∗:1
M = RM ∪R0, i.e., the coarsest possible admissible relation. Here, all
invalid message-tag pairs are in relation to each other, i.e., belong to the
same equivalence class.
Lemma 1. R1:1
M and R∗:1
M are admissible equivalence relations.
Proof. Let X = M×Sig×VK. Observe that for each a = (m, σ, vk) ∈X we have
either Ver(vk, m, σ) = 1 and (a, a) ∈RM, or Ver(vk, m, σ) = 0 and (a, a) ∈R0.
In other words, Fix(X) ⊆RM ∪R0.
We ﬁrst consider R1:1
M . Reﬂexivity and symmetry are clear. To show transitiv-
ity, let a, b, c ∈X with (a, b), (b, c) ∈R1:1
M . Nothing is to show if (a, b) ∈Fix(X)
or (b, c) ∈Fix(X). Thus assume (a, b), (b, c) ∈RM. Transitivity of RM implies
(a, c) ∈RM ⊆R1:1
M . Admissibility follows from Fix(X) ⊆RM ∪R0.
We next consider R∗:1
M . Reﬂexivity follows from Fix(X) ⊆RM ∪R0 = R∗:1
M .
Symmetry is clear. To show transitivity, let a, b, c ∈X with (a, b), (b, c) ∈R∗:1
M .
Then either (a, b), (b, c) ∈RM or (a, b), (b, c) ∈R0. In both cases (a, c) ∈R∗:1
M
follows. Admissibility is clear.
⊓⊔
We are now ready to specify our signature-based LMT scheme. More pre-
cisely, we deﬁne a family of schemes, parameterized by an admissible equiva-
lence relation R. We stress that the security achieved by our LMT construction
is independent of the speciﬁc relation in use (as long as it is admissible) as the
latter inﬂuences only how invalid message-tag pairs are grouped together. Deﬁn-
ing our construction in respect to arbitrary admissible relations leaves ﬂexibility
to the user of the scheme—it is the application that determines whether R1:1
M ,
R∗:1
M , or any other admissible relation is the favorable one.
www.ebook3000.com

204
F. G¨unther and B. Poettering
Construction 2 (LMT Scheme Sig-LMT from a Generic Signature
Scheme). Let Σ be a signature scheme with message space M = {0, 1}∗, signa-
ture space Sig, and veriﬁcation key space VK. Let R be an admissible equivalence
relation on M × Sig × VK. Deﬁne the LMT scheme Sig-LMT in respect to R
with tag space T = Sig × VK as follows:
KGen(1λ): Set (sk, vk) ←R Σ.KGen(1λ) and output tagging key tk = (sk, vk).
Tag(tk, m): Compute σ ←R Sign(sk, m) and output tag τ = (σ, vk).
Link(m1, τ1, m2, τ2): Parse τ1 as (σ1, vk1) and τ2 as (σ2, vk2). Output 1 if (m1,
σ1, vk1) R (m2, σ2, vk2). Otherwise, output 0.
Correctness of Sig-LMT follows directly from the deﬁnition of admissibility. The
scheme’s unforgeability properties are analyzed in Theorem 2; as mentioned
above, they are independent of the particular choice of relation R.
Theorem 2 (Security of Sig-LMT). For any admissible equivalence relation
R, the LMT scheme Sig-LMT deﬁned in respect to R is (strongly) unforgeable if
the underlying signature scheme Σ is (strongly) unforgeable.
Proof. We reduce the unforgeability of the Sig-LMT scheme to the unforgeability
of the Σ signature scheme. The proof can easily be adapted to cover the strong
variants of the corresponding security notions.
From an eﬃcient adversary A against lmt-euf of Sig-LMT we construct an
eﬃcient adversary B against euf-cma of Σ. Concretely, B(vk) runs A(1λ) as
a subroutine. Each oracle query OTag(m) posed by A is forwarded by B as
σ ←OSign(m) to its own oracle, and τ = (σ, vk) is answered to A (observe that
this is a perfect simulation). Let Q denote the collection of all occurring such
pairs (m, σ). Finally, when A outputs a candidate tag forgery (m∗, τ ∗), B parses
τ ∗as (σ∗, vk∗), outputs σ∗, and stops.
Assume A is successful, i.e., (m∗, τ ∗) is a valid tag forgery. By deﬁnition we
then have (m∗, σ∗, vk∗) R (m, σ, vk) for some (m, σ) ∈Q. As Ver(vk, m, σ) = 1
by construction, we particularly have (m∗, σ∗, vk∗) RM (m, σ, vk), i.e., Ver(vk,
m∗, σ∗) = 1. Further on, as m∗was never queried to the OTag oracle, it was
also not queried to B’s OSign oracle, i.e., adversary B is successful in forging a
signature. We hence have Succeuf-cma
Σ,B
(λ) = Succlmt-euf
Sig-LMT,A(λ). As the left-hand
side is negligible by assumption, this completes the proof.
⊓⊔
We next transform LMT schemes into signature schemes. The intuition
behind our construction is to use tags as signatures and to include a reference
message-tag pair in the veriﬁcation key against which candidate signatures (i.e.,
tags) can be aligned. However, doing so na¨ıvely would not result in an unforge-
able signature scheme: an adversary could just output the reference pair as a
forgery. We deploy a technical solution to this problem in Construction 3: the
ﬁxed preﬁx "1" is prepended to all signed messages, preventing collision with
the "0" message used for the reference tag.
Construction 3 (Signature Scheme LMT-Sig from a Generic LMT
Scheme). Let L be an LMT scheme with tag space T . Deﬁne the signature
scheme LMT-Sig with Sig = VK = T as follows:

Linkable Message Tagging: Solving the Key Distribution Problem
205
KGen(1λ): Set tk ←R L.KGen(1λ), compute τ0 ←Tag(tk, "0"), and output key
pair (sk, vk) = (tk, τ0).
Sign(sk, m): Compute τ ←Tag(tk, "1"∥m) and output signature σ = τ.
Ver(vk, m, σ): Output Link("1"∥m, σ, "0", τ0).
Correctness of LMT-Sig follows from correctness of L. The unforgeability of
Construction 3 is assessed as follows.
Theorem 3 (Security
of
LMT-Sig).
The signature scheme LMT-Sig is
(strongly) unforgeable if the underlying LMT scheme L is (strongly) unforgeable.
Proof. We reduce the unforgeability of the LMT-Sig signature scheme to the
unforgeability of LMT scheme L. The proof can easily be adapted to cover the
strong variants of the corresponding security notions.
From an eﬃcient adversary A against euf-cma of LMT-Sig we construct an
eﬃcient adversary B against lmt-euf of L. Concretely, B(1λ) starts by posing a
τ0 ←OTag("0") query to its tagging oracle. Then B runs A, on input vk = τ0,
as a subroutine. Each oracle query OSign(m) posed by A is forwarded by B as
OTag("1"∥m) to its own oracle, and the result is relayed to A (observe that this
is a perfect simulation). Finally, when A outputs a candidate signature forgery
(m∗, σ∗), B outputs ("1"∥m∗, σ∗) and stops.
Assume A is successful, i.e., (m∗, σ∗) is a valid signature forgery. By def-
inition we then have Link("1" ∥m∗, σ∗, "0", τ0) = 1. Further on, as m∗was
never queried to the OSign oracle, "1" ∥m∗was also not queried to the
OTag oracle, i.e., adversary B is successful in forging a tag. We hence have
Succlmt-euf
L,B
(λ) = Succeuf-cma
LMT-Sig,A(λ). As the left-hand side is negligible by assump-
tion, this completes the proof.
⊓⊔
4
Classiﬁable Message Tagging Schemes
The main functionality of LMT schemes is the partitioning of message-tag pairs
into sets according to their origin. Correspondingly, Deﬁnition 3 requires the
Link algorithm to induce an equivalence relation ∼on the message-tag space
M × T such that, essentially, each equivalence class corresponds to one origin.
Note that, so far, the used notion of origin is only virtual: it does not explicitly
appear in syntax, correctness, or security deﬁnition of LMT schemes. In other
words, although the Link algorithm always implies existence of projection
π: M × T →(M × T )/∼; (m, τ) 
→[m, τ]
that maps message-tag pairs to their ‘origin’ (cf. Fact 1), there is no formal
requirement in Section 3 that demands that this mapping be eﬀectively com-
putable.
We argue that for many natural applications of the LMT primitive the direct
computability of π would be quite desirable. Assume, for instance, a mail client
that is instructed to automatically classify received emails according to their
www.ebook3000.com

206
F. G¨unther and B. Poettering
origin. In such a setting, for each incoming email m with corresponding tag τ,
the Link algorithm of a plain LMT scheme would have to be invoked several
times, namely at least once for each priorly identiﬁed class of origin. If, however,
we assume existence of an eﬃcient projection π as deﬁned above, the mail client
could sort any email directly, i.e., without any further pair-wise computation,
into a folder of name ρ ◦π(m, τ), where injective function ρ: (M × T )/∼→
{0, 1}∗assigns a (unique) label to each origin.
In this section we introduce an LMT variant called classiﬁable message tag-
ging (CMT); such schemes are equipped with a dedicated algorithm for the eﬃ-
cient computation of ρ ◦π, for an adequate labeling scheme ρ. We will deﬁne the
adapted syntax and security notions, study formal relations between the CMT
and LMT primitives, and ﬁnally identify generic CMT constructions. We leave
the direct construction of (more eﬃcient) instances to Section 5.
4.1
Syntax and Security
The syntactical diﬀerence between LMT and CMT schemes is that the Link
algorithm is replaced by the new Classify algorithm that shall compute ρ ◦π. In
contrast to the introduction given above, we assume that the labels output by
Classify are elements of an abstract set C of class identiﬁers; the only restriction
on C is that its elements can be tested for equality.
Deﬁnition 5 (CMT Scheme). A classiﬁable message tagging (CMT) scheme
C = (KGen, Tag, Classify) consists of a message space M = {0, 1}∗, a tag space T ,
a class identiﬁer space C, and the following eﬃcient algorithms:
KGen(1λ): On input the security parameter, this probabilistic algorithm outputs
a tagging key tk.
Tag(tk, m): On input a tagging key tk and message m ∈M, this algorithm
outputs a tag τ ∈T .
Classify(m, τ): On input a message-tag pair (m, τ) ∈M × T , this deterministic
algorithm outputs a class identiﬁer cid ∈C.
Correctness of CMT schemes requires that for any two pairs of message and
corresponding tag (created with the same tagging key) the Classify algorithm
outputs the same class identiﬁer:
Deﬁnition 6 (Correctness of CMT Schemes). A CMT scheme C is correct
if for all λ ∈N, all tk ←R KGen(1λ), all m1, m2 ∈M, and all τ1 ←R Tag(tk, m1)
and τ2 ←R Tag(tk, m2), we have Classify(m1, τ1) = Classify(m2, τ2).
Deﬁnition 7 (Key-Speciﬁc Class Identiﬁer cidtk). Consider a (correct)
CMT scheme C and a ﬁxed key tk ←R KGen(1λ). For any message m ∈M,
compute τ ←R Tag(tk, m) and cid ←Classify(m, τ). Then the correctness of
C ensures that cid is independent of both m and the randomness used in the
Tag algorithm. In other words, for each tagging key tk there exists a (uniquely)
corresponding key-speciﬁc class identiﬁer cidtk deﬁned in this way.

Linkable Message Tagging: Solving the Key Distribution Problem
207
Exptcmt-euf
C,A
(1λ):
(a) tk ←R KGen(1λ)
(b) (m∗, τ ∗) ←R AOTag(1λ)
(c) Return 1 iﬀall hold:
– (m∗, ·) ̸∈Q
– Classify(m∗, τ ∗) = cidtk
Exptcmt-suf
C,A
(1λ):
(a) tk ←R KGen(1λ)
(b) (m∗, τ ∗) ←R AOTag(1λ)
(c) Return 1 iﬀall hold:
– (m∗, τ ∗) ̸∈Q
– Classify(m∗, τ ∗) = cidtk
Processing of OTag(m):
(a) τ ←R Tag(tk, m)
(b) Q ←Q∪{(m, τ)}
(c) Return τ
Fig. 4. Experiments for (strong) unforgeability of CMT schemes. We assume that
queries to OTag oracle are answered as speciﬁed on the right, and that set Q is initialized
as Q ←∅.
Similarly to LMT schemes, we deﬁne unforgeability as the essential security
property of CMT schemes: Given a collection of genuine message-tag pairs for a
ﬁxed class identiﬁer cidtk, it shall be impossible to come up with a tag τ ∗on a
fresh message m∗such that Classify(m∗, τ ∗) = cidtk. We again distinguish two
variants of unforgeability, namely cmt-euf, and the (strictly) stronger cmt-suf.
Deﬁnition 8 (Unforgeability of CMT Schemes). A CMT scheme C is
(strongly) unforgeable (cmt-euf, respectively cmt-suf) if for all eﬃcient adver-
saries A the success probability Succcmt-euf
C,A
(resp., Succcmt-suf
C,A
) is a negligible func-
tion where
Succcmt-euf
C,A
(λ) = Pr

Exptcmt-euf
C,A
(1λ) = 1

, Succcmt-suf
C,A
(λ) = Pr

Exptcmt-suf
C,A
(1λ) = 1

are deﬁned in respect to the experiments from Figure 4, and the probabilities are
taken over the random coins of the respective experiment and the adversary.
4.2
CMT Schemes are Special LMT Schemes
We motivated the introduction of CMT schemes with the interest in a specially
optimized LMT variant. However, it is not immediately apparent that schemes
deﬁned in accordance with Deﬁnitions 5–8 are indeed of the LMT type. We
next give formal evidence for this relation, both syntax-wise and security-wise.
Interestingly, as we elaborate in the full version, the reverse relation does not
hold in general, i.e., there exist LMT schemes that do not have a CMT analogue.
Let C = (KGen, Tag, Classify) be an arbitrary CMT scheme with message
space M and tag space T . Deﬁne the following auxiliary algorithm:
Link(m1, τ1, m2, τ2): On input message-tag pairs (m1, τ1), (m2, τ2) ∈M×T out-
put 0 or 1 such that the following condition is met:
Link(m1, τ1, m2, τ2) = 1
⇔
Classify(m1, τ1) = Classify(m2, τ2).
(2)
Given this, deﬁne the LMT scheme corresponding to C as L = (KGen, Tag, Link).
Regarding its correctness, note that condition (a) of Deﬁnition 3 is fulﬁlled due
to the correctness of C, and that condition (b) follows from (2) in conjunction
with Fact 1. In addition, a comparison of Figures 2 and 4 readily establishes the
following relation between security notions.
www.ebook3000.com

208
F. G¨unther and B. Poettering
Lemma 2 (Unforgeability of C is Equivalent to Unforgeability of L). A
CMT scheme is cmt-euf (resp. cmt-suf) if and only if the corresponding LMT
scheme is lmt-euf (resp. lmt-suf).
⊓⊔
4.3
On the Generic Relation Between Signature and CMT Schemes
In Section 3.3 we showed how to construct LMT schemes from signature schemes
and vice versa. We analyze next if similar results also hold in the CMT setting.
We will ﬁrst focus on how to generically obtain CMT schemes from signa-
ture schemes. Recall that we based our corresponding transformation in the LMT
setting on an arbitrary admissible equivalence relation R that determines how
invalid tags are grouped together (cf. Construction 2). This oﬀers a degree of
freedom that we implicitly exploit when constructing our signature-based CMT
scheme Sig-CMT presented below: the key observation is that Construction 2
with R = R∗:1
M yields exactly the same LMT scheme as is obtained by under-
standing Sig-CMT as an LMT scheme in the terms of Section 4.2. Indeed, in both
cases message-tag pairs are in relation exactly when either both tags are valid
and the veriﬁcation keys match (the latter serve as key-speciﬁc class identiﬁers
in Sig-CMT), or when the tags are both invalid.
Construction 4 (CMT Scheme Sig-CMT from a Generic Signature
Scheme). Let Σ be a signature scheme with signature space Sig and veriﬁcation
key space VK. Deﬁne the CMT scheme Sig-CMT with tag space T = Sig × VK
and class identiﬁer space C = VK ˙∪{⊥} (where ˙∪denotes the disjoint union) as
follows:
KGen(1λ): Set (sk, vk) ←R Σ.KGen(1λ) and output tagging key tk = (sk, vk).
Tag(tk, m): Compute σ ←R Sign(sk, m) and output tag τ = (σ, vk).
Classify(m, τ): Parse τ as (σ, vk). Output cid = vk if Ver(vk, m, σ) = 1. Other-
wise, output cid = ⊥.
Correctness of the scheme is obvious. Concerning its security claim, by Lemma 2
it suﬃces to prove the (strong) unforgeability of the LMT scheme corresponding
to Sig-CMT. Following the observations above, as the latter scheme results from
Construction 2 with R = R∗:1
M , Theorem 2 and Lemma 1 establish the following
security result.
Theorem 4 (Security of Sig-CMT). The CMT scheme Sig-CMT is (strongly)
unforgeable if the underlying signature scheme Σ is (strongly) unforgeable.
⊓⊔
The next step is to generically construct a signature scheme from a CMT
scheme. That this works in principle is not surprising by our earlier results:
CMT schemes are just special LMT schemes, and the latter already imply
signature schemes. We observe, however, that the following generic construc-
tion is slightly more eﬃcient.
Construction 5 (Signature Scheme CMT-Sig from a Generic CMT
Scheme). Let C be a CMT scheme with tag space T and class identiﬁer space C.
Deﬁne the signature scheme CMT-Sig as follows:

Linkable Message Tagging: Solving the Key Distribution Problem
209
KGen(1λ): Set tk ←R C.KGen(1λ) and compute corresponding key-speciﬁc class
identiﬁer cidtk. Output key pair (sk, vk) = (tk, cidtk).
Sign(sk, m): Compute τ ←R Tag(tk, m) and output signature σ = τ.
Ver(vk, m, σ): Output 1 if Classify(m, τ) = cidtk. Otherwise, output 0.
Correctness of CMT-Sig follows from the correctness of C. Observe that,
regarding its security statement, we had to strengthen the precondition in com-
parison to Theorem 3 for a technical reason.
Theorem 5 (Security of CMT-Sig). If M has super-polynomial cardinality,
the signature scheme CMT-Sig is (strongly) unforgeable if the underlying CMT
scheme C is (strongly) unforgeable.
Proof. We reduce the unforgeability of the CMT-Sig signature scheme to the
unforgeability of CMT scheme C. The proof can easily be adapted to cover the
strong variants of the corresponding security notions.
From an eﬃcient adversary A against euf-cma of CMT-Sig we construct an
eﬃcient adversary B against cmt-euf of C. Concretely, after ﬁxing a ﬁnite sub-
set M0 ⊆M of super-polynomial size, B(1λ) starts by picking a random message
m0 ←R M0, posing a τ0 ←OTag(m0) query to its tagging oracle, and comput-
ing key-speciﬁc class identiﬁer cid ←Classify(m0, τ0). Then B runs A, on input
vk = cid, as a subroutine. Each oracle query OSign(m) posed by A is forwarded
by B as OTag(m) to its own oracle, and the result is relayed to A (observe that
this is a perfect simulation). Finally, when A outputs a candidate signature
forgery (m∗, σ∗), B outputs the same pair and stops.
Assume A is successful, i.e., (m∗, σ∗) is a valid signature forgery. By deﬁnition
we then have Classify(m∗, σ∗) = cid. Further on, as m∗was never queried to the
OSign oracle, either we have m∗= m0 (with negligible probability ϵ ≤1/|M0|),
or m∗was not queried to B’s OTag oracle, i.e., adversary B is successful in forging
a tag. We hence have Succcmt-euf
C,B
(λ) = Succeuf-cma
CMT-Sig,A(λ)−ϵ. As both the left-hand
side and ϵ are negligible by assumption, this completes the proof.
⊓⊔
5
Practical Classiﬁable Message Tagging Constructions
We focus next on practical, eﬃciency-optimized CMT constructions. Our moti-
vation comes from the observation that the generic methods from Construc-
tion 4 demand a signature scheme’s veriﬁcation key to be included in every
tag; as we reveal, this is not required in direct, i.e., non-generic constructions.
Indeed, we propose a CMT scheme with more compact tags, deﬁned over a
prime-order cyclic group with security under the DLP assumption in the random
oracle model. Interestingly, the construction is implicitly based on a signature
scheme where the veriﬁcation key can be uniquely reconstructed from any (valid)
signature.
In the full version of this paper [9] we further present an eﬃcient CMT scheme
that does not require random oracles, discuss our (fruitless) eﬀorts of ﬁnding
factoring-based CMT or LMT constructions, and explore whether signatures
from standardized email authentication schemes (OpenPGP and S/MIME) can
be reinterpreted in the CMT or LMT sense.
www.ebook3000.com

210
F. G¨unther and B. Poettering
KGen(1λ):
x ←R Zq
X ←gx
Output (sk, vk) = (x, X)
Sign(sk, m):
k ←R Zq, R ←gk
c ←H(m, R)
s ←k + xc mod q
Output σ = (R, s)
Ver(vk, m, σ):
Parse σ as (R, s)
If gs = RXH(m,R)
output 1,
else output 0
KGen(1λ):
x ←R Zq
Output tk = x
Tag(tk, m):
k ←R Zq, R ←gk
c ←H(m, R)
s ←k + xc mod q
Output τ = (R, s)
Classify(m, τ):
Parse τ as (R, s)
cid ←(gs/R)1/H(m,R)
Output cid
Fig. 5. Signature scheme Schnorr (top) and CMT scheme Schnorr-CMT (bottom). For
further details see Construction 6.
5.1
A Highly Practical CMT Scheme Based on the DLP
Our direct CMT construction is based on the Schnorr signature scheme
(cf. Schnorr [15] and Figure 5) and exploits the fact that in the latter the ver-
iﬁcation key can be reconstructed from any valid signature, requiring only one
(multi-)exponentiation. Interestingly this does not hold for the related signature
schemes DSA and ECDSA, as we explore in the full version of this paper [9].
We specify the new scheme as follows:
Construction 6 (CMT
Scheme
Schnorr-CMT).
The
CMT
scheme
Schnorr-CMT is deﬁned in respect to a cyclic group G = ⟨g⟩of prime order q and
a hash function H : M×G →Zq. The tag space of Schnorr-CMT is T = G×Zq,
the class identiﬁer space is C = G, and its algorithms are speciﬁed in Figure 5.
For the correctness of Schnorr-CMT observe that for all m1, m2 ∈M and r1, r2 ∈
Zq we have
(gs1/R1)1/H(m1,R1) =(gk1+xc1/gk1)1/c1 =gx=(gk2+xc2/gk2)1/c2 =(gs2/R2)1/H(m2,R2).
In other words, for tagging key tk we have the key-speciﬁc class identiﬁer cidtk =
gtk (which corresponds exactly with the veriﬁcation key in the Schnorr scheme).
We establish the security of Schnorr-CMT as follows.
Theorem 6 (Security of Schnorr-CMT). The CMT scheme Schnorr-CMT is
strongly unforgeable (cmt-suf) if the DLP is hard in G and H is modeled as a
random oracle. By consequence, the scheme is also unforgeable (cmt-euf).
Proof. We reduce the strong unforgeability of Schnorr-CMT to the strong exis-
tential unforgeability of the Schnorr signature scheme. Together with Fact 3
below, this establishes the statement.
From an eﬃcient adversary A against cmt-suf of Schnorr-CMT we construct
an eﬃcient adversary B against suf-cma of Schnorr. Concretely, B(vk) runs A(1λ)
as a subroutine. Each oracle query OTag(m) posed by A is forwarded by B as

Linkable Message Tagging: Solving the Key Distribution Problem
211
OSign(m) to its own oracle, and the result is relayed to A (observe that this is a
perfect simulation). Finally, when A outputs a candidate tag forgery (m∗, τ ∗),
B outputs the same pair and stops.
Assume A is successful, i.e., (m∗, τ ∗) with τ ∗= (R∗, s∗) is a valid tag
forgery. By deﬁnition we then have (gs∗/R∗)1/H(m∗,R∗) = cidtk = gtk, i.e.,
gs∗= R∗(gtk)H(m∗,R∗), hence in particular τ ∗is a valid Schnorr signature on m∗.
Further on, as m∗was never queried to the OTag oracle with answer τ ∗, it was
also not queried to B’s OSign oracle with that answer, i.e., adversary B is success-
ful in forging a signature. We hence have Succsuf-cma
Schnorr,B(λ) = Succcmt-suf
Schnorr-CMT,A(λ).
As the left-hand side is negligible by assumption, this completes the proof.
⊓⊔
Fact 3 (Unforgeability of Schnorr Signature Scheme [14]). The Schnorr
signature scheme is strongly existentially unforgeable (suf-cma) if DLP is hard
in G and H is modeled as a random oracle.1
6
Conclusion and Open Problems
This paper approaches the key distribution problem of classical signature
schemes from an entirely new direction: Our notions of linkable and classiﬁ-
able message tagging (LMT and CMT) allow to unambiguously decide whether
pairs of messages and authentication tags originate from the same source (i.e.,
tagging key). This is achieved without requiring a special setup (e.g., a pre-
shared authentic veriﬁcation key or a PKI). We construct secure instantiations
of the new primitives, both with and without random oracles (for the latter see
the full version [9]), based on diﬀerent hardness assumptions.
Acknowledgments. The authors thank all anonymous reviewers for their valuable
comments. Both authors were supported by the German Federal Ministry of Education
and Research (BMBF) within EC SPRIDE, and Bertram Poettering additionally by
EPSRC Leadership Fellowship EP/H005455/1 and a Sofja Kovalevskaja Award of the
Alexander von Humboldt Foundation. This work has been co-funded by the German
Research Foundation (DFG) as part of project S4 within the CRC 1119 CROSSING.
References
1. Al-Riyami, S.S., Paterson, K.G.: Certiﬁcateless public key cryptography. In: Laih,
C.-S. (ed.) ASIACRYPT 2003. LNCS, vol. 2894, pp. 452–473. Springer, Heidelberg
(2003)
2. Balfanz, D., Smetters, D.K., Stewart, P., Wong, H.C.: Talking to strangers: authen-
tication in ad-hoc wireless networks. In: NDSS 2002. The Internet Society, February
2002
1 Although the statement proven by Pointcheval and Stern [14] considers only euf-cma
security, their results can readily be extended to also cover the suf-cma notion.
www.ebook3000.com

212
F. G¨unther and B. Poettering
3. Blake-Wilson, S., Menezes, A.: Unknown key-share attacks on the station-to-
station (STS) protocol. In: Imai, H., Zheng, Y. (eds.) PKC 1999. LNCS, vol. 1560,
pp. 154–170. Springer, Heidelberg (1999)
4. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the weil pairing. In: Boyd,
C. (ed.) ASIACRYPT 2001. LNCS, vol. 2248, pp. 514–532. Springer, Heidelberg
(2001)
5. Callas, J., Donnerhacke, L., Finney, H., Shaw, D., Thayer, R.: OpenPGP Message
Format. RFC 4880 (Proposed Standard), November 2007. http://www.ietf.org/
rfc/rfc4880.txt. Updated by RFC 5581
6. Diﬃe, W., Hellman, M.E.: New directions in cryptography. IEEE Transactions on
Information Theory 22(6), 644–654 (1976)
7. Fox-IT: Black Tulip – Report of the investigation into the DigiNotar Certiﬁ-
cate Authority breach, August 2012. http://www.rijksoverheid.nl/bestanden/
documenten-en-publicaties/rapporten/2012/08/13/black-tulip-update/
black-tulip-update.pdf
8. Google
Online
Security
Blog:
Maintaining
digital
certiﬁcate
secu-
rity,
July
2014.
http://googleonlinesecurity.blogspot.de/2014/07/
maintaining-digital-certiﬁcate-security.html
9. G¨unther, F., Poettering, B.: Linkable Message Tagging: Solving the key distribution
problem of signature schemes. Cryptology ePrint Archive, Report 2014/014 (2014).
http://eprint.iacr.org/2014/014
10. Kaliski, B.: PKCS #7: Cryptographic Message Syntax Version 1.5. RFC 2315
(Informational), March 1998. http://www.ietf.org/rfc/rfc2315.txt
11. Koblitz, N., Menezes, A.: Another look at security deﬁnitions. Advances in Math-
ematics of Communications 7(1), 1–38 (2013)
12. Mashatan, A., Vaudenay, S.: A message recognition protocol based on standard
assumptions. In: Zhou, J., Yung, M. (eds.) ACNS 2010. LNCS, vol. 6123, pp. 384–
401. Springer, Heidelberg (2010)
13. Menezes, A., Smart, N.P.: Security of signature schemes in a multi-user setting.
Designs, Codes and Cryptography 33(3), 261–274 (2004)
14. Pointcheval, D., Stern, J.: Security arguments for digital signatures and blind sig-
natures. Journal of Cryptology 13(3), 361–396 (2000)
15. Schnorr, C.P.: Eﬃcient signature generation by smart cards. Journal of Cryptology
4(3), 161–174 (1991)
16. Shamir, A.: Identity-based cryptosystems and signature schemes. In: Blakely, G.R.,
Chaum, D. (eds.) CRYPTO 1984. LNCS, vol. 196, pp. 47–53. Springer, Heidelberg
(1985)
17. TURKTRUST
Information
Security
Services
Inc.:
Public
Announcements,
January
2013.
http://www.turktrust.com.tr/en/about-us/news-detail/
kamuoyu-aciklamalari
18. Weimerskirch, A., Westhoﬀ, D.: Zero common-knowledge authentication for perva-
sive networks. In: Matsui, M., Zuccherato, R.J. (eds.) SAC 2003. LNCS, vol. 3006,
pp. 73–87. Springer, Heidelberg (2004)
19. Whitten, A., Tygar, J.D.: Why Johnny can’t encrypt: a usability evaluation of
PGP 5.0. In: Proceedings of the 8th Conference on USENIX Security Symposium,
SSYM 1999, vol. 8, p. 14. USENIX Association, Berkeley (1999). http://dl.acm.
org/citation.cfm?id=1251421.1251435

Generic Transformation to Strongly Existentially
Unforgeable Signature Schemes with Continuous
Leakage Resiliency
Yuyu Wang(B) and Keisuke Tanaka
Tokyo Institute of Technology, Tokyo, Japan
wang.y.ar@m.titech.ac.jp,
keisuke@is.titech.ac.jp
Abstract. In ProvSec 2014, Wang and Tanaka proposed a transfor-
mation which converts weakly existentially unforgeable (wEUF) sig-
nature schemes into strongly existentially unforgeable (sEUF) ones in
the bounded leakage model. To obtain the construction, they combined
the leakage resilient (LR) chameleon hash functions with the Gener-
alised Boneh-Shen-Waters (GBSW) transformation proposed by Stein-
feld, Pieprzyk, and Wang. However, their transformation cannot be used
in a more realistic model called continual leakage model since the secret
key of the LR chameleon hash functions cannot be updated.
In this paper, we propose a transformation which can convert wEUF
signature schemes into sEUF ones in the continual leakage model. To
achieve our goal, we give a new deﬁnition of continuous leakage resilient
(CLR) chameleon hash function and construct it based on the CLR
signature scheme proposed by Malkin, Teranishi, Vahlis, and Yung.
Although the CLR chameleon hash functions satisfy the property of
strong collision-resistance, because of the existence of the updating algo-
rithm, an adversary may ﬁnd the kind of collisions such that messages
are the same but randomizers are diﬀerent. From this fact, we cannot
combine our chameleon hash functions with the GBSW transformation
directly, or the sEUF security of the transformed signature schemes can-
not be achieved. To solve this problem, we improve the original GBSW
transformation by making use of the Groth-Sahai proof system and then
combine it with our CLR chameleon hash functions.
Keywords: Generic transformation · Strong existential unforgeability ·
Continual leakage model · Continuous leakage resilient chameleon hash
function
Department of Mathematical and Computing Sciences, Graduate School of Informa-
tion Science and Engineering, Tokyo Institute of Technology, and CREST, JST, W8-
55, 2-12-1 Ookayama, Meguro-ku, Tokyo 152-8552, Japan. Supported by the Ministry
of Education, Science, Sports and Culture, Grant-in-Aid for Scientiﬁc Research (A)
No.24240001 and (C) No.23500010, a grant of I-System Co. Ltd., and NTT Secure
Platform Laboratories.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 213–229, 2015.
DOI: 10.1007/978-3-319-19962-7 13
www.ebook3000.com

214
Y. Wang and K. Tanaka
1
Introduction
1.1
Background
For a signature scheme, if it is hard to forge signatures on messages not signed
before, then we say this signature scheme satisﬁes the security of weak existen-
tial unforgeability (wEUF). Furthermore, if it is also hard to forge signatures on
messages signed before, then the strong existential unforgeability (sEUF) secu-
rity is said to be satisﬁed, which is known as the strongest security for the forgery
of signatures and required by some applications. There have already been sev-
eral transformations proposed to convert wEUF signature schemes into sEUF
ones (c.f. [4,6,17,23,24]). Specially, In [23], Steinfeld, Pieprzyk, and Wang pre-
sented a generic transformation called Generalised Boneh-Shen-Waters (GBSW)
transformation which exploits the chameleon hash functions.
In [26], Wang and Tanaka presented a generic transformation that can con-
vert fully leakage resilient (FLR) signature schemes which are wEUF into ones
which are sEUF. For FLR signature schemes, information of signing keys and
randomness may be leaked. However, this transformation only works well in the
bounded leakage model, in which the adversary is allowed to learn some bounded
leakage on the secret information. We hope there may be a transformation that
can convert wEUF-FLR signature schemes into sEUF-FLR ones in a more real-
istic model called continual leakage model.
The continual leakage model was suggested by Dodis, Haralambiev, L´opez-
Alt, and Wichs [11] and Brakerski, Kalai, Katz, and Vaikuntanathan [8], which
is an extension of the bounded leakage model introduced by Akavia, Goldwasser,
and Vaikuntanathan [2]. In the continual leakage model, the signing key is peri-
odically updated, and there is only bound on the leakage between two succes-
sive key updates, but no bound on the total leakage during the lifetime of the
system. There has been a lot of research for cryptographic primitives in the con-
tinual leakage model (c.f., [8,10,11,14,19,20]). As far as we know, the only previ-
ously presented sEUF-FLR signature scheme in this model is proposed by Wang
et al. [27]. However, they did not provide a generic transformation to sEUF-FLR
signature schemes. Furthermore, The reason why the transformation proposed
in [26] cannot be used in the continual leakage model is that the secret key of the
leakage resilient (LR) chameleon hash functions used in that transformation can-
not be updated.
1.2
Our Results
First, we give the deﬁnition of continuous leakage resilient (CLR) chameleon hash
function as an extension of the deﬁnition of LR chameleon hash function [26]. For
the LR chameleon hash functions, collisions can be found eﬃciently by making
use of the secret key, and it is hard to ﬁnd any collisions if the total leak-
age obtained during the lifetime of the system is bounded. In the case of CLR
chameleon hash functions, it is hard to ﬁnd collisions even when the secret key
is continuously leaked, without bound of total leakage. To construct the CLR

Generic Transformation to sEUF Signature Schemes with CLR
215
chameleon hash functions, we exploit the signature scheme in [20], in which the
tuple of key generation algorithm, updating algorithm, and relation of the pub-
lic/secret key pair satisﬁes the CLR one-way relation (OWR) deﬁned by Dodis
et al. [11]. Our construction inherits the properties of this instantiation of CLR-
OWR scheme, and can tolerate any leakage of ℓ= (1−o(1))L bits between every
two successive key updating, where L is the length of the secret key.
Then, we make use of the CLR chameleon hash functions and the GBSW
transformation to obtain a generic transformation from wEUF-FLR signature
schemes into sEUF-FLR ones. Although the CLR chameleon hash functions
satisfy the property of strong collision-resistance, an adversary may ﬁnd mes-
sage/randomizer pairs for the CLR chameleon hash functions such that the hash
values and messages are the same but randomizers are diﬀerent, because of the
existence of updating algorithms. From this fact, we cannot combine the CLR
chameleon hash functions with the GBSW transformation directly or the sEUF
security cannot be satisﬁed, while Wang et al. combined the LR chameleon hash
functions with the GBSW transformation directly to obtain their transforma-
tion in the bounded leakage model [26]. To solve this problem, we improve the
original GBSW transformation by making use of the Groth-Sahai proof system.
If the wEUF-FLR signature scheme can tolerate leakage of ℓw bits in
each round, then the converted signature scheme is resilient to any leakage of
min{ℓ, ℓw} bits in each round. Assume that ℓw = (1 −o(1))L (such as the sig-
nature scheme in [20]), then we can obtain a signature scheme that tolerates
leakage of ( 1
2 −o(1))L′ bits, where L′ = 2L is the length of the signing key. The
same as [26], we argue that we can obtain an ℓs-sEUF-FLR signature scheme
with signing key of length L′′ where ℓs = (1−o(1))L′′ by applying our technique
to the wEUF-FLR signature scheme in [14].
As far as we know, this is the ﬁrst generic transformation that can convert
wEUF(-FLR) signature schemes into sEUF(-FLR) ones in the continual leakage
model.
2
Preliminaries
2.1
CLR One-Way Relation
A OWR scheme usually consists of two algorithms KeyGen and R, where KeyGen
generates a public/secret key pair (y, x) satisfying R(y, x) = 1. It is said to
be secure if for any probabilistic polynomial time (PPT) adversary A, given
y, it is diﬃcult to ﬁnd x∗such that R(y, x∗) = 1. In the case of CLR-OWR
scheme, there is one more algorithm Update which is used to update the secret
key periodically while the public key does not change. Furthermore, a CLR-
OWR scheme keeps secure even if an adversary can learn leakage of the secret
keys continuously. We now give the formal deﬁnition of CLR-OWR schemes,
following [11].
Deﬁnition 1 (CLR-OWR schemes [11]). A CLR-OWR scheme consists of
three algorithms (KeyGen, Update, R). KeyGen takes as input 1k and outputs a
www.ebook3000.com

216
Y. Wang and K. Tanaka
public/secret key pair (y, x). Update takes as input a secret key x and outputs a
refreshed secret key x′. R takes as input a public/secret key pair (y, x) and out-
puts 1 if (y, x) is “correct”, and outputs 0 otherwise. The ℓ-CLR-OWR scheme
must satisfy two properties, which are correctness property and security property.
The correctness property is satisﬁed if for any polynomial q = q(k), we com-
pute (y, x[0]) ←KeyGen(1k), x[1] ←Update(y, x[0]), ..., x[q] ←Update(y, x[q−1]),
then we have R(y, x[0]) = ... = R(y, x[q]) = 1.
The security property is satisﬁed if for any PPT adversary A, we have
Pr[A wins] ≤negl(k) in the following game:
1. The challenger computes (y, x[0]) ←KG(1k) and sets L = 0.
2. On input (1k, y), A runs for arbitrarily many leakage rounds i = 0, ..., q. In
each round i:
(a) A makes adaptive queries to the challenger. Every time on receiv-
ing the description of a polynomial-time computable function fj, if
L + |fj(x[i])| ≤ℓ, the challenger sends fj(x[i]) back to A and updates
L = L + |fj(x[i])|. Otherwise it aborts.
(b) The challenger samples x[i+1] ←Update(y, x[i]) and sets L = 0 at the
end of the round.
3. A wins if it outputs x∗such that R(y, x∗) = 1.
2.2
FLR Signature Scheme in the Continual Leakage Model
We now recall the deﬁnition of FLR signature scheme in the continual leakage
model from [7,14].
A signature scheme in the continual leakage model consists of four PPT
algorithms (KG, Update, Sign, Verify). KG takes as input 1k and outputs a sign-
ing/veriﬁcation key pair (pk, sk). Update takes as input a veriﬁcation/signing
key pair (pk, sk) and outputs a refreshed signing key sk′. Sign takes as input
a signing key sk and a message m and returns a signature σ. Verify takes as
input a veriﬁcation key pk, a message m, and a signature σ and outputs 1 if the
signature is valid, outputs 0 otherwise. In addition to the correctness, we require
the following property.
Deﬁnition 2 (wEUF-FLR signature schemes [7]). A signature scheme
(KG, Update, Sign, Verify) is said to be wEUF and ℓ-FLR in the continual leak-
age model if for any PPT adversary A, we have Pr[A wins] ≤negl(k) in the
following game:
1. Compute (pk, sk) ←KG(1k, ℓ), set state = sk and L = 0.
2. Run the adversary A on input (1k, pk). The adversary may make adaptive
queries to the signing oracle, the leakage oracle and the updating oracle,
deﬁned as follows:
– Signing oracle: On receiving a query mi, the signing oracle samples ri ←
{0, 1}∗, and computes σi ←Signsk(mi; ri). It updates state = state||ri
and outputs σi.

Generic Transformation to sEUF Signature Schemes with CLR
217
– Leakage oracle: On receiving a polynomial-time computable function fj :
{0, 1}∗→{0, 1}ℓj, if L + |fj(state)| ≤ℓ, then outputs fj(state) and sets
L = L + |fj(state)|. Otherwise it aborts.
– Updating oracle: On receiving an updating query, the updating oracle
computes sk′ ←Update(pk, sk). It resets sk = sk′, state = sk, and
L = 0.
3. A outputs (m∗, σ∗) and wins if : (a) Verifypk(m∗, σ∗) = 1, (b) m∗was not
queried to the signing oracle.
The deﬁnition of sEUF-FLR signature schemes is the same as the above one,
except the winning condition (b) being set as follows.
– the pair (m∗, σ∗) is new, that is, either m∗was not queried to the signing
oracle or it was, σ∗is not the one(s) generated as a signature of m∗by the
signing oracle.
Without loss of generality, we can assume that the adversary makes a leakage
query every time after making a signing query.
The deﬁnition described above does not consider the leakage on key genera-
tion and key updating since generating key and updating key may be conducted
“oﬀ-line”, according to [7].
2.3
Assumptions in Bilinear Group
In this paper, we let G be an algorithm takes as input 1k and outputs gk =
(p, G1, G2, GT , e) such that p is prime, (G1, G2, GT ) are descriptions of groups of
order p, and e : G1×G2 →GT is a non-degenerate eﬃciently computable bilinear
map. It is required that there is no eﬃcient computable mapping between G1
and G2.
The same as [20], we use additive notation for pairings, such as e((a +
b)A, B) = a · e(A, B) + b · e(A, B). We denote e(AT , B) = n
i=1 e(Ai, Bi), where
A = (A1, ..., An)T ∈G1, B = (B1, ..., Bn)T ∈G2.
We now recall the Decisional Diﬃe-Hellman (DDH) assumption, the Sym-
metric External Diﬃe-Hellman (SXDH) assumption, and the Double Paring
Assumption.
Deﬁnition 3 (DDH assumption). Let G be a group of primer order p. For
any PPT adversary A, we have
Pr[G1, G2 ←G; r ←Zp : A(G, G1, G2, rG1, rG2) = 1]
≈Pr[G1, G2 ←G; r1, r2 ←Zp : A(G, G1, G2, r1G1, r2G2) = 1].
SXDH assumption [3,5,12,13,21,25]. Let gk = (p, G1, G2, GT , e) be the tuple
generated by G as we introduced earlier, the SXDH assumption states that the
DDH problem is hard in both groups G1 and G2.
www.ebook3000.com

218
Y. Wang and K. Tanaka
Deﬁnition 4 (Double Paring Assumption [1,12,15]). For any PPT adver-
sary A, we have
Pr[G1, G2 ←G1; (Z1, Z2) ←A(gk, G1, G2) :
Z1, Z2 ∈G2 ∧(Z1, Z2) ̸= (0, 0) ∧e(G1, Z1) + e(G2, Z2) = 0] ≤negl(k).
The double pairing assumption is implied by the SXDH assumption (ref.,
[1,12,15]).
Now we give a lemma on which our construction will be based.
Lemma 1 (Simular to [12]). For any PPT adversary A, we have
Pr[(p, G1, G2, GT , e) ←G(1k); B ←Gn
1; M ←Gn
2; M ∗←A(gk, B, M) :
e(BT , M ∗) = e(BT , M) ∧M ∗̸= M] ≤negl(k).
The proof of this lemma is based on the SXDH assumption and almost the
same as the proof of the second preimage relation in [12]. We give the proof as
follows.
Proof. Assume that there exists an adversary A that given B = (B1, ..., Bn)T
and M = (M1, ..., Mn)T ∈Gn
2, ﬁnds M ∗∈Gn
2 such that M ̸= M ∗and
e(BT , M) = e(BT , M ∗) with non-negligible probability ϵ. By making use of A,
we construct an adversary B that breaks the double-pairing assumption.
B takes as input G1, G2, chooses α1, β1, ..., αn, βn ←Zp, and sets B =
(α1G1 + β1G2, ..., αnG1 + βnG2)T . Then B chooses M ←Gn
2 and gives B, M
to A. With probability ϵ, A returns M ∗such that M ∗̸= M and e(BT , M ∗) =
e(BT , M). Then B outputs (Z1, Z2) = (n
i=1 αi(Mi −M ∗
i ), n
i=1 βi(Mi −M ∗
i )).
We have
e(G1, Z1) + e(G2, Z2) = e(G1,
n

i=1
αi(Mi −M ∗
i )) + e(G2,
n

i=1
βi(Mi −M ∗
i ))
= e(BT , M −M ∗) = 0.
Furthermore, there exists j ∈[1, ..., n] for which Mj −M ∗
j ̸= 0. Since αj is
information theoretically hidden, we have Z1 ̸= 0 with probability (1 −1/q).
Thus, B breaks the double pairing assumption with non-negligible probability.
2.4
Groth-Sahai Proofs
In [20], Malkin et al. made use of the Groth-Sahai Proof system [16] to construct
their signature scheme. Inspired by them, we will construct our transformation
based on this system.
In this paper, the statements are of the form e(AT , M) = T for (A, M, T) ∈
Gn
1 × Gn
2 × GT , where M is the witness.
The proof system consists of four algorithms (HideCRS, BindCRS, Prf, Vrf).
HideCRS takes as input gk (ref., Section 2.3) and outputs the common reference

Generic Transformation to sEUF Signature Schemes with CLR
219
string (CRS) crs = (G, H) ←G2
2. BindCRS takes as input gk, chooses G ←G2
2,
α ←Zp, and outputs the CRS and trapdoor information (crs = (G, H =
αG), α). Prf takes as input (gk, crs, (A, T), M), chooses R ←Zn×2
p
, and outputs
σ = (C, D, Π) = (R·G, M +R·H, RT A). Vrf takes as input (gk, crs, (A, T), σ)
and outputs 1 if (e(AT , C), e(AT , D)) = (e(ΠT , G), T + e(ΠT , H)), outputs 0
otherwise. Groth and Sahai showed that the two types of CRS are indistinguish-
able under the SXDH assumption.
The scheme described above satisﬁes two properties, which are perfect witness
indistinguishability property and perfect extractability property. Their deﬁnitions
are as follow.
The perfect witness indistinguishability property is satisﬁed if for all PPT
adversaries A,
Pr[gk ←G(1k), crs ←HideCRS(gk), (A, T, M 0, M 1, st) ←A(gk, CRS),
σ ←Prf(gk, CRS, (A, T), M 0) : 1 ←A(σ, st)]
= Pr[gk ←G(1k), crs ←HideCRS(gk), (A, T, M 0, M 1, st) ←A(gk, CRS),
σ ←Prf(gk, CRS, (A, T), M 1) : 1 ←A(σ, st)],
where it is required that e(AT , M 0) = e(AT , M 1) = T.
The perfect extractability property is satisﬁed if for all possible output gk of
G(1k), all possible output (crs, α) of BindCRS(gk), all (A, T) ∈Gn
1 × GT and all
σ = (C, D, Π) ∈Gn×1
2
× Gn×1
2
× G2
1 satisfying Vrf(gk, crs, (A, T), σ) = 1, we
set M ∗= D −αC, then e(AT , M ∗) = T always holds.
3
CLR Chameleon Hash Functions
In this section, we deﬁne the CLR chameleon hash function. This deﬁnition is an
extension of the notion of chameleon hash function [18,22] and LR chameleon
hash function [26]. Then we give our construction of CLR chameleon hash func-
tions based on a CLR-OWR scheme from [20].
3.1
Deﬁnition
An ℓ-CLR chameleon hash function scheme consists of four PPT algorithms
(KGF , TCF , F, UDF ).
KGF is a key generation algorithm that takes as input (1k, ℓ), and outputs
a public/private key pair (pkF , skF ). F is a hash function evaluation algorithm
that takes as input pkF , a message m, and a randomizer r, and outputs a hash
value h = FpkF (m; r). TCF is a trapdoor collision ﬁnder algorithm that takes as
input skF , an arbitrary message pair (m, m′), and a randomizer r, and outputs
r′ = TCF (skF , (m, r), m′) such that FpkF (m; r) = FpkF (m′; r′). UDF is a key
update algorithm takes as input (pkF , skF ) and samples a refreshed secret key
sk′
F for pkF .
An ℓ-CLR chameleon hash function scheme must satisfy four properties,
which are reversibility, correctness, random trapdoor collision, and ℓ-CLR strong
collision-resistance.
www.ebook3000.com

220
Y. Wang and K. Tanaka
The reversibility property is satisﬁed if r′ = TCF (skF , (m, r), m′) is equiva-
lent to r = TCF (skF , (m′, r′), m).
The correctness property is satisﬁed if for any polynomial i = i(k), any
message pair (m, m′), and a randomizer r, if we compute (pkF , sk[0]
F ) ←
KGF (1k), sk[1]
F
←UDF (pkF , sk[0]
F ), ..., sk[i]
F
←UDF (pkF , sk[i−1]
F
), and r′ =
TCF (sk[i]
F , (m, r), m′), we have FpkF (m; r) = FpkF (m′; r′). If the r′ has a uniform
probability distribution on the randomness space, then the random trapdoor col-
lision property is also satisﬁed.
The ℓ-CLR strong collision-resistance property is satisﬁed if for any PPT
adversary A, we have Pr[A wins] ≤negl(k) in the following game:
1. the challenger computes (pkF , sk[0]
F ) ←KGF (1k) and sets L = 0.
2. On input (1k, pkF , F), A runs for arbitrarily many leakage rounds i = 0, ..., q.
In each round i:
(a) A makes adaptive queries to the challenger. Every time on receiv-
ing the description of a polynomial-time computable function fj, if
L + |fj(sk[i]
F )| ≤ℓ, then the challenger sends fj(sk[i]
F ) back to A and
updates L = L + |fj(sk[i]
F )|. Otherwise it aborts.
(b) the
challenger
refreshes
the
secret
key
by
sampling
sk[i+1]
F
←
Update(pkF , sk[i]
F ) and resets L = 0 at the end of the round.
3. A wins if it outputs (m, r) and (m′, r′) such that m ̸= m′ and FpkF (m, r) =
FpkF (m′, r′).
The deﬁnition of standard chameleon hash function is the same as the deﬁ-
nition of CLR one except that there exists no key updating algorithm and the
adversary is not allowed to make leakage queries to learn any information about
the secret keys. Furthermore, although the original deﬁnition of chameleon hash
function scheme just require that m ̸= m′, it is required that the adversary
cannot ﬁnd a collision that (m, r) ̸= (m′, r′) for the standard chameleon hash
function here. As far as we know, all of the previously presented chameleon
functions satisfy this stronger version of strong collision-resistance naturally.
3.2
Construction of CLR One-Way Relation Scheme
Theorem 1. The scheme described in Figure 1 is an ℓ-CLR-OWR scheme for
ℓ= n log p −(2 + Θ(1/
√
k)) log p if the SXDH assumption holds.
If we add (G, H) where G ←G2
2 and H = (H0, ...Ht) ←(G2
2)t+1 to the
public key, then the public/secret key pair of our CLR-OWR scheme is the same
as the veriﬁcation/signing key pair of the continuous leakage resilient signature
scheme in [20].
For the signature scheme in [20], a PPT adversary can make three kinds of
queries, which are updating queries, leakage queries, and signing queries, and the
probability to output a valid forgery against the wEUF experiment is negligible
if the SXDH assumption holds (we refer the reader to [20] for details of the

Generic Transformation to sEUF Signature Schemes with CLR
221
– Key generation algorithm KG(1k):
1. Run gk = (p, G1, G2, GT , e) ←G(1k).
2. Choose A ←G1, Q ←G2, a, q ←Zn
p satisfying ⟨aT , q⟩= 0. A =
aA, Q = qQ.
3. Choose W [0] ←Gn
2 .
4. Compute T = e(AT , W [0]).
5. Return y = (gk, A, T, Q) and x[0] = W [0].
– Updating algorithm Update(y, x[i]):
1. Parse pk = (gk, A, T, Q) and x[i] = W [i].
2. Choose s ←Zp.
3. Return x[i+1] = W [i+1] = W [i] + sQ.
– Veriﬁcation algorithm R(y, x[i]):
1. Parse y = (gk, A, T, Q) and x[i] = W [i].
2. Output 1 if T = e(AT , W [i]), and output 0 otherwise.
Fig. 1. CLR-OWR scheme
proof). Now we assume that the adversary only makes updating queries and
leakage queries for the signing key. It is clear that the advantage of the adversary
becomes even smaller than before.
Furthermore, according to [20], the signatures output by the signing algo-
rithms are Groth-Sahai proofs which prove statements of the form e(AT , W ) =
T where W is the witness (and signing key), and the CRSs depend on the
messages. It is not hard to see that if an adversary can obtain W ∗such that
e(AT , W ∗) = T, then it is able to forge signatures against the wEUF game by
using W ∗as the signing key. As a result, the adversary cannot output a valid
signing key (or secret key) after making updating queries and leakage queries.
Since the signature scheme in [20] can tolerate n log p −(2 + Θ(1/
√
k)) log p
bits of leakage on the signing key in each leakage round, the probability that any
PPT adversary A, who can learn n log p −(2 + Θ(1/
√
k)) log p bits of leakage
on the secret key in each leakage round, outputs a valid secret key is negligible.
Furthermore, if we set n = k, we have n log p−(2+Θ(1/
√
k)) log p = (1−o(1))L
where L is the length of secret key.
3.3
Construction of CLR Chameleon Hash Function
We present our construction of CLR chameleon hash functions in Figure 2.
Theorem 2. The scheme described in Figure 2 is an ℓ-CLR chameleon hash
function for ℓ= n log p −(2 + Θ(1/
√
k)) log p if the SXDH assumption holds.
To prove that our scheme is a CLR chameleon hash function scheme, we have
to show that this scheme satisﬁes the properties of correctness, reversibility,
random trapdoor collision, and CLR strong collision-resistance. It is not hard
www.ebook3000.com

222
Y. Wang and K. Tanaka
– Key generation algorithm KGF (1k):
1. Run gk = (p, G1, G2, GT , e) ←G(1k).
2. Choose A ←G1, Q ←G2, a, q ←Zn
p satisfying ⟨a, q⟩= 0. A = aA, Q =
qQ.
3. Choose W [0] ←Gn
2 .
4. Compute T = e(AT , W [0]).
5. Return pkF = (gk, A, T, Q) and sk[0]
F = W [0].
– Hash function evaluation algorithm FpkF (m, R) where R ←Gn
2 :
1. Return h = J(m)(T + e(AT , R)), where J denotes a strongly collision
resistant hash function from {0, 1}∗to Zp/{0}.
– Trapdoor collision ﬁnder algorithm TCF (sk[i]
F , (m, R), m′):
1. Parse sk[i]
F = W [i].
2. Return R′ =
J(m)
J(m′)(W [i] + R) −W [i].
– Updating algorithm UDF (pkF , sk[i]
F ):
1. Parse pk = (gk, A, T, Q) and sk[i]
F = W [i].
2. Choose s ←Zp.
3. Return sk[i+1]
F
= W [i+1] = W [i] + sQ.
Fig. 2. CLR Chameleon Hash Function Scheme
to prove that our scheme satisﬁes the properties of correctness, reversibility,
random trapdoor collision, and we will argue that if there exists an adversary
that breaks the CLR strong collision-resistance for this scheme, then we can
construct another adversary that breaks the security property of the CLR-OWR
scheme in Figure 1.
Proof. First we argue that the correctness property is satisﬁed for our scheme.
For any polynomial integer i ≥0, if we compute ((gk, A, T, Q), W [0]) ←
KGF (1k), W [1] = W [0] + s0Q, ..., W [i] = W [i−1] + si−1Q, where s0, ..., si−1
are randomly chosen from Zp, we have e(AT , W [i]) = e(AT , W [0] + (s0 +
... + si−1)Q) = T + (s0 + ... + si−1)e(AT , Q) = T. According to the trap-
door collision ﬁnder algorithm described above, if R′ = TCF (sk[i]
F , (m, R), m′),
we have J(m′)(W [i] + R′) = J(m)(W [i] + R), which means that we have
J(m′)(e(AT , W [i])+e(AT , R′)) = J(m)(e(AT , W [i])+e(AT , R)), equivalently,
FpkF (m′, R′) = FpkF (m, R).
Since R′ = J(m)
J(m′)(W [i] + R) −W [i] is equivalent to R = J(m′)
J(m) (W [i] + R′) −
W [i], if R′ = TCF (skF , (m, R), m′) holds, R = TCF (skF , (m′, R′), m) holds as
well, which makes our scheme satisfy the reversibility property. Furthermore, it
is apparent that R′ has a uniform probability distribution on Gn
2 if R is chosen
randomly from Gn
2, which makes our scheme also satisfy the random trapdoor
collision property.

Generic Transformation to sEUF Signature Schemes with CLR
223
Since we have shown that our scheme satisﬁes the properties of correctness,
reversibility, and random trapdoor collision, what we are left to do is to prove
that our scheme also satisﬁes the property of CLR strong collision-resistance.
Let VRF be a deterministic algorithm which takes as input (gk, A, T, Q, W ),
and outputs 1 if T
=
e(AT , W ), outputs 0 otherwise. It is clear that
(KGF , UDF , VRF ) is the same as the ℓ-CLR-OWR that we have stated in
Figure 1. We argue that if there exists a PPT adversary B that breaks the
ℓ-CLR strong collision-resistance property, then there exists a PPT adversary A
that wins the ℓ-security experiment of CLR-OWR (c.f., Section 2.1).
The challenger generates ((gk, A, T, Q), W [0]) and gives (gk, A, T, Q) to A.
Then A gives (gk, A, T, Q) to B as the public key.
Every time B runs for a new leakage round, A asks the challenger to update
the secret key. After getting a leakage query fi(·) from B, A sends the query to
the challenger and gives the answer back to B. Since the number of leaked bits
obtained by B in each round should be less than ℓ, all of the queries from B can
be answered. After getting the output of B denoted by (m, R) and (m′, R′), A
computes W ∗= J(m′)R′−J(m)R
J(m)−J(m′)
(Since m′ ̸= m and J(·) is a strongly collision
resistant hash function, we know the probability that (J(m)−J(m′)) mod p = 0
is negligible). Then A outputs W ∗.
If B has found the collision successfully, we have J(m)(T + e(AT , R)) =
J(m′)(T + e(AT , R′)). Furthermore, since J(m)(W ∗+ R) = J(m′)(W ∗+ R′),
which means J(m)(e(AT , W ∗) + e(AT , R)) = J(m′)(e(AT , W ∗) + e(AT , R′)),
we have T = e(AT , W ∗) = J(m′)e(AT ,R′)−J(m)e(AT ,R)
J(m)−J(m′)
.
As a result if B can ﬁnd a collision successfully with probability ϵ in poly-
nomial time t, then A can break the security of CLR one-way relation with the
same probability in the same running time, completing the proof.
Notice that it is very easy to ﬁnd a collision ((m, R1), (m, R2)) for this CLR
chameleon hash function such that FpkF (m, R1) = FpkF (m, R2) and R1 ̸= R2,
since for any m, s ∈Zp, and R1 ∈Gn
2, we have FpkF (m, R1) = J(m)(T +
e(AT , R1)) = J(m)(T + e(AT , R2) = FpkF (m, R2) where R2 = R1 + sQ. As a
result, this CLR chameleon hash function scheme does not satisfy the stronger
version of strong collision-resistance that we talked about in Section 3.1.
4
Generic Transformation
We now give the construction of the generic transformation that can convert
any wEUF-FLR signature schemes into sEUF-FLR ones in the continual leakage
model. Our construction is inspired by the transformation in [26]. In [26], Wang
et al. improved the GBSW transformation in [23] by substituting the standard
chameleon hash functions with the LR ones. However, substituting the standard
chameleon hash functions in the GBSW transformation with the CLR ones is
not enough to obtain the transformation we want. The reason is that it is very
hard to achieve the chameleon hash functions satisfying the stronger version of
www.ebook3000.com

224
Y. Wang and K. Tanaka
strong collision-resistance as [23,26] in the continual leakage model. To solve this
problem, we make use of the Groth-Sahai proof system.
Let Σ = (KG, Sign, Verify, Update) be an arbitrary ℓw-wEUF-FLR signa-
ture scheme with randomness space ΩΣ in the continual leakage model, F =
(KGF , F, TCF , UDF ) the ℓ-CLR chameleon hash function scheme with random-
ness space RF , where ℓ= n log p−(2+Θ(1/
√
k)) log p, and H = (KGH, H, TCH)
a standard chameleon hash function with randomness space RH. We make use
of the Groth-Sahai proof system and the GBSW scheme [23] to construct an
ℓs-sEUF-FLR signature scheme Σ′ as shown in Figure 3.
For Σ′, the signature is a tuple of (σ, r, s, π, T). π = (Π, C, D) is a Groth-
Sahai proof for the statement T = e(BT , M) where B is a part of the public
key and M is a randomizer generated in the signing process. σ is the signature
depending on m, σ, Π, and T.
Inspired by [20], we use the Water’s hash function to generate the CRS of
the Groth-Sahai proof system. Water’s hash function is deﬁned as hgk(H, x) =
H0 + t
i=1 xiHi, where gk = (p, G1, G2, GT , e), H = (H0, ..., Ht) ∈(G2
2)t+1,
x ∈{0, 1}t, and xi is the ith bit of x. We generate the CRS as (G, Hr =
hgk(H, J′(r))). Notice that to make the signature depend on Π, we have to
compute Π before generating r and the CRS.
By making use of the Groth-Sahai proof system, we can make sure that if
there exists an adversary that can forge a message/signature pair which is the
same as a pair generated by the signing oracle except that r or π is diﬀerent,
then we can extract M ∗such that e(BT , M ∗) = T = e(BT , M) ∧M ∗̸= M
from the forged π (in the hybrid game) with non-negligible probability, breaking
Lemma 1.
Theorem 3. The signature scheme described in Figure 3 is an ℓs-sEUF-FLR
signature scheme for ℓs = min{ℓ, ℓw}.
To prove that Σ′ is secure in the continual leakage model, we show that
if there is an adversary that can break the sEUF-FLR property, then there
exist ﬁve adversaries against the wEUF-FLR property of Σ, the strong collision-
resistance of H and F, and Lemma 1, respectively. Some parts of our proof are
similar to [23]. The proof sketch is given as follows.
Proof sketch. For i = 1, ..., q, let mi be the ith signing query, σ′
i = (σi, ri, si, πi =
(Πi, Ci, Di), Ti) be the answer to the ith signing query, Hri = hgk(H, J′(ri)),
hi = FpkF (mi||σi||Πi||Ti; ri), and ¯mi = HpkH(hi; si). We denote fj as the
jth leakage query of A. At some point, A outputs (m∗, σ′∗) where σ′∗=
(σ∗, r∗, s∗, π∗= (Π∗, C∗, D∗), T ∗) as the forgery. In the same way, H∗
r =
hgk(H, J′(r∗)), h∗= FpkF (m∗||σ∗||Π∗||T ∗; r∗) and ¯m∗= HpkH(h∗; s∗).
If A wins the sEUF-FLR experiment with non-negligible probability ϵ, then
A outputs a forgery, which is one of the following ﬁve types with probability ϵ/5
in the sEUF-FLR experiment:

Generic Transformation to sEUF Signature Schemes with CLR
225
– KG′(1k):
1. Run gk = (p, G1, G2, GT , e) ←G(1k).
2. Run (pk, sk) ←KG(1k).
3. Run (pkF , skF ) ←KGF (1k).
4. Run (pkH, skH) ←KGH(1k).
5. Randomly choose G ←G2
2, H = (H0, H1, ..., Ht) ←(G2
2)t+1, B ←Gn
1 .
6. Output public key pks = (gk, pk, pkF , pkH, G, H, B, m′, σ′) and secret
key sks = (sk, skF ), where m′ and σ′ are arbitrary ﬁxed strings.
– Sign′
sks(m):
1. Parse sks = (sk, skF ).
2. Randomly choose ω←ΩΣ, s←RH, r′←RF , R ←Zn×2
p
, and M ←Gn
2 .
3. Compute h = FpkF (m′||σ′; r′).
4. Compute ¯m = HpkH (h; s).
5. Compute σ = Signsk( ¯m; ω).
6. Compute Π = RT B, T = e(BT , M).
7. Compute r = TCF (skF , (m′||σ′, r′), m||σ||Π||T).
8. Compute Hr = hgk(H, J′(r)), where J′ denotes a strongly collision resis-
tant hash function from {0, 1}∗to {0, 1}t.
9. Compute (C, D) = (RG, M + RHr), π = (Π, C, D).
10. Output σ′ = (σ, r, s, π, T).
– Verify′(pks, m, σ′):
1. Parse pks = (gk, pk, pkF , pkH, G, H, B, m′, σ′), σ′ = (σ, r, s, π, T), and
π = (Π, C, D).
2. Compute h = FpkF (m||σ||Π||T; r).
3. Compute ¯m = HpkH (h; s).
4. Compute Hr = hgk(H, J′(r)).
5. Output
1
if
Verify(pk, ¯m, σ)
=
1
and
(e(BT , C), e(BT , D))
=
(e(ΠT , G), T + e(ΠT , Hr)), and output 0 otherwise.
– Update′(pks, sks):
1. Parse pks = (gk, pk, pkF , pkH, G, H, B, m′, σ′) and sks = (sk, skF ).
2. Compute sk′ ←Update(pk, sk) and sk′
F ←UDF (pkF , skF ).
3. Output sk′
s = (sk′, sk′
F ).
Fig. 3. GBSW Transformation in the Continuous Leakage Model
– type I forgery: ¯m∗/∈{ ¯m1, ..., ¯mq}.
– type II forgery: there exists i∗∈{1, ..., q} such that ¯m∗=
¯mi∗, but
(h∗, s∗) ̸= (hi∗, si∗).
– type III forgery: there exists i∗∈{1, ..., q} such that ¯m∗= ¯mi∗and
(h∗, s∗) = (hi∗, si∗), but (m∗, σ∗, Π∗, T ∗) ̸= (mi∗, σi∗, Πi∗, Ti∗).
– type IV forgery: there exists i∗∈{1, ..., q} such that ¯m∗= ¯mi∗, (h∗, s∗) =
(hi∗, si∗), and (m∗, σ∗, Π∗, T ∗) = (mi∗, σi∗, Πi∗, Ti∗), but r∗̸= ri∗.
– type V forgery: there exists i∗∈{1, ..., q} such that ¯m∗= ¯mi∗, (h∗, s∗) =
(hi∗, si∗), (m∗, σ∗, Π∗, T ∗) = (mi∗, σi∗, Πi∗, Ti∗), and r∗= ri∗, but π∗̸=
πi∗.
www.ebook3000.com

226
Y. Wang and K. Tanaka
What we have to do is to show how to construct PPT adversary AI against
the ℓw-wEUF-FLR of Σ, adversary AII against the strong collision-resistance
of H, adversary AIII against the ℓ-CLR strong collision-resistance of F, and
adversaries AIV and AV against Lemma 1, by making use of A. Each of the
adversaries AI, AII, AIII, AIV , and AV succeeds if A outputs a type I, type
II, type III, type IV, and type V forgery, respectively.
Now we give the overview of AI, AII, AIII, AIV , and AV .
There are ﬁve games for AI, AII, AIII, AIV , and AV , respectively. In each
game, the adversary (which is one of AI, AII, AIII, AIV , and AV ) gets some
public information from the challenger and simulates the signing oracle of A. If
A makes leakage queries to the adversary, the adversary answers by making use
of the leakage oracle and the secret information generated by itself.
The ﬁnal outputs of the adversaries are as follows.
Game of AI. AI outputs ( ¯m∗, σ′∗) as the forgery for Σ and succeeds when A
outputs the type I forgery.
Game of AII. AII outputs (h∗, s∗) and (hi∗, si∗) as a collision for H and succeeds
when A outputs the type II forgery.
Game of AIII. AIII outputs ((m∗, σ∗, Π∗, T ∗), r∗) and ((mi∗, σi∗, Πi∗, Ti∗), ri∗)
as a collision for F and succeeds when A outputs the type III forgery.
Game of AIV . When A outputs the type IV forgery, we have that the prob-
ability that r∗= ri for some i is negligible. Depending on this fact, we build
a hybrid game for the game of AIV , in which, hgk(H, J′(r∗)) is a binding CRS
and hgk(H, J′(ri)) for i = 1, ..., q are hiding CRSs. As a result, Mi is hidden
for i = 1, ..., q and M ∗can be extracted with non-negligible probability where
M ∗̸= Mi∗∧T ∗= Ti∗. Then AIV outputs M ∗, breaking Lemma 1.
Game of AV . When A outputs the type V forgery, we can extract M ∗in almost
the same way, and we have M ∗̸= Mi∗since Π∗= Πi∗, r∗= ri∗, and π∗̸= πi∗.
Then AV outputs M ∗̸= Mi∗where M ∗̸= Mi∗∧T ∗= Ti∗, breaking Lemma 1.
We show how these ﬁve adversaries run in the full version of this paper.
Remark. We do not discuss the leakage on key generation and key updating. If
the wEUF-FLR signature scheme can tolerate leakage on key generation and key
updating, then the resulting scheme can also tolerate this kind of leakage to some
extent. The CLR-OWR scheme (c.f., Figure 1) from [20] can tolerate leakage of
length c log k bits1 during the key generation and key updating where c ≥0 is
some constant, and the public key can be sampled without knowledge of the
secret key for some instantiations of chameleon hash functions, such as the well-
known Discrete-log based instantiation by Chaum, van Heijst, and Pﬁtzmann [9].
1 This is also counted in the leakage on secret key.

Generic Transformation to sEUF Signature Schemes with CLR
227
Furthermore, the same as [26], we can obtain a (1 −o(1))L-sEUF-FLR sig-
nature scheme by setting skF = sk if we apply our technique to the (1 −o(1))L-
wEUF-FLR signature scheme proposed in [14] where L is the length of secret
key. We refer the reader to [26] for details of the discussion2.
5
Conclusions
In this paper, we have ﬁrst deﬁned the continuous leakage resilient chameleon
hash function and given the construction of it based on the signature scheme
proposed in [20]. Then we have combined this new kind of chameleon hash func-
tion with the Groth-Sahai proof system [16] and the GBSW [23] transformation
to obtain a transformation which converts wEUF-FLR schemes into sEUF-FLR
ones in the continual leakage model.
However, the transformed signature scheme is only resilient to any leakage of
min{ℓ, ℓw} in each round, where ℓis the leakage parameter of the CLR chameleon
hash function and ℓw is the leakage parameter of the original wEUF-FLR sig-
nature scheme, for most cases. We leave a transformation from ℓw-wEUF-FLR
signature scheme into ℓw-sEUF-FLR ones in the continual leakage model without
loosing the eﬃciency as a future work.
References
1. Abe, M., Fuchsbauer, G., Groth, J., Haralambiev, K., Ohkubo, M.: Structure-
preserving signatures and commitments to group elements. In: Rabin, T. (ed.)
CRYPTO 2010. LNCS, vol. 6223, pp. 209–236. Springer, Heidelberg (2010)
2. Akavia, A., Goldwasser, S., Vaikuntanathan, V.: Simultaneous hardcore bits and
cryptography against memory attacks. In: Reingold, O. (ed.) TCC 2009. LNCS,
vol. 5444, pp. 474–495. Springer, Heidelberg (2009)
3. Ballard, L., Green, M., de Medeiros, B., Monrose, F.: Correlation-resistant storage
via keyword-searchable encryption. Cryptology ePrint Archive, Report 2005/417
(2005). http://eprint.iacr.org/
4. Bellare, M., Shoup, S.: Two-tier signatures, strongly unforgeable signatures, and
ﬁat-shamir without random oracles. In: Okamoto, T., Wang, X. (eds.) PKC 2007.
LNCS, vol. 4450, pp. 201–216. Springer, Heidelberg (2007)
5. Boneh, D., Boyen, X., Shacham, H.: Short group signatures. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 41–55. Springer, Heidelberg (2004)
6. Boneh, D., Shen, E., Waters, B.: Strongly unforgeable signatures based on com-
putational Diﬃe-Hellman. In: Yung, M., Dodis, Y., Kiayias, A., Malkin, T. (eds.)
PKC 2006. LNCS, vol. 3958, pp. 229–240. Springer, Heidelberg (2006)
7. Boyle, E., Segev, G., Wichs, D.: Fully leakage-resilient signatures. In: Paterson,
K.G. (ed.) EUROCRYPT 2011. LNCS, vol. 6632, pp. 89–108. Springer, Heidelberg
(2011)
2 The discussion in [26] is totally suitable for our situation although we consider two
more adversaries in this paper.
www.ebook3000.com

228
Y. Wang and K. Tanaka
8. Brakerski, Z., Kalai, Y.T., Katz, J., Vaikuntanathan, V.: Overcoming the hole in
the bucket: public-key cryptography resilient to continual memory leakage. In: 2010
51st Annual IEEE Symposium on Foundations of Computer Science (FOCS), pp.
501–510, October 2010
9. Chaum, D., van Heijst, E., Pﬁtzmann, B.: Cryptographically strong undeniable
signatures, unconditionally secure for the signer. In: Feigenbaum, J. (ed.) CRYPTO
1991. LNCS, vol. 576, pp. 470–484. Springer, Heidelberg (1992)
10. Dodis, Y., Lewko, A., Waters, B., Wichs, D.: Storing secrets on continually leaky
devices. In: 2011 IEEE 52nd Annual Symposium on Foundations of Computer
Science (FOCS), pp. 688–697, October 2011
11. Dodis, Y., Haralambiev, K., L´opez-Alt, A., Wichs, D.: Cryptography against con-
tinuous memory attacks. In: Proceedings of the 2010 IEEE 51st Annual Symposium
on Foundations of Computer Science, FOCS 2010, pp. 511–520. IEEE Computer
Society, Washington (2010)
12. Dodis, Y., Haralambiev, K., L´opez-Alt, A., Wichs, D.: Eﬃcient public-key cryptog-
raphy in the presence of key leakage. In: Abe, M. (ed.) ASIACRYPT 2010. LNCS,
vol. 6477, pp. 613–631. Springer, Heidelberg (2010)
13. Galbraith, S.D., Rotger, V.: Easy decision-diﬃe-hellman groups. LMS Journal of
Computation and Mathematics 7(2004) (2004)
14. Garg, S., Jain, A., Sahai, A.: Leakage-resilient zero knowledge. In: Rogaway, P.
(ed.) CRYPTO 2011. LNCS, vol. 6841, pp. 297–315. Springer, Heidelberg (2011)
15. Groth, J.: Homomorphic trapdoor commitments to group elements. IACR Cryp-
tology ePrint Archive 2009, 7 (2009)
16. Groth, J., Sahai, A.: Eﬃcient non-interactive proof systems for bilinear groups. In:
Smart, N.P. (ed.) EUROCRYPT 2008. LNCS, vol. 4965, pp. 415–432. Springer,
Heidelberg (2008)
17. Huang, Q., Wong, D.S., Zhao, Y.: Generic transformation to strongly unforgeable
signatures. In: Katz, J., Yung, M. (eds.) ACNS 2007. LNCS, vol. 4521, pp. 1–17.
Springer, Heidelberg (2007)
18. Krawczyk, H., Rabin, T.: Chameleon signatures. In: NDSS. The InternetSociety
(2000)
19. Lewko, A., Lewko, M., Waters, B.: How to leak on key updates. In: Proceedings of
the Forty-third Annual ACM Symposium on Theory of Computing, STOC 2011,
pp. 725–734. ACM, New York (2011)
20. Malkin, T., Teranishi, I., Vahlis, Y., Yung, M.: Signatures resilient to continual
leakage on memory and computation. In: Ishai, Y. (ed.) TCC 2011. LNCS, vol.
6597, pp. 89–106. Springer, Heidelberg (2011)
21. Scott, M.: Authenticated id-based key exchange and remote log-in with simple
token and pin number. Cryptology ePrint Archive, Report 2002/164 (2002). http://
eprint.iacr.org/
22. Shamir, A., Tauman, Y.: Improved online/oﬄine signature schemes. In: Kilian, J.
(ed.) CRYPTO 2001. LNCS, vol. 2139, pp. 355–367. Springer, Heidelberg (2001)
23. Steinfeld, R., Pieprzyk, J., Wang, H.: How to strengthen any weakly unforgeable
signature into a strongly unforgeable signature. In: Abe, M. (ed.) CT-RSA 2007.
LNCS, vol. 4377, pp. 357–371. Springer, Heidelberg (2006)
24. Teranishi, I., Oyama, T., Ogata, W.: General conversion for obtaining strongly
existentially unforgeable signatures. In: Barua, R., Lange, T. (eds.) INDOCRYPT
2006. LNCS, vol. 4329, pp. 191–205. Springer, Heidelberg (2006)

Generic Transformation to sEUF Signature Schemes with CLR
229
25. Verheul, E.R.: Evidence that XTR is more secure than supersingular elliptic curve
cryptosystems. In: Pﬁtzmann, B. (ed.) EUROCRYPT 2001. LNCS, vol. 2045, pp.
195–210. Springer, Heidelberg (2001)
26. Wang, Y., Tanaka, K.: Generic transformation to strongly existentially unforgeable
signature schemes with leakage resiliency. In: Chow, S.S.M., Liu, J.K., Hui, L.C.K.,
Yiu, S.M. (eds.) ProvSec 2014. LNCS, vol. 8782, pp. 117–129. Springer, Heidelberg
(2014)
27. Wang, Y., Tanaka, K.: Strongly simulation-extractable leakage-resilient NIZK. In:
Susilo, W., Mu, Y. (eds.) ACISP 2014. LNCS, vol. 8544, pp. 66–81. Springer,
Heidelberg (2014)
www.ebook3000.com

Constant Size Ring Signature
Without Random Oracle
Priyanka Bose(B), Dipanjan Das, and Chandrasekharan Pandu Rangan
Indian Institute of Technology, Madras, Adyar, Chennai 600036, Tamilnadu, India
{priyab,dipanjan,rangan}@cse.iitm.ac.in
Abstract. Ring signature enables an user to anonymously sign a mes-
sage on behalf of a group of users termed as ‘ring’ formed in an ‘ad-hoc’
manner. A naive scheme produces a signature linear in the size of the
ring, but this is extremely ineﬃcient when ring size is large. Dodis et
al. proposed a constant size scheme in EUROCRYPT’13, but its security
is provided in random oracle model. Best known result without random
oracle is a sub-linear size construction by Chandran et al. in ICALP’07
and a follow-up work by Essam Ghadaﬁin IMACC’13. Therefore, con-
struction of a constant size ring signature scheme without random oracle
meeting stringent security requirement still remained as an interesting
open problem.
Our ﬁrst contribution is a generic technique to convert a compat-
ible signature scheme to a constant-sized ring signature scheme. The
technique employs a constant size set membership check that may be
of independent interest. Our construction is instantiated with asymmet-
ric pairing over groups of composite order and meets strongest security
requirements, viz. anonymity under full key exposure and unforgeabil-
ity against insider-corruption without using random oracle under simple
hardness assumptions. We also demonstrate a concrete instantiation of
the scheme with Full Boneh-Boyen signature scheme.
Keywords: Ring signature · Constant size · Groth-sahai protocol · Set
membership · Zero-knowledge
1
Introduction
The idea of ring signature was introduced by Rivest, Shamir and Tauman [26].
Ring signature leaks no information more than the endorsement of the mes-
sage by some ring member. Unlike a group in a group signatures [12], a ring is
not administered by a manager. In practice, ring members may be completely
unaware of each others’ inclusion in the ring. To form a ring, the real signer arbi-
trarily chooses a set of potential signers including himself, thus concealing his
identity. Since rings are formed on-the-ﬂy, notions such as addition or deletion
of users, revocation of signing rights or divulging the anonymity of the actual
signer etc. are irrelevant.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 230–247, 2015.
DOI: 10.1007/978-3-319-19962-7 14

Constant Size Ring Signature Without Random Oracle
231
Apart from regular properties, e.g. correctness and unforgeability that any
signature scheme must have, ring signature [2] mandates anonymity. Correctness
allows a ring member to sign on a message on behalf of the ring. Unforgeability is
deﬁned by the impossibility of a new signature to be generated by an adversary
on behalf of the ring. Finally, anonymity demands a signature not being traceable
to its signer. In other words, signatures produced on a message by any two
members of the ring have identical distributions.
The prime application of ring signature is in anonymous leaking of sensitive
secrets as suggested in the original paper [26]. Another application is designated
veriﬁer signatures [19], where the veriﬁer designated by conﬁrmer/prover can
obtain validity or invalidity of the proof. For more applications, refer to [14][24].
Such protocol, often with additional blindness requirement, ﬁnds its relevance
in e-voting or e-cash.
Table 1 gives a quick survey on PKI based ring signatures.
1.1
Motivation
Most of the ring signature constructions [26][1][5][18][2][13][28][8][27][9] are of
linear size with respect to the size of the ring. First four constructions are in
random oracle model (ROM), remaining ones but the last are without random
Table 1. Survey of Ring Signatures in PKI Setting
Author
Reference
Size
Model
Remarks
Rivest et al.
[26]
O(N)
ROM
Trapdoor permutation
Abe et al.
[1]
O(N)
ROM
RSA and DL based signatues
Boneh et al.
[5]
O(N)
ROM
Co-GDH based signature
Herranz et al.
[18]
O(N)
ROM
Based on Schnorr ring signature
Bender et al.
[2]
O(N)
w/o ROM
ZAP based, ineﬃcient
Chow et al.
[13]
O(N)
w/o ROM
(q, n)-DsjSDH assumption
Shacham et al.
[28]
O(N)
w/o ROM
User keys belong to same group
Boyen
[8]
O(N)
w/o ROM
First unconditional anonymity
Schage et al.
[27]
O(N)
w/o ROM
Weak notion of unforgeability
Brakerski et al.
[9]
O(N)
Standard
Weak notion of unforgeability
Chandran et al.
[10]
O(
√
N)
w/o ROM
FBB scheme in composite order
Yuen et al.
[30]
O(
√
N)
Standard
Stronger deﬁnition of anonymity
Ghadaﬁ
[16]
O(
√
N)
w/o ROM
Uses GS NIZK protocol
Dodis et al.
[14]
O(1)
ROM
Fiat-Shamir transformation
Our
construction
-
O(1)
w/o ROM
Composite order group
www.ebook3000.com

232
P. Bose et al.
oracle (RO) and the last one is in standard model. Often there are some limita-
tions, e.g. [2] makes use of generic ZAP, which is a 2-round, public-coin, witness-
indistinguishable proof system for any language in NP, hence ineﬃcient and far
from being practical. Chow et al. introduced a new strong assumption in [13].
First sub-linear size ring signature scheme with O(
√
N) signature size was pro-
posed by Chandran, Groth and Sahai [10] followed by Ghadaﬁ[16]. Both the
schemes are provably secure without random oracle. To the best of our knowl-
edge, only constant size ring signature scheme in PKI setting known so far is by
Dodis et al. [14]. But, their approach uses Fiat-Shamir transformation and prov-
ably secure in random oracle model. So the challenge of achieving constant-size
ring signature without random oracle motivated our research.
1.2
Our Contribution
Our major contribution is to present a generic technique to build a ring signa-
ture scheme on top of any compatible signature scheme, (such as Full-Boneh-
Boyen [3]) having size independent of the cardinality of the ring. The scheme is
instantiable in the most eﬃcient Type-3 bilinear setting without any compromise
in eﬃciency. We have attained the strongest possible security [2], e.g. anonymity
under full key exposure and unforgeability against insider-corruption without
using random oracle. Also we present a concrete instantiation of the technique
to compare it with the existing schemes.
Lastly, our ring signature uses an O(1) size membership checking protocol to
test the containment of an integer in a public set. It makes use of Groth-Sahai
[17] commitment to realize witness indistinguishability and zero-knowledgeness.
The protocol as well as its proof may be of independent interest.
1.3
Paper Organization
The paper is organized as follows: section 2 provides the necessary background
pertaining to the ideas used in the paper. In section 3, we introduce a non-
interactive, constant size membership proof to prove the knowledge of an element
of a public set. Our main contribution, the construction of a constant-sized
ring signature for PKI based cryptosystems is outlined in section 4. We have
instantiated our construction in section 5. Conclusion and future directions are
oﬀered in section 6.
2
Preliminaries
2.1
Notations
By PPT, we mean a probabilistic polynomial time algorithm with respect to
a security parameter κ. All adversaries deﬁned here will be PPT except stated
otherwise. Given a probability distribution D and an element y, y ←D denotes
selecting an element y according to D. Let A be a probabilistic algorithm, then

Constant Size Ring Signature Without Random Oracle
233
A(x1...xn) describes the output distribution of A based on inputs x1, x1, ..., xn.
Zn denotes set of all integers modulo n, where n is composite, product of two
safe primes. The set of all polynomials in x with coeﬃcients in Zn is represented
by Zn[x]. Let G be a group and m ∈Z. Zm
n = {xi|xi ∈Zn, i ∈[0, m −1]} and
Gm = {Xi|Xi ∈G, i ∈[0, m−1]}. A function ν : N →R+ is said to be negligible
if ∀c > 0, ∃k′ such that ν(k) < k−c for all k > k′.
2.2
Bilinear Groups
A bilinear pairing is deﬁned to be G = (n, G1, G2, GT , e, g1, g2) where we choose
G1 = ⟨g1⟩, G2 = ⟨g2⟩and GT as multiplicative groups of order n. A bilinear
pairing e is a map e : G1 × G2 →GT having the following properties.
• Bilinearity: For g1 ∈G1, g2 ∈G2 and a, b ∈Zn the following holds true:
e(ga
1, gb
2) = e(g1, g2)ab.
• Non-degeneracy: For any X ∈G1 and Y ∈G2, if e(X, Y) = 1T , the
identity element of GT , then either X is the identity of G1 or Y is the
identity of G2, but not both.
• Eﬃciently Computable: The map e should be eﬃciently computable.
Three main types of pairings exist in the literature [15][29].
– Type-1. The groups G1 and G2 are the same.
– Type-2. G1 ̸= G2, but an eﬃciently computable isomorphism ζ : G2 →G1
exists.
– Type-3. G1 ̸= G2 and no eﬃciently computable isomorphism are known to
exist between G1 and G2.
We will use asymmetric pairing over groups of composite order which can
be shown to be generated eﬃciently using the method in [21]. Meiklejohn et al.
have shown that this setting has an advantage of the resulting curve having an
embedding degree k = 1 and thus optimally eﬃcient.
2.3
Hardness Assumptions
All the hardness assumptions are stated below:
• Decisional Diﬃe-Hellman Assumption (DDH).[25] Given a cyclic gr-
oup G = ⟨g⟩, a tuple ⟨g, ga, gb, gab, gc⟩where a, b, c ∈R Zn and for all PPT
adversaries ADDH, the probability
|Pr[ADDH(g, ga, gb, gab) = 1] −Pr[ADDH(g, ga, gb, gc) = 1]| < ν(κ)
• Symmetric External Diﬃe-Hellman Assumption (SXDH).[25] DDH
holds in both groups G1 and G2.
www.ebook3000.com

234
P. Bose et al.
• Decisional Linear Assumption (DLIN).[4] For Type-1 bilinear groups
where G1 = G2 = G = ⟨g⟩, given ⟨ga, gb, gra, gsb, gt⟩and a, b, s, r, t ∈Zp
being unknown, it is hard to tell whether t = r + s or t is random.
• Subgroup Hiding Assumption (SGH).[6] Given a generation algorithm
G, which takes security parameter κ as input and gives output a tuple
⟨G, GT , e, sk⟩, where sk = (p, q) such that e : G × G →GT and G and
GT are both groups of order n = pq, it is computationally in feasible to
distinguish between an element of G and an element of Gp. Formally, for all
PPT adversaries ASGH, the probability
|Pr[(sk, G, GT , e) ←G(1κ); n = pq; sk = (p, q); x ←G :
ASGH(n, G, GT , e, x) = 0] −Pr[(sk, G, GT , e) ←G(1κ);
n = pq; sk = (p, q); x ←G : ASGH(n, G, GT , e, xq) = 0]| < ν(κ)
where ASGH outputs 1 if it believes x ∈Gp and 0 otherwise. SGH being
hard in asymmetric pairing over composite order groups means, it is hard in
both G1 and G2.
• q-Strong Diﬃe-Hellman Assumption (q-SDH).[3] Let α ∈R Zp. Given
a (q + 1)-tuple ⟨g, gα, gα2, ..., gαq⟩∈Gq+1 as input, for every adversary
Aq-SDH, the probability
Pr[Aq-SDH(g, gα, gα2, ..., gαq) = ⟨c, g
1
α+c ⟩] < ν(κ)
for any value of c ∈Zp\{−α}. Though naturally q-type assumptions are
deﬁned on prime order groups, it has been shown in [11] that all q-type
assumptions can also be proven to be secure in composite order groups pro-
vided subgroup hiding assumption (SGH) holds.
• Square Root Modulo Composite (SQROOT)[22]. Given a composite
integer n and a ∈Qn(the set of quadratic residues modulo n), it is compu-
tationally hard to ﬁnd a square root of a mod n; that is an integer x such
that x2 ≡a (mod n), where n = pq, product of two safe primes.
In all the deﬁnitions above, ν(κ) is negligible in the security parameter κ.
2.4
Groth-Sahai Proofs
Groth-Sahai[17] introduced a highly eﬃcient and ﬂexible proof system in com-
mon reference string (CRS) model that yields Non-Interactive Witness-Indistin-
guishable (NIWI) and Zero-Knowledge (NIZK) proofs. It can be used for proving
satisﬁability of certain types of equations under various cryptographic assump-
tions. This proof system can be instantiated both in prime and composite order
bilinear groups. The set of equations provable in this framework are as follows:

Constant Size Ring Signature Without Random Oracle
235
X1, ..., Xm ∈G1; Y1, ..., Yn ∈G1; x1, ..., xm′ ∈Zn and y1, ..., yn′ ∈Zn are
variables.
Pairing Product Equation (PPE):
n

i=1
e(Ai, Yi) ·
m

i=1
e(X i, Bi) ·
m

i=1
n

j=1
e(X i, Yj)γij = tT
For constants Ai ∈G1, Bi ∈G2, tT ∈GT , γij ∈Zn
Multi-scalar Multiplication Equation (MSME) in G1:
n′

i=1
yiAi +
m

i=1
biX i +
m

i=1
n′

j=1
γijyjX i = T1
For constants Ai, T1 ∈G1 and bi, γij ∈Zn
Multi-scalar Multiplication Equation (MSME) in G2:
n

i=1
aiYi +
m′

i=1
xiBi +
m′

i=1
n

j=1
γijxiYj = T2
For constants Bi, T2 ∈G2 and ai, γij ∈Zn
Quadratic Equation (QE) in Zn:
n′

i=1
aiyi +
m′

i=1
xibi +
m′

i=1
n′

j=1
γijxiyj = t
For constants ai, bi, γij, t ∈Zn
With multiplicative notation, multi-scalar multiplication equations will be
multi-scalar multi-exponential equations. For the sake of clarity, we have under-
lined the elements of the witness in the description of the equations.
Groth-Sahai proof system consists of the following four PPT algorithms as
deﬁned in [16]
• GSSetup(1κ): It takes security parameter κ as input and produces descrip-
tion of bilinear group G and secret key sk as output.
• GSCRSGen(G, sk): Given group description G as input, it outputs common
reference string (CRS) crs and an extraction key xk.
www.ebook3000.com

236
P. Bose et al.
• GSCommit(w, τw): Given a witness w ∈G and randomness τw, it produces
a commitment to w with randomness τw. We denote the commitment to a
witness w as Υw in this paper.
• GSProve(G, crs, x, w): It uses GSCommit(.,.) internally and outputs proof
φ = ⟨Υ , Γ ⟩, where Υ = ⟨c, d⟩and Γ = ⟨π, θ⟩as deﬁned in [17, p. 12]. In
symmetric setting Υ = ⟨c⟩and Γ = ⟨π⟩. In asymmetric setting for linear
equation Υ = ⟨c⟩. Here, Υ is called commitment to witnesses.
• GSVerify(G, crs, x, φ): It takes the tuple ⟨G, crs, x, φ⟩as input and outputs
1 if proof φ is accepted or 0 if rejected.
In addition to the algorithms above, we also deﬁne the following ones:
• GSExtract(G, crs, xk, φ): It takes the tuple ⟨G, crs, xk, φ⟩as input and out-
puts the witness w used in the proof φ.
• GSCRSSimGen(G): It takes group description G and outputs simulated
CRS crssim and a trapdoor key td.
• GSSimProve(G, crssim, td, x): It takes G, simulated CRS crssim and a trap-
door key td and generates simulated proofs φsim.
The system works by ﬁrst committing to the elements of the witness and then
producing the proof of satisﬁability of all equations. If one witness component
is involved in more than one equation, then same commitment is used during
veriﬁcation, thereby making the proofs correlated.
2.5
Ring Signatures - Deﬁnitions
Deﬁnition 1 (Ring Signature): A ring signature scheme is a quadruple of
PPT algorithms RSig := (RSetup, RKeyGen, RSign, RVerify) which gener-
ates public parameters, keys for users, signs message and veriﬁes the validity of
signature on a message produced by user.
• RSetup(1κ): It takes security parameter κ as input and produces public
parameters rParam as output.
• RKeyGen(rParam): Given rParam as input, it produces a secret key SK
and a public key PK.
• RSign(m, SKs, R): Given a private signing key SKs as input, it outputs a
signature Σ on message m with respect to a ring R := (PK1, PK2, ..., PKn).
We require that PKs ∈R for s ∈[1, n] where n ∈N and ⟨PKs, SKs⟩is a
valid key pair.
• RVerify(m, Σ, R): It veriﬁes a signature Σ on message m with respect to a
set of public keys in R and outputs 1 if succeeds, otherwise 0.
The quadruple RSig := (RSetup, RKeyGen, RSign, RVerify) is a secure
ring signature scheme if it satisﬁes the following properties from the literatures
[2][10].

Constant Size Ring Signature Without Random Oracle
237
Deﬁnition 2 (Correctness): [2] A ring signature scheme RSig := (RSetup,
RKeyGen, RSign, RVerify) is correct if for any polynomial p(.), a set of secret-
public key pairs {(PKi, SKi)}p(κ)
i=1 generated by RKeyGen(.), any message m and
any index j ∈[1, p(κ)], the signature Σ produced by RSign(m, SKj, R) will be
accepted by RVerify(m, Σ, R). Here R = (PK1, PK2...PKp(κ))
Deﬁnition 3 (Anonymity Against Full Key Exposure): [2] A ring sig-
nature scheme RSig := (RSetup, RKeyGen, RSign, RVerify) is anonymous
(with respect to full key exposure ) if for any adversary A and for any poly-
nomial p(.), the probability that A succeeds in the following game is negligibly
close to 1/2:
1. Key pairs (PKi, SKi)p(κ)
i=1 are generated by the challenger using rParam ←
RSetup(1κ) and RKeyGen(rParam, ωi) for randomly chosen ωi. A is given
S := (PKi)p(κ)
i=1 .
2. Throughout the game, A has access to a signing oracle Osign(s,m,R) that
outputs RSign(m, SKs, R). Here, we require PKs ∈R and s ∈[1, p(κ)].
3. A is also given access to the corrupt oracle Corrupt(i) that outputs ωi, the
random coins associated with user i.
4. A outputs a message m, two distinct indices i0 and i1 and a ring R with
the only condition that PKi0, PKi1 ∈R. It interacts with the challenger to
obtain a signature Σ ←RSign(m, SKib, R) where b ←{0, 1}.
5. A outputs a bit b′ and succeeds if b = b′.
Deﬁnition 4 (Unforgeability with Respect to Insider Corruption):
[2] A ring signature scheme RSig := (RSetup, RKeyGen, RSign, RVerify) is
unforgeable (with respect to insider corruption) if for any adversary A and for
any polynomial p(.), the probability that A succeeds in the following game is
negligible:
1. Key pairs (PKi, SKi)p(κ)
i=1 are generated by the challenger using
RKeyGen(rParam). A is given S := (PKi)p(κ)
i=1
2. Throughout the game, A has access to a signing oracle Osign(s,m,R) that
outputs RSign(m, SKs, R). Here, we require PKs ∈R.
3. A is also given access to the corrupt oracle Corrupt(i) that outputs SKi.
4. A outputs ⟨R⋆, m⋆, Σ⋆⟩and succeeds if RVerify(m⋆, Σ⋆, R⋆) = 1, A never
queried ⟨⋆, m⋆, R⋆⟩and R⋆⊆S −C, where C is the set of corrupted users.
2.6
Polynomial Commitments
Polynomial commitment is committing to a polynomial with a short string used
by some veriﬁer to conﬁrm the claimed evaluations of the committed polynomial.
An eﬃcient polynomial commitment scheme can be found in the literature in [20].
The main idea of this paper was to commit to the polynomial F(x) over a bilinear
www.ebook3000.com

238
P. Bose et al.
group with two diﬀerent types of commitment schemes based on discrete log and
Pedersen commitments. It ensures the size of the commitment to be constant, a
single group element.
We can apply the above polynomial commitment scheme to construct Zero
Knowledge Set (ZKS) [23]. ZKS allows a committer to create a short commitment
to the set of values contained in a set S and later prove statements like sj ∈S
or sj /∈S without revealing S or the upper bound of |S|. In a slightly diﬀerent
notion of ZKS, called nearly ZKS, upper bound of |S| is revealed. Kate et al.
[20] have shown an application of his polynomial commitment scheme in nearly
ZKS. Our primary idea of constructing a constant size membership proof of an
element in a public set is derived from [20].
3
Constant Size Set Membership Proof
We provide a non-interactive, constant-sized set membership proof technique
based on the application of polynomial commitment scheme in ZKS [20] and
Groth-Sahai NIZK proof system [17]. The technique allows a prover to prove the
containment of an element αδ in a set S = {α1, α2, ..., αδ, ...αN} ∈ZN
n .
The sub-linear size membership proof in [16] arranges the set elements in the
form of a square matrix. Each element of a vertical and horizontal bit vector
is committed using Groth-Sahai (GS) scheme resulting in an expensive sub-
linear blowup both in number of proofs and commitment components. GS proofs
for O(

|S|) number of MSME and QE equations as well as corresponding GS
commitments contribute to the ﬁnal size of the proof.
Our formulation constructs a polynomial F(x) having only αi ∈S, ∀i ∈
[1, |S|] as roots. The prover aims to demonstrate the existence of some secret
value αδ ∈S to the veriﬁer in a non-interactive manner without revealing its
value. While correctness of the proof system follows from the construction itself,
soundness relies on the hardness of q-SDH assumption. Veriﬁcation equations
are in the form of Pairing Product Equation (PPE) and Multi-scalar Multipli-
cation Equation (MSME) as deﬁned by GS framework. Variables which could
potentially leak out the secret value αδ are committed using GS commitment
scheme to provide required zero-knowledgeness. Our proof works both in prime
and composite order groups. However, to be able to ﬁt it as-is in our ring signa-
ture scheme, we use asymmetric pairing of composite order in the presentation.
Our membership proof consists of following four algorithms:
– MemSetup(1κ, q): This algorithm is run by a trusted authority (possibly a
distributed one to enhance security) to generate required q-SDH tuple and
initialize GS protocol.
• Initialize GS protocol ⟨G, sk⟩←GSSetup(1κ) in asymmetric setting of
composite order n = p.q where sk = ⟨p, q⟩, G = ⟨n, G1, G2, GT , e, g1, g2⟩
and q-SDH assumption holds in G1. p and q are large prime numbers.
• Generate common reference string ⟨crs, xk⟩←GSCRSGen(G, sk)
• Choose a secret key β ∈R Z∗
n

Constant Size Ring Signature Without Random Oracle
239
• Generate a (q + 1) tuple qSDH = ⟨g1, gβ
1 , gβ2
1 , ..., gβq
1 ⟩∈Gq+1
1
to accom-
modate a set of cardinality ≤q. Note that the secret key is not needed
any more and can be discarded.
• Publish public parameters mParam = ⟨G, crs, qSDH, gβ
2 ⟩
– MemWitness(mParam, αδ, S): This algorithm is run by the prover to gen-
erate witness W testifying the presence of αδ ∈S.
• Compute the polynomial F(x) = |S|
i=1(x −αi) = |S|
j=0 Fjxj, αi ∈S
• Compute the polynomial ψ(x) =
F (x)
(x−αδ) = |S|−1
i=0
ψixi
• Compute w = gψ(β)
1
= |S|−1
i=0 (gβi
1 )ψi. Note that the components of the
form gβi
1
are available to the prover as part of qSDH tuple.
• Compute D = gαδ
2
• Output the tuple W = ⟨αδ, w, D⟩as witness.
– MemProve(mParam, S, W): This algorithm is run by the prover to gener-
ate commitments for variables and GS proofs for veriﬁcation equations.
• Compute C = gF (β)
1
= |S|
i=0(gβi
1 )Fi. Note that the components of the
form gβi
1
are available to the prover as part of qSDH tuple.
• Compute t = e(C, g2)
• Compute the membership proof φmem = ⟨{Υw, Υαδ, ΥD}, Γ mem⟩
φmem ←GSProve{G, crs, {e(w, gβ
2 /D) = t ∧D = g
αδ
2 }, (αδ, w, D)}
• Send the proof φmem to the veriﬁer.
– MemVerify(mParam, S, φmem): This algorithm is run by the veriﬁer to
verify the presence of the element αδ chosen by the prover in the set S.
• Compute F(x), C and t in the same way as the prover did from publicly
available information.
• Compute c ←GSVerify{G, crs, {e(w, gβ
2 /D) = t ∧D = g
αδ
2 }, φmem}
• Announce ‘Success’ if c = 1, ‘Failure’ otherwise
Theorem 1. The set membership proof technique is correct, perfectly sound and
zero-knowledge.
Proof: Due to space constraint, detailed proof of the theorem above will be
presented in the full version of the paper [7].
Cost of the Membership Proof:
We present the cost of membership proof
and associated commitments of our construction in terms of group elements of
G1 and G2 in Table 2. Due to space constraint, detailed calculation of the sizes
of the proof elements will be presented in the full version of the paper [7].
www.ebook3000.com

240
P. Bose et al.
Table 2. Cost of our membership proofs
Components | Instantiations
DLING
DDHG1 + DLING2
SXDHG1,G2
G
G1
G2
G1
G2
GS Commitments
9
4
3
4
2
GS Proofs
18
8
6
8
6
Membership Proofs
27
21
20
4
Generic Construction of Ring Signature
We now present a construction of constant size ring signature scheme based
on our membership proof outlined in section 3. Signature scheme is a four
algorithm protocol Sig := (SSetup, SKeyGen, SSign, SVerify). Let G be a
bilinear group, M be the message space, ⟨SKi = {ski1, ski2, ..., skiM}, PKi =
{pki1, pki2, ..., pkiN}⟩be the secret and public keys (N and M are independent
of each other) of the signer i with respect to the signature scheme Sig. Let
Δ = ⟨Δ1, Δ2, ..., Δn⟩be the signature on message m ∈M and R be the ring.
The signature scheme must be a compatible one satisfying the following charac-
teristics:
– Our construction requires G = ⟨n, G1, G2, GT , e, g1, g2⟩to be a bilinear group
of composite order in asymmetric setting [21] to be able to instantiate GS
commitment scheme under SXDH assumption. Apparently for composite
order groups, SGH instantiation of GS scheme in symmetric setting could
have been the most obvious choice. But, the reason such a construction
wouldn’t work in our case is GS commitments are not fully extractable in
this setting as we require in the unforgeability game. Moreover, proofs are
Lco sound rather than being perfectly sound in this case.
– q-SDH assumption must be hard in G1 for our constant size set membership
proof to be plugged-in.
– Secret key SKi ∈ZM
n and public key PKi ∈GN
k , k ∈[1, 2]
– Veriﬁcation equations of the scheme must be MSME or PPE committable
in GS framework.
– We commit signature components in GS framework. Signature component
Δi that depends on SKi must be a group element of G1 or G2 committable
in GS framework. Unless committed, an adversary may trivially break the
signature anonymity by test verifying Δi with ∀PKj ∈R. Extractability is
important to demonstrate the impossibility of forgery by the challenger in
the unforgeability game.
Our ring signature construction is as follows:
– RSetup(1κ, q): This algorithm is run by a trusted authority (possibly a
distributed one to enhance security). GS proof system is instantiated and a
suitable hash function is chosen to associate message to ring information.

Constant Size Ring Signature Without Random Oracle
241
• mParam ←MemSetup(1κ, q). Parse mParam as public parameters
⟨G, crs, qSDH, gβ
2 ⟩of the constant size membership proof technique as
outlined in section 3. Parse G as a description of a bilinear group
⟨n, G1, G2, GT , e, g1, g2⟩of composite order n
=
p.q where q-SDH
assumption holds in G1. p and q are large prime numbers.
• Choose a collision-resistant hash function H : {0, 1}∗→M used to map
the concatenation of some pre-agreed representation of message m and
R to M
• sParam ←SSetup(1κ)
• Publish public parameters rParam = ⟨sParam, mParam, H⟩
– RKeyGen(rParam): Key generation protocol is assumed to have run by
each of the prospective ring members to generate their own secret-public key
pairs.
• Generate key-pair (SKi, PKi) ←SKeyGen(sParam, G) for all prospec-
tive ring member i ∈R
• Extend the public key of the signature scheme by computing pub-
lic integers qij = sk2
ij (mod n) ∈Zn, ∀skij ∈SKi for all prospec-
tive ring member i ∈R. Going ahead, these components will help us
in showing the correlation between the public key PKi and ring R.
Augment the public key PKi by including qi = {qij}, j ∈[1, M].
PK′
i = ⟨PKi, qi1, qi2, ..., qiM⟩acts as the extended public key for signer
i of our signature algorithm.
• Publish extended public keys {PK′
i} to the world.
– RSign(m, SKs, rParam): This algorithm is run by the real signer s having
key-pair (SKs, PKs). A ring is an M-tuple R = ⟨R1, R2, ..., RM⟩. R is
formed by s choosing a set of k potential signers, which includes himself.
There are as many ring components as q-components present in extended
public key. We denote j-th ring component as Rj = {q1j, q2j, ...qsj, ..., qkj}.
Message m and ring information R are made available for public veriﬁcation.
• Associate the message to the ring by computing m′ ←H(m||R), m ∈
{0, 1}∗
• Signer s runs Δ ←SSign(m′, SKs, sParam)
• Generate GS proofs for the signature:
φsig ←GSProve(G, crs, {SVerify(PKs, m′, Δ) = 1}, (PKs, Δ′))
• Compute witnesses:
Wj = MemWitness(mParam, qsj, Rj), ∀j ∈[1, M]
Deﬁne W = {Wj}, ∀j ∈[1, M]
www.ebook3000.com

242
P. Bose et al.
• Generate the membership proof:
φmemj ←MemProve(mParam, Rj, Wj), ∀j ∈[1, M]
Deﬁne φmem = {φmemj}, ∀j ∈[1, M].
• Generate proofs of correlation between qsj and sksj:
φqj ←GSProve(G, crs, {qsj = sksj
2}, (qsj, sksj)), ∀j ∈[1, M]
Deﬁne φq = {φqj}, ∀j ∈[1, M]
• Generate proofs of correlation between SK′
si ⊆SKs and PKs where
pksi = fpki(SK′
si), 
i
SK′
si = SKs:
φpki ←GSProve(G, crs, {pksi = fpki(SK′
si)}, (pksi, SK′
si)), ∀pksi ∈PKs
Deﬁne φpk = {φpki}, ∀pksi ∈PKs. Note that computing f −1
pki is always
hard.
• Publish message m, ring signature Σ ←⟨φsig, φmem, φq, φpk, Δ\Δ′⟩and
ring information R
– RVerify(m, R, Σ, rParam): The veriﬁer runs this algorithm to verify the
validity of the ring signature on the message with respect to the ring infor-
mation published.
• Let V E = {V Ei} be the set of veriﬁcation equations of the signature
scheme Sig. Verify the consistency of the signature,
csig ←GSVerify(G, crs, {V E}, φsig)
• Verify the membership of each q-component of signer’s extended public
key in the ring,
cmemi ←MemVerify(mParam, R, φmemi), ∀φmemi ∈φmem
• Verify proofs of correlation between qsj and sksj:
cqj ←GSVerify(G, crs, {qsj = sksj
2}, φqj), ∀j ∈M
• Verify proofs of correlation between SK′
si ⊆SKs and PKs where pksi =
fpk(SK′
si), 
i
SK′
si = SKs:
cpki ←GSVerify(G, crs, {pksi = fpk(SK′
s)}, φpki), ∀pksi ∈PKs
• Announce ‘Success’ if (csig ∧(∧
i cmemi)∧(∧
i cqi)∧(∧
i cpki)) = 1, ‘Failure’
otherwise
The idea of the proof system above is to show correlation among commit-
ments shared across equations. If a witness is involved in more than one equa-
tion, prover must use the same set of randomness to commit to that particular
witness throughout. On the other hand, veriﬁer re-uses the same commitment
during veriﬁcation which makes the proofs correlated. Intuitively, public key
PKs
φpk
−−−−−→SKs
φq
−−−−−→qs
φmem
−−−−−→ring R

Constant Size Ring Signature Without Random Oracle
243
Theorem 2. The generic construction of ring signature scheme outlined above
is a secure one satisfying correctness, anonymity and unforgeability.
Proof: Due to space constraint, detailed proof of the theorem above will be
presented in the full version of the paper [7].
5
Instantiation Based on Full Boneh-Boyen Signature
(FBB) Scheme
To quantify the reduction in size our construction oﬀers, we will now pick up
FBB scheme for a concrete instantiation. [3] proves the security of the signature
scheme for prime order groups. Their proof translates directly to composite order
model as shown by [10]. Our construction is in asymmetric setting over composite
order group [21] where both q-SDH [11] and SXDH assumptions hold.
– RSetup(1κ, q): This algorithm is run by a trusted authority (possibly a
distributed one to enhance security).
• mParam ←MemSetup(1κ, q). Parse mParam as public parameters
⟨G, crs, qSDH, gβ
2 ⟩of the constant size membership proof technique as
outlined in section 3. Parse G as a description of a bilinear group
⟨n, G1, G2, GT , e, g1, g2⟩of composite order n
=
p.q where q-SDH
assumption holds in G1. p and q are large prime numbers.
• Choose a collision-resistant hash function H : {0, 1}∗→Zn
• Publish public parameters rParam ←⟨mParam, H⟩
– RKeyGen(rParam): Key generation protocol is assumed to have run by
each of the prospective ring member i ∈R to generate their own secret-
public key pairs.
• Uniformly choose secret key SKi = ⟨ai, bi⟩∈Z2
n
• Generate FBB public key PKi
= ⟨Ai, Bi⟩= ⟨gai
2 , gbi
2 ⟩. Compute
qia = a2
i
(mod n) and qib = b2
i
(mod n). Extended public key
PK′
i = ⟨PKi, qia, qib⟩
• Publish extended public keys {PK′
i} to the outer world.
– RSign(m, SKs, rParam): This algorithm is run by the real signer s having
key-pair (SKs = ⟨as, bs⟩, PKs = ⟨As, Bs⟩). Choose k potential signers to
construct a ring R = {Ra, Rb}. Message m and ring information R are made
available for public veriﬁcation. Rename a = as, b = bs, A = As, B = Bs
• Compute m′ ←H(m||R), m ∈{0, 1}∗
• Uniformly choose r ←Zn \ { −a+m′
b
}
• Generate the signature Δ ←g
1
a+r.b+m′
1
www.ebook3000.com

244
P. Bose et al.
• Generate GS proofs for the signature:
φsig ←GSProve(G, crs, {Br = B′∧
e(Δ, A)e(Δ, B′)e(Δ, gm′
2 ) = e(g1, g2)}, (Δ, A, B, B′))
• Compute witnesses W = ⟨Wa, Wb⟩:
Wa ←MemWitness(mParam, qsa, Ra)
Wb ←MemWitness(mParam, qsb, Rb)
• Generate the membership proof φmem = ⟨φmema, φmemb⟩:
φmema ←MemProve(mParam, Ra, Wa)
φmemb ←MemProve(mParam, Rb, Wb)
• Generate proofs of correlation φq = ⟨φqa, φqb⟩between qs = ⟨qsa, qsb⟩
and SKs = ⟨a, b⟩:
φqa ←GSProve(G, crs, {qsa = a2}, (qsa, a))
φqb ←GSProve(G, crs, {qsb = b2}, (qsb, b))
• Generate proofs of correlation φpk = ⟨φpkA, φpkB⟩between SKs and
PKs:
φpkA ←GSProve(G, crs, {A = ga
2}, (A, a))
φpkB ←GSProve(G, crs, {B = gb
2}, (B, b))
• Publish message m, ring signature Σ ←⟨φsig, φmem, φq, φpk, Δ\Δ′, r⟩
and ring information R
– RVerify(m, Σ, R): The veriﬁer runs this algorithm to verify the validity
of the ring signature on the message with respect to the ring information
published.
• Verify the consistency of the signature
csig ←GSVerify(G, crs, {Br = B′∧
e(Δ, A)e(Δ, B′)e(Δ, gm′
2 ) = e(g1, g2)}, φsig)
• Verify the membership of each q-component of signer’s extended public
key in the ring,
cmema ←MemVerify(mParam, Ra, φmema)
cmemb ←MemVerify(mParam, Rb, φmemb)
• Verify proofs of correlation between qs and SKs:
cqa ←GSVerify(G, crs, {qsa = a2}, φqa)
cqb ←GSVerify(G, crs, {qsb = b2}, φqb)

Constant Size Ring Signature Without Random Oracle
245
• Verify proofs of correlation between SKs and PKs:
cpkA ←GSVerify(G, crs, {A = ga
2}, φpkA)
cpkB ←GSVerify(G, crs, {B = gb
2}, φpkB)
• Announce ‘Success’ if (csig∧(cmema∧cmemb)∧(cqa∧cqb)∧(cpkA∧cpkB)) =
1, ‘Failure’ otherwise
Theorem 3. The construction of ring signature scheme outlined above is a
secure if SXDH assumption holds, q-SDH assumption holds in G1 and the hash
function H is collision-resistant.
Proof: The proof for the theorem above follows directly from Theorem 2 and the
security proof for FBB scheme [3].
Cost of the Signature Instantiation:
We present the cost of our signature
instantiation in terms of group elements of G1, G2 and Zp in Table 3. Our ring
signature construction will consist of 50 elements from G1, 42 elements from G2
and 3 elements from Zp.
Table 3. Cost split up under SXDH assumption[17, p. 23,28]
Item Type
Item
CostG1 + CostG2
CostZp
Commitment
ΥΔ
G2
1
-
-
Commitment
ΥA
-
G2
2
-
Commitment
ΥB
-
G2
2
-
Commitment
ΥB′
-
G2
2
-
Commitment
Υa
G2
1
G2
2
-
Commitment
Υb
G2
1
G2
2
-
PPE Proof
ΓsigP P E
G4
1
G4
2
-
Linear MSME(G2)
ΓsigMSME
-
-
Z2
p
Constant
r
-
-
Z1
p
Membership Proof
φmema
G12
1
G8
2
-
Membership Proof
φmemb
G12
1
G8
2
-
Correlation Proof
Γqa
G2
1
G2
2
-
Correlation Proof
Γqb
G2
1
G2
2
-
QE Equality Proof*
-
G2
1
G2
2
-
QE Equality Proof*
-
G2
1
G2
2
-
Correlation Proof
ΓpkA
G4
1
G2
2
-
Correlation Proof
ΓpkB
G4
1
G2
2
-
Total Cost
-
G50
1 + G42
2
+ Z3
p
*We considered correlation QEs to be of the form x1y1 −x2 = 0 having
⟨{a, a}, qsa⟩and ⟨{b, b}, qsb⟩as witnesses. To deal with only one group of variables
in Zn, we implicitly added equations of the form x1 = y1
www.ebook3000.com

246
P. Bose et al.
6
Conclusion and Open Problems
We construct a ring signature without random oracle where the signature size is
independent of the size of the ring. Each user has a Full-Boneh-Boyen signature
key pair. To make a ring signature, the user computes a FBB signature, but
outputs a Groth-Sahai zero-knowledge proof that he created a valid signature
from one of the keys in a designated ring without revealing which. The key step
is to construct a GS proof whose size remains constant, using an accumulation
technique discussed in section 3.
It would be interesting to explore the possibility of applying the generic
construction to signature schemes other than FBB to achieve the same objective.
Achieving a scheme yielding signature of size shorter than our construction is
also a problem which deserves to be studied further.
Acknowledgments. The authors of this paper are grateful to Dr. Jens Groth and
anonymous reviewers of ACISP 2015 for their valuable suggestions.
References
1. Abe, M., Ohkubo, M., Suzuki, K.: 1-out-of-n signatures from a variety of keys.
In: Zheng, Y. (ed.) ASIACRYPT 2002. LNCS, vol. 2501, pp. 415–432. Springer,
Heidelberg (2002)
2. Bender, A., Katz, J., Morselli, R.: Ring signatures: stronger deﬁnitions, and con-
structions without random oracles. In: Halevi, S., Rabin, T. (eds.) TCC 2006.
LNCS, vol. 3876, pp. 60–79. Springer, Heidelberg (2006)
3. Boneh, D., Boyen, X.: Short signatures without random oracles and the sdh
assumption in bilinear groups. Journal of Cryptology 21(2), 149–177 (2008)
4. Boneh, D., Boyen, X., Shacham, H.: Short group signatures. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 41–55. Springer, Heidelberg (2004)
5. Boneh, D., Gentry, C., Lynn, B., Shacham, H.: Aggregate and veriﬁably encrypted
signatures from bilinear maps. In: Biham, E. (ed.) EUROCRYPT 2003. LNCS,
vol. 2656, pp. 416–432. Springer, Heidelberg (2003)
6. Boneh, D., Goh, E.-J., Nissim, K.: Evaluating 2-dnf formulas on ciphertexts. In:
Kilian, J. (ed.) TCC 2005. LNCS, vol. 3378, pp. 325–341. Springer, Heidelberg
(2005)
7. Bose, P., Das, D., Rangan, C.P.: Constant size ring signature without random
oracle. Cryptology ePrint Archive, Report 2015/164 (2015). http://eprint.iacr.org/
2015/164
8. Boyen, X.: Mesh signatures. In: Naor, M. (ed.) EUROCRYPT 2007. LNCS, vol.
4515, pp. 210–227. Springer, Heidelberg (2007)
9. Brakerski, Z., Kalai, Y.T.: A framework for eﬃcient signatures, ring signatures and
identity based encryption in the standard model. In: IACR Eprint archive (2010).
http://eprint.iacr.org/2010/086
10. Chandran, N., Groth, J., Sahai, A.: Ring signatures of sub-linear size without
random oracles. In: Arge, L., Cachin, C., Jurdzi´nski, T., Tarlecki, A. (eds.) ICALP
2007. LNCS, vol. 4596, pp. 423–434. Springer, Heidelberg (2007)
11. Chase, M., Meiklejohn, S.: D´ej`a Q: using dual systems to revisit q-type assump-
tions. In: Nguyen, P.Q., Oswald, E. (eds.) EUROCRYPT 2014. LNCS, vol. 8441,
pp. 622–639. Springer, Heidelberg (2014)

Constant Size Ring Signature Without Random Oracle
247
12. Chaum, D., van Heyst, E.: Group signatures. In: Davies, D.W. (ed.) EUROCRYPT
1991. LNCS, vol. 547, pp. 257–265. Springer, Heidelberg (1991)
13. Chow, S.S.M., Liu, J.K., Wei, V.K., Yuen, T.H.: Ring signatures without random
oracles. In: ASIACCS 2006, pp. 297–302. ACM Press (2005)
14. Dodis, Y., Kiayias, A., Nicolosi, A., Shoup, V.: Anonymous identiﬁcation in ad
hoc groups. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004. LNCS,
vol. 3027, pp. 609–626. Springer, Heidelberg (2004)
15. Galbraith, S.D., Paterson, K.G., Smart, N.P.: Pairings for cryptographers. Discrete
Appl. Math. 156(16), 3113–3121 (2008)
16. Ghadaﬁ, E.M.: Sub-linear blind ring signatures without random oracles. In: Stam,
M. (ed.) IMACC 2013. LNCS, vol. 8308, pp. 304–323. Springer, Heidelberg (2013)
17. Groth, J., Sahai, A.: Eﬃcient non-interactive proof systems for bilinear groups. In:
Smart, N.P. (ed.) EUROCRYPT 2008. LNCS, vol. 4965, pp. 415–432. Springer,
Heidelberg (2008)
18. Herranz, J., S´aez, G.: Forking lemmas for ring signature schemes. In: Johansson,
T., Maitra, S. (eds.) INDOCRYPT 2003. LNCS, vol. 2904, pp. 266–279. Springer,
Heidelberg (2003)
19. Jakobsson, M., Sako, K., Impagliazzo, R.: Designated veriﬁer proofs and their
applications. In: Maurer, U.M. (ed.) EUROCRYPT 1996. LNCS, vol. 1070,
pp. 143–154. Springer, Heidelberg (1996)
20. Kate, A., Zaverucha, G.M., Goldberg, I.: Constant-size commitments to polynomi-
als and their applications. In: Abe, M. (ed.) ASIACRYPT 2010. LNCS, vol. 6477,
pp. 177–194. Springer, Heidelberg (2010)
21. Meiklejohn, S., Shacham, H.: New trapdoor projection maps for composite-order
bilinear groups. Cryptology ePrint Archive, Report 2013/657 (2013). http://eprint.
iacr.org/
22. Menezes, A.J., Vanstone, S.A., Oorschot, P.C.V.: Handbook of Applied Cryptog-
raphy, 1st edn. CRC Press Inc, Boca Raton, FL, USA (1996)
23. Micali, S., Rabin, M., Kilian, J.: Zero-knowledge sets. In: Proceedings of the 44th
Annual IEEE Symposium on Foundations of Computer Science, pp. 80–91 (2003)
24. Naor, M.: Deniable ring authentication. In: Yung, M. (ed.) CRYPTO 2002. LNCS,
vol. 2442, pp. 481–498. Springer, Heidelberg (2002)
25. Naor, M., Reingold, O.: On the construction of pseudorandom permutations: Luby-
rackoﬀrevisited. Journal of Cryptology 12(1), 29–66 (1999)
26. Rivest, R.L., Shamir, A., Tauman, Y.: How to leak a secret: theory and applica-
tions of ring signatures. In: Goldreich, O., Rosenberg, A.L., Selman, A.L. (eds.)
Theoretical Computer Science. LNCS, vol. 3895, pp. 164–186. Springer, Heidelberg
(2006)
27. Sch¨age, S., Schwenk, J.: A CDH-based ring signature scheme with short signatures
and public keys. In: Sion, R. (ed.) FC 2010. LNCS, vol. 6052, pp. 129–142. Springer,
Heidelberg (2010)
28. Shacham, H., Waters, B.: Eﬃcient ring signatures without random oracles. In:
Okamoto, T., Wang, X. (eds.) PKC 2007. LNCS, vol. 4450, pp. 166–180. Springer,
Heidelberg (2007)
29. Smart, N.P., Vercauteren, F.: On computable isomorphisms in eﬃcient asymmetric
pairing-based systems. Discrete Appl. Math. 155(4), 538–547 (2007)
30. Yuen, T.H., Liu, J.K., Au, M.H., Susilo, W., Zhou, J.: Eﬃcient linkable and/or
threshold ring signature without random oracles. The Computer Journal (2012)
www.ebook3000.com

Security Protocols

Constant-Round Leakage-Resilient
Zero-Knowledge Argument for NP
from the Knowledge-of-Exponent Assumption
Tingting Zhang1,2,3(B), Hongda Li1,2,3, and Guifang Huang1,2,3
1 State Key Laboratory of Information Security, Institute of Information
Engineering of Chinese Academy of Sciences, Beijing, China
{zhangtingting,lihongda,huangguifang}@iie.ac.cn
2 Data Assurance and Communication Security Research Center
of Chinese Academy of Sciences, Beijing, China
3 University of Chinese Academy of Sciences, Beijing, China
Abstract. In this paper, we study the design of constant-round or even
3-round zero-knowledge protocols for all NP languages resistant against
side channel attack. Garg, Jain, and Sahai ﬁrstly formalize a meaningful
deﬁnition of (1 + ϵ)-leakage-resilient zero-knowledge(LRZK), and give
a construction of (1 + ϵ)-LRZK, for every constant ϵ > 0. Then, with
Barak’s non-black-box (NBB) simulation technique, Pandey presents the
ﬁrst construction of constant-round LRZK satisfying the ideal require-
ment ϵ = 0. In this paper, we focus on the construction of constant-round
(especially 3-round) LRZK protocols for all NP languages satisfying the
ideal requirement ϵ = 0, by means of other techniques. Specially, based on
extended Knowledge-of-Exponent Assumption over bilinear groups, we
obtain a constant-round LRZK argument for Hamiltonian Cycle (HC)
problem, and a 3-round LRZK arguments for circuit satisﬁability, which
is the ﬁrst 3-round LRZK protocol for NP.
Keywords: Leakage-resilient zero-knowledge · Knowledge of exponent
assumption · Bilinear map
1
Introduction
Zero-knowledge proof, introduced by Goldwasser et al. [14], has been a funda-
mental cryptographic primitive used in modern cryptography. A zero-knowledge
proof for a language L is an interactive proof where a prover P proves a state-
ment x to a veriﬁer V such that the interaction doesn’t reveal any additional
information besides the validity of the statement. It is formalized by requiring
that for every malicious veriﬁer V∗, there exists a probabilistic polynomial time
This research is supported by the National Natural Science Foundation of China
(Grant No. 61003276) and the Strategic Priority Program of Chinese Academy of
Sciences (Grant No. Y2W0012203).
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 251–269, 2015.
DOI: 10.1007/978-3-319-19962-7 15
www.ebook3000.com

252
T. Zhang et al.
(PPT) simulator S such that on input only the common input x, S can sim-
ulate a “real looking” interaction for V∗. V∗cannot distinguish the simulated
interaction with S and the real interaction with an honest prover P.
Traditionally, it is assumed that the prover’s internal state, including the
witness and the random coins, is perfectly hidden from V∗. However, in the
presence of side channel attack [19,21,25] where an adversary V∗can learn useful
information about the internal state of a cryptographic device, the traditional
notion of security becomes meaningless. To handle this problem, many recent
works considered stronger adversarial models in which the adversary can learn
some leakage on the internal state of the honest party. Now, interest has been
growing in studying leakage-resilient cryptographic primitives [1,3,6,10,12,13].
Garg et al. [13] initiated a study of leakage-resilient zero-knowledge (LRZK),
where V∗is allowed to learn arbitrary amount of leakage on the internal state
of the honest prover by making leakage queries F1, F2, ... during the protocol
execution. Intuitively, the deﬁnition of LRZK should guarantee that no such V∗
can learn anything beyond the validity of the statement and the leakage. To
formalize this intuition, [13] considers a leakage oracle, Ln
w(·), which is parame-
terized by the witness w and the security parameter n; the simulator S is then
given access to such a leakage oracle, which means that during the simulation,
S can answer leakage queries of V∗by querying Ln
w on leakage functions of its
choice. Of course, the length of bits that the simulator can read from Ln
w must be
bounded by some parameters. Formally speaking, the LRZK deﬁnition requires
that for any malicious veriﬁer V∗with total ℓ-bits leakage, there exists a sim-
ulator S which can obtain at most (1 + ϵ)ℓ-bits leakage from Ln
w, and ﬁnally
outputs a view of V∗that is computationally indistinguishable from that in the
real execution. Besides, to prevent the simulator from simply choosing to leak
on the witness instead of using the leakage oracle to only answer the leakage
queries of the veriﬁer, [13] also requires that the simulator is leakage-oblivious
which means that the oracle’s responses are sent directly to the veriﬁer and the
simulator does not get to see them. [13] presents a protocol of n
ϵ rounds, which
satisﬁes the (1 + ϵ)-LRZK for Hamiltonian Cycle (HC) problem for any ϵ > 0.
After that, using Barak’s non-black-box (NBB) simulation technique, Pandey
[22] ﬁrst presents a constant-round LRZK argument for NP, and Li Hongda
et al. [20] give a constant-round LRZK argument of knowledge for NP, both of
which satisfy the ideal requirement ϵ = 0. Up to now, most of constant-round
LRZK protocols are obtained by using Barak’s NBB simulation technique. How-
ever, using Barak’s NBB simulation technique, it is diﬃcult to achieve a 3-round
LRZK protocol for NP. In this paper, we mainly focus on how to construct
3-round LRZK protocols for NP satisfying the ideal requirement ϵ = 0.
1.1
Our Contributions
In this paper, we mainly study how to construct 3-round LRZK protocols.
Finally, under the Knowledge-of-Exponent Assumption over bilinear groups
(KEA)[2], we present a constant-round LRZK argument for HC problem, and
under the extended Knowledge-of-Exponent Assumption over bilinear groups

Constant-Round Leakage-Resilient Zero-Knowledge Argument
253
(XKEA)[2], we construct a 3-round LRZK argument for circuit satisﬁability,
which is the ﬁrst 3-round LRZK protocol for NP. And both of our protocols
satisfy the ideal requirement ϵ = 0 .
Let HC be all directed graphs that contain a Hamiltonian cycle. We ﬁrst
recall Bellare and Palacio’s three-round zero-knowledge protocol for HC (BPtzk)
from the Knowledge-of-Exponent Assumption [7].
Let q be a prime such that p = 2q + 1 is also a prime and the length of the
binary representation of p is n bits. It also assumes that if p is an n-bit prime
then any x ∈Zp can be represented by a unique n-bit string. Let Gq denote the
subgroup of quadratic residues of Z∗
p, and g is its generator. The Knowledge-
of-Exponent Assumption (KEA1) says that for any adversary A that takes as
input q, g, ga and returns (C, Y ) with Y = Ca, there exists an extractor ¯
A which
given the same inputs as A returns c such that C = gc.
Let nBHP denote a protocol which is constructed by running n parallel rep-
etitions of the 3-round Blum Hamiltonicity protocol for HC, and (M1, Y, M2)
denote the three messages exchanged in nBHP. Informally speaking, if the sim-
ulator S can decide the challenge string Y before it generates the ﬁrst message
M1, then it can simulate correctly by generating M1 depending on Y . Therefore,
BPtzk is constructed by modifying the way of generating Y in nBHP: in the ﬁrst
round, the prover P generates M1 and p, q, g, ga; then the veriﬁer V sends (B, X)
such that X = Ba; ﬁnally, P generates C, Y such that Y = Cb, and computes
M2 using Y as the challenge string. From KEA1, there exists an extractor for
V which can output b such that B = gb, which means that the simulator S can
control over the ﬁnal challenge Y by computing C = Y
1
b . Thus, S can simulate
correctly. That is, S can generate M1 depending on a random selected challenge
Y , and then makes the ﬁnal challenge string be equal to Y .
To make BPtzk be leakage-resilient zero-knowledge, there are two problems to
be considered. The ﬁrst problem is that KEA1 will not hold when the adversary
can launch leakage attacks. Since if the adversary can query the leakage of a, he
can compute a with just one bit leakage, which means that the adversary can
generate B without knowing b. The second problem is that to respond leakage
queries during simulation, the simulator S needs to “explain its actions” so far
by maintaining that the relation between its messages and state is the same as
the relation between an honest prover’s messages and state, which means that
to emulate an honest prover’s behavior, after sending M1, S must be able to
explain its randomness used in generating commitments in M1, in a way that is
consistent with the prover’s input and the commitments it generated so far in
the protocol. To this end, S is required to be able to reveal the commitment to
1 (or 0) as the commitment to 0 (or 1). This contradicts the binding property
of the commitment scheme.
To deal with the ﬁrst problem, we require that A is not generated by ﬁrst
choosing a ∈Zq and then computing A = ga, but is directly selected from Gq.
Then, to decide the correctness of the pair (B, X), we use the property of bilinear
groups. Thus, we need the KEA assumption [2]. To solve the second problem, we
follow the idea of [13] by making the commitment scheme used in generating M1
www.ebook3000.com

254
T. Zhang et al.
be a trapdoor commitment scheme. We use a new bit commitment scheme ⟨C, R⟩
(presented in Fig.1), which is modiﬁed from Pedersen’s commitment scheme.
Let BG = (G, H, q, g, e) be a bilinear group (described in Section 2.2). The
commitment key is CRS = (BG, h = gt) and the trapdoor is t. In the protocol,
the commitment key can be jointly generated by the prover P and the veriﬁer
V where P generates (BG, Z) with Z ←G, and then V generates a pair (h, ˆh)
such that e(g, ˆh) = e(h, Z). Then, if the KEA holds, there exists an extractor
for V that can extract t so that h = gt. Combining the above analysis, we can
construct a constant-round LRZK protocol for HC. However, it is not 3-round.
And we ﬁnd it is diﬃcult to construct a 3-round LRZK protocol by modifying
nBHP. Since to make the simulator S get the trapdoor, we need extra rounds.
To construct a 3-round LRZK protocol for NP, we must seek for other
solutions. We consider the idea of constructing non-interactive zero-knowledge
(NIZK) for circuit satisﬁability problem in [2,15]. Recall that in the protocol,
the prover P ﬁrst commits to the value in each circuit wire, and then for every
gate g with input wires a, b and output wire c, P generates a proof to prove that
c is equal to g(a, b). Following this idea, we construct our 3-round LRZK proto-
col by generating the common reference string of the NIZK protocol in the ﬁrst
two round, and then generating the commitments and proofs in the third round.
For soundness, we need the commitment scheme to be extractable. This can be
satisﬁed by using the XKEA assumption which says that for any adversary A
that takes as input (BG, h, gx, hx) and returns (A, ˆA), there exists an extractor
XA which given the same inputs as A and returns (a, α) such that A = gahα.
Thus, CRS = (BG, h = gt, ˆg, ˆh) satisfying e(g, ˆh) = e(ˆg, h), and the trapdoor is t.
The scheme is presented in Fig.2. Roughly speaking, our 3-round LRZK proto-
col is constructed as following: in the ﬁrst two round, the prover and the veriﬁer
jointly generate the commitment key; in the third round, the prover generates
corresponding commitments and proofs. Since XKEA holds, the zero-knowledge
simulator can obtain the trapdoor t before generating the third message, which
means that the leakage query can be handled as in [13].
1.2
Related Works
Since being conceptualizing by Goldwasser et al. [14], zero-knowledge proof
systems have been studied in various adversarial settings such as concurrency
attacks [11], malleability attacks [9], reset attacks [5], and so on. KEA1 was
ﬁrstly introduced and used by Damg˚ard in [8]. And later, Hada and Tanaka [18]
extended the KEA1 to KEA2, and used it to show the existence of 3-round,
negligible-error zero-knowledge for NP. But after that, Bellare and Palacio [7]
showed that KEA2 is false, and presented a new version called KEA3 for sav-
ing Hada and Tanaka’s results. In past few years, there have been a number
of interesting researches applying these knowledge of exponent assumptions to
zero-knowledge [2,16,17,24].
The study of leakage-resilient cryptography is initiated by Dziembowski and
Pietrzak [12]. In recent years, a few works focus on the leakage-resilient inter-
active protocols have been worked out, such as leakage-resilient identiﬁcation

Constant-Round Leakage-Resilient Zero-Knowledge Argument
255
schemes [1,10], leakage-resilient multiparty computation [6], leakage-resilient
interactive proofs [3,4,13,20,22] and so on.
2
Preliminaries
We ﬁrst give some standard notations used in this paper. The set of natural
numbers is represented by N. In the following section, we will use n ∈N to
denote the security parameter, and we always implicitly require the size of the
input of all the algorithms in this paper to be bounded by some polynomial in n.
For non-uniform probabilistic poly-time (PPT) algorithms, we mean algorithms
which together with 1n also get some poly-size auxiliary input auxn. For brevity,
we usually leave the dependency on n (and on auxn) implicit. By y ←A(x),
we mean that algorithm A is executed on input x (and 1n, in the non-uniform
case, auxn) and the output is y. Similarly, for any ﬁnite set S, we write y ←S
to denote that y is sampled uniformly from S.
Besides, we assume familiarity with standard concepts such as interactive
Turing machines, interactive proof system, computational indistinguishability,
commitment schemes, NP-languages, witness relations and so on.
2.1
Leakage-Resilient Zero-Knowledge
Let ⟨P, V⟩be an interactive proof system. In this paper, we will only refer to
argument systems which means that the soundness condition holds only against
polynomial time machines P∗.
Now, we start to present some description about leakage attacks. It is
assumed that the random coins used by a party in any particular round are
determined only at the beginning of that round. Let state denote the internal
state of the prover P, which is initialized to be the private input w of P. At the
beginning of each round i, P selects a random coins ri to be used for round i, and
then updates the current state state = state ∥ri. A leakage query on prover’s
state in round i is denoted as a leakage function Fi, to which the prover responds
with Fi(state). The leakage attack of V∗is modeled as any number of arbitrary
leakage queries on prover’s state throughout the interaction.
To formulate zero-knowledge under a leakage attack, we model the zero-
knowledge simulator S as a PPT machine that has access to a leakage oracle
Ln
w parameterized by the witness w and the security parameter n. A query to
the oracle consists of an eﬃciently computable function F, to which the oracle
responds with F(w). Finally, LRZK requires that the the output of S (denoted by
SLn
w(·)(x, z) where z is the auxiliary input) is computationally indistinguishable
from the veriﬁer’s view in the real interaction (denoted by viewV∗(x, z)).
Deﬁnition 1 (Leakage-Resilient Zero-Knowledge[22]). We say that an
interactive proof system ⟨P, V⟩for a language L ∈NP with a witness relation
R, is leakage-resilient zero-knowledge if for every PPT machine V∗that makes
any arbitrary polynomial number of leakage queries on P’s state, there exists a
PPT algorithm S such that the following two conditions hold:
www.ebook3000.com

256
T. Zhang et al.
1. For every x ∈L, every w such that R(x, w) = 1, and every z ∈{0, 1}∗,
viewV∗(x, z) and SLn
w(·)(x, z) are computationally indistinguishable.
2. For every x ∈L, every w such that R(x, w) = 1, and every z ∈{0, 1}∗,
and every suﬃciently long r ∈{0, 1}∗, it holds that ℓS(v, r) ≤ℓV∗(v), where
ℓS(v, r) is the number of bits that S receives from Ln
w when generating the
view v with randomness r, and ℓV∗(v) denote the total length of leakage
answers that V∗receives in the output v.
2.2
Bilinear Groups and Hardness Assumptions
Deﬁnition 2 (Bilinear Groups). Let BGG be a bilinear group generator that
outputs a tuple BG = (G, H, q, g, e), where G and H are cyclic groups of prime
order q, g is a generator of G and e : G × G →H is a non-degenerate bilinear
map, i.e., ∀X, Y ∈G, ∀a, b ∈Zq : e(Xa, Y b) = e(X, Y )ab, and e(g, g) generates
H. In this paper, we assume that given BG = (G, H, q, g, e), one can eﬃciently
verify that BG is a valid bilinear map. Let Ln
BG denote the set of {(G, H, q, g, e)},
where (G, H, q, g, e) is a bilinear group and q is an n-bit prime. Besides, we also
assume that if q is an n-bit prime then any x ∈Zq can be represented by a unique
n-bit string, and for simply, we just use x to denote this unique string.
In some cases, we assume the Diﬃe-Hellman Inversion Assumption, DHIA,
which states that given a random h = gw ∈G, it is infeasible to compute g1/w.
Assumption 1 (DHIA[2]). For every non-uniform PPT algorithm A,
Pr[BG ←BGG, h ←G, g1/w ←A(BG, h) : h = gw] ≤negl.
Next, we will describe a new assumption, called VDHIA, which is very similar
to DHIA. VDHIA says that given a Diﬃe-Hellman tuple (ga, gb, gab), it is diﬃcult
to compute g1/b even when a is chosen maliciously by the adversary. Clearly, any
adversary that can break DHIA can also be used to break VDHIA. This indicates
that VDHIA is an extension of DHIA.
Assumption 2 (VDHIA). For every non-uniform PPT algorithm A, consider
the following probabilistic experiment:
– A on input (′Step1′, 1n) outputs (BG, A), where A ∈G;
– Given (BG, A) as input, the experiment selects b ∈Z∗
q, and outputs (B =
gb, X = Ab) to A.
The VDHIA says that, if (g, A, B, X) is a Diﬃe-Hellman tuple, then for suﬃ-
ciently large n,
Pr[B∗←A(′Step2′, g, A, B, X) : B∗= g1/b] ≤negl.
Besides, we need the KEA assumption, which states that given h = gw ∈G
with unknown discrete-log w, it is infeasible to create A, ˆA so ˆA = Aw with-
out knowing a so A = ga, and the XKEA assumption, which says that given
(g, h, gx, hx), it is infeasible to create A, ˆA so ˆA = Ax without knowing a, α so
A = gahα [2].

Constant-Round Leakage-Resilient Zero-Knowledge Argument
257
Assumption 3 (KEA). For every non-uniform PPT algorithm A, there exists
a non-uniform PPT algorithm XA, the extractor, such that
Pr
BG ←BGG, x ←Zq
(A, ˆA; a) ←(A ∥XA)(BG, gx) : ˆA = Ax ∧A ̸= ga

≤negl.
Where (A, ˆA; a) ←(A ∥XA)(BG, gx) means that A and XA are executed on the
same input (BG, gx) and the same random tape, and A outputs (A, ˆA) whereas
XA outputs a.
Assumption 4 (XKEA). For every non-uniform PPT algorithm A, there
exists a non-uniform PPT algorithm XA, the extractor, such that
Pr
BG ←BGG, h ←G, x ←Zq
(A, ˆA; a, α) ←(A ∥XA)(BG, h, gx, hx) : ˆA = Ax ∧A ̸= gahα

< negl.
3
Extractable and Trapdoor Bit Commitment Scheme
Based on DHIA and XKEA
In the Pedersen’s commitment scheme [23], given a group G of prime order q,
its generator g and an element h = gw, to commit to m ∈Zq, the committer
chooses r ←Zq, and sends C = gmhr; to open, the committer sends (m, r).
This commitment scheme is perfectly hiding and computationally binding. And
if the committer holds w (the discrete log of h), it can open C = gmhr as being
a commitment to any m′ ∈Zq by computing r′ = (m + r · w −m′) · w−1.
In our protocol, we require that the committed value m is exactly in {0, 1}.
However, if just given a commitment C = gmhr, the receiver cannot verify
whether m ∈{0, 1}. Thus, we add a proof for m ∈{0, 1} to the commitment.
We present the trapdoor bit commitment scheme ⟨C, R⟩in Fig.1.
Key generation: Pick BG ←BGG, w ←Zq and let h = gw. The commitment key
is CRS = (BG, h), and the trapdoor key is τ = w.
Commitment: To commit to m ∈{0, 1}, the committer C randomly chooses r ←Zq,
and computes the commitment (C, P) as follows:
C = gmhr,
P = gr(2m−1)hr2.
After receiving the commitment (C, P), the receiver R veriﬁes whether
e(C, Cg−1) = e(h, P). If not, the receiver aborts. Else, the receiver believes that
the message committed in (C, P) is 0 or 1.
Opening: The committer C sends (m, r), and then the receiver R accepts if C =
gmhr and P = gr(2m−1)hr2.
Fig. 1. Commitment Scheme ⟨C, R⟩
www.ebook3000.com

258
T. Zhang et al.
Theorem 1. If the DHIA holds, ⟨C, R⟩is a perfectly hiding and computationally
trapdoor bit commitment scheme.
Proof. The required security properties can be seen as follows.
Correctness: It is easy to verify that an honest receiver always accepts the
commitment of an honest committer. Besides, we also need to prove that for
any accepted commitment (C, P), the message hidden in it is equal to 0 or
1. Suppose there exists a non-uniform PPT adversary that can create a pair
(C = gmhr, P) such that e(C, Cg−1) = e(h, P) but m /∈{0, 1}. Then, we have
e(h, P) = e(C, Cg−1) = e(g, gm(m−1)+(2m−1)wr+(wr)2).
This implies gm(m−1)w−1 = Pg−((2m−1)r+wr2). Thus, when m /∈{0, 1}, we can
get g
1
w = (Pg(1−2m)rh−r2))
1
m(m−1) . Therefore, given the opening of C, we can
compute g
1
w , which contradicts the DHIA.
Perfectly Hiding: For any valid commitment (C, P), we assume that C = gα and
P = gβ. Consider the following equations where m, r are variables,
⎧
⎨
⎩
α = m + wr
β = r(2m −1) + wr2
β = α(α −1)w−1
Clearly, computing the message hidden in (C, P) is equivalent to compute the
solution of the above equations. It is easy to see that these equations only have
two solutions: (m = 0, r = αw−1) and (m = 1, r′ = (α −1)w−1). Thus, the
probability that the committed value in (C, P) is 0 is identical to the probability
that the committed value in (C, P) is 1.
Computationally Binding: Suppose a non-uniform PPT adversary creates two
diﬀerent openings (m, r) and (m′, r′) for a commitment (C, P), i.e., gmhr =
gm′hr′. Then one can easily compute w = (m −m′)(r −r′)−1 such that h = gw.
Computationally Trapdoor: To generate a trapdoor commitment, the simulator
just randomly chooses r ←Zq, and computes (C = hr, P = g−rhr2). To open
to 0, the simulator just sends (0, r). To open to 1, the simulator just computes
r′ = (r · w −1) · w−1, and sends (1, r′). Since r is randomly selected, it is easy
to see that the trapdoor commitment (C, P) is also random, which is just the
same as the commitment generated by an honest committer.
⊓⊔
In our 3-round LRZK protocol, we need a commitment scheme which is
extractable and equivocal. From the XKEA, we know that given BG, h ←G,
ˆg = gx, and ˆh = hx where x ←Zq, if an adversary can produce a pair (A, ˆA)
such that ˆA = Ax, then there exists a non-uniform poly-time algorithm XA, the
extractor, that can extract a pair (a, α) such that A = gahα. Following this idea,
we add a commitment C = ˆgmˆhr to the commitment pair (C, P). The details
are in Fig.2.

Constant-Round Leakage-Resilient Zero-Knowledge Argument
259
Key generation: Pick BG ←BGG, w ←Zq, ˆg ←G, and let h = gw, ˆh = ˆgw. The
commitment key is CRS = (BG, h, ˆg, ˆh), and the trapdoor key is τ = w.
Commitment: To commit to m ∈{0, 1}, the committer C randomly chooses r ←Zq,
and computes the commitments (C, C, P) as follows:
C = gmhr,
C = ˆgmˆhr,
P = gr(2m−1)hr2.
After receiving the commitments (C, C, P), the receiver R veriﬁes whether
e(C, Cg−1) = e(h, P) and e(g, C) = e(ˆg, C). If not, the receiver abort. Else, the
receiver accepts that the message committed in (C, C, P) is 0 or 1.
Opening: The committer C sends (m, r), and then the receiver R veriﬁes whether
C = gmhr, C = ˆgmˆhr and P = gr(2m−1)hr2.
Fig. 2. Commitment scheme ⟨C, 
R⟩
Theorem 2. If the XKEA and DHIA hold, ⟨C, R⟩is a perfectly hiding,
extractable and computationally trapdoor bit commitment scheme.
The proof is easy to get from the above analysis, and we omit it here. In
the following section, by (C, P) = Com(m; r), we mean that (C, P) is a com-
mitment to m with randomness r under the commitment scheme ⟨C, R⟩, and
by (C, C, P) = Com(m; r), we mean that (C, C, P) is a commitment to m with
randomness r under the commitment scheme ⟨C, R⟩.
4
Constant-Round LRZK Arguments for HC
4.1
Our Protocol
In this section, we will present our constant-round protocol ⟨P, V⟩. The protocol
consists of two stages. In Stage 1, P and V jointly generate the commitment
key CRS = (BG, h) for the commitment scheme ⟨C, R⟩(in section 3). The Stage
2 is a variant of Blum’s Hamiltionicity protocol, where instead of using Naor’s
commitment scheme, P uses the commitment scheme ⟨C, R⟩to generate its com-
mitment messages. Besides, in this stage, P and V also engage in coin-ﬂipping
to jointly generate the challenge for Blum’s Hamiltionicity protocol. The details
are presented in Fig.3.
Theorem 3. If KEA and VDHIA hold, Protocol ⟨P, V⟩is a constant-round
leakage-resilient zero-knowledge argument for HC problem.
The completeness is obvious, and we present the proof of soundness
and leakage-resilient zero-knowledge property respectively in Section 4.2 and
Section 4.3.
www.ebook3000.com

260
T. Zhang et al.
Common Input: G = (V, E) ∈HC, |V | = n.
Private Input to P: A Hamiltonian cycle H in G.
Protocol:
– Stage 1 : Jointly Generating the Parameters of ⟨C, R⟩
• P →V: Generate BG ←BGG, and Z ←G. Send (BG, Z) to V.
• V →P: If BG is not a valid bilinear group or A /∈G then abort. Else, choose
t ←Zq, and compute (h = gt, ˆh = Zt). Send (h, ˆh) to P.
– Stage 2: A Variant of Blum’s Hamiltonicity Protocol
• P →V: If e(g, ˆh) ̸= e(h, Z) then abort. Else, let CRS = (BG, h), and P does
as follows:
(1) Select ¯
BG = (¯G, ¯H, ¯q, ¯g, ¯e, ) ←Ln
BG, and A ←¯G;
(2) For every i ∈[n],
- Choose a random permutation πi and set Gi = πi(G).
- For every j ∈[n2], P commits to each bit bj in Gi using the com-
mitment scheme ⟨C, R⟩with CRS = (BG, h).
Let M1 be the set of all the commitments.
P sends (M1, ¯
BG, A) to V.
• V →P: If ¯
BG /∈Ln
BG , or A /∈¯G, or any commitment in M1 is invalid, then
abort. Else, choose b ←Z¯q, and compute B = ¯gb, X = Ab. Send (B, X) to
P.
• P →V: If ¯e(¯g, X) ̸= ¯e(A, B) then abort. Else, select c ∈{0, 1}n, and send it
to V.
• V →P: Send b to P.
• P →V: If B ̸= ¯gb then abort. Else, Let ch = c ⊕b = ch1, ..., chn. For each
i ∈[n], if chi = 0, P decommits to every edge in Gi and reveals πi; else, it
decommits to the edges in the Hamiltonian Cycle in Gi. Let M2 be the set
of all the opening messages. P sends M2 to V.
• V: Output 1 (i.e., accept) if using ch = c ⊕b as the challenge message, each
opening message in M2 is valid. Otherwise output 0.
Fig. 3. Constant-round Protocol for LRZK ⟨P, V⟩
4.2
Proving Computationally Soundness
If protocol ⟨P, V⟩is not computationally sound, then there exists a PPT cheating
prover P∗and an inﬁnite set I = {(x, w) : x /∈L} such that for every (x, w) ∈I,
there exists a polynomial p0(·) satisfying that Pr[⟨P∗, V⟩(x) = 1] > 1/p0(|x|),
where ⟨P∗, V⟩(x) represents the output of V at the end of the protocol.
In the following section, we let pi denote the prover’s i-th message, and
similarly, vi denote the veriﬁer’s i-th message. To prove the soundness of protocol
⟨P, V⟩, we just need to prove the following three facts:
– Firstly, we prove that P∗cannot equivocate its commitments, and each open-
ing message in M2 must be 0 or 1.
– Secondly, we can prove that if the commitment scheme ⟨C, R⟩is computa-
tionally binding, then for every common input G /∈L and every possible
preﬁx (p1, v1, p2), there exist at most one challenge string ch such that the
prover P∗can answer properly in its opening message M2.

Constant-Round Leakage-Resilient Zero-Knowledge Argument
261
– Finally, under the above two conditions, we can prove that if P∗can succeed
with a noticeable probability, then we can use it to construct an adversary
for VDHIA which can also succeed with a noticeable probability.
Firstly, it is easy to verify that under the VDHIA, the ﬁrst fact holds (refer-
ring to Section 3 for more details).
Secondly, if there exist a false statement G /∈L and a preﬁx (p1, v1, p2)
such that there exist at least two challenges that P∗can answer properly in its
opening message, then it is easy to compute a Hamiltonian Cycle for G, which
contradicts G /∈L.
Now, we start to prove the third fact. We ﬁrst construct an adversary A for
VDHIA. A uses P∗as a subroutine, and does as following:
Step 1: Internally interact with P∗as an honest veriﬁer on some (G, w) ∈I
till P∗successfully completes the protocol. Let trans = (p1, v1, p2), p2 =
(M1, ¯
BG, A), v2 = (B1 = gb1, X1) and the challenge be ch∗. Go to Step 2.
Step 2: A forwards ( ¯
BG, A) to the external challenger of VDHIA, and then
receives a challenge pair (B, X). Go to Step 3.
Step 3: A does as following:
(1) A selects b′ ←Z¯q and sets B′ = B¯gb′, X′ = XAb′. If B′ = B1, A
computes b = b1 −b′, outputs g
1
b and stops. Otherwise, continue.
(2) A runs P∗on (trans, B′, X′) to get its response c′. Let b∗= ch∗⊕c′. If
¯gb∗̸= B′, A goes back to (1) of Step 3. Otherwise, A computes b = b∗−b′,
outputs g
1
b and stops.
Now, we have completed the description of A. Intuitively, in Step 1, we ﬁrst ﬁnd
an accepted transcript and the unique challenge ch∗for the preﬁx trans. Then,
from the above analysis, we know that if P∗wants to successfully prove a false
statement, it must output a c′ such that c′ ⊕(b + b′) = ch∗. As a result, it is
easy to compute b.
Besides, we need to analyze the expected running time of A. Recall that we
have assumed that Pr[⟨P∗, V⟩(x) = 1] > 1/p0(|x|). Thus, the probability that
A passes the checks in Step 1 is at least 1/p0(n). In Step 2, the running time
of A is obviously polynomial. From the above analysis, we know that if P∗can
successfully prove a false statement, it must output a c′ such that c′ ⊕(b + b′) =
ch∗. Then, the probability that A passes the checks in (2) of Step 3 is at least
1/p0(n). Therefore, the expected running time of A is O(t2(n) + p0(n)(t1(n) +
t3(n))), where ti(n) is a polynomial bounding the running time of Step i.
Now, we can conclude that if there exists a cheating prover P∗can succeed
with a noticeable probability, then there exists a PPT adversary attacking the
VDHIA that can also succeed with a noticeable probability. This completes the
proof of the computationally soundness.
4.3
Proving Leakage-Resilient Zero-Knowledge
The Simulator S. Let V∗be a PPT cheating veriﬁer, and XV∗be the KEA
extractor for V∗. The simulator receives as input the security parameter 1n, an
www.ebook3000.com

262
T. Zhang et al.
n vertex Hamiltonian graph G, and uses XV∗as a subroutine. By A →B, we
mean that A sends a message to B, and similarly, A ←B means that A receives
a message from B. tape is initialized with the null string.
– Stage 1 : Jointly Generating the Parameter of ⟨C, R⟩
• S →V∗: Generate BG ←BGG, and Z ←G. Send (BG, Z) to V.
Leakage query : Update tape = tape ∥(BG, Z). After receiving a leak-
age function F from V∗, S answers it by querying Ln
H with F ′(H) =
F(H, tape).
• S ←V∗: S runs (V∗∥XV∗)(BG, Z) to get (h, ˆh; t). If e(g, ˆh) = e(h, Z)
but h ̸= gt then output abort.
– Stage 2: Blum Hamiltonicity Protocol
• S →V∗: If e(g, ˆh) ̸= e(h, Z) then abort. Else, let CRS = (BG, h), τ = t.
S does as following:
(1) Select ¯
BG = (¯G, ¯H, ¯q, ¯g, ¯e, ) ←Ln
BG, and A ←¯G;
(2) Choose ch ←{0, 1}n. For i ∈[n], if chi = 0, it commits to a random
Gi = πi(G); otherwise, it commits to a random n-cycle graph Gi.
Let M1 be the set of all the commitments.
S sends (M1, ¯
BG, A) to V∗.
Leakage query : Note that since S holds the trapdoor key τ, it can
equivocate the commitments, i.e., it can compute both the random coins
that result in a commitment to bit 0 and the random coins that result in
a commitment to bit 1, and let ρ be a string that consists of the random
coins for both cases. Besides, S also knows the ﬁnal challenge string ch.
That is to say, S can learn the double trapdoor (ch, τ) before it sends
the commitments. Thus, we can handle the leakage queries just the same
as in [13]: ﬁrst deﬁne a special deterministic function R(G, ρ, H), which
uses ρ and H to construct randomness r′ such that the honest prover
uses H and r′ will result in the exact same transcript as output by S
(i.e., the message M1). Set tape = tape ∥( ¯
BG, A) ∥r′. After receiving a
leakage query F, S answers it by sending F ′(H) = F(H, tape) to Ln
H.
• S ←V∗: Run (V∗∥XV∗)( ¯
BG, A) to get (B, X; b). If ¯e(¯g, X) = ¯e(A, B)
but B ̸= ¯gb then output abort.
• S →V: If ¯e(¯g, X) ̸= ¯e(A, B) then abort. Else, let c = ch ⊕b, and send it
to V∗.
Leakage query : Set tape = tape ∥c. After receiving a leakage function
F from V∗, S answers it by querying Ln
H with F ′(H) = F(H, tape).
• S ←V∗: Receive b∗from V∗.
• S →V: If B ̸= ¯gb∗then abort. Else, S does as following: Open the
commitments in M1 corresponding to the challenge ch. Let M2 be the
set of all the opening messages. S sends M2 to V∗.
Leakage query : Note that no new random coins are generated, i.e., tape
is unchanged. Upon receiving a leakage function F, S answers it by
querying Ln
H with F ′(H) = F(H, tape).
Now, we have completed the description of S. S outputs whatever is the ﬁnal
view of V∗.

Constant-Round Leakage-Resilient Zero-Knowledge Argument
263
Lemma 1. Protocol ⟨P, V⟩is a leakage-resilient zero-knowledge protocol.
Proof. Now, we need to prove that the view of V∗generated when interacting
with the simulator S is computationally indistinguishable from that generated
when interacting with the real prover. Consider the following hybrids:
H0: In this hybrid, the simulator S holds the witness H and interacts with V∗
just like the honest prover. Leakage queries are answered directly based on
H and the random coins it used. This corresponds to the real interaction.
H1: This hybrid is same as H0 except that in Stage 1, S runs (V∗∥XV∗)(BG, Z)
to get (h, ˆh; t). If e(g, ˆh) = e(h, Z) but h ̸= gt, then output abort. Leakage
queries are answered in the same way as in H0.
H2: This hybrid is just like in H1 except that in the fourth-round, S runs (V∗∥
XV∗)( ¯
BG, A) to get (B, X; b). If ¯e(¯g, X) = ¯e(A, B) but B ̸= ¯gb then output
abort. Leakage queries are answered in the same way as in H1.
H3: This hybrid is just like in H2 except that instead of using the witness H, S
generates the commitment messages M1 according to a randomly selected
challenge string ch ∈{0, 1}n, i.e., generates M1 by the way of simulation.
Leakage queries are handled as follows. With the witness H, S uses the func-
tion R(G, ρ, H) (described above) to select corresponding random strings,
and let r′ be the ﬁnal output of R. The simulator answers a leakage query
F by computing F(H, tape ∥( ¯
BG, A) ∥r′).
H4: This hybrid is same as H3 except that the simulator S doesn’t hold a wit-
ness any more, and thus it handles leakage queries slightly diﬀerently. After
receiving F, it creates a function F ′(H) = F(H, tape), and then sends F ′(·)
to the leakage oracle Ln
H. Note that this hybrid corresponds to our ﬁnal
simulation.
Now, we just need to prove the indistinguishability of H0 and H4, which is sat-
isﬁed if Hi is computationally indistinguishable from Hi+1 for i = 0, ..., 3.
Indistinguishability of hybrids H0 and H1 directly follows the KEA assump-
tion. Similarly, under the KEA assumption, hybrids H1 and H2 are also compu-
tationally indistinguishable.
Now, let we see hybrids H2 and H3. From the computationally hiding property
of ⟨C, R⟩, we know that the messages M1 generated in H2 is indistinguishable
from that in H3. Besides, R outputs uniform randomness consistent with the
witness used in hybrid H3, that is to say, the leakage queries are also answered
(and distributed) correctly. Thus, H2 and H3 are also indistinguishable.
Finally, obviously, the output of hybrids H3 and H4 are identically distributed.
This completes the proof.
⊓⊔
5
3-Round LRZK Arguments for Circuit Satisﬁability
In this section, we will present our 3-Round LRZK protocol for circuit satisﬁabil-
ity. Since any circuit can be linearly reduced to a circuit built from NAND-gates,
without loss of generality, we will focus on this simpler case. Before giving the
full protocol, we ﬁrst see the following observation about evaluating NAND-gates
from [15], which is easily proved by constructing a truth table.
www.ebook3000.com

264
T. Zhang et al.
Claim 1. Let a, b, c ∈{0, 1}, then a + b + 2c −2 ∈{0, 1} if and only if c =
a NAND b.
5.1
Protocol
We now present our 3-round LRZK protocol ⟨P, V⟩, which consists of three
stages. In Stage 1, the prover P and the veriﬁer V jointly generate the commit-
ment key CRS = (BG, h, ˆg, ˆh) for the commitment scheme ⟨C, R⟩(in Fig.2). In
Stage 2, the prover P ﬁrst generates commitments to the value of every wire,
and then generate a proof for each NAND-gate using Claim 1. In Stage 3, V
verify the validity of P’s messages. Details are presented in Fig.4.
Theorem 4. Assuming XKEA and VDHIA hold, protocol ⟨P, V⟩is a 3-round
leakage-resilient zero-knowledge argument for circuit satisﬁability.
Proof. We ﬁrst give the proof of completeness and soundness, and present the
proof of leakage-resilient zero-knowledge property in Section 5.2
Completeness. Firstly, every honest prover P holding a valid witness w for C,
can compute correct commitments for all wires and correct proofs for all NAND-
gates. Secondly, the correctness of ⟨C, R⟩guarantees that every committed value
is other 0 or 1. Finally, for every NAND-gate, if the associated commitments
and proof are valid, from Claim 1, the operation of NAND is also correct.
Soundness. Assume there exists a PPT adversary P∗that succeeds in proving
an unsatisﬁable circuit C with probability at least p0, we can use it to construct
an adversary A for VDHIA as follows:
1. Internally interact with P∗by acting as an honest veriﬁer. After receiving the
ﬁrst message (BG, A) from P∗, if BG is not a valid bilinear group or A /∈G,
abort. Otherwise, A forwards it to an external challenger C of VDHIA.
2. After externally receiving a valid challenge pair (h, B) from C, choose y, x ←
Zq, and set h′ = hy, B′ = By, ˆg = gx, ˆh = h′x. Send (h′, B′, ˆg, ˆh) to P∗.
3. After receiving P∗’s proof messages π, if π is invalid then abort. Else, A runs
the extractor XP∗to extract all the opening information in π. If XP∗fails,
A outputs Fail1. Else, check all the NAND-gates, and
– If there exists invalid opening messages such that C
=
gmh′r,
e(C, Cg−1)
=
e(h′, P) but m
/∈
{0, 1}, A outputs h∗
=
g
1
t
=
(Pg(1−2m)rh−r2)
y
m(m−1) .
– If there exists an inconsistent NAND-gate with associated commitments
(C0, C0, P0), (C1, C1, P1), (C2, C2, P2) and the proof P such that M =
C0C1C2
2g−2 = gmh′r, e(M, Mg−1) = e(h′, P) but m = c0+c1+2c2−2 /∈
{0, 1}, A outputs h∗= g
1
t = (Pg(1−2m)rh−r2)
y
m(m−1) .
– Otherwise, A outputs Fail2.

Constant-Round Leakage-Resilient Zero-Knowledge Argument
265
Common Input: A circuit C built from NAND-gates.
Private Input to P: An n-bit string w = w1, ..., wn such that C(w) = 1.
– Stage 1 : Jointly Generating Parameter of Commitment Scheme ⟨C, 
R⟩
• P →V: Generate BG ←BGG, and choose A ←G. Send (BG, A) to V.
• V →P: If BG is not a valid bilinear group or A /∈G then abort. Else,
randomly choose t ←Zq, ˆg ←G, and compute h = gt, B = At, ˆh = ˆgt. Send
(h, B, ˆg, ˆh) to P.
– Stage 2 : Generating the Proof
• P →V: If e(g, B) ̸= e(h, A), or e(g, ˆh) ̸= e(ˆg, h) then abort. Else, let CRS =
(BG, h, ˆg, ˆh) be the commitment key of ⟨C, 
R⟩. P does as following:
(1) Compute commitments for each bit wi as Com(wi; ri) = (Wi, 
Wi, Pi),
where Wi = gwihri, 
Wi = ˆgwiˆhri, Pi = gri(2wi−1)hr2
i .
(2) For the output of the circuit, let the commitment be Cop = g, Cop = ˆg.
(3) For every NAND-gate in C with two input values c0 and c1 which are
committed by (C0, C0, P0) = Com(c0; α) and (C1, C1, P1) = Com(c1; β),
the prover P computes commitments (C2, C2, P2) = Com(c2; γ) for the
corresponding output value c2 = c0NANDc1. Besides let C0C1C2
2g−2 =
gmhr where m = c0 + c1 + 2c2 −2 and r = α + β + 2γ, then P computes
a proof P = gr(2m−1)hr2 for this gate.
(4) Let π consist of commitments for all wires and proofs for all gates. P
sends π to V.
– Stage 3 : Veriﬁcation.
• V : Output 1 if all of the following holds, otherwise output 0.
(1) Every wire’s commitment is correct.
(2) For every NAND-gate, with associated commitments (C0, C0, P0),
(C1, C1, P1), (C2, C2, P2) and the proof P, let M = C0C1C2
2g−2, and
then M satisﬁes e(M, Mg−1) = e(h, P).
Fig. 4. Protocol ⟨P, V⟩
Obviously, A runs in poly-time. Then, we analyze the success probability of A.
First, note that A may abort in Steps 1 and 3 if P∗’s messages are invalid.
Since the distribution of the messages sent by A are identical to the messages
generated by an honest veriﬁer, Pr[ A not abort] ≥p0.
Then, we analyze the probability that A outputs Fail1 and Fail2. Clearly,
under the XKEA assumption, Pr[A outputs Fail1] ≤negl. Besides, the event
that A outputs Fail2 means that there do not exist invalid opening messages
and inconsistent NAND-gate, which implies that C must be a satisﬁable circuit.
As a result, the success probability of A is at least p0 −negl(n), which
contradicts the VDHIA. This proves the soundness.
⊓⊔
5.2
Leakage-Resilient Zero-Knowledge
The Simulator S. Let V∗be a PPT cheating veriﬁer, and XV∗be the KEA
extractor for V∗. The simulator receives as input 1n, a circuit C with n input
wires, and uses XV∗as a subroutine. tape is initialized with the null string.
www.ebook3000.com

266
T. Zhang et al.
– Stage 1: Jointly generating parameter of commitment scheme
⟨C, R⟩:
• S →V∗: Generate BG ←BGG, and pick A ←G, and send (BG, A) to V.
Leakage query : Set tape = tape ∥(BG, A). After receiving a leakage
function F from V∗, answer it by querying Ln
w with F ′(w) = F(w, tape).
• S ←V∗: Run V∗and XV∗on input (BG, A) to get (h, B; t) and (ˆg, ˆh). If
e(g, B) = e(h, A) but gt ̸= h then output abort.
– Stage 2 : Generating the Proof:
• S →V∗: If e(g, B) ̸= e(h, A) or e(g, ˆh) ̸= e(ˆg, h) then S aborts. Else, let
CRS = (BG, h, ˆg, ˆh), τ = t. S does as following:
(1) For the output wire of the circuit, let the commitment be Cop =
g, Cop = ˆg. For every other wire, S just commits to 0.
(2) For every NAND-gate in C with two input commitments (C0 =
gc0hα, 	
C0, P0) and (C1 = gc1hβ, 	
C1, P1), and an output commitment
(C2 = gc2hγ, 	
C2, P2), S computes r = α+β+2γ+(c0+c1+2c2−2)t−1,
and then computes a simulated proof P = g−rhr2 for this gate.
(3) Let π consist of commitments for all wires and proofs for all gates.
Send π to V∗.
Leakage query : Note that since S holds the trapdoor key τ, it can
equivocate the commitments, i.e., it can compute both the random coins
that result in a commitment to bit 0 and the random coins that result
in a commitment to bit 1. Let ρ be a string that consists of the random
coins for both cases. Deﬁne a function R(C, ρ, w) as follows:
(a) For the commitments corresponding to the input wires of C, R selects
from ρ the random coins corresponding to witness w.
(b) For the commitments corresponding to the middle wires of C (i.e., the
wires between the input gates and the output gate), R ﬁrst computes
the values of the middle wires using the witness w, and then selects
the random coins corresponding to these values from ρ.
Let r′ denote the concatenation of all the random coins selected from ρ in
the above manner. Finally, R outputs r′. Now, the simulator S answers
by querying Ln
w with F ′(w) = F(w, tape ∥R(C, ρ, w)).
Now, we have completed the description of S. S outputs whatever is the ﬁnal
view of V∗.
Lemma 2. Protocol ⟨P, V⟩is a leakage-resilient zero-knowledge protocol.
Proof. To prove this lemma, we need to prove that the view of V∗generated when
interacting with the simulator S is indistinguishable from the view generated
when interacting with the real prover. Let us consider the following hybrids.
H0: In this hybrid, the simulator S holds the witness w and interacts with V∗just
as the honest prover. Leakage queries are answered directly based on w and
the random coins it used. Clearly, this corresponds to the real interaction.

Constant-Round Leakage-Resilient Zero-Knowledge Argument
267
H1: This hybrid is same as H0 except that in the second round, S runs V∗and
XV∗to get (h, B; t) and (ˆg, ˆh). If e(g, B) = e(h, A) but gt ̸= h then output
abort. Leakage queries are answered in the same way as in H0.
H2: This hybrid is just like in H1 except that instead of using the witness w,
S commits to 0 for all the input wires and middle wires, and generates a
simulated proof using the trapdoor τ = t. Leakage queries are handled as
follows. With the witness w, S uses the function R(C, ρ, w) (described above)
to select corresponding random strings, and let r′ be the ﬁnal output of R.
The simulator answers a leakage query F by computing F(w, tape ∥r′).
H3: This hybrid is same as H2 except that the simulator S doesn’t hold a witness
any more. Thus it handles leakage queries slightly diﬀerently. After receiving
F, it creates a function F ′(w) = F(w, tape), and then sends F ′(·) to the
leakage oracle Ln
w. Note that this hybrid corresponds to our ﬁnal simulation.
Now, we just need to prove that the indistinguishability of H0 and H3.
Firstly, indistinguishability of hybrids H0 and H1 directly follows the KEA
assumption.
Secondly, H2 is diﬀerent from H1 only in the way of generating the commit-
ments and proofs, and answering the leakage queries.
(1) In H2, the commitments are generated by committing to 0. From the com-
putationally hiding of the commitment scheme, the commitments generated
in hybrids H1 and H2 are computationally indistinguishable.
(2) Note that the proof for C = gmhr just can proving m ∈{0, 1}. If m = 0, C =
hr, P = g−rhr2. If m = 1, C = ghr1 = g(1+tr1) = hr where r1 = r −t−1,
P ′ = gr1hr1
2 = g(r−t−1+t(r−t−1)2) = g−rhr2 = P. Thus, the distribution of
proofs generated in H2 is equal to that of proofs generated in H1.
(3) Finally, since R outputs uniform randomness consistent with the witness
used in hybrid H1, it holds that the leakage queries are also answered and
distributed correctly.
Thus, the outputs of H1 and H2 are computationally indistinguishable.
Finally, note that the simulator in hybrid H3 having access to the leakage
oracle can also answer the leakage queries correctly, i.e., the outputs of H2 and
H3 are identical.
This completes the proof.
⊓⊔
References
1. Alwen, J., Dodis, Y., Wichs, D.: Leakage-resilient public-key cryptography in the
bounded-retrieval model. In: Halevi, S. (ed.) CRYPTO 2009. LNCS, vol. 5677, pp.
36–54. Springer, Heidelberg (2009)
2. Abe, M., Fehr, S.: Perfect NIZK with adaptive soundness. In: Vadhan, S.P. (ed.)
TCC 2007. LNCS, vol. 4392, pp. 118–136. Springer, Heidelberg (2007)
3. Ananth, P., Goyal, V., Pandey, O.: Interactive proofs under continual memory
leakage. In: Garay, J.A., Gennaro, R. (eds.) CRYPTO 2014, Part II. LNCS, vol.
8617, pp. 164–182. Springer, Heidelberg (2014)
www.ebook3000.com

268
T. Zhang et al.
4. Bitansky, N., Canetti, R., Halevi, S.: Leakage-tolerant interactive protocols. In:
Cramer, R. (ed.) TCC 2012. LNCS, vol. 7194, pp. 266–284. Springer, Heidelberg
(2012)
5. Barak, B., Goldreich, O., Goldwasser, S., Lindell, Y.: Resettably-sound zero-
knowledge and its applications. In: FOCS 2002, pp. 116–125 (2001)
6. Boyle, E., Goldwasser, S., Jain, A., Kalai, Y.T.: Multiparty computation secure
against continual memory leakage. In: STOC, pp. 1235–1254. ACM (2012)
7. Bellare, M., Palacio, A.: The knowledge-of-exponent assumptions and 3-round zero-
knowledge protocols. In: Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp.
273–289. Springer, Heidelberg (2004)
8. Damg˚ard, I.: Towards practical public key systems secure against chosen ciphertext
attacks. In: Feigenbaum, J. (ed.) CRYPTO 1991. LNCS, vol. 576, pp. 445–456.
Springer, Heidelberg (1992)
9. Dolev, D., Dwork, C., Naor, M.: Non-malleable cryptography (extended abstract).
In: STOC, pp. 542–552 (1991)
10. Dodis, Y., Haralambiev, K., Lpez-Alt, A., Wichs, D.: Cryptography against con-
tinuous memory attacks. In: FOCS, pp. 511–520 (2010)
11. Dwork, C., Naor, M., Sahai, A.: Concurrent zero-knowledge. J. ACM 51(6),
851–898 (2004)
12. Dziembowski,
S.,
Pietrzak,
K.:
Leakage-resilient
cryptography.
In:
FOCS,
pp. 293–302 (2008)
13. Garg, S., Jain, A., Sahai, A.: Leakage-resilient zero knowledge. In: Rogaway, P.
(ed.) CRYPTO 2011. LNCS, vol. 6841, pp. 297–315. Springer, Heidelberg (2011)
14. Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of interactive
proof systems. In: STOC, pp. 291–304 (1985)
15. Groth, J., Ostrovsky, R., Sahai, A.: Perfect non-interactive zero knowledge for NP.
In: Vaudenay, S. (ed.) EUROCRYPT 2006. LNCS, vol. 4004, pp. 339–358. Springer,
Heidelberg (2006)
16. Groth, J.: Short pairing-based non-interactive zero-knowledge arguments. In: Abe,
M. (ed.) ASIACRYPT 2010. LNCS, vol. 6477, pp. 321–340. Springer, Heidelberg
(2010)
17. Gupta, D., Sahai, A.: On Constant-Round Concurrent Zero-Knowledge from a
Knowledge Assumption. In Cryptology ePrint Archive, Report 2012/572
18. Hada, S., Tanaka, T.: On the existence of 3-round zero-knowledge protocols.
In: Krawczyk, H. (ed.) CRYPTO 1998. LNCS, vol. 1462, pp. 408–423. Springer,
Heidelberg (1998)
19. Kocher, P.C.: Timing attacks on implementations of diﬃe-hellman, RSA, DSS, and
other systems. In: Koblitz, N. (ed.) CRYPTO 1996. LNCS, vol. 1109, pp. 104–113.
Springer, Heidelberg (1996)
20. Li, H., Niu, Q., Liang, B.: Leakage-resilient zero-knowledge proofs of knowledge
for NP. In: Lopez, J., Huang, X., Sandhu, R. (eds.) NSS 2013. LNCS, vol. 7873,
pp. 365–380. Springer, Heidelberg (2013)
21. Osvik, D.A., Shamir, A., Tromer, E.: Cache attacks and countermeasures: the
case of AES. In: Pointcheval, D. (ed.) CT-RSA 2006. LNCS, vol. 3860, pp. 1–20.
Springer, Heidelberg (2006)
22. Pandey, O.: Achieving constant round leakage-resilient zero-knowledge. In: Lindell,
Y. (ed.) TCC 2014. LNCS, vol. 8349, pp. 146–166. Springer, Heidelberg (2014)

Constant-Round Leakage-Resilient Zero-Knowledge Argument
269
23. Pedersen, T.P.: Non-interactive and information-theoretic secure veriﬁable secret
sharing. In: Feigenbaum, J. (ed.) CRYPTO 1991. LNCS, vol. 576, pp. 129–140.
Springer, Heidelberg (1992)
24. Prabhakaran, M., Xue, R.: Statistically hiding sets. In: Fischlin, M. (ed.) CT-RSA
2009. LNCS, vol. 5473, pp. 100–116. Springer, Heidelberg (2009)
25. Quisquater, J.-J., Samyde, D.: Electromagnetic analysis (EMA): measures and
counter-measures for smart cards. In: Attali, S., Jensen, T. (eds.) E-smart 2001.
LNCS, vol. 2140, pp. 200–210. Springer, Heidelberg (2001)
www.ebook3000.com

Modelling Ciphersuite and Version Negotiation
in the TLS Protocol
Benjamin Dowling(B) and Douglas Stebila
Queensland University of Technology, Brisbane, Australia
{b1.dowling,stebila}@qut.edu.au
Abstract. Real-world cryptographic protocols such as the widely used
Transport Layer Security (TLS) protocol support many diﬀerent com-
binations of cryptographic algorithms (called ciphersuites) and simulta-
neously support diﬀerent versions. Recent advances in provable security
have shown that most modern TLS ciphersuites are secure authenticated
and conﬁdential channel establishment (ACCE) protocols, but these anal-
yses generally focus on single ciphersuites in isolation. In this paper we
extend the ACCE model to cover protocols with many diﬀerent sub-
protocols, capturing both multiple ciphersuites and multiple versions,
and deﬁne a security notion for secure negotiation of the optimal sub-
protocol. We give a generic theorem that shows how secure negotiation
follows, with some additional conditions, from the authentication prop-
erty of secure ACCE protocols. Using this framework, we analyse the
security of ciphersuite and three variants of version negotiation in TLS,
including a recently proposed mechanism for detecting fallback attacks.
Keywords: Transport layer security (tls) · Ciphersuite negotiation ·
Version negotiation · Downgrade attacks · Cryptographic protocols
1
Introduction
The security of much communication on the Internet depends on the Transport
Layer Security (TLS) protocol [1–3], previously known as the Secure Sockets
Layer (SSL) protocol [4]. TLS allows two parties to authenticate each other
using public keys and subsequently establish a secure channel which provides
conﬁdentiality and integrity of messages. The general structure of all versions of
SSL and TLS is that a handshake protocol is run, in which a set of cryptographic
preferences are ﬁrst negotiated, then an authenticated key exchange protocol is
used to perform mututal or server-to-client authentication and establish a shared
session key; and then the record layer is active, in which the shared session key
is used with authenticated encryption for secure communication. TLS supports
many combinations of cryptographic parameters, called ciphersuites: as of this
writing, more than 300 ciphersuites have been standardized, with various com-
binations of digital signature algorithms, key exchange methods, hash functions,
ciphers and modes, and authentication codes.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 270–288, 2015.
DOI: 10.1007/978-3-319-19962-7 16

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
271
Given the paramount importance of TLS, formal understanding of its security
is an important goal of cryptography. Wagner and Schneier [5] were among the
ﬁrst to study SSL, and in particular compared SSLv3 [4] to SSLv2 [6]. A key
diﬀerence was that SSLv3 provided authentication of the full handshake, whereas
SSLv2 omitted the ciphersuite negotiation messages, leaving SSLv2 vulnerable
to ciphersuite rollback attacks: an active attack could force clients and servers
to negotiate weaker ciphersuites than the best they mutually support.
Provable Security of TLS. A signiﬁcant body of work is devoted to studying
the provable security of TLS: the majority of it focuses on individual cipher-
suites. Early work on the provable security of TLS analyzed truncated forms
of the TLS handshake [7,8] and a simpliﬁed record layer [9]. More recently,
unmodiﬁed versions of the TLS constructions have been studied by introducing
suitable security deﬁnitions. Paterson et al. [10] showed that certain modes of
authenticated encryption in the TLS record layer satisfy a property known as
secure length-hiding authenticated encryption. In 2012, Jager et al. [11] showed
that, under suitable assumptions on the underlying cryptographic primitives, the
signed-Diﬃe–Hellman TLS ciphersuite is a secure authenticated and conﬁdential
channel establishment (ACCE) protocol, yielding the ﬁrst full proof of security
of an unmodiﬁed TLS ciphersuite. Subsequent eﬀorts [12–14] have shown that
most other TLS ciphersuites (using static or ephemeral Diﬃe–Hellman, RSA key
transport, or pre-shared keys) are also secure. Other recent approaches to analyz-
ing TLS include an alternative composability notion [15] and formal veriﬁcation
of an implementation [16].
Previous security results on TLS all focus on analyzing a single ciphersuite
in isolation. Among other things, TLS allows for versions and ciphersuites to be
negotiated within the protocol, sessions to be resumed, renegotiation within a
session. Moreover, in practice servers often use the same long-term key in many
diﬀerent ciphersuites, and browsers re-attempt failed handshakes with lower
versions. This variety of complex functionality leaves a gap between single-
ciphersuite results and real-world security. Some work has tried to bridge that
gap: Giesen et al. [17] extended the ACCE model to analyze the renegotiation
security of TLS in light of the attack of Ray and Dispensa [18]; Mavrogiannopou-
los et al. [19] demonstrated a cross-ciphersuite attack ﬁrst suggested by Wagner
and Schneier [5] when the same long-term signing key is used in two diﬀerent
key exchange methods; Bergsma et al. [20] developed an ACCE-based model for
multi-ciphersuite security and showed that the Secure Shell (SSH) protocol is
multi-ciphersuite security, though the Mavrogiannopolous et al. attack rules out
a general proof that TLS is multi-ciphersuite secure; and Bhargavan et al. [21]
showed that some combinations of ciphersuites do support key agility (a concept
related to multi-ciphersuite security).
Ciphersuite and Version Negotiation. This work aims to give a formal treatment
of the negotiation of ciphersuites and versions in real-world protocols like TLS.
For ciphersuite negotiation in TLS, the client sends in its ﬁrst handshake mes-
sage a list of its supported ciphersuites in order of preference, and the server
www.ebook3000.com

272
B. Dowling and D. Stebila
responds with one of those that it also supports. With regards to version negoti-
ation, most browsers and servers support multiple versions of SSL and TLS, with
the majority supporting and accepting SSLv3 and TLSv1.0 (with more modern
software also supporting TLSv1.1 and TLSv1.2). The diﬀerences between ver-
sions can signiﬁcantly aﬀect security: TLSv1.1 and TLSv1.2 are less vulnerable
to certain weaknesses in record layer encryption in some ciphersuites; SSLv3
does not support extensions in the ClientHello and ServerHello negotiation
messages; and some extensions such as the Renegotiation Information Exten-
sion [22] are essential to prevent certain types of attacks; and some ciphersuites
with newer, more eﬃcient and secure algorithms are only supported in TLSv1.2.
The TLS protocol standards support a limited version negotiation mecha-
nism at present: the client sends the highest version it supports, and the server
responds with the highest version it supports that is less than or equal to the
client’s version, and that is the version the parties continue to use. However,
some server implementations do not correctly respond to ClientHello messages
containing higher versions, and instead of returning their highest supported ver-
sion in the ServerHello message will instead fail and return an error. Thus, in
practice a more complex version negotiation mechanism is often employed by
web browsers, sometimes called the “downgrade dance”. The client’s browser
will try to negotiate the highest version it supports (say, TLSv1.2); if the hand-
shake fails, then the browser will retry with each lower enabled version (TLSv1.1,
TLSv1.0, SSLv3) until it succeeds. This improved compatibility with incorrect
server implementation comes at the cost of decreased eﬃciency and more impor-
tantly decreased security: the client and server have no way of detecting whether
the negotiated version is actually the highest version they both support or a lower
version due to an attacker maliciously injecting failure messages. In light of this
potential downgrade attack, a very recent Internet-Draft by M¨oller and Lan-
gley has proposed a new backwards-compatible mechanism for detecting such
attacks [23], but as of this writing has yet to be standardized or deployed. The
SCSV extension is proposed to work as follows: If the client is falling back to an
earlier version due to a handshake failure, the client includes the SCSV value
indicating that it has fallen back; if the server observes the fallback SCSV but
supports a higher version than the client requests, the server returns an error
indicating that inappropriate fallback has been detected.
Contributions. We investigate the security of version and ciphersuite negotiation
in TLS. We do so by introducing an extension to the ACCE security model that
generically captures negotiation of “sub-protocols”. In particular, using ideas
from the multi-ciphersuite ACCE security experiment of Bergsma et al. [20], we
extend the ACCE security experiment to include “sub-protocols”: a single proto-
col (such as TLS) consists of a negotiation protocol NP and several sub-protocols
# –
SP (such as diﬀerent ciphersuites or diﬀerent versions), and in each session the
parties use the negotiation protocol to identify which sub-protocol they will use
for that session. We deﬁne secure negotiation for a negotiable protocol, and
use this to derive a negotiation-authentication theorem which allows us to relate
the security of sub-protocol negotiation to ACCE authentication under certain

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
273
conditions. Intuitively, if each sub-protocol individually is a secure ACCE pro-
tocol with an independent long-term key, and if the transcript of all of the
messages in the negotiation protocol is authenticated by the sub-protocol, then
the authentication detects any attempt by an attacker to carry out a downgrade
attack. It is important to note that the aforementioned cross-ciphersuite attack
breaks ACCE authentication security under long-term key reuse setting; thus,
in order to obtain results on multi-ciphersuite TLS, our framework assume long-
term keys are independent for each sub-protocol. Existing analyses of TLS show
([11–14]) that authentication security of TLS holds under independent long-term
key assumptions.
Having established the secure negotiation framework and tools we proceed
to study version and ciphersuite negotiation in TLS in several forms:
1. Ciphersuite negotiation within a single version: For a ﬁxed version of TLS,
by application of the negotiation-authentication theorem we show that TLS
provides secure ciphersuite negotiation.
2. Version negotiation, no fallback: For clients and servers that support multiple
versions of TLS but do not attempt to fallback to earlier versions upon
handshake failure, we show that TLS also provides secure version negotiation
via the negotiation-authentication theorem.
3. Version negotiation, with fallback: For clients and servers that support multi-
ple versions of TLS and where the client will fallback to earlier versions if the
handshake fails, we see that secure negotiation is not provided demonstrating
that our secure negotiation deﬁnition does detect this undesired behaviour.
4. Version negotiation, with fallback using signalling ciphersuite value (SCSV):
A recent Internet-Draft [23] proposes the use of a special ﬂag in the
ClientHello message. We show that this SCSV does provide TLS with
a secure version negotiation mechanism even when fallbacks are used.
2
The TLS Protocol
In this section, we give the details for ciphersuite negotiation and three vari-
ants of version negotiation in the TLS protocol. The following is a description
of the two messages most relevant to TLS ciphersuite and version negotiation:
the ClientHello and ServerHello messages; descriptions of the subsequent
messages can be found in the TLS protocol speciﬁcation [3].
– ClientHello: Sent by the client to begin the TLS handshake. Consists of: the
highest version that the client supports v; a random nonce rc; the optional
identiﬁer of previous session that the client wishes to resume; a list of client
ciphersuite preferences #–c ; and an optional list of extensions extensions
describing additional options or functionality.
– ServerHello: Sent by the server in response to ClientHello. Consists of:
the negotiated choice of version v; a random nonce rs; a session identiﬁer;
the negotiated choice of ciphersuite c∗; and an optional list of extensions.
www.ebook3000.com

274
B. Dowling and D. Stebila
2.1
Ciphersuite Negotiation in TLS
As indicated above, in TLS the client sends in ClientHello.#–c a list of supported
ciphersuites, ordered from most preferred to least preferred. The server also has a
list of supported ciphersuites ordered by preference, and selects its most preferred
ciphersuite that the client also supports. This ciphersuite negotiation protocol
NPcs is described algorithmically in Figure 1. In our formalism, the adversary
activates each party with the vector #–c of their ordered ciphersuite preferences
for that session.
Fig. 1. NPcs: Ciphersuite negotiation protocol in TLS
2.2
Version Negotiation in TLS
As indicated in the standards, in TLS the client sends in ClientHello.v the
highest version of TLS supports, and the server responds in its ServerHello
message with the chosen version. In practice, buggy TLS server implementa-
tions sometimes reject unrecognised versions rather than negotiating a lower
version, so some TLS clients will carry out fallback, where they try again with a
lower supported version. We identify three variants of TLS version negotiation
as follows. Recall again that in our formalism, the adversary activates each party
with a vector #–v of their supported versions for that session.
– No-fallback version negotiation, denoted NPv: Version negotiation as deﬁned
by the TLS standards (Figure 1).
– Fallback version negotiation (the “downgrade dance”), denoted NPv-fb: Ver-
sion negotiation as deﬁned by the TLS standards, but allowing version fall-
back (Figure 3).
– Fallback version negotiation with SCSV, denoted NPv-fb-scsv: The client pro-
ceeds as in fallback version negotiation, but when falling back to a lower
version, the client also includes in its ciphersuite list a fallback signalling
ciphersuite value (SCSV) to indicate that it has fallen back; this ciphersuite
cannot be negotiated, and instead simply serves as a ﬂag. If the server sees
that it would negotiate a version lower than its highest version and the

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
275
Fig. 2. NPv: No-fallback version negotiation protocol in standard TLS
† Note that the “go to (∗)” step in the client execution means that execution remains
in the same session for the client; however, the server, receiving a new ClientHello,
will start a new session.
Fig. 3. NPv-fb: Fallback version negotiation in TLS (the “downgrade dance”)
client has included the fallback SCSV, the server aborts and responds with
inappropriate fallback (Figure 4).
Note that the transcript (π.sid in our formalism) “resets” in fallback ver-
sion negotiation: matching conversations are based solely on the last handshake,
rather than all handshakes that may have fallen back.
3
Security Deﬁnitions
We begin by introducing the standard authenticated and conﬁdential channel
establishment (ACCE) protocol framework as introduced by Jager et al. [11].
www.ebook3000.com

276
B. Dowling and D. Stebila
Fig. 4. NPv-fb-scsv: Fallback negotiation in TLS with signalling ciphersuite value
We then extend the deﬁnition to cover protocols which negotiate a sub-protocol,
and deﬁne the secure negotiation property.
3.1
Authenticated and Conﬁdential Channel Establishment (ACCE)
Protocols
An ACCE protocol is a multi-party protocol. Each instance of the protocol is exe-
cuted between two parties: during the pre-accept phase, the parties establish a
shared secret key and mutually authenticate each other; this is followed by a post-
accept phase, which allows parties to transmitted authenticated and encrypted
payload data. We now proceed to describe the ACCE security model in detail,
beginning with the per-session variables and adversary interaction. Note that, for
simplicity, we restrict to the mutual authentication setting as in the original ACCE
deﬁnition of Jager et al. [11], but our results apply equally to server-only authen-
ticated ACCE [12,13]. Each ciphersuite in TLS is considered a separate ACCE
protocol with independent long-term keys, which limits the application of the
framework to implementations of TLS with no long-term key reuse.
Parties and Sessions. The execution environment consists of nP parties,
denoted P1, P2, . . . PnP . Each party Pi has a long-term public/private key pair
(pki, ski), generated according to the protocol speciﬁcation. Each party can exe-
cute multiple runs of the protocol either sequentially or in parallel; each run is
referred to as a session, and πs
i denotes the sth session at party i. For each session,
the party maintains a collection of the following per-session variables, and we
overload the notation πs
i to refer to both the session itself and the corresponding
collection of per-session variables.

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
277
– ρ ∈{init, resp}: The role of the party in the session.
– pid ∈[nP ]: The index of the intended peer of this session.
– α ∈{in-progress, accept, reject}: The execution status of the session.
– k: A session key, or ⊥; k may for example consist of sub-keys for bi-directional
authentication and encryption.
– T: Transcript of all messages sent and received by the party in this session.
– sid: A session identiﬁer, consisting of an ordered subset of messages in T as
deﬁned by the protocol speciﬁcation.1
– Any additional state speciﬁc to the protocol (such as ephemeral Diﬃe–
Hellman exponents).
– Any additional state speciﬁc to the security experiment.
We use the notation πs
i .ρ etc. to denote each variable of a particular session.
While a session has set α ←in-progress, we say that the session is in the
pre-accept phase; after the session has set α ←accept, we say that the session
is in the post-accept phase.
Deﬁnition 1 (ACCE Protocol). An ACCE protocol P consists of a proba-
bilistic long-term public-private key pair generation algorithm, as well as prob-
abilistic algorithms deﬁning how the party generates and responds to protocol
messages. The protocol speciﬁcation also includes a stateful length-hiding
authenticated encryption (sLHAE) scheme StE [10,11] for sending and receiving
payload data on the record layer.
Adversary Interaction. In the security experiment, the adversary controls all
interactions between parties: the adversary activates sessions with initialization
information; it delivers messages to parties, and can reorder, alter, delete, replace,
and create messages. The adversary can also compromise certain long-term and
per-session values. The adversary interacts parties using the following queries.
The ﬁrst query models normal, unencrypted operation of the protocol, gen-
erally corresponding to the pre-accept phase.
– Send(i, s, m)
$→m′: The adversary sends message m to session πs
i . Party Pi
processes m according to the protocol speciﬁcation and its per-session vari-
ables πs
i , updates its per-session state, and optionally outputs an outgoing
message m′.
There is a distinguished initialization message which allows the adversary
to activate the session with certain information, such as the intended role
ρ the party in the session, the intended communication partner pid, and
any additional protocol-speciﬁc information; when we extend to the nego-
tiable setting in the next subsection, this will include ciphersuite and/or
version preferences.
This query may return error symbol ⊥if the session has entered state
α = accept and no more protocol messages are to be transmitted over
the unencrypted channel.
1 Our separation of the transcript and session identiﬁer follows [20] and is a slight
change compared to the original ACCE model [11] to allow for consideration of
protocols where some messages are not authenticated.
www.ebook3000.com

278
B. Dowling and D. Stebila
The next two queries model adversarial compromise of long-term and per-
session secrets.
– Corrupt(i)
$→ski: Returns long-term secret key ski of party Pi.
– Reveal(i, s)
$→πs
i .k: Returns session key πs
i .k.
The ﬁnal two queries, Encrypt and Decrypt, model communication over the
encrypted channel. The adversary can direct parties to encrypt plaintexts and
obtains the corresponding ciphertext. The adversary can deliver ciphertexts to
parties, which are then decrypted. To accommodate deﬁning the security prop-
erty of indistinguishability of ciphertexts, the Encrypt query takes two messages,
and one of the tasks of the adversary is to distinguish which was encrypted. The
exact speciﬁcation of Encrypt and Decrypt is speciﬁed in Figure 4 of [24] (the full
version of [11]), and is omitted in this paper as these queries are not required
for deﬁning negotiable security.
ACCE Security Deﬁnitions. We now present the two sub-properties that
deﬁne security of ACCE protocols. Like authenticated key exchange (AKE) secu-
rity deﬁnitions, the ACCE framework requires that the protocol provides secure
mutual authentication. The diﬀerence lies in the encryption-challenge: instead
of key indistinguishability (found in AKE experiments) the ACCE framework
requires that all payload data transmitted between parties (during the post-
accept stage) is over an authenticated and conﬁdential channel. The original
motivation for this distinction is that real-world protocols often have key con-
ﬁrmation messages (for example, TLS’s Finished message), which can act as a
key-distinguisher in a AKE security framework. ACCE solves this by focusing
on message conﬁdentiality and integrity instead of key indistinguishability.
We start by deﬁning matching conversations and the mutual authentication
property of an ACCE protocol. Matching conversations is a property useful for
describing the correctness and authentication of a protocol, ﬁrst introduced by
Bellare and Rogaway [25]. 2
Deﬁnition 2 (Matching Sessions). A session πt
j matches session πs
i if:
– if Pi sent the last message in πs
i .sid, then πt
j.sid is a preﬁx of πs
i .sid; or
– if Pi received the last message in πs
i .sid, then πs
i .sid = πt
j.sid,
where X is a preﬁx of Y if X contains at least one message and the messages
in X are identical to and in the same order as the ﬁrst |X| messages in Y .
Deﬁnition 3 (Mutual Authentication). A session πs
i accepts maliciously if
– πs
i .α = accept;
– πs
i .pid = j and no Corrupt(j) query was issued before πs
i .α was updated to
accept; and
– there is not a unique session πt
j that matches πs
i .
2 Our formulation is a slight variant of Jager et al. [11]: we match on session identiﬁers
(a well-deﬁned subset of messages sent and received) rather than the full transcript.

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
279
We deﬁne Advacce-auth
P
(A) as the probability that, when probabilistic adversary
algorithm A terminates in the ACCE experiment for protocol P, there exists a
session that has accepted maliciously.
Channel security for ACCE protocols is deﬁned as the ability of the adversary
to break conﬁdentiality or integrity of the channel. As the channel security deﬁ-
nition does not play a role in the remainder of this paper, we omit the deﬁnition
and refer the reader to Deﬁnition 5.2 of [11] for details. Using the notation of
Bergsma et al. [20], the expression Advacce-aenc
P
(A) denotes the probability that
the adversary A breaks channel security of protocol P.
Deﬁnition 4 (ACCE-Secure).
A protocol P is said to be ϵ-ACCE-secure
against an adversary A if we have that Advacce-auth
P
(A) ≤ϵ and Advacce-aenc
P
(A) ≤ϵ.
3.2
Negotiable ACCE Protocols
In this section we deﬁne formally a negotiable ACCE protocol and the cor-
responding security notions. We do so by explaining the diﬀerences with
Section 3.1. The basis of our deﬁnition is the multi-ciphersuite ACCE deﬁnition
of Bergsma et al. [20], but like the ACCE deﬁnitions above we do not consider
use of the same long-term key in multiple sub-protocols. We then deﬁne the
secure negotiation property.
Diﬀerences in Execution Environment. A negotiable ACCE protocol is
composed of a negotiation protocol NP and a collection of sub-protocols # –
SP; we
use the notation NP∥# –
SP to denote the combined protocol. For example:
– In TLS with multiple ciphersuites, the negotiation protocol NPcs consists of
the sending and receiving of the ClientHello and ServerHello messages as
shown in Figure 1, and each sub-protocol SPi corresponds to the remaining
messages in ciphersuite i.
– For TLS with multiple versions, each sub-protocol SPi corresponds to a dif-
ferent version of TLS; the description of the negotiation protocol depends
on whether and how fallback is handled, and is described in Section 2.
Parties and Sessions. In a negotiable ACCE protocol, each party Pi has a vector
of long-term public/private key pairs (#   –
pki, #  –
ski), one for each sub-protocol.
Each session in a negotiable ACCE protocol maintains two additional per-
session variables:
– #–n: An ordered list of negotiation preferences.
– n: The index of the negotiated sub-protocol.
In the execution of NP∥# –
SP, the protocol begins by running the negotiation
protocol NP, which has as input the ordered list #–n of negotiation preferences; the
negotiation protocol updates per-session variables, and in particular updates the
index n of the negotiated sub-protocol. Once the negotiation protocol completes,
subprotocol SPn is run, operating on the same per-session variables.
www.ebook3000.com

280
B. Dowling and D. Stebila
Adversary Interaction. The adversary can interact with parties exactly as in
Section 3.1. The only diﬀerence is that in the distinguished initialization message
in the Send query, the adversary also includes an ordered list #–n of the sub-
protocol preferences that the party should use in that session. For example, in
ciphersuite negotiation, the adversary may direct the party to prefer RSA over
Diﬃe–Hellman in one session and Diﬃe–Hellman over RSA in another session.
For version negotiation in TLS, order of the list is descending and contiguous
(i.e., if TLSv1.2 and TLSv1.0 are listed as supported, TLSv1.1 must be listed).
Secure Negotiation. Intuitively, a negotiable protocol has secure negotiation
if the adversary cannot cause the parties to successfully negotiate a worse sub-
protocol than the best one they both support. We formalize this via an optimality
function, which will be diﬀerent for each protocol (for example, the optimality
function for TLS ciphersuite negotiation is diﬀerent from that of TLS version
negotiation).
Deﬁnition 5 (Optimal Negotiation). Let ω(#–x, #–y ) →z be a function taking
as input two ordered lists and outputting an element of one of the lists or ⊥. We
say that two sessions πs
i and πt
j do not have optimal negotiation with respect to
ω unless πs
i .n = πt
j.n = ω(πs
i .#–n, πt
j.#–n).
For TLS ciphersuite negotiation, the optimality function yields the ﬁrst
ciphersuite in the server’s ordered list of preferences also supported by the client:
ωcs(#–x, #–y ) = yi, where i = min{j : yj ∈#–x} .
(1)
For TLS version negotiation, the optimality function yields the highest ver-
sion that is supported by both the client and the server:
ωvers(#–x, #–y ) = max{#–x ∩#–y } .
(2)
For TLS version negotiation, we impose the order TLSv1.2 > TLSv1.1 >
TLSv1.0 > SSLv3.0 > SSLv2.0.
We can now deﬁne what it means for a protocol to have secure negotiation,
either of a particular sub-protocol or over all sub-protocols.
Deﬁnition 6 (Secure Negotiation of a Sub-Protocol). We say that a ses-
sion πs
i has negotiated a sub-protocol n∗insecurely with respect to ω if
– πs
i .α = accept;
– πs
i .n = n∗;
– πs
i has not accepted maliciously (in the sense of Deﬁnition 3); and
– πs
i and πt
j do not have optimal negotiation with respect to ω, where πt
j is the
unique session that matches πs
i .
We deﬁne Advneg,ω
NP∥#–
SP,n∗(A) as the probability that, when A terminates in the
negotiable-ACCE experiment for NP∥# –
SP, there exists a session that has negotiated
sub-protocol n∗insecurely with respect to ω.

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
281
Remark 1 (Secure Negotiation vs. Authentication). Secure negotiation, as
deﬁned is a stronger property than authentication: the third condition of Def-
inition 6 eﬀectively incorporates the authentication security deﬁnition. Recall
that authentication is based on matching session identiﬁers; if a protocol uses
the full transcript as the session identiﬁer, then negotiation generally reduces
to authentication, which is shown in the theorem in the next section. However,
if a protocol uses some subset of the transcript as the session identiﬁer, or for
example “resets” the session identiﬁer partway through the handshake as in TLS
version fallback, then negotiation becomes non-trivially diﬀerent from authenti-
cation and requires further consideration, as we shall see in Section 6.
4
Negotiation-Authentication Theorem
We now present our negotiation-authentication theorem, which allows us
under certain conditions to relate the probability of an adversary forcing a user
to insecurely negotiate to NP∥SPn to the probability of an adversary breaking
authentication in NP∥SPn. At ﬁrst glance, this seems obvious: if all of the mes-
sages in a protocol are securely authenticated, then it should be impossible for an
adversary to trick the parties into negotiating something sub-optimal. There is a
reason why the application of the theorem is not trivial: In practise, not all proto-
cols authenticate all messages in the handshake. As we will see Section 6, version
fallback in TLS results in some parts of the negotiation not being authenticated.
Historically, ciphersuite downgrade in SSLv2 was possible as the negotiation
phase wasn’t entirely authenticated.
To be able to apply this theorem, the protocol P has to satisfy certain con-
ditions as shown in the theorem statement below. Precondition 1 captures the
notion that protocols where all handshake message are authenticated, or at least
all handshake messages related to negotiation are authenticated, should allow
us to reduce negotiation security to authentication security. Precondition 2 is a
simply that, in the absence of an active adversary, parties negotiate correctly.
Theorem 1. Let NP∥# –
SP be a negotiable ACCE protocol and let ω be an optimal-
ity function. Suppose that:
1. all message sent and received by a party in the negotiation phase are included
in the session identiﬁer; and
2. in the absence of an active adversary, negotiation is always optimal with
respect to ω,
then for all algorithms A and for all sub-protocols SPn, Advneg,ω
NP∥#–
SP,n(A) =
Advacce-auth
NP∥SPn (A).
The proof of Theorem 1 appears in the full version [26]. The brief description
of the argument is as follows: By condition 1, both parties can verify that in
presence of a passive adversary that negotiation was optimal with respect to ω.
Since both parties can verify (via the session identiﬁer) that the negotiation sub-
protocol SPn is the optimal sub-protocol, and NP||SPn itself is an ACCE protocol
www.ebook3000.com

282
B. Dowling and D. Stebila
with negligible adversary advantage over a passive adversary, then negotiating to
NP||SPn is both optimal and authenticated with negligible adversary advantage.
Once we have related the security of negotiation to the security of authentica-
tion as in the equation in the theorem, we can make use of existing results on
ACCE authentication security, for example the bounds on Advacce-auth
P
(B) given
for ACCE authentication security of P = TLS signed-Diﬃe–Hellman cipher-
suites [11], P = TLS RSA key transport and P = TLS static Diﬃe–Hellman
ciphersuites [12,13].
5
Analysis of TLS Ciphersuite Negotiation
Using our negotiation-authentication theorem from Section 4, we can show that
TLS is ciphersuite-negotiation secure. We do this by showing that ciphersuite
negotiation in TLS satisﬁes the two preconditions outlined in our negotiation-
authentication theorem, and hence secure negotiation of ciphersuites is, not sur-
prisingly, guaranteed by security of authentication. All outputs of ciphersuite
negotiation are included in the session identiﬁer (as seen in Figure 1), thus
precondition 1 is satisﬁed, provided the ciphersuite has secure authentication.
In addition, TLS ciphersuite negotiation is optimal in the presence of a pas-
sive adversary, so precondition 2 is also satisﬁed. Details appear in the full ver-
sion [26].
Corollary 1. For the TLS protocol with ciphersuite negotiation NPcs
as
described in Figure 1 and TLS ciphersuites # –
SP, an adversary A who can force
a user to negotiate insecurely to ciphersuite SPn with respect to the TLS cipher-
suite optimality function ωcs from equation (1) can also break authentication of
that ciphersuite: Advneg,ωcs
NPcs∥#–
SP,n(A) = Advacce-auth
SPn
(A).
6
Analysis of TLS Version Negotiation
In this section, we consider the three variants of TLS version negotiation iden-
tiﬁed in Section 2.2. The no-fallback version negotiation mechanism speciﬁed
by the TLS standard, can easily be seen to be secure using our negotiation-
authentication mechanism. When version fallback is permitted, version negoti-
ation is no longer secure, as we demonstrate with a counterexample, and thus
our model successfully captures this weakness of fallback. Finally, when the sig-
nalling ciphersuite value (SCSV) version fallback detection mechanism is used,
we can show that TLS becomes version-negotiable secure.
6.1
TLS No-Fallback Version Negotiation is Secure
It is straightforward to apply our negotiation-authentication theorem to show
that TLS with no-fallback version negotiation (NPv described in Figure 2), pro-
vides secure version negotiation. Here the session identiﬁer consists of the entire

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
283
transcript, which includes the client and server’s version information, so precon-
dition 1 of Theorem 1 is satisﬁed. It is clear that TLS provides optimal version
negotiation in the presence of a passive adversary, so precondition 2 is satisﬁed.
Thus the negotiation-authentication theorem yields Corollary 2. Details appear
in the full version [26].
Corollary 2. For the TLS protocol with no-fallback version negotiation NPv as
described in Figure 2 and TLS versions # –
SP, an adversary A who can force a user
to negotiate insecurely to version SPn with respect to the TLS version optimality
function ωvers from equation (2) can also break authentication of that version:
Advneg,ωvers
NPv∥#–
SP,n(A) = Advacce-auth
SPn
(A).
6.2
TLS Fallback Version Negotiation is Not Secure
When examining version negotiation in TLS with fallback (NPv-fb from Figure 3),
notice that many diﬀerent ClientHello messages may be sent by the
client before the handshake is accepted by the server. An active adversary
may force this behaviour: instead of delivering the ﬁrst few ClientHello
attempts at handshake messages to the server, the adversary responds with
fatal handshake error, until the client sends a ClientHello which has a suf-
ﬁciently low version that the adversary is satisﬁed. In practise, this may mean a
client and a server both supporting TLSv1.2 may be downgraded to TLSv1.0 by
an adversary returning a handshake error until the client attempts a TLSv1.0
ClientHello with a successful response. In this scenario, the session clearly has
sub-optimal version-negotiation—the client and server both support TLSv1.2,
but the adversary has caused a version 1.0 negotiation—and this provides a
example that TLS with fallback is not version-negotiable secure.
In terms of our negotiation-authentication theorem, it fails to apply here
because not every output of the negotiation phase is authenticated by the sub-
protocol: only the successful ClientHello message is included in the transcript
and is considered for matching sessions. Much like the ciphersuite-downgrade
vulnerability in SSLv2, this allows an active adversary to modify and delete any
of the previous exchanges between the server and client.
6.3
TLS Fallback Version Negotiation with SCSV is Secure
Similar to TLS fallback version negotiation, TLS fallback version negotiation
with SCSV (NPv-fb-scsv as described in Figure 4) does not acknowledge or authen-
ticate any messages previous to the fatal handshake message in the session
identiﬁer, and as such does not satisfy precondition 1 of Theorem 1. Thus, we
cannot use the negotiation-authentication theorem to show that that fallback
version negotiation with SCSV securely negotiates version. Instead, we provide
a direct argument to show that fallback version negotiation with SCSV is secure
provided that no-fallback TLS version negotiation is secure.
www.ebook3000.com

284
B. Dowling and D. Stebila
Theorem 2. For the TLS protocol with fallback version negotiation with SCSV
NPv-fb-scsv as described in Figure 4 and TLS versions # –
SP, an adversary who can
force a user to negotiate insecurely to version SPn with respect to the TLS version
optimality function ωvers from equation 2 can also break authentication of that
version: Advneg,ωvers
NPv-fb-scsv∥#–
SP,n(A) ≤Advacce-auth
SPn
(A).
Proof. The security argument proceeds by showing that an adversary who is
successful in breaking fallback version negotiation with SCSV is also successful
in breaking authentication of the underlying ACCE protocol. We give a high-
level description of the simulator behaviour below.
The simulator B in our argument recreates the SCSV mechanisms described
in Figure 4 and ref. [23] using a version negotiation TLS challenger C for TLS with
no-fallback version negotiation; more precisely, B simulates the neg experiment
for NPv-fb-scsv∥# –
SP using a challenger for NPv∥# –
SP.
B initially forwards all adversarial queries to the challenger C for each session.
After receiving the ClientHello message for a session π from the adversary A,
the simulator is able to determine whether the version in the ClientHello would
cause a handshake error. If the error would occur, B replies to A directly with
fatal handshake error. If the error would not occur, B faithfully forwards all
queries for that session between A and C.
Upon receiving a fatal handshake error from A intended for a session π,
the simulator uses a Send query to activate a new session π′ that is activated
identically to π except FALLBACK SCSV is also included in the list of supported
ciphersuites and the list of supported versions for π′ is modiﬁed to no longer
include the highest supported version v of the session π. B also adds π to a
fallback list FL to determine which sessions have performed version-fallback.
Note that from A’s point-of-view, π′ and π are the same continuous session,
and B now directs all queries sent to π to π′ instead.
As
well,
B,
upon
receiving
a
ClientHello
from
A
that
contains
FALLBACK SCSV in the list of supported ciphersuites, determines if the server’s
highest supported version is higher than the client’s indicated version in the
ClientHello. If so, B replies with an inappropriate fallback error message.
Note that the alert is fatal, so the simulator B will disregard all further Send
queries directed to the server’s session. If not, B forwards the ClientHello to C
and continues to forward all messages for these sessions between A and C.
This describes the simulator’s behaviour during the experiment. Suppose at
some point A breaks the negotiable security of a session π∗. There are two cases:
1. If π∗does not appear on B’s fallback list FL, then all messages were
forwarded faithfully between A and C. An insecure version fallback to
version SPn in B’s simulation of NPv-fb-scsv∥# –
SP thus directly translates to inse-
cure version negotiation to version SPn in C’s execution of NPv∥# –
SP. Hence,
Advneg,ωvers
NPv-fb-scsv∥#–
SP,n(A) ≤Advneg,ωvers
NPv∥#–
SP,n(A). By Corollary 2, Advneg,ωvers
NPv-fb-scsv∥#–
SP,n(A) ≤
Advacce-auth
SPn
(A).

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
285
2. If π∗does appear on B’s fallback list FL, then the simulator will have rejected
any non-optimal handshakes containing the SCSV. It follows then that the
session must have accepted maliciously (either by the A impersonating the
server party or by modifying the handshake of the fallback session π∗′). Thus
an insecure fallback to version SPn in B’s simulation of NPv-fb-scsv∥# –
SP directly
translates to an authentication break in SPn. Hence, Advneg,ωvers
NPv-fb-scsv∥#–
SP,n(A) ≤
Advacce-auth
SPn
(A).
⊓⊔
Need for Contiguous Support of TLS Versions for Fallback with SCSV.
As shown above, SCSV does give additional protection against version down-
grade attacks in TLS implementations that support version fallback. However,
we observe that there is a drawback to the SCSV proposal as it stands: Non-
contiguous support of versions in TLS implementations (a viable scenario in
practise) can hamper interoperability between systems supporting checking for
insecure fallback using SCSV.
In some implementations of TLS,3 users can select a non-contiguous subset
of TLS version support. For example, a user could—for some reason—enable
TLSv1.2 and TLSv1.0, but not TLSv1.1.
In relation to the SCSV, this can result in a connection attempt that could
fail to accept without adversarial interaction. Consider the following scenario:
suppose a client user selects TLSv1.2 and TLSv1.0 to support, and attempts to
connect to a server that only supports TLSv1.1 and TLSv1.0, and will return
a fatal handshake error for TLSv1.2. The client sends a ClientHello with
TLSv1.2. After the server fails to parse the TLSv1.2 handshake correctly, it
reply with a fatal handshake error message. The client falls back, sending a
new ClientHello message with its next highest supported version, TLSv1.0, and
includes FALLBACK SCSV in the ciphersuite list to indicate it is falling back. The
server notes the SCSV and rejects the handshake with inappropriate fallback
as recommended in the SCSV proposal because the server’s highest supported
version (TLSv1.1) is higher than the client’s indicated version (TLSv1.0), despite
the fact that the optimal negotiated version would be TLSv1.0.
An alternative mechanism for secure version fallback would be to include
a signalling ciphersuite value for each version it supports, allow the parties to
detect insecure fallback while allowing non-contiguous version support.
7
Discussion
We have introduced provable security notions for negotiation in Internet pro-
tocols, and extended the deﬁnition of ACCE protocols to utilise previous
3 The current version of Microsoft Internet Explorer (11) and previous versions allow
users to conﬁgure which subset of SSL/TLS versions are enabled (Internet options
→Advanced →Security); Mozilla Firefox up to version 22 did as well. On the server
side, Apache mod ssl, Microsoft IIS, and nginx all allow the server administrate to
select which subset of SSL/TLS versions to enable.
www.ebook3000.com

286
B. Dowling and D. Stebila
comprehensive ACCE proofs of TLS ciphersuites. We develop a negotiation-
authentication theorem and show that ciphersuite negotiation in TLS is secure,
under certain conditions about long-term key reuse. We follow by showing that
the version negotiation in standards-deﬁned TLS and the TLS implementation
with the SCSV is also secure, but demonstrate that TLS implementations that
utilise browser-based version fallback mechanisms are not version-negotiable
secure. This analysis holds for TLS conﬁgurations that exclude sharing long-
term keys across multiple versions. In practice, our analysis requires that TLS
conﬁgurations (in order to have ciphersuite negotiation security) must use inde-
pendent long-term keys and thus distinct digital certiﬁcates for each ciphersuite;
this is currently a necessary cost in order to prevent cross-ciphersuite-like attacks
from breaking authentication in TLS. To the best of our knowledge, no web
server software currently permits conﬁguring diﬀerent certiﬁcate for diﬀerent
TLS ciphersuites with the same signing/key transport algorithm, nor diﬀerent
certiﬁcates for diﬀerent TLS versions.
Future Work. It seems possible that one could extend our analysis to include
TLS conﬁgurations where long-term keys are shared across multiple versions
but a single ﬁxed ciphersuite (i.e. that TLS 1.2 and TLS 1.0 can reuse long-term
keys in the same ciphersuite conﬁguration). However in order to do so requires
extensive modiﬁcation of the negotiation framework to more closely resemble
the multi-ciphersuite setting [20]. This remains a signiﬁcant practical limitation
on long-term key reuse across ciphersuites.
Proposed revisions to TLS in the current draft of TLS 1.3 [27] seem to make
the protocol resistant to cross-ciphersuite and cross-version attacks. The main
change is that, in TLS 1.3, the value signed using the long-term secret key
now includes (the hash of) all handshake messages, including the negotiated
version and ciphersuite. As a result, the multi-ciphersuite composition framework
of Bergsma et al. [20] should be applicable to both multi-version and multi-
ciphersuite conﬁgurations of TLS: a signing oracle for a single sub-protocol could
be constructed to avoid signing objects that would be valid in another sub-
protocol, defeating the ﬁrst step of the cross-ciphersuite attack. This could then
imply negotiation-authentication security of TLS 1.3 with shared long-term keys.
A thorough analysis is required to show this categorically, however.
Our techniques can also be applied to other protocols that negotiate crypto-
graphic parameters or versions, the Secure Shell (SSH) protocol being a prime
candidate. While SSH does have two versions, they are largely incompatible, and
current best-practices including disabling v1 support, so there is little value in
studying SSH version negotiation. However, SSH also supports multiple crypto-
graphic algorithms, and our framework can easily be applied to SSH algorithm
negotiation. Since the parties authenticate their entire transcript, including both
the client’s and server’s algorithm preferences, our negotiation-authentication
theorem readily implies that SSH has secure ciphersuite negotiation if it has
secure authentication, which it does by the recent results of Bergsma et al. [20].

Modelling Ciphersuite and Version Negotiation in the TLS Protocol
287
Acknowledgments. This research has been supported by Australian Research Coun-
cil (ARC) Discovery Project grant DP130104304.
References
1. Dierks, T., Allen, C.: The TLS protocol version 1.0. RFC 2246 (1999)
2. Dierks, T., Rescorla, E.: The Transport Layer Security (TLS) protocol version 1.1.
RFC 4346 (2006)
3. Dierks, T., Rescorla, E.: The Transport Layer Security (TLS) protocol version 1.2.
RFC 5246 (2008)
4. Freier, A.O., Karlton, P., Kocher, P.C.: The Secure Sockets Layer (SSL) protocol
version 3.0. RFC 6101 (2011). Republication of original SSL 3.0 speciﬁcation by
Netscape of November 18, 1996
5. Wagner, D., Schneier, B.: Analysis of the SSL 3.0 protocol. In: Proc. 2nd USENIX
Workshop on Electronic Commerce (1996)
6. Hickman, K.E.B.: The SSL protocol (version 0.2) (1995). http://www-archive.
mozilla.org/projects/security/pki/nss/ssl/draft02.html
7. Jonsson, J., Kaliski Jr., B.S.: On the security of RSA encryption in TLS. In: Yung,
M. (ed.) CRYPTO 2002. LNCS, vol. 2442, pp. 127–142. Springer, Heidelberg (2002)
8. Morrissey, P., Smart, N.P., Warinschi, B.: A modular security analysis of the TLS
handshake protocol. In: Pieprzyk, J. (ed.) ASIACRYPT 2008. LNCS, vol. 5350,
pp. 55–73. Springer, Heidelberg (2008)
9. Krawczyk, H.: The order of encryption and authentication for protecting commu-
nications (or: How Secure Is SSL?). In: Kilian, J. (ed.) CRYPTO 2001. LNCS,
vol. 2139, p. 310. Springer, Heidelberg (2001)
10. Paterson, K.G., Ristenpart, T., Shrimpton, T.: Tag size does matter: attacks and
proofs for the TLS record protocol. In: Lee, D.H., Wang, X. (eds.) ASIACRYPT
2011. LNCS, vol. 7073, pp. 372–389. Springer, Heidelberg (2011)
11. Jager, T., Kohlar, F., Sch¨age, S., Schwenk, J.: On the security of TLS-DHE in
the standard model. In: Safavi-Naini, R., Canetti, R. (eds.) CRYPTO 2012. LNCS,
vol. 7417, pp. 273–293. Springer, Heidelberg (2012)
12. Krawczyk, H., Paterson, K.G., Wee, H.: On the security of the TLS protocol: a
systematic analysis. In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013, Part I.
LNCS, vol. 8042, pp. 429–448. Springer, Heidelberg (2013)
13. Kohlar, F., Sch¨age, S., Schwenk, J.: On the security of TLS-DH and TLS-RSA in
the standard model. Cryptology ePrint Archive, Report 2013/367 (2013). http://
eprint.iacr.org/2013/367
14. Li, Y., Sch¨age, S., Yang, Z., Kohlar, F., Schwenk, J.: On the security of the pre-
shared key ciphersuites of TLS. In: Krawczyk, H. (ed.) PKC 2014. LNCS, vol. 8383,
pp. 669–684. Springer, Heidelberg (2014)
15. Brzuska, C., Fischlin, M., Smart, N.P., Warinschi, B., Williams, S.C.: Less is more:
Relaxed yet composable security notions for key exchange. International Journal
of Information Security 12, 267–297 (2013)
16. Bhargavan, K., Fournet, C., Kohlweiss, M., Pironti, A., Strub, P.Y.: Implementing
TLS with veriﬁed cryptographic security. In: 2013 IEEE Symposium on Security
and Privacy, pp. 445–459. IEEE Computer Society Press (2013)
17. Giesen, F., Kohlar, F., Stebila, D.: On the security of TLS renegotiation. In:
Sadeghi, A.R., Gligor, V.D., Yung, M. (eds.) ACM CCS 2013, pp. 387–398. ACM
Press (2013)
www.ebook3000.com

288
B. Dowling and D. Stebila
18. Ray, M., Dispensa, S.: Renegotiating TLS (2009) http://extendedsubset.com/
Renegotiating TLS.pdf
19. Mavrogiannopoulos, N., Vercauteren, F., Velichkov, V., Preneel, B.: A cross-
protocol attack on the TLS protocol. In: Yu, T., Danezis, G., Gligor, V.D. (eds.)
ACM CCS 2012, pp. 62–72. ACM Press (2012)
20. Bergsma, F., Dowling, B., Kohlar, F., Schwenk, J., Stebila, D.: Multi-ciphersuite
security of the secure shell (SSH) protocol. In: Ahn, G.J., Yung, M., Li, N. (eds.)
ACM CCS 2014, pp. 369–381. ACM Press (2014)
21. Bhargavan, K., Fournet, C., Kohlweiss, M., Pironti, A., Strub, P.-Y., Zanella-
B´eguelin, S.: Proving the TLS handshake secure (As It Is). In: Garay, J.A.,
Gennaro, R. (eds.) CRYPTO 2014, Part II. LNCS, vol. 8617, pp. 235–255. Springer,
Heidelberg (2014)
22. Rescorla, E., Ray, M., Dispensa, S., Oskov, N.: Transport Layer Security (TLS)
renegotiation indication extension. RFC 5746 (2010)
23. M¨oller, B., Langley, A.G.: TLS fallback Signaling Cipher Suite Value (SCSV)
for preventing protocol downgrade attacks (2015). https://tools.ietf.org/html/
draft-ietf-tls-downgrade-scsv-05. Internet-Draft -05
24. Jager, T., Kohlar, F., Sch¨age, S., Schwenk, J.: On the security of TLS-DHE in
the standard model. Cryptology ePrint Archive, Report 2011/219 (2011). http://
eprint.iacr.org/2011/219
25. Bellare, M., Rogaway, P.: Entity authentication and key distribution. In: Stinson,
D.R. (ed.) CRYPTO 1993. LNCS, vol. 773, pp. 232–249. Springer, Heidelberg
(1994)
26. Dowling, B., Stebila, D.: Modelling ciphersuite and version negotiation in the TLS
protocol (full version). Cryptology ePrint Archive (2015)
27. Rescorla, E.: The Transport Layer Security (TLS) protocol version 1.3 (2015).
https://tools.ietf.org/html/draft-ietf-tls-tls13-05. Internet-Draft -05

VisRAID: Visualizing Remote Access
for Intrusion Detection
Leliel Trethowen1, Craig Anslow2, Stuart Marshall1, and Ian Welch1(B)
1 School of Engineering and Computer Science,
Victoria University of Wellington, Wellington, New Zealand
leliel.trethowen@gmail.com,
{stuart,ian}@ecs.vuw.ac.nz
2 Department of Computer Science,
University of Calgary, Calgary, Canada
craig.anslow@ucalgary.ca
Abstract. Detecting malicious attempts to access computers is diﬃcult
with current security applications. Many current applications do not give
the user the right information to ﬁnd and analyze possible attempts. We
present VisRAID – a novel visual analytics web application for detecting
intrusions via remote access attempts, and a user study to evaluate the
eﬀectiveness and usability of the application with security profession-
als. The implications of the study will help inform the design of future
security visualization applications.
1
Introduction
As computer networks have become ubiquitous, threats to the integrity of the
networks and data have multiplied and diversiﬁed. The proliferation of threats
has lead to the development of intrusion detection systems [14]. Intrusions are
deﬁned as access to systems resources for purposes contrary to the intended use
of the system, or access to the system by an unauthorized person.
There are two main methods of operation for intrusion detection systems.
Rule based systems ﬂag any attempt that matches deﬁned rules as malicious.
These systems are extremely eﬀective at detecting and blocking known attack
patterns, particularly for outsider access as rules are written for the known attack
patterns. Insider attacks are more diﬃcult to control with rules based systems,
as blanket access blocks are often not suitable as it is not clear if a user is legiti-
mate. Anomaly based systems use machine learning techniques to automatically
classify incoming events as normal or anomalous. Normal events are ignored,
while anomalous events are ﬂagged for operator attention.
Anomaly based systems are able to recognize new intrusion methods but not
able to provide much if any context about events, while Rule based systems
identify which rule was matched. Anomaly based systems are harder to disguise
existing intrusions from, as their classiﬁcation systems are ﬂexible enough to
recognize small changes in patterns, whereas Rule based systems cannot do this
as easily.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 289–306, 2015.
DOI: 10.1007/978-3-319-19962-7 17
www.ebook3000.com

290
L. Trethowen et al.
Intrusion detection system can suﬀer from false positives and false negatives.
False negatives are undesirable as each represents an intrusion that went unde-
tected and potentially un-countered. Note that not all undetected intrusions will
achieve their goals, however security administrators are not able to eﬀectively
ensure the vulnerabilities used are addressed as they may remain unaware of the
intrusion indeﬁnitely unless traces are left elsewhere in the system.
Large numbers of false positives are problematic for secure systems as they
quickly undermine the trust of users [11]. Many intrusion detection systems
oﬀer very limited forms of alerting with email mostly used, and SMS for critical
alerts. The limited range of sensory urgency available via alerting mechanisms
is problematic, as it causes a mismatch between the apparent and importance
of a message [11].
Despite new intrusion techniques and rapidly growing networks, ensuring that
actual intrusions are being detected is important. Existing intrusion detection
systems have a number of problems: they do not scale well to large networks,
cause information overload, and often fail to reveal important information about
logged events.
In this paper we present VisRAID – a novel visual analytics web application
that addresses these problems by allowing security administrators to eﬀectively
monitor remote access attempts to their systems to detect intrusions. VisRAID
currently monitors SSH remote access attempts as the ports used for SSH traﬃc
are often the focus of intrusion attempts. We present the design, user inter-
face, and implementation of VisRAID, a preliminary user study with security
professionals, and discuss implications for the design of security visualization
applications.
2
Related Work
Related work on visualization of intrusion detection has primarily focused on two
major areas: techniques used to visualize and explore the results of data mining,
and visualization driven techniques. We treat intrusion detection systems (IDS)
as data mining systems. Most of the research to date has focused on network
intrusion detection logs, and relatively little work has considered access or system
log visualization which is the primary focus of our research.
2.1
Data Mining with Visualization
LogView is a visualization application designed to support the understanding
of information extracted through data-mining techniques applied to systems
logs [9]. The visualization component uses treemaps to show clusters of events
in a space eﬃcient manner, with leaf nodes representing events, and branches
showing clusters the events belong to. All leaf nodes are coloured in green, with
shade darkening in four steps representing diﬀerent statuses: OK, WARN, FAIL,
and OUTLIER. The application allows ﬁltering based on time, and search terms.
Time ﬁltering shows only events occurring on the speciﬁed day in the map. Nodes

VisRAID: Visualizing Remote Access for Intrusion Detection
291
matching search terms are highlighted red. Detailed information about a given
event is available via a mouseover. The simple ﬁltering and interaction methods,
coupled with very similar shades for clusters leaves the system very vulnera-
ble to producing information overload in users. The overload potential grows
rapidly as the logs grow, as there is very little information hiding present in this
application.
Itoh et al. created a hierarchical system for visualizing intrusion system detec-
tion logs [7]. Intrusion detection system messages are lacking in the context
needed to support an evaluation of the priority and accuracy of the report. The
application shows the entire network under surveillance using a rectangle pack-
ing algorithm to group machines by subnets. The number of incidents sent and
received from a given machine are displayed as a coloured bar rising out of the
plane. The amount of data produced quickly leads to navigability and readability
problems as the number of incidents reported grows. Simple ﬁltering applications
are available to limit by severity, time, IP, and signature ID. The application is
highly reliant on an IDS with both a low false positive, and false negative rate,
as almost all information about the actual events is hidden, and there is no easy
method to drill down to detailed information.
Xu et al. present a system log data mining application [13]. The log syntax
is automatically recovered through source code analysis, allowing the system
to be applied to any source available. Once log syntax is extracted, logs are
parsed and machine learning algorithms used to perform feature extraction. Once
the features are extracted the principle component analysis anomaly detection
algorithm are applied to this data, to ﬁnd interesting patterns in log messages.
This approach identiﬁed many issues in the tested software, but was forced
to be extended from a pure data-mining approach as users found the black
box nature of data-mining algorithms caused diﬃculty in understanding why
the results were as they are. To assist with this, a very simple decision tree
visualization was added. This visualization was created with the intention of
showing the logic used by the data-mining systems to give context for decisions.
As the processing required for feature extraction and anomaly detection is highly
parallel this approach readily scales to millions of entries, and shows very strong
performance in detecting anomalous patterns in logs. From a security standpoint,
however, decision trees alone do not give suﬃcient context to easily determine if
an anomaly represents an intrusion as the the trees depends on data not always
included in the raw logs.
2.2
Visualization Driven Techniques
Picvis is an application created to generate parallel co-ordinate plots of log
data [12]. Picviz has features to automate data extraction from several common
log formats for use with their plot description language. This language allows
a great deal of control over what variables are shown on a plot. Parallel co-
ordinate plots can show strong clustering extremely well. However there are
issues of scalability, as clusters and patterns can easily be hidden in background
noise unless axes are well chosen. Filtering features are available to help address
www.ebook3000.com

292
L. Trethowen et al.
this limitation, but still require signiﬁcant knowledge of the data structure and
content. This application would be excellent for conﬁrmatory analyses however.
Spiralview is an application that displays time-series data which uses a spiral
visualization technique and has been used to visualize static logs and dynamic
data streams [1]. The aim of Spiralview is to reveal repeating patterns in time
series data from intrusion detection system reports and access logs. An evalua-
tion of the spiral technique asked participants to identify regions of high and low
activity in cellphone calling records [3]. Participants were also asked to estimate
the time period of patterns in the cellphone data. Participants were presented
with both a spiral view and linear timeline views of the data. The study claims
that the spiral view approach will oﬀer higher performance than a linear timeline
due to the reinforcement of repeating patterns. The results showed that users
were signiﬁcantly faster, more accurate, and more satisﬁed with a linear timeline
presentation for identifying regions of high and low activity. Users were signiﬁ-
cantly more accurate at identifying time periods for repeating patterns with the
Spiralview.
The integrated visualization system is an IDS log based visualization appli-
cation, focusing on attacks originating inside the monitored network [10]. The
application provides a uniﬁed logical, geographic and temporal display of data,
using three orthogonal planes. Multiple layouts of the three planes are available,
with animated transitions. The timeline plane in the visualization shows events
for the entire subnet. Individual IP’s can be chosen by shifting the timeline plane
along the IP plane. Filtering features are made available to control what kinds
of events are shown. The application relies on colour to distinguish ports on the
timeline frame, which is easily subject to visual overload, as the human eye is
not able to reliably distinguish ﬁne diﬀerences in colours. Vertical position of the
line indicates the number of events. With poorly described ﬁltering systems and
reliance on colour coding to distinguish ports, this system is extremely vulnera-
ble to producing information overload. This leads to missing important events.
The lack of data hiding creates visual clutter which can easily mask impor-
tant intrusions composed of a small number of events. The application appears
interesting as an attempt to correlate attack information with machine location
through GeoIP systems. Where the number of events is “low enough” lines are
drawn from IP plane to physical location on the lower plane. The exact number
of lines drawn is not clear.
3
VisRAID
VisRAID is a novel web application for network security professionals to visually
explore monitoring of network traﬃc for intrusion detection. VisRAID adopts a
visualization driven technique design. There are several goals we have used to
help guide the design of VisRAID:
G1: Deploy visualizations over the web.
G2: Strong ﬁltering and highlighting options.

VisRAID: Visualizing Remote Access for Intrusion Detection
293
G3: Show surrounding context for anomalous accesses.
G4: Support sharing of work and saving work in progress.
G5: GeoIP support to add context to login attempts.
G6: Allow the user control over which machine is monitored at any given time.
G7: Show network context for currently monitored machine.
G8: Support extensible log parsing.
3.1
User Interface and Timeline Visualization
Figure 1 shows the web-based user interface of VisRAID. The main features are
a timeline overview, vertical scaling, colour-coding of event types, and mouseover
tooltips. Within each timeline, blocks are vertically scaled proportional to the
block with the largest number of events to help with information hiding so
important data is not masked. In Figure 1 the ﬁrst block consists of 5 events
total, the second block is absent indicating no events occurred in that time, and
the third block shows 25 events of three diﬀerent classes.
As networks can become extremely busy by producing lots of activity the
information can overwhelm an analyst’s ability to comprehend and detect mean-
ingful patterns. To address this problem we adopted data hiding techniques, used
a time series based approach for displaying the data, and used time binning to
aggregate entities. In our approach all entries in a short time period are dis-
played as a single entity, with icons indicating some simple features of the hid-
den data. Such features include superuser accesses, number of abnormal failed
access attempts, number of abnormal access attempts, abnormal login locations
for a user, abnormal login times for a user. Each time a bin can be zoomed in
on, allowing the analyst to see greater detail within the bin. For busy systems
and longer time periods there may be multiple levels of binning to aggregate
suﬃciently. This approach reduces the visual complexity, but allows access to
detailed information on demand.
Flags for abnormal login time and location are the most complicated ﬂags,
as they require creating a proﬁle of each user’s access times over repeated access
attempts. This complexity can produce false positives while a user is learning
the application and may be tripped up by a legitimate change in their behaviour.
Timelines are required to have independent vertical scales as the number of
events in a given time period may be highly variable. This is demonstrated in
Figure 1 where the top timeline shows 25 events in the largest bin, and the third
timeline shows in excess of 20K events. Without independent scaling for each
timeline all features of the upper two lines would be overwhelmed by the third.
This led to the inclusion of the black scale indicators found between the controls
and timelines. They are logarithmically scaled such that the timeline with the
highest maximum events per bin is represented by a full bar. These provide a
quick visual indication of how much variability there is between scales.
Each block is subdivided into four colours to represent diﬀerent classes of
events. Each event must be in exactly one event class, this allows the colour
sections to be linearly scaled to block height (i.e. if half the events are failed
connections, half of the block will be red). The colour coding was added to give an
www.ebook3000.com

294
L. Trethowen et al.
Fig. 1. VisRAID - showing an overview of the Honeynet dataset, slider to navigate,
ﬁltering options to make changes, and legend for diﬀerent types of events

VisRAID: Visualizing Remote Access for Intrusion Detection
295
Fig. 2. VisRAID - Tooltip showing statistics for a block
instant overview of the breakdown of event types within each bin. Hovering the
mouse over a block produces a tooltip showing a detailed statistical breakdown of
the events within that block (see Figure 2). Double-clicking on any block zooms
in on that block, with all four timelines reloading to show only data from the
selected block. Zooming can be performed until either there is only one event in
the chosen block, or each block covers 1 second. Where there is only one event
to display, mousing over the block will show the raw log line in a popup.
Above the timelines a slider can be used to navigate the dataset. The position
of the slider gives an approximate indication of how far through the timeline the
view is currently at. The extreme left is when the ﬁrst log event occurred. The
extreme right is the latest log event. The slider can be dragged and moved in
steps. Each step covers exactly as long as is currently shown in the timelines (see
Figure 3).
3.2
Implementation
While there are many kinds of events, and metadata about connections that can
be logged, extended information is highly dependent on SSH demon conﬁgura-
tion. The listed message types can be relied on to be present in all useful logging
levels. A log event will typically be represented by a single log line at the standard
level of logging for OpenSSH. A typical user interaction may generate between
two and three log events: connection, disconnection, and transferring ﬁles across
the secure connection. Malicious access attempts may generate between two and
www.ebook3000.com

296
L. Trethowen et al.
Fig. 3. VisRAID - Showing 2 weeks of the Honeynet dataset

VisRAID: Visualizing Remote Access for Intrusion Detection
297
Fig. 4. Examples of SSHD logs, showing each type of message
three log events: connection, disconnection, and if the username provided is not
recognised. Rates of log generation can vary widely between networks.
We used the following event types from the SSHD logs: connection attempts,
disconnection messages, subsystem requests, invalid usernames, and system mes-
sages. All events contain a timestamp, server name, service name, and process
ID. The remainder of a message is free text. Each entry contains metadata,
for example a connection attempt contains information about authentication
method, username, source address, and status. Whereas a disconnection mes-
sage contains a code, and source IP. Figure 4 shows an example of some of the
messages contained in the SSHD log ﬁles.
A log parsing tool was implemented in two layers: log reader and
writer/analyser. The reader layer is responsible for reading any number of log
ﬁles into a sorted list of events. The list of events is then passed to the ana-
lyzer/writer layer, which is responsible for checking connection attempts to see
if the location and time are frequently used by the user and writing the ana-
lyzed metadata to the datastore. The results of the parser are stored in a MySQL
database.
To address the design goal of deploying visualizations over the web we
implemented a web-based application. The user interface was implemented with
JQuery and visualizations with D3 [2]. Apache Tomcat was used for the server
along with SQL generation from the jOOQ library [4]. The server contained two
layers implemented as servlets. The data access servlet was responsible for fetch-
ing data from the underlying datastore. The servlet takes values from the client
communication layer and returns lists of matching log entries. The servlet can
be easily modiﬁed to communicate with diﬀerent kinds of datastores. The client
communication servlet was responsible for aggregating data returned by the data
access layer, and building HTTP(S) responses from the aggregated data.
4
Evaluation
To evaluate the eﬀectiveness of VisRAID we performed a preliminary user study
with security professionals. We obtained human ethics approval from our Uni-
versity to conduct this user study.
4.1
Participants
Six people were recruited for the user study. Four of the participants were security
professionals who had security components as part of their day jobs, and are
www.ebook3000.com

298
L. Trethowen et al.
regularly involved in log analysis tasks. The other two were computer science
students who had passed a graduate security course.
4.2
Datasets
Two datasets were used in this study which represent real systems exposed to
the public internet.
Honeynet Forensic Data: from Challenge 10 which is publicly available and
anonymized [6]. The data covers a single server, with 35K log entries covering
16 March to 2 May (approx. 729 events/day).
ECS Data: from our computer science department which are network logs,
anonymized, cover three servers for two disjoint weeks, and contain 74K log
entries. (approx. 5300 events/day).
The Honeynet dataset has been extensively analyzed, over the course of two
forensic challenges. Multiple successful brute force and scattergun attacks have
been identiﬁed in this dataset. There were few usernames which showed a pattern
of usage in the log data gathered. The Honeynet dataset was from the GMT-5
timezone.
The ECS dataset is more complex than the Honeynet dataset. The ECS
dataset covers three separate servers, with more active users. The ECS dataset
shows approximated 5300 events/day, more than seven times as many as the
Honeynet dataset. The ECS dataset contains disconnection messages absent
from the Honeynet dataset. These messages can account for at most a dou-
bling of event rates, as there may be at most one disconnection per connection
attempt, and a connection attempt may produce more than one event. As dis-
connection messages are not currently useful, they add a signiﬁcant amount of
noise. This dataset was extensively analyzed before the user study to search
for existing attacks. Several attempted brute force and scattergun attacks were
found, though all were unsuccessful.
The diﬀerence in attack success rates between datasets reﬂects diﬀerences in
the purposes of the networks. The ECS network is provided for use by staﬀand
students in our department at our university. This network can reasonably be
expected to have signiﬁcant amounts of sensitive information stored. Therefore
the school expends signiﬁcant eﬀort in protecting these systems. In contrast, the
Honeynet system is deliberately exposed to lure in attackers, and as such has
signiﬁcantly less eﬀort expended on securing it.
The ECS dataset was altered, to introduce a successful scattergun attack on
one server. This was introduced, as there were no naturally occurring success-
ful attacks discovered after thorough analysis with both VisRAID, and direct
exploration through the database. The introduced scattergun attack in the ECS
dataset had a relatively small attack signature, with only 204 log entries involved,
of 4.7K entries for that day. Some successful attacks on Honeynet had similar
numbers of access attempts, though often a much higher proportion of invalid
or failed attempts for a given day.

VisRAID: Visualizing Remote Access for Intrusion Detection
299
The ECS dataset is recorded from a live network in normal operation. The
log produced contains IP addresses and usernames of everyone to use the sys-
tem during the recording period. As this information could easily be used to
identify people, it requires being anonymized to be ethically used without each
user’s consent. SSHD logs contain usernames and raw IP addresses. Both user-
names and IP addresses can be useful to malicious people. IP addresses allow
for approximate location of a user’s home through GeoIP databases, as well as
direct attacks on the security of their computers. Usernames do not carry as
signiﬁcant a risk to the owner, though these could be useful to mount an attack
on the ECS system directly.
Both datasets were anonymized, but the procedures were diﬀerent. The Hon-
eynet dataset is publicly available in an anonymized form, hence we did not
have to do anything further to the data [6]. The ECS dataset was recorded from
Internet facing servers in the ECS network. The ECS dataset was anonymized by
system admin staﬀwithin our department. The data required anonymizing both
usernames and IP addresses. IP addresses were anonymized with CryptoPAN
a preﬁx preserving IP address anonymize tool extended with support for IPv6
addresses [5]. CryptoPAN uses strong encryption to generate codes which are
combined with the IP address to produce a new valid IP address. This cannot
be reversed without knowledge of the key, or an eﬃcient means of cracking AES
encryption. Usernames were anonymized through a script, where each username
was replaced with the string “user” and a unique number.
4.3
Procedure
The user study was conducted in a controlled lab, with only the participant
and session instructor present. Audio recordings were made as a record of events
during the study as an addition to handwritten observational notes. Participants
were provided with a desktop computer running at 1920x1080 resolution and the
Chrome web browser.
Participants were given up to ten minutes to familiarize themselves with
VisRAID. After familiarization, participants were asked to answer four questions
about each dataset for a total of eight tasks. Questions were presented to users
in a random order to avoid any learning bias. Participants were given up to eight
minutes for each task. The participants were not given the opportunity to read
questions before the study began which limited their opportunity to learn the
answers to later questions while answering a question.
The four questions are listed below. Tasks 1 through 4 were based on ques-
tions 1 and 2, with tasks 1 and 4 using the ECS dataset, and tasks 2 and 3 using
the Honeynet dataset. Tasks 5 through 8 were based on questions 3 and 4, with
tasks 5 and 7 using the ECS dataset, and tasks 6 and 8 using the Honeynet
dataset. Table 1 lists the combinations of tasks, questions, and datasets.
Q1 Find an instance of a successful brute force attack on root.
Q2 Find an instance of a successful scattergun attack. (an instance where the
attacker attempts many common username/password pairs at random).
www.ebook3000.com

300
L. Trethowen et al.
Q3 Find an instance of a legitimate user logging in from an abnormal location.
Q4 Find an instance of a legitimate user logging in at an abnormal time.
Q1 and Q2 are based on the most commonly found attack signatures in
SSH logs with many botnets and automated systems carrying out brute force or
scattergun attacks against any IP address responding to connection requests. As
these attacks are very common and can lead to serious compromises determining
success or failure of such attacks is a core function of any log analysis tool. Q3 and
Q4 are based on ﬁnding anomalous behaviour by legitimate accounts. Anomalous
behaviour by legitimate accounts can be an indication that their account has
been compromised, or that the account owner has become malicious.
For each task a brief questionnaire was completed indicating participants’
subjective opinions about diﬀerent aspects of VisRAID [8]. Participants were
asked to complete the following three questions using a 7 point likert scale,
where 7 is Strongly Disagree, and 1 Strongly Agree.
1. I am satisﬁed with the ease of completing this task.
2. I am satisﬁed with the amount of time it took to complete this task.
3. I am satisﬁed with the support information (e.g. online help, documentation)
when completing this task.
Timing and accuracy for each task was recorded. For each task a date, time,
source IP, and where applicable username involved were recorded. This informa-
tion combined with the dataset provides suﬃcient details to allow checking of
answers for accuracy from the raw logs, database directly, or using VisRAID.
4.4
Results
Each Task was given a pass/fail grade based on accuracy. Time taken to complete
each task was also measured. Results are shown in Table 1. A dash indicates the
task was not completed in time, hence an incorrect answer. Ticks represents
correct answers and crosses incorrect answers.
Table 1. Time and accuracy results for each task by participant (Professionals and
Students). Dashes represent tasks not completed within 8 mins. Ticks represents correct
answers and Crosses incorrect answers.
T# Q Dataset
P1- P
P2 - P
P3 - S
P4 - S
P5 - P
P6 - P
Correct
1
Q1 ECS
3:05
✓
5:46
✗
-
✗
-
✗
-
✗
-
✗
1
2
Q1 Honeynet -
✗
-
✗
2:26
✓
2:09
✓
3:55 ✓
3:08
✓
4
3
Q2 Honeynet 5:10
✓
-
✗
4:18
✓
4:51
✓
8:00 ✓
2:20
✗
4
4
Q2 ECS
-
✗
-
✗
4:18
✓
3:18
✗
-
✗
-
✗
1
5
Q3 ECS
1:09
✓
1:22
✓
1:07
✓
0:39
✓
1:04 ✓
1:10
✓
6
6
Q3 Honeynet 0:31
✓
1:07
✓
1:02
✓
1:13
✗
1:00 ✓
2:15
✓
5
7
Q4 ECS
0:45
✓
1:59
✓
0:42
✗
0:44
✓
2:06 ✓
-
✗
4
8
Q4 Honeynet 0:32
✓
1:10
✗
1:32
✗
1:07
✓
1:15 ✓
0:55
✓
4
Total
26.32 6/8 34.44 3/8 22.45 5/8 20.81 5/8 32.8 6/8 33.08 4/8 29/48

VisRAID: Visualizing Remote Access for Intrusion Detection
301
When participants were working on Tasks 1 and 4 (ECS), they had diﬃculties
in navigating the timeline which was a signiﬁcant aspect for carrying out these
tasks. Task 1 involved ﬁnding a brute force attack which compromised root.
There was no such attack present in the dataset. Demonstrating the absence
of an item in a dataset can be signiﬁcantly harder than ﬁnding the presence
of it similar to ﬁnding bugs in software. Only one participant was successful in
completing Task 1 and we believe the combination of navigation diﬃculties in
the visualization with increased task diﬃculty was the cause of the very high
failure rate for this task. Task 4 involved participants looking for a successful
scattergun attack in the ECS dataset. Only one participant was successful in
completing Task 4. Poor navigation support caused problems as the relatively
small attack signature was easily swamped in other data.
Tasks 2 and 3 (Honeynet) were to ﬁnd a brute force and scattergun attack
respectively. There were multiple successful brute force attacks, and scattergun
attacks with much larger attack signatures (higher number of attempts). These
questions were quickly and reliably answered by most participants. Poor accu-
racy, and signiﬁcantly slower times with the ECS data coupled with observations
of participants attempting these tasks suggest that navigation diﬃculties and
limited ﬁltering options were a greater issue in the more complicated dataset,
with smaller attack signatures, and greater noise. Participants performed much
better for tasks 5–8.
The introduced scattergun attack in the ECS dataset had a relatively small
attack signature, with only 204 log entries involved, of 4.7K entries for that day.
Some successful attacks on the Honeynet dataset had similar numbers of access
attempts, though often a much higher proportion of invalid or failed attempts for
a given day. There were many more legitimate access attempts to the ECS net-
work, and much higher event density. Logging of disconnect messages introduced
further noise to the system.
Participant 2 (Professional) had a great deal of diﬃculty in identifying brute
force and scattergun attacks on both datasets. Feedback and observation of the
participant in action suggest severe diﬃculties with navigation, combined with
the lack of ability to hide all attempts from a speciﬁed set of IP addresses
caused signiﬁcant diﬃculties for this participant. Participant 2 commented that
in the normal course of investigating such incidents using tools such as grep,
they would build up a blacklist of IP’s to hide from results as they were fully
investigated and discarded. VisRAID does not currently support this analysis
feature. Participant 2 has signiﬁcantly more experience in analyzing SSHD logs
using traditional tools where stronger ﬁltering tools are available, such as regular
expressions.
Figure 5 shows the perceived eﬀectiveness for the questions in the survey
participants completed at the end of each task. Each question in the survey was
answered with a score on a 7 point likert scale, where 1 is Strongly Agree and
7 is Strongly Disagree. There were variations between participants as could be
expected in an early prototype, which can be caused by many factors. The results
of the survey match well with the accuracy and time results, as each participant
www.ebook3000.com

302
L. Trethowen et al.
gave a higher score (Disagree) for tasks they found diﬃcult. For ease and amount
of time to complete a task the perceived eﬀectiveness had a similar range with
median of 2 and an outlier at 7. Amount of time did not have any outliers. For
support the perceived eﬀectiveness had a smaller range with a median of 3. The
results shows that participants felt VisRAID was easy to use, allowed them to
ﬁnd the answers within a reasonable amount of time, but better support was
required for helping participants to use VisRAID.
Ease
Time
Support
1
2
3
4
5
6
7
Survey question for each task 
Likert (1 = Strongly Agree, 7 = Strongly Disagree)
Fig. 5. Perceived Eﬀectiveness of Ease of use, completion Time, and Support available
5
Discussion
Based on our evaluation we discuss how VisRAID meets the design goals, weak-
nesses, suggested improvements, and limitations of the user study.
5.1
Design Goals
Several goals were presented to help guide the design of VisRAID. Some design
goals were met while others were not.
G1: Deploy visualizations over the web. VisRAID was developed as a
web-based application and can display visualizations using JQuery and D3 inside
a web browser.
G2: Strong ﬁltering and highlighting options. Participants were able to
successfully answer questions about both datasets with VisRAID. Highlighting
is not currently implemented. Extensions could be added to make the ﬁltering
stronger and implementing highlighting.
G3: Show surrounding context for anomalous accesses. The time-
line display shows the surrounding time, with each level of zoom reducing the
surrounding time that is visible. This provides context to users, but requires
improvement due to navigation diﬃculties when transitioning.
G4: Support sharing of work and saving work in progress. These
goals were not tested, but VisRAID is designed to support sharing of work
through URL passing and saving work in progress through browser bookmarking.

VisRAID: Visualizing Remote Access for Intrusion Detection
303
G5: GeoIP support to add context to login attempts This is currently
used for abnormal location detection, but is not currently made available to the
user directly.
G6: User control over machine monitoring. Users have direct control
over which machine’s log data is shown at any time through the server menu,
which is populated with a list of all servers known to the database.
G7: Show network context for currently monitored machine. Due
to time this design goal was not met.
G8: Extensible log parsing. Only SSHD logs are supported, but integra-
tion of other syslog formats is possible.
5.2
Weaknesses
Navigation. Diﬃculties were experienced by most participants, where abrupt
transitions between zoom levels lead to loss of context, and diﬃculty building
up a mental map of the timeline. Most users demonstrated improved navigation
as they became more familiar with VisRAID. These issues could be addressed
in two major ways: showing a radar view to assist users in maintaining context,
and animating transitions to build up a mental map of the log.
Filtering. Analysis of the diﬃculties experienced by participant 2, and sugges-
tions from other participants several new ﬁltering options would signiﬁcantly
enhance the ability to deal with potential information overload. Implementing
IP blacklisting would be extremely useful for some users, as it would support
an interaction model where one IP is fully investigated, then hidden, and the
process repeated until all suspicious IP’s have been investigated. One partici-
pant suggested allowing ﬁltering by an authentication method. This is strongly
supported by the diﬃculties users had in Task 1, as on multiple occasions, a
successful root login would occur mixed in with many failed attempts. This
successful login would be from a diﬀerent IP address, using an authentication
method not amenable to brute force, such as host-based authentication. Allow-
ing ﬁltering by authentication method, would assist users in avoiding this pitfall,
by hiding a class of logins which cannot be involved in attacks.
Information Hiding. Information hiding is an issue for VisRAID as the time-
zone display caused all participants to query the discrepancy in times for the
Honeynet dataset. This caused some confusion at ﬁrst, however, results suggest
that once informed of the issue users could compensate.
5.3
Suggested Improvements
Animated Zooming. Users complained that they get lost when zooming. A
common feature used to smooth out such transitions and ease navigation is ani-
mating the zoom level. Animated zooming oﬀers the potential for improvements
by helping to address the navigation issues experienced by participants. As each
timeline is currently updated independently and zooming replaces the contents of
www.ebook3000.com

304
L. Trethowen et al.
all timelines. The most common zooming action would be for the selected block
to grow to ﬁll all four timelines, replacing their data with a detailed breakdown.
Filtering by subnet. Adding options to ﬁlter IP addresses by subnet would
potentially be useful, as it would allow more controllable ﬁltering on IP than
is currently present. Currently ﬁlters are restricted to matching against dotted
quad forms of address. There would be some diﬃculty in implementing the ﬁl-
tering approach, as IP addresses are currently stored in human readable formats,
not suitable for matching against less common subnets. Matching against sub-
nets in 1 byte increments (/8, /16, /24) would be easy, as these match with the
dotted quad format used.
IP Address Hiding. The inverse of the IP of interest ﬁlter is IP address hiding
which shows all addresses except those selected. This would allow support of
another interaction model, as used by participant 2. Implementing IP hiding, or
blacklisting is relatively simple from a server side perspective, as the datastore is
able to eﬃciently handle complex selection criteria. The diﬃculty is maintaining
the stateful URL for this ﬁlter. Blacklists can grow potentially quite large, and
URLs have an implementation deﬁned maximum size. Larger URLs can be too
long to email, hence a new approach may be needed.
Filter events by authentication type. This will help reduce false detection
rates for brute force and similar attacks, as some authentication methods are
not vulnerable to these attacks. Adding ﬁltering for authentication type would
oﬀer the ability to hide all events that cannot be involved in speciﬁc types of
attacks. This would be straightforward to implement but requires changes in
several places. The data access layer of the server would have to be modiﬁed
with an optional where clause in the query, and the URL would have to be
modiﬁed with another optional ﬁltering clause.
Suppress abnormal time and place warnings for invalid and failed
attempts. This will cut down the number of abnormalities reported, and help
to reduce false positives and information overload. The ability to spot abnormal
logins would be improved. Implementation would require a change to the server,
to ignore time and location ﬂags when producing the aggregated data.
Separate disconnection messages into their own type. This would allow
hiding of disconnection messages in the same way failed and successful connec-
tions can be hidden, reducing noise in the dataset. Implementation would require
changes in the aggregation code to count disconnections separately, and draw a
5th category of event.
Scaling to larger datasets. VisRAID was only tested on two datasets, where
ECS was the largest and contained up to 75K log entries. Testing on much larger
datasets will determine how well VisRAID scales and performs.
Larger Evaluation. Once VisRAID has been improved a further evaluation
should be conducted with a larger scope, statistically signiﬁcant sample size,
and larger and more varied datasets to address the weaknesses. A further

VisRAID: Visualizing Remote Access for Intrusion Detection
305
improvement to the evaluation procedure would be the inclusion of a training
dataset to allow participants to become familiar with the application.
5.4
Limitations
There were some limitations with the user study and the datasets. The user
study was conducted in a controlled lab environment, for a set period of time,
and an application that the participants were not familiar with. Only six partic-
ipants were involved, two of whom were computer science students. Students are
less ideal for this kind of study, as their experience and domain knowledge are
more limited than those that have been working in the industry for some time.
Obtaining security professionals for user studies is diﬃcult as we found there
were a limited number in the city where the study was conducted. We could
obtain more participants by evaluating in diﬀerent locations. Small, exploratory
evaluations have advantages in cost and time required. With small numbers of
participants, the evaluation can be conducted in a short time and non-viable
approaches can be discarded before signiﬁcant development eﬀort is invested.
Both datasets are in the 10’s of thousands of entries, We have not tested
VisRAID with much larger networks such as over 100K log entries. The addition
of a successful scattergun attack to the ECS dataset represents a potential weak-
ness of this study, however, great care was taken to ensure that the inserted log
entries matched the patterns found in other scattergun attacks on both datasets.
Participants were using datasets that they were not familiar with. Testing on
much larger datasets in the future will determine how VisRAID scales.
6
Conclusion
Detecting malicious attempts to access computers is diﬃcult with current
security applications. Many current applications do not give the user the right
information to ﬁnd and analyze possible attempts. In this paper we presented
VisRAID – a novel visual analytics web application for detecting intrusions via
remote access attempts, and conducted a preliminary user study to evaluate the
eﬀectiveness and usability of the application with security professionals.
The user study involved six participants four of whom were security profes-
sionals. Participants were able to eﬀectively answer the questions in the user
tasks using diﬀerent sized data sets. Some questions proved to be more diﬃcult
than others. The results showed that participants felt VisRAID was easy to use,
allowed them to ﬁnd the answers within a reasonable amount of time, but better
support was required for helping users learn the application. VisRAID could be
improved by allowing easier navigation of the visualizations, providing better
support for ﬁltering by IP, and the ability to hide information more eﬀectively.
www.ebook3000.com

306
L. Trethowen et al.
References
1. Bertini, E., Hertzog, P., Lalanne, D.: SpiralView: towards security policies assess-
ment through visual correlation of network resources with evolution of alarms.
In: Proc. of Conference on Visual Analytics Science and Technology (VAST),
pp. 139–146. IEEE (2007)
2. Bostock, M., Ogievetsky, V., Heer, J.: D3 Data-Driven Documents. IEEE Trans-
actions on Visualization and Computer Graphics 17(12), 2301–2309 (2011)
3. Chin, G., Singhal, M., Nakamura, G., Gurumoorthi, V., Freeman-Cadoret, N.:
Visual analysis of dynamic data streams. Information Visualization 8(3), 212–229
(2009)
4. Data Geekery. jOOQ: Get back in control of your SQL, October 30, 2013. http://
jooq.org
5. Fan, J., Xu, J., Ammar, M., Moon, S.: Preﬁx-preserving ip address anonymization:
Measurement-based security evaluation and a new cryptography-based scheme.
Computer Networks 46(2), 253–272 (2004)
6. Honeynet Project. Forensic Challenge 10 - Attack Visualization, June 05, 2013.
http://www.honeynet.org/challenges/attack visualization challenge
7. Itoh, T., Takakura, H., Sawada, A., Koyamada, K.: Hierarchical visualization of
network intrusion detection data. IEEE Computer Graphics Applications 26(2),
40–47 (2006)
8. Lewis, J.R.: IBM computer usability satisfaction questionnaires: psychometric eval-
uation and instructions for use. International Journal of Human-Computer Inter-
action 7(1), 57–78 (1995)
9. Makanju, A., Brooks, S., Zincir-Heywood, A., Milios, E.: LogView: visualizing
event log clusters. In: Proc. of Conference on Privacy, Security and Trust (PST),
pp. 99–108. IEEE (2008)
10. Mukosaka, S., Koike, H.: Integrated visualization system for monitoring security
in large-scale local area network. In: Proc. of the Asia-Paciﬁc Symposium on Infor-
mation Visualisation (APVIS), pp. 41–44. IEEE (2007)
11. Stanton, N.: Human factors in alarm design. CRC Press (1994)
12. Tricaud, S.: PicViz: ﬁnding a needle in a haystack. In: Proc. of the USENIX Con-
ference on Analysis of System Logs. USENIX Association (2008)
13. Xu, W., Huang, L., Fox, A., Patterson, D., Jordan, M.I.: Detecting large-scale
system problems by mining console logs. In: Proc. of the Symposium on Operating
Systems Principles (SIGOPS), pp. 117–132. ACM (2009)
14. Zhang, Y., Xiao, Y., Chen, M., Zhang, J., Deng, H.: A survey of security visual-
ization for computer network logs. Security and Communication Networks 5(4),
404–421 (2012)

BP-XACML an Authorisation Policy Language
for Business Processes
Khalid Alissa1,2(B), Jason Reid1, Ed Dawson1, and Farzad Salim1
1 Institute of Future Environment, Queensland University of Technology,
Brisbane, QLD, Australia
{Khalid.alissa,jf.reid,e.dawson,f.salim}@qut.edu.au
2 King Abdulaziz City for Science and Technology (KACST), Riyadh, Saudi Arabia
Abstract. XACML has become the defacto standard for enterprise-
wide, policy-based access control. It is a structured, extensible language
that can express and enforce complex access control policies. There have
been several eﬀorts to extend XACML to support speciﬁc authorisa-
tion models, such as the OASIS RBAC proﬁle to support Role Based
Access Control. A number of proposals for authorisation models that
support business processes and workﬂow systems have also appeared in
the literature. However, there is no published work describing an exten-
sion to allow XACML to be used as a policy language with these mod-
els. This paper analyses the speciﬁc requirements of a policy language
to express and enforce business process authorisation policies. It then
introduces BP-XACML, a new proﬁle that extends the RBAC proﬁle for
XACML so it can support business process authorisation policies. In par-
ticular, BP-XACML supports the notion of tasks, and constraints at the
level of a task instance, which are important requirements in enforcing
business process authorisation policies.
Keywords: XACML · BPM · Workﬂow · Authorisation management ·
Authorisation policy language
1
Introduction
The domain of ‘Business Process Management (BPM)’ is an important and
maturing domain. A survey by Gartner [6] showed that BPM is the number one
concern of many senior executives. This increasing interest in BPM has prompted
research in a variety of directions, including the domain of access control. Several
access control models designed speciﬁcally for the business process environment
have been presented in the literature including [3], [11], and [16]. Most of these
proposals focus on the authorisation model itself, and do not specify an autho-
risation policy language, which is an important aspect of authorisation man-
agement. One of the most accepted and widely discussed authorisation policy
languages is the eXtensible Access Control Markup Language (XACML) [8].
XACML is an XML deﬁned standard language for access control policies.
XACML uses rules, which are deﬁned in policies, in conjunction with a standard
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 307–325, 2015.
DOI: 10.1007/978-3-319-19962-7 18
www.ebook3000.com

308
K. Alissa et al.
component called a Policy Decision Point (PDP). The PDP evaluates access
requests against the policies to decide whether to allow or deny the request [9].
The XACML RBAC Proﬁle [2] was proposed to extend the initial version
of XACML. It supports the notion of roles to be able to support role-based
access control policies [2]. The RBAC proﬁle supports both core and hierarchical
RBAC, but it explicitly states that it does not support separation of duty (SoD)
constraints [2], although an earlier draft of the proﬁle [1] did mention SoD, but it
was removed in the ﬁnal release. To the best of the author’s knowledge, currently
there is no published work that aims to extend the XACML language to support
authorisation policies for business processes.
This paper proposes BP-XACML, an extension to XACML to express autho-
risation policies for business processes. The proposed extension builds on the
RBAC proﬁle to support the notion of tasks and task instances, to support
instance level restrictions, and separation of duty (SoD) constraints. The paper
identiﬁes the features that the language should support, deﬁnes the needed exten-
sion, and describes the new XACML proﬁle, BP-XACML. The paper introduces
a new function called ‘performers list’ along with new authorities to support the
history-based instance-level restrictions. It also proposes a new policy set to sup-
port tasks, and a new attribute to recognise the task instances. It introduces new
conditions and functions to support SoD. Figure 1 shows the complete frame-
work of BP-XACML showing all ‘policy-sets’ and authorities. Elements shaded
in white are from the XACML standard. Those with dotted background are
added in the RBAC-XACML proﬁle, while the ones with dark background are
introduced in this paper (BP-XACML).
The rest of the paper is organized as follows. Section 2 provides an example
scenario to illustrate the need for a new policy language. Section 3 discusses the
characteristics of the language. The structure of the policy language is explained
Fig. 1. BP-XACML Authorities and policy sets

BP-XACML an Authorisation Policy Language for Business Processes
309
in section 4. Section 5 discusses the policy model. The language semantics are
explained in section 6. Section 7 provides a review of related works. Finally,
section 8 concludes the paper.
2
Example Scenario
In order to illustrate the various policy language requirements for an access
control system for business processes, this section will consider the access control
policies for a hypothetical business process that runs across a number of systems.
The example scenario is of a process of ﬁxing a pump malfunction in an air-
conditioning system in a high-security facility such as an airport.
Fig. 2. Business process model for ﬁxing pump malfunction
As can be seen in Figure 2, no one can perform a ‘soft reset’ on the pump unless
a malfunction notiﬁcation was received, and it has to be done by someone with the
role ‘coordinator’. If both ‘soft reset’ and ‘hard reset’ fail to solve the problem, a
work order is issued. Only users with the role ‘coordinator’ can issue the work
order. The approval of that work order should be done by a diﬀerent user with
the role ‘Manager’. A user with the role ‘contractor’ needs to show the work order
to gain access to the pump room. Once the issue has been resolved the user who
ﬁxed the problem will notify the user who issued the work order. This notiﬁcation
will result in revoking the access rights granted to the coordinator. The user who
created the work order is the only one allowed to close it, and will only be able to
do so after receiving the notiﬁcation and the invoice.
The policy language must support the deﬁnition of policies that reﬂect these
access control restrictions and conditions. Some of these access control policies
cannot be expressed directly in XACML.
www.ebook3000.com

310
K. Alissa et al.
3
Business Process Authorisation Policy Requirements
With its focus on tasks and their controlled, sequenced execution, an authori-
sation model for business processes introduces a range of capabilities not found
in the standard RBAC model [15]. Similarly, an authorisation policy language
for business processes requires more than what RBAC-XACML currently pro-
vides. This section will identify the important concepts and constraints that
such a policy language should be able to express by describing the signiﬁcant
functionalities that business process authorisation models support.
Role-Based access control (RBAC) [5] is a widely used authorisation con-
cept. It assigns access privileges to ‘roles’ instead of directly assigning them to
users, which reduces management overhead [13]. Users indirectly acquire per-
missions through their membership of roles. RBAC is an important concept to
be supported in business process authorisation [7]. Support for RBAC among
the published business process authorisation models including [16] and [11] is
widespread. For a policy language to be able to support the RBAC concept
it should support the notion of user, role, and permission. Moreover, the pol-
icy language should have the ability to represent Separation of Duties (SoD)
constraints to assist in preventing fraud [5].
Tasks are a fundamental concept in business process management. They are
the building blocks of business processes, so business process authorisation models
such as [11] and [16] typically focus on extending RBAC with the notion of tasks.
Reﬂecting this, authorisation policy language for business processes should sup-
port the notion of ‘tasks’ as a group of permissions. The example in Section 2 shows
that requests are to perform a ‘task’, rather than to acquire a permission. So, it is
important to be able to deal with tasks as well as permissions.
An important functionality that is supported by the more expressive business
process authorisation models such as [16] is history-based restrictions between
tasks on the instance-level, which we will refer to as ‘Instance-level Restrictions
(IR)’. These are restrictions that apply only within a unique execution instance
of a process [16]. For example, consider the policy from section 2, which states
that the person who closes a ‘work order’ must be the same user who issued it. So,
a user will only be allowed to close the work order if he previously performed the
issue function within the same process instance. This is an example of Binding of
Duty (BoD) at the instance level. Separation of duty (SoD) on an instance-level
requires that two tasks within an execution instance of a process, be performed
by diﬀerent users.
A ﬁrst step to support instance-level restrictions is to be able to distin-
guish between instances. Some authorisation models such as [16] and [17] sup-
port the notion of ‘task instance’, which allows diﬀerent execution instances
to be distinguished. So, a policy language should be able to represent a ‘task
instance’. The language should also have the ability to represent the ‘instance-
level restrictions’ themselves by specifying a separation or binding of duty relation
between two tasks. Moreover, in order to enforce this condition (an instance-level
restriction) the language should have the ability to retrieve history based infor-
mation on an instance level [17], such as, who issued a speciﬁc ‘work order’.

BP-XACML an Authorisation Policy Language for Business Processes
311
The key concepts that an authorisation policy language for business processes
should be able to represent are: Users, Roles, Operations, Tasks, Task instance,
Instance-level restrictions, and SoD. The RBAC proﬁle of XACML supports
representation of the ﬁrst three characteristics. The proposed policy language
extends RBAC-XACML to provide support for representation of tasks, task
instances, SoD, and instance-level restrictions.
4
BP-XACML: Policy Structure
BP-XACML is based on XACML which implements rule-based access con-
trol [12]. An authorisation policy may contain multiple authorisation rules (AR),
which are the basic building blocks for stating authorisation restrictions. Each
AR consists of four elements: Subject, Object, Action, and Condition, the eval-
uation of which results in a Allow or Deny decision. AR = {S, O, A, C} →
{Allow, Deny}.
Action (A) is implementation speciﬁc. Condition (C) is a boolean expression
that is evaluated based on the value of variables determined at run time as either
true or false. Conditions can be used to represent complex constraints. The rule
has its speciﬁed eﬀect (allow or deny) if the condition evaluates as true. Rules are
grouped together in ‘policies’, which may contain a target that limits the applica-
bility of rules to requests which match the target’s subject, object and action [9].
Policies also specify a rule-combining algorithm, which resolves potential con-
ﬂicts when more than one rule is applicable [9]. Policies can be grouped together
in a ‘policySet’ that also contains a target, and a policy-combining algorithm. It
may also contain other policy sets included by reference[9].
4.1
Request and Decision
An XACML request message is sent to the PDP when a user tries to access
a controlled resource. The PDP identiﬁes matching policies and evaluates the
request against them to arrive at an authorisation decision. The Request (RQ) is
in the form of {S,O,A}. In BP-XACML there are three types of resource whose
related policies are deﬁned in three diﬀerent policy sets (see Section 4.2). In the
context of the request, the interpretation of S, O and A is diﬀerent for each
type. Because of this, each type of request is processed by a diﬀerent authority.
Firstly, in the case of a user requesting to perform a workﬂow task, the subject
(S), will be the identiﬁer for the speciﬁc user making the request. The object
(O), is the task that the user wants to perform. Since a task explicitly deﬁnes its
associated permissions (object, action pair), they are not separately identiﬁed in
the request. The Action (A), is simply the request to ‘perform’. In the second
case a user requests access to a resource object that is not a workﬂow ‘task’, for
example, to access the ‘pump room’. In this case, O will be the ‘pump room’,
and A will be ‘access’. The third type of request is to activate a role, for example,
‘Adam’ wants to activate the role ‘coordinator’. In such requests, S is ‘Adam’,
O is the role ‘coordinator’, and A is ‘activate’. The decision (DS) will be either
{Allow}, {Deny}, or {Not applicable} if no matching policies are found.
www.ebook3000.com

312
K. Alissa et al.
4.2
Policy Sets
In XACML ‘Policy sets’ are used to group related policies, which contain, groups
of related access control rules. The RBAC proﬁle of XACML predeﬁnes some
policy sets and makes use of them to determine the access control decision.
For example, a RoleAssignment<PolicySet> will include all policies and rules
related to role assignment. In this extended proﬁle we will make use of these
policy sets and introduce new policy sets.
BP-XACML includes seven types of access control policy sets. The PDP will
use two policy sets, the Role<PolicySet>, and the Permission<PolicySet>
to make decisions on the requests directed to the PDP. The task<PolicySet>,
and RoleTask<PolicySet> are used to state the tasks that a role is allowed
to perform. IR<PolicySet> is used to state instance-level restrictions. The SoD
<PolicySet>, and RoleAssignment<PolicySet>, are used for stating and acti-
vating roles of each user. The Role<PolicySet>, Permission<PolicySet>, and
RoleAssignment<PolicySet> are adopted from the XACML RBAC proﬁle [9].
The rest of the PolicySets are newly introduced in this paper, and will be dis-
cussed in this section. The mechanism and application of these policy sets will
be discussed in more detail in section 6. Figure 3 shows the relation between
IRPS, RTPS, and TPS, and gives a summary of the structure of each policy set.
Fig. 3. New Policy Sets
Task<PolicySet> (TPS) is a <PolicySet> that contains the actual tasks
authorised for a given role. The <Target> element of a TPS, should not
limit the applicability of the <PolicySet> as the IR<PolicySet> and the
RoleTask<Policy Set> restrict access (see Figure 3). To achieve role hierar-
chy, a TPS associated with a senior role may also contain references to TPSs
associated with junior roles, thereby allowing the senior role to inherit all access
to tasks associated with the junior roles. In a TPS, (S) refers to user’s role, and
(O) refers to task.

BP-XACML an Authorisation Policy Language for Business Processes
313
RoleTask<PolicySet> (RTPS) is a <PolicySet> that contains the Roles,
and for each role it points to the corresponding Task<PolicySet> (i.e. the TPS
is included in the RTPS by reference). The <Target> element of a RTPS, should
not restrict the applicability of the <PolicySet>, but the <PolicySet>s for each
role (that are included within the RTPS) has a target restricting applicability
for the speciﬁed role only. The RTPS is used to achieve role hierarchy. In the
RTPS Subject (S) refers to the user’s role, and Object (O) refers to the task.
IR<PolicySet> (IRPS) is a <PolicySet> that describes instance-level
restrictions. The RTPS and TPS can only be reached through the IRPS where
they are included by reference. The Task Authority will ﬁrst access this policy
set to check if there is no violation of an IR constraint, then it will be pointed via
the RoleTask<PolicySet> to the related Task<PolicySet>. Section 6.3 explains
this in more detail. In the IRPS, the subject (S) is not restricted because IR con-
straints deal with task instances regardless of the subject. The object (O) is the
task, and the action (A) is ‘perform’. For example, no user is allowed to perform
both ‘issue work order’ and ‘approve work order’. In this case the IRPS will have
both tasks in one policy making sure that the user does not perform both for
the same instance.
SoD<PolicySet> (SoDPS) is a <PolicySet> that describes separation of
duties constraints. It restricts access to the RoleAssignment<PolicySet>. The
Role Enablement Authority will ﬁrst access this policy set to check if there is
no violation of SoD constraint, then it will be pointed to the RoleAssignment
<PolicySet>. In a SoDPS, the subject (S) is not restricted because SoD con-
straints deal with roles regardless of the subject. The object (O) is a role. Each
policy in the SoD<PolicySet> includes a pair of conﬂicting roles.
4.3
Conditions
A condition is speciﬁed as a Boolean expression that is evaluated at runtime.
There are two main types of policy conditions of interest in specifying access
restrictions in this policy model. The ﬁrst one is dynamic Separation of Duties
(SoD) conditions on role level. The other one is instance-level restrictions (IR).
A dynamic SoD condition is an expression that can be evaluated for user-role
relation by testing the current active roles for this user. It is used to prevent a
user from activating two conﬂicting roles by the same user at the same time.
They are deﬁned as policies in the SoD<PolicySet>. SoD : (Role1, Role2). The
Role enablement authority (REA) will be able to know the SoD restriction before
enabling a role. It will use the ‘session‘ component to check the current status of
role enablement for a user requesting role activation. Session maintains the list
of active roles for each user.
An ‘instance-level restriction’ (IR) condition is an expression that can be eval-
uated to check the relation between two objects within the same instance. They
are deﬁned as policies within the IR<PolicySet>. IR : ({Task1, Task2}, type).
IR is a type of SoD (or BoD) restriction on a task level that only applies within
the same instance. It makes sure that the restriction is met within the same
instance. For example, the task of ‘closing work order’ should have a restriction
www.ebook3000.com

314
K. Alissa et al.
that it can be only done by the same user who performed ‘issue work order’ for
this same instance.
5
BP-XACML: Policy Model
BP-XACML is designed to be backward-compatible with the RBAC-XACML
policy structure. This has an important beneﬁt: It means that role-based autho-
risation policies can be deﬁned and managed independently of the workﬂow
authorisation system. These policies will still be applied when a user requires
access to a controlled resource to execute an instance of a business process. This
design approach introduces some complexity, most notably in the inclusion of
the Task Authority as a separate PDP to authorise task activation. But it is
necessary because the role-based authorisation policies that control access to
an organisation’s valuable resources, (e.g. customer records, ﬁnancial records
etc.) are typically created and maintained independently of the business pro-
cesses. They will often exist before a workﬂow is created that uses the controlled
resources. These policies still need to be applied in the context of the workﬂow
but we argue that this should not be done by a parallel and duplicated workﬂow
authorisation system, since this would be ineﬃcient and diﬃcult to maintain.
Accordingly, we have designed the BP-XACML policy structure to work with an
existing RBAC-XACML policy set. This results in an integrated system which
can handle both workﬂow and non-workﬂow requests from a single (and therefore
consistent) set of policies.
After explaining the structure of the BP-XACML policy language, this
section will describe the BP-XACML policy model. It shows how access deci-
sions are made using the deﬁned ‘policy sets’, describes the needed authorities
and repositories, and explains the policy model framework.
5.1
Authorities and Repositories
In this policy model we are introducing a new authority and two repositories
that are needed to fulﬁll the requirements. They are the Task authority (TA),
Performers list (PL), and Task-permissions list (TPL). We also include the ‘Role
Enablement Authority (REA)’, and ‘session’ concept from the XACML RBAC
proﬁle, and we elaborate on how to use them, as the RBAC proﬁle does not
provide these details.
It might appear unnecessarily complex to add these authorities, where some
of them are essentially a specialised PDP. One might argue that one PDP should
be enough. However, the RBAC-XACML proﬁle [2], which is proposed by OASIS,
adopts this approach in introducing the REA. The RBAC proﬁle shows that role
enablement should be out of the scope of the PDP, that is why REA was intro-
duced to be responsible for role assignment and enablement [2]. The justiﬁcation
for having a specialised PDP for role enablement can be understood by looking
at the basic request concept of XACML, where each request contains a subject
and an object. The PDP is designed to deal with one interpretation of each

BP-XACML an Authorisation Policy Language for Business Processes
315
aspect of the request (subject, object, action). For example, in RBAC-XACML
if the PDP receives a request it will look at the subject as the user’s role, and
the object as the resource that the user wants to perform an action on. Adam,
who is a manager, wants to read ﬁle2. The PDP will use the permission policy to
determine if managers are allowed to read ﬁle2. A request to activate a role has
the subject as the user ID, and the object as the role that needs to be activated.
That is why it was necessary to have a specialised PDP called REA. This REA
is designed to look at the subject as the user’s ID, and the object is the role
that the user wants to activate. Therefore it will be able to deal with activation
requests.
BP-XACML deals with three diﬀerent type of requests, where each type of
request has a diﬀerent interpretation of subject and object. The change in subject
and object interpretation, makes it necessary to have a diﬀerent authority to deal
with each diﬀerent type of request. The request to perform a task has the user’s
role as the subject and the task ID as the object. Therefore, the authorisation
of task performance is out of the scope of the PDP. TA is introduced in this
model to be the specialised PDP responsible for making a task performance
decisions. It permits backward compatibility with the role and permission policy
sets deﬁned in RBAC-XACML. TA deals with requests on the basis that the
subject is the user’s role and the object as the task ID. Therefore, it is able to
deal with requests to perform a task.
Fig. 4. Role Enablement Authority
Role Enablement Authority (REA) uses the SoD<PolicySet>, and Role
Assignment<PolicySet> to either allow or deny activation of a speciﬁc role for
a speciﬁc user.
Session provides a quarryable service, which maintains and continuously
refreshes the state of user role enablement relations.
Figure 4 shows how REA uses the RoleAssignment<PolicySet> to know if
the user is allowed to enable a role or not. Before reaching the RoleAssignment
<PolicySet>, REA checks the SoD<PolicySet> to check if a SoD policy is avail-
able for this role. If such a policy exists, REA needs to know the status of the
user’s activated roles. This information can be retrieved from the user’s session.
www.ebook3000.com

316
K. Alissa et al.
The information allows REA to evaluate if the condition is met or not. Based
on that REA will send the ﬁnal decision on the role enablement request.
Fig. 5. Task Authority
Task Authority (TA) uses the IR<PolicySet>, and Task<Policy Set> to
either allow or deny a user’s request to perform a speciﬁc task.
Performers list is introduced to provide a quarryable service to report the user
that performed a completed task instance. It maintains the state of user ‘task
instance’ performance relations, and continuously refreshes the state.
As can be seen in Figure 5, TA uses Task<PolicySet> to check if the role
is allowed to perform the task or not. Before checking the Task<PolicySet>,
TA ﬁrst checks the IR<PolicySet> to determine if there are any instance-level
restrictions on such task. If a restriction is found TA needs to retrieve extra
information to assess the restriction. This information can be found through the
‘Performers list (PL)’. It is important to be able to check IR restrictions. In
order for an IR condition to be evaluated, it is necessary to know the performer
of a given task instance.
Task-permissions list (TPL) is a new proposal. It maintains the state of task-
permission relations. TPL is used by the context handler (CH) to determine the
permissions associated with each task. TPL provides a list of permissions for
each task, where a permission is an action on a resource.
5.2
Access Control
BP-XACML model controls three types of access control requests: activating
a role (controlled by the REA), performing a task (controlled by the TA), and
performing action on a resource (controlled by the PDP). The context handler is
responsible for forwarding the request to the corresponding authority depending
on its type.
A single SoD<PolicySet> is deﬁned in the system, which contains all SoD
restrictions. The policy set itself is not limited (i.e. the target is empty and
therefore does not restrict the applicability of the included policies), but each
policy is limited to a speciﬁc role. It contains a single <PolicySetIdReference>

BP-XACML an Authorisation Policy Language for Business Processes
317
element, which refers to the RoleAssignment<PolicySet> (RAPS). There is a
single RAPS in a system, which contains the information on whether to allow
or deny the role activation for a speciﬁc user.
(a) REA can only access SoD PolicySet
(b) TA can only access IR PolicySet
Fig. 6. New PDPs access
As shown in Figure 6-a, the RAPS must be stored in a policy repository
in such a way that it can never be reached directly by the REA; RAPS must
be reachable only through the SoDPS. This is because, in order to support
separation of duties, it is important that the SoD policies are satisﬁed before
reaching the RAPS. For REA to achieve a decision on role activation request it
accesses the SoDPS and only check the RAPS if the SoD rules were satisﬁed.
A single IR<PolicySet> is deﬁned in the system, which contains all IR
restrictions. The policy set itself is not limited, as the policy set target is empty,
but each policy is limited to a speciﬁc task. The policy set contains a single
<PolicySetIdReference> element, which refers to the RoleTask<PolicySet>.
For the system there is a single RoleTask<Policy Set>, which contains a <Poli-
cySet> for each role, which points to the corresponding Task<PolicySet>.
A user will be authorised to perform a task if there is a permit rule for the
task in the TPS for a role that the user has active.
As shown in Figure 6-b, TPS instances, and the RTPS must be stored in a
policy repository in such a way that they can never be reached directly by the
TA. RTPS must be reachable only through the IRPS. This is because, in order
to support ‘role hierarchy’, the TPS depends on the RTPS to ensure that only
subjects holding the corresponding role attribute (or senior role) will gain access
to perform tasks in the given TPS. For TA to achieve a decision on a request to
‘perform a task’, it ﬁrst must access the IRPS, and check if there are any related
IR policies. IRPS will then point to RTPS. Using the user’s role, RTPS points to
the corresponding TPS, which contains rules stating whether this role is allowed
to perform a task or not. These <PolicySet> relationships and constrains are
summarised in Figure 3.
5.3
Policy Framework
Figure 7 shows the complete BP-XACML framework without the ‘policy sets’.
It includes all the authorities, components, and repositories. As explained ear-
lier, the policy model should be uniﬁed and deal with all authorisation requests,
www.ebook3000.com

318
K. Alissa et al.
regardless of whether or not they arise in the context of a workﬂow. For this rea-
son, the BP-XACML policy model is designed to deal with several types of
requests. It could be either a request to activate a role for a user, a request to
perform a task, or a standard RBAC request to perform an action on a resource.
In this section we will discuss each type of request by it self, and show how it is
handled within the framework.
Fig. 7. BP-XACML framework
The role activation requests are directed to the ‘role enablement authority
(REA)’ by the context handler. The REA will use theSoD<PolicySet> to check
for any SoD restrictions on this role. Then it will point to the RAPS to decide
if this user is allowed to activate this role or not. If there was an SoD constraint
on the role, REA will require extra information. For example, if there is a SoD
condition on activating this role, REA needs to make sure that activating this
role will not breach the SoD condition. Information about the activated roles of
this user will be obtained from the ‘session’ through the CH. Figure 8 shows the
steps related to this type of request.
The standard RBAC request is a request to perform an action on a resource,
where the resource is not a role or a task (e.g. read a ﬁle). This type of
request is directed to the PDP, and will be handled exactly how access requests
are handled in the RBAC-XACML proﬁle [9] using the Role<PolicySet> and
permission<PolicySet>. For more information please refer to [9]. In BP-
XACML, a request to perform a task, will produce a set of one or more requests
of this type (standard request).
If the request was to perform a speciﬁc task, the context handler will forward
the requests to the TA. The TA will use the IRPS to check if there are any IR
restrictions on this task. Violation of an IR results in a deny decision. Then it will
use the user’s role to identify the proper TPS through the RTPS. TPS identiﬁes

BP-XACML an Authorisation Policy Language for Business Processes
319
Fig. 8. Activating a role request
the tasks that this user is allowed to perform based on the role activated at the
request time. If an IR is restricting the assigning of a task, the TA will obtain
extra information from the ‘performers list (PL)’ through the CH to evaluate
the IR condition. If the TA allows the user to perform the task, CH will use
the Task Permissions List (TPL) to retrieve all permissions associated with the
task. Each permission is a pair of an action and a resource. CH will create a
request for each permission, with requests containing the user’s role, action, and
resource. These requests will be sent to the PDP and dealt with as standard
requests to perform an action on a resource. PDP will send back each decision
individually. CH will combine the decisions, where deny over rides. So, if one
request was denied, the whole request to perform the task will be denied. If all
requests were allowed, the CH will then send back to the PEP that this user is
allowed to perform the task. Figure 9 shows the steps for this type of request.
6
BP-XACML: Policy Semantics
In this section, we will reﬁne the previously described policy structure with spe-
ciﬁc data and language representations. Users, roles, operations and permission
are all part of the RBAC proﬁle of XACML. In this paper we adopt these enti-
ties and the way they are expressed from the RBAC-XACML [2]. Refer to [2] for
information on the representation of users, roles, operation, and permissions.
www.ebook3000.com

320
K. Alissa et al.
Fig. 9. A request to perform a task
6.1
Task and Task Instances
Task and task instances are new features that are not supported in RBAC-
XACML. In BP-XACML tasks are expressed as an XACML Resource. Listing 1
shows an example Task<PolicySet> showing the task as a resource.
<PolicySet
...
PolicySetId =" TPS:coordinator:role" PolicyCombiningAlgId ="& policy -combine ;permit - overrides">
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources >
<Actions ><AnyAction
/></Actions >
</Target >
<Policy
PolicyId =" Allowed
tasks"
RuleCombiningAlgId ="& policy -combine ;permit - overrides">
<Target >
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources >
<Actions ><AnyAction
/></Actions >
</Target >
<Rule
Effect =" Permit" RuleId =" issue:work:order:task">
<Subjects >< AnySubject /></Subjects >
<Resources >
<ResourceMatch
MatchId ="& function ;string -match">
<AttributeValue
DataType ="& xml;string"> issue
work
order </ AttributeValue >
<ResourceAttributeDesignator
AttributeId ="& resource;resource -id" DataType ="& xml;string "/>
</ResourceMatch > </Resources >
<Actions >
<ActionMatch
MatchId ="& function ;string -match">
<AttributeValue
DataType ="& xml;string">perform </ AttributeValue >
<ActionAttributeDesignator
AttributeId ="& action;action -id" DataType ="& xml;string "/>
</ActionMatch >
</Actions >
</Target > </Rule >
<Rule
Effect =" Deny" RuleId =" DenyRule "/>
</Policy >
</PolicySet >
Listing 1. Task Policy set
In listing 1 task was represented as an object in the policy, because TPSs
are linking the user’s role to the task, so the task is the object. To be able
to represent ‘Task instance’ a new object attribute is introduced, it is called
‘instance’. It is similar to the ‘role’ attribute from the RBAC-XACML proﬁle.
In section 6.3 an example listing showing instance-level restriction will show how
to make use of the new attribute ‘instance”.
As it can be seen the Task<PolicySet> will include a policy for each task
the role is allowed to perform. The example includes a policy for the task ‘issue
work order’ as a part of the policy set. The policy says if someone wants to
perform the action ‘perform’ on the object ‘task: issue work order’ they will be
allowed. As can be seen in the listing, the policy set target is not limiting the

BP-XACML an Authorisation Policy Language for Business Processes
321
applicability of the policy set. RoleTask<PolicySet> will limit the applicability
to users with the role ‘coordinator’ and then point to this policySet. Listing 2 is
an example RoleTask<PolicySet> for the role ‘coordinator’.
<PolicySet
...
PolicySetId =" RTPS" PolicyCombiningAlgId ="& policy -combine ;permit - overrides">
<Target > <Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources > <Actions ><AnyAction /></
Actions > </Target >
<Policy
PolicyId =" Coordinator:Role" RuleCombiningAlgId ="& rule -combine ;permit - overrides">
<Target >
<Subjects >
<SubjectMatch
MatchId ="& function :any -of">
<Apply
FunctionId =" urn:oasis:names:tc:xacml :3.0: function ;string -equal"
<AttributeValue
DataType ="& xml;string">coordinator </ AttributeValue >
<SubjectAttributeDesignator
AttributeId ="urn: someapp :attributes :role" DataType ="& xml;string "/>
</Apply >
</SubjectMatch >
</Subjects >
<Resources >< AnyResource /></ Resources >
<Actions >< AnyAction /></Actions >
</Target >
<!-- Use
tasks
associated
with
the " coordinator" role
-->
<PolicySetIdReference > TPS: coordinator:role
</ PolicySetIdReference >
</policy > </PolicySet >
Listing 2. The Role Task Policy Set
6.2
SoD on a Role Level
In BP-XACML SoD is expressed as policies in the SoD<PolicySet>. SoD refers
to the dynamic role level separation of duties, which is used to make sure that
no one user activates two conﬂicting roles at the same time. Listing 3 shows an
example SoD policy set. The policy set includes policies stating conﬂicting roles.
For example, the policy set in listing 3 includes a policy stating that in order to
activate the role ‘coordinator, the role ‘manager’ should not be in the activated
roles of the same user.
The function ‘Session’ is a new function that helps to check that the given
role is not available in the activated roles of the given user. This function takes
one argument of data-type ”..#string”, which is the user’s ID. It returns a list of
all roles currently activated for this user. Then the predeﬁned function “any-of”
will compare the given string with the list retrieved by the session function. If
the role was found the function will return the result ‘true’, and if it was not
found, it will return ‘false’. If the condition was true the rule will return ‘deny’
and the request will be denied. If the condition returns false, the rule will not
do anything and continue to the RoleAssignment<PolicySet>.
<PolicySet
...
PolicySetId =" SoD" PolicyCombiningAlgId ="& policy -combine ;deny - overrides">
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources >
<Actions >< AnyAction
/></Actions > </Target >
<Policy
PolicyId =" Coordinator:Role" RuleCombiningAlgId ="& rule -combine ;deny - overrides">
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >
<ResourceMatch
MatchId ="& function;string -match">
<AttributeValue
DataType ="& xml;string "> Coordinator
</ AttributeValue >
<ResourceAttributeDesignator
AttributeId ="& resource ;resource -id" DataType ="& xml;string "/>
</ResourceMatch > </Resources >
<Actions > activate
</Actions >
</Target >
<Rule
RuleId =" role: manager :not:active" Effect =" Deny">
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources >
<Actions >< AnyAction
/></Actions >
</Target >
<Condition
FunctionId ="urn:oasis:names:tc:xacml :3.0: function :any -of">
<AttributeValue
DataType =& xml;string"> manager
</AttributeValue >
<Apply
FunctionId =" http :// localhost/BPXACML/function #function ;Session ">
<SubjectAttributeDesignator
AttributeId ="urn: someapp :attributes :role" DataType ="& xml;string "/>
</Apply > </Condition >
</Rule >
</Policy >
<PolicySetIdReference > Role: Assignment
</PolicySetIdReference >
</PolicySet >
Listing 3. SoD policy set example
www.ebook3000.com

322
K. Alissa et al.
Listing 4 shows an example RoleAssignment<PolicySet>. The <PolicySet>
contains a policy for each user, which contains rules for each role the user can
activate. The policy set in listing 4 includes an example policy for the user Adam,
which includes an example rule for activating the role ‘coordinator’.
<PolicySet
...
PolicySetId =" Role: Assignment " PolicyCombiningAlgId ="& policy -combine ;deny -overrides">
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources >
<Actions ><AnyAction
/></Actions >
</Target >
<Policy
PolicyId =" Roles:For:user:Adam" RuleCombiningAlgId ="& rule -combine ;deny -overrides">
<Target >
<Subjects >
<SubjectMatch
MatchId ="& function ;string -match">
<AttributeValue
DataType ="& xml;string"> Adam
</AttributeValue >
<SubjectAttributeDesignator
AttributeId ="& subject ;subject -id" DataType ="& xml;string "/>
</SubjectMatch > </Subjects >
<Resources >< AnyResource /></ Resources >
<Actions >< AnyAction /></Actions >
</Target >
<Rule
RuleId =" Permission :to:activate :coordinator:role" Effect =" Permit">
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >
<ResourceMatch
MatchId ="& function ;string -equal">
<AttributeValue
DataType ="& xml;string "> Coordinator
</ AttributeValue >
<ResourcesAttributeDesignator
AttributeId ="& resource ;resource -id" DataType ="& xml;string "/>
</ResourcetMatch >
</Resources >
<Actions > Activate
</Actions >
</Target >
</Rule >
</Policy > </PolicySet >
Listing 4. Role Assignment policy set example
6.3
Instance-Level Restrictions (IR)
Instance-level restrictions (IR) are used to fulﬁll the need to apply history based
restrictions within the same instance. For example, the scenario states that the
user who close the ‘work order’ should be the same user who issued it. So, for the
same ‘work order’ (same instance), the user to perform ‘close work order’ must
be the same user who performed ‘issue work order’. IR restrictions are written
as policies in the IR policy set.
Listing 5 is an example IR<PolicySet> that includes instance-level restric-
tion using the BP-XACML language. The IR policy set has a policy for the task
‘close work order’. The policy has a rule stating that the user must be the same
user who issued the work order for the same instance.
The function ‘PL’ is a new function that retrieves the performers list of a
speciﬁc task for a speciﬁc instance. This function takes two arguments of data-
type ”..#string”, which are a task name and an instance number. It returns a
list of all users who performed the task for this instance. Then the predeﬁned
function “any-of” will compare the given string, which is the username of the
user who requests to perform the task, with the list retrieved by the PL function.
The function “any-of” will return ‘true’ if the user was in the performers list,
and it will return ‘false’ if it was not found in the performers list. If it was a
SoD-IR then this condition will be satisﬁed and the user will be denied if he was
part of the list. Because it is a binding of duties constraint in this case, we want
the rule to deny only if the user was not found in the list (i.e. the function ‘any-
of’ returned false), and permit it if he was in the list (i.e. the function ‘any-of’
returned true). For this reason the function “not” has been added to reverse the
output of the function.

BP-XACML an Authorisation Policy Language for Business Processes
323
<PolicySet
...
PolicySetId ="IR" PolicyCombiningAlgId ="& policy -combine ;deny - overrides">
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources >
<Actions >< AnyAction
/></Actions >
</Target >
<Policy
PolicyId =" close:work:order:task
RuleCombiningAlgId ="& rule -combine;deny -overrides ""
<Target >
<Subjects >< AnySubject /></Subjects >
<Resources >
<ResourceMatch
MatchId ="& function;string -match">
<AttributeValue
DataType ="& xml;string"> close
work
order </ AttributeValue >
<ResourceAttributeDesignator
AttributeId ="& resource ;resource -id" DataType ="& xml;string "/>
</ResourceMatch >
</Resources >
<Actions >
<ActionMatch
MatchId ="& function ;string -match">
<AttributeValue
DataType ="& xml;string"> perform
</AttributeValue >
<ActionAttributeDesignator
AttributeId ="& action;action -id" DataType ="& xml;string "/>
</ActionMatch > </Actions > </Target >
<Rule
RuleId =" Must:be:who:issued:work:order" Effect =" Deny">
<Target > <Subjects >< AnySubject /></Subjects >
<Resources >< AnyResource /></ Resources > <Actions ><AnyAction /></
Actions > </Target >
<Condition
FunctionId =urn:oasis:names:tc:xacml :1.0: function :not >
<Apply
FunctionId ="urn:oasis:names:tc:xacml :3.0: function :any -of">
<SubjectAttributeDesignator
AttributeId ="& subject ;subject -id" DataType ="& xml;string "/>
<Apply
FunctionId =" http :// localhost/BPXACML /function #function ;PL">
<AttributeValue
DataType =& xml;string"> issue
work
order
</AttributeValue >
<ResourceAttributeDesignator
AttributeId =" urn: someapp :attributes :instance " DataType ="& xml;string "/>
</Apply >
</Apply > </Condition >
</Policy >
<!-- Point to the
RoleTask
policy
set
-->
<PolicySetIdReference > RoleTask :PolicSet
</ PolicySetIdReference >
</PolicySet >
Listing 5. Example IR Policy set
7
Related Literature
To the best of the authors’ knowledge, currently there is no published work that
aims to extend XACML to support business process authorisation policies. There
are several published works that extend XACML to support diﬀerent models but
none of them focus on ‘business processes’. For example, Wolter et. al. in [19]
developed a XACML customised proﬁle that supports RBAC concept, manda-
tory access control, and permission-based separation of duty policies. The work
does not take into consideration the special requirements that ‘business process’
authorisation policies need such as ‘tasks’, and it does not extend XACML to
support business process authorisation policies.
The work in [4], [10], [18], and [19] all focus on proposing a model transforma-
tion framework that focuses on deriving security policies from the process model,
using a form of extended BPMN as a process modeling language and XACML
as a policy language. These papers start by proposing a new extension to the
process modeling language BPMN, and then propose a model-driven extrac-
tion of the policies based on a mapping between the new modeling language
and the policy language. All four proposals are limited to the BPMN extension
proposed in the corresponding paper (“seBPMN”[19], “ConstrainedBPMN”[18]
“SecureBPMN”[4], and “BPMS”[10]) and they do not extend XACML. Sinha
et. al. [14] also propose a method of translating security requirements into
XACML, by making use of the obligation feature in XACML. It does not pro-
vide an extension to XACML. A draft version of the RBAC-XACML proﬁle [1]
proposed a policy structure to handle dynamic SoD. We use the same policy
structure, but implement the SoD restriction in a diﬀerent way. We also provide
more details on the way it should be used.
www.ebook3000.com

324
K. Alissa et al.
8
Conclusion
This paper introduced BP-XACML, a new proﬁle that extends the RBAC-
XACML and enables the speciﬁcation of business process authorisation policies.
In addition to supporting the XACML RBAC proﬁle, the extended language also
supports the representation of tasks and tasks instance. It proposes a new pol-
icy set called Task<PolicySet> for the incorporation of business process tasks.
BP-XACML also supports separation of duties and binding of duties constraints
at the level of process instances. It supports the representation of the instance-
level restrictions in a way that can be linked to the related tasks and can be
evaluated. The paper proposes a new policy set IR<PolicySet>. The new repos-
itory ‘performers list’ helps in evaluating the instance-level restrictions. The new
repository TPL links tasks to permissions. Finally, it supports the ‘separation
of duties’ on the role level, making use of the ‘REA’ and ‘sessions’ to ﬁnd, and
evaluate the SoD restrictions.
As a future work, it is intended to do an experimental implementation to
test the eﬃciency, feasibility and usability of this design.
References
1. Anderson, A.: Xacml proﬁle for role based access control (rbac), committee draft
01. Standard, OASIS, February 2004
2. Anderson, A.: Core and hierarchical role based access control (rbac) proﬁle of xacml
version 2.0, oasis standard. Standard, OASIS Open, February 2005
3. Atluri, V., Kuang Huang, W.: An authorization model for workﬂows. In: Bertino,
E., Kurth, H., Martella, G., Montolivo, E. (eds.) European Symposium on Research
in Computer Security. LNCS, vol. 1146, pp. 44–64. Springer, Heidelberg (1996)
4. Brucker, A.D., Hang, I., L¨uckemeyer, G., Ruparel, R.: Securebpmn: Modeling and
enforcing access control requirements in business processes. In: Proceedings of the
17th ACM Symposium on Access Control Models and Technologies, SACMAT
2012, pp. 123–126. ACM, New York (2012)
5. Ferraiolo, D., Kuhn, D.: Role-Based Access Control. In: 15th National Computer
Security Conference, pp. 554–563, October 1992
6. Gartner. Leading in times of transition: The 2010 CIO agenda. In Gartner EXP
CIO report (2010)
7. Leitner, M., Rinderle-Ma, S., Mangler, J.: Aw-rbac: access control in adaptive
workﬂow systems. In: Sixth International Conference on Availability, Reliability
and Security, ARES, pp. 27–34. IEEE (2011)
8. Liu, A.X., Chen, F., Hwang, J., Xie, T.: Xengine: A fast and scalable xacml policy
evaluation engine. In: Proceedings of the 2008 ACM SIGMETRICS International
Conference on Measurement and Modeling of Computer Systems, SIGMETRICS
2008, pp. 265–276. ACM, New York (2008)
9. Moses, T.: Extensible access control markup language (xacml) version 2.0. oasis
standard. Technical report, OASIS Open (2005)
10. M¨ulle, J., Stackelberg, S.V., B¨ohm, K.: A security language for bpmn process
models. In: Karlsruhe Reports in Informatics, Karlsruhe (2011)

BP-XACML an Authorisation Policy Language for Business Processes
325
11. Oh, S., Park, S.: Task-Role Based Access Control (T-RBAC): An Improved Access
Control Model for Enterprise Environment. In: Ibrahim, M., K¨ung, J., Revell, N.
(eds.) DEXA 2000. LNCS, vol. 1873, pp. 264–273. Springer, Heidelberg (2000)
12. Samarati, P., di Vimercati, S.C.: Access Control: Policies, Models, and Mechanisms.
In: Focardi, R., Gorrieri, R. (eds.) FOSAD 2000. LNCS, vol. 2171, pp. 137–196.
Springer, Heidelberg (2001)
13. Sandhu, R., Coyne, E., Feinstein, H., Youman, C.: Role - based access control
models. IEEE Computer 29, 38–47 (1996)
14. Sinha, S., Sinha, S.K., Purkayastha, B.S.: Synchronization of Authorization Flow
with Work Object Flow in a Document Production Workﬂow Using XACML and
BPEL. In: Das, V.V., Vijaykumar, R. (eds.) ICT 2010. CCIS, vol. 101, pp. 365–370.
Springer, Heidelberg (2010)
15. Strembeck, M., Mendling, J.: Modeling process-related rbac models with extended
uml activity models. Information & Software Technology 53, 456–483 (2011)
16. Wainer, J., Kumar, A., Barthelmess, P.: WRBAC a work-ﬂow security model incor-
porating controlled overriding of constraints. International Journal of Cooperative
Information Systems (IJCIS) 4, 455–486 (2003)
17. Wainer, J., Kumar, A., Barthelmess, P.: DW-RBAC: A formal security model of
delegation and revocation in workﬂow systems. Inf. Syst. 32(3), 365–384 (2007)
18. Wolter, C., Schaad, A., Meinel, C.: Deriving XACML Policies from Business Pro-
cess Models. In: Weske, M., Hacid, M.-S., Godart, C. (eds.) WISE Workshops 2007.
LNCS, vol. 4832, pp. 142–153. Springer, Heidelberg (2007)
19. Wolter, C., Weiss, C., Meinel, C.: An xacml extension for business process-centric
access control policies. In: IEEE International Symposium on Policies for Dis-
tributed Systems and Networks, POLICY 2009, pp. 166–169, July 2009
www.ebook3000.com

Symmetric Cryptanalysis

How TKIP Induces Biases of Internal States
of Generic RC4
Ryoma Ito(B) and Atsuko Miyaji
Japan Advanced Institute of Science and Technology,
1-1 Asahidai, Nomi-shi, Ishikawa 923-1292, Japan
ryoma.ito.shs@gmail.com,
miyaji@jaist.ac.jp
Abstract. RC4, designed by Rivest, is widely used including WPA,
which is one of the security protocols for IEEE 802.11 wireless stan-
dard. The ﬁrst 3-byte RC4 keys in WPA generated by IV are known
since IV can be obtained by observing a packet. In 2014, Sen Gupta
et al. found linear correlations between the keystream byte and known
RC4 key bytes. In 2015, Our previous work extended linear correlations
to include unknown internal states as well as the keystream byte and
known RC4 key bytes. They found more than 150 linear correlations
experimentally, and proved only 6 cases theoretically. In this paper, we
will provide theoretical proof of 15 cases out of their unproven linear
correlations. These theoretical results demonstrated how TKIP key gen-
eration procedure in WPA induces biases on internal states diﬀerent from
generic RC4.
Keywords: RC4 · WPA · TKIP · Linear correlation
1
Introduction
RC4 is the stream cipher designed by Rivest in 1987, and is widely used in
various standard protocols such as Secure Socket Layer/Transport Layer Secu-
rity (SSL/TLS), Wired Equivalent Privacy (WEP) and Wi-ﬁProtected Access
(WPA), etc. Due to its popularity and simplicity, RC4 has been intensively ana-
lyzed since its speciﬁcation was made public on the internet in 1994 [1–11]. RC4
consists of two algorithms: the Key Scheduling Algorithm (KSA) and the Pseudo
Random Generation Algorithm (PRGA). Both the KSA and the PRGA update
a secret internal state S which is a permutation of all N (typically, N = 28)
possible bytes and two 8-bit indices i and j. The KSA generates the initial state
from a secret key K of l bytes to become the input of the PRGA. Once the initial
state is generated in the KSA, the PRGA outputs a pseudo-random sequence
(keystream) Z1, Z2, . . . , Zr, where r is the number of rounds. The KSA and the
A. Miyaji—Supported by the project “The Security infrastructure Technology for
Integrated Utilization of Big Data” of Japan Science and Technology Agency
CREST.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 329–342, 2015.
DOI: 10.1007/978-3-319-19962-7 19
www.ebook3000.com

330
R. Ito and A. Miyaji
PRGA are shown in Algorithms 1 and 2, respectively, where {SK
i , i, jK
i } and
{Sr, ir, jr} are {S, i, j} in the i-th and r-th round of the KSA and the PRGA,
respectively; tr is a 8-bit index of Zr. All addition used in both the KSA and
the PRGA are arithmetic addition modulo N.
Algorithm 1. KSA
1: for i = 0 to N −1 do
2:
SK
0 [i] ←i
3: end for
4: jK
0 ←0
5: for i = 0 to N −1 do
6:
jK
i+1 ←jK
i + SK
i [i] + K[i mod l]
7:
Swap(SK
i [i], SK
i [jK
i+1])
8: end for
Algorithm 2. PRGA
1: r ←0, i0 ←0, j0 ←0
2: loop
3:
r ←r + 1, ir ←ir−1 + 1
4:
jr ←jr−1 + Sr−1[ir]
5:
Swap(Sr−1[ir], Sr−1[jr])
6:
tr ←Sr[ir] + Sr[jr]
7:
Output: Zr ←Sr[tr]
8: end loop
WPA is the security protocol for IEEE 802.11 wireless networks standardized
as a substitute for WEP in 2003, and uses RC4 for encryption. WPA improves
a 16-byte RC4 key generation procedure known as the Temporary Key Integrity
Protocol (TKIP) to prevent an attack against WEP by Fluhrer et al. [2]. One
of characteristic features in TKIP is that the ﬁrst 3-byte RC4 keys, K[0], K[1]
and K[2], are generated by the last 16-bit Initialization Vector (IV16), which is
a sequence counter as follows:
K[0] = (IV16 >> 8) & 0xFF,
K[1] = ((IV16 >> 8) | 0x20) & 0x7F,
K[2] = IV16 & 0xFF.
Note that these RC4 key bytes in WPA are known since IV can be obtained by
observing a packet.
In 2014, Sen Gupta et al. showed that there exists a characteristic distribution
related to K[0] + K[1] in WPA [3]. They also found some linear correlations
between the keystream byte and known RC4 key bytes in WPA such as Z1 =
−K[0] −K[1], Z3 = K[0] + K[1] + K[2] + 3, etc. They applied these linear
correlations to a plaintext recovery attack against WPA in the same way as
the attack against SSL/TLS by Isobe et al. [4], and reduced the computational
complexity necessary for the attack. In 2015, We extended linear correlations
to include unknown internal states as well as the keystream byte and known
RC4 key bytes [5]. Here, unknown internal states mean Sr[ir+1], Sr[jr+1], jr+1
and tr+1 for r ≥0. Then, more than 150 linear correlations have been found
experimentally, although only 6 correlations have been proved theoretically such
as: S0[i1] = K[0], K[0] −K[1] −3 or K[0] −K[1] −1; S255[i256] = K[0] or
S255[i256] = K[1]; Sr[ir+1] = K[0] + K[1] + 1 (0 ≤r ≤N).
We focus on these correlations remain unproven theoretically. [5]. Actually,
linear correlations including internal states could contribute to reducing the com-
putational complexity necessary for the state recovery attacks against RC4 pro-
posed in [1,6,9] especially with WPA. Furthermore, theoretical proofs on linear

How TKIP Induces Biases of Internal States of Generic RC4
331
correlations including internal states can make clear how TKIP induces biases as
pointed out above. In the previous results, biases related to the ﬁrst round inter-
nal state S0[i1] were intensively investigated but other internal states in more
than second round are still unknown. If we see how many round these biases have
been kept in internal states, then key generation procedure in WPA could be
reconstructed securely while keeping congruity with TKIP. In fact, TKIP should
have been constructed in such a way that it can keep or further enhance original
security level of generic RC4. Our analysis would be also useful to investigate
a generic construction of key generation procedure including IV in such a way
that it can keep or further enhance security level of an original encryption.
In this paper, we will provide theoretical proofs of 15 cases out of remain-
ing linear correlations. Our contributions of 10 theorems can be summarized as
follows:
– Theorems 1, 4 and 5 show that Pr(S0[i1] = −K[0] −K[1] −3), Pr(S1[i2] =
−K[0] −K[1] + K[2] −1) and Pr(S1[i2] = K[0] −K[1] + K[2] + x) (x ∈
{−3, −1, 1}) are double probabilities of random association
1
N in WPA.
– Theorem 2 shows that Pr(S0[i1] = K[0] + K[1] + K[2] + 3) is less than half
of the probability of random association
1
N in both generic RC4 and WPA.
– Theorem 3 shows that Pr(S1[i2] = K[0] + K[1] + K[2] + 3) is pretty high
probability in comparison to the probability of random association 1
N in both
generic RC4 and WPA. This probability is induced by Roos’ bias, that is
Pr(S0[i2] = K[0] + K[1] + K[2] + 3) ≈

1 −2
N

·

1 −1
N
N+3 + 1
N .
– Theorems 6-10 provide theoretical analysis related to the second round index
j2.
This paper is organized as follows: Section 2 summarizes the previous works
necessary for both theoretical proofs and experiments such as Roos’ biases [10,
11], biases of the initial state of the PRGA in generic RC4 [7], the distribution of
K[0]+K[1] and the initial state of PRGA in WPA [3] and the number of samples
necessary for distinguishing two distributions [8]. Section 3 shows the theoretical
proofs of biases based on linear equations and the experimental results. Section 4
concludes this paper.
2
Preliminary for Our Proofs and Experiments
Let us summarize some previous results which will be used in both theoreti-
cal proofs and experiments. Proposition 1 shows Roos’ biases [11], correlations
between the RC4 key bytes and S0, proved by Paul and Maitra [10]. Proposition 2
shows biases of S0, proved by Mantin [7]. Proposition 3 shows a distribution of
K[0] + K[1] in WPA, proved by Sen Gupta et al. [3]. By combining Proposi-
tion 3 with Proposition 1 (Roos’ biases), a characteristic bias on the distribu-
tion of S0[1] is given as Proposition 4 [3]. Finally, Mantin and Shamir showed
Proposition 5 related to the number of samples necessary for distinguishing two
distributions with a constant probability of success [8].
www.ebook3000.com

332
R. Ito and A. Miyaji
Proposition 1 ([10, Corollary 2]). In the initial state of the PRGA for 0 ≤
y ≤N −1, we have
Pr(S0[y] = y(y+1)
2
+ y
x=0 K[x]) ≈

1 −y
N

·

1 −1
N
[ y(y+1)
2
+N] + 1
N .
Proposition 2 ([7, Theorem 6.2.1]). In the initial state of the PRGA for
0 ≤u ≤N −1, 0 ≤v ≤N −1, we have
Pr(S0[u] = v) =

1
N

1 −1
N
v +

1 −

1 −1
N
v
1 −1
N
N−u−1
if v ≤u,
1
N

1 −1
N
N−u−1 +

1 −1
N
v
if v > u.
Proposition 3 ([3, Theorem 1]). For 0 ≤v ≤N −1, the distribution of the
sum v of K[0] and K[1] generated by the temporal key hash function in WPA is
given as follows:
Pr(K[0] + K[1] = v) = 0
if v is odd,
Pr(K[0] + K[1] = v) = 0
if v is even and v ∈[0, 31] ∪[128, 159],
Pr(K[0] + K[1] = v) = 2/256
if v is even and
v ∈[32, 63] ∪[96, 127] ∪[160, 191] ∪[224, 255],
Pr(K[0] + K[1] = v) = 4/256
if v is even and v ∈[64, 95] ∪[192, 223].
Proposition 4 ([3, Theorem 2]). In the initial state of the PRGA in WPA
for 0 ≤v ≤N −1, we have
Pr(S0[1] = v) = α · Pr(K[0] + K[1] = v −1)
+ (1 −α) · (1 −Pr(K[0] + K[1] = v −1)) · Pr(S0[1] = v)RC4
+ (1−α)
N−1 · 
x̸=v Pr(K[0] + K[1] = x −1) · Pr(S0[1] = x)RC4.
where, α =
1
N +

1 −1
N
N+2, and both Pr(S0[1] = v)RC4 and Pr(S0[1] = x)RC4
are taken from Proposition 2.
Proposition 5 ([8, Theorem 2]). Let X and Y be two distributions, and
suppose that the event e occurs in X with a probability p and Y with a probability
p·(1+q). Then, for small p and q, O(
1
p·q2 ) samples suﬃce to distinguish X from
Y with a constant probability of success.
3
Newly Proved Linear Correlations
3.1
Biases Based on Linear Equations
In 2014, Sen Gupta et al. found some linear correlations between the keystream
byte and known RC4 key bytes in WPA using the following linear equations for
a, b, c ∈{0, ±1} and d ∈{0, ±1, ±2, ±3}:
Zr = a · K[0] + b · K[1] + c · K[2] + d for r ≥1 [3].
(1)

How TKIP Induces Biases of Internal States of Generic RC4
333
In 2015, we further extended linear correlations on known RC4 key bytes in both
generic RC4 and WPA to those among unknown state information, known RC4
key bytes and the keystream byte such as
Xr = a · Zr+1 + b · K[0] + c · K[1] + d · K[2] + e for r ≥1,
(2)
where Xr
∈
{Sr[ir+1], Sr[jr+1], jr+1, tr+1}, a, b, c, d
∈
{0, ±1}, and e
∈
{0, ±1, ±2, ±3} [5]. Then, 6 correlations out of more than 150 linear correla-
tions have been shown theoretically as follows:
S0[i1] = K[0], K[0] −K[1] −3 or K[0] −K[1] −1;
S255[i256] = K[0] or K[1];
Sr[ir+1] = K[0] + K[1] + 1 for 0 ≤r ≤N.
In this paper, we will provide newly theoretical proofs of 15 linear correlations
listed in Table 1. Actually, the ﬁrst state recovery attack proposed by Knudsen
et al. reconstructs the internal state of RC4 by computing optimum solutions of
four unknown variables in each round such as Sr[ir+1], Sr[jr+1], jr+1 and tr+1
for r ≥0 [6]. Therefore, these linear correlations could contribute to ﬁnding a
correct internal state of RC4 in WPA.
We often use Roos’ biases shown in Proposition 1 through proofs. Roos’ biases
are denoted by αy = Pr(S0[y] = y(y+1)
2
+y
x=0 K[x]). We assume through proofs
that the probability of certain events, conﬁrmed experimentally that there are
no signiﬁcant biases, is that of random association
1
N (e.g. events related to the
internal state). We also assume that the RC4 key K is generated uniformly at
random in both generic RC4 and WPA, except K[0], K[1] and K[2] in WPA
generated by IV using a sequence counter.
Table 1. Newly proved linear correlations in both generic RC4 and WPA
Xr
Linear correlations
RC4
WPA
Remarks
−K[0] −K[1] −3
0.005336 0.008437 Theorem 1
S0[i1] K[0] + K[1] + K[2] + 3
0.001492 0.001491 Theorem 2
K[0] + K[1] + K[2] + 3
0.360357 0.361718 Theorem 3
−K[0] −K[1] + K[2] −1 0.005305 0.008197 Theorem 4
K[0] −K[1] + K[2] −3
0.005295 0.008163 Theorem 5
K[0] −K[1] + K[2] −1
0.005290 0.008171 Theorem 5
S1[i2]
K[0] −K[1] + K[2] + 1
0.005309 0.008171 Theorem 5
K[2]
0.004428 0.005571 Theorem 6
−K[0] −K[1] + K[2] −2 0.003921 0.004574 Theorem 7
−K[0] −K[1] + K[2]
0.003919 0.005573 Theorem 7
−K[0] −K[1] + K[2] + 2 0.003912 0.004545 Theorem 7
−K[0] + K[1] + K[2]
0.003921 0.005501 Theorem 8
−K[1] + K[2] −2
0.003911 0.005479 Theorem 9
−K[1] + K[2] + 3
0.003899 0.005476 Theorem 9
j2
K[0] −K[1] + K[2]
0.003918 0.005618 Theorem 10
www.ebook3000.com

334
R. Ito and A. Miyaji
3.2
Proof of Biases in S0[i1]
In this section, we prove Theorems 1 and 2 theoretically. Theorem 1 shows that
event (S0[i1] = −K[0]−K[1]−3) yields a positive bias in both generic RC4 and
WPA. We note that Theorem 1 means the ﬁrst round internal state S0[i1] can
be guessed in a double probability of random association 1
N by using known K[0]
and K[1] in WPA. Theorem 2 shows that event (S0[i1] = K[0]+K[1]+K[2]+3)
yields a negative bias in both generic RC4 and WPA.
Theorem 1. In the initial state of the PRGA, we have
Pr(S0[i1] = −K[0] −K[1] −3) ≈

2
N α1 + 1
N

1 −2
N

(1 −α1)
for RC4,
4
N α1 + 1
N

1 −4
N

(1 −α1)
for WPA.
Proof. The probability of event (S0[i1] = −K[0]−K[1]−3) can be decomposed in
two paths: K[0]+K[1] = 126, 254 (Path 1) and K[0]+K[1] ̸= 126, 254 (Path 2).
These paths include all events in order to compute Pr(S0[i1] = −K[0]−K[1]−3).
In the following proof, we use S0[1] instead of S0[i1] (i1 = 1) for simplicity.
Path 1. In K[0] + K[1] = 126, 254, event (S0[1] = −K[0] −K[1] −3) occurs if
and only if S0[1] = K[0] + K[1] + 1. Therefore, we get
Pr(S0[1] = −K[0] −K[1] −3 | Path 1) = α1.
Path 2. In K[0] + K[1] ̸= 126, 254, event (S0[1] = −K[0] −K[1] −3) never
occurs if S0[1] = K[0] + K[1] + 1. If S0[1] ̸= K[0] + K[1] + 1 holds, then we
assume that event (S0[1] = −K[0] −K[1] −3) occurs with the probability of
random association
1
N . Therefore, we get
Pr(S0[1] = −K[0] −K[1] −3 | Path 2) = 1
N · (1 −α1).
The probability of K[0]+K[1] = 126 and 254 in WPA is 2
N , twice as high as that
of random association, although that in generic RC4 is
1
N since K is generated
uniformly at random. By substituting each Pr(K[0] + K[1] = 126, 254) in both
generic RC4 and WPA, we get
Pr(S0[i1] = K[0] −K[1] −3)
= Pr(S0[1] = K[0] −K[1] −3 | Path 1) · Pr(Path 1)
+ Pr(S0[1] = K[0] −K[1] −3 | Path 2) · Pr(Path 2)
≈

2
N α1 + 1
N

1 −2
N

(1 −α1)
for RC4,
4
N α1 + 1
N

1 −4
N

(1 −α1)
for WPA.
⊓⊔
Theorem 2. In the initial state of the PRGA, we have
Pr(S0[i1]=K[0]+K[1]+K[2]+3) ≈1
N

1 −2
N

1 −1
N
N−2+
1
N2

3 −2
N

.

How TKIP Induces Biases of Internal States of Generic RC4
335
Proof. Since both SK
1 [1] = 1 and SK
2 [2] = 2 hold with high probability from
Algorithm 1, we get
jK
1 = K[0],
(3)
jK
2 = K[0] + K[1] + SK
1 [1] = K[0] + K[1] + 1,
(4)
jK
3 = K[0] + K[1] + K[2] + SK
1 [1] + SK
2 [2] = K[0] + K[1] + K[2] + 3. (5)
In this case, SK
3 [2] = K[0]+K[1]+K[2]+3 always holds from step 7 in Algorithm
1, and thus, event (S0[i1] = K[0]+K[1]+K[2]+3) never occurs because SK
r [i1] ̸=
K[0] + K[1] + K[2] + 3 always holds for r ≥3. Then, the probability of event
(S0[i1] = K[0] + K[1] + K[2] + 3) can be decomposed in two paths: jK
1 = 1, 2
(Path 1) and jK
1 ̸= 1, 2 (Path 2). Path 2 is further divided into three subpaths:
jK
2 = 2 (Path 2-1), jK
2 ̸= 2 ∧K[2] = 254 (Path 2-2) and jK
2 ̸= 2 ∧K[2] ̸= 254
(Path 2-3). These paths include all events in order to compute Pr(S0[i1] =
K[0] + K[1] + K[2] + 3). In the following proof, we use S0[1] instead of S0[i1]
(i1 = 1) for simplicity.
Path 1. If jK
1 = 1, then SK
1 [1] ̸= 1 from step 7 in Algorithm 1. Thus, SK
3 [2] ̸=
K[0] + K[1] + K[2] + 3 always holds since jK
3 ̸= K[0] + K[1] + K[2] + 3 from
Eq. (5). Similarly, if jK
1 = 2, then SK
3 [2] ̸= K[0] + K[1] + K[2] + 3 always
holds. Then, we assume that event (S0[1] = K[0] + K[1] + K[2] + 3) occurs
with the probability of random association
1
N . Therefore, we get
Pr(S0[1] = K[0] + K[1] + K[2] + 3 | Path 1) ≈1
N .
Path 2-1. As with the discussion in Path 1, if jK
2
= 2, then SK
3 [2] ̸= K[0] +
K[1] + K[2] + 3 always holds. We then assume that event (S0[1] = K[0] +
K[1] + K[2] + 3) with the probability of random association
1
N . Therefore,
we get
Pr(S0[1] = K[0] + K[1] + K[2] + 3 | Path 2-1) ≈1
N .
Path 2-2. Except the cases in Paths 1 and 2-1, Eqs. (3)-(5) always hold since
we get both SK
1 [1] = 1 and SK
2 [2] = 2. Here, if K[2] = 254, then jK
2
=
jK
3 = K[0] + K[1] + K[2] + 3 holds since K[2] + 3 = 1. Thus, we get both
SK
3 [1] = K[0] + K[1] + K[2] + 3 and SK
3 [2] = 1 from step 7 in Algorithm
1. After the third round of KSA, SK
r [1] = SK
3 [1] for 4 ≤r ≤N if jK
r
̸= 1
during the subsequent N −3 rounds, whose probability is approximately

1 −
1
N
N−3 since we assume that jK
r
= 1 holds with the probability of
random association
1
N . Therefore, we get
Pr(S0[1] = K[0] + K[1] + K[2] + 3 | Path 2-2) ≈

1 −1
N
N−3.
Path 2-3. As with the discussion in Path 2-2, Eqs. (3)-(5) always hold, and
jK
2
̸= jK
3
since K[2] ̸= 254 from the assumption in Path 2-3. Thus, event
(S0[i1] = K[0] + K[1] + K[2] + 3) never occurs since SK
3 [2] = K[0] + K[1] +
K[2] + 3 always holds. Therefore, we get
Pr(S0[1] = K[0] + K[1] + K[2] + 3 | Path 2-3) = 0.
www.ebook3000.com

336
R. Ito and A. Miyaji
In summary, event (S0[i1] = K[0] + K[1] + K[2] + 3) occurs only in Paths 1, 2-1
and 2-2. Therefore, we get
Pr(S0[1] = K[0] + K[1] + K[2] + 3)
= Pr(S0[1] = K[0] + K[1] + K[2] + 3 | Path 1) · Pr(Path 1)
+ Pr(S0[1] = K[0] + K[1] + K[2] + 3 | Path 2-1) · Pr(Path 2-1)
+ Pr(S0[1] = K[0] + K[1] + K[2] + 3 | Path 2-2) · Pr(Path 2-2)
≈1
N · 2
N + 1
N · 1
N

1 −2
N

+

1 −1
N
N−3 · 1
N

1 −1
N

1 −2
N

= 1
N

1 −2
N

1 −1
N
N−2+
1
N2

3 −2
N

,
where we assume that 4 events, (jK
1 = 1), (jK
1 = 2), (jK
2 = 2) and (K[2] = 254),
occur with the probability of random association
1
N , respectively.
⊓⊔
3.3
Proof of Biases in S1[i2]
In this section, we prove Theorems 3-5 theoretically. Theorem 3 shows that event
(S1[i2] = K[0] + K[1] + K[2] + 3) occurs with pretty high probability in both
generic RC4 and WPA. This high probability is induced by Roos’ bias, that is
α2 = Pr(S0[2] = K[0] + K[1] + K[2] + 3). Theorems 4 and 5 show that 4 events
related to S1[i2] yield a positive bias in both generic RC4 and WPA. We note
that Theorems 3-5 mean the second round internal state of S1[i2] can be guessed
in pretty high probability or double probabilities of random association
1
N by
using known K[0], K[1] and K[2] in WPA. Here, we show only the proofs of
Theorems 3 and 4. Theorem 5 is proved in the same way as Theorem 4. In order
to prove the following theorems, let us denote the results of Theorems 2 and 3 as
β = Pr(S0[1] = K[0]+K[1]+K[2]+3) and γ = Pr(S1[2] = K[0]+K[1]+K[2]+3),
respectively.
Theorem 3. After the ﬁrst round of the PRGA, we have
Pr(S1[i2]=K[0]+K[1]+K[2]+3) ≈β·Pr(S0[1]=2) + α2·

1 −Pr(S0[1]=2)

.
Proof. The probability of event (S1[i2] = K[0] + K[1] + K[2] + 3) can be decom-
posed in two paths: j1 = 2 (Path 1) and j1 ̸= 2 (Path 2). These paths include
all events in order to compute Pr(S1[i2] = K[0] + K[1] + K[2] + 3). Note that
j1 = S0[1] from step 4 in Alforithm 2. In the following proof, we use S1[2] instead
of S1[i2] (i2 = 2) for simplicity.
Path 1. In j1 = 2, event (S1[2] = K[0] + K[1] + K[2] + 3) occurs if and only
if S0[1] = K[0] + K[1] + K[2] + 3 from step 5 in Algorithm 2. We assume
that both events (j1 = 2) and (S0[1] = K[0] + K[1] + K[2] + 3) are mutually
independent. Therefore, we get
Pr(S1[2] = K[0] + K[1] + K[2] + 3 | Path 1) = β.

How TKIP Induces Biases of Internal States of Generic RC4
337
Path 2. In j1 ̸= 2, event (S1[2] = K[0] + K[1] + K[2] + 3) occurs if and only
if S0[2] = K[0] + K[1] + K[2] + 3 from step 5 in Algorithm 2. We assume
that both events (j1 ̸= 2) and (S0[2] = K[0] + K[1] + K[2] + 3) are mutually
independent. Therefore, we get
Pr(S1[2] = K[0] + K[1] + K[2] + 3 | Path 2) = α2.
In summary, we get
Pr(S1[i2] = K[0] + K[1] + K[2] + 3)
= Pr(S1[2] = K[0] + K[1] + K[2] + 3 | Path 1) · Pr(Path 1)
+ Pr(S1[2] = K[0] + K[1] + K[2] + 3 | Path 2) · Pr(Path 2)
≈β · Pr(S0[1] = 2) + α2 ·

1 −Pr(S0[1] = 2)

,
where the probability of event (S0[1] = 2) is taken from Propositions 2 and 4 in
generic RC4 and WPA, respectively.
⊓⊔
Theorem 4. After the ﬁrst round of the PRGA, we have
Pr(S1[i2] = −K[0] −K[1] + K[2] −1) ≈

2
N γ + 1
N

1 −2
N

(1 −γ)
for RC4,
4
N γ + 1
N

1 −4
N

(1 −γ)
for WPA.
Proof. The probability of event (S1[i2] = −K[0] −K[1] + K[2] −1) can be
decomposed in two paths: K[0] + K[1] = 126, 254 (Path 1) and K[0] + K[1] ̸=
126, 254 (Path 2). These paths include all events in order to compute Pr(S1[i2] =
−K[0] −K[1] + K[2] −1). In the following proof, we use S1[2] instead of S1[i2]
(i2 = 2) for simplicity.
Path 1. In K[0] + K[1] = 126, 254, event (S1[2] = −K[0] −K[1] + K[2] −1)
occurs if and only if S1[2] = K[0] + K[1] + K[2] + 3. Therefore, we get
Pr(S1[2] = −K[0] −K[1] + K[2] −1 | Path 1) = γ.
Path 2. In K[0] + K[1] ̸= 126, 254, event (S1[2] = −K[0] −K[1] + K[2] −1)
never occurs if S1[2] = K[0]+K[1]+K[2]+3. If S1[2] ̸= K[0]+K[1]+K[2]+3
holds, then we assume that event (S1[2] = −K[0] −K[1] + K[2] −1) occurs
with the probability of random association
1
N . Therefore, we get
Pr(S1[2] = −K[0] −K[1] + K[2] −1 | Path 2) = 1
N · (1 −γ).
The probability of K[0]+K[1] = 126 and 254 in WPA is 2
N , twice as high as that
of random association, although that in generic RC4 is
1
N since K is generated
uniformly at random. By substituting each Pr(K[0] + K[1] = 126, 254) in both
generic RC4 and WPA, we get
Pr(S1[i2] = −K[0] −K[1] + K[2] −1)
= Pr(S1[2] = −K[0] −K[1] + K[2] −1 | Path 1) · Pr(Path 1)
+ Pr(S1[2] = −K[0] −K[1] + K[2] −1 | Path 2) · Pr(Path 2)
≈

2
N γ + 1
N

1 −2
N

(1 −γ)
for RC4,
4
N γ + 1
N

1 −4
N

(1 −γ)
for WPA.
⊓⊔
www.ebook3000.com

338
R. Ito and A. Miyaji
Theorem 5. After the ﬁrst round of the PRGA for x ∈{−3, −1, 1}, we have
Pr(S1[i2] = K[0] −K[1] + K[2] + x) ≈

2
N γ + 1
N

1 −2
N

(1 −γ)
for RC4,
4
N γ + 1
N

1 −4
N

(1 −γ)
for WPA.
3.4
Proof of Biases in j2
In this section, we prove Theorems 6-10 theoretically. Theorem 6 shows that
event (j2 = K[2]) yields a positive bias in both generic RC4 and WPA. On the
other hand, Theorems 7-10 show that 7 events related to j2 yield positive biases
in WPA but those are not biases in generic RC4. Here, we show only the proof
of Theorem 6. Theorems 7-10 are proved in the same way as Theorem 6. In
order to prove the following theorems, let us denote the result of Theorem 3 as
γ = Pr(S1[2] = K[0] + K[1] + K[2] + 3).
Theorem 6. After the second round of the PRGA, we have
Pr(j2 = K[2]) ≈

2
N α1γ + 1
N

1 −2
N

(1 −α1γ)
for RC4,
4
N α1γ + 1
N

1 −4
N

(1 −α1γ)
for WPA.
Proof. The probability of event (j2 = K[2]) can be decomposed in two paths:
K[0]+K[1] = 126, 254 (Path 1) and K[0]+K[1] ̸= 126, 254 (Path 2). These paths
include all events in order to compute Pr(j2 = K[2]). Note that j2 = S0[1]+S1[2]
from step 4 in Algorithm 2.
Path 1. If two events (S0[1] = K[0] + K[1] + 1) and (S1[2] = K[0] + K[1] +
K[2] + 3) occur simultaneously, we get
j2 = S0[1] + S1[2] = (K[0] + K[1] + 1) + (K[0] + K[1] + K[2] + 3)
= 2K[0] + 2K[1] + K[2] + 4.
Then, in K[0] + K[1] = 126, 254, event (j2 = K[2]) occurs if and only if
j2 = 2K[0] + 2K[1] + K[2] + 4, that is both S0[1] = K[0] + K[1] + 1 and
S1[2] = K[0] + K[1] + K[2] + 3 hold simultaneously. We assume that both
events (S0[1] = K[0] + K[1] + 1) and (S1[2] = K[0] + K[1] + K[2] + 3) are
mutually independent. Therefore, we get
Pr(j2 = K[2] | path 1) = α1γ.
Path 2. In K[0] + K[1] ̸= 126, 254 event (j2 = K[2]) never occurs if and only
if j2 = 2K[0] + 2K[1] + K[2] + 4. If either S0[1] ̸= K[0] + K[1] + 1 or
S1[2] ̸= K[0] + K[1] + K[2] + 3 hold, then we assume that event (j2 = K[2])
occurs with the probability of random association
1
N . Therefore, we get
Pr(j2 = K[2] | Path 2) = 1
N · (1 −α1γ).

How TKIP Induces Biases of Internal States of Generic RC4
339
The probability of K[0]+K[1] = 126 and 254 in WPA is 2
N , twice as high as that
of random association, although that in generic RC4 is
1
N since K is generated
uniformly at random. By substituting each Pr(K[0] + K[1] = 126, 254) in both
generic RC4 and WPA, we get
Pr(j2 = K[2]) = Pr(j2 = K[2] | Path 1) · Pr(Path 1)
+ Pr(j2 = K[2] | Path 2) · Pr(Path 2)
≈

2
N α1γ + 1
N

1 −2
N

(1 −α1γ)
for RC4,
4
N α1γ + 1
N

1 −4
N

(1 −α1γ)
for WPA.
⊓⊔
Theorem 7. After the second round of the PRGA for x ∈{−2, 0, 2}, we have
Pr(j2 = −K[0] −K[1] + K[2] + x)
≈
⎧
⎪
⎨
⎪
⎩
1
N α1γ + 1
N

1 −1
N

(1 −α1γ)
for RC4,
2
N α1γ + 1
N

1 −2
N

(1 −α1γ)
if x = −2, 2 for WPA,
4
N α1γ + 1
N

1 −4
N

(1 −α1γ)
if x = 0 for WPA.
Theorem 8. After the second round of the PRGA, we have
Pr(j2 = −K[0] + K[1] + K[2]) ≈

1
N α1γ + 1
N

1 −1
N

(1 −α1γ)
for RC4,
4
N α1γ + 1
N

1 −4
N

(1 −α1γ)
for WPA.
Theorem 9. After the second round of the PRGA for x ∈{−2, 3}, we have
Pr(j2 = −K[1] + K[2] + x) ≈

1
N α1γ + 1
N

1 −1
N

(1 −α1γ)
for RC4,
4
N α1γ + 1
N

1 −4
N

(1 −α1γ)
for WPA.
Theorem 10. After the second round of the PRGA, we have
Pr(j2 = K[0] −K[1] + K[2]) ≈

1
N α1γ + 1
N

1 −1
N

(1 −α1γ)
for RC4,
4
N α1γ + 1
N

1 −4
N

(1 −α1γ)
for WPA.
3.5
Experimental Results
We have conducted experiments on Theorems 1-10 in the following environment
in order to conﬁrm the accuracy of theorems: Intel(R) Core(TM) i3-3220M CPU
with 3.30 GHz, 3.8 GiB memory, gcc 4.8.2 compiler and C language. The number
of samples necessary for our experiments is at least O(N 3) according to Propo-
sition 5. This is why each correlation has a relative bias with the probability of
at least O( 1
N ). Then, we have used N 5 randomly generated RC4 keys in both
generic RC4 and WPA. The number of these samples satisﬁes a condition to
distinguish each correlation from random distribution with constant probability
of success. We also evaluate the percentage of relative error ϵ of experimental
values compared with theoretical values in the same way as [5]:
www.ebook3000.com

340
R. Ito and A. Miyaji
ϵ = |experimental value −theoretical value|
experimental value
× 100(%).
Tables 2 and 3 show experimental and theoretical values and percentage of rel-
ative error ϵ in both generic RC4 and WPA.
We see that ϵ is small enough in each case in generic RC4 such as ϵ ≤
0.730 (%). From this results, we have convinced that theoretical values closely
reﬂects the experimental values in generic RC4.
Table 2. Comparison between experimental and theoretical results for generic RC4
Linear correlation
Experimental value Theoretical value ϵ (%)
−K[0] −K[1] −3
0.005333309
0.005325263
0.151
S0[i1] K[0] + K[1] + K[2] + 3
0.001490745
0.001479853
0.730
K[0] + K[1] + K[2] + 3
0.360360690
0.362016405
0.459
−K[0] −K[1] + K[2] −1
0.005305673
0.005302926
0.052
K[0] −K[1] + K[2] −3
0.005295155
0.005302926
0.147
K[0] −K[1] + K[2] −1
0.005289180
0.005302926
0.260
S1[i2]
K[0] −K[1] + K[2] + 1
0.005309594
0.005302926
0.126
K[2]
0.004430372
0.004401230
0.658
−K[0] −K[1] + K[2] −2
0.003920799
0.003893028
0.708
−K[0] −K[1] + K[2]
0.003919381
0.003893028
0.672
−K[0] −K[1] + K[2] + 2
0.003910929
0.003893028
0.458
−K[0] + K[1] + K[2]
0.003920399
0.003893028
0.698
−K[1] + K[2] −2
0.003910053
0.003893028
0.435
−K[1] + K[2] + 3
0.003897939
0.003893028
0.126
j2
K[0] −K[1] + K[2]
0.003917895
0.003893028
0.635
Table 3. Comparison between experimental and theoretical results for WPA
Linear correlation
Experimental value Theoretical value ϵ (%)
−K[0] −K[1] −3
0.008408305
0.008182569
2.685
S0[i1] K[0] + K[1] + K[2] + 3
0.001491090
0.001479853
0.754
K[0] + K[1] + K[2] + 3
0.361751935
0.362723221
0.268
−K[0] −K[1] + K[2] −1
0.008174625
0.008115732
0.720
K[0] −K[1] + K[2] −3
0.008140906
0.008115732
0.309
K[0] −K[1] + K[2] −1
0.008147205
0.008115732
0.386
S1[i2]
K[0] −K[1] + K[2] + 1
0.008150390
0.008115732
0.425
K[2]
0.005560613
0.005417633
2.571
−K[0] −K[1] + K[2] −2
0.004573276
0.004401230
3.762
−K[0] −K[1] + K[2]
0.005562336
0.005417633
2.601
−K[0] −K[1] + K[2] + 2
0.004543826
0.004401230
3.138
−K[0] + K[1] + K[2]
0.005490766
0.005417633
1.332
−K[1] + K[2] −2
0.005468425
0.005417633
0.929
−K[1] + K[2] + 3
0.005468472
0.005417633
0.930
j2
K[0] −K[1] + K[2]
0.005607004
0.005417633
3.377

How TKIP Induces Biases of Internal States of Generic RC4
341
We also see that theoretical biases in S0[i1] and j2 in WPA produce slightly
large ϵ such as 3.762 (%) but those in S1[i2] in WPA is quite small in the same
way as generic RC4. Let us investigate why such diﬀerences on the percentage of
relative error are produced between generic RC4 and WPA. Actually, diﬀerence
between generic RC4 and WPA exist only in a relation between K[0] and K[1].
Therefore, these diﬀerence inﬂuence theoretical biases in the early round, but
seem to attenuate in the second or more round as we see in results to S0[i1] and
S1[i2].
4
Conclusion
In this paper, we have focused on linear correlations including unknown internal
states as well as the keystream byte and known RC4 key bytes in both generic
RC4 and WPA, and provided newly theoretical proofs of 15 linear correlations
related to S0[i1], S1[i2] and j2. For example, event (S1[i2] = K[0]+K[1]+K[2]+3)
yields a pretty high probability in both generic RC4 and WPA, inﬂuenced
directly by Roos’ bias; and the probability of 5 linear correlations such as
Pr(S0[i1] = −K[0] −K[1] −3), Pr(S1[i2] = −K[0] −K[1] + K[2] −1) and
Pr(S1[i2] = K[0] −K[1] + K[2] + x) for x ∈{−3, −1, 1} is a double probability
of random association
1
N in WPA.
Our theoretical analysis are expected to contribute from the following two
viewpoints. One is to contribute to reducing the computational complexity nec-
essary for the state recovery attacks against RC4 proposed in [1,6,9] especially
with WPA since our linear correlations includes internal states. The other is to
contribute to construct a key generation procedure with IV in such a way that
it keeps or further enhance the security level of its original symmetric cipher.
In our analysis, we have seen how TKIP downgrades security level of generic
RC4 theoretically. These discussions could be generalized to reconstruct a key
generation procedure with IV.
References
1. Das, A., Maitra, S., Paul, G., Sarkar, S.: Some Combinatorial Results towards
State Recovery Attack on RC4. In: Jajodia, S., Mazumdar, C. (eds.) ICISS 2011.
LNCS, vol. 7093, pp. 204–214. Springer, Heidelberg (2011)
2. Fluhrer, S.R., Mantin, I., Shamir, A.: Weaknesses in the Key Scheduling Algo-
rithm of RC4. In: Vaudenay, S., Youssef, A.M. (eds.) SAC 2001. LNCS, vol. 2259,
pp. 1–24. Springer, Heidelberg (2001)
3. Sen Gupta, S., Maitra, S., Meier, W., Paul, G., Sarkar, S.: Dependence in IV-
Related Bytes of RC4 Key Enhances Vulnerabilities in WPA. In: Cid, C., Rech-
berger, C. (eds.) FSE 2014. LNCS, vol. 8540, pp. 350–369. Springer, Heidelberg
(2015)
4. Isobe, T., Ohigashi, T., Watanabe, Y., Morii, M.: Full Plaintext Recovery Attack
on Broadcast RC4. In: Moriai, S. (ed.) FSE 2013. LNCS, vol. 8424, pp. 179–202.
Springer, Heidelberg (2014)
www.ebook3000.com

342
R. Ito and A. Miyaji
5. Ito, R., Miyaji, A.: New Linear Correlations related to State Information of RC4
PRGA using IV in WPA. In: Fast Software Encryption, FSE 2015 (to appear,
2015)
6. Knudsen, L.R., Meier, W., Preneel, B., Rijmen, V., Verdoolaege, S.: Analysis Meth-
ods for (Alleged) RC4. In: Ohta, K., Pei, D. (eds.) ASIACRYPT 1998. LNCS, vol.
1514, pp. 327–341. Springer, Heidelberg (1998)
7. Mantin, I.: Analysis of the Stream Cipher RC4. Master’s thesis, The Weizmann
Institute of Science, Israel (2001). http://www.wisdom.weizmann.ac.il/itsik/RC4/
rc4.html
8. Mantin, I., Shamir, A.: Practical Attack on Broadcast RC4. In: Matsui, M. (ed.)
Fast Software Encryption - FSE 2001. LNCS, vol. 2355, pp. 152–164. Springer,
Berlin Heidelberg (2002)
9. Maximov, A., Khovratovich, D.: New State Recovery Attack on RC4. In: Wagner,
D. (ed.) CRYPTO 2008. LNCS, vol. 5157, pp. 297–316. Springer, Heidelberg (2008)
10. Paul, G., Maitra, S.: Permutation After RC4 Key Scheduling Reveals the Secret
Key. In: Adams, C., Miri, A., Wiener, M. (eds.) SAC 2007. LNCS, vol. 4876,
pp. 360–377. Springer, Heidelberg (2007)
11. Roos, A.: A class of weak keys in the RC4 stream cipher. Posts in sci.crypt. http://
marcel.wanda.ch/Archive/WeakKeys (1995)

Preventing Fault Attacks Using Fault
Randomization with a Case Study on AES
Shamit Ghosh(B), Dhiman Saha, Abhrajit Sengupta,
and Dipanwita Roy Chowdhury
Indian Institute of Technology, Kharagpur, India
{raaz714,saha.dhiman,abhrajit.sengupta}@gmail.com,
drc@cse.iitkgp.ernet.in
Abstract. Infective countermeasures have been shown to be the most
eﬃcient way to prevent fault attacks which are one of the most eﬀective
side-channel attacks on symmetric key ciphers. However, none of the
countermeasures have been found to last in terms of security. Battistello
et al. [1] has broken the last two surviving infective methods against
fault attacks on AES and emphasized on the need of a better security
framework for fault attack countermeasures. The current work is the
ﬁrst such step towards achieving the design of a secure infective counter-
measure as suggested by [1]. We develop a theoretical framework based
on fault randomization to formalize the infective approach used in fault
attack countermeasures. On the basis of this formalization, a new infec-
tive countermeasure is proposed which employs a randomized non-linear
mixing coupled with a linear diﬀusion function. A case study on AES
with a practical construction of the countermeasure is presented. The
full design is implemented on Xilinx SPARTAN-3 FPGA platform and
compared favorably with a related scheme in literature.
Keywords: Infective countermeasure · AES · Diﬀerential fault attack ·
Fault attack countermeasure · Randomized mixing
1
Introduction
Since their inception in 1996 by Boneh et. al [2], Fault Attacks (FA) have gained
considerable attention of the research community. This popularity is primarily
attributed to the power that these attacks put at the hands of an attacker. The
feasibility of fault injection techniques further make these attacks very practi-
cal. Consequently, preventing such attacks is a very challenging area of research.
The primary idea behind the attack is to intentionally inject a fault in an inter-
mediate state of the algorithm and then study the resulting faulty outputs for
possible exploits. One of the most popular targets of fault attacks has been the
Advanced Encryption Standard (AES) [3]. Diﬀerential Fault Analysis (DFA) was
introduced by Biham et. al. [4] on the Data Encryption Standard (DES) and
later mounted on AES by Giraud [5]. Among other improved DFA on AES are
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 343–355, 2015.
DOI: 10.1007/978-3-319-19962-7 20
www.ebook3000.com

344
S. Ghosh et al.
[6–8]. In the light of highly sophisticated and realistic fault attacks, it becomes
imperative to design eﬀective countermeasures against them.
The fault attack countermeasures can be divided into two classes, detection
and infection. In case of detection countermeasure, some redundant computation
is always added to the encryption module. But irrespective of the redundancy, it
has been shown in [9] that fault injection during veriﬁcation, aids the attacker to
bypass the comparison altogether. Even if the veriﬁcation stage itself is redun-
dant, it can be avoided using three fault injections as described in [10]. To over-
come these limitations of fault detection techniques, infective countermeasure has
been introduced in [11] for RSA and later adapted for other encryption schemes
as well. Numerous attempts of protecting AES against fault attacks using fault
infection have been proposed. But those attempts have failed for various reasons,
the primary being the deterministic nature of the infection techniques. This issue
has been addressed by recent works [12,13] that have tried to incorporate ran-
domness into their schemes. In [13], the authors show that the deterministic
diﬀusion used in infective countermeasures are not secure and thus emphasize
on the need of randomness. Indeed the countermeasure of AES proposed in [12]
infects the faulty computation with random values using dummy rounds. How-
ever, both the randomized infective countermeasures have been attacked by [1].
Further, [14] shows some additional weakness in the infection mechanism of [12]
which makes the attack of [1] more feasible. Additionally, [14] presents a modiﬁed
countermeasure algorithm proposed in [12].
Before introducing our approach we brieﬂy outline the vulnerabilities of ran-
domized schemes mentioned above. In [1], the authors have shown that using the
same fault model assumed in [13], the attack complexity can be reduced from
2128 to 16 × 28. The scheme proposed in [12] that uses some additional dummy
rounds, has also been shown to be vulnerable in [1]. This attack requires 36 faults
to recover the full AES-128 key if any row except the top one is infected. The
attack is further improved in [14] by including the top row while reducing the
number of faults to 8. In addition to this, the authors also presented a modiﬁed
version of the countermeasure proposed in [12]. However, like previous works,
as pointed out by Battistello and Giraud[1], this is yet another patch work and
hence the need of a theoretical framework is imperative. Moreover, existing liter-
ature lacks a study of practical implementation of any infective countermeasure.
The work presented in this paper is the ﬁrst such attempt to develop a theoret-
ical framework to formalize the infective countermeasure and at the same time
to present a practical construction based on this.
In the current work, a formalization of fault attacks on symmetric ciphers is
done. Referring to the classical IND-CPA security, we introduce a term called
INDf-CPA security to take into account an adversary that has the power of
fault injection. The idea behind INDf-CPA security is to randomize the induced
fault. To achieve this, we propose a model which uses a linear diﬀusion layer and
a nonlinear mixing function. To validate the proposed method, we show a case
study choosing AES as the crypto primitive. The design rationale of the model is

Preventing Fault Attacks Using Fault Randomization
345
Table 1. Comparative Study with Existing DFA Countermeasures
Algorithm
Fault Model
Vulnerability
Parity/Error
Detecting Codes
Multibyte
Inject more faults than the
error correcting capability
Duplication
Singlebyte,
penultimate round of
key scheduling
Combined Attack [15]
Deterministic
Infection
Single or Multibyte
Fixed fault diﬀusion[16]
Multiplicative
Infection[13]
Single byte, 8th
round
Repetition of Same fault[1]
Dummy Round [12]
Singlebyte at last
eﬀective round
Localization of fault infection
[1,14]
Proposed Model
Single or
Multibyte
No Known vulnerabilities
also furnished. A comparative study with some of the existing countermeasures
is depicted in Table 1.
Contribution: The contribution of the paper is listed as follows:
– Formalized fault randomization as an eﬀective countermeasure against fault
attacks.
– Proposed a practical solution using a linear diﬀusion function (realized by
a maximum length cellular automata) and a nonlinear mixing (achieved by
nonlinear mixing function NMix [17]) following the theoretical model.
– Presented a detailed case study on AES implementing and validating the
entire scheme on Xilinx FPGA platform.
– Furnished a comparative study to show that the proposed method is better
than the only secure scheme in the existing literature.
The rest of the paper is organized as follows. Section 2 formalizes the fault
attack model and the security notions. A theoretical construction based on the
formalized model is discussed in Section 3. Then we sketch a case study on AES
with a practical construction of the countermeasure in Section 4. The implemen-
tation details of the proposed scheme on Xilinx FPGA along with a comparative
study with the countermesure [13] is shown in Section 5. Section 6 concludes the
work.
2
A Security Model for Fault Randomization
In order to formalize our approach, we refer to the classical IND-CPA game.
However, to take into account the additional access to the faulty ciphertext(s),
we modify the IND-CPA and refer to the modiﬁed game as INDf-CPA. In
INDf-CPA an adversary has access to an additional oracle which simulates
www.ebook3000.com

346
S. Ghosh et al.
the faulty encryption. So when the adversary queries his oracle with a plain-
text, it returns a faulty ciphertext following some predeﬁned fault attack model.
Let Π = (K, E, D) be an IND-CPA secure symmetric encryption scheme with
key-space K, message-space M and ciphertext-space C and the security param-
eter n. The encryption oracle Ek(·) on input m ∈M returns Ek(m) ∈C. The
fault simulating oracle Ef
k (·, ·) takes as input (m, L) and returns a faulty cipher-
text Ef
k (m, L) ∈C, where L is a collection of parameters associated with the
fault and is directly determined by the underlying fault model. We now formally
introduce the INDf-CPA game.
Game 1. INDf-CPA(A, Π)
1: procedure Initialize
2:
k
$←−K
▷Chosen by encryption oracle
3:
m0, m1
$←−M
▷Chosen by adversary
4:
b ∈$ {0, 1}
▷Chosen by encryption oracle
5:
c ←Ek(mb)
6:
win = 0
7: end procedure
8: procedure Adversary(c, Ek(·)Ef
k (·, ·))
9:
for i ←1 to q(n) do
▷q(n) is a polynomial in n
10:
c′
i0 ←Ef
k (m0, Li)
c′
i1 ←Ef
k (m1, L′
i)
▷Returned by fault simulating oracle
11:
end for
12:
return b′ ∈{0, 1}
▷Using {c, {c′
i0}, {c′
i1}}, adversary guesses b
13: end procedure
14: procedure Finalize
15:
if b′ = b then
16:
win = 1
17:
end if
18:
return win
19: end procedure
With respect to the INDf-CPA game deﬁned above, an adversary wins if he
is able to correctly guess the value of b. Let A be some class of computation-
ally bounded adversaries. The following expression gives the maximum of the
distinguishing advantages over all adversaries.
AdvINDf-CPA
Π
(A) = max
A∈A
Pr[AEk(m0),Ef
k (·,·) = 0] −
Pr[AEk(m1),Ef
k (·,·) = 1]


Preventing Fault Attacks Using Fault Randomization
347
Thus for a symmetric key encryption scheme Π to be INDf-CPA secure
AdvINDf-CPA
Π
(A) must be upper bounded by a negligible function of the secu-
rity parameter n. This leads us to the following deﬁnition for INDf-CPA security.
Deﬁnition 1. A symmetric encryption scheme Π = (K, E, D) is said to be
INDf-CPA secure if for any computationally bounded adversary A who has the
additional capability of inducing polynomial number of random faults in E and
observe corresponding outputs, there exists a negligible function ϵ such that
max
A∈A
Pr[AEk(m0),Ef
k (·,·) = 0] −Pr[AEk(m1),Ef
k (·,·) = 1]

≤ϵ(n)
where, A represents some class of computationally bounded adversaries.
It is clear from the above deﬁnition that INDf-CPA security
=⇒
IND-CPA
security. However, the converse may not be true. In order to achieve IND-CPA
=⇒INDf-CPA we give the following theorem.
Theorem 1. An IND-CPA secure symmetric encryption scheme Π = (K, E, D)
is also INDf-CPA secure if there exists a randomized transformation T such that
Ef
k (·, ·)
T−→R(·, ·)
where the oracle R returns
Ef
k (·, ·)
 random bits.
Proof. Let A ∈A be any computationally bounded adversary. Given the ran-
domized transformation T , the following derivation explains how we reduce
AdvINDf-CPA
Π
(A) to Advind-cpa
Π
(A) thereby achieving INDf-CPA security from
IND-CPA security.
AdvINDf-CPA
Π
(A)
=
Pr[AEk(m0),Ef
k (·,·) = 0] −Pr[AEk(m1),Ef
k (·,·) = 1]

=
Pr[AEk(m0),R(·,·) = 0] −Pr[AEk(m1),R(·,·) = 1]

[∵Ef
k (·, ·)
T−→R(·, ·)]
=
Pr[AEk(m0) = 0] −Pr[AEk(m1) = 1]

[∵AEk(·),R(·,·) ⇔AEk(·)]
= Advind-cpa
Π
(A)
≤ϵ(n)
[∵Π is IND-CPA secure]
The interpretation of Theorem (1) in real-world terms is that if we can obfuscate
the faulty output of an encryption algorithm then the advantage gained by the
adversary due to the fault induction is completely nulliﬁed. In the next section
of the paper we introduce a theoretical construction of the randomized transfor-
mation T . Later we give a practical construction of T . We ﬁnally show that if
we apply T on AES, we are able to achieve INDfCPA security.
www.ebook3000.com

348
S. Ghosh et al.
3
A Theoretical Construction for T
Our principle objective while designing T is to disperse the fault induced by an
attacker into the entire state of the encryption scheme in a non-deterministic
way. So the function T will be of the following form:
T (f(δ), r) =

0, if f(δ) = 0
random, f(δ) ̸= 0
where f is a function of the fault value δ and r is a random mask.
In order to achieve non-deterministic fault dispersion, we use both linear and
nonlinear layers in the design of T along with a random mask. The construction
is detailed in Fig. 1.
Fig. 1. Construction of T
We use two instances of the encryption algorithm. The fault model assumed
in this work states that the attacker can inject single or multibyte random fault
at anywhere in the intermediate state of the AES. The only assumption is that
faults cannot be induced in both the instances such that they cancel each other
out. We next combine the outputs of both the instances using some combiner ⊞
(typically the XOR function) and feed it to a Linear Diﬀusion Function (LDF)
followed by a Randomized Non-linear Mixing (RNLM). Finally, we combine the
output of RNLM with original output of one of the instances to form the ﬁnal
output. The LDF and RNLM functions are the building blocks of T . In the next
subsection, we discuss about the design rationale behind these building blocks.
3.1
Design Rationale
The functions LDF and RNLM have been introduced to achieve the desired ran-
domization as discussed in Section 2. These functions cater to speciﬁc require-
ments that are to ensured to achieve the goal of T . Existing works that address
these requirements have failed due to various reasons, the primary causes being
low diﬀusion or localized diﬀusion [12,13] and lack of randomness [18,19]. Below
we brieﬂy discuss the eﬀect of these vulnerabilities and the analyze the remedies.

Preventing Fault Attacks Using Fault Randomization
349
Linear Diﬀusion Layer. Low or localized diﬀusion results in low dispersion
of the fault. This in turn reduces the eﬀect of the random mask used [12,13]
and may lead to the retrieval of the original faulty ciphertext. This precludes
the need for a state dependent high diﬀusion function which is ensured by LDF
in T . This layer aims at dispersing the fault thereby denying any advantage
the attacker could gain from the locality of the faults. It is well-known that
linear functions can achieve better diﬀusion. So we propose that the underlying
primitive be linear in nature satisfying the strict avalanche criterion.
Randomized Nonlinear Mixing. The deterministic nature of the earlier fault
attack countermeasures like [18,19] was a major limitation. The authors of [13]
ﬁrst highlighted the need of randomness while handling fault based attacks.
Thus a random parameter is essential. This is also evident from the requirement
of Theorem 1, where we need to transform Ef
k (·, ·) to a random oracle R(·, ·).
RNLM layer of T achieves this goal by using a unique random mask in every
iteration of the encryption. In addition we also propose that random mask be
mixed with the diﬀused fault from LDF using some nonlinear function. Non-
linearity will help protect against reverse engineering and also other diﬀerential
attacks.
The ﬁnal combiner ⊞mixes the output value from the previous stage with the
result of one of the encryption modules. This is done to ensure that, in absence of
any fault value, the genuine ciphertext forms the ﬁnal output. In all other cases
the attacker receives an obfuscated version of the actual faulty ciphertext. In the
next section, we present a case-study on the AES with a practical construction
for T followed by a detailed hardware analysis on FPGA.
4
Fault Randomization: A Case-Study on AES
It is known that AES, when used with a proper mode of operation, is IND-
CPA secure. However, as discussed earlier, there are many attacks on AES that
exploit faults to recover the secret key. This renders AES insecure under INDf-
CPA. There have been many attempts to protect AES against these attacks. Still
those countermeasures are proved to be vulnerable. In this section, we construct
a countermeasure based on the design rationale discussed in the previous section
and choosing Π = AES. The overall structure is depicted in Fig. 2. It is inter-
esting to note that this construction is applicable to any cipher in place of AES.
4.1
The Combiner to Get the Diﬀerential Value Δ
A simple bitwise XOR operation is used to get the diﬀerence between the outputs
of two AES modules.
www.ebook3000.com

350
S. Ghosh et al.
Fig. 2. Countermeasure on AES†
†AES can be replaced by any iterative block cipher
4.2
Cellular Automata Based Linear Diﬀusion
In this design, the linear diﬀusion function D is implemented using three neigh-
borhood1 maximum length2 Cellular Automata (CA) where the input is an
128 bit register. The motivation of using 3-neighborhood CA is stated below.
– The evolution of each cell at each iteration is dependent only upon the
current state of its left, right and itself as in Fig. 3b which is a very optimized
hardware structure.
– Synthesis of maximum length 3-neighborhood CA from a primitive polyno-
mial is well deﬁned in [20].
We have synthesized a maximum length CA from the primitive polynomial
shown in Eq. (1) using the technique stated in [20].
x128 + x29 + x27 + x2 + 1
(1)
CAs are known to provide good diﬀusion property when iterated suﬃcient num-
ber of times. So our next task is to ascertain the minimum number of iterations
of the CA to achieve optimal diﬀusion. In order to do this we rely on the Strict
Avalanche Criterion (SAC). The following lemma gives us an idea about the
maximum number of iterations that will deﬁnitely violate SAC.
Lemma 1. If the number of iterations of an n-cell three neighborhood CA is less
than n −1, then the output of the CA violates the Strict Avalanche Criterion.
1 The evolution of each cell of a 3-neighborhood CA is based on the value of the cell
to its left, the value of the cell itself, and the value of the cell to its right.
2 An n-cell maximum length CA has a period 2n −1, period of a CA is the number
of cycles after which the CA returns to its initial state.

Preventing Fault Attacks Using Fault Randomization
351
Proof. Let Ct : {0, 1}n →{0, 1}n represents t iterations of the n-cell three
neighborhood CA. If the initial state of the CA is X = {x0, x1, · · · , xn−1} and
the output after t iterations is Y = {y0, y1, · · · , yn−1}, then
Ct(x0, x1, · · · , xn−1) = (y0, y1, · · · , yn−1),
where

yi = f t
i (St
i) : St
i ⊆X
f t
i : {0, 1}|St
i| →{0, 1}
Here St
i is the set of cells driving the function f t
i . Initially, the function fi is
dependent upon only xi−1, xi and xi+1. The following set of equations shows the
change of St
i with number of iterations t.
S1
i = {xi−1, xi, xi+1}
S2
i = {xi−2, xi−1, xi, xi+1, xi+2}
...
St
i = {xi−t, · · · , xi, · · · , xi+t},
i ≥t, i + t ≤n
(2)
Now, if t < n−1, then it is clear from Eq. (2), that x0 /∈St
n−1 and xn−1 /∈St
0.
This implies that, if the number of iterations is less than n −1, then the output
bits yn−1, y0 are independent of the input bits x0, xn−1 respectively which is a
straightforward violation of SAC.
(a) LDF block Diagram
(b) Single Round CA
Fig. 3. Design of LDF
So, to satisfy SAC in our case, the number of iterations for the 128 cell CA
cannot be less than 128−1 = 127. Now, to get an experimental lower bound, we
perform the SAC test on the output with increasing number of iterations. The
experiments reveal that iterating the CA for an additional 128 times is suﬃcient
making a total of 127 + 128 = 255 iterations. However, if each iteration corre-
sponds to one clock cycle, the throughput of the scheme will reduce substantially.
So we avoid the iterative design strategy. We now look into the prospect of using
a combinatorial logic that realizes multiple rounds in a single iteration. But,
using a logic that realizes 255 rounds in only one iteration will have a high area
footprint and at the same time increase the circuit depth, thereby increasing
www.ebook3000.com

352
S. Ghosh et al.
the maximum path delay. We address this problem by using a partially unrolled
design to strike a trade oﬀbetween area and latency. We do so by realizing 15
iterations of the CA with a combinatorial logic and then iterate this logic for
17 clock cycles. This reduces the circuit depth which results in increase of both
maximum operating frequency and throughput. The design is shown in Fig. 3.
4.3
Randomized Non-Linear Mixing Using NMix Function
For non-linear mixing purpose, we have used a cryptographically secure and
hardware optimized Bent Function called NMix which was introduced in [17].
For the sake of clear understanding the NMix function is brieﬂy revisited here.
Deﬁnition 2. For two n-bit variables X = (xn−1, xn−2, · · · , x0) and R =
(rn−1, rn−2, · · · , r0), NMix produces an n-bit output variable Y = (yn−1, yn−2,
· · · , y0), where Y = N(X, R) and N is the NMix function. Each output bit of
the NMix is related to the input bits by the following relation:
yi = xi ⊕ri ⊕ci−1
ci =
i

j=0
xjrj ⊕xi−1xi ⊕ri−1ri
where 0 ≤i ≤n −1, c−1 = 0, x−1 = 0, r−1 = 0.
The security properties of NMix is depicted in Table 2 as given in [17].
Table 2. Security Properties of NMix[17]
Parameters
Value
Nonlinearity of output bit yi
22i+1 −2i+2
Bias for best linear approx. of output bit yi
2−i
Bias for best linear approx. of yi ⊕yi+1
0.0625
Provide diﬀerential resistance
Yes
Algebraic degree of output bit yi
2
For our purpose we slightly modify the NMix function by taking c−1 =
cn−1. This way the bias of the 0-th bit is omitted. Being a Bent Function, the
nonlinearity of NMix is 2n−1−2
n
2 −1 which is the maximum possible nonlinearity.
We also compute N(0, R) and ﬁnally we XOR the outputs of the two NMix
functions. This step is required to make sure that the correct ciphertext remains
unaltered if no fault is injected. The PRNG to generate the random mask is also
implemented using a CA in our case. But, this can be replaced by any other
PRNGs as, the implementation of PRNG is not our principle concern.

Preventing Fault Attacks Using Fault Randomization
353
4.4
The Final Combiner
The output from the last step is mixed with the result of one of the AES modules
using a bitwise XOR operation.
5
Hardware Implementation
The proposed countermeasure is implemented on Xilinx Spartan-3 XC3S1500-
4FG676C FPGA platform choosing AES as the encryption function as depicted
in Section 4. The architecture of the design follows the structure in Fig. 2. As
discussed earlier, the multiplicative countermeasure in [13] has been cryptana-
lyzed [1] when F8 multiplication is used but no cryptanalysis exists of the same
scheme when using F128 multiplication. So we have taken the F128 multiplicative
version of [13] for comparison. However, as no implementation details was given
in [13], we also implemented their scheme in the same FPGA platform. For a
fair comparison, the underlying AES primitive used is kept same across all the
implementations. The results are given in Table 3.
Table 3. Implementation Summary and Comparison in Altium NB-2
Countermeasure
Unprotected in FDTC ’12 with Proposed
AES
F128 multiplication
Scheme
Number of LUTs
2214
5881
5669
Number of Slices
1292
3543
3010
Frequency (MHz)
82
70
77
Throughput (Mbit/s)
20.78
14.11
17.52
Eﬃciency (Mbit/s/slice)
0.016
0.004
0.005
It is evident from the table that proposed design clearly outperforms the
multiplicative countermeasure. The increase in hardware requirement compared
to the basic AES is also optimal considering that the scheme uses two AES
modules.
6
Conclusion
In this paper we introduce a formal model of fault attacks on symmetric
ciphers and their countermeasures based on the infective approach. This model
captures the notion of security irrespective of the fault attack strategy. Our
design takes the localization of fault, low diﬀusion and deterministic nature of
the countermeasures into account which were not addressed properly in the exist-
ing literature. In support of our model, we have also shown a case study on AES
and its implementation details on FPGA platform. The hardware results are
shown to be better than the multiplicative countermeasure.
www.ebook3000.com

354
S. Ghosh et al.
References
1. Battistello, A., Giraud, C.: Fault Analysis of Infective AES Computations. In:
2013 Workshop on Fault Diagnosis and Tolerance in Cryptography (FDTC),
pp. 101–107, August 2013
2. Boneh, D., Demillo, R.A., Lipton, R.J.: On the Importance of Checking Crypto-
graphic Protocols for Faults. In: Fumy, W., (ed.) Advances in Cryptology EURO-
CRYPT 1997. LNCS, vol. 1233, pp. 37–51. Springer, Heidelberg (1997)
3. Daemen, J., Rijmen, V.: The Design of Rijndael. Springer-Verlag New York Inc.,
Secaucus, NJ, USA (2002) ISBN: 3540425802
4. Biham, E., Shamir, A.: Diﬀerential Fault Analysis of Secret Key Cryptosystems.
In: Kaliski Jr, B.S. (ed.) CRYPTO 1997. LNCS, vol. 1294, pp. 513–525. Springer,
Heidelberg (1997)
5. Giraud, C.: DFA on AES. In: Dobbertin, H., Rijmen, V., Sowa, A. (eds.) AES
2005. LNCS, vol. 3373, pp. 27–41. Springer, Heidelberg (2005)
6. Tunstall, M., Mukhopadhyay, D., Ali, S.: Diﬀerential Fault Analysis of the
Advanced Encryption Standard Using a Single Fault. In: Ardagna, C.A., Zhou,
J. (eds.) WISTP 2011. LNCS, vol. 6633, pp. 224–233. Springer, Heidelberg (2011)
7. Mukhopadhyay, D.: An Improved Fault Based Attack of the Advanced Encryp-
tion Standard. In: Preneel, B. (ed.) AFRICACRYPT 2009. LNCS, vol. 5580,
pp. 421–434. Springer, Heidelberg (2009)
8. Saha, D., Mukhopadhyay, D., Roy Chowdhury, D.: A Diagonal Fault Attack on
the Advanced Encryption Standard. Cryptology ePrint Archive, Report 2009/581
(2009). http://eprint.iacr.org/
9. Kim, C.H., Quisquater, J.-J.: Fault Attacks for CRT Based RSA: New Attacks,
New Results, and New Countermeasures. In: Sauveron, D., Markantonakis, K.,
Bilas, A., Quisquater, J.-J. (eds.) WISTP 2007. LNCS, vol. 4462, pp. 215–228.
Springer, Heidelberg (2007)
10. Van Woudenberg, J., Witteman, M., Menarini, F.: Practical Optical Fault Injection
on Secure Microcontrollers. In: 2011 Workshop on Fault Diagnosis and Tolerance
in Cryptography (FDTC), pp. 91–99, September 2011
11. Yen, S.M., Joye, M.: Checking before output may not be enough against fault-based
cryptanalysis. IEEE Transactions on Computers 49(9), 967–970 (2000)
12. Gierlichs, B., Schmidt, J.-M., Tunstall, M.: Infective Computation and Dummy
Rounds: Fault Protection for Block Ciphers without Check-before-Output. In:
Hevia, A., Neven, G. (eds.) LatinCrypt 2012. LNCS, vol. 7533, pp. 305–321.
Springer, Heidelberg (2012)
13. Lomne, V., Roche, T., Thillard, A.: On the Need of Randomness in Fault Attack
Countermeasures - Application to AES. In: Proceedings of the 2012 Workshop on
Fault Diagnosis and Tolerance in Cryptography, FDTC 2012, pp. 85–94. IEEE
Computer Society Washington, DC (2012)
14. Tupsamudre, H., Bisht, S., Mukhopadhyay, D.: Destroying fault invariant with
randomization - A countermeasure for AES against diﬀerential fault attacks. In:
Proceedings of the Cryptographic Hardware and Embedded Systems, CHES 2014–
16th International Workshop, Busan, South Korea, September 23–26, pp. 93–111
(2014)
15. Roche, T., Lomn´e, V., Khalfallah, K.: Combined Fault and Side-Channel Attack
on Protected Implementations of AES. In: Prouﬀ, E. (ed.) CARDIS 2011. LNCS,
vol. 7079, pp. 65–83. Springer, Heidelberg (2011)

Preventing Fault Attacks Using Fault Randomization
355
16. Piret, G., Quisquater, J.-J.: A Diﬀerential Fault Attack Technique against SPN
Structures, with Application to the AES and KHAZAD. In: Walter, C.D., Ko¸c,
C¸.K., Paar, C. (eds.) CHES 2003. LNCS, vol. 2779, pp. 77–88. Springer, Heidelberg
(2003)
17. Bhaumik, J., Roy Chowdhury, D.: Nmix: An Ideal Candidate for Key Mixing. In:
SECRYPT, pp. 285–288 (2009)
18. Fournier, J., Rigaud, J.B., Bouquet, S., Robisson, B., Tria, A., Dutertre, J.M.,
Agoyan, M.: Design and characterisation of an AES chip embedding countermea-
sures. IJIEI 1(3/4), 328–347 (2011)
19. Joye, M., Manet, P., Rigaud, J.B.: Strengthening hardware AES implementations
against fault attacks. Information Security, IET 1(3), 106–110 (2007)
20. Cattell, K., Muzio, J.C.: Synthesis of one-dimensional linear hybrid cellular
automata. IEEE Transactions on Computer-Aided Design of Integrated Circuits
and Systems 15(3), 325–335(1996)
www.ebook3000.com

Analysis of Rainbow Tables with Fingerprints
Gildas Avoine1,2, Adrien Bourgeois1, and Xavier Carpent1(B)
1 Universit´e catholique de Louvain, 1348 Louvain-la-Neuve, Belgium
xavier.carpent@uclouvain.be
2 INSA de Rennes, IRISA UMR 6074, 35043 Rennes, France
Abstract. Cryptanalytic time-memory tradeoﬀs were introduced by
Martin Hellman in 1980 to perform key-recovery attacks on cryptosys-
tems. Rainbow tables are a variant and a major advance presented by
Philippe Oechslin at Crypto 2003. Checkpoints for rainbow tables have
been proposed in Indocrypt 2005 as a method to reduce the cost of false
alarms. Endpoints truncation has also been suggested to reduce their
memory consumption.
This article shows that checkpoints and endpoints share the same
nature and uniﬁes checkpoints and endpoint truncation in a single model.
An analysis of the average cryptanalysis time is presented and validated
experimentally, and a method to determine ﬁngerprint conﬁguration sys-
tematically is proposed.
Rainbow tables with ﬁngerprints exhibit a speedup of about two with
respect to their classical counterparts in average cryptanalysis time.
Keywords: Cryptanalysis · Time-memory tradeoﬀ· Rainbow tables
1
Introduction
1.1
Motivations
Fundamental problems in cryptanalysis such as recovering encrypted data with-
out the key, or inverting a hash function can be done by exhaustive search. How-
ever, the search needs to be carried out from scratch with each new instance of the
problem. Moreover, it suﬀers from scalability issues in practice, with instances of
interesting size requiring too much time or computational power. Alternatively,
one could precompute and store a lookup table, but again interesting instances
require unrealistic storage capabilities.
The cryptanalytic time-memory tradeoﬀ(TMTO) is a technique introduced
by Hellman in 1980 [13] that allows an adversary to carry out eﬃcient brute-force
attacks in practice. As its name suggests, it is a tradeoﬀbetween an on-the-ﬂy
exhaustive search and a precomputed lookup table. A TMTO particularly makes
sense when a known plaintext attack is performed more than once (because the
initial precomputation costs more than a single exhaustive search), with a key-
space that does not allow the adversary to store all the pairs (key, ciphertext).
A TMTO is also quite relevant when the attack is time-constrained once the
adversary receives the ciphertext.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 356–374, 2015.
DOI: 10.1007/978-3-319-19962-7 21

Analysis of Rainbow Tables with Fingerprints
357
Cryptanalytic time-memory tradeoﬀs are thus the keystone of many practi-
cal attacks, for example against A5/1 (GSM) in 2000 [7], LILI-128 in 2002 [22],
Windows LM Hash in 2003 [19], Unix passwords in 2005 [17], and Texas Instru-
ments DST in 2005 [8]. In 2010, the attack against A5/1 was resurrected and
a world-wide distributed TMTO-based attack was launched during Black Hat
2010 [18]. The weakness exploited in all these cases is twofold: the key entropy
is not high enough, and a known (constant) plaintext attack is feasible.
In spite of the wide use of cryptanalytic time-memory tradeoﬀs, few signif-
icant advances have been done since Oechslin introduced the rainbow tables at
Crypto 2003 [19], illustrated with the instant cracking of alphanumerical Win-
dows LM Hash passwords. However, any improvement of their eﬃciency may
render attacks more practical, especially when they are time-constrained. It is
thus very important to minimize their cost.
1.2
Background
A Hellman-type cryptanalytic time-memory tradeoﬀconsists of a precomputation
phase that is done once, and an online phase that is expected to be much faster
than a brute-force attack.
Precomputation Phase. To invert a function h : A →B, a set of m chains
of t elements in A is precomputed. A chain starts with an arbitrary value Sj
belonging to A, known as its starting point. Each subsequent element is computed
by iterating a function f : A →A, x →r(h(x)), where r : B →A is a reduction
function, which aim is to assign an arbitrary value in A to any value of B. The
i-th (1 ≤i ≤t) element of the j-th (1 ≤j ≤m) chain is denoted Xj,i, where
Xj,i+1 = f(Xj,i) and Xj,1 = Sj. The values Xj,t are denoted Ej and called the
endpoints. The trick of the TMTO technique consists in only storing the m pairs
(Sj, Ej) in a so-called table. A single table cannot fully cover the set A, and
several tables are consequently required to reach a success rate close to 1.
Online Phase. Given a value y in B, the goal of the online phase is to retrieve x
in A such that h(x) = y (provided such a point exists)1. As the table does not
contain the intermediate points, the adversary computes instead a chain from y
and searches for a match with an endpoint. More precisely, she starts by reducing
y and searching through the m endpoints. If there exists j such that r(y) = Ej,
then she re-computes Xj,t−1 from Sj and veriﬁes whether h(Xj,t−1) = y. If this
holds, the attack succeeds and x = Xj,t−1. Otherwise, the match is called a
false alarm. When a false alarm occurs, or when no matching endpoint is found,
the attack proceeds on the next column: the attacker computes y ←f(y) and
repeats the operations. The attack goes on until a correct value is found, or until
the end of the table is reached, in which case the attack fails for this table.
1 In the following, it is assumed that x is chosen uniformly at random in A.
www.ebook3000.com

358
G. Avoine et al.
A major drawback of Hellman’s method is that two colliding chains in a
given table lead to a fusion. Such artifacts substantially decrease the tradeoﬀ
performance. Two signiﬁcant improvements have been introduced to mitigate
this problem: the distinguished points in 1982 by Rivest [10] and the rainbow table
in 2003 by Oechslin [19]. This article focuses on the latter, which is signiﬁcantly
faster in practice [16,19].
1.3
Related Works
Although not the focus of this paper, the following works are also relevant.
Hellman’s technique is designed to invert random functions. Fiat and Naor
provide in [11] a construction for inverting any function, at the price of a less
eﬃcient tradeoﬀ. De, Trevisan and Tulsiani propose in [9] a similar construction
for inverting any function on a fraction of their input. They also suggest using
time-memory tradeoﬀs for distinguishing the output of pseudorandom generators
from random.
Time-memory tradeoﬀs have also been applied to stream cipher indepen-
dently by Babbage in [3] and Goli´c in [12]. These tradeoﬀs typically require
more data than attacks on block ciphers. Biryukov and Shamir improve in [6]
the eﬃciency of this attack on stream ciphers by combining the Babbage/Goli´c
and the Hellman techniques. Finally, Biryukov, Mukhopadhyay and Sarkar gen-
eralize these diﬀerent approaches in [5], and propose a way to use Hellman’s
technique with multiple data.
In [4], Barkan, Biham, and Shamir showed that the performance of existing
time-memory tradeoﬀs can not be improved by more than a logarithmic factor.
1.4
Contributions
This paper revisits the regular rainbow tables and introduces the rainbow tables
with ﬁngerprints. They form a generalization of rainbow tables and bring a new
vision of them.
The keystone of the rainbow tables with ﬁngerprints is that the endpoints
are no longer stored in the table. Instead, a ﬁngerprint of each chain is stored
along with the starting point. We show that the ﬁngerprint is an alternative
characterization of a chain that behaves better in the online phase than the
endpoint. The ﬁngerprints may be thought of as the concatenation of a truncated
endpoint (as described for instance in [16]), and a series of checkpoints (see [1]).
However, we develop a framework in which the checkpoints and the (truncated
or not) endpoint have the same nature, and analyze them together. We show
that this approach makes sense and that it is more general. This sheds new light
on the problem, and we trust this might lead to further improvements.
We present a theoretical analysis of the average performance of rainbow tables
with ﬁngerprints, and propose a way to eﬃciently and systematically compute
good conﬁgurations.
Rainbow tables are reviewed in Sect. 2, along with existing relevant analysis
and improvements on them. The ﬁngerprint model is introduced in Sect. 3, and is

Analysis of Rainbow Tables with Fingerprints
359
analyzed in Sect. 4. A technique for ﬁnding ﬁngerprint conﬁgurations is described
in Sect. 5. Finally, Sect. 6 presents theoretical results on diﬀerent comparison
between rainbow tables with ﬁngerprint and their regular version, along with
experimental validation.
2
Rainbow Tables
2.1
Description
Oechslin introduced in 2003 [19] an improvement that outperforms the distin-
guished points. In this variant, a diﬀerent reduction function is used per column,
which leads to the so-called rainbow tables. This new organization of the tables
eases the detection of fusions, while keeping constant the chain length, and also
divides the number of lookups by a factor t in comparison with Hellman’s tables.
The online phase is similar to the one of Hellman’s method, but the diﬀerence is
that it is necessary to start the online chains iteratively from the last column at
the right of the table to the ﬁrst column at the left of the table. Indeed, as the
column that contains the expected key is unknown, the ﬁrst reduction function
that must be applied is unknown as well, and each possibility must be tested.
This means that in the worst case, t2/2 operations are necessary to browse all
the table, without taking false alarms into account. A thorough analysis of the
rainbow tables has been done by Avoine, Junod, and Oechslin [2]. The rain-
bow tables are currently used by most of the password crackers, and have been
implemented by Mentens, Batina, Preneel, and Verbauwhede [17] using FPGAs
to retrieve UNIX passwords.
Precomputation Phase. The precomputation phase is very similar to that of the
Hellman method. Instead of iterating a function f : x →r(h(x)) to compute
a chain, a diﬀerent reduction function is used in each column. Chains therefore
consists of elements computed iteratively using fi : x →ri(h(x)), where ri is
the reduction function associated with column i. A typical reduction function
family is ri : y →(y + i) mod N, with N = |A|. A series of chains is computed
in order to form a table.
In order to build a clean2 table, only one chain per diﬀerent endpoint is kept.
These endpoints, along with their corresponding starting points, are stored in
memory. Furthermore, a table of maximal size is obtained when all (or almost
all) the possible endpoints are saved, which happens when the number of chains
computed is suﬃciently large (i.e. when any new chain would have a negligible
probability of having an endpoint that is not yet saved). The structure of a
rainbow table is shown in Fig. 1.
As highlighted by Theorem 2, the probability of success of a single rainbow
table is bounded. In the case of rainbow tables of maximal size, this probability is
about 86.47%. In order to obtain a higher probability of success, multiple tables
2 Although the word “perfect” is usually attributed to tables without merges in the
literature, we ﬁnd this terminology more intuitive and more adapted.
www.ebook3000.com

360
G. Avoine et al.
S1 = X1,1
r1◦h
−−−→
X1,2
r2◦h
−−−→
. . .
rt−2◦h
−−−−→
X1,t−1
rt−1◦h
−−−−→
X1,t = E1
S2 = X2,1
r1◦h
−−−→
X2,2
r2◦h
−−−→
. . .
rt−2◦h
−−−−→
X2,t−1
rt−1◦h
−−−−→
X2,t = E2
...
...
...
...
...
Sj = Xj,1
r1◦h
−−−→
Xj,2
r2◦h
−−−→
. . .
rt−2◦h
−−−−→
Xj,t−1
rt−1◦h
−−−−→
Xj,t = Ej
...
...
...
...
...
Sm = Xm,1
r1◦h
−−−→
Xm,2
r2◦h
−−−→
. . .
rt−2◦h
−−−−→
Xm,t−1
rt−1◦h
−−−−→
Xm,t = Em
Fig. 1. Structure of a rainbow table. The framed columns, respectively the starting
points and the endpoints, are the parts stored in memory.
are used, with a diﬀerent family of reduction functions per table. A typical
number is 4 (achieving a total probability of success of about 99.97%).
In the following, clean rainbow tables of maximal size are assumed, because
they oﬀer the best eﬃciency for a given memory.
Online Phase. The online phase in rainbow tables is again very similar to that
of the Hellman method. In order to invert a given y, one starts by computing
rt−1(y) and searching through the endpoint list whether there exists j such that
Ej = rt−1(y). If so, a chain is rebuilt from the corresponding starting point Sj
in order to compute Xj,t−1 and verify whether h(Xj,t−1) = y. If so, the attack
succeeds with x = Xj,t−1, and if not, this match was a false alarm. In that case,
or when no matching endpoint is found, the attack proceeds to the next table.
Once all tables are cycled3, the attack proceeds with the next column, computing
rt−1(h(rt−2(y))), and so on until the search succeeds or that all columns are
searched through.
2.2
Analysis
For the sake of clarity, the notations provided in [2] and [19] for rainbow tables
are also used below, and summarized in Tab. 1. In addition, some theoretical
results from [2] are provided.
Theorem 1. The number of possible points in column i for a chain generated
from the starting column is
mi+1 = N

1 −

1 −1
N
mi
.
(1)
When using tables of maximum size, this can be approximated by mmax
i
= 2N
i+1.
3 The search procedure for rainbow tables works “vertically” (all tables for each col-
umn) rather than “horizontally” (all columns for each table) because the search is
increasingly more expensive towards the left of the tables. In the Hellman method,
this does not matter.

Analysis of Rainbow Tables with Fingerprints
361
Table 1. Notations used in this paper
Symbol
Meaning
h : A →B
The function to invert
N
|A|
m
Number of chains in one table
t
Number of columns per table
ℓ
Number of tables
qc
Probability of a false alarm occuring when the search is at column c
mi
Number of possible points in column i in a precomputed rainbow table
Proof. See Theorem 1 in [2].
Theorem 2. The success probability of a set of ℓrainbow tables is
P ∗= 1 −

1 −m
N
ℓt
.
(2)
When using tables of maximum size, this can be approximated by P ∗≈1−e−2ℓ.
Proof. See Theorem 2 in [2].
Theorem 3. The probability of occurrence of a false alarm when the search is
at column c is
qc = 1 −
t
i=c

1 −mmax
i
N

≈1 −(c −1)c
t(t + 1)
(3)
Proof. See Theorem 2 in [2].
2.3
Improvements
Checkpoints. In 2005, Avoine, Junod, and Oechslin [1] introduced a new fea-
ture to the rainbow tables, known as the checkpoints. The authors observed that
more than 50% of the cryptanalysis time is devoted to rule out the false alarms.
Their technique consists in storing information (e.g., a parity bit) on some inter-
mediate points of the chains alongside the endpoints. During the online phase,
when a match with an endpoint occurs, its checkpoints must be compared with
the checkpoints of the chain which construction is ongoing. When there is a
match of the endpoints, but no match of the checkpoints, the adversary can
conclude that a false alarm occurred without re-computing the colliding chain.
Although the checkpoints increase the performance of the tradeoﬀ, their impact
is limited given that their storage consumes additional memory.
www.ebook3000.com

362
G. Avoine et al.
Endpoint Truncation. In an eﬀort to lower the memory consumption of the
rainbow tables, an idea is to truncate the endpoints by a ﬁxed amount of bits.
It is not clear where this idea ﬁrst appeared in the literature, but it most likely
originated from the (more straightforward) truncation in the distinguished points
method [10]. In the case of rainbow tables, it was hinted in [4]. As noted in [16],
endpoint truncation however comes with a cost in the form of an increase in
false alarms (due to fortuitous matching endpoints).
3
Fingerprints
Despite having been analyzed separately (see e.g. [16]), checkpoints and end-
point truncation have never been addressed together. Moreover, and more impor-
tantly, good checkpoint positions and truncation amount were up to now found
empirically. In this section, a new model is proposed. It encompasses these two
improvements of rainbow tables in a sensible and uniﬁed way. A technique for
determining conﬁgurations is discussed in Sect. 5.
3.1
Rationale
In regular rainbow tables, chains are composed of the starting points, which
allows one to rebuild that chain without ambiguity, and the endpoints, which
are used to select the chain to rebuild in each step of the online phase. Although it
is necessary for the starting points to be points in A for the chain reconstruction
to be meaningful, it is not necessary for endpoints to have that property. Indeed,
their purpose is solely to compare the online chain with each chain of the table, in
order to determine which should be rebuilt (if there is one). An issue with using
the endpoint as characterization is that when the online chain merges with a
precomputed chain, they cannot be distinguished. This leads to the false alarms,
which are the pet hate of the time-memory tradeoﬀs. The ﬁngerprints reduce
this problem by providing a better way to characterize the chains.
3.2
Description
Deﬁnition. In the model presented in this paper, the characterization of a chain
is the list of checkpoints, and the endpoint is considered as a regular checkpoint.
Formally, a ﬁngerprint Fj is deﬁned as the concatenation of the outputs of the
functions Φi applied to each element Xj,i of the chain:
Fj = Φ1(Xj,1) || Φ2(Xj,2) ||
. . . || Φt(Xj,t)
where j ∈[1, m], “||” denotes the concatenation, and Φi (1 ≤i ≤t) is a check-
point function, used in column i. A checkpoint function is such that:
Φi : A →

{0, 1}σi
if σi > 0
ϵ
otherwise

Analysis of Rainbow Tables with Fingerprints
363
with 0 ≤σi ≤⌈log2 N⌉and ϵ representing no information. The output of the
checkpoint function is called a checkpoint. A ﬁngerprint is therefore the con-
catenation of the checkpoints of the points in the chain. Note that a checkpoint
function is expected to have a uniform distribution of its output, as it is the
case with reduction functions. A typical checkpoint function Φi(x) returns the
σi least signiﬁcant bits of x for instance.
Note that, depending on the conﬁguration (i.e. the value of σi in all columns),
a ﬁngerprint Fj is not necessarily ⌈log2 N⌉bits long. In fact, ﬁngerprints are typ-
ically smaller than the endpoints in regular rainbow tables, as shown in Sect. 6.
This allows the rainbow table with ﬁngerprints to contain more chains than what
a regular rainbow table would, for the same memory.
Precomputation Phase. Precomputation in rainbow tables with ﬁngerprints
is very similar to that of regular rainbow tables. The diﬀerence is that during
the computation of a chain, the checkpoint functions are applied on each point,
such that a ﬁngerprint is computed for that chain. Once a chain is complete, the
starting point, the ﬁngerprint, as well as the endpoint (i.e. the last point of the
chain) are all temporarily stored. Similarly to rainbow tables, chains are then
sorted according to their endpoints in order to remove the merging chains. The
table thus becomes clean (or perfect). Endpoints are then discarded, as they are
no longer required. A ﬁnal step consists in sorting the chains according to their
ﬁngerprints, in order to make the search more eﬃcient4. Note that at this point,
there might be several chains sharing the same ﬁngerprint even though they
had diﬀerent endpoints. However, this is marginal for reasonable conﬁgurations.
This ﬁnal step (sorting ﬁngerprints) requires negligible time with respect to the
earlier work, much like sorting the endpoints requires negligible time over the
computation of the chains. Rainbow tables with ﬁngerprints therefore require
the same amount of precomputation as their regular counterparts.
Online Phase. Again, the algorithm for performing the search in rainbow tables
with ﬁngerprints is very close to the one described in 2.1. However, the checkpoint
functions are applied to the online chain, which gives a partial ﬁngerprint (rather
than an endpoint). The ﬁngerprint is partial because the online chain is shorter
than chains of the table, and therefore it might be that not all checkpoints are
part of it. The partial ﬁngerprint is then compared to stored ﬁngerprints (the
comparison is done for the available bits only). A second particularity is that
there might be several ﬁngerprints matching the partial ﬁngerprint of the online
chain, leading to possibly several false alarms per step (there can only be one in
regular rainbow tables).
The fact that endpoints are possibly not completely part of the ﬁngerprint
means that it is possible that two non-merging chains share the same ﬁngerprint.
4 The sort is performed in reverse order, that is the ﬁngerprints are considered ﬂipped,
because partial ﬁngerprints Φc(Xj,c)|| . . . ||Φt(Xj,t) are searched in the online phase.
This ensures that multiple candidate matching ﬁngerprints are contiguous in the list,
making the search more eﬃcient.
www.ebook3000.com

364
G. Avoine et al.
This leads to false alarms, although they are not of the same type as false alarms
caused by merges. Consequently, false alarms are divided into two types: Type-I
false alarms are those that are merge-induced, and Type-II false alarms are those
that are caused by partial ﬁngerprint matching of non-merging chains. Although
Type-II false alarms do not appear in regular rainbow tables, the additional cost
they incur in tables with ﬁngerprints is more than made up for by the other
beneﬁts.
4
Analysis
This section provides an analysis of rainbow tables with ﬁngerprints. Theorem 4
presents preliminary results regarding fortuitous collisions in checkpoint func-
tions, and Theorem 5 presents the average execution cost of a rainbow table
with ﬁngerprints, for a given conﬁguration.
Let φc be the probability that two diﬀerent points have the same checkpoint
in a given column c:
φc := Pr

Φc(x) = Φc(y)|x, y ∈A : x ̸= y
	
.
(4)
This probability is useful to describe the event of two non-merging chains having
the same partial ﬁngerprint.
Theorem 4. If N ≡0 (mod 2σc), given a column c, the probability that two
diﬀerent points chosen uniformly at random in A have the same checkpoint in c
is:
φc = N/2σc −1
N −1
.
(5)
Proof. Given a value x and its corresponding checkpoint Φc(x), there are N −1
diﬀerent possible values y ̸= x. Among those, there are on average N/2σc −1
values y such that Φc(x) = Φc(y).
⊓⊔
This theorem assumes that both the points in a column and the checkpoints are
uniformly distributed. This is for instance ensured if the reduction and check-
point functions are modulos, and if the h function has a uniformly distributed
output, which is the case in virtually all practical cases. Note that this assump-
tion is already made in previous analyses, such as [2] and [19].
The following theorem gives the average cost of a search using a rainbow
table with ﬁngerprints. Its lengthy proof is given in Appendix A.
Theorem 5. The average amount of evaluations of h during the online phase
using the rainbow tables with ﬁngerprints is:
T =
ℓt

k=1
m
N

1 −m
N
k−1
(Wk + Qk) +

1 −m
N
ℓt
(Wℓt + Qℓt) ,
(6)

Analysis of Rainbow Tables with Fingerprints
365
with
ci =
i −1
ℓ

,
qc = 1 −
t
i=t−c+1

1 −mi
N

,
Wk =
k

i=1
ci,
Qk =
k

i=1
(t −ci)(Pci + Eci),
Pc = 1
N
c

i=1
⎛
⎝
t−i

j=t−c
φj
⎞
⎠(zi−1,c −zi,c),
Ec = (m −qc)
t
i=t−c+1
φi,
zi,c = m(1 + c −i) + (c −i)(c −i + 2)
i2

mi + 2N log

1 −mi
2N

,
z0,c = m(1 + c)

1 −mc
4N

.
Proof. See Appendix A.
5
Algorithm for Finding Optimal Conﬁgurations
This section presents an algorithm for determining the conﬁguration of a rain-
bow table with ﬁngerprints. Up to now, the conﬁgurations for checkpoints and
endpoint truncation were found empirically.
5.1
Hill Climbing
Hill Climbing [21] is a local search technique designed to obtain a local optimum
of a function f using an iterative procedure. If f has a single local optimum
which is thus the global optimum (in our case, minimum), it will be found by
in a ﬁnite (and small) number of steps with Hill Climbing. The idea is the
following. Let f : X →R be the target function of which one wants to ﬁnd
the global minimum. We start with an initial x0 ∈X, and each step consists
in exploring the neighbors of the current point, evaluating f in these neighbor
positions, and comparing these values to that of the current position. The new
current point is then set to be the neighbor that minimized f among all the
neighbors. The search goes on until a situation where all neighbor have small
values through f than the current point, which consists in a local minimum.
The deﬁnition of neighbor depends on the application, but when minimizing
a discrete function, it is rather straightforward. An additional improvement that
we used in order to accelerate the search is starting with a large step, and
decreasing it gradually whenever the search stalls, until the step is suﬃciently
small.
See [21] for a more thorough description of the Hill Climbing algorithm.
www.ebook3000.com

366
G. Avoine et al.
5.2
Application to Checkpoint Functions
As shown in Sect. 4, the performance of the rainbow tables with ﬁngerprints
strongly depends on their conﬁguration.
One way to ﬁnd the best conﬁguration for the checkpoint functions is to apply
a brute-force technique to compute T for the (1 + ⌈log2 N⌉)t possibilities (from
0 to ⌈log2 N⌉bits included for each column), and keep the one that minimizes
T. This however is not feasible for any practical instance, because the parameter
space is too large. Instead, Hill climbing is used, as described in Sect. 5.1, to
compute these conﬁgurations eﬃciently. In order to apply it, the two following
assumptions are made.
First, all the non-ϵ checkpoint functions, except the one in column t, output
exactly one bit. This hypothesis makes sense because one two-bit checkpoint in
a column or two one-bit checkpoints in adjacent columns give nearly identical
results. Moreover, we observed experimentally that good conﬁgurations tend to
have their non-ϵ checkpoints scattered, except in the last column where a more
important concentration is more eﬃcient. This tendency is most likely explained
by Type-II false alarms.
Then, it is assumed that the local minimum is a global minimum (that is, T
is unimodal with respect to the positions of the one-bit checkpoints). This has
been observed experimentally.
Note that this technique is conservative in the sense that if either assumption
is not veriﬁed, then the real optimal conﬁguration can only lead to yet better
performance. In the following, the “optimal conﬁgurations” refer to the best
solutions found using this approach. The determination of the conﬁguration is
of course only done once, before the precomputation phase, and adds a marginal
overhead to its cost.
The overall technique that we used to ﬁnd the optimal conﬁgurations is
displayed in Algorithm 1. The variables nbits and ncp represent respectively
the number of bits for a ﬁngerprint (that is, nbits = t
i=1 σi) and the number
of one-bit non-ﬁnal checkpoints (that is, ncp = nbits−σt). The values nbitsmin
and nbitsmax represent the range of search of nbits. In theory, this goes from 1
up to t×⌈log2 N⌉, but it is impractical to explore that range. These bounds need
to be deﬁned heuristically. In our experiments, we found out that it is hardly
necessary to search beyond, say [0.75⌈log2 N⌉, . . . , 1.25⌈log2 N⌉]. The same holds
for the values ncpmin and ncpmax, which represent the range of search of ncp.
Again, in theory these bounds are respectively 0 and nbits, but in practice,
we observed that the optimal conﬁguration is in most cases in a range of about
[0.1 nbits, . . . , 0.4 nbits].
Finally, we observed that there is an clear constancy in the optimal positions
for the one-bit checkpoints, as represented in Fig. 2. One can notice that, for a
given ncpopt, the relative positions of the one-bit checkpoints remain the same.
When ncpopt changes (as is the case between N = 244 and N = 246 for instance),
the relative checkpoint positions change as well, although they retain the same
structure. Although we did not ﬁnd an analytic way to use this, one could spare
the somewhat tedious procedure exposed in this section by using known optimal

Analysis of Rainbow Tables with Fingerprints
367
Algorithm 1. Algorithm for ﬁnding optimal conﬁgurations of rainbow tables
with ﬁngerprints.
Input: N, M, ℓ
bestcfg ←∅
for nbits ∈[nbitsmin, . . . , nbitsmax] do
m ←M/(ℓ× nbits)
t ←2N/m −1
for ncp ∈[ncpmin, . . . , ncpmax] do
newcfg ←Hill Climbing on T with ncp one-bit checkpoints and a ﬁnal (nbits−
ncp)-bits checkpoint
if T(newcfg) < T(bestcfg) then
bestcfg ←newcfg
end if
end for
end for
return bestcfg
Fig. 2. Repartition of one-bit checkpoints relatively to t
relative checkpoint positions, or using them as initial starting points for the Hill
Climbing search.
6
Theoretical and Experimental Results
6.1
Theoretical Results
Table 2 presents the gain 1 −Tﬁngerprint/Tregular between rainbow tables with
ﬁngerprints in optimal conﬁgurations and regular rainbow tables, for diﬀerent
sizes of key space and memory dedicated to the tradeoﬀ. The value ℓ= 4 is
considered in both cases5, and m and t are set for regular rainbow tables to the
5 This value for ℓrepresents an overwhelming success probability, and is the default
in Ophcrack [20], for instance. Other values of ℓlead to very similar results.
www.ebook3000.com

368
G. Avoine et al.
Table 2. Gain of rainbow tables with ﬁngerprints over regular rainbow tables for
various N and M
238
240
242
244
246
248
2GB
32.48%
35.94%
39.01%
41.73%
44.16%
46.35%
4GB
30.76%
34.36%
37.54%
40.36%
42.88%
45.14%
8GB
29.04%
32.76%
36.05%
38.97%
41.58%
43.93%
optimal values as presented in [2]. For the ﬁngerprint version, Algorithm 1 is
used to ﬁnd the optimal conﬁgurations.
Table 2 is ﬁlled with memory sizes that belong to a reasonable range for
an average personal computer. Note that M denotes the memory dedicated
for endpoints/ﬁngerprints only (adding the starting points about doubles the
memory required). The problem sizes are also driven by practical considerations,
to avoid a prohibitive online search time. Analyzing the results leads to two
trends. The advantage of the rainbow tables with ﬁngerprints over the regular
version tends to increase as the memory decreases. Secondly, the gain increases
with the problem size. This behavior can be explained by the fact that when N
is large, or when M is small, t and therefore T increases, and there is thus more
freedom in the conﬁguration of the checkpoint functions.
Table. 3 lists diﬀerences in the parameters and results between rainbow tables
with ﬁngerprints in optimal conﬁguration and regular rainbow tables in several
settings. Again, the memory M is the one dedicated to endpoint/ﬁngerprint
storage (identical in both cases). The row “Positions” corresponds to the set
of columns associated with a one-bit checkpoint. In the optimal conﬁgurations
found, all checkpoints but the one in the last column consist of at most one
bit, as described in Sect. 5.2. The use of the following checkpoint functions are
assumed:
Φi : A →{0, 1}σi
x →

lsbσi(x)
if σi > 0
ϵ
otherwise,
where lsbn(x) is a function that outputs the n least signiﬁcant bits of x.
One can observe that when additional memory is available, the optimal solu-
tions tend to use some extra memory per chain, and vice versa. Additionally, it
is noteworthy that the cost of a false alarm for rainbow tables with ﬁngerprints
is around one third of the one for regular rainbow tables.
6.2
Experimental Validation
A time-memory tradeoﬀwith rainbow tables with ﬁngerprints has been imple-
mented in order to illustrate the theory with experimental results. We considered

Analysis of Rainbow Tables with Fingerprints
369
Table 3. Analytical performance for the best conﬁgurations of rainbow tables with
ﬁngerprints
(a) N = 248, M = 2GB
regular
rainbow
tables
rainbow tables with ﬁn-
gerprints
m
4.47 × 107
4.88 × 107
|Ej|, |Fj|
48
40
t
1.26 × 107
1.15 × 107
T
2.32 × 1013
1.24 × 1013 (−46.35%)
Average FA cost
1.33 × 1013
0.41 × 1013 (−68.88%)
Positions
8476358, 9172110, 9663530, 10050060, 10371170, 10647046,
10889558, 11106326, 11302572, 11482032
(b) N = 248, M = 4GB
regular
rainbow
tables
rainbow tables with ﬁn-
gerprints
m
8.95 × 107
9.65 × 107
|Ej|, |Fj|
48
41
t
6.29 × 106
5.83 × 106
T
5.79 × 1012
3.18 × 1012 (−45.14%)
Average FA cost
3.33 × 1012,
1.06 × 1012 (−68.20%)
Positions
4285001,
4636802,
4885286,
5080733,
5243100,
5382597,
5505222, 5614831, 5714062, 5804807
(c) N = 248, M = 8GB
regular
rainbow
tables
rainbow tables with ﬁn-
gerprints
m
1.79 × 108
1.89 × 108
|Ej|, |Fj|
48
43
t
3.15 × 106
2.98 × 106
T
1.45 × 1012
0.81 × 1012 (−43.93%)
Average FA cost
8.31 × 1011
2.58 × 1011 (−68.99%)
Positions
2155147,
2334199,
2460731,
2560281,
2642997,
2714070,
2776554, 2832410, 2882981, 2929230, 2971872
NTLM Hash alphanumeric (both lowercase and uppercase) passwords of length
1 to 7, which represents a search space of N = 7
i=1 62i ≈241.70. Considering
longer passwords would better emphasize the performance of the rainbow tables
with ﬁngerprints, but we were time-constrained for the precomputation of the
tables.
www.ebook3000.com

370
G. Avoine et al.
The parameters are m = 5.03 × 108, t = 13554, ℓ= 4. Preﬁx/suﬃx decom-
position [1] was also used in order to save some extra memory, but this has no
inﬂuence on the online performance (it decreases M, the memory used in prac-
tice, but not m, the number of chains). The four tables take up about 14.8GB in
total. Using the methodology described in Sect. 5.2, the following conﬁguration
was found:
Φi(x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
lsb1(x)
if i ∈{10077, 10928, 11530, 12004,
12398, 12736, 13034, 13301}
lsb34(x)
if i = 13554
ϵ
otherwise.
The results of our experiment are presented in Table 4. It shows that the
practice matches with the theoretical estimations.
Table 4. Theoretical and experimental (average of 25000 searches) results for NTLM
problem
Theoretical
Experimental
# operations total (×106)
19.88
19.29
# operations for false alarms (×106)
7.28
7.15
# false alarms
716.57
697.15
The precomputing phase for these tables took roughly a month on about a
hundred machines. The online phase takes place on a machine with a i7-3770
CPU and 16GB of RAM. Recovering any alphanumeric NTLM Hash password
(whose length is 1 to 7 characters) in this setting takes 3.5 seconds on average.
7
Conclusion
This paper uniﬁes checkpoints and endpoint truncation improvements for rain-
bow tables in a new model, in which ﬁngerprints of chains are stored rather
than endpoints. This new model highlights that endpoints (truncated or not)
and checkpoints have the same nature. An analysis of the average search time
of rainbow tables with ﬁngerprints is presented, and corroborated with imple-
mentation results. A method to search for optimal parameters is proposed. Up
to our knowledge, there was up to now no systematic method to ﬁnd checkpoint
positions. Rainbow tables with ﬁngerprint present, in optimal conﬁguration, a
speedup of about two, with respect to the regular rainbow tables.
References
1. Avoine, G., Junod, P., Oechslin, P.: Time-Memory Trade-Oﬀs: False Alarm Detec-
tion Using Checkpoints. In: Maitra, S., Veni Madhavan, C.E., Venkatesan, R. (eds.)
INDOCRYPT 2005. LNCS, vol. 3797, pp. 183–196. Springer, Heidelberg (2005)

Analysis of Rainbow Tables with Fingerprints
371
2. Avoine, G., Junod, P., Oechslin, P.: Characterization and improvement of time-
memory trade-oﬀbased on perfect tables. ACM Trans. Inf. Syst. Secur., 11:17:1–
17:22, July 2008
3. Babbage, S.: A space/time tradeoﬀin exhaustive search attacks on stream ciphers.
In: European Convention on Security and Detection 408 (1995)
4. Barkan,
E.,
Biham,
E.,
Shamir,
A.:
Rigorous
Bounds
on
Cryptanalytic
Time/Memory Tradeoﬀs. In: Dwork, C. (ed.) CRYPTO 2006. LNCS, vol. 4117,
pp. 1–21. Springer, Heidelberg (2006)
5. Biryukov, A., Mukhopadhyay, S., Sarkar, P.: Improved Time-Memory Trade-Oﬀs
with Multiple Data. In: Preneel, B., Tavares, S. (eds.) SAC 2005. LNCS, vol. 3897,
pp. 110–127. Springer, Heidelberg (2006)
6. Gentry, C., Jonsson, J., Stern, J., Szydlo, M.: Cryptanalysis of the NTRU Signature
Scheme (NSS) from Eurocrypt 2001. In: Boyd, C. (ed.) ASIACRYPT 2001. LNCS,
vol. 2248, pp. 1–13. Springer, Heidelberg (2001)
7. Biryukov, A., Shamir, A., Wagner, D.: Real Time Cryptanalysis of A5/1 on a PC.
In: Schneier, B. (ed.) FSE 2000. LNCS, vol. 1978, pp. 1–18. Springer, Heidelberg
(2001)
8. Bono, S., Green, M., Stubbleﬁeld, A., Juels, A., Rubin, A., Szydlo, M.: Security
Analysis of a Cryptographically-Enabled RFID Device. In: 14th USENIX Security
Symposium - USENIX 2005, , Baltimore, Maryland, USA, pp. 1–16. USENIX,
July-August 2005
9. De, A., Trevisan, L., Tulsiani, M.: Time Space Tradeoﬀs for Attacks against One-
Way Functions and PRGs. In: Rabin, T. (ed.) CRYPTO 2010. LNCS, vol. 6223,
pp. 649–665. Springer, Heidelberg (2010)
10. Denning, D.: Cryptography and Data Security, page 100. Addison-Wesley, Boston
(1982)
11. Fiat, A., Naor, M.: Rigorous time/space tradeoﬀs for inverting functions. In: ACM
Symposium on Theory of Computing, STOC 1991, New Orleans, Louisiana, USA,
pp. 534–541. ACM (May 1991)
12. Goli´c, J.D.: Cryptanalysis of Alleged A5 Stream Cipher. In: Fumy, W. (ed.) EURO-
CRYPT 1997. LNCS, vol. 1233, pp. 239–255. Springer, Heidelberg (1997)
13. Hellman, M.: A cryptanalytic time-memory trade oﬀ. IEEE Transactions on Infor-
mation Theory, IT-26(4), 401–406 (1980)
14. Hong, J.: The cost of false alarms in hellman and rainbow tradeoﬀs. Designs, Codes
and Cryptography 57(3), 293–327 (2010)
15. Kim, J.W., Seo, J., Hong, J., Park, K., Kim, S.-R.: High-Speed Parallel Imple-
mentations of the Rainbow Method in a Heterogeneous System. In: Galbraith,
S., Nandi, M. (eds.) INDOCRYPT 2012. LNCS, vol. 7668, pp. 303–316. Springer,
Heidelberg (2012)
16. Lee, G.W., Hong, J.: A comparison of perfect table cryptanalytic tradeoﬀalgo-
rithms. Cryptology ePrint Archive, Report 2012/540 (2012)
17. Mentens, N., Batina, L., Preneel, B.: Ingrid Verbauwhede. Cracking Unix pass-
words using FPGA platforms. SHARCS - Special Purpose Hardware for Attacking
Cryptographic Systems, February 2005
18. Nohl, K.: Attacking phone privacy. Blackhat - White Paper (2010)
19. Oechslin, P.: Making a Faster Cryptanalytic Time-Memory Trade-Oﬀ. In: Boneh,
D. (ed.) CRYPTO 2003. LNCS, vol. 2729, pp. 617–630. Springer, Heidelberg (2003)
20. Oechslin, P.: The ophcrack password cracker (2013). http://ophcrack.sourceforge.
net/
www.ebook3000.com

372
G. Avoine et al.
21. Russell, S.J., Norvig, P.: Artiﬁcial intelligence: a modern approach, vol. 2. Pearson
Education (2003)
22. Saarinen, M.-J.O.: A Time-Memory TradeoﬀAttack Against LILI-128. In: Daemen,
J., Rijmen, V. (eds.) FSE 2002. LNCS, vol. 2365, pp. 231–236. Springer, Heidelberg
(2002)
A
Proof of Theorem 5
Given the online phase described in Sect. 3, we have:
T =
ℓt

k=1
pkTk + pfailTℓt,
(7)
with pfail and pk the probabilities that the attack fails, and that it succeeds after
k steps respectively. Here, Tk denotes the average amount of evaluations of h
when the attack stops after k steps.
Determination of pk and pfail:
The probability that the current point is found in a column is m/N, and pk is
the probability that the current point is found in a column, but is not found in
the preceding k −1 searches:
pk = m
N

1 −m
N
k−1
.
(8)
The probability of failure pfail is simply the probability that the current point is
not found in any of the ℓt previous searches, that is:

1 −m
N
ℓt
.
(9)
Determination of Tk:
At each step, h is computed for the following reasons: when building the online
chain (this work is noted W), and when ﬁltering false alarms (noted Q), hence
Tk = Wk + Qk.
Determination of Wk:
At step k, we begin the ﬁngerprint comparison at column
ck =
k −1
ℓ

.
The number of h computations needed for the online chain is simply ck. Conse-
quently,
Wk =
k

i=1
ci.
(10)

Analysis of Rainbow Tables with Fingerprints
373
Determination of Qk:
Similarly, for each false alarm, a chain has to be computed from the start to the
current column, needing t −ck computations. Hence, we have:
Qk =
k

i=1
(t −ci)FAci,
(11)
with FAc the average number of false alarms after c columns. False alarms in
rainbow tables with ﬁngerprints are of two types. Type-I false alarms are the
same as the ones in rainbow tables and occur because of merges induced by
reduction functions. Type-II false alarms occur because two chains may have
the same partial ﬁngerprint. We will respectively denote by Pc and Ec the aver-
age number of Type-I and Type-II false alarms after c columns. In the following,
all alarms (that is, including the one true alarm) are counted as false alarms, for
the sake of simplicity. The resulting loss in accuracy is negligible.
Determination of Pc:
Because the tables are perfect, there can be at most one Type-I false alarm per
step. This false alarm, if it exists, is due to a chain merging with the online chain,
somewhere between the start of the online chain and the last column. Moreover,
for this chain to cause a false alarm, the partial ﬁngerprint must match before
the merge as well. That is,
Pc =
c

i=1
Pr(partial ﬁngerprints match | not merged up to i)
× Pr(Online chain merges in i)
=
c

i=1
⎛
⎝
t−i

j=t−c
φj
⎞
⎠zi−1,c −zi,c
N
,
(12)
with
zi,c = m(1 + c −i) + (c −i)(c −i + 2)
i2

mi + 2N log

1 −mi
2N

,
(13)
z0,c = m(1 + c)

1 −mc
4N

.
Equation (13) represents the number of chains in column t −c that merge with
one of the m chains of the precomputed table in column t −i. It was computed
in Propositions 4 and 5 of [14]. Equation (12) is a generalization of equation
(1) in [15] for where checkpoints appear in every column and are of potentially
more than one bit. The ﬁrst factor of each term represents the probability that
the online chain (which has not yet merged with any chain of the precomputed
table) shares partial ﬁngerprints with the chain of the precomputation table it
will eventually merge with. The second factor represents the probability that the
online chain will merge at that step.
www.ebook3000.com

374
G. Avoine et al.
Determination of Ec:
The probability of having a merge between columns c and t, already identiﬁed
in [2], is qc = 1 −t
i=c

1 −mi
N

. Considering that the probability that the
online chain merges with a chain of the table is qc, there are, on average, m −qc
non-merging chains. Among those, each creates a Type-II FA with probability
t
i=c φi, which gives:
Ec = (m −qc)
t
i=c
φi.
(14)
Using equations (8), (9), (10), (11), (12), (13), and (14) into (7) gives (6), allowing
us to conclude.
⊓⊔

Privacy Protocols
www.ebook3000.com

A New Public Remote Integrity Checking
Scheme with User Privacy
Yiteng Feng1, Yi Mu1, Guomin Yang1(B), and Joseph K. Liu2
1 Centre for Computer and Information Security Research,
School of Computing and Information Technology,
University of Wollongong, Wollongong, Australia
yf579@uowmail.edu.au, {ymu,gyang}@uow.edu.au
2 Faculty of Information Technology, Monash University, Melbourne, Australia
joseph.liu@monash.edu
Abstract. With a cloud storage, users can store their data ﬁles on a
remote cloud server with a high quality on-demand cloud service and are
able to share their data with other users. Since cloud servers are not usu-
ally regarded as fully trusted and the cloud data can be shared amongst
users, the integrity checking of the remote ﬁles has become an impor-
tant issue. A number of remote data integrity checking protocols have
been proposed in the literature to allow public auditing of cloud data
by a third party auditor (TPA). However, user privacy is not taken into
account in most of the existing protocols. We believe that preserving the
anonymity (i.e., identity privacy) of the data owner is also very importa
nt in many applications. In this paper, we propose a new remote integrity
checking scheme which allows the cloud server to protect the identity
information of the data owner against the TPA. We also deﬁne a formal
security model to capture the requirement of user anonymity, and prove
the anonymity as well as the soundness of the proposed scheme.
Keywords: Data integrity · Identity privacy · Public auditing · Cloud
storage
1
Introduction
Cloud computing oﬀers various kinds of computation and storage services to
end users via computer networks, and is becoming very popular nowadays. One
of the major services is cloud storage which allows users to store their data
ﬁles remotely and access the ﬁles anywhere any time. It has greatly reduced
the burden for local storage management and maintenance. Some commerical
products such as Google Drive and Dropbox have become very popular for both
individuals and enterprises.
However, after the data owners outsource their ﬁles to the cloud server and
delete the local copies, the server may not store the ﬁles correctly due to various
J.K. Liu—Joseph K. Liu is supported by National Natural Science Foundation of
China (61472083).
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 377–394, 2015.
DOI: 10.1007/978-3-319-19962-7 22

378
Y. Feng et al.
reasons such as system crash or deliberately deleting some data blocks that are
seldom or never used in order to save the cost. Moreover, the server may try
to hide the accidents or misbehaviours to the end users. In order to detect or
prevent this kind of situations, we need to audit the integrity of remote ﬁles
either periodically or before downloading. Many protocols have been proposed
for auditing the ﬁle integrity and retrievability in remote storage, such as Proof
of Data Possession (PDP) [1] and Proof of Retrievability (PoR) [6,7]. These
protocols utilised spot-checking techniques such as homomorphic authenticators
to make the auditing more eﬃcient.
Recently, some additional security and usability properties have been pro-
posed and formalised for Remote Integrity Checking (RIC) protocols [4,11,12],
including public auditing (i.e., the data auditing can be performed by a
third-party auditor), batch auditing, and privacy-preserving auditing (i.e., the
third-party auditor cannot learn any information about the ﬁle during the audit-
ing process). These properties are achieved by extending the previous work on
homomorphic authenticators and zero-knowledge proof systems.
Since users may frequently modify the ﬁles by inserting, updating and delet-
ing the ﬁle blocks, data dynamic operations have also been considered in some
recent RIC protocols. In [13,14], a Merkle Hash Tree (MHT) is employed to
achieve this goal where the structure of a ﬁle is represented using a MHT. Later,
a more eﬃcient scheme was proposed by Yang and Jia in [15] where an index
table is maintained by a ﬁxed TPA in order to keep track of the data changes.
Although Yang and Jia’s scheme is more eﬃcient than the MHT approach pro-
posed in [14], the TPA must be ﬁxed for a speciﬁc ﬁle, which can be considered
as a limitation of the scheme. Some RIC protocols [9] have also considered ﬁle
sharing among a group of users, where the technique of proxy-resign is used to
allow authenticators to be transferred from a leaving member to another staying
member in the group.
In this paper, we focus on another important and desirable property of RIC
protocols: identity privacy (i.e., anonymity) of the data owner against outsiders
and the TPA. Such a problem has been studied in [10] where a ring signature (i.e.,
authenticator) rather than an ordinary one is generated for each data block by
the data owner. Nevertheless, there is an issue in this protocol: in order to allow
data dynamic operations, a virtual index is used for each ﬁle block. Since the
cloud server maintains the virtual index table, it can always redirect the challenge
for a corrupted ﬁle block to an uncorrupted one in order to pass the veriﬁcation.
Details of this issue will be shown in Appendix A. A similar problem has also
been considered in [8] where a group signature is used as the authenticator for
each block. However, the group manager is still able to reveal the identity of
signer and it is not easy to set up that kind of group.
Identity privacy is essential in many scenarios. For example, a group of users
may prefer anonymous ﬁle sharing for some reasons such as fear of retribution
for disclosure. Besides, censorship is usually required in local, organizational or
national level applications such as anonymous bidding. A group of bidders will
place their bids which are actually ﬁles on the cloud storage and the identity of
www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
379
bidders should be conﬁdential during assessment. At the same time, the assess-
ment community would like to ensure the integrity of ﬁles periodically or before
they retrieve a ﬁle.
In this paper, we propose a new RIC protocol with user anonymity. Diﬀering
from the protocol in [10], we consider the user anonymity in ﬁle level instead
of data block level in order to save the storage and communication overheads.
In the current work, we only focus on static ﬁles and leave the support of data
dynamic operations as the future work.
Our Contribution. We formalise the notion of user anonymity for RIC pro-
tocols. In our RIC anonymity model, we consider the TPA as the adversary
who aims to discover the identity of the ﬁle owner during the RIC proof with
the cloud server. Then we construct an identity privacy-preserving RIC proto-
col based on the ring signature scheme proposed by Boneh et al. in [2], which
is a variant of BLS signature [3]. The protocol is very practical because of the
homomorphic property of the underlying signature scheme. Moreover, the proto-
col also supports batch veriﬁcation such that the TPA can verify several proofs
simultaneously using one veriﬁcation equation. We prove that the proposed pro-
tocol can ensure data integrity while preserving identity privacy. In addition,
this protocol can be also extended to support the privacy of audited ﬁles (which
is deﬁned as IND-Privacy in [4]).
Paper Organisation. The rest of the paper is organised as follows. In Section 2,
we give the system model and security deﬁnition of the protocol. In Section 3,
we present our identity privacy preserving remote integrity check protocol. We
analyse the security of the proposed scheme in Section 4. We provide some
extensions in Section 5. We conclude the paper in Section 6. The details of an
attack on an existing scheme and the security proofs of the proposed scheme are
given in Appendices.
2
System Model and Security Deﬁnition
Fig. 1 is an overview of the system. The basic case is that d users stored d ﬁles
on the cloud server, and each of them owns one ﬁle. None of the users wants the
TPA to link their identity with the ﬁle. The system can be easily extended to a
more general setting where one user stores multiple ﬁles on the cloud server.
Users ﬁrst form a group to preserve anonymity from the TPA. Then they
outsource their ﬁles to the cloud individually. From the ﬁle level point of view,
a ﬁle has one ﬁle tag, one glue value, some auxiliary information. From the
block level point of view, one authenticator is attached to each block. During
the auditing process, the ﬁle tags are public to the TPA but other information
is kept secret.
After that, this group of users delegate the auditing task for the outsourced
ﬁles to any TPA. Either periodically or at speciﬁc times, the TPA will challenge
the cloud server for the storage of the outsourced ﬁles. The cloud server will then
generate a short response for the challenge based on the information it has.

380
Y. Feng et al.
Fig. 1. System Model
Now we are going to describe the formal deﬁnition of an RIC protocol as well
as the soundness and anonymity game.
2.1
Anonymous RIC Protocols
There are three types of parties in an anonymous RIC protocol: a group of
users, the cloud server, and the TPA. An anonymous RIC scheme consists of the
following algorithms:
– Setup: This algorithm takes a security parameter λ and generates the public
parameters mpk for the whole system.
– KeyGen: This algorithm takes as input mpk and generates the public and
private key pair (pki, ski) for each user.
– TokenGen: This algorithm takes as input a ﬁle F, and the owner’s private
key sk, to generate a ﬁle tag t, and the authenticator σ for each ﬁle block.
– GlueGen: This algorithm takes as input the public keys of all group users
{pki} and the owner’s private key sk to generate a glue value θ and auxiliary
information {b} for anonymous public auditing.
– Challenge: Given the ﬁle tag t, this algorithm generates the challenge chal
for cloud server.
– Response: Taking as input (F, t, {σ}, θ, {b}, chal, mpk), this algorithm out-
puts a proof P to prove the integrity of the ﬁle.
– Verify: Taking as input ({pki}, mpk, t, chal, P), this algorithm outputs true
or false to indicate whether the ﬁle is stored correctly.
2.2
RIC Anonymity
Since we want to ensure that the TPA cannot distinguish the identity of the real
ﬁle owner from other users in the group during multiple runs of the protocol,
www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
381
we ﬁx the owner at the beginning of the adversarial game, and then allow the
adversary to ask multiple proof queries. The Anonymity for an RIC scheme is
deﬁned via an Anonymity game between a challenger C (i.e. the cloud server or
prover) and an Adversary A (i.e. the TPA or veriﬁer) as follows.
– Setup: The challenger C runs Setup and KeyGen to generate the public
parameters and the key pairs for a group of users U1, U2, ..., Ud and passes
all the public keys to the Adversary A. Also, C randomly chooses a user
b ∈[1, d] to be the real signer.
– Phase 1: A can ask for tag queries. In each query, A can choose a ﬁle F
to be stored and C generates the ﬁle tag, the authenticators, the glue value
and the auxiliary information for the ﬁle. Only the ﬁle tag t is returned to
A. A can ask multiple tag queries for diﬀerent ﬁles.
– Phase 2: A uses the ﬁle tag t of ﬁle F which appeared in Phase 1 to
generates the chal to ask for proof from C. Then, C generates the proof P
and sends P to A. In this phase, A can also ask multiple proof queries.
– Decision: A output b′ as the guess of b.
Deﬁne the advantage of adversary A as AdvA(λ) = | Pr[b′ = b] −1/d|.
Deﬁnition 1. We say an RIC scheme has anonymity if for any polynomial-time
algorithm A, AdvA(λ) is a negligible function of the security parameter λ.
2.3
RIC Soundness
We say a protocol is sound if it is infeasible for the cloud server to modify the
content of a ﬁle without being detected by the TPA in the auditing. We deﬁne
the soundness games between a challenger C and an adversary A as follows:
– Setup: C runs Setup and KeyGen to generate the key pairs for a group
of users. C then chooses the ﬁrst user as the real signer and passes all the
public keys to the Adversary.
– Phase 1: A makes multiple queries to C for TokenGen and GlueGen on
any ﬁle F. C generates the ﬁle tag t, authenticators σ, and the glue value θ
and auxiliary information {b} using the secret key of the ﬁrst user, and then
returns (t, {σ}, θ, {b}) to A.
– Phase 2: A outputs a ﬁle F ′ and a ﬁle tag t′ such that t′ = t but F ′ ̸= F for
some (F, t) appeared in Phase 1 (i.e., at least one block of F is corrupted).
C then plays the role as the veriﬁer and executes the RIC protocol with A
by sending a challenge chal which contains at least one corrupted block.
– Decision: C makes a decision which is either True or False after verifying
the proof P ′ generated by the adversary A.
Deﬁnition 2. We say a RIC protocol is ε-sound if Pr[C outputs True] ≤ε.

382
Y. Feng et al.
3
The Proposed Scheme
3.1
Notation
Let G1, G2 and GT be three multiplicative cyclic groups of prime order p. Let
g1 and g2 be the generators of G1 and G2 respectively. The bilinear map e :
G1 × G2 →GT should have the following properties:
– Bilinear: We say that the map is bilinear if e(ua, hb) = e(u, h)ab for all
u ∈G1, h ∈G2, a, b ∈Zp.
– Non-degenerate: The map does not send all pairs in G1 × G2 to the identity
in GT . As they are prime order groups, e(g1, g2) is a generator of GT .
– Computable: There is an eﬃcient algorithm to compute e(u, h) for any u ∈
G1, h ∈G2.
– Isomorphism: In addition, there should be a computable isomorphism ψ from
G2 to G1, with ψ(g2) = g1 and e(ψ(u), h) = e(ψ(h), u) for any u, h ∈G2.
3.2
Our Anonymous RIC Scheme
We present the details of our anonymous RIC scheme.
Setup: Let (e, p, G1, G2, GT , g1, g2, ψ) be the bilinear map and associated
group parameters deﬁned as above. Choose a cryptographic hash functions
H : {0, 1}∗→G1. Choose another generator h ∈G1. Choose two ran-
dom numbers α, τ
∈Zp to generate the commitment keys: u = (u1, u2)
where u1
= (g1, gα
1 ), u2
= (gτ
1, gτα
1 ). The public parameters are mpk =
(e, p, G1, G2, GT , g1, g2, ψ, H, h, u1, u2).
KeyGen: Each user Ui randomly chooses xi ∈Zp and computes yi = gxi
2 .
Besides, each user generates a key pair (spki, sski) for a secure ring signature
scheme. The user Ui’s public key is (yi, spki), and the private key is (xi, sski).
TokenGen: The outsourced ﬁle F is ﬁrst divided into n blocks, and the ﬁle
owner s chooses a random ﬁle name name from some suﬃciently large domain
(e.g., Zp). Let t0 be “name||n”; the ﬁle tag t is t0 together with a ring signature on
t0 under the private key ssks and the public keys {spki}i̸=s: t ←t0||Sigssks(t0).
For each block mj, the signer computes: σj = (H (name||j) · hmj)1/xs .
GlueGen: For each user Ui ̸= Us, the signer chooses ai ∈Zp, and computes
the auxiliary information: bi = gai
1 . Then the signer computes a glue value
θ = 1

ψ
n
i̸=s yai
i
1/xs
. Finally, the user sends {F, t, {σj}j∈[1,n], {bi}i∈[1,d], θ}
to the cloud server. We shows the computation and communication between
client and server in Fig. 2.
Challenge: The TPA ﬁrst retrieves the ﬁle tag t and veriﬁes the ring signature
Sigssks(t0) based on the user public keys of all the users in the ring. The TPA
quits by emitting False if the veriﬁcation fails. Otherwise, the TPA recovers
www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
383
Client
Communication
Cloud Server
1. Divide F into n block.
Choose name ∈Zp.
Let t0 = name||n,
t ←t0||Sigssks(t0).
2. For each block mj, compute:
σj = (H(name||j) · hmj)1/xs
3. For user ui ̸= us,
choose ai ∈Zp,
compute: bi = gai
1
4. Compute a glue value:
θ = 1

ψ
n
i̸=s yai
i
1/xs
5. Outsource the ﬁle to Cloud.
{F, t, {σ}, {b}, θ}
−−−−−−−−−−−−−−→
6. Delegate the auditing to TPA.
Fig. 2. Storing a ﬁle
name, n. Then the TPA picks c elements in set [1, n], where n is the total number
of ﬁle blocks, to indicate the blocks that will be checked. J denotes the subset of
[1, n] that contains all the chosen indices. For j ∈J, the TPA randomly chooses
cj ∈Zp. Finally the TPA sends {(j, cj)}j∈J to the cloud server as a challenge.
Response: Upon receiving the challenge {(j, cj)}j∈J, the cloud server com-
putes μ = 
j∈J cjmj , and Σs = 
j∈J σcj
j · θ , Σi = bi for all i ̸= s . Given
(μ, {Σ}), the TPA can use the following equation to check the integrity of the
ﬁle e

j∈J H(name||j)cj · hμ, g2

= d
i=1 e (Σi, yi) .
However, if we run the above protocol for multiple times, the values of μ and
Σs will change depending on the challenge, while other Σi will remain static,
which will reveal the identity of the ﬁle owner. To address this issue, we make
use of the Groth-Sahai Proof System [5] to hide all the {Σ} while convincing the
TPA they are correct. So in the modiﬁed Response algorithm, using the system
public key u as the commitment key, the cloud server computes commitments
as: c = (c1, c2, ..., cd), where
c1 = (c11, c12) = (gr11+r12τ
1
, gα(r11+r12τ)
1
Σ1) = (ur11
11 ur12
12 , ur11
21 ur12
22 Σ1)
c2 = (c21, c22) = (gr21+r22τ
1
, gα(r21+r22τ)
1
Σ2) = (ur21
11 ur22
12 , ur21
21 ur22
22 Σ2)
...
cd = (cd1, cd2) = (grd1+rd2τ
1
, gα(rd1+rd2τ)
1
Σd) = (urd1
11 urd2
12 , urd1
21 urd2
22 Σd)
where rij(i ∈[1, d], j ∈{1, 2}) is randomly selected from Zp.

384
Y. Feng et al.
The proof becomes: π = (π1, π2) where π1 = (1, yr11
1 yr21
2 ...yrd1
d
) and π2 =
(1, yr12
1 yr22
2 ...yrd2
d
). Finally, (μ, c, π) are sent to TPA instead of (μ, {Σ}).
Verify: First, we deﬁne the ⋆operator as x⋆y = F(x1, y1)F(x2, y2)...F(xn, yn),
where
F(xi, yi) =
e(xi1, yi1) e(xi1, yi2)
e(xi2, yi1) e(xi2, yi2)

for (xi1, xi2) ∈G2
1, (yi1, yi2) ∈G2
2, i ∈[1, n].
To do the veriﬁcation, TPA ﬁrst performs the transformation on the original
veriﬁcation equation as follows.
– Transform Left Hand Side: l = (l1, l2) where l11 = (1, 1) and l12 = (1, L),
where L = e

j∈J H(name||j)cj · hμ, g2

.
– Transform Public Keys: k = (k1, k2, ..., kd) where k1 = (1, y1) and k2 =
(1, y2) ... kd = (1, yd)
The veriﬁer then performs the veriﬁcation via the following equation: l(u ⋆
π) = c ⋆k. Please note that here we use the Hadamard product of the matrix.
We show the computations and message ﬂows between TPA and cloud server in
Fig. 3. The correctness of both the non-anonymous and anonymous veriﬁcation
equations are proved in Appendix B.
4
Security Analysis
4.1
Anonymity of the Protocol
External Diﬃe-Hellman (XDH) Assumption: Groth-Sahai proof system
in [5] is under the assumption SXDH, where the DDH problem is hard in both
G1 and G2. But we need to have isomorphism to generate the glue value, so
we will just assume DDH is hard in G1. Let gk = (λ, p, G1, G2, GT , e, g1, g2),
deﬁne a bilinear map e : G1 × G2 →GT and isomorphism from G2 to G1, with
ψ(g2) = g1. The XDH assumption holds if we have
| Pr[A(gk, ψ, gx
1, gy
1, gxy
1 ) = 1] −Pr[A(gk, ψ, gx
1, gy
1, gz
1) = 1]| ≤ϵ
where x, y, z ←Z∗
p.
Theorem 1. Our new anonymous RIC protocol has identity privacy if XDH
assumption holds.
4.2
Soundness of the Protocol
Co-CDH Problem: Given (G1, G2, g1, g2, h = ga
1, u = gb
2), Compute gab
1 . Sim-
ilar to [2], we can solve the Co-CDH problem by solving two instances of the
following problem: given (G1, G2, g1, g2, u = ga
2, h = gab
1 ), compute gb
1. We will
use this version of the Co-CDH problem to prove the soundness of our protocol.
Theorem 2. The proposed RIC scheme is negl(λ)-sound, where negl(λ) is a
negligible function of the security parameter λ, if the Co-CDH problem is hard.
The proofs of the theorems are presented in Appendix C and D.
www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
385
TPA
Communication
Cloud Server
1. Retrieve the ﬁle tag t.
Verify the signature,
and recover name, n.
2. Pick c elements in [1, n]
to form a subset J.
For each j ∈J,
choose cj ∈Zp.
3. Send Challenge to Cloud.
{(j, cj)}j∈J
−−−−−−−−−−−−−−→
1. Compute: μ = 
j∈J cjmj
2. Compute:
Σs = 
j∈J σ
cj
j · θ
and Σi = bi for all i ̸= s.
3. Commit {Σ} to c:
ci = (ci1, ci2)
= (uri1
11 uri2
12 , uri1
21 uri2
22 Σi)
where rij(i ∈[1, d], j ∈{1, 2})
is randomly selected from Zp.
4. Compute the Proof:
π = (π1, π2).
π1 = (1, yr11
1
yr21
2
...yrd1
d
)
π2 = (1, yr12
1
yr22
2
...yrd2
d
)
{μ, c, π}
←−−−−−−−−−−−−−−
5. Send Response to TPA.
4. Transform left hand side:
l = (l1, l2).
l11 = (1, 1), l12 = (1, L),
while L = e

j∈J H(name||j)cj · hµ, g2

.
5. Transform Public Keys:
k = (k1, k2, ..., kd),
where ki = (1, yi).
6. Verify the proof with
commitment key u:
l(u ⋆π) = c ⋆k.
Fig. 3. Auditing

386
Y. Feng et al.
5
Extension
5.1
Batch Auditing
Our scheme can be easily extended to support batch auditing, which can audit
multiple ﬁles for the group at the same time and save the pairing computations.
For example, for non-anonymous auditing, given two challenges for diﬀerent
ﬁles {(j, cj)}j∈J and {(j′, c′
j)}j′∈J′, the cloud server can calculate (μ, {Σ} and
(μ′, {Σ′}), and veriﬁcation equation becomes
e
⎛
⎝

j∈J
H(name||j)cj

·
⎛
⎝
j′∈J′
H(name′||j′)c′
j
⎞
⎠· hμ+μ′, g2
⎞
⎠=
d

i=1
e

Σi · Σ′
i, yi

.
For anonymous auditing, the equation for the veriﬁcation is still
l(u ⋆π) = c ⋆k .
As a result, the response from the cloud server still contains three parts
(μ + μ′, c, π) where the commitment c will hide Σi · Σ′
i instead of Σi.
It is also worth noting that during TPA veriﬁcation, L inside l will be
changed to
⎛
⎝
j∈J
H(name||j)cj
⎞
⎠·
⎛
⎝
j′∈J′
H(name′||j′)c′
j
⎞
⎠· hμ+μ′ .
5.2
IND-Privacy
We have addressed the identity privacy of users, and we can also extend the
scheme to provide the privacy of the audited ﬁles, which is deﬁned as IND-
Privacy in [4]. With IND-Privacy, the TPA is not able to distinguish which ﬁle
is being audited. The Groth-Sahai proof system [5] is also used in [4] to achieve
this goal.
The non-anonymous veriﬁcation equation of our RIC scheme
e
⎛
⎝
j∈J
H(name||j)cj · hμ, g2
⎞
⎠=
d

i=1
e (Σi, yi)
can be expressed as
e
⎛
⎝
j∈J
H(name||j)cj, g2
⎞
⎠=
d

i=1
e (Σi, yi) · e(hμ, g−1
2 ) .
Similar to [4], we can hide hμ as well as all the {Σ} in the commitment to achieve
both Anonymity and IND-Privacy. The equation is still in the form of
l(u ⋆π) = c ⋆k ,
where c and k will have extra components, and l, π need to be changed accord-
ingly.
www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
387
5.3
Data Dynamics
There is no ideal solution for supporting data dynamics at the moment. However,
if the TPA is ﬁxed, then we can make the TPA keep the index tables for the
ﬁles to keep track of all the data dynamic operations as [15] did. The cloud users
have to communicate with TPA after they update the ﬁles on cloud server.
Another solution for achieving data dynamic operations is to replace the
index information i of a data block m in the computation of the authenti-
cator, and use the Merkle Hash Tree (MHT) for the block sequence enforce-
ment. This approach has been used in [14]. The authenticator will become
σj = (H (mj) · hmj)1/xs, and every time before auditing, the root stored on
the cloud server and signed by the user will be veriﬁed ﬁrst using some auxiliary
information that allows reconstruction the MHT. The rest of our scheme remains
unchanged.
6
Conclusion
In this paper, we introduced a new security notion – RIC Anonymity for RIC
protocols. We also proposed a new RIC protocol that can preserve the identity
privacy of the ﬁle owner when the TPA audits the ﬁles stored on the cloud server.
We proved the soundness and the anonymity of the proposed protocol, and also
showed that the protocol can support batch veriﬁcations of multiple RIC proofs,
IND-Privacy, and data dynamic operations.
References
1. Ateniese, G., Burns, R., Curtmola, R., Herring, J., Kissner, L., Peterson, Z.,
Song, D.: Provable data possession at untrusted stores. In: ACM CCS, pp. 598–609
(2007)
2. Boneh, D., Gentry, C., Lynn, B., Shacham, H.: Aggregate and veriﬁably encrypted
signatures from bilinear maps. In: EUROCRYPT, pp. 416–432 (2003)
3. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the weil pairing. J. Cryp-
tology 17(4), 297–319 (2004)
4. Fan, X., Yang, G., Mu, Y., Yu, Y.: On indistinguishability in remote data integrity
checking. The Computer Journal (2013)
5. Groth, J., Sahai, A.: Eﬃcient Non-interactive Proof Systems for Bilinear Groups.
In: Smart, N.P. (ed.) EUROCRYPT 2008. LNCS, vol. 4965, pp. 415–432. Springer,
Heidelberg (2008)
6. Juels, A., Kaliski Jr., B.S.: Pors: proofs of retrievability for large ﬁles. In: ACM
CCS, pp. 584–597 (2007)
7. Shacham, H., Waters, B.: Compact Proofs of Retrievability. In: Pieprzyk, J. (ed.)
ASIACRYPT 2008. LNCS, vol. 5350, pp. 90–107. Springer, Heidelberg (2008)
8. Wang, B., Li, B., Li, H.: Knox: Privacy-Preserving Auditing for Shared Data with
Large Groups in the Cloud. In: Bao, F., Samarati, P., Zhou, J. (eds.) ACNS 2012.
LNCS, vol. 7341, pp. 507–525. Springer, Heidelberg (2012)

388
Y. Feng et al.
9. Wang, B., Li, B., Li, H.: Public auditing for shared data with eﬃcient user revoca-
tion in the cloud. In: Joint Conference of the IEEE Computer and Communications
Societies, pp. 2904–2912 (2013)
10. Wang, B., Li, B., Li, H.: Oruta: Privacy-preserving public auditing for shared data
in the cloud. IEEE Transactions on Cloud Computing 2(1), 43–56 (2014)
11. Wang, C., Chow, S.S.M., Wang, Q., Ren, K., Lou, W.: Privacy-preserving public
auditing for secure cloud storage. IEEE Transaction on Computers 62(2), 362–375
(2013)
12. Wang, C., Wang, Q., Ren, K., Lou, W.: Privacy-preserving public auditing for data
storage security in cloud computing. In: 2010 Proceedings IEEE INFOCOM, pp.
1–9, March 2010
13. Wang, Q., Wang, C., Li, J., Ren, K., Lou, W.: Enabling Public Veriﬁability and
Data Dynamics for Storage Security in Cloud Computing. In: Backes, M., Ning, P.
(eds.) ESORICS 2009. LNCS, vol. 5789, pp. 355–370. Springer, Heidelberg (2009)
14. Wang, Q., Wang, C., Ren, K., Lou, W., Li, J.: Enabling public auditability and data
dynamics for storage security in cloud computing. IEEE Transactions on Parallel
and Distributed System 22(5), 847–859 (2011)
15. Yang, K., Jia, X.: An eﬃcient and secure dynamic auditing protocol for data storage
in cloud computing. IEEE Transactions on Parallel and Distributed Systems 24(9),
1717–1726 (2013)
A
A Security Issue in Oruta
Recently, a new public auditing protocol was proposed by Wang et al. in [10]
to achieve the desirable features like public auditing, group anonymity and data
dynamics, which is described in the Literature Review. Nevertheless, we review
the protocol in [10] and show that there is a security issue in the protocol:
a dishonest cloud server can delete some data blocks in a ﬁle without being
caught by the third-party auditor. The reason is that the cloud server maintains
an index hash table in order to achieve data dynamics. During auditing process,
the cloud server answers to the identiﬁer query for challenged indices, which will
be used in the veriﬁcation, but the integrity of the identiﬁer is not ensured.
A.1
Reviewing the Protocol
Similar to most of the protocols (e.g, [11,14,15], the protocol Oruta [10] is based
on the homomorphic authenticators and spot-checking techniques. However, it
uses a ring signature [2] as the authenticator to achieve anonymity for each block.
As it is a variant of BLS signature [3], the ring signature still can be aggregated.
Besides, it uses the index hash table to support data dynamic operations. We
describe the ﬁve algorithms inside Oruta.
Setup. Let G1, G2 and GT be three multiplicative cyclic groups of prime order
p, and g1 and g2 be the generators of G1 and G2, respectively. Let e : G1 ×G2 →
GT be a bilinear map, and ψ : G2 →G1 be a computable isomorphism with
ψ(g2) = g1. Let H1 : {0, 1}∗→G1, H2 : {0, 1}∗→Zq, and h : G1 →Zp
www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
389
denote three cryptographic hash functions. The global system parameters are
(e, ψ, p, q, G1, G2, GT , g1, g2, H1, H2, h).
An outsourced data ﬁle M is divided into n blocks, and each block mj is
divided into k elements in Zp. Then, the data component M can be viewed as
an n × k matrix. Also, let d denote the number of users in the group where the
ﬁle is shared and they want to preserve identity privacy from TPA.
KeyGen. Each user ui randomly chooses xi ∈Zp and computes wi = gxi
2 . Thus,
the user ui’s public key is wi, and the private key is xi. Besides, the user who
ﬁrstly creates the ﬁle should generate a public aggregate key pak = {η1, ..., ηk},
where each ηl (1 ≤l ≤k) is a random elements of G1.
SignGen. Given all members’ public keys {w1, ..., wd}, a block mj = {mj,1, ...,
mj,k}, the identiﬁer of the block idj, a public aggregate key pak = {η1, ..., ηk}
and the private key of the signer xs, the user us generates a ring signature for
this block as follows.
1. The signer ﬁrst aggregates block mj with the public aggregate key pak, and
computes βj = H1(idj) k
l=1 ηmj,l
l
∈G1.
2. Then the signer randomly chooses aj,i ∈Zp and sets σj,i = gaj,i
1
for all
i ̸= s. And for i = s, he/she computes σj,i = (
βj
ψ(
i̸=s w
aj,i
i
))1/xs. Therefore,
the authenticator which is actually a ring signature of block mj is σj =
{σj,1, ..., σj,d}.
After the owner outsourced the ﬁle to the cloud server, any group members can
send the auditing request to a third-party auditor (TPA). With the challenge
and response process, the TPA checks the integrity of ﬁles without revealing the
identity of the owner.
ProofGen. TPA generates the challenge in the following way:
1. The TPA picks c elements in set [1, n], where n is the total number of blocks,
to indicate the blocks that will be checked. Let J denote the indices of the
chosen blocks.
2. For j ∈J, the TPA randomly chooses yj ∈Zq. Then the TPA sends
{(j, yj)}j∈J to the cloud server as a challenge message.
After receiving {(j, yj)}j∈J, the cloud server generates the proof as follows:
1. For l ∈[1, k], the cloud server randomly chooses rl ∈Zq, and computes
λl = ηrl
l ∈G1, and μl = 
j∈J yjmj,l + rlh(λl) ∈Zp.
2. For i ∈[1, d], the cloud server computes φi = 
j∈J σyj
j,i.
Then the cloud server sends the proof {{λl}l∈[1,k], {μl}l∈[1,k], {φi}i∈[1,d],
{idj}j∈J} to TPA.

390
Y. Feng et al.
ProofVeriy. After receiving the proof, and given the public aggregate key pak =
{η1, ..., ηk} and all the public keys {w1, ..., wd} of the group members, the TPA
veriﬁes the proof by checking:
e(

j∈J
H1(idj)yj ·
k

l=1
ημl
l , g2)
?= (
d

i=1
e(φi, wi)) · e(
k

i=1
λh(λl)
l
, g2)
If this equation holds, the TPA sends a positive audit report back to the request
user and vice versa.
Remarks. Instead of using the index of the block as its identiﬁer (e.g. the
index of block mj is j), this scheme utilises index hash tables. An identiﬁer
from this table is described as idj = {vj, rj}, where vj is the virtual index of
block mj, and rj = H2(mj||vj) is generated using a collision-resistance hash
function H2 : {0, 1}∗∈Zq. Here q is a prime that is much smaller than p. If
vi < vj, then block mi is in front of mj in the ﬁle. The initial virtual index
of block mj is set as vj = j · δ, where δ indicates the number of data block
that can be inserted into mj and mj+1. For example, if m′
j is inserted, then
v′
j = (vj−1 + vj)/2, r′
j = H2(m′
j||v′
j) is inserted into the index hash table; if
mj is deleted, then the corresponding entry is removed from the table. During
the computation of the authenticators and the challenge/response process, the
identiﬁers are used instead of the indices. However, the TPA does not know
about this table, so the identiﬁer needs to be returned by the cloud server.
A.2
On the Security of the Protocol
As the basic requirements of an auditing protocol, Yang and Jia [15] pointed
out that three kinds of attack must be prevented: Replace, Forge and Replay.
In the ﬁrst attack, the adversary may choose another pair of uncorrupted data
block and data tag to replace the challenged pair to generate a valid proof. In
the second attack, the adversary may try to forge a data tag for a (modiﬁed)
data block. Lastly, in the replay attack, the adversary may try to generate a
valid proof based on previous proofs or other information without retrieving the
data blocks and data tags honestly. Below we show that the Oruta scheme [10]
is vulnerable to the ﬁrst type of attack.
For simplicity, let’s consider the case where the TPA challenges for only one
block mj, and sends (j, yj) to the cloud. If mj is deliberately deleted by the
cloud server but not the user, the server can still use mj+1, σj+1 to generate a
valid proof as follows.
1. For l ∈[1, k], the cloud server randomly chooses rl ∈Zq, and computes
λl = ηrl
l ∈G1.
2. For l ∈[1, k], the cloud server also computes μl = yjmj+1,l + rlh(λl) ∈Zp.
3. For i ∈[1, d], the cloud server computes φi = σyj
j+1,i.
Then the cloud server sends the proof {{λ}, {μ}, {φ}, {idj+1} to the TPA.
www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
391
The TPA veriﬁes the proof by checking: e(H1(idj+1)yj · k
l=1 ημl
l , g2)
?=
(d
i=1 e(φi, wi)) · e(k
i=1 λh(λl)
l
, g2). Actually, this is still a valid proof as
RHS = (
d

i=1
e(σyj
j+1,i, wi) · e(
k

l=1
λh(λl)
l
, g2)
=
 d

i=1
e(σj+1,i, wi)
yj
· e(
k

l=1
ηrlh(λl), g2)
= e(βj+1, g2)yj · e(
k

l=1
ηrlh(λl), g2)
= e((H1(idj+1)
k

l=1
ηmj+1,l
l
)yj, g2) · e(
k

l=1
ηrlh(λl), g2)
= e(H1(idj+1)yj ·
k

l=1
ηyjmj+1,l+rlh(λl)
l
, g2)
= e(H1(idj+1)yj ·
k

l=1
ημl
l , g2)
Back to the normal case, since the cloud server maintains the index hash
table, it can always redirect the challenge on the corrupted blocks to uncorrupted
blocks in order to pass the veriﬁcation. The index hash table is used by Oruta
to support data dynamic operations. However, our attack essentially shows that
such a technique is not suitable since it makes the scheme vulnerable to the
Replace attack.
In [10], the authors assumed that the cloud server will return the identiﬁers
for challenged indices honestly in the soundness (Unforgeability of Response)
model and proof. However, as is known, the cloud server is treated as a soundness
adversary in Remote Integrity Check protocols. So the cloud server has the
motivation not to return the correct identiﬁers.
A.3
Recommendation
Despite of many interesting features supported by this protocol, we showed that
a dishonest cloud server can deliberately delete some data blocks in a ﬁle but
still pass the veriﬁcation. We also pointed out that the problem is caused by the
technique used in “Oruta” for allowing data dynamic operations.
Based on Yang and Jia’s scheme [15], we can let the TPA maintain the index
hash table as the cloud server is treated as the soundness adversary of the RIC
protocol. Nevertheless, the TPA becomes stateful if we adopt such an approach,
and another veriﬁer cannot perform the auditing without such a table. Another
option to solve the problem is to use the Merkle Hash Tree (MHT) which has
been used in [14]. It uses a tree structure to organise the ﬁle blocks, and the

392
Y. Feng et al.
roots of the tree, which are derived from the ﬁle blocks, need to be veriﬁed in
every operation.
B
Proof of Correctness
Correctness of the Non-anonymous Veriﬁcation Equation:
e

j∈J H(name||j)cj · hμ, g2

= d
i=1 e (Σi, yi).
RHS =

i̸=s
e(Σi, yi) · e(Σs, ys)
=

i̸=s
e (gai
1 , yi) · e
⎛
⎜
⎝

j∈J
σcj
j

ψ
⎛
⎝
i̸=s
yai
i
⎞
⎠
1/xs
, ys
⎞
⎟
⎠
= e
⎛
⎝g1,
n

i̸=s
yai
i
⎞
⎠· e
⎛
⎝1

ψ
⎛
⎝
i̸=s
yai
i
⎞
⎠, g2
⎞
⎠· e
⎛
⎝
j∈J
σcj
j , ys
⎞
⎠
= e
⎛
⎝ψ
⎛
⎝
n

i̸=s
yai
i
⎞
⎠, g2
⎞
⎠· e
⎛
⎝1

ψ
⎛
⎝
i̸=s
yai
i
⎞
⎠, g2
⎞
⎠· e
⎛
⎝
j∈J
σcj
j , ys
⎞
⎠
= e
⎛
⎝
j∈J
σcj
j , ys
⎞
⎠= e
⎛
⎝
j∈J
(H (name||j) · hmj)cj/xs , gxs
2
⎞
⎠
= e
⎛
⎝
j∈J
H (name||j)cj · h

j∈J cjmj, g2
⎞
⎠
= e
⎛
⎝
j∈J
(H (name||j)cj · hμ, g2
⎞
⎠= LHS
Correctness of the anonymous veriﬁcation equation: l(u ⋆π) = c ⋆k .
LHS = l F(u1, π1)F(u2, π2)
=
1 1
1 L
 1 e(g1, yr11
1
yr21
2
...yrd1
d
)
1 e(gα
1 , yr11
1
yr21
2
...yrd1
d
)

=
1 e(gτ
1, yr12
1
yr22
2
...yrd2
d
)
1 e(gτα
1 , yr12
1
yr22
2
...yrd2
d
)

RHS = F(c1, k1)F(c2, kd)...F(cd, kd)
=
1
e(gr11+r12τ
1
, y1)
1 e(gα(r11+r12τ)
1
Σ1, y1)
 1
e(gr21+r22τ
1
, y2)
1 e(gα(r21+r22τ)
1
Σ2, y2)
 
1
e(grd1+rd2τ
1
, yd)
1 e(gα(rd1+rd2τ)
1
Σd, yd)

www.ebook3000.com

A New Public Remote Integrity Checking Scheme with User Privacy
393
Calculating Hadamard product:
e(g1, yr11
1 yr21
2 ...yrd1
d
)e(gτ
1, yr12
1 yr22
2 ...yrd2
d
)
= e(g1, yr11+r12τ
1
)e(g1, yr21+r22τ
2
)...e(g1, yrd1+rd2τ
d
)
= e(gr11+r12τ
1
, y1)e(gr21+r22τ
1
, y2)...e(grd1+rd2τ
1
, yd)
L e(gα
1 , yr11
1 yr21
2 ...yrd1
d
)e(gτα
1 , yr12
1 yr22
2 ...yrd2
d
)
= L e(gα(r11+r12τ)
1
, y1)e(gα(r21+r22τ)
1
, y2)e(gα(rd1+rd2τ)
1
, yd)
(as L can be viewed as e(Σ1, y1)e(Σ2, y2)...e(Σd, yd))
= e(gα(r11+r12τ)
1
Σ1, y1)e(gα(r21+r22τ)
1
Σ2, y2)e(gα(rd1+rd2τ)
1
Σd, yd)
C
Proof of Anonymity (Theorem 1)
Proof. For the (unconditional) anonymity of the ﬁle tag, it directly follows that
of the underlying ring signature (e.g., [2]). In the following we will focus on the
anonymity of the responses returned from cloud server. Let A be the adversary
who has a non-negligible advantage ϵ in winning the Anonymity game, we can
construct a simulator C to solve the XDH problem.
Simulator C receives a challenge gk, ψ, A = gx
1, B = gy
1, C = gz
1, where z is
either xy or a random element ξ in Zp. C simulates the game as follows.
Setup: Simulator C sets the commitment key to be u1 = (g1, A), u2 = (B, C).
C then uses the information in gk and ψ to generate all user public/private key
pairs as described. Finally Simulator C randomly chooses a user b ∈[1, d] as the
real owner of all the queried ﬁles.
Phase 1: Simulator C answers the tag queries honestly and stores the tokens,
glue value and auxiliary information correctly.
Phase 2: To answer a proof query, C computes μb, {Σb} honestly. Then C uses
{Σb} to generate response as follows: Randomly choose r11, r12, r21, r22...rd1, rd2
from Zp. Then compute the commitment c: c11 = gr11
1 Br12 , c12 = Ar11Cr12Σb1 ,
c21 = gr21
1 Br22 , c22 = Ar21Cr22Σb2 , ... cd1 = grd1
1
Brd2 , cd2 = Ard1Crd2Σbd .
Finally compute the proof π = (π1, π2) where π1 = (1, yr11
1 yr21
2 ...yrd1
d
) and π2 =
(1, yr12
1 yr22
2 ...yrd2
d
).
Decision: Simulator C sends the response (μ, c, π) to A. A outputs b′ as a guess
of b. If b′ = b, then simulator C outputs 1; otherwise C outputs 0 for the instance
of the XDH problem.
Probability: Case 1: z = xy. In this case, the distribution of the response is
identically to that of a real response, so we have Pr[b′ = b] = 1/d + ϵ. Case 2:
z = ξ. In this case, the commitment scheme is perfectly hiding and reveals no
information about the value of b. Hence, under this case we have Pr[b′ = b] = 1/d.
Combining both cases, C has advantage ϵ to solve the XDH problem.

394
Y. Feng et al.
D
Proof of Soundness (Theorem 2)
Proof. We will prove this by contradiction. If there exists an adversary A who can
win the soundness game with non-negligible probability, then we can construct a
simulator to solve the variant of the Co-CDH problem also with a non-negligible
probability:
Setup: Simulator C sets up the system parameters and chooses α, τ ∈Zp to
generate the commitment key u1 = (g1, gα
1 ) and u2 = (gτ
1, gτα
1 ). C then sets
h = gab
1
as the other generator in system parameter and constructs a table
< name, j, rj, H(name||j) > for hash oracle. C also randomly chooses xi ∈Zp
for each user and computes the public key yi = (ga
2)xi = uxi. (We can view the
private key as axi.)
Phase 1: For simplicity, Simulator C chooses the ﬁrst user as the signing user,
and generates the ﬁle tag using the underlying ring signature scheme. C answers
the token queries as follows:
– Hash Query: Simulator C randomly chooses rj ∈Zp and sets H(name||j) =
ψ(ga
2)rj/hmj. The entry < name, j, rj, H(name||j) > is stored into the table.
– Authenticator: σj = (H(name||j) · hmj)1/ax1 = ψ(ga
2)rj/ax1 = grj/x1
1
Simulator C answers the glue queries as follows:
– For each user i ̸= 1 in the ring, C chooses ai ∈Zp, and computes auxiliary
information. bi = gai
1
– C computes a glue value θ =
1
ψ(
d
i̸=1 y
ai
i )
1/ax1 =
1
ψ(
n
i̸=1((ga
2 )xi)ai)
1/ax1 =
1
g(

i̸=1 aixi)/x1
1
.
Phase 2: Finally A outputs a proof P ′ = (μ′, c, π) for t′, {m′
j}j∈J and challenge
{cj}j∈J, where at least one m′
j has been modiﬁed by the adversary.
C uses the commitment secret key α to recover the Σ′
i = ci2/cα
i1 and
let μ = 
j∈J cjmj, {Σ} be the honestly generated component. Then we
have the following equations: e

j∈J H (name||j)cj · hμ′, g2

= n
i=1 e (Σ′
i, yi)
then e

j∈J H (name||j)cj · hμ, g2

= n
i=1 e (Σi, yi). Therefore, we can get
e(hμ′−μ, g2) = n
i=1 e (Σ′
i/Σi, yi) then e(hμ′−μ, g2) = e
n
i=1 (Σ′
i/Σi)xi , ga
2

.
As C chooses the challenges cj at random and h = gab
1 , with overwhelming
probability 1 −1/p, μ′ = 
j∈J cjm′
j ̸= μ = 
j∈J cjmj , we can obtain
gb
1 =
 n

i=1
(Σ′
i/Σi)xi
1/(μ′−μ)
.
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
with Public Veriﬁability and Data Privacy
Cl´ementine Gritti(B), Willy Susilo, and Thomas Plantard
Centre for Computer and Information Security Research,
School of Computing and Information Technology,
University of Wollongong, Wollongong, Australia
cjpg967@uowmail.edu.au,
{wsusilo,thomaspl}@uow.edu.au
Abstract. We present a Dynamic Provable Data Possession (PDP)
system with Public Veriﬁability and Data Privacy. Three entities are
involved: a client who is the owner of the data to be stored, a server that
stores the data and a Third Party Auditor (TPA) who may be required
when the client wants to check the integrity of its data stored on the
server. The system is publicly veriﬁable with the possible help of the
TPA who acts on behalf of the client. The system exhibits data dynam-
icity at block level allowing data insertion, deletion and modiﬁcation to
be performed. Finally, the system is secure at the untrusted server and
data private. We present a practical PDP system by adopting asymmet-
ric pairings to gain eﬃciency and reduce the group exponentiation and
pairing operations. In our scheme, no exponentiation and only three pair-
ings are required during the proof of data possession check, which clearly
outperforms all the existing schemes in the literature. Furthermore, our
protocol supports proof of data possession on as many data blocks as
possible at no extra cost.
Keywords: Provable Data Possession · Practicality · Data operations ·
Public veriﬁability · Data integrity · Data privacy
1
Introduction
One of the most essential issue in storing data at an untrusted server is the abil-
ity to check the integrity of the data. Data owner has to ensure that the server
really possesses the claimed stored data. Numerous proof-of-storage solutions
have been proposed such as Proofs of Retrievability systems [1,2] and Provable
Data Possessions systems [3,4]. In the latter system, the client is able to check
that a server has stored its data without retrieving them from the server and
without letting the server to access the entire data ﬁle. Both systems should
satisfy the main property of eﬃciency in terms of computational and commu-
nication complexities and the storage overhead on the server’s side should be as
This work is partially supported by ARC Linkage Project LP12020052.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 395–412, 2015.
DOI: 10.1007/978-3-319-19962-7 23

396
C. Gritti et al.
small as possible. The properties of unbounded uses on the number of proof-of-
storage interactions and statelessness of the client are required to obtain systems
with public veriﬁability, in which anyone can verify the integrity of the stored
data [5,6]. More recently, an idea emerged as delegating the data integrity check
to a Third Party Auditor (TPA) [7,8]. More precisely, the client retains its data
on an untrusted server and asks a trusted TPA to verify the authenticity of the
stored data. This concept can be seen as a particular case of public veriﬁability.
At the same time, another idea arised as dynamically updating the stored data
[9–11]. In other words, the client is able to insert, delete and modify its stored
data blocks and the server should then update these blocks on its side.
It is widely acknowledged that a storage service is susceptible to attacks or
failures and leads to possible non-retrievable losses of the client’s stored data. A
solution is to construct a system that oﬀers an eﬃcient, frequent and secure data
integrity check process to the client. Nevertheless, the frequency of data integrity
veriﬁcation and the percentage of checked data are often limited because of
the computational and communication costs on both server’s and client’s sides,
although these two properties are really essential for storage service.
1.1
Our Contributions
In this work, we provide a Dynamic Provable Data Possession (PDP) system with
Public Veriﬁability and Data Privacy. There are three entities in the system: a
client who is the owner of the data to be stored, a server that stores the data (e.g.
a cloud), and a semi-honest Third Party Auditor (TPA) who can be required
when the client wants to check the integrity of its data stored on the server.
The client gets a large amount of data that it wants to store on the server
without retaining a local copy. The server gets an important storage space and
computation resources and supplies services for the client. The system is public
veriﬁable, meaning that anyone is enabled to check the integrity of the data, not
only the TPA on behalf of the client or the client itself. However, the TPA can be
requested to judge whether the data integrity is maintained by checking the proof
of data possession. We stress that the client may be able to perform integrity
checking by itself; however, it could be limited in resources and therefore it may
be neceesary to ask to the TPA (such as when the client is a mobile phone).
Since this often happens naturally in practice, we only consider the case of the
TPA acting on behalf of the client.
The system is also data dynamic at the block level supporting three oper-
ations: data insertion, deletion and modiﬁcation. Finally, the system is secure
at the untrusted server, meaning that a server cannot successfully generate a
correct proof of data possession without storing all the ﬁle blocks, and data pri-
vate, meaning that the TPA learns nothing about the data of the client from all
available information.
Our scheme outperforms the existing schemes in the literature in terms of
practicality. The ﬁrst reﬁnement is a better eﬃciency due the use of asymmetric
pairings. The second amelioration is a decrease of the number of group exponen-
tiation and pairing computations. In particular, the TPA needs to compute no
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
397
exponentiation and only three pairings in order to verify the proof of data pos-
session generated by the server. This implies that the latter can be requested by
the client through the TPA to create the proof on any percentage of the stored
data, without any computational constraints. The result of these improvements
is clear in terms of performance evaluation.
1.2
Related Work
Ateniese et al. [3] ﬁrst deﬁned the notion of Provable Data Possession (PDP),
which allows a client to verify the integrity of its data stored at an untrusted
server without retrieving the entire ﬁle. Their scheme is designed for static data
and used public key-based homomorphic tags for auditing the data ﬁle. Nev-
ertheless, the precomputation of the tags imposes heavy computation overhead
that can be expensive for entire ﬁle. Subsequently, Ateniese et al. [4] constructed
scalable and eﬃcient schemes using symmetric keys in order to improve the eﬃ-
ciency of veriﬁcation. This results in lower overhead than their previous scheme.
The scheme partially supports dynamic data operations (block updates, dele-
tions and appends to the stored ﬁle); however, it is not publicly veriﬁable and is
limited in number of veriﬁcation requests.
Thereafter, several works were done following the models given in [3,4]. Wang
et al. [5] combined a BLS-based homomorphic authenticator with a Merkle hash
tree to achieve a public auditing protocol with fully dynamic data. Hao et al. [6]
designed a dynamic public auditing system based on RSA. However, they did
not provide any proof of security. Their scheme is shown not to be secure in [12].
Erway et al. [9] proposed a fully dynamic PDP scheme based on rank-based
authenticated dictionary. Unfortunately, their system is very ineﬃcient. Zhu
et al. [11] used index-hash tables to support fully dynamic data and constructed
a zero-knowledge PDP. Zhu et al. [13] created a dynamic audit service based
on fragment structure, random sampling and index-hash table that supports
timely anomaly detection. Wang et al. [14] proposed a system to ensure the
correctness of users’ data stored on multiple servers by requiring homomorphic
tokens and erasure codes in the auditing process. Le and Markopoulou [15] con-
structed an eﬃcient dynamic remote data integrity checking scheme based on
a homomorphic MAC scheme and CPA-secure encryption scheme and speciﬁ-
cally designed for network coding based storage cloud. Wang et al. [16] gave a
ﬂexible distributed storage integrity auditing protocol utilizing the homomor-
phic token and the distributed erasure-coded data. Subsequently, Wang et al.
[7] designed a privacy-preserving protocol, Oruta, that allows public auditing on
shared data stored in the cloud. The scheme allows public auditing and identity
privacy but fails to support large groups and traceability. In a parallel work,
Wang et al. [8] presented a privacy-preserving auditing system, Knox, for data
stored in the cloud and shared among a large number of users in the group. The
scheme allows identity privacy, large users’ number and traceability but is only
for private auditing. Nevertheless, Yu et al. [17] demonstrated that the protocols
in [7,8,16] are subject to active adversary attacks.

398
C. Gritti et al.
1.3
Paper Organization
In the next Section, we review the deﬁnitions and notations that will be used
throughout this paper. Additionally, we also provide the deﬁnition of dynamic
PDP scheme with public veriﬁability and data privacy, along with its secu-
rity models. In Section 3, we present our scheme. In Section 4, we present the
corresponding security proofs. In Section 5, we discuss about the computation
and communication costs and we evaluate and compare the performance of our
scheme with other existing ones. Finally, we conclude the paper in Section 6.
2
Deﬁnitions
We use the Homomorphic Veriﬁable Tags (HVT) [3] to build veriﬁcation meta-
data linked to data blocks (deﬁned in Appendix A). To construct our scheme,
we use bilinear maps (deﬁned in Appendix A for completness).
Throughout this paper, we write i ∈[a, b] to describe that i can take all
the values in the interval of reals between a and b. Let i ∈]a, b] (resp. [a, b[)
mean that i can take all the values in the interval of reals between a and b, but
a excluded (resp. b excluded). Let i = 1, · · · , n mean that i can take all the
values in N∩[1, n], where N is the set of naturals {1, 2, · · · }. Z denotes the set of
the integers {· · · , −2, −1, 0, 1, 2, · · · }, Zp denotes the set {0, · · · , p −1} and Z∗
p
denotes the set of positive integers smaller than p and relatively prime with p.
Q denotes the set of the rationals. We let |I| denote the cardinality of the set I.
Let || denote the symbol of concatenation, e.g. m = m1||m2 is the ﬁle made of
the concatenation of the two blocks m1 and m2. We let m =⊥mean that m
does not take any value. Let |m| denote the bit size of the element m.
2.1
DPDP Scheme
The following deﬁnition of the scheme follows the ones from [3] and [9]. A Dynamic
Provable Data Possession scheme with Public Veriﬁability and Data Privacy Π =
(KeyGen, Tag- Gen, PerfOp, CheckOp, Gen- Proof, CheckProof) is as
follows:
KeyGen(λ) →(pk, sk). The probabilistic key generation algorithm is run
by the client to setup the scheme. It takes as input the security parameter λ,
and outputs a pair of public and secret keys (pk, sk).
TagGen(pk, sk, m) →Tm. The (possibly) probabilistic tag generation algo-
rithm is run by the client to generate the veriﬁcation metadata. It takes as inputs
the public key pk, the secret key sk and a ﬁle block m, and outputs a veriﬁcation
metadata Tm. Then, the client stores all the ﬁle blocks m in an ordered collection
F and the corresponding veriﬁcation metadata Tm in an ordered collection E.
It forwards these two collections to the server and deletes them from its local
storage.
PerfOp(pk, F, E, info) →(F′, E′, ν′). This algorithm is run by the server in
response to a data operation requested by the client. It takes as inputs the public
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
399
key pk, the previous collection F of all the ﬁle blocks, the previous collection E
of all the veriﬁcation metadata, and the data operation details info given by
the client. The element info speciﬁes the operation to be performed: it can
be either insertion or deletion or modiﬁcation, along with other information
like the rank where the operation has to be performed, the ﬁle block and the
corresponding metadata that are looked at. It outputs the updated veriﬁcation
metadata collection F′, the updated veriﬁcation metadata collection E′, and
the related updating proof ν′. The server sends ν′ to the TPA. We give more
information about the data operation process below.
CheckOp(pk, ν′) →{“success”, “failure”}. This algorithm is run by the
TPA on behalf of the client to verify the server’s behavior during the data
operation (insertion, deletion or modiﬁcation). It takes as inputs the public key
pk and the updating proof ν′ sent by the server. It outputs “success” if ν′ is
a correct updating proof; otherwise it outputs “failure”. We assume that the
answer is then forwarded to the client. We omit this part of the process.
GenProof(pk, F, chal, Σ) →ν. This algorithm is run by the server in order
to generate a proof of data possession. It takes as inputs the public key pk, an
ordered collection F ⊂F of blocks, a challenge chal and an ordered collection
Σ ⊂E which are the veriﬁcation metadata corresponding to the blocks in F. It
outputs a proof of data possession ν for the blocks in F that are determined by
the challenge chal.
We assume that a ﬁrst challenge chalC is generated by the client and for-
warded to the TPA. Then, the TPA generates a challenge chal from chalC and
sends it to the server. In particular, if the client wants to check the integrity of
its data without the help of the TPA, then chalC = chal. We omit the process
done by the client at this point.
CheckProof(pk, chal, ν) →{“success”, “failure”}. This algorithm is run by
the TPA in order to validate the proof of data possession. It takes as inputs the
public key pk, the challenge chal and the proof of data possession ν. It outputs
“success” if ν is a correct proof of data possession for the blocks determined by
chal; otherwise it outputs “failure”. We assume that the answer is then forwarded
to the client. We omit this part of the process.
We require that a Dynamic Provable Data Possession scheme with Pub-
lic Veriﬁability and Data Privacy Π is correct if for (pk, sk) ←KeyGen(λ),
for Tm ←TagGen(pk, sk, m), for (F′, E′, ν′) ←PerfOp(pk, F, E, info), for
ν
←
GenProof(pk, F, chal, Σ), then “success”
←
CheckOp(pk, ν′) and
“success” ←CheckProof(pk, chal, ν). We now give more details about the
data operations that can be performed.
PerfOp(pk, F, E, info = (insertion, 2i+1
2 , m 2i+1
2 , Tm 2i+1
2 )) →(F′, E′, ν′).
This algorithm is run by the server in response to a data insertion requested
by the client. It takes as inputs the public key pk, the previous collection F of all
the ﬁle blocks, the previous collection E of all the veriﬁcation metadata, the type
“insertion” of the data operation to be performed, the index 2i+1
2
denoting the
rank where the data operation is performed (in the ordered collections F and E),
the ﬁle block m 2i+1
2
to be inserted, and the corresponding veriﬁcation metadata

400
C. Gritti et al.
Tm 2i+1
2
to be inserted, for i = 0, · · · , n. More precisely, m 2i+1
2
is inserted between
the existing blocks mi and mi+1 and Tm 2i+1
2
is inserted between the existing ver-
iﬁcation metadata Tmi and Tmi+1, for i = 1, · · · , n−1. For i = 0, m 1
2 is appended
before m1 and Tm 1
2 is appended before Tm1. For i = n, m 2n+1
2
is appended after
mn and Tm 2n+1
2
is appended after Tmn. Finally, it outputs the updated ﬁle block
collection F′ containing m 2i+1
2 , the updated veriﬁcation metadata collection E′
containing Tm 2i+1
2 , and the related updating proof ν′. The server sends ν′ to the
TPA.
PerfOp(pk, F, E, info = (deletion, i)) →(F′, E′, ν′). This algorithm is run
by the server in response to a data deletion requested by the client. It takes
as inputs the public key pk, the previous collection F of all the ﬁle blocks, the
previous collection E of all the veriﬁcation metadata, the type “deletion” of the
data operation to be performed, and the index i denoting the rank where the data
operation is performed (in the ordered collections F and E). The server deletes
the existing ﬁle block mi, and the corresponding veriﬁcation metadata Tmi, for
i = 1, · · · , n. More precisely, mi is deleted, giving that mi−1 is followed by mi+1
and Tmi is deleted, giving that Tmi−1 is followed by Tmi+1, for i = 2, · · · , n −1.
For i = 1, m1 is removed, giving that the ﬁle now begins from m2, and Tm1
is removed, giving that the collection of veriﬁcation metadata now begins from
Tm2. For i = n, mn is removed, giving that the ﬁle now ends at mn−1, and
Tmn is removed, giving that the collection of veriﬁcation metadata now ends
at Tmn−1. Finally, it outputs the updated ﬁle block collection F′ that does not
contain mi anymore, the updated veriﬁcation metadata collection E′ that does
not contain Tmi anymore, and the related updating proof ν′. The server sends
ν′ to the TPA. The deletion operation stops when the number of blocks is equal
to 0.
PerfOp(pk, F, E, info = (modiﬁcation, i, m′
i, Tm′
i)) →(F′, E′, ν′). This algo-
rithm is run by the server in response to a data modiﬁcation requested by the
client. It takes as inputs the public key pk, the previous collection F of all the
ﬁle blocks, the previous collection E of all the veriﬁcation metadata, the type
“modiﬁcation” of the data operation to be performed, the index i denoting the
rank where the data operation is performed (in the ordered collections F and E),
the ﬁle block m′
i which replaces the existing block mi, and the corresponding
veriﬁcation metadata Tm′
i which replaces the existing veriﬁcation metadata Tmi,
for i = 1, · · · , n. We assume that the ﬁle block m′
i and the corresponding veriﬁ-
cation metadata Tm′
i were provided by the client to the server, such that Tm′
i was
correctly computed by running the algorithm TagGen. It outputs the updated
veriﬁcation metadata collection F′ replacing mi by m′
i, the updated veriﬁcation
metadata collection E′ replacing Tmi by Tm′
i, and the related updating proof
ν′. The server sends ν′ to the TPA. We allow the client to make full re-write
updates, meaning that all the ﬁle blocks m1, · · · , mn are replaced by m′
1, · · · , m′
n
and all the veriﬁcation metadata Tm1, · · · , Tmn are replaced by Tm′
1, · · · , Tm′
n.
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
401
Remarks. About the proof of data possession: The set of data blocks (following
a certain percentage of blocks; e.g. 90%) that are checked to be correctly stored
are chosen by the TPA on behalf of the client. The server has to generate a
proof of data possession based on this set. We notice that sometimes in the
literature [6,12], the TPA just sends a challenge chal without specifying which
blocks have to be checked, which leads to the fact that the server must generate
a proof of data possession based on all the stored data blocks, at the cost of the
communication overhead.
About the data operations: We assume that the frequency of checking the
integrity of the data is much higher than the frequency of performing data oper-
ations. To generate an updating proof, no challenge is required, meaning that
the updating proof is based only the recently updated ﬁle block and the cor-
responding veriﬁcation metadata. Therefore, one can think that this proof is
not strong enough, however we suppose that the TPA on behalf of the client
regularly asks to the server to check the integrity of the data by generat-
ing a challenge that can include the ﬁle blocks recently updated. Moreover,
when the server is generating the updating proof ν′, it can include an element
info′ ∈{insertion, deletion, modiﬁcation} in this proof to enable the TPA to
know which operation was performed. A solution to check that the server has
correctly updated the collection F′ of the ﬁle blocks and the collection E′ of the
veriﬁcation metadata after operation is to order the data into a Merkle hash tree
[5] or rank-based authenticated skip lists [9].
2.2
Security Models
Security against the server. The below-mentioned deﬁnition of the scheme fol-
lows the ones from [3] and [9]. We consider a Dynamic Provable Data Possession
scheme with Public Veriﬁability and Data Privacy Π = (KeyGen, TagGen,
Perf- Op, CheckOp, GenProof, CheckProof). Let a data possession game
between a challenger C and an adversary A be as follows:
KeyGen. (pk, sk) ←KeyGen(λ) is run by C. The element pk is given to A.
Adaptive queries. A makes adaptive queries through the intermediary of two
oracles. The adversary is given access to a tag generation oracle OT G as fol-
lows. A chooses a ﬁrst block m1 and forwards it the challenger. C computes
the corresponding veriﬁcation metadata Tm1 ←TagGen(pk, sk, m1) and gives
it to the adversary. The adversary keeps on the same queries process with C
for the veriﬁcation metadata Tm2 ←TagGen(pk, sk, m2), · · · , Tmn ←TagGen
(pk, sk, mn), where the blocks m2, · · · , mn are chosen by A. Then, the adver-
sary creates an ordered collection F = {m1, · · · , mn} of ﬁle blocks along with an
ordered collection E = {Tm1, · · · , Tmn} of the corresponding veriﬁcation meta-
data.
Thereafter, the adversary is given access to a data operation performance ora-
cle ODOP as follows. A submits to the challenger a block mi, for i = 1, · · · , n,
and the corresponding value infoi about the data operation that the adver-
sary wants to perform. The adversary runs the algorithm PerfOp and outputs
a new ﬁle blocks ordered collection F′, a new metadata ordered collection E′,

402
C. Gritti et al.
and the corresponding updating proof ν′. C checks the value ν′ by running the
algorithm CheckOp(pk, ν′) and gives back the resulting answer belonging to
{“success”, “failure”} to the adversary. If the answer is “failure”, then the chal-
lenger aborts; otherwise, it proceeds. The above interaction between A and C
can be repeated.
Setup. The adversary submits ﬁle blocks m∗
i along with the corresponding
values info∗
i , for i ∈I ⊆]0, n + 1[∩Q. Adaptive queries are again generated
by the adversary, such that the ﬁrst info∗
i speciﬁes a full re-write update (this
corresponds to the ﬁrst time that the client sends a ﬁle to the server). The
challenger veriﬁes the data operations.
Challenge. The ﬁnal version of the blocks mi ∈I is considered such that
these blocks were created according to the data operations requested by the
adversary, and veriﬁed and accepted by the challenger in the previous step.
The challenger sets F = {mi}i∈I of these ﬁle blocks and E = {Tmi}i∈I of
the corresponding veriﬁcation metadata. C then takes an ordered collection
F = {mi1, · · · , mik} ⊂F and the corresponding veriﬁcation metadata ordered
collection Σ = {Tmi1 , · · · , Tmik } ⊂E, for ij ∈I, j = 1, · · · , k. It generates a
resulting challenge chal for F and Σ and forwards it to A.
Forge. The adversary generates a proof of data possession ν on chal. Then,
the challenger runs CheckProof(pk, chal, ν) and gives the answer belonging to
{“success”, “failure”} to A. If the answer is “success” then the adversary wins.
The Dynamic Provable Data Possession scheme with Public Veriﬁability and
Data Privacy Π
=
(KeyGen, TagGen, PerfOp, CheckOp, GenProof,
Check- Proof) is said to be secure if for any probabilistic polynomial-time
(PPT) adversary A who can win the above data possession game with non-
negligible probability, then the challenger C can extract at least the challenged
parts of the ﬁle by resetting and challenging the adversary polynomially many
times by means of a knowledge extractor E.
Privacy against the TPA. The below-mentioned deﬁnition of the scheme fol-
lows the one from [12]. We consider a Dynamic Provable Data Possession
scheme with Public Veriﬁability and Data Privacy Π = (KeyGen, TagGen,
PerfOp, Check- Op, GenProof, CheckProof). Let a data privacy game
between a challenger C and an adversary A be as follows:
KeyGen. (pk, sk) ←KeyGen(λ) is run by C. The element pk is given to A.
Queries. A gives to the challenger two ﬁles m0 = m0,1|| · · · ||m0,n and m1 =
m1,1|| · · · ||m1,n of equal length. C randomly selects a bit b ∈R {0, 1}, computes
Tmb,i ←TagGen(pk, sk, mb,i) for i = 1, · · · , n and gives them to A. Then,
the adversary creates an ordered collection F = {mb,1, · · · , mb,n} of ﬁle blocks
along with an ordered collection E = {Tmb,1, · · · , Tmb,n} of the corresponding
veriﬁcation metadata.
Challenge. The adversary forwards chal to C.
Generation of the Proof. The challenger outputs a proof of data possession
ν∗←GenProof(pk, F, chal, Σ) for the blocks in F that are determined by
the challenge chal, where F = {mb,i1, · · · , mb,ik} ⊂F is an ordered collection
of blocks and Σ = {Tmb,i1, · · · , Tmb,ik } ⊂E is an ordered collectection of the
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
403
veriﬁcation metadata corresponding to the blocks in F, for 1 ≤ij ≤n, 1 ≤j ≤k
and 1 ≤k ≤n.
Guess. The adversary returns a bit b′. A wins if b′ = b.
The Dynamic Provable Data Possession scheme with Public Veriﬁability and Data
Privacy Π
=
(KeyGen, TagGen, PerfOp, CheckOp, GenProof, Check-
Proof) is said to be data private if there is no probabilistic polynomial-time
(PPT) adversary A who can win the above data privacy game with non-negligible
advantage equal to |Pr[b′ = b] −1
2|.
3
Our DPDP Construction
The ﬁle to be stored is split into n blocks, and each block is split into s sectors.
We let each block and sector be elements of Zp for some large prime p. For
instance, let the ﬁle be b bits long. Then, the ﬁle is split into n = ⌈b/s · log(p)⌉
blocks. The aforementioned intuition comes from [2]. Suppose that the blocks
contain s ≥1 elements of Zp. Therefore, a tradeoﬀexists between the storage
overhead and the communtication overhead. More precisely, the communication
complexity rises as s + 1 elements of Zp. Finally, a larger value of s yields less
storage overhead at cost of a high communication. Moreover, p should be λ bits
long, where λ is the security parameter such that n >> λ.
KeyGen(λ) →(pk, sk). Let GroupGen(λ) be an algorithm that, on input
the security parameter λ, generates the cyclic groups G1, G2 and GT of prime
order p = p(λ) with bilinear map e : G1 × G2 →GT . Let g1 and g2 be gener-
ators of G1 and G2 respectively. Then, the client randomly chooses s elements
h1, · · · , hs ∈R G1. Moreover, it selects at random a ∈R Zp and sets its public
key pk = (p, G1, G2, e, g1, g2, h1, · · · , hs, ga
2) and its secret key sk = a.
TagGen(pk, sk, m) →Tm. A ﬁle m is split into n blocks mi, for i = 1, · · · , n.
Each block mi is then split into s sectors mi,j ∈Zp, for j = 1, · · · , s. We suppose
that |m| = b and n = ⌈b/s·log(p)⌉. Therefore, the ﬁle m can be seen a n×s matrix
with elements denoted as mi,j. The client computes the veriﬁcation metadata
Tmi = (s
j=1 hmi,j
j
)−sk = (s
j=1 hmi,j
j
)−a = (s
j=1 h−a·mi,j
j
) for i = 1, · · · , n.
Then, it sets Tm = (Tm1, · · · , Tmn) ∈Gn
1.
Then, the client stores all the ﬁle blocks m in an ordered collection F and the
corresponding veriﬁcation metadata Tm in an ordered collection E. It forwards
these two collections to the server and deletes them from its local storage.
PerfOp(pk, F, E, info = (insertion, 2i+1
2 , m 2i+1
2 , Tm 2i+1
2 )) →(F′, E′, ν′).
After receiving the elements
2i+1
2 , m 2i+1
2
and Tm 2i+1
2
from the client, for
i = 0, · · · , n, the server prepares the updating proof as follows. It ﬁrst selects
at random u1, · · · , us ∈R Zp and computes U1 = hu1
1 , · · · , Us = hus
s . It also
chooses at random w 2i+1
2
∈R Zp and sets cj = m 2i+1
2
,j · w 2i+1
2
+ uj ∈Zp for
j = 1, · · · , s, then Cj = hcj
j for j = 1, · · · , s, and d = T
w 2i+1
2
m 2i+1
2 . Finally, it returns
ν′ = (U1, · · · , Us, C1, · · · , Cs, d) ∈G2s+1
1
to the TPA.
PerfOp(pk, F, E, info = (deletion, i)) →(F′, E′, ν′). After receiving an index
i = 1, · · · , n from the client, the server prepares the updating proof as follows. It

404
C. Gritti et al.
ﬁrst selects at random u1, · · · , us ∈R Zp and computes U1 = hu1
1 , · · · , Us = hus
s .
It also chooses at random wi ∈R Zp and sets cj = mi,j · wi + uj ∈Zp for
j = 1, · · · , s, then Cj = hcj
j
for j = 1, · · · , s, and d = T wi
mi, where mi and Tmi
are the existing ﬁle block and veriﬁcation metadata to be deleted respectively.
Finally, it returns ν′ = (U1, · · · , Us, C1, · · · , Cs, d) ∈G2s+1
1
to the TPA.
PerfOp(pk, F, E, info = (modiﬁcation, i, m′
i, Tm′
i)) →(F′, E′, ν′). After
receiving the elements i, m′
i and Tm′
i from the client, the server prepares the
updating proof as follows. It ﬁrst selects at random u1, · · · , us ∈R Zp and com-
putes U1 = hu1
1 , · · · , Us = hus
s . It also chooses at random wi ∈R Zp and sets
cj = m′
i,j · wi + uj ∈Zp for j = 1, · · · , s, then Cj = hcj
j
for j = 1, · · · , s, and
d = T wi
m′
i. Finally, it returns ν′ = (U1, · · · , Us, C1, · · · , Cs, d) ∈G2s+1
1
to the
TPA.
CheckOp(pk, ν′) →{“success”, “failure”}. The TPA has to check whether
the following equation holds:
e(d, ga
2) · e(
s

j=1
Uj, g2)
?= e(
s

j=1
Cj, g2)
(1)
If Eq. 1 holds, then the TPA returns “success” to the client; otherwise. it returns
“failure” to the client.
GenProof(pk, F, chal, Σ) →ν. After receiving a challenge chalC from the
client, the TPA prepares a challenge chal to send to the server as follows. First,
it chooses a subset I ⊆]0, n + 1[Q, randomly chooses |I| elements vi ∈R Zp and
sets chal = {(i, vi)}i∈I. Second, after receiving the challenge chal which indicates
the speciﬁc blocks for which the client, through the TPA, wants a proof of data
possession, the server sets the ordered collection F = {mi}i∈I ⊂F of blocks and
an ordered collection Σ = {Tmi}i∈I ⊂E which are the veriﬁcation metadata
corresponding to the blocks in F. It then selects at random r1, · · · , rs ∈R Zp and
computes R1 = hr1
1 , · · · , Rs = hrs
s . It also sets bj = 
(i,vi)∈chal mi,j ·vi +rj ∈Zp
for j = 1, · · · , s, then Bj = hbj
j for j = 1, · · · , s, and c = 
(i,vi)∈chal T vi
mi. Finally,
it returns ν = (R1, · · · , Rs, B1, · · · , Bs, c) ∈G2s+1
1
to the TPA.
CheckProof(pk, chal, ν) →{“success”, “failure”}. The TPA has to check
whether the following equation holds:
e(c, ga
2) · e(
s

j=1
Rj, g2)
?= e(
s

j=1
Bj, g2)
(2)
If Eq. 2 holds, then the TPA returns “success” to the client; otherwise. it returns
“failure” to the client.
Correctness. If all the algorithms are correctly generated, then the above scheme
is correct. For the updating proof, we have:
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
405
e(d, ga
2) · e(
s

j=1
Uj, g2) = e(T wi
mi, ga
2) · e(
s

j=1
huj
j , g2) = e(
s

j=1
hmi,j·wi+uj
j
, g2)
= e(
s

j=1
hcj
j , g2) = e(
s

j=1
Cj, g2)
For the proof of data possession, we have:
e(c, ga
2) · e(
s

j=1
Rj, g2) = e
⎛
⎜
⎜
⎝

(i,vi)
∈chal
T vi
mi, ga
2
⎞
⎟
⎟
⎠· e(
s

j=1
h
rj
j , g2) = e(
s

j=1
h

(i,vi)
∈chal
mi,j·vi+rj
j
, g2)
= e(
s

j=1
h
bj
j , g2) = e(
s

j=1
Bj, g2)
Remarks. About the veriﬁcation metadata: The size of the veriﬁcation metadata
Tm is small in comparison to the size of the data blocks m. Additionally, the
veriﬁcation metadata protect the integrity of the blocks. Indeed, the server gen-
erates the proofs of data possession that certify the veriﬁcation metadata instead
of the data blocks themselves.
About the proof of data possession: The element bj = 
(i,vi)∈chal mi,j ·vi+rj,
for j = 1, · · · , s, has size approximately equal to the size of a single block.
4
Security Proofs
Discrete Logarithm (DL) Problem. Let G1 be a multiplicative cyclic group of
prime order p = p(λ) (where λ is the security parameter). The DL problem is as
follows: for a ∈Zp, given g1, ga
1 ∈G1, output a. The DL problem holds in G1 if
no t-time algorithm has advantage at least ε in solving the DL problem in G1.
Security against the Server. For any probabilistic polynomial-time (PPT) adver-
sary A who wins the game, there is a challenger C that interacts with the adver-
sary A as follows.
KeyGen. C runs GroupGen(λ) →(p, G1, G2, GT , e) and selects two gen-
erators g1 and g2 of G1 and G2 respectively. Then, it randomly chooses s
elements h1, · · · , hs ∈R G1 and an element a ∈R Zp. It sets the public key
pk = (p, G1, G2, e, g1, g2, h1, · · · , hs, ga
2) and forwards it to A. It sets the secret
key sk = a and keeps it.
Adaptive queries. A has access to the tag generation oracle OT G as follows.
It ﬁrst adaptively selects blocks mi, for i = 1, · · · , n. C splits each block mi, for
i = 1, · · · , n into s sectors mi,j. Then, it computes Tmi = (s
j=1 hmi,j
j
)−sk =
(s
j=1 hmi,j
j
)−a, for i = 1, · · · , n, and gives them to A. The adversary sets
an ordered collection F = {m1, · · · , mn} of blocks and an ordered collection
E = {Tm1, · · · , Tmn} which are the veriﬁcation metadata corresponding to the

406
C. Gritti et al.
blocks in F. A has access to the data operation performance oracle ODOP as
follows. Repeatedly, the adversary selects a block ml and the corresponding ele-
ment infol and forwards them to the challenger. l denotes the rank where A
wants the data operation to be performed; l is equal to 2i+1
2
for an insertion and
to i for a deletion or a modiﬁcation. Moreover, ml =⊥in the case of a deletion,
since only the rank is needed to perform this kind of operation. Then, A out-
puts a new ﬁle blocks ordered collection F′ (containing the updated version of
the block ml), a new veriﬁcation metadata ordered collection E′ (containing the
updated version of the veriﬁcation metadata Tml) and a corresponding updating
proof ν′ = (U1, · · · , Us, C1, · · · , Cs, d), such that wl is randomly chosen from
Zp, d = T wl
ml, and for j = 1, · · · , s, uj is randomly chosen from Zp, Uj = hrj
j ,
cj = ml,j ·wl +uj and Cj = hcj
j . C runs the algorithm CheckOp on the value ν′
and sends the answer to A. If the answer is “failure”, then the challenger aborts;
otherwise, it proceeds.
Setup. The adversary selects blocks m∗
i and the corresponding elements
info∗
i , for i ∈I ⊆]0, n + 1[∩Q, and forwards them to the challenger who checks
the data operations. In particular, the ﬁrst info∗
i indicates a full re-write.
Challenge. The challenger chooses a subset I ⊆I, randomly chooses |I|
elements vi ∈R Zp and sets chal = {(i, vi)}i∈I. It forwards chal as a challenge
to A.
Forge. Upon receiving the challenge chal, the resulting proof of data posses-
sion on the correct stored ﬁle m should be ν = (R1, · · · , Rs, B1, · · · , Bs, c) and
pass the Eq. 2. However, A generates a proof of data possession on an incorrect
stored ﬁle ˜m as ˜ν = (R1, · · · , Rs, ˜B1, · · · , ˜Bs, ˜c), such that rj is randomly chosen
from Zp, Rj = hrj
j , ˜bj = 
(i,vi)∈chal ˜mi,j · vi + rj and ˜Bj = h
˜bj
j , for j = 1, · · · , s.
It also sets ˜c = 
(i,vi)∈chal T vi
˜mi. Finally, it returns ˜ν = (R1, · · · , Rs, ˜B1, · · · , ˜Bs,
˜c) to the challenger. If the proof of data possession still passes the veriﬁcation,
then A wins. Otherwise, it fails. We deﬁne Δbj = ˜bj −bj, for j = 1, · · · , s. At
least one element of {Δbj}j=1,··· ,s is non-zero.
Analysis: We provide the analysis of the above security proof in Appendix B.
Privacy against the TPA. For any probabilistic polynomial-time (PPT) adver-
sary A who wins the game, there is a challenger C that interacts with the adver-
sary A as follows.
KeyGen. C runs GroupGen(λ) →(p, G1, G2, GT , e) and selects two gen-
erators g1 and g2 of G1 and G2 respectively. Then, it randomly chooses s
elements h1, · · · , hs ∈R G1 and an element a ∈R Zp. It sets the public key
pk = (p, G1, G2, e, g1, g2, h1, · · · , hs, ga
2) and forwards it to A. It sets the secret
key sk = a and keeps it.
Queries. A gives to the challenger two ﬁles m0 = m0,1|| · · · ||m0,n and m1 =
m1,1|| · · · ||m1,n of equal length. C randomly selects a bit b ∈R {0, 1} and for
i = 1, · · · , n, splits each block mb,i into s sectors mb,i,j. Then, it computes
Tmb,i = (s
j=1 hmb,i,j
j
)−sk = (s
j=1 hmb,i,j
j
)−a, for i = 1, · · · , n, and gives them
to A.
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
407
Challenge. The adversary chooses a subset I ⊆{1, · · · , n}, randomly chooses
|I| elements vi ∈R Zp and sets chal = {(i, vi)}i∈I. It forwards chal as a challenge
to C.
Generation of the Proof. Upon receiving the challenge chal, the challenger
selects an ordered collection F = {mi}i∈I of blocks and an ordered collection
Σ = {Tmi}i∈I which are the veriﬁcation metadata corresponding to the blocks
in F such that Tmi = (s
j=1 hmi,j
j
)−sk = (s
j=1 hmi,j
j
)−a, for i ∈I. It then
randomly chooses r1, · · · , rs ∈R Zp and computes R∗
1 = hr1
1 , · · · , R∗
s = hrs
s .
It also randomly selects b1, · · · , bs ∈Zp and computes B∗
1 = hb1
1 , · · · , B∗
s =
hbs
s . It sets c∗= 
(i,vi)∈chal T vi
mi as well. Finally, the challenger returns ν∗=
(R∗
1, · · · , R∗
s, B∗
1, · · · , B∗
s, c∗).
Guess. The adversary returns a bit b′.
Analysis: We provide the analysis of the above security proof in Appendix B.
5
Performance
5.1
Computational and Communication Costs
In Figure 1, we compare the computational cost of our scheme with the ones in
[8,13]. We include the schemes from [8,13] for comparison since they are recent
and the oﬀer similar features to our scheme. In all the schemes, during the exe-
cution of the algorithm KeyGen, the number of exponentiations in G1 and
Fig. 1. Group multiplication, group exponentiation and pairing benchmarks. MZp and
MG1 denote multiplications in Zp and G1 respectively. EG1, EG2 and EGT denote expo-
nentiations in G1, G2 and GT respectively. P, PA and PS denote pairings, asymmetric
pairings and symmetric pairings respectively. Let “PV” denote “public veriﬁability”
and “D” denote “dynamicity”.; the expression “Let s be the number of sectors in one
ﬁle block and |I| be the cardinality of the set I ⊆]0, n+1[∩Q when setting the challenge
chal. A blank means that there is no group operation performed. Let “/” point out
symmetric pairings, i.e. G1 = G2 [13]. Let “-” mean that no operation is performed.

408
C. Gritti et al.
G2 is constant. The algorithm TagGen in [13] and ours requires O(s) expo-
nentiations in G1, where s is the number of sectors in each ﬁle block. In [8],
TagGen needs only a constant number of exponentiations in G1, however there
is an extra computation cost of generating the veriﬁcation metadata, which is
the cost of computing 3 exponentiations in GT and 3 pairings. Moreover, the
number of multiplications in G1 is constant in [8,13], whereas it is linear in s
in our case. In [13] and our scheme, the generation of proof of prossession in
GenProof needs the computation of O(s + |I|) exponentiations in G1; whereas
in [8], the generation of proof of prossession only involves the computation of
O(|I|) exponentiations in G1. In addition, the number of multiplications in G1
is linear in |I| in our scheme and in [8], whereas it it linear in both |I| and s in
[13]. The computation cost of checking the proof in CheckProof diﬀers in the
three schemes. In [8], the algorithm CheckProof requires O(|I|) exponentia-
tions in G1 and GT and 4 pairings. In [13], the algorithm CheckProof needs
O(s + |I|) exponentiations in G1 and a constant number of pairings equal to
3. Moreover, the number of multiplications in both Zp and G1 varies between
the three systems. In [8], O(s + |I|) and O(|I|) multiplications are required in
Zp and G1 respectively. In [13], O(s + |I|) multiplications in G1 are computed,
while O(s) multiplications in G1 are needed in our case. Finally, in our scheme,
the computation cost is lighter; more precisely it is only the cost of computing
3 pairings (no exponentiation is required).
The communication cost of our protocol is mostly due to two factors: the chal-
lenge and the proof of data possession. The communication cost of a challenge
chal = {(i, vi)}i∈I is |I|(|n| + |p|) bits, where |I| is the number of selected ﬁle
blocks, |n| is the length of an index and |p| is the length of an element in Zp. The
communication cost of a proof of data possession ν = (R1, · · · , Rs, B1, · · · , Bs, c)
is (2·s+1)|p| bits, where s is the number of sectors in each block. An additional
cost can be the communication cost of an updating proof ν′ = (U1, · · · , Us, C1,
· · · , Cs, d), which is (2 · s + 1)|p| bits, where s is the number of sectors in each
block. However, this happens only when the client wants to update its data. We
assume that the frequency of checking the integrity of the data is much higher
than the frequency of performing data operations. Therefore, we leave out this
additional cost.
5.2
Evaluation and Comparison of the Performance
We evaluate the practicality of our scheme and compare it to the one of the
scheme in [13]. We use results of cryptographic operation implementations (expo-
nentiations and pairings) using the MIRACL library, provided by Certivox for
the MIRACL Authentication Server Project Wiki. All the following experiments
are based on Borland C/C++ Compiler/Assembler and tested on a processor
2.4 GHz Intel i5 520M. For symmetric pairing-based systems (e.g. the scheme
in [13]), AES with a 80-bit key and a Super Singular curve over GFp, for a
512-bit modulus p and an embedding degree equal to 2, are used. For asym-
metric pairing-based systems (e.g. our scheme), AES with a 80-bit key and a
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
409
Fig. 2. Timings for symmetric and asymmetric pairing types and pairing-based sys-
tems. Times are in milliseconds. Let “Expon.” denote exponentations. Let “/” point
out symmetric pairings, i.e. G1 = G2 [13]. Let “-” denote the results are equal to zero.
Cocks-Pinch curve over GFp, for a 512-bit modulus p and an embedding degree
equal to 2, are used.
In Figure 2, we evaluate and compare the eﬃciency of our scheme. We assume
that 2 GB data are stored. The ﬁle is split into one million blocks of size 2 KB,
such that the size of the index is |n| = 20 bits. We assume that the number of
sectors in each ﬁle block is s = 100 and the number of blocks determined in the
challenge chal is |I| = 460. The main diﬀerence of time between the two proto-
cols is not due to the exponentiation and pairing number diﬀerence but rather
to the use of symmetric or asymmetric pairings. The total time in the algorithm
KeyGen is 2.98 milliseconds in [13], whereas it is only 0.51 milliseconds in our
construction. In the algorithm TagGen, it takes 151.98 milliseconds to generate
the veriﬁcation metadata in [13], whereas it takes one third of this time in ours.
Then, it requires a total time of 839.23 milliseconds in the algorithm GenProof
of [13], whereas, in our case, it requires only one third of this time. The reason
may be that there are two stages to generate the proof in [13] (called “commit-
ment” and “response”), while we need only one stage. Finally, in the algorithm
CheckProof, it takes 844.42 milliseconds to check the proof of data possession
in [13], whereas the time in our case is negligible. Indeed, the cost for verifying
the proof is constant in our protocol.
Remarks. The probability of detecting corrupted block is 1 −(1 −|X|
n )|I|, where
|X| is the number of corrupted blocks. Given 1, 000, 000 of blocks, the challenge
requires 460 blocks to allow the detection of 1% fraction of incorrect data with
99% probability of detecting misbehavior [3]. In several papers [3,7,9,16], this
observation is followed for the implementation and the experimentation of their
protocol. Because the number of computations is constant in our veriﬁcation
process, we are able to check more than 460 blocks, nay all the one million of
blocks. On the client’s side, the computational cost remains the same during the
algorithm CheckProof and slightly changes when creating the challenge: the
client has to pick at random |I| elements in Zp. If the number |I| increases, then

410
C. Gritti et al.
the client has to chooses more elements. However we consider that this cost is
negligible. In addition, we assume that the server has huge storage space and
computation stock: it is able to generate a proof of data possession on as many
blocks as the client requests.
We note that the eﬃciency of the scheme in [13] and ours are dependent on
the value of s. Thus, a bigger value s leads to a weaker eﬃciency for both of the
systems. Nevertheless, our scheme still remains more practical than the one in
[13] since the number of group exponentiations in the algorithms TagGen and
GenProof is linear in s in both of the systems and the number of exponenti-
ations in the algorithm CheckProof is also linear in s in [13] whereas there is
no exponentation is required in our scheme.
6
Conclusion
We proposed an eﬃcient Dynamic PDP with Public Veriﬁability and Data Pri-
vacy, which is more practical than the existing schemes in the literature. In par-
ticular, in order to check the proof of data possession generated by the server, the
client is not required to compute any exponentiation but rather only a constant
number of pairings.
References
1. Juels, A., Kaliski Jr., B.S.: Pors: proofs of retrievability for large ﬁles. In: Proc. of
CCS 2007 (2007)
2. Shacham, H., Waters, B.: Compact proofs of retrievability. In: Pieprzyk, J. (ed.)
ASIACRYPT 2008. LNCS, vol. 5350, pp. 90–107. Springer, Heidelberg (2008)
3. Ateniese, G., Burns, R., Curtmola, R., Herring, J., Kissner, L., Peterson, Z., Song,
D.: Provable data possession at untrusted stores. In: Proc. of CCS 2007 (2007)
4. Ateniese, G., Di Pietro, R., Mancini, L.V., Tsudik, G.E.: Scalable and eﬃcient
provable data possession. In: Proc. of SecureComm 2008 (2008)
5. Wang, C., Wang, Q., Ren, K., Lou, W.: Privacy-preserving public auditing for data
storage security in cloud computing. In: Proc. of INFOCOM 2010 (2010)
6. Hao, Z., Zhong, S., Yu, N.: A privacy-preserving remote data integrity check-
ing protocol with data dynamics and public veriﬁability. IEEE TKDE 23(9),
1432–1437 (2011)
7. Wang, B., Li, B., Li, H.: Oruta: privacy-preserving public auditing for shared data
in the cloud. IEEE TCC 2(1), 43–56 (2012)
8. Wang, B., Li, B., Li, H.: Knox: privacy-preserving auditing for shared data with
large groups in the cloud. In: Bao, F., Samarati, P., Zhou, J. (eds.) ACNS 2012.
LNCS, vol. 7341, pp. 507–525. Springer, Heidelberg (2012)
9. Erway, C., K¨up¸c¨u, A., Papamanthou, C., Tamassia, R.: Dynamic provable data
possession. In: Proc. of CCS 2009 (2009)
10. Wang, Q., Wang, C., Li, J., Ren, K., Lou, W.: Enabling public veriﬁability and
data dynamics for storage security in cloud computing. In: Backes, M., Ning, P.
(eds.) ESORICS 2009. LNCS, vol. 5789, pp. 355–370. Springer, Heidelberg (2009)
11. Zhu, Y., Wang, H., Hu, Z., Ahn, G.-J., Hu, H., Yau, S.S.: Dynamic audit services
for integrity veriﬁcation of outsourced storages in clouds. In: Proc. of SAC 2011
(2011)
www.ebook3000.com

Eﬃcient Dynamic Provable Data Possession
411
12. Yu, Y., Au, M.H., Mu, Y., Tang, S., Ren, J., Susilo, W., Dong, L.: Enhanced
privacy of a remote data integrity-checking protocol for secure cloud storage. IJIS,
1–12 (2014)
13. Zhu, Y., Ahn, G.-J., Hu, H., Yau, S.S., An, H.G., Hu, C.-J.: Dynamic audit services
for outsourced storages in clouds. IEEE TSC 6(2), 227–238 (2013)
14. Wang, C., Wang, Q., Ren, K., Lou, W.: Ensuring data storage security in cloud
computing. In: Proc. of IWQoS 2009 (2009)
15. Le, A., Markopoulou, A.: Nc-audit: Auditing for network coding storage. CoRR,
abs/1203.1730 (2012)
16. Wang, C., Wang, Q., Ren, K., Cao, N., Lou, W.: Toward secure and dependable
storage services in cloud computing. IEEE TSC 5(2), 220–232 (2012)
17. Yu, Y., Niu, L., Yang, G., Mu, Y., Susilo, W.: On the security of auditing mecha-
nisms for secure cloud storage. GCS 30(1), 127–132 (2014)
A
Deﬁnitions
Homomorphic Veriﬁable Tags (HVT). For each ﬁle block m, a HVT Tm is cre-
ated. A HVT acts as a veriﬁcation metadata for the ﬁle blocks and besides being
unforgeable, it has the blockless veriﬁcation property (the server constructs a
proof of data possession allowing the client to verify if the server possesses cer-
tain ﬁle blocks even when the client does not have access to the actual ﬁle blocks
along with the homomorphic tags property (given two veriﬁcation metadata Tmi
and Tmj, anyone can combine them into the veriﬁcation metadata Tmi+mj cor-
responding to the sum of the ﬁles mi + mj). The server stores the HVTs along
with the ﬁle. The client should be able to check the HVTs on speciﬁc blocks,
even though it does not possess any of these blocks, that is possible based on
the blockless veriﬁcation property of HVT.
Bilinear Maps. Let G1, G2 and GT be three multiplicative cyclic groups of prime
order p = p(λ) (where λ is the security parameter). Let g1 be a generator of G1,
g2 be a generator of G2 and e : G1 × G2 →GT be a bilinear map with the
bilinearity property (∀u ∈G1, ∀v ∈G2, ∀a, b ∈Zp, e(ua, vb) = e(u, v)ab) along
with the non-degeneracy property (e(g1, g2) ̸= 1GT ). (G1, G2) is said to be a
bilinear group if the group operation in (G1, G2) and the bilinear map e are
both eﬃciently computable.
B
Analysis of the Security Proofs
Security against the Server. We prove that if the adversary can win the game,
then a solution to the DL problem is found, which contradicts the assumption
that the DL problem is hard in G1. Let assume that the server wins the game.
Then, according to Eq. 2, we have e(c, ga
2) · e(s
j=1 Rj, g2) = e(s
j=1 ˜Bj, g2).
Since the proof ν = (R1, · · · , Rs, B1, · · · , Bs, c) is a correct one, we also have
e(c, ga
2) · e(s
j=1 Rj, g2) = e(s
j=1 Bj, g2). Therefore, we get that s
j=1 ˜Bj =
s
j=1 Bj. We can re-write as s
j=1 h
˜bj
j
= s
j=1 hbj
j
or even as s
j=1 hΔbj
j
= 1.

412
C. Gritti et al.
For two elements g, h ∈G1, there exists x ∈Zp such that h = gx since G1 is a
cyclic group. Without loss of generality, given g, h ∈G1, each hj could randomly
and correctly be generated by computing hj = gyj ·hzj ∈G1 such that yj and zj
are random values of Zp. Then, we have 1 = s
j=1 hΔbj
j
= s
j=1(gyj · hzj)Δbj =
g
s
j=1 yj·Δbj · h
s
j=1 zj·Δbj. Clearly, we can ﬁnd a solution to the DL problem.
More speciﬁcally, given g, h = gx ∈G1, we can compute h = g
s
j=1 yj ·Δbj
s
j=1 zj ·Δbj = gx
unless the denominator is zero. However, as we deﬁned in the game, at least one
element of {Δbj}j=1,··· ,s is non-zero. Since zj is a random element of Zp, the
denominator is zero with probability equal to 1/p, which is negligible. Thus, if
the adversary wins the game, then a solution of the DL problem can be found
with probability equal to 1 −1
p, which contradicts the fact that the DL problem
is assumed to be hard in G1. Therefore, for the adversary, it is computationally
infeasible to win the game and generate an incorrect proof of data possession
which can pass the veriﬁcation.
Moreover, the simulation of the tag generation oracle OT G is perfect. The
simulation of the data operation performance oracle ODOP is almost perfect
except when the challenger aborts. This happens the data operation was not
correclty performed. As previously, we can prove that if the adversary can pass
the updating proof, then a solution to the DL problem is found. Following the
above analysis and according to Eq. 1, if the adversary generates an incorrect
updating proof which can pass the veriﬁcation, then a solution of the DL problem
can be found with probability equal to 1 −1
p, which contradicts the fact that
the DL problem is assumed to be hard in G1. Therefore, for the adversary, it
is computationally infeasible to generate an incorrect updating proof which can
pass the veriﬁcation. The proof is completed.
Privacy against the TPA. The probability Pr[b′ = b] must be equal to 1
2 since
the veriﬁcation metadata Tmb,i, for i = 1, · · · , n, and the proof ν∗are indepen-
dent of the bit b. We now prove that the veriﬁcation metadata and the proof of
data possession given to the adversary are correctly distributed. The value Tmb,i
is equal to (s
j=1 hmb,i,j
j
)−sk = (s
j=1 hmb,i,j
j
)−a. Since sk = a is kept secret
from A, the above simulation is perfect. For a block ﬁle mb, there exists vb,i,
for (i, vb,i) ∈chalb, such that bb,j = 
(i,vb,i)∈chalb mb,i,j · vb,i + rb,j. In addition,
Rb,1, · · · , Rb,s, Bb,1, · · · , Bb,s are statically indistinguishable with the actual out-
puts corresponding to m0 or m1. Thus, the answers given to the adversary are
correctly distributed. The proof is completed.
www.ebook3000.com

Privately Computing Set-Union and
Set-Intersection Cardinality via Bloom Filters
Rolf Egert, Marc Fischlin(B), David Gens, Sven Jacob, Matthias Senker,
and J¨orn Tillmanns
Technische Universit¨at Darmstadt, Darmstadt, Germany
marc.fischlin@cryptoplexity.de
Abstract. In this paper we propose a new approach to privately com-
pute the set-union cardinality and the set-intersection cardinality among
multiple honest-but-curious parties. Our approach is inspired by a pro-
posal of Ashok and Mukkamala (DBSec’14) which deploys Bloom ﬁlters
to approximate the size tightly. One advantage of their solution is that it
avoids ample public-key cryptography. Unfortunately, we show here that
their protocol is vulnerable to actual attacks. We therefore propose a
new Bloom ﬁlter based protocol, also forgoing heavy cryptography, and
prove its security.
1
Introduction
The set-union cardinality problem consists of n parties, each party holding a
set Xi of data, and the task is to compute the size of the union of all sets,
s = | Xi|. Ideally, this should be done in a way such that only the ﬁnal result s
is revealed but nothing about the individual input sets. The problem is a close
relative to other so-called privacy-preserving set operation problems, including
the set-intersection cardinality problem where parties aim to compute s = | Xi|
securely, and the more general set-union and set-intersection problems where the
goal is to explicitly compute the union and the intersection, respectively, and not
only their cardinality. There are also more relaxed versions of the problem, called
disjointness and conjointness testing, where the parties only check whether the
size of the intersection resp. union is 0 or not.
Protocols for privacy-preserving set operations have numerous applications,
explaining the vast number of protocol proposals and publications (as discussed
below). To name a few applications, De Cristofaro et al. [4] point out that such
protocols can be used for anomaly detection in network monitoring or for iden-
tifying common friends in social networks. Kerschbaum [22] lists supply chain
integrity protection as another application. De Cristofaro et al. [4] also discuss
that the cardinality versions can be speciﬁcally used in the areas of genomic
computations, location sharing, or aﬃliation-hiding authentication.
1.1
The Ashok-Mukkamala Protocol
Ashok and Mukkamala [1] recently proposed a fast multi-party protocol for
the set union cardinality problem using Bloom ﬁlters. A Bloom ﬁlter [3] is an
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 413–430, 2015.
DOI: 10.1007/978-3-319-19962-7 24

414
R. Egert et al.
array-based representation for sets where each inserted element induces a set of
1’s in the array, based on the results of hashing the element with a set of public
hash functions.1 Verifying membership can be then carried out by re-hashing
the element and checking for 1-entries in the array. As such, Bloom ﬁlters have a
small but tolerable false-positive rate, since one may accidentally hit 1’s caused
by other elements. The size of a Bloom ﬁlter is usually proportional to the num-
ber of elements, independently of the size of the domain of the elements.
The idea of the Ashok and Mukkamala (AM) protocol is now to use the fact
that unions of Bloom ﬁlters correspond to the bit-wise OR of the arrays, which
facilitates the computation of the union of the underlying sets. The size of the
union then corresponds, with exponentially high accuracy [27], to the number
of 0’s and 1’s in the derived array. Unlike other solutions for the problem the
AM protocol does not rely on expensive cryptographic operations and reduces
the network communication overhead signiﬁcantly.
Unfortunately, the authors of [1] only sketch some ideas why their protocol
should indeed be secure, lacking a formal proof in the common simulation-based
sense of secure multi-party computation. Our ﬁrst result is to show that such
a proof is elusive. We show how each party in the AM protocol can predict
any other party’s input set with very high precision, even if honestly following
the protocol description, by inspecting the communication data afterwards. This
clearly violates the notion of a secure protocol.
1.2
Secure Cardinality Protocols Based on Bloom Filters
We adopt the approach [1] to use Bloom ﬁlters to devise protocols for the cardi-
nality problems. Our ﬁrst protocol is for the set-union cardinality problem and
for three (or more) parties. We assume that each party ﬁrst locally computes
the Bloom ﬁlter of its input set. In the protocol two dedicated parties act as
accumulators, receiving random shares of each party’s Bloom ﬁlter. The sharing
will be such that it is compatible with the union operation for Bloom ﬁlters,
enabling each accumulator to compute the union over their Bloom ﬁlter shares.
Both accumulators agree on a random permutation and forward the permuted
arrays of their shares to the third dedicated party, the evaluator. The evaluator
then assembles the permuted ﬁlters of the accumulators, computes the size of
the union from the number of 1’s, and announces the result to the other parties
(if required).
Our protocol computes the size of the union with very small error (due to
the negligible error caused by the Bloom ﬁlter approach and some term related
to the secret sharing of the ﬁlters). It withstands honest-but-curious adversaries,
as long as the adversary can only inspect the data of one of the three dedicated
parties, and it provably leaks only the size of the union of the input Bloom
ﬁlters of all parties.2 The protocol is perfectly secure and does not rely on any
1 The hash functions do not need to be cryptographically secure, but can still be based
on hash functions like SHA [29].
2 Note that one can in principle compile protocols in the honest-but-curious case to
thwart malicious attacks [13], albeit this comes with an observable slow down.
www.ebook3000.com

Privately Computing Set-Union
415
cryptographic assumption. It requires little interaction between parties and the
bit communication of each party is proportional to the size m of the Bloom ﬁlter.
The latter is based on the observation that, for the cardinality problem, we can
use “small” error-prone Bloom ﬁlter shares, as we are still able to approximate
the number of errors suﬃciently well and to subtract them out of the ﬁnal result.
We actually determine parameters enabling varying levels of communication
complexity and accuracy.
Next we brieﬂy discuss how to extent our protocol if more than one party
can be accessed by the adversary. Basically, to tolerate t accesses of dedicated
parties (and an arbitrary number of further parties) we need Ω(t2) parties in
total, building diﬀerent layers of accumulators. For example, for t = 2 we need
at least 6 participants. The protocol remains perfectly secure in the honest-but-
curious setting and still provides a linear communication complexity for each
party (linear in the size m of the Bloom ﬁlter).
We conclude with a two-party protocol for the cardinality problem, still based
on Bloom ﬁlters. The protocol is a slight modiﬁcation of the protocol of Kiayias
and Mitrofanova [24] for testing disjointness, adopted to the case of union car-
dinality and the Bloom ﬁlter setting. Here we however need to revert to cryp-
tographic means like homomorphic encryption. Our protocol is based on the
ElGamal encryption scheme and computes the set-union cardinality problem
in the honest-but-curious model. As opposed to similar protocols for the gen-
eral set-union problem we take advantage of the fact that we merely need to
compute the size of the union. This allows us to outsource the major compu-
tational eﬀort to compute m encryptions and thus modular exponentiations for
the Bloom ﬁlter array of size m to one party, the server. The client side, on the
other hand, only computes a single encryption and m modular multiplications.
This protocol appears in Appendix A.
We ﬁnally discuss that all our protocols can be easily adapted to compute
the set-intersection cardinality problem. Indeed, as pointed out in [4], solutions
in the two-party case for the private set-union cardinality problem in principle
also give rise to protocols for the intersection problem, noting that |X1 ∩X2| =
|X1| + |X2| −|X1 ∪X2|. However, this requires that the sizes of the individual
sets X1, X2 are public, or that incorporated privately into the computation. Also,
the formula gets signiﬁcantly more complicated for multiple parties.
Hence, we here instead use a direct approach for Bloom ﬁlters via De Mor-
gan’s law to adapt our protocols. This approach, surprisingly, went unnoticed
in [1]. Given the Bloom ﬁlters each party ﬁrst inverts its array bit-wise. Then they
compute the cardinality of the union of these inverted ﬁlters with our protocol.
This yields the bit-wise inverse of the AND of the original Bloom ﬁlters. The
parties can thus derive the cardinality of the intersection by subtracting the
cardinality of the obtained ﬁlter from the size of the Bloom ﬁlters.
1.3
Related Work
There are numerous works on privacy-preserving set operations, with various
security and complexity properties. We list here only protocols speciﬁcally for

416
R. Egert et al.
set operation problems, neglecting general-purpose multi-party protocols. Still,
we note that there are solutions which apply general methods like oblivious
transfer to the set-operation setting. For a comprehensive overview about such
approaches based on oblivious transfer, and their performance characteristics,
see [28]. We also omit a comparison to assisted protocols in which (partially)
trustworthy third parties support the evaluation; see [21] for an overview over
these protocols.
The early proposals for set operation protocols by Freedman et al. [11] and
by Kiayias and Mitrofanova [24] used polynomials to represent input sets and
jointly evaluated the polynomials via homomorphic encryption. Several sub-
sequent approaches [5,12,14,17,18,25] adopted this idea in order to improve
over security guarantees, eﬃciency, or functionality. Compared to our protocols
these works often aim at the more general problems of set intersection and set
union, and start by designing versions withstanding honest-but-curious adver-
saries before adding (eﬃcient) zero-knowledge proofs to achieve security against
malicious adversaries. At the same time, the proposals are usually more costly,
even in the honest-but-curious model, in the sense that they deploy public-key
cryptographic operations, and they often focus on the two-party case. This is
also true for other public-key based approaches like [4,6,7].
Besides the oblivious polynomial evaluation approach, intersections can also
be computed via oblivious pseudorandom functions [10]. Basically, this allows
one party to evaluate a pseudorandom function on selected values without knowl-
edge of the key, such that intersections can be spotted by comparing function
values. This approach has been reﬁned in several works [16,19,20], including also
proposals with trustworthy hardware tokens [9,15]. All these approaches are for
two-parties only and, due to the current state of art of oblivious pseudorandom
functions, based on public-key operations or additional hardware components.
Using Bloom ﬁlters for privacy-preserving set operations has been suggested
before for example in [22,23]. The former work [22] describes a Bloom ﬁlter
based two-party protocol using homomorphic encryption to allow membership
veriﬁcation of single elements. This comes at the cost of a high communication
complexity and reveals the element to be checked. The latter paper [23] extends
this idea and securely computes the set intersection via Bloom ﬁlters and homo-
morphic encryption, but adds extra computations on encrypted elements. Dong
et al. [8] used so-called garbled Bloom ﬁlters to compute intersections based on
oblivious transfer. Garbled Bloom ﬁlters basically store the bits of the under-
lying sets in a randomly shared way in a single ﬁlter. This is in contrast to
our approach in which the original ﬁlter is split into many shares. In addition,
the oblivious transfer step in their protocol is inherent, even in the honest-but-
curious model.
There are also approaches for secure set-operation protocols which are built
on top of very basic multi-party computation protocols. For example, using the
SEPIA library with secure protocols for addition and multiplication of bits,
Many et al. [26] propose to compute the union of Bloom ﬁlters via a bit-wise
OR according to the formula a ∨b = a + b −a · b. Especially the sub protocol for
www.ebook3000.com

Privately Computing Set-Union
417
multiplication in this formula, however, adds a signiﬁcant overhead. Similarly,
Blanton and Aguiar [2] use basic comparison operations and oblivious sorting to
implement set operations like the computation of the union in a modular way.
Compared to our dedicated solution the overhead is again noticeable.
2
Preliminaries
2.1
Secure Multi-Party Computation
We brieﬂy sketch here the prerequisites of secure multi-party computations as
in, e.g., [13]. More details can be found in the full version.
The general multi-party computation model assumes n participants, some-
times also called sites here. The goal of the parties is to jointly compute a function
f on their inputs, where we usually assume that one party derives this result and
ﬁnally distributes it to all other parties. This computation takes places in the
presence of an honest-but-curious adversary. This adversary may non-adaptively
decide to inspect up to t views of the parties after protocol completion and is
called t-bounded. The view of a party consists of the party’s input, its random-
ness, and the incoming and outgoing communication in the execution.3 To ensure
that nothing about a party’s input is leaked, we assume that there is a simulator
which can generate the same distribution of the t views given only the inputs of
the t inspected parties and the function value. In this case the protocol is said
to provide perfect privacy or perfect security.
Here we sometimes relax the requirement on completeness in the sense that
we allow for a small error in the protocol’s output. For a real-valued function f as
for our cardinality problems here we say that a protocol securely ϵ-approximates
f if security holds as above, and the protocol yields with probability 99, 9% an
output which is within the interval v ± ϵ of the actual function value v.
2.2
Using Bloom Filters for Multi-Party Computations
In this work we use Bloom ﬁlters to represent the sets Xi. Bloom ﬁlters, intro-
duced by Burton Howard Bloom in the 1970’s [3], are data structures for mem-
bership checking on sets. Given a data set X = {x1, x2, · · · , xd}, a bit-array of
size m, initialized with 0, and a set of public hash functions H = {h1, h2, · · · , hk}
with range {1, 2, . . . , m}, one creates the Bloom ﬁlter BF for the set X as follows.
For each pair xi ∈X and hj ∈H compute hj(xi) and set the corresponding bit
in the array to 1. To check if a given element a is in the set X one computes
all values hj(a) for j = 1, 2, . . . , k, looks up the corresponding entries in the
previously generated array, and predicts membership of a in X if and only if all
resulting array positions contain 1’s. This can only result in false positives due
to collisions, i.e., if the hash values hj(a) for some element a /∈X all map to 1’s
which have been set by hashing other elements.
3 We assume that all other network traﬃc is not available to the adversary, say, since
it is encrypted with fast hybrid or symmetric encryption.

418
R. Egert et al.
The error rate of Bloom ﬁlters directly corresponds to the size m of the bit
array, the number k of hash functions and the size d of the data set. To get
a good trade-oﬀbetween size of the Bloom ﬁlter and error-rate, we choose the
parameters such that the equation k = m
d ln 2, taken from [29], holds. As usual,
this assumes that the hash functions behave like independent random functions.
With this the Bloom ﬁlter should be ﬁlled to approximately 50%.
When using Bloom ﬁlters for private set operations one usually starts with
the representation of the input sets of the parties as Bloom ﬁlters for some
agreed-upon hash functions. The protocol then usually computes the union or
intersection (or their cardinality) of the Bloom ﬁlters BFi, neglecting the small
errors due to false-positive rate of the ﬁlters. In our case we thus compute the
(parameterized) function (X1, . . . , Xn) →|n
i=1 BFi| securely, where the hash
functions are given as randomly chosen parameters (for the function and to
the protocol participants, including the adversary) and are used to derive the
Bloom ﬁlters BFi. Note that computing m −|n
i=1 BFi|, as we actually do here,
is equivalent.4
We remark that cryptographic protocols using Bloom ﬁlters implicitly assume
an a-priori bound on the size of sets. The reason is that the common parameters
for the Bloom ﬁlters are usually chosen to match these numbers. Else, if chosen
independently of the data size, the error rate for functional correctness may
increase signiﬁcantly. We also make the assumption here, visualized by the fact
that the k hash functions for the ﬁlter and the ﬁlters’ size m are available to all
parties in our protocol.
3
Attacks on the Ashok-Mukkamala Protocol
As mentioned before security of a protocol for the set-union cardinality problem
should guarantee that participants cannot learn anything about other parties’
inputs beyond the size of the union of all data. We now show that the scheme pro-
posed in [1] violates this security property as an adversary can identify another
party’s input with high probability. This holds even if the adversary only inspects
the communication data of a party after protocol completion.
3.1
The AM-Protocol in a Nutshell
Recall that the AM-Protocol is based on the approximation of the size of a
set via the entries in a Bloom ﬁlter. That is, given k independent and agreed-
upon hash functions h1, . . . , hk with range in {1, 2, . . . , m} —where we assume
in the analysis that the functions are random— we build the Bloom ﬁlter of bit
size m by hashing each element x ∈X via all functions hi(x) and setting the
corresponding bit to 1. Then, given only the Bloom ﬁlter, we can approximate
the size of X via the number z of zeros in the ﬁlter by:
4 The protocol in [1] also seems to aim to compute this function securely, but this is
not speciﬁed.
www.ebook3000.com

Privately Computing Set-Union
419
|X| =
ln(z/m)
k ln(1 −1/m)
Furthermore, the approximation is quite tight [29].
The AM-Protocol exploits that the bitwise OR of partial Bloom ﬁlters for
any r sets of hash function indices K1, K2, . . . , Kr ⊆{1, 2, . . . , k} yields a Bloom
ﬁlter for the hash functions with indices in the union K1 ∪K2 ∪· · · ∪Kr. More
precisely, letting BF|K denote the Bloom ﬁlter created by applying only hash
functions with indices from K ⊆{1, 2, . . . , k} to the set X, we have
r
i=1
BF|Ki = BF|∪r
i=1Ki.
This enables each site Si to split the entire Bloom ﬁlter for its input data into
partial ones, one for each other party Sj, by picking random subsets KSi→Sj ⊆
{1, 2, . . . , k} of all hash functions h1, . . . , hk, and creating the partial Bloom
ﬁlters BFSi→Sj = BF|KSi→Sj . Each partial ﬁlter is then handed to the site Sj
for further processing. This is called the decomposition phase in [1].
For correctness it is necessary to ensure that all hash keys are used in some
Bloom ﬁlter BFSi→Sj of party Si. The AM-Protocol therefore ﬁrst lets Si pick a
random number rSi→Sj in some range [a, b] for each partial ﬁlter, and then lets
Si include rSi→Sj random keys in the subset KSi→Sj. The exact ﬁgures and the
roles of a, b remain unspeciﬁed; it seems to us that they should prevent trivial
subsets. To ensure that each key appears in at least one ﬁlter, the AM-protocol
once more lets Si randomly assign each hash key to one of the n partial Bloom
ﬁlters.
Once a party Sj has received the partial Bloom ﬁlters BFSi→Sj from all sites
Si, the party Sj computes the union of all these Bloom ﬁlters to create a ﬁlter
BF′
Sj and sends out this value to all other sites. This is called the reconstruction
phase in [1]. In the ﬁnal merger phase each site Si computes the Bloom ﬁlter
union over all values BF′
Sj received from the n sites Sj. The ﬁnal step is now to
approximate the size of the union of the input data via the number z of 0-entries
in the ﬁnal Bloom ﬁlter.
3.2
Attack #1: Computing a Candidate List
Note that the underlying security idea of the AM-Protocol is that in the decom-
position phase each party Sj only obtains a partial Bloom ﬁlter BFSi→Sj from
any other party Si. In fact, Ashok and Mukkamala [1] argue about the number
rSi→Sj of used hash functions being well distributed, neglecting the question
of how much information about the original data is still contained in a partial
Bloom ﬁlter. This observation is the leverage for our ﬁrst attack, which allows us
to use the partial Bloom ﬁlters to verify, with high accuracy, if the other party’s
input contains some individual data x.
To illustrate our attack assume that rSi→Sj hash functions with indices
KSi→Sj have been used to construct the partial Bloom ﬁlter BFSi→Sj. Both

420
R. Egert et al.
the number rSi→Sj and the actual set KSi→Sj are only known to party Si.
Party Sj now tries to check whether some data x is part of Si’s input or not. To
do so, it ﬁrst computes the fraction p ∈[0, 1] of 1-entries in the partial Bloom
ﬁlter. Then Sj hashes x with all hash functions h1, . . . , hk and counts how often
it hits 1’s in the ﬁlter BFSi→Sj. If x is not part of Si’s input, the hash values
will, on the average, hit kp times; if x on the other hand, is contained in the
set, the process will generate rSi→Sj hits for the rSi→Sj actually chosen hash
functions in KSi→Sj, plus an expected (k −rSi→Sj)p hits for the remaining,
unused hashed functions. On the average these are about kp + (1 −p)rSi→Sj
hits, which exceeds the amount in the other case signiﬁcantly for reasonable
parameter choices. Although this gap and the number of samples is presumably
too small to apply the Chernoﬀ-Hoeﬀding bounds for estimating the deviation
of expectations, our experiments and threshold choice below show that this gap
suﬃces for a good prediction. Hence, Sj can decide membership of x in Si’s
input with high probability.
We have run simulations on how good we can actually predict membership
of elements. For this we created two Bloom ﬁlters for sets Xi, Xj with a given
overlap |Xi ∩Xj| for the respective parameters m, |Xi| = |Xj|, and k. Since
we work with the Bloom ﬁlters exclusively and the actual data are irrelevant,
we emulated ideal hash functions by inserting 1’s for each element at random
positions to create the Bloom ﬁlters (but with consistent position choice for the
common elements, of course). For the partial Bloom ﬁlters we picked a random
subset rSi→Sj ∈[a, b] of the hash functions, where we chose a = 3 and b = k −3.
For each parameter set we repeated the experiment 1, 000 times, averaging the
results.
Table 1. Simulation results for attack #1
|Xi| = |Xj| = 10, 000,
m = 1, 000, 000, k = 70
|Xi ∩Xj| precision recall
10
79.5 %
90.8 %
100
95.4 %
83.8 %
1000
99.2 %
71.7 %
|Xi| = |Xj| = 10, 000,
m = 2, 000, 000, k = 140
|Xi ∩Xj| precision recall
10
92.2 %
94.9 %
100
97.6 %
90.9 %
1000
99.8 %
83.3 %
|Xi| = |Xj| = 25, 000,
m = 1, 000, 000, k = 70
|Xi ∩Xj| precision recall
10
31.3 %
69.9 %
100
72.5 %
58.4 %
1000
93.9 %
45.3 %
To determine the candidate elements we ﬁrst count the number of ones for
each element. Then we compute the average and maximum count (AVG and
MAX) over all elements. Finally we select all elements as candidates for which
the count is equal or greater to the following bound:
AVG + max(0.6, p) · (MAX −AVG)
That is, if the hits exceeds the average number by about 60% of the gap to the
maximum (or a p-fraction of the gap, where p is the ratio of 1’s in the received
www.ebook3000.com

Privately Computing Set-Union
421
Bloom ﬁlter) then we consider the value to be in the set. Extensive simulations
with diﬀerent approaches to calculate the bound led us to the given formula.
Table 1 shows our simulation results. Here, precision (basically determin-
ing exactness) designates the percentage of correctly identiﬁed candidates out
of all the chosen candidates. We mark the percentage of correctly identiﬁed
candidates out of the actually shared elements as recall (basically determining
completeness).
3.3
Attack #2: Reconstructing the Set of Hash Functions
For the second attack we use a candidate list of common elements which could
have been generated, for example, by our ﬁrst attack. The attack here takes
advantage of the fact that, for common elements, we can check if one of the
k hash functions coincides on these elements. That is, for each of the k hash
functions we check how many of the elements in the list hit a 1 in the partial
Bloom ﬁlter we have obtained. We can roughly expect that only the actually
chosen r hash functions will produce hits for all candidates.
Once we have identiﬁed the used hash functions we can in principle use the
partial Bloom ﬁlter to plot out the other party’s elements, with an error which
is higher than for the optimal choice for Bloom ﬁlter parameters, but still giving
useful information to an attacker. We refrain from doing so here, though, as the
importance to hide this choice has already been mentioned in [1].
We have again run experiments to verify the correctness of our idea. We
have used the same parameters as for the ﬁrst attack. We used the exact list of
common elements as the candidate list. Our algorithm decided to include a hash
function as chosen if the number of ones counted for that hash function is greater
or equal to (AVGh + MAXh)/2 where AVGh and MAXh are the average and
maximum number of ones for all hash functions. The results of our experiments
are given in Table 2.
Table 2. Simulation results for attack #2
|Xi| = |Xj| = 10, 000,
m = 1, 000, 000, k = 70
|Xi ∩Xj| success
10
99.2 %
100
100 %
1000
100 %
|Xi| = |Xj| = 10, 000,
m = 2, 000, 000, k = 140
|Xi ∩Xj| success
10
97.3 %
100
100 %
1000
100 %
|Xi| = |Xj| = 25, 000,
m = 1, 000, 000, k = 70
|Xi ∩Xj| success
10
65.2 %
100
100 %
1000
100 %
3.4
Combination of Attacks #1 and #2
As brieﬂy mentioned before the attacks can also be combined. In the ﬁrst step
we use attack #1 to generate a list of candidates that, with high probability,
are part of the other party’s input. We subsequently use this candidate list

422
R. Egert et al.
as an input for attack #2 to reconstruct the hash function set. The results of
the simulation of the combined attack are displayed in Table 3 where success
denotes the likelihood of identifying the r chosen hash functions correctly. Note
that we cannot expect to achieve the same success rate as in the case of the exact
candidate list, but our experiments show that for suﬃciently large intersections
we still achieve overwhelming rates.
Table 3. Simulation results for combination of attacks #1 and #2
|Xi| = |Xj| = 10, 000,
m = 1, 000, 000, k = 70
|Xi ∩Xj| success
10
75.7 %
100
99.5 %
1000
99.9 %
|Xi| = |Xj| = 10, 000,
m = 2, 000, 000, k = 140
|Xi ∩Xj| success
10
90.1 %
100
99.9 %
1000
100 %
|Xi| = |Xj| = 25, 000,
m = 1, 000, 000, k = 70
|Xi ∩Xj| success
10
0.7 %
100
70.7 %
1000
99.7 %
4
Advanced Protocols for the Set-Union Cardinality
Problem
In this section we present our new protocols. Although inspired by the general
idea of using Bloom ﬁlters as in [1] our proposed solutions are substantially
diﬀerent in the way they deploy Bloom ﬁlters. We only describe here the set-
union protocol; the set-intersection protocol can be derived by working over the
inverted Bloom ﬁlters, as explained in the Introduction.
4.1
The Three-Party Case
We ﬁrst discuss the most basic scenario of our protocol with an arbitrary number
of regular participants and three core nodes A,B and C. Two of the core nodes
will act as accumulators of intermediate results of other parties and forward
their values to the third party, the evaluator, who will compute the ﬁnal result
(and possibly distribute it to all other parties). An overview over the proposed
protocol is given in Figure 1. Each of the core nodes acts as a regular participant,
too, but has to perform some additional work. The protocol consists of a general
part which is executed by all members and a special part for the core nodes. For
simpliﬁcation we will refer to the core nodes as A, B and C for the rest of this
section, where A and B are called accumulators and C is called the evaluator.
The idea of the ﬁrst part of the protocol is that each party ﬁrst locally com-
putes its Bloom ﬁlter for its input. Then the party transforms the representation
of its Bloom ﬁlter of 0’s and 1’s into b-bit values where
0 →0 mod 2b,
1 →random element mod 2b.
www.ebook3000.com

Privately Computing Set-Union
423
Si
A
B
C
input: Xi
locally
compute
BFi for
Xi,
ShSi→A
−−−−−→
accumulate
ShSi→A’s
apply
transfor-
mation to
obtain
ShSi
ShSi→B
−−−−−−−−−−−−−−−−−−−−−−→
accumulate
ShSi→B’s
pick
random
permuta-
tion
π
π
−−−−→
compute
π( ShSi→A)
π( ShSi→A)
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−→
compute
π( ShSi→B)
π( ShSi→B)
−−−−−−−−−−−−−−→
compute # of
0-entries
output:
m −|  BFi|
Fig. 1. Protocol steps in the case of three or more parties
Here b = 4, 8 or 16 may be appropriate choices, but even b = 1 is possible if
one can tolerate slightly higher error rates. Subsequently the party splits its
transformed Bloom ﬁlter representation into two equal-size shares ShSi→A and
ShSi→B by mapping an entry r mod 2b to random r1, r2 mod 2b such that r =
r1+r2 mod 2b and placing r1 in the ﬁrst Bloom ﬁlter share and r2 into the second
one. Note that each of the two Bloom ﬁlter shares individually does not reveal
any information about the original values. An example of this transformation
process for b = 8 and thus Z256 is given in Figure 2.
1|0|1|1|0|1|0|1|...
25|0|125|68|0|230|0|137|...
128|69|222|5|101|68|53|96|...
153|187|159|63|155|162|203|41|...
ShSk→A
ShSk→B
Original BF
Random Element
A+B %256 ≡ rand Elm
0 → 0
1 → {0,..,255}
Fig. 2. Local share computation of a node’s Bloom ﬁlter

424
R. Egert et al.
The parties now all send their ﬁrst Bloom ﬁlter share to the accumulator A,
and their second share to accumulator B. For each entry in the arrays, the accu-
mulator simply sums up the corresponding entries in all received ﬁlter shares. At
this point neither A nor B individually possess any useful information about the
Bloom ﬁlters of the other parties. Still they hold a shared version of the com-
bined Bloom ﬁlter of all parties. Now they agree on a random permutation π over
{1, 2, . . . , m} and permute the entries of their shares according to π. This step is
necessary to ensure that the evaluator C cannot reconstruct information about
individual data from the combined ﬁlter. Both A and B then send their permuted
ﬁlters to C who adds the entries component-wise and ﬁnally counts the number
of 0-entries in the derived ﬁlter. Eventually C can compute an approximation
the size of the union set as in [1]. An example of the calculations performed by
the accumulators and the evaluator is given in Figure 3.
B
A
183|113|255|27|112|134|130|184|...
∑ ShSi→A
113|134|130|184|183|112|255|27|...
π 
π (∑ ShSi→A)
π 
π (∑ ShSi→A)
π (∑ ShSi→B)
Random Permutaon π 
98|74|25|41|156|96|126|66|...
74|96|126|66|98|156|25|41|...
π 
π (∑ ShSi→B)
∑ ShSi→B
113|134|130|184|183|112|255|27|...
 74 | 96 |126| 66 | 98 |156| 25 | 41 |...
187|230|  0  |250| 25 | 12 | 24 | 68 |...
∑ 
-> 7 ones  -> esmate |L(X)|
Fig. 3. Accumulation and evaluation of the transmitted Bloom ﬁlters by the core nodes
Note that the ﬁnal result, independently of the inaccuracies due to the set-
size approximation technique via the zeros, contains a small error. This error is
introduced by the representation of 1’s as random elements in Z2b, potentially
picking 0 mod 2b for a 1-entry.5 However, we can actually estimate these false
elements quite accurately: Let z0 denote the number of 0-entries in the ﬁnal
Bloom ﬁlter, and z1 the number of (false) 0-representations of original 1-entries,
such that z = z0 + z1 for the eventually derived number z of zeros. Note that
the expected value (over the random representations of the parties) of z1 is
2−b(m −z0) since each of the m −z0 non-zero entries is misrepresented with
probability 2−b. It follows that the expected number Ez0 of z0 is given by
Ez0 = z −2−bm
1 −2−b .
5 Excluding 0-representations for 1’s potentially enables an attacker to trace the orig-
inal 0-entries with some small, yet noticeable probability, such that we rather accept
an error on the side of correctness.
www.ebook3000.com

Privately Computing Set-Union
425
Hence, given z (and the parameters m, b) we can approximate the actual value
of z0 easily.
Furthermore, since z1 is given by the sum of independent variables, the num-
ber of errors in our approximation follows a binomial distribution. Suppose we
take for z1 a conﬁdence interval of 99.9%. Then we can calculate the error bounds
for the estimation of z0 and thus of the ﬁnal result for diﬀerent values of b and
| Xi|, the actual size of the union. Approximating the binomial distribution
through the Gaussian distribution we obtain that with probability at least 99.9%
the result of an honest execution of the protocol lies within an interval ±3.29
times the standard deviation σ :=

(m −z0) · 2−b(1 −2−b) around the mean.
In this case, using the formula for estimating z0, our approximation is in the
interval (m−z0)±3.29σ/(1−2−b) for the standard deviation σ with probability
99.9%.
For a concrete example consider a densely ﬁlled Bloom ﬁlter of size m =
1, 000, 000, with only 10% of 0-entries, and let b = 1. Then with probability
of 99.9% our guess will be within ±1, 561 elements of the expected 450, 000
misrepresentations. Approximating z0 as above with the same conﬁdence we
will output an estimation in the interval between 96, 878 and 103, 122 for the
actual value 100, 000. For the same value of m, but 50% of the Bloom ﬁlter being
ﬁlled, and now with b = 8, our approximation of the actual value of 500, 000 is
within the range 498, 854 and 500, 146 with probability of at least 99.9%.
4.2
Proof of Security
We will now show security for our proposed protocol. Recall that the notion
of ϵ-approximation means that, in terms of correctness, the output value (for
a benign execution) is within an interval ±ϵ of the actual function value with
probability 99.9%.
Theorem 1. Let n ≥3 and consider the n-party protocol in Section 4.1. The
protocol ϵ-approximates the function fm,h1,...,hk(X1, . . . , Xn) = m −|n
i=1 BFi|
perfectly secure in the honest-but-curious case against 1-bounded non-adaptive
adversaries, where ϵ = 3.29 · (1 −2−b)
−1 ·

2−b · (1 −2−b) · |n
i=1 BFi|.
We stress again that the parameter b only inﬂuences the correctness of the
computation. The bound for ϵ has already been derived in the previous section.
Note that for large b, like b = 128, and reasonable ﬁlter size the approximation
is correct with probability 99.9%.
Proof. First note that if the party inspected by the adversary is diﬀerent from
a core node then security is trivial, as such parties only send out information.
Such a view is easy to simulate because the simulator receives the party’s input.
We can thus focus on the case of the adversary accessing one of the core nodes.
Consider ﬁrst the case that an adversary inspects one of the accumulators A
or B. We only consider the case of A here, as the case of B is analogous; the only
diﬀerence is that A chooses the random permutation and transmits it. Because A

426
R. Egert et al.
is an accumulator, the adversary in the actual protocol execution learns a single
share of every Bloom ﬁlter of every participant of the protocol. The entries
of these shares ShSi→A, i = 1, 2, . . . , n are determined by the randomness of
the corresponding participant Si. Each share individually consists of m random
elements from Z2b.
We can devise a simulator for A as follows: The simulator receives as input A’s
input set and the output of the protocol |n
i=1 BFi| (if this value is eventually
distributed to all participants by the evaluator C). It creates a view of A by
faithfully computing the ﬁrst outgoing messages of A as an ordinary participant
via A’s input data. Then it simulates each incoming share ShSi→A by picking m
random elements from Z2b. The simulator also places a random permutation π
in A’s view, and the aggregated and permuted ﬁlter shares as the message sent
to C. It is easy to see that our simulator perfectly simulates the view of A in an
actual protocol execution.
Finally consider the case that the adversary asks to see the view of the
evaluating node C. The node C in the actual protocol execution receives as
input two randomly permuted vectors sent by A and B. When put together,
these vectors add up to m−| BFi| presentations of 0-entries plus a random set
of false 0-presentations of 1-entries, i.e., where the shares add up to 0 mod 2b.
We can build a simulator as follows. The simulator, receiving m −| BFi| and
C’s data set, ﬁrst creates the random ﬁlter shares C would send as an ordinary
participant to A and B. It next prepares an empty Bloom ﬁlter and randomly
distributes | BFi| random elements from Z2b and leaves the other entries as 0.
It next splits all the entries of this ﬁlter randomly into two Bloom ﬁlters as
the protocol participants, and puts these shares into the view of C. This again
perfectly simulates the actual view of C in a genuine protocol execution, where
C also receives randomly permuted entries of the same distribution.
⊓⊔
4.3
Extensions to the Multi-Party Case
The basic three-party protocol which we described previously is only secure if at
most one of the three core nodes is inspected by an adversary. For an adversary
being able to access more core nodes we need to adapt the previous approach.
The basic idea of our extension is to use additional layers of accumulators. The
i-th layer (where we count the evaluator as layer 1 and the two accumulators
of the basic case as layer 2) will consist of i accumulators. To withstand t-
bounded adversaries we will use t + 1 of such layers where parties can only act
as accumulators on one level. The set-up for t = 2 is given in Figure 4.
The execution starts by having each party compute its Bloom ﬁlter and split-
ting it up into t + 1 random shares over the group Z2b similar to the three-party
case. i.e., 0-entries are random shares of 0, and 1-entries become random shares
of random elements from Z2b. Again all of the core nodes are also participating
in the general Bloom ﬁlter distribution phase in the beginning, i.e., act both as
accumulators as well as contributors. Then each party sends its t + 1 shares to
the parties of the highest accumulator layer. The accumulators of a layer accu-
mulate their shares and permute the accumulated Bloom ﬁlter shares randomly,
www.ebook3000.com

Privately Computing Set-Union
427
where each layer picks a fresh permutation, e.g., chosen by one party and dis-
tributed to the accumulators of the same layer.
In the next step the accumulators forward their ﬁlters to the next lower layer.
Here, allowing to reduce the communication overhead, it suﬃces that each lower-
level accumulator receives at least two independent shares from the higher layer.
In Figure 4 party B for example guarantees the two independent shares by
splitting its share for the lower level, such that A and C can simply forward
their share. When the evaluator eventually receives the shares it computes the
output as before.
Security relies on the same observation as in the three-party case. First
note that the adversary cannot obtain all individual shares of a participant
sent to the t + 1 accumulators of the highest layer, as the adversary can only
inspect up to t parties. The adversary could, potentially, inspect all t parties
of the second highest layer, but then the data would correspond to randomly
permuted shares of the overall result already. This is again easy to simulate,
similar to the case of inspection of the evaluator C in the three party case.
If the adversary, on the other hand, inspects a party of the highest layer to
learn the random permutation of that layer, then it must miss one of the t parties
of the second highest layer and thus at least one of the shares. We can set this
argument forth, noting that if the adversary misses the permutation of the Bloom
ﬁlters (as the composition of all permutations of all t layers, except for layer 1)
by not inspecting any party of some layer, then the t-bounded adversary can-
not learn any information, besides inspecting the evaluator. But the t-bounded
adversary can only learn the permutation if it inspects one accumulator for each
layer. But then it misses the data of the evaluator and could only derive infor-
mation about individual Bloom ﬁlters if it was able to access all shares of a layer.
But by construction, since it inspects one party at each of the t layer levels, it
must lack knowledge of a share on each level for every Bloom ﬁlter. It follows as
in the three-party case that nothing is leaked except the function’s output.
S1
Sn
A
B
C
D
E
F
π(∑ ShSi→A)=ShA→D 
ShB→D
π(∑ ShSi→C)=ShC→E 
ShB→E
Ƭ(ShA→D+ShB→D)=ShD→F 
Ƭ(ShB→E+ShC→E)=ShE→F 
ShSi→A 
ShSi→B 
ShSi→C 
permutaon π
π 
Permutaon Ƭ 
π(∑ ShSi→B)=ShB→D+ShB→E 
Fig. 4. Accumulation and evaluation by the core nodes in the multi-party case

428
R. Egert et al.
5
Conclusion
Our protocols adopt the basic idea of the AM protocol to devise secure multi-
party protocols which are provably secure, lightweight on the crypto operations,
and low on network communication. It remains an interesting open question
how one can enhance our protocol to withstand malicious adversaries, ideally
forgoing expensive zero-knowledge proofs. Also, a worthwhile eﬀort would be to
devise errorless versions of our protocol.
Acknowledgments. Marc Fischlin is supported by the Heisenberg grant Fi 940/3-2
and SPP 1736 grant Fi 940/5-1 of the German Research Foundation (DFG).
References
1. Ashok, V.G., Mukkamala, R.: A scalable and eﬃcient privacy preserving global
itemset support approximation using bloom ﬁlters. In: Atluri, V., Pernul, G. (eds.)
DBSec 2014. LNCS, vol. 8566, pp. 382–389. Springer, Heidelberg (2014)
2. Blanton, M., Aguiar, E.: Private and oblivious set and multiset operations. In:
Youm, H.Y., Won, Y. (eds.) ASIACCS 2012, pp. 40–41. ACM Press, May 2012
3. Bloom, B.H.: Space/time trade-oﬀs in hash coding with allowable errors. Commu-
nications of the ACM 13(7), 422–426 (1970)
4. De Cristofaro, E., Gasti, P., Tsudik, G.: Fast and private computation of cardinality
of set intersection and union. In: Pieprzyk, J., Sadeghi, A.-R., Manulis, M. (eds.)
CANS 2012. LNCS, vol. 7712, pp. 218–231. Springer, Heidelberg (2012)
5. Dachman-Soled, D., Malkin, T., Raykova, M., Yung, M.: Eﬃcient robust private
set intersection. In: Abdalla, M., Pointcheval, D., Fouque, P.-A., Vergnaud, D.
(eds.) ACNS 2009. LNCS, vol. 5536, pp. 125–142. Springer, Heidelberg (2009)
6. De Cristofaro, E., Kim, J., Tsudik, G.: Linear-complexity private set intersection
protocols secure in malicious model. In: Abe, M. (ed.) ASIACRYPT 2010. LNCS,
vol. 6477, pp. 213–231. Springer, Heidelberg (2010)
7. De Cristofaro, E., Tsudik, G.: Practical private set intersection protocols with lin-
ear complexity. In: Sion, R. (ed.) FC 2010. LNCS, vol. 6052, pp. 143–159. Springer,
Heidelberg (2010)
8. Dong, C., Chen, L., Wen, Z.: When private set intersection meets big data: an
eﬃcient and scalable protocol. In: Sadeghi, A.R., Gligor, V.D., Yung, M. (eds.)
ACM CCS 2013, pp. 789–800. ACM Press, November 2013
9. Fischlin, M., Pinkas, B., Sadeghi, A.-R., Schneider, T., Visconti, I.: Secure set
intersection with untrusted hardware tokens. In: Kiayias, A. (ed.) CT-RSA 2011.
LNCS, vol. 6558, pp. 1–16. Springer, Heidelberg (2011)
10. Freedman, M.J., Ishai, Y., Pinkas, B., Reingold, O.: Keyword search and obliv-
ious pseudorandom functions. In: Kilian, J. (ed.) TCC 2005. LNCS, vol. 3378,
pp. 303–324. Springer, Heidelberg (2005)
11. Freedman, M.J., Nissim, K., Pinkas, B.: Eﬃcient private matching and set intersec-
tion. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004. LNCS, vol. 3027,
pp. 1–19. Springer, Heidelberg (2004)
12. Frikken, K.B.: Privacy-preserving set union. In: Katz, J., Yung, M. (eds.) ACNS
2007. LNCS, vol. 4521, pp. 237–252. Springer, Heidelberg (2007)
13. Goldreich, O.: The Foundations of Cryptography, vol. 2. Cambridge University
Press (2004)
www.ebook3000.com

Privately Computing Set-Union
429
14. Hazay, C.: Oblivious polynomial evaluation and secure set-intersection from alge-
braic PRFs. In: Dodis, Y., Nielsen, J.B. (eds.) TCC 2015, Part II. LNCS, vol. 9015,
pp. 90–120. Springer, Heidelberg (2015)
15. Hazay, C., Lindell, Y.: Constructions of truly practical secure protocols using stan-
dardsmartcards. In: Ning, P., Syverson, P.F., Jha, S. (eds.) ACM CCS 2008, pp.
491–500. ACM Press, October 2008
16. Hazay, C., Lindell, Y.: Eﬃcient protocols for set intersection and pattern match-
ing with security against malicious and covert adversaries. Journal of Cryptology
23(3), 422–456 (2010)
17. Hazay, C., Nissim, K.: Eﬃcient set operations in the presence of malicious adver-
saries. Journal of Cryptology 25(3), 383–433 (2012)
18. Hohenberger, S., Weis, S.A.: Honest-veriﬁer private disjointness testing without
random oracles. In: Danezis, G., Golle, P. (eds.) PET 2006. LNCS, vol. 4258,
pp. 277–294. Springer, Heidelberg (2006)
19. Jarecki, S., Liu, X.: Eﬃcient oblivious pseudorandom function with applications
to adaptive OT and secure computation of set intersection. In: Reingold, O. (ed.)
TCC 2009. LNCS, vol. 5444, pp. 577–594. Springer, Heidelberg (2009)
20. Jarecki, S., Liu, X.: Fast secure computation of set intersection. In: Garay, J.A.,
De Prisco, R. (eds.) SCN 2010. LNCS, vol. 6280, pp. 418–435. Springer, Heidelberg
(2010)
21. Kamara, S., Mohassel, P., Raykova, M., Sadeghian, S.: Scaling private set inter-
section to billion-element sets. In: Christin, N., Safavi-Naini, R. (eds.) FC 2014.
LNCS, vol. 8437, pp. 195–215. Springer, Heidelberg (2014)
22. Kerschbaum, F.: Public-key encrypted bloom ﬁlters with applications to supply
chain integrity. In: Li, Y. (ed.) Data and Applications Security and Privacy XXV.
LNCS, vol. 6818, pp. 60–75. Springer, Heidelberg (2011)
23. Kerschbaum, F.: Outsourced private set intersection using homomorphic encryp-
tion. In: Youm, H.Y., Won, Y. (eds.) ASIACCS 2012, pp. 85–86. ACM Press, May
2012
24. Kiayias, A., Mitrofanova, A.: Testing disjointness of private datasets. In: S. Patrick,
A., Yung, M. (eds.) FC 2005. LNCS, vol. 3570, pp. 109–124. Springer, Heidelberg
(2005)
25. Kissner, L., Song, D.: Privacy-preserving set operations. In: Shoup, V. (ed.)
CRYPTO 2005. LNCS, vol. 3621, pp. 241–257. Springer, Heidelberg (2005)
26. Many, D., Burkhart, M., Dimitropoulos, X.: Tech. Rep. TIK report no. 345, ETH
Zurich, Switzerland (2012)
27. Papapetrou, O., Siberski, W., Nejdl, W.: Cardinality estimation and dynamic
length adaptation for bloom ﬁlters. Distributed and Parallel Databases 28(2–3),
119–156 (2010)
28. Pinkas, B., Schneider, T., Zohner, M.: Faster private set intersection based on OT
extension. In: Proceedings of the 23rd USENIX Security Symposium, San Diego,
CA, USA, August 20–22, pp. 797–812. USENIX Association (2014)
29. Tarkoma, S., Rothenberg, C.E., Lagerspetz, E.: Theory and practice of bloom
ﬁlters for distributed systems. IEEE Communications Surveys and Tutorials 14(1),
131–155 (2012)

430
R. Egert et al.
A
The Two-Party Case
In the two-party case it seems inevitable to rely on public-key cryptography and
computations on encrypted data. Our solution here utilizes the homomorphic
property of the ElGamal encryption scheme. In the full version we discuss that
it is computationally secure under the decisional Diﬃe-Hellman assumption. In
contrast to the other protocols, the protocol here provides perfect correctness.
Our protocol has the interesting feature that the major part of computational
complexity lies on one side, supporting typical client-server scenarios: While one
party has to perform 2m exponentiations to create the m ElGamal encryptions
of the m Bloom ﬁlter entries, the other party merely needs to compute two
exponentiations and up to 2m + 2 multiplications. In contrast to our previous
protocols, the result of the protocol is perfectly correct.
The protocol in Figure 5 works as follows. First the parties will compute the
intersection of the Bloom ﬁlters. For this party 1 encrypts the entries BF1[i]
of its Bloom ﬁlter bitwise as g1−BF1[i] to (Ri, Si) = (gri, pkri · g1−BF1[i]) for
random ri. Among these m pairs, party 2 picks those for which its Bloom ﬁlter
value BF2[i] is 0, and multiplies them together (component-wise). To hide the
choice of this subset, party 2 re-randomizes the result by multiplication with
(gs, pks). Note that, at this point, the obtained ciphertext (V, W) is an encryption
of g

i:BF2[i]=0(1−BF1[i]), thus counting the number of entries i for which both
ﬁlters are 0. Hence, if party 1 decrypts and determines this sum with at most m
multiplications by comparing it to powers g0, g1, g2, . . . gm, it obtains the size of
the union of the ﬁlters by subtracting this sum from m.
Party 1
Party 2
input: Bloom ﬁlter BF1 of size m
Bloom ﬁlter BF2 of size m
pick (sk, pk) for ElGamal scheme
over group G = ⟨g⟩of prime order q > m
for i = 1 to m do:
pick ri ←Zq
set (Ri, Si) = (gri, pkri · g1−BF1[i])
pk, (Ri, Si)i=1,2,...,m
−−−−−−−−−−−−−−−−−−→
pick s ←Zq
compute V = gs · 
i:BF2[i]=0 Ri
compute W = pks · 
i:BF2[i]=0 Si
(V, W)
←−−−−−−−−−−−−−−−−−−
decrypt to Σ = W · V −sk
set σ = 0
//ﬁnd σ with Σ = gσ
while Σ ̸= 1 and σ ≤m do
set Σ ←Σ · g−1 and σ ←σ + 1
output: m −σ
//assume that party 1 sends the sum to party 2, too
Fig. 5. Two-Party Protocol based on Bloom ﬁlters and the ElGamal encryption scheme
www.ebook3000.com

Symmetric Constructions

Generalizing PMAC Under Weaker Assumptions
Nilanjan Datta1(B) and Kan Yasuda2
1 Indian Statistical Institute, Kolkata 203, B.T. Road, Kolkata 700108, India
nilanjan isi jrf@yahoo.com
2 NTT Secure Platform Laboratories, 3-9-11 Midoricho Musashino-shi,
Tokyo 180-8585, Japan
yasuda.kan@lab.ntt.co.jp
Abstract. In this paper, we study the security of PMAC-type construc-
tions generalizing the underlying primitive to keyed functions. We ﬁrst
consider the construction with two diﬀerent primitives: one for interme-
diate calls and another for ﬁnalization. While the security of original
PMAC was based on the assumption that the primitive (block ciphers)
is a pseudo-random permutation (PRP), here we show that for MAC
security of the construction, we just need MAC security of the internal
primitives and privacy-preserving MAC (PP-MAC) security for the ﬁnal-
ization primitive. As PP-MAC is strictly weaker than a pseudo-random
function (PRF), this shows that PRF assumption on underlying prim-
itives is not a necessary condition to achieve MAC security of PMAC
type constructions. In the context, we also show that for PRF security
of the construction, we only need the ﬁnalization primitive to be PRF
secure. The requirement on the internal primitive reduces from PRF to
just a secure MAC. Moreover, we show that for MAC security of the con-
struction, PRF security of underlying primitive is not essential. We claim
that, if we restrict to use only one primitive (as two keys are required, if
two diﬀerent primitives are used) then for MAC security, the primitive
only needs to be PP-MAC secure. This essentially makes the construction
single key PP-MAC domain extender, having the parallelizability advan-
tage over iCBC-MAC. We also show that, if we want the construction to
be PRF secure, then we need the underlying primitive to be PRF secure.
This can be thought as an alternative proof of the original PMAC, not
restricted to block-ciphers only but takes care any keyed functions.
Keywords: MAC · PMAC · Privacy preserving · Regular · Finalization
1
Introduction
Message Authenticated Codes. A message authentication code (MAC) is a
symmetric-key algorithm that ensures the integrity of a message. A popular way
of constructing a MAC scheme is to build it from a symmetric-key primitive,
Nilanjan Datta—The work of the paper was performed during the ﬁrst author’s
internship at NTT.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 433–450, 2015.
DOI: 10.1007/978-3-319-19962-7 25
www.ebook3000.com

434
N. Datta and K. Yasuda
such as a block cipher or a compression function. These “small” primitives take
only ﬁxed-length inputs, while a MAC scheme should be able to process variable-
length messages. A straightforward approach to this problem is to iterate primi-
tives in a certain orderly manner. For example, the NIST-standardized CMAC [8]
iterates a block cipher in CBC mode, and the widely-deployed HMAC [2] iterates
a compression function in the style of Merkle-Damg˚ard construction.
PMAC. In this paper we focus on a construction called PMAC, which was
developed by Black and Rogaway in 2002 [6]. PMAC improves upon the
XOR MAC [1], which was parallelizable but not deterministic. We consider the
eﬃciency of PMAC particularly advantageous. Indeed, PMAC iterates a block
cipher in a fully parallelizable way, unlike CMAC or HMAC, both of which
are structurally serial. Moreover, PMAC is rate-1, requiring just 1 block-cipher
invocation per message block.
PMAC Variants and Security Proofs. PMAC is provided with proofs of
security. In the original paper of PMAC [6] Black and Rogaway showed that
PMAC is a variable-input-length pseudo-random function (PRF), and hence
MAC-secure, assuming the underlying block cipher to be a pseudo-random per-
mutation (PRP).
Subsequently, Rogaway introduced a new version of PMAC [11], where the
mask update function, which had originally used Gray code, was replaced with
“doubling” over a ﬁnite ﬁeld. This new version of PMAC made it clear that the
construction could be viewed as being based on a tweakable block cipher, and
the security proof could be recast in the framework of a tweakable PRP. For
this framework, it is crucial that the underlying block cipher EK be a PRP. In
particular, the proofs are based on the fact that the secret mask L = EK(0) is
indistinguishable from a random value.
In addition, Sarkar presented a variant called iPMAC [12]. The iPMAC con-
struction improves upon PMAC in the way of generating and updating secret
masks. The security proof of iPMAC is also based on the assumption that the
underlying primitive is a PRP/PRF.
Motivation Behind the Work. To summarize, we see that existing proofs
of PMAC heavily rely on the PRP assumption about the block cipher and as a
result prove that PMAC is not only MAC-secure but a PRF. However, we note
that the notion of PRF is strictly stronger than a secure MAC. In fact, there
are plenty of existing constructions [4,9,14] whose MAC security can be proven
based on weaker-than-PRF assumptions about the underlying primitives. So let
us pose the following basic question:
Q. Is the PRP/PRF assumption about the underlying primitive
essential for the MAC security of PMAC-type constructions?

Generalizing PMAC Under Weaker Assumptions
435
Table 1. Summary of our results
PMAC - Type
Assumption on Primitive
Achieved
(Internal)
(External)
Two Key
MAC
PRF
PRF
′′
MAC
PP-MAC
PP-MAC
One Key
PRF
PRF
′′
PP-MAC
PP-MAC
This is our main motivation. In this paper we make attempts to identify the
essential requirements on the underlying primitives in PMAC-type construc-
tions. Our answer to the above question is negative. We obtain fairly subtle but
signiﬁcant results; we succeed in weakening the PRP/PRF assumption, but we
do so only when slightly modifying the original PMAC construction.
Observations on Primitive Requirements. Before we state our results, let
us explain why we considered that the answer to the above question was possibly
negative. Our speculation was based on the following two observations:
• Finalization Speciﬁcity. We note a substantial diﬀerence between the security
requirement on the internal primitive used for intermediate calls and that
on the external primitive used for ﬁnalization. For example, the composition
G ◦F is a PRF if G is a PRF and F a computationally almost universal
function. Then the internal F can be constructed via universal hash func-
tions or via diﬀerentially uniform functions. The former can be realized by,
for example, multiplications over a ﬁnite ﬁeld [13] and the latter by, for
example, 4-round AES [10]. On the other hand, the external G needs to be
a full-ﬂedged primitive, such as the full, 10-round AES.
• Block-Cipher Speciﬁcity. A block cipher is a rather “disproportionate” prim-
itive for constructing MACs. A block cipher is a keyed permutation, but
generally its inverse does not get invoked for message authentication. Being
a permutation often hinders our understanding of the exact requirements
on the primitive; the fact that for a construction to be MAC secure, the
block cipher needs to be a PRP does not automatically imply that a keyed
function used instead must also be a PRF.
1.1
Our Contributions
Table 1 summarizes our results. We prove security of four constructions. The
details are as follows:
1. Two-Key Generalized PMAC version. We generalize PMAC version by sepa-
rating the intermediate calls from the ﬁnalization call. We do this by using
two diﬀerent keyed functions (compressed or ), each having an independent
key.
www.ebook3000.com

436
N. Datta and K. Yasuda
(a) In this setting we ﬁrst show that, to achieve MAC security of the con-
struction, PRF security of underlying primitives are not necessary. We
show that, if the underlying external primitive is a privacy preserving
MAC (PP-MAC), which is strictly weaker than PRF and the internal
primitive is just MAC secure, then the construction is PP-MAC secure.
(b) Then we show that, in order to achieve PRF security of the construction,
we need PRF security of the external primitive and MAC security of the
internal primitives. As the block-cipher is one particular keyed function,
the result shows that even for the original PMAC construction, we need
the PRF security for the last block-cipher only. Just MAC-security of
the internal block-ciphers is good enough to produce the PRF security
of construction.
2. One-Key Generalized PMAC Version. Now, we consider the PMAC versions
where only one key is being used meaning that we use only a single keyed
function that acts both as internal as well as external primitive. For this
scenario, we obtain the following results:
(a) We show that, if the underlying function is PP-MAC secure, then the
construction is also a PP-MAC. Imporatance of this result is that, we can
view this construction as the best known single-key domain extension of
PP-MAC that has the following advantages over the construction iCBC-
MAC [14]: (i) Unlike iCBC-MAC which is inherently sequential, this
construction has the advantage of being fully parallelizable and (ii) One
can use non-compressing functions as the underlying keyed function.
(b) Now, we show that if the underlying function is a PRF secure then the
construction is PRF secure. This can be viewed as an alternative proof
of the original PMAC which is not just restricted to block-ciphers, but
also for generalized keyed functions.
Note that, for regular functions like block-cipher, the notion PP-MAC and PRF
are equivalent. So, if we use block-cipher as underlying function, then for two
key version, we need the ﬁnalize block-cipher to be PRF secure and for one key
version, we need the underlying block-cipher to be PRF secure, even for the
MAC security.
Practical Signiﬁcance of Our Results. Using the result, potentially we
might be able to construct a faster-than-PMAC mode of operation using a full
round AES as external primitive and a reduced round AES as internal primitive
assuming that round-shaved AES still is MAC-secure. To realize the construction
by using a keyed function, one can use compression function of SHA-1 or SHA-2,
making it keyed via IV. We note that the SHA instruction set will become soon
available on Intel x86 platforms.

Generalizing PMAC Under Weaker Assumptions
437
2
Preliminaries
2.1
Security Deﬁnitions
In this section we provide the deﬁnitions of cAU, MAC, PP-MAC and PRF secu-
rity notions. Here we assume A to be a probabilistic adversary with it’s random
coin rA.
cAU (computationally Almost Universal). A keyed function FK is sayed to have
computationally almost universal if no adversary can ﬁnd two messages (M, M ′)
for which FK(M) = FK(M ′) holds. The adversary doesn’t have any oracle access
of the function FK. For formally, we deﬁne the cAU advantage of an adversary
A against the scheme FK as:
AdvcAU
F
(A)
Δ= PrrA,K[(M, M ′) ←A,
FK(M) = FK(M ′),
M ̸= M ′].
(1)
The keyed function FK is called (t, ϵ)-cAU if for all collision adversaries A with
complexity at most t has at most ϵ cAU-advantage.
MAC (Message Authentication Code). Message Authentication Code (MAC) is
used to ensure the “integrity” of the message by sending a tag T = FK(M) along
with the message M. The pair (M, T) is called a valid pair. The receiver veriﬁes
whether the obtained pair is valid or not. As far as security is concerned, a MAC
needs to ensure that even if an adversary A possess some tagged messages (may
be of adversary’s own choice), it must not be able produce a valid tag corre-
sponding to a new message, called fresh valid pair. More formally, we deﬁne the
MAC advantage of a forgery adversary A against the scheme F as follows.
AdvMAC
F
(A)
Δ= PrrA,K[(M, T) ←AFK, (M, T) is a fresh valid pair].
(2)
The algorithm F is called (t, q, ϵ)-mac if for any forgery adversary A making at
most q queries with (time) complexity at most t has mac-advantage at most ϵ.
PP-MAC (Privacy-Preserving MAC). The notion of PP-MAC [4] is a combi-
nation of unforgeability and left or right indistinguishability. We already have
the notion of MAC. Now we deﬁne the notion of privacy preservation. Let
GK : X →Y be a function family. The left oracle picks a key K ←K at
the beginning of each experiment and replies y = GK(x) upon query (x, x′),
whereas the right oracle replies GK(x′) upon query (x, x′). The advantage of an
adversary A to distinguish the left oracle to the right is given by,
AdvPP
G (A)
Δ= PrrA,K[AGK(Left) = 1] −PrrA,K[AGK(Right) = 1].
(3)
Note that here we consider that the queries made by the adversary A are legit-
imate: (xi = xj) ⇔(x′
i = x′
j). This means that the values x1, x2, . . . are all
distinct, and so are x′
1, x′
2, . . . , except when A repeats its queries.
www.ebook3000.com

438
N. Datta and K. Yasuda
PRF (Pseudo Random Function). The notion of PRF [7] is used for indistin-
guishability of a keyed function from a random function chosen at random. Let
GK be the keyed function. We deﬁne the distinguishing advantage of A distin-
guishing GK from a function $ chosen uniformly at random, as:
AdvPRF
G
(A)
Δ= PrrA,K[AGK = 1] −PrrA,$[A$ = 1].
(4)
We deﬁne the maximum prf-advantage Advprf
G (q, σ, t) = maxA Advprf
G (A) where
the maximum most q with the total number of blocks at most σ.
2.2
Known Implications Among PRF, PP-MAC, MAC and cAU
In this subsection, we brieﬂy discuss the known implications among the above
mentioned security deﬁnitions.
Relation between PP and MAC
(I) PP ⇏MAC: A constant function GK = 0 is PP-secure but not MAC.
(II) MAC ⇏PP: Let GK is secure MAC. Now the function G′
K(x)
=
GK(x)||lsb(x) is also a secure MAC but it’s not PP.
Relation between PRF and PPMAC
(I) PRF ⇒PP-MAC: One can easily show that any (t, q, ϵ)-PRF G is (t′, q −
1, ϵ −
1
2n )-MAC [5] and any (t, q, ϵ)-PRF G is (t, q, ϵ
2)-PP [4] for some t′ ≈t.
(II) PP-MAC ⇏PRF: Consider the construction G′
K(M) = GK(M)||0. It is
easy to check that G′
K is a PP-MAC as GK is PP-MAC but it is clearly not
PRF as the last bit of G′
k is always 0.
(III) Regular + PP ⇒PRF: This can be shown from the following two known
results:
(a) PP ⇒ROR: In [3], Bellare et al showed that PP and ROR are identical
notions.
(b) Regular + ROR ⇒PRF: Let GK : D →R be a regular function. This
implies that if we choose r randomly from D and r′ randomly from R; then
GK(r) and r′ are indistinguishable. Now by ROR property, we know that for any
M ∈D, GK(M) and GK(r) are indistinguishable. So these two imply GK(M)
and r′ are indistinguishable - implying the PRF security of GK.
Relation between MAC and cAU
MAC ⇒cAU: It is easy to see that any (t, 1, ϵ)-MAC G is (t, ϵ)-cAU as whenever
an adversary against cAU ﬁnds a collision (M1, M2), the MAC adversary can
query for M1 to get a response T and forge for (M2, T).

Generalizing PMAC Under Weaker Assumptions
439
cAU ⇏MAC: It is easy to see that, the identity function FK(x) = x is cAU
as no collision occurs but not MAC as the forger can easily forge even without
making any queries.
Composition Results
(I) If g is a PP-MAC and H is a cAU then the composition g ◦H is a PP-MAC.
(II) If g is a PRF and H is a cAU then their composition g ◦H is a secure PRF.
Both of these composition results were given by Bellare in [4].
3
PMAC Based Generalized Constructions
Here we consider the generalized PMAC construction. It uses two primitives:
internal primitive F : K × {0, 1}m →{0, 1}n and external primitive G : K ×
{0, 1}m →{0, 1}n. For a message M, the tag T is generated as follows:
GK
M[l]
pad
Σ
δ
Σ∗
T
FK
M[2]
M[1]
M[l −1]
L
2L
2l−2L
Y [1]
Y [2]
Y [l −1]
X[1]
X[l −1]
X[2]
FK
FK
1m−n
Fig. 1. Pictorial representation of the generalized PMAC
K, K′
←$ {0, 1}K
Σ∗←HK,K′(M)
T ←GK′(Σ∗)
The description of HK,K′ function on input M is given by the following equa-
tions:
L ←GK′(0)||0m−n
X[i] ←M[i] ⊕2i−1.L
for i = 1 to (l −1)
Y [i] ←FK(X[i])
for i = 1 to (l −1)
Σ ←((Y [1] ⊕Y [2] ⊕· · · ⊕Y [l −1])||1m−n) ⊕pad(M[l])
δ ←

3.2l−2.L
if |M[l]| = m
5.2l−2.L
else
Σ∗←Σ ⊕δ
www.ebook3000.com

440
N. Datta and K. Yasuda
We will consider the following two versions of PMAC type constructions which
uses the above structure:
• PMACTK[K, K′] (PMAC Two-key version). Here we consider two diﬀerent
primitives: internal keyed function FK and the external keyed function GK′
where K and K′ are two independent keys chosen uniformly at random from
the key space.
• PMACOK[K] (PMAC One-key version). Here we consider only one under-
lying keyed function FK, which acts as both the internal and the external
primitive. Again K has to be chosen uniformly at random from the key
space.
4
Security of PMACTK and PMACOK
In this section, we show the security of Generalized PMAC two key and one key
version (PMACTK and PMACOK respectively) under diﬀerent assumptions on
the internal and external primitive. In fact we show the following:
• If F is MAC-secure and G is PP-MAC secure then PMACTK is PP-MAC
secure.
• If F is MAC-secure and G is PRF secure then PMACTK is PRF secure.
• If F is PP-MAC secure then PMACOK is PP-MAC secure.
• If F is PRF secure then PMACOK is PRF secure.
More formally, the security of PMACTK and PMACOK are given by the following
4 theorems:
Theorem 1. Any (t, q) oracle adversary, having an aggregate length of σ blocks,
can break PP-MAC security of PMACTK with only negligible probability:
AdvMAC
PMACTK[K,K′](t, q) ≤AdvMAC
G
(t, q) + AdvPP
G (t, q) + ϵ1 + ϵ′
1
AdvPP
PMACTK[K,K′](t, q) ≤AdvPP
G (t, q) + AdvMAC
G
(t, q) + ϵ1 + ϵ′
1
where ϵ1
=
q
2

.l.AdvMAC
F
(t + O(l),
2l −3) + AdvMAC
G
(t, 0) and ϵ′
1
=
σ−q
2

.AdvMAC
G
(t, 0) + q.AdvMAC
F
(t + O(l), l −2).
Theorem 2. Any (t, q) oracle adversary, having an aggregate length of σ blocks,
to distinguish PMACTK from a random function has negligible prf advantage:
AdvPRF
PMACTK[K,K′](t, q) ≤AdvPRF
G
(t + O(σ), σ) + ϵ2 + ϵ′
2
where ϵ2 =
q
2

.l.AdvMAC
F
(t+O(l), 2l−3)+ 1
2n and ϵ′
2 = (
σ−q
2 )
2n
+q.AdvMAC
F
(t+
O(l), l −2).
Theorem 3. Any (t, q) oracle adversary, having an aggregate length of σ blocks,
can break PP-MAC security of PMACOK with only negligible probability:
AdvMAC
PMACOK[K](t, q) ≤AdvMAC
F
(t + O(σ), σ + l) + AdvPP
F (t + O(σ), σ)
+2(σ + σ2).AdvMAC
F
(t + O(l), 2l)
AdvPP
PMACOK[K](t, q) ≤3.AdvPP
F (t + O(σ), 2.σ) + 4(σ + σ2).AdvMAC
F
(t + O(l), 2l)

Generalizing PMAC Under Weaker Assumptions
441
Theorem 4. Any (t, q) oracle adversary, having an aggregate length of σ blocks,
to distinguish PMACOK from a random function has negligible prf advantage:
AdvPRF
PMACOK[K](t, q) ≤AdvPRF
F
(t + O(σ), σ) + 2(σ+σ2)
2n
Note that, by (t, q) oracle adversary we mean an adversary that can make
at most q many queries to the oracle and has time complexity at most t and l
denotes the maximum block length of an adversarial query.
High-level proof idea of these theorems:
• The main idea is that, we can show the function H(·) is computationally
Almost Universal (cAU) function i.e. there will be no collision in the value
Σ∗for any 2 of the q messages. Infact, we will show that, if there is a col-
lision in Σ∗for any two distinct messages, then using that information an
adversary can break the MAC or PRF security of the underlying primitives,
with very high probability, which violates our assumptions.
• Now, using the fact that the composition of a PP-MAC with a cAU is indeed
a PP-MAC [4]; we prove theorem 1. For theorem 2, we use the fact that the
composition of cAU with a PRF is indeed a PRF [4]. Theorem 3 and 4 are
basically careful extensions of Theorem 1 and 2 which incorporating only
one-key using a technique similar to the one, used in the proof of iCBC-
MAC [14].
4.1
Security of Generalized PMAC (Two Key) Version
Consider a (t, q)-adversary which runs in O(t) time and can make at most q
distinct queries say M1, . . . , Mq. Let li := |Mi| denote the length of message
Mi in blocks where a block consists of n bits. By Mi[j], we denotes the jth
block of message Mi. We similarly deﬁne Xi[j], Yi[j], Σi. By our assumption
σ = q
i=1 li. We denote E as the complement of the event E and E1..j as the
event ∧j
i=1Ei. We call two message Mj[1..lj] and Mk[1..lk] to be identical, if
one of them has full ﬁnal block and the other has an incomplete ﬁnal block and
lj = lk, ∀i < lj, Mj[i] = Mk[i], pad(Mj[lj]) = pad(Mk[lj]). Now we deﬁne the
following events:
COLLj: It is event that there is a collision for the jth message with one of it’s
previous message. More formally, we can write it as the event {Σ∗
j
= Σ∗
i , for
some i < j}.
BADj: It is the event that a non-trivial collision occurs in the inputs of the
internal primitive or the external primitive while processing the jth message. For
the two key versions, it means a non-trivial collision in some X variables (internal
primitive F) or a non-trivial collision in Σ and 0 in the external primitive G.
Now we state and prove a very important lemma on how to bound the collision
probability for generalized PMAC based constructions:
www.ebook3000.com

442
N. Datta and K. Yasuda
Lemma 1. If ∀j ≤q, (i) Pr[COLLj | COLL1..(j−1) ∧BADj] ≤ϵj1 and
(ii) Pr[BADj | COLL1..(j−1)] ≤ϵj2, then Pr[COLL] ≤q
j=1(ϵj1 + ϵj2).
Proof. The proof of lemma is provided through the following set of equalities:
Pr[COLL] ≤Pr[∨q
j=1(COLLj ∧COLL1..(j−1))]
≤
q

j=1
Pr[(COLLj ∧COLL1..(j−1))]
≤
q

j=1
Pr[COLLj ∧COLL1..(j−1) ∧BADj] +
q

j=1
Pr[COLLj ∧COLL1..(j−1) ∧BADj]
≤
q

j=1
Pr[COLLj | COLL1..(j−1) ∧BADj] +
q

j=1
Pr[BADj | COLL1..(j−1)]
≤
q

j=1
ϵj1 + ϵj2
(I) If F is MAC-secure and G is PP-MAC secure then the generalized
PMAC is PP-MAC secure.
In this subsection, we prove that MAC security of F and PP-MAC security
of G is good enough to make the construction PP-MAC security of G-PMAC.
More formally, we will prove theorem 1. For that, we ﬁrst bound ϵj1 and ϵj2 for
MAC secure F and PP-MAC secure G and then apply those results in lemma 1
to obtain our result. First we state and prove the two lemmas:
Lemma 2. If F is a MAC and G is a PP-MAC, then for PMACTK,
ϵj1 ≤(j −1).(l −1).AdvMAC
F
(t + O(l), 2l −3) + AdvMAC
G
(t, 0).
Proof. Suppose the event COLLj occurs. Then one of the following two cases
occur:
• Case 1. Collision occur in Mj with a message which are not identical: This
case yields a non-trivial equation of Y := FK(X) variables, which can be
used by adversary A1 (runs in time t + O(l)) which uses the collision of two
non-identical messages to break the MAC security of FK with probability
1
(l−1).(j−1), making at most (2l −3)-many queries.
This ensures that the
probability of occuring this case can be bounded by (l−1).(j−1).AdvMAC
F
(t+
O(l), 2l −3)).
• Case 2. Collision occurs in Mj with an identical message. In this case, we
obtain the non-trivial equation L := GK′(0) = 0, which can be used by an
adversary to forge with (0, 0) against the external primitive GK′. So, the
probability of occuring this case can be bounded by AdvMAC
G
(t, 0).
The lemma follows from the two cases.
Lemma 3. If F is a MAC and G is a PP-MAC, then for PMACTK,

Generalizing PMAC Under Weaker Assumptions
443
Adversary A1
1 K′ ←$ {0, 1}n; L ←GK′(0)||0m−n; choose k ←$ [1..(j −1)]
2 For i = 1..(lj −1) and i′ = 1..(lk −1)
3
Xj[i] ←Mj[i] ⊕2i−1L; Xk[i′] ←Mk[i′] ⊕2i′−1L
4 Choose c ←$ [1..(lj −1)]
5 For i = 1..(lj −1) except i = c,
6
Yj[i] = FK(Xj[i])
7 For i = 1..(lk −1)
8
Yk[i] = FK(Xk[i])
9 Yj[c] ←((
i̸=c Yj[i]+
i Yj[i])||1m−n)+δMj +δMk+pad(Mk[lk])+pad(Mj[lj])
10 Forge FK with (Xj[c], Yj[c])
Algorithm 1: From COLL to Forge.
ϵj2 ≤[
lj−1
2

+(lj −1).(j−1
i=1 (li −1))].AdvMAC
G
(t, 0) + AdvMAC
F
(t+O(l), l−2)
Proof. Here we show, how to bound the probabilities of the BAD events i.e
non-trivial collisions in the internal primitive FK or the external primitive GK′.
Note that, the event BADj (BAD event while processing jth message) occurs, if
one of these three events occurs:
• Event E1 (∃k ̸= k′, Xj[k] = Xj[k′]): This is a collision in internal primitive
FK occurs in two diﬀerent X blocks of jth Message. Now, one can claim
that, Pr[E1|COLL1..(j−1)] ≤
lj−1
2

.AdvMAC
G
(t, 0). Note that, for any pair
(k, k′), Xj[k] = Xj[k′] gives rise to the non-trivial equation L := GK′(0) =
( Mj[k]+Mj[k′]
2k−1+2k′−1 )n, which can be used to forge against G with (0, L). The result
follows as there can be atmost
lj−1
2

many (k, k′) pairs.
• Event E2 (∃j′ < j, k ̸= k′, Xj[k] = Xj′[k′]): This is a collision in internal
primitive FK occurs in a X block of jth Message with another X block in
j′th Message. Using the similar idea as used for event E1, one can easily show
that, Pr[E2|COLL1..(j−1)] ≤(lj −1).(j−1
i=1(li −1)).AdvMAC
G
(t, 0).
• Event E3 (Σ∗
j = 0): If Σ∗
j = 0, then we have a non-trivial equation of FK
of X variables: lj−1
i=1 FK(Xj[i]) = Mj[lj] + δMj, which can be used by an
adversary (making at most l −2 many queries) to forge the MAC security of
F. More formally, one can show that, Pr[E3|COLL1..(j−1)] ≤AdvMAC
F
(t +
O(l), l −2).
Adding the probability of all these above mentioned Bad events, we obtain lemma
3.
⊓⊔
www.ebook3000.com

444
N. Datta and K. Yasuda
Proof of Theorem 1. To prove theorem 1, we apply lemma 2 and lemma 3 in
lemma 1 and obtain the following relation:
Pr[COLL] ≤
q

j=1
(ϵj1 + ϵj2)
≤
q
2

l.AdvMAC
F
(t + O(l), 2l −3) + AdvMAC
G
(t, 0)
+ [
σ −q
2

.AdvMAC
G
(t, 0) + q.AdvMAC
F
(t + O(l), l −2) ]
The theorem follows as we put the value of Pr[COLL] in the following equations:
AdvMAC
PMACTK[K,K](t, q) ≤AdvMAC
G
(t, q) + AdvPP
G (t, q) + Pr[COLL]
AdvPP
PMACTK[K,K′](t, q) ≤AdvPP
G (t, q) + AdvMAC
G
(t, q) + Pr[COLL]
⊓⊔
Remark 1. This shows that, if we can use diﬀerent internal and external prim-
itives (which requires two diﬀerent keys chosen uniformly at random), then to
obtain MAC security, we only need PP-MAC security of the external primitive
and MAC security of the internal primitives implying PRF security of primitives
are not necessary.
(II) If F is MAC-secure and G is PRF Secure then PMACTK is PRF
Secure. Now, we look at the security of the construction when the ﬁnalizing
function GK′ is a PRF and prove the construction as PRF. The proof is identical
to the previous proof. So, instead of providing the details once again, we just
mention the places where it diﬀers.
Lemma 4. If F is a MAC and G is a PRF, then for PMACTK,
ϵj1 ≤(j −1).(l −1).AdvMAC
F
(t + O(l), 2l −3) +
1
2n .
Proof. The proof is identical to Lemma 2 except that the probability of occuring
case 2 is bounded by
1
2n as G is considered as a PRF. As the forging probability
of F is atleast
1
2n , the result follows.
⊓⊔
Lemma 5. If F is a MAC and G is a PRF, then for PMACTK,
ϵj2 ≤[
lj−1
2

+ (lj −1).(j−1
i=1(li −1))]. 1
2n + AdvMAC
F
(t + O(l), l −2)
Proof. This proof is identical to Lemma 3 except that the probability of occuring
case 1 and 2 is bounded by
1
2n as G is considered as a PRF.
⊓⊔

Generalizing PMAC Under Weaker Assumptions
445
Proof of Theorem 2. To prove theorem 2, we apply lemma 4 and lemma 5 in
lemma 1 and obtain the following relation:
Pr[COLL] ≤
q

j=1
(ϵj1 + ϵj2)
≤
q
2

.l.AdvMAC
F
(t + O(l), 2l −3) + 1
2n
+ [
σ −q
2

. 1
2n + q.AdvMAC
F
(t + O(l), l −2) ]
The theorem follows as we put the value of Pr[COLL] in the following equation:
AdvPRF
PMACTK[K,K′](t, q) ≤AdvPRF
G
(t + O(σ), σ) + Pr[COLL]
⊓⊔
Remark 2. If we consider only block-ciphers (of n bits) as the primitives, then
also the above theorem holds as it is just a subcase of the General PMAC version.
This shows that for PRF security of the original PMAC, we need PRF security
only for external block-cipher and MAC security for the internal primitives.
4.2
Security of Generalized PMAC (One Key) Version
Now, we look at the security of the relaxed version of the generalized PMAC
construction when we use only one key K and the function FK is used both
internal as well as external primitive. The proof idea is similar to the proof of
iCBC-MAC, presented by Yasuda.
First we recall the deﬁnition of Higher-Order AU (hoau), introduced by
Yasuda in [14]. The notion is as follows: A hoau-adversary A, given access to its
oracle FK(·), outputs a pair of distinct messages M, M ′ ∈{0, 1}∗. A’s goal is
to come up with such a pair as HK(M) = HK(M ′), where H is deﬁned in the
deﬁnition of generalized PMAC. In order for A to succeed, the criteria is that
M and M ′ needs to be fresh, meaning that, during the computation of HK(M)
and HK(M ′), all the input values to F should be new, i.e., none of the input
values to F has been queried by A to its oracle FK(·). More formally,
Advhoau
F
(A) = Pr[M, M ′ are fresh, M ̸= M ′, HK(M) = HK(M ′)|(M, M ′) ←
AFK(·)]
Now we prove the important lemma which says that If FK is a secure MAC then
it is hoau:
Lemma 6. Advhoau
F
(t, q, l) ≤4.l2.AdvMAC
F
(t + 2l −1, q + 2l + 1)
Proof. Here we provide a brief sketch of the proof. Detailed proof can be found
in the full version. Let A be an adversary that runs in time at most t, makes q
many queries to FK oracle and outputs a pair of message (M, M ′) in order to
attack the Hoau property of F. Now consider the following cases:
www.ebook3000.com

446
N. Datta and K. Yasuda
Case 1. Internal Input Collision: In this case there exists i ̸= j such that X[i] =
X′[j] or X[i] = X[j] or X′[i] = X′[j] occurs. Let the event be denoted as InColl.
One can show that,
Pr[InColl] ≤(2l2 −l).AdvMAC
F
(t + O(1), 0)
Case 2. Internal Output Collision: In this case there exists i, j such that (i)X[i] ̸=
X′[j] but Y [i] = Y ′[j] or (ii) X[i] ̸= X[j] but Y [i] = Y [j] or (iii) Y ′[i] = Y ′[j]
occurs. Let the event be denoted as OutColl. One can show that,
Pr[OutColl] ≤(2l2 −l).AdvMAC
F
(t + O(1), 0)
Case 3. Final Output Collision: In this case no internal and external collision
occurs we have HK(M) = HK(M ′). Let the event be denoted as FinalColl. For
this case, one can show that,
Pr[FinalColl] ≤l.AdvMAC
F
(t + O(2l), 2l)
It is easy to see that whenever A succeeds, one of the following cases occur and
hence we have the following hoau advantage
Advhoau
F
≤Pr[InColl ∧OutColl ∧FinalColl]
≤Pr[InColl] + Pr[OutColl] + Pr[FinalColl]
≤4l2.AdvMAC
F
(t + O(2l), 2l)
⊓⊔
(I) If F is PP-MAC Secure then PMACOK is PP-MAC Secure. We’ll
prove it in two parts: ﬁrst we prove the MAC part i.e. if F is PP-MAC secure
then PMACOK is MAC secure and then we show the PP part i.e. if F is PP-
MAC secure then PMACOK is PP secure.
Proof of Theorem 3. Suppose A be an adversary that runs at time at most
t and makes exactly q distinct queries in order to attack the MAC security of
the construction PMACOK. At the end A outputs (M ′, T ′) as the forgery. Now
consider the two games G1 and G2:
Now observe that, if adversary A succeeds in forgery, then at least one of the
events Forge, Zero or Coll occurs in game G1. Note that, according to the game
deﬁnition, these three events are disjoint. Hence we obtain,
AdvMAC
F
(A) ≤Pr[G1(A) sets Forge, Zero or Coll]
= Pr[G1(A) sets Forge] + Pr[G1(A) sets Zero or Coll]
−Pr[G2(A) sets Zero or Coll] + Pr[G2(A) sets Zero or Coll]
= Pr[Forge] + (Pr[G1(A) = 1] −Pr[G2(A) = 1])
+Pr[G2(A) sets Zero] + Pr[G2(A) sets Coll]
(5)
Now consider the following cases:
Case 1. One can construct a forger F, which makes at most σ + l queries and

Generalizing PMAC Under Weaker Assumptions
447
Game G1(A)
Game G2(A)
1 K ←$ {0, 1}n; L ←FK(0)||0; Y ←φ
2 (M ′, T ′) ←A(·) where upon A’s i-th query M do
3
For j = 1, . . . , (l −1)
4
X[j] = M[j] + 2j−1.L; If X[j] = 0 set Zero1 ←1 Return 1
5
Y [j] = FK(X[j])
6
Σ∗= (Y [1] + · · · + Y [l −1]||1) + pad(M[l]) + δM
7
If Σ ∈Y then Coll ←1; Return 1; If Σ = 0 then Zero2 ←1; Return 1
8
Y ←Y ∪Σi; Σi ←< i >m
9
T ←FK(Σi); Return T to A
10 For j = 1, . . . , (l′ −1)
11
X′[j] = M ′[j] + 2j−1.L
12
If X′[j] = 0 set Zero1 ←1 Return 1
13
Y ′[j] = FK(X′[j])
14 (Σ′)∗= (Y ′[1] + · · · + Y ′[l −1]||1) + M ′[l′] + δM′
15 If (Σ′)∗∈Y then Coll ←1; Return 1; If (Σ′)∗= 0 then Zero2 ←1; Return
1
16
If FK((Σ′)∗) = T ′ then Forge ←1
Return 0.
Algorithm 2: Game G1(A) and G2(A): Boxed statements are only for
Game G1(A)
succeeds in producing a forgery whenever the Forge event occurs. Hence, we
obtain
Pr[ Forge] ≤AdvMAC
F
(F)
≤AdvMAC
F
(t + O(σ), σ + l)
(6)
Details of this forger can be found in the full version.
Case 2 . One can construct a PP-adversary D, which behaves as follows: if the
oracle O with which D interacts is the Left FK oracle, then running DO coincides
with G1(A) and if oracle O is the Right FK oracle, then DO coincides with G2(A).
Details of D can be found in the full version. Using that distinguisher D, one
can show that,
Pr[G1(A) = 1] −Pr[G2(A) = 1] = Pr[DLeft = 1] −Pr[DRight = 1]
= AdvPP
F (D) ≤AdvPP
F (t + O(σ), σ + l)(7)
Case 3. One can construct two adversaries Z1 and Z2 which makes at most
l-many queries such that, whenever Zero1 occurs in G2(A) then adversary Z1
breaks mac security of F with probability
1
(q+1).(l−1) and whenever Zero2 occurs
adversary Z2 breaks mac security of F with probability
1
q+1. So, we have,
Pr[G2(A) sets Zero] = Pr[G2(A) sets Zero1] + Pr[G2(A) sets Zero2]
≤(σ + l).AdvMAC
F
(t + O(l), l)
(8)
www.ebook3000.com

448
N. Datta and K. Yasuda
Case 4. Consider the adversary C which chooses α, β uniformly from [1, q + 1]
and return (M = Mα, M ′ = Mβ).
Given two integers i, j : 1 ≤i < j ≤(q + 1), let Colli,j denotes the event
that the ﬂag Coll in game G2 gets set at A’s j-th query in such a way as
Σ∗
i = Σ∗
j . Note that the events Colli,j are disjoint. Now observe that adver-
sary C wins in the hoau sense if the guessed values α, β coincide with i, j,
because the message pair (M, M ′) is guaranteed to be fresh owing to the fact
that Coll and Zero are disjoint in game G2 by deﬁnition. Therefore, we have,
Advhoau
F
(C) ≥Pr[∨i,j(Colli,j∧?(i, j) = (α, β))] = 
i,j Pr[Colli,j].Pr[(i, j) =
(α, β)] =
1
(
q+1
2 )Pr[G2(A) sets Coll] which imply,
Pr[G2(A) sets Coll] ≤
q + 1
2

.Advhoau
F
(t, q)
≤4.σ2
2 .AdvMAC
F
(t + O(l), 2l)
(9)
The ﬁrst part of theorem 3, is obtained from the equation (5) to (9). Using
similar idea, one can proof the PP part also. We skip the proof due to page
limitation and can be found in the full version.
⊓⊔
Remark 3. This shows that, for single key generalized PMAC version, to obtain
MAC security, we need only PP-MAC security of the underlying primitive,
which is strictly weaker than PRF assumption. This beats the existing PP-
MAC domain extender iCBC-MAC as this construction is parallel and there is
no restriction in the domain and range size of the function.
(II) If F is PRF Secure then PMACOK is PRF Secure. Suppose A be a
prf-adversary that runs at time at most t and makes exactly q distinct queries
in order to attack PRF-security of the construction PMACOK.
Proof of Theorem 4. Let f : {0, 1}m →{0, 1}n be a function chosen uniformly
random. Consider the algorithm PMACf : {0, 1}∗→{0, 1}n which is identical
to PMACOK except that instead of FK, it uses f. Suppose $ : {0, 1}∗→{0, 1}n
is a function chosen uniformly at random. Now, it is easy to check that
AdvPRF
F
(A) = Pr[APMACOK = 1] −Pr[A$ = 1]
= Pr[APMACOK] −Pr[APMACf ] + Pr[APMACf ] −Pr[A$ = 1]
≤AdvPRF
F
(t + O(σ), σ) + Pr[APMACf ] −Pr[A$ = 1]
(10)
Now consider the game G3 deﬁned in algorithm 3.
Observe that, PMACf behaves just like a true random function unless Zero or

Generalizing PMAC Under Weaker Assumptions
449
Game G3(A)
1 K ←$ {0, 1}n; L ←FK(0)||0; Y ←φ
2 b ←A(·) where on A’s i-th query M do
3
For j = 1, . . . , (l −1)
4
X[j] = M[j] + 2j−1.L; If X[j] = 0 set Zero ←1 Return 1
5
Y [j] = f(X[j])
6
Σ∗= (Y [1] + · · · + Y [l −1]||1) + pad(M[l]) + δM
7
If Σ∗∈Y then Coll ←1; Return 1 ; Else Y ←Y ∪Σ∗
8
T ←f(Σ∗); Return T to A
9 Return b
Algorithm 3: Description of Game G3(A)
Coll occurs. Hence,
Pr[APMACf ] −Pr[A$ = 1] ≤Pr[APMACf sets Zero or Coll]
≤q.l
2n + 4l2.
q
2

. 1
2n
≤σ + 2.σ2
2n
(11)
Theorem 4 obtained from the equation (10) and (11).
⊓⊔
Remark 4. If we consider only block-ciphers (of n bits) as primitive, then this
can thought as an alternative security proof of the original PMAC.
5
Conclusions
In this paper we have shown that the underlying primitives used in PMAC-
type constructions need not necessarily be PRF(PRP) in general. Speciﬁcally,
we have proven that it suﬃces for the primitives to be PP-MAC, and under
such conditions PMAC-type constructions are ensured to be secure MACs. An
interesting case is when the primitive is a regular function, including the case
of a permutation (block cipher). In such a case the requirement of PP-MAC
becomes equivalent to that of PRF(PRP). In this paper we have also explored
the case where two diﬀerent primitives are used, one for intermediate calls and
another for ﬁnalization. In this case, while the ﬁnalizing primitive still needs to
be a PP-MAC, the internal primitive only needs to be a secure MAC. Therefore,
when applied to a PMAC based on block ciphers using two independent keys,
our result implies that it might be possible to use a faster, MAC-secure block
cipher for the intermediate calls.
www.ebook3000.com

450
N. Datta and K. Yasuda
References
1. Bellare, M., Gu´erin, R., Rogaway, P.: XOR MACs: new methods for message
authentication using ﬁnite pseudorandom functions. In: Coppersmith, D. (ed.)
CRYPTO 1995. LNCS, vol. 963, pp. 15–28. Springer, Heidelberg (1995). §1
2. Bellare, M., Canetti, R., Krawczyk, H.: Keying hash functions for message authen-
tication. In: Koblitz, N. (ed.) CRYPTO 1996. LNCS, vol. 1109, pp. 1–15. Springer,
Heidelberg (1996). §1
3. Bellare, M., Desai, A., Jokipii, E., Rogaway, P.: A concrete security treatment of
symmetric encryption. In: Proceedings of the 38th Annual Symposium on Foun-
dations of Computer science, FOCS, vol. 394 (1997). §2.2
4. Bellare, M.: New proofs for NMAC and HMAC: security without collision-
resistance. In: Dwork, C. (ed.) CRYPTO 2006. LNCS, vol. 4117, pp. 602–619.
Springer, Heidelberg (2006). §2.1, §2.2, §2.2, §4, §4
5. Bellare, M., Goldrich, O., Mityagin, A.: The power of veriﬁcation queries in mes-
sage authentication and authenticated encryption. Cryptology ePrint Archive:
Report 2004/309 (2004). §2.2
6. Black, J.A., Rogaway, P.: A block-cipher mode of operation for parallelizable
message authentication. In: Knudsen, L.R. (ed.) EUROCRYPT 2002. LNCS,
vol. 2332, pp. 384–397. Springer, Heidelberg (2002)
7. Goldreich, O., Goldwasser, S., Micali, S.: How to construct random functions. In:
JACM 1986, pp. 792–807 (1986). §2.1
8. Iwata, T., Kurosawa, K.: OMAC: one-key CBC MAC. In: Johansson, T. (ed.)
FSE 2003. LNCS, vol. 2887, pp. 129–153. Springer, Heidelberg (2003). §1
9. Maurer, U.M., Sj¨odin, J.: Single-key AIL-MACs from any FIL-MAC. In: Caires,
L., Italiano, G.F., Monteiro, L., Palamidessi, C., Yung, M. (eds.) ICALP 2005.
LNCS, vol. 3580, pp. 472–484. Springer, Heidelberg (2005)
10. Minematsu, K., Tsunoo, Y.: Provably secure MACs from diﬀerentially-uniform
permutations and AES-based implementations. In: Robshaw, M. (ed.) FSE 2006.
LNCS, vol. 4047, pp. 226–241. Springer, Heidelberg (2006). §1
11. Rogaway, P.: Eﬃcient instantiations of tweakable blockciphers and reﬁnements to
modes OCB and PMAC. In: Lee, P.J. (ed.) ASIACRYPT 2004. LNCS, vol. 3329,
pp. 16–31. Springer, Heidelberg (2004). §1
12. Sarkar, P.: Pesudo-Random functions and parallelizable modes of operations of a
block cipher. IEEE Transaction on Information Theory 56, 4025–4037 (2010). §1
13. Shoup, V.: On fast and provably secure message authentication based on universal
hashing. In: Koblitz, N. (ed.) CRYPTO 1996. LNCS, vol. 1109, pp. 313–328.
Springer, Heidelberg (1996). §1
14. Yasuda, K.: A single-key domain extender for privacy-preserving MACs and
PRFs. In: Lee, P.J., Cheon, J.H. (eds.) ICISC 2008. LNCS, vol. 5461, pp. 268–285.
Springer, Heidelberg (2009). §2a, §4, §4.2

sp-AELM: Sponge Based Authenticated
Encryption Scheme for Memory Constrained
Devices
Megha Agrawal(B), Donghoon Chang, and Somitra Sanadhya
Indraprastha Institute of Information Technology, Delhi (IIIT-D), India
{meghaa,donghoon,somitra}@iiitd.ac.in
Abstract. In authenticated encryption schemes, there are two tech-
niques for handling long ciphertexts while working within the constraints
of a low buﬀer size: Releasing unveriﬁed plaintext (RUP) or Producing
intermediate tags (PIT). In this paper, in addition to these two tech-
niques, we propose another way to handle a long ciphertext with a low
buﬀer size by storing and releasing only one (generally, or only few)
intermediate state, without releasing or storing any part of an unveri-
ﬁed plaintext and without need of generating any intermediate tag. In
this paper we explain this generalized technique using our new construc-
tion sp-AELM. sp-AELM is a sponge based authenticated encryption
scheme that provides support for limited memory devices. We also pro-
vide its security proof for privacy and authenticity in an ideal permuta-
tion model, using a code based game playing framework. Furthermore,
we also present two more variants of sp-AELM that serve the same pur-
pose and are more eﬃcient than sp-AELM.
The ongoing CAESAR competition has 9 submissions which are
based on the Sponge construction. We apply our generalized technique
of storing single intermediate state to all these submissions, to deter-
mine their suitability with a devices having limited memory. Our ﬁndings
show that only ASCON and one of the PRIMATE’s mode(namely GIB-
BON) satisify the limited memory constraint using this technique, while
the remaining 8 schemes (namely, Artemia, ICEPOLE, Ketje, Keyak,
NORX, Π-cipher, STRIBOB and two of the PRIMATEs mode: APE &
HANUMAN) are not suitable for this scenario directly.
Keywords: Authenticated encryption · CAESAR · Cryptographic
module · Remote key authenticated encryption · Decrypt-then-mask pro-
tocol · Privacy · Authenticity
1
Introduction
Authenticated encryption (AE), formalized in [4,5], is a technique that combines
encryption and authentication to provide both privacy and authenticity of the
data by means of a single construction, usually with a single key. The formal
deﬁnition of privacy and authenticity are provided in [5], where AE is introduced
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 451–468, 2015.
DOI: 10.1007/978-3-319-19962-7 26
www.ebook3000.com

452
M. Agrawal et al.
as a block cipher mode of operation with the same block cipher performing both
encryption and authentication. Informally, an AE scheme receives a message
and a secret key as inputs and generates a ciphertext and a tag during encryp-
tion process. On the receiver side, the ciphertext and tag pair is veriﬁed, and
the corresponding plaintext after decryption is returned only if the AE scheme
veriﬁes the supplied tag.
There exist a wide variety of AE modes. Some of the popular AE modes are
GCM [27], OCB [29], EAX [7], CCM [15] and CWC [23]. In these “oﬄine” AE
modes, the device needs to store the complete plaintext, in the encryption mode,
to produce the tag. Not all devices possess large memory to completely store a
message and hence the modes mentioned earlier can’t be directly used in the case
of a long message. Consequently, the concept of online authenticated encryption
was proposed in [18], in which encryption can be done on the ﬂy. If the message
(resp. ciphertext) blocks are denoted by M1, M2, . . . (resp. C1, C2, . . .), then the
requirement of online AE means that the ciphertext block Ci can be computed
without the knowledge of plaintext block Mj for any j > i. Most of the block-
cipher based authenticated encryption schemes can be used in online encryption
mode. Many authenticated encryption schemes that support online encryption
have been submitted to the currently on going CAESAR competition [1]. Some
of these are APE [3], NORX [22], AEGIS [30] etc.
However, decryption in an AE scheme can never be online due to the fact
that the ciphertext needs to be veriﬁed before producing the plaintext. If this
was not the case then an attacker could simply ask for the decryption of a
ciphertext of his choice, while associating any arbitrary tag with the ciphertext.
The requirement of verifying the tag before producing the decrypted text can be
solved in two diﬀerent ways. In one case, the system implementing the decryption
process could store the complete plaintext and produce it only if the tag veriﬁes.
In the other case, the system ﬁrst applies the tag veriﬁcation algorithm and
then produces the plaintext, block by block, only if the tag veriﬁes. It may
be possible to achieve the implementation of the ﬁrst method in a single pass
over the ciphertext, whereas the second method can’t be implemented in less
than 2 passes over the ciphertext. However, the ﬁrst method requires potentially
large memory on the device while the second method could be implemented
even on low memory devices. In fact, with the increasing usage of low cost
RFID devices, sensors and trusted platform modules (TPM), the need for an
AE scheme which can supports both the encryption and decryption functions in
an online form is increasing day by day. None of the schemes submitted in the
CAESAR competition consider this limited memory constraint explicitly.
Related Work: At FSE 1996, Blaze [10] proposed a new paradigm for secret-
key block ciphers: Remotely keyed encryption (RKE). RKE is concerned with
the problem of “high-bandwidth encryption with low bandwidth smartcards”. A
scheme to achieve the same was proposed in this work, but some limitations of the
scheme were also mentioned in the same work. Later, Lucks [24] provided the ﬁrst
formal model for RKE and chose to interpret the question as that of implementing
a remotely key pseudorandom permutation (RKPRP). The work [24] was further

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
453
improved, both in terms of formal modelling and the actual construction, by an
inﬂuential work of Blaze et al. [11]. It was observed in this later work that the
PRP’s length preserving property implies that it can not be semantically secure
when viewed as encryption function alone. Thus, in addition to the RKPRP which
was termed “length preserving RKE”, the work [11] also introduced the notion
of “length increasing RKE” which was also referred to as “remote key authenti-
cated encryption” (RKAE). While the deﬁnition given in [11] was important and
the ﬁrst step towards formalizing this new notion, it turns out to be quite non-
standard (it involves an “arbiter” who can fool any adversary). The notion of such
an arbiter looks quite artiﬁcial. Later, Dodis et al. [14] provided the formal deﬁni-
tion of a remote key authenticated encryption. The RKAE scheme solves the prob-
lem where one wishes to split the task of high bandwidth authenticated encryption
between a secure client (but limited bandwidth or computationally limited device)
and an insecure (but computationally powerful) host. Though RKAE is eﬃcient,
but the Crypto device (e.g. a card) that performs encryption and decryption doesn’t
know the actual value of plaintext and ciphertext (Refer Table 1). Rather, it trusts
the insecure host to provide these values, making it unsuitable for real world appli-
cations. Further, the security of this scheme is proved in a setting where the adver-
sary has oracle access only to the combined functionality of the host and the card.
However, the host is assumed to be insecure (subject to break-in by an adversary)
in this scheme, i.e., the adversary can have access to the internal state of an encryp-
tion algorithm executed on the host side. So, the underlying assumption of having
oracle access to combined functionality is not justiﬁed for deﬁning security of the
scheme.
Later, Fouque et al. at SAC 2003 proposed a decryption protocol named
Decrypt-Then-Mask (DTM) [18]. The main idea behind this protocol is to blind
the plaintext blocks obtained after decryption by XORing them with a pseudo-
random sequence of bits and return it to the sender. These blocks do not “look”
meaningful to the attacker until “unmasking” is applied. Once a tag gets veriﬁed
at the receiver end, the seed of the pseudorandom number generator(PRNG)
used to mask the plaintext blocks is returned to the sender. This allows the
sender to run the same PRNG and un-mask the plaintext blocks. However this
protocol has a drawback. The DTM requires two additional passes excluding no.
of passes required for underlying AE during decryption, which makes it com-
putationally expensive, specially in the case of long messages. These two extra
passes (one at the crypto module and another one at the user side) in DTM
are due to the use of PRNG, which creates extra overhead particularly in case
of long message. The scenarios mentioned above point towards the need of an
authenticated encryption scheme which remains eﬃciently implementable with
low memory crypto module even while handling long messages.
Recently, Andreeva et al. in ASIACRYPT 2014 [16] provides deﬁnitions to
formalize an AE scheme’s security against release of unveriﬁed plaintexts. Even
though these settings provide support for the devices with limited memory con-
straint but from the security point of view, it is essential to have a tag veriﬁcation
before releasing the plaintext.
www.ebook3000.com

454
M. Agrawal et al.
The issue of releasing unveriﬁed plaintext has also been discussed in on going
CAESAR competition [1]. Its feature page explicitly states: “Beware that security
questions are raised by any authenticated cipher that handles a long ciphertext in
one pass without using a large buﬀer: releasing unveriﬁed plaintext to applications
often means releasing it to attackers and also requires an analysis of how the
applications will react”. However releasing unveriﬁed plaintext is not the only
solution to handle large ciphertexts in memory constrained environment. In this
work, we present a new solution that serves the same purpose, even though, it
requires two passes, among them only one pass is eﬀective as another pass takes
place on user side and we usually assume that the user has enough memory on
their side.
Another requirement regarding intermediate tags mentioned in CAESAR [1]
feature page states: “If a long plaintext is split into separate packets, each of
which is separately authenticated (and encrypted), then a long forgery need not
be buﬀered before it is rejected. Applying this split to any MAC (or authenticated
cipher) produces a new MAC (or authenticated cipher) with diﬀerent perfor-
mance properties; perhaps the same type of fast rejection can be better achieved
in another way”. These settings still require signiﬁcant memory to store the
decrypted text and tags for every packet, which may not be available for the
devices with the limited memory constraint. However the scheme proposed in
this paper can support intermediate tag even for devices with the limited mem-
ory as we only need to store one intermediate state for all the packets and can
also support fast rejection by checking those intermediate tags. For more details
one can refer to full version of this paper [2].
Our Contribution: In this paper, we introduced a new generalized technique
for authenticated encryption which store only one intermediate state instead of
entire plaintext during tag veriﬁcation. And then this intermediate state is used
by the user on their side to decrypt ciphertext. Without releasing unveriﬁed
plaintext this technique allow us to do a tag veriﬁcation for a long message on
the devices with limited memory settings. We explained this generalized tech-
nique using our new construction sp-AELM and its variants. This new construc-
tion and its two more variants support both online encryption as well as tag
veriﬁcation in constrained memory setting for long messages, which makes it
suitable for implementation on devices that have limited memory. The Sponge
construction supports arbitrarily long input and output sizes, and hence allows
building various cryptographic primitives such as a hash function or a stream
cipher [9]. More recently, use of Sponge based hash functions as an authenticated
encryption primitive has been proposed in [8]. Keccak, the winner of the SHA-3
competition, is also built on the Sponge construction. Considering the accept-
ability and future adaptability of the Sponge construnction in Cryptographic
software/hardware, we choose the Sponge function as a basic primitive for the
construction of our authenticated encryption scheme sp-ALEM.
In sp-AELM, instead of returning all the plaintext blocks, we provide only
one internal state to the user, using which plaintext can be computed easily at
his side. Our scheme requires a total of three passes, one for encryption and

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
455
two for decryption. This compares favourably with the DTM scheme, which
requires overall more number of passes (discussed in Table 1), making our scheme
more eﬃcient. In sp-AELM, all computations are proposed to be done inside
a cryptographic module, where the actual plaintext and ciphertext values are
securely known, as opposed to the RKAE scheme [14]. More details about sp-
AELM are given in Section 4. In addition to this, we also present two more
eﬃcient variants of sp-AELM. More details about these variants are given in
Section 6.
Table 1 Description: This table shows the comparison of RKAE, DTM, the
proposed scheme sp-AELM and sp-AELM variants. Our proposed scheme and
its variants support online encryption. However, in the case of RKAE and DTM,
it depends on the underlying AE scheme that is used. All these three schemes
support low memory veriﬁcation, i.e., there is no need to store message blocks on
a cryptographic module during decryption. Next we compare these schemes on
the basis of number of passes required for encryption and decryption. For a given
message M of n blocks, we use the usual notion of a “pass” as the processing of
all n blocks of M once. The RKAE scheme requires two passes1 for encryption
during execution of Conceal algorithm (one pass for encrypting n block message
and another pass for computing the hash value on the output of the ﬁrst pass,
explained in Fig. 1(a)), while the number of passes required for DTM depends
on the underlying AE scheme. sp-AELM and its variants require only one pass
for encryption i.e. it visits the n block message exactly once. For decryption
and veriﬁcation, RKAE requires two passes1 as shown in Fig. 1(b) (one pass
for computing the hash value and another one for decryption). DTM uses two
additional passes for pseudo random number generator (one pass for masking the
n block message and another for unmasking the n blocks) apart from the number
of passes for the underlying authenticated decryption algorithm. sp-AELM and
its variants require only two passes (one at the receiver side and another one
at the sender side as shown in Fig. 4(b)) for the decryption and veriﬁcation.
We have also used communication overhead between the host and the Crypto
module as a comparison parameter in terms of number of message blocks n.
RKAE require only 2 communications(shown in Fig. 1b), DTM require 2n + 2
communications(shown in Fig. 2(b)) whereas sp-AELM and its variants require
n + 2 communications(shown in Fig. 4(b)).
In addition to this, we also applied the same technique used in sp-AELM on
all Sponge based authenticated encryption schemes submitted to the CAESAR
competition, to evaluate their suitability for supporting low memory constraint.
Currently there are nine Sponge based AE schemes in the CAESAR competition.
We addressed all these nine schemes using the same technique that we used in
sp-AELM, i.e., during veriﬁcation and decryption, storing only one intermediate
state instead of storing all decrypted text and returning this intermediate state
only when tag gets veriﬁed. Detailed analysis of the individual scheme is provided
in Section 7. Our ﬁndings are brieﬂy summarized in Table 2.
1 For RKAE encryption/decryption we neglect the computations carried out at the
Crypto module, as it is processed on a small data.
www.ebook3000.com

456
M. Agrawal et al.
Table 1. Comparison of RKAE, DTM, sp-AELM and sp-AELM variants:(a) One pass
is deﬁned as processing of n blocks of a message once.(b)The communication overhead
is given in terms of number of blocks n for a message M.
Parameters
RKAE
DTM
sp-AELM
sp-AELM
variants
[14]
[18]
[This paper]
[This paper]
Online Encryption
Depends
on
underlying AE
Depends
on
underlying AE
Yes
Yes
Support for low memory veriﬁ-
cation
Yes
Yes
Yes
Yes
No.
of
Passes
required
for
Encryption and tag generation
Two
Depends
on
underlying AE
One
One
No.
of
Passes
required
for
Decryption and Veriﬁcation
Two
2 + Depends on
underlying AE
Two
Two
Communications overhead b/w
Host and Crypto module during
veriﬁcation and decryption
2
2n + 2
n + 2
n + 2
Knowledge
of
Plaintext
and
Ciphertext to Crypto module
No
Yes
Yes
Yes
Table 2. Analysis of CAESAR schemes showing their suitability for supporting limited
memory constraint.
Sponge based AE Schemes submit-
ted in CAESAR
Support for limited memory devices
(shown in Section 7)
Artemia [21], ICEPOLE [28], Ketje [19],
Keyak
[20],
NORX
[22],
PRI-
MATEs(APE,
HANUMAN)
[17],
Π-
Cipher [13], STRIBOB [26]
No
Ascon [12], PRIMATEs(GIBBON) [17]
Yes
Roadmap : The rest of this paper is organized as follows: Section 2 gives the
brief description of Remote Key Authenticated Encryption [14] and the protocol
deﬁned in [18]. Section 3 deﬁnes some preliminaries followed by Section 4 that
deﬁnes the construction of the proposed AE scheme (sp-AELM). We provide the
security proof of the proposed scheme in Section 5. In Section 6, we present two
more eﬃcient variants of sp-AELM. Section 7 presents the brief analysis of all
Sponge base AE schemes submitted to the CAESAR competition. Finally, we
conclude this paper with Section 8.
2
Previous Work
2.1
Remotely Keyed Authenticated Encryption
In [14] Dodis et al. proposed a formalized solution to the problem of remotely
keyed authenticated encryption (RKAE). One round of the proposed scheme
consists of seven diﬀerent algorithms that run between two parties called the host
and the cryptographic module: (RKG, StartAE, CardAE, FinishAE, StartAD,
CardAD, FinishAD). In this scheme, the authors used the smart card as the
Crypto module. The host is assumed to be powerful but insecure, and the Crypto

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
457
module is assumed to have low bandwidth and limited memory but taken to
be secure. For a given authenticated encryption scheme AE, we explain the
RKAE using an example in Fig. 1. The process of encryption and decryption is
individually shown in Fig. 1(a) and Fig. 1(b) respectively.
Host H
Crypto Module CM
C h
(K)
C′ = C, h
C
b = ADK(C)
b
M or⊥= Open(h, b)
Host H
Crypto Module CM
(M)
(K)
(h, b) = Conceal(M)
b
C = AEK(b)
C
Return C′ = C, h
where h = Eτ(M),
b = τ H(h)
(a) E ncryption
(b) Decryption
Parse b = τ H(h)
M or ⊥= Dτ (h)
Fig. 1. Remote Key Authenticated Encyprion
2.2
Decrypt-Then-Mask Protocol
In [18], Fouque et al. proposed a generic construction called Decrypt-then-mask.
Their construction doesn’t aﬀect encryption, only the decryption part is modi-
ﬁed. They use a pseudorandom number generator to mask the plaintext blocks,
to eliminate the need of storing plaintext blocks. Once the tag gets veriﬁed, the
scheme returns the seed of the PRNG that has been used to mask the plain-
text blocks. We use CM to denote cryptographic module and U to represent
user of this device in further description of the scheme. For a given authenti-
cated encryption scheme AE, the encryption and decryption component work
as shown in Fig. 2.
3
Preliminaries
Deﬁnition 1 (Ideal Online Function). Let func(A, B) be deﬁned as set of
all functions from set A to set B. Now, we deﬁne ideal online function $pad as:
$pad(N, A, M, flag) →
(C, T)
if flag is 1,
C
if flag is 0,
where,
pad(X)= X∥10t where t is a non-negative integer s.t |X∥10t|= pr for p > 0
and some ﬁxed r.
N= nonce of r bit,
A= Associated data, where |A| < r and A′=pad(A),
M= input message that can be partial or complete depending on the ﬂag
value,
flag =

0 ; if user has queried partial message M ,
1 ; if user has queried complete message M .
www.ebook3000.com

458
M. Agrawal et al.
User R
Crypto Module CM
(C, T )
(K)
C = c1 c2 ... cn
s0 ←{0, 1}s
c1
p1
c2
p2
cn
pn
T
s
for i = 1, 2...., n
mi = ADK(ci)
(ri, si) ←P RNG(si−1)
pi = mi ⊕ri
if T is valid
s = s0
else
s = ⊥
if s = ⊥, C is invalid
else
s0 = s
for i = 1, 2...., n
(ri, si) ←P RNG(si−1)
mi = pi ⊕ri
$
User R
Crypto Module CM
(M)
M = m1 m2 ... mn
(C, T ) = AEK(M)
(K)
(a) E ncryption
(b) Decryption with Masking
where C = c1 c2 ... cn
(C, T )
M
(C, T )
Fig. 2.
Encryption
and
Decryption
using
Decrypt-Then-Mask
Protocol:
In
(b)decryption, to represent it diagrammatically we assume ADK(ci) returns the inter-
mediate value mi
In case flag = 0, we are assuming user has supplied incomplete message and
wlog length of supplied message (|M|) is multiple of r.
M ′ =
 m0∥. . . ∥mn−1 = M, where n = |M|/r and |mi| = r
; if ﬂag=0 ,
m0∥. . . ∥mn−1 = pad(M) s.t. |mi| = r for 0 ≤i ≤n −1 ; if ﬂag=1 .
C = c0∥c1∥. . . ∥cn−1 where cj = g(N, A′, m0∥. . . ∥mj) for j = 0, . . . , n −1,
and
g
$←−func({0, 1}r × {0, 1}r × ({0, 1}r)+, {0, 1}r),
T = g′(N, A′, M ′), where g
′
$←−func({0, 1}r × {0, 1}r × ({0, 1}r)+, {0, 1}t).
Notice that above function is online: here preﬁxes of outputs remain the same
if preﬁxes of the inputs remain constant. Furthermore, if we consider that nonce
and associated data are unique for each function invocation in the ideal online
function, then we acheive full privacy. This is because the inputs to g and g′ will
then be unique for each invocations, and since g and g′ are functions randomly
chosen from func, we get outputs that are independent and uniformly distributed.
Deﬁnition 2 (Privacy). For a given authenticated encryption scheme AE =
(K, E, D), we deﬁne privacy in terms of the ability of an adversary A to distin-
guish between the output of an encryption oracle E from the output of an ideal
online function $pad. We deﬁne
Advpriv
AE (A) = Pr[K
$←−K : AEK(.,.,.,.) ⇒1] −Pr[A$pad(.,.,.,.) ⇒1]
The oracle EK on input (N, A, M, flag), returns the C or (C, T) depending
on the ﬂag value whereas the oracle $pad on input (N, A, M, flag), works as
deﬁned in Def. 1. Here the advantage of an adversary A will be its ability to
distinguish between the ciphertext outputs from the EK and $pad .
Deﬁnition 3 (Authenticity).
Here we give a notion of authenticity of the
ciphertext tag pair of an authenticated encryption scheme. For a given authen-
ticted encryption scheme AE = (K, E, D), let A be an adversary having an

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
459
encryption oracle EK. We say that A forges if it outputs a (N, A, C, T) tuple
where DK(N, A, C, T) ̸= INV ALID and adversary A didn’t ask a query
EK(N, A, M, flag) that resulted in response (C, T).
Let ExpAuth
Π
(A) be the forging experiment for a given AE. Then the forging
experiment is deﬁned as follows:
1. Adversary A can query encryption oracle E, decryption oracle D atmost
qenc, qdec times respectively.
2. All the query responses of encryption oracle E, are stored in a set, say R.
This R set contain (N, A, C, T) tuple.
3. If adversary A is able to generate a (N, A, C, T) tuple /∈R that produces
valid message M, then he wins and output is 1 otherwise output is 0, after
trying qdec number of queries.
We say adversary wins i.e. he succeed in creating forgery if ExpAuth
AE (A) = 1.
So, the advantage of adversary in forging the scheme is deﬁned as:
AdvAuth
AE (A) = Pr[ExpAuth
AE (A) = 1]
4
Our Construction: sp-AELM
A cryptographic module should not reveal any information about the plaintext
until ciphertext-tag pair gets veriﬁed. Once the ciphertext gets veriﬁed, then
crypto device is allowed to reveal the plaintext. However, a cryptographic module
is likely to have some storage restriction. Therefore, it can not store a large
plaintext M, verify the tag and output M only when M is valid. Traditional
authenticated encryption schemes do not satisfy this usage scenario. We propose
a new sponge based authenticated encryption scheme sp-AELM that considers
this situation. sp-AELM uses a permutation as the underlying cryptographic
primitive. Section 4.1 gives detail of the proposed scheme.
4.1
Description of sp-AELM
We now describe the new authenticated encryption scheme sp-AELM that
addresses the low memory issue mentioned earlier. Schematic structure of sp-
AELM is shown in Fig. 3. Our authenticated encryption scheme takes key K,
nonce N, associated data A, plaintext M and flag as inputs and returns C or
(C, T) depending on the value of the flag, where C represents the ciphertext
and T denotes tag or message authentication code (MAC). We denote crypto-
graphic module by CM and the user of this module by U. The user U uses the
crypto module CM for encryption, decryption and veriﬁcation.
www.ebook3000.com

460
M. Agrawal et al.
π
K
N
π
π
A0
m0
π
c0
π
mn−2
mn−1
π
cn−1
cn−2
π
K
A0
π
π
N
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
π
Aj−1
⊕
0r
0c
Kr
Kc
⊕
⊕
⊕
⊕
⊕
⊕
Nr
Nc
a1
b1
an−2
bn−2
an−1
bn−1
an
bn
a0
b0
π
Aj−1
⊕
⊕
Z0
Kr
Kc
Nr
Nc
Fig. 3. sp-AELM Construction
Algorithm
1.
Encryption
EK(N, A, M, flag)
1
Initialization: IV1 = 0r, IV2 = 0c,
Kr∥Kc
$
←−{0, 1}b,
Iπ = {((IV1 ⊕K)∥IV2, Kr∥Kc)}
2
if (flag = 1) then
3
M = m0∥m1∥.....∥mn−1, Where
|mi| = r and 0 ≤i < (n −1)
4
P ad(M) =
m0∥m1∥.....∥(mn−1∥10r−(|mn−1|+1))
5
else
6
M = m0∥m1∥...∥mn−1, Where
|mi| = r
7
if |mn−1| < r then {return Invalid;}
8
P ad(A) = A0∥A1 . . . ∥Aj−1 s.t. |Ai| = r
and 0 ≤i < (j −1)
9
x = Kr ⊕N , w = Kc
10
Nr∥Nc = π(x∥w)
11
x = Nr, w = Nc ⊕w
12
for i = 0 →j −1 do
13
x′∥w′ = π(x ⊕Ai∥w)
14
w = w′ ⊕w, x = x′
15
a0 = x′, b0 = w′
16
c0 = a0 ⊕m0
17
for i = 1 →n −1 do
18
x
′
∥w
′
= π(ci−1∥bi−1)
19
bi = bi−1 ⊕w
′
20
ai = x
′
21
ci = ai ⊕mi
22
C = c0∥c1∥.....∥cn−1
23
if (flag = 0) then
24
Return C; Exit
25
an∥bn = π(cn−1∥bn−1)
26
x = an, w = bn
27
x = x ⊕K
28
K
′
r∥K
′
c = π(x∥w)
29
x = K
′
r ⊕N , w = K
′
c ⊕w
30
N
′
r∥N
′
c = π(x∥w)
31
x = N
′
r, w = N
′
c ⊕w
32
for i = 0 →j −1 do
33
x′∥w′ = π(x ⊕Ai∥w)
34
w = w′ ⊕w, x = x′
35
T = Z0 = x
36
Return (C, T )
Algorithm 2. Decryption DK
(N, A, C, T)
1 Initialization: IV1 = 0r, IV2 = 0c,
Kr∥Kc
$
←−{0, 1}b,
Iπ = {((IV1 ⊕K)∥IV2, Kr∥Kc)}
2 |P ad(A)| = r
3 x = Kr ⊕N , w = Kc
4 Nr∥Nc = π(x∥w)
5 x = Nr, w = Nc ⊕w
6 for i = 0 →j −1 do
7
x′∥w′ = π(x ⊕Ai∥w)
8
w = w′ ⊕w, x = x′
9 a0 = x, b0 = w
10 m0 = a0 ⊕c0
11 for i = 1 →n −1 do
12
x
′∥w
′ = π(ci−1∥bi−1)
13
bi = bi−1 ⊕w
′
14
ai = x
′
15
mi = ai ⊕ci
16 M = m0∥m1∥.....∥mn−1
17 x = an, w = bn
18 x = x ⊕K
19 K
′
r∥K
′
c = π(x∥w)
20 x = K
′
r ⊕N , w = K
′
c ⊕w
21 N
′
r∥N
′
c = π(x∥w)
22 x = N
′
r, w = N
′
c ⊕w
23 for i = 0 →j −1 do
24
x′∥w′ = π(x ⊕Ai∥w)
25
w = w′ ⊕w, x = x′
26 Z0 = x
27 if (Z0 == T ) then
28
Return (a0, b0)
29 else
30
Return ⊥
4.1.1
Encryption.
The algorithm for encryption, EK(., ., ., .) is explained in Algorithm 1. It takes
an input, the secret key K of r bits, nonce N of r bits and associated data A,
plaintext M and a flag value. This ﬂag value can be 0 or 1, where 0 represents
continue i.e. partial M is provided as an input and 1 represents stop i.e., M is

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
461
complete, we can do the tag computation. Associatd data A is partitioned into r
bit blocks(A0∥. . . Aj−1) and 10∗padding is used for last block if required. We use
two initialization vectors IV1 and IV2 of size r and c respectively, each of which
is initialized to zero. Further, ﬂag value is checked, if it is 1, then the message
M is padded using Pad(M) and divided into n blocks (M = m0∥m1∥. . . mn−1),
each block is of r bit (i.e. |M|/r = n). Otherwise it is just processed into r
bit blocks. Algorithm iterates a ﬁxed permutation π : A × B →A × B, where
|A| = r and |B| = c. First (IV1 ⊕K)∥IV2 is given input to π and the output
is Kr∥Kc. Then IV2 is XORed with Kc(say this value X). The next input to
π is (Kr ⊕N)∥X and the corresponding output is Nr∥Nc. Then this Nc valus
is XORed with X. Similarly associated data A is processed. After that message
block m′
is for i = 0, 2, ..(n −1) get processed. Note that encryption is online
here, we don’t need to know message blocks in advance i.e., ci can be calculated
without prior knowledge of mj for any j > i. Once all the message blocks are
processed and flag is 0, then C = c0∥c1∥....∥cn−1 is return to the user and
algorithm terminates. Otherwise K, N, A are processed again in a order followed
by tag generation. Tag T is generated from Z0 value in Fig. 3. Finally (C, T)
pair is returned to the user, where C = c0∥c1∥....∥cn−1.
4.1.2
Decryption and Veriﬁcation.
The algorithm for decryption DK(., ., ., .) is given in Algorithm 2. The decryp-
tion process is similar to encryption. All the steps are same except for XORing
with the message. The only diﬀerence is rather than XORing with mi, we XOR
with ci. Once the message block mi is evaluated we use that as input just like
encryption. Here in this decryption algorithm, we just store (a0, b0) value, all
m′
is block not get stored anywhere. Finally tag Z0 is calculated. Once the tag
becomes available , the given tag T is compared with Z0. If tag gets veriﬁed, i.e.,
Z0 = T, then algorithm returns (a0, b0) value. Once the user get this value, he
can easily recover plaintext M from C as m0= c0 ⊕a0, m1 = c1 ⊕π(c0, b0)[initial
r bit] and so on (explained in Algorithm 2). If tag doesn’t get veriﬁed, then it
returns invalid operator, i.e., plaintext cannot be calculated in this case. Fig. 4(b)
shows the decryption protocol used in this new scheme.
User U
Crypto Module CM
c1
C = c0 c1 ....... cn−1
s
m0 = a0 ⊕c0
For i = 1 to n −1,
x
w = π(ci−1 bi−1)
bi = bi−1 ⊕w
ai = x
mi = ai ⊕ci
M = m0 m1 .... mn−1
s = DK(N, A, C, T)
where s = (a0, b0)or⊥
if s = ⊥, C is invalid
else
Crypto Module CM
User U
(N, C, T)
(K)
(M)
(K)
M = m0 m1 ....... mn−1
(C, T) =
(C, T)
(a) E ncryption
(b) Decryption
EK(N, A, M)
(C, T)
where C = c0 c1 ....... cn−1
M
cn
T
Fig. 4. Encryption and Decryption protocol for sp-AELM
www.ebook3000.com

462
M. Agrawal et al.
5
Security Proof
In this section, we state theorems for the privacy and authenticity proof of sp-
AELM. For the detailed proof of these theorems, one can refer to full version [2].
We have used recently evolved game playing technique proposed by Bellare and
Rogaway in [6]. We prove security of sp-AELM in the ideal permutation model,
where the underlying permutation is assumed to behave perfectly random. We
also restrict our proof to the assumption that nonce N will always be generated
diﬀerent and randomly by the attacker. As it is not practically feasible by the
algorithm to generate it randomly and diﬀerently everytime.
5.1
Privacy
We obtain an upper bound for the advatnage of the adversary who can dis-
tinguish the output of the proposed scheme with a random oracle in the ideal
permutation model.
Theorem 1. Let Π = (K, E, D) denote the proposed Authenticated Encryption
scheme with deﬁned padding rule and an permutation π, which operates on b bits.
The adversary A has given access to π, π−1. Then the advantage of A relative
to E is given by
Advpriv
Π
(A) = Pr[K
$←−K : AEK(),π,π−1 = 1] −Pr[K
$←−K : A$pad(),π,π−1 = 1] .
Advpriv
Π
(A) ≤σ(σ −1)
2b + 1
+ σ(σ −1)
2c + 1
+ (qπ + qπ−1).qenc
2r
+ 2(qπ + qπ−1)σ
2c −σ
+ qπ
2r .
where $pad is deﬁned in Def. 1, σ is the maximum number of block calls to
π, π−1 by encryption E and decryption D algorithm . qenc, qπ and qπ−1 are the
maximum number of queries to encryption oracle Enc, π and π−1 oracle respec-
tively by adversary A. b(= r + c) is the size on which π permutation operates.
Proof. Refer to full version [2].
5.2
Authenticity
In this section, we analyze the security of authenticity of the tag produced in our
scheme. The forgery of an AE scheme is deﬁned as the ability of an adversary A to
generate a valid (N, A, C, T) tuple, without directly querying it to the encryption
oracle. The adversary is allowed to make limited number of queries to encryption,
decryption, π and π−1 oracles. For an AE scheme, we say the adversary A is
successful in forging if it outputs a (N, A, C, T) tuple where DK(N, A, C, T) ̸=
INV ALID and adversary A didn’t ask a query EK(N, A, M, flag) that resulted
in response (C, T) .
Theorem 2. Let Π
= (K, E, D) be the proposed authenticated encryption
scheme with deﬁned padding rule (pad) and ideal permutation (π) which oper-
ate on b(= r + c) bits. The adversary A is given access to Encryption oracle E,
Decryption oracle D, π and π−1 oracle. Then Π = (K, E, D) is forgeable with
the probability

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
463
Pr[ExpAuth
Π
(A) = 1]≤σ(σ −1)
2b+1
+ σ(σ −1)
2c + 1
+ qdec
2|T | + qπ
2r .
where σ is maximum number of blocks to π, π−1 by encryption oracle E, and
decryption oracle D, qdec is the number of queries to decryption oracle, qπ is the
number of queries to π oracle and |T| is the tag length.
Proof. Refer to full version [2].
6
More Variants of sp-AELM
This section presents two more variants of sp-AELM. The advantage of these vari-
ants over actual construction is that it doesn’t require feed forward operation.
Schematically construction of sp-AELM variants are shown in Fig. 5 and Fig. 6.
These variants support the low memory constraint in a same way as in sp-AELM
by storing only one intermediate state(shown using red line in Fig. 5 ) instead of
storing complete text. Security proof for these constructions are not provided here
due to space restrictions, although, it can be proved in same manner as sp-AELM.
Intuitively, we can say these are secure as releasing intermediate state will not
result for the adversary to gain any information about key. One can choose these
variants over sp-AELM, when there is very limited amount of memory, which is
not even capable of storing states required for feed-forward operation.
π
K
K
π
π
A
m0
π
c0
π
mn−2
mn−1
π
cn−1
cn−2
K
Z0
. . .
⊕
. . .
⊕
⊕
⊕
⊕
⊕
⊕
N
0c
π
Fig. 5. sp-AELM variant 1
π
K
N
π
π
A
m0
π
c0
π
mn−2
mn−1
π
cn−1
cn−2
K
Z0
. . .
⊕
. . .
⊕
⊕
⊕
⊕
⊕
⊕
0r
0c
π
K
π
⊕
Fig. 6. sp-AELM variant 2
7
Analysis of Sponge Based AE Schemes Submitted in
CAESAR
In this section, we apply our newly proposed generalized technique, which stores
only one intermediate state instead of entire plaintext during tag veriﬁcation,
www.ebook3000.com

464
M. Agrawal et al.
on various sponge based schemes submitted to the CAESAR competition to
determine their suitability for supporting devices having limited memory con-
straint. There are ten sponge based AE schemes submitted to CAESAR for the
ﬁrst round, out of which one scheme (CBEAM [25]) has been withdrawn. Cur-
rently there are nine sponge based AE schemes competing for the next round.
In the following subsections we present the brief analysis of some of the schemes
ARTEMIA, ASCON, PRIMATE and Π-cipher, after applying the same tech-
nique used in sp-AELM. Rest of the schemes(ICEPOLE [28], STRIBOB [26],
NORX [22], Ketje [19] and Keyak [20])can be analyzed in a similar way.
7.1
ARTEMIA [21]
Artemia is family of dedicated authenticated encryption scheme. It is based on
JHAE mode as shown in Fig. 7.
While analyzing this mode, we ﬁnd that it can not support low memory
device constraint. Our analysis is based on the same technique proposed in sp-
AELM i.e., storing only one intermediate state(shown using red line in Fig. 7)
instead of storing whole message during decryption. This technique can not be
applied here. As releasing this intermediate state will result in attacker to ﬁnd
the value of key. Since he already knows the value of T and can do the forward
computation using Cs
i to get the state value after last π block, XORing this
value with T will result in value of K.
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
π
π
π
π
π
π
π
IV
K
N
K
T
A1
A2
Ai−1 Ai
M1
M2
Mj−1
Mj
C1
C2
Cj
Fig. 7. JHAE Mode
⊕
⊕
⊕
⊕
⊕
⊕
⊕
⊕
pa
pa
pb
pb
pb
pb
pb
K∥N
k∥a∥b∥0∗
A1
Ai
C1
P1
Pj
Cj
0∗∥K
0∗∥1
K∥0∗
K
T
Fig. 8. ASCON
7.2
ASCON [12]
ASCON is a family of authenticated encryption designs ASCONa,b −k. The
family members are parameterized by the key length k ≤128 and internal round
numbers a and b. Each design speciﬁes an authenticated encryption algorithm
Ek,a,b and decryption algorithm Dk,a,b.
On analyzing this scheme, we ﬁnd out that it can support low memory devices
by storing only one intermediate value(shown using red line in Fig. 8) instead of
storing all decrypted blocks during decryption, without breaking the security of
construction. Further, this intermediate value can be used to decrypt the message
at user side. This is due to the use of key at the end, which also prevents attcacker
from doing forgery.

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
465
ARTEMIA [21], ICEPOLE [28], STRIBOB [26], NORX [22], Ketje [19] and
Keyak [20] are analyzed in similar way as ASCON and the results predict that
these schemes can not support the limited memory constraint using this tech-
nique. For more details refer to full version [2].
7.3
Π-Cipher [13]
Π-Cipher is parallel, incremental, nonce based, tag second-preimage resistant,
authenticated encryption cipher with associated data. Its construction is shown
in Fig. 9.
This AE scheme can not support limited memory constraint. Suppose if we
store CIS′′ and ctr + i + 2 values instead of storing all decrypted text blocks.
Now using these intermediate values and known ciphertext values attacker can
calculate the plaintext and Tag T ′′. However using this T ′′ he can not get the key
due to the unavailability of Secret message number(SMN). Though it is secure
against key recovery attack but forgery is possible here. As using T ′′, it is easy to
generate a new ciphertext C and its corresponding valid tag T using a repeated
nonce(SMN). This is due to the reason that T ′′ value will be same for a given
key K and secret message number SMN.
⊕
K∥P MN∥10∗
π
⊕
π
⊕
π
⊕
π
⊕
π
⊕
π
A1
Ai
t1
ti
T
ctr + 1
ctr + i
Common Internal
state (CIS)
Common Internal
state (CIS)
Common Internal
state (CIS)
Common Internal
state (CIS)
Common Internal
state (CIS
′)
⊕
π
⊕
π
⊕
⊕
π
π
⊕
π
π
⊕
⊕
⊕
⊕
SMN
T
t0
T
C1 M1
Mj
Cj
t1
tj
T
T
(ctr + i) + 1
(ctr + i + 1) + 1
(ctr + i + 1) + j
Common Internal
state (CIS
′)
Common Internal
state (CIS
′′)
CIS
′′
C0
Common Internal
state (CIS
′′)
Fig. 9. Π Cipher
7.4
PRIMATE [17]
The authenticated encryption family PRIMATEs is deﬁned by two parameters:
the security level s ∈{10, 15} and mode of operation scheme ∈{GIBBON,
HANUMAN, APE}. These modes are shown in Fig. 10, 11, 12. Out of these
three modes of operation of PRIMATE authenticated encryption family, only
GIBBON can support limited memory constraint by storing only one intermedi-
ate state(shown using red line in Fig. 10), without revealing key to the attacker.
Also, attacker will not be able to create forgery due to the use of key at the end.
HANUMAN and APE can be easily broken to get the key, when storing only
intermediate state. For more explaination refer full version [2].
www.ebook3000.com

466
M. Agrawal et al.
⊕
⊕
⊕
⊕
⊕
⊕
⊕
P1
P2
P1
T
0c/2∥K
K
A1
. . .
. . .
Ai
P1
C1
Pj
Cj
. . .
. . .
P2
P3
P3
P3
0c/2∥K
0r
N∥K
Fig. 10. GIBBON
⊕
⊕
⊕
⊕
⊕
P1
T
K
A1
. . .
. . .
Ai
P1
C1
Pj
Cj
. . .
. . .
P4
P1
P1
P1
0r
N∥K
Fig. 11. HANUMAN
⊕
⊕
⊕
⊕
⊕
P1
T
K
A1
. . .
. . .
Ai
P1
C1
Pj−1
Cj−1
. . .
. . .
P1
P1
P1
P1
0r
K
⊕
0b−1∥1
⊕
Cj
Pj
P1
Fig. 12. APE
8
Conclusion
In this paper, we proposed a new generalized technique for AE schmes to sup-
port devices with limited memory. This new technique has been explained in
this paper through a new sponge based AE scheme sp-AELM. sp-AELM can
be used to support cryptographic modules having limited storage capabilities.
We provided its security proof in an ideal permutation model using code based
game playing framework for both privacy and authenticity. In addition to this,
we also present two more variants of sp-AELM that serve the same purpose and
are more eﬃcient than sp-AELM. Further, we applied this newly introduced
technique to all Sponge based AE schemes submitted to the CAESAR competi-
tion for determining their suitability to support devices with memory constraint.
Our analysis shows that ASCON and one of the PRIMATEs instance namely
GIBBON, can support limited memory constraint using this technique, while
remaining schemes are not directly suitable for this scenario.
Acknowledgments. We thank our crypto group at IIIT Delhi and the ACISP 2015
PC members for their valuable comments.
References
1. CAESAR: Competition for authenticated encryption: Security, applicability, and
robustness (2014). http://competitions.cr.yp.to/caesar.html
2. Agrawal, M., Chang, D., Sanadhya, S.: A new authenticated encryption technique
for handling long ciphertexts in memory constrained devices. Cryptology ePrint
Archive, Report 2015/331 (2015). http://eprint.iacr.org/
3. Andreeva, E., Bilgin, B., Bogdanov, A., Luykx, A., Mennink, B., Mouha, N.,
Yasuda, K.: APE: Authenticated permutation-based encryption for lightweight
cryptography. IACR Cryptology ePrint Archive 2013, 791 (2013)

sp-AELM: Sponge Based AE Scheme for Memory Constrained Devices
467
4. Bellare, M., Namprempre, C.: Authenticated Encryption: Relations Among
Notions and Analysis of the Generic Composition Paradigm. J. Cryptol. 21(4),
469–491 (2008)
5. Bellare, M., Rogaway, P.: Encode-then-encipher encryption: how to exploit nonces
or redundancy in plaintexts for eﬃcient cryptography. In: Okamoto, T. (ed.) ASI-
ACRYPT 2000. LNCS, vol. 1976, pp. 317–330. Springer, Heidelberg (2000)
6. Bellare, M., Rogaway, P.: Code-Based Game-Playing Proofs and the Security of
Triple Encryption. IACR Cryptology ePrint Archive 2004, 331 (2004)
7. Bellare, M., Rogaway, P., Wagner, D.: EAX: A Conventional Authenticated-
Encryption Mode. IACR Cryptology ePrint Archive 2003, 69 (2003)
8. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: Duplexing the sponge: single-
pass authenticated encryption and other applications. In: Miri, A., Vaudenay, S.
(eds.) SAC 2011. LNCS, vol. 7118, pp. 320–337. Springer, Heidelberg (2012)
9. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: Cryptographic sponge func-
tions (2011). http://sponge.noekeon.org/
10. Blaze, M.: High-bandwidth encryption with low-bandwidth smartcards. In:
Gollmann, G. (ed.) Fast Software Encryption. Lecture Notes in Computer Science,
vol. 1039, pp. 33–40. Springer, Heidelberg (1996)
11. Blaze, M., Feigenbaum, J., Naor, M.: A formal treatment of remotely keyed encryp-
tion. In: Nyberg, K. (ed.) EUROCRYPT 1998. LNCS, vol. 1403, pp. 251–265.
Springer, Heidelberg (1998)
12. Dobraunig, C., Eichlseder, M., Mendel, F., Schlaﬀer, M.: Ascon v1. http://
competitions.cr.yp.to/round1/asconv1.pdf
13. Gligoroski, D., Mihajloska, H., Samardjiska, S., Jacobsen, H., El-Hadedy, M.,
Jensen, R.E.: PiCipher v1. http://competitions.cr.yp.to/round1/picipherv1.pdf
14. Dodis, Y.: Concealment and Its Applications to Authenticated Encryption. In:
Dent, A.W., Zheng, Y. (eds.) Practical Signcryption. Information Security and
Cryptography, pp. 149–173. Springer, Heidelberg (2010)
15. Dworkin, M.J.: Sp 800–38c. recommendation for block cipher modes of opera-
tion: The CCM mode for authentication and conﬁdentiality. Technical report,
Gaithersburg, MD, United States (2004)
16. Andreeva, E., Bogdanov, A., Luykx, A., Mennink, B., Mouha, N., Yasuda, K.: How
to securely release unveriﬁed plaintext in authenticated encryption. In: Sarkar,
P., Iwata, T. (eds.) ASIACRYPT 2014. LNCS, vol. 8873, pp. 105–125. Springer,
Heidelberg (2014)
17. Andreeva, E., Bilgin, B., Bogdanov, A., Luykx, A., Mendel, F., Mennink, B.,
Mouha, N., Wang, Q., Yasuda, K.: PRIMATEs v1. http://competitions.cr.yp.to/
round1/primatesv1.pdf
18. Fouque, P.-A., Joux, A., Martinet, G., Valette, F.: Authenticated On-Line Encryp-
tion. In: Matsui, M., Zuccherato, R.J. (eds.) Selected Areas in Cryptography.
Lecture Notes in Computer Science, vol. 3006, pp. 145–159. Springer, Heidelberg
(2003)
19. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G., Van Keer, R.: Ketje v1.
http://competitions.cr.yp.to/round1/ketjev11.pdf
20. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G., Van Keer, R.: Ketje v1.
http://keyak.noekeon.org/Keyak-1.2.pdf
21. Alizadeh, J., Aref, M.R., Bagheri, N.: Artemia v1. http://competitions.cr.yp.to/
round1/artemiav1.pdf
22. Neves, S., Aumasson, J.-P., Jovanovic, P.: NORX: Parallel and Scalable AEAD
(2014). https://norx.io/
www.ebook3000.com

468
M. Agrawal et al.
23. Kohno, T., Viega, J., Whiting, D.: CWC: a high-performance conventional authen-
ticated encryption mode. In: Roy, B., Meier, W. (eds.) FSE 2004. LNCS, vol. 3017,
pp. 408–426. Springer, Heidelberg (2004)
24. Lucks, S.: On the security of remotely keyed encryption. In: Biham, E. (ed.) FSE
1997. LNCS, vol. 1267, pp. 219–229. Springer, Heidelberg (1997)
25. Saarinen, M.-J.O.: The CBEAMr1 Authenticated Encryption Algorithm. http://
competitions.cr.yp.to/round1/cbeamr1.pdf
26. Saarinen, M.-J.O.: The STRIBOBr 1 Authenticated Encryption Algorithm. http://
competitions.cr.yp.to/round1/stribobr1.pdf
27. McGrew, D.A., Viega, J.: The security and performance of the galois/counter mode
(GCM) of operation. In: Canteaut, A., Viswanathan, K. (eds.) INDOCRYPT 2004.
LNCS, vol. 3348, pp. 343–355. Springer, Heidelberg (2004)
28. Morawiecki, P., Gaj, K., Homsirikamol, E., Matusiewicz, K., Pieprzyk, J.,
Rogawski, M., Srebrny, M., Wojcik, M.: ICEPOLE v1. http://competitions.cr.yp.
to/round1/icepolev1.pdf
29. Rogaway, P., Bellare, M., Black, J.: OCB: A block-cipher mode of operation for
eﬃcient authenticated encryption. ACM Trans. Inf. Syst. Secur. 6(3), 365–403
(2003)
30. Wu, H., Preneel, B.: AEGIS: A Fast Authenticated Encryption Algorithm. In:
Lange, T., Lauter, K., Lisonˇek, P. (eds.) SAC 2013. LNCS, vol. 8282, pp. 185–202.
Springer, Heidelberg (2014)

Homomorphic Encryption
and Obfuscation
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based
Homomorphic Encryption
Masaya Yasuda1(B), Takeshi Shimoyama2, Jun Kogure2,
Kazuhiro Yokoyama3, and Takeshi Koshiba4
1 Institute of Mathematics for Industry, Kyushu University,
744 Motooka Nishi-ku, Fukuoka 819-0395, Japan
yasuda@imi.kyushu-u.ac.jp
2 FUJITSU LABORATORIES LTD., 1-1, Kamikodanaka 4-chome,
Nakahara-ku, Kawasaki 211-8588, Japan
3 Department of Mathematics, Rikkyo University, Nishi-Ikebukuro,
Tokyo 171-8501, Japan
4 Division of Mathematics, Electronics and Informatics,
Graduate School of Science and Engineering, Saitama University,
255 Shimo-Okubo, Sakura, Saitama 338-8570, Japan
Abstract. Homomorphic encryption enables various calculations while
preserving the data conﬁdentiality. Here we apply the homomor-
phic encryption scheme proposed by Brakerski and Vaikuntanathan
(CRYPTO 2011) to secure statistical analysis between two variables.
For reduction of ciphertext size and practical performance, we propose a
method to pack multiple integers into a few ciphertexts so that it enables
eﬃcient computation over the packed ciphertexts. Our packing method
is based on Yasuda et al.’s one (DPM 2013). While their method gives
eﬃcient secure computation only for small integers, our modiﬁcation is
eﬀective for larger integers. Our implementation shows that our method
is faster than the state-of-the-art work. Speciﬁcally, for one million inte-
gers of 16 bits (resp. 128 bits), it takes about 20 minutes (resp. 3.6 hours)
for secure covariance and correlation on an Intel Core i7-3770 3.40 GHz
CPU.
Keywords: Homomorphic encryption · Ring-LWE assumption ·
Packing methods · Secure covariance and correlation
1
Introduction
The recent development of cloud computing easily allows clients to outsource
their data to cloud services. However, security and privacy issues have risen at the
same time (e.g., see [8] for such issues). Homomorphic encryption is encryption
with the additional property that it can support operations on encrypted data
A part of this research was done when the ﬁrst author belonged to Fujitsu Labora-
tories Ltd.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 471–487, 2015.
DOI: 10.1007/978-3-319-19962-7 27

472
M. Yasuda et al.
(without decryption). If clients send their data in homomorphically encrypted
format, the cloud can still perform calculation on encrypted data. Since all data
in the cloud are encrypted, the conﬁdentiality of clients’ data can be preserved
irrespective of any actions in the cloud. Therefore this technology gives a pow-
erful tool to break several barriers for adoption of various cloud services. Here
we focus on application of homomorphic encryption to secure statistical anal-
ysis. Among privacy-preserving data mining techniques [1], the randomization
method is useful for such statistical analysis, in which suﬃciently large noises
are added to raw values so that individual values cannot be recovered but only
the entire statistics can be approximately obtained. The randomization method
is simple and eﬀective, but it can only recover rough statistical information. In
contrast, the homomorphic encryption technology enables to output accurate
results and hence it is expected to be applied to various areas such as health
care, chemical analysis and marketing analysis.
Depending on possible operations, we classify homomorphic encryption sche-
mes into the following types:
– Additive or multiplicative schemes (e.g., the Paillier scheme [19] is additive)
can support only additions or multiplications on encrypted data (electronic
voting is a possible application of an additive scheme).
– Fully homomorphic encryption (FHE) schemes can support “arbitrary”
operations. After Gentry’s breakthrough [11], a number of new FHE schemes
and implementations have been proposed (e.g., [3,5,6,9,12]), but current
FHE schemes are impractical (recently, Ducas and Micciancio [10] gave a
new method to make FHE schemes eﬃcient).
– Somewhat homomorphic encryption (SHE) schemes can support a limited
number of both additions and multiplications. The construction of almost
all FHE schemes starts from an SHE scheme. The associated SHE schemes
are much more practical than FHE, and they are applicable to various appli-
cations (note that SHE schemes are faster than [10]).
1.1
Related Work
Several work for statistical analysis have been proposed so far. In 2011, Lauter,
Naehrig and Vaikuntanathan [16] utilized the SHE scheme of [5] for secure stan-
dard deviation and logistical regression computations. They also proposed a
method to pack a large integer (e.g., 128 bits) into a single ciphertext for eﬃ-
cient secure sums and products over integers. In 2013, Yasuda et al. [23] extended
Lauter et al.’s method to pack multiple integers, and their extension enables eﬃ-
cient secure inner product computation. Unlike [16,23], Wu and Haven [14] in
2012 used the leveled FHE scheme of [3] for large-scale analysis such as covari-
ance and linear regression computations. Moreover, they used the CRT (Chinese
Remainder Theorem) packing method proposed by Smart and Vercauteren [21]
to operate multiple integers simultaneously. Recently, Lauter, L´opez-Alt and
Naehrig [15] applied a ring-based scheme for computing on encrypted genomic
data. Diﬀerent from the above packing methods, they focus on the structure of
data and show how to encode two types of genomic data for genomic algorithms.
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
473
1.2
Our Contributions
As in [16,23], we use the SHE scheme proposed by Brakerski and Vaikuntanathan
[5]. The security of the scheme relies on the hardness of the ring learning with
errors (RLWE) problem. Denote R = Z[x]/(xn + 1) for n a power of 2. The
packing method of [23] ﬁrst transforms multiple integers ai’s into a polynomial
f(x) ∈R with coeﬃcients given by the ai’s, and then encrypts the polynomial.
The homomorphic correctness over R enables to operate on multiple integers
over packed ciphertexts. The method is eﬀective for small integers of size 1 or 2
bits (in fact, it is implemented in [23] for secure distance computation between
“binary” vectors). However, the method becomes much less eﬃcient for larger
integers since larger coeﬃcients of f(x) requires larger plaintext space and then
it causes slower performance (see also [16, Section 4.1] for the same obstacle).
1. Our main contribution is to modify the packing method of [23] for integers
of practical bit-size p (e.g., p = 16 or 32). The basic idea is to use binary
representation of an integer for polynomial transformation in order to make
the coeﬃcients of f(x) always small. Our main trick involves an array of
coeﬃcients of f(x) consisting of multiple integers, which enables eﬃcient
computation of secure inner product for integers of p bits as in [23].
2. We implemented the SHE scheme with our modiﬁed packing method for
secure statistical analysis for p = 16 ∼128. Our experiments show that our
method gives faster performance than [14] for secure covariance of integers
of 128 bits. Speciﬁcally, for one million integers of 16 bits (resp. 128 bits),
our method takes about 20 minutes (resp. 3.6 hours) for secure covariance
and correlation on an Intel Core i7-3770 3.40 GHz CPU.
Notation The symbols Z and Q denote the ring of integers and the ﬁeld of ratio-
nal numbers, respectively. For a prime number p, the ﬁnite ﬁeld with p elements
is denoted by Fp. For two integers z and d, let [z]d denote the reduction of z mod-
ulo d included in the interval [−d/2, d/2) (the reduction of z modulo d included
in the interval [0, d) is denoted by “z mod d”). For A = (a0, a1, . . . , ak−1), let
||A||∞denote the ∞-norm deﬁned by maxi |ai|. We also let ⟨A, B⟩denote the
inner product of two vectors A and B of same length. Finally, let lg(q) denote
the logarithm value of an integer q with base 2.
2
RLWE-Based Somewhat Homomorphic Encryption
In this section, we brieﬂy review the construction and the homomorphic correct-
ness of the SHE scheme proposed by Brakerski and Vaikuntanathan [5]. For the
construction, it requires the following four parameters:
n: a 2-power integer deﬁning the base ring R = Z[x]/(xn + 1) for the scheme.
The degree n is sometimes called the lattice dimension.
q: a prime number with q ≡1 mod 2n, deﬁning the ring Rq = Fq[x]/(xn + 1),
which is the ciphertext space. Note that according to [4], the condition q ≡
1 mod 2n is not necessary for the construction and the security (but the
setting q ≡1 mod 2n is selected in numerous papers for eﬃciency).

474
M. Yasuda et al.
t: an integer with t < q to determine a plaintext space Rt = (Z/tZ)[x]/(f(x)).
σ: the parameter deﬁning a discrete Gaussian error distribution χ = DZn,σ.
The security of the scheme (constructed in Section 2.1 below) relies on the fol-
lowing assumption, which is a simpliﬁed version of the RLWE assumption of
Lyubashevsky, Peikert and Regev [18] (the following assumption is independent
of the parameter t, see [5, Proposition 1] for details):
Deﬁnition 1 (RLWE). Given parameters (n, q, t, σ), the assumption RLWEn,q,χ
is that it is infeasible to distinguish the following two distributions:
1. One samples (ai, bi) uniformly from (Rq)2.
2. One ﬁrst draws s ←χ = DZn,σ uniformly and then samples (ai, bi) ∈(Rq)2
by sampling ai ←Rq uniformly, ei ←χ and setting bi = ais + ei.
2.1
Construction of SHE Scheme
Here we give only the construction of the public-key variant scheme (speciﬁcally,
the following construction is the slight variant of [16, Section 3.2]).
– Key Generation We choose an element R ∋s ←χ. We then sample a
uniformly random element p1 ∈Rq and an error R ∋e ←χ. Set pk = (p0, p1)
with p0 = −(p1s + te) as the public key and sk = s as the secret key.
– Encryption For a plaintext m ∈Rt and the public key pk = (p0, p1), the
encryption samples R ∋u, f, g ←χ and compute the “fresh” ciphertext by
Enc(m, pk) = (c0, c1) = (p0u + tg + m, p1u + tf),
(1)
where the plaintext m ∈Rt is regarded as an element of Rq in the natural
way due to the condition t < q.
– Homomorphic Operations Given two ciphertexts ct
=
(c0, . . . , cξ)
and ct′ = (c′
0, . . . , c′
η), the homomorphic addition “∔” is computed by
component-wise addition ct ∔ct′ = (c0 + c′
0, . . . , cmax(ξ,η) + c′
max(ξ,η)) (by
padding with zeros if necessary). Similarly, the homomorphic subtraction is
given by component-wise subtraction. The homomorphic multiplication “∗”
is computed by ct∗ct′ = (ˆc0, . . . , ˆcξ+η), with (z denotes a symbolic variable)
ξ+η

i=0
ˆcizi =
 ξ

i=0
cizi

·
⎛
⎝
η

j=0
c′
jzj
⎞
⎠.
– Decryption For a (fresh or homomorphically operated) ciphertext ct =
(c0, . . . , cξ), the decryption with the secret key sk = s is computed by
Dec(ct, sk) = [ ˜m]q mod t ∈Rt,
(2)
where ˜m = 	ξ
i=0 cisi ∈Rq. For the secret key vector s = (1, s, s2, . . .), we
can simply rewrite Dec(ct, sk) = [⟨ct, s⟩]q mod t.
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
475
Remark 1. Given a fresh ciphertext ct = (c0, c1) generated by (1), we have
⟨ct, s⟩= (p0u + tg + m) + s · (p1u + tf) = m + t · (g + sf −ue)
(3)
in the ring Rq since p0 + p1s = −te. If the value m + t · (g + sf −ue) does
not wrap around mod q (all errors e, f, g, u ←χ must be suﬃciently small), we
have [⟨ct, s⟩]q = m + t · (g + sf −ue) in “the base ring R” (see also Lemma 1
below for details). In this case, we can recover the correct plaintext m by mod
t-operation, which shows the decryption mechanism for any fresh ciphertexts.
For two fresh ciphertexts ct1, ct2, we clearly have

⟨ct1 ∔ct2, s⟩= ⟨ct1, s⟩+ ⟨ct2, s⟩
⟨ct1 ∗ct2, s⟩= ⟨ct1, s⟩· ⟨ct2, s⟩
(4)
by the construction of homomorphic operations. These two equations imply that
the homomorphic correctness of the encryption scheme holds (see also (5) below).
2.2
Homomorphic Correctness
The “homomorphic correctness” means that the decryption procedure can
recover the operated result over plaintexts after performing several homomor-
phic operations over ciphertexts. It follows from the proof of [16, Lemma 3.3]
that homomorphic operations over ciphertexts correspond to the ring structure
of the plaintext space Rt (here we say that the scheme has the homomorphic
correctness over Rt). Speciﬁcally, we have

Dec(ct ∔ct′, sk) = m + m′ ∈Rt
Dec(ct ∗ct′, sk) = m × m′ ∈Rt
(5)
for ciphertexts ct, ct′ corresponding to plaintexts m, m′, respectively. However,
the scheme merely gives an SHE scheme (not an FHE scheme), and its correct-
ness holds under the following condition (the below lemma is very important for
choosing suitable parameters (n, q, t, σ) in order to avoid decryption failure):
Lemma 1 (Condition for successful decryption). For a ciphertext ct, the
decryption Dec(ct, sk) recovers the correct result if it satisﬁes the condition
∥⟨ct, s⟩∥∞< q/2.
In the inequality, we regard ⟨ct, s⟩as the element of R calculated by the right hand
side of (3) and (4), and for a = 	n−1
i=0 aixi ∈R, let ∥a∥∞= max |ai| denote the
∞-norm of its coeﬃcient representation. Speciﬁcally, for a fresh ciphertext ct,
the ∞-norm ∥⟨ct, s⟩∥∞is given by ∥m+t(g+sf −ue)∥∞with t ∈Z, m ∈Rt ⊂R
and e, f, g, u, s ←χ = DZn,σ (i.e., we here regard ⟨ct, s⟩∈R for evaluation).
Furthermore, for a homomorphically operated ciphertext, the ∞-norm can be
calculated by (4).

476
M. Yasuda et al.
3
Packing Method for Secure Statistical Computations
A certain special packing method enables us to eﬃciently perform several secure
computations, using the RLWE-based homomorphic encryption scheme con-
structed in Section 2.1. Before presenting our packing method, let us ﬁrst review
previous methods.
3.1
Review of Previous Packing Methods
Packing Method by [16]. Lauter et al. [16, Section 4.1] introduce a message
encoding technique for secure statistics over large integers such as 128 bits. Their
technique can pack a large integer into a single ciphertext, and it also enables
eﬃcient computation of sums and products over packed ciphertexts. Speciﬁcally,
for the degree parameter n of Section 2.1, their technique breaks an integer M
of up to n bits into a binary vector (m0, . . . , mn−1), creates a polynomial by
pm(M) =
n−1

i=0
mixi,
and ﬁnally encrypts M as ctpack(M)
:=
Enc (pm(M), pk), where pm(M)
is regarded as an element of Rt for taking suﬃciently large t. We have
pm(M)|x=2 = M, where f(x)|x=a = f(a) for a polynomial f(x) and an
integer a. For two integers M, M ′, the homomorphic addition ctpack(M) ∔
ctpack(M ′) gives the polynomial addition pm(M) + pm(M ′) on encrypted data
by the homomorphic correctness (5), and it also gives the integer addition
pm(M) + pm(M ′)|x=2 = M + M ′. However, the integer multiplication causes a
obstacle since the polynomial multiplication pm(M) · pm(M ′) has degree larger
than n in general. Their solution is to encode integers of at most (n/d) bits
when it requires d homomorphic multiplications. Their technique is eﬀective in
computing low degree multiplications such as the standard deviation.
Extension by [23]. Yasuda et al. [23] extends the packing method of Lauter
et al., by taking two types of packed ciphertexts as follows; For an integral vector
A = (a0, . . . , an−1) of length n, set
pm(1)(A) =
n−1

i=0
aixi and pm(2)(A) = −
n−1

i=0
aixn−i,
(6)
and then packed ciphertexts are deﬁned as ct(i)
pack(A) := Enc

pm(i)(A), pk

for
i = 1, 2 as in [16]. The ﬁrst type is same as Lauter et al.’s technique, but the
second one enables eﬃcient computation of secure inner product. Speciﬁcally,
for two vectors A and B of length n, only one homomorphic multiplication
over ct(1)
pack(A) and ct(2)
pack(B) can give the inner product ⟨A, B⟩on encrypted
data [23, Proposition1]. This inner product computation is eﬀective for secure
distance computations such as the Euclidean and the Hamming distances, rather
than secure statistical analysis (see [23, Section 4] for the application of secure
Hamming distance to privacy-preserving biometrics).
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
477
3.2
Our Modiﬁed Packing Method
When we handle integers of very small size (e.g., 1 or 2 bits), the packing method
of [23] is eﬀective and suﬃcient for secure statistics. However, for integers of
practical bit-size (e.g., even for 16 or 32 bits), the packing method enforces to set
the size parameter t of the plaintext space Rt to be considerably large, and then
such parameter setting would cause slow performance (see also [16, Section 4.1]
for their description on the same problem). Speciﬁcally, let A = (a0, . . . , an−1)
and B = (b0, . . . , bn−1) be two integral vectors of length n with entries ai, bi of p
bits. For obtaining secure inner product, we should take the parameter t larger
than the value ⟨A, B⟩= 	n−1
i=0 aibi so that the decryption result can not wrap
around by modulo t-operation (see the decryption procedure (2)). Since aibi is
of 2p bits, we should set
t ≥n · 22p,
which is too large to have practical performance. More speciﬁcally, when we use
such a huge parameter t, the encryption (1) generates a fresh ciphertext with
huge noises tg and tf where f, g ←χ. In this case, Lemma 1 requires huge q in
order to avoid decryption failure, and it also requires huge n for suﬃcient security
(e.g., see Appendix A for selection of parameters). As a result, such parameter
setting makes the size of ciphertexts huge (the size of a fresh ciphertext is given
by 2n · lg(q)), and then it causes impractical performance of the encryption
scheme. Then, in the below, we shall modify the packing method of [23] for
secure statistics over integers of practical bit-size.
Polynomial Transformation Modiﬁcation. Given an integer m, let A =
(a0, a1, . . . , am−1) be a vector of length m with entries ai of less than p bits
(e.g., consider p = 16 or 32). For a chosen integer r > 0 (typically set r = 2),
write each integral entry ai in the base-r representation, namely, we have
ai =
d−1

u=0
ai,uru with ∃ai,u ∈{0, 1, . . . , r −1},
(7)
where d = ⌈logr 2p⌉. Unlike the packing method of [23], we consider the following
two types of polynomials in the base ring R = Z[x]/(xn + 1):
Deﬁnition 2 (Modiﬁed Packing Method). Assume n ≥2md. Two types of
our modiﬁed polynomial transformation in the ring R are deﬁned by (cf. (6))
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
pm(1)
m,p,r(A) =
m−1

i=0
d−1

u=0
ai,uxu

x2id and
pm(2)
m,p,r(A) = −
m−1

i=0
d−1

u=0
ai,uxu

xn−2id.
(8)
Then, as in [16,23], two types of our packed ciphertexts are given by
ct(i)
m,p,r(A) := Enc(pm(i)
m,p,r(A), pk) for i = 1, 2. In the typical case where r = 2,
we omit “r” like pm(i)
m,p(A) and ct(i)
m,p(A) for i = 1, 2.

478
M. Yasuda et al.
By (7), the value substituted x = r for the polynomial 	d−1
u=0 ai,uxu is
clearly equal to the integer ai for any i (the idea is derived from Lauter et
al.’s method). Hence the two polynomials (8) correspond to 	m−1
i=0 aix2id and −
	m−1
i=0 aixn−2id, respectively. These polynomial transformations are similar to
the ones (6) introduced in [23]. Therefore our modiﬁcation can be considered as
a combination of [16] and [23], but our trick is the “2d-th power of x” in the
above polynomials (see the next discussion for this trick).
Secure Inner Product Using Our Modiﬁcation. Given A = (a0, . . . , am−1)
and B = (b0, . . . , bm−1) of same length m with entries ai, bi of less than p bits,
we assume n ≥2md as in Deﬁnition 2. From a similar argument of the proof of
[23, Proposition 1], the fact xn = −1 in the base ring R tells that the polynomial
multiplication pm(1)
m,p,r(A) × pm(2)
m,p,r(B) in the base ring R is equal to
m−1

i=0
Ai(x) · x2id

×
⎛
⎝−
m−1

j=0
Bj(x) · xn−2jd
⎞
⎠
= −
m−1

i=0
Ai(x)Bi(x)xn + · · · =
m−1

i=0
Ai(x)Bi(x) + terms of deg ≥2d
(9)
where we set
Ai(x) =
d−1

u=0
ai,uxu and Bi(x) =
d−1

v=0
bi,vxv.
Note that ai,u, bi,v are obtained by the base-r representation (7) for integers ai, bi.
Since 	m−1
i=0 Ai(x)Bi(x) has degree smaller than 2d, we can pick up the sub-
polynomial from the expression (9) since the other terms have degree larger than
2d, due to our trick of taking the 2d-th power of x in our modiﬁed polynomials
(8). Moreover, the value substituted x = r for 	m−1
i=0 Ai(x)Bi(x) is equal to
m−1

i=0
Ai(r)Bi(r) =
m−1

i=0
d−1

u=0
ai,uru
 d−1

v=0
bi,vrv

=
m−1

i=0
aibi = ⟨A, B⟩
by the base-r representation (7) for integers ai’s and bi’s (note that this idea is
similar to the multiplication pm(M) · pm(M ′) in the packing method of [16] for
obtaining integer multiplication M ·M ′). Then the homomorphic correctness (5)
of the encryption scheme gives the following result (cf. [23, Proposition 1]):
Theorem 1. Let A = (a0, . . . , am−1) and B = (b0, . . . , bm−1) be two integral
vector of same length m with entries ai, bi of less than p bits. Assume n ≥2md
as in Deﬁnition 2, where d = ⌈logr 2p⌉for a ﬁxed positive integer r. Let
ct = ct(1)
m,p,r(A) ∗ct(2)
m,p,r(B),
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
479
and let Dec(ct, sk) = 	n−1
i=0 mixi ∈Rt denote its decryption result. Then, under
the condition of Lemma 1 for the ciphertext ct, the sum
2d−1

i=0
miri ∈Z gives the
inner product ⟨A, B⟩modulo t.
For longer vectors, we must divide the vectors into sub-vectors of length m;
Given two vectors A and B of same length N > m, let Ai and Bi be the i-th
sub-vector of length m such that A = (A1 | . . . | Ak) and B = (B1 | . . . | Bk) for
k = ⌈N/m⌉(by padding with zeros if necessary). For encryption of the vector A
(resp. B), consider k ciphertexts ct(1)
m,p,r(Ai) (resp. ct(2)
m,p,r(Bi)) for i = 1, . . . , k.
Then, by Theorem 1 and the homomorphic correctness (5), the combination of
k homomorphic additions and k homomorphic multiplications
ct :=
k

i=1
ct(1)
m,p,r(Ai) ∗ct(2)
m,p,r(Bi)
(10)
gives the inner product ⟨A, B⟩modulo t on encrypted data. Speciﬁcally, let
	n−1
i=0 mixi ∈Rt denote the decryption result Dec(ct, sk) as in Theorem 1, and
then the sum 	2d−1
i=0 miri ∈Z equals to ⟨A, B⟩modulo t. In order to obtain the
correct inner product, we should take the parameter t so that the inner product
does not wrap around by modulo t-operation. Note that we clearly have
n−1

i=0
mixi ≡
k

j=1
pm(1)
m,p,r(Aj) × pm(2)
m,p,r(Bj)
(mod t)
(11)
in the plaintext ring Rt, and each coeﬃcient of pm(1)
m,p,r(Aj) and pm(2)
m,p,r(Bj)
is up to (r −1) by the base-r representation (7). Then, due to our trick of the
2d-th power of x in Deﬁnition 2, the equation on the right side of (11) has
coeﬃcients up to N(r −1)2d (since pm(1)
m,p,r(Aj) × pm(2)
m,p,r(Bj) has coeﬃcients
up to m(r −1)2d by the equation (9)), and hence it requires t ≥N(r −1)2d to
obtain the correct inner product. In particular, in the case r = 2, it requires
t ≥N · p
(12)
since d = p (cf. the packing method of [23] requires t ≥N · 22p for secure inner
product between two vectors of length N, as described in the ﬁrst paragraph of
Section 3.2). The inequality (12) helps us to take practical parameters (n, q, t, σ)
of the encryption scheme for secure statistics (see Appendix A for details).
Features of Our Modiﬁcation. Set r = 2. Given p and n (then d = p), our
method can pack at most ⌊n/2p⌋integers of less than p bits into a single cipher-
text. By Theorem 1, our method further enables to perform secure inner product
between two vectors of length ⌊n/2p⌋, by only one homomorphic multiplication.
Moreover, our method gives a generalization of the two packing methods of [16]

480
M. Yasuda et al.
and [23]; Actually, in the case p = n, the ﬁrst type of our packing method is
same as in [16], and it can pack an integer of at most n bits. In contrast, in
the case p = 1, our method is almost same as in [23] (the main diﬀerence is the
2d-th power of x in Deﬁnition 2), and our method can give eﬃcient secure inner
product between two binary vectors. This shows that for ﬁxed n the parameter
p gives a trade-oﬀbetween the length ⌊n/2p⌋of a vector which we can pack and
the bit-size p of entries which we can handle. In particular, for practical bit-size
p (e.g., p = 16 or 32), while the method of [16] can handle only one integer, our
method can handle multiple integers of simultaneously (speciﬁcally, our method
is about m times faster than [16] for a secure inner product).
Remark 2. Our method does not change the encryption algorithm of the RLWE-
based scheme of [5] (our technique is transformation from a vector to an element
of R before encryption). Therefore, as well as [16,23], our method does not
change the provable security of the original scheme.
Comparison to Other Packing Methods. Smart and Vercauteren [21] pro-
pose the polynomial-CRT packing method, applicable for lattices based homo-
morphic encryption. The CRT packing method is useful to perform SIMD (Single
Instruction - Multiple Data) operations on encrypted data, and the basic strat-
egy in the RLWE-based scheme of Section 2.1 is as follows; If f(x) = xn + 1
factorizes into r-factors modulo t such as f(x) ≡r
i=1 fi(x) mod t, then the
plaintext space ring Rt = (Z/tZ)[x]/(f(x)) can split into the direct product
Rt ≃
r

i=1
Ft[x]/(fi(x)).
In particular, if t satisﬁes t ≡1 mod 2n, then the base ring R completely
splits modulo t, namely, we have Rt ≃(Z/tZ)n. This property enables us to
operate multiple elements of Z/tZ in parallel. Speciﬁcally, given n elements
m1, . . . , mn ∈Ft, we ﬁrst transform the n-fold vector (m1, . . . , mn) to the ele-
ment m ∈Rt, and then encrypt it. Then the generated ciphertext is a packed
one of the mi’s. Based on the work of [13] for homomorphic evaluation of the
AES circuit, Wu and Haven [14] use the CRT packing method in the leveled fully
homomorphic encryption scheme of [3] for secure statistical analysis. As in our
work, they in [14, Section 4.2] introduce an eﬃcient computation of secure inner
product; Given two vectors u = (u1, . . . , un), v = (v1, . . . , vn) ∈Zn, let ct(u)
and ct(v) denote two CRT-packed ciphertexts, respectively. One homomorphic
multiplication ct(u) ∗ct(v) gives all n products uivi’s separately, but the CRT
packing method requires additional procedure (e.g., several homomorphic addi-
tions and rotations) to obtain the inner product 	 uivi. In contrast, our packing
method does not require such the additional procedure.
3.3
Secure Statistical Computations
Basic Statistical Analysis. Let (X, Y ) = (x0, y0), . . . , (xN−1, yN−1) be a pair
of two variables with N independent integer sample pairs (xi, yi). In particular,
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
481
covariance and correlation deﬁned below can describe how two random variables
X and Y are related (in this paper, we focus on covariance and correlation, which
are more complex than fundamental statistics such as mean and variance).
Mean, Variance, and Standard Deviation The mean is the average of a set of
numbers. In contrast, the variance is a measure of the dispersion around the
mean. For a variable X, the variance is denoted by s2
X (sX denotes the standard
deviation), and it is deﬁned s2
X =
	N−1
i=0 (xi −mX)2
N
, where mX denotes the
mean of the variable. It can be rewritten as s2
X =

1
N
N−1

i=0
x2
i

−m2
X.
Covariance and Correlation
The covariance can measure the linear rela-
tionship between two variables X and Y , and the formula is given as
cov(X, Y ) =
1
N −1
N−1

i=0
(xi −mX) (yi −mY ). Its alternative expression is given
as cov(X, Y ) =
1
N −1
N−1

i=0
xiyi −NmXmY

. In contrast, the correlation
examines the relationship between two variables in a symmetric manner. Its
formula is written as r(X, Y ) = cov(X, Y )
sXsY
.
Computations over Our Packed Ciphertexts. As we can easily see, it
suﬃces to compute ﬁve values
N−1

i=0
xi,
N−1

i=0
yi,
N−1

i=0
x2
i ,
N−1

i=0
y2
i , and
N−1

i=0
xiyi
(13)
for the covariance cor(X, Y ) and the correlation r(X, Y ). Here we shall give
eﬃcient computation of (13) on encrypted data, by using our packing method of
Deﬁnition 2. After decryption to obtain the ﬁve values (13), we need to perform
additional procedures over plaintexts for the covariance and the correlation, but
the procedures are tiny (note that we cannot actually compute the standard
deviation sX or sY since the square root computation has to be done after
decryption). Given two parameters m and p, assume that all integers xi’s and
yi’s are of less than p bits and the degree parameter n satisﬁes n ≥2mp (after this
subsection, we always set r = 2, and then d = ⌈logr 2p⌉= p). For encryption
of X and Y , we ﬁrst construct vectors Xi = (xm(i−1), . . . , xmi−1) and Y i =
(ym(i−1), . . . , ymi−1) of length m for i = 1, . . . , k with k = ⌈N/m⌉(by padding
with zeros if necessary), and then generate 4k packed ciphertexts

ct(1)
m,p(Xi), ct(2)
m,p(Xi)
k
i=1 and

ct(1)
m,p(Y i), ct(2)
m,p(Y i)
k
i=1 .
(14)

482
M. Yasuda et al.
For two sums 	 xi and 	 yi over packed ciphertexts, we set C =
m−1

i=0
x2pi,
which clearly equals to pm(1)
m,p(T ) where set T = (1, . . . , 1) of length m. By a
similar argument on Theorem 1, the homomorphic operations
ctS(X) :=
k

i=1
C ∗ct(2)
m,p(Xi) and ctS(Y ) :=
k

i=1
C ∗ct(2)
m,p(Y i)
give two sums 	 xi and 	 yi on encrypted data, respectively, where the homo-
morphic multiplication between the constant C and any ciphertext is deﬁned as
in Section 2.1 (e.g., the homomorphic multiplication C ∗ct(2)
m,p(Xi) corresponds
to the polynomial multiplication C × pm(2)
m,p(Xi), which can give the sum of
entries of Xi as in Theorem 1). Moreover, the result of Theorem 1 shows that
ctSS(X):=
k

i=1
ct(1)
m,p(Xi) ∗ct(2)
m,p(Xi) and ctSS(Y ):=
k

i=1
ct(1)
m,p(Y i) ∗ct(2)
m,p(Y i)
give two sums of squares of xi’s and yi’s, respectively, and
ctIP(X, Y ) :=
k

i=1
ct(1)
m,p(Xi) ∗ct(2)
m,p(Y i)

or
k

i=1
ct(2)
m,p(Xi) ∗ct(1)
m,p(Y i)

gives the inner product 	 xiyi. As a summary, ﬁve homomorphic operations
ctS(X), ctS(Y ), ctSS(X), ctSS(Y ), and ctIP(X, Y )
(15)
enable us to perform our desired values (13) over the packed ciphertexts (14).
Remark 3. Linear regression is one of the statistical estimation problems; Given
a dataset {(xi, yi)}N
i=1 with input variables xi ∈Zp and output variables yi ∈Z.
The aim of linear regression is to approximate y = (y1, . . . , yN)T as a lin-
ear function h(x) = θT x with certain θ ∈Qp. Then we need to take θ in
order to minimize the least-squares regression error. It requires to compute
θ = (XT X)−1XT y, where X = (x1, . . . , xN)T . For such matrix-matrix and
matrix-vector products, we can apply our secure inner products computation.
But we have to separately compute the numerator and denominator of θ (specif-
ically, the denominator of θ is given by the determinant of XT X). On the other
hand, it is diﬃcult to evaluate computations such as the median and the 1-norm
since we cannot compare two values without secret keys.
Remark 4. With the ﬁve values (13), a decryptor can compute basic statistical
analysis such as the covariance and the correlation. The values reveal more infor-
mation than the covariance and the correlation. Actually the values reveal means
mX, mY , standard deviations sX, sY , and the covariance cov(X, Y ). However,
even though they do reveal more information than the covariance and the corre-
lation, this is reasonable to assume that it is not a problem in most cases. If we
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
483
compute the covariance directly, we need to have ciphertexts of 	 xi and 	 yi.
Namely, with the additional ciphertexts, we can compute N(N −1)cov(X, Y )
directly on encrypted data (we assume that N is public). On the other hand, for
the correlation r(X, Y ) = cov(X,Y )
sXsY
, we cannot compute sXsY directly from our
packed ciphertexts. Therefore, for the value sXsY , we need to have ciphertexts
of sX and sY additionally (in other words, each client computes sX or sY on
plaintexts and sends it in encrypted format). Then the decryptor only knows the
numerator and the denominator of r(X, Y ).
Remark 5 (Additional Procedure for Privacy Enhancing). Let ct be one of the
ciphertexts in (15). By Theorem 1, our packing method uses the xk-coeﬃcient
of the decryption result Dec(ct, sk) ∈Rt with only 0 ≤k ≤2d −1 (d = p
in the case r = 2). In other words, our packed ciphertexts may include extra
information in xk-coeﬃcients with 2d ≤k ≤n −1. In order not to give a
decryptor such extra information, we here introduce a method to add random
noises to the ciphertext ct. For example, given ct = ctIP(X, Y ) consisting of
three elements (c0, c1, c2) ∈(Rq)2 by homomorphic operations, we ﬁrst generate
a random polynomial
r = rdxd + rd+1xd+1 + · · · + rn−1xn−1 ∈R
and then computes a ciphertext given by one homomorphic addition ct ∔r =
(c0 + r, c1, c2). Then the decryption of the ciphertext ct ∔r includes our desired
values in the ﬁrst 2d coeﬃcients, but the other coeﬃcients are masked by random
information ri’s. Therefore this procedure can make a decryptor not to obtain
extra information other than necessary information for statistical analysis.
4
Experimental Evaluation
In this section, we give implementation results of our packing method for secure
statistical computations (15). Before reporting our implementation results, let
us describe our method to choose suitable parameters (n, q, t, σ) of the RLWE-
based encryption scheme.
4.1
Selection of Parameters
Here we describe how to choose suitable parameters (n, q, t, σ) for our imple-
mentation (here we focus on taking suitable parameters for the case p = 16 and
N = 104). By Lemma 1, we need to evaluate the ∞-norm size of ⟨ct, s⟩for
each ciphertext ct in (15) to avoid decryption failure, where s denote the secret
key vector deﬁned in Section 2.1. It is suﬃcient to consider only the ciphertext
ctIP := ctIP(X, Y ), which has the largest size among ﬁve ciphertexts in (15)
(actually, ctSS(X), ctSS(Y ), and ctIP(X, Y ) have almost same norm size). We
clearly have
⟨ctIP, s⟩=
k

i=1

ct(1)
m,p(Xi), s

·

ct(2)
m,p(Y i), s

(16)

484
M. Yasuda et al.
in the base ring Rq of the ciphertext space. Let U denote an upper bound of
the ∞-norm size ∥⟨ct, s⟩∥∞for any fresh ciphertext ct. Since ct(1)
m,p(Xi) and
ct(2)
m,p(Y i) are fresh ciphertexts by our construction, all these ciphertexts have
∞-norm size at most U. By the well-known fact (e.g., see [16, Lemma 3.2]) that
∥a + b∥∞≤∥a∥∞+ ∥b∥∞and ∥a · b∥∞≤n · ∥a∥∞· ∥b∥∞
(17)
for any two elements a, b ∈Rq, we have ∥⟨ctIP, s⟩∥∞≤knU 2 by the equation
(16). With respect to the upper bound U, let ct denote a fresh ciphertext given
by (1). Note that ∥⟨ct, s⟩∥∞≈t · ∥g + sf −ue∥∞with e, f, g, u, s ←χ (see
also Remark 1). By [16, Lemma 3.1], any element drawn from χ = DZn,σ has
magnitude at most σ√n with probability 1 −2−n+1. Then we can estimate
∥⟨ct, s⟩∥∞≤2t · (σ√n)2 with overwhelmingly probability (a theoretical upper
bound is given as 2t · (σ√n)2 · n by the property (17), but it seems too large
in practice). Then we set U = 2tσ2n. By using this estimate for U, we have
∥⟨ctIP, s⟩∥∞≤knU 2 = 4kn3t2σ4, and hence Lemma 1 requires
q > 8kn3t2σ4
(18)
for our targeted ciphertext ctIP (then it also enables to avoid decryption failure
for all the ﬁve ciphertexts in (15)).
Here we give concrete parameters (n, q, t, σ) of the RLWE-based scheme of
Section 2.1 for secure statistic computation (15) of N integers of bit-size p =
16 ∼128. For parameter setting, we always set σ = 8 as in [16], and we here
consider to pack m = 100 integers into a single ciphertext by using our packing
method of Deﬁnition 2. In Table 1, given the maximum bit-size p and the number
N of integers (i.e., the number of records), we give our chosen parameters (n, q).
For example, given p = 16 and N = 104, we describe how to choose suitable
parameters (n, q); At ﬁrst, our packing method requires n ≥2mp = 3200 and
then we set n = 4096 = 212, the minimum 2-power integer larger than 3200.
Furthermore, we set t = N · p = 16, 000 < 214 by the condition (12). Finally,
we make use of the inequality (18) to ﬁnd a suitable prime q. Speciﬁcally, since
k = ⌈N/m⌉= 100 < 27, the inequality (18) requires
q > 23+7+36+28+12 = 285.
Then we set the bit-size of q to be 85 for these p and N.
Security Level of Our Chosen Parameters. The computational hardness
of lattice problems, including the RLWE assumption RLWEn,q,χ of Deﬁnition
1 (which assures the security of the scheme of Section 2.1), can be measured
by the root Hermite factor. According to [17], given parameters (n, q, t, σ), the
root Hermite factor δ of RLWEn,q,χ can be calculated by (the factor δ does not
depends on t)
c · q/σ = 22√
n·lg(q)·lg(δ),
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
485
where c is the constant determined by attack advantage ε (c ≈

lg(1/ε)/π),
and we here take c = 2.657 corresponding to ε = 2−32 as in [16]. For our chosen
parameters, we calculate the corresponding factor δ and give it in Table 1 below.
According to the state-of-the-art security analysis of [7] for lattice problems, a
root Hermite factor smaller than 1.0050 is estimated to have 80-bit security level
with an enough margin (as the factor δ is smaller, the security level becomes
higher). Since our chosen parameters always satisfy δ < 1.0050, we estimate that
all our chosen parameters have (much) more than 80-bit security.
4.2
Implementation Results
For our chosen parameters (see values of (n, lg(q)) in Table 1), we implemented
the RLWE-based homomorphic encryption scheme using our packing method
for secure statistical analysis. Note that all our chosen parameters are estimated
to give 80-bit security level for the encryption scheme with enough margins
(see the previous subsection for details). Our experiments ran on an Intel Core
i7-3770 CPU with 3.40 GHz and 16.0 GB RAM, using PARI C library [22]
(version 2.5.5) for arithmetic of large integers (we also use gcc 4.6.0 with -O3
compiler option). In Table 1, we give our informative implementation results;
For example, for N = 104 sample pairs (X, Y ) = {(xi, yi)}N
i=1 of integers of less
than p = 16 bits, we ﬁxed parameters (n, lg(q)) = (4096, 85). In this parameter
setting, Table 1 shows that it took 2.82 seconds to generate 2k packed ciphertexts
Table 1. Performance and ciphertext sizes of secure computations (15) for covari-
ance and correlation between two variables X and Y with N sample pairs (X, Y ) =
{(xi, yi)}N
i=1 of integers of less than p bits (we always pack m = 100 integers into a
single ciphertext by using our packing method of Deﬁnition 2)
Parameters
Performance (seconds)
Size of packed
p
N
(n, lg(q), δ)
Packed Enc.†
Secure comp.
Dec.
ciphertexts‡
16 104
(4096, 85, 1.0036)
2.82
8.74
0.05
34.8 MB
105
(4096, 97, 1.0040)
28.4
113.2
0.05
397 MB
106
(4096, 107, 1.0044)
282
1140
0.05
4.38 GB
32 104
(8192, 88, 1.0018)
6.21
19.73
0.09
72.1 MB
105
(8192, 100, 1.0021)
61.9
262.1
0.09
819 MB
106
(8192, 110, 1.0023)
739
2616
0.09
9.01 GB
64 104
(16384, 91, 1.0009)
11.25
57.78
0.25
149 MB
105 (16384, 103, 1.0011)
137.4
579.4
0.25
1.69 GB
106 (16384, 113, 1.0012)
1395∗
6083∗
0.25
18.5 GB
128 104
(32768, 94, 1.0005)
23.06
122.56
0.55
308 MB
105 (32768, 106, 1.0005)
256.1
1231.4
0.55
3.47 GB
106 (32768, 116, 1.0006)
2992∗
13014∗
0.55
38.0 GB
†Time to generate 2k packed ciphertexts {(ct(1)
m,p(Xi), ct(2)
m,p(Xi))}k
i=1 with k = ⌈N/m⌉
for the variable X with N samples xj’s, ‡Size of 4k packed ciphertexts (14) for two
variables X and Y (one packed ciphertext has size of 2n · lg(q)-bit)
∗Estimated times (due to memory constraints, we cannot perform actual experiments)

486
M. Yasuda et al.
{(ct(1)
m,p(Xi), ct(2)
m,p(Xi))}k
i=1 (the size of each ciphertext is 2n·lg(q) ≈87 KByte,
and hence 4k = 400 packed ciphertexts have size about 400 × 87 KByte = 34.8
MByte). It also took 8.74 seconds to perform secure computations (15), and
ﬁnally ﬁve decryption procedures took 0.05 seconds to obtain ﬁve values (13).
Performance Comparison to Related Work. As introduced in Section
3.2, Wu and Haven [14] implemented the leveled FHE scheme of [3] using the
CRT packing method for large-scale analysis. According to their implementation
results of [14, Table 5], it costs 1.89 minutes (i.e., about 113 seconds) to com-
pute mean and covariance on encrypted data for 4096 integers of 128 bits (their
experiments ran on a 24-core AMD Opteron processor with 2.1 GHz, 512 KB
of cache and 96 GB of available memory using NTL C++ library). In contrast,
Table 1 shows that ours costs 122.56 seconds for 104 integers of 128 bits, and
hence it is estimated to cost only about 50 seconds for 4096 integers. When we
ignore the slight diﬀerence of PC environments and implementation levels, ours
is estimated to be about 113
50 = 2.26 times faster than [14] (note again that it
costs about 113 seconds in [14]). Furthermore, we note that our parameter set-
ting is not optimal for p = 128-bit but for 16-bit integers, and hence ours would
be even faster if we take optimal parameters for 128 bits.
5
Conclusion
For secure statistical analysis over integers of practical bit-size, we modiﬁed the
packing method of [23] over RLWE-based homomorphic encryption schemes.
The main part of our modiﬁcation is the polynomial transformations (8), and
it gives a generalization of [16] and [23]. We also implemented our method for
secure covariance and correlation between two variables with N sample pairs of
integers of less than p bits for N = 104 ∼106 and p = 16 ∼128 (see Table 1
for details). Our method took about 2 minutes for N = 104 integers of p = 128
bits, which is at least twice faster than [14].
Acknowledgments. The authors thank Arnab Roy and Avradip Mandal, research
members of Fujitsu Laboratories of America (FLA), for reviewing a draft paper and
giving useful comments.
References
1. Aggrawal, C.C., Philip, S.Y.: A general survey of privacy-preserving data mining
models and algorithms. Springer (2008)
2. Brakerski, Z., Gentry, C., Halevi, S.: Packed ciphertexts in LWE-based homo-
morphic Encryption. In: Kurosawa, K., Hanaoka, G. (eds.) PKC 2013. LNCS,
vol. 7778, pp. 1–13. Springer, Heidelberg (2013)
3. Brakerski, Z., Gentry, C., Vaikuntanathan, V.: (Leveled) fully homomorphic
encryption without bootstrapping. In: Innovations in Theoretical Computer
Science-ITCS 2012, pp. 309–325. ACM (2012)
4. Brakerski, Z., Langlois, A., Peikert, C., Regev, O., Stehl´e, D.: Classical hardness
of learning with errors. In: Symposium on Theory of Computing-STOC 2013,
PP. 575–584. ACM (2013)
www.ebook3000.com

Secure Statistical Analysis Using RLWE-Based Homomorphic Encryption
487
5. Brakerski, Z., Vaikuntanathan, V.: Fully homomorphic encryption from ring-LWE
and security for key dependent messages. In: Rogaway, P. (ed.) CRYPTO 2011.
LNCS, vol. 6841, pp. 505–524. Springer, Heidelberg (2011)
6. Brakerski, Z., Vaikuntanathan, V.: Eﬃcient fully homomorphic encryption from
(standard) LWE. In: Foundations of Computer Science-FOCS 2011, 97–106. IEEE
(2011)
7. Chen, Y., Nguyen, P.Q.: BKZ 2.0: better lattice security estimates. In: Lee,
D.H., Wang, X. (eds.) ASIACRYPT 2011. LNCS, vol. 7073, pp. 1–20. Springer,
Heidelberg (2011)
8. Cloud Security Alliance (CSA), Security guidance for critical areas of focus in cloud
computing, December 2009. https://cloudsecurityalliance.org/csaguide.pdf
9. van Dijk, M., Gentry, C., Halevi, S., Vaikuntanathan, V.: Fully homomorphic
encryption over the integers. In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS,
vol. 6110, pp. 24–43. Springer, Heidelberg (2010)
10. Ducas, L., Micciancio, D.: FHEW: Bootstrapping homomorphic encryption in less
than a second. Cryptology ePrint Archive: report 2014/816 (2014)
11. Gentry, C.: Fully homomorphic encryption using ideal lattices. In: Symposium on
Theory of Computing-STOC 2009, pp. 169–178. ACM (2009)
12. Gentry, C., Halevi, S.: Implementing gentry’s fully-homomorphic encryption
scheme.
In:
Paterson,
K.G.
(ed.)
EUROCRYPT
2011.
LNCS,
vol.
6632,
pp. 129–148. Springer, Heidelberg (2011)
13. Gentry, C., Halevi, S., Smart, N.P.: Homomorphic evaluation of the AES circuit. In:
Safavi-Naini, R., Canetti, R. (eds.) CRYPTO 2012. LNCS, vol. 7417, pp. 850–867.
Springer, Heidelberg (2012)
14. Wuhan, D., Haven, J.: Using homomorphic encryption for large scale statistical
analysis (2012). http://cs.stanford.edu/people/dwu4//FHE-SI Report.pdf
15. Lauter, K., L´opez-Alt, A., Naehrig, M.: Private computation on encrypted genomic
data. In: Aranha, D.F., Menezes, A. (eds.) LATINCRYPT 2014. LNCS, vol. 8895,
pp. 3–27. Springer, Heidelberg (2015)
16. Lauter, K., Naehrig, M., Vaikuntanathan, V.: Can homomorphic encryption be
practical?. In: ACM workshop on Cloud computing security workshop-CCSW 2011,
pp. 113–124. ACM (2011)
17. Lindner, R., Peikert, C.: Better key sizes (and Attacks) for LWE-based encryp-
tion. In: Kiayias, A. (ed.) CT-RSA 2011. LNCS, vol. 6558, pp. 319–339. Springer,
Heidelberg (2011)
18. Lyubashevsky, V., Peikert, C., Regev, O.: On ideal lattices and learning with errors
over rings. In: Gilbert, H. (ed.) EUROCRYPT 2010. LNCS, vol. 6110, pp. 1–23.
Springer, Heidelberg (2010)
19. Paillier, P.: Public-key cryptosystems based on composite degree residuosity
classes. In: Stern, J. (ed.) EUROCRYPT 1999. LNCS, vol. 1592, pp. 223–238.
Springer, Heidelberg (1999)
20. Peikert, C., Vaikuntanathan, V., Waters, B.: A framework for eﬃcient and com-
posable oblivious transfer. In: Wagner, D. (ed.) CRYPTO 2008. LNCS, vol. 5157,
pp. 554–571. Springer, Heidelberg (2008)
21. Smart, N.P., Vercauteren, F.: Fully homomorphic SIMD operations. Designs, Codes
and Cryptography 71(1), 57–81 (2014)
22. The PARI Group, Bordeaux, PARI/GP. http://pari.math.u-bordeaux.fr/doc.html
23. Yasuda, M., Shimoyama, T., Kogure, J., Yokoyama, K., Koshiba, T.: Practi-
cal packing method in somewhat homomorphic encryption. In: Garcia-Alfaro, J.,
Lioudakis, G., Cuppens-Boulahia, N., Foley, S., Fitzgerald, W.M. (eds.) DPM 2013
and SETOP 2013. LNCS, vol. 8247, pp. 34–50. Springer, Heidelberg (2014)

Bad Directions in Cryptographic Hash Functions
Daniel J. Bernstein1,2(B), Andreas H¨ulsing2(B), Tanja Lange2(B),
and Ruben Niederhagen2(B)
1 Department of Computer Science, University of Illinois at Chicago,
Chicago, IL 60607–7045, USA
djb@cr.yp.to
2 Department of Mathematics and Computer Science, Technische Universiteit
Eindhoven, P.O. Box 513, 5600 MB Eindhoven, The Netherlands
andreas.huelsing@googlemail.com, tanja@hyperelliptic.org,
ruben@polycephaly.org
Abstract. A 25-gigabyte “point obfuscation” challenge “using security
parameter 60” was announced at the Crypto 2014 rump session; “point
obfuscation” is another name for password hashing. This paper shows
that the particular matrix-multiplication hash function used in the chal-
lenge is much less secure than previous password-hashing functions are
believed to be. This paper’s attack algorithm broke the challenge in just
19 minutes using a cluster of 21 PCs.
Keywords: Symmetric cryptography · Hash functions · Password hash-
ing · Point obfuscation · Matrix multiplication · Meet-in-the-middle
attacks · Meet-in-many-middles attacks
1
Introduction
Under normal circumstances, the system protected the passwords so that
they could be accessed only by privileged users and operating system
utilities. But through accident, programming error, or deliberate act,
the contents of the password ﬁle could occasionally become available to
unprivileged users. . . . For example, if the password ﬁle is saved on
backup tapes, then those backups must be kept in a physically secure
place. If a backup tape is stolen, then everybody’s password needs to be
changed. Unix avoids this problem by not keeping actual passwords any-
where on the system.
—“Practical UNIX & Internet Security” [24,
p. 84], 2003
The full version of this paper is available on IACR eprint [13]. The numbering
between both versions is synchronized for easy reference. This work was supported by
the National Science Foundation under grant 1018836, by the Netherlands Organi-
sation for Scientiﬁc Research (NWO) under grant 639.073.005, and by the European
Commission through the ICT program under contract INFSO-ICT-284833 (PUF-
FIN). Permanent ID of this document: 7c4f480d7f090d69c58b96437b6011b1. Date:
2015.04.22.
c
⃝Springer International Publishing Switzerland 2015
E. Foo and D. Stebila (Eds.): ACISP 2015, LNCS 9144, pp. 488–508, 2015.
DOI: 10.1007/978-3-319-19962-7 28
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
489
Consider a server that knows a secret password 11000101100100. The server
could check an input password against this secret password using the following
checkpassword algorithm (expressed in the Python language):
def checkpassword(input):
return int(input == "11000101100100")
But it is much better for the server to use the following checkpassword_hashed
algorithm (see the full version [13] for the deﬁnition of sha256hex):
def checkpassword_hashed(input):
return int(sha256hex(input) == (
"ba0ab099c882de48c4156fc19c55762e"
"83119f44b1d8401dba3745946a403a4f"
))
It is easy for the server to write down this checkpassword_hashed algorithm
in the ﬁrst place: apply SHA-256 to the secret password to obtain the string
ba0...a4f, and then insert that string into a checkpassword_hashed template.
There is no reason to believe that these two algorithms compute identical func-
tions. Presumably SHA-256 has a second (and third and so on) preimage of SHA-
256(11000101100100), i.e., a string for which checkpassword_hashed returns
1 while checkpassword returns 0. However, ﬁnding any such string would be a
huge advance in SHA-256 cryptanalysis. The checkpassword_hashed algorithm
outputs 1 for input 11000101100100, just like checkpassword, and outputs 0
for all other inputs that have been tried, just like checkpassword.
The core advantage of checkpassword_hashed over checkpassword is that it
is obfuscated. If the checkpassword algorithm is leaked to an attacker then the
attacker immediately sees the secret password and seizes control of all resources
protected by that password. If checkpassword_hashed is leaked, the attacker
does not see the secret password without solving a SHA-256 preimage problem:
the loss of conﬁdentiality does not immediately create a loss of integrity.
Obfuscation is a broad concept. There are many aspects of programs that one
might wish to obfuscate and that are not obfuscated in checkpassword_hashed:
for example, one can immediately see that the program is carrying out a SHA-
256 computation, and that (unless SHA-256 is weak) there are very few short
inputs for which the program prints 1. In the terminology of some recent papers
(see Section 2), what is obfuscated here is the key in a particular family of
“keyed functions”, but not the choice of family. Further comments on general
obfuscation appear below. We emphasize password obfuscation (also known as
“password hashing” or “point obfuscation”) because it is an important special
case: a widely deployed application using widely studied symmetric techniques.
1.1. State-of-the-art Password Hashing. See full version of this paper [13].
1.2. Matrix-Multiplication Password Hashing: the “Point Obfusca-
tion” Challenge. A “point obfuscation” challenge was announced by Apon,

490
D.J. Bernstein et al.
Huang, Katz, and Malozemoﬀ[7] at the Crypto 2014 rump session. “Point obfus-
cation” is the same concept as password hashing: see, e.g., [34] (a hashed pass-
word is a “provably secure obfuscation of a ‘point function’ under the random
oracle model”).
The challenge consists of “an obfuscated 14-bit point function on Dropbox”: a
25-gigabyte program with the promise that the program returns 1 for one secret
14-bit input and 0 for all other 14-bit inputs. The goal of the challenge is to deter-
mine the secret 14-bit input: “learn the point and you win!” An accompanying
October 2014 paper [5] described the challenge as having “security parameter
60”, where “security parameter λ is designed to bound the probability of suc-
cessful attacks by 2−λ”.
We tried the 25-gigabyte program on a PC with the following relevant
resources: an 8-core 125-watt AMD FX-8350 “Piledriver” CPU (about $200),
32 gigabytes of RAM (about $400), and a 2-terabyte hard drive (about $100).
The program took slightly over 4 hours for a single input. A brute-force attack
using this program would obviously have been feasible but would have taken
over 65536 hours worst-case and over 32768 hours on average, i.e., an average of
nearly 4 years on the same PC, consuming 500 watt-years of electricity.
1.3. Attacking Matrix-Multiplication Password Hashing. In this paper
we explain how we solved the same challenge in just 19 minutes using a cluster
of 21 such PCs. The solution is 11000101100100; we reused this string above as
our example of a secret password. Of course, knowing this solution allowed us
to compress the original program to a much faster checkpassword algorithm.
The time for our attack algorithm against a worst-case input point would
have been just 34 minutes, about 5000 times faster than the original brute-force
attack, using under 0.2 watt-years of electricity. Our current software is slightly
faster: it uses just 29.5 minutes on 22 PCs, or 35.7 minutes on 16 PCs.
More generally, for an n-bit point function obfuscated in the same way, our
attack algorithm is asymptotically n4/2 times faster than a brute-force search
using the original program. This quartic speedup combines four linear speedups
explained in this paper, taking advantage of the matrix-multiplication structure
of the obfuscated program. Two of the four speedups (Section 3) are applicable
to individual inputs, and could have been integrated into the original program,
preserving the ratio between attack time and evaluation time; but the other two
speedups (Section 4) share work between separate inputs, making the attack
much faster than a simple brute-force attack.
See Section 1.6 for generalizations to more functions.
1.4. Matrix-Multiplication Password Hashing vs. State-of-the-art
Password Hashing. It is well known that a 2n-guess preimage attack against
a hash function, cipher, etc. does not cost exactly 2n times as much as a single
function evaluation: there are always ways to merge small amounts of initial work
across multiple inputs, and to skip small amounts of ﬁnal work. See, for exam-
ple, [35] (“Reduce the DES encryption from 16 rounds to the equivalent of ≈9.5
rounds, by shortcircuit evaluation and early aborts”), [30] (“biclique” attacks
against various hash functions), and [14] (“biclique” attacks against AES).
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
491
However, one expects these speedups to become less and less noticeable
for functions that have more and more rounds. For any state-of-the-art cost-
C password-hashing function, the cost of a 2n-guess preimage attack is very
close to 2nC. The matrix-multiplication function is much weaker: the cost of our
attacks is far below 2n times the cost of the best method known to evaluate the
function.
Even worse, the matrix-multiplication approach has severe performance prob-
lems that end up limiting the number n of input bits. The “obfuscated point
function” includes 2n matrices, each matrix having n+2 rows and n+2 columns,
each entry having approximately 4((λ + 1)(n + 4) + 2)2 log2 λ bits; recall that
λ is the target “security parameter”. If λ is just 60 and n is above 36 then a
single obfuscated password does not ﬁt on a 2-terabyte hard drive, never mind
the time and memory required to print and evaluate the function.
Earlier password-hashing functions handle a practically unlimited number
of input bits with negligible slowdowns; ﬁt obfuscated passwords into far fewer
bits (a small constant times the target security level); allow the user far more
ﬂexibility to select the amount of time and memory used to check a password;
and do not have the worrisome matrix structure exploited by our attacks.
1.5. Context: Obfuscating other Functions. Why, given the extensive hash-
ing literature, would anyone introduce a new password-obfuscation method with
unnecessary mathematical structure, obvious performance problems, and no
obvious advantages? To answer this question, we now explain the context of the
Apon–Huang–Katz–Malozemoﬀpoint-obfuscation challenge; we start by empha-
sizing that their goal was not to introduce a new point-obfuscation method.
Point functions are not the only functions that cryptographers obfuscate.
Consider, for example, the following fast algorithm to compute the pqth power
of an input mod pq, where p and q are particular prime numbers shown in the
algorithm:
def rsa_encrypt_unobfuscated(x):
p = 37975227936943673922808872755445627854565536638199
q = 40094690950920881030683735292761468389214899724061
pinv = 23636949109494599360568667562368545559934804514793
qinv = 15587761943858646484534622935500804086684608227153
return (qinv*q*pow(x,q,p) + pinv*p*pow(x,p,q)) % (p*q)
The following algorithm is not as fast but uses only the product pq:
def rsa_encrypt(x):
pq = int("15226050279225333605356183781326374297180681149613"
"80688657908494580122963258952897654000350692006139")
return pow(x,pq,pq)
These algorithms compute exactly the same function x →xpq mod pq, but the
primes p and q are exposed in rsa_encrypt_unobfuscated while they are obfus-
cated in rsa_encrypt. This obfuscation is exactly the reason that rsa_encrypt

492
D.J. Bernstein et al.
is safe to publish. In other words, RSA public-key encryption is an obfuscation
of a secret-key encryption scheme.
(Note that this size of pq is too small for serious security. The particular pq
shown here was introduced many years ago as the “RSA-100” challenge and was
factored in 1991. One should take larger primes p and q.)
In a FOCS 2013 paper [26], Garg, Gentry, Halevi, Raykova, Sahai, and Waters
proposed an obfuscation method that takes any fast algorithm A as input and
“eﬃciently” produces an obfuscated algorithm Obf(A). The security goal for
Obf is to be an “indistinguishability obfuscator”: this means that Obf(A) is
indistinguishable from Obf(A′) if A and A′ are fast algorithms computing the
same function.
For example, if Obf is an indistinguishability obfuscator, and if an
attacker can extract p and q from Obf(rsa_encrypt_unobfuscated), then
the attacker can also extract p and q from Obf(rsa_encrypt), since the two
obfuscations are indistinguishable; so the attacker can “eﬃciently” extract
p and q from pq, by ﬁrst computing Obf(rsa_encrypt). Contrapositive:
if Obf is an indistinguishability obfuscator and the attacker cannot “eﬃ-
ciently” extract p and q from pq, then the attacker cannot extract p and q
from Obf(rsa_encrypt_unobfuscated); i.e., Obf(rsa_encrypt_unobfuscated)
hides p and q at least as eﬀectively as rsa_encrypt does.
Another example, returning to symmetric cryptography: It is reasonable to
assume that checkpassword and checkpassword_hashed compute the same
function if the input length is restricted to, e.g., 200 bits. This assumption,
together with the assumption that Obf is an indistinguishability obfuscator,
implies that Obf(checkpassword) hides a ≤200-bit secret password at least as
eﬀectively as checkpassword_hashed does.
These examples illustrate the generality of indistinguishability obfuscation. In
the words of Goldwasser and Rothblum [28], eﬃcient indistinguishability obfus-
cation is “best-possible obfuscation”, hiding everything that ad-hoc techniques
would be able to hide.
There are, however, two critical caveats. First, it is not at all clear that the
Obf proposal from [26] (or any newer proposal) will survive cryptanalysis. There
are actually two alternative proposals in [26]: the ﬁrst relies on multilinear maps
[25] from Garg, Gentry, and Halevi, and the second relies on multilinear maps [23]
from Coron, Lepoint, and Tibouchi. In a paper [20] posted early November 2014
(a week after we announced our solution to the “point obfuscation” challenge),
Cheon, Han, Lee, Ryu, and Stehl´e announced a complete break of the main
security assumption in [23], undermining a remarkable number of papers built
on top of [23]. The attack from [20] does not seem to break the application of [23]
to point obfuscation (since “encodings of zero” are not provided in this context),
but it illustrates the importance of leaving adequate time for cryptanalysis. A
followup work by Gentry, Halevi, Maji, and Sahai [27] extends the attack from
[20] to some settings where no “encodings of zero” below the “maximal level”
are available, although the authors of [27] state that “so far we do not have a
working attack on current obfuscation candidates”.
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
493
Second, the literature already contains much simpler, much faster, much
more thoroughly studied techniques for important examples of obfuscation, such
as password hashing and public-key encryption. Even if the new proposals in fact
provide indistinguishability obfuscation for more general functions, there is no
reason to believe that they can provide competitive security and performance for
functions where the previous techniques apply. We would expect the generality of
these proposals to damage the security-performance curve in a broad range of real
applications covered by the previous techniques, implying that these proposals
should be used only for applications outside that range.
The goal of Apon, Huang, Katz, and Malozemoﬀwas to investigate “the prac-
ticality of cryptographic program obfuscation”. Their obfuscator is not limited
to point functions; it takes more general circuits as input. However, after per-
formance evaluation, they concluded that “program obfuscation is still far from
being deployable, with the most complex functionality we are able to obfuscate
being a 16-bit point function”; see [5, page 2]. They chose a 14-bit point function
as a challenge.
1.6. Attacking Matrix-Multiplication-Based Obfuscation of any Func-
tion. The real-world importance of password hashing justiﬁes focusing on point
functions, but we have also adapted our attack algorithm to arbitrary n-bit-to-
1-bit functions. Speciﬁcally, we have considered the method explained in [5] to
obfuscate an arbitrary n-bit-to-1-bit function, and adapted our attack algorithm
to this level of generality. For the general case, with u pairs of w × w matrices
using n input bits, we save a factor of roughly uw/2 in evaluating each input,
and a further factor of approximately n/ log2 w in evaluating all inputs. The
n/ log2 w increases to n/2 for the standard input-bit order described in [5], but
for an arbitrary input-bit order our attack is still considerably faster than a
simple brute-force attack. See Section 8.
We comment that standard cryptographic hashing can be used to obfuscate
general functions. We suggest the following trivial obfuscation technique as a
baseline for future obfuscation challenges: precompute a table of hashes of the
inputs that produce 1; add fake random hashes to pad the table to size 2n (or a
smaller size T, if it is acceptable to reveal that at most T inputs produce 1); and
sort the table for fast lookups. This does not take polynomial time as n →∞
(for T = 2n), but it nevertheless appears to be smaller, faster, and stronger than
all of the recently proposed matrix-multiplication-based obfuscation techniques
for every feasible value of n.
2
Review of the Obfuscation Scheme
Since the initial Obf proposal by Garg, Gentry, Halevi, Raykova, Sahai, and
Waters [26] a lot of research was spent on ﬁnding applications and improving the
proposed scheme. The challenge from [5] which we broke uses the relaxed-matrix-
branching-program method by Ananth, Gupta, Ishai, and Sahai [4] to generate
a size-reduced obfuscated program and combines it with the integer-based mul-
tilinear map (CLT) due to Coron, Lepoint, and Tibouchi [23]. As mentioned in

494
D.J. Bernstein et al.
Section 1, the recent CLT attack by Cheon, Han, Lee, Ryu, and Stehl´e [20] relies
on “encodings of zero” and therefore does not apply to this point-obfuscation
scheme. Our attack will also work for other matrix-multiplication-type obfusca-
tion schemes with a similar structure, and in particular we see no obstacle to
applying the same attack strategy with the Garg–Gentry–Halevi [25] multilinear
map in place of CLT.
Most of the Obf literature does not state concrete parameters and does not
present computer-veriﬁed examples. The ﬁrst implementations, ﬁrst examples,
and ﬁrst challenge were from Apon, Huang, Katz, and Malozemoﬀin [5], [6],
and [7], providing an important foundation for quantifying and verifying attack
performance.
The challenge given in [5] is an obfuscation of a point function, so we ﬁrst give
a self-contained description of these obfuscated point-function programs from the
attacker’s perspective; we then comment brieﬂy on more general functions. For
details on how the matrices below are constructed, we refer the reader to [4],
[23], and of course [5]; but these details are not relevant to our attack.
2.1. Obfuscated Point Functions. A point function is a function on {0, 1}n
that returns 1 for exactly one secret vector of length n and 0 otherwise. The
obfuscation scheme starts with this secret vector and an additional security
parameter λ related to the security of the multilinear map.
The obfuscated version of the point function is given by a list of 2n public
(n + 2) × (n + 2) matrices Bb,k for 1 ≤b ≤n and k ∈{0, 1} with integer entries;
a row vector s of length n + 2 with integer entries; a column vector t of length
n + 2 with integer entries; an integer pzt (a “zero test” value, not to be confused
with an “encoding of zero”); and a positive integer q. All of the entries and pzt
are between 0 and q −1 and appear random. The number of bits of q has an
essentially linear impact upon our attack cost; [5] chooses the number of bits of
q to be approximately 4((λ + 1)(n + 4) + 2)2 log2 λ for multilinear-map security
reasons.
The obfuscated program works as follows:
• Take as input an n-bit vector x = (x[1], x[2], . . . , x[n]).
• Compute the integer matrix A = B1,x[1]B2,x[2] · · · Bn,x[n] by successive
matrix multiplications.
• Compute the integer y(x) = sAt by a vector-matrix multiplication and a dot
product.
• Compute y(x)pzt and reduce mod q to the range [−(q −1)/2, (q −1)/2].
• Multiply the remainder by 22λ+11, divide by q, and round to the nearest
integer. This result is by deﬁnition the matrix-multiplication hash of x.
• Output 0 if this hash is 0; output 1 otherwise.
We have conﬁrmed these steps against the software in [6].
The matrix-multiplication hash here is reminiscent of “Fast VSH” from [21].
Fast VSH hashes a block of input as follows: use input bits to select precomputed
primes from a table, multiply those primes, and reduce mod something. The
matrix-multiplication hash hashes a block of input as follows: use input bits to
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
495
select precomputed matrices from a table, multiply those matrices, and reduce
mod something. The matrices are secretly chosen with additional structure, but
we do not use that structure in our attack.
2.2. Initial Security Analysis. A straightforward brute-force attack deter-
mines the secret vector by computing the matrix-multiplication hash of all 2n
vectors x. Of course, the computation stops once a correct hash is found.
Unfortunately [5] and [7] do not include timings for λ = 60 and n = 14, so
we timed the software from [6] on one of our PCs and saw that each evaluation
took 245 minutes, i.e., 245.74 cycles at 4GHz. As the code automatically used
all 8 cores of the CPU, this leads to a total of 248.74 cycles per evaluation.
A brute-force computation using this software would take 214 · 248.74 = 262.74
cycles worst-case, and would take more than 260 cycles for 85% of all inputs.
For comparison, recall that the CLT parameters were designed to just barely
provide 2λ = 260 security, although the time scale for the 260 here is not clear.
If the time scale of the security parameter is close to one cycle then the cost of
these two attacks is balanced.
In their Crypto 2014 rump-session announcement [8], the authors declared
this brute-force attack to be infeasible: “The great part is, it’s only 14 bits, so
you think you can try all 2 to the 14 points, but it takes so long to evaluate that
it’s not feasible.” The authors concluded in [5, Section 5] that they were “able
to obfuscate some ‘meaningful’ programs” and that “it is important to note that
the fact that we can produce any ‘useful’ obfuscations at all is surprising”.
We agree that a 500-watt-year computation is a nonnegligible investment of
computer time (although we would not characterize it as “infeasible”). However,
in Section 3 we show how to make evaluation two orders of magnitude faster,
bringing a brute-force attack within reach of a small computer cluster in a matter
of days. Furthermore, in Section 4 we present a meet-in-the-middle attack that
is another two orders of magnitude faster.
2.3. Obfuscation of General Functions and Keyed Functions. The obfus-
cation scheme in [4] transforms any function into a sequence of matrix multipli-
cations. At every multiplication the matrix is selected based on a bit of the input
x but usually the bits of x are used multiple times. For general circuits of length
ℓthe paper constructs an oblivious relaxed matrix branching program of length
nℓwhich cycles ℓtimes through the n entries of x in sequence to select from 2nℓ
matrices. In that case most of the matrices are obfuscated identity matrices but
the regular access pattern stops the attacker from learning anything about the
function.
Sometimes (as in the password-hashing example) the structure of the circuit
is already public, and all that one wants to obfuscate is a secret key. In other
words, the circuit computes fz(x) = φ(z, x) for some secret key z, where φ is
a publicly known branching program; the obfuscation needs to protect only the
secret key z, and does not need to hide the function φ. This is called “obfuscation
of keyed functions” in [4]. For this class of functions the length of the obfuscated
program equals the length of the circuit for φ; the bits of x are used (and reused
as often as necessary) in a public order determined by φ.

496
D.J. Bernstein et al.
The designer can drive up the cost of brute-force attacks by including addi-
tional matrices as in the general case, but this also increases the obfuscation
time, obfuscated-program size, and evaluation time.
3
Faster Algorithms for One Input
This section describes two speedups to the obfuscated programs described in
Section 2. These speedups are important for constructive as well as destructive
applications.
Combining these two ideas reduced our time to evaluate the obfuscated point
function for a single input from 245 minutes to under 5 minutes (4 minutes
51 seconds), both measured on the same 8-core CPU. The authors of [6] have
recently included these speedups in their software, with credit to us.
3.1. Cost Analysis for the Original Algorithm. Schoolbook multiplication
of the two (n+2)×(n+2) matrices B1,x[1] and B2,x[2] uses (n+2)3 multiplications
of matrix entries. Similar comments apply to all n −1 matrix multiplications,
for a total of (n −1)(n + 2)3 multiplications of matrix entries.
This quartic operation count understates the asymptotic complexity of the
algorithm for two reasons, even when the security parameter λ is treated as a
constant. The ﬁrst reason is that the number of bits of q grows quadratically
with n. The second reason is that the entries in B1,x[1]B2,x[2] have about twice as
many bits as the entries in the original matrices, the entries in B1,x[1]B2,x[2]B3,x[3]
have about three times as many bits, etc. The paper [5] reports timings for point
functions with n ∈{8, 12, 16} for security parameter 52, and in particular reports
microbenchmarks of the time taken for each of the matrix products, starting with
the ﬁrst; these microbenchmarks clearly show the slowdown from one product
to the next, and the paper explains that “each multiplication increases the mul-
tilinearity level of the underlying graded encoding scheme and thus the size of
the resulting encoding”.
We now account for the size of the matrix entries. Recall that state-of-the-
art multiplication techniques (see, e.g., [11]) take time essentially linear in b,
i.e., b1+o(1), to multiply b-bit integers. The original entries have size quadratic
in n, and the products quickly grow to size cubic in n. More precisely, the ﬁnal
product A = B1,x[1] · · · Bn,x[n] has entries bounded by (n + 2)n−1(q −1)n and
typically larger than (q −1)n; similar bounds apply to intermediate products.
More than n/2 of the products have typical entries above (q −1)n/2, so the
multiplication time is dominated by integers having size cubic in n.
The total time to compute A is n7+o(1) for constant λ, equivalent to n5+o(1)
multiplications of integers on the scale of q. This time dominates the total time
for the algorithm.
3.2. Intermediate Reductions Mod q. We do better by limiting the growth
of the elements in the computation. The ﬁnal result y(x)pzt is in Z/q, the ring of
integers mod q, and is obtained by a sequence of multiplications and additions,
so we are free to reduce mod q at any moment in the computation. Any of the
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
497
initial integer multiplications has inputs at most q −1; we allow the temporary
values to grow to at most (n + 2)(q −1)2 by computing the sum of the products
for one entry and then reduce mod q. Thus any future multiplication also has
its inputs at most q −1.
State-of-the-art division techniques take time within a constant factor of
state-of-the-art multiplication techniques, so (n + 2)2 reductions mod q take
asymptotically negligible time compared to (n+2)3 multiplications. The number
of bits in each intermediate integer drops from cubic in n to quadratic in n.
More precisely, the asymptotic speedup factor is n/2, since the original mul-
tiplication inputs had on average about n/2 times as many bits as q. We observe
a smaller speedup factor for concrete values of n, mainly because of the overhead
for the extra divisions.
The total time to compute A mod q is n6+o(1) for constant λ, dominated by
(n −1)(n + 2)3 = n4 + 5n3 + 6n2 −4n −8 multiplications of integers bounded
by q, inside (n −1)(n + 2)2 = n3 + 3n2 −4 dot products mod q.
3.3. Matrix-Vector Multiplications. We further improve the computation
by reordering the operations used to compute y(x): speciﬁcally, instead of com-
puting A, we compute y(x) =

· · ·

(sB1,x[1])B2,x[2]

· · · Bn,x[n]

t. This sequence
of operations requires n vector-matrix products and a ﬁnal vector-vector multi-
plication.
This combines straightforwardly with intermediate reductions mod q as
above. The total time to compute y(x) mod q is n5+o(1), dominated by n(n +
2) + 1 = (n + 1)2 dot products mod q.
4
Faster Algorithms for Many Inputs
A brute-force attack iterates through the whole input range and computes the
evaluation for each possible input until the result of the evaluation is 1 and
thus the correct input has been found. In terms of complexity our improvements
from Section 3 reduced the cost of brute-forcing an n-bit point function from
time n7+o(1)2n to time n5+o(1)2n for constant λ, dominated by (n + 1)22n dot
products mod q. This algorithm is displayed in Figure 4.1 of [13].
This section presents further reductions to the complexity of the attack.
These share computations between evaluations of many inputs and have no
matching speedups on the constructive side (which usually only evaluates at a
single point at once and in any case cannot be expected to have related inputs).
4.2. Reusing Intermediate Products. Recall that Section 3 computes y(x) =
sB1,x[1] · · · Bn,x[n]t mod q by multiplying from left to right: the last two steps
are to multiply the vector sB1,x[1] · · · Bn−1,x[n−1] by Bn,x[n] and then by t.
Notice that this vector does not depend on the choice of x[n]. By computing
this vector, multiplying the vector by Bn,0 and then by t, and multiplying the
same vector by Bn,1 and then by t, we obtain both y(x[1], . . . , x[n −1], 0) and
y(x[1], . . . , x[n −1], 1). This saves almost half of the cost of the computation.
Similarly, we need only two computations of sB1,x[1] for the two choices of
x[1]; four computations of sB1,x[1]B2,x[2] for the four choices of (x[1], x[2]); etc.

498
D.J. Bernstein et al.
Overall there are 2 + 4 + 8 + · · · + 2n = 2n+1 −2 vector-matrix multiplications
here, plus 2n ﬁnal multiplications by t, for a total of (n + 2)(2n+1 −2) + 2n =
(2n + 5)2n −2(n + 2) dot products mod q.
To minimize memory requirements, we enumerate x in lexicographic order,
maintaining a stack of intermediate products. We reuse products on the stack to
the extent allowed by the common preﬁx between x and the previous x. In most
cases this common preﬁx is almost the entire stack. On average slightly fewer
than two matrix-vector products need to be recomputed for each x. See Figure
4.3 of [13] for a recursive version of this algorithm.
4.4. A Meet-in-the-middle Attack. To do better we change the order of
matrix multiplication yet again, separating ℓ“left” bits from n −ℓ“right” bits:
y(x) = (sB1,x[1] · · · Bℓ,x[ℓ])(Bℓ+1,x[ℓ+1] · · · Bn,x[n]t).
We exploit this separation to store and reuse some computations. Speciﬁcally,
we precompute a table of “left” products
L[x[1], . . . , x[ℓ]] = sB1,x[1] · · · Bℓ,x[ℓ]
for all 2ℓchoices of (x[1], . . . , x[ℓ]). The main computation of all y(x) works as
follows: for each choice of (x[ℓ+ 1], . . . , x[n]), compute the “right” product
R[x[ℓ+ 1], . . . , x[n]] = Bℓ+1,x[ℓ+1] · · · Bn,x[n]t,
and then multiply each element of the L table by this vector.
Computing a single left product sB1,x[1] · · · Bℓ,x[ℓ] from left to right, as in
Section 3, takes ℓvector-matrix products, i.e., ℓ(n + 2) dot products mod q.
Overall the precomputation uses ℓ(n + 2)2ℓdot products mod q.
Computing a single right product Bℓ+1,x[ℓ+1] · · · Bn,x[n]t from right to left
(starting from t) takes n −ℓmatrix-vector products, for a total of (n −ℓ)(n + 2)
dot products mod q. The outer loop in the main computation therefore uses
(n −ℓ)(n + 2)2n−ℓdot products mod q in the worst case. The inner loop in the
main computation, computing all y(x), uses just 2n dot products mod q in total
in the worst case.
The total number of dot products mod q in this algorithm, including precom-
putation, is ℓ(n+2)2ℓ+(n−ℓ)(n+2)2n−ℓ+2n. In particular, for ℓ= n/2 (assum-
ing n is even), the number of dot products mod q simpliﬁes to n(n+2)2n/2 +2n.
For a traditional meet-in-the-middle attack, the outer loop of the main com-
putation simply looks up each result in a precomputed sorted table. Our notion
of “meet” is more complicated, and requires inspecting each element of the table,
but this is still a considerable speedup: each inspection is simply a dot product,
much faster than the vector-matrix multiplications used before.
We comment that taking ℓlogarithmic in n produces almost the same
speedup with polynomial memory consumption. More precisely, taking ℓclose
to 2 log2 n means that 2n−ℓis smaller than 2n by a factor roughly n2, so the
term (n −ℓ)(n + 2)2n−ℓis on the same scale as 2n. The table then contains
roughly n2 vectors, similar size to the original 2n matrices. Taking slightly larger
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
499
ℓreduces the term (n −ℓ)(n + 2)2n−ℓto a smaller scale. A similar choice of ℓ
becomes important for speed in our attack on obfuscations of general functions
in Section 8.2.
4.5. Combining the Ideas. One can easily reuse intermediate products in
the meet-in-the-middle attack. See Figure 4.6 of [13]. This reduces the precom-
putation to 2ℓ+1 −2 vector-matrix multiplications, i.e., (n + 2)(2ℓ+1 −2) dot
products mod q. It similarly reduces the outer loop of the main computation to
(n + 2)(2n−ℓ+1 −2) dot products mod q.
The total number of dot products mod q in the entire algorithm is now
(n + 2)(2ℓ+1 + 2n−ℓ+1 −4) + 2n. For example, for ℓ= n/2, the number of dot
products mod q simpliﬁes to 4(n + 2)(2n/2 −1) + 2n.
This is not much smaller than the meet-in-the-middle attack without reuse:
the dominant term is the same 2n. However, as above one can take much smaller
ℓto reduce memory consumption. The reuse now allows ℓto be taken almost as
small as log2 n without signiﬁcantly compromising speed, so the precomputed
table is now much smaller than the original 2n matrices.
If memory consumption is not a concern then one should compute both an L
table and an R table, interleaving the computations of the tables and obtaining
each LR product as soon as both L and R are known. For equal-size tables this
means computing L0, R0, L0R0, L1, L1R0, R1, L0R1, L1R1, etc. This order
of operations does not improve worst-case performance, but it does improve
average-case performance. The same improvement has been previously applied
to other meet-in-the-middle attacks: for example, Pollard applied this improve-
ment to Shanks’s “baby-step giant-step” discrete-logarithm method. Compare
[38, pages 419–420] to [36, page 439, top].
5
Parallelization
We implemented our attack for shared-memory systems using OpenMP and for
cluster systems using MPI. In general, brute-force attacks are embarrassingly
parallel, i.e., the search space can be distributed over the computing nodes with-
out any need for communication, resulting in a perfectly scalable parallelization.
However, for this attack, some computations are shared between consecutive iter-
ations. Therefore, some cooperation and communication are required between
computing nodes.
5.1. Precomputation. Recall that the precomputation step computes all 2ℓ
possible cases for the “left” ℓbits of the whole input space. A non-parallel
implementation ﬁrst computes ℓvector-matrix multiplications for sB1,0 · · · Bℓ,0
and stores the ﬁrst ℓ−1 intermediate products on a stack. As many intermediate
products as possible are reused for each subsequent case.
For a shared-memory system, all data can be shared between the threads.
Furthermore, the vector-matrix multiplications expose a suﬃcient amount of
parallelism such that the threads can cooperate on the computation of each
multiplication. There is some loss in parallel eﬃciency due to the need for syn-
chronization and work-share imbalance.

500
D.J. Bernstein et al.
For a cluster system, communication and synchronization of such a workload
distribution would be too expensive. Therefore, we split the input range for the
precomputation between the cluster nodes, compute each section of the precom-
puted table independently, and ﬁnally broadcast the table entries to all cluster
nodes. For simplicity, we split the input range evenly which results in some work-
load imbalance. (On each node, the workload is distributed as described above
over several threads to use all CPU cores on each node.) This procedure has some
loss in parallel eﬃciency due to the fact that each cluster node separately per-
forms k vector-matrix multiplications for the ﬁrst precomputation in its range,
due to some workload imbalance, and due to the ﬁnal all-to-all communication.
5.2. Main Computation. For simplicity, we start the main computation once
the whole precomputed table L is available. Recall that a non-parallel imple-
mentation of the main computation ﬁrst computes the vector R[0, . . . , 0] =
Bℓ+1,0 · · · Bn,0t using n −ℓmatrix-vector multiplications, and multiplies this
vector by all 2ℓtable entries. It then moves to other possibilities for the “right”
n−ℓbits, reusing intermediate products in a similar way to the precomputation
and multiplying each resulting vector R[. . .] by all 2ℓtable entries.
For a shared-memory system, the computations of R[. . .] are distributed
between the threads the same way as for the precomputation. However, vector-
vector multiplication does not expose as much parallelism as vector-matrix
multiplication. Therefore, we distribute over the threads the 2ℓindependent
vector-vector multiplications of each of the 2ℓtable entries with R[0, . . . , 0]. As
in the parallelization of precomputation, there is some loss of parallel eﬃciency
due to synchronization and work-share imbalance for the vector-matrix mul-
tiplications and some loss due to work-share imbalance for the vector-vector
multiplications.
For a cluster system we again cannot eﬃciently distribute the workload of one
vector-matrix multiplication over several cluster nodes. Therefore, we distribute
the search space evenly over the cluster nodes and let each cluster node compute
its share of the workload independently. This approach creates some redundant
work because each cluster node computes its own initial R[. . .] using n−ℓmatrix-
vector multiplications.
6
Performance Measurements
We used 22 PCs in the Saber cluster [12] for the attack. Each PC is of the type
described earlier, including an 8-core CPU. The PCs are connected by a gigabit
Ethernet network. Each PC also has two GK110 GPUs but we did not use these
GPUs.
6.1. First Break of the Challenge. We implemented the single-input opti-
mizations described in Section 3 and used 20 PCs to compute 214 point evalua-
tions for all possible inputs. This revealed the secret point 11000101100100 after
about 23 hours. The worst-case runtime for this approach on these 20 PCs is
about 52 hours for checking all 214 possible input points. On 18 October 2014
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
501
Table 6.4. Measurements of real time actually consumed by various components of
complete attack, starting from announcement of challenge
Attack component
Real time
Initial procrastination
a few days
First attempt to download challenge (failed)
82 minutes
Subsequent procrastination
40 days and 40 nights
Fourth attempt to download challenge (succeeded)
about an hour
Original program [6] evaluating one input
245 minutes
Original program evaluating all inputs on one computer (extrapolated) 7.6 years
Copying challenge to cluster (without UDP broadcasts)
about an hour
Reading challenge from disk into RAM
2.5 minutes
Our faster program evaluating one input
4.85 minutes
First successful break of challenge on 20 PCs
23 hours
Further procrastination (“this is fast enough”)
about half a week
Our faster program evaluating all inputs on 21 PCs
34 minutes
Second successful break of challenge on 21 PCs
19 minutes
Our current program evaluating all inputs on 1 PC
444.2 minutes
Our current program evaluating all inputs on 22 PCs
29.5 minutes
Time for an average input point on 22 PCs
19.9 minutes
Successful break of challenge on 22 PCs
17.5 minutes
we sent the authors of [5] the solution to the challenge, and a few hours later
they conﬁrmed that the solution was correct.
6.2. Second Break of the Challenge. We implemented the multiple-
input optimizations described in Section 4 and the parallelization described in
Section 5. Our optimized attack implementation found the input point in under
19 minutes on 21 PCs; this includes the time to precompute a table L of size 27.
The worst-case runtime of the attack for checking all 214 possible input points
is under 34 minutes on 21 PCs.
6.3. Additional Latency. Obviously “19 minutes” understates the real time
that elapsed between the announcement of the challenge (19 August 2014) and
our solution of the challenge with our second program (25 October 2014). See
Table 6.4 for a broader perspective.
The largest deterrent was the diﬃculty of downloading 25 gigabytes. When-
ever a connection broke, the server would insist on starting from the beginning
(“HTTP server doesn’t seem to support byte ranges”), presumably because the
server stores all ﬁles in a compressed format that does not support random
access. The same restriction also meant that we could not download diﬀerent
portions of the ﬁle in parallel.
To truly minimize latency we would have had to overlap the download of the
challenge, the broadcast of the challenge to the cluster, and the computation,
and of course our optimizations and software would have had to be ready ﬁrst.
In this context, the precompute-L-table algorithm in Section 4 has a latency

502
D.J. Bernstein et al.
advantage compared to a bit-reversed algorithm that precomputes an R table
instead of an L table: the portion of the input relevant to L is available sooner
than the portion of the input relevant to R.
6.5. Timings of Various Software Components. We have put the latest
version of our software online at http://obviouscation.cr.yp.to. We applied this
software to the same challenge on 22 PCs. We have applied the latest version of
our software to the same challenge on 22 PCs. The software took a total time of
1769 seconds (29.5 minutes) to check all 214 input points. An average input point
was checked within 1191 seconds (19.9 minutes). The secret challenge point was
found within 1048 seconds (17.5 minutes).
The rest of this section describes the time taken by various components of
this computation.
Each vector-matrix multiplication took 15.577 s on average (15.091 minimum,
16.421 maximum), using all eight cores jointly. For comparison, on a single core,
a vector-matrix multiplication requires about 115 s. Therefore, we achieve a par-
allel eﬃciency of
115s/8
15.577s ≈92% for parallel vector-matrix multiplication.
Each y computation took 8.986 s on average (7.975 minimum, 9.820 max-
imum), using a single core. Each y computation consists of one vector-vector
multiplication, one multiplication by pzt (which we could absorb into the pre-
computed table, producing a small speedup), and one reduction mod q.
On a single machine (no MPI parallelization), after a reboot to ﬂush the
challenge from RAM, the timing breaks down as follows:
1. Loading the matrices for “left” bit positions: 83.999 s.
2. Total precomputation of 27 = 128 table entries: 4055.408 s.
(a) Computing the ﬁrst ℓ= 7 vector-matrix products: 107.623 s.
4. Loading the matrices for “right” bit positions: 78.490 s.
5. Total computation of all 214 evaluations: 22518.900 s.
(a) Computing the ﬁrst n −ℓ= 7 matrix-vector products: 109.731 s.
Overall total runtime: 26654 s (444.2 minutes). From these computations, steps
1, 2a, 4, and 5a are not parallelized for cluster computation. The total timing
breakdown on 22 PCs, after a reboot of all PCs, is as follows:
1. Loading the matrices for “left” bit positions: 89.449 s average (75.786 on
the fastest node, 104.696 on the slowest node). With more eﬀort we could
have overlapped most of this loading (and the subsequent loading) with
computation, or skipped all disk copies by keeping the matrices in RAM.
2. Total precomputation of 27 = 128 table entries: 253.346 s average (217.893
minimum, 295.999 maximum).
(a) Computing the ﬁrst ℓ= 7 vector-matrix products: 107.951 s average
(107.173 minimum, 109.297 maximum).
3. All-to-all communication: 153.591 s average (100.848 minimum, 199.200
maximum); i.e., about 53 s average idle time for the busier nodes to catch
up, followed by about 101 s of communication. With more eﬀort we could
have overlapped most of this communication with computation.
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
503
4. Loading the matrices for “right” bit positions: 85.412 s average (73.710 min-
imum, 97.526 maximum).
5. Total computation of all 214 evaluations: 1097.680 s average (942.981 mini-
mum, 1169.520 maximum).
(a) Computing the ﬁrst n −ℓ= 7 matrix-vector products: 108.878 s average
(107.713 minimum, 110.001 maximum).
6. Final idle time waiting for all other nodes to ﬁnish computation: 80.277 s
average (0.076 minimum, 80.277 maximum).
Overall total runtime, including MPI startup overhead: 1769 s (29.5 minutes).
The overall parallel eﬃciency of the cluster parallelization thus is 26654 s/22
1769 s
≈
68%. Steps 1, 2a, 3, 4, and 5a, totaling 545.281 s, are those parts of the
computation that contain parallelization overhead (in particular the commu-
nication time in step 3 is added compared to the single-machine case). Remov-
ing these steps from the eﬃciency calculation results in a parallel eﬃciency of
(26654 s−380 s)/22
1769 s−545 s
≈98%, which shows that those steps are responsible for almost
all of the loss in parallel eﬃciency.
7
Further Speedups — see [13]
8
Generalizing the Attack Beyond Point Functions
This section looks beyond point functions: it considers the general obfuscation
method explained in [5] for any program. Recall from Section 2 that for general
programs the number of pairs of matrices, say u, is no longer tied to the number
n of input bits: usually each input bit is used multiple times. Furthermore, each
matrix is w × w and each vector has length w for some w > n, where the choice
of w depends on the function and is no longer required to be n + 2.
The speedups from Section 3 rely only on the general matrix-multiplication
structure, not on the pattern of accessing input bits. Reducing intermediate
results mod q saves a factor approximately u/2. Using vector-matrix multiplica-
tion rather than matrix-matrix multiplication saves a factor w.
However, the attacks from Section 4 rely on having each input bit used exactly
once. We cannot simply reorder the matrices to bring together the uses of an
input bit: matrix multiplication is not commutative. Usually many of the matri-
ces are obfuscated identity matrices, but the way the matrices are randomized
prevents these matrices from being removed or reordered; see [5] for details.
This section explains two attacks that apply in more generality. The ﬁrst
attack allows cycling through the input bits any number of times, and saves
a factor approximately n/2 compared to brute force. The second attack allows
using and reusing input bits any number of times in any pattern, and saves a
factor approximately n/(2 log2 w) compared to brute force. The ﬁrst attack is
what one might call a “meet-in-many-middles” attack; the second attack does not
involve precomputations. Both attacks exploit the idea of reusing intermediate
products, sharing computations between adjacent inputs; both attacks can be
parallelized by ideas similar to Section 5.

504
D.J. Bernstein et al.
8.1. Speedup n/2 for Cycling Through Input Bits. Our ﬁrst attack applies
to any circuit obfuscated as explained in [5, Section 2.2.1]. The obfuscated circuit
is constructed to “cycle through each of the input bits x1, x2, . . . , xn in order, m
times”, using u = mn pairs of matrices. In other words, y(x) is deﬁned as
s(B1,x[1] · · · Bn,x[n])(Bn+1,x[1] · · · B2n,x[n]) · · · (B(m−1)n+1,x[1] · · · Bmn,x[n])t.
Evaluating y(x) for one x from left to right takes mn vector-matrix multipli-
cations and 1 vector-vector multiplication, i.e., uw + 1 dot products mod q. A
straightforward brute-force attack thus takes (uw + 1)2n dot products mod q.
One can split the sequence of mn matrices at some position ℓ, and carry out
a meet-in-the-middle attack as in Section 4. However, this produces at most a
constant-factor speedup once m ≥2: either the precomputation has to compute
products at most of the positions for all 2n inputs, or the main computation
has to compute products at most of the positions for all 2n inputs, or both,
depending on ℓ.
We do better by splitting the sequence of input bits at some position ℓ. This
means grouping the matrix positions into two disjoint “left” and “right” sets as
follows, splitting each input cycle:
y(x) =

sB1,x[1] · · · Bℓ,x[ℓ]

Bℓ+1,x[ℓ+1] · · · Bn,x[n]


Bn+1,x[1] · · · Bn+ℓ,x[ℓ]

Bn+ℓ+1,x[ℓ+1] · · · B2n,x[n]

...

B(m−1)n+1,x[1] · · · B(m−1)n+ℓ,x[ℓ]

B(m−1)n+ℓ+1,x[ℓ+1] · · · Bmn,x[n]t

= L1[x[1], . . . , x[ℓ]]R1[x[ℓ+ 1], . . . , x[n]]
L2[x[1], . . . , x[ℓ]]R2[x[ℓ+ 1], . . . , x[n]]
...
Lm[x[1], . . . , x[ℓ]]Rm[x[ℓ+ 1], . . . , x[n]],
where
L1[x[1], . . . , x[ℓ]] = sB1,x[1] · · · Bℓ,x[ℓ],
Li[x[1], . . . , x[ℓ]] = B(i−1)n+1,x[1] · · · B(i−1)n+ℓ,x[ℓ]
for 2 ≤i ≤m,
Ri[x[ℓ+ 1], . . . , x[n]] = B(i−1)n+ℓ+1,x[ℓ+1] · · · Bin,x[n]
for 1 ≤i ≤m −1,
Rm[x[ℓ+ 1], . . . , x[n]] = B(m−1)n+ℓ+1,x[ℓ+1] · · · Bmn,x[n]t.
We exploit this grouping as follows. We use 2ℓ+1 −2 vector-matrix multiplica-
tions to precompute a table of the vectors L1[x[1], . . . , x[ℓ]] for all 2ℓchoices
of x[1], . . . , x[ℓ], as in Section 4. Similarly, for each i ∈{2, . . . , m}, we use
2ℓ+1 −4 matrix-matrix multiplications to precompute a table of the matri-
ces Li[x[1], . . . , x[ℓ]] for all 2ℓchoices of x[1], . . . , x[ℓ]. The tables use space for
(w + (m −1)w2)2ℓintegers mod q.
After this precomputation, the outer loop of the main computation runs
through each choice of x[ℓ+ 1], . . . , x[n], computing the corresponding matrices
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
505
R1[. . . ], . . . , Rm−1[. . . ] and vector Rm[. . . ]. The inner loop runs through each
choice of x[1], . . . , x[ℓ], computing each y(x) by multiplying L1, R1, . . . , Lm, Rm;
each x here takes 2m −2 vector-matrix multiplications and 1 vector-vector mul-
tiplication.
Overall the precomputation costs ((m −1)w2 + w)(2ℓ+1 −2) −2(m −1)w2
dot products mod q; the outer loop of the main computation costs ((m−1)w2 +
w)(2n−ℓ+1 −2) −2(m −1)w2 dot products mod q; and the inner loop costs
((2m −2)w + 1)2n dot products mod q.
In particular, taking ℓ= n/2 (assuming as before that n is even) simpliﬁes
the total cost to 4w(2n/2 −1) + 2n for m = 1, exactly as in Section 4, and
4w((m −1)w + 1)(2n/2 −1) + ((2m −2)w + 1)2n −4(m −1)w2 for general m.
Recall that brute force costs (uw+1)2n = (mnw+1)2n. For large n, large w, and
m ≥2, the asymptotically dominant term has dropped from mnw2n to 2mw2n,
saving a factor of n/2.
The same asymptotic savings appears with much smaller ℓ, almost as small
as log2 w. Beware that this does not make the tables asymptotically smaller than
the original 2mn matrices for m ≥2: most of the table space here is consumed
by matrices rather than vectors.
8.2. Speedup n/ log2 w for any Order of Input Bits. One can try to spoil
the above attack by changing the order of input bits. A slightly diﬀerent order
of input bits, rotating positions in each round, is already stated in [4, Section 3,
Claim 2, ﬁnal formula], but it is easy to adapt the attack to this order. It is
more diﬃcult to adapt the attack to an order chosen randomly, or an order that
combinatorially avoids keeping bits together. Varying the input order is not a
new idea: see, e.g., the compression functions inside MD5 [37] and BLAKE [10].
Many other orders of input bits also arise naturally in “keyed” functions; see
Section 2.
The general picture is that y(x) is deﬁned by the formula
y(x) = sB1,x[inp(1)]B2,x[inp(2)] · · · Bu,x[inp(u)]t
for some constants inp(1), inp(2), . . . , inp(u) ∈{1, 2, . . . , n}. As a ﬁrst uniﬁcation
we multiply s into B1,0 and into B1,1, and then multiply t into Bu,0 and into Bu,1.
Now B1,0, B1,1, Bu,0, Bu,1 are vectors, except that they are integers if u = 1; and
y(x) is deﬁned by
y(x) = B1,x[inp(1)]B2,x[inp(2)] · · · Bu,x[inp(u)].
We now explain a general recursive strategy to evaluate this formula for all
inputs without exploiting any particular pattern in inp(1), inp(2), . . . , inp(u).
The strategy is reducing the number of variable bits in x by one in each iteration.
Assume that not all of inp(1), inp(2), . . . , inp(u) are equal to n. Substitute
x[n] = 0 into the formula for y(x). This means, for each i with inp(i) = n in
turn, eliminating the expression “Bi,x[n]” as follows:
• multiply Bi,0 into Bi+1,0 and into Bi+1,1 if i < u;
• multiply Bi,0 into Bi−1,0 and into Bi−1,1 if i = u;

506
D.J. Bernstein et al.
• set Bi ←Bi+1, then Bi+1 ←Bi+2, . . . , then Bu−1 ←Bu;
• reduce u to u −1.
Recursively evaluate the resulting formula for all choices of x[1], . . . , x[n −1].
Then do all the same steps again with x[n] = 1 instead of x[n] = 0.
More generally, one can recurse on the two choices of x[b] for any b. It is
most eﬃcient to recurse on the most frequently used index b (or one of the most
frequent indices b if there are several), since this minimizes the length of the
formula to handle recursively. This is equivalent to ﬁrst relabeling the indices so
that they are in nondecreasing order of frequency, and then always recursing on
the last bit.
Once n is suﬃciently small (see below), stop the recursion. This means sep-
arately enumerating all possibilities for (x[1], . . . , x[n]) and, for each possibility,
evaluating the given formula
y(x) = B1,x[inp(1)]B2,x[inp(2)] · · · Bu,x[inp(u)]
by multiplication from left to right. Recall that B1,x[inp(1)] is actually a vector
(or an integer if u = 1). Each computation takes u −1 vector-matrix multiplica-
tions, i.e., (u −1)w dot products mod q. (Here we ignore the extra speed of the
ﬁnal vector-vector multiplication.) The total across all inputs is (u −1)w2n dot
products mod q.
To see that the recursion reduces this complexity, consider the impact of
using exactly one level of recursion, from n down to n −1. If index n is used
un times then eliminating each Bi,x[n] costs 2un matrix multiplications, and
produces a formula of length u −un instead of u, so each recursive call uses
(u −un −1)w2n−1 dot products mod q. The bound on the total number of dot
products mod q drops from (u −1)w2n to 4unw2 + (u −un −1)w2n, saving
unw2n −4unw2. This analysis suggests stopping the recursion when 2n drops
below 4w, i.e., at n = ⌈log2 w⌉+ 1.
More generally, the algorithm costs a total of 4unw2+8un−1w2+16un−2w2+
· · · + 2n−ℓ+1uℓ+1w2 + 2n(uℓ+ · · · + u1 −1)w dot products mod q if the recursion
stops at level ℓ. We relabel as explained above so that un ≥un−1 ≥· · · ≥
u1, and assume n > ℓ. The sum uℓ+ · · · + u1 is at most ℓu/n, and the sum
un + 2un−1 + 4un−2 + · · · + 2n−ℓ−1uℓ+1 is at most 2n−ℓu/(n −ℓ), for a total of
less than (4w2−ℓ/(n −ℓ) + ℓ/n)uw2n. Taking ℓ= ⌈log2 w⌉+ 1 reduces this total
to at most (4/(n −⌈log2 w⌉−1) + (⌈log2 w⌉+ 1)/n)uw2n.
For comparison, a brute-force attack against the original problem (separately
evaluating y(x) for each x) costs (u −1)w2n. We have thus saved a factor of
approximately n/ log2 w.
References
[4] Ananth, P., Gupta, D., Ishai, Y., Sahai, A.: Optimizing obfuscation: avoiding
Barrington’s theorem. In: ACM-CCS 2014 (2014). https://eprint.iacr.org/2014/
222
www.ebook3000.com

Bad Directions in Cryptographic Hash Functions
507
[5] Apon, D., Huang, Y., Katz, J., Malozemoﬀ, A.J.: Implementing cryptographic
program obfuscation, version 20141005 (2014). https://eprint.iacr.org/2014/779
[6] Apon, D., Huang, Y., Katz, J., Malozemoﬀ, A.J.: Implementing cryptographic
program obfuscation (software) (2014). https://github.com/amaloz/obfuscation
[7] Apon, D., Huang, Y., Katz, J., Malozemoﬀ, A.J.: Implementing cryptographic
program obfuscation (slides). In: Crypto 2014 Rump Session (2014). http://crypto.
2014.rump.cr.yp.to/bca480a4e7fcdaf5bfa9dec75ﬀ890c8.pdf
[8] Apon,
D.,
Huang,
Y.,
Katz,
J.,
Malozemoﬀ,
A.J.:
Implementing
crypto-
graphic program obfuscation (video). In: Crypto 2014 Rump Session, start-
ing at 3:56:25 (2014). https://gauchocast.ucsb.edu/Panopto/Pages/Viewer.aspx?
id=d34af80d-bdb5-464b-a8ac-2c3adefc5194
[10] Aumasson, J.-P., Henzen, L., Meier, W., Phan, R.C.-W.: SHA-3 proposal BLAKE
(version 1.3) (2010). https://www.131002.net/blake/blake.pdf
[11] Bernstein, D.J.: Fast multiplication and its applications, in Surveys in algorithmic
number theory, pp. 325–384. Cambridge University Press (2008)
[12] Bernstein, D.J.: The Saber cluster (2014). http://blog.cr.yp.to/20140602-saber.
html
[13] Bernstein, D.J., H¨ulsing, A., Lange, T., Niederhagen, R.: Bad directions in cryp-
tographic hash functions (2015). https://eprint.iacr.org/2015/151
[14] Bogdanov, A., Khovratovich, D., Rechberger, C.: Biclique cryptanalysis of the
full AES. In: Lee, D.H., Wang, X. (eds.) ASIACRYPT 2011. LNCS, vol. 7073, pp.
344–371. Springer, Heidelberg (2011)
[20] Cheon, J.H., Han, K., Lee, C., Ryu, H., Stehl´e, D.: Cryptanalysis of the mul-
tilinear map over the integers. In: Oswald, E., Fischlin, M. (eds.) EURO-
CRYPT
2015.
LNCS,
vol.
9056,
pp.
3–12.
Springer,
Heidelberg
(2015).
https://eprint.iacr.org/2014/906
[21] Contini, S., Lenstra, A.K., Steinfeld, R.: VSH, an eﬃcient and provable collision-
resistant hash function. In: Vaudenay, S. (ed.) EUROCRYPT 2006. LNCS, vol.
4004, pp. 165–182. Springer, Heidelberg (2006)
[23] Coron, J.-S., Lepoint, T., Tibouchi, M.: Practical multilinear maps over the inte-
gers. In: Canetti, R., Garay, J.A. (eds.) CRYPTO 2013, Part I. LNCS, vol. 8042,
pp. 476–493. Springer, Heidelberg (2013)
[24] Garﬁnkel, S., Spaﬀord, G., Schwartz, A.: Practical UNIX & Internet security, 3rd
edn. O’Reilly (2003)
[25] Garg, S., Gentry, C., Halevi, S.: Candidate multilinear maps from ideal lattices.
In: Johansson, T., Nguyen, P.Q. (eds.) EUROCRYPT 2013. LNCS, vol. 7881, pp.
1–17. Springer, Heidelberg (2013)
[26] Garg, S., Gentry, C., Halevi, S., Raykova, M., Sahai, A., Waters, B.: Candi-
date indistinguishability obfuscation and functional encryption for all circuits.
In: FOCS 2013, pp. 40–49 (2013)
[27] Gentry, C., Halevi, S., Maji, H.K., Sahai, A.: Zeroizing without zeroes: Cryptana-
lyzing multilinear maps without encodings of zero (2014). https://eprint.iacr.org/
2014/929
[28] Goldwasser, S., Rothblum, G.N.: On best-possible obfuscation. Journal of Cryp-
tology 27, 480–505 (2014)
[30] Khovratovich, D., Rechberger, C., Savelieva, A.: Bicliques for preimages: attacks
on Skein-512 and the SHA-2 family. In: Canteaut, A. (ed.) FSE 2012. LNCS, vol.
7549, pp. 244–263. Springer, Heidelberg (2012)
[34] Lynn, B.Y.S., Prabhakaran, M., Sahai, A.: Positive Results and Techniques for
Obfuscation. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT 2004. LNCS,
vol. 3027, pp. 20–39. Springer, Heidelberg (2004)

508
D.J. Bernstein et al.
[35] Osvik,
D.A.,
Tromer,
E.:
Cryptologic
applications
of
the
PlayStation
3:
Cell SPEED, SPEED (2007). https://hyperelliptic.org/SPEED/slides/Osvik
cell-speed.pdf
[36] Pollard, J.M.: Kangaroos, Monopoly and discrete logarithms. Journal of Cryptol-
ogy 13, 437–447 (2000)
[37] Rivest, R.L.: The MD5 message-digest algorithm. RFC 1321 (1992). https://tools.
ietf.org/html/rfc1321
[38] Shanks, D.: Class number, a theory of factorization, and genera. In: Proceedings
of Symposia in Pure Mathematics, vol. 20, pp. 415–440. AMS (1971)
www.ebook3000.com

Author Index
Agrawal, Megha
451
Alissa, Khalid
307
Anslow, Craig
289
Avoine, Gildas
356
Bansal, Tarun Kumar
93
Bernstein, Daniel J.
488
Bose, Priyanka
230
Bourgeois, Adrien
356
Carpent, Xavier
356
Chang, Donghoon
93, 451
Chen, Rongmao
59
Das, Dipanjan
230
Datta, Nilanjan
433
Dawson, Ed
307
Dowling, Benjamin
270
Egert, Rolf
413
Emura, Keita
77
Feng, Yiteng
377
Fischlin, Marc
413
Gens, David
413
Ghosh, Shamit
343
Gritti, Clémentine
395
Günther, Felix
195
Guo, Fuchun
59, 160
Hanaoka, Goichiro
77
Hao, Ronglin
20
Huang, Guifang
251
Hülsing, Andreas
488
Ishida, Yuu
174
Ito, Ryoma
329
Jacob, Sven
413
Kogure, Jun
471
Koshiba, Takeshi
471
Kurosawa, Kaoru
145
Lai, Jianchang
160
Lange, Tanja
488
Li, Bao
20
Li, Hongda
251
Li, Xiaoqian
20
Liu, Joseph K.
377
Ma, Bingke
20
Marshall, Stuart
289
Miyaji, Atsuko
329
Mu, Yi
59, 160, 377
Negre, Christophe
107
Niederhagen, Ruben
488
Ohta, Kazuo
77
Pandu Rangan, Chandrasekharan
230
Perin, Guilherme
107
Phong, Le Trieu
145
Plantard, Thomas
395
Poettering, Bertram
195
Reid, Jason
307
Roy Chowdhury, Dipanwita
343
Saha, Dhiman
343
Sakai, Yusuke
77
Salim, Farzad
307
Sanadhya, Somitra Kumar
93, 451
Schuldt, Jacob C.N.
77
Sengupta, Abhrajit
343
Senker, Matthias
413
Shikata, Junji
174
Shimoyama, Takeshi
471
Stebila, Douglas
270
Sun, Zhelei
3
Susilo, Willy
160, 395
Tanaka, Keisuke
213
Tang, Qiang
127

Tao, Biaoshuai
39
Tillmanns, Jörn
413
Trethowen, Leliel
289
Wang, Peng
3
Wang, Xiaofen
59
Wang, Yuyu
213
Watanabe, Yohei
174
Welch, Ian
289
Wu, Hongjun
39
Yang, Guomin
59, 377
Yasuda, Kan
433
Yasuda, Masaya
471
Yokoyama, Kazuhiro
471
Zhang, Liting
3
Zhang, Tingting
251
510
Author Index
www.ebook3000.com

