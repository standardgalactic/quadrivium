Turing 
Computability
Robert I. Soare
Theory and Applications

 More information about this series at http://www.springer.com/series/8819
Theory and Applications of Computability
In cooperation with the association Computability in Europe
Series Editors 
Prof. P. Bonizzoni  
Università degli Studi di Milano-Bicocca 
Dipartimento di Informatica Sistemistica e Comunicazione (DISCo)  
Milan 
Italy  
bonizzoni@disco.unimib.it  
 
Prof. V. Brattka  
Universit  der Bundeswehr München
vasco.brattka@unibw.de
 
 
Prof. P. Panangaden
ät
Fakultät für Informatik
Neubiberg
Germany
Prof. E. Mayordomo  
Universidad de Zaragoza 
Departamento de Informática e Ingeniería de Sistemas  
Zaragoza 
Spain 
elvira@unizar.es  
McGill University
School of Computer Science
Montr al
é
prakash@cs.mcgill.ca
Canada
Founding Editors: P. Bonizzoni, V. Brattka, S.B. Cooper, E. Mayordomo 

  
Books published in this series will be of interest to the research community and 
graduate students, with a unique focus on issues of computability. The perspective 
of the series is multidisciplinary, recapturing the spirit of Turing by linking theoretical 
and real-world concerns from computer science, mathematics, biology, physics, 
and the philosophy of science. 
 
The series includes research monographs, advanced and graduate texts, and books 
that offer an original and informative view of computability and computational 
paradigms. 
 
Series Advisory Board  
 
Samson Abramsky, University of Oxford 
Eric Allender  Rutgers, The State University of New Jersey 
Klaus Ambos-Spies, Universität Heidelberg 
Jeremy Avigad, Carnegie Mellon University 
Samuel R. Buss, University of California, San Diego 
Rodney G. Downey, Victoria University of Wellington 
Sergei S. Goncharov, Novosibirsk State University 
Peter Jeavons, University of Oxford 
Nataša Jonoska, University of South Florida, Tampa 
Ulrich Kohlenbach, Technische Universität Darmstadt 
Ming Li, University of Waterloo 
Wolfgang Maass, Technische Universität Graz 
Grzegorz Rozenberg, Leiden University and University of Colorado, Boulder 
Alan Selman, University at Buffalo, The State University of New York 
Wilfried Sieg, Carnegie Mellon University 
Jan van Leeuwen, Universiteit Utrecht 
Klaus Weihrauch, FernUniversität Hagen 
Philip Welch, University of Bristol 
 
 
 
Giorgio Ausiello, Università di Roma, “La Sapienza” 
,

Robert I. Soare 
Theory and Applications
Turing Computability

Robert I. Soare 
Department of Mathematics 
The University of Chicago 
Chicago, Illinois, USA 
03Dxx (Computability and recursion theory). 
 
ISSN 2190-619X 
ISSN  2190-6203  (electronic)  
Theory and Applications of Computability 
ISBN 978-3-642-31932-7 
ISBN 978-3-642-31933-4 (eBook) 
DOI 10.1007/978-3-642-31933-4 
 
Library of Congress Control Number: 
 
© Springer-Verlag Berlin Heidelberg 2016 
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part 
of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, 
recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission 
or information storage and retrieval, electronic adaptation, computer software, or by similar or 
dissimilar methodology now known or hereafter developed.  
The use of general descriptive names, registered names, trademarks, service marks, etc. in this 
publication does not imply, even in the absence of a specific statement, that such names are exempt 
from the relevant protective laws and regulations and therefore free for general use.  
The publisher, the authors and the editors are safe to assume that the advice and information in this 
book are believed to be true and accurate at the date of publication. Neither the publisher nor the 
authors or the editors give a warranty, express or implied, with respect to the material contained 
herein or for any errors or omissions that may have been made. 
 
Cover illustration: Damir Dzhafarov designed the image of the Turing machine used in the book 
cover. 
 
Printed on acid-free paper 
 
This Springer imprint is published by Springer Nature 
The registered company is Springer-Verlag GmbH Berlin Heidelberg 
2016944469

I dedicate this book to my wife, Pegeen.


Contents
I
Foundations of Computability
1
1
Deﬁning Computability
3
1.1
Algorithmically Computable Functions . . . . . . . . . .
3
1.1.1
Algorithms in Mathematics
. . . . . . . . . . . .
3
1.1.2
The Obstacle of Diagonalization and Partial Func-
tions . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.1.3
The Quest for a Characterization . . . . . . . . .
5
1.1.4
Turing’s Breakthrough . . . . . . . . . . . . . . .
5
1.2
⋆⋆Turing Deﬁnes Eﬀectively Calculable . . . . . . . . .
6
1.3
⋆⋆Turing’s Thesis, Turing’s Theorem, TT . . . . . . . .
7
1.4
⋆⋆Turing Machines . . . . . . . . . . . . . . . . . . . . .
7
1.4.1
Exercises on Turing Machines . . . . . . . . . . .
9
1.5
⋆⋆The Basic Results . . . . . . . . . . . . . . . . . . . .
10
1.5.1
Numbering Turing Programs Pe . . . . . . . . . .
10
1.5.2
Numbering Turing Computations . . . . . . . . .
10
1.5.3
The Enumeration Theorem and Universal Machine
11
1.5.4
The Parameter Theorem or s-m-n Theorem . . .
12
1.6
⋆⋆Unsolvable Problems
. . . . . . . . . . . . . . . . . .
13
1.6.1
Computably Enumerable Sets . . . . . . . . . . .
13
1.6.2
Noncomputable C.E. Sets
. . . . . . . . . . . . .
13
1.6.3
The Index Set Theorem and Rice’s Theorem . . .
16
1.6.4
Computable Approximations to Computations . .
17
vii 

viii
Contents
1.6.5
Exercises . . . . . . . . . . . . . . . . . . . . . . .
18
1.7
⋆Computable Permutations and Isomorphisms . . . . .
19
1.7.1
Myhill Isomorphism Theorem . . . . . . . . . . .
20
1.7.2
Acceptable Numberings
. . . . . . . . . . . . . .
21
1.7.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
21
2
Computably Enumerable Sets
23
2.1
⋆⋆Characterizations of C.E. Sets . . . . . . . . . . . . .
23
2.1.1
The Σ0
1 Normal Form for C.E. Sets . . . . . . . .
23
2.1.2
The Uniformization Theorem
. . . . . . . . . . .
25
2.1.3
The Listing Theorem for C.E. Sets
. . . . . . . .
26
2.1.4
The C.E. and Computable Sets as Lattices . . . .
26
2.1.5
Exercises . . . . . . . . . . . . . . . . . . . . . . .
27
2.2
⋆Recursion Theorem (Fixed Point Theorem) . . . . . .
28
2.2.1
Fixed Points in Mathematics . . . . . . . . . . . .
28
2.2.2
Operating on Indices . . . . . . . . . . . . . . . .
28
2.2.3
⋆⋆A Direct Proof of the Recursion Theorem . . .
29
2.2.4
A Diagonal Argument Which Fails
. . . . . . . .
29
2.2.5
Informal Applications of the Recursion Theorem .
31
2.2.6
Other Properties of the Recursion Theorem
. . .
31
2.2.7
Exercises . . . . . . . . . . . . . . . . . . . . . . .
32
2.3
Indexing Finite and Computable Sets . . . . . . . . . . .
33
2.3.1
Computable Sets and ∆0 and ∆1 Indices . . . . .
33
2.3.2
Canonical Index y for Finite Set Dy and String σy
34
2.3.3
Acceptable Numberings of Partial Computable Func-
tions . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.3.4
Exercises . . . . . . . . . . . . . . . . . . . . . . .
37
2.4
⋆Complete Sets and Creative Sets . . . . . . . . . . . .
38
2.4.1
Productive Sets . . . . . . . . . . . . . . . . . . .
38
2.4.2
⋆⋆Creative Sets Are Complete . . . . . . . . . .
39
2.4.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
40
2.5
⋆⋆Elementary Lachlan Games
. . . . . . . . . . . . . .
43
2.5.1
The Deﬁnition of a Lachlan Game . . . . . . . . .
43
2.5.2
Playing Partial Computable (P.C.) Functions
. .
44
2.5.3
Some Easy Examples of Lachlan Games
. . . . .
44
2.5.4
Practicing Lachlan Games . . . . . . . . . . . . .
45
2.5.5
The Signiﬁcance of Lachlan Games . . . . . . . .
45
2.5.6
Exercises on Lachlan Games . . . . . . . . . . . .
45
2.6
⊘The Order of Enumeration of C.E. Sets . . . . . . . .
46
2.6.1
Uniform Sequences and Simultaneous Enumerations
46
2.6.2
Static and Dynamic Properties of C.E. Sets
. . .
47
2.6.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
48
2.7
⊘The Friedberg Splitting Theorem . . . . . . . . . . . .
49
2.7.1
The Priority Ordering of Requirements . . . . . .
49
2.7.2
Exercises . . . . . . . . . . . . . . . . . . . . . . .
50

Contents
ix
3
Turing Reducibility
51
3.1
The Concept of Relative Computability . . . . . . . . . .
51
3.1.1
Turing Suggests Oracle Machines (o-Machines)
.
51
3.1.2
Post Develops Relative Computability
. . . . . .
51
3.2
⋆⋆Turing Computability . . . . . . . . . . . . . . . . . .
52
3.2.1
An o-Machine Model for Relative Computability
52
3.2.2
Turing Computable Functionals Φe . . . . . . . .
53
3.3
⋆Oracle Graphs of Turing Functional Φe
. . . . . . . .
54
3.3.1
The Preﬁx-Free Graph Fe of Functional Φe
. . .
54
3.3.2
The Oracle Graph Ge of Functional Φe . . . . . .
56
3.3.3
The Use Principle for Turing Functionals . . . . .
57
3.3.4
Permitting Constructions . . . . . . . . . . . . . .
57
3.3.5
Lachlan Notation for Approximation by Stages
.
57
3.3.6
Standard Theorems Relativized to A . . . . . . .
58
3.3.7
Exercises . . . . . . . . . . . . . . . . . . . . . . .
59
3.4
⋆Turing Degrees and the Jump Operator . . . . . . . .
60
3.4.1
The Structure of the Turing Degrees
. . . . . . .
60
3.4.2
The Jump Theorem . . . . . . . . . . . . . . . . .
61
3.4.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
62
3.5
⋆Limit Computable Sets and Domination . . . . . . . .
63
3.5.1
Domination and Quantiﬁers (∀∞x) and (∃∞x)
.
64
3.5.2
Uniformly Computable Sequences . . . . . . . . .
64
3.5.3
Limit Computable Sets . . . . . . . . . . . . . . .
65
3.5.4
Exercises . . . . . . . . . . . . . . . . . . . . . . .
66
3.6
⋆⋆The Limit Lemma . . . . . . . . . . . . . . . . . . . .
66
3.6.1
The Modulus Lemma for C.E. Sets . . . . . . . .
68
3.6.2
The Ovals of Σ1 and ∆2 Degrees
. . . . . . . . .
69
3.6.3
Reaching With the Jump: Low and High Sets . .
69
3.6.4
Exercises . . . . . . . . . . . . . . . . . . . . . . .
70
3.7
⋆Trees and the Low Basis Theorem
. . . . . . . . . . .
71
3.7.1
Notation for Trees . . . . . . . . . . . . . . . . . .
71
3.7.2
⋆The Low Basis Theorem for Π0
1 Classes
. . . .
71
3.7.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
72
3.8
Bounded Reducibilities and n-C.E. Sets . . . . . . . . . .
73
3.8.1
A Matrix Mx for Bounded Reducibilities . . . . .
73
3.8.2
Bounded Turing Reducibility
. . . . . . . . . . .
73
3.8.3
Truth-Table Reductions
. . . . . . . . . . . . . .
74
3.8.4
Diﬀerence of C.E., n-c.e., and ω-c.e. Sets . . . . .
75
3.8.5
Exercises . . . . . . . . . . . . . . . . . . . . . . .
77
4
The Arithmetical Hierarchy
79
4.1
Levels in the Arithmetical Hierarchy
. . . . . . . . . . .
79
4.1.1
Quantiﬁer Manipulation . . . . . . . . . . . . . .
80
4.1.2
Placing a Set in Σn or Πn
. . . . . . . . . . . . .
82
4.1.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
83

x
Contents
4.2
⋆⋆Post’s Theorem and the Hierarchy Theorem . . . . .
83
4.2.1
Post’s Theorem Relating Σn to ∅(n) . . . . . . .
84
4.2.2
Exercises . . . . . . . . . . . . . . . . . . . . . . .
85
4.3
⋆Σn-Complete Sets and Πn-Complete Sets
. . . . . . .
86
4.3.1
Classifying Σ2 and Π2 Sets: Fin, Inf, and Tot
. .
86
4.3.2
Constructions with Movable Markers . . . . . . .
87
4.3.3
Classifying Cof as Σ3-Complete . . . . . . . . . .
87
4.3.4
Classifying Rec as Σ3-Complete . . . . . . . . . .
88
4.3.5
Σ3-Representation Theorems . . . . . . . . . . . .
89
4.3.6
Exercises . . . . . . . . . . . . . . . . . . . . . . .
91
4.4
Relativized Hierarchy: Lown and Highn Sets . . . . . . .
91
4.4.1
Relativized Post’s Theorem
. . . . . . . . . . . .
92
4.4.2
Lown and Highn Sets . . . . . . . . . . . . . . . .
92
4.4.3
Common Jump Classes of Degrees . . . . . . . . .
93
4.4.4
Syntactic Properties of Highn and Lown Sets
. .
93
4.4.5
Exercises . . . . . . . . . . . . . . . . . . . . . . .
94
4.5
⋆Domination and Escaping Domination . . . . . . . . .
94
4.5.1
Domination Properties . . . . . . . . . . . . . . .
95
4.5.2
Martin’s High Domination Theorem . . . . . . . .
96
4.5.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
97
4.6
Characterizing Nonlow2 Sets A ≤T ∅′
. . . . . . . . . .
98
4.6.1
Exercises . . . . . . . . . . . . . . . . . . . . . . .
98
4.7
Domination, Escape, and Classes of Degrees . . . . . . .
99
4.8
Uniform Enumerations of Functions and Sets . . . . . . .
99
4.8.1
Limits of Functions . . . . . . . . . . . . . . . . .
100
4.8.2
A-uniform Enumeration of the Computable Func-
tions . . . . . . . . . . . . . . . . . . . . . . . . .
100
4.9
⊘Characterizing Low2 Sets A ≤T ∅′ . . . . . . . . . . .
102
4.9.1
Exercises . . . . . . . . . . . . . . . . . . . . . . .
103
5
Classifying C.E. Sets
107
5.1
⋆Degrees of Computably Enumerable Sets
. . . . . . .
107
5.1.1
Post’s Problem and Post’s Program . . . . . . . .
107
5.1.2
Dynamic Turing Reductions on C.E. Sets . . . . .
108
5.2
⋆Simple Sets and the Permitting Method . . . . . . . .
108
5.2.1
Post’s Simple Set Construction
. . . . . . . . . .
109
5.2.2
The Canonical Simple Set Construction
. . . . .
110
5.2.3
Domination and a Complete Simple Set
. . . . .
111
5.2.4
Simple Permitting and Simple Sets . . . . . . . .
111
5.2.5
Permitting as a Game
. . . . . . . . . . . . . . .
112
5.2.6
Exercises . . . . . . . . . . . . . . . . . . . . . . .
113
5.3
⋆Hypersimple Sets and Dominating Functions
. . . . .
113
5.3.1
Weak and Strong Arrays of Finite Sets . . . . . .
113
5.3.2
Dominating Functions and Hyperimmune Sets . .
114
5.3.3
Degrees of Hypersimple Sets and Dekker’s Theorem
115

Contents
xi
5.3.4
Exercises . . . . . . . . . . . . . . . . . . . . . . .
116
5.4
⋆The Arslanov Completeness Criterion
. . . . . . . . .
117
5.4.1
Eﬀectively Simple Sets Are Complete . . . . . . .
117
5.4.2
Arslanov’s Completeness Criterion for C.E. Sets .
118
5.4.3
Exercises . . . . . . . . . . . . . . . . . . . . . . .
119
5.5
⊘More General Permitting
. . . . . . . . . . . . . . . .
122
5.5.1
Standard and General Permitting . . . . . . . . .
122
5.5.2
Reverse Permitting . . . . . . . . . . . . . . . . .
123
5.5.3
Building a Turing Functional
ΘC = A . . . . . .
123
5.6
⊘Hyperimmune-Free Degrees . . . . . . . . . . . . . . .
124
5.6.1
Two Downward Closure Properties of Domination
124
5.6.2
∆2 Degrees Are Hyperimmune . . . . . . . . . . .
125
5.6.3
Σ2 Approximations and Domination
. . . . . . .
127
5.7
Historical Remarks and Research References . . . . . . .
127
5.7.1
⊘
∆2-Permitting . . . . . . . . . . . . . . . . .
128
6
Oracle Constructions and Forcing
131
6.1
⋆Kleene-Post Finite Extensions . . . . . . . . . . . . . .
131
6.1.1
Exercises . . . . . . . . . . . . . . . . . . . . . . .
133
6.2
Minimal Pairs and Avoiding Cones
. . . . . . . . . . . .
134
6.2.1
Exercises . . . . . . . . . . . . . . . . . . . . . . .
136
6.3
⋆Generic Sets . . . . . . . . . . . . . . . . . . . . . . . .
137
6.3.1
1-Generic Sets . . . . . . . . . . . . . . . . . . . .
137
6.3.2
Forcing the Jump . . . . . . . . . . . . . . . . . .
137
6.3.3
Doing Many Constructions at Once . . . . . . . .
138
6.3.4
Exercises . . . . . . . . . . . . . . . . . . . . . . .
138
6.4
⋆Inverting the Jump . . . . . . . . . . . . . . . . . . . .
139
6.4.1
Exercises . . . . . . . . . . . . . . . . . . . . . . .
141
6.5
Upper and Lower Bounds for Degrees . . . . . . . . . . .
141
6.5.1
Exercises . . . . . . . . . . . . . . . . . . . . . . .
144
7
The Finite Injury Method
147
7.1
A Solution to Post’s Problem
. . . . . . . . . . . . . . .
147
7.1.1
The Intuition Behind Finite Injury . . . . . . . .
147
7.1.2
The Injury Set for Requirement Ne . . . . . . . .
148
7.2
⋆Low Simple Sets
. . . . . . . . . . . . . . . . . . . . .
149
7.2.1
The Requirements for a Low Simple Set A . . . .
149
7.2.2
A Computable[
g(e, s) with g(e) = lims[
g(e, s) =
A′(e) . . . . . . . . . . . . . . . . . . . . . . . . .
150
7.2.3
The Construction of a Low Simple Set A . . . . .
150
7.2.4
The Veriﬁcation of a Low Simple Set A . . . . . .
151
7.2.5
The Restraint Functions r(e, s) as Walls
. . . . .
151
7.2.6
Exercises . . . . . . . . . . . . . . . . . . . . . . .
152
7.3
⋆The Friedberg-Muchnik Theorem . . . . . . . . . . . .
152
7.3.1
Renumbering the Requirements . . . . . . . . . .
152

xii
Contents
7.3.2
The Basic Module to Meet Re for e Even . . . . .
153
7.3.3
The Full Construction
. . . . . . . . . . . . . . .
153
7.3.4
The Veriﬁcation . . . . . . . . . . . . . . . . . . .
154
7.3.5
Exercises . . . . . . . . . . . . . . . . . . . . . . .
154
7.4
⋆Preservation Strategy to Avoid Upper Cones
. . . . .
156
7.4.1
The Notation
. . . . . . . . . . . . . . . . . . . .
156
7.4.2
The Basic Module for Requirement Ne . . . . . .
156
7.4.3
The Construction of A . . . . . . . . . . . . . . .
158
7.4.4
The Veriﬁcation . . . . . . . . . . . . . . . . . . .
158
7.5
Sacks Splitting Theorem . . . . . . . . . . . . . . . . . .
158
7.6
Avoiding the Cone Above a ∆2 Set C >T 0
. . . . . . .
161
7.6.1
Exercises . . . . . . . . . . . . . . . . . . . . . . .
161
II
Trees and Π0
1 Classes
163
8
Open and Closed Classes
165
8.1
Open Classes in Cantor Space . . . . . . . . . . . . . . .
165
8.2
Closed Classes in Cantor Space
. . . . . . . . . . . . . .
166
8.3
The Compactness Theorem . . . . . . . . . . . . . . . . .
168
8.4
Notation for Trees . . . . . . . . . . . . . . . . . . . . . .
168
8.5
Eﬀective Compactness Theorem . . . . . . . . . . . . . .
169
8.6
Dense Open Subsets of Cantor Space . . . . . . . . . . .
170
8.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
171
9
Basis Theorems
175
9.1
Bases and Nonbases for Π0
1-Classes
. . . . . . . . . . . .
175
9.2
Previous Basis Theorems for Π0
1-Classes
. . . . . . . . .
176
9.3
Nonbasis Theorems for Π0
1-Classes . . . . . . . . . . . . .
176
9.4
The Super Low Basis Theorem (SLBT) . . . . . . . . . .
177
9.5
The Computably Dominated Basis Theorem . . . . . . .
178
9.6
Low Antibasis Theorem . . . . . . . . . . . . . . . . . . .
179
9.7
Proper Lown Basis Theorem . . . . . . . . . . . . . . . .
181
10 Peano Arithmetic and Π0
1-Classes
183
10.1
Logical Background . . . . . . . . . . . . . . . . . . . . .
183
10.2
Π0
1 Classes and Completions of Theories
. . . . . . . . .
184
10.3
Equivalent Properties of PA Degrees
. . . . . . . . . . .
185
11 Randomness and Π0
1-Classes
189
11.1
Martin-L¨of Randomness
. . . . . . . . . . . . . . . . . .
189
11.2
A Π0
1 Class of ML-Randoms . . . . . . . . . . . . . . . .
190
11.3
Π0
1 Classes and Measure
. . . . . . . . . . . . . . . . . .
191
11.4
Randomness and Computable Domination . . . . . . . .
192

Contents
xiii
III
Minimal Degrees
195
12 Minimal Degrees Below ∅′′
197
12.1
Function Trees and e-Splitting Strings
. . . . . . . . . .
197
12.2
The e-Splitting Lemmas
. . . . . . . . . . . . . . . . . .
199
12.3
The Splitting Procedure
. . . . . . . . . . . . . . . . . .
200
12.4
The Basic Module for Minimality . . . . . . . . . . . . .
201
12.5
A Minimal Degree Below a ∅′′-Oracle . . . . . . . . . . .
201
12.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
202
13 Minimal Degrees Below ∅′
203
13.1
The Sacks Minimal Degree a < 0′ . . . . . . . . . . . . .
203
13.2
The Basic Module for One Requirement Re
. . . . . . .
203
13.3
Putting the Strategies Together . . . . . . . . . . . . . .
204
13.4
A Subtle Point . . . . . . . . . . . . . . . . . . . . . . . .
205
13.5
Constructing A to Meet Requirements {Re}e∈ω
. . . . .
205
13.6
A Limit Computable Minimal Degree . . . . . . . . . . .
206
13.6.1 Meeting a Single Requirement Re . . . . . . . . .
207
13.7
A Minimal Degree Below a Nonzero C.E. Degree
. . . .
207
IV
Games in Computability Theory
209
14 Banach-Mazur Games
211
14.1
Banach-Mazur Games and Baire Category . . . . . . . .
211
14.1.1 Meager and Comeager Sets . . . . . . . . . . . . .
211
14.1.2 The Baire Category Theorem
. . . . . . . . . . .
212
14.1.3 Banach-Mazur Games
. . . . . . . . . . . . . . .
212
14.1.4 Exercises . . . . . . . . . . . . . . . . . . . . . . .
213
14.2
The Finite Extension Paradigm . . . . . . . . . . . . . .
214
14.2.1 Finite Extension Games
. . . . . . . . . . . . . .
215
14.2.2 Exercises . . . . . . . . . . . . . . . . . . . . . . .
215
15 Gale-Stewart Games
217
15.1
Gale-Stewart Games and Open Games
. . . . . . . . . .
217
15.1.1 Exercises . . . . . . . . . . . . . . . . . . . . . . .
218
15.1.2 Remarks on the Axiom of Determinacy . . . . . .
219
16 More Lachlan Games
221
16.1
Increasingly Complicated Constructions . . . . . . . . . .
221
16.2
Lachlan Games in Computability Theory . . . . . . . . .
222
16.2.1 Playing Turing Reductions . . . . . . . . . . . . .
222
16.3
Some Easy Examples of Lachlan Games
. . . . . . . . .
223
16.3.1 Theorem 5.2.3: Post’s Simple Set
. . . . . . . . .
223
16.3.2 Theorem 5.2.7: Permitting a Simple Set A ≤T C
223

xiv
Contents
16.3.3 Theorem 7.4.1: A Simple Set A ̸≥T C . . . . . . .
223
16.3.4 Friedberg-Muchnik Theorem 7.3.1 . . . . . . . . .
224
V
History of Computability
225
17 History of Computability
227
17.1
Hilbert’s Programs
. . . . . . . . . . . . . . . . . . . . .
227
17.2
G¨odel, Church, and Recursive Functions
. . . . . . . . .
228
17.2.1 The Concept of Recursion . . . . . . . . . . . . .
229
17.2.2 The Primitive Recursive Functions
. . . . . . . .
229
17.2.3 Nonprimitive Recursive Functions . . . . . . . . .
231
17.2.4 Herbrand-G¨odel Recursive Functions . . . . . . .
232
17.2.5 Kleene’s µ-Recursive Functions
. . . . . . . . . .
233
17.2.6 G¨odel Remained Unconvinced . . . . . . . . . . .
234
17.3
Turing’s Analysis . . . . . . . . . . . . . . . . . . . . . .
235
17.3.1 Turing’s Discovery
. . . . . . . . . . . . . . . . .
235
17.3.2 G¨odel Accepts Turing’s Analysis . . . . . . . . . .
236
17.3.3 Turing’s Thesis: Deﬁnition or Theorem . . . . . .
236
17.3.4 Turing’s Demonstration of Turing’s Thesis . . . .
237
17.4
Turing’s Oracle Machine (o-Machine) . . . . . . . . . . .
238
17.4.1 An Extraordinary but Almost Incidental Discovery
238
17.4.2 Turing’s Use of Oracle Machines . . . . . . . . . .
239
17.4.3 Kleene’s Deﬁnition of “General Recursive In”
. .
240
17.5
Emil Post’s Contributions
. . . . . . . . . . . . . . . . .
241
17.5.1 Post Production Systems . . . . . . . . . . . . . .
242
17.5.2 Post Considered the Complete Set K . . . . . . .
242
17.5.3 Post Deﬁned Relative Computability . . . . . . .
243
17.5.4 Developing the Turing Jump . . . . . . . . . . . .
244
17.6
Finite Injury Priority Arguments
. . . . . . . . . . . . .
245
17.7
Computability and Recursion Terminology . . . . . . . .
245
17.7.1 G¨odel Rejects Term “Recursive Function Theory”
246
17.7.2 Changing “Recursive” Back to “Inductive” . . . .
247
17.8
Additional References . . . . . . . . . . . . . . . . . . . .
247
References
251



Preface
The title of this book, The Art of Turing Computability: Theory and Ap-
plications, emphasizes three very important concepts: (1) computability
(eﬀective calculability); (2) Turing or classical computability in the sense of
Turing and Post; and (3) the art of computability: as a skill to be practiced,
but also emphasizing an esthetic sense of beauty and taste in mathematics.
The Art of Classical Computability
Mathematics is an art as well as a science. We use the word “art” in two
senses. First “art” means a skill or craft which can be acquired and im-
proved by practice. For example, Donald Knuth wrote The Art of Computer
Programming, a comprehensive monograph in several volumes on program-
ming algorithms and their analysis. Similarly, the present book is intended
to be a comprehensive treatment of the craft of computability in the sense of
knowledge, skill in solving problems, and presenting the solution in the most
comprehensible, elegant form. The sections have been rewritten over and
over in response to comments by hundreds of readers about what was clear
and what was not, so as to achieve the most elegant and easily understood
presentation.
However, in a larger sense this book is intended to develop the art of
computability as an artistic endeavor, and with appreciation of its math-
ematical beauty. It is not enough to state a valid theorem with a correct
proof. We must see a sense of beauty in how it relates to what came before,
xvii 

xviii
Preface
what will come after, the deﬁnitions, why it is the right theorem, with the
right proof, in the right place.
One of the most famous art treasures is Michelangelo’s statue of David
displayed in the Accademia Gallery in Florence. The long aisle to approach
the statue is ﬂanked with the statues of Michelangelo’s unﬁnished slaves
struggling as if to emerge from the block of marble. There are practically
no details, and yet they possess a weight and power beyond their physical
proportions. Michelangelo thought of himself, not as carving a statue, but
as seeing the ﬁgure within the marble and then chipping away the marble
to release it. The unﬁnished slaves are perhaps a more revealing example
of this talent than the ﬁnished statue of David.
Similarly, it was Alan Turing in 1936 and 1939 who saw the ﬁgure of
computability in the marble more clearly than anyone else. Finding a for-
mal deﬁnition for eﬀectively calculable functions was the ﬁrst step, but
demonstrating that it captured computability was as much an artistic
achievement as a purely mathematical one. G¨odel himself had expressed
doubt that it would be possible to do so. The other researchers thought
in terms of mathematical formalisms like recursive functions, λ-deﬁnable
functions, and arithmetization of syntax. It was Turing who saw the com-
puter itself in the marble, a simple intuitive device equipped with only a
ﬁnite program and using only a ﬁnite sequence of strokes at each stage in a
ﬁnite computation, the vision closest to our modern computer. Even more
remarkable, Turing saw how to explicitly demonstrate that this mechani-
cal device captured all eﬀectively calculable processes. G¨odel immediately
recognized this achievement in Turing and in no one else.
The ﬁrst aim of this book is to present the craft of computability, but
the second and more important goal is to teach the reader to see the ﬁgure
inside the block of marble. It is to allow the reader to understand the nature
of a computable process, of a set which can be computably enumerated, of
the process by which one set B is computed relative to another set A, of a
method by which we measure the information content of a set, an algebraic
structure, or a model, and how we approximate these concepts at a ﬁnite
stage in a computable process.
The Great Papers of Computability
During the 1930’s, educators suggested that college students should read
the great books of Western culture in the original. At the University of
Chicago the principal proponents were President Robert Maynard Hutchins
and his colleague Professor Mortimer Adler. The curriculum relied on pri-
mary sources as much as possible and a discussion under the supervision
of a professor. For decades the Great Books Program became a hallmark
of a University of Chicago education.

xix
In the ﬁrst two decades of Computability Theory from 1930 to 1950 the
primary sources were papers not books. Most were reprinted in the book by
Martin Davis [1965] The Undecidable: Basic Papers on Undecidable Propo-
sitions, Unsolvable Problems, and Computable Functions. Of course, all of
these papers are important, shaped the subject, and should be read by the
serious scholar. However, many of these papers are written in a compli-
cated mathematical style which is diﬃcult for a beginner to comprehend.
Nevertheless, at least two of these papers are of fundamental importance
and are easily accessible to a beginning student. My criteria for selecting
these papers are the following.
1. The paper must have introduced and developed a topic of fundamen-
tal importance to computability.
2. The topic and its development must be as important today as then.
3. The paper must be written in a clear, informal style, so appealing
that any beginning student will enjoy reading it.
There are two papers in computability which meet these criteria.
Turing’s 1936 Paper, Especially §9
Turing’s 1936 paper is probably the single most important paper in com-
putability. It introduces the Turing machine, the universal machine, and
demonstrates the existence of undecidable problems. It is most often used
in mathematics and computer science to deﬁne computable functions. It is
perhaps Turing’s best known and most inﬂuential paper.
I am especially recommending Turing The Extent of the Computable
Numbers, §9, pp. 249–254 in Turing’s 1936 paper. Here Turing gives a
demonstration that the numbers computable by a Turing machine “in-
clude all numbers which would naturally be regarded as computable.” This
is a brilliant demonstration and is necessary for the argument. Without it
we do not know that we have diagonalized against all potential decidable
procedures and therefore we have no undecidable problems. Books on com-
putability rarely give this demonstration even though it is critical, perhaps
because of its nonmathematical nature. Every student of computability
should read this very short section.
Post’s 1944 Paper, Especially §11
Turing’s 1939 paper very brieﬂy introduced the notion of an “oracle ma-
chine,” a Turing machine which could consult an oracle tape (database),
but he did not develop the idea. In his paper Recursively Enumerable
Sets of Positive Integers and Their Decision Problems, Emil Post in 1944
developed two crucial ideas, the structure and information content of com-
Preface

xx
Preface
putably enumerable (c.e.) sets, and the idea of a set B being reducible to
another set A.
Turing never thought of his oracle machine as a device for reducing one
set to another. It was simply a local machine interacting with an external
database as today a laptop might query the Internet. Post was the ﬁrst to
turn the oracle machines into a reducibility of a set B to a set A, written
B ≤T A, which Post generously called Turing reducibility. Post’s entire pa-
per is wonderfully written and easily accessible to a beginner. He begins
with simpler reducibilities such as many-one reducibility and truth-table
reducibility and works up to Turing reducibility which was not understood
at the time.
The last section §11 General (Turing) Reducibility, is especially recom-
mended. Here Post explored informally the idea of a c.e. set B being Turing
reducible to another c.e. set A. For the next decade 1944–1954 Post contin-
ued to develop the notions of Turing reducibility and information content.
In 1948 Post introduced the idea of degrees of unsolvability, now called
Turing degrees, which are the key to measuring the information content of
a set or algebraic structure. Post gave his notes to Kleene before his death
in 1954. Kleene revised them and published the Kleene-Post 1954 paper,
introducing a ﬁnite forcing argument as in Chapter 6 to deﬁne Turing in-
comparable sets. These two notions, computability by Turing’s automatic
machine (a-machine) in 1936, and reducibility of one set B to another set A
in Turing’s 1939 paper and Post’s 1944 paper, are the two most important
ideas in computability theory. Therefore, these papers should be read by
anyone taking a course from this book.
Other excellent computability papers are reprinted in [Davis 1965], es-
pecially the G¨odel Incompleteness Theorem in [G¨odel 1931] with the
improvement by Rosser. Some of these papers may be diﬃcult for a be-
ginner to read, but they will be more accessible after a ﬁrst course in
computability. G¨odel’s collected works can be found in the three volumes,
[G¨odel 1986], [G¨odel 1990], and [G¨odel 1995].

Introduction
Turing Machines
A Turing machine (a-machine) is a kind of idealized typewriter with an
inﬁnite tape and a reading head moving back and forth one cell at a time
(§1.4) according to a ﬁnite state program. In 1936 Turing demonstrated
convincingly that this mathematical model captured the informal notion
of eﬀectively calculable. Turing’s model and analysis have been accepted
ever since as the most convincing model. It is the one on which we base
the results in this book.
Oracle Machines and Turing Reducibility
Immediately after this paper, Turing went to Princeton where he wrote a
PhD dissertation with Alonzo Church. The dissertation was mainly about
ordinal logics, a topic suggested by Church, but one page described an
oracle machine (o-machine) which is of the greatest importance in com-
putability theory. Turing’s oracle machine consisted of a Turing machine
connected to an “oracle” which it could query during the computation.
This is analogous to the modern model of a local server, such as a lap-
top computer, connected to a large database, such as the Internet which
contains too much information to be stored on the local server.
Turing’s oracle machine concept lay dormant for ﬁve years until Emil
Post’s extraordinary 1944 paper revived it, greatly expanded it, and cast
the subject in an informal, intuitive light. Post deﬁned a set B to be Turing
reducible to a set A, written B ≤T A, if there is an oracle machine which
xxi

xxii
Introduction
computes B when the characteristic function of A is written on the oracle
tape. The oracle machines include the ordinary machines because if a set B
is computed by an ordinary Turing machine, then it is computed by an ora-
cle machine with A = ∅on the oracle tape. But the oracle machines do much
more. Turing reducibility is a crucial concept because in computablility the-
ory and applications we rarely prove results about computable functions on
computable sets. We compare noncomputable (undecidable) sets B and A
with respect to their relative information content. We say that sets A and
B are Turing equivalent, written A ≡T B if A ≤T B and B ≤T A, in which
case we view A and B as coding the same information. Turing reducibility
gives us a precise measure of the information they encode relative to other
sets and the Turing degrees (§3.4) are equivalence classes containing sets
with the same information content.
Computable Enumerable Sets
In 1936 Church and Kleene introduced the concept of a computably enu-
merable (c.e) set, also called a recursively enumerable (r.e.) set, as one
which can be eﬀectively listed, such as the theorems in a formal system
like Peano arithmetic. In 1944 Post realized the importance of these sets in
many areas of mathematics, and Post devoted much attention to studying
their information content. His work on the structure of these sets and their
information content under stronger reducibilities has had a great inﬂuence
on the topics in this book.
Of the eﬀective listing of c.e. sets, {We}e∈ω Post reminded us that the
G¨odel diagonal set K = {e : e ∈We} is c.e. and noncomputable. The
famous Post Problem was to determine whether there is only one such set
up to Turing degree.
Bounded Turing Reductions
At ﬁrst, Post did not make much progress on the general case of Turing
reducibility. To progress toward it, he considered various stronger reducibil-
ities called bounded reducibilities. A Turing reduction ΦA
e = B witnessing
B ≤T A is a bounded Turing reduction, written B ≤bT A, if there is a com-
putable function h(x) bounding the use function, namely ϕA
e (x) ≤h(x),
where the use function ϕA
e (x) is the maximum element used (scanned)
during the computation.
For example, every c.e. set B is many-one reducible to K, B ≤m K by
a computable function f, i.e., x ∈B iﬀf(x) ∈K. Post introduced several
structural properties of a c.e. set B in an attempt to prove incompleteness.
For example, he proved that a K ̸≤m B for a simple set B. The varieties of
simple and nonsimple sets he introduced and his various bounded reducibil-
ities had a profound eﬀect on the subject for decades and led indirectly to
most of the results in this book.

xxiii
Finally Understanding Turing Reducibility
Post realized that the bounded reducibilities would not solve his problem.
It required a deeper understanding of Turing reducibility. His understand-
ing increased over the next decade from 1944 until his death in 1954. Post
introduced the notion of degree of unsolvability to collect into one equiv-
alence class sets coding the same information content. He wrote notes on
his work. As he became terminally ill in 1954, Post gave them to Kleene
who expanded them and published it as [Kleene and Post 1954]. This pa-
per was a fundamental advance toward solving Post’s problem and toward
understanding Turing reducibility. The key idea was the continuity of Tur-
ing functionals that if ΦA
e (x) = y then Φσ
e (x) = y for some ﬁnite initial
segment σ ≺A, and that if B ≻σ then ΦB
e (x) = y also.
Using this, Kleene and Post constructed sets A and B computable in
K such that A ̸≤T B and B ̸≤T A. Hence, ∅<T A <T K. This did not
explicitly solve Post’s Problem because the sets were not c.e., but Kleene
and Post divided the conditions into requirements of the form ΦA
e ̸= B,
which could be arranged in a priority list of order type ω and processed
one at a time using the Use Principle. This became the model for most
arguments in the subject. It became the key step in the later solution
of Post’s Problem by Friedberg in 1957 and Muchnik in 1956 since they
combined this strategy with a computable approximation stage by stage.
From these ideas emerged the understanding that a Turing functional Φe
is continuous as a map on Cantor space 2ω and is not only continuous but
eﬀectively continuous because the inverse image of a basic open set is the
computable union of basic open sets.
Priority Arguments
The Kleene-Post construction had produced ﬁnite initial segments σ ≺A
and τ ≺B such that for some x, Φσ
e (x) ̸= τ(x). Hence ΦA
e (x) ̸= B(x). To
make the sets A and B computably enumerable, Muchnik and Friedberg
had to abandon the K-oracle and computably enumerate the sets, letting
As be the ﬁnite set of elements enumerated in A by the end of stage s and
likewise for Bs. They attempted to preserve strings σ ≺As and τ ≺Bs
when it seemed to give Φσ
e (x) ̸= τ(x). This action might later be injured
because action by a higher priority requirement forces σ ̸≺As+1 causing
this condition for e to begin all over again. These results led to much more
complicated inﬁnite injury arguments.
Other Parts of This Book
The introduction so far explains the background and motivation for most of
Part I up to ﬁnite injury priority arguments in Chapter 7. For the summary
Introduction

xxiv
Introduction
and motivation of the other parts see the next section about how to read
this book.

How to Read This Book
Part I: Foundations of Computability
The core of the subject is Part I, Chapters 1–7, from the deﬁnition of
Turing machines in Chapter 1 up to ﬁnite injury priority arguments in
Chapter 7. Traditionally, a beginning undergraduate or graduate course of
ten or ﬁfteen weeks would go through the sections here one by one. Part I
has been streamlined, with more complicated chapters moved to later parts
in order to make this schedule feasible. After ﬁnishing Chapter 7 on ﬁnite
injury, the reader will have a ﬁrm grasp of the fundamental results and
methods of computability theory. One can also cover Part I more quickly
as an initial segment of an advanced computability course by concentrating
on the starred sections in Part I and then moving to other advanced topics.
Part II: Trees and Π0
1 Classes
A tree is a set of strings closed under initial segments and a Π0
1 class
is the set of paths through a computable binary tree. These classes play
an important role in model theory, extensions of Peano arithmetic, algo-
rithmic randomness, and other applications. We study open and closed
computable classes of reals, and basis and nonbasis theorems for Π0
1 classes.
We give a proof of the Superlow Basis Theorem, proved but not published,
by Jockusch and Soare about 1969. We also give a proof by Dzhafarov and
Soare of the Low Antibasis Theorem by Kent and Lewis. We show how Π0
1
xxv

xxvi
How to Read This Book
classes and their basis theorems are related to models of Peano arithmetic,
with results by Jockusch and Soare, Scott, Shoenﬁeld, and Solovay. Finally,
we relate Π0
1 classes to Martin-L¨of randomness, computably dominated
(hyperimmune-free) degrees, and to computably traceable sets.
Part III: Minimal Degrees
A Turing degree a is minimal if a > 0 but there is no degree b such that
0 < b < a. In Chapter 12 we present Spector’s proof of a minimal degree
a < 0′′. The proof uses a forcing argument like those in Chapter 6 but with
more complicated forcing conditions of perfect trees instead of ﬁnite strings.
In Chapter 13 we present the Sacks construction of a minimal degree a < 0′.
This is an approximation to Spector’s method and uses a ﬁnite injury
priority argument. We also sketch a limit computable (full approximation)
construction of a minimal degree below 0′ using a computable construction.
It can also be done below any nonzero computably enumerable degree,
thereby producing a low minimal degree. Chapters 6 and 7 are the only
prerequisites for this material.
Part IV: Games in Computability Theory
Games are very important in understanding the nature of computability,
how to prove theorems, and how to solve problems. In Chapter 14 we
present the classical Banach-Mazur games which are closely related to the
ﬁnite extension constructions of Chapter 6, Sections 1–3, and may be read
simultaneously with them and with Chapter 8 on open and closed classes
in Cantor space. Players I and II alternately construct strings σ2n and
σ2n+1, jointly constructing a point f = ∪nσn in Cantor space 2ω. There is
a predetermined class A ⊆2ω. Player I wins the game according to whether
f ∈A or not. Winning strategies are described in terms of properties of A.
We also discuss the Cantor-Bendixson rank of points in a closed subclass
A ⊆2ω.
In Chapter 15 we make a very brief excursion into Gale-Stewart games.
We consider the complexity of the winning strategy for a very simple
computable game.
We ﬁnish in Chapter 16 by returning to the topic of more Lachlan games,
ﬁrst introduced in §2.5. These games are the principal tool in proving
theorems and solving problems in computability theory.

xxvii
Symbols Marking Importance and Diﬃculty
In Part I we use the following notation for sections, theorems, and exercises.
⋆⋆
Most important.
⋆
Very important.
No Marking
Average importance.
⊘
Skim or defer on a ﬁrst reading until needed in a later chapter.
⋄
Diﬃcult exercise, do not assign lightly.
⋄⋄
Very diﬃcult exercise.
How to Read This Book


Notation
Notation will be deﬁned when introduced. We now summarize the most
common notation and deﬁnitions.
Notation for Sets
The universe is the set of nonnegative integers ω = {0, 1, 2, 3, . . . } which
sometimes appears in the literature as N. Most of the objects we study
can be associated with some n ∈ω called a “code number” or “G¨odel
number.” We can think of operations on these objects as being presented
by a corresponding function on these numbers and our functions will have
domain and range contained in ω.
Uppercase Latin letters A, B, C, D and X, Y , Z normally represent
subsets of ω = {0, 1, 2, 3, . . . } with the usual set operations A ∪B, A ∩B;
|A|, or card(A) denotes the cardinality of A; max(A) denotes the maximum
element x ∈A if A is ﬁnite; A ⊆B denotes that A is a subset of B, and
A ⊂B that it is a proper subset; A −B denotes the set of elements in A
but not in B; A = ω −A, the complement of A; A ⊔B denotes the disjoint
union, i.e., A ∪B provided that A ∩B = ∅; the symmetric diﬀerence is
A ∆B = (A −B) ∪(B −A); a, b, c, . . . x, y, z, . . . represent integers in ω;
A × B is the Cartesian product of A and B, the set of ordered pairs (x, y)
such that x ∈A and y ∈B; ⟨x, y⟩is the integer that is the image of the
pair (x, y) under the standard pairing function from ω × ω onto ω; A ⊆∗B
denotes that |A −B| < ∞; A =∗B denotes that A ∆B is ﬁnite; A ⊂∞B
xxix

xxx
Notation
denotes that |B −A| = ∞. Given a simultaneous enumeration (see p. 46)
of A and B let A \ B denote the set of elements enumerated in A before B
and A ↘B = (A \ B) ∩B, the set of elements appearing in A and later
in B.
Logical Notation
We form predicates with the usual notation of logic where &, ∨, ¬, =⇒, ∃,
∀denote respectively, and, or, not, implies, there exists, for all; (µx) R(x)
denotes the least x such that R(x) if it exists, and is undeﬁned otherwise;
(∃∞x) denotes “there exist inﬁnitely many x,” and (∀∞x) denotes “for
almost all x” as in Deﬁnition 3.5.1. These quantiﬁers are dual to each other.
The latter is written (∃x0)(∀x ≥x0). We use x, y, z < w to abbreviate
x < w, y < w, and z < w. In a partially ordered set we let x | y denote
that x and y are incomparable, i.e., x ̸≤y and y ̸≤x. We often use the dot
convention to abbreviate brackets before and after the principal connective
of a logical expression. For example, if α and β are well-formed formulas,
then α .
=⇒
. β abbreviates [ α ]
=⇒
[ β ]. The algorithm is to
insert a right bracket just before =⇒and then a matching left bracket
just before the ﬁrst symbol in α. Do the corresponding algorithm for β.
The dots increase readability of a long expression. TFAE abbreviates “The
following are equivalent.”
We use the usual Church lambda notation for deﬁning partial functions.
Suppose [. . . x . . .] is an expression such that for any integer x the expres-
sion has at most one corresponding value y. Then λx [. . . x . . .] denotes the
associated partial function θ(x) = y, for example λx [ x2 ]. The expression
λx [ ↑] denotes the partial function which is undeﬁned for all arguments.
We also use the lambda notation for partial functions of k variables, writ-
ing λx1x2 . . . xk in place of λx. An expression such as λx y [ x + y ], denotes
addition as a function of x and y. However, λx [ x + y ] indicates that the
expression is viewed as a function of x with y as a parameter, such as
λx [x + 2]. One advantage is that with an expression of several arguments,
such as in the s-n-m Theorem 1.5.5 (Parameter Theorem) we can make
clear which arguments are variables and which are parameters, for exam-
ple as explained in Remark 1.5.6. Deﬁne f(x) = 1 .−x to be 1 if x = 0
and 0 if x ≥1. We call this the monus function. It produces a 0-1 valued
function f(x) ̸= x.
Lattices and Boolean Algebras
A lattice L = (L; ≤, ∨, ∧) is a partially ordered set (poset) in which any
two elements a and b have a least upper bound (lub) a ∨b and greatest

xxxi
lower bound (glb) a ∧b. An upper semi-lattice has lub only. For example,
the Turing degrees under Turing reducibility form an upper semi-lattice.
If L contains a least element and greatest element these are called the
zero element 0 and unit element 1, respectively. In such a lattice a is the
complement of b if a ∨b = 1 and a ∧b = 0, and L forms a Boolean algebra
if every element has a complement. A nonempty subset I ⊆L forms an
ideal I = (I; ≤, ∧, ∨) of L if I satisﬁes the conditions:
(1)
[a ∈L & a ≤b ∈I] =⇒a ∈I, and
(2)
[a ∈I & b ∈I] =⇒a ∨b ∈I.
A ﬁlter F ⊂L satisﬁes the dual conditions. For example, the subsets of ω
form a Boolean algebra with the ﬁnite sets as an ideal and the coﬁnite sets
as a ﬁlter.
Notation for Strings and Functionals
We let 2<ω denote the set of all ﬁnite sequences of 0’s and 1’s called strings
and denoted by σ, ρ, and τ. Let 2ω denote the set of all functions f from ω
to 2 = {0, 1}, and ωω the set of all functions f from ω to ω. The integers
n ∈ω are type 0 objects, (partial) functions f ∈2ω or subsets A ⊆ω
(which are identiﬁed with their characteristic function χA ∈2ω) are type
1 objects, a (partial) functional Ψ is a map from type 1 objects to type 1
objects, i.e., a map from 2ω to 2ω and is called a type 2 object. Identifying
a set A with its characteristic function χA we often write A(x) for χA(x).
Uppercase Latin letters A, B, C, . . . , represent subsets of ω. Script letters
A, B, C represent subsets of 2ω and are called classes to distinguish them
from sets.
G¨odel Numbering of Finite Objects
In his Incompleteness Theorem [1931] G¨odel introduced the method of
assigning a code number or G¨odel number to every formal (syntactical)
object such as a formula, proof, and so on. We now present two ways to
eﬀectively code a sequence of n-tuples of integers {a1, a2, . . . an}, deﬁne
(1)
a = pa1+1
1
pa2+1
2
. . . pak+1
k
where pi is the ith prime number. Given a we can eﬀectively recover the
prime power (a)i = ai + 1. This coding is injective but not surjective on ω.
The second method uses the following standard pairing function and
has the added advantage that the n-tuple coding below is an injective and
surjective map from ω onto ωn.
Notation

xxxii
Notation
Standard Pairing Function
(i) Let ⟨x, y⟩denote the integer that is the image of the ordered pair (x, y)
under the standard pairing function 1
2(x2 + 2xy + y2 + 3x + y) which is
a 1:1 computable function from ω × ω onto ω. Let π1 and π2 denote the
inverse pairing functions π1(⟨x, y⟩) = x, and π2(⟨x, y⟩) = y.
(ii) Let ⟨x1, x2, x3⟩denote ⟨⟨x1, x2⟩, x3⟩. Let the n-ary pairing function be
(2)
⟨x1, x2, . . . , xn⟩
=
⟨· · · ⟨⟨x1, x2⟩, x3⟩, . . . , xn⟩.
(All these functions are clearly computable and even primitive recursive.)
If the sequences are all of ﬁxed length n we may use method 2, the n-ary
pairing function of (2),
(3)
f(a1, a2, . . . an) = ⟨a1, a2, . . . an⟩
Otherwise, we use the ﬁrst method above of coding using prime powers.
There are many other coding algorithms. The important point for coding
is that the method be eﬀective and invertible, but it is often useful to have
it surjective as well.
Note that both methods are eﬀectively invertible. Let θ be any 1:1 com-
putable partial function. Then θ is eﬀectively invertible on its range. Just
enumerate the pairs (u, v) with θ(u) = v until, if ever, a pair (x, y) is found
and then deﬁne ψ(y) = x. See also the Deﬁnition 2.1.7 of graph(θ) and the
Uniformization Theorem 2.1.8.
Eﬀective Numbering of Finite Sets and Strings
Given a ﬁnite set F = {x1, x2, . . . xk} where x1 < x2 . . . xk we give F the
(strong) index y = 2x1 + 2x2 . . . + 2xk and write that Dy = F. LetD0 = ∅.
Likewise, give every string σ ∈2ω an eﬀective index from using either the
strong index coding or G¨odel numbering so that from the index we can
recover the length k = |σ| and every component σ(i), for i < k. Such a
numbering of strings σz is given in Deﬁnition 2.3.6.
Partial Computable (P.C.) Functions
Let {Pe}e∈ω be an eﬀective numbering of all Turing machine programs (as
in Deﬁnition 1.5.1). We write ϕe(x) = y if program Pe with input x halts
and yields output y, in which case we say that ϕe(x) converges (written
ϕe(x) ↓), and otherwise ϕe(x) diverges (written ϕe(x) ↑); {ϕe}e∈ω is an
eﬀective listing of all partial computable (p.c.) functions; the domain and
range of ϕe are denoted by dom(ϕe) and rng(ϕe). A set A is computably
enumerable (c.e.) if it can be eﬀectively listed, i.e., if A = dom(ϕe) for
some e.

xxxiii
If dom(ϕe) = ω then ϕe is a total computable function (abbreviated
computable function); we let f, g, h, . . . denote total functions; f ◦g or fg
denotes the composition of functions, applying ﬁrst g to an argument x
and then applying f to g(x). Let f ↾x denote the restriction to elements
y < x and f ↾↾x the restriction to elements y ≤x.
Turing Functionals ΦA
e
Let { ePe}e∈ω be an eﬀective numbering of all Turing machine oracle pro-
grams, ﬁnite sets of sextuples deﬁned in §3.2.1. Write ΦA
e (x) = y if oracle
program ePe with A on its oracle tape and input x halts and yields out-
put y. Let the use function ϕA
e (x) be the greatest element z for which the
computation scanned the square A(z) on the oracle tape. We regard Φe
as a (partial) functional (type 2 object) from 2ω to 2ω mapping A to B if
ΦA
e = B.
The use function ϕA
e (x) has an exponent A to distinguish from the p.c.
function ϕ(x). They usually come in matched pairs, ΨA(x) and ψA(x),
ΘA(x) and θA(x), where the lowercase function denotes the use function
corresponding to the uppercase functional. See Deﬁnition 3.2.2 (vi) for a
function f as oracle in place of the set A.
Lachlan Notation
When E(As, xs, ys, . . .) is an expression with a number of arguments
subscripted by s denoting their value at stage s, Lachlan introduced the no-
tation E(A, x, y, . . .)[ s ] to denote the evaluation of E where all arguments
are taken with their values at the end of stage s.
(4)
ΦA
e (x) [ s ] denotes ΦAs
e,s (xs)
and
ϕA
e (x) [ s ] denotes ϕAs
e,s(xs).
This Lachlan notation has become very popular and is now used in most
papers and books.
Notation


Acknowledgements
Among others I would like to thank colleagues and students for careful
reading of preliminary versions of this book and for their suggestions and
corrections.
This includes my University of Chicago colleagues, Denis Hirschfeldt,
Joseph Mileti, Antonio Montalban, and Maryanthe Malliaris; and former
students, Eric Astor, William Chan, Barbara Csima, Chris Conidis, David
Diamondstone, Damir Dzhafarov, Rachel Epstein, Kenneth Harris, Karen
Lange, Russell Miller, Jonathan Stephenson, and Matthew Wright.
It includes colleagues at other universities, Ted Slaman, Richard Shore,
Carl Jockusch, Douglas Cenzer, Leo Harrington, Manuel Lerman; and
colleagues at the University of Wisconsin, Steﬀen Lempp, Bart Kaster-
mans, Arnie Miller, Joe Miller, and Wisconsin students, Asher Kach, Dan
Turetsky, and Nathan Collins.
I am grateful to the students of Barbara Csima at the University of Wa-
terloo, Vladimir Soukharev, Jui-Yi Kao, Atul Sivaswamy, David Belanger,
and Carolyn Knoll; to Piet Rodenburg and Tom Sterkenbert in Amster-
dam and their students, including Frank Nebel; to Notre Dame colleagues
Julia Knight and Peter Cholak and their students, Joshua Cole, Yang Lu,
Stephen Flood, Quinn Culver and John Pardo; to Valentina Harizanov at
George Washington University and her students, Jennifer Chubb and Sarah
Pingrey; to Aaron Sterling at Iowa State University; to Russell Miller’s
student at Queens College CUNY, Rebecca Steiner; to Iraj Kalantari at
Northern Illinois University and his student, Abolfazi Karimi; to Rachel
Epstein and her students at Harvard who covered Part I of the book in de-
tail; to Damir Dzhafarov who drew the diagrams in tikz; to Linda Westrick
xxxv

xxxvi
Acknowledgements
at the University of Connecticut. Carl Jockusch and Damir Dzhafarov read
some of the advanced chapters in detail and made a number of mathemat-
ical corrections and suggestions. Damir also designed the excellent cover
diagram of a Turing machine.
I am grateful to Ronan Nugent, Senior Editor at Springer-Verlag, who
read the manuscript in detail, made a number of corrections, and handled
the editing and production of this book.

Part I
Foundations of Computability

1
Deﬁning Computability
1.1
Algorithmically Computable Functions
In this chapter we deﬁne the notion of a computable function using Tur-
ing machines in §1.4. Then we develop its most important properties such
as the Enumeration Theorem 1.5.3 and the s-m-n Theorem 1.5.5 (Param-
eter Theorem), which we shall use often. The historical development of
other deﬁnitions of computable functions is discussed in the history chapter,
Chapter 17.
1.1.1
Algorithms in Mathematics
Mathematicians have studied calculation and algorithms since earlier than
the time of the Babylonians. Specifying algorithms goes back at least to
Euclid’s Elements (written about 330–320 B.C.), and his famous greatest
common divisor algorithm. Another famous algorithm is the sieve of Er-
atosthenes for calculating whether an integer k is prime by crossing out all
proper multiples of numbers less than k, beginning with 2, then 3, and so
on, to determine whether k has been crossed out, in which case it is not
prime.
These procedures have the properties we recognize in an algorithmic
procedure. The procedure is speciﬁed by a ﬁnite set of instructions; the
calculation proceeds in a ﬁnite sequence of steps, eventually halting with the
answer; it proceeds in a deterministic, completely speciﬁed fashion without
any recourse to human intelligence or random devices.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_1 
3 

4
1. Deﬁning Computability
Prior to 1930 it was generally not considered necessary to deﬁne the in-
formally computable functions, or eﬀectively calculable functions, as they
were called in the 1930s. Rather, Hilbert had called for the discovery of
algorithmic solutions to speciﬁc problems, such as Hilbert’s tenth prob-
lem on the solution of Diophantine equations, or the Entscheidungsproblem
(decision problem), the problem of ﬁnding an algorithm to decide which
formulas of ﬁrst-order logic are valid.
However, G¨odel’s ﬁrst Incompleteness Theorem [G¨odel 1931] (stated in
modern terms and with an improvement by Rosser) showed that any
eﬀectively axiomatizable formal system T which includes elementary num-
ber theory is either inconsistent or incomplete. This dramatic blow to
Hilbert’s famous consistency program suggested to some mathematicians
that Hilbert’s Entscheidungsproblem might also have a negative solution.
However, to prove that a given problem is algorithmically unsolvable they
ﬁrst had to formally characterize the informal class of eﬀectively calcula-
ble functions and then prove that no function in that class constituted a
solution to the speciﬁc problem. The program to precisely deﬁne the infor-
mal class of intuitively computable functions began in earnest after G¨odel’s
results in 1931.
1.1.2
The Obstacle of Diagonalization and Partial Functions
The objective was ﬁrst to formally deﬁne the eﬀectively calculable functions
and then give an eﬀective list of them all. We begin with functions on ω,
and therefore we can identify all ﬁnite objects with code numbers (G¨odel
numbers), as explained in the Notation Section. To characterize the eﬀec-
tively calculable functions we would like to produce a list C = {fn}n∈ω of
functions with three properties: (1) the list {fn}n∈ω includes all and only al-
gorithmically computable functions; (2) there is a uniformly eﬀective listing
of them, namely an algorithmically computable function g(n, x) = fn(x);
and (3) every fn is a total function, i.e., is deﬁned on all x ∈ω. However,
these three conditions are contradictory because we can deﬁne the diagonal
function h(x) = g(x, x) + 1, which is algorithmically computable because
g is, but h ̸∈C because h(x) ̸= fx(x).
Hence, we must abandon one of the three conditions, but we do not
abandon either (1) or (2), both of which are crucial to the entire theory.
Therefore, we must give up (3). If we are dealing with partial computable
functions, then (3) is no longer an obstacle because in the deﬁnition of h
we may no longer have that g(x, x) is deﬁned and hence cannot argue that
h(x) ̸= g(x, x). It is more natural to consider partial computable functions
anyway, because we shall eﬀectively list all algorithms in some formalism,
and certain algorithms may be naturally deﬁned only on some but not all
arguments. All the formal classes we consider produce algorithmic functions
which are partial and are called partial computable (p.c.) functions. Those

1.1. Algorithmically Computable Functions
5
partial functions in the class which are total are called total computable
functions or simply computable functions.
1.1.3
The Quest for a Characterization
To produce an undecidable problem one had to ﬁrst formally deﬁne the class
of eﬀectively calculable functions. Kurt G¨odel, realizing that the primitive
recursive functions he had used in his 1931 Incompleteness Theorem were
not suﬃcient to capture all eﬀectively calculable functions, proposed in
lectures at Princeton University in 1934 the more general class, Herbrand-
G¨odel general recursive functions, now called simply recursive functions.
In 1936 Church proposed Church’s Thesis, that the eﬀectively calculable
functions be identiﬁed with the recursive functions. By the beginning of
1936 G¨odel was not convinced that his own recursive functions captured
the eﬀectively calculable functions. However, when G¨odel saw the following
analysis by Turing later in 1936, he was immediately convinced.
1.1.4
Turing’s Breakthrough
Upon this scene came a twenty-three-year-old graduate student at Cam-
bridge University, who was unaware of the work in recursive functions by
G¨odel, Kleene, and Church at Princeton University. In 1935 Turing had
heard the lectures of Cambridge don M.H.A. Newman on G¨odel’s paper
and on the Hilbert Entscheidungsproblem. Turing worked on the problem
for the remainder of 1935 and submitted his solution to the incredulous
Newman on April 15, 1936. Turing’s monumental paper [Turing 1936] was
distinguished because: (1) Turing analyzed an idealized human computing
agent which brought together the intuitive concept of a “function produced
by a mechanical procedure” which had been evolving for more than two
millennia from Euclid to Leibniz to Babbage and Hilbert; (2) Turing spec-
iﬁed a remarkably simple formal device (Turing machine) and informally
but convincingly demonstrated the equivalence of (1) and (2), namely he
demonstrated Turing’s Thesis (TT); (3) Turing proved the unsolvability
of Hilbert’s Entscheidungsproblem, which established mathematicians had
been studying intently for some time; (4) Turing proposed a universal Tur-
ing machine, one which carried within it the capacity to duplicate any other,
an idea of great theoretical importance which was also later to have consid-
erable impact on the development of high-speed digital computers. G¨odel
enthusiastically accepted Turing’s Thesis and his analysis and thereafter
gave Turing credit for the deﬁnition of mechanical computability.

6
1. Deﬁning Computability
1.2
⋆⋆Turing Deﬁnes Eﬀectively Calculable
We can divide Turing’s 1936 paper into two parts: describing the infor-
mal notion of eﬀectively calculable; and giving the precise mathematical
model of a Turing machine which captures it. By 1936–1937 it had been
shown that various formal deﬁnitions of computable functions were math-
ematically equivalent, including Turing computable functions, recursive
functions, and others. Nevertheless, we have to argue that at least one
of the formal deﬁnitions captures the informal notion of a function being
eﬀectively calculable by a human being. Turing did this more convincingly
than anyone else in [Turing 1936] Sections 1 and 9.
Turing Sections 2–8 presented in [Turing 1936] ﬁrst give the deﬁnition
of a Turing machine, and then a universal machine. Only at the end, in
Section 9, did he give the following informal argument which captures the
notion of eﬀectively calculable functions. From this follows almost at once
the formal deﬁnition of a Turing machine in the next section. We present his
results in the reverse order. The essence of Turing’s deﬁnition in Section 9
is the following.
• Turing proposed a number of simple operations “so elementary that
it is not easy to imagine them further subdivided.”
• He divided the work space into squares, which he assumed to be
one-dimensional.
• He assumed ﬁnitely many symbols. Each square contains one symbol.
• He assumed ﬁnitely many states (of mind).
• The action of the machine is determined by the present state and the
squares observed.
• The squares are bounded by B, say B = 1.
• The reading head examines one symbol in one square.
• We may assume the machine moves to only squares within a radius
C of the current square. We may assume C = 1.
• The machine may print a symbol in the current square, change state,
and move to an adjacent square.
[Sieg 2006] gave an axiomatization of a more general form of these prop-
erties and showed that any procedure satisfying these axioms produces a
Turing machine computable function.

7
1.3
⋆⋆Turing’s Thesis, Turing’s Theorem, TT
Turing believed that he had established in [Turing 1936] that a function is
eﬀectively calculable by a human being iﬀit is computable by a Turing ma-
chine. Turing wrote in [Turing 1954] that “its status is something between
a theorem and a deﬁnition.” Neither Turing nor G¨odel ever described this
as a “thesis,” as Kleene named it in his book [Kleene 1952]. So that readers
can recognize Kleene’s terminology, we shall call it “Turing’s Thesis,” but
also and more accurately “Turing’s Theorem,” letting the symbol TT label
the statement with no ambiguity in content, only in name. (See the history
chapter, Chapter 17.) The result is stated only for numbers but clearly
carries over to ﬁnite structures by G¨odel numbering.
Theorem 1.3.1 (Turing’s Thesis, Turing’s Theorem (TT)). A function is
eﬀectively calculable by a human being iﬀit can be computed by a Turing
machine.
1.4
⋆⋆Turing Machines
Deﬁnition 1.4.1. (Turing)
A Turing machine (automatic machine, a-
machine) M includes a two-way inﬁnite tape divided into cells, a reading
head which scans one cell of the tape at a time, and a ﬁnite set of internal
states Q = {q0, q1, . . . , qn},
n ≥1. Each cell is either blank (B) or has
written on it the symbol 1. In a single step the machine may simultaneously:
(1) change from one state to another; (2) change the scanned symbol s to
another symbol s′ ∈S = {1, B}; and (3) move the reading head one cell to
the right (R) or left (L). The operation of M is controlled by a partial map
δ : Q×S →Q×S ×{R, L} (which may be undeﬁned for some arguments).
The interpretation is that if (q, s, q′, s′, X) ∈δ then the machine M in
state q, scanning symbol s, changes to state q′, replaces s by s′, and moves
to scan one square to the right if X = R (or left if X = L). The map δ
viewed as a ﬁnite set of quintuples is called a Turing program. The input
integer x is represented by a string of x + 1 consecutive 1’s (with all other
cells blank). The Turing machine is pictured in Figure 1.1.
We begin with M in the starting state q1 scanning the leftmost cell
containing a 1, called the starting cell. If the machine ever reaches the
halting state q0, after say s steps, then we say M halts and the output y
is the total number of 1’s on the tape. (Note that f(x) = max{x + 1, s}
bounds the maximum distance from the starting cell to any cell which is
either scanned or contains an input symbol. Hence the determination of y
is eﬀective.)
We may assume that M never makes any further moves after reaching
state q0, i.e., that the domain of δ contains no element of the form (q0, s).
We say that M computes the partial function ψ provided that ψ(x) = y
1.4.
⋆⋆Turing Machines

8
1. Deﬁning Computability
movable reading head
ﬁnite Turing program
δ
current state
two-way inﬁnite tape
q
· · ·
B
1
1
1
B
B
· · ·
Figure 1.1. Turing machine
if and only if M with input x eventually halts and yields output y. For
example, the following machine computes the function f(x) = x + 3.
(1.1)
q1
1
q1
1
R
q1
B
q2
1
R
q2
B
q0
1
R
The instantaneous condition of M during each step in a Turing calcula-
tion is completely determined by: (1) the current state qi of the machine;
(2) the symbol s1 being scanned; (3) the symbols on the tape to the right
of symbol s1 up to the last 1, i.e., s2, s3, . . . , sk; and (4) the symbols to the
left of s1 up to the ﬁrst 1, i.e., t1, t2, . . . tm. This is the (instantaneous)
conﬁguration of the machine at that step and is written
(1.2)
c
=
tmtm−1tm−2 . . . t2 t1 qi s1 s2 s3 . . . sk.
For example, the machine of (1.1) in calculating on input x = 0 passes
through the conﬁgurations, q11, 1q1B, 11q2B, and 111q0B, and it yields
output y = 3. (Recall that the input x is coded by x + 1 consecutive 1’s
while the output y is coded by the total number of 1’s on the tape. Also
notice that the tape contains only ﬁnitely many non-blank symbols at the
beginning of any calculation and that this condition persists at all later
stages, whether the machine halts or not, so that the integers k and m in
(1.2) exist.)
If the machine M enters a state q ̸= q0 and reads a symbol s from which
δ(q, s) gives no moves, then the machine stalls, i.e., makes no further moves,
and gives no output. We do not refer to this as halting even though the
machine stalls and stops forever. We use the term halting only if M enters
the halting state q0.
Deﬁnition 1.4.2. A Turing computation according to Turing program
P with input x is a sequence of conﬁgurations, c0, c1, . . . , cn such that c0
represents the machine in the starting state q1 reading the leftmost symbol

1.4.
⋆⋆Turing Machines
9
of the input x, cn represents the machine in the halting state q0, and the
transition ci →ci+1, for all i < n, is given by the Turing program P.
Thus, from now on a computation will always refer to a halting, i.e.,
convergent, calculation. A partial function of n variables is associated with
each Turing machine M by representing the input (x1, x2, . . . , xn) by the
following initial conﬁguration of M: q1α1Bα2 . . . Bαn where αi consists of
xi + 1 consecutive 1’s.
A Simple Example of a Computation
In (1.1) we gave a simple Turing program to compute f(x) = x + 3. Let us
consider the computation as the machine proceeds on input 2 (represented
by three 1’s, 111, on the tape).
q1 1 1 1 B B
1 q1 1 1 B B
1 1 q1 1 B B
1 1 1 q1 B B
1 1 1 1 q2 B
1 1 1 1 1 q0
The input is 2 (denoted by 111) and the output is 5 (denoted by a total of
ﬁve 1’s on the ﬁnal tape. All the other cells are blank (B) and not explicitly
mentioned. The machine halts in state q0 and never moves again on input
2.
Deﬁnition 1.4.3. Given n inputs x1, . . . xn, we represent these as an input
to a Turing machine by writing each as a block of (xk+1) 1’s and separating
each block by a B.
1.4.1
Exercises on Turing Machines
Exercise 1.4.4. Write Turing machines which compute functions f(x) =
0, f(x) = λx[ k ], f(x) = 2x, and f(x, y) = x + y.

10
1. Deﬁning Computability
1.5
⋆⋆The Basic Results
1.5.1
Numbering Turing Programs Pe
Deﬁnition 1.5.1. (Indices of Turing Programs). Since each Turing pro-
gram is a ﬁnite set of quintuples, we can list all Turing programs in such
a way that for any program we can eﬀectively ﬁnd its number on the list,
and conversely. Use the G¨odel numbering of the Notation Section.
(i) Let Pe be the Turing program with code number e in this coding, also
called the G¨odel number or index e.
(ii) Let ϕ(n)
e
be the partial function of n variables computed by Pe. Let
ϕe denote ϕ(1)
e . We call ϕe a partial computable (p.c.) function. From now
on we identify the Turing program Pe and p.c. function ϕe with index e.
(Some recent books use upper case Φe instead of ϕe, but this will cause no
diﬃculty.)
This is called the standard numbering or canonical numbering of Turing
programs and partial computable functions. By Exercise 1.7.8, any other
eﬀective numbering will be computably isomorphic to this one.
Lemma 1.5.2 (Padding Lemma).
Each partial computable (p.c.) function
ϕx has inﬁnitely many indices. Furthermore, for each x we can eﬀectively
ﬁnd an inﬁnite set Ax of indices for the same partial function (i.e., ϕy = ϕx
for all y ∈Ax).
Proof. Given ϕx, we consider the associated Turing machine Px. If Turing
program Px mentions only internal states {q0, . . . , qn}, add extraneous in-
structions qn+1B qn+1B R, qn+2B qn+2B R, . . . to get new programs for
the same function.
1.5.2
Numbering Turing Computations
In (1.2) we described an (instantaneous) conﬁguration, now denoted by c
below, of a Turing machine M at a given stage v during the computation:
(1.3)
c
=
t qi s1 s
where s1 is the symbol being scanned, t = tw . . . t2 t1 represents the se-
quence of symbols on the tape to the left of s1, and s = s2 . . . sv is the
sequence of symbols on the tape to the right of s1. Since the reading head
moves at most one square at every stage, the sequences t, s and s1 include
the symbols in any cell which has been scanned up to stage v. For example,
M always starts in the initial conﬁguration
(1.4)
c1
=
q1 s1s2 . . . sk+1
i.e., in the starting state q1, reading the ﬁrst symbol s1 of the input of k+1
consecutive 1’s representing integer k. As soon as M (if ever) reaches at

1.5.
⋆⋆The Basic Results
11
stage v a conﬁguration ci which contains the halting state q0,
(1.5)
tw . . . t2 t1 q0 s1 s2 . . . sv,
M outputs the total number of 1’s among the tape symbols in (1.5); it turns
oﬀ; and it never enters another conﬁguration. In this case M converges on
its input. However, M may either go on forever, entering inﬁnitely many
diﬀerent conﬁgurations, or loop through ﬁnitely many inﬁnitely often, or
else stall at some conﬁguration ci if its Turing program Pe (being only a
partial set of instructions) gives it no option to enter another conﬁgura-
tion ci+1. In the latter three cases M diverges on its input. By choosing
from the Turing program Pe the ﬁrst possible move (if any), we can ensure
that the passage of M through conﬁgurations c1, c2, . . . is deterministic.
(We asked that the program be a partial function so it is deterministic, but
if it had been nondeterministic we could have made it deterministic in this
fashion.) Hence, from every ci there is at most one consequent conﬁguration
ci+1.
This action of a Turing machine in passing through an eﬀective sequence
of conﬁgurations can now be coded by G¨odel numbers as follows. A con-
ﬁguration c of the form (1.3) is a ﬁnite sequence of symbols. Once we have
assigned numbers to each tape symbol si and state qj, we can assign a
number to every conﬁguration using the prime power equation (1) of the
Notation Section. If the sequence results in a conﬁguration in the halting
state q0 then the resulting sequence of conﬁgurations is a computation.
1.5.3
The Enumeration Theorem and Universal Machine
In §1.1.2 we showed that there could be no eﬀective enumeration of all total
computable functions. However, the eﬀective numbering in the preceding
subsections for the syntax of Turing machines allows us to now give an
eﬀective enumeration of all partial computable functions. This result is
crucial in virtually all our theorems.
Theorem 1.5.3 (Enumeration Theorem and Universal Machine).
There
is a partial computable (p.c.) function of two variables ψ(e, x) such that
ψ(e, x) = ϕe(x). By TT there is some i such that ϕi(e, x) = ψ(e, x).
Proof. A Turing machine M(e, x) which computes ψ(e, x) is called a uni-
versal Turing machine. We give the instructions in ordinary mathematical
notation but by TT they can be performed by a Turing machine.
Step 1.
Given the pair of inputs (e, x) convert e to the Turing program
Pe by using the numbering of Turing programs in Deﬁnition 1.5.1 and
unique factorization to recover the exponents in (1) of the prime power
representation in the Notation section.
Step 2.
Simulate the action of Pe on input x. The simulation begins
with state q1 on the leftmost symbol of x in standard input form. If the
simulation is in state qj reading symbol sk, then M searches through the

12
1. Deﬁning Computability
tuples in Pe until it ﬁnds the ﬁrst of the form (qj, sk, q, t, X) and then
performs the indicated action on the simulation tape.
Remark 1.5.4. The Enumeration Theorem 1.5.3 is crucial for all our work.
For example, to show that a set A is undecidable we must show that χA ̸=
ϕe for all e. That requires eﬀectively listing all algorithmic partial functions
{ϕe}e∈ω. In 1936 Turing approached this in machine fashion by explicitly
specifying a universal machine, “a single machine which can compute any
computable sequences.” Turing’s universal machine took as input a number
x and a Turing program, which in our notation would be a ﬁnite sequence
of 5-tuples for the Turing program, and his machine performed as in step 2
above.
1.5.4
The Parameter Theorem or s-m-n Theorem
Theorem 1.5.5 (Parameter Theorem or s-m-n Theorem). There is a 1:1
computable function s(x, y) such that for all x, y, and z,
ϕs(x,y) (z) = ϕx (y, z).
Proof. (informal). The algorithm for Turing program Ps(x,y) on input z ﬁrst
obtains program Px by inverting the coding1 of Turing programs in §1.5.1,
and then applies Px to input (y, z). This procedure deﬁnes an algorithm
with inputs x and y. By TT it has a Turing machine index s(x, y). It is
easy to check that s(x, y) is already 1:1. However, instead of checking we
may replace s(x, y) by an obviously 1:1 computable function s′(x, y) such
that ϕs′(x,y) = ϕs(x,y) by using the Padding Lemma 1.5.2 and by deﬁning
s′(x, y) in increasing order of ⟨x, y⟩, where ⟨x, y⟩is the image of (x, y) under
the standard pairing function.
Remark 1.5.6 (Intuition for Parameter Theorem). The Parameter Theo-
rem 1.5.5 asserts that y may be treated as a ﬁxed parameter in the program
Ps(x,y) which operates on z, and furthermore that the index s(x, y) of this
program is computable in x and y. Suppose ϕx(y, z) = y+z. Fix the param-
eter as y = 3 and consider the resulting function f(z) = ϕx(3, z) = 3 + z.
Now f(x) is computable and must have some index ϕi(z) = f(z). The
Parameter Theorem shows that we can pass computably from x and the
parameter y to such an index i for f(z).
1The Parameter Theorem is often stated for an m-tuple (y1, y2, . . . ym) and an n-
tuple (z1, z2, . . . zn). Then the function s is called sm
n (x, −
→
y ), which gives the theorem its
name. Here m = n = 1 and the function is s(x, y) = s1
1(x, y). By the pairing function
(2) we can identify the m-tuple of −
→
y with a single y and likewise the n-tuple −
→
z with a
single z. We achieve notational convenience without loss of generality.

1.6.
⋆⋆Unsolvable Problems
13
Theorem 1.5.7 (Unbounded Search Theorem). If θ(x, y) is a partial
computable function, and
(1.6)
ψ(x) = (µy) [ θ(x, y)↓= 1
&
(∀z < y) [ θ(x, z)↓̸= 1 ] ],
then ψ(x) = y is a partial computable function.
Proof. For a ﬁxed x compute θ(x, y) in order of y as follows. For ﬁxed s
compute s steps for each y ≤s and then go to step s + 1. Continue until
(if ever) the ﬁrst y is found such that θ(x, y)↓= 1. Output ψ(x) = y.
Here ψ(x) diverges if there is no such y. Note that this applies if θ is
total, but we cannot eﬀectively determine whether θ is total. Therefore, we
state it more generally as above. The second conjunct is necessary for ψ to
be partial computable as noted in Exercise 1.6.28.
1.6
⋆⋆Unsolvable Problems
Convention 1.6.1.
If R ⊆ωn,
n ≥1, then R has property P if the
set {⟨x1, . . . , xn⟩: R(x1, x2, . . . , xn)} has property P, such as being com-
putable, c.e., Σ1, etc. (Note that this agrees with the Deﬁnition 2.3 of R
being computable iﬀthe characteristic function χR is computable.)
1.6.1
Computably Enumerable Sets
Deﬁnition 1.6.2. (i) A set A is computably enumerable (c.e.) if A is the
domain of some partial computable (p.c.) function.
(ii) Let the eth c.e. set be denoted by
(1.7)
We :=
dom(ϕe) = { x : ϕe(x)↓}.
Note that any computable set is c.e. since if A is computable, then
A = dom(ψ), where ψ(x) = 1 if the characteristic function χA(x) = 1 and
ψ(x)↑otherwise. We shall show in Theorem 2.1.10 that a nonempty set A is
c.e. iﬀA is the range of a computable function (i.e., iﬀthere is an algorithm
for listing the members of A). The frequent occurrence of c.e. sets in other
branches of mathematics and the existence of noncomputable c.e. sets such
as K below have yielded numerous undecidability results, such as the Davis-
Matijaseviˇc-Putnam-Robinson resolution of Hilbert’s tenth problem on the
unsolvability of certain Diophantine equations, and the Boone-Novikov
theorem on the unsolvability of the word problem for ﬁnitely presented
groups.
1.6.2
Noncomputable C.E. Sets
Deﬁnition 1.6.3. Let K := { x : ϕx(x) converges } = { x : x ∈Wx }.

14
1. Deﬁning Computability
Theorem 1.6.4. K is c.e.
Proof. K is the domain of the following p.c. function:
ψ(x) =
(
x
if ϕx(x) converges
undeﬁned
otherwise.
Now ψ is p.c. because ψ(x) can be computed by applying program Px
to input x and giving output x only if ϕx(x) converges. Alternatively, and
more formally, K = dom(θ), where θ(x) = ϕ(2)
z (x, x) for ϕ(2)
z
the p.c.
function deﬁned in the Enumeration Theorem 1.5.3.
Theorem 1.6.5. K is not computable.
Proof. If K had a computable characteristic function then the following
function would be computable:
f(x) =



ϕx(x) + 1
if x ∈K,
0
if x /∈K.
However, f cannot be computable because f ̸= ϕx for every x.
Therefore, there is no algorithm for deciding on a given input x whether
x ∈K. This is our ﬁrst example of an unsolvable problem.
Deﬁnition 1.6.6. K0 = { ⟨x, y⟩: x ∈Wy }.
Note that K0 is also c.e. Indeed, K0=dom(θ), where θ(⟨x, y⟩) = ϕ(2)
z (y, x)
for ϕ(2)
z
as in the Enumeration Theorem 1.5.3.
Corollary 1.6.7. K0 is not computable.
Proof. Note that x ∈K iﬀ⟨x, x⟩∈K0. Thus if K0 has a computable
characteristic function, so does K, contrary to Theorem 1.6.5.
The halting problem is to decide for arbitrary x and y whether ϕy(x)
converges, i.e., whether ⟨x, y⟩∈K0. Corollary 1.6.7 asserts the unsolvability
of the halting problem. The proof of the corollary suggests an indirect
method for proving unsolvability of new problems by reducing K to them.
Deﬁnition 1.6.8. (i) A is many-one reducible (m-reducible) to B (written
A ≤m B) if there is a computable function f such that f(A) ⊆B and
f(A) ⊆B, i.e., x ∈A iﬀf(x) ∈B.
(ii) A is one-one reducible (1-reducible) to B (A ≤1 B) if A ≤m B by a
1:1 computable function.
For example, the proof of Corollary 1.6.7 established that K ≤1 K0 via
the function f(x) = ⟨x, x⟩. Note that if A ≤m B via f then A ≤m B via f
also. It is obvious that ≤m and ≤1 are reﬂexive and transitive, and hence
induce the following equivalence relations.

1.6.
⋆⋆Unsolvable Problems
15
Deﬁnition 1.6.9. Deﬁne equivalence relations and degrees as follows.
(i) A ≡m B if A ≤m B and B ≤m A.
(ii) A ≡1 B if A ≤1 B and B ≤1 A.
(iii) degm(A) = {B : A ≡m B}.
(iv) deg1(A) = {B : A ≡1 B}.
The equivalence classes under ≡m and ≡1 are called the m-degrees and
1-degrees respectively.
Proposition 1.6.10. If A
≤m
B and B is computable then A is
computable.
Proof. If A ≤m B via f, then χA(x) = χB(f(x)), so χA is computable if B
is computable.
We often write A(x) for the characteristic function χA(x). Proposi-
tion 1.6.10 provides a technique for proving the unsolvability of numerous
problems, such as those of deciding, given x, whether ϕx is a constant func-
tion, a total function, whether dom(ϕx) ̸= ∅, whether ϕx is extendible to
a total computable function, and so on. If we can reduce one unsolvable
problem A to another one B, then B is also unsolvable.
Theorem 1.6.11. K ≤1 Tot := {x : ϕx is a total function}.
Proof. Deﬁne the function:
ψ(x, y) =



1
if x ∈K;
undeﬁned
otherwise.
Clearly, ψ is p.c. because the program to compute ψ(x, y) says: ﬁrst
attempt to compute ϕx(x); if this fails to converge then output nothing; if
it converges then output 1 for every argument y. By the Parameter Theorem
there is a 1:1 computable function f such that ϕf(x)(y) = ψ(x, y). Namely,
choose e such that ϕe(x, y) = ψ(x, y), and deﬁne f(x) = λx[s1
1(e, x)]. Now
f is 1:1 because s1
1 is 1:1. Note that
x ∈K =⇒ϕf(x) = λy[ 1 ] =⇒ϕf(x) total =⇒f(x) ∈Tot, and
x /∈K =⇒ϕf(x) = λy [ ↑] =⇒ϕf(x) not total =⇒f(x) /∈Tot.
Notice that this proof shows that the problem of deciding, given x,
whether ϕx is constant, or even whether dom(ϕx) ̸= ∅, is an unsolvable
problem. Notice also that in this proof K could be replaced by an arbi-
trary c.e. set A. Suppose A = dom (θ) for θ p.c. Then the program begins
by attempting to compute θ(x) in place of ϕx(x). However, we could not

16
1. Deﬁning Computability
replace K by an arbitrary non-c.e. set A because there would be no com-
putable counterpart to this ﬁrst step in the program for ψ, and ψ must be
computable.
Applications of the Parameter Theorem 1.5.5 such as the one above will
occur often. The reader should verify in each case that the instructions for
computing ψ(x, y) are eﬀective. From now on we can simply write ϕf(x)(y)
for ψ(x, y) without explicitly mentioning the Parameter Theorem 1.5.5.
The method in the above proof applies to numerous other sets A in place
of Tot so long as the property deﬁning A is a property of functions and
not of certain indices for them, for example, if A is an index set deﬁned as
follows.
Deﬁnition 1.6.12. A set A ⊆ω is an index set if for all x and y
[ x ∈A
&
ϕx = ϕy ]
=⇒
y ∈A.
1.6.3
The Index Set Theorem and Rice’s Theorem
Theorem 1.6.13 (Index Set Theorem).
If A is a nontrivial index set,
i.e., A ̸= ∅, A ̸= ω, then either K ≤1 A or K ≤1 A. Furthermore, choose
e0 such that ϕe0(y) is undeﬁned for all y. If e0 ∈A, then K ≤1 A.
Proof. If e0 ∈A, then K ≤1 A as follows. (If e0 ∈A, then K ≤1 A
similarly.) Since A ̸= ∅we can choose e1 ∈A. Now ϕe1 ̸= ϕe0 because A
is an index set. By the Parameter Theorem 1.5.5 deﬁne a 1:1 computable
function f such that
ϕf(x)(y) =



ϕe1(y)
if x ∈K
undeﬁned
if x /∈K.
Now
x ∈K
=⇒
ϕf(x) = ϕe1
=⇒
f(x) ∈A,
x ∈K
=⇒
ϕf(x) = ϕe0
=⇒
f(x) ∈A.
The last implication in each line follows because A is an index set.
Corollary 1.6.14 (Rice’s Theorem).
Let C be any class of partial com-
putable functions. Then A = {n : ϕn ∈C} is computable iﬀC = ∅or C is
the class of all partial computable functions.
Proof. By deﬁnition, A is an index set. If A = ∅or A = ∅, then trivially
A is computable. Otherwise, the Index Set Theorem 1.6.13 implies that
K ≤1 A or K ≤1 A. Therefore, A is not computable.
(Rice’s results on c.e. sets can be found in [Rice 1953] and [Rice 1956].) It
is possible that both K ≤1 A and K ≤1 A for an index set A, for example
if A = Tot.

1.6.
⋆⋆Unsolvable Problems
17
Deﬁnition 1.6.15. In addition to K and K0, which are not index sets
(see Exercise 2.2.8), we shall use the following index sets which correspond
to the natural unsolvable problems mentioned above.
K1
=
{x : Wx ̸= ∅};
Fin
=
{x : Wx is ﬁnite};
Inf
=
{x : Wx is inﬁnite}
= ω −Fin;
Tot
=
{x : ϕx is total} = { x : Wx = ω };
Con
=
{x : ϕx is total and constant};
Cof
=
{x : Wx is coﬁnite};
Rec
=
{x : Wx is computable (recursive)};
Ext
=
{x : ϕx is extendible to a total computable function}.
Of the above index sets, K1, Fin, Inf, Tot, Cof, and Rec turn out to be the
most important in later work. Each of the above is a nontrivial index set and
hence noncomputable by the Index Set Theorem 1.6.13. Only K, K0 and
K1 are c.e. sets, and these all have the same 1-degree (see Exercise 1.6.22).
Hence, by Theorem 1.7.4 these three are all computably isomorphic and
may be regarded as interchangeable for all our purposes.
Deﬁnition 1.6.16. A c.e. set A is 1-complete if We ≤1 A for every c.e.
set We.
Clearly, K0 is 1-complete because x ∈We iﬀ⟨x, e⟩∈K0. Thus, K
and K1 are 1-complete by Exercise 1.6.22. The remaining index sets above
(and their complements) are not c.e. as we shall see in §2.1. However, in
Chapter 4 we shall show that
Inf ≡1 Tot ≡1 Con
and
Cof ≡1 Rec ≡1 Ext.
A major goal of computability theory is to classify exactly how unsolvable
a problem is by computing its “degree” of unsolvability relative to other
problems. For example, if A ≡r B, where r = 1, m or the more general
Turing (T) reducibility of Chapter 3, then A and B have the same r-degree
and intuitively they “code the same information.” If A <r B, then B has
strictly higher r-degree than A and codes more information.
In Chapter 4 we shall give another characterization of these sets in terms
of the arithmetical hierarchy. For each n ∈ω, we shall have a level in
the hierarchy consisting of sets of the same T-degree. For example, the
computable sets lie at level 0; the sets K, K0, and K1 at level 1; Inf, Con
and Tot at level 2; Cof, Rec, and Ext at level 3; and so on. The sets at
higher levels have strictly higher T-degree than those at lower levels.
1.6.4
Computable Approximations to Computations
Deﬁnition 1.6.17. We write ϕe,s(x) = y if x, y, e < s and y is the output
of ϕe(x) in < s steps of the Turing program Pe. If such a y exists we say

18
1. Deﬁning Computability
ϕe,s(x) converges, which we write as ϕe,s(x) ↓, and diverges (ϕe,s(x) ↑)
otherwise. Similarly, we write ϕe(x) ↓if ϕe,s(x) ↓for some s and we write
ϕe(x)↓= y if ϕe(x)↓and ϕe(x) = y, and similarly for ϕe,s(x)↓= y. Deﬁne
We,s := dom(ϕe,s).
(If x ∈We,s then x, e < s by Deﬁnition 1.6.17.) Note that ϕe(x) = y iﬀ
(∃s) [ϕe,s(x) = y] and x ∈We iﬀ(∃s) [x ∈We,s].
Theorem 1.6.18. (i) The set { ⟨e, x, s⟩: ϕe,s(x)↓} is computable, as is
the set We,s = dom(ϕe,s).
(ii) The set {⟨e, x, y, s⟩: ϕe,s(x) = y} is computable.
Proof. We get (i) and (ii) because we calculate until an output is found or
until the ﬁrst s steps have been completed.
We often use the following operation of join to construct a set which
codes two given sets A and B and we use it in the exercises below.
Deﬁnition 1.6.19. Let A join B, written A ⊕B, be
{2x : x ∈A} ∪{2x + 1 : x ∈B}.
1.6.5
Exercises
Exercise 1.6.20. Let B = A⊕A for some set A ⊂ω. Prove that B ≤1 B.
Exercise 1.6.21. Prove that the m-degree of A ⊕B is the least upper
bound (lub) of the m-degrees of A and B, i.e.,
(i) A ≤m A ⊕B and B ≤m A ⊕B; and
(ii) if A ≤m C and B ≤m C then A ⊕B ≤m C. (It is false that 1-degrees,
even of c.e. sets, always have an lub or a greatest lower bound (glb).)
Exercise 1.6.22. Prove that K ≡1 K0 ≡1 K1. (Note that the proof of
Theorem 1.6.11 automatically shows that K ≤1 A for A = K1, Con, or
Inf.)
Exercise 1.6.23. Prove that K ≤1 Fin without using the Index Set The-
orem 1.6.13. (In Chapter 4 we shall show that K is Σ1-complete and Fin
is Σ2-complete and that any Σ1 set is m-reducible to any complete Σ2 set.
This gives an alternate proof.)
Exercise 1.6.24. For any x show that K ≤1 {y : ϕx = ϕy}, and also
prove that K ≤1 {y : Wx = Wy}. Hint. Consider separately the cases
Wx ﬁnite and inﬁnite, and use the method of Exercise 1.6.23. (Also see
Exercise 2.4.13 (ii) to see that this reduction cannot be made uniform.)
Exercise 1.6.25. Give a direct construction that Ext ̸= ω. Hence, not
every partial computable function is extendible to a total computable
function.

1.7.
⋆Computable Permutations and Isomorphisms
19
Exercise 1.6.26. Disjoint sets A and B are computably inseparable if there
is no computable set C such that A ⊆C and C ∩B = ∅, and computably
separable otherwise. (The existence of computable inseparable sets is very
useful, for example, in model theory.) Deﬁne A := { x : ϕx(x) = 0 } and
B := { x : ϕx(x) = 1 }.
(i) Prove that A and B are computably inseparable by showing that no
ϕe is the characteristic function of a separating set C.
(ii) Give an alternative proof that Ext ̸= ω.
(iii) For A and B as in part (i), prove that K ≡1 A and K ≡1 B.
There is a stronger notion called eﬀectively inseparable deﬁned in Exer-
cise 2.4.17. Eﬀectively inseparable sets are computably inseparable but not
vice versa. The sets A and B deﬁned here are in fact eﬀectively inseparable.
Exercise 1.6.27. A set A is a cylinder if (∀B) [ B ≤m A
=⇒
B ≤1 A ].
(i) Show that any index set is a cylinder.
(ii) Show that any set of the form A × ω is a cylinder. (Recall that X × Y
is the Cartesian product introduced in the Notation section.)
(iii) Show that A is a cylinder iﬀA ≡1 B × ω for some set B.
Exercise 1.6.28. The partial computable functions are not closed under
µ. Prove that there is a p.c. function θ such that λx [ µy [ ψ(x, y) = 1 ] ]
is not p.c.
Exercise 1.6.29. If A is computable and B and B are each ̸= ∅, prove
that A ≤m B. (Hence, neglecting the trivial sets ∅and ω, there is a least
m-degree.)
1.7
⋆Computable Permutations and Isomorphisms
Deﬁnition 1.7.1. (i)
A computable permutation is a 1:1 computable
function from ω onto ω.
(ii) A property of sets is computably invariant if it is invariant under all
computable permutations.
Examples of computably invariant properties are the following:
(i) A is c.e.;
(ii) A has cardinality n (written |A| = n);
(iii) A is computable.
The following properties are not computably invariant:
(i) 2 ∈A;
(ii) A contains the even integers;

20
1. Deﬁning Computability
(iii) A is an index set.
Deﬁnition 1.7.2. A is computably isomorphic to B (written A ≡B) if
there is a computable permutation p such that p(A) = B.
Deﬁnition 1.7.3. The equivalence classes under ≡are called computable
isomorphism types.
We shall attempt to classify sets up to computable isomorphism just
as the algebraist classiﬁes structures up to isomorphism. One reason for
introducing ≤1 in Deﬁnition 1.6.8 (where ≤m would have suﬃced for un-
decidability results) is the following theorem, which is an eﬀective analogue
of the classical Schr¨oder-Bernstein Theorem for cardinal numbers.
1.7.1
Myhill Isomorphism Theorem
Theorem 1.7.4 (Myhill Isomorphism Theorem).
A ≡B iﬀA ≡1 B.
(Indeed, we prove more in Exercise 1.7.7.)
Proof. ( =⇒). Trivial.
( ⇐= ). Let A ≤1 B via f and B ≤1 A via g. Therefore,
(1.8)
(∀x)(∀y) [ x ∈A ⇐⇒f(x) ∈B
&
y ∈B ⇐⇒g(y) ∈A ].
We deﬁne a computable permutation h by stages s ∈ω so that h(A) = B.
Suppose that by the end of stage 2s we have ﬁnite sets X = {x1, x2, . . . xn}
(on the left-hand side) and Y = {y1, y2, . . . yn} (on the right-hand side)
and a 1:1 map h such that h(xi) = yi for all 1 ≤i ≤n such that
(1.9)
(∀x ∈X) [ x ∈A
⇐⇒
h(x) ∈B ].
Stage 2s + 1.
We shall deﬁne h(s) if it is not already deﬁned. Compute
f(s) = t1. If t1 ̸∈Y deﬁne h(s) = t1. If t1 ∈Y , say t1 = yi, then take
xi = h−1(t1). Note that xi ∈A iﬀs ∈A by (1.8) and (1.9). Compute
f(xi) = t2. If t2 ̸∈Y deﬁne h(s) = t2. Otherwise, t2 = yj for some j. Take
xj = h−1(yj) and note that xj ∈A iﬀs ∈A as before. Compute f(xj) = t3.
If t3 ̸∈Y deﬁne h(s) = t3. Otherwise, t3 = yi for some i. Take xi = h−1(yi)
and note that xi ∈A iﬀs ∈A as before. Compute f(xi) = t4. Continue
in this fashion until a new element z ̸∈Y is found and deﬁne h(s) = z.
Note that X ∪{s} has n+1 elements but Y has only n elements, so the
procedure must terminate.
Stage 2s + 2. Find the value of h−1(s) in similar fashion using h−1 and g
in place of h and f.
Note that the sets A and B may be highly noncomputable. All we have
are the maps f and g and (1.8).

1.7.
⋆Computable Permutations and Isomorphisms
21
1.7.2
Acceptable Numberings
Deﬁnition 1.7.5. (Acceptable Numbering Conditions). Let P be the class
of partial computable functions of one variable.
(i) A numbering of the p.c. functions is a map π from ω onto P.
(ii) The numbering {ϕe}e∈ω of Deﬁnition 1.5.1 is called the standard
numbering or canonical numbering of the partial computable functions.
(iii) Let bπ be another numbering and let ψe denote bπ(e). Then bπ is an
acceptable numbering if there are computable functions f and g such that
(1) ϕf(x) = ψx, and (2) ψg(x) = ϕx.
The following result is important because most obvious numberings are
acceptable and any two acceptable numberings diﬀer merely by a com-
putable permutation. Therefore, it will not matter exactly which acceptable
numbering we chose originally.
Theorem 1.7.6 (Acceptable Numbering Theorem, Rogers).
For any
acceptable numbering {ψe}e∈ω of the partial computable functions, there is
a computable permutation h of ω such that ϕe = ψh(e) for all e.
Proof. Assume that {ψe}e∈ω is an acceptable numbering of the p.c. func-
tions. Let f and g satisfy (1) and (2) of Deﬁnition 1.7.5 (iii). The proof will
follow from several other results and exercises to be considered later. First
prove the Generalized Isomorphism Theorem 1.7.7 so that h exists if both
f and g can be replaced by one-one functions f1 and g1. Second, ﬁnd f1
as in Exercise 1.7.8 and g1 as in Theorem 2.3.9. Complete the proof as in
Corollary 2.3.10.
1.7.3
Exercises
Exercise 1.7.7. (Generalized Isomorphism Theorem). Let ω = S
n An =
S
n Bn where the sequences {An}n∈ω and {Bn}n∈ω are each pairwise dis-
joint. Let f and g be 1:1 computable functions such that f(An) ⊆Bn
and g(Bn) ⊆An for all n. Show that the construction of the Myhill Iso-
morphism Theorem 1.7.4 produces a computable permutation h such that
h(An) = Bn for all n.
Exercise 1.7.8. (Rogers). Fill in the steps of the proof of the Acceptable
Numbering Theorem 1.7.6 as follows.
(i) First use the Padding Lemma 1.5.2 to show that we may replace f by
a 1:1 function f1 if necessary.
(ii) In Theorem 2.3.9 we shall prove that we may also replace g by a 1:1
computable function g1 if necessary. Assuming g1 for now, use Exercise 1.7.7
and the 1:1 functions f1 and g1 to obtain the computable permutation h.

22
1. Deﬁning Computability
Exercise 1.7.8 is important because it proves that any acceptable num-
bering of Turing programs is as good as the one we chose in Deﬁnition 1.7.5
because the two numberings are computably isomorphic. Exercise 1.7.9
gives an example where the function f of Exercise 1.7.8 (i) is computable
but the function g of Exercise 1.7.8 (ii) is not. Although the classes of func-
tions {ψe}e∈ω and {ϕe}e∈ω both constitute the class of p.c. functions, the
former are “hidden” so that we cannot eﬀectively ﬁnd the p.c. function
ψg(e) which corresponds to the standard function ϕe.
Exercise 1.7.9. Obtain an eﬀective numbering ψ which is not acceptable
as follows. Deﬁne
ψ⟨0,q⟩(0)
=
undeﬁned
ψ⟨p+1, q⟩(0)
=
p
ψ⟨p,q⟩(x)
=
ϕq(x),
if x > 0.
Show that {ψn}n∈ω = P but that ψ is not acceptable. Hint. Show that if
there is a computable function g such that ψg(x) = ϕx then we can decide
the halting problem. (For an alternative example deﬁne a computable func-
tion f such that {ϕf(p) : p ∈ω} consists of exactly the partial functions
with nonempty domain and let ψp+1 = ϕf(p), ψ0(y) = λy [ ↑].)

2
Computably Enumerable Sets
2.1
⋆⋆Characterizations of C.E. Sets
This chapter is intended to give the reader a more intuitive feeling for c.e.
sets, their alternative characterizations, and their most useful static and
dynamic properties. We also prove the Recursion Theorem 2.2.1 (Fixed
Point Theorem), which will be a very useful tool, and we apply it to prove
Myhill’s Theorem 2.4.6 that all creative sets are computably isomorphic.
In Deﬁnition 1.6.2 we deﬁned a set A to be computably enumerable (c.e.)
if it is the domain of a partial computable function ϕe. This immediately
gave an eﬀective numbering of c.e. sets We = dom(ϕe) in (1.7) of Chapter 1.
In this chapter we present two other particularly useful characterizations
of c.e. sets: the Σ0
1 quantiﬁer characterization in Theorem 2.1.3; and the
Listing Theorem 2.1.10, which says that A is c.e. iﬀit can be eﬀectively
listed (enumerated). Recall our Convention 1.6.1 that a relation R ⊆ωn is
said to have some property P (such as being computable, c.e., or Σ0
1) iﬀ
the set A = {x : R(x)} has property P.
2.1.1
The Σ0
1 Normal Form for C.E. Sets
Deﬁnition 2.1.1. (i) A set A is a projection of some relation R ⊆ω × ω
if A = {x : (∃y) R(x, y)} (i.e., geometrically A is the projection of the
two-dimensional relation R onto the x-axis).
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_2 
23 

24
2. Computably Enumerable Sets
(ii) A set A is in Σ0
1-form, abbreviated A is Σ0
1, if A is the projection of
some computable relation R ⊆ω × ω.
Convention 2.1.2.
The reason for the notation Σ0
1 is that the corre-
sponding predicate for A has the form of one ∃quantiﬁer followed by a
computable predicate. The forms Σ0
n, Π0
n, and ∆0
n, n ≥0, will be formally
deﬁned in Chapter 4 on the arithmetical hierarchy. The superscript 0 in-
dicates that the quantiﬁers range over integers, but later we shall usually
drop it according to Convention 4.1.1.
Theorem 2.1.3 (Normal Form Theorem for C.E. Sets).
A set A is c.e.
iﬀA is Σ0
1.
Proof. ( =⇒). If A is c.e. then A = We := dom(ϕe) for some e. Hence,
x ∈We
⇐⇒
(∃s) [ x ∈We,s ].
By Theorem 1.6.18 the relation { ⟨e, x, s⟩: x ∈We,s } is computable.
( ⇐= ). Let A = { x : (∃y) R(x, y) }, where R is computable. Then A =
dom(ψ) where ψ(x) = (µy) R(x, y).
Deﬁnition 2.1.4. If A = We then e is a Σ0
1-index or c.e.-index for A.
Theorem 2.1.5 (Quantiﬁer Contraction Theorem).
A is Σ0
1 iﬀthere is
an n ∈ω and a computable relation R ⊆ωnS+1 such that
A = {x : (∃y1) · · · (∃yn) R(x, y1, . . . , yn)}.
Proof. Deﬁne the computable relation S ⊆ω2 by
S(x, z) ⇐⇒dfn R(x, (z)1, (z)2, . . . , (z)n),
where z = p(z)0
0
p(z)1
1
· · · p(z)n
n
is the prime decomposition.
(∃z) S(x, z)
⇐⇒(∃z) R(x, (z)1, (z)2, . . . , (z)n)
⇐⇒(∃y1)(∃y2) · · · (∃yn) R(x, y1, y2, . . . , yn).
(Choose any computable function which maps an n-tuple (x1, . . . , xn) to a
unique y.)
Corollary 2.1.6. The projection of a c.e. relation is c.e.
Deﬁnition 2.1.7. (i) The graph of a (partial) function ψ is the relation
(2.1)
graph (ψ) = { (x, y) : ψ(x)↓= y }.
(ii) Partial functions ψ and θ are equal, ψ = θ, if graph (ψ) = graph (θ).
It follows from Theorem 2.1.5 or Corollary 2.1.6 that a set A is c.e. if A
is of the form
{ x : (∃y1) . . . (∃yn) R(x, y1, . . . , yn) },

2.1.
⋆⋆Characterizations of C.E. Sets
25
where n ∈ω and R ⊆ωn+1 is computable. This is very useful for showing
various sets to be c.e. For example, using this to handle the (∃) quantiﬁers
and using Theorem 1.6.18 to see that the matrices are computable, it is
easy to check that the following sets and relations are c.e.
K = {e : e ∈We} = {e : (∃s) (∃y) [ ϕe,s(e) = y ]},
(2.2)
K0 = {⟨x, e⟩: x ∈We} = {⟨x, e⟩: (∃s) (∃y) [ ϕe,s(x) = y ]},
(2.3)
K1 = {e : We ̸= ∅} = {e : (∃s) (∃x) [ x ∈We,s ]},
(2.4)
rng (ϕe) = {y : (∃s) (∃x) [ϕe,s(x) = y]},
(2.5)
graph (ϕe) = {(x, y) : (∃s) [ϕe,s(x) = y]}.
(2.6)
2.1.2
The Uniformization Theorem
Theorem 2.1.8 (Uniformization Theorem).
If R ⊆ω2 is a c.e. relation,
then there is a p.c. function ψ (called a selector function for R) such that
ψ(x) is deﬁned
⇐⇒(∃y) R(x, y),
and in this case (x, ψ(x)) ∈R. (Furthermore, an index for ψ can be found
computably from a c.e. index for R.)
Proof. Since R is c.e. and hence Σ0
1, there is a computable relation S such
that R(x, y) holds iﬀ(∃z) S(x, y, z). Deﬁne the p.c. function
θ(x) = (µu) S(x, (u)1, (u)2)
and deﬁne ψ(x) = (θ(x))1.
The important thing to grasp about the Uniformization Theorem is not
that ψ exists (which is obvious) but that ψ is partial computable.
Theorem 2.1.9 (Graph Theorem).
A partial function ψ is partial
computable iﬀits graph is computably enumerable.
Proof. ( =⇒). The graph of ψ is c.e. by Theorem 2.1.3 and (2.6).
( ⇐= ). If the graph of ψ is c.e., then ψ is its own p.c. selector function
in Deﬁnition 2.1.7 because R = graph (ψ) can have only ψ as its selector
function.
The following is the basic theorem on c.e. sets, and justiﬁes the earlier
intuitive description of a c.e. set A as one whose members can be eﬀectively
listed, A = { a0, a1, a2, . . . }. (Note that the listing may have repetitions and
need not be in increasing order.)

26
2. Computably Enumerable Sets
2.1.3
The Listing Theorem for C.E. Sets
Theorem 2.1.10 (Listing Theorem).
A set A is c.e. iﬀA = ∅or A is
the range of a total computable function f. Furthermore, f can be found
uniformly in an index for a nonempty A as explained in Exercise 2.1.24.
Proof. ( ⇐= ). If A = ∅, then A is c.e. Now suppose A = rng (f), where
f is a total computable function. Then A is c.e. by (2.5).
( =⇒).
Let A = We ̸= ∅. Choose any a ∈We. Deﬁne the computable
function f by
f(⟨s, x⟩) =
(
x
if x ∈We,s+1 −We,s;
a
otherwise.
Note that each x ∈We, x ̸= a, is listed exactly once. Clearly, A = rng (f),
because if x ∈We, we choose the least s such that x ∈We,s+1. Then
f(⟨s, x⟩) = x and hence x ∈rng (f).
2.1.4
The C.E. and Computable Sets as Lattices
Theorem 2.1.11 (Union Theorem).
The c.e. sets are closed under union
and intersection uniformly, i.e., there are computable functions f and g
such that Wf(x,y) = Wx ∪Wy and Wg(x,y) = Wx ∩Wy.
Proof. Use the Parameter Theorem 1.5.5 to deﬁne f(x, y) by enumerating
z ∈Wf(x,y) if (∃s)[z ∈Wx,s ∪Wy,s] and similarly for g with ∩in place
of ∪.
Corollary 2.1.12 (Reduction Principle for c.e. sets).
Given any two
c.e. sets A and B, there exist c.e. sets A1 ⊆A and B1 ⊆B such that
A1 ∩B1 = ∅and A1 ∪B1 = A ∪B.
Proof. Deﬁne the relation R := A × { 0 } ∪B × { 1 } which is c.e. by Theo-
rem 2.1.11. By the Uniformization Theorem 2.1.8, let ψ be the p.c. selector
function for R. Let A1 = {x : ψ(x) = 0}, B1 = {x : ψ(x) = 1}. (See also
Exercise 2.6.7.)
Deﬁnition 2.1.13. A set A is in ∆1-form, abbreviated A is ∆1, if both A
and A are Σ0
1.
The following basic theorem of Post relates c.e. sets to computable sets.
Theorem 2.1.14 (Complementation Theorem).
A set A is computable
iﬀboth A and A are c.e., i.e., iﬀA ∈∆1.

2.1.
⋆⋆Characterizations of C.E. Sets
27
Proof. ( =⇒). If A is computable, then A is computable and A and A are
both c.e.
( ⇐= ). Let A = We, A = Wi. Deﬁne the computable function
f(x) = (µs) [ x ∈We,s
or
x ∈Wi,s ].
Then x ∈A iﬀx ∈We, f(x) and hence A is computable.
Corollary 2.1.15. K is not c.e.
Proof. By Theorems 1.6.4 and 1.6.5 K is c.e. and not computable.
It is easily shown that if K ≤m A then A is not c.e. Therefore, we
can conclude that many sets such as Tot, Fin, and Cof are not c.e. (See
Exercise 2.1.17.)
Deﬁnition 2.1.16. (i) By the Union Theorem 2.1.11 the c.e. sets form
a distributive lattice E under inclusion with greatest element ω and least
element ∅,
E = ( {We}e∈ω, ∪, ∩, ∅, ω ).
(ii)
By the Complementation Theorem 2.1.14 a c.e. set A ∈E is com-
putable iﬀA ∈E. Hence, the computable sets form a Boolean algebra
C ⊂E consisting of the complemented members of E. (By Corollary 2.1.15
C ̸= E.)
2.1.5
Exercises
Exercise 2.1.17. (i) Prove that if A ≤m B and B is c.e. then A is c.e.
(ii) Show that Fin and Tot are not c.e.
(iii) Show that Cof is not c.e.
Exercise 2.1.18. Prove that if A is c.e. and ψ is p.c. then ψ(A) is c.e. and
ψ−1(A) is c.e.
Exercise 2.1.19. Let f be a total function. Prove that f is computable
iﬀits graph is computable.
Exercise 2.1.20. Prove that every inﬁnite c.e. set contains an inﬁnite
computable subset.
Exercise 2.1.21. A set A is co-c.e. (or equivalently Π0
1) if A is c.e. Use
Exercise 1.6.26 on computably inseparable sets to prove that the Reduction
Principle 2.1.12 fails for Π0
1 sets.
Exercise 2.1.22. The separation principle holds for a class C of sets if for
every A, B ∈C such that A ∩B = ∅there exists C such that C, C ∈C,
A ⊆C, and B ⊆C. By Exercise 1.6.26 the separation principle fails for

28
2. Computably Enumerable Sets
c.e. sets. Use Corollary 2.1.12 to show that the separation principle holds
for co-c.e. sets.
Exercise 2.1.23. Prove that if A ≤1 B and A and B are c.e. and A is
inﬁnite then A ≤1 B via some f such that f(A) = B.
Exercise 2.1.24. (i) Show that the proof of the Listing Theorem 2.1.10
is uniform in e in the sense that there is a p.c. function ψ(e, y) such that
if We ̸= ∅then λy [ ψ(e, y) ] is total and We = {ψ(e, y) : y ∈ω}. This
uniformity is needed, for example, in Exercise 2.6.8.
(ii) If We is inﬁnite, show that there is a total computable one-one function
f such that rng(f) = We.
2.2
⋆Recursion Theorem (Fixed Point Theorem)
2.2.1
Fixed Points in Mathematics
Fixed point theorems play an important role in mathematics. For example,
the Brouwer Fixed Point Theorem asserts that every continuous function
f from the closed unit sphere S = {x : ||x|| ≤1} to itself has a ﬁxed point
x0 in the sense that f(x0) = x0. Not every computable function f can have
a ﬁxed point x0 in this sense because the successor function f(x) = x + 1
cannot have such a ﬁxed point.
2.2.2
Operating on Indices
However, in the spirit of the s-m-n Theorem 1.5.5 let us consider the com-
putable function operating entirely on indices x of p.c. functions ϕx. It
would be too much to expect f to have a ﬁxed point n in the sense that on
Turing programs themselves Pn = Pf(n) (i.e., f(n) = n), but that is more
than we required in the Padding Lemma 1.5.2. Deﬁne Turing programs Pi
and Pj to be equivalent, written Pi ∼Pj, if ϕi = ϕj, i.e., the programs are
extensionally equivalent because they compute the same p.c. function. The
Fixed Point Theorem here asserts that every computable function f has a
ﬁxed point n such that Pn ∼Pf(n), i.e., ϕn = ϕf(n).
The following theorem of Kleene, known as the Recursion Theorem or
Fixed Point Theorem, is one of the most elegant and important results
in the ﬁeld. It shows that certain implicitly deﬁned functions are actually
computable. The proof, which uses only the s-m-n Theorem 1.5.5, is very
short but mysterious. To ensure understanding we present ﬁrst the standard
short proof in §2.2.3 and then explain the proof again in §2.2.4 as a diagonal
argument which fails.

2.2.
⋆Recursion Theorem (Fixed Point Theorem)
29
2.2.3
⋆⋆A Direct Proof of the Recursion Theorem
Theorem 2.2.1 (Recursion Theorem, Kleene).
For every computable
function f there exists an n, called a ﬁxed point of f, such that ϕn = ϕf(n).
Proof. Deﬁne the computable diagonal function d(u) by
(2.7)
ϕd(u)(z) =



ϕϕu(u)(z)
if ϕu(u) converges;
undeﬁned
otherwise.
By the s-m-n Theorem 1.5.5 d is 1:1, total, and d is independent of f.
Given f, choose an index v such that
(2.8)
ϕv = f ◦d.
We claim that n = d(v) is a ﬁxed point for f. First, note that f total
implies f ◦d = ϕv is total, so ϕv(v) converges and ϕd(v) = ϕϕv(v). Now
(2.9)
ϕn = ϕd(v) = ϕϕv(v) = ϕfd(v) = ϕf(n).
The second equality follows from (2.7) and the third follows from (2.8).
Corollary 2.2.2. For every computable function f, there exists n such
that Wn = Wf(n).
2.2.4
A Diagonal Argument Which Fails
Kleene ﬁrst discovered the Recursion Theorem 2.2.1 by trying to refute
Church’s Thesis. The failure of attempts to diagonalize out of the class
of partial computable functions helped convince him and Church of the
robustness of the class and hence of the thesis. The above proof is best
visualized as a “diagonal argument that fails” as in [Owings 1973].
Now consider the matrix whose rows are Ry = {ϕϕy(x)}x∈ω for y ∈ω.
(Here ϕϕy(x) is the undeﬁned function if ϕy(x) diverges.) The entry Ry(x)
will be denoted in the diagram by ϕy(x).

30
2. Computably Enumerable Sets
ϕ0(0)
ϕ0(1)
ϕ0(2)
ϕ0(x)
ϕ0(y)
ϕ0(v)
ϕ1(0)
ϕ1(1)
ϕ1(2)
ϕ1(x)
ϕ1(y)
. . .
ϕ1(v)
ϕ2(0)
ϕ2(1)
ϕ2(2)
ϕ2(x)
ϕ2(y)
. . .
ϕ2(v)
...
ϕy(0)
ϕy(1)
ϕy(2)
ϕy(x)
ϕy(y)
. . .
ϕy(v)
...
ϕe(0)
ϕe(1)
ϕe(2)
ϕe(x)
ϕe(y)
. . .
d(v) = Re(v)∗= ϕe(v)
...
ϕv(0)
ϕv(1)
ϕv(2)
ϕv(x)
. . .
. . .
f ◦d(v) = Rv(v)∗∗= ϕv(v)
...
Here the closure properties of the partial computable functions under the
Parameter Theorem 1.5.5 guarantee that the diagonal sequence shown as
underlined, D = {ϕϕy(y)}y∈ω, is indeed one of the rows, i.e., the eth row
Re, where ϕe(x) = d(x). That is,
(2.10)
D = {ϕϕy(y)}y∈ω = Re := {ϕϕe(x)}x∈ω = {ϕd(x)}x∈ω.
Any computable function f induces a transformation on the rows Ru =
{ϕϕu(x)}x∈ω of this matrix, mapping Ru to the row {ϕf ◦ϕu(x)}x∈ω. In par-
ticular, f maps the diagonal row Re = {ϕd(x)}x∈ω to Rv = {ϕf◦d(x)}x∈ω,
where ϕv(x) = f ◦d(x).
The key is to look at the vth column
of the matrix. Consider its in-
tersection with row Re and row Rv. Now Re = D is indeed the diagonal
sequence. Hence, Re(v), the vth element of row Re, must be ϕd(v) = ϕϕv(v),
by the choice of e and the deﬁnition of the diagonal d(v). Now Rv(v),
the vth element of row Rv, must be ϕϕv(v) by the deﬁnition of row Rv.
Since these matrix entries, Re(v)∗and Rv(v)∗∗, are equal we conclude that
ϕd(v) = ϕfd(v). (These two matrix entries have been marked with * and **
to highlight them in the diagram.) Hence, n = d(v) is a ﬁxed point for f.
An Initial Application of the Recursion Theorem
A typical application of the Recursion Theorem 2.2.1 is the following.
Corollary 2.2.3. There exists n ∈ω such that Wn = { n }.
Proof. By the Parameter Theorem 1.5.5 deﬁne Wf(x) = { x }. By the
Recursion Theorem 2.2.1 there exists n such that Wn = Wf(n) = {n}.

2.2.
⋆Recursion Theorem (Fixed Point Theorem)
31
2.2.5
Informal Applications of the Recursion Theorem
The preceding example suggests a shortcut in applying the Recursion The-
orem because the ﬁnal line has three terms connected by equality signs.
We often omit the middle term containing f and simply write, “deﬁne a
p.c. function ϕn using in advance its own index n as follows:”
(2.11)
ϕn
:=
{ . . .
n
. . . }.
This apparent circularity is removed by the Recursion Theorem 2.2.1
because we are really using the Parameter Theorem 1.5.5 to deﬁne a
computable function f(x):
(2.12)
ϕf(x)(z)
:=
{ . . .
x, z
. . . }
where the portion { . . .
x, z
. . . } is given by a procedure uniformly
computable in x and z. Finally, we apply the Recursion Theorem 2.2.1 to
get a ﬁxed point n for f(x) and combine (2.11) and (2.12) to get
(2.13)
ϕn(z)
=
ϕf(n)(z)
:=
{ . . .
n, z
. . . }.
The only restriction here is that the algorithm { . . .
x, z
. . . } in (2.12)
cannot use any special properties of ϕn, such as ϕn being total or convergent
on a particular z, but rather must apply to any ϕx even if at the end we
can show that ϕn is total.
Even though this seems technically simple, it leads to a big conceptual
advance for us in applying the Recursion Theorem 2.2.1 since from now on
we may assume we have the index before we begin to deﬁne ϕn.
2.2.6
Other Properties of the Recursion Theorem
We stated the Recursion Theorem 2.2.1 above in its simplest form although
the proof actually yields considerably more information which will be useful
and which we now state explicitly.
Proposition 2.2.4. In the Recursion Theorem 2.2.1 the ﬁxed point n can
be computed from an index for f by a 1:1 computable function g.
Proof. Let v(x) be a computable function such that ϕv(x) = ϕx ◦d. Let
g(x) = d(v(x)). Both d and v are 1:1 by the s-m-n Theorem 1.5.5.
Proposition 2.2.5. In the Recursion Theorem 2.2.1 there is an inﬁnite
computable set of ﬁxed points for f.
Proof. By the Padding Lemma 1.5.2 there is an inﬁnite c.e. set V of indices
v such that ϕv = f ◦d, but d is 1:1 so {d(v)}v∈V is inﬁnite and c.e. Choose
an inﬁnite increasing and therefore computable subset.

32
2. Computably Enumerable Sets
For more sophisticated applications such as Myhill’s Theorem 2.4.6 we
need the following form of the Recursion Theorem with parameters. (By
coding ﬁnite sequences it suﬃces to consider a single parameter.) The proof
exploits the uniformity of the earlier proof and is otherwise identical.
Theorem 2.2.6 (Recursion Theorem with Parameters, Kleene).
If
f(x, y) is a computable function, then there is a 1:1 computable function
n(y) such that ϕn(y) = ϕf(n(y), y).
Proof. Deﬁne a 1:1 computable function d by
(2.14)
ϕd(x,y)(z) :=



ϕϕx (x, y) (z)
if ϕx (x, y) converges;
undeﬁned
otherwise.
Choose v such that ϕv(x, y) = f(d(x, y), y). Then n(y) = d(v, y) is a ﬁxed
point, because
ϕd(v,y) = ϕϕv(v,y) = ϕf(d(v,y),y).
The ﬁrst equality follows from the deﬁnition of d in (2.14), and the second
from the deﬁnition of v.
The following theorem strengthens Theorem 2.2.6 by replacing the total
function f(x, y) by a partial function ψ(x, y) using the same proof. This
form will be useful later.
Theorem 2.2.7. If ψ(x, y) is a partial computable function, then there is
a computable function n(y) such that for all y
ψ(n(y), y)↓
=⇒
ϕn(y) = ϕψ(n(y), y).
Proof. Use the same proof as for Theorem 2.2.6.
2.2.7
Exercises
Exercise 2.2.8. Prove that K is not an index set.
Exercise 2.2.9. Deﬁne the following set of minimal indices of p.c.
functions M := { x : ¬(∃y < x) [ ϕx = ϕy ] }.
(i) Prove that M is inﬁnite but contains no inﬁnite c.e. set. Hint. Use the
Recursion Theorem.
(ii) (Jockusch). Let h be a computable function which is ﬁnite-one, i.e., for
each y there are only ﬁnitely many e with h(e) = y. (Note that if h(e) is the
“size” of the program with G¨odel number e, measured in any reasonable
way, then h is ﬁnite-one.) Let
Mh = { e : (∀i) [ h(i) < h(e)
.
=⇒.
ϕi ̸= ϕe ] }.
Show that Mh is an inﬁnite set which does not contain any inﬁnite
c.e. subset.

2.3. Indexing Finite and Computable Sets
33
Exercise 2.2.10. A set A is self-dual if A ≤m A. For example, if A = B⊕B
then A is self-dual.
(a) Use the Recursion Theorem to prove that no index set A can be
self-dual.
(b) Use the Recursion Theorem to give a short proof of Rice’s
Theorem 1.6.14.
Exercise 2.2.11. Show that Corollary 2.2.2 is equivalent to: For every c.e.
set A, (∃n) [Wn = {x : ⟨x, n⟩∈A}]. Hint. Deﬁne the c.e. set
An = {x : ⟨x, n⟩∈A}
and compare the sequence {An}n∈ω with {Wn}n∈ω.
2.3
Indexing Finite and Computable Sets
If A = We then e is a Σ0
1-index for A by Deﬁnition 2.1.4 and e gives a
way to enumerate A. However, if A is computable, then we might want a
stronger ∆0
0-index i such that ϕi is the characteristic function A(x) for A.
Furthermore, if A is ﬁnite, we might want a still stronger canonical index
which speciﬁes all the members of A, its cardinality, and its maximum
element. Here we explore these stronger indices for computable or ﬁnite
sets, and use the Recursion Theorem 2.2.1 to prove that one cannot pass
eﬀectively from a weaker to a stronger index.
2.3.1
Computable Sets and ∆0 and ∆1 Indices
Deﬁnition 2.3.1. (i) We say that e is a Σ0
1-index (Σ1-index, c.e. index)
for a set A if A = We.
(ii) e is a ∆0
0-index (∆0-index, characteristic index) for a set A if ϕe is the
characteristic function χA for A.
(iii) ⟨e, i⟩is a ∆0
1-index (∆1-index) for a computable set A if A = We and
A = Wi.
We normally drop the superscript 0 following convention 2.1.2.
Remark 2.3.2. Clearly, from a ∆0-index for a computable set A we can
eﬀectively obtain a ∆1-index for A and therefore a Σ1-index for A. The
proof of the Complementation Theorem 2.1.14 allows us to pass eﬀectively
from a ∆1-index for A to a ∆0-index for A. From now on we consider ∆0
and ∆1 indices to be completely synonymous.
However, we cannot, in general, pass eﬀectively from a Σ1-index for a
computable set A to a ∆1-index for A, as the following theorem establishes.

34
2. Computably Enumerable Sets
Theorem 2.3.3 (Nonconversion Theorem). There is no partial computable
function ψ such that
(∀x) [ Wx computable
=⇒
(∃y) [ ψ(x)↓= y
&
ϕy = Wx ].
(This asserts that there is no partial computable function which eﬀectively
converts any Σ1 index x for a computable (even ﬁnite) set A, namely
Wx = A, and outputs a ∆0 index y such that ϕy is the characteristic
function of Wx, written ϕy = Wx.)
Proof. Deﬁne a computable function f as follows and use the Recursion
Theorem 2.2.1 in the manner described in §2.2.5 to obtain a ﬁxed point n
for f. Note that the following c.e. set Wn is computable because it is either
empty or a singleton.
(2.15)
Wn = Wf(n) =



{0}
if ψ(n)↓and ϕψ(n)(0)↓= 0;
∅
otherwise.
Now ϕψ(n) cannot be χWn, the characteristic function of Wn, because 0 ∈
Wn
iﬀ
ϕψ(n)(0) = 0
iﬀ
χWn(0) = 0
iﬀ
0 ̸∈Wn.
Corollary 2.3.4. There is no partial computable function θ such that
(∀x) [ Wx computable
=⇒
(∃z) [ θ(x)↓= z
&
Wz = W x ].
Proof. This follows by Theorem 2.3.3 and the eﬀective transfer between
∆0-indices and ∆1-indices in Remark 2.3.2.
Corollary 2.3.5. The computable sets are closed under ∪, ∩, and comple-
mentation. The closure under ∪and ∩is uniformly eﬀective with respect
to both Σ0
1-indices and ∆0
1-indices. The closure under complementation is
uniformly eﬀective with respect to ∆0
1-indices only.
2.3.2
Canonical Index y for Finite Set Dy and String σy
A ﬁnite set, being computable, has both a Σ1-index and a ∆0-index. Yet
the latter does not eﬀectively specify the maximum element of A or even
the cardinality of A. Thus, for each ﬁnite set we introduce a third index
which explicitly speciﬁes all the elements of A.
Deﬁnition 2.3.6. (i)
Given a ﬁnite set A = {x1, x2, . . . , xk} we deﬁne
y = 2x1 + 2x2 + · · · + 2xk to be the canonical index of A. Let Dy denote
the ﬁnite set with canonical index y and D0 denote ∅. (We usually imagine
that x1 < x2 < · · · < xk although the order does not matter.)
(ii)
A sequence {Df(x) }x∈ω for some computable function f is called a
strong array of ﬁnite sets.

2.3. Indexing Finite and Computable Sets
35
(iii) Recall that 2<ω denotes the set of ﬁnite strings of 0’s and 1’s. For σ,
τ in 2<ω let σ ≺τ denote that σ is an initial segment of τ. Let Dy be in
as (i) above. Given z = ⟨y, m⟩, deﬁne the string σz with canonical index z:
(2.16)
σz(x) =



1
if x ∈Dy
&
x < m
0
if x ̸∈Dy
&
x < m
Note that the length |σz| = m. If z = 0, then deﬁne σ0 to be the empty
string ∅sometimes denoted by ϵ.
If y is written in binary expansion then the elements of Dy are the
positions where the digit 1 occurs. For example, the binary expansion of 5
is 101 and D5 = { 0, 2 }. Clearly, there are computable functions f and g
such that f(y) = max{z : z ∈Dy} and g(y) = |Dy|. However, there is no
computable way to go from a ∆0-index for a ﬁnite set to its cardinality or
to a maximum element. (See Exercise 2.3.13.)
Theorem 2.3.7. There is no p.c. function ϕi such that if ϕx is the
characteristic function of a ﬁnite set F then ϕi(x)↓= y where Dy = F.
Proof. Assume ϕi exists. We build ϕn to be the characteristic function of
a ﬁnite set. By the Recursion Theorem 2.2.1 we are given n in advance.
Wait for the least stage s (if ever) such that ϕi,s(n) ↓= y. Meanwhile let
ϕn(x) = 0 for all x < s. If stage s arrives, choose any z ̸∈Dy, z > s, and
deﬁne ϕn(z) = 1. If s does not exist, then ϕn is the characteristic function
of ∅which is ﬁnite, so ϕi fails to have the necessary properties.
2.3.3
Acceptable Numberings of Partial Computable
Functions
In Deﬁnition 1.7.5 we deﬁned a sequence {ψe}e∈ω to be an acceptable num-
bering of the p.c. functions if there exist computable functions f and g such
that (1) ϕf(x) = ψx; and (2) ψg(x) = ϕx. Theorem 1.7.6 showed that for
an acceptable numbering there is a computable permutation h such that
ψx = ϕh(x) provided that we can replace f and g by one-one functions f1
and g1 with the same properties.
It is easy to do this for f by the Padding Lemma 1.5.2 for the standard
numbering {ϕe}e∈ω, but there was no obvious reason why g1 existed. We
now complete the proof by showing that g1 exists. Therefore, the acceptable
numbering {ψe}e∈ω also satisﬁes the Padding Lemma. Note that in our
proof we need only g (not f) to produce g1.
Deﬁnition 2.3.8. For any p.c. function ϕx deﬁne the set of indices for
ϕx,
(2.17)
Indx = { y : ϕy = ϕx }.

36
2. Computably Enumerable Sets
Theorem 2.3.9. Suppose that {ψx}x∈ω is any sequence of p.c. functions
(not necessarily c.e.) and g is a computable function such that ϕx = ψg(x).
Then there is a one-one computable function g1(x) such that ϕx = ψg1(x).
In the following theorem g(Inde) must be inﬁnite or else Inde is com-
putable, contradicting Rice’s Theorem 1.6.14. However, given e and g(e) = i
at stage s it may be that i is already in the range of g1. The objective is to
ﬁnd another index j not already in the range of g1 with ϕe = ψj and to do
so computably and uniformly in e. The Recursion Theorem 2.2.1 supplies
this index in a surprising fashion.
Corollary 2.3.10 (Acceptable Numbering Theorem).
If {ψx}x∈ω is
an acceptable numbering of the partial computable functions as in Def-
inition 1.7.5, then there is a computable permutation h of ω such that
ϕe = ψh(e) for all e.
Proof. (of Corollary 2.3.10).
The one-one function g1 of Theorem 2.3.9
completes the proof of the Acceptable Numbering Theorem 1.7.6.
Proof. (of Theorem 2.3.9). To obtain g1 ﬁrst deﬁne a function h such that
(2.18)
(∀x) [ ϕh(e,x) = ϕe ]
and
(2.19)
(∀x) (∀y) [ x ̸= y
=⇒
gh(e, x) ̸= gh(e, y) ].
Fixing e, deﬁne h(e, k) by induction on k. Deﬁne h(e, 0) = e. Deﬁne
Bk = {gh(e, 0), . . . , gh(e, k)}. Use the Recursion Theorem 2.2.1 to deﬁne
(2.20)
ϕn(z) =
(
ϕe(z)
if g(n) /∈Bk;
undeﬁned
if g(n) ∈Bk.
Case 1. g(n) /∈Bk. Then ϕn = ϕe by the ﬁrst clause of (2.20). Therefore,
n ∈Inde −g−1(Bk). We deﬁne h(e, k + 1) = n.
Case 2. g(n) ∈Bk. Then ϕn = λz[ ↑] by the second clause of (2.20). By
inductive hypothesis, if g(j) ∈Bk then ϕj = ϕe according to (2.18). Hence,
ϕn = ϕe = λz[ ↑]. We now use the following Lemma 2.3.11 to ﬁnd a new
index m ∈Inde −g−1(Bk) for the undeﬁned function ϕe and we deﬁne
h(e, k + 1) = m.
Note that the condition g(n) ∈Bk is computable because Bk is ﬁnite
and g is computable by hypothesis. Therefore, we can tell which of the two
cases in (2.20) will hold in deﬁning ϕn.
Lemma 2.3.11. Let ϕe = λz[ ↑]. There is a computable function m(x)
such that if Wx ⊆Inde, then ϕm(x) = ϕe and m(x) ̸∈Wx.

2.3. Indexing Finite and Computable Sets
37
Proof. Fix ϕi = λz [1]. Using the Recursion Theorem with Parameters 2.2.6
deﬁne the computable function m(x) as follows:
(2.21)
ϕm(x)(z) =



ϕi(z)
if m(x) ∈Wx;
↑
if m(x) ̸∈Wx.
Suppose the ﬁrst clause holds in (2.21). Since m(x) ∈Wx, we know ϕm(x) =
ϕi ̸= ϕe by the choice of ϕi. However, ϕm(x) = ϕe because m(x) ∈Wx ⊆
Ind e. This is a contradiction. Therefore, ϕm(x) was deﬁned by the second
clause of (2.21) and m(x) ̸∈Wx. By the deﬁnition (2.21) we have ϕm(x) =
ϕe = λz [ ↑]. This proves Lemma 2.3.11.
Given the ﬁnite set Bk above, choose an x such that Wx = Bk and deﬁne
m = m(x). Then m ∈Inde −g−1(Bk), and we deﬁne h(e, k + 1) = m. This
completes the deﬁnition of h. Now deﬁne g1(x) by induction on x. Assume
g1(y) has been deﬁned for exactly those y < x. Given x, deﬁne
j = (µk)(∀y < x) [ g(h(x, k)) > g1(y) ].
Deﬁne g1(x) = gh(x, j). This proves Theorem 2.3.9.
Remark 2.3.12. Lemma 2.3.11 is a special case of the more general the-
orem that the index set Indx is productive as deﬁned in Deﬁnition 2.4.3.
However, the only fact we are using here is the productive property of Inde
for ϕe = λz [ ↑]. In Exercise 2.4.13 we prove that the index set Indx is
productive for every x but not uniformly in x.
2.3.4
Exercises
Exercise 2.3.13. Suppose we are given a ∆0-index x for a ﬁnite set F.
Prove that from any one of the following three items one can compute the
remaining two: (1) a canonical index y for F; (2) z = max F; (3) v = |F|.
Conclude by Theorem 2.3.7 that there is no eﬀective way to pass from x
to any of these three.
Exercise 2.3.14. ⋄(Double Recursion Theorem, Smullyan). (i)
Prove
that for any computable functions f(x, y) and g(x, y) there exist a and
b such that ϕa = ϕf(a,b) and ϕb = ϕg(a,b). Hint. Apply the Recursion
Theorem with Parameters 2.2.6 to get a computable function ba(y) such
that ϕba(y) = ϕf(ba(y),y). Let b be a ﬁxed point for the computable function
h(y), where ϕh(y) = ϕg(ba(y),y). Let a = ba(b).
(ii) Use exactly the same method to prove the Double Recursion Theorem
with Parameters, i.e., for any computable functions f(x, y, z) and g(x, y, z)
there exist computable functions a(z) and b(z) such that
ϕa(z) = ϕf( a(z), b(z), z )
and
ϕb(z) = ϕg( a(z), b(z), z ).

38
2. Computably Enumerable Sets
2.4
⋆Complete Sets and Creative Sets
In §1.6 we deﬁned the reducibilities ≤m and ≤1. In Deﬁnition 3.2.2 we shall
deﬁne the more general Turing reducibility ≤T.
Deﬁnition 2.4.1. Let r = 1, m or T reducibility. A set A is r-complete if
A is c.e. and W ≤r A for every c.e. set W.
The following Theorem 2.4.2 was given as Exercise 1.6.22. We now give
the complete but short proof of this key result, because we need to pass
back and forth between these three computably isomorphic sets.
Theorem 2.4.2. The sets K, K0, and K1 are all 1-complete. Therefore,
K0 ≡K1 ≡K by Myhill’s Isomorphism Theorem 1.7.4.
Proof. Each is c.e. by §2.1 equations (2.2), (2.3), and (2.4). Furthermore,
K0 = {⟨x, y⟩: x ∈Wy} is clearly 1-complete, since x ∈Wy iﬀ⟨x, y⟩∈K0.
Let W be any c.e. set. Now, as in Theorem 1.6.11, use the s-m-n-Theorem
to deﬁne a 1:1 computable function f as follows:
Wf(x) =



ω
if x ∈W;
∅
otherwise.
Now if x ∈W, then Wf(x) = ω and f(x) ∈K ∩K1. If x ∈W then
Wf(x) = ∅, so f(x) /∈(K ∪K1). Thus, f witnesses that W ≤1 K and
W ≤1 K1.
2.4.1
Productive Sets
Deﬁnition 2.4.3. (i) A set P is productive if there is a p.c. function ψ(x),
called a productive function for P, such that
(∀x) [ Wx ⊆P
=⇒
[ ψ(x)↓
&
ψ(x) ∈P −Wx ] ].
(ii) A c.e. set C is creative if C is productive.
For example, the set K is creative because K is productive via the iden-
tity function ψ(x) = x. Since K ≡K0 ≡K1 by Theorem 2.4.2, we know
that K0 and K1 are also creative. (Note that if Wx ⊆K then x /∈Wx and
x /∈K.) A creative set C is eﬀectively noncomputable in the sense that
for any candidate Wx for C, ψ(x) is an eﬀective counterexample, because
ψ(x) ∈C −Wx. These sets were called creative in [Post 1944] because
their existence justiﬁes “the generalization that every symbolic logic is in-
complete and extendible relative to the class of propositions” necessary
to code the relation {(x, y) : x ∈Wy}. Post remarked: “The conclusion

2.4.
⋆Complete Sets and Creative Sets
39
is inescapable that even for such a ﬁxed, well-deﬁned body of mathemat-
ical propositions, mathematical thinking is, and must remain, essentially
creative.”
Theorem 2.4.4. Any productive set P
has a total 1:1 computable
productive function p.
Proof. See Exercise 2.4.11.
Theorem 2.4.5. (i) If P is productive then P is not c.e.
(ii) If P is productive with productive function p(x), then P contains an
inﬁnite c.e. set W.
(iii) If P is productive and P ≤m A then A is productive.
Proof. (i) Immediate.
(ii) Let Wn = ∅, and Wh(x) = Wx ∪{ p(x) }. Deﬁne
(2.22)
W = { p(n), ph(n), ph2(n), . . . }.
(iii)
Let P ≤m A via f, and let p be a productive function for P. Let
Wg(x) = f −1(Wx). Then fpg is a productive function for A.
Using the fact that K is productive, Theorem 2.4.5 (iii) gives us a method
for exhibiting new productive sets P by showing that K ≤m P. We now use
the Recursion Theorem 2.2.1 to prove that every productive set has this
property. An immediate corollary is that all creative sets are 1-complete
and hence computably isomorphic to K.
2.4.2
⋆⋆Creative Sets Are Complete
Theorem 2.4.6 (Creative Set Theorem, Myhill, 1955).
(i) If P is productive then K ≤1 P.
(ii) If C is creative, then C is 1-complete and C ≡K.
Proof. (i)
Let p be a total 1:1 productive function for P. Deﬁne the
computable function f by
Wf(x,y) =



{ p(x) }
if y ∈K;
∅
otherwise.
By the Recursion Theorem with Parameters 2.2.6 there is a 1:1 computable
function n(y) such that
(2.23)
Wn(y) = Wf(n(y),y) =



{ p( n(y) ) }
if y ∈K;
∅
otherwise.

40
2. Computably Enumerable Sets
(2.24) y ∈K =⇒Wn(y) = { pn(y) } =⇒Wn(y) ̸⊆P =⇒pn(y) ∈P,
(2.25)
y ∈K =⇒Wn(y) = ∅=⇒Wn(y) ⊆P =⇒pn(y) ∈P.
In both lines the ﬁrst implication follows from the deﬁnition of n(y). The
fact that p is a productive function for P yields the second implication
in (2.24) and the third implication in (2.25). But (2.24) and (2.25) yield
K ≤1 P via the function g(y) = p(n(y)). Part (ii) follows by (i) and the
Myhill Isomorphism Theorem 1.7.4.
Corollary 2.4.7. The following are equivalent:
(i) P is productive;
(ii) K ≤1 P;
(iii) K ≤m P.
Corollary 2.4.8. The following are equivalent:
(i) C is creative;
(ii) C is 1-complete;
(iii) C is m-complete.
The next deﬁnition will be useful in Exercise 2.4.18 below and in Chapter 4.
Deﬁnition 2.4.9. Let (A1, A2) and (B1, B2) be two pairs of sets such that
A1 ∩A2 = ∅= B1 ∩B2. Then
(2.26)
(B1, B2) ≤m (A1, A2)
if there is a computable function f such that f(B1) ⊆A1, f(B2) ⊆A2,
and f(B1 ∪B2) ⊆A1 ∪A2. We write “≤1” if f is 1:1.
2.4.3
Exercises
Exercise 2.4.10. Extend the proof of Theorem 2.4.5 (ii) to show that if
P is productive, then there is a computable function f such that
(∀x) [ Wx ⊆P
=⇒
[ [ Wf(x) ⊆( P ∩Wx ) ]
&
|Wf(x)| = ∞] ].
Apply the procedure to an arbitrary set Wn in place of Wn = ∅in the proof
of Theorem 2.4.5 (ii). Prove that if Wn ⊆P then W ⊆P for the set W in
(2.22). Prove that if a repetition occurs in equation (2.22) then Wn ̸⊆P.
The algorithm needs to succeed only if Wn ⊂P but it needs to be deﬁned
for all indices because we cannot computably determine whether Wn ⊂P.
Exercise 2.4.11. Prove Theorem 2.4.4 that every productive set has
a total 1:1 computable productive function. Hint. (i) Total.
Let P be
productive via ψ. First deﬁne a computable function g such that

2.4.
⋆Complete Sets and Creative Sets
41
Wg(x) =



Wx
if ψ(x)↓;
∅
otherwise.
Show that g(x) is computable. Deﬁne q(x) to be either ψ(x) or ψ(g(x)),
whichever converges ﬁrst.
(ii) One-One.
Convert q to a 1:1 productive function p. Let Wh(x) =
Wx ∪{q(x)}. Apply the method of proof of Theorem 2.4.5 (ii) and Ex-
ercise 2.4.10. Deﬁne p(0) = q(0). To compute p(x + 1), enumerate the
set
{q(x + 1), qh(x + 1), qh2(x + 1), . . .}
until either some y not in {p(0), . . . , p(x)} is found, or a repetition occurs.
Exercise 2.4.12. If A is c.e. and A ⊂K prove that A ∪K ≡K. Hint.
Use the Recursion Theorem as in (2.23) to prove that K ≤m A ∪K.
Exercise 2.4.13. As in Deﬁnition 2.3.8, let Indx = {y : ϕy = ϕx}.
(i)
Prove that for each x, Indx is productive. Note that Lemma 2.3.11
proved this for ϕe(y) undeﬁned for all y. That proof works if dom(ϕx) ̸= ω.
See also Remark 2.3.12. Hint. If dom(ϕx) = ω, then combine Corol-
lary 2.4.7 and Exercise 1.6.24.
(ii) (Fejer). Show that this reduction K ≤m Indx is not uniform in x, i.e.,
there is no computable function f(x, y) in the sense that for all x, y ∈K
iﬀf(x, y) ∈Indx. Hint. Choose y0 ∈K, consider λx [ f(x, y0) ], and use the
Recursion Theorem on f.
Exercise 2.4.14. Prove that if K ≤m A via f and A is not c.e. then there
are 2ℵ0 sets B such that K ≤m B via f. Hence there are 2ℵ0 productive
sets. Hint. If A is not c.e. then S = A −f(K) is inﬁnite.
Remark 2.4.15. In Exercise 1.6.26 we deﬁned a disjoint pair (A, B) of
c.e. sets to be computably inseparable if there is no computable set C such
that A ⊆C and C ∩B = ∅. Now we deﬁne the stronger notion of ef-
fectively inseparable, which implies that any c.e. set C which separates
must be creative and therefore noncomputable. Many pairs of c.e. sets in
computability theory, such as the provable and refutable sentences in the
language of Peano arithmetic, form pairs of eﬀectively inseparable sets.
Deﬁnition 2.4.16. A disjoint pair (A, B) of c.e. sets is eﬀectively insepara-
ble if there is a partial computable function ψ, called a productive function
for (A, B), such that for all x and y,
[A ⊆Wx & B ⊆Wy
&
Wx ∩Wy = ∅]
=⇒
[ψ(⟨x, y⟩)↓
&
ψ(⟨x, y⟩) /∈(Wx ∪Wy)].
Note that if the pair (A, B) is eﬀectively inseparable then it is computably
inseparable. However, the converse is false.

42
2. Computably Enumerable Sets
Exercise 2.4.17. Assume the disjoint pair (A, B) of c.e. sets is eﬀectively
inseparable via ψ.
(i) Use the method of Exercise 2.4.11 to prove that we may assume ψ is
total and 1:1.
(ii)
(Let Wx
\ Wy be as in Deﬁnition 2.6.4.) Prove that the fol-
lowing c.e. sets are eﬀectively inseparable: A = {x : ϕx(x) = 0} and
B = {x : ϕx(x) = 1}. Hint. Deﬁne ψ by
ϕψ(⟨x,y⟩)(z) =







1
if z ∈Wx \ Wy
0
if z ∈Wy \ Wx
↑
otherwise.
(iii) Show that if (A, B) is a pair of eﬀectively inseparable c.e. sets, then
each of A and B is creative.
Exercise 2.4.18. (Smullyan). Assume that (A1, A2) is a pair of eﬀectively
inseparable c.e. sets with productive function p. Prove that if (B1, B2)
is a pair of disjoint c.e. sets then (B1, B2) ≤1 (A1, A2), as in Deﬁni-
tion 2.4.9. Hint. By the Double Recursion Theorem with one parameter
Exercise 2.3.14, deﬁne 1:1 computable functions g(z), h(z) such that
Wg(z) =
(
A1 ∪{p(⟨g(z), h(z)⟩)}
if z ∈B2
A1
otherwise,
and
Wh(z) =
(
A2 ∪{p(⟨g(z), h(z)⟩)}
if z ∈B1,
A2
otherwise.
Let f(z) = p(⟨g(z), h(z)⟩) and show that (B1, B2) ≤1 (A1, A2) via f.
Exercise 2.4.19. (Jockusch-Mohrherr). Let A be any c.e. set except ω.
Prove that A is creative iﬀ
(∀c.e. W) [ A ∩W = ∅
=⇒
A ≡A ∪W ].
Hint.
Show that A contains an inﬁnite c.e. subset W. Take an inﬁnite
computable subset R ⊂W and a creative subset C ⊂R. Now A ≡A ∪C
by hypothesis. Prove that A is creative.
Exercise 2.4.20. ⋄Let C be a class of c.e. sets. Show that the following
two statements are equivalent.
(i) { e : We ∈C } is c.e.
(ii) There is a c.e. set I such that for all c.e. sets W,
W ∈C
⇐⇒
(∃i) [ i ∈I
&
Di ⊆W ].

2.5.
⋆⋆Elementary Lachlan Games
43
(Direction (ii) implies (i) is obvious, but (i) implies (ii) is harder. For this
direction ﬁrst prove from (i) that U ∈C and U ⊆V implies V ∈C. Next
prove that if W ∈C then there is some ﬁnite set F ⊆W such that F ∈C.)
2.5
⋆⋆Elementary Lachlan Games
Lachlan proposed a new kind of game to analyze problems and prove the-
orems on c.e. sets. We introduce it brieﬂy now and develop it more fully in
Chapter 16.
2.5.1
The Deﬁnition of a Lachlan Game
Deﬁnition 2.5.1. A Lachlan game is a game between two players.
• Player I (RED) constructs a ﬁnite or inﬁnite sequence of c.e. sets,
{Un}n∈ω called the red sets.
• Player II (BLUE) constructs a ﬁnite or inﬁnite sequence {Vn}n∈ω of
c.e. sets, called the blue sets.
• At every move (stage) of the game RED may enumerate at most
ﬁnitely many integers into ﬁnitely many red sets and then BLUE
may enumerate at most ﬁnitely many integers into ﬁnitely many blue
sets. Let Zs denote the ﬁnite set of elements enumerated in set Z by
the end of stage s.1
• Each play of the game ends after ω many moves.
• At the start of the game we ﬁx a computable sequence {Re}e∈ω of
ﬁnite conditions on the red and blue sets called requirements which
will be speciﬁed precisely in advance for each particular game.
• Player II wins the play of the game if the red and blue sets con-
structed during that play satisfy all the requirements, and Player I
wins otherwise.
• A game situation at the end of stage s is the result {Un,s}n<s and
{Vn,s}n<s and can be eﬀectively coded by an integer, say using the
canonical indices for these ﬁnite sets.
• A winning strategy for a given player is a function from game situ-
ations to moves (and can be coded as a function f on ω) such that
if the player follows this strategy he will win against any sequence of
moves by his opponent. To prove a theorem we wish to prove that one
player or the other has a winning strategy for that particular game.
1Without loss of generality we may assume that [x ∈Un,s ∨x ∈Vn,s]
=⇒
x, n < s.

44
2. Computably Enumerable Sets
• We begin by thinking of the strategies as computable functions and
therefore of the sets Un and Vn as c.e., but the games can be rela-
tivized to an oracle X, in which case the strategies are X-computable
and the sets are X-c.e.
2.5.2
Playing Partial Computable (P.C.) Functions
This deﬁnition may seem too restrictive because in many theorems in com-
putability we may allow one or both players to construct other objects
such as partial computable (p.c.) functions or Turing reductions ΦA
e (x),
e.g. in the Friedberg-Muchnik theorem to meet a requirement such as
Re : B ̸= ΦA
e . However, no generality is lost because these objects can
be constructed as c.e. sets. For example, to deﬁne ϕe we enumerate the c.e.
set
graph(ϕe) := { ⟨x, y⟩: ϕe(x) = y }
which we deﬁned in Deﬁnition 2.1.7. Similarly, the Turing functionals Φe
deﬁned later can be viewed as c.e. sets. To play a p.c. function or Turing
functional we simply enumerate axioms of the graph on moves during the
game. Therefore, these Lachlan games are as general as we need to prove
most theorems about c.e. sets.
2.5.3
Some Easy Examples of Lachlan Games
We begin by analyzing some known previous theorems in terms of Lachlan
games. Since BLUE has a winning strategy for these games we can let
RED play Vn = Wn without loss of generality. We give a reference to the
earlier result and sketch the winning strategy for BLUE as a game.
The construction of a noncomputable c.e. set K in Deﬁnition 1.6.3 is a
game. RED plays Wn for all n and BLUE plays K. BLUE withholds n
from K until, if ever, RED puts n into Wn, and then BLUE puts n into
K.
The construction of a pair of eﬀectively inseparable c.e. sets A and B in
Exercise 2.4.17 is similar. RED plays ϕe for all e and BLUE plays A and B.
BLUE withholds e from either A or B until ϕe(e)↓, and then enumerates
e into whichever of A and B witnesses that ϕe(e) has the wrong value to
separate them.
Theorem 2.3.3 on the lack of conversion of a Σ1 index to a ∆0 index for
a computable set is a Lachlan game. RED plays a potential p.c. conversion
function ψ and BLUE plays Wn. BLUE withholds 0 from Wn until there
exists y such that ψ(n) ↓= y and ϕy(0) = 0. If this never happens then
0 ̸∈Wn but ϕy(0) ̸= 0. If y appears, then BLUE puts 0 into Wn so that
ϕy(0) ̸= Wn(0) = 1. (Notice that BLUE wins this game because he plays
a Σ1 object and RED plays a ∆0 object, which gives BLUE one more
move.)

2.5.
⋆⋆Elementary Lachlan Games
45
The Myhill Creative Set Theorem 2.4.6 is also a Lachlan game. RED
claims that a ﬁxed set P is productive and plays a 1:1 total computable
productive function p(x) to witness productivity. BLUE plays a 1:1 com-
putable function n(y) and claims that K ≤1 P via p(n(y). For a ﬁxed
y, BLUE withholds p(n(y)) from Wn(y) until y ∈K and then enumer-
ates p(n(y)) in Wn(y). If y ∈K, then p(n(y)) ∈P by (2.25). If y ∈K
then the action by BLUE forces p(n(y)) to move “down” from P to P by
(2.24). (This action is remarkable because we have no information about
the productive set P, but only the property of its productive functon p(x).)
2.5.4
Practicing Lachlan Games
In §2.5.3 we gave several examples of easy Lachlan games. It is not enough
to simply read these examples. You must practice them as with any game.
Go back over the original exercises or theorems and study them as a game.
One of the new things to determine is which of the two players is playing
which items. In general, for a known theorem, the given items are played
by RED, and the items we construct are played by BLUE. We shall often
use the games in future theorems and examples.
2.5.5
The Signiﬁcance of Lachlan Games
The ﬁrst advantage of a Lachlan game is that it helps to reveal, in dynamic
terms, the rationale behind a given proof. The second advantage is that it
helps to solve a new problem when we do not know which side will win. We
assign BLUE and RED to opposite sides of an open question and let them
struggle to ﬁnd a winning strategy. When we sense a weakness for BLUE,
we change sides and attempt to exploit it for RED. We keep changing sides
back and forth with no loyalty to either side as we seek a solution. This
dynamic tension is at the heart of many proofs in the subject, but authors
rarely make any explicit reference to the game.
2.5.6
Exercises on Lachlan Games
Exercise 2.5.2. Let f be a computable function. Show that there is an
n such that: (i)
Wn is computable; and (ii)
(µy) [ Wy = W n ] > f(n).
Hint. Let RED play f. Let BLUE play Wn by ﬁrst computing f(n) us-
ing the Recursion Theorem, and then deﬁning a ﬁnite set Wn which is a
counterexample.
Exercise 2.5.3. Prove that Inf ≤1 Cof by the following function f. Let
RED play Wx and BLUE play Wf(x). Whenever RED adds a new element
to A, BLUE puts the least element bs
0 of B
s into B.
Exercise 2.5.4. ⋄⋆⋆(Lachlan).

46
2. Computably Enumerable Sets
(i) Prove that if K ≤m A × B and B is c.e., then K ≤m A or K ≤m B.
(ii) Conclude that there is no pair of incomparable c.e. m-degrees whose
l.u.b. is the m-degree of K. Hint. Note that A ⊕B ≤m A × B.
Hint for (i). Let RED play B c.e. and play a Turing reduction K0 ≤m A×B
via computable functions h(z) and j(z), i.e.,
z ∈K0
⇐⇒
[ h(z) ∈A
&
j(z) ∈B ].
BLUE constructs a c.e. set D = We whose index e is known in advance by
the Recursion Theorem 2.2.1. Therefore, we have
(2.27)
x ∈We
⇐⇒
⟨x, e⟩∈K0
⇐⇒
[ f(x) ∈A
&
g(x) ∈B ]
for f(x) = h(⟨x, e⟩) and g(x) = j(⟨x, e⟩). BLUE plays two strategies S1 and
S2. Call x good at stage s if x /∈Ds and g(x) ∈Bs. Let G = {x0, x1, . . .}
be a computable enumeration of the elements good at some stage. BLUE
plays a strategy S1 which shows that if |G| = ∞, then
n ∈K
⇐⇒
xn ∈D
⇐⇒
f(xn) ∈A.
Simultaneously, BLUE’s backup strategy S2 shows that if G is ﬁnite,
then D =∗K and x ∈D iﬀg(x) ∈B.
2.6
⊘The Order of Enumeration of C.E. Sets
2.6.1
Uniform Sequences and Simultaneous Enumerations
Deﬁnition 2.6.1. (i) A sequence of c.e. sets V = {Ve}e∈ω is uniformly
c.e. (u.c.e.) if there is a computable function f such that Ve = Wf(e). (In
§3.5.2 we discuss the general concept of uniform computability and give
examples.)
(ii) If V = {Ve}e∈ω is a u.c.e. sequence, and h is a 1:1 computable function
on ω such that h(ω) = {⟨x, e⟩: x ∈Ve}, then h is a simultaneous computable
enumeration (s.c.e.) of V. Intuitively, if h(s) = ⟨x, e⟩, then h causes x to
be enumerated in Ve at stage s. Using h we deﬁne the array:
(2.28)
Ve,s = { x : (∃t ≤s) [ h(t) = ⟨x, e⟩] }.
(iii) When dealing with an s.c.e. h we write Vh to indicate the dependence
on h of the order of enumeration in (2.28). Deﬁne the inﬁnite join:
(2.29)
⊕y∈ω Ay := { ⟨x, y⟩: x ∈Ay }y∈ω.
If ⊕e∈ω Ve is ﬁnite then we allow h to be partial provided that h(s)
deﬁned implies h(t) deﬁned for all t < s so that the domain of h is an
initial segment of ω. This allows us to pass uniformly from any enumera-
tion of ⊕e Ve to an s.c.e. h of it, because we do not have to ask whether

2.6.
⊘The Order of Enumeration of C.E. Sets
47
⊕e Ve is ﬁnite. That is, we just continue to deﬁne h as in the Listing
Theorem 2.1.10 (ii) so long as new elements enter ⊕e Ve.
Convention 2.6.2. Deﬁnition 1.6.17 of the stage s approximation We,s
to We was convenient at the time, but it just bounded the search by stage
s and may have allowed several elements to be enumerated at the same
stage s in the same or diﬀerent c.e. sets. From now on we ﬁx some particu-
lar simultaneous computable enumeration (s.c.e.) h0 of the standard array
{We}e∈ω of all c.e. sets and deﬁne We,s to be the ﬁnite set derived from h0
as in (2.28). We may assume that h0 also satisﬁes:
(2.30)
x ∈We,s
=⇒
x, e < s
as in Deﬁnition 1.6.2. We now have
(2.31)
(∀s) (∃at most one ⟨e, x⟩) [ x ∈We,s+1 −We,s ].
This is convenient for many later constructions.
2.6.2
Static and Dynamic Properties of C.E. Sets
The properties of a c.e. set We presented so far have largely been static
properties, but dynamic properties will play an important role.
Deﬁnition 2.6.3. (i) A property of a c.e. set We is static if it is described
in terms of We as a completed object, such as a lattice property or the Σ0
1
characterization of We in §2.1.1.
(ii) A property of a c.e. set We is dynamic if it is described in terms of
a computable enumeration {We,s}s∈ω of We and measures time-dependent
properties, such as those which determine which elements have entered
a certain set We before entering another given set Wi under a given
simultaneous enumeration.
Theorems 2.6.5 and 2.7.1 in the following sections represent excellent
examples of a combination of static and dynamic properties used to prove
an easy but important theorem. We shall usually be doing a computable
construction where the hypotheses and conclusions are c.e. sets and p.c.
functions. Usually the only information we have is a Σ1 index e for A = We,
and such an e gives only a dynamic procedure for enumerating A as it is
revealed stage by stage, and not any of its static properties as a completed
object.
Deﬁnition 2.6.4. (Dynamic Deﬁnitions for C.E. Sets).
Fix a simulta-
neous computable enumeration (s.c.e.) function h of an array of c.e. sets
{Ve}e∈ω as in (2.28). Let Xs denote Vi,s and Ys denote Vj,s for some i and
j. Then the following sets are c.e.

48
2. Computably Enumerable Sets
(i) Deﬁne X \ Y = {z : (∃s) [ z ∈Xs −Ys ]}, the elements enumerated in
X before (if ever) being enumerated in Y .
(ii)
Deﬁne X ↘Y = (X \ Y ) ∩Y , the elements enumerated in X and
later in Y .
(Do not confuse X\Y with X −Y , which denotes X ∩Y . Notice that
the deﬁnitions X \ Y and X ↘Y depend not only upon the sets X and
Y but also upon the particular s.c.e. function h.)
Theorem 2.6.5 (Dynamic Flow Theorem).
Fix a simultaneous com-
putable enumeration (s.c.e.) of the c.e. sets {We}e∈ω. Suppose B is a
noncomputable c.e. set. Fix some b with Wb = B and deﬁne Bs = Wb,s
so that the simultaneous enumeration includes B. Then for every e,
(2.32)
We ⊇B
=⇒
We ↘B inﬁnite,
and indeed We ↘B is noncomputable (see Exercise 2.6.7).
Proof. Note that We \ B
=
(We ↘B) ⊔B. If |We ↘B| < ∞,
then We \ B =∗B. Hence, B is c.e. and B is computable, contrary to
hypothesis.
2.6.3
Exercises
Exercise 2.6.6. If h is a simultaneous computable enumeration of a u.c.e.
array {Ve}e∈ω prove that there is a computable function g(e, s) such that
for Ve,s, deﬁned in (2.28), we have Dg(e,s) = Ve,s and hence that Ve =
∪s Dg(e,s).
Exercise 2.6.7. (i)
Given computable enumerations { Xs }s∈ω and
{ Ys }s∈ω of c.e. sets X and Y prove that both X \ Y and X ↘Y are
c.e. sets.
(ii) Prove that X \ Y = (X −Y ) ∪(X ↘Y ).
(iii)
Prove that if X −Y is not c.e. then X ↘Y is inﬁnite and indeed
noncomputable.
(iv) Give an alternative proof of the Reduction Principle Corollary 2.1.12
by letting A1 = Wx \ Wy and B1 = Wy \ Wx where Wx = A and Wy = B.
Exercise 2.6.8. Prove that there is a computable function f such that
{ Wf(n) }n∈ω consists precisely of the computable sets. (Hence we can give
an eﬀective list of Σ0
1-indices for the computable sets but not of ∆1-indices
for them.) Hint. Obtain Wf(n) ⊆Wn by enumerating Wn, placing in Wf(n)
only those elements enumerated in increasing order. (Note that we are using
the uniformity shown in Exercise 2.1.24.)

2.7.
⊘The Friedberg Splitting Theorem
49
2.7
⊘The Friedberg Splitting Theorem
The following theorem neatly combines the static and dynamic properties
of c.e. sets. Its statement is static and traditional, but its proof relies on a
key dynamic property.
2.7.1
The Priority Ordering of Requirements
The framework of the construction and proof is one we shall use many times
in more complicated situations. We have a list of conditions to be satisﬁed
called requirements, {Re}e∈ω, which are given their natural ω ordering of
priority: R0, R1, R2, . . . . We say that requirement Ri has higher priority
than Rj if i < j. The point is that every requirement Ri has at most ﬁnitely
many predecessors of higher priority.
We construct a c.e. set A by stages during a computable construction,
letting As denote the set of elements enumerated in A by the end of stage s,
and we deﬁne A = ∪sAs. At stage s + 1 we examine every requirement Ri,
i < s, which requires attention at stage s+1 in that: (1) Ri is not currently
satisﬁed, and (2) some associated condition such as equation (2.34) below
holds which gives us the opportunity to satisfy Ri now. From these Ri we
select the highest priority requirement Re (i.e., the least index e) and we
allow Re to receive attention, that is to act at stage s + 1.
In the following construction, if a requirement Re acts at stage s + 1 it
immediately becomes satisﬁed and remains satisﬁed at all stages t > s + 1.
However, in more complicated constructions, such as the ﬁnite injury con-
structions of Chapter 7, a given requirement Re, after being satisﬁed at
stage s, may later be injured at some stage t > s when some higher priority
requirement Ri, i < e, acts, and Re must start all over.
Theorem 2.7.1 (Friedberg Splitting Theorem).
If B is any noncom-
putable c.e. set there exist disjoint c.e. sets A0 and A1 such that:
(i)
B = A0 ⊔A1 (denoting disjoint union), and
(ii)
A0 and A1 are noncomputable.
Proof. Let f be a 1:1 computable function with range B, and deﬁne
Bs = {f(0), . . . , f(s)}.
For (ii) we try to meet for all e ∈ω and i < 2 the requirement
(2.33)
R⟨e,i⟩
:
We ̸= Ai.
Stage s = 0. Put f(0) in A0. Let Ai,s denote the set of elements in Ai by
the end of stage s.
Stage s + 1. Choose the least ⟨e, i⟩< s if it exists such that
(2.34)
f(s + 1) ∈We,s
&
We,s ∩Ai,s = ∅.

50
2. Computably Enumerable Sets
Enumerate f(s + 1) in Ai (so We,s ∩Ai,s+1 ̸= ∅and R⟨e,i⟩is satisﬁed
forever after). We say that requirement R⟨e,i⟩acts at stage s + 1. If ⟨e, i⟩
fails to exist, then enumerate f(s + 1) in A0.
Let Ai = ∪sAi,s for i = 0, 1. Now A0∩A1 = ∅and A0∪A1 = B. To verify
R⟨e,i⟩choose the least ⟨e, i⟩such that requirement R⟨e,i⟩is not satisﬁed.
Hence, We = Ai so We ⊇B because Ai ⊆B. Therefore, |We ↘B| = ∞
by the Dynamic Flow Theorem 2.6.5. But each R⟨j,k⟩, ⟨j, k⟩< ⟨e, i⟩, acts
at most once. Therefore, R⟨e,i⟩eventually corresponds to the minimal ⟨e, i⟩
satisfying (2.34), at which stage R⟨e,i⟩acts and becomes satisﬁed forever
thereafter, which is a contradiction.
2.7.2
Exercises
Exercise 2.7.2. Generalize Theorem 2.7.1 by using the same proof to
show that if W is any c.e. set, then
(2.35)
W −B non-c.e.
=⇒
W −Ai non-c.e. for i = 0, 1.
Furthermore, c.e. indices for A0 and A1 can be found uniformly from a c.e.
index for B.

3
Turing Reducibility
3.1
The Concept of Relative Computability
3.1.1
Turing Suggests Oracle Machines (o-Machines)
After his epochal paper in 1936 on Turing machines, Turing wrote a Ph.D.
dissertation with Alonzo Church which was published in 1939. A tiny part
of this paper in section 4 contained the germ of one of the most important
ideas in all of modern computability theory. In half a page Turing suggested
augmenting his former a-machines by adding some kind of “oracle” which
could supply the answers to speciﬁc questions during the computation.
Let us suppose we are supplied with some unspeciﬁed means
of solving number-theoretic problems; a kind of oracle as it
were. We shall not go any further into the nature of this or-
acle apart from saying that it cannot be a machine. With the
help of the oracle we could form a new kind of machine (call
them o-machines), having as one of its fundamental processes
that of solving a given number-theoretic problem.
These machines may be described by tables of the same kind
as those used for the description of a-machines.
3.1.2
Post Develops Relative Computability
The subject of oracle machines and relative computability lay dormant
for ﬁve years from 1939 until Post’s beautiful 1944 paper on computably
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_3 
51 

52
3. Turing Reducibility
enumerable sets, which heavily inﬂuenced the subject for decades. Post
explored the concept of reducing a set B to another set A. He introduced
ﬁrst some stronger reducibilities, such as many-one reducibility B ≤m A,
previously studied in Deﬁnition 1.6.8, and truth-table reducibility B ≤tt A,
which we shall study in Deﬁnition 3.8.2. General Turing reducibility was
not well understood in 1944. Post was the principal developer of it in a
series of papers over the next decade in 1944, in 1948, and in 1954, the key
paper by Kleene and Post.
In the crucial last section of Post’s 1944 paper, General (Turing) Re-
ducibility, Post named it “Turing reducibility,” written B ≤T A. Post
described B ≤T A in intuitive terms as the most general form of the
reducibilities he had explored. It is similar to the ordinary computation
process to determine whether x ∈B, except that at certain times the ma-
chine process chooses an element y and asks whether y ∈A? If a correct
answer is supplied, then the machine continues in this fashion until after a
ﬁnite number of steps it yields the answer to the question, is x ∈B? In a
ﬁnite time at most a ﬁnite number of questions can be asked. Post asserted
that a corresponding formulation of “Turing reducibility” should capture
the intuitive notion of eﬀective reducibility just as Turing computability
captures eﬀective calculability.
Consider a laptop computer connected to the Internet. This interaction
between the local computer and a very large database is called interactive
computing in modern computer terminology. Now remove the Internet con-
nection. What remains is the ﬁnite oracle program on the laptop, which
is independent of the database. This emphasizes the ﬁnite nature of the
local oracle machine (o-machine) and its oracle program independent of
the database.
3.2
⋆⋆Turing Computability
Neither Post nor Turing gave a formal deﬁnition of an o-machine. We
present one such formulation of a Turing o-machine in §3.2.1.
3.2.1
An o-Machine Model for Relative Computability
Deﬁnition 3.2.1. (i)
An oracle Turing machine (o-machine) is a Tur-
ing machine with the usual work tape and an extra “read only” tape,
called the oracle tape, upon which is written the characteristic function of
some set A, called the oracle, whose symbols {0, 1} cannot be printed over,
and are preceded by B′s. Two reading heads move along these two tapes
simultaneously.
As before, Q is a ﬁnite set of states, S1 = {B, 0, 1} is the oracle tape
alphabet, S2 = {B, 1} is the work tape alphabet, and {R, L} is the set

3.2.
⋆⋆Turing Computability
53
of head-moving operations right and left. In a given state with the heads
reading symbols s1 and t1 the machine can overprint t1 on the work tape,
change to a new state, and move each reading head one square right or left
independently.
(ii) An oracle Turing program is a ﬁnite sequence of program lines as above.
Fix an eﬀective coding of all oracle Turing programs for o-machines. Let
ePe denote the eth such oracle program under this eﬀective coding.
(iii) If the oracle machine halts, let u be the maximum cell on the oracle
tape scanned during the computation, i.e., the maximum integer tested for
membership in A. We deﬁne u to be the use of the computation. We say
that the elements z ≤u are used in the computation. If no element is
scanned we let u = 0.
3.2.2
Turing Computable Functionals Φe
Deﬁnition 3.2.2. (i) If the oracle program ePe with A on the oracle tape
and input x halts with output y and if u is the maximum element used
(scanned) on the oracle tape during the computation, then we write,
(3.1)
ΦA
e (x) = y
and
ϕA
e (x) = u.
We refer to ΦA
e as a Turing functional (Turing reduction), and we call
ϕA
e the corresponding use function. Note that ΦA
e (x) may be undeﬁned
for some x because ePe may be any oracle program. Such a functional is a
partial functional but we often drop the word partial, unlike in the case of
partial functions. The functional is simply determined by the program ePe
and may be partial or total. However, for every x we have ΦA
e (x) deﬁned
iﬀϕA
e (x) is deﬁned.
(ii) If this happens in < s steps and if e, x, y, and u < s, then we write,
(3.2)
ΦA
e,s(x) = y
and
ϕA
e,s(x) = u
and we assume from now on that ϕA
e,s(x) < s.
(iii) If σ ∈2<ω and this happens with σ on the oracle tape and u < |σ|
(therefore only σ is scanned) then we write,
(3.3)
Φσ
e (x) = y,
ϕσ
e (x) = u,
Φσ
e,s(x) = y,
and
ϕσ
e,s(x) = u.
(iv)
If ΦA
e,s(x) diverges, we write ΦA
e,s(x) ↑and ϕA
e,s(x) ↑. Let W A
e
=
dom(ΦA
e ), and likewise for W A
e,s, W σ
e , and W σ
e,s.

54
3. Turing Reducibility
(v) A partial function θ is Turing computable in A (A-Turing computable),
written θ ≤T A, if there is an e such that ΦA
e (x)↓= y iﬀθ(x) = y. A set B
is Turing reducible to A (B ≤T A) if the characteristic function χB ≤T A.
(vi) We also allow (total) functions f as oracles by deﬁning Φf
e to be ΦA
e
where A = {⟨x, y⟩: f(x) = y}, and allow partial functions ψ as outputs.
Deﬁnition 3.2.3. A functional Ψ on Cantor space 2ω is total if ΨA(x) is
deﬁned for every A ⊆ω and x ∈ω, i.e., if (∀A)(∃B)(∀x)[ ΨA(x) = B(x) ].
Following Church and Turing, we say that a set B is eﬀectively reducible
to another set A if it is reducible in the intuitive sense.
Thesis 3.2.4 (The Post-Turing Thesis). The set B is eﬀectively reducible
to another set A iﬀB is Turing reducible to A (B ≤T A).
This is implicit in Turing’s 1939 paper and Post’s 1944 paper. To justify
the Post-Turing Thesis, note that if B ≤T A then clearly B is eﬀectively
reducible to A. For the converse assume that B is eﬀectively reducible
to A via some procedure P. Now either argue that P’s being eﬀective
corresponds to some oracle program ePe or argue that the graph of P is
eﬀectively enumerable and therefore c.e.
Remark 3.2.5. We regard Φe as a partial function from 2ω to 2ω, which
takes A to B if ΦA
e = B. We call this map a functional (type 2 object).
The lower-case symbol ϕe with no exponent is the usual p.c. function in
Deﬁnition 1.5.1. The symbol ϕA
e (x) with an exponent A is the use function
for ΦA
e (x). The use function is deﬁned only if there is an exponent A and a
computation whose use is being measured. The notation for the use function
ϕA
e (x) always has an exponent such as A and does not conﬂict with the
partial computable function ϕe(x), which has no exponent.1
3.3
⋆Oracle Graphs of Turing Functional Φe
3.3.1
The Preﬁx-Free Graph Fe of Functional Φe
The oracle machine described in §3.2 is self-delimiting in the sense that if
Φσ
e (x) on input x halts after reading exactly string σ on its oracle tape, i.e.,
1Some writers use upper-case Φe for the p.c. function ϕe, but we avoid this because
uppercase Φe with no exponent represents a type 2 partial functional on 2ω. This oracle
algorithm is identiﬁed with the oracle graph Ge and oracle program ePe. However, ϕe is
a type 1 p.c. function on ω given by the Turing program Pe. We wish to keep the types
distinct and consistent.

3.3.
⋆Oracle Graphs of Turing Functional Φe
55
with use ϕσ
e (x) = |σ| −1, then it must turn oﬀand not read any more of
the oracle tape. Therefore, the machine on input x cannot read any ρ ≻σ
and has not halted on any ρ ≺σ. The oracle machine is deterministic and
on a ﬁxed input x and oracle σ goes through the computation in a sequence
of stages Φσ
e,s for s ∈ω.
Deﬁnition 3.3.1. For all e and x we deﬁne the set of minimal halting
strings,
(3.4)
He,x = {σ : (∃s)[ Φσ
e,s(x)↓
and
ϕσ
e,s(x) = |σ| −1 ].
These are the strings σ for which the computation of Φσ
e (x) enters the
halting state q0 after reading exactly σ.
Deﬁnition 3.3.2. A set of strings S ⊆2<ω is preﬁx-free if S is an antichain
with respect to the standard partial ordering ≺on strings, i.e.,
(3.5)
(∀σ)(∀τ)[ [ σ ∈S
&
σ ≺τ ]
=⇒
τ ̸∈S ].
Theorem 3.3.3. For every e and x, He,x of (3.4) is preﬁx-free.
Proof. Suppose that σ ∈He,x. This means that oracle program ePe on input
x and oracle σ entered the halting state q0 at some stage s. At this point
the machine halts forever and never makes another move.
In (2.1) we deﬁned graph(ψ) = {⟨x, y⟩: ψ(x) = y} for partial function
ψ. This graph exactly characterizes ψ and is c.e. iﬀψ is partial computable.
From a p.c. funtion ψ we can compute the c.e. set of its graph, and from
a c.e. set which is a graph we can compute the p.c. function it deﬁnes. In
specifying a graph for a Turing functional in place of a function, we need
to add the oracle string for the computation. We ﬁrst do this in graph Fe
for the minimal strings and then in Ge for all strings.
Deﬁnition 3.3.4. Given Deﬁnition 3.2.2 (iii) of Φσ
e (x), we deﬁne the preﬁx-
free oracle graph of Φe as the following c.e. set of axioms:
(3.6)
Fe = { ⟨σ, x, y⟩: Φσ
e (x) = y
&
σ ∈He,x }.
Therefore, Fe includes only those σ which are minimal strings for e and
x. Later, the oracle graph Ge of (3.7) will include all strings which give
the computation.
Theorem 3.3.5. (Unique Use Property). In (3.6), for every x, y, e, and
oracle A there is at most one string σ ≺A such that ⟨σ, x, y ⟩∈Fe.
Proof. Suppose ΦA
e (x) ↓= y. Then by Theorem 3.3.3 there is a unique
σ ≺A such that Φσ
e (x) converges and σ ∈He,x.
Remark 3.3.6. This unique use property will be applied in inﬁnite injury,
where we shall replace ΦA
e by the hat-trick functional bΦA
e , which becomes
undeﬁned whenever an element less than the use ϕA
e (x) enters A. For this
to succeed we need to know that the current use ϕA
e,s(x) is unique.

56
3. Turing Reducibility
3.3.2
The Oracle Graph Ge of Functional Φe
Deﬁnition 3.3.7. Given the Deﬁnition 3.2.2 (iii) and (3.3) of Φσ
e (x), deﬁne
the oracle graph of Φe as the following c.e. set of axioms:
(3.7)
Ge = { ⟨σ, x, y⟩: Φσ
e (x) = y }.
Of course, the oracle graph Ge cannot be preﬁx-free because mono-
tonicity (3.9) contradicts the preﬁx-free property (3.5). However, every
functional Φe determines a preﬁx-free graph Fe ⊂Ge which we may regard
as a basis for Ge similar to a basis for a vector space.
Theorem 3.3.8 (Oracle Graph Theorem).
Let the relation Φσ
e (x) = y
be as in Deﬁnition 3.2.2, let Fe be as in (3.6), and let Ge be as in (3.7).
(i) Ge is single-valued in the sense that
(3.8)
[ ⟨σ, x, y⟩∈Ge
&
⟨σ, x, z⟩∈Ge ]
=⇒
y = z.
(ii) Ge is c.e.
(iii) Ge is monotonic in the sense that
(3.9)
⟨σ, x, y⟩∈Ge
=⇒
(∀τ ≻σ)[ ⟨τ, x, y⟩∈Ge ].
(iv) ⟨σ, x, y⟩∈Ge
⇐⇒
(∃τ ⪯σ)[ ⟨τ, x, y⟩∈Fe ].
Proof. (i)
This follows by the convention in Deﬁnition 3.2.1 (iii) of an
o-machine that the machine can give an output only when it enters the
halting state q0, and thereafter it can make no moves and give no further
output on that string and input. Therefore, for every pair (σ, x) there can
be at most one y such that Φσ
e (x) = y.
(ii) Clearly, Ge is c.e. because ⟨σ, x, y⟩∈Ge iﬀ(∃s)[Φσ
e,s(x) = y]. This is
Σ1 and therefore c.e.
(iii) For property (3.9), apply the deﬁnition of an o-machine computation.
If Φσ
e,s(x) = y then when the machine produces the output y it enters the
halting state q0, and will never make any more moves on input x. Therefore,
for τ ⪰σ the machine with τ on the oracle tape must eventually enter q0
and give output y by exactly the same computation, and will never make
any more moves.
(iv) Suppose Φτ
e(x)↓= y. Then ⟨σ, x, y⟩∈Fe for the minimal such σ ⪯τ.
For every ρ ⪰σ, we have ⟨ρ, x, y⟩∈Ge by (iii).

3.3.
⋆Oracle Graphs of Turing Functional Φe
57
3.3.3
The Use Principle for Turing Functionals
Theorem 3.3.9 (Use Principle).
Deﬁnition 3.2.2 guarantees:
(i)
ΦA
e (x) = y
=⇒
(∃s) (∃σ ≺A) [ Φσ
e,s(x) = y ];
(ii)
Φσ
e,s(x) = y
=⇒
(∀t ≥s) (∀τ ⪰σ) [ Φτ
e,t(x) = y ];
(iii)
Φσ
e (x) = y
=⇒
(∀A ≻σ) [ ΦA
e (x) = y ].
Proof. For (i), any computation which converges does so at some ﬁnite
stage, having used only ﬁnitely many elements. We may take σ = A ↾
↾ϕA
e,s(x). Now (ii) was proved in the monotonic property (3.9), and (iii)
follows in the same manner from the deﬁnition of an oracle computation.
Use Principle 3.3.9 is crucial for most of our subsequent theorems, where
we often combine (i) and (iii). If ΦA
e (x) = y, we choose σ as in (i). Now for
all B ≻σ we must have ΦB
e (x) = y. We very often use the following fact.
(3.10)
[ ΦA
e,s(x) = y
&
A↾↾ϕ = B ↾↾ϕ ]
=⇒
ΦB
e,s(x) = y,
where ϕ = ϕA
e,s(x). This is because the B-computation ΦB
e,s(x) will read
only σ = A↾↾ϕ on the oracle tape before it enters the halting state q0.
3.3.4
Permitting Constructions
The oracle graph theorem plays a crucial role in permitting constructions
in §5.2.4 and in building a Turing functional ΘC = A in §5.5.3. When we
add an axiom ⟨σ, x, y⟩to the oracle graph G for Θ with σ ≺Cs, we must
respect this commitment on ΘC(x) until some element v ≤|σ| enters Ct,
in which case C permits us to change the value as explained in §5.2.
3.3.5
Lachlan Notation for Approximation by Stages
The following notation by Lachlan has become very popular and is now
used in most papers and books. The idea is that a single object ΦA
e (x)
is being approximated in stages where the value of each parameter may
depend on s. Therefore, we write [s] once to apply to all occurrences.
Deﬁnition 3.3.10. (Lachlan notation). When E(As, xs, ys, . . .) is an ex-
pression with a number of arguments subscripted by s denoting their values
at stage s, the notation E(A, x, y, . . .)[ s ] denotes the evaluation of E with
all arguments taken with their values at s.
(3.11) ΦA
e (x) [ s ] denotes ΦAs
e,s(xs)
and
ϕA
e (x) [ s ] denotes ϕAs
e,s(xs).

58
3. Turing Reducibility
3.3.6
Standard Theorems Relativized to A
Theorem 3.3.11 (Relativized Enumeration Theorem). There exists z ∈ω
such that for all sets A ⊆ω and for all x, y ∈ω, the A-partial computable
function ΦA
z (x, y) satisﬁes ΦA
z (x, y) = ΦA
x (y).
Theorem 3.3.12 (Relativized s-m-n Theorem). For every m, n ≥1 there
exists a 1:1 computable (not merely A-computable) function sm
n of m + 1
variables such that for all sets A ⊆ω and for all x, y1, y2, . . . , ym ∈ω,
ΦA
sm
n (x,y1,...,ym) = λz1, . . . , zn [ ΦA
x (y1, . . . , ym, z1, . . . , zn) ].
Proof. Take m = n = 1, and let s denote sm
n . The new program ePs(x,y) on
input z consists of applying program ePx to input (y, z). This deﬁnes s(x, y)
as a computable function since the program ePs(x,y) is independent of the
oracle A. Of course, s can be made 1:1 by padding, as in Lemma 1.5.2.
Theorem 3.3.13 (Relativized Recursion Theorem, Kleene).
(i) For all
sets A ⊆ω and all x, y ∈ω, if f(x, y) is an A-computable function, then
there is a computable function n(y) such that ΦA
n(y) = ΦA
f(n(y), y).
(ii) Furthermore, n(y) does not depend upon the oracle A, i.e., if
f(x, y) = ΦA
e (x, y)
then the computable function n(y) can be found uniformly in e.
Proof. Apply the proof of the Recursion Theorem with Parameters 2.2.6
but notice that n(y) is a computable function (not merely A-computable)
because the function s(x, y) in the s-m-n Theorem 1.5.5 is computable, and
hence the function d(x, y) is computable, where d(x, y) is obtained as in
the proof of Recursion Theorem with Parameters 2.2.6 but with all partial
functions relativized to A.
Deﬁnition 3.3.14. (i) B is computably enumerable in A if B = W A
e for
some e, where W A
e
= dom(ΦA
e ) as in Deﬁnition 3.2.2 (iv).
(ii) B is in Σ0,A
1
-form (abbreviated B is ΣA
1 ) if B = {x : (∃y) RA(x, y)}
for some A-computable predicate RA(x, y). (By the Quantiﬁer Contraction
Theorem 2.1.5, this is equivalent to asserting that B = {x : (∃y) RA(x, y)}
for some such RA.)
All the results of Chapter 2, §2.1 on c.e. sets relativize to A-c.e. sets by
virtually the same proofs, where we replace “c.e.” and “computable” by
“A-c.e.” and “A-computable.” For example:
Theorem 3.3.15 (Relative Complementation Theorem).
B ≤T A iﬀB
and B are c.e. in A.

3.3.
⋆Oracle Graphs of Turing Functional Φe
59
Theorem 3.3.16. The following are equivalent:
(i) B is c.e. in A;
(ii) B = ∅or B is the range of some A-computable total function;
(iii) B is ΣA
1 .
Proof. The proofs of (i) ⇐⇒(ii) and (iii) ⇐⇒(i) are the relativizations to
A of the proofs in §2.1. E.g., to prove (i) =⇒(iii), let B = W A
e . Hence,
by the Use Principle Theorem 3.3.9,
(3.12)
x ∈B ⇐⇒(∃s) (∃σ) [ σ ≺A & x ∈W σ
e,s ].
Now x ∈W σ
e,s is a computable relation on (e, σ, x, s) by the Graph Theo-
rem 2.1.9 and σ ≺A is an A-computable relation of σ because σ ≺A iﬀ
(∀y < |σ| ) [σ(y) = A(y)]. Hence, (3.12) is of the form (∃s) (∃σ) R(e, σ, x, s),
where R is an A-computable relation.
3.3.7
Exercises
Exercise 3.3.17. Give an eﬀective coding of the programs { ePe}e∈ω using
the method of §1.5.1 and prove that under this coding θe =dfn Φ∅
e is an
acceptable numbering of the partial computable functions as deﬁned in
Deﬁnition 1.7.5.
Exercise 3.3.18. (i)
Prove that {⟨e, σ, x, y, s⟩
:
Φσ
e,s(x)
=
y} is
computable.
(ii) Prove that G := { ⟨e, σ, x, y⟩: Φσ
e (x) = y } is Σ1, 1-complete, and
hence computably isomorphic to K.
Exercise 3.3.19. Given sets B and A prove that B ≤T A iﬀthere are
computable functions f and g such that
x ∈B ⇐⇒(∃σ) [ σ ∈Wf(x)
&
σ ≺A ],
x ∈B ⇐⇒(∃σ) [ σ ∈Wg(x)
&
σ ≺A].
Exercise 3.3.20. Given c.e. sets A and B prove that B ≤T A iﬀthere is
a computable function h such that for Dy as in Deﬁnition 2.3.6 we have:
x ∈B ⇐⇒(∃y) [ y ∈Wh(x)
&
Dy ⊆A ].
Exercise 3.3.21. In the Relativized s-m-n Theorem 3.3.12 we obtained
a computable (rather than an A-computable) function s. Usually, rela-
tivization of the theorems of Chapter 1 and 2 produce only A-computable
functions. For example, exhibit a set A and an A-computable relation
RA(x, y) which cannot be uniformized by any partial computable function
in the sense of Theorem 2.1.8.

60
3. Turing Reducibility
Exercise 3.3.22. Prove that if θ is partial computable in Y ⊆ω, then
there is a computable function f such that
(∀x ∈dom(θ)) [ W Y
f(x) = W Y
θ(x) ].
Furthermore, an index for f can be found uniformly computably from an
e such that θ = ΦY
e .
3.4
⋆Turing Degrees and the Jump Operator
3.4.1
The Structure of the Turing Degrees
Deﬁnition 3.4.1. (i) A ≡T B if A ≤T B and B ≤T A. (Note that ≤T is
reﬂexive and transitive, so ≡T is an equivalence relation.)
(ii)
The Turing degree (also called degree of unsolvability) of A is the
equivalence class deg(A) = {B : B ≡T A}.
(iii) Lower-case boldface letters a, b, c denote degrees, and D denotes the
class of all degrees.
(iv) The degrees D form a partially ordered set (D, ≤) under the relation
deg(A) ≤deg(B) iﬀA ≤T B. We write deg(A) < deg(B) if A <T B, i.e.,
if A ≤T B and B ̸≤T A.
(v) deg(A) ∨deg(B) = deg(A ⊕B). We also write deg(A) ∪deg(B) for
deg(A) ∨deg(B). With ∨the degrees (D, <, ∨) form an upper semi-lattice
(as deﬁned in the Notation section) with a supremum but not an inﬁmum.
(vi) A degree a is computably enumerable if it contains a c.e. set. Let C
denote the class of c.e. degrees with the same ordering as for D.
(vii) A degree a is computably enumerable in b if a contains some set A
c.e. in some set B ∈b.
(viii) A degree a is computably enumerable in and above b (written a is
c.e.a. in b) if a ≥b and a is c.e. in b. The terminology of (vii) and (viii)
applies to sets as well as degrees.
Two sets of the same degree should be thought of as coding the same in-
formation and therefore as equally diﬃcult to compute, while a < b asserts
that sets of degree b are more diﬃcult to compute than those of degree a.
Furthermore, deg(A ⊕B) is clearly the least upper bound for deg(A) and
deg(B) in this partial ordering (see Exercise 3.4.6). Unfortunately, the in-
ﬁmum of two degrees need not always exist for the degrees D or even for
the c.e. degrees C. Hence, these are upper semi-lattices, but neither forms
a lattice.

3.4.
⋆Turing Degrees and the Jump Operator
61
3.4.2
The Jump Theorem
In 1931 G¨odel introduced the diagonal set “eine Klasse K” (although he
deﬁned K for the Π0
1 (co-c.e.) sets W e, not for the Σ1 sets, as done today).
In 1936 Kleene deﬁned K = {e : e ∈We} as we did in Deﬁnition 1.6.3
and showed that: K is not computable, but K is computably enumerable
and hence is computably approximable, as we showed in Theorems 1.6.4
and 1.6.5. With the development of computability relative to an oracle
A, which we have presented in §3.2, in 1954 Kleene and Post deﬁned this
same diagonal operator KA, but relative to an oracle A, and noted that
the previous proofs showed that KA >T A and KA is c.e. in A.
Deﬁnition 3.4.2. (i) Let KA = { x : ΦA
x (x) ↓} = { x : x ∈W A
x }. KA
is called the jump of A and is denoted by A′ (pronounced “A prime”).
We also use the notation HA for KA because this represents the halting
problem relativized to A of whether ΦA
x (x) halts.
(ii) A(n), the nth jump of A, is obtained by iterating the jump n times,
namely A(0) = A, A(n+1) = (A(n))′. Note that A(1) = A′.
It follows from the relativization to A of Theorem 2.4.2 that KA ≡
KA
0 ≡KA
1 where KA
0 = {⟨x, y⟩: ΦA
x (y)↓} and KA
1 = {x : W A
x ̸= ∅}. These
alternative characterizations of the jump are useful. The crucial properties
of the jump operator are the following. (Recall by Deﬁnition 3.4.1 (viii)
that B is c.e.a. in A if B is c.e. in A and B ≥T A.)
Theorem 3.4.3 (Jump Theorem). (i) A′ is c.e.a. in A.
(ii) A′ ̸≤T A.
(iii) B is c.e. in A iﬀB ≤1 A′.
(iv) If A is c.e. in B and B ≤T C then A is c.e. in C.
(v) B ≤T A iﬀB′ ≤1 A′.
(vi) If B ≡T A then B′ ≡1 A′ (and therefore B′ ≡T A′).
(vii) A is c.e. in B iﬀA is c.e. in B.
Proof. Parts (i)–(iii) follow by relativizing the proofs in Chapters 1 and
2. Now KA
0 := {⟨x, y⟩: x ∈W A
y } and KA ≡KA
0 by relativizing to A
Deﬁnition 1.6.6 and Exercise 1.6.22. Therefore, A′ = KA ≡KA
0 . However,
A itself is clearly c.e. in A. Hence, A = W A
y for some y, but W A
y ≤1 KA
0 ,
and therefore A ≤1 KA.
Note that (iii) ( =⇒) uses KA ≡KA
0 .
(iv)
If A ̸= ∅, then A is the range of some B-computable function, and
hence of some C-computable function, since B ≤T C.

62
3. Turing Reducibility
(v) ( =⇒). If B ≤T A then B′ is c.e. in A by (iv), because B′ is c.e. in B
by (i). Hence, B′ ≤1 A′ by (iii).
(v) ( ⇐= ). If B′ ≤1 A′, then both B and B are c.e. in A by (iii) (because
B, B ≤1 B′). Hence, B ≤T A by the Complementation Theorem 2.1.14.
(vi) follows immediately from (v).
(vii) follows immediately from (iv).
Let a′ = deg(A′) for A ∈a. Note that a′ > a and a′ is c.e. in a.
By the Jump Theorem 3.4.3 (vi) the jump is well deﬁned on degrees. Let
0(n) = deg(∅(n)). Thus, we have an inﬁnite hierarchy of degrees,
0 < 0′ < 0′′ < · · · < 0(n) < · · · .
The ﬁrst few degrees in this hierarchy are of special importance and will
be shown to be the degrees of certain unsolvable problems considered in
Chapter 1.
0 = deg(∅) = {B : B is computable};
0′ = deg(∅′), where ∅′ := K∅≡K ≡K0 ≡K1;
0′′ = deg(∅′′) = deg(Fin) = deg(Tot) = deg(Inf);
0′′′ = deg(∅′′′) = deg(Cof) = deg(Rec) = deg(Ext).
By deﬁnition, degree 0 is the least degree and consists precisely of the
computable sets. Degree 0′ (read “zero prime”) is the degree of the halting
problem and also the degree of the problem K1 = {x : Wx ̸= ∅} because
K ≡K1 ≡K0 by Theorem 2.4.2. The above characterizations for 0′′ and
0′′′ will be shown in Chapter 4. In §3.6.3 we use the jump to deﬁne the
low and high sets according to their information content, and we develop
further lowness and highness properties in §4.4 and §4.7.
Deﬁnition 3.4.4. Fix A ⊆ω and let a = deg(A). Relativizing Deﬁni-
tion 2.6.1 to A we deﬁne a sequence of sets {Vn}n∈ω to be uniformly
computable in A (uniformly of degree ≤a) if there is an A-computable
function g(x, n) such that λx [ g(x, n) ] is the characteristic function of Vn,
for all n.
3.4.3
Exercises
Exercise 3.4.5. Prove that there are at least 2ℵ0 degrees. Conclude that
there are exactly 2ℵ0 degrees.

3.5.
⋆Limit Computable Sets and Domination
63
0
0′
0′′
0(n)
...
degrees a ≤0′
c.e. degrees C
all
Turing
degrees
Figure 3.1. Turing Degrees (D, ≤)
Exercise 3.4.6. Show that deg(A⊕B) is the least upper bound for deg(A)
and deg(B) in (D, ≤, ∪).
Exercise 3.4.7. (a) Let {Ay}y∈ω be any countable sequence of sets. Deﬁne
the inﬁnite join ⊕yAy as in (2.29). Prove that deg(⊕yAy) is the uniform
least upper bound for {deg(Ay)}y∈ω in the sense that if there exist a set C
and a computable function f such that Ay = ΦC
f(y) for all y, then ⊕yAy ≤T
C.
(b) Prove that this operation is not well deﬁned on degrees. Namely, de-
ﬁne {Ay}y∈ω and {By}y∈ω such that Ay ≡T By but A ̸≡T B for A = ⊕yAy
and B = ⊕yBy.
Exercise 3.4.8. Prove that ∅′ ≡K. (Recall that Φ∅is an acceptable
numbering by Exercise 3.3.17.)
3.5
⋆Limit Computable Sets and Domination
The most interesting and important classes include not only the class
of computable sets, but also those sets which can be approximated by a
computable sequence. There are various levels of eﬀectiveness in these ap-

64
3. Turing Reducibility
proximations. We began with a c.e. set (Σ1 set) A = ∪s∈ωAs where As
is a monotonic computable sequence. Now we consider the more general
case A = lims As sometimes called a “trial and error” predicate because
membership of x ∈As can change ﬁnitely often as s goes to inﬁnity. This
is a limit computable approximation also called a ∆2-approximation.
With these approximations we also study the modulus function of Deﬁni-
tion 3.5.4 and the computation function of Deﬁnition 5.6.5, which measure
how quickly the approximation has settled. Closely connected is the idea
of domination in Deﬁnition 3.5.2, which we relate to the modulus function
in Propositon 3.5.5. We develop more properties of domination in Deﬁni-
tion 4.5.1, along with its negation, called escape. We relate these two key
ideas of domination and escape to classes of degrees in §4.7.
3.5.1
Domination and Quantiﬁers (∀∞x) and (∃∞x)
Deﬁnition 3.5.1. (i) (∃∞x) R(x) abbreviates (∀y)(∃z > y) R(z),
i.e., “there exist inﬁnitely many x such that R(x).”
(ii) (∀∞x) R(x) abbreviates (∃y)(∀z > y) R(z),
i.e., “for almost every x, R(x),” often written as (a.e. x) R(x).
These quantiﬁers are dual because (∀∞x) R(x) iﬀ¬(∃∞x)¬R(x).
Deﬁnition 3.5.2. (i) A function g dominates f, denoted by f <∗g, if
(3.13)
(∀∞x) [ f(x) < g(x) ].
(ii) If g does not dominate f then we say that f escapes g, i.e.,
(3.14)
(∃∞x) [ g(x) ≤f(x) ].
3.5.2
Uniformly Computable Sequences
In analysis, a function f on the real numbers is continuous at a point x0 if
(∀ϵ > 0)(∃δ > 0) [ |x −x0| < δ
=⇒
|f(x) −f(x0)| < ϵ ].
A sequence of functions fn(x) on the reals is uniformly continuous if the
δ may be chosen to be independent of n, i.e.,
(∀ϵ > 0)(∃δ > 0)(∀n)[ |x −x0| < δ
=⇒
[ |fn(x) −fn(x0)| < ϵ ].
We often build a sequence of computable functions {fs(x)}s∈ω or sets
in stages s ∈ω. Each function fs is computable by some individual al-
gorithm, but we usually need to uniformly compute the sequence with a
single computable function g(x, s) = fs(x).

3.5.
⋆Limit Computable Sets and Domination
65
Deﬁnition 3.5.3. A sequence of computable functions {fs(x)}s∈ω or
sets is uniformly computable if there is a computable function g such
that g(x, s) = fs(x) for all s and x. We also call this a computable se-
quence because the function g deﬁnes the sequence and the elements in its
members.
If {As}s∈ω is a sequence of computable sets, then the property of being
computable is shared by every member of the sequence, i.e., every As has
a computable characteristic function hs(x). However, we do not call this a
uniformly computable sequence unless there is a single computable func-
tion g(x, s) such that g(x, s) = hs(x). This is the same concept as that in
the Enumeration Theorem 1.5.3. There we had every partial computable
function ϕe identiﬁed with a Turing machine Pe which computed it. How-
ever, in virtually all constructions we also needed to uniformly list them
with a single p.c. function ψ(e, x) = ϕe(x) guaranteed by Theorem 1.5.3.
Similarly, in Deﬁnition 2.6.1 we deﬁned the concept of sequence {Ve}e∈ω
of c.e. sets as being uniformly c.e. if there is a single computable function
g(e) such that Ve = Wg(e). Recall that A↾↾x denotes {A(y) : y ≤x}.
3.5.3
Limit Computable Sets
Deﬁnition 3.5.4. (i) A set A is limit computable if there is a computable
sequence {As}s∈ω such that for all x,
(3.15)
A(x) = lims As(x).
By the Limit Lemma 3.6.2 (ii), we call {As}s∈ω a ∆2-approximation for A.
(ii) Given {As}s∈ω, any function m(x) is a modulus (of convergence) if
(3.16)
(∀x)(∀s ≥m(x)) [ A↾↾x = As ↾↾x ].
We deﬁne the least function:
(3.17)
mA(x) = (µs) [ A↾↾x = As ↾↾x ].
(iii) If A is c.e., then a computable sequence {As}s∈ω is a Σ1-approximation
to A if A = ∪sAs and As ⊆As+1. In this case mA(x) is a modulus and is
called the least modulus.
We could have alternatively deﬁned the least modulus as the ﬁrst stage
after which the approximation is always correct, i.e.,
(3.18)
qA(x) = (µs)(∀t ≥s) [ A↾↾x = At ↾↾x ].
The advantage is that qA is a modulus in the sense of (3.16). The disad-
vantage is that qA ̸≤T A in the ∆2 case, because for a ∆2-sequence the

66
3. Turing Reducibility
approximation may attain the correct value, change to an incorrect value,
and later return to the correct value.
In the Σ1 case, mA = qA and mA ≤T A, so we have the best of both
worlds. We shall explore modulus properties in the next Proposition 3.5.5,
the Limit Lemma 3.6.2 and the Modulus Lemma 3.6.3. We shall later deﬁne
the closely related computation function in Deﬁnition 5.6.5.
Proposition 3.5.5. (i)
If A is limit computable via {As}s∈ω with any
modulus m(x), then A ≤T m.
(ii) Conversely, if A is c.e. via a Σ1-approximation {As}s∈ω or is ∆2 via a
∆2-approximation {As}s∈ω with least function mA(x), then mA(x) ≤T A.
(iii)
Let {As}s∈ω be a Σ1-approximation to a c.e. set A and mA(x) be
the least modulus. If g(x) dominates mA(x) then A ≤T g. If g ≤T ∅then
A ≤T ∅.
(iv)
Let {As}s∈ω and {Ds}s∈ω be Σ1-approximations of A and D with
least modulus functions mA(x) and mD(x) respectively. If mD(x) dominates
mA(x), then A ≤T D.
Proof. (i) A(x) = Am(x)(x).
(ii) From A and {As}s∈ω we can compute the least function mA(x).
(iii) Note that (∀∞x)[ Ag(x)(x) = A(x) ]. Therefore, A ≤T g.
(iv) (∀∞x) [ x ∈A
⇐⇒
x ∈AmD (x) ].
Proposition 3.5.5 (iii) fails for a ∆2-approximation even if the computable
function g(x) dominates the least function mA(x) in (3.17). Exercise 3.5.6
shows just how weak the least function mA is for ∆2-sequences, although
for Σ1-sequences it is very powerful because mA = qA for Σ1-sequences.
However, in the ∆2-case, if we replace the least function mA(x) by the
closely related computation function cA(x) of Deﬁnition 5.6.5 (5.15), then
Proposition 3.5.5 (iii) holds, as we shall prove in Theorem 5.6.6.
3.5.4
Exercises
Exercise 3.5.6. Construct a noncomputable ∆2 set A, a computable func-
tion f(x), and a ∆2-approximation {As}s∈ω such that f(x) dominates the
least function mA(x). (Compare with the Σ1 case in Proposition 3.5.5 (iii).)
3.6
⋆⋆The Limit Lemma
We have studied the Σ0
1, Π0
1, and ∆0
1 sets. In Chapter 4 we shall study the
Σ0
n, Π0
n, and ∆0
n sets in the arithmetical hierarchy. However, the following

3.6.
⋆⋆The Limit Lemma
67
property, ∆0
2, plays such an important role in the Limit Lemma 3.6.2 below
that we introduce it now. We often drop the superscript 0 for convenience.
Deﬁnition 3.6.1. (i) A set A is Σ2 if there is a computable relation R
with
x ∈A
⇐⇒
(∃y)(∀z) R(x, y, z).
(ii) A set A is Π2 if A is Σ2.
(iii) A set A is ∆2 if A ∈Σ2 and A ∈Π2.
The following three properties are used very often and completely inter-
changeably without explanation.2 Shoenﬁeld in [Shoenﬁeld 1959] proved
the equivalence of (i) and (iii). The equivalence of (ii) follows from Post’s
Theorem 4.2.2 (iv), a part of which is introduced here.
Lemma 3.6.2 (Limit Lemma, Shoenﬁeld, 1959).
TFAE:
(i) A is limit computable;
(ii) A ∈∆2;
(iii) A ≤T ∅′.
Proof. (i) =⇒(ii). Let A(x) = lims As(x) with {As}s∈ω computable.
Then
x ∈A
⇐⇒
(∃s)(∀t)[ t > s
=⇒
At(x) = 1 ]
x ∈A
⇐⇒
(∃s)(∀t)[ t > s
=⇒
At(x) = 0 ]
and therefore, A ∈Σ2 and A ∈Σ2.
(ii) =⇒(iii). Assume there are computable relations R and S such that
x ∈A ⇐⇒(∃s)(∀t)R(x, s, t)
&
x ∈A ⇐⇒(∃s)(∀t)S(x, s, t).
The predicate (∀t)R(x, s, t) is Π1 and therefore computable in ∅′. Hence,
the predicate (∃s)(∀t)R(x, s, t) is Σ1 in ∅′ and therefore c.e. in ∅′, and
likewise for (∃s)(∀t)S(x, s, t). Therefore, A and A are each c.e. in ∅′. Thus,
A ≤T ∅′.
2Some authors introduce the property of limit computable as above, but use the
name ∆0
2 for it. It is not correct to deﬁne a set A to be ∆0
2 if it has the limit computable
property. However, after proving the equivalence of the three properties in the Limit
Lemma 3.6.2, authors often mention one term (such as, A is ∆0
2 or A ≤T ∅′) and then
immediately use another property, such as A limit computable, without explanation.

68
3. Turing Reducibility
(iii) =⇒(i).
Fix a computable sequence {Ks}s∈ω with ∪sKs = K ≡∅′.
Assume A = ΦK
e . For every x and s deﬁne
f(x, s) =



ΦKs
e,s(x)
if deﬁned;
0
otherwise.
For every x the ﬁrst clause holds for all but ﬁnitely many s. Therefore,
A(x) = lims f(x, s).
3.6.1
The Modulus Lemma for C.E. Sets
Lemma 3.6.3 (Modulus Lemma).
If B is c.e. and A ≤T B, then
A = lims As for a computable sequence {As}s∈ω with a modulus m(x) ≤T
B.
Proof. Let B = ∪sBs be c.e., A = ΦB
e and deﬁne
As = { x : x < s
&
ΦB
e (x) [ s ]↓= 1 },
m(x) = (µs)(∃z ≤s)(∀y ≤x) [ ΦB↾z
e
(y) [ s ]↓
&
B ↾z = Bs ↾z ].
Now {As}s∈ω is a computable sequence because the deﬁning clause for As
is computable. Furthermore, m(x) is B-computable because the quantiﬁers
are bounded, the ﬁrst clause in the matrix deﬁning m(x) is computable,
and the second clause is B-computable. Finally, m(x) is a modulus because
by the Use Principle 3.3.9 the matrix of m(x) holds for all s ≥m(x).
Deﬁnition 3.6.4. Let {As(x)}s∈ω be a uniformly computable sequence of
computable sets, such that (∀x)[lims As(x) exists]. Deﬁne the change set,
(3.19)
C = { ⟨s, x ⟩: (∃t)s<t [ As(x) ̸= At(x) ] }.
Note that C is Σ1 and hence c.e., and that the x-section A[x] is ﬁnite
for every x. (See Deﬁnition 3.8.7 for the deﬁnition of the x-section.) We
call C the change set because if ⟨s, x⟩∈C then the value As(x) will later
change at some stage t > s. The change set C will be used in the proof of
the following Theorem 3.6.5 and in Theorem 3.8.8.
Theorem 3.6.5 (Modulus Criterion). A has c.e. degree iﬀA = lims As
for some computable sequence {As}s∈ω with a modulus m ≤T A.
Proof. ( =⇒).
Let A ≡T B with B c.e. Apply the Modulus Lemma 3.6.3
to obtain a computable sequence {As}s∈ω with a modulus m(x) ≤T B.
( ⇐= ).
Let A = lims As with m ≤T A. The deﬁnition of C in (3.19) is
equivalent if we replace the quantiﬁer bound s < t by s < t ≤m(x) because
m(x) is a modulus. Therefore, C ≤T m ≤T A. Furthermore, A ≤T C

3.6.
⋆⋆The Limit Lemma
69
because, given x, we can ﬁnd some ⟨s, x⟩∈C. Now x ∈A iﬀx ∈As.
Hence, A ≡T C .
3.6.2
The Ovals of Σ1 and ∆2 Degrees
Imagine the degrees d ≤0′ as an oval with top 0′ and bottom 0. The Limit
Lemma 3.6.2 exactly characterizes the ∆2 degrees as the degrees in this
outer oval. Now imagine a smaller oval inside the ﬁrst oval with the same top
0′ and bottom 0 but containing only the computably enumerable degrees.
Theorem 3.6.5, building on the Limit Lemma 3.6.2, characterizes the sets
and degrees in this inner oval of c.e. degrees. Let A be limit computable
via the ∆2 approximating sequence {As}s∈ω with least function mA(x). By
Proposition 3.5.5 (ii) we always have the least function mA ≤T A. For a
∆2-approximation the least function mA(x) may not always be a modulus.
Remarkably, however, if A has c.e. degree, then m ≤T A holds for some
modulus m of some particular ∆2 approximation for A, as Theorem 3.6.5
demonstrates. Note that all the above results on approximating a set A =
lims As hold by the same proofs as those for approximating a function
f = lims fs.
3.6.3
Reaching With the Jump: Low and High Sets
The jump A′ = KA was deﬁned in Deﬁnition 3.4.2. If A ≤T B then A′ ≤T
B′ by the Jump Theorem 3.4.3 (v). This asserts that the jump preserves
the Turing reducibility. Therefore, if A ≤T ∅′, then ∅′ ≤T A′ ≤T ∅′′. We
now classify sets A ≤T ∅′ as low or high according as to whether A′ has
the lowest or highest possible value.
Deﬁnition 3.6.6. Fix a set A ≤T ∅′.
(i) A is low if A′ ≡T ∅′, the lowest possible value.
(ii) A is high if A′ ≡T ∅′′, the highest possible value.
According to the Limit Lemma 3.6.2 relativized to A, we see which
A′ has the greatest degree under ≤T that can be approximated by an
A-computable sequence. Think of the jump A′ as the reach of A as mea-
sured with respect to standard mileposts such as ∅′ and ∅′′. The jump
(reach) measures the information content of A. A low set A has low com-
puting power because KA, the halting problem relativized to A, has the
same degree as the unrelativized halting problem K. Hence, A does not
extend the reach of the jump over the computable case.
As the terminology suggests, a computable set has zero information con-
tent, a low set has low information content (but may be noncomputable), a
high set has high information content (but is not necessarily complete), and

70
3. Turing Reducibility
a complete set A ≡∅′ has complete information content with respect to
other c.e. sets. The study of the information content and algebraic structure
of low and high sets will be a major theme throughout the book. We shall
develop a connection between the high/low sets and domination/escape
properties in §4.7.
Low Sets
If A is low its reach is only ∅′, as for a computable set C. It resembles the
computable sets in algebraic structure and information content, as we shall
see later. In the Low Basis Theorem 3.7.2 we shall prove that every inﬁnite
computable binary tree T ⊆2<ω may not have a computable path, but it
does have a low path which is almost as good.
High Sets
If A is high its reach is A′ ≡T ∅′′. In §4.3.1 we shall prove that Tot ≡T ∅′′,
where Tot := { e : ϕe total }. This means that there is an A-computable
sequence {As}s∈ω such that lims As(x) = Tot(x), which says that Tot is
only a “jump away” from A in the sense that Tot is A-limit computable.
This is a very strong property with many consequences, as we shall prove
in Chapter 4 and in subsequent chapters. For the rest of this chapter we
consider only low sets and in Chapter 4 we consider a spectrum of high
and low sets.
3.6.4
Exercises
Exercise 3.6.7.
In the Limit Lemma 3.6.2 there are six possible direct
implications among the three properties (i), (ii) and (iii) listed there. There
we proved (i) =⇒(ii) =⇒(iii) =⇒(i). Give a direct proof of the re-
maining three implications: (i) implies (iii) (which was also proved directly
in Theorem 3.6.5 using the change set C deﬁned in (3.19); (iii) implies (ii);
and (ii) implies (i).
Exercise 3.6.8. (Relativized Limit Lemma). Prove the Limit Lemma 3.6.2
relativized to a set A.
Exercise 3.6.9. (Iterated Limit Lemma).
Prove that if n ≥1, then
f ≤T ∅(n) iﬀthere is a computable function bf of (n + 1) variables such
that
f(x) = limy1 limy2 · · · limyn bf(x, y1, y2, . . . yn).

3.7.
⋆Trees and the Low Basis Theorem
71
3.7
⋆Trees and the Low Basis Theorem
3.7.1
Notation for Trees
Deﬁnition 3.7.1. (i)
A tree T ⊆ω<ω is a set of strings closed under
initial segments, i.e., σ ∈T and τ ≺σ imply τ ∈T. Fix any tree T.
(ii) The class of inﬁnite paths through T is:
(3.20)
[ T ] = { f : (∀n) [ f ↾n ∈T ] }.
(iii) A class C ⊆2ω is a Π0
1-class if C = [ T ] for some computable binary
tree T ⊆2<ω.
(iv) For σ ∈T, deﬁne the subtree Tσ of nodes τ ∈T comparable with σ:
(3.21)
Tσ = { τ ∈T : σ ⪯τ
∨
τ ≺σ }.
(v) Deﬁne the subtree of extendible nodes σ ∈T:
(3.22)
T ext = { σ ∈T : (∃f ≻σ)[ f ∈[ T ] ] }
The tree T is extendible if T = T ext. If T ⊆2<ω is computable, then
T ext is co-c.e. (See Exercise 3.7.4.)
3.7.2
⋆The Low Basis Theorem for Π0
1 Classes
Let T ⊆2<ω be an inﬁnite computable tree. What are the degrees of
members f ∈[ T ]? We cannot always ﬁnd a computable path but we can
always ﬁnd a low path. We shall deﬁne and explain bases for Π0
1-classes in
Chapter 9.
Theorem 3.7.2 (Low Basis Theorem, Jockusch-Soare, 1972b). If C ⊆2ω
is a nonempty Π0
1 class, then it contains a member f of low degree (f ′ ≡T
0′).
Proof. Now ∅′ can decide whether a computable tree G ⊆2<ω is ﬁnite
because
(3.23)
|G| < ∞
⇐⇒
(∃n)(∀σ)|σ|=n [ σ ̸∈G ].
The bounded quantiﬁer in front of the computable matrix remains com-
putable, and the (∃n) quantiﬁer makes the condition Σ1 hence computable
in ∅′. Let T be a computable tree such that [T] = C. Use ∅′ to deﬁne a
sequence of inﬁnite computable trees T = T0 ⊇T1 ⊇. . . as follows. Deﬁne:
(3.24)
Ue
=
{ σ : Φσ
e, |σ| (e)↑},

72
3. Turing Reducibility
which is also a computable tree. Given Te: (1) deﬁne Te+1 = Te ∩Ue if
Te ∩Ue is inﬁnite; and (2) deﬁne Te+1 = Te otherwise. If (1), then Φg
e(e)↑
for all g ∈[Te+1], and if (2), then Φg
e(e)↓for all g ∈[Te+1]. (Namely, we say
that Te+1 forces the jump as described in Chapter 6.) Choose f ∈∩e∈ω[Te],
which is an intersection of a descending sequence of nonempty closed sets,
and is hence nonempty by the compactness of Cantor space 2ω. (See the
Compactness Theorem 8.3.1 (ii).) Now ∅′ can decide using (3.23) which of
(1) and (2) holds in the deﬁnition of Te+1 and hence whether Φf
e(e) ↓or
not. Therefore, f ′ ≤T ∅′ and f is low.
We can also use this method to prove a similar basis theorem that any
nonempty Π0
1 class C ⊆2ω contains a member f such that every g ≤T f is
dominated by a computable function.
3.7.3
Exercises
Exercise 3.7.3. (a) Prove that T ext is the smallest subtree of T under
inclusion such that [ T ext ] = [ T ], i.e., prove that if [ T1 ] = [ T ], then
T ext ⊆T1.
(b) Prove that Tσ is inﬁnite iﬀ[ Tσ ] ̸= ∅.
Exercise 3.7.4. (a) Fix computable tree T ⊆2<ω. Let T
ext = T −T ext.
Prove that T
ext is Σ1 and therefore T ext is Π1. Conclude that T ext ≤T ∅′.
(b)
Prove directly the Kreisel Basis Theorem that if T is computable
and [ T ] ̸= ∅then [ T ] contains a member f ≤T ∅′. (Do not use the Low
Basis Theorem 3.7.2.)
Exercise 3.7.5. Prove that there is a computable inﬁnite tree T ⊂2<ω
with no computable inﬁnite paths.
Exercise 3.7.6. Prove that if C ⊆2ω is a nonempty Π0
1 class, then the
lexicographically least member f ∈C has c.e. degree.
Exercise 3.7.7. (a) Let T ⊆2<ω be a tree. A point f ∈[ T ] is isolated
if there exists a σ ∈T such that [ Tσ ] = {f}, in which case we say that σ
isolates f in T. Prove that if T is computable and f is isolated, then f is
computable.
(b) Show that if T is computable and [ T ] is ﬁnite, then all its members
are isolated and hence computable.

3.8. Bounded Reducibilities and n-C.E. Sets
73
3.8
Bounded Reducibilities and n-C.E. Sets
3.8.1
A Matrix Mx for Bounded Reducibilities
A bounded reducibility is a Turing reducibility ΦA
e (x) with a computable
function h(x) which bounds the use function, i.e., ϕA
e (x) < h(x). Given h(x)
imagine a matrix Mx with a column y for every y < h(x) corresponding to
the question “is y ∈A?” The rows of Mx are all strings σ of length h(x)
corresponding to the 2h(x) many answers over all such y < h(x).
The action of ΦA
e on x is entirely determined by the action of Φσ
e (x) for
these rows σ of Mx. For example, if B ≤m A via a computable function
f(x), then h(x) = f(x) + 1 and x ∈B iﬀσ(f(x)) = 1, where σ ≺A.
We begin in §3.8.2 with the most general bounded reducibility called
bounded Turing reducibility (B ≤bT A), where we are given only the com-
putable bound h(x), i.e., only the matrix Mx. In §3.8.3 we study the more
restrictive case of truth-table reducibility (B ≤tt A), where Φσ
e (x) converges
for every x and every row σ ∈Mx. (See Remark 3.8.3.)
3.8.2
Bounded Turing Reducibility
Deﬁnition 3.8.1. (i) A set B is bounded Turing reducible (bT-reducible)
to a set A (B ≤bT A) (also called weak truth-table (wtt) reducible) if there
is a Turing reduction ΦA
e = B and a computable function h(x) such that
the use ϕA
e (x) < h(x).3
(ii) A set B is identity bounded Turing reducible to A (B ≤ibT A) if B ≤bT
A with h(x) = x + 1.4
The bT-reductions and ibT-reductions occur naturally in several parts
of the subject.5 For example, often we are given a noncomputable c.e. set
A and we construct a simple set B ≤T A by ordinary permitting, as in
3In his 1944 paper Section 6 Post introduced the deﬁnition of B ≤tt A which became
rapidly understood. Turing reducibility was not well understood in the 1940s and 1950s.
Therefore, in 1959 Friedberg and Rogers introduced bT-reducibility as wtt-reducibility
(B ≤wtt A) i.e., as a weakening of tt-reducibility which was already a strengthening of
≤T. Today we understand Turing reducibility as in this chapter and view bT-reducibility
as a one-step strengthening of ≤T without the need for any intermediate step. Also bT
is more recognizable from its name than wtt.
4Note that ibT occurs often, for example, with simple permitting in Theorem 5.2.7.
5More recently, ibT has occurred in applications of computability to diﬀerential ge-
ometry by Soare in 2004 and Csima and Soare in 2006, and ibT-reducibility has also been
used in applications to algorithmic randomness and Kolmogorov complexity. Barmpalias
and Lewis in 2006 have shown the nondensity of the ibT-degrees of c.e. sets.

74
3. Turing Reducibility
§5.2 where an element x is allowed to enter B at some stage only if some
y ≤x has just entered A. When A↾↾x has settled, B ↾↾x has settled also,
so B ≤ibT A.
3.8.3
Truth-Table Reductions
Recall that |σ| denotes the length of σ, and σy is the string with canonical
index y as deﬁned in Deﬁnition 2.3.6. We identify σy and its index y and
write g(σ) to mean g(y) in (ii).
Deﬁnition 3.8.2.
A set B is truth-table reducible (tt-reducible) to a set
A (B ≤tt A) if there are computable functions h(x) and g(x) with the
following properties.
(i)
To determine whether x ∈B the reduction procedure may ask ques-
tions of the form “is y ∈A?” only for elements y < h(x). (This is exactly
as in the bounded Turing Deﬁnition 3.8.1.) This determines 2h(x) many
strings { σi : i < 2h(x)} of 0’s and 1’s, each of length h(x), which we call
the rows of the truth-table.
(ii)
The function g(x) selects which rows for which the answer is “yes”
that x ∈B as follows.
x ∈B
⇐⇒
(∃i < 2h(x)) [g(i) = 1
&
σi ≺A}.
Remark 3.8.3. Both the bT-reduction and the tt-reduction use the matrix
Mx described in §3.8.1, The crucial diﬀerence between a bT-reduction and
a tt-reduction is that in the latter case Φσ
e (x) must be deﬁned for every row
σ ∈Mx but in the bT case only some rows σ need to have Φσ
e (x) deﬁned.
Therefore, the tt-reduction must not only have a bound h(x) on the infor-
mation scanned, but in advance of A it must also give the answer Φσ
e (x)
for all rows σ of length h(x). As we range through these rows, g(σ) = 1 in
Theorem 3.8.5 selects exactly those rows σ which have Φσ
e (x) = 1. See The-
orem 5.3.6 for a natural tt-reduction D ≤tt A. For a bT-reduction ΦA
e = B
we do not have a complete table Mx as for tt. We have only a c.e. graph
Ge as in Deﬁnition 3.3.7 consisting of strings ⟨σ, x, y⟩except that all the
strings σ have |σ| < h(x). We cannot decide which rows σ will appear in
Ge.
Deﬁnition 3.8.4. (i)
A partial functional Ψ on Cantor space 2ω is a
partial map with dom(Ψ) and rng(Ψ) ⊆2ω. (We use the term functional
for maps whose input and output may be an inﬁnite object A ∈2ω to
distinguish from functions from ω to ω.)
(ii) A Turing functional Φe on 2ω is total if (∀X)(∀x) [ ΦX
e (x) is deﬁned ].

3.8. Bounded Reducibilities and n-C.E. Sets
75
The next theorem gives the very pleasing characterization that Φe is a
tt-reduction iﬀΦe is total. This is sometimes taken as a deﬁnition of the
former, but this elegant property is a theorem, not a deﬁnition.
Theorem
3.8.5
(Truth-Table Theorem, Nerode).
The following
deﬁnitions of tt-reducible are equivalent.
(i) B ≤tt A as deﬁned in Deﬁnition 3.8.2.
(ii) ΦA
e
= B for some total Φe.
(iii) There is a computable function g(x) such that for every x
x ∈B
⇐⇒
( ∃y ∈Dg(x) ) [ σy ≺A ].
Proof. (i) =⇒(ii). Obvious because (i) ensures Φe total.
(ii) =⇒(iii). Uniformly in x, enumerate the set Ux = { σ : Φσ
e (x)↓}. Since
Φe is total, we apply the Compactness Theorem 8.3.1 (iv) to get a ﬁnite
subset Fx ⊆Ux with ∪σ∈Fx J σ K
= 2ω. To ﬁnd Fx uniformly eﬀectively
in x, keep enumerating Ux until Fx appears. Deﬁne h(x) = max{ |σ| : σ ∈
Fx} and deﬁne g(x) by
Dg(x) = { y : |σy| = h(x)
&
Φσy
e (x) = 1 }.
Now g(x) satisﬁes (iii).
(iii) =⇒(i). If (iii) holds via g(x), let h(x) = max{ |σ| : σ ∈Dg(x) }. For
every σ of length h(x), deﬁne:
Φσ
e (x) =



1
(∃τ ⪯σ) [ τ ∈Dg(x) ];
0
otherwise.
Now Φe with h(x) satisﬁes (i).
3.8.4
Diﬀerence of C.E., n-c.e., and ω-c.e. Sets
The Limit Lemma 3.6.2 characterized sets A ≤T ∅′ as those where
A = lims As for a computable sequence {As}s∈ω. Now consider special cases
based on how many times the approximation changes on x. These notions
are more general than c.e. sets A, but not the most general case of A ≤T ∅′.
Deﬁnition 3.8.6. (i)
A set D is the diﬀerence of c.e. sets (d.c.e.) if
D = A −B where A and B are c.e. sets.
(ii) A set A is omega-c.e. (written ω-c.e.) if there is a computable sequence
{As}s∈ω with A0 = ∅and As(x) ∈{0, 1}, and a computable function g(x)

76
3. Turing Reducibility
which bounds the number of changes in the approximation {As}s∈ω in the
following sense,
(3.25)
A = lims As
&
| { s : As(x) ̸= As+1(x) } | ≤g(x).
(iii) For n ∈ω the set A is n-c.e. if g(x) ≤n.
For example, the only 0-c.e. set is ∅, the 1-c.e. sets are the usual c.e. sets,
and the 2-c.e. sets are the d.c.e. sets. The next theorem gives an elegant
characterization of ω-c.e. sets.
Deﬁnition 3.8.7. For any set A ⊆ω deﬁne the y-section of A,
(3.26)
A[ y ] = { ⟨x, z⟩: ⟨x, z⟩∈A
&
z = y }.
Using the pairing function we can identify A with a subset of ω × ω and
view A[ y ] as the yth row of A. We use the square bracket notation A[ y ] to
distinguish from the yth jump A(y). We also use this notation in Chapter 6
and other chapters.
Theorem 3.8.8 (Bounded T-Reducibility Theorem). The following are
equivalent.
(i) A ≤bT ∅′.
(ii) A is ω-c.e.
(iii) A ≤tt ∅′.
Proof. Clearly, (iii) implies (i).
(i) =⇒(ii). We use K for ∅′ for notational clarity. Suppose ΦK
e = A with
computable bound g(x) ≥ϕK
e (x) as in (3.25). Let { bAs}s∈ω be any com-
putable enumeration of A. We speed up the given A enumeration { bAs}s∈ω
to obtain a new enumeration {As}s∈ω of A as follows. Given s ﬁnd the
least t > s such that
(∀x ≤t) [ bAt(x) = Φ Kt
e, t (x) ],
and deﬁne As = bAt. Now As+1(x) ̸= As(x) only if some element z ≤g(x)
enters K, which can happen at most g(x) + 1 times, once for each z ∈
[0, g(x)].
(ii) =⇒(iii).
Assume A = lims As satisﬁes (3.25) via g(x). Deﬁne the
c.e. change set C as in (3.19). Therefore, |C[x]| is the number of changes
on x during the approximation, and |C[x]| ≤g(x) by hypothesis (ii). Fur-
thermore, A(x) = 1 iﬀ|C[x]| is odd, because the approximation changes
between 0 and 1 starting with 0.
First build a truth-table to demonstrate that A ≤tt C. For a given x
the truth-table has rows of width g(x) as in Deﬁnition 3.8.2 (ii). For each

3.8. Bounded Reducibilities and n-C.E. Sets
77
k ≤g(x) construct a row beginning with k many 1’s followed by all 0’s.
Now to tt-compute from C whether x ∈A, compute k = |C[x]|. Next, ﬁnd
the row beginning with k many 1’s. Now A(x) = 1 iﬀk is odd. Hence,
A ≤tt C. However, C is c.e. Hence, C ≤m ∅′ and therefore A ≤tt ∅′.
This proof shows the diﬀerence between T-reductions and tt-reductions.
First, the assumption on h(x) ensures that A ≤bT C. Second, the approx-
imation always begins with As(x) = 0 for s = 0 and changes between 0
and 1 because all values are in {0, 1} rather than in ω. Therefore, we can
make up a row in the truth-table which gives a value for A(x) based only
on the number of changes. This ensures that A ≤tt C. This case is unusual
since most reductions we consider produce only A ≤T B for some set B
and sometimes produce A ≤bT B, as in permitting arguments. Note that
instead of directly building a truth-table we could argue that this process
builds a total functional ΦC
e = A, which it clearly does.
Remark 3.8.9. To speed up an enumeration of a c.e. set A means to take
a given computable enumeration { bAs}s∈ω and produce a new computable
enumeration {As}s∈ω with As ⊇bAs by using some special hypotheses on
A such as above or such as A being low as we shall see later.
3.8.5
Exercises
Exercise 3.8.10. Let f be a one-one computable function with range A.
Deﬁne the deﬁciency set for this enumeration f to be:
D = { s : (∃t > s) [ f(t) < f(s) ] }.
Prove that A ≤T D and D ≤tt A.
Exercise 3.8.11. Show that the ω-c.e. sets are closed under union and
complementation and therefore form a Boolean algebra.
Exercise 3.8.12. (i) Show that A is (2n + 1)-c.e. iﬀA is the union of n
d.c.e. sets and a c.e. set.
(ii) Show that a set A is (2n + 2)-c.e. iﬀA is the union of n + 1 d.c.e. sets.
Exercise 3.8.13. Show that the m deﬁned in the Modulus Lemma 3.6.3
is not necessarily the least modulus. Explicitly deﬁne the least modulus as
an A-computable function.
Exercise 3.8.14. Deﬁne Cn = { e : |We| = n }.
(i) For n ≥0, show that Cn is d.c.e.
(ii) For n ≥0, show that Cn is not c.e.
Exercise 3.8.15. Show that the d.c.e. sets are closed under intersection.

78
3. Turing Reducibility
Exercise 3.8.16. Show that for each n there is an (n + 1)-c.e. set which
is not n-c.e. Hence, the d.c.e. sets are not closed under union.
Hint. Fix n. First specify a method to eﬀectively list all n-c.e. sets
{Zn
e }e∈ω. Next, treat this as a game in which Player I can insert or
delete an element xe from his (n+1)-c.e. set D in order to arrange that
D(xe) ̸= Zn
e (xe). The D-player has one more move for xe than the Zn
e -
player does. Hence, this closely resembles and generalizes Theorem 1.6.5
that K is not computable because as a 1-c.e. set K has one more move
than any computable function ϕe.
Exercise 3.8.17. (Jockusch and others). Show by induction on n that if
A is n-c.e. then either A or A contains an inﬁnite c.e. set.
Exercise 3.8.18.
Suppose that A and B are c.e. sets and A is not
computable. Prove that A × A ̸≤m B ⊕B.
Hint. (Jockusch).
Suppose for a contradiction that f is a computable
function such that for all x and y
x ∈A & y ∈A ⇐⇒f(x, y) ∈B ⊕B.
Deﬁne C = { y : (∃x) [ f(x, y) ∈B ⊕∅] }. Show that C is c.e., C ⊆A, and
that there exists a ∈A −C. Show that for all x,
x ∈A
⇐⇒
f(x, a) ∈∅⊕B.
Hence, A is co-c.e.
Exercise 3.8.19. (i) Show that K × K is d.c.e.
(ii) Show that if D is d.c.e. then D ≤1 K×K. (Hence, K×K is 1- complete
with respect to d.c.e. sets.)
(iii) Show that K ⊕K is d.c.e.
(iv) Using Exercise 3.8.18 show that it is false that K × K ≤m K ⊕K.
(Hence, K ⊕K is neither 1-complete nor m-complete with respect to d.c.e.
sets.
Exercise 3.8.20. Deﬁne A := {x : Wx = {0}}. Give an alternative proof
that K × K ̸≤m K ⊕K by showing that K × K ≡m A and that A ̸≡m A
by the Recursion Theorem.
Exercise 3.8.21. Prove the relativized form of the Modulus Lemma 3.6.3.
Show that for any set B ⊆ω if A is c.e.a. in B and the function f ≤T A,
then f = lims bf(x, s) for some B-computable function bf with modulus
m ≤T A.

4
The Arithmetical Hierarchy
4.1
Levels in the Arithmetical Hierarchy
In addition to the notions of computability and relative computability,
the Kleene arithmetical hierarchy is one of the fundamental concepts of
computability theory. In §2.1 we showed that a set A is c.e. iﬀit has the
syntactical form Σ0
1 deﬁned with a string of existential quantiﬁers. Now we
deﬁne the more general notion of Σ0
n with n alternating blocks of quanti-
ﬁers. We prove that ∅(n) ∈Σ0
n −Σ0
n−1 for n > 1. Therefore, the Σ0
n classes
do not collapse, but rather form a hierarchy called the arithmetical hierar-
chy because these classes are deﬁnable in arithmetic. The relativized form
of the hierarchy enables us to deﬁne several important special classes of sets
and degrees called highn and low n, some of whose properties we develop
now, and more later. The arithmetical hierarchy was introduced in Kleene’s
paper [Kleene 1943] and was developed in Kleene’s book [Kleene 1952].
Convention 4.1.1. We now deﬁne the Σ0
n and Π0
n sets, where the super-
script 0 indicates that we are counting
number quantiﬁers, not function
quantiﬁers as in Σ1
1. We rarely mention function quantiﬁers until Part II on
open and closed classes in Cantor space. Therefore, in Part I Chapters 1–7
we usually drop the superscript 0 from Σ0
n, Π0
n, and ∆0
n, and abbreviate
these by Σn, Πn, and ∆n. Particularly in the relativized case, we write ΣA
n
rather than Σ0,A
n .
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_  
79 
4

80
4. The Arithmetical Hierarchy
Deﬁnition 4.1.2. (i) A set B is in Σ0 (Π0, ∆0) iﬀB is computable. As in
Deﬁnition 2.3.1, a ∆0-index for B is an index e such that ϕe = χB. (Indices
for Σn and Πn sets will be given in Deﬁnition 4.2.4.)
(ii)
For n ≥1,
B is in Σn (written B ∈Σn) if there is a computable
relation R(x, y1, y2, . . . , yn) such that
x ∈B ⇐⇒(∃y1) (∀y2) (∃y3) · · · (Qyn) R(x, y1, y2, . . . , yn),
where Q is ∃for n odd, and ∀for n even.
(iii) Likewise, B is Πn (B ∈Πn) if
x ∈B ⇐⇒(∀y1) (∃y2) (∀y3) · · · (Qyn) R(x, y1, y2, . . . , yn),
where Q is ∃or ∀according to whether n is even or odd.
(iv) Similarly, B is ∆n (B ∈∆n) if B ∈Σn and B ∈Πn.
(v) B is arithmetical if B ∈S
n(Σ0
n ∪Π0
n).
Note that B is arithmetical iﬀB can be obtained from a computable
relation by ﬁnitely many applications of projection and complementation.
(See Exercise 4.1.10.)
Deﬁnition 4.1.3. Fix a set A. If we replace everywhere “computable” in
Deﬁnition 4.1.2 by “A-computable” then we have the deﬁnition of B being
Σn in A (written B ∈ΣA
n ), B being Πn in A (B ∈ΠA
n ), B ∈∆A
n , and B
being arithmetical in A.
4.1.1
Quantiﬁer Manipulation
We say that a formula is Σn (Πn) if it is Σn (Πn) as a relation of its free
variables. We assume familiarity with the usual rules of quantiﬁer manipu-
lation from elementary logic for converting a formula to an equivalent one
in prenex normal form, consisting of a string of quantiﬁers (preﬁx) followed
by a formula with no quantiﬁers (matrix), which will in our case be a com-
putable relation. Using these rules we can show the following facts, which
will be frequently used to prove that a particular set is in Σn or Πn. The only
nontrivial fact is (vi), concerning bounded quantiﬁers. A bounded quantiﬁer
is one of the form (Qx ≤y)F, which abbreviates (∀x) [x ≤y =⇒F] if
Q is ∀, and (∃x) [x ≤y & F] if Q is ∃. Part (vi) asserts that bounded
quantiﬁers may be moved to the right past ordinary quantiﬁers and thus
may be ignored in counting quantiﬁer complexity.
Theorem 4.1.4. (i) A ∈Σn ⇐⇒A ∈Πn;
(ii)
A ∈Σn( or Πn) =⇒(∀m > n) [ A ∈Σm ∩Πm ];

4.1. Levels in the Arithmetical Hierarchy
81
(iii) A, B ∈Σn( Πn ) =⇒A ∪B, A ∩B ∈Σn( Πn );
(iv) [R ∈Σn & n > 0 & A = { x : (∃y) R(x, y) }] =⇒A ∈Σn;
(v) [B ≤m A & A ∈Σn] =⇒B ∈Σn;
(vi) If R ∈Σn( Πn ), and A and B are deﬁned by
⟨x, y⟩∈A ⇐⇒(∀z < y) R(x, y, z),
⟨x, y⟩∈B ⇐⇒(∃z < y) R(x, y, z),
then A, B ∈Σn( Πn ).
Proof. (i)
If A = { x : (∃y1) (∀y2) · · · R(x, −→y ) }, then
A = { x : (∀y1) (∃y2) · · · ¬R(x, −→y ) }.
(ii)
For example, if A = { x : (∃y1) (∀y2) R(x, y1, y2) }, then
A = { x : (∃y1) (∀y2) (∃y3) [R(x, y1, y2) & y3 = y3] }.
(iii)
Let A = { x : (∃y1) (∀y2) · · · R(x, −→y ) }, and
B = { x : (∃z1) (∀z2) · · · S(x, −→z ) }.
Then
x ∈A ∪B ⇐⇒(∃y1) (∀y2) · · · R(x, −→y )
∨
(∃z1) (∀z2) · · · S(x, −→z ),
⇐⇒(∃y1) (∃z1) (∀y2) (∀z2) · · · [ R(x, −→y )
∨
S(x, −→z ) ],
⇐⇒(∃u1) (∀u2) · · · [ R(x, (u1)0, (u2)0, . . .)
∨
S(x, (u1)1, (u2)1, . . .) ],
where (u)0 is the prime power coding as in the Notation section. Likewise,
this holds for A ∩B.
(iv)
Immediate by quantiﬁer contraction, as in (iii).
(v)
Let A = { x : (∃y1) (∀y2) · · · R(x, −→y ) } and B ≤m A via f. Then
B = { x : (∃y1) (∀y2) · · · R(f(x), −→y ) }.
(vi)
The proof is by induction on n. If n = 0, then A and B are clearly
computable. Fix n > 0, suppose R ∈Σn and assume (vi) for all m < n.
Then B ∈Σn by (iv). Now there exists S ∈Πn−1 such that
⟨x, y⟩∈A ⇐⇒(∀z < y) R(x, y, z),
⇐⇒(∀z < y) (∃u) S(x, y, z, u),

82
4. The Arithmetical Hierarchy
⇐⇒(∃σ) (∀z < y) S(x, y, z, σ(z)),
where σ ranges over ω<ω. Now (∀z < y) S ∈Πn−1 by the inductive hy-
pothesis, so A ∈Σn. The case R ∈Πn follows from the case R ∈Σn
by (i).
4.1.2
Placing a Set in Σn or Πn
Proposition 4.1.5.
Fin ∈Σ2.
Proof.
x ∈Fin
⇐⇒
Wx is ﬁnite
⇐⇒
(∃s) (∀t) [ t ≤s ∨Wx,t = Wx,s ].
The bracketed relation of x, s, t is clearly computable.
Proposition 4.1.6.
Cof ∈Σ3.
Proof.
x ∈Cof
⇐⇒
W x is ﬁnite
⇐⇒
(∃y) (∀z) [ z ≤y
∨
z ∈Wx ]
⇐⇒
(∃y)(∀z)(∃s) [ z ≤y
∨
z ∈Wx,s ].
Since the ﬁnal preﬁx depends only on the type and relative position of
the quantiﬁer symbols and sentential connectives, we frequently abbreviate
these calculations by replacing previously identiﬁed predicates with strings
of quantiﬁers indicating the classes to which they belong.
Proposition 4.1.7.
{ ⟨x, y⟩: Wx ⊆Wy } ∈Π2.
Proof.
Wx ⊆Wy
⇐⇒
(∀z) [z ∈Wx =⇒z ∈Wy]
⇐⇒
(∀z) [ z /∈Wx ∨z ∈Wy ]
⇐⇒
(∀z) [ ∀∨∃]
⇐⇒
∀∀∃[ . . . ]
⇐⇒
∀∃[ . . . ].
Corollary 4.1.8 (Classiﬁcation of Tot). (i) { ⟨x, y⟩: Wx = Wy } ∈Π2.
(ii) Tot = { y : Wy = ω } ∈Π2.
Proof. (i) follows by Proposition 4.1.7 and Theorem 4.1.4 (iii), and (ii)
follows from Proposition 4.1.7 with Wx = ω.

4.2.
⋆⋆Post’s Theorem and the Hierarchy Theorem
83
Corollary 4.1.9. Rec ∈Σ3. (Rec := {e : We ≡T ∅} in Deﬁnition 1.6.15.)
Proof.
x ∈Rec
⇐⇒
Wx is computable
(i.e., recursive)
⇐⇒
(∃y) [ Wx = W y ]
⇐⇒
(∃y) [ Wx ∩Wy = ∅
&
Wx ∪Wy = ω ]
⇐⇒
∃[ ∀
&
∀∃]
by Corollary 4.1.8
⇐⇒
∃∀∃[ . . . ].
4.1.3
Exercises
Exercise 4.1.10. Prove that A is arithmetical, i.e., that A ∈S
n(Σn∪Πn),
iﬀA can be obtained from a computable relation by a ﬁnite number of
applications of projection and complementation.
Exercise 4.1.11. Prove that Ext ∈Σ3 for Ext as deﬁned in Deﬁni-
tion 1.6.15.
Exercise 4.1.12. Prove that
{⟨x, y⟩: Wx and Wy are computably separable} ∈Σ3.
(Recall from Remark 2.4.15 and Exercise 1.6.26 that Wx and Wy are com-
putably separable if Wx ⊆R and Wy ⊆R for some computable set R, and
Wx and Wy are computably inseparable otherwise.)
Exercise 4.1.13. Deﬁne A ⊆∗B if A −B is ﬁnite, i.e., if A ⊆B except
for at most ﬁnitely many elements. Deﬁne A =∗B if A ⊆∗B and B ⊆∗A.
Prove that the following are two sets are Σ3:
{⟨x, y⟩: Wx ⊆∗Wy};
{⟨x, y⟩: Wx =∗Wy}.
Exercise 4.1.14. Show that { x : Wx is creative } ∈Σ3.
4.2
⋆⋆Post’s Theorem and the Hierarchy Theorem
Deﬁnition 4.2.1. A set A is Σn-complete (Πn-complete) if A ∈Σn( Πn )
and B ≤1 A for every B ∈Σn( Πn ). (By Exercises 4.2.6 and 4.2.7 it makes
no diﬀerence whether we use “B ≤m A” or “B ≤1 A” in the deﬁnition of
Σn–complete and Πn-complete.)

84
4. The Arithmetical Hierarchy
Note that A is Σ1-complete iﬀA is 1-complete as deﬁned in Deﬁni-
tion 2.4.1. Hence, K is Σ1-complete and K is Π1-complete. The following
fundamental theorem relates the jump hierarchy of degrees from §3.4 to
the arithmetical hierarchy.
4.2.1
Post’s Theorem Relating Σn to ∅(n)
Theorem 4.2.2 (Post’s Theorem).
For every n ≥0,
(i)
B ∈Σn+1
⇐⇒
B is c.e. in some Πn set
⇐⇒
B is c.e. in some Σn set
by Theorem 3.4.3 (vii).
(ii) ∅(n) is Σn-complete for n > 0;
(iii) B ∈Σn+1
⇐⇒
B is c.e. in ∅(n);
(iv) B ∈∆n+1
⇐⇒
B ≤T ∅(n).
Proof. (i) ( =⇒). Let B ∈Σn+1. Then x ∈B ⇐⇒(∃y) R(x, y) for some
R ∈Πn. Hence B is Σ1 in R and therefore c.e. in R by Theorem 3.3.16.
(i) ( ⇐= ). Suppose B is c.e. in some Πn set C. Then for some e,
x ∈B ⇐⇒x ∈W C
e
x ∈B ⇐⇒(∃s) (∃σ) [ σ ≺C
&
x ∈W σ
e,s ].
Clearly, x ∈W σ
e,s is computable by Oracle Graph Theorem 3.3.8. Hence,
by Theorem 4.1.4 (iv) it suﬃces to show that σ ≺C is Σn+1. Now
σ ≺C
⇐⇒
(∀y < lh(σ)) [σ(y) = C(y)]
⇐⇒(∀y < lh(σ)) [[σ(y) = 1 & y ∈C] ∨[σ(y) = 0 and y /∈C]]
⇐⇒(∀y < lh(σ)) [Πn ∨Σn]
because C ∈Πn. Hence, σ ≺C is Σn+1 by Theorem 4.1.4 (ii), (iii), and
(vi).
(ii) This is proved by induction on n and is clear for n = 1. Fix n ≥1 and
assume ∅(n) is Σn-complete. Hence ∅(n) is Πn-complete. Now
B ∈Σn+1 ⇐⇒B is c.e. in some Σn set by (i)
⇐⇒B is c.e. in ∅(n) by inductive hypothesis
⇐⇒B ≤1 ∅(n+1) by the Jump Theorem 3.4.3 (iii).
Hence, ∅(n+1) is Σn+1-complete.

4.2.
⋆⋆Post’s Theorem and the Hierarchy Theorem
85
(iii) Now ∅(n) is Πn-complete for n > 0 by (ii), and (i) and (ii) imply (iii).
(iv)
B ∈∆n+1 ⇐⇒B, B ∈Σn+1,
⇐⇒B, B are c.e. in ∅(n), by (iii),
⇐⇒B ≤T ∅(n).
Corollary 4.2.3 (Hierarchy Theorem).
(∀n > 0)[ ∆n ⊂Σn
&
∆n ⊂
Πn ]. Clearly, ∆n ⊆Σn. The content here is that Σn ̸⊆∆n.
Proof. ∅(n) ∈Σn−Πn, by Post’s Theorem 4.2.2 (ii) and (iv), and the Jump
Theorem 3.4.3 (ii). Likewise, ∅(n) ∈Πn −Σn.
Deﬁnition 4.2.4. (Σn and Πn Indices).
(i) By Deﬁnition 2.1.4, e is a Σ1-index for B if B = We, and we also say
that e is a Π1-index for B.
(ii) For n > 0, by Theorem 4.2.2 (iii), B ∈Σn iﬀB ≤1 ∅(n), say via ϕe.
Then e is a Σn-index for B and a Πn-index for B.
(iii) As in Deﬁnition 2.3.1 and Deﬁnition 4.1.2 (i), a ∆0-index for B is an
index e such that ϕe = χB. For n ≥1, a ∆n-index for B is a pair ⟨e, i⟩
where e is a Σn index for B and i is a Πn index for B. (These deﬁnitions
relativize to an oracle A.)
4.2.2
Exercises
Exercise 4.2.5. In the Limit Lemma 3.6.2, prove that we can pass ef-
fectively from an index for any one characterization (i), (ii), or (iii) to
any other. An index for (i) is an e such that ϕe(s, x) = As(x) and
A(x) = lims As(x); An index for (ii) is a ∆2-index for A. An index for
(iii) is an e such that A = ΦK
e .
Exercise 4.2.6. Prove that if B ≤m A and A = ∅(n) for n ≥1 then
B ≤1 A. Hint. Use the Padding Lemma 1.5.2. An alternative proof is to
show that B ∈Σn and hence B is c.e. in ∅(n−1) by Post’s Theorem 4.2.2.
Therefore, we can apply the Jump Theorem 3.4.3.
Exercise 4.2.7. Prove that if B = ∅(n) for n ≥1, and B ≤m A, then
B ≤1 A. Hint. Use the method of Theorem 2.3.9. (By Exercise 4.2.7, in
order to prove that A is Σn-complete it suﬃces to prove that ∅(n) ≤m A
rather than proving ∅(n) ≤1 A.)

86
4. The Arithmetical Hierarchy
4.3
⋆Σn-Complete Sets and Πn-Complete Sets
We have shown that ∅(n) is Σn-complete for all n. (Following Conven-
tion 4.1.1 we normally drop the superscript 0 from now on.) However,
there are other Σn-complete sets with natural deﬁnitions which will be
useful in later applications. For example, we know that K, K0 and K1
are all Σ1-complete and we shall now show that Fin is Σ2-complete and
Cof and Rec are Σ3-complete. Once we have classiﬁed a set A as being in
Σn by the method of §4.1, we attempt to show that the classiﬁcation is
the best possible by proving that B ≤1 A for some known Σn-complete
set B, thus showing that A is Σn-complete. Recall from Deﬁnition 2.4.9
that (A, B) ≤m (C, D) via f computable if f(A) ⊆C,
f(B) ⊆D, and
f(A ∪B) ⊆C ∪D. We write “≤1” if f is 1:1.
Deﬁnition 4.3.1. For n ≥1 deﬁne (Σn, Πn) ≤m (C, D) if (A, A) ≤m (C, D)
for some Σn-complete set A, and similarly for ≤1 in place of ≤m. In this
case we also write Σn ≤m C and Πn ≤m D. (By the same remark as that
in Deﬁnition 4.2.1, it makes no diﬀerence whether we write “≤m” or “≤1”
here.)
(This notation seems strange because Σn and Πn are classes not sets.
It is justiﬁed because if (Σn, Πn) ≤m (C, D) then (A, A) ≤m (C, D) and
(B, B) ≤m (C, D) for any Σn set A and Πn set B.)
4.3.1
Classifying Σ2 and Π2 Sets: Fin, Inf, and Tot
Theorem 4.3.2. (Σ2, Π2) ≤1 (Fin, Tot). Therefore, Fin is Σ2-complete,
Inf and Tot are Π2-complete, and Inf ≡1 Tot. Hence, Inf and Tot are
computably isomorphic, written Inf ≡Tot.
Proof. By Proposition 4.1.5 and Corollary 4.1.8, Fin ∈Σ2 (so Inf ∈Π2)
and Tot ∈Π2. Fix A ∈Σ2. Therefore, A ∈Π2, and there is a computable
relation R such that
x ∈A
⇐⇒
(∀y)(∃z) R(x, y, z).
Using the s-m-n Theorem 1.5.5, deﬁne a 1:1 computable function f by
ϕf(x)(u) =
(
0
if (∀y ≤u) (∃z) R(x, y, z);
↑
otherwise.
Now
x ∈A
=⇒
Wf(x) = ω
=⇒
f(x) ∈Tot,
but
x ∈A
=⇒
Wf(x) is ﬁnite
=⇒
f(x) ∈Fin.

4.3.
⋆Σn-Complete Sets and Πn-Complete Sets
87
4.3.2
Constructions with Movable Markers
Most of the deﬁnitions of c.e. sets so far have been static in the sense of
§2.6.2, but from now on we often give dynamic deﬁnitions. For example,
we may deﬁne a c.e. set B by a construction using a computable sequence
of stages s where Bs represents the set of elements enumerated in B by the
end of stage s and B = ∪sBs. To construct B we concentrate on the stage s
approximation to the complement B because these are the only elements
over which we still have control. Those already in B are irretrievable. Given
Bs, deﬁne the element bs
y for y ∈ω as follows:
(4.1)
B = b0 < b1 < b2 < . . .
&
Bs = bs
0 < bs
1 < bs
2 < . . .
To deﬁne Bs it is often useful to imagine a sequence of markers {Γy}y∈ω
such that the marker Γy is associated with element bs
y at the end of stage s.
Now bs
y ≤bs+1
y
. Therefore, we may imagine marker Γy as moving upwards
and being associated with a nondecreasing (possibly ﬁnite) sequence of
elements {bs
y}s∈ω among the integers. Hence, the name movable markers is
used in the literature.1
The advantage of concentrating on the marker Γy rather than the element
z = bs
y it is currently resting on is that for applications we may have
an additional c.e. kicking set Vy which is coordinated with the marker
Γy. Whenever Vy receives a new element, the current position of Γy is
enumerated in B. Hence, Γy comes to a limit and by exists iﬀVy is ﬁnite.
Therefore, B is inﬁnite iﬀevery Vy is ﬁnite. We have already implicitly
used this method for y = 0 in Exercise 2.5.3 to prove that Inf ≤1 Cof. We
now illustrate the movable marker method in the following Theorem 4.3.3
but with a movable marker for every y not only for y = 0.
4.3.3
Classifying Cof as Σ3-Complete
Theorem 4.3.3. Cof is Σ3-complete.
Proof. Fix A ∈Σ3. Now for some relation R ∈Π2, x ∈A iﬀ(∃y)R(x, y).
Since R ∈Π2 there is a computable function g by Theorem 4.3.2 such that
R(x, y) iﬀWg(x,y) is inﬁnite. Therefore,
(4.2)
x ∈A
⇐⇒
(∃y) [ Wg(x,y) is inﬁnite ].
1For more sophisticated applications, it is better to think of the markers as ﬁxed
boxes or windows sometimes arranged in some geometrical pattern, such as a matrix, a
tree, or simply a line as here, through which the integers move downwards. From this
point of view the boxes are ﬁxed and the integers are moving among them, but we still
have box Γy associated with a nondecreasing sequence of elements {bs
y}s∈ω.

88
4. The Arithmetical Hierarchy
We shall deﬁne a c.e. set Bx uniformly in x such that x ∈A iﬀBx is coﬁnite.
Fix x. For notational convenience we drop the superscript x. We enumerate
B = ∪s∈ω Bs by stages s in the following computable construction. Use the
notation of §4.3.2 and (4.1). We think of Wg(x,y) as a kicking set so that
each new element entering Wg(x,y) “kicks” the marker Γy and forces it to
move once more.
Stage s = 0. Set B0 = ∅.
Stage s + 1. Let Bs = {bs
0 < bs
1 < · · · < bs
y < · · · }. For each y ≤s such that
Wg(x,y), s ̸= Wg(x,y), s+1, enumerate bs
y in Bs+1. If no such y exists, deﬁne
Bs+1 = Bs. This ends the construction.
Case 1. x ∈A. By (4.2), choose the least y such that Wg(x,y) is inﬁnite.
Now marker Γy is moved inﬁnitely often. Therefore, lims bs
y = ∞, and
|B| ≤y.
Case 2. x ̸∈A. By induction, ﬁx y, and choose s such that Wg(x,y), s =
Wg(x,y) and, for all z < y such that bs
z = bz. Now Γy never moves again after
s. Hence, every marker comes to rest on B, which is therefore inﬁnite.
4.3.4
Classifying Rec as Σ3-Complete
Deﬁnition 4.3.4. (i) Cpl = { x : Wx ≡T K }, indices of complete c.e.
sets.
(ii) Rec = { x : Wx ≡T ∅}, indices of computable (recursive) sets.
Theorem 4.3.5. (Σ3, Π3) ≤1 (Cof, Cpl), and (Σ3, Π3) ≤1 (Rec, Cpl).
Corollary 4.3.6 (Rogers).
Rec is Σ3-complete.
Proof. By Corollary 4.1.9 and Theorem 4.3.5 because Cof ⊆Rec and
because Rec ∩Cpl = ∅.
Proof. (Theorem 4.3.5). Let A be Σ3. We deﬁne a c.e. set Bx uniformly
in x such that
(4.3)
x ∈A
⇐⇒
(∃y) [ Wg(x,y) is inﬁnite ]
⇐⇒
Bx is coﬁnite,
(4.4)
x ̸∈A
=⇒
Bx ≡T K.
Fix x. For notational convenience we can drop the x. Let {Ks}s∈ω be a
computable enumeration of K. The construction is now exactly the same
as that of Theorem 4.3.3 except that at Stage s + 1 we replace the second
sentence by the following:
“For each y ≤s such that either Wg(x,y),s ̸= Wg(x,y), s+1
or y ∈Ks+1 −Ks, enumerate bs
y in Bs+1.”

4.3.
⋆Σn-Complete Sets and Πn-Complete Sets
89
Now if x ∈A then some Wg(x,y) is inﬁnite and it causes B to be ﬁnite
as before. If x ̸∈A then the extra clause generates at most one extra move
for marker Γy. Therefore, all markers move ﬁnitely often and B is inﬁnite.
The extra coding ensures that K ≤T B. Choose a stage s such that marker
Γy has settled on bs
y by the end of stage s. Then y ∈K iﬀy ∈Ks because
if y enters K at some stage t > s then marker Γy must move at stage t,
which it cannot.
Remark 4.3.7. Theorem 4.3.5 also implies the previous Theorem 4.3.3
that Cof is Σ3-complete, and it shows that (Π3, Σ3) ≤m (Cpl, Cpl). This
does not imply that Cpl is Π3-complete. It says exactly that Cpl is Π3-
hard, namely that a Π3-complete set is m-reducible to it. Indeed Cpl is
Σ4-complete.
Remark 4.3.8. An alternative coding is to move the markers to prove that
if x ∈A, then B dominates all p.c. functions and therefore K ≤T B by
Theorem 4.5.4 (ii). In Theorem 4.3.5 we have two strategies. The primary
strategy S1 uses Wg(x,y) to show that if x ∈A then B is ﬁnite. If x ∈A,
this primary strategy guarantees only that B is inﬁnite. In this case we can
simultaneously play the secondary strategy S2, which ensures B ≡T K. In
the Π3 case, where B is inﬁnite, we can code various other properties into
B. For example, in Chapter 5 Exercise 5.2.10 we prove that {e : We simple}
is Π3-complete.
One may imagine that the Π3 alternative on B is an expert woods-
man who goes through the forest chopping down only certain trees to
code information. If the Σ3 alternative holds, then the logging company
comes through, cutting all the trees and erasing any coding done by the
woodsman.
In Exercise 4.3.12 we shall prove that Ext is Σ3-complete by deﬁning a
p.c. function ϕf(x) and having a strategy S2 for marker Γy which guarantees
that ϕf(x) is not extendible to a total function ϕy and that indeed Γy
bounds a counterexample z. In Exercise 5.2.10, the markers Γy, y < e,
allow some bs
y ∈We to enter B to achieve B ∩We ̸= ∅, so Bx will be simple
(see §5.2). The only restriction on the secondary strategy S2 is that it must
cause the marker Γy to move at most ﬁnitely often so as not to accidentally
cause B to be ﬁnite even though x ̸∈A which is the Π3 case.
4.3.5
Σ3-Representation Theorems
The following are probably the most useful characterizations for approxi-
mating a Σ3 set A, i.e., for “guessing” whether x ∈A, and should be viewed
as reﬁnements of (4.2).

90
4. The Arithmetical Hierarchy
Theorem 4.3.9 (First Σ3-Representation Theorem). If A ∈Σ3 then there
is a computable function g such that
(4.5)
x ∈A ⇐⇒(∀∞y) [ Wg(x,y) = ω ] and
(4.6)
x ∈A ⇐⇒(∀y) [ Wg(x,y) is ﬁnite ].
Proof. Since A ∈Σ3, let A ≤1 Cof via f using Theorem 4.3.3. Deﬁne g by
z ∈Wg(x,y) ⇐⇒(∀u) [y ≤u ≤z =⇒u ∈Wf(x)].
Hence,
x ∈A =⇒Wf(x) coﬁnite
=⇒(∃y)(∀z ≥y) [ z ∈Wf(x) ]
=⇒(∃y) (∀z ≥y) [Wg(x,z) = ω];
and
x ∈A =⇒Wf(x) coinﬁnite
=⇒(∀y) (∃z ≥y) [z /∈Wf(x)]
=⇒(∀y) [Wg(x,y) ﬁnite].
Remark 4.3.10. (Guessing About a Σ3 Set A). To “guess” about mem-
bership in a Σ2 set A, we have a computable function f such that x ∈A
iﬀWf(x) is ﬁnite. For a Σ3 set A, Theorem 4.3.9 is the two-dimensional
analogue where Wg(x,y) is viewed as the yth row of a matrix. If x ∈A, then
almost all rows are ω, and the others are ﬁnite. If x ̸∈A then all rows are
ﬁnite. The next corollary says that in the ﬁrst case we may redeﬁne the
matrix so that there is a unique row which is inﬁnite and that row is ω.
Theorem 4.3.11 (Second Σ3-Representation Theorem-Uniqueness).
If
A ∈Σ3 then there is a computable function h such that the following lines
hold:
(4.7)
x ∈A
⇐⇒
(∃! y) [ Wh(x,y) = ω
&
(∀z ̸= y)[ Wh(x,z) =∗∅] ],
(4.8)
x ∈A ⇐⇒(∀y) [ Wh(x,y) =∗∅],
where (∃! y)R(y) denotes that there exists a unique y such that R(y).
Proof. A is Σ3. Choose g(x, y) satisfying (4.5) and (4.6). Deﬁne
f(x, y, s) = y + Σz<y | Wg(x,z), s |.
(Think of f(x, y, s) as the position at the end of stage s of a movable marker
Γx
y which moves along the h rows trying to represent row Wg(x,y) on some
h row but which is bumped whenever an element appears in some Wg(x,z)
for some z < y.)
Stage s + 1. Let z = f(x, y, s). Enumerate in Wh(x,z) all w ∈Wg(x,y), s.

4.4. Relativized Hierarchy: Lown and Highn Sets
91
Veriﬁcation.
Case 1.
x ∈A. Choose the least y such that Wg(x,y) = ω. Then z =
lims f(x, y, s) exists, and Wh(x,z) = Wg(x,y) = ω. Also, lims f(x, v, s) = ∞
for all v > y and hence Wh(x,u) is ﬁnite for all u > z.
Case 2.
x ̸∈A. For each z there are at most ﬁnitely many y such that
lims f(x, y, s) = z because of the clause “y +” in the deﬁnition of f(x, y, s).
But each g row Wg(x,y) is ﬁnite. Hence, every h row Wh(x,z) is ﬁnite.
4.3.6
Exercises
Exercise 4.3.12. ⋄Prove that (Σ3, Π3) ≤1 (Cof, Ext) and hence that Ext
is Σ3-complete. Hint. Use the notation and method of Theorem 4.3.3 to
construct ϕf(x) such that if x ∈A, then f(x) ∈Cof ⊂Ext, and if x /∈A,
then f(x) ∈Ext.
Exercise 4.3.13. Show {⟨x, y⟩: Wx and Wy are computably separable}
is Σ3-complete. Hint. Make ϕf(x) of Exercise 4.3.12 take values ⊆{ 0, 1 }.
Exercise 4.3.14. Prove that {⟨x, y⟩: Wx ⊆∗Wy} and {⟨x, y⟩: Wx =∗
Wy} are each Σ3-complete.
Exercise 4.3.15. Show that if A is a c.e. set, then Gm(A) ∈Σ3 where
Gm(A) := { x : Wx ≡m A }.
Exercise 4.3.16. ⋄(Lerman). Let ζ (zeta) denote the order type of the
integers Z (both positive and negative in their natural order). Hence, ζ has
order type ω∗+ ω. A ζ-representation for a set A ⊆ω is a linear ordering
Lζ
A = ζ + ao + ζ + a1 + . . . ,
where A = {a0, a1, . . .} is not necessarily in increasing order and possibly
with repetitions.
(i) Prove that if Lζ
A is a computable linear ordering, i.e., the < relation on
it is computable, then A ∈Σ3.
(ii)⋄Prove that if A ∈Σ3 then there is a computable ordering L of order
type Lζ
A.
4.4
Relativized Hierarchy: Lown and Highn Sets
Deﬁnition 4.4.1. The deﬁnition of ΣA
n (ΠA
n ) is the same as Deﬁnition 4.1.2
for Σn (Πn) except that the matrix R is A-computable instead of com-

92
4. The Arithmetical Hierarchy
putable. If a = deg(A), we use the notation Σa
n in place of ΣA
n since the
class ΣA
n is independent of the particular representative A ∈a.
Everything in this chapter can be relativized to an arbitrary set A with
virtually the same proofs, and with ΣA
n , ΠA
n and A(n) in place of Σn, Πn
and ∅(n), respectively.
4.4.1
Relativized Post’s Theorem
Theorem 4.4.2 (Relativized Post’s Theorem).
For every n ≥0,
(i)
A(n) is ΣA
n -complete if n > 0;
(ii) B ∈ΣA
n+1
⇐⇒
B is c.e. in A(n);
(iii) B ≤T A(n)
⇐⇒
B ∈∆A
n+1 := ΣA
n+1 ∩ΠA
n+1;
(iv) B ≤T A(n+1)
⇐⇒
(∃f ≤T A(n)) [ B(x) = lims f(x, s) ].
Deﬁne FinA, TotA, and CofA as before but with W A
e
in place of We.
The proofs in §4.3 relativize to A and establish that FinA is ΣA
2 -complete,
TotA is ΠA
2 -complete, and CofA and RecA are ΣA
3 -complete, where RecA
is the set of e’s such that W A
e
is A-computable (A-recursive). Hence, if
a = deg(A), then a′ = deg(A′), a′′ = deg(FinA), and a′′′ = deg(CofA).
4.4.2
Lown and Highn Sets
In Deﬁnition 3.6.6 we introduced the low and high sets as those sets A ≤T ∅′
whose jump A′ has the lowest value ∅′ and highest value ∅′′. In Deﬁni-
tion 3.4.2 (ii) we also deﬁned the nth jump A(n) by iterating the jump n
times, where A(0) = A, A(1) = A′ and A(n+1) = (A(n))′. If A ≤T ∅′, then
by iterating the Jump Theorem 3.4.3 we know ∅(n) ≤T A(n) ≤T ∅(n+1).
Deﬁnition 4.4.3. Fix a set A ≤T ∅′.
(i) A is lown if A(n) ≡T ∅(n), the lowest possible value.
(ii) A is highn if A(n) ≡T ∅(n+1), the highest possible value.
(iii) Let D denote the ∆2 degrees and C the c.e. degrees. A Turing degree
d ∈D is lown or highn according to whether it contains a lown or highn set,
since this property is degree invariant. For every n ≥0, deﬁne the following
subclasses of D:
Hn = { d : d ∈D
&
d(n) = 0(n+1) }
Ln = { d : d ∈D
&
d(n) = 0(n) }.
(iv) A set or degree which is not lown or highn for any n is intermediate.

4.4. Relativized Hierarchy: Lown and Highn Sets
93
Clearly, Ln ⊆Ln+1 and Hn ⊆Hn+1 for every n. Even restricted from
D to C there is an intermediate c.e. degree and that the classes are strictly
increasing,
(∀n) [ Ln ⊂Ln+1
&
Hn ⊂Hn+1 ].
Often we replace the ∆2 degrees D by the c.e. degrees C and use the same
low/high notation, Ln/Hn, as above. Which one is intended will be clear
from the context.
4.4.3
Common Jump Classes of Degrees
The most common jump classes of degrees are the following, with their
complements (some of which are not given). In §4.7 we relate several of
these classes to domination and escape properties.
H0
=
{0′}
the complete degree
L0
=
{0}
the degree of ∅
L1
=
{d ∈D : d′ = 0′}
low1
L2
=
{d ∈D : d′′ = 0′′}
low2
L2
=
{d ∈D : d′′ > 0′′}
nonlow2
H1
=
{d ∈D : d′ = 0′′}
high1
H1
=
{d ∈D : d′ < 0′′}
nonhigh1.
4.4.4
Syntactic Properties of Highn and Lown Sets
We now develop a syntactic characterization of high and low in terms of
arithmetical quantiﬁers. This is often useful in applying the hypothesis of
high or low.
Theorem 4.4.4 (High Theorem). For any set A ⊆ω TFAE:
(i)
A is high
(i.e., ∅′′ ≤T A′, whether A ≤T ∅′ or not);
(ii) Σ2 ⊆∆A
2 ;
(iii) Σ2 ⊆ΠA
2 ;
(iv)
∅(2) ≤1 A(2)
(i.e., Tot ≤1 FinA).

94
4. The Arithmetical Hierarchy
Proof.
A is high
⇐⇒
∅′′ ≤T A′
⇐⇒
∅′′ ∈∆A
2
by Post’s Theorem 4.4.2
⇐⇒
Σ2 ⊆∆A
2
because ∅′′ is Σ2-complete
⇐⇒
Σ2 ⊆ΠA
2
because Σ2 ⊆ΣA
2 trivially
⇐⇒
∅(2) ≤1 A(2)
because A(2) is ΠA
2 -complete
⇐⇒
Tot ≤1 FinA
because ∅(2) ≡1 Tot.
Theorem 4.4.5 (Low Theorem). For any set A ⊆ω TFAE:
(i) A is low
(i.e., A′ ≤T ∅′);
(ii) ΣA
1 ⊆∆2,
(iii) ΣA
1 ⊆Π2;
(iv) A′ ≤1 ∅(2)
(i.e., iﬀKA
1 ≤1 Tot).
Proof.
A is low
⇐⇒
A′ ≤T ∅′
⇐⇒
A′ ∈∆2
by Post’s Theorem 4.2.2
⇐⇒
ΣA
1 ⊆∆2
because A′ is ΣA
1 -complete
⇐⇒
ΣA
1 ⊆Π2
because ΣA
1 ⊆Σ∅′
1 = Σ2
⇐⇒
A′ ≤1 ∅(2)
because ∅(2) is Π2-complete.
4.4.5
Exercises
Exercise 4.4.6. State and prove classiﬁcations for high2 and low2 similar
to those in Theorems 4.4.4 and 4.4.5 for high1 and low1.
4.5
⋆Domination and Escaping Domination
Recall the Deﬁnition 3.5.1 of the quantiﬁers (∀∞x) and (∃∞x), and
Deﬁnition 3.5.2 of domination and escape, which we now repeat and extend.
Deﬁnition 4.5.1. (i) A function g dominates f, denoted by f <∗g, if
(4.9)
(∀∞x) [ f(x) < g(x) ].
A partial function θ(x) dominates a partial function ψ(x) if
(∀∞x) [ ψ(x)↓
=⇒
ψ(x) < θ(x)↓].

4.5.
⋆Domination and Escaping Domination
95
(ii) A function f escapes (domination by) g if f ̸<∗g, i.e., if
(4.10)
(∃∞x) [ g(x) ≤f(x) ].
(iii) A function g majorizes f, denoted by f < g, if
(4.11)
(∀x) [ f(x) < g(x) ].
(iv) Functions f and g are almost equal, denoted by f =∗g, if
(∀∞x) [ g(x) = f(x) ].
(v) A class C of functions is closed under ﬁnite diﬀerences if
[ g ∈C
&
g =∗h ]
=⇒
h ∈C.
Proposition 4.5.2. Let C be a class of functions closed under ﬁnite dif-
ferences, such as the computable functions or the A-computable functions
for some A. Then for every f,
(∃g ∈C) [ g >∗f ]
⇐⇒
(∃h ∈C) [ h > f ].
Proof. One direction is obvious. For the other direction, assume g >∗f,
and ﬁnd h =∗g such that h > f.
By Proposition 4.5.2, given such a C and g ∈C with g >∗f, we shall
assume that g > f. In particular, if we have a computable g >∗f then we
shall assume we have computable g > f.2
4.5.1
Domination Properties
Deﬁnition 4.5.3. Let {As}s∈ω be a computable enumeration of c.e. set
A.
(i) The stage function is the partial computable function
θA(x) =
(
(µs) [ x ∈As ]
if x ∈A
undeﬁned
otherwise.
(ii) The least modulus as in (3.17) of Deﬁnition 3.5.4 is
mA(x) = (µs) [ As ↾↾x = A↾↾x ].
Note that θA(x) is partial but partial computable, while mA(x) is total but
not computable (unless A is computable).
2Dominate and majorize are very similar. We normally prefer dominate because by
Proposition 4.5.2 if a computable function g dominates f then a computable function h
majorizes f. The negation of dominate is escape which gives a rich structure of nonlow2
degrees in §4.5 and §4.6, but the negation of “g majorizes f” is simply (∃x) [f(x) ≥g(x)],
which is not useful.

96
4. The Arithmetical Hierarchy
Theorem 4.5.4 (Domination Properties).
Let {As}s∈ω be an enumera-
tion of a c.e. set A and f a total function.
(i)
If f dominates θA(x) then A ≤T f.
(ii)
For any D ≤T ∅′,
D ≡T ∅′
⇐⇒
(∃f ≤T D)[ f dominates every partial computable function ].
(iii)
If f dominates mA(x) then A ≤T f.
(iv)
If {Bs}s∈ω is an enumeration of a c.e. set B and mA(x) dominates
the least modulus function mB(x), then B ≤T A.
Proof. (i)
(∀∞x) [ x ∈A
⇐⇒
x ∈Af(x) ].
(ii) (⇐=)
By (i) because f dominates θK(x).
(ii) (=⇒)
Build f ≤T ∅′ by using ∅′ to determine for a given input x
which ϕe(x) converge for e ≤x. Then deﬁne f(x) to exceed all these values.
(iii)
(∀∞x) [ x ∈A
⇐⇒
x ∈Af(x) ].
(iv)
(∀∞x) [ x ∈B
⇐⇒
x ∈BmA(x) ].
These are only the simplest facts about domination. In §4.5.2 and
throughout the book we develop many more domination properties, and
extend (ii) to an elegant characterization by Martin in Theorem 4.5.6 of
functions which dominate all total computable functions. Escape proper-
ties are more subtle, but in Theorem 4.6.2 we characterize functions which
escape ∅′-computable functions and we use these in computable model
theory.
4.5.2
Martin’s High Domination Theorem
The ﬁrst few levels of the high/low degree hierarchy, especially the high1,
low1, and low2 degrees and their complements, have many important ap-
plications. In addition to the syntactic characterization of high degrees
in Theorem 4.4.4, we now give the very useful characterization (Theo-
rem 4.5.6) by Martin in terms of dominating functions. The following
characterization of high degrees gives useful characterizations in §4.7 and
§4.8 for uniform enumerations of the computable functions and properties
of those ∆2 sets which are low2 or nonlow2. Later we consider low2 and
nonlow2 sets. We now extend the domination notions from Deﬁnition 3.5.2.
Deﬁnition 4.5.5. f is dominant if f dominates every (total) computable
function; an inﬁnite set A = {a0 < a1 < · · · } is dominant if its principal

4.5.
⋆Domination and Escaping Domination
97
function pA dominates every (total) computable function, where pA(n) =
an.
Theorem 4.5.6 (High Domination Theorem, Martin, 1966b).
A set A is
high ( ∅′′ ≤T A′) iﬀthere is a dominant function f ≤T A.
Proof. By Theorem 4.3.2 we know that Tot ≡T
∅′′. Hence, by the
Limit Lemma 3.6.8 relativized to A, we have ∅′′ ≤T A′ iﬀthere is
an A-computable {0, 1}-valued function g(e, s) such that lims g(e, s) =
Tot(e) := χT ot(e).
(=⇒).
Assume ∅′′ ≤T A′. Given g(e, s) as above we deﬁne a dominant
function f ≤T A as follows:
Stage s. (To deﬁne f(s)). For all e ≤s deﬁne t(e) and f(s) as follows:
t(e) = (µt > s) [ g(e, t) = 0
∨
(∀x ≤s) [ ϕe,t(x)↓] ],
f(s) = max{ t(e) : e ≤s }.
Note that t(e) exists because if ϕe is not total, then limt g(e, t) = 0. If ϕe
is total, then limt g(e, t) = 1, and therefore f(s) > ϕe(s) for a.e. s. (Recall
by Deﬁnition 1.6.17 that if ϕe,t(x) = y then e, x, y < t.)
(⇐=).
Assume f ≤T A is dominant. Deﬁne an A-computable function
g(e, s) such that lims g(e, s) = Tot(e) as follows:
(4.12)
g(e, s) =



1
if (∀z ≤s) [ ϕe,f(s)(z)↓];
0
otherwise.
Note that if ϕe is total, then so is θe(y) = (µs) (∀z ≤y) [ ϕe,s(z)↓]. Thus,
f(y) dominates θe(y). Therefore, g(e, s) = 1 for a.e. s. If ϕe is not total,
then ϕe(y) and θe(y) diverge for some y, and g(e, s) = 0 for all s ≥y.
4.5.3
Exercises
Exercise 4.5.7. Give another proof of Martin’s Theorem 4.5.6. Hint. As-
sume A′ ≥T ∅′′. Using Theorem 4.4.4 (iv) ﬁx a computable function g such
that ϕe is total iﬀW A
g(e) is ﬁnite. Use an A-computable construction to
deﬁne f ≤T A. To deﬁne f(s) ﬁrst wait for all e ≤s until either ϕe(s)↓or
W A
g(e) receives a new element.
Exercise 4.5.8. Let A be coinﬁnite, nonhigh, and c.e. Prove that A has
a computable enumeration {As}s∈ω that is diagonally correct, that is,
(∃∞s) [ as
s = as ], where As = {as
0 < as
1 < · · · } and A = {a0 < a1 < · · · }.

98
4. The Arithmetical Hierarchy
4.6
Characterizing Nonlow2 Sets A ≤T ∅′
Fix A ≤T ∅′ and relativize the previous proof to the cone {B : A ≤T B}
with base A in place of ∅and with ∅′ ≥T A as a set in this cone. We obtain
the following useful escape property characterizing nonlow2 sets A ≤T ∅′.
Theorem 4.6.1 (Relativized Domination Theorem, Martin, 1966b).
Fix
A ≤T ∅′. Then A′′ ≤T ∅′′ (i.e., A is low2) if and only if there is a function
g ≤T ∅′ which dominates every total function f ≤T A.
Proof. Fix A ≤T ∅′. Relativize Martin’s Theorem 4.5.6 to the cone of sets
{X : X ≥T A}. Now A is low2 (A′′ ≡T ∅′′) iﬀ∅′, viewed as a member of
this cone, is high in the cone, namely iﬀone jump of ∅′, that is, ∅′′, reaches
A′′ in Turing degree, because A′′ is the double jump of the base A of the
cone. By Martin’s Theorem 4.5.6 this occurs iﬀthere is a function g ≤T ∅′
which is dominant relative to A-computable functions, so that g dominates
every total function f ≤T A.
Corollary 4.6.2 (Nonlow2 Escape Theorem).
Fix A ≤T ∅′. Then A is
nonlow2 (A′′ > ∅′′) iﬀfor every function g ≤T ∅′ there is a function f ≤T A
which escapes g in the sense of (4.10), i.e.,
(4.13)
(Nonlow2 Escape)
(∀g ≤T ∅′) (∃f ≤T A) (∃∞x) [ g(x) ≤f(x) ].
Proof. This is the contrapositive of Theorem 4.6.1.
We have stated (4.13) separately for the sake of the list of properties in
Theorem 4.7.1.
4.6.1
Exercises
Exercise 4.6.3.⋄⋄
(Csima, Hirschfeldt, Knight, Soare, 2004).
Identify
a string σy with its code number y. A set A satisﬁes the isolated path
property if for every computable tree T ⊆2<ω with no terminal nodes and
with isolated paths dense,
(∃g ≤T A) (∀σ ∈T) [ gσ ∈[ Tσ ]
&
gσ is isolated ],
i.e., for every x ∈T, gσ = λy [g(σ, y)] is a path extending σ, which is an
isolated path of the closed set [ T ]. Prove that every nonlow2 set A ≤T 0′
satisﬁes the isolated path property.
Exercise 4.6.4.⋄⋄
(Csima, Hirschfeldt, Knight, Soare, 2004).
A set A
satisﬁes the tree property if for every computable tree T ⊆2<ω with no
terminal nodes, and every uniformly ∆2 sequence of subsets {Si}i∈ω all
dense in [ T ],
(∃g ≤T A) (∀σ ∈T) (∀i) (∃τ ∈Si) [ σ ≺gσ
&
τ ≺gσ
&
gσ ∈[ T ] ].
Prove that every nonlow2 set A ≤0′ satisﬁes the tree property.

99
4.7
Domination, Escape, and Classes of Degrees
Martin’s Theorem 4.5.6 gave a remarkable connection between high degrees
H1 and dominant functions, and the Nonlow2 Escape Theorem 4.6.2 pro-
duced an escape characterization for L2 degrees. Now we summarize the
previous properties in the following Theorem 4.7.1.
Recall the Deﬁnition 4.5.1 of dominate and escape and the common
jump classes in §4.4.3. The contrapositive of Martin’s High Domination
Theorem 4.5.6 is
(4.14)
A′ ̸≥T ∅′′
⇐⇒
(∀g ≤T A)(∃f ≤∅) (∃∞x) [ g(x) ≤f(x) ].
In this case we say “f escapes g.” We say that a set A satisfying the right-
hand side has the escape property. Martin’s equation (4.14) says that the
degrees satisfying the escape property are exactly the nonhigh1 degrees.
However, this deﬁnition does not require that we be able to uniformly
ﬁnd an index i with ϕi = f given an index e with g = ΦA
e . Roughly, if we can
uniformly ﬁnd i from e, then the A satisﬁes the Uniform Escape Property
(UEP). We now summarize the domination and escape characterizations
so far. (The redundancy of these properties is intensional, e.g., our stating
a property on one line and its negation on the next, so that we can later
refer to a speciﬁc property by its line number here, because we intend to
further develop both domination and escape.)
Theorem 4.7.1. Fix a degree d ≤0′.
(i) d = 0′
⇐⇒
(∃g ≤d)[ g dominates all p.c. functions ].
(ii) d < 0′
⇐⇒
(∀g ≤d)( ∃θ p.c. )[ θ escapes g ].
(iii) d ∈H1
⇐⇒
(∃g ≤d)(∀f ≤0)[ g dominates f ].
(iv) d ∈H1
⇐⇒
(∀g ≤d)(∃f ≤0)[ f escapes g ].
(v) d ∈L2
⇐⇒
(∃g ≤0′)(∀f ≤d)[ g dominates f ].
(vi) d ∈L2
⇐⇒
(∀g ≤0′)(∃f ≤d)[ f escapes g ].
Proof. Theorem 4.5.4 (ii) establishes (i) and (ii), Martin’s Domination The-
orem 4.5.6 establishes (iii) and (iv), the NonLow2 Escape Theorem 4.6.2
proves (v) and (vi).
4.8
Uniform Enumerations of Functions and Sets
Theorem 4.8.2 will relate nicely to the previous Martin Theorem 4.5.6 on
dominant functions and high degrees. Also, the notions we now introduce in
Deﬁnition 4.8.1 have proved useful in other areas of computability theory,
computable model theory, and models of arithmetic.
4.8. Uniform Enumerations of Functions and Sets

100
4. The Arithmetical Hierarchy
Deﬁnition 4.8.1. (i) If f(x, y) is a binary function then
(4.15)
fy denotes λ x [ f(x, y) ].
As in analytic geometry, we imagine a two-dimensional plane with hori-
zontal coordinate x and vertical coordinate y. We view λx, y [ f(x, y) ] as
specifying a matrix with entry f(x, y) at the location (x, y). For vertical
coordinate y ∈ω we view fy as the yth row according to our notation
(4.15).
(ii) Let C be a class of (unary) functions and a be a degree. Then C is called
a-uniform (a-subuniform) if there is a binary function f(x, y) of degree ≤a
such that
C = { fy }y∈ω
( respectively, C ⊆{ fy }y∈ω ).
Therefore, f uniformly lists the rows { fy }y∈ω. In the uniform case these
are exactly the rows of C. In the subuniform case C may be a proper subclass
of these rows.
4.8.1
Limits of Functions
Given f(x, y) as in (4.15), we may need to take limits in both the x and y
directions. For example, if {Ay}y∈ω is a uniformly computable sequence of
computable sets then the vertical limit B(x) = limy Ay(x) is a ∆2 set as in
the Limit Lemma 3.6.2. Now suppose that Ay = Wf(y) where f(x) is the
computable function in the proof of Theorem 4.3.2. Hence, Wf(y) is ﬁnite
if Wy is ﬁnite and Wf(y) = ω otherwise. Deﬁne C(y) = limx Ay(x). Now
C(y) = limx Ay(x) = Tot(y).
Hence, C′ ≥T 0′′, a useful fact in many inﬁnite injury constructions such as
the Thickness Lemma, because any set D thick in A also satisﬁes D′ ≥T 0′′.
4.8.2
A-uniform Enumeration of the Computable Functions
The next useful characterization follows from Martin’s Theorem 4.5.6.
Theorem 4.8.2 (Jockusch, 1972a).
If d is any degree, then statements
(i)–(iv) are equivalent:
(i) d′ ≥0′′
(ii) the computable functions are d-uniform;
(iii) the computable functions are d-subuniform;
(iv) the computable sets are d-uniform.

4.8. Uniform Enumerations of Functions and Sets
101
If d is c.e., then (i)–(iv) are each equivalent to
(v) the computable sets are d-subuniform.
Proof. The implications (ii) =⇒(iii), (ii) =⇒(iv), and (iv) =⇒(v) are
immediate.
(i) =⇒(ii). By Martin’s Theorem 4.5.6 choose a dominant function g of
degree ≤d. Deﬁne f(⟨e, i⟩, x) = ϕe,i+g(x)(x) if ϕe,i+g(y)(y) ↓for all y ≤x
and f(⟨e, i⟩, x) = 0 otherwise. Now either f⟨e,i⟩= ϕe is a total function, or
f⟨e,i⟩is ﬁnitely nonzero. In either case f⟨e,i⟩is computable. If ϕe is total
then g(x) dominates θ(x) = (µs)[ ϕe,s(x) ↓], so ϕe = f⟨e,i⟩for some i.
(iii) =⇒(i).
Let f(e, x) be a function of degree ≤d such that every
computable function is an fe. Deﬁne g(x) = max{fe(x) : e ≤x}. Then g is
dominant, so d′ ≥0′′ by Martin’s Theorem 4.5.6.
(iv) =⇒(i). By Theorem 4.3.2 and Exercise 4.3.12 we have
(Tot, Tot) ≤m (Tot, Ext)
via some computable function g. Assume f has degree ≤d and that the
fe’s are exactly the computable characteristic functions. Then for all e,
e ∈Tot
⇐⇒(∃i) [ fi extends ϕg(e) ]
⇐⇒(∃i) (∀x) (∀y) (∀s) [ ϕg(e), s (x) = y
=⇒
fi(x) = y ].
Thus, Tot ∈ΣA
2 . But Tot ∈Π2 ⊆ΠA
2 . Therefore, Tot ∈∆A
2 . Hence, 0′′ ≤d′
by the Relativized Post’s Theorem 4.4.2.
(v) =⇒(i). (The following resembles the proof that the computable func-
tions are not uniformly computable.) Assume that d is c.e. but (i) is false
and f(e, x) is any function of degree ≤d. We must construct a {0, 1}-valued
computable function h ̸= fe for all e. Since deg(f) ≤0′ there is a com-
putable function ˆf(e, x, s) such that f(e, x) = lims ˆf(e, x, s) and a modulus
function m(e, x) for ˆf which has degree ≤d by the Modulus Lemma 3.6.3.
Let p(x) = max{m(e, ⟨e, x⟩) : e ≤x}. Since deg(p) ≤d and (i) fails,
there is a computable function q(x) which p(x) fails to dominate. Deﬁne
h(⟨e, x⟩) = 1 .−ˆf(e, ⟨e, x⟩, q(x)). Then h is a computable function and
h(⟨e, x⟩) ̸= fe(⟨e, x⟩) whenever x ≥e and q(x) ≥p(x). (Exercise 4.9.6 on
Π0
1-classes shows that the hypothesis d c.e. is necessary for this part.)
Corollary 4.8.3 (Jockusch).
If d < 0′ is c.e. then the class of c.e. sets
of degree ≤d is not d-uniform.
Proof. If d is a counterexample, then the computable sets are d-
subuniform. Therefore, d′ = 0′′ by (v) =⇒(i) of Theorem 4.8.2. However,

102
4. The Arithmetical Hierarchy
since the c.e. sets of degree ≤d are d-uniform, they are 0′-uniform and so
d′′ = 0′′ by a later result.
4.9
⊘Characterizing Low2 Sets A ≤T ∅′
Deﬁnition 4.9.1.
The 0′-uniform property of A asserts:
(4.16)
U(A) :
(∃f ≤T ∅′) [ { Y : Y ≤T A } = { fe }e∈ω ],
where fe = λx [ f(x, e) ] as in (4.15) and is viewed as the eth row of the
matrix with characteristic function f(x, e). (We identify a set Y with its
characteristic function χY .)
The uniformity property U(A) asserts that there is a ∅′-computable
matrix f ≤T ∅′ whose rows { fe }e∈ω are exactly the sets Y ≤T A.
Theorem
4.9.2. If A
≤T
0′ is low 2 then U(A) holds, i.e., the
A-computable functions (and hence also A-computable sets) are 0′-uniform.
Proof. Let A be low2 i.e., A′′ ≤T ∅′′. Hence, TotA ≤T ∅′′. Let bg(e, s) be a
∅′-computable function whose limit g(e) = lims bg(e, s) is the characteristic
function of TotA. Now, using a ∅′ oracle, ﬁnd for every e and x
(µt > x) [ ΦA
e,t(x)↓
∨
bg(e, t) = 0 ].
If the ﬁrst case holds, deﬁne h(x, e) = ΦA
e,t(x), and in the second case deﬁne
h(x, e) = 0. This produces h ≤T ∅′. Let ω<ω be {τi}i∈ω. Deﬁne f ≤T ∅′ by
f(x, ⟨e, i⟩) =
(
τi(x)
if x < |τi| ;
h(x, e)
if x ≥|τi| .
For every e, if ΦA
e is total, then ΦA
e =∗he and ΦA
e = f⟨e,i⟩for some i.
Corollary 4.9.3. If X ≤T 0′ is low 2, then there is a computable function
bf(x, y, s) such that the limit f(x, y) = lims bf(x, y, s) exists for all x and y,
and
(4.17)
{Y : Y ≤T X} = { fy : y ∈ω }.
Proof. Apply Theorem 4.9.2 to see that f(x, y) ≤T ∅′ exists and apply the
Limit Lemma 3.6.2 to derive bf(x, y, s).
For a ﬁxed low2 set X, we can think of f(x, y) as a ∅′-matrix with rows
{ fy }y∈ω, which is approximated at every stage s in our computable con-
struction by λ x y [ bf(x, y, s) ], and which in the limit correctly gives (4.17).
We can often use the dynamic matrix approximation
{ λ e y [ bf(e, y, s) ] }s∈ω

4.9.
⊘Characterizing Low2 Sets A ≤T ∅′
103
to show that a low2 set resembles a computable set.
Proposition 4.9.4. Set A satisﬁes U(A) iff A ≤T 0′ and A is low2.
Proof. (⇐=). Apply Theorem 4.9.2.
(=⇒). If f is a computable function satisfying (4.17) then Y = A itself is
one of the rows fy for some y, but f ≤T 0′, so A ≤T 0′. Using f ≤T 0′
we can deﬁne a 0′-function which dominates every A-computable function.
Now A′′ ≤T 0′′ by Theorem 4.6.1.
4.9.1
Exercises
Exercise 4.9.5. Give another proof of Theorem 4.9.2 using domination.
Hint. If A is low2 then ∅′ is high over A. Relativize Theorem 4.8.2 to A,
replacing ∅by A and A by ∅′. By Theorem 4.6.1, choose a ∅′-function g
which dominates every total A-computable function ΦA
e . Since A ≤T ∅′ we
can ∅′-computably deﬁne:
f(⟨e, i⟩, x) =
(
ΦA
e, i+g(x)(x)
if
(∀y ≤x)[ ΦA
e, i+g(y)(y)↓]
0
otherwise.
Either f⟨e,i⟩= ΦA
e is a total function, or f⟨e,i⟩is ﬁnitely nonzero. If ΦA
e is
total then g(x) dominates c(x) = (µs) [ΦA
e,s(x)↓].
Exercise 4.9.6. [Jockusch] Show that the hypothesis d c.e. in the proof of
(v) =⇒(i) of Theorem 4.8.2 was necessary by proving that there is a (non-
c.e.) degree d such that d′ = 0′ and the computable sets are d-subuniform.
Hint. Apply the Low Basis Theorem 3.7.2 to the Π0
1 class C ⊆2ω deﬁned
by
f ∈C ⇐⇒
rng(f) ⊆{ 0, 1 }
&
(∀e) (∀x) [ ϕe(x)↓
=⇒
f(⟨e, x⟩) = min{ 1, ϕe(x) } ]
to obtain some f ∈C of low degree.

104
4. The Arithmetical Hierarchy
Cpl ≡∅(4)
Rec ≡Cof ≡∅(3)
Fin ≡∅′′
K = ∅′
∅(4)
∅(3) ≡Cof
∅
′′ ≡Tot ≡Inf
∅
′
∆3
= sets computable in ∅′′
∆2
= sets computable in ∅′
∆0 = ∆1
= computable sets
c.e. sets
co-c.e. sets
Σ1
Σ2
Σ3
Σ4
Π1
Π2
Π3
Figure 4.1. Arithmetical hierarchy of sets of integers

4.9.
⊘Characterizing Low2 Sets A ≤T ∅′
105
0
0′
...
...
c.e. degrees
L1
L2
L3
H1
H2
H3
Figure 4.2. High and low degrees

5
Classifying C.E. Sets
5.1
⋆Degrees of Computably Enumerable Sets
5.1.1
Post’s Problem and Post’s Program
In §1.6 we constructed a noncomputable c.e. set K. In §2.4 we studied cre-
ative sets and showed that all are computably isomorphic to K. So far the
noncomputable c.e. sets we have exhibited are all computably isomorphic
to K and therefore of Turing degree 0′. Post in [Post 1944] asked whether
there is only one noncomputable c.e. set up to Turing equivalence.
Deﬁnition 5.1.1. [Post, 1944]. Post’s Problem was whether there exists
a computably enumerable set A with ∅<T A <T ∅′.
Post considered this a very signiﬁcant question because he recognized
that important mathematical problems, such as the solvability of Hilbert’s
tenth problem on Diophantine equations, could be coded as questions of
decidability for a c.e. set. Since Post, many more such problems have been
discovered and related to c.e. sets, such as problems in number theory,
ﬁnitely presented groups, diﬀerential geometry and other ﬁelds. For exam-
ple, given a computably axiomatizable theory such as Peano arithmetic,
the set of theorems can be eﬀectively enumerated but not necessarily de-
cided. Post recognized that if the answer to his problem is negative, then
there is only one undecidable problem up to Turing equivalence for these
mathematical questions.
Post’s program for answering his question was to deﬁne c.e. sets A whose
complements, although inﬁnite, were increasingly thin, such as the simple
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_5 
107 

108
5. Classifying C.E. Sets
sets in §5.2 and hypersimple sets in §5.3. He attempted to show that the
complete set K cannot be reduced to such an A by one of the strong
reducibilities he introduced, such as the many-one reducibility, or the truth-
table reduciblility in §3.8.3.
Post’s program of thin sets initially succeeded for some bounded re-
ducibilities but not for full Turing reducibility, which was not well
understood in 1944 when Post began. From 1944 to 1954 Post gradually
developed a deeper understanding of Turing reducibility and information
content of c.e. sets and in 1948 he deﬁned the notion of degree of un-
solvability (Turing degree). Post’s ideas led to our present understanding
of Turing functionals as presented in Chapter 3. They were published in
the important Kleene-Post paper of 1954, including ﬁnite extension oracle
constructions of incomparable sets below ∅′. We shall present these ideas
in Chapter 6. Meanwhile, simple sets and bounded reducibilities led to a
rich development of many ideas in the subject, as we now explore in this
chapter.
5.1.2
Dynamic Turing Reductions on C.E. Sets
The Turing reductions we have considered so far have been static, such
as B ≤m A and B ≤tt A, meaning they can apply to sets which are not
c.e., and even if A and B are c.e. these reductions do not mention any
enumeration of them. One of the other main themes in this chapter is the
study of dynamic Turing reductions, which only apply to c.e. sets and which
measure how quickly the enumeration of one settles in comparison with the
second.
We begin with the easy notion of permitting in §5.2, where we are given
a noncomputable c.e. set C and we wish to build a simple set A ≤T C.
We say that C permits an element x to enter A at some stage only if an
element y ≤x simultaneously enters C. This achieves A ≤T C because
A↾↾x settles more quickly than C ↾↾x, i.e., mA(x) ≤mC(x), for these least
modulus functions deﬁned in Deﬁnition 3.5.4 (iii) for Σ1-approximations.
We develop this notion of comparing modulus functions much further
in §5.4, where we are given a c.e. set A with a certain property such as
its being eﬀectively simple or able to compute a ﬁxed point free function.
Then we prove that K ≤T A by giving an enumeration of A which settles
more slowly than one for K.
5.2
⋆Simple Sets and the Permitting Method
Post introduced the notion of a simple set in an attempt to solve Post’s
Problem of Deﬁnition 5.1.1. Post succeeded in proving that every simple
set A satisﬁes K ̸≤m A but not K ̸≤T A as he had hoped. Indeed, Post

5.2.
⋆Simple Sets and the Permitting Method
109
himself recognized that there are complete simple sets, and we shall give
several proofs of it, including Theorem 5.2.6.
Deﬁnition 5.2.1. (i) An inﬁnite set is immune if it contains no inﬁnite
c.e. set.
(ii) A c.e. set A is simple if A is immune.
Proposition 5.2.2. If A is simple then:
(i) A is not computable;
(ii) A is not creative;
(iii) A is not m-complete
(i.e., K ̸≤m A).
Proof. (i) A cannot be c.e. since otherwise it would contain an inﬁnite c.e.
set.
(ii) The complement of a creative set does contain an inﬁnite c.e. set by
Theorem 2.4.5.
(iii) If K ≤m A, then A is creative by Corollary 2.4.8.
Note that in our classsiﬁcation of the structure of c.e. sets we now have
at least two types of noncomputable c.e. sets which cannot be computably
isomorphic: creative sets like K, and simple sets.
5.2.1
Post’s Simple Set Construction
Theorem 5.2.3 (Post’s simple set, 1944).
There exists a simple set A.
Proof. We construct a coinﬁnite c.e. set A = ∪s As by stages such that for
all e we meet the following requirement:
(5.1)
Pe :
|We| = ∞
=⇒
We ∩A ̸= ∅.
Construction.
Stage s = 0. Let A0 = ∅.
Stage s + 1. Given As, choose the least e < s such that
(5.2)
We,s ∩As = ∅
&
(∃x > 2e) [ x ∈We,s ].
If e exists, choose the least corresponding x and enumerate x in A. If there
is no such e, go to stage s + 2.
End construction.
Veriﬁcation. To see that A is inﬁnite, note that A contains at most e
elements out of the 2e + 1 elements {0, 1, 2, . . . , 2e}, one for each Wi, 0 ≤
i < e, and each such Pi acts at most once because of the ﬁrst clause of
(5.2). Hence, card ( A ↾↾2e ) ≥e + 1. Therefore, A is inﬁnite.

110
5. Classifying C.E. Sets
Next A satisﬁes requirement Pe. Every Pi receives attention at most
once. Choose s0 such that no Pi, i < e, satisﬁes (5.2) at any stage s > s0. If
We is inﬁnite, choose x > 2e satisfying (5.2) at some stage s > s0. Hence,
Pe acts at stage s + 1, and A ∩We ̸= ∅thereafter.
Deﬁnition 5.2.4. A simple set A is eﬀectively simple if there is a
computable function f such that
(5.3)
(∀e) [ We ⊆A
=⇒
|We| ≤f(e) ].
Note that Post’s simple set is eﬀectively simple via f(e) = 2e+1, because
if We ⊆A then We ⊆{0, 1, . . . , 2e}. Post realized that simple sets are not
necessarily Turing incomplete, and indeed he built a complete simple set.
Ironically, we shall prove in §5.4 that all eﬀectively simple sets are Turing
complete. Therefore, eﬀectively simple sets do not help in solving Post’s
Problem for constructing an incomplete c.e. set which is noncomputable.
5.2.2
The Canonical Simple Set Construction
The following construction of a simple set is more ﬂexible than Post’s simple
set for future constructions and it gives a smaller bound f(e) = e on
eﬀective simplicity. For deﬁniteness we refer to it as the canonical simple
set A because it uses the marker constructions described in §4.3.2 and (4.1),
where As = {as
0 < as
1 < · · · }.
Theorem 5.2.5 (Canonical simple set).
There is a simple set A which is
eﬀectively simple via the function f(e) = e.
Proof.
For every e we meet the requirement Pe of (5.1). We use the
notation of §4.3.2, namely As = { as
0 < as
1 < . . . }.
Construction. Let A0 = ∅.
Stage s + 1. Given As. Choose the least e < s such that
(5.4)
We,s ∩As = ∅
&
(∃i > e) [ as
i ∈We,s ].
Choose the least such i and enumerate as
i in As+1. If there is no such e, go
to stage s + 2.
End construction.
Veriﬁcation. For every e, we act for We at most once. Therefore,
(∀n) (∃<∞s) (∃i ≤n) [ as
i ∈As+1 −As ].
Namely, after aj = as
j for all j < n, element as
n enters A for the sake of
set We, e < n, at most once for every such e < n. Hence, lims as
n = an
exists. Therefore, A = {a0 < a1 < a2 . . .} and |A| = ∞. Now if We ⊆A
and |We| > e then for some i ≥e we have ai ∈We. Thus, we would have
put ai into A. Therefore, A is eﬀectively simple via f(e) = e.

5.2.
⋆Simple Sets and the Permitting Method
111
5.2.3
Domination and a Complete Simple Set
It will follow that both the Post simple set and the canonical simple set,
being eﬀectively simple, are Turing complete. However, by a much shorter
and very useful argument, we now construct a complete simple set. It suf-
ﬁces to build a simple set A whose principal function pA dominates every
p.c. function. This requires only moving the markers slightly more often to
achieve domination.
Theorem 5.2.6. There is a simple set A such that A = {a0 < a1 . . .}
dominates every p.c. function and hence A ≡T K. (This set is dense simple
as deﬁned in Exercise 5.3.12).
Proof. Perform the construction of the canonical simple set A in Theo-
rem 5.2.5, but, in addition to the former strategy for (5.4), if
(5.5)
ϕe,s(n)↓≥
as
n
&
e ≤n
then enumerate as
n into As+1 for the sake of ϕe. Now ϕe causes each as
n
to be enumerated only if e ≤n, and even then at most ﬁnitely often until
ϕe(n) < as
n. Therefore, an = lims as
n exists. But ϕe(n) < an for all n ≥e
by the construction. Hence, the principal function pA(n) = an dominates
ϕe. It follows from Theorem 4.5.4 (ii) that pA ≥T ∅′.
5.2.4
Simple Permitting and Simple Sets
Theorem 5.2.6 shows that simple sets can have degree 0′, and therefore
simplicity does not guarantee Turing incompleteness. Now we prove that
for every noncomputable c.e. set C we can construct a simple set A ≤T C.
Therefore, the structural property of A being simple places no restriction
on its degree except that A must be noncomputable. We use the simple
(easy) permitting method in which an element x is permitted to enter A
at a given stage only when an element y ≤x enters C. In the later section
§5.5 we consider more general permitting.
Theorem 5.2.7. For any noncomputable c.e. set C there is a simple set
A ≤T C. Indeed, the proof naturally guarantees that A ≤ibT C for identity
bounded Turing reducibility of Deﬁnition 3.8.1 (ii). (Furthermore, we can
also arrange A ≡T C as in Exercise 5.2.12.)
Proof. Let {Cs}s∈ω be a computable enumeration of C. We modify the
Post simple set construction of Theorem 5.2.3 and construct a coinﬁnite
c.e. set A to satisfy for all e the following requirement (5.6) which replaces
the Post requirement (5.1).
(5.6) Pe :
|We| = ∞
=⇒
[ We ∩A ̸= ∅
∨
C ≡T ∅].

112
5. Classifying C.E. Sets
Construction. Deﬁne A0 = ∅.
Stage s + 1. Given As choose the least e such that
(5.7) We,s ∩As = ∅& (∃x > 2e) [ x ∈We,s
& Cs+1 ↾↾x ̸= Cs ↾↾x ].
(Note that (5.7) is the same as the Post simple set (5.2) except that the
last clause demands that (∃y ≤x)[y ∈Cs+1 −Cs], i.e., that C permits x at
stage s+1.) Choose the least such e and enumerate the least corresponding
x in A. If there is no such e go to stage s + 2.
End construction.
Veriﬁcation.
Clearly, A is inﬁnite by the same proof as that of Theo-
rem 5.2.3. Furthermore, A ≤T C by Proposition 3.5.5 (iii) because mA(x) ≤
mC(x), with these least modulus functions deﬁned in Deﬁnition 3.5.4 (iv).
Lemma 5.2.8.
(∀e)[ We inﬁnite
=⇒
We ∩A ̸= ∅].
Proof.
If not, choose the least e which is a counterexample. Hence, We
is inﬁnite and We ∩A = ∅. Therefore, there is an increasing c.e. sequence
of elements x1 < x2 < . . . with 2e < x1 and a corresponding c.e. sequence
of stages s1 < s2 < . . . such that for all i we have xi ∈We [ si ] and no
element y ≤xi enters C at any stage t ≥si. Otherwise, (5.7) would allow
We ∩A ̸= ∅. Now deﬁne a computable function ge such that ge = C,
contradicting the hypothesis that C is noncomputable. When xi appears
in We [ si ], deﬁne ge(y) = C(y) [ si ] for all y ≤xi. But C ↾↾xi does
not change after si, and therefore ge = C. Note that we have achieved
A ≤ibT C.
5.2.5
Permitting as a Game
In this proof we did not introduce the function ge during the construction
but only in the veriﬁcation, using a proof by contradiction. However, it is
sometimes more accurate to think of this as a Lachlan game as presented
in §2.5 where we deﬁne ge during the construction, and we shall present
this version of the permitting of a simple set in §16.3.2.
The intuition is that in Theorem 5.2.7 Player I (RED) plays the noncom-
putable c.e. set C and all the c.e. sets {We}e∈ω. Player II (BLUE) plays
A, attempting to make A simple and A ≤T C by permitting. While We ∩A
remains empty, BLUE plays for every e an initial segment of a computable
function ge, threatening to make ge = C. In chess and in Lachlan games the
threat is often just as eﬀective as the completed action. RED can ignore
the threat of ge only ﬁnitely often before he must give C permission for
elements to enter A or else A is computable via ge.

5.3.
⋆Hypersimple Sets and Dominating Functions
113
5.2.6
Exercises
Exercise 5.2.9. Let S be the class of simple sets and C the class of coﬁnite
sets. Prove that S ∪C is a ﬁlter in E. (In Exercise 5.3.8 we shall see this for
the h-simple sets.)
Exercise 5.2.10. ⋄
Show that {e : We is simple} is Π3-complete. Hint.
Combine the methods of the canonical simple set construction of Theo-
rem 5.2.5 and the Σ3 marker construction of Theorem 4.3.3 as follows. Let
A be Σ3-complete and g be as in Theorem 4.3.9. Construct a computable
function f such that if x ∈A then Wf(x) is coﬁnite, and if x /∈A then
Wf(x) is simple. Construct Bx = Wf(x) as in Theorem 5.2.5 but also move
bx
n whenever a new element is enumerated in Wg(x,n).
Exercise 5.2.11. Prove that if A ≤m S and A is part of a computably
inseparable pair (as deﬁned in Exercise 1.6.26) of c.e. sets then S is not
simple. Note that K ≡{ x : ϕx(x) = 0 }, and hence by Exercise 2.4.18, K
is part of an eﬀectively inseparable (and therefore computably inseparable)
pair of c.e. sets. (Hence, a simple set is not m-complete.) Hint. Let (A, B)
be computably inseparable, A ≤m S via f, and consider f(B).
Exercise 5.2.12. In Theorem 5.2.7 show that we can modify the construc-
tion to achieve C ≤T A. Hint. In (5.7) replace 2e by 3e. Whenever some
x enters C put into A some y ≤3x currently in A. Prove that A is simple
and that mC(x) ≤mA(3x) which guarantees C ≤T A.
5.3
⋆Hypersimple Sets and Dominating Functions
Although Post proved that simple sets are necessarily m-incomplete, he
realized that simple sets could be Turing complete. Therefore, Post contin-
ued by deﬁning coinﬁnite c.e. sets with even thinner complements called
hypersimple (h-simple) and hyperhypersimple (hh-simple) sets. Although
these sets also failed to solve Post’s problem, they were later shown to have
interesting characterizations which gave information about the structure of
c.e. sets and the relationship between a c.e. set and its degree.
5.3.1
Weak and Strong Arrays of Finite Sets
Deﬁnition 5.3.1. (Recall the ﬁnite set Dy with index y in Deﬁni-
tion 2.3.6.)
(i) A sequence {Fn}n∈ω of ﬁnite sets is a strong (weak) array if there is a
computable function f such that Fn = Df(n) (Fn = Wf(n)).
(ii) An array is disjoint if its members are pairwise disjoint.

114
5. Classifying C.E. Sets
(iii) An inﬁnite set B is hyperimmune abbreviated h-immune, (respectively,
hyperhyperimmune, abbreviated hh-immune) if there is no disjoint strong
(weak) array { Fn }n∈ω such that Fn ∩B ̸= ∅for all n.
(iv) A c.e. set A is hypersimple, abbreviated h-simple (hyperhypersimple,
abbreviated hh-simple) if A is h-immune (hh-immune).
The intention behind h-simplicity and hh-simplicity is that instead of
specifying a c.e. set { an }n∈ω ⊆A we specify a disjoint c.e. array of ﬁnite
sets { Fn }n∈ω such that each Fn contains some x ∈A but we cannot
tell which x ∈Fn has this property. In a strong array we can explicitly
compute max(Fn) and all its members, but in a weak array we can merely
enumerate Fn. It can be easily shown that hh-simple implies h-simple and
h-simple implies simple. We shall prove later that these implications are
not reversible.
5.3.2
Dominating Functions and Hyperimmune Sets
See Deﬁnitions 3.5.2, 4.5.1, and §4.5 for the deﬁnitions of domination and
escape and their properties.
Deﬁnition 5.3.2. A function g (or inﬁnite set A) is computably bounded
(computably majorized) if (∃h ≤T ∅) (∀x) [ g(x) ≤h(x) ]. (Extend the
deﬁnition to inﬁnite sets A by using the principal function pA(x).)
Theorem 5.3.3 (Kuznecov, Medvedev, Uspenskii).
An inﬁnite set A is
hyperimmune iﬀA is not computably bounded.
Proof. ( ⇐= ).
Assume A is not hyperimmune. Let {Dg(x)}x∈ω be
a disjoint strong array with Dg(x) ∩A ̸= ∅for all x. Deﬁne f(x) =
max(S{ Dg(y) }y≤x). Then f(x) ≥pA(x) for all x. Therefore, A is com-
putably bounded by f.
( =⇒).
Assume pA is bounded by a computable function f. Deﬁne
g by Dg(0) = [ 0, f(0) ], where we deﬁne [ n, m ] = { n, n + 1, . . . , m }.
Given g(0), g(1), . . . , g(n), deﬁne k = 1 + max( S { Dg(i) }i≤n) and deﬁne
D g(n+1) = [ k, f(k) ]. Now k ≤pA(k) ≤f(k) so pA(k) ∈Dg(n+1) ∩A. This
disjoint strong array {Dg(n)}n∈ω witnesses that A is not hyperimmune.
Corollary 5.3.4. A coinﬁnite c.e. set A is h-simple iﬀA is not computably
bounded.
Note that Post’s simple set S of Theorem 5.2.3 is not hypersimple since
S is dominated by f(x) = 2x. The canonical simple set construction of
Theorem 5.2.5 may or may not produce an h-simple set. For example, the
simple set A constructed in Theorem 5.2.6 produced pA which dominated
all p.c. functions and hence makes A h-simple.

5.3.
⋆Hypersimple Sets and Dominating Functions
115
5.3.3
Degrees of Hypersimple Sets and Dekker’s Theorem
Deﬁnition 5.3.5. Let A be an inﬁnite c.e. set and f a 1:1 computable
function with range A (an enumeration of A). Let as denote f(s) and
As = {av : v ≤s}.
(i) Deﬁne the deﬁciency set D to be the Σ1 set of deﬁciency stages:
(5.8)
D = { s : (∃t > s) [ at < as ] }.
(ii) The Π1 set T = D is the set of true stages (nondeﬁciency stages):
(5.9)
T = { t : A↾at = At ↾at }.
Therefore, at a true stage t ∈T the element at just enumerated is smaller
than any element later enumerated. The intuition is that the deﬁciency set
D measures how far f is from being an order-preserving enumeration of A
(which, of course, is not possible if A is not computable). The set T of true
stages will play an important role in inﬁnite injury, where we shall use the
obvious fact that an apparent computation ΦA
e (x)[ t ] = y at a true stage
t ∈T is a true computation ΦA
e (x) = y because no element z ≤u can
later enter A, where u = ϕA
e (x)[ t ], the use of the computation. (Also recall
truth-table reducibility B ≤tt A from Deﬁnition 3.8.2.) See [Dekker 1954].
Theorem 5.3.6 (Dekker, 1954).
Let A be any noncomputable c.e. set
and D the deﬁciency set of A with respect to some ﬁxed enumeration of A.
(i) A ≤T D.
(ii) D ≤tt A.
(iii) D is hypersimple.
(iv) Reductions in (i) and (ii) are uniform in any Σ1 indices of A and D.
Proof. (i) Now D is Σ1 and hence c.e. Clearly, D is inﬁnite. Note that
(5.10)
x ∈A
iﬀ
x ∈{a0, a1, . . . , ap D(x)}
by the deﬁnition of D and the fact that x ≤apD(x). Hence, A ≤T D.
(ii) Next D ≤tt A since to test whether s ∈D we A-computably ﬁnd the
least stage v such that Av ↾as = A↾as. Now s ∈D iﬀv > s, i.e., iﬀs ∈Dv.
(iii) Now D is h-immune, because if some computable function g dominates
pD then by (5.10) x ∈A iﬀx ∈{a0, a1, . . . , ag(x)}, which implies that A is
computable.
(iv)
Clearly, the reductions in (i) and (ii) are uniformly computable in
Σ1-indices for A and D.

116
5. Classifying C.E. Sets
Corollary 5.3.7. For every noncomputable c.e. set A there is an h-simple
set D ≡T A. Hence, every nonzero c.e. degree contains an h-simple set.
5.3.4
Exercises
Exercise 5.3.8. Show that the h-simple sets together with the coﬁnite
sets form a ﬁlter in E. (In Exercise 5.2.9 we saw this for the simple sets and
later we shall see it for the hh-simple sets.)
Exercise 5.3.9. Give a direct “movable marker” type construction of an
h-simple set. Hint. Modify the construction of the canonical simple set in
Theorem 5.2.5 with requirement Pe of (5.1) replaced by the requirement
bPe : { Dϕe(x) }x∈ω a disjoint strong array
=⇒
(∃x)[ Dϕe(x) ⊆A ].
Exercise 5.3.10. Given a noncomputable c.e. set A, use the preceding
exercise and the method of Theorem 5.2.7 to ﬁnd an h-simple set H ≤ibT A.
Exercise 5.3.11. Show that {x : Wx is h-simple} is Π3-complete. (See the
hint for Exercise 5.2.10.)
Exercise 5.3.12. A coinﬁnite c.e. set A is dense simple (Martin) if
the principal function pA dominates every total computable function. We
constructed a dense simple set in Theorem 5.2.6.
(i) Prove that a dense simple set is h-simple.
(ii) Prove that a dense simple set is high.
(iii) Construct an example of an h-simple set which is not dense simple.
Exercise 5.3.13. Show that any coinﬁnite c.e. set B has an h-simple
superset A. Hint. If B is not already h-simple, then by Theorem 2.3 there
is an increasing computable function f such that for all n,
[f(n), f(n +
1)) ∩B ̸= ∅. Let Fn = [f(n), f(n + 1)). Play the strategy of Exercise
2.9 but with the markers Γe each associated with some set Fn instead of
an integer n. When x is enumerated in B, it is also enumerated in A. In
addition, when Fn has no marker all its members are put into A. Begin by
associating Γe with Fe. To meet bPe of Exercise 2.9 wait for some x such
that ϕe(x) ↓and Dϕe(x) ∩Fn = ∅for each Fn associated currently with a
marker Γi, i ≤e. For each y ∈Dϕe(x) ﬁnd n such that y ∈Fn, enumerate
all members of Fn into A and move the marker (if any) associated with Fn
to some Fm, m ≥n, Fm not yet a subset of A. Prove that each Γe moves
ﬁnitely often and comes to rest on some Fn such that Fn ∩A ̸= ∅. Hence,
A is inﬁnite. (Note that A is not obtained uniformly from B.)
Exercise 5.3.14. A set S is introreducible if S ≤T T for every inﬁnite
set T ⊆S. For the deﬁciency set D of Deﬁnition 5.3.5 prove that D is
introreducible.

5.4.
⋆The Arslanov Completeness Criterion
117
Exercise 5.3.15. A set A is bounded truth-table reducible to a set B (writ-
ten A ≤btt B) if there is some n (called the norm of the reduction) and there
are computable functions f and g such that for all x: (1) |Df(x)| ≤n and (2)
x ∈A iﬀB ∩Df(x) = Dy for some y in Dg(x). (For example, for any set A,
A ≤btt A.) Let B be the Boolean algebra generated by the c.e. sets. Prove
that A ∈B iﬀA ≤btt K. (Note that A ≤m B =⇒A ≤btt B =⇒A ≤tt B,
and that ≤btt and ≤tt are reﬂexive and transitive and therefore induce
equivalence relations ≡btt and ≡tt.)
Exercise 5.3.16. Prove that if A and B are c.e. and ̸= ω, ̸= ∅, and neither
is ∅nor ω, and A ≤btt B with norm 1, then A ≤m B.
Exercise 5.3.17. Let B be the least Boolean algebra containing E. (B is the
Boolean algebra obtained by closing the c.e. sets under complementation,
union and intersection).
(i) Prove that A ∈B iﬀA is a ﬁnite union of d.c.e. sets.
(ii) Prove that A ∈B iﬀA ≤btt K.
(iii) Show that there exists a set A ≤T K such that A /∈B.
Exercise 5.3.18. ⋄(Friedberg and Rogers, 1959). Show that K ̸≤bT H for
H h-simple. See [Friedberg-Rogers 1959]. Hint (Owings). Assume K = ΦH
e
with f as above. It suﬃces to show that for every interval [0, y] which
intersects H we can ﬁnd uniformly in y some z > y such that [y+1, z]∩H ̸=
∅. Suppose F = H ∩[0, y]. Let Wn consist of all x such that
(∃σ) [ Φσ
e (x) = 0
&
(∀y < lh(σ) [ σ(y) = 0 =⇒y ∈F ]
& [σ(y) = 1 =⇒y ∈H] ].
Apply to Wn the productive function for K and then apply f to obtain zF .
Let z = max{ zF : F ⊆[0, y] }.
5.4
⋆The Arslanov Completeness Criterion
5.4.1
Eﬀectively Simple Sets Are Complete
Although Post constructed a complete simple set, he did not realize
that his original simple set and indeed all eﬀectively simple sets (as in
Deﬁnition 5.2.4) are complete.
Theorem 5.4.1 (Martin, 1966a). If A is eﬀectively simple then K ≤T A.
Proof. Let {Ks}s∈ω be a computable enumeration of K and θ(x) be a p.c.
function such that θ(x) = (µs) [ x ∈Ks ] if x ∈K and θ(x) diverges

118
5. Classifying C.E. Sets
otherwise. Let A be eﬀectively simple via f, { As }s∈ω be a computable
enumeration of A, and As = { as
0 < as
1 < as
2 < · · · }. By the Recursion
Theorem with Parameters 2.2.6, deﬁne the computable function h by
(5.11)
Wh(x) =



{ aθ(x)
0
< aθ(x)
1
< . . . < aθ(x)
fh(x) }
if x ∈K;
∅
otherwise.
Set r(x) = (µs) [as
fh(x) = afh(x)]. Then r ≤T A because f and h are
computable. (Here fh(x) denotes f(h(x)).) Now if x ∈K and r(x) ≤θ(x),
then Wh(x) ⊆A and |Wh(x)| = fh(x) + 1, contrary to the hypothesis on f.
Hence, r(x) > θ(x) for all x ∈K. Therefore, x ∈K iﬀx ∈Kr(x). Hence,
K ≤T A.
5.4.2
Arslanov’s Completeness Criterion for C.E. Sets
Deﬁnition 5.4.2. A function f is a ﬁxed point free (FPF) function if
(∀x) [ Wf(x) ̸= Wx ].
Theorem 5.4.3 (Arslanov Completeness Criterion, 1981).
A c.e. set A
is complete iﬀthere is a ﬁxed point free function f ≤T A.
Proof. ( =⇒).
Assume A ≡T
∅′
≡T
K1 = {e : We ̸= ∅} by
Exercise 1.6.22. Deﬁne
Wf( x ) =



∅
if Wx ̸= ∅;
{0}
otherwise.
( ⇐= ).
Assume (∀x)[ Wf(x) ̸= Wx ], where f ≤T A. By the Modulus
Lemma there is a computable function bf(x, s) such that f(x) = lims bf(x, s)
for every x, and the sequence { λx bf(x, s) }s∈ω has a modulus m ≤T A. Let
{Ks}s∈ω be a computable enumeration of K. Let θ(x) = (µs)[x ∈Ks] if
x ∈K, and let θ(x) diverge otherwise. By the Recursion Theorem with
Parameters 2.2.6 deﬁne the computable function h by
Wh( x ) =
(
W b
f( h(x), θ(x) )
if x ∈K;
∅
otherwise.
Now if x ∈K and θ(x) ≥m(h(x)), then bf(h(x), θ(x)) = f(h(x)) and
W f( h(x) ) = Wh(x), contrary to the hypothesis on f. Hence, for all x,
x ∈K
⇐⇒
x ∈K m( h(x) ),
and therefore K ≤T A.

5.4.
⋆The Arslanov Completeness Criterion
119
Corollary 5.4.4 (Arslanov, 1981).
Given a c.e. degree a, a < 0′ iﬀfor
every function f ∈a there exists n such that Wn = Wf(n).
Note that the hypothesis of “A is c.e.” in Theorem 5.4.3 is necessary
by Exercise 5.4.14. Secondly, if f does not have a ﬁxed point n such that
Wn = Wf(n), we might at least hope for a *-ﬁxed point (almost ﬁxed point),
namely an n such that Wn =∗Wf(n). Exercise 5.4.11 is analogous to the
Recursion Theorem since it shows that every function f ≤T ∅′ has a *-ﬁxed
point, while Exercise 5.4.15 gives a ∅′′-completeness criterion, which is the
analogue for *-ﬁxed points of Theorem 5.4.3 for ﬁxed points. Finally, if f
has no almost ﬁxed points we might hope that f has a Turing ﬁxed point,
namely an n such that Wn ≡T Wf(n). In a later chapter we shall prove
that this is true if f ≤T ∅(2).
5.4.3
Exercises
Exercise 5.4.5. (Jockusch). Prove that the following are equivalent for
an arbitrary set A:
(i) (∃f ≤T A) (∀e) [We ̸= Wf(e)],
(ii) (∃g ≤T A) (∀e) [ϕe ̸= ϕg(e)],
(iii) (∃h ≤T A) (∀e) [ h(e) ̸= ϕe(e) ].
Hint. For (ii) implies (iii), let d be the computable function deﬁned in the
proof of the Recursion Theorem, and let h(e) = g(d(e)). For (iii) implies
(i), ﬁx a p.c. function θ such that if We ̸= ∅then θ(e) ∈We. Choose
a computable function q such that for every e, ϕq(e) = λy [ θ(e) ]. Let
Wf(e) = { h(q(e)) } for all e. (Note that the implication (i) implies (iii) is a
generalization of the Recursion Theorem.)
Exercise 5.4.6. A set A is eﬀectively immune if A is inﬁnite and there
is a computable function f such that if Wx ⊆A then |Wx| < f(x). Prove
that if A is eﬀectively immune, B is c.e., and A ≤T B, then B ≡T ∅′. Hint.
Use the Modulus Lemma 3.6.3 and modify the proof of Theorem 5.4.1.
Exercise 5.4.7. (Smullyan-Martin).
(i)
Prove that if A is eﬀectively
simple and A ⊆B ⊂∞ω and B is c.e. then B is eﬀectively simple. (Recall
that X ⊂∞Y denotes that X ⊂Y and Y −X is inﬁnite.)
(ii) Show that there is an eﬀectively simple hypersimple set. Hint. Combine
the positive requirements of Theorem 5.2.5 and Exercise 5.3.9. The negative
requirements assert only that lims an,s exists, and this will be satisﬁed if
the positive requirements at most ﬁnitely often cause an,s ̸= an,s+1, which
they do. Note that Post’s simple set S of Theorem 1.3 is eﬀectively simple
and not hypersimple.

120
5. Classifying C.E. Sets
Exercise 5.4.8. (Shoenﬁeld, 1957). A is quasi-creative if A is c.e. and
(∃f ≤T ∅) (∀x) [ Wx ⊆A
=⇒
[Df(x) ⊂A
&
Df(x) ̸⊆Wx ] ].
Prove that A quasi-creative implies A complete. Hint. Use the Recursion
Theorem in the manner of Theorem 5.4.1 or Theorem 2.4.6.)
Exercise 5.4.9. For each of the following properties deﬁne f appropriately
and apply Theorem 5.4.3 to show that A is complete.
(i) A creative.
(ii) A quasi-creative (as deﬁned in Exercise 5.4.8).
(iii) A eﬀectively simple.
(iv) B of Exercise 5.4.7.
Exercise 5.4.10. (Morris-Gill). A c.e. set A is subcreative (M. Blum) iﬀ
there is a computable function g such that for every x if Wx ∩A is ﬁnite
(possibly empty), then A ⊂Wg(x) ⊆A ∪W x. Apply Theorem 5.4.3 to
prove that every subcreative set is complete. Hint. Find the least s such
that either (∃y) [y ∈Wg(x),s −A] or Wx,s ̸= ∅. In the former case set
Wf(x) = { y }, and otherwise set Wf(x) = ∅. Show that f ≤T A, and f
satisﬁes Theorem 5.4.3.
Exercise 5.4.11. (Arslanov, Nadirov, and Solov’ev, 1977). An integer n
is an almost ﬁxed point for a function f if Wf(n) =∗Wn.
(i)
Show that for any function θ partial computable in ∅′ there is a
computable function f such that (∀x ∈dom(θ) ) [Wθ(x) =∗Wf(x)]. Hint.
Choose a total computable function bf(x, s) such that θ(x) = lims bf(x, s)
for every x ∈dom(θ). Deﬁne
Wf(x) =
[
{ W b
f(x,s),s : s ∈ω }.
(ii) Show that any function f ≤T ∅′ has an almost ﬁxed point.
(iii)
Use (ii) to show that for no coinﬁnite c.e. set A does there exist a
function f ≤T ∅′ such that for all x with A ⊆Wx: (1) Wx ∩Wf(x) =∗A;
and (2) Wx∪Wf(x)=∗ω. (The point is that we shall show A is hh-simple iﬀ
L∗(A) is a Boolean algebra, i.e., there is a function f satisfying (1) and (2).
By this exercise we cannot have f ≤T ∅′.)
Exercise 5.4.12. ⋄
(Jockusch and Soare, 1972a). In Theorem 5.2.7 we
were given a noncomputable c.e. set C and constructed a simple set A ≤T C
by permitting with f(x) = x and without the explicit coding of C ≤T A de-
scribed in Exercise 5.2.12. Prove that this explicit coding is unnecessary by
showing that C ≤T A automatically by using the method of Theorem 5.4.3.
(This is an example of a certain maximum degree principle which asserts

5.4.
⋆The Arslanov Completeness Criterion
121
roughly that a c.e. set A being constructed has the highest degree not
explicitly ruled out.)
Exercise 5.4.13. (i) (Lachlan, 1968a). A c.e. set A is weakly creative if
(∃f ≤T A)(∀x)[ Wx ⊆A
=⇒
f(x) /∈Wx ∪A ].
Prove that a c.e. set A is weakly creative iﬀA is complete.
(ii) (Martin). A c.e. set S is weakly eﬀectively simple if
|S| = ∞
&
(∃f ≤T S)(∀x)[ Wx ⊆S
=⇒
f(x) > |Wx| ].
Show that every weakly eﬀectively simple set is complete.
(iii) Show that any complete simple set is weakly eﬀectively simple.
Exercise 5.4.14. (Arslanov, 1979 and 1981).
Show that there exists a
set A ≤T ∅′, A′ ≡T ∅′, and f ≤T A, such that (∀e) [We ̸= Wf(e)]. Hint.
(Jockusch). Show that the class C of { 0, 1 }-valued functions h such that
(∀e) [ h(e) ̸= ϕe(e) ] is a Π0
1 class as in Deﬁnition 8.2.1. Apply the Low Basis
Theorem 3.7.2 to get h ∈C, h of low degree, and apply Exercise 5.4.5.
Exercise 5.4.15. (∅′′-Completeness Criterion, Arslanov, 1981). Suppose
A ∈Σ2 and ∅′ ≤T A. Prove that
A ≡T ∅′′
⇐⇒
(∃f ≤T A) (∀e) [ We ̸=∗Wf(e) ].
(Hence, this theorem is to Exercise 5.4.11 what Theorem 5.4.3 is to the
Recursion Theorem.) Hint (Jockusch). First show by the method of Exer-
cise 5.4.11(a) that if ψ is a function partial computable in ∅′ then there
exists a computable function g(e) such that
(∀e ∈dom(ψ) [ Wψ(e) =∗Wg(e) ].
Replace the construction of Theorem 5.4.3 by a ∅′-construction. Let B =
Fin, which is c.e. in ∅′. Let { As }s∈ω and {Bs}s∈ω be ∅′-computable enu-
merations of A and B. Let θ(x) = µs[x ∈Bs] if x ∈B and let θ(x) diverge
otherwise. From f = ΦA
e deﬁne bf as in Theorem 5.4.3 except that now
bf ≤T ∅′. Hence, bf(y, θ(x)) is a function partial computable in ∅′ so there
is a computable function g(y, x) such that
(∀x) (∀y) [ bf(y, θ(x))↓
=⇒
W b
f(y,θ(x)) =∗Wg(y,x) ].
Use the Recursion Theorem with Parameters 2.2.6 applied with parameter
x to the function g to obtain a computable function h(x) such that for all
x, Wh(x) = Wg(h(x),x), and hence
(∀x ∈B) [ Wh(x) = Wg(h(x),x) =∗W b
f(h(x),θ(x)) ].
Now complete the proof as in Theorem 5.4.3.

122
5. Classifying C.E. Sets
5.5
⊘More General Permitting
In Theorem 5.2.7 we were given a noncomputable c.e. set C and we built
a simple set A ≤ibT C using the identity function to permit. The proof
suggests that instead of the identity we could have ﬁxed in advance any
computable function f(x) and permitted x to enter A when an element
y ≤f(x) entered C.
5.5.1
Standard and General Permitting
Theorem 5.5.1 (Standard Permitting Theorem).
Let f(x) be a com-
putable function and let A and C be c.e. sets with computable enumerations
{As}s∈ω and {Cs}s∈ω, respectively, such that
(5.12) As+1 ↾↾x ̸= As ↾↾x
.
=⇒
.
( ∃y ≤f(x) ) [ y ∈Cs+1 −Cs ].
Then A ≤T C. Indeed, A is bounded Turing reducible to C, A ≤bT C, as
in Deﬁnition 3.8.1 (i).
Proof. The condition (5.12) guarantees that mA(x) ≤mC(f(x)).
When we use a computable function f(x) and (5.12) as in Theorem 5.5.1,
we refer to it as standard permitting, and we achieve A ≤bT C. The proof
suggests the more general possibility of ﬁxing a function f ≤T C and still
achieving mA(x) ≤mC(f(x)), which would ensure A ≤T C but not A ≤bT
C. This does not quite succeed because we assume only that f ≤T C, and
we need a computable function in order to carry out the permitting which
is a computable construction. However, if we replace f(x) by a computable
approximation bf(x, s) and modify the conditions accordingly, then we can
succeed. In the simple permitting method, we have f(x) = x and conclude
that A ≤ibT C.
Theorem 5.5.2 (General Permitting Theorem). Let A and C be c.e. sets
with computable enumerations {As}s∈ω and {Cs}s∈ω and let bf(x, s) be a
computable function satisfying the following conditions:
(i)
f(x) = lims bf(x, s) > 0 exists.
(ii)
0 <
bf(x, s) ̸=
bf(x, s + 1)
. =⇒.
( ∃y ≤bf(x, s) ) [ y ∈Cs+1 −Cs ].
(iii)
As+1 ↾↾x ̸= As ↾↾x
.
=⇒
.
( ∃y ≤bf(x, s) ) [ y ∈Cs+1 −Cs ].
Then A ≤T C.
Proof. Now f(x) = lims bf(x, s) > 0 by (i). Next, f ≤T C by (ii) because
if bf(x, s) > 0, then
f(x) = bf(x, s)
⇐⇒
¬( ∃y ≤bf(x, s) ) [ y ∈C −Cs ].

5.5.
⊘More General Permitting
123
Finally, A ≤T C because mA(x) ≤mC (f(x)), which is C-computable.
5.5.2
Reverse Permitting
Theorem 5.5.3 is important because it shows that general permitting is the
most general form of reducibility on c.e. sets A ≤T C in the sense that any
Turing reduction among them can be reduced to the general permitting in
Theorem 5.5.2.
Theorem 5.5.3 (Reverse Permitting).
If A and C are c.e. and A ≤T C,
then there are computable enumerations {As}s∈ω and {Cs}s∈ω of A and C,
and a computable function bf(x, s) satisfying the conditions of the General
Permitting Theorem 5.5.2.
Proof. Fix A and C and e such that A = ΦC
e . Fix computable enumerations
{ bAt}t∈ω and { bCt}t∈ω of A and C. Now for every s ﬁnd the least t > s such
that
(5.13)
(∀x ≤s) [ Φ
b
C
e (x) [ t ] ↓
=
bA(x) [ t ] ].
Now deﬁne As = bAt and Cs = bCt and deﬁne
bf(x, s) =
(
supz≤x ϕ b
C
e (z) [ t ]
if x ≤s;
0
if x > s.
Once bf(x, s) is deﬁned for some x ≤s, the value bf(x, s) persists unless
z ∈Cv+1 −Cv for some z ≤bf(x, v), in which case the process begins again.
The function bf(x, s) satisﬁes conditions (i) and (ii) of Theorem 5.5.2, and
it satisﬁes (iii) by the Use Principle in Theorem 3.3.9.
5.5.3
Building a Turing Functional
ΘC = A
Now let us relate the permitting ideas of the General Permitting The-
orem 5.5.2 and the movable marker arguments of §4.3.2. Often we are
given a noncomputable c.e. set C and we wish to build a c.e. set A with
certain properties and an explicit Turing reduction ΘC = A with use func-
tion θC(x). We view θ(x) in a dual role, as a movable marker taking the
place of marker Γx in §4.3.2, and as the ﬁnal value of the use function for
θ(x) = lims θ(x)[s].
We begin by placing θ(x) on −1, indicating that it is not yet deﬁned.
Later we may place θ(x) on some use u > 0 at some stage s, making
θ(x)[s] = u, and simultaneously deﬁning Θ(x)[s] = y for some y. By doing

124
5. Classifying C.E. Sets
so we are placing an axiom ⟨σ, x, y⟩into the oracle graph G of Θ as explained
in §3.3, where σ = Cs ↾↾u. Since σ ≺Cs, we are committed to these values
of Θ(x)[s] and θ(x)[s] so long as σ ≺Ct for t > s. If some w ≤u enters
C at stage t > s, then we are relieved of any commitment, and we can
begin deﬁning Θ(x) and θ(x) anew. Now C is c.e. and can never return to
the former neighborhood σ ≺Cs at any stage v > t. Therefore, the former
axiom ⟨σ, x, y⟩can never apply to C after stage t, and C is permitted to
ignore this axiom forever.
5.6
⊘Hyperimmune-Free Degrees
Martin and Miller in [Miller and Martin 1968] extended the deﬁnition of
hyperimmune from a single set to an entire degree.
Deﬁnition
5.6.1. [Miller and Martin, 1968]
(i)
A degree d is
hyperimmune (h-immune) if it contains a hyperimmune set.
(ii) If degree d contains no hyperimmune set, it is called hyperimmune-free
(since it is free of hyperimmune sets). It is also called computably dominated
because by Theorem 5.3.3 every set B ∈d is dominated by a computable
function.
Corollary 5.3.7 shows that every nonzero c.e. degree is hyperimmune. The
next few results will demonstrate that every nonzero degree comparable
with 0′ is hyperimmune, showing that the hyperimmune-free degrees are
scarce. However, by Theorem 9.5.1 at least one nonzero hyperimmune-free
degree exists.
5.6.1
Two Downward Closure Properties of Domination
The key point of Deﬁnition 5.6.1 (ii) is that a function f or set A is com-
putably bounded if there is a single computable function h which bounds
(majorizes) f, while f being hyperimmune-free imposes computable bound-
ing on every function g ≡T f, a very strong condition. Remarkably, it turns
out not to matter whether we insist on having this condition for all g ≤T f
or merely for all g ≡T f. (Recall that pA is the principal function of A, the
function lisiting all elements in increasing order.)
Theorem 5.6.2 (Miller and Martin, 1968). Suppose A is hyperimmune-
free.
(i) If B ≤T A, then B is hyperimmune-free.
(ii) If f ≤T A, then f is hyperimmune-free.

5.6.
⊘Hyperimmune-Free Degrees
125
Proof. (i) Let B = ΦA
e . Deﬁne g(x) as follows. Let g(0) = 0. For every x ∈
ω deﬁne g(2x+1) = g(2x)+pB(x)+1 and g(2x+2) = g(2x+1)+pA(x)+1.
Now g is strictly increasing and therefore is the principal function of some
set C ≡T A. Therefore, some computable function h bounds g = pC. But
then h(2x + 1) bounds pB(x).
(ii) Let f = ΦA
e . Deﬁne g(0) = 0. For every x ∈ω deﬁne g(x + 1) = g(x) +
f(x)+1. Now g is strictly increasing and therefore is the principal function
of some set C ≡T f. Therefore, some computable function h bounds g = pC.
But then h(x + 1) bounds f(x) by part (i).
Corollary 5.6.3. The hyperimmune degrees are closed upwards and the
hyperimmune-free degrees are closed downwards.
Proof. By Theorem 5.6.2.
Theorem 5.6.4. A set A is hyperimmune-free iﬀfor every total f,
(5.14)
f ≤T A
=⇒
f ≤tt A.
Proof. (=⇒). Suppose that A is hyperimmune-free and f = ΦA
e . Deﬁne
g(x) = (µs) [ ΦA
e,s(x)↓],
which exists because f is total. Also note that g ≤T A. Therefore, by
Theorem 5.6.2 there exists some computable function h which bounds g.
Deﬁne a Turing functional ΨX(x) which, on any input x and oracle X,
runs ΦX
e.s(x) for s = h(x) many steps, and outputs y if ΦX
e.s(x)↓= y and 0
otherwise. Then ΨX is total for every X and ΨA = ΦA
e .
(⇐=) (Jockusch) Assume f ≤T A. To prove that A is hyperimmune-free
we must show that f is bounded by some computable function h. Now
f ≤tt A by (5.14). Fix a total reduction Φe such that f = ΦA
e . Deﬁne a
computable function h. Given x, search for a level n such that Φσ
e (x)↓for
all σ of length n. Such a level must exist, because otherwise {σ : Φσ
e (x)↑}
would be an inﬁnite tree, and Φg
e(x) would not converge for any path g
through it. Let h(x) = max{Φσ
e (x) : |σ| = n}. Clearly, h bounds f.
5.6.2
∆2 Degrees Are Hyperimmune
Every nonzero c.e. degree is hyperimmune because it contains a hypersimple
set. We now prove that nonzero degrees d ≤0′ are also hyperimmune. We
also explore the Σ2 degrees and other degrees with respect to computable
domination. Here we use the following computation function, cA(x), rather
than the least function mA(x) of (3.17) because having a computable func-
tion h which dominates mA(x) for a ∆2 approximation gives no information
while having one which dominates cA(x) gives much more information.

126
5. Classifying C.E. Sets
Deﬁnition 5.6.5. Let A be a ∆2 set and let {As}s∈ω be a computable
sequence such that A = lims As. The computation function is
(5.15)
cA(x) = (µs > x) [ As ↾↾x = A↾↾x ],
where A↾↾x denotes the restriction of A to elements y ≤x.
Theorem 5.6.6. Let A be ∆2 and let {As}s∈ω be a ∆2 approximation to
A with computation function cA(x).
(i) cA ≡T A.
(ii) If g(x) dominates cA(x) then A ≤T g. Therefore, A is computable iﬀ
a computable function g dominates cA(x).
Proof. (i) A ≤T cA because A(x) = As(x) for s = cA(x). Also, cA(x) ≤T A
because we generate As(x) until the ﬁrst s > x with A↾↾x = As ↾↾x.
(ii) If A is computable then cA is computable by (i). Conversely, assume
cA(x) < g(x) for all x. Deﬁne
(5.16)
y = (µz > x) (∀t)z≤t≤g(z) [ At ↾↾x = Az ↾↾x ].
By the deﬁnition of cA(x) and the fact that cA(x) < g(x) we know that for
all z ≥x the interval [ z, g(z) ] (called a frame) must contain at least one
stage t which is z-true in the sense that At ↾↾z = A↾↾z. But A = lims As
implies that As ↾↾x = A↾↾x for almost all s. Therefore, almost all z-frames
must contain only stages t which are x-true. This proves that A(x) = Ay(x)
because all values for x in the y-frame agree by (5.16) and one must agree
with A(x) because y > x and cA(y) ≥cA(x).
Corollary 5.6.7 (Miller and Martin, 1968). If ∅<T A ≤T ∅′ then deg(A)
is hyperimmune.
Proof. Let ∅<T A ≤T ∅′. Hence, A ∈∆2. By Theorem 5.6.6, no com-
putable function can dominate cA ≡T A. Therefore, by Theorem 5.6.2, A
cannot have hyperimmune-free degree.
Corollary 5.6.8. If a nonzero degree d is comparable with 0′ then d is
hyperimmune.
Proof. By Corollary 5.6.7, all nonzero degrees d ≤0′ are hyperimmune. By
the upward closure of hyperimmune degrees in Theorem 5.6.2, all degrees
d > 0′ are also hyperimmune.
The next result generalizes Corollary 5.6.7 and shows that most degrees
obtained by iterating the jump are hyperimmune.
Corollary 5.6.9 (Miller and Martin, 1968). If B <T A ≤T B′ then deg(A)
is hyperimmune.

5.7. Historical Remarks and Research References
127
Proof. The set A is ∆B
2 and there is a B-computable sequence {As}s∈ω
such that A = lims As by Deﬁnition 5.6.5 relativized to B. Deﬁne the com-
putation function cA as there. If any computable (or even B-computable)
function h dominates cA then A ≤T B, contrary to hypothesis.
5.6.3
Σ2 Approximations and Domination
Deﬁnition
5.6.10. (i)
A computable sequence {As}s∈ω
is a Σ2
approximation to a Σ2 set A if
(5.17)
x ∈A
⇐⇒
(∀∞s)[ x ∈As ].
(ii) For such a Σ2 sequence deﬁne the Σ2 computation function
(5.18) cA(x) = (µs ≥x)(∀z ≤x)[ z ∈A
=⇒
(∃t)x≤t≤s[ z ̸∈At ] ].
Theorem 5.6.11. Let A be a Σ2 set and let {As}s∈ω be a Σ2 approxima-
tion to A with cA(x) the Σ2 computation function. If a computable function
dominates cA(x) then A is computably enumerable.
Proof. Let A be Σ2. Now assume that (∀x)[g(x) ≥cA(x)]. From (5.17) and
(5.18) we know
(5.19)
(∀x) [ x ∈A
=⇒
(∀y > x)(∃t)y≤t≤g(y) [ x ̸∈At ] ],
(5.20)
(∀x) [ x ∈A
⇐⇒
(∃y > x)(∀t)y≤t≤g(y) [ x ∈At ] ].
Therefore, A is Σ1 in g. If g is computable, then A is Σ1 and hence c.e.
5.7
Historical Remarks and Research References
In 1959 Friedberg and Rogers introduced the notion of bounded Turing
reducibility under the name weak truth-table reducibility, wtt-reducibility,
because like tt-reducibility it has a computable bound h(x) on the use, but
unlike tt it need not be a total functional.
It follows from Corollary 5.3.7 that hypersimplicity does not guaran-
tee incompleteness. Although hypersimple sets can be easily constructed
directly (see Exercise 5.3.9), it is not obvious how to construct an hyperhy-
persimple set. Indeed, the ﬁrst and most natural example is a maximal set.
Maximal sets have the thinnest possible complement which a coinﬁnite c.e.
set can have. However, in 1965 Yates constructed a complete maximal set,
thereby refuting Post’s idea that the thinness of complement of a coinﬁnite
c.e. set could guarantee incompleteness.
In the original investigations of computability, attention was focused on
total computable functions as the most familiar and easily understood from

128
5. Classifying C.E. Sets
traditional mathematics. The Herbrand-G¨odel general recursive functions
and the Turing machines demonstrated convincingly that the central con-
cept was that of a partial computable function and that the total ones
should be viewed as a restriction of this central concept. Likewise, the ﬁrst
to systematically explore relative reducibilities was Post who built up re-
ducibilities from the most obvious m-reducibility to btt and tt-reducibilities.
All these give a total reduction A = ΦB, and indeed tt is equivalent to
reducibility by a total Turing reduction Φ (see Theorem 3.8.5).
These concepts of Post so inﬂuenced the ﬁrst two decades of the subject
that when Friedberg and Rogers in 1959 introduced the notion A = ΦB
with use function ϕB(x) bounded by a computable function h(x) they
thought of it as a “weakening” of the existing concept of tt, rather than
the strengthening A bounded Turing reducible to B, written A ≤bT B, of
the general notion of A ≤T B, which was not well understood in 1959.
Today we see that the way to understand a Turing reducibility on c.e.
sets B ≤T A is through the General Permitting Theorem 5.5.2 because it
is the most general. The many examples of B ≤T A through the standard
permitting in Theorem 5.5.1 and the more general permitting in Theo-
rem 5.5.2 illustrate this dynamic approach. Early results such as Myhill’s
1955 Theorem in Chapter 2 that K ≤m C for a creative set C tended to re-
inforce the role of strong and total reducibilities. However, Martin’s result
on completeness of eﬀectively simple sets and Arslanov’s generalization in
§5.4 showed that static and total reductions should be replaced now by
partial and dynamic ones.
5.7.1
⊘
∆2-Permitting
In the general permitting of Theorem 5.5.2 we might be given a noncom-
putable c.e. set A and we might construct a Σ1 or even ∆2 set B ≤T A. At
some stage s we might have issued an axiom ⟨σ, x, 0⟩for Ψσ(x) = 0 = Bs(x)
where σ = As ↾↾x. At a later stage s + 1, if As+1 ↾↾x = τ ̸= σ then we are
released forever from the previous axiom because A, being c.e. , can never
return to neighborhood σ. This enables us to issue a new axiom, ⟨τ, x, 1⟩,
for Ψτ(x) = 1 and deﬁne Bs+1 ↾↾x = ΨA ↾↾x [s + 1]. Now A being c.e.,
can never have entered neighborhood τ before, and therefore there is no
previous axiom involving τ.
All this fails if A is ∆2 instead of Σ1. Using the above example, there
may be a later stage t > s + 1 when A returns to neighborhood σ. In
this case we have already made a commitment of Ψσ(x) and must return
B to the previous state Bv ↾↾x = Bσ ↾↾x. Nevertheless, Posner devel-
oped a system of ∆2-permitting by returning after every such change to
the previous conﬁguration and commitment. R. Miller reﬁned the method
to prove in [R. Miller 2001] that there exists a linear order whose degree
spectrum (degrees of isomorphic copies) includes every nonzero ∆2 degree
but not 0. Csima in [Csima 2004] also developed the method to ﬁnd for

5.7. Historical Remarks and Research References
129
any nonzero ∆2 degree d and any complete decidable theory a d-decidable
model omitting the nonprincipal types. The method is particularly useful
if one wants to prove a theorem of the following form: for any nonzero ∆2
degree there exists such and such in that degree. The rough idea is that
if the ∆2 degree d is not computable, and if one returns as necessary to
previous conﬁgurations, there will eventually be a permitted change which
is not later reversed.

6
Oracle Constructions and Forcing
6.1
⋆Kleene-Post Finite Extensions
We have seen in Chapter 5 how Post tried to solve Post’s Problem 5.1.1 by
deﬁning c.e. sets A with ever thinner complements. Post himself did not live
to see the refutation of this approach by [Friedberg 1958], who constructed
a maximal set with the thinnest complement of all, and the construction
of a complete maximal set by Yates, which refuted Post’s approach. Post
moved on to understand full Turing reducibility in [Post 1944]. He gave an
excellent intuitive description of one set being Turing reducible to another.
From 1944 until his death in 1954 Post worked to understand Turing re-
ducibility and decision problems for c.e. sets. Post in [Post 1944] page 289
introduced and later deﬁned in [Post 1948] degrees of unsolvability (Turing
degrees,) as we have presented in Deﬁnition 3.4.1. Post thought carefully
about the properties of Turing reducibility and wrote extensive notes. Just
before his death in 1954 he gave his notes to Kleene, who revised and
expanded them and published them as [Kleene and Post 1954]. This fun-
damental paper clariﬁed the properties of a Turing reduction, including the
Use Principle 3.3.9, and used it to construct sets of incomparable degree
below ∅′, as in Theorem 6.1.1. The paper did not directly address Post’s
Problem, because it was for ∆2 sets, not Σ1 sets, but it laid the indispens-
able foundation for the later solution by Friedberg and Muchnik, presented
in Chapter 7, who added a computable approximation to the Kleene-Post
method to obtain Turing incomparable Σ1 sets.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
131 
6 

132
6. Oracle Constructions and Forcing
The ﬁrst major contribution in [Kleene and Post 1954] is the ﬁnite ex-
tension oracle construction. Here we ﬁx some oracle X, such as X = ∅′
or X = ∅′′, and build a set A ≤T X by an X-computable construction of
ﬁnite initial segments {σs}s∈ω of A with σs ≺σs+1 . For example, given
σs, index e, and argument x, we can ask the ∅′-question,
(∃ρ ≻σs)(∃y)(∃t) [ Φ ρ
e,t (x)↓= y ]?
If so, we can deﬁne σs+1 = ρ, which guarantees that ΦA
e (x) = y for every
A ≻σs+1 by the Use Principle 3.3.9. If not, then ΦA
e (x) diverges for every
A ≻σs and we can deﬁne σs+1 ≻σs in any fashion.
By the ﬁnite extension of σs+1 ≻σs we have decided (forced) Turing com-
putability properties of an inﬁnite set A ≻σs+1 not yet fully constructed.
In §6.3 on generic sets we study the general case of forcing conditions which
are ﬁnite initial segments. In §6.5 on least upper bounds we consider inﬁnite
matrices as forcing conditions.
Theorem 6.1.1 (Kleene-Post, 1954).
There exist sets A, B ≤T ∅′ such
that A |T B ( i.e., A ̸≤T B and B ̸≤T A.) Therefore, ∅<T A, B <T ∅′.
Proof. We shall construct functions χA and χB in stages s so χA = ∪sσs
and χB = ∪sτs, where σs and τs are the ﬁnite strings constructed by the
end of stage s. Since the construction of σs and τs at stage s is computable
in ∅′, the sequences
{σs}s∈ω and {τs}s∈ω are ∅′-computable sequences.
Therefore, A, B ≤T ∅′. It suﬃces to meet, for each e, the requirements:
(6.1)
Re :
A ̸= ΦB
e
&
Se :
B ̸= ΦA
e
to ensure that A ̸≤T B and B ̸≤T A. Hence, A |T B.
Stage s = 0. Deﬁne σ0 = τ0 = ∅.
Stage s + 1 = 2e + 1. (We satisfy Re.) Given σs, τs ∈2<ω of length ≥s.
Let n = |σs| = (µx) [ x /∈dom(σs) ]. Using a ∅′-oracle we test whether
(6.2)
(∃t) (∃ρ) [ ρ ≻τs
&
Φρ
e,t (n)↓].
Note that ρ ≻τs is computable as a relation of strings ρ and τs. The
second clause of (6.2) is computable by the Oracle Graph Theorem 3.3.8 (i).
Therefore, (6.2) is a Σ1 statement and can be decided computably in ∅′.
Case 1. Suppose (6.2) is satisﬁed. The matrix of (6.2) is computable. Find
the least pair ⟨ρ, t⟩satisfying that matrix. Deﬁne τs+1 = ρ and σs+1(n) =
1 .−Φρ
e,t(n) so that σs+1(n) ̸= Φρ
e,t(n).
Case 2. Suppose (6.2) fails. Then deﬁne σs+1 = σsb0 and τs+1 = τsb0.
In either case, |σs+1|, |τs+1| ≥s+1. Therefore, χA = ∪sσs and χB = ∪sτs
are deﬁned on all arguments. In either case, if f ⪰σs+1 and g ⪰τs+1 then
f(n) ̸= Φg
e(n) by the Use Principle Theorem 3.3.9.

6.1.
⋆Kleene-Post Finite Extensions
133
Stage s + 1 = 2e + 2. (We satisfy Se.) Proceed exactly as above but with
the roles of σs and τs replaced by τs and σs, mutatis mutandis.
Theorem 6.1.2 (Relativized Version). For any degree c, there are degrees
a, b such that c ≤a, b and a, b ≤c′ and a | b.
Proof. Fix a set C ∈c. Relativize the above proof to C, using a C ′-oracle
to build sets A and B such that (A ⊕C) |T (B ⊕C) and A, B ≤T C ′. In
place of (6.2) we use a C ′-oracle to test whether
(6.3)
(∃t) (∃τ1) (∃τ2) [ τ1 ≻τs
&
τ2 ≺C
&
Φτ1⊕τ2
e,t
(n)↓],
where τ1 ⊕τ2 is deﬁned to be the shortest string ρ ∈2<ω such that ρ(2x) =
τ1(x) and ρ(2x + 1) = τ2(x). The obvious modiﬁcation of Cases 1 and 2
ensures that A ̸= ΦB⊕C
e
. At stage 2e+2 we ensure that B ̸= ΦA⊕C
e
. Finally,
let a = deg(A ⊕C) and b = deg(B ⊕C).
Deﬁnition 6.1.3. A countable sequence of sets {Ai}i∈ω is computably
independent if for each i, Ai ̸≤T ⊕{Aj : j ̸= i}, where the inﬁnite join is
deﬁned as in Exercise 3.4.7.
6.1.1
Exercises
Exercise 6.1.4. Modify the proof of Theorem 6.1.1 to build an indepen-
dent sequence {Aj}j∈ω of sets each computable in ∅′ (indeed, ⊕jAj ≤T ∅′).
Hint. Use a ﬁnite extension ∅′-computable construction to build at stage s
strings {ρs
j}s∈ω such that if Aj = ∪sρs
j then we meet for each e and i the
requirement
R⟨e,i⟩: Ai ̸= Φ⊕{Aj : j̸=i }
e
.
At stage s = 0, set ρ0
j = ∅for all j. At stage s + 1 = ⟨e, i⟩+ 1 we meet
requirement R⟨e,i⟩as follows. Given { ρs
j }j∈ω, only ﬁnitely many of which
are nonempty, let n = |ρs
i|, and use a ∅′-oracle to test whether there exist
m and (a code number for) a ﬁnite sequence of strings σ0, σ1, . . . , σk such
that
(6.4) Φ⊕{ σj : j̸=i }
e
(n)↓= m
&
(∀j ≤k) [ j ̸= i
=⇒
ρs
j ≺σj ].
Now according to whether or not (6.4) holds proceed as in Theorem 6.1.1
Case 1 (letting ρs+1
i
(n) = 1 .−m, and ρs+1
j
= σj for j ̸= i), or as in Case 2
otherwise. (Be sure to make each Ai total.)
Exercise 6.1.5. A partially ordered set P = (P, ≤P) is countably universal
if every countable partially ordered set is order isomorphic to a subordering
of P. Prove that there is a computable partial ordering ≤R of ω which is
countably universal. Hint. This can be done either by considering a com-
putably presented atomless Boolean algebra, or by a direct construction
where at stage s + 1, given a ﬁnite set Ps of elements in ≤R, one obtains
Ps+1 by adding a new point for each possible order type over Ps. A Boolean

134
6. Oracle Constructions and Forcing
algebra B = ({ bi }i∈ω; ≤, ∨, ∧, ′) is computably presented if there exist a
computable relation P(i, j) and computable functions f, g and h such that
P(i, j) holds iﬀbi ≤bj, and such that bf(i,j) = bi ∨bj, bg(i,j) = bi ∧bj, and
bh(i) = b′
i.
Exercise 6.1.6. Show that for a countable partially ordered set P = ⟨P, ≤P⟩
there is a 1:1 order-preserving map from P into D(≤0′), the degrees ≤0′.
Hint. By Exercise 6.1.5 we may assume P = ω and ≤P is a computable
relation. Let { Ai }i∈ω be as in Exercise 6.1.4. Deﬁne f : ω →D(≤0′) by
f(i) = ai = deg(⊕Aj : j ≤P i). Show that if i ≤P j then ai ≤aj (by
deﬁnition and the fact that ≤P is computable), and if i ̸≤P j then ai ̸≤aj
(by the computable independence of { Ai }i∈ω).
Exercise 6.1.7. Prove that there are 2ℵ0 mutually incomparable degrees.
Hint. Recall Deﬁnition 8.2.1 of a tree T ⊆2<ω and its associated trees in
Deﬁnition 3.7.1. Construct a tree T ⊆2<ω such that f |T g for every pair
f, g ∈[ T ] with f ̸= g. Let T = ∪eTe where tree Te+1 ⊃Te and Te+1 is
deﬁned by induction as follows. Let T0 = { ∅}, the tree with the empty
node (root) as its only member. Given Te deﬁne Le to be the leaves of tree
Te, namely
Le = { σ : σ ∈Te
&
(∀τ ≻σ) [ τ /∈Te ] }.
Next deﬁne the successors to leaves,
Se = { σb0 : σ ∈Le }
∪
{ σb1 : σ ∈Le }.
Suppose Se = { ρi : i ≤2e+1 }. Fix i , j ≤2e+1, i ̸= j. Use the method
of Theorem 6.1.1 to replace ρi and ρj by strings σ ≻ρi, τ ≻ρj satisfying
(6.5)
(∀f ≻σ) (∀g ≻τ) [ Φf
e ̸= g
&
Φg
e ̸= f ].
Repeat this procedure for all i, j ≤2e+1 with i ̸= j.
6.2
Minimal Pairs and Avoiding Cones
Deﬁnition 6.2.1. Degrees a and b form a minimal pair if a, b > 0 and
(6.6)
(∀c) [ [ c ≤a
&
c ≤b ]
=⇒
c = 0 ].
Minimal pairs have played an important role in computability theory.
Later we shall construct a minimal pair of computably enumerable degrees.
In §6.5 we shall modify the minimal pair construction to ﬁnd an exact
pair of degrees for an ascending sequence of degrees as deﬁned in Deﬁni-
tion 6.5.2. To simplify the notation now and later we introduce a useful
remark of Posner which allows us to replace pairs of indices by a single
index.
Remark 6.2.2 (Posner).
For all sets A and B with A ̸= B and all i
and j, there exists e such that ΦA
e = ΦA
i and ΦB
e = ΦB
j .

6.2. Minimal Pairs and Avoiding Cones
135
Proof. Since A ̸= B they diﬀer on some element n, say n ∈A −B. Deﬁne
the Turing reduction ΦX
e for any X by
ΦX
e (y) =



ΦX
i (y)
if n ∈X;
ΦX
j (y)
otherwise.
Theorem 6.2.3. There is a minimal pair of degrees a, b < 0′.
Corollary 6.2.4 (Theorem 6.1.1). There exist a, b < 0′ with a | b.
Proof. If a, b is a minimal pair then a | b. If a ≤b then a∧b = a > 0.
Proof of Theorem 6.2.3. It suﬃces to construct sets A and B unequal and
computable in ∅′ satisfying for all e the following requirements.
(6.7) Ne :
ΦA
e
= ΦB
e
total
=⇒
(∃g ≤T ∅) [ g = ΦA
e ].
(6.8)
Pe :
A ̸= ϕe
and
B ̸= ϕe.
We shall use a ∅′-oracle construction to build increasing sequences of
strings, {σs}s∈ω and {τs}s∈ω, and then deﬁne A = ∪sσs and B = ∪sτs.
Deﬁne σ0 = ∅and τ0 = ∅.
Stage s + 1 = 2e + 1.
(Satisfy Pe for A and B.)
Given σs and τs
let x = |σs| = (µy)[σs(y) ↑]. Ask ∅′ whether ϕe(x) ↓. If so, deﬁne
σs+1(x) = 1 .−ϕe(x) and otherwise deﬁne σs+1(x) = 0. Do likewise to
ensure that τs+1 and ϕe are not compatible.
Stage s + 1 = 2e + 2. (Satisfy Ne.) Ask ∅′ the Σ1 question,
(6.9)
(∃ρ ≻σs) (∃ν ≻τs) (∃x) [ Φρ
e(x) ↓
̸=
Φν
e(x)↓]?
If so, deﬁne σs+1 = ρ and τs+1 = ν. If not, deﬁne σs+1 = σsb0 and
τs+1 = τsb0.
Lemma 6.2.5. (∀e) [ ΦA
e = ΦB
e = f
total
=⇒
f is computable ].
Proof. Assume ΦA
e = ΦB
e = f is total. At stage s+1 = 2e+2, equation (6.9)
could not have held, else ΦA
e ̸= ΦB
e . Hence, for any x we can choose ρ ≻σs
such that Φρ
e(x) ↓= y by the Use Principle 3.3.9 because ΦA
e is total. Now
any other ξ ≻σs for which Φξ
e(x) ↓= z must have y = z, else one of y and
z must form a disagreement with Φν
e(x) for some ν ≺B, contrary to our
hypothesis that (6.9) fails. Therefore, f(x) = y even though we may not
have ρ ≺f. Since searching for the ﬁrst such string ρ, which must exist, is
a computable procedure, we know that f is computable.
So far the degrees we have constructed, such as 0(n) or degrees below 0′,
are comparable to 0′. We now show how to construct a degree a incompara-
ble with a given degree b > 0. To achieve this, a must avoid the lower cone
of degrees { d : d ≤b } and the upper cone { d : d ≥b }. The strategy for
accomplishing the latter (which we play on the even stages) will be used

136
6. Oracle Constructions and Forcing
in this chapter, and will be reﬁned and often used in constructions of c.e.
degrees, such as in the Sacks Splitting Theorem in Chapter 7.
Theorem 6.2.6 (Avoiding Cones).
For every degree b > 0 there exists a
degree a < b′ such that a | b.
Proof. Fix B ∈b. Construct f, the characteristic function of A, by
a B′-computable ﬁnite extension construction, f = ∪sσs, to meet the
requirements Re and Se of Theorem 6.1.1.
Stage s = 0. Set σ0 = ∅.
Stage s + 1 = 2e + 1.
(Satisfy Re : A ̸= ΦB
e .)
Let n = |σs|. With a
B′-oracle determine whether ΦB
e (n) converges, i.e., whether ⟨n, e⟩∈KB
0 ≡
B′. If so, deﬁne σs+1(n) = 1 .−ΦB
e (n). If not, deﬁne σs+1(n) = 0.
Stage s+1 = 2e+2. (Satisfy Se : B ̸= ΦA
e .) Given σs, ﬁrst ∅′-computably
test whether the following equation holds:
(6.10)
(∃σ)(∃τ)(∃x)(∃y)(∃z)(∃t)
[ σs ≺σ, τ
&
Φσ
e,t(x)↓= y
̸=
z = Φτ
e,t(x)↓].
If so, one of the values y or z must diﬀer from B(x). Let σs+1 be the
ﬁrst σ ≻σs such that Φσ
e (x)↓̸= B(x) for some x. (This is B′-computable
because B ⊕∅′ ≤T B′.) If (6.10) fails, we let σs+1 = σsb0. In this case,
we claim that for any f ≻σs if Φf
e = g is total, then g is computable
(and hence Φf
e ̸= B because ∅<T B). To compute g(x), enumerate Ge of
the Oracle Graph Theorem 3.3.8 (ii) until the ﬁrst σ ≻σs is found such
that Φσ
e (x) converges. Now g(x) = Φf
e(x) = Φσ
e (x), because otherwise for
some τ, σs ⪯τ ≺f, Φτ
e(x)↓̸= Φσ
e (x), thereby satisfying (6.10).
6.2.1
Exercises
Exercise 6.2.7. Construct an inﬁnite sequence of degrees an ≤0′,
n ∈ω, which pairwise form minimal pairs. Hint. Build noncomputable sets
{An}n∈ω meeting for all i, j, and all m ̸= n,
N⟨m,n,i,j⟩:
ΦAm
i
= ΦAn
j
= f total
. =⇒.
f is computable.
Exercise 6.2.8. (i) Fix a degree c > 0. Build a degree b which forms a
minimal pair with c.
(ii)
Given nonzero degrees {cn}n∈ω, ﬁnd a sequence of degrees {ai}i∈ω
each of which is incomparable with cn for every n and which pairwise form
minimal pairs.

6.3.
⋆Generic Sets
137
6.3
⋆Generic Sets
In the two preceding sections we constructed a sequence of ﬁnite functions
σs ⪯σs+1 so that σs+1 (and indeed all τ ⪰σs+1) met a particular require-
ment. The generic construction in this section encompasses all the previous
examples. Recall that in the Notation section we gave an eﬀective index y
to each string σy ∈2<ω and we identify the string σy with its index y. Like-
wise, we identify a c.e. set of strings Ve ⊆2<ω with the corresponding c.e.
set of integers and use the same notation, Ve. Deﬁnition 2.6.1 deﬁned u.c.e.
and s.c.e arrays of c.e. sets. Generic sets were studied by [Jockusch 1980].
6.3.1
1-Generic Sets
Deﬁnition 6.3.1. Let V = {Ve}e∈ω be a u.c.e. sequence of c.e. sets
Ve ⊆2<ω as in Deﬁnition 2.6.1, with strings identiﬁed with their indices.
(i) We say f ∈2ω forces Ve if it satisﬁes the forcing requirement,
(6.11)
Fe :
(∃σ ≺f) [ σ ∈Ve
∨
(∀ρ ≻σ) [ ρ ̸∈Ve ] ].
If σ satisﬁes the matrix of Fe we say that σ forces Fe (written σ ⊩Fe) and
any f ≻σ also forces Fe (written f ⊩Fe).
(ii) We say f is generic with respect to V = {Ve}e∈ω (written V-generic)
if f forces Ve for every e ∈ω.
(iii) We say f is 1-generic if it is generic with respect to {We}e∈ω. (The
term “1-generic” refers to the fact that f is deciding Σ1 statements.)
If the f satisﬁes the ﬁrst clause σ ∈Ve of the matrix in (6.11), then
we say f is e-white and otherwise f is e-black. For every e the 1-generic
function f must be either e-black or e-white.
The point about a 1-generic set is that it is amorphous and diﬃcult to
describe. For example, it cannot be computable or even c.e. However, we
can construct a 1-generic ∆2 set.
6.3.2
Forcing the Jump
Occasionally, we build f as the characteristic function of a set A and we
wish to control the jump A′. (At a ﬁnite stage we decide whether e ∈A′.)
We can accomplish this by meeting for all e the following requirement called
forcing the jump ΦA
e (e):
(6.12)
Je :
(∃σ ≺A) [ Φσ
e (e) ↓
∨
(∀τ ⪰σ) [ Φτ
e(e) ↑] ].

138
6. Oracle Constructions and Forcing
Theorem 6.3.2 (Jockusch-Posner).
A set A is 1-generic iﬀA forces the
jump, i.e., satisﬁes every jump requirement {Je}e∈ω of (6.12).
Proof. (=⇒).
Deﬁne Wh(e) = {σ : Φσ
e (e) ↓}. Now A forces Wh(e).
Therefore, A forces the jump ΦA
e (e), i.e., satisﬁes the requirement Je.
(⇐=). Deﬁne a computable function f(e) by
Φσ
f(e)(z) =
(
1
if (∃s ≤|σ|) (∃τ ⪯σ) [ τ ∈We,s ],
undeﬁned
otherwise.
If A meets requirement Jf(e) of (6.12), then we can clearly see that A forces
Ve = {σ : Φσ
f(e)(f(e))↓} and A forces We.
6.3.3
Doing Many Constructions at Once
In the preceding sections we constructed sets with several diﬀerent prop-
erties: incomparable with another, half of a minimal pair, and avoiding a
cone. If we now construct a 1-generic set A, then A automatically has all
these properties because each property corresponds to a dense set and a
1-generic set meets every dense set of strings. Dense sets, comeager sets,
and Banach-Mazur games are explained in Chapter 14. The Banach-Mazur
games described there are very similar to the ﬁnite extension strategies
presented in this chapter.
In Theorem 14.2.1 we shall consider ﬁnite extension arguments in the
general setting of the Finite Extension Paradigm which subsumes them.
This does not cover the coding argument for the Friedberg Completeness
Criterion in Theorem 6.4.1 below. However, we extend our paradigm anal-
ysis to the Finite Extension Coding Paradigm in Theorem 14.2.2 which
covers these examples.
6.3.4
Exercises
Exercise 6.3.3. Construct a 1-generic set A ≤T ∅′. Hint. Use a ∅′-oracle
and ﬁnite extension construction as in the Kleene-Post Theorem 6.1.1 to
meet all the jump requirements Je in (6.12).
Exercise 6.3.4. (Jockusch-Posner) Prove that if a set A is 1-generic, then
A ⊕∅′ ≡T A′. Prove that there is a nonzero low degree.
Exercise 6.3.5. (Jockusch-Posner) Assume A is 1-generic.
(i)
Prove that A is immune. Hint. Let Z be a c.e. subset of A. Deﬁne
Ve = { σ : (∃x ∈Z) [σ(x) = 0] } and use Fe of (6.11) to prove that Z is
ﬁnite.
(ii) Prove that A is hyperimmune.

6.4.
⋆Inverting the Jump
139
(iii) Prove that there is no noncomputable c.e. set Z ≤T A. Hint. Assume
Z = ΦA
i and deﬁne
Ve = { σ : (∃x) [ Φσ
i (x) = 0 & x ∈Z ] },
and apply requirement Fe of (6.11) to show that Z is c.e.
(iv) Prove that A0 and A1 are Turing incomparable where A0(x) = A(2x)
and A1(x) = A(2x + 1). Hint. To see that A0 ̸= ΦA1
e
consider the c.e. set
of strings
Ve = { σ : (∃x) [ Φσ1
e (x)↓̸= σ0(x) ] }
where σ0(x) = σ(2x) and σ1(x) = σ(2x + 1).
(v) Prove that there are sets Bi ≤T A, i ∈ω, such that for every i, we
have Bi ̸≤T ⊕{ Bj : j ̸= i }.
Exercise 6.3.6. (Shoenﬁeld) Show there is a set A ≤T ∅′ which does not
have c.e. degree.
Exercise 6.3.7. Given B such that ∅<T B ≤T ∅′ ﬁnd a low set A such
that A ̸≥T B. Hint. Use a ∅′-construction to build A = ∪sσs. For each e
designate some stage s at which you: (1) force A ̸= ϕe; (2) make A satisfy
the lowness requirement for Φe; and (3) look for e-splittings, ρ, τ extending
σs and some x such that Φρ
e(x)↓̸= Φτ
e(x)↓. If you do not ﬁnd them, then
either ΦA
e is not total or is computable.
Exercise 6.3.8. (i)
Let {An}n∈ω be a sequence of sets uniformly com-
putable in ∅′, i.e., there is a ∅′-computable function g such that for all x
and n, g(n, x)
=
An(x). Prove that there is a set B ≤T ∅′ such that
(∀n) [ B ̸≡T An ]. Hint. Ensure that B is noncomputable and for each e
and n, if ΦB
e = An, then An is computable.
(ii) Give another proof of Exercise 6.3.6.
(iii) Show there is a degree d ≤0′ which is not n-c.e. and not even ω-c.e.
6.4
⋆Inverting the Jump
Note that for any degree a,
0 ≤a and hence 0′ ≤a′, i.e., any jump is
above 0′. Hence, the jump, viewed as a map on degrees, has range contained
in {b : b ≥0′}. The next theorem asserts that this map is onto the set
{b : b ≥0′}. A degree a is called complete if a ≥0′. Hence, the result also
gives a criterion for a being complete.
Theorem 6.4.1 (Friedberg Completeness Criterion). For every degree
b ≥0′ there is a degree a such that a′ = a ∪0′ = b.

140
6. Oracle Constructions and Forcing
Proof. Fix B ∈b. We shall construct f, the characteristic function of A,
by ﬁnite initial segments {σs}s∈ω using a B-computable ﬁnite extension
construction.
Stage s = 0. Set σ0 = ∅.
Stage s + 1 = 2e + 1. (We decide whether e ∈A′.) We meet the forcing
the jump requirement Je of (6.12). If A meets Je we say that A forces the
jump on argument e. Given σs, use a ∅′-oracle to test whether
(6.13)
(∃σ) (∃t) [ σs ≺σ
&
Φσ
e,t(e)↓].
(Note that the matrix is computable. Therefore, (6.13) is a Σ1 condition
and is computable in ∅′.) If (6.13) is satisﬁed, let σs+1 be the ﬁrst such σ
in the standard enumeration of Ge of the Oracle Graph Theorem 3.3.8. If
not, set σs+1 = σs.
Stage s+1 = 2e+2. (We code B(e) into A.) Let n = |σs|. Deﬁne σs+1(n) =
B(e). (This completes the construction.)
Now f = ∪sσs is total since |σ2e| ≥e. Let A = {x : f(x) = 1}, and
a = deg(A). The construction is B-computable because at odd stages we
use a ∅′-oracle, at even stages we use a B-oracle, and ∅′ ≤T B. Since
A ⊕∅′ ≤T A′ for any A, to prove A′ ≡T B ≡T A ⊕∅′ it suﬃces to prove
the following two lemmas.
Lemma 6.4.2. A′ ≤T B.
Lemma 6.4.3. B ≤T A ⊕∅′.
Proof of Lemma 6.4.2.
Since the construction is B-computable, the se-
quence {σs}s∈ω is B-computable. To decide whether e ∈A′, B-computably
determine using ∅′ ≤T B whether (6.13) holds for σ2e. If so, e ∈A′, and
otherwise e /∈A′ because no σ ⪰σs has Φσ
e (e) deﬁned.
Proof of Lemma 6.4.3.
We show {σs}s∈ω is an (A ⊕∅′)-computable se-
quence. This suﬃces because B(e) is the last value of σ2e+2. The proof is
by induction on s. Given {σs : s ≤2e}, use a ∅′-oracle to compute σ2e+1.
If n = |σ2e+1| then σ2e+2 = σ2e+1bA(n), so σ2e+2 is computed from σ2e+1
using an A-oracle.
This completes the proof of Theorem 6.4.1.
Theorem 6.4.4 (Relativized Friedberg Completeness Criterion).
For every degree c,
F1(c) :
(∀b) [ b ≥c′ =⇒(∃a) [ a ≥c & a′ = a ∪c′ = b ] ].
Proof. Do the proof of Theorem 6.4.1 with c and c′ in place of 0 and 0′.

6.5. Upper and Lower Bounds for Degrees
141
Corollary 6.4.5. For every n ≥1, and every degree c,
Fn(c) :
(∀b) [ b ≥c(n)
=⇒
(∃a) [ a ≥c & a(n) = a ∪c(n) = b ] ].
Proof. To prove (∀c)Fn(c) holds for all n ≥1, use induction on n and the
fact that Fn+1(c) follows from Fn(c) and F1(c(n)).
Although Theorem 6.4.1 demonstrates a pleasant property of the jump
operator, it also demonstrates an unpleasant property, namely that the
jump as a map on degrees is not 1:1. To see this, apply Theorem 6.4.1 with
b = 0′′ to obtain a such that a′ = a ∪0′ = 0′′. Clearly, a | 0′, yet they
have the same jump. It is also possible to have a < b and a′ = b′. (It is
easy to see that the jump is 1:1 on sets.)
6.4.1
Exercises
Exercise 6.4.6. [Jockusch-Shore, 1983] Prove that for any i ∈ω and any
B such that ∅′ ≤T B there exists A such that
A ⊕W A
i ≡T A ⊕∅′ ≡T B.
Note that Theorem 6.4.1 is a special case of this setting where i is deﬁned
by W X
i
= X′. Hint. Do the proof of Theorem 6.4.1 but in (6.12) replace
Φρ
e(e)↓by e ∈W ρ
i for ρ = σ or τ. (Note that this construction is uniform
in B and in any j such that ΦB
j = ∅′.)
Exercise 6.4.7. Prove that
(∀b ≥0′) (∃a0) (∃a1) [ a0 | a1 & a′
0 = a0 ∪0′ = b = a1 ∪0′ = a′
1 ].
Hint. Combine the constructions of Theorems 6.1.1 and 6.4.1 to handle
four types of requirements, the two types from Theorem 6.1.1 and the two
from Theorem 6.4.1. As in that theorem at stage 2e + 2, code B(e) into
both of A0 and A1.
6.5
Upper and Lower Bounds for Degrees
Every nonempty ﬁnite set of degrees has a least upper bound (lub). In this
section we show that this is false for greatest lower bounds (glb’s). Hence,
the degrees do not form a lattice, but merely an upper semi-lattice.
Deﬁnition 6.5.1. (i) For any set A deﬁne the ω-jump of A,
A(ω) = { ⟨x, n⟩: x ∈A(n) }.
In Exercise 6.5.9 we show that this is well-deﬁned on degrees. Therefore,
we can deﬁne the induced ω-jump on degrees a(ω) = deg(A(ω)) for A ∈a.

142
6. Oracle Constructions and Forcing
(ii)
An inﬁnite sequence of degrees {an}n∈ω is ascending if an ≤an+1
for all n and strictly ascending if an < an+1 for all n. For example,
0, 0(1), 0(2), . . . is strictly ascending, and 0(ω) is a natural upper bound
for the sequence, although by the next theorem the sequence has no lub.
Deﬁnition 6.5.2. If {an}n∈ω is an ascending sequence of degrees then
upper bounds b and c are an exact pair for the sequence if for every degree
d,
[ d ≤b
&
d ≤c ]
=⇒
(∃n) [ d ≤an ].
Theorem 6.5.3 (Kleene-Post-Spector).
For every ascending sequence of
degrees, {an}n∈ω, namely an ≤an+1, there exist upper bounds band c
which form an exact pair for the sequence.
Corollary 6.5.4. No inﬁnite strictly ascending sequence of degrees, i.e.,
an < an+1, has a least upper bound.
Corollary 6.5.5. There are degrees b and c with no greatest lower bound.
Before proving Theorem 6.5.3 we make some deﬁnitions and introduce
some new notation.
Deﬁnition 6.5.6. For any set A ⊆ω deﬁne the y-section of A,
(6.14)
A[y] = {⟨x, z⟩: ⟨x, z⟩∈A
&
z = y}
and
(6.15)
A[<y] =
[
{ A[z] : z < y }.
(Using the pairing function we can identify A with a subset of ω × ω and
view A[y] as the yth row of A. We use the square bracket notation A[y] to
distinguish from the yth jump A(y).)
Deﬁnition 6.5.7. (i) Given sets A and B, for every y the thickness
requirement for y states
(6.16)
Ty :
A[y] =∗B[y]
where X =∗Y denotes that (X −Y ) ∪(Y −X) is ﬁnite.
(ii) A subset A ⊆B is a thick subset of B, written A ⊆thick B, if Ty is
satisﬁed for all y.
Thick subsets will be very useful here and in later constructions of
c.e. sets and degrees, such as the thickness lemma and inﬁnite injury
constructions.
Deﬁnition 6.5.8. Partial functions θ, ψ are compatible, which we write as
compat(θ, ψ), if they have a common extension, i.e., if there is no x for which
θ(x) and ψ(x) are deﬁned and unequal. Otherwise, they are incompatible.

6.5. Upper and Lower Bounds for Degrees
143
Proof of Theorem 6.5.3.
Choose Ay ∈ay for each y and then deﬁne
A = {⟨x, y⟩: x ∈Ay}, so that ⟨x, y⟩∈A[y] iﬀx ∈Ay. We shall construct
characteristic functions f and g of sets B and C which are thick in A (so
that Ay ≡T B[y] ≤T B, and likewise for C). This ensures that b = deg(B)
and c = deg(C) are upper bounds for { an }n∈ω. For all y we must meet
the thickness requirements,
T B
y :
B[y] =∗A[y],
T C
y :
C[y] =∗A[y].
We must also meet, for all e and i, the exact pair requirements,
R⟨e,i⟩:
ΦB
e = ΦC
i
total
=⇒
(∃y) [ ΦB
e ≤T Ay ]
by looking for “e-splittings” as we did in proving Theorem 6.2.3.
Let σs, τs, Bs, and Cs be the portions of f, g, B, and C deﬁned by the
end of stage s of the following construction.
Stage s = 0. Set σ0 = τ0 = ∅.
Stage s + 1. Assume that σs and τs are deﬁned on ω[<s] and assume that:
(6.17)
(∀y < s) [ B[y]
s
=∗C[y]
s
=∗A[y] ];
and
(6.18)
(dom(σs) −ω[<s]) =∗∅=∗(dom(τs) −ω[<s]).
Step 1. (Satisfy R⟨e,i⟩for s = ⟨e, i⟩.) If
(∃σ) (∃τ) (∃x) (∃t) [ compat(σ, σs)
&
compat(τ, τs)
(6.19)
&
Φσ
e,t(x)↓̸= Φτ
i,t(x)↓],
then let σ and τ be the ﬁrst such strings and extend σs to bf = σs ∪σ
and τs to bg = τs ∪τ. Otherwise, let bf = σs, and bg = τs. Note that
σs ≡T A[<s] ≡T τs by (6.17) and (6.18). Hence, compat(σ, σs) is an A[<s]-
computable relation on σ. (Note that for s > 0, Step 1 requires an A′
s−1 ≡T
(A[<s])′ oracle.)
Step 2. (Satisfy T B
s and T C
s .)
Let σs+1 = bf on dom( bf). On all x ∈ω[s]−dom( bf) deﬁne σs+1(x) = A(x).
Let τs+1 = bg on dom(bg) and τs+1(x) = A(x) for all x ∈ω[s] −dom(bg). By
(6.18), σs (and hence bf) is already deﬁned on at most ﬁnitely many elements
of ω[s], and similarly for τs, so B[s]
s+1 =∗A[s] =∗C[s]
s+1, and f and g are now
deﬁned on ω[≤s]. This ends the construction.
If (6.19) holds, then ΦB
e ̸= ΦC
i . If (6.19) fails and ΦB
e = ΦC
i = h is total,
then for s = ⟨e, i⟩we shall show that h ≤T A[<s]. Notice that A[<s] ≤T As

144
6. Oracle Constructions and Forcing
because
A[<s] ≡T A[0] ⊕· · · ⊕A[s−1] ≡T A0 ⊕· · · ⊕As−1 ≤T As.
To A[<s]-computably determine h(x), ﬁnd the ﬁrst string σ in some enu-
meration of {σ : Φσ
e (x)↓} such that compat(σ, σs) and set h(x) = Φσ
e (x).
Now h(x) = Φf
e(x), or else for some σ′ ≺f, compat(σ′, σs) holds and
Φσ′
e (x)↓= y ̸= Φσ
e (x), so (6.19) holds for either σ or σ′ and for any τ ≺C
such that Φτ
i (x) converges.
6.5.1
Exercises
Exercise 6.5.9. Let the ω-jump A(ω) be deﬁned as in Deﬁnition 6.5.1.
Prove that if A ≡T B, then A(ω) ≡T B(ω). Hint. To show that B(ω) ≤T A(ω)
we must prove that Bn
≤T
A(ω) uniformly in n. Apply the Jump
Theorem 3.4.3 (vi) to show that B(n) ≡T A(n) uniformly in n.
Exercise 6.5.10. Show that the proof of Theorem 6.5.3 automatically
produces sets B and C computable in ⊕{ A′
y }y∈ω.
Exercise 6.5.11. Show that in the proof of Theorem 6.5.3 if B is any
upper bound for the Ay sets then we can modify Steps 1 and 2 to construct
C such that B and C satisfy the same requirements as before.
Exercise 6.5.12. Let I be a countable ideal contained in the Turing
degrees D. Prove that there exist degrees b, c such that for all a ∈D,
a ∈I
⇐⇒
[ a ≤b
&
a ≤c ].
We call b and c an exact pair for the ideal I as in Deﬁnition 6.5.2, and
“ideal” is deﬁned in the Notation section.
Exercise 6.5.13. ⋄(K. Lange). Fix an inﬁnite computable tree T ⊆2<ω.
Fix a set A = {An}n∈ω ⊆[ T ] of computable paths through T (not
necessarily closed) but dense in T in the sense that
(∀σ ∈T)(∃An ≻σ)[ An ∈A ].
For some degree d, a d-basis for A is a sequence of paths X = {Bn}n∈ω ⊆
[ T ] and a function f ≤T d such that ϕf(n) = Bn, i.e., d can uniformly com-
pute a ∆0-index for every path in A, viewed as a row in the d-computable
matrix B = ⊕nBn.
(i) If the set A of isolated paths of T is dense in T, prove that A has a
0′-basis.
(ii) Prove that if A has a 0′-basis X = {An}n∈ω, then there is a sequence
{Bn}n∈ω such that B = ⊕nBn is low and the collection of paths {Bn}n∈ω

6.5. Upper and Lower Bounds for Degrees
145
equals the collection of paths {An}n∈ω, although the sequences may not
be the same.
Hint for (ii).
Given a 0′-basis X = {An}n∈ω, use a 0′-construction to
build another basis Y = {Bn}n∈ω having the same rows {An} as X but
perhaps in a diﬀerent order. Simultaneously, force the jump of the matrix
B = ⊕nBn so that B is low. Search only through strings σ such that
(∀j ≤|σ|)[ σ[j] ∈T ], where σ[j](x) = σ(⟨x, j⟩). Now extend these σ[j] on
the B side by 0-eﬀectively choosing some row on the A side extending σ[j]
and ﬁlling this row in on the B side.
Remark 6.5.14. Note that if A ≤T ∅′ and S = A′ then S ≥T ∅′ and S
is c.e. in ∅′. Therefore, the jump map takes the degrees a ≤0′ into the
degrees c.e. in and above 0′. The next theorem proves that this map is
onto.
Exercise 6.5.15. ⋄(Shoenﬁeld Jump Inversion Theorem).
Fix S such
that ∅′ ≤T S and S is c.e. in ∅′, namely such that S is c.e. in and above
(c.e.a.) in ∅′. Construct A ≤T ∅′ such that A′ ≡T S. Hint. Deﬁne a
∅′-sequence {σs}s∈ω of {0, 1}-valued partial functions such that σs ⪯σs+1
and lims σs = χA. We ensure that S ≤T A′ by arranging that for all y,
limx A(⟨x, y⟩) = χS(y). We ensure A′ ≤T S by forcing the jump ΦA
e (e).
Fix a ∅′-computable enumeration { Ss }s∈ω of S such that |Ss+1 −Ss| = 1.
Let σ0 = ∅. The following is a ∅′-construction.
Stage s + 1. Assume that if y ∈Ss then σs(⟨x, y⟩) = 1 for almost every x,
and otherwise σs(⟨x, y⟩)↓for at most ﬁnitely many x and σs(⟨x, y⟩)↑for
all other x.
Step 1. Now σs+1 has a computable domain and is computable on its do-
main. Hence, we can ∅′-computably test for each e ≤s which has not yet
been forced in A′ whether
(∃t) (∃σ) [compat(σ, σs)
&
Φσ
e,t(e)↓
(6.20)
&
(∀y < e) (∀x) [ ⟨x, y⟩/∈dom(σs)
=⇒
σ(⟨x, y⟩) = 0 ] ].
If so, choose the least e and the least corresponding string σ. Deﬁne τs+1 =
σs ∪σ and say that e is forced into A′. Otherwise, deﬁne τs+1 = σs.
Step 2. Enumerate the next element z ∈Ss+1 −Ss. Deﬁne
σs+1(⟨x, y⟩) =







τs+1(⟨x, y⟩)
if ⟨x, y⟩∈dom(τs+1);
1
if y = z and ⟨x, y⟩/∈dom(τs+1);
0
if y /∈Ss+1, ⟨x, y⟩≤s, ⟨x, y⟩/∈dom(τs+1).
The last clause is to ensure that if y /∈S then limx A(⟨x, y⟩) = 0. To see
that A′ ≤T S, ﬁx e, assume that membership of i ∈A′ has been decided

146
6. Oracle Constructions and Forcing
for all i < e, and ﬁnd s such that Ss ↾e = S ↾e. Show that if e has not been
forced into A′ by stage s, then e ̸∈A′, i.e., it has been forced out of A′.

7
The Finite Injury Method
7.1
A Solution to Post’s Problem
A positive solution to Post’s problem was ﬁnally achieved by Friedberg in
[Friedberg 1957] and independently by Muchnik in [Muchnik 1956], who
built c.e. sets A and B of incomparable (Turing) degree. Friedberg then
produced other results on c.e. sets in [Friedberg 1957b], [Friedberg 1957c]
and [Friedberg 1958].
7.1.1
The Intuition Behind Finite Injury
To achieve this we must meet requirements similar to those in Chapter 6,
such as Re : ΦB
e ̸= A, in Kleene-Post Theorem line (6.1). However, we use
a computable construction rather than the oracle constructions which were
used in Chapter 6 to build A = ∪s σs for σs ≺σs+1. If we build A by ﬁnite
extensions in a computable construction, then A must be computable and
therefore not interesting. Hence, we now build A = ∪s As as a computably
enumerable set: a computable union of ﬁnite sets {As}s∈ω.
This presents a new diﬃculty. In Chapter 6 we normally met a require-
ment like Re by ﬁnding a string ρ ∈Ve (which was a certain c.e. set of
strings associated with Re), and then by extending σs to some σs+1 ≻ρ,
thereby satisfying Re forever. Here we also meet Re (at least temporar-
ily) by enumerating elements into A so that As+1 ≻ρ. Unlike the oracle
construction in Kleene-Post Theorem 6.1.1, this does not guarantee that
ρ ≺A because new elements x < |ρ| may later enter A.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_  
147 
7

148
7. The Finite Injury Method
Therefore, to ensure At ≻ρ for all t > s, we must prevent 0’s in the
characteristic function of As+1 from later changing to 1’s. Hence, we issue
a restraint function r(e, s + 1) which with priority Re prevents any lower
priority requirement Ri, i > e, from enumerating any x ≤r(e, s + 1) into
A. If this restraint is successful, then ρ ≺A and Re is satisﬁed at the end.
However, the requirements {Ri}i<e have higher priority than Re, and can
override the restraint r(e, s+1) in an eﬀort to satisfy their own conditions.
If this happens at stage s + 1 we say Re is injured at stage s + 1 and Re
begins anew to satisfy its condition at later stages. This injury may arise
because some higher priority requirement R0 is slow to act. Meanwhile, Re
has acted and has built a wall of restraint to defend its action. Only then
does R0 act, injuring any restraint by Re. We must allow R0 to act and
injure Re or else R0 may never be satisﬁed.
The solution is the Golden Rule: every requirement Re treats the weaker
requirements {Rj}j>e as it itself wants to be treated by the higher priority
requirements {Ri}i<e. For this chapter on ﬁnite injury this means that
Re acts at most ﬁnitely often to injure any lower priority requirement Rj,
j > e. By the Golden Rule the higher priority requirements {Ri}i<e injure
Re at most ﬁnitely often and Re is satisﬁed.
7.1.2
The Injury Set for Requirement Ne
Deﬁnition 7.1.1. Let {As}s∈ω be a computable enumeration of a c.e.
set A and r(e, s) be a computable function representing the restraint for
a future requirement such as Re : ΦA
e ̸= B, as in (7.6) or Ne : ΦA
e ̸= C,
as in (7.8). We shall see that the requirement wishes to restrain elements
x ≤r(e, s) from entering A at stage s + 1. We say that element x injures
the requirement associated with r(e, s) at stage s + 1 if x ∈As+1 −As and
x ≤r(e, s). Deﬁne the injury set,
(7.1)
Ie = { x : (∃s) [ x ∈As+1 −As
&
x ≤r(e, s) ] }.
Remark 7.1.2. In the three sections §7.2, §7.3, and §7.5 we give three
diﬀerent results, each of which yields a solution to Post’s problem, and
each of which uses a diﬀerent kind of ﬁnite injury priority argument. Each
of the three methods is fundamental and will be essential for results in
later chapters. The three methods are in ascending order with respect to
technical complexity because if |Ie| is the number of times that requirement
Re is injured then |Ie| ≤e in §7.2, |Ie| < 2e in §7.3, and |Ie| is ﬁnite, but
not even computably bounded, in §7.5. In Chapter 8 we shall have inﬁnite
injury with the injury set Ie inﬁnite.

7.2.
⋆Low Simple Sets
149
7.2
⋆Low Simple Sets
Probably the easiest solution to Post’s problem is the construction of a low
simple set A. Simplicity guarantees that A is c.e. and noncomputable while
the lowness of A, i.e., A′ ≡T ∅′, guarantees incompleteness, i.e., A <T ∅′.
Furthermore, in this construction the requirements may be separated into
the positive requirements Pe, which attempt to put elements into A, and
the negative requirements Ne, which attempt to keep elements out of A.
Low sets and degrees were studied in §4.4.2. They have several pleasant
structural properties which will be explored later.
7.2.1
The Requirements for a Low Simple Set A
Theorem 7.2.1. There is a simple set A which is low (A′ ≡T ∅′).
Corollary 7.2.2. There is a noncomputable c.e. set A which is incomplete,
i.e., ∅<T A <T ∅′.
Proof of Theorem 7.2.1. Construct A c.e. to meet for all e the requirements:
(simplicity)
Pe :
| We | = ∞
=⇒
We ∩A ̸= ∅;
(lowness)
Ne :
(∃∞s) [ ΦAs
e,s(e)↓]
=⇒
ΦA
e (e)↓;
(A
inﬁnite)
Ce :
ae = lims as
e exists,
where As consists of the elements enumerated in A by the end of stage
s, A = ∪sAs, As = {as
0 < as
1 < · · · }, and A = {a0 < a1 < · · · },
as in the canonical simple set construction in Theorem 5.2.5, which this
Theorem 7.2.1 generalizes. (The expression (∃∞x)R(x) was deﬁned in
Deﬁnition 3.5.1.)
The priority ranking of the requirements is {Ne ≺Ce ≺Pe}e∈ω, meaning
that Ne has higher priority than Ce, which has higher priority than Pe,
which has higher priority than Ne+1, and so on. Requirements Ne and Ce
are both negative, tending to restrain elements out of A, and thus there
is no conﬂict between them, but Pe is a positive requirement, tending to
enumerate elements into A, and must respect any restraint imposed by Ni
or Ci for all i ≤e. Note that the requirements {Ne}e∈ω guarantee A′ ≤T ∅′
as follows.

150
7. The Finite Injury Method
7.2.2
A Computable bg(e, s) with g(e) = lims bg(e, s) = A′(e)
Deﬁne the computable function bg(e, s) by
bg(e, s) :=



1
if
ΦAs
e,s(e)↓;
0
otherwise.
If requirement Ne is satisﬁed for all e, then g(e) = lims bg(e, s) exists for
all e. But g ≤T ∅′ by the Limit Lemma 3.6.2, and g is the characteristic
function of A′. Therefore, A′ ≤T g ≤T ∅′.
Recall from Deﬁnition 3.2.2 that the use function ϕAs
e,s(x) is the maximum
element used in the computation ΦAs
e,s(x) if the latter converges, and is 0
otherwise. To aid in meeting Ne, given As, deﬁne for all e the restraint
function,
(7.2)
r(e, s) := ϕAs
e,s(e).
Now r(e, s) is a computable function because {As}s∈ω is a computable
sequence. To meet Ne we attempt to restrain with priority Ne any elements
x ≤r(e, s) from entering As+1. The point is that if ΦAs
e,s(e) ↓, with r =
ϕAs
e,s(e), and Ne succeeds in preventing any x ≤r from later entering A,
then A ↾↾r = As ↾↾r and hence ΦA
e (e) ↓. Thus, such elements can only
enter A for the sake of some Pi of higher priority (namely i < e). The
requirement Ce restrains all elements {as
j}j≤e from entering As+1, unless
they are enumerated by a higher priority requirement Pi, i < e, exactly as
in the Canonical Simple Set Theorem 5.2.5.
7.2.3
The Construction of a Low Simple Set A
Stage s = 0. Let A0 = ∅.
Stage s + 1. Given As, let As = {as
0 < as
1 < . . .} and compute r(e, s) for
all e. Choose the least i ≤s such that
(7.3)
Wi,s ∩As = ∅;
and
(7.4)
(∃x) [ x ∈Wi,s
&
x > as
i
&
(∀e ≤i) [ r(e, s) < x ] ].
(The ﬁrst clause of (7.4) says x is useful for Pi because x ∈Wi,s. The
second clause says x is not restrained by any requirement Ce, e ≤i, because
x > as
e. The third clause says that x is not restrained by any requirement
Ne, e ≤i.) If i exists, choose the least x satisfying (7.4). Enumerate x in
As+1, and say that requirement Pi receives attention. Hence, Wi,s∩As+1 ̸=
∅, Pi is satisﬁed, and (7.3) fails for stages > s+1. Therefore, Pi never again

7.2.
⋆Low Simple Sets
151
receives attention. If i does not exist, do nothing, and deﬁne As+1 = As.
Let A = ∪sAs. This ends the construction.
7.2.4
The Veriﬁcation of a Low Simple Set A
Lemma 7.2.3. Deﬁne the injury set Ie as in (7.1). For all e,
(i) The injury set Ie is ﬁnite. (That is, Ne is injured ﬁnitely often.)
(ii) ae = lims as
e exists. ( Ce is injured ﬁnitely often.) Hence, |A| = ∞.
Proof. Each positive requirement Pi contributes at most one element to
A by (7.3). But by the second and third clauses of (7.4), Ce and Ne can
be injured by Pi only if i < e, and at most once for each such i. Hence,
|Ie| ≤e, and likewise for requirement Ce.
Lemma 7.2.4. (∀e) [requirement Ne is met
&
r(e) := lims r(e, s) exists ].
Proof. Fix e. By Lemma 7.2.3, choose stage se such that Ne is not injured
at any stage s > se. If ΦAs
e,s(e) converges for s > se, then by induction
on t ≥s,
r(e, t) = r(e, s) and ΦAt
e,t(e) = ΦAs
e,s(e) for all t ≥s. Hence,
As ↾↾r = A ↾↾r for r = r(e, s). Therefore, ΦA
e (e) is deﬁned by the Use
Principle Theorem 3.3.9.
Lemma 7.2.5. (∀i) [requirement Pi is met ].
Proof. Fix i such that Wi is inﬁnite. By Lemma 7.2.4, choose s such that
(∀t ≥s)(∀e ≤i) [ r(e, t) = r(e)
&
ae = at
e ].
Choose s′ ≥s such that no Pj, j < i, receives attention after stage s′.
Choose t > s′ such that
(∃x) [ x ∈Wi,t
&
x > ai
&
(∀e ≤i)[ r(e) < x ] ].
Now either Wi,t∩At ̸= ∅or else Pi receives attention at stage t+1. In either
case, Wi,t ∩At+1 ̸= ∅. Therefore, Pi is met by the end of stage t + 1.
7.2.5
The Restraint Functions r(e, s) as Walls
In this and later constructions one should think of r(e, s) as a wall imposed
by Ne, extending from 0 to r(e, s). For ﬁxed e the wall r(e, s) is not mono-
tonically increasing in s because after a wall r(e, s) is erected, penetration
of that wall by some x injuring Ne may cause ΦAs+1
e,s+1(e)↑so that the wall
drops to 0. If Pi wishes to contribute some element x to A, then x must
lie beyond all walls r(e, s), e ≤i. The crucial feature of all ﬁnite injury
constructions is that each wall is penetrated (injured) ﬁnitely often and
therefore comes to a limit. But then each positive requirement is satisﬁed
because it merely chooses a witness beyond all walls of higher priority.

152
7. The Finite Injury Method
7.2.6
Exercises
Exercise 7.2.6. In the proof of Theorem 7.2.1, replace the requirements
Pe by the requirements of Exercise 5.3.9 to give a direct construction of a
low hypersimple set.
Exercise 7.2.7. Combine the method of Theorem 7.2.1 with the permit-
ting method of Theorem 5.2.7 to prove that for any noncomputable c.e. set
A there is a low simple (indeed, low hypersimple) set B ≤ibT A.
7.3
⋆The Friedberg-Muchnik Theorem
The Friedberg-Muchnik Theorem states that there exist c.e. sets A and B
of incomparable degree. Its proof is the canonical ﬁnite injury theorem,
not only because it was the ﬁrst example of a ﬁnite injury proof, but also
because the injury pattern is the most typical. The injury pattern is a bit
more complex than that of the low simple set of Theorem 7.2.1, where
the injury set Ie satisﬁes |Ie| ≤e, but not as complex as the unbounded
injury pattern in the Sacks Splitting Theorem 7.5.1, where we have merely
|Ie| < ∞. Here we have |Ie| < 2e, which is typical of these arguments.
Theorem 7.3.1 (Friedberg, 1957; Muchnik, 1956).
There exist c.e. sets
A and B of incomparable Turing degree.
7.3.1
Renumbering the Requirements
Convention 7.3.2 (Indexing Convention).
From now on we assume that
for every Turing reduction Φe there are inﬁnitely many even indices i and
odd indices j such that Φi = Φe = Φj. We also assume that ϕe has been
deﬁned by ϕe := Φ∅
e, so the same holds for the p.c. functions ϕe.
Proof. Hence, to satisfy all the incomparability requirements it suﬃces to
satisfy merely all even requirements for ΦB
e and all odd requirements for ΦA
e .
(This enables us to have the subscript of Re match that of Φe, which makes
the proof more perspicuous than having R2e : A ̸= ΦB
e .) We construct c.e.
sets A and B to meet the same requirements as in (6.1) of the Kleene-Post
theorem,
(7.5)
Re :
A ̸= ΦB
e
for e even,
(7.6)
Re :
B ̸= ΦA
e
for e odd.
We say that requirement Ri has higher priority than Rj if i < j. We ﬁrst
present the basic module or atomic strategy for meeting a single requirement
Re and then explain how to combine these strategies.

7.3.
⋆The Friedberg-Muchnik Theorem
153
7.3.2
The Basic Module to Meet Re for e Even
Select an integer x not yet in A. Wait for s such that ΦBs↾u
e,s
(x)↓= 0, which
must happen if ΦB
e = A. (Now u < s by Deﬁnition 3.2.2 (iii).)
Action. At stage s + 1 enumerate x in A, and deﬁne a restraint function
r(e, s + 1) = s + 1 which prevents lower priority requirements Rj, j >
e, from enumerating any z ≤r(e, s + 1) into B. If the higher priority
requirements Ri, i < e, have ﬁnished acting by stage s then the restraint
function r(e, s + 1) ensures that B ↾↾s = Bs ↾↾s so that
ΦB
e (x)↓= 0
̸=
1 = A(x)
and requirement Re is met. If some Ri, i < e, acts at some stage t > s + 1,
then we reset the Re basic module with a fresh witness x′ and begin all
over. On the other hand r(e, s) = 0 indicates that requirement Re is not
currently satisﬁed and may need to be satisﬁed again if the opportunity
arises.
7.3.3
The Full Construction
We now combine all the strategies as follows. Let ω[y] = {⟨x, y⟩: x ∈ω}.
To avoid conﬂict between requirements, we choose witnesses x ∈ω[e] to
meet Re. For every e we set the restraint function r(e, s) = 0 for s = 0.
We later reset r(e, s + 1) = 0 if Re is injured at stage s + 1. Therefore,
r(e, s) > 0 indicates that Re has been satisﬁed at some stage t ≤s and not
injured since then. On the other hand, r(e, s) = 0 indicates that Re has
either never been satisﬁed, or satisﬁed, injured, and never satisﬁed since
then until now.
Stage s = 0. Deﬁne r(e, 0) = 0 for all e.
Stage s + 1 even. Choose the least even e such that
r(e, s) = 0
&
(7.7)
(∃x)[ x ∈ω[e] −As
&
ΦBs
e,s(x)↓= 0
&
(∀i < e)[ r(i, s) < x ] ].
Action.
If there is no such e, then do nothing and go to stage s + 2.
Otherwise, choose the least such e and the least corresponding x. We say
Re acts at stage s + 1. Perform the following steps.
Step 1. Enumerate x in A. (This makes As+1(x) = 1.)
Step 2.
Deﬁne r(e, s + 1) = s + 1. (This attempts to restrain Bs ↾↾s in
order to preserve the computation ΦBs
e,s(x)↓= 0 ̸= 1 = As+1(x).)
Step 3.
For all j > e, deﬁne r(j, s + 1)
=
0. We say that these lower
priority requirements {Rj}j>e are injured at s + 1 and are reset.

154
7. The Finite Injury Method
Step 4.
For all i < e deﬁne r(i, s + 1) = r(i, s). (This leaves the pre-
vious action performed by these higher priority requirements {Ri}i<e
untouched.)
Stage s+1 odd. Do the same for odd e with the roles of A and B reversed.
7.3.4
The Veriﬁcation
Lemma 7.3.3. If requirement Re acts at some stage s + 1 and is never
later injured, then requirement Re is met and r(e, t) = s+1 for all t ≥s+1.
Proof. Suppose Re acts at stage s + 1 and e is even. Then ΦBs
e (x)↓= 0 for
some x ∈As+1. Since no Ri, i < e, ever acts after stage s + 1, it follows
by induction on t > s that Re never acts again and r(e, t) = s + 1 for all
t > s. Hence, no Rj, j > e, enumerates any x ≤s into B after stage s + 1.
Therefore, B ↾↾s = Bs ↾↾s and ΦB
e (x)↓= 0 ̸= A(x).
Lemma 7.3.4. For every e, requirement Re is met, acts at most ﬁnitely
often, and r(e) = lims r(e, s) exists.
Proof. Fix e and assume true for all Ri, i < e. Let v be the greatest stage at
which some such Ri acts, if ever, and v = 0 if none exists. Then r(e, v) = 0
and this will persist until some stage s + 1 > v, if ever, when Re acts. If
Re acts at some stage s + 1 then by Lemma 7.3.3 that action satisﬁes Re,
which never acts again, and r(e, t) = s + 1 for all t ≥s + 1.
Either way, r(e) exists and Re acts at most ﬁnitely often. Now suppose
that Re is not met. Then ΦB
e = A. Now by stage v at most ﬁnitely many
elements x ∈ω[e] have been enumerated in A. Choose the least x ∈ω[e]−Av
such that x > v. Eventually, there will be a stage s such that ΦBs
e,s(x)↓= 0
since x /∈As. Hence, Re acts at stage s+1, and by Lemma 7.3.3 this action
satisﬁes Re forever.
This completes the proof of the Friedberg-Muchnik Theorem 7.3.1
Proposition 7.3.5. Deﬁne the injury set Ie as in (7.1) for A and e even
and similarly for B in place of A for e odd. Then in Theorem 7.3.1 we have
|Ie| < 2e.
Proof. Deﬁne fs(i) = 1 if r(i, s) > 0 and fs(i) = 0 otherwise. If Re is
injured at stage s + 1 it is only because Ri acts for some i < e. Therefore,
fs(i) = 0 and fs+1(i) = 1, causing f to increase lexicograpically at stage
s + 1 on the initial segment [0, e −1]. However, fs ↾e is a binary string of
exactly e bits and can increase lexicographically at most 2e −1 times.
7.3.5
Exercises
Exercise 7.3.6. (i) Show that there is a u.c.e. sequence of c.e. sets {Ai}i∈ω
such that for every i, Ai ̸≤T ⊕{Aj}j̸=i. Hint. Modify the construction of

7.3.
⋆The Friedberg-Muchnik Theorem
155
the Friedberg-Muchnik Theorem 7.3.1 to meet the requirements R⟨e,i⟩of
Exercise 6.1.4.
(ii) Show that any countable partially ordered set can be embedded in
the c.e. degrees (C, ≤) by an order-preserving map. (See the hint for
Exercise 6.1.6.)
Exercise 7.3.7. (Cooper-Epstein-Lachlan). Construct a pair of c.e. sets
A and B such that the d.c.e. set D = A −B does not have c.e. degree.
Hint. For each e, i, j meet the requirement
R⟨e,i,j⟩:
D ̸= ΦWe
i
∨
We ̸= ΦD
j .
To meet a single R⟨e,i,j⟩choose x not yet in A or B and wait for a stage s
such that
0 = ΦWe,s↾↾u
i,s
(x)
&
We,s ↾↾u = ΦDs↾↾v
j,s
↾↾u
for some u and v, where Ds = As −Bs. Now enumerate x in As+1 and
restrain D from changing on any other elements ≤v. We win R⟨e,i,j⟩by
the ﬁrst clause unless there is some stage t ≥s + 1 and y < u such that
y ∈We,t−We,s. In this case we enumerate x in Bt so that Dt ↾↾v = Ds ↾↾v
and ΦDt↾↾v
j,t
(y) = We,s(y) ̸= We,t(y).
Exercise 7.3.8. A set A is autoreducible if there is an e such that for all
x, A(x) = ΦA−{ x }
e
(x). (The idea is that Φe determines whether x ∈A by
using oracle questions “y ∈A?” only for x ̸= y.)
(i)
Construct a c.e. set A which is not autoreducible. Hint. For each e
choose a witness x, and attempt to meet A(x) ̸= ΦA−{ x }
e
(x) by waiting for
ΦAs−{ x }
e,s
(x) ↓= y for some s, then (1) enumerating x in A iﬀy = 0; and
(2) attempting to restrain elements z ≤ϕAs
e (x, s) from entering A.
(ii) For any noncomputable c.e. set B construct a c.e. set A ≤T B such
that A is not autoreducible. (Ladner has shown that one cannot achieve
A ≡T B because he proved that A is autoreducible iﬀA is mitotic, namely
A is the disjoint union of c.e. sets A0 and A1 such that A ≡T A0 ≡T A1,
and that there is a nonzero c.e. degree containing only mitotic c.e. sets.)
Exercise 7.3.9. Recall the deﬁnitions of ≤tt, ≤bT and ≤ibT from Chap-
ter 5. Note that if A0 and A1 are disjoint c.e. sets, then Ai ≤ibT A0 ∪A1
for i = 0, 1. Use a priority argument to construct disjoint c.e. sets A0 and
A1 such that Ai ̸≤tt A0 ∪A1, i = 0, 1. Hint. Pick a witness x to meet the
requirement that Ai ̸≤tt A0 ∪A1 via the eth tt-reduction; wait until the
latter converges on A0,s ∪A1,s ∪{ x }, and put x into A0 or A1 to achieve
a disagreement.
Exercise 7.3.10. Combine the permitting method with the Friedberg-
Muchnik construction of Theorem 7.3.1 to show that for any noncom-
putable c.e. set C there exist Turing incomparable c.e. sets A, B ≤T
C.

156
7. The Finite Injury Method
7.4
⋆Preservation Strategy to Avoid Upper Cones
In the Friedberg-Muchnik Theorem 7.3.1 we satisﬁed an incomparability
requirement A ̸= ΦB
e by enumerating an element x into A and simulta-
neously preserving B ↾↾ϕB
e (x). Here we are given a noncomputable c.e.
set C and we must construct a noncomputable c.e. set A ̸≥T C. In the
noneﬀective case of building A such that B ̸= ΦA
e using an oracle in Theo-
rem 6.2.6, we searched for e-splittings to meet requirement Re : A ̸= ΦB
e . If
we found none, we claimed that ΦA
e , if total, was computable. Here we adopt
an apparently more passive approach of preserving agreements between C
and ΦA
e with the intention that if these agreements are suﬃciently well
preserved and if C = ΦA
e , then C is computable, contrary to hypothesis.
Theorem 7.4.1 (Cone Avoidance Theorem, Sacks).
For every noncomputable c.e. set C there is a simple set A such that
C ̸≤T A (and hence ∅<T A <T ∅′).
7.4.1
The Notation
It clearly suﬃces to construct A to be coinﬁnite and to satisfy, for all e,
the requirements:
(7.8)
Ne :
ΦA
e
̸= C;
(7.9)
Pe :
We inﬁnite
=⇒
We ∩A ̸= ∅.
Let { Cs }s∈ω be a computable enumeration of C. We shall give a com-
putable enumeration {As}s∈ω of A. Given {Ct}t≤s and {At}t≤s, deﬁne for
all e the following length function ℓ(e, s), restraint function r(e, s), and the
combined restraint function R(e.s).
(7.10)
ℓ(e, s) := max{ x : (∀y < x) [ ΦA
e (y)[s]↓= Cs(y) ] };
(7.11)
r(e, s) := max{ ϕA
e (x)[s] : x ≤ℓ(e, s) };
(7.12)
R(e, s) := max{ r(i, s) : i ≤e }.
Deﬁne the injury set Ie as in (7.1). If x ≤r(e, s) and x ∈As+1 −
As then x represents an injury to requirement Ne at stage s + 1. As in
Lemma 7.2.4, note that each Ie is ﬁnite (indeed, |Ie| ≤e) because Ne is
injured at most once by each Pi, i < e, whereupon Pi is satisﬁed forever
as in Theorem 7.2.1.
7.4.2
The Basic Module for Requirement Ne
Requirement Ne restrains with priority Ne any x ≤r(e, s) from entering
As+1 −As.

7.4.
⋆Preservation Strategy to Avoid Upper Cones
157
Lemma 7.4.2. If Ne is injured at most ﬁnitely often then ΦA
e
̸= C.
Proof. Assume for a contradiction that ΦA
e = C. Then lims ℓ(e, s) = ∞.
Choose s′ such that Ne is never injured after stage s′. We shall deﬁne a
computable function ge such that ge(x) = C(x), contrary to hypothesis. To
compute ge(p) for some p ∈ω ﬁnd the least s > s′ such that ℓ(e, s) > p. It
follows by induction on t ≥s that
(7.13)
(∀t ≥s) [ l(e, t) > p
&
r(e, t) ≥max{ ϕ(As; e, x, s) : x ≤p } ],
and hence that ΦAs
e,s(p) = ΦAs
e (p) = ΦA
e (p) = C(p), whence C is com-
putable. To prove (7.13), assume it holds for t. Then r(e, t) and s > s′
ensure that At+1 ↾↾z = At ↾↾z for all numbers z used in a computa-
tion ΦAt
e,t(x) = y for any x ≤p. Thus, ΦAt+1
e,t+1(x) = y, so l(e, t + 1) > p,
unless Ct+1(x) ̸= Ct(x) for some x < ℓ(e, t). But if Ct(x) ̸= Cs(x) for
some t ≥s and x ≤p, where x is minimal, then our use of “≤ℓ(e, t)”
rather than “< ℓ(e, t)” in the deﬁnition of r(e, t) ensures that the disagree-
ment Ct(x) ̸= ΦAt
e,t(x) is preserved forever, contrary to our hypothesis that
C = ΦA
e .
(Note that even though the Sacks strategy is always described as one
which preserves agreements, it is crucial that we preserve at least one dis-
agreement as well whenever possible. The reason that the disagreement is
preserved is that C is c.e. and therefore the approximation Cs(x) can only
change from 0 to 1 and never back again. See Theorem 7.6.1 to extend this
analysis to the case where C is ∆2 in place of C c.e.)
Lemma 7.4.3. If Ne is injured at most ﬁnitely often, and C ̸= ΦA
e , then
lims r(e, s) < ∞.
Proof. By Lemma 7.4.2, choose p = (µx) [ C(x) ̸= ΦA
e (x) ]. Choose s′
suﬃciently large such that for all s ≥s′,
(1) (∀x < p) [ ΦAs
e,s(x)↓= ΦA
e (x) ];
(2) (∀x ≤p) [ Cs(x) = C(x) ]; and
(3) Ne is not injured at stage s.
Case 1. (∀s ≥s′) [ ΦAs
e,s(p)↑]. Then r(e, s) = r(e, s′) for all s ≥s′.
Case 2. ΦAt
e,t(p) ↓for some t ≥s′. Then ΦAs
e,s(p) = ΦAt
e,t(p) for all s ≥t
because ℓ(e, s) ≥p, and so, by the deﬁnition of r(e, s), and the fact that
Ne is not injured after stage t, the computation ΦAt
e,t(p) is preserved forever.
Thus, ΦA
e (p) = ΦAs
e,s(p). But C(p) ̸= ΦA
e (p). Hence,
(∀s ≥t) [ Cs(p) ̸= ΦAs
e,s(p)
&
ℓ(e, s) = p
&
r(e, s) = r(e, t) ].
Therefore, r(e, t) = lims r(e, s) = r(e).

158
7. The Finite Injury Method
7.4.3
The Construction of A
Stage s = 0. Deﬁne A0 = ∅.
Stage s + 1. Given As, deﬁne ℓ(e, s) and r(e, s) as above for all e. We say
Pi requires attention at stage s + 1 if i ≤s, Wi,s ∩As = ∅, and
(7.14)
(∃x) [ x ∈Wi,s
&
x > 2i
&
(∀e ≤i) [ r(e, s) < x ] ].
(If x exists, then x < s by Deﬁnition 1.6.17. Therefore, (7.14) is a
computable condition.) If i exists, choose the least such i and the least
corresponding x and enumerate x in As+1. We say Pi receives attention
(acts) at stage s + 1.
7.4.4
The Veriﬁcation
Lemma 7.4.4. For every e, Ne is met and r(e)
:=
lims r(e, s) < ∞
exists.
Proof. Every positive requirement Pi acts at most once. Hence Ne can be
injured at most e times. Apply Lemma 7.4.2 and Lemma 7.4.3.
Lemma 7.4.5. (∀e) [ We inﬁnite
=⇒
We ∩A ̸= ∅].
Proof. By Lemma 7.4.4, deﬁne r(i) := lims r(i, s) for i ≤e, and deﬁne
R(e) := max{ r(i) : i ≤e }. Now if
(∃x) [ x ∈We
&
x > 2e
&
x > R(e) ],
then We ∩A ̸= ∅. Note that A is inﬁnite by the clause “x > 2e” in (7.14)
and hence A is simple.
7.5
Sacks Splitting Theorem
Shortly after proving Theorem 7.3.1, Friedberg [1958a] proved the Fried-
berg Splitting Theorem 2.7.1, stating that any c.e. set B >T ∅could be
split as the disjoint union of noncomputable c.e. sets A0 and A1. Sacks
[1963b] then generalized these two Friedberg theorems simultaneously by
showing that A0 and A1 could be chosen to be not merely noncomputable
but even Turing incomparable. Furthermore, they can both be chosen not
to be in the cone above a given noncomputable C. To accomplish this Sacks
used the method in the preceding section to avoid an upper cone.
Theorem 7.5.1 (Sacks Splitting Theorem, Sacks, 1963b).
Let B and C
be c.e. sets such that C is noncomputable. Then there exist low c.e. sets A0
and A1 such that:

7.5. Sacks Splitting Theorem
159
(i) A0 ⊔A1 = B and
(ii) C ̸≤T Ai, for i = 0, 1.
Proposition 7.5.2. If the c.e. set B is the disjoint union of c.e. sets A0
and A1 then B ≡T A0 ⊕A1.
Proof. First, note that Ai ≤T B for i = 0, 1. Hence, A0 ⊕A1 ≤T B because
to decide whether x ∈Ai, ﬁrst ask whether x ∈B. If so, enumerate A0
and A1 until x appears in one of them. In the other direction, obviously
B ≤T A0 ⊕A1.
Corollary 7.5.3. If b is any nonzero c.e. degree, there are incomparable
low c.e. degrees a0 and a1 such that b = a0 ∪a1.
Proof. Choose a c.e. set B ∈b. Apply the Sacks Splitting Theorem 7.5.1
to B with C = B to obtain A0 and A1. Hence, A0, A1 <T B. By Propo-
sition 7.5.2, B ≡T A0 ⊕A1. Now A0 and A1 cannot have comparable
degree because if, say, A0 ≤T A1 then A1 ≡T B. Let a0 = deg(A0) and
a1 = deg(A1).
Corollary 7.5.4. The low c.e. degrees generate the c.e. degrees when closed
under join.
Corollary 7.5.5. No c.e. degree is minimal.
Corollary 7.5.6. For any c.e. degree c, 0 < c < 0′, there is a c.e. degree
incomparable with c.
Proof. Let B = K, let C ∈c be c.e., and apply the Sacks Splitting The-
orem 7.5.1. One of A0, and A1 must have degree incomparable with c, or
else A0 ≤T C and A1 ≤T C. Hence, K ≤T C, contrary to C <T ∅′.
Note that in Corollary 7.5.6 we do not produce A incomparable with C
uniformly in C but merely give a pair A0, A1 of which one succeeds. Later
we shall be able to ﬁnd A uniformly from C.
Proof of Theorem 7.5.1.
(We may assume that B is inﬁnite, or else the
result is trivial. This, however, does not aﬀect the uniformity of A0 and A1
from B and C.) Let {Bs}s∈ω and {Cs}s∈ω be computable enumerations of
B and C such that B0 = ∅and |Bs+1 −Bs| = 1 for all s. We shall give
computable enumerations {Ai,s}s∈ω, i = 0, 1, satisfying the single positive
requirement
P :
x ∈Bs+1 −Bs
=⇒
[ x ∈A0,s+1 ∨x ∈A1,s+1 ],
and the negative requirements for i = 0, 1, and all e,
N⟨e,i⟩:
C ̸= ΦAi
e .
(The lowness of Ai will follow from the strategy to achieve the N⟨e,i⟩
requirements, because the restraint function ri(e, s) exists and is ﬁnite.)

160
7. The Finite Injury Method
Stage s = 0. Deﬁne Ai,0 = ∅, i = 0, 1.
Stage s+1. Given Ai,s, deﬁne the computable functions li(e, s) and ri(e, s)
as in the proof of the Avoiding Cone Theorem 7.4.1 but with Ai,s in place
of As. Let x ∈Bs+1 −Bs. Choose ⟨e′, i′⟩to be the least ⟨e, i⟩such that
x ≤ri(e, s), and enumerate x in A1−i′, s+1. (Namely, choose the highest
priority requirement N⟨e′,i′⟩which would be injured by enumerating x in
Ai′, and enumerate x on the “other side” A1−i′.) If ⟨e′, i′⟩fails to exist,
enumerate x into A0.
To see that the construction succeeds, deﬁne the injury set I i
e as in the
proof of the Avoiding Cone Theorem 7.4.1 but with Ai in place of A. It
follows by induction on ⟨e, i⟩that for i = 0, 1, and all e,
(1) I i
e is ﬁnite;
(2) C ̸= ΦAi
e ; and
(3) ri(e) := lims ri(e, s) exists and is ﬁnite.
Namely, ﬁx ⟨e, i⟩and assume (1), (2), and (3) hold for all ⟨k, j⟩< ⟨e, i⟩. By
(3), choose t such that rj(k, s) = rj(k) for all ⟨k, j⟩< ⟨e, i⟩and all s ≥t.
Choose r greater than all such rj(k). Choose v > t with B ↾r = Bv ↾r.
Now N⟨e,i⟩is never injured after stage v, so (1) holds for ⟨e, i⟩. Now (2)
and (3) hold for ⟨e, i⟩exactly as in the Avoiding Cone Theorem 7.4.1 and
Lemmas 7.4.2, and 7.4.3.
Lemma 7.5.7. A0 and A1 are both low.
Proof. To see that each Ai is low, deﬁne the computable function g as
follows:
ΦX
g(e)(y) =



C(0)
if y = 0
&
ΦX
e (e)↓;
undeﬁned
otherwise.
Note that for i = 0, 1,
e ∈A′
i ⇐⇒ΦAi
e (e)↓⇐⇒ΦAi
g(e)(0) = C(0) ⇐⇒lims l i(g(e), s) > 0,
so A′
i ∈∆0
2 because li and g are computable functions, and lims li(g(e), s)
exists, and hence A′
i ≤T ∅′.
This completes the proof of the Sacks Cone Avoidance Theorem 7.5.1.
Note that the injury set I i
e , although ﬁnite, has no obvious bounding
function as in §7.2 and §7.3. Indeed, in general there is no computable
function g such that | I i
e | ≤g(i, e).

7.6. Avoiding the Cone Above a ∆2 Set C >T 0
161
7.6
Avoiding the Cone Above a ∆2 Set C >T 0
Now suppose that C is not c.e. as in §7.4 but rather is ∆2. Let C = lims Cs
for a computable sequence {Cs}s∈ω. We might begin by deﬁning ℓ(e, s)
and r(e, s) as in §7.4.1, with the same basic module for Ne. The diﬃculty
is that Lemma 7.4.2 no longer holds. Suppose that Ne is never injured and
restrains every x ≤r(e, s) from entering A at stage s+1. When ℓ(e, s) > p,
we deﬁne ge(p) = ΦA
e (p)[ s ] = q. Later, C may change, causing ℓ(e, t) < p
for some t > s which causes r(e, t) < r(e, s), and may allow elements to
enter A, thus destroying the A-computation ΦA
e (p)[ s ] = q. Now both C and
ΦA
e may later take a diﬀerent value q′ = ΦA
e (p)[ t ] = C(p) ̸= q. The result
is that ΦA
e = C but ge ̸= C, and we cannot claim that C is computable.
The solution is to deﬁne a stronger length of agreement function.
(7.15)
(maximum length function)
max(e, s) := max{ ℓ(e, t) : t ≤s }.
Theorem 7.6.1 (∆2-Avoiding Cone Theorem). For every noncomputable
∆0
2 set C there is a simple set A such that C ̸≤T A.
Proof. Let C = lims Cs for a computable sequence {Cs}s∈ω. Let Ne and
Pe be as in Theorem 7.4.1. Let max(e, s) be as in (7.15), and use it in place
of ℓ(e, s) to deﬁne the new restraint function,
(7.16)
r(e, s) := max{ ϕA
e (y) [ s ] : y ≤max(e, s) }.
Now perform the same construction and proof as in Theorem 7.4.1.
Lemma 7.6.2. If Ne is injured at most ﬁnitely often, then C ̸= ΦA
e .
Proof. Assume that C = ΦA
e . Then lims ℓ(e, s) = lims max(e, s) = ∞.
Choose s′ such that Ne is never injured after stage s′. We shall deﬁne a
computable function ge such that ge(x) = C(x), contrary to hypothesis. To
compute ge(p) for some p ∈ω ﬁnd the least s > s′ such that max(e, s) > p
and ΦA
e (p)[s] is deﬁned. It follows by induction on t ≥s that
(7.17)
(∀t ≥s) [ max(e, t) > p
&
r(e, t) ≥max{ ϕA
e (x)[ s ] : x ≤p } ].
Hence, ge(p) = ΦA
e (p)[ s ] = ΦA
e (p) = C(p) and C is computable.
7.6.1
Exercises
Exercise 7.6.3. Prove that if {Cj}j∈ω is a computable sequence of non-
computable ∆0
2 sets and B is a c.e. set then there exist disjoint c.e. sets
A0 and A1 such that B = A0 ∪A1 and Cj ̸≤T Ai for j ∈ω, i ∈{ 0, 1 }.
Conclude that there is no computable enumeration {Ai}i∈ω of c.e. (∆0
2)
sets such that {deg(Ai)}i∈ω consists precisely of the nonzero c.e. (∆0
2)
degrees. Hint. Replace the negative requirements in the Sacks Splitting
Theorem 7.5.1 by N⟨e,i,j⟩: Cj ̸= ΦAi
e
and use the same method.

162
7. The Finite Injury Method
Exercise 7.6.4. Given the sequence { Cj }j∈ω as in Exercise 7.6.3 ﬁnd an
inﬁnite sequence {Ai}i∈ω of pairwise Turing incomparable c.e. sets meeting
all the requirements N⟨e,i,j⟩of Exercise 7.6.3.
Exercise 7.6.5. Prove that there exist low c.e. degrees a0 and a1 such
that for any c.e. degree c there exist c.e. degrees b0 ≤a0 and b1 ≤a1
such that c = b0 ∪b1. Hint. Apply the Sacks Splitting Theorem 7.5.1 to
K0 = {⟨x, y⟩: x ∈Wy} to obtain A0 and A1. Fix We ∈c, consider y = e,
and exhibit B0 and B1.

Part II
Trees and Π0
1 Classes

8
Open and Closed Classes
8.1
Open Classes in Cantor Space
Using ordinal notation identify the ordinal 2 with the set of smaller ordinals
{0, 1}. Identify set A ⊆ω with its characteristic function f : ω →{0, 1} and
represent the set of these functions as 2ω. Use the conventions of the No-
tation section, especially the numbering σy of strings σ ∈2<ω. We use the
notation on trees of §3.7 and sometimes use Convention 4.1.1 of dropping
the superscript 0 in deﬁning arithmetic classes. We now deal with classes
A ⊆2ω, i.e., second-order objects, rather than just ﬁrst-order objects like
sets A ⊆ω.1
Deﬁnition 8.1.1. (i)
Cantor space is 2ω with the following topology
(collection of open classes). For every σ ∈2<ω deﬁne the basic clopen class
(closed and open class)
(8.1)
J σ K = { f : f ∈2ω
&
σ ≺f }.
The open classes of Cantor space are unions of basic clopen classes.2
1Some material from the chapters in Part II was modiﬁed from that in the paper by
Diamondstone, Dzhafarov, and Soare [2011].
2The classes J σ K are called clopen because they are both closed and open. Cantor
space and Baire space are both separable. They have a countable base of open classes
as above. Therefore, every open class is a union of countably many basic open classes.
Although these are classes they are often called open sets, viewing the objects as reals.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_  
165 
8

166
8. Open and Closed Classes
(ii) A set A ⊆2<ω is an open representation of the open class
(8.2)
J A K
=
[
σ∈A
J σ K.
(We may assume A is closed upwards, i.e., σ ∈A and σ ≺τ implies τ ∈A.)3
(iii)
A class A is eﬀectively open (computably open) if A = J A K for a
computable set A ⊆ω. (See Theorem 8.1.2 (i).)
(iv) A class A is (lightface) Σ0
1 (abbreviated (lightface) Σ1) if there is a
computable R such that
(8.3)
A = { f : (∃x) R( f ↾x ) }.
(v)
A class A is (boldface) Σ0
1 if (8.3) holds with R replaced by RX
computable in some X ⊆ω. In this case we say A is Σ0,X
1
or simply ΣX
1 .
Theorem 8.1.2 (Eﬀectively Open Classes).
Let A ⊆2ω.
(i)
If A = J A K with A c.e., then A = J B K for some computable set
B ⊆ω.
(ii) A is eﬀectively open iﬀA is (lightface) Σ0
1.
(iii) A is open iﬀA is (boldface) Σ0
1.
Proof. (i)
Let A = J A K with A c.e. and upward closed. Let A = ∪sAs
for a computable enumeration {As}s∈ω. Deﬁne a computable set B with
A = J B K as follows. At stage s, for every σ with |σ| = s put σ into B if
(∃ρ ⪯σ)[ρ ∈As], and put σ into B otherwise. If σ ∈A, then σ ∈As for
some s, and every τ ⪰σ with |τ| ≥s is put into B. Hence J σ K ⊆J B K.
Therefore, J A K ⊆J B K. Clearly, B ⊆A since A is upward closed. Therefore,
J B K ⊆J A K.
(ii)
Let A be eﬀectively open. Then A = J B K for some B computable.
Deﬁne R(σ) iﬀσ ∈B. Now f ∈A iﬀ(∃x) R(f ↾x). Hence, A is Σ0
1.
Conversely, assume A is Σ0
1 via a computable R satisfying (8.3). Deﬁne
A = {σ : R(σ)}. Then A = J A K.
(iii) Relativize the proof of (ii) to a set X ⊆ω.
8.2
Closed Classes in Cantor Space
Recall the tree notation deﬁned in §3.7.
3If σ ∈A and σ ≺τ but τ ̸∈A we may add τ to A without changing J A K.

8.2. Closed Classes in Cantor Space
167
Deﬁnition 8.2.1. (i) A tree T ⊆2<ω is a set closed under initial segments,
i.e., σ ∈T and τ ≺σ imply τ ∈T. (By our canonical coding of strings
σ ∈2<ω we may think of T as a subset of ω.) The set of inﬁnite paths
through T is
(8.4)
[ T ] = { f : (∀n) [ f ↾n ∈T ] }.
(ii) A class C ⊆2ω is (lightface) Π0
1 if there is a computable relation R(x)
such that
(8.5)
C = { f : (∀x) R( f ↾x ) }.
A class C is (boldface) Π0
1 if (8.5) holds for RX computable in some X ⊆ω.
This is also written Π0,X
1
and is abbreviated ΠX
1 .
(iii)
A class C ⊆2ω is eﬀectively closed (computably closed) if its com-
plement is eﬀectively open. A set C ⊆2ω is closed if its complement is
open.
Theorem 8.2.2 (Eﬀectively Closed Sets and Computable Trees).
Fix
C ⊆2ω. TFAE:
(i) C = [ T ] for some computable tree T;
(ii) C is eﬀectively closed;
(iii) C is a Π0
1 class.
Corollary 8.2.3 (Closed Sets and Trees).
Fix C ⊆2ω. The following are
equivalent (TFAE):
(i) C = [ T ] for some tree T;
(ii) C is closed;
(iii) C is a (boldface) Π0
1 class.
Proof. Relativize the proof of Theorem 8.2.2 to X ⊆ω.
Remark 8.2.4. (Representing Closed Classes). The most convenient way
of representing open and closed classes is with trees. If C is closed we choose
a tree T such that C = [ T ]. Deﬁne A = ω −T. Then T is downward closed,
A is upward closed, as sets of strings, and A deﬁnes the open set J A K =
2ω −[ T ] = C. Note that the representations A and T are complementary in
ω and the open and closed classes J A K and [ T ] are complementary in 2ω.
The only diﬀerence between the eﬀective case and general case is whether
the tree T is computable or only computable in some set X.
We may imagine a path f ∈2ω trying to climb the tree T without passing
through a node σ ∈A. If f succeeds, then f ∈C = [ T ]. However, if f ≻σ
for even one node σ ∈A, then f falls oﬀthe tree forever and f ̸∈C.

168
8. Open and Closed Classes
8.3
The Compactness Theorem
Particularly useful features of Cantor space are the well-known Compact-
ness Theorem and the Eﬀective Compactness Theorem 8.5.1, both of which
lead to the study of one of our main topics, Π0
1 classes.
Theorem 8.3.1 (Compactness Theorem).
The following easy and well-
known properties hold for Cantor Space 2ω. The term “compactness” refers
to any of them, but particularly to (iv).
(i) (Weak K¨onig’s Lemma, WKL).
If T ⊆2<ω is an inﬁnite tree, then
[ T ] ̸= ∅.
(ii)
If
T0 ⊇T1 . . . is a decreasing sequence of trees with [ Tn ] ̸= ∅for
every n, and intersection Tω = ∩n∈ω Tn, then [ Tω ] ̸= ∅.
(iii) If {Ci}i∈ω is a countable family of closed sets such that ∩i∈F Ci ̸= ∅
for every ﬁnite set F ⊆ω, then ∩i∈ω Ci ̸= ∅also.
(iv) (Finite subcover). Any open cover J A K = 2ω has a ﬁnite open subcover
F ⊆A such that J F K = 2ω.
Proof. (i) Let T be inﬁnite. We construct a sequence of nodes σ0 ≺σ1 . . .
such that f = ∪n∈ω σn and f ∈[ T ]. Deﬁne a node σ to be large if there
are inﬁnitely many τ ≻σ such that τ ∈T. Deﬁne σ0 = ∅, which is large.
Given σn large, one of σnb0 and σnb1 must be large by the pigeon-hole
principle. (This fails for Baire space ωω, where there may be inﬁnitely many
possible successors none of which is large.) Let σn+1 = σnb0 if it is large
and σn+1 = σnb1 otherwise.
(ii)
Build a new tree S by putting σ of length n into S if σ ∈∩i≤n Ti
(which is also a tree). Note that S is inﬁnite because [ Tn ] ̸= ∅for every n.
By K¨onig’s Lemma (i) there exists f ∈[ S ], but [ S ] = [ Tω ].
(iii)
Deﬁne bCi = ∩j≤i Cj. Hence, bC0 ⊇bC1 . . . is a decreasing sequence of
nonempty closed sets. Choose a decreasing sequence of computable trees
T0 ⊇T1 . . . such that [ Ti ] = bCi and apply (ii).
(iv)
Suppose J A K is an open cover of 2ω but J F K ̸⊇2ω for any ﬁnite
subset F ⊂A. Hence, the closed set [TF ] = 2ω −J F K is nonempty for all
F ⊆A. Therefore, C = T
F ⊂A [ TF ] ̸= ∅by (iii), but C = 2ω −J A K ̸= ∅.
Hence, J A K ̸⊇2ω.
8.4
Notation for Trees
Recall the notation in §3.7 for a tree T ⊆2<ω:

8.5. Eﬀective Compactness Theorem
169
Tσ = { τ ∈T : σ ⪯τ
or
τ ≺σ };
T ext = { σ ∈T : (∃f ≻σ)[ f ∈[ T ] ] }.
A path f ∈[ T ] is isolated if (∃σ)[ [ Tσ ] = { f } ]. We say that σ isolates
f because J σ K ∩[ T ] = {f} and we call σ an atom. If f is isolated we
say it has Cantor-Bendixson rank 0. If f is not isolated, then f is a limit
point and has rank ≥1. (See Deﬁnition 8.7.5 and surrounding exercises for
Cantor-Bendixson rank.)
8.5
Eﬀective Compactness Theorem
For a computable tree T ⊆2<ω we can establish the following eﬀective
analogues of the Compactness Theorem 8.3.1.
Theorem 8.5.1 (Eﬀective Compactness Theorem). Let T ⊆2<ω be a
computable tree.
(i) T ext is a Π0
1 set. Hence,
T ext is Σ0
1,
T ext ≤m ∅′,
and T ext ≤T ∅′.
(ii) (Kreisel Basis Theorem)
[ T ] ̸= ∅
=⇒
(∃f ≤T ∅′)[ f ∈[ T ] ].
(This was generalized in the Low Basis Theorem 3.7.2.)
(iii) If f ∈[ T ] is the lexicographically least member, then f has c.e. degree.
(iv) If f ∈[ T ] is isolated, then f is computable. If [ T ] is ﬁnite, then all
paths are isolated and therefore computable.
(v) Given an open cover J A K = 2ω with A c.e. there is ﬁnite subset F ⊆A
such that J F K = 2ω and a canonical index for F can be found uniformly
in a c.e. index for A.
Proof. (i) The formal deﬁnition of T ext in (3.22) has one function quan-
tiﬁer, and it is in Σ1
1 form. Indeed is this the best we can do for Baire
space ωω. However, for Cantor space 2ω we can use the Compactness
Theorem 8.3.1 (i) to reduce it to one arithmetical quantiﬁer.
(8.6) σ ∈T ext
⇐⇒
Tσ
is ﬁnite
⇐⇒(∃n)(∀τ ≻σ) |τ|=n [ τ ̸∈T ].
This is a Σ0
1 condition because the second quantiﬁer on τ is bounded by
|τ| = n and acts like a ﬁnite disjunction. (See Theorem 4.1.4 (vi).)
(ii)
Now use a ∅′ oracle to choose f ∈[ T ] such that f = ∪nσn. Given
σn ∈T ext, let σn+1 = σnb0 if σnb0 ∈T ext, and σnb1 otherwise.
(iii)
(This gives a stronger conclusion than (ii).) Let f be the lexico-
graphically least member of [ T ], i.e., in the dictionary ordering <L on the
alphabet {0, 1}. (Think of the tree T as growing downwards and σ <L f as

170
8. Open and Closed Classes
denoting that σ is to the left of f lexicographically.) Deﬁne the following
c.e. set of nodes M ⊆T ext such that M ≡T f:
M = {σ : (∀τ) |τ| = |σ| [ [ τ ∈T & τ ≤L σ ]
=⇒
τ ∈T ext ] }
(We just wait until σ and all its predecessors of length |σ| have appeared
nonextendible. Then we put σ into M. In this way we enumerate all nodes
τ <L f. Therefore, f determines a left c.e set, one where when σ is
enumerated, all later strings τ enumerated satisfy σ ≤L τ.)
(iv)
Choose σ ∈T with [ Tσ ] = {f}. To compute f assume we have
computed τ = f ↾n. Exactly one of τ b0 and τ b1 is extendible. Enumerate
T ext until one of these nodes appears and take the other one.
(v) Assume J A K = 2ω with A c.e. Enumerate A until a ﬁnite set F ⊆A
is found with J F K = 2ω by the Compactness Theorem (iv). We can search
until we ﬁnd it.
Remark 8.5.2. Note that the conclusions in the Eﬀective Compactness
Theorem 8.5.1 have various levels of eﬀectiveness even though the hypothe-
ses are all eﬀective. In (v) if J A K covers 2ω then the passage from A to
F is computable because we simply enumerate A until F appears (as with
any Σ1 process). However, if J A K fails to cover 2ω then the complementary
closed class [ T ] = 2ω −J A K is nonempty. Then (ii) gives a path f ∈[ T ]
with f ≤T ∅′ and (iii) even produces a path of c.e. degree, but neither
produces a computable path f because, given an extendible string σ ≺f,
the process for the proof of K¨onig’s Lemma in Theorem 8.3.1 (i) does not
computably determine whether to extend to σb0 or σb1. In Theorem 9.3.2
we shall construct a computable tree with paths but no computable paths.
8.6
Dense Open Subsets of Cantor Space
The following important notion of dense sets will be developed more later.
Deﬁnition 8.6.1. Let S be Cantor space 2ω.
(i) A set A ⊆S is dense if (∀σ) (∃f ≻σ) [ f ∈A ].
(ii) An open set A ⊆S is dense open if
(8.7)
(∀τ)(∃σ ⪰τ)(∀f ≻σ) [ f ∈A ].
(iii)
A class B ⊆S is Gδ, i.e., boldface Π0
2, if B = ∩i Ai, a countable
intersection of open sets Ai.

8.7. Exercises
171
To be dense A must contain a point f in every basic open set J σ K. To be
dense open A must contain an entire basic open set J τ K ⊆J σ K for every
basic open set J σ K. Notice that a set is dense open iﬀit is both dense and
open.
After open and closed sets, much attention has been paid in point set
topology to Gδ sets. If the sets Ai are dense open sets, then they have
special signiﬁcance. In §14.1.3 we shall explore Banach-Mazur games for
ﬁnding a point f ∈∩i Ai where the Ai are dense open
sets. This is
the paradigm for the ﬁnite extension constructions in Chapter 6, where
we used the method to construct sets and degrees meeting an inﬁnite se-
quence of “requirements.” Meeting a requirement Ri amounts to meeting
the corresponding dense open set A i.
8.7
Exercises
Exercise 8.7.1. We use the notation and deﬁnitions of §8.1, including the
open representation A of J A K and the closed representation T = A of the
closed set [ T ] = 2ω −J A K, and we use the tree notation of §3.7 on the Low
Basis Theorem.
(i) Deﬁne the open representation A to be the set of strings σ containing
at least two 0’s, and let T = A. Describe the paths f ∈[ T ]. Which are the
limit points and which are the isolated ones?
(ii) Next deﬁne the open representation A to be the set of strings σ con-
taining at least three 0’s, and let T = A. Describe the paths f ∈[ T ]. (See
Exercise 8.7.9 for the Cantor-Bendixson rank of these points, which gives
much deeper insight into the structure of [ T ] when three 0’s are replaced
by n 0’s.)
Exercise 8.7.2. Prove that if T is computable and [ T ] has exactly one
limit point f, then f ≤T ∅′′.
Exercise 8.7.3. Prove that there is a computable tree T ⊂2<ω such that
[T] contains a unique limit point f ≡T ∅′′.
Exercise 8.7.4. (i) Deﬁne
(8.8)
Γ(T) = { σ :
card ([Tσ]) < ∞},
i.e., the nodes σ with only ﬁnitely many paths f ∈[ T ] with f ≻σ.
(ii) If T = T ext, deﬁne the set of splitting nodes,
(8.9)
S(T) = { σ : (∃ρ ∈T)(∃τ ∈T) [ σ ≺ρ & σ ≺τ & ρ | τ ] },

172
8. Open and Closed Classes
the nodes σ which split in T in the sense that some ρ and τ split σ, where
ρ | τ denotes that (∃x) [ ρ(x)↓̸= τ(x)↓].
(i) Prove that if σ ∈Γ(T) and f ∈[ Tσ ] then f is isolated.
(ii) Prove that if f ∈[ T ] is not isolated then every σ ≺f lies in S(T).
(iii) Prove that S(T) is Σ1 in T and hence S(T) ≤T T ′.
Deﬁnition 8.7.5. (Cantor-Bendixson Derivative for tree T). Fix a tree T.
For σ ∈T deﬁne the Cantor-Bendixson rank r(σ) of σ relative to T.
D0(T) = T.
Dα+1(T) = Dα(T) −Γ(Dα(T)) for Γ deﬁned in (8.8).
Dλ(T) =
\
{Dα(T) : α < λ} for λ a limit ordinal.
r(σ) = (µα)[ σ ∈Dα(T) −Dα+1(T) ].
If there is no such α, deﬁne r(σ) = ∞.
Deﬁnition 8.7.6. (Cantor-Bendixson derivative for closed set A).
If A
is a closed set, choose a tree T such that [T] = C and let r(σ) be the
rank above for tree T. If r(σ) = α and σ isolates f in Dα(T), then deﬁne
r(f) = α. If there is no such α then deﬁne r(f) = ∞.
The derivative of a closed set C is the set of all points which are not iso-
lated points of C, and we are iterating this derivative. Note that derivative
of a closed set is closed.
Exercise 8.7.7. Prove that Deﬁnition 8.7.6 for the Cantor-Bendixson
derivative of a closed set does not depend on the choice of the tree such
that [T] = C. Take any two trees T1 and T2 such that [T1] = [T2] = C and
prove that the tree derivative of Deﬁnition 8.7.5 gives the same rank in
both trees for any f ∈C. Hint. Keep applying the fact that T ext
1
= T ext
2
.
Exercise 8.7.8. ⋄
(i) Prove that Dα(T) is a tree and hence [Dα(T)] is
closed subset of A = [T].
(ii)
Show that there is an ordinal β such that Dβ(T) = Dα(T) for all
α > β. Deﬁne D∞(T) = Dβ(T). Prove that there is an α < ω1 such that
Dα(T) = D∞(T). We call D∞(T) and [D∞(T)] the perfect kernel.
(iii) Prove that either D∞(T) = ∅or else D∞(T) is a perfect tree, namely
every σ ∈D∞(T) splits as deﬁned above. In this case D∞(T) has 2ℵ0 many
inﬁnite paths.
(iv) Let β be as in (ii). Prove that [Dα(T)] −[Dα+1(T)] is countable for
every α < β. Therefore, ∪α<β[Dα(T)] is countable, namely [T] −[D∞(T)]
is countable.

8.7. Exercises
173
Exercise 8.7.9. Deﬁne the open representation A as in Exercise 8.7.1 and
deﬁne T = A.
(i) Analyze the Cantor-Bendixson rank of all points f ∈[ T ].
(ii) How does the rank change if we deﬁne A to be all strings having at
least n 0’s?
(iii) Deﬁne a computable tree T such that [T] has a point of rank ω.

9
Basis Theorems
9.1
Bases and Nonbases for Π0
1-Classes
The main theme of this chapter is this: Given a nonempty Π0
1 class C what
are the Turing degrees of members f ∈C?
Deﬁnition 9.1.1. A nonempty Π0
1 class C is special if it contains no
computable member.
It follows that if T ⊆2<ω is a computable tree such that [ T ] is spe-
cial, then T ext must be a perfect tree, meaning that every σ ∈T ext
admits incompatible extensions in T ext because any isolated path would
be computable. Therefore, every special Π0
1 class has 2ℵ0 members.
Deﬁnition 9.1.2. (i) Let D ⊆2ω be a class of sets. We call D a basis for
Π0
1 classes if every nonempty Π0
1 class has a member f ∈D.
(ii) Let D be the corresponding class of Turing degrees of sets X ∈D.
Then D is a basis for Π0
1 classes if D is. Otherwise, we call D a nonbasis.
(iii) We call D an antibasis if whenever a Π0
1 class contains a member
of every degree in d ∈D, it contains a member of every degree d.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_  
175 
9

176
9. Basis Theorems
9.2
Previous Basis Theorems for Π0
1-Classes
In §3.7 the Low Basis Theorem and exercises included some of the fol-
lowing basis theorems which we now list again. By the Kreisel Basis
Theorem 8.5.1 (ii) we can always ﬁnd f ≤T ∅′. In 1960 Shoenﬁeld improved
the Kreisel Basis Theorem to f strictly below ∅′, namely f <T ∅′.
Theorem 9.2.1 (Kreisel-Shoenﬁeld Basis Theorem). Every nonempty Π0
1
class C has a member f <T ∅′.
Proof. Given a Π0
1 class C, Shoenﬁeld considered the Π0
1 class D of all ⟨f, g⟩
such that f ∈C and
(∀e)[ Φf
e(e)↓
=⇒
Φf
e(e) ̸= g(e) ].
He then applied Kreisel’s result to D.
The previous Low Basis Theorem 3.7.2 substantially generalized these
results by Kreisel and Shoenﬁeld and will itself be generalized below.
Theorem 9.2.2 (Low Basis Theorem). The low sets form a basis for Π0
1.
Theorem 9.2.3. The sets of c.e. degree form a basis for Π0
1.
We proved this in the Eﬀective Compactness Theorem 8.5.1 (iii). We
shall see that it is false for the sets of incomplete c.e. degree.
9.3
Nonbasis Theorems for Π0
1-Classes
Deﬁnition 9.3.1. If A and B are disjoint sets, then S is a separating set
if A ⊆S and B ∩S = ∅.
Theorem 9.3.2. (i) If We and Wi are disjoint c.e. sets, then the class of
separating sets is a Π0
1-class.
(ii) There is a nonempty Π0
1-class with no computable members.
Proof. (i) Deﬁne a computable tree T with [ T ] the class of separating sets
of We and Wi. For σ with |σ| = s, put σ in T if ∀x < |σ|
x ∈We,s
=⇒
σ(x) = 1
. & .
x ∈Wi,s
=⇒
σ(x) = 0.
Hence, f ∈[ T ] iﬀ
(∀x)[x ∈We
=⇒
f(x) = 1
. & .
x ∈Wi
=⇒
f(x) = 0 ].
(ii) Let We and Wi be disjoint c.e. sets which are computably inseparable
as deﬁned in Exercise 1.6.26.

9.4. The Super Low Basis Theorem (SLBT)
177
Corollary 9.3.3. The class of computable sets is not a basis for Π0
1 classes
(i.e., {0} is a nonbasis).
We can generalize the preceding corollary as follows.
Theorem 9.3.4 (Jockusch and Soare, 1972a, Theorem 4). The class of
sets of incomplete c.e. degree is not a basis for Π0
1 classes (i.e., the class of
c.e. degrees d < 0′ is a nonbasis).
Proof. Let A be the Post simple set of Theorem 5.2.3. Then A and every
inﬁnite subset S ⊆A is eﬀectively immune via f(x) = 2x + 1, and there-
fore is not of incomplete c.e. degree by Exercise 5.4.6. Furthermore, A is
computably bounded by f(x) = 2x and therefore A is not hyperimmune
by Theorem 5.3.3. Let {Fx}x∈ω be a disjoint strong array witnessing that
A is not hyperimmune. Deﬁne the Π0
1 class
C = { S : S ∩A = ∅
&
(∀x)[ Fx ∩S ̸= ∅]}.
This produces a nonempty Π0
1 class C containing only inﬁnite subsets of A
and therefore having no members of incomplete c.e. degree.
Note that C has no c.e. members and no members of incomplete c.e.
degree.
9.4
The Super Low Basis Theorem (SLBT)
The proof of the Low Basis Theorem 3.7.2 gives even more information
about the jump f ′ than was explicitly claimed, but explaining it requires
some deﬁnitions.
Deﬁnition 9.4.1. A set A ≤T ∅′ is super low if A′ ≤tt ∅′ or equivalently
if A′ is ω-c.e. by Theorem 3.8.8.
Theorem 9.4.2 (Super Low Basis Theorem (SLBT)). Every nonempty Π0
1
class C ⊆2ω has a member A which is super low and indeed A′ is 2e+1-c.e.
We now give what was historically the ﬁrst proof of the SLBT from
c. 1969, by Jockusch and Soare. This unpublished result was subsequently
obtained independently by others.
Proof. We construct a computable a sequence of strings {σs}s∈ω such that
A := lims σs is super low. Fix a computable tree T with [ T ] = C. Deﬁne
the computable tree,
(9.1)
Ue,s
=
{ σ : Φσ
e, s (e)↑}
Let T0, s = T for all s. For every s given Te,s: (1) deﬁne Te+1, s = Te, s∩Ue,s,
the e-black strings, if the latter contains a string σ of length s; and (2) deﬁne
Te+1, s = Te, s, the e-white strings, otherwise.

178
9. Basis Theorems
To visualize this e-strategy, ﬁx e and the previous tree Te,s. Begin by
playing the e-black strategy of choosing σs to be e-black if possible until
for some n all nodes of length n are e-white. In other words, try to outrun
letting Φσ
e (e)↓as long as possible. This may involve many changes in σs but
no change in the e-black strategy. During this phase nest the i-strategies
within the e-strategy for all i > e.
If ever there is a stage when there is an n such that all strings of length
n are e-white, then make one change of e-strategy from e-black to e-white.
Thereafter, the e-strategy exerts no inﬂuence on the i-strategies for i > e.
To prove that this construction succeeds deﬁne the following computable
function.
bg(e, s) :=



1
if
Φσs
e,s(e)↓;
0
otherwise.
Clearly, bg(e, s) is computable. Fix e and assume by induction that g(j) =
lims bg(j, s) for all j < e and that g(j) = A′(j). Now the e-strategy begins in
the e-black case and σs ̸= σs+1 only if σs becomes e-white. If this happens
ﬁnitely often, then the ﬁnal σs is e-black and lims bg(e, s) = 0 = A′(e). If it
happens inﬁnitely often, then the e-white nodes cover Te. By compactness
there is a ﬁnite subcover and therefore an n when all strings of length n
are e-white. At this point we change once from the e-black to the e-white
strategy. Thereafter, σs never changes, bg(e, s) = g(e) = A′(e).
Furthermore, assume by induction that for e −1 there are at most 2e
stages when bg(e −1, s) ̸= bg(e −1, s + 1). The e-strategy adds one more
to each so that there are at most 2e+1 stages when bg(e, s) ̸= bg(e, s + 1).
(This is the same injury pattern as for the Friedberg-Muchnik ﬁnite injury
construction.)
9.5
The Computably Dominated Basis Theorem
The key idea in the next theorem is to use a ∅′′ oracle to build a member f
of a given Π0
1 class with the property that we can decide whether Φf
e is total
or not at a deﬁnite stage of the construction. This diﬀers from the proof
of the Low Basis Theorem, where we needed only a ∅′ oracle to similarly
decide whether Φf
e(e) converges or not. In both cases, however, we use the
same technique (known as forcing with Π0
1 classes) of continually pruning
an inﬁnite computable tree while preserving certain desired properties.
Recall that a function f is computably dominated (hyperimmune-free) if
every function h ≡T f is dominated by some computable function g. (See
also Deﬁnition 5.6.1.)

9.6. Low Antibasis Theorem
179
Theorem 9.5.1 (Computably Dominated Basis Theorem, Jockusch and
Soare, 1972b).
Every nonempty Π0
1 class has a member f which is low2
and computably dominated.
Proof. Fix a nonempty Π0
1 class C and a computable tree T ⊆2<ω such
that C = [T]. We build a sequence of inﬁnite computable trees
T = T0 ⊇T1 ⊇· · ·
as follows. Given Te, deﬁne for each x ∈ω the set
Ue,x = {σ ∈Te : Φσ
e,|σ|(x) ↑},
noting that this is a computable subtree of Te whose index as such can
be found eﬀectively from e, x, and an index for Te. Now ∅′′ can determine
whether any of these subtrees is inﬁnite, since this amounts to answering
the following Σ0
2 question:
(∃x)(∀n)(∃σ)|σ|=n [ σ ∈Ue,x ]?
If so, let Te+1 = Ue,x for the least x such that Ue,x is inﬁnite, and otherwise
let Te+1 = Te. In the former case, Φf
e(x) ↑for all f ∈[Te+1], so Φf
e is not
total, and in the latter, Φf
e(y)↓for all y and all f ∈[Te+1], so Φf
e is total.
As usual, take f ∈∩e∈ω [ Te ]. Then ∅′′ can compute the set Totf of
all e ∈ω such that Φf
e is total, and hence also f ′′ ≡T Totf, because the
above construction was ∅′′-eﬀective. Therefore, whether or not e ∈Totf was
decided during the construction at a ﬁnite stage. Hence, f is low2. To show
that f is computably dominated, let h be an f-computable function and ﬁx
e such that h = Φf
e. In particular, Φf
e is total, so during the construction
it must have been that Ue,x was ﬁnite for all x. Hence, for every x, there
must exist an n such that Φσ
e,|σ|(x) ↓for all σ ∈Te of length n; let nx be
the least such n for a given x. Since Te is computable, we can eﬀectively
ﬁnd nx for every x, meaning that the function
g(x) = max{Φσ
e,|σ|(x) : |σ| = nx ∧σ ∈Te}
is computable. Note that g bounds h.
Note that if C is a special Π0
1 class, i.e., one with no computable members,
then the above theorem yields a low2 nonlow1 member f ∈C, because no
noncomputable, computably dominated f can be computable in ∅′, let alone
be low, as we saw in Theorem 5.6.7.
9.6
Low Antibasis Theorem
For the purposes of the following theorem, we will say that a set S ⊆2<ω
is isomorphic to 2<ω provided there is a bijection g : 2<ω →S such that
for all σ, τ ∈2<ω, σ ⪯τ if and only if g(σ) ⪯g(τ). Notice that if a

180
9. Basis Theorems
tree T has a subset isomorphic to 2<ω via a computable such bijection,
then [T] has a member of every degree. Indeed, for every real X, we have
Y = ∪n g(X ↾n) ∈[ T ]. Clearly, Y ≤T X, while to compute X(n) from Y
for a given n we search for a σ ∈2<ω until we ﬁnd one of length greater
than n with g(σ) ⊂Y , and then σ(n) = X(n).
Theorem 9.6.1 (Low Antibasis Theorem, Kent and Lewis, 2009).
Every
Π0
1 class that has a member of every nonzero low degree has one of every
degree.
Proof. 1 Fix a nonempty Π0
1 class C not containing a member of every
degree and let T ⊆2<ω be a computable tree such that C = [ T ]. We deﬁne
a noncomputable low set A such that for all e ∈ω,
(9.2)
ΦA
e
= h ∈2ω
=⇒
[ h ≤T ∅
∨
h ̸∈[ T ] ].
In particular, [T] has no member h ≡T A. We obtain A as ∪sσs where
σ0 ⪯σ1 ⪯· · · are built in a ∅′-construction. Write Φρ
e = τ if
(∀x < |τ|)[ Φρ
e(x)↓= τ(x) ].
Let σ0 = ∅. At stage s+1 we are given σs.
Stage s+1 = 3e.
Let n = |σ|. Using ∅′, deﬁne σs+1 ≻σs such that
σs+1(n) ̸= ϕe(n).
Stage s+1 = 3e+1. Ask ∅′ whether there exists ρ ≻σs such that Φρ
e(e)
converges. If so, deﬁne σs+1 to be the least such ρ, and deﬁne σs+1 = σs
otherwise.
Stage s+1 = 3e+2. There are two cases.
Case 1. There exist strings α ≻σs and τ such that Φα
e = τ and τ /∈T.
In this case let σs+1 be the least such α.
Case 2.
Otherwise. In this case it follows that if ΦA
e = h total, then
h ∈[T]. We proceed as follows. For a given σ deﬁne the c.e. set
Vσ
=
{⟨α, β⟩: [σ ≺α, β]
& (∃ρ)(∃τ)[ Φα
e = ρ
&
Φβ
e = τ ]
& (∃x < min{|ρ|, |τ|)}[ ρ(x)↓̸= τ(x)↓]}.
(We say that ⟨α, β⟩form an e-splitting of σ.) Using ∅′ we search for a σ ≻σs
such that Vσ = ∅. We claim that this search must succeed, and we deﬁne
σs+1 = σ for the least such σ found.
1This proof is due to Dzhafarov and Soare with comments by Jockusch.

9.7. Proper Lown Basis Theorem
181
Suppose the claim is false. We shall contradict the assumption that [T]
does not have a member of every degree. Deﬁne a map h : 2<ω 7→2<ω as
follows. Let h(∅) = σs+1. Having deﬁned h(σ) for some σ, search com-
putably for the least member ⟨α, β⟩of the nonempty c.e. set Vσ. Then
deﬁne h(σb0) = α and h(σb1) = β. Now deﬁne g : 2<ω 7→T by letting
g(σ) = Φh(σ)
e
for all σ. Since Case 1 does not hold, it is clear that g(σ) ∈T.
Therefore, g deﬁnes an isomorphic copy of 2<ω in T, contrary to hypothesis.
The ﬁrst two types of stages guarantee that A = ∪sσs is a low
noncomputable set. It remains to prove the following lemma.
Lemma 9.6.2. If ΦA
e = h is total, then h is computable or h /∈[T].
Proof. If Case 1 held at Stage s+1 = 3e+2, then h would not be in [T]. So
suppose Case 2 held. By construction, σs+1 ⪯A was such that Vσs+1 = ∅.
In other words, there are no e-splittings above σs+1. Thus, to compute h(n)
ﬁnd the ﬁrst α ⪰σs+1 such that Φα
e (n) ↓. Now Φα
e (n) = ΦA
e (n) = h(n),
else there would have been an e-splitting above σs.
Corollary 9.6.3. If C is a nonempty Π0
1 class which does not have a
member of every degree, then there are inﬁnitely many low degrees with
no members in C.
Proof. Combine the proof of this theorem with Exercise 6.3.7, where we
avoided the cone above a nonzero low degree and repeat for inﬁnitely many
low degrees uniformly below 0′.
There are two notable features of the proof of the Low Antibasis The-
orem 9.6.1. As in Exercise 6.3.7 we do not try to force the functional to
be undeﬁned. We merely look for e-splittings, which is a Σ1 process, and
then apply Lemma 9.6.2 if we cannot ﬁnd them. Second, we do not actually
build the computable bijection g but we threaten to. This is analogous to
constructing a simple set A below a noncomputable c.e. set C where we
threatened to build a computable characteristic function g = C. We did
not build all of g but enough of g to force C to permit elements to enter A.
9.7
Proper Lown Basis Theorem
The following generalization of the Low Basis Theorem says that, up to
degree, the restriction of the jump operator to any special Π0
1 class is sur-
jective. The trick used for pushing the jump of the member up to the desired
set is like the one used in the standard proof of the Friedberg Completeness
Criterion.
The following theorem was stated with proof by Jockush and Soare in
1972 after Theorem 2.1 and later by Cenzer in 1999.

182
9. Basis Theorems
Theorem 9.7.1. For every set A ≥T ∅′, every special Π0
1 class has a
member f satisfying f ⊕∅′ ≡T f ′ ≡T A.
Proof. Fix a nonempty Π0
1 class C and a computable tree T
⊆2<ω
such that C = [T]. We build a sequence of inﬁnite computable trees
T = T0 ⊇T1 ⊇· · · as follows. Let Te be given. If e is even, deﬁne Te+1 from
Te as in the proof of the Low Basis Theorem. If e is odd, say e = 2i + 1,
note that T ext
e
must be perfect since C is special, so ∅′ can ﬁnd the smallest
extendible nodes σ, τ ∈Te such that σ(x) = 0 and τ(x) = 1 for some x.
Let Te+1 consist of all the nodes in Te comparable with σ or τ, depending
on whether A(i) = 0 or A(i) = 1, respectively.
Take f ∈∩e∈ω [ Te ]. If e is even, Te+1 can be obtained from Te com-
putably in ∅′, and hence both f ⊕∅′-eﬀectively and A-eﬀectively because
A ≥T ∅′. If e is odd, say e = 2i + 1, then to obtain Te+1 from Te we need
an oracle for ∅′ to ﬁnd the extendible nodes σ and τ and the position x
on which they disagree, and then an oracle for A since we need to know
A(i). But in this case, i ∈A iﬀf(x) = 1, so an oracle for f suﬃces to
determine whether to let Te+1 consist of the nodes comparable with σ or
the nodes comparable with τ. Since f ′ is decided during the construction,
we consequently have that f ⊕∅′ ≤T f ′ ≤T A ≤T f ⊕∅′, as desired.

10
Peano Arithmetic and Π0
1-Classes
10.1
Logical Background
One of the earliest purposes of computability theory was the study of log-
ical systems and theories. We consider theories in a computable language:
one which is countable, and whose function, relation, and constant sym-
bols and their arities are eﬀectively given. We also assume that languages
come equipped with an eﬀective coding for formulas and sentences in the
languages, i.e., a G¨odel numbering, and identify sets of formulas with the
corresponding set of G¨odel numbers. We can then speak of the Turing
degree of a theory in a computable language. Here we will examine the
language L = {+, ·, <, 0, 1} of arithmetic, and theories extending PA, the
theory of Peano arithmetic.
Deﬁnition 10.1.1. Let DPA be the set of (Turing) degrees of complete
consistent extensions of Peano arithmetic; such a degree is called a PA
degree.
The following is surely the best known theorem in mathematical logic.
Theorem 10.1.2 (G¨odel, 1931; Rosser, 1936).
1. The theory of Peano arithmetic is incomplete.
2. Furthermore, any consistent computably axiomatizable extension of
PA is also incomplete.
Corollary 10.1.3. 0 /∈DPA.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
 
183 
10

184
10. Peano Arithmetic and Π0
1-Classes
Thus, there is no complete consistent extension of PA which is com-
putable. However, there are many ways to extend PA to a complete theory,
and we can think of them as paths on a computable tree. We identify
a completion of Peano Arithmetic with the set of G¨odel numbers of its
sentences.
10.2
Π0
1 Classes and Completions of Theories
Theorem 10.2.1. There exists a Π0
1 class whose members are precisely
the completions of Peano Arithmetic. Thus, DPA is the degree spectrum of
a Π0
1 class.
Proof. (Sketch).
Fix a bijective G¨odel numbering G : ω →SentL for
sentences of arithmetic. Given σ ∈2<ω, we identify σ with the sentence
θ(σ) =
^
σ(i)=1
G(i)
&
^
σ(j)=0
¬G(j).
We say that a sentence θ “appears to be consistent at stage t” if there is
no derivation of ¬θ from the ﬁrst t axioms of PA in fewer than t lines.
Since there are ﬁnitely many such derivations, the relation R(σ, t) = “θ(σ)
appears to be consistent at stage t” is computable. Therefore, the class
C
=
{ f ∈2ω : (∀n)(∀t < n)R(f ↾t, n) }
is a Π0
1 class. Some f is an element of this class if and only if the cor-
responding set of sentences G({n : f(n) = 1}) is a complete consistent
extension of PA.
Remark 10.2.2. This theorem follows from an analysis of Lindenbaum’s
Lemma. Note that no special properties of PA were used, beyond the fact
that it is a computably axiomatizable theory in a computable language.
Therefore, the same theorem applies to all such theories.
Lindenbaum’s Lemma says that a consistent theory T has a complete
consistent extension. This follows by the Compactness Theorem.
We deﬁned a PA degree as a degree of a completion of Peano Arithmetic.
From this deﬁnition, it may be surprising that the class of degrees is closed
upwards. This is true, however, and to demonstrate it we need an impor-
tant fact arising from G¨odel’s incompleteness theorem: the proof actually
constructs a “G¨odel sentence” which is independent of the axioms.
Theorem 10.2.3 (G¨odel’s Incompleteness Theorem, eﬀective version).
From a description of a consistent, computably axiomatizable theory T ex-
tending PA, we can eﬀectively ﬁnd a sentence, called the G¨odel-Rosser
sentence of T, which is independent of T.

10.3. Equivalent Properties of PA Degrees
185
10.3
Equivalent Properties of PA Degrees
The PA degrees arise naturally in a variety of contexts, especially those
relating to trees and weak K¨onig’s lemma. This is because the PA degrees
are exactly those degrees which can achieve weak K¨onig’s lemma by ﬁnding
paths through trees. For this reason, there are several equivalent properties
which all serve to deﬁne the PA degrees. We shall highlight a few of these
properties.
Deﬁnition 10.3.1. A function f : ω →ω is diagonally noncomputable
(d.n.c.) if, for all e, if ϕe(e)↓, then f(e) ̸= ϕe(e).
Recall that up to Turing degree this is equivalent to f being ﬁxed point
free by Exercise 5.4.5.
Deﬁnition 10.3.2. A function is n-valued if f(e) < n for each e ∈ω.
The term “diagonally noncomputable” derives from the particular way
that d.n.c. functions are noncomputable. We see that if f is d.n.c., f cannot
be computable, because then f would be ϕe for some e, but f and ϕe
diﬀer on argument e; thus d.n.c. functions diagonalize against the list of all
(partial) computable functions. We will be primarily interested in 2-valued
d.n.c. functions.
Theorem 10.3.3 (Scott, 1962; Jockusch and Soare, 1972b; Solovay,
unpublished). 1
For a Turing degree d, the following are equivalent:
(i)
d is the degree of a complete consistent extension of Peano
arithmetic.
(ii) d computes a complete consistent extension of Peano arithmetic.
(iii) d computes a 2-valued d.n.c. function.
(iv) Every partial computable 2-valued function has a total d-computable
2-valued extension.
(v) Every nonempty Π0
1 class has a member of degree at most d.
(vi) Every computably inseparable pair has a separating set of degree at
most d.
Proof. (i) =⇒(ii). This implication is trivial.
(ii) =⇒(iii). Let d compute a complete consistent extension T of PA,
and let f be the (partial computable) diagonal function f(e) = ϕe(e). By
results of G¨odel and Kleene, there is a formula ψ representing f, in the
1In 1962 Scott proved the equivalence of conditions (i) and (v). In 1972b Jockusch
and Soare proved the equivalence of conditions (ii) and (vi); the equivalence with (iii)
and (iv) is also implicit in their work. Jockusch and Soare left the equivalence of (i) and
(ii) as an open question, which was answered by Solovay (unpublished).

186
10. Peano Arithmetic and Π0
1-Classes
sense that
f(x)↓= y
⇐⇒
PA ⊢ψ(x, y), and
f(x)↓̸= y
⇐⇒
PA ⊢¬ψ(x, y).
Since PA ⊢ψ(x, y) implies that ψ(x, y) ∈T, and T is complete and
d-computable, the function
bf(e) =
(
1
ψ(e, 0) ∈T
0
¬ψ(e, 0) ∈T
is a d-computable 2-valued d.n.c. function.
(iii) =⇒(iv). Suppose g is a 2-valued d.n.c. function, and let f be a partial
computable 2-valued function. There is a computable function bf such that
f(x) = ϕ b
f(x)( bf(x)) for all x. Then 1 −(g ◦bf) is a total d-computable
2-valued function extending f.
(iv) =⇒(v). Let P be a nonempty Π0
1 class, and T a computable tree
with P = [ T ]. Fix a computable bijection h : ω →2<ω. Let f be the
function
f(e) =















0
h(e) ∈T and there is a level l such that h(e)b0
has a descendent at level l in T, but h(e)b1 does not
1
h(e) ∈T and there is a level l such that h(e)b1
has a descendent at level l in T, but h(e)b0 does not.
This function f is partial computable, since to compute f(e) one simply
searches for a level l such that one case or the other holds. If h(e) ∈T is
extendible, then either both h(e)b0 and h(e)b1 are extendible, in which
case f(e) ↑, or only one is, so f(e) ↓, and h(e)bf(e) is extendible. Let bf
be a 2-valued d-computable extension of f. Then using bf, we can ﬁnd an
element of [ T ] as follows: starting with any string σ ∈T ext, apply bf ◦h−1
to get either 0 or 1, which we can append to σ to get a longer string still
in T ext. Starting with the empty string, we can iterate this process to get
an inﬁnite d-computable path through [T], i.e., an element of P.
(v)
=⇒
(vi).
If A, B is a computably inseparable pair, the class of
separating sets is a Π0
1 class by Theorem 9.3.2. If property (v) holds, this
has a d-computable member.
(vi) =⇒(i). Fix some order of L-sentences, and some order for generating
proofs. Let A be the set of pairs (F, ψ), where F is a ﬁnite set of L-sentences
and ψ is an L-sentence, such that a proof of a contradiction is found from
PA ∪F ∪{ψ} before (if ever) ﬁnding a proof of a contradiction from PA ∪
F ∪{¬ψ}. Similarly, let B be the set of pairs (F, ψ), such that a proof of

10.3. Equivalent Properties of PA Degrees
187
contradiction is found from PA∪F ∪{¬ψ} before (if ever) ﬁnding one from
PA∪F ∪{ψ}. Clearly A and B are disjoint c.e. sets. Suppose the pair A, B
has a d-computable separating set C. Let D ∈d. We shall construct a
completion T of PA, of degree d, in stages, along with a bijective function
g : ω →SentL, also deﬁned in stages. At stage n we shall determine g(n),
and decide whether g(n) ∈T. Deﬁne the set of sentences,
Fn
=
(T ∩g[0 . . . n −1]) ∪{¬ψ : ψ ∈g[0 . . . n −1] \ T}.
In other words, Fn keeps track of every sentence we decided by the begin-
ning of stage n. It contains those sentences we have declared to be in T,
together with the negations of those sentences we have declared not to be
in T. At stage n, do the following:
1. If n is even, let g(n) be the G¨odel sentence of PA ∪Fn. If n is odd, let
g(n) be the ﬁrst L-sentence not yet in the range of g.
2. If n = 2s is even, consider whether s is an element of D. If s ∈D, then
g(n) ∈T; otherwise, g(n) /∈T.
3. If n is odd, consider the pair (Fn, g(n)). If this pair is in C, then g(n) /∈T;
otherwise, g(n) ∈T.
We shall show that T is a complete consistent extension of PA, of degree
d. Assume (for the sake of induction) that Fn is consistent with PA. (Since
F0 = ∅, it is consistent with PA.) Note that Fn+1 is either Fn∪{g(n)} or else
Fn∪{¬g(n)}. Since Fn is consistent with PA, at least one of Fn∪{g(n)} and
Fn∪{¬g(n)} must be consistent with PA. Furthermore, if n is even, both are
consistent since g(n) is the G¨odel sentence for PA∪Fn. If both are consistent
with PA, then clearly Fn+1 is as well. Suppose instead only one of the two is
consistent (so we know n is odd). If only Fn ∪{g(n)} is consistent with PA,
then a proof of contradiction will be found from PA ∪Fn ∪{¬g(n)} before
ﬁnding one from PA∪Fn ∪{g(n)}, so (Fn, g(n)) ∈B. Thus (Fn, g(n)) /∈C;
by the construction, g(n) ∈T, and Fn+1 is consistent with PA. Similarly,
if only Fn ∧¬g(n) is consistent with PA, then the construction goes the
opposite way and again Fn+1 is consistent with PA. By induction, Fn is
consistent with PA for all n, so T = S
n Fn is consistent with PA. Since Fn
decides g(0) . . . g(n−1), T is complete. Therefore, T is a complete consistent
extension of PA.
In order to show that T has degree d, we ﬁrst show that g ≤T T. To
see this, note that g(n) is either the ﬁrst L-sentence which is not one of
g(0) . . . g(n −1), if n is odd, or else g(n) is the G¨odel sentence of PA ∪Fn,
where Fn is determined entirely by T and the values g(0) . . . g(n−1). Thus
g(n) can be computed from n, g(0) . . . g(n −1), and T, so g ≤T T. From
the construction, we see that s ∈D if and only if g(2s) ∈T, so we have
D ≤T g ⊕T ≤T T. However, the entire construction was d-computable, so
T ∈d.

11
Randomness and Π0
1-Classes
11.1
Martin-L¨of Randomness
In this chapter, we explore some of the relationships between Π0
1 classes,
algorithmic randomness, and computably dominated degrees.
Let µ be the Lebesgue measure on Cantor space, with which we assume
the reader is familiar. For completeness, we deﬁne the measure of an open
class A ⊆2ω. Let A ⊂2<ω be any set with A = [[A]] which is preﬁx-free
(i.e., if σ ∈A and τ ≺σ then τ /∈A). Alternatively, let A could be the
class of strings σ such that J σ K ⊆A and σ is minimal with respect to this
property. Such an A can be seen to exist for example as follows. Since A
is open, its complement is closed and hence is equal to [T] for some tree
T ⊆2<ω (which is not necessarily computable). Then A can be taken to
consist of all elements of T whose predecessors all belong to T. Now the
measure of A is deﬁned as
µ(A) =
X
σ∈A
2−|σ|.
the Lebesgue measure on Cantor space has all the same properties we
are familiar with from the Lebesgue measure on the real line. Recall that
a sequence of c.e. sets A0, A1, . . . is uniformly c.e. (abbreviated u.c.e.) if
there exists a computable function f such that An = Wf(n) for all n.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
 
189 
11

190
11. Randomness and Π0
1-Classes
Deﬁnition 11.1.1.
1. A sequence A0, A1, . . . of subclasses of 2ω is uniformly (lightface) Σ0
1
if there exists a u.c.e. sequence A0, A1, . . . of subsets of 2<ω such that
An = J An K for all n.
2.
A Martin-L¨of (ML) test is a uniformly Σ0
1 sequence A0, A1, . . . of
subclasses of 2ω such that µ(An) ≤2−n for all n.
3.
A set X ∈2ω fails a Martin-L¨of test A0, A1, . . . if X ∈T
n∈ω An.
Otherwise, X passes the test.
4.
A set X ∈2ω is Martin-L¨of random (ML-random) if it passes every
Martin-L¨of test.
The key point here is that the ML test must be eﬀective in two ways.
The sequence {An}n∈ω must be uniformly c.e., and it must converge com-
putably fast in measure to 0. The intuition is that a non-ML-random set
X is “caught” by an inﬁnite sequence {An}n∈ω which reveals some of its
information even though the measure of T
n{An} is eﬀectively 0. For ex-
ample, if the set X is computable then it is non-ML-random because it
fails the ML test in which An = J X ↾n K. Schnorr proved that a set is
ML-random iﬀit is 1-random, a closely related concept, so one may use
the terms interchangeably.
11.2
A Π0
1 Class of ML-Randoms
A Martin-L¨of test A0, A1, . . . is called universal if T
n∈ω An ⊇T
n∈ω Bn for
every other Martin-L¨of test B0, B1, . . .. Thus, if X passes a universal test,
it must pass every test, and hence
\
n∈ω
An = { X ∈2ω : X is not ML-random }.
This is a (lightface) Π0
2 class and therefore an eﬀective analogue of the (bold-
face) Π0
2 classes (i.e., Gδ classes) such as those we studied in Chapter 8,
and which we shall study in the Banach-Mazur theorem in Chapter 14.
The following theorem is thus useful when trying to show that a given
set is not ML-random.
Theorem 11.2.1 (Martin-L¨of, 1966). There exists a universal Martin-L¨of
test.
Proof. Let {V 0
n }n∈ω, {V 1
n }n∈ω, . . . be an eﬀective listing of all uniformly
c.e. subsets of 2<ω. Let Be
n = J V e
n K where we stop enumerating if the
measure exceeds 2−n. Then {Be
n}n∈ω for e ∈ω lists all ML tests. Deﬁne
An = Be
e+n+1. Then the {An} are uniformly c.e. and µ(An) ≤2−n.
µ(An) = Σe µ(Be
n+e+1) ≤Σe 2−n+e+1 = 2−n.

11.3. Π0
1 Classes and Measure
191
Therefore, {An}n∈ω is a universal ML test.
Notice that this implies that the class of ML-randoms has measure 1.
Indeed, each member of a universal Martin-L¨of test U0, U1, . . . is an open
set covering {X ∈2ω : X is not ML-random}, implying that
µ({X ∈2ω : X is not ML-random}) ≤µ(Un) ≤2−n
for all n. Essentially the same argument, in reverse, yields the following:
Corollary 11.2.2. (F. Stephan) There is a nonempty Π0
1 class all of whose
elements are ML-random.
Proof. Let U0, U1, . . . be a universal Martin-L¨of test. For every n > 0, Un
is a proper Σ0
1 subclass of 2ω, implying that Un is a nonempty Π0
1 class. By
the deﬁnition of a universal Martin-L¨of test,
U n ⊆
[
n∈ω
Un =
\
n∈ω
Un = {X ∈2ω : X is ML-random},
as desired.
From this and the various basis theorems in Chapter 9, we can conclude
that there are ML-random sets which are of c.e. degree, hyperimmune-free
(computably dominated), low, even superlow, and of PA degree. However,
any set which is ML-random and of PA degree must be of degree ≥0′.
11.3
Π0
1 Classes and Measure
Given the measure-theoretic deﬁnition of ML-randomness, it is natural to
ask about the measure of Π0
1 classes containing ML-randoms. The following
theorem gives a full answer to this question.
Theorem 11.3.1. Let C be a Π0
1 class. If µ(C) = 0, then C contains no
ML-random sets.
Proof. Suppose C has measure 0. Let T ⊆2<ω be a tree such that C = [T],
and for each n ∈ω, let An = [[{σ ∈T : |σ| = n}]]. Then A0, A1, . . . is a
nested sequence of open classes whose intersection is the measure 0 class
C, so it must be that limn µ(An) = 0. As the sequence {An}n∈ω is given
by a strong array of ﬁnite sets of strings, the map n 7→µ(An) ∈Q, the
rationals, is computable. Therefore, we can ﬁnd a computable function p
such that µ(Ap(n)) ≤2−n for all n. Now since A0, A1, . . . is uniformly Σ0
1,
Ap(0), Ap(1), . . . is a Martin-L¨of test. But for all f ∈C, f ∈T
n∈ω Ap(n), so
f is not ML-random.
Note that we can view this as a generalization of the remark earlier that
any computable set is not ML-random beginning with a similar sequence
deﬁned by strings of length n.

192
11. Randomness and Π0
1-Classes
Theorem 11.3.2 (Kucera). Let C be a Π0
1 class. If µ(C) > 0, then every
ML-random set computes a member of C.
Proof. Suppose C has positive measure and let X be a ML-random set. Let
V0 be a preﬁx-free c.e. subset of 2<ω such that C = [[V0]]. For each n ∈ω,
let Vn+1 = [[{σbτ : σ ∈Vn & τ ∈V0}, and let An = [[Vn]]. Notice that for
all n, Vn is preﬁx-free since V0 is, so we have
µ(An+1)
=
P
σ∈Vn+1 2−|σ|
=
P
σ∈Vn
P
τ∈V0 2−|στ|
=
P
σ∈Vn 2−|σ| P
τ∈V0 2−|τ|
=
µ(An)µ(A0).
It follows that µ(An) = µ(A0)n+1 = µ(C)n+1, and hence that limn µ(An) =
0 because µ(C) = 1 −µ(C) < 1. Since A0, A1, . . . is uniformly Σ0
1, and the
measures µ(An) converge to zero faster than the (computable) function
p(n) = qn, where q > µ(A0) is rational, there is some subsequence of the
sequence {An} which is a Martin-L¨of test. Since X is ML-random, it is
not in the intersection of this test, so X /∈An for some least n. If n = 0,
then X /∈C and hence X ∈C. If n > 0, since X ∈An−1, we can choose
σ ∈Vn−1 such that σ ≺X. Since no τ ∈V0 can satisfy σbτ ≺X, it follows
that Y = {x −|σ| : x ∈X & x ≥|σ|} /∈A0 as X = σbY . Thus, Y ∈C,
which, since Y ≡T X, completes the proof.
We saw in Chapter 9 that the PA degrees are precisely those which, for
every nonempty Π0
1 class, bound the degree of a member of that class. The
preceding theorem can be seen as saying that the degrees of ML-random
sets are precisely the analogues of PA degrees with respect to Π0
1 classes of
positive measure. This is a surprising fact because, in most other settings,
the PA degrees and degrees of ML-random sets behave very diﬀerently. It
is fact that if a set X is both ML-random and of PA degree, then X ≥T ∅′
although we do not prove it.
11.4
Randomness and Computable Domination
We conclude by looking at applications of some of the ideas from com-
putable domination to two other notions studied in the area of algorithmic
randomness. We begin with the following.
Deﬁnition 11.4.1. [Terwijn and Zambella] (i) A set X is computably trace-
able if there is a computable function p such that, for each f ≤T X, there
is a computable function h with |Dh(n)| ≤p(n) and f(n) ∈Dh(n) for all n.

11.4. Randomness and Computable Domination
193
(ii) A set X is c.e. traceable if there is a computable function p such that,
for each f ≤T X, there is a computable function h with |Wh(n)| ≤p(n)
and f(n) ∈Wh(n) for all n.
The idea of computably traceable is that there is for any function f ≤T X
a strong array of “boxes” Dh(n) such that the value f(n) lies in box Dh(n).
In addition, there is a single computable function p(n) which uniformly
bounds the size of the boxes over all such f. The idea of c.e. traceable is
the same except with a weak array Wh(n) in place of a strong array. This
is the analogous change in weakening h-simple to hh-simple by replacing a
strong array by a weak one.
Clearly, every computably traceable set is c.e. traceable, and it can be
shown that this implication is strict (see Downey and Hirschfeldt [2010]).
On the other hand, the following theorem shows that the reverse implication
is true if we restrict ourselves to sets of computably dominated degree.
Theorem 11.4.2 (Kjos-Hanssen, Nies, and Stephan, 2005). If X is a set
of computably dominated degree, then X is c.e. traceable if and only if it is
computably traceable.
Proof. Let X be a c.e. traceable set of computably dominated degree, and
let p be a bound as in Deﬁnition 11.4.1 (ii). Given f ≤T X, let h0 be a
computable function with |Wh0(n)| ≤p(n) and f(n) ∈Wh0(n) for all n.
Deﬁne a function g by
g(n) = (µs)[ f(n) ∈Wh0(n),s ],
so that g is total and X-computable. By Theorem 5.6.2 (ii), there exists
a computable function h1 with h1(n) ≥g(n) for all n. If we deﬁne h by
letting h(n) be the canonical index of the ﬁnite set Wh0(n),h1(n), we have
|Dh(n)| = |Wh0(n),h1(n)| ≤|Wh0(n)| ≤p(n)
and f(n) ∈Wh0(n),h1(n) = Dh(n). Hence, X is computably traceable.
We obtain a similar result by looking at the following notion of ran-
domness due to Kurtz. In view of Theorem 11.3.1 (i), it is implied by
ML-randomness, and, as above, it can be shown that this implication is
strict.
Deﬁnition 11.4.3. A Kurtz test is an eﬀective sequence of clopen classes
{An}n∈ω such that
(∀n)[ µ(An) < 2−n ].
A set X is Kurtz random or weakly 1-random if it passes every Kurtz test.
Kurtz tests are equivalent to Π0
1 classes of measure 0 in a uniform
way. Therefore, a set X is weakly 1-random iﬀX avoids all Π0
1 classes
of measure 0 iﬀX is contained in every Σ0
1 class of measure 1.

194
11. Randomness and Π0
1-Classes
Theorem 11.4.4 (Nies, Stephan, and Terwijn, 2005). If X is a set of
computably dominated degree, then X is ML-random if and only if it is
weakly 1-random.
Proof. Let X be a set of computably dominated degree which is not
1-random. Let A0, A1, . . . be a Martin-L¨of test which X does not pass,
and let f be a computable function such that An = J Wf(n) K for all n.
Deﬁne a function g by
g(n) = (µs)(∃σ ≺X)[ σ ∈Wf(e),s ],
noting that since X ∈J Wf(n) K for all n, g is total and X-computable. By
Theorem 5.6.2 (ii), there exists a computable function h with h(n) ≥g(n)
for all n. Deﬁne
C =
\
n∈ω
Wf(n), h(n).
Therefore, C is a Π0
1 class with X ∈C and
µ(C) ≤µ([[Wf(n),h(n)]]) ≤µ(Sn) = 2−n
for all n. Hence, C is a Σ0
1 class of measure 1 not containing X, so X is not
weakly 1-random.
It follows by a result of Kurtz (see [Downey and Hirschfeldt 2010]), that
every hyperimmune degree contains a set which is weakly 1-random but
not 1-random. Thus, the degrees separating these two randomness notions
are precisely the hyperimmune degrees.

Part III
Minimal Degrees

12
Minimal Degrees Below ∅′′
12.1
Function Trees and e-Splitting Strings
This chapter presents the important method of forcing with trees to con-
truct minimal degrees. Variations on this method have produced many
results on degrees and their initial segments as presented in Lerman [1983].
Theorems using the minimal degree construction can be found in the
bibliographies of Epstein [1975] and [1979].
Deﬁnition 12.1.1. A degree a is minimal if a > 0 and there is no degree
b such that 0 < b < a.
Spector [1956] proved the existence of minimal degrees below 0′′ and
Sacks [1963a] proved their existence below 0′. Our method is a revision of
that of Shoenﬁeld [1966], which is a simpliﬁcation of the Sacks method.
We begin with some terminology and lemmas which will be useful in both
proofs.
Deﬁnition 12.1.2. (i)
Let α, β, γ ∈2<ω be strings. We say β and γ
split α if α ≺β,
α ≺γ, and β and γ are incompatible in the sense of
Deﬁnition 6.5.8.
(ii) A function tree (abbreviated f-tree) is a partial computable function
T : 2<ω →2<ω
such that if one of T(αb0), and T(αb1) is deﬁned, then all of T(α), T(αb0),
and T(αb1) are deﬁned and T(αb0) and T(αb1) split T(α). (For example,
the identity function Id(σ) = σ is an f-tree.)
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
 
197 
12

198
12. Minimal Degrees Below ∅′′
Remark 12.1.3.
Recall the deﬁnition of a tree T ⊆2<ω and its asso-
ciated trees in Deﬁnition 3.7.1. In this chapter we need a stronger notion
which gives more information about splittings. We use the term “f-tree”
(function tree) to distinguish this notion from the previous notion of tree.
Note that if T is a total f-tree, and bT is the downward closure of rng(T)
under initial segments, then bT is an ordinary computable tree as deﬁned
in Deﬁnition 3.7.1. This is used in the e-white Lemma 12.2.3. We use the
concept of f-tree in this Part III only, and elsewhere “tree” will mean an
ordinary tree.
Deﬁnition 12.1.4. (Subtrees).
(i) We say that a string σ is on an f-tree T if σ ∈rng(T).
(ii) A set A is on T if σ ≺A for inﬁnitely many σ on T.
(iii) An f-tree T1 is a sub-f-tree of T (written T1 ⊆T) if σ on T1 implies
σ on T (and hence A on T1 implies A on T).
(iv)
If T is an f-tree and ν = T(α) is a node on T then we deﬁne the
sub-f-tree Tν which contains exactly those nodes ρ in T such that ρ ⪰ν.
Deﬁne for all β ∈2<ω,
(12.1)
Tν (β) = T(αbβ).
(This closely resembles the Deﬁnition 3.7.1 (i) of the restricted subtree
Tν of an ordinary tree T, which consisted of nodes ρ ∈T such that either
ρ ⪯ν or ν ≺ρ.)
Notation 12.1.5. We use α, β, and γ for strings in the domain of a
function tree T and ρ, σ, and τ for strings in the range.
Deﬁnition 12.1.6. (e-Splitting a Node).
(i) Strings ρ and τ e-split ν on f-tree T, and we say ν e-splits on T if ρ
and τ are on T, ν ≺ρ, ν ≺τ, and Φρ
e and Φτ
e are incompatible, that is,
(12.2)
(∃x) (∃y) (∃z) (∃t) [ Φρ
e,t(x)↓= y
&
Φτ
e,t(x)↓= z
&
y ̸= z ].
(If (12.2) holds, then ρ and τ necessarily split ν as in Deﬁnition 12.1.2 (i).)
(ii) An f-tree T is e-splitting if whenever T(αb0) and T(αb1) are deﬁned,
they e-split T(α).
Deﬁnition 12.1.7. (e-Black or e-White)
(i) A node ν on f-tree T is e-black if there are no e-splittings on T above
ν. (This is a Π1 question, as shown in (12.4).)
(ii) A node ν on f-tree T is e-white if the immediate extensions of ν on T
form an e-splitting above ν, that is
T(α) = ν
& T(αb0) = ρ & T(αb1) = τ
&
ρ, τ is an e-splitting of ν.

12.2. The e-Splitting Lemmas
199
(iii) A total f-tree T is e-white if every node on T is e-white, is e-black if
every node on T is e-black, and is e-gray otherwise,
12.2
The e-Splitting Lemmas
We shall show that to construct a set A of minimal degree it suﬃces to
meet for all e the following requirements, as proved in the next two lemmas
below.
(12.3)
Re :
A lies on a total f-tree T which is e-white or e-black.
We could add requirements to make A noncomputable, Se : A ̸= ϕe, but
the following simple lemma makes this unnecessary.
Lemma 12.2.1 (Noncomputability Lemma, Posner-Epstein).
If A meets
all the minimality requirements {Re}e∈ω, then A is not computable.
Proof. Assume toward a contradiction that A is computable. Deﬁne the
computable functional ΦX
e as follows:
Φσ
e (x) =
(
σ(x)
if σ is incompatible with A;
undeﬁned
if σ ≺A.
If A satisﬁes the minimality requirement Re then A must lie on the tree
T for Φe and T must be either e-black or e-white. First, note that T is a
total f-tree and Φe is the identity of the initial segments of A. Therefore,
T cannot be e-black because every node ν on T has an e-splitting on T.
But T cannot be e-white because no ν ≺A is half of an e-splitting.
The intuition for the following procedure to meet Re is as follows. We
start with an f-tree T which probably has many e-gray nodes and we
attempt to ﬁnd a sub-f-tree consisting of either all e-black nodes or all
e-white nodes. The next two lemmas say that this suﬃces for meeting
requirement Re.
Lemma 12.2.2 (e-Black Lemma).
If A is on T, a total f-tree, ν is on
T, ν ≺A, Tν is e-black, and ΦA
e = g is total, then g is computable.
Proof. Suppose ΦA
e = g is total. To compute g(x) ﬁnd any τ on Tν such
that Φτ
e(x) converges, and let y = Φτ
e(x). We claim g(x) = y. Such a τ
exists because ΦA
e (x) converges, and ν ≺A, so Φρ
e(x) converges for some ρ
on Tν with ρ ≺A. Furthermore, Φρ
e(x) = Φτ
e(x) because otherwise ρ and
τ form an e-splitting of ν on Tν. Therefore, Φτ
e(x) = ΦA
e (x). Finally, g is
computable because T is computable, and therefore rng(T) is c.e. and can
be enumerated until τ is found.

200
12. Minimal Degrees Below ∅′′
Lemma 12.2.3 (e-White Lemma).
If A is on T, a total f-tree, ν is on
T, ν ≺A, Tν is e-white, and ΦA
e = g is total, then A ≤T g.
Proof. Fix g as an oracle. We shall g-computably deﬁne a sequence of
strings {σs}s∈ω on T such that A = ∪s σs. Deﬁne σ0 = ν. Now suppose
we are given σs = T(α) for some α such that σs ≺A. Compute ρ =
T(αb0) and τ = T(αb1). These exist and e-split σs because Tν is e-white.
Therefore, (12.2) holds for ρ and τ. Exactly one value y or z of (12.2) agrees
with g(x) because ΦA
e (x) = g(x) and ΦA
e (x) = y or ΦA
e (x) = z. Enumerate
the quadruples ⟨x, y, z, t⟩until the ﬁrst is found satisfying (12.2). Deﬁne
σs+1 = ρ if g(x) = y and deﬁne σs+1 = τ if g(x) = z. Now σs+1 ≺A
because A extends exactly one of ρ and τ, and ΦA
e (x) = g(x).
12.3
The Splitting Procedure
The splitting procedure presented next will prune an e-gray f-tree T to
obtain an e-white sub-f-tree bT ⊆T. It succeeds provided that T contains
no e-black nodes. Otherwise, the procedure stalls on any e-black node ν
and produces only a partial f-tree bT because it never ﬁnds an e-splitting
on T above ν.
Deﬁnition 12.3.1. Given an f-tree T, a string σ on T, and e ∈ω, deﬁne
bT = Sp(T, σ, e), the e-splitting sub-f-tree of T above σ, by induction on
|α| as follows. Set bT(∅) = σ. If bT(α) = ν is deﬁned, enumerate all tuples
⟨ρ, τ, t, x, y, z⟩such that ν ≺ρ, ν ≺τ, and ν, ρ, and τ are on T, until (if
ever) the ﬁrst such tuple is found satisfying the e-splitting in the matrix
of (12.2). Deﬁne bT(αb0) = ρ and bT(αb1) = τ, so that ν becomes e-white.
If they do not exist, then bT(αbi) is undeﬁned for i = 0, 1 and ν remains
e-black forever. (This enumeration of tuples is done using the canonical
indices of strings presented in the Notation section.)
Remark 12.3.2. The Splitting Automaton Sp(T, σ, e). In this chap-
ter most constructions use some oracle. However, it is crucial that this
splitting procedure used as a submodule in those constructions be entirely
eﬀective with no oracle. The function bT = Sp(T, σ, e) is a partial com-
putable function with inputs T, σ and e. From a ﬁxed node ν it waits for a
splitting to appear and adds it to the e-white tree it is building. If there is
no such splitting, then the procedure stalls at ν and Sp(T, σ, e) produces
only a partial f-tree. This is how partial trees arise in the ∅′ but not the
∅′′ case. We can think of Sp(T, σ, e) as a kind of automaton which chugs
along adding e-splittings whenever they appear, but gets stuck forever if it
stumbles across a node ρ which is e-black, although the automaton cannot
recognize this. If not, and if Tσ is a total f-tree, then bT = Sp(T, σ, e) is a
total e-white f-tree.

201
12.4
The Basic Module for Minimality
We begin with the f-tree T−1 = Id, the identity. Now suppose by induction
we have thinned the tree to obtain a total sub-f-tree T which has satisﬁed
all the minimal requirements Ri for i < e. By Lemmas 12.2.2 and 12.2.3,
to guarantee the minimality condition for e it suﬃces to ﬁnd A and a total
sub-f-tree bT ⊆T with A on bT such that bT is either e-black or e-white.
Whether a given node ν on T is e-black is a Π1-question, as follows:
(12.4) ν is e-black on T
⇐⇒
¬(∃ρ ≻ν)(∃τ ≻ν)[ ρ and τ e-split ν ]?
where all strings range over T. Therefore, the following question is Σ2 :
(12.5)
(∃ν on T)[ ν is e-black ]?
The basic module is as follows. Ask the Σ2 question (12.5) above. (This
assumes one has a 0′′-oracle as in Spector’s theorem that a < 0′′. If not,
we need to make various approximations to the Σ2 question.)
Case 1. (12.5) holds. Choose the ﬁrst e-black node ν on T. Let bT = Tν,
which is an e-black tree.
Case 2. (12.5) fails. Deﬁne bT = Sp(T, σ, e) of Deﬁnition 12.3.1, which is a
total e-white tree because every node on bT e-splits on T and hence on bT.
12.5
A Minimal Degree Below a ∅′′-Oracle
Theorem 12.5.1 (Spector, 1956).
There is a minimal degree a < 0′′.
Proof. Let T −1 = Id, the identity tree, and σ−1 = ∅, the empty node.
Stage e ≥0. Assume by induction on e that we are given a total f-tree
T e−1 and string σe−1 on T e−1 such that for σ = σe−1 and T = T e−1
σ
, and
for all i, 0 ≤i < e, we have that T is either i-black or i-white. Use the
∅′′-oracle to decide the Σ2-question of whether (12.5) holds for e and tree
T = T e−1
σ
.
Case 1. (12.5) holds for e and T. Use a ∅′′-oracle to choose the ﬁrst e-black
node ν ≻σ on T. Let T e = T e−1
ν
, which is an e-black tree, and let σe = ν.
Case 2. (12.5) fails for e and T. Deﬁne bT = Sp(T, σ, e) using the splitting
procedure in Deﬁnition 12.3.1. This produces an e-white sub-f-tree bT ⊆T.
Find an extension bσ ≻σ such that bσ is on bT. Deﬁne T e = bT bσ and σe = bσ.
This completes stage e. Let A = ∪e σe. Note that the sequence of trees
{T e
σe}e∈ω is a decreasing sequence of closed sets and σe ≺σe+1 ≺f. Hence,
by the Compactness Theorem 8.3.1 (iii) the intersection is nonempty and
A lies on all these trees.
12.5 A Minimal Degrees Below a
-Oracle
∅′′

202
12. Minimal Degrees Below ∅′′
Furthermore, A has minimal degree by Lemmas 12.2.2 and 12.2.3 because
for every e we have shown that A lies on an f-tree T e
σe which is either e-
black or e-white. Furthermore, A ≤T ∅′′ because the above construction
uses a only a ∅′′-oracle.
12.6
Exercises
Exercise 12.6.1. (Sacks). Show that any countable ascending sequence of
degrees b0 < b1 < · · · has a minimal upper bound a. (Namely, a is an up-
per bound but there is no upper bound d < a.) Hint. Choose a set Bn ∈bn
for each n. Use Theorem 12.5.1 to ﬁnd a total computable f-tree T1 satis-
fying R0. Deﬁne a total B0-computable f-tree eT1 ⊆T1 which still satisﬁes
R0 and such that B0 ≤T A for every A on eT1. Deﬁne eTs(α) by induction
on |α| as follows. Let eT1(∅) = T1(∅). Assume eT1(α) has been deﬁned and
equals T1(ρ) for some ρ. If |α| = n, deﬁne eT1(αbi) = T1(ρbB0(n)bi) for
i = 0, 1. Choose an appropriate σ1 on eT1, |σ1| ≥n. In general, apply the
above procedure to eTn to obtain a Bn-computable total f-tree eTn+1 ⊆eTn
such that eTn+1 satisﬁes Rn and Bn ≤T A for every A on eTn+1. Next, choose
σn+1 ∈eTn+1 such that σn ≺σn+1. Let A = ∪nσn.
Exercise 12.6.2. Show that there exist 2ℵ0 diﬀerent minimal degrees.
Hint. Use the method of Theorem 12.5.1 with that of Exercise 6.1.6 to
build a tree of f-trees.

13
Minimal Degrees Below ∅′
13.1
The Sacks Minimal Degree a < 0′
The Spector proof of a minimal degree used a ∅′′ oracle to prune one tree
T e−1 to obtain the next tree T e. Sacks used a variation of the ﬁnite injury
method. He saw that the Spector method could be approximated to ﬁnd a
minimal degree below a ∅′ oracle.
Theorem 13.1.1 (Sacks).
There is a minimal degree a < 0′.
Proof. We begin with the basic module to satisfy a single requirement Re
and then give the full construction to satisfy all the requirements {Re}e∈ω.
13.2
The Basic Module for One Requirement Re
We use a ∅′-oracle and present the basic module to construct a tree T e
to meet a single requirement Re as deﬁned in (12.3). For simplicity let us
ﬁx e, the preceding tree T e−1, and a string σ ∈T e−1 which we are trying to
extend. We must deﬁne a sub-f-tree T e ⊆T e−1
σ
, which is either e-white or
e-black, and a string σ′ ≻σ on it. As a ﬁrst example, let us consider e = 0
so T e−1 = Id, the identity tree. Other trees T e,s for e ≥0 will change as s
changes, but T −1,s = Id for all s. This simpliﬁes the description of T 0.
In the basic module in §12.4 for the minimal degree a < 0′′ we asked the
Σ2 question (12.4) of whether there is a node ν ≻σ with ν ∈T e−1 such
that ν is e-black on T e−1. If so, we built T e = T e−1
ν
, an e-black f-tree. If
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
 
13
203 

204
13. Minimal Degrees Below ∅′
not, we launched the e-splitting automaton and let T e = Sp(T, σ, e). We
can no longer ask the oracle whether there exists an e-black node ν on
T e−1. Therefore, we must begin with the e-white strategy. We start with
the e-white f-tree
(13.1)
T e,s = Sp (T e−1
σ
, σ, e).
Of course, this strategy may stall if it encounters a node which does not
e-split. To recover from this obstacle we use the ∅′-oracle to test whether
(13.2)
(∃ν)|ν|≤s [ ν on T e,s
&
ν is e-black on T e−1,s
σ
].
If so, we deﬁne T e,s+1 = T e−1
ν
, an e-black f-tree, and σ′ = ν.
Notice that this is the same strategy as in the ∅′′-case except that we no
longer have a ∅′′-oracle to determine whether there exists an e-black node
ν ∈T e−1. We have only a ∅′-oracle which can recognize whether a given
node ν is e-black if we stumble across it. (The ﬁnal conjuct in (13.2) is Π1
because T e−1
σ
is total and computable, and hence the bounded quantiﬁer
makes this a ∅′-question.)
13.3
Putting the Strategies Together
So long as T e−1,s remains ﬁxed this strategy for T e,s has at most one reverse
of strategy when the e-strategy is forced to change from the e-white to the
e-black stategy. If this occurs then we have a deﬁnite e-black node and as
in the ∅′′ case there is no reason to ever change back to the e-white strategy
again.
However, suppose e = 1 and we are constructing a tree T 1 to meet
requirement R1. Now T −1 = Id never changes, and the 0-tree T 0,s changes
at most once from the white to the black strategy. Next e = 1 is given
the previous tree T 0,s. While T 0,s is 0-white the strategy for e = 1 plays
as if this is the ﬁnal tree T 0 that we have at the end of the construction.
However, if T 0,s suddenly switches to the 0-black tree, then T 1 is injured
and must restart the 1-strategy as deﬁned in (13.3) with e = 1.
When the tree T e−1,s = T e−1 ﬁnally becomes ﬁxed, the e-strategy re-
verses from e-white to e-black at most once and succeeds in building a tree
T e which satisﬁes requirement Re. However, for a general e the tree T e−1
may change 2e many times because for each j > 0 the j-strategy may be
reset whenever the preceding tree T j−1 changes. Therefore, whenever tree
T e−1 changes we must reset the e-strategy by redeﬁning
(13.3)
T e,s+1 = Sp (T e−1,s, σ, e).
This causes the e-strategy to begin anew on the current tree T e−1 with the
e-white strategy.

205
13.4
A Subtle Point
If T e−1,s is currently in the (e −1)-white strategy, then we have currently
recognized only ﬁnitely many nodes as (e −1)-white. What does it mean
that the e-strategy uses a ∅′-oracle to recognize that a node ν ∈T e−1 is
e-black? Note that e-black means no futher e-splittings on the previous tree
T e−1,s, but we have so far examined only ﬁnitely many nodes σ ∈T e−1,s,
perhaps only σ of length less than s. How can we determine whether there
are longer ones which do e-split?
The answer is that at stage s we have an index j for a (potentially) total
tree Tj = T e−1,s. In the ﬁrst case, T e−1,s is in the (e −1)-black mode, in
which case T e−1,s = T e−2,s
ν
and is total if T e−2,s is total and is not later
reset. In the second case, T e−1,s is in the (e −1)-white mode and of the
form Sp(T e−2,s, σ, e −1). In this case it is also a total tree provided that
the (e −1)-strategy never changes from white to black. If it does, then the
(e −1)-strategy is reset. In either case we may assume by induction that
we have an index for T e−2,s as a total computable f-tree. From this we
have an index for Tj regardless of which case holds currently for T e−1,s.
Therefore, we can behave as if Tj is a total tree and the ﬁnal tree T e−1,
because either this is true or the (e −1)-strategy is reset and we begin
again.
We ask the ∅′-oracle the same Π1 question as in (12.4),
(13.4) ν is e-black on Tj
⇐⇒
¬(∃ρ ≻ν)(∃τ ≻ν)[ ρ and τ e-split ν ]?
where all strings range over Tj.
Either T e,t = Tj = T e for all t > s, in which case Tj is total and the
question gives the correct answer, or else T e,s ̸= T e,t at some future stage
t > s, in which case we reset the strategy at stage t and it does not matter
what action we took at stage s. The main point is that if we are in the
(e −1)-white mode at stage s, we cannot let Tj be only the ﬁnite set of
nodes enumerated in the white tree so far. Finding no e-splitting in this
small tree is not suﬃcient reason to change from the e-white to the e-black
strategy.
13.5
Constructing A to Meet Requirements
{Re}e∈ω
Deﬁne the initial string σ−1 = ∅and the initial tree T −1,s = Id
for all s.
Stage s ≥0. Given σs and trees T e,s with T e,s ⊇T e+1,s for all −1 ≤e < s.
13.5
Constructing A to Meet Requirements {Re}e∈ω

206
13. Minimal Degrees Below ∅′
Case 1. Using the ∅′-oracle ﬁnd the least e ≤s (if it exists) such that T e,s
is in the e-white mode but
(∃ν) |ν| ≤s [ ν ∈T e−1,s
&
ν ≻σs
&
ν is e-black on T e−1,s ].
(This question is computable in ∅′ because the quantiﬁer is bounded, the
ﬁrst two clauses in the matrix are computable, and the third is Π1 by
(12.4).) Choose the ﬁrst such ν in the canonical listing of the nodes of T.
Deﬁne
σs+1 = ν
&
T e,s+1 = T e−1,s+1
ν
,
which is the e-black sub-f-tree of T e−1,s above ν. For all i, e ≤i ≤s, deﬁne
T i+1,s+1 = Sp(T i,s+1, σs+1, i).
For all i < e deﬁne T i,s+1 = T i,s.
Case 2.
Case 1 fails. Namely, there is no such e. For all e ≤s deﬁne
T e,s+1 = T e,s and σs+1 = σs. For e = s+1 let T s+1,s+1 = Sp(T s,s, σs, s).
At the end of stage s go to stage s + 1. Deﬁne A = ∪sσs. Therefore,
A ≤T ∅′ because the sequence of strings {σs}s∈ω is computable in ∅′.
Lemma 13.5.1. For every e the strategy for e is reversed at most ﬁnitely
often, requirement Re is satisﬁed, T e = lims T e,s exists and A is on T e.
Proof.
Fix e and assume these hypotheses true for every i < e. Choose
the last stage s at which Case 1 applied to some i < e if it exists, and let
s = 0 if there is no such stage. Then T e,s = Sp(T e−1, σs, e), the e-white
sub-f-tree. The e-strategy reverses at most once after stage s, say at some
stage t > s. Hence, T e = T e,v for all v > t. Note that the sequence of trees
{T e}e∈ω is a decreasing sequence of closed sets and σs ⪯σs+1 ≺f. Hence,
by the Compactness Theorem 8.3.1 (iii), the intersection is nonempty and
A lies on all these trees. Therefore, A meets every requirement Re and A
has minimal degree.
13.6
A Limit Computable Minimal Degree
In the preceding section we built the set of minimal degree A = ∪sσs
for a sequence of strings {σs}s∈ω determined by an oracle such as 0′. In
this section we give a limit computable construction of a set A of mini-
mal degree. This construction produces a computable sequence of strings
{σs}s∈ω such that A(x) = lims σs(x). By the Limit Lemma 3.6.2 we have
A ≤T ∅′. Therefore, this gives another proof of Theorem 13.1.1. This limit

13.7. A Minimal Degree Below a Nonzero C.E. Degree
207
computable construction1 is necessary in §13.7 on a minimal degree below
a nonzero c.e. degree, and is very ﬂexible for other applications.
13.6.1
Meeting a Single Requirement Re
We give a very brief sketch to meet a single requirement. Fix e and assume
that T e−1 is a ﬁxed tree. Begin with the e-splitting c.e. tree T e,s of (13.1)
and color all these nodes e-white. The nodes extending these which have
not yet e-split we color e-black and ﬁll in the identity tree of T e−1 above
them. If any nodes later split, they are colored e-white and the e-white
boundary is extended. An e-white node never changes back to e-black so
the tree lims T e,s exists.
Choose a node αs as follows. First, choose the longest e-white node β
with the least index with this property, and then choose a γ through the
black nodes so that αs = βbγ has length at least s. Later, if there is an
e splitting ρ, τ of β, we move γs+1 to one of these, say ρ, to stay as long
as possible within the e-white nodes. Such a change occurs for γ at most
once, so lims αs exists. Therefore, the inﬁnite path A is ∆2. It either lies
on an e-white tree if the e-white boundary advances to inﬁnity along the
path A, or else there is a last e-black node on A, in which case A lies on an
e-black tree. Whenever we have a choice of nodes, we choose the one with
the least index satisfying the given condition.
To put the requirements together we play two versions of the strategy for
e + 1, one within the e-white nodes and one outside the e-white boundary
within the e-black nodes. The second strategy for e + 1 guesses that the
e-white boundary never advances further along the present approximation
to A, and this strategy is reset whenever that occurs. This leads to injury
of the strategy. If the e-white boundary advances to inﬁnity along A, then
the strategy for e + 1 plays exactly as formerly, but among the e-white
nodes. If the e-white boundary advances only ﬁnitely often along the path
A, then the strategy for e + 1 is reset at most ﬁnitely often and eventually
behaves exactly like the former strategy, but played now on e-black nodes.
13.7
A Minimal Degree Below a Nonzero C.E.
Degree
Previously, we used an oracle such as ∅′′ or ∅′ to determine for a given
node ν whether it ever e-split or remained e-black forever. Now, we have
no oracle, only a computable construction, and therefore in this version of
the minimal degree method we must begin with the assumption that every
1This was previously called a full approximation construction. Now it is called a limit
computable construction as in Deﬁnition 3.5.4 and in the Limit Lemma 3.6.2.

208
13. Minimal Degrees Below ∅′
node ν is e-black. If e-splittings appear during the construction, we can
begin building the e-splitting white tree as in §12.3, where we started to
construct the e-white tree bT = Sp(T, σ, e).
We now give only a very small sketch to convey the main idea for a reader
familiar with the limit computable minimal degree construction above and
with the permitting construction of §5.2. For more details on this theorem
see Lerman [1983, Chapter XI], or Epstein [1979, Chapter XI], or Epstein
[1975, Chapter II].
Theorem 13.7.1. If C is a noncomputable c.e. set, then there is a set
A ≤T C of minimal degree.
Proof. (Very brief sketch). We give a very brief sketch for meeting a single
requirement. Fix e and assume that T e−1 is a ﬁxed tree. Begin with the
e-splitting c.e. tree T e,s of (13.1) and color all these nodes e-white as in
§13.6.1. Begin by deﬁning αs = βsbγs, as before. However, if we later see
an e-splitting ρ, τ of βs, we cannot immediately move γs to it, but can only
later at stage t > s if there is a Ct ↾n change where n = |β|, which permits
this move. We start to deﬁne a computable function g(t) = n to encourage
C to make at least one such change. We continue deﬁning g(ti) = ni as
more such points appear.
There are three cases. If inﬁnitely many points appear and none is per-
mitted, then C is computable. If one is permitted, we make the change and
begin the strategy again until A lies on an e-white tree. If there are at most
ﬁnitely many such requests for a change to an e-white splitting, then A lies
on an e-black tree.
Corollary 13.7.2. There is a low minimal degree.

Part IV
Games in Computability
Theory

14
Banach-Mazur Games
14.1
Banach-Mazur Games and Baire Category
14.1.1
Meager and Comeager Sets
We use the deﬁnitions and notation on the topology of Cantor space and
Baire space from §8.1 with basic open sets J σ K deﬁned in (8.1). We extend
Deﬁnition 8.6.1, which introduced dense sets and dense open sets.
Deﬁnition 14.1.1. Let S be Cantor space 2ω. (Baire space ωω is similar.)
(i) For a string τ ∈2<ω a set A is dense in the basic open set J τ K if
(14.1)
(∀σ ⪰τ)(∃f ≻σ)[ f ∈A ].
(ii) A set A ⊆S is dense if A is dense in J ν K for ν the null string, i.e.,
(14.2)
(∀σ)(∃f ≻σ) [ f ∈A ].
(iii) A set A ⊆S is a dense open set if
(14.3)
(∀τ)(∃σ ≻τ)(∀f ≻σ) [ f ∈A ].
Therefore, a set A is dense open if it is both dense and open. Note that A
contains the dense open set D := ∪σ J σ K for all σ in the second quantiﬁer
of (14.3).
(iv) A is comeager if it contains the intersection of a countable family of
dense open sets, namely A ⊇∩i J Ai K for J Ai K dense open.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
 
211
14

212
14. Banach-Mazur Games
(v)
A is meager if its complement is comeager. (Also A is meager if it
is of ﬁrst category, See Exercise 14.1.6 for a discussion of ﬁrst and second
category and their relationship to comeager.)
The intuition is that comeager sets are large. They form a ﬁlter, are
dense, uncountable, and are closed under countable intersections. Meager
sets are small. They form an ideal, and countable sets are meager.
14.1.2
The Baire Category Theorem
In many theorems we are given a sequence {An}n∈ω of subsets of 2ω, and
we want to construct a point f ∈2ω which meets every one. If the sets
An were merely dense this might not be possible. (See Exercise 14.1.4.)
However, if every An is dense and open, then the dense open property
(14.3) ensures that we can do exactly that. Hence, with a ﬁnite extension
at stage s + 1 from σs to σs+1 = ρ we can satisfy once and for all the
requirement Rn : f ∈An and move on to other requirements on the list.
This is the essence of the following theorem by Baire.
Theorem 14.1.2 (Baire Category Theorem, 1899).
Let A be comeager.
(i) A is not empty.
(ii) Indeed, (∀ρ ∈2ω) [ A ∩J ρ K ̸= ∅]. Therefore, A is dense.
Proof. If A is comeager, then A ⊇∩i J Ai K for Ai dense open. Given any
τ ⪰ρ and i there exists σi ≻τ such that σi ∈Ai. Construct f = ∪i σi
where σi ≺σi+1 and σi ∈Ai for all i. Hence, f ∈(∩i J Ai K) ∩J ρ K.
14.1.3
Banach-Mazur Games
In 1928 the Polish mathematician S. Mazur invented the following game,
called a Banach-Mazur game. We ﬁx ahead of time a set A ⊆2ω. Player I
chooses string σ0 = ∅. Player II chooses σ1 ≻σ0. For i ≥1, given σ2i−1,
Player I ﬁrst chooses σ2i ≻σ2i−1 and then Player II chooses σ2i+1 ≻σ2i.
The play of the game is the inﬁnite sequence f = ∪n σn so constructed.
If f ∈A, then Player I wins, and otherwise Player II wins. (Note that f
is a unique point because σi ≺σi+1. This strict extension guarantees that
∩i J σi K = f.)
This is similar to the Gale-Stewart game in Chapter 15 except that in the
latter each σi+1 is exactly a one point extension of σi. As before, a winning
strategy for one of the players is a function from ﬁnite positions telling him
which string to play next. It follows from the proof of the Baire Category
Theorem 14.1.2 that if A is comeager, then Player I has a winning strategy.
Mazur conjectured the converse, which Banach proved.

14.1.
Banach-Mazur Games and Baire Category
213
Theorem 14.1.3 (Banach-Mazur). Player I has a winning strategy in the
Banach-Mazur game for A iﬀA is comeager. (Equivalently, Player II has
a winning strategy iﬀA is meager.)
Proof. ( ⇐= ). Let Player I apply the strategy of Theorem 14.1.2 (ii) with
ρ = σ2i−1 to ﬁnd σ2i ≻ρ such that σ2i ∈Ai.
( =⇒). (The reverse is more complicated and will be omitted.)
14.1.4
Exercises
Exercise 14.1.4. Construct dense sets A0, A1 ⊂2ω such that A0∩A1 = ∅.
Exercise 14.1.5. For any set A ⊆2ω deﬁne the closure of A, denoted by
Acl, to be the smallest closed set C ⊇A. Given A deﬁne the tree
TA = { σ : (∃f ≻σ) [ f ∈A ] }.
(i) Show that TA is an extendible tree. Prove that Acl = [ TA ].
(ii) Consider the points f ∈Acl −A. Are they limit points or isolated
points?
(iii) Let A = { 1n0∞}n≥1, where 1n0∞denotes a string of n 1’s followed
by an inﬁnite string of 0’s. Describe Acl and Acl −A. What is the Cantor-
Bendixson rank of f ∈Acl −A? (See Deﬁnition 8.7.5 and surrounding
exercises for the Cantor-Bendixson rank.)
(iv) Construct a set A such that there exists f ∈Acl −A of Cantor-
Bendixson rank 2.
Exercise 14.1.6. A set A is nowhere dense if there is no τ such that A is
dense in J τ K in the sense of (14.1).
(i) Prove that A is nowhere dense iﬀits complement A = 2ω −A contains
a dense open set.
(ii) Prove that if C = [T] is a nowhere dense closed set then
(∀σ ∈T)(∃τ ≻σ)[ τ ̸∈T ].
Hence, the tree T has lots of “holes.”
(iii) R. Baire deﬁned a set A to be of ﬁrst category if it is a countable union
of nowhere dense sets. Prove that A is of ﬁrst category iﬀA is meager as
in Deﬁnition 14.1.1 (vi).
(iv) Baire deﬁned an A to be of second category if it is not of ﬁrst category.
Prove that if A is comeager then it is of second category. Assume that A is
both comeager and of ﬁrst category (meager) and derive a contradiction.
(It is false that a set A of second category is necessarily comeager.)

214
14. Banach-Mazur Games
Exercise 14.1.7. Prove the following. (i) The comeager sets form a ﬁlter,
i.e., are closed under supersets and intersections.
(ii) A comeager set is uncountable.
(iii) The comeager sets are closed under countable intersections.
Exercise 14.1.8. Fix a set X ≤T ∅′. Let Ai, i ∈ω, be a (countable)
uniformly ∆0
2 sequence of ∆0
2 sets which are dense open.
(i) Prove that if X ≡T ∅′, then there is an f ∈∩i Ai such that f ≤T X.
(ii) Now assume that the Ai are not necessarily all dense. What oracle X
suﬃces to construct f ≤T X such that f ∈Ai for every dense Ai?
14.2
The Finite Extension Paradigm
The following theorem expresses the essence of all the ﬁnite extension oracle
constructions seen in §6.1–§6.4, although they were not exactly stated this
way. All these and many more can be derived immediately from this one
paradigm theorem by appropriately deﬁning the sets {Ve}e∈ω.
Theorem 14.2.1 (Finite Extension Paradigm).
As in Deﬁnition 2.6.1,
given a u.c.e. sequence V = {Ve}e∈ω of c.e. sets, there exists f ≤T ∅′ which
is V-generic, i.e., f forces every Ve in the sense of (6.11).
Proof. We construct a ∅′-computable sequence of strings {σs}s∈ω.
Stage s = 0. Let σ0 = ϵ the null string.
Stage s + 1. Given σs let e = s and ask the ∅′-oracle whether:
(14.4)
(∃ρ ≻σs) [ ρ ∈Ve ]
(denoted
ρ ⊩f ∈Ve).
If so, ﬁnd the ﬁrst such ρ and deﬁne σs+1 = ρ. If not, deﬁne σs+1 to be
the ﬁrst ρ ≻σs. Deﬁne f = ∪σs. Clearly, f ≤T ∅′. Note that if (14.4) fails,
then automatically
(14.5)
(∀ρ ≻σs) [ ρ ̸∈Ve ].
(denoted
σs ⊩f ̸∈Ve).
If (14.4) holds we pronounce ρ ⊩f ∈J Ve K as asserting that ρ forces
f ∈J Ve K = Ve and if (14.5) holds we pronounce ρ ⊩f ̸∈J Ve K as asserting
that ρ forces f ̸∈J Ve K. In either case, σs+1 ⊩f ∈Ve or σs+1 ⊩f ̸∈Ve so
f forces (decides) Ve via string σ = σs+1.
Theorem 14.2.1 can be used to derive most of the ﬁnite extension results
such as those in §6.1–§ 6.4.
For the Friedberg Jump Theorem 6.4.1 we also had to code a set B. It
is easy to add this feature to the paradigm Theorem 14.2.1 whether or not
B ≥T ∅′. Given a sequence of strings, S = {σs}n∈ω, deﬁne the function
which codes the sequence to be gS(n) = σn.

14.2. The Finite Extension Paradigm
215
Theorem 14.2.2 (Finite Extension Coding Paradigm).
Fix a uniformly
c.e. sequence V = {Ve}e∈ω of c.e. sets and any set B ⊆ω.
(i) There exists a sequence S = {σs}s∈ω such that f = ∪s σs is V-generic
(forces every Ve) and
(14.6)
gS ≤T B ⊕∅′
&
gS ≤T A ⊕∅′.
(ii) If V = {We}e∈ω then f is 1-generic and A′ ≡T A ⊕∅′ ≡T B ⊕∅′.
Proof. Do the same as in Theorem 14.2.1 except that at stage s + 1 after
ﬁnding ρ ≻σs which decides Vs, let σs+1 = ρbB(s).
14.2.1
Finite Extension Games
It is useful to think of the method in the Finite Extension Paradigm The-
orem 14.2.1 as a modiﬁcation of the Banach-Mazur game in §14.1.3 with
the following changes.
1. Player I plays the sequence {σs}s∈ω of strings σs ≺σs+1, and deﬁnes
f = ∪s σs. (Player II plays none of the strings σs. The sequence
{σs}s∈ω is usually constructed computably in some oracle X, often
X = ∅′ or some related set such as X = D′ for some set D ⊆ω.)
2. Player II plays a u.c.e. sequence V = {Ve}e∈ω of c.e. sets Ve ⊆ω.
3. Player I wins if f forces Ve for every e.
4. A winning strategy for Player I is a function from ﬁnite positions
describing which string σs+1 to play next. (For example, the proof
of the Finite Extension Paradigm Theorem 14.2.1 yields a winning
strategy for Player I computable in ∅′.)
Deﬁnition
14.2.3. Constructions of the type in Finite Extension
Paradigm Theorem 14.2.1 and in the ﬁnite extension games are called ﬁ-
nite extension oracle constructions or sometimes Kleene-Post constructions
because of Kleene-Post [1954].
14.2.2
Exercises
Exercise 14.2.4. Show that every c.e. set A >T ∅bounds a 1-generic
set B. Hint. Fix a computable enumeration {As}s∈ω of A. Build a ∆2 set
B = lims Bs by a standard permitting argument so that B ≤ibT A as in
Theorem 5.2.7. Construct B to meet, as in (6.11), every e requirement,
Re :
(∃σ ≺A) [ σ ∈Ve
∨
(∀τ ≻σ) [ τ ̸∈Ve ] ]

216
14. Banach-Mazur Games
as follows. Let σ1 be the ﬁrst string (if any) which appears in Ve, say at
stage s1, and let x1 = (µy) [ σ1(y) ̸= Bs1(y) ]. Given σi, xi, and si for
i < j, xj > xj−1, sj > sj−1 and σj ∈Ve,sj such that σj ↾↾xj ≺Asj,
deﬁne fe(y) = Asj(y) for all y ≤xj. If At ↾↾xj ̸= Asj ↾↾xj for some j and
t > sj then A permits us to change Bt so that Bt+1 ≻σj. If not, then A is
computable via fe providing Ve is dense along B.

15
Gale-Stewart Games
15.1
Gale-Stewart Games and Open Games
Gale-Stewart games illustrate the applications of Π0
1-classes. In a Gale-
Stewart game there are two players who alternately choose elements ai ∈
{0, 1}. Player I chooses a0, then player II chooses a1, and so on. The inﬁnite
sequence f chosen, namely f(n) = an, is the particular play of the game.
We ﬁx ahead of time a set A ⊆2ω. In game G(A) player I wins if the
play f ∈A and II wins otherwise. A winning strategy for player I is a
function g on ﬁnite positions in the game, namely strings σ ∈2<ω of even
length (nodes at which I is to play), such that g(σ) ∈{0, 1} and if I follows
strategy g then he wins the game. Likewise, a winning strategy for player
II is deﬁned on strings σ of odd length (where Player II is to play), and
guarantees a win for player II. The game G(A) is determined if one player
or the other has a winning strategy. The ﬁrst easy theorem about these
games is that G(A) is determined if A is open, namely boldface Σ1. This
means that A = J A K for some set A ⊆ω as deﬁned in (8.2). We can
play as if this were an eﬀectively open set by ﬁxing the parameter A as an
oracle. We analyze the computable content of this game and the winning
strategies.
Theorem 15.1.1 (Gale-Stewart, 1953). If A ⊆2ω is open, then the game
G(A) is determined.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
 
217 
15

218
15. Gale-Stewart Games
Proof. Let A = J A K as in (8.2). Deﬁne an open set J B K ⊇J A K, namely a
certain A-c.e. set B ⊆2<ω, B ⊇A, by induction as follows,
(15.1)
σ ∈A
=⇒
σ ∈B
(15.2)
|σ| even
&
(∃i) [σbi ∈B ]
.
=⇒
σ ∈B
(15.3)
|σ| odd
&
(∀i) [σbi ∈B ]
.
=⇒
σ ∈B.
The set B represents the nodes σ from which Player I has a winning
strategy to eventually get into the open set A. In (15.1) if σ ∈A then
σ ∈B because Player I has already ensured that f ∈J A K. Now |σ| even
means that Player I is to play next. Therefore, if (15.2) holds, then there
is an immediate extension τ = σbi ∈B which Player I can play. Hence,
by moving from σ to τ ∈B Player I can ensure inductively that he has a
winning strategy from position σ. The case |σ| odd, namely Player II to
play, is similar but every extension τ = σbi must be in B or else Player II
can move to avoid nodes in B.
Note that B is an A-computably enumerable set. (This uses the com-
pactness of 2ω because in ωω for (15.3) we would have to examine inﬁnitely
many i before putting σ into B.) Choose an A-computable tree T such that
[T] = 2ω −J B K. If T is inﬁnite then Player II has a winning strategy g
which consists of always choosing nodes σ ̸∈B. This strategy g amounts
to choosing a path on [T]. This strategy is not necessarily A-computable
because although the tree T is A-computable, the tree of extendible nodes
T ext is only computable in A′ by the Eﬀective Compactness Theorem 8.5.1.
If the tree T is ﬁnite, then player I has a winning strategy h ≤T A.
15.1.1
Exercises
Exercise 15.1.2. Now assume that A is computable with χA = ϕk.
(i)
Prove that if Player I has a winning strategy h, then Player I has a
computable winning strategy.
(ii) Prove that if Player II has a winning strategy, then he has a winning
strategy g ≤T ∅′.
(iii)
Prove that if Player II has a winning strategy g then he has a low
winning strategy h, namely such that h′ ≡T ∅′. (You must consider the Π0
1
class of strategies for player II, not just the class of plays.)
(iv) (Slaman) Prove that (i) is not uniform. Use the Recursion Theorem
to prove there is no total computable function ψ such that for all k, if
χA = ϕk, then ψ(k) converges, and if Player I has a winning strategy then
ϕψ(k) is an eﬀective winning strategy for Player I.

15.1. Gale-Stewart Games and Open Games
219
15.1.2
Remarks on the Axiom of Determinacy
D.A. Martin [1975] proved determinacy for all Borel sets. The Axiom of
Determinacy (AD) asserts that all games are determined. The assumption
that deﬁnable sets are determined plays an important role in set theory. Full
AD contradicts the Axiom of Choice (AC) but nevertheless is an important
tool. A cone of degrees is a set of degrees of the form {d : d ≥a} for some
degree a.
Theorem 15.1.3 (Martin, 1968). If AD holds, then every set of degrees
either contains a cone or is disjoint from a cone.
Proof. Given a set A of degrees, let A∗be the class of sets whose degrees
are in A. Suppose Player I has a winning strategy for G(A∗). That strategy
has a degree a and every degree b ≥a must be in A. Choose any function
f ∈b, let Player II play according to f and Player I according to the
winning strategy. The ﬁnal outcome will be a function of degree b. The
outcome must be in A∗because Player I was following a winning strategy.
Hence, b ∈A. Similarly, if Player II has a winning strategy of degree d
then all degrees c ≥d lie in A.

16
More Lachlan Games
16.1
Increasingly Complicated Constructions
With the Kleene-Post [1954] paper on oracle constructions presented in
Chapter 6, and the ﬁnite injury computable approximations to them in
Friedberg [1957] and Muchnik [1956] presented in Chapter 7, constructions
in computability entered a new and much more complicated phase in the
1960s. Shoenﬁeld [1961] and independently Sacks [1963a, 1963c, and 1964a]
invented the inﬁnite injury method for constructing c.e. sets and degrees.
These inﬁnite injury constructions were very diﬃcult to read, even more so
because they were presented in the Kleene T predicate notation of Kleene’s
papers fashionable at the time. Lachlan [1966b] and independently Yates
[1966a] invented a still more diﬃcult inﬁnitary method, called the minimal
pair method, to construct a minimal pair of c.e. degrees.
By the middle of the 1960s computability theory was in danger of being
crushed by proofs which were so complicated that it was diﬃcult for a
reader to even verify them, much less extend them to new theorems. By
the late 1970s, Lachlan had invented an intuitive game theory model for
constructing c.e. sets which clearly revealed the intuition. This remains one
of the most important tools in the subject for understanding the material,
presenting theorems, and solving new problems.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_
 
221
16

222
16. More Lachlan Games
16.2
Lachlan Games in Computability Theory
Several kinds of games have played a role in computability theory. In the
Banach-Mazur game of Chapter 14, the players I and II alternately choose
ﬁnite sequences σ ∈2<ω to construct a set A = ∪sσs. Player I has a
winning stategy for forcing A into a target set A ⊆2ω iﬀA is comeager.
The Banach-Mazur game is particularly well suited to the ﬁnite exten-
sion constructions of a set A in Chapter 6 computable in some oracle X
because the sequence of strings {σs}s∈ω is X-computable. Therefore, we
can X-computably determine A(x) for every x. The Gale-Stewart game in
Chapter 15 is similar except that the strings must be of length 1.
These games are not suitable for a construction of a computable enumer-
able set A because the latter requires a computable construction with no
oracle X. After studying Martin’s advances [1970] on Gale-Stewart games
to study measurable cardinals and analytic games, Lachlan proposed a new
kind of game to analyze problems and to construct computably enumerable
sets. Lachlan [1970] observed that many theorems in computability theory
can be viewed as a game between two players, Player I (RED) and Player II
(BLUE). We refer the reader to the deﬁnition in §2.5 of a Lachlan game.
16.2.1
Playing Turing Reductions
This deﬁnition may seem too restrictive because in many theorems in com-
putability we may allow one or both players to construct other objects
such as partial computable (p.c.) functions, or Turing reductions ΦA
e (x),
e.g. in the Friedberg-Muchnik theorem, to meet a requirement such as
Re : B ̸= ΦA
e . However, no generality is lost because these objects can be
constructed as c.e. sets. For example, to deﬁne ϕe we enumerate the c.e.
set
graph (ϕe) := { ⟨x, y⟩: ϕe(x) = y }
which we deﬁned in Deﬁnition 2.1.7. Likewise, we can identify the Tur-
ing functional Φe with the c.e. set which is the oracle graph Ge from
Deﬁnition 3.3.7:
(16.1)
Ge := { ⟨σ, x, y⟩: Φσ
e (x) = y }.
To play a Turing functional we simply enumerate axioms of this type in the
oracle graph on moves during the game. Therefore, allowing the players to
each build inﬁnitely many c.e. sets is about as general as any theorem we
prove using computable constructions, and oracle constructions are simply
computable constructions relativized to the oracle. Therefore, these Lach-
lan games are as general as we need to prove most theorems about c.e.
sets.

16.3. Some Easy Examples of Lachlan Games
223
16.3
Some Easy Examples of Lachlan Games
We begin by analyzing some known theorems from preceding chapters in
terms of Lachlan games. Since BLUE has a winning strategy for these
games we can let RED play Vn = Wn without loss of generality. We give
the reference to the earlier mentioned result and sketch the winning strategy
for BLUE as a game.
16.3.1
Theorem 5.2.3: Post’s Simple Set
To prove Theorem 5.2.3 as a game we allow RED to play Un = Wn and
allow BLUE to play a single set A = V0 which he must guarantee is
coinﬁnite and satisﬁes for all e the requirement (5.1),
Pe :
|We| = ∞
=⇒
We ∩A ̸= ∅.
The method in Theorem 5.2.3 gives a winning strategy for BLUE to satisfy
Pe by waiting roughly until We,s ∩As = ∅and there is some x ∈We,s,
x > 2e. Then BLUE enumerates x into A. Theorem 5.2.5 gives a second
winning strategy for BLUE .
16.3.2
Theorem 5.2.7: Permitting a Simple Set A ≤T C
In Theorem 5.2.7 RED plays a noncomputable c.e. set C and {Wn}n∈ω
while BLUE plays a simple set A and a Turing reduction ΨC = A by
permitting. To ensure that C permits often enough for BLUE to satisfy
every Pe requirement, BLUE also plays for every e a p.c. function ge.
Suppose that some requirement Pe fails because We is inﬁnite but We∩A =
∅. Then, as in Lemma 5.2.8, with each new element x appearing in We,
BLUE extends ge(y) on arguments y ≤x and C ↾x will not later change.
Hence, C is computable.
(Note that the blue function ge is rarely explicitly mentioned in proofs
of this theorem, but it is implicit in any such proof because it shows how
BLUE can force a given We to eventually permit. There are often such
implicit elements in proofs which the Lachlan game makes explicit and
provides a method to resolve the conﬂict.)
16.3.3
Theorem 7.4.1: A Simple Set A ̸≥T C
In this theorem RED plays a noncomputable c.e. set C and a Turing reduc-
tion Φe while BLUE plays a noncomputable (say simple) c.e. set A such
that ΦA
e ̸= C. To assist in this, BLUE again plays a computable function
ge and attempts to preserve agreements between ΦA
e and C while ge records
these agreements. If RED allows these agreements to go to inﬁnity, then
BLUE achieves ge = C, refuting the hypothesis that C is noncomputable.

224
16. More Lachlan Games
16.3.4
Friedberg-Muchnik Theorem 7.3.1
RED plays Turing functional Φe and BLUE plays c.e. sets A and B. For
e even, BLUE wants to satisfy the requirement Re : A ̸= ΦB
e , and vice
versa for e odd. To aid in meeting requirement Re, BLUE builds a wall
of restraint r(e, s), not allowing any element x < r(e, s) to enter B for the
sake of any lower priority requirement Rj, j > e. At some stage t, BLUE
chooses a fresh element x > t, and therefore x > r(i, s) for all higher
priority i < e. BLUE waits until, if ever, Φe(x)[s]↓= 0 for some s > t. He
puts x into A and deﬁnes r(e, s) = s to preserve the computation.
This restraint is not an oﬃcial element of the Lachlan game, but rather
an internal notation to aid BLUE. This strategy ensures that BLUE’s
action will be injured at most ﬁnitely often and he will eventually succeed
in meeting every requirement.

Part V
History of Computability

17
History of Computability
17.1
Hilbert’s Programs
Around 1880, Georg Cantor, a German mathematician, invented naive set
theory. A small fraction of this is sometimes taught to elementary school
children. It was soon discovered that this naive set theory was inconsistent
because it allowed unbounded set formation, such as the set of all sets.
David Hilbert, the world’s foremost mathematician from 1900 to 1930, de-
fended Cantor’s set theory but suggested a formal axiomatic approach to
eliminate the inconsistencies. He proposed two programs. First, Hilbert
wanted an axiomatization for mathematics, beginning with arithmetic,
and a ﬁnitary consistency proof of that system. Second, Hilbert suggested
that the statements about mathematics be regarded as formal sequences of
symbols, and his famous Entscheidungsproblem (decision problem) was to
ﬁnd an algorithm to decide whether a statement was valid or not. Hilbert
characterized this as the fundamental problem of mathematical logic.
Hilbert retired and gave a special address in 1930 in K¨onigsberg, the city
of his birth. Hilbert spoke on the importance of mathematics in science
and the importance of logic in mathematics. He asserted that there are
no unsolvable problems and stressed, “We must know. We will know.” At
a mathematical conference preceding Hilbert’s address, a quiet, obscure
young man, Kurt G¨odel, only a year beyond his Ph.D. in 1931, refuted
Hilbert’s consistency program with his famous incompleteness theorem and
changed forever the foundations of mathematics. G¨odel soon joined other
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4_17 
227

228
17. History of Computability
leading ﬁgures, Albert Einstein and John von Neumann, at the Institute
for Advanced Study in Princeton.
17.2
G¨odel, Church, and Recursive Functions
The refutation of Hilbert’s ﬁrst program on consistency gave hope for re-
futing his second program on the Entscheidungsproblem. However, this was
no ordinary problem in number theory or analysis. To prove the unsolv-
ability of a certain problem, such as Hilbert’s famous Tenth Problem on
Diophantine equations of 1900, one must: (1) ﬁnd a precise mathematical
deﬁnition for the intuitive idea of algorithm; (2) demonstrate beyond doubt
that every algorithm has been captured; (3) prove that no algorithm on the
list can be the solution of the Diophantine equation problem.
Work began independently at Princeton and Cambridge. Alonzo Church
completed an A.B. degree at Princeton in 1924 and his Ph.D. degree there
under Oswald Veblen in 1927. Church joined the Department of Mathemat-
ics at Princeton from 1929 until his retirement in 1967, when he moved to
UCLA. Church worked from 1931 through 1934 with his graduate student,
Stephen Cole Kleene, on the formal system of λ-deﬁnable functions. They
had such success that in 1934 Church proposed privately to G¨odel that a
function is eﬀectively calculable (intuitively computable) if and only if it
is λ-deﬁnable. G¨odel rejected this ﬁrst version of Church’s Thesis. In addi-
tion, Kleene reported “chilly receptions from audiences around 1933–35 to
disquisitions on λ-deﬁnability.”
However, in the spring of 1934 G¨odel lectured on recursive functions.
By 1935 Church and Kleene had moved enthusiastically to the formalism
of G¨odel’s recursive functions as a vehicle to capture the intuitive idea
of eﬀectively calculable. In 1931 G¨odel had used the primitive recursive
functions, those where one computes a value f(n) by using previously com-
puted values f(m), for m < n, such as the factorial function f(0) = 1 and
f(n + 1) = (n + 1) · f(n).
In his 1934 lectures at Princeton, G¨odel extended this to the (Herbrand-
G¨odel) (general) recursive functions. Church eagerly embraced them and
formulated his famous Church’s Thesis in [Church 1935] and [Church 1936]
that the eﬀectively calculable functions coincide with the recursive func-
tions. Again, G¨odel failed to accept this thesis even though he was the
author of the recursive functions. G¨odel noted that recursive functions are
clearly eﬀectively calculable, but the converse “cannot be proved, since the
notion of ﬁnite computation is not deﬁned, but it serves as a heuristic
principle.”

17.2. G¨odel, Church, and Recursive Functions
229
17.2.1
The Concept of Recursion
The term recursion refers to a function f deﬁned by induction. We ﬁrst
deﬁne f(0) and then deﬁne f(x+1) in terms of previously deﬁned functions
using as inputs x and f(x). For example, the factorial function f(x) = x!
is deﬁned by the recursion schemes
(17.1)
f(0) = 1
and
f(x + 1) = (x + 1) · f(x),
where we assume that multiplication has been previously deﬁned. Dedekind
in [Dedekind 1888] showed that certain functions could be uniquely deﬁned
by recursion. The concept of recursion gradually developed during the early
1900s particularly in the work of [Skolem 1923], [Hilbert 1926] and espe-
cially [G¨odel 1931]. Many logic papers may be found in the source book
[van Heijenoort 1967].
17.2.2
The Primitive Recursive Functions
Up until the early 1930s, the term “recursive function” meant what we now
call a primitive recursive function to distinguish it from the Herbrand-G¨odel
general recursive function deﬁned in §17.2.4. In 1931 G¨odel used primitive
recursive functions in the proof of his famous incompleteness theorem and
called them simply by the German term “rekursiv.” The main property
of recursion is the primitive recursion scheme (V) below, which yields an
inductive deﬁnition of f(n + 1) using the preceding value f(n) and previ-
ously deﬁned functions g and h. [Kleene 1952] put the primitive recursive
functions in the following succinct form which has become standard.
Deﬁnition 17.2.1. The class of primitive recursive functions is the least
class C of functions closed under the following Schemes (I)–(V).
(I) The successor function f(x) = (x + 1) is in C.
(II) The constant functions f(x1, . . . , xn) = m are in C, 0 ≤m, n.
(III) The identity functions f(x1, x2, . . . xn) = xi, 1 ≤i ≤n, are in C.
(IV) (Composition)
If g1, g2, . . . , gm, h ∈C, then
f(x) = h(g1(x), . . . , gm(x))
is in C, where g1, . . . , gm are functions of n variables, x = (x1, . . . , xn), and
h is a function of m variables.
(V) (Primitive Recursion)
If g, h ∈C and n ≥1, then f ∈C where
f(0, x) = g(x)
f(x1 + 1, x) = h(x1, f(x1, x)x)
where x = (x2, . . . , xn), the n−1 variables treated as parameters, assuming
g and h are functions of n −1 and n + 1 variables, respectively, and f is

230
17. History of Computability
a function of n variables. (In case n = 1, a 0-ary function is a constant
function which is in C by Scheme (II).)
Therefore, a function f is primitive recursive iﬀthere is a derivation,
namely a sequence f1, f2, . . . , fk = f such that each fi,
i ≤k, is either
an initial function (i.e., is obtained by Schemes (I), (II), or (III)), or fi is
obtained from {fj : j < i} by an application of Scheme (IV) or (V). For
example, the function f(x1, x2) = x1 + x2 has the following derivation.
f1(x) = x + 1
by (I)
f2(x) = x
by (III)
f3(x1, x2, x3) = x2
by (III)
f4 = f1 ◦f3
by (IV)
f5(0, x2) = f2(x2)
f5(x1 + 1, x2) = f4(x1, f5(x1, x2), x2)
by (V)
Similarly, [Kleene 1952] showed that all the usual functions on ω are
primitive recursive, including x·y, xy, x! and limited subtraction x monus
y,
x .−y
:=



x −y
if x ≥y,
0
if x < y.
Deﬁnition 17.2.2. (Characteristic Functions). (i) Let χA(x) denote the
characteristic function of A, i.e., χA(x) = 1 if x ∈A and χA(x) = 0
otherwise. For convenience, we often write A(x) for χA(x). The character-
istic function for a relation R(x1, x2, . . . xk) is the function χR such that
χR(x1, x2, . . . xk) = 1 if R(x1, x2, . . . xk) holds and χR(x1, x2, . . . xk) = 0
otherwise.
(ii) A predicate (i.e., a relation) is primitive recursive (computable) if its
characteristic function is primitive recursive (computable).
For example, it can be shown that the relation R = {x : x is prime} is
primitive recursive. Let p0, p1, . . . be the prime numbers in increasing order.
Any x ∈ω has a unique representation
(17.2)
x = px0
0 px1
1
. . . pxn
n
. . . ,
where ﬁnitely many xi ̸= 0. It can be shown that the function
(17.3)
(x)i = xi
is a primitive recursive function of x and i. Thus, for any ﬁnite sequence
of nonzero integers {a0, a1, . . . , an} there is a unique “code” number a =
pa0
0 . . . pan
n such that each ai = (a)i can be obtained primitively recursively
from a. G¨odel and later Kleene used this prime power coding to give a G¨odel
number to syntactical objects such as proofs or derivations of recursive
functions.

17.2. G¨odel, Church, and Recursive Functions
231
17.2.3
Nonprimitive Recursive Functions
Most of the usual number-theoretic functions in ordinary mathematics are
primitive recursive as is shown in [Kleene 1952]. Therefore, primitive recur-
sive functions are a good ﬁrst approximation to algorithmic functions, but
they do not comprise all algorithmic functions. First, primitive recursive
functions are total, and they can be eﬀectively listed. Therefore, a diagonal
argument produces an eﬀectively calculable function which is not primitive
recursive. Second, the primitive recursive functions do not even include all
possible recursions. Scheme (V) allowed recursion on only one variable.
The following Ackermann generalized exponential is deﬁned by simultane-
ous induction on two variables. Hermes [1969] shows it is not primitive
recursive because it dominates every primitive recursive function.
f(0, 0, y)
=
y,
f(0, x + 1, y)
=
f(0, x, y) + 1,
f(1, 0, y)
=
0,
f(z + 2, 0, y)
=
1,
f(z + 1, x + 1, y)
=
f(z, f(z + 1, x, y), y).
This function is deﬁned informally as in [Rogers 1967] as follows.
f(0, x, y) = y + x
f(1, x, y) = y · x
f(n + 1, x, y) = the result of applying y to itself x times
under the nth level operation λuv[f(n, u, v)].
For example, multiplication y · x is the result of adding y to itself x
times, exponentiation yx is the result of multiplying y by itself x times, and
the Ackermann function generalizes this notion through all levels n ∈ω.
[Hermes 1969] reduced Ackermann’s main idea to the following example,
h(x, y), where z′ denotes z + 1.
h(0, y) =
y′
h(x′, 0) =
h(x, 1)
h(x′, y′) =
h(x, h(x′, y)).
(17.4)
This system of equations unambiguously deﬁnes an algorithmically com-
putable function by recursion. The key diﬀerence here is the third line,
which uses simultaneous recursion on x and y and cannot be duplicated by
primitive recursion. [Hermes 1969] proved that for every primitive recursive
function g(x1, · · · , xn) there is a number c such that
(∀x1) · · · (∀xn) [ g(x1, x2, · · · , xn) < h(c, x1 + x2 + · · · + xn) ].

232
17. History of Computability
This is proved by induction on the number of primitive recursive schemes
deﬁning g. Hence, h cannot be primitive recursive.
Ackermann’s function poses another serious problem. Clearly, the func-
tions deﬁned by multiple simultaneous recursions are algorithmically
computable, but how do we deﬁne them? If we allow simultaneous recur-
sion on (n + 1) variables then we can produce a function not deﬁnable by
recursion on only n variables. Therefore, it is not clear how to generalize
Scheme (V) to capture even those functions deﬁned by recursion, much less
the algorithmically computable ones.
17.2.4
Herbrand-G¨odel Recursive Functions
A succinct characterization of all functions deﬁned by recursion, including
partial ones, was achieved in [G¨odel 1934]. He had used the primitive re-
cursive functions in the proof of his incompleteness theorem in 1931, but
he realized they did not constitute all eﬀectively calculable functions. In
the spring of 1934 G¨odel gave a series of lectures at Princeton in which
he introduced what he called the general recursive functions to distinguish
them from the primitive recursive functions which up to that time had
been called “recursive functions.” G¨odel reﬁned a suggestion of Herbrand.
Hence, these are called (Herbrand-G¨odel) general recursive functions or
simply recursive functions.
We avoid the formal deﬁnition (see [Kleene 1952]) but informally sketch
the idea. Consider the equations of (17.1) which deﬁne the factorial func-
tion, f(0) = 1 and f(x+1) = (x+1)·f(x). Roughly, let the formal language
L consist of nonlogical symbols: a unary function symbol S for successor,
and the constant symbol 0 for 0. Let numeral k denote the term Sk(0). In
addition, L has a variety of function letters, one of which, F, is called the
principal function letter, corresponding to the informal function f being
deﬁned. We write the system of equations EF to deﬁne F:
(17.5)
F(0) = 1
and
F(x + 1) = G((x + 1), F(x)).
Here we assume that a previously speciﬁed system of equations EG deﬁnes
multiplication g(x, y) = x · y. The rules for deriving new equations from
those in (17.5) are the following.
R1 Substitution of a numeral for every occurrence of a particular variable
in an equation.
R2 Replacement in the right-hand side of an equation of a term of the
form H(c) by a numeral d, provided that H(c) = d has already been derived
and H is a function letter (such as F or G in our example of the factorial
function).

17.2. G¨odel, Church, and Recursive Functions
233
Deﬁnition 17.2.3. [G¨odel, 1934] A (partial) function f on the integers is
(Herbrand-G¨odel) general recursive (usually abbreviated recursive) if there
is a ﬁnite system of equations E with principal function letter F such that
f(n) = m if and only if we can derive F(n) = m from E using the rules R1
and R2.
It is easy to see how to derive any value of the factorial function f(x) = y
as an equation F(x) = y, and indeed to show that all the primitive recur-
sive functions are (Herbrand-G¨odel) general recursive. The calculations are
natural in that they closely resemble those a mathematician would make
with pencil and paper calculating the same values. The main point is that
these two simple rules give a formal characterization which captures the
notion of all recursions even for partial functions.
Herbrand had written G¨odel a letter in 1931 describing systems of equa-
tions which uniquely deﬁne a (partial) function. In 1934 G¨odel made
two restrictions on this deﬁnition to make it eﬀective, ﬁrst that the left-
hand sides of the functional equations be in standard form with F being
the outermost symbol, and second that for each set of natural numbers
n1, . . . nj there exists a unique m such that F(n1, . . . nj) = m is a de-
rived equation (see [Sieg 1994]). In 1936, 1943, and 1952 Kleene introduced
variants of G¨odel’s two rules, which give an equivalent formulation of the
Herbrand-G¨odel deﬁnition.
In the initial deﬁnitions and advances for computability from 1931 to
1937 researchers considered only total computable functions as is com-
mon in other branches of mathematics. It was [Kleene 1938] who ﬁrst
proposed considering partial computable functions and this helped resolve
some diﬃculties.
17.2.5
Kleene’s µ-Recursive Functions
[Kleene 1936] adapted G¨odel’s 1931 method of arithmetization of syn-
tax to give Scheme (VI), which, together with primitive recursive
Schemes (I)–(V), gives an alternative and useful characterization of the
general recursive functions.
Deﬁnition 17.2.4. (Kleene, 1936).
The class C of µ-recursive (partial)
functions is the least class obtained by closing under Schemes (I)–(V) for
the primitive recursive functions and the following Scheme (VI).
(VI)
(Unbounded Search)
If θ(x, y) ∈C is a partial function, and
(17.6)
ψ(x) = (µy) [ θ(x, y)↓= 1
&
(∀z < y) [ θ(x, z)↓̸= 1 ] ],
then ψ is in C. (Here ψ(x) diverges if there is no such y. Hence, ψ may be
nontotal.)
To see that partial algorithmic functions are closed under Scheme (VI),
ﬁx x and a partial function θ(x, y) for which we have an algorithm. Now

234
17. History of Computability
compute in order θ(x, y) for y = 0, y = 1, . . . , and do not proceed to y + 1
until (if ever) the computation for y converges. If there is a ﬁrst y with
θ(x, y)↓= 1, then output y. Otherwise, continue forever.
The µ-recursive functions give a compact, mathematically appealing
deﬁnition and they are useful for proving the Kleene Normal Form
Theorem.
Theorem 17.2.5 (Kleene Normal Form Theorem). There exists a pred-
icate T(e, x, y) (called the Kleene T-predicate) and a function U(y) both
primitive recursive such that, for every e,
ψe(x) = (µy) T(e, x, y),
where {ψe}e∈ω is an eﬀective listing of all partial recursive functions.
This proves that the µ-recursive partial functions include all partial re-
cursive functions. However, proving that a nonprimitive recursive function
(such as the Ackermann function) is µ-recursive requires ﬁrst using the
G¨odel 1931 arithmetization method and then applying Scheme (VI). Fur-
thermore, arithmetization is very tedious. In contrast, Turing programs can
be decomposed into submodules and often give a more perspicuous demon-
stration that a function is computable. [Church 1936] and [Kleene 1936b]
proved that the classes of general recursive functions and λ-deﬁnable func-
tions are the same. Kleene also proved the equivalence with the µ-recursive
functions.
17.2.6
G¨odel Remained Unconvinced
By 1934 Kleene had shown that a large class of number-theoretic func-
tions were λ-deﬁnable. On the strength of this evidence, Church informally
proposed to G¨odel around March 1934 that the notion of “eﬀectively calcu-
lable” be identiﬁed with “λ-deﬁnable,” a suggestion which G¨odel rejected
as “thoroughly unsatisfactory,” according to Martin Davis’s account. After
hearing G¨odel’s lectures in 1934 on the general recursive functions Church
changed the formal deﬁnition from “λ-deﬁnable” to “recursive,” his ab-
breviation for Herbrand-G¨odel general recursive, and Church presented on
April 19, 1935 to the American Mathematical Society his famous proposi-
tion published in [Church 1936] and known since [Kleene 1952] as Church’s
Thesis, which asserts that the eﬀectively calculable functions should be
identiﬁed with the recursive functions.
G¨odel, however, remained unconvinced of the validity of Church’s Thesis
through its publication in [Church 1936]. This is all the more signiﬁcant,
ﬁrst, because G¨odel had originated the formalism of the general recur-
sive functions, the one upon which Church based his thesis, and the one
which captured the notion of all recursions; and second, because much of
the evidence for Church’s Thesis rested on the coincidence of these formal

17.3. Turing’s Analysis
235
classes (general recursive functions, µ-recursive functions, and λ-deﬁnable
functions), and this was based largely on Kleene’s use in Scheme (VI) of
arithmetization, the method that G¨odel himself had introduced so dramat-
ically in his 1931 incompleteness theorem. Until seeing Turing’s 1936 paper
G¨odel was “not at all persuaded.”
17.3
Turing’s Analysis
17.3.1
Turing’s Discovery
Independently, Turing attended lectures in 1935 at Cambridge University
by topologist M.H.A. (Max) Newman on G¨odel’s paper [1931] and Hilbert’s
Entscheidungsproblem. A year later, Turing submitted his solution to the
incredulous Newman on April 15, 1936. Turing’s paper [Turing 1936] was
distinguished because: (1) Turing analyzed an idealized human computing
agent—call it a “computor”—which brought together the intuitive concep-
tions of a “function produced by a mechanical procedure” that had been
evolving for more than two millennia from Euclid to Leibniz to Babbage
and Hilbert; (2) Turing speciﬁed a remarkably simple formal device (Tur-
ing machine) and demonstrated the equivalence of (1) and (2); (3) Turing
proved the unsolvability of Hilbert’s Entscheidungsproblem, which promi-
nent mathematicians had been studying intently for some time; (4) Turing
proposed a universal Turing machine, one which carried within it the ca-
pacity to duplicate any other, an idea which was later to have great impact
on the development of high-speed digital computers and to have consid-
erable theoretical importance. As a boy, Turing had been fascinated by
his mother’s typewriter. He devised his Turing machine as a kind of ideal-
ized typewriter with a reading head moving over a ﬁxed unbounded tape
or platen1 on which the head writes. Turing’s model was by far the most
convincing then and now. From 1936 to 1938 Turing completed his Ph.D.
at Princeton under Church. His Ph.D. thesis was on a diﬀerent topic but
contained a crucial idea (5), that of a local machine communicating with a
database, the same mechanism we use today when a laptop communicates
with the Internet.
1The platen is the cylindrical roller in a typewriter against which the paper is held. In
1930 the typing head was ﬁxed in the center and the platen and a carriage moved back
and forth under it as the keys struck the platen. By 1980 the IBM Selectric typewriter
had a ﬁxed carriage and a movable writing ball which passed back and forth across the
platen. This was Turing’s design in 1936. I do not know whether IBM paid royalties to
Turing’s estate.

236
17. History of Computability
17.3.2
G¨odel Accepts Turing’s Analysis
G¨odel enthusiastically accepted Turing’s analysis and always thereafter
gave Turing credit for the deﬁnition of mechanical computability. For the
Princeton Bicentennial he wrote [G¨odel 1946], “one [Turing] has for the ﬁrst
time succeeded in giving an absolute deﬁnition of an interesting epistemo-
logical notion, i.e., one not depending on the formalism chosen.” G¨odel also
wrote, “That this really is the correct deﬁnition of mechanical computabil-
ity was established beyond any doubt by Turing.” Church wrote that of the
three notions—computability by a Turing machine, general recursiveness
of Herbrand-G¨odel-Kleene, and lambda-deﬁnability—“The ﬁrst has the ad-
vantage of making the identiﬁcation with eﬀectiveness in the ordinary (not
explicitly deﬁned) sense evident immediately, i.e., without the necessity of
proving preliminary theorems.”
Later G¨odel explained why he had accepted Turing’s analysis so com-
pletely. For G¨odel the essential point was to deﬁne what a procedure is. He
believed that Turing had done this, but in 1935 he was not convinced that
his own deﬁnition of recursive functions accomplished this.
In the Nachlass printed in Volume III of [G¨odel 1995], page 166, G¨odel
wrote,
When I ﬁrst published my paper about undecidable proposi-
tions the result could not be pronounced in this generality,
because for the notions of mechanical procedure and of for-
mal system no mathematically satisfactory deﬁnition had been
given at that time.. . . The essential point is to deﬁne what a
procedure is.
G¨odel believed that Turing in 1936 had done so, but G¨odel was not con-
vinced by Church’s argument in 1936 for recursive functions. By 1937, the
three deﬁnitions of computable functions had been proved mathematically
equivalent so the deﬁnitions are extensionally equivalent but not intension-
ally equivalent. Turing’s analysis is regarded as the most convincing and
is the one on which most modern texts make the formal deﬁnition of a
computable function.
17.3.3
Turing’s Thesis: Deﬁnition or Theorem
Turing’s claim in 1936 was that a function is intuitively computable if and
only if it is computable by a Turing machine. He gave evidence for this claim
in Sections 1 and 9. Simultaneously, Church claimed in 1936 that a function
is eﬀectively calculable iﬀit is Herbrand-G¨odel recursive. Neither statement
was intended as a thesis, but rather as a claim with a demonstration, al-
beit one relating an intuitive concept to a formal deﬁnition. Unfortunately,
Kleene referred to these in his inﬂuential book [Kleene 1952] as “Church’s
Thesis” and “Turing’s Thesis,” implying that there might be some ele-

17.3. Turing’s Analysis
237
ment of debate about them. Church’s demonstration was somewhat less
convincing than Turing’s so we restrict attention here to Turing’s.
The English term “thesis” comes from the Greek word θ´ϵασις, meaning
“something put forth.” In logic and rhetoric it refers to a “proposition laid
down or stated, especially as a theme to be discussed and proved, or to be
maintained against attack.” It can be a hypothesis presented without proof,
or it can be an assertion put forward with the intention of defending and
debating it. The Harvard College Writing Center notes online says that a
thesis is “not a topic; nor is it a fact; nor is it an opinion.” A theorem such
as the G¨odel Completeness Theorem is not a thesis. It is a fact with a proof
in a formal axiomatic system which cannot be refuted. Attaching the term
“thesis” to such a proposition invites continual reexamination. It signals to
the reader that the proposition may not be completely valid, but rather it
should continually be examined more critically.
This is not a question of mere semantics, but about what Turing actually
achieved. If we use the term “thesis” in connection with Turing’s work, then
we are continually suggesting some doubt about whether he really gave an
authentic characterization of the intuitively calculable functions. The cen-
tral question about Turing’s work in 1936 is whether Turing demonstrated
his assertion beyond any reasonable doubt, or whether it is merely a thesis,
in need of continual veriﬁcation. Neither Church nor Turing ever referred to
their 1936 characterizations of eﬀectively calculable functions as a “thesis.”
They thought of them as claims with demonstrations.
Turing’s last published paper [Turing 1954] discussed puzzles. Turing
wrote of his central assertion (about a function being eﬀectively calculable
iﬀit is computable by a Turing machine) that this assertion lies somewhere
between a theorem and a deﬁnition.
In so far as we know a priori what is a puzzle and what is not,
the statement is a theorem. In so far as we do not know what
puzzles are, the statement is a deﬁnition that tells us something
about what they are.
In any case, most scholars agree that it is not a thesis, which in English
weakens the claim to something in need of debate or continual veriﬁcation.
Nevertheless, we sometimes use the term “Turing’s Thesis” to identify the
claim because since [Kleene 1952] it has been referred to as such in the
literature.
17.3.4
Turing’s Demonstration of Turing’s Thesis
Since the beginning of the Entscheidungsproblem the study of computabil-
ity had been tied to formal axiomatic systems. G¨odel’s 1931 incompleteness
theorem had been about axiomatic systems extending arithmetic. His re-
cursive functions were in fact formal systems with a ﬁnite set of equations
as axioms and two rules of inference for deriving new equations. Church

238
17. History of Computability
followed this axiomatic approach. Church in [Church 1936] attempted
to demonstrate that any eﬀectively calculable function was derivable
in a certain formal system, and that any function derivable there was
Herbrand-G¨odel recursive. G¨odel was not completely convinced by this
demonstration.
Turing took a completely diﬀerent approach. Turing was a marathon
runner. After a run one day he lay down in a meadow to rest and the idea
of a Turing machine came to him. He reduced the mechanical process to
its smallest parts as described in Chapter 1. What is remarkable is not
only the deﬁnition of the Turing machine but also the demonstration in
[Turing 1936], Section 9, that it captures the idea of eﬀectively calculable
functions. We have reproduced this demonstration in Chapter 1 before
presenting the Turing machine deﬁnition.
In this masterful demonstration, which Robin Gandy considered as pre-
cise as most mathematical proofs, Turing analyzed the informal nature of
functions computable by a ﬁnite procedure and demonstrated that they
coincide with those computable by an a-machine. Gandy, in [Gandy 1988],
page 82 of Herken’s book [Herken 1988], observed,
Turing’s analysis does much more than provide an argument
for Turing’s Thesis; it proves a theorem.
Furthermore, Gandy continued, “Turing’s analysis makes no reference
whatsoever to calculating machines. Turing machines appear as a result, a
codiﬁcation, of his analysis of calculations by humans.”
Wittgenstein remarked about Turing machines, “These machines are hu-
mans who calculate.” Turing’s achievement was to determine not what
machines could compute, but what human beings could compute with
enough resources of time and space for the computation.
17.4
Turing’s Oracle Machine (o-Machine)
17.4.1
An Extraordinary but Almost Incidental Discovery
One of Turing’s most important inventions, that of an oracle machine, ap-
peared very brieﬂy in Section 4 of [Turing 1939]. It was an aside and was
unnecessary. Turing’s oracle machine was developed by Post into Turing re-
ducibility and other reducibilities. Turing reducibility allows us to measure
the information content and complexity of structures and sets. It is cru-
cially important in computability theory, because it subsumes the ordinary
Turing machine and much more. Today the notion of a local machine in-
teracting with a remote database or remote machine is central to practical
computing.

17.4. Turing’s Oracle Machine (o-Machine)
239
After Turing’s a-machine discovery in April, 1936, Max Newman at
Cambridge suggested that Turing go to Princeton to study with Church.
Turing completed his Ph.D. at Princeton under Church from 1936–1938.
Many mathematicians found G¨odel’s Incompleteness Theorem unsettling.
Turing’s dissertation, published as [Turing 1939], was on ordinal logics, ap-
parently a suggestion of Church, and was an attempt to get around G¨odel’s
incompleteness theorem by adding new axioms. If T1 is a consistent exten-
sion of Peano arithmetic, then the arithmetical sentence σ1 asserting the
unprovability of itself is independent of T1 but we can form a new theory
T2 = T1 ∪{σ1} which strictly extends T1. One can continue this sequence
through all the computable (constructive) ordinals.
17.4.2
Turing’s Use of Oracle Machines
In one of the most important and most obscure parts of all of computability
theory, Turing wrote in section 4 of [Turing 1939] a short statement about
oracle machines.
Let us suppose we are supplied with some unspeciﬁed means of
solving number-theoretic problems; a kind of oracle as it were.
. . . This oracle . . . cannot be a machine.
With the help of the oracle we could form a new kind of ma-
chine (call them o-machines), having as one of its fundamental
processes that of solving a given number-theoretic problem.
Turing introduced oracle machines for a very speciﬁc purpose. In the pre-
ceding Section 3, Turing had considered Π2 predicates (∀∃-predicates over
a computable matrix), and had shown that the Riemann Hypothesis and
other common problems were Π2, which Turing called “number-theoretic.”
For example, the question of whether a Turing a-machine computes a par-
tial function with inﬁnite domain is Π2. More precisely, let ϕe be the
partial computable function computed by the Turing program Pe with
G¨odel number e and let We be the domain of ϕe. Now We is a Σ1-set.
Deﬁne
Inf
=
{ e : We is inﬁnite }.
Now Inf is Π2, and in fact Π2-complete, i.e., for every Π2 set V there is a
computable function f such that x ∈V iﬀf(x) ∈Inf.
Turing invented oracle machines to construct a set which was not Π2.
This could easily have been accomplished by a diagonal argument with-
out oracle machines. Turing put the oracle Inf on the oracle tape. By the
same diagonal argument as in [Turing 1936] for a noncomputable function
he used the oracle machine to construct a non-Π2 set. Turing wrote in
[Turing 1939]

240
17. History of Computability
Given any one of these machines we may ask the question
whether it prints an inﬁnity of ﬁgures 0 or 1; I assert that this
class of problem is not number-theoretic [i.e., Π2].
In his analysis of [Turing 1939], [Feferman 2007] page 1204 wrote,
In Section 4 Turing introduced a new idea that was to change
the face of the general theory of computation (also known as
recursion theory) but the only use he made of it was curiously
inessential. His aim was to produce an arithmetical problem
that is not number-theoretic in his sense, i.e., not in ∀∃-form.
This is trivial by a diagonalization argument, since there are
only countably many eﬀective relations R(x, y) of which we can
say that ∀x∃yR(x, y) holds. Turing’s way of dealing with this,
instead, is through the new notion of computation relative to
an oracle.. . .
“He then showed that the problem of determining whether an
o-machine terminates on any given input is an arithmetical
problem not computable by any o-machine, and hence not solv-
able by the oracle itself. Turing did nothing further with the
idea of o-machines, either in this paper or afterward.”
For a ﬁxed set A ⊆ω, the set of positive integers, eﬀectively number all
Turing oracle programs. Let ΦA
e (x) denote the partial function computed
by the o-machine with G¨odel number e and with A on the oracle tape.
Deﬁne the relative halting set
(17.7)
KA
=
{ e : ΦA
e (e) halts }.
Theorem 17.4.1 (Turing 1939, page 173). Given A the set KA is not
computable in A.
Turing had shown in [Turing 1936] that there is a diagonal set not com-
putable by a Turing a-machine. The same proof on o-machines relativized
to A establishes the theorem. His speciﬁc application is that if A = Inf,
then KA is not Π2. In 1939 Turing left the topic of oracle machines, never
to return to it. It mostly lay dormant for ﬁve years until it was developed
in a beautiful form by Post in 1944 and 1948, and by Kleene and Post in
1954 and in other papers.
17.4.3
Kleene’s Deﬁnition of “General Recursive In”
Kleene in [Kleene 1943], page 44, gave a deﬁnition of “general recursive
in.” Kleene wrote,
A function ϕ which can be deﬁned from given functions
ψ1, . . . , ψk by a series of applications of general recursive
schemata we call general recursive in the given functions; and

17.5. Emil Post’s Contributions
241
in particular, a function deﬁnable ab initio by these means we
call general recursive.
Kleene was thinking of auxiliary functions used in some Herbrand-G¨odel
computation, where the functions are all recursive, such as multiplication
being used in the deﬁnition of factorial. It is possible that Kleene thought
of an inﬁnite nonrecursive oracle A as the auxiliary function ψ, and the
result a function ψ which interrogates A as an external database during
the computation. If so, Kleene would surely have cited Turing [1939, §4],
where this idea ﬁrst appeared. There is no evidence in Kleene [1943] that
Kleene thought this way. The notion of “general recursive in” or relative
recursive does not appear again in [Kleene 1943].
Both Turing in 1939 and Kleene in 1943 very brieﬂy alluded to a com-
putation using an external set A, but neither developed the idea of relative
computablity. That was done by Post in 1944. Soare in [Soare 2009] an-
alyzes how the Turing oracle machine also gives a model for modern
interactive computing where a local computer like a laptop communicates
with an external database such as one on the Internet.
17.5
Emil Post’s Contributions
More than a decade older than the others, Emil Post was the oldest prin-
cipal reseacher in computability theory among G¨odel, Church, Turing, and
Kleene in the 1930s. In 1936 Post was teaching at City College in New York
and had been in touch with Church and was aware of [Church 1936]. Inde-
pendently of Turing, Post proposed in [Post 1936] a remarkably similar
computing model. His paper “Finite Combinatory Processes, Formula-
tion I” proposed a discrete machine almost identical to Turing’s model,
composed of boxes which could be blank or contain a mark. On a single
step the worker could determine whether the box observed is marked or
not; mark it or erase a mark; and move one box to the left or right.
From this it is often and erroneously written that Post’s contribution
here was “essentially the same” as Turing’s, but, in fact, it was much less.
Post did not attempt to prove that his formalism coincided with any other
formalism, such as general recursiveness, but merely expressed the expec-
tation that this would turn out to be true, while Turing in [Turing 1937b]
proved the Turing computable functions equivalent to the λ-deﬁnable ones.
Post gave no hint of a universal Turing machine. Most important, Post
gave no analysis, as did Turing, of why the intuitively computable func-
tions are computable in his formal system. Post oﬀers only as a “working
hypothesis” that his contemplated “wider and wider formulations” are “log-
ically reducible to formulation 1.” Lastly, Post, of course, did not prove the
unsolvability of the Entscheidungsproblem because at the time Post was
not aware of [Turing 1936], and Post believed that in 1936 Church had

242
17. History of Computability
settled the Entscheidungsproblem. Furthermore, Post wrote in [Post 1936]
that Church’s identiﬁcation of eﬀective calculability and recursiveness was
a working hypothesis which is in “need of continual veriﬁcation.” This irri-
tated Church who criticized it in his review [Church 1937b] of [Post 1936].
Post’s contributions during the 1930s were original and insightful, corre-
sponding in spirit to Turing’s more than to Church’s, but they were not
as inﬂuential as those of Church and Turing. It was only during the next
phase, from 1940 to 1954, that Post’s remarkable inﬂuence was fully felt.
17.5.1
Post Production Systems
As Turing left the subject of pure computability theory in 1939, his man-
tle fell on Post. Post continued the tradition of clear, intuitive proofs, of
exploring the most basic objects such as computability and computably
enumerable sets, and, most of all, of exploring relative computability and
Turing reducibility. During the next decade and a half, from 1940 until his
death in 1954, Post played an extraordinary role in shaping the subject.
Post in [Post 1941] and [Post 1943] introduced a second and unrelated
formalism called a production system and (in a restricted form) a normal
system, which he explained again in [Post 1944]. Post’s (normal) canonical
system is a generational
system, rather than a computational system as
is the case for general recursive functions or Turing computable functions,
because it gives an algorithm for generating (listing) a set of integers rather
than computing a function. This led Post to concentrate on eﬀectively enu-
merable sets rather than computable functions. Post’s normal system gives
a formal deﬁnition of eﬀectively enumerable sets which is equivalent to the
deﬁnition of computably enumerable sets.
17.5.2
Post Considered the Complete Set K
One of Post’s most inﬂuential contributions during this period was the
remarkably clear and intuitive paper [Post 1944], Recursively enumerable
sets of positive integers and their decision problems. Post deﬁned the notion
of one set being reducible to another, and in 1944 and 1948 Post introduced
the term degree of unsolvability for the equivalence class of all sets mutually
reducible to one another. In 1939 Turing had thought only in terms of the
oracle as an external database. Post thought of it as a vehicle to compare
the information content of two sets and to reduce one to the other.
Post’s paper in 1944 revealed with intuition and great appeal the signif-
icance of the computably enumerable sets and the importance of G¨odel’s
Incompleteness Theorem. Post called G¨odel’s diagonal set
(17.8)
K = { e : e ∈We }
the complete set because every c.e. set We is computable in K (We ≤T K).
The set K has the same degree as the halting problem of whether a Turing

17.5. Emil Post’s Contributions
243
machine with program Pe halts on a given input x. Moreover, Post felt
that the creative property of K revealed the inherent creativeness of the
mathematical process. Post posed his famous “Post’s problem” of whether
there exists a computably enumerable (c.e.) set A such that ∅<T A <T K.
17.5.3
Post Deﬁned Relative Computability
Researchers in the 1930s concentrated on a formal deﬁnition of an eﬀec-
tively calculable function, not on a deﬁnition of a function computable in an
oracle. The exception was Turing, who deﬁned oracle machines in 1939. The
idea lay dormant for ﬁve years until Post studied computably enumerable
(c.e.) sets and their decision problems in 1944. Post believed that, along
with decidable and undecidable problems, the relative reducibility (solv-
ability) or nonreducibility of one problem to another is a crucial issue. Post
studied not only the structure of the computably enumerable sets, those
which could be eﬀectively listed, but he initiated a series of reducibilities
of one set to another culminating in the most general reducibility which
he generously named “Turing” reducibility. Post’s aim was to use these re-
ducibilities to study the information content of one set relative to another.
In his introduction in 1944 Post wrote,
Related to the question of solvability or unsolvability of prob-
lems is that of the reducibility or non-reducibility of one
problem to another. Thus, if problem P1 has been reduced to
problem P2, a solution of P2 immediately yields a solution of
P1, while if P1 is proved to be unsolvable, P2 must also be
unsolvable. For unsolvable problems the concept of reducibility
leads to the concept of degree of unsolvability, two unsolvable
problems being of the same degree of unsolvability if each is
reducible to the other, one of lower degree of unsolvability than
another if it is reducible to the other, but that other is not re-
ducible to it, of incomparable degrees of unsolvability if neither
is reducible to the other.
Here Post is not merely introducing reducibility of one problem to an-
other for the sake of demonstrating solvability or unsolvability. He takes it
further by introducing for the ﬁrst time in the subject the term “degree of
unsolvability” to mean that two sets code the same information, i.e., have
the same information content. For decades since then, researchers have
classiﬁed objects in algebra, model theory, complexity, and computability
theory according to their degree of unsolvability or information content.
Post continued,
A primary problem in the theory of recursively enumerable sets
is the problem of determining the degrees of unsolvability of
the unsolvable decision problems thereof.. . . Now in his paper

244
17. History of Computability
on ordinal logics in Section 4, Turing presents as a side issue
a formulation which can immediately be restated as the gen-
eral formulation of the “recursive reducibility” of one problem
to another, and proves a result which immediately generalizes
to the result that for any “recursively given” unsolvable prob-
lem there is another of higher degree of unsolvability. While his
theorem does not help us in our search for that lower degree
of unsolvability, his formulation makes our problem precise. It
remains a problem at the end of this paper.
In 1944 Post wrote an intuitive Section 11 on the general case of Turing
reducibility, but it was not well understood at the time. Post continued
to study it for a decade and deﬁned the concept of degree of unsolvability,
now called “Turing degree.” Before his death in 1954, Post gave his notes
to Kleene, who published the joint paper [Kleene and Post 1954] which
laid the foundation of all the subsequent results on Turing reducibility and
Turing degree.
17.5.4
Developing the Turing Jump
In 1931 G¨odel [1931] was the ﬁrst to introduce the diagonal Π1-set D.
The complement D is computably isomorphic to the complete Σ1-set K,
deﬁned in (17.8). By relativizing Post’s results to the set KA deﬁned by
Turing in (17.7) we see that KA is c.e. in A and A <T KA, i.e., KA is of
strictly higher Turing degree than K. Post [1944] noted that Turing was
the ﬁrst to deﬁne KA in this form relative to an oracle A, although Turing
did not develop its properties. More properties of the jump and of Turing
reducibility were developed in Kleene-Post [1954]. Let A′ denote the Turing
jump KA. Let 0′ be the degree of ∅′. The jump operator is well deﬁned on
Turing degrees and gives a hierarchy in the diagram of Turing degrees.
Meanwhile, Kleene in [Kleene 1943] developed the arithmetic hierarchy
described in Chapter 4 of predicates classiﬁed by a preﬁx of quantiﬁers.
However, to establish that this is indeed a hierarchy, we need Post’s theo-
rem, which implies that ∅n+1 ∈Σ0
n+1 −Σ0
n, so that the hierarchy does not
collapse at any level n.
In his 1944 paper Post moved to other topics which were to have the
most profound inﬂuence on computability theory. First, Post believed that
computability should be done as informally as group theory, with a mini-
mum of formalism. With Rogers’ book [Rogers 1967] there was a return to
Post’s informal approach and it has prevailed since then. Second, Post un-
derstood that computably enumerable (eﬀectively enumerable) sets occur
in many areas of mathematics and wanted to study their content. Third,
Post in 1944 and 1948 began studying various reducibilities of one set to
another and started to classify the information content. These themes have
dominated the subject ever since. Post’s eﬀorts to understand Turing re-

245
ducibility culminated in the crucial paper [Kleene and Post 1954] which
cast Turing reduciblity as an eﬀectively continuous functional on Cantor
space and led to several decades of work on degrees.
17.6
Finite Injury Priority Arguments
Post’s problem was the question of ﬁnding an incomplete noncomputable
c.e. set A. In 1954 Kleene and Post used a ﬁnite forcing argument to ﬁnd an
incomplete noncomputable set A ≤T ∅′. This is slightly weaker, because A
is merely ∆0
2, not Σ0
1. Nevertheless, their method was transformed into the
ﬁnite injury priority method only a couple of years later by Friedberg in
[Friedberg 1957] and Muchnik in [Muchnik 1956]. It is not accidental that
these results followed so closely after the 1954 paper, which ﬁnally helped
understand Turing reductions.
The name “priority argument” is a slight misnomer. Priority of require-
ments had been part of the Kleene and Post theorems, but the new elements
included a computable construction in place of a ∅′-oracle construction and
also injury to the previous action of a requirement Re by the later action
of a higher priority requirement Ri for i < e. The key idea of Friedberg and
Muchnik was to simply restart the action for Re whenever Re is injured and
simultaneously to protect that action against later injury by lower priority
requirements Rj for j > e. This ensured that after ﬁnite injury the strat-
egy for Re will eventually succeed. This computable approximation to the
Kleene-Post theorem was a great advance, but it was built upon a decade
of work by Post from 1944 to 1954 in understanding a Turing reduction.
17.7
Computability and Recursion Terminology
Up until the 1930s the term “recursive” had meant deﬁned by induction
or recursion as in the primitive recursive functions. By 1935 Church and
Kleene had switched from the λ-deﬁnable function to the Herbrand-G¨odel
recursive functions introduced by G¨odel in 1934.
By 1936 Kleene and Church had begun thinking of the word “recur-
sive” to mean “eﬀectively calculable” (intuitively computable). Church had
seen his ﬁrst thesis rejected by G¨odel and was heavily invested in the ac-
ceptance of his 1936 thesis in terms of recursive functions. Without the
acceptance of this thesis Church had no unsolvable problem. Church wrote
in [Church 1936], page 96, reprinted in [Davis 1965] that a “recursively
enumerable set” is one which is the range of a recursive function. This is
apparently the ﬁrst appearance of the term “recursively enumerable” in the
literature and the ﬁrst appearance of “recursively” as an adverb meaning
“eﬀectively” or “computably.”
17.7
Computability and Recursion Terminology

246
17. History of Computability
Kleene in [Kleene 1936], page 238, mentioned “recursive enumeration”
and noted that there is no recursive enumeration of Herbrand-G¨odel re-
cursive systems of equations which gives only the systems that deﬁne the
(total) recursive functions. By a “recursive enumeration” Kleene states that
he means “a recursive sequence (i.e., the successive values of a recursive
function of one variable).” Post in his paper [Post 1944], under the inﬂu-
ence of Church and Kleene, adopted this terminology of “recursive” and
“recursively enumerable” over his own earlier terminology of “eﬀectively
generated set,” “normal set,” and “generated set.” Thereafter, it was ﬁrmly
established.
Martin Davis entitled his book [Davis 1958] Computability and Unsolv-
ability, but adopted the prevailing Kleene terminology at the time that
calculable functions should be called “recursive functions.” Davis wrote
on page vii of his Preface, “This book is an introduction to the theory
of computability and noncomputability, usually referred to as the theory
of recursive functions.” Davis refers several times to “the theory of com-
putability” as including “purely mechanical procedures for solving various
problems.”
This is very typical of usage from [Kleene 1936] through [Rogers 1967]
and [Soare 1987] and beyond, where the term computability theory is often
used for the concept, especially to a nontechnical general audience. How-
ever, a computable function always has been called a “recursive function,”
and a computably enumerable set always has been called a recursively eu-
merable (r.e.) set. This is even true for [Hopcroft and Ullman, 1979] and
other computer science books. In contrast, Turing’s epochal 1936 paper
uses only the terminology “computable function” and calculable function,
and never mentions “recursive” in the sense of calculable. Kleene thought
of “recursive” with the dual meaning of inductive and eﬀectively calculable.
Kleene named the subject “recursive function theory” or simply “recursion
theory.”
17.7.1
G¨odel Rejects Term “Recursive Function Theory”
Neither Turing nor G¨odel ever used the word “recursive” to mean “com-
putable.” G¨odel never used the term “recursive function theory” to name
the subject; when others did, G¨odel reacted sharply and negatively, as re-
lated privately by Martin Davis. In a discussion with G¨odel at the Institute
for Advanced Study in Princeton about 1952–54, Martin Davis casually
used the term “recursive function theory” as it was used then. Davis re-
lated, “To my surprise, G¨odel reacted sharply, saying that the term in
question should be used with reference to the kind of work Rosza Peter
did.” (See Peter’s work on recursions in [Peter 1934] and [Peter 1951].)
The meaning of “recursive” as “inductive” led to ambiguity. Kleene often
wrote of calculations and algorithms dating back to the Babylonians, the

17.8. Additional References
247
Greeks, and other early civilizations. However, Kleene in [Kleene 1981b],
page 44, wrote,
I think we can say that recursive function theory was born there
ninety-two years ago with Dedekind’s Theorem 126 (‘Satz der
Deﬁnition durch Induktion’) that functions can be deﬁned by
primitive recursion.
Did he mean that recursion and inductive deﬁnition began with Dedekind
or that computability and algorithms began there? The latter would con-
tradict his several other statements, such as [Kleene 1988], page 19, where
Kleene wrote, “The recognition of algorithms goes back at least to Euclid
(c. 330 B.C.).” When one uses a term like “recursive” to also mean “com-
putable” or “algorithmic” as Kleene did, then one is never sure whether
a particular instance means “calculable” or “inductive,” and our language
has become imprecise. Returning “recursive” to its original meaning of “in-
ductive” has made its use much clearer. We do not need another word to
mean “computable.” We already have one.
17.7.2
Changing “Recursive” Back to “Inductive”
By 1995 there was considerable ambiguity in the literature as to whether
an instance of “recursive” meant “inductive” or “computable.” In 1995 Leo
Harrington said, “set theory is about sets, model theory is about models,
but recursion theory is not about recursion.”
After the articles [Soare 1996] and [Soare 1999] on the history and sci-
entiﬁc reasons for why we should use “computable” and not “recursive” to
mean “calculable,” many authors changed terminology to have “recursive”
mean only inductive and they introduced new terms such as“computably
enumerable (c.e.)” to replace “recursively enumerable.” This helped lead
to an increased awareness of the relationship of Turing computability to
other areas. There sprang up organizations like Computability in Europe
(CiE) which developed these relationships.
17.8
Additional References
G¨odel’s papers can be found in the three volumes [G¨odel 1986], [G¨odel 1990],
and [G¨odel 1995]. This includes [G¨odel 1931], [G¨odel 1934], [G¨odel 1936],
[G¨odel 193?], [G¨odel 1946], [G¨odel, 1951], and [G¨odel 1964]. Computabiilty
papers from the 1930s and 1940s are reprinted in [Davis 1965].
Papers on G¨odel and Turing include: [Gandy 1980], [Gandy 1988] in
[Herken 1988], [Sieg 1997], [Sieg 2006], [Sieg 2008], and [Sieg 2009], and
also [Feferman 2007], [Wang 1981], [Wang 1987], and [van Heijenoort 1967].
Details of Turing’s life can be found in his biography by [Hodges 1983].

248
17. History of Computability
Books on computability theory include: [Cooper 2004], [Davis 1958],
[Enderton 2011], [Epstein 1975], [Epstein 1979], [Hermes 1969]. The books
include [Kleene 1952], [Kleene 1967], [Lerman 1983], [Odifreddi 1989], and
[Odifreddi 1999], [Rogers 1967], [Shoenﬁeld 1971], [Shoenﬁeld 1993], as
well as [Soare 1987].
There are several books on algorithmic complexity including [Nies 2009]
as well as [Downey and Hirschfeldt 2010].
Material on Hilbert and his programs may be found in [Hilbert 1904],
[Hilbert 1926], [Hilbert and Ackermann 1928], [Hilbert and Bernays 1934].
Dedekind in [Dedekind 1888] proved that certain functions such as addition
and multiplication were deﬁned by recursion.
Papers by Church include his Church’s Thesis abstract in [Church 1935],
his paper about it in [Church 1936], corrections in [Church 1936b], and
his reviews of Turing and Post in [Church 1937] and [Church 1937b].
[Church and Kleene 1936] extended the deﬁnitions to recursive ordinal
numbers, and [Kleene 1938] gave a deﬁnition for notations for recursive
ordinal numbers. Kleene in 1936 introduced the µ-recursive functions
and [Kleene 1936b] proved the equivalence of recursive functions and
λ-deﬁnable functions, giving more evidence for Church’s Thesis.
Jockusch and Soare studied Π0
1-classes in [Jockusch and Soare 1971], and
also in [Jockusch and Soare 1972] and [Jockusch and Soare 1972b] follow-
ing work in [Shoenﬁeld 1960] on degrees of models and in [Scott 1962] on
degrees of extensions of Peano arithmetic. Cenzer gave a summary of work
on Π0
1-classes in [Cenzer 1999]. Diamondstone, Dzhafarov, and Soare gave
a more recent account in 2010 in [DiaDzhSoa 2010].
We presented in §4.8 results by [Jockusch 1972] on degrees in which
the computable functions are uniformly computable and in §6.3 results
from [Jockusch 1980] on generic sets. Other results on these topics can be
found in these papers. The Shoenﬁeld Limit Lemma of [Shoenﬁeld 1959]
characterized the ∆2 sets. A similar characterization in terms of trial and
error predicates was given by [Putnam 1965]. Permitting by ∆2 sets was
presented in [R. Miller 2001] and [Csima 2004].
Friedberg is best known for solving Post’s problem [Friedberg 1957] done
independently in [Muchnik 1956]. However, Friedberg wrote several other
important papers on computably enumerable sets, [Friedberg 1957b], also
[Friedberg 1957c] and [Friedberg 1958], and in [Friedberg-Rogers 1959] in-
troduced weak truth-table (bounded Turing) reducibility. Inﬁnite games
with perfect information were studied in [Gale-Stewart 1953] which proved
that open games are determined.
Articles on Turing and computability theory can be found in [Soare 1996],
[Soare 1999], [Soare 2007], [Soare 2009], [Soare 2012], [Soare 2012b], also
[Soare 2013], [Soare 2013b], [Soare 2013c], and [Soare 2015] as well as in
the references in these papers. Applications of computability theory to
diﬀerential geometry can be found in [Soare 2004].

17.8. Additional References
249
In addition to his main papers, [Turing 1936] and [Turing 1939], Turiing
gave some minor corrections in [Turing 1937] and proved the equiva-
lence of Turing machines and λ-deﬁnable functions in [Turing 1937b]. In
[Turing 1950] he considered computing machinery and intelligence, and in
[Turing 1950b] he studied the word problem for certain semi-groups. In his
ﬁnal published paper, [Turing 1954], he considered puzzles and whether his
main characterization is a deﬁnition or a theorem.
Dekker developed his theorem on hypersimple sets and deﬁciency sets
in [Dekker 1954]. Lachlan introduced Lachlan games in [Lachlan 1970]
and studied the priority method with the viewpoint of topology in
[Lachlan 1973], in [Mathias and Rogers 1973]; [Hopcroft and Ullman, 1979]
showed how to build subroutines for Turing machines to make it easier
to program them; [Martin 1966] developed the results on high degrees
presented in Chapter 4; and [Martin 1975] proved determinacy of Borel
games.
After his retirement, Kleene wrote some retrospective papers on the ori-
gins of recursive function theory, including [Kleene 1981], [Kleene 1981b],
[Kleene 1981c] and [Kleene 1987]. Kleene’s papers and books had great in-
ﬂuence on the subject, especially [Kleene 1936], [Kleene 1943], and his very
inﬂuential book [Kleene 1952].
Myhill proved the creative set theorem of Chapter 2 in [Myhill 1955], no-
ticed that the computably enumerable sets form a lattice in [Myhill 1956],
and asked whether the induced partial ordering was dense. Spector in
[Spector 1956] constructed a minimal degree below 0′′. In addition, Sacks
in [Sacks 1963b] and [Sacks 1963c] constructed one below 0′. Also, Sacks
proved the jump theorem in [Sacks 1963] which generalizes the Shoen-
ﬁeld jump theorem in Chapter 6. Shoenﬁeld in [Shoenﬁeld 1960b] used the
minimal degree construction to give an uncountable set of incomparable
minimal degrees and in [Shoenﬁeld 1966] gave an elegant exposition of the
minimal degree method.

References
[Cenzer 1999]
D. Cenzer, Π0
1-classes in computability theory, Handbook of Computabil-
ity Theory (E. Griﬀor, ed.), Studies in Logic and the Foundations of
Mathematics, vol. 140, North-Holland, Amsterdam, 1999, pp. 37–85.
[Church 1935]
A. Church, An unsolvable problem of elementary number theory, Prelimi-
nary report (abstract), Bull. Amer. Math. Soc. 41 (1935), 332–333.
[Church 1936]
A. Church, An unsolvable problem of elementary number theory, Amer. J.
of Math. 58 (1936), 345–363.
[Church 1936b]
A. Church, A note on the Entscheidungsproblem, J. Symbolic Logic 1
(1936), no. 3, 40–41, corrections on pp. 101–102.
[Church 1937]
A. Church, Review of Turing 1936, J. Symbolic Logic 2 (1937), no. 1, 42–43.
[Church 1937b]
A. Church, Review of Post 1936, J. Symbolic Logic 2 (1937), no. 1, 43.
[Church and Kleene 1936]
A. Church and S. C. Kleene, Formal deﬁnitions in the theory of ordinal
numbers, Fund. Math. 28 (1936), 11–21.
[Cooper 2004]
S. B. Cooper, Computability theory, Chapman & Hall/CRC Mathematics,
London, New York, 2004.
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4
251

252
References
[Csima 2004]
B. F. Csima, Degree spectra of prime models, J. Symbolic Logic 69 (2004),
430–442.
[Davis 1958]
M. Davis, Computability and unsolvability, McGraw-Hill, New York, 1958,
reprinted in 1982 by Dover Publications.
[Davis 1965]
M. Davis (ed.), The undecidable. Basic papers on undecidable propositions,
unsolvable problems, and computable functions, Raven Press, Hewlett, New
York, 1965.
[Dedekind 1888]
R. Dedekind, Was sind und was sollen die Zahlen?, 6th ed., Braunschweig,
1930.
[Dekker 1954]
J. C. E. Dekker, A theorem on hypersimple sets, Proc. Amer. Math. Soc. 5
(1954), 791–796.
[DiaDzhSoa 2010] D. Diamondstone, D. Dzhafarov, and R. I. Soare, Π0
1-classes,
Peano Arithmetic, randomness, and computable domination, Notre Dame
J. Form. Log. 51 (2010), 127–159, 50th Anniversary Issue.
[Downey and Hirschfeldt 2010]
R. G. Downey and D. R. Hirschfeldt, Algorithmic randomness and com-
plexity, Theory and Applications of Computability, Springer-Verlag, New
York, 2010.
[Enderton 2011]
H. B. Enderton, Computability theory: An introduction to recursion theory,
Elsevier, Amsterdam, 2011.
[Epstein 1975]
R. L. Epstein, Minimal degrees of unsolvability and the full approximation
construction, vol. 3, Memoirs of the American Mathematical Society, no.
162, American Mathematical Society, Providence, RI, 1975.
[Epstein 1979]
R. L. Epstein, Degrees of unsolvability: Structure and theory, Lecture Notes
in Mathematics, no. 759, Springer-Verlag, Berlin, Heidelberg, New York,
1979.
[Feferman 2007]
S. Feferman, Turing’s Thesis, Notices Amer. Math. Soc. 53 (2007), no. 10,
1200–1206.
[Friedberg 1957]
R. M. Friedberg, Two recursively enumerable sets of incomparable degrees
of unsolvability, Proc. Natl. Acad. Sci. USA 43 (1957), 236–238.
[Friedberg 1957b]
R. M. Friedberg, The ﬁne structure of degrees of unsolvability of recursively
enumerable sets, Summaries of Cornell University Summer Institute for
Symbolic Logic, Communications Research Division, Institute for Defense
Analyses, Princeton, NJ, 1957, pp. 404–406.

References
253
[Friedberg 1957c]
R. M. Friedberg, A criterion for completeness of degrees of unsolvability,
J. Symbolic Logic 22 (1957), 159–160.
[Friedberg 1958]
R. M. Friedberg, Three theorems on recursive enumeration: I. Decompo-
sition, II. Maximal set, III. Enumeration without duplication, J. Symbolic
Logic 23 (1958), 309—316.
[Friedberg-Rogers 1959]
R. M. Friedberg and H. Rogers, Jr., Reducibility and completeness for sets
of integers, Z. Math. Logik 5 (1959), 117–125.
[Gale-Stewart 1953]
D. Gale and F.M. Stewart, Inﬁnite games with perfect information, Contri-
butions to the Theory of Games, Annals of Mathematics Studies, 28, vol. 2,
Princeton University Press, Princeton, NJ, 1953, pp. 245–266.
[Gandy 1980]
R. Gandy, Church’s thesis and principles for mechanisms, The Kleene Sym-
posium (J. Barwise, J. J. Keisler, and K. Kunen, eds.), North-Holland,
Amsterdam, 1980, pp. 123–148.
[Gandy 1988]
R. Gandy, The conﬂuence of ideas in 1936, in [Herken 1988], pp. 55–111.
[G¨odel 1931]
K. G¨odel, ¨Uber formal unentscheidbare S¨atze der Principia Mathematica
und verwandter Systeme. I, Monatsh. Math. und Phys. 38 (1931), 173–198
(English translation in [Davis 1965], pp. 4–38; in van Heijenoort, [1967],
pp. 592–616; and in [G¨odel 1986], pp. 145–195).
[G¨odel 1934]
K. G¨odel, On undecidable propositions of formal mathematical systems,
notes by S. C. Kleene and J. B. Rosser on lectures at the Institute for Ad-
vanced Study, Princeton, New Jersey, 1934, 30 pp., reprinted in [Davis 1965,
pp. 39–74] and in [G¨odel 1986, pp. 346–371].
[G¨odel 1936]
K. G¨odel, On the length of proofs, in [G¨odel 1986], pp. 397–399; reprinted
in [Davis 1965], pp. 82–83, with a Remark added in proof [of the original
German publication].
[G¨odel 193?]
K. G¨odel, Undecidable Diophantine propositions, in [G¨odel 1995], pp. 164–
174.
[G¨odel 1946]
K. G¨odel, Remarks before the Princeton Bicentennial Conference of Prob-
lems in Mathematics, 1946, reprinted in [Davis 1965], pp. 84–87, and in
[G¨odel 1990], pp. 150–153.
[G¨odel, 1951]
K. G¨odel, Some basic theorems on the foundations of mathematics and
their implications, [G¨odel 1995], pp. 304–323. (This was the Gibbs Lecture
delivered by G¨odel on December 26, 1951 to the American Mathematical
Society).

254
References
[G¨odel 1964]
K. G¨odel, Postscriptum to [G¨odel 1931], written in 1946, reprinted in
[Davis 1965], pp. 71–73.
[G¨odel 1986]
K. G¨odel, Publications 1929–1936, Kurt G¨odel Collected works (S. Fefer-
man et al., eds.), vol. I, Oxford University Press, Oxford, 1986.
[G¨odel 1990]
K. G¨odel, Publications 1938–1974, Kurt G¨odel Collected works (S. Fefer-
man et al., eds.), vol. II, Oxford University Press, Oxford, 1990.
[G¨odel 1995]
K. G¨odel, Unpublished essays and lectures, Kurt G¨odel Collected works
(S. Feferman et al., eds.), vol. III, Oxford University Press, Oxford, 1995.
[Herken 1988]
R. Herken (ed.), The universal Turing machine: A half-century survey,
Oxford University Press, 1988.
[Hermes 1969]
H. Hermes, Enumerability, decidability, computability: An introduction
to the theory of recursive functions, 2nd revised ed., Springer-Verlag,
Berlin, Heidelberg, New York, 1969. (This is an English translation
of Aufz¨ahlbarkeit, Entscheidbarkeit, Berechenbarkeit, Grundlehren der
mathematischen Wissenschaften, Band 109), Springer-Verlag, 1965.)
[Hilbert 1904]
D. Hilbert, ¨Uber die Grundlagen der Logik und der Arithmetik, Verhand-
lungen des Dritten Internationalen Mathematiker-Kongresses in Heidelberg
vom 8. bis 13. August 1904, Teubner, Leipzig, 1905, reprinted in van
Heijenoort 1967, pp. 129–138, pp. 174–185.
[Hilbert 1926]
D. Hilbert, ¨Uber das Unendliche, Math. Ann. 95 (1926), no. 1, 161–190
(English translation in van Heijenoort 1967, pp. 367–392).
[Hilbert and Ackermann 1928]
D. Hilbert and W. Ackermann, Grundz¨uge der theoretischen Logik,
Springer-Verlag, Berlin, 1928 (English translation of 1938 edition, Chelsea,
New York, 1950).
[Hilbert and Bernays 1934]
D. Hilbert and P. Bernays, Grundlagen der Mathematik, Springer, Berlin,
I (1934), II (1939); Second ed., I (1968), II (1970).
[Hodges 1983]
A. Hodges, Alan Turing: The enigma, Burnett Books and Hutchinson, Lon-
don, Simon and Schuster, New York, 1983, new edition, Vintage, London,
1992.
[Hopcroft and Ullman, 1979]
J. E. Hopcroft and J. D. Ullman, Introduction to automata, languages and
computation, Addison-Wesley, 1979.
[Jockusch 1972]
C. G. Jockusch, Jr., Degrees in which the recursive sets are uniformly
recursive, Canad. J. Math. 24 (1972), 1092–1099.

References
255
[Jockusch 1980] C. G. Jockusch, Jr., Degrees of generic sets, Recursion theory:
Its generalizations and applications (F. R. Drake and S. S. Wainer, eds.),
Cambridge University Press, 1980, pp. 110–139.
[Jockusch and Soare 1971]
C. G. Jockusch and R. I. Soare, A minimal pair of Π0
1 classes, J. Symbolic
Logic 36 (1971), 66–78.
[Jockusch and Soare 1972]
C. G. Jockusch and R. I. Soare, Degrees of members of Π0
1 classes, Paciﬁc
J. Math. 40 (1972), 605–616.
[Jockusch and Soare 1972b]
C. G. Jockusch and R. I. Soare, Π0
1 classes and degrees of theories, Trans.
Amer. Math. Soc. 173 (1972), 33–56.
[Kleene 1936]
S. C. Kleene, General recursive functions of natural numbers, Math. Ann.
112 (1936), 727–742.
[Kleene 1936b]
S. C. Kleene, λ-Deﬁnability and recursiveness, Duke Math. J. 2 (1936),
340–353.
[Kleene 1938]
S. C. Kleene, On notation for ordinal numbers, J. Symbolic Logic 3 (1938),
150–155.
[Kleene 1943]
S. C. Kleene, Recursive predicates and quantiﬁers, Trans. Amer. Math. Soc.
53 (1943), 41–73.
[Kleene 1952]
S. C. Kleene, Introduction to metamathematics, van Nostrand, New York,
1952, ninth reprint 1988, Wolters-NoordhoﬀPublishing Co., Groningen and
North-Holland, Amsterdam.
[Kleene 1967]
S. C. Kleene, Mathematical logic, John Wiley and Sons, Inc., New York,
London, Sydney, 1967.
[Kleene 1981]
S. C. Kleene, Origins of recursive function theory, Ann. Hist. Comput. 3
(1981), 52–67.
[Kleene 1981b]
S. C. Kleene, The theory of recursive functions, approaching its centennial,
Bull. Amer. Math. Soc. (N.S.) 5 (1981), no. 1, 43–61.
[Kleene 1981c]
S. C. Kleene, Algorithms in various contexts, Proceedings of the Symposium
on Algorithms in Modern Mathematics and Computer Science (dedicated
to Al-Khwarizmi) (Urgench, Khorezm Region, Uzbek, SSR, 1979), Lecture
Notes in Computer Science, vol. 122, Springer-Verlag, Berlin, Heidelberg
and New York, 1981, pp. 355–360.
[Kleene 1987]
S. C. Kleene, Reﬂections on Church’s Thesis, Notre Dame J. Form. Log.
28 (1987), 490–498.

256
References
[Kleene 1988]
S. C. Kleene, Turing’s analysis of computability, and major applications of
it, in [Herken 1988], pp. 17–54.
[Kleene and Post 1954]
S. C. Kleene and E. L. Post, The upper semi-lattice of degrees of recursive
unsolvability, Ann. of Math. 59 (1954), 379–407.
[Lachlan 1970]
A. H. Lachlan, On some games which are relevant to the theory of
recursively enumerable sets, Ann. of Math. (2) 91 (1970), 291–310.
[Lachlan 1973]
A. H. Lachlan, The priority method for the construction of recursively
enumerable sets, in Mathias and Rogers [1973], pp. 299–310.
[Lerman 1983]
M. Lerman, Degrees of unsolvability: Local and global theory, Perspectives in
Mathematical Logic, Springer-Verlag, Heidelberg, New York, Tokyo, 1983.
[Martin 1966]
D. A. Martin, Classes of recursively enumerable sets and degrees of
unsolvability, Z. Math. Logik Grundlagen Math. 12 (1966), 295–310.
[Martin 1975]
D. A. Martin, Borel determinacy, Ann. of Math. (2) 102 (1975), no. 2,
363–371.
[Mathias and Rogers 1973]
A. R. D. Mathias and H. Rogers, Jr. (eds.), Cambridge Summer School
in Mathematical Logic, held in Cambridge, England, August 1–21, 1971,
Lecture Notes in Mathematics, no. 337, Berlin, Heidelberg, New York,
Springer-Verlag, 1973.
[R. Miller 2001]
R. Miller, The ∆0
2-spectrum of a linear order, J. Symbolic Logic 66 (2001),
470–486.
[Miller and Martin 1968]
W. Miller and D. A. Martin, The degree of hyperimmune sets, Z. Math.
Logik Grundlagen Math. 14 (1968), 159–166.
[Muchnik 1956]
A. A. Muchnik, On the unsolvability of the problem of reducibility in the
theory of algorithms, Dokl. Akad. Nauk 108 (1956), 194–197, (Russian).
[Myhill 1955]
J. Myhill, Creative sets, Z. Math. Logik Grundlagen Math. 1 (1955), 97–
108.
[Myhill 1956]
J. Myhill, The lattice of recursively enumerable sets, J. Symbolic Logic 21
(1956), 220 (abstract).
[Nies 2009]
A. Nies, Computability and randomness, Oxford Logic Guides 51, Oxford
University Press, Oxford, UK, 2009.
[Odifreddi 1989]
P. Odifreddi, Classical Recursion Theory: The theory of functions and sets

References
257
of natural numbers, Studies in Logic and the Foundations of Mathematics
125, vol. I, North-Holland, Amsterdam, 1989.
[Odifreddi 1999]
P. Odifreddi, Classical Recursion Theory: The theory of functions and sets
of natural numbers, Studies in Logic and the Foundations of Mathematics
143, vol. II, North-Holland, Amsterdam, 1999.
[Owings 1973]
J. C. Owings, Jr., Diagonalization and the recursion theorem, Notre Dame
J. Form. Log. 14 (1973), no. 1, 95–99.
[Peter 1934]
R. P´eter, ¨Uber den Zusammenhang der verschiedenen Begriﬀe der rekur-
siven Funktion, Math. Ann. 110 (1934), 612–632.
[Peter 1951]
R. P´eter, Rekursive Funktionen, Akad´emiai Kiad´o (Akademischer Ver-
lag), Budapest, 1951, 206 pp. Recursive Functions, third revised edition,
Academic Press, New York, 1967, 300 pp.
[Post 1936]
E. L. Post, Finite combinatory processes–formulation I, J. Symbolic Logic
1 (1936), 103–105, reprinted in [Davis 1965], pp. 288–291.
[Post 1941]
E. L. Post, Absolutely unsolvable problems and relatively undecidable propo-
sitions: Account of an anticipation (Submitted for publication in 1941,
never published) Printed in [Davis 1965], pp. 338–433.
[Post 1943]
E. L. Post, Formal reductions of the general combinatorial decision problem,
Amer. J. Math. 65 (1943), 197–215.
[Post 1944]
E. L. Post, Recursively enumerable sets of positive integers and their deci-
sion problems, Bull. Amer. Math. Soc. 50 (1944), no. 5, 284–316, reprinted
in [Davis 1965], pp. 304–337.
[Post 1948]
E. L. Post, Degrees of recursive unsolvability: preliminary report (abstract),
Bull. Amer. Math. Soc. 54 (1948), 641–642.
[Putnam 1965]
H. Putnam, Trial and error predicates and the solution to a problem of
Mostowski, J. Symbolic Logic 30 (1965), 49–57.
[Rice 1953]
H. G. Rice, Classes of enumerable sets and their decision problems, Trans.
Amer. Math. Soc. 74 (1953), 358–366.
[Rice 1956]
H. G. Rice, On completely recursively enumerable classes and their key
arrays, J. of Symbolic Logic 21 (1956), no. 3, 304–308.
[Rogers 1967]
H. Rogers, Jr., Theory of recursive functions and eﬀective computability,
McGraw-Hill, New York, 1967.

258
References
[Sacks 1963]
G. E. Sacks, Recursive enumerability and the jump operator, Trans. Amer.
Math. Soc. 108 (1963), 223–239.
[Sacks 1963b]
G. E. Sacks, On the degrees less than 0′, Ann. of Math. (2) 77 (1963), no. 2,
211–231.
[Sacks 1963c]
G. E. Sacks, Degrees of unsolvability, Annals of Mathematics Studies,
no. 55, Princeton University Press, Princeton, NJ, 1963 (see revised edition,
1966).
[Scott 1962]
Dana S. Scott, Algebras of sets binumerable in complete extensions of arith-
metic, Proceedings of the Symposium on Pure and Applied Mathematics,
vol. V, American Mathematical Society, Providence, RI, 1962, pp. 117–121.
[Shoenﬁeld 1959]
J. R. Shoenﬁeld, On degrees of unsolvability, Ann. of Math. (2) 69 (1959),
644–653.
[Shoenﬁeld 1960]
J. R. Shoenﬁeld, Degrees of models, J. Symbolic Logic 25 (1960), no. 3,
233–237.
[Shoenﬁeld 1960b]
J. R. Shoenﬁeld, An uncountable set of incomparable degrees, Proc. Amer.
Math. Soc. 11 (1960), no. 1, 61–62.
[Shoenﬁeld 1966]
J. R. Shoenﬁeld, A theorem on minimal degrees, J. Symbolic Logic 31
(1966), no. 4, 539–544.
[Shoenﬁeld 1971]
J. R. Shoenﬁeld, Degrees of unsolvability, North-Holland Mathematics
Studies, no. 2, North-Holland, Amsterdam, 1971.
[Shoenﬁeld 1993]
J. R. Shoenﬁeld, Recursion theory, Lecture Notes in Logic 1, Springer-
Verlag, Heidelberg, New York, 1993.
[Sieg 1994]
W. Sieg, Mechanical procedures and mathematical experience, Mathematics
and Mind (A. George, ed.), Oxford University Press, 1994, pp. 71–117.
[Sieg 1997]
W. Sieg, Step by recursive step: Church’s analysis of eﬀective calculability,
Bull. Symbolic Logic 3 (1997), no. 2, 154–180.
[Sieg 2006]
W. Sieg, G¨odel on computability, Philosophia Mathematica 14 (2006), 189–
207.
[Sieg 2008]
W. Sieg, Church without dogma-axioms for computability, New Computa-
tional Paradigms (B. L¨owe, A. Sorbi, and B. Cooper, eds.), Springer-Verlag,
2008, pp. 139–152.

References
259
[Sieg 2009]
W. Sieg, On computability, Handbook of the Philosophy of Mathematics
(Andrew D. Irvine, ed.), Elsevier, 2009, pp. 535–630.
[Skolem 1923]
T. Skolem, Begr¨undung der elementaren Arithmetik durch die rekurrierende
Denkweise ohne Anwendung scheinbarer Ver¨anderlichen mit unendlichem
Ausdehnungsbereich, no. 6, Skrifter utgit av Videnskapsselskapet i Kris-
tiania, I. Mathematisk-Naturvidenskabelig Klasse, 1923, 38 pp. (English
translation in van Heijenoort, 1967, pp. 302–333.)
[Soare 1987]
R. I. Soare, Recursively enumerable sets and degrees: A study of computable
functions and computably generated sets, Perspectives in Mathematical
Logic, Springer, Heidelberg, 1987.
[Soare 1996]
R. I. Soare, Computability and recursion, Bull. Symbolic Logic 2 (1996),
284–321.
[Soare 1999]
R. I. Soare, The history and concept of computability, Handbook of Com-
putability Theory (E. R. Griﬀor, ed.), North-Holland, Amsterdam, 1999,
pp. 3–36.
[Soare 2004]
R. I. Soare, Computability theory and diﬀerential geometry, Bull. Symbolic
Logic 10 (2004), no. 4, 457–486.
[Soare 2007]
R. I. Soare, Computability and incomputability, computation and logic in the
real world, Computation and Logic in the Real World, Third Conference on
Computability in Europe, Proceedings, CiE 2007, Siena, Italy, June 2007
(S. B. Cooper, B. L¨owe, and A. Sorbi, eds.), Lecture Notes in Computer
Science 4497, Springer, Berlin, Heidelberg, 2007.
[Soare 2009]
R. I. Soare, Turing oracle machines, online computing, and three dis-
placements in computability theory, Ann. Pure Appl. Logic 160 (2009),
368–399.
[Soare 2012]
R. I. Soare, An interview with Robert Soare: Reﬂections on Alan Turing,
XRDS, Crossroads, the ACM magazine for students 18 (2012), no. 3.
[Soare 2012b]
R. I. Soare, Formalism and intuition in computability theory, Phil. Trans.
R. Soc. Lond. Ser. A 370 (2012), 3277–3304.
[Soare 2013]
R. I. Soare, Turing and the art of classical computability, Alan Turing—
His Work and Impact (Barry Cooper and Jan van Leeuwen, eds.), Elsevier,
2013, pp. 65–70.
[Soare 2013b]
R. I. Soare, Interactive computing and relativized computability, Com-

260
References
putability: G¨odel, Church, Turing, and Beyond (Jack Copeland, Carl Posy,
and Oron Shagrir, eds.), MIT Press, 2013.
[Soare 2013c]
R. I. Soare, Turing and the discovery of computability, Turing’s legacy:
Developments from Turing’s ideas in logic (Rodney Downey, ed.), Lec-
ture Notes in Logic 42, Association for Symbolic Logic and Cambridge
University Press, 2014.
[Soare 2015]
R. I. Soare, Why Turing’s Thesis is not a thesis, Turing Centenary Volume
(Thomas Strahm and Giovanni Sommaruga, eds.), Birkh¨auser/Springer,
Basel, to appear.
[Spector 1956]
Cliﬀord Spector, On degrees of recursive unsolvability, Ann. of Math. (2)
64 (1956), no. 3, 581–592.
[Turing 1936]
A. M. Turing, On computable numbers with an application to the Entschei-
dungsproblem, Proc. London Math. Soc. (2) 42 (1936), 230–265, reprinted
in [Davis 1965], pp. 115–153.
[Turing 1937]
A. M. Turing, A correction, Proc. London Math. Soc. (2) 43 (1937), 544–
546.
[Turing 1937b]
A. M. Turing, Computability and λ-deﬁnability, J. Symbolic Logic 2 (1937),
153–163.
[Turing 1939]
A. M. Turing, Systems of logic based on ordinals, Proc. London Math. Soc.
(2) 45 (1939), 161–228; reprinted in [Davis 1965], 154–222.
[Turing 1950]
A. M. Turing, Computing machinery and intelligence, Mind 59 (1950),
433–460.
[Turing 1950b]
A. M. Turing, The word problem in semi-groups with cancellation, Ann. of
Math. 52 (1950), no. 2, 491–505.
[Turing 1954]
A. M. Turing, Solvable and unsolvable problems, Science News 31 (1954),
7–23.
[van Heijenoort 1967]
J. van Heijenoort (ed.), From Frege to G¨odel, A sourcebook in mathematical
logic, 1879–1931, Harvard University Press, Cambridge, MA, 1967.
[Wang 1981]
H. Wang, Some facts about Kurt G¨odel, J. Symbolic Logic 46 (1981), no. 3,
653–659.
[Wang 1987]
H. Wang, Reﬂections on Kurt G¨odel, MIT Press, Cambridge, MA, 1987.

Index
∆2-permitting, 128
Π0
1-class, 167
Σ1 set, 24
Σ3-Representation Theorems, 89
Σn, Πn, and ∆n sets, 79
Σn-complete set, 85
1-generic sets, 137
acceptable numbering, 21
Acceptable Numbering Theorem, 21
Ackermann function, 231
antibasis, 175
arithmetical hierarchy, 79
Arslanov Completeness Criterion, 118
avoiding cones, 134
Baire Category Theorem, 212
Banach-Mazur games, 211
basis theorems for Π0
1 classes, 175
bounded reducibilities, 73
bounded Turing reducibility, 73
Bounded T-Reducibility Theorem, 76
canonical index of ﬁnite set Dy, 34
canonical simple set, 110
Cantor space, 165
Cantor-Bendixson rank, 172
characteristic index, 33
characterizing nonlow2 sets, 98
Church’s Thesis, 5
closed classes, 166
Compactness Theorem, 168
compatible, 142
Complementation Theorem, 26
computable function, 5
computable permutation, 19
computably bounded, 114
Computably Dominated Basis
Theorem, 178
computably enumerable (c.e.) set, 13
computably inseparable, 19
computably invariant, 19
computably presented, 134
computably traceable, 192
computation function, 126
Cone Avoidance Theorem, 156
countably universal, 133
creative set, 38
Creative Set Theorem, 39
cylinder, 19
d.c.e., n.c.e., and ω-c.e. sets, 75
deﬁciency set, 115
Dekker’s Theorem, 115
© Springer-Verlag Berlin Heidelberg 2016 
R.I. Soare, Turing Computability, Theory and Applications of Computability,  
DOI 10.1007/978-3-642-31933-4 
261

262
Index
dense open subsets, 170
diagonally noncomputable (d.n.c.),
185
dominating function, 114
domination, 64
domination and escaping, 94
dynamic deﬁnitions for c.e. sets, 47
Dynamic Flow Theorem, 48
e-splitting lemmas, 199
e-splitting strings, 198
eﬀective compactness theorem, 169
eﬀectively immune, 119
eﬀectively inseparable, 41
Entscheidungsproblem, 4
Enumeration Theorem, 11
exact pair, 142
ﬁnite extension paradigm, 214
ﬁnite extensions, 131
ﬁnite injury, 147
ﬁrst category, 213
ﬁxed point free, 118
forcing the jump, 137
Friedberg Completeness Criterion,
139
Friedberg Splitting Theorem, 49
Friedberg-Muchnik Theorem, 152
function tree (f-tree), 197
G¨odel-Rosser sentence, 184
Gale Stewart games, 217
general permitting, 122
general recursive in, 240
generic sets, 137
graph of a function, 24
Graph Theorem, 25
halting problem, 14
Herbrand-G¨odel recursive, 232
Hierarchy Theorem, 85
High Domination Theorem, 96
Hilbert’s programs, 227
hyperimmune, 114
hyperimmune-free degrees, 124
hypersimple set, 113
immune, 109
index set, 16
Index Set Theorem, 16
injury set, 148
inverting the jump, 139
jump operator, 61
Jump Theorem, 61
Kleene Normal Form, 234
Kleene’s µ-Recursive Functions, 233
Kreisel Basis Theorem, 169
Kreisel-Shoenﬁeld Basis Theorem,
176
Kurtz test, 193
Lachlan games, 43
Lachlan notation, 57
lattice E of c.e. sets, 27
limit computable sets, 63
Limit Lemma, 66
Listing Theorem, 26
low and high sets, 69
Low Antibasis Theorem, 179
Low Basis Theorem, 71
low simple sets, 149
lown and highn sets, 92
majorizes, 95
many-one degree, 15
many-one reducible, 14
Martin-L¨of Randomness, 189
meager and comeager sets, 211
minimal degree, 197
minimal indices, 32
minimal pair, 134
Modulus Lemma, 68
movable markers, 87
Myhill Isomorphism Theorem, 20
nonbasis theorems for Π0
1-classes, 176
Nonconversion Theorem, 34
nonprimitive recursive functions, 231
Normal Form for C.E. Sets, 23
nowhere dense, 213
one-one degree, 15
one-one reducible, 14
open classes, 165
oracle construction, 132
Oracle Graph Theorem, 56

Index
263
oracle graphs of functionals, 54
oracle machine, 51
Padding Lemma, 10
partial computable function, 4
Peano arithmetic, 183
permitting and simple sets, 111
permitting as a game, 112
permitting constructions, 57
Post’s contributions, 241
Post’s Problem, 107
Post’s simple set, 109
Post’s Theorem, 83
preﬁx free graph, 54
preservation strategy, 156
primitive recursive functions, 229
priority ordering of requirements, 49
procedure, 3
productive set, 38
projection, 23
Proper Lown Basis Theorem, 181
Quantiﬁer Contraction Theorem, 24
r-complete, 38
recursion terminology, 245
Recursion Theorem, 29
Reduction Principle, 26
relative computability, 51
Relativized Post’s Theorem, 92
relativized standard theorems, 58
restraint functions as walls, 151
reverse permitting, 123
Rice’s Theorem, 16
s-m-n Theorem, 12
Sacks minimal degree a < 0′, 203
Sacks Splitting Theorem, 158
second category, 213
self-dual, 33
separation principle, 27
Shoenﬁeld Jump Inversion, 145
simple set, 108
simultaneous computable
enumeration (s.c.e.), 46
Spector minimal degree a < 0′′, 201
strong array of ﬁnite sets, 113
Superlow Basis Theorem, 177
thickness requirement, 142
trees, 71
truth-table reducibility, 74
Truth-Table Theorem, 75
Turing computability, 52
Turing computable functional, 53
Turing computation, 8
Turing degrees, 60
Turing machine, 7
Turing program, 7
Turing’s Thesis, 5
Uniformization Theorem, 25
uniformly c.e., 46
Union Theorem, 26
universal machine, 11, 12
universal Martin-L¨of test, 190
upper and lower bounds, 141
use function, 54
Use Principle, 57
Weak K¨onig’s Lemma, WKL, 168
weakly 1-random, 193
wtt-reducible, 73
y-section of A, namely A[y], 76

