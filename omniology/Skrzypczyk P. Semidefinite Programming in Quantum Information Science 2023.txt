
IOP Series in Quantum Technology
Series Editor: Barry Garraway (School of Mathematical and Physical
Sciences, University of Sussex, UK), Barry Sanders (Institute for
Quantum Science and Technology, University of Calgary, Canada), and
Lincoln Carr (Quantum Engineering Program, Colorado School of Mines,
USA)
About the series
The IOP Series in Quantum Technology is dedicated to bringing together
the most up to date texts and reference books from across the emerging
field of quantum science and its technological applications. Prepared by
leading experts, the series is intended for graduate students and researchers
either already working in or intending to enter the field. The series seeks
(but is not restricted to) publications in the following topics:
Quantum biology
Quantum communication
Quantum computation
Quantum control
Quantum cryptography
Quantum engineering
Quantum machine learning and intelligence
Quantum materials
Quantum metrology
Quantum optics
Quantum sensing
Quantum simulation
Quantum software, algorithms and code
Quantum thermodynamics
Hybrid quantum systems

A full list of titles published in this series can be found here:
https://iopscience.iop.org/bookListInfo/iop-series-in-quantum-technology

Semidefinite Programming in
Quantum Information Science
Paul Skrzypczyk
School of Physics, University of Bristol, Bristol, UK
Daniel Cavalcanti
Algorithmiq Ltd, Helsinki, Finland
IOP Publishing, Bristol, UK

© IOP Publishing Ltd 2023
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system or
transmitted in any form or by any means, electronic, mechanical, photocopying, recording or
otherwise, without the prior permission of the publisher, or as expressly permitted by law or under
terms agreed with the appropriate rights organization. Multiple copying is permitted in accordance
with the terms of licences issued by the Copyright Licensing Agency, the Copyright Clearance
Centre and other reproduction rights organizations.
Permission to make use of IOP Publishing content other than as set out above may be sought at
permissions@ioppublishing.org.
Paul Skrzypczyk and Daniel Cavalcanti have asserted their right to be identified as the authors of this
work in accordance with sections 77 and 78 of the Copyright, Designs and Patents Act 1988.
ISBN 978-0-7503-3343-6 (ebook)
ISBN 978-0-7503-3341-2 (print)
ISBN 978-0-7503-3344-3 (myPrint)
ISBN 978-0-7503-3342-9 (mobi)
DOI 10.1088/978-0-7503-3343-6
Version: 20230301
IOP ebooks
Published by IOP Publishing, wholly owned by The Institute of Physics, London
IOP Publishing, No.2 The Distillery, Glassfields, Avon Street, Bristol, BS2 0GR, UK
US Office: IOP Publishing, Inc., 190 North Independence Mall West, Suite 601, Philadelphia, PA
19106, USA
Supplementary material is available at https://github.com/paulskrzypczyk/SDPBook.

Contents
Preface
Author biographies
About this book
Part I The fundamentals
1
 Linear programming
1.1
 The basics
1.1.1
 Feasibility
1.2
 Geometric interpretation
1.2.1
 Equality constraints
1.2.2
 Inequality constraints
1.2.3
 The feasible set
1.2.4
 The objective function
1.3
 Duality
1.4
 Slack variables
1.5
 Weak and strong duality
1.6
 Concluding remarks
1.7
 Advanced topics
1.7.1
 Complementary slackness
1.7.2
 Dual form of ℓ1 and ℓ∞ norms

1.8
 Further reading
2
 Semidefinite programming
2.1
 Primal semidefinite programs
2.2
 Duality
2.3
 Weak and strong duality
2.4
 Complementary slackness
2.5
 Linear programs as special instances of semidefinite programs
2.6
 Concluding remarks
2.7
 Further reading
Part II Semidefinite programming in quantum information science
3
 Quantum states
3.1
 Quantum state estimation
3.1.1
 Trace distance estimation
3.1.2
 Fidelity estimation
3.1.3
 Finite statistics
3.1.4
 Relaxing the feasibility problem
3.1.5
 Certificate of infeasibility
3.1.6
 Geometrical interpretation
3.1.7
 Property estimation
3.2
 The quantum marginal problem
3.3
 Concluding remarks
3.4
 Further reading
3.5
 Advanced topics

3.5.1
 The fidelity SDP
4
 Quantum measurements
4.1
 Quantum measurement estimation
4.2
 Quantum state discrimination I
4.2.1
 Minimum-error quantum state discrimination
4.2.2
 Binary state discrimination
4.2.3
 Optimality conditions
4.2.4
 Unambiguous quantum state discrimination
4.3
 Quantum state discrimination II
4.3.1
 Transforming the non-linear problem into a linear one
4.3.2
 Generalised robustness of measurement informativeness
4.3.3
 Structure of the optimal ensemble and noise measurement
4.4
 Concluding remarks
4.5
 Further reading
4.6
 Advanced topics
4.6.1
 Unambiguous quantum state discrimination revisited
5
 Quantum entanglement
5.1
 Entanglement of pure and mixed states
5.2
 The positive-partial-transpose criterion
5.3
 Entanglement negativity
5.4
 Random robustness of entanglement and SDP relaxations
5.5
 k-symmetric extensions
5.6
 Concluding remarks
5.7
 Further reading

5.8
 Advanced topics
5.8.1
 Entanglement witnesses from k-symmetric extensions
6
 Measurement incompatibility
6.1
 Joint measurability as an SDP
6.2
 Two dichotomic measurements
6.3
 Concluding remarks
6.4
 Further reading
6.5
 Advanced topics
6.5.1
 Measurement incompatibility and quantum nonlocality
7
 Quantum channels
7.1
 The Choi–Jamiołkowski isomorphism
7.2
 Channel estimation
7.3
 The diamond norm and channel discrimination
7.4
 The conditional min-entropy and the singlet fidelity
7.5
 Concluding remarks
7.6
 Further reading
7.7
 Advanced topics

Preface
We can safely say that learning semidefinite programming was a turning
point in both of our careers. It all started in 2013, when we both joined Prof.
Antonio Acínʼs group at ICFO—The Institute of Photonic Sciences
(Barcelona) to conduct our postdoctoral research. At that time we became
interested in the problem of characterising quantum steering, a form of
quantum correlations that were first noticed by Schrödinger in response to
Einstein, Podolsky and Rosenʼs famous 1935 paper. We suspected that there
was more to discover about quantum steering, and the role it can play in
quantum information science. It was then, during the traditional Quantum
Information Conference ‘13, held in the beautiful mountain village of
Benasque (Spain), that Miguel Navascués (now a group leader at the
University of Vienna) mentioned that steering could be studied using
semidefinite programming. We immediately started digging into this idea
and, a few months later, we published our first paper (also in collaboration
with Miguel) showing how to use semidefinite programming in the
quantification of steering. Since then, we have both been using semidefinite
programming directly to achieve results in quantum information and
foundations, or indirectly to test assumptions, to the point that using this
technique has become an obsession. In fact, this is the main reason why we
decided to write this book: semidefinite programming has helped us
tremendously, and we are sure that it will help other researchers too.
We also have to mention the push we got from the VII Paraty Quantum
Information School in 2019, where one of us was invited to give a mini-
course on the topic of this book. During this event we saw a big interest
from students on the topic, and realised there was a lack of a concise and
coherent source of information about it, that could appeal to theorist or
experimentalist, mathematician or physicist, and all those in between.
Because of this, we would like to thank Antonio Acín for providing us
with a relaxed and inspiring collaborative environment in his group. We
would also like to thank Miguel Navascués, and everyone involved in the
organisation of the Benasque Quantum Information Conference as well as

the organisers and students of the VII Paraty Quantum Information School.
We also thank our numerous colleagues who, for so many times, have
helped us to better understand semidefinite programming. In particular
Marco T Quintino, Dennis Rosset, Jean D Bancal, Valerio Scarani, Marco
Piani, Ashley Montanaro, Tony Short, and Sandu Popescu. Finally, we
would like to thank IOP Publishing, and in particular John Navas, for
giving us the opportunity to write this book.

Author biographies
Paul Skrzypczyk
Paul Skrzypczyk is currently an Associate Professor and Royal Society
University Research Fellow at the University of Bristol in the School of
Physics. He obtained his PhD in Theoretical Physics from the University of
Bristol in 2011, under the supervision of Professor Sandu Popescu, with his
PhD 
studies 
focusing 
on 
quantum 
nonlocality 
and 
quantum
thermodynamics. He carried out postdoctoral research at the University of
Cambridge, and ICFO—The Institute for Photonic Sciences, before
returning to Bristol in 2015. In 2016 he was awarded a Royal Society
University Research Fellowship, and became a lecturer in 2018 and an
Associate Professor in 2022. Paulʼs research interest span many areas of
quantum information and quantum foundations, ranging from quantum
nonlocal effects, such as Bell nonlocality, quantum steering and quantum
teleportation, to quantum measurements and measurement incompatibility,
to quantum thermodynamics. Convex geometry, semidefinite programming
and convex optimisation have been the primary mathematical tools used in
his research over the years.
Daniel Cavalcanti

Daniel Cavalcanti is currently a senior researcher at Algorithmiq Ltd. He
obtained a PhD in Theoretical Physics at ICFO—Institute of Photonic
Sciences in 2008 on the topics of entanglement and characterisation of
quantum correlations. After a short postdoc at ICFO in 2009, he joined the
Centre for Quantum Technology (Singapore) in 2010, first as a postdoc in
Professor Valerio Scaraniʼs group, and soon as an independent researcher.
In 2013 he returned to ICFO, where he stayed until 2021 on a Ramón y
Cajal grant. Danielʼs research has focused on quantum foundations,
quantum correlations, quantum communication and, more recently,
quantum computation. Daniel also holds a masterʼs degree in graphic
design and runs Bitflow, a graphic design studio dedicated to science and
technology related projects.

About this book
Semidefinite programming (SDP1) is a type of optimisation problem with
vast applications in physics, engineering, combinatorial optimisation, and
many other fields. In this book we are interested in applications of
semidefinite programming in the field of quantum information. It turns out
to be pretty natural that many problems in quantum mechanics and quantum
information can be cast as SDPs, because the mathematical description of
quantum states and quantum measurements in terms of positive
semidefinite operators fit naturally in the SDP framework. Thus, although
here we will mostly focus on quantum information, the present book can
also be relevant when addressing other problems in quantum physics.
From a practical point of view, there are two main reasons to study
SDPs. First, once a problem is recognised as an SDP, there is a theoretical
machinery that can be used to solve the problem or, at least, obtain bounds
on its solution. Second, there are plenty of efficient computer algorithms
and modelling languages for solving SDPs, such as CVX, CVXOPT,
CVXPY, MOSEK and YALMIP, allowing us to numerically solve SDPs
involving relatively big matrices with todayʼs standard laptop computers.
As a starting point for performing numerical calculations of SDPs we
recommend in particular the CVX and CVXPY modelling systems for
constructing and solving convex optimisation problems (of which SDPs are
a subclass) that can be implemented in Matlab and Python respectively.
This book will focus exclusively on the theoretical machinery of SDPs.
However, to accompany it, we have set up a repository at
https://github.com/paulskrzypczyk/SDPBook, which contains a small
number of example codes, covering some of the SDPs studied in this book.
The structure of this book is the following. It is split into two parts. Part
I is devoted to the description of semidefinite programming, focusing on its
main aspects. It starts with a simpler subclass of optimisation problems
called linear programs (chapter 1) and then moves on to the main
description of SDPs (chapter 2). In these two chapters we will also set up

the notation, nomenclature and basic definitions and concepts that will be
used throughout the book. Then, Part II is devoted to particular problems
from across the realm of quantum information science that can be tackled
with the help of semidefinite programming. The list of problems we
consider here is by no means exhaustive. Nonetheless, it is important to
explain a little about the choice of problems presented. First, we wanted to
cover a wide range of problems in quantum information. In this regard, you
will find chapters related to quantum states, measurements, entanglement
and channels. Second, we have chosen problems specifically that allow us
to introduce key methods and tools for transforming problems into SDPs,
and for manipulating and analysing those SDPs. These methods and tools
are those which we believe to be very useful for a reader who wants
semidefinite programming to be a useful tool in their research or work. In
this respect, we encourage the reader to go through all chapters, even if the
particular topic of the chapter is not so relevant for them; the way the topic
is studied should hopefully teach them something new and interesting about
semidefinite programming beyond the topic itself. In any case, we list the
most important messages of each chapter in a section called Concluding
Remarks.
The list of problems we cover are as follows:
Chapter 3 addresses one of most basic problems in quantum physics,
how to determine the properties of quantum states produced by an
uncharacterised source. There are numerous variants of this problem,
the most well-known being quantum state tomography, that is,
estimating exactly which state the source is emitting. In this chapter
we will review this and other variants of state estimation, including the
so-called quantum marginal problem. This will allow us to study
various aspects of SDPs, including how to obtain certificates of
infeasibility and the prevalent notion of a ‘witness’.
In chapter 4, we shift focus to quantum measurements. We will first
discuss the problem of estimating which measurement a given
measuring device is performing. We then study quantum state
discrimination, the problem of determining—by performing a
measurement—which state, out of a set of possibilities, a given source
is producing. We show how to gain new insight into this problem by

using the key concept of SDP duality, and how the tool of
complementary slackness can be used to derive optimality conditions.
We then move on to the problem of characterising quantum
entanglement in chapter 5. Entanglement is nowadays seen as the main
resource behind many quantum information tasks, such as quantum
teleportation, computation and cryptography. In this chapter we will
see how SDPs can be used to detect and quantify entanglement. We
will also see how we can use a sequence—or hierarchy—of
semidefinite programs to obtain approximations to the set of separable
quantum states, and therefore bounds on many quantities of interest.
In chapter 6 we will study one of the most basic and interesting
properties of quantum mechanics: measurement incompatibility. We
will see how this problem can be solved by semidefinite programming,
and use duality to uncover an unexpected link to quantum nonlocality.
Finally, in chapter 7 we will study quantum channels. We will see how
the so-called Choi–Jamiołkowski isomorphism—which links quantum
channels with quantum states—allows for semidefinite programming
techniques to be applied to quantum channels. We will then see how
we can estimate an uncharacterised channel, calculate the diamond
norm (which characterises the operational distinguishability between
channels) and finally how to use duality to uncover a link between a
channel optimisation problem and quantum entropies.
At the end of each chapter we also suggest a small amount of additional
material on each topic (in the section Further reading). It is important to
note that the list of references is by no means exhaustive. Our aim is simply
to provide the curious reader with further resources—in the form of relevant
textbooks or review articles—to complement the present text. In this
connection, let us stress that there are several texts on semidefinite
programming that can be used to complement this book in general. In
particular, the book Convex Optimization by S Boyd and L Vandenberghe is
a must-have reference on convex optimisation, which includes and goes
beyond the theory of SDPs, and provides the reader with a comprehensive
amount of information on the subject (and is freely available!). More
related to quantum information are the textbook The Theory of Quantum
Information and lecture notes Theory of Quantum Information by J Watrous

and the lecture notes Semidefinite Programming & Quantum Information
by J Sikora and A Varvitsiotis, all of which are freely available online.
Supplementary 
material 
is 
available 
at
https://github.com/paulskrzypczyk/SDPBook.
Finally, this book is very much just an introduction to the topic of
semidefinite programming. There are many more advanced topics that we
chose not to cover here. Our goal was to provide a solid foundation to the
key aspects of the theory, and to demonstrate their widespread applicability
in quantum information science. We hope that using this book as a
foundation, those readers who choose to do so, will be well placed to go on
and master more advanced aspects of semidefinite programming—and
more generally convex optimisation—and put them to good use in
whichever direction they see fit.
1Throughout this book we will use the acronym SDP to denote both semidefinite programming and
semidefinite program.

Part I
The fundamentals

IOP Publishing
Semidefinite Programming in Quantum Information Science
Paul Skrzypczyk and Daniel Cavalcanti

(1.1a
)
(1.1b
)
(1.1c
)
(1.1d
)
(1.1e
)
Chapter 1
Linear programming
1.1 The basics
Before jumping into semidefinite programming (SDP), we start by discussing a simpler type of
optimisation problem called linear programming. This will help us in setting up some of the
notation, and will lay important foundations for the reader, allowing them to become more familiar
with the type of problems that we will consider throughout this book.
A linear program (LP1) is a constrained optimisation problem that consists in maximising (or
minimising) a linear function f(x1, … , xk)—called the objective function—of a set of real
variables x1, … , xk, i.e. f : Rk →R. We will use the colour orange for variables throughout the
book, to visually highlight that these are the unknowns that need to be solved for.
These variables have to satisfy a set of linear equality and/or inequality constraints. That is, we
have a set of m functions gi : Rk →R with associated values bi, for i = 1, … , m, such that 
gi(x1, … , xk) = bi for all i, and similarly a second set of n functions hj : Rk →R with associated
bounds cj, for j = 1, … , n, such that hj(x1, … , xk) ⩽cj for all j.
Combining everything together, we can write a linear program as:
maximise
f(x1, … , xk)
gm(x1, … , xk) = bm,
hn(x1, … , xk) ⩽cn.
The different parts (or elements)—the objective function, the constraint functions, the bounds
—that arise in a linear program fall broadly into two different classes; there are those that can be
thought of as defining the problem itself, and those that form the particular instance of the problem.
It is perhaps easiest to think of this in analogy to how one would write a piece of computer code to
solve a problem. Instead of rewriting the code every time before being run, it is useful for the code
to accept some input data, which modifies the problem to some extent. This input data is what
specifies the particular instance of the problem, while the code (which doesn’t change from instance
to instance) specifies the problem that is being solved.
subject to
g1(x1, … , xk) = b1,
⋮
h1(x1, … , xk) ⩽c1,
⋮

(1.2a
)
(1.2b
)
(1.2c
)
(1.2d
)
(1.2e
)
As an example, consider that we want to solve a problem which involves optimising over a
probability distribution. In this case, we will need to impose that the probabilities are positive
numbers, which sum up to unity. These constraints belong to the problem, and will be the same,
independent of the instance of the problem being solved. On the other hand, there may be additional
constraints on the probabilities that will specify the instance. In example 1.1 below, we additionally
constrain some of the marginal probability distributions. Since we are interested not in a specific set
of marginals, but rather in the problem for an arbitrary set of fixed marginals, it is natural to view
these as the input data, specifying a particular instance of a general marginal problem.
There is no rule regarding which parts or elements of a problem will be fixed by the problem,
and which will depend upon the particular instance. For example, it could be that the equality
constraints define the problem, or that they define the instance, or that some arise from the problem
and some from the instance. In general, each part of a linear program can relate either to the
instance or the problem or both, ranging from the objective function, to just the bounds on some of
the inequality constraints, etc. As we come to study the many examples of LPs (and SDPs) in this
book this should hopefully become clear, and show how rich the interplay between instance and
problem can be.
In order to aid our thinking, when writing explicit examples down, we will use the colour blue
to denote the input data (i.e. those parts which depend upon the instance) and leave the other
elements which define the problem in black.
Example 1.1. Marginal Problem.
Consider three random variables X, Y and Z that can assume values x, y and z respectively.
Suppose that we have knowledge of the pairwise marginal distributions PX,Y (x, y), 
PX,Z(x, z), and PY ,Z(y, z), but not of the joint distribution PX,Y ,Z(x, y, z). Consider that we
would like to find the maximum of a linear function over all possible joint distributions that
have the fixed marginal distributions that we observe. For example, this could be simply one
of the elements, say PX,Y ,Z(0, 0, 0), or the correlator ⟨XY Z⟩= ∑x,y,z xyzPX,Y ,Z(x, y, z).
Given that probabilities are positive numbers that sum up to unity, this is an instance of an LP,
and can be written as:
maximise
f(PX,Y ,Z(x, y, z))
subject to
∑
z
PX,Y ,Z(x, y, z) = PX,Y (x, y) ∀x, y,
∑
y
PX,Y ,Z(x, y, z) = PX,Z(x, z) ∀x, z,
∑
x
PX,Y ,Z(x, y, z) = PY ,Z(y, z) ∀y, z,
PX,Y ,Z(x, y, z) ⩾0 ∀x, y, z.
In this example it is only the right-hand side of the equality constraints, enforcing that
th
i
l di t ib ti
t th t
th i
t d t
if i
i
i
t
f th

(1.3a
)
(1.3b
)
(1.3c
)
the marginal distributions are correct, that are the input data specifying a given instance of the
problem.
It is also important to note that there appears to be a missing constraint, namely 
∑x,y,z PX,Y ,Z(x, y, z) = 1. This constraint is in fact implicitly contained in the above
problem. If for example we consider the first constraint, and sum both sides over all x and y,
as long as PX,Y (x, y) is a normalised marginal probability distribution, which will always be
the case in problems of interest, then it implies that the joint distribution must also be
normalised.
The above is a simple example, but hopefully starts to demonstrate that natural problems indeed
have the structure of the abstract linear program specified above. As will be seen throughout this
book, the structure of a linear program is sufficiently general that many problems can be identified
as as such.
Exercises
1.1 Show that any LP can also be written as a minimisation problem, by suitably
redefining the objective function. In this way, it can be seen that we can equally consider
minimisation or maximisation problems, and we should use whichever is most natural
from the perspective of the problem of interest2.
1.2 Show that a constraint imposing a lower bound can always be expressed as a
constraint imposing an upper bound. In this way, it can be seen that we can take all
constraints to be upper bounds without loss of generality..
It can often be useful to adopt a vectorial notation and rewrite LPs in a more compact form.
First, it is useful to introduce a vector →x ∈Rk to contain the variables of the problem. Second, the
linear function f can be encoded in a vector →a ∈Rk, such that f(x1, … , xk) = →a ⋅→x. In a similar
way, each linear function associated with the equality and inequality constraints, gi and hj
respectively, can be encoded in vectors →r i ∈Rk and →sj ∈Rk respectively. With this convention, the
LP (1.1) can be re-expressed as
maximise
→a ⋅→x
subject to
→r i ⋅→x = bi,
i = 1, … , m
→sj ⋅→x ⩽cj,
j = 1, … , n.
As a second example, we now show how the ℓ1 and ℓ∞ norms of vectors can be cast as LPs.
This will show that in some cases, even if the objective function is not linear, it is possible to
manipulate the optimisation problem so that it can be written as an LP. This is an important point
that will appear again and again in other problems discussed in this book. This shows that LPs
capture a much broader class of problems than may initially be obvious.

(1.4)
(1.5a
)
(1.5b
)
(1.6a
)
(1.6b
)
(1.7a
)
(1.7b
)
Example 1.2. ℓ1 and ℓ∞ norms.
For a vector →y, recall that the ℓ1 and ℓ∞ norms are given by
∥→y ∥1= ∑
i
∣yi ∣,
∥→y ∥∞= maxi ∣yi ∣.
Although both of these norms appear to be non-linear functions of →y, they can both in fact be
calculated by linear programming.
In order to see how this is possible, consider first the simpler problem of evaluating the
absolute value ∣z ∣ of a number z. This will be equal to z if z ⩾0, and equal to −z if z < 0.
One way to evaluate this is to introduce a variable x, and solve the simple LP
∣z ∣= minimise
x
subject to −x ⩽z ⩽x,
where we have expressed two inequality constraints in a single line, which should
hopefully cause no confusion. If z ⩾0, then the constraint z ⩽x will be the limiting one, and
x = z is the minimum value of x we can take. On the other hand, if z < 0, then −x ⩽z will
be the limiting one, in which case x = −z is the minimum (positive) value of x. In both
cases, x =∣z ∣, as required.
This basic idea can be generalised to evaluate the ℓ1 and ℓ∞ norms In particular, we find
∥→y ∥1= minimise
→1 ⋅→x
subject to −→x ⩽→y ⩽→x
where →1 = (1, … , 1), such that the objective function is the sum of the elements of →x,
that is →1 ⋅→x = ∑i xi. This LP is then seen to just sum up the absolute value of each
component of →y, as required. For the ℓ∞ norm we have, similarly,
∥→y ∥∞= minimise
x
subject to −x→1 ⩽→y ⩽x→1.
Here, instead of introducing a vector variable →x, we have introduced a scalar variable x.
The constraint demands that x ⩾∣yi ∣, for all i. It is the largest such value, maxi ∣yi ∣ which
will be the limiting constraint, and thus we will recover the ℓ∞ norm.
Exercises
1.3 If f(x1, … , xk) = →a ⋅→x, show that the component ak of →a is f(0, … , 0, 1, 0, … , 0),
where the 1 is the kth argument, corresponding to the variable xk.

(1.8a
)
(1.8b
)
(1.9a
)
(1.9b
)
(1.10
)
(1.11
)
1.4 Consider the function of two variables, f(x1, x2) = 2x1 −x2. Write down the
associated vector →a.
1.5 If gi(x1, … , xk) = →r i ⋅→x, find the analogous relationship between the components
of →r i and the value of gi at a carefully chosen point.
1.6 An alternative formulation of the ℓ1 norm compared to (1.6) is
∥→y ∥1= maximise
→t ⋅→y
subject to
∥→t ∥∞⩽1,
i.e. the ℓ1 norm of a vector →y is the largest scalar product between →y and any vector 
→t  whose ℓ∞ norm is bounded by one. For this reason, the ℓ1 norm is said to be the dual
norm of the ℓ∞ norm.
The formulation (1.8) is not an LP, due to the non-linear constraint. Using the LP (1.7)
for the ℓ∞ norm, show that it is possible to obtain an alternative LP representation of the 
ℓ1 norm given by
∥→y ∥1= maximise
→t ⋅→y
subject to −→1 ⩽→t ⩽→1.
It is also common to go one step further than the vectorial form for an LP given in (1.3), by
combining all of the vectors →r i associated to the equality constraints into a single rectangular m × k
matrix B, such that the rows of B are given by the transposed vectors (row vectors) →r T
i ,
B =
.
Similarly, all of the vectors associated to inequality constraints can be combined into a
rectangular n × k matrix C, such that the rows are given by the transposed vectors →sT
j ,
C =
.
The values bi and bounds cj can then naturally be viewed as the components of vectors 
→b ∈Rm and →c ∈Rn, respectively, and (1.3) can be expressed as
maximise
→a ⋅→x
⎛
⎜
⎝
→r T
1
⋮
→r T
m
⎞
⎟
⎠
⎛
⎜
⎝
→s
T
1
⋮
→s
T
n
⎞
⎟
⎠

(1.13
)
(1.14
)
(1.15
)
(1.12
a)
(1.12
b)
(1.12
c)
subject to
B→x = →b,
C→x ⩽→c.
 
It is important at this stage to point out that in (1.12c) we use the notation →y ⩽→z in a
component-wise manner, meaning that yk ⩽zk for k = 1, … , n. Alternatively, we can view this as
imposing that the vector →z −→y is component-wise nonnegative.
1.1.1 Feasibility
A vector →x satisfying the constraints of an LP, e.g. (1.12b) and (1.12c) is called a feasible point. In
general, there will exist infinitely many feasible points for an LP, as will be seen in more detail
below. We will denote the set of all feasible points by F, and refer to it as the feasible set. This set
has an extremely important property: it is a convex set. This means that if →x1 and →x2 are both
feasible points, then any point of the form →x′= p→x1 + (1 −p)→x2, with 0 ⩽p ⩽1 is also a feasible
point, →x′∈F. A proof of this is as follows:
Proof →x1 ∈F means that B→x1 = →b and C→x1
⩽→c. Similarly, →x2 ∈F means that B→x2 = →b
and C→x2
⩽→c. Together these conditions imply, due to linearity, that for any p, the point 
→x′= p→x1 + (1 −p) →x2 satisfies
and so →x′ satisfies the necessary equality constraints to be in F. Similarly, if we restrict
to 0 ⩽p ⩽1, then furthermore, again due to linearity,
where the restriction on p is needed to ensure that in both cases the inequalities do not
change direction. Thus →x′ satisfies all the necessary constraints, and is contained in F.
We will discuss the geometrical meaning of convexity in the next section.
With the above notation in place for the feasible set of an LP, we can compactly write an LP as
α = max
→x∈F →a ⋅→x,
that is, as the maximisation of the objective function over the feasible set.
B→x′ = B(p→x1 + (1 −p)→x2),
= p→b + (1 −p)→b,
= →b,
C→x′ = C(p→x1 + (1 −p)→x2),
⩽p→c + (1 −p)→c,
= →c,

(1.16
)
(1.17
)
(1.18
)
(1.19
a)
(1.19
b)
(1.19
c)
In the above we have also introduced α to denote the optimal value of the problem, i.e. the
maximal value that the objective function can take on the feasible set. When no confusion arises,
we will sometimes omit the word ‘optimal’, and refer simply to ‘the value’ of an LP, as the optimal
value of the objective function. We will use the notation →x* to denote an optimal variable that
achieves the maximum, i.e.
→x
* = argmax
→x∈F
→a ⋅→x.
Optimal variables in general are not unique: there can be infinitely many optimal variables that
simultaneously achieve the maximum. In fact, the set of all optimal variables is itself a convex set.
The proof of this is very similar to the proof that the feasible set F is convex, and is left as an
exercise below.
Clearly, the value of the objective function evaluated at any feasible point provides a lower
bound on α, i.e.
→a ⋅→x ⩽α ∀→x ∈F.
It can also occur that there is no feasible point, i.e. that there is no →x that satisfies all of the
constraints of the LP; another way of saying this is that the feasible set is the empty set: F = ∅. In
this case, the LP is said to be infeasible.
It is customary, and as we will see later, useful and mathematically consistent, to assign the
optimal value α = −∞ in this case. Intuitively, this indicates that the problem takes the smallest
possible value.
This finally leads us to a special subset of LPs known as feasibility LPs. Here the objective
function is constant, and can without loss of generality be taken to be such that →a = →0, i.e. such that 
f(x1, ⋯, xn) = 0 for all →x. The associated LP is then equivalent to checking for the existence of a
feasible point →x. We have that
α = max
→x∈F
→0 ⋅→x = {
which is to say that such an LP checks whether the feasible set F is the empty set or not.
Since it is a rather cumbersome notation to introduce an arbitrary constant objective function,
we will use a special notation for feasibility problems, which emphasises that their goal is to find a
feasible point if it exists:
find
→x
subject to
B→x = →b,
C→x ⩽→c.
Interestingly, this shows that feasibility problems of the form (1.19) are indeed themselves
linear programs, even though they appear not to be of the form (1.12) due the lack of a
maximisation.
An example of a feasibility LP that naturally arises is the following:
0
if F ≠∅,
−∞if F = ∅,

(1.20
a)
(1.20
b)
(1.20
c)
(1.20
d)
(1.20
e)
Example 1.3. Majorisation (feasibility form).
Consider two probability distributions P(x) and Q(x). Majorisation captures the important
notion of one probability distribution being more ‘disordered’ than another. The distribution 
P(x) majorises Q(x), written P(x) ≻Q(x), if there exists a doubly-stochastic matrix D,
with components Dxy, such that →q = D→p, where the components of →q and →p are the
probabilities qx = Q(x) and py = P(y) respectively. This leads to the following feasibility
LP:
find
D
subject to
D→p = →q,
∑
x
Dxy = 1 ∀y,
∑
y
Dxy = 1 ∀x,
Dxy ⩾0 ∀x, y.
In the above, the constraints (1.20c) and (1.20e) ensures that the matrix D is stochastic,
so that it maps probability distributions to probability distributions (i.e. maintains positivity
and normalisation), while (1.20d) ensures that D leaves the uniform distribution invariant,
and so is moreover doubly stochastic.
Exercises
1.7 Show that the set of all optimal variables of a linear program forms a convex set.
This implies, in particular, that if two or more distinct optimal variables exist, then there
will be infinitely many optimal variables, formed by convex combinations of these. This
fact can prove useful, as we will see later.
1.8 Check if the following LPs are feasible or not: (a)
(b)
find
→x
subject to
x1 + x2 ⩾1,
x1 ⩽1
3 ,
x2 ⩽1
2 .

(1.21
)
1.9 In example 1.1 we saw an instance of the marginal problem, where we want to
calculate a function f(PX,Y ,Z(x, y, z)) of the unknown joint distribution of three random
variables. An important instance of the marginal problem is the feasibility form, where
one wants to know whether the marginals are compatible with any joint distribution or
not.
(a) Write down the feasibility marginal problem LP for the scenario considered in
example 1.1, where we are given all three pairwise marginal distributions as data.
(b) Show that the marginal problem is always infeasible if the single party
marginals are inconsistent. That is, for example, if
∑
y
PX,Y (x, y) ≠∑
z
PX,Z(x, z).
This gives a simple set of necessary conditions that must be satisfied—and should
always be checked—before the LP is solved.
(c) Consider the marginal problem where we are only given two of the pairwise
marginal distributions, PX,Y (x, y) and PY ,Z(y, z), and assume these are consistent,
i.e. ∑x PX,Y (x, y) = ∑z PY ,Z(y, z). Show that this marginal problem is always
feasible, with solution
P
*
X,Y ,Z(x, y, z) = PX,Y (x, y)PY ,Z(y, z)
PY (y)
.
We say that this marginal problem has no frustration between the constraints
—there is no tension between simultaneously satisfying both constraints, and the
random variable Y can be simultaneously correlated with both X and Z. In Chapter
3, when we consider the analogous quantum marginal problem, it will be seen that
this property no longer holds, due to monogamy of entanglement.
It can sometimes be useful to recast a feasibility LP as a standard LP—i.e. as an LP with a non-
constant objective function. There are a number of reasons why this can be useful. First, from a
numerical perspective it is often much more stable to solve a standard LP than a feasibility LP.
Second, if a problem is indeed infeasible, it can often be useful to understand how close it is to
being feasible. Finally, as we will see below, when we introduce the important concept of duality,
having a feasibility LP expressed as a standard LP can again prove useful.
There are multiple ways in which a feasibility LP can be turned into a standard LP, and
depending upon the particular problem, different methods might be preferable. The feature they
have in common is to relax the constraints defining the feasible set, by introducing additional
variables, and then to minimise (or sometimes maximise) these variables, to attempt to solve the
find
→x
subject to
x1 + x2 + x3 = 1,
x1 + x2 ⩾1,
x2 + x3 ⩾1.

(1.22
)
(1.23
a)
(1.23
b)
(1.23
c)
(1.23
d)
(1.23
e)
(1.23
f)
problem with the original feasible set F. The example below shows one way of doing this for the
Majorisation feasibility problem from example 1.3.
Example 1.4. Majorisation (maximisation form).
The uniform probability distribution U(x) = 1/n, for x = 1, … , n is majorised by all other
probability distributions—it is the most disordered of all probability distributions. Using this
fact, we can consider the family of probability distributions
Qt(x) = tQ(x) + (1 −t)U(x)
parametrised by a new variable t such that 0 ⩽t ⩽1. This family extrapolates between 
Q(x) and the uniform distribution U(x). When t = 0, we have P(x) ≻Q0(x) = U(x). We
can then look for the largest value of t such that P(x) ≻Qt(x): if this occurs at t = 1, this
means P(x) ≻Q(x), and the original LP is feasible. If it occurs at t < 1, then P(x) ⊁Q(x),
and the problem is infeasible. Moreover, the closer t is to 1, the closer P(x) is to majorising 
Q(x). This relaxed form of the problem is an LP, given by
maximise
t
subject to
D→p = t→q + (1 −t)→u,
∑
x
Dxy = 1 ∀y,
∑
y
Dxy = 1 ∀x,
Dxy ⩾0 ∀x, y,
t ⩽1,
where →u is the uniform probability vector with components ux = 1/n.
Comparing to the original feasible form (1.20), we see that we have introduced one new
scalar variable, which has become the objective function. In terms of the constraints, it is only
the first equality constraint which is relaxed. Indeed, for a fixed value of t, the right-hand side
of this constraint has changed compared to its original form, and can be seen as relaxing the
feasible set when t < 1.
Exercises
1.10 In example 1.4 above, only the upper bound t ⩽1 is imposed, and not the lower
bound 0 ⩽t. Show that the lower bound on t is irrelevant due to this being a

maximisation problem. Hint: Show that t = 0 is a feasible choice, by finding an explicit
choice for D that is simultaneously feasible.
1.11 Turn the two feasibility LPs from exercise 1.8 into standard form LPs. Hint:
Consider relaxing the inequality constraints by introducing a new variable to be
minimised.
1.2 Geometric interpretation
Linear programs can be understood geometrically, and this is in fact a very useful way to gain
understanding and intuition about them. In this section, we will outline some of this geometric
understanding.
We will first focus on the feasible set F, before considering the objective function. Recall that
the feasible set is specified by a collection of equality and inequality constraints. In what follows,
we will take the variable to be a point →x ∈Rk.
1.2.1 Equality constraints
The set of all equality constraints {gi(→x) = bi}i specify an affine subspace H ∈Rk in which the
point →x must lie. Here the significance of the subspace being affine rather than linear is that it need
not pass through the origin. The dimension of this subspace will depend upon the number of
linearly independent equations in the LP. If there are ℓ linearly independent equations then the
dimension of H will be (k −ℓ). Each equation gi(→x) = bi itself specifies a hyperplane, and the
vector →r i which appears in the vector representation of the function, gi(→x) = →r i ⋅→x, is geometrically
the normal vector to the hyperplane. The affine subspace H is then nothing but the intersection of
all of the hyperplanes specified by each of the equality constraints. An illustrative example
involving two constraints in 3-D is depicted in figure 1.1.

Figure 1.1. Equality constraints. An illustrative example in 3-D of how an affine subspace H
arises from two equality constraints, g1(→x) = b1 and g2(→x) = b2. Both of these constraints
specify planes, with normal vectors →r 1 and →r 2, respectively. Their intersection is a line,
depicted in black. Any feasible point →x of the corresponding LP must lie on this line.
1.2.2 Inequality constraints
Inequality constraints, on the other hand, specify half-spaces, i.e. they divide the space into two,
such that →x must lie in one half. In particular, the vector →sj which appears in the vector
representation of the function →sj ⋅→x = hj(→x) ⩽cj is again geometrically the normal vector to the
hyperplane which divides the space in two. This hyperplane is displaced from the origin in the
direction of →sj by the amount cj.
The collection of all inequality constraints thus specify a set of half-spaces, and a feasible point
must lie in the intersection of all of these half-spaces. The resulting body is called a polyhedral set.
It may or may not be the case that this polyhedral set is bounded—i.e. is finite in extent. If it is
bounded, then the body is called a polytope. An illustrative example of a non-bounded polyhedral
set formed by two inequality constraints in 2-D is depicted in figure 1.2.

Figure 1.2. Inequality constraints. An illustrative example in 2-D of how inequality
constraints specify half-spaces. The constraint h1(→x) = c1 specifies a line, displaced by a
distance c1 in the direction of →s1, the vector which defines the function, h1(→x) = →s1 ⋅→x.
Points which satisfy the inequality lie in the (blue) shaded region above this line. It is possible
to specify any half-space in this manner. In this example, the brown shaded triangular region
on the right contains all the points which jointly satisfy both of the constraints, and is the
resulting polyhedral set formed by these two inequality constraints.
1.2.3 The feasible set
Putting the above two ingredients together, we see that the feasible set F of an LP is then
geometrically the intersection of the affine subspace H generated by the equality constraints, with
the polyhedral set formed by the inequality constraints. This intersection forms itself a polyhedral
set, which again may or may not be a polytope. We illustrate all of these ideas in the following
example, in which we see how the probability simplex arises.
Example 1.5 The probability simplex.
The probability simplex arises as the feasible set of an LP when the variable being optimised
is a probability distribution. Consider a three outcome random variable X, which takes on the
values x = 0, 1 and 2, with associated probability distribution p(x). In order to be a valid
probability distribution we have 3 inequality constraints, imposing that the probabilities are
positive,
p(0) ⩾0,
p(1) ⩾0,
p(2) ⩾0,

(1.24
)
(1.25
)
and a single equality constraint, imposing that the probability distribution is normalised,
p(0) + p(1) + p(2) = 1.
Geometrically, we can represent a probability distribution as a point in R3. The 3
inequality constraints collectively demand that the point →p, with components px = p(x), lies
in the positive orthant. The equality constraint is the plane which passes though (1, 0, 0), 
(0, 1, 0) and (0, 0, 1), the three deterministic probability distributions. The feasible set this
creates is the probability simplex, as depicted below.
In this example, the feasible set is seen to be bounded, and so is a polytope—it is simply
an equilateral triangle.
In higher dimensions we would arrive at a similar construction, which would produce
higher dimensional simplices arising as the intersection of the normalisation constraint
(geometrically an affine subspace) with the inequality constraints (geometrically the positive
orthant), which always leads to a simplex, a polytope with vertices equal to the deterministic
probability distributions.
Finally, in section 1.1.1 when we introduced the notion of feasibility, we saw that the feasible
set has the extremely important property of being a convex set. This is most easily understood from
a geometrical perspective. Recall that convexity says that every point of the form 
→x′= p→x1 + (1 −p)→x2, with 0 ⩽p ⩽1 is feasible whenever both →x1 and →x2 are. Geometrically says
that the line segment between any two points inside the set—→x1 and →x2—is itself inside the feasible
set. That is, the feasible set is not just a polyhedral set or polytope, but moreover a convex
polyhedral set or convex polytope. In figure 1.4 you will find a few examples of different convex
sets in 2-D.
Linear programs, and SDPs are special instances of a more general class of optimisation
problem known as convex optimisation problems. In all such problems, the feasible set always
forms a convex set, and this is crucial to the fact that LPs and SDPs don’t have local optima but
only global optima, and hence can be solved much more easily than problems which do not have
this property (so-called non-convex optimisation problems).
1.2.4 The objective function
Having visualised the feasible set F geometrically, all that remains is to understand the objective
function. Recall that this is a linear function f(→x), which can be specified by a vector →a through 
f(→x) = →a ⋅→x. Geometrically, it is useful to view this as a direction, specified by →a. Hyperplanes
perpendicular to →a are the surfaces on which the function is constant, as depicted in figure 1.3.

Figure 1.3. Objective function. An illustrative example in 2-D of the objective function 
f(→x) = →a ⋅→x, with the direction of →a depicted above. The dashed lines, perpendicular to →a, are
surfaces on which the function is constant.
The maximum of the function f(→x) thus occurs at the point (or points) in the feasible set F
which are furthest in the direction of →a. We can therefore see, rather intuitively from a geometric
perspective, that if the feasible set is bounded in extent, then the maximum will be finite; if on the
other hand the feasible set is unbounded, the maximum will depend on whether the direction of →a
coincides with the direction in which F is unbounded or not. This is illustrated in figure 1.4.

Figure 1.4. Graphical solutions to LPs. An illustrative example in 2-D of graphically solving
an LP. We depict the feasible sets of different LPs which share the same objective function. In
(a) the feasible set is a polytope, with optimal solution →x*. In (b) the feasible set is
unbounded, however, maximising the objective function still leads to a finite solution,
attained at →x
*. In (c) the feasible set is again unbounded, and in this case has no maximum
value, since it increases indefinitely in the direction of the objective function. If however, we
were to consider a minimisation problem over this set (with the same objective function), then
the minimum is finite and attained at →x
*.
Geometrically, we also understand why LPs can have infinitely many optimal solutions →x*. This
happens, in particular, when the relevant face of the feasible set happens to align with the objective
function, i.e. such that the normal vector to the face is in the same direction as the vector →a
specifying the objective function. In this case, all vectors →x on the relevant face of F will be
optimal, and achieve the same optimal value α = →a ⋅→x*.
Exercises
1.12 Draw a collection of inequality constraints in 2-D which lead to an infeasible LP.
1.13 Construct geometrically an LP in 2-D which is feasible as far as the inequality
constraints are concerned, but which is infeasible when an equality constraint is taken

into consideration.
1.14 It is often the case that the constraint →x ⩾→0 is included in the definition of an LP,
although this is by no means necessary. In this exercise, we will try to understand why
such a constraint can in principle be included without loss of generality, by suitably
changing variables. We will restrict attention to 2-D, where it is most easy to visualise
the key concepts.
(a) Sketch the feasible region of the following LP
and confirm that it is not true that →x ⩾→0 for all →x ∈F.
(b) Consider the new variable →x′= →x + →1. Rewrite the LP from (a) in terms of →x′,
and sketch the new feasible set F′. Show therefore that →x′⩾→0 within F′.
This shows that sometimesa simple shift of the variables of the problem make them
positive without loss of generality.
(c) Sketch the feasible region of the following LP
and confirm that it is not true that →x ⩾→0 for all →x ∈F.
(d) Consider the new variable →x′ such that
Rewrite the LP from (c) in terms of →x′, and sketch the new feasible set F′. Show
therefore that →x′⩾→0 within F′. Furthermore, show that this change of variables is
an orthogonal transformation (that is, it is a real matrix that preserves the inner
product between vectors) with determinant 1.
This shows that sometimes a simple rotation of the variables of the problem make
them positive without loss of generality.
(e) Sketch the feasible region of the following LP
maximise
2x1 + x2
subject to
x1 + x2 ⩽1
x1 −x2 ⩽1
x1 + x2 ⩾−1
x1 −x2 ⩾−1
maximise
−3x1 + x2
subject to
x1 + x2 ⩾0
x1 −x2 ⩾0
x′
1 = x1 −x2
√2
,
x′
2 = x1 + x2
√2
.
maximise
x1 + x2
subject to
2x1 + x2 ⩽2
x1 + 2x2 ⩽2

(1.26
a)
(1.26
b)
and confirm that it is not true that →x ⩾→0 for all →x ∈F. Use the sketch to explain
why no simple shift, rotation or reflection of the variables will be able to produce
new variables →x′ such that →x′⩾→0.
(f) Consider the new variable →x′ such that
Rewrite the LP from (e) in terms of →x′, and sketch the new feasible set F′. Show
therefore that →x′⩾→0 within F′.
(g) Write the transformation from (f) in the form →x′= S→x + →t . Confirm that S is not
an orthogonal transformation, but is invertible.
This shows that, in general, it is always possible to find an invertible affine
transformation – i.e. a shift and an invertible linear transformation – that
transforms the feasible set so that it is contained inside the positive quadrant. Can
you think of any exceptions to this?
1.3 Duality
We now introduce an extremely important aspect of the theory of linear programs—duality. Every
linear program has an alternative formulation, which is known as the dual problem. The importance
of the dual problem, as will be seen, is that any feasible point it defines provides an upper bound to
the original linear program. In order to differentiate the original problem from the dual problem,
from now on the original problem will be referred to as the primal LP.
As we noted above, it is rather straightforward to find lower bounds on the optimal value of a
linear program, since any feasible point →x ∈F provides such a bound. What is less obvious at first
sight, is how to find upper bounds, and this is the first key motivation for introducing the dual
problem.
The dual formulation is in reality much more useful than just this. Under some mild
assumptions, that will be presented later on, the optimal value of the dual LP is guaranteed to be
equal to the optimal value of the primal LP. It is for this reason that we refer to this as the dual
formulation, as it provides a completely novel way of expressing the optimisation problem of
interest, with wide ranging implications, both from a calculational perspective, as well as from a
conceptual perspective.
In what follows we will derive the general form of the dual LP associated to a primal LP in the
form (1.3), i.e. when using the vectorial notation. In order to do so, let us first rewrite (1.3) and
associate Lagrange multipliers—also known as dual variables to each constraint:
maximise
→a ⋅→x
subject to
→r i ⋅→x = bi
i = 1, … , m
: yi
→sj ⋅→x ⩽cj
j = 1, … , n
: zj
x′
1 = −2x1 + x2 + 2
3
,
x′
2 = x1 −2x2 + 2
3
.

(1.26
c)
(1.27
a)
(1.27
b)
(1.28
)
(1.29
)
(1.30
)
where we have displayed the dual variables (in red) after the colon on the right-hand side of each
equation, i.e. yi is the dual variable associated to the equality constraint →r i ⋅→x = bi, and
similarly for zj.
Let us now define the so-called Lagrangian of the problem as the following function
L = →a ⋅→x +
m
∑
i=1
yi(bi −→
ri ⋅→x) +
n
∑
j=1
zj(cj −→
sj ⋅→x)
= (→a −
m
∑
i=1
yi→r i −
n
∑
j=1
zj→sj) ⋅→x +
m
∑
i=1
yibi +
n
∑
j=1
zjcj,
The Lagrangian is constructed by adding additional terms to the objective function, where the
additional terms are formed by multiplying the constraints with the associated dual variables. The
logic of this construction is that these are the most general linear functions of the constraints that
can be added—equivalent to an arbitrary scaling. The utility of this will become apparent in the
following.
Although not written explicitly, the Lagrangian should be considered as a function of the primal
variable →x, and all of the dual variables yi and zj.
A priori the dual variables that appear in the Lagrangian are arbitrary. However, it will prove
useful to impose some carefully chosen constraints on these variables. In particular, we will first
impose that
zj ⩾0
∀j.
In order to understand why these constraints are imposed, let us consider the value of the
Lagrangian when →x is taken to be a feasible point of the primal LP, →x ∈F. Focusing on (1.27),
independent of whether we impose the above constraint or not, notice first that the second term
vanishes, since bi −→
ri ⋅→x = 0 for all i, from (1.26b). Now, upon imposing the constraint (1.28), the
third term will necessarily be nonnegative, which follows from (1.26c).
The above implies, in particular, that we have the important property
L ⩾→a ⋅→x
for all →x ∈F whenever zi ⩾0 ∀i.
That is, the Lagrangian is seen to upper bound the value of the objective function for all
feasible points →x when the restriction (1.28) is imposed on the dual variables.
We can go one step further, by focusing on (1.27b). Notice that it is possible to make the
Lagrangian independent of the primal variable →x if we further restrict our attention to dual variables
which satisfy
→a −
m
∑
i=1
yi→r i −
n
∑
j=1
zj→sj = →0.
In this case, the Lagrangian simply equals

(1.31
)
(1.32
a)
(1.32
b)
(1.32
c)
(1.33
a)
(1.33
b)
(1.33
c)
L =
m
∑
i=1
yibi +
n
∑
j=1
zjcj.
Because of the previous constraint/restriction on the dual variables, the Lagrangian remains
larger than the objective function when evaluated at any feasible primal point, even though it is now
independent of the primal variable in this subspace of dual variables. That is, the Lagrangian is
constant as far as the primal variables are concerned when the set of dual variables is restricted to
satisfy (1.30). Moreover, because the dual variables are simultaneously restricted to satisfy (1.28),
we are guaranteed that the value of the Lagrangian is always larger than the value of the primal
objective function.
The final key observation is then to realise that the tightest upper bound on the primal objective
function is obtained by minimising the Lagrangian over the dual variables subject to the carefully
chosen constraints (1.28) and (1.30). That is, we arrive at the following optimisation problem,
known as the dual LP:
minimise
m
∑
i=1
yibi +
n
∑
j=1
zjcj
subject to
→a −
m
∑
i=1
yi→r i −
n
∑
j=1
zj→sj = →0,
zj ⩾0
j = 1, … n.
 
We can simplify the form of the dual LP by realising that yi and zj can naturally be taken to be
components of vectors →y and →z, living in Rm and Rn respectively. The dual objective function is
then simply →b ⋅→y + →c ⋅→z. For the constraint, recall that in (1.10) we previously defined B to be the
matrix whose rows were →
ri
T. From this it follows that ∑i yi→
ri = BT→y. Similarly it can be seen
that ∑j zj→
sj = C T→z, where C is defined in (1.11), and is the matrix whose rows are →
sj
T, so that
the columns of C T are the vectors →
sj.
Putting everything together, we arrive at the equivalent, but simpler form of the dual LP:
minimise
→b ⋅→y + →c ⋅→z
subject to
BT→y + C T→z = →a,
→z ⩾0.
The structure of the dual is very similar to the primal LP in matrix form as given in (1.12).
First of all, it is a constrained optimisation problem, but now a minimisation instead of a
maximisation. Second, the objective function, which we will refer to as the dual objective function,
is linear in the dual variables →y and →z. Finally, it contains linear equality constraints, and the
simplest inequality constraint, →z ⩾0. That is, the dual is itself a linear program. The difference is
that whereas the primal problem had a single variable →x, in the dual we have ended up with a pair of

(1.34
)
(1.35
)
variables →y and →z. This apparent difference is in fact purely cosmetic, and it is possible to make the
two problems look identical in form. In particular, the dual vectors can be concatenated into a single
vector →y′= →y ⊕→z ∈Rm+n, i.e.
→
y′ = [ ].
Carrying out the rest of the details explicitly is left as an exercise below. In what follows we
will continue to instead phrase the dual LP in terms of the pair of variables, and take it as
understood that the key structure of a linear program is to have a linear objective function and linear
equality and inequality constraints in any number of variables3.
One interesting point worth highlighting is how the dimensions of the primal and dual problems
differ. The primal problem optimises over k variables and involves m equality constraints and n
inequality constraints. In contrast, the dual problem optimises over n + m variables and involves k
equality constraints and n inequality constraints. Since all of k, n and m can vary independently, this
means that there can be big differences between the dimensions of the primal and dual problems,
when considered geometrically.
Since the dual problem is itself an LP, this means that we have all of the same ingredients as for
the primal LP. When we want to explicitly differentiate between the two, we will prefix with either
primal or dual. When this distinction isn’t important, we will drop this prefix.
In particular, any pair of dual variables (→y, →z) that satisfy the constraints of the dual LP will be
said to be dual feasible, and the set of all dual feasible variables will be denoted by ˜
F. The dual
optimal value is then compactly
β = min
(→y,→z)∈˜
F
→b ⋅→y + →c ⋅→z
and any pair of variables (→y*, →z *) that achieve the minimum are called dual optimal. As with
primal LPs, we will sometimes refer to β simply as ‘the value’ of the dual, by which we always
mean the optimal value of the dual objective function.
In order to illustrate further how to find the dual of a problem, we will now return to our first
example, and obtain its dual LP:
Example 1.6 Dual of marginal problem LP.
In this example, we return to the marginal problem, which was reformulated as an LP in
example 1.1. The Lagrangian associated to this problem is
→y
→z
L = f(PX,Y ,Z(x, y, z)) + ∑
x,y
ν(x, y)(PX,Y (x, y) −∑
z
PX,Y ,Z(x, y, z))
+ ∑
x,z
ν(x, z)(PX,Z(x, z) −∑
y
PX,Y ,Z(x, y, z))
+ ∑
y,z
ν(y, z)(PY ,Z(y, z) −
+ ∑
x,y,z
ω(x, y, z)PX,Y ,Z(x, y, z),

Exercises
1.15 Re-express the dual LP (1.33) in terms of the concatenated variable 
→y′= →y ⊕→z ∈Rm+n.
1.16 Find the dual LP of the Majorisation LP (in maximisation form), from example 1.4.
1.17 Consider the following minimisation LP,
(1.36
)
(1.37
)
(1.38
)
(1.39
)
(1.40
a)
(1.40
b)
(1.40
c)
where we have introduced sets of dual variables {ν(x, y)}x,y, {ν(x, z)}x,z, {ν(y, z)}y,z and 
{ω(x, y, z)}x,y,z, associated to the four sets of constraints from the primal problem. For a
feasible joint probability distribution PX,Y ,Z(x, y, z), the first three of these additional terms
will all vanish, and the final term can be made nonnegative by restricting attention to dual
variables such that
ω(x, y, z) ⩾0
∀x, y, z.
Under this restriction, we will have that L ⩾f(PX,Y ,Z(x, y, z)). By further re-arranging,
and writing f(PX,Y ,Z(x, y, z)) explicitly as f(PX,Y ,Z(x, y, z)) = ∑x,y,z ax,y,zPX,Y ,Z(x, y, z),
we arrive at
We can therefore make the Lagrangian independent of PX,Y ,Z(x, y, z)—the primal
variables—by restricting our attention further to dual variables that satisfy
ax,y,z −ν(x, y) −ν(x, z) −ν(y, z) + ω(x, y, z) = 0
∀x, y, z.
 
We obtain the dual formulation by then finding the best upper bound on the primal
objective function, i.e. by minimising the remaining terms in the Lagrangian subject to the set
of identified constraints, namely
ω(x, y, z) ⩾0
∀x, y, z.
L = ∑
x,y,z
(ax,y,z −ν(x, y) −ν(x, z) −ν(y, z) + ω(x, y, z))PX,Y ,Z(x, y, z)
+ ∑
x,y
ν(x, y)PX,Y (x, y) + ∑
x,z
ν(x, z)PX,Z(x, z) + ∑
y,z
ν(y, z)PY ,Z(y, z).
minimise
∑
x,y
ν(x, y)PX,Y (x, y) + ∑
x,z
ν(x, z)PX,Z(x, z) + ∑
y,z
ν(y, z)PY ,Z(y, z)
subject to
ν(x, y) + ν(x, z) + ν(x, y) −ω(x, y, z) = ax,y,z
∀x, y, z,

(1.41
)
(1.42
)
(1.43
)
Find the dual LP, which will now be a maximisation LP, by introducing dual variables
and a Lagrangian which will provide the tightest lower bound on the value of the primal
LP.
1.4 Slack variables
The dual of the marginal problem in example 1.6 allows us to introduce a new important concept—
that of a slack variable. These are variables that often arise when switching from a primal to a dual
problem, which do not appear in the objective function. As such, it is advantageous to solve for
them, which simplifies the structure of the dual LP, and usually highlights its form in a more natural
way.
In the example 1.6 notice that the dual variables ω(x, y, z) appear only within the constraints
and not in the objective function. We can therefore re-arrange (1.40) in order to solve for these
variables, leading to
ω(x, y, z) = ν(x, y) + ν(x, z) + ν(y, z) −ax,y,z
∀x, y, z.
However, we also have the inequality constraints (1.40b) ω(x, y, z) ⩾0, which must not be
forgotten about. This will continue to be imposed if we enforce
ν(x, y) + ν(x, z) + ν(y, z) ⩾ax,y,z
∀x, y, z.
This equation replaces the pair of equations (1.40) and (1.40b), combining them into a single
set of inequality constraints. What this shows is that the only role that ω(x, y, z) was playing was to
turn this set of inequality constraints into a set of equality constraints. This is why we refer to them
as ‘slack variables’, as they pick up the slack in a set of inequality constraints. After removing these
variables, we arrive at the simpler dual formulation of the marginal problem:
Exercises
1.18. In the main text we show how slack variables can be removed from an LP,
which has the effect of converting equality constraints into inequality constraints.
Show that, in the converse direction, whenever a problem has inequality
constraint(s), it is always possible to add new slack variable(s), satisfying suitable
inequality constraint(s), and convert it/them into equality constraint(s).
minimise
→a ⋅→x
subject to
B→x = →b,
C→x ⩾→c.
minimise
∑
x,y
ν(x, y)PX,Y (x, y) + ∑
x,z
ν(x, z)PX,Z(x, z)
+ ∑
y,z
ν(y, z)PY ,Z(y, z)
subject to
ν(x, y) + ν(x, z) + ν(y, z) ⩾ax,y,z
∀x, y, z.

(1.44
)
(1.45
)
(1.46
)
1.5 Weak and strong duality
In the above we introduced the dual LP in order to obtain the tightest upper bound on the primal
optimal value. In particular, to recap, it was shown that
where the second line follows from the dual constraint (1.33b), the third line follows directly
from the scalar product, the fourth line follows from the primal constraints (1.12b) and (1.12c) and
the last line follows from the dual objective function (1.33). This important relation is known as
weak duality.
Notice that any feasible pair of dual variables →y and →z, i.e. satisfying the constraints of the dual
LP, provide an upper bound on the dual optimal value β, since →b ⋅→y + →c ⋅→z ⩾β. Similarly, any
feasible primal variable →x—satisfying the constraints of the primal LP—provides a lower bound on
the optimal value α, i.e. →a ⋅→x ⩽α. Combining these observations with the statement of weak
duality, we thus also see that
→a ⋅→x ⩽α ⩽β ⩽→b ⋅→y + →c ⋅→z
for all primal feasible points →x and dual feasible pairs →y and →z. This is itself an important result
that leads to the following realisation: if one finds a set of primal and dual feasible variables such
that
→a ⋅→x = →b ⋅→y + →c ⋅→z
then it follows immediately that they must be primal and dual optimal respectively.
Furthermore, in this case, something interesting has happened—the values of the primal and dual
LPs in fact coincide, i.e. saturate the bound of weak duality. If this special condition holds, we say
that the LP satisfies strong duality.
Conceptually, strong duality is very important, and justifies why we refer to the dual LP as dual:
it really is an equivalent way of arriving at the value of the LP—and here we can refer to the value
of the LP since the dual value and the primal value are equal.
Crucially, strong duality is not just a theoretical possibility, but is the generic behaviour of LPs:
that is, in practice, it is essentially always the case that an LP will satisfy strong duality, unless the
problem is set up in a particularly bad way. In particular, it can be shown that:
Whenever the primal LP is feasible and bounded, i.e. −∞< α < ∞, then strong duality
holds, and the value of the primal and dual LPs coincide, α = β.
There are two other possibilities, that the primal LP can be either infeasible or unbounded. In the
former case, the primal feasible set F is empty. In the latter case, the feasible set must be a
α = →a ⋅→x
*
= (BT→y
* + C T→z
*) ⋅→x
*
= →y
* ⋅B→x
* + →z
* ⋅C→x
*
⩽→y
* ⋅→b + →z
* ⋅→c
= β,

polyhedral set, rather than a polytope, and the direction of the objective function must align with the
direction in which the feasible set is unbounded. In both cases, strong duality will not in general
hold.
As will be seen, and as should be fairly intuitive, in any problem that is relevant in this book—
and where we want to use duality—or in practice, the LP will always be feasible and bounded, and
hence strong duality will hold, and prove to be a powerful tool. The exception to this rule is when
considering feasibility problems, where by construction the problem is to determine whether the LP
is feasible or not. However, as seen previously, we can recast feasibility LPs as standard LPs, and
therefore even in this case duality can still be used as a powerful tool.
Finally, it was also noted that the dual problem is itself an LP. There is in fact nothing special
about which problem we call the primal and which the dual, and therefore from the perspective of
strong duality, everything can alternatively be phrased in terms of the dual instead. In this case, as
long as the dual LP is feasible and bounded, then strong duality will hold.
We will not provide a proof of the fact that if the primal or dual is feasible and bounded then
strong duality holds. Proofs can be found in many standard texts on linear programming. Since this
book is introductory and focuses on the use of linear and semidefinite programming in quantum
information science, we rely merely on using it to ensure that the dual formulation is an equivalent
expression for the problems considered here.
1.6 Concluding remarks
In this chapter we have covered most of the fundamental aspects of linear programming. The
purpose of this was two-fold. First, linear programming is an interesting and relevant topic by itself,
and actually many interesting problems in quantum information can be recast as an LP. Second, and
more importantly, the aim of this chapter was to serve as an introduction to the main topic of this
book, semidefinite programming. As we will see in the next chapter, semidefinite programming is a
rather natural extension of LP, that arises when optimising over variables naturally associated with
operators, rather than those naturally associated with vectors. Because of this, many of the features
and results discussed in this chapter will naturally generalise to SDP.
We hope that at this point you now have a basic familiarity with LPs. In particular, we would
like that you keep in mind the following important take-home messages:
Definition. A LP is an optimisation problem (customarily a maximisation) of a real linear
function over real variables, subject to various linear equality and inequality constraints—see
(1.12).
Duality. Every LP has an associated dual formulation, which is itself an LP (customarily a
minimisation)—see equation (1.33).
Weak duality. Every feasible point of the dual LP provides an upper bound on the optimal
value of the primal LP. Similarly, every feasible point of the primal LP provides a lower bound
on the optimal value of the dual LP—see (1.44).
Strong duality. Under mild assumptions (feasibility and boundedness) the primal and dual
optimal values are equal to each other.
Representability. It is sometimes possible to reformulate an optimisation problem with a non-
linear objective function and/or non-linear constraints as an LP—see example 1.2.
1.7 Advanced topics

(1.47
)
(1.48
)
(1.49
)
We now go on to cover a couple of more advanced topics. As a reader, if you are just interested in
covering just the basics of linear programming, then this section is not as essential as the topics
covered above. As such, it can safely be skipped in the first instance. However, in our view, as one
gains more familiarity with LPs and SDPs, it should prove useful to revisit these topics, as they will
add to the general toolbox of techniques that can be applied to solve problems, and will aid in
gaining further insights using linear programming.
1.7.1 Complementary slackness
An important concept which arises from strong duality is the notion of complementary slackness,
which provides useful information about primal and dual optimal variables, and their relationship.
Moreover, as we will see, the complementary slackness conditions furthermore provide us with a
set of necessary and sufficient criteria for optimality, which can be used in place of solving an LP
directly.
Let us return to the Lagrangian associated to the primal problem (1.26), namely
L = →a ⋅→x +
m
∑
i=1
yi(bi −→
ri ⋅→x) +
n
∑
j=1
zj(cj −→
sj ⋅→x).
The dual LP (1.32) was obtained by minimising this Lagrangian subject to a number of
carefully chosen constraints. When strong duality holds, it tells us that the Lagrangian evaluated
using a set of optimal variables is equal to the value of the primal objective function, which is
simply →a ⋅→x
*. This is however just the first term of the Lagrangian, and therefore, the sum of the
remaining terms must vanish. The second term vanishes, since →x* is feasible. This leaves just the
final term. Each term in the sum is however nonnegative, by the constraints of the primal and dual
LPs, (1.3c) and (1.32c) respectively. Therefore, when strong duality hold, it follows that
z
*
j(cj −→
sj ⋅→x*) = 0
∀j.
These conditions are known as complementary slackness conditions. They tell us that there are
important orthogonality relations between the primal and dual optimal variables. This can most
readily be seen by re-expressing (1.48) in vector notation, which reads
→z
* ⋅(→c −C→x
*) = 0,
where we recall that C is the matrix defined in (1.11) whose rows are the transposed vectors 
→sT
j . That is, the optimal dual variable →z* is orthogonal to the vector →c −C→x* formed from the
optimal primal variable →x*.
We can gain some intuition about the complementary slackness conditions by introducing the
notion of whether a constraint is active or not. Imagine that we have found an optimal solution of
the dual LP, such that some component or components of the optimal dual variable →z
* do not
vanish, e.g. z
*
1 ≠0. In this case, the constraint that z1 ⩾0 is not active as it did not constrain the
optimal value of the dual LP. If we look at the complementary slackness conditions (1.48), in order
to satisfy it, c1 −→
s1 ⋅x* = 0. This however shows that the constraint →
s1 ⋅x* ⩽c1 from the primal
LP is active, i.e. saturated. We can also apply the same reasoning to the inequality constraints of the
primal LP, and arrive at similar conclusions.

(1.50
)
(1.51
a)
(1.51
b)
(1.51
c)
What this shows us is that whenever a constraint in the primal (or dual) is not active—meaning
that the inequality is not saturated by the optimal variables—then the constraint on the associated
dual (or primal) variable is necessarily active. We can view this as showing that the ‘slack’ in the
problem has to be picked up either by the primal or by the dual.
This can also be understood from a simple example. Consider the probability simplex from
example 1.5. If we were to add an additional constraint
p(0) + p(1) + p(2) ⩽2,
then clearly this constraint is never active, since p(0) + p(1) + p(2) = 1 < 2. Thus, including
this additional constraint in any LP which optimises over the probability simplex will have no effect
on the optimal value. This new constraint constrains the problem in an unessential (or trivial) way.
Now consider how the Lagrangian—and therefore dual LP—of the problem with the additional
constraint relates to the original problem. The only difference between these two dual problems
would be that the original problem would have fewer dual variables, since there is one fewer
constraint in the problem. There is however a different way to think about this: instead of viewing
the problem as having one fewer dual variable, we can instead imagine imposing the additional
constraint, and at the same time impose that the associated dual variable is zero. This is exactly
what happens in complementary slackness—if an optimal dual variable zj is found that vanishes,
then we know that the corresponding constraint from the primal was in fact non-essential and non-
constraining.
Finally, complementary slackness is important since if we impose it, along with the constraints
of the primal and dual problems, a set of conditions which are both necessary and sufficient for
optimality are obtained. That is, a set of primal and dual variables are jointly optimal if and only if
Primal feasible:
B→x* = →b,
C→x* ⩽→c,
Dual feasible:
BT→y
* + C T→z
* = →a,
→z
* ⩾0
Complementary slackness:
→z* ⋅(→c −C→x*) = 0.
These conditions can prove useful. In particular, they provide a method for finding optimal
solutions: if the primal and dual feasible sets have been fully characterised, one can try and directly
solve the complementary slackness condition. If this can be achieved, we are guaranteed that these
variables are optimal. In exercise 1.21 below an example of this will be seen.
Exercises
1.19 In the main text we analysed the situation where the optimal dual variables z
*
1 did
not vanish (meaning that the first of the dual inequality constraints is not active). We saw
that this implied that the associated inequality constraint on the primal variable must be
active (i.e. satisfied with equality). Show, on the contrary, that if one of the inequality
constraints is not active for an optimal primal variable, then this implies that the
associated optimal dual variable vanishes (and hence the inequality constraint is not
active).

(1.52
a)
(1.52
b)
(1.52
c)
(1.53
a)
(1.53
b)
(1.53
c)
(1.53
d)
(1.54
a)
(1.54
b)
1.20 In this exercise we will explicitly calculate what happens when non-essential
inequality constraints are removed from a simple linear program. Consider the following
LP in two variables
maximise
x1 + 2x2
subject to
−1 ⩽x1 ⩽2,
−3 ⩽x2 ⩽4.
(a) Solve this LP by inspection to show that the optimal value is α = 10.
(b) Write down the Lagrangian associated to this LP, and use it to show that the dual LP
is
minimise
z1 + 2z2 + 3z3 + 4z4
subject to
z2 −z1 = 1,
z4 −z3 = 2,
z1 ⩾0,
z2 ⩾0,
z3 ⩾0,
z4 ⩾0.
(c) Solve the dual by inspection and verify that complementary slackness is
satisfied by the optimal primal and dual variables and identify which constraints of the
primal and dual LPs are active, and which are inactive.
(d) Consider now the problem formed by ignoring the inactive constraints from the
above LP. Write down the primal LP and its Lagrangian. Show that this leads to a trivial
dual LP.
1.7.2 Dual form of ℓ1 and ℓ∞ norms
In this section we will return to the ℓ1 and ℓ∞ norms from example 1.2 and study their dual forms.
Using these, in combination with a characterisation of norms in terms of their dual norms, we will
arrive at an interesting way of characterising the norm balls in terms of feasibility LPs.
For the ℓ1 norm, the Lagrangian associated to the problem (1.6) is
L = →1 ⋅→x −→u ⋅(→y + →x) −→v ⋅(→x −→y),
= (→1 −→u −→v ) ⋅→x + (→v −→u) ⋅→y,
where →u and  are the dual variables associated to the left-hand and right-hand inequalities in
(1.6b). Since (1.6) is a minimisation problem, we want L to be smaller than the primal objective
function for all feasible primal variables →x, hence we take →u ⩾0 and 
 and note that extra
minus signs have been introduced into the Lagrangian compared to how it has been defined
previously, in order to make the dual vectors nonnegative. The Lagrangian is made independent of
the primal variables by further choosing 
. We obtain the dual LP by finding the best
lower bound, i.e. by maximising, leading to

(1.55
a)
(1.55
b)
(1.55
c)
(1.56
a)
(1.56
b)
(1.57
a)
(1.57
b)
(1.58
)
(1.59
a)
(1.59
b)
(1.59
c)
∥→y ∥1= maximise
(→v −→u) ⋅→y
subject to
→u + →v = →1,
→u ⩾0,
→v ⩾0.
This is indeed equal to ∥→y ∥1 as we can see that strong duality holds for vectors →y of interest.
In particular, if all of the entries of →y are finite, then ∥→y ∥1< ∞, and the primal is clearly feasible,
hence strong duality holds. We can learn something more by combining the insight from the dual
formulation of the ℓ1 norm with the expression for the ℓ1 norm given in exercise 1.6, namely
∥→y ∥1= maximise
→t ⋅→y
subject to
∥→t ∥∞⩽1.
By carefully comparing (1.55) and (1.56), we find an interesting method to characterise the
ℓ∞ unit ball—the set of vectors which have infinity norm less than or equal to unity. The standard
definitions for this ball are
B∞= {→t ∣∥→t ∥∞⩽1},
= {→t ∣−→1 ⩽→t ⩽→1},
where the second line just states that all components of any vector in the ball must be between
−1 and 1.
To arrive at the new characterisation, compare (1.55) and (1.56). Notice that 
 is playing
the role of →t , and hence the constraints on →u and  must ensure that 
. That is, we are
lead to a third—and less obvious—characterisation of the unit ball, namely
B∞= {→t ∣→t = →v −→u, →u + →v = →1, →u ⩾0, →v ⩾0}.
This form, and the form (1.57b), provide us with two interesting methods to optimise over B∞,
since they show that the ball is representable by a set of linear inequality and equality constraints,
hence it can be used inside an LP, turning a seemingly non-linear constraint on a variable into a set
of linear ones.
As an exercise below you will similarly show that the dual form for the ℓ∞ norm is given by
∥→y ∥∞= maximise
(→v −→u) ⋅→y
subject to
(→u + →v ) ⋅→1 = 1,
→u ⩾0,
→v ⩾0
from which it follows that the unit ℓ1 ball, B1 = {→t ∣∥→t ∥1⩽1}, can be alternatively
represented as

(1.61
)
(1.62
)
(1.60
)
B1 = {→t ∣→t = →v −→u, (→u + →v ) ⋅→1 = 1, →u ⩾0, →v ⩾0}.
This case is more interesting than the case of B∞ in some ways, since here it is only through
duality that we arrive at a characterisation for B1 that is representable by a LP. This provides, as
above, a method to impose the seemingly non-linear constraint ∥→x ∥1⩽1 inside an LP.
Exercises
1.21 In this exercise we will find the complementary slackness conditions for the ℓ1 LP
in (1.6), and use them to certify optimal variables.(a) Starting from the Lagrangian
(1.54), show that the complementary slackness conditions are
u
*
i (yi −x
*
i ) = 0
∀i,
v
*
i (yi + x
*
i ) = 0
∀i.
(b) Show that the following primal and dual variables are feasible for their
respective problems:
xi =∣yi ∣,
ui = {
vi = {
(c) Use complementary slackness to show moreover that the variables from (b) are
optimal primal and dual variables, and confirm that the primal and dual objective values
coincide with each other, and are equal to ∥→y ∥1. We can interpret →x
* as being the
absolute-value-vector of →y, and 
 and →u* as being projectors onto the positive and
negative parts of →y, respectively.
1.22 In this exercise we will show that the ℓ1 unit ball is given by (1.60).
(a) Write down the Lagrangian associated to the primal LP for the ℓ∞ norm given in
(1.7), and use it to derive the dual LP as given in (1.59).
(b) Using the fact that
show that the ℓ1 unit ball is given by (1.60).
1.23 Derive the dual of the LP for the ℓ1 norm found in exercise 1.6. How does this
relate to the 3 other LPs, (1.6), (1.8) and (1.55), found for the ℓ1 norm so far?
1.24 We can use the LP representations of B1 and B∞ to arrive at alternative relaxations
of the majorisation feasibility LP from example 1.3. In particular, we can introduce a
new variable →q′, which is an approximation to →q, and minimise the distance between →q
and →q′, where the distance can be either ∥→q −→q′∥1 or ∥→q −→q′∥∞. Explicitly, the two
relaxations are
1 if yi < 0,
0 otherwise,
1 if yi ⩾0,
0 otherwise.
∥→y ∥∞= maximise
→t ⋅→y
subject to
∥→t ∥1⩽1,
minimise
t
minimise
t

Use the characterisations of B1 and B∞ to express both of these problems as LPs.
1.8 Further reading
Boyd S and Vandenberghe L 2004 Convex Optimization (Cambridge: Cambridge University
Press) https://web.stanford.edu/~boyd/cvxbook/
1Throughout this book we will use the acronym LP to denote both linear programming and linear program.
2We will state the take-home message of an exercise, where appropriate, directly after it, in purple italic text, or provide additional
context/information about the exercise and its significance. It will be useful to consult these take-home messages once the exercise
has been completed, to make sure the purpose of the exercise is fully understood.
3It is useful to recall that →x was itself just a convenient way of grouping together the k variables xi. What we see is that when
deriving the dual LP, we naturally end up grouping the dual variables into two vectors →y and →z. Nothing however stops us from
further grouping these two into a single vector of dual variables.
minimise
t
minimise
t
subject to
D→p = →q′,
subject to
D→p = →q′,
∥→q −→q′∥1⩽t,
∥→q −→q′∥∞⩽t,
∑
x
Dxy = 1 ∀y,
∑
x
Dxy = 1 ∀y,
∑
y
Dxy = 1 ∀x,
∑
y
Dxy = 1 ∀x,
Dxy ⩾0 ∀x, y.
Dxy ⩾0 ∀x, y.

IOP Publishing
Semidefinite Programming in Quantum Information
Science
Paul Skrzypczyk and Daniel Cavalcanti

Chapter 2
Semidefinite programming
In this chapter we will cover the fundamental aspects of semidefinite programming,
which will be seen to be closely related to the fundamental aspects of linear
programming covered in the previous chapter. Whereas in the context of linear
programming the basic objects of interest were real vectors, in the context of
semidefinite programming, the basic objects of interest are Hermitian operators. We
will see later in this chapter that linear programming can in fact be viewed as a
special instance of semidefinite programming, which also explains why the two are
so intimately related to each other.
2.1 Primal semidefinite programs
A semidefinite program (SDP1) is a constrained optimisation problem in an operator
variable, that we will denote X, and colour in orange. This is a Hermitian operator,
such that X† = X, and acts on a complex vector space, which we will take to be
finite dimensional throughout this book. The objective function is a real linear
function in X, which can always be written as tr(AX), for some Hermitian operator
A. Note that since we consider exclusively Hermitian operators, the word ‘Hermitian’
will almost always be omitted throughout this chapter and book2.
As with linear programs (LPs), in the context of an SDP the operator X is
required to satisfy a number of linear equality and inequality constraints, of the form 
Φi(X) = Bi for i = 1, … , m and Γj(X) ≼Cj for j = 1 … , n, where all of the Bi
and Cj are Hermitian operators of arbitrary finite dimension, and where Φi(⋅) and 
Γj(⋅) are linear maps that are hermiticity-preserving, which means that Φi(X) and 
Γj(X) are Hermitian operators whenever X is Hermitian. Throughout this book we
will use the symbol ≼ (similarly ≽) to denote an operator inequality, i.e. A ≽B
means that the operator B − A must be positive semidefinite, i.e. such that all of its
eigenvalues are nonnegative.
Putting these ingredients together, an SDP can be written as
maximise
tr(AX)

(2.2a
)
(2.2b
)
(2.2c
)
(2.1a
)
(2.1b
)
(2.1c
)
subject to
Φi(X) = Bi
i = 1, … , m,
Γj(X) ≼Cj
j = 1 … , n.
Here, as in the previous chapter, we will assume without loss of generality that
the (primal) SDP in this general form is a maximisation problem, since any
minimisation problem can be expressed as a maximisation by appropriately
introducing minus signs, as shown in exercise 2.2 below. In practice, we will
encounter naturally both minimisation and maximisation problems and will treat the
two on equal footing.
Just as with linear programs, the elements that arise in an SDP—the objective
function, the constraint functions, the bounds—fall broadly into two classes, those
which specify the problem and its general structure, and the input data, which specify
the particular instance of the problem. As before, it is insightful to think in analogy to
how a piece of code would be written; code will often require input data to run; the
lines of code then specify the problem, while the input to the code specifies the
instance of the problem. As with LPs in the previous chapter, we will see that which
parts of an SDP are specified by the problem and which parts are specified by the
instance can vary greatly, depending upon the problem being studied. Also as in the
previous chapter, problem data will always be denoted in blue.
With the above in place, consider now a simple example of a problem which
naturally arises in quantum theory, and can be cast as an SDP:
Example 2.1 Maximum eigenvalue of a Hermitian operator.
A problem that naturally arises is to find the maximum eigenvalue of a
Hermitian operator H, where we treat H as the input data of the problem,
specifying a particular instance of the general maximum-eigenvalue problem.
This problem can naturally be cast as the following SDP:
maximise
tr(Hρ)
subject to
tr(ρ) = 1,
ρ ≽0.
This program maximises the expected value of H with respect to a
quantum state ρ. The optimal value will be achieved when ρ lies in the
subspace of H with maximum eigenvalue. If H is non-degenerate this
corresponds to the projector onto the eigenvector with maximum eigenvalue.

(2.3)
(2.4a
)
(2.4b
)
The main point about the above example is that many problems can in fact be cast
as SDPs, and this is where their power lies in many respects. The above problem can
of course be solved without resorting to SDPs. However, in practice, it can and does
prove useful to be able to identify when a problem can be rephrased or recast as an
SDP, as this provides methods to solve analytically or numerically a problem, either
exactly or approximately, or to find relevant bounds and approximations.
Since we will pre-empt the later section on duality, the SDP (2.1) will be referred
to as the primal SDP. An operator X that satisfies all of the constraints in (2.1b) and
(2.1c) is said to be (primal) feasible, where we will only say ‘primal’ when this is
necessary, and will more generally just say that such an X is feasible. As for LPs, we
will denote the set of all (primal) feasible X by F. This set has the crucial property of
being convex, with essentially the same proof as given in section 1.1.1. In particular,
if X1 and X2 are both feasible operators, then X′= pX1 + (1 −p)X2 will also be
feasible, for all 0 ⩽p ⩽1.
With this notation for the feasible set, we can also write compactly the SDP (2.1)
as
α =max
X∈F
tr(AX),
with the optimal (primal) value being α. As with LPs, we will refer to α as just ‘the
value’ of the SDP when no confusion arises, by which it is always meant the optimal
value of the primal objective function. A star will be used to denote the optimal
(primal) variable, X *, such that α = tr(AX *). Optimal variables of SDPs do not
need to be unique, and in general there can be infinitely many optimal variables,
which collectively form a convex set.
As with LPs, it is relatively easy to find lower bounds on the optimal values of
SDPs—any feasible point X ∈F providing a lower bound, tr(AX) ⩽α. We will
see shortly that upper bounds on optimal values can be found by using duality, just as
previously for LPs.
If the feasible set of an SDP happens to be the empty set, F = ∅, then the SDP is
said to be infeasible, and the optimal value is again taken to be α = −∞, the smallest
possible value. This naturally leads to the special class of SDPs called feasibility
SDPs. We will use the same special notation as in (1.19) for feasibility SDPs,
find
X
subject to
Φi(X) = Bi
i = 1, … , m,

(2.5a
)
(2.5b
)
(2.5c
)
(2.6a
)
(2.6b
)
(2.6c
)
(2.4c
)
Γj(X) ≼Cj
j = 1 … , n.
That is, feasibility problems of the form (2.4) are indeed SDPs, and therefore
can be solved. It can nevertheless be useful to recast such feasibility SDPs as
standard SDPs, by introducing new variables into the problem which suitably relax
the constraints, and enlarge the feasible set. By maximising (or minimising) over
these new variables, it is then possible to determine whether the original SDP is
feasible or not. We will encounter numerous examples of this in later chapters.
A second example, now of a feasibility problem, that arises in quantum theory, is
the following:
Example 2.2 Hamiltonian feasibility problem.
Consider the problem where we have an unknown Hamiltonian H, and are
only told the average (expected) energy of a set of quantum states, 
tr(Hρi) = Ei, for i = 1, … , n. The problem is to determine whether there is a
Hamiltonian H whose ground-state energy is nonnegative, consistent with this
data. This leads to the following feasibility SDP:
find H
subject to
tr(Hρi) = Ei
i = 1, … , n,
H ≽0.
A straightforward way to convert this into a standard optimisation SDP is
to relax the problem, and to allow the Hamiltonian H to have negative energy
eigenvalues, but to maximise the smallest eigenvalue. This can be achieved by
replacing the constraint H ≽0 by the constraint H ≽λI, where λ is a new
variable. Maximising the value of λ searches for the Hamiltonian, consistent
with the data, which has the largest ground-state energy. The SDP is
maximise
λ
subject to
tr(Hρi) = Ei
i = 1, … , n,
H ≽λI.
If λ* < 0, this shows that the feasibility problem (2.5) is infeasible—
there is no Hamiltonian with positive ground-state energy consistent with the
data. On the other hand, if λ* ⩾0, then the problem was feasible, and a
*

(2.7)
(2.8a
)
(2.8b
)
(2.9a
)
(2.9b
)
solution H * is obtained.
As with LPs, it is also the case that certain problems which do not appear to be
SDPs—because of non-linear objective function or non-linear constraints—can in
fact be cast as SDPs, by making the correct simple observations. As an example, we
see that certain norms on operators which are very important in quantum information
can be expressed as SDPs, similar to how the ℓ1 and ℓ∞ norms studied in example
1.2 can be cast as LPs:
Example 2.3 SDPs for trace and operator norms.
Recall that for Hermitian operators the trace and operator norms are,
respectively
where {λi} are the eigenvalues of A.3 In a very similar fashion to the ℓ1 and ℓ∞
norms for vectors, studied in example 1.2, we find that an SDP representation
of the trace norm is
∥A ∥1= minimise
tr(X)
subject to
−X ≼A ≼X,
while an SDP representation of the operator norm is
∥A ∥∞= minimise
x
subject to −xI ≼A ≼xI,
where x is a (real) scalar variable.
It is worth noting that these two SDPs bare some resemblance to the LPs for
ℓ1 and ℓ∞ in (1.6) and (1.7) respectively, but are not as straightforward to
analyse.
We also note that the operator norm is closely related to the maximum-
eigenvalue problem studied in example 2.1, with the only difference being that
here it is the eigenvalue with largest absolute value that is of interest. In
example 2.4 we derive the dual SDP for the maximum-eigenvalue problem,
which should be compared to (2.9).
∥A ∥1= ∑
i
∣λi ∣,
∥A ∥∞= maxi ∣λi ∣,

The above two examples show that semidefinite programming can be applied to
problems which even at first sight do not appear to be SDPs, due to inherent non-
linearities in the problem. In fact, it is unknown—and still an active area of research
—to understand when and how problems can be cast as SDPs. In this book we will
see numerous examples where this general technique is used, transforming problems
in ingenious ways, so that they can be cast as SDPs.
Exercises
2.1. In the main text it is claimed that any real linear function of a variable 
X can be written in the form f(X) = tr(AX) for a suitably chosen
Hermitian operator A. In this exercise, we will prove this. (a) Show that
when A and X are both Hermitian, than tr(AX) is real. (b) Assuming that 
f(X) = tr(AX), show that f(∣j⟩⟨i ∣) = ⟨i ∣A ∣j⟩. (c) Consider an
operator A whose matrix elements are ⟨i ∣A ∣j⟩= f(∣j⟩⟨i ∣). Show that,
if f is linear, then tr(AX) = f(X).
2.2 Consider the SDP (2.1), except assume that the goal is to minimise
rather than to maximise the objective function. Show that the optimal
value α′ of this minimisation SDP can be calculated, up to a minus sign,
by solving a maximisation SDP with a different objective function. This
implies that minimisation and maximisation SDPs are equivalent, since it
is trivial to correct for the sign of α′.
2.3 Show that the optimal value of the SDP in example 2.1 is indeed the
maximum eigenvalue of the operator H.
2.4 Show that the minimum eigenvalue of a Hermitian operator H can
similarly be cast as an SDP, similar to example 2.1.
2.5 Show that the problem of finding the sum of the k largest eigenvalues
of a Hermitian operator H can be cast as an SDP. Note here that we treat k
as being input data into the problem, specifying how many eigenvalues to
sum. Hint: Consider starting from example 2.1, and thinking about how
the properties of ρ should change.
2.6 The trace norm and the operator norm are dual norms. This means that
an alternative expression for the trace norm is (compare to (1.8))
∥A ∥1= maximise
tr(AX)

(2.10
a)
(2.10
b)
(2.12
)
(2.13
)
(2.11
a)
(2.11
b)
(2.14
)
subject to
∥X ∥∞⩽1.
Using the SDP representation for the operator norm in (2.9),
show that the above expression for the trace norm—which is not an SDP
as written due to the non-linear constraint—can be recast as the following
SDP:
∥A ∥1= maximise
tr(AX)
subject to
−I ≼X ≼I.
2.7 Let us denote by A(+) and A(−) the positive and negative parts of
a Hermitian operator A, respectively. That is, writing A = ∑i λi ∣λi⟩⟨λi ∣
in spectral decomposition,
A(+) = ∑
i:λi⩾0
λi ∣λi⟩⟨λi ∣,
A(−) = ∑
i:λi<0
λi ∣λi⟩⟨λi ∣.
Show that
X * = A(+) −A(−)
is a feasible variable for the SDP (2.8), and that it achieves the value 
tr(X *) =∥A ∥1, which implies it is also an optimal variable.
2.8 Find an optimal operator X * for the SDP (2.11), constructed from the
projectors onto the positive and negative parts of A,
Π(+) = ∑
i:λi⩾0
∣λi⟩⟨λi ∣,
Π(−) = ∑
i:λi<0
∣λi⟩⟨λi ∣.
2.2 Duality
In the previous chapter we saw that every LP has a dual formulation. The same is
also true more generally in the context of semidefinite programming. Every primal
SDP too has a dual SDP formulation, the optimal value of which provides an upper
bound on the optimal value of the primal SDP. Moreover, given mild assumptions—
which are satisfied by almost all of the problems of interest in quantum information
science—the optimal values of the primal and the dual SDPs coincide.

(2.15
a)
(2.15
b)
(2.15
c)
(2.16
)
(2.17
)
In what follows we will again explicitly show how the dual SDP formulation of
(2.1) can be obtained, using the associated Lagrangian of the optimisation problem,
and discuss when the two problems are guaranteed to have the same solution, known
as strong duality. We will mostly reproduce all of the steps of deriving the dual of an
LP that were went through in the previous chapter. There are a number of reasons for
going into detail again here. First, it is important to practice the general method of
obtaining a dual problem from a primal one. Second, we will gain insight by seeing
how the procedure for LPs translates across so directly for SDPs.
Let us associate a Lagrange multiplier, also called a dual variable, Yi for 
i = 1, … , m to each equality constraint (2.1b) and Zj for j = 1, … , n to each
inequality constraint (2.1c). Each of these dual variables will be taken to be
Hermitian, such that Yi† = Yi and Zj† = Zj. Using the same notation as in the
previous chapter, the primal SDP with dual variables expressed after the colon is:
maximise
tr(AX)
subject to
Φi(X) = Bi,
i = 1, … , m
: Yi
Γj(X) ≼Cj,
j = 1 … , n
: Zj.
We then define the following Lagrangian function for the SDP,
L = tr(AX) +
m
∑
i=1
tr{Yi[Bi −Φi(X)]} +
n
∑
j=1
tr{Zj[Cj −Γj(X)]},
= tr{X[A −
m
∑
i=1
Φ†
i(Yi) −
n
∑
j=1
Γ†
j(Zj)]} +
m
∑
i=1
tr(YiBi) +
n
∑
j=1
tr(ZiCi),
where the maps Φ†
i(⋅) and Γ†
j(⋅) are the adjoint maps of Φi(⋅) and Γj(⋅)
respectively4. That is, we obtain the Lagrangian by adding to the objective function
two sets of new terms, which are formed by multiplying the constraints with the dual
variables, and taking a trace. The logic for this construction, just as for the case of
LPs, is that these are the most general real linear functions of the constraints that can
be added. As previously, the utility of this will become apparent in the following, and
we also emphasise that the Lagrangian should be considered as a function of all of
the primal and dual variables, even though it is not explicitly written as such.
We will now use the Lagrangian to place carefully chosen constraints on the dual
variables, which up until this stage are arbitrary, apart from being Hermitian. First,
we will demand that

(2.18
)
(2.19
)
(2.20
)
(2.21
)
(2.22
a)
Zj ≽0
∀j.
The reason for imposing these constraints is that when they are in place, the
Lagrangian is never smaller than the value of the objective function for any feasible
variable X:
L ⩾tr(AX)
for all X ∈F whenever Zi ≽0 ∀i.
This can be seen to be true by inspection of the Lagrangian (2.16); the first sum
of terms vanishes whenever X is feasible, while the second sum will contain only
terms which are nonnegative, since for any pair of positive semidefinite operators A
and B, we have that tr(AB) ⩾0 (see exercise 2.9). The constraints Zi ≽0
precisely ensure that all operators that appear in the sum are products of positive
semidefinite operators, and hence the bound follows.
The second constraint we will impose upon the dual variables arises from
inspecting (2.17). Notice that the Lagrangian can be made independent of the primal
variable X if we further restrict to dual variables that satisfy
A −
m
∑
i=1
Φ†
i(Yi) −
n
∑
j=1
Γ†
j(Zj) = 0,
i.e. such that the term multiplying X identically vanishes. Thus, the value of the
Lagrangian, when evaluated for a feasible primal variable, and for dual variables
which satisfy these constraints becomes equal to
L =
m
∑
i=1
tr(YiBi) +
n
∑
j=1
tr(ZiCi).
Crucially, because of the first constraint imposed on the dual variables, we
know that this value will always be larger than the value of the primal objective
function. Finally, we now see that the tightest upper bound on this value can be
obtained by minimising the Lagrangian over all dual variables that satisfy all of the
above carefully chosen constraints. That is, we arrive at the following dual
optimisation problem
minimise
m
∑
i=1
tr(YiBi) +
n
∑
j=1
tr(ZiCi)

(2.24
)
(2.22
b)
(2.22
c)
(2.23
)
subject to
A −
m
∑
i=1
Φ†
i(Yi) −
n
∑
j=1
Γ†
j(Zj) = 0,
Zj ≽0
j = 1, … , n.
We can notice that, as expected, the dual problem is itself an SDP. Indeed, the
objective function is a linear function of the dual variables, which satisfy a number of
linear equality and inequality constraints. Just as we saw for LPs, the number of dual
variables has increased, compared to the single primal variable. This is however once
again a purely cosmetic feature, and it is possible to combine all variables into a
single operator variable, which we leave as an exercise below.
As with LPs, the dual feasible set ˜
F is defined as the set of all dual variables 
(Y1, … , Ym, Z1, … , Zn) that satisfy the constraints (2.22b) and (2.22c). We refer to
the dual SDP as being either feasible or infeasible, depending upon whether this set is
empty or not. We will also denote the optimal value of the dual problem by β, and can
succinctly write the dual as
β =
min
(Y1,…,Ym,Z1,…,Zn)
∈˜
F
m
∑
i=1
tr(YiBi) +
n
∑
j=1
tr(ZiCi).
We can apply duality to example 2.1, which leads to a second natural way of
expressing the maximum eigenvalue of an operator as an optimisation problem:
Example 2.4 Dual form of maximum eigenvalue of a Hermitian operator.
We will now derive the dual SDP for the maximum eigenvalue of a
Hermitian operator, considered in example 2.1. The first constraint, (2.2b), that 
tr(ρ) = 1, involves a scalar, and hence we need a scalar dual variable, which
will be called y. The requirement that it should be Hermitian reduces here to
requiring that y is real. We will associate the dual variable Z with the second
constraint, (2.2c), requiring that ρ ≽0. The Lagrangian of the problem is
therefore
 
L = tr(Hρ) + y[1 −tr(ρ)] + tr(Zρ)
L = tr[(H −yI + Z)ρ] + y.

(2.25
)
(2.26
)
(2.28
a)
(2.28
b)
We see that Z ≽0 should be imposed in order for the last term to be
nonnegative, and H −yI + Z = 0 in order for the Lagrangian to become
independent of the primal variable ρ. In this case, the Lagrangian becomes
simply L = y. We thus arrive at the following dual formulation:
 
We can notice further that the objective function does not depend upon the
dual variable Z. Just as was seen in section 1.4 for the case of LPs, SDPs can
also have slack variables, and here Z is playing the role of such a slack
variable, converting what should be a single inequality constraint into an
equality constraint with an associated inequality constraint. In particular, we
can use (2.25) to solve for Z, giving
Z = yI −H.
Z however needs to be positive semidefinite, hence yI −H ≽0 needs to
be imposed. The final, simplified dual SDP is therefore
minimise
y
subject to
yI ≽H.
A little thought shows that this is indeed equal to the maximum
eigenvalue of H. In particular, we can notice that I and H can always be
diagonalised in the same basis. The constraint is then seen to imply that y has to
be larger than or equal to every eigenvalue of H. The minimum y for which this
is true is the maximum eigenvalue of H.
Exercises
2.9 Show that if A and B are both positive semidefinite operators, A ≽0
and B ≽0, then tr(AB) ⩾0.
2.10 In the main text it is claimed that all of the dual variables can always
be combined into a single dual variable. Show how this can be done, and
minimise
y
subject to
yI −Z = H,
Z ≽0.

(2.29
a)
(2.29
b)
(2.29
c)
(2.30
a)
g
,
write down the dual SDP in terms of a single variable. Hint: You will want
to consider how to concatenate variables into a single variable by forming
a block-diagonal operator..
2.11 In this exercise we will derive the dual SDP of a minimisation SDP.
Consider the following general form of a minimisation SDP
minimise
tr(AX)
subject to
Φi(X) = Bi
i = 1, … , m,
Γj(X) ≽Cj
j = 1, … , n.
(a) Write down the Lagrangian for this problem.
(b) Write down the conditions that need to be satisfied by the dual
variables in order for the Lagrangian to provide a lower bound on the
value of the primal SDP when evaluated on primal feasible variables.
(c) Write down the condition that needs to be satisfied by the dual
variables in order for the Lagrangian to be independent of the primal
variables.
(d) Write down the dual SDP, by maximising the Lagrangian subject
to the constraints from parts (b) and (c).
2.12 In example 2.2 we saw the relaxation (2.6) of the Hamiltonian
Feasibility Problem. Find the dual SDP of (2.6).
2.13 In exercise 2.4 you showed that the minimum eigenvalue of a
Hermitian operator H can be cast as an SDP. Find the dual form of this
SDP.
2.14 In exercise 2.5 you showed that finding the k largest eigenvalues of a
Hermitian operator H can be cast as an SDP. Find the dual of this SDP.
2.3 Weak and strong duality
We will now return to the important properties of weak and strong duality. Weak
duality, which always holds, tells us that the optimal value of the dual SDP is an
upper bound on the optimal value of the primal. Strong duality, which basically holds
in all problems of our interest, tells us that these optimal values coincide.
Concerning weak duality, we can immediately see that
α = tr(AX *)

(2.31
)
(2.30
b)
(2.30
c)
(2.30
d)
(2.30
e)
= tr([∑
i
Φ†
i(Y
*
i ) + ∑
j
Γ†
j(Z
*
j )]X *)
= tr([∑
i
Y
*
i Φi(X *) + ∑
j
Z
*
j Γj(X *)])
⩽∑
i
tr(Y
*
i Bi) + ∑
j
tr(Z
*
j Cj)
= β.
Let us clarify this derivation. The first line is the definition of the optimal primal
value. In the second line we have used (2.22b) to substitute for A. The third line is
obtained by using the definition of the adjoint maps in reverse, which was used to
shift the action of the maps from the dual variables onto the primal variable. In the
fourth line we have eliminated the primal variable by making use of the constraints
(2.1b) and (2.1c) of the primal SDP, from which the upper bound follows. Finally, the
last line is just the definition of the optimal dual value.
Under relatively mild assumptions, a much stronger condition holds, known as
strong duality, in which case the optimal values of the primal and dual SDPs
coincide. This can be viewed as the main reason for calling this the dual SDP, as
when strong duality holds, it can be seen as a dual formulation of the same
optimisation problem, and in many cases this sheds considerable light on how to
think about the problem at hand.
Let us assume that the primal SDP satisfies two natural properties:
(i) The feasible set F is non-empty, i.e. F ≠∅, and furthermore, there exists a
strictly feasible solution. That is, if we replace all of the inequality constraints
by strict inequality constraints,
while maintaining all of the equality constraints Φi(X) = Bi for 
i = 1, … , m, then it is still possible to find a feasible X. Such an X is said to
be in the relative interior of the feasible set F. This can be viewed as a type of
robustness statement; it says that within the feasible set it should be possible to
perturb points and not lose feasibility. Finally, recall then even when interested
in feasibility problems, we can always relax to a (standard) optimisation
problem, and then apply the above assumption to the relaxation.
Γj(X) ≺Cj
j = 1, … , n,
X ≻0,

(ii) Second, we assume that the optimal value is finite, α < ∞. This says that
the optimisation should not be unbounded, but should be genuinely constrained,
and have a non-trivial maximum value.
If the above two conditions are satisfied, then strong duality holds, and the value of
the primal and the dual SDPs coincide. As a summary
Whenever the primal SDP is strictly feasible and bounded, then strong duality
holds, and the value of the primal and dual SDPs coincide, α = β.
In the above, there was nothing special about focusing on the primal problem. We
could repeat the entire discussion focusing exclusively on the dual, and it would still
be true. That is
If the dual SDP is strictly feasible and bounded, then strong duality also
holds.
This is useful, as it is sometimes more straightforward to check these conditions for
the dual compared to the primal, or vice versa.
Finally, there is a third condition which can be used, and in practice is most useful
of all. If both problems are strictly feasible, then it actually implies that they are
bounded. Hence
Strong duality holds if both the primal and the dual problems are strictly
feasible.
Just like in the case of strong duality for LPs, we will not provide a proof of strong
duality of SDPs in this book. This is not the focus of this book—which is instead
about using semidefinite programming, rather than deriving the properties they have.
Proofs of strong duality can be found in almost all standard texts on the subject,
including in those contained at the end of this chapter under Further reading.
In order to illustrate these concepts, we will return to the SDP formulations of the
trace and operator norm from example 2.3. Strong duality will provide us with
alternative SDP representations of these two important norms:
Example 2.5 Dual SDPs for trace and operator norms.
In this example we will return to the trace and operator norms from
example 2.3 and derive the dual SDP for the trace norm. This will be used to
find an expression for the unit operator norm ball. We will state the results for
the operator norm, with calculations left as an exercise below. It is particularly
interesting to compare what follows to what was seen in the case of vectors, in
section 1.7.2.

(2.32
a)
(2.32
b)
(2.33
a)
(2.33
b)
(2.33
c)
(2.34
)
(2.35
a)
(2.35
b)
(2.35
c)
The Lagrangian for (2.8) is
L = tr(X) −tr[Z1(A + X)] −tr[Z2(X −A)]
= tr[X(I −Z1 −Z2)] + tr[(Z2 −Z1)A]
where we have introduced dual variables Z1 ≽0 and Z2 ≽0 associated
to the left-hand and right-hand inequalities in (2.8b) respectively. Note that
because the primal problem is a minimisation, minus signs have been
introduced for the last two terms in L. We want the Lagrangian to lower bound
the primal objective function for all feasible X, and this is now the case given
that Z1 ≽0 and Z2 ≽0. Making the Lagrangian independent of the primal
variables and maximising it leads to the dual SDP for the trace norm,
∥A ∥1= maximise
tr[(Z2 −Z1)A]
subject to
Z1 + Z2 = I,
Z1 ≽0,
Z2 ≽0.
It is straightforward to see that this dual is strictly feasible, e.g. by taking 
Z1 = Z2 = I/2. The primal problem (2.8) is also strictly feasible by
inspection, e.g. by taking X = λI, for any λ >∥A ∥1. Since both problems are
strictly feasible, strong duality holds, and (2.33) is indeed a second formulation
of the trace norm.
In exercise 2.11 an alternative SDP for the trace norm was derived, given
explicitly in (2.11). Comparing this with the dual formulation (2.33) derived
here, we obtain a characterisation of the unit operator norm ball, 
B∞= {W ∣∥W ∥∞⩽1} = {W ∣−I ≼W ≼I}, given by
In a similar fashion, this can be repeated for the operator norm. We find
that the dual SDP is
∥A ∥∞= maximise
tr[(Z2 −Z1)A]
subject to
tr(Z1 + Z2) = 1,
Z1 ≽0,
Z2 ≽0.
B∞= {W ∣W = Z2 −Z1, Z1 + Z2 = I, Z1 ≽0, Z2 ≽0}.

(2.36
)
This dual SDP formulation can be used to obtain a characterisation of the unit
trace norm ball, B1 = {W ∣∥W ∥1⩽1}, given by
B1 = {W ∣W = Z2 −Z1, tr(Z1 + Z2) = 1, Z1 ≽0, Z2 ≽0}.
This form is particularly interesting, since in comparison to the operator
norm ball, there is no obvious characterisation that can be directly arrived at.
The significance of (2.34) and (2.36) is that they show that the non-linear
constraints ∥X ∥1⩽1 and ∥X ∥∞⩽1 can be imposed as constraints inside
SDPs, something which at first sight is not obvious at all.
The above example hopefully demonstrates that it is possible to check strong
duality fairly easily, especially for simple SDPs. In all of the problems studied in this
book, and in practice in almost all of the problems that tend to be encountered in
quantum information science where semidefinite programming can be applied, we
find that strong duality holds, and it is usually straightforward (or relatively easy) to
check that this is the case.
It is nevertheless possible to find examples of SDPs where strong duality doesn’t
hold, and you will find these presented in many standard textbooks on SDPs. The
crucial point is that these examples are usually constructed explicitly in order just to
show that there are exceptions to the rule of strong duality. Thus, although it is
important to understand that strong duality is not a given, from here on out we will
not dwell much on this point, and will simply verify whenever we present the dual
SDP of a problem that strong duality holds (or leave it as an exercise).
Exercises 2.3
2.15 Show that strong duality holds for the maximum eigenvalue SDP of a
Hermitian operator from examples 2.1 and 2.4.
2.16 (a) Derive the dual SDP for the operator norm given in (2.35).(b)
Using the fact that the operator norm and trace norm are dual norms, find
an SDP for the operator norm in a form analogous to (2.10) for the trace
norm.(c) Using your answer to part (b), derive the characterisation of the
trace norm ball given in (2.36).
2.17 Starting from example 2.5, find characterisations for the ϵ-balls for
the operator and trace norm, i.e. the sets {W ∣∥W ∥∞⩽ϵ} and 
{W ∣∥W ∥1⩽ϵ}. Can the constraints ∥X ∥1⩽ϵ and ∥X ∥∞⩽ϵ also
be imposed as constraints inside SDPs?

(2.37
)
(2.38
a)
(2.38
b)
(2.38
c)
(2.39
)
2.18 Show that optimal dual variables for the SDP (2.33) are
Z
*
1 = Π(−),
Z
*
2 = Π(+),
where Π(+) and Π(−) are the projectors onto the positive and
negative parts of A, as defined in (2.14). That is, show that these operators
are feasible, and that they achieve the value ∥A ∥1. This is an important
lesson, which shows that we can view the dual SDP as a variational
method for finding the projectors onto the positive and negative parts of A
.
2.19 Find optimal dual variables for the SDP (2.35), which achieve the
value ∥A ∥∞.
2.20 In exercise 2.10 an alternative SDP was derived for the trace norm.
(a) Show that the dual formulation of the SDP (2.11) from this
exercise is
∥A ∥1= minimise
tr(Z1 + Z2)
subject to
A = Z2 −Z1,
Z1 ≽0,
Z2 ≽0.
(b) Explain how this relates to the characterisation of the unit
trace norm ball (2.36) from example 2.5 and the trace norm ϵ-ball
from exercise 2.17.
2.4 Complementary slackness
As with LPs, complementary slackness also arises from strong duality in the case of
SDPs, and tells us important information about the optimal primal and dual variables.
As we did in the context of linear programming, our starting point is to return to
the Lagrangian from (2.16), namely
L = tr(AX) +
m
∑
i=1
tr{Yi[Bi −Φi(X)]} +
n
∑
j=1
tr{Zj[Cj −Γj(X)]}.
When strong duality holds, then L = α = β when we substitute in optimal
variables X *, Y
*
i  for i = 1, … , m and Z
*
j  for j = 1 … , n. This follows from how
the dual was constructed, which was to use the Lagrangian to find the best upper

(2.40
)
(2.41
)
bound on the primal objective function. Now, since X * is by assumption feasible, the
second term identically vanishes. Every term in the summation in the third term is
always nonnegative by construction, whenever we use feasible (primal and dual)
variables. Thus, the only way in which the Lagrangian can equal the primal objective
value is if every single one of these terms vanish,
tr{Z
*
j [Cj −Γj(X *)]} = 0
for j = 1, … , n.
We can however go one step further. Recall that all Zj ≽0, in order to be dual
feasible, and that Cj −Γj(X) ≽0 always holds in order for X to be primal
feasible. The only way that tr(AB) = 0, when both A ≽0 and B ≽0 is if 
AB = 0 (and similarly BA = 0). Thus, we see that when strong duality holds then
the optimal primal and dual variables satisfy
Z
*
j [Cj −Γj(X *)] = 0
for j = 1, … , n,
which are known as the complementary slackness conditions. These are
important and useful relations between the optimal variables, which can be viewed as
orthogonality relations between the optimal primal and dual variables. In particular,
as with LP, complementary slackness provides us information about when constraints
are active, and moreover, to what extent they are active.
For example, let us focus on the constraint Z1 ≽0. Imagine that an optimal dual
variable Z
*
1 is found that is not identically zero, but has a number of non-zero
eigenvalues. Let us denote the projector onto the subspace of non-zero eigenvalues,
the support of Z
*
1 by Π1. What this shows is that the constraint Z
*
1 ≽0 is only
active on the complementary subspace I −Π1, i.e. on the nullspace of Z
*
1. Now,
since 
Z
*
1[C1 −Γ1(X *)] = [C1 −Γ1(X *)]Z
*
1 = 0, 
we 
have 
that 
Z
*
1[C1 −Γ1(X *)] −[C1 −Γ1(X *)]Z
*
1 = 0, 
i.e. 
[C1 −Γ1(X *), Z
*
1] = 0—they
commute, and hence can be diagonalised in the same basis. But then it is
straightforward to see, due to the positive semidefiniteness of the operators, that 
C1 −Γ1(X *) must vanish on the support of Z
*
1, otherwise it is impossible that their
product is zero, hence the support of C1 −Γ1(X *) is contained in the nullspace 
I −Π1 of Z
*
1, and conversely, the support of Z
*
1 is seen to be in the nullspace of 
C1 −Γ1(X *).

(2.42
a)
(2.42
b)
(2.42
c)
Exercises
2.21 Primal and dual SDP formulations of the trace norm were given in
(2.8) and (2.33) respectively. Optimal primal and dual variables were
found in exercises 2.7 and 2.18 respectively. Show that these optimal
variables satisfy complementary slackness.
2.5 Linear programs as special instances of semidefinite
programs
We finish this section by discussing an important fact—that linear programming can
be viewed as a special case of semidefinite programming.
First of all we can see that if all of the constraint of an SDP were written
explicitly in terms of the matrix elements of the involved operators, we would end up
with a set of polynomial constraints in these variables, with the degree of the
polynomial depending upon the dimension of the operators. This arises because an
operator is positive semidefinite if and only if all of its leading principle minors
(determinant of an upper-left sub-matrix) are nonnegative, and these determinants are
polynomials in the matrix elements of the operator. We consider the example for 2 ×
2 operator in exercise 2.22 below.
Because of this important realisation, SDPs can also be seen as optimisation
problems with a linear objective functions satisfying special types of polynomial
constraints, which generalise the linear inequality constraints required to be a linear
program.
Second, we can also explicitly rewrite any LP in the language of an SDP. The
basic observation is that vectors can be viewed as diagonal operators. Let us assume
that we want to re-express an LP given in vector form (as in (1.3)), namely,
maximise
→a ⋅→x
subject to
→r i ⋅→x = bi
i = 1, … , m,
→sj ⋅→x ⩽cj
j = 1, … , n,
as an SDP. First consider that we are able to optimise over diagonal operators,
and so can encode the variable →x from the LP in an operator X as
X = ∑
i
xi ∣i⟩⟨i ∣= diag(→x).

(2.43
)
(2.44
)
(2.45
)
(2.46
)
(2.47
)
(2.48
)
(2.49
)
(2.50
a)
(2.50
b)
If we similarly define the diagonal operator A = ∑i ai ∣i⟩⟨i ∣= diag(→a), then the
objective function of the LP, →a ⋅→x, can then be expressed as
→a ⋅→x = tr(AX),
as required for the objective function of an SDP. We can apply the same idea for
all of the constraints. In particular, it is possible to take
Ri = ∑
k
(ri)k ∣k⟩⟨k ∣= diag (→r i),
Sj = ∑
k
(sj)
k
∣k⟩⟨k ∣= diag(→sj),
Φi(X) = tr(RiX),
Γj(X) = tr(SjX),
Bi = bi,
Cj = cj,
which then expresses the constraints of an LP in SDP form. We have thus
almost recast the LP as an SDP. The one final ingredient is to further enforce the
assumption that X is a diagonal operator. This can be ensured by introducing a
further equality constraint. In particular, consider the following map, which is the
difference between the dephasing and identity maps, the former of which sets all off-
diagonal elements of an operator to zero,
If an operator X is diagonal, then Φ(deph)(X) = X and so Φ(diag)(X) = 0. On
the other hand, if X has any non-zero off-diagonal elements, then Φ(diag)(X) ≠0.
Thus, adding the constraint
Φ(diag)(X) = 0,
to an SDP, has the effect of restricting the feasible set F to be contained within
the set of diagonal operators. Hence in this way we can recover an arbitrary LP of the
form (2.42) in the form of an SDP, namely
maximise
tr(diag(→a)X)
subject to
tr(diag(→
ri )X) = bi
i = 1, … m,
tr(diag(→
sj)X) = cj
i = 1, … m,
Φ(diag)(X) = Φ(deph)(X) −Φ(id)(X)
= ∑
i
∣i⟩⟨i ∣X ∣i⟩⟨i ∣−X.

(2.51
)
(2.52
)
(2.53
)
(2.50
c)
(2.50
d)
Φ(diag)(X) = 0.
As such, we see that any LP can also be thought of as a semidefinite
program. Thus, any result stated about the general theory of semidefinite
programming immediately holds for linear programming, and this is one of the main
reason for showing that LPs is a special instance of SDPs. In practice, it is often
much more useful to identify a problem as a linear program if it is one (rather than
leaving it as an SDP), as this can speed numerics, or simplify analytics.
Exercises
2.22. Consider an arbitrary Hermitian 2 × 2 operator, with corresponding
matrix
X = (
),
where x11 and x22 are real, while x12 is complex.
(a) Show that the eigenvalues of this operator are
λ1,2 = 1
2 (x11 + x22 ± √(x11 −x22)2 + 4 ∣x12 ∣2).
(b) Assuming that X is normalised so that tr(X) = 1, show that X ≽0 if
and only if
x11(1 −x11) ⩾∣x12 ∣2.
This shows that for a 2×2 operator to be positive semidefinite, a non-
linear inequality constraint must be satisfied by its matrix elements. This
demonstrates how SDPs generalise the linear inequality constraints of LPs to
non-linear polynomial constraints..
2.6 Concluding remarks
This brings to a close this chapter on the basics of semidefinite programming, and
also the first part of this book, covering the introduction and basics. We hope that at
this stage you understand the following key points:
x11
x12
x
*
12
x22

Definition. An SDP is an optimisation problem of a linear function of an
operator variable, subject to a number of linear operator equality and inequality
constraints—see (2.1).
Duality. Every SDP has a dual formulation, which is also an SDP—see (2.22).
Weak and strong duality. Just like for LPs, we have both weak and strong
duality for SDPs. The former means feasible points of the primal and dual SDPs
always provide bounds on the optimal values of the other problem (see (2.30)).
Strong duality says that if either problem strictly feasible and bounded, or both
problems are strictly feasible, then the optimal values of the two coincide.
Representability. It is possible to recast optimisation problems with non-linear
objective functions or non-linear constraints as SDPs—see example 2.3.
Special case: LPs are special cases of SDPs, which are a much more general
class of optimisation problems.
We now move on to the main part of the book, where our focus is on putting into
practice all of the abstract concepts presented up until now, in the context of quantum
information science. We will focus on seeing how a wide range of problems, from
across the field, can be cast as linear or semidefinite programs, how duality is useful
both from a calculational perspective and a conceptual perspective, and how the
ability to find SDPs allow for powerful relaxations or approximations of many
interesting problems.
2.7 Further reading
Boyd S and Vandenberghe L 2004 Convex Optimization (Cambridge:
Cambridge University Press) https://web.stanford.edu/~boyd/cvxbook/
Watrous J 2018 Theory of Quantum Information (Lecture Notes) (Cambridge:
Cambridge 
University 
Press) 
section 
1.2.3
https://cs.uwaterloo.ca/~watrous/TQI/
Watrous J 2011 The Theory of Quantum Information (Cambridge: Cambridge
University Press) ch 7 and 8 https://cs.uwaterloo.ca/~watrous/TQI-notes/
Sikora J and Varvitsiotis A 2015 Semidefinite Programming & Quantum
Information, lectures 7–9, presented at Perimeter Institute for Theoretical
Physics, 
Waterloo, 
Canada
https://sites.google.com/site/jamiesikora/teaching/semidefinite-programming-
quantum-information
1We will use the acronym to denote both semidefinite program and semidefinite programming.
2This is similar to the fact that we only considered real vectors in chapter 1, and referred to these simply as
‘vectors’ rather than the more precise ‘real vectors’.
3We restrict here to Hermitian operators, since it will significantly simplify the SDPs derived.

4Recall 
that 
the 
adjoint 
map 
Λ†(⋅) 
of 
Λ(⋅) 
is 
the 
unique 
map 
defined 
such 
that 
tr(Λ(X)Y ) = tr(XΛ†(Y )) ∀X, Y .

Part II
Semidefinite programming in quantum
information science

IOP Publishing
Semidefinite Programming in Quantum Information Science
Paul Skrzypczyk and Daniel Cavalcanti

Chapter 3
Quantum states
In this chapter we begin the second—and main—part of this book, where we explore the use of
semidefinite programming in the context of quantum information science. As will be seen,
semidefinite programming proves to be a versatile and powerful tool, which finds widespread and
varied applications.
One of the first reasons why SDPs are so useful in quantum information is because—
mathematically—quantum states are positive semidefinite operators, ρ ≽0, which are normalised, 
tr(ρ) = 1. Being a linear operator inequality and an equality constraint respectively, these conditions
can be used as constraints inside SDPs, so that many problems involving optimisation over quantum
states can be cast as SDPs. In this chapter we will describe some of these problems. We will discuss
problems related to quantum state estimation, which refers to the question of estimating the state that
a source produces given the outcome statistics of a set of measurements. In the case this set of
measurements is tomographically complete, this is equivalent to quantum state tomography—
characterising the state emerging from a source. Sometimes, however, the information obtained
experimentally is not enough to single out a unique quantum state. With the help of SDPs we can
nevertheless characterise the set of states compatible with a given set of experimental observations,
and estimate additional (unmeasured) properties of quantum states.
Altogether, these topics will allow us to see how problems involving quantum states can be cast as
SDPs, and to use various aspects of the theory of SDPs presented in the previous chapters, in order to
gain important insights about these problems.
We will end this chapter with a brief section on the quantum marginal problem, which can be
viewed as a generalisation of quantum state estimation. In this problem, we consider multipartite
systems, and are given complete information only about some of their subsystems. The goal is then to
determine the global state, or properties of it. As will be seen, the tools of semidefinite programming
can also be used to solve this problem, and leads to a simple way to see when certain sets of marginals
are inconsistent with each other.
3.1 Quantum state estimation
Suppose an experimentalist comes to you and says
I have a source of spin-1/2 particles (i.e. qubits) in my laboratory, that I have measured along
two different spin directions ˆx and ˆy, obtaining the following expectation values: ⟨σx⟩= 0.9
and ⟨σy⟩= 0.5,
where σx, σy and σz are the three Pauli operators. Is there any way to know if they are telling the truth
or not? More precisely, is it possible to determine whether what they claim to have observed is
consistent with the predictions of quantum mechanics? The simple situation above can indeed be
checked through basic algebraic means, using the properties of the measurements used. But in more

(3.1a
)
(3.1b
)
(3.1c
)
(3.1d
)
complicated and sophisticated situations, involving, e.g. many measurements with no symmetry
relations between them, or high-dimensional quantum system, the task becomes more intricate.
However, this problem can in fact be cast as a simple feasibility SDP. Namely, suppose that we are
given the measurement results for a set of N observables M1, … , MN. Let us assume that we are
only told the average values of each measurement, ⟨M1⟩= m1, … , ⟨MN⟩= mN. Our goal is to
check if these reported values are compatible with some quantum state ρ. This amounts to solving the
following feasibility SDP:
find
ρ
subject to
tr(Mxρ) = mx
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0.
There are three possibilities that can arise.
1. Unique solution.The set of observables {Mx} we consider might have the property of being
tomographically complete. This means that knowing the results for every measurement in the set
is sufficient to uniquely determine the state. Mathematically, the set must have a sufficient
number of linearly independent measurements in order to determine all of the matrix elements of
the density operator ρ. In this case, the feasible set of the SDP is a unique density operator 
F = ρ*.
2. No solution. The other extreme case is when there is no solution, i.e. there is no quantum state ρ
which is able to produce the desired list of expectation values (and the experimentalist was lying
or mistaken). In this case, the SDP is infeasible, and we see that the feasible set must be empty, 
F = ∅. We will study this in detail in section 3.1.5, where it is shown that the dual SDP can be
used to provide us with a certificate, which will convince us that there is no quantum state
producing the desired set of expectation values.
3. Multiple solutions. The situation in between the above two cases is that there are infinitely
many states ρ which produce the given set of expectation values. This means that the set of
measurements is not tomographically complete, such that they do not uniquely determine all of
the matrix elements of the density operator. On the other hand, the expectation values are
consistent with each other. In terms of the SDP, here the feasible set F will be non-empty, and
contain more than a single state.
3.1.1 Trace distance estimation
The above shows that quantum state estimation can be cast as an SDP. We can however use
semidefinite programming to dig much deeper into the problem of state estimation. As a first
example, imagine that not only do we have the set of measurement results, but also a target state, that
we believe was prepared, and which was measured to produce the observed statistics. If the statistics
are incompatible with this target state we might be interested in understanding how close the prepared
state was to the target state.
In this section we will see that this question can be answered using semidefinite programming. In
particular, we will show that it is possible to find the best-case trace distance between any state
consistent with the measurement results and some target state.

(3.2)
(3.3)
(3.4a
)
(3.4b
)
(3.4c
)
(3.4d
)
The key ingredient is to use the primal SDP formulation for the trace norm, as given in (2.8),
which we will see can be harnessed here for our needs.
Recall that for a pair of quantum states the trace distance is given by
T(ρ, σ) = 1
2 ∥ρ −σ ∥1.
This is a non-linear function of ρ and σ, and so cannot be used directly as either the objective function
or as a constraint inside an SDP. However, as we saw in example 2.3 in the previous chapter, it can
nevertheless be possible to recast problems which appear non-linear as SDPs. We will see here that
trace distance estimation is indeed such a problem where the non-linearity is not a road block. The
first thing to note is that although non-linear, the trace distance is nevertheless a convex function of
either state, such that
T(qρ0 + (1 −q)ρ1, σ) ⩽qT(ρ0, σ) + (1 −q)T(ρ1, σ),
and similarly for the second state.
There are two possibilities that are of potential interest—the best case and the worst case. In the
former, we would want to find the closest state to our target state consistent with the measurement
results. On the other hand, in the latter case, we would seek to find the state which is furthest away
from our target state and still consistent with the results.
The fact that the trace distance is convex means that we will not be able to analyse the worst case,
but only the best case. Why is this? This is in fact an important lesson about convex optimisation—
more general than just linear programs (LPs) and SDPs. As the following sketch illustrates, convex
objective functions are naturally associated with minimisation problems and concave objective
functions are naturally associated with maximisation problems: maximising a convex function we are
led to the extremes of the function—to the boundary of the domain. This is a fundamentally different
type of optimisation problem compared with finding the optima, which naturally occur at stationary
points.
Since the trace distance is convex, we can consider problems involving its minimisation, which
here would correspond to finding the minimal distance or closest state to the target state. In particular,
the problem we can attempt to solve is
minimise
1
2 ∥ρ −σ ∥1
subject to
tr(Mxρ) = mx
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0.

(3.5a
)
(3.5b
)
(3.5c
)
(3.5d
)
(3.5e
)
This is still not an SDP, but it can be turned into one by making use of example 2.3, in particular
(2.8), which gave an SDP for the trace norm ∥A ∥1 of an arbitrary Hermitian operator A. Here there
are two additional complications: (i) whereas previously A was the data of the problem, here 
A = ρ −σ is instead a variable; (ii) as stated above, we now want to minimise the trace norm rather
than just calculate it. Luckily both of these complications are harmless. First, in (2.8) the variable X is
never multiplied by the data A. Thus, although here A = ρ −σ is now a variable, it doesn’t actually
stop the problem from being linear, and therefore from being an SDP.
Second, since the SDP (2.8) for the trace norm is a minimisation, and we want to consider here the
best case—itself corresponding to minimisation—we end up with a double minimisation. However,
double minimisations are still convex optimisation problems, and in this case our problem remains an
SDP. Altogether, we arrive at the following SDP for finding the closest state in trace distance to a
target state, given the measurement results:
minimise
1
2 tr(X)
subject to −X ≼ρ −σ ≼X,
tr(Mxρ) = mx,
x = 1, … , N
tr(ρ) = 1,
ρ ≽0.
Incidentally, we can now understand mathematically why it is not possible to analyse the worst
case, i.e. to find the state which is as far as possible from the target state. In such a case, we would
end up with almost the same problem as (3.4), except the objective would now be to maximise, rather
than minimise. However, we would then not be able to end up at a form like (3.5), since there it was
possible to combine the two minimisations—one over ρ and one over X—into a single minimisation,
and obtain an SDP. To evaluate the worst case, we would need to maximise over ρ and minimise over 
X, and these cannot be combined into a single optimisation. This reflects the fact that to find the
worst case, as already realised, would require maximising a convex function, which is a
fundamentally different type of problem.
3.1.2 Fidelity estimation

(3.6)
(3.7a
)
(3.7b
)
(3.7c
)
(3.7d
)
(3.8a
)
(3.8b
)
(3.9)
We now turn our attention to a second notion of closeness between states—namely the fidelity. We
will start by specialising to the problem of determining how close ρ is to a pure quantum state 
σ =∣ψ⟩⟨ψ ∣. As will be seen, this is more straightforward than the general problem of estimating the
fidelity to a mixed state. In particular, the fidelity between a state ρ (which can be either mixed or
pure) and a pure state σ =∣ψ⟩⟨ψ ∣ is
F(ρ, σ) = ⟨ψ ∣ρ ∣ψ⟩= tr(∣ψ⟩⟨ψ ∣ρ),
which, notably, is a linear function of ρ. We can thus use this as the objective function directly, and
arrive at the following SDP to find the closest state in fidelity to a target state, i.e. the state with
maximum fidelity with the target state σ =∣ψ⟩⟨ψ ∣,
maximise
tr(∣ψ⟩⟨ψ ∣ρ)
subject to
tr(Mxρ) = mx
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0.
This SDP again allows us to understand the best case, i.e. the largest fidelity among all possible
states that are compatible with the observed data.
Interestingly, since the fidelity is linear, we can now consider the associated minimisation
problem, i.e. to replace the maximisation in (3.7) by a minimisation. In this case, we then find the
worst-case fidelity, i.e. the smallest fidelity among all possible states consistent with the measurement
results.
This is somewhat surprising, since we saw for the trace distance that it isn’t possible to obtain the
worst-case state. The key difference here is that the fidelity to a pure state is linear, meaning it is both
convex and concave, and so we can in fact also solve the worst-case problem too. Unfortunately, as
will be seen below, this is a special property of the fidelity with pure states. In the more general case,
of fidelity with a mixed target state, it is again only possible to solve the best-case scenario.
Moving on to the more general problem of estimating the fidelity between two mixed states, the
general expression for the fidelity is given by
F(ρ, σ) = ∥√ρ√σ∥
2
1,
= [tr(√√σρ√σ)]
2
,
which is now a non-linear function of both ρ and σ. This means that, just as with the trace
distance, we can no longer directly use this as the objective function in an SDP. Although non-linear,
the fidelity is nevertheless a concave function (in either state), meaning that
F(qρ0 + (1 −q)ρ1, σ) ⩾qF(ρ0, σ) + (1 −q)F(ρ1, σ),
for q ∈[0, 1], and similarly for σ. This says that the fidelity between the average state 
ρ′= qρ0 + (1 −q)ρ1 and σ is never smaller than the average of the fidelities between ρ0 and σ and ρ1
and σ.

(3.10
a)
(3.10
b)
(3.11
)
(3.12
a)
(3.12
b)
(3.12
c)
(3.12
d)
(3.12
e)
The fact that the fidelity is concave means—once again—that it will only be possible to estimate
the best-case fidelity, since we will be able to consider maximising the fidelity (and now a larger
fidelity means a closer state), given the constraints arising from the measurements result.
The difficulty that must still be overcome is to understand how we can evaluate the fidelity
objective function using semidefinite programming. We will return to this topic in more detail in the
‘Advanced topics’ section 3.5.1, but just as with the trace distance, even though the fidelity is a non-
linear function, it can nevertheless be expressed as an SDP by introducing auxiliary variables. As
shown in section 3.5.1, the square-root-fidelity is in fact given by the following SDP:
√F(ρ, σ) = maximise
tr(Y )
subject to
(
) ≽0.
We have written the constraint (3.10b) in a relatively intuitive way, arranging the variables Y
and Z into a block matrix, along with the data of the problem—the quantum states ρ and σ. It is
important to appreciate that this inequality constraint is equivalent to the standard form as in (2.1c),
namely of the form Γ(X) ≼C. In particular, since we have a pair of variables Y  and Z, we have a
map Γ(Y , Z), which can be written
Γ(Y , Z) =∣0⟩⟨0 ∣⊗ρ+ ∣0⟩⟨1 ∣⊗(Y + iZ)+ ∣1⟩⟨0 ∣⊗(Y −iZ)+ ∣1⟩⟨1 ∣⊗σ
with a similar technique applicable for any block matrix. As can be seen, the block matrix form
of (3.10b) is much easier to read than the form of (3.11), and hence we will use the block form
whenever appropriate to do so.
Returning to the problem of estimating the largest fidelity with a target state, we can now directly
use (3.10) in order to recast the problem as an SDP. In particular, the following SDP is arrived at,
which evaluates the best-case (square-root) fidelity between any state ρ consistent with the data, and a
target state σ:
maximise
tr(Y )
subject to
(
) ≽0,
tr(Mxρ) = mx
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0.
Note that, compared with the SDP formulation of √F(ρ, σ), we have relaxed ρ from being input
data to being a variable, constrained by the measurement results. Crucially, as can be seen, this
problem remains linear, and subsequently remains an SDP. We can also note that, just as for the trace
distance, the above works since the SDP formulation of the fidelity was a maximisation problem. By
relaxing ρ, the best-case state given the constraints, is now naturally found.
In principle, distances other than the trace distance and fidelity can also be considered in state
estimation. As the above two examples have hopefully demonstrated, these distances need not be
ρ
Y + iZ
Y −iZ
σ
ρ
Y + iZ
Y −iZ
σ

(3.13
a)
(3.13
b)
(3.13
c)
(3.13
d)
linear functions, but they must be expressible themselves as SDPs.
3.1.3 Finite statistics
We now turn our attention to a different aspect of quantum state estimation, that of finite statistics. In
practice, due to the fact that every experiment can only handle a finite number of measurement
rounds, it is rather unreasonable to assume that the expectation values m1, … , mN are known
exactly. In reality, these will have been estimated themselves, and will only be known up to some
level of uncertainty. Let us therefore assume that the result of each measurement is only known to lie
in some interval [mx −Δx, mx + Δx]. The problem of interest now is the feasibility problem of
determining whether there is a quantum state ρ which is consistent with all of these uncertain
expectation values,
find
ρ
subject to
mx −Δx ⩽tr(Mxρ) ⩽mx + Δx
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0,
where to aid presentation we have displayed both inequality constraints related to the
measurement intervals in a single line for each expectation value. Each equality constraint from the
original problem (3.1) is thus replaced by a pair of inequality constraints. As will be seen later, this
will have an effect on the dual SDP—which will have twice as many dual variables compared to the
dual of the original problem.
From the perspective of the structure of the SDP, since there are no equality constraints relating ρ
with the observed data in this problem, even if the set of measurements {Mx}x is tomographically
complete, in general we would never expect to find a unique solution, unlike before. This is rather
natural, as we would expect to have some residual uncertainty about the state, given the uncertainty in
the measurement results, whenever they are consistent.
3.1.4 Relaxing the feasibility problem
In another direction, we return now to our original feasibility problem of quantum state estimation, as
given in (3.1), and look at how it can be relaxed to an optimisation problem. There are a few of
reasons for doing this. First, it will allow us to understand quantitatively how inconsistent a set of
measurement results are, whenever there is no state that can lead to them. Second, from a numerical
perspective, it is useful to be able to transform feasibility problems into optimisation problems, which
are generally much more stable to solve. Finally, having an optimisation form will allow us to use
duality, which we will show to be useful in later sections.
There are multiple ways in which the feasibility problem (3.1) can be relaxed to an optimisation
problem, each with their relative merits. Here we will adapt the approach from the previous section on
finite statistics, in order to obtain a relaxation of the problem, which is always feasible.
The key idea is to relax the equality constraints (3.1b)—to not demand that the observed
expectation values are reproduced exactly, but allow them to be reproduced approximately, in a very
similar fashion to the above section. Whereas in the above the relaxation was coming from the
uncertainty due to finite statistics, here the logic is different. Here we seek to find a set of
measurement results which best approximates the target results. If they can be reproduced exactly,

(3.14
)
(3.15
a)
(3.15
b)
(3.15
c)
(3.15
d)
then the original problem was feasible, and hence we obtain a quantum state ρ that can reproduce the
statistics. If on the other hand the problem is infeasible, it will be necessary to perturb the results in
order for them to be producible by some quantum state. The crucial observation is that a sufficiently
big perturbation of the results will always be producible by some quantum state. This means that this
relaxation will lead to an SDP which will be feasible by construction. Finally, by minimising the size
of the perturbation, the best approximation is found.
It is interesting to note that this approach can be seem as complementary to that taken in sections
3.1.1 and 3.1.2 on trace distance and fidelity estimation. In particular, in those sections, in essence we
sought to find the state which best approximated a target state. Here, on the other hand, we seek to
find the set of measurement results which best approximates the target measurement results.
A simple way to achieve the above relaxation is to place a uniform bound on how much any single
result can differ from the desired result. That is, we introduce a new variable δ, and replace the
equality constraints (3.1b) with pairs of inequality constraints
mx −δ ⩽tr(Mxρ) ⩽mx + δ
x = 1, … , N.
This enforces that for all measurements, ∣tr(Mxρ) −mx ∣⩽δ. The reason for writing this in the
form (3.14) is that in this form the constraint is manifestly linear in all of the variables. It is also worth
noting that this is very similar to (3.13b), the difference being that previously the uncertainties Δx
depended upon the measurement, and were input data to the problem, whereas here we simplify and
consider only a single δ, which is now constant and a variable of the problem. Putting everything
together, we arrive at the following relaxed SDP for quantum state estimation:
minimise
δ
subject to
mx −δ ⩽tr(Mxρ) ⩽mx + δ
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0.
Any solution with δ = 0 satisfies all of the constraints of the original problem (3.1). On the other
hand, when δ* > 0, this signifies that the original problem (3.1) is infeasible, and there is no
quantum state able to reproduce the data.
It is important to realise that δ* provides us with quantitative information regarding how close the
problem is to being feasible: if δ* is small this means that there is a quantum state that is able to
reproduce closely the measurement results; on the other hand, if δ* is large, at least one of the
measurement results needs to be significantly different from that observed, in order to be producible
by some quantum state.
Exercises
3.1 By defining vectors →m with components mx and →m′ with components m′
x = tr(Mxρ),
show that the SDP (3.15) can also be written as

(3.16
a)
(3.16
b)
This shows that this relaxation can be understood as minimising the ℓ∞ distance between
the target data →m, and any set of data that can be produced in quantum mechanics..
3.2 Write down the SDP relaxation of (3.1) which minimises instead the ℓ1 distance 
1
2 ∥→m −→m′∥1, between the target data →m, and data that can be produced in quantum
mechanics →m′.
3.1.5 Certificate of infeasibility
We now consider the situation where we are given some experimental data which is inconsistent, such
that there is no quantum state that could possibly lead to this data. An interesting question is: can we
certify that this is the case without having to numerically solve the SDP? Is there an analytic
certificate that can be used to prove unequivocally that the SDP is infeasible? In this section it will be
seen that duality allows us to provide such a simple certificate, which will convince us whenever a set
of measurement results is inconsistent. This idea is rather general, and can be widely applied to
guarantee that an given SDP is infeasible.
Our starting point will be the relaxed problem (3.15). Recall that we attempt to minimise δ, and if
we are able to find a solution δ = 0, then the associated state ρ will be consistent with the
measurement results. On the other hand, if δ* > 0, then the results are inconsistent. In what follows
we will show how duality can be used to guarantee that δ* > 0 without having to solve the SDP.
Recall that for a minimisation problem, the values that the dual objective function can take always
lower bound the optimal value of the primal problem (weak duality). Therefore, if we can find a set of
dual variables such that the value of the dual objective function is strictly positive, then with certainty
the primal problem has δ* > 0. It is precisely a collection of dual variables that lead to a positive
value of the dual objective function that will constitute our certificate. Let us now put this into
practice.
By introducing scalar dual variables ux and 
 associated to the first and second inequality
constraint respectively in (3.15b), a scalar z associated to (3.15c) and an operator W associated to
(3.15d), the associated Lagrangian of the problem is
L = δ −
N
∑
x=1
ux[tr(Mxρ) −mx + δ] −
N
∑
x=1
vx[mx + δ −tr(Mxρ)] + z[1 −tr(ρ)] −tr(Wρ),
= δ[1 −
N
∑
x=1
(ux + vx)] + tr[ρ(
N
∑
x=1
(vx −ux)Mx −zI −W)] + z +
N
∑
x=1
(ux −vx)mx.
Note that since the primal problem is a minimisation problem, the Lagrangian is constructed to
be smaller than the value of the primal objective function for all primal feasible variables, and hence
we take ux ⩾0, 
 and W ≽0. Recall that this is the reason for the additional minus signs in
the Lagrangian in the second, third and last term, which arise whenever we construct the Lagrangian
for a minimisation problem, as shown in exercise 2.11. We can additionally make the Lagrangian
minimise
∥→m′−→m ∥∞
subject to
m′
x = tr(Mxρ)
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0.

(3.17
a)
(3.17
b)
(3.17
c)
(3.17
d)
(3.18
a)
(3.18
b)
(3.18
c)
(3.19
)
independent of the primal variables by ensuring the first and second brackets vanish in (3.16b).
Maximising, to obtain the best lower bound, and solving for W, which is seen to play the role of a
slack variable, we arrive at the dual formulation
maximise
z +
N
∑
x=1
(ux −vx)mx
subject to
zI +
N
∑
x=1
(ux −vx)Mx ≼0,
N
∑
x=1
(ux + vx) = 1,
ux ⩾0
vx ⩾0
x = 1, … , N.
Let us now analyse this dual a little. The first thing to notice is that the constraints (3.17c) and
(3.17d), together with the fact that everywhere else only the combination 
 appears, shows that
the problem can be interpreted as one of optimising over a single dual variable 
, with
components 
, such that ∥→t ∥1⩽1. This can be seen from the definition of the ℓ1 unit
ball from (1.62). Thus, we can express (3.17) in a simpler form:
maximise
z + →t ⋅→m
subject to
zI + →t ⋅→
M ≼0,
∥→t ∥1⩽1,
where we have introduced an operator vector →
M = (M1, … , MN), the components of which
are the observables, and, as above, →m = (m1, … , mN) is the vector whose components are the
measurement results.
How does this serve as a certificate for the fact that the measurement results →m were inconsistent?
Let us assume that we have found a set of dual feasible points—i.e. a set of dual variables (z, →t )
satisfying the constraints—such that β = z + →t ⋅→m > 0. Now, consider the constraint (3.18b), and
multiply both sides by an arbitrary quantum state ρ and take the trace. We see that
tr[ρ(zI + →t ⋅→
M)] = z +
N
∑
x=1
tx(ρMx) ⩽0.
The first equality follows from the linearity of the trace, while the second follows from the fact
that for two operators A ≽0 and B ≼0, we have tr(AB) ⩽0. What this shows is that the operator
inequality (3.18b) guarantees that any set of measurement results →m′= (tr(ρM1), … , tr(ρMN)) that
can arise by performing measurements on a quantum state, will never lead to a positive value of β.
This shows that the claim that the purported results →m were observed, must have been false. The dual
problem is thus seen to look for a carefully chosen set of dual variables (z, →t ) such that on the one
hand, the purported results lead to a positive value of the dual objective function, while
simultaneously demanding that all valid measurement results lead to a negative value. In the next

(3.20
)
(3.21
)
(3.22
)
(3.23
)
section we will explore the geometry of this, but as a preview, what we have just observed can be
thought of as a separation between what is allowed and what is not allowed, and is a common
geometrical feature of certificates of this type.
Why is this better than solving the primal SDP in (3.1)? There are a number of advantages. First,
given the dual variables, no optimisation is required in order to check whether the following two
conditions hold: (i) β = z + →t ⋅→m > 0, and (ii) all of the eigenvalues of W = zI + →t ⋅→
M are
negative. Second, this certificate can in principle even be checked analytically, that is, we can
analytically evaluate β and find the eigenvalues of W, and thus verify analytically that all of the
constraints of the dual are satisfied. This is in contrast to only having a numerical solution for the
primal problem. Finally, although this certificate is designed for a given set of inconsistent data →m, it
can be used more universally, to check the inconsistency of any data. In particular, although it may
fail to identify inconsistent data, if any set of data leads to a strictly positive value of β, then it is
guaranteed to be inconsistent. We exemplify this in the following example:
Example 3.1 Equatorial plane of the Bloch sphere
In this example, we will show how the above dual SDP (3.18) can in fact be used as a method to
derive the equator of the Bloch sphere. That is, any qubit, written in the form ρ = (I + →r ⋅→σ)/2,
with →σ = (σx, σy, σz) the vector of Pauli operators and →r the Bloch vector with components 
ri = tr(σiρ), will be a valid density operator only if r2
x + r2
y ⩽1.
In order to obtain this result, assume that two Pauli measurements are performed, 
→
M = (σx, σy). We will use (3.18) to find the allowed measurement results →m = (mx, my) that
can arise—and in so doing re-derive the equatorial plane of the Bloch sphere.
From (3.18b), we are seeking dual variables that satisfy
zI + txσx + tzσz ≼0
and from (3.18c), we furthermore must have ∥→t ∥1=∣tx ∣+ ∣tz ∣⩽1. Since any operator
of the form nxσx + nyσy has eigenvalues ±1 whenever ∥→n ∥2= √n2x + n2y = 1, we see that
the eigenvalues of the operator zI + txσx + tyσy are
λ± = z± ∥→t ∥2,
and so we will satisfy (3.20) whenever
z+ ∥→t ∥2⩽0.
We can therefore take z = −∥→t ∥2, so that the inequality is saturated. With this choice of 
z, the dual objective function is
−∥→t ∥2 +→t ⋅→m.
Now, any set of measurement outcomes →m = (mx, my) for which this is strictly positive is
inconsistent, since we have just arranged it such that this can never happen. That is, →m is

(3.24
)
(3.25
)
(3.26
)
(3.27
)
inconsistent if
→t ⋅→m >∥→t ∥2.
Up to this point, we still haven’t specified →t , other than the requirement that ∥→t ∥1⩽1.
Let us therefore choose
→t =
→m
∥→m ∥1
.
This implies that ∥→t ∥2=∥→m ∥2 / ∥→m ∥1, and so the data is inconsistent whenever
∥→m ∥2
2>∥→m ∥2,
i.e. ∥→m ∥2> 1. In other words, consistent measurement outcomes must satisfy ∥→m ∥2⩽1.
Written out in full, this equates to mx2 + my2 ⩽1. Since →m is nothing but the components of
the Bloch vector of a qubit in the equatorial plane, this re-derives the equatorial plane of the
Bloch sphere.
Of course this result is well-known and can be obtained more directly, by finding the
eigenvalues of a qubit density operator—we did not need to resort to the duality theory of SDPs
to derive this result. However, the utility of going through this example is that in more
complicated situations, involving for example non-Pauli measurements, or higher dimensions,
this approach can still be applied, and provides a general method that can be used to understand
the limitations of the quantum state space, and the measurement statistics it leads to.
As an exercise below, this same procedure is carried out with all three Pauli measurements,
from which the entire Bloch sphere of a qubit can similarly be recovered.
Exercises
3.3 Apply the same argument as in exercise 3.1, but for data →m = (mx, my, mz) arising
from the three Pauli measurements →
M = (σx, σy, σz), to show that the data is inconsistent
whenever ∥→m ∥2> 1. Explain why this re-derives the Bloch sphere.
3.1.6 Geometrical interpretation
We finish our exploration of quantum state estimation by investigating how the above certificates of
infeasibility can be understood geometrically. Understanding SDPs and their duality geometrically
can be very powerful, and provides insight and intuition for how and why duality works.
Our starting point is to think geometrically about the space of quantum states and space of
measurement data. The space of all quantum states of a fixed, finite dimension d is the set
S = {ρ ∣ρ ≽0, tr(ρ) = 1},
where ρ is an operator acting on Cd. This is a convex set, which we can always visualise as a
subset of Rd2. For a fixed set of measurements →
M, the set of all quantum states S gets mapped into a

(3.28
)
space of measurement results, which is the image of S under the mapping
ρ ↦→m = (tr(M1ρ), … , tr(MNρ))
which can be represented as a subset of RN. We denote this image by M. This mapping is
illustrated in figure 3.1. Because this is a linear map, the convexity of the state space is preserved, and
the space of all measurement results is also a convex set—see exercise 3.4.
Figure 3.1. Mapping between state space and space of measurement results of a fixed set of
measurements. An illustration of the mapping of the quantum state space S into the set of
measurement results M, under the mapping ρ ↦→m = (tr(M1ρ), … , tr(MNρ)). For
illustrative purposes both spaces are depicted as being 2-D, although in general they are both
high-dimensional bodies of different dimension. Each quantum state ρ is mapped to a single
vector of measurement results →m. In general, the mapping can be many-to-one, with multiple
quantum states being mapped to the same point in M. This means that the inverse mapping,
from a vector →m′ leads to a subset of the state space S, as depicted.
We can understand many features of the state estimation problem from this geometrical
perspective. First, note that the estimation problem is an inverse problem: we are given a point in the
measurement space, and ask for the quantum state(s) ρ under the inverse mapping. When the set of
measurements is not tomographically complete, then multiple states lead to the same set of
measurement results. This shows that there is a loss of information. As such, there is not a unique
solution to the inverse problem. In this case, the dimension of the measurement space will be smaller
than the dimension of the state space. On the other hand, when the measurements are tomographically
complete, there is no loss of information and a one-to-one mapping between the two spaces. This
implies that the dimension of the measurement space must be equal or greater to the dimension of the
state space.
Most interestingly, we can gain insight into the certificate of infeasibility. Geometrically, if a
fictitious set of measurement results →minc is inconsistent, this means it lies outside of the image of S.
A remarkable fact from convex geometry now comes into play: it is always possible to find a
hyperplane which separates a point from a convex set. This is somewhat obvious in one, two and

three dimensions, and in fact it holds in all dimensions. The certificate of infeasibility in precisely the
specification of such a separating hyperplane, as depicted in figure 3.2.
Figure 3.2. Geometric interpretation of certificate of infeasibility. An illustrative example in 2-
D of how the certificate of infeasibility can be viewed as a separating hyperplane where 
z + →t ⋅→m = 0, which separates M—the image of S (blue set)—from the supposed set of
measurement results →minc. The vector →t  specifies a direction, and z specifies an offset, such that
the image of S lies in the (green) region where z + →t ⋅→m < 0 and →minc lies in the orange
region, where z + →t ⋅→m > 0. Re-arranging, we can view −z as the ‘bound’ on the linear
function →t ⋅→m that separates the two regions.
As we will see in many instances throughout this book, dual SDPs can often be interpreted as
providing certificates or witnesses of certain properties, and these can be understood geometrically as
specifying separating hyperplanes.
Exercises
3.4 Show that the set M of measurement results—the image of S from (3.27) under the
mapping (3.28)—is a convex set. That is, show that if two sets of results →
m1 and →
m2 are
both in M, then so is any set of results of the form →m′= p →
m1 + (1 −p) →
m2 for 0 ⩽p ⩽1.

(3.29
a)
(3.29
b)
(3.29
c)
(3.29
d)
3.1.7 Property estimation
It can sometimes be the case that we are less interested in estimating the full state ρ that led to the
results →m, and more interested in knowing some property of it. If this property can be calculated by a
linear function f(ρ), such as energy or magnetisation, then we can find the range of values which are
possible, by finding both the minimum and maximum value of this property that any quantum state ρ
can have. To do this, we can modify the feasibility SDP (3.1) and introduce the objective function 
f(ρ), which is either minimised or maximised.
As an example, we can estimate the maximum expected value of an unperformed measurement
with observable ˜
M by solving the following SDP
maximise
tr( ˜
Mρ)
subject to
tr(Mxρ) = mx
x = 1, … , N,
tr(ρ) = 1,
ρ ≽0.
By solving both this, and the analogous minimisation problem, we find the range of possible
outcomes for the measurement ˜
M, consistent with the set of measurement results observed. As
previously, there are three regimes that can be encountered. If the measurements 
→
M are
tomographically complete, the feasible set is a unique state F = ρ*, and there will be a unique
expectation value ˜m = tr( ˜
Mρ*). Conversely, if there is no solution (because the measurement results
→m are inconsistent), the optimal value is α* = −∞, signalling the infeasibility of the problem.
Finally, when the measurements are consistent but not tomographically complete, we would expect
there to be a range of values, all consistent with the measurement results.
In sections 3.1.1 and 3.1.2 we saw that it is possible to calculate the trace distance and fidelity to a
target state σ. From the current perspective, we can view these as two further instances of property
testing—of the state having the property of being σ. As was seen previously, even though the trace
distance and fidelity are non-linear functions, both of these properties can nevertheless be estimated
using semidefinite programming. It is possible to estimate other properties—specified by non-linear
functions—using similar techniques.
3.2 The quantum marginal problem
In this final section we will now consider the quantum marginal problem. This problem is closely
related to quantum state estimation, with the key difference being in the type of information given. In
the previous sections of this chapter, we considered being given a set of measurement results, and
were interested in estimating the quantum state—or properties of it—from this measurement data. We
discussed in those sections the idea of tomographically complete data, i.e. data which is sufficient to
uniquely determine the quantum state.
In the context of the quantum marginal problem, we will be interested in multipartite quantum
states, comprising a number of subsystems. The assumption made now is that we have perfect
knowledge of some of the subsystems—i.e. some of the marginal states, more commonly referred to
as reduced density operators. This perfect knowledge can be thought of as being obtained by having
tomographically complete data for these subsystems—i.e. by having performed a tomographically
complete set of measurements, and having the corresponding measurement results. The basic

(3.30
a)
(3.30
b)
(3.30
c)
(3.30
d)
(3.30
e)
(3.31
)
(3.32
a)
(3.32
b)
problems of the quantum marginal problem are then to either determine the global state consistent
with all of the marginals, or to estimate some property of this global state, given access only to the
marginals.
We could now phrase everything just as was done above, in terms of measurement results.
However, since the focus is now exclusively on situations where we have full knowledge of a number
of subsystems, it is useful to adopt a more direct approach, and simply specify the reduced density
operators of those subsystems. On the one hand, this is a conceptually cleaner way to approach the
problem. On the other hand, it is an important lesson to realise that even in this formulation, we can
still apply the techniques of semidefinite programming.
As a concrete example, let us consider the direct quantum analogue of the (classical) marginal
problem considered in example 1.1. Therefore, consider a tripartite quantum system, with subsystems
labelled by X, Y and Z. Suppose that we have knowledge of the bipartite reduced density operators 
ρXY , ρXZ and ρY Z, but not of the joint state ρXY Z. Consider that we want to determine whether there
is any joint state consistent with the reduced density operators, and to find an example of one if it
does. This can be cast as the following feasibility SDP:
find
σXY Z
subject to
trZ(σXY Z) = ρXY ,
trY (σXY Z) = ρXZ,
trX(σXY Z) = ρY Z,
σXY Z ≽0,
tr(σXY Z) = 1.
As with the state estimation problem, there are a number of interesting variants of this basic
problem that can be considered. First, we can consider both trace distance and fidelity estimation of
the global state (or a marginal state) to a target state, in analogy to the problems studied in sections
3.1.1 and 3.1.2. We study these generalisations in exercises 3.5 and 3.6 respectively. Second, we can
also consider the analogous problem of property estimation from section 3.1.7. This is studied in
exercise 3.7 below.
We can also consider a problem which is closely related to the finite-statistics version of state
estimation from section 3.1.3. Here we imagine that instead of knowing the bipartite reduced density
operators exactly, they are only known approximately. One way to model this is to assume that the
marginals need to be ϵ-close to a fixed state, i.e. to demand
∥σXY −ρXY ∥1⩽ϵ,
where we have used the shorthand σXY = trZ(σXY Z), and similarly for σXZ and σY Z. We note
that, just as when considering finite statistics, ϵ is considered as being data which is specified in the
problem—allowing us to impose either stricter or weaker constraints on how close the reduced
density operators of ρXY Z need to be to the target states. Thus, we arrive at the following optimisation
problem
find
σXY Z
subject to
∥σXY −ρXY ∥1⩽ϵ,
∥σXZ −ρXZ ∥1⩽ϵ,

(3.32
c)
(3.32
d)
(3.32
e)
(3.33
a)
(3.33
b)
(3.33
c)
(3.33
d)
(3.33
e)
(3.34
a)
(3.34
b)
∥σY Z −ρY Z ∥1⩽ϵ,
σXY Z ≽0,
tr(σXY Z) = 1.
As written, this is not an SDP, due to the non-linear inequality constraints (3.32b)−(3.32d).
However, we can make use of the SDP characterisation of the ϵ trace norm ball, as given in exercise
2.17, itself a small extension of the unit trace norm ball from equation 2.36. In particular, we arrive at
find
σXY Z
s.t.
σXY −ρXY = ωXY −ζXY , tr(ωXY + ζXY ) = ϵ,
ωXY ≽0, ζXY ≽0,
σXZ −ρXZ = ωXZ −ζXZ,
tr(ωXZ + ζXZ) = ϵ,
ωXZ ≽0, ζXZ ≽0,
σY Z −ρY Z = ωY Z −ζY Z,
tr(ωY Z + ζY Z) = ϵ,
ωY Z ≽0, ζY Z ≽0,
σXY Z ≽0,
tr(σXY Z) = 1.
In order to emphasise the relationship between this formulation and (3.32), we have presented
four constraints per line, which collectively replace the corresponding trace norm constraint from the
former. Note also that we have had to introduce two new variables per constraint, thus arriving at a
larger problem. Nevertheless, this form is explicitly an SDP, and shows that it is possible to solve the
analogue of the finite statistics problem for the quantum marginal problem. Finally, although we
chose to place a constraint in terms of the trace norm, it is also possible in principle impose any
distance-type constraint, as long as it can be expressed as an SDP. Examples of such include other
norms, such as the operator norm, as well as the fidelity, both of which are left as exercises below.
Finally, we can also consider turning the problem from a feasibility SDP into a (standard)
optimisation SDP. As always, there are numerous approaches that one can take to achieve this. Here
we will consider a particularly simple approach which can be used when the target marginal states are
pure. In this case, a relaxation of the marginal problem is to find a global state whose marginals have
the largest average fidelity with the target pure marginals.
As a particular example, let us consider the analogue situation from exercise 1.9(c), where only
two of the marginals are specified. Let us therefore assume that ρXY =∣ψXY ⟩⟨ψXY ∣ and 
ρY Z =∣ψY Z⟩⟨ψY Z ∣. The largest average fidelity that can be achieved with these two states is given
by the following simple SDP
maximise
1
2 (⟨ψXY ∣σXY ∣ψXY ⟩+ ⟨ψY Z ∣σY Z ∣ψY Z⟩)
subject to
σXY Z ≽0,
tr(σXY Z) = 1.
In exercise 3.8, we can use the dual of (3.34) to show that a particle cannot simultaneously be in
a pure entangled state with two other particles.
In chapter 5 we will return to an important variant of the marginal problem when studying the
notion of a k-symmetric extension, a powerful tool in the theory of entanglement.
Exercises
3.5 In this exercise we will consider problems involving finding the closest state to a target
state—either the global state, or a marginal—in terms of the trace distance.

(3.35
a)
(3 35
(a) Consider a situation involving three particles, where we are given all of the
pairwise marginals, ρXY , ρXZ and ρY Z, and wish to estimate the trace distance
between the closest compatible state σXY Z and a target global state ρXY Z. Write down
the optimisation problem analogous to (3.4) that needs to be solved. This problem will
not be an SDP.
(b) Make use of (2.8) in order to re-express the optimisation problem from part (a) as
an SDP.
(c) Repeat the exercise from parts (a) and (b), assuming now instead that only the
marginal states ρXY  and ρXZ are specified, and that the goal is to estimate the trace
distance between the closest compatible marginal state σY Z and a target marginal state
ρY Z.
3.6 In this exercise we will repeat the same calculations as in the previous exercise, except
instead of optimising the trace distance, we now optimise the fidelity.
(a) Consider a situation involving three particles, where we are given all of the
pairwise marginals, ρXY , ρXZ and ρY Z, and wish to estimate the fidelity between the
closest compatible state σXY Z and a target global state ρXY Z. Write down the
optimisation problem that needs to be solved. This problem will not be an SDP.
(b) Make use of (3.10) in order to re-express the optimisation problem from part (a) as
an SDP.
(c) Repeat the exercise from parts (a) and (b), assuming now instead that only the
marginal states ρXY  and ρXZ are specified, and that the goal is to estimate the fidelity
between the closest compatible marginal state σY Z and a target marginal state ρY Z.
3.7 In this exercise we will consider property estimation in the context of the marginal
problem. Consider that we are given the Hamiltonian H of three particles, and the three
pairwise marginal states ρXY , ρXZ and ρY Z. Our goal is to find the range of average
energies that the system can have, consistent with these marginals.
(a) Write down an SDP that evaluates the minimum possible average energy any
global state σXY Z can have, given the Hamiltonian H and marginal states.
(b) Write down an SDP that evaluates the maximum possible average energy any
global state σXY Z can have, given the Hamiltonian H and marginal states.
3.8 In this exercise we will derive the dual SDP of (3.34) and use it to show that, when in a
pure state, a qubit cannot simultaneously be entangled with two other qubits.
(a) Write down the Lagrangian associated to the primal SDP (3.34), using MXY Z and 
μ as dual variables for the first and second constraint, respectively.
(b) Identify the constraints that need to be satisfied by the dual variables in order that
(i) The Lagrangian upper bounds the value of the primal objective function for
all primal feasible variables.
(ii) The Lagrangian becomes independent of the primal variables.
(c) Use parts (a) and (b) to show that, after solving for the slack variables, the dual
SDP to (3.34) is
minimise
μ
subject to
μI ≽1
2 (∣ψXY ⟩⟨ψXY ∣⊗IZ + IX⊗∣ψY Z⟩⟨ψY Z ∣).

(3.35
b)
(3.36
)
(3.37
)
This SDP can be solved explicitly, with optimal value given by
1
2 ∥∣ψXY ⟩⟨ψXY ∣⊗IZ + IX⊗∣ψY Z⟩⟨ψY Z ∣∥∞.
(d) For two projection operators Π1 and Π2, the following bound can be shown to
hold:
∥Π1 + Π2 ∥∞⩽1 + √∥Π2Π1Π2 ∥∞.
Writing the states ∣ΨXY ⟩ and ∣ΨY Z⟩ in terms of their Schmidt decompositions,
∣ΨXY ⟩= ∑
i
√pi ∣iX⟩∣iY ⟩,
∣ΨY Z⟩= ∑
i
√qi ∣iY ⟩∣iZ⟩,
use (3.36) to show that the optimum value of the dual SDP (3.35) is not larger than
μ* ⩽1
2 (1 + maxi√piqi).
(e) Explain why the answer to part (d) shows that a qubit cannot simultaneously
be in a pure entangled state with two other particles.
3.3 Concluding remarks
In this chapter we began our exploration of applying semidefinite programming techniques to
concrete problems in quantum information science. We mainly focused on the problem of quantum
state estimation, which allowed us to study a variety of interesting features of SDPs. In particular, the
main results described in this chapter are:
Quantum state estimation. The first problem dealt with was determining the existence of a
quantum state compatible with a set of measurement data. We introduced a few variants of this
problem, in particular, focusing on different figures of merit, such as the trace distance and the
fidelity. This demonstrated that problems involving non-linear objective functions can be cast as
SDPs.
Double minimisation. We showed that it is possible to cast problems involving double
minimisation or double maximisation as SDPs—see (3.5).
Certificates of infeasibility. When considering feasibility problems reformulated as
optimisation problems, the dual variables of SDPs can often be viewed as providing certificates
of infeasibility. This follows from the facts that (i) every feasibility SDP can be turned into an
optimisation SDP in which a positive solution indicates that the original problem was infeasible;
(ii) due to weak duality, the value of the objective function of the dual SDP lower bounds the
optimal value of the primal SDP. This allows us to analytically certify infeasibility.
3.4 Further reading
Nielsen M A and Chuang I L 2000 Quantum Computation and Quantum Information
(Cambridge: Cambridge University Press) http://doi.org/10.1017/CBO9780511976667

(3.38
)
(3.39
)
(3.40
a)
(3.40
b)
(3.40
c)
(3.41
)
(3.42
)
(3.43
)
3.5 Advanced topics
3.5.1 The fidelity SDP
In this section we will derive the SDP formulation for fidelity as given in (3.10). Recall that for a
general pair of quantum states ρ and σ, the fidelity is defined by
F(ρ, σ) =∥√ρ√σ ∥2
1.
Our starting point in this section will be Uhlmann’s theorem, which gives an alternative
expression for the fidelity in terms of purifications of ρ and σ. Recall that a purification of a (mixed)
state ω is a bipartite state ∣χ⟩ such that
trB[∣χ⟩⟨χ ∣] = ω,
where we label the systems as A and B.
Uhlmann’s theorem then gives a classification of the fidelity in terms of the biggest overlap
between any purification of ρ and σ, namely
F(ρ, σ) = maximise
∣⟨ψ ∣ϕ⟩∣2
subject to
trB[∣ψ⟩⟨ψ ∣] = ρ,
trB[∣ϕ⟩⟨ϕ ∣] = σ.
Let us consider that we have found an arbitrary purification of ρ and an arbitrary purification of 
σ, which we denote by ∣ψ⟩ and ∣ϕ⟩ respectively. Consider then the following state
∣Ψ⟩=
1
√2
(∣ψ⟩∣0⟩+ eiθ ∣ϕ⟩∣1⟩),
where we have now introduced a third system, labelled C, taken to be a qubit, and an arbitrary
phase factor eiθ which we will fix below.
The basic observation we make is that if ∣ψ⟩ and ∣ϕ⟩ are similar—i.e. if they are close to being
the same state, or have a large overlap ∣⟨ψ ∣ϕ⟩∣—then the state ∣Ψ⟩ cannot be very entangled.
In particular, as will be seen later in chapter 5, the entanglement of a pure state can be determined
by the reduced density operator of one subsystem. A state is entangled if and only if the reduced
density operator (on any subsystem) is mixed. In our case, the reduced density operator of C is
ωC = trAB[∣Ψ⟩⟨Ψ ∣] = 1
2 (∣0⟩⟨0 ∣+ ∣1⟩⟨1 ∣+e−iθ⟨ϕ ∣ψ⟩∣0⟩⟨1 ∣+eiθ⟨ψ ∣ϕ⟩∣1⟩⟨0 ∣).
Let us now choose the angle θ such that eiθ⟨ψ ∣ϕ⟩ is real and nonnegative (and therefore equal
to e−iθ⟨ϕ ∣ψ⟩ and, moreover ∣⟨ψ ∣ϕ⟩∣). The purity of ωC is then seen to be
tr[ω2
C] = 1
2 (1+ ∣⟨ψ ∣ϕ⟩∣2).

(3.44
a)
(3.44
b)
(3.44
c)
(3.45
)
(3.46
a)
(3.46
b)
This shows that when ∣ψ⟩ and ∣ϕ⟩ are orthogonal, such that ∣⟨ψ ∣ϕ⟩∣= 0, then the purity of ωC is
minimal, since ωC = 1
2 I is the maximally mixed state in this case. On the other hand, when 
∣⟨ψ ∣ϕ⟩∣= 1—meaning that they are the same state—then the purity of ωC is maximal, and indeed 
ωC =∣+⟩⟨+ ∣ is a pure state in this case. What this shows is that, as claimed, the entanglement of 
∣Ψ⟩ depends upon the overlap of ∣ψ⟩ and ∣ϕ⟩, and can therefore be used to measure it.
We will now see how to use the above insight in order to derive (and interpret) the SDP for
fidelity. Let us look instead at the reduced density operator ωAC,
ωAC
= trB[∣Ψ⟩⟨Ψ ∣],
= 1
2 (ρ⊗∣0⟩⟨0 ∣+σ⊗∣1⟩⟨1 ∣
+ e−iθtrB[∣ψ⟩⟨ϕ ∣]⊗∣0⟩⟨1 ∣+eiθtrB[∣ϕ⟩⟨ψ ∣]⊗∣1⟩⟨0 ∣)
where we used the fact that trB[∣ψ⟩⟨ψ ∣] = ρ and trB[∣ϕ⟩⟨ϕ ∣] = σ. Being a density operator,
we know that ωAC ≽0. Moreover, it can be seen that the trace of the Hermitian part of the off-
diagonal block e−iθtrB[∣ψ⟩⟨ϕ ∣] is
tr[ e−iθtrB[∣ψ⟩⟨ϕ ∣] + eiθtrB[∣ϕ⟩⟨ψ ∣]
2
] =∣⟨ψ ∣ϕ⟩∣.
Why is this relevant? Well, recall that, due to Uhlmann’s theorem, ∣⟨ψ ∣ϕ⟩∣, when maximised,
is precisely √F(ρ, σ). We have however just realised that ∣⟨ψ ∣ϕ⟩∣ is also the trace of the Hermitian
part of the off-diagonal block of ωAC. This provides us with a way of obtaining an upper bound on
the fidelity. The off-diagonal block e−iθtrB[∣ψ⟩⟨ϕ ∣] can be treated as a variable, which we denote by
Y + iZ (with Y = Y † and Z = Z† Hermitian operators) and then consider maximising the trace of Y
(the Hermitian part), subject to the constraint that ωAC is a valid density operator, namely
√F(ρ, σ) ⩽maximise
tr(Y )
subject to
(
) ≽0,
where we have written ωAC as a block matrix, and have ignored the overall factor of 1
2 , which
doesn’t affect whether or not it is positive semidefinite. This is an upper bound, since we know that it
is possible to take Y + iZ = e−iθtrB[∣ψ⟩⟨ϕ ∣], with ∣ψ⟩ and ∣ϕ⟩ the optimal purifications of ρ and σ
respectively (which achieve the fidelity through Uhlmann’s theorem), and with θ such that eiθ⟨ψ ∣ϕ⟩
is real. However, since we have relaxed the problem, and are maximising, there is no guarantee that
this is the optimal solution, the maximum might be attained at a strictly larger number than the
fidelity.
In order to show that this isn’t the case, we can now proceed in the other direction, to show that 
tr(Y *) ⩽√F(ρ, σ). Let us assume that (3.46) has been solved, and that optimal variables Y * and 
Z * have been found. This in particular means that we have found a density operator
1
ρ
Y + iZ
Y −iZ
σ

(3.47
)
(3.48
)
(3.49
a)
(3.49
b)
(3.49
c)
(3.50
a)
(3.50
b)
(3.50
c)
(3.50
d)
(3.51
)
ω
*
AC = 1
2 (ρ⊗∣0⟩⟨0 ∣+σ⊗∣1⟩⟨1 ∣+(Y * + iZ *)⊗∣0⟩⟨1 ∣+(Y * −iZ *)⊗∣1⟩⟨0 ∣).
Consider then a purification of ω
*
AC, which we denote ∣Ψ*⟩ (with the purifying system labelled
B). From this purification we can define two (normalised) states,
∣ψ*⟩= √2(IAB ⊗⟨0 ∣C) ∣Ψ*⟩,
∣ϕ*⟩= √2(IAB ⊗⟨1 ∣C) ∣Ψ*⟩,
Crucially, these states can be seen to be purifications of ρ and σ. Indeed, we see that
trB[∣ψ*⟩⟨ψ* ∣] = 2trB[(IAB ⊗⟨0 ∣C) ∣Ψ*⟩⟨Ψ* ∣(IAB⊗∣0⟩C)],
= 2[(IA ⊗⟨0 ∣C)ω
*
AC(IA⊗∣0⟩C)],
= ρ,
and similarly trB[∣ϕ*⟩⟨ϕ* ∣] = σ. (Note also that this confirms that ∣ψ*⟩ and ∣ϕ*⟩ are
normalised.) Now, the overlap between ∣ψ*⟩ and ∣ϕ*⟩ is
∣⟨ψ* ∣ϕ*⟩∣= 2⟨Ψ* ∣(IAB⊗∣0⟩⟨1 ∣C) ∣Ψ*⟩,
= 2 ∣tr[(IA⊗∣0⟩⟨1 ∣C)ω
*
AC] ∣,
= ∣tr(Y *) + i tr(Z *) ∣,
= √tr (Y *)
2 + tr (Z *)
2.
So, from Ulhmann’s theorem, since ∣ψ*⟩ and ∣ϕ*⟩ are purifications of ρ and σ, we know that
the fidelity F(ρ, σ) must be at least ∣⟨ψ* ∣ϕ*⟩∣2, and therefore we have the bound
√F(ρ, σ) ⩾∣⟨ψ* ∣ϕ*⟩∣= √tr (Y *)2 + tr (Z *)2.
However, comparing with (3.46), we have tr(Y *) ⩾√F(ρ, σ). The only way that these two
bounds can be satisfied is if √F(ρ, σ) = tr(Y *) and tr(Z *) = 0.
That is, this shows that in (3.46) the inequality can be replied by an equality, and that in fact this
SDP precisely evaluates to the fidelity between ρ and σ.
The derivation is moreover interesting since it sheds light on how to interpret the SDP. We can
view the objective function as maximising the entanglement of a state of the form (3.41), which
entangles purifications of ρ and σ. Only if the states have a small fidelity (meaning they are close to
being orthogonal) can there exist purifying states that then can be superposed and generate a large
amount of entanglement. When the states have a large fidelity, meaning they are similar, it is not
possible to find purifications of them which generate much entanglement by superposing them.
This can be viewed as a type of trade-off relation, between how similar states are, and how much
their purifications can be entangled with an auxiliary system, and shows that the fidelity quantifies
this trade-off.

IOP Publishing
Semidefinite Programming in Quantum Information
Science
Paul Skrzypczyk and Daniel Cavalcanti

Chapter 4
Quantum measurements
In this chapter we will see that semidefinite programming is highly relevant and applicable
to problems involving optimisation over quantum measurements. The reason for this is
similar to the reason why semidefinite programs (SDPs) arise so broadly when considering
problems involving quantum states—because the elements of a measurement M = {Ma}
are positive semidefinite operators, Ma ≽0, and the normalisation condition, ∑a Ma = I
, is a linear equality constraint. This means that it is always possible to optimise over of the
set of quantum measurements inside an SDP. In this chapter, we will see numerous
examples of problems involving measurements where SDP techniques can be applied to
solve the problem, and to gain important insights.
In particular, we will begin by considering the analogous problem to state estimation
considered in the previous chapter—namely measurement estimation. It will be seen that
many of the same ideas carry over in a very natural way to this setting. We will then turn to
a second fundamental task of quantum information science, which finds application in
numerous settings: the problem of quantum state discrimination. We will see in this chapter
how this task can be formulated as a semidefinite program, and that complementary
slackness can be used in order to re-derive the well-known optimality conditions which
constitute necessary and sufficient conditions satisfied by any measurement which can
perform state discrimination optimally.
We then study state discrimination from a second, complementary perspective,
considering instead a fixed measurement. We will see that semidefinite programming can
be used to answer the question of ‘how useful’ a given measurement is for quantum state
discrimination.
4.1 Quantum measurement estimation
Chapter 3 started by considering the problem of quantum state estimation, which was
motivated by a situation where an experimentalist observes a set of expectation values
when measuring a set of (known) observables on an (unknown) quantum state that they
want to estimate. Here, we will begin by considering the symmetric situation. Namely,
consider a situation where an experimentalist uses an unknown measuring device to
measure a collection of known quantum states. As previously, the question now is to
determine which set of measurements is compatible with the experimental data.

(4.1a
)
(4.1b
)
(4.1c
)
(4.1d
)
(4.2a
)
(4.2b
)
(4.2c
)
(4.2d
)
In more detail, let us assume that we have an unknown measurement M = {Ma}a,
with outcomes a = 1, … , o, which is used to measure a known set of N quantum states 
{ρx}x, leading to observed statistics {p(a ∣x)}a,x. Finding a measurement compatible
with these statistics is given by the following feasibility SDP1:
find
M
subject to
tr(Maρx) = p(a ∣x)
∀a, x,
Ma ≽0
a = 1, … , o,
∑
a
Ma = I.
As in the case of (3.1), there are three possibilities that can arise: if the set of states 
{ρx}x is tomographically complete—meaning that measurements on such a set of states
are sufficient to uniquely determine the measurement performed—then if the statistics were
feasible, there will be a unique solution; on the other hand, if the states are not
tomographically complete, but the statistics are still compatible, then there will be
infinitely many solutions; finally, if the statistics cannot be produced by any measurement,
then the problem is infeasible.
In the above, we have assumed that the full statistics p(a ∣x) are given. It is possible
consider other possibilities for the data that is given, for example to only be given
expectation values. In this case, the problem remains a feasibility SDP. This formulation is
studied in exercise 4.1.
We can also consider other variants of the problem, similar to those considered in
chapter 3. For example, it is natural that the probabilities p(a ∣x) will not be known
exactly, but will have some inherent uncertainty, due to finite statistics. If we denote the
uncertainty in the probability p(a ∣x) by Δax, then the following feasibility SDP searches
for a valid measurement consistent with these constraints:
find
M
subject to
p(a ∣x) −Δax ⩽tr(Maρx) ⩽p(a ∣x) + Δax
∀a, x,
Ma ≽0
a = 1, … , o,
∑
a
Ma = I.
Finally, it can also be useful to work with a standard optimisation SDP, rather than the
feasibility SDP (4.1). One way to achieve this, which leads to an SDP that is bounded and
feasible—which will therefore have a dual formulation—is to consider minimising a

(4.3a
)
(4.3b
)
(4.3c
)
(4.3d
)
(4.4a
)
(4.4b
)
(4.4c
)
(4.4d
)
uniform perturbation of the probabilities p(a ∣x). Namely, the following minimisation
SDP
minimise
δ
subject to
p(a ∣x) −δ ⩽tr(Maρx) ⩽p(a ∣x) + δ
∀a, x,
Ma ≽0
a = 1, … , o,
∑
a
Ma = I.
If the feasibility problem (4.1) was feasible, then δ* = 0, and both the left-hand and
right-hand inequality constraints in (4.3b) become equal, and so enforce that 
tr(Maρx) = p(a ∣x). On the other hand, if (4.1) was infeasible, then δ* > 0 will be
necessary in order to find a solution. However, it is clear that it will always be possible to
find a solution with δ* ⩽1, since at δ = 1, the constraints (4.3b) are necessarily vacuous,
and any measurement will be a feasible solution.
In exercise 4.2 the dual formulation of (4.3) is derived. It is shown that this formulation
is
maximise
∑
a,x
(vax −uax)p(a ∣x) + tr(Y )
subject to
Y + ∑
x
(vax −uax)ρx ≼0
a = 1, … , o,
∑
a,x
(uax + vax) = 1
uax ⩾0,
vax ⩾0
∀a, x.
This dual formulation can be understood geometrically, such that we arrive at a very
similar type of situation as encountered in figure 3.2, in the context of state estimation. In
particular, let us group all of the probabilities p(a ∣x) into a single vector →p. That is, we
will have a vector whose components are p(a ∣x), and therefore, it will be natural to label
the components by the pair of indices a and x, which will be denoted pax.2 In a similar
fashion, we can define vectors →u and 
 with components uax and 
 respectively.
Recalling (1.62), it can be seen that it is advantageous to combine these vectors into a
single vector 
, in which case the constraints (4.4c) and (4.4d) can be interpreted
as imposing ∥→s ∥1⩽1. This leads us to the following equivalent expression for the dual
formulation (4.4),
maximise
→s ⋅→p + tr(Y )

(4.5a
)
(4.5b
)
(4.5c
)
subject to
Y + ∑
x
saxρx ≼0
a = 1, … , o,
∥→s ∥1⩽1.
This is similar in form to (3.18), and can be understood analogously. The data 
p(a ∣x) specifies a point →p in the space of measurement results. Within this space, given
the set of states {ρx}x, there is a (convex) subset of feasible data. The dual formulation can
be interpreted as finding a separating hyperplane, such that if the proposed data p(a ∣x)
was infeasible, it will lie on one side of the plane, while the entire feasible set of data lies
on the other side. This is very similar and completely analogous to figure 3.2 from the
previous chapter.
Exercises
4.1 In this exercise we will consider the variant of measurement estimation
where we are instead given as data the expectation values mx, obtained when
the measurement M is performed on state ρx.
(a) Write down the quantum mechanical expression for the expectation
value when performing a measurement M = {Ma}a on a state ρx.
(b) Write down a feasibility SDP that will determine whether a M exists,
that is able to reproduce the expectation value data {mx}x.
4.2 In this exercise we will derive the dual SDP (4.4).
(a) Write down the Lagrangian associated to (4.3), introducing dual
variables uax and 
 for a = 1, … , o and x = 1, … , N, associated to the
right-hand and left-hand constraints in (4.3b), Xa associated to (4.3c) and 
Y  associated to (4.3d)
(b) Use the Lagrangian to arrive at a dual formulation of (4.3), by
identifying the required inequality and equality constraints that need to be
satisfied in order to make the Lagrangian simultaneously a lower bound on
the primal objective function and independent of the primal variables.
(c) Show that in the dual SDP derived in (b) Xa are slack variables, and
can therefore be eliminated. Thus, show that (4.4) is the dual SDP
formulation of the measurement estimation problem.
4.2 Quantum state discrimination I
We now turn our attention to quantum state discrimination, which is a fundamental task of
quantum information science, which finds application in numerous settings. The techniques

(4.6)
(4.7a
)
(4.7b
)
of semidefinite programming can be widely applied to this task, as we will see in this
section and the next.
In the setting of quantum state discrimination, we have a source of quantum particles
which outputs probabilistically one of a number of quantum states. The goal is to correctly
identify which state was emitted. More formally, the source produces the quantum state ρi,
for i = 1, … , m with probability q(i). The source is thus characterised by an ensemble
E = {q(i), ρi}i. We will also define the associated probability vector →q whose elements are
qi = q(i).
We can view quantum state discrimination as the encoding of classical data into
quantum states, which then needs to be recovered or decoded. The classical information is
the random variable i, distributed according to q(i). In order to decode the information
stored in the quantum state, it is necessary to perform a measurement, and based upon the
result of this measurement to make a guess of the value of i. This will only be a guess,
since in general it will not be possible to perfectly identify which state ρi was sent, and
therefore to identify the value of i. In quantum state discrimination the overarching goal is
to guess as well as possible the state, and hence the value of i.
There are a number of different figures of merit that one can consider optimising in this
task. Here we will focus on the two most widely studied, minimum-error quantum state
discrimination, and unambiguous quantum state discrimination. In the former, we seek to
minimise the average error made, which is equivalent to maximising the average success
probability of correctly guessing; in the latter we seek to maximise the probability of being
certain that the state has been correctly identified.
4.2.1 Minimum-error quantum state discrimination
The first variant of quantum state discrimination we will consider is when the goal is to
minimise the average error of incorrectly identifying the state. Due to symmetry, this can
alternatively be phrased as maximising the average probability of correctly identifying the
state. Upon receiving a state, we assume that a measurement M = {Ma}a is performed. If
the outcome of the measurement is a, then we will guess that this was the state received.
The probability to obtain the outcome a when the state is ρi is
p(a ∣i) = tr(Maρi).
The figure of merit we consider is the average probability of correctly guessing the state,
Pguess = p(a = i)
= ∑
i
q(i)p(a = i ∣i)
= ∑
i
q(i) tr(Miρi).

(4.7c
)
(4.8)
(4.9a
)
(4.9b
)
(4.9c
)
(4.10
)
This is the average probability of guessing correctly using the measurement M, and the
guessing strategy that a = i. In order to find the best possible average guessing
probability, we need to optimise over all choices of measurement, namely
P
*
guess = max
M
∑
i
q(i) tr(Miρi).
In exercise 4.3 it is shown that this is indeed the best possible average guessing probability,
i.e. that you do not need to optimise over more general guessing strategies, involving, for
example, not merely using the measurement result to directly guess which state was sent, i
= a. The final step is to realise that the optimisation over measurements can be written as
an SDP. In particular, using the conditions that must be satisfied by any valid measurement,
we arrive at the following explicit SDP formulation of (4.8):
P
*
guess = maximise
∑
i
q(i) tr(Miρi)
subject to
Ma ≽0
a = 1, … , m,
∑
a
Ma = I.
 
As a first application, we will see below that in the simplest possible quantum state
discrimination task—involving two equally likely states—then we can use insights from
chapter 2 to solve the SDP analytically, and in so doing, arrive at an operational
interpretation for the trace distance (3.2).
4.2.2 Binary state discrimination
In the case of binary state discrimination, where either the state ρ1 or ρ2 is given, with
equal probability q(1) = q(2) = 1/2, we need to optimise over two outcome
measurements M = {M1, M2}. Due to the normalisation constraint M1 + M2 = I, we see
that only a single measurement operator is actually optimised over. We could solve for 
M2 = I −M1, however this would break the symmetry between the two measurement
operators somewhat. A more symmetrical way to reduce down to a single operator is to
introduce an auxiliary operator Z such that
M1 = I + Z
2
,
M2 = I −Z
2
.
By construction, we have that M1 + M2 = I. In order for each element to remain
positive semidefinite, we see that Z must satisfy
−I ≼Z ≼I,

(4.11
)
(4.12
a)
(4.12
b)
(4.13
a)
(4.13
b)
with the left-hand inequality ensuring that M1 ≽0, and the right-hand ensuring that 
M2 ≽0. For binary quantum state discrimination, in terms of this new variable, we
therefore find that (4.9) becomes
P
*
guess = maximise
1
2 + 1
4 tr[Z(ρ1 −ρ2)]
subject to −I ≼Z ≼I.
At this stage, we can now cast our mind back to exercise 2.6, and the SDP for the
trace norm given in (2.11). By inspection, we see that by considering A = ρ1 −ρ2, the
only difference between the two SDPs would be in the objective function, which has been
shifted and re-scaled from tr(ZA) to 1
2 + 1
4 tr(ZA), and therefore we have
P
*
guess = 1
2 + 1
4 ∥ρ1 −ρ2 ∥1,
= 1
2 [1 + T(ρ1, ρ2)]
where in the second line we have furthermore used the definition of the trace distance,
namely T(ρ1, ρ2) = 1
2 ∥ρ1 −ρ2 ∥1 as given in (3.2). We have thus recovered the well-
known result—a special instance of the Helstrom bound—the trace distance quantifies how
well two states can be distinguished from each other in the setting of minimum-error binary
quantum state discrimination. This result is important as it provides a clear operational
interpretation of the trace distance between two states.
Exercises
4.3 In this exercise we will show that when optimising over measurement
strategies in minimum-error quantum state discrimination, without loss of
generality we can assume that a fixed measurement is performed, and take the
outcome of the measurement to be the guess of which state was received.
Consider the following general class of strategies: (i) generate a random variable
λ according to a probability distribution p(λ); (ii) conditional on λ, when the
state is received, apply a unitary transformation Uλ to the state; (iii) measure the
state using an arbitrary measurement M = {Ma} and obtain an outcome a; (iv)
conditional on both a and λ, probabilistically make a guess for the state
according to a probability distribution p(i ∣a, λ).
(a) Write down Pguess for the above strategy.
(b) Show that your answer to part (a) can be expressed in a form identical
to (4.7c) using a measurement M′= {M′i}, with elements

(4.14
)
(4.15
)
(4.16
a)
(4.16
b)
M ′
i = ∑
a,λ
p(λ)p(i ∣a, λ)U †
λMaUλ.
(c) Verify that M′ from part (b) is a valid measurement.
(d) Explain why the above shows that there is no loss of generality in
restricting to the basic subset of strategies considered in the main text.
4.4 Show that for non-symmetric binary quantum state discrimination, with
arbitrary q(1) and q(2), the average success probability is
p
*
guess = 1
2 + 1
2 ∥q(1)ρ1 −q(2)ρ2 ∥1
4.5 Use exercise 2.7 to show that an optimal measurement for binary quantum
state discrimination is
M
*
1 = Π(+),
M
*
2 = Π(−),
where Π(+) and Π(−) are the projectors onto the positive and negative parts
of ρ1 −ρ2, respectively, as defined in (2.14). This provides a complete
understanding of the problem of binary quantum state discrimination, giving
both the optimal success probability, and the measurement that should be
performed in order to achieve it.
4.2.3 Optimality conditions
Going beyond the simple case of binary quantum state discrimination, it is in general a
difficult problem to find the optimal success probability and measurements for minimum-
error quantum state discrimination. There are however a set of necessary and sufficient
conditions, which if satisfied, guarantee that a set of measurements is indeed optimal.
These conditions are
M
*
i (q(i)ρi −q(j)ρj)M
*
j = 0
i, j = 1, … , m,
∑
j
q(j)ρjM
*
j −q(i)ρi ≽0
i = 1, … , m.
We will now see that the concept of complementary slackness—introduced in section
2.4—can be used to derive these conditions. Our starting point is the Lagrangian associated
to (4.9), which we see is
L = ∑
i
q(i) tr(Miρi) + ∑
i
tr(ZiMi) + tr[W(I −∑
i
Mi)],

(4.17
a)
(4.17
b)
(4.18
a)
(4.18
b)
(4.18
c)
(4.19
)
(4.20
a)
(4.20
b)
= ∑
i
tr[Mi(q(i)ρi + Zi −W)] + tr(W),
where we have introduced dual variables Zi ≽0 for i = 1, … , m and W associated
to the positivity constraints (4.9b) and normalisation constraint (4.9c) respectively. The
dual SDP formulation for minimum-error quantum state discrimination is therefore
P
*
guess = minimise
tr(W)
subject to
q(i)ρi + Zi −W = 0
i = 1, … , m,
Zi ≽0
i = 1, … , m.
We have chosen not to eliminate the slack variables Zi for the time being. The reason
for doing so will become clear below, but we emphasise that when using complementary
slackness, it is important to keep all dual variables initially, even the slack variables.
First of all, in order to use complementary slackness it necessary to check that strong
duality holds. Here, it can be seen directly that it does indeed hold. In particular, note first
that for all values of a, Ma = I/m ≻0 is a strictly feasible solution for the primal SDP
(4.9). Second, for all values of i, Zi = γI ≻0 is a strictly feasible dual variables for the
dual SDP (4.18). Since both problems are thus strictly feasible, strong duality holds. This
confirms in turn that P
*
guess is finite, as we know to be true on physical grounds.
Since strong duality holds, we can now appeal to complementary slackness, in order to
see what can be learnt about the optimal variables. From (4.17), we see that the second
term must vanish in order that L = p
*
guess, which implies that
Z
*
i M
*
i = 0
i = 1, … , m,
since M
*
i ⩾0 and Z
*
i ⩾0, as explained in section 2.4.
Now, from the dual constraint (4.18b), we see that for all i, Z
*
i = W * −q(i)ρi.
Inserting this into the complementary slackness condition, we see that
0 = Z
*
i M
*
i = (W * −q(i)ρi)M
*
i
⇒W *M
*
i = q(i)ρiM
*
i
i = 1, … , m.
If we now sum both sides of (4.20b) over i, given that W * is independent of i, and
that ∑i M
*
i = I, we can solve for W * in terms of the optimal dual measurement operators 
M
*
i , namely

(4.21
)
(4.22
)
(4.23
)
(4.24
)
(4.25
)
W * = ∑
i
q(i)ρiM
*
i .
This is already an important relationship between the optimal primal and dual
variables. Using the fact again that Z
*
i = W * −q(i)ρi, combined with the above, and the
constraint Z
*
i ≽0, we see that
Z
*
i = ∑
i
q(i)ρiM
*
i −q(i)ρi ≽0,
which is precisely the second optimality condition (4.16b).
To obtain the first optimality condition we start by returning to (4.20b), and consider
multiplying both sides of the equation from the left by an optimal measurement operator 
M
*
j , which shows that
M
*
j W *M
*
i = M
*
j q(i)ρiM
*
i
i, j = 1, … , m.
We can now consider taking the Hermitian conjugate of this equation, keeping in
mind that all of the operators involved are Hermitian. Interchanging the indices i ↔j, we
arrive at
M
*
j W *M
*
i = M
*
j q(j)ρjM
*
i
i, j = 1, … , m,
which is almost identical to before, except now on the left-hand side we have q(j)ρj
instead of q(i)ρi. Crucially, since the left-hand sides of (4.23) and (4.24) are equal, this
allows us to eliminate the slack variable W *, and obtain
M
*
i (q(i)ρi −q(j)ρj)M
*
j = 0
i, j = 1, … , m,
which are precisely the first set of optimality conditions (4.16).
Thus, we have shown that the optimality conditions (4.16) are implications of the
complementary slackness conditions associated to the primal and dual SDP formulations of
minimum-error quantum state discrimination. As a small note, the complementary
slackness conditions themselves are both necessary and sufficient. Since these were used to
derive implications, we recover the fact that (4.16) are necessary conditions that must be
satisfied. What is not shown yet, is that they remain sufficient conditions, equivalent to the
complementary 
slackness 
conditions. 
This 
‘converse’ 
argument 
is 
however
straightforward, and left for exercise 4.8 below.
Exercises

(4.26
)
4.6 Show that the optimal measurements for binary quantum state
discrimination found in exercise 4.5 satisfy the optimality conditions (4.16) 
as they must.
4.7 Calculate the optimal dual variables W * and Z
*
i  for i = 1, 2, for binary
quantum state discrimination, and show that the complementary slackness
conditions (4.19) are satisfied for these in combination with the optimal
measurements found in exercise 4.5.
4.8 In this exercise we will show that the optimality conditions (4.16) are
equivalent to the complementary slackness conditions. In particular, it needs to
be shown that starting from the conditions (4.16), a feasible set of optimal dual
variables can be defined, that satisfy complementary slackness (4.19). Note that
we do not need to worry about the primal variables being feasible, since by
assumption a valid measurement has been found for the conditions to make
sense. We will guess, based upon (4.21) and (4.22), that the following set of dual
variables are optimal:
W * = ∑
i
q(i)ρiM
*
i ,
Z
*
i = ∑
j
q(j)ρjM
*
j −q(i)ρi
(a) Show that, due to the second set of optimality constraints (4.16b),
these dual variables are dual feasible, i.e. satisfy (4.18b) and (4.18c).
(b) Show that, due to the first set of optimality constraints (4.16), the
complementary slackness conditions (4.19), Z
*
i M
*
i = 0, are satisfied.
Hint: It will be useful to use the fact that Z *†
i
= Z
*
i  in order to obtain an
alternative expression for Z *
i  as a first step. Together, parts (a) and (b)
imply that whenever the optimality conditions (4.16) are satisfied, then so
too are the complementary slackness conditions. Since satisfying
complementary slackness is sufficient for being optimal, this shows that the
optimality conditions are both necessary and sufficient..
4.2.4 Unambiguous quantum state discrimination
We now consider a second variant of quantum state discrimination, known as unambiguous
quantum state discrimination. In the previous setting, of minimum-error quantum state
discrimination, all that was required was that on average the state was identified as well as
possible. This means, in particular, that errors are made: the guess of the state is not always
equal to the state received. In some circumstances, such errors can be problematic or highly
undesirable, and this motivates unambiguous state discrimination.
In the current setting, we consider allowing a new freedom in state discrimination—the
possibility of not making a guess of the state, that is, of declaring failure in identifying the
state. Now, however, we demand that whenever a guess is made, we should be certain that

(4.27
)
(4.28
)
(4.29
a)
(4.29
b)
the state has been correctly identified. The figure of merit in unambiguous state
discrimination is therefore to maximise the probability of being certain about the state,
which is equivalent to minimising the probability of being uncertain about the state (i.e.
declaring failure).
In order to model this situation, when considering a quantum state discrimination task
with m states, a measurement M = {Ma} with m + 1 outcomes is used. The first m
outcomes are the guesses, a = 1, … , m, while the additional outcome a = ∅ is the
‘failure’ outcome. That is, the result a ≠∅ should be returned whenever it is certain that
the corresponding state was sent—i.e. when the state has been unambiguously identified—
and should return the failure outcome a = ∅ in any other case, signifying the failure to
identify the state.
How can we guarantee that when an outcome a ≠∅ is seen that we are certain of the
state? In order to do so, it must be the case that the probability of seeing any outcome other
than i on the state ρi must be strictly zero. That is, the measurement used must be restricted
to satisfy
p(a ∣i) = tr(Maρi) = 0
i, a = 1, … , m; a ≠i.
Note that this condition is not imposed for M∅, the measurement element associated
with failure. For reasons that will become clear below, it will be useful to consider instead
of the state ρi, the product, or unnormalised state, q(i)ρi namely to impose
p(a, i) = q(i) tr(Maρi) = 0
i, a = 1, … , m; a ≠i.
One way to see why this is in fact a more natural constraint to impose is that it means
that if a state would occur with zero probability, q(i) = 0, for some i, then by imposing
(4.28) no constraint would be imposed, while according to (4.27) a constraint would still be
imposed, which is rather unnatural. We will also see below that if (4.28) is used, it will lead
to a simpler dual SDP with a more natural structure (compared to using (4.27)), which will
prove useful.
Since (4.28) constitute a set of linear constraints that must be satisfied by the
measurement, we can impose them as constraints inside an SDP—restricting the class of
measurements considered—and optimise to find the best such measurement for
unambiguous state discrimination. We therefore arrive at the following SDP which
provides the largest average probability of unambiguously identifying a state
P
*
guess = maximise
m
∑
a=1
q(i) tr(Miρi)
subject to
q(i) tr(Maρi) = 0
i, a = 1, … , m; a ≠i.
Ma ≽0
a = 1, … , m, ∅

(4.29
c)
(4.29
d)
∑
a
Ma = I.
 
Unambiguous state discrimination is a harder task than minimum-error state
discrimination, since the requirements on the measurement are more demanding. It can be
seen that in certain circumstances unambiguous state discrimination is impossible, meaning
that the optimal measurement for a given ensemble of states E = {q(i), ρi} has M
*
a = 0
for a = 1, … , m and M
*
∅= I, leading to P
*
guess = 0.
We can actually understand when this happens. There are two separate cases to
consider. First, since ρi ≽0, the only way that tr(Maρi) = 0 is if Maρi = 0. Therefore,
if a ρi is full rank, then it follows that no other state can be unambiguously identified, 
Ma = 0, for a ≠ i. Unambiguous state discrimination is therefore impossible for a set of
two or more full-rank states, and is uninteresting already when one state is full rank. We
therefore restrict our attention to the case where none of the states are full rank.
Interestingly, even if none of the states are full rank it can still happen that
unambiguous state discrimination is impossible. In the ‘Advanced topics’ section 4.6.1 we
investigate this further, and show how it can lead to insight into the dual SDP for
unambiguous state discrimination.
4.3 Quantum state discrimination II
In the previous section we viewed quantum state discrimination from the perspective where
the ensemble of states to be discriminated was the data of the problem, and considered
optimising over the set of quantum measurements, in order to identify the state with the
largest probability of success (or, said differently, with the smallest probability of error).
Quantum state discrimination is also interesting from an alternative perspective, where
we view the measurement as fixed, i.e. as the input data, and allow ourselves to optimise
over different state discrimination tasks, each specified by an ensemble E. In this section,
we will consider quantum state discrimination from this alternative perspective.
The motivation for considering this comes from understanding the question of how
informative a measurement is—about its ability to provide classical information about the
quantum state. Intuitively, one way to see that a given measurement is highly informative is
if it can perform very well in at least one quantum state discrimination task. On the other
hand, if a measurement is unable to perform well in any quantum state discrimination task,
then this is naturally an uninformative measurement.
We will see below that this intuition can be formalised, and that the duality of
semidefinite programming shows that quantum state discrimination provides an operational
characterisation of a quantifier of measurement informativeness, known as the generalised
robustness of measurement informativeness. This is a particular example of a more general
correspondence that exists, and it is thus useful to study this example in detail to learn how
SDPs can be applied in such settings.

(4.30
)
(4.31
)
(4.32
)
(4.33
a)
Let us focus on the task of minimum-error quantum state discrimination, as considered
in section 4.2.1. Assuming the same guessing strategy as previously—that if the outcome a
is observed, a guess is made that the state received was ρa—the probability of correctly
guessing the state, for a fixed measurement M = {Ma} with o outcomes, a = 1, … , o,
and for a fixed ensemble E = {q(i), ρi}, with the same number of states o, is
Pguess = ∑
i
q(i) tr(Miρi).
Inspired by the analysis from before, we may be tempted to optimise this average
success probability over all ensembles in order to define a figure of merit for how
informative a measurement is, namely
P
*
guess = maximise
∑
i
q(i) tr(Miρi),
that is, to merely interchange the role played by the measurement (now considered the
fixed input data), and the ensemble (now considered the optimisation variable). However,
as shown in exercise 4.11, P
*
guess is not a good figure of merit, since it is maximised by an
ensemble with only a single state occurring with unit probability. What is problematic
about (4.31) is that it doesn’t capture the fact that as the ensemble E is varied, the intrinsic
difficultly in identifying the state also varies. Consider for example a trivial situation in
which we have no ability to perform a measurement at all. How well can we do in a
quantum state discrimination task? The optimal strategy is to guess the most likely state all
of the time. If we do this, our probability of correctly guessing the state is
P (no meas)
guess
= maxiq(i).
Therefore, we can always do very well in a state discrimination game that is very
asymmetric, such that one state occurs very frequently. In the limiting case, where only a
single state is sent, with unit probability, the game can be won (trivially) with certainty,
irrespective of the measurement we use. Thus, the optimisation problem (4.31) can be
maximised by picking games of this type.
To overcome the above problem, we instead consider the advantage that is offered by a
measurement in a particular game, compared to what can be achieved with no
measurement. Said differently, we can consider normalising Pguess by P (no meas)
guess
, namely
maximise
∑i q(i) tr(Miρi)
maxjq(j)
subject to
q(i) ⩾0
i = 1, … , o,
∑
i
q(i) = 1,

(4.33
b)
(4.33
c)
(4.34
a)
(4.34
b)
(4.35
)
(4.36
)
(4.37
)
ρi ≽0,
tr(ρi) = 1
i = 1, … , o.
This problem has a non-linear objective function, and as such is not directly an
SDP. However, as we will now see, an SDP can nevertheless be found which has exactly
the same optimal value as (4.33), which can be understood as being equivalent to it. In
particular, consider the following SDP
maximise
∑
i
tr(Miωi)
subject to
ωi ≽0,
tr(ωi) ⩽1
i = 1, … , o.
A priori this SDP is unrelated to the previous optimisation problem (4.33). However,
to see why they are related, let us first consider that we have found a set of optimal
variables E* = {q*(i), ρ
*
i } for the original optimisation problem, and let us consider
defining a set of potential variables for the SDP (4.34) via
ωi =
q*(i)ρ
*
i
maxjq*(j) .
In order to be feasible for the original problem (4.33), q*(i) ⩾0 and ρ
*
i ≽0, and so
we see that ωi ≽0, as required by the first constraint in (4.34b). Moreover, we also see
that
tr(ωi) =
q*(i)
maxjq*(j) ⩽1,
and so the second constraint in (4.34b) is also satisfied. Thus, ωi is a feasible variable
for the SDP (4.34) for all i = 1, … , o. Denoting the optimal value of the original problem
(4.33) by α* and the optimal value of the SDP (4.34) by ˜α*, we therefore see that the latter
places an upper bound on the original problem, since
α* = ∑i q*(i) tr(Miρ
*
i )
maxjq*(j)
= ∑
i
tr(Miωi) ⩽˜α*,
where the first equality is by definition of being optimal for the original (4.33), the
second equality follows from the definition of ωi in (4.35), and the inequality follows since
we have no guarantee that this particular choice of ωi is optimal for the SDP (4.34), and so
the value of the objective function only lower bounds the optimal value ˜α*.
We now consider going in the other direction, and assume that an optimal set of
variables {ω
*
i } for the SDP (4.34) has been found, and define a set of potential variables
for the original problem (4.33) via3

(4.38
)
(4.39
)
(4.40
)
q(i) =
tr(ω
*
i )
∑j tr(ω*
j)
,
ρi =
ω
*
i
tr(ω*
i )
.
Since ωi ≽0 in order to be feasible for the SDP (4.34), it follows that q(i) ⩾0, and
by construction ∑i q(i) = 1, so this is a valid set of probabilities, and is feasible for the
original problem (4.33). Similarly, ρi ≽0, and by construction tr(ρi) = 1, so this is also
a valid set of states, that is feasible for the original problem (4.33). Altogether, this defines
a feasible ensemble E. The advantage that M provides for the associated discrimination
game is
∑i q(i)(Miρi)
maxjq(j)
= ∑i tr(Miω
*
i )
maxj tr(ω*
j)
⩾∑
i
tr(Miω
*
i ) = ˜α*,
where the first equality is obtained by substituting (4.38) and simplifying, the middle
inequality follows since maxj tr(ω
*
j) ⩽1 in order to be feasible for the SDP (4.34), and
the second equality is by definition of the optimal value of the SDP. Since this ensemble
need not be the optimal ensemble for the original problem (4.33), we see that α* ⩾˜α*.
Crucially, since it was previously also shown in (4.37) that α* ⩽˜α*, we have inequalities
in both directions, and hence we arrive at the important conclusion that
α* = ˜α*,
that is, the two problems have the same optimal value. This is very important, as it
shows that the advantage that is offered by a measurement in quantum state discrimination,
which is naturally a non-linear quantity, can in fact be solved by SDP, once it is realised
that there is an associated SDP. Moreover, when this SDP is solved, not only is the optimal
value of the original problem recovered, but via (4.38) so too are the associated optimal
variables. We therefore obtain all of the information about the solution.
At this stage, you might be wondering how we arrived at the realisation that such an
equivalent SDP existed? It appears to have sprung out of thin air. Will this hold more
generally, or was it a genuine piece of magic? Although in general such an associated SDP
may not in general exist, or it may be difficult to find even if it does, there are three key
steps that were taken here—in the background—that led to this realisation. It will be
instructive to go over these three steps, which we do in the next section.
Before doing so, however, we will conclude with the realisation that the SDP (4.34) can
be solved rather readily, allowing us to obtain an analytical expression for the advantage
provided by a given measurement. We can start by noticing that the SDP decouples. That
is, each of the variables ωi, for fixed i, is independent of the others, satisfying its own pair
of constraints. At the same time, the objective function is also a linear combination of

(4.43
)
(4.41
a)
(4.41
b)
(4.42
)
objective functions for each variable. The optimal value is therefore the sum of the optimal
values α
*
i  for the problems
maximise
tr(Miωi)
subject to
ωi ≽0,
tr(ωi) ⩽1
i = 1, … , o.
Comparing to (2.1), it is evident that this is almost exactly the same SDP seen
previously for evaluating the maximum eigenvalue of a Hermitian operator. The only
difference is that previously we had the equality constraint tr(ωi) = 1, rather than the
inequality constraint tr(ωi) ⩽1. It can however be shown that without loss of generality
the constraint tr(ωi) ⩽1 will always be saturated by an optimal variable. Hence we can
replace it by the equality constraint. This is shown in exercise 4.10.
This shows that (4.41) evaluates to the maximum eigenvalue of Mi. However, since 
Mi ≽0, we furthermore know that the maximum eigenvalue coincides with the operator
norm, λmax(Mi) =∥Mi ∥∞. Hence, we can see that the advantage provided by a
measurement in quantum state discrimination is
max
E={q(i),ρi}
∑i q(i) tr(Miρi)
maxjq(j)
= ∑
a
∥Ma ∥∞.
This is a non-trivial function of the measurement M. In exercise 4.9, we show that the
most and least informative measurements can be identified using this form, and that the
former correspond to measurements with rank-1 elements, while the latter have elements
proportional to the identity operator.
Exercises
4.9 In this exercise we will use the form (4.42) to identify the most and least
informative measurements.
(a) Consider a measurement M acting on d-dimensional quantum states
with o ⩾d outcomes. Denote the spectral decomposition of each
measurement operator by
Ma = ∑
i
λ(a)
i Π(a)
i ,
where λ(a)
i
⩾0, we order the eigenvalues in decreasing order, and
where Π(a)
i  are rank-1 projectors. Show that the advantage offered by a
measurement M is upper bounded, α* ⩽d. Hint: You may want to consider
taking the trace of the normalisation condition ∑a Ma = I.

(4.44
)
(b) Consider measurements M acting on d-dimensional quantum states
with o ⩾d outcomes, for which its measurement elements are of the form 
Ma = γaΠa, where γa > 0 is a positive constant and Πa is a rank-1
projector. Show that in this case α* = d.
(c) Conversely, using your analysis from part (a) or otherwise, show that if
a measurement M has even a single measurement operator with two or
more non-zero eigenvalues, then α* < d.
(d) Show that ∥Ma ∥∞ is minimised when all of the eigenvalues of Ma
are equal to each other. Use this to show that the least informative
measurements, which provide no advantage in any state discrimination
task, have measurement operators of the form Ma = q(a)I, where q(a) is a
probability distribution.
4.10 In this exercise we will show that without loss of generality tr(ω
*
i ) = 1 in
(4.41).
(a) Assume that we have found ω
*
i ≽0 such that tr(ω
*
i ) = δ < 1 that we
believe to be optimal. Consider now adding onto ω
*
i  another operator 
ζi ≽0, such that tr(ω
*
i + ζi) = 1, i.e. any positive semidefinite operator
such that tr(ζi) = 1 −δ > 0. Show that the new variable ωi′= ω*
i + ζi is
feasible for (4.41) and saturates the second constraint.
(b) Show that the new variable achieves the value
α = tr(Miω
*
i ) + tr(Miζi) ⩾α*.
This shows that ωi′ is never a worse variable than ω*
i ; it can only
increase the value of the objective function, not decrease it.
(c) Consider now any ζi which is not orthogonal to Mi, i.e. such that 
tr(Miζi) > 0. Show that this must increase the value of the objective
function.
(d) Explain why this is in contradiction with the assumption that ω*
i  was
optimal and hence why the optimal variables must saturate the inequality 
tr(ωi) ⩽1.
4.3.1 Transforming the non-linear problem into a linear one
In this section we will now describe the main ideas that allowed us to arrive at the SDP
(4.34). We will start by analysing the objective function of the original problem, (4.33)
which is non-linear in two distinct ways. First of all it has a fractional form, involving the
division of one function by another. Second, from the perspective of this fractional form,
both the numerator and denominator are non-linear functions themselves. In order to arrive

(4.45
)
(4.46
)
(4.47
a)
(4.47
b)
(4.47
c)
(4.47
d)
at a problem with a linear objective function—as is needed for SDPs—we therefore need to
understand how to overcome these different contributions to the non-linearity of the
objective function.
We will start by realising that the numerator can be made linear by combining the
variables together, and defining
σi = q(i)ρi.
This can be viewed as a collection of sub-normalised states, just as we previously saw
when studying unambiguous quantum state discrimination in section 4.2.4. This may
appear as a trick, but in fact it is deeper than that. The reason why is because we can map
back-and-forth, in a one-to-one fashion, between ensembles E = {q(i), ρi} and sets of sub-
normalised states ˜E = {σi}, via q(i) = tr(σi), ρi = σi/q(i), as shown in exercise 4.12.
This set of sub-normalised states form the natural variables of the problem, and in these
natural variables, the numerator is linear. It turns out that in any problem involving
ensembles, it is always possible to linearise this aspect of the problem, by specifying the
ensemble in terms of sub-normalised states.
Moving on to the denominator, this is non-linear in a less trivial way. We can however
linearise it by introducing an additional variable r, subject to the constraints
q(i) ⩽r
i = 1, … , o.
This ensures that maxiq(i) ⩽r. Indeed, one way to view this is that 
maxiq(i) =∥→q ∥∞⩽r, i.e. the ℓ∞ norm of the vector →q with elements qi = q(i) is
bounded by r.4 What we have done is to make use of the same idea for converting the ℓ∞
norm into an LP, as done in (1.7). We can therefore consider the problem
maximise
∑i tr(Miσi)
r
subject to
σi ≽0
i = 1, … , o,
∑
i
tr(σi) = 1,
tr(σi) ⩽r
i = 1, … , o.
Similar to previously, it can be shown that the optimal value of this problem is equal
to the optimal value of the original problem (4.33), by carefully using the optimal variables
for each problem to define variables for the other, and showing that this leads to both upper
and lower bounds. This is carried out explicitly in exercise 4.13.
The form (4.47) is still a non-linear optimisation problem, however we have reduced
the non-linearity to only the fractional form. Both the numerator and the denominator are
now linear functions of the variables of the problem. It happens that such linear-fractional

(4.48
)
(4.49
)
optimisation problems can always be re-cast as semidefinite programs, using a standard
technique. In exercise 4.14, we consider the general instance of this problem, and show that
it can always be re-cast as an explicit SDP, which in our case, leads directly to (4.34).
Exercises
4.11 In this exercise we will find the optimal ensemble for (4.31), and show that
it has a trivial form—involving only a single state.
(a) Consider a partial optimisation over only the variables ρi. Show that
P
*
guess = maximise
∑
i
q(i) ∥Mi ∥∞
with associated optimal variables ρ
*
i  being rank-1 projectors onto
eigenvectors of Mi with maximum eigenvalue.
(b) Now optimise over q(i) to show that
P
*
guess = maxi ∥Mi ∥∞,
with associated optimal variable q(i) equal to 1 for any single j such
that ∥Mj ∥∞= maxi ∥Mi ∥∞, and all other q(i) = 0.
(c) Consider now the case that for all a, ∥Ma ∥∞< 1. Explain in this case,
using the structure of the discrimination game, why there is a better
guessing strategy than using the measurement M.
This shows that we should consider a more general guessing strategy in
order to analyse this game properly, whereby we don’t force ourselves to
use theoutcome of the measurement as the guess directly, but consider also
more general ways of producing guesses from the measurement result.
Since we are ultimately not really interested in this (trivial) problem, we
will not delve into the details of this further, but note that this is another
way to see why this is not an interesting problem to consider.
4.12 Consider an ensemble of quantum states, E = {q(i), ρi} and an associated
collection of sub-normalised states ˜E = {σi}, where σi = q(i)ρi. Show that
these are two equivalent specifications of the same ensemble. More precisely,
show that there is a unique mapping back from ˜E to E, which maps each sub-
normalised state σi into the pair (q(i), ρi).
4.13 In this exercise we will show that the optimal value of (4.47) is equal to the
optimal value of (4.33), in a similar fashion to the presentation in the main text.

(4.50
)
(4.51
)
(4.52
a)
(4.52
b)
(4.52
c)
(4.52
d)
(4.53
a)
(4.53
b)
(4.53
c)
(a) Consider an optimal ensemble for (4.33), E * = {q*(i), ρ
*
i }. Defining
variables σi and r for (4.47) via
σi = q*(i)ρ
*
i ,
r = max
j
q*(j),
show that these variables are feasible, and hence that the optimal
value α* of (4.33) provides a lower bound on the optimal value ˆα* of
(4.47), α* ⩽ˆα*.
(b) Now consider an optimal set of variables for (4.47), {σ
*
i } and r*.
Defining variables for (4.33) via
q(i) = tr(σ
*
i ),
ρi =
σ
*
i
tr(σ*
i )
,
show that these variables are feasible, and hence that the optimal
value ˆα* of (4.47) provides a lower bound on the optimal value α* of
(4.33), ˆα* ⩽α*. Together (a) and (b) show that α* = ˆα*, and so the two
optimisation problems (4.33) and (4.47) are equivalent, and both evaluate
to the optimal advantage provided by 𝕄 in a quantum state discrimination
task.
4.14 Consider a general type of linear-fractional optimisation problem
maximise
tr(AX) + a
tr(DX) + d
subject to
Φi(X) = B i
i = 1, … , m,
Γj(X) ≼Cj
j = 1 … , n,
X ≽0,
which has an identical set of constraints (and therefore feasible set) as the
general SDP from (2.1), however the objective function is the fraction of two
linear functions. To this problem we associate the following SDP
maximise
tr(AS) + at
subject to
Φi(S) = Bit
i = 1, … , m,
Γj(S) ≼Cjt
j = 1 … , n,
S ≽0,
t ⩾0,

(4.54
)
(4.55
)
(4.56
)
(4.57
)
(4.53
d)
(4.53
e)
tr(DS) + dt = 1.
We will show in this exercise that the optimal value of these two
problems coincide, and hence (4.53) can be viewed as the SDP formulation of
the original non-linear optimisation problem (4.52).
(a) Consider an optimal variable X * for the original problem (4.52), and
potential variables for the SDP (4.53)
S =
X *
tr(DX *) + d ,
t =
1
tr(DX *) + d .
Show that these variables are feasible for the SDP (4.53) and hence
that the optimal value α* of the original problem (4.52) is a lower bound on
the optimal value ˜α* of the SDP (4.53), α* ⩽˜α*.
(b) Conversely, consider now an optimal set of variables S * and t* for the
SDP (4.53) and assume first that t* > 0. Defining a potential variable X
for the original problem (4.52) via
X = S *
t* ,
show that this is feasible and hence that ˜α* ⩽α*, i.e. that the optimal
value of the SDP (4.53) lower bounds the optimal value of the original
problem (4.52).
(c) We will now consider the edge case, not covered in part (b), that 
t* = 0. Let us pick a feasible variable for the original problem (4.52), and
denote it X0. Show that the potential variable
X = X0 + vS *
is feasible for the SDP (4.53) whenever 
. Furthermore, show
that in the limit 
, the objective function of the original problem
(4.52) becomes
lim
v→∞
tr[A(X0 + vS *)] + a
tr[D(X0 + vS *)] + d = ˜α*.
This shows that, even if t*= 0, we can nevertheless find a feasible
variable for the original problem (4.52) which achieves a value as close to
the optimal value ᾶ* of the SDP (4.53), as desired. Together with part (b),
this shows that the SDP (4.53) is an equivalent problem to the original

(4.58
a)
(4.58
b)
(4.59
a)
(4.59
b)
(4.59
c)
problem (4.52), allowing us to recover both the optimal value (potentially
as a limit), and the optimal variables.
4.3.2 Generalised robustness of measurement informativeness
In the previous section it was seen that when considering a fixed measurement, it is
possible to quantify the advantage that it provides in any quantum state discrimination
game via solving the SDP (4.34). This was so because it was shown that the SDP is
equivalent to (4.33), the original form of the problem. We will now show that duality
provides further insight into this task, and that the advantage offered by a measurement is
captured by a geometrical quantifier known as the generalised robustness of measurement
informativeness.
Our starting point, as before, is to write down the Lagrangian associated to the primal
SDP, in this case as given in (4.34). It is
L = ∑
i
tr(Miωi) + ∑
i
tr(Yiωi) + ∑
i
zi[1 −tr(ωi)]
= ∑
i
tr[ωi(Mi + Yi −ziI)] + ∑
i
zi,
where we have introduced two sets of dual variables, {Yi} and {zi}, associated with
the left-hand and right-hand constraints in (4.34b) respectively. The Lagrangian upper
bounds the primal objective value for all feasible {ωi} if Yi ≽0 and zi ⩾0 for 
i = 1, … o, and becomes independent of the primal variables when Mi + Yi −ziI = 0.
This leads us directly to the dual SDP
minimise
∑
i
zi
subject to
Mi + Yi = ziI
i = 1, … , o
Yi ≽0,
zi ⩾0
i = 1, … , o.
In exercise 4.15 we show that both the primal (4.34) and dual (4.59) are strictly
feasible, and hence strong duality holds. The dual SDP (4.59) thus also evaluates to the
advantage provided by the measurement M. Interestingly, we can interpret the dual in a
geometrical way, by carefully analysing the nature of the dual variables.
First of all, since Ya is added to Ma,5 we might naturally be led to wonder if it can be
viewed itself as a measurement. Since each Ya is positive semidefinite, they satisfy the first
requirement to be interpreted as measurement operators. Considering their normalisation,
we see, by summing (4.59b) over a, that

(4.60
a)
(4.60
b)
(4.61
)
(4.62
)
(4.63
a)
(4.63
b)
(4.63
c)
(4.63
d)
(4.63
e)
∑
a
Ma + ∑
a
Ya = ∑
a
zaI
⇒∑
a
Ya = (∑
a
za −1)I.
Although the Ya are not themselves normalised, since their sum is proportional to the
identity operator, we can nevertheless extract a normalised measurement from them. In
particular, by defining
r = ∑
a
za −1,
Na = 1
r Ya,
then N = {Na} forms a valid measurement. Note that from (4.60b) we see that r ⩾0,
since the sum of a collection of positive semidefinite operators is always positive
semidefinite, and it would therefore be a contradiction if the right-hand side, equal to rI,
were not positive semidefinite, which is the case whenever r < 0.
In a similar fashion, we can also extract a normalised probability distribution from the
dual variables za. In particular,
p(a) =
za
1 + r ,
is readily seen to form a normalised set of probabilities. We can therefore re-express
(4.59) in terms of the variables Na, p(a) and r as
minimise
1 + r
subject to
Ma + rNa
1 + r
= p(a)I
a = 1, … , o,
Na ≽0,
∑
a
Na = I,
p(a) ⩾0,
∑
a
p(a) = 1,
r ⩾0.
In fact, we have not quite shown this reformulation is equivalent, only that it provides
a lower bound—since it could be the case that we have actually relaxed the problem by
optimising over all measurements N and probabilities p(a). However, in exercise 4.16 it is
shown that the two problems are indeed equivalent. In this new form the problem (4.59) is
now expressed in a non-linear form (since the variables appear multiplied together in the
constraint (4.63b)). The benefit of re-expressing it this way is because this form allows us

(4.64
)
(4.65
)
(4.66
)
to see the geometrical nature of the problem, and this geometrical nature arises in many
contexts. This type of optimisation is known as a generalised robustness.
In (4.63) we will interpret the measurement N = {Na} as a type of generalised noise
that is added to our measurement of interest, M = {Ma}. We imagine that instead of
performing the measurement M all of the time, with probability r/(1 + r) the
measurement N is instead performed, which is thought of as degrading our measurement6.
Why is this viewed as a degradation? We can similarly interpret the right-hand side of
(4.63b) as constituting a trivial or useless measurement, T = {Ta} = {p(a)I}. This
measurement is trivial as for all quantum states it leads to the same measurement outcomes,
tr(Taρ) = p(a)
independent of ρ
Such a measurement doesn’t actually need to be performed at all; a classical random
variable distributed according to p(a) can be announced as the measurement outcome,
rather than performing the measurement. We therefore see why the measurement N is
considered as noise: this noise is mixed with the measurement M until the measurement
becomes completely useless or trivial.
We therefore see that the optimisation (4.63) seeks to find the worst-case noise N, such
that when this noise is mixed with the smallest probability r/(1 + r), the resulting
measurement becomes useless. Said the other way, having solved the problem (4.63), we
are guaranteed that if the probability of mixing in noise is smaller than r*/(1 + r*), then
definitely the measurement hasn’t become trivial yet.
All of this can be most easily conveyed using a diagram. As depicted in figure 4.1, we
can represent the space of all possible measurements M (of a fixed dimension and with a
fixed number of outcomes)
M = {M ∣Ma ≽0, a = 1, … , o, ∑
a
Ma = I},
which is a convex set. The measurement of interest M is a point in this space. The set
of all trivial measurements,
Mtriv = {M ∣Ma = p(a)I, p(a) ⩾0, ∑
a
p(a) = 1}
forms a convex subset of M, which is of lower dimension. Picking a noise
measurement N, the line segment between this measurement and M can be drawn. We can
see that only those N such that this line segment intersects the set of trivial measurements 
Mtriv should be considered. We can denote the two lengths—between M and the point of
intersection, and between N and the point of intersection—by ℓ and L respectively. In terms
of these lengths we have

(4.67
)
r = ℓ
L
that is, geometrically, r has the interpretation of being the relative distance of M from
being a trivial measurement, compared to the distance of the noise N from being trivial.
The optimisation (4.63) therefore seeks to minimise this ratio—i.e. to find a noise
measurement N that is the furthest from being trivial compared to M. One particularly nice
aspect about this geometrical understanding is that if we fix a direction, we fix ℓ. We can
therefore always find a better r by making L larger—that is, by moving N further away, in
the same direction. This will always be possible until the boundary of the set is reached,
meaning that the optimal noise measurement N* will always be an extremal measurement.
As we will see below, this can be viewed as a geometrical manifestation of complementary
slackness, which provides a number of key insights into the structure of the optimal
ensemble E * = {q*(i), ρ
*
i } and optimal noise measurement N* = {N
*
a }.
Figure 4.1. 
Geometric 
interpretation 
of 
generalised 
robustness. 
Simple
representation of the space of measurements M. The subset of trivial measurements,
which is lower dimensional, is represented here as a line segment. The noise
measurement N sits on the other side of the trivial set compared to M, and the line
joining them intersects this set at a trivial measurement T. The generalised robustness
is the ratio of the distance ℓ between M and T and the distance L between N and T.
4.3.3 Structure of the optimal ensemble and noise measurement

(4.68
)
(4.69
)
(4.70
)
(4.71
)
We will now see that a significant amount can be learnt about the structure of the optimal
ensemble and noise measurement, using the complementary slackness conditions, in
conjunction with the other facts already learnt to date.
From the Lagrangian (4.58), we can readily write down the complementary slackness
conditions for our discrimination problem. Namely, the optimal primal and dual variables
satisfy
Y
*
i ω
*
i = 0,
z
*
i [1 −tr(ω
*
i )] = 0,
i = 1, … , o
We already showed previously that tr(ω
*
i ) = 1 without loss of generality. In exercise
4.17 below, it will also be shown that z
*
i > 0 for all i, hence from the second
complementary slackness condition in (4.68), a second, independent way of arriving at the
same conclusion is obtained. In (4.38) we saw how to use ω*
i  in order to generate an
ensemble, which is moreover an optimal ensemble. Since we now know that tr(ω
*
i ) = 1, it
follows that
q*(i) = 1
o ,
ρ
*
i = ω
*
i ,
which shows that the optimal ensemble sends the states ρ
*
i  uniformly at random with
probability 1/o. We also saw in (4.61) how to use Y
*
a  in order to generate an optimal noise
measurement, N
*
a = Y
*
a /r*. Together, this allows us to re-express the first complementary
slackness condition in (4.68) as
N
*
i ρ
*
i = 0
i = 1, … , o.
To see what this is means, consider playing the quantum state discrimination game for
the ensemble E * = {q*(i), ρ
*
i } with the measurement N* = {N
*
a }. The average success
probability is
Pguess = ∑
i
q*(i) tr(N
*
i ρ
*
i ) = 0.
That is, this is the worst possible measurement that could be used, which fails to
correctly identify the state ever! Mathematically, (4.70) shows that N
*
a  has at least one zero
eigenvalue, and is therefore an extremal measurement, as we saw above geometrically.
Finally, we can also see that if none of the measurement operators Ma are trivial—in
the sense of being proportional to the identity—then the optimal ensemble cannot contain
full-rank states. Indeed, from (4.70), if ρ
*
i  were full rank, then it would immediately imply
that N
*
i = 0. This in turn would mean that no noise is added to Mi in order for it to

(4.72
a)
(4.72
b)
(4.72
c)
become trivial. However, by assumption this was not the case, and so we can infer, since 
N
*
i ≠0, then ρ* is not full rank.
Exercises
4.15 Show that both the primal SDP (4.34) and dual SDP (4.59) are strictly
feasible, and hence that strong duality holds.
4.16 In this exercise we will show that the two problems (4.59) and (4.63) are
equivalent.
(a) Assume an optimal set of variables for (4.59). Show that, through the
definitions (4.61) and (4.62), that the optimal value of (4.59) upper bounds
the optimal value of (4.63).
(b) Assume now an optimal set of variables for (4.63). Using these to
define a feasible set of variables for (4.59), show that the optimal value of
(4.63) upper bounds the optimal value to (4.59).
This shows that the two problems have the same optimal value, and are
therefore equivalent.
4.17 In this exercise we show that, just as the primal SDP (4.34) could be solved
analytically, so too can the dual SDP (4.59).
(a) Show that in (4.59) Ya are slack variables and that the an equivalent
form of the dual is
minimise
∑
i
zi
subject to
ziI ≽Mi
i = 1, … , o,
zi ⩾0,
i = 1, … o.
(b) Assume that the constraint za ⩾0 is saturated for some a, i.e. that 
z*
a = 0. Explain why this implies that the corresponding Ma = 0. Since, by
the nature of the problem, Ma ≠ 0 , this shows that za > 0 without loss of
generality.
(c) Given part (b), use the dual formulation of the maximum eigenvalue
SDP from (2.28) to analytically solve (4.72), and confirm that it agrees
with the analytic solution to the primal problem from (4.42).
(d) Starting from the Lagrangian (4.58), write down the complementary
slackness conditions for this problem.
(e) Use complementary slackness, and part (b) to provide an alternative
proof that tr(ω
*
i ) = 1.

4.4 Concluding remarks
In this chapter we considered problems involving quantum measurements. As we have
seen, optimising over quantum measurements also fits perfectly inside the SDP framework,
since they are defined by semidefinite constraints. We have also studied the problem of
quantum state discrimination from two alternative points of view, and seen numerous
applications of semidefinite programming in this context. The main ideas that we hope you
learnt in this chapter are:
Measurement estimation. Similarly to quantum state estimation, the problem of
estimating which measurement is being performed given a set of observed outcomes
can be cast as an SDP. Moreover, we can consider the case of finite statistics, and
quantify how far from being feasible a set of measurement data is—equation (4.3).
Minimum-error quantum state discrimination. The guessing probability of
minimum-error quantum state discrimination can be cast as an SDP, allowing for the
optimal measurements for this task to be found—(4.9).
Operational interpretation of the trace distance. The trace distance quantifies how
well two states can be distinguished in symmetric and binary minimum-error binary
quantum state discrimination—see (4.13).
Optimality of measurements. Complementary slackness allows us to find necessary
and sufficient conditions for the optimality of measurements for minimum-error
quantum state discrimination—(4.16).
Unambiguous state discrimination. We can determine the set of measurements that
minimise the probability of failure in unambiguous quantum state discrimination
using SDPs—(4.29).
Linear-fractional optimisation problems. We have seen how to transform an
optimisation problem were the objective function involves the division of two linear
functions into an SDP—see exercise 4.14.
4.5 Further reading
Bae J and Kwek L-C 2015 Quantum state discrimination and its applications J. Phys.
A: Math. Theor. 48 083001
4.6 Advanced topics
4.6.1 Unambiguous quantum state discrimination revisited
In this section we will return to unambiguous state discrimination. We will begin by
analysing more carefully when unambiguous state discrimination is impossible. We will
then use this insight to see how we can interpret the dual formulation in terms of
approximate linear dependence.
Suppose that the ensemble of states—viewed as a collection of sub-normalised states—
is linearly dependent, meaning that it is possible to find a set of real numbers μi for 

(4.73
)
(4.74
)
(4.75
a)
(4.75
b)
(4.75
c)
i = 1, … , m such that
∑
i
μiq(i)ρi = 0.
The advantage of using again sub-normalised states, similar to the reasoning for
imposing (4.28), is that it ensures that we only consider states that occur with non-zero
probability, which will be advantageous below.
After multiplying (4.73) by Ma, for some fixed value of a, and taking the trace, we see,
given that the measurement satisfies q(i) tr(Maρi) = 0 for all values of i ≠a, that all but
the term i = a vanishes, and therefore we have
q(a)μa tr(Maρa) = 0.
Therefore 
as 
long 
as 
μa ≠0, 
it 
must 
be 
the 
case 
that 
p(a, i = a) = q(a) tr(Maρa) = 0. That is, the measurement can never unambiguously
identify the state ρa. In such a case, the ‘failure outcome’ a = ∅ is returned all of the time,
indicating that we are never certain which state has been sent.
When will we have that none of the μi vanish? This will occur when the set of sub-
normalised states {q(i)ρi} is linearly dependent as a whole, but no subset is linearly
dependent (i.e. all subsets are linearly independent).
We will now see why this insight into when unambiguous state discrimination is
impossible is useful, and can be extended to understand how well unambiguous state
discrimination can be performed in general. In particular, by considering the dual
formulation of (4.29), we will see in what follows that the average probability of success in
unambiguous quantum state discrimination can be lower bounded by quantifying how far
the set of sub-normalised states is from being linearly dependent.
In exercise 4.18, it is shown that the dual formulation of (4.29) is
P
*
guess = minimise
tr(Z)
subject to
Z ≽q(a)ρa + ∑
i≠a
μaiq(i)ρi
a = 1, … , m,
Z ≽0.
This SDP has a structure that is somewhat familiar. In particular, there is some
similarity to the SDP for the trace norm, given in (2.8), except the right-hand side of
(4.75b) contains the dual variables μai. This suggests that one way to proceed is via partial
optimisation—to consider first that the dual variables μai are fixed—and analysing the
structure of the dual problem only from the perspective of the dual variable Z, before
returning to the problem of optimising the remaining variables. This leads us to consider
the following SDP,

(4.76
a)
(4.76
b)
(4.76
c)
(4.77
a)
(4.77
b)
(4.78
)
minimise
tr(Z)
subject to
Z ≽X,
Z ≽0,
which we arrive at by considering only a single constraint from (4.75b), and treating
the right-hand side as (fixed) data X. In exercise 4.19, we show that this SDP evaluates
exactly to ∥X (+) ∥1, the trace norm of the positive part of the operator X.
How can we use this to understand (4.75)? First of all, there is not a single operator X,
but one for each value of a, and these are not data, but rather variables, so we will define 
Xa = q(a)ρa + ∑i≠a μaiq(i)ρi, which are the operators appearing on the right-hand side
of (4.75b). Second, if there was only a single Xa, then the above shows that (4.75) would
evaluate to ∥Xa(+)∥1. The fact there are multiple Xa, but only a single variable Z
appearing in all of the constraints (4.75b) is similar to what happens in the LP for the ℓ∞
norm (1.7)—where a scalar variable bounded every component of a vector. We see
immediately that tr(Z) definitely cannot be smaller than ∥Xa(+)∥1 for any value of a.
However, it may furthermore not even be possible to achieve any of these values, since
there will in general be overlap between the positive parts of the Xa(+) for different values
of a. We can nevertheless obtain the interesting lower bound on the guessing probability by
ignoring this fact,
P
*
guess ⩾minimise
maxa∥Xa(+)∥1
subject to
Xa = q(a)ρa + ∑
i≠a
μaiq(i)ρi
a = 1, … , m.
 
Let us now try to understand why this lower bound—which at first sight might look
less informative—is in fact a useful way of understanding the dual.
First of all, notice that if we take the uninteresting case—where the set of unnormalised
states {q(i)ρi} is linearly dependent, then each Xa can be made to vanish. In particular, we
can take
μai = μi
μa
where the μi are from (4.73). Direct substitution shows that this makes Xa vanish, in
which case ∥Xa(+)∥1 also vanishes for all a, and so P
*
guess = 0 from the dual (4.75), before
even getting to the lower bound.
Let us therefore now assume that we are in the case of interest—where the set of
unnormalised states is linearly independent. We may then imagine looking for a set of

numbers μi such that ∑i μiq(i)ρi is ‘smallest’. However, what exactly is meant by
smallest is a subtle question. The first difficulty encountered is that there is an ambiguity in
defining μi, since we can always consider a second choice μi′= γμi, for some choice of γ,
and this should not change our notion of ‘smallness’. That is, to start with we need to fix a
type of normalisation or scale for the μi.
With this in mind, we can now see that each Xa in (4.77b) can be viewed as making a
specific choice for the normalisation of a set of μi. In particular, Xa fixes μa = 1, and sets 
μi = μai for i ≠a. This is a somewhat natural normalisation condition, which can be seen
to fix an overall scale for the μi. There is no good reason to single out a specific μa to set
to be equal to one—since all are equivalent as far as the problem is concerned. We will see
shortly how this is dealt with.
Let us first assume that we have fixed a normalisation convention—μa = 1 for some
specific choice of a. We can choose to measure how far the resulting operator Xa is from
vanishing using ∥Xa(+) ∥1, i.e. by the trace norm of its positive part. Each choice for a in
principle could lead to a different number however. One natural choice is to consider the
worst case, i.e. the largest distance, as a figure of merit.
Mathematically, this is precisely maxa ∥Xa(+) ∥1, which we now understand can be
viewed as quantifying how far the set of unnormalised states q(i)ρi is from being linearly
dependent, irrespective of which μi is fixed to be one. By optimising over all choices of 
μai, we seek to find the best set of coefficients which make the combination approximately
vanish.
The lower bound optimisation problem (4.77) can thus be interpreted as calculating the
distance of the set of unnormalised states {q(i)ρi} from being linearly independent. We see
therefore that how close a set of states is to being linearly independent in a crucial property
which bounds how well the set can be unambiguously discriminated.
Exercises
4.18 In this question we will derive the dual SDP formulation of unambiguous
state discrimination, as given in (4.75).
(a) Write down the Lagrangian associated to the primal SDP (4.29).
(b) Identify the constraints satisfied by the dual variables: (i) in order for
the Lagrangian to upper bound the primal value; (ii) in order for the
Lagrangian to be independent of the primal variables.
(c) Show that part (b) leads to the dual SDP stated in (4.75).
4.19 In this question we will show that the SDP (4.76) evaluates to ∥A(+) ∥1.
(a) Show that Z = A(+) achieves the value ∥A(+) ∥1 for the SDP (4.76).
This shows that ∥A(+) ∥1 is an upper bound on the value of the SDP.
(b) Show that the dual SDP of (4.76) is

(4.79
a)
(4.79
b)
(4.79
c)
maximise
tr(AX)
subject to
X + Y = I,
X ≽0,
Y ≽0.
(c) Verify that strong duality holds for this primal-dual SDP pair.
(d) Pick a pair of dual variables X and Y  such that the value of the dual is 
∥A(+) ∥1. Since this a lower bound on the primal SDP, this guarantees.
that the SDP evaluates to ∥A(+) ∥1.
4.20 Show that if the set of states {ρi} is linearly dependent then the value of
the dual SDP in its original form, (4.75), is zero, i.e. find a feasible Z such that 
tr(Z) = 0.
1Note that in (4.1b) we have written ∀a, x as shorthand for a = 1, … , o; x = 1, … , N, to avoid unnecessary clutter. In
the rest of this book, whenever a set of conditions holds for more than one variable in a given line of an SDP, we will
always use this shorthand, with the range left implicit.
2If this is confusing, you can imagine that components are labelled by i, and that the ordering of the components runs
through all possibility probabilities, i.e. →p = (p(1 ∣1), p(2 ∣1), … , p(o ∣1), p(1 ∣2), … , p(o ∣N)). However, it is more
convenient, and natural, to simply label the components by the pair, and to leave this ordering as implicitly understood.
3Note that if ωi = 0 for some i, then we set ρi = 0, i.e. we do not encounter the problem of dividing by zero.
4Note that since →q ⩾0, we do not need to include here the lower bound −r ⩽q(i) that would otherwise be needed for the
ℓ∞ norm.
5Note that we switch index from i to a at this stage, as we tend to think of a as the outcome of the measurement, and i as
labelling a state from an ensemble. It is therefore nice to change the (dummy) label, to emphasise that the focus is now
back on the measurement.
6We warn the reader that the parameterisation (p, 1 −p), with 0 ⩽p ⩽1, can also be found instead of 
(1/(1 + r), r/(1 + r)) in the literature about this topic. Here we will stick to the later because this parameterisation
appears more directly from the duality theory.

IOP Publishing
Semidefinite Programming in Quantum Information Science
Paul Skrzypczyk and Daniel Cavalcanti

(5.1)
(5.2)
Chapter 5
Quantum entanglement
In this chapter we will turn our attention to quantum entanglement—one of the most important aspects of quantum
theory from the perspective of quantum information. As we will see, the techniques of semidefinite programming
play a wide ranging role in entanglement theory, starting from one of the simplest criteria for detecting
entanglement, known as the positive-partial-transpose criteria. This leads to a natural way to quantify
entanglement, through the so-called negativity. In general, the set of unentangled—or separable—states has a
complicated structure, which has no computationally easy characterisation. However, semidefinite programs
(SDPs) can be used to approximate the set of separable states, and allows for bounds to be obtained on many
quantities of interest.
We will also introduce a new and powerful idea in this chapter—that of a sequence or hierarchy of SDP
criteria, which in the limit converge to the set of separable states, known as k-symmetric extensions. The idea of a
hierarchy is a general technique, and this section aims to demonstrate how this powerful idea works.
5.1 Entanglement of pure and mixed states
A pure bipartite dA × dB quantum state ∣Ψ⟩AB is entangled if and only if it cannot be factorised, i.e. written as
a direct product state
∣Ψ⟩AB =∣ψ⟩A ∣ϕ⟩B,
where ∣ψ⟩A is an arbitrary pure state for system A, ∣ϕ⟩B is an arbitrary pure state for system B, and we have used
the notation ∣ψ⟩A ∣ϕ⟩B to denote the tensor product state ∣ψ⟩A⊗∣ϕ⟩B (this could also be denoted ∣ψ, ϕ⟩AB).
There is a straightforward way to check if such a decomposition exists: We can use two facts: (i) that the reduced
density operator of a bipartite pure state is mixed if and only if the state is entangled; (ii) only for pure density
operators ρ do we have tr(ρ2) = 1. Together, this shows that
∣Ψ⟩AB is entangled if and only if tr(ρ2
A) < 1,
where ρA = trB(∣Ψ⟩AB⟨Ψ ∣).
When we move onto mixed bipartite states, the situation becomes more intricate. A dA × dB quantum state 
ρAB is entangled if and only if it cannot be written as a convex combination of product states, namely
ρAB ≠∑
λ
p(λ)ρA
λ ⊗ρB
λ
where λ = 1, … , N, is a classical random variable taking on N values, with probabilities p(λ), and {ρA
λ } and 
{ρB
λ } are arbitrary sets of states for system A and B respectively, which need not be related in any way. Any state
which has a decomposition of the form (5.2) is said to be separable.
One of the most basic questions in the theory of entanglement is to determine whether a generic density
operator ρAB is entangled or not. Unlike in the special case of pure states, in general this is known to be a hard
problem, for which no efficient algorithm should exist, for reasons of computational complexity (in particular, the
entanglement problem has been shown to be an NP-hard problem). Intuitively, from (5.2), we see that to answer
the entanglement question requires searching over infinitely many decompositions of a state. Unlike for problems
previously encountered in this book, there is no known way around this complexity, and deciding if a quantum
state is entangled or not is not currently known to be an SDP. Nevertheless, as will be seen below, progress can still

(5.3)
(5.4)
(5.5)
(5.6)
(5.7)
be made on this important question. First, there is an exception to the above rule, when considering small
dimensions (to be more specific, if dA × dB = 4, 6). In this case, it is in fact possible to determine whether a state
is entangled or not using an SDP. Second, we will introduce an important idea: a hierarchy of feasibility
semidefinite programs which must all be satisfied if a state is separable. This hierarchy provides a sequence of
(outer) approximations to the set of separable states, which can be used in practice to obtain useful and interesting
bounds on entanglement.
5.2 The positive-partial-transpose criterion
Although it is computationally difficult to build a test for entanglement that works for quantum states of any
dimension, this does not rule out the possibility of finding a simple criterion that certifies the entanglement of
some, but not all, quantum states. That is, it is very useful to have sufficient criteria which guarantee that a state is
entangled.
The most famous such criterion is the positive-partial-transpose criterion. It is based on the partial transpose
linear map, which can be specified as
X TA
AB = Γ(TA)(XAB) = ∑
i,j
(∣j⟩⟨i ∣⊗I)XAB(∣j⟩⟨i ∣⊗I)
where we introduce the notation Γ(TA) to emphasise the connection with (2.1c), and to highlight that (as we will
discuss again later) this is a specific linear map that can be used as a constraint inside an SDP. We can see that the
partial transpose simply applies a transposition on the first Hilbert space, while leaving the second Hilbert space
untouched.
The positive-partial-transpose criterion says that a bipartite quantum state is necessarily entangled if
transposing only one part of it—referred to as a partial transpose—turns it into an operator that is not positive
semidefinite (and therefore no longer a quantum state). That is,
ρTA
AB ⋡0 ⇒ρAB ≠∑
λ
p(λ)ρA
λ ⊗ρB
λ .
This result can be proven easily by contradiction: if a density operator σAB is separable, then
σTA
AB = ∑
λ
p(λ)(ρA
λ )
T ⊗ρB
λ ≽0,
since (ρA
λ )
T ≽0 whenever ρA ≽0 (since transposition does not change the eigenvalues of a matrix). Thus, if 
ρTA
AB ⋡0 then ρAB must necessarily be entangled1.
The converse of the PPT criterion is not necessarily true: there exist quantum states which are entangled but
which also remain positive semidefinite after applying the partial transpose. Such states are called PPT entangled
states, standing for ‘positive-partial-transpose’. When states are not PPT, we refer to them as NPT entangled states
where NPT stands for ‘negative-partial-transpose’.
We can define the set of all PPT states,
SPPT = {πAB ∣πAB ≽0, tr(πAB) = 1, πTA
AB ≽0},
and as shown in exercise 5.2, this is a convex set of states. We can similarly define the set of separable states,
The fact that the PPT criterion does not detect all entangled states means that the set SPPT of PPT states strictly
contains the set Ssep of separable states, Ssep ⊂SPPT. We must note however, that there is in fact a set of PPT
Ssep = {σAB ∣σAB ≽0, tr(σAB) = 1, σAB = ∑
λ
p(λ)ρA
λ ⊗ρB
λ ,
ρA
λ ≽0, ρB
λ ≽0, tr(ρA
λ ) = 1, tr(ρB
λ ) = 1}.

(5.8)
(5.9)
(5.10
a)
(5.10
b)
(5.10
c)
states for each dimension of Alice’s and Bob’s system. When considering the smallest possible dimensions, when 
dA = dB = 2, dA = 2 and dB = 3 or dA = 3 and dB = 2, then it turns out that the PPT criterion is also a
sufficient criterion for a state to be separable, and in these dimensions Ssep = SPPT. In these situations, testing
whether a quantum state is PPT or not is equivalent of testing whether or not it is separable. This is however the
exception to the rule, and in general the two are not equivalent. We can see how the PPT criterion can be used in
practice, for the simplest class of entangled states:
Example 5.1 PPT criterion applied to two-qubit isotropic states.
In this simple example we will see how the PPT criterion can be used to detect the entanglement of two-
qubit isotropic states, mixed states of the form
ρAB(w) = w ∣Φ+⟩⟨Φ+ ∣+(1 −w) IA ⊗IB
4
,
with ∣Φ+⟩=
1
√2 (∣0⟩∣0⟩+ ∣1⟩∣1⟩) the maximally entangled state and 0 ⩽w ⩽1. Isotropic states are
entangled when w > 1
3  and separable otherwise.
A direct calculation shows that ∣Φ+⟩⟨Φ+ ∣TA= 1
2 S, where S is the ඌඐൺඉ unitary operator, 
S = ∑i,j ∣i⟩∣j⟩⟨j ∣⟨i ∣, such that S ∣ψ⟩∣χ⟩=∣χ⟩∣ψ⟩ for all states ∣ψ⟩ and ∣χ⟩. It then follows that
ρAB(w)TA = w
2 S + (1 −w) IA ⊗IB
4
.
ඌඐൺඉ has eigenvalues 1 (with multiplicity 3) and −1. The former eigenspace is spanned by the symmetric
states ∣0⟩∣0⟩, ∣1⟩∣1⟩ and ∣Ψ+⟩=
1
√2 (∣0⟩∣1⟩+ ∣1⟩∣0⟩), while the latter corresponds to the
antisymmetric maximally entangled state ∣Ψ−⟩=
1
√2 (∣0⟩∣1⟩−∣1⟩∣0⟩). The eigenvalues of ρAB(w)TA
are thus 1+w
4  (with multiplicity 3) and 1−3w
4
. In order for ρAB(w)TA to be PPT all eigenvalues must be
nonnegative, and hence 1−3w
4
⩾0, which is equivalent to w ⩽1
3 . Thus, when w > 1
3  the state is NPT
entangled. This thus demonstrates that the PPT criterion is able to detect all entangled two-qubit isotropic
states.
In exercise 5.1 you will show that this result generalises to isotropic states of arbitrary dimension.
We end this section by noting that the above can be used to express the problem of whether a given state ρAB is
an NPT entangled state as a feasibility SDP. Namely,
find X
subject to
X ≽0,
X = ρTA
AB.
This simple SDP forces the variable to be equal to the partial transpose of the input quantum state. Only if
this operator is positive semidefinite will the problem be feasible. In practice this SDP is too simple to be used—
one can simply find the eigenvalues of ρTA
AB directly, and determine whether they are nonnegative. It is nevertheless
important to realise that the problem is an instance of a feasibility SDP. In what follows, we will go further, and see
how to consider an optimisation form of this problem, which will allow us to quantify entanglement.
Exercises

(5.11
)
(5.12
)
(5.13
a)
(5.13
b)
(5.13
c)
5.1 In this exercise we will show that the PPT criterion is able to detect the entanglement of isotropic
states in any dimension. The family of d-dimensional isotropic states is given by
ρ(d)
AB(wd) = wd ∣Φ+
(d)⟩⟨Φ+
(d) ∣+(1 −w) IA ⊗IB
d2
,
where ∣Φ+
(d)⟩=
1
√d ∑i ∣i⟩∣i⟩ is the maximally entangled state of two qudits, and where 
0 ⩽wd
⩽1. d-dimensional isotropic states are entangled when wd >
1
d+1  and separable otherwise.
(a) Show that
∣Φ+
(d)⟩⟨Φ+
(d) ∣TA= 1
d S(d),
where S(d) = ∑i,j ∣i⟩∣j⟩⟨j ∣⟨i ∣ is the d-dimensional ඌඐൺඉ unitary operator.
(b) Using the fact that the eigenvalues of S(d) are 1 and −1 (with corresponding eigenspaces
spanned by symmetric and antisymmetric states, respectively), show that ρ(d)
AB(wd) is NPT
whenever it is entangled (i.e. for wd >
1
d+1 ).
This result is more interesting than Example 5.1. In that example, it was guaranteed that the PPT
criterion had to detect the entanglement of the state, since PPT and separable are equivalent for two-
qubit states.Here, in contrast, since the tates are qudits, it is not guaranteed that the PPT criterion
should detect all entangled states in the family. This results shows that it nevertheless does.
5.3 Entanglement negativity
The PPT criterion can be used to define a quantifier of entanglement, known as entanglement negativity. The basic
idea behind this quantity is that when a state is more entangled, then there is a sense in which its partial transpose
will be a more negative operator. As we will see, the negativity of a quantum state can be cast as a semidefinite
program. Moreover, through duality we will be able to show that all pure entangled states have a negative-partial
transpose.
One measure of ‘how negative’ an operator is the absolute value of the sum of all of its negative eigenvalues.
The larger this number, the ‘more negative’ the operator is. We can turn the evaluation of this quantity into an SDP
by recalling that a (Hermitian) operator A can be decomposed into a positive part A(+) and a negative part A(−),
A = A(+) −A(−),
where A(+) ≽0 and A(−) ≽0 (see exercise 2.7). In this form, all of the positive eigenvalues of A (and
corresponding eigenprojectors) are collected into A(+), while the (absolute value of the) negative eigenvalues (and
corresponding eigenprojectors) are collected into A(−). The utility of writing A in this form is that it provides us
with a convenient way to express the absolute value of the sum of the negative eigenvalues of A. Namely, we can
re-express this as the trace norm of the negative part, ∥A(−) ∥1, since this, by definition, is the sum of the
eigenvalues of A(−) (which are all positive), which are themselves nothing but the absolute values of the negative
eigenvalues of A.
As will be shown in exercise 5.3, ∥A(−) ∥1 can be cast as the following pair of primal and dual SDPs
minimise
tr(Y )
maximise
−tr(XA)
subject to A = Z −Y ,
subject to I ≽X,
Y ≽0,
Z ≽0.
X ≽0.
Using these, we can now directly define the negativity of a quantum state N (ρAB) to be the absolute value of
the sum of the negative eigenvalues of ρTA
AB, which can equally be thought of as the trace norm of the negative part

(5.14
a)
(5.14
b)
(5.14
c)
(5.15
a)
(5.15
b)
(5.15
c)
(5.16
)
(5.17
a)
(5.17
b)
(5.17
c)
(5.18
)
(5.19
)
(5.20
)
of ρTA
AB, and immediately write it as an SDP in primal form as
N (ρAB) = minimise
tr(Y )
subject to ρTA
AB = Z −Y ,
Y ≽0,
Z ≽0,
and in dual form as
N (ρAB) = maximise −tr(X TAρAB)
subject to I ≽X,
X ≽0,
where we have used the fact that the adjoint of the partial transpose is the partial transpose itself, i.e. that 
tr(F TAG) = tr(FGTA) for all F and G, in order to slightly re-express the dual objective function.
The dual has an important geometrical interpretation as optimising over quantitative entanglement witnesses,
or more precisely in this case, quantitative witnesses of NPT entanglement. To elucidate this, we will make a small
change of variable,
W = X TA,
in terms of which the dual is
N (ρAB) = maximise −tr(WρAB)
subject to
I ≽W TA,
W TA ≽0.
The operator W is known as an entanglement witness. In order to see why, we start from the constraint
(5.17c). This constraint implies that tr(WσAB) ⩾0 for all separable σAB, as can be verified directly, using the fact
that tr(FG) = tr(F TAGTA) for all F and G,
tr(WσAB) = tr(W TAσTA
AB) ⩾0,
where the inequality follows since W TA ≽0 from (5.17c), σTA
AB ≽0 as we saw in (5.5), and as we have
used many times, the trace of the product of positive semidefinite operators is never negative. What this shows is
that the only way in which tr(WρAB) can be negative is if ρAB is entangled. In other words tr(WρAB) ⩽0
witness the entanglement of ρAB. This is a direct application of the results presented in section 3.1.5, where the
dual formulation of an SDP was show to provide a certificate of infeasibility (in the present case, a certificate that
the state is not PPT).
The constraint (5.17b) can be understood as setting the normalisation of the entanglement witness. To see this,
we consider multiplying the constraint by an arbitrary separable quantum state σAB and taking the trace, leading to
tr(σAB) ⩾tr(W TAσAB).
We can then use the fact that tr(W TAσAB) = tr(WσTA
AB), and realise that σTA
AB = σ′
AB is a separable quantum
state (in general different from σAB). Finally, using the fact that σAB is normalised, we arrive at the inequality
1 ⩾tr(Wσ′
AB),
i.e. that the value that the witness takes on any separable state is bounded from above by unity. Altogether,
what this shows us is that the constraints in (5.17) enforce that the dual variable W must have a (Hilbert–Schmidt)

scalar product with any separable state lying in the interval 0 ⩽tr(WσAB) ⩽1. We thus arrive at the realisation
that the negativity can be interpreted as the violation of a quantitative entanglement witness, that is, by how much
the condition tr(WρAB) ⩾0 is violated. This is summarised graphically in figure 5.1. Although the normalisation 
0 ⩽tr(WσAB) ⩽1 is rather natural, it not the only choice that could be taken. Interestingly, varying the way in
which an entanglement witness is normalised leads to a number of other interesting entanglement quantifiers, as
we will see later.
Figure 5.1. Negativity as a quantitative entanglement witness. Geometrically, we can view an entanglement
witness W as specifying a direction in the space of quantum states; the witness is such that the set of all
separable states Ssep lies in the half-space tr(WσAB) ⩾0. Additionally, for the negativity, entanglement
witnesses are normalised such that Ssep lies in the strip such that 0 ⩽tr(WσAB) ⩽1. The value tr(WρAB)
of an entangled quantum state ρAB can be made negative by appropriately choosing the direction of W. The
negativity corresponds to (the negative of) this value, for the optimally chosen direction W.
It is also important to note that in the above, the entanglement witnesses are only able to detect entangled states
that have a negative-partial transpose. Any entangled state that has a positive-partial transpose will not be detected,
as must be the case by construction. Nevertheless, it is important to realise conceptually the structure of the
entanglement witnesses associated to negativity. In the following examples, we first calculate the negativity of
two-qubit isotropic states and then show how the dual formulation of the negativity SDP can be used to detect the
entanglement of all pure entangled states. That is, to prove that there are no pure PPT entangled quantum states.
Example 5.2 Negativity of two-qubit isotropic states.
In example 5.1 we saw how to use the PPT criterion to detect the entanglement of two-qubit isotropic states.
In this example, we will use this simple state to gain some understanding of the primal and dual formulations
of the negativity.
When w > 1
3 , in example 5.1 it was shown that ρAB(w)TA has a single negative eigenvalue λ−= 1−3w
4
.
The negativity of the state is therefore N (ρAB(w)) = 3w−1
4
.
Turning now to the primal SDP formulation of negativity (5.14), a natural choice of primal variables are 
Z = [ρAB(w)TA]
(+) and Y = [ρAB(w)TA]
(−), the positive and negative parts of ρAB(w)TA respectively. In

exercise 5.3 below, these are shown to be optimal choices. With these choices, the objective function
evaluates to tr([ρAB(w)TA]
(−)) = 3w−1
4
, as expected.
Turning to the dual SDP formulation (5.15), we can take X =∣Ψ−⟩⟨Ψ−∣, the projector onto the
antisymmetric maximally entangled state, the eigenstate of ρAB(w)TA with eigenvalue −1. This is feasible, as
it is both positive semidefinite, and less than the identity, being a projector. In exercise 5.3 below, this is
again shown to be an optimal choice, since it is the projector onto the negative part of ρAB(w)TA. Direct
calculation shows that tr(X TAρAB(w)) = tr(XρAB(w)TA) = 1−3w
4
, as expected.
Finally, from this construction we therefore obtain the (single) quantitative entanglement witness 
W =∣Ψ−⟩⟨Ψ−∣TA, which optimally detects the entanglement of the isotropic state for all values w > 1
3 ,
and certifies that the negativity is (at least) 3w−1
4
.
(5.21
)
(5.22
)
(5.23
)
Example 5.3 All pure entangled states have non-zero negativity.
In this example we will show that all pure entangled states have non-zero negativity. Another way of
phrasing this is to say that the PPT criterion in fact detects all pure entangled states. Consider a state ∣Ψ⟩
written in Schmidt decomposition as
∣Ψ⟩= ∑
i
√pi ∣iA⟩∣iB⟩,
where {∣iA⟩} and {∣jB⟩} are orthonormal bases for systems A and B respectively, and √pi ⩾0 are
the Schmidt coefficients of the state. Since the state is assumed to be entangled, at least two of the Schmidt
coefficients do not vanish. Without loss of generality, we will assume that p1 > 0 and p2 > 0. Let us
consider the potential dual variable
X =∣Ψ−
12⟩⟨Ψ−
12 ∣,
∣Ψ−
12⟩=
1
√2
(∣1A⟩∣2B⟩−∣2A⟩∣1B⟩),
where we see that ∣Ψ−
12⟩ is the maximally entangled singlet state in the two-qubit subspace spanned by
the first and second basis states of each system.
Since X is a rank-1 projector, it follows directly that it is both a positive semidefinite operator and less
than the identity, i.e. both of the constraints (5.15b) and (5.15c) are satisfied. This is thus a feasible dual
variable. All that remains is to evaluate the dual objective function. To that end, we see that
and therefore a simple calculation shows that
−tr(X TA ∣Ψ⟩⟨Ψ ∣) = √p1p2 > 0.
Since the value of the dual objective function, when evaluated using a dual feasible variable places a
lower bound on the value of the primal objective function—in this case the negativity of the state—this
shows that all entangled pure states have non-zero negativity. In other words, this shows that all pure
entangled states have a negative-partial transpose. The dual variable X =∣Ψ−
12⟩⟨Ψ−
12 ∣ is optimal when the
only non-zero Schmidt coefficients are √p1 and √p2. When this is not the case, i.e. when there are
additional non-zero Schmidt coefficients, a sum of projectors can be used. This is both feasible and optimal,
as shown in exercise 5.4.
X TA = ∣Ψ−
12⟩⟨Ψ−
12 ∣TA,
= 1
2 (∣1A⟩∣2B⟩⟨1A ∣⟨2B ∣+ ∣2A⟩∣1B⟩⟨2A ∣⟨1B ∣−∣1A⟩∣1B⟩⟨2A ∣⟨2B ∣−∣2A⟩∣2B⟩⟨1A ∣⟨1B

(5.24
)
(5.25
)
(5.26
)
(5.27
)
The last example teaches us a very useful lesson: we can use the same witness to detect the entanglement of
different states. This is very useful from an experimental point of view, because it allows us to detect entanglement
of states that are unknown (i.e. without the need of performing quantum state tomography) by measuring a witness
operator W. Furthermore, the observed violation of the witness provides a lower bound on the negativity of the
state, since the witness might not be optimal for this state. In fact, this is a general idea that goes beyond the
negativity: after solving an instance of an SDP for a given quantity, we can obtain the dual variables and use them
to estimate the quantity for other instances.
Exercises
5.2 Show that the set SPPT is a convex set. That is, show that if πAB and π′
AB are both PPT states, then
for all 0 ⩽p ⩽1, the state pπAB + (1 −p)π′
AB is contained in SPPT.
5.3 In this exercise we will show that (5.13) constitute primal and dual SDP formulations of ∥A(−) ∥1.
(a) Show that Y = A(−) and Z = A(+) are feasible variables for the primal SDP.
(b) Given part (a), show that the primal optimal value α* lower bounds ∥A(−) ∥1.
(c) Write down the Lagrangian for the primal problem and use it to derive the dual problem.
(d) Show that both the primal and dual problems are strictly feasible, and therefore that strong
duality holds.
(e) Show that X = Π(−) (the projector onto the negative eigenspace of A) is a feasible variable for
the dual SDP.
(f) Given part (e), show that the dual optimal value β* upper bounds ∥A(−) ∥1.
(g) Use parts (b), (d) and (f) to show that this pair of SDPs are primal and dual formulations of 
∥A(−) ∥1.
5.4 In this exercise we will study the generalisation of (5.22), and show that it evaluates to the
negativity of a pure state.
(a) Consider the family of operators
Xij =∣Ψ−
ij⟩⟨Ψ−
ij ∣,
∣Ψ−
ij⟩=
1
√2
(∣iA⟩∣jB⟩−∣jA⟩∣iB⟩),
j > i.
Show that
−tr(Xij
TA ∣Ψ⟩⟨Ψ ∣) = √pipj
where ∣Ψ⟩ is the pure entangled state from (5.4).
(b) Show that Xij is orthogonal to Xi′j′ unless i = i′ and j = j′.
(c) Consider the dual variable
X = ∑
j>i
Xij.
Using part (b), show that this dual variable is feasible for the dual negativity SDP (5.15).
Hint: It is useful to consider the operator X 2, and what it tells us about the eigenvalues of X.
(d) Using part (a), show that
−tr(X TA ∣Ψ⟩⟨Ψ ∣) = ∑
j>i
√pipj.
(e) It can be shown (by independent means) that the negativity of a pure state ∣Ψ⟩ is

(5.28
)
(5.29
a)
(5.29
b)
(5.29
c)
(5.30
a)
(5.30
b)
(5.30
c)
N (∣Ψ⟩⟨Ψ ∣) =
(∑i √pi)2 −1
2
.
Show that this expression is equal to the right-hand side of (5.27). This shows that X is an
optimal dual variable, and evaluates to the negativity of a pure state, irrespective of what the state
is, i.e. irrespective of the Schmidt coefficients.
5.4 Random robustness of entanglement and SDP relaxations
We can further use the positive-partial-transpose condition to arrive at the important concept of an SDP relaxation.
Sometimes there is no computationally efficient or easy way to solve a problem. In such instances, it is important
and useful to be able to find a relaxation of the problem, which can be easily solved, and which will provide useful
bounds. A common use of semidefinite programming is to find efficient relaxations of both convex and non-
convex optimisation problems. This is precisely what happens with the separability problem.
The feasibility problem of testing whether or not a quantum state is separable is computationally hard in
general. However, as we saw above, testing whether or not a state is PPT can be solved via an SDP. Clearly, this
relaxation doesn’t allow us to detect the entanglement of all states—those states which are both PPT and entangled
—but we can certify the entanglement of all entangled states which are not PPT, i.e. all NPT entangled states.
It is important to realise that not only can we relax the feasibility problem, but the PPT criterion can also be
used to relax optimisation problems involving entanglement too, for instance, to find bounds on entanglement
quantifiers. We can illustrate this by looking at a quantifier known as the random robustness of entanglement
RR(ρAB). This is defined by the following optimisation problem
RR(ρAB) = minimise
r
subject to
ρAB + r IA ⊗IB
dAdB
1 + r
∈Ssep,
r ⩾0.
If the optimal value of this problem is 0, then the first constraint implies that ρAB ∈Ssep, while if it is strictly
positive, then the state is necessarily entangled. The random robustness of entanglement of ρAB can be interpreted
as being the minimal amount of white noise 
I⊗I
dAdB  that we must mix with ρAB such that the mixture becomes a
separable state.
Unfortunately, this problem cannot be solved easily, due to the fact that there is no known algorithmic
characterisation of the set of separable states Ssep (except in the case of the smallest dimensions). We can,
nevertheless relax this optimisation problem and replace the set Ssep by the set SPPT of PPT states. As seen before,
testing if a state is PPT can be cast as an SDP, so we can consider the following relaxed SDP:
RNPT
R
(ρAB) = minimise
r
subject to
(ρAB + r IA ⊗IB
dAdB
)
TA
≽0,
r ⩾0.
Notice that in the above we have multiplied the constraint (5.29b) from previously by 1 + r. This can be
done, without any loss of generality, since 1 + r ⩾0, and therefore we do not change the positive semidefiniteness
of the left-hand side by performing this multiplication. Essentially what is being done here is to consider an
unnormalised state, which can always be normalised later. The reason for removing the denominator should

(5.32
)
(5.33
a)
(5.33
b)
(5.33
c)
(5.31
)
hopefully be clear—it turns the problem into an SDP, while with the denominator in place it would not yet be in
the form of an SDP.
In the above we see that RNPT
R
(ρAB) = r* > 0 means that some non-zero amount of white noise has to be
mixed with ρAB to make the mixture PPT, so that ρAB is guaranteed to be entangled by the PPT criterion. If,
however r* = 0 then ρAB is PPT, i.e. is not NPT entangled. Thus, we cannot guarantee whether it is entangled or
not. As such, the relaxed robustness RNPT
R
(ρAB) can be seen as the robustness to being not-NPT entangled, and
can be viewed as an alternative quantifier to the entanglement negativity from section 5.3.
Crucially, in terms of the quantification of the entanglement of ρAB, since Ssep ⊂SPPT, we see that the
optimal value r* of the relaxed problem (5.30) lower bounds the original problem (5.29), i.e.
RNPT
R
(ρAB) ⩽RR(ρAB).
That is, this shows that we need to mix with less noise to make a state PPT than to make it separable. It also
shows that the relaxation simply doesn’t count the entanglement of PPT states. Intuitively, if the set of states SPPT
is ‘similar’ to the set of separable states—i.e. if the total volume of PPT entangled states is small—then this
relaxation gives a reasonable approximation to the random robustness of entanglement. In practice this is a
reasonable first approximation. As we will see below, better SDP relaxations do exist, which provide tighter
bounds.
We end by stressing that the above is just one example of how the PPT criterion can be used to find bounds on
quantities of interest. In general, in any convex optimisation problem where the constraint σAB ∈Ssep needs to be
imposed, we can always relax this constraint to the SDP constraint σAB ∈SPPT, which in many cases leads to a
relaxed problem which is itself an SDP.
Exercises
5.5 (a) Show that the random robustness of entanglement (5.29) of the two-qubit isotropic state (5.8) is
RR(ρAB(w)) = 3w −1.
Hint: You can compute for the random robustness analytically, without needing to perform any
optimisation.
(b) Find the random robustness of the two-qudit isotropic state (5.11).
5.6 In this exercise we will derive the dual SDP formulation of (5.30) for RNPT
R
(ρAB), in order to
compare with the dual formulation of the negativity from (5.17).
(a) Write down the Lagrangian associated to (5.30), by introducing dual variables X and μ for the
first and second constraints respectively.
(b) Identify the constraints necessary to make the Lagrangian (i) a lower bound on the optimal
primal value and (ii) independent of the primal variables.
(c) Use part (c) to arrive at the dual formulation of (5.30) and confirm that strong duality holds.
(d) Introduce a new dual variable W = X TA, and show, after eliminating slack variables (if this
has not already been done), that the dual can be expressed as
RNPT
R
(ρAB) = maximise
−tr(WρAB)
subject to
tr(W) ⩽dAdB,
W TA ≽0.
(e) Explain why the constraint (5.33b) can be viewed as a normalisation constraint,
demanding that value of the entanglement witness W evaluated on the maximally mixed state 
I/dAdB should not exceed 1, and make a sketch similar in form to figure 5.1 showing the structure
of the entanglement witness geometrically.

(5.35
a)
(5.36
a)
(5.36
b)
(5.36
c)
(5.35
b)
(5.35
c)
(5.34
a)
(5.34
b)
(5.34
c)
(5.34
d)
(5.37
)
(5.38
)
g
g
y
5.7 An important variant of the robustness of entanglement is the generalised robustness of
entanglement, given by
RG(ρAB) = minimise
r
subject to ρAB + rσAB
1 + r
∈Ssep,
r ⩾0,
σAB ≽0,
tr(σAB) = 1,
where the ‘noise’ is now any (possibly entangled) quantum state σAB, and the optimisation seeks
to find the worst-case noise, mixing with which makes ρAB separable as quickly as possible.
(a) Show that by relaxing the separability constraint to the PPT constraint, and by introducing the
new variable ωAB = rσAB, that a relaxation of the generalised robustness of entanglement is given
by the following SDP:
RNPT
G
(ρAB) = minimise
tr(ωAB)
subject to
(ρAB + ωAB)TA ≽0,
ωAB ≽0.
(b) Write down the Lagrangian associated to (5.35), and use it to show that the dual
formulation of RNPT
G
(ρAB) is given by
RNPT
G
(ρAB) = maximise
−tr(WρAB)
subject to
W TA ≽0,
I ≽W,
making sure to confirm that strong duality holds.
(c) The dual formulation (5.36) shows that the generalised robustness of NPT entanglement can be
interpreted as a quantitative entanglement witness. Find the interpretation of the normalisation
constraint (5.36c), and use this to make a sketch similar to figure 5.1.
5.8 In this exercise we will calculate the generalised robustness of the two-qubit isotropic state (5.8).
(a) Using the fact that I ⊗I =∣Φ+⟩⟨Φ+ ∣+ ∣Φ−⟩⟨Φ−∣+ ∣Ψ+⟩⟨Ψ+ ∣+ ∣Ψ−⟩⟨Ψ−∣, where 
∣Φ+⟩, ∣Φ−⟩, ∣Ψ+⟩ and ∣Ψ−⟩ are the four two-qubit Bell states, along with knowledge that two-
qubit isotropic states become separable at w = 1
3 , show that the generalised robustness of
entanglement of ∣Φ+⟩ is at most
RG(∣Φ+⟩⟨Φ+ ∣) ⩽1,
and find the noise ω
*
AB which achieves this value.
(b) Using part (a), show that the generalised robustness of the two-qubit isotropic state ρAB(w) is
at most
RG(ρAB(w)) ⩽3w −1
2
.
(c) Show that the operator W = α ∣Ψ−⟩⟨Ψ−∣TA has as eigenstates the four Bell states 
∣Φ+Φ, ∣Φ−⟩, ∣Ψ+⟩ and ∣Ψ−⟩ with eigenvalues −α
2 , α
2 , α
2  and α
2  respectively. Use this to show
that W is a feasible dual variable for the dual formulation of the generalised robustness of NPT

(5.40
a)
(5.40
b)
(5.41
a)
(5.41
b)
(5.41
c)
(5.41
d)
(5.40
c)
(5.39
a)
(5.39
b)
(5.39
c)
(5.39
d)
(5.39
e)
entanglement (5.36) as long as α ⩽2.
(d) Evaluate the dual objective function of (5.36), and show therefore that the generalised
robustness of entanglement of the two-qubit isotropic state is RG(ρAB(w)) = 3w−1
2
, i.e. that the
bound obtained in part (b) is tight.
5.9 Another entanglement quantifier is the weight of entanglement. This quantifies the minimal
(probabilistic) amount of entanglement that needs to be used in order to reproduce a given state. In
particular, it is given by the following optimisation problem
W(ρAB) = minimise
p
subject to pωAB + (1 −p)σAB = ρAB,
ωAB ≽0,
tr(ωAB) = 1,
σAB ∈Ssep,
p ⩾0.
The optimal separable state σ*
AB in the decomposition (5.39b) of ρAB is referred to as the ‘best-
separable-approximation’ of ρAB.
(a) Show that by relaxing the separability constraint to the PPT constraint, and defining new
variable ˜σAB = (1 −p)σAB that a relaxation of the weight of entanglement is the following SDP:
W NPT(ρAB) = minimise
1 −tr(˜σAB)
subject to
ρAB −˜σAB ≽0,
˜σAB ≽0,
˜σTA
AB ≽0.
(b) Write down the Lagrangian associated to (5.40), and use it to show that the dual
formulation of W NPT(ρAB) is given by
W NPT(ρAB) = maximise
−tr(WρAB)
subject to
W = Y TA + Z,
Y ≽0,
Z ≽0,
W ≽−I,
making sure to confirm that strong duality holds.
(c) Show that the constraints (5.41b) and (5.41c) together ensure that W is an entanglement
witness, i.e. tr(WσAB) is nonnegative for all separable states σAB.
Note that this form is more general than just taking W TA ⩾0, as was the, constraint above. Such
entanglement witnesses are known as ‘decomposable witnesses’.
(d) The dual formulation (5.41), along with part (c), shows that the weight of NPT entanglement
can be also interpreted as a quantitative entanglement witness. Find the interpretation of the
normalisation constraint (5.41d), and use this to make a sketch similar to figure 5.1.
5.5 k-symmetric extensions
We have seen above that the PPT criterion gives a relaxation of the separability constraint in terms of a
semidefinite constraint. This allowed us to obtain lower bounds on quantifiers of entanglement, such as the random
robustness of entanglement, via SDPs. A natural question is whether there are better relaxations of the separability
constraint that allow us to obtain tighter bounds on entanglement quantifiers, but which nevertheless remain SDPs.

(5.42
)
(5.43
)
(5.44
)
In this section we will see that this is indeed the case, and that there is a sequence of relaxations—each one tighter
than the previous—which provide bounds on entanglement quantifiers. This sequence of relaxations is captured by
the notion of a k-symmetric extension of a quantum state. Such extensions provides a hierarchy of SDPs that
constitutes better and better lower bounds on the entanglement of quantum states.
We say that a bipartite state ρAB has a k-symmetric extension if there exists a (k + 1)-partite state ρAB1…Bk
such that all of the two-party reduced density operators ρABj coincide, and are equal to the state ρAB, that is if 
ρABj = ρAB for all j. An extremely important result is the following:
A quantum state ρAB is separable if and only if it has a k-symmetric extension for all k.
The ‘if’ statement can be proven easily by construction. Consider an arbitrary separable state,
σsep
AB = ∑
λ
p(λ)ρA
λ ⊗ρB
λ .
A k-symmetric extension of this state can directly be written down, by simply ‘copying’ the state of the B
system k times. That is, the state
ρAB1…Bk = ∑
λ
pλρA
λ ⊗ρB1
λ ⊗⋯⊗ρBk
λ ,
with ρBj
λ = ρB
λ  for all values of j, has the property that ρABj = σsep
AB. The intuition behind this is that since the
two systems are only classically correlated (through the variable λ and their local states), it is possible to copy or
‘clone’ these correlations and produce a k-symmetric extension.
In the other direction, the proof—that only separable states have k-symmetric extensions for all values of k—is
not as straightforward. This property nevertheless captures—and quantifies—the notion of monogamy of
entanglement that we encountered in section 3.2 in the context of the quantum marginal problem. Monogamy of
entanglement is the phenomenon whereby if ρAB is entangled, then this limits the amount of entanglement that the
A can have with other systems at the same time. That is, A only has a finite capacity of sharing entanglement. So,
sharing a significant amount of entanglement with one system limits the amount of entanglement that can be
shared with other systems (this is in stark contrast to classical correlations, which have no such finite capacity).
Thus, since a k-symmetric extension requires A to share exactly the same amount of entanglement with each B,
monogamy of entanglement shows us that for some k we must exceed the capacity of A to be entangled, and such
an extension cannot exist. Moreover, if A is highly entangled with B, then it should fail to have k-symmetric
extensions for small values of k compared to less entangled states, as the capacity will be reached much faster.
This is the key insight behind k-symmetric extensions, and shows how they can be used as a powerful tool for
entanglement detection. In particular, if we flip the above logic, and consider the set of states that have a k-
symmetric extension, then as k increases states in this set cannot have much entanglement, so they must be
approximately separable. As k increases, the entanglement drops, and the approximation becomes better.
Before proceeding further, it will be useful to focus on the one aspect of k-symmetric extensions that hasn’t
been discussed yet—the symmetry in this definition. In fact we haven’t yet imposed any symmetry on the
extension ρAB1⋯Bk, other than demanding that all of the bipartite reduced density operators coincide. It is useful to
demand that the extension is symmetric among all of the B subsystems. That is, if we denote by Πsym the projector
onto the symmetric subspace2, then we demand that
(IA ⊗Πsym)ρAB1⋯Bk(IA ⊗Πsym) = ρAB1⋯Bk.
This says that the state is symmetric under permutation of any of the B subsystems, which is much stronger
than just demanding that each of the reduced density operators ρABj coincide. There are a couple of reasons for
imposing this symmetry constraint. First, at a conceptual level, it is important to realise that this is all that is
needed from the extension; it isn’t necessary to consider non-symmetric states3. Second, and probably more
importantly, this makes k-symmetric extensions a much more efficient tool from the perspective of SDPs (which
we will get to shortly). In particular, if the dimension of Alice’s and Bob’s systems are taken to be the same, and
equal to d, then the naive dimension of a k-symmetric extension is dk+1, which grows exponentially fast with k.

(5.45
)
(5.46
a)
(5.46
b)
(5.46
c)
(5.46
d)
(5.47
a)
(5.47
b)
(5.47
c)
Very quickly such extensions become too big to use in any actual piece of code. It is important therefore to
understand to what extent this can be overcome, and this is where the symmetry comes in. By restricting to the
symmetric subspace, we do not need to consider a state in the full, exponentially-large Hilbert space, but rather a
state in the symmetric subspace, which is of much smaller dimension, d (
). This dimension only grows
polynomially with k, as kd−1 when k is large, and so it is much more efficient to use this method when taking into
account the symmetry.
We can now put everything together, and define the set of states which have a k-symmetric extension (similar
to how the set of PPT states was defined in (5.6)),
Note that we only need to impose σAB = ρAB1, since due to the symmetry of the state, it then follows
immediately that σAB = ρABj for all j. Note also that ρAB1⋯Bk satisfies tr(ρAB1⋯Bk) = 1, since σAB = ρAB1. We
refer to the set of states which have a k-symmetric extension as being k-extendible.
Crucially for our purposes here, the set of k-extendible states Sk SE is specified by a set of positive semidefinite
constraints and linear matrix equalities. As such, this can be specified inside an SDP to define a feasible set. This
allows us to use the k-extendible set as an approximation to the set of separable states, which then allows us to
relax non-SDP optimisation problems involving the set of separable states to SDPs involving k-extendible states.
In contrast to before, when we considered the PPT-relaxation (5.6) of the separable set (5.7), instead of getting
a single approximation, we now obtain a sequence of relaxations, indexed by k. As k increases, the set of k-
extendible states becomes a better approximation of the separable set, and in the limit k →∞ the sets coincide.
This thus provides us with an extremely powerful approximation scheme, which is highly useful in practice.
The problem of whether a state ρAB has a k-symmetric extension is an instance of a feasibility semidefinite
program. In particular, it is the following problem:
find
ρAB1⋯Bk
subject to
ρAB = ρAB1,
ρAB1⋯Bk ≽0,
(IA ⊗Πsym)ρAB1⋯Bk(IA ⊗Πsym) = ρAB1⋯Bk.
In contrast to the feasibility SDP for being PPT that we saw in (5.10), which was purely academic and not
useful in practice, here this feasibility SDP is necessary and useful for determining when a state has a k-symmetric
extension. Note also that in the above SDP we have written the constraint that ρAB1⋯Bk is in the symmetric
subspace explicitly in (5.46d). In practice (i.e. when writing code), it is crucial to work directly in the symmetric
subspace (and not impose it as a constraint), in order to benefit from the size reduction that this offers in the SDP.
It is nevertheless useful to write the SDP in the form given above, to conceptually emphasise the symmetric nature
of the extension.
As with the PPT criterion, the k-symmetric criterion is most powerful when used for approximately evaluating
properties of a state, such as entanglement quantifiers. As a concrete example, let us return to the random
robustness of entanglement (5.29). We can now consider the following sequence of relaxations
Rk SE
R
(ρAB) = minimise
r
subject to
ρAB + r IA ⊗IB
dAdB
1 + r
∈Sk SE,
r ⩾0.
As is shown in exercise 5.11, this can be re-expressed as the following SDP:
d + k −1
k
Sk SE = {σAB ∣σAB = ρAB1, ρAB1⋯Bk ≽0,
(IA ⊗Πsym)ρAB1⋯Bk(IA ⊗Πsym) = ρAB1⋯Bk}.

(5.50
)
(5.48
a)
(5.48
b)
(5.48
c)
(5.48
d)
(5.48
e)
(5.49
)
Rk SE
R
(ρAB) = minimise
r
subject to
ρAB + r IA ⊗IB
dAdB
= ˜ρ AB1,
˜ρ AB1⋯Bk ≽0,
(IA ⊗Πsym)˜ρ AB1⋯Bk(IA ⊗Πsym) = ˜ρ AB1⋯Bk,
r ⩾0.
This sequence of SDPs for increasing k provides us with a sequence of lower-bounds on the random
robustness of entanglement, which converge in the limit,
R1 SE
R
(ρAB) ⩽R2 SE
R
(ρAB) ⩽⋯⩽lim
k→∞Rk SE
R
(ρAB) = RR(ρAB).
In practice, since the SDPs become larger in size (optimising over extensions of larger dimension as k
increases), there is a trade-off between the resources required (the time to solve the SDP or the memory needed in
order to solve it) and the level of approximation achieved.
Exercises
5.10 In this exercise we will show that two-qubit isotropic states (5.8) have 2-symmetric extensions
when w ⩽1
2 . (a) Consider the following tripartite state,
ρAB1B2 = 1
2 ∣Φ+⟩⟨Φ+ ∣AB1 ⊗IB2
2
+ 1
2 ∣Φ+⟩⟨Φ+ ∣AB2 ⊗IB1
2 ,
where we note that on the right-hand side, since the systems are labelled, we do not attribute any
significance to the order of the tensor factors. Verify that this state is symmetric among the B systems,
and that it is a 2-extension for the isotropic state ρAB( 1
2 ). (b) Show that by mixing ρAB1B2 with the
maximally mixed state of three qubits, that we can furthermore obtain a 2-extension for any isotropic
state with w ⩽1
2 .
5.11 In this exercise we will show that (5.47) can be cast as the SDP (5.48). (a) Using the definition of
the set Sk SE, write down the optimisation problem that needs to be solved in order to calculate the
random robustness of being k-extendible. Note that this will not yet be an SDP. Why not?
(b) Introduce a new variable ˜ρ AB1⋯Bk = (1 + r)ρAB1⋯Bk, and show that in terms of this variable, the
optimisation problem from part (a) becomes equal to (5.48).
We can interpret the SDP (5.48) as optimising over the set of super-normalised k-symmetric
extensions
.
We can notice in the above that the first approximation, R1 SE
R
(ρAB) is in fact always equal to 0. This is
because a 1-extension is equivalent to not seeking an extension at all, and in this case the set S1 SE is equal to the
set of all bipartite states, and does not distinguish between separable and entangled states at all. We can improve
this, by combining the idea of a k-symmetric extension with the PPT criterion from section 5.2.
In particular, beyond just demanding that the extension is symmetric, we can furthermore impose that it should
be positive under partial transposition. Up until now we have only considered the PPT criterion for bipartite
systems, whereas we now have a multipartite system. Looking back at the symmetric extension of a separable state
in (5.43), it can be noticed that the extension is a fully separable state, with no entanglement whatsoever. It follows
that if we consider an arbitrary bipartition of the state into two parts, and consider taking the partial transpose of
one half, the density operator will remain positive semidefinite—this in effect treats the multipartite state as a

(5.51
)
(5.52
a)
(5.52
b)
(5.52
c)
(5.52
d)
(5.52
e)
bipartite state, and applies the logic of the PPT criterion. Another way of saying the above, is that if any subset of
B systems is picked, and a partial transpose is performed, then a positive semidefinite operator is obtained. We can
impose this as an additional set of constraints which must be satisfied by an extension—that it is PPT when any
subset of B systems is transposed. This leads to a better relaxation of separability, since the set of permissible
extensions is reduced to be smaller in size.
There is however an amount of redundancy which should first be removed, which has arisen once again from
the symmetry of the extension. The symmetry implies that the PPT constraints only need to be imposed for a
specific subset of bipartitions, rather than for all bipartitions. To see why, consider imposing that the extension is
PPT when transposing only B1, ρ
TB1
AB1⋯Bk ≽0. Now, because of the symmetry, we can relabel which B system is
which. Consider therefore relabelling the first and second subsystems of B, B1 ↔B2. After relabelling, it is now
imposed that the partial transpose on B2 leaves the density operator positive semidefinite. That is, because of the
symmetry, we see that transposing B1 is equivalent to transposing B2, or any individual B subsystem. By a similar
logic, transposing the first two subsystems is equivalent to transposing two arbitrary subsystems, and so forth.
Therefore, without any loss of generality, if it is demanded that the state remains PPT after transposing the first ℓ
subsystems, this is equivalent to demanding the state is PPT after transposing an arbitrary set of ℓ subsystems; we
do not need to independently impose these constraints.
It is important to note that the above observation dramatically reduces the number of constraints that need to be
imposed, and therefore dramatically reduces the number of variables in the dual problem. In particular, if we didn’t
take into account the symmetries, the number of bipartitions that would need to be considered is 2k−1 −1, and
grows exponentially with the size of the extension. Taking into account the symmetries, only k −1 bipartitions
need to be considered.
Putting everything together, we can now define a final sequence of sets which approximate the set of separable
states (5.7), the set of states which have a PPT k-symmetric extension, or PPT k-extendible states for short,
S PPT
k SE = {σAB ∣σAB = ρAB1, ρAB1⋯Bk ≽0, (IA ⊗Πsym)ρAB1⋯Bk (IA ⊗Πsym) = ρAB1⋯Bk, ρ
T(ℓ)
AB1⋯Bk ≽0
where T(ℓ) = TB1⋯Bℓ is shorthand for transposing the first ℓ subsystems of B.
Similarly to above, the problem of determining whether a state has a PPT k-symmetric extension is the
following feasibility SDP:
find
ρAB1⋯Bk
subject to
ρAB = ρAB1,
ρAB1⋯Bk ≽0,
(IA ⊗Πsym)ρAB1⋯Bk(IA ⊗Πsym) = ρAB1⋯Bk,
ρ
T(ℓ)
AB1⋯Bk ≽0
ℓ= 1, … , k.
This can be seen as an adaptation of the feasibility SDP (5.46) for k-extendibility, adding in the PPT
constraints (5.52e). In a completely analogous fashion, by adding the same constraints to (5.48), we obtain an SDP
relaxation, computing the random robustness of a state to having a PPT k-symmetric extension. This same idea can
be applied in many contexts, and provides a converging sequence of approximations for many quantities of
interest.
5.6 Concluding remarks
In this chapter we have discussed entanglement from the perspective of SDP. As was seen, even though detecting
or quantifying the entanglement of states of arbitrary dimension is a difficult task, we can nevertheless use SDPs to
obtain sufficient criteria for entanglement detection, and also to obtain bounds for various entanglement
quantifiers. In this regards, in this chapter we have learnt the following:
Entanglement negativity. The entanglement negativity can be written as an SDP (5.14).

(5.53
)
(5.54
a)
(5.54
b)
Entanglement witnesses. Building on an idea already presented at section 3.1.5, we have seen how the dual
formulation of entanglement quantifiers, such as the negativity or robustnesses, provide quantitative
entanglement witness—see equation (5.17).
SDP relaxation. Although deciding whether a state is entangled or not is a difficult task in general, we can
relax the problem, in order to find an SDP formulation that approximates it. We have applied this idea to the
random robustness of entanglement, where the separability constraint have been substituted by the PPT
constraint—see equation (5.30).
k-symmetric extensions. We have also presented a sequence of SDP relaxations to the separability problem
that detects the entanglement of any state in the limit of large k. Although this limit is not practical, since the
size of the corresponding SDP grows with k, it nevertheless demonstrates an important point—that a hard
problem can be approximated by a sequence of SDPs.
5.7 Further reading
Horodecki R, Horodecki P, Horodecki M and Horodecki K 2009 Quantum entanglement Rev. Mod. Phys. 81
865
Gühne O and Tóth G 2009 Entanglement detection Phys. Rep. 474 1
Doherty A C 2014 Entanglement and the shareability of quantum states J. Phys A: Math. Theor. 47 424004
5.8 Advanced topics
5.8.1 Entanglement witnesses from k-symmetric extensions
Here we briefly discuss how duality can be used in order to obtain a converging sequence of sets of entanglement
witnesses, which can also prove useful in practice.
Recall that an entanglement witness is an operator which has a nonnegative expectation value on any separable
state, but can have a negative expectation value for some entangled states. Formally, we can define the set of all
entanglement witnesses as the following set
Went = {W ∣tr(WσAB) ⩾0 for all σAB ∈Ssep}.
The difficulty in characterising the set of separable states Ssep carries across into the realm of entanglement
witnesses, and it is just as difficult to characterise the set of entanglement witnesses. Section 5.5 however provides
us with a method for constructing approximations to the set of entanglement witnesses. In particular, we will see
that we can obtain inner approximations to the set of entanglement witnesses—i.e. subsets of the set Went, which
can witness some—but not all—entangled states.
The simplest, and smallest, inner approximation to Went that we have already encountered implicitly in section
5.3 is the set of NPT-entanglement witnesses, arising from the PPT approximation SPPT. In particular, a summary
of what was found there is that
WNPT = {W ∣tr(WσAB) ⩾0 for all σAB ∈SPPT},
= {W ∣W TA ≽0},
where the first line is the definition of an NPT-entanglement witness, and the second line is the result that this
set has a simple characterisation, as the set of operators which are themselves PPT. In particular, we can take 
W =∣ϕ⟩⟨ϕ ∣TA, i.e. to be the partial transpose of a rank-1 projector onto an entangled state. On the one hand, such
an operator will have a nonnegative expectation value on all PPT states. On the other hand, it will detect any NPT
entangled state such that ∣ϕ⟩ is contained in the eigenspace associated to the negative eigenvalue(s) of the partially
transposed state.
We can obtain a sequence of better approximations to the set of entanglement witnesses by considering the set 
SkSE of k-extendible states. Although it is possible to work directly with the feasibility SDP (5.46) to do this, it is
preferable to work with a standard optimisation SDP when using the Lagrangian to pass to the dual. We will
therefore derive the dual formulation of the k-symmetric approximation of random robustness of entanglement

(5.55
a)
(5.55
b)
(5.56
a)
(5.56
b)
(5.56
c)
(5.57
)
(5.58
a)
(5.58
b)
(5.58
c)
(5.59
)
(5.48), and see how we can use this to find the associated approximate set of entanglement witnesses. The
Lagrangian associated to (5.48) is
where X ≽0 and x ⩾0, as these are the dual variables associated with the inequality constraints. From the
Lagrangian, we can see that only W will appear in the dual objective function, and hence X and x are both slack
variables. After removing them from the problem, we arrive at the following initial form of the dual problem
maximise −tr(WρAB)
subject to
tr(W)
dAdB ⩽1
W ⊗IB2⋯Bk + (IA ⊗Πsym)Y (IA ⊗Πsym) −Y ≽0.
An important simplification that can be made is to transform the final constraint (5.56c) into a more useful
and insightful form. To do so, we can multiply the constraint, from the left and from the right by IA ⊗Πsym. Since 
IA ⊗Πsym is a projector, it follows that (IA ⊗Πsym)(IA ⊗Πsym) = IA ⊗Πsym, and hence we arrive at
(IA ⊗Πsym)W ⊗IB2⋯Bk(IA ⊗Πsym) ≽0,
where we use the fact that conjugating a positive semidefinite operator (multiplying on the left and right by
another operator) leaves it positive semidefinite, as shown in exercise 5.12. This form is simpler than (5.56c), and
helps to demonstrate its significance; it says that although the operator W ⊗IB2⋯Bk need not be positive
semidefinite—and in fact cannot be positive semidefinite if it will detect the entanglement of some state—its
projection onto the symmetric subspace of B1 to Bk must be a positive semidefinite operator.
Putting everything together, we thus arrive at the simplified dual SDP
maximise −tr(WρAB)
subject to
tr(W) ⩽dAdB,
(IA ⊗Πsym)W ⊗IB2⋯Bk(IA ⊗Πsym) ≽0,
where in (5.58b) we have multiplied both sides by dAdB to simplify. The final realisation that can be made is
that here exactly the same constraint (5.62b) applies as in the dual formulation of the random robustness of NPT
entanglement (5.33b). This is a normalisation constraint on the entanglement witness, and is what turns it into a
quantitative witness, here such that the value of the witness equals the random robustness of being k-extendible. It
is thus the remaining constraint which captures the notion of an entanglement witness for k-extendibility. To
confirm this, we can consider multiplying the constraint (5.58c) by the extension σAB1⋯Bk of an arbitrary k-
extendible state σAB1, and taking the trace, to obtain
where in the first line the cyclicity of the trace has been used, and the symmetry of the extension, 
(IA ⊗Πsym)σAB1⋯Bk(IA ⊗Πsym) = σAB1⋯Bk, and the final inequality holds as we took the trace of the product
L = r −tr[W(ρAB + r IA ⊗IB
dAdB
−˜ρ AB1)] −tr(X˜ρ AB1⋯Bk)
+ tr{Y [(IA ⊗Πsym)˜ρ AB1⋯Bk(IA ⊗Πsym) −˜ρ AB1⋯Bk]} −xr,
= tr{˜ρ AB1⋯Bk[W ⊗IB2⋯Bk −X + (IA ⊗Πsym)Y (IA ⊗Πsym) −Y ]}
+ r[1 −tr(W)
dAdB −x] −tr(WρAB),
tr[(IA ⊗Πsym)W ⊗IB2⋯Bk(IA ⊗Πsym)σAB1⋯Bk] = tr[(W ⊗IB2⋯Bk)σAB1⋯Bk]
= tr(WσAB1) ⩾0,

(5.60
)
(5.61
)
of two positive semidefinite operators. This shows that tr(WσAB) is nonnegative for any k-extendible state, as
required for a witness of entanglement based upon k-extendibility. We thus arrive at the following sequence of
inner approximations to Went,
Wk SE = {W ∣(IA ⊗Πsym)W ⊗IB2⋯Bk(IA ⊗Πsym) ≽0}.
Finally, in exercise 5.13, a similar analysis is carried out, based upon k-symmetric PPT extensions, where it is
shown that the corresponding sequence of inner approximations to the set of entanglement witnesses is
W PPT
k SE = {W ∣(IA ⊗Πsym)W ⊗IB2⋯Bk(IA ⊗Πsym) ≽(IA ⊗Πsym)
k−1
∑
ℓ=1
X Tℓ
ℓ(IA ⊗Πsym),
X Tℓ
ℓ
≽
The difference to the set of witnesses for non-k-extendibility is that now W ⊗IB1⋯Bk no longer needs to be
positive semidefinite when projected onto the symmetric subspace of B, but must be ‘greater than’ the operator 
∑k−1
ℓ=1 X Tℓ
ℓ (on the subspace), which in general will not be a positive semidefinite operator. This is thus a
relaxation of the constraint, and hence the set of witnesses, for a given k, will be larger, i.e. this is a better inner
approximation. This is as it should be, as the corresponding approximation to the set of separable states S PPT
k SE  is a
better outer approximation to the set of separable states compared to Sk SE. The price that we pay is that this set is
computationally more demanding, with k −1 additional bipartite operator variables introduced.
Exercises
5.12 (a) Show that if an operator A is positive semidefinite, A ≽0, then the conjugated operator 
A′= B†AB (for an arbitrary, not necessarily Hermitian operator B) is also positive semidefinite. Hint: It
is useful to use the fact that an operator is positive semidefinite if it has a nonnegative expectation value
for all states, i.e. A ≽0 is equivalent to ⟨ψ ∣A ∣ψ⟩⩾0 for all ∣ψ⟩.
(b) Use part (a) to explain why (5.61) holds.
5.13 In this exercise we will derive the set of entanglement witnesses that detect non-PPT k-
extendibility given in (5.65).
(a) Write down the SDP relaxation of the random robustness of entanglement (5.29) based upon
PPT k-symmetric extensions.
(b) Write down the Lagrangian associated to this SDP, in analogy to (5.55).
(c) Use the Lagrangian from part (b) to arrive at a dual SDP formulation of the primal SDP from
part (a).
(d) Simplify the dual, in analogy to how the dual (5.56) was simplified to arrive at (5.62).
(e) Use the simplified dual from part (d) to identify the set W PPT
k SE  of witnesses of non-PPT k-
extendibility.
1We have presented the positive-partial transposition criterion in terms of the transposition with respect to party A, but we could equivalently have used
the transposition with respect to party B since X TA = (X TB)T.
2There are many ways of representing the projector onto the symmetric subspace. Two useful forms are
(i) Πsym = ∫dψ ∣ψ⟩⟨ψ ∣⊗k, where dψ is the invariant (Haar) measure over the state space;
(ii) Πsym =
1
k! ∑π∈Sk Vπ, where Sk is the symmetric group over k elements, and Vπ is the permutation unitary
such that Vπ ∣i1, … , ik⟩=∣iπ−1(1), … , iπ−1(k)⟩.
3One way to see this is to note that if we find an asymmetric extension, we can always use it to construct other asymmetric extensions by performing
permutations of the B systems. These can then all be mixed equally, which produces a symmetric extension, which will be just as good as any of the
individual asymmetric ones. We can therefore restrict to symmetric extensions from the beginning without loss of generality.

IOP Publishing
Semidefinite Programming in Quantum Information
Science
Paul Skrzypczyk and Daniel Cavalcanti

Chapter 6
Measurement incompatibility
In this chapter we return to the study of measurements, but this time rather than
considering a single measurement at a time, we will consider scenarios involving sets of
measurements, and the problem of measurement incompatibility—one of the fundamental
aspects of quantum theory.
Conceptually, the key idea is whether a set of measurements can (or can’t) be
performed simultaneously. In other words, if a single experiment can be carried out which
allows for the results of a set of measurements to be inferred simultaneously or not.
Originally, measurement incompatibility was associated with the fact that some
measurements are described by observables that don’t commute. In fact, for projective
measurements two observables commute if and only if they share a common eigenbasis.
Then by performing the single experiment that implements a measurement in this
eigenbasis one can obtain information about all observables that share this eigenbasis.
However, when measurements are not projective (i.e. when they are described by more
general Positive Operator–Valued Measure (POVM) elements), then this construction is
no longer enough and we have to consider a more general notion of incompatibility,
known as non-joint measurability.
In this chapter we will see that the set of all compatible sets of measurements—also
referred to as jointly measurable sets—can be represented by a semidefinite program
(SDP). We will see that this allows us to use SDP to quantify how incompatible a set of
measurements are. In the special case of two dichotomise (two-outcome) measurement, in
the ‘Advanced topics’ section we will use SDP duality to furthermore present a surprising
result—that the measurements are incompatible precisely when they can be used to
demonstrate quantum nonlocality.
6.1 Joint measurability as an SDP
Consider a set of m measurements, {Mx}x, each of which is specified by a collection of o
POVM elements, Mx = {Ma∣x} for a = 1, … , o, where for simplicity it is assumed that
each measurement has the same number of outcomes1. This set of measurements is
compatible or jointly measurable if there exists a single parent measurement which can
be measured in place of the individual measurements, the outcome of which is then used
to simulate the outcomes of the individual measurements. More concretely, this means

(6.1)
(6.2a
)
(6.2b
)
(6.2c
)
(6.2d
)
that there is a parent measurement N = {Nλ}, with an arbitrary number of outcomes l,
and a probabilistic assignment of outcomes for the m measurements, specified by a
conditional probability distribution p(a ∣λ, x). Thus, mathematically the set {Mx}x is
jointly measurable if every POVM element can be decomposed as
Ma∣x = ∑
λ
p(a ∣λ, x)Nλ.
A basic question that arises is: given a set of measurements Mx = {Ma∣x}, how can we
determine if it is compatible. This question can be phrased as the follow feasibility
problem
find
N, p(a ∣λ, x)
subject to
Ma∣x = ∑
λ
p(a ∣λ, x)Nλ
∀a, x,
Nλ
≽0
∀λ,
∑
λ
Nλ = I,
p(a ∣λ, x) ⩾0
∀a, x, λ,
∑
a
p(a ∣λ, x) = 1
∀λ, x.
This feasibility problem is not an SDP, since the constraint (6.2b) is non-linear in the
variables of the problem. However, as with all the other problems encountered thus far,
we can overcome this problem, and show that checking whether a set of measurements is
jointly measurable or not can indeed be cast as a feasibility SDP.
The key observation to make is that we can restrict to a special class of parent
measurements N and assignments p(a ∣λ, x) without loss of generality. We can
understand (6.1) operationally, interpreting it as a model that first measures N producing
a measurement result λ, which is then used to generate the results of any measurement 
Mx probabilistically according to p(a ∣λ, x). Let us think about the collection of all m
measurement results jointly. When a set of measurements is jointly measurable, in
principle all of the measurement results could be asked for, rather than just a single result.
In order to distinguish them, we can label the outcome of the first measurement by a1, the
outcome of the second by a2, and so forth, and collect all m into a vector 
→a = (a1, … , am). How many different sets of results could in principle be obtained?
There are precisely om results—each measurement having o outcomes, and there being m
measurements. The probability for a particular string →a being produced (given the result
of the measurement λ) is
p(→a ∣λ) = p(a1 ∣λ, x = 1)p(a2 ∣λ, x = 2) ⋯p(am ∣λ, x = m),

(6.3a
)
(6.3b
)
(6.4)
(6.5a
)
(6.5b
)
(6.5c
)
(6.6)
(6.7a
)
(6.7b
)
(6.7c
)
= ∏
x
p(ax ∣λ, x).
We arrive at a useful formula by now going backwards, and asking what is the
probability that the result of the measurement Mx will be a. This will be the total
probability, over all vectors →a, such that the xth component is equal to a, ax = a. In
particular, we have
p(a ∣λ, x) = ∑
→a
δax,ap(→a ∣λ).
That is, we can view p(a ∣λ, x) as the marginal of the distribution p(→a ∣λ), i.e. 
p(a ∣λ, x) = p(ax = a ∣λ). To see why this is useful, (6.4) can be substituted into (6.1)
to obtain
Ma∣x = ∑
λ
p(a ∣λ, x)Nλ,
= ∑
λ
∑
→a
δax,ap(→a ∣λ)Nλ,
= ∑
→a
δax,aN ′
→a
where we have defined N ′
→a by
N ′
→a = ∑
λ
p(→a ∣λ)Nλ.
Since Nλ ≽0 and p(→a ∣λ) ⩾0, we see immediately that N ′
→a ≽0. Moreover, summing
over →a it is seen that
∑
→a
N ′
→a = ∑
→a
∑
λ
p(→a ∣λ)Nλ,
= ∑
λ
Nλ,
= I,
where the second line follows since p(→a ∣λ) is a normalised conditional probability
distribution, and the third line follows because N is a normalised measurement. This
shows that N′ = {N ′
→a}→a is a valid measurement, with outcomes →a. From this it follows
that we can interpret (6.5c) in an interesting way: it says that there is a class of canonical

(6.8a
)
(6.8b
)
(6.8c
)
(6.8d
)
parent measurements, whose outcomes are labelled by the string of outcomes of the m
measurements Mx. When using these measurements, we deterministically assign the
outcome a = ax to the measurement labelled x. Moreover, this canonical measurement
has a finite number of outcomes om.
In this form, we see that there is a strong parallel between being jointly measurable
and the classical marginal problem 1.1, with the set of measurements {Mx} being the
(single-body) marginals of the canonical parent measurement N.
Since we can always arrive at a canonical measurement and deterministic assignment
starting from any parent measurement N and any probabilistic assignment p(a ∣λ, x)
through (6.6), we see that it is possible to instead search exclusively over canonical
parents without any loss of generality, and that the feasibility problem (6.2) can be
reformulated as the following SDP
find
N
subject to
Ma∣x = ∑
→a
δax,aN→a
∀a, x
N→a ≽0
∀→a,
∑
→a
N→a = I.
In this form all constraints are linear. It is important to note here that the number of
constraints grows exponentially with the number of measurements m, since (6.8c)
contains om positivity constraints—one for each element of the exponentially big parent
measurement. This means solving this SDP numerically becomes quickly impractical
when m grows.
6.2 Two dichotomic measurements
As a more concrete example, we will now study in detail the simplest situation that is
interesting from the perspective of measurement incompatibility—when there are two
measurements, each of which has two outcomes, which are often referred to as
dichotomic measurements.
We will begin by going beyond the feasibility problem, and consider how to relax
(6.8) into an optimisation form. The method that we will adopt is similar to the one used
in the context of measurement informativeness, when we considered a robustness-like
measure. But here we will follow the same approach as in the case of the random
robustness of entanglement, and consider, as the noise, a completely trivial two-outcome
measurement which has POVM elements Ta = 1
2 I for a = 1, 2. Such a measurement
will return a uniformly at random, independent of the quantum state being measured. We

(6.9)
(6.10
a)
(6.10
b)
(6.10
c)
(6.10
d)
(6.10
e)
now imagine the trivial situation, where both measurements are identical and equal to this
trivial measurement, then such a pair of measurement is—by construction—jointly
measurable. If we treat this as a type of noise, it follows that for any set of measurement 
{Mx}, we can consider noisy versions, with POVM elements equal to
M ′
a∣x = Ma∣x + r I
2
1 + r
∀a, x.
For sufficiently large r, this set of measurements is guaranteed to be jointly measurable.
The smallest r that we can take, such that the set {M′
x} is jointly measurable, is therefore
a quantifier of how incompatible the original set of measurements {Mx} is; if the set is
already jointly measurable, then no noise needs to be added; on the other hand, if the set
needs a lot of noise to be added before it becomes jointly measurable, then the set of
measurements is naturally very incompatible. This type of quantifier is known as the
random robustness of measurement incompatibility. Here the word ‘random’
distinguishes that the noise is fixed to be the set of trivial measurements mentioned
before, in contrast to the generalised robustness, where the noise was a general
measurement
We can use the random robustness to relax the feasibility problem (6.8). In particular,
we arrive at the minimisation problem
minimise
r
subject to
Ma∣x + r I
2
1 + r
= ∑
→a
δax,aN→a
∀a, x,
N→a ≽0
∀→a,
∑
→a
N→a = I,
r ⩾0.
We note that since two dichotomic measurements are being considered here, the
parent measurement has only 22 = 4 outcomes, N = {N1,1, N1,2, N2,1, N2,2}. One
potential complication that we have introduced is that the problem is no longer an SDP as
written. This can however easily be rectified by making a small change of variables. In
particular, by defining ˜
N →a = (1 + r)N→a. This represents an unnormalised parent
measurement, since it satisfies the normalisation-type condition
∑
→a
˜
N →a = (1 + r)I.

(6.11
)
(6.12
a)
(6.12
b)
(6.12
c)
(6.12
d)
(6.12
e)
(6.13
a)
(6.13
b)
(6.13
c)
(6.13
d)
(6.13
e)
(6.13
f)
In terms of unnormalised parent measurements, the random robustness is indeed seen to
be an SDP, given by
minimise
r
subject to
Ma∣x + r I
2 = ∑
→a
δax,a ˜
N →a
∀a, x,
N→a ≽0
∀→a,
∑
→a
N→a = (1 + r)I,
r ⩾0.
It will be advantageous to simplify further, and use the equality constraints (6.12b)
and normalisation constraint (6.12d) to solve for all but one element of the unnormalised
parent measurement. This is carried out in exercise 6.1 below. There it is shown that we
arrive at the following equivalent SDP:
minimise
r
subject to
M1∣1 + r I
2 ≽˜
N 1,1,
M1∣2 + r I
2 ≽˜
N 1,1,
˜
N 1,1 ≽M1∣2 −M2∣1,
˜
N 1,1 ≽0,
r ⩾0.
We will continue studying this SDP in the ‘Advanced topics’ section 6.5.1. It will be
seen there that by studying its dual formulation, we uncover an interesting and surprising
quantitative connection to quantum nonlocality.
We will end this chapter by looking at the simplest example of measurement
incompatibility—a pair of Pauli measurements.
Example 6.1. Random robustness of Pauli X and Z measurements.
In this example we will explicitly solve the above SDP in order to find the
random robustness of Pauli X and Z measurements. In particular, this means we
consider

(6.14
)
(6.15
)
(6.16
)
(6.17
)
(6.18
)
M1∣1 =∣+⟩⟨+ ∣= I + X
2
,
M1∣2 =∣0⟩⟨0 ∣= I + Z
2
,
M2∣1 =∣−⟩⟨−∣= I −X
2
,
M2∣2 =∣1⟩⟨1 ∣= I −Z
2
,
with X =∣+⟩⟨+ ∣−∣−⟩⟨−∣=∣0⟩⟨1 ∣+ ∣1⟩⟨0 ∣ and Z =∣0⟩⟨0 ∣−∣1⟩⟨1 ∣.
It will be convenient to write ˜
N 1,1 in Bloch-vector notation, i.e. to write
˜
N 1,1 = μI + →ν ⋅→σ
2
,
where →σ = (X, Y , Z) is the vector of Pauli operators. This is convenient,
since the eigenvalues of any operator of the form →n ⋅→σ are λ± = ± ∥→n ∥2.
We will restrict our attention here to parent measurements N that have rank-1
POVM elements. Such measurements are extremal, and lie on the boundary of the
set of measurements. An optimal parent measurement will be extremal within the
feasible set of the SDP (as it true for all SDPs), however, due to the constraints of
the problem, it is not guaranteed that the feasible set contains rank-1 measurements.
It is nevertheless a reasonable assumption to try and seek such a solution.
Moreover, we will find such a solution if and only if the constraints (6.13b)—
(6.13e) are all saturated simultaneously. If we find a parent with rank-1 elements it
means that all of the inequalities can indeed be saturated simultaneously. If on the
other hand this weren’t possible, a contradiction would necessarily be run into, and
therefore we would have to revise the assumption.
With all of this in place, the final constraint (6.13e) in this instance is therefore
equivalent to
μ =∥→ν ∥2,
where we have imposed that this constraint is saturated, which implies that 
λ−= 0 and ˜
N 1,1 is a rank-1 operator.
Moving now to the first constraint (6.13b), after substituting both (6.16) and 
μ =∥→ν ∥2, and simplifying, we arrive at
(1 + r −μ)I + (1 −ν1, ν2, ν3) ⋅→σ ≽0.
Using 
the 
fact 
that 
the 
eigenvalues 
of 
(1 −ν1, ν2, ν3) ⋅→σ 
are 
λ± = ±√1 −2ν1+ ∥→ν ∥2
2, after further rearrangement and simplification we
arrive at
ν1 = 1
2 + (1 + r)(μ −1
2 (1 + r)).

(6.19
)
(6.20
a)
(6.20
b)
(6.21
)
(6.22
)
(6.23
)
(6.24
)
(6.25
a)
(6.25
b)
1
2 + ( + )(μ
2 ( + ))
By symmetry, it also follows immediately that (6.13c) is equivalent to
ν3 = 1
2 + (1 + r)(μ −1
2 (1 + r)),
= ν1.
Finally, applying the same technique, (6.13d) is readily shown to be equivalent
to
ν1 + ν3 = 1.
Given that in (6.20) we saw that ν1 = ν3, it immediately follows that
ν
*
1 = 1
2 ,
ν
*
3 = 1
2 ,
and therefore from (6.20) that
r = 2μ −1.
Our goal is to minimise r. The only freedom that remains is in ν2, and the
minimum value of r is easily seen to occur when ν
*
2 = 0, in which case μ =∥ν ∥2
is minimised, and equal to μ* =
1
√2 . Thus, we finally find
r* = √2 −1.
It is most insightful not to look at this value of robustness, but instead to look
at the parent measurement that achieves this robustness. After substituting
everything back in, we find that
N
*
1,1 = 1
2
I + X+Z
√2
2
,
N
*
1,2 = 1
2
I + X−Z
√2
2
,
N
*
2,1 = 1
2
I −X−Z
√2
2
,
N
*
2,2 = 1
2
I −X+Z
√2
2
.
This optimal parent measurement has a natural interpretation: with probability
1/2, a measurement of the observable X+Z
√2  is made, while with probability 1/2, 
X−Z
√2  is measured. These measurements can be thought of as trying to measure
‘superpositions’ of X and Z If the first measurement is performed and the outcome

(6.26
)
(6.27
)
(6.28
)
superpositions  of X and Z. If the first measurement is performed, and the outcome
+1 is observed, then the results for the X and Z measurements are set to (1, 1), since
the +1 eigenstate of X+Z
√2  has a large overlap with the +1 eigenstates of both X and
Z. Similarly, if the result −1 is observed, then the X and Z measurement results are
set to (−1, −1), for the same reason. In this way, although we do not manage to
reproduce the statistics of X and Z exactly, their ‘noisy’ versions are nevertheless
reproduced. In particular, the first child measurement of this parent has POVM
elements
M ′
1∣1 = N1,1 + N1,2 =
I +
X
√2
2
,
M ′
2∣1 = N2,1 + N2,2 =
I −
X
√2
2
.
This can be considered a noisy-X measurement since it can be thought of as
performing a measurement of X with probability 
1
√2  and producing a uniformly
random measurement outcome with probability 1 −
1
√2 .
We end by noting that this example highlights why joint measurability is a more
meaningful notion than commutativity for general (non-projective) measurements.
As can be easily seen, the noisy child measurements that the above parent leads to
do not commute. From the perspective of commutation, it would appear therefore
that they are not compatible. However, this conclusion is wrong, since they can be
jointly measured, by performing the above parent measurement.
Exercises
6.1 In this exercise, we will derive the SDP for the random robustness of two
dichotomic measurements as given in (6.13).
(a) Considering first the case →a = (1, 1), show that the constraint (6.12b)
implies that
˜
N 1,2 = M1∣1 + r I
2 −˜
N 1,1.
(b) Similarly, considering the case →a = (1, 2), show that the constraint
(6.12b) implies that
˜
N 2,1 = M1∣2 + r I
2 −˜
N 1,1.
(c) Verify that the cases →a = (2, 1) and →a = (2, 2) do not lead to any new
equations. Explain why this is the case.

(6.29
)
(6.30
a)
Hint: You will need to use the measurements Mx and ˜
N.
(d) Use the normalisation condition (6.12d), in conjunction with (6.27) and
(6.28) to show that
˜
N 2,2 = ˜
N 1,1 −M1∣2 + M2∣1
(e) Using your answers to parts (a), (b) and (d), and the fact that N→a ≽0
, show that the SDP (6.12) can be re-expressed as (6.13).
6.3 Concluding remarks
In this brief chapter we have studied measurement incompatibility in the most general
setting, considering arbitrary POVM measurements. The one key take-home message is
the following:
Measurement incompatibility. The problem of determining if a set of
measurements can be performed simultaneously can be determined by an SDP—see
equation (6.8).
6.4 Further reading
Heinosaari T, Miyadera T and Ziman M 2016 An invitation to quantum
incompatibility J. Phys. A: Math. Theor. 49 123001
6.5 Advanced topics
6.5.1 Measurement incompatibility and quantum nonlocality
In this section, we will present a surprising result, obtained through SDP duality: a pair of
dichotomic measurements is incompatibile if and only if they can be used to violate the
CHSH Bell inequality. That is, if they are incompatible, then there is a joint entangled
state that can be shared between two parties, and a pair of dichotomic measurements for
the second party, such that the statistics generated violate the CHSH Bell inequality.
Conversely, if the measurements are jointly measurable, then it is well known that they
can never lead to nonlocality, since both entanglement and incompatible measurements
are necessary in order to produce nonlocality.
Our starting point is to look at the dual formulation of (6.13), the SDP we found
previously for determining whether a pair of dichotomic measurements is compatible or
not. In exercise 6.2 it is shown that the dual of this SDP is given by
maximise
tr(Y M1∣2) −tr(WM1∣1) −tr(XM1∣2) −tr(Y M2∣1)
subject to
W + X = Y + Z,

(6.30
b)
(6.30
c)(6.30
d)
(6.31
)
(6.32
a)
(6.32
b)
(6.32
c)
(6.33
a)
(6.33
b)
(6.33
c)
tr(W + X) = 2,
W ≽0,
X ≽0,
Y ≽0,
Z ≽0.
In order to appreciate the significance of the dual formulation, we need to
understand the significance of the dual variables. It was shown previously in exercise
4.12 that an ensemble can be specified by a collection of subnormalised states, that sum
up to a normalised state. If we therefore consider σ1∣1 = W/2 and σ2∣1 = X/2, these can
be interpreted as specifying an ensemble ˜E 1 = {σ1∣1, σ2∣1}. Similarly, we could consider
σ1∣2 = Y /2 and σ2∣2 = Z/2, as specifying a second ensemble ˜E 2 = {σ1∣2, σ2∣2}. The
constraint (6.30b) then says something interesting—it says that these two ensembles lead
to the same average density operator.
Crucially, whenever we have two (or more) ensembles that have the same average
density operator, then they can always be created by performing appropriate
measurements on the same pure entangled state. That is, there are a pair of measurements
Q1 = {Q1∣1, Q2∣1} and Q2 = {Q1∣2, Q2∣2} and a bipartite quantum state ∣ψ⟩ such that
σa∣x = trB[(I ⊗Qa∣x) ∣ψ⟩⟨ψ ∣].
What this shows is that the optimisation in (6.30) can be interpreted as optimising
over the measurements Q1 and Q2 and the state ∣ψ⟩. The final step is to re-express the
objective function. We see, for example, that
tr(Y M1∣2) = 2 tr(σ1∣2M1∣2) = 2 tr(trB[(I ⊗Q1∣2) ∣ψ⟩⟨ψ ∣]M1∣2),
= 2 tr[(M1∣2 ⊗Q1∣2) ∣ψ⟩⟨ψ ∣],
= 2⟨ψ ∣(M1∣2 ⊗Q1∣2) ∣ψ⟩
The final form is a conditional joint probability—the probability of the pair of
outcomes (1, 1) when the measurements M2 and Q2 are performed on the first and
second systems, respectively, of the bipartite state ∣ψ⟩. These probabilities are precisely
those which occur in a Bell test, where distant measurements are performed on a shared
quantum state. We therefore arrive at the final form for (6.30), namely
maximise
2⟨ψ ∣(M1∣2 ⊗Q1∣2 −M1∣1 ⊗Q1∣1 −M1∣2 ⊗Q2∣1 −M2∣1 ⊗Q1∣2) ∣ψ⟩
subject to
Q1∣1 + Q2∣1 = I,
Q1∣1 + Q2∣1 = I,
Q1∣1 ≽0,
Q2∣1 ≽0,
Q1∣2 ≽0,
Q2∣2 ≽0,

(6.36
a)
(6.36
b)
(6.35
)
(6.33
d)
(6.33
e)
(6.34
)
⟨ψ ∣ψ⟩= 1.
Although this is no longer written as an SDP, it has an important interpretation.
This problem seeks to find the largest violation of the expression
β = 2[p(1, 1 ∣2, 2) −p(1, 1 ∣1, 1) −p(1, 2 ∣2, 1) −p(2, 1 ∣1, 2)]
where p(a, b ∣x, y) = ⟨ψ ∣(Ma∣x ⊗Qb∣y) ∣ψ⟩ optimised over all shared quantum
states ∣ψ⟩ and over all choices of measurements for Bob Q1 and Q2, but with fixed
measurements for Alice M1 and M2. Since strong duality holds, we have β* = r*, and
hence β* > 0 implies that the measurements M1 and M2 are incompatible, and that a
strictly positive amount of noisy needs to be added in order to make them jointly
measurable.
Although it may not be immediately obvious, the expression (6.34) is a Bell
expression—that arises in the study of quantum nonlocality. It is a linear combination of
probabilities, all of which can be obtained by performing measurements on a joint
entangled state.
In fact (6.34) is something very important indeed. It is the Clauser–Horne–Shimony–
Holt (CHSH) Bell inequality in disguise. This form is the so-called ‘CH form’, with
local-bound equal to 0. That is, any local-hidden-variable model that can produce
correlations of the form p(a, b ∣x, y) can never achieve of value greater than 0 in (6.34).
What this shows is that a pair of dichotomic measurements are incompatible if and
only if they can violate the CHSH Bell inequality, and can thus be used to demonstrate
nonlocality.
Exercises
6.2 In this exercise we will derive the dual SDP of (6.13).
Write down the Lagrangian associated to (6.13), associating dual
variables W, X, Y  and Z to the four constraints, in order.
Show that the Lagrangian lower bounds the primal objective value if all
the dual variables are positive semidefinite.
Show that the Lagrangian is independent of the primal variables if
W + X = Y + Z,
tr(W + Z) = 2.
Show therefore that the dual SDP is given by
maximise
tr(Y M1∣2) −tr(WM1∣1) −tr(XM1∣2) −tr(Y M2∣1)
subject to
W + X = Y + Z,
tr(W + Z) = 2,

)
(6.36
c)
(6.36
d)
tr(W + Z)
2,
W ≽0,
X ≽0,
Y ≽0,
Z ≽0.
Show that both the primal and dual SDPs are strictly feasible,
and hence that strong duality holds.
1Notice that we can always assume that the measurements have the same number of outcomes without loss of
generality, since, if they don’t, we can simply redefine them by adding null measurement operators (corresponding to
outcomes that never occur) until the number of outcomes coincide.

IOP Publishing
Semidefinite Programming in Quantum Information
Science
Paul Skrzypczyk and Daniel Cavalcanti

Chapter 7
Quantum channels
In the last chapter of this book we will study quantum channels—describing the
general evolution of a quantum state. We will see here, as in previous chapters, that
the tool of semidefinite programming (SDP) can be used to study a wide range of
problems involving quantum channels. The main ingredient that facilitates this is the
so-called Choi–Jamiołkowski isomorphism, which provides a mapping between
quantum channels and bipartite quantum states, which are then positive semidefinite
operators, and facilitate the use of SDP techniques.
We will begin by first summarising the key features of the Choi–Jamiołkowski
isomorphism before considering a number of simple applications. As in the previous
chapters on quantum states and quantum measurements, the most basic application is
that of channel estimation—which is often referred to as process tomography.
We will also show how duality can lead to some surprising results. In particular,
we will show that a natural question concerning quantum channels—to find the
maximal overlap of a quantum state when applying local quantum channels on one
side—in fact is given by the conditional min-entropy, a well-known quantity in
quantum information with applications in quantum cryptography. We will also see
how an important distinguishability measure on quantum channels—the diamond
norm—can be cast as an SDP, which then allows for many problems involving
approximation to be solved by SDP.
Finally, we will also see that a slightly more general object—a collection of sub-
channels (also often referred to as an instrument)—which captures probabilistic
transformations, i.e. post-measurement states, can also be studied using SDPs, and
outline a couple of simple examples to demonstrate this.
7.1 The Choi–Jamiołkowski isomorphism
The central ingredient that we need in order to use SDP to study problems involving
quantum channels is the Choi–Jamiołkowski isomorphism. Recall that a quantum
channel is a linear map from density operators to density operators, which is both
trace preserving and completely positive. That is, a channel Λ(⋅) will map the density
operator ρ to another density operator σ = Λ(ρ). Trace preservation ensures that σ has

(7.1)
(7.2)
(7.3)
(7.4)
tr(σ) = 1, as required to be a valid density operator. σ also needs to be a positive
operator. However, imposing that Λ(⋅) transforms positive matrices into positive
matrices is not enough: if ρ is actually the reduced state of a larger state ρAB such that 
ρ = trB(ρAB), then we should also impose that the final (bipartite) state is positive
semidefinite, i.e.
Λ ⊗id(ρAB) = σAB ≽0
for all ρAB,
where id(⋅) is the identity channel, that leaves all states unchanged, id(ω) = ω, for all
ω, and the dimension of B is arbitrary1. If a channel satisfies (7.1), we say that it is
completely positive.
The Choi–Jamiołkowski isomorphism states that there is a one-to-one mapping
between every quantum channel, and a subset of bipartite quantum states. In
particular, to any given channel Λ(⋅), we can associate the so-called Choi state XΛ,
through the relationship
XΛ = Λ ⊗id(∣Φ+⟩⟨Φ+ ∣),
where ∣Φ+⟩=
1
√d ∑i ∣i⟩∣i⟩ is the maximally entangled state (of two qudits).
Because Λ(⋅) is trace preserving and completely positive, XΛ is a valid density
operator, for any channel Λ(⋅), and therefore satisfies XΛ ≽0 and tr(XΛ) = 1. We
can see however that not all states can arise as Choi states. In particular, if we consider
tracing out the first subsystem, because the channel only acts locally on this system,
the reduced density operator of the second system must remain unchanged, and
therefore be the maximally mixed state, that is
trA(XΛ) = 1
d I.
The Choi–Jamiołkowski isomorphism says that the set of Choi states is in one-to-one
correspondence with the set of quantum channels. That is, given a density operator X,
satisfying trA(X) = 1
d I, then this uniquely specifies a completely positive and trace-
preserving quantum channel. The associated channel ΛX(⋅) is
ΛX(ρ) = dtrB[(I ⊗ρT)X],
where the transpose (which is basis-dependent) is taken in the basis of the maximally
entangled state used to define X.

(7.5)
(7.6)
(7.7)
(7.9)
(7.8)
Exercises
7.3 In this exercise, we will confirm that if we use the Choi state XΛ of a
channel Λ(⋅), then the channel ΛXΛ(⋅) defined through (7.4) is indeed just 
Λ(⋅), as required.
(a) By substituting the definition of the maximally entangled state, show
that the Choi state can alternatively be written as
XΛ = 1
d ∑
i,j
Λ(∣i⟩⟨j ∣)⊗∣i⟩⟨j ∣.
(b) Substitute XΛ (in the form from (7.5)) into (7.4), to show that 
ΛXΛ(⋅) = Λ(⋅).
7.4 In this exercise we will study another representation of quantum
channels, in terms of so-called Kraus operators.
(a) Show that any map of the form
Λ(ρ) = ∑
a
KaρK †
a,
is completely positive, for any set of operators {Ka}, for 
a = 1, … , N. The operators Ka are called Kraus operators, and this
decomposition is known as the Kraus decomposition of the map.
(b) Show that in order to be trace preserving the Kraus operators must
satisfy
∑
a
K †
aKa = I.
(c) Combining (7.2) and the Kraus decomposition (7.6), show that the
Choi state can be written as
XΛ = 1
d ∑
i,j,a
Ka ∣i⟩⟨j ∣K †
a⊗∣i⟩⟨j ∣.
7.5 In this exercise we will consider a special class of completely positive
maps called unital maps. Consider the dual map Λ†(⋅) of a completely
positive trace preserving map Λ(⋅), that is, the unique map that satisfies
tr[MΛ(ρ)] = tr[Λ†(M)ρ],
for all operators ρ and M.

(7.10
)
(7.12
)
(7.11
)
(7.13
)
(a) Show that Λ†(⋅) is completely positive if and only if Λ(⋅) is
completely positive.
(b) Show that Λ†(⋅) satisfies the unitality condition
Λ†(I) = I,
if and only if Λ(⋅) is trace preserving.
The physical significance of this is that the dual map is also
normalisation-preserving, but now in the Heisenberg representation.
In particular, this condition ensures that a valid (normalised)
measurement remains normalised after application of the (dual)
channel 
Λ†(⋅). 
That is, 
M′= {M ′
a} 
with 
M ′
a = Λ†(Ma)
is a valid POV M whenever M = {Ma} is a valid POV M.
(c) Show that if a map Λ†(⋅) is completely positive and unital, then the
corresponding Choi state satisfies
XΛ† ≽0,
trB(XΛ†) = 1
d I.
7.6 In this exercise we will consider more general maps than quantum
channels, i.e. linear maps which need not be either completely positive nor
trace preserving. We will however require all maps to preserve hermiticity,
i.e. to keep the output Hermitian (since the input will always be assumed to
be a density operator, which is therefore Hermitian).
(a) Show that if a map Γ(⋅) is trace non-increasing, meaning that 
tr[Γ(σ)] ⩽tr[σ] for all states σ, then the associated Choi state will
satisfy
trA(XΓ) ≼1
d I.
(b) Show that if a map Γ(⋅) is can be written as the difference of
two quantum channels, Γ(⋅) = Λ(⋅) −Ω(⋅), then
trA(XΓ) = 0.
We now have enough background in place in order to show how the Choi–
Jamiołkowski isomorphism allows for problems involving quantum channels to be

(7.14
a)
(7.14
b)
(7.14
c)
(7.14
d)
(7.15
a)
(7.15
b)
(7.15
c)
(7.15
d)
cast as SDPs. We will make this explicit through the use of an example, that of
channel estimation.
7.2 Channel estimation
In this section we will consider a natural problem, that of channel estimation, which is
the analogue of state estimation from chapter 3 and measurement estimation from
chapter 4. Consider a situation where one has access to a channel, which is yet to be
characterised. The only knowledge about the channel that one has is its action on a
fixed set of input states. That is, one has access to the data {ρi, σi} for i = 1, … , N,
such that Λ(ρi) = σi. The goal is to determine whether or not this data is consistent
with a completely positive and trace preserving channel (or possibly a set of
channels), and to find a channel able to reproduce the results, if it exists. This is
therefore an instance of a feasibility problem, which can be written as
find
Λ(⋅)
subject to
Λ(ρi) = σi
i = 1, … , N,
tr[Λ(ω)] = 1
for all ω,
Λ ⊗id(ωAB) ≽0
for all ωAB.
As written, this feasibility problem may appear to be rather complicated, due to
the final two constraints—enforcing trace preservation and complete positivity—
which must hold for all states, either on the space on which the channel acts, or on all
bipartite states. However, using the Choi–Jamiołkowski isomorphism from the
previous section, we see that the problem can be recast in terms of the set of Choi
states (of the unknown channel Λ(⋅)), which turns the two constraints into SDP
constraints. In particular, we can recast (7.14) as the following SDP
find
X
subject to
dtrB[(I ⊗ρiT)X] = σi
i = 1, … , N,
trA(X) = 1
d I,
X ≽0.
In this formulation, we have rephrased the three constraints (7.14b)–(7.14d) in
terms of Choi states in (7.15b)–(7.15d), all of which are now linear equality or
inequality constraints.

(7.16
a)
(7.16
b)
(7.16
c)
(7.16
d)
(7.17
a)
(7.17
b)
(7.17
c)
(7.17
d)
(7.17
e)
As is often the case, it is interesting and important to relax this problem to an
optimisation form, rather than the natural feasibility form. A natural way to do this is
to allow the constraints to be relaxed. Here, we could seek to find the channel which is
best able to produce the target output states σi given the input states ρi. That is, one
possible relaxation is
minimise
δ
subject to
∥Λ(ρi) −σi ∥1⩽δ
i = 1, … , N,
tr[Λ(ω)] = 1
for all ω,
Λ ⊗id(ωAB) ≽0
for all ωAB,
where we seek to minimise the largest discrepancy between the output of the
channel on any of the input states ρi and the target σi, as quantified by the natural
distance measure on states—the trace distance. As shown in exercise 7.7, this can be
cast as the following SDP
minimise
δ
subject to
tr(Yi) ⩽δ
i = 1, … , N,
−Yi ≼dtrB[(I ⊗ρiT)X] −σi ≼Y i
i = 1, … , N,
Yi ≽0,
i = 1, … , N,
trA(X) = 1
d I,
X ≽0.
Exercises
7.7 Use the SDP formulation of the trace norm from (2.8) to show that
(7.16) can be cast as the SDP (7.17).
7.8. In this exercise we will consider a relaxed version of (7.14).
Instead of knowing exactly the output of the channel when the input
state is ρi, it is natural to assume that it is known up to some
precision. This can be modelled by enforcing that the output is not
equal to σi, but only close to it in trace distance, i.e. we have the
constraints
∥Λ(ρi) −σi ∥1⩽ϵ,

7.3 The diamond norm and channel discrimination
In this section we will now consider the most natural norm when considering quantum
channels, known as the diamond norm, and the associated distance measure between
quantum channels. This norm can be defined operationally, in analogy to how the
trace norm inherits an operational interpretation through the trace distance. This is
how we will introduce it here.
Recall that, as seen in section 4.2.2, when considering binary state discrimination,
it is the trace distance T(ω, σ) = 1
2 ∥ω −σ ∥1 that determines the probability of
distinguishing between ω and σ, when performing an optimal measurement for state
discrimination. We saw there that P
*
guess = 1
2 [1 + T(ω, σ)]. This showed us that the
trace distance, and therefore trace norm, were not only mathematically meaningful
definitions, but physically and operationally motivated ones. In order to arrive at a
good norm for channels, we will use this as the key inspiration.
(7.18
)
(7.19
a)
(7.19
b)
(7.19
c)
(7.19
d)
(7.19
e)
(7.19
f)
where ϵ quantifies the uncertainty of the output of the channel, and
should be considered as input data into the problem.Using the
SDP characterisation of the ϵ trace norm ball from exercise 2.17,
show that the relaxed feasibility problem can be written as
find
X
subject to
dtrB[(I ⊗ρiT)X] −σi = Zi −Yi
i = 1, … , m,
tr(Zi −Yi) = ϵ
i = 1, … , N,
Zi ≽0,
Yi ≽0,
i = 1, … , N,
trA(X) = 1
d I,
X ≽0.
7.9 Explain how exercise 7.8 can be used to find an alternative
formulation of the relaxation (7.16), and conversely how (7.17) can
equally be use to find an alternative SDP formulation applicable for
exercise 7.8.

(7.20
a)
(7.20
b)
(7.20
c)
(7.21
a)
(7.21
b)
(7.21
c)
(7.22
)
With this in mind, we can therefore consider the task of channel discrimination,
whereby we are given either the channel Λ(⋅) or Ω(⋅) (with equal probability), and
wish to guess, as best as possible, which channel was given. Whereas in state
discrimination all that could be done was to measure the states, in channel
discrimination we need to consider both the state ρ that will be input into the channel,
and the (binary) measurement M = {(I + Z)/2, (I −Z)/2} that will be used to
discriminate between the output states. Crucially, we will allow ourselves to send only
part of a bipartite state through the channel, in order to help distinguish between the
two channels as best as possible.
It is helpful to realise, given the way the problem has been formulated above, that
we can think of channel discrimination in two parts; first, for a fixed input state ρ, we
end up with a binary state discrimination problem between the two states Λ ⊗id(ρ)
and Ω ⊗id(ρ); second, since we can choose the input state, this varies the binary state
discrimination problem (which concerns the output states of the channel), and so to
optimally discriminate the channels, we can optimise over all binary state
discrimination tasks that the two channels give us access to.
Given the above, we can define the average success probability in correctly
guessing which of the two channels was given, in direct analogy to (4.12), by
P
*
guess = maximise
1
2 + 1
4 tr[Z(Λ ⊗id(ρ) −Ω ⊗id(ρ))]
subject to −I ≼Z ≼I,
ρ ≽0,
tr[ρ] = 1,
and therefore define the diamond norm of a map by
∥Γ(⋅) ∥⋄= maximise
tr[Z(Γ ⊗id(ρ))]
subject to
−I ≼Z ≼I,
ρ ≽0,
tr(ρ) = 1,
and associated diamond norm distance by
D⋄(Λ(⋅), Ω(⋅)) = 1
2 ∥Λ(⋅) −Ω(⋅) ∥⋄.
With these definitions, the diamond norm distance, by construction, has the same
operational interpretation as the trace distance; it quantifies how well two channels
can be distinguished in binary channel discrimination.

(7.23
a)
(7.23
b)
(7.23
c)
(7.24
a)
(7.24
b)
(7.24
c)
(7.24
d)
(7.25
a)
(7.25
b)
(7.25
c)
As written in (7.21), the diamond norm is not an SDP, since the objective function
is a nonlinear function, containing a product of the variables Z and ρ. However, as
will be shown in section 7.7, we can in fact recast the diamond norm so that it is given
by the following SDP:
∥Γ(⋅) ∥⋄= maximise
tr[Y XΓ]
subject to −d(I ⊗σ) ≼Y ≼d(I ⊗σ),
σ ≽0,
tr(σ) = 1,
where XΓ is the Choi state2 associated to Γ(⋅), and d is the dimension of the
Hilbert space on which the channel acts. In exercise 7.10 it is shown that the dual SDP
of (7.23) is given by
∥Γ(⋅) ∥⋄= minimise
μ
subject to
XΓ = Z2 −Z1,
Z1 ≽0,
Z2 ≽0,
μI ≽d(trA[Z1 + Z2]),
where we note that Z1 and Z2 are operators on the bipartite Hilbert space 
HA ⊗HB.3
In 
(7.24) 
it 
can 
be 
seen 
that 
μ 
is 
minimised 
when 
equal 
to 
μ* = d ∥trA[Z1 + Z2] ∥∞, and that this value can always be attained. Therefore, we
can equivalently express the diamond norm as
∥Γ(⋅) ∥⋄= minimise
d ∥trA[Z1 + Z2] ∥∞
subject to
XΓ = Z2 −Z1,
Z1 ≽0,
Z2 ≽0.
It is important at this point to make a couple of notes. First, although our initial
motivation was to measure the distance between quantum channels, the diamond norm
is in fact defined on more general quantum maps (as considered in exercise 7.8), i.e.
linear operations which act on the space of (Hermitian) operators and produce
(Hermitian) operators. In particular, we are interested in maps of the form 
Γ(⋅) = Λ(⋅) −Ω(⋅), which are the difference of two quantum channels. Such maps
will in general be neither completely positive nor trace preserving. Nevertheless, the

(7.26
a)
(7.26
b)
(7.27
a)
(7.27
b)
diamond norm is well defined on such maps, and equals the objective value of the
(primal or dual) SDPs given.
Conversely, if we do consider a completely positive and trace preserving map Λ(⋅)
with corresponding Choi state XΛ, then it necessarily has unit diamond norm, 
∥Λ(⋅) ∥⋄= 1. To see this, note first that in the primal SDP (7.23) if Y = IAB and 
σ = IB/d are picked as primal variables, then they can easily be seen to be feasible,
satisfying −IAB ≼Y ≼IAB, and therefore ∥Λ(⋅) ∥∞⩾tr(XΛ) = 1. 
The
inequality follows since we have no guarantee that this choice of primal variables is
optimal. On the other hand, in the dual SDP (7.25) a feasible set of variables is to take
Z2 = XΛ ≽0, and Z1 = 0. In this case, ∥trA(Z2) ∥∞=∥I/d ∥∞= 1
d , and
therefore ∥Λ(⋅) ∥⋄⩽1, where again the inequality follows due to the dual variables
being potentially sub-optimal. However, the lower and upper bounds on the diamond
norm of the channel match, and hence we conclude that it must be equal to unity (and
furthermore that the variables picked are optimal for both the primal and dual SDPs
respectively).
As a second note, we can also use the dual formulation (7.24) to define two
interesting sets of maps, both of which can then be optimised over inside SDPs. First
of all, we can simply define the unit diamond norm ball, i.e. all maps which satisfy 
∥Γ(⋅) ∥⋄⩽1. In particular, this is given by
B⋄= {Γ(⋅) ∣∥Γ(⋅) ∥⋄⩽1},
= {Γ(⋅) ∣XΓ = Z2 −Z1, Z1 ≽0, Z2 ≽0, I ≽d(trA[Z1 + Z2])}.
The second interesting set is the set of quantum channels that are ϵ close to a
target quantum channel Λ(⋅). That is, the set Bϵ,Λ
⋄ of channels Ω(⋅) such 
∥Λ(⋅) −Ω(⋅) ∥⋄⩽ϵ. This can similarly be specified as
Bϵ,Λ
⋄
= {Ω(⋅) ∣∥Λ(⋅) −Ω(⋅) ∥⋄⩽ϵ},
= {Ω(⋅) ∣XΛ −XΩ = Z2 −Z1, Z1 ≽0, Z2 ≽0, ϵI ≽d(trA[Z1 + Z2]),
XΩ ≽0, trA(XΩ) = I/d}.
As a simple example of a problem where this set arises is to return to the problem of
channel estimation from the previous section. Consider now a variant of channel
estimation where we would like to know if there is any channel which approximates a
fixed target channel Λ(⋅) and that is also able to reproduce the input–output data
given. Here, we can take approximation to mean that the channel sought after should

(7.28
a)
(7.28
b)
(7.28
c)
(7.28
d)
(7.28
e)
(7.29
a)
(7.29
b)
(7.29
c)
(7.29
d)
(7.29
e)
(7.29
f)
be ϵ close to Λ(⋅) in diamond norm. Formally, the feasibility problem to be solved is
therefore
find
Ω(⋅)
subject to
Ω(ρi) = σi
i = 1, … , N,
∥Λ(⋅) −Ω(⋅) ∥⋄⩽ϵ
tr[Ω(ω)] = 1
for all ω,
Ω ⊗id(ωAB) ≽0
for all ωAB.
Using the characterisation of Bϵ,Λ
⋄ from (7.27b), this can be expressed as the
following feasibility SDP
find
XΩ
subject to
dtrB[(I ⊗ρiT)XΩ] = σi
i = 1, … , N,
XΛ −XΩ = Z2 −Z1,
Z1 ≽0,
Z2 ≽0,
ϵI ≽d(trA[Z1 + Z2]),
XΩ ≽0,
trA(XΩ) = 1
d I.
Exercises
7.10 In this exercise we will derive the dual formulation (7.24) of the
diamond norm.
(a) Write down the Lagrangian associated to the primal SDP
(7.23), associating dual variables Z1 and Z2 to the left-hand and
right-hand constraints in (7.23b), and associating Z3 and μ to the
first and second constraints in (7.23c).
(b) Identify the constraints that need to be satisfied by the dual
variables so that the Lagrangian both upper bounds the value of
the primal objective function, and is independent of the primal
variables Y  and σ.
(c) Use part (b) to write down the dual formulation of the
diamond norm.

(7.30
a)
(7.30
b)
(d) Show that Z3 is a slack variable, and therefore simplify the
dual to arrive at (7.24).
7.11 Find an SDP representation of the diamond norm ϵ ball, that is,
the set of maps Bϵ
⋄= {Γ(⋅) ∣∥Γ(⋅) ∥⋄⩽ϵ}, analogous to (7.26b).
7.12 The SDP (7.29) can be simplified, by noting that Z1 is a slack
variable. Solve for Z1 to obtain a simplified SDP formulation of
(7.29).
7.13 The feasibility problem (7.28) can be relaxed to an optimisation
problem, by finding the minimal ϵ for which there is a solution. Write
down the associated SDP formulation of this problem.
7.4 The conditional min-entropy and the singlet fidelity
We now turn our attention to a second problem concerning channels, and show that
the duality of SDPs allows us to uncover an operational interpretation of an entropic
quantity known as the conditional min-entropy which at first sight has no obvious
physical or operational interpretation.
The question which we will study is how close is a given bipartite quantum state
ρAB to being maximally entangled? In chapter 3 several notions of distances between
quantum states were studied. Here we will choose to measure closeness using the
fidelity, introduced in section 3.1.2. The fidelity between ρAB and the maximally
entangled state ∣Φ+⟩=
1
√d ∑i ∣i⟩∣i⟩ could be measured directly, that is, 
F(ρAB, ∣Φ+⟩⟨Φ+ ∣) = ⟨Φ+ ∣ρAB ∣Φ+⟩. However there is an obvious drawback to
this—namely the fact that the (local) basis in which the maximally entangled state 
∣Φ+⟩ was defined is completely arbitrary. This means we might underestimate how
entangled the state is, simply because of a mismatch between the basis used to
measure the entanglement in. We therefore might want to consider instead
FΦ+(ρAB) = maximise
F(ρAB, (U ⊗V ) ∣Φ+⟩⟨Φ+ ∣(U † ⊗V †))
subject to
U †U = I,
V †V = I.
We will refer to this quantity as the singlet fidelity4. That is, to optimise over
local unitary operators U and V , in order to change the basis of the maximally
entangled state ∣Φ+⟩. However, as proven in exercise 7.14, the maximally entangled
state ∣Φ+⟩ has an important invariance, namely that for any operator A,
(A ⊗I) ∣Φ+⟩= (I ⊗AT) ∣Φ+⟩,

(7.31
)
(7.32
a)
(7.32
b)
(7.32
c)
(7.33
a)
(7.33
b)
(7.33
c)
where, as always, the transpose is in the basis of the maximally entangled state. Using
this fact, in exercise 7.14 it is shown that it isn’t necessary to optimise over local
unitaries on both particles, but to consider only local unitaries on a single particle,
which we take to be the first. Physically, this shows that it is possible to change the
basis of both particles of the maximally entangled state just by applying local unitaries
on one particle. We can therefore set V = I without any loss of generality in (7.30),
and achieve the same fidelity with the maximally entangled state.
It will be interesting to go one step further, and to allow for more general channels
to be applied on the first particle, in order to obtain a one-sided optimised singlet
fidelity. That is, on top of any unitary transformation U—whose purpose is to change
the basis of ∣Φ+⟩—we will moreover consider instead of the singlet fidelity of ρAB,
rather the singlet fidelity of Λ ⊗id(ρAB) optimised over all channels Λ(⋅).
This is rather natural, and it allows for the most general (one-sided) manipulation
of the state to be performed. Such a procedure cannot generate entanglement, since it
is clearly an LOCC operation (in fact, it doesn’t even involve any classical
communication). Hence, the utility of such a local processing is to allow for a better
assessment of the entanglement contained in the state ρAB. Since the change of basis
unitary U can be incorporated into the channel Λ(⋅), and since we are optimising over
channels, the quantity of interest is thus
F (A)
Φ+ (ρAB) = maximise
⟨Φ+ ∣Λ ⊗id(ρAB) ∣Φ+⟩
subject to
tr[Λ(ω)] = 1
for all ω,
Λ ⊗id(ωAB) ≽0
for all ωAB,
where we denote by F (A)
Φ+ (ρAB) the one-sided optimised singlet fidelity. We
could now proceed as before, and use the Choi state of Λ(⋅) to re-express this
problem. However, since the objective function already involves ∣Φ+⟩ (which
appears in the definition of the Choi state), there is an alternative route, which turns
out to be more useful. In particular, we can notice that the objective function can be
written as
⟨Φ+ ∣Λ ⊗id(ρAB) ∣Φ+⟩= tr[(Λ ⊗id(ρAB)) ∣Φ+⟩⟨Φ+ ∣],
= tr[ρAB(Λ† ⊗id(∣Φ+⟩⟨Φ+ ∣))],
= tr[ρABXΛ†],

(7.34
a)
(7.34
b)
(7.34
c)
(7.35
a)
(7.35
b)
(7.35
c)
where in the second line we used the definition of the adjoint map Λ†(⋅) to move the
channel from ρAB to ∣Φ+⟩, and in the third line we have then used the fact that this is
precisely the definition of the Choi state for the (adjoint) map Λ†(⋅).
As was shown in exercise 7.5, the adjoint Ω†(⋅) of quantum channel Ω(⋅), is a
completely positive unital map, i.e. one which has the maximally mixed state as a
fixed point, Ω†(I/d) = I/d. In terms of the Choi state, it was also shown that this is
equivalent to trB(XΩ†) = I/d (and XΩ† ≽0, which maintains the complete
positivity of Ω(⋅)). Putting all of these ingredients together, we therefore see that
(7.32) can be expressed explicitly as an SDP, in terms of the Choi state of Λ†(⋅), as
follows5:
maximise
tr[ρABXΛ†]
subject to
trB[XΛ†] = 1
d I,
XΛ† ≽0.
As we can see, the final form of the SDP, in terms of the Choi state, is
remarkably different from the original formulation in terms of the channel.
Nevertheless, it is just a re-expression, and one that can be used in practice to compute
the optimised singlet fidelity of a state. As we will now see, there is a second
advantage of this SDP formulation, namely that its dual formulation provides
surprising links to a seemingly unrelated quantities.
As shown in exercise 7.5, the dual formulation of (7.34) is
minimise
1
d tr(Y )
subject to
ρAB + Z = Y ⊗I,
Z ≽0.
As is also shown in exercise 7.5, both the primal and dual problems are strictly
feasible, so strong duality holds, and this is a dual formulation of the optimised singlet
fidelity.
We can now proceed in two ways, both of which are interesting. The first way is
to realise that (7.35) can be seen as a type of generalised robustness, as has been seen
many times before. In particular, we can first note that since ρAB ≽0 (by
assumption), and Z ≽0, due to (7.35c), it must be the case that Y ≽0, since

(7.36
)
(7.37
)
(7.38
a)
(7.38
b)
(7.38
c)
(7.38
d)
otherwise it is impossible for the equality constraint (7.35b) to hold. We can therefore
interpret each of these dual variables as (unnormalised) quantum states and define
ω =
Z
tr(Z) ,
σ =
Y
tr(Y ) .
If we further define r = tr(Z), then taking the trace of the equality constraint
(7.35b), it is seen that
tr(Y ) = 1 + r
d
.
Altogether this allows us to re-express the dual SDP (7.35) as the following
problem:
minimise
1 + r
d2
subject to
ρAB + rω
1 + r
= σ ⊗I
d ,
ω ≽0,
tr(ω) = 1,
σ ≽0,
tr(σ) = 1.
The constraints in (7.38) collectively show that this problem—which is no longer
written in the form of an SDP—can be interpreted as a generalised robustness. In
particular, we can interpret ω as the (generalised) noise which must be added to the
state ρAB, in order to bring it to a form where it is a product state and its B system has
become maximally mixed. The only small difference is that whereas previously we
have been interested in the minimal value of r, now we are interested in the value 1+r
d2
instead, which is merely an affine function of r.
What this shows then is that—through duality—we can see that the one-sided
optimised singlet fidelity F (A)
Φ+ (ρAB) of a state ρAB, namely the largest fidelity that
can be achieved with a maximally entangled state when optimising over channels on
the first system, is in fact equal to the (generalised) robustness of the state to being
product and having the second system completely mixed. We hope you will agree that,
a priori, there seems to be no obvious reason why these two quantities should be
related in any way, however through duality, we find the remarkable fact that they are
one and the same thing.
The second way to proceed is to return to the dual SDP (7.35) and to simplify it
slightly by realising that Z is a slack variable that can be removed. This allows us to

(7.39
a)
(7.39
b)
(7.40
)
(7.41
a)
(7.41
b)
(7.42
a)
(7.42
b)
(7.43
a)
(7.43
b)
re-express (7.35) as
minimise
1
d tr(Y )
subject to ρAB ≼Y ⊗I.
In this form, we can now recognise the similarity to the definition of a well-
known quantity from quantum information, namely the conditional min-entropy.
Before jumping straight to this definition, we recall first that the conditional von
Neumann entropy S(A ∣B)ρ can be defined two ways; either directly in terms of the
von Neumann entropy as
S(A ∣B)ρ = S(ρAB) −S(ρB),
where S(ρ) = −tr(ρ log ρ) is the von Neumann entropy; or as a variational
expression in terms of the relative entropy as
S(A ∣B)ρ = −minimise
D(ρAB ∥I ⊗σ)
subject to
σ ≽0,
tr(σ) = 1,
where D(ρ ∥ω) = tr(ρ(log ρ −log ω)) is the quantum relative entropy, and we
have used red for the variables, as we are interested in relating to the dual formulation
of the optimised singlet fidelity (7.35). It is this second form which generalises to
other entropies. In particular, the so-called min conditional entropy Hmin(A ∣B)ρ is
defined in terms of the max relative entropy6 Dmax(ρ ∥ω), through the analogous
equation
Hmin(A ∣B)ρ = −minimise
Dmax(ρAB ∥I ⊗σ)
subject to
σ ≽0,
tr(σ) = 1,
where
Dmax(ρ ∥ω) = minimise
λ
subject to
ρ ≼2λω.
In exercise 7.16, it is shown that (7.42) and (7.43) can be combined, in order to
give a more direct variational expression for Hmin(A ∣B)ρ, and that furthermore,
after introducing new variables,

(7.44
a)
(7.44
b)
(7.44
c)
(7.45
)
(7.46
)
Hmin(A ∣B)ρ = −log minimise
tr(W)
subject to
ρAB ≼I ⊗W
W ≽0.
We are now finally in a position to compare with (7.39). We have arrived at an
expression for the conditional min-entropy which is very similar to the expression
previously obtained for the dual of the optimised singlet fidelity. The first seemingly
important difference is that the constraint is of the form ρAB ≼I ⊗W rather than 
ρAB ≼Y ⊗I, however this simply means that the roles of A and B have been
interchanged. The other difference is the additional constraint in (7.44) demanding
that W ≽0, which is not present in (7.35). However, as was argued previously,
given that ρAB ≽0, it follows that any feasible W will satisfy W ≽0, otherwise
(7.44b) cannot be satisfied. We can therefore conclude that the two problems are
optimising over the same feasible set (up to the permutation of systems), and therefore
we obtain the remarkable result that
Hmin(B ∣A)ρ = −log [dF (A)
Φ+ (ρAB)].
This shows that the conditional min-entropy is a function of the optimised singlet
fidelity of a state, and this provides an operational interpretation of the quantity.
In the example below, this quantity will be further studied, specialising to a
quantum–classical state, and it will be seen that it reduces to a conditional guessing
probability. Before doing so, we note that the conditional min-entropy—like the
conditional (von Neumann) entropy S(A ∣B)ρ—can be negative. In fact, from (7.45),
the conditional min-entropy will be negative whenever
F (A)
Φ+ (ρAB) > 1
d ,
that is, whenever the state ρAB is sufficiently entangled such that its optimised
singlet fidelity is above 1
d . As we show in exercise 7.17, only entangled states have
this property, and hence Hmin(B ∣A)ρ < 0 can also be interpreted as an entropic
entanglement witness.
Example 7.1. The conditional min-entropy of classical-quantum states.

(7.47
)
(7.48
a)
(7.48
b)
(7.48
c)
(7.48
d)
(7.48
e)
In this example we will consider a special class of bipartite quantum states,
known as ‘quantum–classical states’, which take the form
ρAX = ∑
x
p(x)ρx
A⊗∣x⟩⟨x ∣,
where we use X to label the second Hilbert space (rather than B), in order
to emphasise that this quantum system encodes a classical random variable X
(such that the probability that X takes on value x is p(x)), i.e. is diagonal in the
basis {∣x⟩}, and the diagonal entries are the classical probabilities p(x). Such
states exhibit purely classical correlations between the classical random variable
X, and the quantum states ρx
A. In this example, we are interested in computing
the conditional min-entropy Hmin(X ∣A) of such states, that is, the conditional
min-entropy of the classical part of the state, conditioned on the quantum part of
the state.
Calculating directly using (7.44) is rather complicated in general, so we will
instead use (7.45), and thus calculate the optimised singlet fidelity F (A)
Φ+ (ρAX)
instead. Going all the way back to (7.32), for a fixed channel Λ(⋅), we see that
⟨Φ+ ∣Λ ⊗id(ρAX) ∣Φ+⟩= ⟨Φ+ ∣(∑
x
p(x)Λ(ρx
A)⊗∣x⟩⟨x ∣) ∣Φ+⟩,
= 1
d ∑
i
⟨i ∣⟨i ∣(∑
x
p(x)Λ(ρx
A)⊗∣x⟩⟨x ∣) ∑
j
∣j⟩∣j⟩,
= 1
d ∑
x
p(x)⟨x ∣Λ(ρx
A) ∣x⟩,
= 1
d ∑
x
p(x) tr[Λ(ρx
A) ∣x⟩⟨x ∣],
= 1
d ∑
x
p(x) tr[ρx
AΛ†(∣x⟩⟨x ∣)].
In the above, in the first line we substituted the definition of the quantum–
classical state; in the second line we substituted for the definition of ∣Φ+⟩; and
in the third we performed the inner products and simplified. Finally, in the
fourth and fifth line we first expressed the expectation value as a trace, and then

(7.49
a)
(7.49
b)
(7.50
)
used the definition of the adjoint map to move the action of Λ(⋅) onto the
projector ∣x⟩⟨x ∣.
In the final line, an important realisation can be made. Since Λ†(⋅) is a
completely positive unital map, it maps measurements to measurements. That is,
given any measurement M = {Mx}, a new measurement M′= {M ′
x} with
POVM elements M ′
x = Λ†(Mx) we can formed, using any completely positive
unital map Λ†(⋅). Moreover, as shown in exercise 7.18 any d outcome
measurement acting on a d-dimensional Hilbert space can be formed by
applying a completely positive unital map to an ideal projective measurement of
the form M = {∣x⟩⟨x ∣}.
When considering optimising over all channels Λ(⋅), we can now use the
above realisation to re-express this as an optimisation over all d-outcome
measurements M. That is, for quantum–classical states, an equivalent
formulation of the optimised singlet fidelity is
F (A)
Φ+ (ρAX) = maximise
1
d ∑
x
p(x) tr[ρx
AMx]
subject to
Mx ≽0,
∑
x
Mx = I.
This is however exactly the same problem (up to the factor of 1
d ) that was
encountered previously in chapter 4, namely this is quantum state
discrimination, as given in (4.9). That is to say that we can view the quantum–
classical state (7.47) as encoding a quantum state discrimination task, and see
that the optimised singlet fidelity of this state is nothing but 1
d P
*
guess, i.e. it is up
to the factor of 1
d  the guessing probability in quantum state discrimination that
was previously studied.
Combining this with (7.45), we obtain the important result that for quantum–
classical states,
Hmin(X ∣A)ρ = −log P
*
guess,
that is, the conditional min-entropy is precisely the log of the guessing
probability. We can view the quantum states ρx
A as quantum side information
about the classical variable X. The conditional min-entropy is the (conditional)
guessing probability of correctly identifying the value of the random variable X.
This shows that the optimised singlet fidelity F (A)
Φ+ (ρAB) can be viewed as a

(7.51
)
(7.52
a)
Exercises
7.14
(a) Show that the maximally entangled state ∣Φ+⟩=
1
√d ∑i ∣i⟩∣i⟩
has the following invariance property:
(A ⊗I) ∣Φ+⟩= (I ⊗AT) ∣Φ+⟩,
for any operator A, where T denotes transpose in the basis of 
∣Φ+⟩. Hint: One way to show this is to consider the matrix elements
of the left- and right-hand side, and so show that they are equal.
(b) Using (7.51), show that all of the states that ∣Φ+⟩ can be
transformed into by local unitaries on both systems, i.e. all states of
the form (U ⊗V ) ∣Φ+⟩, can be reached by considering unitaries on
the first system alone, i.e. by transformations of the form 
(W ⊗I) ∣Φ+⟩, for W a unitary operator.
7.15 In this exercise we will derive the dual formulation of (7.34), as given
in (7.35).
(a) Write down the Lagrangian associated with (7.34), calling the dual
variables corresponding to the first and second constraint respectively 
Y  and Z.
(b) Use the Lagrangian to derive the dual formulation (7.35).
(c) Show that both the primal (7.34) and dual (7.35) are strictly
feasible, and hence that strong duality holds.
7.16 In this exercise we will show how (7.42) and (7.43) can be combined,
in order to give a more direct variational expression for Hmin(A ∣B)ρ as
given in (7.44).
(a) Show that by combining (7.42) and (7.43) directly, one obtains the
following optimisation problem for Hmin(A ∣B)ρ:
Hmin(A ∣B)ρ = −minimise
λ
fully quantum generalisation of this guessing task. That is, the generalisation of
guessing the value of a random variable can be thought of as maximising the
(quantum) correlation—i.e. entanglement—between the system

(7.52
b)
(7.52
c)
(7.53
a)
(7.53
b)
(7.53
c)
(7.54
a)
(7.56
)
(7.54
b)
(7.55
)
subject to
ρAB ≼2λI ⊗σ,
σ ≽0,
tr(σ) = 1,
This is not an SDP, since (i) the variable λ appears in the
exponent of the first constraint; (ii) The variables λ and σ appear
multiplied together.
(b) Introduce the new variable W = 2λσ. Show that (7.52) can be re-
expressed solely in terms of W, as
Hmin(A ∣B)ρ = −minimise
log[tr(W)]
subject to
ρAB ≼I ⊗W,
W ≽0.
(c) Explain why minx log(x) = log(minxx), and use this to
show that (7.53) is equivalent to (7.44).
7.17 In this exercise we will show that the optimised singlet fidelity is less
than 1
d  for all separable states, F (A)
Φ+ (σsep) ⩽1
d .
(a) Consider first product states of the form σsep = ω ⊗ζ. Show that
in this case, the optimised singlet fidelity is:
F (A)
Φ+ (ω ⊗ζ) = maximise
⟨Φ+ ∣σ ⊗ζ ∣Φ+⟩
subject to
σ ≽0,
tr(σ) = 1.
(b) Show that for all operators F and G that
⟨Φ+ ∣F ⊗G ∣Φ+⟩= 1
d tr[F TG].
(c) Use part (a) and (b) to show that F (A)
Φ+ (ω ⊗ζ) ⩽1
d .
(d) Show that the optimised singlet fidelity is a convex function, that is
F (A)
Φ+ (∑
i
p(i)σi) ⩽∑
i
p(i)F (A)
Φ+ (σi),
for any ensemble of states {p(i), σi}.
(e) Use part (c) and (d) to show that the optimised singlet fidelity is
less than 1
d  for all separable states.

(7.58
)
(7.57
)
7.18 In this exercise we will show that any d outcome measurement acting
on a d-dimensional Hilbert space can be formed by applying a completely
positive unital map to an ideal projective measurement of the form 
M = {∣x⟩⟨x ∣}. Consider the following Choi state
XΛ† = 1
d ∑
a
Ma⊗∣a⟩⟨a ∣,
where M = {Ma} is an arbitrary d outcome POVM.
(a) Show that XΛ† ≽0.
(b) Show that trB(XΛ†) = 1
d I.This shows that XΛ† is the Choi state
associated to a completely positive unital map Λ†(⋅).
(c) Show that the action of the associated channel Λ†(⋅) on the
projector ∣x⟩⟨x ∣ is
Λ†(∣x⟩⟨x ∣) = Mx.
This shows that it is possible to map an ideal projective
measurement (acting on a d-dimensional Hilbert space) into any other
d outcome measurement M.
7.5 Concluding remarks
In the last chapter of this book we have dealt with quantum channels, the objects that
describes how quantum states evolve or can be manipulated. The key fact that allows
the use of SDPs in the study of quantum channels is the Choi–Jamiołkowski
isomorphism between channels and states. In particular, we presented the following
topics:
Channel estimation. Given a set of input and output states of an unknown
channel, it is possible to determined which channels are consistent with this data
using an SDP—see equation (7.15).
Diamond norm. We can compute the diamond norm of a channel and the
diamond norm distance between channels using semidefinite programming—see
equation (7.23).
Channel discrimination. The average success probability in a binary channel
discrimination task (7.20) can be calculated by an SDP, and provides an
operational interpretation of the diamond norm distance—see (7.22).
Optimised singlet fidelity and generalised robustness. The optimised singlet
fidelity quantifies how close we can bring a quantum state to a maximally

(7.59
a)
(7.59
b)
(7.59
c)
(7.60
)
entangled state by applying local quantum channels on one of the subsystems. It
can be calculated using the SDP (7.34). Furthermore, its dual formulation, as
given in equation (7.35) provides us with an operational interpretation of the
optimised singlet fidelity as a generalised robustness—see equation (7.38).
Optimised singlet fidelity and conditional min-entropy. Duality furthermore
provides us with a one-to-one connection between the conditional min-entropy of
a bipartite state (equations (7.40) and (7.41)) and the optimised singlet fidelity of
that state—see equation (7.45).
7.6 Further reading
Watrous J 2018 Theory of Quantum Information (Lecture Notes) (Cambridge:
Cambridge University Press) https://cs.uwaterloo.ca/~watrous/TQI/
https://cs.uwaterloo.ca/~watrous/TQI-notes/
7.7 Advanced topics
In this brief section we will show how to arrive at the SDP (7.23) for the diamond
norm. Our starting point will be (7.21), which we repeat for convenience:
∥Γ(⋅) ∥⋄= maximise
tr[Z(Γ ⊗id(ρ))]
subject to −I ≼Z ≼I,
ρ ≽0,
tr(ρ) = 1.
This form is not an SDP, since the variables Z and ρ appear multiplied together
in the objective function. In this section, we will see how to combine these variables,
which will lead us to the SDP formulation.
The first step we will take is to reformulate the problem in terms of the Choi state 
XΓ associated to the map Γ(⋅).7 Now, (7.4) gives the action of a map Γ(⋅) on a state ρ,
in terms of its Choi state. However, this doesn’t specify the action of Γ ⊗id on a
bipartite state ρAB. We can however extend (7.4) linearly, and see that the action is
Γ ⊗id(ρAC) = dtrB[(IA ⊗ρTB
BC)(XAB ⊗IC)],
where we have introduced labels for all of the Hilbert spaces, in order to make
everything as clear as possible. In particular, note that it is convenient to treat the state
as being on the Hilbert spaces A and C, in order to allow the Hilbert space B to be that
of the Choi state.

(7.61
)
(7.62
)
(7.63
)
(7.64
)
(7.65
)
Using (7.60), and introducing explicit labels for the Hilbert spaces, we see that the
objective function in (7.59) can be written as
tr[ZAC(Γ ⊗id(ρAC))] = d tr[(ZAC ⊗IB)(IA ⊗ρTB
BC)(XAB ⊗IC)].
Note that in the above, there is a slight complication with regards to the notation.
In particular, the first term on the right-hand side, (ZAC ⊗IB) does not mean that the
ordering of the Hilbert spaces B and C has been interchanged. We still want to
consider that the order of the Hilbert spaces is the (standard) order ABC. This is
however difficult to denote in writing. This is why we choose to take the approach of
labelling the Hilbert spaces, and accept that the order in which the Hilbert spaces are
written down may disagree with the actual order in which the Hilbert spaces occur.
With the above subtlety aside, we can write the right-hand side of (7.61) in the
form tr(YABXAB) if the following operator is defined
YAB = dtrC[(ZAC ⊗IB)(IA ⊗ρTB
BC)],
which combines together the two variables Z and ρ into a single operator
variable. Our goal is thus to characterise the constraints that are satisfied by Y , given
the constraints that are satisfied by Z and ρ from (7.59b) and (7.59c), and to show that
they are linear equality and/or inequality constraints, which can then be imposed
inside an SDP.
The first step we will take is to realise that the partial transpose can be removed by
introducing a maximally entangled state and performing a partial trace. In particular,
in exercise 7.20 it is shown that
trA[(F ⊗I) ∣Φ+⟩⟨Φ+ ∣] = 1
d F T,
for any operator F. Using this, we can express Y  as
YAB = d2trCD[(ZAC⊗∣Φ+⟩⟨Φ+ ∣BD)(IAB ⊗ρDC)].
Now, based upon this expression, we can consider the following class of maps
Ωω(G) = d2trCD[(GAC⊗∣Φ+⟩⟨Φ+ ∣BD)(IAB ⊗ωCD)],
where ω ≽0 is a positive semidefinite operator. It is straightforward to see that
this map is positive, such that Ωω(G) ≽0 whenever G ≽0. In particular, we can
see that

(7.66
)
(7.67
a)
(7.67
b)
(7.67
c)
(7.68
a)
(7.68
b)
(7.68
c)
(7.69
)
(7.70
)
(7.71
)
tr[FΩω(G)] = d2 tr[(GAC⊗∣Φ+⟩⟨Φ+ ∣BD)(FAB ⊗ωCD)] ⩾0,
whenever F ≽0, since in this case all operators on the right-hand side are
positive semidefinite. Thus this shows that Ωω(G) ≽0. The reason for introducing
this map is because we can then see that Y = Ωρ(Z). This can be used in the
following way: from the left-hand constraint in (7.59b), we see that I + Z ≽0. From
the fact that Ωρ(⋅) is a positive map, we can therefore conclude that Ωρ(I + Z) ≽0.
Since Ωρ is also linear,
Ωρ(I + Z) = Ωρ(I) + Ωρ(Z)
= Ωρ(I) + Y ,
= dI ⊗ρT
B + Y ,
where in the last line we used
Ωρ(I) = d2trCD[(IAC⊗∣Φ+⟩⟨Φ+ ∣BD)(IAB ⊗ρCD)],
= d2IA ⊗trD[∣Φ+⟩⟨Φ+ ∣BD (IB ⊗ρD)],
= d(I ⊗ρT
B).
Thus, if we denote by
σ = ρT
B,
we conclude that Ωρ(I + Z) ≽0 implies that
−d(I ⊗σ) ≼Y .
An identical line of reasoning follows for the right-hand constraint in (7.59b),
from which we arrive at
Y ≼d(I ⊗σ).
We have thus arrived at a new pair of variables, (Y , σ), which are constrained to
satisfy −I ⊗σ ≼Y ≼I ⊗σ and σ ≽0, tr(σ) = 1, where the latter two
constraints follow since σ is the transpose of the reduced density operator of ρ, which
is itself a density operator. What will now be shown is that from any such pair of
operators we can construct Z and ρ which satisfy the constraints (7.59b) and (7.59c),
which shows that the two pairs are equivalent.

(7.72
)
(7.73
a)
(7.73
b)
(7.74
)
(7.75
)
(7.76
)
Concerning ρ, we will take this to be any extension of σT. That is, we can take ρ
to be any bipartite density operator such that trA(ρ) = σT
B. Being a valid density
operator, this means that tr(ρ) = 1 and ρ ≽0, as required by (7.59c).
For Z we will take the operator
Z = 1
d (I ⊗
1
√σ )Y (I ⊗
1
√σ ).
Here, as previously, we take 
1
√σ  to be defined by the pseudo-inverse, i.e. only
upon its support (and to remain zero outside of its support). The map 
Γσ(F) = 1
d (I ⊗
1
√σ )F(I ⊗
1
√σ ), being a conjugation, is positive. We can therefore
apply it to Y + d(I ⊗σ) ≽0, and will have Γσ(Y + d(I ⊗σ)) ≽0. This implies,
in particular that
Γσ(Y + d(I ⊗σ)) = 1
d (I ⊗
1
√σ )(Y + d(I ⊗σ))(I ⊗
1
√σ ),
= Z + I ⊗I ≽0.
Similarly, since d(I ⊗σ) −Y ≽0, we have Γσ(d(I ⊗σ) −σ) ≽0, which an
identical calculation shows that
I ⊗I −Z ≽0.
Thus, we have −I ≼Z ≼I, exactly the constraints (7.59b).
To summarise, we have shown that on the one hand, for any pair of variables 
(Z, ρ) from the set
{ (Z, ρ) ∣−I ≼Z ≼I, ρ ≽0, tr(ρ) = 1}
we can find a pair of variables (Y , σ) from the set
{ (Y , σ) ∣−d(I ⊗σ) ≼Y ≼d(I ⊗σ), σ ≽0, tr(σ) = 1},
through the mappings (7.62) and (7.69). On the other hand, for any pair (Y , σ)
we can find a pair (Z, ρ) using the inverse mapping (7.72), and taking ρ to be any
extension of σT. Finally, we saw that the bi-linear objective function (7.61) of ρ and Z
is equal to the linear objective function of Y , tr(Y X). Altogether, this therefore
shows that the diamond norm can be written as an SDP in the variables (Y , σ) as
given in (7.23), namely

(7.77
a)
(7.77
b)
(7.77
c)
∥Γ(⋅) ∥⋄= maximise
tr[Y XΓ]
subject to −d(I ⊗σ) ≼Y ≼d(I ⊗σ),
σ ≽0,
tr(σ) = 1.
Exercises
7.19 Show that in (7.60), if we consider a product state of the form 
ρAC = ρA ⊗ρC, then this expression recovers (7.4), up to the
addition of the system ρC.
7.20 Show that the maximally entangled state satisfies the property
(7.63).
1Note that, although arbitrary, it suffices to check only for dB = dA, due to the fact that it is ultimately
entanglement between the two systems that is important, and the maximally-sized subspace of B that can be
entangled with A is precisely of dimension dB.
2Note that we use ‘state’, but in general XΓ might not be normalised, if Γ is not a channel (but merely a map).
3In order to avoid over-complicating and overloading the notation, we use A to denote both the input and the output
spaces a channel, even if the channel changes the dimension of the Hilbert space. If ever any potential confusion
could arise by using the same label for both spaces, we will instead use different labels, such as A and A′.
4This is because the so-called singlet state ∣Ψ−⟩=
1
√2 (∣0⟩∣1⟩−∣1⟩∣0⟩) is a maximally entangled state,
equivalent to ∣Φ+⟩ up to a local unitary transformation U ⊗V . We could thus have picked this as our target
maximally entangled state without loss of generality; we do not, in order to make a link with the Choi state of the
channel.
5Note that, as mentioned before, we will continue to call XΛ† a Choi state even when Λ†(⋅) is not a trace
preserving map, meaning that XΛ† is a not normalised state. It is nevertheless positive semidefinite, and in order to
avoid overloading the terminology, we stick to the term ‘state’.
6Note that this terminology—which is standard—might seem confusing, but we follow it here since it does have a
justification: the max relative entropy is the largest amongst all Renyi relative entropies, while the associated
conditional min-entropy is the smallest amongst all conditional Renyi entropies.
7We remind, once again, that since Γ(⋅) is not necessarily either completely positive or trace preserving, strictly
speaking XΓ is not a state, but we can think of it as a pseudo-state, since it still arises from the local action of the
map Γ(⋅) on the state ∣Φ+⟩.

