Universitext
Achim Klenke
Probability 
Theory
A Comprehensive Course
Third Edition

Universitext

Universitext
Series Editors
Sheldon Axler
San Francisco State University
Carles Casacuberta
Universitat de Barcelona
John Greenlees
University of Warwick
Angus MacIntyre
Queen Mary University of London
Kenneth Ribet
University of California, Berkeley
Claude Sabbah
École Polytechnique, CNRS, Université Paris-Saclay, Palaiseau
Endre Süli
University of Oxford
Wojbor A. Woyczy´nski
Case Western Reserve University
Universitext is a series of textbooks that presents material from a wide variety of
mathematical disciplines at master’s level and beyond. The books, often well class-
tested by their author, may have an informal, personal even experimental approach
to their subject matter. Some of the most successful and established books in the
series have evolved through several editions, always following the evolution of
teaching curricula, into very polished texts.
Thus as research topics trickle down into graduate-level teaching, ﬁrst textbooks
written for new, cutting-edge courses may make their way into Universitext.
More information about this series at http://www.springer.com/series/223

Achim Klenke
Probability Theory
A Comprehensive Course
Third Edition

Achim Klenke
Institut f¨ur Mathematik
Johannes Gutenberg-Universit¨at Mainz
Mainz, Germany
ISSN 0172-5939
ISSN 2191-6675
(electronic)
Universitext
ISBN 978-3-030-56401-8
ISBN 978-3-030-56402-5
(eBook)
https://doi.org/10.1007/978-3-030-56402-5
Mathematics Subject Classiﬁcation: 60-01, 60B10, 60G42, 60G55, 60H05, 60H10, 60J10, 37-01, 28-01,
82-00
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland
AG 2020
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG.
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface to the Third Edition
New in the third edition: the sections close with a short “takeaways” block where
highlights of the section are summarized sometimes on an informal level without
full rigor. Furthermore, in some places “reﬂection” blocks have been added. They
are of different levels of difﬁculty indicated by the number of clubsuits. Finally,
there are more exercises and some new illustrations.
Many people have helped in correcting errors or improving the exposition by
asking questions and I thank all of them. In particular, I would like to thank Philipp
Neumann for many helpful comments.
Mainz, Germany
Achim Klenke
June 2020
v

Preface to the Second Edition
In the second edition of this book, many errors have been corrected. Furthermore,
the text has been extended carefully in many places. In particular, there are more
exercises and a lot more illustrations.
I would like to take the opportunity to thank all of those who helped in improving
the ﬁrst edition of this book, in particular: Michael Diether, Maren Eckhoff, Christo-
pher Grant, Matthias Hammer, Heiko Hoffmann, Martin Hutzenthaler, Martin Kolb,
Manuel Mergens, Thal Nowik, Felix Schneider, Wolfgang Schwarz, and Stephan
Tolksdorf.
A constantly updated list of errors can be found at www.aklenke.de.
Mainz
Achim Klenke
March 2013
vii

Preface to the First Edition
This book is based on two four-hour courses on advanced probability theory
that I have held in recent years at the universities of Cologne and Mainz. It is
implicitly assumed that the reader has a certain familiarity with the basic concepts
of probability theory, although the formal framework will be fully developed in this
book.
The aim of this book is to present the central objects and concepts of probability
theory: random variables, independence, laws of large numbers and central limit
theorems, martingales, exchangeability and inﬁnite divisibility, Markov chains
and Markov processes, as well as their connection with discrete potential theory,
coupling, ergodic theory, Brownian motion and the Itô integral (including stochastic
differential equations), the Poisson point process, percolation, and the theory of
large deviations.
Measure theory and integration are necessary prerequisites for a systematic
probability theory. We develop it only to the point to which it is needed for our
purposes: construction of measures and integrals, the Radon–Nikodym theorem and
regular conditional distributions, convergence theorems for functions (Lebesgue)
and measures (Prohorov), and construction of measures in product spaces. The
chapters on measure theory do not come as a block at the beginning (although they
are written such that this would be possible; that is, independent of the probabilistic
chapters) but are rather interlaced with probabilistic chapters that are designed to
display the power of the abstract concepts in the more intuitive world of probability
theory. For example, we study percolation theory at the point where we barely have
measures, random variables, and independence; not even the integral is needed. As
the only exception, the systematic construction of independent random variables is
deferred to Chap. 14. Although it is rather a matter of taste, I hope that this setup
helps to motivate the reader throughout the measure-theoretical chapters.
Those readers with a solid measure-theoretical education can skip in particular
the ﬁrst and fourth chapters and might wish only to look up this or that.
In the ﬁrst eight chapters, we lay the foundations that will be needed in all
the subsequent chapters. After that, there are seven more or less independent
parts, consisting of Chaps. 9–20, and 23. The chapter on Brownian motion (21)
ix

x
Preface to the First Edition
makes reference to Chaps. 9–15. Again, after that, the three blocks consisting of
Chaps. 22, 24, and 25, 26 can be read independently.
I should like to thank all those who read the manuscript and the German
original version of this book and gave numerous hints for improvements: Roland
Alkemper, René Billing, Dirk Brüggemann, Anne Eisenbürger, Patrick Jahn, Arnulf
Jentzen, Ortwin Lorenz, L. Mayer, Mario Oeler, Marcus Schölpen, my colleagues
Ehrhard Behrends, Wolfgang Bühler, Nina Gantert, Rudolf Grübel, Wolfgang
König, Peter Mörters, and Ralph Neininger, and in particular my colleague from
Munich Hans-Otto Georgii. Dr John Preater did a great job language editing the
English manuscript and also pointing out numerous mathematical ﬂaws.
I am especially indebted to my wife Katrin for proofreading the English
manuscript and for her patience and support.
I would be grateful for further suggestions, errors, etc. to be sent by e-mail to
math@aklenke.de.
Mainz
Achim Klenke
October 2007

Contents
1
Basic Measure Theory .....................................................
1
1.1
Classes of Sets ......................................................
1
1.2
Set Functions ........................................................
11
1.3
The Measure Extension Theorem ..................................
18
1.4
Measurable Maps ...................................................
36
1.5
Random Variables...................................................
45
2
Independence ...............................................................
53
2.1
Independence of Events ............................................
53
2.2
Independent Random Variables ....................................
61
2.3
Kolmogorov’s 0–1 Law.............................................
69
2.4
Example: Percolation ...............................................
73
3
Generating Functions ......................................................
85
3.1
Deﬁnition and Examples ...........................................
85
3.2
Poisson Approximation.............................................
89
3.3
Branching Processes ................................................
91
4
The Integral .................................................................
95
4.1
Construction and Simple Properties ...............................
95
4.2
Monotone Convergence and Fatou’s Lemma ...................... 104
4.3
Lebesgue Integral Versus Riemann Integral ....................... 107
5
Moments and Laws of Large Numbers .................................. 113
5.1
Moments ............................................................ 113
5.2
Weak Law of Large Numbers ...................................... 121
5.3
Strong Law of Large Numbers ..................................... 125
5.4
Speed of Convergence in the Strong LLN ......................... 135
5.5
The Poisson Process ................................................ 139
xi

xii
Contents
6
Convergence Theorems .................................................... 147
6.1
Almost Sure and Measure Convergence ........................... 147
6.2
Uniform Integrability ............................................... 153
6.3
Exchanging Integral and Differentiation........................... 160
7
Lp-Spaces and the Radon–Nikodym Theorem.......................... 163
7.1
Deﬁnitions........................................................... 163
7.2
Inequalities and the Fischer–Riesz Theorem ...................... 165
7.3
Hilbert Spaces....................................................... 172
7.4
Lebesgue’s Decomposition Theorem .............................. 175
7.5
Supplement: Signed Measures ..................................... 179
7.6
Supplement: Dual Spaces........................................... 186
8
Conditional Expectations .................................................. 191
8.1
Elementary Conditional Probabilities.............................. 191
8.2
Conditional Expectations ........................................... 195
8.3
Regular Conditional Distribution .................................. 203
9
Martingales.................................................................. 213
9.1
Processes, Filtrations, Stopping Times............................. 213
9.2
Martingales.......................................................... 218
9.3
Discrete Stochastic Integral ........................................ 223
9.4
Discrete Martingale Representation Theorem and the CRR
Model................................................................ 224
10
Optional Sampling Theorems ............................................. 229
10.1
Doob Decomposition and Square Variation ....................... 229
10.2
Optional Sampling and Optional Stopping ........................ 233
10.3
Uniform Integrability and Optional Sampling..................... 239
11
Martingale Convergence Theorems and Their Applications .......... 241
11.1
Doob’s Inequality ................................................... 241
11.2
Martingale Convergence Theorems ................................ 243
11.3
Example: Branching Process ....................................... 254
12
Backwards Martingales and Exchangeability ........................... 257
12.1
Exchangeable Families of Random Variables ..................... 257
12.2
Backwards Martingales ............................................. 263
12.3
De Finetti’s Theorem ............................................... 266
13
Convergence of Measures.................................................. 273
13.1
A Topology Primer ................................................. 274
13.2
Weak and Vague Convergence ..................................... 281
13.3
Prohorov’s Theorem ................................................ 290
13.4
Application: A Fresh Look at de Finetti’s Theorem............... 300

Contents
xiii
14
Probability Measures on Product Spaces ................................ 303
14.1
Product Spaces ...................................................... 304
14.2
Finite Products and Transition Kernels ............................ 307
14.3
Kolmogorov’s Extension Theorem................................. 317
14.4
Markov Semigroups ................................................ 322
15
Characteristic Functions and the Central Limit Theorem............. 327
15.1
Separating Classes of Functions.................................... 327
15.2
Characteristic Functions: Examples................................ 336
15.3
Lévy’s Continuity Theorem ........................................ 344
15.4
Characteristic Functions and Moments ............................ 349
15.5
The Central Limit Theorem ........................................ 356
15.6
Multidimensional Central Limit Theorem ......................... 365
16
Inﬁnitely Divisible Distributions .......................................... 367
16.1
Lévy–Khinchin Formula............................................ 367
16.2
Stable Distributions ................................................. 381
17
Markov Chains ............................................................. 391
17.1
Deﬁnitions and Construction ....................................... 391
17.2
Discrete Markov Chains: Examples................................ 399
17.3
Discrete Markov Processes in Continuous Time .................. 404
17.4
Discrete Markov Chains: Recurrence and Transience ............ 411
17.5
Application: Recurrence and Transience of Random Walks...... 415
17.6
Invariant Distributions .............................................. 423
17.7
Stochastic Ordering and Coupling ................................. 429
18
Convergence of Markov Chains........................................... 435
18.1
Periodicity of Markov Chains ...................................... 435
18.2
Coupling and Convergence Theorem .............................. 439
18.3
Markov Chain Monte Carlo Method ............................... 445
18.4
Speed of Convergence .............................................. 453
19
Markov Chains and Electrical Networks ................................ 461
19.1
Harmonic Functions ................................................ 462
19.2
Reversible Markov Chains ......................................... 465
19.3
Finite Electrical Networks .......................................... 467
19.4
Recurrence and Transience ......................................... 473
19.5
Network Reduction ................................................. 480
19.6
Random Walk in a Random Environment ......................... 488
20
Ergodic Theory ............................................................. 493
20.1
Deﬁnitions........................................................... 493
20.2
Ergodic Theorems .................................................. 497
20.3
Examples ............................................................ 500
20.4
Application: Recurrence of Random Walks ....................... 502
20.5
Mixing ............................................................... 506
20.6
Entropy .............................................................. 510

xiv
Contents
21
Brownian Motion ........................................................... 515
21.1
Continuous Versions ................................................ 515
21.2
Construction and Path Properties .................................. 522
21.3
Strong Markov Property ............................................ 529
21.4
Supplement: Feller Processes ...................................... 532
21.5
Construction via L2-Approximation ............................... 535
21.6
The Space C([0, ∞)) ............................................... 544
21.7
Convergence of Probability Measures on C([0, ∞)) ............. 546
21.8
Donsker’s Theorem ................................................. 549
21.9
Pathwise Convergence of Branching Processes ................... 553
21.10
Square Variation and Local Martingales ........................... 560
22
Law of the Iterated Logarithm............................................ 573
22.1
Iterated Logarithm for the Brownian Motion ...................... 573
22.2
Skorohod’s Embedding Theorem .................................. 576
22.3
Hartman–Wintner Theorem ........................................ 583
23
Large Deviations ............................................................ 587
23.1
Cramér’s Theorem .................................................. 588
23.2
Large Deviations Principle ......................................... 594
23.3
Sanov’s Theorem.................................................... 598
23.4
Varadhan’s Lemma and Free Energy............................... 603
24
The Poisson Point Process ................................................. 611
24.1
Random Measures .................................................. 611
24.2
Properties of the Poisson Point Process............................ 616
24.3
The Poisson–Dirichlet Distribution ................................ 627
25
The Itô Integral ............................................................. 635
25.1
Itô Integral with Respect to Brownian Motion .................... 635
25.2
Itô Integral with Respect to Diffusions ............................ 644
25.3
The Itô Formula ..................................................... 648
25.4
Dirichlet Problem and Brownian Motion .......................... 657
25.5
Recurrence and Transience of Brownian Motion.................. 659
26
Stochastic Differential Equations ......................................... 665
26.1
Strong Solutions .................................................... 665
26.2
Weak Solutions and the Martingale Problem ...................... 675
26.3
Weak Uniqueness via Duality ...................................... 682
References......................................................................... 691
Notation Index.................................................................... 699
Name Index ....................................................................... 703
Subject Index ..................................................................... 707

Chapter 1
Basic Measure Theory
In this chapter, we introduce the classes of sets that allow for a systematic
treatment of events and random observations in the framework of probability theory.
Furthermore, we construct measures, in particular probability measures, on such
classes of sets. Finally, we deﬁne random variables as measurable maps.
1.1
Classes of Sets
In the following, let Ω ̸= ∅be a nonempty set and let A ⊂2Ω (set of all subsets of
Ω) be a class of subsets of Ω. Later, Ω will be interpreted as the space of elementary
events and A will be the system of observable events. In this section, we introduce
names for classes of subsets of Ω that are stable under certain set operations and we
establish simple relations between such classes.
Deﬁnition 1.1 A class of sets A is called
•
∩-closed (closed under intersections) or a π-system if A ∩B ∈A whenever
A, B ∈A,
•
σ-∩-closed (closed under countable1 intersections) if ∞
n=1 An ∈A for any
choice of countably many sets A1, A2, . . . ∈A,
•
∪-closed (closed under unions) if A ∪B ∈A whenever A, B ∈A,
•
σ-∪-closed (closed under countable unions) if ∞
n=1 An ∈A for any choice of
countably many sets A1, A2, . . . ∈A,
•
\-closed (closed under differences) if A \ B ∈A whenever A, B ∈A, and
•
closed under complements if Ac := Ω \ A ∈A for any set A ∈A.
1By “countable” we always mean either ﬁnite or countably inﬁnite.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_1
1

2
1
Basic Measure Theory
Deﬁnition 1.2 (σ-algebra) A class of sets A ⊂2Ω is called a σ-algebra if it fulﬁlls
the following three conditions:
(i) Ω ∈A.
(ii) A is closed under complements.
(iii) A is closed under countable unions.
Sometimes a σ-algebra is also named a σ-ﬁeld. As we will see, we can deﬁne
probabilities on σ-algebras in a consistent way. Hence these are the natural classes
of sets to be considered as events in probability theory.
Theorem 1.3 If A is closed under complements, then we have the equivalences
A is ∩-closed
⇐⇒
A is ∪-closed,
A is σ- ∩-closed
⇐⇒
A is σ- ∪-closed.
Proof The two statements are immediate consequences of de Morgan’s rule
(reminder: ( Ai)c
=
 Ac
i ). For example, let A be σ-∩-closed and let
A1, A2, . . . ∈A. Hence
∞

n=1
An =
 ∞

n=1
Ac
n
c
∈A.
Thus A is σ-∪-closed. The other cases can be proved similarly.
⊓⊔
Theorem 1.4 Assume that A is \-closed. Then the following statements hold:
(i) A is ∩-closed.
(ii) If in addition A is σ-∪-closed, then A is σ-∩-closed.
(iii) Any countable (respectively ﬁnite) union of sets in A can be expressed as a
countable (respectively ﬁnite) disjoint union of sets in A.
Proof
(i) Assume that A, B ∈A. Hence also A ∩B = A \ (A \ B) ∈A.
(ii) Assume that A1, A2, . . . ∈A. Hence
∞

n=1
An =
∞

n=2
(A1 ∩An) =
∞

n=2
A1 \ (A1 \ An) = A1 \
∞

n=2
(A1 \ An) ∈A.
(iii) Assume that A1, A2, . . . ∈A. Hence a representation of
∞

n=1
An as a countable
disjoint union of sets in A is
∞

n=1
An = A1⊎(A2\A1)⊎((A3\A1)\A2)⊎(((A4\A1)\A2)\A3)⊎. . . .
⊓⊔

1.1
Classes of Sets
3
Remark 1.5 Sometimes the disjoint union of sets is denoted by the symbol . Note
that this is not a new operation but only stresses the fact that the sets involved are
mutually disjoint. ♦
Deﬁnition 1.6 A class of sets A ⊂2Ω is called an algebra if the following three
conditions are fulﬁlled:
(i) Ω ∈A.
(ii) A is \-closed.
(iii) A is ∪-closed.
If A is an algebra, then obviously ∅= Ω \ Ω is in A. However, in general, this
property is weaker than (i) in Deﬁnition 1.6.
Theorem 1.7 A class of sets A ⊂2Ω is an algebra if and only if the following three
properties hold:
(i) Ω ∈A.
(ii) A is closed under complements.
(iii) A is closed under intersections.
Proof This is left as an exercise.
⊓⊔
Deﬁnition 1.8 A class of sets A ⊂2Ω is called a ring if the following three
conditions hold:
(i) ∅∈A.
(ii) A is \-closed.
(iii) A is ∪-closed.
A ring is called a σ-ring if it is also σ-∪-closed.
Deﬁnition 1.9 A class of sets A ⊂2Ω is called a semiring if
(i) ∅∈A,
(ii) for any two sets A, B ∈A the difference set B \ A is a ﬁnite union of mutually
disjoint sets in A,
(iii) A is ∩-closed.
Deﬁnition 1.10 A class of sets A ⊂2Ω is called a λ-system (or Dynkin’s λ-system)
if
(i) Ω ∈A,
(ii) for any two sets A, B ∈A with A ⊂B, the difference set B \ A is in A, and
(iii) ∞
n=1 An ∈A for any choice of countably many pairwise disjoint sets
A1, A2, . . . ∈A.
Example 1.11
(i) For any nonempty set Ω, the classes A = {∅, Ω} and A = 2Ω are the trivial
examples of algebras, σ-algebras and λ-systems. On the other hand, A = {∅}
and A = 2Ω are the trivial examples of semirings, rings and σ-rings.

4
1
Basic Measure Theory
(ii) Let Ω = R. Then A = {A ⊂R : A is countable} is a σ-ring.
(iii) A = {(a, b] : a, b ∈R, a ≤b} is a semiring on Ω = R (but is not a ring).
(iv) The class of ﬁnite unions of bounded intervals is a ring on Ω = R (but is not
an algebra).
(v) The class of ﬁnite unions of arbitrary (also unbounded) intervals is an algebra
on Ω = R (but is not a σ-algebra).
(vi) Let E be a ﬁnite nonempty set and let Ω := EN be the set of all E-valued
sequences ω = (ωn)n∈N. For any ω1, . . . , ωn ∈E, let
[ω1, . . . , ωn] := {ω′ ∈Ω : ω′
i = ωi for all i = 1, . . . , n}
be the set of all sequences whose ﬁrst n values are ω1, . . . , ωn. Let A0 = {∅}.
For n ∈N, deﬁne
An := {[ω1, . . . , ωn] : ω1, . . . , ωn ∈E}.
(1.1)
Hence A := ∞
n=0 An is a semiring but is not a ring (if #E > 1).
(vii) Let Ω be an arbitrary nonempty set. Then
A := {A ⊂Ω : A or Ac is ﬁnite}
is an algebra. However, if #Ω = ∞, then A is not a σ-algebra.
(viii) Let Ω be an arbitrary nonempty set. Then
A := {A ⊂Ω : A or Ac is countable}
is a σ-algebra.
(ix) Every σ-algebra is a λ-system.
(x) Let Ω = {1, 2, 3, 4} and A =
	
∅, {1, 2}, {1, 4}, {2, 3}, {3, 4}, {1, 2, 3, 4}

.
Hence A is a λ-system but is not an algebra. ♦
Theorem 1.12 (Relations between classes of sets)
(i) Every σ-algebra also is a λ-system, an algebra and a σ-ring.
(ii) Every σ-ring is a ring, and every ring is a semiring.
(iii) Every algebra is a ring. An algebra on a ﬁnite set Ω is a σ-algebra.
Proof
(i) This is obvious.
(ii) Let A be a ring. By Theorem 1.4, A is closed under intersections and is hence
a semiring.
(iii) Let A be an algebra. Then ∅= Ω \Ω ∈A, and hence A is a ring. If in addition
Ω is ﬁnite, then A is ﬁnite. Hence any countable union of sets in A is a ﬁnite
union of sets.
⊓⊔

1.1
Classes of Sets
5
Deﬁnition 1.13 (liminf and limsup) Let A1, A2, . . . be subsets of Ω. The sets
lim inf
n→∞An :=
∞

n=1
∞

m=n
Am
and
lim sup
n→∞
An :=
∞

n=1
∞

m=n
Am
are called limes inferior and limes superior, respectively, of the sequence (An)n∈N.
Remark 1.14
(i) lim inf and lim sup can be rewritten as
lim inf
n→∞An =
	
ω ∈Ω : #{n ∈N : ω ̸∈An} < ∞

,
lim sup
n→∞
An =
	
ω ∈Ω : #{n ∈N : ω ∈An} = ∞

.
In other words, limes inferior is the event where eventually all of the An occur.
On the other hand, limes superior is the event where inﬁnitely many of the An
occur. In particular, A∗:= lim infn→∞An ⊂A∗:= lim supn→∞An.
(ii) We deﬁne the indicator function on the set A by
1A(x) :=

1,
if x ∈A,
0,
if x ̸∈A.
(1.2)
With this notation,
1A∗= lim inf
n→∞1An
and
1A∗= lim sup
n→∞
1An.
(iii) If A ⊂2Ω is a σ-algebra and if An ∈A for every n ∈N, then A∗∈A and
A∗∈A. ♦
Proof This is left as an exercise.
⊓⊔
Theorem 1.15 (Intersection of classes of sets) Let I be an arbitrary index set, and
assume that Ai is a σ-algebra for every i ∈I. Hence the intersection
AI :=
	
A ⊂Ω : A ∈Ai for every i ∈I

=

i∈I
Ai
is a σ-algebra. The analogous statement holds for rings, σ-rings, algebras and λ-
systems. However, it fails for semirings.
Proof We give the proof for σ-algebras only. To this end, we check (i)–(iii) of
Deﬁnition 1.2.
(i) Clearly, Ω ∈Ai for every i ∈I, and hence Ω ∈AI .

6
1
Basic Measure Theory
(ii) Assume A ∈AI . Hence A ∈Ai for any i ∈I. Thus also Ac ∈Ai for any
i ∈I. We conclude that Ac ∈AI .
(iii) Assume A1, A2, . . . ∈AI. Hence An ∈Ai for every n ∈N and i ∈I. Thus
A := ∞
n=1 An ∈Ai for every i ∈I. We conclude A ∈AI .
Counterexample for semirings: Let Ω = {1, 2, 3, 4}, A1 = {∅, Ω, {1}, {2, 3},
{4}} and A2 = {∅, Ω, {1}, {2}, {3, 4}}. Then A1 and A2 are semirings but A1∩A2 =
{∅, Ω, {1}} is not.
⊓⊔
Theorem 1.16 (Generated σ-algebra)
Let E ⊂2Ω. Then there exists a smallest
σ-algebra σ(E) with E ⊂σ(E):
σ(E) :=

A⊂2Ω is a σ-algebra
A⊃E
A.
σ(E) is called the σ-algebra generated by E. E is called a generator of σ(E).
Similarly, we deﬁne δ(E) as the λ-system generated by E.
Proof A = 2Ω is a σ-algebra with E ⊂A. Hence the intersection is nonempty. By
Theorem 1.15, σ(E) is a σ-algebra. Clearly, it is the smallest σ-algebra that contains
E. For λ-systems the proof is similar.
⊓⊔
Remark 1.17 The following three statements hold:
(i) E ⊂σ(E).
(ii) If E1 ⊂E2, then σ(E1) ⊂σ(E2).
(iii) A is a σ-algebra if and only if σ(A) = A.
The same statements hold for λ-systems. Furthermore, δ(E) ⊂σ(E). ♦
Theorem 1.18 (∩-closed λ-system) Let D ⊂2Ω be a λ-system. Then
D is a π-system
⇐⇒
D is a σ-algebra.
Proof “ ⇐ ”
This is obvious.
“ ⇒”
We check (i)–(iii) of Deﬁnition 1.2.
(i) Clearly, Ω ∈D.
(ii) (Closedness under complements) Let A ∈D. Since Ω ∈D and by property (ii)
of the λ-system, we get that Ac = Ω \ A ∈D.
(iii) (σ-∪-closedness) Let A, B ∈D. By assumption, A ∩B ∈D, and trivially
A ∩B ⊂A. Thus A \ B = A \ (A ∩B) ∈D. This implies that D is \-closed.
Now let A1, A2, . . . ∈D. By Theorem 1.4(iii), there exist mutually disjoint
sets B1, B2, . . . ∈D with ∞
n=1 An = ∞
n=1 Bn ∈D.
⊓⊔
Theorem 1.19 (Dynkin’s π-λ theorem) If E ⊂2Ω is a π-system, then
σ(E) = δ(E).

1.1
Classes of Sets
7
Proof “⊃”
This follows from Remark 1.17.
“⊂”
We have to show that δ(E) is a σ-algebra. By Theorem 1.18, it is enough to
show that δ(E) is a π-system. For any B ∈δ(E) deﬁne
DB := {A ∈δ(E) : A ∩B ∈δ(E)}.
In order to show that δ(E) is a π-system, it is enough to show that
δ(E) ⊂DB
for any B ∈δ(E).
(1.3)
In order to show that DE is a λ-system for any E ∈δ(E), we check (i)–(iii) of
Deﬁnition 1.10:
(i) Clearly, Ω ∩E = E ∈δ(E); hence Ω ∈DE.
(ii) For anyA, B ∈DE with A ⊂B, we have (B\A)∩E = (B∩E)\(A∩E) ∈δ(E).
(iii) Assume that A1, A2, . . . ∈DE are mutually disjoint. Hence
 ∞

n=1
An

∩E =
∞

n=1
(An ∩E) ∈δ(E).
By assumption, A ∩E ∈E if A, E ∈E; thus E ⊂DE if E ∈E. By
Remark 1.17(ii), we conclude that δ(E) ⊂DE for any E ∈E. Hence we get that
B ∩E ∈δ(E) for any B ∈δ(E) and E ∈E. This implies that E ∈DB for any
B ∈δ(E). Thus E ⊂DB for any B ∈δ(E), and hence (1.3) follows.
⊓⊔
For an illustration of the inclusions between the classes of sets, see Fig. 1.1.
algebra
λ-system
σ-ring
σ-algebra
ring
semiring
σ-∪-stable
Ω ∈A
∩-stable
Ω ∈A
σ-∪-stable
∪-stable
Fig. 1.1 Inclusions between classes of sets A ⊂2Ω.

8
1
Basic Measure Theory
Reﬂection Where does the proof of Theorem 1.19 fail if E is not ∩-stable? Find an
example of a class of sets E that is not ∩-stable and such that σ(E) ̸= δ(E). ♠
We are particularly interested in σ-algebras that are generated by topologies. The
most prominent role is played by the Euclidean space Rn; however, we will also
consider the (inﬁnite-dimensional)space C([0, 1]) of continuous functions [0, 1] →
R. On C([0, 1]) the norm ∥f ∥∞= supx∈[0,1] |f (x)| induces a topology. For the
convenience of the reader, we recall the deﬁnition of a topology.
Deﬁnition 1.20 (Topology) Let Ω ̸= ∅be an arbitrary set. A class of sets τ ⊂2Ω
is called a topology on Ω if it has the following three properties:
(i) ∅, Ω ∈τ.
(ii) A ∩B ∈τ for any A, B ∈τ.
(iii) 
A∈F A ∈τ for any F ⊂τ.
The pair (Ω, τ) is called a topological space. The sets A ∈τ are called open,
and the sets A ⊂Ω with Ac ∈τ are called closed.
In contrast with σ-algebras, topologies are closed under ﬁnite intersections only, but
they are also closed under arbitrary unions.
Let d be a metric on Ω, and denote the open ball with radius r > 0 centered at
x ∈Ω by
Br(x) = {y ∈Ω : d(x, y) < r}.
Then the usual class of open sets is the topology
τ =
 
(x,r)∈F Br(x) : F ⊂Ω × (0, ∞)

.
Deﬁnition 1.21 (Borel σ-algebra) Let (Ω, τ) be a topological space. The σ-
algebra
B(Ω) := B(Ω, τ) := σ(τ)
that is generated by the open sets is called the Borel σ-algebra on Ω. The elements
A ∈B(Ω, τ) are called Borel sets or Borel measurable sets.
Remark 1.22
In many cases, we are interested in B(Rn), where Rn is equipped
with the Euclidean distance
d(x, y) = ∥x −y∥2 =




n

i=1
(xi −yi)2 .

1.1
Classes of Sets
9
(i) There are subsets of Rn that are not Borel sets. These sets are not easy to
construct like, for example, Vitali sets that can be found in calculus books (see
also [37, Theorem 3.4.4]). Here we do not want to stress this point but state
that, vaguely speaking, all sets that can be constructed explicitly are Borel sets.
(ii) If C ⊂Rn is a closed set, then Cc ∈τ is in B(Rn) and hence C is a Borel set.
In particular, {x} ∈B(Rn) for every x ∈Rn.
(iii) B(Rn) is not a topology. To show this, let V ⊂Rn such that V ̸∈B(Rn).
If B(Rn) were a topology, then it would be closed under arbitrary unions. As
{x} ∈B(Rn) for all x ∈Rn, we would get the contradiction V = 
x∈V {x} ∈
B(Rn). ♦
In most cases the class of open sets that generates the Borel σ-algebra is too big
to work with efﬁciently. Hence we aim at ﬁnding smaller (in particular, countable)
classes of sets that generate the Borel σ-algebra and that are more amenable. In
some of the examples, the elements of the generating class are simpler sets such as
rectangles or compact sets.
We introduce the following notation. We denote by Q the set of rational numbers
and by Q+ the set of strictly positive rational numbers. For a, b ∈Rn, we write
a < b
if ai < bi
for all i = 1, . . . , n.
(1.4)
For a < b, we deﬁne the open rectangle as the Cartesian product
(a, b) :=
n×
i=1
(ai, bi) := (a1, b1) × (a2, b2) × · · · × (an, bn).
(1.5)
Analogously,we deﬁne [a, b], (a, b] and [a, b). Furthermore,we deﬁne (−∞, b) :=
×n
i=1(−∞, bi), and use an analogous deﬁnition for (−∞, b] and so on. We
introduce the following classes of sets:
E1 := {A ⊂Rn : A is open},
E2 := {A ⊂Rn : A is closed},
E3 := {A ⊂Rn : A is compact},
E4 := {Br(x) : x ∈Qn, r ∈Q+},
E5 := {(a, b) : a, b ∈Qn, a < b},
E6 := {[a, b) : a, b ∈Qn, a < b},
E7 := {(a, b] : a, b ∈Qn, a < b},
E8 := {[a, b] : a, b ∈Qn, a < b},
E9 := {(−∞, b) : b ∈Qn},
E10 := {(−∞, b] : b ∈Qn},
E11 := {(a, ∞) : a ∈Qn},
E12 := {[a, ∞) : a ∈Qn}.
Theorem 1.23 The Borel σ-algebra B(Rn) is generated by any of the classes of
sets E1, . . . , E12, that is, B(Rn) = σ(Ei) for any i = 1, . . . , 12.

10
1
Basic Measure Theory
Proof We show only some of the identities.
(1) By deﬁnition, B(Rn) = σ(E1).
(2) Let A ∈E1. Then Ac ∈E2, and hence A = (Ac)c ∈σ(E2). It follows that
E1 ⊂σ(E2). By Remark 1.17, this implies σ(E1) ⊂σ(E2). Similarly, we
obtain σ(E2) ⊂σ(E1) and hence equality.
(3) Any compact set is closed; hence σ(E3) ⊂σ(E2). Now let A ∈E2. The
sets AK := A ∩[−K, K]n, K ∈N, are compact; hence the countable
union A = ∞
K=1 AK is in σ(E3). It follows that E2 ⊂σ(E3) and thus
σ(E2) = σ(E3).
(4) Clearly, E4 ⊂E1; hence σ(E4) ⊂σ(E1). Now let A ⊂Rn be an open set.
For any x ∈A, deﬁne R(x) = min(1, sup{r > 0 : Br(x) ⊂A}). Note
that R(x) > 0, as A is open. Let r(x) ∈(R(x)/2, R(x)) ∩Q. For any
y ∈A and x ∈(BR(y)/3(y)) ∩Qn, we have R(x) ≥R(y) −∥x −y∥2 >
2
3R(y), and hence r(x) > 1
3R(y) and thus y ∈Br(x)(x). It follows that
A = 
x∈A∩Qn Br(x)(x) is a countable union of sets from E4 and is hence
in σ(E4). We have shown that E1 ⊂σ(E4). By Remark 1.17, this implies
σ(E1) ⊂σ(E4).
(5–12) Exhaustion arguments similar to that in (4) also work for rectangles. If in (4)
we take open rectangles instead of open balls Br(x), we get B(Rn) = σ(E5).
For example, we have
n×
i=1
[ai, bi) =
∞

k=1
n×
i=1

ai −1
k , bi

∈σ(E5).
The other inclusions Ei ⊂σ(Ej) can be shown similarly.
⊓⊔
Remark 1.24 Any of the classes E1, E2, E3, E5, . . . , E12 (but not E4) is a π-system.
Hence, the Borel σ-algebra equals the generated λ-system: B(Rn) = δ(Ei) for i =
1, 2, 3, 5, . . ., 12. In addition, the classes E4, . . . , E12 are countable. This is a crucial
property that will be needed later. ♦
Deﬁnition 1.25 (Trace of a class of sets) Let A ⊂2Ω be an arbitrary class of
subsets of Ω and let A ∈2Ω \ {∅}. The class
A
A := {A ∩B : B ∈A} ⊂2A
(1.6)
is called the trace of A on A or the restriction of A to A.
Theorem 1.26 Let A ⊂Ω be a nonempty set and let A be a σ-algebra on Ω or
any of the classes of Deﬁnitions 1.6–1.9. Then A
A is a class of sets of the same type
as A; however, on A instead of Ω. For λ-systems this is not true in general.
Proof This is left as an exercise.
⊓⊔

1.2
Set Functions
11
Takeaways σ-algebras are classes of sets that are stable under countable
intersections and unions. They can be generated by classes with less structure
(algebras, rings, semirings), but also by classes with a different structure (e.g.,
a topology). In the case of a topology we get a Borel σ-algebra, that can also
be generated using simple sets such as rectangles.
Exercise 1.1.1 Let A be a semiring. Show that any countable (respectively ﬁnite)
union of sets in A can be written as a countable (respectively ﬁnite) disjoint union
of sets in A. ♣
Exercise 1.1.2 Give a counterexample that shows that, in general, the union A∪A′
of two σ-algebras need not be a σ-algebra. ♣
Exercise 1.1.3 Let (Ω1, d1) and (Ω2, d2) be metric spaces and let f : Ω1 →Ω2
be an arbitrary map. Denote by Uf =
	
x ∈Ω1 : f is discontinuous at x

the set
of points of discontinuity of f . Show that Uf ∈B(Ω1).
Hint: First show that for any ε > 0 and δ > 0 the set
Uδ,ε
f
:= 	x ∈Ω1 :
there are y, z ∈Bε(x) with d2(f (y), f (z)) > δ
is open (where Bε(x) = {y ∈Ω1 : d1(x, y) < ε}). Then construct Uf from such
Uδ,ε
f . ♣
Exercise 1.1.4 Let Ω be an uncountably inﬁnite set and A = σ({ω} : ω ∈Ω).
Show that
A =
	
A ⊂Ω : A is countable or Ac is countable

.
♣
Exercise 1.1.5 Let A be a ring on the set Ω. Show that A is an Abelian algebraic
ring with multiplication “ ∩” and addition “ △”. ♣
1.2
Set Functions
We aim at assigning to each “event” (which will be formalised later) a number that
can be interpreted as the probability for the event to occur. To this end, we ﬁrst
study more general set functions that assign nonnegative numbers to subsets. Then
we describe those properties necessary for such a function to qualify as a probability
assignment.
Deﬁnition 1.27 Let A ⊂2Ω and let μ : A →[0, ∞] be a set function. We say that
μ is
(i) monotone if μ(A) ≤μ(B) for any two sets A, B ∈A with A ⊂B,

12
1
Basic Measure Theory
(ii) additive if μ
 n
i=1
Ai

=
n
i=1
μ(Ai) for any choice of ﬁnitely many mutually
disjoint sets A1, . . . , An ∈A with
n
i=1
Ai ∈A,
(iii) σ-additive if
μ
 ∞

i=1
Ai

=
∞

i=1
μ(Ai) for any choice of countably many
mutually disjoint sets A1, A2, . . . ∈A with
∞

i=1
Ai ∈A,
(iv) subadditive if for any choice of ﬁnitely many sets A, A1, . . . , An ∈A with
A ⊂
n
i=1
Ai, we have μ(A) ≤
n
i=1
μ(Ai), and
(v) σ-subadditive if for any choice of countably many sets A, A1, A2, . . . ∈A
with A ⊂
∞

i=1
Ai, we have μ(A) ≤
∞

i=1
μ(Ai) .
Deﬁnition 1.28 Let A be a semiring and let μ : A →[0, ∞] be a set function with
μ(∅) = 0. μ is called a
•
content if μ is additive,
•
premeasure if μ is σ-additive,
•
measure if μ is a premeasure and A is a σ-algebra, and
•
probability measure if μ is a measure and μ(Ω) = 1.
Deﬁnition 1.29 Let A be a semiring. A content μ on A is called
(i) ﬁnite if μ(A) < ∞for every A ∈A and
(ii) σ-ﬁnite if there exists a sequence of sets Ω1, Ω2, . . . ∈A such that Ω =
∞

n=1
Ωn and such that μ(Ωn) < ∞for all n ∈N.
Example 1.30 (Contents, measures)
(i) Let ω ∈Ω and δω(A) = 1A(ω) (see (1.2)). Then δω is a probability measure
on any σ-algebra A ⊂2Ω. δω is called the Dirac measure for the point ω.
(ii) Let Ω be a ﬁnite nonempty set. By
μ(A) := #A
#Ω
for A ⊂Ω,
we deﬁne a probability measure on A = 2Ω. This μ is called the uniform
distribution on Ω. For this distribution, we introduce the symbol UΩ := μ.
The resulting triple (Ω, A, UΩ) is called a Laplace space.
(iii) Let Ω be countably inﬁnite and let
A := {A ⊂Ω : #A < ∞or #Ac < ∞}.

1.2
Set Functions
13
Then A is an algebra. The set function μ on A deﬁned by
μ(A) =

0,
if A is ﬁnite,
∞,
if Ac is ﬁnite,
is a content but is not a premeasure. Indeed, μ 
ω∈Ω{ω} = μ(Ω) = ∞,
but 
ω∈Ω μ ({ω}) = 0.
(iv) Let (μn)n∈N be a sequence of measures (premeasures, contents) and let
(αn)n∈N be a sequence of nonnegative numbers. Then also μ := ∞
n=1 αnμn
is a measure (premeasure, content).
(v) Let Ω be an (at most) countable nonempty set and let A = 2Ω. Further, let
(pω)ω∈Ω be nonnegative numbers. Then A →μ(A) := 
ω∈A pω deﬁnes
a σ-ﬁnite measure on 2Ω. We call p = (pω)ω∈Ω the weight function of μ.
The number pω is called the weight of μ at point ω.
(vi) If in (v) the sum 
ω∈Ω pω equals one, then μ is a probability measure. In
this case, we interpret pω as the probability of the elementary event ω. The
vector p = (pω)ω∈Ω is called a probability vector.
(vii) If in (v) pω = 1 for every ω ∈Ω, then μ is called counting measure on Ω.
If Ω is ﬁnite, then so is μ.
(viii) Let A be the ring of ﬁnite unions of intervals (a, b] ⊂R. For a1 < b1 <
a2 < b2 < . . . < bn and A =
n
i=1
(ai, bi], deﬁne
μ(A) =
n

i=1
(bi −ai).
Then μ is a σ-ﬁnite content on A (even a premeasure) since ∞
n=1(−n, n] =
R and μ((−n, n]) = 2n < ∞for all n ∈N.
(ix) Let f : R →[0, ∞) be continuous. In a similar way to (viii), we deﬁne
μf (A) =
n

i=1
 bi
ai
f (x) dx.
Then μf is a σ-ﬁnite content on A (even a premeasure). The function f
is called the density of μ and plays a role similar to the weight function p
in (v). ♦
Lemma 1.31 (Properties of contents) Let A be a semiring and let μ be a content
on A. Then the following statements hold.
(i) If A is a ring, then μ(A ∪B) + μ(A ∩B) = μ(A) + μ(B) for any two sets
A, B ∈A.
(ii) μ is monotone. If A is a ring, then μ(B) = μ(A) + μ(B \ A) for any two sets
A, B ∈A with A ⊂B.

14
1
Basic Measure Theory
(iii) μ is subadditive. If μ is σ-additive, then μ is also σ-subadditive.
(iv) If A is a ring, then
∞

n=1
μ(An) ≤μ
 ∞

n=1
An

for any choice of countably many
mutually disjoint sets A1, A2, . . . ∈A with
∞

n=1
An ∈A.
Proof
(i) Note that A ∪B = A ⊎(B \ A) and B = (A ∩B) ⊎(B \ A). As μ is additive,
we obtain
μ(A ∪B) = μ(A) + μ(B \ A)
and
μ(B) = μ(A ∩B) + μ(B \ A).
This implies (i).
(ii) Let A ⊂B. Since A ∩B = A, we obtain μ(B) = μ(A ⊎(B \ A)) = μ(A) +
μ(B \ A) if B \ A ∈A. In particular, this is true if A is a ring. If A is only a
semiring, then there exists an n ∈N and mutually disjoint sets C1, . . . , Cn ∈A
such that B \ A = n
i=1 Ci. Hence μ(B) = μ(A) + n
i=1 μ(Ci) ≥μ(A) and
thus μ is monotone.
(iii) Let n ∈N and A, A1, . . . , An ∈A with A ⊂n
i=1 Ai. Deﬁne B1 = A1 and
Bk = Ak \
k−1

i=1
Ai =
k−1

i=1
(Ak \ (Ak ∩Ai))
for k = 2, . . . , n.
By the deﬁnition of a semiring, any Ak \ (Ak ∩Ai) is a ﬁnite disjoint union of
sets in A. Hence there exists a ck ∈N and sets Ck,1, . . . , Ck,ck ∈A such that
ck
i=1 Ck,i = Bk ⊂Ak. Similarly, there exist dk ∈N and Dk,1, . . . , Dk,dk ∈A
such that Ak \ Bk = dk
i=1 Dk,i. Since μ is additive, we have
μ(Ak) =
ck

i=1
μ(Ck,i) +
dk

i=1
μ(Dk,i) ≥
ck

i=1
μ(Ck,i).
Again due to additivity and monotonicity, we get
μ(A) = μ
 n

k=1
ck

i=1
(Ck,i ∩A)

=
n

k=1
ck

i=1
μ(Ck,i ∩A)
≤
n

k=1
ck

i=1
μ(Ck,i) ≤
n

k=1
μ(Ak).
Hence μ is subadditive. By a similar argument, σ-subadditivity follows from
σ-additivity.

1.2
Set Functions
15
(iv) Let A be a ring and let A =
∞

n=1
An ∈A. Since μ is additive (and thus
monotone), we have by (ii)
m

n=1
μ(An) = μ
 m

n=1
An

≤μ(A)
for any m ∈N.
It follows that
∞

n=1
μ(An) ≤μ(A).
⊓⊔
Remark 1.32 The inequality in (iv) can be strict (see Example 1.30(iii)). In other
words, there are contents that are not premeasures. ♦
If A is a ring an μ is a content on A, then by Lemma 1.31, for A, B ∈E such that
μ(A), μ(B) < ∞, we have
μ(A ∪B) = μ(A) + μ(B) −μ(A ∩B).
Similarly, for three sets A, B, C ∈A with ﬁnite content, we have
μ(A ∪B ∪C) =μ(A ∪B) + μ(C) −μ((A ∩C) ∪(B ∩C))
=μ(A) + μ(B) + μ(C)
−μ(A ∩B) −μ(A ∩C) −μ(B ∩C) + μ(A ∩B ∩C).
Note that the sign of each expression changes with the number of sets that are cut.
This statement will now be generalised to an arbitrary ﬁnite number of sets.
Theorem 1.33 (Inclusion–exclusion formula)
Let A be a ring and let μ be a
content on A. Let n ∈N and A1, . . . , An ∈A such that μ(A1 ∪. . . ∪An) < ∞.
Then the following inclusion and exclusion formulas hold:
μ(A1 ∪. . . ∪An) =
n

k=1
(−1)k−1

{i1,...,ik}⊂{1,...,n}
μ(Ai1 ∩. . . ∩Aik),
μ(A1 ∩. . . ∩An) =
n

k=1
(−1)k−1

{i1,...,ik}⊂{1,...,n}
μ(Ai1 ∪. . . ∪Aik).
Here summation is over all subsets of {1, . . . , n} with k elements.
Proof This is left as an exercise. Hint: Use induction on n.
⊓⊔
The next goal is to characterize σ-subadditivity by a certain continuity property
(Theorem 1.36). To this end, we agree on the following conventions.

16
1
Basic Measure Theory
Deﬁnition 1.34 Let A, A1, A2, . . . be sets. We write
•
An ↑A and say that (An)n∈N increases to A if A1 ⊂A2 ⊂. . . and ∞
n=1 An =
A, and
•
An ↓A and say that (An)n∈N decreases to A if A1 ⊃A2 ⊃A3 ⊃. . . and
∞
n=1 An = A.
Assume that we have a sequence of events A1, A2, . . . that cannot all occur jointly.
Then we should have that the probability for A1, . . . , An to occur jointly vanishes
as n →∞. This is a property of continuity that cannot be deduced from the axioms
of a content and thus must be postulated separately.
Deﬁnition 1.35 (Continuity of contents) Let μ be a content on the ring A.
(i) μ is called lower semicontinuous if μ(An)
n→∞
−→μ(A) for any A ∈A and
any sequence (An)n∈N in A with An ↑A.
(ii) μ is called upper semicontinuous if μ(An)
n→∞
−→μ(A) for any A ∈A and
any sequence (An)n∈N in A with μ(An) < ∞for some (and then eventually
all) n ∈N and An ↓A.
(iii) μ is called ∅-continuous if (ii) holds for A = ∅.
In the deﬁnition of upper semicontinuity, we needed the assumption μ(An) < ∞
since otherwise we would not even have ∅-continuity for an example as simple as the
counting measure μ on (N, 2N). Indeed, An := {n, n+1, . . .} ↓∅but μ(An) = ∞
for all n ∈N.
Theorem 1.36 (Continuity and premeasure) Let μ be a content on the ring A.
Consider the following ﬁve properties.
(i) μ is σ-additive (and hence a premeasure).
(ii) μ is σ-subadditive.
(iii) μ is lower semicontinuous.
(iv) μ is ∅-continuous.
(v) μ is upper semicontinuous.
Then the following implications hold:
(i) ⇐⇒(ii) ⇐⇒(iii) ⇒(iv) ⇐⇒(v).
If μ is ﬁnite, then we also have (iv) ⇒(iii).
Proof “(i) ⇒(ii)”
Let A, A1, A2, . . . ∈A with A ⊂∞
i=1 Ai. Deﬁne B1 = A1
and Bn = An \ n−1
i=1 Ai ∈A for n = 2, 3, . . .. Then A = ∞
n=1(A ∩Bn). Since μ
is monotone and σ-additive, we infer
μ(A) =
∞

n=1
μ(A ∩Bn) ≤
∞

n=1
μ(An).

1.2
Set Functions
17
Hence μ is σ-subadditive.
“(ii) ⇒(i)”
This follows from Lemma 1.31(iv).
“(i) ⇒(iii)”
Let μ be a premeasure and A ∈A. Let (An)n∈N be a sequence in
A such that An ↑A and let A0 = ∅. Then
μ(A) =
∞

i=1
μ(Ai \ Ai−1) = lim
n→∞
n

i=1
μ(Ai \ Ai−1) = lim
n→∞μ(An).
“(iii) ⇒(i)”
Assume now that (iii) holds. Let B1, B2, . . . ∈A be mutually
disjoint, and assume that B =
∞

n=1
Bn ∈A. Deﬁne An =
n
i=1
Bi for all n ∈N. Then
it follows from (iii) that
μ(B) = lim
n→∞μ(An) =
∞

i=1
μ(Bi).
Hence μ is σ-additive and therefore a premeasure.
“(iv) ⇒(v)”
Let A, A1, A2, . . . ∈A with An ↓A and μ(A1) < ∞. Deﬁne
Bn = An \ A ∈A for all n ∈N. Then Bn ↓∅. This implies μ(An) −μ(A) =
μ(Bn)
n→∞
−→0.
“(v) ⇒(iv)”
This is evident.
“(iii) ⇒(iv)”
Let A1, A2, . . . ∈A with An ↓∅and μ(A1) < ∞. Then A1 \
An ∈A for any n ∈N and A1 \ An ↑A1. Hence
μ(A1) = lim
n→∞μ(A1 \ An) = μ(A1) −lim
n→∞μ(An).
Since μ(A1) < ∞, we have lim
n→∞μ(An) = 0.
“(iv) ⇒(iii)”
(for ﬁnite μ) Assume that μ(A) < ∞for every A ∈A and that
μ is ∅-continuous. Let A, A1, A2, . . . ∈A with An ↑A. Then we have A \ An ↓∅
and
μ(A) −μ(An) = μ(A \ An)
n→∞
−→0.
Hence (iii) follows.
⊓⊔
Example 1.37 (Compare Example 1.30(iii).) Let Ω be a countable set, and deﬁne
A = {A ⊂Ω : #A < ∞or #Ac < ∞},
μ(A) =

0,
if A is ﬁnite,
∞,
if A is inﬁnite.
Then μ is an ∅-continuous content but not a premeasure. ♦

18
1
Basic Measure Theory
Deﬁnition 1.38
(i) A pair (Ω, A) consisting of a nonempty set Ω and a σ-algebra A ⊂2Ω is
called a measurable space. The sets A ∈A are called measurable sets. If
Ω is at most countably inﬁnite and if A = 2Ω, then the measurable space
(Ω, 2Ω) is called discrete.
(ii) A triple (Ω, A, μ) is called a measure space if (Ω, A) is a measurable space
and if μ is a measure on A.
(iii) If in addition μ(Ω) = 1, then (Ω, A, μ) is called a probability space. In this
case, the sets A ∈A are called events.
(iv) The set of all ﬁnite measures on (Ω, A) is denoted by Mf (Ω) := Mf (Ω, A).
The subset of probability measures is denoted by M1(Ω) := M1(Ω, A).
Finally, the set of σ-ﬁnite measures on (Ω, A) is denoted by Mσ(Ω, A).
Takeaways In this section, we have compiled a wish list of the properties
that a probability assignment should have: σ-additivity and normalization
(Deﬁnition 1.28). We have seen how σ-additivity follows from additivity
(which is easier to check) and continuity (Theorem 1.36). In order for the
notion of σ-additivity to make sense, the underlying class of sets must be
closed under countable set operations; that is, it must be a σ-algebra. This
shows that the concepts formed in Sect. 1.1 are sensible.
Exercise 1.2.1 Let A = {(a, b] ∩Q : a, b ∈R, a ≤b}. Deﬁne μ : A →[0, ∞)
by μ

(a, b] ∩Q

= b −a. Show that A is a semiring and μ is a content on A that
is lower and upper semicontinuous but is not σ-additive. ♣
1.3
The Measure Extension Theorem
In this section, we construct measures μ on σ-algebras. The starting point will be
to deﬁne the values of μ on a smaller class of sets; that is, on a semiring. Under a
mild consistency condition, the resulting set function can be extended to the whole
σ-algebra.
Before we develop the complete theory, we begin with two examples: The
Lebesgue measure and the inﬁnite product measure. While the Lebesgue measure
is ubiquitous in analysis, the inﬁnite product measure plays an important role in
probability theory for modelling inﬁnitely many independent events.
Example 1.39 (Lebesgue measure) Let n ∈N and let
A = {(a, b] : a, b ∈Rn, a ≤b}

1.3
The Measure Extension Theorem
19
be the semiring of half open rectangles (a, b] ⊂Rn (see (1.5)). The n-dimensional
volume of such a rectangle is
μ((a, b]) =
n

i=1
(bi −ai).
Can we extend the set function μ to a (uniquely determined) measure on the Borel
σ-algebra B(Rn) = σ(A)? We will see that this is indeed possible. The resulting
measure is called Lebesgue measure (or sometimes Lebesgue–Borel measure) λ on

Rn, B(Rn)

. ♦
Example 1.40 (Product measure, Bernoulli measure) We construct a measure for
an inﬁnitely often repeated random experiment with ﬁnitely many possible out-
comes. Let E be the set of possible outcomes. For e ∈E, let pe ≥0 be the
probability that e occurs. Hence 
e∈E pe = 1. For a ﬁxed realization of the
repeated experiment, let ω1, ω2, . . . ∈E be the observed outcomes. Hence the
space of all possible outcomes of the repeated experiment is Ω = EN. As in
Example 1.11(vi), we deﬁne the set of all sequences whose ﬁrst n values are
ω1, . . . , ωn:
[ω1, . . . , ωn] := {ω′ ∈Ω : ω′
i = ωi for any i = 1, . . ., n}.
(1.7)
Let A0 = {∅}. For n ∈N, deﬁne the class of cylinder sets that depend only on the
ﬁrst n coordinates
An := {[ω1, . . . , ωn] : ω1, . . . , ωn ∈E},
(1.8)
and let A := ∞
n=0 An.
We interpret [ω1, . . . , ωn] as the event where the outcome of the ﬁrst experiment
is ω1, the outcome of the second experiment is ω2 and ﬁnally the outcome of the
nth experiment is ωn. The outcomes of the other experiments do not play a role for
the occurrence of this event. As the individual experiments ought to be independent,
we should have for any choice ω1, . . . , ωn ∈E that the probability of the event
[ω1, . . . , ωn] is the product of the probabilities of the individual events; that is,
μ([ω1, . . . , ωn]) =
n

i=1
pωi.
This formula deﬁnes a content μ on the semiring A, and our aim is to extend μ in a
unique way to a probability measure on the σ-algebra σ(A) that is generated by A.
Before we do so, we make the following deﬁnition. Deﬁne the (ultra-)metric d
on Ω by
d(ω, ω′) =

2−inf{n∈N: ωn̸=ω′
n},
if ω ̸= ω′,
0,
if ω = ω′.
(1.9)

20
1
Basic Measure Theory
Hence (Ω, d) is a compact metric space. Clearly,
[ω1, . . . , ωn] = B2−n(ω) = {ω′ ∈Ω : d(ω, ω′) < 2−n}.
The complement of [ω1, . . . , ωn] is an open set, as it is the union of (#E)n −1 open
balls
[ω1, . . . , ωn]c =

(ω′
1,...,ω′n)̸=(ω1,...,ωn)
[ω′
1, . . . , ω′
n].
Since Ω is compact, the closed subset [ω1, . . . , ωn] is compact. As in Theorem 1.23,
it can be shown that σ(A) = B(Ω, d).
Exercise: Prove the statements made above. ♦
Reﬂection Why is there no inﬁnite product measure if 
e p(e) ∈(0, ∞) \ {1}? ♠
The main result of this chapter is Carathéodory’s measure extension theorem.
Theorem 1.41 (Carathéodory)
Let A ⊂2Ω be a ring and let μ be a σ-ﬁnite
premeasure on A. There exists a unique measure μ on σ(A) such that μ(A) = μ(A)
for all A ∈A. Furthermore, ˜μ is σ-ﬁnite.
We prepare for the proof of this theorem with a couple of lemmas. In fact, we will
show a slightly stronger statement in Theorem 1.53.
Lemma 1.42 (Uniqueness by an ∩-closed generator) Let (Ω, A, μ) be a σ-ﬁnite
measure space and let E ⊂A be a π-system that generates A. Assume that there
exist sets Ω1, Ω2, . . . ∈E such that ∞
n=1 Ωn = Ω and μ(Ωn) < ∞for all n ∈N.
Then μ is uniquely determined by the values μ(E), E ∈E.
If μ is a probability measure, the existence of the sequence (Ωn)n∈N is not needed.
Proof Let ν be a (possibly different) σ-ﬁnite measure on (Ω, A) such that
μ(E) = ν(E)
for every E ∈E.
Let E ∈E with μ(E) < ∞. Consider the class of sets
DE =
	
A ∈A : μ(A ∩E) = ν(A ∩E)

.
In order to show that DE is a λ-system, we check the properties of Deﬁnition 1.10:
(i) Clearly, Ω ∈DE.
(ii) Let A, B ∈DE with A ⊃B. Then
μ ((A \ B) ∩E) = μ(A ∩E) −μ(B ∩E)
= ν(A ∩E) −ν(B ∩E) = ν ((A \ B) ∩E) .
Hence A \ B ∈DE.

1.3
The Measure Extension Theorem
21
(iii) Let A1, A2, . . . ∈DE be mutually disjoint and A =
∞

n=1
An. Then
μ(A ∩E) =
∞

n=1
μ(An ∩E) =
∞

n=1
ν(An ∩E) = ν(A ∩E).
Hence A ∈DE.
Clearly, E ⊂DE; hence δ(E) ⊂DE. Since E is a π-system, Theorem 1.19 yields
A ⊃DE ⊃δ(E) = σ(E) = A.
Hence DE = A.
This implies μ(A ∩E) = ν(A ∩E) for any A ∈A and E ∈E with μ(E) < ∞.
Now let Ω1, Ω2, . . . ∈E be a sequence such that ∞
n=1 Ωn = Ω and μ(Ωn) < ∞
for all n ∈N. Let En := n
i=1 Ωi, n ∈N, and E0 = ∅. Hence En = n
i=1(Ec
i−1 ∩
Ωi). For any A ∈A and n ∈N, we thus get
μ(A ∩En) =
n

i=1
μ(A ∩Ec
i−1) ∩Ωi
 =
n

i=1
ν(A ∩Ec
i−1) ∩Ωi
 = ν(A ∩En).
Since En ↑Ω and since μ and ν are lower semicontinuous, we infer
μ(A) = lim
n→∞μ(A ∩En) = lim
n→∞ν(A ∩En) = ν(A).
The additional statement is trivial as ˜E := E ∪{Ω} is a π-system that generates
A, and the value μ(Ω) = 1 is given. Hence one can choose the constant sequence
En = Ω, n ∈N. However, note that it is not enough to assume that μ is ﬁnite. In
this case, in general, the total mass μ(Ω) is not uniquely determined by the values
μ(E), E ∈E; see Example 1.45(ii).
⊓⊔
Reﬂection Where in the previous proof did we exploit the ∩-stability? What goes
wrong if ∩-stability is missing? Compare Example 1.45. ♠
Example 1.43 Let Ω = Z and E = 	En : n ∈Z
 where En = (−∞, n] ∩Z. Then
E is a π-system and σ(E) = 2Ω. Hence a ﬁnite measure μ on (Ω, 2Ω) is uniquely
determined by the values μ(En), n ∈Z.
However, a σ-ﬁnite measure on Z is not uniquely determined by the values on E:
Let μ be the counting measure on Z and let ν = 2μ. Hence μ(E) = ∞= ν(E) for
all E ∈E. In order to distinguish μ and ν one needs a generator that contains sets of
ﬁnite measure (of μ). Do the sets ˜Fn = [−n, n] ∩Z, n ∈N do the trick? Indeed, for
any σ-ﬁnite measure μ, we have μ( ˜Fn) < ∞for all n ∈N. However, the sets ˜Fn
do not generate 2Ω (but which σ-algebra?). We get things to work out better if we
modify the deﬁnition: Fn = [−n/2, (n+1)/2]∩Z. Now σ({Fn, n ∈N}) = 2Ω, and

22
1
Basic Measure Theory
hence E = {Fn, n ∈N} is a π-system that generates 2Ω and such that μ(Fn) < ∞
for all n ∈N. The conditions of the theorem are fulﬁlled as Fn ↑Ω. ♦
Example 1.44 (Distribution function) A probability measure μ on the space
Rn, B(Rn) is uniquely determined by the values μ((−∞, b]) (where (−∞, b] =
×n
i=1(−∞, bi], b ∈Rn). In fact, these sets form a π-system that generates
B(Rn) (see Theorem 1.23). In particular, a probability measure μ on R is uniquely
determined by its distribution function F : R →[0, 1], x →μ((−∞, x]). ♦
Example 1.45
(i) Let Ω = {1, 2, 3, 4} and E = {	1, 2}, {2, 3}
. Clearly, σ(E) = 2Ω but E is not
a π-system. In fact, here a probability measure μ is not uniquely determined
by the values, say μ({1, 2}) = μ({2, 3}) =
1
2. We give just two different
possibilities: μ = 1
2δ1 + 1
2δ3 and μ′ = 1
2δ2 + 1
2δ4.
(ii) Let Ω = {1, 2} and E = {{1}}. Then E is a π-system that generates 2Ω. Hence
a probability measure μ is uniquely determined by the value μ({1}). However,
a ﬁnite measure is not determined by its value on {1}, as μ = 0 and ν = δ2 are
different ﬁnite measures that agree on E. ♦
Lemma 1.42 yields uniqueness in Carathéodory’s theorem. The more challenging
part is to come up with a candidate μ for the extension of the pre-measure in the
ﬁrst place. The strategy is to deﬁne a number μ∗(E) for each E ∈2Ω by covering E
with elements of E and then determine the total content. The smallest value μ∗(E)
that can be obtained by such an approximation is called the outer measure of E.
The second step is to check that μ∗is a measure at least on σ(E). This gives a good
candidate for μ.
Deﬁnition 1.46 (Outer measure) A set function μ∗: 2Ω →[0, ∞] is called an
outer measure if
(i) μ∗(∅) = 0, and
(ii) μ∗is monotone,
(iii) μ∗is σ-subadditive.
Lemma 1.47 Let A ⊂2Ω be an arbitrary class of sets with ∅∈A and let μ
be a nonnegative set function on A with μ(∅) = 0. For A ⊂Ω, deﬁne the set of
countable coverings F with sets F ∈A:
U(A) =

F ⊂A : F is at most countable and A ⊂

F∈F
F

.
Deﬁne
μ∗(A) := inf
 
F∈F
μ(F) : F ∈U(A)

,

1.3
The Measure Extension Theorem
23
where inf ∅= ∞. Then μ∗is an outer measure. If in addition μ is σ-subadditive,
then μ∗(A) = μ(A) for all A ∈A.
Proof We check properties (i)–(iii) of an outer measure.
(i) Since ∅∈A, we have {∅} ∈U(∅); hence μ∗(∅) = 0.
(ii) If A ⊂B, then U(A) ⊃U(B); hence μ∗(A) ≤μ∗(B).
(iii) Let An ⊂Ω for any n ∈N and let A ⊂∞
n=1 An. We show that μ∗(A) ≤
∞
n=1 μ∗(An). Without loss of generality, assume μ∗(An) < ∞and hence
U(An) ̸= ∅for all n ∈N. Fix ε > 0. For every n ∈N, choose a covering
Fn ∈U(An) such that

F∈Fn
μ(F) ≤μ∗(An) + ε 2−n.
Then F := ∞
n=1 Fn ∈U(A) and
μ∗(A) ≤

F∈F
μ(F) ≤
∞

n=1

F∈Fn
μ(F) ≤
∞

n=1
μ∗(An) + ε.
Let A ∈A. Since {A} ∈U(A), we have μ∗(A) ≤μ(A). If μ is σ-subadditive,
then for any F ∈U(A), we have 
F∈F μ(F) ≥μ(A); hence μ∗(A) ≥μ(A).
⊓⊔
Deﬁnition 1.48 (μ∗-measurable sets) Let μ∗be an outer measure. A set A ∈2Ω
is called μ∗-measurable if
μ∗(A ∩E) + μ∗(Ac ∩E) = μ∗(E)
for any E ∈2Ω.
(1.10)
We write M(μ∗) = {A ∈2Ω : A is μ∗-measurable}.
Lemma 1.49 A ∈M(μ∗) if and only if
μ∗(A ∩E) + μ∗(Ac ∩E) ≤μ∗(E)
for any E ∈2Ω.
Proof As μ∗is subadditive, the other inequality is trivial.
⊓⊔
Lemma 1.50 M(μ∗) is an algebra.
Proof We check properties (i)–(iii) of an algebra from Theorem 1.7.
(i) Ω ∈M(μ∗) is evident.
(ii) (Closedness under complements)
By deﬁnition, A ∈M(μ∗)
⇐⇒Ac ∈
M(μ∗).

24
1
Basic Measure Theory
(iii) (π-system)
Let A, B ∈M(μ∗) and E ∈2Ω. Then
μ∗((A ∩B) ∩E) + μ∗
(A ∩B)c ∩E

= μ∗(A ∩B ∩E) + μ∗(Ac ∩B ∩E) ∪(Ac ∩Bc ∩E) ∪(A ∩Bc ∩E)
≤μ∗(A ∩B ∩E) + μ∗(Ac ∩B ∩E)
+ μ∗(Ac ∩Bc ∩E) + μ∗(A ∩Bc ∩E)
= μ∗(B ∩E) + μ∗(Bc ∩E)
= μ∗(E).
Here we used A ∈M(μ∗) in the last but one equality and B ∈M(μ∗) in the
last equality.
⊓⊔
Lemma 1.51 An outer measure μ∗is σ-additive on M(μ∗).
Proof Let A, B ∈M(μ∗) with A ∩B = ∅. Then
μ∗(A ∪B) = μ∗(A ∩(A ∪B)) + μ∗(Ac ∩(A ∪B)) = μ∗(A) + μ∗(B).
Inductively, we get (ﬁnite) additivity. By deﬁnition, μ∗is σ-subadditive; hence we
conclude by Theorem 1.36 that μ∗is also σ-additive.
⊓⊔
Lemma 1.52 If μ∗is an outer measure, then M(μ∗) is a σ-algebra. In particular,
μ∗is a measure on M(μ∗).
Proof By Lemma 1.50, M(μ∗) is an algebra and hence a π-system. By Theo-
rem 1.18, it is sufﬁcient to show that M(μ∗) is a λ-system.
Hence, let A1, A2, . . . ∈M(μ∗) be mutually disjoint, and deﬁne A :=
∞

n=1
An.
We have to show A ∈M(μ∗); that is,
μ∗(A ∩E) + μ∗(Ac ∩E) ≤μ∗(E)
for any E ∈2Ω.
(1.11)
Let Bn =
n
i=1
Ai for all n ∈N. For all n ∈N, we have
μ∗(E ∩Bn+1) = μ∗
(E ∩Bn+1) ∩Bn

+ μ∗
(E ∩Bn+1) ∩Bc
n

= μ∗(E ∩Bn) + μ∗(E ∩An+1).

1.3
The Measure Extension Theorem
25
Inductively, we get μ∗(E ∩Bn) = n
i=1 μ∗(E ∩Ai). The monotonicity of μ∗now
implies that
μ∗(E) = μ∗(E ∩Bn) + μ∗(E ∩Bc
n) ≥μ∗(E ∩Bn) + μ∗(E ∩Ac)
=
n

i=1
μ∗(E ∩Ai) + μ∗(E ∩Ac).
Letting n →∞and using the σ-subadditivity of μ∗, we conclude
μ∗(E) ≥
∞

i=1
μ∗(E ∩Ai) + μ∗(E ∩Ac) ≥μ∗(E ∩A) + μ∗(E ∩Ac).
Hence (1.11) holds and the proof is complete.
⊓⊔
We come to an extension theorem for measures that makes slightly weaker
assumptions than Carathéodory’s theorem (Theorem 1.41).
Theorem 1.53 (Extension theorem for measures) Let A be a semiring and let μ :
A →[0, ∞] be an additive, σ-subadditive and σ-ﬁnite set function with μ(∅) = 0.
Then there is a unique σ-ﬁnite measure μ : σ(A) →[0, ∞] such that μ(A) =
μ(A) for all A ∈A.
Proof As A is a π-system, uniqueness follows by Lemma 1.42.
In order to establish the existence of μ, we deﬁne as in Lemma 1.47
μ∗(A) := inf
 
F∈F
μ(F) : F ∈U(A)

for any A ∈2Ω.
By Lemma 1.47, μ∗is an outer measure and μ∗(A) = μ(A) for any A ∈A. We
have to show that M(μ∗) ⊃σ(A). Since M(μ∗) is a σ-algebra (Lemma 1.52), it
is enough to show A ⊂M(μ∗).
To this end, let A ∈A and E ∈2Ω with μ∗(E) < ∞. Fix ε > 0. Then there is a
sequence E1, E2, . . . ∈A such that
E ⊂
∞

n=1
En
and
∞

n=1
μ(En) ≤μ∗(E) + ε.
Deﬁne Bn := En ∩A ∈A . Since A is a semiring, for every n ∈N there is an
mn ∈N and sets C1
n, . . . , Cmn
n
∈A such that En \ A = En \ Bn =
mn

k=1
Ck
n. Hence
E ∩A ⊂
∞

n=1
Bn,
E ∩Ac ⊂
∞

n=1
mn

k=1
Ck
n
and
En = Bn ⊎
mn

k=1
Ck
n.

26
1
Basic Measure Theory
By the deﬁnition of the outer measure and since μ is assumed to be (ﬁnitely)
additive, we get
μ∗(E ∩A) + μ∗(E ∩Ac) ≤
∞

n=1
μ(Bn) +
∞

n=1
mn

k=1
μ(Ck
n)
=
∞

n=1

μ(Bn) +
mn

k=1
μ(Ck
n)

=
∞

n=1
μ(En)
≤μ∗(E) + ε.
Hence μ∗(E ∩A) + μ∗(E ∩Ac) ≤μ∗(E) and thus A ∈M(μ∗), which implies
A ⊂M(μ∗). Now deﬁne μ : σ(A) →[0, ∞], A →μ∗(A). By Lemma 1.51, μ is
a measure and μ is σ-ﬁnite since μ is σ-ﬁnite.
⊓⊔
Reﬂection In Theorem 1.53, in general, μ cannot be extended to a measure on all
of 2Ω. Why? At which point would the proof fail? Usually it is difﬁcult to show in a
speciﬁc situation that the extension to 2Ω is impossible. We refer to analysis books
like [37] where Vitali sets are used in order to show that the Lebesgue measure
cannot be deﬁned on 2R. ♠♠
Example 1.54 (Lebesgue measure, continuation of Example 1.39) We aim at
extending the volume μ((a, b]) = n
i=1(bi −ai) that was deﬁned on the class
of rectangles A = {(a, b] : a, b ∈Rn, a ≤b} to the Borel σ-algebra B(Rn). In
order to check the assumptions of Theorem 1.53, we only have to check that μ is
σ-subadditive. To this end, let (a, b], (a(1), b(1)], (a(2), b(2)], . . . ∈A with
(a, b] ⊂
∞

k=1
(a(k), b(k)].
We show that
μ((a, b]) ≤
∞

k=1
μ(a(k), b(k)].
(1.12)
For this purpose we use a compactness argument to reduce (1.12) to ﬁnite additivity.
Fix ε > 0. For any k ∈N, choose bε(k) > b(k) such that
μ

(a(k), bε(k)]

≤μ

(a(k), b(k)]

+ ε 2−k−1.

1.3
The Measure Extension Theorem
27
Further choose aε ∈(a, b) such that μ((aε, b]) ≥μ((a, b]) −ε
2. Now [aε, b] is
compact and
∞

k=1
(a(k), bε(k)) ⊃
∞

k=1
(a(k), b(k)] ⊃(a, b] ⊃[aε, b],
whence there exists a K0 such that K0
k=1(a(k), bε(k)) ⊃(aε, b]. As μ is (ﬁnitely)
subadditive (see Lemma 1.31(iii)), we obtain
μ((a, b]) ≤ε
2 + μ((aε, b]) ≤ε
2 +
K0

k=1
μ((a(k), bε(k)])
≤ε
2 +
K0

k=1

ε 2−k−1 + μ((a(k), b(k)])

≤ε +
∞

k=1
μ((a(k), b(k)]).
Letting ε ↓0 yields (1.12); hence μ is σ-subadditive. ♦
Combining the last example with Theorem 1.53, we have shown the following
theorem.
Theorem 1.55 (Lebesgue measure)
There exists a uniquely determined measure
λn on

Rn, B(Rn)

with the property that
λn((a, b]) =
n

i=1
(bi −ai)
for all a, b ∈Rn with a < b.
λn is called the Lebesgue measure on Rn, B(Rn) or Lebesgue–Borel measure.
Example 1.56 (Lebesgue–Stieltjes measure) Let Ω = R and A = {(a, b] : a, b ∈
R, a ≤b}. A is a semiring and σ(A) = B(R), where B(R) is the Borel σ-algebra
on R. Furthermore, let F : R →R be monotone increasing and right continuous.
We deﬁne a set function
˜μF : A →[0, ∞),
(a, b] →F(b) −F(a).
Clearly, ˜μF (∅) = 0 and ˜μF is additive.
Let (a, b], (a(1), b(1)], (a(2), b(2)], . . . ∈A such that (a, b] ⊂∞
n=1(a(n),
b(n)] and a < b. Fix ε > 0 and choose aε ∈(a, b) such that F(aε) −F(a) < ε/2.
This is possible, as F is right continuous. For any k ∈N, choose bε(k) > b(k) such
that
F(bε(k)) −F(b(k)) < ε 2−k−1.

28
1
Basic Measure Theory
As in Example 1.54, it can be shown that ˜μF ((a, b]) ≤ε +∞
k=1 ˜μF ((a(k), b(k)]).
This implies that ˜μF is σ-subadditive. By Theorem 1.53, we can extend ˜μF
uniquely to a σ-ﬁnite measure μF on B(R). ♦
Deﬁnition 1.57 (Lebesgue–Stieltjes measure) The measure μF on

R, B(R)

deﬁned by
μF((a, b]) = F(b) −F(a)
for all a, b ∈R with a < b
is called the Lebesgue–Stieltjes measure with distribution function F.
Example 1.58 Important special cases for the Lebesgue–Stieltjes measure are the
following:
(i) If F(x) = x, then μF = λ1 is the Lebesgue measure on R.
(ii) Let f : R →[0, ∞) be continuous and let F(x) =
 x
0
f (t) dt for all x ∈R.
Then μF is the extension of the premeasure with density f that was deﬁned in
Example 1.30(ix).
(iii) Let x1, x2, . . . ∈R and αn ≥0 for all n ∈N such that ∞
n=1 αn < ∞.
Then F = ∞
n=1 αn 1[xn,∞) is the distribution function of the ﬁnite measure
μF = ∞
n=1 αnδxn.
(iv) Let x1, x2, . . . ∈R such that μ = ∞
n=1 δxn is a σ-ﬁnite measure. Then μ
is a Lebesgue–Stieltjes measure if and only if the sequence (xn)n∈N does not
have a limit point. Indeed, if (xn)n∈N does not have a limit point, then by the
Bolzano–Weierstraß theorem, #{n ∈N : xn ∈[−K, K]} < ∞for every
K > 0. If we let F(x) = #{n ∈N : xn ∈[0, x]} for x ≥0 and F(x) =
−#{n ∈N : xn ∈(x, 0)} for x < 0, then μ = μF . On the other hand, if μ is a
Lebesgue–Stieltjes measure, this is μ = μF for some F, then #{n ∈N : xn ∈
(−K, K]} = F(K) −F(−K) < ∞for all K > 0; hence (xn)n∈N does not
have a limit point.
(v) If lim
x→∞

F(x) −F(−x)

= 1, then μF is a probability measure. ♦
We will now have a closer look at the case where μF is a probability measure.
Deﬁnition 1.59 (Distribution function) A right continuous monotone increasing
function F : R →[0, 1] with F(−∞) :=
lim
x→−∞F(x) = 0 and F(∞) :=
lim
x→∞F(x) = 1 is called a (proper) probability distribution function (p.d.f.). If we
only have F(∞) ≤1 instead of F(∞) = 1, then F is called a (possibly) defective
p.d.f. If μ is a (sub-) probability measure on R, B(R), then Fμ : x →μ((−∞, x])
is called the distribution function of μ.
Clearly, Fμ is right continuous and Fμ(−∞) = 0, since μ is upper semicontinuous
and ﬁnite (Theorem 1.36). Since μ is lower semicontinuous, we have Fμ(∞) =
μ(R); hence Fμ is indeed a (possibly defective) distribution function if μ is a (sub-)
probability measure.

1.3
The Measure Extension Theorem
29
The argument of Example 1.56 yields the following theorem.
Theorem 1.60 The map μ →Fμ is a bijection from the set of probability measures
on

R, B(R)

to the set of probability distribution functions, respectively from the
set of sub-probability measures to the set of defective distribution functions.
We have established that every ﬁnite measure on

R, B(R)

is a Lebesgue–Stieltjes
measure for some function F. For σ-ﬁnite measures, the corresponding statement
does not hold in this generality as we saw in Example 1.58(iv).
We come now to a theorem that combines Theorem 1.55 with the idea of
Lebesgue–Stieltjes measures. Later we will see that the following theorem is valid
in greater generality. In particular, the assumption that the factors are of Lebesgue–
Stieltjes type can be dropped.
Theorem 1.61 (Finite products of measures)
Let n ∈N and let μ1, . . . , μn be
ﬁnite measures or, more generally, Lebesgue–Stieltjes measures on R, B(R). Then
there exists a unique σ-ﬁnite measure μ on Rn, B(Rn) such that
μ((a, b]) =
n

i=1
μi((ai, bi])
for all a, b ∈Rn with a < b.
We call μ =:
n
 
i=1
μi the product measure of the measures μ1, . . . , μn.
Proof The proof is the same as for Theorem 1.55. One has to check that the intervals
(a, bε] and so on can be chosen such that μ((a, bε]) < μ((a, b]) + ε. Here we
employ the right continuity of the increasing function Fi that belongs to μi. The
details are left as an exercise.
⊓⊔
Remark 1.62 Later we will see in Theorem 14.14 that the statement holds even
for arbitrary σ-ﬁnite measures μ1, . . . , μn on arbitrary (even different) measurable
spaces. One can even construct inﬁnite products if all factors are probability spaces
(Theorem 14.39). ♦
Example 1.63 (Inﬁnite product measure, continuation of Example 1.40) Let E be a
ﬁnite set and let Ω = EN be the space of E-valued sequences. Further, let (pe)e∈E
be a probability vector. Deﬁne a content μ on A = {[ω1, . . . , ωn] : ω1, . . . , ωn ∈
E, n ∈N} by
μ([ω1, . . . , ωn]) =
n

i=1
pωi.
We aim at extending μ to a measure on σ(A). In order to check the assumptions
of Theorem 1.53, we have to show that μ is σ-subadditive. As in the preceding
example, we use a compactness argument.

30
1
Basic Measure Theory
Let A, A1, A2, . . . ∈A and A ⊂∞
n=1 An. We are done if we can show that
there exists an N ∈N such that
A ⊂
N

n=1
An.
(1.13)
Indeed, due to the (ﬁnite) subadditivity of μ (see Lemma 1.31(iii)), this implies
μ(A) ≤
N
n=1
μ(An) ≤
∞

n=1
μ(An); hence μ is σ-subadditive.
We now give two different proofs for (1.13).
1. Proof.
The metric d from (1.9) induces the product topology on Ω; hence, as
remarked in Example 1.40, (Ω, d) is a compact metric space. Every A ∈A
is closed and thus compact. Since every An is also open, A can be covered by
ﬁnitely many An; hence (1.13) holds.
2. Proof.
We now show by elementary means the validity of (1.13). The procedure
imitates the proof that Ω is compact. Let Bn := A\n
i=1 Ai. We assume Bn ̸= ∅
for all n ∈N in order to get a contradiction. By Dirichlet’s pigeonhole principle
(recall that E is ﬁnite), we can choose ω1 ∈E such that [ω1] ∩Bn ̸= ∅for
inﬁnitely many n ∈N. Since B1 ⊃B2 ⊃. . ., we obtain
[ω1] ∩Bn ̸= ∅
for all n ∈N.
Successively choose ω2, ω3, . . . ∈E in such a way that
[ω1, . . . , ωk] ∩Bn ̸= ∅
for all k, n ∈N.
Bn is a disjoint union of certain sets Cn,1, . . . , Cn,mn ∈A. Hence, for every
n ∈N there is an in ∈{1, . . . , mn} such that [ω1, . . . , ωk] ∩Cn,in ̸= ∅for
inﬁnitely many k ∈N. Since [ω1] ⊃[ω1, ω2] ⊃. . ., we obtain
[ω1, . . . , ωk] ∩Cn,in ̸= ∅
for all k, n ∈N.
For ﬁxed n ∈N and large k, we have [ω1, . . . , ωk] ⊂Cn,in. Hence ω =
(ω1, ω2, . . .) ∈Cn,in ⊂Bn. This implies ∞
n=1 Bn ̸= ∅, contradicting the
assumption. ♦
Combining the last example with Theorem 1.53, we have shown the following
theorem.
Theorem 1.64 (Product measure, Bernoulli measure) Let E be a ﬁnite nonempty
set and Ω = EN. Let (pe)e∈E be a probability vector. Then there exists a unique
probability measure μ on σ(A) = B(Ω) such that
μ([ω1, . . . , ωn]) =
n

i=1
pωi
for all ω1, . . . , ωn ∈E and n ∈N.

1.3
The Measure Extension Theorem
31
μ is called the product measure or Bernoulli measure on Ω with weights (pe)e∈E.
We write

e∈E peδe
⊗N := μ. The σ-algebra (2E)⊗N := σ(A) is called the
product σ-algebra on Ω.
We will study product measures in a systematic way in Chap. 14.
The measure extension theorem yields an abstract statement of existence and
uniqueness for measures on σ(A) that were ﬁrst deﬁned on a semiring A only. The
following theorem, however, shows that the measure of a set from σ(A) can be well
approximated by ﬁnite and countable operations with sets from A.
Denote by
A △B := (A \ B) ∪(B \ A)
for A, B ⊂Ω
(1.14)
the symmetric difference of the two sets A and B.
Theorem 1.65 (Approximation theorem for measures)
Let A ⊂2Ω be a
semiring and let μ be a measure on σ(A) that is σ-ﬁnite on A.
(i) For any A ∈σ(A) and ε > 0, there exist mutually disjoint sets A1, A2, . . . ∈A
such that A ⊂
∞

n=1
An and μ
 ∞

n=1
An \ A

< ε.
(ii) For any A ∈σ(A) with μ(A) < ∞and any ε > 0, there exists an n ∈N and
mutually disjoint sets A1, . . . , An ∈A such that μ

A △
n
k=1
Ak

< ε.
(iii) For any A ∈M(μ∗), there are sets A−, A+ ∈σ(A) with A−⊂A ⊂A+ and
μ(A+ \ A−) = 0.
Remark 1.66 (iii) implies that (i) and (ii) also hold for A ∈M(μ∗) (with μ∗
instead of μ). If A is an algebra, then in (ii) for any A ∈σ(A), we even have
infB∈A μ(A △B) = 0. ♦
Proof (ii)
As μ and the outer measure μ∗coincide on σ(A) and since μ(A)
is ﬁnite, by the very deﬁnition of μ∗(see Lemma 1.47) there exists a covering
B1, B2, . . . ∈A of A such that
μ(A) ≥
∞

i=1
μ(Bi) −ε/2.
Let n ∈N with
∞

i=n+1
μ(Bi) < ε
2 (such an n exists since μ(A) < ∞). For any three
sets C, D, E, we have
C △D = (D \ C) ∪(C \ D) ⊂(D \ C) ∪(C \ (D ∪E)) ∪E ⊂(C △(D ∪E)) ∪E.

32
1
Basic Measure Theory
Choosing C = A, D = n
i=1 Bi and E = ∞
i=n+1 Bi, this yields
μ

A △
n

i=1
Bi

≤μ

A △
∞

i=1
Bi

+ μ

∞

i=n+1
Bi

≤μ
 ∞

i=1
Bi

−μ(A) + ε
2 ≤ε.
As A is a semiring, there exist a k ∈N and A1, . . . , Ak ∈A such that
n

i=1
Bi = B1 ⊎
n

i=2
i−1

j=1
(Bi \ Bj) =:
k
i=1
Ai.
(i) Let A ∈σ(A) and En ↑Ω, En ∈σ(A) with μ(En) < ∞for any n ∈N. For
every n ∈N, choose a covering (Bn,m)m∈N of A ∩En with
μ(A ∩En) ≥
∞

m=1
μ(Bn,m) −2−nε.
(This is possible due to the deﬁnition of the outer measure μ∗, which coincides
with μ on A.) Let
∞

m,n=1
Bn,m =
∞

n=1
An for certain An ∈A, n ∈N
(Exercise 1.1.1). Then
μ
 ∞

n=1
An \ A

= μ
 ∞

n=1
∞

m=1
Bn,m \ A

≤μ
 ∞

n=1
∞

m=1

Bn,m \ (A ∩En)


≤
∞

n=1
 ∞

m=1
μ(Bn,m)

−μ(A ∩En)

≤ε.
(iii) Let A ∈M(μ∗) and (En)n∈N as above. For any m, n ∈N, choose An,m ∈
σ(A) such that An,m ⊃A ∩En and μ∗(An,m) ≤μ∗(A ∩En) + 2−n
m .

1.3
The Measure Extension Theorem
33
Deﬁne Am :=
∞

n=1
An,m ∈σ(A). Then Am ⊃A and μ∗(Am \ A) ≤1
m. Deﬁne
A+ :=
∞

m=1
Am. Then σ(A) ∋A+ ⊃A and μ∗(A+\A) = 0. Similarly, choose
(A−)c ∈σ(A) with (A−)c ⊃Ac and μ∗((A−)c \ Ac) = 0. Then A+ ⊃A ⊃
A−and μ(A+ \ A−) = μ∗(A+ \ A−) = μ∗(A+ \ A) + μ∗(A \ A−) = 0.
⊓⊔
Remark 1.67 (Regularity of measures)
(Compare with Theorem 13.6.) Let λn be
the Lebesgue measure on

Rn, B(Rn)

. Let A be the semiring of rectangles of the
form (a, b] ⊂Rn; hence B(Rn) = σ(A) by Theorem 1.23. By the approximation
theorem, for any A ∈B(Rn) and ε > 0, there exist countably many A1, A2, . . . ∈A
with A ⊂∞
i=1 Ai and
λn
 ∞

i=1
Ai \ A

< ε/2.
For any Ai, there exists an open rectangle Bi ⊃Ai with λn(Bi \ Ai) < ε 2−i−1
(upper semicontinuity of λn). Hence U = ∞
i=1 Bi is an open set U ⊃A with
λn(U \ A) < ε.
This property of λn is called outer regularity.
If λn(A) is ﬁnite, then for any ε > 0 there exists a compact K ⊂A such that
λn(A \ K) < ε.
This property of λn is called inner regularity. Indeed, let N > 0 be such that
λn(A)−λn(A∩[−N, N]n) < ε/2. Choose an open set U ⊃(A∩[−N, N]n)c such
that λn(U \ (A ∩[−N, N]n)c) < ε/2, and let K := [−N, N]n \ U ⊂A. ♦
Deﬁnition 1.68 (Null set) Let (Ω, A, μ) be a measure space.
(i) A set A ∈A is called a μ-null set, or brieﬂy a null set, if μ(A) = 0. By Nμ
we denote the class of all subsets of μ-null sets.
(ii) Let E(ω) be a property that a point ω ∈Ω can have or not have. We say that
E holds μ-almost everywhere (a.e.) or for almost all (a.a.) ω if there exists a
null set N such that E(ω) holds for every ω ∈Ω \ N. If A ∈A and if there
exists a null set N such that E(ω) holds for every ω ∈A \ N, then we say that
E holds almost everywhere on A.
If μ = P is a probability measure, then we say that E holds P-almost surely
(a.s.), respectively almost surely on A.
(iii) Let A, B ∈A be such that μ(A △B) = 0. Then we write A = B
(mod μ).
Deﬁnition 1.69 A measure space (Ω, A, μ) is called complete if Nμ ⊂A.

34
1
Basic Measure Theory
Remark 1.70 (Completion of a measure space) Let (Ω, A, μ) be a σ-ﬁnite measure
space. There exists a unique smallest σ-algebra A∗⊃A and an extension μ∗of μ
to A∗such that (Ω, A∗, μ∗) is complete. (Ω, A∗, μ∗) is called the completion of
(Ω, A, μ). With the notation of Theorem 1.53, this completion is

Ω, M(μ∗), μ∗M(μ∗)

.
Furthermore,
M(μ∗) = σ(A ∪Nμ) = {A ∪N : A ∈A, N ∈Nμ}
and μ∗(A ∪N) = μ(A) for any A ∈A and N ∈Nμ.
In the following, we will not need these statements. Hence, instead of giving a
proof, we refer to the textbooks on measure theory (e.g., [37]). ♦
Example 1.71 Let λ be the Lebesgue measure (more accurately, the Lebesgue–
Borel measure) on

Rn, B(Rn)

. Then λ can be extended uniquely to a measure
λ∗on
B∗(Rn) = σB(Rn) ∪N,
where N is the class of subsets of Lebesgue–Borel null sets. B∗(Rn) is called the
σ-algebra of Lebesgue measurable sets. For the sake of distinction, we sometimes
call λ the Lebesgue–Borel measure and λ∗the Lebesgue measure. However, in
practice, this distinction will not be needed in this book. ♦
Example 1.72 Let μ = δω be the Dirac measure for the point ω ∈Ω on some
measurable space (Ω, A). If {ω} ∈A, then the completion is A∗= 2Ω, μ∗= δω.
In the extreme case of a trivial σ-algebra A = {∅, Ω}, however, the empty set is the
only null set, Nμ = {∅}; hence A∗= {∅, Ω}, μ∗= δω. Note that, on the trivial
σ-algebra, Dirac measures for different points ω ∈Ω cannot be distinguished. ♦
Deﬁnition 1.73 Let (Ω, A, μ) be a measure space and Ω′ ∈A. On the trace σ-
algebra A
Ω′, we deﬁne a measure by
μ
Ω′(A) := μ(A)
for A ∈A with A ⊂Ω′.
This measure is called the restriction of μ to Ω′.
Example 1.74 The restriction of the Lebesgue–Borel measure λ on

R, B(R)

to [0, 1] is a probability measure on ([0, 1], B(R)
[0,1]). More generally, for a
measurable A ∈B(R), we call the restriction λ
A the Lebesgue measure on A.
Often this measure will be denoted by the same symbol λ when there is no danger
of ambiguity.

1.3
The Measure Extension Theorem
35
Later we will see (Corollary 1.84) that B(R)
A = B(A), where B(A) is the Borel
σ-algebra on A that is generated by the (relatively) open subsets of A. ♦
Example 1.75 (Uniform distribution) Let A ∈B(Rn) be a measurable set with n-
dimensional Lebesgue measure λn(A) ∈(0, ∞). Then we can deﬁne a probability
measure on B(Rn)
A by
μ(B) := λn(B)
λn(A)
for B ∈B(Rn) with B ⊂A.
This measure μ is called the uniform distribution on A and will be denoted by
UA := μ. ♦
Takeaways The measure extension theorem shows how to extend contents
from semirings to σ-algebras but usually does not give a concrete con-
struction. However, in the special case where the content was deﬁned on
an algebra in the ﬁrst place, the measure on sets of the σ-algebra can be
approximated arbitrarily well by sets from the algebra. This will be helpful
in many places. In order for the measure extension to work, σ-additivity
is decisive. It is an interesting ﬁnding that in two important examples we
could check σ-subadditivity using topological properties. More speciﬁcally,
we used compactness arguments. At that point it was only a small step to
show that the Lebesgue measure is regular in the sense that the measure of an
arbitrary measurable set can be approximated by compact subsets as well as
by open supersets.
Exercise 1.3.1 Show the following generalization of Example 1.58(iv): A measure
∞
n=1 αnδxn is a Lebesgue–Stieltjes measure for a suitable function F if and only if

n: |xn|≤K αn < ∞for all K > 0. ♣
Exercise 1.3.2 Let Ω be an uncountably inﬁnite set and let ω0 ∈Ω be an arbitrary
element. Let A = σ({ω} : ω ∈Ω \ {ω0}).
(i) Give a characterization of A as in Exercise 1.1.4 (page 11).
(ii) Show that (Ω, A, δω0) is complete. ♣
Exercise 1.3.3 Let (μn)n∈N be a sequence of ﬁnite measures on the measurable
space (Ω, A). Assume that for any A ∈A there exists the limit μ(A) :=
lim
n→∞μn(A).
Show that μ is a measure on (Ω, A).
Hint: In particular, one has to show that μ is ∅-continuous. ♣

36
1
Basic Measure Theory
1.4
Measurable Maps
A major task of mathematics is to study homomorphisms between objects; that is,
structure-preserving maps. For topological spaces, these are the continuous maps,
and for measurable spaces, these are the measurable maps.
In the rest of this chapter, we let (Ω, A) and (Ω′, A′) be measurable spaces.
Deﬁnition 1.76 (Measurable maps)
(i) A map X : Ω →Ω′ is called A – A′-measurable (or, brieﬂy, measurable) if
X−1(A′) := {X−1(A′) : A′ ∈A′} ⊂A; that is, if
X−1(A′) ∈A
for any A′ ∈A′.
If X is measurable, we write X : (Ω, A) →(Ω′, A′).
(ii) If Ω′ = R and A′ = B(R) is the Borel σ-algebra on R, then X : (Ω, A) →

R, B(R)

is called an A-measurable real map.
Example 1.77
(i) The identity map id : Ω →Ω is A – A-measurable.
(ii) If A = 2Ω or A′ = {∅, Ω′}, then any map X : Ω →Ω′ is A – A′-measurable.
(iii) Let A ⊂Ω. The indicator function 1A : Ω →{0, 1} is A – 2{0,1}-measurable
if and only if A ∈A. ♦
Theorem 1.78 (Generated σ-algebra) Let (Ω′, A′) be a measurable space and
let Ω be a nonempty set. Let X : Ω →Ω′ be a map. The preimage
X−1(A′) := {X−1(A′) : A′ ∈A′}
(1.15)
is the smallest σ-algebra with respect to which X is measurable. We say that
σ(X) := X−1(A′) is the σ-algebra on Ω that is generated by X.
Proof This is left as an exercise.
⊓⊔
We now consider σ-algebras that are generated by more than one map.
Deﬁnition 1.79 (Generated σ-algebra)
Let Ω be a nonempty set. Let I be an
arbitrary index set. For any i ∈I, let (Ωi, Ai) be a measurable space and let
Xi : Ω →Ωi be an arbitrary map. Then
σ(Xi, i ∈I) := σ

i∈I
σ(Xi)

= σ

i∈I
X−1
i
(Ai)

is called the σ-algebra on Ω that is generated by (Xi, i ∈I). This is the smallest
σ-algebra with respect to which all Xi are measurable.
As with continuous maps, the composition of measurable maps is again measurable.

1.4
Measurable Maps
37
Theorem 1.80 (Composition of maps) Let (Ω, A), (Ω′, A′) and (Ω′′, A′′) be
measurable spaces and let X : Ω →Ω′ and X′ : Ω′ →Ω′′ be measurable maps.
Then the map Y := X′ ◦X : Ω →Ω′′, ω →X′(X(ω)) is A – A′′-measurable.
Proof Obvious, since Y −1(A′′) = X−1((X′)−1(A′′)) ⊂X−1(A′) ⊂A.
⊓⊔
In practice, it is often not possible to check if a map X is measurable by checking
if all preimages X−1(A′), A′ ∈A′ are measurable. Most σ-algebras A′ are simply
too large. Thus it comes in very handy that it is sufﬁcient to check measurability on
a generator of A′ by the following theorem.
Theorem 1.81 (Measurability on a generator) Let E′ ⊂A′ be a class of A′-
measurable sets. Then σ(X−1(E′)) = X−1(σ(E′)) and hence
X is A - σ(E′)-measurable ⇐⇒X−1(E′) ∈A
for all E′ ∈E′.
If in particular σ(E′) = A′, then
X is A −−A′-measurable ⇐⇒
X−1(E′) ⊂A.
Proof Clearly, X−1(E′) ⊂X−1
σ(E′)

= σ

X−1(σ(E′))

. Hence also
σ

X−1(E′)

⊂X−1
σ(E′)

.
For the other inclusion, consider the class of sets
A′
0 :=
	
A′ ∈σ(E′) : X−1(A′) ∈σ(X−1(E′))

.
We ﬁrst show that A′
0 is a σ-algebra by checking (i)–(iii) of Deﬁnition 1.2:
(i) Clearly, Ω′ ∈A′
0.
(ii) (Stability under complements)
If A′ ∈A′
0, then
X−1((A′)c) = (X−1(A′))c ∈σ(X−1(E′));
hence (A′)c ∈A′
0.
(iii) (σ-∪-stability)
Let A′
1, A′
2, . . . ∈A′
0. Then
X−1
 ∞

n=1
A′
n

=
∞

n=1
X−1(A′
n) ∈σ(X−1(E′));
hence ∞
n=1 A′
n ∈A′
0.
Now A′
0 = σ(E′) since E′ ⊂A′
0. Hence X−1(A′) ∈σ(X−1(E′)) for any A′ ∈
σ(E′) and thus X−1(σ(E′)) ⊂σ(X−1(E′)).
⊓⊔

38
1
Basic Measure Theory
Corollary 1.82 (Measurability of composed maps) Let I be a nonempty index
set and let (Ω, A), (Ω′, A′) and (Ωi, Ai) be measurable spaces for any i ∈I.
Further, let (Xi : i ∈I) be a family of measurable maps Xi : Ω′ →Ωi with
A′ = σ(Xi : i ∈I). Then the following holds: A map Y : Ω →Ω′ is A –
A′-measurable if and only if Xi ◦Y is A – Ai-measurable for all i ∈I.
Proof If Y is measurable, then by Theorem 1.80 every Xi ◦Y is measurable. Now
assume that all of the composed maps Xi◦Y are A – Ai-measurable. By assumption,
the set E′ := {X−1
i
(A′′) : A′′ ∈Ai, i ∈I} is a generator of A′. Since all Xi ◦Y
are measurable, we have Y −1(A′) ∈A for any A′ ∈E′. Hence Theorem 1.81 yields
that Y is measurable.
⊓⊔
Recall the deﬁnition of the trace of a class of sets from Deﬁnition 1.25.
Corollary 1.83 (Trace of a generated σ-algebra) Let E ⊂2Ω and assume that
A ⊂Ω is nonempty. Then σE
A
 = σ(E)
A.
Proof Let X : A →Ω, ω →ω be the canonical inclusion; hence X−1(B) = A∩B
for all B ⊂Ω. By Theorem 1.81, we have
σ

E
A

= σ({E ∩A : E ∈E})
= σ({X−1(E) : E ∈E}) = σ(X−1(E))
= X−1(σ(E)) = {A ∩B : B ∈σ(E)} = σ(E)
A.
⊓⊔
Recall that, for any subset A ⊂Ω of a topological space (Ω, τ), the class τ
A is
the topology of relatively open sets (in A). We denote by B(Ω, τ) = σ(τ) the Borel
σ-algebra on (Ω, τ).
Corollary 1.84 (Trace of the Borel σ-algebra) Let (Ω, τ) be a topological space
and let A ⊂Ω be a nonempty subset of Ω. Then
B(Ω, τ)
A = B

A, τ
A

.
Example 1.85
(i) Let Ω′ be countable. Then X : Ω →Ω′ is A – 2Ω′-measurable if and only if
X−1({ω′}) ∈A for all ω′ ∈Ω′. If Ω′ is uncountably inﬁnite, this is wrong in
general. (For example, consider Ω = Ω′ = R, A = B(R), and X(ω) = ω for
all ω ∈Ω. Clearly, X−1({ω}) = {ω} ∈B(R). If, on the other hand, A ⊂R is
not in B(R), then A ∈2R, but X−1(A) ̸∈B(R).)
(ii) For x ∈R, we agree on the following notation for rounding:
⌊x⌋:= max{k ∈Z : k ≤x}
and
⌈x⌉:= min{k ∈Z : k ≥x}.
(1.16)

1.4
Measurable Maps
39
The maps R →Z, x →⌊x⌋and x →⌈x⌉are B(R) – 2Z-measurable since for
all k ∈Z the preimages {x ∈R : ⌊x⌋= k} = [k, k + 1) and {x ∈R : ⌈x⌉=
k} = (k −1, k] are in B(R). By the composition theorem (Theorem 1.80), for
any measurable map f : (Ω, A) →R, B(R) the maps ⌊f ⌋and ⌈f ⌉are also
A – 2Z-measurable.
(iii) A map X : Ω →Rd is A – B(Rd)-measurable if and only if
X−1((−∞, a]) ∈A
for any a ∈Rd.
In fact σ((−∞, a], a ∈Rd) = B(Rd) by Theorem 1.23. The analogous
statement holds for any of the classes E1, . . . , E12 from Theorem 1.23. ♦
Example 1.86 Let d(x, y) = ∥x −y∥2 be the usual Euclidean distance on Rn and
let B(Rn, d) = B(Rn) be the Borel σ-algebra with respect to the topology generated
by d. For any subset A of Rn, we have B(A, d) = B(Rn, d)
A. ♦
We want to extend the real line by the points −∞and +∞. Thus we deﬁne
R := R ∪{−∞, +∞}.
From a topological point of view, R will be considered as the so-called two point
compactiﬁcation by considering R as topologically isomorphic to [−1, 1] via the
map
ϕ : [−1, 1] →R,
x →
⎧
⎪⎨
⎪⎩
tan(πx/2),
if x ∈(−1, 1),
−∞,
if x = −1,
∞,
if x = +1.
In fact, ¯d(x, y) =
ϕ−1(x) −ϕ−1(y)
 for x, y ∈R deﬁnes a metric on R such that
ϕ and ϕ−1 are continuous. Hence ϕ is a topological isomorphism. We denote by
¯τ the corresponding topology induced on R and by τ the usual topology on R.
Corollary 1.87 With the above notation, ¯τ
R = τ and hence B

R

R = B(R).
In particular, if X : (Ω, A) →

R, B(R)

is measurable, then in a canonical way
X is also an R-valued measurable map.
Thus R is really an extension of the real line, and the inclusion R →R is
measurable.
Reﬂection Check that each of the families E1, . . . , E12 from Theorem 1.23 (with
n = 1) is a generator for B(R). Also check that the families {[−∞, a], a ∈Q},
{[−∞, a), a ∈Q}, {[b, ∞], b ∈Q} and {(b, ∞], b ∈Q} are generators of B(R).
♠

40
1
Basic Measure Theory
Theorem 1.88 (Measurability of continuous maps) Let (Ω, τ) and (Ω′, τ ′) be
topological spaces and let f : Ω →Ω′ be a continuous map. Then f is B(Ω) –
B(Ω′)-measurable.
Proof As B(Ω′) = σ(τ ′) and by Theorem 1.81, it is sufﬁcient to show that
f −1(A′) ∈σ(τ) for all A′ ∈τ ′. However, since f is continuous, we even have
f −1(A′) ∈τ for all A′ ∈τ ′.
⊓⊔
For x, y ∈R, we agree on the following notation.
x ∨y = max(x, y)
(maximum),
x ∧y = min(x, y)
(minimum),
x+ = max(x, 0)
(positive part),
x−= max(−x, 0)
(negative part),
|x| = max(x, −x) = x−+ x+
(modulus),
sign(x) = 1{x>0} −1{x<0}
(sign function).
Analogously, for measurable real maps we write, for example, X+ = max(X, 0).
The maps x →x+, x →x−and x →|x| are continuous (and hence measurable
by the preceding theorem). Clearly, the map x →sign(x) also is measurable. Using
Corollary 1.82, we thus get the following corollary.
Corollary 1.89 If X is a real or R-valued measurable map, then the maps X−, X+,
|X| and sign(X) also are measurable.
Theorem 1.90 (Coordinate maps are measurable) Let (Ω, A) be a measurable
space and let f1, . . . , fn : Ω →R be maps. Deﬁne f := (f1, . . . , fn) : Ω →Rn.
Then
f is A −B(Rn)-measurable
⇐⇒
each fi is A −B(R)-measurable.
The analogous statement holds for fi : Ω →R := R ∪{±∞}.
Proof For b ∈Rn, we have f −1((−∞, b)) =
n
i=1
f −1
i
((−∞, bi)). If each fi is
measurable, then f −1((−∞, b)) ∈A. However, the rectangles (−∞, b), b ∈Rn,
generate B(Rn), and hence f is measurable. Now assume that f is measurable. For
i = 1, . . . , n, let πi : Rn →R, x →xi be the projection on the ith coordinate.
Clearly, πi is continuous and thus B(Rn) – B(R)-measurable. Hence fi = πi ◦f is
measurable by Theorem 1.80.
⊓⊔
In the following theorem, we agree that x
0 := 0 for all x ∈R.
Theorem 1.91 Let (Ω, A) be a measurable space. Let h : (Ω, A) →R, B(R)
and f, g : (Ω, A) →Rn, B(Rn) be measurable maps. Then also the maps f + g,
f −g, f · h and f/h are measurable.

1.4
Measurable Maps
41
Proof The map π : Rn × R →Rn, (x, α) →α · x is continuous and thus
measurable. By Theorem 1.90, (f, h) : Ω →Rn × R is measurable. Hence also
the composed map f · h = π ◦(f, h) is measurable. Similarly, we obtain the
measurability of f + g and f −g.
In order to show measurability of f/h, we deﬁne the map H : R →R, x →1/x.
Note that by our convention H(0) = 0. Hence f/h = f ·H ◦h. Thus it is enough to
show that H is measurable. Clearly, H
R\{0} is continuous. For any open set U ⊂R,
U \{0} is also open and hence H −1(U \{0}) ∈B(R). Furthermore, H −1({0}) = {0}.
Concluding, we get H −1(U) = H −1(U \ {0}) ∪(U ∩{0}) ∈B(R).
⊓⊔
Theorem 1.92 Let X1, X2, . . . be measurable maps (Ω, A) →(R, B(R)). Then
the following maps are also measurable:
inf
n∈N Xn,
sup
n∈N
Xn,
lim inf
n→∞Xn,
lim sup
n→∞
Xn.
Proof For any a ∈R, we have

inf
n∈N Xn
−1
([−∞, a)) =
∞

n=1
X−1
n ([−∞, a)) ∈A.
By Theorem 1.81, this implies that inf
n∈N Xn is measurable. The proof for sup
n∈N
Xn is
similar.
For any n ∈N, we deﬁne Yn := inf
m≥n Xm. Note that Yn is measurable and hence
lim inf
n→∞Xn := sup
n∈N
Yn also is measurable. The proof for the limes superior is similar.
⊓⊔
We come to an important example of measurable maps (Ω, A) →

R, B(R)

, the
so-called simple functions.
Deﬁnition 1.93 (Simple function) Let (Ω, A) be a measurable space. A map f :
Ω →R is called a simple function if there is an n ∈N and mutually disjoint
measurable sets A1, . . . , An ∈A, as well as numbers α1, . . . , αn ∈R, such that
f =
n

i=1
αi 1Ai.
Remark 1.94 A measurable map that assumes only ﬁnitely many values is a simple
function. (Exercise: Show this!) ♦
Deﬁnition 1.95 Assume that f, f1, f2, . . . are maps Ω →R such that
f1(ω) ≤f2(ω) ≤. . . and
lim
n→∞fn(ω) = f (ω)
for any ω ∈Ω.

42
1
Basic Measure Theory
Then we write fn ↑f and say that (fn)n∈N increases (pointwise) to f . Analogously,
we write fn ↓f if (−fn) ↑(−f ).
Theorem 1.96 Let (Ω, A) be a measurable space and let f : Ω →[0, ∞] be
measurable. Then the following statements hold.
(i) There exists a sequence (fn)n∈N of nonnegative simple functions such that fn ↑
f .
(ii) There are measurable sets A1, A2, . . . ∈A and numbers α1, α2, . . . ≥0 such
that f =
∞

n=1
αn 1An.
Proof
(i) For n ∈N0, deﬁne fn =

2−n⌊2nf ⌋

∧n. Then fn is measurable (by
Theorem 1.92 and Example 1.85(ii)) and assumes at most n2n + 1 different
values. Hence it is a simple function. Clearly, fn ↑f .
(ii) Let fn be as above. Let Bn,i := {ω : fn(ω) −fn−1(ω) = i 2−n} and βn,i =
i 2−n for n ∈N and i = 1, . . . , 2n. Hence fn −fn−1 =
2n

i=1
βn,i 1Bn,i . By
changing the numeration (n, i) →m, we get (αm)m∈N and (Am)m∈N such that
f = f0 +
∞

n=1
(fn −fn−1) =
∞

m=1
αm 1Am.
⊓⊔
As a corollary to this statement on the structure of [0, ∞]-valued measurable maps,
we show the following factorization lemma.
Corollary 1.97 (Factorization lemma) Let (Ω′, A′) be a measurable space and
let Ω be a nonempty set. Let f : Ω →Ω′ be a map. A map g : Ω →R is
σ(f ) – B(R)-measurable if and only if there is a measurable map ϕ : (Ω′, A′) →
(R, B(R)) such that g = ϕ ◦f .
Proof “ ⇐ ”
If ϕ is measurable and g = ϕ ◦f , then g is measurable by
Theorem 1.80.
“ ⇒”
Now assume that g is σ(f ) – B(R)-measurable. First consider the case
g ≥0. Then there exist measurable sets A1, A2 . . . ∈σ(f ) as well as numbers
α1, α2, . . . , ∈[0, ∞) such that g = ∞
n=1 αn 1An. By the deﬁnition of σ(f ), for
any n ∈N there is a set Bn ∈A′ such that f −1(Bn) = An; that is, such that
1An = 1Bn ◦f . Deﬁne ϕ : Ω′ →R by
ϕ =
∞

n=1
αn 1Bn.
Clearly, ϕ is A′ – B(R)-measurable and g = ϕ ◦f .

1.4
Measurable Maps
43
Now drop the assumption that g is nonnegative. Then there exist measurable
maps ϕ−and ϕ+ such that g−= ϕ−◦f and g+ = ϕ+ ◦f . Note that g+(ω) ∧
g−(ω) = 0 for all ω ∈Ω. Hence
ω →ϕ(ω) :=

ϕ+(ω) −ϕ−(ω),
if ϕ+(ω) < ∞or ϕ−(ω) < ∞,
0,
else
does the trick.
⊓⊔
A measurable map transports a measure from one space to another.
Deﬁnition 1.98 (Image measure) Let (Ω, A) and (Ω′, A′) be measurable spaces
and let μ be a measure on (Ω, A). Further, let X : (Ω, A) →(Ω′, A′) be
measurable. The image measure of μ under the map X is the measure μ ◦X−1
on (Ω′, A′) that is deﬁned by
μ ◦X−1 : A′ →[0, ∞],
A′ →μ(X−1(A′)).
Example 1.99 Let μ be a measure on Z2 and let X : Z2 →Z, (x, y) →x + y.
Then
μ ◦X−1({x}) =

y∈Z
μ({(x −y, y)}).
♦
Example 1.100 Let L : Rn →Rn be a linear bijection and let λ be the Lebesgue
measure on

Rn, B(Rn)

. Then λ ◦L−1
= | det(L)|−1λ. This is clear since
for any a, b ∈Rn with a < b, the parallelepiped L−1((a, b]) has volume
| det(L−1)| n
i=1(bi −ai). ♦
As a generalization of the last example, we state without proof the transformation
formula for measures with continuous densities under differentiable maps. The
proof can be found in textbooks on calculus.
Theorem 1.101 (Transformation formula in Rn) Let μ be a measure on Rn that
has a continuous (or piecewise continuous) density f : Rn →[0, ∞). That is,
μ((x, y]) =
 y1
x1
dt1 · · ·
 yn
xn
dtn f (t1, . . . , tn)
for all x, y ∈Rn, x ≤y.

44
1
Basic Measure Theory
Let A ⊂Rn be an open or a closed subset of Rn with μ(Rn \ A) = 0. Further,
let B ⊂Rn be open or closed. Finally, assume that ϕ : A →B is a continuously
differentiable bijection with derivative ϕ′. Then the image measure μ ◦ϕ−1 has the
density
fϕ(x) =
⎧
⎪⎪⎨
⎪⎪⎩
f (ϕ−1(x))
| det(ϕ′(ϕ−1(x)))|,
if x ∈B mit det(ϕ′(ϕ−1(x))) ̸= 0,
0,
else.
Takeaways Measurable maps are the natural maps between two measurable
spaces as they are structure preserving. We have encountered conditions for
measurability that are easy to check, e.g., continuity and measurability on a
generator. Furthermore, we have seen that compositions of measurable maps,
vectors of measurable maps and so on are again measurable.
Exercise 1.4.1 Let f : R →R, x →|x|. Show that a Borel measurable map
g : R →R is σ(f ) = f −1(B(R))-measurable if and only if g is even. ♣
Exercise 1.4.2 Let (Ω, A, μ) be a measure space and let f
: Ω
→R be
measurable. Assume that g : Ω →R fulﬁlls g = f μ-almost everywhere. Show
that g need not be measurable. ♣
Exercise 1.4.3 Let f : R →R be differentiable with derivative f ′. Show that f ′
is B(R) – B(R)-measurable. ♣
Exercise 1.4.4 (Compare Examples 1.40 and 1.63) Let Ω = {0, 1}N and let A =
(2{0,1})⊗N be the σ-algebra generated by the cylinder sets
	
[ω1, . . . , ωn] : n ∈N, ω1, . . . , ωn ∈{0, 1}

.
Further, let μ = ( 1
2δ0 + 1
2δ1)⊗N be the Bernoulli measure on Ω with equal weights
on 0 and 1. For all n ∈N, let Xn : Ω →{0, 1}, ω →ωn be the nth coordinate map.
Finally, let
U(ω) =
∞

n=1
Xn(ω) 2−n
for ω ∈Ω.
(i) Show that A = σ(Xn : n ∈N).
(ii) Show that U is A – B([0, 1])-measurable.
(iii) Determine the image measure μ ◦U−1 on ([0, 1], B([0, 1])).
(iv) Determine an Ω0 ∈A such that ˜U := U
Ω0 is bijective.

1.5
Random Variables
45
(v) Show that ˜U−1 is B([0, 1]) – A
Ω0-measurable.
(vi) Give an interpretation of the map Xn ◦˜U−1. ♣
Exercise 1.4.5 (Lusin’s theorem)
Let f : R →R be a Borel measurable map.
Show that for any ε > 0, there exists a closed set C ⊂R with λ(R \ C) < ε such
that the restriction f 
C of f to C is continuous. (Note: Clearly, this does not mean
that f would be continuous in every point x ∈C.)
Hint: Use the inner regularity of Lebesgue measure λ (Remark 1.67) to show
the assertion ﬁrst for indicator functions. Next construct a sequence of maps that
approximates f uniformly on a suitable set C. ♣
1.5
Random Variables
The fundamental idea of modern probability theory is to model one or more random
experiments as a probability space (Ω, A, P). The sets A ∈A are called events.
In most cases, the events of Ω are not observed directly. Rather, the observations
are aspects of the single experiments that are coded as measurable maps from
Ω to a space of possible observations. In short, every random observation (the
technical term is random variable) is a measurable map. The probabilities of the
possible random observations will be described in terms of the distribution of the
corresponding random variable, which is the image measure of P under X. Hence
we have to develop a calculus to determine the distributions of, for example, sums
of random variables.
Deﬁnition 1.102 (Random variables) Let (Ω′, A′) be a measurable space and let
X : Ω →Ω′ be measurable.
(i) X is called a random variable with values in (Ω′, A′). If (Ω′, A′)
=

R, B(R)

, then X is called a real random variable or simply a random
variable.
(ii) For A′ ∈A′, we denote {X ∈A′} := X−1(A′) and P[X ∈A′] := P[X−1(A′)].
In particular, we let {X ≥0} := X−1([0, ∞)) and deﬁne {X ≤b} similarly
and so on.
Deﬁnition 1.103 (Distributions) Let X be a random variable.
(i) The probability measure PX := P ◦X−1 is called the distribution of X.
(ii) For a real random variable X, the map FX : x →P[X ≤x] is called the
distribution function of X (or, more accurately, of PX). We write X ∼μ if
μ = PX and say that X has distribution μ.
(iii) A family (Xi)i∈I of random variables is called identically distributed if PXi =
PXj for all i, j ∈I. We write X D= Y if PX = PY (D for distribution).

46
1
Basic Measure Theory
Theorem 1.104 For any distribution function F, there exists a real random
variable X with FX = F.
Proof We explicitly construct a probability space (Ω, A, P) and a random variable
X : Ω →R such that FX = F.
The simplest choice would be (Ω, A) =

R, B(R)

, X : R →R the
identity map and P the Lebesgue–Stieltjes measure with distribution function F
(see Example 1.56).
A more instructive approach is based on ﬁrst constructing, independently of
F, a sort of standard probability space on which we deﬁne a random variable
with uniform distribution on (0, 1). In a second step, this random variable will be
transformed by applying the inverse map F −1: Let Ω := (0, 1), A := B(R)
Ω
and let P be the Lebesgue measure on (Ω, A) (see Example 1.74). Deﬁne the left
continuous inverse of F:
F −1(t) := inf{x ∈R : F(x) ≥t}
for t ∈(0, 1).
Then
F −1(t) ≤x
⇐⇒t ≤F(x).
In particular, {t : F −1(t) ≤x} = (0, F(x)] ∩(0, 1); hence F −1 : (Ω, A) →

R, B(R)

is measurable and
P[{t : F −1(t) ≤x}] = F(x).
Concluding, X := F −1 is the random variable that we wanted to construct.
⊓⊔
Example 1.105 We present some prominent distributions of real random variables
X. These are some of the most important distributions in probability theory, and we
will come back to these examples in many places.
(i) Let p ∈[0, 1] and P[X = 1] = p, P[X = 0] = 1 −p. Then PX =: Berp is
called the Bernoulli distribution with parameter p; formally
Berp = (1 −p) δ0 + p δ1.
Its distribution function is
FX(x) =
⎧
⎨
⎩
0,
if x < 0,
1 −p,
if x ∈[0, 1),
1,
if x ≥1.
The distribution PY of Y := 2X −1 is sometimes called the Rademacher
distribution with parameter p; formally Radp = (1 −p) δ−1 + p δ+1. In
particular, Rad1/2 is called the Rademacher distribution.

1.5
Random Variables
47
(ii) Let p ∈[0, 1] and n ∈N, and let X : Ω →{0, . . ., n} be such that
P[X = k] =
n
k

pk(1 −p)n−k.
Then PX =: bn,p is called the binomial distribution with parameters n and
p; formally
bn,p =
n

k=0
n
k

pk(1 −p)n−k δk.
(iii) Let p ∈(0, 1] and X : Ω →N0 with
P[X = n] = p (1 −p)n
for any n ∈N0.
Then γp := b−
1,p := PX is called the geometric distribution2 with parameter
p; formally
γp =
∞

n=0
p (1 −p)n δn.
Its distribution function is F(x) = 1 −(1 −p)⌊x+1⌋∨0
for x ∈R.
We can interpret X + 1 as the waiting time for the ﬁrst success in a
series of independent random experiments, any of which yields a success
with probability p. Indeed, let Ω = {0, 1}N and let P be the product measure
(1 −p)δ0 + p δ1
⊗N (Theorem 1.64), as well as A = σ([ω1, . . . , ωn] :
ω1, . . . , ωn ∈{0, 1}, n ∈N). Deﬁne
X(ω) := inf{n ∈N : ωn = 1} −1,
where inf ∅= ∞. Clearly, any map
Xn : Ω →R,
ω →

n −1,
if ωn = 1,
∞,
if ωn = 0,
2Warning: For some authors, the geometric distribution is shifted by one to the right; that is, it is a
distribution on N.

48
1
Basic Measure Theory
is A – B(R)-measurable. Thus also X = infn∈N Xn is A – B(R)-measurable
and is hence a random variable. Let ω0 := (0, 0, . . .) ∈Ω. Then P[X ≥n] =
P[[ω0
1, . . . , ω0
n]] = (1 −p)n. Hence
P[X = n] = P[X ≥n]−P[X ≥n+1] = (1−p)n−(1−p)n+1 = p (1−p)n.
(iv) Let r > 0 (note that r need not be an integer) and let p ∈(0, 1]. We denote
by
b−
r,p :=
∞

k=0
−r
k

(−1)k pr(1 −p)k δk
(1.17)
the negative binomial distribution or Pascal distribution with parameters
r and p. (Here
x
k

= x(x−1)···(x−k+1)
k!
for x ∈R and k ∈N is the generalized
binomial coefﬁcient.) If r ∈N, then one can show as in the preceding example
that b−
r,p is the distribution of the waiting time for the rth success in a series
of random experiments. We come back to this in Example 3.4(iv).
(v) Let λ ∈[0, ∞) and let X : Ω →N0 be such that
P[X = n] = e−λ λn
n!
for any n ∈N0.
Then PX =: Poiλ is called the Poisson distribution with parameter λ.
(vi) Consider an urn with B ∈N black balls and W ∈N white balls. Draw n ∈N
balls from the urn without replacement. A little bit of combinatorics shows
that the probability of drawing exactly b ∈{0, . . . , n} black balls is given by
the hypergeometric distribution with parameters B, W, n ∈N:
HypB,W;n

{b}

=
B
b
 W
n −b

B + W
n

for b ∈{0, . . . , n}.
(1.18)
This generalizes easily to the situation of k colors and Bi balls of color
i = 1, . . . , k. As above, we get that the probability of drawing out of n
balls exactly bi balls of color i for each i = 1, . . . , k (with the restriction
b1 + . . . + bk = n and bi ≤Bi for all i) is given by the generalized
hypergeometric distribution
HypB1,...,Bk;n

{(b1, . . . , bk)}

=
B1
b1

· · ·
Bk
bk

B1 + . . . + Bk
n
.
(1.19)

1.5
Random Variables
49
(vii) Let μ ∈R, σ 2 > 0 and let X be a real random variable with
P[X ≤x] =
1
√
2πσ 2
 x
−∞
exp

−(t −μ)2
2σ 2

dt
for x ∈R.
Then PX =: Nμ,σ 2 is called the Gaussian normal distribution with parame-
ters μ and σ 2. In particular, N0,1 is called the standard normal distribution.
(viii) Let θ > 0 and let X be a nonnegative random variable such that
P[X ≤x] = P[X ∈[0, x]] =
 x
0
θ e−θt dt
for x ≥0.
Then PX is called the exponential distribution
with parameter θ (in
shorthand, expθ).
(ix) Let μ ∈Rd and let Σ be a positive deﬁnite symmetric d × d matrix. Let X
be an Rd-valued random variable such that
P[X ≤x] = det(2π Σ)−1/2

(−∞,x]
exp

−1
2
%
t −μ, Σ−1(t −μ)
&
λd(dt)
for x ∈Rd (where ⟨·, ·⟩denotes the inner product in Rd). Then PX =: Nμ,Σ
is the d-dimensional normal distribution with parameters μ and Σ. ♦
Deﬁnition 1.106 If the distribution function F : Rn →[0, 1] is of the form
F(x) =
 x1
−∞
dt1 · · ·
 xn
−∞
dtn f (t1, . . . , tn)
for x = (x1, . . . , xn) ∈Rn,
for some integrable function f : Rn →[0, ∞), then f is called the density of the
distribution.
Example 1.107
(i) Let θ, r > 0 and let Γθ,r be the distribution on [0, ∞) with density
x →
θr
Γ (r) xr−1e−θx.
(Here Γ denotes the gamma function.) Then Γθ,r is called the Gamma
distribution with scale parameter θ and shape parameter r.
(ii) Let r, s > 0 and let βr,s be the distribution on [0, 1] with density
x →Γ (r + s)
Γ (r)Γ (s) xr−1(1 −x)s−1.
Then βr,s is called the Beta distribution with parameters r and s.

50
1
Basic Measure Theory
(iii) Let a > 0 and let Caua be the distribution on R with density
x →1
aπ
1
1 + (x/a)2 .
Then Caua is called the Cauchy distribution with parameter a. ♦
Takeaways A random variable X is a measurable map from a probability
space to some measurable space. The image measure PX describes the
distribution of X. In most cases, only the distribution of a random variable
is of interest but not the underlying probability space. We have got acquainted
with some fundamental probability distributions:
•
Bernoulli-distribution Berp on {0, 1}
•
binomial distribution bn,p on {0, . . . , n}
•
geometric distribution γp on N0
•
negative binomial distribution (or Pascal distribution) b−
r,p on N0
•
Poisson distribution Poiλ on N0
•
hypergeometric distribution HypB,W;n on {0, . . . , n}
•
normal distribution Nμ,σ 2 on R
•
exponential distribution expθ on [0, ∞)
•
Gamma distribution Γθ,r on [0, ∞)
•
Beta distribution βr,s on [0, 1]
•
Cauchy distribution Caua on R
Exercise 1.5.1 Use the identity
−n
k

(−1)k =
n+k−1
k

to deduce (1.17) by combi-
natorial means from its interpretation as a waiting time. ♣
Exercise 1.5.2 Give an example of two normally distributed random variables X
and Y such that (X, Y) is not (two-dimensional) normally distributed. ♣
Exercise 1.5.3 Use the transformation formula (Theorem 1.101) to show the
following statements.
(i) Let X ∼Nμ,σ 2 and let a ∈R \ {0} and b ∈R. Then (aX + b) ∼Naμ+b,a2σ 2.
(ii) Let X ∼expθ and a > 0. Then aX ∼expθ/a. ♣
Exercise 1.5.4 Show that F
: R2 →[0, 1] is the distribution function of a
(uniquely determined) probability measure μ on (R2, B(R2)) if and only if
(i) F is monotone increasing and right continuous
(ii) F((−x1, y2)) + F((y1, −x2)) →0 and F(x) →1 for all y1, y2 ∈R and for
x = (x1, x2) →∞,
(iii) F((y1, y2))−F((y1, x2))−F((x1, y2))+F((x1, x2)) ≥0 for all x1 ≤y1 and
x2 ≤y2. ♣

1.5
Random Variables
51
Exercise 1.5.5
(i) Let F and G be distribution functions on R. Use Exercise 1.5.4 to show that
(x, y) →F(x) ∧G(y) is a distribution function on R2.
(ii) Give an example of two distribution functions F and G on R2 such that
(x, y) →F(x) ∧G(y) is not a distribution function on R4.
Hint: First use the inclusion-exclusion formula (Theorem 1.33) to derive a
criterion similar to that in Exercise 1.5.4(iii). ♣

Chapter 2
Independence
The measure theory from the preceding chapter is a linear theory that could not
describe the dependence structure of events or random variables. We enter the realm
of probability theory exactly at this point, where we deﬁne independence of events
and random variables. Independence is a pivotal notion of probability theory, and
the computation of dependencies is one of the theory’s major tasks.
In the following, (Ω, A, P) is a probability space and the sets A ∈A are the
events. As soon as constructing probability spaces has become routine, the concrete
probability space will lose its importance and it will be only the random variables
that will interest us. The bold font symbol P will then denote the universal object
of a probability measure, and the probabilities P[ ·] with respect to it will always be
written in square brackets.
2.1
Independence of Events
We consider two events A and B as (stochastically) independent if the occurrence
of A does not change the probability that B also occurs. Formally, we say that A
and B are independent if
P[A ∩B] = P[A] · P[B].
(2.1)
Example 2.1 (Rolling a die twice) Consider the random experiment of rolling a
die twice. Hence Ω = {1, . . ., 6}2 endowed with the σ-algebra A = 2Ω and the
uniform distribution P = UΩ (see Example 1.30(ii)).
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_2
53

54
2
Independence
(i) Two events A and B should be independent, e.g., if A depends only on the
outcome of the ﬁrst roll and B depends only on the outcome of the second roll.
Formally, we assume that there are sets ˜A, ˜B ⊂{1, . . . , 6} such that
A = ˜A × {1, . . . , 6}
and
B = {1, . . . , 6} × ˜B.
Now we check that A and B indeed fulﬁll (2.1). To this end, we compute
P[A] = #A
36 = # ˜A
6 and P[B] = #B
36 = # ˜B
6 . Furthermore,
P[A ∩B] = #( ˜A × ˜B)
36
= # ˜A
6 · # ˜B
6 = P[A] · P[B].
(ii) Stochastic independence can occur also in less obvious situations. For instance,
let A be the event where the sum of the two rolls is odd,
A =
	
(ω1, ω2) ∈Ω : ω1 + ω2 ∈{3, 5, 7, 9, 11}

,
and let B be the event where the ﬁrst roll gives at most a three
B = {(ω1, ω2) ∈Ω : ω1 ∈{1, 2, 3}
.
Although it might seem that these two events are entangled in some way, they
are stochastically independent. Indeed, it is easy to check that P[A] = P[B] =
1
2 and P[A ∩B] = 1
4. ♦
What is the condition for three events A1, A2, A3 to be independent? Of course,
any of the pairs (A1, A2), (A1, A3) and (A2, A3) has to be independent. However,
we have to make sure also that the simultaneous occurrence of A1 and A2 does not
change the probability that A3 occurs. Hence, it is not enough to consider pairs only.
Formally, we call three events A1, A2 and A3 (stochastically) independent if
P[Ai ∩Aj] = P[Ai] · P[Aj]
for all i, j ∈{1, 2, 3}, i ̸= j,
(2.2)
and
P[A1 ∩A2 ∩A3] = P[A1] · P[A2] · P[A3].
(2.3)
Note that (2.2) does not imply (2.3) (and (2.3) does not imply (2.2)).
Example 2.2 (Rolling a die three times) We roll a die three times. Hence Ω =
{1, . . ., 6}3 endowed with the discrete σ-algebra A
=
2Ω and the uniform
distribution P = UΩ (see Example 1.30(ii)).
(i) If we assume that for any i = 1, 2, 3 the event Ai depends only on the outcome
of the ith roll, then the events A1, A2 and A3 are independent. Indeed, as in the

2.1
Independence of Events
55
preceding example, there are sets ˜A1, ˜A2, ˜A3 ⊂{1, . . . 6} such that
A1 = ˜A1 × {1, . . . , 6}2,
A2 = {1, . . ., 6} × ˜A2 × {1, . . . , 6},
A3 = {1, . . ., 6}2 × ˜A3.
The validity of (2.2) follows as in Example 2.1(i). In order to show (2.3), we
compute
P[A1 ∩A2 ∩A3] = #( ˜A1 × ˜A2 × ˜A3)
216
=
3

i=1
# ˜Ai
6
=
3

i=1
P[Ai].
(ii) Consider now the events
A1 := {ω ∈Ω : ω1 = ω2},
A2 := {ω ∈Ω : ω2 = ω3},
A3 := {ω ∈Ω : ω1 = ω3}.
Then #A1 = #A2 = #A3 = 36; hence P[A1] = P[A2] = P[A3] =
1
6.
Furthermore, #(Ai ∩Aj) = 6 if i ̸= j; hence P[Ai ∩Aj] =
1
36. Hence (2.2)
holds. On the other hand, we have #(A1∩A2∩A3) = 6, thus P[A1∩A2∩A3] =
1
36 ̸= 1
6 · 1
6 · 1
6. Thus (2.3) does not hold and so the events A1, A2, A3 are not
independent. ♦
In order to deﬁne independence of larger families of events, we have to request the
validity of product formulas, such as (2.2) and (2.3), not only for pairs and triples
but for all ﬁnite subfamilies of events. We thus make the following deﬁnition.
Deﬁnition 2.3 (Independence of events) Let I be an arbitrary index set and let
(Ai)i∈I be an arbitrary family of events. The family (Ai)i∈I is called independent
if for any ﬁnite subset J ⊂I the product formula holds:
P
' 
j∈J
Aj
(
=

j∈J
P[Aj].
Reﬂection How do you choose four events A1, A2, A3, A4 such that each pair
Ai, Aj, i ̸= j, and each triple Ai, Aj, Ak, #{i, j, k} = 3, is independent, but
A1, A2, A3, A4 is not? ♠
Reﬂection An event is independent of itself if A and B are independent for B = A.
Check that in this case A has either probability 0 or 1. ♠

56
2
Independence
The most prominent example of an independent family of inﬁnitely many events is
given by the perpetuated independent repetition of a random experiment.
Example 2.4 Let E be a ﬁnite set (the set of possible outcomes of the individual
experiment) and let (pe)e∈E be a probability vector on E. Equip (as in Theo-
rem 1.64) the probability space Ω = EN with the σ-algebra A = σ({[ω1, . . . , ωn] :
ω1, . . . , ωn ∈E, n ∈N}) and with the product measure (or Bernoulli measure)
P =

e∈E peδe
⊗N; that is where P
)
[ω1, . . . , ωn]
*
=
n

i=1
pωi. Let ˜Ai ⊂E for any
i ∈N, and let Ai be the event where ˜Ai occurs in the ith experiment; that is,
Ai =
	
ω ∈Ω : ωi ∈˜Ai

=

(ω1,...,ωi)∈Ei−1× ˜Ai
[ω1, . . . , ωi].
Intuitively, the family (Ai)i∈N should be independent if the deﬁnition of indepen-
dence makes any sense at all. We check that this is indeed the case. Let J ⊂N be
ﬁnite and n := max J. Formally, we deﬁne Bj = Aj and ˜Bj = ˜Aj for j ∈J and
Bj = Ω and ˜Bj = E for j ∈{1, . . . , n} \ J. Then
P
+ 
j∈J
Aj
,
= P
+ 
j∈J
Bj
,
= P
+
n

j=1
Bj
,
=

e1∈˜B1
· · ·

en∈˜Bn
n

j=1
pej =
n

j=1
 
e∈˜Bj
pe

=

j∈J
 
e∈˜Aj
pe

.
This is true in particular for #J = 1. Hence P[Ai] = 
e∈˜Ai pe for all i ∈N,
whence
P
+ 
j∈J
Aj
,
=

j∈J
P[Aj].
(2.4)
Since this holds for all ﬁnite J ⊂N, the family (Ai)i∈N is independent. ♦
If A and B are independent, then Ac and B also are independent since P[Ac ∩B] =
P[B] −P[A ∩B] = P[B] −P[A]P[B] = (1 −P[A])P[B] = P[Ac]P[B]. We
generalize this observation in the following theorem.
Theorem 2.5 Let I be an arbitrary index set and let (Ai)i∈I be a family of events.
Deﬁne B0
i = Ai and B1
i = Ac
i for i ∈I. Then the following three statements are
equivalent.
(i) The family (Ai)i∈I is independent.
(ii) There is an α ∈{0, 1}I such that the family (Bαi
i )i∈I is independent.
(iii) For any α ∈{0, 1}I, the family (Bαi
i )i∈I is independent.

2.1
Independence of Events
57
Proof This is left as an exercise.
⊓⊔
Example 2.6 (Euler’s prime number formula)
The Riemann zeta function is
deﬁned by the Dirichlet series
ζ(s) :=
∞

n=1
n−s
for s ∈(1, ∞).
Euler’s prime number formula is a representation of the Riemann zeta function as
an inﬁnite product
ζ(s) =

p∈P

1 −p−s−1,
(2.5)
where P := {p ∈N : p is prime}.
We give a probabilistic proof for this formula. Let Ω = N, and for ﬁxed s > 1
deﬁne P on 2Ω by
P[{n}] = ζ(s)−1 n−s
for n ∈N.
Let pN = {pn : n ∈N} and Pn = {p ∈P : p ≤n}. We consider pN ⊂Ω as
an event. Note that P[pN] = p−s and that (pN, p ∈P) is independent. Indeed, for
k ∈N and mutually distinct p1, . . . , pk ∈P, we have k
i=1(piN) = (p1 · · · pk)N.
Thus
P
- k
i=1
(piN)
.
=
∞

n=1
P
)
{p1 · · · pkn}
*
= ζ(s)−1 (p1 · · · pk)−s
∞

n=1
n−s
= (p1 · · · pk)−s =
k
i=1
P[ piN ].
By Theorem 2.5, the family ((pN)c, p ∈P) is also independent, whence
ζ(s)−1 = P[{1}] = P
+ 
p∈P
(pN)c
,
= lim
n→∞P
' 
p∈Pn
(pN)c(
= lim
n→∞

p∈Pn
1 −P[ pN ] =

p∈P
1 −p−s.
This shows (2.5). ♦

58
2
Independence
If we roll a die inﬁnitely often, what is the chance that the face shows a six inﬁnitely
often? This probability should equal one. Otherwise there would be a last point in
time when we see a six and after which the face only shows a number one to ﬁve.
However, this is not very plausible.
Recall that we formalized the event where inﬁnitely many of a series of events
occur by means of the limes superior (see Deﬁnition 1.13). The following theorem
conﬁrms the conjecture mentioned above and also gives conditions under which we
cannot expect that inﬁnitely many of the events occur.
Theorem 2.7 (Borel–Cantelli lemma) Let A1, A2, . . . be events and deﬁne A∗=
lim sup
n→∞
An.
(i) If ∞
n=1 P[An] < ∞, then P[A∗] = 0. (Here P could be an arbitrary measure
on (Ω, A).)
(ii) If (An)n∈N is independent and ∞
n=1 P[An] = ∞, then P[A∗] = 1.
Proof
(i) P is upper semicontinuous and σ-subadditive; hence, by assumption,
P[A∗] = lim
n→∞P
- ∞

m=n
Am
.
≤lim
n→∞
∞

m=n
P[Am] = 0.
(ii) De Morgan’s rule and the lower semicontinuity of P yield
P)(A∗)c* = P
- ∞

m=1
∞

n=m
Ac
n
.
= lim
m→∞P
- ∞

n=m
Ac
n
.
.
However, for every m ∈N (since log(1 −x) ≤−x for x ∈[0, 1]), by upper
continuity of P
P
+ ∞

n=m
Ac
n
,
= lim
N→∞P
+
N

n=m
Ac
n
,
=
∞

n=m

1 −P[An]

= exp
 ∞

n=m
log 1 −P[An]
≤exp

−
∞

n=m
P[An]

= 0.
⊓⊔
Example 2.8 We throw a die again and again and ask for the probability of seeing
a six inﬁnitely often. Hence Ω = {1, . . ., 6}N, A = (2{1,...,6})⊗N is the product
σ-algebra and P =


e∈{1,...,6}
1
6δe
⊗N is the Bernoulli measure (see Theorem 1.64).
Furthermore, let An = {ω ∈Ω : ωn = 6} be the event where the nth roll shows
a six. Then A∗= lim sup
n→∞
An is the event where we see a six inﬁnitely often (see

2.1
Independence of Events
59
Remark 1.14). Furthermore, (An)n∈N is an independent family with the property
∞

n=1
P[An] =
∞

n=1
1
6 = ∞. Hence the Borel–Cantelli lemma yields P[A∗] = 1. ♦
Example 2.9 We roll a die only once and deﬁne An for any n ∈N as the event
where in this one roll the face showed a six. Note that A1 = A2 = A3 = . . .. Then

n∈N P[An] = ∞; however, P[A∗] = P[A1] = 1
6. This shows that in Part (ii) of
the Borel–Cantelli lemma, the assumption of independence is indispensable. ♦
Example 2.10 Let Λ ∈(0, ∞) and 0 ≤λn ≤Λ for n ∈N. Let Xn, n ∈N, be
Poisson random variables with parameters λn. Then
P
)
Xn ≥n for inﬁnitely many n
*
= 0.
Indeed,
∞

n=1
P[Xn ≥n] =
∞

n=1
∞

m=n
P[Xn = m] =
∞

m=1
m

n=1
P[Xn = m]
=
∞

m=1
m

n=1
e−λn λm
n
m! ≤
∞

m=1
m Λm
m!
= Λ eΛ < ∞.
♦
(2.6)
Note that in Theorem 2.7 in the case of independent events, only the probabilities
P[A∗] = 0 and P[A∗] = 1 could show up. Thus the Borel–Cantelli lemma belongs
to the class of so-called 0–1 laws. Later we will encounter more 0–1 laws (see, for
example, Theorem 2.37).
Now we extend the notion of independence from families of events to families
of classes of events.
Deﬁnition 2.11 (Independence of classes of events) Let I be an arbitrary index
set and let Ei ⊂A for all i ∈I. The family (Ei)i∈I is called independent if, for any
ﬁnite subset J ⊂I and any choice of Ej ∈Ej, j ∈J, we have
P
+ 
j∈J
Ej
,
=

j∈J
P[Ej].
(2.7)
Example 2.12 As in Example 2.4, let (Ω, A, P) be the product space of inﬁnitely
many repetitions of a random experiment whose possible outcomes e are the
elements of the ﬁnite set E and have probabilities p = (pe)e∈E. For i ∈N, deﬁne
Ei =
	
{ω ∈Ω : ωi ∈A} : A ⊂E

.
For any choice of sets Ai ∈Ei, i ∈N, the family (Ai)i∈N is independent; hence
(Ei)i∈N is independent. ♦

60
2
Independence
Theorem 2.13
(i) Let I be ﬁnite, and for any i ∈I let Ei ⊂A with Ω ∈Ei. Then
(Ei)i∈I is independent
⇐⇒(2.7) holds for J = I.
(ii) (Ei)i∈I is independent ⇐⇒

(Ej)j∈J is independent for all ﬁnite J ⊂I

.
(iii) If (Ei ∪{∅}) is ∩-stable, then
(Ei)i∈I is independent
⇐⇒(σ(Ei))i∈I is independent.
(iv) Let K be an arbitrary set and let (Ik)k∈K be mutually disjoint subsets of I. If
(Ei)i∈I is independent, then  
i∈Ik Ei

k∈K is also independent.
Proof
(i) “ ⇒”
This is trivial.
(i) “ ⇐ ”
For J ⊂I and j ∈I \ J, choose Ej = Ω.
(ii)
This is trivial.
(iii) “ ⇐ ”
This is trivial.
(iii) “ ⇒”
Let J ⊂I be ﬁnite. We will show that for any two ﬁnite sets J and
J ′ with J ⊂J ′ ⊂I,
P
+ 
i∈J ′
Ei
,
=

i∈J ′
P[Ei] for any choice

Ei ∈σ(Ei),
if i ∈J,
Ei ∈Ei,
if i ∈J ′ \ J.
(2.8)
The case J ′ = J is exactly the claim we have to show.
We carry out the proof of (2.8) by induction on #J. For #J = 0, the statement
(2.8) holds by assumption of this theorem.
Now assume that (2.8) holds for every J with #J = n and for every ﬁnite
J ′ ⊃J. Fix such a J and let j ∈I \ J. Choose J ′ ⊃˜J := J ∪{j}. We show
the validity of (2.8) with J replaced by ˜J. Since # ˜J = n + 1, this veriﬁes the
induction step.
Let Ei ∈σ(Ei) for any i ∈J, and let Ei ∈Ei for any i ∈J ′ \(J ∪{j}). Deﬁne
two measures μ and ν on (Ω, A) by
μ : Ej →P
+ 
i∈J ′
Ei
,
and
ν : Ej →

i∈J ′
P[Ei].
By the induction hypothesis (2.8), we have μ(Ej) = ν(Ej) for every Ej ∈
Ej ∪{∅, Ω}. Since Ej ∪{∅} is a π-system, Lemma 1.42 yields that μ(Ej) =
ν(Ej) for all Ej ∈σ(Ej). That is, (2.8) holds with J replaced by J ∪{j}.

2.2
Independent Random Variables
61
(iv) This is trivial, as (2.7) has to be checked only for J ⊂I with
#(J ∩Ik) ≤1
for any k ∈K.
⊓⊔
Takeaways Two events A and B are independent if P[A ∩B] = P[A] ·
P[B]. We have extended this notion to families of events and even to families
of classes of sets. The Borel-Cantelli lemma shows that inﬁnitely many of
countably many independent events occur jointly with probability either 0 or
1 depending on the summability of the probabilities of the single events.
Exercise 2.1.1 In a queue each new arriving person chooses independently a
random waiting position. What is the probability that the ﬁrst position changes
inﬁnitely often? ♣
Exercise 2.1.2 Show that the conclusion of the interesting part of the Borel-Cantelli
lemma (Theorem 2.7(ii)) still holds under the following weaker condition: Each
of the families (A1, A3, A5, . . .) and (A2, A4, A6, . . .) is independent (but not
necessarily independent of each other). ♣
2.2
Independent Random Variables
Now that we have studied independenceof events, we want to study independenceof
random variables. Here also the deﬁnition ends up with a product formula. Formally,
however, we can also deﬁne independence of random variables via independence of
the σ-algebras they generate. This is the reason why we studied independence of
classes of events in the last section.
Independent random variables allow for a rich calculus. For example, we can
compute the distribution of a sum of two independent random variables by a simple
convolution formula. Since we do not have a general notion of an integral at hand
at this point, for the time being we restrict ourselves to presenting the convolution
formula for integer-valued random variables only.
Let I be an arbitrary index set. For each i ∈I, let (Ωi, Ai) be a measurable
space and let Xi : (Ω, A) →(Ωi, Ai) be a random variable with generated σ-
algebra σ(Xi) = X−1
i
(Ai).
Deﬁnition 2.14 (Independent random variables) The family (Xi)i∈I of random
variables is called independent if the family (σ(Xi))i∈I of σ-algebras is indepen-
dent.
As a shorthand, we say that a family (Xi)i∈I is “i.i.d.” (for “independent and
identically distributed”) if (Xi)i∈I is independent and if PXi = PXj for all i, j ∈I.

62
2
Independence
Remark 2.15
(i) Clearly, the family (Xi)i∈I is independent if and only if, for any ﬁnite set J ⊂I
and any choice of Aj ∈Aj, j ∈J, we have
P
' 
j∈J
{Xj ∈Aj}
(
=

j∈J
P[Xj ∈Aj].
The next theorem will show that it is enough to request the validity of such a
product formula for Aj from an ∩-stable generator of Aj only.
(ii) If ( ˜Ai)i∈I is an independent family of σ-algebras and if each Xi is ˜Ai – Ai-
measurable, then (Xi)i∈I is independent. This is a direct consequence of the
fact that σ(Xi) ⊂˜Ai.
(iii) For each i ∈I, let (Ω′
i, A′
i) be another measurable space and assume that
fi : (Ωi, Ai) →(Ω′
i, A′
i) is a measurable map. If (Xi)i∈I is independent,
then (fi ◦Xi)i∈I is independent. This statement is a special case of (ii) since
fi ◦Xi is σ(Xi) – A′
i-measurable (see Theorem 1.80).♦
Theorem 2.16 (Independent generators) For any i
∈
I, let Ei
⊂
Ai be
a π-system that generates Ai. If (X−1
i
(Ei))i∈I is independent, then (Xi)i∈I is
independent.
Proof By Theorem 1.81, X−1
i
(Ei) is a π-system that generates the σ-algebra
X−1
i
(Ai) = σ(Xi). Hence the statement follows from Theorem 2.13.
⊓⊔
Example 2.17 Let E be a countable set and let (Xi)i∈I be random variables with
values in (E, 2E). In this case, (Xi)i∈I is independent if and only if, for any ﬁnite
J ⊂I and any choice of xj ∈E, j ∈J,
P)Xj = xj for all j ∈J* =

j∈J
P[Xj = xj].
This is obvious since 	{x} : x ∈E
 ∪{∅} is a π-system that generates 2E, thus
	
X−1
i
({xi}) : xi ∈E

∪{∅} is a π-system that generates σ(Xi) (Theorem 1.81). ♦
Example 2.18 Let E be a ﬁnite set and let p = (pe)e∈E be a probability vector.
Repeat a random experiment with possible outcomes e ∈E and probabilities pe for
e ∈E inﬁnitely often (see Example 1.40 and Theorem 1.64). Let Ω = EN be the
inﬁnite product space and let A be the σ-algebra generated by the cylinder sets (see
(1.8)). Let P =

e∈E peδe
⊗N be the Bernoulli measure. Further, for any n ∈N,
let
Xn : Ω →E,
(ωm)m∈N →ωn,
be the projection on the nth coordinate. In other words: For any simple event ω ∈Ω,
Xn(ω) yields the result of the nth experiment. Then, by (2.4) (in Example 2.4), for

2.2
Independent Random Variables
63
n ∈N and x ∈En, we have
P)Xj = xj for all j = 1, . . . , n* = P)[x1, . . . , xn]* = P
+
n

j=1
X−1
j ({xj})
,
=
n

j=1
P)X−1
j ({xj})* =
n

j=1
P[Xj = xj],
and P[Xj = xj] = pxj . By virtue of Theorem 2.13(i), this implies that the
family (X1, . . . , Xn) is independent and hence, by Theorem 2.13(ii), (Xn)n∈N is
independent as well. ♦
In particular, we have shown the following theorem.
Theorem 2.19 Let E be a ﬁnite set and let (pe)e∈E be a probability vector on E.
Then there exists a probability space (Ω, A, P) and an independent family (Xn)n∈N
of E-valued random variables on (Ω, A, P) such that P[Xn = e] = pe for any
e ∈E.
Later we will see that the assumption that E is ﬁnite can be dropped. Also
one can allow for different distributions in the respective factors. For the time
being, however, this theorem gives us enough examples of interesting families of
independent random variables.
Our next goal is to deduce simple criteria in terms of distribution functions and
densities for checking whether a family of random variables is independent or not.
Deﬁnition 2.20 For any i ∈I, let Xi be a real random variable. For any ﬁnite
subset J ⊂I, let
FJ := F(Xj )j∈J : RJ →[0, 1],
x →P
)
Xj ≤xj for all j ∈J
*
= P
+ 
j∈J
X−1
j

(−∞, xj]
,
.
Then FJ is called the joint distribution function of (Xj)j∈J. The probability
measure P(Xj )j∈J on RJ is called the joint distribution of (Xj)j∈J.
Theorem 2.21 A family (Xi)i∈I of real random variables is independent if and only
if, for every ﬁnite J ⊂I and every x = (xj)j∈J ∈RJ ,
FJ (x) =

j∈J
F{j}(xj).
(2.9)
Proof The class of sets {(−∞, b], b ∈R} is an ∩-stable generator of the Borel
σ-algebra B(R) (see Theorem 1.23). Equation (2.9) says that, for any choice

64
2
Independence
of real numbers (xi)i∈I, the events (X−1
i
((−∞, xi]))i∈I are independent. Hence
Theorem 2.16 yields the claim.
⊓⊔
Corollary 2.22 In addition to the assumptions of Theorem 2.21, we assume that
any FJ has a continuous density fJ = f(Xj )j∈J (the joint density of (Xj)j∈J). That
is, there exists a continuous map fJ : RJ →[0, ∞) such that
FJ (x) =
 xj1
−∞
dt1 · · ·
 xjn
−∞
dtn fJ (t1, . . . , tn)
for all x ∈RJ
(where J = {j1, . . . , jn}). In this case, the family (Xi)i∈I is independent if and only
if, for any ﬁnite J ⊂I
fJ (x) =

j∈J
fj(xj)
for all x ∈RJ .
(2.10)
Corollary 2.23 Let n
∈
N and let μ1, . . . , μn be probability measures on

R, B(R)

. Then there exists a probability space (Ω, A, P) and an independent
family of random variables (Xi)i=1,...,n on (Ω, A, P) with PXi = μi for each
i = 1, . . . , n.
Proof Let Ω = Rn and A = B(Rn). Let P = /n
i=1 μi be the product measure of
the μi (see Theorem 1.61). Further, let Xi : Rn →R, (x1, . . . , xn) →xi be the
projection on the ith coordinate for each i = 1, . . . , n. Then, for any i = 1, . . ., n,
F{i}(x) = P[Xi ≤x] = P)Ri−1 × (−∞, x] × Rn−i*
= μi

(−∞, x]

·

j̸=i
μj(R) = μi

(−∞, x]

.
Hence indeed PXi = μi. Furthermore, for all x1, . . . , xn ∈R,
F{1,...,n}((x1, . . . , xn)) = P
+
n×
i=1
(−∞, xi]
,
=
n

i=1
μi

(−∞, xi]

=
n

i=1
F{i}(xi).
Hence Theorem 2.21 (and Theorem 2.13(i)) yields the independence of (Xi)i=1,...,n.
⊓⊔
Example 2.24 Let X1, . . . , Xn be independent exponentially distributed random
variables with parameters θ1, . . . , θn ∈(0, ∞). Then
F{i}(x) =
 x
0
θie−θit dt = 1 −e−θix
for x ≥0

2.2
Independent Random Variables
65
and hence
F{1,...,n}
(x1, . . . , xn) =
n

i=1
1 −e−θixi.
Consider now the random variable Y = max(X1, . . . , Xn). Then
FY (x) = P)Xi ≤x for all i = 1, . . . , n*
= F{1,...,n}

(x, . . . , x)

=
n

i=1

1 −e−θix
.
The distribution function of the random variable Z := min(X1, . . . , Xn) has a nice
closed form:
FZ(x) = 1 −P[Z > x]
= 1 −P
)
Xi > x for all i = 1, . . . , n
*
= 1 −
n

i=1
e−θix = 1 −exp

−(θ1 + . . . + θn) x

.
In other words, Z is exponentially distributed with parameter θ1 + . . . + θn. ♦
Example 2.25 Let μi ∈R and σ 2
i
> 0 for i ∈I. Let (Xi)i∈I be real random
variables with joint density functions (for ﬁnite J ⊂I)
fJ (x) =

j∈J

2πσ 2
j
−1
2 exp

−

j∈J
(xj −μj)2
2σ 2
j

for x ∈RJ.
Then (Xi)i∈I is independent and Xi is normally distributed with parameters
(μi, σ 2
i ).
For any ﬁnite I = {i1, . . . , in} (with mutually distinct i1, . . . , in), the vector
Y = (Xi1, . . . , Xin) has the n-dimensional normal distribution with μ = μI :=
(μi1, . . . , μin) and with Σ = ΣI the diagonal matrix with entries σ 2
i1, . . . , σ 2
in (see
Example 1.105(ix)). ♦
Theorem 2.26 Let K be an arbitrary set and Ik, k ∈K, arbitrary mutually disjoint
index sets. Deﬁne I = 
k∈K
Ik.
If the family (Xi)i∈I is independent, then the family of σ-algebras (σ(Xj, j ∈
Ik))k∈K is independent.

66
2
Independence
Proof For k ∈K, let
Zk =
0 
j∈Ik
Aj : Aj ∈σ(Xj), #{j ∈Ik : Aj ̸= Ω} < ∞
1
be the semiring of ﬁnite-dimensional rectangular cylinder sets. Clearly, Zk is a π-
system and σ(Zk) = σ(Xj, j ∈Ik). Hence, by Theorem 2.13(iii), it is enough to
show that (Zk)k∈K is independent. By Theorem 2.13(ii), we can even assume that
K is ﬁnite.
For k ∈K, let Bk ∈Zk and Jk ⊂Ik be ﬁnite with Bk = 
j∈Jk Aj for certain
Aj ∈σ(Xj). Deﬁne J = 
k∈K Jk. Then
P
+ 
k∈K
Bk
,
= P
+ 
j∈J
Aj
,
=

j∈J
P[Aj] =

k∈K

j∈Jk
P[Aj] =

k∈K
P[Bk].
⊓⊔
Example 2.27 If (Xn)n∈N is an independent family of real random variables,
then also (Yn)n∈N = (X2n −X2n−1)n∈N is independent. Indeed, for any n ∈
N, the random variable Yn is σ(X2n, X2n−1)-measurable by Theorem 1.91, and
(σ(X2n, X2n−1))n∈N is independent by Theorem 2.26. ♦
Example 2.28 Let (Xm,n)(m,n)∈N2 be an independent family of Bernoulli random
variables with parameter p ∈(0, 1). Deﬁne the waiting time for the ﬁrst “success”
in the mth row of the matrix (Xm,n)m,n by
Ym := inf 	n ∈N : Xm,n = 1
 −1.
Then (Ym)m∈N are independent geometric random variables with parameter p (see
Example 1.105(iii)). Indeed,
{Ym ≤k} =
k+1

l=1
{Xm,l = 1} ∈σ(Xm,l, l = 1, . . . , k + 1) ⊂σ(Xm,l, l ∈N).
Hence Ym is σ(Xm,l, l
∈
N)-measurable and thus (Ym)m∈N is independent.
Furthermore,
P[Ym > k] = P[Xm,l = 0, l = 1, . . . , k + 1] =
k+1

l=1
P[Xm,l = 0] = (1 −p)k+1.
Concluding, we get P[Ym = k] = P[Ym > k −1] −P[Ym > k] = p(1 −p)k. ♦

2.2
Independent Random Variables
67
Deﬁnition 2.29 (Convolution) Let μ and ν be probability measures on (Z, 2Z).
The convolution μ ∗ν is deﬁned as the probability measure on (Z, 2Z) such that
(μ ∗ν)({n}) =
∞

m=−∞
μ({m}) ν({n −m}).
We deﬁne the nth convolution power recursively by μ∗1 = μ and
μ∗(n+1) = μ∗n ∗μ.
Remark 2.30 The convolution is a symmetric operation: μ ∗ν = ν ∗μ. ♦
Theorem 2.31 If X and Y are independent Z-valued random variables, then
PX+Y = PX ∗PY .
Proof For any n ∈Z,
PX+Y ({n}) = P[X + Y = n]
= P
+ 
m∈Z

{X = m} ∩{Y = n −m}
,
=

m∈Z
P){X = m} ∩{Y = n −m}*
=

m∈Z
PX[{m}] PY [{n −m}] = (PX ∗PY )[{n}].
⊓⊔
Reﬂection Check that PX+Y = PX∗PY does not imply that X and Y be independent.
♠♠
Owing to the last theorem, it is natural to deﬁne the convolution of two probability
measures on Rn (or more generally on an Abelian group) as the distribution of
the sum of two independent random variables with the corresponding distributions.
Later we will encounter a different (but equivalent) deﬁnition that will, however,
rely on the notion of an integral that is not yet available to us at this point (see
Deﬁnition 14.20).
Deﬁnition 2.32 (Convolution of measures)
Let μ and ν be probability measures
on Rn and let X and Y be independent random variables with PX = μ and PY = ν.
We deﬁne the convolution of μ and ν as μ ∗ν = PX+Y .
Recursively, we deﬁne the convolution powers μ∗k for all k ∈N and let μ∗0 = δ0.

68
2
Independence
Example 2.33 Let X and Y be independent Poisson random variables with param-
eters μ and λ ≥0. Then
P[X + Y = n] = e−μe−λ
n

m=0
μm
m!
λn−m
(n −m)!
= e−(μ+λ) 1
n!
n

m=0
n
m

μmλn−m = e−(μ+λ) (μ + λ)n
n!
.
Hence Poiμ ∗Poiλ = Poiμ+λ. ♦
Takeaways Families of random variables are independent if the events they
describe are independent (Deﬁnition 2.14). In order to check independence,
it is enough to check it on a generator of the σ-algebra (Theorem 2.16). For
example, it can be enough to check independence for intervals, rectangles
or, in the discrete case, for single points. Independence of random variables
can be characterised via product formulas for their joint distribution functions
(Theorem 2.21), densities (Corollary 2.22) or weight functions (exercise!).
The distribution of a sum of independent random variables can be computed
using a convolution formula (Theorem 2.31).
Exercise 2.2.1 Let X and Y be independent random variables with X ∼expθ and
Y ∼expρ for certain θ, ρ > 0. Show that
P[X < Y] =
θ
θ + ρ .
♣
Exercise 2.2.2 (Box–Muller method) Let U and V be independent random vari-
ables that are uniformly distributed on [0, 1]. Deﬁne
X :=
2
−2 log(U) cos(2πV )
and
Y :=
2
−2 log(U) sin(2πV ).
Show that X and Y are independent and N0,1-distributed.
Hint: First compute the distribution of
2
−2 log(U) and then use the transformation
formula (Theorem 1.101) as well as polar coordinates. ♣
Exercise 2.2.3 (Multinomial distribution) Let m ∈N and let p = (p1, . . . , pm)
be a probability vector on {1, . . ., m}. Let X1, . . . , Xn be independent random
variables with values in 1, . . . , m and distribution p. We deﬁne an Nm
0 -valued
random variable Y = (Y1, . . . , Ym) by
Yi := #{k = 1, . . . , n : Xk = i}
for i = 1, . . . , m.

2.3
Kolmogorov’s 0–1 Law
69
Show that for k = (k1, . . . , km) ∈Nm
0 with k1 + . . . + km = n, we have
P[Y = k] = Muln,p({k}) :=
n
k

pk.
(2.11)
Here
n
k

=

n
k1, . . . , km

=
n!
k1! · · · km!
is the multinomial coefﬁcient and pk = pk1
1 · · · pkm
m . The distribution Muln,p on
Nm
0 is called multinomial distribution with parameters n and p. ♣
2.3
Kolmogorov’s 0–1 Law
With the Borel–Cantelli lemma, we have seen a ﬁrst 0–1 law for independent events.
We now come to another 0–1 law for independent events and for independent σ-
algebras. To this end, we ﬁrst introduce the notion of the tail σ-algebra.
Deﬁnition 2.34 (Tail σ-algebra)
Let I be a countably inﬁnite index set and let
(Ai)i∈I be a family of σ-algebras. Then
T

(Ai)i∈I

:=

J⊂I
#J<∞
σ
 
j∈I\J
Aj

is called the tail σ-algebra of (Ai)i∈I. If (Ai)i∈I is a family of events, then we deﬁne
T

(Ai)i∈I

:= T

({∅, Ai, Ac
i , Ω})i∈I

.
If (Xi)i∈I is a family of random variables, then we deﬁne T

(Xi)i∈I

:=
T

(σ(Xi))i∈I

.
occurrence is independent of any ﬁxed ﬁnite subfamily of the Xi. To put it
differently, for any ﬁnite subfamily of the Xi, we can change the values of the Xi
arbitrarily without changing whether A occurs or not.
Theorem 2.35 Let J1, J2, . . . be ﬁnite sets with Jn ↑I. Then
T

(Ai)i∈I

=
∞

n=1
σ


m∈I\Jn
Am

.
In the particular case I = N, this reads T

(An)n∈N

=
∞

n=1
σ
 ∞

m=n
Am

.

70
2
Independence
The name “tail σ-algebra” is due to the interpretation of I = N as a set of times.
As is made clear in the theorem, any event in T does not depend on the ﬁrst ﬁnitely
many time points.
Proof “⊂”
This is clear.
“⊃”
Let Jn ⊂I, n ∈N, be ﬁnite sets with Jn ↑I. Let J ⊂I be ﬁnite. Then there
exists an N ∈N with J ⊂JN and
∞

n=1
σ
 
m∈I\Jn Am

⊂
N

n=1
σ
 
m∈I\Jn Am

= σ
 
m∈I\JN Am

⊂σ
 
m∈I\J Am

.
The left-hand side does not depend on J. Hence we can form the intersection over
all ﬁnite J and obtain
∞

n=1
σ
 
m∈I\Jn Am

⊂T

(Ai)i∈I

.
⊓⊔
Maybe at ﬁrst glance it is not evident that there are any interesting events in the
tail σ-algebra at all. It might not even be clear that we do not have T = {∅, Ω}.
Hence we now present simple examples of tail events and tail σ-algebra measurable
random variables. In Sect. 2.4, we will study a more complex example.
Example 2.36
(i) Let A1, A2, . . . be events. Then the events A∗:= lim inf
n→∞An and A∗:=
lim sup
n→∞
An are in T ((An)n∈N). Indeed, if we deﬁne Bn :=
∞

m=n
Am for n ∈N,
then Bn ↑A∗and Bn ∈σ((Am)m≥N) for any n ≥N. Thus A∗∈σ((Am)m≥N)
for any N ∈N and hence A∗∈T ((An)n∈N). The case A∗is similar.
(ii) Let (Xn)n∈N be a family of R-valued random variables. Then the maps X∗:=
lim infn→∞Xn and X∗
:= lim supn→∞Xn are T ((Xn)n∈N)-measurable.
Indeed, if we deﬁne Yn := supm≥n Xm, then for any N ∈N, the random
variable X∗= infn≥1 Yn = infn≥N Yn is TN := σ(Xn, n ≥N)-measurable
and hence also measurable with respect to T ((Xn)n∈N) = ∞
n=1 Tn.
The case X∗is similar.
(iii) Let (Xn)n∈N be real random variables. Then the Cesàro limits
lim inf
n→∞
1
n
n

i=1
Xi
and
lim sup
n→∞
1
n
n

i=1
Xi

2.3
Kolmogorov’s 0–1 Law
71
are T ((Xn)n∈N)-measurable. In order to show this, choose N ∈N and note
that
X∗:= lim inf
n→∞
1
n
n

i=1
Xi = lim inf
n→∞
1
n
n

i=N
Xi
is σ((Xn)n≥N)-measurable. Since this holds for any N, X∗is T ((Xn)n∈N)-
measurable. The case of the limes superior is similar. ♦
Theorem 2.37 (Kolmogorov’s 0–1 Law) Let I be a countably inﬁnite index set
and let (Ai)i∈I be an independent family of σ-algebras. Then the tail σ-algebra is
P-trivial, that is,
P[A] ∈{0, 1}
for any A ∈T ((Ai)i∈I).
Proof It is enough to consider the case I = N. For n ∈N, let
Fn :=
0
n

k=1
Ak : A1 ∈A1, . . . , An ∈An
1
.
Then F := ∞
n=1 Fn is a semiring and σ(F) = σ(
n∈N An). Indeed, for any
n ∈N and An ∈An, we have An ∈F; hence σ(
n∈N An) ⊂σ(F). On the
other hand, we have Fm ⊂σ(m
n=1 An) ⊂σ(
n∈N An) for any m ∈N; hence
F ⊂σ(
n∈N An).
Let A ∈T ((An)n∈N) and ε > 0. By the approximation theorem for measures
(Theorem 1.65), there exists an N ∈N and mutually disjoint sets F1, . . . , FN ∈
F such that P[A △(F1 ∪. . . ∪FN)] < ε. Clearly, there is an n ∈N such that
F1, . . . , FN ∈Fn and thus F := F1 ∪. . . ∪FN ∈σ(A1 ∪. . . ∪An). Obviously,
A ∈σ(∞
m=n+1 Am); hence A is independent of F. Thus
ε > P[A \ F] = P[A ∩(Ω \ F)] = P[A]

1 −P[F]

≥P[A]

1 −P[A] −ε

.
Letting ε ↓0 yields 0 = P[A](1 −P[A]).
⊓⊔
Corollary 2.38 Let (An)n∈N be a sequence of independent events. Then
P
'
lim sup
n→∞
An
(
∈{0, 1}
and
P
'
lim inf
n→∞An
(
∈{0, 1}.
Proof Essentially this is a simple conclusion of the Borel–Cantelli lemma. How-
ever, the statement can also be deduced from Kolmogorov’s 0–1 law as limes
superior and limes inferior are in the tail σ-algebra.
⊓⊔

72
2
Independence
Corollary 2.39 Let (Xn)n∈N be an independent family of R-valued random vari-
ables. Then X∗:= lim infn→∞Xn and X∗:= lim supn→∞Xn
are almost
surely constant. That is, there exist x∗, x∗∈R such that P[X∗= x∗] = 1 and
P[X∗= x∗] = 1.
If all Xi are real-valued, then the Cesàro limits
lim inf
n→∞
1
n
n

i=1
Xi
and
lim sup
n→∞
1
n
n

i=1
Xi
are also almost surely constant.
Proof Let X∗:= lim inf
n→∞Xn. For any x ∈R, we have {X∗≤x} ∈T ((Xn)n∈N);
hence P[X∗≤x] ∈{0, 1}. Deﬁne
x∗:= inf{x ∈R : P[X∗≤x] = 1} ∈R.
If x∗= ∞, then evidently
P[X∗< ∞] = lim
n→∞P[X∗≤n] = 0.
If x∗∈R, then
P[X∗≤x∗] = lim
n→∞P
'
X∗≤x∗+ 1
n
(
= 1
and
P[X∗< x∗] = lim
n→∞P
'
X∗≤x∗−1
n
(
= 0.
If x∗= −∞, then
P[X∗> −∞] = lim
n→∞P[X∗> −n] = 0.
The cases of the limes superior and the Cesàro limits are similar.
⊓⊔
Takeaways Consider an event that is described by the values of inﬁnitely
many random variables. If the occurrence of the event does not change when
we change ﬁnitely many values of the random variables, then the event is
called terminal. If the random variables are independent, then terminal events
either have probability 0 or 1 (Kolmogorov’s 0–1 law). In the Borel-Cantelli
lemma we have encountered a special case.

2.4
Example: Percolation
73
Exercise 2.3.1 Let (Xn)n∈N be an independent family of Rad1/2 random variables
(i.e., P[Xn = −1] = P[Xn = +1] = 1
2) and let Sn = X1 + . . . + Xn for any n ∈N.
Show that lim supn→∞Sn = ∞almost surely. ♣
Exercise 2.3.2 Consider two families (A1, A3, A5, . . .) and (A2, A4, A6, . . .) of
events and assume that each family is independent but they are not necessarily
independent of each other. In Exercise 2.1.2 it was shown that the conclusion of
the Borel-Cantelli lemma still holds under this weaker assumption. Now ﬁnd an
example that shows that the conclusion of Kolmogorov’s 0–1 law need not hold
under this assumption. ♣
2.4
Example: Percolation
Consider the d-dimensional integer lattice Zd, where any point is connected to any
of its 2d nearest neighbors by an edge. If x, y ∈Zd are nearest neighbors (that is,
∥x −y∥2 = 1), then we denote by e = ⟨x, y⟩= ⟨y, x⟩the edge that connects x
and y. Formally, the set of edges is a subset of the set of subsets of Zd with two
elements:
E =
	
{x, y} : x, y ∈Zd with ∥x −y∥2 = 1

.
Somewhat more generally, an undirected graph G is a pair G = (V, E), where V
is a set (the set of “vertices” or nodes) and E ⊂{{x, y} : x, y ∈V, x ̸= y} is a
subset of the set of subsets of V of cardinality two (the set of edges or bonds).
Our intuitive understanding of an edge is a connection between two points x and
y and not an (unordered) pair {x, y}. To stress this notion of a connection, we use a
different symbol from the set brackets. That is, we denote the edge that connects x
and y by ⟨x, y⟩= ⟨y, x⟩instead of {x, y}.
Our graph (V, E) is the starting point for a stochastic model of a porous medium.
We interpret the edges as tubes along which water can ﬂow. However, we want
the medium not to have a homogeneous structure, such as Zd, but an amorphous
structure. In order to model this, we randomly destroy a certain fraction 1 −p of
the tubes (with p ∈[0, 1] a parameter) and keep the others. Water can ﬂow only
through the remaining tubes. The destroyed tubes will be called “closed”, the others
“open”. The fundamental question is: For which values of p is there a connected
inﬁnite system of tubes along which water can ﬂow? The physical interpretation is
that if we throw a block of the considered material into a bathtub, then the block will
soak up water; that is, it will be wetted inside. If there is no inﬁnite open component,
then the water may wet only a thin layer at the surface. See Fig. 2.1 for a computer
simulation of the percolation model.
We now come to a formal description of the model. Choose a parameter
p ∈[0, 1] and an independent family of identically distributed random variables
(Xp
e )e∈E with Xp
e ∼Berp; that is, P[Xp
e = 1] = 1 −P[Xp
e = 0] = p for any

74
2
Independence
Fig. 2.1 Percolation on a 15 × 15 grid, p = 0.42.
e ∈E. We deﬁne the set of open edges as
Ep := {e ∈E : Xp
e = 1}.
(2.12)
Consequently, the edges in E \ Ep are called closed. Hence we have constructed
a (random) subgraph (Zd, Ep) of (Zd, E). We call (Zd, Ep) a percolation model
(more precisely, a model for bond percolation, in contrast to site percolation,
where vertices can be open or closed). An (open) path (of length n) in this subgraph
is a sequence π = (x0, x1, . . . , xn) of points in Zd with ⟨xi−1, xi⟩∈Ep for all
i = 1, . . . , n. We say that two points x, y ∈Zd are connected by an open path if
there is an n ∈N and an open path (x0, x1, . . . , xn) with x0 = x and xn = y. In this
case, we write x ←→p y. Note that “←→p” is an equivalence relation; however, a
random one, as it depends on the values of the random variables (Xp
e )e∈E. For every
x ∈Zd, we deﬁne the (random) open cluster of x; that is, the connected component
of x in the graph (Zd, Ep):
Cp(x) := {y ∈Zd : x ←→p y}.
(2.13)

2.4
Example: Percolation
75
Lemma 2.40 Let x, y ∈Zd. Then 1{x←→py} is a random variable. In particular,
#Cp(x) is a random variable for any x ∈Zd.
Proof We may assume x = 0. Let fy,n = 1 if there exists an open path of length
at most n that connects 0 to y, and fy,n = 0 otherwise. Clearly, fy,n ↑1{0←→py}
for n →∞; hence it sufﬁces to show that each fy,n is measurable. Let Bn :=
{−n, −n + 1, . . . , n −1, n}d and En := {e ∈E : e ∩Bn ̸= ∅}. Then Yn :=
(Xp
e : e ∈En) : Ω →{0, 1}En is measurable (with respect to 2({0,1}En)) by
Theorem 1.90. However, fy,n is a function of Yn, say fy,n = gy,n ◦Yn for some map
gy,n : {0, 1}En →{0, 1}. By the composition theorem for maps (Theorem 1.80),
fy,n is measurable.
The additional statement holds since #Cp(x) = 
y∈Zd 1{x←→py}.
⊓⊔
Deﬁnition 2.41 We say that percolation occurs if there exists an inﬁnitely large
open cluster. We call
ψ(p) := P[there exists an inﬁnite open cluster]
= P
' 
x∈Zd
{#Cp(x) = ∞}
(
the probability of percolation. We deﬁne
θ(p) := P[#Cp(0) = ∞]
as the probability that the origin is in an inﬁnite open cluster.
By the translation invariance of the lattice, we have
θ(p) = P[#Cp(y) = ∞]
for any y ∈Zd.
(2.14)
The fundamental question is: How large are θ(p) and ψ(p) depending on p?
We make the following simple observation.
Theorem 2.42 The map [0, 1] →[0, 1], p →θ(p) is monotone increasing.
Proof Although the statement is intuitively so clear that it might not need a proof,
we give a formal proof in order to introduce a technique called coupling. Let p, p′ ∈
[0, 1] with p < p′. Let (Ye)e∈E be an independent family of random variables with
P[Ye ≤q] = q for any e ∈E and q ∈{p, p′, 1}. At this point, we could, for
example, assume that Ye ∼U[0,1] is uniformly distributed on [0, 1]. Since we have
not yet shown the existence of an independent family with this distribution, we
content ourselves with Ye that assume only three values {p, p′, 1}. Hence
P[Ye = q] =
⎧
⎨
⎩
p,
if q = p,
p′ −p,
if q = p′,
1 −p′,
if q = 1.

76
2
Independence
Such a family (Ye)e∈E exists by Theorem 2.19. For q ∈{p, p′} and e ∈E, we
deﬁne
Xq
e :=
0 1,
if Ye ≤q,
0,
else.
Clearly, for any q ∈{p, p′}, the family (Xq
e )e∈E of random variables is independent
(see Remark 2.15(iii)) and Xq
e ∼Berq. Furthermore, Xp
e ≤Xp′
e for any e ∈E. The
procedure of deﬁning two families of random variables that are related in a speciﬁc
way (here “≤”) on one probability space is called a coupling.
Clearly, Cp(x) ⊂Cp′(x) for any x ∈Zd; hence θ(p) ≤θ(p′).
⊓⊔
With the aid of Kolmogorov’s 0–1 law, we can infer the following theorem.
Theorem 2.43 For any p ∈[0, 1], we have ψ(p) =

0,
if θ(p) = 0,
1,
if θ(p) > 0.
Proof If θ(p) = 0, then by (2.14)
ψ(p) ≤

y∈Zd
P[#Cp(y) = ∞] =

y∈Zd
θ(p) = 0.
Now let A = 
y∈Zd{#Cp(y) = ∞}. Clearly, A remains unchanged if we change
the state of ﬁnitely many edges. That is, A ∈σ((Xp
e )e∈E\F ) for every ﬁnite F ⊂E.
Hence A is in the tail σ-algebra T ((Xp
e )e∈E) by Theorem 2.35. Kolmogorov’s 0–1
law (Theorem 2.37) implies that ψ(p) = P[A] ∈{0, 1}. If θ(p) > 0, then ψ(p) ≥
θ(p) implies ψ(p) = 1.
⊓⊔
Due to the monotonicity, we can make the following deﬁnition.
Deﬁnition 2.44 The critical value pc for percolation is deﬁned as
pc = inf{p ∈[0, 1] : θ(p) > 0} = sup{p ∈[0, 1] : θ(p) = 0}
= inf{p ∈[0, 1] : ψ(p) = 1} = sup{p ∈[0, 1] : ψ(p) = 0}.
We come to the main theorem of this section.
Theorem 2.45 For d = 1, we have pc = 1. For d ≥2, we have pc(d) ∈
)
1
2d−1, 2
3
*.
Proof First consider d = 1 and p < 1. Let A−:= {Xp
⟨n,n+1⟩= 0 for some n < 0}
and A+ := {Xp
⟨n,n+1⟩= 0 for some n > 0}. Let A = A−∩A+. By the Borel–
Cantelli lemma, we get P[A−] = P[A+] = 1. Hence θ(p) = P[Ac] = 0.
Now assume d ≥2.

2.4
Example: Percolation
77
Lower bound First we show pc ≥
1
2d−1. Clearly, for any n ∈N,
P[#Cp(0) = ∞] ≤P
)
there is an x ∈Cp(0) with ∥x∥∞= n
*
.
We want to estimate the probability that there exists a point x ∈Cp(0) with distance
n from the origin. Any such point is connected to the origin by a path without self-
intersections π that starts at 0 and has length m ≥n. Let Π0,m be the set of such
paths. Clearly, #Π0,m ≤2d ·(2d −1)m−1 since there are 2d choices for the ﬁrst step
and at most 2d −1 choices for any further step. For any π ∈Π0,m, the probability
that π uses only open edges is
P[π is open] = pm.
Hence, for p <
1
2d−1,
θ(p) ≤
∞

m=n

π∈Π0,m
P[π is open] ≤
2d
2d −1
∞

m=n

(2d −1)p
m
=
2d
(2d −1)(1 −(2d −1)p)
(2d −1)pn n→∞
−→0.
We conclude that pc ≥
1
2d−1.
Upper bound We can consider Zd as a subset of Zd × {0} ⊂Zd+1. Hence,
if percolation occurs for p in Zd, then it also occurs for p in Zd+1. Hence the
corresponding critical values are ordered pc(d + 1) ≤pc(d).
Thus, it is enough to consider the case d = 2. Here we show pc ≤2
3 by using a
contour argument due to Peierls [127], originally designed for the Ising model of a
ferromagnet, see Example 18.16 and (18.9).
For N ∈N, we deﬁne (compare (2.13) with x = (i, 0))
CN :=
N

i=0
Cp(i, 0)
as the set of points that are connected (along open edges) to at least one of the
points in {0, . . . , N} × {0}. Due to the subadditivity of probability (and since
P[#Cp
(i, 0)

= ∞] = θ(p) for any i ∈Z), we have
θ(p) =
1
N + 1
N

i=0
P
)
#Cp
(i, 0)

= ∞
*
≥
1
N + 1P
)
#CN = ∞
*
.

78
2
Independence
Now consider those closed contours in the dual graph ( ˜Z2, ˜E) that surrounds CN if
#CN < ∞. Here the dual graph is deﬁned by
˜Z2 =
1
2, 1
2

+ Z2,
˜E =

{x, y} : x, y ∈˜Z2, ∥x −y∥2 = 1

.
An edge ˜e in the dual graph ( ˜Z2, ˜E) crosses exactly one edge e in (Z2, E). We
call ˜e open if e is open and closed otherwise. A circle γ is a self-intersection free
path in ( ˜Z2, ˜E) that starts and ends at the same point. A contour of the set CN is a
minimal circle that surrounds CN. Minimal means that the enclosed area is minimal
(see Fig. 2.2). For n ≥2N, let
Γn =

γ : γ is a circle of length n that surrounds {0, . . ., N} × {0}

.
We want to deduce an upper bound for #Γn. Let γ ∈Γn and ﬁx one point of γ .
For deﬁniteness, choose the upper point

m + 1
2, 1
2

of the rightmost edge of γ that
crosses the horizontal axis (in Fig. 2.2 this is the point

5 + 1
2, 1
2

). Clearly, m ≥N
and m ≤n since γ surrounds the origin. Starting from

m + 1
2, 1
2

, for any further
0
−1
1
5
0
−1
1
Fig. 2.2 Contour of the cluster C5.

2.4
Example: Percolation
79
edge of γ , there are at most three possibilities. Hence
#Γn ≤n · 3n.
We say that γ is closed if it uses only closed edges (in ˜E). A contour of CN is
automatically closed and has a length of at least 2N. Hence for p > 2
3
P[#CN < ∞] =
∞

n=2N
P
)
there is a closed circle γ ∈Γn
*
≤
∞

n=2N
n ·

3(1 −p)
n
N→∞
−→
0.
We conclude pc ≤2
3.
⊓⊔
In general, the value of pc is not known and is extremely hard to determine. In the
case of bond percolation on Z2, however, the exact value of pc can be determined
due to the self-duality of the planar graph (Z2, E). (If G = (V, E) is a planar graph;
that is, a graph that can be embedded into R2 without self-intersections, then the
vertex set of the dual graph is the set of faces of G. Two such vertices are connected
by exactly one edge; that is, by the edge in E that separates the two faces. Evidently,
the two-dimensional integer lattice is isomorphic to its dual graph. Note that the
contour in Fig. 2.2 can be considered as a closed path in the dual graph.) We cite a
theorem of Kesten [94].
Theorem 2.46 (Kesten [94]) For bond percolation in Z2, the critical value is pc =
1
2 and θ(pc) = 0.
Proof See, for example, the book of Grimmett [63, pages 287ff].
⊓⊔
It is conjectured that θ(pc) = 0 holds in any dimension d ≥2. However, rigorous
proofs are known only for d = 2 and d ≥19 (see [67]).
Uniqueness of the Inﬁnite Open Cluster∗
Fix a p such that θ(p) > 0. We saw that with probability one there is at least one
inﬁnite open cluster. Now we want to show that there is exactly one.
Denote by N ∈{0, 1, . . ., ∞} the (random) number of inﬁnite open clusters.
Theorem 2.47 (Uniqueness of the inﬁnite open cluster) For any p ∈[0, 1], we
have Pp[N ≤1] = 1.
Proof This theorem was ﬁrst proved by Aizenman, Kesten and Newman [2, 3]. Here
we follow the proof of Burton and Keane [23] as described in [63, Section 8.2].

80
2
Independence
The cases p = 1 and θ(p) = 0 (hence in particular the case p = 0) are trivial.
Hence we assume now that p ∈(0, 1) and θ(p) > 0.
Step 1.
We ﬁrst show that
Pp[N = m] = 1
for some m = 0, 1, . . . , ∞.
(2.15)
We need a 0–1 law similar to that of Kolmogorov. However, N is not measurable
with respect to the tail σ-algebra. Hence we have to ﬁnd a more subtle argument.
Let u1 = (1, 0, . . . , 0) be the ﬁrst unit vector in Zd. On the edge set E, deﬁne the
translation τ : E →E by τ(⟨x, y⟩) = ⟨x + u1, y + u1⟩. Let
E0 :=
	
⟨(x1, . . . , xd), (y1, . . . , yd)⟩∈E : x1 = 0, y1 ≥0

be the set of all edges in Zd that either connect two points from {0} × Zd−1
or one point of {0} × Zd−1 with one point of {1} × Zd−1. Clearly, the sets
(τ n(E0), n ∈Z) are disjoint and E = 
n∈Z τ n(E0). Hence the random variables
Yn := (Xp
τ n(e))e∈E0, n ∈Z, are independent and identically distributed (with values
in {0, 1}E0).Deﬁne Y = (Yn)n∈Z and τ(Y) = (Yn+1)n∈Z. Deﬁne Am ∈{0, 1}E by
{Y ∈Am} = {N = m}.
Clearly, the value of N does not change if we shift all edges simultaneously. That
is, {Y ∈Am} = {τ(Y) ∈Am}. An event with this property is called invariant or
shift invariant. Using an argument similar to that in the proof of Kolmogorov’s 0–1
law, one can show that invariant events (deﬁned by i.i.d. random variables) have
probability either 0 or 1 (see Example 20.26 for a proof).
Step 2.
We will show that
Pp[N = m] = 0
for any m ∈N \ {1}.
(2.16)
Accordingly, let m = 2, 3, . . .. We assume that P[N = m] = 1 and show that this
leads to a contradiction.
For L ∈N, let BL := {−L, . . . , L}d and denote by EL = {e = ⟨x, y⟩∈E :
x, y ∈BL} the set of those edges with both vertices lying in BL. For i = 0, 1, let
Di
L := {Xp
e = i for all e ∈EL}. Let N1
L be the number of inﬁnite open clusters if
we consider all edges e in EL as open (independently of the value of Xp
e ). Similarly
deﬁne N0
L where we consider all edges in EL as closed. Since Pp[Di
L] > 0, and
since N = m almost surely, we have Ni
L = m almost surely for i = 0, 1.
Let
A2
L:=

x1,x2∈BL\BL−1
	Cp(x1) ∩Cp(x2) = ∅
 ∩	#Cp(x1) = #Cp(x2) = ∞

2.4
Example: Percolation
81
be the event where there exist two points on the boundary of BL that lie in different
inﬁnite open clusters. Clearly, A2
L ↑{N ≥2} for L →∞.
Deﬁne A2
L,0 in a similarly way to A2
L; however, we now consider all edges e ∈EL
as closed, irrespective of whether Xp
e = 1 or Xp
e = 0. If A2
L occurs, then there
are two points x1, x2 on the boundary of BL such that for any i = 1, 2, there is an
inﬁnite self-intersection free open path πxi starting at xi that avoids x3−i. Hence
A2
L ⊂A2
L,0. Now choose L large enough for P[A2
L,0] > 0.
If A2
L,0 occurs and if we open all edges in BL, then at least two of the inﬁnite
open clusters get connected by edges in BL. Hence the total number of inﬁnite open
clusters decreases by at least one. We infer Pp[N1
L ≤N0
L −1] ≥Pp[A2
L,0] > 0,
which leads to a contradiction.
Step 3.
In Step 2, we have shown already that N does not assume a ﬁnite value
larger than 1. Hence it remains to show that almost surely N does not assume the
value ∞. Indeed, we show that
Pp[N ≥3] = 0.
(2.17)
This part of the proof is the most difﬁcult one. We assume that Pp[N ≥3] > 0 and
show that this leads to a contradiction.
We say that a point x ∈Zd is a trifurcation point if
•
x is in an inﬁnite open cluster Cp(x),
•
there are exactly three open edges with endpoint x, and
•
removing all of these three edges splits Cp(x) into three mutually disjoint inﬁnite
open clusters.
By T we denote the set of trifurcation points, and let TL := T ∩BL. Let r := Pp[0 ∈
T ]. Due to translation invariance, we have (#BL)−1Ep[#TL] = r for any L. (Here
Ep[#TL] denotes the expected value of #TL, which we deﬁne formally in Chap. 5.)
Let
A3
L:=

x1,x2,x3∈BL\BL−1
 
i̸=j
{Cp(xi) ∩Cp(xj) = ∅}

∩
 3

i=1
{#Cp(xi) = ∞}

be the event where there are three points on the boundary of BL that lie in different
inﬁnite open clusters. Clearly, A3
L ↑{N ≥3} for L →∞.
As for A2
L,0, we deﬁne A3
L,0 as the event where there are three distinct points on
the boundary of BL that lie in different inﬁnite open clusters if we consider all edges
in EL as closed. As above, we have A3
L ⊂A3
L,0.

82
2
Independence
For three distinct points x1, x2, x3 ∈BL \ BL−1, let Fx1,x2,x3 be the event
where for any i = 1, 2, 3, there exists an inﬁnite self-intersection free open path
πxi starting at xi that uses only edges in Ep \ EL and that avoids the points xj,
j ̸= i. Then
A3
L,0 ⊂

x1,x2,x3∈BL\BL−1
mutually distinct
Fx1,x2,x3.
Let L be large enough for Pp[A3
L,0] ≥Pp[N ≥3]/2 > 0. Choose three pairwise
distinct points x1, x2, x3 ∈BL \ BL−1 with Pp[Fx1,x2,x3] > 0.
If Fx1,x2,x3 occurs, then we can ﬁnd a point y ∈BL that is the starting point of
three mutually disjoint (not necessarily open) paths π1, π2 and π3 that end at x1, x2
and x3. Let Gy,x1,x2,x3 be the event where in EL exactly those edges are open that
belong to these three paths (that is, all other edges in EL are closed). The events
Fx1,x2,x3 and Gy,x1,x2,x3 are independent, and if both of them occur, then y is a
trifurcation point. Hence
r = Pp[y ∈T ] ≥Pp[Fx1,x2,x3] ·

p ∧(1 −p)
#EL > 0.
Now we show that r must equal 0, which contradicts the assumption Pp[N ≥3] >
0. Let KL be the set of all edges which have at least one endpoint in BL. We consider
two edges in KL as equivalent if there exists a path in BL along open edges that does
not hit any trifurcation point and which joins at least one endpoint of each of the two
edges. We denote the equivalence relation by R and let UL = KL/R be the set of
equivalence classes. (Note that the three neighboring edges of a trifurcation point
are in different equivalence classes.) We turn the set HL := UL ∪TL into a graph
by considering two points x ∈TL and u ∈UL as neighbors if there exists an edge
k ∈u which is incident to x. Note that each point x ∈TL has exactly three neighbors
which are in UL. The points in UL can be isolated (that is, without neighbors) or can
be joined to arbitrarily many points in TL but not in UL.
A circle is a self-avoiding (ﬁnite) path that ends at its starting point. Note that
the graph HL has no circles. To show this assume there was a self-avoiding path
(h0, h1, . . . , hn) starting and ending in some point h0 = hn = x ∈TL. Then
h1, hn−1 ∈UL are distinct but connected in Kp even if we remove x. However,
by the deﬁnition of the trifurcation point x, this is impossible. On the other hand,
if there was a self-avoiding path (g0, . . . , gm) starting and ending in some point
g0 = gm = u ∈UL, then (g1, g2, . . . , gm, g1) is a self-avoiding path starting and
ending in g1 ∈TL. However, we have just shown that such a path could not exist.
Write degHL(h) for the degree of h ∈HL; that is, the number of neighbors of h
in HL. A point h with degHL(h) = 1 is called a leaf of HL. Obviously, only points
of UL can be leaves. Let Z be a connected component of HL that contains at least

2.4
Example: Percolation
83
one point x ∈TL. Since Z is a tree (that is, it is connected and contains no circles),
we have
#Z −1 = 1
2

h∈Z
degHL(h).
Rearranging this formula yields an expression for the number of leaves:
#	u ∈Z : degHL(u) = 1
 = 2 +

h∈Z
 degHL(h) −2+
≥2 + #	h ∈Z : degHL(h) ≥3
≥2 + #(Z ∩TL).
Summing over the connected components Z of HL with at least one point in TL, we
obtain
#	u ∈HL : degHL(u) = 1
 ≥#TL.
Observe that any leaf u ∈HL contains an edge that is incident to a point x ∈TL.
Hence the edges of u lie in an inﬁnite open cluster of Kp and there is at least one
edge k ∈u incident to a point at the boundary BL \ BL−1 of BL. For distinct leaves
these are distinct points since the leaves belong to disjoint open clusters. Hence we
get the bound
#TL ≤#(BL \ BL−1)
and thus
#TL
#BL
≤#(BL \ BL−1)
#BL
≤d
L
L→∞
−→
0.
Now r = (#BL)−1Ep[#TL] ≤d/L implies r = 0. (Note that in the argument we
used the notion of the expected value Ep[#TL] that will be formally introduced only
in Chap. 5.)
⊓⊔
Takeaways Independent coin tosses decide if an edge of Zd is retained
(probability p) or removed. The remaining random graph almost surely
contains a (unique) inﬁnite connected component if p is larger than a critical
value pc. For d ≥2, we have 0 ≤
1
2d−1 ≤pc ≤2
3 (Theorem 2.45). Starting
with a graph other than Zd, for example an inﬁnite binary tree, can result in
multiple inﬁnite connected components (Exercise 2.4.1).

84
2
Independence
0
Fig. 2.3 Binary tree.
Exercise 2.4.1 Let T be the inﬁnite binary tree (Fig. 2.3). That is, each point in T
has exactly three neighbours. We single out an arbitrary point of T and name it 0.
Now consider bond percolation on T with probability p.
(i) Show that pc
≥1/2. Hint: Use a similar argument as in the proof of
Theorem 2.45.
(ii) Let Jn be the number of connected subgraphs of T that contain 0. Show that
Jn ≤4n+1. Use a contour argument similarly as in Theorem 2.45 to show that
pc ≤3
4. (In fact, we could use the theory of branching processes to show that
pc = 1
2.)
(iii) For p ∈(pc, 1), show that with positive probability there are at least two
inﬁnite connected components.
In (iii) one can even show that almost surely there are inﬁnitely many inﬁnite
connected components. ♣

Chapter 3
Generating Functions
It is a fundamental principle of mathematics to map a class of objects that are of
interest into a class of objects where computations are easier. This map can be one to
one, as with linear maps and matrices, or it may map only some properties uniquely,
as with matrices and determinants.
In probability theory, in the second category fall quantities such as the median,
mean and variance of random variables. In the ﬁrst category, we have characteristic
functions, Laplace transforms and probability generating functions. These are useful
mostly because addition of independent random variables leads to multiplication
of the transforms. Before we introduce characteristic functions (and Laplace
transforms) later in the book, we want to illustrate the basic idea with probability
generating functions that are designed for N0-valued random variables.
In the ﬁrst section, we give the basic deﬁnitions and derive simple properties.
The next two sections are devoted to two applications: The Poisson approximation
theorem and a simple investigation of Galton–Watson branching processes.
3.1
Deﬁnition and Examples
Deﬁnition 3.1 (Probability generating function) Let X be an N0-valued random
variable. The (probability) generating function (p.g.f.) of PX (or, loosely speaking,
of X) is the map ψPX = ψX deﬁned by (with the understanding that 00 = 1)
ψX : [0, 1] →[0, 1],
z →
∞

n=0
P[X = n] zn.
(3.1)
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_3
85

86
3
Generating Functions
Theorem 3.2
(i) ψX is continuous on [0, 1] and inﬁnitely often continuously differentiable on
(0, 1). For n ∈N, the nth derivative ψ(n)
X fulﬁlls
lim
z↑1 ψ(n)
X (z) =
∞

k=n
P[X = k] · k(k −1) · · · (k −n + 1),
(3.2)
where both sides can equal ∞.
(ii) The distribution PX of X is uniquely determined by ψX.
(iii) For any r ∈(0, 1), ψX is uniquely determined by countably many values
ψX(xi), xi ∈[0, r], i ∈N. If the series in (3.1) converges for some z > 1,
then the statement is also true for any r ∈(0, z) and we have
lim
x↑1 ψ(n)
X (x) = ψ(n)
X (1) < ∞
for n ∈N.
In this case, ψX is uniquely determined by the derivatives ψ(n)
X (1), n ∈N.
Proof The statements follow from the elementary theory of power series. For the
ﬁrst part of (iii), see, eg. [149, Theorem 8.5].
⊓⊔
Reﬂection Come up with an example for X such that the series in (3.1) does not
converge for any z > 1 but lim
x↑1 ψ′
X(x) exists and is ﬁnite. ♠♠
Theorem 3.3 (Multiplicativity of generating functions) If X1, . . . , Xn are inde-
pendent and N0-valued random variables, then
ψX1+...+Xn =
n

i=1
ψXi .
Proof Let z ∈[0, 1) and write ψX1(z) ψX2(z) as a Cauchy product
ψX1(z) ψX2(z) =
 ∞

n=0
P[X1 = n] zn
  ∞

n=0
P[X2 = n] zn

=
∞

n=0
zn
 n

m=0
P[X1 = m] P[X2 = n −m]

=
∞

n=0
zn
n

m=0
P[X1 = m, X2 = n −m]
=
∞

n=0
P[X1 + X2 = n] zn = ψX1+X2(z).
Inductively, the claim follows for all n ≥2.
⊓⊔

3.1
Deﬁnition and Examples
87
Example 3.4
(i) Let X be bn,p-distributed for some n ∈N and let p ∈[0, 1]. Then
ψX(z) =
n

m=0
n
m

pm(1 −p)n−m zm =

pz + (1 −p)
n.
(3.3)
(ii) If X, Y are independent, X ∼bm,p and Y ∼bn,p, then, by Theorem 3.3,
ψX+Y (z) =

pz + (1 −p)
m 
pz + (1 −p)
n =

pz + (1 −p)
m+n.
Hence, by Theorem 3.2(ii), X + Y is bm+n,p-distributed and thus (by Theo-
rem 2.31)
bm,p ∗bn,p = bm+n,p.
(iii) Let X and Y be independent Poisson random variables with parameters λ ≥0
and μ ≥0, respectively. That is, P[X = n] = e−λλn/n! for n ∈N0. Then
ψPoiλ(z) =
∞

n=0
e−λ (λz)n
n!
= eλ(z−1).
(3.4)
Hence X + Y has probability generating function
ψPoiλ(z) · ψPoiμ(z) = eλ(z−1) eμ(z−1) = ψPoiλ+μ(z).
Thus X + Y ∼Poiλ+μ. We conclude that
Poiλ ∗Poiμ = Poiλ+μ.
(3.5)
(iv) Let X1, . . . , Xn
∼γp be independent geometrically distributed random
variables with parameter p ∈(0, 1). Deﬁne Y = X1 + . . . + Xn. Then, for
any z ∈[0, 1],
ψX1(z) =
∞

k=0
p(1 −p)k zk =
p
1 −(1 −p)z.
(3.6)

88
3
Generating Functions
By the generalized binomial theorem (see Lemma 3.5 with α
= −n),
Theorem 3.3 and (3.6), we have
ψY (z) = ψX1(z)n =
pn
(1 −(1 −p)z)n
=
∞

k=0
pn
−n
k

(−1)k (1 −p)k zk
=
∞

k=0
b−
n,p({k}) zk.
Here, for r ∈(0, ∞) and p ∈(0, 1],
b−
r,p =
∞

k=0
−r
k

(−1)k pr(1 −p)k δk
(3.7)
is the negative binomial distribution with parameters r and p. By the unique-
ness theorem for probability generating functions, we get Y ∼b−
n,p; hence (see
Deﬁnition 2.29 for the nth convolution power) b−
n,p = γ ∗n
p . ♦
Lemma 3.5 (Generalized binomial theorem) For α ∈R and k ∈N0, we deﬁne
the binomial coefﬁcient
α
k

:= α · (α −1) · · · (α −k + 1)
k!
.
(3.8)
Then the generalized binomial theorem holds:
(1 + x)α =
∞

k=0
α
k

xk
for all x ∈C with |x| < 1.
(3.9)
In particular, we have
1
√
1 −x
=
∞

n=0
2n
n

4−n xn
for all x ∈C with |x| < 1.
(3.10)
Proof The map f : x →(1 + x)α is holomorphic up to possibly a singularity
at x = −1. Hence it can be developed in a power series about 0 with radius of
convergence at least 1:
f (x) =
∞

k=0
f (k)(0)
k!
xk
for |x| < 1.

3.2
Poisson Approximation
89
For k ∈N0, the kth derivative is f (k)(0) = α(α −1) · · · (α −k + 1). Hence (3.9)
holds.
The additional claim follows by the observation that (for α = −1/2) we have
−1/2
n
 = 2n
n
(−4)−n.
⊓⊔
Takeaways Generating functions determine a probability distribution on N0.
They are the perfect analytic tool for studying sums of independent random
variables (on N0) as these sums translate into products of the generating
functions.
Exercise 3.1.1 Show that b−
r,p ∗b−
s,p = b−
r+s,p for r, s ∈(0, ∞) and p ∈(0, 1]. ♣
Exercise 3.1.2 Give an example for two different probability generating functions
that coincide at countably many points xi ∈(0, 1), i ∈N. (That is, in Theo-
rem 3.2(iii), the assumption ψ(z) < ∞for some z > 1 cannot be dropped.) ♣
3.2
Poisson Approximation
Lemma 3.6 Let μ and (μn)n∈N be probability measures on (N0, 2N0) with gener-
ating functions ψ and ψn, n ∈N. Then the following statements are equivalent.
(i)
μn({k})
n→∞
−→μ({k}) for all k ∈N0.
(ii)
μn(A)
n→∞
−→μ(A)
for all A ⊂N0.
(iii)
ψn(z)
n→∞
−→ψ(z)
for all z ∈[0, 1].
(iv)
ψn(z)
n→∞
−→ψ(z)
for all z ∈[0, η) for some η ∈(0, 1).
We write μn
n→∞
−→μ if any of the four conditions holds and say that (μn)n∈N
converges weakly to μ.
Proof (i) ⇒(ii)
Fix ε > 0 and choose N ∈N such that μ({N + 1, N +
2, . . .}) < ε
4. For sufﬁciently large n0 ∈N, we have
N

k=0
μn({k}) −μ({k})
 < ε
4
for all n ≥n0.

90
3
Generating Functions
In particular, for any n ≥n0, we have μn({N + 1, N + 2, . . .}) < ε
2. Hence, for
n ≥n0,
μn(A) −μ(A)
 ≤μn({N + 1, N + 2, . . .}) + μ({N + 1, N + 2, . . .})
+

k∈A∩{0,...,N}
μn({k}) −μ({k})

< ε.
(ii) ⇒(i)
This is trivial.
(i) ⇐⇒(iii) ⇐⇒(iv)
This follows from the elementary theory of power series.
⊓⊔
Reﬂection If instead of μ(N0) = 1, in the previous lemma we only assume
μ(N0) ∈[0, 1], then we still have (i) ⇐ (ii)
⇐⇒
(iii)
⇐⇒
(iv), but not
(i) ⇒(ii). Why? ♠
Let (pn,k)n,k∈N be numbers with pn,k ∈[0, 1] such that the limit
λ := lim
n→∞
∞

k=1
pn,k ∈(0, ∞)
(3.11)
exists and such that lim
n→∞
∞
k=1 p2
n,k = 0 (e.g., pn,k = λ/n for k ≤n and pn,k = 0
for k > n). For each n ∈N, let (Xn,k)k∈N be an independent family of random
variables with Xn,k ∼Berpn,k.
Deﬁne
Sn :=
∞

l=1
Xn,l
and
Sn
k :=
k

l=1
Xn,l
for k ∈N.
Theorem 3.7 (Poisson approximation) Under the above assumptions, the distri-
butions (PSn)n∈N converge weakly to the Poisson distribution Poiλ.
Proof The p.g.f. of the Poisson distribution is ψ(z) = eλ(z−1) (see (3.4)). On the
other hand, Sn −Sn
k and Sn
k are independent for any k ∈N; hence ψSn = ψSn
k ·
ψSn−Sn
k . Now, for any z ∈[0, 1],
1 ≥ψSn(z)
ψSn
k (z) = ψSn−Sn
k (z) ≥1 −P[Sn −Sn
k ≥1] ≥1 −
∞

l=k+1
pn,l
k→∞
−→1,

3.3
Branching Processes
91
hence
ψSn(z) = lim
k→∞ψSn
k (z) =
∞

l=1
(pn,lz + (1 −pn,l))
= exp
 ∞

l=1
log

1 + pn,l(z −1)


.
Note that | log(1 + x) −x| ≤x2 for |x| < 1
2. By assumption, max
l∈N pn,l →0 for
n →∞; hence, for sufﬁciently large n,

 ∞

l=1
log

1 + pn,l(z −1)

−

(z −1)
∞

l=1
pn,l

≤
∞

l=1
p2
n,l ≤
 ∞

l=1
pn,l

max
l∈N pn,l
n→∞
−→0.
Together with (3.11), we infer
lim
n→∞ψSn(z) = lim
n→∞exp

(z −1)
∞

l=1
pn,l

= eλ(z−1).
⊓⊔
Takeaways The number of successes of a large number of improbable
independent events is approximately Poisson distributed. Hence the Poisson
distribution is used to model the number of rare successes in a large number
of trials.
Exercise 3.2.1 Let λ > 0 and pn = λ/n, n ∈N. In Theorem 3.7, it was shown that
the binomial distribution bn,λ/n converges to the Poisson distribution Poiλ. Show
this with a different approach by checking condition (i) from Lemma 3.6. ♣
3.3
Branching Processes
Branching processes are models for the random development of the size of a
population. Generating functions are the ideal tool for the analysis of such processes.

92
3
Generating Functions
Let T, X1, X2, . . . be independent N0-valued random variables. What is the
distribution of S := T
n=1 Xn? First of all, note that S is measurable since
{S = k} =
∞

n=0
{T = n} ∩{X1 + . . . + Xn = k}.
Theorem 3.8 If the random variables X1, X2, . . . are also identically distributed,
then the probability generating function of S is given by ψS(z) = ψT (ψX1(z)).
Proof We compute
ψS(z) =
∞

k=0
P[S = k] zk
=
∞

k=0
∞

n=0
P[T = n] P[X1 + . . . + Xn = k] zk
=
∞

n=0
P[T = n] ψX1(z)n = ψT
ψX1(z).
⊓⊔
Now assume that p0, p1, p2, . . . ∈[0, 1] are such that
∞

k=0
pk = 1. Let (Xn,i)n,i∈N0
be an independent family of random variables with P[Xn,i = k] = pk for all
i, k, n ∈N0.
Let Z0 = 1 and
Zn =
Zn−1

i=1
Xn−1,i
for n ∈N.
Zn can be interpreted as the number of individuals in the nth generation of a
randomly developing population. The ith individual in the nth generation has Xn,i
offspring (in the (n + 1)th generation).
Deﬁnition 3.9 (Zn)n∈N0 is called a Galton–Watson process or branching process
with offspring distribution (pk)k∈N0.
Probability generating functions are an important tool for the investigation of
branching processes. Hence, let
ψ(z) =
∞

k=0
pk zk

3.3
Branching Processes
93
be the p.g.f. of the offspring distribution and let ψ′ be its derivative. Recursively,
deﬁne the nth iterate of ψ by
ψ1 := ψ
and
ψn := ψ ◦ψn−1 for n = 2, 3, . . . .
Finally, let ψZn be the p.g.f. of Zn.
Lemma 3.10 ψn = ψZn for all n ∈N.
Proof For n = 1, the statement is true by deﬁnition. For n ∈N, we conclude
inductively by Theorem 3.8 that ψZn+1 = ψ ◦ψZn = ψ ◦ψn = ψn+1.
⊓⊔
Clearly, the probability qn := P[Zn = 0] that Z is extinct by time n is monotone
increasing in n. We denote by
q := lim
n→∞P[Zn = 0]
the extinction probability; that is, the probability that the population will eventually
die out.
Under what conditions do we have q = 0, q = 1, or q ∈(0, 1)? Clearly, q ≥p0.
On the other hand, if p0 = 0, then Zn is monotone in n; hence q = 0.
Theorem 3.11 (Extinction probability of the Galton–Watson process)
Assume p1 ̸= 1. Then:
(i) F := {r ∈[0, 1] : ψ(r) = r} = {q, 1}.
(ii) The following equivalences hold:
q < 1
⇐⇒
lim
z↑1 ψ′(z) > 1
⇐⇒
∞

k=1
kpk > 1.
Proof
(i) We have ψ(1) = 1; hence 1 ∈F. Note that
qn = ψn(0) = ψ(qn−1)
for all n ∈N
and qn ↑q. Since ψ is continuous, we infer
ψ(q) = ψ

lim
n→∞qn

=
lim
n→∞ψ(qn) =
lim
n→∞qn+1 = q.
Thus q ∈F. If r ∈F is an arbitrary ﬁxed point of ψ, then r ≥0 = q0. Since ψ
is monotone increasing, it follows that r = ψ(r) ≥ψ(q0) = q1. Inductively,
we get r ≥qn for all n ∈N0; that is, r ≥q. We conclude q = min F.
(ii) If p0+p1 = 1, then all of the statements are obvious. Now assume p0+p1 < 1.
For the ﬁrst equivalence, we distinguish two cases.

94
3
Generating Functions
Case 1:
limz↑1 ψ′(z) ≤1. Since ψ is strictly convex, in this case, we have ψ(z) >
z for all z ∈[0, 1); hence F = {1}. We conclude q = 1.
Case 2:
limz↑1 ψ′(z) > 1. As ψ is strictly convex and since ψ(0) ≥0, there is a
unique r ∈[0, 1) such that ψ(r) = r. Hence F = {r, 1} and q = min F = r.
The second equivalence in (ii) follows by (3.2).
⊓⊔
For further reading, we refer to [5].
Takeaways A branching process dies out eventually if the mean number of
offspring is no larger than 1. More generally, the extinction probability is the
smallest ﬁxed point of the generating function of the offspring distribution.
Exercise 3.3.1 Assume that we have a branching process Z = (Zn)n∈N0 with Z0 =
1 whose offspring distribution is given by p0 = 1/3 and p2 = 2/3. Compute ψ′(1)
and the extinction probability. ♣
Exercise 3.3.2 Assume that we have a branching process Z = (Zn)n∈N0 with Z0 =
1 whose offspring distribution is given by pk = 1
3 · (2/3)k, k ∈N0.
(i) Compute the generating function ψ and the extinction probability q.
(ii) For this particular ψ, all the iterates are of a special form and can be computed
explicitly. Do it!
(iii) Compute limn→∞ψn(z), z ∈[0, 1]. What does the result imply for the
convergence of PZn? (Compare Lemma 3.6 and the comment below it.) ♣

Chapter 4
The Integral
Based on the notions of measure spaces and measurable maps, we introduce the
integral of a measurable map with respect to a general measure. This generalizes
the Lebesgue integral that can be found in textbooks on calculus. Furthermore,
the integral is a cornerstone in a systematic theory of probability that allows for
the deﬁnition and investigation of expected values and higher moments of random
variables.
In this chapter, we deﬁne the integral by an approximation scheme with simple
functions. Then we deduce basic statements such as Fatou’s lemma. Other important
convergence theorems for integrals follow in Chaps. 6 and 7.
4.1
Construction and Simple Properties
In the following, (Ω, A, μ) will always be a measure space. We denote by E the
vector space of simple functions (see Deﬁnition 1.93) on (Ω, A) and by
E+ := {f ∈E : f ≥0}
the cone (why this name?) of nonnegative simple functions. If
f =
m

i=1
αi 1Ai
(4.1)
for some m ∈N and for α1, . . . , αm ∈(0, ∞), and for mutually disjoint sets
A1, . . . , Am ∈A, then (4.1) is said to be a normal representation of f .
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_4
95

96
4
The Integral
Lemma 4.1 If f
=
m
i=1 αi 1Ai and f
=
n
j=1 βj 1Bj are two normal
representations of f ∈E+, then
m

i=1
αi μ(Ai) =
n

j=1
βj μ(Bj).
Proof If μ(Ai ∩Bj) > 0 for some i and j, then Ai ∩Bj ̸= ∅, and f (ω) = αi = βj
for any ω ∈Ai ∩Bj. Furthermore, clearly Ai ⊂n
j=1 Bj if αi ̸= 0, and Bj ⊂
m
i=1 Ai if βj ̸= 0. We conclude that
m

i=1
αi μ(Ai) =
m

i=1
n

j=1
αi μ(Ai ∩Bj)
=
m

i=1
n

j=1
βj μ(Ai ∩Bj) =
n

j=1
βj μ(Bj).
⊓⊔
This lemma allows us to make the following deﬁnition (since the value of I(f ) does
not depend on the choice of the normal representation).
Deﬁnition 4.2 Deﬁne the map I : E+ →[0, ∞] by
I(f ) =
m

i=1
αi μ(Ai)
if f has the normal representation f = m
i=1 αi 1Ai.
Lemma 4.3 The map I is positive linear and monotone increasing: Let f, g ∈E+
and α ≥0. Then the following statements hold.
(i) I(αf ) = α I(f ).
(ii) I(f + g) = I(f ) + I(g).
(iii) If f ≤g, then I(f ) ≤I(g).
Proof This is left as an exercise.
⊓⊔
Deﬁnition 4.4 (Integral) If f : Ω →[0, ∞] is measurable, then we deﬁne the
integral of f with respect to μ by

f dμ := sup
	
I(g) : g ∈E+, g ≤f

.

4.1
Construction and Simple Properties
97
Remark 4.5 By Lemma 4.3(iii), we have I(f ) =
3
f dμ for any f
∈E+.
Hence the integral is an extension of the map I from E+ to the set of nonnegative
measurable functions. ♦
If f, g : Ω →R with f (ω) ≤g(ω) for any ω ∈Ω, then we write f ≤g.
Analogously, we write f ≥0 and so on. On the other hand, we write “f ≤g
almost everywhere” if the weaker condition holds that there exists a μ-null set N
such that f (ω) ≤g(ω) for any ω ∈Nc.
Lemma 4.6 Let f, g, f1, f2, . . . be measurable maps Ω →[0, ∞]. Then:
(i) (Monotonicity) If f ≤g, then
3
f dμ ≤
3
g dμ.
(ii) (Monotone convergence) If fn
↑
f , then the integrals also converge:
3
fn dμ ↑
3
f dμ.
(iii) (Linearity) If α, β ∈[0, ∞], then

(αf + βg) dμ = α

f dμ + β

g dμ,
where we use the convention ∞· 0 := 0.
Proof
(i) This is immediate from the deﬁnition of the integral.
(ii) By (i), we have
lim
n→∞

fn dμ = sup
n∈N

fn dμ ≤

f dμ.
Hence we only have to show
3
f dμ ≤sup
n∈N
3
fn dμ.
Let g ∈E+ with g ≤f . It is enough to show that
sup
n∈N

fn dμ ≥

g dμ.
(4.2)
Assume that the simple function g has the normal representation g
=
N
i=1 αi 1Ai for some α1, . . . , αN
∈
(0, ∞) and mutually disjoint sets
A1, . . . , AN ∈A. For any ε > 0 and n ∈N, deﬁne the set
Bε
n = {fn ≥(1 −ε) g}.

98
4
The Integral
Since fn ↑f ≥g, we have Bε
n ↑Ω for any ε > 0. Hence, by (i), for any
ε > 0,

fn dμ ≥
 
(1 −ε) g 1Bεn

dμ
=
N

i=1
(1 −ε) αi μ(Ai ∩Bε
n)
n→∞
−→
N

i=1
(1 −ε) αi μ(Ai) = (1 −ε)

g dμ.
Letting ε ↓0 implies (4.2) and hence the claim (ii).
(iii) By Theorem 1.96, any nonnegative measurable map is a monotone limit of
simple functions. Hence there are sequences (fn)n∈N and (gn)n∈N in E+ such
that fn ↑f and gn ↑g. Thus also (αfn + βgn) ↑αf + βg. By (ii) and
Lemma 4.3, this implies

(αf + βg) dμ = lim
n→∞

(αfn + βgn) dμ
= α lim
n→∞

fn dμ + β lim
n→∞

gn dμ = α

f dμ + β

g dμ. ⊓⊔
For any measurable map f : Ω →R, we have f + ≤|f | and f −≤|f |, which
implies
3
f ± dμ ≤
3
|f | dμ. In particular, if
3
|f | dμ < ∞, then also
3
f −dμ <
∞and
3
f + dμ < ∞. Thus we can make the following deﬁnition that is the ﬁnal
deﬁnition for the integral of measurable functions.
Deﬁnition 4.7 (Integral of measurable functions) A measurable function f
:
Ω →R is called μ-integrable if 3 |f | dμ < ∞. We write
L1(μ) := L1(Ω, A, μ) :=

f : Ω →R : f is measurable and
3
|f | dμ < ∞

.
For f ∈L1(μ), we deﬁne the integral of f with respect to μ by

f (ω) μ(dω) :=

f dμ :=

f + dμ −

f −dμ.
(4.3)
If we only have
3
f −dμ < ∞or
3
f + dμ < ∞, then we also deﬁne
3
f dμ by
(4.3). Here the values +∞and −∞, respectively, are possible.
For A ∈A, we deﬁne

A
f dμ :=

(f 1A) dμ.

4.1
Construction and Simple Properties
99
Theorem 4.8 Let f : Ω →[0, ∞] be a measurable map.
(i) We have f = 0 almost everywhere if and only if
3
f dμ = 0.
(ii) If
3
f dμ < ∞, then f < ∞almost everywhere.
Proof
(i) “ ⇒” Assume f = 0 almost everywhere. Let N = {ω : f (ω) > 0}. Then
f ≤∞· 1N and n1N ↑∞· 1N. From Lemma 4.6(i) and (ii), we infer
0 ≤

f dμ ≤

(∞· 1N) dμ = lim
n→∞

n1N dμ = 0.
“ ⇐ ”
Let Nn = {f ≥1
n}, n ∈N. Then Nn ↑N and
0 =

f dμ ≥
 1
n 1Nn dμ = μ(Nn)
n
.
Hence μ(Nn) = 0 for any n ∈N and thus μ(N) = 0.
(ii) Let A = {ω : f (ω) = ∞}. For n ∈N, we have 1
nf 1{f ≥n} ≥1{f ≥n}. Hence
Lemma 4.6(i) implies
μ(A) =

1A dμ ≤

1{f ≥n} dμ ≤1
n

f 1{f ≥n} dμ ≤1
n

f dμ n→∞
−→0.
⊓⊔
Theorem 4.9 (Properties of the integral) Let f, g ∈L1(μ).
(i) (Monotonicity)
If f ≤g almost everywhere, then 3 f dμ ≤3 g dμ.
In particular, if f = g almost everywhere, then 3 f dμ = 3 g dμ.
(ii) (Triangle inequality)
 3 f dμ
 ≤3 |f | dμ.
(iii) (Linearity)
If α, β ∈R, then αf + βg ∈L1(μ) and

(αf + βg) dμ = α

f dμ + β

g dμ.
This equation also holds if at most one of the integrals
3
f dμ and
3
g dμ is
inﬁnite.
Proof
(i) Clearly, f + ≤g+ a.e., hence (f + −g+)+ = 0 a.e. By Theorem 4.8, we get
3
(f + −g+)+ dμ = 0. Since f + ≤g+ +(f + −g+)+ (not only a.e.), we infer
from Lemma 4.6(i) and (iii)

f + dμ ≤
 
g+ + (f + −g+)+
dμ =

g+ dμ.

100
4
The Integral
Similarly, we use f −≥g−a.e. to obtain

f −dμ ≥

g−dμ.
This implies

f dμ =

f + dμ −

f −dμ ≤

g+ dμ −

g−dμ =

g dμ.
(ii) Since f + + f −= |f |, Lemma 4.6(iii) yields


f dμ
 =


f + dμ −

f −dμ
 ≤

f + dμ +

f −dμ
=
 
f + + f −
dμ =

|f | dμ.
(iii) Since |αf + βg| ≤|α| · |f | + |β| · |g|, Lemma 4.6(i) and (iii) yield that
αf +βg ∈L1(μ). In order to show linearity, it is enough to check the following
three properties.
(a) 3 (f + g) dμ = 3 f dμ + 3 g dμ.
(b) 3 αf dμ = α 3 f dμ for α ≥0.
(c) 3 (−f ) dμ = −3 f dμ.
(a) We have (f + g)+ −(f + g)−= f + g = f + −f −+ g+ −g−; hence
(f + g)+ + f −+ g−= (f + g)−+ f + + g+. By Lemma 4.6(iii), we
infer

(f +g)+ dμ+

f −dμ+

g−dμ =

(f +g)−dμ+

f + dμ+

g+ dμ.
Hence

(f + g) dμ =

(f + g)+ dμ −

(f + g)−dμ
=

f + dμ −

f −dμ +

g+ dμ −

g−dμ
=

f dμ +

g dμ.
(b) For α ≥0, we have

αf dμ =

αf + dμ −

αf −dμ = α

f + dμ −α

f −dμ = α

f dμ.

4.1
Construction and Simple Properties
101
(c) We have

(−f ) dμ =

(−f )+ dμ −

(−f )−dμ
=

f −dμ −

f + dμ = −

f dμ.
The supplementary statement is simple and is left as an exercise.
⊓⊔
Theorem 4.10 (Image measure) Let (Ω, A) and (Ω′, A′) be measurable spaces,
let μ be a measure on (Ω, A) and let X : Ω →Ω′ be measurable. Let μ′ = μ◦X−1
be the image measure of μ under the map X. Assume that f : Ω′ →R is μ′-
integrable. Then f ◦X ∈L1(μ) and

(f ◦X) dμ =

f dμ ◦X−1.
In particular, if X is a random variable on (Ω, A, P), then

f (x) P[X ∈dx] :=

f (x) PX[dx] =

f dPX =

f (X(ω)) P[dω].
Proof This is left as an exercise.
⊓⊔
Example 4.11 (Discrete measure space) Let (Ω, A) be a discrete measurable space
and let μ = 
ω∈Ω
αωδω for certain numbers αω ≥0, ω ∈Ω. A map f : Ω →R is
integrable if and only if 
ω∈Ω
|f (ω)| αω < ∞. In this case,

f dμ =

ω∈Ω
f (ω) αω.
♦
Deﬁnition 4.12 (Lebesgue integral) Let λ be the Lebesgue measure on Rn and
let f : Rn →R be measurable with respect to B∗(Rn) – B(R) (here B∗(Rn) is the
Lebesgue σ-algebra; see Example 1.71) and λ-integrable. Then we call

f dλ
the Lebesgue integral of f . If A ∈B(Rn) and f : Rn →R is measurable (or
f : A →R is B∗(Rn)
A – B(R)-measurable and hence f 1A is B∗(Rn) – B(R)-
measurable), then we write

A
f dλ :=

f 1A dλ.

102
4
The Integral
Deﬁnition 4.13 Let μ be a measure on (Ω, A) and let f : Ω →[0, ∞) be a
measurable map. Deﬁne the measure ν by
ν(A) :=

(1A f ) dμ
for A ∈A.
We say that f μ := ν has density f with respect to μ.
Remark 4.14 We still have to show that ν is a measure. To this end, we check
the conditions of Theorem 1.36. Clearly, ν(∅) = 0. Finite additivity follows from
additivity of the integral (Lemma 4.6(iii)). Lower semicontinuity follows from the
monotone convergence theorem (Theorem 4.20). ♦
Theorem 4.15 We have g ∈L1(f μ) if and only if (gf ) ∈L1(μ). In this case,

g d(f μ) =

(gf ) dμ.
Proof First note that the statement holds for indicator functions. Then, with the
usual arguments, extend it step by step ﬁrst to simple functions, then to nonnegative
measurable functions and ﬁnally to signed measurable functions.
⊓⊔
Deﬁnition 4.16 For measurable f : Ω →R, deﬁne
∥f ∥p :=

|f |p dμ
1/p
,
if p ∈[1, ∞),
and
∥f ∥∞:= inf 	K ≥0 : μ({|f | > K}) = 0
.
Further, for any p ∈[1, ∞], deﬁne the vector space
Lp(μ) :=

f : Ω →R is measurable and ∥f ∥p < ∞

.
Theorem 4.17 The map ∥·∥1 is a seminorm on L1(μ); that is, for all f, g ∈L1(μ)
and α ∈R,
∥αf ∥1 = |α| · ∥f ∥1,
∥f + g∥1 ≤∥f ∥1 + ∥g∥1,
∥f ∥1 ≥0 for all f
and
∥f ∥1 = 0
if f = 0
a.e.
(4.4)
Proof The ﬁrst and the third statements follow from Theorem 4.9(iii) and Theo-
rem 4.8(i). The second statement follows from Theorem 4.9(i) since |f + g| ≤

4.1
Construction and Simple Properties
103
|f | + |g|; hence
∥f + g∥1 =

|f + g| dμ ≤

|f | dμ +

|g| dμ = ∥f ∥1 + ∥g∥1.
⊓⊔
Remark 4.18 In fact, ∥· ∥p is a seminorm on Lp(μ) for all p
∈[1, ∞].
Linearity and positivity are obvious, and the triangle inequality is a consequence
of Minkowski’s inequality, which we will show in Theorem 7.17. ♦
Theorem 4.19 Let μ(Ω) < ∞and 1 ≤p′ ≤p ≤∞. Then Lp(μ) ⊂Lp′(μ) and
the canonical inclusion i : Lp(μ) →Lp′(μ), f →f is continuous.
Proof Let f ∈L∞(μ) and p′ ∈[1, ∞). Then |f |p′ ≤∥f ∥p′
∞almost everywhere;
hence

|f |p′ dμ ≤

∥f ∥p′
∞dμ = ∥f ∥p′
∞· μ(Ω) < ∞.
Thus ∥f −g∥p′ ≤μ(Ω)1/p′∥f −g∥∞for f, g ∈L∞(μ) and hence i is continuous.
Now let p, p′ ∈[1, ∞) with p′ < p and let f ∈Lp(μ). Then |f |p′ ≤1 + |f |p;
hence

|f |p′ dμ ≤μ(Ω) +

|f |p dμ < ∞.
Finally, let f, g ∈Lp(μ). For any c > 0, we have
|f −g|p′ = |f −g|p′ 1{|f −g|≤c} + |f −g|p′ 1{|f −g|>c} ≤cp′ + cp′−p|f −g|p.
In particular, letting c = ∥f −g∥p we obtain
∥f −g∥p′ ≤

cp′μ(Ω) + cp′−p∥f −g∥p
p
1/p′
= (1 + μ(Ω))1/p′∥f −g∥p.
Hence, also in this case, i is continuous.
⊓⊔
Takeaways The integral was deﬁned ﬁrst for functions which take only
ﬁnitely many values. For more general measurable functions, the integral was
then deﬁned as the limit of integrals of approximating elementary functions.
The full procedure is rather technical and does not allow for a smooth intuitive
description. From an abstract point of view, the integral is monotone and linear
and fulﬁlls the triangle inequality, which allows to use it to deﬁne normed
vector spaces of functions.

104
4
The Integral
Exercise 4.1.1 Let f : R →R be deﬁned by f (x) = e−x1[0,∞)(x), and let λ the
Lebesgue measure on R.
(i) Find a sequence (fn) of elementary functions such that fn ↑f .
(ii) Compute
3
fn dλ and determine
3
f dλ as a limit of integrals. ♣
Exercise 4.1.2 (Sequence spaces) Now we do not assume μ(Ω) < ∞. Assume
there exists an a > 0 such that for any A ∈A either μ(A) = 0 or μ(A) ≥a. Show
that the reverse inclusion to Theorem 4.19 holds,
Lp′(μ) ⊂Lp(μ)
if 1 ≤p′ ≤p ≤∞.
(4.5)
♣
Exercise 4.1.3 Let 1 ≤p′ < p ≤∞and let μ be σ-ﬁnite but not ﬁnite. Show that
Lp(μ) \ Lp′(μ) ̸= ∅. ♣
4.2
Monotone Convergence and Fatou’s Lemma
What are the conditions that allow the interchange of limit and integral? In this
section, we derive two simple criteria that prepare us for important applications
such as the law of large numbers (Chap. 5). More general criteria will be presented
in Chap. 6.
Theorem 4.20 (Monotone convergence, Beppo Levi theorem) Let f1, f2, . . . ∈
L1(μ) and let f : Ω →R be measurable. Assume fn ↑f a.e. for n →∞. Then
lim
n→∞

fn dμ =

f dμ,
where both sides can equal +∞.
Proof Let N ⊂Ω be a null set such that fn(ω) ↑f (ω) for all ω ∈Nc. The
functions f ′
n := (fn −f1) 1Nc and f ′ := (f −f1) 1Nc are nonnegative and fulﬁll
f ′
n ↑f ′. By Lemma 4.6(ii), we have 3 f ′
n dμ
n→∞
−→3 f ′ dμ. Since fn = f ′
n + f1
a.e. and f = f ′ + f1 a.e., Theorem 4.9(iii) implies

fn dμ =

f1 dμ +

f ′
n dμ
n→∞
−→

f1 dμ +

f ′ dμ =

f dμ.
⊓⊔
Theorem 4.21 (Fatou’s lemma) Let f ∈L1(μ) and let f1, f2, . . . be measurable
with fn ≥f a.e. for all n ∈N. Then
 
lim inf
n→∞fn

dμ ≤lim inf
n→∞

fn dμ.

4.2
Monotone Convergence and Fatou’s Lemma
105
Proof By considering (fn −f )n∈N, we may assume fn ≥0 a.e. for all n ∈N.
Deﬁne
gn := inf
m≥n fm.
Then gn ↑lim inf
m→∞fm as n →∞, and hence by the monotone convergence theorem
(Lemma 4.6(ii)) and by monotonicity, gn ≤fn (thus 3 gn dμ ≤3 fn dμ),

lim inf
n→∞fn dμ = lim
n→∞

gn dμ ≤lim inf
n→∞

fn dμ.
⊓⊔
Example 4.22 (Petersburg game)
By a concrete example, we show that in Fatou’s
lemma the assumption of an integrable minorant is essential. Consider a gamble
in a casino where in each round the player’s bet either gets doubled or lost. For
example, roulette is such a game. If the player bets on “red”, she gets the stake back
doubled if the ball lands in a red pocket. Otherwise the bet is lost (for the player,
not for the casino). There are 37 pockets (in European roulettes), 18 of which are
red, 18 are black and one is green (the zero). Hence, by symmetry, the chance of
winning should be p = 18/37 < 1
2. Now assume the gamble is played again and
again. We can model this on a probability space (Ω, A, P) where Ω = {−1, 1}N,
A = (2{−1,1})⊗N is the σ-algebra generated by the cylinder sets [ω1, . . . , ωn] and
P = ((1 −p)δ−1 + pδ1)⊗N is the product measure. Denote by Dn : Ω →{−1, 1},
ω →ωn the result of the nth game (for n ∈N). If in the ith game the player makes
a (random) stake of Hi euros, then the cumulative proﬁt after the nth game is
Sn =
n

i=1
HiDi.
Now assume the gambler adopts the following doubling strategy. In the ﬁrst round,
the stake is H1 = 1. If she wins, then she does not bet any money in the subsequent
games; that is, Hn = 0 for all n ≥2 if D1 = 1. On the other hand, if she loses, then
in the second game she doubles the stake; that is, H2 = 2 if D1 = −1. If she wins
the second game, she leaves the casino and otherwise doubles the stake again and
so on. Hence we can describe the strategy by the formula
Hn =

0,
if there is an i ∈{1, . . ., n −1} with Di = 1,
2n−1,
else.
Note that Hn depends on D1, . . . , Dn−1 only. That is, it is measurable with respect
to σ(D1, . . . , Dn−1). Clearly, it is a crucial requirement for any strategy that the
decision for the next stake depend only on the information available at that time and
not depend on the future results of the gamble.

106
4
The Integral
The probability of no win until the nth game is (1−p)n; hence P[Sn = 1−2n] =
(1 −p)n and P[Sn = 1] = 1 −(1 −p)n. Hence we expect an average gain of

Sn dP = (1 −p)n(1 −2n) + (1 −(1 −p)n) = 1 −

2 (1 −p)
n ≤0
since p ≤1
2 (in the proﬁtable casinos). We deﬁne
S =

−∞,
if −1 = D1 = D2 = . . . ,
1,
else.
Then Sn
n→∞
−→
S a.s. but limn→∞
3
Sn dP <
3
S dP = 1 since S = 1 a.s.
By Fatou’s lemma, this is possible only if there is no integrable minorant for the
sequence (Sn)n∈N. If we deﬁne ˜S := inf{Sn : n ∈N}, then indeed
P
) ˜S = 1 −2n−1*
= P
)
D1 = . . . = Dn−1 = −1 and Dn = 1
*
= p(1 −p)n−1.
Hence
3 ˜S dP = ∞
n=1(1 −2n−1) p(1 −p)n−1 = −∞since p ≤1
2. ♦
Takeaways Assume we are given a pointwise convergent sequence of non-
negative functions. Then the limit (inferior) of the integrals is at least as
large as the integral of the limit (Fatou’s lemma). In the case of monotone
convergence we have equality. As an example where inequality holds, instead
of the standard example from calculus textbooks (fn = n · 1(0,1/n), f = 0),
we studied a game of hazard that we will encounter in a different context later.
Exercise 4.2.1 Let (Ω, A, μ) be a measure space and let f ∈L1(μ). Show that
for any ε > 0, there is an A ∈A with μ(A) < ∞and
3
A f dμ −
3
f dμ
 < ε. ♣
Exercise 4.2.2 Let f1, f2, . . . ∈L1(μ) be nonnegative and such that lim
n→∞
3
fn dμ
exists. Assume there exists a measurable f with fn
n→∞
−→f μ-almost everywhere.
Show that f ∈L1(μ) and
lim
n→∞
 fn −f
 dμ =
lim
n→∞

fn dμ −

f dμ.
♣
Exercise 4.2.3 Let f
∈L1([0, ∞), λ) be a Lebesgue integrable function on
[0, ∞). Show that for λ-almost all t ∈[0, ∞) the series ∞
n=1 f (nt) converges
absolutely. ♣
Exercise 4.2.4 Let λ be the Lebesgue measure on R and let A be a Borel set with
λ(A) < ∞. Show that for any ε > 0, there is a compact set C ⊂A, a closed set

4.3
Lebesgue Integral Versus Riemann Integral
107
D ⊂R \ A and a continuous map ϕ : R →[0, 1] with 1C ≤ϕ ≤1R\D and such
that ∥1A −ϕ∥1 < ε.
Hint: Use the regularity of Lebesgue measure (Remark 1.67). ♣
Exercise 4.2.5 Let λ be the Lebesgue measure on R, p ∈[1, ∞) and let f ∈
Lp(λ). Show that for any ε > 0, there is a continuous function h : R →R such that
∥f −h∥p < ε.
Hint: Use Exercise 4.2.4 to show the assertion ﬁrst for indicator functions, then for
simple functions and ﬁnally for general f ∈Lp(λ). ♣
Exercise 4.2.6 Let λ be the Lebesgue measure on R, p ∈[1, ∞) and let f ∈
Lp(λ). A map h : R →R is called a step function if there exist n ∈N and
numbers t0 < t1 < . . . < tn and α1, . . . , αn such that h = n
k=1 αk 1(tk−1,tk].
Show that for any ε > 0, there exists a step function h such that ∥f −h∥p < ε.
Hint:
Use the approximation theorem for measures (Theorem 1.65) with the
semiring of left open intervals to show the assertion ﬁrst for measurable indicator
functions. Then use the approximation arguments as in Exercise 4.2.5. ♣
4.3
Lebesgue Integral Versus Riemann Integral
We show that for Riemann integrable functions the Lebesgue integral and the
Riemann integral coincide.
Let I = [a, b] ⊂R be an interval and let λ be the Lebesgue measure on I.
Further, consider sequences t = (tn)n∈N of partitions tn = (tn
i )i=0,...,n of I (i.e.,
a = tn
0 < tn
1 < . . . < tn
n = b) that get ﬁner and ﬁner. That is,
|tn| := max{tn
i −tn
i−1 : i = 1, . . ., n}
n→∞
−→0.
Assume that for any n ∈N, the partition tn+1 is a reﬁnement of tn; that is,
	
tn
0 , . . . , tn
n

⊂
	
tn+1
0
, . . . , tn+1
n+1

.
For any function f : I →R and any n ∈N, deﬁne the nth lower sum and upper
sum, respectively, by
Lt
n(f ) :=
n

i=1
(tn
i −tn
i−1) inf f

[tn
i−1, tn
i )

,
Ut
n(f ) :=
n

i=1
(tn
i −tn
i−1) sup f

[tn
i−1, tn
i )

.
A function f : I →R is called Riemann integrable if there exists a t such that the
limits of the lower sums and upper sums are ﬁnite and coincide. In this case, the
value of the limit does not depend on the choice of t, and the Riemann integral of f

108
4
The Integral
is deﬁned as (see, e.g., [149])
 b
a
f (x) dx :=
lim
n→∞Lt
n(f ) =
lim
n→∞Ut
n(f ).
(4.6)
Theorem 4.23 (Riemann integral and Lebesgue integral) Let f : I →R be
Riemann integrable on I = [a, b]. Then f is Lebesgue integrable on I with integral

I
f dλ =
 b
a
f (x) dx.
Proof Choose t such that (4.6) holds. By assumption, there is an n ∈N with
|Lt
n(f )| < ∞and |Ut
n(f )| < ∞. Hence f is bounded. We can thus replace f
by f + ∥f ∥∞and hence assume that f ≥0. Deﬁne
gn := f (b) 1{b} +
n

i=1
(inf f ([tn
i−1, tn
i ))) 1[tn
i−1,tn
i ),
hn := f (b) 1{b} +
n

i=1
(sup f ([tn
i−1, tn
i ))) 1[tn
i−1,tn
i ).
As tn+1 is a reﬁnement of tn, we have gn ≤gn+1 ≤hn+1 ≤hn. Hence there exist
g and h with gn ↑g and hn ↓h. By construction, we have g ≤h and

I
g dλ = lim
n→∞

I
gn dλ = lim
n→∞Lt
n(f )
= lim
n→∞Ut
n(f ) = lim
n→∞

I
hn dλ =

I
h dλ.
Hence h = g λ-a.e. By construction, g ≤f ≤h, and as limits of simple functions,
g and h are B(I) – B(R)-measurable. This implies that, for any α ∈R, the set
{f ≤α} =

{g ≤α} ∩{g = h}

⊎

{f ≤α} ∩{g ̸= h}

is the union of a B(I)-set with a subset of a null set and is hence in B(I)∗(the
Lebesgue completion of B(I)). Hence f is B(I)∗-measurable. By the monotone
convergence theorem (Theorem 4.20), we conclude

I
f dλ = lim
n→∞

I
gn dλ =
 b
a
f (x) dx.
⊓⊔

4.3
Lebesgue Integral Versus Riemann Integral
109
Example 4.24 Let f : [0, 1] →R, x →1Q. Then clearly f is not Riemann
integrable since Ln(f ) = 0 and Un(f ) = 1 for all n ∈N. On the other hand, f is
Lebesgue integrable with integral
3
[0,1] f dλ = 0 because Q ∩[0, 1] is a null set. ♦
Remark 4.25 An improperly Riemann integrable function f on a one-sided open
interval I = (a, b] or I = [0, ∞) is not necessarily Lebesgue integrable. Indeed,
the improper integral
3 ∞
0
f (x) dx := limn→∞
3 n
0 f (x) dx is deﬁned by a limit
procedure that respects the geometry of R. The Lebesgue integral does not do that.
For example, the function f : [0, ∞) →R, x →
1
1+x sin(x) is improperly Riemann
integrable but is not Lebesgue integrable since
3
[0,∞) |f | dλ = ∞. ♦
Reﬂection Consider the function f (x) = 1/x, x ∈[−1, 1] \ {0}, f (0) = 0.
Cauchy’s principal value of the integral
3 1
−1 f (x)dx is deﬁned as
lim
n→∞
 −1/n
−1
1
x dx +
 1
1/n
1
x dx

= 0.
Why is this kind of limit incompatible with the concept of the Lebesgue integral? ♠
On the one hand, improperly Riemann integrable functions need not be Lebesgue
integrable. On the other hand, there are Lebesgue integrable functions that are not
Riemann integrable (such as 1Q). The geometric interpretation is that the Riemann
integral respects the geometry of the integration domain by being deﬁned via
slimmer and slimmer vertical rectangles (Fig. 4.1). On the other hand, the Lebesgue
integral respects the geometry of the range by being deﬁned via slimmer and
slimmer horizontal strips. In particular, the Lebesgue integral does not make any
assumption on the geometry of the domain and is thus more universal than the
Riemann integral. In order to underline this, we present the following theorem that
will also be useful later.
Fig. 4.1 For the Riemann integral, the area under the curve is approximated by rectangles of a
ﬁxed breadth (left hand side). The Lebesgue integral approximates the area by the measure of the
levels sets (right hand side).

110
4
The Integral
Theorem 4.26 Let f : Ω →R be measurable and f ≥0 almost everywhere.
Then
∞

n=1
μ({f ≥n}) ≤

f dμ ≤
∞

n=0
μ({f > n})
(4.7)
and

f dμ =
 ∞
0
μ({f ≥t}) dt.
(4.8)
Proof Deﬁne f ′ = ⌊f ⌋and f ′′ = ⌈f ⌉. Then f ′ ≤f ≤f ′′ and hence
3
f ′ dμ ≤
3
f dμ ≤
3
f ′′ dμ. Now the ﬁrst inequality of (4.7) follows from

f ′ dμ =
∞

k=1
μ({f ′ = k}) · k =
∞

k=1
k

n=1
μ({f ′ = k})
=
∞

n=1
∞

k=n
μ({f ′ = k})
=
∞

n=1
μ({f ′ ≥n}) =
∞

n=1
μ({f ≥n}).
Similarly, we infer the second inequality in (4.7) from

f ′′ dμ =
∞

n=1
μ({f ′′ ≥n}) =
∞

n=1
μ({f > n −1}).
If g(t) := μ({f ≥t}) = ∞for some t > 0, then both sides in (4.8) equal ∞.
Hence, in the following, assume g(t) < ∞for all t > 0.
For ε > 0 and k ∈N, deﬁne gε := g ∧g(ε), f ε := f 1{f ≥ε} and f ε
k = 2kf ε as
well as
αε
k := 2−k
∞

n=1
μ({f ε ≥n2−k}).
Then αε
k
k→∞
−→
3 ∞
0
gε(t) dt. Furthermore, by (4.7) (with f replaced by f ε
k ), we
have
αε
k = 2−k
∞

n=1
μ({f ε
k ≥n}) ≤

f ε dμ
≤2−k
∞

n=0
μ({f ε
k > n}) = 2−k
∞

n=0
μ({f ε > n2−k}) ≤αε
k + 2−k g(ε).

4.3
Lebesgue Integral Versus Riemann Integral
111
Since 2−k g(ε)
k→∞
−→0, we get
3 ∞
0
gε(t) dt =
3
f ε dμ. Since f ε ↑f and gε ↑g
for ε ↓0, the monotone convergence theorem implies (4.8).
⊓⊔
Takeaways A Riemann integrable function on a compact interval is
Lebesgue integrable and the integrals coincide. For nonnegative functions, the
Lebesgue integral can be computed via a kind of partial integration formula
(Theorem 4.26).
Exercise 4.3.1 Use Theorem 4.26 to compute
3 1
0 log(x) dx and
3 π
0 sin(x) dx. ♣
Exercise 4.3.2 Let f : [0, 1] →R be bounded. Show that f is (properly) Riemann
integrable if and only if f is λ-a.e. continuous. ♣
Exercise 4.3.3 If f : [0, 1] →R is Riemann integrable, then f is Lebesgue
measurable. Give an example that shows that f need not be Borel measurable. (Hint:
Without proof, use the existence of a subset of [0, 1] that is not Borel measurable.
Based on this, construct a set that is not Borel and whose closure is a null set.) ♣
Exercise 4.3.4 Let f : [0, 1] →(0, ∞) be Riemann integrable. Without using
the equivalence of the Lebesgue integral and the Riemann integral, show that
3 1
0 f (x) dx > 0. ♣

Chapter 5
Moments and Laws of Large Numbers
The most important characteristic quantities of random variables are the median,
expectation and variance. For large n, the expectation describes the typical approxi-
mate value of the arithmetic mean (X1 +. . .+Xn)/n of i.i.d. random variables (law
of large numbers). In Chap. 15, we will see how the variance determines the size of
the typical deviations of the arithmetic mean from the expectation.
5.1
Moments
In the following, let (Ω, A, P) be a probability space.
Deﬁnition 5.1 Let X be a real-valued random variable.
(i) If X ∈L1(P), then X is called integrable and we call
E[X] :=

X dP
the expectation or mean of X. If E[X] = 0, then X is called centered. More
generally, we also write E[X] =
3
X dP if only X−or X+ is integrable.
(ii) If n ∈N and X ∈Ln(P), then the quantities
mk := E
'
Xk(
,
Mk := E
'
|X|k(
for any k = 1, . . . , n,
are called the kth moments and kth absolute moments, respectively, of X.
(iii) If X ∈L2(P), then X is called square integrable and
Var[X] := E
'
X2(
−E[X]2
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_5
113

114
5
Moments and Laws of Large Numbers
is the variance of X. The number σ :=
√
Var[X] is called the standard
deviation of X. Formally, we sometimes write Var[X] = ∞if E[X2] = ∞.
(iv) If X, Y ∈L2(P), then we deﬁne the covariance of X and Y by
Cov[X, Y] := E
)
X −E[X]

Y −E[Y]
*
.
X and Y are called uncorrelated if Cov[X, Y] = 0 and correlated otherwise.
Remark 5.2
(i) The deﬁnition in (ii) is sensible since, by virtue of Theorem 4.19, X ∈Ln(P)
implies that Mk < ∞for all k = 1, . . . , n.
(ii) If X, Y ∈L2(P), then XY ∈L1(P) since |XY| ≤X2 + Y 2. Hence the
deﬁnition in (iv) makes sense and we have
Cov[X, Y] = E[XY] −E[X] E[Y].
In particular, Var[X] = Cov[X, X]. ♦
We collect the most important rules of expectations in a theorem. All of these
properties are direct consequences of the corresponding properties of the integral.
Theorem 5.3 (Rules for expectations) Let X, Y, Xn, Zn, n ∈N, be real integrable
random variables on (Ω, A, P).
(i) If PX = PY , then E[X] = E[Y].
(ii) (Linearity) Let c ∈R. Then cX ∈L1(P) and X + Y ∈L1(P) as well as
E[cX] = c E[X]
and
E[X + Y] = E[X] + E[Y].
(iii) If X ≥0 almost surely, then
E[X] = 0
⇐⇒
X = 0
almost surely.
(iv) (Monotonicity) If X ≤Y almost surely, then E[X] ≤E[Y] with equality if and
only if X = Y almost surely.
(v) (Triangle inequality)
E[X]
 ≤E)|X|*.
(vi) If Xn ≥0 almost surely for all n ∈N, then E
' ∞

n=1
Xn
(
=
∞

n=1
E[Xn].
(vii) If Zn ↑Z for some Z, then E[Z] = limn→∞E[Zn] ∈(−∞, ∞].
Again probability theory comes into play when independence enters the stage; that
is, when we exit the realm of linear integration theory.
Theorem 5.4 (Independent L(P)-random variables are uncorrelated) Let
X, Y ∈L1(P) be independent. Then (X Y) ∈L1(P) and E[XY] = E[X] E[Y].
In particular, independent square integrable random variables are uncorrelated.

5.1
Moments
115
Proof Assume ﬁrst that X and Y take only ﬁnitely many values. Then XY also
takes only ﬁnitely many values and thus XY ∈L1(P). It follows that
E[XY] =

z∈R\{0}
z P[XY = z]
=

z∈R\{0}

x∈R\{0}
x z
x P[X = x, Y = z/x]
=

y∈R\{0}

x∈R\{0}
xy P[X = x] P[Y = y]
=
 
x∈R
x P[X = x]
 
y∈R
y P[Y = y]

= E[X] E[Y].
For N ∈N, the random variables XN
:=

2−N4
2N|X|
5
∧N and YN
:=

2−N4
2N|Y|
5
∧N take only ﬁnitely many values and are independent as well.
Furthermore, XN ↑|X| and YN ↑|Y|. By the monotone convergence theorem
(Theorem 4.20), we infer
E[|XY|] = lim
N→∞E[XNYN] = lim
N→∞E[XN] E[YN]
=

lim
N→∞E[XN]
 
lim
N→∞E[YN]

= E[|X|] E[|Y|] < ∞.
Hence XY ∈L1(P). Furthermore, we have shown the claim in the case where X
and Y are nonnegative. Hence (and since each of the families {X+, Y +}, {X−, Y +},
{X+, Y −} and {X−, Y −} is independent) we obtain
E[XY] = E[(X+ −X−)(Y + −Y −)]
= E[X+Y +] −E[X−Y +] −E[X+Y −] + E[X−Y −]
= E[X+] E[Y +] −E[X−] E[Y +] −E[X+] E[Y −] + E[X−] E[Y −]
= E[X+ −X−] E[Y + −Y −] = E[X] E[Y].
⊓⊔
Theorem 5.5 (Wald’s identity) Let T, X1, X2, . . . be independent real random
variables in L1(P). Let P[T ∈N0] = 1 and assume that X1, X2, . . . are identically
distributed. Deﬁne
ST :=
T

i=1
Xi.
Then ST ∈L1(P) and E[ST ] = E[T ] E[X1].

116
5
Moments and Laws of Large Numbers
Proof Deﬁne Sn = n
i=1 Xi for n ∈N0. Then ST
= ∞
n=1 Sn 1{T =n}. By
Remark 2.15, the random variables Sn and 1{T =n} are independent for any n ∈N and
thus uncorrelated. This implies (using the triangle inequality; see Theorem 5.3(v))
E
)
|ST |
*
=
∞

n=1
E
)
|Sn| 1{T =n}
*
=
∞

n=1
E
)
|Sn|
*
E
)
1{T =n}
*
≤
∞

n=1
E
)
|X1|
*
n P[T = n] = E[|X1|] E[T ].
The same computation without absolute values yields the remaining part of the
claim.
⊓⊔
We collect some basic properties of the variance.
Theorem 5.6 Let X ∈L2(P). Then:
(i) Var[X] = E
)
(X −E[X])2*
≥0.
(ii) Var[X] = 0 ⇐⇒X = E[X] almost surely.
(iii) The map f : R →R, x →E
)
(X −x)2*
is minimal at x0 = E[X] with
f (E[X]) = Var[X].
Proof
(i) This is a direct consequence of Remark 5.2(ii).
(ii) By Theorem 5.3(iii), we have E)(X −E[X])2* = 0 ⇐⇒(X −E[X])2 = 0
a.s.
(iii) Clearly, f (x) = E[X2] −2x E[X] + x2 = Var[X] + (x −E[X])2.
⊓⊔
Theorem 5.7 The map Cov : L2(P) × L2(P) →R is a positive semideﬁnite
symmetric bilinear form and Cov[X, Y] = 0 if Y is almost surely constant. The
detailed version of this concise statement is: Let X1, . . ., Xm, Y1, . . ., Yn ∈L2(P)
and α1, . . . , αm, β1, . . . , βn ∈R as well as d, e ∈R. Then
Cov
⎡
⎣d +
m

i=1
αiXi, e +
n

j=1
βjYj
⎤
⎦=

i,j
αiβj Cov[Xi, Yj].
(5.1)
In particular, Var[αX] = α2Var[X] and the Bienaymé formula holds,
Var
- m

i=1
Xi
.
=
m

i=1
Var[Xi] +
m

i,j=1
i̸=j
Cov[Xi, Xj].
(5.2)
For uncorrelated X1, . . . , Xm, we have Var
)m
i=1 Xi
*
= m
i=1 Var[Xi].

5.1
Moments
117
Proof
Cov
+
d +
m

i=1
αi Xi, e +
n

j=1
βj Yj
,
= E
+ m

i=1
αi(Xi −E[Xi])

n

j=1
βj(Yj −E[Yj])
,
=
m

i=1
n

j=1
αiβj E)(Xi −E[Xi])(Yj −E[Yj])*
=
m

i=1
n

j=1
αiβj Cov[Xi, Yj].
⊓⊔
Theorem 5.8 (Cauchy–Schwarz inequality) If X, Y ∈L2(P), then

Cov[X, Y]
2 ≤Var[X] Var[Y].
Equality holds if and only if there are a, b, c ∈R with |a| + |b| + |c| > 0 and such
that aX + bY + c = 0 a.s.
Proof The Cauchy–Schwarz inequality holds for any positive semideﬁnite bilinear
form and hence in particular for the covariance map. Using the notation of variance
and covariance, a simple proof looks like this:
Case 1:
Var[Y] = 0. Here the statement is trivial (choose a = 0, b = 1 and
c = −E[Y]).
Case 2:
Var[Y] > 0. Let θ := −Cov[X,Y]
Var[Y] . Then, by Theorem 5.6(i),
0 ≤Var[X + θY] Var[Y] =

Var[X] + 2θ Cov[X, Y] + θ2 Var[Y]

Var[Y]
= Var[X] Var[Y] −Cov[X, Y]2
with equality if and only if X + θY is a.s. constant. Now let a = 1, b = θ and
c = −E[X] −b E[Y].
⊓⊔
Example 5.9
(i) Let p ∈[0, 1] and X ∼Berp. Then
E[X2] = E[X] = P[X = 1] = p
and thus Var[X] = p(1 −p).

118
5
Moments and Laws of Large Numbers
(ii) Let n ∈N and p ∈[0, 1]. Let X be binomially distributed, X ∼bn,p. Then
E[X] =
n

k=0
kP[X = k] =
n

k=0
k
n
k

pk (1 −p)n−k
= np ·
n

k=1
n −1
k −1

pk−1 (1 −p)(n−1)−(k−1) = np.
Furthermore,
E[X(X −1)] =
n

k=0
k(k −1) P[X = k]
=
n

k=0
k(k −1)
n
k

pk (1 −p)n−k
= np ·
n

k=1
(k −1)
n −1
k −1

pk−1 (1 −p)(n−1)−(k−1)
= n(n −1)p2 ·
n

k=2
n −2
k −2

pk−2 (1 −p)(n−2)−(k−2)
= n(n −1)p2.
Hence E[X2] = E[X(X−1)]+E[X] = n2p2 +np(1−p) and thus Var[X] =
np(1 −p).
The statement can be derived more simply than by direct computation if
we make use of the fact that bn,p = b∗n
1,p (see Example 3.4(ii)). That is (see
Theorem 2.31), PX = PY1+...+Yn, where Y1, . . . , Yn are independent and Yi ∼
Berp for any i = 1, . . . , n. Hence
E[X] = nE[Y1] = np,
Var[X] = nVar[Y1] = np(1 −p).
(5.3)

5.1
Moments
119
(iii) Let μ ∈R and σ 2 > 0, and let X be normally distributed, X ∼Nμ,σ 2. Then
E[X] =
1
√
2πσ 2
 ∞
−∞
x e−(x−μ)2/(2σ 2) dx
=
1
√
2πσ 2
 ∞
−∞
(x + μ) e−x2/(2σ 2) dx
= μ +
1
√
2πσ 2
 ∞
−∞
x e−x2/(2σ 2) dx = μ.
(5.4)
Similarly, we get Var[X] = E[X2] −μ2 = . . . = σ 2.
(iv) Let θ > 0 and let X be exponentially distributed, X ∼expθ. Then
E[X] = θ
 ∞
0
x e−θx dx = 1
θ ,
Var[X] = −θ−2 + θ
 ∞
0
x2 e−θx dx = θ−2

−1 +
 ∞
0
x2 e−x dx

= θ−2.
♦
(5.5)
Theorem 5.10 (Blackwell–Girshick) Let T, X1, X2, . . . be independent real ran-
dom variables in L2(P). Let P[T ∈N0] = 1 and let X1, X2, . . . be identically
distributed. Deﬁne
ST :=
T

i=1
Xi.
Then ST ∈L2(P) and
Var[ST ] = E[X1]2 Var[T ] + E[T ] Var[X1].
Proof Deﬁne Sn = n
i=1 Xi for n ∈N. Then (as in the proof of Wald’s identity)
Sn and 1{T =n} are independent; hence S2
n and 1{T =n} are uncorrelated and thus
E
'
S2
T
(
=
∞

n=0
E
'
1{T =n} S2
n
(
=
∞

n=0
E[1{T =n}] E
'
S2
n
(
=
∞

n=0
P[T = n]

Var[Sn] + E[Sn]2

120
5
Moments and Laws of Large Numbers
=
∞

n=0
P[T = n]

n Var[X1] + n2 E[X1]2
= E[T ] Var[X1] + E)T 2* E[X1]2.
By Wald’s identity (Theorem 5.5), we have E[ST ] = E[T ] E[X1]; hence
Var[ST ] = E
'
S2
T
(
−E[ST ]2 = E[T ] Var[X1] +

E
)
T 2*
−E[T ]2
E[X1]2,
as claimed.
⊓⊔
Reﬂection In the proof of Theorem 5.10, where did we use the independence of
T ? Check that if E[Xi] = 0 for all i ∈N, then instead of independence of T , it is
enough to postulate: {T ≤n} is independent of Xn+1, Xn+2, . . . for all n. ♠♠
Takeaways Moments are important characteristics of probability distribu-
tions. We have seen a formula for the ﬁrst and second moment of a sum
of random variables, even if the number of summands is random itself.
Independent random variables are uncorrelated. In this case, the formulas for
the second moments of sums are particularly simple.
Exercise 5.1.1 Let X be a nonnegative random variable with ﬁnite second moment.
Use the Cauchy-Schwarz inequality for X and 1{X>0} in order to show the Paley-
Zygmund inequality
P[X > 0] ≥E[X]2
E[X2].
♣
Exercise 5.1.2 Let X be an integrable real random variable whose distribution
PX has a density f (with respect to the Lebesgue measure λ). Show (using
Theorem 4.15) that
E[X] =

R
xf (x) λ(dx).
♣
Exercise 5.1.3 Let X ∼βr,s be a Beta-distributed random variable with parameters
r, s > 0 (see Example 1.107(ii)). Show that
E[Xn] =
n−1

k=0
r + k
r + s + k
for any n ∈N.
♣

5.2
Weak Law of Large Numbers
121
Exercise 5.1.4 Let X1, X2, . . . be i.i.d. nonnegative random variables. By virtue of
the Borel–Cantelli lemma, show that
lim sup
n→∞
1
nXn =

0 a.s.,
if E[X1] < ∞,
∞a.s.,
if E[X1] = ∞.
♣
Exercise 5.1.5 Let X1, X2, . . . be i.i.d. nonnegative random variables. By virtue of
the Borel–Cantelli lemma, show that for any c ∈(0, 1)
∞

n=1
eXn cn

< ∞a.s.,
if E[X1] < ∞,
= ∞a.s.,
if E[X1] = ∞.
♣
5.2
Weak Law of Large Numbers
Theorem 5.11 (Markov inequality, Chebyshev inequality) Let X be a real
random variable and let f : [0, ∞) →[0, ∞) be monotone increasing. Then for
any ε > 0 with f (ε) > 0, the Markov inequality holds,
P
)
|X| ≥ε
*
≤E[f (|X|)]
f (ε)
.
In the special case f (x) = x2, we get P)|X| ≥ε* ≤ε−2 E)X2*. In particular, if
X ∈L2(P), the Chebyshev inequality holds:
P
)
|X −E[X]| ≥ε
*
≤ε−2 Var[X].
Proof We have
E[f (|X|)] ≥E)f (|X|) 1{f (|X|)≥f(ε)}
*
≥E)f (ε) 1{f (|X|)≥f(ε)}
*
≥f (ε) P)|X| ≥ε*.
⊓⊔
Deﬁnition 5.12 Let (Xn)n∈N be a sequence of real random variables in L1(P) and
let Sn = n
i=1(Xi −E[Xi]).
(i) We say that (Xn)n∈N fulﬁlls the weak law of large numbers if
lim
n→∞P
+
1
n
Sn
 > ε
,
= 0
for any ε > 0.

122
5
Moments and Laws of Large Numbers
(ii) We say that (Xn)n∈N fulﬁlls the strong law of large numbers if
P
+
lim sup
n→∞

1
n
Sn
 = 0
,
= 1.
Remark 5.13 The strong law of large numbers implies the weak law. Indeed, if
Aε
n :=
 1
nSn
 > ε

and A =

lim sup
n→∞
 1
nSn
 > 0

, then clearly
A =

m∈N
lim sup
n→∞
A1/m
n
;
hence P
'
lim sup
n→∞
Aε
n
(
= 0 for ε > 0. By Fatou’s lemma (Theorem 4.21), we obtain
lim sup
n→∞
P )Aε
n
* = 1 −lim inf
n→∞E )1(Aεn)c*
≤1 −E
'
lim inf
n→∞1(Aεn)c
(
= E
+
lim sup
n→∞
1Aεn
,
= 0.
♦
Theorem 5.14 Let X1, X2, . . . be uncorrelated random variables in L2(P) with
V := supn∈N Var[Xn] < ∞. Then (Xn)n∈N fulﬁlls the weak law of large numbers.
More precisely, for any ε > 0, we have
P
+
1
n
Sn
 ≥ε
,
≤V
ε2n
for all n ∈N.
(5.6)
Reﬂection Let Sn be the sum of the numbers shown when rolling a die n-times.
Then Sn/n should be close to 3.5 for large n - but close in which sense? The
weak law of large numbers states that the distribution of Sn/n is concentrated in
the vicinity of 3.5 (Fig. 5.1). On the other, the strong law of large numbers claims
that for ﬁxed ω, we have Sn(ω)/n
n→∞
−→3.5 (Fig. 5.2).♠
Proof Without loss of generality, assume E[Xi] = 0 for all i ∈N and thus Sn =
X1 + · · · + Xn. By Bienaymé’s formula (Theorem 5.7), we obtain
Var
+1
n
Sn
,
= n−2
n

i=1
Var [Xi] ≤V
n .
By Chebyshev’s inequality (Theorem 5.11), for any ε > 0,
P
)
|Sn/n| ≥ε
*
≤
V
ε2 n
n→∞
−→0.
⊓⊔

5.2
Weak Law of Large Numbers
123
3.3 3.33
3.37 3.4 3.43
3.47 3.5 3.53
3.57 3.6 3.63
3.67 3.7
0.00
0.05
0.10
0.15
0.20
0.25
3.3 3.33
3.37 3.4 3.43
3.47 3.5 3.53
3.57 3.6 3.63
3.67 3.7
0.00
0.05
0.10
0.15
0.20
0.25
Fig. 5.1 Rolling a die n times: Probabilities for Sn/n. Left hand side: n = 1000, Right hand side
n = 10 000. The bars show the probabilities for values in [x, x + 0.01), 3.3 ≤x ≤3.7.
0
2000
4000
6000
8000
10000
3.2
3.3
3.4
3.5
3.6
Fig. 5.2 Rolling a die n times: For a ﬁxed realisation, the values of Sn/n converge to 3.5. We have
n on the horizontal axis.
Example 5.15 (Weierstraß’s approximation theorem) Let f : [0, 1] →R be a
continuous map. By Weierstraß’s approximation theorem, there exist polynomials
fn of degree at most n such that
∥fn −f ∥∞
n→∞
−→0,
where ∥f ∥∞:= sup{|f (x)| : x ∈[0, 1]} denotes the supremum norm of f ∈
C([0, 1]) (the space of continuous functions [0, 1] →R).

124
5
Moments and Laws of Large Numbers
We present a probabilistic proof of this theorem. For n ∈N, deﬁne the
polynomial fn by
fn(x) :=
n

k=0
f (k/n)
n
k

xk (1 −x)n−k
for x ∈[0, 1].
fn is called the Bernstein polynomial of order n.
Fix ε > 0. As f is continuous on the compact interval [0, 1], f is uniformly
continuous. Hence there exists a δ > 0 such that
|f (x) −f (y)| < ε
for all x, y ∈[0, 1] with |x −y| < δ.
Now ﬁx p ∈[0, 1] and let X1, X2, . . . be independent random variables with Xi ∼
Berp, i ∈N. Then Sn := X1 + . . . + Xn ∼bn,p and thus
E[f (Sn/n)] =
n

k=0
f (k/n) P[Sn = k] = fn(p).
We get
|f (Sn/n) −f (p)| ≤ε + 2∥f ∥∞1{|(Sn/n)−p|≥δ}
and thus (by Theorem 5.14 with V = p(1 −p) ≤1
4)
|fn(p) −f (p)| ≤E[|f (Sn/n) −f (p)|]
≤ε + 2∥f ∥∞P
+
Sn
n −p
 ≥δ
,
≤ε + ∥f ∥∞
2 δ2 n
for any p ∈[0, 1]. Hence ∥fn −f ∥∞
n→∞
−→0. ♦
Takeaways Laws of large numbers show that sums of very many random
variables approach their expected value. One can use second moments and
Chebyshev’s inequality to establish a weak law of large numbers.
Exercise 5.2.1 (Bernstein–Chernov bound) Let n ∈N and p1, . . . , pn ∈[0, 1].
Let X1, . . . , Xn be independent random variables with Xi = Berpi for any i =
1, . . . , n. Deﬁne Sn = X1 + . . . + Xn and m := E[Sn]. Show that, for any δ > 0,
the following two estimates hold:
P
)
Sn ≥(1 + δ)m
*
≤

eδ
(1 + δ)1+δ
m

5.3
Strong Law of Large Numbers
125
and
P
)
Sn ≤(1 −δ)m
*
≤exp

−δ2 m
2

.
Hint: For Sn, use Markov’s inequality with f (x) = eλx for some λ > 0 and then
ﬁnd the λ that optimizes the bound. ♣
5.3
Strong Law of Large Numbers
We show Etemadi’s version [47] of the strong law of large numbers for identically
distributed, pairwise independent random variables. There is a zoo of strong laws
of large numbers, each of which varies in the exact assumptions it makes on the
underlying sequence of random variables. For example, the assumption that the
random variables be identically distributed can be waived if other assumptions are
introduced such as bounded variances. We do not strive for completeness but show
only a few of the statements.
In order to illustrate the method of the proof of Etemadi’s theorem, we ﬁrst
present (and prove) a strong law of large numbers under stronger assumptions.
Theorem 5.16 Let X1, X2, . . . ∈L2(P) be pairwise independent (that is, Xi and
Xj are independent for all i, j ∈N with i ̸= j) and identically distributed. Then
(Xn)n∈N fulﬁlls the strong law of large numbers.
Proof The random variables (X+
n )n∈N and (X−
n )n∈N again form pairwise indepen-
dent families of square integrable random variables (compare Remark 2.15(ii)).
Hence, it is enough to consider (X+
n )n∈N. Thus we henceforth assume Xn ≥0
almost surely for all n ∈N.
Let Sn = X1 + . . . + Xn for n ∈N. Fix ε > 0. For any n ∈N, deﬁne kn =
⌊(1 + ε)n⌋≥1
2(1 + ε)n. Then, by Chebyshev’s inequality (Theorem 5.11),
∞

n=1
P
+
Skn
kn
−E[X1]
 ≥(1 + ε)−n/4
,
≤
∞

n=1
(1 + ε)n/2 Var
'
k−1
n Skn
(
=
∞

n=1
(1 + ε)n/2 k−1
n
Var[X1]
≤2 Var[X1]
∞

n=1
(1 + ε)−n/2 < ∞.
(5.7)

126
5
Moments and Laws of Large Numbers
Thus, by the Borel–Cantelli lemma, for P-a.a. ω, there is an n0 = n0(ω) such that

Skn
kn
−E[X1]
 < (1 + ε)−n/4
for all n ≥n0,
whence
lim sup
n→∞
k−1
n Skn −E[X1]
 = 0
almost surely.
Note that kn+1 ≤(1 + 2ε)kn for sufﬁciently large n ∈N. For l ∈{kn, . . . , kn+1},
we get
1
1 + 2ε k−1
n
Skn ≤k−1
n+1 Skn ≤l−1 Sl ≤k−1
n
Skn+1 ≤(1 + 2ε) k−1
n+1 Skn+1.
Now 1 −(1 + 2ε)−1 ≤2ε implies
lim sup
l→∞
l−1Sl −E[X1]
 ≤lim sup
n→∞
k−1
n Skn −E[X1]
 + 2ε lim sup
n→∞
k−1
n Skn
≤2ε E[X1]
almost surely.
Hence the strong law of large numbers is in force.
⊓⊔
Reﬂection The proof of the previous theorem made use of the fact that (X+
n )n∈N
and (X−
n )n∈N are uncorrelated families. Why is it not enough to assume in the
theorem that (Xn)n∈N be uncorrelated (instead of pairwise independent)? ♠
The similarity of the variance estimates in the weak law of large numbers and in
(5.7) suggests that in the preceding theorem the condition that the random variables
X1, X2, . . . be identically distributed could be replaced by the condition that the
variances be bounded (see Exercise 5.3.1).
We can weaken the condition in Theorem 5.16 in a different direction by
requiring integrability only instead of square integrability of the random variables.
Theorem 5.17 (Etemadi’s strong law of large numbers (1981)) Let X1, X2, . . .
∈L1(P) be pairwise independent and identically distributed. Then (Xn)n∈N fulﬁlls
the strong law of large numbers.
We follow the proof in [39, Section 2.4]. Deﬁne μ = E[X1] and Sn = X1+. . .+Xn.
We start with some preparatory lemmas. (For the “a.s.” notation see Deﬁnition 1.68.)
Lemma 5.18 For n ∈N, deﬁne Yn := Xn 1{|Xn|≤n} and Tn = Y1 + · · · + Yn. The
sequence (Xn)n∈N fulﬁlls the strong law of large numbers if Tn/n
n→∞
−→μ a.s.

5.3
Strong Law of Large Numbers
127
Proof By Theorem 4.26, we have
∞

n=1
P)|Xn| > n* ≤E)|X1|* < ∞. Thus, by the
Borel–Cantelli lemma,
P
)
Xn ̸= Yn for inﬁnitely many n
*
= 0.
Hence there is an n0 = n0(ω) with Xn = Yn for all n ≥n0, whence for n ≥n0
Tn −Sn
n
= Tn0 −Sn0
n
n→∞
−→0.
⊓⊔
Lemma 5.19 2x

n>x
n−2 ≤4 for all x ≥0.
Proof For m ∈N, by comparison with the corresponding integral, we get
∞

n=m
n−2 ≤m−2 +
 ∞
m
t−2 dt = m−2 + m−1 ≤2
m.
⊓⊔
Lemma 5.20
∞

n=1
E
)
Y 2
n
*
n2
≤4 E[|X1|].
Proof By Theorem 4.26, E
)
Y 2
n
*
=
3 ∞
0
P
)
Y 2
n > t
*
dt. Substituting x = √t, we
obtain
E
'
Y 2
n
(
=
 ∞
0
2x P[|Yn| > x] dx ≤
 n
0
2x P[|X1| > x] dx.
By Lemma 5.19, for m →∞,
fm(x) =
 m

n=1
n−2 1{x<n}

2x P[|X1| > x] ↑f (x) ≤4 P[|X1| > x].
Hence, by the monotone limit theorem, we can interchange the summation and the
integral and obtain
∞

n=1
E
)
Y 2
n
*
n2
≤
∞

n=1
n−2
 ∞
0
1{x<n} 2x P[|X1| > x] dx
=
 ∞
0
 ∞

n=1
n−2 1{x<n}

2x P[|X1| > x] dx
≤4
 ∞
0
P[|X1| > x] dx = 4 E[|X1|].
⊓⊔

128
5
Moments and Laws of Large Numbers
Proof of Theorem 5.17 As in the proof of Theorem 5.16, it is enough to consider
the case Xn ≥0. Fix ε > 0 and let α = 1 + ε. For n ∈N, deﬁne kn = ⌊αn⌋. Note
that kn ≥αn/2. Hence, for all m ∈N (with n0 = ⌈log m/ log α⌉),

n: kn≥m
k−2
n
≤4
∞

n=n0
α−2n = 4 α−2n0(1 −α−2)−1 ≤4(1 −α−2)−1 m−2.
(5.8)
The aim is to employ Lemma 5.20 to reﬁne the estimate (5.7) for (Yn)n∈N and
(Tn)n∈N. For δ > 0, Chebyshev’s inequality yields (together with (5.8))
∞

n=1
P
)Tkn −E
)
Tkn
* > δ kn
*
≤δ−2
∞

n=1
Var
)
Tkn
*
k2n
= δ−2
∞

n=1
k−2
n
kn

m=1
Var[Ym] = δ−2
∞

m=1
Var[Ym]

n: kn≥m
k−2
n
≤4(1 −α−2)−1 δ−2
∞

m=1
m−2 E
)
Y 2
m
*
< ∞by Lemma 5.20.
(In the third step, we could change the order of summation since all summands are
nonnegative.) Letting δ ↓0, we infer by the Borel–Cantelli lemma
lim
n→∞
Tkn −E )Tkn
*
kn
= 0
almost surely.
(5.9)
By the monotone convergence theorem (Theorem 4.20), we have
E[Yn] = E)X1 1{X1≤n}
*
n→∞
−→
E[X1].
Hence E[Tkn]/kn
n→∞
−→E[X1]. By (5.9), we also have Tkn/kn
n→∞
−→E[X1] a.s. As
in the proof of Theorem 5.16, we also get (since Yn ≥0)
lim
l→∞
Tl
l
= E[X1]
almost surely.
By Lemma 5.18, this implies the claim of Theorem 5.17.
⊓⊔
Reﬂection In Etemadi’s theorem, we assumed that the random variables
X1, X2, . . . are identically distributed. Come up with an example that shows that
this condition cannot simply be dropped. ♠♠
Example 5.21 (Monte Carlo integration) Let f : [0, 1] →R be a function and
assume we want to determine the value of its integral I :=
3 1
0 f (x) dx numerically.

5.3
Strong Law of Large Numbers
129
Assume that the computer generates numbers X1, X2, . . . that can be considered as
independent random numbers, uniformly distributed on [0, 1]. For n ∈N, deﬁne the
estimated value
:In := 1
n
n

i=1
f (Xi).
Assuming f ∈L1([0, 1]), the strong law of large numbers yields :In
n→∞
−→I a.s.
Note that the last theorem made no statement on the speed of convergence. That
is, we do not have control on the quantity P[|:In −I| > ε]. In order to get more
precise estimates for the integral, we need additional information; for example, the
value V1 :=
3
f 2(x) dx −I 2 if f ∈L2([0, 1]). (For bounded f , V1 can easily be
bounded.) Indeed, in this case, Var[:In] = V1/n; hence, by Chebyshev’s inequality,
P
'
|:In −I| > ε n−1/2(
≤V1/ε2.
Hence the error is at most of order n−1/2. The central limit theorem will show that
the error is indeed exactly of this order.
If f is smooth in some sense, then the usual numerical procedures yield better
orders of convergence. Hence Monte Carlo simulation should be applied only if
all other methods fail. This is the case in particular if [0, 1] is replaced by G ⊂Rd
for very large d. ♦
Deﬁnition 5.22 (Empirical distribution function) Let X1, X2, . . . be real random
variables. The map Fn : R →[0, 1], x →1
n
n
i=1
1(−∞,x](Xi) is called the empirical
distribution function of X1, . . . , Xn.
Theorem 5.23 (Glivenko–Cantelli) Let X1, X2, . . . be i.i.d. real random variables
with distribution function F, and let Fn, n ∈N, be the empirical distribution
functions. Then
lim sup
n→∞
sup
x∈R
Fn(x) −F(x)
 = 0
almost surely.
Proof Fix x ∈R and let Yn(x) = 1(−∞,x](Xn) and Zn(x) = 1(−∞,x)(Xn) for n ∈
N. Additionally, deﬁne the left-sided limits F(x−) = limy↑x F(y) and similarly
for Fn. Then each of the families (Yn(x))n∈N and (Zn(x))n∈N is independent.
Furthermore, E[Yn(x)] = P[Xn ≤x] = F(x) and E[Zn(x)] = P[Xn < x] =
F(x−). By the strong law of large numbers, we thus have
Fn(x) = 1
n
n

i=1
Yi(x)
n→∞
−→F(x)
almost surely

130
5
Moments and Laws of Large Numbers
and
Fn(x−) = 1
n
n

i=1
Zi(x)
n→∞
−→F(x−)
almost surely.
Formally, deﬁne F(−∞) = 0 and F(∞) = 1. Fix some N ∈N and deﬁne
xj := inf 	x ∈R : F(x) ≥j/N
,
j = 0, . . ., N,
and
Rn :=
max
j=1,...,N−1
Fn(xj) −F(xj)
 +
Fn(xj−) −F(xj−)

.
As shown above, Rn
n→∞
−→
0 almost surely. For x ∈(xj−1, xj), we have (by
deﬁnition of xj)
Fn(x) ≤Fn(xj−) ≤F(xj−) + Rn ≤F(x) + Rn + 1
N
and
Fn(x) ≥Fn(xj−1) ≥F(xj−1) −Rn ≥F(x) −Rn −1
N .
Hence
lim sup
n→∞
sup
x∈R
Fn(x) −F(x)
 ≤
1
N + lim sup
n→∞
Rn =
1
N .
Letting N →∞, the claim follows.
⊓⊔
Example 5.24 (Shannon’s theorem) Consider a source of information that sends a
sequence of independent random symbols X1, X2, . . . drawn from a ﬁnite alphabet
E (that is, from an arbitrary ﬁnite set E). Let pe be the probability of the symbol
e ∈E. Formally, the X1, X2, . . . are i.i.d. E-valued random variables with P[Xi =
e] = pe for e ∈E.
For any ω ∈Ω and n ∈N, let
πn(ω) :=
n

i=1
pXi(ω)
be the probability that the observed sequence X1(ω), . . . , Xn(ω) occurs. Deﬁne
Yn(ω) := −log(pXn(ω)). Then (Yn)n∈N is i.i.d. and E[Yn] = H(p), where
H(p) := −

e∈E
pe log(pe)

5.3
Strong Law of Large Numbers
131
is the entropy of the distribution p = (pe)e∈E (compare Deﬁnition 5.25). By the
strong law of large numbers, we infer Shannon’s theorem:
−1
n log πn = 1
n
n

i=1
Yi
n→∞
−→H(p)
almost surely.
♦
Entropy and Source Coding Theorem∗
We brieﬂy discuss the importance of πn and the entropy. How can we quantify
the information inherent in a message X1(ω), . . . , Xn(ω)? This information can be
measured by the length of the shortest sequence of zeros and ones by which the
message can be encoded. Of course, you do not want to invent a new code for
every message but rather use one code that allows for the shortest average coding
of the messages for the particular information source. To this end, associate with
each symbol e ∈E a sequence of zeros and ones that when concatenated yield the
message. The length l(e) of the sequence that codes for e may depend on e. Hence,
for efﬁciency, those symbols that appear more often get a shorter code than the more
rare symbols. The Morse alphabet is constructed similarly (the letters “e” and “t”,
which are the most frequent letters in English, have the shortest codes (“dot” and
“dash”), and the rare letter “q” has the code “dash-dash-dot-dash”). However, the
Morse code also consists of gaps of different lengths that signal ends of letters and
words. As we want to use only zeros and ones (and no gap-like symbols), we have to
arrange the code in such a way that no code is the beginning of the code of a different
symbol. For example, we could not encode one symbol with 0110 and a different
one with 011011. A code that fulﬁlls this condition is called a binary preﬁx code.
Denote by c(e) ∈{0, 1}l(e) the code of e, where l(e) is its length. We can represent
the codes of all letters in a tree.
Let us construct a code C = (c(e), e ∈E) that is efﬁcient in the sense that it
minimizes the expected length of the code (of a random symbol)
Lp(C) :=

e∈E
pe l(e).
We ﬁrst deﬁne a speciﬁc code and then show that it is almost optimal. As a ﬁrst step,
we enumerate E = {e1, . . . , eN} such that pe1 ≥pe2 ≥. . . ≥peN . Deﬁne ℓ(e) ∈N
for any e ∈E by
2−ℓ(e) ≤pe < 2−ℓ(e)+1.
Let ˜pe = 2−ℓ(e) for any e ∈E and let ˜qk = 
l<k ˜pel for k = 1, . . . , N.

132
5
Moments and Laws of Large Numbers
By construction, ℓ(el) ≤ℓ(ek) for all l ≤k; hence the binary representation of
˜qk has at most ℓ(ek) digits:
˜qk =
ℓ(ek)

i=1
ci(ek) 2−i.
Here the numbers c1(ek), . . . , cℓ(ek)(ek) ∈{0, 1} are uniquely determined.
Clearly, ˜ql ≥˜qk + 2−ℓ(ek) for any l > k; hence
c1(ek), . . . , cℓ(ek)(ek) ̸= c1(el), . . . , cℓ(ek)(el)
for all l > k.
Thus C = (c(e), e ∈E) is a preﬁx code.
For any b > 0 and x > 0, denote by logb(x) := log(x)
log(b) the logarithm of x to base
b. By construction, −log2(pe) ≤l(e) ≤1 −log2(pe). Hence the expected length is
−

e∈E
pe log2(pe) ≤Lp(C) ≤1 −

e∈E
pe log2(pe).
The length of this code for the ﬁrst n symbols of our random information source
is thus approximately −n
k=1 log2(pXk(ω)) = −log2 πn(ω). Here we have the
connection to Shannon’s theorem. That theorem thus makes a statement about the
length of a binary preﬁx code needed to transmit a long message.
Now, is the code constructed above optimal, or are there codes with smaller mean
length? The answer is given by the source coding theorem for which we prepare with
a deﬁnition and a lemma.
Deﬁnition 5.25 (Entropy) Let p = (pe)e∈E be a probability distribution on the
countable set E. For b > 0, deﬁne
Hb(p) := −

e∈E
pe logb(pe)
with the convention 0 logb(0) := 0. We call H(p) := He(p) (e = 2.71 . . . Euler’s
number) the entropy and H2(p) the binary entropy of p.
Note that, for inﬁnite E, the entropy need not be ﬁnite.
Lemma 5.26 (Entropy inequality) Let b and p be as above. Further, let q be a
sub-probability distribution; that is, qe ≥0 for all e ∈E and 
e∈E qe ≤1. Then
Hb(p) ≤−

e∈E
pe logb(qe)
(5.10)
with equality if and only if Hb(p) = ∞or q = p.
Proof Without loss of generality, we can do the computation with b = e; that is,
with the natural logarithm. Note that log(1 + x) ≤x for x > −1 with equality if
and only if x = 0. If in (5.10) the left-hand side is ﬁnite, then we can subtract the

5.3
Strong Law of Large Numbers
133
right-hand side from the left-hand side and obtain
H(p) +

e∈E
pe log(qe) =

e: pe>0
pe log(qe/pe)
=

e: pe>0
pe log

1 + qe −pe
pe

≤

e: pe>0
pe
qe −pe
pe
=

e∈E

qe −pe

≤0.
If q ̸= p, then there is an e ∈E with pe > 0 and qe ̸= pe. If this is the case, then
strict inequality holds if H(p) < ∞.
⊓⊔
Theorem 5.27 (Source coding theorem) Let p
= (pe)e∈E be a probability
distribution on the ﬁnite alphabet E. For any binary preﬁx code C = (c(e), e ∈E),
we have Lp(C) ≥H2(p). Furthermore, there is a binary preﬁx code C with
Lp(C) ≤H2(p) + 1.
Proof The second part of the theorem was shown in the above construction. Now
assume that a preﬁx code is given. Let L = maxe∈E l(e). For e ∈E, let
CL(e) =
	
c ∈{0, 1}L : ck = ck(e) for k ≤l(e)

the set of all dyadic sequences of length L that start like c(e). Since we have a
preﬁx code, the sets CL(e), e ∈E, are pairwise disjoint and 
e∈E CL(e) ⊂{0, 1}L.
Hence, if we deﬁne qe := 2−l(e), then (note that #CL(e) = 2L−l(e))

e∈E
qe = 2−L 
e∈E
#CL(e) ≤1.
By Lemma 5.26, we have Lp(C) = 
e∈E
pe l(e) = −
e∈E
pe log2(qe) ≥H2(p).
⊓⊔
Takeaways For random variables with second moments, a strong law of
large numbers can be shown using the Borel-Cantelli lemma and Chebyshev’s
inequality ﬁrst on an subsequence and then on the full sequence. For pairwise
independent random variables with ﬁrst moment, we could establish a strong
law of large number via an involved truncation procedure which allows to use
second moments estimates.
Exercise 5.3.1 Show the following improvement of Theorem 5.16: If X1, X2, . . .
∈L2(P) are pairwise independent with bounded variances, then (Xn)n∈N fulﬁlls
the strong law of large numbers. ♣

134
5
Moments and Laws of Large Numbers
Exercise 5.3.2 Let (Xn)n∈N be a sequence of independent identically distributed
random variables with 1
n(X1 + . . . + Xn)
n→∞
−→Y almost surely for some random
variable Y. Show that X1 ∈L1(P) and Y = E[X1] almost surely.
Hint: First show that
P
)
|Xn| > n for inﬁnitely many n
*
= 0
⇐⇒
X1 ∈L1(P).
♣
Exercise 5.3.3 Let E be a ﬁnite set and let p be a probability vector on E. Show
that the entropy H(p) is minimal (in fact, zero) if p = δe for some e ∈E. It is
maximal (in fact, log(#E)) if p is the uniform distribution on E. ♣
Exercise 5.3.4 (Subadditivity of Entropy) For i = 1, 2, let Ei be a ﬁnite set
and pi a probability vector on Ei. Let p be a probability vector on E1 × E2 with
marginals p1 and p2. That is,

e2∈E2
p(e1,e2) = p1
e1
and

f 1∈E1
p(f 1,f 2) = p2
f 2
for all e1 ∈E1, f 2 ∈E2.
Show that H(p) ≤H(p1) + H(p2). ♣
Exercise 5.3.5 Let b ∈{2, 3, 4, . . .}. A b-adic preﬁx code is deﬁned in a similar
way as a binary preﬁx code; however, instead of 0 and 1, now all numbers
0, 1, . . ., b−1 are admissible. Show that the statement of the source coding theorem
holds for b-adic preﬁx codes with H2(p) replaced by Hb(p). ♣
Exercise 5.3.6 We want to check the efﬁciency of the Morse alphabet. To this end
we need a table of the Morse code as well as the frequencies of the letters in a typical
text. The following frequencies for letters in German texts are taken from [11, p. 10].
The frequencies for other languages can be found easily, e.g., at Wikipedia.
Letter
Morse code
Frequency
A
.-
0.0651
B
-...
0.0189
C
-.-.
0.0306
D
-..
0.0508
E
.
0.1740
F
..-.
0.0166
G
-.
0.0301
H
....
0.0476
I
..
0.0755
J
.--
0.0027
K
-.-
0.0121
L
.-..
0.0344
M
-
0.0253
Letter
Morse code
Frequency
N
-.
0.0978
O
--
0.0251
P
.-.
0.0079
Q
-.-
0.0002
R
.-.
0.07
S
...
0.0727
T
-
0.0615
U
..-
0.0435
V
...-
0.0067
W
.-
0.0189
X
-..-
0.0003
Y
-.-
0.0004
Z
-..
0.0113

5.4
Speed of Convergence in the Strong LLN
135
Here ‘.’ denotes a short signal while ‘-’ denotes a long signal. Each letter is
ﬁnished by a pause sign. Thus the Morse code can be interpreted as a ternary preﬁx
code.
Determine the average code length of a letter and compare it with the entropy H3
in order to check the efﬁciency of the Morse code. ♣
Exercise 5.3.7 Let m ∈(0, ∞) and let
Wm =

p = (pk)k∈N0 is a probability measure on N0 and
∞

k=0
kpk = m

be the set of probability measures on N0 with expectation m.
(i) Show that there exists a pmax ∈Wm that maximises the entropy; that is,
H

pmax

= supp∈Wm H(p).
(ii) Compute pmax explicitly. ♣
5.4
Speed of Convergence in the Strong LLN
In the weak law of large numbers, we had a statement on the speed of convergence
(Theorem 5.14). In the strong law of large numbers, however, we did not. As
we required only ﬁrst moments, in general, we cannot expect to get any useful
statements. However, if we assume the existence of higher moments, we get
reasonable estimates on the rate of convergence.
The core of the weak law of large numbers is Chebyshev’s inequality. Here we
present a stronger inequality that claims the same bound but now for the maximum
over all partial sums until a ﬁxed time.
Theorem 5.28 (Kolmogorov’s inequality) Let n ∈N and let X1, X2, . . . , Xn be
independent random variables with E[Xi] = 0 and Var[Xi] <∞for i = 1, . . . , n.
Further, let Sk = X1 + . . . + Xk for k = 1, . . . , n. Then, for any t > 0,
P
)
max{Sk : k = 1, . . . , n} ≥t
*
≤
Var[Sn]
t2 + Var[Sn].
(5.11)
Furthermore, Kolmogorov’s inequality holds:
P
)
max{|Sk| : k = 1, . . . , n} ≥t
*
≤t−2 Var[Sn].
(5.12)
a generalization of Kolmogorov’s inequality.

136
5
Moments and Laws of Large Numbers
Proof We decompose the probability space according to the ﬁrst time τ at which
the partial sums exceed the value t. Hence, let
τ := min
	
k ∈{1, . . . , n} : Sk ≥t

and Ak = {τ = k} for k = 1, . . . , n. Further, let
A =
n

k=1
Ak =
	
max{Sk : k = 1, . . . , n} ≥t

.
Let c ≥0. The random variable (Sk +c) 1Ak is σ(X1, . . . , Xk)-measurable and Sn−
Sk is σ(Xk+1, . . . , Xn)-measurable. By Theorem 2.26, the two random variables are
independent, and
E)(Sk + c) 1Ak(Sn −Sk)* = E)(Sk + c) 1Ak
* E)Sn −Sk
* = 0.
Clearly, the events A1, . . . , An are pairwise disjoint; hence n
k=1 1Ak = 1A ≤1.
We thus obtain
Var[Sn] + c2 = E
)
(Sn + c)2*
≥E
- n

k=1
(Sn + c)2 1Ak
.
=
n

k=1
E
'
(Sn + c)2 1Ak
(
=
n

k=1
E
'
(Sk + c)2 + 2(Sk + c)(Sn −Sk) + (Sn −Sk)2
1Ak
(
=
n

k=1
E
'
(Sk + c)2 1Ak
(
+
n

k=1
E
'
(Sn −Sk)2 1Ak
(
≥
n

k=1
E
'
(Sk + c)2 1Ak
(
.
(5.13)
Since c ≥0, we have (Sk + c)2 1Ak ≥(t + c)2 1Ak. Hence we can continue (5.13)
to get
Var[Sn] + c2 ≥
n

k=1
E
'
(t + c)2 1Ak
(
= (t + c)2 P[A].
For c = Var[Sn]/t ≥0, we obtain
P[A] ≤Var[Sn] + c2
(t + c)2
= c(t + c)
(t + c)2 =
tc
t2 + tc =
Var[Sn]
t2 + Var[Sn].

5.4
Speed of Convergence in the Strong LLN
137
This shows (5.11). In order to show (5.12), choose
¯τ := min
	
k ∈{1, . . . , n} : |Sk| ≥t

.
Let ¯Ak = {¯τ = k} and ¯A = {¯τ ≤n}. We cannot now continue (5.13) as above with
c > 0. However, if we choose c = 0, then S2
k 1 ¯Ak ≥t2 1 ¯Ak. The same calculation
as in (5.13) does then yield P[ ¯A] ≤t−2 Var[Sn].
⊓⊔
From Kolmogorov’s inequality, we derive the following sharpening of the strong
law of large numbers.
Theorem 5.29 Let X1, X2, . . . be independent random variables with E[Xn] = 0
for any n ∈N and V := sup{Var[Xn] : n ∈N} < ∞. Then, for any ε > 0,
lim sup
n→∞
|Sn|
n1/2(log(n))(1/2)+ε = 0
almost surely.
Proof Let kn = 2n and l(n) = n1/2(log(n))(1/2)+ε for n ∈N. Then we have
l(kn+1)/l(kn)
n→∞
−→
√
2. Hence, for n ∈N sufﬁciently large and k ∈N with
kn−1 ≤k ≤kn, we have |Sk|/l(k) ≤2|Sk|/l(kn). Hence, it is enough to show for
every δ > 0 that
lim sup
n→∞
l(kn)−1 max{|Sk| : k ≤kn} ≤δ
almost surely.
(5.14)
For δ > 0 and n ∈N, deﬁne Aδ
n :=
	
max{|Sk| : k ≤kn} > δ l(kn)

. Kolmogorov’s
inequality yields
∞

n=1
P )Aδ
n
* ≤
∞

n=1
δ−2(l(kn))−2 V kn =
V
δ2(log 2)1+2ε
∞

n=1
n−1−2ε < ∞.
The Borel–Cantelli lemma then gives P )lim supn→∞Aδ
n
* = 0 and hence (5.14).
⊓⊔
In Chap. 22, we will see that for independent identically distributed, square inte-
grable, centered random variables X1, X2, . . ., the following strengthening holds,
lim sup
n→∞
|Sn|
2
2n Var[X1] log(log(n))
= 1
almost surely.
Hence, in this case, the speed of convergence is known precisely. If the X1, X2, . . .
are not independent but only pairwise independent, then the rate of convergence
deteriorates, although not drastically. Here we cite without proof a theorem that was
found independently by Rademacher [141] and Menshov [113].

138
5
Moments and Laws of Large Numbers
Theorem 5.30 (Rademacher–Menshov) Let X1, X2, . . . be uncorrelated, square
integrable, centered random variables and let (an)n∈N be an increasing sequence of
nonnegative numbers such that
∞

n=1
(log n)2a−2
n
Var[Xn] < ∞.
(5.15)
Then lim sup
n→∞
a−1
n
n

k=1
Xk
 = 0
almost surely.
Proof See, for example, [128].
⊓⊔
Remark 5.31 Condition (5.15) is sharp in the sense that for any increasing sequence
(an)n∈N with ∞
n=1 a−2
n (log n)2 = ∞, there exists a sequence of pairwise indepen-
dent, square integrable, centered random variables X1, X2, . . . with Var[Xn] = 1
for all n ∈N such that
lim sup
n→∞
a−1
n
n

k=1
Xk
 = ∞
almost surely.
See [22]. There an example of [164] (see also [165, 166]) for orthogonal series is
developed further. See also [117]. ♦
For random variables with inﬁnite variance, the statements about the rate of
convergence naturally get weaker. For example (see [8]), see the following theorem.
Theorem 5.32 (Baum and Katz [8]) Let γ > 1 and let X1, X2, . . . be i.i.d. Deﬁne
Sn = X1 + . . . + Xn for n ∈N. Then
∞

n=1
nγ −2 P[|Sn|/n>ε] < ∞for any ε > 0 ⇐⇒E[|X1|γ ]<∞and E[X1] = 0.
Takeaways Kolmogorov’s inequality gives bounds for the maximum of
partial sums of random variables similar to Chebyshev’s inequality for one
random variable. We have used this inequality in order to give an (almost
sharp) upper bound on the speed of convergence in the strong law of large
numbers (Theorem 5.29). Later, with a lot of additional effort, we will achieve
a sharp bound in Theorem 22.11.
Exercise 5.4.1 Let X1, . . . , Xn be independent real random variables and let Sk =
X1 + . . .+ Xk for k = 1, . . ., n. Show that for t > 0 Etemadi’s inequality holds:
P
'
max
k=1,...,n |Sk| ≥t
(
≤3 max
k=1,...,n P
)
|Sk| ≥t/3
*
.
♣

5.5
The Poisson Process
139
5.5
The Poisson Process
We develop a model for the number of clicks of a Geiger counter in the (time)
interval I = (a, b]. The number of clicks should obey the following rules. It
should
•
be random and independent for disjoint intervals,
•
be homogeneous in time in the sense that the number of clicks in I = (a, b] has
the same distribution as the number of clicks in c + I = (a + c, b + c],
•
have ﬁnite expectation, and
•
have no double points: At any point of time, the counter makes at most one click.
We formalize these requirements by introducing the following notation:
I :=
	
(a, b] : a, b ∈[0, ∞), a ≤b

,
ℓ((a, b]) := b −a
(the length of the interval I = (a, b]).
For I ∈I, let NI be the number of clicks after time a but no later than b. In
particular, we deﬁne Nt := N(0,t] as the total number of clicks until time t. The
above requirements translate to: (NI, I ∈I) being a family of random variables
with values in N0 and with the following properties:
(P1) NI∪J = NI + NJ if I ∩J = ∅and I ∪J ∈I.
(P2) The distribution of NI depends only on the length of I: PNI = PNJ for all
I, J ∈I with ℓ(I) = ℓ(J).
(P3) If J ⊂I with I ∩J = ∅for all I, J ∈J with I ̸= J, then (NJ , J ∈J ) is
an independent family.
(P4) For any I ∈I, we have E[NI] < ∞.
(P5) lim supε↓0 ε−1 P[Nε ≥2] = 0.
The meaning of (P5) is explained by the following calculation. Deﬁne
λ := lim sup
ε↓0
ε−1 P[Nε ≥2].
For any n ∈N and ε > 0, we have
P[N2−n ≥2] ≥⌊2−n/ε⌋P[Nε ≥2] −⌊2−n/ε⌋2 P[Nε ≥2]2.
Hence
2n P[N2−n ≥2] ≥λ −2−nλ2
n→∞
−→
λ.

140
5
Moments and Laws of Large Numbers
Then (because (1 −ak/k)k k→∞
−→e−a if ak
k→∞
−→a)
P
)
there is a double click in (0, 1]
*
= lim
n→∞P
+ 2n−1

k=0
	
N(k 2−n,(k+1)2−n] ≥2

,
= 1 −lim
n→∞P
+ 2n−1

k=0
	N(k 2−n,(k+1)2−n] ≤1
,
= 1 −lim
n→∞
2n−1

k=0
P
)
N(k 2−n,(k+1)2−n] ≤1
*
= 1 −lim
n→∞

1 −P[N2−n ≥2]
2n
= 1 −e−λ.
Hence we have to postulate λ = 0. This, however, is exactly (P5).
The following theorem shows that properties (P1)–(P5) characterize the random
variables (NI, I ∈I) uniquely and that they form a Poisson process.
Deﬁnition 5.33 (Poisson process) A family (Nt, t ≥0) of N0-valued random
variables is called a Poisson process with intensity α ≥0 if N0 = 0 and if:
(i) For any n ∈N and any choice of n + 1 numbers 0 = t0 < t1 < . . . < tn, the
family (Nti −Nti−1, i = 1, . . . , n) is independent.
(ii) For t > s ≥0, the difference Nt −Ns is Poisson-distributed with parameter
α(t −s); that is,
P[Nt −Ns = k] = e−α(t−s)(α(t −s))k
k!
for all k ∈N0.
See Fig. 5.3 for a computer simulation of a Poisson process.
The existence of the Poisson process has not yet been shown. We come back to
this point in Theorem 5.36.
Fig. 5.3 Simulation of a
Poisson process with rate
α = 0.5.
0
2
4
6
8
10
0
1
2
3
4
5
6

5.5
The Poisson Process
141
Theorem 5.34 If (NI, I ∈I) has properties (P1)–(P5), then (N(0,t], t ≥0) is a
Poisson process with intensity α := E[N(0,1]]. If, on the other hand, (Nt, t ≥0) is
a Poisson process, then (Nt −Ns, (s, t] ∈I) has properties (P1)–(P5).
Proof First assume that (Nt, t ≥0) is a Poisson process with intensity α ≥0.
Then, for I = (a, b], clearly PNI = Poiα(b−a) = Poiαℓ(I). Hence (P2) holds. By (i),
we have (P3). Clearly, E[NI] = α ℓ(I) < ∞; thus we have (P4). Finally, P[Nε ≥
2] = 1 −e−αε −α ε e−αε = f (0) −f (αε), where f (x) := e−x + xe−x. The
derivative is f ′(x) = −xe−x, whence
lim
ε↓0 ε−1 P[Nε ≥2] = −αf ′(0) = 0.
This implies (P5).
Now assume that (NI, I ∈I) fulﬁlls (P1)–(P5). Deﬁne α(t) := E[Nt]. Then
(owing to (P2))
α(s + t) = E
)
N(0,s] + N(s,s+t]
*
= E
)
N(0,s]
*
+ E
)
N(0,t]
*
= α(s) + α(t).
As t →α(t) is monotone increasing, this implies linearity: α(t) = t α(1) for any
t ≥0. Letting α := α(1), we obtain E[NI] = α ℓ(I). It remains to show that
PNt = Poiαt. In order to apply the Poisson approximation theorem (Theorem 3.7),
for ﬁxed n ∈N, we decompose the interval (0, t] into 2n disjoint intervals of equal
length,
I n(k) :=

(k −1)2−nt, k2−nt
*
,
k = 1, . . . , 2n.
Now deﬁne Xn(k) := NI n(k) and
Xn(k) :=
0 1,
if Xn(k) ≥1,
0,
else.
By properties (P2) and (P3), the random variables (Xn(k), k = 1, . . . , 2n) are
independent and identically distributed. Hence also (Xn(k), k = 1, . . . , 2n) are
i.i.d., namely Xn(k) ∼Berpn, where pn = P[N2−nt ≥1].
Finally, let Nn
t := 2n
k=1 Xn(k). Then Nn
t ∼b2n,pn. Clearly, Nn+1
t
−Nn
t ≥0.
Now, by (P5),
P
)
Nt ̸= Nn
t
*
≤
2n

k=1
P
)
Xn(k) ≥2
*
= 2n P [N2−nt ≥2]
n→∞
−→
0.
(5.16)
Hence P
'
Nt = lim
n→∞Nn
t
(
= 1. By the monotone convergence theorem, we get
α t = E [Nt] =
lim
n→∞E
)
Nn
t
*
=
lim
n→∞pn 2n.

142
5
Moments and Laws of Large Numbers
Using the Poisson approximation theorem (Theorem 3.7), we infer that, for any
l ∈N0,
P[Nt = l] =
lim
n→∞P
)
Nn
t = l
*
= Poiαt({l}).
Hence PNt = Poiα t.
⊓⊔
Reﬂection Why do we need condition (iii) in the deﬁnition of the Poisson process?
Consider a Poisson process (Nt)t≥0 and choose an independent exponentially
distributed random variable T (it would sufﬁce for T to have a density). Now deﬁne
˜Nt = Nt for t ̸= T and let ˜NT = 0. The process ˜N fulﬁlls (i) and (ii), but not
(iii). In fact, t →˜Nt is not monotone. A second possibility to spoil (iii) is to deﬁne
Nt := supr<t Nr für t > 0 und N0 = 0. In this case, t →Nt is monotone but it is
not right continuous, although (i) and (ii) hold.
In either case, where does the proof of Theorem 5.34 fail? ♠♠
At this point, we still have to show that there are Poisson processes at all. We present
a general two-step construction principle that will be used in a similar form later in
Chap. 24 in a more general setting. In the ﬁrst step, we determine the (random)
number of jumps in (0, 1]. In the second step, we distribute these jumps uniformly
and independently on (0, 1]. Strictly speaking, this gives the Poisson process only
on the time interval (0, 1], but it is clear how to move on: We perform the same
procedure independently for each of the intervals (1, 2], (2, 3] and so on and then
collect the jumps (see also Exercise 5.5.1).
Let α > 0 and let L be a Poiα random variable. Further, let X1, X2, . . .
be independent random variables, that are uniformly distributed on (0, 1], i.e.,
Xk ∼U(0,1] for each k. We assume that {L, X1, X2, . . .} is an independent family
of random variables. We now deﬁne N = (Nt)t∈[0,1] by
Nt :=
L

l=1
1(0,t](Xl)
for t ∈[0, 1].
(5.17)
Theorem 5.35 The family N of random variables deﬁned in (5.17) is a Poisson
process with intensity α (and time set [0, 1]).
Proof We have to show that the increments of N in ﬁnitely many pairwise disjoint
intervals are independent and Poisson distributed. Hence let m ∈N and 0 = t0 <
t1 < . . . < tm = 1. We use the abbreviations pi := ti −ti−1 and λi = α · (ti −ti−1)
and show that
(Nti −Nti−1)i=1,...,m is independent
(5.18)
and
Nti −Nti−1 ∼Poiλi
for all i = 1, . . . , m.
(5.19)

5.5
The Poisson Process
143
This is equivalent to showing that for each choice of k1, . . . , km ∈N0, we have
P
)
Nti −Nti−1 = ki for any i = 1, . . . , m
*
=
m

i=1

e−λi λki
i
ki!

.
(5.20)
Write
Mn,i := #
	
l ≤n : ti−1 < Xl ≤ti

=
n

l=1
1(ti−1,ti](Xl).
By Exercise 2.2.3, the vector (Mn,1, . . . , Mn,m) is multinomially distributed with
parameters n and p = (p1, . . . , pm). That is, if we assume n := k1 + . . .+ km, then
P
)
Mn,1 = k1, . . . , Mn,m = km
*
=
n!
k1! · · · km! pk1
1 · · · pkm
m .
In order to show (5.20), note that the event in (5.20) implies L = n and that L and
(Mn,1, . . . , Mn,m) are independent. Hence we have
P
)
Nti −Nti−1 = ki for i = 1, . . . , m
*
= P
)
{Nti −Nti−1 = ki for i = 1, . . . , m} ∩{L = n}
*
= P){Mn,1 = k1, . . . , Mn,m = km} ∩{L = n}*
= P
)
Mn,1 = k1, . . . , Mn,m = km
*
· P[L = n]
=
n!
k1! · · · km! pk1
1 · · · pkm
m e−α αn
n!
=
m

i=1

e−λi λki
i
ki!

.
⊓⊔
We close this section by presenting a further, rather elementary and instructive con-
struction of the Poisson process based on specifying the waiting times between the
clicks of the Geiger counter, or, more formally, between the points of discontinuity
of the map t →Nt(ω). At time s, what is the probability that we have to wait
another t time units (or longer) for the next click? Since we modeled the clicks as a
Poisson process with intensity α, this probability can easily be computed:
P
)
N(s,s+t] = 0
*
= e−αt.
Hence the waiting time for the next click is exponentially distributed with parameter
α. Furthermore, the waiting times should be independent. We now take the waiting
times as the starting point and, based on them, construct the Poisson process.

144
5
Moments and Laws of Large Numbers
Let W1, W2, . . . be an independent family of exponentially distributed random
variables with parameter α > 0; hence P[Wn > x] = e−αx. We deﬁne
Tn :=
n

k=1
Wk
and interpret Wn as the waiting time between the (n −1)th click and the nth click.
Tn is the time of the nth click. Appealing to this intuition we deﬁne the number of
clicks until time t by
Nt := #{n ∈N0 : Tn ≤t}.
Hence
{Nt = k} = {Tk ≤t < Tk+1}.
In particular, Nt is a random variable; that is, measurable.
Theorem 5.36 The family (Nt, t ≥0) is a Poisson process with intensity α.
Proof (We follow the proof in [59, Theorem 3.34]) We must show that for any
n ∈N and any sequence 0 = t0 < t1 < . . . < tn, we have that (Nti −Nti−1, i =
1, . . . , n) is independent and Nti −Nti−1 ∼Poiα(ti−ti−1). We are well aware that
it is not enough to show this for the case n = 2 only. However, the notational
complications become overwhelming for n ≥3, and the idea for general n ∈N
becomes clear in the case n = 2. Hence we restrict ourselves to the case n = 2.
Hence we show for 0 < s < t and l, k ∈N0 that
P[Ns = k, Nt −Ns = l] =

e−αs (αs)k
k!
 
e−α(t−s)(α(t −s))l
l!

.
(5.21)
This implies that Ns and (Nt −Ns) are independent. Furthermore, by summing over
k ∈N0, this yields Nt −Ns ∼Poiα(t−s).
By Corollary 2.22, the distribution P(W1,...,Wk+l+1) has the density
x →αk+l+1 e−αSk+l+1(x),
where Sn(x) := x1 + . . . + xn. It is sufﬁcient to consider l ≥1 since we get the
l = 0 term from the fact that the probability measure has total mass one. Hence, let
l ≥1. We compute
P[Ns = k, Nt −Ns = l] = P[Tk ≤s < Tk+1, Tk+l ≤t < Tk+l+1]
=
 ∞
0
· · ·
 ∞
0
dx1 · · · dxk+l+1
αk+l+1 e−αSk+l+1(x) 1{Sk(x)≤s<Sk+1(x)} 1{Sk+l(x)≤t<Sk+l+1(x)}.

5.5
The Poisson Process
145
Starting with xk+l+1, we integrate successively. In the ﬁrst step, substitute z =
Sk+l+1(x) to obtain
 ∞
0
dxk+l+1 α e−αSk+l+1(x) 1{Sk+l+1(x)>t} =
 ∞
t
dz α e−αz = e−αt.
Now keep x1, . . . , xk ﬁxed and substitute for the remaining variables by letting y1 =
Sk+1(x) −s, y2 = xk+2, . . . , yl = xk+l to obtain
 ∞
0
· · ·
 ∞
0
dxk+1 · · · dxk+l 1{s<Sk+1(x)≤Sk+l≤t}
=
 ∞
0
· · ·
 ∞
0
dy1 · · · dyl 1{y1+...+yl≤t−s} = (t −s)l
l!
.
(The last identity can be obtained, for example, by induction on l.) Now integrate
the remaining variables x1, . . . , xk to get
 ∞
0
· · ·
 ∞
0
dx1 · · · dxk 1{Sk(x)≤s} = sk
k! .
In total, we have
P[Ns = k, Nt −Ns = l] = e−αt αk+l sk
k!
(t −s)l
l!
;
hence (5.21) holds.
⊓⊔
Takeaways Assume that events, e.g. radioactive decays, happen at probabil-
ity ≈α ·(b −a) (for some α > 0) in a small time interval (a, b]. Also assume
that the events in disjoints intervals come independently. Then the waiting
times between events are exponentially distributed with parameter α and the
total number of events up to time t is described by a Poisson process.
Exercise 5.5.1 Let Ln, Xn
k , k, n ∈N be independent random variables with Ln ∼
Poiα and Xn
k ∼U(n−1,n] (the uniform distribution on (n −1, n]) for all k, n ∈N.
Deﬁne
Nt := #
	
(k, n) ∈N2 : k ≤Ln and Xn
k ≤t

.
Show that (Nt)t≥0 is a Poisson process with intensity α. ♣

146
5
Moments and Laws of Large Numbers
Exercise 5.5.2 Let T > 0 and let X1, X2, . . . be i.i.d. random variables that are
uniformly distributed on [0, 1]. Let
N := max
	
n ∈N0 : X1 + . . . + Xn ≤T

and compute E[N]. ♣

Chapter 6
Convergence Theorems
In the strong and the weak laws of large numbers, we implicitly introduced the
notions of almost sure convergence and convergence in probability of random
variables. We saw that almost sure convergence implies convergence in mea-
sure/probability. This chapter is devoted to a systematic treatment of almost sure
convergence, convergence in measure and convergence of integrals. The key role
for connecting convergence in measure and convergence of integrals is played by
the concept of uniform integrability.
6.1
Almost Sure and Measure Convergence
In the following, (Ω, A, μ) will be a σ-ﬁnite measure space. We ﬁrst deﬁne
in metric spaces almost sure convergence and convergence in measure and then
compare both concepts. To this end, we need two lemmas that ensure that the
distance function associated with two measurable maps is again measurable. In
the following, let (E, d) be a separable metric space with Borel σ-algebra B(E).
“Separable” means that there exists a countable dense subset. For x ∈E and r > 0,
denote by Br(x) = {y ∈E : d(x, y) < r} the ball with radius r centered at x.
Lemma 6.1 Let f, g : Ω →E be measurable with respect to A – B(E). Then the
map H : Ω →[0, ∞), ω →d(f (ω), g(ω)) is A – B([0, ∞))-measurable.
Proof Let F ⊂E be countable and dense. By the triangle inequality, d(x, z) +
d(z, y) ≥d(x, y) for all x, y ∈E and z ∈F. Let (zn)n∈N be a sequence in F
with zn
n→∞
−→x. Since d is continuous, we have d(x, zn) + d(zn, y)
n→∞
−→d(x, y).
Putting things together, we infer infz∈F(d(x, z) + d(z, y)) = d(x, y). Since x →
d(x, z) is continuous and hence measurable, the maps fz, gz : Ω →[0, ∞) with
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_6
147

148
6
Convergence Theorems
fz(ω) = d(f (ω), z) and gz(ω) = d(g(ω), z) are also measurable. Thus fz +gz and
H = infz∈F(fz + gz) are measurable.
(A somewhat more systematic proof is based on the fact that (f, g) is A – B(E ×
E)-measurable (this will follow from Theorem 14.8) and that d : E × E →[0, ∞)
is continuous and hence B(E × E) – B([0, ∞))-measurable. As a composition of
measurable maps, ω →d(f (ω), g(ω)) is measurable.)
⊓⊔
Let f, f1, f2, . . . : Ω →E be measurable with respect to A – B(E).
Deﬁnition 6.2 We say that (fn)n∈N converges to f
(i) in μ-measure (or, brieﬂy, in measure), symbolically fn
meas
−→f , if
μ({d(f, fn) > ε} ∩A)
n→∞
−→0
for all ε > 0 and all A ∈A with μ(A) < ∞, and
(ii) μ-almost everywhere (a.e.), symbolically fn
a.e.
−→f , if there exists a μ-null
set N ∈A such that
d(f (ω), fn(ω))
n→∞
−→0
for any ω ∈Ω \ N.
If μ is a probability measure, then convergence in μ-measure is also called
convergence in probability. If (fn)n∈N converges a.e., then we also say that
(fn)n∈N converges almost surely (a.s.) and write fn
a.s.
−→f . Sometimes we
will drop the qualiﬁcations “ almost everywhere” and “ almost surely ”.
Remark 6.3 Let A1, A2, . . . ∈A with An ↑Ω and μ(An) < ∞for any n ∈N.
Then a.e. convergence is equivalent to a.e. convergence on each An. ♦
Remark 6.4 Almost everywhere convergence implies convergence in measure: For
ε > 0, deﬁne
Dn(ε) =
	
d(f, fm) > ε for some m ≥n

.
Then D(ε) := ∞
n=1 Dn(ε) ⊂N, where N is the null set from the deﬁnition of
almost everywhere convergence. Upper semicontinuity of μ implies
μ

Dn(ε) ∩A

n→∞
−→μ

D(ε) ∩A

= 0
for any A ∈A with μ(A) < ∞. ♦
Remark 6.5 Almost everywhere convergence and convergence in measure deter-
mine the limit up to equality almost everywhere. Indeed, let fn
meas
−→f and
fn
meas
−→g. Let A1, A2, . . . ∈A with An ↑Ω and μ(An) < ∞for any n ∈N.

6.1
Almost Sure and Measure Convergence
149
Then (since d(f, g) ≤d(f, fn) + d(g, fn)), for any m ∈N and ε > 0,
μAm ∩{d(f, g) > ε}
≤μ

Am ∩{d(f, fn) > ε/2}

+ μ

Am ∩{d(g, fn) > ε/2}
 n→∞
−→0.
Hence μ

{d(f, g) > 0}

= 0. ♦
Reﬂection Maybe it comes as a surprise that in the deﬁnition of stochastic conver-
gence, the set A of ﬁnite measure pops up. It is used to localise the convergence.
Consider the case Ω = R, μ the Lebesgue measure and fn := 1[n,n+1], f ≡0.
With our deﬁnition of stochastic convergence we have fn
meas
−→f . However, if we
do not intersect with the set A, then stochastic convergence would fail, although
we still had fn
a.e.
−→f . Hence convergence almost everywhere would not imply
stochastic convergence. Now this causes trouble in many places and so we chose a
deﬁnition where this implication holds. ♠
Remark 6.6 In general, convergence in measure does not imply almost everywhere
convergence. Indeed, let (Xn)n∈N be an independent family of random variables
with Xn ∼Ber1/n. Then Xn
n→∞
−→0 in probability but the Borel–Cantelli lemma
implies lim supn→∞Xn = 1 almost surely. ♦
Theorem 6.7 Let A1, A2, . . . ∈A with AN ↑Ω and μ(AN) < ∞for all N ∈N.
For measurable f, g : Ω →E, let
˜d(f, g) :=
∞

N=1
2−N
1 + μ(AN)

AN

1 ∧d(f (ω), g(ω))

μ(dω).
(6.1)
Then ˜d is a metric that induces convergence in measure: If f, f1, f2, . . . are
measurable, then
fn
meas
−→f
⇐⇒
˜d(f, fn)
n→∞
−→0.
Proof For N ∈N, deﬁne
˜dN(f, g) :=

AN

1 ∧d(f (ω), g(ω))

μ(dω).
Then ˜d(f, fn)
n→∞
−→0 if and only if ˜dN(f, fn)
n→∞
−→0 for all N ∈N.
“ ⇒”
Assume fn
meas
−→f . Then, for any ε ∈(0, 1),
˜dN(f, fn) ≤μ

AN ∩{d(f, fn) > ε}

+ ε μ(AN)
n→∞
−→ε μ(AN).
Letting ε ↓0 yields ˜dN(f, fn)
n→∞
−→0.

150
6
Convergence Theorems
“ ⇐ ”
Assume ˜d(f, fn)
n→∞
−→0. Let B ∈A with μ(B) < ∞. Fix δ > 0 and
choose N ∈N large enough that μ(B \ AN) < δ. Then, for ε ∈(0, 1),
μ

B ∩{d(f, fn) > ε}

≤δ + μ

AN ∩{d(f, fn) > ε}

≤δ + ε−1 ˜dN(f, fn)
n→∞
−→δ.
Letting δ ↓0 yields μ

B ∩{d(f, fn) > ε}
 n→∞
−→0; hence fn
meas
−→f .
⊓⊔
Consider the most prominent case E = R equipped with the Euclidean metric.
Here the integral is the basis for another concept of convergence.
Deﬁnition 6.8 (Mean convergence) Let f, f1, f2, . . . ∈L1(μ). We say that the
sequence (fn)n∈N converges in mean to f , symbolically
fn
L1
−→f,
if ∥fn −f ∥1
n→∞
−→0.
Remark 6.9 If fn
L1
−→f , then in particular
3
fn dμ
n→∞
−→
3
f dμ. ♦
Remark 6.10 If fn
L1
−→f and fn
L1
−→g, then f = g almost everywhere. Indeed,
by the triangle inequality, ∥f −g∥1 ≤∥fn −f ∥1 + ∥fn −g∥1
n→∞
−→0. ♦
Remark 6.11 Both L1-convergence and almost everywhere convergence imply
convergence in measure. All other implications are incorrect in general. ♦
Theorem 6.12 (Fast convergence) Let (E, d) be a separable metric space. In
order for the sequence (fn)n∈N of measurable maps Ω →E to converge almost
everywhere, it is sufﬁcient that one of the following conditions holds.
(i) E = R and there is a p ∈[1, ∞) with fn ∈Lp(μ) for all n ∈N and there is
an f ∈Lp(μ) with
∞

n=1
∥fn −f ∥p
p < ∞.
(ii) There is a measurable f with
∞

n=1
μ(A ∩{d(f, fn) > ε}) < ∞for all ε > 0
and for all A ∈A with μ(A) < ∞.
In both cases, we have fn
n→∞
−→f almost everywhere.
(iii) E is complete and there is a summable sequence (εn)n∈N such that
∞

n=1
μ(A ∩{d(fn, fn+1) > εn}) < ∞
for all A ∈A with μ(A) < ∞.

6.1
Almost Sure and Measure Convergence
151
Proof Clearly, condition (i) implies (ii) since Markov’s inequality yields that
μ({|f −fn| > ε}) ≤ε−p ∥f −fn∥p
p.
By Remark 6.3, it is enough to consider the case μ(Ω) < ∞.
Assume (ii). Let Bn(ε) = {d(f, fn) > ε} and B(ε) = lim sup
n→∞
Bn(ε). By the
Borel–Cantelli lemma, μ(B(ε)) = 0. Let N = ∞
n=1 B (1/n). Then μ(N) = 0 and
fn(ω)
n→∞
−→f (ω)
for any ω ∈Ω \ N.
Assume (iii). Let Bn = {d(fn, fn+1) > εn} and B = lim sup
n→∞
Bn. Then μ(B) = 0
and (fn(ω))n∈N is a Cauchy sequence in E for any ω ∈Ω \B. Since E is complete,
the limit f (ω) := limn→∞fn(ω) exists. For ω ∈B, deﬁne f (ω) = 0.
⊓⊔
Corollary 6.13 Let (E, d) be a separable metric space. Let f, f1, f2, . . . be
measurable maps Ω →E. Then the following statements are equivalent.
(i) fn
n→∞
−→f in measure.
(ii) For any subsequence of (fn)n∈N, there exists a sub-subsequence that converges
to f almost everywhere.
Proof “(ii) ⇒(i)”
Assume that (i) does not hold. Let ˜d be a metric that induces
convergence in measure (see Theorem 6.7). Then there exists an ε > 0 and a
subsequence (fnk)k∈N with ˜d(fnk, f ) > ε for all k ∈N. Clearly, no subsequence of
(fnk)k∈N converges to f in measure; hence neither converges almost everywhere.
“(i) ⇒(ii)”
Now assume (i). Let A1, A2, . . . ∈A with AN ↑Ω and μ(AN) <
∞for any N ∈N. Since fnk
meas
−→f for k →∞, we can choose a subsequence
(fnkl )l∈N such that μ

Al ∩

d

f, fnkl

> 1/l

< 2−l for any l ∈N. Hence, for
each N ∈N, we have
∞

l=1
μ

AN ∩

df, fnkl
 > 1
l

≤N μ(AN) +
∞

l=N+1
2−l < ∞.
By Theorem 6.12(ii), (fnkl )l∈N converges to f almost everywhere on AN. By
Remark 6.3, (fnkl )l∈N converges to f almost everywhere.
⊓⊔
Corollary 6.14 Let (Ω, A, μ) be a measure space in which almost everywhere
convergence and convergence in measure do not coincide. Then there does not exist
a topology on the set of measurable maps Ω →E that induces almost everywhere
convergence.
Proof Assume that there does exist a topology that induces almost everywhere
convergence. Let f, f1, f2, . . . be measurable maps with the property that fn
meas
−→
f , but not fn
n→∞
−→f almost everywhere. Now let U be an open set that contains f ,
but with fn ̸∈U for inﬁnitely many n ∈N. Hence, let (fnk)k∈N be a subsequence
with fnk ̸∈U for all k ∈N. Since fnk
k→∞
−→f in measure, by Corollary 6.13,
there exists a further subsequence (fnkl )l∈N of (fnk)k∈N with fnkl
l→∞
−→f almost

152
6
Convergence Theorems
everywhere. However, then fnkl ∈U for all but ﬁnitely many l, which yields a
contradiction!
⊓⊔
Corollary 6.15 Let (E, d) be a separable complete metric space. Let (fn)n∈N be a
Cauchy sequence in measure in E; that is, for any A ∈A with μ(A) < ∞and any
ε > 0, we have
μA ∩{d(fm, fn) > ε} −→0
for m, n →∞.
Then (fn)n∈N converges in measure.
Proof Without loss of generality, we may assume μ(Ω) < ∞. Choose a subse-
quence (fnk)k∈N such that
μ
	
d(fn, fnk) > 2−k

< 2−k
for all n ≥nk.
By Theorem 6.12(iii), there is an f with fnk
k→∞
−→f almost everywhere; hence, in
particular, μ({d(fnk, f ) > ε/2})
k→∞
−→0 for all ε > 0. Now
μ({d(fn, f ) > ε}) ≤μ({d(fnk, fn) > ε/2}) + μ({d(fnk, f ) > ε/2}).
If k is large enough that 2−k < ε/2 and if n ≥nk, then the ﬁrst summand is smaller
than 2−k. Hence we have μ({d(fn, f ) > ε})
n→∞
−→0; that is, fn
meas
−→f .
⊓⊔
Takeaways Almost everywhere (almost sure) convergence implies stochas-
tic convergence. Also L1-convergence implies stochastic convergence. The
opposite implications hold only under an additional condition of summability
(see Theorem 6.12).
Exercise 6.1.1 Let Ω be countable. Show that convergence in probability implies
almost everywhere convergence. ♣
Exercise 6.1.2 Give an example of a sequence that
(i) converges in L1 but not almost everywhere,
(ii) converges almost everywhere but not in L1. ♣
Exercise 6.1.3 (Egorov’s theorem (1911))
Let (Ω, A, μ) be a ﬁnite measure
space and let f1, f2, . . . be measurable functions that converge to some f almost
everywhere. Show that, for every ε > 0, there is a set A ∈A with μ(Ω \ A) < ε
and supω∈A |fn(ω) −f (ω)|
n→∞
−→0. ♣

6.2
Uniform Integrability
153
Exercise 6.1.4 Let (Xi)i∈N be independent, square integrable random variables
with E[Xi] = 0 for all i ∈N.
(i) Show that ∞
i=1 Var[Xi] < ∞implies that there exists a real random variable
X with n
i=1 Xi
n→∞
−→X almost surely.
(ii) Does the converse implication hold in (i)? ♣
6.2
Uniform Integrability
From the preceding section, we can conclude that convergence in measure plus
existence of L1 limit points implies L1-convergence.Hence convergence in measure
plus relative sequential compactness in L1 yields convergence in L1. In this section,
we study a criterion for relative sequential compactness in L1, the so-called uniform
integrability.
Deﬁnition 6.16 A family F ⊂L1(μ) is called uniformly integrable if
inf
0≤g∈L1(μ) sup
f ∈F
 
|f | −g
+ dμ = 0.
(6.2)
Theorem 6.17 The family F ⊂L1(μ) is uniformly integrable if and only if
inf
0≤g ∈L1(μ)
sup
f ∈F

{|f |>g}
|f | dμ = 0.
(6.3)
If μ(Ω) < ∞, then uniform integrability is equivalent to either of the following two
conditions:
(i)
inf
a∈[0,∞) sup
f ∈F

(|f | −a)+ dμ = 0,
(ii)
inf
a∈[0,∞) sup
f ∈F

{|f |>a}
|f | dμ = 0.
Proof Clearly, (|f |−g)+ ≤|f |·1{|f |>g}; hence (6.3) implies uniform integrability.
Now assume (6.2). For ε > 0, choose gε ∈L1(μ) such that
sup
f ∈F

(|f | −gε)+ dμ ≤ε.
(6.4)
Deﬁne 
gε = 2gε/2. Then, for f ∈F,

{|f |>
gε}
|f | dμ ≤

{|f |>
gε}
(|f | −gε/2)+ dμ +

{|f |>
gε}
gε/2 dμ.

154
6
Convergence Theorems
By construction,
3
{|f |>
gε}(|f | −gε/2)+ dμ ≤ε/2 and
gε/2 1{|f |>
gε} ≤

|f | −gε/2
+ 1{|f |>
gε};
hence also

{|f |>
gε}
gε/2 dμ ≤

{|f |>
gε}
(|f | −gε/2)+ dμ ≤ε
2.
Summing up, we have
sup
f ∈F

{|f |>
gε}
|f | dμ ≤ε.
(6.5)
Clearly, (ii) implies (i). If μ(Ω) < ∞, then (i) implies uniform integrability of F
since the inﬁmum is taken over the smaller set of constant functions. We still have
to show that uniform integrability implies (ii). Accordingly, assume F is uniformly
integrable (but not necessarily μ(Ω) < ∞). For any ε > 0 (and gε and ˜gε as above),
choose aε such that
3
{gε/2>aε} gε/2 dμ < ε
2. Then

{|f |>aε}
|f | dμ ≤

{|f |>gε/2}
|f | dμ +

{gε/2>aε}
gε/2 dμ < ε.
⊓⊔
Theorem 6.18
(i) If F ⊂L1(μ) is a ﬁnite set, then F is uniformly integrable.
(ii) If F, G ⊂L1(μ) are uniformly integrable, then (f + g :
f ∈F, g ∈G),
(f −g : f ∈F, g ∈G) and {|f | : f ∈F} are also uniformly integrable.
(iii) If F is uniformly integrable and if, for any g ∈G, there exists an f ∈F with
|g| ≤|f |, then G is also uniformly integrable.
Proof The proof is simple and is left as an exercise.
⊓⊔
The following theorem describes a very useful criterion for uniform integrability.
We will use it in many places.
Theorem 6.19 For ﬁnite μ, F ⊂L1(μ) is uniformly integrable if and only if there
is a measurable function H : [0, ∞) →[0, ∞) with limx→∞H(x)/x = ∞and
sup
f ∈F

H(|f |) dμ < ∞.
H can be chosen to be monotone increasing and convex.

6.2
Uniform Integrability
155
Proof “ ⇐ ”
Assume there is an H with the advertised properties. Then Ka :=
infx≥a H(x)
x
↑∞if a ↑∞. Hence, for a > 0,
sup
f ∈F

{|f |≥a}
|f | dμ ≤1
Ka
sup
f ∈F

{|f |≥a}
H(|f |) dμ
≤1
Ka
sup
f ∈F

H (|f |) dμ
a→∞
−→0.
“ ⇒”
Assume F is uniformly integrable. As we have μ(Ω) <
∞, by
Theorem 6.17, there exists a sequence an ↑∞with
sup
f ∈F

(|f | −an)+ dμ < 2−n.
Deﬁne
H(x) =
∞

n=1
(x −an)+
for any x ≥0.
As a sum of convex functions, H is convex. Further, for any n ∈N and x ≥2an,
H(x)/x ≥n
k=1(1 −ak/x)+ ≥n/2; hence we have H(x)/x ↑∞. Finally, by
monotone convergence, for any f ∈F,

H(|f (ω)|) μ(dω) =
∞

n=1

(|f | −an)+ dμ ≤
∞

n=1
2−n = 1.
⊓⊔
Reﬂection In the above theorem, why did we need that μ is ﬁnite? Can you come
up with a counterexample for the case μ(Ω) = ∞? Which part of the theorem
would still hold? ♠
Recall the notation ∥· ∥p from Deﬁnition 4.16.
Deﬁnition 6.20 Let p ∈[1, ∞]. A family F ⊂Lp(μ) is called bounded in Lp(μ)
if sup{∥f ∥p : f ∈F} < ∞.
Corollary 6.21 Let μ(Ω) < ∞and p > 1. If F is bounded in Lp(μ), then F is
uniformly integrable.
Proof Apply Theorem 6.19 with the convex map H(x) = xp.
⊓⊔
Corollary 6.22 If (Xi)i∈I is a family of square integrable random variables with
sup{|E[Xi]| : i ∈I} < ∞
and
sup{Var[Xi] : i ∈I} < ∞,
then (Xi)i∈I is uniformly integrable.

156
6
Convergence Theorems
Proof Since E[X2
i ] = E[Xi]2 + Var[Xi], i ∈I, is bounded, this follows from
Corollary 6.21 with p = 2.
⊓⊔
Lemma 6.23 There is a map h ∈L1(μ) with h > 0 almost everywhere.
Proof Let A1, A2, . . . , ∈A with An ↑Ω and μ(An) < ∞for all n ∈N. Deﬁne
h =
∞

n=1
2−n
1 + μ(An))−1 1An.
Then h > 0 almost everywhere and
3
h dμ =
∞

n=1
2−n
μ(An)
1+μ(An) ≤1.
⊓⊔
Theorem 6.24 A family F ⊂L1(μ) is uniformly integrable if and only if the
following two conditions are fulﬁlled.
(i) C := sup
f ∈F

|f | dμ < ∞.
(ii) There is a function 0 ≤h ∈L1(μ) such that for any ε > 0, there is a δ(ε) > 0
with
sup
f ∈F

A
|f | dμ ≤ε
for all A ∈A such that

A
h dμ < δ(ε).
If μ(Ω) < ∞, then (ii) is equivalent to (iii):
(iii) For all ε > 0, there is a δ(ε) > 0 such that
sup
f ∈F

A
|f | dμ ≤ε
for all A ∈A with μ(A) < δ(ε).
Proof “ ⇒”
Let F be uniformly integrable. Let h ∈L1(μ) with h > 0 a.e. Let
ε > 0 and let gε/3 be an ε/3-bound for F (as in (6.5)). Since
	
gε/3 ≥αh

↓∅for
α →∞, for sufﬁciently large α = α(ε), we have

{gε/3≥αh}
gε/3 dμ < ε
3.
Letting δ(ε) :=
ε
3α(ε), we get for any A ∈A with
3
A h dμ < δ(ε) and any f ∈F,

A
|f | dμ ≤

{|f |>gε/3}
|f | dμ +

A
gε/3 dμ
≤ε
3 + α

A
h dμ +

{gε/3≥αh}
gε/3 dμ ≤ε.

6.2
Uniform Integrability
157
Hence we have shown (ii). In the above computation, let A = Ω to obtain

|f | dμ ≤2ε
3 + α

h dμ < ∞.
Hence we have also shown (i).
“ ⇐ ”
Assume (i) and (ii). Let ε > 0. Choose h and δ(ε) > 0 as in (ii) and C as
in (i). Deﬁne h =
C
δ(ε)h. Then

{|f |>h}
h dμ = δ(ε)
C

{|f |>h}
h dμ ≤δ(ε)
C

|f | dμ ≤δ(ε);
hence, by assumption,
3
{|f |>h} |f | dμ < ε.
“(ii) ⇒(iii)”
Assume (ii). Let ε > 0 and choose δ = δ(ε) as in (ii). Choose
K < ∞large enough that
3
{h≥K} h dμ < δ/2. For all A ∈A with μ(A) < δ/(2K),
we obtain

A
h dμ ≤Kμ(A) +

{h≥K}
h dμ < δ;
hence
3
A |f | dμ ≤ε for all f ∈F.
“(iii) ⇒(ii)”
Assume (iii) and μ(Ω) < ∞. Then h ≡1 serves the purpose.
⊓⊔
We come to the main theorem of this section.
Theorem 6.25 Let {fn
:
n ∈N} ⊂L1(μ). The following statements are
equivalent.
(i) There is an f ∈L1(μ) with fn
n→∞
−→f in L1.
(ii) (fn)n∈N is an L1(μ)-Cauchy sequence; that is, ∥fn−fm∥1 −→0 for m, n →
∞.
(iii) (fn)n∈N is uniformly integrable and there is a measurable map f such that
fn
meas
−→f .
The limits in (i) and (iii) coincide.
Proof “(i) ⇒(ii)”
This is evident.
“(ii) ⇒(iii)”
For any ε > 0, there is an nε ∈N such that ∥fn −fnε∥1 < ε
for all n ≥nε. Hence ∥(|fn| −|fnε|)+∥1 < ε for all n ≥nε. Thus gε =
max{|f1|, . . . , |fnε|} is an ε-bound for (fn)n∈N (as in (6.4)). For ε > 0, let
μ

{|fm −fn| > ε}

≤ε−1 ∥fm −fn∥1 −→0
for m, n →∞.
Thus (fn)n∈N is also a Cauchy sequence in measure; hence it converges in measure
by Corollary 6.15.

158
6
Convergence Theorems
“(iii) ⇒(i)”
Let f be the limit in measure of the sequence (fn)n∈N. Assume that
(fn)n∈N does not converge to f in L1. Then there is an ε > 0 and a subsequence
(fnk)k∈N with
∥f −fnk∥1 > 2ε
for all k ∈N.
(6.6)
Here we deﬁne ∥f −fnk∥1 = ∞if f ̸∈L1(μ). By Corollary 6.13, there is a
subsequence (fn′
k)k∈N of (fnk)k∈N with fn′
k
k→∞
−→f almost everywhere. By Fatou’s
lemma (Theorem 4.21) with 0 as a minorant, we thus get

|f | dμ ≤lim inf
k→∞

|fn′
k| dμ < ∞.
Hence f ∈L1(μ). By Theorem 6.18(ii) (with G = {f }), we obtain that the family
(f −fn′
k)k∈N is uniformly integrable; hence there is a 0 ≤g ∈L1(μ) such that
3
(|f −fn′
k| −g)+ dμ < ε. Deﬁne
gk = |fn′
k −f | ∧g
for k ∈N.
Then gk
k→∞
−→0 almost everywhere and g −gk ≥0. By Fatou’s lemma,
lim sup
k→∞

gk dμ =

g dμ −lim inf
k→∞

(g −gk) dμ
≤

g dμ −
 
lim
k→∞(g −gk)

dμ = 0.
Since |f −fn′
k| = (|f −fn′
k| −g)+ + gk, this implies that
lim sup
k→∞
∥f −fn′
k∥1 ≤lim sup
k→∞
 
|f −fn′
k| −g
+ dμ + lim sup
k→∞

gk dμ ≤ε,
contradicting (6.6).
⊓⊔
Corollary 6.26 (Lebesgue’s convergence theorem, dominated convergence) Let
f be measurable and let (fn)n∈N be a sequence in L1(μ) with fn
n→∞
−→
f
in
measure. Assume that there is an integrable dominating function 0 ≤g ∈L1(μ)
with |fn| ≤g almost everywhere for all n ∈N. Then f ∈L1(μ) and fn
n→∞
−→f
in L1; hence in particular
3
fn dμ
n→∞
−→
3
f dμ.
Proof This is a consequence of Theorem 6.25, as the dominating function ensures
uniform integrability of the sequence (fn)n∈N.
⊓⊔

6.2
Uniform Integrability
159
Convergence
almost
everywhere
Stochastic
convergence
L1 convergence
subsequence
subsequence
uniform
integrability
uniform
integrability
Fig. 6.1 Implications between the concepts of convergence.
Takeaways Loosely speaking, a family of functions is uniformly integrable
if the main contributions to the integrals of those functions do not come from
extremely large values of the functions. Together with stochastic convergence,
uniform integrability is equivalent to L1-convergence (see Fig. 6.1). As a
consequence we get Lebesgue’s dominated convergence theorem.
Exercise 6.2.1 Let H ∈L1(μ) with H > 0
μ-a.e. (see Lemma 6.23) and let
(E, d) be a separable metric space. For measurable f, g : Ω →E, deﬁne
dH(f, g) :=
 1 ∧d(f (ω), g(ω)) H(ω) μ(dω).
(i) Show that dH is a metric that induces convergence in measure.
(ii) Show that dH is complete if (E, d) is complete. ♣

160
6
Convergence Theorems
6.3
Exchanging Integral and Differentiation
We study how properties such as continuity and differentiability of functions of two
variables behave under integration with respect to one of the variables.
Theorem 6.27 (Continuity lemma) Let (E, d) be a metric space, x0 ∈E and let
f : Ω × E →R be a map with the following properties.
(i) For any x ∈E, the map ω →f (ω, x) is in L1(μ).
(ii) For almost all ω ∈Ω, the map x →f (ω, x) is continuous at the point x0.
(iii) There is a map h ∈L1(μ), h ≥0, such that |f ( ·, x)| ≤h
μ-a.e. for all
x ∈E.
Then the map F : E →R, x →
3
f (ω, x) μ(dω) is continuous at x0.
Proof Let (xn)n∈N be a sequence in E with lim
n→∞xn = x0. Deﬁne fn = f ( ·, xn).
By assumption, |fn| ≤h and fn
n→∞
−→
f ( ·, x0) almost everywhere. By the
dominated convergence theorem (Corollary 6.26), we get
F(xn) =

fn dμ
n→∞
−→

f ( ·, x0) dμ = F(x0).
Hence F is continuous at x0.
⊓⊔
Reﬂection Find an example that shows that condition (iii) in Theorem 6.27 cannot
simply be dropped. ♠
Theorem 6.28 (Differentiation lemma) Let I ⊂R be a nontrivial open interval
and let f : Ω × I →R be a map with the following properties.
(i) For any x ∈E, the map ω →f (ω, x) is in L1(μ).
(ii) For almost all ω ∈Ω, the map I →R, x →f (ω, x) is differentiable with
derivative f ′.
(iii) There is a map h ∈L1(μ), h ≥0, such that |f ′( ·, x)| ≤h μ-a.e. for all
x ∈I.
Then, for any x ∈I, f ′( ·, x) ∈L1(μ) and the function F : x →
3
f (ω, x) μ(dω)
is differentiable with derivative
F ′(x) =

f ′(ω, x) μ(dω).
Proof Let x0 ∈I and let (xn)n∈N be a sequence in I with xn ̸= x0 for all n ∈N and
such that lim
n→∞xn = x0. We show that, along the sequence (xn)n∈N, the difference
quotients converge. Deﬁne
gn(ω) = f (ω, xn) −f (ω, x0)
xn −x0
for all ω ∈Ω.

6.3
Exchanging Integral and Differentiation
161
By assumption (ii), we have
gn
n→∞
−→f ′( ·, x0)
μ-almost everywhere.
By the mean value theorem of calculus, for all n ∈N and for almost all ω ∈Ω,
there exists a yn(ω) ∈I with gn(ω) = f ′(ω, yn(ω)). In particular, |gn| ≤h almost
everywhere for all n ∈N. By the dominated convergence theorem (Corollary 6.26),
the limiting function f ′( ·, x0) is in L1(μ) and
lim
n→∞
F(xn) −F(x0)
xn −x0
=
lim
n→∞

gn(ω) μ(dω) =

f ′(ω, x0) μ(dω).
⊓⊔
Example 6.29 (Laplace transform) Let X be a nonnegative random variable on
(Ω, A, P). Using the notation of Theorem 6.28, let I = [0, ∞) and f (x, λ) = e−λx
for λ ∈I. Then
F(λ) = E
)
e−λX*
is inﬁnitely often differentiable in (0, ∞). The ﬁrst two derivatives of F are
F ′(λ) = −E[Xe−λX] and F ′′(λ) = E[(X2)e−λX]. Successively, we get the nth
derivative F (n)(λ) = E[(−X)ne−λX]. By monotone convergence, we get
E[X] = −lim
λ↓0 F ′(λ)
(6.7)
and
E[Xn] = (−1)n lim
λ↓0 F (n)(λ)
for all n ∈N.
(6.8)
Indeed, for ε > 0 and I = (ε, ∞), we have
sup
x≥0, λ∈I

d
dλf (x, λ)
 =
sup
x≥0, λ∈I
x e−λx = ε−1e−1 < ∞.
Thus F fulﬁlls the assumptions of Theorem 6.28. Inductively, we get the statement
for F (n) since

dn
dλn f (x, λ)
 ≤(n/ε)ne−n < ∞
for x ≥0 and λ ≥ε.
♦

162
6
Convergence Theorems
Takeaways Consider a function of two variables that is continuous or
differentiable with respect to one variable. Take the integral with respect to
the other variable. We have used the convergence theorems from the last
section to show that the integral is continuous or differentiable, respectively,
if a regularity assumption is fulﬁlled. In this case, integral and derivative
commute.
Exercise 6.3.1 Let X be a random variable on (Ω, A, P) and let
Λ(t) := log

E
)
etX*
for all t ∈R.
Show that D := {t ∈R : Λ(t) < ∞} is a nonempty interval and that Λ is inﬁnitely
often differentiable in the interior of D. ♣

Chapter 7
Lp-Spaces and the Radon–Nikodym
Theorem
In this chapter, we study the spaces of functions whose pth power is integrable. In
Sect. 7.2, we ﬁrst derive some of the important inequalities (Hölder, Minkowski,
Jensen) and then in Sect. 7.3 investigate the case p = 2 in more detail. Apart
from the inequalities, the important results for probability theory are Lebesgue’s
decomposition theorem and the Radon–Nikodym theorem in Sect. 7.4. At ﬁrst
reading, some readers might wish to skip some of the more analytic parts of this
chapter.
7.1
Deﬁnitions
We always assume that (Ω, A, μ) is a σ-ﬁnite measure space. In Deﬁnition 4.16,
for measurable f : Ω →R, we deﬁned
∥f ∥p :=

|f |p dμ
1/p
for p ∈[1, ∞)
and
∥f ∥∞:= inf
	
K ≥0 : μ(|f | > K) = 0

.
Further, we deﬁned the spaces of functions where these expressions are ﬁnite:
Lp(Ω, A, μ) = Lp(A, μ) = Lp(μ) = {f : Ω →R measurable and ∥f ∥p < ∞}.
We saw that ∥· ∥1 is a seminorm on L1(μ). Here our ﬁrst goal is to change ∥· ∥p
into a proper norm for all p ∈[1, ∞]. Apart from the fact that we still have to show
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_7
163

164
7
Lp-Spaces and the Radon–Nikodym Theorem
the triangle inequality, to this end, we have to change the space a little bit since we
only have
∥f −g∥p = 0
⇐⇒
f = g
μ-a.e.
For a proper norm (that is, not only a seminorm), the left-hand side has to imply
equality (not only a.e.) of f and g. Hence we now consider f and g as equivalent if
f = g almost everywhere. Thus let
N = {f is measurable and f = 0
μ-a.e.}.
For any p ∈[1, ∞], N is a subvector space of Lp(μ). Thus formally we can build
the factor space. This is the standard procedure in order to change a seminorm into
a proper norm.
Deﬁnition 7.1 (Factor space)
For any p ∈[1, ∞], deﬁne
Lp(Ω, A, μ) := Lp(Ω, A, μ)/N = { ¯f := f + N : f ∈Lp(μ)}.
For ¯f ∈Lp(μ), deﬁne
;; ¯f
;;
p = ∥f ∥p for any f ∈¯f . Also let
3 ¯f dμ =
3
f dμ if
this expression is deﬁned for f .
Note that
;; ¯f
;;
p and
3 ¯f dμ do not depend on the choice of the representative f ∈¯f .
Recall from Theorem 4.19 that
3 ¯f dμ is well-deﬁned if f ∈Lp(μ) and if μ is ﬁnite
but it need not be if μ is inﬁnite.
We ﬁrst investigate convergence with respect to ∥· ∥p. To this end, we extend
the corresponding theorem (Theorem 6.25) on convergence with respect to ∥· ∥1.
Deﬁnition 7.2 Let p ∈[1, ∞] and f, f1, f2, . . . ∈Lp(μ). If ∥fn −f ∥p
n→∞
−→0,
then we say that (fn)n∈N converges to f in Lp(μ) and we write fn
Lp
−→f.
Theorem 7.3 Let p ∈[1, ∞] and f1, f2, . . . ∈Lp(μ). Then the following
statements are equivalent:
(i) There is an f ∈Lp(μ) with fn
Lp
−→f .
(ii) (fn)n∈N is a Cauchy sequence in Lp(μ).
If p < ∞, then, in addition, (i) and (ii) are equivalent to:
(iii) (|fn|p)n∈N is uniformly integrable and there exists a measurable f with
fn
meas
−→f .
The limits in (i) and (iii) coincide.
Proof For p = ∞, the equivalence of (i) and (ii) is a simple consequence of the
triangle inequality.

7.2
Inequalities and the Fischer–Riesz Theorem
165
Now let p ∈[1, ∞). The proof is similar to the proof of Theorem 6.25.
“(i) ⇒(ii)”
Note that |x + y|p ≤2p (|x|p + |y|p) for all x, y ∈R. Hence
∥fm −fn∥p
p ≤2p ∥fm −f ∥p
p + ∥fn −f ∥p
p
 n→∞
−→0
for m, n →∞.
“(ii) ⇒(iii)”
This works as in the proof of Theorem 6.25.
“(iii) ⇒(i)”
Since |fn|p
n→∞
−→
|f |p in measure, by Theorem 6.25, we have
|f |p ∈L1(μ) and hence f ∈Lp(μ). For n ∈N, deﬁne gn = |fn −f |p.
Then gn
n→∞
−→
0 in measure, and (gn)n∈N is uniformly integrable since gn ≤
2p (|fn|p + |f |p). Hence we get (by Theorem 6.25) ∥fn −f ∥p
p = ∥gn∥1
n→∞
−→0.
⊓⊔
Takeaways We have adapted the convergence theorems of the last chapter to
Lp convergence. This is the starting point for the investigation of topological
properties of Lp spaces in the subsequent sections.
Exercise 7.1.1 Let f : Ω →R be measurable. Show that the following hold.
(i) If
3
|f |p dμ < ∞for some p ∈(0, ∞), then ∥f ∥p
p→∞
−→∥f ∥∞.
(ii) The integrability condition in (i) cannot be waived. ♣
Exercise 7.1.2 Let p ∈(1, ∞), f ∈Lp(λ), where λ is the Lebesgue measure on
R. Let T : R →R, x →x + 1. Show that
1
n
n−1

k=0
f ◦T k n→∞
−→0
in Lp(λ).
♣
7.2
Inequalities and the Fischer–Riesz Theorem
We present one of the most important inequalities of probability theory, Jensen’s
inequality for convex functions, and indicate how to derive from it Hölder’s
inequality and Minkowski’s inequality. They in turn yield the triangle inequality
for ∥· ∥p and help in determining the dual space of Lp(μ). However, for the formal
proofs of the latter inequalities, we will follow a different route.
Before stating Jensen’s inequality, we give a primer on the basics of convexity of
sets and functions.
Deﬁnition 7.4 A subset G of a vector space (or of an afﬁne linear space) is called
convex if, for any two points x, y ∈G and any λ ∈[0, 1], we have λx + (1 −
λ)y ∈G.

166
7
Lp-Spaces and the Radon–Nikodym Theorem
Example 7.5
(i) The convex subsets of R are the intervals.
(ii) A linear subspace of a vector space is convex.
(iii) The set of all probability measures on a measurable space is a convex set. ♦
Deﬁnition 7.6 Let G be a convex set. A map ϕ : G →R is called convex if for
any two points x, y ∈G and any λ ∈[0, 1], we have
ϕλx + (1 −λ)y ≤λ ϕ(x) + (1 −λ) ϕ(y).
ϕ is called concave if (−ϕ) is convex.
Let I ⊂R be an interval. Let ϕ : I →R be continuous and in the interior
I ◦twice continuously differentiable with second derivative ϕ′′. Then ϕ is convex if
and only if ϕ′′(x) ≥0 for all x ∈I ◦. To put it differently, the ﬁrst derivative ϕ′ of a
convex function is a monotone increasing function. In the next theorem, we will see
that this is still true even if ϕ is not twice continuously differentiable when we pass
to the right-sided derivative D+ϕ (or to the left-sided derivative), which we show
always exists.
Theorem 7.7 Let I ⊂R be an interval with interior I ◦and let ϕ : I →R be a
convex map. Then:
(i) ϕ is continuous on I ◦and hence measurable with respect to B(I).
(ii) For x ∈I ◦, deﬁne the function of difference quotients
gx(y) := ϕ(y) −ϕ(x)
y −x
for y ∈I \ {x}.
Then gx is monotone increasing and there exist the left-sided and right-sided
derivatives
D−ϕ(x) := lim
y↑x gx(y) = sup{gx(y) : y < x}
and
D+ϕ(x) := lim
y↓x gx(y) = inf{gx(y) : y > x}.
(iii) For x ∈I ◦, we have D−ϕ(x) ≤D+ϕ(x) and
ϕ(x) + (y −x)t ≤ϕ(y) for any y ∈I
⇐⇒
t ∈[D−ϕ(x), D+ϕ(x)].
Hence D−ϕ(x) and D+ϕ(x) are the minimal and maximal slopes of a tangent
at x.

7.2
Inequalities and the Fischer–Riesz Theorem
167
(iv) The maps x →D−ϕ(x) and x →D+ϕ(x) are monotone increasing. x →
D−ϕ(x) is left continuous and x →D+ϕ(x) is right continuous. We have
D−ϕ(x) = D+ϕ(x) at all points of continuity of D−ϕ and D+ϕ.
(v) ϕ is differentiable at x if and only if D−ϕ(x) = D+ϕ(x). In this case, the
derivative is ϕ′(x) = D+ϕ(x).
(vi) ϕ is almost everywhere differentiable and ϕ(b) −ϕ(a) =
3 b
a D+ϕ(x) dx for
a, b ∈I ◦.
Proof
(i) Let x ∈I ◦. Assume that lim infh↓0 ϕ(x −h) ≤ϕ(x)−ε for some ε > 0. Since
ϕ is convex, for y ∈I ◦such that y > x, we have
ϕ(y) ≥ϕ(x) + y −x
h
ϕ(x) −ϕ(x −h)
for all h > 0 with x −h ∈I ◦.
Combining this with the assumption, we get ϕ(y) = ∞for all y > x. Hence
the assumption was false. A similar argument for the right-hand side yields
continuity of ϕ at x.
(ii) Monotonicity is implied by convexity. The other claims are evident.
(iii) By monotonicity of gx, we have D−ϕ(x) ≤D+ϕ(x). By construction, ϕ(x)+
(y −x)t ≤ϕ(y) for all y < x if and only if t ≥D−ϕ(x). The inequality holds
for all y > x if and only if t ≤D+ϕ(x).
(iv) For ε > 0, by the convexity, the map x →gx(x + ε) is monotone increasing
and is continuous by (i). Being an inﬁmum of monotone increasing and
continuous functions the map x →D+ϕ(x) is monotone increasing and
right continuous. The statement for D−ϕ follows similarly. As x →gx(y)
is monotone, we get D+ϕ(x′) ≥D−ϕ(x′) ≥D+ϕ(x) for x′ > x. If D+ϕ is
continuous at x, then D−ϕ(x) = D+ϕ(x).
(v) This is obvious since D−ϕ and D+ϕ are the limits of the sequences of slopes
of the left-sided and right-sided secant lines, respectively.
(vi) For ε > 0, let Aε = {x ∈I : D+ϕ(x) ≥ε + limy↑x D+ϕ(y)} be the set
of points of discontinuity of size at least ε. For any two points a, b ∈I with
a < b, we have #(Aε ∩(a, b)) ≤ε−1(D+ϕ(b) −D+ϕ(a)); hence Aε ∩(a, b)
is a ﬁnite set. Thus Aε is countable. Hence also A = ∞
n=1 A1/n is countable
and thus a null set. By (iv) and (v), ϕ is differentiable in I ◦\ A with derivative
D+ϕ.
⊓⊔
If I is an interval, then a map g : I →R is called afﬁne linear if there are numbers
a, b ∈R such that g(x) = ax + b for all x ∈I. If ϕ : I →R is a map, then we
write
L(ϕ) := 	g : I →R is afﬁne linear and g ≤ϕ
.
As a shorthand, we write sup L(ϕ) for the map x →sup{f (x) : f ∈L(ϕ)}.

168
7
Lp-Spaces and the Radon–Nikodym Theorem
Corollary 7.8 Let I ⊂R be an open interval and let ϕ : I →R be a map. Then
the following are equivalent.
(i) ϕ is convex.
(ii) For any x0 ∈I, there exists a g ∈L(ϕ) with g(x0) = ϕ(x0) .
(iii) L(ϕ) is nonempty and ϕ = sup L(ϕ).
(iv) There is a sequence (gn)n∈N in L(ϕ) with ϕ = limn→∞max{g1, . . . , gn}.
Furthermore, if I ⊂R is an interval (not necessarily open) and ϕ : I →R is
convex, then we still have L(ϕ) ̸= ∅.
Proof “(ii) ⇒(iii) ⇐⇒(iv)”
This is obvious.
“(iii) ⇒(i)”
The supremum of convex functions is convex and any afﬁne linear
map is convex. Hence sup L(ϕ) is convex if L(ϕ) ̸= ∅.
“(i) ⇒(ii)”
By Theorem 7.7(iii), for any x0 ∈I, the map
x →ϕ(x0) + (x −x0) D+ϕ(x0)
is in L(ϕ).
Since for the implication “(i) ⇒(ii)” we did not need that I is open, we get the
supplementary statement.
⊓⊔
Theorem 7.9 (Jensen’s inequality) Let I ⊂R be an interval and let X be an
I-valued random variable with E[|X|] < ∞. If ϕ is convex, then E[ϕ(X)−] < ∞
and
E[ϕ(X)] ≥ϕ(E[X]).
Proof As L(ϕ) ̸= ∅by Corollary 7.8, we can choose numbers a, b ∈R such that
ax + b ≤ϕ(x) for all x ∈I. Hence
E[ϕ(X)−] ≤E[(aX + b)−] ≤|b| + |a| · E[|X|] < ∞.
We distinguish the cases where E[X] is in the interior I ◦or at the boundary ∂I.
Case 1. If E[X] ∈I ◦, then let t+ := D+ϕ(E[X]) be the maximal slope of a tangent
of ϕ at E[X]. Then ϕ(x) ≥t+ · (x −E[X]) + ϕ(E[X]) for all x ∈I; hence
E[ϕ(X)] ≥t+ E[X −E[X]] + E[ϕ(E[X])] = ϕ(E[X]).
Case 2. If E[X] ∈∂I, then X = E[X] a.s.; hence E[ϕ(X)] = E[ϕ(E[X])] =
ϕ(E[X]).
⊓⊔
Jensen’s inequality can be extended to Rn. To this end, we need a representation
of convex functions of many variables as a supremum of afﬁne linear functions.
Recall that a function g : Rn →R is called afﬁne linear if there is an a ∈Rn and

7.2
Inequalities and the Fischer–Riesz Theorem
169
a b ∈R such that g(x) = ⟨a, x⟩+ b for all x. Here ⟨·, ·⟩denotes the usual inner
product on Rn.
Theorem 7.10 Let G ⊂Rn be open and convex and let ϕ : G →R be a map.
Then Corollary 7.8 holds with I replaced by G. If ϕ is convex, then ϕ is continuous
and hence measurable. If ϕ is twice continuously differentiable, then ϕ is convex if
and only if the Hessian matrix is positive semideﬁnite.
Proof As we need these statements only in the proof of the multidimensional
Jensen inequality, which will not play a central role in the following, we only
give references for the proofs. In Rockafellar’s book [146], continuity follows from
Theorem 10.1, and the statements of Corollary 7.8 follow from Theorem 12.1 and
Theorem 18.8. The claim about the Hessian matrix can be found in Theorem 4.5.
⊓⊔
Theorem 7.11 (Jensen’s inequality in Rn) Let G ⊂Rn be a convex set and let
X1, . . . , Xn be integrable real random variables with P[(X1, . . . , Xn) ∈G] = 1.
Further, let ϕ : G →R be convex. Then E[ϕ(X1, . . . , Xn)−] < ∞and
E
)
ϕ(X1, . . . , Xn)
*
≥ϕ(E[X1], . . . , E[Xn]).
Proof First consider the case where G is open. Here, the argument is similar to the
proof of Theorem 7.9. Let g ∈L(ϕ) with
gE[X1], . . . , E[Xn] = ϕE[X1], . . . , E[Xn].
As g ≤ϕ is linear, we get
E
)
ϕ(X1, . . . , Xn)
*
≥E[g(X1, . . . , Xn)] = g

E[X1], . . . , E[Xn]

.
Integrability of ϕ(X1, . . . , Xn)−can be derived in a similar way to the one-
dimensional case.
Now consider the general case where G is not necessarily open. Here the problem
that arises when (E[X1], . . . , E[Xn]) ∈∂G is a bit more tricky than in the one-
dimensional case since ∂G can have ﬂat pieces that in turn, however, are convex.
Hence one cannot infer that (X1, . . . , Xn) equals its expectation almost surely. We
only sketch the argument. First infer that (X1, . . . , Xn) is almost surely in one of
those ﬂat pieces. This piece is necessarily of dimension smaller than n. Now restrict
ϕ to that ﬂat piece and inductively reduce its dimension until reaching a point, the
case that has already been treated above. Details can be found, e.g., in [37, Theorem
10.2.6].
⊓⊔
Example 7.12 Let X be a real random variable with E[X2] < ∞, I = R and
ϕ(x) = x2. By Jensen’s inequality, we get
Var[X] = E[X2] −(E[X])2 ≥0.
♦

170
7
Lp-Spaces and the Radon–Nikodym Theorem
Example 7.13 Let G = [0, ∞)×[0, ∞), α ∈(0, 1) and ϕ(x, y) = xαy1−α. Then ϕ
is concave (exercise!); hence, for nonnegative random variables X and Y with ﬁnite
expectation (by Theorem 7.11),
E
'
XαY 1−α(
≤(E[X])α (E[Y])1−α.
♦
Example 7.14 Let G, X and Y be as in Example 7.13. Let p ∈(1, ∞). Then
ψ(x, y) =

x1/p + y1/pp is concave. Hence (by Theorem 7.11)

E[X]1/p + E[Y]1/pp
≥E
'
X1/p + Y 1/pp(
.
♦
Before we present Hölder’s inequality and Minkowski’s inequality, we need a
preparatory lemma.
Lemma 7.15 (Young’s inequality) For p, q ∈(1, ∞) with 1
p + 1
q = 1 and for
x, y ∈[0, ∞),
xy ≤xp
p + yq
q .
(7.1)
Proof Fix y ∈[0, ∞) and deﬁne f (x) := xp
p + yq
q −xy for x ∈[0, ∞). f is
twice continuously differentiable in (0, ∞) with derivatives f ′(x) = xp−1 −y and
f ′′(x) = (p −1)xp−2. In particular, f is strictly convex and hence assumes its
(unique) minimum at x0 = y1/(p−1). By assumption, q =
p
p−1; hence xp
0 = yq and
thus
f (x0) =
 1
p + 1
q

yq −y1/(p−1)y = 0.
⊓⊔
Theorem 7.16 (Hölder’s inequality) Let p, q ∈[1, ∞] with 1
p + 1
q = 1 and f ∈
Lp(μ), g ∈Lq(μ). Then (fg) ∈L1(μ) and
∥fg∥1 ≤∥f ∥p · ∥g∥q.
Proof The cases p = 1 and p = ∞are trivial. Hence, let p ∈(1, ∞). Let f ∈
Lp(μ) and g ∈Lq(μ) be nontrivial. By passing to f/∥f ∥p and g/∥g∥q, we may
assume that ∥f ∥p = ∥g∥q = 1. By Lemma 7.15, we have
∥fg∥1 =

|f | · |g| dμ ≤1
p

|f |p dμ + 1
q

|g|q dμ
= 1
p + 1
q = 1 = ∥f ∥p · ∥g∥q.
⊓⊔

7.2
Inequalities and the Fischer–Riesz Theorem
171
Theorem 7.17 (Minkowski’s inequality)
For p ∈[1, ∞] and f, g ∈Lp(μ),
∥f + g∥p ≤∥f ∥p + ∥g∥p.
(7.2)
Proof The case p = ∞is trivial. Hence, let p ∈[1, ∞). The left-hand side in
(7.2) does not decrease if we replace f and g by |f | and |g|. Hence we may assume
f ≥0 and g ≥0 and (to avoid trivialities) ∥f + g∥p > 0.
Now (f + g)p ≤2p(f p ∨gp) ≤2p(f p + gp); hence f + g ∈Lp(μ). Apply
Hölder’s inequality to f · (f + g)p−1 and to g · (f + g)p−1 to get
∥f + g∥p
p =

(f + g)p dμ =

f (f + g)p−1 dμ +

g(f + g)p−1 dμ
≤∥f ∥p · ∥(f + g)p−1∥q + ∥g∥p · ∥(f + g)p−1∥q
= (∥f ∥p + ∥g∥p) · ∥f + g∥p−1
p
.
Note that in the last step, we used the fact that p −p/q = 1. Dividing both sides by
∥f + g∥p−1
p
yields (7.2).
⊓⊔
In Theorem 7.17, we veriﬁed the triangle inequality and hence that ∥· ∥p is a
norm. Theorem 7.3 says that this norm is complete (i.e., every Cauchy sequence
converges). A complete normed vector space is called a Banach space. Summing
up, we have shown the following theorem.
Theorem 7.18 (Fischer–Riesz)
(Lp(μ), ∥· ∥p) is a Banach space for every p ∈
[1, ∞].
Takeaways In this section, we have encountered the most prominent integral
inequalities: Jensen’s inequality for convex functions, Hölder’s inequality
and Minkowski’s inequality. Together with the topological considerations in
Sect. 7.1, these inequalities enabled us to show the celebrated Fischer-Riesz
theorem.
Exercise 7.2.1 Show Hölder’s inequality by applying Jensen’s inequality to the
function of Example 7.13. ♣
Exercise 7.2.2 Show Minkowski’s inequality by applying Jensen’s inequality to the
function of Example 7.14. ♣
Exercise 7.2.3 Let X be a real random variable and let p, q ∈(1, ∞) with 1
p +
1
q = 1. Show that X is in Lp(P) if and only if there exists a C < ∞such that
|E[XY]| ≤C ∥Y∥q for any bounded random variable Y. ♣

172
7
Lp-Spaces and the Radon–Nikodym Theorem
7.3
Hilbert Spaces
In this section, we study the case p = 2 in more detail. The main goal is the
representation theorem for continuous linear functionals on Hilbert spaces due to
Riesz and Fréchet. This theorem is a cornerstone for a functional analytic proof of
the Radon–Nikodym theorem in Sect. 7.4.
Deﬁnition 7.19 Let V be a real vector space. A map ⟨·, ·⟩: V ×V →R is called
an inner product if:
(i) (Linearity)
⟨x, α y + z⟩= α ⟨x, y⟩+ ⟨x, z⟩for all x, y, z ∈V and α ∈R.
(ii) (Symmetry)
⟨x, y⟩= ⟨y, x⟩for all x, y ∈V .
(iii) (Positive deﬁniteness)
⟨x, x⟩> 0 for all x ∈V \ {0}.
If only (i) and (ii) hold and ⟨x, x⟩≥0 for all x, then ⟨·, ·⟩is called a positive
semideﬁnite symmetric bilinear form, or a semi-inner product.
If ⟨·, ·⟩is an inner product, then (V, ⟨·, ·⟩) is called a (real) Hilbert space if
the norm deﬁned by ∥x∥:= ⟨x, x⟩1/2 is complete; that is, if (V, ∥· ∥) is a Banach
space.
Deﬁnition 7.20 For f, g ∈L2(μ), deﬁne
⟨f, g⟩:=

fg dμ.
For ¯f , ¯g ∈L2(μ), deﬁne ⟨¯f , ¯g⟩:= ⟨f, g⟩, where f ∈¯f and g ∈¯g.
Note that this deﬁnition is independent of the particular choices of the representa-
tives of f and g.
Theorem 7.21 ⟨·, ·⟩is an inner product on L2(μ) and a semi-inner product on
L2(μ). In addition, ∥f ∥2 = ⟨f, f ⟩1/2.
Proof This is left as an exercise.
⊓⊔
As a corollary to Theorem 7.18, we get the following.
Corollary 7.22 (L2(μ), ⟨·, ·⟩) is a real Hilbert space.
Lemma 7.23 If ⟨·, ·⟩is a semi-inner product on the real vector space V , then
⟨·, ·⟩: V × V →R is continuous (with respect to the product topology of the
topology on V that is generated by the pseudo-metric d(x, y) = ⟨x −y, x −y⟩1/2).
Proof This is obvious.
⊓⊔
Deﬁnition 7.24 (Orthogonal complement) Let V be a real vector space with inner
product ⟨·, ·⟩. If W ⊂V , then the orthogonal complement of W is the following
linear subspace of V :
W ⊥:=
	
v ∈V : ⟨v, w⟩= 0 for all w ∈W

.

7.3
Hilbert Spaces
173
Theorem 7.25 (Orthogonal decomposition) Let (V, ⟨·, ·⟩) be a Hilbert space
and let W ⊂V be a closed linear subspace. For any x ∈V , there is a unique
representation x = y + z where y ∈W and z ∈W ⊥.
Proof Let x ∈V and c := inf{∥x −w∥: w ∈W}. Further, let (wn)n∈N be a
sequence in W with ∥x −wn∥
n→∞
−→c. The parallelogram law yields
∥wm −wn∥2 = 2 ∥wm −x∥2 + 2 ∥wn −x∥2 −4
;;;;
1
2(wm + wn) −x
;;;;
2
.
As W is linear, we have (wm + wn)/2 ∈W; hence ∥1
2(wm + wn) −x∥≥c. Thus
(wn)n∈N is a Cauchy sequence: ∥wm −wn∥−→0 if m, n →∞.
Since V is complete and W is closed, W is also complete; hence there is a y ∈W
with wn
n→∞
−→y. Now let z := x −y. Then ∥z∥= limn→∞∥wn −x∥= c by
continuity of the norm (Lemma 7.23).
Consider an arbitrary w ∈W \{0}. We deﬁne ϱ := ⟨z, w⟩/∥w∥2 and get y+ϱw ∈
W; hence
c2 ≤∥x −(y + ϱ w)∥2 = ∥z∥2 + ϱ2 ∥w∥2 + 2ϱ ⟨z, w⟩= c2 −ϱ2 ∥w∥2.
Concluding, we have ⟨z, w⟩= 0 for all w ∈W and thus z ∈W ⊥.
Uniqueness of the decomposition is easy: If x = y′ + z′ is an orthogonal
decomposition, then y −y′ ∈W and z −z′ ∈W ⊥as well as y −y′ + z −z′ = 0;
hence
0 = ∥y −y′ + z −z′∥2 = ∥y −y′∥2 + ∥z −z′∥2 + 2⟨y −y′, z −z′⟩
= ∥y −y′∥2 + ∥z −z′∥2,
whence y = y′ and z = z′.
⊓⊔
Theorem 7.26 (Riesz–Fréchet representation theorem) Let (V, ⟨·, ·⟩) be a Hil-
bert space and let F : V →R be a map. Then the following are equivalent.
(i) F is continuous and linear.
(ii) There is an f ∈V with F(x) = ⟨x, f ⟩for all x ∈V .
The element f ∈V in (ii) is uniquely determined.
Proof “(ii) ⇒(i)”
For any f ∈V , by deﬁnition of the inner product, the map
x →⟨x, f ⟩is linear. By Lemma 7.23, this map is also continuous.
“(i) ⇒(ii)”
If F ≡0, then choose f = 0. Now assume F is not identically zero.
As F is continuous, the kernel W := F −1({0}) is a closed (proper) linear subspace
of V . Let v ∈V \ W and let v = y + z for y ∈W and z ∈W ⊥be the orthogonal
decomposition of v. Then z ̸= 0 and F(z) = F(v) −F(y) = F(v) ̸= 0. Hence
we can deﬁne u := z/F(z) ∈W ⊥. Clearly, F(u) = 1 and for any x ∈V , we
have F(x −F(x)u) = F(x) −F(x)F(u) = 0; hence x −F(x)u ∈W and thus

174
7
Lp-Spaces and the Radon–Nikodym Theorem
⟨x −F(x)u, u⟩= 0. Consequently, F(x) = ⟨x, u⟩/∥u∥2. Now deﬁne f := u/∥u∥2.
Then F(x) = ⟨x, f ⟩for all x ∈V .
“Uniqueness”
Let ⟨x, f ⟩= ⟨x, g⟩for all x ∈V . Letting x = f −g, we get
0 = ⟨f −g, f −g⟩; hence f = g.
⊓⊔
Reﬂection Find an example of a discontinuous linear map F : V →R. ♠
In the following section, we will need the representation theorem for the space
L2(μ), which, unlike L2(μ), is not a Hilbert space. However, with a little bit
of abstract nonsense, one can apply the preceding theorem to L2(μ). Recall that
N = {f ∈L2(μ) : ⟨f, f ⟩= 0} is the subspace of functions that equal zero almost
everywhere. Let L2(μ) = L2(μ)/N be the factor space. This is a special case of
the situation where (V, ⟨·, ·⟩) is a linear space with complete semi-inner product.
In this case, N := {v ∈V : ⟨v, v⟩= 0} and V0 = V/N := {f + N : f ∈V }.
Denote ⟨v + N, w + N⟩0 := ⟨v, w⟩to obtain a Hilbert space (V0, ⟨·, ·⟩0).
Corollary 7.27 Let (V, ⟨·, ·⟩) be a linear vector space with complete semi-inner
product. The map F : V →R is continuous and linear if and only if there is an
f ∈V with F(x) = ⟨x, f ⟩for all x ∈V .
Proof One implication is trivial. Hence, let F be continuous and linear. Then
F(0) = 0 since F is linear. Note that F(v) = F(0) = 0 for all v ∈N
since F is continuous. Indeed, v lies in every open neighborhood of 0; hence F
assumes at v the same value as at 0. Thus F induces a continuous linear map
F0 : V0 →R by F0(x + N) = F(x). By Theorem 7.26, there is an f + N ∈V0
with F0(x + N) = ⟨x + N, f + N⟩0 for all x + N ∈V0. However, F(x) = ⟨x, f ⟩
for all x ∈V by the deﬁnition of F0 and ⟨·, ·⟩0.
⊓⊔
Corollary 7.28 The map F : L2(μ) →R is continuous and linear if and only if
there is an f ∈L2(μ) with F(g) =
3
gf dμ for all g ∈L2(μ).
Proof The space L2(μ) fulﬁlls the conditions of Corollary 7.27.
⊓⊔
Takeaways We recognised the function spaces L2 as Hilbert spaces. In
Hilbert spaces, continuous linear maps can be represented as a scalar product
with some ﬁxed vector (Riesz-Fréchet theorem).
Exercise 7.3.1 (Fourier series)
For n ∈N0, deﬁne Sn, Cn : [0, 1] →[0, 1] by
Sn(x) = sin(2πn x), Cn(x) = cos(2πn x). For two square summable sequences
(an)n∈N and (bn)n∈N0, let ha,b := b0 + ∞
n=1(anSn + bnCn). Further, let W be the
vector space of such ha,b.
Show the following:
(i) The functions C0, Sn, Cn, n ∈N form an orthogonal system in L2([0, 1], λ).
(ii) The series deﬁning ha,b converges in L2([0, 1], λ).
(iii) W is a closed linear subspace of L2([0, 1], λ).

7.4
Lebesgue’s Decomposition Theorem
175
(iv) W = L2([0, 1], λ). More precisely, for any f ∈L2([0, 1], λ), there exist
uniquely deﬁned square summable sequences (an)n∈N and (bn)n∈N0 such that
f = ha,b. Furthermore, ∥f ∥2
2 = b2
0 + ∞
n=1(a2
n + b2
n).
Hint: Show (iv) ﬁrst for step functions (see Exercise 4.2.6). ♣
7.4
Lebesgue’s Decomposition Theorem
In this section, we employ the properties of Hilbert spaces that we derived in the
last section in order to decompose a measure into a singular part and a part that is
absolutely continuous, both with respect to a second given measure. Furthermore,
we show that the absolutely continuous part has a density. Let μ and ν be measures
on (Ω, A). By Deﬁnition 4.13, a measurable function f : Ω →[0, ∞) is called a
density of ν with respect to μ if
ν(A) :=

f 1A dμ
for all A ∈A.
(7.3)
On the other hand, for any measurable f : Ω →[0, ∞), equation (7.3) deﬁnes
a measure ν on (Ω, A). In this case, we also write
ν = f μ
and
f = dν
dμ.
(7.4)
For example, the normal distribution ν = N0,1 has the density f (x) =
1
√
2π e−x2/2
with respect to the Lebesgue measure μ = λ on R.
If g : Ω →[0, ∞] is measurable, then (by Theorem 4.15)

g dν =

gf dμ.
(7.5)
Hence g ∈L1(ν) if and only if gf ∈L1(μ), and in this case (7.5) holds.
If ν = f μ, then ν(A) = 0 for all A ∈A with μ(A) = 0. The situation is quite
the opposite for, e.g., the Poisson distribution μ = Poiϱ with parameter ϱ > 0 and
ν = N0,1. Here N0 ⊂R is a ν-null set with μ(R \ N0) = 0. We say that ν is
singular to μ.
The main goal of this chapter is to show that an arbitrary σ-ﬁnite measure ν
on a measurable space (Ω, A) can be decomposed into a part that is singular to
the σ-ﬁnite measure μ and a part that has a density with respect to μ (Lebesgue’s
decomposition theorem, Theorem 7.33).

176
7
Lp-Spaces and the Radon–Nikodym Theorem
Theorem 7.29 (Uniqueness of the density) Let ν be σ-ﬁnite. If f1 and f2 are
densities of ν with respect to μ, then f1 = f2 μ-almost everywhere. In particular,
the density dν
dμ is unique up to equality μ-almost everywhere.
Proof Let En ↑Ω with ν(En) < ∞, n ∈N. Let An = En ∩{f1 > f2} for n ∈N.
Then ν(An) < ∞; hence
0 = ν(An) −ν(An) =

An
(f1 −f2) dμ.
By Theorem 4.8(i), f2 1An = f1 1An μ-a.e. As f1 > f2 on An, we infer μ(An) = 0
and
μ({f1 > f2}) = μ
 
n∈N
An

= 0.
Similarly, we get μ({f1 < f2}) = 0; hence f1 = f2 μ-a.e.
⊓⊔
Deﬁnition 7.30 Let μ and ν be two measures on (Ω, A).
(i) ν is called absolutely continuous with respect to μ (symbolically ν ≪μ) if
ν(A) = 0
for all A ∈A with μ(A) = 0.
(7.6)
The measures μ and ν are called equivalent (symbolically μ ≈ν) if ν ≪μ
and μ ≪ν.
(ii) μ is called singular to ν (symbolically μ ⊥ν) if there exists an A ∈A such
that μ(A) = 0 and ν(Ω \ A) = 0.
Remark 7.31 Clearly, μ ⊥ν
⇐⇒
ν ⊥μ. ♦
Example 7.32
(i) Let μ be a measure on

R, B(R)

with density f
with respect to the
Lebesgue measure λ. Then μ(A) =
3
A f dλ = 0 for every A ∈A with
λ(A) = 0; hence μ ≪λ. If λ-almost everywhere f > 0, then μ(A) =
3
A f dλ > 0 if λ(A) > 0; hence μ ≈λ. If λ({f = 0}) > 0, then (since
μ({f = 0}) = 0) λ ̸≪μ.
(ii) Consider the Bernoulli distributions Berp and Berq for p, q ∈[0, 1]. If p ∈
(0, 1), then Berq ≪Berp. If p ∈{0, 1}, then Berq ≪Berp if and only if
p = q, and Berq ⊥Berp if and only if q = 1 −p.
(iii) Consider the Poisson distributions Poiα and Poiβ for α, β ≥0. We have
Poiα ≪Poiβ if and only if β > 0 or α = 0.
(iv) Consider the inﬁnite product measures (see Theorem 1.64) (Berp)⊗N and
(Berq)⊗N on Ω = {0, 1}N. Then (Berp)⊗N ⊥(Berq)⊗N if p ̸= q. Indeed,
for n ∈N, let Xn((ω1, ω2, . . .)) = ωn be the projection of Ω to the nth
coordinate. Then under (Berr)⊗N the family (Xn)n∈N is independent and
Bernoulli-distributed with parameter r (see Example 2.18). By the strong law

7.4
Lebesgue’s Decomposition Theorem
177
of large numbers, for any r ∈{p, q}, there exists a measurable set Ar ⊂Ω
with (Berr)⊗N(Ω \ Ar) = 0 and
lim
n→∞
1
n
n

i=1
Xi(ω) = r
for all ω ∈Ar.
In particular, Ap ∩Aq = ∅if p ̸= q and thus (Berp)⊗N ⊥(Berq)⊗N. ♦
Theorem 7.33 (Lebesgue’s decomposition theorem)
Let μ and ν be σ-ﬁnite
measures on (Ω, A). Then ν can be uniquely decomposed into an absolutely
continuous part νa and a singular part νs (with respect to μ):
ν = νa + νs, where νa ≪μ and νs ⊥μ.
νa has a density with respect to μ, and dνa
dμ is A-measurable and ﬁnite μ-a.e.
Corollary 7.34 (Radon–Nikodym theorem)
Let μ and ν be σ-ﬁnite measures
on (Ω, A). Then
ν has a density w.r.t. μ
⇐⇒
ν ≪μ.
In this case, dν
dμ is A-measurable and ﬁnite μ-a.e. dν
dμ is called the Radon–Nikodym
derivative of ν with respect to μ.
Proof One direction is trivial. Hence, let ν ≪μ. By Theorem 7.33, we get that
ν = νa has a density with respect to μ.
⊓⊔
Proof (of Theorem 7.33) The idea goes back to von Neumann. We follow the
exposition in [37].
By the usual exhaustion arguments, we can restrict ourselves to the case where
μ and ν are ﬁnite. By Theorem 4.19, the canonical inclusion i : L2(Ω, A, μ +
ν) →L1(Ω, A, μ + ν) is continuous. Since ν ≤μ + ν, the linear functional
L2(Ω, A, μ + ν) →R, h →
3
h dν is continuous. By the Riesz–Fréchet theorem
(here Corollary 7.28), there exists a g ∈L2(Ω, A, μ + ν) such that

h dν =

hg d(μ + ν)
for all h ∈L2(Ω, A, μ + ν)
(7.7)
or equivalently

f (1 −g) d(μ + ν) =

f dμ
for all f ∈L2(Ω, A, μ + ν).
(7.8)

178
7
Lp-Spaces and the Radon–Nikodym Theorem
If in (7.7) we choose h = 1{g<0}, then we get that (μ+ν)-almost everywhere g ≥0.
Similarly, with f = 1{g>1} in (7.8), we obtain that (μ+ν)-almost everywhere g ≤1.
Hence 0 ≤g ≤1.
Now let f ≥0 be measurable and let (fn)n∈N be a sequence of nonnegative
functions in L2(Ω, A, μ + ν) with fn ↑f . By the monotone convergence theorem
(applied to the measure (1−g)(μ+ν); that is, the measure with density (1−g) with
respect to μ+ν), we obtain that (7.8) holds for all measurable f ≥0. Similarly, we
get (7.7) for all measurable h ≥0.
Let E := g−1({1}). If we let f = 1E in (7.8), then we get μ(E) = 0. Deﬁne the
measures νa and νs for A ∈A by
νa(A) := ν(A \ E)
and
νs(A) := ν(A ∩E).
Clearly, ν = νa + νs and νs(Ω \ E) = 0; hence νs ⊥μ. If now A ∩E = ∅and
μ(A) = 0, then
3
1A dμ = 0. Hence, by (7.8), also
3
A(1 −g) d(μ + ν) = 0.
On the other hand, we have 1 −g > 0 on A; hence μ(A) + ν(A) = 0 and thus
νa(A) = ν(A) = 0. If, more generally, B is measurable with μ(B) = 0, then
μ(B \ E) = 0; hence, as shown above, νa(B) = νa(B \ E) = 0. Consequently,
νa ≪μ and ν = νa + νs is the decomposition we wanted to construct.
In order to obtain the density of νa with respect to μ, we deﬁne f
:=
g
1 −g 1Ω\E. For any A ∈A, by (7.8) and (7.7) with h = 1A\E,

A
f dμ =

A∩Ec g d(μ + ν) = ν(A \ E) = νa(A).
Hence f = dνa
dμ .
⊓⊔
Reﬂection Why do we assume σ-ﬁniteness of the measures in the Radon-Nikodym
theorem? Find an example that shows that this assumption cannot be dropped. ♠
Takeaways Loosely speaking, a σ-ﬁnite measure μ has a density with
respect to a σ-ﬁnite measure ν if locally μ is a multiple of ν. A necessary
and sufﬁcient condition for this to be true is that μ vanishes on the sets where
ν vanishes. The actual density could be gained using Hilbert space theory, in
particular the Riesz-Fréchet representation theorem.
Exercise 7.4.1 For every x ∈(0, 1], let x = (0, x1x2x3 . . .) := ∞
n=1 xn2−n be
the dyadic expansion (with lim supn→∞xn = 1 for deﬁniteness). Deﬁne a map
F : (0, 1] →(0, 1] by
F(x) = (0, x1x1x2x2x3x3 . . .) =
∞

n=1
3 xn 4−n.

7.5
Supplement: Signed Measures
179
Let U be a random variable that is uniformly distributed on (0, 1] and denote by
μ := PU◦F −1 the distribution of F(U).
Show that the probability measure μ has a continuous distribution function and
that μ is singular to the Lebesgue measure λ
(0,1]. ♣
Exercise 7.4.2 Let n ∈N and p, q ∈[0, 1]. For which values of p and q do we
have bn,p ≪bn,q? Compute the Radon–Nikodym derivative dbn,p
dbn,q . ♣
7.5
Supplement: Signed Measures
In this section, we show the decomposition theorems for signed measures (Hahn,
Jordan) and deliver an alternative proof for Lebesgue’s decomposition theorem. We
owe some of the proofs to [89].
Deﬁnition 7.35 Let μ and ν be two measures on (Ω, A). ν is called totally
continuous with respect to μ if, for any ε > 0, there exists a δ > 0 such that
for all A ∈A
μ(A) < δ
implies
ν(A) < ε.
(7.9)
Remark 7.36 The deﬁnition of total continuity is similar to that of uniform inte-
grability (see Theorem 6.24(iii)), at least for ﬁnite μ. We will come back to this
connection in the framework of the martingale convergence theorem that will
provide an alternative proof of the Radon–Nikodym theorem (Corollary 7.34). ♦
Theorem 7.37 Let μ and ν be measures on (Ω, A). If ν is totally continuous with
respect to μ, then ν ≪μ. If ν(Ω) < ∞, then the converse also holds.
Proof “ ⇒”
Let ν be totally continuous with respect to μ. Let A ∈A with
μ(A) = 0. For all ε > 0, by assumption, ν(A) < ε; hence ν(A) = 0 and thus
ν ≪μ.
“ ⇐ ”
Let ν be ﬁnite but not totally continuous with respect to μ. Then there
exist an ε > 0 and sets An ∈A with μ(An) < 2−n but ν(An) ≥ε for all n ∈N.
Deﬁne A := lim sup
n→∞
An =
∞

n=1
∞

k=n
Ak. Then
μ(A) =
lim
n→∞μ
 ∞

k=n
Ak

≤
lim
n→∞
∞

k=n
μ(Ak) ≤
lim
n→∞
∞

k=n
2−k = 0.

180
7
Lp-Spaces and the Radon–Nikodym Theorem
Since ν is ﬁnite and upper semicontinuous (Theorem 1.36), we have
ν(A) =
lim
n→∞ν
 ∞

k=n
Ak

≥inf
n∈N ν(An) ≥ε > 0.
Thus ν ̸≪μ.
⊓⊔
Example 7.38 In the converse implication of the theorem, the assumption of
ﬁniteness is essential. For example, let μ = N0,1 be the standard normal distribution
on R and let ν be the Lebesgue measure on R. Then ν has the density f (x) =
√
2π ex2/2 with respect to μ. In particular, we have ν ≪μ. On the other hand,
μ([n, ∞))
n→∞
−→
0 and ν([n, ∞)) = ∞for any n ∈N. Hence ν is not totally
continuous with respect to μ. ♦
Example 7.39 Let (Ω, A) be a measurable space and let μ and ν be ﬁnite measures
on (Ω, A). Denote by Z the set of ﬁnite partitions of Ω into pairwise disjoint
measurable sets. That is, Z ∈Z is a ﬁnite subset of A such that the sets C ∈Z
are pairwise disjoint and 
C∈Z C = Ω for all Z. For Z ∈Z, deﬁne a function
fZ : Ω →R by
fZ(ω) =

C∈Z: μ(C)>0
ν(C)
μ(C) 1C(ω).
We show that the following three statements are equivalent.
(i) The family (fZ : Z ∈Z) is uniformly integrable in L1(μ) and
3
fZ dμ =
ν(Ω) for any Z ∈Z.
(ii) ν ≪μ.
(iii) ν is totally continuous with respect to μ.
The equivalence of (ii) and (iii) was established in the preceding theorem. If (ii)
holds, then, for all Z ∈Z,

fZ dμ =

C∈Z: μ(C)>0
ν(C) = ν(Ω)
since ν(C) = 0 for those C that do not appear in the sum. Now ﬁx ε > 0. Since
(ii) implies (iii), there is a δ′ > 0 such that ν(A) < ε/2 for all A ∈A with
μ(A) ≤δ′. Let K := ν(Ω)/δ′ and δ < ε/(2K). Then
μ
⎛
⎝

C∈Z: Kμ(C)≤ν(C)
C
⎞
⎠=

C∈Z: Kμ(C)≤ν(C)
μ(C) ≤
1
K ν(Ω) = δ′;

7.5
Supplement: Signed Measures
181
hence

C∈Z: Kμ(C)≤ν(C)
ν(C) = ν
⎛
⎝

C∈Z: Kμ(C)≤ν(C)
C
⎞
⎠< ε
2.
We conclude that for all A ∈A with μ(A) < δ,

A
fZ dμ =

C∈Z: μ(C)>0
μ(A ∩C) ν(C)
μ(C)
=

0<Kμ(C)≤ν(C)
μ(A ∩C) ν(C)
μ(C) +

Kμ(C)>ν(C)
μ(A ∩C) ν(C)
μ(C)
≤ε
2 +

Kμ(C)>ν(C)
K μ(A ∩C) ≤ε
2 + K μ(A) < ε.
Hence (fZ, Z ∈Z) is uniformly integrable by Theorem 6.24(iii).
Now assume (i). If μ = 0, then
3
f dμ = 0 for all f ; hence ν(Ω) = 0 and thus
ν ≪μ. Hence, let μ ̸= 0. Let A ∈A with μ(A) = 0. Then Z = {A, Ac} ∈Z
and fZ = 1Acν(Ac)/μ(Ac). By assumption, ν(Ω) =
3
fZ dμ = ν(Ac); hence
ν(A) = 0 and thus ν ≪μ. ♦
Deﬁnition 7.40 (Signed measure)
A set function ϕ : A →R is called a signed
measure on (Ω, A) if it is σ-additive; that is, if for any sequence of pairwise
disjoint sets A1, A2, . . . ∈A,
ϕ
 ∞

n=1
An

=
∞

n=1
ϕ(An).
(7.10)
The set of all signed measures will be denoted by M± = M±(Ω, A).
Remark 7.41
(i) If ϕ is a signed measure, then in (7.10) we automatically have absolute
convergence. Indeed, the value of the left-hand side does not change if we
change the order of the sets A1, A2, . . .. In order for this to hold for the right-
hand side, by Weierstraß’s theorem on rearrangements of series, the series has
to converge absolutely. In particular, for any sequence (An)n∈N of pairwise
disjoint sets, we have lim
n→∞
∞
k=n |ϕ(Ak)| = 0.
(ii) If ϕ ∈M±, then ϕ(∅) = 0 since R ∋ν(∅) = 
n∈N ν(∅).
(iii) In general, ϕ ∈M± is not σ-subadditive. ♦
Example 7.42 If μ+, μ−are ﬁnite measures, then ϕ := μ+ −μ−∈M±. We will
see that every signed measure has such a representation. ♦

182
7
Lp-Spaces and the Radon–Nikodym Theorem
Theorem 7.43 (Hahn’s decomposition theorem)
Let ϕ be a signed measure.
Then there is a set Ω+ ∈A with ϕ(A) ≥0 for all A ∈A, A ⊂Ω+ and ϕ(A) ≤0
for all A ∈A, A ⊂Ω−:= Ω \ Ω+. Such a decomposition Ω = Ω−⊎Ω+ is
called a Hahn decomposition of Ω (with respect to ϕ).
Proof Let α := sup
	
ϕ(A) : A ∈A

. We have to show that ϕ attains the maximum
α; that is, there exists an Ω+ ∈A with ϕ(Ω+) = α. If this is the case, then α ∈R
and for A ⊂Ω+, A ∈A, we would have
α ≥ϕ(Ω+ \ A) = ϕ(Ω+) −ϕ(A) = α −ϕ(A);
hence ϕ(A) ≥0. For A ⊂Ω−, A ∈A, we would have ϕ(A) ≤0 since
α ≥ϕ(Ω+ ∪A) = ϕ(Ω+) + ϕ(A) = α + ϕ(A).
We now construct Ω+ with ϕ(Ω+) = α. Let (An)n∈N be a sequence in A with
α = lim
n→∞ϕ(An). Let A := ∞
n=1 An. As each An could still contain “portions with
negative mass”, we cannot simply choose Ω+ = A. Rather, we have to peel off the
negative portions layer by layer.
Deﬁne A0
n := An, A1
n := A \ An, and let
Pn :=
 n

i=1
As(i)
i
: s ∈{0, 1}n

be the partition of A that is generated by A1, . . . , An. Clearly, for any B, C ∈Pn,
either B = C or B ∩C = ∅holds. In addition, we have An =

B∈Pn
B⊂An
B. Deﬁne
P−
n := {B ∈Pn : ϕ(B) < 0},
P+
n := Pn \ P−
n
and
Cn :=

B∈P+
n
B.
Due to the ﬁnite additivity of ϕ, we have
ϕ(An) =

B∈Pn
B⊂An
ϕ(B) ≤

B∈P+
n
B⊂An
ϕ(B) ≤

B∈P+
n
ϕ(B) = ϕ(Cn).

7.5
Supplement: Signed Measures
183
For m ≤n, let En
m = Cm ∪. . . ∪Cn. Hence, for m < n, we have En
m \ En−1
m
⊂Cn
and thus
En
m \ En−1
m
=

B∈P+
n
B⊂Enm\En−1
m
B.
In particular, this implies ϕ(En
m \ En−1
m
) ≥0. For Em := 
n≥m Cn, we also have
En
m ↑Em (n →∞) and
ϕ(Am) ≤ϕ(Cm) = ϕ(Em
m) ≤ϕ(Em
m) +
∞

n=m+1
ϕ(En
m \ En−1
m
)
= ϕ

Em
m ∪
∞

n=m+1
(En
m \ En−1
m
)

= ϕ
 ∞

n=m
En
m

= ϕ(Em).
Now deﬁne Ω+ = ∞
m=1 Em; hence Em ↓Ω+. Then
ϕ(Em) = ϕ

Ω+ ⊎

n≥m
(En \ En+1)

= ϕ(Ω+) +
∞

n=m
ϕ(En \ En+1)
m→∞
−→ϕ(Ω+).
In the last step, we used Remark 7.41(i). Summing up, we have
α = lim
m→∞ϕ(Am) ≤lim
m→∞ϕ(Em) = ϕ(Ω+).
However, by deﬁnition, α ≥ϕ(Ω+); hence α = ϕ(Ω+). This ﬁnishes the proof.
⊓⊔
Corollary 7.44 (Jordan’s decomposition theorem)
Assume ϕ ∈M±(Ω, A) is a
signed measure. Then there exist uniquely determined ﬁnite measures ϕ+, ϕ−with
ϕ = ϕ+ −ϕ−and ϕ+ ⊥ϕ−.
Proof Let Ω = Ω+ ⊎Ω−be a Hahn decomposition. Deﬁne ϕ+(A) := ϕ(A∩Ω+)
and ϕ−(A) := −ϕ(A ∩Ω−).
The uniqueness of the decomposition is trivial.
⊓⊔

184
7
Lp-Spaces and the Radon–Nikodym Theorem
Corollary 7.45 Let ϕ ∈M±(Ω, A) and let ϕ = ϕ+ −ϕ−be the Jordan
decomposition of ϕ. Let Ω = Ω+ ⊎Ω−be a Hahn decomposition of Ω. Then
∥ϕ∥T V := sup
	
ϕ(A) −ϕ(Ω \ A) : A ∈A

= ϕ(Ω+) −ϕ(Ω−)
= ϕ+(Ω) + ϕ−(Ω)
deﬁnes a norm on M±(Ω, A), the so-called total variation norm.
Proof We only have to show the triangle inequality. Let ϕ1, ϕ2 ∈M±. Let Ω =
Ω+ ⊎Ω−be a Hahn decomposition with respect to ϕ := ϕ1 + ϕ2 and let Ω =
Ω+
i ⊎Ω−
i be a Hahn decomposition with respect to ϕi, i = 1, 2. Then
∥ϕ1 + ϕ2∥T V = ϕ1(Ω+) −ϕ1(Ω−) + ϕ2(Ω+) −ϕ2(Ω−)
≤ϕ1(Ω+
1 ) −ϕ1(Ω−
1 ) + ϕ2(Ω+
2 ) −ϕ2(Ω−
2 )
= ∥ϕ1∥T V + ∥ϕ2∥T V .
⊓⊔
Reﬂection An important object in stochastic analysis is a random set function ϕ on
B([0, 1]) with the property that ϕ(A) ∼N0,λ(A) is normally distributed and ϕ(A)
and ϕ(B) are independent on disjoint sets A and B. With a little effort it is possible
to construct ϕ as a (random) additive set function. However, ϕ cannot be a (random)
signed measure. Why? ♠♠♠
With a lemma, we prepare for an alternative proof of Lebesgue’s decomposition
theorem (Theorem 7.33).
Lemma 7.46 Let μ, ν be ﬁnite measures on (Ω, A) that are not mutually singular;
in short, μ ̸⊥ν. Then there is an A ∈A with μ(A) > 0 and an ε > 0 with
εμ(E) ≤ν(E)
for all E ∈A with E ⊂A.
Proof For n ∈N, let Ω = Ω+
n ⊎Ω−
n be a Hahn decomposition for (ν−1
nμ) ∈M±.
Deﬁne M := 
n∈N Ω−
n . Clearly, (ν −1
nμ)(M) ≤0; hence ν(M) ≤1
nμ(M) for all
n ∈N and thus ν(M) = 0. Since μ ̸⊥ν, we get μ

Ω \ M) = μ(
n∈N Ω+
n

> 0.
Thus μ(Ω+
n0) > 0 for some n0 ∈N. Deﬁne A := Ω+
n0 and ε := 1
n0 . Then μ(A) > 0
and (ν −εμ)(E) ≥0 for all E ⊂A, E ∈A.
⊓⊔
Alternative proof of Theorem 7.33.
We show only the existence of a decompo-
sition. By choosing a suitable sequence Ωn ↑Ω, we can assume that ν is ﬁnite.
Consider the set of functions
G :=
0
g : Ω →[0, ∞] : g is measurable and

A
g dμ ≤ν(A) for all A ∈A
1
,

7.5
Supplement: Signed Measures
185
and deﬁne
γ := sup
 
g dμ : g ∈G

.
Our aim is to ﬁnd a maximal element f in G (i.e., an f for which
3
f dμ = γ ).
This f will be the density of νa.
Clearly, 0 ∈G; hence G ̸= ∅. Furthermore,
f, g ∈G
implies
f ∨g ∈G.
(7.11)
Indeed, letting E := {f ≥g}, for all A ∈A, we have

A
(f ∨g) dμ =

A∩E
f dμ +

A\E
g dμ ≤ν(A ∩E) + ν(A \ E) = ν(A).
Choose a sequence (gn)n∈N in G such that
3
gn dμ
n→∞
−→γ , and deﬁne the function
fn = g1 ∨. . . ∨gn. Now (7.11) implies fn ∈G. Letting f := sup{fn : n ∈N}, the
monotone convergence theorem yields

A
f dμ = sup
n∈N

A
fn dμ ≤ν(A)
for all A ∈A
(that is, f ∈G), and

f dμ = sup
n∈N

fn dμ ≥sup
n∈N

gn dμ = γ.
Hence
3
f dμ = γ ≤ν(Ω). Now deﬁne, for any A ∈A,
νa(A) :=

A
f dμ
and
νs(A) := ν(A) −νa(A).
By construction, νa ≪μ is a ﬁnite measure with density f with respect to μ. Since
f ∈G, we have νs(A) = ν(A) −
3
A f dμ ≥0 for all A ∈A, and thus also νs is a
ﬁnite measure. It remains to show νs ⊥μ.
At this point we use Lemma 7.46. Assume that we had νs ̸⊥μ. Then there would
be an ε > 0 and an A ∈A with μ(A) > 0 such that εμ(E) ≤νs(E) for all E ⊂A,
E ∈A. Then, for B ∈A, we would have

B
(f + ε 1A) dμ =

B
f dμ + εμ(A ∩B)
≤νa(B) + νs(A ∩B) ≤νa(B) + νs(B) = ν(B).

186
7
Lp-Spaces and the Radon–Nikodym Theorem
In other words, (f + ε 1A) ∈G and thus
3
(f + ε 1A) dμ = γ + εμ(A) > γ ,
contradicting the deﬁnition of γ . Hence in fact νs ⊥μ.
Takeaways A signed measure is a ﬁnite measure that can also assume
negative values. A signed measure can be written as the difference of two
ﬁnite mutually singular measures (Jordan decomposition). With the help of
signed measures we could present a different approach to proving the Radon-
Nikodym theorem.
Exercise 7.5.1 Let μ be a σ-ﬁnite measure on (Ω, A) and let ϕ be a signed measure
on (Ω, A). Show that, analogously to the Radon–Nikodym theorem, the following
two statements are equivalent:
(i) ϕ(A) = 0 for all A ∈A with μ(A) = 0.
(ii) There is an f ∈L1(μ) with ϕ = f μ; hence 3
A f dμ = ϕ(A) for all A ∈A.
♣
Exercise 7.5.2 Let μ, ν, α be ﬁnite measures on (Ω, A) with ν ≪μ ≪α.
(i) Show the chain rule for the Radon–Nikodym derivative:
dν
dα = dν
dμ
dμ
dα
α-a.e.
(ii) Show that f :=
dν
d(μ+ν) exists and that dν
dμ =
f
1−f holds μ-a.e. ♣
7.6
Supplement: Dual Spaces
By the Riesz–Fréchet theorem (Theorem 7.26), every continuous linear functional
F : L2(μ) →R has a representation F(g) = ⟨f, g⟩for some f ∈L2(μ). On the
other hand, for any f ∈L2(μ), the map L2(μ) →R, g →⟨f, g⟩is continuous
and linear. Hence L2(μ) is canonically isomorphic to its topological dual space
(L2(μ))′. This dual space is deﬁned as follows.
Deﬁnition 7.47 (Dual space) Let (V, ∥· ∥) be a Banach space. The dual space V ′
of V is deﬁned by
V ′ := {F : V →R is continuous and linear}.
For F ∈V ′, we deﬁne ∥F∥′ := sup{|F(f )| : ∥f ∥= 1}.
Remark 7.48 As F is continuous, for any δ > 0, there exists an ε > 0 such that
|F(f )| < δ for all f ∈V with ∥f ∥< ε. Hence ∥F∥′ ≤δ/ε < ∞. ♦

7.6
Supplement: Dual Spaces
187
We are interested in the case V = Lp(μ) for p ∈[1, ∞] and write ∥F∥′
p for
the norm of F ∈V ′. In the particular case V = L2(μ), by the Cauchy–Schwarz
inequality, we have ∥F∥′
2 = ∥f ∥2. This can be generalized:
Lemma 7.49 Let p, q ∈[1, ∞] with 1
p + 1
q = 1. The canonical map
κ : Lq(μ) →(Lp(μ))′
κ(f )(g) =

fg dμ
for f ∈Lq(μ), g ∈Lp(μ)
is an isometry; that is, ∥κ(f )∥′
p = ∥f ∥q.
Proof We show equality by showing the two inequalities separately.
“≤”
This follows from Hölder’s inequality.
“≥”
For any admissible pair p, q and all f
∈Lq(μ), g ∈Lp(μ), by the
deﬁnition of the operator norm, ∥κ(f )∥′
p ∥g∥p ≥
 3
fg dμ
. Deﬁne the sign
function sign(x) = 1(0,∞)(x) −1(−∞,0)(x). Replacing g by ˜g := |g| sign(f ) (note
that ∥˜g∥p = ∥g∥p), we obtain
∥κ(f )∥′
p ∥g∥p ≥


f ˜g dμ
 = ∥fg∥1.
(7.12)
First consider the case q = 1 and f ∈L1(μ). Applying (7.12) with g ≡1 ∈L∞(μ)
yields ∥κ(f )∥′
∞≥∥f ∥1.
Now let q ∈(1, ∞). Let g := |f |q−1. Since q−1
q
= 1
p, we have
∥κ(f )∥′
p · ∥g∥p ≥∥fg∥1 = ∥|f |q||1 = ∥f ∥q
q = ∥f ∥q · ∥f ∥q−1
q
= ∥f ∥q · ∥g∥p.
Finally, let q = ∞. Without loss of generality, assume ∥f ∥∞∈(0, ∞). Let
ε > 0. Then there exists an Aε ∈A with 0 < μ(Aε) < ∞such that
Aε ⊂
	
|f | > (1 −ε)∥f ∥∞

.
If we let g =
1
μ(Aε) 1Aε, then ∥g∥1 = 1 and ∥κ(f )∥′
1 ≥∥fg∥1 ≥(1−ε)∥f ∥∞.
⊓⊔
Theorem 7.50 Let p ∈[1, ∞) and assume 1
p + 1
q = 1. Then Lq(μ) is isomorphic
to its dual space (Lp(μ))′ by virtue of the isometry κ.
Proof The proof makes use of the Radon–Nikodym theorem (Corollary 7.34).
However, here we only sketch the proof since we do not want to go into the details of
signed measures and signed contents. A signed content ν is an additive set function
that is the difference ν = ν+ −ν−of two ﬁnite contents. This deﬁnition is parallel
to that of a signed measure that is the difference of two ﬁnite measures.

188
7
Lp-Spaces and the Radon–Nikodym Theorem
As κ is an isometry, κ in particular is injective. Hence we only have to show that
κ is surjective. Let F ∈(Lp(μ))′. Then ν(A) = F(1A) is a signed content on A
and we have
|ν(A)| ≤∥F∥′
p (μ(A))1/p.
Since μ is ∅-continuous, ν is also ∅-continuous and is thus a signed measure on A.
We even have ν ≪μ. By the Radon–Nikodym theorem (Corollary 7.34) (applied
to the measures ν−and ν+; see Exercise 7.5.1), ν admits a density with respect to
μ; that is, a measurable function f with ν = f μ.
Let
Ef :=
	
g : g is a simple function with μ(g ̸= 0) < ∞

and let
E+
f :=
	
g ∈Ef : g ≥0

.
Then, for g ∈Ef ,
F(g) =

gf dμ.
(7.13)
In order to show that (7.13) holds for all g ∈Lp(μ), we ﬁrst show f ∈Lq(μ). To
this end, we distinguish two cases.
Case 1: p = 1.
For every α > 0,
μ({|f | > α}) ≤1
α ν({|f | > α})
= 1
α F(1{|f |>α}) ≤1
α ∥F∥′
1 · ∥1{|f |>α}∥1 = 1
α ∥F∥′
1 · μ({|f | > α}).
This implies μ({|f | > α}) = 0 if α > ∥F∥′
1; hence ∥f ∥∞≤∥F∥′
1 < ∞.
Case 2: p ∈(1, ∞).
By Theorem 1.96, there are g1, g2, . . . ∈E+
f such that
gn ↑|f | μ-a.e. Deﬁne hn = sign(f )(gn)q−1 ∈Ef ; hence
∥gn∥q
q ≤

hnf dμ = F(hn)
≤∥F∥′
p · ∥hn∥p = ∥F∥′
p · (∥gn∥q)q−1.
Thus we have ∥gn∥q ≤∥F∥′
p. Monotone convergence (Theorem 4.20) now yields
∥f ∥q ≤∥F∥′
p < ∞; hence f ∈Lq(μ).
Concluding, the map 
F : g →
3
gf dμ is in (Lp(μ))′, and 
F(g) = F(g) for
every g ∈Ef . Since 
F is continuous and Ef ⊂Lp(μ) is dense, we get 
F = F.
⊓⊔

7.6
Supplement: Dual Spaces
189
Remark 7.51 For p = ∞, the statement of Theorem 7.50 is false in general. (For
ﬁnite A, the claim is trivially true even for p = ∞.) For example, let Ω = N,
A = 2Ω and let μ be the counting measure. Thus we consider sequence spaces ℓp =
Lp(N, 2N, μ). For the subspace ℓK ⊂ℓ∞of convergent sequences, F : ℓK →R,
(an)n∈N →lim
n→∞an is a continuous linear functional. By the Hahn–Banach theorem
of functional analysis (see, e.g., [87] or [174]), F can be extended to a continuous
linear functional on ℓ∞. However, clearly there is no sequence (bn)n∈N ∈ℓ1 with
F((an)n∈N) =
∞

m=1
ambm. ♦
Takeaways Lq is the dual space to Lp, if 1
p + 1
q = 1 and p ∈[1, ∞). This
beautiful theorem could be shown using the tools that we developed in the
previous sections for other purposes.
Exercise 7.6.1 Show that Ef ⊂Lp(μ) is dense if p ∈[1, ∞). ♣

Chapter 8
Conditional Expectations
If there is partial information on the outcome of a random experiment, the proba-
bilities for the possible events may change. The concept of conditional probabilities
and conditional expectations formalizes the corresponding calculus.
8.1
Elementary Conditional Probabilities
Example 8.1 We throw a die and consider the events
A := {the face shows an odd number},
B := {the face shows three or smaller}.
Clearly, P[A] = 1
2 and P[B] = 1
2. However, what is the probability that A occurs if
we already know that B occurs?
We model the experiment on the probability space (Ω, A, P), where Ω =
{1, . . ., 6}, A = 2Ω and P is the uniform distribution on Ω. Then
A = {1, 3, 5}
and
B = {1, 2, 3}.
If we know that B has occurred, it is plausible to assume the uniform distribution
on the remaining possible outcomes; that is, on {1, 2, 3}. Thus we deﬁne a new
probability measure PB on (B, 2B) by
PB[C] = #C
#B
for C ⊂B.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_8
191

192
8
Conditional Expectations
By assigning the points in Ω \ B probability zero (since they are impossible if B
has occurred), we can extend PB to a measure on Ω:
P[C|B] := PB[C ∩B] = #(C ∩B)
#B
for C ⊂Ω.
In this way, we get P[A|B] =
#{1, 3}
#{1, 2, 3} = 2
3. ♦
Motivated by this example, we make the following deﬁnition.
Deﬁnition 8.2 (Conditional probability)
Let (Ω, A, P) be a probability space
and B ∈A. We deﬁne the conditional probability given B for any A ∈A by
P[A|B] =
⎧
⎨
⎩
P[A ∩B]
P[B]
,
if P[B] > 0,
0,
otherwise.
(8.1)
Remark 8.3 The speciﬁcation in (8.1) for the case P[B] = 0 is arbitrary and is of
no importance. ♦
Theorem 8.4 If P[B] > 0, then P[ · |B] is a probability measure on (Ω, A).
Proof This is obvious.
⊓⊔
Theorem 8.5 Let A, B ∈A with P[A], P[B] > 0. Then
A, B are independent
⇐⇒P[A|B] = P[A] ⇐⇒P[B|A] = P[B].
Proof This is trivial!
⊓⊔
Theorem 8.6 (Summation formula)
Let I be a countable set and let (Bi)i∈I be
pairwise disjoint sets with P
)
i∈I Bi
*
= 1. Then, for any A ∈A,
P[A] =

i∈I
P[A|Bi] P[Bi].
(8.2)
Proof Due to the σ-additivity of P, we have
P[A] = P
-
i∈I
(A ∩Bi)
.
=

i∈I
P[A ∩Bi] =

i∈I
P[A|Bi]P[Bi].
⊓⊔
Theorem 8.7 (Bayes’ formula) Let I be a countable set and let (Bi)i∈I be
pairwise disjoint sets with P
)
i∈I Bi
*
= 1. Then, for any A ∈A with P[A] > 0
and any k ∈I,
P[Bk |A] =
P[A|Bk] P[Bk]

i∈I P[A|Bi] P[Bi].
(8.3)

8.1
Elementary Conditional Probabilities
193
Proof We have
P[Bk |A] = P[Bk ∩A]
P[A]
= P[A|Bk] P[Bk]
P[A]
.
Now use the expression in (8.2) for P[A].
⊓⊔
Example 8.8 In the production of certain electronic devices, a fraction of 2% of
the production is defective. A quick test detects a defective device with probability
95%; however, with probability 10% it gives a false alarm for an intact device.
If the test gives an alarm, what is the probability that the device just tested is
indeed defective?
We formalize the description given above. Let
A := {device is declared as defective},
B := {device is defective},
and
P[B] = 0.02,
P[Bc] = 0.98,
P[A|B] = 0.95,
P[A|Bc] = 0.1.
Bayes’ formula yields
P[B|A] =
P[A|B] P[B]
P[A|B] P[B] + P[A|Bc] P[Bc]
=
0.95 · 0.02
0.95 · 0.02 + 0.1 · 0.98 = 19
117 ≈0.162.
On the other hand, the probability that a device that was not classiﬁed as defective
is in fact defective is
P[B|Ac] =
0.05 · 0.02
0.05 · 0.02 + 0.9 · 0.98 =
1
883 ≈0.00113.
♦
Now let X ∈L1(P). If A ∈A, then clearly also 1AX ∈L1(P). We deﬁne
E[X; A] := E[1A X].
(8.4)
If P[A] > 0, then P[ · |A] is a probability measure. Since 1AX ∈L1(P), we have
X ∈L1(P[ · |A]). Hence we can deﬁne the expectation of X with respect to P[ · |A].

194
8
Conditional Expectations
Deﬁnition 8.9 Let X ∈L1(P) and A ∈A. Then we deﬁne
E[X|A] :=

X(ω) P[dω|A] =
⎧
⎨
⎩
E[1AX]
P[A]
,
if P[A] > 0,
0,
else.
(8.5)
Clearly, P[B|A] = E[1B |A] for all B ∈A.
Consider now the situation that we studied with the summation formula for
conditional probabilities. Hence, let I be a countable set and let (Bi)i∈I be pairwise
disjoint events with

i∈I
Bi = Ω. We deﬁne F := σ(Bi, i ∈I). For X ∈L1(P), we
deﬁne a map E[X|F] : Ω →R by
E[X|F](ω) = E[X|Bi]
⇐⇒
Bi ∋ω.
(8.6)
Lemma 8.10 The map E[X|F] has the following properties.
(i) E[X|F] is F-measurable.
(ii) E[X|F] ∈L1(P), and for any A ∈F, we have

A
E[X|F] dP =

A
X dP.
Proof
(i) Let f be the map f : Ω →I with
f (ω) = i
⇐⇒
Bi ∋ω.
Further, let g : I →R, i →E[X|Bi]. Since I is discrete, g is measurable.
Since f is F-measurable, E[X|F] = g ◦f is also F-measurable.
(ii) Let A ∈F and J ⊂I with A = 
j∈J Bj. Let J ′ := {i ∈J : P[Bi] > 0}.
Hence

A
E[X|F] dP =

i∈J ′
P[Bi] E[X|Bi] =

i∈J ′
E[1BiX] =

A
X dP.
⊓⊔
Takeaways We have developed the notion of the (elementary) conditional
probability and have established two simple but important formulas: the
summation formula and Bayes’ formula. We have also reformulated the
elementary conditional expectation and highlighted those of its properties that
allow for a generalisation to conditional expectations given σ-algebras.

8.2
Conditional Expectations
195
Exercise 8.1.1 (Lack of memory of the exponential distribution) Let X > 0 be
a strictly positive random variable and let θ > 0. Show that X is exponentially
distributed if and only if
P[X > t + s|X > s] = P[X > t]
for all s, t ≥0.
In particular, X ∼expθ if and only if P[X > t + s|X > s] = e−θt for all s, t ≥0.
♣
Exercise 8.1.2 Consider a theatre with n seats that is fully booked for this evening.
Each of the n people entering the theatre (one by one) has a seat reservation.
However, the ﬁrst person is absent-minded and takes a seat at random. Any
subsequent person takes his or her reserved seat if it is free and otherwise picks
a free seat at random.
(i) What is the probability that the last person gets his or her reserved seat?
(ii) What is the probability that the kth person gets his or her reserved seat? ♣
8.2
Conditional Expectations
Let X be a random variable that is uniformly distributed on [0, 1]. Assume that
if we know the value X = x, the random variables Y1, . . . , Yn are independent
and Berx-distributed. So far, with our machinery we can only deal with conditional
probabilities of the type P[ · |X ∈[a, b]], a < b (since X ∈[a, b] has positive
probability). How about P[Y1 = . . . = Yn = 1
X = x]? Intuitively, this should
be xn. We thus need a notion of conditional probabilities that allows us to deal with
conditioning on events with probability zero and that is consistent with our intuition.
In the next section, we will see that in the current example this can be done using
transition kernels. First, however, we have to consider a more general situation.
In the following, F ⊂A will be a sub-σ-algebra and X ∈L1(Ω, A, P). In
analogy with Lemma 8.10, we make the following deﬁnition.
Deﬁnition 8.11 (Conditional expectation)
A random variable Y is called a
conditional expectation of X given F, symbolically E[X|F] := Y, if:
(i) Y is F-measurable.
(ii) For any A ∈F, we have E[X1A] = E[Y1A].
For B ∈A, P[B|F] := E[1B |F] is called a conditional probability of B given
the σ-algebra F.
Theorem 8.12 E[X|F] exists and is unique (up to equality almost surely).
Since conditional expectations are deﬁned only up to equality a.s., all equalities with
conditional expectations are understood as equalities a.s., even if we do not say so
explicitly.

196
8
Conditional Expectations
Proof
Uniqueness Let Y and Y ′ be random variables that fulﬁll (i) and (ii). Let A = {Y >
Y ′} ∈F. Then, by (ii),
0 = E[Y1A] −E[Y ′ 1A] = E[(Y −Y ′) 1A].
Since (Y −Y ′) 1A ≥0, we have P[A] = 0; hence Y ≤Y ′ almost surely. Similarly,
we get Y ≥Y ′ almost surely.
Existence Let X+ = X ∨0 and X−= X+ −X. By
Q±(A) := E[X± 1A]
for all A ∈F,
we deﬁne two ﬁnite measures on (Ω, F). Clearly, Q± ≪P; hence the Radon–
Nikodym theorem (Corollary 7.34) yields the existence of F-measurable densities
Y ± such that
Q±(A) =

A
Y ± dP = E[Y ± 1A].
Now deﬁne Y = Y + −Y −.
⊓⊔
Deﬁnition 8.13 If Y is a random variable and X
∈L1(P), then we deﬁne
E[X|Y] := E[X|σ(Y)].
Theorem 8.14 (Properties of the conditional expectation) Let (Ω, A, P) and let
X be as above. Let G ⊂F ⊂A be σ-algebras and let Y ∈L1(Ω, A, P). Then:
(i) (Linearity) E[λX + Y |F] = λE[X|F] + E[ Y |F].
(ii) (Monotonicity) If X ≥Y a.s., then E[X|F] ≥E[ Y |F].
(iii) If E[|XY|] < ∞and Y is measurable with respect to F, then
E[XY |F] = Y E[X|F]
and
E[ Y |F] = E[ Y |Y] = Y.
(iv) (T owerproperty)
E[E[X|F]|G] = E[E[X|G]|F] = E[X|G].
(v) (T riangleinequality) E[|X|
F] ≥
E[X|F]
.
(vi) (Independence) If σ(X) and F are independent, then E[X|F] = E[X].
(vii) If P[A] ∈{0, 1} for any A ∈F, then E[X|F] = E[X].
(viii) (Dominatedconvergence) Assume Y ∈L1(P), Y ≥0 and (Xn)n∈N is
a sequence of random variables with |Xn| ≤Y for n ∈N and such that
Xn
n→∞
−→X a.s. Then
lim
n→∞E[Xn|F] = E[X|F]
a.s. and in L1(P).
(8.7)

8.2
Conditional Expectations
197
Proof
(i) The right-hand side is F-measurable; hence, for A ∈F,
E)1A
λE[X|F] + E[Y |F]* = λE)1A E[X|F]* + E)1A E[Y |F]*
= λE[1A X] + E[1A Y]
= E
)
1A (λX + Y)
*
.
(ii) Let A = {E[X|F] < E[Y |F]} ∈F. Since we have X ≥Y, we get
E[1A (X −Y)] ≥0 and thus P[A] = 0.
(iii) First assume X ≥0 and Y ≥0. For n ∈N, deﬁne Yn = 2−n⌊2nY⌋. Then
Yn ↑Y and Yn E[X|F] ↑Y E[X|F] (since E[X|F] ≥0 by (ii)). By the
monotone convergence theorem (Lemma 4.6(ii)),
E)1A Yn E[X|F]* n→∞
−→E)1A Y E[X|F]*.
On the other hand,
E)1A Yn E[X|F]* =
∞

k=1
E)1A 1{Yn=k 2−n} k 2−n E[X|F]*
=
∞

k=1
E
)
1A 1{Yn=k 2−n} k 2−n X
*
= E
)
1A YnX
* n→∞
−→E[1A YX].
Hence E[1A Y E[X|F]] = E[1A YX]. In the general case, write X = X+ −
X−and Y = Y +−Y −and exploit the linearity of the conditional expectation.
(iv) The second equality follows from (iii) with Y = E[X|G] and X = 1. Now let
A ∈G. Then, in particular, A ∈F; hence
E)1AE[E[X|F]|G]* = E)1AE[X|F]* = E[1A X] = E)1A E[X|G]*.
(v) This follows from (i) and (ii) with X = X+ −X−.
(vi) Trivially, E[X] is measurable with respect to F. Let A ∈F. Then X and 1A
are independent; hence E[E[X|F] 1A] = E[X 1A] = E[X] E[1A].
(vii) For any A ∈F and B ∈A, we have P[A ∩B] = 0 if P[A] = 0, and
P[A ∩B] = P[B] if P[A] = 1. Hence F and A are independent and thus
F is independent of any sub-σ-algebra of A. In particular, F and σ(X) are
independent. Hence the claim follows from (vi).
(viii) Let |Xn| ≤Y for any n ∈N and Xn
n→∞
−→X almost surely. Deﬁne Zn :=
supk≥n |Xk −X|. Then 0 ≤Zn ≤2Y and Zn
a.s.
−→0. By Corollary 6.26
(dominated convergence), we have E[Zn]
n→∞
−→
0; hence, by the triangle

198
8
Conditional Expectations
inequality,
E)E[Xn|F]−E[X|F]
*≤E[E[|Xn−X|
F]] = E[|Xn−X|] ≤E[Zn]
n→∞
−→0.
However, this is the L1(P)-convergence in (8.7). As (Zn)n∈N is decreasing,
by (ii) also (E[Zn
F])n∈N decreases to some limit, say, Z. By Fatou’s lemma,
E[Z] ≤
lim
n→∞E[E[Zn|F]] = lim
n→∞E[Zn] = 0.
Hence Z = 0 and thus E[Zn
F]
n→∞
−→0 almost surely. However, by (v),
E[Xn
F] −E[X
F]
 ≤E[Zn|F].
⊓⊔
Reﬂection Can we relax the condition in (viii) that the Xn be dominated to uniform
integrability of (Xn)n∈N? ♠♠♠
Remark 8.15 Intuitively, E[X|F] is the best prediction we can make for the value
of X if we only have the information of the σ-algebra F. For example, if σ(X) ⊂F
(that is, if we know X already), then E[X|F] = X, as shown in (iii). At the other
end of the spectrum is the case where X and F are independent; that is, where
knowledge of F does not give any information on X. Here the best prediction for X
is its mean; hence E[X] = E[X|F], as shown in (vi).
What exactly do we mean by “best prediction”? For square integrable random
variables X, by the best prediction for X we will understand the F-measurable
random variable that minimizes the L2-distance from X. The next corollary shows
that the conditional expectation is in fact this minimizer. ♦
Remark 8.16 Let X : Ω →R be a random variable such that X−∈L1(P). We can
deﬁne the conditional expectation as the monotone limit
E[X|F] := lim
n→∞E[Xn|F],
where −X−≤X1 and Xn ↑X. Due to the monotonicity of the conditional
expectation (Theorem 8.14(ii)) it is easy to show that the limit does not depend on
the choice of the sequence (Xn) and that it fulﬁlls the conditions of Deﬁnition 8.11.
Analogously, we can deﬁne the conditional expectation X+ ∈L1(P). For this
generalization of the conditional expectation, we still have E[X|F] ≤E[Y |F] a.s.
if Y ≥X a.s. (see Exercise 8.2.1). ♦
Corollary 8.17 (Conditional expectation as projection) Let F ⊂A be a σ-
algebra and let X be a random variable with E[X2] < ∞. Then E[X|F] is the
orthogonal projection of X on L2(Ω, F, P). That is, for any F-measurable Y with
E[Y 2] < ∞,
E
)
(X −Y)2*
≥E
)
(X −E[X|F])2*
with equality if and only if Y = E[X|F].

8.2
Conditional Expectations
199
Proof First assume that E[E[X|F]2] < ∞. (In Theorem 8.20, we will see
that we have E[E[X|F]2] ≤E[X2], but here we want to keep the proof self-
contained.) Let Y be F-measurable and assume E[Y 2] < ∞. Then, by the Cauchy–
Schwarz inequality, we have E[|XY|] < ∞. Thus, using the tower property,
we infer E[XY] = E[E[X|F]Y] and E
)
XE[X|F]
*
= E
)
E[XE[X|F]
F]
*
=
E
)
E[X|F]2*
. Summing up, we have
E
)
(X −Y)2*
−E
'
X −E[X|F]
2(
= E
'
X2 −2XY + Y 2 −X2 + 2XE[X|F] −E[X|F]2(
= E
'
Y 2 −2Y E[X|F] + E[X|F]2(
= E
'
Y −E[X|F]
2(
≥0.
For the case E[E[X|F]2] < ∞, we are done. Hence, it sufﬁces to show that
this condition follows from the assumption E[X2] < ∞. For N ∈N, deﬁne the
truncated random variables |X| ∧N. Clearly, we have E[E[|X| ∧N |F]2] ≤N2.
By what we have shown already (with X replaced by |X| ∧N and with Y = 0 ∈
L2(Ω, F, P)), and using the elementary inequality a2 ≤2(a −b)2 + 2b2, a, b ∈R,
we infer
E
'
E
)
|X| ∧N
F
*2(
≤2E
'
(|X| ∧N) −E[|X| ∧N
F]
2(
+ 2E
)
(|X| ∧N)2*
≤4E
)
(|X| ∧N)2*
≤4E[X2].
By Theorem 8.14(ii) and (viii), we get E[|X|∧N
F] ↑E[|X|
F] for N →∞. By
the triangle inequality (Theorem 8.14(v)) and the monotone convergence theorem
(Theorem 4.20), we conclude
E
)
E[X|F]2*
≤E
)
E[|X|
F]2*
= lim
N→∞E
)
E[|X| ∧N
F]2*
≤4E[X2] < ∞.
This completes the proof.
⊓⊔
Example 8.18 Let X, Y ∈L1(P) be independent. Then
E[X + Y |Y] = E[X|Y] + E[Y |Y] = E[X] + Y.
♦

200
8
Conditional Expectations
Example 8.19 Let X1, . . . , XN be independent with E[Xi] = 0, i = 1, . . . , N. For
n = 1, . . . , N, deﬁne Fn := σ(X1, . . . , Xn) and Sn := X1 + . . . + Xn. Then, for
n ≥m,
E[Sn
Fm] = E[X1
Fm] + . . . + E[Xn
Fm]
= X1 + . . . + Xm + E[Xm+1] + . . . + E[Xn]
= Sm.
By Theorem 8.14(iv), since σ(Sm) ⊂Fm, we have
E[Sn|Sm] = E
)
E[Sn|Fm]
Sm
*
= E[Sm|Sm] = Sm.
♦
Next we show Jensen’s inequality for conditional expectations.
Theorem 8.20 (Jensen’s inequality) Let I ⊂R be an interval, let ϕ : I →R
be convex and let X be an I-valued random variable on (Ω, A, P). Further, let
E[|X|] < ∞and let F ⊂A be a σ-algebra. Then
∞≥E[ϕ(X)|F] ≥ϕ(E[X|F]).
Proof For the existence of E[ϕ(X)|F] with values in (−∞, ∞] note that ϕ(X)−∈
L1(P) and see Remark 8.16. By Exercise 8.2.2, we have E[X|F] ∈I a.s., hence
ϕ(E[X|F]) is well-deﬁned.
(Recall from Deﬁnition 1.68 the jargon words “almost surely on A”.) Note that
X = E[X|F] on the event {E[X|F] is a boundary point of I}; hence here the
claim is trivial. Indeed, without loss of generality, assume 0 is the left boundary
of I and A := {E[X|F] = 0}. As X assumes values in I ⊂[0, ∞), we have
0 ≤E[X 1A] = E[E[X|F] 1A] = 0; hence X1A = 0. The case of a right boundary
point is similar.
Hence now consider the event B := {E[X|F] is an interior point of I}. For every
interior point x ∈I, let D+ϕ(x) be the maximal slope of a tangent of ϕ at x; i.e.,
the maximal number t with ϕ(y) ≥(y −x)t +ϕ(x) for all y ∈I (see Theorem 7.7).
For each x ∈I ◦, there exists a P-null set Nx such that, for every ω ∈B \ Nx, we
have
E
)
ϕ(X)|F
*
(ω) ≥ϕ(x) + E
)
D+ϕ(x) (X −x)
F
*
(ω)
= ϕ(x) + D+ϕ(x) E[X|F](ω) −x =: ψω(x).
(8.8)
Let V := Q ∩I ◦. Then N := 
x∈V Nx is a P-null set and (8.8) holds for every
ω ∈B \ N and every x ∈V .

8.2
Conditional Expectations
201
The map x →D+ϕ(x) is right continuous (by Theorem 7.7(iv)). Therefore
x →ψω(x) is also right continuous. Hence, for every ω ∈B \ N, we have
ϕE[X|F](ω) = ψω
E[X|F](ω)
≤sup
x∈I ◦ψω(x) = sup
x∈V
ψω(x) ≤E
)
ϕ(X)|F
*
(ω).
(8.9)
⊓⊔
Corollary 8.21 Let p ∈[1, ∞] and let F ⊂A be a sub-σ-algebra. Then the map
Lp(Ω, A, P) →Lp(Ω, F, P),
X →E[X|F],
is a contraction (that is, ∥E[X|F]∥p ≤∥X∥p) and thus continuous. Hence, for
X, X1, X2, . . . ∈Lp(Ω, A, P) with ∥Xn −X∥p
n→∞
−→0,
;;E[Xn|F] −E[X|F]
;;
p
n→∞
−→0.
Proof For p ∈[1, ∞), use Jensen’s inequality with ϕ(x) = |x|p. For p = ∞, note
that |E[X|F]| ≤E[|X||F] ≤E[∥X∥∞
F] = ∥X∥∞.
⊓⊔
Corollary 8.22 Let (Xi, i ∈I) be uniformly integrable and let (Fj, j ∈J) be a
family of sub-σ-algebras of A. Deﬁne Xi,j := E[Xi
Fj]. Then (Xi,j, (i, j) ∈I ×
J) is uniformly integrable. In particular, for X ∈L1(P), the family (E[X|Fj], j ∈
J) is uniformly integrable.
Proof By Theorem 6.19, there exists a monotone increasing convex function f with
the property that f (x)/x →∞, x →∞and L := supi∈I E[f (|Xi|)] < ∞. Then
x →f (|x|) is convex; hence, by Jensen’s inequality,
E
)
f (|Xi,j|)
*
= E
)
f
E[Xi |Fj]
*
≤L < ∞.
Thus (Xi,j, (i, j) ∈I × J) is uniformly integrable by Theorem 6.19.
⊓⊔
Example 8.23 Let μ and ν be ﬁnite measures with ν ≪μ. Let f = dν
@
dμ be
the Radon–Nikodym derivative and let I = {F ⊂A : F is a σ-algebra}. Consider
the measures μF and νF that are restricted to F. Then ν
CF ≪μ
CF (since
in F there are fewer μ-null sets); hence the Radon–Nikodym derivative fF :=
dν
CF@dμ
CF exists. Then (fF : F ∈I) is uniformly integrable (with respect
to μ). (For ﬁnite σ-algebras F, this was shown in Example 7.39.) Indeed, let P =
μ/μ(Ω) and Q = ν/μ(Ω). Then fF = dQ
CF
@
dP
CF. For any F ∈F, we
thus have E[fF 1F ] =
3
F fF dP = Q(F) =
3
F f dP = E[f 1F ]; hence fF =
E[f |F]. By the preceding corollary, (fF : F ∈I) is uniformly integrable with
respect to P and thus also with respect to μ. ♦

202
8
Conditional Expectations
Takeaways The conditional expectation of a random variable X given a σ-
algebra F is the best prediction on X that can be made given the information
coded in F (at least if X has a second moment). On the technical side,
the conditional expectation is constructed via the Radon-Nikodym theorem.
It shares the main properties of ordinary expectations (linearity, triangle
inequality, monotone and dominated convergence, Jensen’s inequality) and
in addition has the so-called tower property.
Exercise 8.2.1 Show the assertions of Remark 8.16. ♣
Exercise 8.2.2 Let I ⊂R be an arbitrary interval and let X ∈L1(Ω, A, P) be
a random variable such that X ∈I a.s. For F ⊂A, show that E[X|F] ∈I a.s.
Is this statement still true if we require only X−∈L1(Ω, A, P) instead of X ∈
L1(Ω, A, P)? ♣
Exercise 8.2.3 (Bayes’ formula)
Let A ∈A and B ∈F ⊂A. Show that
P[B|A] =
3
B P[A|F] dP
3
P[A|F] dP .
If F is generated by pairwise disjoint sets B1, B2, . . ., then this is exactly Bayes’
formula of Theorem 8.7. ♣
Exercise 8.2.4 Give an example for E[E[X|F]|G] ̸= E[E[X|G]|F]. ♣
Exercise 8.2.5 Show the conditional Markov inequality: For monotone increasing
f : [0, ∞) →[0, ∞) and ε > 0 with f (ε) > 0,
P)|X| ≥ε|F* ≤E
)
f (|X|)
F
*
f (ε)
.
♣
Exercise 8.2.6 Show the conditional Cauchy–Schwarz inequality: For square inte-
grable random variables X, Y,
E[XY |F]2 ≤E[X2|F] E[Y 2|F].
♣
Exercise 8.2.7 Let X1, . . . , Xn be integrable i.i.d. random variables. Let Sn =
X1 + . . . + Xn. Show that
E[Xi |Sn] = 1
n Sn
for every i = 1, . . . , n.
♣
Exercise 8.2.8 Let X1 and X2 be independent and exponentially distributed with
parameter θ > 0. Compute E[X1 ∧X2|X1]. ♣

8.3
Regular Conditional Distribution
203
Exercise 8.2.9 Let X and Y be real random variables with joint density f and let
h : R →R be measurable with E[|h(X)|] < ∞. Denote by λ the Lebesgue measure
on R.
(i) Show that almost surely
E[h(X)|Y] =
3
h(x)f (x, Y) λ(dx)
3
f (x, Y) λ(dx)
.
(ii) Let X and Y be independent and expθ-distributed for some θ > 0. Compute
E[X|X + Y] and P[X ≤x |X + Y] for x ≥0. ♣
8.3
Regular Conditional Distribution
Let X be a random variable with values in a measurable space (E, E). With our
machinery, so far we can deﬁne the conditional probability P[A|X] for ﬁxed A ∈A
only. However, we would like to deﬁne for every x ∈E a probability measure
P[ · |X = x] such that for any A ∈A, we have P[A|X] = P[A|X = x] on
{X = x}. In this section, we show how to do this.
For example, we are interested in a two-stage random experiment. At the ﬁrst
stage, we manipulate a coin at random such that the probability of a success (i.e.,
“head”) is X. At the second stage, we toss the coin n times independently with
outcomes Y1, . . . , Yn. Hence the “conditional distribution of (Y1, . . . , Yn) given
{X = x}” should be (Berx)⊗n.
Let X be as above and let Z be a σ(X)-measurable real random variable. By
the factorization lemma (Corollary 1.97 with f = X and g = Z), there is a map
ϕ : E →R such that
ϕ is E – B(R)-measurable
and
ϕ(X) = Z.
(8.10)
If X is surjective, then ϕ is determined uniquely. In this case, we denote Z ◦X−1 :=
ϕ (even if the inverse map X−1 itself does not exist).
Deﬁnition 8.24 Let Y
∈L1(P) and X : (Ω, A) →(E, E). We deﬁne the
conditional expectation of Y given X = x by E[Y |X = x] := ϕ(x), where ϕ is
the function from (8.10) with Z = E[Y |X].
Analogously, deﬁne P[A|X = x] = E[1A
X = x] for A ∈A.
For a ﬁxed set B ∈A with P[B] > 0, the conditional probability P[ · |B] is a
probability measure. Is this true also for P[ · |X = x]? The question is a bit tricky
since for every given A ∈A, the expression P[A|X = x] is deﬁned for almost all
x only; that is, up to x in a null set that may, however, depend on A. Since there are
uncountably many A ∈A in general, we could not simply unite all the exceptional

204
8
Conditional Expectations
sets for any A. However, if the σ-algebra A can be approximated by countably many
A sufﬁciently well, then there is hope.
Our ﬁrst task is to give precise deﬁnitions. Then we present the theorem that
justiﬁes our hope.
Deﬁnition 8.25 (Transition kernel, Markov kernel) Let (Ω1, A1), (Ω2, A2) be
measurable spaces. A map κ : Ω1 × A2 →[0, ∞] is called a (σ-)ﬁnite transition
kernel (from Ω1 to Ω2) if:
(i) ω1 →κ(ω1, A2) is A1-measurable for any A2 ∈A2.
(ii) A2 →κ(ω1, A2) is a (σ-)ﬁnite measure on (Ω2, A2) for any ω1 ∈Ω1.
If in (ii) the measure is a probability measure for all ω1 ∈Ω1, then κ is called a
stochastic kernel or a Markov kernel. If in (ii) we also have κ(ω1, Ω2) ≤1 for
any ω1 ∈Ω1, then κ is called sub-Markov or substochastic.
Remark 8.26 It is sufﬁcient to check property (i) in Deﬁnition 8.25 for sets A2 from
a π-system E that generates A2 and that either contains Ω2 or a sequence En ↑Ω2.
Indeed, in this case,
D :=
	
A2 ∈A2 : ω1 →κ(ω1, A2) is A1-measurable

is a λ-system (exercise!). Since E ⊂D, by the π–λ theorem (Theorem 1.19), D =
σ(E) = A2. ♦
Example 8.27
(i) Let (Ω1, A1) and (Ω2, A2) be discrete measurable spaces and let (Kij) i∈Ω1
j∈Ω2
be a matrix with nonnegative entries and ﬁnite row sums
Ki :=

j∈Ω2
Kij < ∞
for i ∈Ω1.
Then we can deﬁne a ﬁnite transition kernel from Ω1 to Ω2 by κ(i, A) =

j∈A Kij. κ is stochastic if Ki = 1 for all i ∈Ω1. It is substochastic if
Ki ≤1 for all i ∈Ω1.
(ii) If μ2 is a ﬁnite measure on Ω2, then κ(ω1, ·) ≡μ2 is a ﬁnite transition kernel.
(iii) κ(x, ·) = Poix is a stochastic kernel from [0, ∞) to N0 (note that x →
Poix(A) is continuous and hence measurable for all A ⊂N0).
(iv) Let μ be a distribution on Rn and let X be a random variable with PX = μ.
Then κ(x, ·) = P[X + x ∈·] = δx ∗μ deﬁnes a stochastic kernel from
Rn to Rn. Indeed, the sets (−∞, y], y ∈Rn form an ∩-stable generator of
B(Rn) and x →κ(x, (−∞, y]) = μ((−∞, y −x]) is left continuous and
hence measurable. Hence, by Remark 8.26, x →κ(x, A) is measurable for all
A ∈B(Rn). ♦

8.3
Regular Conditional Distribution
205
Deﬁnition 8.28 Let Y be a random variable with values in a measurable space
(E, E) and let F ⊂A be a sub-σ-algebra. A stochastic kernel κY,F from (Ω, F) to
(E, E) is called a regular conditional distribution of Y given F if
κY,F(ω, B) = P[{Y ∈B}|F](ω)
for P-almost all ω ∈Ω and for all B ∈E; that is, if

1B(Y) 1A dP =

κY,F( ·, B) 1A dP
for all A ∈F, B ∈E.
(8.11)
Consider the special case where F = σ(X) for a random variable X (with values
in an arbitrary measurable space (E′, E′)). Then the stochastic kernel
(x, A) →κY,X(x, A) = P[{Y ∈A}|X = x] = κY,σ(X)

X−1(x), A

(the function from the factorization lemma with an arbitrary value for x ̸∈X(Ω)) is
called a regular conditional distribution of Y given X.
Theorem 8.29 (Regular conditional distributions in R) Let Y
: (Ω, A) →

R, B(R)

be real-valued. Then there exists a regular conditional distribution κY,F
of Y given F.
Proof The strategy of the proof consists in constructing a measurable version of
the distribution function of the conditional distribution of Y by ﬁrst deﬁning it for
rational values (up to a null set) and then extending it to the real numbers.
For r ∈Q, let F(r, ·) be a version of the conditional probability P[Y
∈
(−∞, r]|F]. For r ≤s, clearly 1{Y∈(−∞,r]} ≤1{Y∈(−∞,s]}. Hence, by The-
orem 8.14(ii) (monotonicity of the conditional expectation), there is a null set
Ar,s ∈F with
F(r, ω) ≤F(s, ω)
for all ω ∈Ω \ Ar,s.
(8.12)
By Theorem 8.14(viii) (dominated convergence), there are null sets Br ∈F, r ∈Q,
and C ∈F such that
lim
n→∞F

r + 1
n, ω

= F(r, ω)
for all ω ∈Ω \ Br
(8.13)
as well as
inf
n∈N F(−n, ω) = 0
and
sup
n∈N
F(n, ω) = 1
for all ω ∈Ω \ C.
(8.14)
Let N :=
 
r,s∈Q Ar,s

∪
 
r∈Q Br

∪C. For ω ∈Ω \ N, deﬁne
˜F(z, ω) := inf
	
F(r, ω) : r ∈Q, r > z

for all z ∈R.

206
8
Conditional Expectations
By construction, ˜F( ·, ω) is monotone increasing and right continuous. By (8.12)
and (8.13), we have
˜F(z, ω) = F(z, ω)
for all z ∈Q and ω ∈Ω \ N.
(8.15)
Therefore, by (8.14), ˜F( ·, ω) is a distribution function for any ω ∈Ω \ N. For ω ∈
N, deﬁne ˜F( ·, ω) = F0, where F0 is an arbitrary but ﬁxed distribution function.
For any ω ∈Ω, let κ(ω, ·) be the probability measure on (Ω, A) with
distribution function ˜F( ·, ω). Then, for r ∈Q and B = (−∞, r],
ω →κ(ω, B) = F(r, ω) 1Nc(ω) + F0(r) 1N(ω)
(8.16)
is F-measurable. Now {(−∞, r], r ∈Q} is a π-system that generates B(R). By
Remark 8.26, measurability holds for all B ∈B(R) and hence κ is identiﬁed as a
stochastic kernel.
We still have to show that κ is a version of the conditional distribution. For A ∈
F, r ∈Q and B = (−∞, r], by (8.16),

A
κ(ω, B) P[dω] =

A
P
)
Y ∈B|F
*
dP = P
)
A ∩{Y ∈B}
*
.
As functions of B, both sides are ﬁnite measures on B(R) that coincide on the ∩-
stable generator
	
(−∞, r], r ∈Q

. By the uniqueness theorem (Lemma 1.42), we
thus have equality for all B ∈B(R). Hence P-a.s. κ( ·, B) = P[Y ∈B|F] and thus
κ = κY,F.
⊓⊔
Example 8.30 Let Z1, Z2 be independent Poisson random variables with parame-
ters λ1, λ2 ≥0. One can show (exercise!) that (with Y = Z1 and X = Z1 + Z2)
P[Z1 = k
Z1 + Z2 = n] = bn,p(k)
for k = 0, . . . , n,
where p =
λ1
λ1+λ2 . ♦
This example could still be treated by elementary means. The full strength of the
result is displayed in the following examples.
Example 8.31 Let X and Y be real random variables with joint density f (with
respect to Lebesgue measure λ2 on R2). For x ∈R, deﬁne
fX(x) =

R
f (x, y) λ(dy).

8.3
Regular Conditional Distribution
207
Clearly, fX(x) > 0 for PX-a.a. x ∈R and f −1
X
is the density of the absolutely
continuous part of the Lebesgue measure λ with respect to PX. The regular
conditional distribution of Y given X has density
P[Y ∈dy |X = x]
dy
= fY|X(x, y) := f (x, y)
fX(x)
for PX[dx]-a.a. x ∈R.
(8.17)
Indeed, by Fubini’s theorem (Theorem 14.19), the map x →3
B fY|X(x, y) λ(dy) is
measurable for all B ∈B(R) and for A, B ∈B(R), we have

A
P[X ∈dx]

B
fY|X(x, y) λ(dy)
=

A
P[X ∈dx] fX(x)−1

B
f (x, y) λ(dy)
=

A
λ(dx)

B
f (x, y) λ(dy)
=

A×B
f dλ2 = P[X ∈A, Y ∈B].
♦
Example 8.32 Let μ1, μ2 ∈R, σ1, σ2 > 0 and let Z1, Z2 be independent and
Nμi,σ 2
i -distributed (i = 1, 2). Then there exists a regular conditional distribution
P[Z1 ∈· |Z1 + Z2 = x]
for x ∈R.
If we deﬁne X = Z1 + Z2 and Y = Z1, then (X, Y) ∼Nμ,Σ is bivariate
normally distributed with covariance matrix Σ :=
σ 2
1 + σ 2
2 σ 2
1
σ 2
1
σ 2
1

and with μ :=
μ1 + μ2
μ1

. Note that
Σ−1 =

σ 2
1 σ 2
2
−1
 σ 2
1
−σ 2
1
−σ 2
1 σ 2
1 + σ 2
2

= (σ 2
1 σ 2
2 )−1 BT B,

208
8
Conditional Expectations
where B =
σ1 −σ1
0
σ2

. Hence (X, Y) has the density (see Example 1.105(ix))
f (x, y) = det(2π Σ)−1/2 exp

−
1
2σ 2
1 σ 2
2
;;;;B
x −(μ1 + μ2)
y −μ1
;;;;
2
=

4π2σ 2
1 σ 2
2
−1/2 exp

−σ 2
1 (y −(x −μ2))2 + σ 2
2 (y −μ1)2
2σ 2
1 σ 2
2

= Cx exp

−(y −μx)2/2σ 2
x

.
Here Cx is a normalising constant and
μx = μ1 +
σ 2
1
σ 2
1 + σ 2
2
(x −μ1 −μ2)
and
σ 2
x =
σ 2
1 σ 2
2
σ 2
1 + σ 2
2
.
By (8.17), P[Z1 ∈· |Z1 + Z2 = x] has the density
y →fY|X(x, y) =
Cx
fX(x) exp

−(y −μx)2
2σ 2x

,
hence
P[Z1 ∈· |Z1 + Z2 = x] = Nμx,σ 2x for almost all x ∈R.
♦
Example 8.33 If X and Y are independent real random variables, then for PX-
almost all x ∈R
P[X + Y ∈· |X = x] = δx ∗PY .
♦
The situation is not completely satisfying as we have made the very restrictive
assumption that Y is real-valued. Originally we were also interested in the situation
where Y takes values in Rn or in even more general spaces. We now extend the
result to a larger class of ranges for Y.
Deﬁnition 8.34 Two measurable spaces (E, E) and (E′, E′) are called isomorphic
if there exists a bijective map ϕ : E →E′ such that ϕ is E – E′-measurable and
the inverse map ϕ−1 is E′ – E-measurable. Then we say that ϕ is an isomorphism
of measurable spaces. If in addition μ and μ′ are measures on (E, E) and (E′, E′)
and if μ′ = μ ◦ϕ−1, then ϕ is an isomorphism of measure spaces, and the measure
spaces (E, E, μ) and (E′, E′, μ′) are called isomorphic.
Deﬁnition 8.35 A measurable space (E, E) is called a Borel space if there exists a
Borel set B ∈B(R) such that (E, E) and (B, B(B)) are isomorphic.

8.3
Regular Conditional Distribution
209
A separable topological space whose topology is induced by a complete metric is
called a Polish space. In particular, Rd, Zd, RN, (C([0, 1]), ∥· ∥∞) and so forth are
Polish. Closed subsets of Polish spaces are again Polish. We come back to Polish
spaces in the context of convergence of measures in Chap. 13. Without proof, we
present the following topological result (see, e.g., [37, Theorem 13.1.1]).
Theorem 8.36 Let E be a Polish space with Borel σ-algebra E. Then (E, E) is a
Borel space.
Theorem 8.37 (Regular conditional distribution) Let F
⊂A be a sub-σ-
algebra. Let Y be a random variable with values in a Borel space (E, E) (hence,
for example, E Polish, E = Rd, E = R∞, E = C([0, 1]), etc.). Then there exists a
regular conditional distribution κY,F of Y given F.
Proof Let B ∈B(R) and let ϕ : E →B be an isomorphism of measurable spaces.
By Theorem 8.29, we obtain the regular conditional distribution κY ′,F of the real
random variable Y ′ = ϕ ◦Y. Now deﬁne κY,F(ω, A) = κY ′,F(ω, ϕ(A)) for A ∈E.
⊓⊔
To conclude, we pick up again the example with which we started. Now we
can drop the quotation marks from the statement and write it down formally.
Hence, let X be uniformly distributed on [0, 1]. Given X = x, let (Y1, . . . , Yn)
be independent and Berx-distributed. Deﬁne Y = (Y1, . . . , Yn). By Theorem 8.37
(with E = {0, 1}n ⊂Rn), a regular conditional distribution exists:
κY,X(x, ·) = P[Y ∈· |X = x]
for x ∈[0, 1].
Indeed, for almost all x ∈[0, 1],
P[Y ∈· |X = x] = (Berx)⊗n.
Theorem 8.38 Let X be a random variable on (Ω, A, P) with values in a Borel
space (E, E). Let F ⊂A be a σ-algebra and let κX,F be a regular conditional
distribution of X given F. Further, let f : E →R be measurable and E[|f (X)|] <
∞. Then
E[f (X)|F](ω) =

f (x) κX,F(ω, dx)
for P-almost all ω.
(8.18)
Proof We check that the right-hand side in (8.18) has the properties of the
conditional expectation.
It is enough to consider the case f ≥0. By approximating f by simple functions,
we see that the right-hand side in (8.18) is F-measurable (see Lemma 14.23 for a
formal argument). Hence, by Theorem 1.96, there exist sets A1, A2, . . . ∈E and
numbers α1, α2, . . . ≥0 such that
gn :=
n

i=1
αi 1Ai
n→∞
−→f.

210
8
Conditional Expectations
Now, for any n ∈N and B ∈F,
E[gn(X) 1B] =
n

i=1
αi P[{X ∈Ai} ∩B]
=
n

i=1
αi

B
P[{X ∈Ai}|F] P[dω]
=
n

i=1
αi

B
κX,F(ω, Ai) P[dω]
=

B
n

i=1
αi κX,F(ω, Ai) P[dω]
=

B

gn(x) κX,F(ω, dx)

P[dω].
By the monotone convergencetheorem, for almost all ω, the inner integral converges
to
3
f (x)κX,F(ω, dx). Applying the monotone convergence theorem once more,
we get
E[f (X) 1B] =
lim
n→∞E[gn(X) 1B] =

B

f (x) κX,F(ω, dx) P[dω].
⊓⊔
Takeaways Consider the conditional probability of some event B given a
σ-algebra. If it is chosen such that as a function of B it is a probability
measure (almost surely), then it is called a regular version of the conditional
probabilities. The existence is nontrivial as there can be uncountably many
events B and the conditional probability is deﬁned only up to null sets. So it
is an important theorem that a regular version of the conditional probabilities
exists at least on Polish spaces (like Rd).
Exercise 8.3.1 Let (E, E) be a Borel space and let μ be an atom-free measure (that
is, μ({x}) = 0 for any x ∈E). Show that for any A ∈E and any n ∈N, there exist
pairwise disjoint sets A1, . . . , An ∈E with n
k=1 Ak = A and μ(Ak) = μ(A)/n
for any k = 1, . . . , n. ♣
Exercise 8.3.2 Let p, q ∈(1, ∞) with
1
p + 1
q = 1 and let X ∈Lp(P) and
Y ∈Lq(μ). Let F ⊂A be a σ-algebra. Use the preceding theorem to show the
conditional version of Hölder’s inequality:
E
)
|XY|
F
*
≤E
)
|X|p F
*1/p E
)
|Y|q F
*1/q
almost surely.
♣

8.3
Regular Conditional Distribution
211
Exercise 8.3.3 Assume the random variable (X, Y) is uniformly distributed on the
disc B := {(x, y) ∈R2 : x2 + y2 ≤1} and on [−1, 1]2, respectively.
(i) In both cases, determine the conditional distribution of Y given X = x.
(ii) Let R :=
√
X2 + Y 2 and Θ = arctan(Y/X). In both cases, determine the
conditional distribution of Θ given R = r. ♣
Exercise 8.3.4 Let A ⊂Rn be a Borel measurable set of ﬁnite Lebesgue measure
λ(A) ∈(0, ∞) and let X be uniformly distributed on A (see Example 1.75). Let
B ⊂A be measurable with λ(B) > 0. Show that the conditional distribution of X
given {X ∈B} is the uniform distribution on B. ♣
Exercise 8.3.5 (Borel’s paradox) Consider the Earth as a ball (as widely accepted
nowadays). Let X be a random point that is uniformly distributed on the surface.
Let Θ be the longitude and let Φ be the latitude of X. A little differently from the
usual convention, assume that Θ takes values in [0, π) and Φ in [−π, π). Hence,
for ﬁxed Θ, a complete great circle is described when Φ runs through its domain.
Now, given Θ, is Φ uniformly distributed on [−π, π)? One could conjecture that
any point on the great circle is equally likely. However, this is not the case! If we
thicken the great circle slightly such that its longitudes range from Θ to Θ + ε (for
a small ε), on the equator it is thicker (measured in meters) than at the poles. If we
let ε →0, intuitively we should get the conditional probabilities as proportional to
the thickness (in metres).
(i) Show that P[{Φ ∈·}|Θ = θ] for almost all θ has the density 1
4| cos(φ)| for
φ ∈[−π, π).
(ii) Show that P[{Θ ∈·}|Φ = φ] = U[0,π) for almost all φ.
Hint: Show that Θ and Φ are independent, and compute the distributions of Θ
and Φ. ♣
Exercise 8.3.6 (Rejection sampling for generating random variables) Let E be
a countable set and let P and Q be probability measures on E. Assume there is a
c > 0 with
f (e) := Q({e})
P({e}) ≤c
for all e ∈E with P({e}) > 0.
Let X1, X2, . . . be independent random variables with distribution P. Let
U1, U2, . . . be i.i.d. random variables that are independent of X1, X2, . . . and
that are uniformly distributed on [0, 1]. Let N be the smallest (random) nonnegative
integer n such that Un ≤f (Xn)/c and deﬁne Y := XN.
Show that Y has distribution Q.
Remark This method for generating random variables with a given distribution Q
is called rejection sampling, as it can also be described as follows. The random
variable X1 is a proposal for the value of Y. This proposal is accepted with
probability f (X1)/c and is rejected otherwise. If the ﬁrst proposal is rejected, the
game starts afresh with proposal X2 and so on. ♣

212
8
Conditional Expectations
Exercise 8.3.7 Let E be a Polish space and let P, Q ∈M1(R). Let c > 0 with
f := dQ
dP ≤c P-almost surely. Show the statement analogous to Exercise 8.3.6. ♣
Exercise 8.3.8 Show that (R, B(R)) and

Rn, B(Rn)

are isomorphic. Conclude
that every Borel set B ∈B(Rn) is a Borel space. ♣

Chapter 9
Martingales
One of the most important concepts of modern probability theory is the martingale,
which formalizes the notion of a fair game. In this chapter, we ﬁrst lay the
foundations for the treatment of general stochastic processes. We then introduce
martingales and the discrete stochastic integral. We close with an application to a
model from mathematical ﬁnance.
9.1
Processes, Filtrations, Stopping Times
We introduce the fundamental technical terms for the investigation of stochastic
processes (including martingales). In order to be able to recycle the terms later in a
more general context, we go for greater generality than is necessary for the treatment
of martingales only.
In the following, let (E, τ) be a Polish space with Borel σ-algebra E. Further,
let (Ω, F, P) be a probability space and let I ⊂R be arbitrary. We are mostly
interested in the cases I = N0, I = Z, I = [0, ∞) and I an interval.
Deﬁnition 9.1 (Stochastic process) Let I ⊂R. A family of random variables X =
(Xt, t ∈I) (on (Ω, F, P)) with values in (E, E) is called a stochastic process with
index set (or time set) I and range E.
Remark 9.2 Sometimes families of random variables with more general index sets
are called stochastic processes. We come back to this with the Poisson point process
in Chap. 24. ♦
Remark 9.3 Following a certain tradition, we will often denote a stochastic process
by X = (Xt)t∈I if we want to emphasize the “time evolution” aspect rather than the
formal notion of a family of random variables. Formally, both objects are of course
the same. ♦
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_9
213

214
9
Martingales
Example 9.4 Let I = N0 and let (Yn, n ∈N) be a family of i.i.d. Rad1/2-random
variables on a probability space (Ω, F, P); that is, random variables with
P[Yn = 1] = P[Yn = −1] = 1
2.
Let E = Z (with the discrete topology) and let
Xt =
t
n=1
Yn
for all t ∈N0.
(Xt, t ∈N0) is called a symmetric simple random walk on Z. ♦
Example 9.5 The Poisson process X = (Xt)t≥0 with intensity α > 0 (see Sect. 5.5)
is a stochastic process with range N0. ♦
We introduce some further terms.
Deﬁnition 9.6 If X is a random variable (or a stochastic process), we write L[X] =
PX for the distribution of X. If G ⊂F is a σ-algebra, then we write L[X|G] for
the regular conditional distribution of X given G.
Deﬁnition 9.7 An E-valued stochastic process X = (Xt)t∈I is called
(i) real-valued if E = R,
(ii) a process with independent increments if X is real-valued and for all n ∈N
and all t0, . . . , tn ∈I with t0 < t1 < . . . < tn, we have that
(Xti −Xti−1)i=1,...,n is independent,
(iii) a Gaussian process if X is real-valued and for all n ∈N and t1, . . . , tn ∈I,
(Xt1, . . . , Xtn) is n-dimensional normally distributed, and
(iv) integrable (respectively square integrable) if
X
is real-valued and
E[|Xt|] < ∞(respectively E[(Xt)2] < ∞) for all t ∈I.
Now assume that I ⊂R is closed under addition. Then X is called
(v) stationary if L
)
(Xs+t)t∈I
*
= L
)
(Xt)t∈I
*
for all s ∈I, and
(vi) a process with stationary increments if X is real-valued and
L
)
Xs+t+r −Xt+r
*
= L
)
Xs+r −Xr
*
for all r, s, t ∈I.
(If 0 ∈I, then it is enough to consider r = 0.)

9.1
Processes, Filtrations, Stopping Times
215
Example 9.8
(i) The Poisson process with intensity θ and the random walk on Z are processes
with stationary independent increments.
(ii) If Xt, t ∈I, are i.i.d. random variables, then (Xt)t∈I is stationary.
(iii) Let (Xn)n∈Z be real-valued and stationary and let k ∈N and c0, . . . , ck ∈R.
Deﬁne
Yn :=
k

i=0
ciXn−i.
Then Y = (Yn)n∈Z is a stationary process. If c0, . . . , ck ≥0 and c0+. . .+ck =
1, then Y is called the moving average of X (with weights c0, . . . , ck). ♦
The following two deﬁnitions make sense also for more general index sets I that
are partially ordered. However, we restrict ourselves to the case I ⊂R.
Deﬁnition 9.9 (Filtration)
Let F = (Ft, t ∈I) be a family of σ-algebras with
Ft ⊂F for all t ∈I. F is called a ﬁltration if Fs ⊂Ft for all s, t ∈I with s ≤t.
Deﬁnition 9.10 A stochastic process X = (Xt, t ∈I) is called adapted to the
ﬁltration F if Xt is Ft-measurable for all t ∈I. If Ft = σ(Xs, s ≤t) for all t ∈I,
then we denote by F = σ(X) the ﬁltration that is generated by X.
Remark 9.11 Clearly, a stochastic process is always adapted to the ﬁltration it
generates. Hence the generated ﬁltration is the smallest ﬁltration to which the
process is adapted. ♦
Deﬁnition 9.12 (Predictable) Let I = N0 or I = N. A stochastic process X =
(Xn, n ∈I) is called predictable (or previsible) with respect to the ﬁltration F =
(Fn, n ∈N0) if X0 is constant (if I = N0) and if for every n ∈N,
Xn is Fn−1-measurable.
Example 9.13 Let I = N0 and let Y1, Y2, . . . be real random variables. For n ∈N0,
deﬁne Xn := n
m=1 Ym. Let
F0 = {∅, Ω}
and
Fn = σ(Y1, . . . , Yn)
for n ∈N.
Then F = (Fn, n ∈N0) = σ(Y) is the ﬁltration generated by Y = (Yn)n∈N and X
is adapted to F; hence σ(X) ⊂F. Clearly, (Y1, . . . , Yn) is measurable with respect
to σ(X1, . . . , Xn); hence σ(Y) ⊂σ(X), and thus also F = σ(X).
Now let 
Xn := n
m=1 1[0,∞)(Ym). Then 
X is also adapted to F; however, in
general, F ⫌σ(
X). ♦
Example 9.14 Let I = N0 and let D1, D2, . . . be i.i.d. Rad1/2-distributed random
variables (that is, P[Di = −1] = P[Di = 1] = 1
2 for all i ∈N). Let D = (Di)i∈N
and F = σ(D). We interpret Di as the result of a bet that gives a gain or loss of one

216
9
Martingales
euro for every euro we put at stake. Just before each gamble we decide how much
money we bet. Let Hn be the number of euros to bet in the nth gamble. Clearly, Hn
may only depend on the results of the gambles that happened earlier, but not on Dm
for any m ≥n. To put it differently, there must be a function Fn : {−1, 1}n−1 →
N such that Hn = Fn(D1, . . . , Dn−1). (For example, for the Petersburg game
(Example 4.22) we had Fn(x1, . . . , xn−1) = 2n−1 1{x1=x2=...=xn−1=0}.) Hence
H is predictable. On the other hand, any predictable H has the form Hn =
Fn(D1, . . . , Dn−1), n ∈N, for certain functions Fn : {−1, 1}n−1 →N. Hence
any predictable H is an admissible gambling strategy. ♦
Deﬁnition 9.15 (Stopping time) A random variable τ with values in I ∪{∞} is
called a stopping time (with respect to F) if for any t ∈I
{τ ≤t} ∈Ft.
The idea is that Ft reﬂects the knowledge of an observer at time t. Whether or
not {τ ≤t} is true can thus be determined on the basis of the information available
at time t.
Theorem 9.16 Let I be countable. τ is a stopping time if and only if {τ = t} ∈Ft
for all t ∈I.
Proof This is left as an exercise!
⊓⊔
Example 9.17 Let I = N0 (or, more generally, let I ⊂[0, ∞) be right-discrete;
that is, t < inf I ∩(t, ∞) for all t ≥0, and hence I in particular is countable)
and let K ⊂R be measurable. Let X be an adapted real-valued stochastic process.
Consider the ﬁrst time that X is in K:
τK := inf{t ∈I : Xt ∈K}.
It is intuitively clear that τK should be a stopping time since we can determine by
observation up to time t whether {τK ≤t} occurs. Formally, we argue that {Xs ∈
K} ∈Fs ⊂Ft for all s ≤t. Hence also the countable union of these sets is in Ft:
{τK ≤t} =

s∈I∩[0,t]
{Xs ∈K} ∈Ft.
Consider now the random time τ := sup{t ∈I : Xt ∈K} of the last visit of X
to K. For a ﬁxed time t, on the basis of previous observations, we cannot determine
whether X is already in K for the last time. For this we would have to rely on
prophecy. Hence, in general, τ is not a stopping time. ♦
Lemma 9.18 Let I ⊂[0, ∞) be closed under addition and let σ and τ be stopping
times. Then:
(i) σ ∨τ and σ ∧τ are stopping times.
(ii) If σ, τ ≥0, then σ + τ is also a stopping time.
(iii) If s ≥0, then τ + s is a stopping time. However, in general, τ −s is not.

9.1
Processes, Filtrations, Stopping Times
217
Before we present the (simple) formal proof, we state that in particular (i) and (iii)
are properties we would expect of stopping times. With (i), the interpretation is
clear. For (iii), note that τ −s peeks into the future by s time units (in fact, {τ −s ≤
t} ∈Ft+s), while τ + s looks back s time units. For stopping times, however, only
retrospection is allowed.
Proof
(i) For t ∈I, we have {σ ∨τ ≤t} = {σ ≤t} ∩{τ ≤t} ∈Ft and {σ ∧τ ≤t} =
{σ ≤t} ∪{τ ≤t} ∈Ft.
(ii) Let t ∈I. By (9.18), τ ∧t and σ ∧t are stopping times for any t ∈I. In
particular, {τ ∧t ≤s} ∈Fs ⊂Ft for any s ≤t. On the other hand, we have
τ ∧t ≤s for s > t. Hence τ ′ := (τ ∧t)+1{τ>t} and σ ′ := (σ ∧t)+1{σ>t} (and
thus τ ′+σ ′) are Ft-measurable. We conclude {τ+σ ≤t} = {τ ′+σ ′ ≤t} ∈Ft.
(iii) For τ + s, this is a consequence of (9.18) (with the stopping time σ ≡s). For
τ −s, since τ is a stopping time, we have {τ −s ≤t} = {τ ≤t + s} ∈Ft+s.
However, in general, Ft+s is a strict superset of Ft; hence τ−s is not a stopping
time.
⊓⊔
Deﬁnition 9.19 Let τ be a stopping time. Then
Fτ :=
	
A ∈F : A ∩{τ ≤t} ∈Ft for any t ∈I

is called the σ-algebra of τ-past.
Example 9.20 Let I
=
N0 (or let I
⊂
[0, ∞) be right-discrete; compare
Example 9.17) and let X be an adapted real-valued stochastic process. Let K ∈R
and let τ = inf{t : Xt ≥K} be the stopping time of ﬁrst entrance in [K, ∞).
Consider the events A = {sup{Xt : t ∈I} > K −5} and B = {sup{Xt : t ∈I} >
K + 5}.
Clearly, {τ ≤t} ⊂A for all t ∈I; hence A ∩{τ ≤t} = {τ ≤t} ∈Ft. Thus
A ∈Fτ. However, in general, B /∈Fτ since up to time τ, we cannot decide whether
X will ever exceed K + 5. ♦
Lemma 9.21 If σ and τ are stopping times with σ ≤τ, then Fσ ⊂Fτ.
Proof Let A ∈Fσ and t ∈I. Then A ∩{σ ≤t} ∈Ft. Now {τ ≤t} ∈Ft since τ
is a stopping time. Since σ ≤τ, we thus get
A ∩{τ ≤t} =

A ∩{σ ≤t}

∩{τ ≤t} ∈Ft.
⊓⊔
Deﬁnition 9.22 If τ < ∞is a stopping time, then we deﬁne Xτ(ω) := Xτ(ω)(ω).
Lemma 9.23 Let I be countable, let X be adapted and let τ < ∞be a stopping
time. Then Xτ is measurable with respect to Fτ.

218
9
Martingales
Proof Let A be measurable and t ∈I. Hence {τ = s} ∩X−1
s (A) ∈Fs ⊂Ft for all
s ≤t. Thus
X−1
τ (A) ∩{τ ≤t} =

s∈I
s≤t

{τ = s} ∩X−1
s (A)

∈Ft.
⊓⊔
For uncountable I and for ﬁxed ω, in general, the map I →E, t →Xt(ω) is
not measurable; hence neither is the composition Xτ always measurable. Here one
needs assumptions on the regularity of the paths t →Xt(ω); for example, right
continuity. We come back to this point in Chap. 21 and leave this as a warning for
the time being.
Takeaways We have got acquainted to the notions stochastic process, ﬁltra-
tion, adapted, stopping time, and σ-algebra of τ-past. These concepts form
the basic vocabulary for the description of stochastic processes, in particular
martingales, in the subsequent sections.
9.2
Martingales
Everyone who does not own a casino would agree without hesitation that the
successive payment of gains Y1, Y2, . . ., such that Y1, Y2, . . . are i.i.d. with E[Y1] =
0, could be considered a fair game consisting of consecutive rounds. In this case, the
process X of partial sums Xn = Y1 + . . . + Yn is integrable and E[Xn
Fm] = Xm
if m < n (where F = σ(X)). We want to use this equation for the conditional
expectations as the deﬁning equation for a fair game that in the following will be
called a martingale. Note that, in particular, this deﬁnition does not require that the
individual payments be independent or identically distributed. This makes the notion
quite a bit more ﬂexible. The momentousness of the following concept will become
manifest only gradually.
Deﬁnition 9.24 Let (Ω, F, P) be a probability space, I ⊂R, and let F be a
ﬁltration. Let X = (Xt)t∈I be a real-valued, adapted stochastic process with
E[|Xt|] < ∞for all t ∈I. X is called (with respect to F) a
martingale
if E[Xt
Fs] = Xs for all s, t ∈I with t > s,
submartingale
if E[Xt
Fs] ≥Xs for all s, t ∈I with t > s,
supermartingale
if E[Xt
Fs] ≤Xs for all s, t ∈I with t > s.

9.2
Martingales
219
Remark 9.25 Clearly, for a martingale, the map t
→E[Xt] is constant, for
submartingales it is monotone increasing and for supermartingales it is monotone
decreasing. ♦
Remark 9.26 The etymology of the term martingale has not been resolved com-
pletely. The French la martingale (originally Provençal martegalo, named after
the town Martiques) in equitation means “a piece of rein used in jumping and
cross country riding”. Sometimes the ramiﬁed shape, in particular of the running
martingale (French la martingale à anneaux), is considered as emblematic for the
doubling strategy in the Petersburg game.
This doubling strategy itself is the second meaning of la martingale. Starting
here, a shift in the meaning towards the mathematical notion seems plausible. A
different derivation, in contrast to the appearance, is based on the function of the
rein, which is to “check the upward movement of the horse’s head”. Thus the notion
of a martingale might ﬁrst have been used for general gambling strategies (checking
the movements of chance) and later for the doubling strategy in particular. ♦
Remark 9.27 If I = N, I = N0 or I = Z, then it is enough to consider at each
instant s only t = s +1. In fact, by the tower property of the conditional expectation
(Theorem 8.14(iv)), we get
E[Xs+2
Fs] = E)E[Xs+2
Fs+1]
Fs
*.
Thus, if the deﬁning equality (or inequality) holds for any time step of size one, by
induction it holds for all times. ♦
Remark 9.28 If we do not explicitly mention the ﬁltration F, we tacitly assume that
F is generated by X; that is, Ft = σ(Xs, s ≤t). ♦
Remark 9.29 Let F and F′ be ﬁltrations with Ft ⊂F′
t for all t, and let X be an
F′-(sub-, super-) martingale that is adapted to F. Then X is also a (sub-, super-)
martingale with respect to the smaller ﬁltration F. Indeed, for s < t and for the case
of a submartingale,
E[Xt
Fs] = E[E[Xt
F′
s]
Fs] ≥E[Xs
Fs] = Xs.
In particular, an F-(sub-, super-) martingale X is always a (sub-, super-) martingale
with respect to its own ﬁltration σ(X). ♦
Reﬂection If X is a martingale with respect to some ﬁltration F, then X is adapted
to any larger ﬁltration F′ ⊃F but it is not necessarily an F′-martingale. Why? ♠
Example 9.30 Let Y1, . . . , YN be independent random variables with E[Yt] = 0 for
all t = 1, . . . , N. Let Ft := σ(Y1, . . . , Yt) and Xt :=
t
s=1
Ys. Then X is adapted

220
9
Martingales
and integrable, and E[Yr
Fs] = 0 for r > s. Hence, for t > s,
E[Xt
Fs] = E[Xs
Fs] + E[Xt −Xs
Fs] = Xs +
t
r=s+1
E[Yr
Fs] = Xs.
Thus, X is an F-martingale.
Similarly, X is a submartingale if E[Yt] ≥0 for all t, and a supermartingale if
E[Yt] ≤0 for all t. ♦
Reﬂection In the previous example one might be tempted to assume that the Yi are
uncorrelated instead of independent. Why is this not enough? ♠
Example 9.31 Consider the situation of the preceding example; however, now with
E[Yt] = 1 and Xt = t
s=1 Ys for t ∈N0. By Theorem 5.4, Y1 · Y2 is integrable.
Inductively, we get E[|Xt|] < ∞for all t ∈N0. Evidently, X is adapted to F and
for all s ∈N0, we have
E[Xs+1
Fs] = E[XsYs+1
Fs] = Xs E[Ys+1
Fs] = Xs.
Hence X is an F-martingale. ♦
Theorem 9.32
(i) X is a supermartingale if and only if (−X) is a submartingale.
(ii) Let X and Y be martingales and let a, b ∈R. Then (aX +bY) is a martingale.
(iii) Let X and Y be supermartingales and a, b ≥0. Then (aX + bY) is a
supermartingale.
(iv) Let X and Y be supermartingales. Then Z := X ∧Y = (min(Xt, Yt))t∈I is a
supermartingale.
(v) If (Xt)t∈N0 is a supermartingale and E[XT ] ≥E[X0] for some T ∈N0,
then (Xt)t∈{0,...,T } is a martingale. If there exists a sequence TN →∞with
E[XTN ] ≥E[X0], then X is a martingale.
Proof (i), (ii) and (iii)
These are evident.
(iv) Since |Zt| ≤|Xt| + |Yt|, we have E[|Zt|] < ∞for all t ∈I. expectation
(Theorem 8.14(ii)), for t
> s, we have E[Zt
Fs] ≤E[Yt
Fs] ≤Ys and
E[Zt
Fs] ≤E[Xt
Fs] ≤Xs; hence E[Zt
Fs] ≤Xs ∧Ys = Zs.
(v) For t ≤T , let Yt := E[XT
Ft]. Then Y is a martingale and Yt ≤Xt. Hence
E[X0] ≤E[XT ] = E[YT ] = E[Yt] ≤E[Xt] ≤E[X0].
(The ﬁrst inequality holds by assumption.) We infer that Yt = Xt almost surely for
all t and thus (Xt)t∈{0,...,T } is a martingale.
Let TN →∞with E[XTN ] ≥E[X0] for all N ∈N. Then, for any t > s ≥0,
there is an N ∈N with TN > t. Hence, E[Xt
Fs] = Xs and X is a martingale.
⊓⊔

9.2
Martingales
221
Remark 9.33 Many statements about supermartingales hold mutatis mutandis for
submartingales. For example, in the preceding theorem, claim (i) holds with the
words “submartingale” and “supermartingale” interchanged, claim (iv) holds for
submartingales if the minimum is replaced by a maximum, and so on. We often do
not give the statements both for submartingales and for supermartingales. Instead,
we choose representatively one case. Note, however, that those statements that
we make explicitly about martingales usually cannot be adapted easily to sub- or
supermartingales (such as (ii) in the preceding theorem). ♦
Corollary 9.34 Let X be a submartingale and a ∈R. Then (X −a)+ is a
submartingale.
Proof Clearly, 0 and Y = X −a are submartingales. By (iv), (X −a)+ = Y ∨0 is
also a submartingale.
⊓⊔
Theorem 9.35 Let X be a martingale and let ϕ : R →R be a convex function.
(i) If
E[ϕ(Xt)+] < ∞
for all t ∈I,
(9.1)
then (ϕ(Xt))t∈I is a submartingale.
(ii) If t∗:= sup(I) ∈I, then E[ϕ(Xt∗)+] < ∞implies (9.1).
(iii) In particular, if p ≥1 and E[|Xt|p] < ∞for all t ∈I, then (|Xt|p)t∈I is a
submartingale.
Proof
(i) We always have E[ϕ(Xt)−] < ∞(Theorem 7.9); hence, by assumption,
E[|ϕ(Xt)|] < ∞for all t ∈I. Jensen’s inequality (Theorem 8.20) then yields,
for t > s,
E[ϕ(Xt)
Fs] ≥ϕ(E[Xt
Fs]) = ϕ(Xs).
(ii) Since ϕ is convex, so is x →ϕ(x)+. Furthermore, by assumption, we have
E[ϕ(Xt∗)+] < ∞; hence Jensen’s inequality implies that, for all t ∈I,
E[ϕ(Xt)+] = E
)
ϕ

E[Xt∗Ft]
+*
≤E
)
E[ϕ(Xt∗)+ Ft]
*
= E
)
ϕ(Xt∗)+*
< ∞.
(iii) This is evident since x →|x|p is convex.
⊓⊔
Example 9.36 (See Example 9.4) Symmetric simple random walk X on Z is a
square integrable martingale. Hence (X2
n)n∈N0 is a submartingale. ♦

222
9
Martingales
Takeaways A martingale is a mathematical model for a fair game of
many rounds. Partial sums of independent centred random variables are an
important example. Submartingales are favourable games (the mean future
is better than the present) and supermartingales are unfavourable games (the
mean future is not as good as the present). Convex functions of martingales
are submartingales.
Exercise 9.2.1 Let Y be a random variable with E[|Y|] < ∞and let F be a ﬁltration
as well as
Xt := E[Y
Ft]
for all t ∈I.
Show that X is an F-martingale. ♣
Exercise 9.2.2 Let (Xn)n∈N0 be a predictable F-martingale. Show that Xn = X0
almost surely for all n ∈N0. ♣
Exercise 9.2.3 Show that the claim of Theorem 9.35 continues to hold if X is
only a submartingale but if ϕ is in addition assumed to be monotone increasing.
Give an example that shows that the monotonicity of ϕ is essential. (Compare
Corollary 9.34.) ♣
Exercise 9.2.4 (Azuma’s inequality) Show the following.
(i) If X is a random variable with |X| ≤1 a.s., then there is a random variable Y
with values in {−1, +1} and with E[Y |X] = X.
(ii) For X as in (i) with E[X] = 0, infer that (using Jensen’s inequality)
E)eλX* ≤cosh(λ) ≤eλ2/2
for all λ ∈R.
(iii) If (Mn)n∈N0 is a martingale with M0 = 0 and if there is a sequence (ck)k∈N of
nonnegative numbers with |Mn −Mn−1| ≤cn a.s. for all n ∈N, then
E
)
eλMn*
≤exp

1
2λ2
n

k=1
c2
k

.
(iv) Under the assumptions of (iii), Azuma’s inequality holds:
P
)
|Mn| ≥λ
*
≤2 exp

−
λ2
2 n
k=1 c2
k

for all λ ≥0.
Hint: Use Markov’s inequality for f (x) = eγ x and choose the optimal γ . ♣

9.3
Discrete Stochastic Integral
223
9.3
Discrete Stochastic Integral
So far we have encountered a martingale as the process of partial sums of gains of
a fair game. This game can also be the price of a stock that is traded at discrete
times on a stock exchange. With this interpretation, it is particularly evident that it
is natural to construct new stochastic processes by considering investment strategies
for the stock. The value of the portfolio, which is the new stochastic process,
changes as the stock price changes. It is the price multiplied by the number of
stocks in the portfolio. In order to describe such processes formally, we introduce
the following notion.
Deﬁnition 9.37 (Discrete stochastic integral)
Let (Xn)n∈N0 be an F-adapted real
process and let (Hn)n∈N be a real-valued and F-predictable process. The discrete
stochastic integral of H with respect to X is the stochastic process H ·X deﬁned by
(H ·X)n :=
n

m=1
Hm(Xm −Xm−1)
for n ∈N0.
(9.2)
If X is a martingale, then H ·X is also called the martingale transform of X.
Remark 9.38 Clearly, H ·X is adapted to F. ♦
Let X be a (possibly unfair) game where Xn −Xn−1 is the gain per euro in the
nth round. We interpret Hn as the number of euros we bet in the nth game. H is then
a gambling strategy. Clearly, the value of Hn has to be decided at time n −1; that
is, before the result of Xn is known. In other words, H must be predictable.
Now assume that X is a fair game (that is, a martingale) and H is locally
bounded (that is, each Hn is bounded). Then (since E[Xn+1 −Xn
Fn] = 0)
E[(H ·X)n+1
Fn] = E[(H ·X)n + Hn+1(Xn+1 −Xn)
Fn]
= (H ·X)n + Hn+1 E[Xn+1 −Xn
Fn]
= (H ·X)n.
Thus H ·X is a martingale. The following theorem says that the converse also
holds; that is, X is a martingale if, for sufﬁciently many predictable processes, the
stochastic integral is a martingale.
Theorem 9.39 (Stability theorem)
Let (Xn)n∈N0 be an adapted, real-valued
stochastic process with E[|X0|] < ∞.
(i) X is a martingale if and only if, for any locally bounded predictable process H,
the stochastic integral H ·X is a martingale.
(ii) X is a submartingale (supermartingale) if and only if H ·X is a submartingale
(supermartingale) for any locally bounded predictable H ≥0.

224
9
Martingales
Proof
(i) “ ⇒”
This has been shown in the discussion above.
“ ⇐ ”
Fix an n0 ∈N, and let Hn = 1{n=n0}. Then (H ·X)n0−1 = 0; hence
0 = E)(H ·X)n0
Fn0−1
* = E)Xn0
Fn0−1
* −Xn0−1.
(ii) This is similar to (i).
⊓⊔
The preceding theorem says, in particular, that we cannot ﬁnd any locally bounded
gambling strategy that transforms a martingale (or, if we are bound to nonnegative
gambling strategies, as we are in real life, a supermartingale) into a submartingale.
Quite the contrary is suggested by the many invitations to play all kinds of “sure
winning systems” in lotteries.
Example 9.40 (Petersburg game) We continue Example 9.14 (see also Exam-
ple 4.22). Deﬁne Xn := D1 + . . . + Dn for n ∈N0. Then X is a martingale.
The gambling strategy Hn := 2n−1 1{D1=D2=...=Dn−1=−1} for n ∈N and H0 = 1
is predictable and locally bounded. Let Sn = n
i=1 HiDi = (H ·X)n be the gain
after n rounds. Then S is a martingale by the preceding theorem. In particular, we
get (as shown already in Example 4.22) that E[Sn] = 0 for all n ∈N. We will
come back later to the point that this superﬁcially contrasts with Sn
n→∞
−→1 a.s.
(see Example 11.6).
For the moment, note that the martingale S′ = (1 −Sn)n∈N0, just like the one in
Example 9.31, has the structure of a product of independent random variables with
expectation 1. In fact, S′
n = n
i=1(1 −Di). ♦
Takeaways Assume that the price of a risky asset at discrete trading times
n = 0, 1, 2, . . . is a martingale. Also assume that we follow a bounded trading
strategy that cannot use future information. Then the value of our portfolio is
described by a discrete stochastic integral which is again a martingale.
9.4
Discrete Martingale Representation Theorem
and the CRR Model
By virtue of the stochastic integral, we have transformed a martingale X via a
gambling strategy H into a new martingale H ·X. Let us change the perspective
and ask: For ﬁxed X, which are the martingales Y (with Y0 = 0) that can be
obtained as discrete stochastic integrals of X with a suitable gambling strategy
H
= H(Y)? Possibly all martingales Y? This is not the case, in general, as
the example below indicates. However, we will see that all martingales can be

9.4
Discrete Martingale Representation Theorem and the CRR Model
225
represented as stochastic integrals if the increments Xn+1 −Xn can take only two
values (given X1, . . . , Xn). In this case, we give a representation theorem and use it
to discuss the fair price for a European call option in the stock market model of Cox–
Ross–Rubinstein. This model is rather simple and describes an idealized market (no
transaction costs, fractional numbers of stocks tradeable and so on). For extensive
literature on stochastic aspects of mathematical ﬁnance, we refer to the textbooks
[9, 42, 48, 57, 86, 102, 121] or [160].
Example 9.41 Consider the very simple martingale X = (Xn)n=0,1 with only two
time points. Let X0 = 0 almost surely and P[X1 = −1] = P[X1 = 0] = P[X1 =
1] =
1
3. Let Y0 = 0. Further, let Y1 = 2 if X1 = 1 and Y1 = −1 otherwise.
Then Y is manifestly a σ(X)-martingale. However, there is no number H1 such that
H1X1 = Y1. ♦
Let T ∈N be a ﬁxed time. If (Yn)n=0,1,...,T is an F-martingale, then Yn =
E[YT
Fn] for all n ≤T . An F-martingale Y is thus determined uniquely by
the terminal values YT (and vice versa). Let X be a martingale. As (H ·X) is
a martingale, the representation problem for martingales is thus reduced to the
problem of representing an integrable random variable V := YT as v0 + (H ·X)T ,
where v0 = E[YT ].
We saw that, in general, this is not possible if the differences Xn+1 −Xn take
three (or more) different values. Hence we now consider the case where only two
values are possible. Here, at each time step, a system of two linear equations with
two unknowns has to be solved. In the case where Xn+1 −Xn takes three values,
the system has three equations and is thus overdetermined.
Deﬁnition 9.42 (Binary model) A stochastic process
X0, . . . , XT
is called
binary splitting or a binary model if there exist random variables D1, . . . , DT with
values in {−1, +1} and functions fn : Rn−1 × {−1, +1} →R for n = 1, . . . , T , as
well as x0 ∈R such that X0 = x0 and
Xn = fn(X1, . . . , Xn−1, Dn)
for any n = 1, . . . , T.
By F = σ(X), we denote the ﬁltration generated by X.
Note that Xn depends only on X1, . . . , Xn−1 and Dn but not on the full information
inherent in the values D1, . . . , Dn. If the latter were the case, a ramiﬁcation into
more than two values in one time step would be possible.
Theorem 9.43 (Representation theorem) Let X be a binary model and let VT
be an FT -measurable random variable. Then there exists a bounded predictable
process H and a v0 ∈R with VT = v0 + (H ·X)T .
Note that F is the ﬁltration generated by X, not the, possibly larger, ﬁltration
generated by D1, . . . , DT . For the latter case, the claim of the theorem would be
incorrect since, loosely speaking, with H we can bet on X but not on the Di.

226
9
Martingales
Proof We show that there exist FT −1-measurable random variables VT −1 and HT
such that VT = VT −1 + HT (XT −XT −1). By a backward induction, this yields the
claim.
Since VT is FT -measurable, by the factorization lemma (Corollary 1.97) there
exists a function gT : RT →R with VT = gT (X1, . . . , XT ). Deﬁne
X±
T = fT (X1, . . . , XT −1, ±1)
and
V ±
T
= gT (X1, . . . , XT −1, X±
T ).
Each of these four random variables is manifestly FT −1-measurable. Hence we are
looking for solutions VT −1 and HT of the following system of linear equations:
VT −1 + HT (X−
T −XT −1) = V −
T ,
VT −1 + HT (X+
T −XT −1) = V +
T .
(9.3)
By construction, X+
T −X−
T ̸= 0 if V +
T −V −
T ̸= 0. Hence we can solve (9.3) and
get
HT :=
⎧
⎨
⎩
V +
T −V −
T
X+
T −X−
T ,
if X+
T ̸= X−
T ,
0,
else,
and VT −1 = V +
T −HT (X+
T −XT −1) = V −
T −HT (X−
T −XT −1).
⊓⊔
We now want to interpret X as the market price of a stock and VT as the payment
of a ﬁnancial derivative on X, a so-called contingent claim or, brieﬂy, claim. For
example, VT could be a (European) call option with maturity T and strike price
K ≥0. In this case, we have VT = (XT −K)+. Economically speaking, the
European call gives the buyer the right (but not the obligation) to buy one stock at
time T at price K (from the issuer of the option). As typically the option is exercised
only if the market price at time T is larger than K (and then gives a proﬁt of XT −K
as the stock could be sold at price XT on the market), the value of the option is
indeed VT = (XT −K)+.
At the stock exchanges, not only are stocks traded but also derivatives on stocks.
Hence, what is the fair price π(VT ) for which a trader would offer (and buy) the
contingent claim VT ? If there exists a strategy H and a v0 such that VT = v0 +
(H·X)T , then the trader can sell the claim for v0 (at time 0) and replicate the claim
by building a portfolio that follows the trading strategy H. In this case, the claim
VT is called replicable and the strategy H is called a hedging strategy, or brieﬂy
a hedge. A market in which every claim can be replicated is called complete. In this
sense, the binary model is a complete market.
If there was a second strategy H ′ and a second v′
0 with v′
0 + (H ′·X)T = VT ,
then, in particular, v0 −v′
0 = ((H ′ −H)·X)T . If we had v0 > v′
0, then the trader
could follow the strategy H ′−H (which gives a ﬁnal payment of VT −VT = 0) and
make a sure proﬁt of v0 −v′
0. In the opposite case, v0 < v′
0, the strategy H −H ′

9.4
Discrete Martingale Representation Theorem and the CRR Model
227
ensures a risk-free proﬁt. Such a risk-free proﬁt (or free lunch in economic jargon)
is called an arbitrage. It is reasonable to assume that a market gives no opportunity
for an arbitrage. Hence the fair price π(VT ) is determined uniquely once there is
one trading strategy H and a v0 such that VT = v0 + (H ·X)T .
Until now, we have not assumed that X is a martingale. However, if X is
a martingale, then (H · X) is a martingale with (H · X)0 = 0; hence clearly
E[(H ·X)T ] = 0. Thus
π(VT ) = v0 = E[VT ].
(9.4)
Since, in this case, v0 does not depend on the trading strategy and is hence unique,
the market is automatically arbitrage-free. A ﬁnite market is thus arbitrage-free if
and only if there exists an equivalent martingale (to be deﬁned below). In this case,
uniqueness of this martingale is equivalent to completeness of the market (“the
fundamental theorem of asset pricing” by Harrison–Pliska [68]). In larger markets,
equivalence holds only with a somewhat more ﬂexible notion of arbitrage (see [30]).
Now if X is not a martingale, then in some cases, we can replace X by a different
process X′ that is a martingale and such that the distributions PX and PX′ are
equivalent; that is, have the same null sets. Such a process is called an equivalent
martingale, and PX′ is called an equivalent martingale measure. A trading strategy
that replicates VT with respect to X also replicates VT with respect to X′. In
particular, the fair price does not change if we pass to the equivalent martingale
X′. Thus we can compute π(VT ) by applying (9.4) to the equivalent martingale.
While here this is only of interest in that it simpliﬁes the computation of fair
prices, it has an economic interpretation as a measure for the market prices that
we would see if all traders were risk-neutral; that is, for traders who price a future
payment by its mean value. Typically, however, traders are risk-averse and thus real
market prices include a discount due to the inherent risk.
Now we consider one model in greater detail.
Deﬁnition 9.44 Let T ∈N, a ∈(−1, 0) and b > 0 as well as p ∈(0, 1).
Further, let D1, . . . , DT be i.i.d. Radp random variables (that is,
P[D1 = 1] =
1 −P[D1 = −1] = p). We let X0 = x0 > 0 and for n = 1, . . . , T , deﬁne
Xn =

(1 + b) Xn−1,
if Dn = +1,
(1 + a) Xn−1,
if Dn = −1.
X is called the multi-period binomial model or the Cox–Ross–Rubinstein model
(without interest returns).
As we have shown already, the CRR model is complete. Further, with the choice
p = p∗:=
a
a−b, we can change X into a martingale. Hence the model is also
arbitrage-free (for all p ∈(0, 1)). Now we want to compute the price of a European
call option VT := (XT −K)+ explicitly. To this end, we can assume p = p∗.

228
9
Martingales
Letting A := min{i ∈N0 : (1 + b)i(1 + a)T −ix0 > K}, we get
π(VT ) = Ep∗[VT ] =
T

i=0
bT,p∗({i})
'
(1 + b)i(1 + a)T −ix0 −K
(+
= x0
T

i=A
T
i

(p∗)i(1 −p∗)T −i '
(1 + b)i(1 + a)T −i(
−K
T

i=A
bT,p∗({i}).
If we deﬁne p′ = (1 + b)p∗, then p′ ∈(0, 1) and 1 −p′ = (1 −p∗)(1 + a). We
thus obtain the Cox–Ross–Rubinstein formula
π(VT ) = x0 bT,p′({A, . . . , T }) −K bT,p∗({A, . . . , T }).
(9.5)
This is the discrete analogue of the celebrated Black–Scholes formula for option
pricing in certain time-continuous markets.
Takeaways Consider a stochastic process that can take only two values at
time t + 1 given the full history up to time t. Such a process is said to be
binary splitting. The main theorem says that any function of the history up to
a given time t can be represented as a discrete stochastic integral with respect
to this binary splitting process. Rephrased to the language of ﬁnancial markets
this means: If the price of a risky asset is given by a binary splitting process
than there is a hedging strategy for any contingent claim. As a by-product we
get a discrete version of the celebrated Black-Scholes formula.

Chapter 10
Optional Sampling Theorems
In Chap. 9 we saw that martingales are transformed into martingales if we apply
certain admissible gambling strategies. In this chapter, we establish a similar
stability property for martingales that are stopped at a random time. In order also
to obtain these results for submartingales and supermartingales, in the ﬁrst section,
we start with a decomposition theorem for adapted processes. We show the optional
sampling and optional stopping theorems in the second section. The chapter ﬁnishes
with the investigation of random stopping times with an inﬁnite time horizon.
10.1
Doob Decomposition and Square Variation
Let X = (Xn)n∈N0 be an adapted process with E[|Xn|] < ∞for all n ∈N0. We
will decompose X into a sum consisting of a martingale and a predictable process.
To this end, for n ∈N0, deﬁne
Mn := X0 +
n

k=1
Xk −E[Xk
Fk−1]
(10.1)
and
An :=
n

k=1

E[Xk
Fk−1] −Xk−1

.
Evidently, Xn = Mn + An. By construction, A is predictable with A0 = 0, and
M is a martingale since
E[Mn −Mn−1
Fn−1] = E
)
Xn −E[Xn
Fn−1]
Fn−1
*
= 0.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_10
229

230
10
Optional Sampling Theorems
Theorem 10.1 (Doob decomposition) Let X = (Xn)n∈N0 be an adapted inte-
grable process. Then there exists a unique decomposition X = M + A, where A
is predictable with A0 = 0 and M is a martingale. This representation of X is
called the Doob decomposition. X is a submartingale if and only if A is monotone
increasing.
Proof We only have to show uniqueness of the decomposition. Hence, let X =
M + A = M′ + A′ be two such decompositions. Then M −M′ = A′ −A is a
predictable martingale; hence (see Exercise 9.2.2) Mn −M′
n = M0 −M′
0 = 0 for
all n ∈N0.
⊓⊔
Example 10.2 Let I = N0 or I = {0, . . . , N}. Let (Xn)n∈I be a square integrable
F-martingale (that is, E[X2
n] < ∞for all n ∈I). By Theorem 9.35, Y := (X2
n)n∈I
is a submartingale. Let Y = M + A be the Doob decomposition of Y. Then (X2
n −
An)n∈I is a martingale. Furthermore, E[Xi−1Xi
Fi−1] = Xi−1E[Xi
Fi−1] =
X2
i−1; hence (as in (10.1))
An =
n

i=1

E[X2
i
Fi−1] −X2
i−1

=
n

i=1

E[(Xi −Xi−1)2Fi−1] −2X2
i−1 + 2 E[Xi−1Xi
Fi−1]

=
n

i=1
E
)
(Xi −Xi−1)2Fi−1
*
.
♦
(10.2)
Deﬁnition 10.3 Let (Xn)n∈I be a square integrable F-martingale. The unique
predictable process A for which (X2
n −An)n∈I becomes a martingale is called the
square variation process of X and is denoted by (⟨X⟩n)n∈I := A.
By the preceding example, we conclude the following theorem.
Theorem 10.4 Let X be as in Deﬁnition 10.3. Then, for n ∈N0,
⟨X⟩n =
n

i=1
E
)
(Xi −Xi−1)2Fi−1
*
(10.3)
and
E[⟨X⟩n] = Var[Xn −X0].
(10.4)
Remark 10.5 If Y and A are as in Example 10.2, then A is monotone increasing
since (X2
n)n∈I is a submartingale (see Theorem 10.1). Therefore, A is sometimes
called the increasing process of Y. ♦

10.1
Doob Decomposition and Square Variation
231
Example 10.6 Let Y1, Y2, . . . be independent, square integrable, centered random
variables. Then Xn := Y1 + . . . + Yn deﬁnes a square integrable martingale with
⟨X⟩n = n
i=1 E[Y 2
i ]. In fact, An = n
i=1 E[Y 2
i
Y1, . . . , Yi−1] = n
i=1 E[Y 2
i ] (as
in Example 10.2).
Note that in order for ⟨X⟩to have the simple form as in Example 10.6, it is not
enough for the random variables Y1, Y2, . . . to be uncorrelated. ♦
Example 10.7 Let Y1, Y2, . . . be independent, square integrable random variables
with E[Yn] = 1 for all n ∈N. Let Xn := n
i=1 Yi for n ∈N0. Then X = (Xn)n∈N0
is a square integrable martingale with respect to F = σ(X) (why?) and
E)(Xn −Xn−1)2Fn−1
* = E)(Yn −1)2X2
n−1
Fn−1
* = Var[Yn] X2
n−1.
Hence ⟨X⟩n = n
i=1 Var[Yi] X2
i−1. We see that the square variation process can
indeed be a truly random process. ♦
Example 10.8 Let (Xn)n∈N0 be the one-dimensional symmetric simple random
walk
Xn =
n

i=1
Ri
for all n ∈N0,
where R1, R2, R3, . . . are i.i.d. and ∼Rad1/2; that is,
P[Ri = 1] = 1 −P[Ri = −1] = 1
2.
Clearly, X is a martingale and hence |X| is a submartingale. Let |X| = M + A
be Doob’s decomposition of |X|. Then
An =
n

i=1

E[|Xi|
Fi−1] −|Xi−1|

.
Now
|Xi| =
⎧
⎪⎪⎨
⎪⎪⎩
|Xi−1| + Ri,
if Xi−1 > 0,
|Xi−1| −Ri,
if Xi−1 < 0,
1,
if Xi−1 = 0.
Therefore,
E[|Xi|
Fi−1] =

|Xi−1|,
if |Xi−1| ̸= 0,
1,
if |Xi−1| = 0.

232
10
Optional Sampling Theorems
The process
An = #
	
i ≤n −1 : |Xi| = 0

is the so-called local time of X at 0. We conclude that (since P[X2j = 0] =
2j
j

4−j
and P[X2j+1 = 0] = 0)
E[|Xn|] = E
)
#{i ≤n −1 : Xi = 0}
*
=
n−1

i=0
P[Xi = 0] =
⌊(n−1)/2⌋

j=0
2j
j

4−j.
♦
(10.5)
Example 10.9 We want to generalize the preceding example further. Evidently, we
did not use (except in the last formula) the fact that X is a random walk. Rather, we
just used the fact that the differences (ΔX)n := Xn −Xn−1 take only the values
−1 and +1. Hence, now let X be a martingale with |Xn −Xn−1| = 1 almost surely
for all n ∈N and with X0 = x0 ∈Z almost surely. Let f : Z →R be an
arbitrary map. Then Y := (f (Xn))n∈N0 is an integrable adapted process (since
|f (Xn)| ≤maxx∈{x0−n,...,x0+n} |f (x)|). In order to compute Doob’s decomposition
of Y, deﬁne the ﬁrst and second discrete derivatives of f :
f ′(x) := f (x + 1) −f (x −1)
2
and
f ′′(x) := f (x −1) + f (x + 1) −2f (x).
Further, let F ′
n := f ′(Xn−1) and F ′′
n := f ′′(Xn−1). By computing the cases Xn =
Xn−1 −1 and Xn = Xn−1 + 1 separately, we see that for all n ∈N
f (Xn) −f (Xn−1) = f (Xn−1 + 1) −f (Xn−1 −1)
2
(Xn −Xn−1)
+ 1
2f (Xn−1 −1) + 1
2f (Xn−1 + 1) −f (Xn−1)
= f ′(Xn−1)(Xn −Xn−1) + 1
2f ′′(Xn−1)
= F ′
n · (Xn −Xn−1) + 1
2F ′′
n .

10.2
Optional Sampling and Optional Stopping
233
Summing up, we get the discrete Itô formula:
f (Xn) = f (x0) +
n

i=1
f ′(Xi−1)(Xi −Xi−1) +
n

i=1
1
2f ′′(Xi−1)
= f (x0) + (F ′·X)n +
n

i=1
1
2F ′′
i .
(10.6)
Here F ′ ·X is the discrete stochastic integral (see Deﬁnition 9.37). Now M :=
f (x0) + F ′·X is a martingale by Theorem 9.39 since F ′ is predictable (and since
|F ′
n| ≤maxx∈{x0−n,...,x0+n} |F ′(x)|), and A :=
n
i=1
1
2F ′′
i

n∈N0
is predictable.
Hence f (X) := (f (Xn))n∈N0 = M + A is the Doob decomposition of f (X). In
particular, f (X) is a submartingale if f ′′(x) ≥0 for all x ∈Z; that is, if f is
convex. We knew this already from Theorem 9.35; however, here we could also
quantify how much f (X) differs from a martingale.
In the special cases f (x) = x2 and f (x) = |x|, the second derivative is f ′′(x) =
2 and f ′′(x) = 2·1{0}(x), respectively. Thus, from (10.6), we recover the statements
of Theorem 10.4 and Example 10.8.
Later we will derive a formula similar to (10.6) for stochastic processes in
continuous time (see Sect. 25.3). ♦
Takeaways For a submartingale, the mean future is better than the present.
Subtracting the differences for each time step, we decompose a submartingale
into a sum of a martingale and a monotone increasing predictable process.
This is the so-called Doob decomposition. If X is an L2-martingale, then
X2 is a submartingale and the corresponding increasing process is called the
variance process or square variation process.
10.2
Optional Sampling and Optional Stopping
Lemma 10.10 Let I ⊂R be countable, let (Xt)t∈I be a martingale, let T ∈I and
let τ be a stopping time with τ ≤T . Then Xτ = E[XT
Fτ] and, in particular,
E[Xτ] = E[X0].

234
10
Optional Sampling Theorems
Proof It is enough to show that E[XT 1A] = E[Xτ 1A] for all A ∈Fτ. By the
deﬁnition of Fτ, we have {τ = t} ∩A ∈Ft for all t ∈I. Hence
E[Xτ 1A] =

t≤T
E[Xt 1{τ=t}∩A] =

t≤T
E
)
E[XT
Ft] 1{τ=t}∩A
*
=

t≤T
E[XT 1A 1{τ=t}] = E[XT 1A].
⊓⊔
Theorem 10.11 (Optional sampling theorem) Let X = (Xn)n∈N0 be a supermar-
tingale and let σ ≤τ be stopping times.
(i) Assume there exists a T ∈N with τ ≤T . Then
Xσ ≥E[Xτ
Fσ],
and, in particular, E[Xσ] ≥E[Xτ]. If X is a martingale, then equality holds
in each case.
(ii) If X is nonnegative and if τ < ∞a.s., then we have E[Xτ] ≤E[X0] < ∞,
E[Xσ] ≤E[X0] < ∞and Xσ ≥E[Xτ
Fσ].
(iii) Assume that, more generally, X is only adapted and integrable. Then X is a
martingale if and only if E[Xτ] = E[X0] for any bounded stopping time τ.
Proof
(i) Let X = M + A be Doob’s decomposition of X. Hence A is predictable and
monotone decreasing, A0 = 0, and M is a martingale. Applying Lemma 10.10
to M yields
Xσ = Aσ + Mσ = E[Aσ + MT
Fσ]
≥E[Aτ + MT
Fσ] = E[Aτ + E[MT
Fτ]
Fσ]
= E[Aτ + Mτ
Fσ] = E[Xτ
Fσ].
Here we used Fτ ⊃Fσ, the tower property and the monotonicity of the
conditional expectation (see Theorem 8.14).
(ii) We have Xτ∧n
n→∞
−→Xτ almost surely. By (i), we get E[Xτ∧n] ≤E[X0] for
any n ∈N. Using Fatou’s lemma, we infer
E[Xτ] ≤lim inf
n→∞E[Xτ∧n] ≤E[X0] < ∞.
Similarly, we can show that E[Xσ] ≤E[X0].
Now, let m, n ∈N with m ≥n. Part (i) applied to the bounded stopping
times τ ∧m ≥σ ∧n yields
Xσ∧n ≥E[Xτ∧m
Fσ∧n].

10.2
Optional Sampling and Optional Stopping
235
Now {σ < n} ∩A ∈Fσ∧n for A ∈Fσ. Hence
E
)
Xσ 1{σ<n}∩A
*
= E
)
Xσ∧n 1{σ<n}∩A
*
≥E
)
Xτ∧m 1{σ<n}∩A
*
.
Using Fatou’s lemma, we get
E[Xτ 1{σ<n}∩A] ≤lim inf
m→∞E
)
Xτ∧m 1{σ<n}∩A
*
≤E
)
Xσ 1{σ<n}∩A
*
.
Monotone convergence (for n →∞) thus yields E[Xτ 1A] ≤E[Xσ 1A].
(iii) If X is a martingale, then the claim follows from Lemma 10.10. Now assume
that E[Xτ] = E[X0] for any bounded stopping time τ. Let t > s and A ∈Fs.
It is enough to show that E[Xt 1A] = E[Xs 1A]. Deﬁne τ = s 1A +t1Ac. Then
τ is a bounded stopping time. However, by assumption,
E[Xt 1A] = E[Xt]−E[Xt 1Ac] = E[X0]−E[Xτ]+E[Xs 1A] = E[Xs 1A].
⊓⊔
Corollary 10.12 Let X be a martingale (respectively a submartingale), and assume
(τN)N∈N is a monotone increasing sequence of bounded stopping times (hence τN ≤
TN, N ∈N for some TN ∈N). Then (XτN )N∈N is a martingale (respectively a
submartingale) with respect to the ﬁltration (FτN )N∈N.
Deﬁnition 10.13 (Stopped process) Let I
⊂R be countable, let (Xt)t∈I be
adapted and let τ be a stopping time. We deﬁne the stopped process Xτ by
Xτ
t = Xτ∧t
for any t ∈I.
Further, let Fτ be the ﬁltration Fτ = (Fτ
t )t∈I = (Fτ∧t)t∈I.
Remark 10.14 Xτ is adapted both to F and to Fτ. ♦
Theorem 10.15 (Optional stopping) Let (Xn)n∈N0 be a (sub-, super-) martingale
with respect to F and let τ be a stopping time. Then Xτ is a (sub-, super-) martingale
both with respect to F and with respect to Fτ.
Proof We give the proof only for the case where X is a submartingale. The other
cases are similar since there (−X) is a submartingale.
For each n ∈N0, we have
E
)Xτ
n
*
≤E
)
max
	
|Xm| : m ≤n

*
≤E
)
|X0|] + . . . + E[|Xn|] < ∞.
Hence Xτ is integrable.

236
10
Optional Sampling Theorems
Let X be a submartingale. Since {τ > n −1} ∈Fn−1, we have
E[Xτ
n −Xτ
n−1
Fn−1] = E[Xτ∧n −Xτ∧(n−1)
Fn−1]
= E[(Xn −Xn−1) 1{τ>n−1}
Fn−1]
= 1{τ>n−1} E[Xn −Xn−1
Fn−1]
≥0, since X is an F-submartingale.
Therefore, Xτ is an F-submartingale. As Xτ is adapted to Fτ and since Fτ is the
smaller ﬁltration, Xτ is also an Fτ-submartingale (see Remark 9.29).
⊓⊔
Example 10.16 Let X be a symmetric simple random walk on Z (see Exam-
ple 10.8). Let a, b ∈Z with a < 0, b > 0 and let
τa = inf{t ≥0 : Xt = a},
τb = inf{t ≥0 : Xt = b} and τa,b = τa ∧τb.
τa,b is a stopping time by Lemma 9.18. Let A = {τa,b = τa} be the event where
X hits a before hitting b. We want to compute P[A]. By Exercise 2.3.1, almost
surely lim supn→∞Xn = ∞and lim infn→∞Xn = −∞. Therefore, almost surely
τa < ∞and τb < ∞. By the optional stopping theorem, Xτa,b is a martingale. Since
τa,b ∧n
n→∞
−→τa,b almost surely, we get Xτa,b
n
n→∞
−→Xτa,b almost surely. As |Xτa,b
n
|
is bounded by b −a, we can infer that Xτa,b
n
n→∞
−→Xτa,b also in L1. Thus
0 = lim
n→∞E
)
Xτa,b
n
*
= E
)
Xτa,b
*
= a · P
)
τa,b = τa
*
+ b · P
)
τa,b = τb
*
= b + (a −b) P[τa,b = τa].
We conclude that P
)
τa,b = τa
*
=
b
b −a . ♦
Example 10.17 Finally, we use our machinery in order to compute E[τa,b] and
E[τa]. The square variation process ⟨X⟩(compare Deﬁnition 10.3) is given by
⟨X⟩n =
n

i=1
E
'
(Xi −Xi−1)2Fi−1
(
= n;
hence

X2
n −n

n∈N0 is a martingale. By the optional stopping theorem,
0 = E
)
X2
τa,b∧n −(τa,b ∧n)
*
for all n ∈N0.
Monotone convergence yields
E
)
τa,b
*
= E
)
X2
τa,b
*
= a2 P
)
τa,b = τa
*
+ b2 P
)
τa,b = τb
*
= |a| · b.

10.2
Optional Sampling and Optional Stopping
237
In order to compute E[τa], note that τa,b ↑τa almost surely if b →∞. The
monotone convergence theorem thus yields E[τa] = lim
b→∞E[τa,b] = ∞. ♦
Remark 10.18 Evidently, Xτb = b > 0. Hence X0 < E
)
Xτb
F0
*
= b. The claim
of the optional sampling theorem may thus fail, in general, if the stopping time is
unbounded. ♦
Example 10.19 (Gambler’s ruin problem) Consider a game of two persons, A and
B. In each round, a coin is tossed. Depending on the outcome, either A gets a euro
from B or vice versa. The game endures until one of the players is ruined. For
simplicity, we assume that in the beginning A has kA ∈N euros while B has kB =
N −kA euros, where N ∈N, N ≥kA. We want to know the probability of B’s
ruin. In Example 10.16 we saw that for a fair coin this probability is kA/N. Now we
allow the coin to be unfair.
Hence, let Y1, Y2, . . . be i.i.d. and ∼Radp (that is, P[Yi = 1] = 1 −P[Yi =
−1] = p) for some p ∈(0, 1) \ { 1
2}. Denote by Xn := kB + n
i=1 Yi the running
total for B after n rounds, where formally we assume that the game continues even
after one player is ruined. We deﬁne as above τ0, τN and τ0,N as the times of ﬁrst
entrance of X into {0}, {N} and {0, N}, respectively. The ruin probability of B thus
is pN
B := P[τ0,N = τ0]. Since X is not a martingale (except for the case p = 1
2
that was excluded), we use a trick to construct a martingale. Deﬁne a new process
Z by Zn := rXn = rkB n
i=1 rYi, where r > 0 has to be chosen so that Z becomes
a martingale. By Example 9.31, this is the case if and only if
E[rY1] = pr + (1 −p)r−1 = 1;
hence, if r = 1 or r = 1−p
p . Evidently, the choice r = 1 is useless (as Z does not
yield any information on X); hence we assume r = 1−p
p . We thus get
τ0 = inf
	
n ∈N0 : Zn = 1

and
τN = inf
	
n ∈N0 : Zn = rN
.
(Note that here we cannot argue as above in order to show that τ0 < ∞and
τN < ∞almost surely. In fact, for p ̸=
1
2, only one of the statements holds.
However, using, for example, the strong law of large numbers, we obtain that
lim infn→∞Xn = ∞(and thus τN < ∞) almost surely if p > 1
2. Similarly, τ0 < ∞
almost surely if p < 1
2.) As in Example 10.16, the optional stopping theorem yields
rkB = Z0 = E[Zτ0,N ] = pN
B + (1 −pN
B )rN. Therefore, the probability of B’s ruin
is
pN
B = rkB −rN
1 −rN .
(10.7)

238
10
Optional Sampling Theorems
If the game is advantageous for B (that is, p > 1
2), then r < 1. In this case, in the
limit N →∞(with constant kB),
p∞
B := lim
N→∞pN
B = rkB.
(10.8)
♦
Takeaways For a martingale, by deﬁnition, the conditional expected value at
a later time given the information available at the present time is just the value
at the present time. Here we have shown that this remains true for random
times as long as they are bounded stopping times (optional sampling theorem).
For general stopping times, we have shown that the stopped martingale is
again a martingale (optional stopping theorem). The corresponding statements
also hold for submartingales and supermartingales.
Exercise 10.2.1 Let X be a square integrable martingale with square variation
process ⟨X⟩. Let τ be a ﬁnite stopping time. Show the following:
(i) If E[⟨X⟩τ ] < ∞, then
E
)
(Xτ −X0)2*
= E
)
⟨X⟩τ
*
and
E
)
Xτ
*
= E
)
X0
*
.
(10.9)
(ii) If E[⟨X⟩τ ] = ∞, then both equalities in (10.9) may fail. ♣
Exercise 10.2.2 We consider a situation that is more general than the one in the
preceding example by assuming only that Y1, Y2, . . . are i.i.d. integrable random
variables that are not almost surely constant (and Xn = Y1 + . . . + Yn). We further
assume that there is a δ > 0 such that E[exp(θY1)] < ∞for all θ ∈(−δ, δ).
Deﬁne a map ψ : (−δ, δ) →R by θ →log

E[exp(θY1)]

and the process Zθ by
Zθ
n := exp(θXn −nψ(θ)) for n ∈N0. Show the following:
(i) Zθ is a martingale for all θ ∈(−δ, δ).
(ii) ψ is strictly convex.
(iii) E
)2
Zθn
* n→∞
−→0 for θ ̸= 0.
(iv) Zθ
n
n→∞
−→0 almost surely.
We may interpret Yn as the difference between the premiums and the payments of
an insurance company at time n. If the initial capital of the company is k0 > 0, then
k0 + Xn is the account balance at time n. We are interested in the ruin probability
p(k0) = P
)
inf{Xn + k0 : n ∈N0} < 0
*
depending on the initial capital.

10.3
Uniform Integrability and Optional Sampling
239
It can be assumed that the premiums are calculated such that E[Y1] > 0. Show
that if the equation ψ(θ) = 0 has a solution θ∗̸= 0, then θ∗< 0. Show further that
in this case, the Cramér–Lundberg inequality holds:
p(k0) ≤exp(θ∗k0).
(10.10)
Equality holds if k0 ∈N and if Yi assumes only the values −1 and 1. In this case,
we get (10.8) with r = exp(θ∗). ♣
10.3
Uniform Integrability and Optional Sampling
We extend the optional sampling theorem to unbounded stopping times. We will see
that this is possible if the underlying martingale is uniformly integrable (compare
Deﬁnition 6.16).
Lemma 10.20 Let (Xn)n∈N0 be a uniformly integrable martingale. Then the family
(Xτ : τ is a ﬁnite stopping time) is uniformly integrable.
Proof By Theorem 6.19, there exists a monotone increasing, convex function f :
[0, ∞) →[0, ∞) with lim infx→∞f (x)/x = ∞and L := supn∈N0 E[f (|Xn|)] <
∞. If τ < ∞is a ﬁnite stopping time, then by the optional sampling theorem for
bounded stopping times (Theorem 10.11 with τ = n and σ = τ∧n), E[Xn
Fτ∧n] =
Xτ∧n. Since {τ ≤n} ∈Fτ∧n, Jensen’s inequality yields
E
)
f (|Xτ|) 1{τ≤n}
*
= E
)
f (|Xτ∧n|) 1{τ≤n}
*
≤E
)
E
)
f (|Xn|)
Fτ∧n
*
1{τ≤n}
*
= E
)
f (|Xn|) 1{τ≤n}
*
≤L.
Hence E[f (|Xτ|)] ≤L. By Theorem 6.19, the family
{Xτ, τ is a ﬁnite stopping time}
is uniformly integrable.
⊓⊔
Theorem 10.21 (Optional sampling and uniform integrability) Let (Xn, n ∈
N0) be a uniformly integrable martingale (respectively supermartingale) and let
σ ≤τ be ﬁnite stopping times. Then E[|Xτ|] < ∞and Xσ
= E[Xτ
Fσ]
(respectively Xσ ≥E[Xτ
Fσ]).
Proof First let X be a martingale. We have {σ ≤n} ∩F ∈Fσ∧n for all F ∈Fσ.
Hence, by the optional sampling theorem (Theorem 10.11),
E)Xτ∧n 1{σ≤n}∩F
* = E)Xσ∧n 1{σ≤n}∩F
*.

240
10
Optional Sampling Theorems
By Lemma 10.20, (Xσ∧n, n ∈N0) and thus (Xσ∧n 1{σ≤n}∩F , n ∈N0) are
uniformly integrable. Similarly, this holds for Xτ. Therefore, by Theorem 6.25,
E[Xτ 1F ] = lim
n→∞E
)
Xτ∧n 1{σ≤n}∩F
*
= lim
n→∞E
)
Xσ∧n 1{σ≤n}∩F
*
= E[Xσ 1F ].
We conclude that E[Xτ
Fσ] = Xσ.
Now let X be a supermartingale and let X = M + A be its Doob decomposition;
that is, M is a martingale and A ≤0 is predictable and decreasing. Since
E[|An|] = E[−An] ≤E[|Xn −X0|] ≤E[|X0|] + sup
m∈N0
E[|Xm|] < ∞,
we have An ↓A∞for some A∞≤0 with E[−A∞] < ∞(by the monotone
convergence theorem). Hence A and thus M = X −A are uniformly integrable
(Theorem 6.18(ii)). Therefore,
E[|Xτ|] ≤E[−Aτ] + E[|Mτ|] ≤E[−A∞] + E[|Mτ|] < ∞.
Furthermore,
E[Xτ
Fσ] = E[Mτ
Fσ] + E[Aτ
Fσ]
= Mσ + Aσ + E[(Aτ −Aσ)
Fσ]
≤Mσ + Aσ = Xσ.
⊓⊔
Corollary 10.22 Let X be a uniformly integrable martingale (respectively super-
martingale) and let τ1 ≤τ2 ≤. . . be ﬁnite stopping times. Then (Xτn)n∈N is a
martingale (respectively supermartingale).
Reﬂection Find an example that shows that uniform integrability is essential in
Theorem 10.21. ♠
Takeaways The deﬁning property for (sub-, super-) martingales can be
extended to unbounded (but ﬁnite) stopping times if and only if the processes
are uniformly integrable.

Chapter 11
Martingale Convergence Theorems
and Their Applications
We became familiar with martingales X = (Xn)n∈N0 as fair games and found
that under certain transformations (optional stopping, discrete stochastic integral)
martingales turn into martingales. In this chapter, we will see that under weak condi-
tions (non-negativity or uniform integrability) martingales converge almost surely.
Furthermore, the martingale structure implies Lp-convergence under assumptions
that are (formally) weaker than those of Chap. 7. The basic ideas of this chapter are
Doob’s inequality (Theorem 11.2) and the upcrossing inequality (Lemma 11.3).
11.1
Doob’s Inequality
With Kolmogorov’s inequality (Theorem 5.28), we became acquainted with an
inequality that bounds the probability of large values of the maximum of a square
integrable process with independent centered increments. Here we want to improve
this inequality in two directions. On the one hand, we replace the independent
increments by the assumption that the process of partial sums is a martingale. On
the other hand, we can manage with less than second moments; alternatively, we
can get better bounds if we have higher moments.
Let I ⊂N0 and let X = (Xn)n∈I be a stochastic process. For n ∈N, we denote
X∗
n = sup{Xk : k ≤n}
and
|X|∗
n = sup{|Xk| : k ≤n}.
Lemma 11.1 If X is a submartingale, then, for all λ > 0,
λ P
)
X∗
n ≥λ
*
≤E
)
Xn 1{X∗n≥λ}
*
≤E
)
|Xn| 1{X∗n≥λ}
*
.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_11
241

242
11
Martingale Convergence Theorems and Their Applications
Proof The second inequality is trivial. For the ﬁrst one, let
τ := inf
	
k ∈I : Xk ≥λ

∧n.
By Theorem 10.11 (optional sampling theorem),
E[Xn] ≥E[Xτ] = E
)
Xτ 1{X∗n≥λ}
*
+ E
)
Xτ 1{X∗n<λ}
*
≥λ P
)
X∗
n ≥λ
*
+ E
)
Xn 1{X∗n<λ}
*
.
(Note that τ = n if X∗
n < λ.) Now subtract E)Xn 1{X∗n<λ}
*.
⊓⊔
Theorem 11.2 (Doob’s Lp-inequality) Let X be a martingale or a positive sub-
martingale.
(i) For any p ≥1 and λ > 0,
λp P
)
|X|∗
n ≥λ
*
≤E
)
|Xn|p*
.
(ii) For any p > 1,
E
)
|Xn|p*
≤E
)
(|X|∗
n)p*
≤

p
p −1
p
E
)
|Xn|p*
.
Proof We follow the proof in [145]. As all the statements in (i) and (ii) are trivially
true if E[|X|p
n] = ∞, we may and will assume that E[|Xn|p] < ∞.
(i) By Theorem 9.35, (|Xn|p)n∈I is a submartingale, and the claim follows by
Lemma 11.1.
(ii) The ﬁrst inequality is trivial. By Lemma 11.1, for the second inequality, we
have
λP
)
|X|∗
n ≥λ
*
≤E
)
|Xn| 1{|X|∗n≥λ}
*
.
Hence, for any K > 0,
E
)
(|X|∗
n ∧K)p*
= E
- |X|∗
n∧K
0
p λp−1 dλ
.
= E
+ K
0
p λp−1 1{|X|∗n≥λ} dλ
,
=
 K
0
p λp−1 P[|X|∗
n ≥λ] dλ

11.2
Martingale Convergence Theorems
243
≤
 K
0
p λp−2 E
)
|Xn| 1{|X|∗n≥λ}
*
dλ
= p E
-
|Xn|
 |X|∗
n∧K
0
λp−2 dλ
.
=
p
p −1 E)|Xn| · (|X|∗
n ∧K)p−1*.
Hölder’s inequality then yields
E
)
(|X|∗
n ∧K)p*
≤
p
p −1 E
)
(|X|∗
n ∧K)p*(p−1)/p · E
)
|Xn|p*1/p.
We raise both sides to the pth power and divide by E)(|X|∗
n∧K)p*p−1 (here we
need the truncation at K to make sure we divide by a ﬁnite number) to obtain
E
)
(|X|∗
n ∧K)p*
≤

p
p −1
p
E
)
|Xn|p*
.
Finally, let K →∞.
⊓⊔
Reﬂection Check that Kolmogorov’s inequality (5.12) is a special case of (i) for
p = 2. ♠
Takeaways Martingales, respectively sub- and supermartingales, have so
much structure that the maximal value over a ﬁnite trajectory can be estimated
by the ﬁnal value only; at least in expectation or as a pth moment.
Exercise 11.1.1 Let (Xn)n∈N0 be a submartingale or a supermartingale. Use Theo-
rem 11.2 and Doob’s decomposition to show that, for all n ∈N and λ > 0,
λ P
)
|X|∗
n ≥λ
*
≤6 E[|X0|] + 4 E[|Xn|].
♣
11.2
Martingale Convergence Theorems
In this section, we present the usual martingale convergence theorems and give a
few small examples. We start with the core of the martingale convergence theorems,
the so-called upcrossing inequality.
Let F = (Fn)n∈N0 be a ﬁltration and F∞= σ
 
n∈N0 Fn

. Let (Xn)n∈N0 be
real-valued and adapted to F. Let a, b ∈R with a < b. If we think of X as a stock

244
11
Martingale Convergence Theorems and Their Applications
a
b
τ0 = 0
σ1
τ2
σ2 τ3 σ3
τ4
σ4
τ5
Fig. 11.1 Four upcrossings over [a, b] are completed. One more has just started.
price, it would be a sensible trading strategy to buy the stock when its price has
fallen below a and to sell it when it exceeds b at least if we knew for sure that the
price would always rise above the level b again. Each time the price makes such an
upcrossing from a to b, we make a proﬁt of at least b −a. If we get a bound on
the maximal proﬁt we can make, dividing it by b −a gives a bound on the maximal
number of such upcrossings. If this number is ﬁnite for all a < b, then the price has
to converge as n →∞.
Let us get into the details. Deﬁne stopping times σ0 ≡0 and (see Fig. 11.1)
τk := inf{n ≥σk−1 : Xn ≤a}
for k ∈N,
σk := inf{n ≥τk : Xn ≥b}
for k ∈N.
Note that τk = ∞if σk−1 = ∞, and σk = ∞if τk = ∞. We say that X has its
kth upcrossing over [a, b] between τk and σk if σk < ∞. For n ∈N, deﬁne
Ua,b
n
:= sup{k ∈N0 : σk ≤n}
as the number of upcrossings over [a, b] until time n.
Lemma 11.3 (Upcrossing inequality) Let (Xn)n∈N0 be a submartingale. Then
E
'
Ua,b
n
(
≤E[(Xn −a)+] −E[(X0 −a)+]
b −a
.
Proof Recall the discrete stochastic integral H ·X from Deﬁnition 9.37. Formally,
the intimated trading strategy H is described for m ∈N0 by
Hm :=

1,
if m ∈{τk + 1, . . . , σk} for some k ∈N,
0,
else.

11.2
Martingale Convergence Theorems
245
H is nonnegative and predictable since, for all m ∈N,
{Hm = 1} =
∞

k=1
{τk ≤m −1} ∩{σk > m −1},
and each of the events is in Fm−1. Deﬁne Y = max(X, a). If k ∈N and σk < ∞,
then clearly Yσi −Yτi = Yσi −a ≥b −a for all i ≤k; hence
(H ·Y)σk =
k

i=1
σi

j=τi+1
(Yj −Yj−1) =
k

i=1
(Yσi −Yτi) ≥k(b −a).
For j ∈{σk, . . . , τk+1}, we have (H ·Y)j = (H ·Y)σk. On the other hand, for
j ∈{τk + 1, . . . , σk}, we have (H ·Y)j ≥(H ·Y)τk = (H ·Y)σk−1. Hence (H ·Y)n ≥
(b −a)Ua,b
n
for all n ∈N.
By Corollary 9.34, Y is a submartingale, and (by Theorem 9.39) so are H ·Y and
(1 −H)·Y. Now Yn −Y0 = (1·Y)n = (H ·Y)n + ((1 −H)·Y)n; hence
E[Yn −Y0] ≥E
)
(H ·Y)n
*
≥(b −a)E
)
Ua,b
n
*
.
⊓⊔
Theorem 11.4 (Martingale convergence theorem) Let (Xn)n∈N0 be a submartin-
gale with sup{E[X+
n ] : n ≥0} < ∞. Then there exists an F∞-measurable random
variable X∞with E[|X∞|] < ∞and Xn
n→∞
−→X∞almost surely.
Proof Let a < b. Since E[(Xn −a)+] ≤|a| + E[X+
n ], by Lemma 11.3,
E[Ua,b
n
] ≤|a| + E[X+
n ]
b −a
.
Manifestly, the monotone limit Ua,b := limn→∞Ua,b
n
exists. By assumption, we
have E
)
Ua,b*
= limn→∞E[Ua,b
n
] < ∞. In particular, P
)
Ua,b < ∞
*
= 1. Deﬁne
the F∞-measurable events
Ca,b =

lim inf
n→∞Xn < a

∩
0
lim sup
n→∞
Xn > b
1
⊂

Ua,b = ∞

and
C =

a,b∈Q
a<b
Ca,b.
Then P)Ca,b* = 0 and thus also P[C] = 0. However, by construction, (Xn)n∈N
is convergent on Cc. Hence there exists the almost sure limit X∞= limn→∞Xn.
Each Xn is F∞-measurable; hence X∞also is F∞-measurable.

246
11
Martingale Convergence Theorems and Their Applications
By Fatou’s lemma,
E[X+
∞] ≤sup
	
E[X+
n ] : n ≥0

< ∞.
On the other hand (since X is a submartingale), again by Fatou’s lemma,
E[X−
∞] ≤lim inf
n→∞E[X−
n ] = lim inf
n→∞

E[X+
n ] −E[Xn]

≤sup
	
E[X+
n ] : n ∈N0

−E[X0] < ∞.
⊓⊔
Corollary 11.5 If X is a nonnegative supermartingale, then there is an F∞-mea-
surable random variable X∞≥0 with E[X∞] ≤E[X0] and Xn
n→∞
−→X∞a.s.
Proof The preceding theorem with (−X) establishes X∞as the almost sure limit.
Fatou’s lemma yields
E[X∞] ≤lim inf
n→∞E[Xn] ≤E[X0].
⊓⊔
Reﬂection Why do we need nonnegativity of X in Corollary 11.5? Find an example
of a supermartingale that does not converge. ♠
Example 11.6 Let Sn be the account balance in the Petersburg game after the nth
round (see Example 9.40). Then S is a martingale and Sn ≤1 almost surely for any
n. Hence the assumptions of Theorem 11.4 are fulﬁlled and (Sn)n∈N0 converges to a
ﬁnite random variable almost surely for n →∞. Since the account changes as long
as stakes are put up (that is, as long as Sn < 1), we get lim
n→∞Sn = 1 almost surely.
Since E[Sn] = 0 for all n ∈N0, this convergence cannot hold in L1. This
observation tallies with the fact that S is not uniformly integrable. ♦
For uniformly integrable martingales, a stronger convergence theorem holds.
Theorem 11.7 (Convergence theorem for uniformly integrable martingales)
Let (Xn)n∈N0 be a uniformly integrable F- (sub-, super-) martingale. Then there
exists an F∞-measurable integrable random variable X∞with Xn
n→∞
−→X∞a.s.
and in L1. Furthermore:
•
Xn = E[X∞
Fn] for all n ∈N if X is a martingale.
•
Xn ≤E[X∞
Fn] for all n ∈N if X is a submartingale.
•
Xn ≥E[X∞
Fn] for all n ∈N if X is a supermartingale.
Remark 11.8 The statement of Theorem 11.7 can be reformulated as: The process
(Xn)n∈N0∪{∞} is a (sub-, super-) martingale with respect to (Fn)n∈N0∪{∞}. ♦
Proof We give the proof for the case where X is a submartingale. Uniform
integrability implies sup{E[X+
n ] :
n ≥0} < ∞. By Theorem 11.4, the almost
sure limit X∞exists. Hence E[|Xn −X∞|]
n→∞
−→
0 by Theorem 6.25. By
Corollary 8.21, the L1-convergence of (Xn) implies the L1-convergence of the

11.2
Martingale Convergence Theorems
247
conditional expectations: E
)E[Xn
Fm] −E[X∞
Fm]
*
n→∞
−→
0. Thus, by the
triangle inequality,
E
)
E[X∞
Fm] −Xm
−*
−E
)
E[Xn
Fm] −Xm
−*
≤E
'E[X∞
Fm] −E[Xn
Fm]

( n→∞
−→0.
As X is a submartingale, we have E[Xn
Fm] −Xm
−= 0 for n ≥m. Therefore,
E
) 
E[X∞
Fm] −Xm
−*
= 0 and thus E[X∞
Fm] −Xm ≥0 almost surely.
⊓⊔
Corollary 11.9 Let X ≥0 be a martingale and let X∞= lim
n→∞Xn. Then E[X∞] =
E[X0] if and only if X is uniformly integrable.
Proof This is a direct consequence of Theorem 6.25.
⊓⊔
Let p ∈[1, ∞). A real-valued stochastic process (Xi)i∈I is called Lp-bounded if
supi∈I E[|Xi|p] < ∞(Deﬁnition 6.20). In general, for (|Xi|p)i∈I to be uniformly
integrable it is not enough that (Xi)i∈I be Lp-bounded. However, if X is a
martingale and if p > 1, then Doob’s inequality implies that the statements are
equivalent. In particular, in this case, almost sure convergence implies convergence
in Lp.
Theorem 11.10 (Lp-convergence theorem for martingales) Let p > 1 and let
(Xn)n∈N0 be an Lp-bounded martingale. Then there exists an F∞-measurable
random variable X∞with E[|X∞|p] < ∞and Xn
n→∞
−→X∞almost surely and
in Lp. In particular, (|Xn|p)n∈N0 is uniformly integrable.
Proof By Corollary 6.21, X is uniformly integrable. Hence the almost sure limit
X∞exists. By Doob’s inequality (Theorem 11.2), for all n ∈N,
E
)
sup
	
|Xk|p : k ≤n

*
≤

p
p −1
p
E
)
|Xn|p*
.
Therefore,
E
'
sup
	
|Xk|p : k ∈N0

(
≤

p
p −1
p
sup

E
)
|Xn|p*
: n ∈N0

< ∞.
Hence, in particular, (|Xn|p)n∈N0 is uniformly integrable.
Since |Xn −X∞|p ≤2p sup{|Xm|p : m ∈N0}, dominated convergence yields
E
)
|X∞|p*
< ∞
and
E
)
|Xn −X∞|p* n→∞
−→0.
⊓⊔
Reﬂection Let (Xn) be an Lp-bounded sequence of random variables that is almost
surely convergent. In general, this does not imply that (Xn) also converges in Lp.

248
11
Martingale Convergence Theorems and Their Applications
However, for martingales, it does as we have seen in the above theorem. Exactly
where in the proof did we use the martingale property? ♠
For the case of square integrable martingales, there is a convenient criterion for
L2-boundedness that we record as a corollary (see Deﬁnition 10.3).
Corollary 11.11 Let X be a square integrable martingale with square variation
process ⟨X⟩. Then the following four statements are equivalent:
(i) supn∈N E[X2
n] < ∞.
(ii) limn→∞E[⟨X⟩n] < ∞.
(iii) X converges in L2.
(iv) X converges almost surely and in L2.
Proof “((i)) ⇐⇒((ii))”
Since Var[Xn −X0] = E[⟨X⟩n] (see Theorem 10.4),
X is bounded in L2 if and only if ((ii)) holds.
“((iv)) ⇒((iii)) ⇒((i))”
This is trivial.
“((i)) ⇒((iv))”
This is the statement of Theorem 11.10.
⊓⊔
Remark 11.12 In general, the statement of Theorem 11.10 fails for p = 1. See
Exercise 11.2.1. ♦
Lemma 11.13 Let X be a square integrable martingale with square variation
process ⟨X⟩, and let τ be a stopping time. Then the stopped process Xτ has square
variation process ⟨Xτ ⟩= ⟨X⟩τ := (⟨X⟩τ∧n)n∈N0.
Proof This is left as an exercise.
⊓⊔
If in Corollary 11.11 we do not assume that the expectations of the square variation
are bounded but only that the square variation is almost surely bounded, then we
still get that X converges almost surely (albeit not in L2).
Theorem 11.14 If X is a square integrable martingale with supn∈N⟨X⟩n < ∞
almost surely, then X converges almost surely.
Proof Without loss of generality, we can assume that X0 = 0, otherwise consider
the martingale (Xn −X0)n∈N0, which has the same square variation process. For
K > 0, let
τK := inf{n ∈N : ⟨X⟩n+1 ≥K}.
This is a stopping time since ⟨X⟩is predictable. Evidently, supn∈N⟨X⟩τK ∧n ≤K
almost surely. By Corollary 11.11, the stopped process XτK converges almost surely
(and in L2) to a random variable that we denote by XτK
∞. By assumption, P[τK =
∞] →1 for K →∞; hence X converges almost surely.
⊓⊔

11.2
Martingale Convergence Theorems
249
Example 11.15 Let X be a symmetric simple random walk on Z. That is, Xn =
n
k=1
Rk, where R1, R2, . . . are i.i.d. and ∼Rad1/2:
P[R1 = 1] = P[R1 = −1] = 1
2.
Then X is a martingale; however, lim supn→∞Xn = ∞and lim infn→∞Xn = −∞.
Therefore, X does not even converge improperly. By the martingale convergence
theorem, this is consonant with the fact that X is not uniformly integrable. ♦
Example 11.16 (Voter model, due to [28, 75]) Consider a simple model that
describes the behavior of opportunistic voters who are capable of only one out of
two opinions, say 0 and 1. Let Λ ⊂Zd be a set that we interpret as the sites at each
of which there is one voter. For simplicity, assume that Λ = {0, . . ., L −1}d for
some L ∈N. Let x(i) ∈{0, 1} be the opinion of the voter at site i ∈Λ and denote
by x ∈{0, 1}Λ a generic state of the whole population. We now assume that the
individual opinions may change at discrete time steps. At any time n ∈N0, one site
In out of Λ is chosen at random and the individual at that site reconsiders his or
her opinion. To this end, the voter chooses a neighbor In + Nn ∈Λ (with periodic
boundary conditions; that is, with addition modulo L in each coordinate) at random
and adopts his or her opinion. We thus get a random sequence (Xn)n∈N0 of states
in {0, 1}Λ that represents the random evolution of the opinions of the whole colony.
See Fig. 11.2 for a simulation of the voter model.
For a formal description of this model, let (In)n∈N and (Nn)n∈N be independent
random variables. For any n ∈N, In is uniformly distributed on Λ and Nn is
uniformly distributed on the set N := {i ∈Zd : ∥i∥2 = 1} of the 2d nearest
neighbors of the origin. Furthermore, x = X0 ∈{0, 1}Λ is the initial state. The
states at later times are deﬁned inductively by
Xn(i) =

Xn−1(i),
if In ̸= i,
Xn−1(In + Nn),
if In = i.
Of course, the behavior over small periods of time is determined by the perils of
randomness. However, in the long run, we might see certain patterns. To be more
speciﬁc, the question is: In the long run, will there be a consensus of all individuals
or will competing opinions persist?

250
11
Martingale Convergence Theorems and Their Applications
Fig. 11.2 Snapshot of a voter model on an 800 × 800 torus. The black dots are the Ones.
Let Mn := 
i∈Λ Xn(i) be the total number of individuals of opinion 1 at time
n. Let F be the ﬁltration F = (Fn)n∈N0, where Fn = σ(Ik, Nk : k ≤n) for all
n ∈N0. Then M is adapted to F and
E[Mn
Fn−1] = Mn−1 −E[Xn−1(In)
Fn−1] + E[Xn−1(In + Nn)
Fn−1]
= Mn−1 −

i∈Λ
P[In = i] Xn−1(i) +

i∈Λ
P[In + Nn = i] Xn−1(i)
= Mn−1
since P[In = i] = P[In + Nn = i] = L−d for all i ∈Λ. Hence M is a bounded
F-martingale and thus converges almost surely and in L1 to a random variable M∞.
Since M takes only integer values, there is a (random) n0 such that Mn = Mn0 for
all n ≥n0. However, then also Xn = Xn0 for all n ≥n0. Manifestly, no state x with
x ̸≡0 and x ̸≡1 is stable. In fact, if x is not constant and if i, j ∈Λ are neighbors
with x(i) ̸= x(j), then
P[Xn ̸= Xn−1
Xn−1 = x] ≥P[In−1 = i, Nn−1 = j −i] = L−d(2d)−1.

11.2
Martingale Convergence Theorems
251
This implies M∞∈{0, Ld}. Now E[M∞] = M0; hence we have
P
)
M∞= Ld *
= M0
Ld
and
P
)
M∞= 0
*
= 1 −M0
Ld .
Thus, eventually there will be a consensus of all individuals, and the probability that
the surviving opinion is e ∈{0, 1} is the initial frequency of opinion e.
We could argue more formally to show that only the constant states are stable:
Let ⟨M⟩be the square variation process of M. Then
⟨M⟩n =
n

k=1
E)1{Mk̸=Mk−1}
Fk−1
* =
n

k=1
P)Xk−1(Ik) ̸= Xk−1(Ik + Nk)
Fk−1
*.
Hence
L2d ≥Var[Mn] = E[⟨M⟩n]
=
n

k=1
P[Xk−1(Ik) ̸= Xk−1(Ik + Nk)]
≥(2d)−1L−d
n

k=1
P[Mk−1 ̸∈{0, Ld}].
Therefore, ∞
k=1 P[Mk−1 ̸∈{0, Ld}] ≤2dL3d < ∞, and so, by the Borel–Cantelli
lemma, M∞∈{0, Ld}. ♦
Example 11.17 (Radon–Nikodym theorem) With the aid of the martingale con-
vergence theorem, we give an alternative proof of the Radon–Nikodym theorem
(Corollary 7.34).
Let (Ω, F, P) be a probability space and let Q be another probability measure
on (Ω, A). We assume that F is countably generated; that is, there exist countably
many sets A1, A2, . . . ∈F such that F = σ({A1, A2, . . .}). For example, this is the
case if F is the Borel σ-algebra on a Polish space. For the case Ω = Rd, one could
take the open balls with rational radii, centered at points with rational coordinates
(compare Remark 1.24).
We construct a ﬁltration F = (Fn)n∈N by letting Fn := σ({A1, . . . , An}).
Evidently, #Fn < ∞for all n ∈N. More precisely, there exists a unique ﬁnite
subset Zn ⊂Fn \ {∅} such that B =

C∈Zn
C⊂B
C for any B ∈Fn. Zn decomposes Fn
into its “atoms”. Finally, deﬁne a stochastic process (Xn)n∈N by
Xn :=

C∈Zn: P[C]>0
Q(C)
P[C] 1C.

252
11
Martingale Convergence Theorems and Their Applications
Clearly, X is adapted to F. Let B ∈Fn and m ≥n. For any C ∈Zm, either
C ∩B = ∅or C ⊂B. Hence
E[Xm 1B] =

C∈Zm: P[C]>0
Q(C)
P[C] P[C ∩B] =

C∈Zm: C⊂B
Q(C) = Q(B).
(11.1)
In particular, X is an F-martingale.
Now assume that Q is absolutely continuous with respect to P. By Example 7.39,
this implies that X is uniformly integrable. By the martingale convergence theorem,
X converges P-almost surely and in L1(P) to a random variable X∞. By (11.1),
we have E[X∞1B] = Q(B) for all B ∈
n∈N Fn and thus also for all B ∈F.
Therefore, X∞is the Radon–Nikodym density of Q with respect to P.
Note that for this proof we did not presume the existence of conditional
expectations (rather we constructed them explicitly for ﬁnite σ-algebras); that is,
we did not resort to the Radon–Nikodym theorem in a hidden way.
It could be objected that this argument works only for probability measures.
However, this ﬂaw can easily be remedied. Let μ and ν be arbitrary (but nonzero)
σ-ﬁnite measures. Then there exist measurable functions g, h : Ω →(0, ∞) with
3
g dμ = 1 and
3
h dν = 1. Deﬁne P = gμ and Q = hν. Clearly, Q ≪P if
ν ≪μ. In this case, g
hX∞is a version of the Radon–Nikodym derivative dν
dμ.
The restriction that F is countably generated can also be dropped. Using the
approximation theorems for measures, it can be shown that there is always a
countably generated σ-algebra G ⊂F such that for any A ∈F, there is a B ∈G
with P[A△B] = 0. This can be employed to prove the general case. We do not give
the details but refer to [170, Chapter 14.13]. ♦
Takeaways For (sub-) martingales, Doob’s upcrossing lemma bounds the
number of upcrossings over a given interval. As a consequence, we get almost
sure convergence of nonnegative (super-) martingales. Uniformly integrable
(sub-, super-) martingales converge almost surely and in L1. For p > 1, Lp-
bounded martingales also converge in Lp.
Exercise 11.2.1 For p = 1, the statement of Theorem 11.10 may fail. Give an
example of a nonnegative martingale X with E[Xn] = 1 for all n ∈N but such that
Xn
n→∞
−→0 almost surely. ♣
Exercise 11.2.2 Let X1, X2, . . . be independent, square integrable random vari-
ables with ∞
n=1
1
n2 Var[Xn] < ∞. Use the martingale convergence theorem to
show the strong law of large numbers for (Xn)n∈N. ♣
Exercise 11.2.3 Give an example of a square integrable martingale that converges
almost surely but not in L2. ♣

11.2
Martingale Convergence Theorems
253
Exercise 11.2.4 Show that in Theorem 11.14 the converse implication may fail.
That is, there exists a square integrable martingale X that converges almost surely
but without lim
n→∞⟨X⟩n < ∞almost surely. ♣
Exercise 11.2.5 Show the following converse of Theorem 11.14. Let L > 0 and let
(Xn)n∈N be a martingale with the property
Xn+1 −Xn
 ≤L
a.s.
(11.2)
Deﬁne the events
C :=
	
(Xn)n∈N converges as n →∞

,
A+ :=

lim sup
n→∞
Xn < ∞

,
A−:=

lim inf
n→∞Xn > −∞

,
F :=

sup
n∈N
⟨X⟩n < ∞

.
Show that
C = A+ = A−= F
(mod P).
Here equality of events (mod P) means that the events differ at most by a P-null set
(see Deﬁnition 1.68(iii)).
Hint: Use the stopping times σK = inf{n ∈N : |Xn| ≥K}; σ ±
K = inf{n ∈N :
±Xn ≥K} and τK as in the proof of Theorem 11.14. ♣
Exercise 11.2.6 Let the notation be as in Exercise 11.2.5. However, instead of
(11.2) we make the weaker assumption
E
'
sup
n∈N
Xn+1 −Xn

(
< ∞.
(11.3)
Show that
C = A+ = A−
(mod P).
Hint:
Use suitable stopping times ϱK and apply the martingale convergence
theorem (Theorem 11.4) to the stopped process XϱK. ♣
Exercise 11.2.7 (Conditional Borel–Cantelli lemma) Let (Fn)n∈N0 be a ﬁltration
and let (An)n∈N be events with An
∈
Fn for all n
∈
N. Deﬁne A∞
=
	 ∞
n=1 P[An|Fn−1] = ∞

and A∗= lim supn→∞An. Show the conditional
Borel–Cantelli lemma: P[A∞△A∗] = 0.

254
11
Martingale Convergence Theorems and Their Applications
Hint: Apply Exercise 11.2.5 to Xn = ∞
n=1(1An −P[An|Fn−1]). ♣
Exercise 11.2.8 Let p ∈[0, 1] and let X = (Xn)n∈N0 be a stochastic process with
values in [0, 1]. Assume that for all n ∈N0, given X0, . . . , Xn, we have
Xn+1 =
0 1 −p + pXn
with probability Xn,
pXn
with probability 1 −Xn.
Show that X is a martingale that converges almost surely. Compute the distribution
of the almost sure limit limn→∞Xn. ♣
Exercise 11.2.9 Let f ∈L1(λ), where λ is the restriction of the Lebesgue measure
to [0, 1]. Let In,k = [k 2−n, (k + 1) 2−n) for n ∈N and k = 0, . . . , 2n −1. Deﬁne
fn : [0, 1] →R by
fn(x) = 2n

Ik,n
f dλ,
if k is chosen such that x ∈Ik,n.
Show that fn(x)
n→∞
−→f (x) for λ-almost all x ∈[0, 1]. ♣
Exercise 11.2.10 Assume that F = (Fn)n∈N is a ﬁltration on the probability
space (Ω, A, P). Let F∞:= σ(Fn : n ∈N), and let M be the vector space
of uniformly integrable F-martingales. Show that the map Φ : L1(F∞) →M,
X∞→(E[X∞|Fn])n∈N is an isomorphism of vector spaces. ♣
11.3
Example: Branching Process
Let p = (pk)k∈N0 be a probability vector on N0 and let (Zn)n∈N0 be the Galton–
Watson process with one ancestor and offspring distribution p (see Deﬁnition 3.9).
For convenience, we recall the construction of Z. Let (Xn,i)n∈N0, i∈N be i.i.d.
random variables with P[X1,1 = k] = pk for k ∈N0. Let Z0 = 1 and inductively
deﬁne
Zn+1 =
Zn

i=1
Xn,i
for n ∈N0.
We interpret Zn as the size of a population at time n and Xn,i as the number of
offspring of the ith individual of the nth generation.
Let m := E[X1,1] < ∞be the expected number of offspring of an individual and
let σ 2 := Var[X1,1] ∈(0, ∞) be its variance. Let Fn := σ(Xk,i : k < n, i ∈N).
Then Z is adapted to F. Deﬁne Wn = m−n Zn.
Lemma 11.18 W is a martingale. In particular, E[Zn] = mn for all n ∈N.

11.3
Example: Branching Process
255
Proof We compute the conditional expectation for n ∈N0:
E[Wn+1
Fn] = m−(n+1) E[Zn+1
Fn]
= m−(n+1) E
- Zn

i=1
Xn,i
Fn
.
= m−(n+1)
∞

k=1
E
)
1{Zn=k}k · Xn,i
Fn
*
= m−n
∞

k=1
E
)
k · 1{Zn=k}
Fn
*
= m−n Zn = Wn.
⊓⊔
Theorem 11.19 Let Var[X1,1] ∈(0, ∞). The a.s. limit W∞= lim
n→∞Wn exists and
m > 1
⇐⇒
E[W∞] = 1
⇐⇒
E[W∞] > 0.
Proof W∞exists since W ≥0 is a martingale. If m ≤1, then (Zn)n∈N converges
a.s. to some random variable Z∞. Note that Z∞is the only choice since σ 2 > 0.
Now let m > 1. Since E[Zn−1] = mn−1 (Lemma 11.18), by the Blackwell–
Girshick formula (Theorem 5.10),
Var[Wn] = m−2n 
σ 2 E[Zn−1] + m2 Var[Zn−1]

= σ 2 m−(n+1) + Var[Wn−1].
Inductively, we get Var[Wn] = σ 2
n+1

k=2
m−k ≤σ 2 m
m −1 < ∞. Hence W is bounded
in L2 and Theorem 11.10 yields Wn →W∞in L2 and thus in L1. In particular,
E[W∞] = E[W0] = 1.
⊓⊔
Reﬂection Typically, the distribution of W cannot be computed explicitly. How-
ever, here we sketch a particular situation where this is possible. Assume that the
offspring distribution is given by P[X1,1 = k] = 1
3(2/3)k, k ∈N0. In Lemma 3.10,
we have seen how to iterate the generating function ψ(s) = E[sX1,1] = 1/(3 −2s)

256
11
Martingale Convergence Theorems and Their Applications
so as to get ψn(s) = E[sZn] =
(2−2n)s+2n−1
(2−2n+1)s+2n+1−1. Compare also Lemma 21.44. By
letting s = e−λ/2n, we obtain
lim
n→∞E[eλZn/2n] = 1 + λ
1 + 2λ = 1
2 + 1
2
1
1 + 2λ = E[e−λW],
where in the last step we assumed that PW = 1
2δ0 + 1
2 exp1/2. ♠♠♠
The proof of Theorem 11.19 was simple due to the assumption of ﬁnite variance of
the offspring distribution. However, there is a much stronger statement that here we
can only quote (see [95], and see [111] for a modern proof).
Theorem 11.20 (Kesten–Stigum [95]) Let m > 1. Then
E[W∞] = 1
⇐⇒
E[W∞] > 0
⇐⇒
E[X1,1 log(X1,1)+] < ∞.
Takeaways A Galton-Watson branching process (Zn) with mean offspring
number m > 1 has a positive chance to survive and in this case grows
indeﬁnitely. If the offspring number has a second moment, then Zn grows
of order mn and Zn/mn is uniformly integrable. Hence Zn/mn is an almost
surely and L1-convergent martingale. In general, the growth to inﬁnity of Zn
can also be slower than mn.

Chapter 12
Backwards Martingales
and Exchangeability
With many data acquisitions, such as telephone surveys, the order in which the data
come does not matter. Mathematically, we say that a family of random variables is
exchangeable if the joint distribution does not change under ﬁnite permutations. De
Finetti’s structural theorem says that an inﬁnite family of E-valued exchangeable
random variables can be described by a two-stage experiment. At the ﬁrst stage,
a probability distribution Ξ on E is drawn at random. At the second stage, i.i.d.
random variables with distribution Ξ are implemented.
We ﬁrst deﬁne the notion of exchangeability. Then we consider backwards
martingales and prove the convergence theorem for them. This is the cornerstone
for the proof of de Finetti’s theorem.
12.1
Exchangeable Families of Random Variables
Deﬁnition 12.1 Let I be an arbitrary index set and let E be a Polish space. A family
(Xi)i∈I of random variables with values in E is called exchangeable if
L )Xϱ(i)

i∈I
* = L )
(Xi)i∈I
*
for any ﬁnite permutation ϱ : I →I.
Recall that a ﬁnite permutation is a bijection ϱ : I →I that leaves all but ﬁnitely
many points unchanged.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_12
257

258
12
Backwards Martingales and Exchangeability
Strictly speaking, the deﬁnition of exchangeability makes sense only if we
identify Y = (Xi)i∈I and Y ′ = (Xϱ(i))i∈I as random variables on the product space
EI. The investigation of product spaces and their σ-algebras is, however, postponed
to Chap. 14.
Remark 12.2 Clearly, the following are equivalent.
(i) (Xi)i∈I is exchangeable.
(ii) Let n ∈N and assume i1, . . . , in ∈I are pairwise distinct and j1, . . . , jn ∈I
are pairwise distinct. Then we have L[(Xi1, . . . , Xin)] = L[(Xj1, . . . , Xjn)].
In particular (n = 1), exchangeable random variables are identically distributed. ♦
Example 12.3
(i) If (Xi)i∈I is i.i.d., then (Xi)i∈I is exchangeable.
(ii) Consider an urn with N balls, M of which are black. Successively draw without
replacement all of the balls and deﬁne
Xn :=

1,
if the nth ball is black,
0,
else.
Then (Xn)n=1,...,N is exchangeable. Indeed, this follows by elementary com-
binatorics since for any choice x1, . . . , xN ∈{0, 1} with x1 + . . . + xN = M,
we have
P
)
X1 = x1, . . . , XN = xN
*
=
1
N
M
.
This formula can be derived formally via a small computation with conditional
probabilities. As we will need a similar computation for Pólya’s urn model
in Example 12.29, we give the details here. Let sk = x1 + . . . + xk for k =
0, . . . , N and let
gk(x) =
0
M −sk,
if x = 1,
N −M + sk −k,
if x = 0.
Then P[X1 = x1] = g0(x1)/N and
P[Xk+1 = xk+1|X1 = x1, . . . , Xk = xk] = gk(xk+1)
N −k
for k = 1, . . . , N −1.

12.1
Exchangeable Families of Random Variables
259
Clearly, gk(0) = N −M −l, where l = #{i ≤k : xi = 0}. Therefore,
P[X1 = x1, . . . , XN = xN]
= P[X1 = x1]
N−1

k=1
P[Xk+1 = xk+1|X1 = x1, . . . , Xk = xk]
= 1
N!
N−1

k=0
gk(xk+1) =
1
N!

k: xk=1
gk(1)

k: xk=0
gk(0)
= 1
N!
M−1

l=0
(M −l)
N−1

l=0
(N −M −l) = M! (N −M)!
N!
.
(iii) Let Y be a random variable with values in [0, 1]. Assume that, given Y, the
random variables (Xi)i∈I are independent and BerY -distributed. That is, for
any ﬁnite J ⊂I,
P[Xj = 1 for all j ∈J
Y] = Y #J.
Then (Xi)i∈I is exchangeable. ♦
Reﬂection Find an example of an exchangeable family (Xn)n∈N of {0, 1}-valued
random variables that is not independent.♠
Let X = (Xn)n∈N be a stochastic process with values in a Polish space E.
Let S(n) be the set of permutations ϱ : {1, . . ., n} →{1, . . ., n}. We consider
ϱ also as a map N →N by deﬁning ϱ(k) = k for k > n. For ϱ ∈S(n)
and x = (x1, . . . , xn) ∈En, denote xϱ = (xϱ(1), . . . , xϱ(n)). Similarly, for
x ∈EN, denote xϱ = (xϱ(1), xϱ(2), . . .) ∈EN. Let E′ be another Polish space.
For measurable maps f : En →E′ and F : EN →E′, deﬁne the maps f ϱ and F ϱ
by f ϱ(x) = f (xϱ) and F ϱ(x) = F(xϱ). Further, we write f (x) = f (x1, . . . , xn)
for x ∈En and for x ∈EN.
Deﬁnition 12.4
(i) A map f : En →E′ is called symmetric if f ϱ = f for all ϱ ∈S(n).
(ii) A map F : EN →E′ is called n-symmetric if F ϱ = F for all ϱ ∈S(n). F is
called symmetric if F is n-symmetric for all n ∈N.
Example 12.5
(i) For x ∈RN, deﬁne the nth arithmetic mean by an(x) = 1
n
n
i=1 xi. Clearly,
an is an n-symmetric map (but not m-symmetric for any m > n). Furthermore,
¯a(x) := lim sup
n→∞
an(x) deﬁnes a symmetric map RN →R ∪{−∞, +∞}.
(ii) The map s : RN →[0, ∞], x →∞
i=1 |xi| is symmetric. Unlike ¯a, the value
of s depends on every coordinate if it is ﬁnite.

260
12
Backwards Martingales and Exchangeability
(iii) For x ∈EN, deﬁne the nth empirical distribution by ξn(x) =
1
n
n
i=1 δxi
(recall that δxi is the Dirac measure at the point xi). Clearly, ξn is an n-
symmetric map.
(iv) Let k ∈N and let ϕ : Ek →R be a map. The nth symmetrized average
An(ϕ) : EN →R,
x →1
n!

ϱ∈S(n)
ϕ(xϱ)
(12.1)
is an n-symmetric map. ♦
Deﬁnition 12.6 Let X = (Xn)n∈N be a stochastic process with values in E. For
n ∈N, deﬁne
E′
n := σ(F : F : EN →R is measurable and n-symmetric)
and let En := X−1(E′
n) be the σ-algebra of events that are invariant under all
permutations ϱ ∈S(n). Further, let
E′ :=
∞

n=1
E′
n = σF : F : EN →R is measurable and symmetric
and let En := ∞
n=1 En = X−1(E′) be the σ-algebra of exchangeable events for X,
or brieﬂy the exchangeable σ-algebra.
Remark 12.7 If A ∈σ(Xn, n ∈N) is an event, then there is a measurable B ⊂EN
with A = {X ∈B}. If we denote Aϱ = {Xϱ ∈B} for ϱ ∈S(n), then En = {A :
Aϱ = A for all ϱ ∈S(n)}. This justiﬁes the name “exchangeable event”. ♦
Remark 12.8 If we write Ξn(ω) := ξn(X(ω)) =
1
n
n
i=1 δXi(ω) for the nth
empirical distribution, then, by Exercise 12.1.1, we have En ⊃σ(Ξn) and En =
σ(Ξn, Xn+1, Xn+2, . . .).. ♦
Remark 12.9 Denote by T = 
n∈N σ(Xn+1, Xn+2, . . .) the tail σ-algebra. Then
T ⊂E, and strict inclusion is possible.
Indeed, evidently σ(Xn+1, Xn+2, . . .) ⊂En for n ∈N; hence T ⊂E. Now let
E = {0, 1} and let X1, X2, . . . be independent random variables with P[Xn = 1] ∈
(0, 1) for all n ∈N. The random variable S := ∞
n=1 Xn is measurable with respect
to E but not with respect to T . ♦
Theorem 12.10 Let X = (Xn)n∈N be exchangeable. If ϕ : EN →R is measurable
and if E[|ϕ(X)|] < ∞, then for all n ∈N and all ϱ ∈S(n),
E[ϕ(X)|En] = E[ϕ(Xϱ)|En].
(12.2)

12.1
Exchangeable Families of Random Variables
261
In particular,
E[ϕ(X)
En] = An(ϕ) := 1
n!

ϱ∈S(n)
ϕ(Xϱ).
(12.3)
Proof Let A ∈En. Then there exists a B ∈E′
n such that A = X−1(B). Let F = 1B.
Then F ◦X = 1A. By the deﬁnition of En, the map F : EN →R is measurable,
n-symmetric and bounded. Therefore,
E
)
ϕ(X)F(X)
*
= E
)
ϕ(Xϱ)F(Xϱ)
*
= E
)
ϕ(Xϱ)F(X)
*
.
Here we used the exchangeability of X in the ﬁrst equality and the symmetry of F
in the second equality. From this (12.2) follows. However, An(ϕ) is En-measurable
and hence
E)ϕ(X)
En
* = E
⎡
⎣1
n!

ϱ∈S(n)
ϕ(Xϱ)
En
⎤
⎦= 1
n!

ϱ∈S(n)
ϕ(Xϱ).
⊓⊔
Heuristic for the Structure of Exchangeable Families
Consider a ﬁnite exchangeable family X1, . . . , XN of E-valued random variables.
For n ≤N, what is the conditional distribution of (X1, . . . , Xn) given ΞN? For any
measurable A ⊂E, {Xi ∈A} occurs for exactly NΞN(A) of the i ∈{1, . . ., N},
where the order does not change the probability. Hence we are in the situation of
drawing colored balls without replacement. More precisely, let the pairwise distinct
points e1, . . . , ek ∈E be the atoms of ΞN and let N1, . . . , Nk be the corresponding
absolute frequencies. Hence ΞN = k
i=1(Ni/N)δei. We thus deal with balls of k
different colors and with Ni balls of the ith color. We draw n of these balls without
replacement but respecting the order. Up to the order, the resulting distribution is
thus the generalized hypergeometric distribution (see (1.19) on page 48). Hence, for
pairwise disjoint, measurable sets A1, . . . , Ak with k
l=1 Al = E, for i1, . . . , in ∈
{1, . . ., k}, pairwise distinct j1, . . . , jn ∈{1, . . . , N} and with the convention ml :=
#{r ∈{1, . . . , n} : ir = l} for l ∈{1, . . . , k}, we have
P
)
Xjr ∈Air for all r = 1, . . . , n
ΞN
*
=
1
(N)n
k
l=1

NΞN(Al)

ml.
(12.4)
Here we deﬁned (n)l := n(n −1) · · · (n −l + 1).

262
12
Backwards Martingales and Exchangeability
What happens if we let N →∞? For simplicity, assume that for all l = 1, . . . , k,
the limit Ξ∞(Al) = limN→∞ΞN(Al) exists in a suitable sense. Then (12.4)
formally becomes
P
)
Xjr ∈Air for all r = 1, . . . , n
Ξ∞
*
=
k
l=1
Ξ∞(Al)ml.
(12.5)
Drawing without replacements thus asymptotically turns into drawing with replace-
ments. Hence the random variables X1, X2, . . . are independent with distribution
Ξ∞given Ξ∞.
For a formal proof along the lines of this heuristic, see Sect. 13.4.
In order to formulate (and prove) this statement (de Finetti’s theorem) rigorously
in Sect. 12.3, we need some more technical tools (e.g., the notion of conditional
independence). A further tool will be the convergence theorem for backwards mar-
tingales that will be formulated in Sect. 12.2. For further reading on exchangeable
random variables, we refer to [4, 33, 98, 105].
Takeaways An event that is described by a sequence X1, X2, . . . of random
variables is called symmetric if ﬁnitely many of the Xi can be permuted
without changing the event. The event is called n-symmetric if we allow only
permutations of X1, . . . , Xn for some n. The exchangeable events form the
so-called exchangeable σ-algebra E. Every terminal event is symmetric. The
family X = (Xn)n∈N is called exchangeable if ﬁnitely many of the Xi can be
permuted without changing the distribution of the family.
Exercise 12.1.1 Let n ∈N. Show that every symmetric function f : En →R
can be written in the form f (x) = g
 1
n
n
i=1 δxi

, where g has to be chosen
appropriately (depending on f ). ♣
Exercise 12.1.2 Derive equation (12.4) formally. ♣
Exercise 12.1.3 Let X1, . . . , Xn be exchangeable, square integrable random vari-
ables. Show that
Cov[X1, X2] ≥−
1
n −1 Var[X1].
(12.6)
For n ≥2, give a nontrivial example for equality in (12.6). ♣
Exercise 12.1.4 Let X1, X2, X3 . . . be exchangeable, square integrable random
variables. Show that Cov[X1, X2] ≥0. ♣

12.2
Backwards Martingales
263
Exercise 12.1.5 Show that for all n ∈N \ {1}, there is an exchangeable family of
random variables X1, . . . , Xn that cannot be extended to an inﬁnite exchangeable
family X1, X2, . . .. ♣
12.2
Backwards Martingales
The concepts of ﬁltration and martingale do not require the index set I (interpreted
as time) to be a subset of [0, ∞). Hence we can consider the case I = −N0.
Deﬁnition 12.11 (Backwards martingale) Let F = (Fn)n∈−N0 be a ﬁltration. A
stochastic process X = (Xn)n∈N0 is called a backwards martingale with respect
to F if X = (X−n)n∈−N0 is an F-martingale.
Remark 12.12 A backwards martingale is always uniformly integrable. This fol-
lows from Corollary 8.22 and the fact that X−n = E[X0
F−n] for any n ∈N0.
♦
Example 12.13 Let X1, X2, . . . be exchangeable real random variables. For n ∈N,
let F−n = En and
Yn = 1
n
n

i=1
Xi.
We show that (Y−n)n∈N is an F-backwards martingale. Clearly, Y is adapted.
Furthermore, by Theorem 12.10 (with k = n and ϕ(X1, . . . , Xn) =
1
n−1(X1 +
. . . + Xn−1)),
E )Yn−1
F−n
* = 1
n!

ϱ∈S(n)
1
n −1
Xϱ(1) + . . . + Xϱ(n−1)
 = Yn.
Now replace F by the smaller ﬁltration G
=
(Gn)n∈−N that is deﬁned by
G−n = σ(Y−n, Xn+1, Xn+2, . . .) = σ(Y−n, Y−n−1, Y−n−2, . . .) for n ∈N. This
is the ﬁltration generated by Y; thus Y is also a G-backwards martingale (see
Remark 9.29). ♦
Let a < b and n ∈N. Let Ua,b
−n be the number of upcrossings of X over
[a, b] between times −n and 0. Further, let Ua,b = lim
n→∞Ua,b
−n . By the upcrossing
inequality (Lemma 11.3), we have E
)
Ua,b
−n
*
≤
1
b−aE
)
(X0 −a)+*
; hence P
)
Ua,b <
∞
*
= 1. As in the proof of the martingale convergence theorem (Theorem 11.4),
we infer the following.

264
12
Backwards Martingales and Exchangeability
Theorem 12.14 (Convergence theorem for
backwards
martingales)
Let
(Xn)n∈−N0 be a martingale with respect to F = (Fn)n∈−N0. Then there exists
X−∞= lim
n→∞X−n almost surely and in L1. Furthermore, X−∞= E[X0
F−∞],
where F−∞=
∞

n=1
F−n.
Example 12.15 Let X1, X2, . . . be exchangeable, integrable random variables.
Further, let T = ∞
n=1 σ(Xm, m ≥n) be the tail σ-algebra of X1, X2, . . . and
let E be the exchangeable σ-algebra. Then E[X1
T ] = E[X1
E] a.s. and
1
n
n

i=1
Xi
n→∞
−→E[X1
E]
a.s. and in L1.
Indeed, if we let Yn := 1
n
n
i=1
Xi, then (by Example 12.13) (Yn)n∈N is a backwards
martingale with respect to (Fn)n∈−N = (E−n)n∈−N and thus
Yn
n→∞
−→Y∞= E[X1
E]
a.s. and in L1.
Now, by Example 2.36(ii), Y∞is T -measurable; hence (since T ⊂E and by virtue
of the tower property of conditional expectation) Y∞= E[X1
T ]. ♦
Example 12.16 (Strong law of large numbers) If Z1, Z2, . . . are real and i.i.d. with
E[|Z1|] < ∞, then
1
n
n

i=1
Zi
n→∞
−→E[Z1]
almost surely.
By Kolmogorov’s 0-1 law (Theorem 2.37), the tail σ-algebra T is trivial; hence we
have
E[Z1
T ] = E[Z1]
almost surely.
In Corollary 12.19, we will see that in the case of independent random variables, E
is also P-trivial. This implies E[Z1
E] = E[Z1]. ♦
We close this section with a generalization of Example 12.15 to mean values of
functions of k ∈N variables. This conclusion from the convergence theorem for
backwards martingales will be used in an essential way in the next section.
Theorem 12.17 Let X = (Xn)n∈N be an exchangeable family of random variables
with values in E. Assume that k ∈N and let ϕ : Ek →R be measurable with
E[|ϕ(X1, . . . , Xk)|] < ∞. Denote ϕ(X) = ϕ(X1, . . . , Xk) and let An(ϕ) :=
1
n!

ϱ∈S(n) ϕ(Xϱ). Then

12.2
Backwards Martingales
265
E[ϕ(X)
E] = E[ϕ(X)
T ] = lim
n→∞An(ϕ)
a.s. and in L1.
(12.7)
Proof By Theorem 12.10, An(ϕ) = E[ϕ(X)
En]. Hence (An(ϕ))n≥k is a back-
wards martingale with respect to (E−n)n∈−N. Hence, by Theorem 12.14,
An(ϕ)
n→∞
−→E
)
ϕ(X)
E
*
a.s. and in L1.
(12.8)
As for the arithmetic mean (Example 12.16), we can argue that limn→∞An(ϕ) is
T -measurable. Indeed,
lim sup
n→∞
#
	
ϱ ∈S(n) : ϱ−1(i) ≤l for some i ∈{1, . . ., k}

n!
= 0
for all l ∈N.
Thus, for large n, the dependence of An(ϕ) on the ﬁrst l coordinates is negligible.
Together with (12.8), we get (12.7).
⊓⊔
Corollary 12.18 Let X = (Xn)n∈N be exchangeable. Then, for any A ∈E there
exists a B ∈T with P[A △B] = 0.
Note that T ⊂E; hence the statement is trivially true if the roles of E and T are
interchanged.
Proof Since E ⊂σ(X1, X2, . . .), by the approximation theorem for measures, there
exists a sequence of measurable sets (Ak)k∈N with Ak ∈σ(X1, . . . , Xk) and such
that P[A △Ak]
k→∞
−→0. Choose (kl)l∈N such that ∞
l=1 P[A △Akl] < ∞, hence
1Akl
l→∞
−→1A almost surely. Let Ck ⊂Ek be measurable with
Ak = {(X1, . . . , Xk) ∈Ck}
for all k ∈N. Letting ϕk := 1Ck, Theorem 12.17 implies that
1A = E[1A|E] = E
'
lim
l→∞ϕkl(X)
E
(
= lim
l→∞E[ϕkl(X)|E]
= lim
l→∞E[ϕkl(X)|T ] =: ψ
almost surely.
Hence there is a T -measurable function ψ with ψ = 1A almost surely. We can
assume that ψ = 1B for some B ∈T .
⊓⊔
As a further application, we get the 0-1 law of Hewitt and Savage [72].
Corollary 12.19 (0-1 law of Hewitt–Savage) Let X1, X2, . . . be i.i.d. random
variables. Then the exchangeable σ-algebra is P-trivial; that is, P[A] ∈{0, 1} for
all A ∈E.
Proof By Kolmogorov’s 0-1 law (Theorem 2.37), T is trivial. Hence the claim
follows immediately from Corollary 12.18.
⊓⊔

266
12
Backwards Martingales and Exchangeability
Takeaways A backwards martingale (Yn)n∈N0 is a stochastic process such
that (Y−m)m∈−N0 is a martingale. Backwards martingales are uniformly inte-
grable and converge almost surely and in L1. For functions of exchangeable
random variables X1, X2, . . ., averaging over all permutations of X1, . . . , Xn
deﬁnes a backwards martingale. As a consequence, the terminal σ-algebra and
the exchangeable σ-algebra coincide (mod P). In particular, for i.i.d. random
variables, the exchangeable σ-algebra is P-trivial.
12.3
De Finetti’s Theorem
In this section, we show the structural theorem for countably inﬁnite exchangeable
families that was heuristically motivated at the end of Sect. 12.1. Hence we shall
show that a countably inﬁnite exchangeable family of random variables is an
i.i.d. family given the exchangeable σ-algebra E. Furthermore, we compute the
conditional distribution of the individual random variables. As a ﬁrst step, we deﬁne
conditional independence formally (see [25, Chapter 7.3]).
Deﬁnition 12.20 (Conditional independence)
Let (Ω, F, P) be a probability
space, let A ⊂F be a sub-σ-algebra and let (Ai)i∈I be an arbitrary family of
sub-σ-algebras of F. Assume that for any ﬁnite J ⊂I, any choice of Aj ∈Aj and
for all j ∈J,
P
' 
j∈J
Aj
A
(
=

j∈J
P
)
Aj
A
*
almost surely.
(12.9)
Then the family (Ai)i∈I is called independent given A.
A family (Xi)i∈I of random variables on (Ω, F, P) is called independent
(and identically distributed) given A if the generated σ-algebras (σ(Xi))i∈I are
independent given A (and the conditional distributions P[Xi ∈· |A] are equal).
Example 12.21 Any family (Ai)i∈I of sub-σ-algebras of F is independent given
F. Indeed, letting A = 
j∈J Aj,
P[A|F] = 1A =

j∈J
1Aj =

j∈J
P )Aj
F*
almost surely.
♦
Example 12.22 If (Ai)i∈I is an independent family of σ-algebras and if A is trivial,
then (Ai)i∈I is independent given A. ♦
Example 12.23 There is no “monotonicity” for conditional independence in the
following sense: If F1, F2 and F3 are σ-algebras with F1 ⊂F2 ⊂F3 and such

12.3
De Finetti’s Theorem
267
that (Ai)i∈I is independent given F1 as well as given F3, then this does not imply
independence given F2.
In order to illustrate this, assume that X and Y are nontrivial independent real
random variables. Let F1 = {∅, Ω}, F2 = σ(X + Y) and F3 = σ(X, Y). Then
σ(X) and σ(Y) are independent given F1 as well as given F3 but not given F2. ♦
Let X = (Xn)n∈N be a stochastic process on a probability space (Ω, F, P) with
values in a Polish space E. Let E be the exchangeable σ-algebra and let T be the
tail σ-algebra.
Theorem 12.24 (de Finetti) The family X = (Xn)n∈N is exchangeable if and only
if there exists a σ-algebra A ⊂F such that (Xn)n∈N is i.i.d. given A. In this case,
A can be chosen to equal the exchangeable σ-algebra E or the tail-σ-algebra T .
Proof “ ⇒”
Let X be exchangeable and let A = E or A = T . For any n ∈N,
let fn : E →R be a bounded measurable map. Let
ϕk(x1, . . . , xk) =
k
i=1
fi(xi)
for any k ∈N.
Let An(ϕ) be the symmetrized average from Theorem 12.17. Then
An(ϕk−1)An(fk) = 1
n!

ϱ∈S(n)
ϕk−1(Xϱ) 1
n
n

i=1
fk(Xi)
= 1
n!

ϱ∈S(n)
ϕk(Xϱ) + Rn,k = An(ϕk) + Rn,k,
where
Rn,k
 ≤2
;;ϕk−1
;;
∞·
;;fk
;;
∞· 1
n!
1
n

ϱ∈S(n)
n

i=1
1{i∈{ϱ(1),...,ϱ(k−1)}}
= 2
;;ϕk−1
;;
∞·
;;fk
;;
∞· k −1
n
n→∞
−→0.
Together with Theorem 12.17, we conclude that
An(ϕk−1) An(fk)
n→∞
−→E
)
ϕk(X1, . . . , Xk)
A
*
a.s. and in L1.
On the other hand, again by Theorem 12.17,
An(ϕk−1)
n→∞
−→E
)
ϕk−1 (X1, . . . , Xk−1)
A
*

268
12
Backwards Martingales and Exchangeability
and
An(fk)
n→∞
−→E
)
fk(X1)
A
*
.
Hence
E
)
ϕk(X1, . . . , Xk)
A
*
= E
)
ϕk−1(X1, . . . , Xk−1)
A
*
E
)
fk(X1)
A
*
.
Thus we get inductively
E
- k
i=1
fi(Xi)
A
.
=
k
i=1
E
)
fi(X1)
A
*
.
Therefore, X is i.i.d. given A.
“ ⇐ ”
Now let X be i.i.d. given A for a suitable σ-algebra A ⊂F. For any
bounded measurable function ϕ : En →R and for any ϱ ∈S(n), we have
E[ϕ(X)
A] = E[ϕ(Xϱ)
A]. Hence
E[ϕ(X)] = E
)
E[ϕ(X)
A]
*
= E
)
E[ϕ(Xϱ)
A]
*
= E[ϕ(Xϱ)],
whence X is exchangeable.
⊓⊔
Denote by M1(E) the set of probability measures on E equipped with the
topology of weak convergence (see Deﬁnition 13.12 and Remark 13.14). That is,
a sequence (μn)n∈N in M1(E) converges weakly to a μ ∈M1(E) if and only
if 3 f dμn
n→∞
−→
3 f dμ for any bounded continuous function f : E →R.
We will study weak convergence in Chap. 13 in greater detail. At this point, we
use the topology only to make M1(E) a measurable space, namely with the
Borel σ-algebra B(M1(E)). Now we can study random variables with values in
M1(E), so-called random measures (compare also Sect. 24.1). For x ∈EN, let
ξn(x) = 1
n
n
i=1 δxi ∈M1(E).
Deﬁnition 12.25 The random measure
Ξn := ξn(X) := 1
n
n

i=1
δXi
is called the empirical distribution of X1, . . . , Xn.
Assume the conditions of Theorem 12.24 are in force.
Theorem 12.26 (de Finetti representation theorem) The family X = (Xn)n∈N
is exchangeable if and only if there is a σ-algebra A ⊂F and an A-measurable
random variable Ξ∞: Ω →M1(E) with the property that given Ξ∞, (Xn)n∈N is
i.i.d. with L[X1|Ξ∞] = Ξ∞. In this case, we can choose A = E or A = T .

12.3
De Finetti’s Theorem
269
Proof “ ⇐ ”
This follows as in the proof of Theorem 12.24.
“ ⇒”
Let X be exchangeable. Then, by Theorem 12.24, there exists a σ-algebra
A ⊂F such that (Xn)n∈N is i.i.d. given A. As E is Polish, there exists a regular
conditional distribution (see Theorem 8.37) Ξ∞:= L[X1
A]. For measurable
A1, . . . , An ⊂E, we have P[Xi ∈Ai |A] = Ξ∞(Ai) for all i = 1, . . . , n; hence
P
+ n

i=1
{Xi ∈Ai}
Ξ∞
,
= E
+
P
+
n

i=1
{Xi ∈Ai}
A
,Ξ∞
,
= E
+
n

i=1
Ξ∞(Ai)
Ξ∞
,
=
n

i=1
Ξ∞(Ai).
Therefore, L[X|Ξ∞] = Ξ⊗N
∞.
⊓⊔
Remark 12.27
(i) In the case considered in the previous theorem, by the strong law of large
numbers, for any bounded continuous function f : E →R,

f dΞn
n→∞
−→

f dΞ∞
almost surely.
If in addition E is locally compact (e.g., E = Rd), then one can even show that
Ξn
n→∞
−→Ξ∞
almost surely.
(ii) For ﬁnite families of random variables there is no perfect analog of de Finetti’s
theorem. See [33] for a detailed treatment of ﬁnite exchangeable families. ♦
Example 12.28 Let (Xn)n∈N be exchangeable and assume Xn ∈{0, 1}. Then there
exists a random variable Y : Ω →[0, 1] such that, for all ﬁnite J ⊂N,
P
)
Xj = 1 for all j ∈J
Y
*
= Y #J.
In other words, (Xn)n∈N is independent given Y and BerY -distributed. Compare
Example 12.3(iii). ♦
Example 12.29 (Pólya’s urn model) (See Example 14.41, compare also [17, 135]
and [58].) Consider an urn with a total of N balls among which M are black and
M −N are white. At each step, a ball is drawn and is returned to the urn together
with an additional ball of the same color. Let
Xn :=

1,
if the nth ball is black,
0,
else,

270
12
Backwards Martingales and Exchangeability
and let Sn = n
i=1 Xi. Then
P
)
Xn = 1
X1, X2, . . . , Xn−1
*
= Sn−1 + M
N + n −1.
Inductively, for x1, . . . , xn ∈{0, 1} and sk = k
i=1 xi, we get
P)Xi = xi for any i = 1, . . . , n*
=

i≤n: xi=1
M + si−1
N + i −1

i≤n: xi=0
N + i −1 −M −si−1
N + i −1
=
(N −1)!
(N −1 + n)! · (M + sn −1)!
(M −1)!

N −M −1 + (n −sn)

!
(N −M −1)!
.
The right-hand side depends on sn only and not on the order of the x1, . . . , xn.
Hence (Xn)n∈N is exchangeable. Let Z = lim
n→∞
1
nSn. Then (Xn)n∈N is i.i.d. BerZ-
distributed given Z. Hence (see Example 12.28)
E
)
Zn*
= E
)
P
)
X1 = · · · = Xn = 1
Z
**
= P [Sn = n]
= (N −1)!
(M −1)!
(M + n −1)!
(N + n −1)!
for all n ∈N.
By Exercise 5.1.3, these are the moments of the Beta distribution βM,N−M on [0, 1]
with parameters (M, N −M) (see Example 1.107(ii)). A distribution on [0, 1] is
uniquely characterized by its moments (see Theorem 15.4). Hence Z ∼βM,N−M.
♦
Takeaways Consider a two-step random experiment where in the ﬁrst step
we choose a probability measure Ξ∞on some space E. In the second step,
we draw i.i.d. random variables X1, X2, . . . with distribution Ξ∞. Then the
sequence X1, X2, . . . is exchangeable. Now, de Finetti’s theorem states that
any inﬁnite and exchangeable family can be constructed in this way and
that Ξ∞is measurable with respect to the exchangeable σ-algebra. For ﬁnite
families, this is not true.

12.3
De Finetti’s Theorem
271
Exercise 12.3.1 Let (Xn)n∈Z be an exchangeable family of {0, 1}-valued random
variables.
(i) Show that the distribution of (Xn)n∈Z is uniquely determined by the values
mn := E[X1 · X2 · · · Xn],
n ∈N.
(ii) Conclude that for any random variable Y on [0, 1], the distribution is uniquely
determined by its moments mn := E[Y n], n ∈N. ♣

Chapter 13
Convergence of Measures
One focus of probability theory is distributions that are the result of an interplay of
a large number of random impacts. Often a useful approximation can be obtained
by taking a limit of such distributions, for example, a limit where the number of
impacts goes to inﬁnity. With the Poisson distribution, we have encountered such
a limit distribution that occurs as the number of very rare events when the number
of possibilities goes to inﬁnity (see Theorem 3.7). In many cases, it is necessary
to rescale the original distributions in order to capture the behavior of the essential
ﬂuctuations, e.g., in the central limit theorem. While these theorems work with real
random variables, we will also see limit theorems where the random variables take
values in more general spaces such as the space of continuous functions when we
model the path of the random motion of a particle.
In this chapter, we provide the abstract framework for the investigation of con-
vergence of measures. We introduce the notion of weak convergence of probability
measures on general (mostly Polish) spaces and derive the fundamental properties.
The reader will proﬁt from a solid knowledge of point set topology. Thus we start
with a short overview of some topological deﬁnitions and theorems.
We do not strive for the greatest generality but rather content ourselves with the
key theorems for probability theory. For further reading, we recommend [14] and
[82].
At ﬁrst reading, the reader might wish to skip this rather analytically ﬂavored
chapter. In this case, for the time being it sufﬁces to get acquainted with the
deﬁnitions of weak convergence and tightness (Deﬁnitions 13.12 and 13.26), as
well as with the statements of the Portemanteau theorem (Theorem 13.16) and
Prohorov’s theorem (Theorem 13.29).
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_13
273

274
13
Convergence of Measures
13.1
A Topology Primer
Excursively, we present some deﬁnitions and facts from point set topology. For
details, see, e.g., [90].
In the following, let (E, τ) be a topological space with the Borel σ-algebra E =
B(E) (compare Deﬁnitions 1.20 and 1.21). We will also assume that (E, τ) is a
Hausdorff space; that is, for any two points x, y ∈E with x ̸= y, there exist
disjoint open sets U, V such that x ∈U and y ∈V .
For A ⊂E, we denote by A the closure of A, by A◦the interior and by ∂A the
boundary of A. A set A ⊂E is called dense if A = E.
(E, τ) is called metrizable if there exists a metric d on E such that τ is induced
by the open balls Bε(x) := {y ∈E : d(x, y) < ε}. A metric d on E is called
complete if any Cauchy sequence with respect to d converges in E. (E, τ) is called
completely metrizable if there exists a complete metric on E that induces τ. If
(E, d) is a metric space and A, B ⊂E, then we write d(A, B) = inf{d(x, y) : x ∈
A, y ∈B} and d(x, B) := d({x}, B) for x ∈E.
A metrizable space (E, τ) is called separable if there exists a countable dense
subset of E. Separability in metrizable spaces is equivalent to the existence of
a countable base of the topology; that is, a countable set U ⊂τ with A =

U∈U: U⊂A U for all A ∈τ. (For example, choose the ε-balls centered at the
points of a countable subset and let ε run through the positive rational numbers.)
A compact metric space is always separable (simply choose for each n ∈N a ﬁnite
cover Un ⊂τ comprising balls of radius 1
n and then take U := 
n∈N Un).
A set A ⊂E is called compact if each open cover U ⊂τ of A (that is,
A ⊂
U∈U U) has a ﬁnite subcover; that is, a ﬁnite U′ ⊂U with A ⊂
U∈U′ U.
Compact sets are closed. By the Heine–Borel theorem, a subset of Rd is compact
if and only if it is bounded and closed. A ⊂E is called relatively compact if
A is compact. On the other hand, A is called sequentially compact (respectively
relatively sequentially compact) if any sequence (xn)n∈N with values in A has
a subsequence (xnk)k∈N that converges to some x ∈A (respectively x ∈A). In
metrizable spaces, the notions compact and sequentially compact coincide. A set
A ⊂E is called σ-compact if A is a countable union of compact sets. E is called
locally compact if any point x ∈E has an open neighborhood whose closure
is compact. A locally compact, separable metric space is manifestly σ-compact
and there even exists a countable basis U′ of the topology consisting of relatively
compact open sets. (In fact: Choose an arbitrary countable base U of the topology.
For any x ∈E, there exists a relatively compact neighborhood Bx ∋x. Each Bx is a
union of elements of U each of which is then also relatively compact. Hence, there
exists a relatively compact Ux ∈U with x ∈Ux. Now let U′ := {Ux : x ∈E} ⊂U.)
If E is a locally compact metric space and if U ⊂E is open and K ⊂U is
compact, then there exists a compact set L with K ⊂L◦⊂L ⊂U. (For example,
for any x ∈K, take an open ball Bεx(x) of radius εx > 0 that is contained in U
and that is relatively compact. By making εx smaller (if necessary), one can assume
that the closure of this ball is contained in U. As K is compact, there are ﬁnitely

13.1
A Topology Primer
275
many points x1, . . . , xn ∈K with K ⊂V := n
i=1 Bεxi (xi). By construction,
L = V ⊂U is compact.) Specializing on the case U = E, we get that for any
compact set K, there exists a relatively compact open set L◦⊃K.
We present one type of topological space that is of particular importance in
probability theory in a separate deﬁnition.
Deﬁnition 13.1 A topological space (E, τ) is called a Polish space if it is separable
and if there exists a complete metric that induces the topology τ.
Examples of Polish spaces are countable discrete spaces (however, not Q with
the usual topology), the Euclidean spaces Rn, and the space C([0, 1]) of continuous
functions [0, 1] →R, equipped with the supremum norm ∥· ∥∞. In practice, all
spaces that are of importance in probability theory are Polish spaces.
Let (E, d) be a metric space. A set A ⊂E is called totally bounded if, for any
ε > 0, there exist ﬁnitely many points x1, . . . , xn ∈A such that A ⊂
n

i=1
Bε(xi).
Evidently, compact sets are totally bounded. In Polish spaces, a partial converse is
true.
Lemma 13.2 Let (E, τ) be a Polish space with complete metric d. A subset A ⊂E
is totally bounded with respect to d if and only if A is relatively compact.
Proof This is left as an exercise.
⊓⊔
In the following, let (E, τ) be a topological space with Borel σ-algebra E =
B(E) := σ(τ) and with complete metric d. For measures on (E, E), we introduce
the following notions of regularity.
Deﬁnition 13.3 A σ-ﬁnite measure μ on (E, E) is called
(i) locally ﬁnite or a Borel measure if, for any point x ∈E, there exists an open
neighborhood U ∋x such that μ(U) < ∞,
(ii) inner regular if
μ(A) = sup
	
μ(K) : K ⊂A is compact

for all A ∈E,
(13.1)
(iii) outer regular if
μ(A) = inf
	
μ(U) : U ⊃A is open

for all A ∈E,
(13.2)
(iv) regular if μ is inner and outer regular, and
(v) a Radon measure if μ is an inner regular Borel measure.

276
13
Convergence of Measures
Deﬁnition 13.4 We introduce the following spaces of measures on E:
M(E) := 	Radon measures on (E, E)
,
Mf (E) :=
	
ﬁnite measures on (E, E)

,
M1(E) :=
	
μ ∈Mf (E) : μ(E) = 1

,
M≤1(E) := 	μ ∈Mf (E) : μ(E) ≤1
.
The elements of M≤1(E) are called sub-probability measures on E.
Further, we agree on the following notation for spaces of continuous functions:
C(E) :=
	
f : E →R is continuous

,
Cb(E) := 	f ∈C(E) is bounded
,
Cc(E) :=
	
f ∈C(E) has compact support

⊂Cb(E).
Recall that the support of a real function f is f −1(R \ {0}).
Unless otherwise stated, the vector spaces C(E), Cb(E) and Cc(E) are equipped
with the supremum norm.
Lemma 13.5 If E is Polish and μ ∈Mf (E), then for any ε > 0, there is a compact
set K ⊂E with μ(E \ K) < ε.
Proof Let ε > 0. For each n ∈N, there exists a sequence xn
1, xn
2, . . . ∈E with
E =
∞

i=1
B1/n(xn
i ). Fix Nn ∈N such that μ

E \
Nn

i=1
B1/n

xn
i
 
< ε
2n . Deﬁne
A :=
∞

n=1
Nn

i=1
B1/n

xn
i

.
By construction, A is totally bounded. Since E is Polish, A is compact. Furthermore,
it follows that μE \ A ≤μE \ A <
∞

n=1
ε 2−n = ε.
⊓⊔
Theorem 13.6 If E is Polish and if μ ∈Mf (E), then μ is regular. In particular,
in this case, Mf (E) ⊂M(E).
Proof (Outer regularity)
Step 1. Let B ⊂E be closed and let ε > 0. Let d be a complete metric on E. For
δ > 0, let
Bδ := 	x ∈E : d(x, B) < δ

13.1
A Topology Primer
277
be the open δ-neighborhood of B. As B is closed, we have 
δ>0 Bδ = B. Since μ is
upper semicontinuous (Theorem 1.36), there is a δ > 0 such that μ(Bδ) ≤μ(B)+ε.
Step 2. Let B ∈E and ε > 0. Consider the class of sets
A :=
	
V ∩C : V ⊂E open, C ⊂E closed

.
Clearly, we have E = σ(A). It is easy to check that A is a semiring. Hence by the
approximation theorem for measures (Theorem 1.65), there are mutually disjoint
sets An = Vn ∩Cn ∈A, n ∈N, such that B ⊂A := ∞
n=1 An and μ(A) ≤
μ(B)+ε/2. As shown in the ﬁrst step, for any n ∈N, there is an open set Wn ⊃Cn
such that μ(Wn) ≤μ(Cn) + ε 2−n−1. Hence also Un := Vn ∩Wn is open. Let
B ⊂U := ∞
n=1 Un. We conclude that μ(U) ≤μ(A)+∞
n=1 ε 2−n−1 ≤μ(B)+ε.
Inner regularity Replacing B by Bc, the outer regularity yields the existence of a
closed set D ⊂B with μ(B \ D) < ε/2. By Lemma 13.5, there exists a compact
set K with μ(Kc) < ε/2. Deﬁne C = D ∩K. Then C ⊂B is compact and
μ(B \ C) < ε. Hence μ is also inner regular.
⊓⊔
Corollary 13.7 The Lebesgue measure λ on Rd is a regular Radon measure.
However, not all σ-ﬁnite measures on Rd are regular.
Proof Clearly, Rd is Polish and λ is locally ﬁnite. Let A ∈B(Rd) and ε > 0. There
is an increasing sequence (Kn)n∈N of compact sets with Kn ↑Rd. Since any Kn is
bounded, we have λ(Kn) < ∞. Hence, by the preceding theorem, for any n ∈N,
there exists an open set Un ⊃A ∩Kn with λ(Un \ A) < ε/2n. Thus λ(U \ A) < ε
for the open set U := 
n∈N Un.
If λ(A) < ∞, then there exists an n ∈N with λ(A\Kn) < ε/2. By the preceding
theorem, there exists a compact set C ⊂A ∩Kn with λ((A ∩Kn) \ C) < ε/2.
Therefore, λ(A \ C) < ε.
If, on the other hand, λ(A) = ∞, then for any L > 0, we have to ﬁnd a compact
set C ⊂A with λ(C) > L. However, λ(A ∩Kn)
n→∞
−→∞; hence there exists an
n ∈N with λ(A ∩Kn) > L + 1. By what we have shown already, there exists a
compact set C ⊂A ∩Kn with λ((A ∩Kn) \ C) < 1; hence λ(C) > L.
Finally, consider the measure μ = 
q∈Q δq. Clearly, this measure is σ-ﬁnite;
however, it is neither locally ﬁnite nor outer regular.
⊓⊔
Deﬁnition 13.8 Let (E, dE) and (F, dF ) be metric spaces. A function f : E →F
is called Lipschitz continuous if there exists a constant K < ∞, the so-called
Lipschitz constant, with dF (f (x), f (y)) ≤K · dE(x, y) for all x, y ∈E. Denote
by LipK(E; F) the space of Lipschitz continuous functions with constant K and
by Lip(E; F) = 
K>0 LipK(E; F) the space of Lipschitz continuous functions
on E.
We abbreviate LipK(E) := LipK(E; R) and Lip(E) := Lip(E; R).
Deﬁnition 13.9 Let F ⊂M(E) be a family of Radon measures. A family C of
measurable maps E →R is called a separating family for F if, for any two

278
13
Convergence of Measures
measures μ, ν ∈F, the following holds:

f dμ =

f dν
for all f ∈C ∩L1(μ) ∩L1(ν)

⇒
μ = ν.
Lemma 13.10 Let (E, d) be a metric space. For any closed set A ⊂E and any
ε > 0, there is a Lipschitz continuous map ρA,ε : E →[0, 1] with Lipschitz constant
1/ε and
ρA,ε(x) =

1,
if x ∈A,
0,
if d(x, A) ≥ε.
Proof Let ϕ : R →[0, 1], t →(t ∨0) ∧1. For x ∈E, deﬁne ρA,ε(x) =
1 −ϕ

ε−1d(x, A)

.
⊓⊔
Theorem 13.11 Let (E, d) be a metric space.
(i). Lip1(E; [0, 1]) is separating for Mf (E) and for M(E).
(ii). If, in addition, E is locally compact, then Cc(E)∩Lip1(E; [0, 1]) is separating
for M(E).
Proof (i)
Case Mf (E). Let μ1, μ2 ∈Mf (E) be such that
3
f dμ1 =
3
f dμ2
for all f ∈Lip1(E; [0, 1]). It is enough to show that μ1(C) = μ2(C) for all closed
sets C ⊂E as the closed sets form a ∩-stable generator of the Borel σ-algebra
that contains E. Since μ1 and μ2 are ﬁnite measures, for the function ρC,ε from
Lemma 13.10, we have
0 ≤ρC,ε ≤1 ∈L1(μi),
i = 1, 2,
for all ε > 0.
Note that ρC,ε
ε→0
−→1C. Hence by the dominated convergence theorem (Corol-
lary 6.26), we have μi(C) = limε→0
3
ρC,ε dμi. For any ε ∈(0, 1], we have
ερC,ε ∈Lip1(E; [0, 1]). We conclude that

ρC,ε dμ1 = ε−1

(ερC,ε) dμ1 = ε−1

(ερC,ε) dμ2 =

ρC,ε dμ2.
This implies μ1(C) = μ2(C); hence μ1 = μ2.
(i) Case M(E).
In contrast to the case Mf (E), the function 1 is not integrable.
Hence, we modify the approach by showing that it is enough to consider compact
sets K instead of C and by showing that there exists an open set U ⊃K and a δ > 0
such that
ρK,ε ≤1U ∈L1(μi),
i = 1, 2
for all ε ∈(0, δ).
(13.3)
Arguing as above, this will show that μ1(K) = μ2(K) and will hence conclude the
proof.

13.1
A Topology Primer
279
Here come the details. Assume μ1, μ2 ∈M(E) are measures with
3
f dμ1 =
3
f dμ2 for all f ∈Lip1(E; [0, 1]). If A ∈E, then
μi(A) = sup 	μi(K) : K ⊂A is compact
since the Radon measure μi is inner regular (i = 1, 2). Hence, it is enough to show
that μ1(K) = μ2(K) for any compact set K.
Now let K ⊂E be compact. Since μ1 and μ2 are locally ﬁnite, for every x ∈K,
there exists an open set Ux ∋x with μ1(Ux) < ∞and μ2(Ux) < ∞. Since K is
compact, we can ﬁnd ﬁnitely many points x1, . . . , xn ∈K such that K ⊂U :=
n
j=1 Uxj . By construction, μi(U) < ∞; hence 1U ∈L1(μi) for i = 1, 2. Since
Uc is closed and since Uc ∩K = ∅, we get δ := d(Uc, K) > 0. Let ρK,ε be the
map from Lemma 13.10. By construction, equation (13.3) holds and the proof is
complete. (ii)
If E is locally compact, then in ((i)) we can choose the neighborhoods Ux to be
relatively compact. Hence U is relatively compact; thus ρK,ε has compact support
and is thus in Cc(E) for all ε ∈(0, δ).
⊓⊔
Takeaways A Polish space is a separable topological space that allows for
a complete metric, e.g., the euclidian space Rd. Polish spaces are standard
spaces of measure theory and probability theory. Radon measures are inner
regular Borel measures (locally ﬁnite measures). Finite measures on Polish
spaces are Radon measures. The class of Lipschitz-continuous functions is
a separating family for ﬁnite measures and for Radon measures. On locally
compact spaces, also Lipschitz continuous functions with compact support
form a separating class.
Exercise 13.1.1
(i) Show that C([0, 1]) has a separable dense subset.
(ii) Show that the space (Cb([0, ∞)), ∥· ∥∞) of bounded continuous functions,
equipped with the supremum norm, is not separable.
(iii) Show that the space Cc([0, ∞)) of continuous functions with compact support,
equipped with the supremum norm, is separable. ♣
Exercise 13.1.2 Let μ be a locally ﬁnite measure. Show that μ(K) < ∞for any
compact set K. ♣
Exercise 13.1.3 (Lusin’s theorem)
Let Ω be a Polish space, let μ be a ﬁnite
measure on (Ω, B(Ω)) and let f : Ω →R be a map. Show that the following
two statements are equivalent:
(i) There is a Borel measurable map g : Ω →R with f
= g
μ-almost
everywhere.

280
13
Convergence of Measures
(ii) For any ε > 0, there is a compact set Kε with μ(Ω \ Kε) < ε such that the
restricted function f 
Kε is continuous. ♣
Exercise 13.1.4 Let U be a family of intervals in R such that W := 
U∈U U has
ﬁnite Lebesgue measure λ(W). Show that for any ε > 0, there exist ﬁnitely many
pairwise disjoint sets U1, . . . , Un ∈U with
n

i=1
λ(Ui) > 1 −ε
3
λ(W).
Hint: Choose a ﬁnite family U′ ⊂U such that 
U∈U′ U has Lebesgue measure at
least (1 −ε)λ(W). Choose a maximal sequence U′′ (sorted by decreasing lengths)
of disjoint intervals and show that each U ∈U′ is in (x −3a, x + 3a) for some
(x −a, x + a) ∈U′′. ♣
Exercise 13.1.5 Let C ⊂Rd be an open, bounded and convex set and assume that
U ⊂{x + rC : x ∈Rd, r > 0} is such that W := 
U∈U U has ﬁnite Lebesgue
measure λd(W). Show that for any ε > 0, there exist ﬁnitely many pairwise disjoint
sets U1, . . . , Un ∈U such that
n

i=1
λd(Ui) > 1 −ε
3d
λ(W).
Show by a counterexample that the condition of similarity of the open sets in U is
essential. ♣
Exercise 13.1.6 Let μ be a Radon measure on Rd and let A ∈B(Rd) be a μ-null
set. Let C ⊂Rd be bounded, convex and open with 0 ∈C. Use Exercise 13.1.5 to
show that
lim
r↓0
μ(x + rC)
rd
= 0
for λd -almost all x ∈A.
Conclude that if F is the distribution function of a Stieltjes measure μ on R and if
A ∈B(R) is a μ-null set, then d
dx F(x) = 0 for λ -almost all x ∈A. ♣
Exercise 13.1.7 (Fundamental theorem of calculus) (Compare [37].) Let f ∈
L1(Rd), μ = f λd and let C ⊂Rd be open, convex and bounded with 0 ∈C. Show
that
lim
r↓0
μ(x + rC)
rd λd(C)
= f (x)
for λd -almost all x ∈Rd.
For the case d = 1, conclude the fundamental theorem of calculus:
d
dx

[0,x]
f dλ = f (x)
for λ -almost all x ∈R.

13.2
Weak and Vague Convergence
281
Hint: Use Exercise 13.1.6 with μq(dx) = (f (x) −q)+λd(dx) for q ∈Q, as well
as the inequality
μ(x + rC)
rd λd(C)
≤q + μq(x + rC)
rd λd(C) .
♣
Exercise 13.1.8 Similarly as in Corollary 13.7, show the following: Let E be a σ-
compact polish space and let μ be a measure on E. Then μ is a Radon measure if
and only if μ(K) < ∞for any compact K ⊂E. ♣
Exercise 13.1.9 Show that the set of rationals Q (with the standard topology) is not
a Polish space. To this end, ﬁll in the details in the following sketch.
We assume that d is a metric on Q that induces the standard topology and such
that (Q, d) is complete. We aim at a contradiction.
Let q1, q2, . . . be an arbitrary enumeration of Q. Choose r1 ∈Q and ε1 > 0 such
that q1 ̸∈Bε1(r1). Now choose successively ri+1 ∈Bεi/2(ri) and εi+1 ∈(0, εi/2)
such that qi+1 ̸∈Bεi+1(ri+1). As d is complete, there is an x ∈Q with {x} =
∞
i=1 Bεi(ri). On the other hand, by construction, we have qk ̸∈∞
i=1 Bεi(ri) for
all k ∈N. ♣
13.2
Weak and Vague Convergence
In Theorem 13.11, we saw that integrals of bounded continuous functions f
determine a Radon measure on a metric space (E, d). If E is locally compact,
it is enough to consider f with compact support. This suggests that we can use
Cb(E) and Cc(E) as classes of test functions in order to deﬁne the convergence of
measures.
Deﬁnition 13.12 (Weak and vague convergence)
Let E be a metric space.
(i) Let μ, μ1, μ2, . . . ∈Mf (E). We say that (μn)n∈N converges weakly to μ,
formally μn
n→∞
−→μ (weakly) or μ = w-lim
n→∞μn, if

f dμn
n→∞
−→

f dμ
for all f ∈Cb(E).
(ii) Let μ, μ1, μ2, . . . ∈M(E). We say that (μn)n∈N converges vaguely to μ,
formally μn
n→∞
−→μ (vaguely) or μ = v-lim
n→∞μn, if

f dμn
n→∞
−→

f dμ
for any f ∈Cc(E).

282
13
Convergence of Measures
Remark 13.13 By Theorem 13.11, the weak limit is unique. By Theorems 13.6
and 13.11, the same holds for the vague limit if E is Polish and locally compact.
♦
Remark 13.14
(i) In functional analysis the notion of weak convergence is somewhat different.
Starting from a normed vector space X (here the space of ﬁnite signed mea-
sures with the total variation norm), consider the space X′ of continuous linear
functionals X →R. The sequence (μn) in X converges weakly to μ ∈X, if
Φ(μn)
n→∞
−→Φ(μ) for every Φ ∈X′. In the case of ﬁnite signed measures this
is equivalent to: (μn) is bounded and μn(A)
n→∞
−→μ(A) for any measurable
A (see [38, Theorem IV.9.5]). Comparing this to Theorem 13.16(vi), we see
that the functional analysis notion of weak convergence is stronger than ours
in Deﬁnition 13.12.
(ii) Weak convergence (as introduced in Deﬁnition 13.12) induces on Mf (E) the
weak topology τw. This is the coarsest topology such that for all f ∈Cb(E),
the map Mf (E) →R, μ →3 f dμ is continuous. In functional analysis,
τw corresponds to the so-called weak∗-topology. Starting from a normed
vector space X (here X = Cb(E) with the norm ∥· ∥∞), we deﬁne the
weak∗-topology on the dual space X′ by writing μn
n→∞
−→μ if and only if
μn(x)
n→∞
−→μ(x) for all x ∈X. Clearly, each μ deﬁnes a continuous linear
form on Cb(E) by f →μ(f ) :=
3
f dμ. Hence Mf (E) ⊂Cb(E)′. This
implies that τw is the trace of the weak∗-topology on Mf (E).
(iii) If E is separable, then it can be shown that (Mf (E), τw) is metrizable; for
example, by virtue of the so-called Prohorov metric. This is deﬁned by
dP (μ, ν) := max{d′
P (μ, ν), d′
P (ν, μ)},
(13.4)
where
d′
P (μ, ν) := inf{ε > 0 : μ(B) ≤ν(Bε) + ε for any B ∈B(E)},
(13.5)
and where Bε = {x : d(x, B) < ε}; see, e.g., [14, Appendix III, Theorem 5].
(It can be shown that d′
P (μ, ν) = d′
P(ν, μ) if μ, ν ∈M1(E).) If E is locally
compact and Polish, then (Mf (E), τw) is again Polish (see [136, page 167]).
(iv) Similarly, the vague topology τv on M(E) is the coarsest topology such that
for all f ∈Cc(E), the map M(E) →R, μ →
3
f dμ is continuous. If E
is locally compact, then (M(E), τv) is a Hausdorff space. If, in addition, E is
Polish, then (M(E), τv) is again Polish (see, e.g., [82, Section 15.7]). ♦
While weak convergence implies convergence of the total masses (since 1 ∈
Cb(E)), with vague convergence a mass defect (but not a mass gain) can be
experienced in the limit.

13.2
Weak and Vague Convergence
283
Lemma 13.15 Let E be a locally compact Polish space and let μ, μ1, μ2, . . . ∈
M(E) be measures such that μn
n→∞
−→μ vaguely. Then
μ(E) ≤lim inf
n→∞μn(E).
Proof Let (fN)N∈N be a sequence in Cc(E; [0, 1]) with fN ↑1. Then
μ(E) = sup
N∈N

fN dμ
= sup
N∈N
lim
n→∞

fN dμn
≤lim inf
n→∞
sup
N∈N

fN dμn
= lim inf
n→∞μn(E).
⊓⊔
Clearly, the sequence (δ1/n)n∈N of probability measures on R converges weakly
to δ0; however, not in total variation norm. Indeed, for the closed set (−∞, 0], we
have limn→∞δ1/n((−∞, 0]) = 0 < 1 = δ0((−∞, 0]). Loosely speaking, at the
boundaries of closed sets, mass can immigrate but not emigrate. The opposite is
true for open sets: limn→∞δ1/n((0, ∞)) = 1 > 0 = δ0((0, ∞)). Here mass can
emigrate but not immigrate. In fact, weak convergence can be characterized by this
property. In the following theorem, a whole bunch of such statements will be hung
on a coat hanger (French: portemanteau).
For measurable g : Ω →R, let Ug be the set of points of discontinuity of g.
Recall from Exercise 1.1.3 that Ug is Borel measurable.
Theorem 13.16 (Portemanteau) Let E be a metric space and let μ, μ1, μ2, . . . ∈
M≤1(E). The following are equivalent.
(i) μ = w-lim
n→∞μn.
(ii)
3
f dμn
n→∞
−→
3
f dμ for all bounded Lipschitz continuous f .
(iii)
3
f dμn
n→∞
−→
3
f dμ for all bounded measurable f with μ(Uf ) = 0.
(iv) lim inf
n→∞μn(E) ≥μ(E) and lim sup
n→∞
μn(F) ≤μ(F) for all closed F ⊂E.
(v) lim sup
n→∞
μn(E) ≤μ(E) and lim inf
n→∞μn(G) ≥μ(G) for all open G ⊂E.
(vi)
lim
n→∞μn(A) = μ(A) for all measurable A with μ(∂A) = 0.
If E is locally compact and Polish, then in addition each of the following is
equivalent to the previous statements.
(vii) μ = v-lim
n→∞μn and μ(E) = lim
n→∞μn(E).
(viii) μ = v-lim
n→∞μn and μ(E) ≥lim sup
n→∞
μn(E).

284
13
Convergence of Measures
Proof “(iv) ⇐⇒(v) ⇒(vi)”
This is trivial.
“(iii) ⇒(i) ⇒(ii)”
This is trivial.
“(ii) ⇒(iv)”
Convergence of the total masses follows by using the test function
1 ∈Lip(E; [0, 1]). Let F be closed and let ρF,ε be as in Lemma 13.10. Then
lim sup
n→∞
μn(F) ≤inf
ε>0 lim
n→∞

ρF,ε dμn = inf
ε>0

ρF,ε dμ = μ(F)
since ρF,ε(x)
ε→0
−→1F(x) for all x ∈E.
“(viii) ⇒(vii)”
This is obvious by Lemma 13.15.
“(i) ⇒(vii)”
This is clear since Cc(E) ⊂Cb(E) and 1 ∈Cb(E).
“(vii) ⇒
(v)”
Let G be open and ε > 0. Since μ is inner regular (Theo-
rem 13.6), there is a compact set K ⊂G with μ(G) −μ(K) < ε. As E is locally
compact, there is a compact set L with K ⊂L◦⊂L ⊂G. Let δ := d(K, Lc) > 0
and let ρK,δ be as in Lemma 13.10. Then 1K ≤ρK,δ ≤1L; hence ρK,δ ∈Cc(E)
and thus
lim inf
n→∞μn(G) ≥lim inf
n→∞

ρK,δ dμn =

ρK,δ dμ ≥μ(K) ≥μ(G) −ε.
Letting ε →0, we get (v).
“(vi) ⇒(iii)”
Let f : E →R be bounded and measurable with μ(Uf ) = 0.
We make the elementary observation that for all D ⊂R,
∂f −1(D) ⊂f −1(∂D) ∪Uf .
(13.6)
Indeed, if f is continuous at x ∈E, then for any δ > 0, there is an ε(δ) > 0 with
f (Bε(δ)(x)) ⊂Bδ(f (x)). If x ∈∂f −1(D), then there are y ∈f −1(D) ∩Bε(δ)(x)
and z ∈f −1(Dc) ∩Bε(δ)(x). Therefore, f (y) ∈Bδ(f (x)) ∩D ̸= ∅and f (z) ∈
Bδ(f (x)) ∩Dc ̸= ∅; hence f (x) ∈∂D.
Let ε > 0. Evidently, the set A := 	y ∈R : μ f −1 ({y})
 > 0
 of atoms of
the ﬁnite measure μ ◦f −1 is at most countable. Hence, there exist N ∈N and
y0 ≤−∥f ∥∞< y1 < . . . < yN−1 < ∥f ∥∞< yN such that
yi ∈R \ A
and
|yi+1 −yi| < ε
for all i.
Let Ei = f −1 ([yi−1, yi)) for i = 1, . . . , N. Then E = N
i=1 Ei and by (13.6),
μ∂Ei
 ≤μf −1({yi−1}) + μf −1({yi}) + μUf
 = 0.
Therefore,
lim sup
n→∞

f dμn ≤lim sup
n→∞
N

i=1
μn(Ei) · yi =
N

i=1
μ(Ei) · yi ≤ε +

f dμ.

13.2
Weak and Vague Convergence
285
We let ε →0 and obtain lim sup
n→∞
3
f dμn ≤
3
f dμ. Finally, consider (−f ) to
obtain the reverse inequality lim inf
n→∞

f dμn ≥

f dμ.
⊓⊔
Deﬁnition 13.17 Let X, X1, X2, . . . be random variables with values in E. We say
that (Xn)n∈N converges in distribution to X, formally Xn
D
−→X or Xn
n→∞
⇒X,
if the distributions converge weakly and hence if PX = w-lim
n→∞PXn. Sometimes we
write Xn
D
−→PX or Xn
n→∞
⇒PX if we want to specify only the distribution PX
but not the random variable X.
Theorem 13.18 (Slutzky’s theorem)
Let X, X1, X2, . . . and Y1, Y2, . . . be ran-
dom variables with values in E. Assume Xn
D
−→X and d(Xn, Yn)
n→∞
−→0 in
probability. Then Yn
D
−→X.
Proof Let f : E →R be bounded and Lipschitz continuous with constant K. Then
f (x) −f (y)
 ≤K d(x, y) ∧2 ∥f ∥∞
for all x, y ∈E.
Dominated convergence yields lim sup
n→∞
E
)f (Xn) −f (Yn)
*
= 0. Hence we have
lim sup
n→∞
E[f (Yn)] −E[f (X)]

≤lim sup
n→∞
E[f (X)] −E[f (Xn)]
 + lim sup
n→∞
E[f (Xn) −f (Yn)]
 = 0.
⊓⊔
Corollary 13.19 If Xn
n→∞
−→X in probability, then Xn
D
−→X, n →∞. The
converse is false in general.
Example 13.20 If X, X1, X2, . . . are i.i.d. (with nontrivial distribution), then triv-
ially Xn
D
−→X but not Xn
n→∞
−→X in probability. ♦
Recall the deﬁnition of a distribution function of a probability measure from
Deﬁnition 1.59.
Deﬁnition 13.21 Let F, F1, F2, . . . be distribution functions of probability mea-
sures on R. We say that (Fn)n∈N converges weakly to F, formally Fn
n→∞
⇒F,
Fn
D
−→F or F = w-lim
n→∞Fn, if
F(x) = lim
n→∞Fn(x) for all points of continuity x of F.
(13.7)
If F, F1, F2, . . . are distribution functions of sub-probability measures, then we
deﬁne F(∞) := limx→∞F(x) and for weak convergence require in addition
F(∞) ≥lim supn→∞Fn(∞).

286
13
Convergence of Measures
Note that (13.7) implies F(∞) ≤lim infn→∞Fn(∞). Hence, if Fn
D
−→F, then
F(∞) = limn→∞Fn(∞).
Example 13.22 If F is the distribution function of a probability measure on R and
Fn(x) := F(x +n) for x ∈R, then (Fn)n∈N converges pointwise to 1. However, this
is not a distribution function, as 1 does not converge to 0 for x →−∞. On the other
hand, if Gn(x) = F(x −n), then (Gn)n∈N converges pointwise to G ≡0. However,
G(∞) = 0 < lim supn→∞Gn(∞) = 1; hence we do not have weak convergence
here either. Indeed, in each case, there is a mass defect in the limit (in the case of
the Fn on the left and in the case of the Gn on the right). However, the deﬁnition
of weak convergence of distribution functions is constructed so that no mass defect
occurs in the limit. ♦
Theorem 13.23 Let μ, μ1, μ2, . . . ∈M≤1(R) with corresponding distribution
functions F, F1, F2, . . .. The following are equivalent.
(i) μ = w-lim
n→∞μn.
(ii) Fn
D
−→F.
Proof “(i) ⇒(ii)”
Let F be continuous at x. Then μ∂(−∞, x] = μ({x}) = 0.
By Theorem 13.16, Fn(x) = μn ((−∞, x])
n→∞
−→μ((−∞, x]) = F(x).
“(ii) ⇒(i)”
Let f ∈Lip1(R; [0, 1]). By Theorem 13.16, it is enough to show
that

f dμn
n→∞
−→

f dμ.
(13.8)
Let ε > 0. Fix N ∈N and choose N + 1 points of continuity y0 < y1 < . . . < yN
of F such that F(y0) < ε, F(yN) > F(∞) −ε and yi −yi−1 < ε for all i. Then

f dμn ≤

Fn(y0) + Fn(∞) −Fn(yN)

+
N

i=1
(f (yi) + ε)(Fn(yi) −Fn(yi−1)).
By assumption, limn→∞Fn(∞) = F(∞) and Fn(yi)
n→∞
−→F(yi) for every i =
0, . . . , N; hence
lim sup
n→∞

f dμn ≤3 ε +
N

i=1
f (yi)F(yi) −F(yi−1) ≤4 ε +

f dμ.
Therefore,
lim sup
n→∞

f dμn ≤

f dμ.
Replacing f by (1 −f ), we get (13.8).
⊓⊔

13.2
Weak and Vague Convergence
287
Corollary 13.24 Let X, X1, X2, . . . be real random variables with distribution
functions F, F1, F2, . . .. Then the following are equivalent.
(i) Xn
D
−→X.
(ii) E[f (Xn)]
n→∞
−→E[f (X)] for all f ∈Cb(R).
(iii) Fn
D
−→F.
How stable is weak convergence if we pass to image measures under some map
ϕ? Clearly, we need a certain continuity of ϕ at least at those points where the limit
measure puts mass. The following theorem formalizes this idea and will come in
handy in many applications.
Theorem 13.25 (Continuous mapping theorem) Let (E1, d1) and (E2, d2) be
metric spaces and let ϕ : E1 →E2 be measurable. Denote by Uϕ the set of points
of discontinuity of ϕ.
(i) If μ, μ1, μ2, . . . ∈M≤1(E1) with μ(Uϕ) = 0 and μn
n→∞
−→μ weakly, then
μn ◦ϕ−1 n→∞
−→μ ◦ϕ−1 weakly.
(ii) If X, X1, X2, . . . are E1-valued random variables with P[X ∈Uϕ] = 0 and
Xn
D
−→X, then ϕ(Xn)
D
−→ϕ(X).
Proof First note that Uϕ ⊂E1 is Borel measurable by Exercise 1.1.3. Hence the
conditions make sense.
(i) Let f ∈Cb(E2). Then f ◦ϕ is bounded and measurable and Uf ◦ϕ ⊂Uϕ; hence
μ(Uf ◦ϕ) = 0. By Theorem 13.16,
lim
n→∞

f d

μn ◦ϕ−1
= lim
n→∞

(f ◦ϕ) dμn
=

(f ◦ϕ) dμ =

f dμ ◦ϕ−1.
(ii) This is obvious since Pϕ(X) = PX ◦ϕ−1.
⊓⊔
Takeaways Weak convergence of measures is deﬁned via convergence of
integrals of bounded continuous test functions. If the test functions are also
assumed to have compact support, we get vague convergence of measures.
Roughly speaking, the difference is that vague convergence does not imply
convergence of total masses. In fact, vague convergence is a sensible notion
even for inﬁnite measures. The most important properties of weak and vague
convergence are summarised in the portemanteau theorem and the continuous
mapping theorem. For probability measures on R, weak convergence is
tantamount to convergence of distribution functions at all points of continuity
of the limiting function.

288
13
Convergence of Measures
Exercise 13.2.1 Recall d′
P from (13.5). Show that dP (μ, ν) = d′
P (μ, ν) =
d′
P (ν, μ) for all μ, ν ∈M1(E). ♣
Exercise 13.2.2 Show that the topology of weak convergence on Mf (E) is
coarser than the topology induced on Mf (E) by the total variation norm (see
Corollary 7.45). That is, ∥μn −μ∥T V
n→∞
−→0 implies μn
n→∞
−→μ weakly. ♣
Exercise 13.2.3 Let E = R and μn =
1
n
n
k=0 δk/n. Let μ = λ
[0,1] be the
Lebesgue measure restricted to [0, 1]. Show that μ = w-lim
n→∞μn. ♣
Exercise 13.2.4 Let E = R and λ be the Lebesgue measure on R. For n ∈N, let
μn = λ
[−n,n]. Show that λ = v-lim
n→∞μn but that (μn)n∈N does not converge weakly.
♣
Exercise 13.2.5 Let E = R and μn = δn for n ∈N. Show that v-lim
n→∞μn = 0 but
that (μn)n∈N does not converge weakly. ♣
Exercise 13.2.6 (Lévy metric)
For two probability distribution functions F and
G on R, deﬁne the Lévy distance by
d(F, G) = inf
	
ε ≥0 : G(x −ε) −ε ≤F(x) ≤G(x + ε) + ε for all x ∈R

.
Show the following:
(i) d is a metric on the set of distribution functions.
(ii) Fn
n→∞
⇒F if and only if d(Fn, F)
n→∞
−→0.
(iii) For every P ∈M1(R), there is a sequence (Pn)n∈N in M1(R) such that each
Pn has ﬁnite support and such that Pn
n→∞
⇒P. ♣
Exercise 13.2.7 We can extend the notions of weak convergence and vague con-
vergence to signed measures; that is, to differences ϕ := μ+ −μ−of measures
from Mf (E) and M(E), respectively, by repeating the words of Deﬁnition 13.12
for these classes. Show that the topology of weak convergence is not metrizable in
general.
Hint: Consider E = [0, 1].
(i) For n ∈N, deﬁne ϕn = δ1/n −δ2/n. Show that, for any C > 0, (Cϕn)n∈N
converges weakly to the zero measure.
(ii) Assume there is a metric that induces weak convergence. Show that then there
would be a sequence (Cn)n∈N with Cn ↑∞and 0 = w-lim
n→∞(Cnϕn).
(iii) Choose an f ∈C([0, 1]) with f (2−n) = (−1)nC−1/2
n
for any n ∈N, and
show that
 3
f d(Cnϕn)

n∈N does not converge to zero.
(iv) Use this construction to contradict the assumption of metrizability. ♣

13.2
Weak and Vague Convergence
289
Exercise 13.2.8 Show that (13.4) deﬁnes a metric on M1(E) and that this metric
induces the topology of weak convergence. ♣
Exercise 13.2.9 Show the implication “(vi) ⇒(iv)” of Theorem 13.16 directly.
♣
Exercise 13.2.10 Let X, X1, X2, . . . and Y1, Y2, . . . be real random variables.
Assume PYn = N0,1/n for all n ∈N. Show that Xn
D
−→
X if and only if
Xn + Yn
D
−→X. ♣
Exercise 13.2.11 For each n ∈N, let Xn be a geometrically distributed random
variable with parameter pn ∈(0, 1). How must we choose the sequence (pn)n∈N
in order that PXn/n converges weakly to the exponential distribution with parameter
α > 0? ♣
Exercise 13.2.12 Let X, X1, X2, . . . be real random variables with Xn
n→∞
⇒X.
Show the following.
(i) E[|X|] ≤lim infn→∞E[|Xn|].
(ii) Let r > p > 0. If sup
n∈N
E[|Xn|r] < ∞, then E[|X|p] = lim
n→∞E[|Xn|p]. ♣
Exercise 13.2.13 Let F, F1, F2, . . . be probability distribution functions on R, and
assume Fn
n→∞
⇒F. Let F −1(u) = inf{x ∈R : F(x) ≥u}, u ∈(0, 1), be the left
continuous inverse of F (see the proof of Theorem 1.104). Show that
F −1
n (u)
n→∞
−→F −1(u) at every point of continuity u of F −1.
Conclude that F −1(u)
n→∞
−→F −1(u) for Lebesgue almost all u ∈(0, 1). ♣
Exercise 13.2.14 Let μ, μ1, μ2, . . . ∈M1(R) with μn
n→∞
−→μ weakly. Show that
there exists a probability space (Ω, A, P) and real random variables X, X1, X2, . . .
on (Ω, A, P) with distributions PX = μ and PXn = μn, n ∈N, such that
Xn
n→∞
−→X
P-a.s.
Hint: Use Exercise 13.2.13. ♣
Exercise 13.2.15 Let (E, d) be a metric space and let μ, μ1, μ2, . . . be probability
measures on E. A measurable map f : E →R is called uniformly integrable with
respect to (μn)n∈N, if
inf
a>0 sup
n∈N

{|f |>a}
|f | dμn = 0.

290
13
Convergence of Measures
Let f be continuous and uniformly integrable with respect to (μn)n∈N and assume
that μn
n→∞
−→μ weakly. Show that
3
|f | dμ < ∞and that

f dμn
n→∞
−→

f dμ.
Hint: Apply Exercise 13.2.14 to the image measures μn ◦f −1. ♣
13.3
Prohorov’s Theorem
In the following, let E be a Polish space with Borel σ-algebra E. A fundamental
question is: When does a sequence (μn)n∈N of measures on (E, E) converge weakly
or does at least have a weak limit point? Evidently, a necessary condition is that
(μn(E))n∈N is bounded. Hence, without loss of generality, we will consider only
sequences in M≤1(E). However, this condition is not sufﬁcient for the existence of
weak limit points, as for example the sequence (δn)n∈N of probability measures on R
does not have a weak limit point (although it convergesvaguely to the zero measure).
This example suggests that we also have to make sure that no mass “vanishes at
inﬁnity”. The idea will be made precise by the notion of tightness.
We start this section by presenting as the main result Prohorov’s theorem [136].
We give the proof ﬁrst for the special case E = R and then come to a couple of
applications. The full proof of the general case is deferred to the end of the section.
Deﬁnition 13.26 (Tightness) A family F ⊂Mf (E) is called tight if, for any
ε > 0, there exists a compact set K ⊂E such that
sup 	μ(E \ K) : μ ∈F
 < ε.
Remark 13.27 If E is Polish, then by Lemma 13.5, every singleton {μ} ⊂Mf (E)
is tight and thus so is every ﬁnite family. ♦
Example 13.28
(i) If E is compact, then M1(E) and M≤1(E) are tight.
(ii) If (Xi)i∈I is an arbitrary family of random variables with
C := sup{E[|Xi|] : i ∈I} < ∞,
then {PXi : i ∈I} is tight. Indeed, for ε > 0 and K = [−C/ε, C/ε], by
Markov’s inequality, PXi(R \ K) = P[|Xi| > C/ε] ≤ε.
(iii) The family (δn)n∈N of probability measures on R is not tight.
(iv) The family (U[−n,n])n∈N of uniform distributions on the intervals [−n, n],
regarded as measures on R, is not tight. ♦

13.3
Prohorov’s Theorem
291
Recall that a family F of measures is called weakly relatively sequentially compact
if every sequence in F has a weak limit point (in the closure of F).
Theorem 13.29 (Prohorov’s theorem (1956)) Let (E, d) be a metric space and
F ⊂M≤1(E). Then:
(i) F is tight
⇒
F is weakly relatively sequentially compact.
(ii) If E is Polish, then also the converse holds:
F is tight
⇐
F is weakly relatively sequentially compact.
Corollary 13.30 Let E be a compact metric space. Then the sets M≤1(E) and
M1(E) are weakly sequentially compact.
Corollary 13.31 If E is a locally compact separable metric space, then M≤1(E)
is vaguely sequentially compact.
Proof Let (μn)n∈N be a sequence in M≤1(E). We have to show that there exists a
vaguely convergent subsequence.
As E is locally compact and separable, E is σ-compact. Let U1, U2, . . . ⊂E be
relatively compact open sets covering E. Inductively, we deﬁne relatively compact
open sets Wn ↑E with Wn ⊂Wn+1 for all n ∈N. Let W1 := U1. Having deﬁned
Wn, we choose a relatively open set Ln ⊃Wn and deﬁne Wn+1 := Ln ∪Un+1. Note
that for any compact C ⊂E, there exists an N(C) ∈N such that C ⊂Wn for all
n ≥N(C).
Applying
Prohorov’s
theorem
(i.e.,
Corollary
13.30)
to
the
measures
(μk1W n)k∈N, for each n ∈N, we can choose a sequence (kn
l )l∈N and a measure
˜μn := w-lim
l→∞μkn
l 1W n whose support lies in W n. We may assume that the sequences
(kn
l )l∈N were chosen successively such that (kn+1
l
) is a subsequence of (kn
l ).
Note that we have ˜μn(W n) ≤˜μn+1(W n), but equality does not hold in general.
For f ∈Cc(E), there exists an n0 ∈N such that the support of f is contained in
Wn0. Hence, for m ≥n ≥n0, we have

f d ˜μn = lim
l→∞

f 1W n dμkn
l
= lim
l→∞

f 1W n dμkm
l
= lim
l→∞

f 1W m dμkm
l =

f d ˜μm
and thus

f d ˜μn = lim
m→∞

f dμkm
m.

292
13
Convergence of Measures
This implies that for any measurable relatively compact set A ⊂E, we have
˜μm(A) = ˜μN(A)(A)
for any m ≥N(A).
For any measurable set A ⊂E, deﬁne
μ(A) := sup
n∈N
sup
m>n
˜μm(A ∩Wn) = sup
n∈N
˜μn+1(A ∩Wn).
It is easy to check that μ is a lower semicontinuous content and is hence a measure
(see Theorem 1.36). By construction, for any f ∈Cc(E), we infer

f dμ = lim
n→∞

f dμknn.
Concluding, we have μ = v-lim
n→∞μknn.
⊓⊔
Remark 13.32 The implication (ii) in Theorem 13.29 is less useful but a lot simpler
to prove. Here we need that E is Polish since clearly every singleton is weakly
compact but is tight only under additional assumptions; for example, if E is Polish
(see Lemma 13.5). ♦
Proof (of Theorem 13.29(ii))
We start as in the proof of Lemma 13.5. Let
{x1, x2, . . .} ⊂E be dense. For n ∈N, deﬁne An,N :=
N
i=1
B1/n(xi). Then
An,N ↑E for N →∞for all n ∈N. Let
δ := sup
n∈N
inf
N∈N sup
μ∈F
μ(Ac
n,N).
Then there is an n ∈N such that for any N ∈N, there is a μN ∈F with
μN(Ac
n,N) ≥δ/2. As F is weakly relatively sequentially compact, (μN)N∈N has
a weakly convergent subsequence (μNk)k∈N whose weak limit will be denoted by
μ ∈M≤1(E). By the Portemanteau theorem (Theorem 13.16(iv)), for any N ∈N,
μ(Ac
n,N) ≥lim inf
k→∞μNk(Ac
n,N) ≥lim inf
k→∞μNk(Ac
n,Nk) ≥δ/2.
On the other hand, Ac
n,N ↓∅for N →∞; hence μ(Ac
n,N)
N→∞
−→0. Thus δ = 0.
Now ﬁx ε > 0. By the above, for any n ∈N, we can choose an N′
n ∈N such
that μ(Ac
n,N′n) < ε/2n for all μ ∈F. By construction, the set A := ∞
n=1 An,N′n is
totally bounded and hence relatively compact. Further, for every μ ∈F,
μ

( A )c
≤μ(Ac) ≤
∞

n=1
μ(Ac
n,N′n) ≤ε.
Hence F is tight.
⊓⊔

13.3
Prohorov’s Theorem
293
The other implication in Prohorov’s theorem is more difﬁcult to prove, especially
in the case of a general metric space. For this reason, we ﬁrst give a proof only for
the case E = R and come to applications before proving the difﬁcult implication in
the general situation.
The problem consists in ﬁnding a candidate for a weak limit point. For
distributions on R, the problem is equivalent to ﬁnding a weak limit point for a
sequence of distribution functions. Here Helly’s theorem is the tool. It is based on
a diagonal sequence argument that will be recycled later in the proof of Prohorov’s
theorem in the general case.
Let
V =
	
F : R →R is right continuous, monotone increasing and bounded

be the set of distribution functions of ﬁnite measures on R.
Theorem 13.33 (Helly’s theorem) Let (Fn)n∈N be a uniformly bounded sequence
in V . Then there exists an F ∈V and a subsequence (Fnk)k∈N with
Fnk(x)
k→∞
−→F(x) at all points of continuity of F.
Proof We use a diagonal sequence argument. Choose an enumeration of the rational
numbers Q = {q1, q2, q3, . . . }. By the Bolzano–Weierstraß theorem, the sequence
(Fn(q1))n∈N has a convergent subsequence Fn1
k(q1)
k∈N. Analogously, we ﬁnd a
subsequence (n2
k)k∈N of (n1
k)k∈N such that

Fn2
k(q2)

k∈N converges. Inductively, we
obtain subsequences (n1
k) ⊃(n2
k) ⊃(n3
k) ⊃. . . such that

Fnl
k(ql)

k∈N converges
for all l ∈N. Now deﬁne nk := nk
k. Then

Fnk(q)

k∈N converges for all q ∈Q.
Deﬁne 
F(q) = lim
k→∞Fnk(q) and
F(x) = inf
	
F(q) : q ∈Q with q > x

.
As 
F is monotone increasing, F is right continuous and monotone increasing.
If F is continuous at x, then for every ε > 0, there exist numbers q−, q+ ∈
Q, q−< x < q+ with 
F(q−) ≥F(x)−ε and 
F (q+) ≤F(x)+ε. By construction,
lim sup
k→∞
Fnk(x) ≤lim
k→∞Fnk(q+) = 
F(q+) ≤F(x) + ε.
Hence lim sup
k→∞
Fnk(x) ≤F(x). A similar argumentfor q−yields lim inf
k→∞Fnk(x) ≥
F(x).
⊓⊔
Reﬂection Check that in the above proof, in general, we do not have F(q) = ˜F(q)
for all q ∈Q.♠

294
13
Convergence of Measures
Proof (of Theorem 13.29(i) for the case E = R) Assume F is tight and (μn)n∈N
is a sequence in F with distribution functions Fn : x →μN((−∞, x]). By
Helly’s theorem, there is a monotone right continuous function F : R →[0, 1]
and a subsequence (Fnk)k∈N of (Fn)n∈N with Fnk(x)
k→∞
−→F(x) at all points of
continuity x of F. We will show
(i) F is the distribution function of a (sub-) probability measure. That is, we have
F(−∞) = 0.
(ii) We have F(∞) ≥lim supk→∞Fnk(∞).
By Theorem 13.23, this is enough to conclude the proof.
As F is tight, for every ε > 0, there is a K < ∞with Fn(x) −Fn(−∞) < ε for
all n ∈N and x < −K. If x > K is a point of continuity of F, then
0 = lim inf
k→∞Fnk(−∞) ≥lim inf
k→∞Fnk(x) −ε
= F(x) −ε ≥F(−∞) −ε ≥−ε.
This shows (i).
As F is tight, for every ε > 0, there is a K < ∞with Fn(∞) −Fn(x) < ε
for all n ∈N and x > K. If x > K is a point of continuity of F, then
lim supk→∞Fnk(∞) ≤lim supk→∞Fnk(x) + ε = F(x) + ε ≤F(∞) + ε. This
shows (ii).
⊓⊔
Reﬂection Find an example that shows that without the tightness assumption, we
need not have F(−∞) = 0 nor F(∞) = 1.♠
We come to a ﬁrst application of Prohorov’s theorem. The full strength of that
theorem will become manifest when suitable separating classes of functions are at
our disposal. We come back to this point in more detail in Chap. 15.
Theorem 13.34 Let E be Polish and let μ, μ1, μ2, . . . ∈M≤1(E). Then the
following are equivalent.
(i) μ = w-lim
n→∞μn.
(ii) (μn)n∈N is tight, and there is a separating family C ⊂Cb(E) such that

f dμ = lim
n→∞

f dμn
for all f ∈C.
(13.9)
Proof “(i) ⇒(ii)”
By the simple implication in Prohorov’s theorem (Theo-
rem 13.29(ii)), weak convergence implies tightness.
“(ii) ⇒(i)”
Let (μn)n∈N be tight and let C ⊂Cb(E) be a separating class with
(13.9). Assume that (μn)n∈N does not converge weakly to μ. Then there are ε > 0,
f ∈Cb(E) and (nk)k∈N with nk ↑∞and such that


f dμnk −

f dμ
 > ε
for all k ∈N.
(13.10)

13.3
Prohorov’s Theorem
295
By Prohorov’s theorem, there exists a ν ∈M≤1(E) and a subsequence (n′
k)k∈N of
(nk)k∈N with μn′
k →ν weakly. Due to (13.10), we have
3
f dμ −
3
f dν
 ≥ε;
hence μ ̸= ν. On the other hand,

h dμ = lim
k→∞

h dμn′
k =

h dν
for all h ∈C;
hence μ = ν. This contradicts the assumption and thus (i) holds.
⊓⊔
We want to shed some more light on the connection between weak and vague
convergence.
Theorem 13.35 Let E be a locally compact Polish space and let μ, μ1, μ2, . . .
∈Mf (E). Then the following are equivalent.
(i) μ = w-lim
n→∞μn.
(ii) μ = v-lim
n→∞μn and μ(E) = lim
n→∞μn(E).
(iii) μ = v-lim
n→∞μn and μ(E) ≥lim sup
n→∞
μn(E).
(iv) μ = v-lim
n→∞μn and {μn, n ∈N} is tight.
Proof “(i) ⇐⇒(ii) ⇐⇒(iii)”
This follows by the Portemanteau theorem.
“(ii) ⇒(iv)”
It is enough to show that for any ε > 0, there is a compact set
K ⊂E with lim supn→∞μn(E \ K) ≤ε. As μ is regular (Theorem 13.6), there is
a compact set L ⊂E with μ(E \ L) < ε. Since E is locally compact, there exists a
compact set K ⊂E with K◦⊃L and a ρL,K ∈Cc(E) with 1L ≤ρL,K(x) ≤1K.
Therefore,
lim sup
n→∞
μn(E \ K) ≤lim sup
n→∞

μn(E) −

ρL,K dμn

= μ(E) −

ρL,K dμ ≤μ(E \ L) < ε.
“(iv) ⇒(i)”
Let L ⊂E be compact with μn(E \ L) ≤1 for all n ∈N. Let
ρ ∈Cc(E) with ρ ≥1L. Since
3
ρ dμn converges by assumption, we thus have
sup
n∈N
μn(E) ≤1 + sup
n∈N
μn(L) ≤1 + sup
n∈N

ρ dμn < ∞.
Hence also
C := max(μ(E), sup{μn(E) : n ∈N}) < ∞,
and we can pass to μ/C and μn/C. Thus, without loss of generality assume that
all measures are in M≤1(E). As Cc(E) is a separating class for M≤1(E) (see
Theorem 13.11), (i) follows by Theorem 13.34.
⊓⊔

296
13
Convergence of Measures
Proof of Prohorov’s theorem, Part (i), general case There are two main routes
for proving Prohorov’s theorem in the general situation. One possibility is to show
the claim ﬁrst for measures on Rd. (We have done this already for d = 1, see
Exercise 13.3.4 for d ≥2.) In a second step, the statement is lifted to sequence
spaces RN. Finally, in the third step, an embedding of E into RN is constructed. For
a detailed description, see [12] or [83].
Here we follow the alternative route as described in [13] (and later [14]) or
[44]. The main point of this proof consists in ﬁnding a candidate for a weak limit
point for the family F. This candidate will be constructed ﬁrst as a content on a
countable class of sets. From this an outer measure will be derived. Finally, we
show that closed sets are measurable with respect to this outer measure. As you see,
the argument follows a pattern similar to the proof of Carathéodory’s theorem.
Let (E, d) be a metric space and let F ⊂M≤1(E) be tight. Then there exists
an increasing sequence K1 ⊂K2 ⊂K3 ⊂. . . of compact sets in E such that
μ(Kc
n) <
1
n for all μ ∈F and all n ∈N. Deﬁne E′ := ∞
n=1 Kn. Then E′ is
a σ-compact metric space and therefore in particular, separable. By construction,
μ(E \ E′) = 0 for all μ ∈F. Thus, any μ can be regarded as a measure on E′.
Without loss of generality, we may hence assume that E is σ-compact and thus
separable. Hence there exists a countable base U of the topology τ
E on E; that is,
a countable set U of open sets such that A = 
U∈U, U⊂A U for any open A ⊂E.
Deﬁne
C′ :=
	
U ∩Kn : U ∈U, n ∈N

and
C :=
0 N

n=1
Cn : N ∈N and C1, . . . , CN ∈C′
1
.
Clearly, C is a countable set of compact sets in E, and C is stable under formation
of unions. Any Kn possesses a ﬁnite covering with sets from U; hence Kn ∈C.
Now let (μn)n∈N be a sequence in F. By virtue of the diagonal sequence
argument (see the proof of Helly’s theorem, Theorem 13.33), we can ﬁnd a
subsequence (μnk)k∈N such that for all C ∈C, there exists the limit
α(C) := lim
k→∞μnk(C).
(13.11)
Assume that we can show that there is a measure μ on the Borel σ-algebra E of E
such that
μ(A) = sup 	α(C) : C ∈C with C ⊂A
for all A ⊂E open.
(13.12)

13.3
Prohorov’s Theorem
297
Then
μ(E) ≥sup
n∈N
α(Kn) = sup
n∈N
lim
k→∞μnk(Kn)
≥sup
n∈N
lim sup
k→∞

μnk(E) −1
n

= lim sup
k→∞
μnk(E).
Furthermore, for open A and for C ∈C with C ⊂A,
α(C) = lim
k→∞μnk(C) ≤lim inf
k→∞μnk(A),
hence μ(A) ≤lim infk→∞μnk(A). By the Portemanteau theorem (Theorem 13.16),
μ = w-lim
k→∞μnk; hence F is recognized as weakly relatively sequentially compact.
It remains to show that there exists a measure μ on (E, E) that satisﬁes (13.12).
Clearly, the set function α on C is monotone, additive and subadditive:
α(C1) ≤α(C2),
if C1 ⊂C2,
α(C1 ∪C2) = α(C1) + α(C2),
if C1 ∩C2 = ∅,
α(C1 ∪C2) ≤α(C1) + α(C2).
(13.13)
We deﬁne
β(A) := sup
	
α(C) : C ∈C with C ⊂A

for A ⊂E open
and
μ∗(G) := inf 	β(A) : A ⊃G is open
for G ∈2E.
Manifestly, β(A) = μ∗(A) for any open A. It is enough to show (Steps 1–3 below)
that μ∗is an outer measure (see Deﬁnition 1.46) and that (Step 4) the σ-algebra
of μ∗-measurable sets (see Deﬁnition 1.48 and Lemma 1.52) contains the closed
sets and thus E. Indeed, Lemma 1.52 would then imply that μ∗is a measure on
the σ-algebra of μ∗-measurable sets and the restricted measure μ := μ∗E fulﬁlls
μ(A) = μ∗(A) = β(A) for all open A. Hence equation (13.12) holds.
Evidently, μ∗(∅) = 0 and μ∗is monotone. In order to show that μ∗is an outer
measure, it only remains to check that μ∗is σ-subadditive.

298
13
Convergence of Measures
Step 1 (Finite subadditivity of β). Let A1, A2 ⊂E be open and let C ∈C with
C ⊂A1 ∪A2. Let n ∈N with C ⊂Kn. Deﬁne two sets
B1 :=
x ∈C : d(x, Ac
1) ≥d(x, Ac
2) ,
B2 :=
x ∈C : d(x, Ac
1) ≤d(x, Ac
2) .
2
A
1
1
C
A
2
B
B
Evidently, B1 ⊂A1 and B2 ⊂A2. As x →d(x, Ac
i ) is continuous for i = 1, 2,
the closed subsets B1 and B2 of C are compact. Hence d(B1, Ac
1) > 0. Thus there
exists an open set D1 with B1 ⊂D1 ⊂D1 ⊂A1. (One could choose D1 as the
union of the sets of a ﬁnite covering of B1 with balls of radius d(B1, Ac
1)/2. These
balls, as well as their closures, are subsets of A1.) Let UD1 := {U ∈U : U ⊂D1}.
Then B1 ⊂D1 = 
U∈UD1 U. Now choose a ﬁnite subcovering {U1, . . . , UN} ⊂
UD1 of B1 and deﬁne C1 := N
i=1 U i ∩Kn. Then B1 ⊂C1 ⊂A1 and C1 ∈C.
Similarly, choose C2 ∈C with B2 ⊂C2 ⊂A2. Thus
α(C) ≤α(C1 ∪C2) ≤α(C1) + α(C2) ≤β(A1) + β(A2).
Hence also
β(A1 ∪A2) = sup
	
α(C) : C ∈C with C ⊂A1 ∪A2

≤β(A1) + β(A2).
Step 2 (σ-subadditivity of β). Let A1, A2, . . . be open sets and let C ∈C with
C ⊂∞
i=1 Ai. As C is compact, there exists an n ∈N with C ⊂n
i=1 Ai. As
shown above, β is subadditive; thus
α(C) ≤β
 n

i=1
Ai

≤
∞

i=1
β(Ai).
Taking the supremum over such C yields
β
 ∞

i=1
Ai

= sup
0
α(C) : C ∈C with C ⊂
∞

i=1
Ai
1
≤
∞

i=1
β(Ai).

13.3
Prohorov’s Theorem
299
Step 3 (σ-subadditivity of μ∗). Let G1, G2, . . . ∈2E. Let ε > 0. For any n ∈N
choose an open set An ⊃Gn with β(An) < μ∗(Gn)+ε/2n. By the σ-subadditivity
of β,
μ∗
 ∞

n=1
Gn

≤β
 ∞

n=1
An

≤
∞

n=1
β(An) ≤ε +
∞

n=1
μ∗(Gn).
Letting ε ↓0 yields μ∗ ∞
n=1 Gn

≤∞
n=1 μ∗(Gn). Hence μ∗is an outer
measure.
Step 4 (Closed sets are μ∗-measurable). By Lemma 1.49, a set B ⊂E is μ∗-
measurable if and only if
μ∗(B ∩G) + μ∗(Bc ∩G) ≤μ∗(G)
for all G ∈2E.
Taking the inﬁmum over all open sets A ⊃G, it is enough to show that for every
open B and every open A ⊂E,
μ∗(B ∩A) + μ∗(Bc ∩A) ≤β(A).
(13.14)
Let ε > 0. Choose C1 ∈C with C1 ⊂A ∩Bc and α(C1) > β(A ∩Bc) −ε. Further,
let C2 ∈C with C2 ⊂A ∩Cc
1 and α(C2) > β(A ∩Cc
1) −ε. Since C1 ∩C2 = ∅and
C1 ∪C2 ⊂A, we get
β(A) ≥α(C1 ∪C2) = α(C1) + α(C2) ≥β(A ∩Bc) + β(A ∩Cc
1) −2ε
≥μ∗(A ∩Bc) + μ∗(A ∩B) −2ε.
Letting ε →0, we get (13.14). This completes the proof of Prohorov’s theorem.
□
Takeaways A family of measures is called tight if for larger and larger
compacts, there is arbitrarily little mass outside the compact. By Prohorov’s
theorem, in Polish spaces, tightness is equivalent to relative sequential
compactness. Since usually tightness is easier to check, we have a powerful
tool for showing the existence of accumulation points.
Exercise 13.3.1 Show that a family F ⊂Mf (R) is tight if and only if there exists
a measurable map f : R →[0, ∞) such that f (x) →∞for |x| →∞and
supμ∈F
3 f dμ < ∞. ♣

300
13
Convergence of Measures
Exercise 13.3.2 Let L ⊂R × (0, ∞) and let F = {Nμ,σ 2 : (μ, σ 2) ∈L} be a
family of normal distributions with parameters in L. Show that F is tight if and only
if L is bounded. ♣
Exercise 13.3.3 If P is a probability measure on [0, ∞) with mP := 3 x P(dx) ∈
(0, ∞), then we deﬁne the size-biased distribution :
P on [0, ∞) by
:
P (A) = m−1
P

A
x P(dx).
(13.15)
Now let (Xi)i∈I be a family of random variables on [0, ∞) with E[Xi] = 1. Show
that
 A
PXi

i∈I is tight if and only if (Xi)i∈I is uniformly integrable. ♣
Exercise 13.3.4 (Helly’s theorem in Rd)
Let x = (x1, . . . , xd) ∈Rd and y =
(y1, . . . , yd) ∈Rd. Recall the notation x ≤y if xi ≤yi for all i = 1, . . . , d. A map
F : Rd →R is called monotone increasing if F(x) ≤F(y) whenever x ≤y. F is
called right continuous if F(x) = limn→∞F(xn) for all x ∈Rd and every sequence
(xn)n∈N in Rd with x1 ≥x2 ≥x3 ≥. . . and x = limn→∞xn. By Vd denote the set
of monotone increasing, bounded right continuous functions on Rd.
(i) Show the validity of Helly’s theorem with V replaced by Vd.
(ii) Conclude that Prohorov’s theorem holds for E = Rd. ♣
13.4
Application: A Fresh Look at de Finetti’s Theorem
(After an idea of Götz Kersting.) Let E be a Polish space and let X1, X2, . . . be an
exchangeable sequence of random variables with values in E. As an alternative to
the backwards martingale argument of Sect. 12.3, here we give a different proof of
de Finetti’s theorem (Theorem 12.26). Recall that de Finetti’s theorem states that
there exists a random probability measure Ξ on E such that, given Ξ, the random
variables X1, X2, . . . are independent and Ξ-distributed. For x = (x1, x2, . . .) ∈
EN, let ξn(x) := 1
n
n
l=1 δxl be the empirical distribution of x1, . . . , xn. Let
μn,k(x) := ξn(x)⊗k = n−k
n

i1,...,ik=1
δ(xi1,...,xik )
be the distribution on Ek that describes k-fold independent sampling with replace-
ment (respecting the order) from (x1, . . . , xn). Let
νn,k(x) := (n −k)!
n!
n

i1,...,ik=1
#{i1,...,ik}=k
δ(xi1,...,xik )

13.4
Application: A Fresh Look at de Finetti’s Theorem
301
be the distribution on Ek that describes k-fold independent sampling without
replacement (respecting the order) from (x1, . . . , xn). For all x ∈EN,
;;μn,k(x) −νn,k(x)
;;
T V ≤Rn,k := k(k −1)
n
.
Indeed, the probability pn,k that we do not see any ball twice when drawing k balls
(with replacement) from n different balls is
pn,k =
k−1

l=1
(1 −l/n)
and thus Rn,k ≥2(1−pn,k). We therefore obtain the rather intuitive statement that as
n →∞the distributions of k-samples with replacement and without replacement,
respectively, become the same:
lim
n→∞sup
x∈EN
;;μn,k(x) −νn,k(x)
;;
T V = 0.
Now let f1, . . . , fk ∈Cb(E) and F(x1, . . . , xk) := f1(x1) · · · fk(xk). As the
sequence X1, X2, . . . is exchangeable, for any choice of pairwise distinct numbers
1 ≤i1, . . . , ik ≤n,
E[F(X1, . . . , Xk)] = E[F(Xi1, . . . , Xik)].
Averaging over all choices i1, . . . , ik, we get
E
)
f1(X1) · · · fk(Xk)
*
= E
)
F(X1, . . . , Xk)
*
= E
' 
F dνn,k(X)
(
.
Hence
E
)
f1(X1) · · · fk(Xk)
*
−E
' 
f1 dξn(X) · · ·

fk dξn(X)
(
=
E
' 
F dνn,k(X)
(
−E
' 
F dμn,k(X)
(
≤∥F∥∞Rn,k
n→∞
−→0.
We will exploit the following criterion for tightness of subsets of M1(M1(E)).
Exercise 13.4.1 Show that a subset K ⊂M1(M1(E)) is tight if and only if, for
any ε > 0, there exists a compact set K ⊂E with the property
μ
	
μ ∈M1(E) : μ(Kc) > ε


< ε
for all μ ∈K.
♣

302
13
Convergence of Measures
Since E is Polish, PX1 is tight. Hence, for any ε > 0, there exists a compact set
K ⊂E with P[X1 ∈Kc] < ε2. Therefore,
P[ξn(X)(Kc) > ε] ≤ε−1 E[ξn(X)(Kc)] = ε−1 P[X1 ∈Kc] ≤ε.
Hence the family (Pξn(X))n∈N is tight. Let Ξ∞be a random variable (with values
in M1(E)) such that PΞ∞= w-lim
l→∞Pξnl (X) for a suitable subsequence (nl)l∈N. The
map ξ →3 F dξ = 3 f1 dξ · · · 3 fk dξ is bounded and (as a product of continuous
maps) is continuous with respect to the topology of weak convergence on M1(E);
hence it is in Cb(M1(E)). Thus
E
' 
F dΞ⊗k
∞
(
=
lim
l→∞E
' 
f1 dξnl(X) · · ·

fk dξnl(X)
(
= E
)
f1(X1) · · · fk(Xk)
*
.
Note that the limit does not depend on the choice of the subsequence and is thus
unique. Summarising, we have
E
)
f1(X1) · · · fk(Xk)
*
= E
' 
f1 dΞ∞· · ·

fk dΞ∞
(
.
Since the distribution of (X1, . . . , Xk) is uniquely determined by integrals of the
above type, we conclude that P(X1,...,Xk) = PΞ⊗k
∞. In other words, (X1, . . . , Xk) D=
(Y1, . . . , Yk), where, given Ξ∞, the random variables Y1, . . . , Yk are independent
with distribution Ξ∞.
Takeaways Consider an exchangeable family X1, X2, . . . of random vari-
ables. The empirical distributions of the ﬁrst n random variables yield a tight
family which, by Prohorov’s theorem, has a limit point. This approach allows
for an independent proof of de Finetti’s theorem.
Exercise 13.4.2 Show that a family (Xn)n∈N of random variables is exchangeable
if and only if, for every choice of natural numbers 1 ≤n1 < n2 < n3 . . ., we have
(X1, X2, . . .) D= (Xn1, Xn2, . . .).
Warning: One of the implications is rather difﬁcult to show. ♣

Chapter 14
Probability Measures on Product Spaces
As a motivation, consider the following example. Let X be a random variable that is
uniformly distributed on [0, 1]. As soon as we know the value of X, we toss n times
a coin that has probability X for a success. Denote the results by Y1, . . . , Yn.
How can we construct a probability space on which all these random variables
are deﬁned? One possibility is to construct n + 1 independent random variables
Z0, . . . , Zn that are uniformly distributed on [0, 1] (see, e.g., Corollary 2.23 for the
construction). Then deﬁne X = Z0 and
Yk =
0 1,
if Zk < X,
0,
if Zk ≥X.
Intuitively, this ﬁts well with our idea that the Y1, . . . , Yn are independent as soon
as we know X and record a success with probability X.
In the above description, we have constructed by hand a two-stage experiment.
At the ﬁrst stage, we determine the value of X. At the second stage, depending
on the value of X, the values of Y = (Y1, . . . , Yn) are determined. Clearly, this
construction makes use of the speciﬁc structure of the problem. However, we now
want to develop a systematic framework for the description and construction of
multi-stage experiments. In contrast to Chap. 2, here the random variables need
not be independent. In addition, we also want to construct systematically inﬁnite
families of random variables with given (joint) distributions.
In the ﬁrst section, we start with products of measurable spaces. Then we come
to ﬁnite products of measure spaces and product measures with transition kernels.
Finally, we consider inﬁnite products of probability spaces. The main result is
Kolmogorov’s extension theorem.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_14
303

304
14
Probability Measures on Product Spaces
14.1
Product Spaces
Deﬁnition 14.1 (Product space) Let (Ωi, i ∈I) be an arbitrary family of sets.
Denote by Ω = ×
i∈I Ωi the set of maps ω : I →
i∈I
Ωi such that ω(i) ∈Ωi
for all i ∈I. Ω is called the product of the spaces (Ωi, i ∈I), or brieﬂy the
product space. If, in particular, all the Ωi are equal, say Ωi = Ω0, then we write
Ω = ×
i∈I Ωi = ΩI
0 .
Example 14.2
(i) If Ω1 = {1, . . . , 6} and Ω2 = {1, 2, 3}, then
Ω1 × Ω2 =
	
ω = (ω1, ω2) : ω1 ∈{1, . . . , 6}, ω2 ∈{1, 2, 3}

.
(ii) If Ω0 = R and I = {1, 2, 3}, then R{1,2,3} is isomorphic to the customary R3.
(iii) If Ω0 = R and I = N, then RN is the space of sequences (ω(n), n ∈N) in R.
(iv) If I = R and Ω0 = R, then RR is the set of maps R →R. ♦
Deﬁnition 14.3 (Coordinate maps) If i ∈I, then Xi : Ω →Ωi, ω →ω(i)
denotes the ith coordinate map. More generally, for J ⊂J ′ ⊂I, the restricted
map
XJ ′
J
: ×
j∈J ′
Ωj −→×
j∈J
Ωj,
ω′ →ω′
J
(14.1)
is called the canonical projection. In particular, we write XJ := XI
J .
Deﬁnition 14.4 (Product-σ-algebra)
Let (Ωi, Ai), i ∈I, be measurable spaces.
The product-σ-algebra
A =
 
i∈I
Ai
is the smallest σ-algebra on Ω such that for every i ∈I, the coordinate map Xi is
measurable with respect to A – Ai; that is,
A = σ

Xi, i ∈I

:= σ

X−1
i
(Ai), i ∈I

.
If (Ωi, Ai) = (Ω0, A0) for all i ∈I, then we also write A = A⊗I
0 .
For J ⊂I, let ΩJ := ×
j∈J
Ωj and AJ = /
j∈J
Aj.
Remark 14.5 The concept of the product-σ-algebra is similar to that of the product
topology: If ((Ωi, τi), i ∈I) are topological spaces, then the product topology τ
on Ω = ×
i∈I
Ωi is the coarsest topology with respect to which all coordinate maps
Xi : Ω −→Ωi are continuous. ♦

14.1
Product Spaces
305
Deﬁnition 14.6 Let I ̸= ∅be an arbitrary index set, let (E, E) be a measurable
space, let (Ω, A) = (EI, E⊗I ) and let Xt : Ω →E be the coordinate map for
every t ∈I. Then the family (Xt)t∈I is called the canonical process on (Ω, A).
Lemma 14.7 Let ∅̸= J ⊂I. Then XI
J is measurable with respect to AI – AJ .
Proof For any j ∈J, Xj = XJ
j ◦XI
J is measurable with respect to A – Aj. Thus,
by Corollary 1.82, XI
J is measurable.
⊓⊔
Theorem 14.8 Let I be countable, and for every i ∈I, let (Ωi, τi) be Polish with
Borel σ-algebra Bi = σ(τi). Let τ be the product topology on Ω = ×
i∈I
Ωi and
B = σ(τ).
Then (Ω, τ) is Polish and B = /
i∈I
Bi. In particular, B(Rd) = B(R)⊗d for
d ∈N.
Proof Without loss of generality, assume I = N. For i ∈N, let di be a complete
metric that induces τi. It is easy to check that
d(ω, ω′) :=
∞

i=1
2−i
di(ω(i), ω′(i))
1 + di(ω(i), ω′(i))
(14.2)
is a complete metric on Ω that induces τ.
Now for any i ∈N, let Di ⊂Ωi be a countable dense subset and let yi ∈Di be
an arbitrary point. It is easy to see that the set
D =

x ∈×
i∈N
Di : xi ̸= yi only ﬁnitely often

is a countable dense subset of Ω. Hence Ω is separable and thus Polish.
Now, for any i ∈I, let βi = {Bε(xi) : xi ∈Di, ε ∈Q+} be a countable base of
the topology of Ωi consisting of ε-balls. Deﬁne
β :=
∞

N=1
 N

i=1
X−1
i
(Bi) : B1 ∈β1, . . . , BN ∈βN

.
Then β is a countable base of the topology τ; hence any open set A ⊂Ω is a
(countable) union of sets in β ⊂/
i∈N Bi. Hence τ ⊂/
i∈N Bi and thus B ⊂
/
i∈N Bi.
On the other hand, each Xi is continuous and thus measurable with respect to B
– Bi. Therefore, B ⊃/
i∈N Bi.
⊓⊔
Deﬁnition 14.9 (Cylinder sets) For any i ∈I, let Ei ⊂Ai be a subclass of the
class of measurable sets.
For any A ∈AJ , X−1
J (A) ⊂Ω is called a cylinder set with base J. The set
of such cylinder sets is denoted by ZJ . In particular, if A = ×j∈J Aj for certain

306
14
Probability Measures on Product Spaces
Aj ∈Aj, then X−1
J (A) is called a rectangular cylinder with base J. The set
of such rectangular cylinders will be denoted by ZR
J . The set of such rectangular
cylinders for which in addition Aj ∈Ej for all j ∈J holds will be denoted by
ZE,R
J
.
Write
Z =

J⊂I ﬁnite
ZJ ,
(14.3)
and similarly deﬁne ZR and ZE,R. Further, deﬁne
ZR
∗=
∞

N=1
 N

n=1
An : A1, . . . , AN ∈ZR

and similarly ZE,R
∗
.
Remark 14.10 Every ZJ is a σ-algebra, and Z and ZR
∗are algebras. Furthermore,
/
i∈I Ai = σ(Z). ♦
Lemma 14.11 If every Ei is a π-system, then ZE,R is a π-system.
Proof This is left as an exercise.
⊓⊔
Theorem 14.12 For any i ∈I, let Ei ⊂Ai be a generator of Ai.
(i)
/
j∈J
Aj = σ
 ×
j∈J Ej : Ej ∈Ej ∪{Ωj}

for every countable J ⊂I.
(ii) /
i∈I
Ai = σ(ZR) = σ

ZE,R
.
(iii) Let μ be a σ-ﬁnite measure on A, and assume every Ei is also a π-system.
Furthermore, assume there is a sequence (En)n∈N in ZE,R with En ↑Ω and
μ(En) < ∞for all n ∈N (this condition is satisﬁed, for example, if μ is ﬁnite
and Ωi ∈Ei for all i ∈I). Then μ is uniquely determined by the values μ(A)
for all A ∈ZE,R.
Proof
(i) Let A′
J = σ
×
j∈J
Ej : Ej ∈Ej ∪{Ωj} for every j ∈J

. Note that
×
j∈J
Ej =

j∈J
(XJ
j )−1(Ej) ∈AJ ,
hence A′
J ⊂AJ . On the other hand, (XJ
j )−1(Ej) ∈A′
J for all j ∈J and
Ej ∈Ej. Since Ei is a generator of Ai, we have (XJ
j )−1(Aj) ∈A′
J for all
Aj ∈Aj, and hence AJ ⊂A′
J .

14.2
Finite Products and Transition Kernels
307
(ii) Evidently, ZE,R ⊂ZR ⊂A; hence also σ(ZE,R) ⊂σ(ZR) ⊂A. By
Theorem 1.81, we have σ

ZE,R
{i}

= σ(Xi) for all i ∈I; hence σ(Xi) ⊂
σ(ZE,R). Therefore, AI ⊂σ(ZE,R).
(iii) By (ii) and Lemma 14.11, ZE,R is a π-system that generates A. Hence, the
claim follows by Lemma 1.42.
⊓⊔
Reﬂection Find an example that shows that in (iii), we cannot simply drop the
assumption that there exists a sequence En ↑Ω with μ(En) < ∞. ♠
Takeaways Consider an arbitrary product of measurable spaces. The product
σ-algebra is the smallest σ-algebra such that all coordinate maps are measur-
able. It is also induced by ﬁnite dimensional cylinder sets. For a countable
product of Polish spaces, the Borel σ-algebra of the product is the product of
the Borel σ-algebras. In either case, a probability measure on the product is
uniquely determined by its values on cylinder sets.
Exercise 14.1.1 Show that
 
i∈I
Ai =

J⊂I countable
ZJ .
(14.4)
Hint: Show that the right-hand side is a σ-algebra. ♣
14.2
Finite Products and Transition Kernels
Consider now the situation of ﬁnitely many σ-ﬁnite measure spaces (Ωi, Ai, μi),
i = 1, . . . , n, where n ∈N.
Lemma 14.13 Let A ∈A1 ⊗A2 and let f : Ω1 × Ω2 →R be an A1 ⊗A2-
measurable map. Then, for all ˜ω1 ∈Ω1 and ˜ω2 ∈Ω2,
A ˜ω1 := {ω2 ∈Ω2 : ( ˜ω1, ω2) ∈A} ∈A2,
A ˜ω2 := {ω1 ∈Ω1 : (ω1, ˜ω2) ∈A} ∈A1,
f ˜ω1 : Ω2 →R,
ω2 →f ( ˜ω1, ω2)
is A2-measurable,
f ˜ω2 : Ω1 →R,
ω1 →f (ω1, ˜ω2)
is A1-measurable.
Proof For ˜ω1, deﬁne the embedding map i : Ω2 →Ω1 × Ω2 by i(ω2) = ( ˜ω1, ω2).
Note that X1 ◦i is constantly ˜ω1 (and hence A1-measurable), and X2 ◦i = idΩ2
(and hence A2-measurable). Thus, by Corollary 1.82, the map i is measurable with

308
14
Probability Measures on Product Spaces
respect to A2 – (A1 ⊗A2). Hence A ˜ω1 = i−1(A) ∈A2 and f ˜ω1 = f ◦i is
measurable with respect to A2.
⊓⊔
The following theorem generalizes Theorem 1.61.
Theorem 14.14 (Finite product measures)
There exists a unique σ-ﬁnite mea-
sure μ on A := /n
i=1 Ai such that
μ(A1 × · · · × An) =
n

i=1
μi(Ai)
for Ai ∈Ai, i = 1, . . ., n.
(14.5)
n
 
i=1
μi := μ1 ⊗· · · ⊗μn := μ is called the product measure of the μi.
If all spaces involved equal (Ω0, A0, μ0), then we write μ⊗n
0
:=
n/
i=1
μ0.
Proof Let ˜μ be the restriction of μ to ZR. Evidently, ˜μ(∅) = 0, and it is simple to
check that ˜μ is σ-ﬁnite. Let A1, A2, . . . ∈ZR be pairwise disjoint and let A ∈ZR
with A ⊂∞
k=1 Ak. Then, by the monotone convergence theorem,
˜μ(A) =

μ1(dω1) · · ·

μn(dωn) 1A((ω1, . . . , ωn))
≤

μ1(dω1) · · ·

μn(dωn)
∞

k=1
1Ak((ω1, . . . , ωn)) =
∞

k=1
˜μ(Ak).
In particular, if A = A1  A2, one similarly gets ˜μ(A) = ˜μ(A1)+ ˜μ(A2). Hence ˜μ
is a σ-ﬁnite, additive, σ-subadditive set function on the semiring ZR with ˜μ(∅) = 0.
By the measure extension theorem (Theorem 1.53), ˜μ can be uniquely extended to
a σ-ﬁnite measure on A = σ(ZR).
⊓⊔
Example 14.15 For i = 1, . . . , n, let (Ωi, Ai, Pi) be a probability space. On the
space (Ω, A, P) :=
×n
i=1 Ωi, /n
i=1 Ai, /n
i=1 Pi

, the coordinate maps Xi :
Ω →Ωi are independent with distribution PXi = Pi. ♦
In order to formulate Fubini’s theorem rigorously, we need the following
deﬁnition.
Deﬁnition 14.16 Let (Ω, A, μ) a measure space and (Ω′, A′) a measurable space.
Let N ∈A with μ(N) = 0. A map f : Ω\N →Ω′ is called a μ-almost everywhere
deﬁned and measurable map from (Ω, A) to (Ω′, A′), if f −1(A′) ⊂A.
Remark 14.17 Let g, h : Ω →R be measurable ﬁnite almost everywhere. Then
g −h is almost everywhere deﬁned and measurable. In particular, this holds if g and
h are integrable. ♦

14.2
Finite Products and Transition Kernels
309
Remark 14.18 Assume that f is almost everywhere deﬁned and measurable (with
null set N) and takes values in R. Deﬁne f ′(ω) = 0 for ω ∈N and f ′(ω) = f (ω)
else. Then f ′ is measurable (and everywhere deﬁned). If f ′ is integrable, then we
can deﬁne the integral
3
f dμ :=
3
f ′dμ. ♦
Theorem 14.19 (Fubini)
Let (Ωi, Ai, μi) be σ-ﬁnite measure spaces, i = 1, 2.
Let f : Ω1 × Ω2 →R be measurable with respect to A1 ⊗A2. If f ≥0 or
f ∈L1(μ1 ⊗μ2), then
ω1 →

f (ω1, ω2) μ2(dω2) is μ1-a.e. deﬁned and A1-measurable,
ω2 →

f (ω1, ω2) μ1(dω1) is μ2-a.e. deﬁned and A2-measurable,
(14.6)
and

Ω1×Ω2
f d(μ1 ⊗μ2) =

Ω1

Ω2
f (ω1, ω2) μ2(dω2)

μ1(dω1)
=

Ω2

Ω1
f (ω1, ω2) μ1(dω1)

μ2(dω2).
(14.7)
Proof The proof follows the usual procedure of stepwise approximations, starting
with an indicator function.
We ﬁrst show the statement for nonnegative f . There are functions hi : Ωi →
(0, ∞) such that
3
hi dμi < ∞, i = 1, 2 (see Lemma 6.23). Now write
f (ω1, ω2) =
f (ω1, ω2)
h1(ω1)h2(ω2) · h1(ω1)h2(ω2).
Hence, it is enough to show the statement for the ﬁnite measures ˜μi := hiμi instead
of μi, i = 1, 2.
Now assume that μ1 and μ2 are ﬁnite measures. First let f = 1A for A =
A1 × A2 with A1 ∈A1 and A2 ∈A2. Then (14.6) and (14.7) hold trivially.
Now consider the set G ⊂A1 ⊗A2 such that A ∈G if and only if (14.6)
and (14.7) hold for f = 1A. It is easy to see that G is a Dynkin system. In fact,
Ω1 × Ω2 ∈G is trivial. If A ∈G and f = 1Ω1×Ω2\A, then clearly
ωi →

f (ω1, ω2) μ3−i(dω3−i)
= μ3−i(Ω3−i) −

1A(ω1, ω2) μ3−i(dω3−i) is Ai-measurable,
for i = 1, 2. Similarly, (14.7) holds. Hence, G is stable under complements.

310
14
Probability Measures on Product Spaces
Finally, for pairwise disjoint sets A1, A2, . . . ∈G and A := A1 ∪A2 ∪. . ., we
have
ωi →

1A(ω1, ω2) μ3−i(dω3−i)
=
∞

n=1

1An(ω1, ω2) μ3−i(dω3−i) is Ai-measurable,
for i = 1, 2. Similarly, (14.7) holds for f = 1A. Hence A ∈G.
Now, G is a Dynkin system that contains a ∩-stable generator of A1⊗A2 (namely,
the cylinder sets A1 × A2, A1 ∈A1, A2 ∈A2). Hence G = A1 ⊗A2 by Dynkin’s
π-λ theorem (Theorem 1.19).
We have thus shown that (14.6) and (14.7) hold for f = 1A for all A ∈A1 ⊗A2.
Building ﬁnite sums, (14.6) and (14.7) also hold if f is a simple function.
Consider now f
≥0. Then, by Theorem 1.96, there exists a sequence of
simple functions (fn)n∈N with fn ↑f . By the monotone convergence theorem
(Theorem 4.20), (14.6) and (14.7) also hold for this f .
Now let f ∈L1(μ1 ⊗μ2). Then f = f + −f −with f +, f −≥0 being
integrable functions. Since (14.6) and (14.7) hold for f −and f +, by Remark 14.17
and 14.18 this is true for f also.
⊓⊔
Reﬂection Come up with an example of a measurable function f such that the
integrals on the right hand side of (14.7) both exist but do not coincide. Which
condition of the theorem would be violated? ♠
In Deﬁnition 2.32, we deﬁned the convolution of two real probability measures
μ and ν as the distribution of the sum of two independent random variables with
distributions μ and ν, respectively. As a simple application of Fubini’s theorem, we
can give a new deﬁnition for the convolution of, more generally, ﬁnite measures on
Rn. Of course, for real probability measures, it coincides with the old deﬁnition. If
the measures have Lebesgue densities, then we obtain an explicit formula for the
density of the convolution.
Let X and Y be Rn-valued random variables with densities fX and fY . That is,
fX, fY : Rn →[0, ∞] are measurable and integrable with respect to n-dimensional
Lebesgue measure λn and, for all x ∈Rn,
P[X ≤x] =

(−∞,x]
fX(t) λn(dt)
and
P[Y ≤x] =

(−∞,x]
fY (t) λn(dt).
Here (−∞, x] = {y ∈Rn : yi ≤xi for i = 1, . . . , n} (compare (1.5)).
Deﬁnition 14.20 Let n ∈N. For two Lebesgue integrable maps f, g : Rn →
[0, ∞], deﬁne the convolution f ∗g : Rn →[0, ∞] by
(f ∗g)(x) =

Rn f (y) g(x −y) λn(dy).

14.2
Finite Products and Transition Kernels
311
For two ﬁnite measures μ, ν ∈Mf (Rn), deﬁne the convolution μ ∗ν ∈Mf (Rn)
by
(μ ∗ν)((−∞, x]) =
 
1Ax(u, v) μ(du) ν(dv),
where Ax := {(u, v) ∈Rn × Rn : u + v ≤x}.
Lemma 14.21 The map f ∗g is measurable and we have f ∗g = g ∗f and

Rn(f ∗g) dλn =

Rn f dλn
 
Rn g dλn

.
Furthermore, μ ∗ν = ν ∗μ and (μ ∗ν)(Rn) = μ(Rn) ν(Rn).
Proof The claims follow immediately from Fubini’s theorem.
⊓⊔
Theorem 14.22 (Convolution of n-dimensional measures)
(i) If X and Y are independent Rn-valued random variables with densities fX and
fY , then X + Y has density fX ∗fY .
(ii) If μ = f λn and ν = gλn are ﬁnite measures with Lebesgue densities f and g,
then μ ∗ν = (f ∗g)λn.
Proof
(i) Let x ∈Rn and A := {(u, v) ∈Rn × Rn : u + v ≤x}. Repeated application of
Fubini’s theorem and the translation invariance of λn yields
P[X + Y ≤x] = P[(X, Y) ∈A]
=

Rn×Rn 1A(u, v) fX(u) fY (v)

λn⊗2 (d(u, v))
=

Rn

Rn 1A(u, v) fX(u) λn(du)

fY (v) λn(dv)
=

Rn

(−∞,x−v]
fX(u) λn(du)

fY (v) λn(dv)
=

Rn

(−∞,x]
fX(u −v) λn(du)

fY (v) λn(dv)
=

(−∞,x]

Rn fX(u −v) fY (v) λn(dv)

λn(du)
=

(−∞,x]
(fX ∗fY ) dλn.
(ii) In (i), replace μ by PX and ν by PY . The claim is immediate.
⊓⊔

312
14
Probability Measures on Product Spaces
We come next to a concept that generalizes the notion of product measures and
points in the direction of the example from the introduction to this chapter.
Recall the deﬁnition of a transition kernel from Deﬁnition 8.25.
Lemma 14.23 Let κ be a ﬁnite transition kernel from (Ω1, A1) to (Ω2, A2) and let
f : Ω1 × Ω2 →[0, ∞] be measurable with respect to A1 ⊗A2 −B([0, ∞]). Then
the map
If : Ω1 →[0, ∞],
ω1 →

f (ω1, ω2) κ(ω1, dω2)
is well-deﬁned and A1-measurable.
Proof By Lemma 14.13, for every ω1 ∈Ω1, the map fω1 is measurable with respect
to A2; hence If (ω1) =
3
fω1(ω2) κ(ω1, dω2) is well-deﬁned. Hence, it remains to
show measurability of If .
If g = 1A1×A2 for some A1 ∈A1 and A2 ∈A2, then clearly Ig(ω1) =
1A1(ω1)κ(ω1, A2) is measurable. Now let
D = 	A ∈A1 ⊗A2 : I1A is A1-measurable
.
We show that D is a λ-system:
(i) Evidently, Ω1 × Ω2 ∈D.
(ii) If A, B ∈D with A ⊂B, then I1B\A = I1B −I1A is measurable, where we
used the fact that κ is ﬁnite; hence B \ A ∈D.
(iii) If A1, A2, . . . ∈D are pairwise disjoint and A := ∞
n=1 An, then I1A =
∞
n=1 I1An is measurable; hence A ∈D.
Summarising, D is a λ-system that contains a π-system that generates A1 ⊗A2
(namely, the rectangles). Hence, by the π–λ theorem (Theorem 1.19), D = A1⊗A2.
Hence I1A is measurable for all A ∈A1 ⊗A2. We infer that Ig is measurable for
any simple function g. Now let (fn)n∈N be a sequence of simple functions with
fn ↑f . For any ﬁxed ω1 ∈Ω1, by the monotone convergence theorem, If (ω1) =
limn→∞Ifn(ω1). As a limit of measurable functions, If is measurable.
⊓⊔
Remark 14.24 In the following, we often write 3 κ(ω1, dω2) f (ω1, ω2) instead of
3 f (ω1, ω2) κ(ω1, dω2) since for multiple integrals this notation allows us to write
the integrator closer to the corresponding integral sign. ♦
Theorem 14.25 Let (Ωi, Ai), i = 0, 1, 2, be measurable spaces. Let κ1 be a ﬁnite
transition kernel from (Ω0, A0) to (Ω1, A1) and let κ2 be a ﬁnite transition kernel
from (Ω0 × Ω1, A0 ⊗A1) to (Ω2, A2). Then the map
κ1 ⊗κ2 : Ω0 × (A1 ⊗A2) →[0, ∞),
(ω0, A) →

Ω1
κ1(ω0, dω1)

Ω2
κ2((ω0, ω1), dω2) 1A((ω1, ω2))

14.2
Finite Products and Transition Kernels
313
is well-deﬁned and is a σ-ﬁnite (but not necessarily a ﬁnite) transition kernel from
(Ω0, A0) to (Ω1 × Ω2, A1 ⊗A2). If κ1 and κ2 are (sub)stochastic, then κ1 ⊗κ2 is
(sub)stochastic. We call κ1 ⊗κ2 the product of κ1 and κ2.
If κ2 is a kernel from (Ω1, A1) to (Ω2, A2), then we deﬁne the product κ1 ⊗κ2
similarly by formally understanding κ2 as a kernel from (Ω0 × Ω1, A0 ⊗A1) to
(Ω2, A2) that does not depend on the Ω0-coordinate.
Proof Let A ∈A1 ⊗A2. By Lemma 14.23, the map
gA : (ω0, ω1) →

κ2((ω0, ω1), dω2) 1A(ω1, ω2)
is well-deﬁned and A0 ⊗A1-measurable. Thus, again by Lemma 14.23, the map
ω0 →κ1 ⊗κ2(ω0, A) =

κ1(ω0, dω1) gA(ω0, ω1)
is well-deﬁned and A0-measurable. For ﬁxed ω0, by the monotone convergence
theorem, the map A →κ1 ⊗κ2(ω0, A) is σ-additive and thus a measure.
For ω0 ∈Ω0 and n ∈N, let Aω0,n := {ω1 ∈Ω1 : κ2((ω0, ω1), Ω2) < n}.
Since κ2 is ﬁnite, we have 
n≥1 Aω0,n = Ω1 for all ω0 ∈Ω0. Furthermore,
κ1 ⊗κ2(ω0, An × Ω2) ≤n · κ1(ω0, An) < ∞. Hence κ1 ⊗κ2(ω0, ·) is σ-ﬁnite and
is thus a transition kernel.
The supplement is trivial.
⊓⊔
Corollary 14.26 (Products via kernels) Let (Ω1, A1, μ) be a ﬁnite measure
space, let (Ω2, A2) be a measurable space and let κ be a ﬁnite transition kernel from
Ω1 to Ω2. Then there exists a unique σ-ﬁnite measure μ⊗κ on (Ω1×Ω2, A1⊗A2)
with
μ ⊗κ(A1 × A2) =

A1
κ(ω1, A2) μ(dω1)
for all A1 ∈A1, A2 ∈A2.
If κ is stochastic and if μ is a probability measure, then μ ⊗κ is a probability
measure.
Proof Apply Theorem 14.25 with κ2 = κ and κ1(ω0, ·) = μ.
⊓⊔
Corollary 14.27 Let n ∈N and let (Ωi, Ai), i = 0, . . . , n, be measurable spaces.
For i = 1, . . . , n, let κi be a substochastic kernel from
 i−1
×
k=0
Ωk,
i−1
/
k=0
Ak

to
(Ωi, Ai) or from (Ωi−1, Ai−1) to (Ωi, Ai). Then the recursion κ1 ⊗· · · ⊗κi :=
(κ1 ⊗· · · ⊗κi−1) ⊗κi for any i = 1, . . . , n deﬁnes a substochastic kernel
i/
k=1
κk := κ1⊗· · ·⊗κi from (Ω0, A0) to

i×
k=1
Ωk,
i/
k=1
Ak

. If all κk are stochastic,
then all
i/
k=1
κk are stochastic.

314
14
Probability Measures on Product Spaces
If μ is a ﬁnite measure on (Ω0, A0), then μi := μ⊗
i/
k=1
κk is a ﬁnite measure on

i×
k=0
Ωk,
i/
k=0
Ak

. If μ is a probability measure and if every κi is stochastic, then
μi is a probability measure.
Proof The claims follow inductively by Theorem 14.25.
⊓⊔
Deﬁnition 14.28 (Composition of kernels) Let (Ωi, Ai) be measurable spaces,
i = 0, 1, 2, and let κi be a substochastic kernel from (Ωi−1, Ai−1) to (Ωi, Ai),
i = 1, 2. Deﬁne the composition of κ1 and κ2 by
κ1 · κ2 : Ω0 × A2 →[0, ∞),
(ω0, A2) →

Ω1
κ1(ω0, dω1) κ2(ω1, A2).
Theorem 14.29 If we denote by π2 : Ω1 × Ω2 →Ω2 the projection to the second
coordinate, then
(κ1 · κ2)(ω0, A2) = (κ1 ⊗κ2)

ω0, π−1
2 (A2)

for all A2 ∈A2.
In particular, the composition κ1 · κ2 is a (sub)stochastic kernel from (Ω0, A0) to
(Ω2, A2).
Proof This is obvious.
⊓⊔
Lemma 14.30 (Kernels and convolution) Let μ and ν be probability measures
on Rd and deﬁne the kernels κi : (Rd, B(Rd)) →(Rd, B(Rd)), i = 1, 2, by
κ1(x, dy) = μ(dy) and κ2(y, dz) = (δy ∗ν)(dz). Then κ1 · κ2 = μ ∗ν.
Proof This is trivial.
⊓⊔
Theorem 14.31 (Kernels and convolution) Assume X1, X2, . . . are independent
Rd-valued random variables with distributions μi := PXi, i = 1, . . . , n. Let Sk :=
X1 + . . . + Xk for k = 1, . . . , n, and deﬁne stochastic kernels from Rd to Rd by
κk(x, ·) = δx ∗μk for k = 1, . . . , n. Then
 n
 
k=1
κk

(0, ·) = P(S1,...,Sn).
(14.8)
Proof For k = 1, . . ., n, deﬁne the measurable bijection ϕk : (Rd)k →(Rd)k by
ϕk(x1, . . . , xk) = (x1, x1 + x2, . . . , x1 + . . . + xk).

14.2
Finite Products and Transition Kernels
315
Evidently, B((Rd)n) = σ

ϕn(A1 × · · · × An) : A1, . . . , An ∈B(Rd). Hence, it is
enough to show (14.8) for sets of this type. That is, it is enough to show that

n
 
k=1
κk

(0, ϕn(A1 × · · · × An)) = P(S1,...,Sn)(ϕn(A1 × · · · × An)) =
n

k=1
μk(Ak).
For n = 1, this is clear. By deﬁnition, κn(yn−1, yn−1 + An) = μn(An). Inductively,
we get

n
 
k=1
κk

(0, ϕn(A1 × · · · × An))
=

ϕn−1(A1×···×An−1)
 n−1
 
k=1
κk

0, d(y1, . . . , yn−1)

κn

yne−1, yn−1 + An

=
 n−1

k=1
μk(Ak)

μn(An).
⊓⊔
Theorem 14.32 (Fubini for transition kernels)
Let (Ωi, Ai) be measurable
spaces, i = 1, 2. Let μ be a ﬁnite measure on (Ω1, A1) and let κ be a ﬁnite
transition kernel from Ω1 to Ω2. Assume that f : Ω1 × Ω2 →R is measurable
with respect to A1 ⊗A2. If f ≥0 or f ∈L1(μ ⊗κ), then

Ω1×Ω2
f d(μ ⊗κ) =

Ω1

Ω2
f (ω1, ω2) κ(ω1, dω2)

μ(dω1).
(14.9)
Proof For f
=
1A1×A2 with A1
∈
A1 and A2
∈
A2, the statement is
true by deﬁnition. For general f , apply the usual approximation argument as in
Theorem 14.19.
⊓⊔
Example 14.33 We come back to the example from the beginning of this chapter.
Let n ∈N and let (Ω2, A2) =

{0, 1}n, (2{0,1})⊗n
be the space of n-fold coin
tossing. For any p ∈[0, 1], deﬁne
Pp = (Berp)⊗n =

(1 −p)δ0 + pδ1
⊗n.
Pp is that probability measure on (Ω2, A2) under which the coordinate maps Yi are
independent Bernoulli random variables with success probability p.
Further, let Ω1 = [0, 1], let A1 = B([0, 1]) be the Borel σ-algebra on Ω1 and let
μ = U[0,1] be the uniform distribution on [0, 1]. Then the identity map X : Ω1 →
[0, 1] is a random variable on (Ω1, A1, μ) that is uniformly distributed on [0, 1].
Finally, consider the stochastic kernel κ from Ω1 to Ω2, deﬁned by
κ(ω1, A2) = Pω1(A2).

316
14
Probability Measures on Product Spaces
If we let Ω = Ω1 × Ω2, A = A1 ⊗A2 and P = μ ⊗κ, then X and Y1, . . . , Yn
describe precisely the random variables on (Ω, A, P) from the beginning of this
chapter. ♦
Remark 14.34 The procedure can be extended to n-stage experiments. Let (Ωi, Ai)
be the measurable space of the ith experiment, i = 0, . . . , n −1. Let P0 be a
probability measure on (Ω0, A0). Assume that for i = 1, . . . , n−1, the distribution
on (Ωi, Ai) depends on (ω1, . . . , ωi−1) and is given by a stochastic kernel κi from
Ω0 × · · · × Ωi−1 to Ωi. The whole n-stage experiment is then described by the
coordinate maps on the probability space

n−1
×
i=0
Ωi,
n−1
/
i=0
Ai, P0 ⊗
n−1
/
i=1
κi

. ♦
Takeaways For ﬁnite products of measurable spaces, we deﬁne the product
measure. The integral of an integrable function on the product space can be
computed by successive integration (in arbitrary order) over the individual
coordinates (Fubini’s theorem).
Depending on the outcome of a random experiment, we choose the
distribution of a second random experiment (in a measurable way). The cor-
responding map is called a stochastic kernel. By concatenation of stochastic
kernels we construct multi-step random experiments. This procedure leads to
a generalisation of the concept of a product measure.
Exercise 14.2.1 Show the following convolution formulas.
(i) Normal distribution: Nμ1,σ 2
1 ∗Nμ2,σ 2
2 = Nμ1+μ2,σ 2
1 +σ 2
2
for all μ1, μ2 ∈R
and σ 2
1 , σ 2
2 > 0.
(ii) Gamma distribution: Γθ,r ∗Γθ,s = Γθ,r+s for all θ, r, s > 0.
(iii) Cauchy distribution: Caur ∗Caus = Caur+s for all r, s > 0. ♣
Exercise 14.2.2 (Hilbert–Schmidt operator) Let (Ωi, Ai, μi), i = 1, 2, be σ-
ﬁnite measure spaces and let a : Ω1 × Ω2 →R be measurable with

μ1(dt1)

μ2(dt2) a(t1, t2)2 < ∞.
For f ∈L2(μ1), deﬁne
(Af )(t2) =

a(t1, t2)f (t1) μ1(dt1).
Show that A is a continuous linear operator from L2(μ1) to L2(μ2). ♣
Exercise 14.2.3 (Partial integration) Let Fμ and Fν be the distribution functions
of locally ﬁnite measures μ and ν on R. For x ∈R, deﬁne the left-sided limit

14.3
Kolmogorov’s Extension Theorem
317
F(x−) = supy<x F(y) and the jump height ΔF(x) = F(x) −F(x−). Show that,
for a < b,

(a,b]
Fμ dν = Fμ(b)Fν(b) −Fμ(a)Fν(a) −

(a,b]
Fν(x−)μ(dx)
= Fμ(b)Fν(b) −Fμ(a)Fν(a) −

(a,b]
Fν dμ +

a<x≤b
ΔFμ(x) ΔFν(x).
♣
(14.10)
14.3
Kolmogorov’s Extension Theorem
In the previous section, we saw how we can implement n-stage experiments on
a probability space. In this section, we ﬁrst show how to implement countably
many successive experiments on one probability space (Ionescu–Tulcea’s theorem).
Thereafter we also construct probability measures on products of uncountably many
spaces (Kolmogorov’s extension theorem).
Let (Ωi, Ai), i ∈N0, be measurable spaces and let P0 be a probability measure
on (Ω0, A0). Let Ωi := ×i
k=0 Ωk and Ai = /i
k=0 Ak and
Ω :=
∞×
k=0
Ωk
and
A =
∞
 
k=0
Ak.
For every i ∈N, let κi be a stochastic kernel from (Ωi−1, Ai−1) to (Ωi, Ai). In
Corollary 14.27, we deﬁned inductively probability measures Pi = P0 ⊗/i
k=1 κk
on (Ωi, Ai). By construction, for i, j ≥k and A ∈Ak, we had
Pi(A × Ωk+1 × · · · × Ωi) = Pj(A × Ωk+1 × · · · × Ωj).
(14.11)
Now we want to deﬁne a probability measure P on (Ω, A) such that for k ∈N0 and
A ∈Ak
P

A ×
∞×
i=k+1
Ωi

= Pk(A).
(14.12)
Theorem 14.35 (Ionescu–Tulcea)
There is a uniquely determined probability
measure P on (Ω, A) such that (14.12) holds.
Proof Uniqueness is clear since the ﬁnite-dimensional rectangular cylinders form a
π-system that generates A. It remains to show the existence of that measure.
We use (14.12) to deﬁne a set function P on cylinder sets. Clearly, P is additive
and is hence a content. If we can show that P is ∅-continuous, then P is a

318
14
Probability Measures on Product Spaces
premeasure (by Theorem 1.36) and thus by Carathéodory’s theorem (Theorem 1.41)
can be extended uniquely to a measure on A.
Hence, let A0 ⊃A1 ⊃A2 ⊃. . . be a sequence in Z with α := infn∈N0 P(An) >
0. It is enough to show that ∞
n=0 An ̸= ∅. Without loss of generality, we can assume
that An = A′
n × ×∞
k=n+1 Ωk for certain A′
n ∈An. For n ≥m, deﬁne
hm,n(ω0, . . . , ωm) :=

δ(ω0,...,ωm) ⊗
n
 
k=m+1
κk


A′
n

and hm := infn≥m hm,n. Inductively, we show that for every i ∈N0, there exists a
ϱi ∈Ωi such that
hm(ϱ0, . . . , ϱm) ≥α.
(14.13)
Since A′
n+1 ⊂A′
n × Ωn+1, we have
hm,n+1(ω0, . . . , ωm) =

δ(ω0,...,ωm) ⊗
n+1
 
k=m+1
κk


A′
n+1

≤

δ(ω0,...,ωm) ⊗
n+1
 
k=m+1
κk


A′
n × Ωn+1

=

δ(ω0,...,ωm) ⊗
n
 
k=m+1
κk


A′
n

= hm,n(ω0, . . . , ωm).
Hence hm,n ↓hm for n →∞and by the monotone convergence theorem,

hm dPm = inf
n≥m

hm,n dPm = inf
n∈N0
Pn(A′
n) = α,
whence we have (14.13) for m = 0. Now assume that (14.13) holds for m ∈N0.
Then

hm+1(ϱ0, . . . , ϱm, ωm+1) κm+1

(ϱ0, . . . , ϱm), dωm+1

=
inf
n≥m+1

hm+1,n(ϱ0, . . . , ϱm, ωm+1) κm+1

(ϱ0, . . . , ϱm), dωm+1

= hm(ϱ0, . . . , ϱm) ≥α.
Hence (14.13) holds for m + 1.

14.3
Kolmogorov’s Extension Theorem
319
Let ϱ := (ϱ0, ϱ1, . . .) ∈Ω. By construction,
α ≤hm,m(ϱ0, . . . , ϱm) = 1A′m(ϱ0, . . . , ϱm),
hence ϱ ∈Am for all m ∈N0 and thus ∞
i=0 Ai ̸= ∅.
⊓⊔
Corollary 14.36 (Product measure) For every n ∈N0, let Pn be a probability
measure on (Ωn, An). Then there exists a uniquely determined probability measure
P on (Ω, A) with
P

A0 × · · · × An ×
∞×
i=n+1
Ωi

=
n

k=0
Pk(Ak)
for Ai ∈Ai, i = 0, . . . , n and n ∈N0.
/∞
i=0 Pi := P is called the product of the measures P0, P1, . . .. Under P, the
coordinate maps (Xi)i∈N0 are independent.
Proof This follows by Ionescu–Tulcea’s theorem with κi((ω0, . . . , ωi−1), ·) = Pi.
⊓⊔
We want to make a statement similar to that of Ionescu–Tulcea’s theorem;
however, without the assumption that the measures Pk are deﬁned a priori by
kernels. Before we formulate the theorem, we generalize the consistency condition
(14.11). Recall that for L ⊂J ⊂I, XJ
L : ΩJ −→ΩL denotes the canonical
projection.
Deﬁnition 14.37 A family (PJ , J ⊂I ﬁnite) of probability measures on the space
(ΩJ, AJ ) is called consistent if
PL = PJ ◦

XJ
L
−1
for all L ⊂J ⊂I ﬁnite.
Recall that Ω = ×
i∈I
Ωi and A = /
i∈I
Ai. Let P be a probability measure on
(Ω, A). Since XL = XJ
L ◦XJ, the family (PJ := P ◦X−1
J , J ⊂I ﬁnite) is
consistent. Thus, consistency is a necessary condition for the existence of a measure
P on the product space with PJ := P ◦X−1
J . If all the measurable spaces are Borel
spaces (recall Deﬁnition 8.35), for example Rd, Zd, C([0, 1]) or more general Polish
spaces, then this condition is also sufﬁcient. We formulate this statement ﬁrst for a
countable index set.
Theorem 14.38 Let I be countable and let (Ωi, Ai) be Borel spaces for all i ∈I.
Let (PJ , J ⊂I ﬁnite) be a consistent family of probability measure. Then there
exists a unique probability measure P on (Ω, A) with PJ = P ◦X−1
J
for all ﬁnite
J ⊂I.

320
14
Probability Measures on Product Spaces
Proof Without loss of generality, assume I = N0. Let Pn := P{0,...,n}, Ωn :=
Ω{0,...,n} and An := A{0,...,n}. It is easy to check that ﬁnite products of Borel spaces
are again Borel spaces; hence (Ωn, An) is Borel for all n ∈N0.
Let F := {A × Ωn+1 : A ∈An}, Y : Ωn+1 →Ωn+1, (ω0, . . . , ωn+1) →ωn+1
and Z : Ωn+1 →Ωn, (ω0, . . . , ωn+1) →(ω0, . . . , ωn). By Theorem 8.37 (with
Ω = Ωn+1, A = An+1 and E = Ωn+1), there is a stochastic kernel κ′
n+1 from
(Ωn+1, F) to (Ωn+1, An+1) such that κ′
n+1 is a regular conditional distribution of
Y given F (under the probability measure Pn+1). Hence, for A ∈An and B ∈An+1,
we have (compare (8.11))
Pn+1(A × B) =

1B(Y) 1A×Ωn+1 dPn+1 =

κ′
n+1( ·, B) 1A×Ωn+1 dPn+1.
Since κ′
n+1( ·, B) is F-measurable, there is a stochastic kernel κn+1 from (Ωn, An)
to (Ωn+1, An+1) such that
κn+1
(ω0, . . . , ωn), · = κ′
n+1
(ω0, . . . , ωn+1), ·
for all ω0, . . . , ωn+1.
Hence
κ′
n+1( ·, B) = κn+1(Z( ·), B)
and
1A×Ωn+1 = 1A(Z).
We infer that
Pn+1(A × B) =

κn+1(Z, B) 1A(Z) dPn+1
=

κn+1( ·, B) 1A d

Pn+1 ◦Z−1
=

A
κn+1( ·, B) dPn.
Note that in the last equality we used the fact that (Pn)n∈N0 is a projective family.
By Corollary14.26, we get Pn+1 = Pn ⊗κn+1. Recursively, we obtain Pn = P0 ⊗
/n
k=1 κk for all n ∈N. Using Theorem 14.35, this yields the claim.
⊓⊔
The last step in our construction is to replace the countable index set I by an
arbitrary index set.
Theorem 14.39 (Kolmogorov’s extension theorem) Let I be an arbitrary index
set and let (Ωi, Ai) be Borel spaces, i ∈I. Let (PJ , J ⊂I ﬁnite) be a consistent
family of probability measures. Then there exists a unique probability measure P on
(Ω, A) with PJ = P ◦X−1
J
for every ﬁnite J ⊂I. P is called the projective limit
and will be denoted by P =: lim
←−
J↑I
PJ .

14.3
Kolmogorov’s Extension Theorem
321
Proof For countable J ⊂I, by Theorem 14.38, there is a unique probability
measure PJ on (ΩJ , AJ ) with PJ ◦(XJ
K)−1 = PK for ﬁnite K ⊂J. By deﬁning
˜PJ (X−1
J (AJ )) := PJ (AJ) for AJ ∈AJ , we get a probability measure ˜PJ on
(Ω, σ(XJ)).
Let J, J ′ ⊂I be countable and let A ∈σ(XJ )∩σ(XJ ′)∩Z be a σ(XJ )∩σ(XJ ′)-
measurable cylinder with a ﬁnite base. Then there exists a ﬁnite K ⊂J ∩J ′ and
AK ∈AK with A = X−1
K (AK). Hence ˜PJ (A) = PK(AK) = ˜PJ ′(A). Moreover, by
Theorem 14.12, ˜PJ (A) = PK(AK) = ˜PJ ′(A) for all A ∈σ(XJ ) ∩σ(XJ ′). Now,
by Exercise 14.1.1, for any A ∈A, there is a countable J ⊂I with A ∈σ(XJ ).
Hence, independently of the choice of J, we can uniquely deﬁne a set function P on
A by P(A) = ˜PJ (A). It remains to show that P is a probability measure. Evidently,
P(Ω) = 1. If A1, A2, . . . ∈A are pairwise disjoint and A := ∞
n=1 An, then for
any n ∈N, there is a countable Jn ⊂I with An ∈σ(XJn). Deﬁne J = 
n∈N Jn.
Then each An is in σ(XJ ); thus A ∈σ(XJ ). Therefore,
P(A) = ˜PJ (A) =
∞

n=1
˜PJ (An) =
∞

n=1
P(An).
This shows that P is a probability measure.
⊓⊔
Example 14.40 Let

(Ωi, τi), i ∈I

be an arbitrary family of Polish spaces (recall
from Theorem 8.36 that Polish spaces are also Borel spaces). Let Ai = σ(τi) and
let Pi be an arbitrary probability measure on (Ωi, Ai) for every i ∈I. For ﬁnite
J ⊂I, let PJ := /
j∈J Pj be the product measure of the Pj, j ∈J. Evidently, the
family (PJ, J ⊂I ﬁnite) is consistent. We call
P =
 
i∈I
Pi := lim
←−
J↑I
PJ
the product measure on (Ω, A). Under P, all coordinate maps Xj are independent.
♦
Example 14.41 (Pólya’s urn model) (Compare Example 12.29.) In an urn there are
initially k red and n −k blue balls. At each step, one ball is drawn at random and is
returned to the urn with an additional ball of the same color. Hence, at time i ∈N0
there are n + i balls in the urn. The random number of red balls is denoted by Xi.
For a more formal description, let n ∈N and k ∈{0, . . . , n}. Let I = N0, Ωi =
{0, . . ., n + i}, i ∈N. Let P0[{k}] = 1, and deﬁne the stochastic kernels κi from Ωi
to Ωi+1 by
κi(xi, {xi+1}) =
⎧
⎪⎪⎨
⎪⎪⎩
xi
n+i ,
if xi+1 = xi + 1,
1 −
xi
n+i ,
if xi+1 = xi,
0,
else.

322
14
Probability Measures on Product Spaces
Now let Pi+1 = Pi ⊗κi. Under the measure P = lim
←−
i→∞
Pi, the projections (Xi, i ∈
N0) describe Pólya’s urn model. ♦
Takeaways Consider an inﬁnite product of Borel measure spaces. A family
of probability measures on all ﬁnite products of these spaces is called pro-
jective if the image measures under projections coincide. By Kolmogorov’s
theorem, for a projective family, there exists a probability measure on the
inﬁnite product space such that the projections coincide with the original
measures we started with. This is a universal construction of a probability
measure on the product space and it allows in a very ﬂexible way to construct
the large probability spaces needed for the deﬁnition of stochastic processes.
As a particularly simple application, we get an inﬁnite product measure such
that all coordinate maps are independent with a desired distribution.
14.4
Markov Semigroups
Deﬁnition 14.42 Let E be a Polish space. Let I ⊂R be a nonempty index set and
let (κs,t : s, t ∈I, s < t) be a family of stochastic kernels from E to E. We say
that the family is consistent if κr,s · κs,t = κr,t for any choice of r, s, t ∈I with
r < s < t.
Deﬁnition 14.43 Let E be a Polish space. Let I ⊂[0, ∞) be an additive semigroup
(for example, I = N0 or I = [0, ∞)). A family (κt : t ∈I) of stochastic kernels is
called a semigroup of stochastic kernels, or a Markov semigroup, if
κ0(ω, ·) = δω
for all ω ∈E
(14.14)
and if it satisﬁes the Chapman–Kolmogorov equation:
κs · κt = κs+t
for all s, t ∈I.
(14.15)
Indeed, ({κt : t ∈I}, ·) is a semigroup in the algebraic sense and the map t →κt
is a homomorphism of semigroups. In particular, the kernels commute in the sense
that κs · κt = κt · κs for all s, t ∈I.
Lemma 14.44 If (κt : t ∈I) is a Markov semigroup, then the family of kernels,
deﬁned by ˜κs,t := κt−s for t > s, is consistent.
Proof This is trivial.
⊓⊔

14.4
Markov Semigroups
323
Theorem 14.45 (Kernel via a consistent family of kernels) Let I ⊂[0, ∞) with
0 ∈I and let (κs,t : s, t ∈I, s < t) be a consistent family of stochastic kernels on
the Polish space E. Then there exists a kernel κ from (E, B(E)) to (EI, B(E)⊗I)
such that, for all x ∈E and for any choice of ﬁnitely many numbers 0 = j0 < j1 <
j2 < . . . < jn from I, and with the notation J := {j0, . . . , jn}, we have
κ(x, ·) ◦X−1
J
=

δx ⊗
n−1
 
k=0
κjk,jk+1

.
(14.16)
Proof First we show that, for ﬁxed x ∈E, (14.16) deﬁnes a probability measure
κ(x, ·). Deﬁne the family (PJ : J ⊂I ﬁnite, 0 ∈J) by PJ := δx⊗
n−1
/
k=0
κjk,jk+1. By
Kolmogorov’s extension theorem, it is enough to show that this family is consistent.
In fact, if for 0 ̸∈J ⊂I ﬁnite, we deﬁne PJ as the projection of PJ∪{0} to EJ, then
the family (PJ : J ⊂I ﬁnite) is projective. Hence, let 0 ∈L ⊂J ⊂I with J ⊂I
ﬁnite. We have to show that PJ ◦(XJ
L)−1 = PL. We may assume that L = J \ {jl}
for some l = 1, . . ., n. The general case can be inferred inductively.
First consider l = n. Let Aj0, . . . , Ajn−1 ∈B(E) and A := ×j∈L Aj. Then
PJ ◦(XJ
L)−1(A) = PJ (A × E) = PL ⊗κjn−1,jn(A × E)
=

A
PL

d(ω0, . . . , ωn−1)

κjn−1,jn(ωn−1, E) = PL(A).
Now let l ∈{1, . . . , n −1}. For all j ∈L, let Aj ∈B(E) and Ajl := E. Deﬁne
A := ×j∈L Aj, and abbreviate A′ = ×l−1
k=0 Ajk and P ′ = δx ⊗/l−2
k=0 κjk,jk+1. For
i = 0, . . . , n −1, let
fi(ωi) =
n−1
 
k=i
κjk,jk+1

(ωi, Aji+1 × · · · × Ajn).
By assumption and using Fubini’s theorem, we get
fl−1(ωl−1) =

E
κjl−1,jl(ωl−1, dωl)

Ajl+1
κjl,jl+1(ωl, dωl+1) fl+1(ωl+1)
=

Ajl+1
κjl−1,jl+1(ωl−1, dωl+1) fl+1(ωl+1).

324
14
Probability Measures on Product Spaces
This implies
PJ ◦(XJ
L)−1(A) =

A′ P ′(d(ω0, . . . , ωl−1)) fl−1(ωl−1)
=

A′ P ′(d(ω0, . . . , ωl−1))

Ajl+1
κjl−1,jl+1(ωl−1, dωl+1) fl+1(ωl+1)
= PL(A).
It remains to show that κ is a stochastic kernel. That is, we have to show that
x →κ(x, A) is measurable with respect to B(E) – B(E)⊗I. By Remark 8.26, it
sufﬁces to check this for rectangular cylinders with a ﬁnite base A ∈ZR since ZR
is a π-system that generates B(E)⊗I. Hence, let 0 = t0 < t1 < . . . < tn and
B0, . . . , Bn ∈B(E) as well as A = n
i=0 X−1
ti (Bi). However, by Corollary 14.27,
the following map is measurable,
x →Px[A] =

δx ⊗
n−1
 
i=0
κti,ti+1

n×
i=0
Bi

.
⊓⊔
Corollary 14.46 (Measures by consistent families of kernels) Under the assump-
tions of Theorem 14.45, for every probability measure μ on E, there exists a unique
probability measure Pμ on

EI, B(E)⊗I
with the following property: For any
choice of ﬁnitely many numbers 0 = j0 < j1 < j2 < . . . < jn from I, and
letting J := {j0, . . . , jn}, we have Pμ ◦X−1
J
= μ ⊗/n−1
k=0 κjk,jk+1.
Proof Take Pμ = 3 μ(dx) κ(x, ·).
⊓⊔
As a simple conclusion of Lemma 14.44 and Theorem 14.45, we get the following
statement that we formulate separately because it will play a central role later.
Corollary 14.47 (Measures via Markov semigroups) Let (κt : t ∈I) be a
Markov semigroup on the Polish space E. Then there exists a unique stochastic
kernel κ from (E, B(E)) to (EI, B(E)⊗I) with the property: For all x ∈E and for
any choice of ﬁnitely many numbers 0 = t0 < t1 < t2 < . . . < tn from I, and letting
J := {t0, . . . , tn}, we have
κ(x, ·) ◦X−1
J
=

δx ⊗
n−1
 
k=0
κtk+1−tk

.
(14.17)
For any probability measure μ on E, there exists a unique probability measure
Pμ on

EI, B(E)⊗I
with the property: For any choice of ﬁnitely many numbers
0 = t0 < t1 < t2 < . . . < tn from I, and letting J := {t0, . . . , tn}, we have
Pμ ◦X−1
J
= μ ⊗/n−1
k=0 κtk+1−tk. We denote Px = Pδx = κ(x, ·) for x ∈E.

14.4
Markov Semigroups
325
Example 14.48 (Independent normally distributed increments) Let I = [0, ∞) and
Ωi = R, i ∈[0, ∞), equipped with the Borel σ-algebra B = B(R). Further, let
Ω = R[0,∞), A = B⊗[0,∞) and let Xt be the coordinate map for t ∈[0, ∞). In the
sense of Deﬁnition 14.6, X = (Xt)t≥0 is thus the canonical process on (Ω, A).
We construct a probability measure P on (Ω, A) such that the stochastic
process X has independent, stationary, normally distributed increments (recall
Deﬁnition 9.7). That is, it should hold that
(Xti −Xti−1)i=1,...,n is independent
for all 0 =: t0 < t1 < . . . < tn,
(14.18)
PXt−Xs = N0,t−s
for all t > s.
(14.19)
To this end, deﬁne stochastic kernels κt(x, dy) := δx ∗N0,t(dy) for t ∈[0, ∞)
where N0,0 = δ0. By Lemma 14.30, the Chapman–Kolmogorov equation holds
since (compare Exercise 14.2.1(i))
κs · κt(x, dy) = δx ∗(N0,s ∗N0,t)(dy) = δx ∗N0,s+t(dy) = κs+t(x, dy).
Let P0 = δ0 and let P be the unique probability measure on Ω corresponding to P0
and (κt : t ≥0) according to Corollary 14.47. By Theorem 14.31, the equations
(14.18) and (14.19) hold.
With (Xt)t≥0, we have almost constructed the so-called Brownian motion. In
addition to the properties we required here, Brownian motion has continuous paths;
that is, the maps t →Xt are almost surely continuous. Note that at this point it is
not even clear that the paths are measurable maps. We will have some work to do to
establish continuity of the paths, and we will come back to this in Chap. 21. ♦
The construction in the preceding example does not depend on the details of the
normal distribution but only on the validity of the convolution equation
N0,s+t = N0,s ∗N0,t.
Hence, in (14.19) we can replace the normal distribution by any parameterized
family of distributions (νt, t ≥0) with the property νt+s = νt ∗νs. Examples
include the Gamma distribution νt = Γθ,t (for ﬁxed parameter θ > 0), the Poisson
distribution νt = Poit, the negative binomial distribution νt = b−
t,p (for ﬁxed
p ∈(0, 1]), the Cauchy distribution νt = Caut and others (compare Theorem 15.13
and Corollary 15.14). We establish the result in a theorem.
Deﬁnition 14.49 (Convolution semigroup) Let I ⊂[0, ∞) be a semigroup. A
family ν = (νt : t ∈I) of probability distributions on Rd is called a convolution
semigroup if νs+t = νs ∗νt holds for all s, t ∈I.
If I = [0, ∞) and if in addition νt
t→0
−→δ0, then the convolution semigroup is
called continuous (in the sense of weak convergence).

326
14
Probability Measures on Product Spaces
If d = 1 and νt((−∞, 0)) = 0 for all t ∈I, then ν is called a nonnegative
convolution semigroup.
For the following theorem, compare Deﬁnition 9.7.
Theorem 14.50 For any convolution semigroup (νt : t ∈I) and any x ∈Rd, there
exists a probability measure Px on the product space (Ω, A) =

(Rd)I, B(Rd)⊗I
such that the canonical process (Xt)t∈I is a stochastic process with Px[X0 = x] =
1, with stationary independent increments and with Px ◦(Xt −Xs)−1 = νt−s
for t > s. On the other hand, every stochastic process (Xt)t∈I (on an arbitrary
probability space (Ω, A, P)) with stationary independent increments deﬁnes a
convolution semigroup by νt = P ◦(Xt −X0)−1 for all t ∈I.
Takeaways For a Markov process, the conditional distribution at time t given
the full history until some time s < t is a function of the state at time s only
and can be described by a stochastic kernel κs,t. On the other hand, if a family
of stochastic kernels κs,t, s < t, fulﬁlls the a minimal consistency condition
(the Chapman-Kolmogorov equation), then Kolmogorov’s extension theorem
allows to construct a probability space and a Markov process on it that ﬁts to
these kernels. Convolution semigroups are a special application and yield real
valued processes with independent and stationary increments.
Exercise 14.4.1 Assume that (νt : t ≥0) is a continuous convolution semigroup.
Show that νt = lims→t νs for all t > 0. ♣
Exercise 14.4.2 Assume that (νt : t ≥0) is a convolution semigroup. Show that
νt/n
n→∞
−→δ0. ♣
Exercise 14.4.3 Show that a nonnegative convolution semigroup is continuous. ♣
Exercise 14.4.4 Show that a continuous real convolution semigroup (νt : t ≥0)
with νt((−∞, 0)) = 0 for some t > 0 is nonnegative. ♣
Exercise 14.4.5 Use the methods developed in this section to construct a stochastic
process (Xt)t≥0 with independent and stationary Poisson-distributed increments.
Furthermore, show that such a process can be constructed in such a way that almost
surely the map t →Xt is monotone increasing and right continuous. (Compare
Sect. 5.5.) ♣

Chapter 15
Characteristic Functions and the Central
Limit Theorem
The main goal of this chapter is the central limit theorem (CLT) for sums of
independent random variables (Theorem 15.38) and for independent arrays of
random variables (Lindeberg–Feller theorem, Theorem 15.44). For the latter, we
prove only that one of the two implications (Lindeberg’s theorem) that is of interest
in the applications.
The ideal tools for the treatment of central limit theorems are so-called char-
acteristic functions; that is, Fourier transforms of probability measures. We start
with a more general treatment of classes of test functions that are suitable to
characterize weak convergence and then study Fourier transforms in greater detail.
The subsequent section proves the CLT for real-valued random variables by means
of characteristic functions. In the ﬁfth section, we prove a multidimensional version
of the CLT.
15.1
Separating Classes of Functions
Let (E, d) be a metric space with Borel σ-algebra E = B(E).
Denote by C = {u + iv : u, v ∈R} the ﬁeld of complex numbers. Let
Re(u + iv) = u
and
Im(u + iv) = v
denote the real part and the imaginary part, respectively, of z = u + iv ∈C. Let
z = u −iv be the complex conjugate of z and |z| =
√
u2 + v2 its modulus. A
prominent role will be played by the complex exponential function exp : C →C,
which can be deﬁned either by Euler’s formula exp(z) = exp(u)

cos(v) + i sin(v)

or by the power series exp(z) = ∞
n=0 zn/n!. It is well-known that exp(z1 + z2) =
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_15
327

328
15
Characteristic Functions and the Central Limit Theorem
exp(z1) · exp(z2). Note that Re(z) = (z + z)/2 and Im(z) = (z −z)/2i imply
cos(x) = eix + e−ix
2
and
sin(x) = eix −e−ix
2i
for all x ∈R.
A map f : E →C is measurable if and only if Re(f ) and Im(f ) are measurable
(see Theorem 1.90 with C ∼= R2). In particular, any continuous function E →C is
measurable. If μ ∈M(E), then we deﬁne

f dμ :=

Re(f ) dμ + i

Im(f ) dμ
if both integrals exist and are ﬁnite. Let Cb(E; C) denote the Banach space of
continuous, bounded, complex-valued functions on E equipped with the supremum
norm ∥f ∥∞= sup{|f (x)| : x ∈E}. We call C ⊂Cb(E; C) a separating class for
Mf (E) if for any two measures μ, ν ∈Mf (E) with μ ̸= ν, there is an f ∈C such
that
3
f dμ ̸=
3
f dν. The analogue of Theorem 13.34 holds for C ⊂Cb(E; C).
Deﬁnition 15.1 Let K = R or K = C. A subset C ⊂Cb(E; K) is called an algebra
if
(i) 1 ∈C,
(ii) if f, g ∈C, then f · g and f + g are in C, and
(iii) if f ∈C and α ∈K, then (αf ) is in C.
We say that C separates points if for any two points x, y ∈E with x ̸= y, there
is an f ∈C with f (x) ̸= f (y).
Theorem 15.2 (Stone–Weierstraß) Let E be a compact Hausdorff space. Let K =
R or K = C. Let C ⊂Cb(E; K) be an algebra that separates points. If K = C, then
in addition assume that C is closed under complex conjugation (that is, if f ∈C,
then the complex conjugate function f is also in C).
Then C is dense in Cb(E; K) with respect to the supremum norm.
Proof We follow the exposition in Dieudonné [34, Chapter VII.3]. First consider
the case K = R. We proceed in several steps.
Step 1.
By Weierstraß’s approximation theorem (Example 5.15), there is a
sequence (pn)n∈N of polynomials that approach the map [0, 1] →[0, 1], t →√t
uniformly. If f ∈C, then also
|f | = ∥f ∥∞lim
n→∞pn

f 2/∥f ∥2
∞

is in the closure C of C in Cb(E; R).
Step 2.
Applying Step 1 to the algebra C yields that, for all f, g ∈C,
f ∨g = 1
2(f + g + |f −g|)
and
f ∧g = 1
2(f + g −|f −g|)
are also in C.

15.1
Separating Classes of Functions
329
Step 3.
We show that for any f ∈Cb(E; R), any x ∈E and any ε > 0, there exists
a gx ∈C with gx(x) = f (x) and gx(y) ≤f (y) + ε for all y ∈E. As C separates
points, for any z ∈E \ {x}, there exists an Hz ∈C with Hz(z) ̸= Hz(x) = 0. For
such z, deﬁne hz ∈C by
hz(y) = f (x) + f (z) −f (x)
Hz(z)
Hz(y)
for all y ∈E.
In addition, deﬁne hx := f . Then hz(x) = f (x) and hz(z) = f (z) for all
z ∈E. Since f and hz are continuous, for any z ∈E, there exists an open
neighborhood Uz ∋z with hz(y) ≤f (y) + ε for all y ∈Uz. We construct
a ﬁnite covering Uz1, . . . , Uzn of E consisting of such neighborhoods and deﬁne
gx = min(hz1, . . . , hzn). By Step 2, we have gx ∈C.
Step 4.
Let f ∈Cb(E; R), ε > 0 and, for any x ∈E, let gx be as in Step 3. As
f and gx are continuous, for any x ∈E, there exists an open neighborhood Vx ∋x
with gx(y) ≥f (y) −ε for any y ∈Vx. We construct a ﬁnite covering Vx1, . . . , Vxn
of E and deﬁne g := max(gx1, . . . , gxn). Then g ∈C by Step 2 and ∥g −f ∥∞< ε
by construction. Letting ε ↓0, we get C = Cb(E; R).
Step 5.
Now consider K = C. If f ∈C, then by assumption Re(f ) = (f + ¯f )/2
and Im(f ) = (f −¯f )/2i are in C. In particular, C0 := {Re(f ) : f ∈C} ⊂C is a real
algebra that, by assumption, separates points and contains the constant functions.
Hence C0 is dense in Cb(E; R). Since C = C0 + iC0, C is dense in Cb(E; C).
⊓⊔
Corollary 15.3 Let E be a compact metric space. Let K = R or K = C. Let
C ⊂Cb(E; K) be a family that separates points; that is, stable under multiplication
and that contains 1. If K = C, then in addition assume that C is closed under
complex conjugation.
Then C is a separating family for Mf (E).
Proof Let μ1, μ2 ∈Mf (E) with 3 g dμ1 = 3 g dμ2 for all g ∈C. Let C′ be the
algebra of ﬁnite linear combinations of elements of C. By linearity of the integral,
3 g dμ1 = 3 g dμ2 for all g ∈C′.
For any f ∈Cb(E, R) and any ε > 0, by the Stone–Weierstraß theorem, there
exists a g ∈C′ with
;;f −g
;;
∞< ε. By the triangle inequality,


f dμ1 −

f dμ2
 ≤


f dμ1 −

g dμ1
 +


g dμ1 −

g dμ2

+


g dμ2 −

f dμ2

≤ε (μ1(E) + μ2(E)).
Letting ε
↓
0, we get equality of the integrals and hence μ1
=
μ2 (by
Theorem 13.11).
⊓⊔

330
15
Characteristic Functions and the Central Limit Theorem
Reﬂection In the Stone-Weierstraß theorem for the case K = C, it is assumed that
the algebra is closed under complex conjugation. Find an example that shows that
this condition cannot be dropped. ♠♠
The following theorems are simple consequences of Corollary 15.3.
Theorem 15.4 The distribution of a bounded real random variable X is character-
ized by its moments.
Proof Without loss of generality, we can assume that X takes values in E := [0, 1].
For n ∈N, deﬁne the map fn : [0, 1] →[0, 1] by fn : x →xn. Further, let f0 ≡1.
The family C = {fn, n ∈N0} separates points and is closed under multiplication;
hence it is a separating class for Mf (E). Thus PX is uniquely determined by its
moments E[Xn] = 3 xn PX(dx), n ∈N.
⊓⊔
Example 15.5 (due to [73]) In the preceding theorem, we cannot simply drop
the assumption that X is bounded without making other assumptions (see Corol-
lary 15.33). Even if all moments exist, the distribution of X is, in general, not
uniquely determined by its moments. As an example consider X := exp(Y), where
Y ∼N0,1. The distribution of X is called the log-normal distribution. For every
n ∈N, nY is distributed as the sum of n2 independent, standard normally distributed
random variables nY D= Y1 + . . . + Yn2. Hence, for n ∈N,
E[Xn] = E[enY] = E[eY1+...+Yn2 ] =
n2

i=1
E[eYi] = E[eY]n2
=
 ∞
−∞
(2π)−1/2 ey e−y2/2 dy
n2
= en2/2.
(15.1)
We construct a whole family of distributions with the same moments as X. By the
transformation formula for densities (Theorem 1.101), the distribution of X has the
density
f (x) =
1
√
2π
x−1 exp

−1
2 log(x)2

for x > 0.
For α ∈[−1, 1], deﬁne probability densities fα on (0, ∞) by
fα(x) = f (x)

1 + α sin(2π log(x))

.
In order to show that fα is a density and has the same moments as f , it is enough to
show that, for all n ∈N0,
m(n) :=
 ∞
0
xn f (x) sin(2π log(x)) dx = 0.

15.1
Separating Classes of Functions
331
With the substitution y = log(x)−n, we get (note that sin(2π(y +n)) = sin(2πy))
m(n) =
 ∞
−∞
eyn+n2(2π)−1/2 e−(y+n)2/2 sin(2π(y + n)) dy
= (2π)−1/2 en2/2
 ∞
−∞
e−y2/2 sin(2πy) dy = 0,
where the last equality holds since the integrand is an odd function. ♦
Theorem 15.6 (Laplace transform) A ﬁnite measure μ on [0, ∞) is character-
ized by its Laplace transform
Lμ(λ) :=

e−λx μ(dx)
for λ ≥0.
Proof We face the problem that the space [0, ∞) is not compact by passing to the
one-point compactiﬁcation E = [0, ∞]. For λ ≥0, deﬁne the continuous function
fλ : [0, ∞] →[0, 1] by fλ(x) = e−λx if x < ∞and fλ(∞) = limx→∞e−λx.
Then C = {fλ, λ ≥0} separates points, f0 = 1 ∈C and fμ · fλ = fμ+λ ∈
C. By Corollary 15.3, C is a separating class for Mf ([0, ∞]) and thus also for
Mf ([0, ∞)).
⊓⊔
Remark 15.7 Let X and Y be independent nonnegative random variables with
Laplace transforms LX := LPX and LY := LPY , respectively. Further, let a ≥0 and
b ≥0. Then we clearly have LaX+b(t) = e−btLX(at) and LX+Y (t) = LX(t)·LY (t)
for t ≥0. ♦
Reﬂection Check the statements of the preceding remark! ♠
Deﬁnition 15.8 For μ ∈Mf (Rd), deﬁne the map ϕμ : Rd →C by
ϕμ(t) :=

ei⟨t,x⟩μ(dx).
ϕμ is called the characteristic function of μ.
Theorem 15.9 (Characteristic function) A ﬁnite measure μ
∈
Mf (Rd) is
characterized by its characteristic function.
Proof Let μ1, μ2
∈
Mf (Rd) with ϕμ1(t)
= ϕμ2(t) for all t
∈
Rd. By
Theorem 13.11(ii), Cc(Rd) is a separating class for Mf (Rd). Hence, it is enough
to show that
3
f dμ1 =
3
f dμ2 for all f ∈Cc(Rd).
Let f : Rd →R be continuous with compact support and let ε > 0. Assume
that K > 0 is large enough such that f (x) = 0 for x ̸∈(−K/2, K/2)d and such
that μi

Rd \ (−K, K)d
< ε, i = 1, 2. Consider the torus E := Rd/(2KZd) and
deﬁne ˜f : E →R by
˜f

x + 2KZd
= f (x)
for x ∈[−K, K)d.
Since the support of f is contained in (−K, K)d, ˜f is continuous.

332
15
Characteristic Functions and the Central Limit Theorem
For m ∈Zd deﬁne
gm : Rd →C,
x →exp

i⟨πm/K, x⟩

.
Let C be the algebra of ﬁnite linear combinations of the gm. For g ∈C, we have
g(x) = g(x + 2Kn) for all x ∈Rd and n ∈Zd. Hence, the map
˜g : E →C,
˜g(x + 2KZd) = g(x)
is well-deﬁned, continuous and bounded. Furthermore, ˜C := { ˜g : g ∈C} ⊂
Cb(E; C) is an algebra that separates points and is closed under complex conju-
gation. As E is compact, by the Stone–Weierstraß theorem, there is a g ∈C such
that ∥˜g −˜f ∥∞< ε. We infer
;;(f −g)1[−K,K]d
;;
∞< ε
and
;;(f −g)1Rd\[−K,K]d
;;
∞≤∥g∥∞= ∥˜g∥∞≤∥˜f ∥∞+ ε = ∥f ∥∞+ ε.
By assumption of the theorem,
3
g dμ1 =
3
g dμ2. Hence, using the triangle
inequality, we conclude


f dμ1 −

f dμ2
 ≤

|f −g| dμ1 +

|f −g| dμ2
≤ε2∥f ∥∞+ 2ε + μ1(Rd) + μ2(Rd).
As ε > 0 was arbitrary, the integrals coincide.
⊓⊔
Corollary 15.10 A ﬁnite measure μ on Zd is uniquely determined by the values
ϕμ(t) =

ei⟨t,x⟩μ(dx),
t ∈[−π, π)d.
Proof This is obvious since ϕμ(t + 2πk) = ϕμ(t) for all k ∈Zd.
⊓⊔
While the preceding corollary only yields an abstract uniqueness statement, we will
proﬁt also from an explicit inversion formula for Fourier transforms.
Theorem 15.11 (Discrete Fourier inversion formula) Let μ ∈Mf (Zd) with
characteristic function ϕμ. Then, for every x ∈Zd,
μ({x}) = (2π)−d

[−π,π)d e−i⟨t,x⟩ϕμ(t) dt.

15.1
Separating Classes of Functions
333
Proof By the dominated convergence theorem,

[−π,π)d e−i⟨t,x⟩ϕμ(t) dt =

[−π,π)d e−i⟨t,x⟩
⎛
⎝lim
n→∞

|y|≤n
ei⟨t,y⟩μ({y})
⎞
⎠dt
= lim
n→∞

[−π,π)d e−i⟨t,x⟩
|y|≤n
ei⟨t,y⟩μ({y}) dt
=

y∈Zd
μ({y})

[−π,π)d ei⟨t,y−x⟩dt.
The claim follows since, for y ∈Zd,

[−π,π)d ei⟨t,y−x⟩dt =

(2π)d,
if x = y,
0,
else.
⊓⊔
Similar inversion formulas hold for measures μ on Rd. Particularly simple is
the case where μ possesses an integrable density f :=
dμ
dλ with respect to d-
dimensional Lebesgue measure λ. In this case, we have the Fourier inversion
formula,
f (x) = (2π)−d

Rd e−i⟨t,x⟩ϕμ(t) λ(dt).
(15.2)
Furthermore, by Plancherel’s theorem, f ∈L2(λ) if and only if ϕμ ∈L2(λ). In this
case, ∥f ∥2 = ∥ϕ∥2/(2π)d/2.
Since we will not need these statements in the following, we only refer to the
standard literature (e.g., [174, Chapter VI.2] or [54, Theorem XV.3.3 and Equation
(XV.3.8)]).
Takeaways A priori, checking equality of two measures by computing
integrals or checking weak convergence of a sequence of measures requires
to consider a huge class of test functions. The Stone-Weierstraß theorem and
its corollaries allow to boil down the class of test functions to a tractable
size. In fact, in many cases, it is enough to consider moments, Laplace
transforms or characteristic functions. There is some freedom in the choice
of the class of test functions so it can be adapted to the individual problem.
For example, characteristic functions work well with sums of independent
random variables.

334
15
Characteristic Functions and the Central Limit Theorem
Exercise 15.1.1 Show that, in the Stone–Weierstraß theorem, compactness of E is
essential. Hint: Let E = R and use the fact that Cb(R) = Cb(R; R) is not separable.
Construct a countable algebra C ⊂Cb(R) that separates points. ♣
Exercise 15.1.2 Let d ∈N and let μ be a ﬁnite measure on [0, ∞)d. Show that μ
is characterized by its Laplace transform Lμ(λ) =
3
e−⟨λ,x⟩μ(dx), λ ∈[0, ∞)d. ♣
Exercise 15.1.3 Let n ∈N and let X1, . . . , Xn be i.i.d. exponentially distributed
random variables with parameter 1. Finally, let Y1, . . . , Yn be independent expo-
nentially distributed random variables with PYk = expk. That is, (Y1, . . . , Yn) D=
(X1, X2/2, X3/3, . . . , Xn/n). Show that
max{X1, . . . , Xn} D= Y1 + . . . + Yn.
Hint:
(i) Compute the Laplace transforms LY1, . . . , LYn and use Remark 15.7 to
compute LY1+...+Yn.
(ii) Use the explicit formula for the Laplace transform M := max{X1, . . . , Xn}
from Remark 2.24 to compute the Laplace transform
LM(t) =
n!
(t + 1)(t + 2) · · · (t + n)
for t ≥0.
(iii) Use the uniqueness theorem for Laplace transforms.
An alternative strategy of proof is: Sort the values of the Xi by size M = X(1) >
X(2) > . . . > X(n). Check that X(n)
D= Yn. Show that the conditional distribution
L
)
X(1) −X(n), . . . , X(n−1) −X(n)
|X(n)*
does not depend on X(n) and that it
equals the (unconditional) distribution of the ordered values of X1, . . . , Xn−1. By
an iteration procedure, show the even stronger statement

X(n), X(n−1), . . . , X(1)
 D=

Yn, Yn−1 + Yn, . . . , Y1 + Y2 + . . . + Yn

.
We will use this Exercise later in Example 17.27. ♣
Exercise 15.1.4 Show that, under the assumptions of Theorem 15.11, Plancherel’s
equation holds:

x∈Zd
μ({x})2 = (2π)−d

[−π,π)d |ϕμ(t)|2 dt.♣
Exercise 15.1.5 (Mellin transform)
Let X be a nonnegative real random variable.
For s ≥0, deﬁne the Mellin transform of PX by
mX(s) = E[Xs]
(with values in [0, ∞]).

15.1
Separating Classes of Functions
335
Assume there is an ε0 > 0 with mX(ε0) < ∞(respectively mX(−ε0) < ∞).
Show that, for any ε > 0, the distribution PX is characterized by the values mX(s)
(respectively mX(−s)), s ∈[0, ε].
Hint: For continuous f : [0, ∞) →[0, ∞), let
φf (z) =
 ∞
0
tz−1f (t) dt
for those z ∈C for which the integral is well-deﬁned. By a standard result
of complex analysis if φf (s) < ∞for an s > 1, then φf is holomorphic in
{z ∈C : Re(z) ∈(1, s)} (and is thus uniquely determined by the values φf (r),
r ∈(1, 1 + ε) for any ε > 0). Furthermore, for all r ∈(1, s),
f (t) =
1
2π i
 ∞
−∞
t−(r+iρ)φf (r + iρ) dρ.
(i) Conclude the statement for X with a continuous density.
(ii) For δ > 0, let Yδ ∼U[1−δ,1] be independent of X. Show that XYδ has a
continuous density.
(iii) Compute mXYδ, and show that mXYδ →mX for δ ↓0.
(iv) Show that XYδ ⇒X for δ ↓0. ♣
Exercise 15.1.6 Let X, Y, Z be independent nonnegative random variables such
that P[Z > 0] > 0 and such that the Mellin transform mXZ(s) is ﬁnite for some
s > 0.
Show that if XZ D= YZ holds, then X D= Y. ♣
Exercise 15.1.7 Let μ be a probability measure on R with integrable characteristic
function ϕμ and hence ϕμ ∈L1(λ), where λ is the Lebesgue measure on R. Show
that μ is absolutely continuous with bounded continuous density f = dμ
dλ given by
f (x) = 1
2π
 ∞
−∞
e−itxϕμ(t) dt
for all x ∈R.
Hint: Show this ﬁrst for the normal distribution N0,ε, ε > 0. Then show that μ∗N0,ε
is absolutely continuous with density fε, which converges pointwise to f (as ε →
0). ♣

336
15
Characteristic Functions and the Central Limit Theorem
Exercise 15.1.8 Let (Ω, τ) be a separable topological space that satisﬁes the T3 1
2
separation axiom: For any closed set A ⊂Ω and any point x ∈Ω \ A, there exists
a continuous function f : Ω →[0, 1] with f (x) = 0 and f (y) = 1 for all y ∈A.
(Note in particular that every metric space is a T3 1
2 -space.)
Show that σ(Cb(Ω)) = B(Ω); that is, the Borel σ-algebra is generated by the
bounded continuous functions Ω →R. ♣
15.2
Characteristic Functions: Examples
Recall that Re(z) is the real part of z ∈C. We collect some simple properties of
characteristic functions.
Lemma 15.12 Let X be a random variable with values in Rd and characteristic
function ϕX(t) = E
)
ei⟨t,X⟩*
. Then:
(i) |ϕX(t)| ≤1 for all t ∈Rd and ϕX(0) = 1.
(ii) ϕaX+b(t) = ϕX(at) ei⟨b,t⟩for all a ∈R and b ∈Rd.
(iii) PX = P−X if and only if ϕ is real-valued.
(iv) If X and Y are independent, then ϕX+Y = ϕX · ϕY.
(v) 0 ≤1 −Re(ϕX(2t)) ≤4(1 −Re(ϕX(t))) for all t ∈Rd.
Proof
(i) and (ii) are trivial.
(iii) ϕX(t) = ϕX(−t) = ϕ−X(t).
(iv) As ei⟨t,X⟩and ei⟨t,Y⟩are independent random variables, we have
ϕX+Y (t) = E
)
ei⟨t,X⟩· ei⟨t,Y⟩*
= E
)
ei⟨t,X⟩*
E
)
ei⟨t,Y⟩*
= ϕX(t) ϕY (t).
(v) By the addition theorem for trigonometric functions,
1 −cos(⟨2t, X⟩) = 2

1 −(cos(⟨t, X⟩))2
≤4

1 −cos(⟨t, X⟩)

.
Now take the expectations of both sides.
⊓⊔
In the next theorem, we collect the characteristic functions for some of the most
important distributions.
Theorem 15.13 (Characteristic functions of some distributions)
For some
distributions P with density x →f (x) on R or weights P({k}), k ∈N0, we state
the characteristic function ϕ(t) explicitly:

15.2
Characteristic Functions: Examples
337
Distribution
Char. fct.
Name Symbol
Parameter
on
Density / Weights
ϕ(t)
normal Nμ,σ 2
μ ∈R σ 2 > 0
R
1
√
2πσ 2 exp

−(x−μ)2
2σ 2

eiμt · e−σ 2t2/2
uniform U[0,a]
a > 0
[0, a]
1/a
eiat−1
iat
uniform U[−a,a]
a > 0
[−a, a]
1/2a
sin(at)
at
triangle Tria
a > 0
[−a, a]
1
a

1 −|x|/a
+
2 1−cos(at)
a2t2
N.N.
a > 0
R
1
π
1−cos(ax)
ax2
(1 −|t|/a)+
Gamma Γθ,r
θ > 0 r > 0
[0, ∞)
θr
Γ (r) xr−1 e−θx
(1 −it/θ)−r
exponential expθ
θ > 0
0, ∞)
θ e−θx
θ
θ −it
two-sided exponential exp2
θ
θ > 0
R
θ
2 e−θ|x|
1
1 + (t/θ)2
Cauchy Caua
a > 0
R
1
aπ
1
1 + (x/a)2
e−a|t|
binomial bn,p
n ∈N p ∈[0, 1]
{0, . . . , n}
n
k

pk(1 −p)n−k
(1 −p) + peitn
negative binomial b−
r,p
r > 0 p ∈(0, 1]
N0
−r
k

(−1)kpr(1 −p)k

p
1 −(1 −p)eit
r
Poisson Poiλ
λ > 0
N0
e−λ λk
k!
exp

λ(eit −1)


338
15
Characteristic Functions and the Central Limit Theorem
Proof
(i) (Normal distribution) By Lemma 15.12, it is enough to consider the case
μ = 0 and σ 2 = 1. By virtue of the differentiation lemma (Theorem 6.28)
and using partial integration, we get
d
dt ϕ(t) =
1
√
2π
 ∞
−∞
eitx ix e−x2/2 dx = −t ϕ(t).
This linear differential equation with initial value ϕ(0) = 1 has the unique
solution ϕ(t) = e−t2/2.
(ii) (Uniform distribution) This is immediate.
(iii) (Triangle distribution) Note that Tria = U[−a/2,a/2] ∗U[−a/2,a/2]; hence
ϕTria(t) = ϕU[−a/2,a/2](t)2 = 4 sin(at/2)2
a2 t2
= 2 1 −cos(at)
a2 t2
.
Here we used the fact that by the addition theorem for trigonometric functions
1 −cos(x) = sin(x/2)2 + cos(x/2)2 −cos(x) = 2 sin(x/2)2.
(iv) (N.N.) This can either be computed directly or can be deduced from (iii) by
using the Fourier inversion formula (equation (15.2)).
(v) (Gamma distribution) Again it sufﬁces to consider the case θ = 1. For
0 ≤b < c ≤∞and t ∈R, let γb,c,t be the linear path in C from b −ibt to
c −ict, let δb,t be the linear path from b to b −ibt and let ϵc,t be the linear
path from c −ict to c. Substituting z = (1 −it)x, we get
ϕ(t) =
1
Γ (r)
 ∞
0
xr−1 e−x eitx dx = (1 −it)−r
Γ (r)

γ0,∞,t
zr−1 e−z dz.
Hence, it sufﬁces to show that
3
γ0,∞,t zr−1 exp(−z) dz = Γ (r).
The function z →zr−1 exp(−z) is holomorphic in the right complex
plane. Hence, by the residue theorem for 0 < b < c < ∞,
 c
b
xr−1 exp(−x) dx =

γb,c,t
zr−1 exp(−z) dz
+

δb,t
zr−1 exp(−z) dz +

ϵc,t
zr−1 exp(−z) dz.
Recall that
3 ∞
0
xr−1 exp(−x) dx =: Γ (r). Hence, it is enough to show that
the integrals along δb,t and ϵc,t vanish if b →0 and c →∞.

15.2
Characteristic Functions: Examples
339
However, |zr−1 exp(−z)| ≤(1 + t2)(r−1)/2 br−1 exp(−b) for z ∈δb,t. As
the path δb,t has length b |t|, we get the estimate


δb,t
zr−1 e−z dz
 ≤br e−b (1 + t2)r/2 −→0
for b →0.
Similarly,


ϵc,t
zr−1 e−z dz
 ≤cr e−c (1 + t2)r/2 −→0
for c →∞.
(vi) (Exponential distribution) This follows from (v) since expθ = Γθ,1.
(vii) (Two-sided exponential distribution) If X and Y are independent expθ-
distributed random variables, then it is easy to check that X −Y ∼exp2
θ.
Hence
ϕexp2
θ (t) = ϕexpθ (t) ϕexpθ (−t) =
1
1 −it/θ
1
1 + it/θ =
1
1 + (t/θ)2 .
(viii) (Cauchy distribution) This can either be computed directly using residue
calculus or can be inferred from the statement for the two-sided exponential
distribution by the Fourier inversion formula (equation (15.2)).
(ix) (Binomial distribution) By the binomial theorem,
ϕ(t) =
n

k=0
n
k

(1 −p)n−k(peit)k = (1 −p + peit)n.
(x) (Negative binomial distribution) By the generalized binomial theorem
(Lemma 3.5), for all x ∈C with |x| < 1,
(1 −x)−r =
∞

k=0
−r
k

(−x)k.
Using this formula with x = (1 −p) eit gives the claim.
(xi) (Poisson distribution) Clearly, ϕPoiλ(t) =
∞

n=0
e−λ (λeit)n
n!
= eλ(eit−1).
⊓⊔
Corollary 15.14 The following convolution formulas hold.
(i) Nμ1,σ 2
1 ∗Nμ2,σ 2
2 = Nμ1+μ2,σ 2
1 +σ 2
2 for μ1, μ2 ∈R and σ 2
1 , σ 2
2 > 0.
(ii) Γθ,r ∗Γθ,s = Γθ,r+s for θ, r, s > 0.
(iii) Caua ∗Caub = Caua+b for a, b > 0.
(iv) bm,p ∗bn,p = bm+n,p for m, n ∈N and p ∈[0, 1].

340
15
Characteristic Functions and the Central Limit Theorem
(v) b−
r,p ∗b−
s,p = b−
r+s,p for r, s > 0 and p ∈(0, 1].
(vi) Poiλ ∗Poiμ = Poiλ+μ for λ, μ ≥0.
Proof This follows by Theorem 15.13 and by ϕμ∗ν = ϕμ ϕν (Lemma 15.12).
⊓⊔
The following theorem gives two simple procedures for calculating the characteris-
tic functions of compound distributions.
Theorem 15.15
(i) Let μ1, μ2, . . . ∈Mf (Rd) and let p1, p2, . . . be nonnegative numbers with
∞

n=1
pnμn(Rd) < ∞. Then the measure μ :=
∞

n=1
pnμn ∈Mf (Rd) has
characteristic function
ϕμ =
∞

n=1
pn ϕμn.
(15.3)
(ii) Let N, X1, X2, . . . be independent random variables. Assume X1, X2, . . .
are identically distributed on Rd with characteristic function ϕX. Assume
N takes values in N0 and has the probability generating function fN. Then
Y :=
N
n=1
Xn has the characteristic function ϕY(t) = fN(ϕX(t)).
(iii) In particular, if we let N ∼Poiλ in (ii), then ϕY (t) = exp(λ(ϕX(t) −1)).
Proof
(i) Deﬁne νn =
n
k=1
pkμk. By the linearity of the integral, ϕνn =
n
k=1
pkϕμk. By
assumption, μ = w-lim
n→∞νn; hence also ϕμ(t) = lim
n→∞ϕνn(t).
(ii) Clearly,
ϕY (t) =
∞

n=0
P[N = n] E
)
ei⟨t,X1+...+Xn⟩*
=
∞

n=0
P[N = n] ϕX(t)n = fN(ϕX(t)).
(iii) In this special case, fN(z) = eλ(z−1) for z ∈C with |z| ≤1.
⊓⊔

15.2
Characteristic Functions: Examples
341
Example 15.16 Let n ∈N, and assume that the points 0 = a0 < a1 < . . . < an and
1 = y0 > y1 > . . . > yn = 0 are given. Let ϕ : R →[0, ∞) have the properties
that
•
ϕ(ak) = yk for all k = 0, . . . , n and ϕ is linearly interpolated between the points
ak,
•
ϕ(x) = 0 for |x| > an, and
•
ϕ is even (that is, ϕ(x) = ϕ(−x)).
Assume in addition that the yk are chosen such that ϕ is convex on [0, ∞). This is
equivalent to the condition that m1 ≤m2 ≤. . . ≤mn ≤0, where mk := yk−yk−1
ak−ak−1 is
the slope on the kth interval. We want to show that ϕ is the characteristic function
of a probability measure μ ∈M1(R).
Deﬁne pk = ak(mk+1 −mk) for k = 1, . . . , n.
Let μk
∈M1(R) be the distribution on R with density
1
π
1−cos(akπ)
akx2
. By
Theorem 15.13, μk has the characteristic function ϕμk(t) =

1 −|t|
ak
+
. The
characteristic function ϕμ of μ := n
k=1 pkμk is then
ϕμ(t) =
n

k=1
pk(1 −|t|/ak)+.
This is a continuous, symmetric, real function with ϕμ(0) = 1. It is linear on each
of the intervals [ak−1, ak]. See Fig. 15.1 for an example with n = 4. By partial
ϕ(t)
t
y0 = 1
y1
y2
y3
a1
a2
a3
a4
−a4
−a3
−a2
−a1
Fig. 15.1 The characteristic function ϕ from Example 15.16 with n = 4.

342
15
Characteristic Functions and the Central Limit Theorem
summation, for all k = 1, . . . , n (since mn+1 = 0),
ϕμ(al) =
n

k=1
ak(mk+1 −mk)

1 −al
ak
+
=
n

k=l
(ak −al)(mk+1 −mk)
=
'
(an −al)mn+1 −(al −al)ml
(
−
n

k=l+1
(ak −ak−1)mk
= −
n

k=l+1
(yk −yk−1) = yl = ϕ(al).
Hence ϕμ = ϕ. ♦
Example 15.17 Deﬁne the function ϕ : R →[−1, 1] for t
∈[−π, π) by
ϕ(t) = 1 −2|t|/π, and assume ϕ is periodic (with period 2π). By the discrete
Fourier inversion formula (Theorem 15.11), ϕ is the characteristic function of the
probability measure μ ∈M1(Z) with μ({x}) = (2π)−1 3 π
−π cos(tx) ϕ(t) dt. In
fact, in order that μ be a measure (not only a signed measure), we still have to show
that all of the masses μ({x}) are nonnegative. Clearly, μ({0}) = 0. For x ∈Z \ {0},
use partial integration to compute the integral,
 π
−π
cos(tx) ϕ(t) dt = 2
 π
0
cos(tx) (1 −2t/π) dt
= 4
x

1 −2
π

sin(πx) −4
x sin(0) + 4
πx
 π
0
sin(tx) dt
=
4
πx2 (1 −cos(πx)).
Summing up, we have
μ({x}) =

4
π2x2 ,
if x is odd,
0,
else.
Since μ(Z) = ϕ(0) = 1, μ is indeed a probability measure. ♦
Example 15.18 Deﬁne the function ψ : R →[0, 1] for t ∈[−π/2, π/2) by ψ(t) =
1−2|t|/π. Assume ψ is periodic with period π. If ϕ is the characteristic function of
the measure μ from the previous example, then clearly ψ(t) = |ϕ(t)|. On the other
hand, ψ(t) = 1
2 + 1
2ϕ(2t). By Theorem 15.15 and Lemma 15.12(ii), we infer that
ψ is the characteristic function of the measure ν with ν(A) = 1
2δ0(A) + 1
2μ(A/2)

15.2
Characteristic Functions: Examples
343
for A ⊂R. Hence,
ν({x}) =
⎧
⎪⎪⎨
⎪⎪⎩
1
2,
if x = 0,
8
π2x2 ,
if
x
2 ∈Z is odd,
0,
else.
♦
Example 15.19 Let ϕ(t) = (1 −2|t|/π)+ be the characteristic function of the
distribution “N.N.” from Theorem 15.13 (with a
= π/2) and let ψ be the
characteristic function from the preceding example. Note that ϕ(t) = ψ(t) for
|t| ≤π/2 and ϕ(t) = 0 for |t| > π/2; hence ϕ2 = ϕ · ψ. Now let X, Y, Z be
independent real random variables with characteristic functions ϕX = ϕY = ϕ and
ϕZ = ψ. Then ϕXϕY = ϕXϕZ; hence X + Y D= X + Z. However, the distributions
of Y and Z do not coincide. ♦
Takeaways In order to compute characteristic functions, in many cases it
is enough to have a table of characteristic functions for some repertoire of
standard distributions and to know how characteristic functions transform
under linear maps and independent sums. We have studied both in this section.
It is of a certain theoretical interest and will be needed later that triangle
functions and sums of triangle functions are characteristic functions.
Exercise 15.2.1 Let ϕ be the characteristic function of the d-dimensional random
variable X. Assume that ϕ(t) = 1 for some t ̸= 0. Show that P[X ∈Ht] = 1, where
Ht = {x ∈Rd : ⟨x, t⟩∈2πZ}
=
	
y + z · (2πt/∥t∥2
2) : z ∈Z, y ∈Rd with ⟨y, t⟩= 0

.
Infer that ϕ(t + s) = ϕ(s) for all s ∈Rd. ♣
Exercise 15.2.2 Show that there are real random variables X, X′ and Y, Y ′ with the
properties (i) X D= X′ and Y D= Y ′, (ii) X′ and Y ′ are independent, (iii) X + Y D=
X′ + Y ′, and (iv) X and Y are not independent. ♣
Exercise 15.2.3 Let X be a real random variable with characteristic function ϕ. X is
called lattice distributed if there are a, d ∈R such that P[X ∈a + dZ] = 1. Show
that X is lattice distributed if and only if there exists a u ̸= 0 such that |ϕ(u)| = 1.
♣

344
15
Characteristic Functions and the Central Limit Theorem
Exercise 15.2.4 Let X be a real random variable with characteristic function ϕ.
Assume that there is a sequence (tn)n∈N of real numbers such that |tn| ↓0 and
|ϕ(tn)| = 1 for any n. Show that there exists a b ∈R such that X = b almost surely.
If in addition, ϕ(tn) = 1 for all n, then X = 0 almost surely. ♣
15.3
Lévy’s Continuity Theorem
The main statement of this section is Lévy’s continuity theorem (Theorem 15.24).
Roughly speaking, it says that a sequence of characteristic functions converges
pointwise to a continuous function if and only if the limiting function is a charac-
teristic function and the corresponding probability measures converge weakly. We
prepare for the proof of this theorem by assembling some analytic tools.
Lemma 15.20 Let μ ∈M1(Rd) with characteristic function ϕ. Then
|ϕ(t) −ϕ(s)|2 ≤2

1 −Re(ϕ(t −s))

for all s, t ∈Rd.
Proof By the Cauchy–Schwarz inequality,
|ϕ(t) −ϕ(s)|2 =


Rd ei⟨t,x⟩−ei⟨s,x⟩μ(dx)

2
=


Rd

ei⟨t−s,x⟩−1

ei⟨s,x⟩μ(dx)

2
≤

Rd
ei⟨t−s,x⟩−1
2 μ(dx) ·

Rd
ei⟨s,x⟩2 μ(dx)
=

Rd
ei⟨t−s,x⟩−1e−i⟨t−s,x⟩−1 μ(dx)
= 2

1 −Re(ϕ(t −s))

.
⊓⊔
Deﬁnition 15.21 Let (E, d) be a metric space. A family (fi, i ∈I) of maps E →
R is called uniformly equicontinuous if, for every ε > 0, there exists a δ > 0 such
that |fi(t) −fi(s)| < ε for all i ∈I and all s, t ∈E with d(s, t) < δ.
Theorem 15.22 If F ⊂M1(Rd) is a tight family, then {ϕμ : μ ∈F} is uniformly
equicontinuous. In particular, every characteristic function is uniformly continuous.
Proof We have to show that, for every ε > 0, there exists a δ > 0 such that, for all
t ∈Rd, all s ∈Rd with |t −s| < δ and all μ ∈F, we have |ϕμ(t) −ϕμ(s)| < ε.

15.3
Lévy’s Continuity Theorem
345
As F is tight, there exists an N ∈N with μ([−N, N]d) > 1 −ε2/6 for all
μ ∈F. Furthermore, there exists a δ > 0 such that, for x ∈[−N, N]d and u ∈Rd
with |u| < δ, we have
1 −ei⟨u,x⟩ < ε2/6. Hence we get for all μ ∈F
1 −Re(ϕμ(u)) ≤

Rd
1 −ei⟨u,x⟩ μ(dx)
≤ε2
3 +

[−N,N]d
1 −ei⟨u,x⟩ μ(dx)
≤ε2
3 + ε2
6 = ε2
2 .
Thus, for |t −s| < δ by Lemma 15.20, |ϕμ(t) −ϕμ(s)| ≤ε.
⊓⊔
Lemma 15.23 Let (E, d) be a metric space and let f, f1, f2, . . . be maps E →
R with fn
n→∞
−→f pointwise. If (fn)n∈N is uniformly equicontinuous, then f is
uniformly continuous and (fn)n∈N converges to f uniformly on compact sets; that
is, for every compact set K ⊂E, we have sups∈K |fn(s) −f (s)|
n→∞
−→0.
Proof Fix ε > 0, and choose δ > 0 such that |fn(t) −fn(s)| < ε for all n ∈N and
all s, t ∈E with d(s, t) < δ. For these s, t, we thus have
|f (s) −f (t)| = lim
n→∞|fn(s) −fn(t)| ≤ε.
Hence, f is uniformly continuous.
Now let K ⊂E be compact. As compact sets are totally bounded, there exists
an N ∈N and points t1, . . . , tN ∈K with K ⊂N
i=1 Bδ(ti). Choose n0 ∈N large
enough that |fn(ti) −f (ti)| ≤ε for all i = 1, . . . , N and n ≥n0.
Now let s ∈K and n ≥n0. Choose a ti with d(s, ti) < δ. Then
|fn(s) −f (s)| ≤|fn(s) −fn(ti)| + |fn(ti) −f (ti)| + |f (ti) −f (s)| ≤3ε.
As ε > 0 was arbitrary, we infer that fn
n→∞
−→f uniformly on K.
⊓⊔
A map f : Rd →R is called partially continuous at x = (x1, . . . , xd) if, for
any i = 1, . . . , d, the map yi →f (x1, . . . , xi−1, yi, xi+1, . . . , xd) is continuous at
yi = xi.
Theorem 15.24 (Lévy’s continuity theorem) Let P, P1, P2, . . . ∈M1(Rd) with
characteristic functions ϕ, ϕ1, ϕ2, . . ..
(i) If P = w-lim
n→∞Pn, then ϕn
n→∞
−→ϕ uniformly on compact sets.
(ii) If ϕn
n→∞
−→f pointwise for some f : Rd →C that is partially continuous at 0,
then there exists a probability measure Q such that ϕQ = f and Q = w-lim
n→∞Pn.

346
15
Characteristic Functions and the Central Limit Theorem
Proof
(i) By the deﬁnition of weak convergence, we have ϕn
n→∞
−→ϕ pointwise. As the
family (Pn)n∈N is tight, by Theorem 15.22, (ϕn)n∈N is uniformly equicontinu-
ous. By Lemma 15.23, this implies uniform convergence on compact sets.
(ii) By Theorem 13.34, it is enough to show that the sequence (Pn)n∈N is tight.
For this purpose, it sufﬁces to show that, for every k = 1, . . . , n, the sequence
(P k
n )n∈N of kth marginal distributions is tight. (Here P k
n := Pn ◦π−1
k , where
πk : Rd →R is the projection on the kth coordinate.) Let ek be the kth unit
vector in Rd. Then ϕP kn (t) = ϕn(t ek) is the characteristic function of P k
n . By
assumption, ϕP kn
n→∞
−→fk pointwise for some function fk that is continuous at
0. We have thus reduced the problem to the one-dimensional situation and will
henceforth assume d = 1.
As ϕn(0) = 1 for all n ∈N, we have f (0) = 1. Deﬁne the map h :
R →[0, ∞) by h(x) = 1 −sin(x)/x for x ̸= 0 and h(0) = 0. Clearly, h is
continuously differentiable on R. It is easy to see that α := inf{h(x) : |x| ≥
1} = 1 −sin(1) > 0. Now, for K > 0, compute (using Markov’s inequality
and Fubini’s theorem)
Pn

[−K, K]c
≤α−1

[−K,K]c h(x/K) Pn(dx)
≤α−1

R
h(x/K) Pn(dx)
= α−1

R
  1
0
1 −cos(tx/K) dt

Pn(dx)
= α−1
 1
0
 
R

1 −cos(tx/K)

Pn(dx)

dt
= α−1
 1
0

1 −Re(ϕn(t/K))

dt.
Using dominated convergence, we conclude that
lim sup
n→∞
Pn([−K, K]c) ≤α−1 lim sup
n→∞
 1
0

1 −Re(ϕn(t/K))

dt
= α−1
 1
0

lim
n→∞

1 −Re(ϕn(t/K))

dt
= α−1
 1
0

1 −Re(f (t/K))

dt.
As f is continuous and f (0) = 1, the last integral converges to 0 for K →∞.
Hence (Pn)n∈N is tight.
⊓⊔

15.3
Lévy’s Continuity Theorem
347
Reﬂection Find an example of a pointwise convergent sequence of characteristic
functions (ϕn) such that the limiting function ϕ is not continuous (at 0). ♠
Applying Lévy’s continuity theorem to Example 15.16, we get a theorem of Pólya.
Theorem 15.25 (Pólya) Let f : R →[0, 1] be continuous and even with f (0) =
1. Assume that f is convex on [0, ∞). Then f is the characteristic function of a
probability measure.
Proof Deﬁne fn by fn(k/n) := f (k/n) for k = 0, . . . , n2, and assume fn is
linearly interpolated between these points. Furthermore, let fn be constant to the
right of n and for x < 0, deﬁne fn(x) = fn(−x). This is an approximation of f on
[0, ∞) by convex and piecewise linear functions. By Example 15.16, every fn is a
characteristic function of a probability measure μn. Clearly, fn
n→∞
−→f pointwise;
hence f is the characteristic function of a probability measure μ = w-lim
n→∞μn on R.
⊓⊔
Corollary 15.26 For every α ∈(0, 1] and r > 0, ϕα,r(t) = e−|r t|α is the
characteristic function of a symmetric probability measure μα,r on R.
Remark 15.27 In fact, ϕα,r is a characteristic function for every α ∈(0, 2] (α = 2
corresponds to the normal distribution), see Sect. 16.2. The distributions μα,r are
the so-called α-stable distributions (see Deﬁnition 16.20): If X1, X2, . . . , Xn are
independent and μα,a-distributed, then ϕX1+...+Xn(t) = ϕX(t)n = ϕX(n1/α t);
hence X1 + . . . + Xn
D= n1/αX1. ♦
The Stone–Weierstraß theorem implies that a characteristic function determines a
probability distribution uniquely. Pólya’s theorem gives a sufﬁcient condition for
a symmetric real function to be a characteristic function. Clearly, that condition
is not necessary, as, for example, the normal distribution does not fulﬁll it. For
general education we present Bochner’s theorem that formulates a necessary and
sufﬁcient condition for a function ϕ : Rd →C to be the characteristic function of a
probability measure.
Deﬁnition 15.28 A function f : Rd →C is called positive semideﬁnite if, for all
n ∈N, all t1, . . . , tn ∈Rd and all y1, . . . , yn ∈C, we have
n

k,l=1
yk ¯yl f (tk −tl) ≥0,
in other words, if the matrix (f (tk −tl))k,l=1,...,n is positive semideﬁnite.
Lemma 15.29 If μ ∈Mf (Rd) has characteristic function ϕ, then ϕ is positive
semideﬁnite.

348
15
Characteristic Functions and the Central Limit Theorem
Proof We have
n

k,l=1
yk ¯yl ϕ(tk −tl) =
n

k,l=1
yk ¯yl

eix(tk−tl) μ(dx)
=

n

k,l=1
yk eixtk yl eixtl μ(dx)
=
 
n

k=1
yk eixtk

2
μ(dx) ≥0.
⊓⊔
In the case d = 1, the following theorem goes back to Bochner (1932).
Theorem 15.30 (Bochner) A continuous function ϕ : Rd →C is the charac-
teristic function of a probability distribution on Rd if and only if ϕ is positive
semideﬁnite and ϕ(0) = 1.
The statement still holds if Rd is replaced by a locally compact Abelian group.
Proof For the case d = 1 see [19, §20, Theorem 23] or [54, Chapter XIX.2, page
622]. For the general case, see, e.g., [71, page 293, Theorem 33.3].
⊓⊔
Takeaways In order to check weak convergence of a sequence of probability
measures, it is enough to show tightness and pointwise convergence of the
characteristic functions. If the limiting function is continuous at 0, then by
Levy’s theorem, tightness and hence weak convergence are automatic.
Exercise 15.3.1 (Compare [50] and [4]) Show that there exist two exchangeable
sequences X
= (Xn)n∈N and Y
= (Yn)n∈N of real random variables with
PX ̸= PY but such that
n

k=1
Xk
D=
n

k=1
Yk
for all n ∈N.
(15.4)
Hint:
(i) Deﬁne the characteristic functions (see Theorem 15.13) ϕ1(t) =
1
1+t2 and
ϕ2(t) = (1 −t/2)+. Use Pólya’s theorem to show that
ψ1(t) :=

ϕ1(t),
if |t| ≤1,
ϕ2(t),
if |t| > 1,

15.4
Characteristic Functions and Moments
349
and
ψ2(t) :=

ϕ2(t),
if |t| ≤1,
ϕ1(t),
if |t| > 1,
are characteristic functions of probability distributions on R.
(ii) Deﬁne independent random variables Xn,i, Yn,i, n ∈N, i = 1, 2, and Θn,
n ∈N such that Xn,i has characteristic function ϕi, Yn,i has characteristic
function ψi and P[Θn = 1] = P[Θn = −1] = 1
2. Deﬁne Xn = Xn,Θn and
Yn = Yn,Θn. Show that (15.4) holds.
(iii) Determine E[ei t1X1+i t2X2] and E[eit1Y1+it2Y2] for t1 = 1
2 and t2 = 2. Conclude
that (X1, X2) ̸D= (Y1, Y2) and thus PX ̸= PY . ♣
Exercise 15.3.2 Show that for any δ > 0 and ε > 0, there is a C < ∞such that
for any μ ∈M1(R) with characteristic function ϕ, we have
μ([−δ, δ]c) ≤C
 ε
0
(1 −Re(ϕ(t))) dt.
For εδ ≤3 one can choose C = 12/δ2ε3. Hint: Proceed as in the proof of Lévy’s
continuity theorem. ♣
Exercise 15.3.3 Let (μn)n∈N be a sequence of probability measures on R and
denote by (ϕn)n∈N the corresponding characteristic functions. Assume that we have
ϕn(t)
n→∞
−→
1 for t in a neighborhood of 0. Use Exercise 15.3.2 to show that
μn
n→∞
−→δ0. ♣
Exercise 15.3.4 (Continuity theorem for Laplace transforms) Let (μn)n∈N be a
sequence of probability measures on [0, ∞) and let
ψn(t) =

e−txμn(dx)
for t ≥0,
n ∈N
be the Laplace transforms. We assume that there exists a map ψ : [0, ∞) →[0, 1]
that is continuous in 0 and such that ψn
n→∞
−→ψ pointwise.
Show that ψ is the Laplace transform of a probability measure μ on [0, ∞) and
that μn
n→∞
−→μ weakly. ♣
15.4
Characteristic Functions and Moments
We want to study the connection between the moments of a real random variable X
and the derivatives of its characteristic function ϕX. We start with a simple lemma.

350
15
Characteristic Functions and the Central Limit Theorem
Lemma 15.31 For t ∈R and n ∈N, we have
eit −1 −it
1! −. . . −(it)n−1
(n −1)!
 ≤|t|n
n! .
Proof As the nth derivative of eit has modulus 1, this follows by Taylor’s formula.
⊓⊔
Theorem 15.32 (Moments and differentiability) Let X be a real random variable
with characteristic function ϕ.
(i) If E[|X|n] < ∞, then ϕ is n-times continuously differentiable with derivatives
ϕ(k)(t) = E
)
(iX)k eitX*
for k = 0, . . . , n.
(ii) In particular, if E[X2] < ∞, then
ϕ(t) = 1 + it E[X] −1
2t2 E[X2] + ε(t) t2
with ε(t) →0 for t →0.
(iii) Let h ∈R. If lim
n→∞
|h|nE[|X|n]
n!
= 0, then, for every t ∈R,
ϕ(t + h) =
∞

k=0
(ih)k
k! E
'
eitXXk(
.
In particular, this holds if E
)
e|hX|*
< ∞.
Proof
(i) For t ∈R, h ∈R \ {0} and k ∈{1, . . . , n}, deﬁne
Yk(t, h, x) = k! h−k eitx

eihx −
k−1

l=0
(ihx)l
l!

.
Then
E[Yk(t, h, X)] = k! h−k

ϕ(t + h) −ϕ(t) −
k−1

l=1
E)eitX(iX)l* hl
l!

.
If the limit ϕk(t) := limh→0 E[Yk(t, h, X)] exists, then ϕ is k-times differen-
tiable at t with ϕ(k)(t) = ϕk(t).
However (by Lemma 15.31 with n = k + 1), Yk(t, h, x)
h→0
−→(ix)keitx
for all x ∈R and (by Lemma 15.31 with n = k) |Yk(t, h, x)| ≤|x|k. As

15.4
Characteristic Functions and Moments
351
E[|X|k] < ∞by assumption, the dominated convergence theorem implies
E[Yk(t, h, X)]
h→0
−→E[(iX)keitX] = ϕ(k)(t).
Applying the continuity lemma (Theorem 6.27) yields that ϕ(k) is continuous.
(ii) This is a direct consequence of (i).
(iii) By assumption,
ϕ(t + h) −
n−1

k=0
(ih)k
k! E
)
eitXXk*
 = |h|n
n!
E[Yn(t, h, X)]

≤|h|n E[|X|n]
n!
n→∞
−→0.
⊓⊔
Corollary 15.33 (Method of moments) Let X be a real random variable with
α := lim sup
n→∞
1
n E
)
|X|n*1/n < ∞.
Then the characteristic function ϕ of X is analytic and the distribution of X is
uniquely determined by the moments E[Xn], n ∈N. In particular, this holds if
E)et|X|* < ∞for some t > 0.
Proof By Stirling’s formula,
lim
n→∞
1
n! nn e−n √
2π n = 1.
Thus, for |h| < 1/(3α),
lim sup
n→∞
E
)
|X|n*
· |h|n/n! = lim sup
n→∞
(2π n)−1/2 
E
)
|X|n*1/n · |h| · e/n
n
≤lim sup
n→∞
(2π n)−1/2 (e/3)n = 0.
Hence the characteristic function can be expanded about any point t ∈R in a power
series with radius of convergence at least 1/(3α). In particular, it is analytic and is
hence determined by the coefﬁcients of its power series about t = 0; that is, by the
moments of X.
⊓⊔

352
15
Characteristic Functions and the Central Limit Theorem
Example 15.34
(i) Let X ∼Nμ,σ 2. Then, for every t ∈R,
E
)
etX*
=

2πσ 2−1/2
 ∞
−∞
etxe−(x−μ)2/2σ 2 dx
= eμt+t2σ 2/2
2πσ 2−1/2
 ∞
−∞
e−(x−μ−tσ 2)2/2σ 2 dx
= eμt+t2σ 2/2 < ∞.
Hence the distribution of X is characterized by its moments. The characteristic
function ϕ(t) = eiμt e−σ 2t2/2 that we get by the above calculation with t
replaced by it is indeed analytic. (ii) Let X be exponentially distributed with
parameter θ > 0. Then, for t ∈(0, θ),
E
)
etX*
= θ
 ∞
0
etx e−θx dx =
θ
θ −t < ∞.
Hence the distribution of X is characterized by its moments. The above
calculation with t replaced by it yields ϕ(t) = θ/(θ −it), and this function
is indeed analytic. The fact that in the complex plane ϕ has a singularity at
t = −iθ implies that the power series of ϕ about 0 has radius of convergence
θ. In particular, this implies that not all exponential moments are ﬁnite. This is
reﬂected by the above calculation that shows that, for t ≥θ, the exponential
moments are inﬁnite.
(iii) Let X be log-normally distributed (see Example 15.5). Then E[Xn] = en2/2.
In particular, here α = ∞. In fact, in Example 15.5, we saw that here the
moments do not determine the distribution of X.
(iv) If X takes values in N0 and if β := lim supn→∞E[Xn]1/n < 1, then
by Hadamard’s criterion ψX(z) := ∞
k=1 P[X = k] zk < ∞for |z| <
1/β. In particular, the probability generating function X is characterized by
its derivatives ψ(n)
X (1), n ∈N, and thus by the moments of X. Compare
Theorem 3.2(iii). ♦
Theorem 15.35 Let X be a real random variable and let ϕ be its characteristic
function. Let n ∈N, and assume that ϕ is 2n-times differentiable at 0 with derivative
ϕ(2n)(0). Then E[X2n] = (−1)n ϕ(2n)(0) < ∞.
Proof We carry out the proof by induction on n ∈N0. For n = 0, the claim
is trivially true. Now, let n ∈N, and assume ϕ is 2n-times (not necessarily
continuously) differentiable at 0. Deﬁne u(t) = Re(ϕ(t)). Then u is also 2n-times
differentiable at 0 and u(2k−1)(0) = 0 for k = 1, . . . , n since u is even. Since
ϕ(2n)(0) exists, ϕ(2n−1) is continuous at 0 and ϕ(2n−1)(t) exists for all t ∈(−ε, ε)
for some ε > 0. Furthermore, ϕ(k) exists in (−ε, ε) and is continuous on (−ε, ε) for

15.4
Characteristic Functions and Moments
353
any k = 0, . . . , 2n −2. By Taylor’s formula, for every t ∈(−ε, ε),
u(t) −
n−1

k=0
u(2k)(0) t2k
(2k)!
 ≤
|t|2n−1
(2n −1)!
sup
θ∈(0,1]
u(2n−1)(θt)
 .
(15.5)
Deﬁne a continuous function fn : R →[0, ∞) by fn(0) = 1 and
fn(x) = (−1)n (2n)! x−2n
-
cos(x) −
n−1

k=0
(−1)k x2k
(2k)!
.
for x ̸= 0.
By the induction hypothesis, E[X2k] = (−1)k u(2k)(0) for all k = 1, . . . , n −1.
Using (15.5), we infer
E)fn(tX) X2n* ≤2n
|t|
sup
θ∈(0,1]
|u(2n−1)(θt)| ≤gn(t) := 2n
sup
θ∈(0,1]
|u(2n−1)(θt)|
θ |t|
.
Now Fatou’s lemma implies
E)X2n* = E)fn(0)X2n* ≤lim inf
t→0 E)fn(tX)X2n*
≤lim inf
t→0 gn(t) = 2n
u(2n)(0)
 < ∞.
By Theorem 15.32, this implies E[X2n] = (−1)n u(2n)(0) = (−1)n ϕ(2n)(0).
⊓⊔
Remark 15.36 For odd moments, the statement of the theorem may fail (see, e.g.,
Exercise 15.4.4 for the ﬁrst moment). Indeed, ϕ is differentiable at 0 with derivative
i m for some m ∈R if and only if x P[|X| > x]
x→∞
−→0 and E[X 1{|X|≤x}]
x→∞
−→m.
(See [54, Chapter XVII.2a, page 565].) ♦
Takeaways A random variable with ﬁnite nth moment possesses a character-
istic function that is n-times differentiable. The moments can be read off from
the derivatives at 0. If all moments exist and do not grow too quickly, then the
moments determine the distribution.
Exercise 15.4.1 Let X and Y be nonnegative random variables with
lim sup
n→∞
1
nE[|X|n]1/n < ∞,
lim sup
n→∞
1
nE[|Y|n]1/n < ∞,

354
15
Characteristic Functions and the Central Limit Theorem
and
E[Xm Y n] = E[Xm] E[Y n]
for all m, n ∈N0.
Show that X and Y are independent.
Hint:
Consider the random variable Y with respect to the probability measure
XmP[ ·]/E[Xm], and use Corollary 15.33 to show that
E[Xm 1A(Y)]/E[Xm] = P[Y ∈A]
for all A ∈B(R) and m ∈N0.
Now apply Corollary 15.33 to the random variable X with respect to the probability
measure P[ · |Y ∈A]. ♣
Exercise 15.4.2 Let r, s > 0 and let Z ∼Γ1,r+s and B ∼βr,s be independent (see
Example 1.107). Use Exercise 15.4.1 to show that the random variables X := BZ
and Y := (1 −B)Z are independent with X ∼Γ1,r and Y ∼Γ1,s. ♣
Exercise 15.4.3 Show that, for α > 2, the function φα(t) = e−|t|α is not a
characteristic function.
(Hint: Assume the contrary and show that the corresponding random variable would
have variance zero.) ♣
Exercise 15.4.4 Let X1, X2, . . . be i.i.d. real random variables with characteristic
function ϕ. Show the following.
(i) If ϕ is differentiable at 0, then ϕ′(0) = i m for some m ∈R.
(ii) ϕ is differentiable at 0 with ϕ′(0) = i m if and only if (X1+. . .+Xn)/n
n→∞
−→
m in probability.
(iii) Assume that ϕ is differentiable at 0 and that X1 ≥0 almost surely. Then
E[X1] = −i ϕ′(0) < ∞. Hint: Use (ii) and the law of large numbers.
(iv) The distribution of X1 can be chosen such that ϕ is differentiable at 0 but
E[|X1|] = ∞. ♣
Exercise 15.4.5 Let X1, X2, . . . be real random variables. For r > 0 let Mr(Xn) =
E[|Xn|r] be the rth absolute moment. For k ∈N let mk(Xn) = E[Xk
n] be the kth
moment if Mk(Xn) < ∞.
(i) Assume that X is a real random variable and that (Xnl)l∈N is a subsequence
such that
PXnl
l→∞
−→PX weakly.
Assume further that there is an r > 0 such that supn∈N Mr(Xn) < ∞. Show
that for any k ∈N ∩(0, r) and s ∈(0, r) we have Ms(X) < ∞as well as
Ms(Xnl)
l→∞
−→Ms(X)
and
mk(Xnl)
l→∞
−→mk(X).

15.4
Characteristic Functions and Moments
355
(ii) Assume that for any k ∈N the limit
mk := lim
n→∞mk(Xn)
exists and is ﬁnite (note that ﬁnitely many of the mk(Xn) may be undeﬁned for
any k.) Show that there exists a real random variable X with mk = mk(X) for
all k ∈N and a subsequence (Xnl)l∈N such that
PXnl
l→∞
−→PX weakly.
(iii) Show the theorem of Fréchet–Shohat: If in (ii) the distribution of X is
determined by its moments mk(X), k ∈N (see Corollary 15.33), then
PXn
n→∞
−→PX weakly.
♣
Exercise 15.4.6 Let X1, X2, . . . be i.i.d. real random variables with E[X1] = 0 and
E[|X1|k] < ∞for all k ∈N.
(i) Show that there exist ﬁnite numbers (dk)k∈N (depending on the distribution
PX1) such that for any k, n ∈N we have
E
)
(X1 + . . . + Xn)2k−1* ≤d2k−1 nk−1
and
E
)
(X1 + . . . + Xn)2k*
−(2k)!
2k k! E
)
X2
1
*k nk ≤d2k nk−1.
Hint: Expand the bracket expression, sort the terms by the different mixed
moments and compute by combinatorial means the number of each type of
summand. The number of summands of the type E[X2
l1 · · · X2
lk] (for different
l1, . . . , lk) is of particular importance.
(ii) Let Y ∼N0,1. Use Theorem 15.32(i) to show that for any k ∈N we have
E
)
Y 2k−1*
= 0
and
E
)
Y 2k*
= (2k)!
2k k! .
(iii) Let S∗
n = (X1 + . . . + Xn)/√n Var[X1]. Use Exercise 15.4.5 to infer the
statement of the central limit theorem (compare Theorem 15.38)
PS∗n
n→∞
−→N0,1 weakly.
♣

356
15
Characteristic Functions and the Central Limit Theorem
15.5
The Central Limit Theorem
In the strong law of large numbers, we saw that, for large n, the order of magnitude
of the sum Sn = X1 + . . .+ Xn of i.i.d. integrable random variables is n · E[X1]. Of
course, for any n, the actual value of Sn will sometimes be smaller than n·E[X1] and
sometimes larger. In the central limit theorem (CLT), we study the size and shape
of the typical ﬂuctuations around n · E[X1] in the case where the Xi have a ﬁnite
variance.
We prepare for the proof of the CLT with a lemma.
Lemma 15.37 Let X1, X2, . . . be i.i.d. real random variables with E[X1] = μ and
Var[X1] = σ 2 ∈(0, ∞). Let
S∗
n :=
1
√
nσ 2
n

k=1
(Xk −μ)
be the normalized nth partial sum. Then
lim
n→∞ϕS∗n(t) = e−t2/2
for all t ∈R.
Proof Let ϕ = ϕXk−μ. Then, by Theorem 15.32(ii),
ϕ(t) = 1 −σ 2
2 t2 + ε(t) t2,
where the error term ε(t) goes to 0 if t →0. By Lemma 15.12(iv) and (ii),
ϕS∗n(t) = ϕ

t
√
nσ 2
n
.
Now

1 −t2
2n
n n→∞
−→e−t2/2 and


1 −t2
2n
n
−ϕ

t
√
nσ 2
n  ≤n
1 −t2
2n −ϕ

t
√
nσ 2
 
≤n t2
nσ 2
ε

t
√
nσ 2

n→∞
−→0.
(Note that |un −vn| ≤|u −v| · n · max(|u|, |v|)n−1 for all u, v ∈C.)
⊓⊔

15.5
The Central Limit Theorem
357
Theorem 15.38 (Central limit theorem (CLT)) Let X1, X2, . . . be i.i.d. real
random variables with μ := E[X1] ∈R and σ 2 := Var[X1] ∈(0, ∞). For n ∈N,
let S∗
n :=
1
√
σ 2n
n
i=1(Xi −μ). Then
PS∗n
n→∞
−→N0,1 weakly.
For −∞≤a < b ≤+∞, we have
lim
n→∞P[S∗
n ∈[a, b]] =
1
√
2π
3 b
a e−x2/2 dx.
Proof By Lemma 15.37 and Lévy’s continuity theorem (Theorem 15.24),

PS∗n

converges to the distribution with characteristic function ϕ(t)
= e−t2/2. By
Theorem 15.13(i), this is N0,1. The additional claim follows by the Portemanteau
theorem (Theorem 13.16) since N0,1 has a density; hence N0,1(∂[a, b]) = 0.
⊓⊔
Remark 15.39 If we prefer to avoid the continuity theorem, we could argue as
follows: For every K > 0 and n ∈N, we have P[|S∗
n| > K] ≤Var[S∗
n]/K2 =
1/K2; hence the sequence

PS∗n

is tight. As characteristic functions determine
distributions, the claim follows by Theorem 13.34. ♦
We want to weaken the assumption in Theorem 15.38 that the random variables
are identically distributed. In fact, we can even take a different set of summands
for every n. The essential assumptions are that the summands are independent,
each summand contributes only a little to the sum and the sum is centered and has
variance 1.
Deﬁnition 15.40 For every n ∈N, let kn ∈N and let Xn,1, . . . , Xn,kn be real
random variables. We say that (Xn,l) =

Xn,l, l = 1, . . . , kn, n ∈N

is an array
of random variables. Its row sum is denoted by Sn = Xn,1 + . . . + Xn,kn. The array
is called
•
independent if, for every n ∈N, the family (Xn,l)l=1,...,kn is independent,
•
centered if Xn,l ∈L1(P) and E[Xn,l] = 0 for all n and l, and
•
normed if Xn,l ∈L2(P) and
kn

l=1
Var[Xn,l] = 1 for all n ∈N.
A centered array is called a null array if its individual components are asymptoti-
cally negligible in the sense that, for all ε > 0,
lim
n→∞max
1≤l≤kn
P[|Xn,l| > ε] = 0.
Deﬁnition 15.41 A centered array of random variables (Xn,l) with Xn,l ∈L2(P)
for every n ∈N and l = 1, . . . , kn is said to satisfy the Lindeberg condition if, for
all ε > 0,
Ln(ε) :=
1
Var[Sn]
kn

l=1
E
'
X2
n,l 1
X2
n,l> ε2 Var[Sn]
( n→∞
−→0.
(15.6)

358
15
Characteristic Functions and the Central Limit Theorem
The array fulﬁlls the Lyapunov condition if there exists a δ > 0 such that
lim
n→∞
1
Var[Sn]1+(δ/2)
kn

l=1
E)|Xn,l|2+δ* = 0.
(15.7)
Lemma 15.42 The Lyapunov condition implies the Lindeberg condition.
Proof For x ∈R, we have x2 1{|x|>ε′} ≤(ε′)−δ |x|2+δ 1{|x|>ε′} ≤(ε′)−δ |x|2+δ.
Letting ε′ := ε√Var[Sn], we get
Ln(ε) ≤ε−δ
1
Var[Sn]1+(δ/2)
kn

l=1
E
)
|Xn,l|2+δ*
.
⊓⊔
Example 15.43 Let (Yn)n∈N be i.i.d. with E[Yn] = 0 and Var[Yn] = 1. Let
kn = n and Xn,l =
Yl
√n. Then (Xn,l) is independent, centered and normed. Clearly,
P[|Xn,l| > ε] = P[|Y1| > √εn ]
n→∞
−→0; hence (Xn,l) is a null array. Furthermore,
Ln(ε) = E)Y 2
1 1{|Y1|>ε√n}
* n→∞
−→0; hence (Xn,l) satisﬁes the Lindeberg condition.
If Y1 ∈L2+δ(P) for some δ > 0, then
n

l=1
E
)
|Xn,l|2+δ*
= n−(δ/2) E
)
|Y1|2+δ* n→∞
−→0.
In this case, (Xn,l) also satisﬁes the Lyapunov condition. ♦
The following theorem is due to Lindeberg (1922, see [108]) for the implication
(i) ⇒(ii) and is attributed to Feller (1935 and 1937, see [51, 52]) for the converse
implication (ii) ⇒(i). As most applications only need (i) ⇒(ii), we only prove
that implication. For a proof of (ii) ⇒(i) see, e.g., [155, Theorem III.4.3].
Theorem 15.44 (Central limit theorem of Lindeberg–Feller)
Let (Xn,l) be an
independent centered and normed array of real random variables. For every n ∈N,
let Sn = Xn,1 + . . . + Xn,kn. Then the following are equivalent.
(i) The Lindeberg condition holds.
(ii) (Xn,l) is a null array and PSn
n→∞
−→N0,1.
We prepare for the proof of Lindeberg’s theorem with a couple of lemmas.
Lemma 15.45 If (i) of Theorem 15.44 holds, then (Xn,l) is a null array.
Proof For ε > 0, by Chebyshev’s inequality,
kn

l=1
P
)
|Xn,l| > ε
*
≤ε−2
kn

l=1
E
)
X2
n,l 1{|Xn,l|>ε}
*
= ε−2 Ln(ε)
n→∞
−→0.
⊓⊔

15.5
The Central Limit Theorem
359
In the following, ϕn,l and ϕn will always denote the characteristic functions of
Xn,l and Sn.
Lemma 15.46 For every n ∈N and t ∈R, we have
kn

l=1
1 −ϕn,l(t)
 ≤t2
2 .
Proof For every x ∈R, we have |eitx −1 −itx| ≤t2x2
2 . Since E[Xn,l] = 0,
kn

l=1
ϕn,l(t) −1
 =
kn

l=1
E[eitXn,l −1]

≤
kn

l=1
E
)eitXn,l −itXn,l −1
*
+
E[itXn,l]

≤
kn

l=1
t2
2 E[X2
n,l] = t2
2 .
⊓⊔
Lemma 15.47 If (i) of Theorem 15.44 holds, then
lim
n→∞
 log ϕn(t) −
kn

l=1
E
)
eitXn,l −1
* = 0.
Proof Let mn :=
max
l=1,...,kn
ϕn,l(t) −1
. Note that, for all ε > 0,
eitx −1
 ≤

2 x2/ε2,
if |x| > ε,
ε |t|,
if |x| ≤ε.
This implies
ϕn,l(t) −1
 ≤E
'eitXn,l −1
 1{|Xn,l|≤ε}
(
+ E
'eitXn,l −1
 1{|Xn,l|>ε}
(
≤εt + 2 ε−2 E
'
X2
n,l 1{|Xn,l|>ε}
(
.
Hence, for all ε > 0,
lim sup
n→∞
mn ≤lim sup
n→∞

εt + 2 ε−2Ln(ε)

= εt,

360
15
Characteristic Functions and the Central Limit Theorem
and thus lim
n→∞mn = 0. Now | log(x) −(x −1)| ≤|x −1|2 for all x ∈C with
|x −1| ≤1
2. If n is sufﬁciently large that mn < 1
2, then
log ϕn(t) −
kn

l=1
E[eitXn,l −1]
 =

kn

l=1

log(ϕn,l(t)) −

ϕn,l(t) −1

≤
kn

l=1
ϕn,l(t) −1
2
≤mn
kn

l=1
ϕn,l(t) −1

≤1
2 mn t2
(by Lemma 15.46)
−→0
for n →∞.
⊓⊔
In order to work with the concepts of weak convergence in this proof, we introduce
the function
ft(x) :=
⎧
⎪⎪⎨
⎪⎪⎩
1
x2

eitx −1 −itx

,
if x ̸= 0,
−t2
2 ,
if x = 0,
(15.8)
as well as the measures νn ∈Mf (R), n ∈N,
νn(dx) :=
kn

l=1
x2 PXn,l(dx).
Lemma 15.48 For every t ∈R, we have ft ∈Cb(R).
Proof Clearly, ft is continuous on R \ {0}. On the other hand, for |x| ≥1, we have
|ft(x)| ≤|eitx| + 1 + |t/x| ≤2 + |t|. It remains to show that ft is continuous at 0.
This will imply that ft is bounded also on the compact set [−1, 1]. Taylor’s theorem
(Lemma 15.31) yields
eitx −1 −itx = −t2x2
2
+ R(tx)

15.5
The Central Limit Theorem
361
with |R(tx)| ≤1
6|tx|3. Hence, for ﬁxed t, we have
lim
0̸=x→0 ft(x) = −t2
2 +
lim
0̸=x→0
R(tx)
x2
= −t2
2 = ft(0).
⊓⊔
Lemma 15.49 If (i) of Theorem 15.44 holds, then νn
n→∞
−→δ0 weakly.
Proof For every n ∈N, we have νn ∈M1(R) since
νn(R) =
kn

l=1

x2 PXn,l(dx) =
kn

l=1
Var[Xn,l] = 1.
However, for ε > 0, we have νn([−ε, ε]c) = Ln(ε)
n→∞
−→0; hence νn
n→∞
−→δ0.
⊓⊔
Lemma 15.50 If (i) of Theorem 15.44 holds, then

ft dνn
n→∞
−→−t2
2 .
Proof By Lemma 15.48, we have ft ∈Cb(R). Furthermore, by Lemma 15.49 we
have νn
n→∞
⇒δ0. In other words, we have
3
ft dνn
n→∞
−→ft(0) = −t2/2.
⊓⊔
Proof of Theorem 15.44
“(i) ⇒(ii)”
We have to show that lim
n→∞log ϕn(t) = −t2
2 for every t ∈R. By
Lemma 15.47, this is equivalent to
lim
n→∞
kn

l=1
ϕn,l(t) −1 = −t2
2 .
Now ft(x) x2 +itx = eitx −1 and
3
itx PXn,l(dx) = itE[Xn,l] = 0, since the array
(Xn,l) is centered. Hence, we get
kn

l=1

ϕn,l(t) −1

=
kn

l=1
 
ft(x) x2 + itx

PXn,l(dx)
=
kn

l=1

ft(x) x2 PXn,l(dx)

362
15
Characteristic Functions and the Central Limit Theorem
=

ft dνn
n→∞
−→−t2
2
(by Lemma 15.50).
⊓⊔
As an application of the Lindeberg–Feller theorem, we give the so-called three-
series theorem, which is due to Kolmogorov.
Theorem 15.51 (Kolmogorov’s three-series theorem) Let X1, X2, . . . be inde-
pendent real random variables. Let K > 0 and Yn := Xn 1{|Xn|≤K} for all n ∈N.
The series ∞
n=1 Xn converges almost surely if and only if each of the following
three conditions holds:
(i)
∞

n=1
P[|Xn| > K] < ∞.
(ii)
∞

n=1
E[Yn] converges.
(iii)
∞

n=1
Var[Yn] < ∞.
Proof “ ⇐ ”
Assume that (i), (ii) and (iii) hold. By Exercise 6.1.4, since (iii)
holds, the series ∞
n=1(Yn−E[Yn]) converges a.s. As (ii) holds, ∞
n=1 Yn converges
almost surely. By the Borel–Cantelli lemma, there exists an N = N(ω) such that
|Xn| ≤K; hence Xn = Yn for all n ≥N. Hence ∞
n=1 Xn = N−1
n=1 Xn+∞
n=N Yn
converges a.s.
“ ⇒”
Assume that ∞
n=1 Xn converges a.s. Clearly, this implies (i) (otherwise,
by the Borel–Cantelli lemma, |Xn| > K inﬁnitely often, contradicting the assump-
tion).
We assume that (iii) does not hold and produce a contradiction. To this end, let
σ 2
n = n
k=1 Var[Yk] and deﬁne an array (Xn,l; l = 1, . . ., n, n ∈N) by Xn,l =
(Yl −E[Yl])/σn. This array is independent, centered and normed. Since σ 2
n
n→∞
−→
∞, for every ε > 0 and for sufﬁciently large n ∈N, we have 2K < εσn; thus
|Xn,l| < ε for all l = 1, . . . , n. This implies Ln(ε)
n→∞
−→
0, where Ln(ε) =
n
l=1
E)X2
n,l 1{|Xn,l|>ε}
* is the quantity of the Lindeberg condition (see (15.6)). By the
Lindeberg–Feller theorem, we then get Sn := Xn,1 + . . . + Xn,n
n→∞
⇒N0,1. As
shown in the ﬁrst part of this proof, almost sure convergence of ∞
n=1 Xn and (i)
imply that
∞

n=1
Yn
converges almost surely.
(15.9)

15.5
The Central Limit Theorem
363
In particular, Tn := (Y1 + . . . + Yn)/σn
n→∞
⇒0. Thus, by Slutzky’s theorem, we
also have (Sn −Tn) n→∞
⇒N0,1. On the other hand, for all n ∈N, the difference
Sn −Tn is deterministic, contradicting the assumption that (iii) does not hold.
Now that we have established (iii), by Exercise 6.1.4, we see that ∞
n=1(Yn −
E[Yn]) converges almost surely. Together with (15.9), we conclude (ii).
⊓⊔
As a supplement, we cite a statement about the speed of convergence in the central
limit theorem (see, e.g., [155, Chapter III, §11] for a proof). With different bounds
(instead of 0.8), the statement was found independently by Berry [10] and Esseen
[46].
Theorem 15.52 (Berry–Esseen)
Let X1, X2, . . . be independent and identically
distributed with E[X1] = 0, E[X2
1] = σ 2 ∈(0, ∞) and γ := E[|X1|3] < ∞. Let
S∗
n :=
1
√
nσ 2 (X1 +· · ·+Xn) and let Φ : x →
1
√
2π
3 x
−∞e−t2/2dt be the distribution
function of the standard normal distribution. Then, for all n ∈N,
sup
x∈R
P )S∗
n ≤x* −Φ(x)
 ≤
0.8 γ
σ 3√n.
Example 15.53 Let α ∈(0, 1). Consider the distribution μα on R with density
fα(x) = 1
2α |x|−1−1/α 1{|x|≥1}.
Let X1, X2, . . . , be i.i.d. random variables with distribution μα. Then E[X1] = 0
and σ 2 := Var[X1] = 1/(1 −2α) < ∞if α < 1/2. Let Fn denote the distribution
function of S∗
n and FΦ the distribution function of the standard normal distribution.
The closer Fn and FΦ are, the closer lie the points (F −1
Φ (t), F −1
n (t)) on the diagonal
{(x, x) : x ∈R}. A graphical representation of the points (F −1
Φ (t), F −1
n (t)), t ∈R
is called Q-Q-plot or quantile-quantile-plot.
As α approaches 1/2, the distribution μα has less and less moments. Hence we
expect the convergence in the central limit theorem to be slower. For ﬁxed n, we
expect the deviation of Fn from FΦ to be larger for larger α. The graphs in Fig. 15.2
illustrate this. ♦
Takeaways If a random variable is the sum of many independent centred
random variables, each of which takes mainly small values, then its distribu-
tion is close to a normal distribution. The Feller-Lindeberg theorem makes
rigorous sense of the expressions “mainly small values” and “close to a
normal distribution” and formulates the precise statement.
Exercise 15.5.1 The argument of Remark 15.39 is more direct than the argument
with Lévy’s continuity theorem but is less robust: Give a sequence X1, X2, . . . of

364
15
Characteristic Functions and the Central Limit Theorem
−4
−2
0
2
4
F −1
100(t)
α = 0.4
F −1
Φ (t)
−4
−2
0
2
4
−4
−2
0
2
4
−4
−2
0
2
4
F −1
100(t)
α = 0.48
F −1
Φ (t)
Fig. 15.2 Q-Q-plots for S∗
100 from Example 15.53 with α = 0.4 (left) and α = 0.48 (right). The
abscissa shows the quantiles of the standard normal distribution. For convenience, also the diagonal
is drawn.
independent real random variables with E[|Xn|] = ∞for all n ∈N but such that
X1 + . . . + Xn
√n
n→∞
⇒N0,1.
♣
Exercise 15.5.2 Let Y1, Y2, . . . be i.i.d. with E[Yi] = 0 and E[Y 2
i ] = 1. Let
Z1, Z2, . . . be independent random variables (and independent of Y1, Y2, . . .) with
P[Zi = i] = P[Zi = −i] = 1
2
1 −P[Zi = 0] = 1
2
1
i2 .
For i, n ∈N, deﬁne Xi := Yi + Zi and Sn = X1 + . . . + Xn.
Show that n−1/2Sn
n→∞
⇒N0,1 but that (Xi)i∈N does not satisfy the Lindeberg
condition.
Hint: Do not try a direct computation! ♣
Exercise 15.5.3 Let X1, X2, . . . be i.i.d. random variables with density
f (x) =
1
|x|3 1R\[−1,1](x).
Then E[X2
1] = ∞but there are numbers A1, A2, . . ., such that
X1 + . . . + Xn
An
n→∞
⇒N0,1.
Determine one such sequence (An)n∈N explicitly. ♣

15.6
Multidimensional Central Limit Theorem
365
15.6
Multidimensional Central Limit Theorem
We come to a multidimensional version of the CLT.
Deﬁnition 15.54 Let C be a (strictly) positive deﬁnite symmetric real d × d matrix
and let μ ∈Rd. A random vector X = (X1, . . . , Xd)T is called d-dimensional
normally distributed with expectation μ and covariance matrix C if X has the
density
fμ,C(x) =
1
2
(2π)d det(C)
exp

−1
2
B
x −μ, C−1(x −μ)
C
(15.10)
for x ∈Rd. In this case, we write X ∼Nμ,C.
Theorem 15.55 Let μ ∈Rd and let C be a real positive deﬁnite symmetric d × d
matrix. If X ∼Nμ,C, then the following statements hold.
(i) E[Xi] = μi for all i = 1, . . ., d.
(ii) Cov[Xi, Xj] = Ci,j for all i, j = 1, . . . , d.
(iii) ⟨λ, X⟩∼N⟨λ,μ⟩,⟨λ,Cλ⟩for every λ ∈Rd.
(iv) ϕ(t) := E[ei⟨t,X⟩] = ei⟨t,μ⟩e−1
2 ⟨t,Ct⟩for every t ∈Rd.
Moreover, X ∼Nμ,C ⇐⇒(iii) ⇐⇒(iv).
Proof (i) and (ii) follow by simple computations. The same is true for (iii) and
(iv). The implication (iii) ⇒(iv) is straightforward as the characteristic function
ϕ uniquely determines the distribution of X by Theorem 15.9.
⊓⊔
Remark 15.56 For one-dimensional normal distributions, it is natural to deﬁne the
degenerate normal distribution by Nμ,0 := δμ. For the multidimensional situation,
there are various possibilities for degeneracy depending on the size of the kernel of
C. If C is only positive semideﬁnite (and symmetric, of course), we deﬁne Nμ,C as
that distribution on Rn with characteristic function ϕ(t) = ei⟨t,μ⟩e−1
2 ⟨t,Ct⟩. ♦
Theorem 15.57 (Cramér–Wold device) Let Xn = (Xn,1, . . . , Xn,d)T ∈Rd, n ∈
N, be random vectors. Then, the following are equivalent:
(i) There is a random vector X such that Xn
n→∞
⇒X.
(ii) For any λ ∈Rd, there is a random variable Xλ such that ⟨λ, Xn⟩n→∞
⇒Xλ.
If (i) and (ii) hold, then Xλ D= ⟨λ, X⟩for all λ ∈Rd.
Proof Assume (i). Let λ ∈Rd and s ∈R. The map Rd →C, x →ei s⟨λ,x⟩is
continuous and bounded; hence we have E[ei s⟨λ,Xn⟩]
n→∞
−→E[ei s⟨λ,X∞⟩]. Thus (ii)
holds with Xλ := ⟨λ, X⟩.
Now assume (ii). Then (PXn,l)n∈N is tight for every l = 1, . . . , d. Hence (PXn)n∈N
is tight and thus relatively sequentially compact (Prohorov’s theorem). For any weak

366
15
Characteristic Functions and the Central Limit Theorem
limit point Q for (PXn)n∈N and for any λ ∈Rd, we have

Q(dx) ei⟨λ,x⟩= E
)
eiXλ*
.
Hence the limit point Q is unique and thus (PXn)n∈N converges weakly to Q. That
is, (i) holds.
If (ii) holds, then the distributions of the limiting random variables Xλ are
uniquely determined and by what we have shown already, Xλ = ⟨λ, X⟩is one
possible choice. Thus Xλ D= ⟨λ, X⟩.
⊓⊔
Theorem 15.58 (Central limit theorem in Rd) Let (Xn)n∈N be i.i.d. random
vectors with E[Xn,i] = 0 and E[Xn,iXn,j] = Cij , i, j = 1, . . . , d. Let S∗
n :=
X1+...+Xn
√n
. Then
PS∗n
n→∞
−→N0,C weakly.
Proof Let λ ∈Rd. Deﬁne Xλ
n = ⟨λ, Xn⟩, Sλ
n = ⟨λ, S∗
n⟩and S∞∼N0,C. Then
E[Xλ
n] = 0 and Var[Xλ
n] = ⟨λ, Cλ⟩. By the one-dimensional central limit theorem,
we have PSλn
n→∞
−→N0,⟨λ,Cλ⟩= P⟨λ, S∞⟩. By Theorem 15.57, this yields the claim.
⊓⊔
Takeaways For vector-valued random variables to converge, it is enough that
the projections to one-dimensional subspaces converge (Cramér-Wold). We
use this to conclude a central limit theorem for multi-dimensional independent
and identically distributed random variables.
Exercise 15.6.1 Let μ ∈Rd, let C be a symmetric positive semideﬁnite real d ×
d matrix and let X ∼Nμ,C (in the sense of Remark 15.56). Show that AX ∼
NAμ,ACAT for every m ∈N and every real m × d matrix A. ♣
Exercise 15.6.2 (Cholesky factorization)
Let C be a positive deﬁnite symmet-
ric real d×d matrix. Then there exists a real d×d matrix A = (akl) with A·AT = C.
The matrix A can be chosen to be lower triangular. Let W := (W1, . . . , Wd)T , where
W1, . . . , Wd are independent and N0,1-distributed. Deﬁne X := AW +μ. Show that
X ∼Nμ,C. ♣

Chapter 16
Inﬁnitely Divisible Distributions
For every n, the normal distribution Nμ,σ 2 is the nth convolution power of a prob-
ability measure (namely, of Nμ/n,σ 2/n). This property is called inﬁnite divisibility
and is shared by other probability distributions such as the Poisson distribution and
the Gamma distribution. In the ﬁrst section, we study which probability measures
on R are inﬁnitely divisible and give an exhaustive description of this class of
distributions by means of the Lévy–Khinchin formula.
Unlike the Poisson distribution, the normal distribution is the limit of rescaled
sums of i.i.d. random variables (central limit theorem). In the second section, we
investigate brieﬂy which subclass of the inﬁnitely divisible measures on R shares
this property.
16.1
Lévy–Khinchin Formula
For the sake of brevity, in this section, we use the shorthand “CFP” for “character-
istic function of a probability measure on R”.
Deﬁnition 16.1 A measure μ ∈M1(R) is called inﬁnitely divisible if, for every
n ∈N, there is a μn ∈M1(R) such that μ∗n
n = μ. Analogously, a CFP ϕ is called
inﬁnitely divisible if, for every n ∈N, there is a CFP ϕn such that ϕ = ϕn
n. A real
random variable X is called inﬁnitely divisible if, for every n ∈N, there exist i.i.d.
random variables Xn,1, . . . , Xn,n such that X D= Xn,1 + . . . + Xn,n.
Manifestly, all three notions of inﬁnite divisibility are equivalent, and we will use
them synonymously. Note that the uniqueness of μn and ϕn, respectively, is by no
means evident. Indeed, n-fold divisibility alone does not imply uniqueness of the
nth convolution root μ∗1/n := μn or of ϕn, respectively. As an example for even n,
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_16
367

368
16
Inﬁnitely Divisible Distributions
choose a real-valued CFP ϕ for which |ϕ| ̸= ϕ is also a CFP (see Examples 15.17
and 15.18). Then ϕn = |ϕ|n is n-fold divisible; however, the factors are not unique.
By virtue of Lévy’s continuity theorem, one can show that (see Exercise 16.1.2)
ϕ(t) ̸= 0 for all t ∈R if ϕ is inﬁnitely divisible. The probabilistic meaning of this
fact is that as a continuous function log(ϕ(t)) is uniquely deﬁned and thus there
exists only one continuous function ϕ1/n = exp(log(ϕ)/n). The nth convolution
roots are thus unique if the distribution is inﬁnitely divisible.
Example 16.2
(i) δx is inﬁnitely divisible with δ∗n
x/n = δx for every n ∈N.
(ii) The normal distribution is inﬁnitely divisible with Nm,σ 2 = N ∗n
m/n,σ 2/n.
(iii) The Cauchy distribution Caua with density x →(aπ)−1 (1 + (x/a)2)−1 is
inﬁnitely divisible with Caua = Cau∗n
a/n. Indeed, Caua has CFP ϕa(t) =
e−a|t|; hence ϕn
a/n = ϕa.
(iv) Every symmetric stable distribution with index α ∈(0, 2] and scale parameter
γ > 0 (that is, the distribution with CFP ϕα,γ (t) = e−|γ t|α) is inﬁnitely
divisible. Indeed, ϕn
α,γ/n1/α = ϕα,γ . (To be precise, we have shown only for
α ∈(0, 1] (in Corollary 15.26) and for α = 2 (normal distribution) that ϕα,γ
is in fact a CFP. In Sect. 16.2, we will show that this is true for all α ∈(0, 2].
For α > 2, ϕα,γ is not a CFP, see Exercise 15.4.3.)
(v) The Gamma distribution Γθ,r with CFP ϕθ,r(t) = exp(rψθ(t)), where
ψθ(t) = log(1 −it/θ), is inﬁnitely divisible with Γθ,r = Γ ∗n
θ,r/n.
(vi) The Poisson distribution is inﬁnitely divisible with Poiλ = Poi∗n
λ/n.
(vii) The negative binomial distribution b−
r,p({k}) =
−r
k

(−1)kpr(1−p)k, k ∈N0,
with parameters r > 0 and p ∈(0, 1), is inﬁnitely divisible with b−
r,p =
(b−
r/n,p)∗n. Indeed, ϕr,p(t) = erψp(t), where
ψp(t) = log(p) −log

1 −(1 −p)eit
.
(viii) Let X and Y be independent with X ∼N0,σ 2 and Y ∼Γθ,r, where σ 2, θ, r >
0. It can be shown that the random variable Z := X/
√
Y is inﬁnitely divisible
(see [65] or [131]). In particular, Student’s t-distribution with k ∈N degrees
of freedom is inﬁnitely divisible (this is the case where σ 2 = 1 and θ = r =
k/2).
(ix) The binomial distribution bn,p with parameters n ∈N and p ∈(0, 1) is not
inﬁnitely divisible (why?).
(x) Somewhat more generally, there is no nontrivial inﬁnitely divisible distribu-
tion that is concentrated on a bounded interval. ♦
A main goal of this section is to show that every inﬁnitely divisible distribution can
be composed of three generic ones:
•
the Dirac measures δx with x ∈R,
•
the normal distributions Nμ,σ 2 with μ ∈R and σ 2 > 0, and
•
(limits of) convolutions of Poisson distributions.

16.1
Lévy–Khinchin Formula
369
As convolutions of Poisson distributions play a special role, we will consider them
separately.
If ν ∈M1(R) with CFP ϕν and if λ > 0, then one can easily check that ϕ(t) =
exp(λ(ϕν(t) −1)) is the CFP of μλ = ∞
k=0 e−λ λk
k! ν∗k. Hence, formally we can
write μλ = e∗λ(ν−δ0). Indeed, μλ is inﬁnitely divisible with μλ = μ∗n
λ/n. We want
to combine the two parameters λ and ν into one parameter λν. For ν ∈Mf (R),
we can deﬁne ν∗n = ν(R)n(ν/ν(R))∗n (and ν∗n = 0 if ν = 0). In both cases, let
ν∗0 := δ0. Hence we make the following deﬁnition.
Deﬁnition 16.3 The compound Poisson distribution with intensity measure ν ∈
Mf (R) is the following probability measure on R:
CPoiν := e∗(ν−ν(R)δ0) := e−ν(R)
∞

n=0
ν∗n
n! .
The CFP of CPoiν is given by
ϕν(t) = exp

(eitx −1) ν(dx)

.
(16.1)
In particular, CPoiμ+ν = CPoiμ ∗CPoiν; hence CPoiν is inﬁnitely divisible.
Example 16.4 For every measurable set A ⊂R \ {0} and every r > 0,
r−1CPoirν(A) = e−rν(R)ν(A) + e−rν(R)
∞

k=2
rk−1ν∗k(A)
k!
r↓0
−→ν(A).
We use this in order to show that b−
r,p = CPoirν for some ν ∈Mf (N). To this end,
for k ∈N, we compute
r−1b−
r,p({k}) = r(r + 1) · · · (r + k −1)
r k!
pr(1 −p)k
r↓0
−→(1 −p)k
k
.
If we had b−
r,p = CPoirν for some ν ∈Mf (N), then we would have ν({k}) =
(1 −p)k/k. We compute the CFP of CPoirν for this ν,
ϕrν(t) = exp

r
∞

k=1
((1 −p)eit)k −(1 −p)k
k

= pr 
1 −(1 −p)eit−r
.
However, this is the CFP of b−
r,p; hence indeed b−
r,p = CPoirν. ♦
Not every inﬁnitely divisible distribution is of the type CPoiν, however we have the
following theorem.

370
16
Inﬁnitely Divisible Distributions
Theorem 16.5 A probability measure μ on R is inﬁnitely divisible if and only if
there is a sequence (νn)n∈N in Mf (R \ {0}) such that CPoiνn
n→∞
−→μ.
If μ is inﬁnitely divisible and μn ∈M1(R) is such that μ∗n
n = μ for all n ∈N,
then νn = 1R\{0}nμn is a possible choice.
Since every CPoiνn is inﬁnitely divisible, on the one hand we have to show that
this property is preserved under weak limits. On the other hand, we show that, for
inﬁnitely divisible μ, the sequence νn = 1R\{0}nμ∗1/n does the trick. We prepare
for the proof of Theorem 16.5 with a further theorem.
Theorem 16.6 Let (ϕn)n∈N be a sequence of CFPs. Then the following are
equivalent.
(i) For every t ∈R, the limit ϕ(t) = lim
n→∞ϕn
n(t) exists and ϕ is continuous at 0.
(ii) For every t ∈R, the limit ψ(t) = lim
n→∞n(ϕn(t)−1) exists and ψ is continuous
at 0.
If (i) and (ii) hold, then ϕ = eψ is a CFP.
Proof The proof is based on a Taylor expansion of the logarithm,
| log(z) −(z −1)| ≤|z −1|2
for z ∈C with |z −1| < 1
2.
As an immediate consequence, we get
1
2|z −1| ≤| log(z)| ≤3
2|z −1|
for z ∈C with |z −1| < 1
2.
In particular, for (zn)n∈N in C,
lim sup
n→∞
n |zn −1| < ∞⇐⇒lim sup
n→∞
|n log(zn)| < ∞,
(16.2)
and limn→∞n(zn −1) = limn→∞n log(zn) if one of the limits exists.
Applying this to zn = ϕn(t), we see that (ii) implies (i). On the other hand, (i)
implies (ii) if lim infn→∞n log(|ϕn(t)|) > −∞and hence if ϕ(t) ̸= 0 for all t ∈R.
Since ϕ is continuous at 0 and since ϕ(0) = 1, there is an ε > 0 with |ϕ(t)| > 1
2
for all t ∈[−ε, ε]. Since ϕ and ϕn are CFPs, |ϕ|2 and |ϕn|2 are also CFPs. Thus,
since |ϕn(t)|2n converges to |ϕ(t)|2 pointwise, Lévy’s continuity theorem implies
uniform convergence on compact sets. Now apply (16.2) with zn = |ϕn(t)|2. Thus
(n(1 −|ϕn(t)|2))n∈N is bounded for t ∈[−ε, ε]. Hence, by Lemma 15.12(v),
n(1 −|ϕn(2t)|2) ≤4n(1 −|ϕn(t)|2) also is bounded; thus
|ϕ(2t)|2 ≥lim inf
n→∞exp(4n(|ϕn(t)|2 −1)) = (|ϕ(t)|2)4.

16.1
Lévy–Khinchin Formula
371
Inductively, we get |ϕ(t)| ≥2−(4k) for |t| ≤2kε. Hence there is a γ > 0 such that
|ϕ(t)| > 1
2 e−γ t2
for all t ∈R.
(16.3)
If (i) and (ii) hold, then
log ϕ(t) = lim
n→∞n log(ϕn(t)) = lim
n→∞n(ϕn(t) −1) = ψ(t).
By Lévy’s continuity theorem, as a continuous limit of CFPs, ϕ is a CFP.
⊓⊔
Corollary 16.7 If the conditions of Theorem 16.6 hold, then ϕr is a CFP for every
r > 0. In particular, ϕ = (ϕ1/n)n is inﬁnitely divisible.
Proof If ϕn is the CFP of μn ∈M1(R), then ern(ϕn−1) is the CFP of CPoirnμn.
Being a limit of CFPs that is continuous at 0, by Lévy’s continuity theorem, ϕr =
erψ = limn→∞ern(ϕn−1) is a CFP. Letting r =
1
n, we get that ϕ = (ϕ1/n)n is
inﬁnitely divisible.
⊓⊔
Corollary 16.8 Let ϕ : R →C be continuous at 0. ϕ is an inﬁnitely divisible CFP
if and only if there is a sequence (ϕn)n∈N of CFPs such that ϕn
n(t) →ϕ(t) for all
t ∈R.
Proof One implication has been shown already in Corollary 16.7. Hence, let ϕ be
an inﬁnitely divisible CFP. Then ϕn = ϕ1/n serves the purpose.
⊓⊔
Corollary 16.9 If (μn)n∈N is a (weakly) convergent sequence of inﬁnitely divisible
probability measures on R, then μ = limn→∞μn is inﬁnitely divisible.
Proof Apply Theorem 16.6, where ϕn is the CFP of μ∗1/n
n
.
⊓⊔
Corollary 16.10 If μ ∈M1(R) is inﬁnitely divisible, then there exists a continuous
convolution semigroup (μt)t≥0 with μ1 = μ and a stochastic process (Xt)t≥0 with
independent, stationary increments Xt −Xs ∼μt−s for t > s.
Proof Let ϕ be the CFP of μ. The existence of the convolution semigroup follows
by Corollaries 16.8 and 16.7 if we deﬁne μr by ϕr. Since ϕr(t) ̸= 0 for all t ∈
R, we have ϕr →1 for r →0 and thus the semigroup is continuous. Finally,
Theorem 14.50 implies the existence of the process X.
⊓⊔
Corollary 16.11 If ϕ is an inﬁnitely divisible CFP, then there exists a γ > 0 with
|ϕ(t)| ≥1
2e−γ t2 for all t ∈R. In particular, for α > 2, t →e−|t|α is not a CFP.
Proof This is a direct consequence of (16.3).
⊓⊔
Proof (of Theorem 16.5) As every CPoiνn is inﬁnitely divisible, by Corollary 16.9,
the weak limit is also inﬁnitely divisible.
Now let μ be inﬁnitely divisible with CFP ϕ. For n ∈N choose μn ∈M1(R)
such that μ∗n
n = μ and let ϕn the CFP of μn. Then ϕn
n = ϕ. By Theorem 16.6, we

372
16
Inﬁnitely Divisible Distributions
have en(ϕn−1) n→∞
−→ϕ. As en(ϕn−1) is the CFP of CPoinμn, we infer CPoinμn
n→∞
−→
μ. Now let νn = 1R\{0}nμn. Then CPoiνn = CPoinμn
n→∞
−→μ.
⊓⊔
Without proof, we quote the following strengthening of Corollary 16.8 that relies on
a ﬁner analysis using the arguments from the proof of Theorem 16.6.
Theorem 16.12 Let (ϕn,l; l = 1, . . . , kn, n ∈N) be an array of CFPs with the
property
sup
L>0
lim sup
n→∞
sup
t∈[−L,L]
sup
l=1,...,kn
|ϕn,l(t) −1| = 0.
(16.4)
Assume that, for every t ∈R, the limit ϕ(t) := limn→∞
kn
l=1 ϕn,l(t) exists and that
ϕ is continuous at 0. Then ϕ is an inﬁnitely divisible CFP.
Proof See, e.g., [54, Chapter XV.7].
⊓⊔
In the special case where for every n, the individual ϕn,l are equal and where
kn
n→∞
−→
∞, equation (16.4) holds automatically if the product converges to a
continuous function. Thus, the theorem is in fact an improvement of Corollary 16.8.
The beneﬁt of this theorem will become clear through the following observation.
Let (Xn,l; l = 1, . . . , kn, n ∈N) be an array of real random variables with CFPs
ϕn,l. This array is a null array if and only if (16.4) holds. In fact, if P[|Xn,l| > ε] < δ,
then we have |ϕn,l(t) −1| ≤2ε + δ for all t ∈[−1/ε, 1/ε]. Hence (16.4) holds if
the array (Xn,l) is a null array. On the other hand, (16.4) implies ϕn,ln
n→∞
−→1 for
every sequence (ln) with ln ≤kn. Hence Xn,ln
n→∞
−→0 in probability.
From these considerations and from Theorem 16.12, we conclude the following
theorem.
Theorem 16.13 Let (Xn, l; l = 1, . . . , kn, n ∈N) be an independent null array of
real random variables. If there exists a random variable S with
Xn,1 + . . . + Xn,kn
n→∞
⇒S,
then S is inﬁnitely divisible.
As a direct application of Theorem 16.5, we give a complete description of the
class of inﬁnitely divisible probability measures on [0, ∞) in terms of their Laplace
transforms. The following theorem is of independent interest. Here, however, it is
primarily used to provide familiarity with the techniques that will be needed for the
more challenging classiﬁcation of the inﬁnitely divisible probability measures on R.
Theorem 16.14 (Lévy–Khinchin formula on [0, ∞)) Let μ ∈M1([0, ∞)) and
let u : [0, ∞) →[0, ∞), t →−log
3
e−tx μ(dx) be the log-Laplace transform μ.
μ is inﬁnitely divisible if and only if there exists an α ≥0 and a σ-ﬁnite measure

16.1
Lévy–Khinchin Formula
373
ν ∈M((0, ∞)) with

(1 ∧x) ν(dx) < ∞
(16.5)
and such that
u(t) = αt +
 
1 −e−tx
ν(dx)
for t ≥0.
(16.6)
In this case, the pair (α, ν) is unique. ν is called the canonical measure or Lévy
measure of μ, and α is called the deterministic part.
Proof “ ⇒”
First assume μ is inﬁnitely divisible. The case μ = δ0 is trivial.
Now let μ ̸= δ0; hence u(1) > 0.
For n ∈N, there exists a μn ∈M1(R) such that μ∗n
n
= μ. Clearly, we have
μn((−∞, 0))n ≤μ((−∞, 0)) = 0. Hence μn is supported by [0, ∞). Deﬁne νn =
nμn ∈Mf ([0, ∞)). By Theorem 16.5, we have CPoiνn
n→∞
−→μ.
If we deﬁne un(t) :=
3
(1−e−tx) νn(dx), then (as in (16.1)) un(t)
n→∞
−→u(t) for
all t ≥0. In particular, un(1) > 0 for sufﬁciently large n. Deﬁne ˜νn ∈M1([0, ∞))
by ˜νn(dx) := 1−e−x
un(1) νn(dx). Hence, for all t ≥0,

e−tx ˜νn(dx) = un(t + 1) −un(t)
un(1)
n→∞
−→
u(t + 1) −u(t)
u(1)
.
The right hand side is continuous and hence a variation of Lévy’s continuity
theorem for Laplace transforms (compare Exercise 15.3.4) yields that the weak
limit ˜ν := w-lim ˜νn (in M1([0, ∞)) exists and is uniquely determined by u. Let
α := ˜ν({0}) u(1) and deﬁne ν ∈M((0, ∞)) by
ν(dx) = u(1)(1 −e−x)−1 1(0,∞)(x) ˜ν(dx).
Since 1 ∧x ≤2(1 −e−x) for all x ≥0, clearly

(1 ∧x) ν(dx) ≤2

(1 −e−x) ν(dx) ≤2u(1) < ∞.
For all t ≥0, the function (compare (15.8))
ft : [0, ∞) →[0, ∞),
x →

1−e−tx
1−e−x ,
if x > 0,
t,
if x = 0,

374
16
Inﬁnitely Divisible Distributions
is continuous and bounded (by t ∨1). Hence we have
u(t) = lim
n→∞un(t) = lim
n→∞un(1)

ft d ˜νn
= u(1)

ft d ˜ν = αt +

(1 −e−tx) ν(dx).
“ ⇐ ”
Now assume that α and ν are given. Deﬁne the intervals I0 = [1, ∞) and
Ik = [1/(k + 1), 1/k) for k ∈N. Let X0, X1, . . . be independent random variables
with PXk = CPoi(ν|Ik ) for k = 0, 1, . . ., and let X := α + ∞
k=0 Xk. For every
k ∈N, we have E[Xk] =
3
Ik x ν(dx); hence ∞
k=1 E[Xk] =
3
(0,1) x ν(dx) < ∞.
Thus X < ∞almost surely and α + n
k=0 Xk
n→∞
⇒X. Therefore,
−log E
)
e−tX*
= αt −
∞

k=0
log E
)
e−tXk*
= αt +
 
1 −e−tx
ν(dx).
“Uniqueness” For x, t > 0, we have
0 ≤t−1 (1 −e−tx) ≤x ∧1
t
t→∞
−→0.
By the dominated convergence theorem with dominating function 1 ∧x for t ≥1,
we infer
t−1

(1 −e−tx) ν(dx)
t→∞
−→0.
Thus we can compute α as
α = lim
t→∞u(t)/t.
Deﬁne the map h : (0, ∞) →(0, 1) by
h(x) = 1 −1 −e−x
x
.
Note that h(x)/(1 ∧x) ≤1 for all x > 0. Hence ˜ν := hν is a ﬁnite measure and
ν = h−1˜ν is uniquely deﬁned by ˜ν. Let
u(t) := α
2 + u(t) −
 t+1
t
u(s) ds
=

e−tx

1 −
 1
0
e−sxds

ν(dx) =

e−tx ˜ν(dx).
That is, u is the Laplace transform of ˜ν which determines ˜ν and ν uniquely.
⊓⊔

16.1
Lévy–Khinchin Formula
375
Example 16.15 For an inﬁnitely divisible distribution μ on [0, ∞), we can compute
the Lévy measure ν by the vague limit
ν = v-lim
n→∞nμ∗1/n
(0,∞).
(16.7)
Often α is also easy to obtain (e.g., via the representation from Exercise 16.1.3). For
example, for the Gamma distribution, we get α = 0 and
nΓθ,1/n(A) =
θ1/n
Γ (1/n)/n

A
x(1/n)−1 e−θx dx
n→∞
−→

A
x−1 e−θx dx,
hence ν(dx) = x−1e−θx dx. ♦
For inﬁnitely divisible distributions on R, we would like to obtain a description
similar to that in the preceding theorem. However, an inﬁnitely divisible real random
variable X is not simply the difference of two inﬁnitely divisible nonnegative
random variables, as the normal distribution shows. In addition, we have more
freedom if, as in the last proof, we want to express X as a sum of independent
random variables Xk.
Hence we deﬁne the real random variable X as the sum of independent random
variables,
X = b + XN + X0 +
∞

k=1
(Xk −αk),
(16.8)
where b ∈R, XN = N0,σ 2 for some σ 2 ≥0 and PXk = CPoiνk with intensity
measure νk that is concentrated on Ik := (−1/k, −1/(k + 1)] ∪[1/(k + 1), 1/k)
(with the convention 1/0 = ∞), k ∈N0. Furthermore, αk = E[Xk] =
3
x νk(dx)
for k ≥1. In order for the series to converge almost surely, it is sufﬁcient (and also
necessary, as a simple application of Kolmogorov’s three-series theorem shows) that
∞

k=1
Var[Xk] < ∞.
(16.9)
(In contrast to the situation in Theorem 16.14, here it is not necessary to have
∞
k=1 E[|Xk −αk|] < ∞. This allows for greater freedom in the choice of ν than
in the case of nonnegative random variables.) Now Var[Xk] =
3
x2 νk(dx). Hence,
if we let ν = ∞
k=0 νk, then (16.9) is equivalent to
3
(−1,1) x2 ν(dx) < ∞. As ν0 is
always ﬁnite, this in turn is equivalent to
3
(x2 ∧1) ν(dx) < ∞.

376
16
Inﬁnitely Divisible Distributions
Deﬁnition 16.16 A σ-ﬁnite measure ν on R is called a canonical measure if
ν({0}) = 0 and
 
x2 ∧1

ν(dx) < ∞.
(16.10)
If σ 2 ≥0 and b ∈R, then (σ 2, b, ν) is called a canonical triple.
To every canonical triple, by (16.8) there corresponds an inﬁnitely divisible random
variable. Deﬁne
ψ0(t) = log E)eitX0* =

I0
eitx −1 ν(dx).
For k ∈N, let
ψk(t) = log E
)
eit(Xk−αk)*
=

Ik

eitx −1 −itx

ν(dx).
(Note that it is not a priori clear, that the logarithm in the two equations above is
well-deﬁned. In general, the expectation could be zero for some t. However, the
right hand sides are well-deﬁned and by (16.1) are the exponentials of the left hand
sides. Hence the logarithms could be applied on both sides. This also shows that the
expectations on the left hand side never equal zero. Hence
ψ(t) := log E
)
eitX*
= −σ 2
2 t2 + ibt +
∞

k=0
ψk(t)
satisﬁes the Lévy–Khinchin formula
ψ(t) = −σ 2
2 t2 + ibt +
 
eitx −1 −itx 1{|x|<1}

ν(dx).
(16.11)
Theorem 16.17 (Lévy–Khinchin formula) Letμ ∈M1(R) and
ψ(t) := log

eitx μ(dx).
μ is inﬁnitely divisible if and only if ψ is well-deﬁned and there exists a canonical
triple (σ 2, b, ν) such that (16.11) holds. By (16.11), this triple is uniquely deter-
mined.
Again, ν is called the Lévy measure of μ, σ 2 is called the Gaussian coefﬁcient and
b is called the centering constant.

16.1
Lévy–Khinchin Formula
377
Proof We have shown already that via (16.11) every canonical triple (σ 2, b, ν)
corresponds to an inﬁnitely divisible distribution μ. It remains to show:
(i) A canonical triple is uniquely determined by (16.11).
(ii) For every inﬁnitely divisible distribution, there exists a canonical triple such
that (16.11) holds.
(i) Uniqueness. For ε ∈[0, 1/2) and t ≥0, deﬁne
gt,ε(x) = eitx −1 −itx 1{|x|<1−ε}.
For ε = 0, this is the function in the Lévy-Khinchin formula (16.11). However,
since we will work with weak convergence and since gt,ε is discontinuous at
x = −(1 −ε) and x = 1 −ε, we will later need to adjust the parameter ε in
such a way that ν does not have atoms at these points of discontinuity. Finally,
we will let ε →0.
Obviously, we have |gt,ε(x)| ≤2 + |t|. Hence, for x ̸= 0,

gt,ε(x)
t2(1 ∧x2)
 ≤2 + |t|
t2
1
1 ∧x2
t→∞
−→0.
(16.12)
For x ∈(−1/2, 1/2), by Lemma 15.31, we have
gt,ε(x)
 =
eitx −1 −itx
 ≤(tx)2.
For t ≥1, ε ∈[0, 1/2) and x ̸= 0, we thus have (note that (2 + |t|)/t2 ≤3)

gt,ε(x)
t2(1 ∧x2)
 ≤12.
(16.13)
Since (16.10) holds, by the dominated convergence theorem,
lim
t→∞
ψ(t)
t2
= −σ 2
2 + lim
t→∞
ib
t + lim
t→∞
 ∞
−∞

gt(x)
t2(1 ∧x2)

(1 ∧x2)ν(dx)
= −σ 2
2 .
(16.14)
This implies the uniqueness of σ 2. Thus we can and will assume σ 2 = 0 in the
following. Deﬁne
ψ(t) = ψ(t) −1
2
 t+1
t−1
ψ(s) ds.
(16.15)

378
16
Inﬁnitely Divisible Distributions
Then
ψ(t) =

R
eitx

1 −1
2
 1
−1
eisx ds

ν(dx) =

eitx h(x) ν(dx),
(16.16)
where h(x) = 1 −sin(x)
x
for x ̸= 0 and h(0) = 0. Deﬁne ˆh(x) = h(x)/(1 ∧x2)
for x ̸= 0 and ˆh(0) = 1/6. Clearly, h and ˆh are bounded and continuous and
1
7 < 1 −sin(1) ≤ˆh(x) ≤3
2
for any x ∈R.
(16.17)
ψ is the characteristic function of ˜ν ∈Mf (R), where ˜ν(dx) = h(x)ν(dx).
Hence ˜ν is uniquely determined by ψ. Since ν(dx) = (1{x̸=0}/h(x))˜ν(dx), ν
is also uniquely determined by ψ. Now the number b is the difference of the
remaining terms.
(ii) Existence of a canonical triple. Let μ be inﬁnitely divisible and let
ψ(t) = log

eitx μ(dx).
Clearly, Im(ψ) is odd and Re(ψ(t)) ≤0 for all t ∈R. Hence ψ(0) ≥0 (with ψ
from (16.15)) and ψ(0) = 0 if Reψ(t) = for all t ∈[−1, t]. By Exercise 15.2.4,
this is the case if and only if μ = δb for some b ∈R. In this case, (0, b, 0) is
the corresponding canonical triple.
Now assume ψ(0) > 0. By Theorem 16.5, there exists a sequence (νn)n∈N in
Mf (R) with CPoiνn
n→∞
−→μ and νn({0}) = 0 for any n ∈N. Deﬁne
bn,ε =

x 1{|x|<1−ε} νn(dx)
for ε ∈[0, 1/2).
Then, by (16.1) and with gt,ε from (i) (and for any ε ∈[0, 1/2)),
ψn(t) := log

eitx CPoiνn(dx) =

(eitx −1) νn(dx) =

gt,ε dνn + ibn,εt.
As in (16.16), we have
ψn(t) := ψn(t) −1
2
 t+1
t−1
ψn(s) ds =

eitx h(x) νn(dx).

16.1
Lévy–Khinchin Formula
379
As ψn
n→∞
−→
ψ converges uniformly on compact sets (Theorem 15.24(i)), and
since ψ is continuous and thus locally bounded, we have ψn
n→∞
−→ψ pointwise.
Therefore,

eitx h(x) νn(dx)
n→∞
−→ψ(t).
(16.18)
In particular, ψn(0) > 0 for large n. If we let ˜νn(dx) = (h(x)/ψn(0))νn(dx) ∈
M1(R), then
3
eitx ˜νn(dx)
n→∞
−→ψ(t)/ψ(0) and the right-hand side is continuous.
Hence, by Lévy’s continuity theorem, there is a ˜ν ∈M1(R) with ˜νn
n→∞
−→˜ν and
ψ(t) = ψ(0)

eitx ˜ν(dx).
Let σ 2 := −6 ψ(0) ˜ν({0}) and deﬁne a canonical measure ν by
ν(dx) = ψ(0)
h(x) 1{x̸=0} ˜ν(dx).
For any t ∈R and ε ∈[0, 1/2), the map (compare (15.8))
ft,ε : R →C,
x →
 gt,ε(x)
h(x) ,
if x ̸= 0,
−3t2,
if x = 0,
is continuous except for the points |x| = 1 −ε and is bounded (by 84 t2, see (16.13)
and (16.17)). Since ν((−1/2, 1/2)c) < ∞, the set of ε such that ν({1 −ε} ∪{−1 +
ε}) = 0 is dense in [0, 1/2]. Let (εk)k∈N be a sequence in [0, 1/2] such that εk ↓0
and ν({1 −εk} ∪{−1 + εk}) = 0. Fix k ∈N. By the Portemanteau Theorem
(Theorem 13.16(iii)), we infer

gt,εk dνn = ψn(0)

ft,εk d ˜νn
n→∞
−→ψ(0)

ft,εk d ˜ν = −σ 2
2 t2 +

gt,εk dν.
Hence also the limit
it bεk := lim
n→∞it bn,εk = lim
n→∞

ψn(t) −

gt,εk dνn

= ψ(t) + σ 2
2 t2 −

gt,εk dν
exists and we have
ψ(t) = −σ 2
2 t2 + ibεkt +

gt,εk dν.

380
16
Inﬁnitely Divisible Distributions
As |gt,εk(x)| ≤12t2(1 ∧x2), and since gt,εk(x)
k→∞
−→
gt,0(x), the dominated
convergence theorem yields

gt,0 dν = lim
k→∞

gt,εk dν.
Also, since ν((−1/2, 1/2)c) < ∞, the limit
b := lim
k→∞bεk
exists and we have
ψ(t) = −σ 2
2 t2 + ibt +

gt,0 dν.
⊓⊔
Remark 16.18 There are many versions of the Lévy–Khinchin formula
ψ(t) = −σ 2
2 t2 + ibt +
 
eitx −1 −it f (x)

ν(dx)
that differ in the function it f (x) that is subtracted for the centering in the integral.
We chose f (x) = x 1{|x|<1} since this ﬁts best to the construction with the random
variables Xk. However, for a given canonical measure ν, any function ˜f for which
3 |f −˜f | dν < ∞holds is possible; that is, every ˜f for which |f (x)−˜f (x)|/(1∧x2)
is bounded. One common function is, e.g., ˜f (x) = sin(x). The Lévy measure and
the Gaussian coefﬁcient σ 2 do not change but the b differs:
˜b −b =
  ˜f −f  dν.
If ν is a measure that is concentrated on (0, ∞) and such that
3
(1 ∧x) ν(dx) < ∞
holds, then this f is integrable with respect to ν and can thus be replaced by ˜f = 0.
Hence we recover Theorem 16.14 as a special case. However, condition (16.10) is
weaker than
3
(1 ∧x) ν(dx) < ∞and thus describes a larger class of measures than
is considered in Theorem 16.14. This implies that to a canonical triple (b, 0, ν) with
ν((−∞, 0)) = 0 and
3
(1 ∧x) ν(dx) = ∞, there corresponds an inﬁnitely divisible
probability distribution μ that is not concentrated on [0, ∞), no matter how b is
chosen. ♦
Reﬂection In the proof of Theorem 16.17, why was it necessary to introduce the
ε > 0? How can we get rid of this technicality by replacing the function f (x) =
x 1{|x|<1} by ˜f (x) = sin(x), as in Remark 16.18? What are the problems that come
with this approach? ♠♠

16.2
Stable Distributions
381
For a given inﬁnitely divisible distribution μ, we can compute the canonical measure
ν as the vague limit
ν = v-lim
n→∞nμ∗1/n
R\{0}.
(16.19)
Example 16.19 For the Cauchy distribution Caua with ψ(t) = −a |t|, by symme-
try, we get b = 0 and, by (16.14), σ 2 = −2 limt→∞ψ(t)/t2 = 0. Finally, if A ⊂R
with (−ε, ε) ∩A = ∅for some ε > 0, then
n Cau1/n(A) = 1
π

A
n2
1 + (nx)2 dx
n→∞
−→
1
π

A
1
x2 dx.
Hence Cau1 has the canonical triple

0, 0, (πx2)−1dx

. ♦
Takeaways An inﬁnitely divisible random variable can be written as a sum
of arbitrarily many independent and identically distributed random variables.
On the other hand, it can also be split into three characteristic parts: a
deterministic number, a normally distributed random variable and a mixture
of Poisson jumps of various sizes (Lévy-Khinchin formula). Every inﬁnitely
divisible distribution is a weak limit of compound Poisson distributions.
Exercise 16.1.1 Use a variance argument to show that an inﬁnitely divisible
distribution that is concentrated on a bounded interval is a Dirac measure. ♣
Exercise 16.1.2 Let ϕ be inﬁnitely divisible, and for every n ∈N, let ϕn be a CFP
with ϕn
n = ϕ. Use Lévy’s continuity theorem to show that ϕn
n→∞
−→1 uniformly on
compact sets ϕn
n→∞
−→1. Conclude that ϕ(t) ̸= 0 for all t ∈R. ♣
Exercise 16.1.3 Under the conditions of Theorem 16.14, show that
α = sup
	
x ≥0 : μ([0, x)) = 0

.
♣
16.2
Stable Distributions
A distribution μ on the real numbers is called stable if for any n ∈N, the n-fold
convolution μ∗n equals μ up to an afﬁne linear transformation. Hence stability can
be interpreted as self-similarity. We ﬁrst show that the class of stable distributions
is rather simple and can easily be parameterized. Then we quote results which say
that stable distributions are exactly those distributions that occur as limits of sums
of i.i.d. random variables.

382
16
Inﬁnitely Divisible Distributions
Symmetric Stable Distributions
For α ∈(0, 2), let
θα :=

R
(1 −cos(x)) |x|−α−1 dx =
0−2Γ (−α) cos(απ/2),
if α ̸= 1,
π,
if α = 1.
(Note that the integral diverges for α ∈R\(0, 2)). Then να(dx) = θ−1
α
|x|−α−1 dx
is a canonical measure since

(1 ∧x2) να(dx) = 2 θ−1
α

α−1 + (2 −α)−1
< ∞.
Let ψα be the logarithm of the characteristic function that corresponds to the
inﬁnitely divisible measure μα with canonical triple (0, 0, να). By the Lévy–
Khinchin formula, we have
ψα(t) =
 ∞
−∞
eitx −1 −itx 1{|x|<1}
 θ−1
α
|x|−α−1 dx
= −θ−1
α
 ∞
−∞
1 −cos(tx) |x|−α−1 dx
= −|t|α.
Hence ϕα(t) := e−|t|α is the characteristic function of the inﬁnitely divisible
measure μα, which is called the symmetric stable distribution with index α. The
name is due to the fact that, for i.i.d. random variables X1, X2, . . . that are μα-
distributed, we have
X1 + . . . + Xn
D= n1/αXn
for all n ∈N.
(16.20)
General Stable Distributions
Motivated by equation (16.20), we present a somewhat more general notion of
stability of a distribution.
Deﬁnition 16.20 (Stable distribution) Let μ ∈M1(R) be a probability distri-
bution on the real numbers that is not concentrated in one point. Assume that
X1, X2, . . . are i.i.d. random variables with distribution μ. The distribution μ is

16.2
Stable Distributions
383
said to be stable in the broad sense if there exist nonnegative numbers a1, a2, . . .
and real numbers d1, d2, . . . such that
X1 + . . . + Xn
D= an X1 + dn
for all n ∈N.
(16.21)
μ is called stable (in the strict sense), if (16.21) holds with d1 = d2 = . . . = 0.
μ is called stable in the broad sense with index α ∈(0, 2], if (16.21) holds with
an = n1/α, n ∈N. It is called stable (in the strict sense) with index α ∈(0, 2], if in
addition, we can choose d1 = d2 = . . . = 0.
Remark 16.21 If μ is stable in the broad sense, then it is inﬁnitely divisible. ♦
Theorem 16.22 Let μ be stable in the broad sense.
(i) There is an α ∈(0, 2] such that μ is stable in the broad sense with index α.
(ii) If α = 2, then μ is a normal distribution.
(iii) If α ∈(0, 2), then the Lévy measure ν of μ has the density
ν(dx)
dx
=

c−(−x)−α−1,
if x < 0,
c+ x−α−1,
if x > 0,
(16.22)
for some c−, c+ ≥0, c−+ c+ > 0.
(iv) If α ̸= 1, then there exists a b ∈R such that μ ∗δ−b is stable with index α.
(v) If α = 1, then dn = (c+ −c−) n log(n), n ∈N. If c−= c+, then μ is a
Cauchy distribution.
Remark 16.23 If μ is inﬁnitely divisible with Lévy measure ν given by (16.22),
then ψ(t) := log
3
eitx μ(dx) is given by
ψ(t)=
⎧
⎨
⎩
|t|αΓ (−α)
)
(c+ + c−) cos
 πα
2

−i sign(t) (c+ −c−) sin
 πα
2
*
, α ̸= 1,
−|t|(c+ + c−)
)π
2 + i sign(t)(c+ −c−) log(|t|)
*
, α = 1.
(16.23)
♦
Lemma 16.24 Let μ be inﬁnitely divisible with canonical triple (σ 2, b, ν); that is,
with log-characteristic function ψ(t) := log
 3
eitxμ(dx)

given by
ψ(t) = −σ 2
2 t2 + ibt +
 
eitx −1 −itx 1{|x|<1}

ν(dx).
Further, let a > 0, d ∈R, n ∈N and let X, X1, . . . , Xn be i.i.d. random variables
with distribution μ.
(i) The canonical triple of X1 + . . . + Xn is (nσ 2, nb, nν).

384
16
Inﬁnitely Divisible Distributions
(ii) The canonical triple of aX + d is (a2σ 2, ˜b, ν ◦m−1
a ), where ma : R →R,
x →ax is the multiplication by a and
˜b := ab + d + a

(1{|x|<1/a} −1{|x|<1})x ν(dx).
(16.24)
Proof
(i) The log-characteristic function of X1 + . . . + Xn is nψ.
(ii) The log-characteristic function of aX + d is
ψaX+d(t) = ψ(at) + idt
= −a2σ 2
2
t2 + i(ab + d)t +
 
eiatx −1 −iatx 1{|x|<1}

ν(dx)
= −a2σ 2
2
t2 + i ˜bt +
 
eiatx −1 −iatx 1{|x|<1/a}

ν(dx)
= −a2σ 2
2
t2 + i ˜bt +
 
eitx −1 −itx 1{|x|<1}

ν ◦m−1
a (dx).
⊓⊔
Lemma 16.25 (Scaling of the canonical triple) Under the assumptions of Theo-
rem 16.22, let (σ 2, b, ν) be the canonical triple of μ.
(i) We have
(a2
n −n)σ 2 = 0
for all n ∈N
(16.25)
and (with man as in Lemma 16.24)
nν = ν ◦m−1
an
for all n ∈N.
(16.26)
(ii) If ν = 0, then an = n1/2 for all n ∈N and
dn = b

n −n1/2).
(16.27)
(iii) Assume that α ∈(0, 2), an = n1/α, and that ν is given by (16.22). Then we
have
dn =

b + c+ −c−
α −1
 n −n1/α
if α ̸= 1,
(16.28)
and
dn = (c+ −c−) n log(n)
if α = 1.
(16.29)

16.2
Stable Distributions
385
Proof
(i) Let (a2
nσ 2, ˜bn, ν◦m−1
an ) be the canonical triple of anX+dn as determined in the
preceding lemma and let (nσ 2, nb, nν) be the canonical triple of X1+. . .+Xn.
By (16.21) and due to the uniqueness of the canonical triple (Theorem 16.17),
we infer a2
nσ 2 = nσ 2, ˜bn = nb and ν ◦m−1
an = nν.
(ii) If ν = 0, then σ 2 > 0, since by assumption, μ is not concentrated in one point.
Hence, by (16.25), we get an = n1/2. By virtue of Lemma 16.24(ii), we have
nb = ˜bn = bn1/2 + dn and thus (16.27) holds.
(iii) Using (16.24), we compute ˜bn more explicitly:
nb = ˜bn = bn1/α + dn −n1/α

1{n−1/α≤|x|<1}x ν(dx)
= bn1/α + dn −n1/α(c+ −c−)
 1
n−1/α x−α dx
= bn1/α + dn −(c+ −c−)

(1 −α)−1(n1/α −n),
if α ̸= 1,
n log(n),
if α = 1.
Rearranging terms yields (16.28) and (16.29).
⊓⊔
Proof (of Theorem 16.22) We distinguish the cases lim infn→∞an n−1/2 < ∞and
“= ∞”.
Case 1.
Assume that lim infn→∞an n−1/2 < ∞. Let C ∈[1, ∞) and let (nk)k∈N
be a subsequence such that ank n−1/2
k
≤C for any k ∈N. Then for any x ∈R \ {0},
we have
C2 ≥n−1
k (1 ∨a2
nk) ≥
n−1
k (1 ∧a2
nkx2)
1 ∧x2
k→∞
−→0.
Using (16.26) and (16.10), the dominated convergence theorem yields
 ∞
−∞
(1 ∧x2) ν(dx) =
 ∞
−∞
n−1
k (1 ∧a2
nkx2)
1 ∧x2
(1 ∧x2) ν(dx)
k→∞
−→0.
That is, we have ν = 0. By Lemma 16.25(ii), we see that μ ∗δ−b is stable with
index 2. This shows (ii).
Case 2.
Assume that
an n−1/2 n→∞
−→∞.
(16.30)

386
16
Inﬁnitely Divisible Distributions
By (16.25), we have σ 2 = 0 and hence ν ̸= 0. We deﬁne the function
F(x) =

ν([x, ∞)),
if x > 0,
ν((−∞, x]),
if x < 0.
Since we have ν ̸= 0, there is an x0 ∈R \ {0} such that F(x0) > 0. By symmetry,
we may assume that x0 > 0. Using (16.26), we infer
n F(x) = F(x/an)
for any x ∈R \ {0}, n ∈N,
and thus
F
an+1
an
k
x0

=

n
n + 1
k
F(x0)
for any k ∈Z.
We can rephrase this as
F(x) = (x/x0)−αnF(x0)
for any x ∈	(an+1/an)k x0 : k ∈Z
,
where αn := log((n + 1)/n)/ log(an+1/an). Since F is monotone decreasing and
since F(x)
x→∞
−→0, we have αn > 0 for all n ∈N, and

m
m + 1
  x
x0
−αm
≤F(x)
F(x0) ≤
n + 1
n
  x
x0
−αn
for x > 0, m, n ∈N.
Letting x →∞, we obtain αm ≥αn. By symmetry, we also get αm ≤αn. Hence,
we deﬁne α := α1 > 0 and get an = n1/α for all n ∈N (note that (16.21) implies
a1 = 1). By the assumption (16.30), we have α < 2. This shows (i).
We have F(1) = xα
0 F(x0) > 0 and F(x) = x−α F(1) for all x > 0. Similarly,
we get F(x) = (−x)−αF(−1) for x < 0 (with the same α ∈(0, 2) since it
is determined by the sequence (an)n∈N). Deﬁning c+ = α ν([1, ∞)) and c−:=
αν((−∞, −1]), we get (16.22) and thus (iii) and (i).
The statements (iv) and (v) are immediate consequences of Lemma 16.25.
⊓⊔
Convergence to Stable Distributions
To complete the picture, we cite theorems from [54, Chapter XVII.5] (see also [62]
and [128]) that state that only stable distributions occur as limiting distributions of
rescaled sums of i.i.d. random variables X1, X2, . . ..
In the following, let X, X1, X2, . . . be i.i.d. random variables and for n ∈N, let
Sn = X1 + . . . + Xn.

16.2
Stable Distributions
387
Deﬁnition 16.26 (Domain of attraction) Let μ ∈M1(R) be nontrivial. The
domain of attraction Dom(μ) ⊂M1(R) is the set of all distributions PX with
the property that there exist sequences of numbers (an)n∈N and (dn)n∈N with
Sn −dn
an
n→∞
⇒μ.
If μ is stable (in the broader sense) with index α ∈(0, 2], then PX is said to be in
the domain of normal attraction if we can choose an = n1/α.
Theorem 16.27 Let μ ∈M1(R) be nontrivial. Then Dom(μ) ̸= ∅if and only if μ
is stable (in the broader sense). In this case, μ ∈Dom(μ).
In the following, an important role is played by the function
U(x) := E)X2 1{|X|≤x}
*.
(16.31)
A function H : (0, ∞) →(0, ∞) is called slowly varying at ∞if
lim
x→∞
H(γ x)
H(x) = 1
for all γ > 0.
In the following, we assume that there exists an α ∈(0, 2] such that
U(x) xα−2 is slowly varying at ∞.
(16.32)
Theorem 16.28
(i) If PX is in the domain of attraction of some distribution, then there exists an
α ∈(0, 2] such that (16.32) holds.
(ii) In the case α = 2, we have: If PX is not concentrated at one point, then (16.32)
implies that PX is in the domain of attraction of some distribution.
(iii) In the case α ∈(0, 2), we have: PX is in the domain of attraction of some
distribution if and only if (16.32) holds and the limit
p := lim
x→∞
P[X ≥x]
P[|X| ≥x]
exists.
(16.33)
Theorem 16.29 Let PX be in the domain of attraction of an α-stable distribution
(that is, assume that condition (ii) or (iii) of Theorem 16.28 holds), and assume that
(an)n∈N is such that
C := lim
n→∞
n U(an)
a2n
∈(0, ∞)
exists. Further, let μ be the stable distribution with index α whose characteristic
function is given by (16.23) with c+ = Cp and c−= C(1 −p).

388
16
Inﬁnitely Divisible Distributions
(i) In the case α ∈(0, 1), let bn ≡0.
(ii) In the case α = 2 and Var[X] < ∞, let E[X] = 0.
(iii) In the case α ∈(1, 2], let dn = n E[X] for all n ∈N.
(iv) In the case α = 1, let dn = n an E[sin(X/an)] for all n ∈N.
Then
Sn −dn
an
n→∞
⇒μ.
Corollary 16.30 If PX is in the domain of attraction of a stable distribution with
index α, then E
)
|X|β*
< ∞for all β ∈(0, α) and E
)
|X|β*
= ∞if β > α and
α < 2.
Takeaways A random variable X is called inﬁnitely divisible if for any n ∈N
it can be written as a sum of n independent and identically distributed random
variables. It is called stable if each of the summands has the same distribution
as bn + X/an for some sequences (an) and (bn). We have seen that in this
case, we must have an = n1/α for some α ∈(0, 2]. A stable distribution is
characterised by its index α and a skewness parameter (and, of course, a scale
parameter); see Remark 16.23.
Exercise 16.2.1 Let μ be an α-stable distribution and let ϕ be its characteristic
function.
(i) Show by a direct computation using only the deﬁnition of stability that
|ϕ(t) −1| ≤C|t|α for t close to 0 (for some C < ∞).
(ii) Use Exercise 15.3.2 to infer that μ = δ0 if α > 2.
(iii) Modify the argument in order to show that for α > 2, the α-stable distributions
in the broad sense are also necessarily trivial. ♣
Exercise 16.2.2 Show that the distribution on R with density f (x) = 1 −cos(x)
πx2
is not inﬁnitely divisible. ♣
Exercise 16.2.3 Let Φ be the distribution function of the standard normal distribu-
tion N0,1 and let F : R →[0, 1] be deﬁned by
F(x) =

2

1 −Φ

x−1/2
,
if x > 0,
0,
else.
Show the following.
(i) F is the distribution function of a 1
2-stable distribution.
(ii) If X1, X2, . . . are i.i.d. with distribution function F, then 1
n
n
k=0 Xk diverges
almost surely for n →∞.

16.2
Stable Distributions
389
Hint: Compute the density of F, and show that the Laplace transform is given by
λ →e−
√
2λ. ♣
Exercise 16.2.4 Which of the following distributions is in the domain of attraction
of a stable distribution and for which parameter?
(i) The distribution on R with density
f (x) =
⎧
⎪⎪⎨
⎪⎪⎩
ϱ
1
1+α |x|α,
if x < −1,
(1 −ϱ)
1
1+β xβ,
if x > 1,
0,
else.
Here α, β < −1 and ϱ ∈[0, 1].
(ii) The exponential distribution expθ for θ > 0.
(iii) The distribution on N with weights c nα if n is even and c nβ if n is odd. Here
α, β < −1 and c = (2αζ(−α) + (1 −2β)ζ(−β))−1 (ζ is the Riemann zeta
function) is the normalization constant. ♣

Chapter 17
Markov Chains
In spite of their simplicity, Markov processes with countable state space (and
discrete time) are interesting mathematical objects with which a variety of real-
world phenomenacan be modeled. We give an introduction to the basic concepts and
then study certain examples in more detail. The connection with discrete potential
theory will be investigated later, in Chap. 19. Some readers might prefer to skip the
somewhat technical construction of general Markov processes in Sect. 17.1.
There is a vast literature on Markov chains. For further reading, see, e.g., [21, 26,
64, 66, 91, 116, 123, 124, 144, 153].
17.1
Deﬁnitions and Construction
In the following, E is always a Polish space with Borel σ-algebra B(E), I ⊂R and
(Xt)t∈I is an E-valued stochastic process. We assume that (Ft)t∈I = F = σ(X) is
the ﬁltration generated by X.
Deﬁnition 17.1 We say that X has the Markov property (MP) if, for every A ∈
B(E) and all s, t ∈I with s ≤t,
P
)
Xt ∈A
Fs
*
= P
)
Xt ∈A
Xs
*
.
Remark 17.2 If E is a countable space, then X has the Markov property if and
only if, for all n ∈N, all s1 < . . . < sn < t and all i1, . . . , in, i ∈E with
P[Xs1 = i1, . . . , Xsn = in] > 0, we have
P)Xt = i
Xs1 = i1, . . . , Xsn = in
* = P)Xt = i
Xsn = in
*.
(17.1)
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_17
391

392
17
Markov Chains
In fact, (17.1) clearly implies the Markov property. On the other hand, if X has the
Markov property, then (see (8.6)) P[Xt = i
Xsn](ω) = P[Xt = i
Xsn = in] for
almost all ω ∈{Xsn = in}. Hence, for A := {Xs1 = i1, . . . , Xsn = in} (using the
Markov property in the second equation),
P)Xt = i , Xs1 = i1, . . . , Xsn = in
*
= E)E[1{Xt=i}
Fsn] 1A
* = E)E[1{Xt=i}
Xsn] 1A
*
= E)P[Xt = i
Xsn = in] 1A
* = P)Xt = i
Xsn = in
* P[A].
Dividing both sides by P[A] yields (17.1). ♦
Deﬁnition 17.3 Let I ⊂[0, ∞) be closed under addition and assume 0 ∈I. A
stochastic process X = (Xt)t∈I is called a time-homogeneous Markov process with
distributions (Px)x∈E on the space (Ω, A) if:
(i) For every x ∈E, X is a stochastic process on the probability space (Ω, A, Px)
with Px [X0 = x] = 1.
(ii) The map κ : E × B(E)⊗I →[0, 1], (x, B) →Px[X ∈B] is a stochastic
kernel.
(iii) X has the time-homogeneous Markov property (MP): For every A ∈B(E),
every x ∈E and all s, t ∈I, we have
Px
)
Xt+s ∈A
Fs
*
= κt(Xs, A)
Px-a.s.
Here, for every t ∈I, the transition kernel κt : E × B(E) →[0, 1] is the
stochastic kernel deﬁned for x ∈E and A ∈B(E) by
κt(x, A) := κ

x, {y ∈EI : y(t) ∈A}

= Px [Xt ∈A] .
The family (κt(x, A), t ∈I, x ∈E, A ∈B(E)) is also called the family of
transition probabilities of X.
We write Ex for expectation with respect to Px, Lx[X] = Px and Lx[X|F] =
Px[X ∈· |F] (for a regular conditional distribution of X given F).
If E is countable, then X is called a discrete Markov process.
In the special case I = N0, X is called a Markov chain. In this case, κn is called
the family of n-step transition probabilities.
Remark 17.4 We will see that the existence of the transition kernels (κt) implies
the existence of the kernel κ. Thus, a time-homogeneous Markov process is
simply a stochastic process with the Markov property and for which the transition
probabilities are time-homogeneous. Although it is sometimes convenient to allow
also time-inhomogeneous Markov processes, for a wide range of applications it is
sufﬁcient to consider time-homogeneous Markov processes. We will not go into the

17.1
Deﬁnitions and Construction
393
details but will henceforth assume that all Markov processes are time-homogeneous.
♦
In the following, we will use the somewhat sloppy notation PXs[X ∈
·] :=
κ(Xs, ·). That is, we understand Xs as the initial value of a second Markov process
with the same distributions (Px)x∈E.
Example 17.5 Let Y1, Y2, . . . be i.i.d. Rd-valued random variables and let
Sx
n = x +
n

i=1
Yi
for x ∈Rd
and
n ∈N0.
Deﬁne probability measures Px on (Rd)N0, (B(Rd))⊗N0 by Px = P◦(Sx)−1. Then
the canonical process Xn : (Rd)N0 →Rd is a Markov chain with distributions
(Px)x∈Rd. The process X is called a random walk on Rd with initial value x. ♦
Example 17.6 In the previous example, it is simple to pass to continuous time; that
is, I = [0, ∞). To this end, let (νt)t≥0 be a convolution semigroup on Rd and let
κt(x, dy) = δx ∗νt(dy). In Theorem 14.50, for every x ∈Rd, we constructed a
measure Px on

(Rd)[0,∞), B(Rd)⊗[0,∞)
with
Px ◦(X0, Xt1, . . . , Xtn)−1 = δx ⊗
n−1
 
i=0
κti+1−ti
for any choice of ﬁnitely many points 0 = t0 < t1 < . . . < tn. It is easy to check
that the map κ : Rd × B(Rd)⊗[0,∞), (x, A) →Px[A] is a stochastic kernel. The
time-homogeneous Markov property is immediate from the fact that the increments
are independent and stationary. ♦
Example 17.7 (See Example 9.5 and Theorem 5.36) Let θ > 0 and νθ
t ({k}) =
e−θt tkθk
k! , k ∈N0, the convolution semigroup of the Poisson distribution. The
Markov process X on N0 with this semigroup is called a Poisson process with
(jump) rate θ. ♦
As in Example 17.6, we will construct a Markov process for a more general Markov
semigroup of stochastic kernels.
Theorem 17.8 Let I ⊂[0, ∞) be closed under addition and let (κt)t∈I be a
Markov semigroup of stochastic kernels from E to E. Then there is a measurable
space (Ω, A) and a Markov process ((Xt)t∈I, (Px)x∈E) on (Ω, A) with transition
probabilities
Px [Xt ∈A] = κt(x, A)
for all x ∈E, A ∈B(E), t ∈I.
(17.2)

394
17
Markov Chains
Conversely, for every Markov process X, Equation (17.2) deﬁnes a semigroup of
stochastic kernels. By (17.2), the ﬁnite-dimensional distributions of X are uniquely
determined.
Proof “ ⇒”
We construct X as a canonical process. Let Ω = E[0,∞) and A =
B(E)⊗[0,∞). Further, let Xt be the projection on the tth coordinate. For x ∈E,
deﬁne (see Corollary 14.46) on (Ω, A) the probability measure Px such that, for
ﬁnitely many time points 0 = t0 < t1 < . . . < tn, we have
Px ◦(Xt0, . . . , Xtn)−1 = δx ⊗
n−1
 
i=0
κti+1−ti.
Then
Px
)
Xt0 ∈A0, . . . , Xtn ∈An
*
=

An−1
Px
)
Xt0 ∈A0, . . . , Xtn−2 ∈An−2, Xtn−1 ∈dxn−1
*
κtn−tn−1(xn−1, An);
hence Px[Xtn ∈An|Ftn−1] = κtn−tn−1(Xtn−1, An). Thus X is recognized as a
Markov process. Furthermore, we have Px[Xt ∈A] = (δx · κt)(A) = κt(x, A).
“ ⇐ ”
Now let (X, (Px)x∈E) be a Markov process. Then a stochastic kernel κt is
deﬁned by
κt(x, A) := Px [Xt ∈A]
for all x ∈E, A ∈B(E), t ∈I.
By the Markov property, we have
κt+s(x, A) = Px [Xt+s ∈A] = Ex
)
PXs [Xt ∈A]
*
=

Px [Xs ∈dy]Py [Xt ∈A]
=

κs(x, dy)κt(y, A) = (κs · κt) (x, A).
Hence (κt)t∈I is a Markov semigroup.
⊓⊔
Theorem 17.9 A stochastic process X = (Xt)t∈I is a Markov process if and only
if there exists a stochastic kernel κ : E × B(E)⊗I →[0, 1] such that, for every
bounded B(E)⊗I −B(R)-measurable function f : EI →R and for every s ≥0
and x ∈E, we have
Ex
)
f ((Xt+s)t∈I)
Fs
*
= EXs [f (X)] :=

EI κ(Xs, dy) f (y).
(17.3)

17.1
Deﬁnitions and Construction
395
Proof “ ⇐ ”
The time-homogeneous Markov property follows by (17.3) with
the function f (y) = 1A(y(t)) since PXs[Xt ∈A] = Px[Xt+s ∈A|Fs] =
κt(Xs, A).
“ ⇒”
By the usual approximation arguments, it is enough to consider functions
f that depend only on ﬁnitely many coordinates 0 ≤t1 ≤t2 ≤. . . ≤tn. We
perform the proof by induction on n.
For n
=
1 and f an indicator function, this is the (time-homogeneous)
Markov property. For general measurable f , the statement follows by the usual
approximation arguments.
Now assume the claim is proved for n ∈N. Again it sufﬁces to assume that
f is an indicator function of the type f (x) = 1B1×···×Bn+1(xt1, . . . , xtn+1) (with
B1, . . . , Bn+1 ∈B(E)). Using the Markov property (third and ﬁfth equalities in the
following equation) and the induction hypothesis (fourth equality), we get
Ex
'
f (Xt+s)t≥0
Fs
(
= Ex
'
Ex
)
f

(Xt+s)t≥0
Ftn+s
*Fs
(
= Ex
'
Ex
)
1{Xtn+1+s∈Bn+1}
Ftn+s
*
1B1(Xt1+s) · · · 1Bn(Xtn+s)
Fs
(
= Ex
'
PXtn+s
)
Xtn+1−tn ∈Bn+1
*
1B1(Xt1+s) · · · 1Bn(Xtn+s)
Fs
(
= EXs
'
PXtn
)Xtn+1−tn ∈Bn+1
* 1B1(Xt1) · · · 1Bn(Xtn)
(
= EXs
'
PX0
)
Xtn+1 ∈Bn+1
Ftn
*
1B1(Xt1) · · · 1Bn(Xtn)
(
= EXs
'
PX0
)
Xt1 ∈B1, . . . , Xtn+1 ∈Bn+1
Ftn
*(
= EXs [f (X)] .
⊓⊔
Corollary 17.10 A stochastic process (Xn)n∈N0 is a Markov chain if and only if
Lx
)
(Xn+k)n∈N0
Fk
*
= LXk
)
(Xn)n∈N0
*
for every k ∈N0.
(17.4)
Proof If the conditional distributions exist, then, by Theorem 17.9, the equa-
tion (17.4) is equivalent to X being a Markov chain. Hence we only have to show
that the conditional distributions exist.
Since E is Polish, EN0 is also Polish and we have B(EN0) = B(E)⊗N0
(see Theorem 14.8). Hence, by Theorem 8.37, there exists a regular conditional
distribution of (Xn+k)n∈N0 given Fk.
⊓⊔

396
17
Markov Chains
Theorem 17.11 Let I = N0. If (Xn)n∈N0 is a stochastic process with distributions
(Px, x ∈E), then the Markov property in Deﬁnition 17.3(iii) is implied by the
existence of a stochastic kernel κ1 : E × B(E) →[0, 1] with the property that for
every A ∈B(E), every x ∈E and every s ∈I, we have
Px
)
Xs+1 ∈A
Fs
*
= κ1(Xs, A).
(17.5)
In this case, the n-step transition kernels κn can be computed inductively by
κn = κn−1 · κ1 =

E
κn−1( ·, dx) κ1(x, ·).
In particular, the family (κn)n∈N is a Markov semigroup and the distribution X is
uniquely determined by κ1.
Proof In Theorem 17.9, let ti = i for every i ∈N0. For the proof of that theorem,
only (17.5) was needed.
⊓⊔
The (time-homogeneous) Markov property of a process means that, for ﬁxed time
t, the future (after t) depends on the past (before t) only via the present (that is, via
the value Xt). We can generalize this concept by allowing random times τ instead
of ﬁxed times t.
Deﬁnition 17.12 Let I ⊂[0, ∞) be closed under addition. A Markov process
(Xt)t∈I with distributions (Px, x ∈E) has the strong Markov property if, for every
a.s. ﬁnite stopping time τ, every bounded B(E)⊗I −B(R) measurable function
f : EI →R and every x ∈E, we have
Ex
)
f ((Xτ+t)t∈I)
Fτ
*
= EXτ [f (X)] :=

EI κ(Xτ, dy) f (y).
(17.6)
Remark 17.13 If I is countable, then the strong Markov property holds if and only
if, for every almost surely ﬁnite stopping time τ, we have
Lx
)
(Xτ+t)t∈I
Fτ
* = LXτ
)
(Xt)t∈I
* := κ(Xτ, ·).
(17.7)
This follows just as in Corollary 17.10. ♦
Most Markov processes one encounters have the strong Markov property. In
particular, for countable time sets, the strong Markov property follows from the
Markov property. For continuous time, however, in general, some work has to be
done to establish the strong Markov property.
Theorem 17.14 If I ⊂[0, ∞) is countable and closed under addition, then every
Markov process (Xn)n∈I with distributions (Px)x∈E has the strong Markov property.
Proof Let f : EI →R be measurable and bounded. Then, for every s ∈I, the
random variable 1{τ=s} Ex
)f 
(Xs+t)t∈I
 |Fτ
* is measurable with respect to Fs.

17.1
Deﬁnitions and Construction
397
Using the tower property of the conditional expectation and Theorem 17.9 in the
third equality, we thus get
Ex
)
f

(Xτ+t)t∈I
 Fτ
*
=

s∈I
1{τ=s} Ex
)
f

(Xs+t)t∈I
 Fτ
*
=

s∈I
Ex
'
1{τ=s} Ex
)
f

(Xs+t)t∈I
Fs
*Fτ
(
=

s∈I
Ex
'
1{τ=s} EXs
)f (Xt)t∈I
*Fτ
(
= EXτ
)
f

(Xt)t∈I
*
.
⊓⊔
As a simple application of the strong Markov property, we show the reﬂection
principle for random walks.
Theorem 17.15 (Reﬂection principle)
Let Y1, Y2, . . . be i.i.d. real random vari-
ables with symmetric distribution L[Y1] = L[−Y1]. Deﬁne X0 = 0 and Xn :=
Y1 + . . . + Yn for n ∈N. Then, for every n ∈N0 and a > 0,
P
+
sup
m≤n
Xm ≥a
,
≤2 P[Xn ≥a] −P[Xn = a].
(17.8)
If we have P[Y1 ∈{−1, 0, 1}] = 1, then for a ∈N equality holds in (17.8).
Proof Let a > 0 and n ∈N. Deﬁne the time of ﬁrst excess of a (truncated at
(n + 1)),
τ := inf{m ≥0 : Xm ≥a} ∧(n + 1).
Then τ is a bounded stopping time and
sup
m≤n
Xm ≥a
⇐⇒
τ ≤n.
Let f (m, X) = 1{m≤n}

1{Xn−m>a} + 1
2 1{Xn−m=a}

. Then
f τ, (Xτ+m)m∈N0
 = 1{τ≤n}

1{Xn>a} + 1
2 1{Xn=a}

.
The strong Markov property of X yields
E0
)
f

τ, (Xτ+m)m≥0
 Fτ
*
= ϕ (τ, Xτ ) ,

398
17
Markov Chains
where ϕ(m, x) = Ex[f (m, X)]. (Recall that Ex denotes the expectation for X if
X0 = x.)
Due to the symmetry of Yi, we have
ϕ(m, x)
⎧
⎪⎪⎨
⎪⎪⎩
≥1
2,
if m ≤n and x ≥a,
= 1
2,
if m ≤n and x = a,
= 0,
if m > n.
Hence
{τ ≤n} = {τ ≤n} ∩{Xτ ≥a} ⊂
0
ϕ(τ, Xτ ) ≥1
2
1
∩{τ ≤n}
= {ϕ(τ, Xτ ) > 0} ∩{τ ≤n}.
Now (17.8) is implied by
P[Xn > a] + 1
2 P[Xn = a] = E
)
f

τ, (Xτ+m)m≥0
*
= E0
)
ϕ(τ, Xτ ) 1{τ≤n}
*
≥1
2 P0 [τ ≤n] .
(17.9)
Now assume P[Y1 ∈{−1, 0, 1}] = 1 and a ∈N. Then Xτ = a if τ ≤n. Hence
{ϕ(τ, Xτ ) > 0} ∩{τ ≤n} =

ϕ(τ, Xτ ) = 1
2

∩{τ ≤n}.
Thus, in the last step of (17.9), equality holds and hence also in (17.8).
⊓⊔
Reﬂection Find an example for strict inequality in (17.8). ♠
Reﬂection Consider the case P[Y1 = 1] = P[Y1 = −1] =
1
2. Then we have
equality in (17.8). In fact, in this case, the reﬂection principle can be derived also
in an elementary way via a bijection that changes the signs of those Yi with i > τ.
Each path of the process X of partial sums that ends above a corresponds to a unique
path that reaches a but ends below a.
Try and ﬁll the details in this argument. ♠

17.2
Discrete Markov Chains: Examples
399
Takeaways For Markov processes, the future depends upon the information
up to a given time only via the state at this very time. If the time set is
countable, this property can be generalized to random (stopping) times and
is then called strong Markov property. Markov processes can be characterised
by their transition probabilities (stochastic kernels).
Exercise 17.1.1 Let I ⊂R and let X = (Xt)t∈I be a stochastic process. For t ∈I,
deﬁne the σ-algebras that code the past before t and the future beginning with t by
F≤t := σ(Xs : s ∈I, s ≤t)
and
F≥t := σ(Xs : s ∈I, s ≥t).
Show that X has the Markov property if and only if, for every t ∈I, the σ-algebras
F≤t and F≥t are independent given σ(Xt) (compare Deﬁnition 12.20).
In other words, a process has the (possibly time-inhomogeneous) Markov
property if and only if past and future are independent given the present. ♣
17.2
Discrete Markov Chains: Examples
Let E be countable and I = N0. By Deﬁnition 17.3, a Markov process X =
(Xn)n∈N0 on E is a discrete Markov chain (or Markov chain with discrete state
space).
If X is a discrete Markov chain, then (Px)x∈E is determined by the transition
matrix
p = (p(x, y))x,y∈E := (Px[X1 = y])x,y∈E.
The n-step transition probabilities
p(n)(x, y) := Px [Xn = y]
can be computed as the n-fold matrix product
p(n)(x, y) = pn(x, y),
where
pn(x, y) =

z∈E
pn−1(x, z)p(z, y)
and where p0 = I is the unit matrix.

400
17
Markov Chains
By induction, we get the Chapman–Kolmogorov equation (see (14.15)) for all
m, n ∈N0 and x, y ∈E,
p(m+n)(x, y) =

z∈E
p(m)(x, z) p(n)(z, y).
(17.10)
Deﬁnition 17.16 A matrix (p(x, y))x,y∈E with nonnegative entries and with

y∈E
p(x, y) = 1
for all x ∈E
is called a stochastic matrix on E.
A stochastic matrix is essentially a stochastic kernel from E to E. In Theorem 17.8
we saw that, for the semigroup of kernels (pn)n∈N, there exists a unique discrete
Markov chain whose transition probabilities are given by p. The arguments we gave
there were rather abstract. Here we give a construction for X that could actually be
used to implement a computer simulation of X.
Let (Rn)n∈N0 be an independent family of random variables with values in EE
and with the property
P[Rn(x) = y] = p(x, y)
for all x, y ∈E.
(17.11)
For example, choose (Rn(x), x ∈E, n ∈N) as an independent family of random
variables with values in E and distributions
P[Rn(x) = y] = p(x, y)
for all x, y ∈E and n ∈N0.
Note, however, that in (17.11) we have required neither independence of the random
variables (Rn(x), x ∈E) nor that all Rn had the same distribution. Only the one-
dimensional marginal distributions are determined. In fact, in many applications it
is useful to have subtle dependence structures in order to couple Markov chains with
different initial chains. We pick up this thread again in Sect. 18.2.
For x ∈E, deﬁne
Xx
0 = x
and
Xx
n = Rn(Xx
n−1)
for n ∈N.
Finally, let Px := L[Xx] be the distribution of Xx. Recall that this is a probability
measure on the space of sequences (EN0, B(E)⊗N0).

17.2
Discrete Markov Chains: Examples
401
Theorem 17.17
(i) With respect to the distribution (Px)x∈E, the canonical process X on
(EN0, B(E)⊗N0) is a Markov chain with transition matrix p.
(ii) In particular, to any stochastic matrix p, there corresponds a unique discrete
Markov chain X with transition probabilities p.
Proof “(ii)”
This follows from (i) since Theorem 17.11 yields uniqueness of X.
“(i)”
For n ∈N0 and x, y, z ∈E, by construction,
Px[Xn+1 = z
Fn, Xn = y] = P
)
Xx
n+1 = z
σ

Rm, m ≤n

, Xx
n = y
*
= P
)
Rn+1(Xx
n) = z
σ

Rm, m ≤n

, Xx
n = y
*
= P)Rn+1(y) = z]
= p(y, z).
Hence, by Theorem 17.11, X is a Markov chain with transition matrix p.
⊓⊔
Example 17.18 (Random walk on Z) Let E = Z, and assume
p(x, y) = p(0, y −x)
for all x, y ∈Z.
In this case, we say that p is translation invariant. A discrete Markov chain X with
transition matrix p is a random walk on Z. Indeed, Xn
D= X0 +Z1+. . .+Zn, where
(Zn)n∈N are i.i.d. with P [Zn = x] = p(0, x).
The Rn that we introduced in the explicit construction are given by Rn(x) :=
x + Zn. ♦
Example 17.19 (Computer simulation) Consider the situation where the state space
E = {1, . . . , k} is ﬁnite. The aim is to simulate a Markov chain X with transition
matrix p on a computer. Assume that the computer provides a random number
generator that generates an i.i.d. sequence (Un)n∈N of random variables that are
uniformly distributed on [0, 1]. (Of course, this is wishful thinking. But modern
random number generators produce sequences that for many purposes are close
enough to really random sequences.)
Deﬁne r(i, 0) = 0, r(i, j) = p(i, 1) + . . . + p(i, j) for i, j ∈E, and deﬁne Yn
by
Rn(i) = j
⇐⇒
Un ∈[r(i, j −1), r(i, j)).
Then, by construction, P[Rn(i) = j] = r(i, j) −r(i, j −1) = p(i, j). ♦
Example 17.20 (Branching process as a Markov chain) We want to understand the
Galton–Watson branching process (see Deﬁnition 3.9) as a Markov chain on E =
N0.

402
17
Markov Chains
To this end, let (qk)k∈N0 be a probability vector, the offspring distribution of one
individual. Deﬁne q∗0
k
= 1{0}(k) and
q∗n
k
=
k

l=0
q∗(n−1)
k−l
ql
for n ∈N
as the n-fold convolutions of q. Hence, for n individuals, q∗n
k
is the probability to
have exactly k offspring. Finally, deﬁne the matrix p by p(x, y) = q∗x
y
for x, y ∈
N0.
Now let (Yn,i, n ∈N0, i ∈N0) be i.i.d. with P[Yn,i = k] = qk. For x ∈N0,
deﬁne the branching process X with x ancestors and offspring distribution q by
X0 = x and Xn := Xn−1
i=1 Yn−1,i. In order to show that X is a Markov chain, we
compute
P[Xn = xn
X0 = x, X1 = x1, . . . , Xn−1 = xn−1]
= P[Yn−1,1 + . . . + Yn−1,xn−1 = xn]
= P∗xn−1
Y1,1 ({xn}) = q∗xn−1
xn
= p(xn−1, xn).
Hence X is a Markov chain on N0 with transition matrix p. ♦
Example 17.21 (Wright’s evolution model) In population genetics, Wright’s evo-
lution model [172] describes the hereditary transmission of a genetic trait with
two possible speciﬁcations (say A and B); for example, resistance/no resistance
to a speciﬁc antibiotic. It is assumed that the population has a constant size of
N ∈N individuals and the generations change at discrete times and do not overlap.
Furthermore, for simplicity, the individuals are assumed to be haploid; that is, cells
bear only one copy of each chromosome (like certain protozoans do) and not two
copies (as in mammals).
Here we consider the case where none of the traits is favored by selection. Hence,
it is assumed that each individual of the new generation chooses independently and
uniformly at random one individual of the preceding generation as ancestor and
becomes a perfect clone of that. Thus, if the number of individuals of type A in the
current generation is k ∈{0, . . ., N}, then in the new generation it will be random
and binomially distributed with parameters N and k/N.
The gene frequencies k/N in this model can be described by a Markov chain X
on E = {0, 1/N, . . . , (N −1)/N, 1} with transition matrix p(x, y) = bN,x({Ny}).
Note that X is a (bounded) martingale. Hence, by the martingale convergence
theorem (Theorem 11.7), X converges Px-almost surely to a random variable X∞
with Ex[X∞] = Ex[X0] = x. As with the voter model (see Example 11.16) that is
closely related to Wright’s model, we can argue that the limit X∞can take only the
stable values 0 and 1. That is, Px[limn→∞Xn = 1] = x = 1−Px[limn→∞Xn = 0].
♦

17.2
Discrete Markov Chains: Examples
403
Example 17.22 (Discrete Moran model) In contrast to Wright’s model, the Moran
model also allows overlapping generations. The situation is similar to that of
Wright’s model; however, now in each time step, only (exactly) one individual gets
replaced by a new one, whose type is chosen at random from the whole population.
As the new and the old types of the replaced individual are independent, as a
model for the gene frequencies, we obtain a Markov chain X on E = {0, 1
N , . . . , 1}
with transition matrix
p(x, y) =
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
x(1 −x),
if y = x + 1/N,
x2 + (1 −x)2,
if y = x,
x(1 −x),
if y = x −1/N,
0,
else.
Here also, X is a bounded martingale and we can compute the square variation
process,
⟨X⟩n =
n

i=1
E
)
(Xi −Xi−1)2Xi−1
*
= 2
N2
n−1

i=0
Xi(1 −Xi).
(17.12)
♦
Takeaways A Markov process indexed by the natural numbers is called a
Markov chain. Markov chains with discrete state spaces give rise to many
interesting probabilistic examples. The transition probabilities are given by
stochastic matrices.
Exercise 17.2.1 (Discrete martingale problem) Let E ⊂R be countable and let
X be a Markov chain on E with transition matrix p and with the property that,
for any x, there are at most three choices for the next step; that is, there exists a
set Ax ⊂E of cardinality 3 with p(x, y) = 0 for all y ∈E \ Ax. Let d(x) :=

y∈E(y −x) p(x, y) for x ∈E.
(i) Show that Mn := Xn −n−1
k=0 d(Xk) deﬁnes a martingale M with square
variation process ⟨M⟩n = n−1
i=0 f (Xi) for a unique function f : E →[0, ∞).
(ii) Show that the transition matrix p is uniquely determined by f and d.
(iii) For the Moran model (Example 17.22), use the explicit form (17.12) of the
square variation process to compute the transition matrix. ♣

404
17
Markov Chains
17.3
Discrete Markov Processes in Continuous Time
Let E be countable and let (Xt)t∈[0,∞) be a Markov process on E with transition
probabilities pt(x, y) = Px[Xt = y] (for x, y ∈E). (Some authors call such a
process a Markov chain in continuous time.)
Let x, y ∈E with x ̸= y. We say that X jumps with rate q(x, y) from x to y if
the following limit exists:
q(x, y) := lim
t↓0
1
t Px[Xt = y].
Henceforth we assume that the limit q(x, y) exists for all y ̸= x and that

y̸=x
q(x, y) < ∞
for all x ∈E.
(17.13)
Then we deﬁne
q(x, x) = −

y̸=x
q(x, y).
(17.14)
Finally we assume that (which is equivalent to exchangeability of the limit and the
sum over y ̸= x in the display preceding (17.13))
lim
t↓0
1
t

Px [Xt = y] −1{x=y}

= q(x, y)
for all x, y ∈E.
(17.15)
Deﬁnition 17.23 If (17.13), (17.14) and (17.15) hold, then q is called the Q-matrix
of X. Sometimes q is also called the generator of the semigroup (pt)t≥0.
Example 17.24 (Poisson process) The Poisson process with rate α > 0 (compare
Sect. 5.5) has the Q-matrix q(x, y) = α(1{y=x+1} −1{y=x}). ♦
Theorem 17.25 Let q be an E × E matrix such that q(x, y) ≥0 for all x, y ∈E
with x ̸= y. Assume that (17.13) and (17.14) hold and that
λ := sup
x∈E
|q(x, x)| < ∞.
(17.16)
Then q is the Q-matrix of a unique Markov process X.
Intuitively, (17.15) suggests that we deﬁne pt = etq in a suitable sense. Then,
formally, q =
d
dt pt
t=0. The following proof shows that this formal argument can
be made rigorous.

17.3
Discrete Markov Processes in Continuous Time
405
Proof Let I be the unit matrix on E. Deﬁne
p(x, y) = 1
λ q(x, y) + I(x, y)
for x, y ∈E,
if λ > 0 and p = I otherwise. Then p is a stochastic matrix and q = λ(p −I).
Let

(Yn)n∈N0,

PY
x

x∈E

be a discrete Markov chain with transition matrix p and
let (Tt)t≥0, PT
n

n∈N0
 be a Poisson process with rate λ. Let Xt := YTt and Px =
PY
x ⊗PT
0 . Then X :=

(Xt)t≥0, (Px)x∈E

is a Markov process and
pt(x, y) := Px [Xt = y] =
∞

n=0
PT
0 [Tt = n] PY
x [Yn = y]
= e−λt
∞

n=0
λn tn
n! pn(x, y).
This power series (in t) converges everywhere (note that as a linear operator, p has
ﬁnite norm ∥p∥∞≤1) to the matrix exponential function eλtp(x, y). Furthermore,
pt(x, y) = e−λteλtp(x, y) = eλt(p−I)(x, y) = etq(x, y).
Differentiating the power series termwise yields d
dt pt(x, y)
t=0 = q(x, y). Hence
X is the required Markov process.
Now assume that (pt)t≥0 are the transition probabilities of another Markov
process X with the same generator q; that is, with
lim
s↓0
1
s
ps(x, y) −I(x, y) = q(x, y).
It is easy to check that
lim
s↓0
1
s

pt+s(x, y) −pt(x, y)

= (q · pt)(x, y).
That is, we have (d/dt)pt(x, y) = q pt(x, y). Similarly, we get (d/dt)pt =
q pt(x, y). Hence also,
pt(x, y) −pt(x, y) =
 t
0

q(ps −ps)

(x, y) ds.

406
17
Markov Chains
If we let rs = ps −ps, then ∥rs∥∞≤2 and ∥q∥∞≤2λ; hence
sup
s≤t
∥rs∥∞≤sup
s≤t
 s
0
∥qru∥∞du
≤∥q∥∞sup
s≤t
 s
0
∥ru∥∞du ≤2λt sup
s≤t
∥rs∥∞.
For t < 1/2λ, this implies rt = 0. Assuming rs = 0 for all s ≤(n −1)t, we
conclude
sup
s≤nt
∥rs∥∞≤2λ
 nt
(n−1)t
∥ru∥∞du ≤2λt sup
s≤nt
∥rs∥∞= 0,
hence rs = 0 for all s ≤nt. By induction, we get rs = 0 hence ps = ps for all
s ≥0.
⊓⊔
Remark 17.26 The condition (17.16) cannot be dropped easily, as the following
example shows. Let E = N and
q(x, y) =
⎧
⎪⎨
⎪⎩
x2,
if y = x + 1,
−x2,
if y = x,
0,
else.
We construct explicitly a candidate X for a Markov process with Q-matrix q. Let
T1, T2, . . . be independent, exponentially distributed random variables with PTn =
expn2. Deﬁne Sn = T1 + . . . + Tn−1 and Xt = sup{n ∈N0 : Sn ≤t}. Then, at any
time, X makes at most one step to the right. Furthermore, due to the lack of memory
of the exponential distribution (see Exercise 8.1.1),
P[Xt+s ≥n + 1|Xt = n]
= P[Sn+1 ≤t + s|Sn ≤t, Sn+1 > t]
= P[Tn ≤s + t −Sn|Sn ≤t, Tn > t −Sn] = P[Tn ≤s]
= 1 −exp(−n2s).
Therefore,
lim
s↓0 s−1P[Xt+s = n + 1|Xt = n] = n2
and
lim
s↓0 s−1
P[Xt+s = n|Xt = n] −1

= −n2;

17.3
Discrete Markov Processes in Continuous Time
407
hence
lim
s↓0 s−1 
P[Xt+s = m|Xt = n] −I(m, n)

= q(m, n)
for all m, n ∈N.
Let
τ n = inf{t ≥0 : Xt = n} = Sn
for n ∈N.
Then E1[τ n] = n−1
k=1
1
k2 . By monotone convergence, E1
) supn∈N τ n* < ∞. That
is, in ﬁnite time, X exceeds all levels. We say that X explodes. ♦
Example 17.27 (Yule process)
We consider an example that resembles the preced-
ing one at ﬁrst glance. However, the qualitative behaviour will be quite different.
Let E = N and let X = (Xt)t≥0 be a Markov process on E with Q-matrix
q(x, y) =
⎧
⎪⎨
⎪⎩
x,
if y = x + 1,
−x,
if y = x,
0,
else.
This process can be regarded as a Galton-Watson branching process in continuous
time. Each of the x individuals has an exponentially distributed lifetime with
parameter 1. When a particle dies, it has two offspring. Each of the offspring gets its
own independent exponential lifetime. Due to the lack-of-memory property of the
exponential distribution, also the remaining lifetimes of the other x −1 individuals
are independent and exponentially distributed with parameter 1. As the minimum
of x independent exp1-distributed random variables is expx-distributed, the waiting
time for the next branching event is expx-distributed. This property is reﬂected by
the assumption that the jump rate q(x, x + 1) equals x.
For n ∈N0 and t ≥0, deﬁne the probability
fn(t) := P1[Xt > n].
Clearly, we have fn(0) = 0 for all n ∈N. Now X jumps from n to n + 1 at rate n.
Hence, we have
d
dt fn(t) = n P1[Xt = n] = n (fn−1(t) −fn(t)).
Note that f0(t) = 1 for all t ≥0 and hence f ′
1(t) = 1 −f1(t). The unique solution
of this differential equation is f1(t) = 1 −e−t. By induction, we get
P1[Xt > n] = fn(t) = (1 −e−t)n
for all n ∈N, t ≥0.

408
17
Markov Chains
In particular, we see that Xt is ﬁnite for all t. Now we determine the asymptotic
growth rate of X. For x > 0, we have
P1[e−tXt > x] = P[Xt > etx] = (1 −e−t)⌊etx⌋t→∞
−→e−x.
That is, e−tXt converges in distribution to a random variable W with W ∼exp1.
We can use the jump times of X for an alternative derivation. Similarly as in
Remark 17.28, we deﬁne independent random variables T1, T2, . . . with Tn ∼expn.
Now let Sn := T1 + . . . + Tn−1 and deﬁne X by
Xt := sup 	n ∈N : Sn ≤t
for all t ≥0.
Let Z1, Z2, . . . be independent exponentially distributed random variables with
parameter 1. From Exercise 15.1.3, we know that
Sn+1
D= max{Z1, . . . , Zn}.
Hence, we have
P[Xt > n] = P[Sn+1 ≤t] = P[Z1 ≤t]n = (1 −e−t)n.
♦
Example 17.28 (A variant of Pólya’s urn model) Consider a variant of Pólya’s urn
model with black and red balls (compare Example 12.29). In contrast to the original
model, we do not simply add one ball of the same color as the ball that we return.
Rather, the number of balls that we add varies from time to time. More precisely,
the kth ball of a given color will be returned together with rk more balls of the same
color. The numbers r1, r2, . . . ∈N are parameters of the model. In particular, the
case 1 = r1 = r2 = . . . is the classical Pólya’s urn model. Let
Xn :=

1,
if the nth ball is black,
0,
else.
For the classical model, we saw (Example 12.29) that the fraction of black balls
in the urn converges a.s. to a Beta-distributed random variable Z. Furthermore,
given Z, the sequence X1, X2, . . . is independent and BerZ-distributed. A similar
statement holds for the case where r = r1 = r2 = . . . for some r ∈N. Indeed,
here only the parameters of the Beta distribution change. In particular (as the Beta
distribution is continuous and, in particular, does not have atoms at 0 or 1), almost
surely we draw inﬁnitely many balls of each color. Formally, P[B] = 0 where B is
the event where there is one color of which only ﬁnitely many balls are drawn.
The situation changes when the numbers rk grow quickly as k →∞. Assume
that in the beginning there is one black and one red ball in the urn. Denote by
wn = 1 + n
k=1 rk the total number of balls of a given color after n balls of that
color have been drawn already (n ∈N0).

17.3
Discrete Markov Processes in Continuous Time
409
For illustration, ﬁrst consider the extreme situation where wn grows very quickly;
for example, wn = 2n for every n ∈N. Denote by
Sn = 2(X1 + . . . + Xn) −n
the number of black balls drawn in the ﬁrst n steps minus the number of red balls
drawn in these steps. Then, for every n ∈N0,
P[Xn+1 = 1|Sn] =
2Sn
1 + 2Sn
and
P[Xn+1 = 0|Sn] =
2−Sn
1 + 2−Sn .
We conclude that (Zn)n∈N0 := (|Sn|)n∈N0 is a Markov chain on N0 with transition
matrix
p(z, z′) =
⎧
⎪⎪⎨
⎪⎪⎩
2z/(1 + 2z),
if z′ = z + 1 > 1,
1,
if z′ = z + 1 = 1,
1/(1 + 2z),
if z′ = z −1 ≥0,
0,
else.
The event B from above can be written as
B = 	Zn+1 < Zn only ﬁnitely often
.
Let A =
	
Zn+1 > Zn for all n ∈N0

denote the event where Z ﬂees directly to
∞and let τz = inf{n ∈N0 : Zn ≥z}. Evidently,
Pz[A] =
∞

z′=z
p(z′, z′ + 1) ≥1 −
∞

z′=z
1
1 + 2z′ ≥1 −21−z.
It is easy to check that P0[τz < ∞] = 1 for all z ∈N0. Using the strong Markov
property, we get that, for all z ∈N0,
P0[B] ≥P0[Zn+1 > Zn for all n ≥τz] = Pz[A] ≥1 −21−z,
and thus P0[B] = 1. In prose, almost surely eventually only balls of one color will
be drawn.
This example was a bit extreme. In order to ﬁnd a necessary and sufﬁcient
condition on the growth of (wn), we need more subtle methods that appeal to the
above example of the explosion of a Markov process.
We will show that P[B] = 1 if and only if ∞
n=0
1
wn < ∞. To this end, consider
independent random variables T s
1 , T r
1 , T s
2 , T r
2 , . . . with PT rn = PT sn = expwn−1. Let
T r
∞= ∞
n=1 T r
n and T s
∞= ∞
n=1 T s
n . Clearly, E[T r
∞] = ∞
n=0 1/wn < ∞;
hence, in particular, P[T r
∞< ∞] = 1. The corresponding statement holds for T s
∞.

410
17
Markov Chains
Note that T r
∞and T s
∞are independent and have densities (since T r
1 and T s
1 have
densities); hence we have P[T r
∞= T s
∞] = 0.
Now let
Rt := sup
	
n ∈N : T r
1 + . . . + T r
n−1 ≤t

and
St := sup
	
n ∈N : T s
1 + . . . + T s
n−1 ≤t

.
Let R := {T r
1 + . . . + T r
n , n ∈N} and let S := {T s
1 + . . . + T s
n , n ∈N} be the jump
times of (Rt) and (St). Deﬁne U := R ∪S = {u1, u2, . . .}, where u1 < u2 < . . ..
Let
Xn =
0 1,
if un ∈S,
0,
else.
Let Ln = x1 + . . . + xn. Then
P[Xn+1 = 1
X1 = x1, . . . , Xn = xn]
= P
)
un+1 ∈S
(uk ∈S ⇐⇒xk = 1) for every k ≤n
*
= P
)
T s
1 + . . . + T s
Ln+1 < T r
1 + . . . + T r
n−Ln+1
T s
1 + . . . + T s
Ln+1 > T r
1 + . . . + T r
n−Ln]
= P
)
T s
Ln+1 < T r
n−Ln+1
*
=
wLn
wLn + wn−Ln
.
Hence (Xn)n∈N0 is our generalized urn model with weights (wn)n∈N0. Consider
now the event Bc where inﬁnitely many balls of each color are drawn. Evidently,
{Xn = 1 inﬁnitely often} = {sup S = sup U} and {Xn = 0 inﬁnitely often} =
{sup R = sup U}. Since sup S = T s
∞and sup R = T r
∞, we thus have P[Bc] =
P[T r
∞= T s
∞] = 0. ♦
Takeaways A Markov processes in continuous time and with discrete state
space can be described by its jump rates (q-matrix). If the jump rates are
bounded, then the process can be constructed as a Markov chain at random
times given by a Poisson clock.
Exercise 17.3.1 Consider the Yule process X from Example 17.27. Show that
Wt := e−tXt, t ≥0, is a martingale. Conclude that (Wn)n∈N converges almost
surely an in L1 to a random variable W that is exponentially distributed with

17.4
Discrete Markov Chains: Recurrence and Transience
411
parameter 1. (In fact, using Exercise 21.4.2, it can even be shown that (Wt)t≥0
converges to W almost surely and in L1.) ♣
Exercise 17.3.2 Let r, s, R, S ∈N. Consider the generalized version of Pólya’s urn
model (Xn)n∈N0 with rk = r and sk = s for all k ∈N. Assume that in the beginning
there are R red balls and S black balls in the urn. Show that the fraction of black
balls converges almost surely to a random variable Z with a Beta distribution and
determine the parameters. Show that (Xn)n∈N0 is i.i.d. given Z and Xi ∼BerZ for
all i ∈N0. ♣
Exercise 17.3.3 Show that, almost surely, inﬁnitely many balls of each color are
drawn if
∞

n=0
1
wn
= ∞. ♣
17.4
Discrete Markov Chains: Recurrence and Transience
In the following, let X = (Xn)n∈N0 be a Markov chain on the countable space E
with transition matrix p.
Deﬁnition 17.29 For any x ∈E, let τx := τ 1
x := inf{n > 0 : Xn = x} and
τ k
x = inf

n > τ k−1
x
: Xn = x

for k ∈N, k ≥2.
τ k
x is the kth entrance time of X for x. For x, y ∈E, let
F(x, y) := Px[τ 1
y < ∞] = Px
)
there is an n ≥1 with Xn = y
*
be the probability of ever going from x to y. In particular, F(x, x) is the return
probability (after the ﬁrst jump) from x to x.
Note that τ 1
x > 0 even if we start the chain at X0 = x.
Theorem 17.30 For all x, y ∈E and k ∈N, we have
Px
)
τ k
y < ∞
*
= F(x, y) F(y, y)k−1.
Proof We carry out the proof by induction on k. For k = 1, the claim is true
by deﬁnition. Now let k ≥2. Using the strong Markov property of X (see
Theorem 17.14), we get
Px
'
τ k
y < ∞
(
= Ex
'
Px
'
τ k
y < ∞
Fτ k−1
y
(
1{τ k−1
y
<∞}
(
= Ex
'
F(y, y) · 1{τ k−1
y
<∞}
(
= F(y, y) · F(x, y) F(y, y)k−2 = F(x, y) F(y, y)k−1.
⊓⊔

412
17
Markov Chains
Deﬁnition 17.31 A state x ∈E is called
•
recurrent if F(x, x) = 1,
•
positive recurrent if Ex[τ 1
x ] < ∞,
•
null recurrent if x is recurrent but not positive recurrent,
•
transient if F(x, x) < 1, and
•
absorbing if p(x, x) = 1.
The Markov chain X is called (positive/null) recurrent if every state x ∈E is
(positive/null) recurrent and is called transient if every recurrent state is absorbing.
Remark 17.32 Clearly, we have:
“absorbing” ⇒“positive recurrent” ⇒“recurrent”. ♦
Example 17.33
(i) In Fig. 17.1, the state 2 is absorbing. If it does not get trapped in 2, the chain
will eventually jump from 5 to 6 and will not return after that. Hence 1, 3, 4
and 5 are transient. The states 6, 7 and 8 are positive recurrent. One can show
(see Exercise 17.6.1) that E6[τ6] = 17
4 , E7[τ7] = 17
5 and E8[τ8] = 17
8 .
(ii) The chain in Fig. 17.2 has a drift to the right if r > 1
2. Hence, in this case, every
state is transient. On the other hand, if r ∈(0, 1
2), then the chain has a drift to
the left (except at the point 0) and hence visits every state again and again. Thus
the chain is recurrent. With a little thought, one can show (see Exercise 17.6.4)
that in this case, the chain is actually positive recurrent and in the remaining
case r = 1
2 it is null recurrent.♦
Deﬁnition 17.34 Denote by N(y) = ∞
n=0 1{Xn=y} the total number of visits of X
to y and by
G(x, y) = Ex[N(y)] =
∞

n=0
pn(x, y)
the Green function of X.
1
1/2
1
1/3
1/6
1/2
1/2
1/2
1/2
3/4
1/4
1/4
3/4
1/2
1/2
1
3
8
2
4
6
7
5
Fig. 17.1 Markov chain with eight states. The numbers are the transition probabilities for the
corresponding arrows. State 2 is absorbing, the states 1, 3, 4 and 5 are transient and the states 6, 7
and 8 are (positive) recurrent.

17.4
Discrete Markov Chains: Recurrence and Transience
413
1
1−r
r
r
r
−
1
r
−
1
r
−
1
r
0
1
2
3
Fig. 17.2 Markov chain on N0 with parameter r ∈(0, 1). The chain is positive recurrent if r ∈
(0, 1/2), null recurrent if r = 1/2 and transient if r ∈(1/2, 1).
Reﬂection The Green function G is deﬁned by a geometric series. Hence, formally
we should have G = (I −p)−1 with I the unit matrix. In which situations can this
formalism be justiﬁed? ♠♠
Theorem 17.35
(i) For all x, y ∈E, we have (with the convention 1/0 := ∞, 0/0 := 0 and
0 · ∞:= 0)
G(x, y) =
⎧
⎪⎪⎨
⎪⎪⎩
F(x, y)
1 −F(y, y),
if x ̸= y
1
1 −F(y, y),
if x = y
⎫
⎪⎪⎬
⎪⎪⎭
= F(x, y) G(y, y) + 1{x=y}.
(17.17)
(ii) A non-absorbing state x ∈E is recurrent if and only if G(x, x) = ∞.
Proof (ii) follows by (i). Hence, it remains to show (17.17). By Theorem 17.30, we
have
G(x, y) = Ex[N(y)] =
∞

k=1
Px[N(y) ≥k]
= 1{x=y} +
∞

k=1
Px
'
τ k
y < ∞
(
= 1{x=y} +
∞

k=1
F(x, y) F(y, y)k−1
=
⎧
⎪⎪⎨
⎪⎪⎩
F(x, y)
1 −F(y, y),
if x ̸= y,
1
1 −F(x, x),
if x = y.
The second equality in (17.17) is an immediate consequence.
⊓⊔
Theorem 17.36 If x is recurrent and F(x, y) > 0, then y is also recurrent, and
F(x, y) = F(y, x) = 1.
Proof Let x, y ∈E, x ̸= y, be such that F(x, y) > 0. Then there is a k ∈N and
states x1, . . . , xk ∈E with xk = y and xi ̸= x for all i = 1, . . . , k and such that

414
17
Markov Chains
Px [Xi = xi for all i = 1, . . . , k] > 0.
In particular, pk(x, y) > 0. By the Markov property, we have
1 −F(x, x) = Px
'
τ 1
x = ∞
(
≥Px
'
X1 = x1, . . . , Xk = xk, τ 1
x = ∞
(
= Px [X1 = x1, . . . , Xk = xk] · Py
'
τ 1
x = ∞
(
= Px [X1 = x1, . . . , Xk = xk] (1 −F(y, x)) .
If now F(x, x) = 1, then also F(y, x) = 1. Since F(y, x) > 0, there exists an
l ∈N with pl(y, x) > 0. Hence, for n ∈N0,
pl+n+k(y, y) ≥pl(y, x) pn(x, x) pk(x, y).
If x is recurrent, then we conclude that
G(y, y) ≥
∞

n=0
pl+n+k(y, y) ≥pl(y, x)pk(x, y)G(x, x) = ∞
and hence also that y is recurrent. Changing the roles of x and y in the above
argument, we get F(x, y) = 1.
⊓⊔
Deﬁnition 17.37 A discrete Markov chain is called
•
irreducible if F(x, y) > 0 for all x, y ∈E, or equivalently G(x, y) > 0, and
•
weakly irreducible if F(x, y) + F(y, x) > 0 for all x, y ∈E.
Theorem 17.38 An irreducible discrete Markov chain is either recurrent or tran-
sient. If |E| ≥2, then there is no absorbing state.
Proof This follows directly from Theorem 17.36.
⊓⊔
Theorem 17.39 If E is ﬁnite and X is irreducible, then X is recurrent.
Proof Evidently, for all x ∈E,

y∈E
G(x, y) =
∞

n=0

y∈E
pn(x, y) =
∞

n=0
1 = ∞.

17.5
Application: Recurrence and Transience of Random Walks
415
As E is ﬁnite, there is a y ∈E with G(x, y) = ∞. Since F(y, x) > 0, there exists
a k ∈N with pk(y, x) > 0. Therefore, since pn+k(x, x) ≥pn(x, y) pk(y, x), we
have
G(x, x) ≥
∞

n=0
pn(x, y) pk(y, x) = pk(y, x) G(x, y) = ∞.
⊓⊔
Takeaways A state of a Markov chain is called recurrent if the chain returns
to it almost surely. Otherwise it is called transient. A recurrent state is called
positive recurrent if the expected time of return is ﬁnite; otherwise it is null
recurrent. For irreducible chains all states are in the same class: either positive
recurrent, null recurrent or transient. A state is recurrent if and only if the
expected number of visits (Green function) is inﬁnite.
Exercise 17.4.1 Let x be positive recurrent and let F(x, y) > 0. Show that y is
also positive recurrent. ♣
17.5
Application: Recurrence and Transience of Random
Walks
In this section, we study recurrence and transience of random walks on the D-
dimensional integer lattice ZD, D = 1, 2, . . .. A more exhaustive investigation can
be found in Spitzer’s book [159].
Consider ﬁrst the simplest situation of symmetric simple random walk X on ZD.
That is, at each step, X jumps to any of its 2D neighbors with the same probability
1/2D. Hence, in terms of the Markov chain notation, we have E = ZD and
p(x, y) =
 1
2D ,
if |x −y| = 1,
0,
else.
Is this random walk recurrent or transient?
The central limit theorem suggests that
pn(0, 0) ≈CD n−D/2
as n →∞
for some constant CD that depends on the dimension D. However, ﬁrst we have to
exclude the case where n is odd since here clearly pn(0, 0) = 0. Thus let Y1, Y2, . . .
be independent ZD-valued random variables with P[Yi = x] = p2(0, x). Then
X2n
D= Sn := Y1 + . . . + Yn for n ∈N0; hence G(0, 0) = ∞
n=0 P[Sn = 0].

416
17
Markov Chains
Clearly, Y1 = (Y 1
1 , . . . , Y D
1 ) has covariance matrix Ci,j := E[Y i
1 · Y j
1 ] = 2
D 1{i=j}.
By the local central limit theorem (see, e.g., [20, pages 224ff] for a one-dimensional
version of that theorem or Exercise 17.5.1 for an analytic derivation), we have
nD/2p2n(0, 0) = nD/2 P[Sn = 0]
n→∞
−→
2 (4π/D)−D/2.
(17.18)
Now ∞
n=1 n−α < ∞if and only if α > 1. Hence G(0, 0) < ∞if and only if
D > 2. We have thus shown the following theorem of Pólya [134].
Theorem 17.40 (Pólya [134]) Symmetric simple random walk on ZD is recurrent
if and only if D ≤2.
The procedure we used here to derive Pólya’s theorem has the disadvantage that it
relies on the local central limit theorem, which we have not proved (and will not).
Hence we will consider different methods of proof that yield further insight into the
problem.
Consider ﬁrst the one-dimensional simple random walk that with probability p
jumps one step to the right and with probability 1 −p jumps one step to the left.
Then
G(0, 0) =
∞

n=0
2n
n
p(1 −p)n =
∞

n=0
−1/2
n
 −4p(1 −p)n.
Using the generalized binomial theorem (see Lemma 3.5), we get (since we have
(1 −4p(1 −p))1/2 = |2p −1|)
G(0, 0) =

1
|2p−1|,
if p ̸= 1
2,
∞,
if p = 1
2.
(17.19)
Thus, simple random walk on Z is recurrent if and only if it is symmetric; that is, if
p = 1
2.
Of course, transience in the case p ̸= 1
2 could also be deduced directly from the
strong law of large numbers since limn→∞1
nXn = E0[X1] = 2p −1 almost surely.
In fact, this argument is even more robust since it uses only that the single steps of
X have an expectation that is not zero.
Consider now the situation where X does not necessarily jump to one of its
nearest neighbors but where we still have E0[|X1|] < ∞and E0[X1] = 0. The
strong law of large numbers does not yield recurrence immediately and we have to
do some work:
By the Markov property, for every N ∈N and every y ̸= x,
GN(x, y) :=
N

k=0
Px[Xk = y] =
N

k=0
Px
)
τ 1
y = k
* N−k

l=0
Py[Xl = y] ≤GN(y, y).

17.5
Application: Recurrence and Transience of Random Walks
417
This implies for all L ∈N
GN(0, 0) ≥
1
2L + 1

|y|≤L
GN(0, y)
=
1
2L + 1
N

k=0

|y|≤L
pk(0, y)
≥
1
2L + 1
N

k=1

y: |y/k|≤L/N
pk(0, y).
By the weak law of large numbers, we have lim infk→∞

|y|≤εk pk(0, y) = 1 for
every ε > 0. Hence, letting L = εN, we get
lim inf
N→∞GN(0, 0) ≥
1
2ε
for every ε > 0.
Thus G(0, 0) = ∞, which shows that X is recurrent.
We summarize the discussion in a theorem.
Theorem 17.41 A random walk on Z with ∞
x=−∞|x| p(0, x) < ∞is recurrent
if and only if ∞
x=−∞x p(0, x) = 0.
Now what about symmetric simple random walk in dimension D = 2 or in higher
dimensions? In order that the random walk be at the origin after 2n steps, it must
perform ki steps in the ith direction and ki steps in the opposite direction for some
numbers k1, . . . , kD ∈N0 with k1 + . . . + kD = n. We thus get
p2n(0, 0) = (2D)−2n

k1+...+kD=n

2n
k1, k1, . . . , kD, kD

,
(17.20)
where

N
l1,...,lr

=
N!
l1!···lr! is the multinomial coefﬁcient. In particular, for D = 2,
p2n(0, 0) = 4−2n
n

k=0
(2n)!
(k!)2((n −k)!)2
= 4−2n
2n
n

n

k=0
n
k

n
n −k

=

2−2n
2n
n
2
.

418
17
Markov Chains
Note that in the last step, we used a simple combinatorial identity that follows,
e.g., by the convolution formula (bn,p ∗bn,p)({n}) = b2n,p({n}). Now, by Stirling’s
formula,
lim
n→∞
√n 2−2n
2n
n

=
1
√π ,
hence limn→∞np2n(0, 0) = 1
π . In particular, we have ∞
n=1 p2n(0, 0) = ∞. That
is, two-dimensional symmetric simple random walk is recurrent.
For D ≥3, the sum over the multinomial coefﬁcients cannot be computed in
a satisfactory way. However, it is not too hard to give an estimate that shows that
there exists a c = cD such that p2n(0, 0) ≤c n−D/2, which implies G(0, 0) ≤
c ∞
n=1 n−D/2 < ∞(see, e.g., [53, page 361] or [59, Example 6.31]). Here,
however, we follow a different route.
Things would be easy if the individual coordinates of the chain were independent
one-dimensional random walks. In this case, the probability that at time 2n all
coordinates are zero would be the Dth power of the probability that the ﬁrst
coordinate is zero. For one coordinate, however, which moves only with probability
1/D and thus has variance 1/D, the probability of being back at the origin at time
2n is approximately (n π/D)−1/2. Up to a factor, we would thus get (17.18) without
using the multidimensional local central limit theorem.
An elegant way to decouple the coordinates is to pass from discrete time to
continuous time in such a way that the individual coordinates become independent
but such that the Green function remains unchanged.
We give the details. Let (T i
t )t≥0, i = 1, . . . , D be independent Poisson processes
with rate 1/D. Let Z1, . . . , ZD be independent (and independent of the Poisson
processes) symmetric simple random walks on Z. Deﬁne T := T 1 + . . . + T D,
Y i
t := Zi
T i
t for i = 1, . . . , D and let Yt = (Y 1
t , . . . , Y D
t ). Then Y is a Markov chain
in continuous time with Q-matrix q(x, y) = p(x, y) −1{x=y}. As T is a Poisson
process with rate 1, (XTt )t≥0 is also a Markov process with Q-matrix q. It follows
that (XTt )t≥0
D= (Yt)t≥0. We now compute
GY :=
 ∞
0
P0[Yt = 0] dt =
 ∞
0
∞

n=0
P0
)X2n = 0, Tt = 2n* dt
=
∞

n=0
p2n(0, 0)
 ∞
0
e−t t2n
(2n)! dt = G(0, 0).
The two processes (Xn)n∈N0 and (Yt)t∈[0,∞) thus have the same Green function. As
the coordinates of Y are independent, we have
GY =
 ∞
0
P0[Y 1
t = 0]D dt.

17.5
Application: Recurrence and Transience of Random Walks
419
Hence we only have to compute the asymptotics of P0[Y 1
t
= 0] for large t. We
can argue as follows. By the law of large numbers, we have T 1
t ≈t/D for large t.
Furthermore, P0[Y 1
t is even] ≈1
2. Hence we have, with nt = ⌊t/2D⌋for t →∞
(compare Exercise 17.5.2),
P0[Y 1
t = 0] ∼1
2P
)
Z1
2nt = 0
*
= 1
2
2nt
nt

4−nt ∼

2π/D
−1/2 t−1/2.
(17.21)
Since
3 ∞
1
t−α dt < ∞if and only if α > 1, we also have GY < ∞if and only if
D > 2. However, this is the statement of Pólya’s theorem.
Finally, we present a third method of studying recurrence and transience of
random walks that does not rely on the Euclidean properties of the integer lattice
but rather on the Fourier inversion formula.
First consider a general (discrete time) irreducible random walk with transition
matrix p on ZD. By φ(t) = 
x∈ZD ei⟨t,x⟩p(0, x) denote the characteristic function
of a single transition. The convolution of the transition probabilities translates into
powers of the characteristic function; hence
φn(t) =

x∈ZD
ei⟨t,x⟩pn(0, x).
By the Fourier inversion formula (Theorem 15.11), we recover the n-step transition
probabilities from φn by
pn(0, x) = (2π)−D

[−π,π)D e−i⟨t,x⟩φn(t) dt.
In particular, for λ ∈(0, 1),
Rλ :=
∞

n=0
λnpn(0, 0)
= (2π)−D
∞

n=0

[−π,π)D λn φn(t) dt
= (2π)−D

[−π,π)D
1
1 −λ φ(t) dt.
= (2π)−D

[−π,π)D Re

1
1 −λ φ(t)

dt.

420
17
Markov Chains
Now G(0, 0) = limλ↑1 Rλ and hence
X is recurrent ⇐⇒lim
λ↑1

[−π,π)D Re

1
1 −λ φ(t)

dt = ∞.
(17.22)
If we had φ(t) = 1 for some t ∈(−2π, 2π)D \ {0}, then we would have φn(t) = 1
for every n ∈N and hence, by Exercise 15.2.1, P0[⟨Xn, t/(2π)⟩∈Z] = 1. Thus X
would not be irreducible contradicting the assumption. Due to the continuity of φ
for all ε > 0, we thus have
inf 	|φ(t) −1| : t ∈[−π, π)D \ (−ε, ε)D
 > 0.
We summarize the discussion in a theorem due to Chung and Fuchs [27].
Theorem 17.42 (Chung–Fuchs [27])
An irreducible random walk on ZD with
characteristic function φ is recurrent if and only if, for every ε > 0,
lim
λ↑1

(−ε,ε)D Re

1
1 −λ φ(t)

dt = ∞.
(17.23)
Now consider symmetric simple random walk. Here φ(t) =
1
D
D
i=1 cos(ti).
Expanding the cosine function in a Taylor series, we get cos(ti) = 1 −1
2t2
i + O(t4
i );
hence 1 −φ(t) =
1
2D∥t∥2
2 + O(∥t∥4
2). We infer that X is recurrent if and only if
3
∥t∥2<ε ∥t∥−2
2
dt = ∞. We compute this integral in polar coordinates (with CD the
surface of the unit sphere in RD):

∥t∥2<ε
∥t∥−2
2
dt = CD
 ε
0
rD−1r−2 dr = ∞
⇐⇒
D ≤2.
Hence, X is recurrent if and only if D ≤2.
In Sect. 19.3, we will encounter a further method of proving Pólya’s theorem that
has a completely different structure and that is based on the connection between
Markov chains and electrical networks.
In fact, the Chung–Fuchs theorem can be used to compute the numerical values
of the Green function GD(0, 0) of symmetric simple random walk on ZD if we
compute numerically the so-called Watson integral
GD(0, 0) = (2π)−D

[−π,π)D
D
D −(cos(x1) + . . . + cos(xD)) dx.
(17.24)

17.5
Application: Recurrence and Transience of Random Walks
421
For this purpose, we follow [80] (where there are further reﬁnements of the method)
to transform the D-fold integral into a double integral. Denote by
I0(t) := 1
π
 π
0
et cos(θ) dθ
the so-called modiﬁed Bessel function of the ﬁrst kind. Using the identity 1
λ =
3 ∞
0
e−λt dt for the integrand and applying Fubini’s theorem, we get
GD(0, 0) =
D
(2π)D
 ∞
0
e−Dt
 
[−π,π)D et(cos(x1)+...+cos(xD)) dx

dt
and thus
GD(0, 0) = D
 ∞
0
e−Dt I0(t)D dt.
(17.25)
The right-hand side of (17.25) can quickly be computed numerically with great
accuracy (see Table 17.1).
For the case D = 3, Watson [169] found the expression
Table 17.1 Green function GD(0, 0) and return probability FD(0, 0) of simple symmetric
random walk on ZD. The numerical computations are based on (17.25).
D
GD(0, 0)
FD(0, 0)
2
∞
1
3
1.51638605915
0.34053732955
4
1.23946712185
0.19320167322
5
1.15630812484
0.13517860982
6
1.11696337322
0.10471549562
7
1.09390631559
0.08584493411
8
1.07864701202
0.07291264996
9
1.06774608638
0.06344774965
10
1.05954374789
0.05619753597
11
1.05313615291
0.05045515982
12
1.04798637482
0.04578912090
13
1.04375406289
0.04191989708
14
1.04021240323
0.03865787709
15
1.03720412092
0.03586962312
16
1.03461657857
0.03345836447
17
1.03236691238
0.03135214040
18
1.03039276285
0.02949628913
19
1.02864627888
0.02784852234
20
1.02709011674
0.02637559869

422
17
Markov Chains
G3(0, 0) = 1218 + 12
√
2 −10
√
3 −7
√
6
π2
K

(2 −
√
3)(
√
3 −
√
2)
2
,
where K(m) =
3 1
0

(1 −t2)(1 −mt2)
−1/2 dt is the complete elliptic integral of
the ﬁrst kind with modulus m ∈(−1, 1). This in turn can be expressed as a (quickly
convergent) series
K(m) = π
2

1 +
∞

n=1
 (2n)!
4n(n!)2
2
m2

.
Glasser and Zucker [61] found an expression as a product of four Gamma functions,
G3(0, 0) =
√
6
32π3 Γ
 1
24

Γ
 5
24

Γ
 7
24

Γ
11
24

= 1.5163860591519780181 . . .
Takeaways Symmetric
nearest
neighbour
random
walk
on
the
D-
dimensional integer lattice is recurrent if D ≤2 and is transient if D > 2.
A (one-dimensional) random walk on the integers is recurrent if and only if
the jump distribution is centred. The (numerical) computation of the Green
function is possible via the Fourier inversion formula.
Exercise 17.5.1 For n ∈N0, let pn be the matrix of n-step transition probabilities
of simple symmetric random walk on ZD. For n ∈N, derive the formula (see
Theorem 15.11)
p2n(0, 0) = (2π)−D

[−π,π)D D−2n
cos(t1) + . . . + cos(tD)
2n dt.
By a suitable bound for the integral, conclude the convergence nD/2p2n(0, 0)
n→∞
−→
2(4π/D)−D/2 (see (17.18)). ♣
Exercise 17.5.2 Show (17.21) formally. ♣
Exercise 17.5.3 Use Theorem 17.42 to show that a random walk on Z2 with

x∈Z2 x p(0, x) = 0 is recurrent if 
x∈Z2 ∥x∥2
2 p(0, x) < ∞. ♣
Exercise 17.5.4 Use Theorem 17.42 to show that, for D ≥3 every irreducible
random walk on ZD is transient ♣
Exercise 17.5.5 Show
(17.25)
for
GD(0, 0)
directly
with
the
p2n(0, 0)
from (17.20) and using the representation of I0(t) as the series I0(t)
=
∞
k=0(k!)−2 (t/2)k. ♣

17.6
Invariant Distributions
423
17.6
Invariant Distributions
In the following, let p be a stochastic matrix on the discrete space E and let
(Xn)n∈N0 be a corresponding Markov chain.
This section is devoted to the question: Which distributions are preserved under
the dynamics of the Markov chain? Of course, often the chain will not stay put in a
speciﬁc state but the distribution of the random state of the chain might nevertheless
be the same for all times. If such an invariant distribution exists, we will see in
Chap. 18 that under rather weak conditions, the distribution of a Markov chain
(started in an arbitrary state) converges in the large time limit to such an invariant
distribution.
Deﬁnition 17.43 If μ is a measure on E and f : E →R is a map, then we
write μp({x}) = 
y∈E μ({y})p(y, x) and pf (x) = 
y∈E p(x, y)f (y) if the sums
converge.
Deﬁnition 17.44
(i) A σ-ﬁnite measure μ on E is called an invariant measure if
μp = μ.
A probability measure that is an invariant measure is called an invariant
distribution. Denote by I the set of invariant distributions.
(ii) A function f : E →R is called subharmonic if pf exists and if f ≤pf .
f is called superharmonic if f ≥pf and harmonic if f = pf .
Remark 17.45 In the terminology of linear algebra, an invariant measure is a left
eigenvector of p corresponding to the eigenvalue 1. A harmonic function is a right
eigenvector corresponding to the eigenvalue 1. ♦
Lemma 17.46 If f is bounded and (sub-, super-) harmonic, then (f (Xn))n∈N0 is a
(sub-, super-) martingale with respect to the ﬁltration F = σ(X) generated by X.
Proof Let f be bounded and subharmonic. Then
Ex[f (Xn)
Fn−1] = EXn−1[f (X1)] =

y∈E
p(Xn−1, y)f (y)
= pf (Xn−1) ≥f (Xn−1).
⊓⊔
Theorem 17.47 If any point is transient, then an invariant distribution does not
exist.
Proof By assumption, G(x, y) = ∞
n=0 pn(x, y) < ∞for all x, y ∈E; hence
pn(x, y)
n→∞
−→
0. For every probability measure μ on E, we thus have that
μpn({x})
n→∞
−→0. If μ was invariant, however, then we would have μpn({x}) =
μ({x}) for all n ∈N.
⊓⊔

424
17
Markov Chains
Theorem 17.48 Let x be a recurrent state and let τ 1
x = inf{n ≥1 :
Xn = x}.
Then one invariant measure μx is deﬁned by
μx({y}) = Ex
⎡
⎣
τ 1
x −1

n=0
1{Xn=y}
⎤
⎦=
∞

n=0
Px
'
Xn = y, τ 1
x > n
(
.
Proof First we have to show that μx({y}) < ∞for all y ∈E. For y = x, clearly
μx({x}) = 1. For y ̸= x and F(x, y) = 0, we have μx({y}) = 0. Now let y ̸= x and
F(x, y) > 0. As x is recurrent, we have F(x, y) = F(y, x) = 1 and y is recurrent
(Theorem 17.36). Let
:
F(x, y) = Px
'
τ 1
x > τ 1
y
(
.
Then :
F(x, y) > 0 (otherwise y would not be visited). Changing the roles of x and
y, we also get :
F(y, x) > 0.
By the strong Markov property (Theorem 17.14), we have
Ey
⎡
⎣
τ 1
x −1

n=0
1{Xn=y}
⎤
⎦= 1 + Ey
⎡
⎢⎣
τ 1
x −1

n=τ 1y
1{Xn=y}; τ 1
x > τ 1
y
⎤
⎥⎦
= 1 +

1 −:
F(y, x)

Ey
⎡
⎣
τ 1x −1

n=0
1{Xn=y}
⎤
⎦.
Hence,
Ey
⎡
⎣
τ 1
x −1

n=0
1{Xn=y}
⎤
⎦=
1
:
F(y, x).
Therefore,
μx({y}) = Ex
⎡
⎣
τ 1
x −1

n=0
1{Xn=y}
⎤
⎦= Ex
⎡
⎢⎣
τ 1
x −1

n=τ 1y
1{Xn=y}; τ 1
x > τ 1
y
⎤
⎥⎦=
:
F (x, y)
:
F (y, x) < ∞.
Deﬁne pn(x, y) = Px
)
Xn = y; τ 1
x > n
*
. Then, for every z ∈E,
μx p({z}) =

y∈E
μx({y}) p(y, z) =
∞

n=0

y∈E
pn(x, y) p(y, z).

17.6
Invariant Distributions
425
Case 1: x ̸= z.
In this case,

y∈E
pn(x, y)p(y, z) =

y∈E
Px
'
Xn = y, τ 1
x > n, Xn+1 = z
(
= Px
'
τ 1
x > n + 1; Xn+1 = z
(
= pn+1(x, z).
Hence (since p0(x, z) = 0)
μx p({z}) =
∞

n=0
pn+1(x, z) =
∞

n=1
pn(x, z) =
∞

n=0
pn(x, z) = μx({z}).
Case 2: x = z.
In this case, we have

y∈E
pn(x, y)p(y, x) =

y∈E
Px
'
Xn = y; τ1
x > n; Xn+1 = x
(
= Px
'
τ1
x = n + 1
(
.
Thus (since Px
)
τ 1
x = 0
*
= 0)
μx p({x}) =
∞

n=0
Px
'
τ 1
x = n + 1
(
= 1 = μx({x}).
⊓⊔
Corollary 17.49 If X is positive recurrent, then π :=
μx
Ex
)
τ 1x
* is an invariant
distribution for any x ∈E.
Theorem 17.50 If X is irreducible, then X has at most one invariant distribution.
Remark 17.51
(i) One could in fact show that if X is irreducible and recurrent, then an invariant
measure of X is unique up to a multiplicative factor. However, the proof is a
little more involved. Since we will not need the statement here, we leave its
proof as an exercise (compare Exercise 17.6.6; see also [39, Section 6.5]).
(ii) For transient X, there can be more than one invariant measure. For example,
consider the asymmetric random walk on Z that jumps one step to the right
with probability r and one step to the left with probability 1 −r (for some
r ∈(0, 1)). The invariant measures are the nonnegative linear combinations of
the measures μ1 and μ2 given by μ1({x}) ≡1 and μ2({x}) = (r/(1 −r))x,
x ∈Z. X is transient if and only if r ̸= 1/2, in which case we have μ1 ̸= μ2.
♦
Proof Let π and ν be invariant distributions. Choose an arbitrary probability vector
(gn)n∈N with gn > 0 for all n ∈N. Deﬁne the stochastic matrix p(x, y) =
∞
n=1 gn pn(x, y). Then p(x, y) > 0 for all x, y ∈E and πp = π as well as
νp = ν.

426
17
Markov Chains
Consider now the signed measure μ = π −ν. We have μp = μ. If we had
μ ̸= 0, then there would exist (since μ(E) = 0) points x1, x2 ∈E with μ({x1}) > 0
and μ({x2}) < 0. Clearly, for every y ∈E, this would imply
μ({x1}) p(x1, y) +
μ({x2}) p(x2, y)
 <
μ({x1}) p(x1, y)
 +
μ({x2}) p(x2, y)
; hence
;; μp
;;
T V =

y∈E


x∈E
μ({x})p(x, y)

<

y∈E

x∈E
|μ({x})| p(x, y) =

x∈E
|μ({x})| = ∥μ ∥T V .
Since this is a contradiction, we conclude that μ = 0.
⊓⊔
Recall that I is the set of invariant distributions of X.
Theorem 17.52 Let X be irreducible. X is positive recurrent if and only if I ̸= ∅.
In this case, I = {π} with
π({x}) =
1
Ex[τ 1x ] > 0
for all x ∈E.
Proof If X is positive recurrent, then I ̸= ∅by Corollary 17.49. Now let I ̸= ∅
and π ∈I. As X is irreducible, we have π({x}) > 0 for all x ∈E. Let Pπ =

x∈E π({x})Px. Fix an x ∈E and for n ∈N0, let
σ n
x = sup
	
m ≤n : Xm = x

∈N0 ∪{−∞}
be the time of last entrance in x before time n. (Note that this is not a stopping time.)
By the Markov property, for all k ≤n,
Pπ
)
σ n
x = k
*
= Pπ
)
Xk = x, Xk+1 ̸= x, . . . , Xn ̸= x
*
= Pπ
)
Xk+1 ̸= x, . . . , Xn ̸= x |Xk = x
*
Pπ[Xk = x]
= π({x}) Px
)
X1, . . . , Xn−k ̸= x
*
= π({x}) Px
)
τ 1
x ≥n −k + 1
*
.

17.6
Invariant Distributions
427
Hence, for every n ∈N0 (since Py
)
τ 1
x < ∞
*
= 1 for all y ∈E),
1 =
n

k=0
Pπ
)
σ n
x = k
*
+ Pπ
)
σ n
x = −∞
*
= π({x})
n

k=0
Px
'
τ 1
x ≥n −k + 1
(
+ Pπ
'
τ 1
x ≥n + 1
(
n→∞
−→π({x})
∞

k=1
Px
'
τ 1
x ≥k
(
= π({x}) Ex
'
τ 1
x
(
.
Therefore, Ex
)
τ 1
x
*
=
1
π({x}) < ∞, and thus X is positive recurrent.
⊓⊔
Example 17.53 Let (px)x∈N0 be numbers in (0, 1] and let X be an irreducible
Markov chain on N0 with transition matrix
p(x, y) =
⎧
⎪⎨
⎪⎩
px,
if y = x + 1,
1 −px,
if y = 0,
0,
else.
If μ is an invariant measure, then the equations for μp = μ read
μ({n}) = pn−1 μ({n −1})
for n ∈N,
μ({0}) =
∞

n=0
μ({n})(1 −pn).
Hence we get
μ({n}) = μ({0})
n−1

k=0
pk
and (note that the sum is a telescope sum)
μ({0}) = μ({0})
∞

n=0
(1 −pn)
n−1

k=0
pk = μ({0})

1 −
∞

n=0
pn

.
Hence there exists a nontrivial invariant measure μ (that is, μ({0}) can be chosen
strictly positive) if and only if ∞
n=0 pn = 0. This, however, is true if and only if
∞
n=0(1 −pn) = ∞. Using a Borel–Cantelli argument, it is not hard to show that
this is exactly the condition for recurrence of X.

428
17
Markov Chains
If μ ̸= 0, then μ is a ﬁnite measure if and only if
M :=
∞

n=0
n−1

k=0
pk < ∞.
Hence X is positive recurrent if and only if M < ∞. In fact, it is not hard to show
that M is the expected time to return to 0; hence the criterion for positive recurrence
could also be deduced by Theorem 17.52.
A necessary condition for M < ∞is of course that the series ∞
n=0(1 −pn)
diverge; that is, that X is recurrent. One sufﬁcient condition for M < ∞is
∞

n=0
exp

−
n−1

k=0
(1 −pk)

< ∞.
♦
Takeaways An irreducible Markov chain possesses an invariant distribution
if and only if it is positive recurrent. The invariant distribution is unique and
is given as the reciprocals of the expected return times.
Exercise 17.6.1 Consider the Markov chain from Fig. 17.1 (page 412). Determine
the set of all invariant distributions. Show that the states 6, 7 and 8 are positive
recurrent and compute the expected ﬁrst entrance times
E6[τ6] = 17
4 ,
E7[τ7] = 17
5
and
E8[τ8] = 17
8 .
♣
Exercise 17.6.2 Let X = (Xt)t≥0 be a Markov chain on E in continuous time with
Q-matrix q. Show that a probability measure π on E is an invariant distribution for
X if and only if 
x∈E π({x})q(x, y) = 0 for all y ∈E. ♣
Exercise 17.6.3 Let G be a countable Abelian group and let p be the transition
matrix of an irreducible random walk X on G. That is, we have p(hg, hf ) =
p(g, f ) for all h, g, f ∈G. (This generalizes the notion of a random walk on ZD.)
Use Theorem 17.52 to show that X is positive recurrent if and only if G is ﬁnite. ♣
Exercise 17.6.4 Let r ∈[0, 1] and let X be the Markov chain on N0 with transition
matrix (see Fig. 17.2 on page 413)
p(x, y) =
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
1,
if x = 0 and y = 1,
r,
if y = x + 1 ≥2,
1 −r,
if y = x −1,
0,
else.

17.7
Stochastic Ordering and Coupling
429
Compute the invariant measure and show the following using Theorem 17.52:
(i) If r ∈

0, 1
2

, then X is positive recurrent.
(ii) If r = 1
2, then X is null recurrent.
(iii) If r ∈{0} ∪
 1
2, 1
*
, then X is transient. ♣
Exercise 17.6.5
(i) Use a direct argument to show that the Markov chain in Example 17.53 is
recurrent if and only if ∞
n=0(1 −pn) = ∞.
(ii) Show that the expected time to return to 0 is M and infer that the chain is
positive recurrent if and only if M < ∞.
(iii) Give examples of sequences (px)x∈N0 such that the chain is (a) transient, (b)
null recurrent, (c) positive recurrent, and (d) positive recurrent but
∞

n=0
exp

−
n−1

k=0
(1 −pk)

= ∞.
♣
Exercise 17.6.6 Let X be irreducible and recurrent. Show that, as claimed in
Remark 17.51, the invariant measure is unique up to constant multiples.
Hint: Let π ̸= 0 be an invariant measure for X and abbreviate Pπ = 
x∈E
π({x})Px
(note that, in general, this need not be a ﬁnite measure). Let x, y ∈E with x ̸= y
and deduce by induction that
π({y}) = Pπ
)τ 1
x ≥n, X0 ̸= x, Xn = y* +
n

k=1
Pπ
)τ 1
x ≥k, X0 = x, Xk = y*.
Infer that
π({y}) ≥
∞

k=1
Pπ
)
τ 1
x ≥k, X0 = x, Xk = y
*
= π({x}) μx({y}),
where μx is the invariant measure deﬁned in Theorem 17.48. Now use the fact
that πpn = π and μxpn = μx for all n ∈N to conclude that even π({y}) =
π({x})μx({y}) holds. ♣
17.7
Stochastic Ordering and Coupling
In many situations, for the comparison of two distributions, it is helpful to construct
a product space such that the two distributions are the marginal distributions but
are not necessarily independent. We ﬁrst introduce the abstract principle of such
couplings and then give some examples.

430
17
Markov Chains
There are many concepts to order probability measures on R or Rd such that the
“larger” one has a greater preference for large values than the “smaller” one. As
one of the most prominent orders we present here the so-called stochastic order and
illustrate its connection with couplings. As an excuse for presenting this section in
a chapter on Markov chains, we ﬁll ﬁnally use a simple Markov chain in order to
prove a theorem on the stochastic order of binomial distributions.
Deﬁnition 17.54 Let (E1, E1, μ1) and (E2, E2, μ2) be probability spaces. A prob-
ability measure μ on (E1×E2, E1 ⊗E2) with μ( · ×E2) = μ1 and μ(E1× ·) = μ2
is called a coupling of μ1 and μ2.
Clearly, the product measure μ = μ1 ⊗μ2 is a coupling, but in many situations
there are more interesting ones.
Example 17.55 Let X be a real random variable and let f, g : R →R be monotone
increasing functions with E[f (X)2] < ∞and E[g(X)2] < ∞. We want to show
that the random variables f (X) and g(X) are nonnegatively correlated.
To this end, let Y be an independent copy of X; that is, a random variable with
PY = PX that is independent of X. Note that E[f (X)] = E[f (Y)] and E[g(X)] =
E[g(Y)]. For all numbers x, y ∈R, we have (f (x) −f (y))(g(x) −g(y)) ≥0.
Hence
0 ≤E)f (X) −f (Y)g(X) −g(Y)*
= E[f (X)g(X)] −E[f (X)] E[g(Y)] + E[f (Y)g(Y)] −E[f (Y)] E[g(X)]
= 2 Cov[f (X), g(X)].
♦
(17.26)
Example 17.56 Let (E, ϱ) be a Polish space. For two probability measures P and
Q on (E, B(E)), denote by K(P, Q) ⊂M1(E × E) the set of all couplings of P
and Q. The so-called Wasserstein metric on M1(E) is deﬁned by
dW(P, Q) := inf
0 
ϱ(x, y) ϕ(d(x, y)) : ϕ ∈K(P, Q)
1
.
(17.27)
It can be shown that (this is the Kantorovich–Rubinstein theorem [84]; see also [37,
pages 420ff])
dW(P, Q) = sup
0 
f d(P −Q) : f ∈Lip1(E; R)
1
.
(17.28)
Compare this representation of the Wasserstein metric with that of the total variation
norm,
∥P −Q∥T V = sup
0 
f d(P −Q) : f ∈L∞(E) with ∥f ∥∞≤1
1
.
(17.29)

17.7
Stochastic Ordering and Coupling
431
In fact, we can also give a deﬁnition for the total variation in terms of a coupling:
Let D := {(x, x) : x ∈E} be the diagonal in E × E. Then
∥P −Q∥T V = inf
	
ϕ((E × E) \ D) : ϕ ∈K(P, Q)

.
(17.30)
See [60] for a comparison of different metrics on M1(E).♦
As an example of a more involved coupling, we quote the following theorem that is
due to Skorohod.
Theorem 17.57 (Skorohod coupling) Let μ, μ1, μ2, . . . be probability measures
on a Polish space E with μn
n→∞
−→
μ. Then there exists a probability space
(Ω, A, P) with random variables X, X1, X2, . . . with PX = μ and PXn = μn for
every n ∈N such that Xn
n→∞
−→X almost surely.
Proof See, e.g., [83, page 79].
⊓⊔
Reﬂection For real valued random variables, a Skorohod coupling can be con-
structed explicitly using the distribution functions. How does this work in detail?
♠
We now come to the concept of stochastic order.
Deﬁnition 17.58 Let μ1, μ2 ∈M1(Rd). We write μ1 ≤st μ2 if

f dμ1 ≤

f dμ2
for every monotone increasing bounded function f : Rd →R. In this case, we say
that μ2 is stochastically larger than μ1.
Evidently, ≤st is a partial order on M1(Rd). The stochastic order belongs to the
class of so-called integral orders that are deﬁned by the requirement that the integrals
with respect to a certain class of functions (here: monotone increasing and bounded)
are ordered. Other classes of functions that are often considered are convex functions
or indicator functions on lower or upper orthants.
Let F1 and F2 be the distribution functions of μ1 and μ2. Clearly, μ1 ≤st μ2
implies F1(x) ≥F2(x) for all x ∈Rd. If d = 1, then both statements are equivalent.
However, for d ≥2, the condition F1 ≥F2 is weaker than μ1 ≤st μ2. For example,
consider d = 2 and
μ1 = 1
2δ(0,0) + 1
2δ(1,1)
and
μ2 = 1
2δ(1,0) + 1
2δ(0,1).
The partial order deﬁned by the comparison of the distribution functions is called
(lower) orthant order.
For a survey on different orders of probability measures, see, e.g., [120].

432
17
Markov Chains
The following theorem was shown by Strassen [161] in larger generality for
integral orders.
Theorem 17.59 (Strassen’s theorem) Let
L := 	(x1, x2) ∈Rd × Rd : x1 ≤x2

.
Then μ1 ≤st μ2 if and only if there is a coupling ϕ of μ1 and μ2 with ϕ(L) = 1.
Proof Let ϕ be such a coupling. For monotone increasing bounded f : Rd →R,
we have f (x1)−f (x2) ≤0 for every x = (x1, x2) ∈L; hence
3
f dμ1−
3
f dμ2 =
3
L

f (x1) −f (x2)

ϕ(dx) ≤0 and thus μ1 ≤st μ2.
Now assume μ1 ≤st μ2. We only consider the case d = 1 (see [120, Thm. 3.3.5]
for d ≥2). Here F((x1, x2)) := min(F1(x1), F2(x2)) deﬁnes a distribution function
on R × R (see Exercise 1.5.5) that corresponds to a coupling ϕ with ϕ(L) = 1. A
somewhat more explicit representation can be obtained using random variables. Let
U be a random variable that is uniformly distributed on (0, 1). Then
Xi := F −1
i
(U) := inf
	
x ∈R : Fi(x) ≥U

is a real random variable with distribution μi (see proof of Theorem 1.104). Clearly,
we have X1 ≤X2 almost surely; that is, P[(X1, X2) ∈L] = 1. Evidently, the
distribution function of (X1, X2) is F.
⊓⊔
While Strassen’s theorem yields the existence of an abstract coupling, in many
examples a natural coupling can be established and used as a tool for proving, e.g.,
stochastic orders.
Example 17.60 Let n ∈N and 0 ≤p1 ≤p2 ≤1. Let Y1, . . . , Yn be independent
random variables that are uniformly distributed on [0, 1]. Deﬁne Xi = #{k ≤n :
Yk ≤pi}, i = 1, 2. Then Xi ∼bn,pi and X1 ≤X2 almost surely. This coupling
shows that bn,p1 ≤st bn,p2.
An even simpler coupling can be used to show that bm,p ≤st bn,p for m ≤n and
p ∈[0, 1]. ♦
Theorem 17.61 Let n1, n2 ∈N and p1, p2 ∈(0, 1). We have bn1,p1 ≤st bn2,p2 if
and only if
(1 −p1)n1 ≥(1 −p2)n2
(17.31)
and
n1 ≤n2.
(17.32)
Proof (The proof follows the exposition in [100, Section 3]) Since bni,pi({0}) =
(1−pi)ni, conditions (17.31) and (17.32) are clearly necessary for bn1,p1 ≤st bn2,p2.
Hence we only have to show sufﬁciency of the two conditions.

17.7
Stochastic Ordering and Coupling
433
Assume that (17.31) and (17.32) hold. By Example 17.60, it is enough to consider
the smallest p2 that fulﬁlls (17.31). Hence we assume (1 −p1)n1 = (1 −p2)n2.
Deﬁne λ := −n1 log(1 −p1) = −n2 log(1 −p2). We will construct a binomially
distributed random variable by throwing a Poiλ-distributed number T of balls in ni
boxes and count the number of nonempty boxes. More precisely, let T ∼Poiλ and
let X1, X2, . . . be independent and uniformly distributed on [0, 1] and independent
of T . For n ∈N, t ∈N0 and l = 1, . . . , n, deﬁne
Mn,t,l = #
	
s ≤t : Xs ∈((l −1)/n, l/n]

and the number of nonempty boxes after t balls are thrown:
Nn,t :=
n

l=1
1{Mn,t,l>0}.
By Theorem 5.35, the random variables Mn,T,1, . . . , Mn,T,n are independent and
Poiλ/n-distributed. In particular, we have
P[Mni,T,l > 0] = 1 −e−λ/ni = pi
and thus Nni,T ∼bni,pi, i = 1, 2. Hence it sufﬁces to show that Nn1,T ≤st Nn2,T .
For this in turn it is enough to show
Nn1,t ≤st Nn2,t
for all t ∈N0.
(17.33)
In fact, let f : {0, . . . , n} →R be monotone increasing. Then
E[f (Nn1,T )] =
∞

t=0
E[f (Nn1,t)] P[T = t]
≤
∞

t=0
E[f (Nn2,t)] P[T = t] = E[f (Nn2,T )].
We use an induction argument to show (17.33). For t = 0, the claim holds trivially.
Now assume that (17.33) holds for some given t ∈N0. We are now at the point to
use a Markov chain. Note that (for ﬁxed n), (Nn,t)t=0,1,... is a Markov chain with
state space {0, . . ., n} and transition matrix
pn(k, l) =
⎧
⎪⎨
⎪⎩
k/n,
if l = k,
1 −k/n,
if l = k + 1,
0,
otherwise.

434
17
Markov Chains
We deﬁne for k, l = 0, . . ., n
hn,l(k) =
n

j=l
pn(k, j) =
⎧
⎪⎨
⎪⎩
0,
if k < l −1,
1 −k/n,
if k = l −1,
1,
if k > l −1.
Then P[Nn,t+1 ≥l] = E[hn,l(Nn,t)] and hn,l(k) is monotone increasing both in k
and in n. Hence by the induction hypothesis, we have
P[Nn1,t+1 ≥l] = E[hn1,l(Nn1,t)] ≤E[hn1,l(Nn2,t)]
≤E[hn2,l(Nn2,t)] = P[Nn2,t+1 ≥l].
We conclude that Nn1,t+1 ≤st Nn2,t+1 which completes the induction and the proof
of the theorem.
⊓⊔
Takeaways A coupling is a probability measure on a product space with
given marginals. In many situations it is desirable to have a coupling with
additional properties like all the mass lies above the diagonal. The latter
property can be achieved if the marginals are stochastically ordered. Optimal
couplings can be used also for the deﬁnitions of a metric on probability
measures such as the Wasserstein metric, for example. Using Markov chains
we construct a coupling to prove a theorem on the stochastic ordering of
binomial distributions.
Exercise 17.7.1 Use an elementary direct coupling argument to show the claim of
Theorem 17.61 for the case n2/n1 ∈N. ♣
Exercise 17.7.2 For the Poisson distribution, show that
Poiλ1 ≤st Poiλ2 ⇐⇒λ1 ≤λ2.
♣
Exercise 17.7.3 Let n ∈N, p ∈(0, 1) and λ > 0. Show that
bn,p ≤st Poiλ ⇐⇒(1 −p)n ≥e−λ.
♣

Chapter 18
Convergence of Markov Chains
We consider a Markov chain X with invariant distribution π and investigate
conditions under which the distribution of Xn converges to π for n →∞.
Essentially it is necessary and sufﬁcient that the state space of the chain cannot
be decomposed into subspaces
•
that the chain does not leave
•
or that are visited by the chain periodically; e.g., only for odd n or only for even n.
In the ﬁrst case, the chain would be called reducible, and in the second case, it would
be periodic.
We study periodicity of Markov chains in the ﬁrst section. In the second section,
we prove the convergence theorem. The third section is devoted to applications of
the convergence theorem to computer simulations with the so-called Monte Carlo
method. In the last section, we describe the speed of convergence to the equilibrium
by means of the spectrum of the transition matrix.
18.1
Periodicity of Markov Chains
We study the conditions under which a positive recurrent Markov chain X on
the countable space E (and with transition matrix p), started in an arbitrary
μ ∈M1(E), converges in distribution to an invariant distribution π; that is,
μpn
n→∞
−→π. Clearly, it is necessary that π be the unique invariant distribution;
that is, up to a factor π it is the unique left eigenvector of p for the eigenvalue 1.
As shown in Theorem 17.50, for this uniqueness it is sufﬁcient that the chain be
irreducible.
In order for μpn
n→∞
−→π to hold for every μ ∈M1(E), a certain contraction
property of p is necessary. Manifestly, 1 is the largest (absolute value of an)
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_18
435

436
18
Convergence of Markov Chains
eigenvalue of p. However, p is sufﬁciently contractive only if the multiplicity of
the eigenvalue 1 is exactly 1 and if there are no further (possibly complex-valued)
eigenvalues of modulus 1.
For the latter property, it is not sufﬁcient that the chain be irreducible. For
example, consider on E = {0, . . ., N −1} the Markov chain with transition matrix
p(x, y) = 1{y=x+1(mod N)}. The eigenvalue 1 has the multiplicity 1. However,
all complex Nth roots of unity e2πik/N, k = 0, . . . , N −1, are eigenvalues of
modulus 1. Clearly, the uniform distribution on E is invariant but lim
n→∞δxpn does
not exist for any x ∈E. In fact, every point is visited periodically after N steps.
In order to obtain criteria for the convergence of Markov chains, we thus have to
understand periodicity ﬁrst. Thereafter, for irreducible aperiodic chains, we state
the convergence theorem.
If m, n ∈N, then write m
n if m is a divisor of n; that is, if n
m ∈N. If M ⊂N,
then denote by gcd(M) the greatest common divisor of all n ∈M. In the following,
let X be a Markov chain on the countable space E with transition matrix p.
Deﬁnition 18.1
(i) For x, y ∈E, deﬁne
N(x, y) :=
	
n ∈N0 : pn(x, y) > 0

.
For any x ∈E, dx := gcd(N(x, x)) is called the period of the state x.
(ii) If dx = dy for all x, y ∈E, then d := dx is called the period of X.
(iii) If dx = 1 for all x ∈E, then X is called aperiodic.
See Figs. 18.1 and 18.2 for illustrations of aperiodic and periodic Markov chains.
Lemma 18.2 For any x ∈E, there exists an nx ∈N with
pndx(x, x) > 0
for all n ≥nx.
(18.1)
1/2
1/2
1/2
1/2
1/2
1
1
1/2
Fig. 18.1 The left Markov chain is periodic with period 2, and the right Markov chain is aperiodic.

18.1
Periodicity of Markov Chains
437
1
1
1
1
1
1
1/2
1/2
2
8
5
3
4
7
6
1
1
Fig. 18.2 Here N(8, 8) = {6, 10, 12, 14, 16, . . .}; hence d8 := gcd({6, 10, 12, . . .}) = 2 and
n8 = 5. The chain thus has period 2. However, n1 = 2 and n4 = 4.
Proof Let k1, . . . , kr
∈N(x, x) with gcd({k1, . . . , kr}) = dx. Then, for all
m1, . . . , mr ∈N0, we also have r
i=1 ki mi ∈N(x, x). Basic number theory then
yields that, for every n ≥nx := r · r
i=1(ki/dx), there are numbers m1, . . . , mr ∈
N0 with n dx = r
i=1 ki mi. Hence (18.1) holds.
⊓⊔
The problem of ﬁnding the smallest number N such that any n dx, n ≥N can
be written as a nonnegative integer linear combination of k1, . . . , kr is called the
Frobenius problem. The general solution is unknown; however, for the case r = 2,
Sylvester [163] showed that N = (k1/dx −1)(k2/dx −1) is minimal. In the general
case, for N, the upper bound 2 max{ki : i = 1, . . . , r}2/(rd2
x) is known; see, e.g.,
[45].
Lemma 18.3 Let X be irreducible. Then the following statements hold.
(i) d := dx = dy for all x, y ∈E.
(ii) For all x, y ∈E, there exist nx,y ∈N and Lx,y ∈{0, . . . , d −1} such that
nd + Lx,y ∈N(x, y)
for all n ≥nx,y.
(18.2)
Lx,y is uniquely determined, and we have
Lx,y + Ly,z + Lz,x = 0 (mod d)
for all x, y, z ∈E.
(18.3)
Proof
(i) Let m, n ∈N0 with pm(x, y) > 0 and pn(y, z) > 0. Then
pm+n(x, z) ≥pm(x, y) pn(y, z) > 0.
Hence we have
N(x, y) + N(y, z) := 	m + n : m ∈N(x, y), n ∈N(y, z)
 ⊂N(x, z).
(18.4)

438
18
Convergence of Markov Chains
If, in particular, m ∈N(x, y), n ∈N(y, x) and k ≥ny, then kdy ∈N(y, y);
hence m+kdy ∈N(x, y) and m+n+kdy ∈N(x, x). Therefore, dx
(m+n+
kdy) for every k ≥ny; hence dx
dy. Similarly, we get dy
dx; hence dx = dy.
(ii) Let m ∈N(x, y). Then m + kd ∈N(x, y) for every k ≥nx. Hence (18.2)
holds with
nx,y := nx +
Im
d
J
and
Lx,y := m −d
Im
d
J
.
Owing to (18.4), we have
(nx,y + ny,z)d + Lx,y + Ly,z ∈N(x, z).
Together with z = x, it follows that d
(Lx,y + Ly,x). Hence the value of Lx,y
is unique in {0, . . ., d −1} and Lx,y = −Ly,x (mod d). For general z, we infer
that d
(Lx,y + Ly,z + Lz,x); hence (18.3).
⊓⊔
Theorem 18.4 Let X be irreducible with period d. Then there exists a disjoint
decomposition of the state space
E =
d−1

i=0
Ei
(18.5)
with the property
p(x, y) > 0 and x ∈Ei
⇒
y ∈Ei+1 (mod d).
(18.6)
This decomposition is unique up to cyclic permutations.
See Fig. 18.3 for an illustration of the state space decomposition of a periodic
Markov chain.
E
E
E
1
0
2
Fig. 18.3 State space decomposition of a Markov chain with period d = 3.

18.2
Coupling and Convergence Theorem
439
Property (18.6) says that X visits the Ei one after the other (see Fig. 18.3 or 18.2,
where d = 2, E0 = {1, 3, 5, 7} and E1 = {2, 4, 6, 8}). Somewhat more formally,
we could write: If x ∈Ei for some i, then Px
)
Xn ∈Ei+n (mod d)
*
= 1.
Proof
Existence x0 ∈E and let
Ei := 	y ∈E : Lx0,y = i
for i = 0, . . . , d −1.
Clearly, (18.5) holds. Let i ∈{0, . . ., d −1} and x ∈Ei. If y ∈E with p(x, y) > 0,
then Lx,y = 1 and hence Lx0,y = Lx0,x + Lx,y = i + 1 (mod d).
Uniqueness Let (
Ei, i = 0, . . ., d −1) be another decomposition that satis-
ﬁes (18.5) and (18.6). Without loss of generality, assume E0 ∩
E0 ̸= ∅(otherwise
permute the 
Ei cyclically until this holds). Fix an arbitrary x0 ∈E0 ∩
E0. By
assumption, p(x0, y) > 0 now implies y ∈E1 and y ∈
E1; hence y ∈E1 ∩
E1.
Inductively, we get that pnd+i(x, y) > 0 implies y ∈Ei ∩
Ei (for all n ∈N and
i = 0, . . . , d −1).
However, since the chain is irreducible, for every y ∈E, there exist numbers
n(y) and i(y) such that pn(y) d+i(y)(x0, y) > 0; hence y ∈Ei(y) ∩
Ei(y). Therefore,
we have Ei = 
Ei for every i = 0, . . . , d −1.
⊓⊔
Takeaways Assume that a Markov chain can return to a given state only at
times that are a multiple of some natural number d and assume that d is the
largest number with this property. Then d is said to be the period of that
state. For irreducible chains, all states have the same period. For example,
for nearest neighbour random walk on the integers, every state has period
d = 2. If we have d = 1 for every state, then the Markov chain is called
aperiodic. For periodic chains, the state space decomposes into d subspaces
that can be entered at speciﬁc times (mod d) only. In this sense, aperiodicity
has the ﬂavour of an irreducibility condition which is needed in order that two
independent chains started in arbitrary states could meet each other.
18.2
Coupling and Convergence Theorem
Our goal is to use a coupling of two discrete Markov chains that are started in
different distributions μ and ν in order to show the convergence theorem for Markov
chains.
In the following, let E be a countable space and let p be a stochastic matrix
on E. Recall the deﬁnition of a general coupling of two probability measures from
Deﬁnition 17.54.

440
18
Convergence of Markov Chains
Deﬁnition 18.5 A bivariate process ((Xn, Yn))n∈N0 with values in E × E is called
a coupling if (Xn)n∈N0 and (Yn)n∈N0 are Markov chains, each with transition
matrix p.
A coupling is called successful if P(x,y)
) 
m≥n{Xm ̸= Ym}
*
n→∞
−→
0 for all
x, y ∈E.
Of course, two independent chains form a coupling, though maybe not the most
interesting one.
Example 18.6 (Independent coalescence) The most important coupling is Markov
chains that run independently until they coalesce: Let X and Y be independent
chains with transition matrix p until they ﬁrst meet. After that, the chains run
together. We call this coupling the independent coalescent. The transition matrix is
¯p

(x1, y1), (x2, y2)

=
⎧
⎪⎨
⎪⎩
p(x1, x2) · p(y1, y2),
if x1 ̸= y1,
p(x1, x2),
if x1 = y1, x2 = y2,
0,
if x1 = y1, x2 ̸= y2.
Denote by τ := inf{n ∈N0 : Xn = Yn} the time of coalescence. We can construct
the coupling using two independent chains ˜X and ˜Y by deﬁning X := ˜X, ˜τ :=
inf{n ∈N0 : ˜Xn = ˜Yn} and
Yn :=
0 ˜Yn,
if n < ˜τ,
Xn,
if n ≥˜τ.
Instead of checking by a direct computation that this process (X, Y) is indeed
a coupling with transition matrix ¯p, consider the construction of Markov chains
from Theorem 17.17: Let (Rn(x) : n ∈N0, x ∈E) be independent random
variables with distribution P[Rn(x1) = x2] = p(x1, x2), and let ˜Rn((x1, y1)) =
(Rn(x1), Rn(y1)). Then ( ˜Rn)n∈N0 is independent and we have
P
) ˜Rn((x1, y1)) = (x2, y2)
*
= ¯p

(x1, y1), (x2, y2)

.
As we saw in Theorem 17.17, by Xn+1 := Rn(Xn) and Yn+1 := Rn(Yn), two
Markov chains X and Y are deﬁned with transition matrix p. On the other hand,
we have (Xn+1, Yn+1) =
˜Rn((Xn, Yn)). Hence the bivariate process is indeed a
coupling with transition matrix ¯p. ♦
Example 18.7 Let E = Z and p(x, y) = 1/3 if |x−y| ≤1 and 0 otherwise. Clearly,
p is the transition matrix of an aperiodic recurrent random walk on Z. We will show
that we can obtain a successful coupling by coalescing independent chains.
Accordingly, let ˜X and ˜Y be independent random walks with transition matrix p.
Then the difference chain (Zn)n∈N0 := ( ˜Xn −˜Yn)n∈N0 is a symmetric random walk

18.2
Coupling and Convergence Theorem
441
with ﬁnite expectation and hence recurrent. Furthermore, Z is irreducible. For any
two points x, y ∈Z, we thus have
P(x,y)[˜τ < ∞] = Px−y[Zn = 0 for some n ∈N0] = 1.
Therefore, X and Y coalesce almost surely. ♦
Recurrence, irreducibility and aperiodicity alone are not sufﬁcient for the inde-
pendent coalescence coupling to be successful. In Exercise 18.2.4, an example is
studied that shows that spacial homogeneity cannot easily be dropped if we want to
have a successful coupling. Dropping the assumption of recurrence is easier, as the
following theorem shows.
Theorem 18.8 Let X be an arbitrary aperiodic and irreducible random walk on
Zd with transition matrix p. Then there exists a successful coupling (X, Y).
Proof
Step 1.
First, consider the case where p(0, x) = 3−d for all x ∈{−1, 0, 1}d. The
individual coordinates X(1), . . . , X(d) of X are independent random walks on Z with
transition probabilities P0[X(i)
1
= xi] = 1/3 for xi = −1, 0, 1. By Example 18.7,
we can construct independent successful couplings (X(i), Y (i)), i = 1, . . ., d, with
merging times τ (i). Deﬁne Y = (Y (1), . . . , Y (d)) and τ = max{τ (1), . . . , τ (d)} <
∞. Then (X, Y) is a successful coupling and Xn = Yn for n ≥τ.
Step 2.
Now, consider the case where
λ := 3d min 	p(0, x) : x ∈{−1, 0, 1}d
 > 0.
If λ = 1, then the condition of Step 1 is fulﬁlled and we are done. Hence, we
assume that λ ∈(0, 1). We deﬁne the transition matrix ˆp on Zd by ˆp(x, y) = 3−d
for y −x ∈{−1, 0, 1}d. Note that also ˇp := (p −λ ˆp)/(1 −λ) is the transition
matrix of a random walk on Zd and that
p = λ ˆp + (1 −λ) ˇp.
Let ˆX and ˇX be independent random walks with transition matrices ˆp and ˇp,
respectively. Assume that ˆX0 = X0 and ˇX0 = 0. Furthermore, let Z1, Z2, . . . be
i.i.d. Bernoulli random variables with parameter λ that are independent of ˆX and ˇX.
Deﬁne Sn := Z1 + . . . + Zn for n ∈N and
Xn := ˆXSn + ˇXn−Sn.
That is, in each time step, a coin ﬂip decides whether X makes a jump according to
the matrix ˆp or ˇp. Hence X is a random walk with transition matrix p.

442
18
Convergence of Markov Chains
By Step 1, there exists a successful coupling ( ˆX, ˆY) such that ˆY is independent of
ˇX and Z1, Z2, . . .. Consequently,
Yn := ˆYSn + ˇXn−Sn,
n ∈N,
is also a random walk with transition matrix p. Since we have Sn →∞almost
surely, the coupling (X, Y) is successful.
Step 3.
Finally, we consider the general situation. Since X is irreducible and
aperiodic, by Lemma 18.3(ii), there exists an N ∈N, such that the N-step transition
matrix fulﬁlls
pN(0, x) > 0
for all x ∈{−1, 0, 1}d.
Hence, the random walk X′ = (X′
n)n∈N := (XnN)n∈N fulﬁlls the condition from
Step 2. Let (X′, Y ′) be the coupling that was constructed in Step 2 and let
τ := inf
	
n ∈N0 : X′
m = Y ′
m for all m ≥n

.
Then Y ′ is a random walk with transition matrix pN. For n ∈N0, deﬁne YnN := Y ′
n.
It remains to close the gaps between the points {0, N, 2N, . . .} in such a way that Y
is a random walk and (X, Y) is a successful coupling.
Let (Ux,y,n : x, y ∈Zd, n ∈N0) be an independent family of (Zd)N−1-valued
random variables Ux,y,n = (Ux,y,n
1
, . . . , Ux,y,n
N−1 ) such that
P[(X1, . . . , XN−1) ∈· |X0 = x, XN = y] = PUx,y,n
for all x, y ∈Zd with pN(x, y) > 0 and for all n ∈N0. We further assume that the
Ux,y,n are independent of X and Y ′. For k ∈{nN + 1, . . . , (n + 1)N −1}, deﬁne
Yk :=

U
Y ′
n,Y ′
n+1,n
k−nN
,
if n < τ,
Xk,
else.
It is easy to check that Y is indeed a random walk with transition matrix p. By
construction, the coupling (X, Y) is successful.
⊓⊔
Theorem 18.9 Let X be a Markov chain on E with transition matrix p. If there
exists a successful coupling, then every bounded harmonic function is constant.
Proof Let f : E →R be bounded and harmonic; hence pf = f . Let x, y ∈
E, and let (X, Y) be a successful coupling. By Lemma 17.46, (f (Xn))n∈N0 and
(f (Yn))n∈N0 are martingales; hence we have
|f (x) −f (y)| =
E(x,y)[f (Xn) −f (Yn)]
 ≤2∥f ∥∞P(x,y)[Xn ̸= Yn]
n→∞
−→0. ⊓⊔

18.2
Coupling and Convergence Theorem
443
Corollary 18.10 If X is an irreducible random walk on Zd, then every bounded
harmonic function is constant.
This statement holds more generally if we replace Zd by a locally compact Abelian
group. In that form, the theorem goes back to Choquet and Deny [24], see also [144].
Proof Let p be the transition matrix of X. Let ¯X be a Markov chain with transition
matrix ¯p(x, y) = 1
2p(x, y) + 1
2 1{x}(y). Clearly, X and ¯X have the same harmonic
functions. Now ¯X is an aperiodic irreducible random walk; hence, by Theorem 18.8,
there is a successful coupling for all initial states.
⊓⊔
Reﬂection Consider the random walk on the integers with transition matrix given
by p(k, k + 1) = r and p(k, k −1) = 1 −r for some r ∈[0, 1]. The bounded
harmonic functions are constant, but what are the unbounded harmonic functions?
Be careful, the cases r = 1
2 and r ̸= 1
2 are different. ♠
Theorem 18.11 Let p be the transition matrix of an irreducible, positive recurrent,
aperiodic Markov chain on E. Then the independent coalescent chain is a successful
coupling.
Proof Let ˜X and ˜Y be two independent Markov chains on E, each with transition
matrix p. Then the bivariate Markov chain Z := (( ˜Xn, ˜Yn))n∈N0 has the transition
matrix p deﬁned by
p

(x1, y1), (x2, y2)

= p(x1, x2) · p(y1, y2).
We ﬁrst show that the matrix p is irreducible. Only here do we need aperiodicity of
p. Accordingly, ﬁx (x1, y1), (x2, y2) ∈E × E. Then, by Lemma 18.2, there exists
an m0 ∈N such that
pn(x1, x2) > 0
and
pn(y1, y2) > 0
for all n ≥m0.
For n ≥m0, we thus have p n(x1, y1), (x2, y2) > 0. Hence p is irreducible.
Now deﬁne the stopping time τ of the ﬁrst entrance of ( ˜X, ˜Y) into the diagonal
D := {(x, x) : x ∈E} by τ := inf 	n ∈N0 :
˜Xn = ˜Yn

. Let π be the invariant
distribution of ˜X. Then, clearly, the product measure π ⊗π ∈M1(E×E) is an (and
then the) invariant distribution of ( ˜X, ˜Y ). Thus ( ˜X, ˜Y) is positive recurrent (hence,
in particular, recurrent) by Theorem 17.52. Therefore, P(x,y)[τ < ∞] = 1 for all
initial points (x, y) ∈E × E of Z.
⊓⊔
Theorem 18.12 Let X be a Markov chain with transition matrix p such that there
exists a successful coupling. Then
;;(μ −ν)pn;;
T V
n→∞
−→0 for all μ, ν ∈M1(E).
If X is aperiodic and positive recurrent with invariant distribution π, then we
have
;;Lμ[Xn] −π
;;
T V
n→∞
−→0 for all μ ∈M1(E).

444
18
Convergence of Markov Chains
Proof It is enough to consider the case μ = δx, ν = δy for some x, y ∈E.
Summation over x and y yields the general case. Let (Xn, Yn)n∈N0 be a successful
coupling. Then
;;(δx −δy)pn;;
T V ≤2 P(x,y)[Xn ̸= Yn]
n→∞
−→
0.
⊓⊔
We summarize the connection between aperiodicity and convergence of distribu-
tions of X in the following theorem.
Theorem 18.13 (Convergence of Markov chains) Let X be an irreducible, posi-
tive recurrent Markov chain on E with invariant distribution π. Then the following
are equivalent:
(i) X is aperiodic.
(ii) For every x ∈E, we have
;;Lx[Xn] −π
;;
T V
n→∞
−→0.
(18.7)
(iii) Equation (18.7) holds for some x ∈E.
(iv) For every μ ∈M1(E), we have
;;μpn −π
;;
T V
n→∞
−→0.
Proof The implications (iv)
⇐⇒
(ii) ⇒
(iii) are evident. The implica-
tion (i) ⇒(ii) was shown in Theorem 18.12. Hence we only show (iii) ⇒(i).
“(iii) ⇒(i)”
Assume that (i) does not hold. If X has period d ≥2, and if n ∈N
is not a multiple of d, then, by Theorem 17.52,
;;δxpn −π
;;
T V ≥|pn(x, x) −π({x})| = π({x}) > 0.
Thus, for every x ∈E, we have lim sup
n→∞
;;δxpn −π
;;
T V > 0. Therefore, (iii) does
not hold.
⊓⊔
Takeaways For two examples of aperiodic and irreducible Markov chains,
we have constructed a coupling such that two chains meet almost surely:
Random walks on the d-dimensional integer lattice and positive recurrent
Markov chains. In both cases, we infer that bounded harmonic functions are
constant. In the latter case, we also get convergence of the Markov chain to
the invariant distribution (in distribution).
Exercise 18.2.1 Let dP be the Prohorov metric (see (13.4) and Exercise 13.2.1).
Show that dP (P, Q) ≤√dW(P, Q) for all P, Q ∈M1(E). If E has a ﬁnite
diameter diam(E), then dW(P, Q) ≤(diam(E) + 1)dP (P, Q) for all P, Q ∈
M1(E). ♣

18.3
Markov Chain Monte Carlo Method
445
Exercise 18.2.2 Consider the bivariate process (X, Y) that was constructed from ˜X
and ˜Y in Example 18.6. Show that (X, Y) is a coupling with transition matrix ¯p. ♣
Exercise 18.2.3 Let X be an arbitrary aperiodic irreducible recurrent random walk
on Zd. Show that, for any two starting points, the independent coalescent coupling
is successful.
Hint: Show that the difference of two independent recurrent random walks is a
recurrent random walk. ♣
Exercise 18.2.4 Let X be a Markov chain on Z2 with transition matrix
p((x1, x2), (y1, y2)) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
1
4,
if x1 = 0, ∥y −x∥2 = 1,
1
4,
if x1 ̸= 0 and y1 = x1 ± 1, x2 = y2,
1
2,
if x1 ̸= 0 and y1 = x1, x2 = y2,
0,
else.
Intuitively, this is the symmetric simple random walk whose vertical transitions are
all blocked away from the vertical axis. Show that X is null recurrent, irreducible
and aperiodic and that independent coalescence does not give a successful coupling.
♣
18.3
Markov Chain Monte Carlo Method
Let E be a ﬁnite set and let π ∈M1(E) with π(x) := π({x}) > 0 for every x ∈E.
We consider the problem of sampling a random variable Y with distribution π on a
computer. For example, this is a relevant problem if E is a very large set and if sums
of the type 
x∈E f (x)π(x) have to be approximated numerically by the estimator
n−1 n
i=1 f (Yi) (see Example 5.21).
Assume that our computer has a random number generator that provides
realizations of i.i.d. random variables U1, U2, . . . that are uniformly distributed on
[0, 1]. In order for the problem to be interesting, assume also that the distribution π
cannot be constructed directly too easily.
Metropolis Algorithm
We have seen already in Example 17.19 how to simulate a Markov chain on a
computer. Now the idea is to construct a Markov chain X whose distribution
converges to π in the long run. If we simulate such a chain and let it run long enough
this should give a sample that is distributed approximately like π. The chain should
be designed so that at each step, only a small number of transitions are possible

446
18
Convergence of Markov Chains
in order to ensure that the procedure described in Example 17.19 works efﬁciently.
(Of course, the chain with transition matrix p(x, y) = π(y) converges to π, but
this does not help a lot.) This method of producing (approximately) π-distributed
samples and using them to estimate expected values of functions of interest is called
the Markov chain Monte Carlo method or, brieﬂy, MCMC (see [15, 112, 119]).
Let q be the transition matrix of an arbitrary irreducible Markov chain on E (with
q(x, y) = 0 for most y ∈E). We use this to construct the Metropolis matrix (see
[70, 114]).
Deﬁnition 18.14 Deﬁne a stochastic matrix p on E by
p(x, y) =
⎧
⎪⎨
⎪⎩
q(x, y) min

1, π(y)q(y,x)
π(x)q(x,y)

,
if x ̸= y, q(x, y) > 0,
0,
if x ̸= y, q(x, y) = 0,
1 −
z̸=x p(x, z),
if x = y.
p is called the Metropolis matrix of q and π.
Note that p is reversible (see Sect. 19.2); that is, for all x, y ∈E, we have
π(x) p(x, y) = π(y) p(y, x).
(18.8)
In particular, π is invariant (check this!). We thus obtain the following theorem.
Theorem 18.15 Assume that q is irreducible and that for any x, y ∈E, we have
q(x, y) > 0 if and only if q(y, x) > 0. Then the Metropolis matrix p of q and π is
irreducible with unique invariant distribution π. If, in addition, q is aperiodic, or q
is not reversible with respect to π, then p is aperiodic.
In order to simulate a chain X that converges to π, we take a reference chain with
transition matrix q and use the Metropolis algorithm: If the chain with transition
matrix q proposes a transition from the present state x to state y, then we accept this
proposal with probability
π(y) q(y, x)
π(x) q(x, y) ∧1.
Otherwise the chain X stays at x.
In the deﬁnition of p, the distribution π appears only in terms of the quotients
π(y)/π(x). In many cases of interest, these quotients are easy to compute even
though π(x) and π(y) are not. We illustrate this with an example.
Example 18.16 (Ising model) The Ising model (pronounced like the English word
“easing”) is a thermodynamical (and quantum mechanical) model for ferromag-
netism in crystals. It makes the following assumptions:
•
Atoms are placed at the sites of a lattice Λ (for example, Λ = {0, . . ., N −1}2).

18.3
Markov Chain Monte Carlo Method
447
•
Each atom i ∈Λ has a magnetic spin x(i) ∈{−1, 1} that either points upwards
(x(i) = +1) or downwards (x(i) = −1).
•
Neighboring atoms interact.
•
Due to thermic ﬂuctuations, the state of the system is random and distributed
according to the so-called Boltzmann distribution π on the state space E :=
{−1, 1}Λ. A parameter of this distribution is the inverse temperature β = 1
T ≥0
(with T the absolute temperature).
Deﬁne the local energy that describes the energy level of a single atom at i ∈Λ
as a function H i of the state x of the whole system,
H i(x) = 1
2

j∈Λ: i∼j
1{x(i)̸=x(j)}.
Here i ∼j indicates that i and j are neighbors in Λ (that is, coordinate-wise mod
N, we also speak of periodic boundary conditions). The total energy (or Hamilton
function) of the system in state x is the sum of the individual energies,
H(x) =

i∈Λ
H i(x) =

i∼j
1{x(i)̸=x(j)}.
The Boltzmann distribution π on E := {−1, 1}Λ for the inverse temperature β ≥0
is deﬁned by
π(x) = Z−1
β exp(−βH(x)),
where the partition sum Zβ = 
x∈E
exp(−βH(x)) is the normalising constant such
that π is a probability measure.
Macroscopically, the individual spins cannot be observed but the average mag-
netization can; that is, the modulus of the average of all spins,
mΛ(β) =

x∈E
π(x)

1
#Λ

i∈Λ
x(i)
 .
If we consider a very large system, then we are close to the so-called thermodynamic
limit
m(β) := lim
Λ↑Zd mΛ(β).

448
18
Convergence of Markov Chains
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.84
0.85
0.86
0.87
0.88
0.89
0.9
0.91
0.92
Magnetization
Inverse temperature
Fig. 18.4 Computer simulation of the magnetization curve of the Ising model on a 1000 × 1000
grid. The dashed vertical line indicates the critical inverse temperature.
Using a contour argument, as for percolation (see [127]), one can show that (for
d ≥2) there exists a critical value βc = βc(d) ∈(0, ∞) such that
m(β)
0> 0,
if β > βc,
= 0,
if β < βc.
(18.9)
See Fig. 18.4 for a computer simulation of the curve β →m(β).
For a similar model, the Weiss ferromagnet, we will prove in Example 23.20
the existence of such a phase transition. In the physical literature, Tc := 1/βc is
called the Curie temperature for spontaneous magnetization. This is a material-
dependent constant (chromium bromide (CrBr) 37 Kelvin, nickel 645 K, iron
1017 K, cobalt 1404 K). Below the Curie temperature, these materials are magnetic,
and above it they are not. Below the critical temperature, the magnetization increases
with decreasing temperature. We will see in a computer simulation that the Ising
model displays this critical temperature effect.
If x ∈E, then denote by xi,σ the state in which at site i the spin is changed to
σ ∈{−1, +1}; that is,
xi,σ(j) =

σ,
if j = i,
x(j),
if j ̸= i.

18.3
Markov Chain Monte Carlo Method
449
Furthermore, deﬁne the state xi in which the spin at i is reversed, xi := xi,−x(i). As
reference chain, we choose a chain with transition probabilities
q(x, y) =
 1
#Λ,
if y = xi for some i ∈Λ,
0,
else.
In words, we choose a random site i ∈Λ (uniformly on Λ) and invert the spin at
that site. Clearly, q is irreducible.
The Metropolis algorithm for this chain accepts the proposal of the reference
chain with probability 1 if π(xi) ≥π(x). Otherwise the proposal is accepted only
with probability π(xi)/π(x). However, now
H(xi) −H(x) =

j: j∼i
1{x(j)̸=−x(i)} −

j: j∼i
1{x(j)̸=x(i)}
= −2

j: j∼i

1{x(j)̸=x(i)} −1
2

.
Hence π(xi)/π(x) = exp

−2β 
j∼i

1{x(j)=x(i)} −1
2

, and this expression is
easy to compute as it depends only on the 2d neighboring spins and, in particular,
does not require knowledge of the value of Zβ. We thus obtain the Metropolis
transition matrix
p(x, y)=
⎧
⎪⎪⎨
⎪⎪⎩
1
#Λ

1 ∧exp
'
2β 
j: j∼i
(1{x(j)̸=x(i)}−1
2)
(
, if y = xi for some i ∈Λ,
1 −
i∈Λ p(x, xi), if x = y,
0, else.
For a practical simulation use the computer’s random number generator to produce
independent random variables I1, I2, . . . and U1, U2, . . . with In ∼UΛ and Un ∼
U[0,1]. Then deﬁne
Fn(x) =
⎧
⎨
⎩
xIn,
if Un ≤exp
'
2β 
j: j∼i(1{x(j)̸=x(i)} −1
2)
(
,
x,
else,
and deﬁne the Markov chain (Xn)n∈N by Xn = Fn(Xn−1) for n ∈N. See Figs. 18.5
and 18.6 for computer simulations of equilibrium states and metastable states of the
Ising model. ♦

450
18
Convergence of Markov Chains
Fig. 18.5 Equilibrium states of the Ising model on an 800 × 800 grid (black dot = spin +1). Left
side: below the critical temperature (β > βc); Right side: above the critical temperature.
Fig. 18.6 Ising model (150 × 150 grid) below the critical temperature. Even after a long time, the
computer simulation does not produce the equilibrium state but rather so-called metastable states,
in which the Weiss domains are clearly visible.
Gibbs Sampler
We consider a situation where, as in the above example, a state consists of many
components x = (xi)i∈Λ ∈E and where Λ is a ﬁnite set. As an alternative to the
Metropolis chain, we consider a different procedure to establish a Markov chain
with a given invariant distribution. For the so-called Gibbs sampler or heat bath

18.3
Markov Chain Monte Carlo Method
451
algorithm, the idea is to adapt the state locally to the stationary distribution. If x is
a state and i ∈Λ, then deﬁne
x−i := {y ∈E : y(j) = x(j) for j ̸= i}.
Deﬁnition 18.17 (Gibbs sampler) Let q ∈M1(Λ) with q(i) > 0 for every i ∈Λ.
The transition matrix p on E with
p(x, y) =

qi π(xi,σ)
π(x−i) ,
if y = xi,σ for some i ∈Λ,
0,
else,
is called a Gibbs sampler for the invariant distribution π.
Verbally, each step of the chain with transition matrix p can be described by the
following instructions.
(1) Choose a random coordinate I according to some distribution (qi)i∈Λ.
(2) With probability π(xI,σ)/π(x−I), replace x by xI,σ.
If I = i, then the new state has the distribution L(X|X−i = x−i), where X is
a random variable with distribution π. Note that, for the Gibbs sampler also it is
enough to know the values of the distribution π only up to the normalising constant.
(In a more general framework, the Gibbs sampler and the Metropolis algorithm can
be understood as special cases of one and the same method.) For states x and y that
differ only in the ith coordinate, we have (since x−i = y−i)
π(x) p(x, y) = π(x) qi
π(y)
π(x−i) = π(y) qi
π(x)
π(y−i) = π(y) p(y, x).
Thus the Gibbs sampler is a reversible Markov chain with invariant measure π.
Irreducibility of the Gibbs sampler, however, has to be checked for each case.
Example 18.18 (Ising model) In the Ising model described above, we have x−i =
{xi,−1, xi,+1}. Hence, for i ∈Λ and σ ∈{−1, +1},
π(xi,σx−i) =
π(xi,σ)
π({xi,−1, xi,+1})
=
e−βH(xi,σ )
e−βH(xi,−1) + e−βH(xi,+1)
=

1 + exp
'
β

H(xi,σ) −H(xi,−σ)
(−1
=

1 + exp
'
2β 
j: j∼i(1{x(j)̸=σ} −1
2)
(−1
.

452
18
Convergence of Markov Chains
The Gibbs sampler for the Ising model is thus the Markov chain (Xn)n∈N0 with
values in E = {−1, 1}Λ and with transition matrix
p(x, y)=
⎧
⎨
⎩
1
#Λ

1+exp
'
2β 
j: j∼i
(1{x(j)̸=x(i)}−1
2)
(−1
, if y = xi for some i ∈Λ,
0, otherwise.
♦
Perfect Sampling
The MCMC method as described above is based on hope: We let the chain run for
a long time and hope that its distribution is close to the invariant distribution. Even
if we can compute the speed of convergence (and in many cases, this is not trivial,
we come back to this point in Sect. 18.4), the distribution will never be exactly the
invariant distribution.
Although this ﬂaw might seem inevitable in the MCMC method, it is in fact, at
least theoretically, possible to use a very similar method that allows perfect sampling
according to the invariant distribution π, even if we do not know anything about
the speed of convergence. The idea is simple. Assume that F1, F2, . . . are i.i.d.
random maps E →E with P[F(x) = y] = p(x, y) for all x, y ∈E. We have
seen how to construct the Markov chain X with initial value X0 = x by deﬁning
Xn = Fn ◦Fn−1 ◦· · · ◦F1(x).
Note that F n
1 (x) := F1 ◦. . . ◦Fn(x) D= Fn ◦. . . ◦F1(x). Hence we have
P[F n
1 (x) = y]
n→∞
−→π(y)
for every y.
However, if F n
1 turns out to be a constant map (e.g., F n
1 ≡x∗for some random
x∗), then we will also have F m
1
≡x∗for all m ≥n. If by some clever choice
of the distribution of Fn one can ensure that the stopping time T := inf{n ∈N :
F n
1 is constant} is almost surely ﬁnite (and this is always possible), then we will
have P[F T
1 (x) = y] = π(y) for all x, y ∈E. A simple algorithm for this method is
the following.
(1) Let F ←idE and n ←0.
(2) Let n ←n + 1. Generate Fn and let F ←F ◦Fn.
(3) If F is not a constant map, then go to (2).
(4) Output F(∗).
This method is called coupling from the past and goes back to Propp and Wilson
[138] (see also [55, 56, 92, 137, 139, 171]). David Wilson has nice simulations and
a survey of the current research on his web site http://www.dbwilson.com/. A nice
survey on MCMC methods including coupling from the past is [66].

18.4
Speed of Convergence
453
For a practical implementation, there are two main problems: (1) The full map Fn
has to be generated and has to be composed with F. The computer time needed for
this is at least of the order of the size of the space E. (2) Checking if F is constant
needs computer time of the same order of magnitude. Consequently, the method can
be efﬁciently implemented only if there is more structure. For example, assume that
E is partially ordered with a smallest element 0 and a largest element 1 (like the
Ising model). Further, assume that the maps Fn can be chosen to be almost surely
monotone increasing. In this case, it is enough to compute at each step F(0) and
F(1) since F is constant if the values coincide.
Takeaways In order to draw random samples (approximately) according to a
given distribution, it is sometimes feasible to simulate a suitable Markov chain
that converges to this distribution as its invariant measure. The Metropolis
algorithm constitutes a universal tool for the construction of such a Markov
chain. The Gibbs sampler is a more speciﬁc algorithm often helpful in
statistical mechanics. The technique of coupling from the past allows for
drawing exactly according to the desired distribution.
18.4
Speed of Convergence
So far we have ignored the question of the speed of convergence of the distribution
PXn to π. For practical purposes, however, this is often the most interesting question.
We do not intend to go into the details and we only brieﬂy touch upon the topic.
Without loss of generality, assume E = {1, . . . , N}. If p is reversible (Equation
(18.8)), then f →pf deﬁnes a symmetric linear operator on L2(E, π) (exercise!).
All eigenvalues λ1, . . . , λN (listed according to the corresponding multiplicity) are
real and have modulus at most 1 since p is stochastic. Thus we can arrange the
eigenvalues by decreasing modulus λ1 = 1 ≥|λ2| ≥. . . ≥|λN|. If p is irreducible
and aperiodic, then |λ2| < 1. Let μ1 = π, μ2, . . . , μN be an orthonormal basis
of left eigenvectors for the eigenvalues λ1, . . . , λN. Then, for every probability
measure μ = α1μ1 + . . . + αNμN, we have μpn = N
i=1 λn
i αi μi
n→∞
−→α1π.
Since for each n ∈N, the left hand side is a probability measure, we have α1 = 1
and
∥μpn −π∥T V ≤C|λ2|n
(18.10)
for a constant C (that does not depend on μ). A similar formula holds if p is
not reversible; however, with a correction term of order at most nV −1. Here, V
is the size of the largest Jordan block square matrix for the eigenvalue λ2 in the

454
18
Convergence of Markov Chains
Jordan canonical form of p. In particular, V is no larger than the multiplicity of the
eigenvalue with second largest modulus.
The speed of convergence is thus exponential with a rate that is determined by
the spectral gap 1 −|λ2| of the second largest eigenvalue of p. In practice, for a
large space E, computing the spectral gap is often extremely difﬁcult.
Reﬂection Why have we restricted ourselves to aperiodic Markov chains? What is
λ2 in the periodic case? For example, consider E = {0, . . ., N−1} and the transition
matrix given by p(k, k + 1(mod N)) = 1 for all k. ♠
Example 18.19 Let r ∈(0, 1) and N ∈N, N ≥2. Further, let E = {0, . . . , N −1}.
We consider the transition matrix
p(i, j) =
⎧
⎨
⎩
r,
if j = i + 1 (mod N),
1 −r,
if j = i −1 (mod N),
0,
else.
p is the transition matrix of simple (asymmetric) random walk on the discrete torus
Z/(N), which with probability r makes a jump to the right and with probability
1 −r makes a jump to the left. Clearly, p is irreducible, and p is aperiodic if and
only if N is odd. Furthermore, the uniform distribution UE is the unique invariant
distribution.
Case 1: N odd.
Let θk = e2πi k/N, k = 0, . . . , N −1, be the Nth roots of unity
and let the corresponding (right) eigenvectors be
xk :=

θ0
k , θ1
k , . . . , θN−1
k

.
It is easy to check that p has the eigenvalues
λk := r θk + (1 −r) θk = cos
 2πk
N

+ (2r −1) i sin
 2πk
N

,
k = 0, . . . , N −1.
The moduli of the eigenvalues are given by |λk| = f (2πk/N), where
f (ϑ) =
2
1 −4r(1 −r) sin(ϑ)2
for ϑ ∈R.
Since N is odd, |λk| is maximal (except for k = 0) for k = N−1
2
and for k = N+1
2 .
For these k, |λk| equals γ :=
2
1 −4r(1 −r) sin(π/N)2. Since all eigenvalues
are different, every eigenvalue has multiplicity 1. Hence there is a constant C <
∞such that
∥μpn −UE∥T V ≤C γ n
for all n ∈N, μ ∈M1(E).

18.4
Speed of Convergence
455
Case 2: N even.
In this case, p is not aperiodic. Nevertheless, the eigenvalues
and eigenvectors are of the same form as in Case 1. In order to get an aperiodic
chain, for ε > 0, deﬁne the transition matrix
pε := (1 −ε)p + εI,
where I is the unit matrix on E. pε describes the random walk on E that with
probability ε does not move and with probability 1 −ε makes a jump according
to p. Clearly, pε is irreducible and aperiodic. The eigenvalues are
λε,k = (1 −ε)λk + ε,
k = 0, . . . , N −1,
and the corresponding eigenvectors are the xk from above. Evidently, λε,0 = 1,
and if ε > 0 is very small, then λε,N/2 = 2ε −1 is the eigenvalue with the
second largest modulus. For larger values of ε, we have |λε,1| > |λε,N/2|. More
precisely, if we let
ε0 :=
(1 −(2r −1)2) sin(2π/N)2
(1 −(2r −1)2) sin(2π/N)2 + 2 cos(2π/N),
then the eigenvalue with the second largest modulus has modulus
γε = |λε,N/2| = 1 −2ε,
if ε ≤ε0,
or
γε = |λε,1|
=
K
(1 −ε) cos

2π
N

+ ε
2
+

(1 −ε)(2r −1) sin

2π
N
2
,
if ε ≥ε0.
It is easy to check that ε →|λε,N/2| is monotone decreasing and that ε →|λε,1|
is monotone increasing. Hence γε is minimal for ε = ε0.
Hence there is a C < ∞with
∥μpn
ε −UE∥T V ≤C γ n
ε
for all n ∈N, μ ∈M1(E),
and the best speed of convergence (in this class of transition matrices) can be
obtained by choosing ε = ε0. ♦

456
18
Convergence of Markov Chains
Example 18.20 (Gambler’s ruin) We consider the gambler’s ruin problem from
Example 10.19 with the probability of a gain r ∈(0, 1). Here the state space is
E = {0, . . ., N}, and the transition matrix is of the form
p(i, j) =
⎧
⎪⎪⎨
⎪⎪⎩
r,
if j = i + 1 ∈{2, . . ., N},
1 −r,
if j = i −1 ∈{0, . . ., N −2},
1,
if j = i ∈{0, N},
0,
else.
This transition matrix is not irreducible; rather it has two absorbing states 0 and N.
In Example 10.19 (Equation (10.7)) for the case r ̸= 1
2, and Example 10.16 for the
case r = 1
2, it was shown that, for every μ ∈M1(E),
μpn n→∞
−→(1 −m(μ))δ0 + m(μ)δN.
(18.11)
Here m(μ) = 3 pN(x) μ(dx), where the probability pN(x) that the chain, if started
at x, hits N is given by
pN(x) =
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
1 −

1−r
r
x
1 −

1−r
r
N ,
if r ̸= 1
2,
x
N ,
if r = 1
2.
How quick is the convergencein (18.11)? Here also the convergencehas exponential
speed and the rate is determined by the second largest eigenvalue of p.
Hence we have to compute the spectrum of p. Clearly, x0 = (1, 0, . . . , 0) and
xN = (0, . . . , 0, 1) are left eigenvectors for the eigenvalue 1. In order for x =
(x0, . . . , xN) to be a left eigenvector for the eigenvalue λ, the following equations
have to hold:
λxk = rxk−1 + (1 −r)xk+1
for k = 2, . . ., N −2,
(18.12)
and
λxN−1 = rxN−2.
(18.13)
If (18.12) and (18.13) hold for x1, . . . , xN−1, then we deﬁne x0 :=
1−r
λ−1x1 and
xN :=
r
λ−1xN−1 and get that in fact xr = λx. We make the ansatz
λ = (1 −r)ρ(θ + θ) and xk = ρk(θk −θk)
for k = 1, . . . , N −1,

18.4
Speed of Convergence
457
where
ρ =
2
r/(1 −r) and θ ∈C \ {−1, +1} with |θ| = 1.
Thus we have θθ = 1 and (1 −r)ρk+1 = rρk−1. Therefore, for every k =
2, . . . , N −1,
λxk = (1 −r) ρk+1(θk −θk)(θ + θ)
= (1 −r) ρk+1)
(θk+1 −θk+1) + θθ (θk−1 −θk−1)
*
= r ρk−1(θk−1 −θk−1) + (1 −r) ρk+1(θk+1 −θk+1)
= r xk−1 + (1 −r) xk+1.
That is, (18.12) holds. The same computation with k = N −1 shows that (18.13)
holds if and only if θN −θN = 0; that is, if θ2N = 1. In all, then, for θ, we get
N −1 different values (note that the complex conjugates of the values considered
here lead to the same values λn),
θn = e(n/N)π i
for n = 1, . . . , N −1.
The corresponding eigenvalues are
λn = σ cos
n π
N

for n = 1, . . ., N −1.
Here the variance of the individual random walk step is
σ 2 := 4r(1 −r).
(18.14)
As all eigenvalues are real, the corresponding eigenvectors are given by
xn
k = 2

r
1 −r
n/2
sin
n π
N

,
k = 1, . . . , N −1.
The second largest modulus of an eigenvalue is |λn| = σ cos  π
N
 if n = 1 or
n = N −1. Thus there exists a C > 0 such that, for every μ ∈M1(E), we have
μpn({1, . . . , N −1}) ≤C

σ cos
 π
N
n
for every n ∈N.
In other words, the probability that the game has not ﬁnished up to the nth round is
at most C

σ cos(π/N)
n.

458
18
Convergence of Markov Chains
An alternative approach to the eigenvalues can be made via the roots of the
characteristic polynomial
χN(x) = det(p −xI),
x ∈R.
Clearly, χ1(x) = (1 −x)2 and χ2(x) = −x(1 −x)2. Using Laplace’s expansion
formula for the determinant (elimination of rows and columns), we get the recursion
χN(x) = −x χN−1(x) −r(1 −r) χN−2(x).
(18.15)
The solution is (check this!)
χN(x) = (−1)N−1 (σ/2)N−1 (1 −x)2 UN−1

x/σ

,
(18.16)
where
Um(x) :=
⌊m/2⌋

k=0
(−1)k
m −k
k

(2x)m−2k
denotes the so-called mth Chebyshev polynomial of the second kind.
Using de Moivre’s formula, one can show that, for x ∈(−σ, σ),
χN(x) = (−1)N−1 (σ/2)N−1 (1 −x)2 sin

N arccos

x/σ

2
1 −(x/σ)2
= (1 −x)2
N−1

k=1

σ cos
πk
N

−x

.
(18.17)
Apart from the double zero at 1, we get the zeros
σ cos πk/N),
k = 1, . . . , N −1.
♦
Takeaways The speed at which a Markov chain converges towards its
invariant distribution is determined by the spectral gap of its transition matrix.
For two examples we could compute the spectral gap explicitly.
Exercise 18.4.1 Show (18.16). ♣
Exercise 18.4.2 Show (18.17). ♣

18.4
Speed of Convergence
459
Exercise 18.4.3 Let ν(dx) = 2
π
√
1 −x2 1[−1,1](x) dx. Show that the Chebyshev
polynomials of the second kind are orthonormal with respect to ν; that is,

UmUn dν = 1{m=n}.
♣
Exercise 18.4.4 Let E = {1, 2, 3} and
p =
⎛
⎜⎝
1/2 1/3 1/6
1/3 1/3 1/3
0 3/4 1/4
⎞
⎟⎠. Compute the
invariant distribution and the exponential rate of convergence. ♣
Exercise 18.4.5 Let E = {0, . . . , N −1}, r ∈(0, 1) and
p(i, j) =
⎧
⎨
⎩
r,
if j = i + 1 (mod N),
1 −r,
if j = i (mod N),
0,
else.
Show that p is the transition matrix of an irreducible, aperiodic random walk and
compute the invariant distribution and the exponential rate of convergence. ♣
Exercise 18.4.6 Let N ∈N and let E = {0, 1}N denote the N-dimensional
hypercube. That is, two points x, y ∈E are connected by an edge if they differ
in exactly one coordinate. Let p be the transition matrix of the random walk on E
that stays put with probability ε > 0 and that with probability 1 −ε makes a jump
to a randomly (uniformly) chosen neighboring site.
Describe p formally and show that p is aperiodic and irreducible. Compute the
invariant distribution and the exponential rate of convergence. ♣

Chapter 19
Markov Chains and Electrical Networks
We consider symmetric simple random walk on Z2. By Pólya’s theorem (Theo-
rem 17.40), this random walk is recurrent. However, is this still true if we remove a
single edge from the lattice L2 of Z2? Intuitively, such a small local change should
not make a difference for a global phenomenon such as recurrence. However, the
computations used in Sect. 17.5 to prove recurrence are not very robust and would
need a substantial improvement in order to cope with even a small change. The
situation becomes even more puzzling if we restrict the random walk to, e.g., the
upper half plane {(x, y) : x ∈Z, y ∈N0} of Z2. Is this random walk recurrent?
Or consider bond percolation on Z2. Fix a parameter p ∈[0, 1] and independently
declare any edge of L2 open with probability p and closed with probability 1 −p.
At a second stage, start a random walk on the random subgraph of open edges. At
each step, the walker chooses one of the adjacent open edges at random (with equal
probability) and traverses it. For p > 1
2, there exists a unique inﬁnite connected
component of open edges (Theorem 2.47). The question that we answer at the end
of this chapter is: Is a random walk on the inﬁnite open cluster recurrent or transient?
The aim of this chapter is to establish a connection between certain Markov
chains and electrical networks. This connection
•
in some cases allows us to distinguish between recurrence and transience by
means of easily computable quantities, and
•
in other cases provides a comparison criterion that says that if a random walk on
a graph is recurrent, then a random walk on any connected subgraph is recurrent.
Any of the questions raised above can be answered using this comparison
technique.
Some of the material of this chapter is taken from [110] and [36].
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_19
461

462
19
Markov Chains and Electrical Networks
19.1
Harmonic Functions
In this chapter, E is always a countable set and X is a discrete Markov chain on E
with transition matrix p and Green function G. Recall that F(x, y) is the probability
of hitting y at least once when starting at x. Compare Sect. 17.4, in particular,
Deﬁnitions 17.29 and 17.34.
Deﬁnition 19.1 Let A ⊂E. A function f : E →R is called harmonic on E \ A if
pf (x) = 
y∈E p(x, y)f (y) exists and if pf (x) = f (x) for all x ∈E \ A.
Theorem 19.2 (Superposition principle) Assume f and g are harmonic on E \A
and let α, β ∈R. Then αf + βg is also harmonic on E \ A.
Proof This is trivial.
⊓⊔
Example 19.3 Let X be transient and let a ∈E be a transient state (that is, a is not
absorbing). Then f (x) := G(x, a) is harmonic on E \ {a}: For x ̸= a, we have
pf (x) = p
∞

n=0
pn(x, a) =
∞

n=1
pn(x, a) = G(x, a) −1{a}(x) = G(x, a).
♦
Example 19.4 For x ∈E, let τx := inf{n > 0 : Xn = x}. For A ⊂E, let
τ := τA := inf
x∈A τx
be the stopping time of the ﬁrst entrance to A. Assume that A is chosen so that
Px[τA < ∞] = 1 for every x ∈E. Let g : A →R be a bounded function. Deﬁne
f (x) :=

g(x),
if x ∈A,
Ex[g(Xτ )],
if x ∈E \ A.
(19.1)
Then f is harmonic on E \ A. We give two proofs for this statement.
1. Proof.
By the Markov property, for x ̸∈A and y ∈E,
Ex
)
g(Xτ)
X1 = y
*
=

g(y),
if y ∈A
Ey[g(Xτ )],
if y ∈E \ A

= f (y).
Hence, for x ∈E \ A,
f (x) = Ex[g(Xτ)] =

y∈E
Ex
)
g(Xτ); X1 = y
*
=

y∈E
p(x, y) Ex
)
g(Xτ)
X1 = y
*
=

y∈E
p(x, y) f (y) = pf (x).

19.1
Harmonic Functions
463
2. Proof.
We change the Markov chain by adjoining a cemetery state Δ. That is,
the new state space is ˜E = E ∪{Δ} and the transition matrix is
˜p(x, y) =
⎧
⎪⎪⎨
⎪⎪⎩
p(x, y),
if x ∈E \ A, y ̸= Δ,
0,
if x ∈E \ A, y = Δ,
1,
if x ∈A ∪{Δ}, y = Δ.
(19.2)
The corresponding Markov chain ˜X is transient, and Δ is the only absorbing state.
Furthermore, we have pf = f on E \ A if and only if ˜pf = f on E \ A. Since
˜G(y, y) = 1 for all y ∈A, we have (compare Theorem 17.35)
Px[Xτ = y] = Px[˜τy < ∞] = ˜F(x, y) = ˜G(x, y)
for all x ∈E \ A, y ∈A.
Now x →˜G(x, y) is harmonic on E \ A. Hence, by the superposition principle,
f (x) =

y∈A
˜G(x, y) g(y)
(19.3)
is harmonic on E \A. Due to the analogy of (19.3) to Green’s formula in continuous
space potential theory, the function ˜G is called the Green function for the equation
(p −I)f = 0 on E \ A. ♦
Deﬁnition 19.5 The system of equations
(p −I)f (x) = 0,
for x ∈E \ A,
f (x) = g(x),
for x ∈A,
(19.4)
is called the Dirichlet problem on E \ A with respect to p −I and with boundary
value g on A.
We have shown the existence of solutions of the Dirichlet problem in Exam-
ple 19.4. In order to show uniqueness (under certain conditions) we ﬁrst derive the
maximum principle for harmonic functions.
If p = I then any function f that coincides with g on A is a solution of the
Dirichlet problem. However, even in less extreme situations the solution of (19.4)
may be ambiguous. This is the case if E \ A decomposes into domains between
which the chain that is stopped in A cannot change.
In order to describe formally the irreducibility condition that we have to impose,
we introduce the transition matrix pA of the chain stopped upon reaching A by
pA(x, y) :=
0 p(x, y),
if x ̸∈A,
1{x=y},
if x ∈A.

464
19
Markov Chains and Electrical Networks
Further, deﬁne FA for pA similarly as F was deﬁned for p. Finally, for x ∈E let
Sn
A(x) =
	
y ∈E : (pA)n(x, y) > 0

,
for n ∈N0
and
SA(x) =
∞

n=0
Sn
A(x) = 	y ∈E : FA(x, y) > 0
.
Theorem 19.6 (Maximum principle) Let f be a harmonic function on E \ A.
(i) If there exists an x0 ∈E \ A such that
f (x0) = sup f (SA(x0)),
(19.5)
then f (y) = f (x0) for any y ∈SA(x0).
(ii) In particular, if FA(x, y) > 0 for all x, y ∈E \ A, and if there is an x0 ∈E \ A
such that f (x0) = sup f (E), then f (x0) = f (y) for any y ∈E \ A.
Proof
(i) Let m := sup f (SA(x0)). As f is harmonic on E \ A, we have pAf = f on E.
Hence, for any n ∈N,
f (x0) = (pA)nf (x0) =

y∈Sn
A(x0)
pn
A(x0, y)f (y) ≤m
with equality if and only if f (y) = m for all y ∈Sn
A(x0). Since (19.5) implies
equality, we infer f (x0) = f (y) for all y ∈SA(x0).
(ii) This is a direct consequence of (i) since SA(x) ⊃E \ A for any x ∈E \ A. ⊓⊔
Theorem 19.7 (Uniqueness of harmonic functions) Assume that F(x, y) > 0 for
all x, y ∈E. Let A ⊂E be such that A ̸= ∅and E \ A is ﬁnite. Assume that f1 and
f2 are harmonic on E \ A. If f1 = f2 on A, then f1 = f2.
In other words, the Dirichlet problem (19.4) has a unique solution given by (19.3)
(or equivalently by (19.1)).
Proof By the superposition principle, f := f1 −f2 is harmonic on E \ A with
f 
A ≡0.
We will show f ≤0. Then, by symmetry, also f ≥0 and hence f ≡0. To
this end, we assume that there exists an x ∈E such that f (x) > 0 and deduce a
contradiction.
Since f 
A ≡0 and since E \ A is ﬁnite, there is an x0 ∈E \ A such that
f (x0) = max f (E) ≥f (x) > 0.

19.2
Reversible Markov Chains
465
Since F(x, y) > 0 for all x, y ∈E, we have
n0 := min
	
n ∈N0 : pn(x0, y) > 0 for some y ∈A

< ∞.
Clearly, we have pn0(x0, y) = (pA)n0(x0, y) for all y ∈A. Hence, there exists a
y ∈A such that (pA)n0(x0, y) > 0, i.e., y ∈SA(x0). By Theorem 19.6, this implies
f (x0) = f (y) = 0 contradicting the assumption.
⊓⊔
Takeaways Let E be countable and let p be a stochastic matrix on E. Let
A ⊂E. A function f is called harmonic on G := E \ A if (p −I)f = 0
holds on G. If the values of f on A are prescribed, then we say that f solves a
Dirichlet problem. If p is irreducible on G and f is not constant, then f does
not assume its maximum in G. As a consequence, we get uniqueness of the
solution of the Dirichlet problem.
Exercise 19.1.1 Let p be the substochastic E×E matrix that is given by p(x, y) =
˜p(x, y), x, y ∈E (with ˜p as in (19.2)). Hence p(x, y) = p(x, y) 1x∈E\A. Let I be
the unit matrix on E.
(i) Show that I −p is invertible.
(ii) Deﬁne G := (I −p)−1. Show that G(x, y) = ˜G(x, y) for all x, y ∈E \ A and
that G(x, y) = 1{x=y} if x ∈A. In particular,
G(x, y) = Px[XτA = y]
for x ∈E \ A and y ∈A.
♣
19.2
Reversible Markov Chains
Deﬁnition 19.8 The Markov chain X is called reversible with respect to the
measure π if
π({x}) p(x, y) = π({y}) p(y, x)
for all x, y ∈E.
(19.6)
Equation (19.6) is sometimes called the equation of detailed balance. X is called
reversible if there is a π with respect to which X is reversible.
Remark 19.9 If X is reversible with respect to π, then π is an invariant measure
for X since
π p({x}) =

y∈E
π({y}) p(y, x) =

y∈E
π({x}) p(x, y) = π({x}).

466
19
Markov Chains and Electrical Networks
If X is irreducible and recurrent, then, by Remark 17.51, π is thus unique up to
constant multiples. ♦
Reﬂection Let X = (Xn)n∈Z be a reversible Markov chain (with transition matrix
p) with respect to π and assume that PX0 = π. Check that X′
n := X−n, n ∈Z, is
also a Markov chain with transition matrix p. This justiﬁes the term reversible. ♠
Example 19.10 Let (E, K) be a graph with vertex set (or set of nodes) E and with
edge set K (see page 73). By ⟨x, y⟩= ⟨y, x⟩∈K, denote an (undirected) edge
that connects x with y. Let C := (C(x, y), x, y ∈E) be a family of weights with
C(x, y) = C(y, x) ≥0 for all x, y ∈E and
C(x) :=

y∈E
C(x, y) < ∞
for all x ∈E.
If we deﬁne p(x, y) := C(x,y)
C(x) for all x, y ∈E, then X is reversible with respect to
π({x}) = C(x). In fact,
π({x}) p(x, y) = C(x) C(x, y)
C(x)
= C(x, y)
= C(y, x) = C(y) C(y, x)
C(y)
= π({y}) p(y, x).
♦
(19.7)
Deﬁnition 19.11 Let (E, K), C and X be as in Example 19.10. Then X is called a
random walk on E with weights C. In particular, if C(x, y) = 1{⟨x,y⟩∈K}, then X is
called a simple random walk on (E, K).
Thus the random walk with weights C is reversible. However, the converse is also
true.
Theorem 19.12 If X is a reversible Markov chain and if π is an invariant
measure, then X is a random walk on E with weights C(x, y) = p(x, y) π({x}). If
X is irreducible and recurrent, then π and hence C are unique up to a factor.
Proof This is obvious.
⊓⊔
Takeaways A reversible Markov chain is stationary and fulﬁlls an even
stronger equilibrium condition: The condition of detailed balance says that
on average the Markov chain jumps from x to y as often as it jumps from y to
x (for all x and y).
Exercise 19.2.1 Show that p is reversible with respect to π if and only if the linear
map L2(π) →L2(π), f →pf is self-adjoint. ♣

19.3
Finite Electrical Networks
467
Exercise 19.2.2 Let β > 0, K ∈N and W1, . . . , WK ∈R. Deﬁne
p(i, j) := 1
Z exp(−βWj)
for all i, j = 1, . . . , K,
where Z := K
j=1 exp(−βWj) is the normalising constant.
Assume that in K (enumerated) urns there are a total of N indistinguishable balls.
At each step, choose one of the N balls uniformly at random. If i is the number of
the urn from which the ball is drawn, then with probability p(i, j) move the ball to
the urn with number j.
(i) Give a formal description of this process as a Markov chain.
(ii) Determine the invariant distribution π and show that the chain is reversible with
respect to π. ♣
19.3
Finite Electrical Networks
An electrical network (E, C) consists of a set E of sites (the electrical contacts) and
wires between pairs of sites. The conductance of the wire that connects the points
x ∈E and y ∈E \ {x} is denoted by C(x, y) ∈[0, ∞). If C(x, y) = 0, then we
could just as well assume that there is no wire connecting x and y. By symmetry,
we have C(x, y) = C(y, x) for all x and y. Denote by
R(x, y) =
1
C(x, y) ∈(0, ∞]
the resistance of the connection ⟨x, y⟩. A particular case is that of a graph (E, K)
where all edges have the same conductance, say 1; that is, C(x, y) = 1{⟨x,y⟩∈K}.
The corresponding network (E, C) will be called the unit network on (E, K).
In the remainder of this section, assume that (E, C) is a ﬁnite electrical network.
Now let A ⊂E. At the points x0 ∈A, we apply the voltages u(x0) (e.g., using
batteries). What is the voltage u(x) at x ∈E \ A?
Deﬁnition 19.13 A map I : E × E →R is called a ﬂow on E \ A if it is
antisymmetric (that is, I(x, y) = −I(y, x)) and if it obeys Kirchhoff’s rule:
I(x) = 0,
for x ∈E \ A,
I(A) = 0.
(19.8)
Here we denoted
I(x) :=

y∈E
I(x, y)
and
I(A) :=

x∈A
I(x).

468
19
Markov Chains and Electrical Networks
Deﬁnition 19.14 A ﬂow I : E × E →R on E \ A is called a current ﬂow if there
exists a function u : E →R with respect to which Ohm’s rule is fulﬁlled:
I(x, y) = u(x) −u(y)
R(x, y)
for all x, y ∈E, x ̸= y.
In this case, I(x, y) is called the ﬂow from x to y and u(x) is called the electrical
potential (or voltage) at x.
Reﬂection Give an example of a current that is not an electrical current. ♠
Theorem 19.15 An electrical potential u in (E, C) is a harmonic function on
E \ A:
u(x) =

y∈E
1
C(x) C(x, y) u(y)
for all x ∈E \ A.
In particular, if the network is irreducible, an electrical potential is uniquely
determined by the values on A.
Proof By Ohm’s rule and Kirchhoff’s rule,
u(x) −

y∈E
C(x, y)
C(x) u(y) =

y∈E
C(x, y)
C(x) (u(x) −u(y)) =
1
C(x)

y∈E
I(x, y) = 0.
Hence u is harmonic for the stochastic matrix p(x, y) = C(x, y)/C(x). The claim
follows by the uniqueness theorem for harmonic functions (Theorem 19.7).
⊓⊔
Corollary 19.16 Let X be a Markov chain on E with edge weights C. Then u(x) =
Ex[u(XτA)].
Assume A = {x0, x1} where x0 ̸= x1, and u(x0) = 0, u(x1) = 1. Then I(x1)
is the total ﬂow into the network and −I(x0) is the total ﬂow out of the network.
Kirchhoff’s rule says that the ﬂow is divergence-free and that the ﬂows into and out
of the network are equal. In other words, the net ﬂow is I(x0) + I(x1) = 0.
Recall that, by Ohm’s rule, the resistance of a wire is the quotient of the potential
difference and the current ﬂow. Hence we deﬁne the effective resistance between x0
and x1 as
Reff(x0 ↔x1) = u(x1) −u(x0)
I(x1)
=
1
I(x1) = −
1
I(x0).
Correspondingly, the effective conductance is Ceff(x0 ↔x1) = Reff(x0 ↔x1)−1.
As I and u are uniquely determined by x0, x1 and C, the quantities Ceff(x0 ↔x1)
and Reff(x0 ↔x1) are well-deﬁned and can be computed from C.
Consider now two sets A0, A1 ⊂E with A0 ∩A1 = ∅, A0, A1 ̸= ∅. Deﬁne
u(x) = 0 for every x ∈A0 and u(x) = 1 for every x ∈A1. Let I be the

19.3
Finite Electrical Networks
469
corresponding current ﬂow. In a manner similar to the above, we make the following
deﬁnition.
Deﬁnition 19.17 We call Ceff(A0 ↔A1) := I(A1) the effective conductance
between A0 and A1 and Reff(A0 ↔A1) :=
1
I(A1) the effective resistance between
A0 and A1.
Example 19.18
(i) Let E = {0, 1, 2} with C(0, 2) = 0, and A0 = {x0} = {0}, A1 = {x1} = {2}.
Deﬁne u(0) = 0 and u(2) = 1. Then (with p(x, y) = C(x, y)/C(x)),
u(1) = 1 · p(1, 2) + 0 · p(1, 0) =
C(1, 2)
C(1, 2) + C(1, 0) =
R(1, 0)
R(1, 0) + R(1, 2)
=
Reff(1 ↔0)
Reff(1 ↔0) + Reff(1 ↔2).
The total current ﬂow is
I({2}) = u(1) C(0, 1) =
1
R(0, 1) + R(1, 2) =
1
1
C(0,1) +
1
C(1,2)
.
Hence we have Reff(0 ↔2) =
1
I({2}) = R(0, 1) + R(1, 2) and Ceff(0 ↔2) =

C(0, 1)−1 + C(1, 2)−1−1.
(ii) (Series connection (see Fig.19.1))
Let n ∈N, n ≥2 and E = {0, . . ., n}
with conductances C(k −1, k) > 0 and C(k, l) = 0 if |k −l| > 1. By
Kirchhoff’s rule, we have I(l, l + 1) = −I(x1) for any l = 0, . . . , n −1. By
Ohm’s rule, we get u(1) = u(0) + I(x1) R(0, 1), u(2) = u(1) + I(x1) R(1, 2)
u(0) = 0
u(6) = 1
x1 = 6
x0 = 1
C(5, 6)
C(0, 1)
C(1, 2)
Fig. 19.1 Series connection of six resistors. The effective resistance is Reff(0 ↔6) = R(0, 1) +
. . . + R(5, 6).

470
19
Markov Chains and Electrical Networks
and so on, yielding
u(k) −u(0) = I(x1)
k−1

l=0
R(l, l + 1).
Hence
Reff(0 ↔k) = u(k) −u(0)
I(x1)
=
k−1

l=0
R(l, l + 1).
By symmetry, we also have
Reff(k ↔n) =
n−1

l=k
R(l, l + 1)
and thus Reff(0 ↔n) = Reff(0 ↔k) + Reff(k ↔n).
Finally, for k ∈{1, . . ., n −1}, we get
u(k) =
Reff(0 ↔k)
Reff(0 ↔k) + Reff(k ↔n).
Note that this yields the ruin probability of the corresponding Markov chain X
on {0, . . ., n},
Pk[τn < τ0] = u(k) = Reff(0 ↔k)
Reff(0 ↔n) =
k−1

l=0
R(l, l + 1)
N n−1

l=0
R(l, l + 1).
(19.9)
(iii) (Parallel connection (see Fig.19.2))
Let E = {0, 1}. We extend the model
a little by allowing for more than one wire to connect 0 and 1. Denote the
conductances of these wires by C1, . . . , Cn. Then, by Ohm’s rule, the current
ﬂow along the ith wire is Ii =
u(1)−u(0)
Ri
=
1
Ri . Hence the total current is
I = n
i=1
1
Ri and thus we have
Ceff(0 ↔1) =
n

i=1
Ci
and
Reff(0 ↔1) =
 n

i=1
1
Ri
−1
.
♦
In each of the three preceding examples, the effective resistance is a monotone
function of the individual resistances. This is more than just coincidence.
Theorem 19.19 (Rayleigh’s monotonicity principle) Let (E, C) and (E, C′) be
electrical networks with C(x, y) ≥C′(x, y) for all x, y ∈E.
Then, for A0, A1 ⊂E with A0, A1 ̸= ∅and A0 ∩A1 = ∅,

19.3
Finite Electrical Networks
471
u(0) = 0
u(6) = 1
x1 = 6
x0 = 1
R1
R2
R3
R4
R5
R6
Fig. 19.2 Parallel connection of six resistors. The effective resistance is Reff(0 ↔1) = (R−1
1
+
. . . + R−1
6 )−1.
Ceff(A0 ↔A1) ≥C′
eff(A0 ↔A1).
The remainder of this section is devoted to the proof of this theorem. We will
need a theorem on conservation of energy and Thomson’s principle (also called
Dirichlet’s principle) on the minimization of the energy dissipation.
Theorem 19.20 (Conservation of energy) Let A = A0∪A1, and let I be a ﬂow on
E \ A (but not necessarily a current ﬂow; that is, Kirchhoff’s rule holds but Ohm’s
rule need not). Further, let w : E →R be a function that is constant both on A0
and on A1: w
A0 ≡: w0 and w
A1 ≡: w1. Then
(w1 −w0)I(A1) = 1
2

x,y∈E
(w(x) −w(y)) I(x, y).
Note that this is a discrete version of Gauß’s integral theorem for (wI). In fact,
Kirchhoff’s rule says that I is divergence-free on E \ A.
Proof We compute

x,y∈E
(w(x) −w(y))I(x, y) =

x∈E

w(x)

y∈E
I(x, y)

−

y∈E

w(y)

x∈E
I(x, y)

=

x∈A

w(x)

y∈E
I(x, y)

−

y∈A

w(y)

x∈E
I(x, y)

= w0I(A0)+w1I(A1)−w0(−I(A0))−w1(−I(A1))
= 2(w1 −w0)I(A1).
⊓⊔

472
19
Markov Chains and Electrical Networks
Deﬁnition 19.21 Let I be a ﬂow on E \ A. Denote by
LI := LC
I := 1
2

x,y∈E
I(x, y)2 R(x, y)
the energy dissipation of I in the network (E, C).
Theorem 19.22 (Thomson’s (or Dirichlet’s) principle of minimization of energy
dissipation) Let I and J be unit ﬂows from A1 to A0 (that is, I(A1) = J(A1) = 1).
Assume in addition that I is a current ﬂow (that is, it satisﬁes Ohm’s rule with some
potential u that is constant both on A0 and on A1). Then
LI ≤LJ
with equality if and only if I = J. In particular, the unit current ﬂow is uniquely
determined.
Proof Let D = J −I ̸≡0 be the difference of the ﬂows. Then clearly D(A0) =
D(A1) = 0. We infer

x,y∈E
J(x, y)2 R(x, y)
=

x,y∈E

I(x, y) + D(x, y)
2R(x, y)
=

x,y∈E

I(x, y)2 + D(x, y)2
R(x, y) + 2

x,y∈E
I(x, y) D(x, y) R(x, y)
=

x,y∈E

I(x, y)2 + D(x, y)2
R(x, y) + 2

x,y∈E

u(x) −u(y)

D(x, y).
By the principle of conservation of energy, the last term equals
2

x,y∈E

u(x) −u(y)

D(x, y) = 4D(A1)(u1 −u0) = 0.
Therefore (since D ̸≡0),
LJ = LI + 1
2

x,y∈E
D(x, y)2 R(x, y) > LI.
⊓⊔
Proof (Rayleigh’s monotonicity principle, Theorem 19.19) Let I and I ′ be the unit
current ﬂows from A1 to A0 with respect to C and C′, respectively. By Thomson’s

19.4
Recurrence and Transience
473
principle, the principle of conservation of energy and the assumption R(x, y) ≤
R′(x, y) for all x, y ∈E, we have
Reff(A0 ↔A1) = u(1) −u(0)
I(A1)
= u(1) −u(0)
= 1
2

x,y∈E
I(x, y)2 R(x, y)
≤1
2

x,y∈E
I ′(x, y)2 R(x, y) ≤1
2

x,y∈E
I ′(x, y)2 R′(x, y)
= u′(1) −u′(0) = R′
eff(A0 ↔A1).
⊓⊔
Takeaways Let us imagine the edges of some graph as resistors in an
electrical network. We can compute the effective resistances in parallel and
serial connections. The electrical current between two contacts (vertices in
the graph) minimises the electrical power among all unit currents. We use
this to infer uniqueness of the electrical current. As a consequence we get
a formal proof for the intuitive fact that increasing the resistance along an
individual bond (or even removing the bond which is the same as increasing
the resistance to inﬁnity) increases the effective resistance between any two
given points.
19.4
Recurrence and Transience
We consider the situation where E is countable and A1 = {x1} for some x1 ∈E.
Let X be a random walk on E with weights C = (C(x, y), x, y ∈E) and hence
with transition probabilities p(x, y) = C(x, y)/C(x) (compare Deﬁnition 19.11).
The main goal of this section is to express the probability 1 −F(x1, x1) that the
random walk never returns to x1 in terms of effective resistances in the network.
In order to apply the results on ﬁnite electrical networks from the last section, we
henceforth assume that A0 ⊂E is such that E \ A0 is ﬁnite. We will obtain 1 −
F(x1, x1) as the limit of the probability that a random walk started at x1 hits A0
before returning to x1 as A0 ↓∅.

474
19
Markov Chains and Electrical Networks
Let u = ux1,A0 be the unique potential function on E with u(x1) = 1 and u(x) =
0 for any x ∈A0. By Theorem 19.7, u is harmonic and can be written as
ux1,A0(x) = Ex
'
1{XτA0∪{x1}=x1}
(
= Px
)
τx1 < τA0
*
for every x ∈E \ (A0 ∪{x1}).
Hence the current ﬂow I with respect to u satisﬁes
−I(A0) = I(x1) =

x∈E
I(x1, x) =

x∈E

u(x1) −u(x)

C(x1, x)
= C(x1)

x∈E

1 −u(x)

p(x1, x)
= C(x1)
⎛
⎝

x̸∈A0∪{x1}
p(x1, x) Px
)τA0 < τx1
* +

x∈A0
p(x1, x)
⎞
⎠
= C(x1) Px1
)
τA0 < τx1
*
.
Therefore,
pF (x1, A0) := Px1
)
τA0 < τx1
*
= Ceff(x1 ↔A0)
C(x1)
=
1
C(x1)
1
Reff(x1 ↔A0).
(19.10)
Deﬁnition 19.23 We denote the escape probability of x1 by
pF (x1) = Px1
)
τx1 = ∞
*
= 1 −F(x1, x1).
We denote the effective conductance from x1 to ∞by
Ceff(x1 ↔∞) := C(x1) inf
	
pF (x1, A0) : A0 ⊂E with |E \ A0|< ∞, A0 ̸∋x1

.
Lemma 19.24 For any decreasing sequence An
0 ↓∅such that |E \ An
0| < ∞and
x1 ̸∈An
0 for all n ∈N, we have
Ceff(x1 ↔∞) =
lim
n→∞Ceff(x1 ↔An
0).
Proof This is obvious since
Ceff(x1 ↔∞) = C(x1) inf
	
pF (x1, A0) : |E \ A0| < ∞, A0 ̸∋x1

(19.11)
and since pF (x1, A0) is monotone decreasing in A0.
⊓⊔

19.4
Recurrence and Transience
475
Theorem 19.25 We have
pF (x1) =
1
C(x1) Ceff(x1 ↔∞).
(19.12)
In particular,
x1 is recurrent
⇐⇒
Ceff(x1 ↔∞) = 0
⇐⇒
Reff(x1 ↔∞) = ∞.
Proof Let An
0 ↓∅be a decreasing sequence such that |E \ An
0| < ∞and x1 ̸∈An
0
for all n ∈N. Deﬁne Fn :=
	
τAn
0 < τx1

. For every M ∈N, we have
Px1[τAn
0 ≤M] ≤
M

k=0
Px1[Xk ∈An
0]
n→∞
−→
0.
Hence τAn
0 ↑∞almost surely, and thus Fn ↓{τx1 = ∞} (up to a null set). We
conclude
1
C(x1) Ceff(x1 ↔∞) =
lim
n→∞Px1[Fn] = Px1[τx1 = ∞] = pF (x1).
⊓⊔
Example 19.26 Symmetric simple random walk on E = Z is recurrent. Here
C(x, y) = 1{|x−y|=1}. The effective resistance from 0 to ∞can be computed by
the formulas for parallel and sequence connections,
Reff(0 ↔∞) = 1
2
∞

i=0
R(i, i + 1) = ∞.
♦
Example 19.27 Asymmetric simple random walk on E = Z with p(x, x + 1) =
p ∈( 1
2, 1), p(x, x −1) = 1 −p
is transient. Here one choice (and thus up to
multiples the unique choice) for the conductances is
C(x, x + 1) =

p
1 −p
x
for x ∈Z,
and C(x, y) = 0 if |x −y| > 1. By the monotonicity principle, the effective
resistance from 0 to ∞can be bounded by
Reff(0 ↔∞) =
lim
n→∞Reff(0 ↔{−n, n})
≤
lim
n→∞Reff(0 ↔n)
=
∞

n=0
1 −p
p
n
=
p
2p −1 < ∞.
♦

476
19
Markov Chains and Electrical Networks
0
1
2
3
4
5
Fig. 19.3 Electrical network on Z2. The bold lines are superconductors. The nth and the (n+1)th
superconductors are connected by 4(2n + 1) edges.
Reﬂection Check that nearest neighbour random walk on an inﬁnite binary tree
(see Fig. 2.3) is transient. ♠
Example 19.28 Symmetric simple random walk on E = Z2 is recurrent. Here again
C(x, y) = 1{|x−y|=1}. Let Bn = {−n, . . . , n}2 and ∂Bn = Bn\Bn−1. We construct a
network C′ with greater conductances by adding ring-shaped superconductors along
∂B. (See Figs. 19.3 and 19.4 for illustrations.) That is, we replace C(x, y) by
C′(x, y) =

∞,
if x, y ∈∂Bn for some n ∈N,
C(x, y),
else.
Then R′
eff(Bn ↔Bc
n) =
1
4(2n+1) (note that there are 4(2n+1) edges that connect
Bn with Bc
n), and thus
R′
eff(0 ↔∞) =
∞

n=0
1
4(2n + 1) = ∞.

19.4
Recurrence and Transience
477
4 edges
12 edges
4(2n + 1) edges
0
1
2
n
n + 1
Fig. 19.4 Effective network after adding superconductors to Z2. The ring-shaped superconductors
have melted down to single points.
By the monotonicity principle, we thus have Reff(0 ↔∞) ≥R′
eff(0 ↔∞) = ∞.
♦
Example 19.29 Let (E, K) be an arbitrary connected subgraph of the square lattice
(Z2, L2). Then simple random walk on (E, K) (see Deﬁnition 19.11) is recurrent.
Indeed, by the monotonicity principle, we have
R(E,K)
eff
(0 ↔∞) ≥R(Z2,L2)
eff
(0 ↔∞) = ∞.
♦
We formulate the method used in the foregoing examples as a theorem.
Theorem 19.30 Let C and C′ be edge weights on E with C′(x, y) ≤C(x, y) for
all x, y ∈E. If the Markov chain X with weights C is recurrent, then the Markov
chain X′ with weights C′ is also recurrent.
In particular, consider a graph (E, K) and a subgraph (E′, K′). If simple
random walk on (E, K) is recurrent, then so is simple random walk on (E′, K′).
Proof This follows from Theorem 19.25 and Rayleigh’s monotonicity principle
(Theorem 19.19).
⊓⊔
Example 19.31 Symmetric simple random walk on Z3 is transient. In order to prove
this, we construct a subgraph for which we can compute R′
eff(0 ↔∞) < ∞.
Sketch We consider the set of all inﬁnite paths starting at 0 and that
•
begin by taking one step in the x-direction, the y-direction or the z-direction,
•
continue by choosing a possibly different direction x, y or z and make two steps
in that direction, and
•
at the nth stage choose a direction x, y or z and take 2n+1 steps in that direction.
For example, by xyyxxxxzzzzzzzz. . . we denote the path that starts with one
step in direction x, then chooses y, then x, then z and so on. Note that after two

478
19
Markov Chains and Electrical Networks
x
xx
y
z
yx
yy
yz
xz
xy
zy
yzz
yyy
xxx
zzz
zxx
zx
zyy
xzz
zz
yxx
xyy
x
y
z
yy
yx
yz
xz
zz
zx
zy
xy
xx
zzz
zxx
zyy
yzz
yyy
yxx
xyy
xzz
xxx
Fig. 19.5 Scheme of the ﬁrst three steps (two stages) of the graph from Example 19.31. The left
ﬁgure shows the actual edges where, e.g., xyy indicates that the ﬁrst step is in direction x, the
second step is in direction y and then the third step is necessarily also in direction y. In the right
ﬁgure, the nodes at the ends of xz/zx, xy/yx and yz/zy are split into two nodes and then connected
by a superconductor (bold line). If we remove the superconductors from the network, we end up
with the network of Fig. 19.6 whose effective resistance R′
eff(0 ↔∞) is not smaller than that of
Z3. (If at the root we apply a voltage of 1 and at the points to the right the voltage 0, then by
symmetry no current ﬂows through the superconductors. Thus, in fact, the network is equivalent
to that in Fig. 19.6.)
paths follow different directions for the ﬁrst time, they will not have any common
edge again, though some of the nodes can be visited by both paths.
Consider the electrical network with unit resistors. Apply a voltage of 1 at the ori-
gin and 0 at the endpoints of the paths at the nth stage. By symmetry, the potential at
a given node depends only on the distance (length of the shortest path) from the ori-
gin. We thus obtain an equivalent network if we replace multiply used nodes by mul-
tiple nodes (see Fig. 19.5). Thus we obtain a tree-shaped network: For any n ∈N0,
after 2n steps each path splits into three (see Fig. 19.6). The 3n paths leading from
the nodes of the nth generation to those of the (n+1)th generation are disjoint paths,
each of length 2n−1. If B(n) denotes the set of points up to the nth generation, then
R′
eff
0 ↔B(n + 1)c =
n−1

k=0
R′
eff
B(k) ↔B(k)c =
n−1

k=0
2k 3−k.
Therefore, R′
eff(0 ↔∞) = 1
3
∞
k=0

2
3
k
= 1 < ∞. On this tree, random walk is
transient. Hence, by Theorem 19.30, random walk on Z3 is also transient. ♦

19.4
Recurrence and Transience
479
R(0, 1)=1/3
R(1, 2) = 2/9
R(2, 3) = 4/27
Reﬀ(0 ↔2) = 5/9
Reﬀ(0 ↔3) = 19/27
3
2
1
0
Fig. 19.6 A tree as a subgraph of Z3 on which random walk is still transient.
Takeaways A reversible Markov chain escapes from a point x to inﬁnity
(that is, it never returns to x) with positive probability if and only if in
the corresponding electrical network, the effective resistance between x and
inﬁnity is ﬁnite. We use this idea to give a different proof for the fact that
simple random walk on Zd is recurrent if and only if d ≤2. Furthermore, and
more importantly, we use Rayleigh’s monotonicity principle to show that if a
random on a graph is recurrent, then it is also recurrent on any subgraph.

480
19
Markov Chains and Electrical Networks
Exercise 19.4.1 Consider the electrical network on Zd with unit resistors between
neighboring points. Let X be a symmetric simple random walk on Zd. Finally, ﬁx
two arbitrary neighboring points x0, x1 ∈Zd. Show the following:
(i) The effective conductance between x0 and x1 is Ceff(x0 ↔x1) = d.
(ii) If d ≤2, then Px0[τx1 < τx0] = 1
2.
(iii) If d ≥3, then Px0[τx1 < τx0 |τx0 ∧τx1 < ∞] = 1
2. ♣
19.5
Network Reduction
Example 19.32 Consider a random walk on the graph in Fig. 19.7 that starts at x
and at each step jumps to one of its neighbors at random with equal probability.
What is the probability P that this Markov chain visits 1 before it visits 0?
We can regard the graph as an electrical network with unit resistors at each edge,
voltage 0 at 0 and voltage 1 at 1. Then P equals the voltage at point x:
P = u(x).
In order to compute u(x), we replace the network step by step by simpler networks
such that the effective resistances between 0, 1, and x remain unchanged. Hence in
each step the voltage u(x) at point x does not change. ♦
Reduced Network
Assume that we have already reduced the network to a network with the three points
0, 1 and x and with resistors between these points R′(0, 1), R′(0, x) and R′(1, x).
See Fig. 19.8.
0
x
1
Fig. 19.7 Initial situation.

19.5
Network Reduction
481
R (0, x)
R (0, 1)
R (x, 1)
0
x
1
Fig. 19.8 Reduced network with three nodes.
Clearly, we have
P = u(x) =
R′(0, x)
R′(0, x) + R′(1, x).
(19.13)
If we knew the effective resistances Reff(0 ↔x), Reff(1 ↔x) and Reff(0 ↔1),
we could avoid the hassle of reducing the network and we could compute u(x)
directly. In order to derive the formula for u(x), we make the following observations.
In the reduced network, the effective resistances are easy to compute: If {a, b, c} =
{0, 1, x}, then
Reff(a ↔b) =

1
R′(a, b) +
1
R′(a, c) + R′(b, c)
−1
.
(19.14)
Solving these three equations for R′(0, 1), R′(0, x) and R′(1, x) and plugging
the values into (19.13) yields
P = u(x) = Reff(0 ↔1) + Reff(0 ↔x) −Reff(x ↔1)
2 Reff(0 ↔1)
.
(19.15)
In particular, in the case R′(0, 1) = ∞(or equivalently Reff(0 ↔1) = Reff(0 ↔
x) + Reff(x ↔1)), we have Reff(0 ↔x) = R′(0, x) and Reff(1 ↔x) = R′(1, x),
hence
u(x) =
Reff(0 ↔x)
Reff(0 ↔x) + Reff(x ↔1).
(19.16)
Since we always have u(x) ∈[0, 1], rearranging the terms yields (again in the
general situation)
Reff(1 ↔x) ≤Reff(0 ↔1) + Reff(0 ↔x).
(19.17)
This is the triangle inequality for the effective resistances and it shows that the
effective resistance is a metric in any electrical network.

482
19
Markov Chains and Electrical Networks
Step-by-Step Reduction of the Network
Having seen how to compute u(x) from the effective resistances, we now turn to the
systematic computation of these effective resistances. Later we will come back to
the introductory example and make the computations explicit.
There are four elementary transformations for the reduction of an electrical
network:
1. Deletion of loops.
The three points on the very right of the graph form a loop
that can be deleted from the network without changing any of the remaining
voltages. In particular, any edge that directly connects 0 to 1 can be deleted.
2. Joining serial edges.
If two (or more) edges are in a row such that the nodes
along them do not have any further adjacent edges, this sequence of edges can be
substituted by a single edge whose resistance is the sum of the resistances of the
single edges (see Fig. 19.1).
3. Joining parallel edges.
Two (or more) edges with resistances R1, . . . , Rn that
connect the same two nodes can by replaced by a single edge with resistance
R = (R−1
1
+ . . . + R−1
n )−1 (see Fig. 19.2).
4. Star–triangle transformation (see Exercise 19.5.1).
The star-shaped part of
a network (left in Fig. 19.9) is equivalent to the triangle-shaped part (right in
Fig. 19.9) if the resistances R1, R2, R3, 
R1, 
R2, 
R3 satisfy the condition
Ri ˜Ri = δ
for any i = 1, 2, 3,
(19.18)
where
δ = R1R2R3

R−1
1
+ R−1
2
+ R−1
3

=

R1 
R2 
R3

R1 + 
R2 + 
R3
.
x1
x2
x3
x
z
1
x2
x3
R1
R3
R2
R1
R3
R2
Fig. 19.9 Star–triangle transformation.

19.5
Network Reduction
483
Application to Example 19.32
With the four transformations at hand, we solve the problem of Example 19.32.
Assume that initially all edges have resistance 1. In the ﬁgures we label each edge
with its resistance if it differs (in the course of the reduction) from 1.
Step 1.
Delete the loop at the right-hand side (left in Fig. 19.10).
Step 2.
Replace the series on top, bottom and right by edges with resistance 2
(right in Fig. 19.10).
Step 3.
Use the star-triangle transformation to remove the lower left node (left
in Fig. 19.11). Here R1 = 1, R2 = 2, R3 = 1, δ = 5, 
R1 = δ/R1 = 5,

R2 = δ/R2 = 5/2 and 
R3 = δ/R3 = 5.
Step 4.
Replace the parallel edges with resistances R1 = 5 and R2 = 1 by one
edge with R = ( 1
5 + 1)−1 = 5
6 (right in Fig. 19.11).
Step 5.
Use the star-triangle transformation to remove the lower right node (left
in Fig. 19.12). Here R1 = 5, R2 = 2, R3 = 5
6, δ = 95/6, 
R1 = δ/R1 = 19/6,

R2 = δ/R2 = 95/12 and 
R3 = δ/R3 = 19.
Step 6.
Replace the parallel edges by edges with resistances ( 12
95 + 2
5)−1 = 19
10 and
( 6
19 + 1)−1 = 19
25, respectively (right in Fig. 19.12).
0
x
1
2
2
2
1
x
0
Fig. 19.10 Steps 1 and 2.
5/2
5
5
2
1
2
x
0
5
x
2
5/2
5/6
2
1
0
Fig. 19.11 Steps 3 and 4.

484
19
Markov Chains and Electrical Networks
19
95/12
19/6
5/2
2
x
0
1
19
2
x
0
1
19/10
19/25
Fig. 19.12 Steps 5 and 6.
54/25
27/5
0
x
2
1
19
513/125
x
1
0
R (0, x) = 27/32
R (x, 1) = 27/26
R (0, 1) = 27/8
Fig. 19.13 Steps 7 and 8.
Step 7.
Use the star-triangle transformation to remove the lower right node (left
in Fig. 19.13). Here R1 = 19
10, R2 = 19
25, R3 = 1, δ = 513
125, 
R1 = δ/R1 = 54
25,

R2 = δ/R2 = 27
5 and 
R3 = δ/R3 = 513
125.
Step 8.
Replace the three pairs of parallel edges by single edges with resistances
( 5
27 + 1)−1 = 27
32,
( 25
54 + 1
2)−1 = 27
26
and
( 1
19 + 125
513)−1 = 27
8 , respectively.
In the reduced network, we have the resistances R′(0, x) = 27
32 and R′(x, 1) =
27
26. Using (19.13), the probability that the random walk visits 1 before 0 is
P =
27
32
27
32 + 27
26
= 13
29.
Using the values of R′(0, x), R′(1, x) and R′(0, 1) and equation (19.14), we
compute the effective resistances in the reduced network (and hence in the original
network):
Reff(0 ↔x) =

32
27 +
1
27
8 + 27
26
−1
= 17
24,
Reff(1 ↔x) =

26
27 +
1
27
32 + 27
8
−1
= 5
6,
Reff(0 ↔1) =

8
27 +
1
27
26 + 27
32
−1
= 29
24.

19.5
Network Reduction
485
Using (19.15) we can use the values to compute u(x):
P = u(x) =
29
24 + 17
24 −5
6
2 · 29
24
= 13
29.
Clearly, the latter computation is more complicated than using the resistances
R′ from the reduced network directly. However, it has the advantage that it can be
performed without going through all the network reduction steps if, for some reason,
we know the effective resistances already. For example, we could buy resistors in an
electronic market, solder the network and measure the resistances with a multimeter.
♦
Alternative Solution
A different approach to solving the problem of Example 19.32 is to use linear
algebra instead of network reduction. It is a matter of taste as to which solution
is preferable. First generate the transition matrix p of the Markov chain. To this
end, enumerate the nodes of the graph from 1 to 12 as in Fig. 19.14. The chain starts
at 2, and we want to compute the probability that it visits 3 before 5.
3
5
9
8
7
10
6
1
2
12
4
11
Fig. 19.14 Graph with enumerated nodes.

486
19
Markov Chains and Electrical Networks
Generate the matrix p of the chain that is killed at 3 and at 5 and compute G =
(I −p)−1. By Exercise 19.1.1 (with A = {3, 5}, x = 2 and y = 3), the probability
of visiting 3 before 5 is P = G(2, 3) = 13
29.
p :=
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
0 1
2
1
2 0 0 0 0 0 0 0 0 0
1
3 0 0 0 1
3
1
3 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1
2
1
2 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 1
4
1
4 0 0 0 0 0 1
4
1
4 0 0
0 0 1
4
1
4 0 0 0 0 0 1
4
1
4 0
0 0 0 1
2 0 0 0 0 0 0 1
2 0
0 0 0 0 1
3
1
3 0 0 0 0 0 1
3
0 0 0 0 0 1
3
1
3 0 0 0 0 1
3
0 0 0 0 0 0 1
2
1
2 0 0 0 0
0 0 0 0 0 0 0 0 1
2
1
2 0 0
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
,
G := (I −p)−1 =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
143
116
81
116
21
29
3
58
8
29
19
58
3
29
3
58
15
116
9
58
3
58
11
116
27
58
81
58
13
29
3
29
16
29
19
29
6
29
3
29
15
58
9
29
3
29
11
58
0
0
1
0
0
0
0
0
0
0
0
0
3
58
9
58
24
29
165
58
5
29
15
29
78
29
68
29
21
58
30
29
107
58
27
58
0
0
0
0
1
0
0
0
0
0
0
0
19
116
57
116
18
29
15
58
11
29
95
58
15
29
15
58
75
116
45
58
15
58
55
116
3
58
9
58
24
29
39
29
5
29
15
29
78
29
39
29
21
58
30
29
39
29
27
58
3
58
9
58
24
29
68
29
5
29
15
29
78
29
97
29
21
58
30
29
68
29
27
58
5
58
15
58
11
29
7
29
18
29
25
29
14
29
7
29
93
58
21
29
7
29
45
58
3
29
9
29
19
29
20
29
10
29
30
29
40
29
20
29
21
29
60
29
20
29
27
29
3
58
9
58
24
29
107
58
5
29
15
29
78
29
68
29
21
58
30
29
165
58
27
58
11
116
33
116
15
29
27
58
14
29
55
58
27
29
27
58
135
116
81
58
27
58
215
116
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
.

19.5
Network Reduction
487
Takeaways There are essentially two possibilities to systematically deter-
mine the effective resistance between two points in an electrical network.
Firstly, one can solve the system of linear equations belonging to the Markov
chain killed in the two points. Secondly, the network can be reduced in a series
of elementary steps: Resolving parallel connections, resolving serial connec-
tions and resolving intermediate points using the star-triangle transformation.
While solving the linear equations is a simple job for a computer, network
reduction can give insights into the structure of the problem and can lead to
general formulas also for similar networks.
Exercise 19.5.1 Show the validity of the star-triangle transformation. ♣
Exercise 19.5.2 Consider a random walk on the honeycomb graph shown below.
Show that if the walk starts at x, then the probability of visiting 1 before 0 is
8
17
using
(i) the method of network reduction, and
(ii) the method of matrix inversion. ♣
x
1
0
Exercise 19.5.3 Consider the graph of Fig. 19.15.
(i) For the effective conductance between a and z, show that Ceff(a ←→z) =
√
3.
(ii) For a random walk started at a, show that the probability Pa[τz < τa] of visiting
z before returning to a is Pa[τz < τa] = 1/
√
3. ♣
Exercise 19.5.4 For the graph of Fig. 19.16, determine Ceff(a ←→z) and Pa[τz <
τa]. (This is simpler than in Exercise 19.5.3!) ♣
Exercise 19.5.5 For a random walk on the graph of Fig. 19.17, determine the
probability Pa[τz < τa]. ♣

488
19
Markov Chains and Electrical Networks
z
a
Fig. 19.15 Simple ladder graph
z
a
Fig. 19.16 Crossed ladder graph
z
a
Fig. 19.17 Random walk on a hypercube.
19.6
Random Walk in a Random Environment
(Compare [143, 175] and [76, 77, 96].) Consider a Markov chain X on Z that at
each step makes a jump either to the left (with probability w−
i ) or to the right (with
probability w+
i ) if X is at i ∈Z. Hence, let w−
i ∈(0, 1) and w+
i := 1 −w−
i
for
i ∈Z. Then X is the Markov chain with transition matrix
pw(i, j) =
⎧
⎪⎨
⎪⎩
w−
i ,
if j = i −1,
w+
i ,
if j = i + 1,
0,
else.
We consider (w−
i )i∈Z as an environment in which X walks and later choose the
environment at random.

19.6
Random Walk in a Random Environment
489
In order to describe X in terms of conductances of an electrical network, we
deﬁne ϱi := w−
i /w+
i
for i ∈Z. Let Cw(i, j) := 0 if |i −j| ̸= 1 and
Cw(i + 1, i) := Cw(i, i + 1) :=
 i
k=0 ϱ−1
k ,
if i ≥0,
−1
k=i ϱk,
if i < 0.
With this deﬁnition,
Cw(i, i + 1)
Cw(i)
=
1
ϱi + 1 = w+
i
and
Cw(i, i −1)
Cw(i)
=
ϱi
ϱi + 1 = w−
i .
Hence the transition probabilities pw are indeed described by the Cw. Let
R+
w :=
∞

i=0
Rw(i, i + 1) =
∞

i=0
1
Cw(i, i + 1) =
∞

i=0
i
k=0
ϱk
and
R−
w :=
∞

i=0
Rw(−i, −i −1) =
∞

i=0
1
Cw(−i, −i −1) =
∞

i=1
1

k=−i
ϱ−1
k .
Note that R+
w and R−
w are the effective resistances from 0 to +∞and from 0 to
−∞, respectively. Hence
Rw,eff(0 ↔∞) =
1
1
R−
ω +
1
R+
ω
is ﬁnite if and only if R−
w < ∞or R+
w < ∞. Therefore, by Theorem 19.25,
X is transient
⇐⇒
R−
w < ∞or R+
w < ∞.
(19.19)
If X is transient, in which direction does it get lost?
Theorem 19.33
(i) If R−
w < ∞or R+
w < ∞, then (agreeing on ∞
∞= 1)
P0
)Xn
n→∞
−→−∞* =
R+
w
R−
w + R+
w
and
P0
)Xn
n→∞
−→+∞* =
R−
w
R−
w + R+
w
.
(ii) If R−
w = ∞and R+
w = ∞, then lim inf
n→∞Xn = −∞and lim sup
n→∞
Xn = ∞
almost surely.

490
19
Markov Chains and Electrical Networks
Proof
(i) Let τN := inf
	
n ∈N0 : Xn ∈{−N, N}

. As X is transient, we have P0[τN <
∞] = 1 and (as in (19.9))
P0
)
XτN = −N
*
=
Rw,eff(0 ↔N)
Rw,eff(−N ↔N) =
Rw,eff(0 ↔N)
Rw,eff(0 ↔−N) + Rw,eff(0 ↔N).
Again, since X is transient, we infer
P0
)
Xn
n→∞
−→−∞
*
= P
)
sup{Xn : n ∈N0} < ∞
*
= lim
N→∞P) sup{Xn : n ∈N0} < N*
≤lim sup
N→∞
P)XτN = −N*
=
R+
w
R−
w + R+
w
.
By symmetry (and since X is transient), we get
P0
)
Xn
n→∞
−→−∞
*
= 1−P0
)
Xn
n→∞
−→∞
*
≥1−
R−
w
R−
w + R+
w
=
R+
w
R−
w + R+
w
.
(ii) If R−
w = R+
w = ∞, then X is recurrent and hence every point is visited
inﬁnitely often. That is, lim supn→∞Xn = ∞and lim infn→∞Xn = −∞
a.s.
⊓⊔
We now consider the situation where the sequence w = (w−
i )i∈Z is also random.
That is, we consider a two-stage experiment: At the ﬁrst stage we choose a
realization of i.i.d. random variables W = (W −
i )i∈Z on (0, 1) and let W +
i
:=
1 −W −
i . At the second stage, given W, we construct a Markov chain X on Z with
transition matrix
pW (i, j) =
⎧
⎪⎨
⎪⎩
W −
i ,
if j = i −1,
W +
i ,
if j = i + 1,
0,
else.
Note that X is a Markov chain only given W; that is, under the probability measure
P[X ∈· |W]. However, it is not a Markov chain with respect to the so-called
annealed measure P[X ∈·]. In fact, if W is unknown, observing X gives an
increasing amount of information on the true realization of W. This is precisely
what memory is and is thus in contrast with the Markov property of X.
Deﬁnition 19.34 The process X is called a random walk in the random environ-
ment W.

19.6
Random Walk in a Random Environment
491
We are now in the position to prove a theorem of Solomon [158]. Let ϱi :=
W −
i /W +
i
for i ∈Z and R−
W and R+
W be deﬁned as above.
Theorem 19.35 (Solomon [158]) Assume that E[| log(ϱ0)|] < ∞.
(i) If E[log(ϱ0)] < 0, then Xn
n→∞
−→∞a.s.
(ii) If E[log(ϱ0)] > 0, then Xn
n→∞
−→−∞a.s.
(iii) If E[log(ϱ0)] = 0, then lim inf
n→∞Xn = −∞and lim sup
n→∞
Xn = ∞a.s.
Proof (i) and (ii)
By symmetry, it is enough to show (ii). Hence, let c :=
E[log(ϱ0)] > 0. By the strong law of large numbers, there is an n−
0
= n−
0 (ω)
with
1

k=−n
ϱ−1
k
= exp

−
1

k=−n
log(ϱk)

< e−cn/2
for all n ≥n−
0 .
Therefore,
R−
W =
∞

n=1
1

k=−n
ϱ−1
k
≤
n−
0 −1

n=1
1

k=−n
ϱ−1
k
+
∞

n=n−
0
e−cn/2 < ∞
a.s.
Similarly, there is an n+
0 = n+
0 (ω) with
n

k=0
ϱk > ecn/2
for all n ≥n+
0 .
We conclude
R+
W =
∞

n=0
n

k=0
ϱk ≥
n+
0 −1

n=0
n

k=0
ϱk +
∞

n=n+
0
ecn/2 = ∞
a.s.
Now, by Theorem 19.33, we get Xn
n→∞
−→−∞almost surely.
(iii)
In order to show R−
W = R+
W = ∞almost surely, it is enough to show
lim supn→∞
n
k=0 log(ϱk) > −∞and lim supn→∞
1
k=−n log(ϱ−1
k ) > −∞
almost surely if E[log(ϱ0)] = 0. If log(ϱ0) has a ﬁnite variance, this follows by
the central limit theorem. In the general case, it follows by Theorem 20.21.
⊓⊔
Reﬂection In the situation of Theorem 19.35, come up with an example such that
E[W +
i −W −
i ] > 0 but still Xn
n→∞
−→−∞holds. ♠

492
19
Markov Chains and Electrical Networks
Takeaways One-dimensional random walks in random environment can be
regarded as random walks in a network of random conductances. This is a
specialty of dimension one that makes it easy to check if the random walk is
transient or recurrent.
Exercise 19.6.1 Consider the situation of Theorem 19.35 but with the random walk
restricted to N0. To this end, change the walk so that whenever it attempts to make
a step from 0 to −1, it simply stays in 0. Show that this random walk in a random
environment is
•
a.s. transient if E[log(ϱ0)] < 0,
•
a.s. null recurrent if E[log(ϱ0)] = 0, and
•
a.s. positive recurrent if E[log(ϱ0)] > 0. ♣

Chapter 20
Ergodic Theory
Laws of large numbers, e.g., for i.i.d. random variables X1, X2, . . ., state that the
sequence of averages converges a.s. to the expected value, n−1 n
i=1 Xi
n→∞
−→
E[X1]. Hence averaging over one realization of many random variables is equivalent
to averaging over all possible realizations of one random variable. In the terminol-
ogy of statistical physics this means that the time average, or path (Greek: odos)
average, equals the space average. The “space” in “space average” is the probability
space in mathematical terminology, and in physics it is considered the space of
admissible states with a certain energy (Greek: ergon). Combining the Greek words
gives rise to the name ergodic theory, which studies laws of large numbers for
possibly dependent, but stationary, random variables.
For further reading, see, for example [103] or [88].
20.1
Deﬁnitions
Deﬁnition 20.1 Let I ⊂R be a set that is closed under addition (for us the
important examples are I = N0, I = N, I = Z, I = R, I = [0, ∞), I = Zd
and so on). A stochastic process X = (Xt)t∈I is called stationary if
L [(Xt+s)t∈I] = L [(Xt)t∈I]
for all s ∈I.
(20.1)
Remark 20.2 If I = N0, I = N or I = Z, then (20.1) is equivalent to
L [(Xn+1)n∈I] = L [(Xn)n∈I] .
♦
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_20
493

494
20
Ergodic Theory
Example 20.3
(i) If X = (Xt)t∈I is i.i.d., then X is stationary. If only PXt = PX0 holds for
every t ∈I (without the independence), then in general, X is not stationary.
For example, consider I = N0 and X1 = X2 = X3 = . . . but X0 ̸= X1.
Then X is not stationary.
(ii) Let X be a Markov chain with invariant distribution π. If L[X0] = π, then
X is stationary.
(iii) Let (Yn)n∈Z be i.i.d. real random variables and let c1, . . . , ck ∈R. Then
Xn :=
k

l=1
cl Yn−l,
n ∈Z,
deﬁnes a stationary process X that is called the moving average with weights
(c1, . . . , ck). In fact, X is stationary if only Y is stationary. ♦
Lemma 20.4 If (Xn)n∈N0 is stationary, then X can be extended to a stationary
process

Xn

n∈Z .
Proof Let 
X be the canonical process on Ω = EZ. For n ∈N, deﬁne a probability
measure P{−n,−n+1,...} ∈M1
E{−n,−n+1,...} by
P{−n,−n+1,...})
X−n ∈A−n, 
X−n+1 ∈A−n+1, . . .
*
= P
)
X0 ∈A−n, X1 ∈A−n+1, . . .
*
.
Then {−n, −n + 1, . . .} ↑Z and P{−n,−n+1,...}, n ∈N is a consistent family.
By the Ionescu–Tulcea theorem (Theorem 14.35), the projective limit P
:=
lim
←−
n→∞
P{−n,−n+1,...} exists. By construction, 
X is stationary with respect to P and
P ◦(
Xn)n∈N0
−1 = P ◦(Xn)n∈N0
−1.
⊓⊔
In the following, assume that (Ω, A, P) is a probability space and τ : Ω →Ω
is a measurable map.
Deﬁnition 20.5 An event A ∈A is called invariant if τ −1(A) = A and quasi-
invariant if 1τ −1(A) = 1A P-a.s. Denote the σ-algebra of invariant events by
I = 	A ∈A : τ −1(A) = A
.
Recall that a σ-algebra I is called P-trivial if P[A] ∈{0, 1} for every A ∈I.

20.1
Deﬁnitions
495
Deﬁnition 20.6
(i) τ is called measure-preserving if
P
)
τ −1(A)
*
= P[A]
for all A ∈A.
In this case, (Ω, A, P, τ) is called a measure-preserving dynamical system.
(ii) If τ is measure-preserving and I is P-trivial, then (Ω, A, P, τ) is called
ergodic.
Lemma 20.7
(i) A measurable map f : (Ω, A) →R, B(R) is I-measurable if and only if
f ◦τ = f .
(ii) (Ω, A, P, τ) is ergodic if and only if any I-measurable f
: (Ω, I) →
(R, B(R)) is P-almost surely constant.
Proof
(i) The statement is obvious if f = 1A is an indicator function. The general case,
can be inferred by the usual approximation arguments (see Theorem 1.96((i))).
(ii) “ ⇒”
Assume that (Ω, A, P, τ) is ergodic. Then, for any c ∈R, we have
f −1((c, ∞)) ∈I and thus P[f −1((c, ∞))] ∈{0, 1}. We conclude that
f = inf
	
c ∈R : P
)
f −1((c, ∞))
*
= 0

P-a.s.
“ ⇐ ”
Assume any I-measurable map is P-a.s. constant. If A ∈I, then 1A
is I-measurable and hence P-a.s. equals either 0 or 1. Thus P[A] ∈{0, 1}.
⊓⊔
Example 20.8 Let n ∈N\{1}, let Ω = Z/(n), let A = 2Ω and let P be the uniform
distribution on Ω. Let r ∈{1, . . . , n} and
τ : Ω →Ω,
x →x + r
(mod n).
Then τ is measure-preserving. If d = gcd(n, r) and
Ai = 	i, τ(i), τ 2(i), . . . , τ n−1(i)
 = i + ⟨r⟩
for i = 0, . . . , d −1,
then A0, . . . , Ad−1 are the disjoint coset classes of the normal subgroup ⟨r⟩⊴Ω.
Hence we have Ai ∈I for i = 0, . . . , d −1, and each A ∈I is a union of certain
Ai’s. Hence we have
(Ω, A, P, τ) is ergodic
⇐⇒
gcd(r, n) = 1.
♦
Example 20.9 (Rotation) Let Ω = [0, 1), let A = B(Ω) and let P = λ be the
Lebesgue measure. Let r ∈(0, 1) and τr(x) = x+r (mod 1). Clearly, (Ω, A, P, τr)
is a measure-preserving dynamical system. We will show
(Ω, A, P, τr) is ergodic
⇐⇒
r is irrational.

496
20
Ergodic Theory
Let f : [0, 1) →R be an I-measurable function. Without loss of generality, we
assume that f is bounded and thus square integrable. Hence f can be expanded in
a Fourier series
f (x) =
∞

n=−∞
cn e2πin x
for P-a.a. x.
This series converges in L2, and the sequence of square summable coefﬁcients
(cn)n∈Z is unique (compare Exercise 7.3.1 with cn = (−i/2)an + (1/2)bn and
c−n = (i/2)an + (1/2)bn for n ∈N as well as c0 = b0). Now we compute
(f ◦τr)(x) =
∞

n=−∞

cn e2πin r
e2πin x
a.e.
By Lemma 20.7, f is I-measurable if and only if f = f ◦τr; that is, if and only
if
cn = cn e2πin r
for all n ∈Z.
If r is irrational, this implies cn = 0 for n ̸= 0, and thus f is almost surely constant.
Therefore, (Ω, A, P, τr) is ergodic.
On the other hand, if r is rational, then there exists some n ∈Z \ {0} with
e2πin r = e−2πin r = 1. Hence x →e2πin x + e−2πin x = 2 cos(2πn x) is I-
measurable but not a.s. constant. Thus, in this case (Ω, A, P, τr) is not ergodic.
♦
Example 20.10 Let X = (Xn)n∈N0 be a stochastic process with values in a Polish
space E. Without loss of generality, we may assume that X is the canonical process
on the probability space (Ω, A, P) =

EN0, B(E)⊗N0, P

. Deﬁne the shift operator
τ : Ω →Ω,
(ωn)n∈N0 →(ωn+1)n∈N0.
Then Xn(ω) = X0(τ n(ω)). Hence X is stationary if and only if (Ω, A, P, τ) is a
measure-preserving dynamical system. ♦
Deﬁnition 20.11 The stochastic process X (from Example 20.10) is called ergodic
if (Ω, A, P, τ) is ergodic.
Example 20.12 Let (Xn)n∈N0 be i.i.d. and let Xn(ω) = X0(τ n(ω)). If A ∈I, then,
for every n ∈N,
A = τ −n(A) = {ω : τ n(ω) ∈A} ∈σ(Xn, Xn+1, . . .).

20.2
Ergodic Theorems
497
Hence, if we let T be the tail σ-algebra of (Xn)n∈N (see Deﬁnition 2.34), then
I ⊂T
=
∞

n=1
σ(Xn, Xn+1, . . .).
By Kolmogorov’s 0-1 law (Theorem 2.37), T is P-trivial. Hence I is also P-trivial
and therefore (Xn)n∈N0 is ergodic. ♦
Takeaways A measure preserving dynamical system consists of a probability
space (Ω, A, P) and a measure preserving map τ : Ω →Ω. It is called
ergodic if there are no nontrivial (w.r.t. P) invariant sets. Examples for
measure preserving dynamical systems are stationary stochastic processes,
i.i.d. random variables, rotations and so on.
Exercise 20.1.1 Let G be a ﬁnite group of measure-preserving measurable maps
on (Ω, A, P) and let A0 := {A ∈A : g(A) = A for all g ∈G}.
Show that, for every X ∈L1(P), we have
E[X|A0] =
1
#G

g∈G
X ◦g.
♣
20.2
Ergodic Theorems
In this section, (Ω, A, P, τ) always denotes a measure-preserving dynamical
system. Further, let f : Ω →R be measurable and
Xn(ω) = f ◦τ n(ω)
for all n ∈N0.
Hence X = (Xn)n∈N0 is a stationary real-valued stochastic process. Let
Sn =
n−1

k=0
Xk
denote the nth partial sum. Ergodic theorems are laws of large numbers for (Sn)n∈N.
We start with a preliminary lemma.

498
20
Ergodic Theory
Lemma 20.13 (Hopf’s maximal-ergodic lemma)
Let X0 ∈L1(P). Deﬁne Mn =
max{0, S1, . . . , Sn}, n ∈N. Then
E
)
X0 1{Mn>0}
*
≥0
for every n ∈N.
Proof For k ≤n, we have Mn(τ(ω)) ≥Sk(τ(ω)). Hence
X0 + Mn ◦τ ≥X0 + Sk ◦τ = Sk+1.
Thus X0 ≥Sk+1 −Mn ◦τ for k = 1, . . . , n. Manifestly, S1 = X0 and Mn ◦τ ≥0
and hence also (for k = 0) X0 ≥S1 −Mn ◦τ. Therefore,
X0 ≥max{S1, . . . , Sn} −Mn ◦τ.
(20.2)
Furthermore, we have
{Mn > 0}c ⊂{Mn = 0} ∩{Mn ◦τ ≥0} ⊂{Mn −Mn ◦τ ≤0}.
(20.3)
By (20.2) and (20.3), and since τ is measure-preserving, we conclude that
E )X0 1{Mn>0}
* ≥E)(max{S1, . . . , Sn} −Mn ◦τ) 1{Mn>0}
*
= E
)
(Mn −Mn ◦τ) 1{Mn>0}
*
≥E
)
Mn −Mn ◦τ
*
= E[Mn] −E[Mn] = 0.
⊓⊔
Theorem 20.14 (Individual ergodic theorem, Birkhoff [16])
Let f = X0 ∈
L1(P). Then
1
n
n−1

k=0
Xk = 1
n
n−1

k=0
f ◦τ k
n→∞
−→E[X0
I]
P-a.s.
In particular, if τ is ergodic, then
1
n
n−1

k=0
Xk
n→∞
−→E[X0]
P-a.s.
Proof If τ is ergodic, then E[X0|I] = E[X0] and the supplement is a consequence
of the ﬁrst statement.
Consider now the general case. By Lemma 20.7, we have E[X0|I] ◦τ =
E[X0|I]
P-a.s. Hence, by passing to 
Xn := Xn −E[X0|I], without loss of
generality, we can assume E[X0|I] = 0. Deﬁne
Z := lim sup
n→∞
1
nSn.

20.2
Ergodic Theorems
499
Let ε > 0 and F := {Z > ε}. We have to show that P[F] = 0. From this we
infer P[Z > 0] = 0 and similarly (with −X instead of X) also lim inf
n→∞
1
nSn ≥0
almost surely. Hence 1
nSn
n→∞
−→0 a.s.
Evidently, Z ◦τ = Z; hence F ∈I. Deﬁne
Xε
n := (Xn −ε) 1F ,
Sε
n := Xε
0 + . . . + Xε
n−1,
Mε
n := max{0, Sε
1, . . . , Sε
n},
Fn := {Mε
n > 0}.
Then F1 ⊂F2 ⊂. . . and
∞

n=1
Fn =
0
sup
k∈N
1
k Sε
k > 0
1
=
0
sup
k∈N
1
k Sk > ε
1
∩F = F,
hence Fn ↑F. Dominated convergence yields E
)
Xε
0 1Fn
* n→∞
−→E
)
Xε
0
*
.
By the maximal-ergodic lemma (applied to Xε), we have E
)
Xε
0 1Fn
*
≥0; hence
0 ≤E )Xε
0
* = E [(X0 −ε) 1F ] = E [E [X0|I] 1F ] −εP[F] = −εP[F].
We conclude that P[F] = 0.
⊓⊔
As a consequence, we obtain the statistical ergodic theorem, or Lp-ergodic
theorem, that was found by von Neumann in 1931 right before Birkhoff proved
his ergodic theorem, but was published only later in [122]. Before we formulate it,
we state one more lemma.
Lemma 20.15 Let p ≥1 and let X0, X1, . . . be identically distributed, real random
variables with E[|X0|p] < ∞. Deﬁne Yn :=
 1
n
n−1

k=0
Xk

p
for n ∈N. Then (Yn)n∈N
is uniformly integrable.
Proof Evidently, the singleton {|X0|p} is uniformly integrable. Hence, by Theo-
rem 6.19, there exists a monotone increasing convex map f : [0, ∞) →[0, ∞)
with f (x)
x
→∞for x →∞and C := E[f (|X0|p)] < ∞. Again, by Theorem 6.19,
it is enough to show that E[f (Yn)] ≤C for every n ∈N. By Jensen’s inequality
(for x →|x|p), we have
Yn ≤1
n
n−1

k=0
|Xk|p.

500
20
Ergodic Theory
Again, by Jensen’s inequality (now applied to f ), we get that
f (Yn) ≤f

1
n
n−1

k=0
|Xk|p

≤1
n
n−1

k=0
f (|Xk|p).
Hence E[f (Yn)] ≤
1
n
n−1

k=0
E[f (|Xk|p)] = C.
⊓⊔
Theorem 20.16 (Lp-ergodic theorem, von Neumann (1931)) Let (Ω, A, P, τ)
be a measure-preserving dynamical system, p ≥1, X0 ∈Lp(P) and Xn = X0 ◦τ n.
Then
1
n
n−1

k=0
Xk
n→∞
−→E[X0|I]
in Lp(P).
In particular, if τ is ergodic, then
1
n
n−1

k=0
Xk
n→∞
−→E[X0] in Lp(P).
Proof Deﬁne
Yn :=

1
n
n−1

k=0
Xk −E[X0|I]

p
for every n ∈N.
By Lemma 20.15, (Yn)n∈N is uniformly integrable, and by Birkhoff’s ergodic
theorem, we have Yn
n→∞
−→
0 almost surely. By Theorem 6.25, we thus have
lim
n→∞E[Yn] = 0.
If τ is ergodic, then E[X0|I] = E[X0].
⊓⊔
Takeaways For ergodic dynamical systems, averages over ω and averages
over trajectories coincide (ergodic theorems). In general dynamical systems,
a similar statement is true if we replace the average over ω by the conditional
expectation given the σ-algebra of invariant events.
20.3
Examples
Example 20.17 Let (X, (Px)x∈E) be a positive recurrent, irreducible Markov chain
on the countable space E. Let π be the invariant distribution of X. Then π({x}) > 0
for every x ∈E. Deﬁne Pπ = 
x∈E π({x})Px. Then X is stationary on (Ω, A, Pπ).
Denote the shift by τ; that is, Xn = X0 ◦τ n.

20.3
Examples
501
Now let A ∈I be invariant. Then A ∈T =
∞

n=1
σ(Xn, Xn+1, . . .). By the strong
Markov property, for every ﬁnite stopping time σ (recall that Fσ is the σ-algebra of
the σ-past),
Pπ[X ∈A
Fσ] = PXσ [X ∈A].
(20.4)
Indeed, we have {X ∈A} = {X ∈τ −n(A)} = {(Xn, Xn+1, . . .) ∈A}. For B ∈Fσ,
using the Markov property (in the third line), we get
Eπ
)
1{X∈B} 1{X∈A}
*
=
∞

n=0

x∈E
Pπ
)
X ∈B, σ = n, Xn = x, X ∈A
*
=
∞

n=0

x∈E
Pπ
)
X ∈B, σ = n, Xn = x, X ◦τ n ∈A
*
=
∞

n=0

x∈E
Pπ
)
X ∈B, σ = n, Xn = x
*
Px[X ∈A]
= Eπ
)
1{X∈B} PXσ [X ∈A]
*
.
In particular, if x ∈E and σx = inf{n ∈N0 : Xn = x}, then σx < ∞since X is
recurrent and irreducible. By (20.4), we conclude that, for every x ∈E,
Pπ[X ∈A] = Eπ [Px[X ∈A]] = Px[X ∈A].
Hence PXn[X ∈A] = Pπ[X ∈A] almost surely and thus (with σ = n in (20.4))
Pπ[X ∈A
X0, . . . , Xn] = PXn[X ∈A] = Pπ[X ∈A].
Now A ∈I ⊂σ(X1, X2, . . .); hence
Pπ[X ∈A
X0, . . . , Xn]
n→∞
−→
Pπ[X ∈A
σ(X0, X1, . . .)] = 1{X∈A}.
This implies Pπ[X ∈A] ∈{0, 1}. Hence X is ergodic.
Birkhoff’s ergodic theorem now implies that, for every x ∈E,
1
n
n−1

k=0
1{Xk=x}
n→∞
−→π({x})
Pπ-a.s.
In this sense, π({x}) is the average time X spends in x in the long run. ♦

502
20
Ergodic Theory
Example 20.18 Let P and Q be probability measures on the measurable space
(Ω, A), and let (Ω, A, P, τ) and (Ω, A, Q, τ) be ergodic. Then either P = Q
or P
⊥Q. Indeed, if P
̸= Q, then there exists an f with |f | ≤1 and
3
f dP ̸=
3
f dQ. However, by Birkhoff’s ergodic theorem,
1
n
n−1

k=0
f ◦τ k n→∞
−→
⎧
⎪⎨
⎪⎩

f dP
P-a.s.,

f dQ
Q-a.s.
If we deﬁne A :=
	 1
n
n−1
k=0 f ◦τ k n→∞
−→
3
f dP

, then P(A) = 1 and Q(A) = 0.
Thus P ⊥Q. ♦
Takeaways The ergodic theorem yields a law of large numbers for the
occupation times of a positive recurrent Markov chain. Furthermore, it shows
that two ergodic measures are either equal or mutually singular.
Exercise 20.3.1 Let (Ω, A) be a measurable space and let τ : Ω →Ω be a
measurable map.
(i) Show that the set M := {μ ∈M1(Ω) : μ ◦τ −1 = μ} of τ-invariant measures
is convex.
(ii) An element μ of M is called extremal if μ = λμ1 + (1 −λ)μ2 for some
μ1, μ2 ∈M and λ ∈(0, 1) implies μ = μ1 = μ2. Show that μ ∈M is
extremal if and only if τ is ergodic with respect to μ. ♣
Exercise 20.3.2 Let p = 2, 3, 5, 6, 7, 10, . . . be square-free (that is, there is no
number r = 2, 3, 4, . . ., whose square is a divisor of p) and let q ∈{2, 3, . . ., p−1}.
For every n ∈N, let an be the leading digit of the p-adic expansion of qn.
Show the following version of Benford’s law: For every d ∈{1, . . . , p −1},
1
n#
	
i ≤n : ai = d

 n→∞
−→log(d + 1) −log(d)
log(p)
.
♣
20.4
Application: Recurrence of Random Walks
Let (Xn)n∈N be a stationary process with values in Rd. Deﬁne Sn := n
k=1 Xk for
n ∈N0. Further, let
Rn = #{S1, . . . , Sn}

20.4
Application: Recurrence of Random Walks
503
denote the range of S; that is, the number of distinct points visited by S up to time
n. Finally, let A := {Sn ̸= 0 for every n ∈N} be the event of an “escape” from 0.
Theorem 20.19 We have lim
n→∞
1
nRn = P[A|I] almost surely.
Proof Let X be the canonical process on (Ω, A, P) =

(Rd)N, B(Rd)⊗N, P

and
let τ : Ω →Ω be the shift; that is, Xn = X0 ◦τ n.
Evidently,
Rn = #
	
k ≤n : Sl ̸= Sk for all l ∈{k + 1, . . . , n}

≥#
	
k ≤n : Sl ̸= Sk for all l > k

=
n

k=1
1A ◦τ k.
Birkhoff’s ergodic theorem yields
lim inf
n→∞
1
nRn ≥P[A|I]
a.s.
(20.5)
For the converse inequality, consider Am = {Sl ̸= 0 for l = 1, . . . , m}. Then, for
every n ≥m,
Rn ≤m + #
	
k ≤n −m : Sl ̸= Sk for all l ∈{k + 1, . . . , n}

≤m + #
	
k ≤n −m : Sl ̸= Sk for all l ∈{k + 1, . . . , k + m}

= m +
n−m

k=1
1Am ◦τ k.
Again, by the ergodic theorem,
lim sup
n→∞
1
nRn ≤P[Am
I]
a.s.
(20.6)
Since Am
↓
A and P[Am
I]
m→∞
−→
P[A|I] almost surely (by Theo-
rem 8.14(8.14)), the claim follows from (20.5) and (20.6).
⊓⊔
Theorem 20.20 Let X = (Xn)n∈N be an integer-valued, integrable, stationary
process with the property E[X1
I] = 0 a.s. Let Sn = X1 + . . . + Xn, n ∈N.
Then
P)Sn = 0 for inﬁnitely many n ∈N* = 1.
In particular, a random walk on Z with centered increments is recurrent (Chung–
Fuchs theorem, compare Theorem 17.41).

504
20
Ergodic Theory
Proof Deﬁne A = {Sn ̸= 0 for all n ∈N}.
Step 1.
We show P[A] = 0. (If X is i.i.d., then S is a Markov chain, and this
implies immediately that 0 is recurrent. Only for the more general case of stationary
X do we need an additional argument.) By the ergodic theorem, we have 1
nSn
n→∞
−→
E[X1
I] = 0 a.s. Thus, for every m ∈N,
lim sup
n→∞
1
n
max
k=1,...,n
Sk


= lim sup
n→∞
1
n
max
k=m,...,n
Sk


≤max
k≥m
|Sk|
k
m→∞
−→0.
Therefore,
lim
n→∞
1
n
max
k=1,...,n Sk

= lim
n→∞
1
n
min
k=1,...,n Sk

= 0.
Now Rn
≤1 +

max
k=1,...,n Sk

−

min
k=1,...,n Sk

; hence
1
nRn
n→∞
−→
0. By
Theorem 20.19, this implies P[A] = 0.
Step 2.
Deﬁne σn := inf{m ∈N : Sm+n = Sn}, Bn := {σn < ∞} for n ∈N0 and
B :=
∞

n=0
Bn.
Since {σ0 = ∞} = A, we have P[σ0 < ∞] = 1. By stationarity, P[σn < ∞] = 1
for every n ∈N0; hence P[B] = 1.
Let τ0 = 0 and inductively deﬁne τn+1 = τn + στn for n ∈N0. Then τn is the
time of the nth return of S to 0. On B we have τn < ∞for every n ∈N0 and hence
P)Sn = 0 inﬁnitely often* = P)τn < ∞for all n ∈N* ≥P[B] = 1.
⊓⊔
If in Theorem 20.20 the random variables Xn are not integer-valued, then there is
no hope that Sn = 0 for any n ∈N with positive probability. On the other hand,
in this case, there is also some kind of recurrence property, namely Sn/n
n→∞
−→0
almost surely by the ergodic theorem. Note, however, that this does not exclude the
possibility that Sn
n→∞
−→∞with positive probability; for instance, if Sn grows like
√n. The next theorem shows that if the Xn are integrable, then the process of partial
sums can go to inﬁnity only with a linear speed.
Theorem 20.21 Let (Xn)n∈N be an integrable ergodic process and deﬁne Sn =
X1 + . . . + Xn for n ∈N0. Then the following statements are equivalent.

20.4
Application: Recurrence of Random Walks
505
(i) Sn
n→∞
−→∞almost surely.
(ii) P
'
Sn
n→∞
−→∞
(
> 0.
(iii)
lim
n→∞
Sn
n = E[X1] > 0 almost surely.
If the random variables X1, X2, . . . are i.i.d. with E[X1] = 0 and P[X1 = 0] < 1,
then lim infn→∞Sn = −∞and lim supn→∞Sn = ∞almost surely.
Proof “(i) ⇐⇒(ii)”
Clearly, B := {Sn
n→∞
−→∞} is an invariant event and thus
has probability either 0 or 1.
“(iii) ⇒(i)”
This is trivial.
“(i) ⇒(iii)”
The equality follows by the individual ergodic theorem. Hence, it is
enough to show that lim infn→∞Sn/n > 0 almost surely.
Note that P[B] = 1. For n ∈N0 and ε > 0, let
Aε
n :=
	
Sm > Sn + ε for all m ≥n + 1

∩B.
Let S−:= inf{Sn : n ∈N0}. By assumption (i), we have S−> −∞almost surely
and τ := sup{n ∈N0 : Sn = S−} is ﬁnite almost surely. Hence there is an N ∈N
with P[τ < N] ≥1
2. Therefore,
P
+ N−1

n=0
A0
n
,
= P[τ < N] ≥1
2.
Since Aε
n ↑A0
n for ε ↓0, there is an ε > 0 with p := P
)
Aε
0
*
≥
1
4N > 0. As
(Xn)n∈N is ergodic,

1Aεn

n∈N0 is also ergodic. By the individual ergodic theorem,
we conclude that 1
n
n−1
i=0 1Aε
i
n→∞
−→p almost surely. Hence there exists an n0 =
n0(ω) such that n−1
i=0 1Aε
i ≥pn
2 for all n ≥n0. This implies Sn ≥S−+ pnε
2
for
n ≥n0 and hence lim infn→∞Sn/n ≥pε
2 > 0.
Now we show the additional statement. Assume that E[X1] = 0 and P[X1 =
0] < 1. Hence, there is an ε > 0 such that P[X1 < −2ε] > ε. Let L :=
lim infn→∞Sn. As shown above, we have P[L = ∞] = 0. The event {L > −∞}
is invariant and hence has probability 0 or 1. We assume P[L > −∞] = 1 and
construct a contradiction. Inductively, deﬁne stopping times τ1 := inf{k ∈N :
Sk < L + ε} and
τn+1 := inf{k > τn : Sk < L + ε}
for n ∈N.
By assumption, we have τn < ∞almost surely for all n. Let F = (Fn)n∈N0 =
σ((Xn)n∈N) be the ﬁltration generated by X = (Xn)n∈N. Let Fτn be the σ-algebra

506
20
Ergodic Theory
of τn-past. Deﬁne the events An := {Xτn+1 < −2ε}, n ∈N. On An, we have
Sτn+1 < L −ε. Clearly, An is independent of Fτn and thus
P
)
An
Fτn
*
= P[An] > ε.
By the conditional version of the Borel-Cantelli Lemma (see Exercise 11.2.7), we
infer
P
'
lim sup
n→∞
An
(
= 1.
This shows that almost surely Sτn+1 < L −ε inﬁnitely often and this in turn
contradicts the assumption that L be ﬁnite.
Consequently, we have P[lim infSn = −∞] = 1. The statement for lim sup Sn is
similar.
⊓⊔
Remark 20.22 It can be shown that Theorem 20.21 holds also without the assump-
tion that the Xn are integrable. See [93]. ♦
Takeaways The set of points visited by a random walk within the ﬁrst n
steps grows with n at a speed that is the probability of no return. Hence, in the
recurrent case, the set grows sublinearly. For a random walk on Z with a ﬁnite
ﬁrst moment, this shows that it is recurrent if and only if the increments are
centred. Consequently, for such a random walk, one out of three alternatives
holds: (i) The random walk goes to ∞at positive speed. (ii) The random walk
goes to −∞at positive speed. (iii) The random walk oscillates around 0 with
a growing amplitude. It is impossible that the random walk would go to ∞
(or −∞) slower than linearly.
20.5
Mixing
Ergodicity provides a weak notion of “independence” or “mixing”. At the other end
of the scale, the strongest notion is “i.i.d.”. Here we are concerned with notions of
mixing that lie between these two.
In the following, we always assume that (Ω, A, P, τ) is a measure-preserving
dynamical system and that Xn := X0 ◦τ n. We start with a simple observation.
Theorem 20.23 (Ω, A, P, τ) is ergodic if and only if, for all A, B ∈A,
lim
n→∞
1
n
n−1

k=0
P
'
A ∩τ −k(B)
(
= P[A] P[B].
(20.7)

20.5
Mixing
507
Proof “ ⇒”
Let (Ω, A, P, τ) be ergodic. Deﬁne
Yn := 1
n
n−1

k=0
1τ −k(B) = 1
n
n−1

k=0
1B ◦τ k.
By Birkhoff’s ergodic theorem, we have Yn
n→∞
−→
P[B] almost surely. Hence
Yn 1A
n→∞
−→1A P[B] almost surely. Dominated convergence yields
1
n
n−1

k=0
P
'
A ∩τ −k(B)
(
= E [Yn 1A]
n→∞
−→E [1A P[B]] = P[A] P[B].
“ ⇐ ”
Now assume that (20.7) holds. Let A ∈I (recall that I is the invariant
σ-algebra) and B = A. Evidently, A ∩τ −k(A) = A for every k ∈N0. Hence,
by (20.7),
P[A] = 1
n
n−1

k=0
P
'
A ∩τ −k(A)
( n→∞
−→P[A]2.
Thus P[A] ∈{0, 1}; hence I is trivial and therefore τ is ergodic.
⊓⊔
We consider a strengthening of (20.7).
Deﬁnition 20.24 A measure-preserving dynamical system (Ω, A, P, τ) is called
mixing if
lim
n→∞P
)
A ∩τ −n(B)
*
= P[A] P[B]
for all A, B ∈A.
(20.8)
Remark 20.25 Sometimes the mixing property of (20.8) is called strongly mixing,
in contrast with a weakly mixing system (Ω, A, P, τ), for which we require only
lim
n→∞
1
n
n−1

i=0
P
'
A ∩τ −i(B)
(
−P[A] P[B]
 = 0
for all A, B ∈A.
“Strongly mixing” implies “weakly mixing” (see Exercise 20.5.1). On the other
hand, there exist weakly mixing systems that are not strongly mixing (see [81]). ♦
Example 20.26 Let I = N0 or I = Z, and let (Xn)n∈I be an i.i.d. sequence with
values in the measurable space (E, E). Hence τ is the shift on the product space
Ω = EI, P =

PX0
⊗I . Let A, B ∈E⊗I . For every ε > 0, there exist events Aε
and Bε that depend on only ﬁnitely many coordinates and such that P[A △Aε] < ε
and P[B △Bε] < ε. Clearly, P[τ −n(A △Aε)] < ε and P[τ −n(B △Bε)] < ε for

508
20
Ergodic Theory
every n ∈Z. For sufﬁciently large |n|, the sets Aε and τ −n(Bε) depend on different
coordinates and are thus independent. This implies
lim sup
|n|→∞
P[A ∩τ −n(B)] −P[A] P[B]

≤lim sup
|n|→∞
P[Aε ∩τ −n(Bε)] −P[Aε] P[Bε]
 + 4ε = 4ε.
Hence τ is mixing. Letting A = B ∈I, we obtain the 0-1 law for invariant events:
P[A] ∈{0, 1}. ♦
Remark 20.27 Clearly, (20.8) implies (20.7) and hence “mixing” implies “ergodic”.
The converse implication is false. ♦
Example 20.28 Let Ω = [0, 1), A = B([0, 1)) and let P = λ be the Lebesgue
measure on ([0, 1), B([0, 1))). For r ∈[0, 1), deﬁne τr : Ω →Ω by
τr(x) = x + r −⌊x + r⌋= x + r
(mod 1).
If r is irrational, then τr is ergodic (Example 20.9). However, τr is not mixing:
Since r is irrational, there exists a sequence kn ↑∞such that
τ kn
r (0) ∈
1
4, 3
4

for n ∈N.
Hence, for A =
'
0, 1
4
(
, we have A ∩τ −kn
r
(A) = ∅. Therefore,
lim inf
n→∞P
)
A ∩τ −n
r
(A)
*
= 0 ̸= 1
16 = P[A]2.
♦
Reﬂection Why is τr not mixing if r is rational? ♠
Theorem 20.29 Let X be an irreducible, positive recurrent Markov chain on the
countable space E and let π be its invariant distribution. Let Pπ = 
x∈E
π({x}) Px.
Then:
(i) X is ergodic (on (Ω, A, Pπ)).
(ii) X is mixing if and only if X is aperiodic.
Proof
(i) This has been shown already in Example 20.17.
(ii) As X is irreducible, by Theorem 17.52, we have π({x}) > 0 for every x ∈E.

20.5
Mixing
509
“ ⇒”
Let X be periodic with period d ≥2. If n ∈N is not a multiple of d, then
pn(x, x) = 0. Hence, for A = B = {X0 = x},
lim inf
n→∞Pπ[X0 = x, Xn = x] = lim inf
n→∞π({x}) pn(x, x)
= 0 ̸= π({x})2 = Pπ[X0 = x]2.
Thus X is not mixing.
“ ⇐ ”
Let X be aperiodic. In order to simplify the notation, we may assume
that X is the canonical process on EN0. Let A, B ⊂Ω = EN0 be measurable.
For every ε > 0, there exists an N ∈N and a ˜Aε ∈E{0,...,N} such that, letting
Aε = ˜Aε × E{N+1,N+2,...}, we have P[A △Aε] < ε. By the Markov property, for
every n ≥N,
Pπ
)
Aε ∩τ −n(B)
*
= Pπ
'
(X0, . . . , XN) ∈˜Aε, (Xn, Xn+1, . . .) ∈B
(
=

x,y∈E
Eπ
)1Aε 1{XN =x} 1{Xn=y} (Xn, Xn+1, . . .) ∈B*
=

x,y∈E
Eπ
)
1Aε 1{XN =x}
*
pn−N(x, y)Py [B] .
By Theorem 18.13, we have pn−N(x, y)
n→∞
−→π({y}) for all x, y ∈E. (For
periodic X, this is false.) Dominated convergence thus yields
lim
n→∞Pπ
)
Aε ∩τ −n(B)
*
=

x,y∈E
Eπ
)
1Aε 1{XN =x}
*
π({y})Py[B]
= Pπ
)
Aε*
Pπ[B].
Since
Pπ
)
Aε ∩τ −n(B)
*
−P
)
A ∩τ −n(B)
*  < ε, the statement follows by
letting ε →0.
⊓⊔
Takeaways Mixing is a concept of independence stronger than ergodicity but
weaker than stochastic independence. It allows dependencies between events
as long as they wash out when the events are shifted apart. An irreducible and
aperiodic positive recurrent Markov chain is mixing. Rotations are not.
Exercise 20.5.1 Show that “strongly mixing” implies “weakly mixing”, which in
turn implies “ergodic”. Give an example of a measure-preserving dynamical system
that is ergodic but not weakly mixing. ♣

510
20
Ergodic Theory
20.6
Entropy
The entropy H(P) of a probability distribution P (see Deﬁnition 5.25) measures the
amount of randomness in this distribution. In fact, the entropy of a delta distribution
is zero and for a distribution on n points, the maximal entropy is achieved by the
uniform distribution and equals log(n) (see Exercise 5.3.3). It is natural to use the
entropy in order to quantify also the randomness of a dynamical system.
First we consider the situation of a simple shift: Let Ω = EN0, where E is a ﬁnite
set equipped with the product σ-algebra A = (2E)⊗N0. Let τ be the shift on Ω and
let P be an invariant probability measure. For n ∈N, denote by Pn the projection of
P on En = E{0,...,n−1}; that is,
Pn({(e0, . . . , en−1)}) = P
'
{e0} × . . . × {en−1} × E{n,n+1,...}(
.
Denote by hn the entropy of Pn. By Exercise 5.3.4, the entropy is subadditive:
hm+n ≤hm + hn
for m, n ∈N.
Hence the following limit exists (see Exercise 20.6.2)
h := h(P, τ) := lim
n→∞
1
n hn = inf
n∈N
1
n hn.
Deﬁnition 20.30 (Entropy of the simple shift)
h(P, τ) is called the entropy of
the dynamical system (Ω, A, P, τ).
Example 20.31 Assume that P is a product measure with marginals π on E. Then
h = H(π) = −

e∈E
π({e}) log(π({e})).
♦
Example 20.32 (Markov chain) Let (Xn)n∈N0 be a Markov chain on E with transi-
tion matrix P and stationary distribution π. Let (Ω, A, P, τ) be the corresponding
dynamical system. For x = (x0, . . . , xn−1) and 0 ≤k < n −1, let
p(k, x) = π({xk})P(xk, xk+1) · · · P(xn−2, xn−1).

20.6
Entropy
511
Then the entropy of Pn is (using stationarity of π in the third line)
H(Pn) = −

x0,...,xn−1∈E
p(0, x) log(p(0, x))
= −

x0,...,xn−1∈E
p(0, x)
-
log(π({x0})) +
n−2

k=0
log(P(xk, xk+1))
.
= H(π) −
n−2

k=0

xk,...,xn−1
p(k, x) log(P(xk, xk+1))
= H(π) −(n −1)

x0,x1∈E
π({x0})P(x0, x1) log(P(x0, x1)).
We infer that the entropy of the dynamical system is
h(P, τ) = −

x,y∈E
π({x})P(x, y) log(P(x, y)).
(20.9)
♦
Example 20.33 (Integer rotation) Consider the rotation of Example 20.8. Let n ∈
N \ {1}, E = Z/(n) and let P be the uniform distribution on Ω. Let r ∈{1, . . ., n}
and
τ : Ω →Ω,
x →x + r
(mod n).
Clearly, τ (n) is the identity map, hence hn = h2n = . . . and thus h(P, τ) = 0. ♦
We now come to the situation of the general dynamical system. Let P be a ﬁnite
measurable partition of Ω; that is, P = {A1, . . . , Ak} for certain pairwise disjoint
non-empty sets A1, . . . , Ak ∈A with Ω = A1∪. . .∪Ak. Denote by Pn the partition
that is generated by the sets n−1
l=0 τ −l(Ail), i1, . . . , in ∈{1, . . ., k}. We deﬁne
hn(P, τ; P) = −

A∈Pn
P[A] log(P[A]).
Similarly as in the simple shift case, we obtain the subadditivity of (hn) and thus
the existence of
h(P, τ; P) := lim
n→∞
1
n hn(P, τ; P) = inf
n∈N
1
n hn(P, τ; P).

512
20
Ergodic Theory
Deﬁnition 20.34 (Kolmogorov–Sinai entropy)
The entropy of a (general) mea-
sure-preserving dynamical system (Ω, A, P, τ) is
h(P, τ) = sup
P
h(P, τ; P),
where the supremum is taken over all ﬁnite measurable partitions of Ω.
Theorem 20.35 (Kolmogorov–Sinai)
Let P be a generator of A; that is A =
σ
 
n∈N0 τ −n(P)

. Then
h(P, τ) = h(P, τ; P).
Proof See, e.g., [88, Theorem 3.2.18], [168, Theorem 4.17] or [156].
⊓⊔
The Kolmogorov–Sinai theorem shows that the entropy that was introduced in
Deﬁnition 20.30 for simple shifts coincides with the entropy of Deﬁnition 20.34;
simply take P =
	
{e} × EN, e ∈E} which generates the product σ-algebra on
Ω = EN0.
Example 20.36 (Rotation) We come back to the rotation of Example 20.9. Let Ω =
[0, 1), A = B(Ω), P = λ the Lebesgue measure, r ∈(0, 1) and τr(x) = x +
r (mod 1).
First assume that r is rational. Let P be an arbitrary ﬁnite measurable partition of
Ω. Choose n ∈N such that rn ∈N0. As in Example 20.33 we obtain hn(P, τr; P) =
hkn(P, τr; P) for all k ∈N, hence h(P, τr, P) = 0. Concluding, we get h(P, τr) =
0.
Now assume that r is irrational. Choose the partition P = {[0, 1/2), [1/2, 1)}.
As r is irrational, it is easy to see that A is generated by 
n∈N0 τ −n
r
(P). Hence
h(P, τr) = h(P, τr, P). In order to compute the latter quantity, we ﬁrst determine
the cardinality #Pn. To this end, consider the map
φn : [0, 1) →{0, 1}n
x →

1[1/2,1)(x), 1[1/2,1)(τr(x)), . . . , 1[1/2,1)(τ n−1
r
(x))

Clearly, we have #φn([0, 1)) = #Pn. As x ∈[0, 1) increases, each coordinate
1[1/2,1)(τ k
r (x)), k = 1, . . . , n −1, changes its value exactly twice. Only 1[1/2,1)(x)
changes the value exactly once. Summing up, we get #φn([0, 1)) ≤2n. The
maximal entropy of a probability measure on N points is achieved by the uniform
distribution and is log(N). Consequently, hn(P, τr; P) ≤log(2n). We conclude that
h(P, τr) = h(P, τr; P) = 0.
♦

20.6
Entropy
513
Takeaways The entropy is an important characteristic of a dynamical system.
It measures the amount of new randomness added in each step. For Markov
chains, the entropy can be computed explicitly. This is particularly helpful
in the context of statistical mechanics when a Markov chain is needed that
maximises the entropy under certain constraints.
Exercise 20.6.1 Let Ω = [0, 1) and τ : x →2x (mod 1). Let P be the Lebesgue
measure on Ω. Determine h(P, τ).
Exercise 20.6.2 Let (an)n∈N be a sequence on nonnegative numbers. The sequence
is called subadditive, if am+n ≤am + an for all m, n ∈N. Show that the limit
limn→∞an/n exists and that
lim
n→∞
1
n an = inf
n∈N
1
n an.
♣
Exercise 20.6.3 Let pi be the transition matrix of a Markov chain on the countable
set Ei with entropy hi, i = 1, 2. Compute the entropy of the bivariate chain on E1 ×
E2 with transition matrix p given by p((x1, x2), (y1, y2)) = p1(x1, y1)p2(x2, y2).
♣
Exercise 20.6.4 Consider a Markov chain on E
=
{1, 2, 3} with transition
matrix p.
(i) Which p maximises the entropy?
(ii) Now we set the constraint p(2, 1) = 0. Which p maximises the entropy under
the constraint? ♣

Chapter 21
Brownian Motion
In Example 14.48, we constructed a (canonical) process (Xt)t∈[0,∞) with indepen-
dent stationary normally distributed increments. For example, such a process can
be used to describe the motion of a particle immersed in water or the change of
prices in the stock market. We are now interested in properties of this process X that
cannot be described in terms of ﬁnite-dimensional distributions but reﬂect the whole
path t →Xt. For example, we want to compute the distribution of the functional
F(X) := supt∈[0,1] Xt. The ﬁrst problem that has to be resolved is to show that
F(X) is a random variable.
In this chapter, we investigate continuity properties of paths of stochastic
processes and show how they ensure measurability of some path functionals. Then
we construct a version of X that has continuous paths, the so-called Wiener process
or Brownian motion. Without exaggeration, it can be stated that Brownian motion is
the central object of probability theory.
For further reading, we recommend, e.g., [86, 118, 145, 152].
21.1
Continuous Versions
A priori the paths of a canonical process are of course not continuous since every
map [0, ∞) →R is possible. Hence, it will be important to ﬁnd out which paths are
P-almost surely negligible.
Deﬁnition 21.1 Let X and Y be stochastic processes on (Ω, A, P) with time set
I and state space E. X and Y are called
(i) modiﬁcations or versions of each other if, for any t ∈I, we have
Xt = Yt
P-almost surely,
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_21
515

516
21
Brownian Motion
(ii) indistinguishable if there exists an N ∈A with P[N] = 0 such that
{Xt ̸= Yt} ⊂N
for all t ∈I.
Clearly, indistinguishable processes are modiﬁcations of each other. Under
certain assumptions on the continuity of the paths, however, the two notions
coincide.
Reﬂection Find an example of two stochastic processes that are modiﬁcations of
each other but that are not indistinguishable. ♠
Deﬁnition 21.2 Let (E, d) and (E′, d′) be metric spaces and γ ∈(0, 1]. A map
ϕ : E →E′ is called Hölder-continuous of order γ (brieﬂy, Hölder-γ -continuous)
at the point r ∈E if there exist ε > 0 and C < ∞such that, for any s ∈E with
d(s, r) < ε, we have
d′(ϕ(r), ϕ(s)) ≤C d(r, s)γ .
(21.1)
ϕ is called locally Hölder-continuous of order γ if, for every t ∈E, there exist ε > 0
and C = C(t, ε) > 0 such that, for all s, r ∈E with d(s, t) < ε and d(r, t) < ε,
the inequality (21.1) holds. Finally, ϕ is called Hölder-continuous of order γ if there
exists a C such that (21.1) holds for all s, r ∈E.
In the case γ = 1, Hölder continuity is Lipschitz continuity (see Deﬁnition 13.8).
Furthermore, for E = R and γ > 1, every locally Hölder-γ -continuous function
is constant. Evidently, a locally Hölder-γ -continuous map is Hölder-γ -continuous
at every point. On the other hand, for a function ϕ that is Hölder-γ -continuous at a
given point t, there need not exist an open neighborhood in which ϕ is continuous.
In particular, ϕ need not be locally Hölder-γ -continuous.
Reﬂection Let f : R →R be continuously differentiable. Check that f is Hölder-
γ -continuous for any γ ∈(0, 1]. If the derivative of f is bounded, then f is also
(globally) Hölder-1-continuous, but not necessarily (globally) Hölder-γ -continuous
for any γ ∈(0, 1). ♠
We collect some simple properties of Hölder-continuous functions.
Lemma 21.3 Let I ⊂R and let f : I →R be locally Hölder-continuous of order
γ ∈(0, 1]. Then the following statements hold.
(i) f is locally Hölder-continuous of order γ ′ for every γ ′ ∈(0, γ ).
(ii) If I is compact, then f is Hölder-continuous.
(iii) Let I be a bounded interval of length T > 0. Assume that there exists an ε > 0
and an C(ε) < ∞such that, for all s, t ∈I with |t −s| ≤ε, we have
|f (t) −f (s)| ≤C(ε) |t −s|γ .
Then f is Hölder-continuous of order γ with constant C := C(ε) ⌈T/ε⌉1−γ .

21.1
Continuous Versions
517
Proof
(i) This is obvious since |t −s|γ ≤|t −s|γ ′ for all s, t ∈I with |t −s| ≤1.
(ii) For t ∈I and ε > 0, let Uε(t) := {s ∈I : |s −t| < ε}. For every t ∈I,
choose ε(t) > 0 and C(t) < ∞such that
|f (r) −f (s)| ≤C(t) · |r −s|γ
for all r, s ∈Ut := Uε(t)(t).
There exists a ﬁnite subcovering U′ = {Ut1, . . . , Utn} of the covering U :=
{Ut, t ∈I} of I. Let ϱ > 0 be a Lebesgue number of the covering U′; that is,
ϱ > 0 is such that, for every t ∈I, there exists a U ∈U such that Uϱ(t) ⊂U.
Deﬁne
C := max
	
C(t1), . . . , C(tn), 2∥f ∥∞ϱ−γ 
.
For s, t ∈I with |t −s| < ϱ, there is an i ∈{1, . . . , n} with s, t ∈Uti. By
assumption, we have |f (t) −f (s)| ≤C(ti) |t −s|γ ≤C |t −s|γ . Now let
s, t ∈I with |s −t| ≥ϱ. Then
|f (t) −f (s)| ≤2∥f ∥∞
|t −s|
ϱ
γ
≤C |t −s|γ .
Hence f is Hölder-continuous of order γ with constant C.
(iii) Let n =
O T
ε
P
. For s, t ∈I, by assumption, |t−s|
n
≤ε and thus
|f (t) −f (s)| ≤
n

k=1
f

s + (t −s)k
n

−f

s + (t −s)k −1
n

≤C(ε) n1−γ |t −s|γ = C |t −s|γ .
⊓⊔
Deﬁnition 21.4 (Path properties) Let I ⊂R and let X = (Xt, t ∈I) be a
stochastic process on some probability space (Ω, A, P) with values in a metric
space (E, d). Let γ ∈(0, 1]. For every ω ∈Ω, we say that the map I →E,
t →Xt(ω) is a path of X.
We say that X has almost surely continuous paths, or brieﬂy that X is a.s.
continuous, if for almost all ω ∈Ω, the path t →Xt(ω) is continuous. Similarly,
we deﬁne locally Hölder-γ -continuous paths and so on.
Lemma 21.5 Let X and Y be modiﬁcations of each other. Assume that one of the
following conditions holds.
(i) I is countable.
(ii) I ⊂R is a (possibly unbounded) interval and X and Y are almost surely right
continuous.
Then X and Y are indistinguishable.

518
21
Brownian Motion
Proof Deﬁne Nt := {Xt ̸= Yt} for t ∈I and ¯N = 
t∈I Nt. By assumption,
P[Nt] = 0 for every t ∈I. We have to show that there exists an N ∈A with
¯N ⊂N and P[N] = 0.
(i) If I is countable, then N := ¯N is measurable and P[N] ≤
t∈I P[Nt] = 0.
(ii) Now let I ⊂R be an interval and let X and Y be almost surely right continuous.
Deﬁne
¯R := {X and Y are right continuous}
and choose an R ∈A with R ⊂¯R and P[R] = 1. Deﬁne
I :=
0
Q ∩I,
if I is open to the right,
(Q ∩I) ∪max I,
if I is closed to the right,
and 
N := 
r∈I Nr. By (i), we have P[
N] = 0. Furthermore, for every t ∈I,
Nt ∩R ⊂

r≥t, r∈I
(Nr ∩R) ⊂
N.
Hence
¯N ⊂Rc ∪

t∈I
Nt ⊂Rc ∪
N =: N,
and thus P[N] ≤P[Rc] + P[
N] = 0.
⊓⊔
We come to the main theorem of this section.
Theorem 21.6 (Kolmogorov–Chentsov) Let X = (Xt, t ∈[0, ∞)) be a real-
valued process. Assume for every T > 0, there are numbers α, β, C > 0 such that
E )|Xt −Xs|α* ≤C|t −s|1+β
for all s, t ∈[0, T ].
(21.2)
Then the following statements hold.
(i) There is a modiﬁcation 
X = (
Xt, t ∈[0, ∞)) of X whose paths are locally
Hölder-continuous of every order γ ∈

0, β
α

.
(ii) Let γ ∈

0, β
α

. For every ε > 0 and T < ∞, there exists a number K < ∞
that depends only on ε, T, α, β, C, γ such that
P
'
| ˜Xt −˜Xs| ≤K |t −s|γ , s, t ∈[0, T ]
(
≥1 −ε.
(21.3)

21.1
Continuous Versions
519
Proof
(i) It is enough to show that, for any T > 0, the process X on [0, T ] has a
modiﬁcation XT that is locally Hölder-continuous of any order γ ∈(0, β/α).
For S, T
> 0, by Lemma 21.5, two such modiﬁcations XS and XT are
indistinguishable on [0, S ∧T ]; hence
ΩS,T :=

there is a t ∈[0, S ∧T ] with XT
t ̸= XS
t

is a null set and thus also Ω∞:=

S,T ∈N
ΩS,T is a null set. Therefore, deﬁning
˜Xt(ω) := Xt
t (ω), t ≥0, for ω ∈Ω \ Ω∞, we get that ˜X is a locally Hölder-
continuous modiﬁcation of X on [0, ∞).
Without loss of generality, assume T = 1. We show that X has a continuous
modiﬁcation on [0, 1]. By Markov’s inequality, for every ε > 0,
P [|Xt −Xs| ≥ε] ≤Cε−α |t −s|1+β.
(21.4)
Hence
Xs
s→t
−→Xt
in probability.
(21.5)
The idea is ﬁrst to construct 
X on the dyadic rational numbers and then to
extend it continuously to [0, 1]. To this end, we will need (21.5). In particular,
for γ > 0, n ∈N and k ∈{1, . . . , 2n}, we have
P
)Xk2−n −X(k−1)2−n
 ≥2−γ n*
≤C 2−n(1+β−αγ ).
Deﬁne
An = An(γ ) := 	 max 	|Xk2−n −X(k−1)2−n|, k ∈{1, . . ., 2n}
 ≥2−γ n
and
Bn :=
∞

m=n
Am
and
N := lim sup
n→∞
An =
∞

n=1
Bn.
It follows that, for every n ∈N,
P[An] ≤
2n

k=1
P
)
|Xk2−n −X(k−1)2−n| ≥2−γ n*
≤C 2−n(β−αγ ).

520
21
Brownian Motion
Now ﬁx γ ∈(0, β/α) to obtain
P[Bn] ≤
∞

m=n
P[Am] ≤C 2−(β−αγ )n
1 −2αγ −β
n→∞
−→0,
(21.6)
hence P[N] = 0. Now ﬁx ω ∈Ω \ N and choose n0 = n0(ω) such that
ω ̸∈
∞

n=n0
An. Hence
Xk2−n(ω) −X(k−1)2−n(ω)
 < 2−γ n
for k ∈{1, . . . , 2n}, n ≥n0.
(21.7)
Deﬁne the sets of ﬁnite dyadic rationals Dm = {k2−m, k = 0, . . . , 2m}, and let
D = 
m∈N
Dm. Any t ∈Dm has a unique dyadic expansion
t =
m

i=0
bi(t) 2−i
for some bi(t) ∈{0, 1}, i = 0, . . . , m.
Let m ≥n ≥n0 and s, t ∈Dm, s ≤t with |s −t| ≤2−n. Let u := max(Dn ∩
[0, s]). Then
u ≤s < u + 2−n
and
u ≤t < u + 21−n
and hence bi(t −u) = bi(s −u) = 0 for i < n. Deﬁne
tl = u +
l
i=n
bi(t −u) 2−i
for l = n −1, . . . , m.
Then, we have tn−1 = u and tm = t. Furthermore, tl ∈Dl for l = n, . . . , m and
tl −tl−1 ≤2−l
for l = n, . . . , m.
Hence, by (21.7),
|Xt(ω) −Xu(ω)| ≤
m

l=n
Xtl(ω) −Xtl−1(ω)
 ≤
m

l=n
2−γ l ≤
2−γ n
1 −2−γ .
Analogously, we obtain |Xs(ω) −Xu(ω)| ≤2−γ n(1 −2−γ )−1, and thus
|Xt(ω) −Xs(ω)| ≤2
2−γ n
1 −2−γ .
(21.8)

21.1
Continuous Versions
521
Deﬁne C0 = 21+γ (1 −2−γ )−1 < ∞. Let s, t ∈D with |s −t| ≤2−n0. By
choosing the minimal n ≥n0 such that |t −s| ≥2−n, we obtain by (21.8),
|Xt(ω) −Xs(ω)| ≤C0 |t −s|γ .
(21.9)
As in the proof of Lemma 21.3(iii), we infer (with K := C0 2(1−γ )n0)
|Xt(ω) −Xs(ω)| ≤K |t −s|γ
for all s, t ∈D.
(21.10)
In other words, for dyadic rationals D, X(ω) is (globally) Hölder-γ -continuous.
In particular, X is uniformly continuous on D; hence it can be extended to [0, 1].
For t ∈D, deﬁne 
Xt := Xt. For t ∈[0, 1] \ D and {sn, n ∈N} ⊂D with
sn −→t, the sequence

Xsn(ω)

n∈N is a Cauchy sequence. Hence the limit

Xt(ω) :=
lim
D∋s→t Xs(ω)
(21.11)
exists. Furthermore, the statement analogous to (21.10) holds not only for
s, t ∈D:

Xt(ω) −
Xs(ω)
 ≤K |t −s|γ
for all s, t ∈[0, 1].
(21.12)
Hence 
X is locally Hölder-continuous of order γ . By (21.5) and (21.11), we
have P
)
Xt ̸= 
Xt
*
= 0 for every t ∈[0, 1]. Hence 
X is a modiﬁcation of X.
(ii) Let ε > 0 and choose n ∈N large enough that (see (21.6))
P[Bn] ≤C 2−(β−αγ )n
1 −2αγ −β < ε.
For ω ̸∈Bn, we conclude that (21.10) holds. However, this is exactly (21.3) with
T = 1. For general T , the claim follows by linear scaling.
⊓⊔
Remark 21.7 The statement of Theorem 21.6 remains true if X assumes values in
some Polish space (E, ϱ) since in the proof we did not make use of the assumption
that the range was in R. However, if we change the time set, then the assumptions
have to be strengthened: If (Xt)t∈Rd is a process with values in E, and if, for certain
α, β > 0, all T > 0 and some C < ∞, we have
E[ϱ(Xt, Xs)α] ≤C ∥t −s∥d+β
2
for all s, t ∈[−T, T ]d,
(21.13)
then for every γ ∈(0, β/α), there is a locally Hölder-γ -continuous version of X. ♦

522
21
Brownian Motion
Takeaways The distribution of a stochastic process determines only proper-
ties that can be described by the values at countably many time points. For
example, continuity is not among those properties. Under certain moment
conditions, a stochastic process X allows for a modiﬁcation
˜X that is
continuous and equals X with probability 1 at any given time.
Exercise 21.1.1 Show the claim of Remark 21.7. ♣
Exercise 21.1.2 Let X = (Xt)t≥0 be a real-valued process with continuous paths.
Show that, for all 0 ≤a < b, the map ω →
3 b
a Xt(ω) dt is measurable. ♣
Exercise 21.1.3 (Optional sampling/ stopping)
Let F be a ﬁltration and let
(Xt)t≥0 be an F-supermartingale with right continuous paths. Let σ and τ be
bounded stopping times with σ
≤τ. Deﬁne σ n
:= 2−n⌈2nσ⌉and τ n
:=
2−n⌈2nτ⌉.
(i) Show that E[Xτ m |Fσ n]
n→∞
−→E[Xτ m |Fσ] almost surely and in L1 as well as
Xσn
n→∞
−→Xσ almost surely and in L1.
(ii) Infer the optional sampling theorem for right continuous supermartingales by
using the analogous statement for discrete time (Theorem 10.11); that is, Xσ ≥
E[Xτ |Fσ].
(iii) Show that if Y is adapted, integrable and right continuous, then Y is a
martingale if and only if E[Yτ ] = E[Y0] for every bounded stopping time τ.
(iv) Assume that X is uniformly integrable and that σ ≤τ are ﬁnite (not necessarily
bounded) stopping times. Show that Xσ ≥E[Xτ |Fσ].
(v) Now let τ be an arbitrary stopping time. Deduce the optional stopping
theorem for right continuous supermartingales: (Xτ∧t)t≥0 is a right continuous
supermartingale. ♣
Exercise 21.1.4 Let X = (Xt)t≥0 be a stochastic process on (Ω, F, P) with values
in the Polish space E and with right continuous paths. Show the following.
(i) The map (ω, t) →Xt(ω) is measurable with respect to F⊗B([0, ∞)) – B(E).
(ii) If in addition X is adapted to the ﬁltration F, then for any t ≥0, the map
Ω × [0, t] →E, (ω, s) →Xs(ω) is Ft ⊗B([0, t]) – B(E) measurable.
(iii) If τ is an F-stopping time and X is adapted, then Xτ is an Fτ-measurable
random variable. ♣
21.2
Construction and Path Properties
Deﬁnition 21.8 A real-valued stochastic process B = (Bt, t ∈[0, ∞)) is called a
Brownian motion if

21.2
Construction and Path Properties
523
0
0.5
1
1.5
2
2.5
3
0.5
1
1.5
2
Fig. 21.1 Computer simulation of a Brownian motion.
(i) B0 = 0,
(ii) B has independent, stationary increments (compare Deﬁnition 9.7),
(iii) Bt ∼N0,t for all t > 0, and
(iv) t →Bt is P-almost surely continuous.
See Fig. 21.1 for a computer simulation of a Brownian motion.
Theorem 21.9 There exists a probability space (Ω, A, P) and a Brownian motion
B on (Ω, A, P). The paths of B are a.s. locally Hölder-γ -continuous for every
γ < 1
2.
Proof As in Example 14.48 or Corollary 16.10 there exists a stochastic process X
that fulﬁlls (i), (ii) and (iii). Evidently, Xt −Xs
D= √t −s X1 ∼N0,t−s for all
t > s ≥0. Thus, for every n ∈N, writing Cn := E[X2n
1 ] = (2n)!
2nn! < ∞, we have
E
'
(Xt −Xs)2n(
= E
'√
t −s X1
2n(
= Cn |t −s|n .
Now let n ≥2 and γ ∈(0, n−1
2n ). Theorem 21.6 yields the existence of a version B
of X that has Hölder-γ -continuous paths. Since all continuous versions of a process
are equivalent, B is locally Hölder-γ -continuous for every γ ∈(0, n−1
2n ) and every
n ≥2 and hence for every γ ∈(0, 1
2).
⊓⊔

524
21
Brownian Motion
Recall that a stochastic process (Xt)t∈I is called a Gaussian process if, for every
n ∈N and for all t1, . . . , tn ∈I, we have that
(Xt1, . . . , Xtn)
is n-dimensional normally distributed.
X is called centered if E[Xt] = 0 for every t ∈I. The map
Γ (s, t) := Cov[Xs, Xt]
for s, t ∈I
is called the covariance function of X.
Remark 21.10 The covariance function determines the ﬁnite-dimensional distribu-
tions of a centered Gaussian process since a multidimensional normal distribution
is determined by the vector of expectations and by the covariance matrix. ♦
Theorem 21.11 Let X = (Xt)t∈[0,∞) be a stochastic process. Then the following
are equivalent:
(i) X is a Brownian motion.
(ii) X is a continuous centered Gaussian process with Cov[Xs, Xt] = s ∧t for all
s, t ≥0.
Proof By Remark 21.10, X is characterized by (ii). Hence, it is enough to show
that, for Brownian motion X, we have Cov[Xs, Xt] = min(s, t). This is indeed true
since for t > s, the random variables Xs and Xt −Xs are independent; hence
Cov[Xs, Xt] = Cov[Xs, Xt −Xs] + Cov[Xs, Xs] = Var[Xs] = s.
⊓⊔
Reﬂection Let X = (X(s,t))s,t≥0 be a centred Gaussian process on the time set
[0, ∞)2 with covariance function
Cov[X(s,t), X(s′,t′)] = (s ∧s′) · (t ∧t′).
Check that there exists a continuous modiﬁcation of X. This modiﬁcation is called
Brownian sheet. ♠♠
Corollary 21.12 (Scaling property of Brownian motion) If B is a Brownian
motion and if K ̸= 0, then (K−1BK2 t)t≥0 is also a Brownian motion.
Example 21.13 Another example of a continuous Gaussian process is the so-called
Brownian bridge X = (Xt)t∈[0,1] that is deﬁned by the covariance function
Γ (s, t) = s ∧t −st. We construct the Brownian bridge as follows.
Let B = (Bt, t ∈[0, 1]) be a Brownian motion and let
Xt := Bt −tB1.

21.2
Construction and Path Properties
525
Clearly, X is a centered Gaussian process with continuous paths. We compute the
covariance function Γ of X,
Γ (s, t) = Cov[Xs, Xt] = Cov[Bs −sB1, Bt −tB1]
= Cov[Bs, Bt] −s Cov[B1, Bt] −t Cov[Bs, B1] + st Cov[B1, B1]
= min(s, t) −st −st + st = min(s, t) −st.
♦
(21.14)
Theorem 21.14 Let (Bt)t≥0 be a Brownian motion and
Xt =

tB1/t,
if t > 0,
0,
if t = 0.
Then X is a Brownian motion.
Proof Clearly, X is a Gaussian process. For s, t > 0, we have
Cov[Xs, Xt] = ts · Cov[B1/s, B1/t] = ts min

s−1, t−1
= min(s, t).
Clearly, t →Xt is continuous at every point t > 0. To show continuity at t = 0,
consider
lim sup
t↓0
Xt = lim sup
t→∞
1
t Bt
≤lim sup
n→∞
1
nBn + lim sup
n→∞
1
n sup 	Bt −Bn, t ∈[n, n + 1]
.
By the strong law of large numbers, we have limn→∞1
nBn = 0 a.s. Using a
generalization of the reﬂection principle (Theorem 17.15; see also Theorem 21.19),
for x > 0, we have (using the abbreviation B[a,b] := {Bt : t ∈[a, b]})
P
)
sup B[n,n+1] −Bn > x
*
= P
)
sup B[0,1] > x
*
= 2 P[B1 > x]
=
2
√
2π
 ∞
x
e−u2/2 du ≤1
x e−x2/2.
In particular,
∞

n=1
P) sup B[n,n+1] −Bn > nε* < ∞for every ε > 0. By the Borel–
Cantelli lemma (Theorem 2.7), we infer
lim sup
n→∞
1
n sup
	
Bt −Bn, t ∈[n, n + 1]

= 0
almost surely.
Hence X is also continuous at 0.
⊓⊔

526
21
Brownian Motion
Theorem 21.15 (Blumenthal’s 0-1 law, see [18]) Let B be a Brownian motion
and let F = (Ft)t≥0 = σ(B) be the ﬁltration generated by B. Further, let F+
0 =

t>0 Ft. Then F+
0 is a P-trivial σ-algebra.
Proof Deﬁne Y n = (B2−n+t −B2−n)t∈[0,2−n], n ∈N. Then (Y n)n∈N is an indepen-
dent family of random variables (with values in C([0, 2−n])). By Kolmogorov’s 0-1
law (Theorem 2.37), the tail σ-algebra T = 
n∈N σ(Y m, m ≥n) is P-trivial. On
the other hand, σ(Y m, m ≥n) = F2−n+1; hence
F+
0
=

t>0
Ft =

n∈N
F2−n+1 = T
is P-trivial.
⊓⊔
Example 21.16 Let B be a Brownian motion. For every K > 0, we have
P
)
inf
	
t > 0 : Bt ≥K
√
t

= 0
*
= 1.
(21.15)
To check this, deﬁne As :=
	
inf{t > 0 : Bt ≥K
√
t } ≤s

and
A :=

inf
	
t > 0 : Bt ≥K
√
t

= 0

=

s>0
As ∈F+
0 .
Then P[A] ∈{0, 1}. By the scaling property of Brownian motion,
P[A] = inf
s>0P[As] ≥P[B1 ≥K] > 0
and thus P[A] = 1. ♦
The preceding example shows that, for every t ≥0, almost surely B is not
Hölder- 1
2-continuous at t. Note that the order of quantiﬁers is subtle. We have not
shown that almost surely B was not Hölder- 1
2-continuous at any t ≥0 (however,
see Remark 22.4). However, it is not too hard to show the following theorem, which
for the case γ = 1 is due to Paley, Wiener and Zygmund [126]. The proof presented
here goes back to an idea of Dvoretzky, Erdös and Kakutani (see [40]).
Theorem 21.17 (Paley–Wiener–Zygmund [126]) For every γ > 1
2, almost surely
the paths of Brownian motion (Bt)t≥0 are not Hölder-continuous of order γ at any
point. In particular, the paths are almost surely nowhere differentiable.
Proof Let γ > 1
2. It sufﬁces to consider B = (Bt)t∈[0,1]. Denote by Hγ,t the set of
maps [0, 1] →R that are Hölder-γ -continuous at t and deﬁne Hγ := 
t∈[0,1) Hγ,t.
The aim is to show that almost surely B ̸∈Hγ . By translation invariance, this
implies that B is nowhere Hölder-γ -continuous a.s. in any of the countably many
intervals [n/2, (n/2) + 1), n ∈N0, which implies the claim of the theorem.

21.2
Construction and Path Properties
527
If t ∈[0, 1) and w ∈Hγ,t, then for every δ > 0 there exists a c = c(δ, w) with
the property |ws −wt| ≤c |s −t|γ for every s ∈[0, 1] with |s −t| < δ. Choose a
k ∈N with k >
2
2γ −1. Then, for n ∈N with n ≥n0 := ⌈(k + 1)/δ⌉, i = ⌊tn⌋+ 1
and l ∈{0, . . . , k −1}, we get
w(i+l+1)/n −w(i+l)/n
 ≤
w(i+l+1)/n −wt
 +
w(i+l)/n −wt
 ≤2c (k + 1)γ n−γ .
Hence, for N ≥2c (k + 1)γ , we have w ∈AN,n,i, where
AN,n,i :=
k−1

l=0

w :
w(i+l+1)/n −w(i+l)/n
 ≤N n−γ 
.
Deﬁne AN,n = n
i=1 AN,n,i, AN = lim infn→∞AN,n and A = ∞
N=1 AN. Clearly,
Hγ ⊂A. Owing to the independence of increments and since the density of the
standard normal distribution is bounded by 1, we get
P[B ∈AN,n,i] = P
)
|B1/n| ≤N n−γ *k = P
)
|B1| ≤N n−γ +1/2*k
≤Nk nk(−γ +1/2).
By the choice of k and since the increments of B are stationary, we have
P
)
B ∈AN
*
= lim
n→∞P
+
B ∈

m≥n
AN,m
,
≤lim sup
n→∞
P[B ∈AN,n]
≤lim sup
n→∞
n

i=1
P[B ∈AN,n,i]
≤lim sup
n→∞
n P[B ∈AN,n,1]
≤Nk lim sup
n→∞
n1+k(−γ +1/2) = 0
Thus P[B ∈A] = 0. Therefore, we almost surely have B ̸∈Hγ .
⊓⊔

528
21
Brownian Motion
Takeaways We have used the Kolmogorov-Chentsov theorem to construct
Brownian motion as a continuous Gaussian process. The paths are Hölder
continuous of any order less than 1/2, but almost surely they are not Hölder
continuous of any order larger than 1/2 at any point. In particular, the paths
are almost surely nowhere differentiable. Any property of Brownian motion
that can be checked arbitrarily early after time 0 has either probability 0 or 1.
Exercise 21.2.1 Let B be a Brownian motion and let λ be the Lebesgue measure
on [0, ∞).
(i) Compute the expectation and variance of
3 1
0 Bs ds. (For the measurability of
the integral see Exercise 21.1.2.)
(ii) Show that almost surely λ

{t : Bt = 0}

= 0.
(iii) Compute the expectation and variance of
 1
0

Bt −
 1
0
Bs ds
2
dt.
♣
Exercise 21.2.2 Let B be a Brownian motion. Show that (B2
t −t)t≥0 is a martingale.
♣
Exercise 21.2.3 Let B be a Brownian motion and σ > 0. Show that the process

exp

σBt −σ 2
2 t

t≥0 is a martingale. ♣
Exercise 21.2.4 Let B be a Brownian motion, a < 0 < b. Deﬁne the stopping time
τa,b = inf{t ≥0 : Bt ∈{a, b}}.
Show that almost surely τa,b < ∞and that P[Bτa,b = b] = −
a
b−a. Furthermore,
show (using Exercise 21.2.2) that E[τa,b] = −ab. ♣
Exercise 21.2.5 Let B be a Brownian motion, b > 0 and τb = inf{t ≥0 : Bt = b}.
Show the following.
(i) E[e−λτb] = e−b
√
2λ for λ ≥0. (Hint: Use Exercise 21.2.3 and the optional
sampling theorem.)
(ii) τb has a 1
2-stable distribution with Lévy measure
ν(dx) =

b/(
√
2π)

x−3/2 1{x>0} dx.
(iii) The distribution of τb has density fb(x) =
b
√
2π e−b2/(2x) x−3/2. ♣
Exercise 21.2.6 Let B be a Brownian motion, a ∈R, b > 0 and τ = inf{t ≥0 :
Bt = at + b}. For λ ≥0, show that
E
)
e−λτ*
= exp

−ba −b
2
a2 + 2λ

.

21.3
Strong Markov Property
529
Conclude that P[τ < ∞] = 1 ∧e−2ba. ♣
21.3
Strong Markov Property
Denote by Px the probability measure such that B = (Bt)t≥0 is a Brownian motion
started at x ∈R. To put it differently, under Px, the process (Bt −x)t≥0 is a standard
Brownian motion. While the (simple) Markov property of (B, (Px)x∈R) is evident,
it takes some work to check the strong Markov property.
Theorem 21.18 (Strong Markov property) Brownian motion B with distribu-
tions (Px)x∈R has the strong Markov property.
Proof Let F = σ(B) be the ﬁltration generated by B and let τ < ∞be an F-
stopping time. We have to show that, for every bounded measurable F : R[0,∞) →
R, we have:
Ex
)F(Bt+τ)t≥0
Fτ
* = EBτ [F(B)].
(21.16)
It is enough to consider continuous bounded functions F that depend on only ﬁnitely
many coordinates t1, . . . , tN since these functions determine the distribution of
(Bt+τ)t≥0. Hence, let f : RN →R be continuous and bounded and F(B) =
f (Bt1, . . . , BtN ). Manifestly, the map
x →Ex[F(B)] = E0[f (Bt1 + x, . . ., BtN + x)]
is continuous and bounded. Now let τ n := 2−n⌊2nτ + 1⌋for n ∈N. Then τ n is a
stopping time and τ n ↓τ; hence Bτ n
n→∞
−→Bτ almost surely. Now every Markov
process with countable time set (here all positive rational linear combinations of
1, t1, . . . , tN) is a strong Markov process (by Theorem 17.14); hence we have
Ex
)F(Bτ n+t)t≥0
Fτ n* = Ex
)f (Bτ n+t1, . . . , Bτ n+tN )
Fτ n*
= EBτn
)
f (Bt1, . . . , BtN )
*
n→∞
−→EBτ
)
f (Bt1, . . . , BtN )
*
= EBτ [F(B)].
(21.17)
As B is right continuous, we have F

(Bτ n+t)t≥0
 n→∞
−→F

(Bτ+t)t≥0

almost
surely and in L1 and thus
E
'Ex
)
F

(Bτ n+t)t≥0
Fτ n*
−Ex
)
F

(Bτ+t)t≥0
Fτ n*
(
≤Ex
'F

(Bτ n+t)t≥0

−F

(Bτ+t)t≥0

( n→∞
−→0.
(21.18)

530
21
Brownian Motion
Furthermore,
Fτ n ↓Fτ+ :=

σ>τ is a stopping time
Fσ ⊃Fτ.
In fact, obviously, we have Fτn ⊃Fτ+ for all n. On the other hand, for A ∈

n∈N Fτn and σ > τ a stopping time, we have for all t
Ft ∋A ∩{τn ≤t} ∩{σ ≤t} = A ∩{(σ ∨τn) ≤t} ↑A ∩{σ ≤t}.
Hence, A ∈Fσ ⊂Fτ+.
By (21.17) and (21.18), using the convergence theorem for backwards martin-
gales (Theorem 12.14), we get that in the sense of L1-limits
EBτ [F(B)] = lim
n→∞Ex
)
F

(Bτ n+t)t≥0
Fτ n*
= lim
n→∞Ex
)
F

(Bτ+t)t≥0
Fτ n*
= Ex
)
F

(Bτ+t)t≥0
Fτ+
*
.
The left-hand side is Fτ-measurable. The tower property of conditional expectation
thus yields (21.16).
⊓⊔
Using the strong Markov property, we show the reﬂection principle for Brownian
motion.
Theorem 21.19 (Reﬂection principle for Brownian motion) For every a > 0 and
T > 0,
P
)
sup
	
Bt : t ∈[0, T ]

> a
*
= 2 P[BT > a] ≤2
√
T
√
2π
1
a e−a2/2T .
Proof By the scaling property of Brownian motion (Corollary 21.12), without loss
of generality, we may assume T = 1. Let τ := inf{t ≥0 : Bt ≥a} ∧1. By the
strong Markov property, (B′
t)t≥0 := (Bτ+t)t≥0 is a Brownian motion started at a
and is independent of Fτ. By symmetry, we have Pa[B′
1−τ > a|τ < 1] = 1
2; hence
P[B1 > a] = P[B1 > a
τ < 1] P[τ < 1]
= Pa[B1−τ > a] P[τ < 1] = 1
2 P[τ < 1].
For the inequality compute
P[B1 > a] =
1
√
2π
 ∞
a
e−x2/2 dx
≤
1
√
2π
1
a
 ∞
a
x e−x2/2 dx =
1
√
2π
1
a e−a2/2.
⊓⊔

21.3
Strong Markov Property
531
As an application of the reﬂection principle we derive Paul Lévy’s arcsine law
[107, page 216] for the last time a Brownian motion visits zero.
Theorem 21.20 (Lévy’s arcsine law) Let T > 0 and ζT := sup{t ≤T : Bt = 0}.
Then, for t ∈[0, T ],
P
)
ζT ≤t
*
= 2
π arcsin
2
t/T

.
Proof Without loss of generality, assume T = 1 and ζ = ζ1. Let 
B be a further,
independent Brownian motion. By the reﬂection principle,
P[ζ ≤t] = P
)
Bs ̸= 0 for all s ∈[t, 1]
*
=
 ∞
−∞
P
)
Bs ̸= 0 for all s ∈[t, 1]
Bt = a
*
P[Bt ∈da]
=
 ∞
−∞
P|a|
)
Bs > 0 for all s ∈[0, 1 −t]
*
P[Bt ∈da]
=
 ∞
−∞
P0
)
|
B1−t| ≤|a|
*
P[Bt ∈da]
= P
)
|
B1−t| ≤|Bt|
*
.
If X and Y are independent and N0,1-distributed, then
Bt, 
B1−t
 D= √
t X,
√
1 −t Y.
Hence
P[ζ ≤t] = P)√
1 −t |Y| ≤
√
t |X|*
= P)Y 2 ≤t(X2 + Y 2)*
= 1
2π
 ∞
−∞
dx
 ∞
−∞
dy e−(x2+y2)/2 1{y2≤t(x2+y2)}.
Passing to polar coordinates, we obtain
P[ζ ≤t] = 1
2π
 ∞
0
r dre−r2/2
 2π
0
dϕ 1{sin(ϕ)2≤t} = 2
π arcsin
√
t

.
⊓⊔

532
21
Brownian Motion
Takeaways Brownian motion can be constructed as a strong Markov process.
This is the starting point for many conclusions. As examples, we have shown
the reﬂection principle and Lévy’s arcsine law.
Exercise 21.3.1 (Hard problem!) Let Px be the distribution of Brownian motion
started at x ∈R. Let a > 0 and τ = inf
	
t ≥0 : Bt ∈{0, a}

. Use the reﬂection
principle to show that, for every x ∈(0, a),
Px[τ > T ] =
∞

n=−∞
(−1)n Px
)
BT ∈[na, (n + 1)a]
*
.
(21.19)
If f is the density of a probability distribution on R with characteristic function ϕ
and supx∈R x2f (x) < ∞, then the Poisson summation formula holds,
∞

n=−∞
f (s + n) =
∞

k=−∞
ϕ(k) e2πis
for all s ∈R.
(21.20)
Use (21.19) and (21.20) (compare also (21.38)) to conclude that
Px[τ > T ] = 4
π
∞

k=0
1
2k+1 exp

−(2k+1)2π2 T
2a2

sin

(2k+1)πx
a

.
(21.21)
♣
21.4
Supplement: Feller Processes
In many situations, a continuous version of a process would be too much to expect,
for instance, the Poisson process is generically discontinuous. However, often there
is a version with right continuous paths that have left-sided limits. At this point,
we only brieﬂy make plausible the existence theorem for such regular versions of
processes in the case of so-called Feller semigroups.
Deﬁnition 21.21 Let E be a Polish space. A map f : [0, ∞) →E is called RCLL
(right continuous with left limits) or càdlàg (continue à droit, limites à gauche) if
f (t) = f (t+) := lims↓t f (s) for every t ≥0 and if, for every t > 0, the left-sided
limit f (t−) := lims↑t f (s) exists and is ﬁnite.
Deﬁnition 21.22 A ﬁltration F = (Ft)t≥0 is called right continuous if F = F+,
where F+
t
= 
s>t Fs. We say that a ﬁltration F satisﬁes the usual conditions (from
the French conditions habituelles) if F is right continuous and if F0 is P-complete.

21.4
Supplement: Feller Processes
533
Remark 21.23 If F is an arbitrary ﬁltration and F+,∗
t
is the completion of F+
t , then
F+,∗satisﬁes the usual conditions. ♦
Theorem 21.24 (Doob’s regularization) Let F be a ﬁltration that satisﬁes the
usual conditions and let X = (Xt)t≥0 be an F-supermartingale such that t →
E[Xt] is right continuous. Then there exists a modiﬁcation 
X of X with RCLL paths.
Proof For a, b ∈Q+, a < b and I ⊂[0, ∞), let Ua,b
I
be the number of upcrossings
of (Xt)t∈I over [a, b]. By the upcrossing inequality (Lemma 11.3), for every N > 0
and every ﬁnite set I ⊂[0, N], we have E[Ua,b
I
] ≤(E[|XN|]+|a|)/(b −a). Deﬁne
Ua,b
N
= Ua,b
Q+∩[0,N]. Then E[Ua,b
N ] ≤(E[|XN|] + |a|)/(b −a). By Exercise 11.1.1,
for λ > 0, we have
λ P
)
sup{|Xt| : t ∈Q+ ∩[0, N]} > λ
*
= λ sup

P
)
sup{|Xt| : t ∈I} > λ
*
: I ⊂Q+ ∩[0, N] ﬁnite

≤6 E[|X0|] + 4 E[|XN|].
Consider the event
A :=

N∈N


a,b∈Q+
0≤a<b≤N
{Ua,b
N
< ∞} ∩
	
sup{|Xt| : t ∈Q+ ∩[0, N]} < ∞


.
We have P[A] = 1; hence A ∈Ft for every t ≥0 since F satisﬁes the usual
conditions. For ω ∈A, for every t ≥0, the limit

Xt(ω) :=
lim
Q+∋s↓t, s>t Xs(ω)
exists and is RCLL. For ω ∈Ac, we deﬁne 
Xt(ω) = 0. As F satisﬁes the usual
conditions, 
X is F-adapted. As X is a supermartingale, for every N, the family
(Xs)s≤N is uniformly integrable. Hence, by assumption,
E[
Xt] =
lim
Q+∋s↓t, s>t E[Xs] = E[Xt].
However, since X is a supermartingale, for every s > t, we have
Xt ≥E[Xs |Ft]
Q+∋s↓t, s>t
−→
E[
Xt |Ft] = 
Xt
in L1.
Therefore, Xt = 
Xt almost surely and hence 
X is a modiﬁcation of X.
⊓⊔
Reﬂection Why cannot we drop the assumption that t →E[Xt] be right continu-
ous? ♠

534
21
Brownian Motion
Corollary 21.25 Let (νt)t≥0 be a continuous convolution semigroup and assume
that
3
|x|ν1(dx) < ∞. Then there exists a Markov process X with RCLL paths and
with independent stationary increments PXt−Xs = νt−s for all t > s.
Let E be a locally compact Polish space and let C0(E) be the set of (bounded)
continuous functions that vanish at inﬁnity. If κ is a stochastic kernel from E to E
and if f is measurable and bounded, then we deﬁne κf (x) =
3
κ(x, dy) f(y).
Deﬁnition 21.26 A Markov semigroup (κt)t≥0 on E is called a Feller semigroup if
f (x) = lim
t→0 κtf (x)
for all x ∈E, f ∈C0(E)
and κtf ∈C0(E) for every f ∈C0(E).
Let X be a Markov process with transition kernels (κt)t≥0 and with respect to a
ﬁltration F that satisﬁes the usual conditions.
Let g ∈C0(E), g ≥0. Let h =
3 ∞
0
e−tκtg dt. Then
e−sκsh = e−s
 ∞
0
e−tκsκtg dt =
 ∞
s
e−tκtg dt ≤h.
Hence Xg := (e−th(Xt))t≥0 is an F-supermartingale.
The Feller property and Theorem 21.24 ensure the existence of an RCLL version

Xg of Xg. It takes a little more work to show that there exists a countable set G ⊂
C0(E) and a process 
X that is uniquely determined by 
Xg, g ∈G, and is an RCLL
version of X. See, e.g., [147, Chapter III.7ff].
Let us take a moment’s thought and look back at how we derived the strong
Markov property of Brownian motion in Sect. 21.3. Indeed, there we needed only
right continuity of the paths and a certain continuity of the distribution as a function
of the starting point, which is exactly the Feller property. With a little more work,
one can show the following theorem (see, e.g., [147, Chapter III.8ff] or [145,
Chapter III, Theorem 2.7]).
Theorem 21.27 Let (κt)t≥0 be a Feller semigroup on the locally compact Polish
space E. Then there exists a strong Markov process (Xt)t≥0 with RCLL paths and
transition kernels (κt)t≥0.
Such a process X is called a Feller process.
Takeaways A Feller semigroup of stochastic kernels is a Markov semigroup
with just enough additional regularity such that we can construct an RCLL
version of the corresponding Markov process.

21.5
Construction via L2-Approximation
535
Exercise 21.4.1 (Doob’s inequality) Let X
= (Xt)t≥0 be a martingale or a
nonnegative submartingale with RCLL paths. For T ≥0, let |X|∗
T =
sup
t∈[0,T ]
|Xt|.
Show Doob’s inequalities:
(i) For any p ≥1 and λ > 0, we have λp P
)
|X|∗
T ≥λ
*
≤E
)
|XT |p*
.
(ii) For any p > 1, we have E
)
|XT |p*
≤E
)
(|X|∗
T )p*
≤

p
p−1
p
E
)
|XT |p*
.
Construct a counterexample that shows that right continuity of the paths of X is
essential. ♣
Exercise 21.4.2 (Martingale convergence theorems) Let X be a stochastic pro-
cess with RCLL paths. Use Doob’s inequality (Exercise 21.4.1) to show that
the martingale convergence theorems (a.s. convergence (Theorem 11.4), a.s. and
L1-convergence for uniformly integrable martingales (Theorem 11.7) and the Lp-
martingale convergence theorem (Theorem 11.10)) hold for X. ♣
Exercise 21.4.3 Let p ≥1 and let X1, X2, X3, . . . be Lp-integrable martingales.
Assume that, for every t ≥0, there exists an 
Xt ∈Lp(P) such that Xn
t
n→∞
−→
Xt in
Lp.
(i) Show that (
Xt)t≥0 is a martingale.
(ii) Use Doob’s inequality to show the following. If p > 1 and if X1, X2, . . . are
a.s. continuous, then there is a continuous martingale X with the following
properties: X is a modiﬁcation of 
X and Xn
t
n→∞
−→Xt in Lp for every t ≥0.
♣
Exercise 21.4.4 Let X be a stochastic process with values in a Polish space E and
with RCLL paths. Let F = σ(X) be the ﬁltration generated by X and deﬁne F+ :=
(F+
t )t≥0 by F+
t
= 
s>t Fs. Let U ⊂E be open and let C ⊂E be closed. For
every set A ⊂E, deﬁne τA := inf{t > 0 : Xt ∈A}. Show the following.
(i) τC is an F-stopping time (and an F+-stopping time).
(ii) τU is an F+-stopping time but in general (even for continuous X) is not an
F-stopping time. ♣
Exercise 21.4.5 Show the statement of Remark 21.23. Conclude that if F is a
ﬁltration and if B is a Brownian motion that is an F-martingale, then B is also
an F+,∗-martingale. ♣
21.5
Construction via L2-Approximation
We give an alternative construction of Brownian motion by functional analytic
means as an L2-approximation. For simplicity, as the time interval we take [0, 1]
instead of [0, ∞).

536
21
Brownian Motion
Let H = L2([0, 1]) be the Hilbert space of square integrable (with respect to
Lebesgue measure λ) functions [0, 1] →R with inner product
⟨f, g⟩=

[0,1]
f (x)g(x) λ(dx)
and with norm ∥f ∥= √⟨f, f ⟩(compare Sect. 7.3). Two functions f, g ∈H are
considered equal if f = g λ-a.e. Let (bn)n∈N be an orthonormal basis (ONB) of H;
that is, ⟨bm, bn⟩= 1{m=n} and
lim
n→∞
;;;f −
n

m=1
⟨f, bm⟩bm
;;; = 0
for all f ∈H.
In particular, for every f ∈H, Parseval’s equation
∥f ∥2 =
∞

m=1
⟨f, bm⟩2
(21.22)
holds and for f, g ∈H
⟨f, g⟩=
∞

m=1
⟨f, bm⟩⟨g, bm⟩.
(21.23)
Now consider an i.i.d. sequence (ξn)n∈N of N0,1-random variables on some
probability space (Ω, A, P). For n ∈N and t ∈[0, 1], deﬁne
Xn
t =

1[0,t](s)
 n

m=1
ξmbm(s)

λ(ds) =
n

m=1
ξm⟨1[0,t], bm⟩.
Clearly, for n ≥m,
E)(Xm
t −Xn
t )2* = E
-
n

k=m+1
ξk
B1[0,t], bk
C
 
n

l=m+1
ξl
B1[0,t], bl
C
.
=
n

k=m+1
B1[0,t], bk
C2 ≤
∞

k=m+1
B1[0,t], bk
C2.
Since ∞
k=1⟨1[0,t], bk⟩2 = ∥1[0,t]∥2 = t < ∞, we have Xn
t ∈L2(P) and
lim
m→∞sup
n≥m
E
)
(Xm
t −Xn
t )2*
= 0.

21.5
Construction via L2-Approximation
537
Hence

Xn
t

n∈N is a Cauchy sequence in L2(P) and thus (since L2(P) is complete,
see Theorem 7.3) has an L2-limit Xt. Thus, for N ∈N and 0 ≤t1, . . . , tN ≤1,
lim
n→∞E
+ N

i=1

Xn
ti −Xti
2
,
= 0.
In particular,

Xn
t1, . . . , Xn
tN
 n→∞
−→

Xt1, . . . , XtN

in P-probability.
Manifestly,

Xn
t1, . . . , Xn
tN

is normally distributed and centered. For s, t ∈[0, 1],
we have
Cov
)
Xn
s , Xn
t
*
= E
- n

k=1
ξk
B
1[0,s], bk
C
  n

l=1
ξl
B
1[0,t], bl
C
.
=
n

k,l=1
E[ξkξl]
B
1[0,s], bk
CB
1[0,t], bl
C
=
n

k=1
B
1[0,s], bk
CB
1[0,t], bk
C
n→∞
−→
B
1[0,s], 1[0,t]
C
= min(s, t).
Hence (Xt)t∈[0,1] is a centered Gaussian process with
Cov[Xs, Xt] = min(s, t).
(21.24)
Lévy Construction of Brownian motion
Up to continuity of paths, X is thus a Brownian motion. A continuous version of X
can be obtained via the Kolmogorov–Chentsov theorem (Theorem 21.6). However,
by a clever choice of the ONB (bn)n∈N, we can construct X directly as a continuous
process. The Haar functions bn,k are one such choice: Let b0,1 ≡1 and for n ∈N
and k = 1, . . . , 2n−1, let
bn,k(t) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
2(n−1)/2,
if
2k −2
2n
≤t < 2k −1
2n
,
−2(n−1)/2,
if
2k −1
2n
≤t < 2k
2n ,
0,
else.

538
21
Brownian Motion
Then (bn,k) is an orthonormal system: ⟨bm,k, bn,l⟩= 1{(m,k)=(n,l)}. It is easy to
check that (bn,k) is a basis (exercise!). Deﬁne the Schauder functions by
Bn,k(t) =

[0,t]
bn,k(s) λ(ds) = B1[0,t], bn,k
C.
Let ξ0,1, (ξn,k)n∈N, k=1,...,2n−1 be independent and N0,1-distributed. Let
Xn := ξ0,1 B0,1 +
n

m=1
2m−1

k=1
ξm,k Bm,k,
and deﬁne ˜Xt as the L2(P)-limit ˜Xt = L2 −limn→∞Xn
t . See Fig. 21.2 for a
computer simulation of Xn, n = 0, 1, 2, 3, 10.
Theorem 21.28 (Brownian motion, L2-approximation) There is a continuous
version X of ˜X. X is a Brownian motion and we have
lim
n→∞
;;Xn −X
;;
∞= 0
P-almost surely.
(21.25)
Proof By (21.25), we have Xt = ˜Xt a.s. for all t ∈[0, 1]. As uniform limits of
continuous functions are continuous, (21.25) implies that X is continuous. Hence,
0
1/4
1/2
3/4
1
−1.5
−1.0
−0.5
0.0
0.5
Fig. 21.2 The processes Xn, n = 0, 1, 2, 3, 10 of the Lévy construction of Brownian motion.

21.5
Construction via L2-Approximation
539
by (21.24) (and Theorem 21.11), X is a Brownian motion. Therefore, it is enough
to prove the existence of an X such that (21.25) holds.
Since (C([0, 1]), ∥· ∥∞) is complete, it sufﬁces to show that P-almost surely
(Xn) is a Cauchy sequence in (C([0, 1]), ∥· ∥∞). Note that ∥Bn,k∥∞≤2−(n+1)/2
if n ∈N and Bn,kBn,l = 0 if k ̸= l. Hence
;;Xn −Xn−1;;
∞≤2−(n+1)/2 max
	
|ξn,k|, k = 1, . . . , 2n−1
.
Therefore,
P
'
∥Xn −Xn−1∥∞> 2−n/4(
≤
2n−1

k=1
P
'
|ξn,k| > 2(n+2)/4(
= 2n−1
2
√
2π
 ∞
2(n+2)/4 e−x2/2dx
≤2n exp

−2n/2
.
Evidently,
∞

n=1
P[∥Xn −Xn−1∥∞> 2−n/4] < ∞; hence, by the Borel–Cantelli
lemma,
P
';;Xn −Xn−1;;
∞> 2−n/4
only ﬁnitely often
(
= 1.
We conclude that lim
n→∞sup
m≥n
∥Xm −Xn∥∞= 0 P-almost surely.
⊓⊔
Brownian Motion and White Noise
The construction of Brownian motion via Haar functions has the advantage that
continuity of the paths is straightforward. For some applications, however, a
decomposition in trigonometric functions is preferable. Here as the orthonormal
basis of L2([0, 1]) we use b0 = 1 and
bn(x) =
√
2 cos(nπ x)
for n ∈N.
For t ∈[0, 1] and n ∈N0, deﬁne
Bn(t) =
 t
0
bn(s) λ(ds);

540
21
Brownian Motion
that is, B0(t) = t and
Bn(t) =
√
2
n π sin(nπ t)
for n ∈N.
Let ξn, n ∈N0, be independent standard normally distributed random variables.
Deﬁne A0 = ξ0 and
An :=
√
2
πn ξn
for n ∈N.
Finally, let
Xn :=
n

k=0
ξk Bk;
that is,
Xn(t) = ξ0 t +
n

k=1
Ak sin(kπ t).
See Fig. 21.3 for a computer simulation of Xn, n = 0, 1, 4, 64, 8192.
0.0
0.2
0.4
0.6
0.8
1.0
−0.5
0.0
0.5
1.0
Fig. 21.3 The processes Xn, n = 0, 1, 4, 64, 8192 from the Fourier Construction of Brownian
motion.

21.5
Construction via L2-Approximation
541
As shown above, the sequence (Xn) converges in L2([0, 1]) towards a process
X, which (up to continuity of paths) has all properties of Brownian motion:
Xt = ξ0 t +
∞

n=1
√
2
nπ ξn sin(nπ t).
This representation of the Brownian motions goes back to Paley and Wiener who
also show that along a suitable subsequence the series converges uniformly almost
surely and hence the limit X is indeed continuous, see [125, Theorem XLIII,
page 148]. The representation is also sometimes called Karhunen–Loève expansion.
More precisely, up to the ﬁrst summand, it is the Karhunen–Loève expansion of the
Brownian bridge (Xt −tX1)t∈[0,1] (see, e.g., [1, Chapter 3.3]).
Taking the formal derivative
˙Xt := d
dt Xt = ξ0 +
√
2
∞

n=1
ξn cos(nπ t)
we get independent identically distributed Fourier coefﬁcients for all frequencies.
Hence, the formal object ˙X is often referred to as white noise as opposed to colored
noise where the coefﬁcients for the different frequencies have different distributions.
The Fourier basis is not too well suited to showing continuity of paths. For
example, the sufﬁcient criterion of absolute summability of coefﬁcients (An) fails
(see Exercise 21.5.5).
Example 21.29 (Stochastic integral à la Paley–Wiener) Assume that (ξn)n∈N is an
i.i.d. sequence of N0,1-distributed random variables. Let (bn)n∈N be an orthonormal
basis of L2([0, 1]) such that Wt := limn→∞
n
k=1 ξk ⟨1[0,t], bk⟩, t ∈[0, 1], is a
Brownian motion. For f ∈L2([0, 1]), deﬁne
I(f ) :=
∞

n=1
ξn ⟨f, bn⟩.
By Parseval’s equation and the Bienaymé formula, we have
∥f ∥2
2 =
∞

n=1
⟨f, bn⟩2 = Var
)
I(f )
*
= E
)
I(f )2*
.
Hence
I : L2([0, 1]) →L2(P),
f →I(f )
is an isometry.
(21.26)

542
21
Brownian Motion
We call
 t
0
f (s) dWs := If 1[0,t]
,
t ∈[0, 1], f ∈L2([0, 1]),
the stochastic integral of f with respect to W. In the special case of the Fourier
basis b0(x) = 1 and bn(x) =
√
2 cos(nπx), n ∈N, this construction goes back to
Paley and Wiener [125, Theorem XLV, page 154].
The process Xt :=
3 t
0 f (s) dWs, t ∈[0, 1], is centered Gaussian with covariance
function
Cov[Xs, Xt] =
 s∧t
0
f 2(u) du.
In fact, it is obvious that X is centered and Gaussian (since it is a limit of
the Gaussian processes of partial sums) and has the given covariance function.
Furthermore, the existence of a continuous version can be obtained as for Brownian
motion by employing the fourth moments of the increments, which for normal
random variables can be computed from the variances (compare Theorem 21.9).
In the following we will assume for the stochastic integral that such a continuous
version is chosen.
In the special case, f =
n
i=1
αi 1(ti−1,ti] for some n ∈N and 0 = t0 < t1 < . . . <
tn and α1, . . . , αn ∈R, we obtain
 1
0
f (s) dWs =
n

i=1
αi

Wti −Wti−1

.
♦
Takeaways Consider an orthonormal basis of the Hilbert space L2([0, 1])
and assign to each basis vector an i.i.d. standard normally distributed factor.
Now integrate over [0, t] and sum up. The inﬁnite series is a Gaussian process
with the same covariance function as Brownian motion. If we choose the
orthonormal basis cleverly, then we automatically get a continuous process.
As one possible choice for the basis consists of cosine functions, this
procedure is known as frequency decomposition of Brownian motion.
Exercise 21.5.1 Use the representation of Brownian motion (Wt)t∈[0,1] as a random
linear combination of the Schauder functions (Bn,k) to show that the Brownian
bridge Y = (Yt)t∈[0,1] = (Wt −tW1)t∈[0,1] is a continuous, Gaussian process with
covariance function Cov[Yt, Ys] = (s ∧t) −st. Further, show that
PY = lim
ε↓0 P
)
W ∈· |W1 ∈(−ε, ε)
*
.
♣

21.5
Construction via L2-Approximation
543
Exercise 21.5.2 (Compare Example 8.32.) Fix T ∈(0, 1). Use an orthonormal
basis b0,1, (cn,k), (dn,k) of suitably modiﬁed Haar functions (such that the cn,k have
support [0, T ] and the dn,k have support [T, 1]) to show that a regular conditional
distribution of WT given W1 is deﬁned by
P[WT ∈· |W1 = x] = NT x,T .
♣
Exercise 21.5.3 Deﬁne Y := (Yt)t∈[0,1] by Y1 = 0 and
Yt = (1 −t)
 t
0
(1 −s)−1 dWs
for t ∈[0, 1).
Show that Y is a Brownian bridge.
Hint: Show that Y is a continuous Gaussian process with the correct covariance
function. In particular, it has to be shown that limt↑1 Yt = 0 almost surely. ♣
Exercise 21.5.4 Let d ∈N. Use a suitable orthonormal basis on [0, 1]d to show:
(i) There is a Gaussian process (Wt)t∈[0,1]d with covariance function
Cov[Wt, Ws] =
d

i=1

ti ∧si

.
(ii) There is a modiﬁcation of W such that t →Wt is almost surely continuous (see
Remark 21.7).
A process W with properties (i) and (ii) is called a Brownian sheet. ♣
Exercise 21.5.5 Consider the coefﬁcients (An)n∈N0 of the Fourier basis of the
construction of Brownian motion. Show the following statements:
(i) ∞
n=0 A2
n < ∞almost surely.
(ii) ∞
n=0 |An| = ∞almost surely.
(iii) n
k=0 Ak, n ∈N converges almost surely.
Hint: Kolmogorov’s three-series theorem (Theorem 15.51). ♣
Exercise 21.5.6 Let t ∈(0, 1) and f0(x) := t as well as
fn(x) := 2 sin(nπ t)
nπ
cos(nπ x)
for n ∈N, x ∈[0, 1].
Show that ∞
n=0 fn(x) = 1[0,t](x) for x ∈(0, 1) \ {t}. ♣

544
21
Brownian Motion
21.6
The Space C([0, ∞))
Are functionals that depend on the whole path of a Brownian motion measurable?
For example, is sup{Xt, t ∈[0, 1]} measurable? For general stochastic processes,
this is false since the supremum depends on more than countably many coordinates.
However, for processes with continuous paths, this is true, as we will show in this
section in a somewhat more general framework.
We may consider Brownian motion as the canonical process on the space Ω :=
C([0, ∞)) of continuous paths.
We start by collecting some properties of the space Ω = C([0, ∞)) ⊂R[0,∞).
Deﬁne the evaluation map
Xt : Ω →R,
ω →ω(t),
(21.27)
that is, the restriction of the canonical projection R[0,∞) →R to Ω.
For f, g ∈C

[0, ∞)

and n ∈N, let dn(f, g) :=
;;;(f −g)
[0,n]
;;;
∞∧1 and
d(f, g) =
∞

n=1
2−n dn(f, g).
(21.28)
Theorem 21.30 d is a complete metric on Ω := C[0, ∞) that induces the
topology of uniform convergence on compact sets. The space (Ω, d) is separable
and hence Polish.
Proof Clearly, every dn is a complete metric on (C([0, n]), ∥· ∥∞). Thus, for every
Cauchy sequence (fN) in (Ω, d) and every n ∈N, there exists a gn ∈Ω with
dn(fN, gn)
N→∞
−→0. Evidently, gn(x) = gm(x) for every x ≤m ∧n; hence there
exists a g ∈Ω with g(x) = gn(x) for every x ≤n for every n ∈N. Hence, clearly,
d(fN, g)
N→∞
−→0, and thus d is complete.
The set of polynomials with rational coefﬁcients is countable and by the
Weierstraß theorem, it is dense in any (C([0, n]), ∥· ∥∞); hence it is dense in
(Ω, d).
⊓⊔
Theorem 21.31 With respect to the Borel σ-algebra B(Ω, d), the canonical
projections Xt, t ∈[0, ∞) are measurable. On the other hand, the Xt generate
B(Ω, d). Hence
(B(R))⊗[0,∞)
Ω = σ

Xt, t ∈[0, ∞)

= B(Ω, d).
Proof The ﬁrst equation holds by deﬁnition. For the second one, we must show the
mutual inclusions.
“⊂”
Clearly, every Xt : Ω −→R is continuous and hence (B(Ω, d) – B(R))-
measurable. Thus σ

Xt, t ∈[0, ∞)

⊂B(Ω, d).

21.6
The Space C([0, ∞))
545
“⊃”
We have to show that open subsets of (Ω, d) are in A := (B(R))⊗[0,∞).
Since (Ω, d) is separable (Theorem 21.30), every open set is a countable union of
ε-balls. Hence it sufﬁces to show that for ﬁxed ω0 ∈Ω, the map ω →d(ω0, ω)
is A-measurable. To this end it is enough to show that for any n ∈N, the map
ω →Yn(ω) := dn(ω0, ω) (see (21.28)) is A-measurable. However, the map
ω →Zt(ω) := |Xt(ω) −Xt(ω0)| ∧1
is A-measurable. Since each ω is continuous, Yn is a countable supremum
Yn =
sup
t∈[0,n]∩Q
Zt
and is hence A-measurable.
⊓⊔
In the following, let A := σ

Xt, t ∈[0, ∞)

.
Corollary 21.32 The map F1 : Ω →[0, ∞), ω →sup{ω(t) : t ∈[0, 1]} is
A-measurable.
Proof F1 is continuous with respect to d and hence B(Ω, d)-measurable.
⊓⊔
If B is a Brownian motion (on some probability space ( 
Ω, 
A,P)), then there
exists an Ω ∈
A with P) Ω * = 1 and B(ω) ∈C([0, ∞)) for every ω ∈Ω. Let
A = 
A
Ω and P = PA. Then B : Ω −→C([0, ∞)) is measurable with respect to
(A, A). With respect to the image measure P = P ◦B−1 on Ω = C([0, ∞)), the
canonical process X = (Xt, t ∈[0, ∞)) on C([0, ∞)) is a Brownian motion.
Deﬁnition 21.33 Let P be the probability measure on Ω = C([0, ∞)) with respect
to which the canonical process X is a Brownian motion. Then P is called the Wiener
measure. The triple (Ω, A, P) is called the Wiener space, and X is called the
canonical Brownian motion or the Wiener process.
Remark 21.34 Sometimes we want a Brownian motion to start not at X0 = 0 but
at an arbitrary point x. Denote by Px that measure on C([0, ∞)) for which 
X =
(Xt −x, t ∈[0, ∞)) is a Brownian motion (with 
X0 = 0). ♦
Takeaways A continuous stochastic process can be considered as a random
variable with values in the space C([0, ∞)) of continuous functions. Here
we have studied the properties of this space as a topological space and as a
measure space.
Exercise 21.6.1 Show that the map
F∞: Ω →[0, ∞],
ω →sup 	ω(t) : t ∈[0, ∞)
,
is A-measurable. ♣

546
21
Brownian Motion
21.7
Convergence of Probability Measures on C([0, ∞))
Let X and (Xn)n∈N be random variables with values in C([0, ∞)) (i.e., continuous
stochastic processes) with distributions PX and (PXn)n∈N.
Deﬁnition 21.35 We say that the ﬁnite-dimensional distributions of (Xn) converge
to those of X if, for every k ∈N and t1, . . . , tk ∈[0, ∞), we have
(Xn
t1, . . . , Xn
tk) n→∞
⇒(Xt1, . . . , Xtk).
In this case, we write Xn
n→∞
⇒
fdd
X or PXn
n→∞
−→
fdd
PX.
Lemma 21.36 Pn
n→∞
−→
fdd
P and Pn
n→∞
−→
fdd
Q imply P = Q.
Proof By Theorem 14.12(iii), the ﬁnite-dimensional distributions determine P
uniquely.
⊓⊔
Theorem 21.37 Weak convergence in M1(Ω, d) implies fdd-convergence:
Pn
n→∞
−→P
⇒
Pn
n→∞
−→
fdd
P.
Proof Let k ∈N and t1, . . . , tk ∈[0, ∞). The map
ϕ : C([0, ∞)) →Rk,
ω →(ω(t1), . . . , ω(tk))
is continuous. By the continuous mapping theorem (Theorem 13.25 on page 287),
we have Pn ◦ϕ−1 n→∞
−→P ◦ϕ−1; hence Pn
n→∞
−→
fdd
P.
⊓⊔
The converse statement in the preceding theorem does not hold. However, we
still have the following.
Theorem 21.38 Let (Pn)n∈N and P be probability measures on C([0, ∞)). Then
the following are equivalent:
(i) Pn
n→∞
−→
fdd
P and (Pn)n∈N is tight.
(ii) Pn
n→∞
−→P weakly.
Proof “(ii) ⇒(i)”
This is a direct consequence of Prohorov’s theorem (Theo-
rem 13.29 with E = C([0, ∞))).
“(i) ⇒(ii)”
By Prohorov’s theorem, (Pn)n∈N is relatively sequentially compact.
Let Q be a limit point for (Pnk)k∈N along some subsequence (nk). Then Pnk
fdd
−→
Q, k →∞. By Lemma 21.36, we have P = Q.
⊓⊔

21.7
Convergence of Probability Measures on C([0, ∞))
547
Next we derive a useful criterion for tightness of sets {Pn} ⊂M1(C([0, ∞))).
We start by recalling the Arzelà–Ascoli characterization of relatively compact sets
in C([0, ∞)) (see, e.g., [37, Theorem 2.4.7] or [174, Theorem III.3]).
For N, δ > 0 and ω ∈C([0, ∞)), let
V N(ω, δ) := sup
	
|ω(t) −ω(s)| : |t −s| ≤δ, s, t ≤N

.
Theorem 21.39 (Arzelà–Ascoli) A set A ⊂C([0, ∞)) is relatively compact if and
only if the following two conditions hold.
(i) {ω(0), ω ∈A} ⊂R is bounded.
(ii) For every N, we have lim
δ↓0 sup
ω∈A
V N(ω, δ) = 0.
Theorem 21.40 A family (Pi, i ∈I) of probability measures on C([0, ∞)) is
weakly relatively compact if and only if the following two conditions hold.
(i) (Pi ◦X−1
0 , i ∈I) is tight; that is, for every ε > 0, there is a K > 0 such that
Pi
	ω : |ω(0)| > K
 ≤ε
for all i ∈I.
(21.29)
(ii) For all η, ε > 0 and N ∈N, there is a δ > 0 such that
Pi
	
ω : V N(ω, δ) > η


≤ε
for all i ∈I.
(21.30)
Proof “ ⇒”
By Prohorov’s theorem (Theorem 13.29), weak relative compact-
ness of (Pi, i ∈I) implies tightness of this family. Thus, for every ε > 0, there
exists a compact set A ⊂C([0, ∞)) with Pi(A) > 1 −ε for every i ∈I. Using the
Arzelà–Ascoli characterization of the compactness of A, we infer (i) and (ii).
“ ⇐ ”
Now assume that (i) and (ii) hold. Then, for ε > 0 and k, N ∈N, choose
numbers Kε and δN,k,ε such that
sup
i∈I
Pi
{ω : |ω(0)| > Kε} ≤ε
2
and
sup
i∈I
Pi
0
ω : V N(ω, δN,k,ε) > 1
k
1
≤2−N−k−1 ε.
Deﬁne
CN,ε =
0
ω : |ω(0)| ≤Kε, V N(ω, δN,k,ε) ≤1
k for all k ∈N
1
.

548
21
Brownian Motion
By the Arzelà–Ascoli theorem, Cε := 
N∈N
CN,ε is relatively compact in C([0, ∞))
and we have
Pi(Cc
ε) ≤ε
2 +
∞

k,N=1
Pi
	
ω : V N(ω, δN,k,ε) > 1/k


≤ε
for all i ∈I.
Hence the claim follows.
⊓⊔
Corollary 21.41 Let (Xi, i ∈I) and (Yi, i ∈I) be families of random variables in
C([0, ∞)). Assume that (PXi, i ∈I) and (PYi, i ∈I) are tight. Then (PXi+Yi, i ∈
I) is tight.
Proof Apply the triangle inequality in order to check (i) and (ii) in the preceding
theorem.
⊓⊔
The following is an important tool to check weak relative compactness.
Theorem 21.42 (Kolmogorov’s criterion for weak relative compactness) Let
(Xi, i ∈I) be a sequence of continuous stochastic processes. Assume that the
following conditions are satisﬁed.
(i) The family (P[Xi
0 ∈·], i ∈I) of initial distributions is tight.
(ii) For any N > 0 there are numbers C, α, β > 0 such that, for all s, t ∈[0, N]
and every i ∈I, we have
E
)
|Xi
s −Xi
t |α*
≤C |s −t|β+1.
Then the family (PXi, i ∈I) = (L[Xi], i ∈I) of distributions of Xi is weakly
relatively compact in M1(C([0, ∞))).
Proof We check the conditions of Theorem 21.40. The ﬁrst condition of Theo-
rem 21.40 is exactly (i).
Let N > 0. By the Kolmogorov–Chentsov theorem (Theorem 21.6(ii)), for ε > 0
and γ ∈(0, β/α), there exists a K such that, for every i ∈I, we have
P
)
|Xi
t −Xi
s| ≤K |t −s|γ for all s, t ∈[0, N]
*
≥1 −ε.
This clearly implies (21.30) with δ = (η/K)1/γ .
⊓⊔
Takeaways In many situations, stochastic processes in continuous time are
constructed as limits of simpler processes. In order to do, criteria for relative
compactness of probability measures on C([0, ∞)) are needed. Particularly
helpful is a moment criterion that postulates that moments of increments over
small intervals decay quickly as the intervals get smaller.

21.8
Donsker’s Theorem
549
21.8
Donsker’s Theorem
Let Y1, Y2, . . . be i.i.d. random variables with E[Y1] = 0 and Var[Y1] = σ 2 > 0.
For t > 0, let Sn
t = ⌊nt⌋
i=1 Yi and Sn
t =
1
√
σ 2nSn
t . By the central limit theorem, for
t > s ≥0, we have L
)Sn
t −Sn
s
* n→∞
−→N0,t−s.
Let B = (Bt, t ≥0) be a Brownian motion. Then
L
)Sn
t −Sn
s
* n→∞
−→L[Bt −Bs]
for any t > s ≥0.
For N ∈N and 0 = t0 < t1 < . . . < tN, the random variables Sn
ti −Sn
ti−1, i =
1, . . . , N, are independent, and hence, we have
L
)
(Sn
t1 −Sn
t0, . . . ,Sn
tN −Sn
tN−1)
* n→∞
−→L[(Bt1 −Bt0, . . . , BtN −BtN−1)].
We infer that
L)(Sn
t1, . . . ,Sn
tN )* n→∞
−→L[(Bt1, . . . , BtN )].
(21.31)
We now deﬁne ¯Sn as Sn but linearly interpolated:
¯Sn
t =
1
√
σ 2n
⌊nt⌋

i=1
Yi + tn −⌊tn⌋
√
σ 2n
Y⌊nt⌋+1.
(21.32)
Then, for ε > 0,
P
)Sn
t −¯Sn
t
 > ε
*
≤ε−2 E
)
(Sn
t −¯Sn
t )2*
≤
1
ε2n
1
σ 2 E[Y 2
1 ] =
1
ε2n
n→∞
−→0.
By Slutzky’s theorem (Theorem 13.18), we thus have convergence of the ﬁnite-
dimensional distributions to the Wiener measure PW :
P¯Sn
n→∞
⇒
fdd
PW.
(21.33)
The aim of this section is to strengthen this convergence statement to weak
convergence of probability measures on C([0, ∞)). The main theorem of this
section is the functional central limit theorem, which goes back to Donsker [35].
Theorems of this type are also called invariance principles since the limiting
distribution is the same for all distributions Yi with expectation 0 and the same
variance.

550
21
Brownian Motion
Theorem 21.43 (Donsker’s invariance principle) In the sense of weak conver-
gence on C([0, ∞)), the distributions of ¯Sn converge to the Wiener measure,
L[ ¯Sn]
n→∞
−→PW.
(21.34)
Proof Owing to (21.33) and Theorem 21.38, it is enough to show that (L[ ¯Sn], n ∈
N) is tight. To this end, we want to apply Kolmogorov’s moment criterion. However,
as in the proof of existence of Brownian motion, second moments are not enough;
rather we need fourth moments in order that we can choose β > 0. Hence the
strategy is to truncate the Yi to obtain fourth moments.
For K > 0, deﬁne
Y K
i
:= Yi 1{|Yi|≤K/2} −E[Yi 1{|Yi|≤K/2}]
and
ZK
i := Yi −Y K
i
for i ∈N.
Then E[Y K
i ] = E[ZK
i ] = 0 and Var[ZK
i ]
K→∞
−→
0 as well as Var[Y K
i ] ≤σ 2,
i ∈N. Clearly, |Y K
i | ≤K for every i. Deﬁne
T K
n :=
n

i=1
Y K
i
and
UK
n :=
n

i=1
ZK
i
for n ∈N.
Let ¯T K,n
t
and ¯UK,n
t
be the linearly interpolated versions of
T K,n
t
:=
1
√
σ 2n
T K
⌊nt⌋
and

UK,n
t
:=
1
√
σ 2n
UK
⌊nt⌋
for t ≥0.
Evidently, ¯Sn =
¯T K,n + ¯UK,n. By Corollary 21.41, it is enough to show that,
for a sequence (Kn)n∈N (chosen later), the families (L[ ¯UKn,n], n ∈N) and
(L[ ¯T Kn,n], n ∈N) are tight.
We consider ﬁrst the remainder term. As UK is a martingale, Doob’s inequality
(Theorem 11.2) yields
P
+
sup
l=1,...,n
|UK
l | > ε√n
,
≤ε−2 Var)ZK
1
*
for every ε > 0.
Now, if Kn ↑∞, n →∞, then for every N > 0, we have
P
+
sup
t∈[0,N]
 ¯UKn,n
t
 > ε
,
≤
N
ε2 σ 2 Var
)
ZKn
1
* n→∞
−→0,
hence ¯UKn,n
n→∞
⇒0 in C([0, ∞)). In particular, (L[ ¯UKn,n], n ∈N) is tight.

21.8
Donsker’s Theorem
551
Next, for N > 0 and s, t ∈[0, N], we compute the fourth moments of the
differences ¯T Kn,n
t+s
−¯T Kn,n
s
for the main term. In the following, let Kn = n1/4. Fix
n ∈N. We distinguish two cases:
Case 1: t < n−1.
Let k := ⌊(t + s)n⌋. If sn ≥k, then
¯T Kn,n
t+s
−¯T Kn,n
s
=
tn
√
nσ 2 Y Kn
k+1.
If sn < k, then
¯T Kn,n
t+s
−¯T Kn,n
s
=
1
√
nσ 2

((t + s)n −k)Y Kn
k+1 + (k −sn)Y Kn
k

.
In either case, we have
 ¯T Kn,n
t+s
−¯T Kn,n
s
 ≤t√n
σ

|Y Kn
k
| + |Y Kn
k+1|

,
hence
E
' ¯T Kn,n
t+s
−¯T Kn,n
s
4(
≤n2t4
σ 4 (2Kn)2 E
'
|Y Kn
1 | + |Y Kn
2 |
2(
≤16n5/2t4
σ 4
Var)Y Kn
1
* ≤16
σ 2 t3/2.
(21.35)
Case 2: t ≥n−1.
Using the binomial theorem, we get (note that the mixed terms
with odd moments vanish since E)Y Kn
1
* = 0)
E)(T Kn
n )4* = n E)(Y Kn
1 )4* + 3n(n −1) E)(Y Kn
1 )2*2
≤nK2
nσ 2 + 3n(n −1)σ 4.
(21.36)
Note that, for independent real random variables X, Y with E[X] = E[Y] = 0
and E)X4*, E)Y 4* < ∞and for a ∈[−1, 1], we have
E)(aX + Y)4* = a4 E)X4* + 6 a2 E)X2* E)Y 2* + E)Y 4*
≤E)X4* + 6 E)X2* E)Y 2* + E)Y 4* = E[(X + Y)4].

552
21
Brownian Motion
We apply this twice (with a = (t + s)n −⌊(t + s)n⌋and a = ⌈sn⌉−sn) and obtain
(using the rough estimate ⌈(t + s)n⌉−⌊sn⌋≤tn + 2 ≤3tn) from (21.36) (since
t ≤N)
E
)
( ¯T Kn,n
t+s
−¯T Kn,n
s
)4*
≤n−2 σ −4 E
)
(T Kn
⌈(t+s)n⌉−T Kn
⌊sn⌋)4*
= n−2 σ −4 E)(T Kn
⌈(t+s)n⌉−⌊sn⌋)4*
≤3tnK2
n
n2 σ 2 + 18t2 =
3
σ 2 tn−1/2 + 18t2
≤
3
σ 2 t3/2 + 18t2 ≤
 3
σ 2 + 18
√
N

t3/2.
(21.37)
By (21.35) and (21.37), for every N > 0, there exists a C = C(N, σ 2) such that,
for every n ∈N and all s, t ∈[0, N], we have
E
)
( ¯T Kn,n
t+s
−¯T Kn,n
s
)4*
≤C t3/2.
Hence, by Kolmogorov’s moment criterion (Theorem 21.42 with α = 4 and β =
1/2), (L[ ¯T Kn,n], n ∈N) is tight in M1(C([0, ∞))).
⊓⊔
Takeaways Properly rescaled sums of i.i.d. centred random variables with
second moments converge to a normally distributed random variable. Using
the moment criterion, here we have shown that also the process of partial sums
converges and that the limit is Brownian motion. This is Donsker’s theorem
that is known in the physics literature as the invariance principle.
Exercise 21.8.1 Let X1, X2, . . . be i.i.d. random variables with continuous distri-
bution function F. Let Gn : [0, 1] →R, t →n−1/2 n
i=1

1[0,t](F(Xi)) −t

and
Mn := ∥Gn∥∞. Further, let M = supt∈[0,1] |Bt|, where B is a Brownian bridge.
(i) Show that E[Gn(t)] = 0 and Cov[Gn(s), Gn(t)] = s ∧t −st for s, t ∈[0, 1].
(ii) Show that E[(Gn(t) −Gn(s))4] ≤C

(t −s)2 + |t −s|/n

for some C > 0.
(iii) Conclude that a suitable continuous version of Gn converges weakly to B. For
example, choose
Hn(t) = n−1/2
n

i=1

hn(F(Xi) −t) −gn(t)

,
where hn is a suitable smoothed version of 1(−∞,0], for example, hn(s) =
1 −(s/εn ∨0) ∧1 for some sequence εn ↓0, and gn(t) :=
3 1
0 hn(t −u) du.
(iv) Finally, show that Mn
n→∞
⇒M.

21.9
Pathwise Convergence of Branching Processes
553
Remark: The distribution of M can be expressed by the Kolmogorov–Smirnov
formula ([101] and [157]; see, e.g., [133])
P[M > x] = 2
∞

n=1
(−1)n−1 e−2n2x2.
(21.38)
Compare (21.21). Using the statistic Mn, one can test if random variables of a known
distribution are independent. Let X1, X2, . . . and
˜X1, ˜X2, . . . be independent
random variables with unknown continuous distribution functions F and ˜F and with
empirical distribution functions Fn and ˜Fn. Further, let
Dn := sup
t∈R
|Fn(t) −˜Fn(t)|.
Under the assumption that F = ˜F holds, √n/2 Dn converges in distribution to M.
This fact is the basis for nonparametric tests on the equality of distributions. ♣
21.9
Pathwise Convergence of Branching Processes∗
In this section, we investigate the convergence of rescaled Galton–Watson processes
(branching processes). As for sums of independent random variables, we ﬁrst show
convergence for a ﬁxed time point to the distribution of a certain limiting process.
The next step is to show convergence of ﬁnite-dimensional distributions. Finally,
using Kolmogorov’s moment criterion for tightness, we show convergence in the
path space C([0, ∞)).
Consider a Galton–Watson process (Zn)n∈N0 with geometric offspring distribu-
tion
p(k) = 2−k−1
for k ∈N0.
That is, let Xn,i, n, i ∈N0 be i.i.d. random variables on N0 with P[Xn,i = k] =
p(k), k ∈N0, and based on the initial state Z0 deﬁne inductively
Zn+1 =
Zn

i=1
Xn,i.
Thus Z is a Markov chain with transition probabilities p(i, j) = p∗i(j), where p∗i
is the ith convolution power of p. In other words, if Z, Z1, . . . , Zi are independent
copies of our Galton–Watson process, with Z0 = i and Z1
0 = . . . = Zi
0 = 1, then
Z D= Z1 + . . . + Zi.
(21.39)

554
21
Brownian Motion
We consider now the probability generating function of X1,1, ψ(1)(s) := ψ(s) :=
E[sX1,1], s ∈[0, 1]. Denote by ψ(n) := ψ(n−1) ◦ψ its nth iterate for n ∈N. Then,
by Lemma 3.10,
Ei[sZn] = E1[sZn]i =

ψ(n)(s)
i
.
For the geometric offspring distribution, ψ(n) can be computed explicitly.
Lemma 21.44 For the branching process with critical geometric offspring distri-
bution, the nth iterate of the probability generating function is
ψ(n)(s) = n −(n −1)s
n + 1 −ns .
Proof Compute
ψ(s) =
∞

k=0
2−k−1 sk =
1
−s + 2.
In order to compute the iterated function, ﬁrst consider general linear rational
functions of the form f (x) = ax+b
cx+d . For such f , deﬁne the matrix Mf =
a b
c d

.
For two linear rational functions f and g, we have Mf ◦g = Mf · Mg. The powers
of M are easy to compute:
Mψ =
 0 1
−1 2

,
M2
ψ =
−1 2
−2 3

,
M3
ψ =
−2 3
−3 4

,
and inductively
Mn
ψ =

−(n −1)
n
−n
n + 1

.
⊓⊔
If we let s = e−λ, then we get the Laplace transform of Zn,
Ei[e−λZn] = ψ(n)(e−λ)i.
By Example 6.29, we can compute the moments of Zn by differentiating the Laplace
transform. That is, we obtain the following lemma.
Lemma 21.45 The moments of Zn are
Ei[Zk
n] = (−1)k dk
dλk

ψ(n)(e−λ)i

λ=0
.
(21.40)

21.9
Pathwise Convergence of Branching Processes
555
In particular, the ﬁrst six moments are
Ei[Zn] = i,
Ei[Z2
n] = 2i n + i2,
Ei[Z3
n] = 6i n2 + 6i2 n + i3,
Ei[Z4
n] = 24i n3 + 36i2 n2 + (12i3 + 2i) n + i4,
(21.41)
Ei[Z5
n] = 120i n4 + 240i2 n3 + (120i3 + 30i) n2 + (20i4 + 10i2) n + i5,
Ei[Z6
n] = 720i n5 + 1800i2 n4 + (1200i3 + 360i) n3,
+ (300i4 + 240i2)n2 + (30i5 + 30i3 + 2i)n + i6.
Hence, Z is a martingale, and the ﬁrst six centered moments are
Ei[(Zn −i)2] = 2i n,
Ei[(Zn −i)3] = 6i n2,
Ei[(Zn −i)4] = 24i n3 + 12i2 n2 + 2i n,
Ei[(Zn −i)5] = 120i n4 + 120i2 n3 + 30i n2,
Ei[(Zn −i)6] = 720i n5 + 1080i2 n4 + (120i3 + 360i) n3 + 60i2n2 + 2i n.
(21.42)
Proof The exact formulas for the ﬁrst six moments are obtained by tenaciously
computing the right-hand side of (21.40).
⊓⊔
Now consider the following rescaling: Fix x ≥0, start with Z0 = ⌊nx⌋
individuals and consider ˜Zn
t := Z⌊tn⌋
n
for t ≥0. We abbreviate
Lx[ ˜Zn] := L⌊nx⌋
)(n−1Z⌊nt⌋)t≥0
*.
(21.43)

556
21
Brownian Motion
Evidently, Ex[ ˜Zn
t ] = ⌊nx⌋
n
≤x for every n; hence (Lx[ ˜Zn
t ], n ∈N) is tight. By
considering Laplace transforms, we obtain that, for every λ ≥0, the sequence of
distributions converges:
lim
n→∞Ex[e−λ ˜Zn
t ] = lim
n→∞

ψ(⌊tn⌋)(e−λ/n)
nx
= lim
n→∞
nt −(nt −1)e−λ/n
nt + 1 −nt e−λ/n
nx
= lim
n→∞

1 −
1 −e−λ/n
n(1 −e−λ/n)t + 1
nx
= exp

−lim
n→∞
x n(1 −e−λ/n)
n(1 −e−λ/n)t + 1

= exp

−
λ
λ + 1/t (x/t)

:= ψt(λ)x.
(21.44)
However, the function ψx
t
is the Laplace transform of the compound Poisson
distribution CPoi(x/t) exp1/t (see Deﬁnition 16.3).
Consider the stochastic kernel κt(x, dy) := CPoi(x/t) exp1/t (dy). This is the
kernel on [0, ∞) whose Laplace transform is given by
 ∞
0
κt(x, dy) e−λy = ψt(λ)x.
(21.45)
Lemma 21.46 (κt)t≥0 is a Markov semigroup and there exists a Markov process
(Yt)t≥0 with transition kernels Px[Yt ∈dy] = κt(x, dy).
Proof It sufﬁces to check that the Chapman–Kolmogorov equation κt · κs
=
κs+t holds. We compute the Laplace transform for these kernels. For λ ≥0,
applying (21.45) twice yields
 
κt(x, dy)κs(y, dz) e−λz =

κt(x, dy) exp

−
λy
λs + 1

= exp

−
λ
λs+1
λ
λs+1t + 1
x

= exp

−
λx
λ(t + s) + 1

=

κt+s(x, dz) e−λz.
⊓⊔
Next we show that Y has a continuous version. To this end, we compute some of
its moments and then use the Kolmogorov–Chentsov theorem (Theorem 21.6).

21.9
Pathwise Convergence of Branching Processes
557
Lemma 21.47 The ﬁrst k moments of Yt can be computed by differentiating the
Laplace transform,
Ex[Y k
t ] = (−1)k dk
dλk

ψ(λ)x
λ=0
,
where ψt(λ) = exp

−
λ
λt+1

. In particular, we have
Ex[Yt ] = x,
Ex[Y 2
t ] = 2x t + x2,
Ex[Y 3
t ] = 6x t2 + 6x2 t + x3,
Ex[Y 4
t ] = 24x t3 + 36x2 t2 + 12x3 t + x4,
Ex[Y 5
t ] = 120x t4 + 240x2 t3 + 120x3 t2 + 20x4 t + x5,
Ex[Y 6
t ] = 720x t5 + 1800x2 t4 + 1200x3 t3 + 300x4 t2 + 30x5 t + x6.
(21.46)
Hence Y is a martingale, and the ﬁrst centered moments are
Ex[(Yt −x)2] = 2x t,
Ex[(Yt −x)3] = 6x t2,
Ex[(Yt −x)4] = 24x t3 + 12x2 t2,
Ex[(Yt −x)5] = 120x t4 + 120x2 t3,
Ex[(Yt −x)6] = 720x t5 + 1080x2 t4 + 120x3 t3.
(21.47)
Theorem 21.48 There is a continuous version of the Markov process Y with tran-
sition kernels (κt)t≥0 given by (21.45). This version is called Feller’s (continuous)
branching diffusion.
See Fig. 26.4 for a computer simulation of Feller’s branching diffusion.
Proof For ﬁxed N > 0 and s, t ∈[0, N], we have
Ex
)
(Yt+s −Ys)4*
= Ex
)
EYs[(Yt −Y0)4]
*
= Ex
)
24Ys t3 + 12Y 2
s t2*
= 24x t3 + 12(2sx + x2) t2 ≤

48Nx + 12x2
t2.
Thus Y satisﬁes the condition of Theorem 21.6 (Kolmogorov–Chentsov)with α = 4
and β = 1.
⊓⊔

558
21
Brownian Motion
Remark 21.49
(i) By using higher moments, it can be shown that the paths of Y are Hölder-
continuous of any order γ ∈(0, 1
2).
(ii) It can be shown that Y is the (unique strong) solution of the stochastic (Itô-)
differential equation (see Examples 26.11 and 26.31)
dYt =
2
2Yt dWt,
(21.48)
where W is a Brownian motion. ♦
Theorem 21.50 We have Lx[ ˜Zn] n→∞
−→
fdd
Lx[Y].
Proof As in (21.44) for 0 ≤t1 ≤t2, λ1, λ2 ≥0 and x ≥0, we get
lim
n→∞Ex
+
e−

λ1 ˜Zn
t1+λ2 ˜Zn
t2
,
= lim
n→∞Ex
'
Ex
'
e−λ2 ˜Zn
t2
 ˜Zn
t1
(
e−λ1 ˜Zn
t1
(
= lim
n→∞Ex
+
exp

−
λ2
λ2(t2 −t1) + 1
˜Zn
t1

e−λ1 ˜Zn
t1
,
= exp
⎛
⎝−

λ2
λ2(t2−t1)+1 + λ1

x

λ2
λ2(t2−t1)+1 + λ1

t1 + 1
⎞
⎠
= Ex
)
exp(−(λ1Yt1 + λ2Yt2))
*
.
Hence, we obtain
Lx
)
λ1 ˜Zn
t1 + λ2 ˜Zn
t2
* n→∞
−→Lx
)
λ1Yt1 + λ2Yt2
*
.
Using the Cramér–Wold device (Theorem 15.57), this implies
Lx
) ˜Zn
t1, ˜Zn
t2
* n→∞
−→Lx
)
Yt1, Yt2
*
.
Iterating the argument, for every k ∈N and 0 ≤t1 ≤t2 ≤. . . ≤tk, we get
Lx
) ˜Zn
ti

i=1,...,k
* n→∞
−→Lx
)
Yti

i=1,...,k
*
.
However, this was the claim.
⊓⊔
The ﬁnal step is to show convergence in path space. To this end, we have
to modify the rescaled processes so that they become continuous. Assume that

21.9
Pathwise Convergence of Branching Processes
559
(Zn
i )i∈N0, n ∈N is a sequence of Galton–Watson processes with Zn
0 = ⌊nx⌋. Deﬁne
the linearly interpolated processes
¯Zn
t :=

t −n−1⌊tn⌋
 
Zn
⌊tn⌋+1 −Zn
⌊tn⌋

+ 1
nZn
⌊tn⌋.
Theorem 21.51 (Lindvall (1972), see [109]) As n →∞, in the sense of weak con-
vergence in M1(C([0, ∞))), the rescaled Galton–Watson processes ¯Zn converge to
Feller’s diffusion Y:
Lx[ ¯Zn]
n→∞
−→Lx[Y].
Proof We have shown already the convergence of the ﬁnite-dimensional distribu-
tions. By Theorem 21.38, it is thus enough to show tightness of (Lx[ ¯Zn], n ∈
N) in M1(C([0, ∞))). To this end, we apply Kolmogorov’s moment criterion
(Theorem 21.42 with α = 4 and β = 1). Hence, for ﬁxed N > 0, we compute
the fourth moments Ex
)( ¯Zn
t+s −¯Zn
s )4* for s, t ∈[0, N]. We distinguish two cases:
Case 1: t < 1
n.
Let k = ⌊(t + s)n⌋. First assume that ⌊sn⌋= k. Then (by
Lemma 21.45)
Ex
)( ¯Zn
t+s −¯Zn
s )4* = n−4(tn)4 E⌊nx⌋
)(Zn
k+1 −Zn
k )4*
= t4 E⌊nx⌋
)24Zn
k + 12(Zn
k)2 + 2Zn
k
*
= t4 
26⌊nx⌋+ 24⌊nx⌋k + ⌊nx⌋2
≤26x t3 + 24xs t2 + x2 t2
≤(50Nx + x2) t2.
In the case ⌊sn⌋= k −1, we get a similar estimate. Therefore, there is a constant
C = C(N, x) such that
Ex
)
( ¯Zn
s+t −¯Zn
s )4*
≤C t2
for all s, t ∈[0, N] with t < 1
n.
(21.49)

560
21
Brownian Motion
Case 2: t ≥1
n.
Deﬁne k := ⌈(t + s)n⌉−⌊sn⌋≤tn + 1 ≤2tn. Then (by
Lemma 21.45)
Ex
)
( ¯Zn
t+s −¯Zn
s )4*
≤n−4E⌊nx⌋
)
(Zn
⌊(t+s)n⌋−Zn
⌊sn⌋)4*
= n−4E⌊nx⌋
)
EZn
⌊sn⌋[(Zn
k −Zn
0)4]
*
= n−4E⌊nx⌋
'
24Zn
⌊sn⌋k3 + 12(Zn
⌊sn⌋)2k2 + 2Zn
⌊sn⌋k
(
≤n−4 
24xn(2tn)3 + (24xn sn + 12x2n2)(2tn)2 + 4xtn2
≤192xt3 + (96xs + 48x2)t2 + 4xn−1t2
≤(292Nx + 48x2) t2.
(21.50)
Combining the estimates (21.49) and (21.50), the assumptions of Kolmogorov’s
moment criterion for tightness (Theorem 21.42) are fulﬁlled with α = 4 and β = 1.
Hence the sequence (Lx[ ¯Zn], n ∈N) is tight.
⊓⊔
Takeaways Branching processes with very large populations undergo only
small relative changes in each generation. By a proper rescaling of time and
population size, we get a continuous limiting process (Lindvall’s theorem).
The details are rather technical as the computation of many moments is
necessary.
21.10
Square Variation and Local Martingales
By the Paley–Wiener-Zygmund theorem (Theorem 21.17), the paths t →Wt
of Brownian motion are almost surely nowhere differentiable and hence have
locally inﬁnite variation. In particular, the stochastic integral
3 1
0 f (s) dWs that we
introduced in Example 21.29 cannot be understood as a Lebesgue–Stieltjes integral.
However, as a preparation for the construction of integrals of this type for larger
classes of integrands and integrators (in Chap. 25), here we investigate the path
properties of Brownian motion and, somewhat more generally, of continuous local
martingales in more detail.

21.10
Square Variation and Local Martingales
561
Deﬁnition 21.52 Let G : [0, ∞) →R be a continuous function. For any t ≥0,
deﬁne the variation up to t by
V 1
t (G) := sup
0 n−1

i=0
Gti+1 −Gti
 : 0 = t0 ≤t1 ≤. . . ≤tn = t, n ∈N
1
.
We say that G has locally ﬁnite variation if V 1
t (G) < ∞for all t ≥0. We write
Cv for the vector space of continuous functions G with continuous variation t →
V 1
t (G).
Remark 21.53 Clearly, V 1(F + G) ≤V 1(F) + V 1(G) and V 1(αG) = |α| V 1(G)
for all continuous F, G : [0, ∞) →R and for all α ∈R. Hence Cv is indeed a
vector space. ♦
Remark 21.54
(i) If G is of the form Gt =
3 t
0 f (s) ds for some locally integrable function f ,
then we have G ∈Cv with V 1
t (G) =
3 t
0 |f (s)| ds.
(ii) If G = G+ −G−is the difference of two continuous monotone increasing
functions G+ and G−, then
V 1
t (G) −V 1
s (G) ≤(G+
t −G+
s ) + (G−
t −G−
s )
for all t > s,
(21.51)
hence we have G ∈Cv. In (21.51), equality holds if G−and G+ “do not grow
on the same sets”; that is, more formally, if G−and G+ are the distribution
functions of mutually singular measures μ−and μ+. The measures μ−and μ+
are then the Jordan decomposition of the signed measure μ = μ+ −μ−whose
distribution function is G. Then the Lebesgue–Stieltjes integral is deﬁned by
 t
0
F(s) dGs :=

[0,t]
F dμ+ −

[0,t]
F dμ−.
(21.52)
(iii) If G ∈Cv, then clearly
G+
t := 1
2

V 1
t (G) + Gt

and
G−
t := 1
2

V 1
t (G) −Gt

is a decomposition of G as in (ii). ♦
The fact that the paths of Brownian motion are nowhere differentiable can be used
to infer that the paths have inﬁnite variation. However, there is also a simple direct
argument.
Theorem 21.55 Let W be a Brownian motion. Then V 1
t (W) = ∞almost surely
for every t > 0.

562
21
Brownian Motion
Proof It is enough to consider t = 1 and to show
Yn :=
2n

i=1
Wi2−n −W(i−1)2−n
 n→∞
−→∞
a.s.
(21.53)
We have E[Yn] = 2n/2 E[|W1|] = 2n/2√2/π and Var[Yn] = 1 −2/π. By
Chebyshev’s inequality,
∞

n=1
P
'
Yn ≤1
2 2n/22
2/π
(
≤
∞

n=1
2π −4
2n
= 2π −4 < ∞.
Using the Borel–Cantelli lemma, this implies (21.53).
⊓⊔
Evidently, the variation is too crude a measure to quantify essential path properties
of Brownian motion. Hence, instead of the increments (in the deﬁnition of the
variation), we will sum up the (smaller) squared increments. For the deﬁnition of
this square variation, more care is needed than in Deﬁnition 21.52 for the variation.
Deﬁnition 21.56 A sequence P = (Pn)n∈N of countable subsets of [0, ∞),
Pn := {t0, t1, t2, . . .}
with 0 = t0 < t1 < t2 < . . . ,
is called an admissible partition sequence if
(i) P1 ⊂P2 ⊂. . .,
(ii) sup Pn = ∞for every n ∈N, and
(iii) the mesh size
|Pn| := sup
t∈Pn
min
s∈Pn, s̸=t |s −t|
tends to 0 as n →∞.
If 0 ≤S < T , then deﬁne
Pn
S,T := Pn ∩[S, T )
and
Pn
T := Pn ∩[0, T ).
If t = tk ∈Pn
T , then let t′ := tk+1 ∧T = min
	
s ∈Pn
T ∪{T } : s > t

.
Example 21.57 Pn = {k2−n : k = 0, 1, 2, . . .}. ♦
Deﬁnition 21.58 For continuous F, G : [0, ∞) →R and for p ≥1, deﬁne the
p-variation of G (along P) by
V p
T (G) := V P,p
T
(G) := lim
n→∞

t∈Pn
T
Gt′ −Gt
p
for T ≥0

21.10
Square Variation and Local Martingales
563
if the limit exists. In particular, ⟨G⟩:= V 2(G) is called the square variation of G.
If T →V 2
T (G) is continuous, then we write G ∈Cqv := CP
qv.
If, for every T ≥0, the limit
V P,2
T
(F, G) := lim
n→∞

t∈Pn
T

Ft′ −Ft

Gt′ −Gt

exists, then we call ⟨F, G⟩:= V 2(F, G) := V P,2(F, G) the quadratic covariation
of F and G (along P).
Remark 21.59 If p′ > p and V p
T (G) < ∞, then V p′
T (G) = 0. In particular, we
have ⟨G⟩≡0 if G has locally ﬁnite variation. ♦
Remark 21.60 By the triangle inequality, we have

t∈Pn+1
T
Gt′ −Gt
 ≥

t∈Pn
T
Gt′ −Gt

for all n ∈N, T ≥0.
Hence in the case p = 1, the limit always exists and coincides with V 1(G) from
Deﬁnition 21.52 (and is hence independent of the particular choice of P). A similar
inequality does not hold for V 2 and thus the limit need not exist or may depend
on the choice of P. In the following, we will, however, show that, for a large
class of continuous stochastic processes, V 2 exists almost surely along a suitable
subsequence of partitions and is almost surely unique. ♦
Remark 21.61
(i) If ⟨F + G⟩T and ⟨F −G⟩T exist, then the covariation ⟨F, G⟩T exists and the
polarization formula holds:
⟨F, G⟩T = 1
4
⟨F + G⟩T −⟨F −G⟩T
.
(ii) If ⟨F⟩T , ⟨G⟩T and ⟨F, G⟩T exist, then by the Cauchy–Schwarz inequality, we
have for the approximating sums
V 1
T (⟨F, G⟩) ≤
2
⟨F⟩T ⟨G⟩T .
♦
Remark 21.62 If f ∈C1(R) and G ∈Cqv, then (exercise!) in the sense of the
Lebesgue–Stieltjes integral
⟨f (G)⟩T =
 T
0
(f ′(Gs))2 d⟨G⟩s.
♦
Corollary 21.63 If F has locally ﬁnite square variation and if ⟨G⟩≡0 (hence, in
particular, if G has locally ﬁnite variation), then ⟨F, G⟩≡0 and ⟨F + G⟩= ⟨F⟩.

564
21
Brownian Motion
Theorem 21.64 For Brownian motion W and for every admissible sequence of
partitions, we have
⟨W⟩T = T
for all T ≥0
a.s.
Proof We prove this only for the case where
∞

n=1
|Pn| < ∞.
(21.54)
For the general case, we only sketch the argument.
Accordingly, assume (21.54). If ⟨W⟩exists, then T
→⟨W⟩T is monotone
increasing. Hence, it is enough to show that ⟨W⟩T exists for every T ∈Q+ =
Q ∩[0, ∞) and that almost surely ⟨W⟩T = T . Since ( 
Wt)t≥0 =

T −1/2WtT

t≥0 is
a Brownian motion, and since ⟨
W⟩1 = T −1⟨W⟩T , it is enough to consider the case
T = 1.
Deﬁne
Yn :=

t∈Pn
1
(Wt′ −Wt)2
for all n ∈N.
Then E[Yn] = 
t∈Pn
1 (t′ −t) = 1 and
Var[Yn] =

t∈Pn
1
Var
)
(Wt′ −Wt)2*
= 2

t∈Pn
1
(t′ −t)2 ≤2 |Pn|.
By assumption (21.54), we thus have ∞
n=1 Var[Yn] ≤2 ∞
n=1 |Pn| < ∞; hence
Yn
n→∞
−→1 almost surely.
If we drop the assumption (21.54), then we still have Var[Yn]
n→∞
−→0; hence
Yn
n→∞
−→
1 in probability. However, it is not too hard to show that (Yn)n∈N is a
backwards martingale (see, e.g., [140, Theorem I.28]) and thus converges almost
surely to 1.
⊓⊔
Corollary 21.65 If W and 
W are independent Brownian motions, then we have
⟨W, 
W⟩T = 0.
Proof The continuous processes ((W + 
W)/
√
2 ) and (W −
W)/
√
2 ) have inde-
pendent normally distributed increments. Hence they are Brownian motions. By
Remark 21.61(i), we have
4
B
W, 
W
C
T =
B
W + 
W
C
T −
B
W −
W
C
T
= 2
B
(W + 
W)/
√
2
C
T −2
B
(W −
W)/
√
2
C
T = 2T −2T = 0.
⊓⊔

21.10
Square Variation and Local Martingales
565
Clearly, (Wt 
Wt )t≥0 is a continuous martingale. Now, by Exercise 21.4.2, the
process (W 2
t −t)t≥0 is also a continuous martingale. Thus, as shown above,
the processes W 2 −⟨W⟩and W 
W −⟨W, 
W⟩are martingales. We will see
(Theorem 21.70) that the square variation ⟨M(ω)⟩of a square integrable continuous
martingale M always exists (for almost all ω) and that the process ⟨M⟩is uniquely
determined by the property that M2 −⟨M⟩is a martingale.
In order to obtain a similar statement for continuous martingales that are not
square integrable, we make the following deﬁnition.
Deﬁnition 21.66 (Local martingale) Let F be a ﬁltration on (Ω, F, P) and let τ
be an F-stopping time. An adapted real-valued stochastic process M = (Mt)t≥0 is
called a local martingale up to time τ if there exists a sequence (τn)n∈N of stopping
times such that τn ↑τ almost surely and such that, for every n ∈N, the stopped
process Mτn = (Mτn∧t)t≥0 is a uniformly integrable martingale. Such a sequence
(τn)n∈N is called a localising sequence for M. M is called a local martingale if M
is a local martingale up to time τ ≡∞. Denote by Mloc,c the space of continuous
local martingales.
Remark 21.67 Let M be a continuous adapted process and let τ be a stopping time.
Then the following are equivalent:
(i) M is a local martingale up to time τ.
(ii) There is a sequence (τn)n∈N of stopping times with τn ↑τ almost surely and
such that every Mτn is a martingale.
(iii) There is a sequence (τn)n∈N of stopping times with τn ↑τ almost surely and
such that every Mτn is a bounded martingale.
Indeed, (iii) ⇒(i) ⇒(ii) is trivial. Hence assume that (ii) holds, and deﬁne τ ′
n
by
τ ′
n := inf{t ≥0 : |Mt| ≥n}
for all n ∈N.
Since M is continuous, we have τ ′
n ↑∞. Hence (σn)n∈N := (τn ∧τ ′
n)n∈N is a
localising sequence for M such that every Mσn is a bounded martingale. ♦
Remark 21.68 A bounded local martingale M is a martingale. Indeed, assume that
|Mt| ≤C < ∞almost surely for all t ≥0 and that (τn)n∈N is a localising
sequence for M. Let t > s ≥0 and A ∈Fs. Then A ∩{τn > s} ∈Fτn∧s and hence
E
)
Mτn∧t 1A∩{τn>s}
*
= E
)
Mτn∧s 1A∩{τn>s}
*
.
Since τn ↑∞, the dominated convergence theorem (Corollary 6.26) yields
E
)
Mt 1A
*
= E
)
Ms 1A
*
.
Hence E[Mt |Fs] = Ms and thus M is a martingale. ♦

566
21
Brownian Motion
Example 21.69
(i) Every martingale is a local martingale.
(ii) In Remark 21.68, we saw that bounded local martingales are martingales. On
the other hand, even a uniformly integrable local martingale need not be a
martingale: Let W = (W 1, W 2, W 3) be a three-dimensional Brownian motion
(that is, W 1, W 2 and W 3 are independent Brownian motions) that starts at
W0 = x ∈R3 \ {0}. Let
u(y) = ∥y∥−1
for y ∈R3 \ {0}.
It is easy to check that u is harmonic; that is, △u(y) = 0 for all y ̸= 0. We will see
later (Corollary 25.34) that this implies that M := (u(Wt))t≥0 is a local martingale.
Deﬁne a localising sequence for M by
τn := inf
	
t > 0 : Mt ≥n

= inf
	
t > 0 : ∥Wt∥≤1/n

,
n ∈N.
An explicit computation with the three-dimensional normal distribution shows
E[Mt] ≤t−1/2
t→∞
−→
0; hence M is integrable but is not a martingale. Since
Mt
t→∞
−→0 in L1, M is uniformly integrable. ♦
Theorem 21.70 Let M be a continuous local martingale.
(i) There exists a unique continuous, monotone increasing, adapted process
⟨M⟩= (⟨M⟩t)t≥0 with ⟨M⟩0 = 0 such that
M2
t −⟨M⟩t

t≥0
is a continuous local martingale.
(ii) If M is a continuous square integrable martingale, then M2 −⟨M⟩is a
martingale.
(iii) For every admissible sequence of partitions P = (Pn)n∈N, we have
Un
T :=

t∈Pn
T
Mt′ −Mt
2 n→∞
−→⟨M⟩T
in probability
for all T ≥0.
The process ⟨M⟩is called the square variation process of M.
Remark 21.71 By possibly passing in (iii) to a subsequence P′ (that might depend
on T ), we may assume that Un
T
n→∞
−→
⟨M⟩T almost surely. Using the diagonal
sequence argument, we obtain (as in the proof of Helly’s theorem) a sequence of
partitions such that Un
T
n→∞
−→
⟨M⟩T almost surely for all T ∈Q+. Since both
T →Un
T and T →⟨M⟩T are monotone and continuous, we get Un
T
n→∞
−→⟨M⟩T

21.10
Square Variation and Local Martingales
567
for all T ≥0 almost surely. Hence, for this sequence of partitions, the pathwise
square variation almost surely equals the square variation process:
⟨M(ω)⟩= V 2(M(ω)) = ⟨M⟩(ω).
♦
Reﬂection In (iii) we only claim stochastic convergence, not almost sure conver-
gence. Can you ﬁnd an example where the convergence is really not almost sure but
only stochastic? ♠♠♠
Proof (of Theorem 21.70) Step 1.
First let |Mt| ≤C almost surely for all t ≥0
for some C < ∞. Then, in particular, M is a martingale (by Remark 21.68). Write
Un
T = M2
T −M2
0 −Nn
T , where
Nn
T = 2

t∈Pn
T
Mt

Mt′ −Mt

,
T ≥0,
is a continuous martingale. Assume that we can show that, for every T
≥0,
(Un
T )n∈N is a Cauchy sequence in L2(P). Then also (Nn
T )n∈N is a Cauchy sequence,
and we can deﬁne 
NT as the L2-limit of (Nn
T )n∈N. By Exercise 21.4.3, 
N has a
continuous modiﬁcation N, and we have Nn
T
n→∞
−→NT in L2 for all T ≥0. Thus
there exists a continuous process ⟨M⟩with
Un
T
n→∞
−→⟨M⟩T
in L2
for all T ≥0,
(21.55)
and N = M2 −M2
0 −⟨M⟩is a continuous martingale.
It remains to show that, for all T ≥0,
(Un
T )n∈N is a Cauchy sequence in L2.
(21.56)
For m ∈N, let
Zm := max

Mt −Ms
2 : s ∈Pm
T , t ∈Pn
s,s′, n ≥m

.
Since M is almost surely uniformly continuous on [0, T ], we have Zm
m→∞
−→
0
almost surely. As Zm ≤4C2, we infer
E
)
Z2
m
* m→∞
−→0.
(21.57)
For n ∈N and numbers a0, . . . , an, we have
(an −a0)2 −
n−1

k=0
(ak+1 −ak)2 = 2
n−1

k=0
(ak −a0)(ak+1 −ak).

568
21
Brownian Motion
In the following computation, we apply this to each summand in the outer sum to
obtain for m ∈N and n ≥m
Um
T −Un
T =

s∈Pm
T

Ms′ −Ms
2 −

t∈Pn
s,s′

Mt′ −Mt
2

= 2

s∈Pm
T

t∈Pn
s,s′

Mt −Ms

Mt′ −Mt

.
(21.58)
Since M is a martingale, for s1, s2 ∈Pm
T and t1 ∈Pn
s1,s′
1, t2 ∈Pn
s2,s′
2 with t1 < t2,
we have
E
'
Mt1 −Ms1

Mt′
1 −Mt1

Mt2 −Ms2

Mt′
2 −Mt2
(
= E
'
Mt1 −Ms1

Mt′
1 −Mt1

Mt2 −Ms2

E
)
Mt′
2 −Mt2
Ft2
*(
= 0.
If we use (21.58) to compute the expectation of

Um
T −Un
T
2, then the mixed terms
vanish and we get (using the Cauchy–Schwarz inequality in the third line)
E
)
(Un
T −Um
T )2*
= 4 E
+ 
s∈Pm
T

t∈Pn
s,s′
(Mt −Ms)2(Mt′ −Mt)2
,
≤4 E
+
Zm

t∈Pn
T
Mt′ −Mt
2
,
≤4 E
)
Z2
m
*1/2 E
+ 
t∈Pn
T

Mt′ −Mt
2
2,1/2
.
(21.59)
For the second factor,
E
+ 
t∈Pn
T

Mt′ −Mt
2
2,
= E
+ 
t∈Pn
T

Mt′ −Mt
4
,
+ 2 E
+ 
s∈Pn
T
Ms′ −Ms
2 
t∈Pn
s′,T
Mt′ −Mt
2
,
.
(21.60)
The ﬁrst summand in (21.60) is bounded by
4C2 E
+ 
t∈Pn
T
Mt′ −Mt
2
,
= 4C2 E)(MT −M0)2* ≤16 C4.

21.10
Square Variation and Local Martingales
569
The second summand in (21.60) equals
2 E
+ 
s∈Pn
T
Ms′ −Ms
2 E
+ 
t∈Pn
s′,T
Mt′ −Mt
2
Fs′
,,
= 2 E
+ 
s∈Pn
T

Ms′ −Ms
2 E
)
(MT −Ms′)2Fs′*,
≤8C2 E
)
(MT −M0)2*
≤32 C4.
Together with (21.59) and (21.57), we obtain
sup
n≥m
E
)
(Un
T −Um
T )2*
≤16
√
3 C2 E
)
Z2
m
*1/2
m→∞
−→
0.
This shows (21.56).
Step 2.
Now let M ∈Mloc,c and let (τN)N∈N be a localising sequence such that
every MτN is a bounded martingale (see Remark 21.67). By Step 1, for T ≥0 and
N ∈N, we have
UN,n
T
:=

t∈Pn
T

MτN
t′ −MτN
t
2 n→∞
−→⟨MτN ⟩T in L2.
Since UN,n
T
= UN+1,n
T
if T ≤τN, there is a continuous process U with UN,n
T
n→∞
−→
UT in probability if T ≤τN. Thus ⟨MτN ⟩T = ⟨M⟩T := UT if T ≤τN. Since
τN ↑∞almost surely, for all T ≥0,
Un
T
n→∞
−→⟨M⟩T in probability.
As

(MτN
T )2 −⟨MτN ⟩T

T ≥0 is a continuous martingale and since ⟨MτN ⟩= ⟨M⟩τN ,
we have M2 −⟨M⟩∈Mloc,c.
Step 3.
It remains to show (ii). Let M be a continuous square integrable martingale
and let (τn)n∈N be a localising sequence for the local martingale M2 −⟨M⟩. Let
T > 0 and let τ ≤T be a stopping time. Then M2
τn∧τ ≤E[M2
T |Fτn∧τ] since M2
is a nonnegative submartingale. Hence (M2
τn∧τ)n∈N is uniformly integrable and thus
(using the monotone convergence theorem in the last step)
E
)
M2
τ
*
= lim
n→∞E
)
M2
τn∧τ
*
= lim
n→∞E
)
⟨M⟩τn∧τ
*
+ E
)
M2
0
*
= E
)
⟨M⟩τ
*
+ E
)
M2
0
*
.
Thus, by the optional sampling theorem, M2 −⟨M⟩is a martingale.
Step 4 (Uniqueness).
Let A and A′ be continuous, monotone increasing, adapted
processes with A0 = A′
0 such that M2 −A and M2 −A′ are local martingales. Then

570
21
Brownian Motion
also N = A −A′ is a local martingale, and for almost all ω, the path N(ω) has
locally ﬁnite variation. Thus ⟨N⟩≡0 and hence N2 −⟨N⟩= N2 is a continuous
local martingale with N0 = 0. Let (τn)n∈N be a localising sequence for N2. Then
E
)
N2
τn∧t
*
= 0 for any n ∈N and t ≥0; hence N2
τn∧t = 0 almost surely and thus
N2
t = limn→∞N2
τn∧t = 0 almost surely. We conclude A = A′.
⊓⊔
Corollary 21.72 Let M be a continuous local martingale with ⟨M⟩≡0. Then
Mt = M0 for all t ≥0 almost surely. In particular, this holds if the paths of M have
locally ﬁnite variation.
Corollary 21.73 Let M, N
∈Mloc,c. Then there exists a unique continuous
adapted process ⟨M, N⟩with almost surely locally ﬁnite variation and ⟨M, N⟩0 = 0
such that
MN −⟨M, N⟩is a continuous local martingale.
⟨M, N⟩is called the quadratic covariation process of M and N. For every
admissible sequence of partitions P and for every T ≥0, we have
⟨M, N⟩T = lim
n→∞

t∈Pn
T

Mt′ −Mt

Nt′ −Nt

in probability.
(21.61)
Proof Existence Manifestly, M + N, M −N ∈Mloc,c. Deﬁne
⟨M, N⟩:= 1
4

⟨M + N⟩−⟨M −N⟩

.
As the difference of two monotone increasing functions, ⟨M, N⟩has locally ﬁnite
variation. Using Theorem 21.70(iii), we get (21.61). Furthermore,
MN −⟨M, N⟩= 1
4

(M + N)2 −⟨M + N⟩

−1
4

(M −N)2 −⟨M −N⟩

is a local martingale.
Uniqueness Let A and A′ with A0 = A′
0 = 0 be continuous, adapted and with
locally ﬁnite variation such that MN−A and MN−A′ are in Mloc,c. Then A−A′ ∈
Mloc,c have locally ﬁnite variation; hence A −A′ = 0.
⊓⊔
Corollary 21.74 If M ∈Mloc,c and A are continuous and adapted with ⟨A⟩≡0,
then ⟨M + A⟩= ⟨M⟩.
If M is a continuous local martingale up to the stopping time τ, then Mτ ∈Mloc,c,
and we write ⟨M⟩t := ⟨Mτ⟩t for t < τ.
Theorem 21.75 Let τ be a stopping time, M be a continuous local martingale up
to τ and τ0 < τ a stopping time with E[⟨M⟩τ0] < ∞. Then E[Mτ0] = E[M0], and
Mτ0 is an L2-bounded martingale if E[M2
0] < ∞.

21.10
Square Variation and Local Martingales
571
Proof Let τn ↑τ be a localising sequence of stopping times for M such that
every Mτn is even a bounded martingale (see Remark 21.67). Then Mτ0∧τn is also a
bounded martingale, and for every t ≥0, we have
E
)
M2
τ0∧τn∧t
*
= E
)
M2
0
*
+ E
)
⟨M⟩τ0∧τn∧t
*
≤E
)
M2
0
*
+ E
)
⟨M⟩τ0
*
< ∞.
(21.62)
Hence

(Mτ0∧τn∧t), n ∈N, t ≥0

is bounded in L2 and is thus uniformly
integrable. Therefore, by the optional sampling theorem for uniformly integrable
martingales,
E[Mτ0] = lim
n→∞E[Mτ0∧τn] = E[M0],
and, for t > s,
E)Mτ0
t
Fs
* = E
'
lim
n→∞Mτ0∧τn
t
Fs
(
= lim
n→∞E
)
Mτ0∧τn
t
Fs
*
= lim
n→∞Mτ0∧τn
s
= Mτ0
s .
Hence Mτ0 is a martingale.
⊓⊔
Corollary 21.76 If M ∈Mloc,c with E[M2
0] < ∞and E)⟨M⟩t
* < ∞for every
t ≥0, then M is a square integrable martingale.
Takeaways Brownian motion is nowhere differentiable and hence has inﬁnite
variation. On the other hand, the square variation (deﬁned as limit of sums
of squared increments along ﬁner and ﬁner partition sequences) is ﬁnite
over compact sets. In the general context, we identify the pathwise deﬁned
square variation as the variance process of a local martingale M. This is the
increasing process ⟨M⟩from the Doob decomposition of M2 which turns
M2 −⟨M⟩into a local martingale. Hence, ⟨M⟩is a measure for the random
ﬂuctuations of M.
Exercise 21.10.1 Show that the random variables (Yn)n∈N from the proof of
Theorem 21.64 form a backwards martingale. ♣

572
21
Brownian Motion
Exercise 21.10.2 Let f : [0, ∞) →R be continuous and let X ∈CP
qv for the
admissible sequence of partitions P. Show that
 T
0
f (s) d⟨X⟩s = lim
n→∞

t∈Pn
T
f (t)

Xt′ −Xt)2
for all T ≥0.
♣
Exercise 21.10.3 Show by a counterexample that if M is a continuous local
martingale with M0 = 0 and if τ is a stopping time with E)⟨M⟩τ
* = ∞, then
this does not necessarily imply E)M2
τ
* = ∞. ♣

Chapter 22
Law of the Iterated Logarithm
For sums of independent random variables we already know two limit theorems:
the law of large numbers and the central limit theorem. The law of large numbers
describes for large n ∈N, the typical behavior, or average value behavior, of sums
of n random variables. On the other hand, the central limit theorem quantiﬁes the
typical ﬂuctuations about this average value.
In Chap. 23, we will study atypically large deviations from the average value in
greater detail. The aim of this chapter is to quantify the typical ﬂuctuations of the
whole process as n →∞. The main message is: While for ﬁxed time the partial sum
Sn deviates by approximately √n from its expected value (central limit theorem),
the maximal ﬂuctuation up to time n is of order √n log log n (Hartman–Wintner
theorem, Theorem 22.11).
We start with the simpler task of computing the ﬂuctuations for Brownian motion
(Theorem 22.1). After that, we will see how sums of independent centered random
variables (with ﬁnite variance) can be embedded in a Brownian motion (Skorohod’s
theorem, Theorem 22.5). This embedding will be used to prove the Hartman–
Wintner theorem.
In this chapter, we follow essentially the exposition of [39, Section 8.8].
22.1
Iterated Logarithm for the Brownian Motion
Let (Bt)t≥0 be a Brownian motion. In Example 21.16, as an application of Blumen-
thal’s 0–1 law, we saw that lim supt↓0 Bt/√t = ∞a.s. Since by Theorem 21.14,
(tB1/t)t≥0 also is a Brownian motion, we get
lim sup
t→∞
Bt
√t = ∞
a.s.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_22
573

574
22
Law of the Iterated Logarithm
The aim of this section is to replace √t by a function such that the limes superior is
ﬁnite and nontrivial.
Theorem 22.1 (Law of the iterated logarithm for Brownian motion)
lim sup
t→∞
Bt
2
2t log log(t)
= 1
a.s.
(22.1)
Before proving the theorem, we state an elementary lemma.
Lemma 22.2 Let X ∼N0,1 be standard normally distributed. Then, for any x > 0,
1
√
2π
1
x + 1
x
e−x2/2 ≤P[X ≥x] ≤
1
√
2π
1
x e−x2/2.
(22.2)
Proof Let ϕ(t) =
1
√
2π e−t2/2 be the density of the standard normal distribution.
Partial integration yields the second inequality in (22.2),
P[X ≥x] =
 ∞
x
1
t (tϕ(t)) dt = −1
t ϕ(t)

∞
x −
 ∞
x
1
t2 ϕ(t) dt ≤1
x ϕ(x).
Similarly, we get
P[X ≥x] ≥1
x ϕ(x) −1
x2
 ∞
x
ϕ(t) dt = 1
x ϕ(x) −1
x2 P[X ≥x].
This implies the ﬁrst inequality in (22.2).
⊓⊔
Proof of Theorem 22.1
Step 1. “≤”
Let α > 1, and deﬁne tn = αn for n ∈N. Later, we let α ↓1. Deﬁne
f (t) = 2α2 log log t. Then by the reﬂection principle (Theorem 21.19) and using
the abbreviation B[a,b] := {Bt : t ∈[a, b]}, we obtain
P
'
sup B[tn,tn+1] >
2
tnf (tn)
(
≤P
'
t−1/2
n+1 sup B[0,tn+1] >
2
f (tn)/α
(
= P
'
sup B[0,1] >
2
f (tn)/α
(
≤
K
α
f (tn) e−f (tn)/2α
= (log α)−α
K
α
f (tn) n−α
≤n−α
for large enough n.
(22.3)

22.1
Iterated Logarithm for the Brownian Motion
575
In the next to last step, we used
f (tn)
2α
= α

log(n log α)

= α log n + α log log α.
Since α > 1, the right-hand side of (22.3) is summable in n:
∞

n=1
P
'
sup B[tn,tn+1] >
2
tnf (tn)
(
< ∞.
The Borel–Cantelli lemma (Theorem 2.7) then yields (note that t →√tf (t) is
monotone increasing)
lim sup
t→∞
Bt
√tf (t) ≤1
a.s.
Now let α ↓1 to obtain
lim sup
t→∞
Bt
√2t log log t ≤1
a.s.
(22.4)
Step 2. “≥”
Here we show the other inequality in (22.1). To this end, we let
α →∞. Let β :=
α
α−1 > 1 and g(t) =
2
β2 log log t. Choose n0 large enough that
βg(tn) ≥1 for all n ≥n0. Then, by Brownian scaling (note that tn −tn−1 = 1
β tn)
and (22.2) (since (x + 1
x )−1 ≥1
2
1
x for x = (βg(tn))1/2 ≥1),
P
'
Btn −Btn−1 >
2
tng(tn)
(
= P
'
B1 >
2
βg(tn)
(
≥
1
√
2π
1
2
1
√βg(tn) e−βg(tn)/2
=
1
√
2π
1
2 (log α)−1/β
1
√βg(tn) n−1/β.
If ε ∈(0, 1 −1/β), then, for sufﬁciently large n ∈N, the right-hand side of the
above equation is ≥n−ε n−1/β ≥n−1. Hence
∞

n=2
P
'
Btn −Btn−1 >
2
tng(tn)
(
= ∞.
The events are independent and hence the Borel–Cantelli lemma yields
P
'
Btn −Btn−1 >
2
tng(tn)
for inﬁnitely many n
(
= 1.
(22.5)

576
22
Law of the Iterated Logarithm
Since
tn log log tn
tn−1 log log tn−1
n→∞
−→α, (22.4) and symmetry of Brownian motion imply
that, for ε > 0,
Btn−1 > −(1 + ε) α−1/2 2
2tn log log tn
for almost all n ∈N
a.s.
(22.6)
From (22.5) and (22.6), it follows that
lim sup
n→∞
Btn
√2tn log log tn
≥1
β −(1 + ε) α−1/2 = α −1
α
−(1 + ε) α−1/2
a.s.
Now, letting α →∞gives lim sup
t→∞
Bt
√2t log log t ≥1 a.s. Together with (22.4), this
implies the claim of the theorem.
⊓⊔
Corollary 22.3 For every s ≥0, a.s. we have lim sup
t↓0
Bs+t −Bs
2
2t log log(1/t)
= 1.
Proof Without loss of generality, assume s = 0. Apply Theorem 22.1 to the
Brownian motion (tB1/t) (see Theorem 21.14).
⊓⊔
Remark 22.4 The statement of Corollary 22.3 is about the typical points s of
Brownian motion B. However, there might be points in which Brownian motion
moves faster than
2
2t log log(1/t). The precise statement is due to Paul Lévy [106]:
Denote by h(δ) :=
2
2δ log(1/δ) Lévy’s modulus of continuity. Then
P
'
lim
δ↓0
sup
s,t∈[0,1]
0≤t−s≤δ
|Bt −Bs|/h(δ) = 1
(
= 1.
(22.7)
(See, e.g., [145, Theorem I.2.5] for a proof.) This implies in particular that almost
surely B is not locally Hölder- 1
2-continuous. ♦
Takeaways The typical ﬂuctuation of a Brownian motion at time t is of order
√t. Its maximal value by time t, however, has size
2
2t log log(t) as t →∞.
Due to the two logarithms in this formula, this statement is called law of the
iterated logarithm. We have proved it by ﬁrst showing it along a geometric
sequence of times and then ﬁlling the gaps.
22.2
Skorohod’s Embedding Theorem
In order to carry over the result of the previous section to sums of square integrable
centered random variables, we use an embedding of such random variables in

22.2
Skorohod’s Embedding Theorem
577
a Brownian motion that is due to Skorohod. This technique also provides an
alternative proof of Donsker’s invariance principle (Theorem 21.43).
Theorem 22.5 (Skorohod’s embedding theorem) Let X be a real random vari-
able with E[X] = 0 and Var[X] < ∞. Then on a suitable probability space we
can construct a random variable Ξ, a Brownian motion B that is independent of Ξ
and an F-stopping time τ such that
Bτ
D= X
and
E[τ] = Var[X].
Here the ﬁltration F is given by Ft = σ(Ξ, (Bs)s≤t).
Remark 22.6 In the above theorem we can de without the additional random
variable; that is, we can choose F = σ(B). The proof is rather involved, though
(see page 579). ♦
Corollary 22.7 Let X1, X2, . . . be i.i.d. real random variables with E[X1] = 0
and Var[X1] < ∞. Further, let Sn = X1 + . . . + Xn, n ∈N. Then on a suitable
probability space there exists a ﬁltration F, a Brownian motion B and F-stopping
times 0 = τ0 ≤τ1 ≤τ2 ≤. . . such that (τn −τn−1)n∈N is i.i.d., E[τ1] = Var[X1]
and (Bτn)n∈N
D= (Sn)n∈N.
Proof (of Corollary 22.7) We only sketch the proof. The details are left to the
reader.
Choose independent triples (B(n), Ξ(n), τ (n)), n ∈N, as in Theorem 22.5. Let τn =
τ (1) + . . . + τ (n). For t ≤τ1 let Bt := B(1)
t
, and deﬁne recursively
Bt = Bτn + B(n+1)
t−τn ,
if τn < t ≤τn+1.
Using repeatedly the strong Markov property of Brownian motion, we see that B is
a Brownian motion. Now let Ft = σ((Ξn)n∈N, (Bs)s≤t).
⊓⊔
We prepare for the proof of Theorem 22.5 with a lemma. In order to allow measures
as integrands, we use the following notation: If μ ∈M(E) is a measure and f ∈
L1(μ) is nonnegative, then deﬁne
3
μ(dx)f (x)δx := f μ, where f μ is the measure
with density f with respect to μ. This is consistent since for measurable A ⊂E,
we then have

μ(dx)f (x)δx

(A) =

μ(dx)f (x)δx(A) =

μ(dx)f (x) 1A(x) = f μ(A).
Lemma 22.8 Let μ ∈M1(R) with
3
x μ(dx) = 0 and σ 2 :=
3
x2 μ(dx) < ∞.
Then there exists a probability measure θ ∈M1((−∞, 0) × [0, ∞)) with
μ =

θ(d(u, v))

v
v −u δu +
−u
v −u δv

.
(22.8)
Furthermore, σ 2 = −
3
uv θ(d(u, v)).

578
22
Law of the Iterated Logarithm
Proof Deﬁne m :=
3
[0,∞) v μ(dv) = −
3
(−∞,0) u μ(du). If m = 0, then θ =
δ(−1,0) is a possible choice. Assume now m > 0 and deﬁne θ by
θ(d(u, v)) := m−1(v −u) μ(du)μ(dv)
for u < 0 and v ≥0.
Then

θ(d(u, v)) = m−1

(−∞,0)
μ(du)

[0,∞)
μ(dv) (v −u)
= m−1

(−∞,0)
μ(du) [m −uμ([0, ∞))]
= m−1
mμ((−∞, 0)) + mμ([0, ∞))

= 1.
Hence, θ is in fact a probability measure. Furthermore,

θ(d(u, v))

v
v −u δu +
−u
v −u δv

= m−1

(−∞,0)
μ(du)

[0,∞)
μ(dv) (vδu −uδv)
=

(−∞,0)
μ(du) δu +

[0,∞)
μ(dv) δv = μ.
By (22.8), we infer
σ 2 =

μ(dx) x2 =

θ(d(u, v))

v
v −u u2 +
−u
v −u v2
= −

θ(d(u, v)) uv. ⊓⊔
Proof (Theorem 22.5) First assume that X takes only the two values u < 0 and
v ≥0: P[X = u] =
v
v−u = 1 −P[X = v]. Let
τu,v = inf
	
t > 0 : Bt ∈{u, v}

.
By Exercise 21.2.4, we have E[Bτu,v] = 0; hence Bτu,v
D= X and E[τu,v] = −uv.
Now let X be arbitrary with E[X] = 0 and σ 2 := E[X2] < ∞. Deﬁne μ = PX
and θ = θμ as in Lemma 22.8. Further, let Ξ = (Ξu, Ξv) be a random variable with
values in (−∞, 0) × [0, ∞) and with distribution θ.
Let F = (Ft)t≥0 where Ft := σ(Ξ, Bs : s ∈[0, t]). Deﬁne τ := τΞu,Ξv. By
continuity of B, we get
{τ ≤t} =

sup
s∈[0,t]
Bs ≥Ξv

∪

inf
s∈[0,t]Bs ≤Ξu

∈Ft.

22.2
Skorohod’s Embedding Theorem
579
Hence τ is an F-stopping time (but not a σ(B)-stopping time). For x < 0,
P[X ≤x] =

(−∞,x]×[0,∞)
θ(d(u, v))
v
v −u
=

(−∞,x]×[0,∞)
θ(d(u, v)) P[Bτu,v = u] = P[Bτ ≤x].
For x ≥0, we similarly get P[X > x] = P[Bτ > x]. Summing up, we have
Bτ
D= X. Furthermore,
E[τ] = −E[ΞuΞv] = −

θ(d(u, v)) uv = σ 2.
⊓⊔
Supplement: Proof of Remark 22.6
Here we prove that in Skorohod’s embedding theorem we can really do without
randomized stopping times; that is, we can choose a stopping time with respect to
the ﬁltration generated by the Brownian motion B. In other words, the stopping time
can be chosen without using additional random variables, such as the Ξ in the proof
given above.
An elegant proof that is based on stochastic analysis methods can be found in
Azéma and Yor; see [7] and [6]. See also [118] for a more elementary version of
that proof. Here, however, we follow an elementary route whose basic idea goes
back to Dubins.
For u < 0 < v, let τu,v = inf{t > 0 : Bt ∈{u, v}}. Hence, if X is a centered
random variable that takes only the values u and v, then, as shown in the proof of
Theorem 22.5, Bτu,v
D= X and E[τu,v] = E[X2].
In a ﬁrst step, we generalize this statement to binary splitting martingales. (Recall
from Deﬁnition 9.42 that a binary splitting process at each time step has a choice of
just two different values, which may however depend on the history of the process.)
In a second step, we show that square integrable centered random variables can be
expressed as limits of such martingales.
Theorem 22.9 Let (Xn)n∈N0 be a binary splitting martingale with X0 = 0. Let B
be a Brownian motion and let F = σ(B) be its canonical ﬁltration. Then there exist
F-stopping times 0 = τ0 ≤τ1 ≤. . . such that
(Xn)n∈N0
D= (Bτn)n∈N0
and such that E[τn] = E[X2
n] holds for all n ∈N0.

580
22
Law of the Iterated Logarithm
If (Xn)n∈N0 is bounded in L2 and thus converges almost surely and in L2 to
some square integrable X∞, then τ := supn∈N τn < ∞a.s., E[τ] = Var[X∞] and
X∞
D= Bτ .
Proof For n ∈N, let fn : Rn−1 × {−1, +1} →R and let Dn be a {−1, +1}-
valued random variable such that Xn = fn(X1, . . . , Xn−1, Dn) holds (compare
Deﬁnition 9.42). Without loss of generality, we may assume that fn is monotone
increasing in Dn. Let τ0 := 0 and inductively deﬁne
τn := inf
	
t > τn−1 : Bt ∈{fn(Bτ1, . . . , Bτn−1, −1), fn(Bτ1, . . . , Bτn−1, +1)}

.
Let ˜Xn := Bτn and
˜Dn :=
0
1,
if
˜Xn ≥˜Xn−1,
−1,
else.
By Exercise 21.2.4 and using the strong Markov property (at τn−1), we get
P
) ˜Dn = 1
 ˜X1, . . . , ˜Xn−1
*
=
˜Xn−1 −fn( ˜X1, . . . , ˜Xn−1, −1)
fn( ˜X1, . . . , ˜Xn−1, +1) −fn( ˜X1, . . . , ˜Xn−1, −1)
and E[τn −τn−1] = E[( ˜Xn −˜Xn−1)2]. On the other hand, since (Xn)n∈N0 is a
martingale, we have
Xn−1 = E[Xn|X0, . . . , Xn−1]
=

i=−1,+1
P[Dn = i|X0, . . . , Xn−1] fn(X1, . . . , Xn−1, i).
Therefore,
P
)
Dn = 1
X1, . . . , Xn−1
*
=
Xn−1 −fn(X1, . . . , Xn−1, −1)
fn(X1, . . . , Xn−1, +1) −fn(X1, . . . , Xn−1, −1).
This implies (Xn)n∈N0
D= ( ˜Xn)n∈N0. Since E[τn −τn−1] = E[(Xn −Xn−1)2],
and since the martingale differences (Xi −Xi−1), i ∈N, are uncorrelated, we get
E[τn] = E[X2
n].
Finally, if (Xn) is bounded in L2, then by the martingale convergence theorem
there is a square integrable centered random variable X∞such that Xn
n→∞
−→X∞
almost surely and in L2. In particular, we have E[X2
n]
n→∞
−→
E[X2
∞]. Clearly,
(τn)n∈N is monotone increasing and thus converges to some stopping time τ. By

22.2
Skorohod’s Embedding Theorem
581
the monotone convergence theorem, E[τ] = limn→∞E[τn] = limn→∞E[X2
n] =
E[X2
∞] < ∞. Hence τ < ∞a.s. As Brownian motion is continuous, we conclude
Bτ = lim
n→∞Bτn = lim
n→∞
˜Xn
D= X∞.
⊓⊔
We have shown the statement of Remark 22.6 in the case where the random
variable X is the limit of a binary splitting martingale. The general case is now
implied by the following theorem (Figs. 22.1 and 22.2).
Theorem 22.10 Let X be a square integrable centered random variable. Then there
exists a binary splitting martingale (Xn)n∈N0 with X0 = 0 and such that Xn
n→∞
−→
X almost surely and in L2.
Proof We follow the idea of the proof in [118]. Let X0 := E[X] = 0. Inductively,
for n ∈N, deﬁne
Dn :=

1,
if X ≥Xn−1,
−1,
if X < Xn−1,
Fn := σ(D1, . . . , Dn)
and
Xn := E[X|Fn].
0
1
−1.5
1.5
0
−1
−2
2
1
3/5
2/5
2/3
1/3
1/2
1/2
1/2
1/2
Fig. 22.1 Binary splitting martingale for the random variable X with P[X = k] =
1
5 for k =
−2, −1, 0, 1, 2.

582
22
Law of the Iterated Logarithm
Hence there exists a map gn : {−1, +1}n →R such that gn(D1, . . . , Dn) = Xn.
Clearly, 1Dk=1 = 1Xk≥Xk−1 almost surely for all k ∈N. Hence the D1, . . . , Dk can
be computed from the X1, . . . , Xk. Thus there exists a map fn : Rn−1×{−1, +1} →
R such that fn(X1, . . . , Xn−1, Dn) = Xn. Therefore, (Xn) is binary splitting.
Manifestly, (Xn)n∈N0 is a martingale. By Jensen’s inequality, we have E[X2
n] ≤
E[X2] < ∞for all n ∈N. Hence (Xn)n∈N0 is bounded in L2 and thus converges
almost surely and in L2 to some square integrable X∞. It remains to show that
X∞= X holds almost surely. To this end, we ﬁrst show
lim
n→∞Dn(ω)X(ω) −Xn(ω) =
X(ω) −X∞(ω)

for almost all ω.
(22.9)
If X(ω) = X∞(ω), then (22.9) holds trivially. If X(ω) > X∞(ω), then X(ω) >
Xn(ω) and thus Dn(ω) = 1 for all sufﬁciently large n; hence (22.9) holds. Similarly,
we get (22.9) if X(ω) < X∞(ω).
Evidently, we have
E
)
Dn(X −Xn)
*
= E
)
Dn E[X −Xn|Fn]
*
= 0.
As

Dn(X −Xn)

n∈N is bounded in L2 (and is thus uniformly integrable), we get
E[|X −X∞|] = limn→∞E[Dn(X −Xn)] = 0; hence X = X∞a.s.
⊓⊔
●
●
●
●
●
●
●
●
●
●
●
τ0
τ1
τ2
τ3 τ4
τ5
τ6 τ7
τ8
τ9
τ10
Bt
Fig. 22.2 Embedding of random variables with uniform distribution on {−2, −1, 0, 1, 2} in a
Brownian motion. After ﬁrst hitting {−1.5, 1} there are two possibilities. In the case where −1.5
is hit before 1, the Brownian motion continuous and is ﬁnally stopped upon hitting −2 or −1. In
the other case, we continue until the Brownian motion hits 0 or 1.5. If it is 0, the Brownian motion
stops. If it is 1.5, we continue until the motion hits 1 or 2. The random time at which the motion
if ﬁnally stopped is τ1. After τ1, we can continue in order generate another sample of the random
variable. Note that in the second period, we have to add Bτ1 to all numbers.

22.3
Hartman–Wintner Theorem
583
Takeaways A centred square integrable random variable can be represented
by a Brownian motion evaluated at a stopping time. There is freedom in the
choice of the stopping time, but there exists an optimal (minimal) stopping
time in the sense that the expected value of the stopping time is the variance
of the random variable. It is impossible to do better. By a repetition of the
argument, the partial sums of i.i.d. centred square integrable random variables
can be embedded in the path of a Brownian motion evaluated at a sequence of
stopping times.
22.3
Hartman–Wintner Theorem
The goal of this section is to prove the law of the iterated logarithm for i.i.d. centered
square integrable random variables Xn, n ∈N, that goes back to Hartman and
Wintner (see [69]). For the special case of Rademacher random variables, the upper
bound was found earlier by Khinchin in 1923 (see [97]).
Theorem 22.11 (Hartman–Wintner,
law
of
the
iterated
logarithm) Let
X1, X2, . . . be i.i.d. real random variables with E[X1] = 0 and Var[X1] = 1.
Let Sn = X1 + . . . + Xn, n ∈N. Then
lim sup
n→∞
Sn
√2n log log n = 1
a.s.
(22.10)
The strategy of the proof is to embed the partial sums Sn of the random variables
in a Brownian motion and then use the law of the iterated logarithm for Brownian
motion. The Skorohod embedding theorem ensures that this works. We follow the
exposition in [39, Section 8.8].
Proof By Corollary 22.7, on a suitable probability space there exists a ﬁltration F,
a Brownian motion B that is an F-martingale, and stopping times τ1 ≤τ2 ≤. . .
such that (Sn)n∈N
D= (Bτn)n∈N. Furthermore, the (τn −τn−1)n∈N are i.i.d. with
E[τn −τn−1] = Var[X1] = 1.
By the law of the iterated logarithm for Brownian motion (see Theorem 22.1),
we have
lim sup
t→∞
Bt
√2t log log t = 1
a.s.
Hence, it is enough to show that
lim sup
t→∞
|Bt −Bτ⌊t⌋|
√2t log log t = 0
a.s.

584
22
Law of the Iterated Logarithm
By the strong law of large numbers (Theorem 5.17), we have 1
nτn
n→∞
−→1 a.s., so
let ε > 0 and let t0 = t0(ω) be large enough that
1
1 + ε ≤τ⌊t⌋
t
≤1 + ε
for all t ≥t0.
Deﬁne
Mt :=
sup
s∈[t/(1+ε), t (1+ε)]
|Bs −Bt|.
It is enough to show that lim sup
t→∞
Mt
√2t log log t = 0. Consider the sequence tn =
(1 + ε)n, n ∈N, and deﬁne
M′
n :=
sup
s∈[tn−1,tn+2]
|Bs −Btn−1|.
Then (by the triangle inequality), for t ∈[tn, tn+1],
Mt ≤2M′
n.
Let δ := (1+ε)3−1. Then tn+2−tn−1 = δtn−1. Brownian scaling and the reﬂection
principle (Theorem 21.19) now yield
P
'
M′
n >
2
3δtn−1 log log tn−1
(
= P
'
sup
s∈[0,1]
|Bs| >
2
3 log log tn−1
(
≤2 P
'
sup
s∈[0,1]
Bs >
2
3 log log tn−1
(
= 4 P
'
B1 >
2
3 log log tn−1
(
≤
2
√3 log log tn−1
exp

−3
2 log log tn−1

(Lemma 22.2)
≤n−3/2
for n sufﬁciently large.
The probabilities can be summed over n; hence the Borel–Cantelli lemma yields
lim sup
t→∞
Mt
√t log log t ≤lim sup
n→∞
2M′
n
√tn−1 log log tn−1
≤2
√
3δ.
Letting ε →0, we get δ = (1 + ε)3 −1 →0, and hence the proof is complete.
⊓⊔

22.3
Hartman–Wintner Theorem
585
Takeaways The Skorohod embedding theorem allows to transfer the law
of the iterated logarithm to sums of i.i.d. centred square integrable random
variables.

Chapter 23
Large Deviations
Except for the law of the iterated logarithm, so far we have encountered two types of
limit theorems for partial sums Sn = X1+. . .+Xn, n ∈N, of identically distributed,
real random variables (Xi)i∈N with distribution function F:
(1) (Weak) laws of large numbers state that (under suitable assumptions on the
family (Xi)i∈N), for every x > 0,
P
)Sn −n E[X1]
 ≥xn
* n→∞
−→0.
(23.1)
From this we get immediately that the empirical distribution functions
Fn : x →1
n
n

i=1
1(−∞,x](Xi)
converge in probability; that is, ∥Fn −F∥∞
n→∞
−→0. In other words, for any
distribution function G ̸= F and any ε > 0 with ε < ∥F −G∥∞, we have
P
)
∥Fn −G∥∞< ε
* n→∞
−→0.
(23.2)
(2) Central limit theorems state that (under different assumptions on the family
(Xi)i∈N) for every x ∈R
P
)
Sn −n E[X1] ≥x√n
* n→∞
−→1 −Φ

x
√Var[X1]

.
(23.3)
Here Φ : t →N0,1((−∞, t]) is the distribution function of the standard normal
distribution.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_23
587

588
23
Large Deviations
In each case, the typical value of Sn is n E[X1]. Equation (23.3) makes a precise
statement about the average size of the deviations (which are of order √n) from
the typical value. A simple consequence is of course that the probability of large
deviations (of order n) from the typical value goes to 0; that is, (23.1) holds.
In this chapter, we compute the speed of convergence in (23.1) (Cramér’s
theorem) and in (23.2) (Sanov’s theorem).
We follow in part the expositions in [31] and [74].
23.1
Cramér’s Theorem
Let X1, X2, . . . be i.i.d. with PXi = N0,1. Then, for every x > 0,
P[Sn ≥xn] = P
)
X1 ≥x√n
*
= 1 −Φ

x√n

= (1 + εn)
1
x
√
2πn
e−n x2/2,
where εn
n→∞
−→0 (by Lemma 22.2). Taking logarithms, we get
lim
n→∞
1
n log P
)
Sn ≥xn
*
= −x2
2
for every x > 0.
(23.4)
It might be tempting to believe that a central limit theorem could be used to
show (23.4) for all centered i.i.d. sequences (Xi) with ﬁnite variance. However,
in general, the limit might be inﬁnite or might be a different function of x, as
we will show below. The moral is that large deviations depend more subtly on
the tails of the distribution of Xi than the average-sized ﬂuctuations do (which are
determined by the variance only). The following theorem shows this for Bernoulli
random variables.
Theorem 23.1 Let X1, X2, . . . be i.i.d. with P[X1 = −1] = P[X1 = 1] = 1
2. Then,
for every x ≥0,
lim
n→∞
1
n log P[Sn ≥xn] = −I(x),
(23.5)
where the rate function I is given by (see Fig. 23.1)
I(z) =
 1+z
2 log(1 + z) + 1−z
2 log(1 −z),
if z ∈[−1, 1],
∞,
if |z| > 1.
(23.6)
Remark 23.2 Here we agree that 0 log 0 = 0. This makes the restriction of I to
[−1, 1] a continuous function with I(−1) = I(1) = log 2. Note that I is strictly
convex on [−1, 1] with I(0) = 0 and I is monotone increasing on [0, 1] and is
monotone decreasing on [−1, 0]. ♦

23.1
Cramér’s Theorem
589
−2
−1
0
1
2
log(2)
∞
I(z)
z
Fig. 23.1 Rate function I(z) from (23.6).
Proof (of Theorem 23.1) For x = 0 and x > 1, the claim is trivial. For x = 1, we
have P[Sn ≥n] = 2−n, and thus again (23.5) holds trivially. Hence, it is enough to
consider x ∈(0, 1). Since Sn+n
2
∼bn,1/2 is binomially distributed, we have
P)Sn ≥xn* = 2−n

k≥(1+x)n/2
n
k

.
Deﬁne an(x) = ⌈n(1 + x)/2⌉for n ∈N. Since k →
n
k

is monotone decreasing for
k ≥n
2, we get
Qn(x) := max
0n
k

: an(x) ≤k ≤n
1
=

n
an(x)

.
(23.7)
We make the estimate
2−n Qn(x) ≤P
)
Sn ≥xn
*
≤(n + 1) 2−n Qn(x).
(23.8)
By Stirling’s formula
lim
n→∞
1
n!nne−n√
2πn = 1,

590
23
Large Deviations
we obtain
lim
n→∞
1
n log Qn(x)
= lim
n→∞
1
n log
n!
an(x)! · (n −an(x))!
= lim
n→∞
1
n log
nn
an(x)an(x) · (n −an(x))n−an(x)
= lim
n→∞
+
log(n) −an(x)
n
log

an(x)

−n −an(x)
n
log

n −an(x)
,
= lim
n→∞
+
log(n) −1 + x
2

log
1 + x
2

+ log(n)

−1 −x
2

log
1 −x
2

+ log(n)
,
= −1 + x
2
log
1 + x
2

−1 −x
2
log
1 −x
2

= −I(x) + log 2.
Together with (23.8), this implies (23.5).
⊓⊔
Under certain assumptions on the distribution of X1, Cramér’s theorem [29]
provides a general principle to compute the rate function I.
Theorem 23.3 (Cramér [29]) Let X1, X2, . . . be i.i.d. real random variables with
ﬁnite logarithmic moment generating function
Λ(t) := log E)etX1* < ∞
for all t ∈R.
(23.9)
Let
Λ∗(x) := sup
t∈R

tx −Λ(t)

for x ∈R,
the Legendre transform of Λ. Then, for every x > E[X1],
lim
n→∞
1
n log P
)
Sn ≥xn
*
= −I(x) := −Λ∗(x).
(23.10)
Proof By passing to Xi −x if necessary, we may assume E[Xi] < 0 and x = 0.
(In fact, if ˜Xi := Xi −x, and ˜Λ and ˜Λ∗are deﬁned as Λ and Λ∗above but for ˜Xi
instead of Xi, then ˜Λ(t) = Λ(t)−t ·x and thus ˜Λ∗(0) = supt∈R(−˜Λ(t)) = Λ∗(x).)

23.1
Cramér’s Theorem
591
Deﬁne ϕ(t) := eΛ(t) and
ϱ := e−Λ∗(0) = inf
t∈Rϕ(t).
By (23.9) and the differentiation lemma (Theorem 6.28), ϕ is differentiable
inﬁnitely often and the ﬁrst two derivatives are
ϕ′(t) = E)X1 etX1*
and
ϕ′′(t) = E)X2
1 etX1*.
Hence ϕ is strictly convex and ϕ′(0) = E[X1] < 0.
First consider the case P[X1 ≤0] = 1. Then ϕ′(t) < 0 for every t ∈R and
ϱ = lim
t→∞ϕ(t) = P[X1 = 0]. Therefore,
P[Sn ≥0] = P[X1 = . . . = Xn = 0] = ϱn
and thus the claim follows.
Now let P[X1 < 0] > 0 and P[X1 > 0] > 0. Then lim
t→∞ϕ(t) = ∞=
lim
t→−∞ϕ(t). As ϕ is strictly convex, there is a unique τ ∈R at which ϕ assumes
its minimum; hence
ϕ(τ) = ϱ
and
ϕ′(τ) = 0.
Since ϕ′(0) < 0, we have τ > 0. Using Markov’s inequality (Theorem 5.11), we
estimate
P[Sn ≥0] = P)eτSn ≥1* ≤E)eτSn* = ϕ(τ)n = ϱn.
Thus we get the upper bound
lim sup
n→∞
1
n log P[Sn ≥0] ≤log ϱ = −Λ∗(0).
The remaining part of the proof is dedicated to verifying the reverse inequality:
lim inf
n→∞
1
n log P[Sn ≥0] ≥log ϱ.
(23.11)
We use the method of an exponential size-biasing of the distribution μ := PX1 of
X1, which turns the atypical values that are of interest here into typical values. That
is, we deﬁne the Cramér transform ˆμ ∈M1(R) of μ by
ˆμ(dx) = ϱ−1eτxμ(dx)
for x ∈R.

592
23
Large Deviations
Let ˆX1, ˆX2, . . . be independent and identically distributed with PˆXi = ˆμ. Then
ˆϕ(t) := E
)
et ˆX1*
= 1
ϱ

R
etxeτx μ(dx) = 1
ϱ ϕ(t + τ).
Hence
E
) ˆX1] = ˆϕ′(0) = 1
ϱ ϕ′(τ) = 0,
Var
) ˆX1] = ˆϕ′′(0) = 1
ϱ ϕ′′(τ) ∈(0, ∞).
Deﬁning ˆSn = ˆX1 + . . . + ˆXn, we get
P[Sn ≥0] =

{x1+...+xn≥0}
μ(dx1) · · · μ(dxn)
=

{x1+...+xn≥0}

ϱ e−τx1
ˆμ(dx1) · · ·

ϱ e−τxn
ˆμ(dxn)
= ϱn E
'
e−τ ˆSn 1{ ˆSn≥0}
(
.
Thus, in order to show (23.11), it is enough to show
lim inf
n→∞
1
n log E
'
e−τ ˆSn 1{ ˆSn≥0}
(
≥0.
(23.12)
However, by the central limit theorem (Theorem 15.38), for every c > 0,
1
n log E
'
e−τ ˆSn 1{ ˆSn≥0}
(
≥1
n log E
'
e−τ ˆSn 1{0≤ˆSn≤c√n }
(
≥1
n log

e−τc√n P
+ ˆSn
√n ∈[0, c]
,
n→∞
−→
lim
n→∞
−τc√n
n
+ lim
n→∞
1
n log

N0,Var[ ˆX1]([0, c])

= 0.
⊓⊔
Example 23.4 If PX1 = N0,1, then
Λ(t) = log

E
)
etX1*
= log

1
√
2π
 ∞
−∞
etxe−x2/2 dx

= t2
2 .

23.1
Cramér’s Theorem
593
Furthermore,
Λ∗(z) = sup
t∈R

tz −Λ(t)

= sup
t∈R

tz −t2
2

= z2
2 .
Hence the rate function coincides with that of (23.4). ♦
Example 23.5 If PX1 = 1
2δ−1 + 1
2δ1, then Λ(t) = log cosh(t). The maximizer t∗=
t∗(z) of the variational problem for Λ∗solves the equation z = Λ′(t∗) = tanh(t∗).
Hence
Λ∗(z) = zt∗−Λ(t∗) = z arctanh(z) −log

cosh(arctanh(z))

.
Now arctanh(z) = 1
2 log 1 + z
1 −z for z ∈(−1, 1) and
cosh

arctanh(z)

=
1
√
1 −z2 =
1
√(1 −z)(1 + z).
Therefore,
Λ∗(z) = z
2 log(1 + z) −z
2 log(1 −z) + 1
2 log(1 −z) + 1
2 log(1 + z)
= 1 + z
2
log(1 + z) + 1 −z
2
log(1 −z).
However, this is the rate function from Theorem 23.1. ♦
Takeaways For random variables with exponential moments, in the weak law
of large numbers, the probability for large deviations decays exponentially
fast. The rate for the decay can be computed via the Legendre transform of
the logarithmic moment generating function.
Exercise 23.1.1 Let X be a real random variable with density f (x) = c−1
e−|x|
1 + |x|3 ,
where c =
 ∞
−∞
e−|x|
1 + |x|3 dx. Check if the logarithmic moment generating function
Λ is continuous and sketch the graph of Λ. ♣
Exercise 23.1.2 Let X be a real random variable and let Λ(t) := log

E
)
etX*
,
t ∈R be its logarithmic moment generating function. Use Hölder’s inequality to
show that Λ is convex and is strictly convex in the interval where it is ﬁnite (if X is
not almost surely constant). ♣

594
23
Large Deviations
23.2
Large Deviations Principle
The basic idea of Cramér’s theorem is to quantify the probabilities of rare events
by an exponential rate and a rate function. In this section, we develop a formal
framework for the quantiﬁcation of probabilities of rare events in which the
complete theory of large deviations can be developed. For further reading, consult,
e.g., [31, 32] or [74].
Let E be a Polish space with complete metric d. Recall that
Bε(x) = {y ∈E : d(x, y) < ε}
denotes the open ball of radius ε > 0 that is centered at x ∈E.
A map f
: E
→R = [−∞, ∞] is called lower semicontinuous if,
for every a ∈R, the level set f −1([−∞, a]) ⊂E is closed. (In particular,
continuous maps are lower semicontinuous. On the other hand, 1(0,1) : R →R
is lower semicontinuous but not continuous.) An equivalent condition for lower
semicontinuity is that limε↓0 inf f (Bε(x)) = f (x) for all x ∈E. (Recall that
inf f (A) = inf{f (x) : x ∈A}.) If K ⊂E is compact and nonempty, then f
assumes its inﬁmum on K. Indeed, for the case where f (x) = ∞for all x ∈K,
the statement is trivial. Now assume inf f (K) < ∞. If an ↓inf f (K) is strictly
monotone decreasing, then K ∩f −1([−∞, an]) ̸= ∅is compact for every n ∈N
and hence the inﬁnite intersection also is nonempty:
f −1(inf f (K)) = K ∩
∞

n=1
f −1([−∞, an]) ̸= ∅.
Reﬂection Check that suprema of lower semicontinuous functions are lower
semicontinuous. In particular, suprema of continuous functions are lower semicon-
tinuous. Which of the functions f (x) = 1{0}(x), g(x) = 1R\Z(x), h(x) = sin(1/x)
for x ̸= 0 and h(0) = −1, are lower semicontinuous? ♠
Deﬁnition 23.6 (Rate function) A lower semicontinuous function I : E →[0, ∞]
is called a rate function. If all level sets I −1([−∞, a]), a ∈[0, ∞), are compact,
then I is called a good rate function.
Deﬁnition 23.7 (Large deviations principle) Let I be a rate function and (με)ε>0
be a family of probability measures on E. We say that (με)ε>0 satisﬁes a large
deviations principle (LDP) with rate function I if
(LDP 1) lim inf
ε→0
ε log(με(U)) ≥−infI(U)
for every open U ⊂E,
(LDP 2) lim sup
ε→0
ε log(με(C)) ≤−inf I(C)
for every closed C ⊂E.
We say that a family (Pn)n∈N of probability measures on E satisﬁes an LDP with
rate rn ↑∞and rate function I if (LDP 1) and (LDP 2) hold with εn = 1/rn and
μ1/rn = Pn.

23.2
Large Deviations Principle
595
Often (LDP 1) and (LDP 2) are referred to as lower bound and upper bound. In
many cases, the lower bound is a lot easier to show than the upper bound.
Before we show that Cramér’s theorem is essentially an LDP, we make two
technical statements.
Theorem 23.8 The rate function in an LDP is unique.
Proof Assume that (με)ε>0 satisﬁes an LDP with rate functions I and J. Then, for
every x ∈E and δ > 0,
I(x) ≥inf I(Bδ(x))
≥−lim inf
ε→0 ε log

με(Bδ(x))

≥−lim sup
ε→0
ε log

με

Bδ(x)

≥inf J

Bδ(x)

δ→0
−→J(x).
Hence I(x) ≥J(x). Similarly, we get J(x) ≥I(x).
⊓⊔
Lemma 23.9 Let N ∈N and let ai
ε, i = 1, . . . , N, ε > 0, be nonnegative numbers.
Then
lim sup
ε→0
ε log
N

i=1
ai
ε =
max
i=1,...,N lim sup
ε→0
ε log(ai
ε).
Proof The sum and maximum differ at most by a factor N:
max
i=1,...,N ε log(ai
ε) ≤ε log
N

i=1
ai
ε ≤ε log(N) +
max
i=1,...,N ε log(ai
ε).
The maximum and limit (superior) can be interchanged and hence
max
i=1,...,N lim sup
ε→0
ε log(ai
ε) = lim sup
ε→0
ε log

max
i=1,...,N ai
ε

≤lim sup
ε→0
ε log
 N

i=1
ai
ε

≤lim sup
ε→0
ε log(N) +
max
i=1,...,N lim sup
ε→0
ε log(ai
ε)
=
max
i=1,...,N lim sup
ε→0
ε log(ai
ε).
⊓⊔
Example 23.10 Let X1, X2, . . . be i.i.d. real random variables that satisfy the
condition of Cramér’s theorem (Theorem 23.3); i.e., Λ(t) = log(E[etX1]) < ∞

596
23
Large Deviations
for every t ∈R. Furthermore, let Sn = X1 +. . .+Xn for every n. We will show that
Cramér’s theorem implies that Pn := PSn/n satisﬁes an LDP with rate n and with
good rate function I(x) = Λ∗(x) := supt∈R(tx −Λ(t)). Without loss of generality,
we can assume that E[X1] = 0. The function I is lower semicontinuous, strictly
convex (in the interval where it is ﬁnite) and has its unique minimum at I(0) = 0.
By convexity, we have I(y) > I(x) whenever y > x ≥0 or y < x ≤0.
Cramér’s theorem says that limn→∞1
n log(Pn([x, ∞))) = −I(x) for x > 0
and (by symmetry) limn→∞1
n log(Pn((−∞, x])) = −I(x) for x < 0. Clearly, for
x > 0,
−I(x) ≥lim inf
n→∞
1
n log Pn((x, ∞))
≥sup
y>x
lim inf
n→∞
1
n log Pn([y, ∞)) = −inf
y>x I(y)
Similarly, lim inf
n→∞
1
n log Pn((−∞, x)) ≥−inf
y<x I(y) for x < 0. Furthermore, by the
law of large numbers, for any x > 0, we have
lim
n→∞
1
n log Pn((−x, ∞)) = lim
n→∞
1
n log Pn([−x, ∞))
= lim
n→∞
1
n log Pn((−∞, x)) = lim
n→∞
1
n log Pn((−∞, x])) = 0 = −I(0).
The main work has been done by showing that the family (Pn)n∈N satisﬁes
conditions (LDP 1) and (LDP 2) at least for unbounded intervals. It remains to show
by some standard arguments (LDP 1) and (LDP 2) for arbitrary open and closed
sets, respectively.
First assume that C ⊂R is closed. Deﬁne x+ := inf

C ∩[0, ∞)

as well as
x−:= sup

C ∩(−∞, 0]

. By monotonicity of I, on (−∞, 0] and [0, ∞), we get
inf I(C) = I(x−) ∧I(x+) (with the convention I(−∞) = I(∞) = ∞). If x−= 0
or x+ = 0, then inf(I(C)) = 0, and (LDP 2) holds trivially. Now let x−< 0 < x+.
Using Lemma 23.9, we get
lim sup
n→∞
1
n log Pn(C)
≤lim sup
n→∞
1
n log Pn
(−∞, x−] + Pn
[x+, ∞)
= max

lim sup
n→∞
1
n log Pn

(−∞, x−]

, lim sup
n→∞
1
n log Pn

[x+, ∞)

= max 	 −I(x−), −I(x+)
 = −infI(C).
This shows (LDP 2).

23.2
Large Deviations Principle
597
Now let U ⊂R be open. Let x ∈U ∩[0, ∞) with I(x) < ∞(if such an x
exists). Then there exists an ε > 0 with (x −ε, x + ε) ⊂U. Now
lim inf
n→∞
1
n log Pn

(x −ε, ∞)

≥−I(x) > −I(x + ε)
= lim
n→∞
1
n log Pn

[x + ε, ∞)

.
Therefore,
lim inf
n→∞
1
n log Pn(U) ≥lim inf
n→∞
1
n log Pn((x −ε, x + ε))
= lim inf
n→∞
1
n log Pn
(x −ε, ∞) −Pn
[x + ε, ∞)
= lim inf
n→∞
1
n log

Pn

(x −ε, ∞)

≥−I(x).
Similarly, this also holds for x ∈U ∩(−∞, 0) with I(x) < ∞; hence
lim inf
n→∞
1
n log Pn(U) ≥−inf I(U).
This shows the lower bound (LDP 1). ♦
In fact, the condition Λ(t) < ∞for all t ∈R can be dropped. Since Λ(0) = 0, we
have Λ∗(x) ≥0 for every x ∈R. The map Λ∗is a convex rate function but is, in
general, not a good rate function. We quote the following strengthening of Cramér’s
Theorem(see [31, Theorem 2.2.3]).
Theorem 23.11 (Cramér) If X1, X2, . . . are i.i.d. real random variables, then
(PSn/n)n∈N satisﬁes an LDP with rate function Λ∗.
Takeaways The distributions of the arithmetic means of a growing number
of i.i.d. random variables concentrate more and more around the expected
value (under certain regularity assumptions, that is). This behaviour has been
quantiﬁed in Sect. 23.1. Here we have developed the abstract framework
(principle of large deviations) for the description of the speed of concentration
for a sequence of probability measures. Finally, we have shown that the results
for i.i.d. random variables that we had already ﬁt in this framework.
Exercise 23.2.1 Let E = R. Show that με := N0,ε satisﬁes an LDP with good
rate function I(x) = x2/2. Further, show that strict inequality can hold in the upper
bound (LDP 2). ♣

598
23
Large Deviations
Exercise 23.2.2 Let E = R. Show that με := N0,ε2 satisﬁes an LDP with good
rate function I(x) = ∞· 1R\{0}(x). Further, show that strict inequality can hold in
the lower bound (LDP 1). ♣
Exercise 23.2.3 Let E = R. Show that με := 1
2N−1,ε + 1
2N1,ε satisﬁes an LDP
with good rate function I(x) = 1
2 min((x + 1)2, (x −1)2). ♣
Exercise 23.2.4 Compute Λ and Λ∗in the case X1 ∼expθ for θ > 0. Interpret
the statement of Theorem 23.11 in this case. Check that Λ∗has its unique zero at
E[X1]. (Result: Λ∗(x) = θx −log(θx) −1 if x > 0 and = ∞otherwise.) ♣
Exercise 23.2.5 Compute Λ and Λ∗for the case where X1 is Cauchy distributed
and interpret the statement of Theorem 23.11. ♣
Exercise 23.2.6 Let Xλ ∼Poiλ for every λ > 0. Show that με := PεXλ/ε satisﬁes
an LDP with good rate function I(x) = x log(x/λ) + λ −x for x ≥0 (and = ∞
otherwise). ♣
Exercise 23.2.7 Let (Xt)t≥0 be a random walk on Z in continuous time that makes
a jump to the right with rate 1
2 and a jump to the left also with rate 1
2. Show that
(PεX1/ε)ε>0 satisﬁes an LDP with convex good rate function
I(x) = 1 + x arcsinh(x) −
2
1 + x2.
♣
23.3
Sanov’s Theorem
This section is close to the exposition in [31].
We present a large deviations principle that, unlike Cramér’s theorem, is not
based on a linear space. Rather, we consider empirical distributions of independent
random variables with values in a ﬁnite set Σ, which often is called an alphabet.
Let μ be a probability measure on Σ with μ({x}) > 0 for any x ∈Σ. Further,
let X1, X2, . . . be i.i.d. random variables with values in Σ and with distribution
PX1 = μ. We will derive a large deviations principle for the empirical measures
ξn(X) := 1
n
n

i=1
δXi.
Note that by the law of large numbers, P-almost surely ξn(X)
n→∞
−→μ. Hence, as
the state space we get E = M1(Σ), equipped with the metric of total variation
d(μ, ν) = ∥μ −ν∥T V . (As Σ is ﬁnite, in E vague convergence, weak convergence
and convergence in total variation coincide.) Further, let
En :=

μ ∈M1(Σ) : nμ({x}) ∈N0 for every x ∈Σ

be the range of the random variables ξn(X).

23.3
Sanov’s Theorem
599
Recall that the entropy of μ is deﬁned by
H(μ) := −

log

μ({x})

μ(dx).
If ν
∈M1(Σ), then we deﬁne the relative entropy (or Kullback–Leibler
information, see [104]) of ν given μ by
H(ν|μ) :=

log
 ν({x})
μ({x})

ν(dx).
(23.13)
Since μ({x}) > 0 for all x ∈Σ, the integrand ν-a.s. is ﬁnite and hence the integral
also is ﬁnite. A simple application of Jensen’s inequality yields H(μ) ≥0 and
H(ν|μ) ≥0 (see Lemma 5.26 and Exercise 5.3.3). Furthermore, H(ν|μ) = 0 if
and only if ν = μ. In addition, clearly,
H(ν|μ) + H(ν) = −

log

μ({x})

ν(dx).
(23.14)
Since the map ν →Iμ(ν) := H(ν|μ) is continuous, Iμ is a rate function.
Lemma 23.12 For every n ∈N and ν ∈En, we have
(n + 1)−#Σe−n H(ν |μ) ≤P[ξn(X) = ν] ≤e−n H(ν |μ).
(23.15)
Proof We consider the set of possible values for the n-tuple (X1, . . . , Xn) such that
ξn(X) = ν:
An(ν) :=

k = (k1, . . . , kn) ∈Σn : 1
n
n

i=1
δki = ν

.
For every k ∈An(ν), we have (compare (23.14))
P[ξn(X) = ν] = #An(ν) P[X1 = k1, . . . , Xn = kn]
= #An(ν)

x∈Σ
μ({x})nν({x})
= #An(ν) exp

n

ν(dx) log μ({x})

= #An(ν) exp  −n[H(ν) + H(ν|μ)].
Now let Y1, Y2, . . . be i.i.d. random variables with values in Σ and with distribution
PY1 = ν. As in the calculation for X, we obtain (since H(ν|ν) = 0)
1 ≥P[ξn(Y) = ν] = #An(ν) e−nH(ν);
hence #An(ν) ≤enH(ν). This implies the second inequality in (23.15).

600
23
Large Deviations
The random variable n ξn(Y) has the multinomial distribution with parameters
(nν({x}))x∈Σ. Hence the map En →[0, 1], ν′ →P[ξn(Y) = ν′] is maximal at
ν′ = ν. Therefore,
#An(ν) = enH(ν) P[ξn(Y) = ν] ≥enH(ν)
#En
≥(n + 1)−#Σ enH(ν).
This implies the ﬁrst inequality in (23.15).
⊓⊔
We come to the main theorem of this section, Sanov’s theorem (see [150] and [151]).
Theorem 23.13 (Sanov [150]) Let X1, X2, . . . be i.i.d. random variables with
values in the ﬁnite set Σ and with distribution μ. Then the family (Pξn(X))n∈N of
distributions of empirical measures satisﬁes an LDP with rate n and rate function
Iμ := H( ·|μ).
Proof By Lemma 23.12, for every A ⊂E,
P)ξn(X) ∈A* =

ν∈A∩En
P[ξn(X) = ν]
≤

ν∈A∩En
e−nH(ν |μ)
≤#(A ∩En) exp

−n inf Iμ(A ∩En)

≤(n + 1)#Σ exp

−n inf Iμ(A)

.
Therefore,
lim sup
n→∞
1
n log P[ξn(X) ∈A] ≤−inf Iμ(A).
Hence the upper bound in the LDP holds (even for arbitrary A).
Similarly, we can use the ﬁrst inequality in Lemma 23.12 to get
P)ξn(X) ∈A* ≥(n + 1)−#Σ exp  −n inf Iμ(A ∩En)
and thus
lim inf
n→∞
1
n log P
)
ξn(X) ∈A
*
≥−lim sup
n→∞
inf Iμ(A ∩En).
(23.16)
Note that, in this inequality, in the inﬁmum we cannot simply replace A ∩En by A.
However, we show that, for open A this can be done at least asymptotically. Hence,
let A ⊂E be open. For ν ∈A, there is an ε > 0 with Bε(ν) ⊂A. For n ≥(2 #Σ)/ε,
we have En ∩Bε(ν) ̸= ∅and hence there exists a sequence νn
n→∞
−→ν with νn ∈

23.3
Sanov’s Theorem
601
En ∩A for large n ∈N. As Iμ is continuous, we have
lim sup
n→∞
inf Iμ(A ∩En) ≤lim
n→∞Iμ(νn) = Iμ(ν).
Since ν ∈A is arbitrary, we get lim supn→∞inf Iμ(A ∩En) = inf Iμ(A).
⊓⊔
Example 23.14 Let Σ
= {−1, 1} and let μ =
1
2δ−1 + 1
2δ1 be the uniform
distribution on Σ. Deﬁne m = m(ν) := ν({1})−ν({−1}). Then the relative entropy
of ν ∈M1(Σ) is
H(ν|μ) = 1 + m
2
log(1 + m) + 1 −m
2
log(1 −m).
Note that this is the rate function from Theorem 23.1. ♦
Next we describe formally the connection between the LDPs of Sanov and Cramér
that was indicated in the previous example. To this end, we use Sanov’s theorem to
derive a version of Cramér’s theorem for Rd-valued random variables taking only
ﬁnitely many different values.
Example 23.15 Let Σ ⊂Rd be ﬁnite and let μ be a probability measure on Σ.
Further, let X1, X2, . . . be i.i.d. random variables with values in Σ and distribution
PX1 = μ. Deﬁne Sn = X1 + . . . + Xn for every n ∈N. Let Λ(t) = log E
)
e⟨t,X1⟩*
for t ∈Rd (which is ﬁnite since Σ is ﬁnite) and Λ∗(x) = supt∈Rd

⟨t, x⟩−Λ(t)

for x ∈Rd.
We show that PSn/n

n∈N satisﬁes an LDP with rate n and rate function Λ∗.
Let ξn(X) be the empirical measure of X1, . . . , Xn. Let E := M1(Σ). Deﬁne
the map
m : E →Rd,
ν →

x ν(dx) =

x∈Σ
x ν({x}).
That is, m maps ν to its ﬁrst moment. Clearly, 1
nSn = m(ξn(X)). For x ∈Rd and
A ⊂Rd, deﬁne
Ex := m−1({x}) = {ν ∈E : m(ν) = x}
and
EA = m−1(A) = {ν ∈E : m(ν) ∈A}.
The map ν →m(ν) is continuous; hence EA is open (respectively closed) if A is
open (respectively closed). Let ˜I(x) := inf Iμ(Ex) (where Iμ(ν) = H(ν|μ) is the

602
23
Large Deviations
relative entropy). Then, by Sanov’s theorem for open U ⊂Rd,
lim inf
n→∞
1
n log PSn/n(U) = lim inf
n→∞
1
n log Pξn(X)
m−1(U)
≥−inf Iμ

m−1(U)

= −inf ˜I(U).
Similarly, for closed C ⊂Rd, we have
lim sup
n→∞
1
n log PSn/n(C) ≤−inf ˜I(C).
In other words, (PSn/n)n∈N satisﬁes an LDP with rate n and rate function ˜I. Hence,
it only remains to show that ˜I = Λ∗.
Note that t →Λ(t) is differentiable (with derivative Λ′) and is strictly convex.
Hence the variational problem for Λ∗(x) admits a unique maximizer t∗(x). More
precisely,
Λ∗(x) = ⟨t∗(x), x⟩−Λ(t∗(x)),
Λ∗(x) > ⟨t, x⟩−Λ(t) for all t ̸= t∗(x), and Λ′(t∗(x)) = x. By Jensen’s inequality,
for every ν ∈M1(Σ),
Λ(t) = log

e⟨t,y⟩μ(dy)
= log
 
e⟨t,y⟩μ({y})
ν({y})

ν(dy)
≥

log

e⟨t,y⟩μ({y})
ν({y})

ν(dy)
= ⟨t, m(ν)⟩−H(ν|μ)
with equality if and only if ν = νt, where νt({y}) = μ({y})e⟨t,y⟩−Λ(t). Hence,
⟨t, x⟩−Λ(t) ≤inf
ν∈Ex H(ν|μ)
with equality if νt ∈Ex. However, we now know that m(νt) = Λ′(t); hence we
have νt∗(x) ∈Ex and thus
Λ∗(x) = ⟨t∗(x), x⟩−Λ(t∗(x)) =
inf
ν∈Ex H(ν|μ) = ˜I(x).
♦

23.4
Varadhan’s Lemma and Free Energy
603
The method of the proof that we applied in the last example to derive the LDP with
rate function ˜I is called a contraction principle. We formulate this principle as a
theorem.
Theorem 23.16 (Contraction principle) Assume the family (με)ε>0 of probability
measures on E satisﬁes an LDP with rate function I. If F is a topological space and
m : E →F is continuous, then the image measures (με ◦m−1)ε>0 satisfy an LDP
with rate function ˜I(x) = inf I(m−1({x})).
Takeaways Consider an i.i.d. sequence of random variables with values in a
ﬁnite set. The empirical distributions converge to the distribution of the ran-
dom variables. The speed of convergence is exponential and the exponential
rate function is the relative entropy. Using the contraction principle this large
deviations principle can be reduced to functions of the random variables. In
particular, we can recover Cramér’s theorem for random variables that take
only ﬁnitely many d-dimensional values.
23.4
Varadhan’s Lemma and Free Energy
Assume that (με)ε>0 is a family of probability measures that satisﬁes an LDP with
rate function I. In particular, we know that, for small ε > 0, the mass of με is
concentrated around the zeros of I. In statistical physics, one is often interested in
integrating with respect to με (where 1/ε is interpreted as “size of the system”)
functions that attain their maximal values away from the zeros of I. In addition,
these functions are exponentially scaled with 1/ε. Hence the aim is to study the
asymptotics of Zφ
ε :=
3
eφ(x)/εμε(dx) as ε →0. Under some mild conditions
on the continuity of φ, the main contribution to the integral comes from those
points x that are not too unlikely (for με) and for which at the same time φ(x)
is large. That is, those x for which φ(x) −I(x) is close to its maximum. These
contributions are quantiﬁed in terms of the tilted probability measures μφ
ε (dx) =
(Zφ
ε )−1eφ(x)/εμε(dx), ε > 0, for which we derive an LDP. As an application, we
get the statistical physics principle of minimising the free energy. As an example,
we analyze the Weiss ferromagnet.
We start with a lemma that is due to Varadhan [167].
Theorem 23.17 (Varadhan’s Lemma [167]) Let I be a good rate function and let
(με)ε>0 be a family of probability measures on E that satisﬁes an LDP with rate
function I. Further, let φ : E →R be continuous and assume that
inf
M>0 lim sup
ε→0
ε log

eφ(x)/ε 1{φ(x)≥M} με(dx) = −∞.
(23.17)

604
23
Large Deviations
Then
lim
ε→0 ε log

eφ(x)/ε με(dx) = sup
x∈E

φ(x) −I(x)

.
(23.18)
Remark 23.18 (Moment condition) The tail condition (23.17) holds if there exists
an α > 1 such that
lim sup
ε→0
ε log

eαφ/ε dμε < ∞.
(23.19)
Indeed, for every M ∈R, we have
ε log

eφ(x)/ε 1{φ(x)≥M} με(dx) = M + ε log

e(φ(x)−M)/ε 1{φ(x)≥M} με(dx)
≤M + ε log

eα(φ(x)−M)/ε με(dx)
= −(α −1)M + ε log

eαφ(x)/ε με(dx).
Together with (23.19), this implies (23.17). ♦
Proof We use different arguments to show that the right-hand side of (23.18) is a
lower and an upper bound for the left-hand side.
Lower bound For any x ∈E and r > 0, we have
lim inf
ε→0
ε log

eφ/ε dμε ≥lim inf
ε→0
ε log

Br(x)
eφ/ε dμε
≥inf φ(Br(x)) −I(x)
r→0
−→φ(x) −I(x).
Upper bound For M > 0 and ε > 0, deﬁne
F ε
M :=

{φ≥M}
eφ(x)/ε με(dx)
and
Gε
M :=

{φ<M}
eφ(x)/ε με(dx).
Deﬁne
FM := lim sup
ε→0
ε log F ε
M
and
GM := lim sup
ε→0
ε log Gε
M.
By Lemma 23.9, for any M > 0,
lim sup
ε→0
ε log

eφ(x)/ε με(dx) = FM ∨GM.

23.4
Varadhan’s Lemma and Free Energy
605
As by assumption infM>0 FM = −∞, it is enough to show that
sup
M>0
GM ≤sup
x∈E

φ(x) −I(x)

.
(23.20)
Let δ > 0. For any x ∈E there is an r(x) > 0 with
inf I

B2r(x)(x)

≥I(x) −δ
and
sup φ

B2r(x)(x)

≤φ(x) + δ.
Let a ≥0. Since I is a good rate function, the level set K := I −1([0, a])
is compact. Thus we can ﬁnd ﬁnitely many x1, . . . , xN ∈I −1([0, a]) such that
N
i=1 Br(xi)(xi) ⊃K. Therefore,
Gε
M ≤

{φ<M}∩Kc eφ(x)/ε με(dx) +
N

i=1

{φ<M}∩Br(xi )(xi)
eφ(x)/ε με(dx)
≤eM/εμε(Kc) +
N

i=1
e(φ(xi)∧M+δ)/εμε

Br(xi)(xi)

= e(M+ε log(με(Kc)))/ε +
N

i=1
e(φ(xi)∧M+δ+ε log(με(Br(xi)(xi))))/ε.
Using Lemma 23.9 and the LDP, we infer
GM ≤(M −a) ∨
max
i=1,...,N

φ(xi) −I(xi) + 2δ

≤(M −a) ∨sup
x∈E

φ(x) −I(x)

+ 2δ.
By letting ﬁrst δ ↓0 and then a ↑∞, we obtain (23.20).
⊓⊔
Theorem 23.19 (Tilted LDP) Assume that (με)ε>0 satisﬁes an LDP with good
rate function I. Further, let φ : E →R be a continuous function that satisﬁes
condition (23.17). Deﬁne Zφ
ε :=
3
eφ/ε dμε and μφ
ε ∈M1(E) by
μφ
ε (dx) = (Zφ
ε )−1 eφ(x)/ε με(dx).
Further, deﬁne I φ : E →[0, ∞] by
I φ(x) = sup
z∈E
φ(z) −I(z) −φ(x) −I(x).
(23.21)
Then (μφ
ε )ε>0 satisﬁes an LDP with rate function I φ.

606
23
Large Deviations
Proof This is left as an exercise. (Compare [32, Exercise 2.1.24], see also [43,
Section II.7].)
⊓⊔
Varadhan’s lemma has various applications in statistical physics. Consider a Polish
space Σ that is interpreted as the space of possible states of a particle. Further,
let λ ∈M1(Σ) be a distribution that is understood as the a priori distribution
of this particle if the inﬂuence of energy could be neglected. If Σ is ﬁnite or is a
bounded subset of an Rd, then by symmetry, typically λ is the uniform distribution
on Σ. If we place n indistinguishable particles independently according to λ on the
random positions z1, . . . , zn ∈Σ, then the state of this ensemble can be described
by x :=
1
n
n
i=1 δzi. Denote by μ0
n ∈M1(M1(Σ)) the corresponding a priori
distribution of x; that is, of the n-particle system.
Now we introduce the hypothesis that the energy Un(x) of a state has the form
Un(x) = nU(x), where U(x) is the average energy of one particle of the ensemble
in state x.
Let T > 0 be the temperature of the system and let β := 1/T be the so-called
inverse temperature. In statistical physics, a key quantity is the so-called partition
function
Zβ
n :=

e−βUn dμ0
n.
A postulate of statistical physics is that the distribution of the state x is the
Boltzmann distribution:
μβ
n(dx) = (Zβ
n )−1 e−βUn(x) μ0
n(dx).
(23.22)
Varadhan’s lemma (more precisely, the tilted LDP) and Sanov’s theorem are the
keys to building a connection to the variational principle for the free energy. For
simplicity, assume that Σ is a ﬁnite set and λ = UΣ is the uniform distribution
on Σ. By Sanov’s theorem, (μ0
n)n∈N satisﬁes an LDP with rate n and rate function
I(x) = H(x|λ), where H(x|λ) is the relative entropy of x with respect to λ. By
(23.14), we have H(x|λ) = log(#Σ) −H(x), where H(x) is the entropy of x.
Deﬁne the free energy (or Helmholtz potential) per particle as
F β(x) := U(x) −β−1H(x).
The theorem on the tilted LDP yields that the sequence of Boltzmann distributions
(μβ
n)n∈N satisﬁes an LDP with rate n and rate function
I β(x) = β ·

F β(x) −
inf
y∈M1(Σ) F β(y)

.
Thus, for large n, the Boltzmann distribution is concentrated on those x that
minimize the free energy. For different temperatures (that is, for different values

23.4
Varadhan’s Lemma and Free Energy
607
of β) these can be very different states. This is the reason for phase transitions at
critical temperatures (e.g., melting ice).
Example 23.20 We consider the Weiss ferromagnet. This is a microscopic model
for a magnet that assumes that each of n indistinguishable magnetic particles has
one of two possible orientations σi ∈Σ = {−1, +1}. The mean magnetization
m = 1
n
n
i=1 σi describes the state of the system completely (as the particles are
indistinguishable). Macroscopically, this is the quantity that can be measured. The
basic idea is that it is energetically favorable for particles to be oriented in the same
direction. We ignore the spatial structure and assume that any particle interacts with
any other particle in the same way. This is often called the mean ﬁeld assumption.
In addition, we assume that there is an exterior magnetic ﬁeld of strength h. Thus
up to constants the average energy of a particle is
U(m) = −1
2m2 −hm.
The entropy of the state m is
H(m) = −1 + m
2
log
1 + m
2

−1 −m
2
log
1 −m
2

.
Hence the average free energy of a particle is
F β(m) = −1
2m2 −hm + β−1'1 + m
2
log
1 + m
2

+ 1 −m
2
log
1 −m
2
(
.
In order to obtain the minima of F β, we compute the derivative
0 !=
d
dmF β(m) = −m −h + β−1 arctanh(m).
Hence, m solves the equation
m = tanh(β(m + h)).
(23.23)
In the case h = 0, m = 0 is a solution of (23.23) for any β. If β ≤1, then this is the
only solution and F β attains its global minimum at m = 0. If β > 1, then (23.23)
has two other solutions, mβ,0
−
∈(−1, 0) and mβ,0
+
= −mβ,0
−, whose values can only
be computed numerically (Fig. 23.2).
In this case, F β has a local maximum at 0 and has global minima mβ,0
± . For
large n, only those values of m for which F β is close to its minimal value can be
attained and thus the distribution is concentrated around 0 if β ≤1 and around
mβ,0
±
if β > 1. In the latter case, the absolute value of the mean magnetization
is
mβ,0
±
 = mβ,0
+
> 0. Hence, there is a phase transition between the high
temperature phase (β ≤1) without magnetization and the low temperature phase

608
23
Large Deviations
Fig. 23.2 The shifted free energy F β(m) −F β(0) of the Weiss ferromagnet without exterior ﬁeld
(h = 0).
Fig. 23.3 Shifted free energy F β(m) −F β(0) of the Weiss ferromagnet with exterior ﬁeld h =
0.04.
(β > 1) where so-called spontaneous magnetization occurs (that is, magnetization
without an exterior ﬁeld).
If h ̸= 0, then F β does not have a minimum at m = 0. Rather, F β is asymmetric and
has a global minimum mβ,h with the same sign as h. Furthermore, for large β, there
is another minimum with the opposite sign (Fig. 23.3). Again, the exact values can

23.4
Varadhan’s Lemma and Free Energy
609
Fig. 23.4 Weiss ferromagnet: magnetization mβ,h as a function of β.
only be computed numerically (Fig. 23.4). However, for high temperatures (small
β), we can approximate mβ,h using the approximation tanh(β(m+h)) ≈β(m+h).
Hence we get
mβ,h ≈
h
β−1 −1 =
h
T −Tc
for T →∞,
(23.24)
where the Curie temperature Tc = 1 is the critical temperature for spontaneous
magnetization. The relation (23.24) is called the Curie–Weiss law. ♦
Takeaways In the context of statistical mechanics, substantial contributions
to an observable are not only due to the most frequent observations but
also due to rare but very large observations. In order to compute the mean
values and to identify the states that yield signiﬁcant contributions, we have
established a so-called tilted large deviations principle. The rate function that
shows up here is the analogue to the free energy of thermodynamics.Applying
this formalism we have been able to describe the phase transition of the Weiss
ferromagnet.

Chapter 24
The Poisson Point Process
Poisson point processes can be used as a cornerstone in the construction of very
different stochastic objects such as, for example, inﬁnitely divisible distributions,
Markov processes with complex dynamics, objects of stochastic geometry and so
forth.
In this chapter, we brieﬂy develop the general framework of random measures
and construct the Poisson point process and characterize it in terms of its Laplace
transform. As an application we construct a certain subordinator and show that the
Poisson point process is the invariant measure of systems of independent random
walks. Via the connection with subordinators, in the third section, we construct two
distributions that play prominent roles in population genetics: the Poisson–Dirichlet
distribution and the GEM distribution.
For a nice exposition including many examples, see also [99].
24.1
Random Measures
In the following, let E be a locally compact Polish space (for example, E = Rd or
E = Zd) with Borel σ-algebra B(E). Let
Bb(E) = 	B ∈B(E) : B is relatively compact
be the system of bounded Borel sets and M(E) the space of Radon measures on E
(see Deﬁnition 13.3).
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_24
611

612
24
The Poisson Point Process
Deﬁnition 24.1 Denote by M = σ(IA : A ∈Bb(E)) the smallest σ-algebra on
M(E) with respect to which all maps
IA : μ →μ(A),
A ∈Bb(E),
are measurable.
Denote by B+(E) the set of measurable maps E →[0, ∞] and by BR
b (E) the set of
bounded measurable maps E →R with compact support. For every f ∈B+(E),
the integral If (μ) :=
3
f dμ is well-deﬁned and for every f ∈BR
b (E), If (μ) is
well-deﬁned and ﬁnite.
Theorem 24.2 Let τv be the vague topology on M(E). Then
M = B(τv) = σ

If : f ∈Cc(E)

= σ

If : f ∈C+
c (E)

.
Proof This is left as an exercise. (See [82, Lemma 4.1].)
⊓⊔
Let Q
M(E) be the space of all measures on E endowed with the σ-algebra

M = σ

IA : A ∈Bb(E)

.
Choose a countable basis U of the topology consisting of relatively compact sets.
Then we get (compare Exercise 13.1.8)
M(E) =

U∈U
	μ ∈Q
M(E) : μ(U) < ∞
.
Hence M(E) ∈
M. Clearly, M = 
MM(E) is the trace σ-algebra of 
M on M(E).
Here we need the slightly larger space in order to deﬁne random measures in such a
way that all almost surely well-deﬁned operations on random measures again yield
random measures.
Deﬁnition 24.3 A random measure on E is a random variable X on some
probability space (Ω, A, P) with values in ( Q
M(E), 
M) and with P[X ∈M(E)] =
1.
Theorem 24.4 Let X be a random measure on E. Then the set function E[X] :
B(E) →[0, ∞], A →E[X(A)] is a measure. We call E[X] the intensity measure
of X. We say that X is integrable if E[X] ∈M(E).
Proof Clearly, E[X] is ﬁnitely additive. Let A, A1, A2, . . . ∈B(E) with An ↑A.
Consider the random variables Yn := X(An) and Y = X(A). Then Yn ↑Y and
hence, by monotone convergence, E[X](An) = E[Yn]
n→∞
−→E[Y] = E[X](A).
Hence E[X] is lower semicontinuous and is thus a measure (by Theorem 1.36).
⊓⊔

24.1
Random Measures
613
Theorem 24.5 Let PX be the distribution of a random measure X. Then PX is
uniquely determined by the distributions of either of the families

(If1, . . . , Ifn) : n ∈N; f1, . . . , fn ∈C+
c (E)

(24.1)
or

(IA1, . . . , IAn) : n ∈N; A1, . . . , An ∈Bb(E) pairwise disjoint

.
(24.2)
Proof The class of sets
I =
	
(If1, . . . , Ifn)−1(A) : n ∈N; f1, . . . , fn ∈C+
c (E), A ∈B([0, ∞)n)

is a π-system and by Theorem 24.2 it generates M. Hence the measure PX is
characterized by its values on I.
Similarly, the claim follows for
(IA1, . . . , IAn) : n ∈N; A1, . . . , An ∈Bb(E).
If A1, . . . , An ∈Bb(E) are arbitrary, then there exist 2n −1 pairwise disjoint sets
B1, . . . , B2n−1 with Ai = 
k: Bk⊂Ai Bk for all i = 1, . . . , n. The distribution of
(IA1, . . . , IAn) can be computed from that of (IB1, . . . , IB2n−1).
⊓⊔
In the following, let i =
√
−1 be the imaginary unit.
Deﬁnition 24.6 Let X be a random measure on E. Denote by
LX(f ) = E
'
exp

−

f dX
(
,
f ∈B+(E),
the Laplace transform of X and by
ϕX(f ) = E
'
exp

i

f dX
(
,
f ∈BR
b (E),
the characteristic function of X.
Theorem 24.7 The distribution PX of a random measure X is characterized by its
Laplace transform LX(f ), f ∈C+
c (E), as well as by its characteristic function
ϕX(f ), f ∈Cc(E).
Proof This is a consequence of Theorem 24.5 and the uniqueness theorem for char-
acteristic functions (Theorem 15.9) and for Laplace transforms (Exercise 15.1.2) of
random variables on [0, ∞)n.
⊓⊔
Deﬁnition 24.8 We say that a random measure X on E has independent
increments if, for any choice of ﬁnitely many pairwise disjoint measurable sets
A1, . . . , An, the random variables X(A1), . . . , X(An) are independent.

614
24
The Poisson Point Process
Corollary 24.9 The distribution of a random measure X on E with independent
increments is uniquely determined by the family (PX(A), A ∈Bb(E)).
Proof This is an immediate consequence of Theorem 24.5.
⊓⊔
Deﬁnition 24.10 Let μ ∈M(E). A random measure X with independent incre-
ments is called a Poisson point process (PPP) with intensity measure μ if, for any
A ∈Bb(E), we have PX(A) = Poiμ(A). In this case, we write PPPμ := PX ∈
M1(M(E)) and say that X is a PPPμ.
See Fig. 24.1 for a simulation of a Poisson point process on the unit square.
Remark 24.11 The deﬁnition of the PPP (and its construction in the following
theorem) still works if (E, E, μ) is only assumed to be a σ-ﬁnite measure space.
However, the characterization in terms of Laplace transforms is a bit simpler in the
case of locally compact Polish spaces considered here. ♦
Theorem 24.12 For every μ ∈M(E), there exists a Poisson point process X with
intensity measure μ.
Proof μ is σ-ﬁnite since μ ∈M(E). Hence there exist En ↑E with μ(En) < ∞
for every n ∈N. Deﬁne μ1 = μ(E1 ∩·) and μn = μ((En \ En−1) ∩·) for n ≥
2. If X1, X2, . . . are independent Poisson point processes with intensity measures
μ1, μ2, . . ., then X = ∞
n=1 Xn has intensity measure E[X] = μ and hence X is
a random measure (see Exercise 24.1.1). Furthermore, it is easy to see that X has
Fig. 24.1 Poisson point process on the unit square with intensity measure 50λ.

24.1
Random Measures
615
independent increments and that
PX(A) = PX1(A) ∗PX2(A) ∗. . . = Poiμ1(A) ∗Poiμ2(A) ∗. . . = Poiμ(A).
Hence we have X ∼PPPμ.
Therefore, it is enough to consider the case μ(E) ∈(0, ∞). Deﬁne
ν = μ( ·)
μ(E) ∈M1(E).
Let N, Y1, Y2, . . . be independent random variables with N ∼Poiμ(E) and PYi = ν
for all i ∈N. Deﬁne
X(A) =
N

n=1
1A(Yn)
for A ∈B(E).
The random variables 1A(Y1), 1A(Y2), . . . are independent and Berν(A)-distributed;
hence we have X(A) ∼Poiμ(A) (see Theorem 15.15(iii)). Let n ∈N and let
A1, . . . , An ∈B(E) be pairwise disjoint. Then
ψ(t) := E
'
exp

i
n

l=1
tl 1Al(Y1)
(
= 1 +
n

l=1
ν(Al)ei tl −1,
t ∈Rn,
is the characteristic function of (1A1(Y1), . . . , 1An(Y1)). Further, let ϕ be the
characteristic function of (X(A1), . . . , X(An)) and let ϕl be the characteristic
function of X(Al) for l = 1, . . . , n. Hence ϕl(tl) = exp(μ(Al)(eitl −1)). By
Theorem 15.15(iii), we have
ϕ(t) = E
'
exp

i
n

l=1
tl X(Al)
(
= exp μ(E)(ψ(t) −1)
= exp

n

l=1
μ(Al)

ei tl −1

=
n

l=1
ϕl(tl).
Thus X(A1), . . . , X(An) are independent. This implies X ∼PPPμ.
⊓⊔
Takeaways A random measure is a random variable taking values in the
space of Radon measures on a set E. For measurable A ⊂E, the intensity
measure yields the expected value of this random variable. The distribution of
a random measure is characterised by its characteristic function as well as by
its Laplace transform. The Poisson point process is a speciﬁc random measure
taking only integer values and whose values on disjoint sets are independent
and Poisson distributed. An example are the ﬁrst rain drops you see on the
side walk.

616
24
The Poisson Point Process
Exercise 24.1.1 Let X1, X2, . . . be random measures and λ1, λ2, . . . ∈[0, ∞).
Deﬁne X := ∞
n=1 λnXn. Show that X is a random measure if and only if we
have P[X(B) < ∞] = 1 for all B ∈Bb(E). Infer that if X is a random variable
with values in
 Q
M(E), 
M(E)

and E[X] ∈M(E), then X is a random measure. ♣
Exercise 24.1.2 Let τw be the topology of weak convergence on M1(E) and let
σ(τw) be the Borel σ-algebra on M1(E). Show that MM1(E) = σ(τw). ♣
24.2
Properties of the Poisson Point Process
Rényi’s Theorem
A measure μ is called atom-free, if μ({x}) = 0 for all x ∈E. An integer valued
measure ν is said to have no double points, if ν({x}) ∈{0, 1} for all x ∈E. For a
random integer valued measure the property to have no double points is in fact an
event (i.e., it is measurable). This will be shown in the subsequent considerations.
In order to illustrate the main idea, ﬁrst assume that ν is a ﬁnite integer valued
measure on (0, 1]. Then ν has no double points if and only if
lim
n→∞
sup
k=0,...,2n−1
ν
 k
2n , k + 1
2n
(
≤1.
(24.3)
Note that the condition ν({x}) ∈{0, 1} has to be fulﬁlled for uncountably many
x ∈(0, 1] while condition (24.3) is a limit of conditions each involving only ﬁnitely
many subsets of (0, 1]. In particular, for a ﬁnite integer valued random measure X
on (0, 1], the property to have no double points

X({x}) ≤1∀x ∈(0, 1]

=

lim
n→∞
sup
k=0,...,2n−1
X
 k
2n , k + 1
2n
(
≤1

(24.4)
is an event. In order to show the same statement for E a locally compact Polish space
(instead of (0, 1]) we have to spend a little work. Hence, let X be a random integer
valued measure on E. Since E is σ-compact, there exists a sequence (En)n∈N of
compacts with En ↑E. It is clearly enough to show that X has almost surely no
double points on any En. Hence, without loss of generality we may and will assume
that E is compact. Since X is locally ﬁnite almost surely, as a consequence X is
ﬁnite almost surely. As E is compact, it is totally bounded. That is, for any n ∈N,
we can cover E by ﬁnitely many open sets Bn
1 , . . . , Bn
Nn with diameter less than 2−n
(see Lemma 13.2). By building intersections for any choice of k1 ∈{1, . . . , N1}, ...,
kn ∈{1, . . . , Nn}, we get the open sets
˜Bk1,...,kn :=
n

m=1
Bm
km.

24.2
Properties of the Poisson Point Process
617
By a suitable rearranging of the enumeration, we call these sets also Bn
k , k =
1, . . . , Nn. By construction, for any Bn+1
k
, there is an l such that Bn+1
k
⊂Bn
l . We
construct a measurable partition of E by letting Dn
1 := Bn
1 and deﬁning successively
Dn
k := Bn
k \
k−1

l=1
Bn
l .
In fact, the sets Dn
1, . . . , Dn
Nn ∈B(E) are pairwise disjoint, have diameters at most
2−n, and cover E. Note that the partition Dn+1 := {Dn+1
k
: k = 1, . . . , Nn+1}
is a reﬁnement of Dn for any n. That is, for any D = Dn+1
k
∈Dn+1, there is a
D′ = Dn
l ∈Dn such that D ⊂D′. By construction, for any sequence (Dn) with
Dn ∈Dn, n ∈N, we either have ∞
n=1 Dn = ∅or ∞
n=1 Dn = {x} for some x ∈E.
If μ ∈Mf (E) then by upper continuity, we have
lim
n→∞
sup
k=1,...,Nn
μ(Dn
k ) = sup
x∈E
μ({x}).
(24.5)
Hence, the integer valued random measure X has almost surely no double points if
and only if
lim
n→∞
sup
k=1,...,Nn
X(Dn
k ) ≤1
a.s.
(24.6)
For the case E = R, the following theorem goes back to Rényi [142, Theorem 2].
Theorem 24.13 (Rényi’s theorem [142]) Let μ ∈M(E) be atom-free and let X
be an integer valued random measure on E. Then the following two statements are
equivalent.
(i) X ∼PPPμ.
(ii) X almost surely has no double points and
P[X(A) = 0] = e−μ(A)
for all A ∈Bb(E).
(24.7)
Proof (i) ⇒(ii)
This is obvious.
(ii) ⇒
(i)
As E is locally compact and Polish, there is a sequence (En) of
compacts such that En ↑E and μ(En) < ∞for all n ∈N. Hence without loss
of generality we may and will assume that E is compact and μ is a ﬁnite measure
on E. Furthermore, as X is almost surely a Radon measure, it is almost surely ﬁnite
on the compact E.

618
24
The Poisson Point Process
If A1, . . . , An ∈Bb(E) are pairwise disjoint, then
P)X(A1) = 0, . . . , X(An) = 0* = P)XA1 ∪. . . ∪An
 = 0*
= e−μ(A1∪...∪An)
=
n

l=1
e−μ(Al) =
n

l=1
P[X(Al) = 0].
If we deﬁne 
X(A) := X(A) ∧1 for A ∈B(E), then the random variables 
X(Al),
l = 1, . . . , n, are independent.
Now let (Dn)n∈N be a sequence of measurable partitions of E consisting of
sets of diameter at most 2−n and such that Dn+1 is a reﬁnement of Dn for any
n ∈N. Such a sequence was constructed in the course of the discussion preceding
Theorem 24.13.
Let
εn := sup
D∈Dn μ(D).
As μ is atom-free, by (24.5), we have
εn
n→∞
−→0.
(24.8)
As X almost surely has no double points and is ﬁnite, for any A ∈B(E) by (24.5),
we have
lim
n→∞

D∈Dn

X(D ∩A) = lim
n→∞

D∈Dn
X(D ∩A) = X(A)
a.s.
(24.9)
In particular, we infer that also the random variables X(Al), l = 1, . . . , n are
independent. In other words, X is a random measure with independent increments.
Now let A ∈B(E) and note that 
D∈Dn 
X(D ∩A) is a sum of independent
Bernoulli random variables with success probabilities pn
D(A) := 1 −e−μ(D∩A) ≤
εn
n→∞
−→0. We have

D∈Dn
pn
D(A)
n→∞
−→μ(A)
and

D∈Dn
(pn
D(A))2 ≤εn

D∈Dn
pn
D(A)
n→∞
−→0.

24.2
Properties of the Poisson Point Process
619
By the theorem on Poisson approximation (Theorem 3.7), we get X(A) ∼Poiμ(A).
Together with the property of independent increments this shows that X is a Poisson
point process with intensity measure μ.
⊓⊔
Reﬂection What is the connection between Rényi’s theorem and the waiting times
in the construction of the Poisson process on [0, ∞) in Theorem 5.36? ♠
Laplace Transform, Characteristic Function and Moments
Theorem 24.14 Let μ ∈M(E) and let X be a Poisson point process with intensity
measure μ. Then X has Laplace transform
LX(f ) = exp

μ(dx)

e−f (x) −1

,
f ∈B+(E),
and characteristic function
ϕX(f ) = exp

μ(dx)

eif (x) −1

,
f ∈BR
b (E).
Proof It is enough to show the claim for simple functions f = n
l=1 αl 1Al with
complex numbers α1, . . . , αn and with pairwise disjoint sets A1, . . . , An ∈Bb(E).
(For general f , the claim follows by the usual approximation arguments.) For such
f , however,
E
)
exp

−If (X)
*
= E
+ n

l=1
e−αlX(Al)
,
=
n

l=1
E
'
e−αlX(Al)(
=
n

l=1
exp

μ(Al)

e−αl −1

= exp

n

l=1
μ(Al)

e−αl −1

= exp
 
μ(dx)e−f (x) −1
.
⊓⊔
Corollary 24.15 (Moments of the PPP) Let μ ∈M(E) and X ∼PPPμ.
(i) If f ∈L1(μ), then E[
3
f dX] =
3
f dμ.
(ii) If f ∈L2(μ) ∩L1(μ), then Var[
3
f dX] =
3
f 2 dμ.
Recall that only for ﬁnite μ, we have the inclusion L2(μ) ⊂L1(μ).

620
24
The Poisson Point Process
Proof If f = f + −f −∈L1(μ), then for the characteristic function, integral
and differentiation interchange, d
dt ϕX(tf +) = iϕX(tf +)
3
f (x) eitf +(x) μ(dx) and
hence (by Exercise 15.4.4(iii))
E
)
If +(X)
*
= 1
i
d
dt ϕX(tf +)
t=0 =

f + dμ.
Arguing similarly with f −and adding up, we get (i).
If f ∈L1(μ) ∩L2(μ), then the argument can be iterated (using Theorem 15.35)
d2
dt2 ϕX(tf ) = −ϕX(tf )
+ 
f 2(x) eitf(x) μ(dx) +
 
f (x) eitf(x) μ(dx)
2 ,
,
hence we have E
)
If (X)2*
= −d2
dt2 ϕX(tf )
t=0 = If 2(μ) + If (μ)2.
⊓⊔
Theorem 24.16 (Mapping theorem) Let E and F be locally compact Polish
spaces and let φ : E →F be a measurable map. Let μ ∈M(E) with
μ ◦φ−1 ∈M(F) and let X be a PPP on E with intensity measure μ. Then X ◦φ−1
is a PPP on F with intensity measure μ ◦φ−1.
Proof For f ∈B+(F),
LX◦φ−1(f ) = LX(f ◦φ) = exp
  
e−f (φ(x)) −1

μ(dx)

= exp
  
e−f (y) −1
 
μ ◦φ−1
(dy)

.
Now, Theorems 24.14 and 24.7 yield the claim.
⊓⊔
Inﬁnitely Divisible Random Variables
Theorem 24.17 Let ν ∈M((0, ∞)) and let X ∼PPPν on (0, ∞). Further, deﬁne
Y :=
3
x X(dx). Then the following are equivalent.
(i) P[Y < ∞] > 0.
(ii) P[Y < ∞] = 1.
(iii) 3 ν(dx)1 ∧x < ∞.
If (i)–(iii) hold, then Y is an inﬁnitely divisible nonnegative random variable with
Lévy measure ν.

24.2
Properties of the Poisson Point Process
621
Proof Let Y∞=
3
[1,∞) x X(dx) and Yt :=
3
(t,1) x X(dx) for t ∈[0, 1). Evidently,
Y = Y0 + Y∞. Furthermore, it is clear that
P[Y∞< ∞] > 0 ⇐⇒P[Y∞< ∞] = 1 ⇐⇒ν([1, ∞)) < ∞.
(24.10)
If (iii) holds, then E[Y0] =
3
(0,1) x ν(dx) < ∞; hence Y0 < ∞a.s. (and thus
Y < ∞a.s. by (24.10)). On the other hand, if (iii) does not hold, then Y∞= ∞a.s.
or E[Y0] = ∞. While Y∞can have inﬁnite expectation even if Y∞< ∞a.s., for
Y0 this is impossible since, in contrast with Y∞, Y0 is composed not of a few large
contributions but many small ones so that a law of large numbers is in force. More
precisely, by Corollary 24.15, we have
Var[Yt] =

(t,1)
x2 ν(dx) ≤

(t,1)
x ν(dx) = E[Yt] < ∞
for all t ∈(0, 1).
Hence, by Chebyshev’s inequality,
P
+
Yt < E[Yt]
2
,
≤4 Var[Yt]
E[Yt]2
t→0
−→0.
Thus Y0 = supt∈(0,1) Yt ≥E[Y0]/2 = ∞almost surely.
Now assume that (i)–(iii) hold. By Theorem 24.14, Y has the Laplace transform
E
)
e−tY *
= exp

ν(dx)

e−tx −1

.
By the Lévy–Khinchin formula (Theorem 16.14), Y is inﬁnitely divisible with Lévy
measure ν.
⊓⊔
Corollary 24.18 Let μi ∈M1([0, ∞)), i = 1, 2, be inﬁnitely divisible distribu-
tions with canonical measures νi ∈M((0, ∞)) and deterministic parts αi ≥0
(compare Theorem 16.14). If we have
α1 ≤α2
and
ν1([x, ∞)) ≤ν2([x, ∞))
for all x > 0,
(24.11)
then μ1 is stochastically smaller than μ2; i.e., μ1 ≤st μ2.
Proof (The proof follows [100, Proof of Lemma 6.1]) The idea is to use a coupling
argument where based on one Poisson point process we construct the two random
variables Y1, Y2 with Yi ∼μi, i = 1, 2, such that Y1 ≤Y2 almost surely. By
Theorem 17.59, this yields the claim.
Let Gi(x) := νi([x, ∞)), i = 1, 2, x > 0, and
φi(y) := G−1
i (y) = inf
	
x ≥0 : Gi(x) ≤y

for y > 0.

622
24
The Poisson Point Process
If νi is ﬁnite, then φi(y) = 0 for y ≥νi((0, ∞)). Let λ denote the Lebesgue measure
on [0, ∞). By construction, for the image measure restricted to the positive reals,
we have

λ ◦φ−1
i

(0,∞) = νi,
i = 1, 2.
Now assume that X is a PPP on (0, ∞) with intensity measure λ. By Theorem 24.16,
the random measures
Xi :=

δφi(x) X(dx)
 
(0,∞) =

X ◦φ−1
i

(0,∞)
are PPPs with intensity measures νi, i = 1, 2. By Theorem 24.17, we thus have
Yi := αi +

φi(x) X(dx) ∼μi
for i = 1, 2.
However, by assumption, we have G1 ≤G2 which implies φ1 ≤φ2 and thus
Y1 ≤Y2 a.s.
⊓⊔
Example 24.19 By Corollary 16.10, for every nonnegative inﬁnitely divisible
distribution μ with Lévy measure ν, there exists a stochastic process (Yt)t≥0 with
independent stationary increments and Yt ∼μ∗t (hence with Lévy measure tν).
Here we give a direct construction of this process. Let X be a PPP on (0, ∞)×[0, ∞)
with intensity measure ν ⊗λ (here λ is the Lebesgue measure). Deﬁne Y0 = 0 and
Yt :=

(0,∞)×(0,t]
x Xd(x, s).
By the mapping theorem, we have X( · × (s, t]) ∼PPP(t−s)ν; hence Yt −Ys is
inﬁnitely divisible with Lévy measure (t −s)ν. The independence of the increments
is evident. Note that t →Yt is right continuous and monotone increasing.
The process Y that we have just constructed is called a subordinator with Lévy
measure ν. ♦
The procedure in the previous example can be generalized by allowing time sets
more general than [0, ∞).
Deﬁnition 24.20 A random measure Y is called inﬁnitely divisible if, for any n ∈N,
there exist i.i.d. random measures Y1, . . . , Yn with Y = Y1 + . . . + Yn.
Theorem 24.21 Let ν ∈M((0, ∞) × E) with

1A(t) (1 ∧x) ν(d(x, t)) < ∞
for all A ∈Bb(E),

24.2
Properties of the Poisson Point Process
623
and let α ∈M(E). Let X be a PPPν and
Y(A) := α(A) +

x 1A(t) X(d(x, t))
for A ∈B(E).
Then Y is an inﬁnitely divisible random measure with independent increments. For
A ∈B(E), Y(A) has the Lévy measure ν( · × A).
We call ν the canonical measure and α the deterministic part of Y.
Proof This is a direct consequence of Theorems 24.16 and 24.17.
⊓⊔
Remark 24.22 We can write Y as Y = α +
3
xδt X(d(x, t)), where δt is the Dirac
measure at t ∈E. If instead of x δt, we allow more general measures χ ∈M(E),
then we get a representation
Y = α +

M(E)
χ X(dχ),
where X ∼PPPν on M(E) and ν ∈M(M(E)) with

ν(dχ)(χ(A) ∧1) < ∞
for any A ∈Bb(E). It can be shown that this is the most general form of an
inﬁnitely divisible measure on E. We call ν the canonical measure of Y and α
the deterministic part. Y is characterized by its Laplace transform which obeys the
Lévy–Khinchin formula:
LY (f ) = exp

−

f dα +

ν(dχ)e−
3
f dχ −1
.
♦
Random Colorings
Let N be a Poisson random variable with parameter λ > 0 and let Z1, Z2, . . .
independent (and independent of N) Bernoulli random variables with probability of
success p ∈[0, 1]. Then
N0 :=
N

i=1
1{0}(Zi)
and
N1 :=
N

i=1
1{1}(Zi)
are independent Poisson random variables with parameters λ0 = (1 −p)λ and
λ1 = pλ. Similarly, we can allow the Zi to take values in {0, . . . , k} (for some

624
24
The Poisson Point Process
k ∈N) with probabilities p0, . . . , pk. Then the random variables
Nm :=
N

i=1
1{m}(Zi),
m = 0, . . . , k,
are independent and Poisson distributed with parameters λm = pmλ, m = 0, . . . , k.
Often, the Zi are interpreted as colors or marks that are a given independently to the
single points of the Poisson random variable N.
While the above statements can be shown easily using elementary methods (this
remains as an exercise), we will now turn to a more general situation. We assume
that the possible colors are drawn from a locally compact Polish space F (which
includes ﬁnite or countable F and F = R) with Borel σ-algebra B(F) and that X is
a Poisson point process on a locally compact Polish space E with intensity measure
μ ∈M(E). Let ν ∈M1(F) and let Z1, Z2, . . . be i.i.d. F-valued random variables
with distribution ν. We assume that the Zi are independent of X. The Zi are the
colors that we want to attach to the points of X. However, in order to do so, we need
an enumeration of the points of X. Any enumeration will do the trick and since the
Zi are i.i.d., the resulting will not depend on the speciﬁc enumeration we choose (in
distribution).
We proceed similarly as in the proof of existence of the Poisson point process
(Theorem 24.12). We decompose μ into a sum of ﬁnite measures μ = ∞
n=1 μn
with μn ∈Mf (E), μn ̸= 0 for any n ∈N. Let (Nn)n∈N be independent random
variables with Nn ∼Poiμn(E). Deﬁne μn := μn/μn(E) ∈M1(E). Let (Yn,i)n,i∈N
and (Zn,i)n,i∈N be independent (and independent of (Nn)) random variables with
Yn,i ∼μn and Zn,i ∼ν, n, i ∈N. Let
X(A) :=
∞

n=1
Nn

i=1
1A(Yn,i),
A ∈Bb(E).
In the proof of Theorem 24.12, we showed that X ∼PPPμ.
We attach random colors Zn,i to the points Yn,i be deﬁning

X(A × B) :=
∞

n=1
Nn

i=1
1A(Yn,i) 1B(Zn,i),
A ∈Bb(E), B ∈B(F).
Clearly, this deﬁnes a random measure

X(C) =
∞

n=1
Nn

i=1
1C((Yn,i, Zn,i)),
C ∈B(E × F).
By construction, we have 
X ∼PPPμ⊗ν.

24.2
Properties of the Poisson Point Process
625
The next generalization we focus on is that we want to allow the distribution
of the random color of a point to depend on its position but not on the positions
of the other points. More precisely, let κ be a Markov kernel from E to F. If
x ∈E is a point of X, that is, if X({x}) = 1, then the color of that point will
be chosen at random with distribution κ(x, ·). The proper way to do this is to use
the construction outlined above but with Zn,i depending on Yn,i. More precisely, we
assume that the bivariate random variables (Yn,i, Zn,i), n, i ∈N, are independent
with distribution μn ⊗κ. That is,
P[Yn,i ∈A, Zn,i ∈B] =

1A(x)κ(x, B) μn(dx)
for A ∈B(E), B ∈B(F).
Clearly, we then have that

Xn(C) :=
Nn

i=1
1C((Yn,i, Zn,i)),
C ∈B(E × F)
is a PPPμn⊗κ.
Finally, we deﬁne

Xn(C) :=
∞

n=1

Xn(C) =
∞

n=1
Nn

i=1
1C((Yn,i, Zn,i)),
C ∈B(E × F).
If x ∈E and X({x}) = 1, then we have Yn,i = x for one of the pairs (n, i) that
show up in the sum. Since L(Zn,i |Yn,i = x) = κ(x, ·), the color of x is distributed
according to κ(x, ·) (and is independent of everything else).
We observe that μ ⊗κ = ∞
n=1(μn ⊗κ) to conclude:
Theorem 24.23 (Coloring theorem) 
X is a PPPμ⊗κ.
In some situations we are interested only in the colors and not in the positions of the
underlying points. In order to formalize this, we deﬁne the projection π : E × F →
F, (x, y) →y and let Xκ := 
X ◦π−1 be the image measure of 
X. More explicitly,
this means
Xκ(B) = ˜X(E × B)
for B ∈Bb(F).
In order for Xκ to be a random measure, we need to assume μκ = (μ ⊗κ) ◦π−1 ∈
M(F). This implies that by the projection, the colors do not concentrate to much to
violate local boundedness of Xκ.
Theorem 24.24 Xκ is a random measure with PXκ = PPPμκ.

626
24
The Poisson Point Process
Proof In the above notation, we have
Xκ(B) = ˜X(E × B) =
∞

n=1
Nn

i=1
1B(Zn,i)
for B ∈Bb(F).
Now Zn,i ∼μnκ and
μκ =
∞

n=1
μnκ =
∞

n=1
μn(E)μnκ.
Following the construction in the proof of Theorem 24.12 we infer the claim.
⊓⊔
We come back to the initial problem of a ﬁnite coloring of Poisson random variable.
Since we are interested in the colors but not in the positions of the points, we take
an arbitrary but sufﬁciently rich space E. For deﬁniteness, let us assume E = [0, 1].
Let λ > 0, and let μ be λ-times the Lebesgue measure on [0, 1]. Let k ∈N and F =
{0, . . ., k} and let (pm)m=0,...,k be probability weights on F. We deﬁne κ(x, {m}) =
pm for all x ∈E. Then μκ({m}) = λpm and the randomly colored point process
Xκ has the property that Nm := Xκ({m}), m = 0, . . . , k are independent Poisson
random variables with parameters λpm. However, N := X(E) ∼Poiλ.
Example 24.25 (PPP as invariant distribution) As an application of the previous
theorem, consider a stochastic process on E = Zd or E = Rd that consists of a
system of independent random walks. Hence assume that we are given i.i.d. random
variables Zi
n, i, n ∈N with distribution ν ∈M1(E). Further, assume that, at time n,
the position of the ith particle of our system of random walks is Si
n := Si
0+n
l=1 Zi
l ,
where Si
0 is an arbitrary, possibly random, starting point. Assume that the particles
are indistinguishable. Hence we simply add the particles at each site:
Xn(A) :=
∞

i=1
1A(Si
n)
for A ⊂E.
Each Xn is a measure on E and, if at the beginning the particles are not too
concentrated locally, it is a locally ﬁnite measure and hence a random measure.
Assume that X0 ∼PPPμ for some μ ∈M(E). Deﬁne κ(x, ·) = δx ∗ν, and
write κn for the n-fold application of κ; that is, κn(x, ·) = δx ∗ν∗n. We thus get
Xκ
0
D= X1. Indeed, independence of the motions of the individual particles in the
deﬁnition of Xκ
0 is exactly independence of the random walks. As X1 is also a PPP,
we get inductively Xκ
n
D= Xn+1 and thus Xn ∼PPPμκn = PPPμ∗ν∗n. In particular,
X0
D= Xn if and only if μ ∗ν = μ. Clearly, this is true if we have E = Zd and μ
the counting measure or if E = Rd and μ is the Lebesgue measure. For example, if
E = Zd, then under rather mild assumptions on ν one can show that the counting
measure μ = λ is the unique (up to multiples) solution of μ ∗ν = μ. In this case,

24.3
The Poisson–Dirichlet Distribution
627
every invariant measure is a convex combination of PPPs with different intensity
measures θλ. ♦
Takeaways For non-atomic intensity measure, the Poisson point process can
be characterised by the probabilities for sets to be vacant (Rényi’s theorem).
Images of Poisson point process are again Poisson point processes. If we
assign an independent random colour to each Poisson point, we get a Poisson
point process on the original space enhanced by the space of colours. Inﬁnitely
divisible nonnegative random variables can be represented as the weighted
sum of points of a Poisson point process with the canonical measure as
intensity measure. Poisson point processes can pop up as invariant states of
large particle systems, in particular in grand canonical ensembles.
Exercise 24.2.1 Use an approximation with simple functions in order to show the
claim of Corollary 24.15 without using characteristic functions. ♣
Exercise 24.2.2 Let p1, p2 ∈(0, 1] and r1, r2 > 0. Show the following statement
about the stochastic order of negative binomial distributions: b−
r1,p1 ≤st b−
r2,p2 if and
only if
p1 ≥p2
and
pr1
1 ≥pr2
2 .
♣
24.3
The Poisson–Dirichlet Distribution∗
The goal of this section is to solve the following problem. Take a stick of length 1.
Choose a point of the stick uniformly at random and break the stick at this point.
Put the left part of the stick (with length, say, W1) aside. With the remaining part of
the stick proceed just as with the original stick. Break it in two and put the left part
(of length W2) aside. Successively, we thus collect fractions of the stick of lengths
W1, W2, W3, . . .. What is the joint distribution of (W1, W2, . . .)? Furthermore, if we
order the numbers W1, W2, . . . in decreasing order W(1) ≥W(2) ≥. . ., what is the
distribution of (W(1), W(2), . . .)? And ﬁnally, why do we ask these questions in a
chapter on Poisson point processes?
Answering these questions requires some preparation. We saw that the Beta
distribution occurs naturally in Pólya’s urn model as the limiting distribution of
the fraction of balls of a given color. Clearly, Pólya’s urn model can be considered
for any number n ≥2 of colors. The limiting distribution is then the n-dimensional
generalization of the Beta distribution, namely the so-called Dirichlet distribution.
Deﬁne the (n −1)-dimensional simplex

628
24
The Poisson Point Process
Δn := {(x1, . . . , xn) ∈[0, 1]n : x1 + . . . + xn = 1}.
Deﬁnition 24.26 Let n ∈{2, 3, . . .} and θ1, . . . , θn > 0. The Dirichlet distribution
Dirθ1,...,θn is the distribution on Δn that is deﬁned for measurable A ⊂Δn by
Dirθ1,...,θn(A) =

1A(x1, . . . , xn) fθ1,...,θn(x1, . . . , xn) dx1 · · · dxn−1.
Here
fθ1,...,θn(x1, . . . , xn) = Γ (θ1 + . . . + θn)
Γ (θ1) · · · Γ (θn) xθ1−1
1
· · · xθn−1
n
.
If the parameters θ1, . . . , θn are integer-valued, they correspond to the numbers of
balls of the different colors that are originally in the urn. Assume that the colors n−1
and n are light green and green and that in the dim light we cannot distinguish them.
Then we should still end up with a Dirichlet distribution in the limit but with n −1
instead of n and with θn−1 + θn instead of θn−1 and θn; that is, Dirθ1,...,θn−2,θn−1+θn.
Let (Mt)t≥0 be the Moran Gamma subordinator, the stochastic process with
right continuous, monotone increasing paths t →Mt and independent, stationary,
Gamma-distributed increments: Mt −Ms ∼Γ1,t−s for t > s ≥0. An important
connection between M and the Dirichlet distribution is revealed by the corollaries
of the following theorem and by Theorem 24.32.
Theorem 24.27 Let n ∈N, θ1, . . . , θn > 0 and Θ := θ1 + . . . + θn. Let X ∼
Dirθ1,...,θn and let Z ∼Γ1,Θ be independent random variables. Then the random
variables Si := Z · Xi, i = 1, . . . , n are independent and Si ∼Γ1,θi.
Proof In the following, always let xn := 1 −n−1
i=1 xi and s = n
j=1 sj. Let
Δ′
n :=

(x1, . . . , xn−1) ∈(0, 1)n−1 :
n−1

i=1
xi < 1

.
For x ∈Δ′
n and z ≥0, the distribution of (X1, . . . , Xn−1, Z) has the density
f (x1, . . . , xn−1, z) =
n

j=1

x
θj −1
j
R
Γ (θj)

zΘ−1 e−z.
Consider the map
F : Δ′
n × (0, ∞) →(0, ∞)n,
(x1, . . . , xn−1, z) →(zx1, . . . , zxn).
This map is invertible with inverse map
F −1 : (s1, . . . , sn) →(s1/s, . . . , sn−1/s, s).

24.3
The Poisson–Dirichlet Distribution
629
The Jacobian determinant of F is det(F ′(x1, . . . , xn−1, z))
=
zn−1. By the
transformation formula for densities (Theorem 1.101), (S1, . . . , Sn) has density
g(s1, . . . , sn) =
f (F −1(s1, . . . , sn))
| det(F ′(F −1(s1, . . . , sn)))|
= sΘ−1 e−s
sn−1
n

j=1

(sj/s)θj −1@
Γ (θj)

=
n

j=1

s
θj −1
j
e−sj @
Γ (θj)

.
However, this is the density for independent Gamma distributions.
⊓⊔
Corollary 24.28 If ti := i
j=1 θj for i = 0, . . . , n, then the random variables
X = ((Mti −Mti−1)/Mtn, i = 1, . . . , n) and S := Mtn are independent with
distributions X ∼Dirθ1,...,θn and S ∼Γ1,tn.
Corollary 24.29 Let (X1, . . . , Xn) ∼Dirθ1,...,θn. Then X1 ∼βθ1,n
i=2 θi and
(X2/(1 −X1), . . . , Xn/(1 −X1)) ∼Dirθ2,...,θn are independent.
Proof Let M be as in Corollary 24.28. Then X1 = Mt1/Mtn ∼βθ1,tn−θ1. Since
X1 =
 Mtn−Mt1
Mt1
+ 1
−1
, we see that X1 depend only on Mt1 and Mtn −Mt1. On the
other hand,

X2
1 −X1
, . . . ,
Xn
1 −X1

=
Mt2 −Mt1
Mtn −Mt1
, . . . , Mtn −Mtn−1
Mtn −Mt1

is independent of Mt1. By Corollary 24.28, it is also independent of Mtn −Mt1 and
is Dirθ2,...,θn-distributed.
⊓⊔
Corollary 24.30 Let V1, . . . , Vn−1 be independent, Vi ∼βθi,θi+1+...+θn and Vn =
1. Then

V1, (1 −V1)V2, (1 −V1)(1 −V2)V3, . . . ,
 n−1

i=1
(1 −Vi)

Vn

∼Dirθ1,...,θn.
Proof This follows by iterating the claim of Corollary 24.29.
⊓⊔
It is natural to ask what happens if we distinguish more and more colors (instead
of pooling them). For simplicity, consider a symmetric situation where we have
θ1 = . . . = θn = θ/n for some θ > 0. Hence we consider
Dirθ;n := Dirθ,...,θ
for θ > 0.

630
24
The Poisson Point Process
If Xn = (Xn
1, . . . , Xn
n) ∼Dirθ/n;n, then, by symmetry, we have E[Xn
i ] = 1/n
for every n ∈N and i = 1, . . . , n. Hence, clearly (Xn
1, . . . , Xn
k) n→∞
⇒0 for any
k ∈N. In order to obtain a nontrivial limit, one possibility is to reorder the values
by decreasing size: Xn
(1) ≥Xn
(2) ≥. . ..
Deﬁnition 24.31 Let θ > 0 and let (Mt)t∈[0,θ] be a Moran Gamma subordinator.
Let m1 ≥m2 ≥. . . ≥0 be the jump sizes of M in decreasing order and let
˜mi = mi/Mθ, i = 1, 2, . . .. The distribution of the random variables ( ˜m1, ˜m2, . . .)
on S := {(x1 ≥x2 ≥. . . ≥0) : x1 + x2 + . . . = 1} is called the Poisson–Dirichlet
distribution PDθ with parameter θ > 0.
To be honest, we still have to show that ∞
i=1 ˜mi = 1. To this end, let Y be a PPP on
(0, ∞) × (0, θ] with intensity measure ν ⊗λ, where λ is the Lebesgue measure and
ν(dx) = e−xx−1 dx is the Lévy measure of the Γ1,1 distribution. We can deﬁne M
by Mt := 
(x,s): Y({x,s})=1, s≤t x. Now we have m1 = sup{x ∈(0, ∞) : Y({x} ×
(0, θ]) = 1}. Inductively, we get mn = sup{x < mn−1 : Y({x} × (0, θ]) = 1} for
n ≥2. Interchanging the order of summations, we obtain Mθ = ∞
n=1 mn.
Theorem 24.32 If Xn ∼Dirθ/n;n for n ∈N, then P(Xn
(1),Xn
(2),...)
n→∞
−→PDθ.
Proof The idea is to express the random variables Xn, n ∈N, in terms of the
increments of the Moran Gamma subordinator (Mt)t∈[0,θ] in such a way that
convergence of distributions implies almost sure convergence. Hence, let Xn
i
=
(Mθi/n −Mθ(i−1)/n)/Mθ. By Corollary 24.28, we have Xn
∼Dirθ/n;n. Let
t1, t2, . . . ∈(0, θ] be the positions of the jumps m1 ≥m2 ≥. . .. Evidently,
Xn
(1) ≥˜m1 for every n. If n is large enough that |t1 −t2| > θ/n, then Xn
(2) ≥˜m2.
Inductively, we get lim infn→∞Xn
(i) ≥
˜mi almost surely. Using the convention
Xn
(i) = 0 for i > n, we have ∞
i=1 Xn
(i) = 1 for every n ∈N. By Fatou’s lemma, we
thus get
1 =
∞

i=1
˜mi ≤
∞

i=1
lim inf
n→∞Xn
(i) ≤lim inf
n→∞
∞

i=1
Xn
(i) = 1.
Therefore, limn→∞Xn
(i) = ˜mi almost surely.
⊓⊔
Instead of ordering the values of Xn by their sizes, there is a different way
of arranging the terms so that the distributions converge. Think of a biological
population in which a certain phenotypical property can be measured with different
levels of precision. If we distinguish n different values of this property, then we
write Xn
i for the proportion of the population that has type i ∈{1, . . . , n}.
Now successively choose individuals from the population at random. Let I n
1 be
the type of the ﬁrst individual. Denote by I n
2 the type of the ﬁrst individual that is
not of type I n
1 . That is, I n
2 is the second type that we see. Now inductively deﬁne
I n
k as the kth type that we see; that is, the type of the ﬁrst individual that has none
of the types I n
1 , . . . , I n
k−1. Consider the vector ˆXn = ( ˆXn
1, . . . , ˆXn
n), where ˆXn
k =

24.3
The Poisson–Dirichlet Distribution
631
Xn
I n
k . Since the probability of the event {I n
1 = i} is proportional to the size of the
subpopulation of type i, we say that ˆXn is the successively size-biased vector.
The distribution of ˆXn does not change if we change the order of the Xn
1, . . . , Xn
n.
For example, instead of Xn
1, . . . , Xn
n, we can use the order statistics (in decreasing
order) (Xn
(1), . . . , Xn
(n)) and again end up with ˆXn as the successively size-biased
vector. Hence we can deﬁne the successively size-biased vector ˆX for the inﬁnite
vector X ∼PDθ. If Xn ∼Dirθ/n;n, then by Theorem 24.32, we have ˆXn n→∞
⇒
ˆX.
Hence we can compute the distribution of ˆX.
Theorem 24.33 Let θ > 0 and Xn ∼Dirθ/n;n, n ∈N. Let X ∼PDθ. Further,
let V1, V2, . . . be i.i.d. random variables on [0, 1] with density x →θ(1 −x)θ−1.
Deﬁne Z1 = V1 and Zk =  k−1
i=1(1 −Vi)Vk for k ≥2. Then:
(i)
ˆXn n→∞
⇒
ˆX.
(ii)
ˆX D= Z.
The distribution of Z is called the GEMθ distribution (Grifﬁths–Engen–
McCloskey).
Proof Statement (i) was shown in the discussion preceding the theorem. In order
to show (ii), we compute the distribution of ˆXn and show that it converges to the
distribution of Z.
Let ˆXn,1 be the vector ˆXn,1 = (Xn
I n
1 , Xn
1, Xn
2, . . . , Xn
I n
1 −1, Xn
I n
1 +1, . . . , Xn
n), in
which only the ﬁrst coordinate is sampled size-biasedly. We show that
ˆXn,1 ∼Dir(θ/n)+1,θ/n,...,θ/n.
(24.12)
Let f (x) =

Γ (θ)/Γ (θ/n)n
· n
k=1 x(θ/n)−1
k
be the density of Dirθ/n;n. We
compute the density ˆf n,1 of ˆXn,1 by decomposing according to the value i of I n
1 :
ˆf n,1(x) =
n

i=1
x1 f (x2, . . . , xi, x1, xi+1, . . . , xn) = n x1 f (x)
=
nΓ (θ)
Γ (θ/n)n xθ/n
1
n

i=2
x(θ/n)−1
i
=
Γ (θ + 1)
Γ ((θ/n) + 1) Γ (θ/n)n−1 xθ/n
1
n

i=2
x(θ/n)−1
i
.
However, this is the density of Dir(θ/n)+1,θ/n,...,θ/n. By Corollary 24.29, we have
ˆXn,1
D= V n
1 , (1 −V n
1 )Y1, . . . , (1 −V n
1 )Yn−1
,

632
24
The Poisson Point Process
where
V n
1 ∼β(θ/n)+1,θ(n−1)/n
and
Y = (Y1, . . . , Yn−1) ∼Dirθ/n;n−1
are independent. Applying this to Y, we get inductively
ˆXn D= Zn,
(24.13)
where
Zn
1 = V n
1
and
Zn
k =
 k−1

i=1
(1 −V n
i )

V n
k
for k ≥2
and where V n
1 , . . . , V n
n−1 are independent and V n
i
∼β(θ/n)+1,θ(n−i)/n. Now it is
easy to check that β(θ/n)+1,θ(n−i)/n
n→∞
−→β1,θ for every i ∈N. Recall that β1,θ has
the density x →θ(1 −x)θ−1. Hence V n
i
n→∞
⇒Vi for every i and thus Zn n→∞
⇒Z
and ˆXn n→∞
⇒Z. Together with (i), this proves claim (ii).
⊓⊔
At the beginning of this chapter, we raised the question of how the sizes W1, W2, . . .
of the stick lengths are distributed if at each step, we break the remaining part of
the stick at a point chosen uniformly at random. The preceding theorem gives the
answer: The vector (W(1), W(2), . . .) has distribution PD1, and (W1, W2, . . .) has
distribution GEM1.
The Chinese Restaurant Process
We will study a further situation in which the Poisson–Dirichlet distribution arises
naturally. As the technical details get a bit tricky, we content ourselves with the
description of the problem and with stating (but not proving) two fundamental
theorems. An excellent reference for this type of problem is [130].
Consider a Chinese restaurant with countably many enumerated round tables. At
each table, there is enough space for arbitrarily many guests. Initially, the restaurant
is empty. One by one an inﬁnite number of guests arrive. The ﬁrst guest sits down at
table number one. If there are already n guests sitting at k tables, then the (n + 1)th
guest can choose between sitting down at any of the k occupied tables or at the free
table with the smallest number (that is, k + 1). Assume that the guest makes his
choice at random (and independently of the previous choices of the other guests).
For l ≤k, denote by Nn
l the number of guests at the lth table and assume that the
probability of choosing the lth table is (Nn
l −α)/(n + θ). Then the probability of
choosing the ﬁrst free table is (θ + kα)/(n + θ). Here α ∈[0, 1] and θ > −α are
parameters. We say that (Nn)n∈N = (Nn
1 , Nn
2 , . . .)n∈N is the Chinese restaurant
process with parameters (α, θ).

24.3
The Poisson–Dirichlet Distribution
633
In the special case α = 0, there is a nice interpretation: Assume that the new
guest can also choose his seating position at the table (that is, his neighbor to the
right). Then, for any of the present guests, the probability of being chosen as a right
neighbor is 1/(n + θ). The probability of starting a new table is θ/(n + θ).
In order to study the large n behavior of Nn/n = (Nn
1 /n, Nn
2 /n, . . .), we extend
the Poisson–Dirichlet distribution and the GEM distribution by a further parameter.
Deﬁnition 24.34 Let α ∈[0, 1) and θ > −α. Let V1, V2, . . . be independent and
Vi ∼β1−α,θ+iα. Deﬁne Z = (Z1, Z2, . . .) by Z1 = V1 and
Zk = Vk
k−1

i=1

1 −Vi

for k ≥2.
Then GEMα,θ := PZ is called the GEM distribution with parameters (α, θ). The
distribution of the size-biased vector (Z(1), Z(2), . . .) is called the Poisson–Dirichlet
distribution with parameters (α, θ), or brieﬂy PDα,θ.
Explicit formulas for the densities of the ﬁnite-dimensional marginals of PDα,θ can
be found in [132]. Note that, for α = 0, we recover the classical distributions
GEMθ = GEM0,θ and PDθ = PD0,θ.
Theorem 24.35 Let α ∈[0, 1), θ > −α and let (Nn)n∈N be the Chinese restaurant
process with parameters (α, θ). Then PNn/n
n→∞
−→PDα,θ.
Proof See [129] or [130, Theorem 25].
⊓⊔
Reﬂection The Hoppe urn is a variation of the Pólya Urne. Initially, there is only
one ball in the urn and this one has a unique label. Whenever this ball is drawn it will
be returned together with a ball of a completely new colour. Whenever one of the
coloured balls is drawn, it will be returned together with a second ball of the same
colour. The unique ball is sometimes called the mutator. What is the connection
between the Hoppe urn and the Chinese restaurant process? ♠
As for the one-parameter Poisson–Dirichlet distribution, there is a representation of
PDα,θ in terms of the size-ordered jumps of a certain subordinator. In the following,
let α ∈(0, 1) and let (Mt)t∈[0,1] be an α-stable subordinator; that is, a subordinator
with Lévy measure ν(dx) = x−α−1 dx. Further, let m1 ≥m2 ≥. . . ≥0 be
the jumps of M, ˜mi = mi/M1 for i ∈N, and ˜m = ( ˜m1, ˜m2, . . .). We quote the
following theorem from [130, Section 4.2].
Theorem 24.36 Let α ∈(0, 1).
(i)
˜m ∼PDα,0.
(ii) If θ > −α, then PDα,θ ≪PDα,0 = P[ ˜m ∈·] and the density is
PDα,θ(dx) =
M−θ
1
E[M−θ
1 ]
P[ ˜m ∈dx].

634
24
The Poisson Point Process
Takeaways The Dirichlet distribution generalises the beta distribution from
two to n types. After sorting the values of a Dirichlet random variable
(X1, . . . , Xn) in decreasing order, we can take the limit as n →∞and get
the so-called Poisson-Dirichlet distribution. Drawing the values of a given
realisation of a Poisson-Dirichlet random variable successively with size
biased probabilities, we get a GEM distributed vector. The GEM distribution
plays an important role in the mathematical descriptions of samples in ecology
and evolutionary genetics.
Exercise 24.3.1 Let (X, 1 −X) ∼Dirθ1,θ2. Show that X ∼βθ1,θ2 is Beta-
distributed. ♣
Exercise 24.3.2 Let X = (X1, . . . , Xn) ∼Dirθ1,...,θn. Show the following.
(i) For any permutation σ on {1, . . ., n}, we have
(Xσ(1), . . . , Xσ(n)) ∼Dirθσ(1),...,θσ(n).
(ii) (X1, . . . , Xn−2, Xn−1 + Xn) ∼Dirθ1,...,θn−2,θn−1+θn. ♣
Exercise 24.3.3 Let (Nn)n∈N be the Chinese restaurant process with parameters
(0, θ).
(i) Let θ = 1.
(a) Show that P[Nn
1 = k] = 1/n for any k = 1, . . . , n,
(b) Show that, for kl = 1, . . . , n −(k1 + . . . + kl−1),
P)Nn
l = kl
Nn
1 = k1, . . . , Nn
l−1 = kl−1
* =
1
n −(k1 + . . . + kl−1).
(c) Infer the claim of Theorem 24.35 in the case α = 0 and θ = 1.
(ii) Let θ > 0.
(a) Show that n P[Nn
1 = ⌊nx⌋]
n→∞
−→θ(1 −x)θ−1 for x ∈(0, 1).
(b) Show that
n P
)
Nn
l = ⌊nxl⌋
Nn
1 = ⌊nx1⌋, . . . ,Nn
l−1 = ⌊nxl−1⌋
*
n→∞
−→(θ/yl)

1 −xl/yl
θ−1
for x1, . . . , xl ∈(0, 1) with yl = 1 −(x1 + . . . + xl−1) > xl.
(c) As in (i), infer the claim of Theorem 24.35 for α = 0 and θ > 0. ♣

Chapter 25
The Itô Integral
The Itô integral allows us to integrate stochastic processes with respect to the
increments of a Brownian motion or a somewhat more general stochastic process.
We develop the Itô integral ﬁrst for Brownian motion and then for generalized
diffusion processes (so-called Itô processes). In the third section, we derive the
celebrated Itô formula. This is the chain rule for the Itô integral that enables us
to do explicit calculations with the Itô integral. In the fourth section, we use the Itô
formula to obtain a stochastic solution of the classical Dirichlet problem. This in turn
is used in the ﬁfth section in order to show that like symmetric simple random walk,
Brownian motion is recurrent in low dimensions and transient in high dimensions.
25.1
Itô Integral with Respect to Brownian Motion
Let W = (Wt)t≥0 be a Brownian motion on the space (Ω, F, P) with respect to
the ﬁltration F that satisﬁes the usual conditions (see Deﬁnition 21.22). That is, W
is a Brownian motion and an F-martingale. The aim of this section is to construct
an integral
I W
t (H) =
 t
0
Hs dWs
for a large class of integrands H : Ω×[0, ∞) →R, (ω, t) →Ht(ω) in such a way
that (I W
t (H))t≥0 is a continuous F-martingale. Since almost all paths s →Ws(ω)
of Brownian motion are of locally inﬁnite variation, W(ω) is not the distribution
function of a signed Lebesgue–Stieltjes measure on [0, ∞). Hence I W
t (H) cannot
be deﬁned in the framework of classical integration theory. The basic new idea is
to establish the integral as an L2-limit. We start with an elementary example to
illustrate this.
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_25
635

636
25
The Itô Integral
Example 25.1 Assume that X1, X2, . . . are i.i.d. Rad1/2 random variables; that is,
P[Xn = 1] = P[Xn = −1] = 1
2. Let (hn)n∈N be a sequence of real numbers.
Under which assumptions on (hn)n∈N is the series
R :=

n∈N
hn Xn
(25.1)
well-deﬁned? If 
n∈N |hn| < ∞, then the series converges absolutely for every
ω. In this case, there is no problem. Now assume that only the weaker condition

n∈N h2
n < ∞holds. In this case, the series (25.1) does not necessarily converge
any more for every ω. However, we have E[hn Xn] = 0 for each n ∈N and
∞
n=1 Var[hn Xn] = ∞
n=1 h2
n < ∞. Hence RN := N
k=1 hk Xk converges in L2
(for N →∞). We can thus deﬁne the series R in (25.1) as the L2-limit of the
partial sums RN. Note that (at least formally) for the approximating sums the order
of summation matters. In a sense, we have constructed ∞
n=1 instead of 
n∈N.
An equivalent formulation that gives a ﬂavor of what is to come is the following.
Denote by ℓ2 the Hilbert space of square summable sequences of real numbers
with inner product ⟨h, g⟩= ∞
n=1 hn gn and norm ∥g∥= ⟨g, g⟩1/2. Let ℓf be the
subspace of those sequences with only ﬁnitely many nonzero entries. Then R(h) =

n∈N hn Xn for h ∈ℓf is well-deﬁned (since it is a ﬁnite sum). Since
E
)
R(h)2*
= Var[R(h)] =

n∈N
Var
)
hn Xn
*
=

n∈N
h2
n = ∥h∥2,
the map R : ℓf →L2(P) is an isometry. As ℓf ⊂ℓ2 is dense, there is a unique
continuous extension of R to ℓ2. Hence, if h ∈ℓ2 and (hN)N∈N is a sequence
in ℓf with ∥hN −h∥
N→∞
−→
0, then R(hN)
N→∞
−→
R(h) in the L2 sense. In
particular, hN
n := hn1{n≤N}, n ∈N, N ∈N, is an approximating sequence for h,
and we have R(hN) = N
n=1 hn Xn. Thus the approximation of R with the partial
sums RN that we described above is a special case of this construction. ♦
The programme for the construction of the Itô integral I W
t (H) is the following.
First consider simple functions as integrands H; that is, the map t →Ht(ω) is a
step function. For these H, the integral can easily be deﬁned as a ﬁnite sum. The
next step is to extend the integral, as in Example 25.1, to integrands that can be
approximated in a certain L2-space by simple integrands.
Deﬁnition 25.2 Denote by E the vector space of maps H : Ω × [0, ∞) →R of
the form
Ht(ω) =
n

i=1
hi−1(ω) 1(ti−1,ti],
where n ∈N, 0 = t0 < t1 < . . . < tn and hi−1 is bounded and Fti−1-measurable
for every i = 1, . . . , n. E is called the vector space of predictable simple processes.

25.1
Itô Integral with Respect to Brownian Motion
637
We equip E with a (pseudo) norm ∥· ∥E by deﬁning
∥H∥2
E =
n

i=1
E
)
h2
i−1
*
(ti −ti−1) = E
+ ∞
0
H 2
s ds
,
.
Deﬁnition 25.3 For H ∈E and t ≥0, deﬁne
I W
t (H) =
n

i=1
hi−1
Wti∧t −Wti−1∧t

and
I W
∞(H) =
n

i=1
hi−1
Wti −Wti−1
.
Clearly, for every bounded stopping time τ,
E
)
I W
τ (H)
*
=
n

i=1
E
)
hi−1 (W τ
ti −W τ
ti−1)
*
=
n

i=1
E
)
hi−1 E
)
W τ
ti −W τ
ti−1
Fti−1
**
= 0
since, by the optional stopping theorem (OST), the stopped Brownian motion W τ
is an F-martingale. Hence (again by the OST) (I W
t (H))t≥0 is an F-martingale. In
particular, we have E
)
I W
ti+1(H) −I W
ti (H)

I W
tj+1(H) −I W
tj (H)
*
= 0 for i ̸= j.
Therefore,
E
)
I W
∞(H)2*
=
n

i=1
E
'
I W
ti (H) −I W
ti−1(H)
2(
=
n

i=1
E
'
h2
i−1

Wti −Wti−1
2(
=
n

i=1
E)h2
i−1
* (ti −ti−1) = ∥H∥2
E.
(25.2)
From these considerations, the following statement is immediate.
Theorem 25.4
(i) The map I W
∞: E →L2(Ω, F, P) is an isometric linear map (with respect to
∥· ∥E and ∥· ∥2).
(ii) The process

I W
t (H)

t≥0 is an L2-bounded continuous F-martingale.

638
25
The Itô Integral
Proof Only the linearity remains to be shown. However, this is trivial.
⊓⊔
The idea is to extend the map I W
∞continuously from E to a suitable closure E of
E. Now as a subspace of what space should we close E? A minimal requirement is
that (ω, t) →Ht(ω) be measurable (with respect to F ⊗B([0, ∞))) and that H
be adapted.
Deﬁnition 25.5 A stochastic process X = (Xt)t≥0 with values in a Polish space
E is called
(i) product measurable if (ω, t) →Xt(ω) is measurable with respect to F ⊗
B([0, ∞)) – B(E),
(ii) progressively measurable if, for every t ≥0, the map Ω × [0, t] →E,
(ω, s) →Xs(ω) is measurable with respect to Ft ⊗B([0, t]) – B(E),
(iii) predictable (or previsible) if (ω, t) →Xt(ω) is measurable with respect to
the predictable σ-algebra P on Ω × [0, ∞):
P := σ

X : X is a left continuous adapted process

.
Remark 25.6 Any H ∈E is predictable. This property ensures that I M(H) is a
martingale for every (even discontinuous) martingale M . The notion of predictabil-
ity is important only for integration with respect to discontinuous martingales. As
we will not develop that calculus in this book, predictability will not be central for
us. ♦
Remark 25.7 If H is progressively measurable, then H is evidently also product
measurable and adapted. With a little work, the converse can also be shown: If
H is adapted and product measurable, then there is a progressively measurable
modiﬁcation of H (see, e.g., [115, pages 68ff]). ♦
Theorem 25.8 If H is adapted and right continuous or left continuous, then H
is progressively measurable. If H is adapted and a.s. right continuous or left
continuous, then there exists a version of H that is progressively measurable.
In particular, every predictable process is progressively measurable.
Proof See Exercise 21.1.4.
⊓⊔
We consider E as a subspace of
E0 :=

H :
product measurable, adapted and ∥H∥2 := E
'  ∞
0
H 2
t dt
(
< ∞

.
Let E denote the closure of E in E0.
Theorem 25.9 If H is progressively measurable (for instance, left continuous or
right continuous and adapted) and E
' 3 ∞
0
H 2
t dt
(
< ∞, then H ∈E.

25.1
Itô Integral with Respect to Brownian Motion
639
Proof Let H be progressively measurable and E
' 3 ∞
0
H 2
t dt
(
< ∞. It is enough
to show that, for any T > 0, there exists a sequence (H n)n∈N in E such that
E
+  T
0
(Hs −H n
s )2 ds
,
n→∞
−→0.
(25.3)
Step 1.
First assume that H is continuous and bounded. Deﬁne H n
0 = 0 and
H n
t = Hi2−n T
if i2−n T < t ≤(i + 1)2−n T for some i = 0, . . . , 2n −1
and H n
t = 0 for t > T . Then H n ∈E, and we have H n
t (ω)
n→∞
−→Ht(ω) for all
t > 0 and ω ∈Ω. By the dominated convergence theorem, we get (25.3).
Step 2.
Now let H be progressively measurable and bounded. It is enough to
show that there exist continuous adapted processes H n, n ∈N, for which (25.3)
holds. Let
H n
t := n
 t∧T
(t−1/n)∨0
Hs ds
for t ≥0, n ∈N.
Then H n is continuous, adapted and bounded by ∥H∥∞. By the fundamental
theorem of calculus (see Exercise 13.1.7), we have
H n
t (ω)
n→∞
−→Ht(ω)
for λ-almost all t ∈[0, T ] and for all ω ∈Ω.
(25.4)
By Fubini’s theorem and the dominated convergencetheorem, we thus conclude that
E
+  T
0
(Hs −H n
s )2 ds
,
=

Ω×[0,T ]
Hs(ω) −H n
s (ω)2 (P ⊗λ)(d(ω, s))
n→∞
−→0.
Step 3.
Now let H be progressively measurable, and assume E
) 3 ∞
0
H 2
t dt
*
< ∞.
It is enough to show that there exists a sequence (H n)n∈N of bounded, progressively
measurable processes such that (25.3) holds. Manifestly, we can choose H n
t
=
Ht 1{|Ht|<n}.
⊓⊔
Deﬁnition 25.10 (Itô integral) For H ∈E, deﬁne the Itô integral
 ∞
0
Hs dWs := I W
∞(H)
as the continuous extension of the map I W
∞: E →L2(P) to the closure E of E.
In other words, if (H n)n∈N is a sequence in E with ∥H −H n∥
n→∞
−→0, then we
deﬁne I W
∞(H) by

640
25
The Itô Integral
I W
∞(H) := lim
n→∞I W
∞

H n
in L2.
If τ is a stopping time, then in the following we use the abbreviation
H (τ)
t
:= Ht 1{t≤τ}
for t ≥0.
(Note that this is not the stopped process H τ
t = Hτ∧t.)
Theorem 25.11
(i) The map I W
∞: E →L2(Ω, F, P) is linear and
E)I W
∞(H)2* = E
+  ∞
0
H 2
s ds
,
.
(ii) For every H ∈E, the process ˜I W(H) deﬁned by ˜I W
t (H) := I W
∞(H (t)) is an
L2-bounded F-martingale that has a continuous modiﬁcation I W (H).
Deﬁnition 25.12 (Itô integral as a process) Let I W (H) be the continuous version
of the martingale (I W
∞(H (t)))t≥0 (see Theorem 25.11(ii)). Denote by
 t
s
Hr dWr := I W
t (H) −I W
s (H)
for 0 ≤s ≤t ≤∞
the Itô integral of H with respect to Brownian motion W on the interval [s, t].
Proof (of Theorem 25.11)
(i) This is a direct consequence of the deﬁnition of I W
∞(H).
(ii) Let (H n)n∈N be a sequence in E with ∥H n −H∥
n→∞
−→
0. By Theo-
rem 25.4(ii), we have
I W
∞

(H n)(t)
= I W
t (H n) = E
)
I W
∞(H n)
Ft
*
for all t ≥0, n ∈N.
Since
;;(H n)(t) −H (t);;
≤
;;H n −H
;;
n→∞
−→
0, this implies (using
Corollary 8.21)
˜I W
t (H) = lim
n→∞I W
t (H n) = lim
n→∞E)I W
∞(H n)
Ft
* = E)I W
∞(H)
Ft
*.
Hence ˜I W(H) is an L2-bounded martingale and I W
t (H n)
n→∞
−→
˜I W
t (H)
in L2 for every t ≥0. By Theorem 25.4(ii), I W (H n) is continuous for
every n ∈N. Thus, by Exercise 21.4.3, there exists a continuous modiﬁcation
I W (H) of ˜I W (H).
⊓⊔
The last step in the construction of the Itô integral is to weaken the strong
integrability condition E
) 3 ∞
0
H 2
s ds
*
< ∞. We start with a simple observation.

25.1
Itô Integral with Respect to Brownian Motion
641
Let τ be a stopping time and recall that
3 τ
0 Hs dWs denotes the random variable
that for any ω assumes the value
 3 τ(ω)
0
Hs dWs

(ω).
Lemma 25.13 Let τ be a stopping time and let H ∈E .
(i) We have
 τ
0
Hs dWs =
 ∞
0
H (τ)
s
dWs :=
 ∞
0
Hs 1{s≤τ} dWs
a.s.
(ii) In particular, for any t ≥0 , on the event {τ ≥t} we have
 t
0
Hs dWs =
 t
0
H (τ)
s
dWs
a.s.
(iii) Let G ∈E be such that Hs = Gs for all s ≤τ. Then
 τ
0
Hs dWs =
 τ
0
Gs dWs
a.s.
Proof
(i) Assume ﬁrst that τ takes values in {k/2n : k ∈N0}∪{∞} for some n ∈N.
Then 1{k/2n≤τ}1{t∈((k−1)/2n,k/2n]} ∈E for all k ∈N. If, in addition, H ∈E,
then also H (τ) ∈E and the claim follows directly from the deﬁnition of
the Itô integral (Deﬁnition 25.3). Now let H ∈E and let (H k)k∈N be a
sequence in E such that ∥H k −H∥E
k→∞
−→0. Writing H k,(τ)
t
:= H k
t 1{t≤τ}
we get that ∥H k,(τ) −H (τ)∥E
k→∞
−→0. By choosing a suitable sequence
km ↑∞, we obtain
 τ
0
Hs dWs = lim
m→∞
 τ
0
H km
s
dWs
= lim
m→∞
 ∞
0
H km,(τ)
s
dWs =
 ∞
0
H (τ)
s
dWs
a.s.
Finally, assume that τ is an arbitrary stopping time and deﬁne τn :=
2−n⌈2nτ⌉for n ∈N. Then (τn) is a sequence of stopping times with τn ↓
τ. Recall that I W(H) is continuous and note that ∥H (τn)−H (τ)∥E
n→∞
−→0.

642
25
The Itô Integral
Hence by taking a suitable sequence n(m) ↑∞, we get
 τ
0
Hs dWs = lim
m→∞
 τn(m)
0
Hs dWs
= lim
m→∞
 ∞
0
H (τn(m))
s
dWs =
 ∞
0
H (τ)
s
dWs
a.s.
(ii), (iii) These statements are direct consequences of (i).
⊓⊔
Deﬁnition 25.14 Let Eloc be the space of progressively measurable stochastic
processes H with
 T
0
H 2
s ds < ∞
a.s.
for all T > 0.
Lemma 25.15 For every H ∈Eloc, there exists a sequence (τn)n∈N of stopping
times with τn ↑∞almost surely and E
) 3 τn
0 H 2
s ds
*
< ∞and hence such that
H (τn) ∈E for every n ∈N.
Proof Deﬁne
τn := inf
0
t ≥0 :
 t
0
H 2
s ds ≥n
1
.
By the deﬁnition of Eloc, we have τn ↑∞almost surely. By construction, we have
;;H (τn);;2 = E
) 3 τn
0 H 2
s ds
*
≤n.
⊓⊔
Deﬁnition 25.16 Let H ∈Eloc and let (τn)n∈N be as in Lemma 25.15. For t ≥0,
deﬁne the Itô integral as the almost sure limit
 t
0
Hs dWs := lim
n→∞
 t
0
H (τn)
s
dWs.
(25.5)
Theorem 25.17 Let H ∈Eloc.
(i) The limit in (25.5) is well-deﬁned and continuous at t. Up to a.s. equality, it is
independent of the choice of the sequence (τn)n∈N.
(ii) If τ is a stopping time with E
) 3 τ
0 H 2
s ds
*
< ∞, then the stopped Itô integral
 3 τ∧t
0
Hs dWs

t≥0 is an L2-bounded, continuous martingale.
(iii) If E
) 3 T
0 H 2
s ds
*
< ∞for all T > 0, then
 3 t
0 Hs dWs

t≥0 is a square
integrable continuous martingale.

25.1
Itô Integral with Respect to Brownian Motion
643
Proof
(i) By Lemma 25.13(ii), on the event {τn ≥t}, we have
 t
0
Hs dWs =
 t
0
H (τn)
s
dWs.
Hence the limit exists, is continuous and is independent of the choice of the
sequence (τn)n∈N.
(ii) This is immediate by Theorem 25.11.
(iii) As we can choose τn = n, this follows from (ii).
⊓⊔
Theorem 25.18 Let H be progressively measurable and E
) 3 T
0 H 2
s ds
*
< ∞for
all T > 0. Then
Mt :=
 t
0
Hs dWs,
t ≥0,
deﬁnes a square integrable continuous martingale, and
(Nt)t≥0 :=

M2
t −
 t
0
H 2
s ds

t≥0
is a continuous martingale with N0 = 0.
Proof It is enough to show that N is a martingale. Clearly, N is adapted. Let τ
be a bounded stopping time. Then
E)Nτ
* = E
+
M2
τ −
 τ
0
H 2
s ds
,
= E
+  ∞
0
H (τ)
s
dWs
2,
−E
+  ∞
0

H (τ)
s
2 ds
,
= 0.
Thus, by the optional stopping theorem (see Exercise 21.1.3(iii)), N is a martingale.
⊓⊔
Recall the notions of local martingales and square variation from Sect. 21.10.
Corollary 25.19 If H
∈Eloc, then the Itô integral Mt
=
3 t
0 Hs dWs is a
continuous local martingale with square variation process ⟨M⟩t =
3 t
0 H 2
s ds.
Example 25.20
(i) Wt =
3 t
0 1 dWs is a square integrable martingale, and (W 2
t −t)t≥0 is a
continuous martingale.
(ii) Since E
) 3 T
0 W 2
s ds
*
=
T 2
2
< ∞for all T ≥0, Mt :=
3 t
0 Ws dWs is
a continuous, square integrable martingale, and

M2
t −
3 t
0 W 2
s ds

t≥0 is a
continuous martingale.

644
25
The Itô Integral
(iii) Assume that H is progressively measurable and bounded, and let Mt :=
3 t
0 Hs dWs. Then M is progressively measurable (since it is continuous and
adapted) and
E
+  T
0
M2
s ds
,
=
 T
0
  s
0
E
)
H 2
r
*
dr
2
ds ≤T 2 ∥H∥2
∞
2
.
Hence 
Mt :=
3 t
0 Ms dWs is a square integrable, continuous martingale and


M2
t −
3 t
0 M2
s dWs

t≥0 is a continuous martingale. ♦
Takeaways We cannot deﬁne an integral with respect to Brownian motion
as integrator as a Stieltjes integral. This is due to the inﬁnite variation of
paths. The Itô integral is therefore fundamentally different and is constructed
in two steps. For piecewise constant adapted integrands, it is just the weighted
sum of Brownian increments. By a clever choice of an L2 norm, the
operator that maps the integrand to the integral is an isometry. Hence, the
integral is obtained by continuous extension of the operator. It is deﬁned for
locally square integrable adapted integrands and is itself a continuous local
martingale.
25.2
Itô Integral with Respect to Diffusions
If
H =
n

i=1
hi−1 1(ti−1,ti] ∈E,
(25.6)
then the elementary integral
I M
t (H) =
n

i=1
hi−1

Mti∧t −Mti−1∧t

is a martingale (respectively local martingale) if M is a martingale (respectively
local martingale). Furthermore,
E
)
(I M
∞(H))2*
=
n

i=1
E
)
h2
i−1(Mti −Mti−1)2*
=
n

i=1
E
)
h2
i−1(⟨M⟩ti −⟨M⟩ti−1)
*
= E
+  ∞
0
H 2
t d⟨M⟩t
,

25.2
Itô Integral with Respect to Diffusions
645
if the expression on the right-hand side is ﬁnite. Roughly speaking, the procedure in
Sect. 25.1 by which we deﬁned the Itô integral for Brownian motion and integrands
H ∈E can be repeated to construct a stochastic integral with respect to M for
a large class of integrands H. Essentially, in the deﬁnition of the norm on E we
have to replace dt (that is, the square variation of Brownian motion) by the square
variation d⟨M⟩t of M:
∥H∥2
M := E
+  ∞
0
H 2
t d⟨M⟩t
,
.
Extending the integral to the closure E works just as for Brownian motion. The
tricky point is to check whether a given integrand is in E. For example, for
discontinuous martingales M the integrands have to be predictable in order for the
stochastic integral to be a martingale (not to mention the difﬁculty of establishing
for such M, the existence of the square variation process). For the case of discrete
time processes, we saw this in Sect. 9.3. Now if M is a continuous martingale with
continuous square variation ⟨M⟩, then the following problem occurs. In the proof
of Theorem 25.9 in Step 2, in order to show that progressively measurable processes
H are in E, we used the fact that H n
t (ω)
n→∞
−→Ht(ω) for Lebesgue-almost all t
and all ω. Now if d⟨M⟩t is not absolutely continuous with respect to the Lebesgue
measure, then this is not sufﬁcient to infer convergence of the integrals with respect
to d⟨M⟩t. In the case of absolutely continuous square variation, however, that proof
works without change. As in Sect. 25.1, we obtain the following theorem.
Theorem 25.21 Let M be a continuous local martingale with absolutely continu-
ous square variation ⟨M⟩and let H be a progressively measurable process with
3 T
0 H 2
s d⟨M⟩s < ∞a.s. for all T ≥0. Then the Itô integral Nt :=
3 t
0 Hs dMs
is well-deﬁned and is a continuous local martingale with square variation ⟨N⟩t =
3 t
0 H 2
s d⟨M⟩s. For any sequence (τn)n∈N with τn ↑∞and
;;H (τn);;
M < ∞, and for
any family (H n,m, n, m ∈N) ⊂E with
;;H n,m −H (τn);;
M
m→∞
−→0, we have
 t
0
Hs dMs = lim
n→∞lim
m→∞I M
t (H m,n)
in probability for all t ≥0.
The following theorem formulates a certain generalization.
Theorem 25.22 Let M1 and M2 be continuous local martingales with absolutely
continuous square variation. Let H i be progressively measurable processes with
3 T
0 (H i
s )2 d⟨Mi⟩s < ∞for i = 1, 2 and T
< ∞. Let Ni
t
:=
3 t
0 H i
s dMi
s
for i = 1, 2. Then N1 and N2 are continuous local martingales with quadratic
covariation ⟨Ni, Nj⟩t =
3 t
0 H i
s H j
s d⟨Mi, Mj⟩s for i, j ∈{1, 2}. If M1 and M2
are independent, then ⟨N1, N2⟩≡0.

646
25
The Itô Integral
Proof First assume H 1, H 2 ∈E. Then there are numbers 0 = t0 < t1 < . . . < tn
and Ftk-measurable bounded maps hi
k, i = 1, 2, k = 0, . . . , n −1 such that
H i
t (ω) =
n

k=1
hi
k−1(ω) 1(tk−1,tk](t).
Therefore,
Ni
t Nj
t =
n

k,l=1
hi
k−1hj
l−1

Mi
tk∧t −Mi
tk−1∧t

Mj
tl∧t −Mj
tl−1∧t

.
Those summands with k ̸= l are local martingales. For any of the summands with
k = l,

hi
k−1hj
k−1
Mi
tk∧t −Mi
tk−1∧t
Mj
tk∧t −Mj
tk−1∧t

−

⟨Mi, Mj⟩tk∧t −⟨Mi, Mj⟩tk−1∧t

t≥0
is a local martingale. Since
n

k=1
hi
k−1hj
k−1

⟨Mi, Mj⟩tk∧t −⟨Mi, Mj⟩tk−1∧t

=
 t
0
H i
s H j
s d⟨Mi, Mj⟩s,

Ni
t Nj
t −
3 t
0 H i
s H j
s d⟨Mi, Mj⟩s

t≥0 is a continuous local martingale.
The case of general progressively measurable H 1, H 2 that satisfy an integrabil-
ity condition follows by the usual L2-approximation arguments.
If M1 and M2 are independent, then ⟨M1, M2⟩≡0.
⊓⊔
In the following, we consider processes that can be expressed as Itô integrals with
respect to a Brownian motion. For these processes, we give a different and more
detailed proof of Theorem 25.21.
Deﬁnition 25.23 Let W be a Brownian motion and let σ and b be progressively
measurable stochastic processes with
3 t
0 σ 2
s + |bs| ds < ∞almost surely for all
t ≥0. Then we say that the process X deﬁned by
Xt =
 t
0
σs dWs +
 t
0
bs ds
for t ≥0
is a generalized diffusion process (or, brieﬂy, generalized diffusion) with diffusion
coefﬁcient σ and drift b. Often X is called an Itô process.

25.2
Itô Integral with Respect to Diffusions
647
In particular, if σ and b are of the form σs = ˜σ(Xs) and bs = ˜b(Xs) for
certain maps ˜σ : R →[0, ∞) and ˜b : R →R, then X is called a diffusion (in the
proper sense).
In contrast with generalized diffusions, we will see that under certain regularity
assumptions on the coefﬁcients, diffusions in the proper sense are Markov processes
(compare Theorems 26.8, 26.10 and 26.26).
A diffusion X can always be decomposed as X = M + A, where Mt =
3 t
0 σs dWs is a continuous local martingale with square variation ⟨M⟩t =
3 t
0 σ 2
s ds
(by Corollary 25.19) and At =
3 t
0 bs ds is a continuous process of locally ﬁnite
variation.
Clearly, for the H in (25.6), we have
 t
0
Hs dMs =
n

i=1
hi−1

Mti∧t −Mti−1∧t

=
n

i=1
hi−1
 ti∧t
ti−1∧t
σs dWs =
 t
0
(Hs σs) dWs.
For progressively measurable H with
3 T
0 H 2
s d⟨M⟩s =
3 T
0 (Hsσs)2 ds < ∞for
all T ≥0, we thus deﬁne the Itô integral as
 t
0
Hs dMs :=
 t
0
(Hsσs) dWs.
Without further work, in particular, without relying on Theorem 25.21, we get the
following theorem.
Theorem 25.24 Let X = M + A be a generalized diffusion with σ and let b be
as in Deﬁnition 25.23. Let H be progressively measurable with
 T
0
H 2
s σ 2
s ds < ∞
a.s.
for all T ≥0
(25.7)
and
 T
0
|Hsbs| ds < ∞
a.s.
for all T ≥0.
(25.8)
Then the process Y deﬁned by
Yt :=
 t
0
Hs dXs :=
 t
0
Hs dMs +
 t
0
Hs dAs :=
 t
0
Hsσs dWs +
 t
0
Hsbs ds

648
25
The Itô Integral
is a generalized diffusion with diffusion coefﬁcient (Hsσs)s≥0 and drift (Hsbs)s≥0.
In particular, Nt :=
3 t
0 Hs dMs is a continuous local martingale with square
variation process ⟨N⟩t =
3 t
0 H 2
s d⟨M⟩s =
3 t
0 H 2
s σ 2
s ds.
Takeaways Diffusions are stochastic processes that are a sum of a process of
bounded variation and a stochastic integral with respect to a Brownian motion.
We have deﬁned the Itô integral for diffusions as integrators in a procedure
similar to the one for Brownian motion. The stochastic integrals are again
diffusions.
Exercise 25.2.1 Let M be a continuous local martingale with absolutely continuous
square variation ⟨M⟩(e.g., a generalized diffusion), and let H be progressively
measurable and continuous with
3 T
0 H 2
s d⟨M⟩s < ∞for all T ≥0. Further,
assume that P = (P(n))n∈N is an admissible sequence of partitions (see Deﬁni-
tion 21.56).
(i) Show that for all T ≥0, in the sense of stochastic convergence, we have
 T
0
Hs dMs = lim
n→∞

t∈Pn
T
Ht(Mt′ −Mt).
(25.9)
(ii) Show that there exists a subsequence of P such that almost surely, we
have (25.9) for all T ≥0. ♣
25.3
The Itô Formula
This and the following two sections are based on lecture notes of Hans Föllmer.
If t →Xt is a differentiable map with derivative X′ and F ∈C1(R) with
derivative F ′, then we have the classical substitution rule
F(Xt) −F(X0) =
 t
0
F ′(Xs) dXs =
 t
0
F ′(Xs)X′
s ds.
(25.10)
This remains true even if X is continuous and has locally ﬁnite variation (see
Sect. 21.10); that is, if X is the distribution function of an absolutely continuous
signed measure on [0, ∞). In this case, the derivative X′ exists as a Radon–
Nikodym derivative almost everywhere, and it is easy to show that (25.10) also
holds in this case.
The paths of Brownian motion W are nowhere differentiable (Theorem 21.17
due to Paley, Wiener and Zygmund) and thus have everywhere locally inﬁnite

25.3
The Itô Formula
649
variation. Hence a substitution rule as simple as (25.10) cannot be expected. Indeed,
it is easy to see that such a rule must be false: Choose F(x) = x2. Then the
right-hand side in (25.10) (with X replaced by W) is
3 t
0 2Ws dWs and is hence a
martingale. The left-hand side, however, equals W 2
t , which is a submartingale that
only becomes a martingale by subtracting t. Indeed, this t is the additional term
that shows up in the substitution rule for Itô integrals, the so-called Itô formula. A
somewhat bold heuristic puts us on the right track: For small t, Wt is of order √t.
If we formally write dWt =
√
dt and carry out a Taylor expansion of F ∈C2(R)
up to second order, then we obtain
dF(Wt) = F ′(Wt) dWt + 1
2F ′′(Wt) (dWt)2 = F ′(Wt) dWt + 1
2F ′′(Wt) dt.
Rewriting this as an integral yields
F(Wt) −F(W0) =
 t
0
F ′(Ws) dWs +
 t
0
1
2F ′′(Ws) ds.
(25.11)
(For certain discrete martingales, we derived a similar formula in Example 10.9.)
The main goal of this section is to show that this so-called Itô formula is indeed
correct.
The subsequent discussion in this section does not explicitly rely on the
assumption that we integrate with respect to Brownian motion. All that is needed is
that the function with respect to which we integrate have continuous square variation
(along a suitable admissible sequence of partitions P = (Pn)n∈N)). In particular,
for Brownian motion, ⟨W⟩t = t.
In the following, let P = (Pn)n∈N be an admissible sequence of partitions
(recall the deﬁnition of Cqv = CP
qv, Pn
T , Pn
S,T , t′ and so on from Deﬁnitions 21.56
and 21.58). Let X ∈C([0, ∞)) with continuous square variation (along P)
T →⟨X⟩T = V 2
T (X) = lim
n→∞

t∈Pn
T
(Xt′ −Xt)2.
For Brownian motion, we have W ∈CP
qv almost surely for any admissible sequence
of partitions (Theorem 21.64) and ⟨W⟩T = T . For continuous local martingales M
passing to a suitable subsequence P′ of P ensures that M ∈CP′
qv almost surely
(Theorem 21.70).
Now ﬁx P and let X ∈Cqv be a (deterministic) function.
Theorem 25.25 (Pathwise Itô formula) Let X ∈Cqv and F ∈C2(R). Then, for
all T ≥0, there exists the limit
 T
0
F ′(Xs) dXs := lim
n→∞

t∈Pn
T
F ′(Xt)(Xt′ −Xt).
(25.12)

650
25
The Itô Integral
Furthermore, the Itô formula holds:
F(XT ) −F(X0) =
 T
0
F ′(Xs) dXs + 1
2
 T
0
F ′′(Xs) d⟨X⟩s.
(25.13)
Here the right integral in (25.13) is understood as a classical (Lebesgue–Stieltjes)
integral.
Remark 25.26 If M is a continuous local martingale, then, by Exercise 25.2.1, the
Itô integral
3 T
0 F ′(Ms) dMs is the stochastic limit of

t∈Pn
T
F ′(Mt)(Mt′ −Mt) as
n →∞. Thus, in fact, for X = M(ω), the pathwise integral in (25.12) coincides
with the Itô integral (a.s.). In particular, for the Itô integral of Brownian motion, the
Itô formula (25.11) holds. ♦
Proof (of Theorem 25.25) We have to show that the limit in (25.12) exists and that
(25.13) holds.
For n ∈N and t ∈Pn
T (with successor t′ ∈Pn
T ), the Taylor formula yields
F(Xt′) −F(Xt) = F ′(Xt)(Xt′ −Xt) + 1
2F ′′(Xt) · (Xt′ −Xt)2 + Rn
t ,
(25.14)
where the remainder
Rn
t =

F ′′(ξ) −F ′′(Xt)

· 1
2(Xt′ −Xt)2
(for a suitable ξ between Xt and Xt′) can be bounded as follows. As X is
continuous, C := {Xt : t ∈[0, T ]} is compact and F ′′
C is uniformly continuous.
Thus, for every ε > 0, there exists a δ > 0 with
|F ′′(Xr) −F ′′(Xs)| < ε
for all r, s ∈[0, T ] with |Xr −Xs| < δ.
Since X is uniformly continuous on [0, T ] and since the mesh size |Pn| of the
partition goes to 0 as n →∞, for every δ > 0, there exists an Nδ such that
sup
n≥Nδ
sup
t∈Pn
T
|Xt′ −Xt| < δ.
Hence, for n ≥Nδ and t ∈Pn
T ,
|Rn
t | ≤1
2ε (Xt′ −Xt)2.
Summing over t ∈Pn
T in (25.14) yields

t∈Pn
T

F(Xt′) −F(Xt)

= F(XT ) −F(X0)

25.3
The Itô Formula
651
and

t∈Pn
T
|Rn
t | ≤ε

t∈Pn
T
(Xt′ −Xt)2
n→∞
−→ε ⟨X⟩T < ∞.
As ε > 0 was arbitrary, we get 
t∈Pn
T |Rn
t |
n→∞
−→
0. We have (see Exer-
cise 21.10.2)

t∈Pn
T
1
2F ′′(Xt)(Xt′ −Xt)2 n→∞
−→1
2
 T
0
F ′′(Xs) d⟨X⟩s.
Hence, in (25.14) the sum of the remaining terms also has to converge. That is, the
limit in (25.12) exists.
⊓⊔
As a direct consequence, we obtain the Itô formula for the Itô integral with respect
to diffusions.
Theorem 25.27 (Itô formula for diffusions) Let Y = M + A be a (generalized)
diffusion (see Deﬁnition 25.23), where Mt =
3 t
0 σs dWs and At =
3 t
0 bs ds. Let
F ∈C2(R). Then we have the Itô formula
F(Yt) −F(Y0) =
 t
0
F ′(Ys) dMs +
 t
0
F ′(Ys) dAs + 1
2
 t
0
F ′′(Ys) d⟨M⟩s
=
 t
0
F ′(Ys)σs dWs +
 t
0

F ′(Ys)bs + 1
2F ′′(Ys)σ 2
s

ds.
(25.15)
In particular, for Brownian motion,
F(Wt) −F(W0) =
 t
0
F ′(Ws) dWs + 1
2
 t
0
F ′′(Ws) ds.
(25.16)
As an application of the Itô formula, we characterize Brownian motion as a
continuous local martingale with a certain square variation process.
Theorem 25.28 (Lévy’s characterization of Brownian motion) Let X ∈Mloc,c
with X0 = 0. Then the following are equivalent.
(i) (X2
t −t)t≥0 is a local martingale.
(ii) ⟨X⟩t = t for all t ≥0.
(iii) X is a Brownian motion.
Proof (iii) ⇒(i)
This is obvious.
(i) ⇐⇒(ii)
This is clear since the square variation process is unique.
(ii) ⇒(iii)
It is enough to show that Xt −Xs ∼N0,t−s given Fs for t > s ≥0.
Employing the uniqueness theorem for characteristic functions, it is enough to show

652
25
The Itô Integral
that (with i = √−1) for A ∈Fs and λ ∈R, we have
ϕA,λ(t) := E
)
eiλ(Xt−Xs) 1A
*
= P[A] e−λ2(t−s)/2.
Applying Itô’s formula separately to the real and the imaginary parts, we obtain
eiλXt −eiλXs =
 t
s
i λ eiλXr dXr −1
2
 t
s
λ2 eiλXr dr.
Therefore,
E
)
eiλ(Xt−Xs) Fs
*
−1
= E
+ t
s
i λ eiλ(Xr−Xs) dXr
Fs
,
−1
2 λ2 E
+ t
s
eiλ(Xr−Xs) dr
Fs
,
.
Now Mt := Re 3 t
s i λ eiλ(Xr−Xs) dXr and Nt := Im 3 t
s i λ eiλ(Xr−Xs) dXr, t ≥s are
continuous local martingales with
⟨M⟩t =
 t
s
λ2 sin

λ(Xr −Xs)
2 dr ≤λ2(t −s)
and
⟨N⟩t =
 t
s
λ2 cos

λ(Xr −Xs)
2 dr ≤λ2(t −s).
Thus, by Corollary 21.76, M and N are martingales. Hence we have
E
+ t
s
i λ eiλ(Xr−Xs) dXr
Fs
,
= 0.
Since A ∈Fs, Fubini’s theorem yields
ϕA,λ(t) −ϕA,λ(s) = E)eiλ(Xt−Xs) 1A
* −P[A]
= −1
2 λ2
 t
s
E
)
eiλ(Xr−Xs) 1A
*
dr = −1
2 λ2
 t
s
ϕA,λ(r) dr.
That is, ϕA,λ is the solution of the linear differential equation
ϕA,λ(s) = P[A]
and
d
dt ϕA,λ(t) = −1
2 λ2 ϕA,λ(t).
The unique solution is ϕA,λ(t) = P[A] e−λ2(t−s)/2.
⊓⊔

25.3
The Itô Formula
653
As a consequence of this theorem, we get that any continuous local martingale
whose square variation process is absolutely continuous (as a function of time) can
be expressed as an Itô integral with respect to some Brownian motion.
Theorem 25.29 (Itô’s martingale representation theorem) Let M be a contin-
uous local martingale with M0 = 0 and absolutely continuous square variation
t →⟨M⟩t. Then, on a suitable extension of the underlying probability space, there
exists a Brownian motion W with
Mt =
 t
0
K
d⟨M⟩s
ds
dWs
for all t ≥0.
Proof Assume that the probability space is rich enough to carry a Brownian motion

W that is independent of M . Let
ft := lim
n→∞n

⟨M⟩t −⟨M⟩t−1/n

for t > 0.
Then f is a progressively measurable version of the Radon–Nikodym derivative
d⟨M⟩t
dt
. Clearly,
3 T
0 1{ft>0} f −1
t
d⟨M⟩t ≤T
< ∞for all T
> 0. Hence the
following integrals are well-deﬁned, and furthermore, as a sum of continuous
martingales,
Wt :=
 t
0
1{fs>0} f −1/2
s
dMs +
 t
0
1{fs=0} d 
Ws
is a continuous local martingale. By Theorem 25.22, we have
⟨W⟩t =
 t
0
1{fs>0} f −1
s
d⟨M⟩s +
 t
0
1{fs=0} ds
=
 t
0
1{fs>0} f −1
s
fs ds +
 t
0
1{fs=0} ds
= t.
Hence, by Theorem 25.28, W is a Brownian motion. On the other hand, we have
 t
0
f 1/2
s
dWs =
 t
0
1{fs>0} f 1/2
s
f −1/2
s
dMs +
 t
0
1{fs=0} f 1/2
s
d 
Ws
=
 t
0
1{fs>0} dMs.
However,
Mt −
 t
0
1{fs>0} dMs =
 t
0
1{fs=0} dMs

654
25
The Itô Integral
is a continuous local martingale with square variation 3 t
0 1{fs=0} d⟨M⟩s = 0 and
hence it almost surely equals zero. Therefore, we have Mt =
3 t
0 f 1/2
s
dWs, as
claimed.
⊓⊔
Reﬂection In Theorem 25.29, why is it not sufﬁcient to postulate continuity of the
map t →⟨M⟩t instead of absolute continuity? Find a counterexample! ♠
We come next to a multidimensional version of the pathwise Itô formula. To
this end, let Cd
qv be the space of continuous maps X : [0, ∞) →Rd, t →
Xt = (X1
t , . . . , Xd
t ) such that, for k, l = 1, . . ., d, the quadratic covariation
(see Deﬁnition 21.58) ⟨Xk, Xl⟩exists and is continuous. Further, let C2(Rd) be
the space of twice continuously differentiable functions F on Rd with partial
derivatives ∂kF and ∂k∂lF, k, l = 1, . . . , d. Denote by ∇the gradient and by
△= (∂2
1 + . . . + ∂2
d) the Laplace operator.
Theorem 25.30 (Multidimensional pathwise Itô formula) Let X ∈Cd
qv and
F ∈C2(Rd). Then
F(XT ) −F(X0) =
 T
0
∇F(Xs) dXs + 1
2
d

k,l=1
 T
0
∂k∂lF(Xs) d⟨Xk, Xl⟩s,
where
 T
0
∇F(Xs) dXs := lim
n→∞

t∈Pn
T
d

k=1
∂kF(Xt)(Xk
t′ −Xk
t ).
Proof This works just as in the one-dimensional case. We leave the details as an
exercise.
⊓⊔
Remark 25.31 If each of the integrals
3 T
0 ∂kF(Xs) dXk
s exists, then
 T
0
∇F(Xs) dXs =
d

k=1
 T
0
∂kF(Xs) dXk
s .
Note that existence of the individual integrals does not follow from the existence of
the integral 3 T
0 ∇F(Xs) dXs.♦
Corollary 25.32 (Product rule) If X, Y, X −Y, X + Y ∈Cqv, then
XT YT = X0Y0 +
 T
0
Ys dXs +
 T
0
Xs dYs + ⟨X, Y⟩T
for all T ≥0
if both integrals exist. In particular, the product rule holds if X and Y are
continuous local martingales.

25.3
The Itô Formula
655
Proof By assumption (and using the polarization formula), the covariation ⟨X, Y⟩
exists. Applying Theorem 25.30 with F(x, y) = xy, the claim follows.
For continuous local martingales, by Exercise 25.2.1, there exists a suitable
sequence of partitions P such that the integrals exist (pathwise).
⊓⊔
Now let Y = M + A be a d-dimensional generalized diffusion. Hence
Mk
t =
d

l=1
 t
0
σ k,l
s
dW l
s
and
Ak
t =
 t
0
bk
s ds
for t ≥0, k = 1, . . . , d.
Here W
=
(W 1, . . . , W d) is a d-dimensional Brownian motion and σ k,l
(respectively bk) are progressively measurable, locally square integrable (respec-
tively locally integrable) stochastic processes for every k, l = 1, . . . , d. Since
⟨W k, W l⟩t = t · 1{k=l}, we have ⟨Y k, Y l⟩t = ⟨Mk, Ml⟩t =
3 t
0 ak,l
s
ds, where
ak,l
s
:=
d

i=1
σ k,i
s
σ l,i
s
is the covariance matrix of the diffusion M. In particular, we have M ∈Cd
qv
almost surely. Note that (by Exercise 25.2.1), there exists a partition sequence P
such that the integrals
3 t
0 σ k,l
s
∂kF(Ys) dW l
s in (25.17) exist in the pathwise sense.
As a corollary of the multidimensional pathwise Itô formula (Theorem 25.30 and
Remark 25.31), we thus get the following theorem.
Theorem 25.33 (Multidimensional Itô formula) Let Y be as above and let F ∈
C2(Rd). Then
F(YT ) −F(Y0) =
 T
0
∇F(Ys) dYs + 1
2
d

k,l=1
 T
0
∂k∂lF(Ys) d⟨Mk, Ml⟩s
=
d

k,l=1
 T
0
σ k,l
s
∂kF(Ys) dW l
s +
d

k=1
 T
0
bk
s ∂kF(Ys) ds
+ 1
2
d

k,l=1
 T
0
ak,l
s
∂k∂lF(Ys) ds.
(25.17)
In particular, for Brownian motion, we have
F(Wt) −F(W0) =
d

k=1
 t
0
∂kF(Ws) dW k
s + 1
2
 t
0
△F(Ws) ds.
(25.18)

656
25
The Itô Integral
Corollary 25.34 The process (F(Wt))t≥0 is a continuous local martingale if and
only if F is harmonic (that is, △F ≡0).
Proof If F is harmonic, then as a sum of Itô integrals, F(Wt) = F(W0) +
d
k=1
3 t
0 ∂kF(Ws) dW k
s is a continuous local martingale.
On the other hand, if (F(Wt))t≥0 is a continuous local martingale, then as a
difference of continuous local martingales,
3 t
0 △F(Ws) ds is also a continuous local
martingale. As t →
3 t
0 △F(Ws) ds has ﬁnite variation, we have
3 t
0 △F(Ws) ds =
0 for all t ≥0 almost surely (by Corollary 21.72). Hence △F ≡0.
⊓⊔
Corollary 25.35 (Time-dependent Itô formula) If F ∈C2,1(Rd × R), then
F(WT , T ) −F(W0, 0)
=
d

k=1
 T
0
∂kF(Ws, s) dW k
s +
 T
0

∂d+1 + 1
2(∂2
1 + . . . + ∂2
d)

F(Ws, s) ds.
Proof Apply Theorem 25.33 to Y = (W 1
t , . . . , W d
t , t)t≥0.
⊓⊔
Takeaways The Itô formula is the probabilistic analogue to the substitution
rule for Riemann integrals. Any continuous local martingale with absolutely
continuous variance process can be represented as an Itô integral with respect
to some Brownian motion. In particular, it is a diffusion. Compare with the
representation theorem in discrete time that we derived in Theorem 9.43.
Exercise 25.3.1 (Fubini’s theorem for Itô integrals) Let X ∈Cqv and assume
that g : [0, ∞)2 →R is continuous and (in the interior) twice continuously
differentiable in the second coordinate with derivative ∂2g. Use the product rule
(Corollary 25.32) to show that
 s
0
 t
0
g(u, v) du

dXv =
 t
0
 s
0
g(u, v) dXv

du
and
 s
0
 v
0
g(u, v) du

dXv =
 s
0
 s
u
g(u, v) dXv

du.
♣
Exercise 25.3.2 (Stratonovich integral) Let P be an admissible sequence of
partitions, X ∈CP
qv and F ∈C2(R) with derivative f = F ′. Show that, for every

25.4
Dirichlet Problem and Brownian Motion
657
t ≥0, the Stratonovich integral
 T
0
f (Xt) ◦dXt := lim
n→∞

t∈Pn
T
f
Xt′ + Xt
2
 Xt′ −Xt

is well-deﬁned, and that the classical substitution rule
F(XT ) −F(X0) =
 T
0
F ′(Xt) ◦dXt
holds. Show that, in contrast with the Itô integral, the Stratonovich integral with
respect to a continuous local martingale is, in general, not a local martingale. ♣
25.4
Dirichlet Problem and Brownian Motion
As for discrete Markov chains (compare Sect. 19.1), the solutions of the Dirichlet
problem in a domain G ⊂Rd can be expressed in terms of a d-dimensional
Brownian motion that is stopped upon hitting the boundary G.
In the following, let G ⊂Rd be a bounded open set.
Deﬁnition 25.36 (Dirichlet problem) Let f : ∂G →R be continuous. A function
u : G →R is called a solution of the Dirichlet problem on G with boundary value
f if u is continuous, twice differentiable in G and
△u(x) = 0
for x ∈G,
u(x) = f (x)
for x ∈∂G.
(25.19)
For sufﬁciently smooth domains, there always exists a solution of the Dirichlet
problem (see, e.g., [79, Section 4.4]). If there is a solution, then as a consequence of
Theorem 25.38, it is unique.
In the following, let W = (W 1, . . . , W d) be a d-dimensional Brownian motion
with respect to a ﬁltration F that satisﬁes the usual conditions. We write Px and Ex
for probabilities and expectations if W is started at W0 = x = (x1, . . . , xd) ∈Rd.
If A ⊂Rd is open, then
τAc := inf
	
t > 0 : Wt ∈Ac
is an F-stopping time (see Exercise 21.4.4). Since G is bounded, we have G ⊂
(−a, a) × Rd−1 for some a > 0. Thus τGc ≤τ((−a,a)×Rd−1)c. By Exercise 21.2.4
(applied to W 1), for x ∈G,
Ex
)
τGc*
≤Ex
)
τ((−a,a)×Rd−1)c
*
= (a −x1)(a + x1) < ∞.
(25.20)

658
25
The Itô Integral
In particular, τGc < ∞Px-almost surely. Hence WτGc is a Px-almost surely well-
deﬁned random variable with values in ∂G.
Deﬁnition 25.37 For x ∈G, denote by
μx,G = Px ◦W −1
τGc
the harmonic measure on ∂G.
Theorem 25.38 If u is a solution of the Dirichlet problem on G with boundary
value f , then
u(x) = Ex
)
f (WτGc )
*
=

∂G
f (y) μx,G(dy)
for x ∈G.
(25.21)
In particular, the solution of the Dirichlet problem is always unique.
Proof Let G1 ⊂G2 ⊂. . . be a sequence of open sets with x ∈G1, Gn ↑G and
Gn ⊂G for every n ∈N. Hence, in particular, every Gn is compact and thus ∇u
is bounded on Gn. We abbreviate τ := τGc and τn := τGcn.
As u is harmonic (that is, △u = 0), by the Itô formula, for t < τ,
u(Wt) = u(W0) +
 t
0
∇u(Ws) dWs = u(W0) +
d

k=1
 t
0
∂ku(Ws) dW k
s .
(25.22)
In particular, M := (u(Wt))t∈[0,τ) is a local martingale up to τ (however, in
general, it is not a martingale). For t < τn, we have
(∂ku(Ws))2 ≤Cn := sup
y∈Gn
∥∇u(y)∥2
2 < ∞
for all k = 1, . . . , d.
Hence, by (25.20),
E
+  τn
0
(∂ku(Ws))2 ds
,
≤Cn Ex[τn] ≤Cn E[τ] < ∞.
Thus, by Theorem 25.17(ii), for every n ∈N, the stopped process Mτn is a
martingale. Therefore,
Ex[u(Wτn)] = Ex[Mτn] = Ex[M0] = u(x).
(25.23)
As W is continuous and τn ↑τ, we have Wτn
n→∞
−→
Wτ ∈∂G. Since u is
continuous, we get
u(Wτn)
n→∞
−→u(Wτ ) = f (Wτ ).
(25.24)

25.5
Recurrence and Transience of Brownian Motion
659
Again, since u is continuous and G is compact, u is bounded. By the dominated
convergence theorem, (25.24) implies convergence of the expectations; that is (also
using (25.23)),
u(x) = lim
n→∞Ex
)
u(Wτn)
*
= Ex
)
f (Wτ )
*
.
⊓⊔
Reﬂection A Dirichlet problem need not have a solution. Find an example based
on the punctured disc G := {(x, y) ∈R2 : x2 + y2 ∈(0, 1)} that does not have a
solution. ♠
Takeaways If the solution of a Dirichlet problem exists, then it is the
expected value of the boundary value at the random point where Brownian
motion ﬁrst leaves the domain. As similar statement for discrete Markov
chains was shown in equation (19.1).
Exercise 25.4.1 Let G = R × (0, ∞) be the open upper half plane of R2 and
x = (x1, x2) ∈G. Show that τGc < ∞almost surely and that the harmonic
measure μx,G on R ∼= ∂G is the Cauchy distribution with scale parameter x2 that
is shifted by x1: μx,G = δx1 ∗Caux2. ♣
Exercise 25.4.2 Let d ≥3 and let G = Rd−1 × (0, ∞) be an open half space of
Rd. Let x = (x1, . . . , xd) ∈G. Show that τGc < ∞almost surely and that the
harmonic measure μx,G on Rd−1 ∼= ∂G has the density
μx,G(dy)
dy
= Γ (d/2)
πd/2
xd
S
(x1 −y1)2 + . . . + (xd−1 −yd−1)2 + x2
d
.
♣
Exercise 25.4.3 Let r > 0 and let Br(0) ⊂Rd be the open ball with radius r
centered at the origin. For x ∈Br(0), determine the harmonic measure μx,Br(0). ♣
25.5
Recurrence and Transience of Brownian Motion
By Pólya’s theorem (Theorem 17.40), symmetric simple random walk (Xn)n∈N on
Zd is recurrent (that is, it visits every point inﬁnitely often) if and only if d ≤2. If
d > 2, then the random walk is transient and eventually leaves every bounded set
A ⊂Zd. To give a slightly different (though equivalent) formulation of this,
lim inf
n→∞∥Xn∥= 0 a.s.
⇐⇒
d ≤2

660
25
The Itô Integral
and
lim
n→∞∥Xn∥= ∞a.s.
⇐⇒
d > 2.
The main result of this section is that a similar dichotomy also holds for Brownian
motion.
Theorem 25.39 Let
W
=
(W 1, . . . , W d)
be a
d-dimensional Brownian
motion.
(i) If d ≤2, then W is recurrent in the sense that
lim inf
t→∞∥Wt −y∥= 0 a.s.
for every y ∈Rd.
In particular, almost surely the path {Wt : t ≥0} is dense in Rd.
(ii) If d > 2, then W is transient in the sense that
lim
t→∞∥Wt∥= ∞a.s.,
and for any y ∈Rd \ {0}, we have inf{∥Wt −y∥: t ≥0} > 0 almost surely.
The basic idea of the proof is to use a suitable Dirichlet problem (and the result of
Sect. 25.4) to compute the probabilities for W to hit certain balls,
BR(x) :=
	
y ∈Rd : ∥x −y∥< R

.
Let 0 < r < R < ∞and let Gr,R be the annulus
Gr,R := BR(0) \ Br(0) =
	
x ∈Rd : r < ∥x∥< R

.
Recall that, for closed A ⊂Rd, we write τA = inf{t > 0 : Wt ∈A} for the
stopping time of ﬁrst entrance into A. We further write
τs := inf
	
t > 0 : ∥Wt∥= s

and
τr,R = inf
	
t > 0 : Wt ̸∈Gr,R

.
If we start W at W0 ∈Gr,R, then clearly τr,R = τr ∧τR. On the boundary of Gr,R,
deﬁne the function f by
f (x) =

1,
if ∥x∥= r,
0,
if ∥x∥= R.
(25.25)
Deﬁne ur,R : Gr,R →R by
ur,R(x) = V (∥x∥) −V (R)
V (r) −V (R) ,

25.5
Recurrence and Transience of Brownian Motion
661
where V : (0, ∞) →R is Newton’s potential function
V (s) = Vd(s) =
⎧
⎪⎪⎨
⎪⎪⎩
s,
if d = 1,
log(s),
if d = 2,
−s2−d,
if d > 2.
(25.26)
It is easy to check that ϕ : Rd \ {0} →R, x →Vd(∥x∥) is harmonic (that
is, △ϕ ≡0). Hence ur,R is the solution of the Dirichlet problem on Gr,R with
boundary value f . By Theorem 25.38, for x ∈Gr,R,
Px
)τr,R = τr
* = Px
)∥Wτr,R∥= r* = Ex
)f (Wτr,R)* = ur,R(x).
(25.27)
Theorem 25.40 For r > 0 and x, y ∈Rd with ∥x −y∥> r, we have
Px
)Wt ∈Br(y) for some t > 0* =
⎧
⎨
⎩
1,
if d ≤2,

∥x−y∥
r
2−d
,
if d > 2.
Proof Without loss of generality, assume y = 0. Then
Px[τr < ∞] =
lim
R→∞Px[τr,R = τr] =
lim
R→∞
V (∥x∥) −V (R)
V (r) −V (R)
=
⎧
⎨
⎩
1,
if d ≤2,
Vd(∥x∥)
Vd(r) ,
if d > 2,
since limR→∞Vd(R) = ∞if d ≤2 and = 0 if d > 2.
⊓⊔
Proof (of Theorem 25.39) Using the strong Markov property of Brownian motion,
we get for r > 0
Px
'
lim inf
t→∞∥Wt∥< r
(
= Px
+ 
s∈(0,r)

R>∥x∥
	
∥Wt∥≤s for some t > τR

,
=
sup
s∈(0,r)
inf
R>∥x∥Px
)
∥Wt∥≤s for some t > τR
*
=
sup
s∈(0,r)
inf
R>∥x∥Px
)
PWτR [τs < ∞]
*
.

662
25
The Itô Integral
However, by Theorem 25.40 (since ∥WτR∥= R for R > ∥x∥), we have
PWτR [τs < ∞] =

1,
if d ≤2,
(s/R)d−2,
if d > 2.
Therefore,
P
'
lim inf
t→∞∥Wt∥< r
(
=

1,
if d ≤2,
0,
if d > 2.
This implies the claim.
⊓⊔
Deﬁnition 25.41 (Polar set) A set A ⊂Rd is called polar if
Px
)
Wt ̸∈A for all t > 0
*
= 1
for all x ∈Rd.
Theorem 25.42 If d = 1, then only the empty set is polar. If d ≥2, then {y} is
polar for every y ∈Rd.
Proof For d = 1, the statement is obvious since
lim sup
t→∞
Wt = ∞
and
lim inf
t→∞Wt = −∞
a.s.
Hence, due to the continuity of W, every point y ∈R will be hit (inﬁnitely often).
Now let d ≥2. Without loss of generality, assume y = 0. If x ̸= 0, then
Px
)
τ{0} < ∞
*
=
lim
R→∞Px
)
τ{0} < τR
*
=
lim
R→∞inf
r>0 Px
)
τr,R = τr
*
=
lim
R→∞inf
r>0 ur,R(x) = 0
(25.28)
since Vd(r)
r→0
−→−∞if d ≥2.
On the other hand, if x = 0, then the strong Markov property of Brownian
motion (and the fact that P0[Wt = 0] = 0 for all t > 0) implies
P0
)
τ{0} < ∞
*
= sup
t>0
P0
)
Ws = 0 for some s ≥t
*
= sup
t>0
P0
)
PWt [τ{0} < ∞]
*
= 0.
Note that in the last step, we used (25.28).
⊓⊔

25.5
Recurrence and Transience of Brownian Motion
663
Takeaways Using the well known analytic solution of a speciﬁc Dirich-
let problem (the Newton potential), we compute the probability for d-
dimensional Brownian motion to ever hit a certain ball depending on d, the
size and the distance of the ball. We conclude that Brownian motion misses
single points if d ≥2 and is transient if d > 2.

Chapter 26
Stochastic Differential Equations
Stochastic differential equations describe the time evolution of certain continuous
Markov processes with values in Rn. In contrast with classical differential equations,
in addition to the derivative of the function, there is a term that describes the
random ﬂuctuations that are coded as an Itô integral with respect to a Brownian
motion. Depending on how seriously we take the concrete Brownian motion as
the driving force of the noise, we speak of strong and weak solutions. In the ﬁrst
section, we develop the theory of strong solutions under Lipschitz conditions for
the coefﬁcients. In the second section, we develop the so-called (local) martingale
problem as a method of establishing weak solutions. In the third section, we
present some examples in which the method of duality can be used to prove weak
uniqueness.
As stochastic differential equations are a very broad subject, and since things
quickly become very technical, we only excursively touch some of the most
important results, partly without proofs, and illustrate them with examples.
26.1
Strong Solutions
Consider a stochastic differential equation (SDE) of the type
X0 = ξ,
dXt = σ(t, Xt) dWt + b(t, Xt) dt.
(26.1)
Here W = (W 1, . . . , W m) is an m-dimensional Brownian motion, ξ is an Rn-
valued random variable with distribution μ that is independent of W, σ(t, x) =

σij (t, x)

i=1,...,n
j=1,...,m is a real n × m matrix and b(t, x) =

bi(t, x)

i=1,...,n is an n-
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_26
665

666
26
Stochastic Differential Equations
dimensional vector. Assume the maps (t, x) →σij (t, x) and (t, x) →bi(t, x) are
measurable.
By a solution of (26.1) we understand a continuous adapted stochastic process X
with values in Rn that satisﬁes the integral equation
Xt = ξ +
 t
0
σ(s, Xs) dWs +
 t
0
b(s, Xs) ds
P-a.s. for all t ≥0.
(26.2)
Written in full, this is
Xi
t = ξi +
m

j=1
 t
0
σij (s, Xs) dW j
s +
 t
0
bi(s, Xs) ds
for all i = 1, . . ., n.
Now the following problem arises: To which ﬁltration F do we wish X to be
adapted? Should it be the ﬁltration that is generated by ξ and W, or do we allow F
to be larger? Already for ordinary differential equations, depending on the equation,
uniqueness of the solution may fail (although existence is usually not a problem);
for example, for f ′ = |f |1/3. If F is larger than the ﬁltration generated by W, then
we can deﬁne further random variables that select one out of a variety of possible
solutions. We thus have more possibilities for solutions than if F = σ(W). Indeed, it
will turn out that in some situations for the existence of a solution, it is necessary to
allow a larger ﬁltration. Roughly speaking, X is a strong solution of (26.1) if (26.2)
holds and if X is adapted to F = σ(W). On the other hand, X is a weak solution
if X is adapted to a larger ﬁltration F with respect to which W is still a martingale.
Weak solutions will be dealt with in Sect. 26.2.
Deﬁnition 26.1 (Strong solution) We say that the stochastic differential equa-
tion (SDE) (26.1) has a strong solution X if there exists a map F
: Rn ×
C([0, ∞); Rm) →C([0, ∞); Rn) with the following properties:
(i) For every t ≥0, the map (x, w) →F(x, w) is measurable with respect to
B(Rn) ⊗Gm
t
– Gn
t , where (for k = m or k = n) Gk
t := σ(πs : s ∈[0, t])
is the σ-algebra generated by the coordinate maps πs : C([0, ∞); Rk) →R,
w →w(s), 0 ≤s ≤t.
(ii) The process X = F(ξ, W) satisﬁes (26.2).
Condition (i) says that the path (Xs)s∈[0,t] depends only on ξ and (Ws)s∈[0,t] but not
on further information. In particular, X is adapted to Ft = σ(ξ, Ws : s ∈[0, t])
and is progressively measurable; hence the Itô integral in (26.2) is well-deﬁned if σ
and b do not grow too quickly for large x.
Remark 26.2 Clearly, a strong solution of an SDE is a generalized n-dimensional
diffusion. If the coefﬁcients σ and b are independent of t, then the solution is an
n-dimensional diffusion. ♦
Remark 26.3 Let X be a strong solution and let F be as in Deﬁnition 26.1. If W ′ is
an m-dimensional Brownian motion on a space (Ω′, F′, P′) with ﬁltration F′, and

26.1
Strong Solutions
667
if ξ′ is independent of W ′ and is F′
0-measurable, then X′ = F(ξ′, W ′) satisﬁes the
integral equation (26.2). Hence, it is a strong solution of (26.1) with W replaced by
W ′. Thus the existence of a strong solution does not depend on the actual realization
of the Brownian motion or on the ﬁltration F. ♦
Deﬁnition 26.4 We say that the SDE (26.1) has a unique strong solution if there
exists an F as in Deﬁnition 26.1 such that:
(i) If W is an m-dimensional Brownian motion on some probability space
(Ω, F, P) with ﬁltration F and if ξ is an F0-measurable random variable
that is independent of W and such that P ◦ξ−1 = μ, then X := F(ξ, W) is a
solution of (26.2).
(ii) For every solution (X, W) of (26.2), we have X = F(ξ, W).
Example 26.5 Let m = n = 1, b ∈R and σ > 0. The Ornstein–Uhlenbeck
process
Xt := ebtξ + σ
 t
0
e(t−s)b dWs,
t ≥0,
(26.3)
is a strong solution of the SDE X0 = ξ and
dXt = σ dWt + b Xt dt.
In the language of Deﬁnition 26.1, we have (in the sense of the pathwise Itô integral
with respect to w)
F(x, w) =

t →ebtx +
 t
0
e(t−s)b dw(s)

for all w ∈Cqv (that is, with continuous square variation). Since P[W ∈Cqv] = 1,
we can deﬁne F(x, w) = 0 for w ∈C([0, ∞); R) \ Cqv.
Indeed, by Fubini’s theorem for Itô integrals, we have (Exercise 25.3.1)
ξ +
 t
0
σ dWs +
 t
0
b Xs ds
= ξ + σWt +
 t
0
b ebsξ ds +
 t
0
σ b
 s
0
eb(s−r) dWr

ds
= ξ + σWt + ebt −1ξ +
 t
0
σ
 t
r
b eb(s−r) ds

dWr
= ebtξ +
 t
0

σ +

eb(t−r) −1

σ

dWr
= Xt.

668
26
Stochastic Differential Equations
It can be shown (see Theorem 26.8) that the solution is also (strongly) unique. ♦
Example 26.6 Let α, β ∈R. The one-dimensional SDE X0 = ξ and
dXt = α Xt dWt + β Xt dt
(26.4)
has the strong solution
Xt = ξ exp

α Wt +

β −α2
2

t

.
In the language of Deﬁnition 26.1, we have σ(t, x) = αx, b(t, x) = βx and
F(x, w) =

t →x exp

α w(t) +

β −α2
2

t

for all w ∈C([0, ∞); R) and x ∈R. Indeed, by the time-dependent Itô formula
(Corollary 25.35),
Xt = ξ +
 t
0
αXs dWs +
 t
0

β −α2
2

+ 1
2α2

Xs ds.
Also in this case, we have strong uniqueness of the solution (see Theorem 26.8).
The process X is called a geometric Brownian motion and, for example, serves in
the so-called Black–Scholes model as the process of stock prices. ♦
We give a simple criterion for existence and uniqueness of strong solutions. For an
n × m matrix A, deﬁne the Hilbert–Schmidt norm
∥A∥=
S
trace

A AT 
=




n

i=1
m

j=1
A2
i,j .
(26.5)
For b ∈Rn, we use the Euclidean norm ∥b∥. Since all norms on ﬁnite-dimensional
vector spaces are equivalent, it is not important exactly which norm we use.
However, the Hilbert–Schmidt norm simpliﬁes the computations, as the following
lemma shows.
Lemma 26.7 Let t →H(t) = (Hij(t))i=1,...,n, j=1,...,m be progressively measur-
able and E
) 3 T
0 H 2
ij(t) dt
*
< ∞for all i, j. Then
E
+;;;;
 T
0
H(t) dWt
;;;;
2,
= E
+  T
0
∥H(t)∥2 dt
,
,
(26.6)
where ∥H∥is the Hilbert–Schmidt norm from (26.5).

26.1
Strong Solutions
669
Proof For i = 1, . . . , n, the process Ii(t) := m
j=1
3 t
0 Hij(s) dW j
s is a continuous
martingale with square variation process ⟨Ii⟩t =
3 t
0
m
j=1 H 2
ij(s) ds. Hence
E)(Ii(T ))2* = E
+  T
0
m

j=1
H 2
ij(s) ds
,
.
The left-hand side in (26.6) equals
n

i=1
E
)
(Ii(T ))2*
= E
+  T
0
n

i=1
m

j=1
H 2
ij(s) ds
,
.
Hence the claim follows by the deﬁnition of ∥H(s)∥2.
⊓⊔
Theorem 26.8 Let b and σ be Lipschitz continuous in the second coordinate. That
is, we assume that there exists a K > 0 such that, for all x, x′ ∈Rn and t ≥0,
∥σ(t, x) −σ(t, x′)∥+ ∥b(t, x) −b(t, x′)∥≤K ∥x −x′∥.
(26.7)
Further, assume the growth condition
∥σ(t, x)∥2 + ∥b(t, x)∥2 ≤K2 (1 + ∥x∥2)
for all x ∈Rn, t ≥0.
(26.8)
Then, for every initial point X0 = x ∈Rn, there exists a unique strong solution X
of the SDE (26.1). This solution is a Markov process and in the case where σ and b
do not depend on t, it is a strong Markov process.
As the main tool, we need the following lemma.
Lemma 26.9 (Gronwall) Let f, g : [0, T ] →R be integrable and let C > 0
such that
f (t) ≤g(t) + C
 t
0
f (s) ds
for all t ∈[0, T ].
(26.9)
Then
f (t) ≤g(t) + C
 t
0
eC(t−s)g(s) ds
for all t ∈[0, T ].
In particular, if g(t) ≡G is constant, then f (t) ≤GeCt for all t ∈[0, T ].
Proof Let F(t) =
3 t
0 f (s) ds and h(t) = F(t) e−Ct. Then, by (26.9),
d
dt h(t) = f (t) e−Ct −CF(t) e−Ct ≤g(t) e−Ct.

670
26
Stochastic Differential Equations
Integration yields
F(t) = eCt h(t) ≤
 t
0
eC(t−s) g(s) ds.
Substituting this into (26.9) gives
f (t) ≤g(t) + CF(t) ≤g(t) + C
 t
0
g(s) eC(t−s) ds.
⊓⊔
Proof (of Theorem 26.8) It is enough to show that, for every T < ∞, there exists
a unique strong solution up to time T .
Uniqueness We ﬁrst show uniqueness of the solution. Let X and X′ be two
solutions of (26.2). Then
Xt −X′
t =
 t
0

b(s, Xs) −b(s, X′
s)

ds +
 t
0

σ(s, Xs) −σ(s, X′
s)

dWs.
Hence
∥Xt −X′
t∥2 ≤2
;;;;
 t
0
b(s, Xs) −b(s, X′
s) ds
;;;;
2
+ 2
;;;;
 t
0
σ(s, Xs) −σ(s, X′
s) dWs
;;;;
2
.
(26.10)
For the ﬁrst summand in (26.10), use the Cauchy–Schwarz inequality, and for the
second one use Lemma 26.7 to obtain
E
)
∥Xt −X′
t∥2*
≤2t
 t
0
E
';;b(s, Xs) −b(s, X′
s)
;;2(
ds
+ 2
 t
0
E
';;σ(s, Xs) −σ(s, X′
s)
;;2(
ds.
Write f (t) = E
)
∥Xt −X′
t∥2*
and C := 2(T + 1)K2. Then f (t) ≤C
3 t
0 f (s) ds.
Hence Gronwall’s lemma (with g ≡0) yields f ≡0.
Existence We use a version of the Picard iteration scheme. For N
∈
N0,
recursively deﬁne processes XN by X0
t ≡x and
XN
t
:= x +
 t
0
bs, XN−1
s
 ds +
 t
0
σs, XN−1
s
 dWs
for N ∈N.
(26.11)

26.1
Strong Solutions
671
Using the growth condition (26.8), it can be shown inductively that
 T
0
E
';;XN
t
;;2(
dt ≤2(T + 1) K2

T +
 T
0
E
';;XN−1
t
;;2(
dt

≤2T (T + 1) K2N1 + ∥x∥2 < ∞,
N ∈N.
Hence, at each step, the Itô integral is well-deﬁned.
Consider now the differences
XN+1
t
−XN
t = It + Jt,
where
It :=
 t
0

σ(s, XN
s ) −σ(s, XN−1
s
)

dWs
and
Jt :=
 t
0

b(s, XN
s ) −b(s, XN−1
s
)

ds.
By applying Doob’s L2-inequality to the nonnegative submartingale (∥It∥2)t≥0,
using Lemma 26.7 and (26.7), we obtain
E
+
sup
s≤t
∥Is∥2
,
≤4 E
)
∥It∥2*
= 4 E
+ t
0
;;σ(s, XN
s ) −σ(s, XN−1
s
)
;;2 ds
,
≤4K2
 t
0
E
';;XN
s −XN−1
s
;;2(
ds.
(26.12)
For Jt, by the Cauchy–Schwarz inequality, we get
∥Jt∥2 ≤t
 t
0
;;b(s, XN
s ) −b(s, XN−1
s
)
;;2 ds.
Hence
E
+
sup
s≤t
∥Js∥2
,
≤t E
+ t
0
;;b(s, XN
s ) −b(s, XN−1
s
)
;;2 ds
,
≤tK2
 t
0
E
';;XN
s −XN−1
s
;;2(
ds.
(26.13)

672
26
Stochastic Differential Equations
Deﬁning
ΔN(t) := E
+
sup
s≤t
;;XN
s −XN−1
s
;;2
,
,
and C := 2K2(4 + T ) ∨2(T + 1)K2(1 + ∥x∥2), we obtain (using the growth
condition (26.8))
ΔN+1(t) ≤C
 t
0
ΔN(s) ds
for N ≥1
and
Δ1(t) ≤2t
 t
0
∥b(s, x)∥2 ds + 2
 t
0
∥σ(s, x)∥2 ds
≤2(T + 1)K2
1 + ∥x∥2
· t ≤C t.
Inductively, we get ΔN(t) ≤(Ct)N
N! . Thus, by Markov’s inequality,
∞

N=1
P
+
sup
s≤t
;;XN
s −XN−1
s
;;2 > 2−N
,
≤
∞

N=1
2NΔN(t)
≤
∞

N=1
(2Ct)N
N!
≤e2Ct < ∞.
Using the Borel–Cantelli lemma, we infer sup
s≤t
∥XN
s −XN−1
s
∥2 N→∞
−→0 a.s. Hence
a.s. (XN)N∈N is a Cauchy sequence in the Banach space (C([0, T ]), ∥· ∥∞).
Therefore, XN converges a.s. uniformly to some X. As uniform convergence
implies convergence of the integrals, X is a strong solution of (26.2).
Markov property The strong Markov property follows from the strong Markov
property of the Brownian motion that drives the SDE.
⊓⊔
We have already seen some important examples of this theorem. Many interesting
problems, however, lead to stochastic differential equations with coefﬁcients that
are not Lipschitz continuous. In the one-dimensional case, using special comparison
methods, one can show that it is sufﬁcient that σ is Hölder-continuous of order 1
2 in
the space variable.
Theorem 26.10 (Yamada–Watanabe) Consider the one-dimensional situation
where m = n = 1. Assume that there exist K < ∞and α ∈)1
2, 1* such that, for all

26.1
Strong Solutions
673
t ≥0 and x, x′ ∈R, we have
b(t, x) −b(t, x′)
 ≤K |x −x′|
and
σ(t, x) −σ(t, x′)
 ≤K |x −x′|α.
Then, for every X0 ∈R, the SDE (26.1) has a unique strong solution X and X is a
strong Markov process.
Proof See [173] or [85, Proposition 5.2.13] and [49, Theorem 5.3.11] for existence
and uniqueness. The strong Markov property follows from Theorem 26.26.
⊓⊔
Example 26.11 Consider the one-dimensional SDE
dXt =
S
γ X+
t dWt + a

b −X+
t

dt
(26.14)
with initial point X0 = x ≥0, where γ > 0 and a, b ≥0 are parameters. The
conditions of Theorem 26.10 are fulﬁlled with α = 1
2 and K = √γ + a. Obviously,
the unique strong solution X remains nonnegative if X0 ≥0. (In fact, it can be
shown that Xt > 0 for all t > 0 if 2ab/γ ≥1, and that Xt hits zero arbitrarily
often with probability 1 if 2ab/γ < 1. See, e.g., [78, Example IV.8.2, page 237].
Compare Example 26.16. See Figs. 26.1 and 26.2 for computer simulations.)
Depending on the context, this process is sometimes called Feller’s branching
diffusion with immigration or the Cox–Ingersoll–Ross model for the time
evolution of interest rates.
0
0.5
1
1.5
5
10
15
20
25
30
Fig. 26.1 Cox–Ingersoll–Ross diffusion with parameters γ = 1, b = 1 and a = 0.3. The path hits
zero again and again since 2ab/γ = 0.6 < 1.

674
26
Stochastic Differential Equations
0
0.5
1
1.5
2
2.5
5
10
15
20
25
30
Fig. 26.2 Cox–Ingersoll–Ross diffusion with parameters γ = 1, b = 1 and a = 2. The path never
hits zero since 2ab/γ = 4 ≥1.
For the case a = b = 0, use the Itô formula to compute that
e−λXt −e−λx −γ λ2
2
 t
0
e−λXsXs ds = λ
 t
0
e−λXs2
γ Xs dWs
is a martingale. Take expectations for the Laplace transform ϕ(t, λ, x) = Ex[e−λXt]
to get the differential equation
d
dt ϕ(t, λ, x) = γ λ2
2 E
)
Xt e−λXt*
= −γ λ2
2
d
dλϕ(t, λ, x).
With initial value ϕ(0, λ, x) = e−λx, the unique solution is
ϕ(t, λ, x) = exp

−
λ
(γ/2)λt + 1 x

.
However (for γ
= 2), this is exactly the Laplace transform of the transition
probabilities of the Markov process that we deﬁned in Theorem 21.48 and that in
Lindvall’s theorem (Theorem 21.51) we encountered as the limit of rescaled Galton–
Watson branching processes. ♦

26.2
Weak Solutions and the Martingale Problem
675
Takeaways A stochastic differential equation is a standard way of describing
a continuous stochastic process. If the coefﬁcients are Lipschitz continuous,
to (almost) every path of the Brownian motion we can assign uniquely a
path of the solution of the differential equation. This is the so-called strong
solution. For a one-dimensional stochastic differential equation, we can relax
the Lipschitz condition on the diffusion coefﬁcient: it is enough that the
diffusion coefﬁcient be Hölder- 1
2-continuous.
Exercise 26.1.1 Let a, b ∈R. Show that the stochastic differential equation
dXt = b −Xt
1 −t dt + dWt
with initial value X0 = a has a unique strong solution for t ∈[0, 1) and that
X1 := limt↑1 X1 = b almost surely. Furthermore, show that the process Y = (Xt −
a −t(b −a))t∈[0,1] can be described by the Itô integral
Yt = (1 −t)
 t
0
(1 −s)−1 dWs,
t ∈[0, 1),
and is hence a Brownian bridge (compare Exercise 21.5.3). ♣
26.2
Weak Solutions and the Martingale Problem
In the last section, we studied strong solutions of the stochastic differential equation
dXt = σ(t, Xt) dWt + b(t, Xt) dt.
(26.15)
A strong solution is a solution where any path of the Brownian motion W gets
mapped onto a path of the solution X. In this section, we will study the notion of
a weak solution where additional information (or additional noise) can be used to
construct the solution.
Deﬁnition 26.12 (Weak solution of an SDE) A weak solution of (26.15) with
initial distribution μ ∈M1(Rn) is a triple
L =

(X, W), (Ω, F, P), F

,
where
•
(Ω, F, P) is a probability space,
•
F = (Ft)t≥0 is a ﬁltration on (Ω, F, P) that satisﬁes the usual conditions,

676
26
Stochastic Differential Equations
•
W is a Brownian motion on (Ω, F, P) and is a martingale with respect to F,
•
X is continuous and adapted (hence progressively measurable),
•
P ◦(X0)−1 = μ, and
•
(X, W) satisﬁes
Xt = X0 +
 t
0
σ(s, Xs) dWs +
 t
0
b(s, Xs) ds
P-a.s.
(26.16)
A weak solution L is called (weakly) unique if, for any further solution L′ with initial
distribution μ, we have P′ ◦(X′)−1 = P ◦X−1.
Remark 26.13 Clearly, a weak solution of an SDE is a generalized n-dimensional
diffusion. If the coefﬁcients σ and b do not depend on t, then the solution is an
n-dimensional diffusion. ♦
Remark 26.14 Clearly, every strong solution of (26.15) is a weak solution. The
converse is false, as the following example shows. ♦
Example 26.15 Consider the SDE (with initial value X0 = 0)
dXt = sign(Xt) dWt,
(26.17)
where sign = 1[0,∞) −1(−∞,0) is the sign function. Then
Xt = X0 +
 t
0
sign(Xs) dWs
for all t ≥0
(26.18)
if and only if
Wt =
 t
0
dWs =
 t
0
sign(Xs) dXs
for all t ≥0.
(26.19)
A weak solution of (26.17) is obtained as follows. Let X be a Brownian motion on
a probability space (Ω, F, P) and F = σ(X). If we deﬁne W by (26.19), then W is
a continuous F-martingale with square variation
⟨W⟩t =
 t
0
(sign(Xs))2 ds = t.
Thus, by Lévy’s characterization (Theorem 25.28), W is a Brownian motion. Hence
((X, W), (Ω, F, P), F) is a weak solution of (26.17).
In order to show that a strong solution does not exist, take any weak solution and
show that X is not adapted to σ(W). Since, by (26.18), X is a continuous martingale
with square variation ⟨X⟩t = t, X is a Brownian motion.

26.2
Weak Solutions and the Martingale Problem
677
Let Fn ∈C2(R) be a convex even function with derivatives F ′
n and F ′′
n such that
sup
x∈R
Fn(x) −|x|
 n→∞
−→0,
|F ′
n(x)| ≤1 for all x ∈R and F ′
n(x) = sign(x) for |x| > 1
n. In particular, we
have
 t
0

F ′
n(Xs) −sign(Xs)
2 ds
n→∞
−→0
a.s.
and thus
 t
0
F ′
n(Xs) dXs
n→∞
−→
 t
0
sign(Xs) dXs
in L2.
(26.20)
By passing to a subsequence, if necessary, we may assume that almost sure
convergence holds in (26.20).
Since F ′′
n is even, we have
Wt =
 t
0
sign(Xs) dXs = lim
n→∞
 t
0
F ′
n(Xs) dXs
= lim
n→∞

Fn(Xt) −Fn(0) −1
2
 t
0
F ′′
n (Xs) ds

= |Xt| −lim
n→∞
1
2
 t
0
F ′′
n (|Xs|) ds.
As the right-hand side depends only on |Xs|, s ∈[0, t], W is adapted to G :=
(σ(|Xs| : s ∈[0, t])). Hence σ(W) ⊂G ⫋σ(X), and thus X is not adapted to
σ(W). ♦
Example 26.16 Let B = (B1, . . . , Bn) be an n-dimensional Brownian motion
started at y ∈Rn. Let x := ∥y∥2, Xt := ∥Bt∥2 = (B1
t )2 + . . . + (Bn
t )2 and
Wt :=
n

i=1
 t
0
1
√Xs
Bi
s dBi
s.
Then W is a continuous local martingale with ⟨W⟩t = t for every t ≥0 and
Xt = x + nt +
 t
0
2
Xs dWs.
That is, (X, W) is a weak solution of the SDE dXt = √2Xt dWt +n dt. X is called
an n-dimensional Bessel process. By Theorem 25.42, B (and thus X) hits the origin

678
26
Stochastic Differential Equations
for some t > 0 if and only if n = 1. Clearly, we can deﬁne X also for noninteger
n ≥0. One can show that X hits zero if and only if n ≤1. Compare Example 26.11.
♦
For the connection between existence and uniqueness of weak solutions and strong
solutions, we only quote here the theorem of Yamada and Watanabe.
Deﬁnition 26.17 (Pathwise uniqueness) A solution of the SDE (26.15) with initial
distribution μ is said to be pathwise unique if, for every μ ∈M1(Rn) and for any
two weak solutions (X, W) and (X′, W) on the same space (Ω, F, P) with the same
ﬁltration F, we have P[Xt = X′
t for all t ≥0] = 1.
Theorem 26.18 (Yamada and Watanabe) The following are equivalent.
(i) The SDE (26.15) has a unique strong solution.
(ii) For any μ ∈M1(Rn), (26.15) has a weak solution, and pathwise uniqueness
holds.
If (i) and (ii) hold, then the solution is weakly unique.
Proof See [173], [148, pages 151ff] or [78, pages 163ff].
⊓⊔
Example 26.19 Let X be a weak solution of (26.17). Then −X is also a weak
solution; that is, pathwise uniqueness does not hold (although it can be shown that
the solution is weakly unique; see Theorem 26.25). ♦
Consider the one-dimensional case m = n = 1. If X is a solution (strong or weak)
of (26.15), then
Mt := Xt −
 t
0
b(s, Xs) ds
is a continuous local martingale with square variation
⟨M⟩t =
 t
0
σ 2(s, Xs) ds.
We will see that this characterizes a weak solution of (26.15) (under some mild
growth conditions on σ and b).
Now assume that, for all t ≥0 and x ∈Rn, the n×n matrix a(t, x) is symmetric
and nonnegative deﬁnite, and let (t, x) →a(t, x) be measurable.
Deﬁnition 26.20 An n-dimensional continuous process X is called a solution of the
local martingale problem for a and b with initial condition μ ∈M1(Rn) (brieﬂy,
LMP(a, b, μ)) if P ◦X−1
0
= μ and if, for every i = 1, . . ., n,
Mi
t := Xi
t −
 t
0
bi(s, Xs) ds,
t ≥0,

26.2
Weak Solutions and the Martingale Problem
679
is a continuous local martingale with quadratic covariation
⟨Mi, Mj⟩t =
 t
0
aij(s, Xs) ds
for all t ≥0, i, j = 1, . . . , n.
We say that the solution of LMP(a, b, μ) is unique if, for any two solutions X and
X′, we have P ◦X−1 = P ◦(X′)−1.
Denote by σ T the transposed matrix of σ. Clearly, a = σσ T is a nonnegative
semideﬁnite symmetric n × n matrix.
Theorem 26.21 X is a solution of LMP(σσ T , b, μ) if and only if (on a suitable
extension of the probability space) there exists a Brownian motion W such that
(X, W) is a weak solution of (26.15).
In particular, there exists a unique weak solution of the SDE (26.15) with initial
distribution μ if LMP(σσ T , b, μ) is uniquely solvable.
Proof We show the statement only for the case m = n = 1. The general case needs
some consideration on the roots of nonnegative semideﬁnite symmetric matrices,
which, however, do not yield any further insight into the stochastics of the problem.
For this we refer to [85, Proposition 5.4.6].
“ ⇐”
If (X, W) is a weak solution, then, by Corollary 25.19, X solves the local
martingale problem.
“ ⇒”
Let X be a solution of LMP(σ 2, b, μ). By Theorem 25.29, on an extension
of the probability space there exists a Brownian motion
˜W such that Mt
=
3 t
0
σ(s, Xs)
 d ˜Ws. If we deﬁne
Wt :=
 t
0
sign(σ(s, Xs)) d ˜Ws,
then Mt =
3 t
0 σ(s, Xs) dWs and hence (X, W) is a weak solution of (26.15).
⊓⊔
In some sense, a local martingale problem is a very natural way of writing a
stochastic differential equation; that is:
X locally has derivative (drift) b and additionally has random normally distributed
ﬂuctuations of size σ.
Here, a concrete Brownian motion does not appear. In fact, in most problems its
occurrence is rather artiﬁcial. Just as Markov chains are described by their transition
probabilities and not by a concrete realization of the random transitions (as in
Theorem 17.17), many continuous (space and time) processes are most naturally
described by the drift and the size of the ﬂuctuations but not by the concrete
realization of the random ﬂuctuations.
From a technical point of view, the formulation of a stochastic differential equa-
tion as a local martingale problem is very convenient since it makes SDEs accessible
to techniques such as martingale inequalities and approximation theorems that can

680
26
Stochastic Differential Equations
be used to establish existence and uniqueness of solutions. Here we simply quote
two important results.
Theorem 26.22 (Existence of solutions) Let (t, x) →b(t, x) and (t, x) →
a(t, x) be continuous and bounded. Then, for every μ ∈M1(Rn), there exists a
solution X of the LMP(a, b, μ).
Proof See [148, Theorem V.23.5].
⊓⊔
Deﬁnition 26.23 The LMP(a, b) is said to be well-posed if, for every x ∈Rn, there
exists a unique solution X of LMP(a, b, δx).
Remark 26.24 If σ and b satisfy the Lipschitz conditions of Theorem 26.8, then the
LMP(σσ T , b) is well-posed. This follows by Theorems 26.8, 26.18 and 26.21. ♦
In the following, we assume
(t, x) →σ(t, x) resp. (t, x) →a(t, x) is bounded on compact sets.
(26.21)
This condition ensures the equivalence of the local martingale problems to the
somewhat more common martingale problem (see [85, Proposition 5.4.11]).
Theorem 26.25 (Uniqueness in the martingale problem) Assume (26.21) and
that, for any x ∈Rn, there exists a solution Xx of LMP(a, b, δx). The distribution
of Xx will be denoted by Px := P ◦(Xx)−1.
Assume that, for any two solutions Xx and Y x of LMP(a, b, δx), we have
P ◦(Xx
T )−1 = P ◦(Y x
T )−1
for any T ≥0.
(26.22)
Then LMP(a, b) is well-posed, and the canonical process X is a strong Markov
process with respect to (Px, x ∈Rn). If a = σσ T , then under Px, the process X is
the unique weak solution of the SDE (26.15).
Proof See [49, Theorem 4.4.2 and Problem 49] and [85, Proposition 5.4.11].
⊓⊔
A fundamental strength of this theorem is that we do not need to check the
uniqueness of the whole process but only have to check in (26.22) the one-
dimensional marginal distributions. We will use this in Sect. 26.3 in some examples.
The existence of solutions of a stochastic differential equation (or equivalently of
a local martingale problem) is often easier to show than the uniqueness of solutions.
We know already that Lipschitz conditions for the coefﬁcients b and σ (not σσ T !)
ensure uniqueness (Theorems 26.8 and 26.18), as here strong uniqueness of the
solution holds.
At ﬁrst glance, it might seem confusing that random ﬂuctuations have a stabil-
ising effect on the solution. That is, there are deterministic differential equations
whose solution is unique only after adding random noise terms. For example,
consider the following equation:
dXt = sign(Xt) |Xt|1/3 dt + σ dWt,
X0 = 0.
(26.23)

26.2
Weak Solutions and the Martingale Problem
681
If σ = 0, then the deterministic differential equation has a continuum of solutions
that can be parameterized by v ∈{−1, +1} and T ≥0, namely Xt = v 2
√
2 (t −
T )3/2 1{t>T }. If σ > 0, then the noise eliminates the instability of (26.23) at
x = 0. We quote the following theorem for the time-independent case from [148,
Theorem V.24.1] (see also [162, Chapter 10]).
Theorem 26.26 (Stroock–Varadhan) Let aij : Rn →R be continuous and let
bi : Rn →R be measurable for i, j = 1, . . . , n. Assume
(i) a(x) = (aij(x)) is symmetric and strictly positive deﬁnite for every x ∈Rn,
(ii) there exists a C < ∞such that, for all x ∈Rn and i, j = 1, . . ., n, we have
aij(x)
 ≤C 1 + ∥x∥2
and
bi(x)
 ≤C 1 + ∥x∥.
Then the LMP(a, b) is well-posed and the SDE (26.15) has a unique strong
solution that is a strong Markov process. The solution X has the Feller property: For
every t > 0 and every bounded measurable f : Rn →R, the map x →Ex[f (Xt)]
is continuous.
We will present explicit examples in Sect. 26.3. Here we just remark that we have
developed a particular method in order to construct Markov processes, namely as
the solution of a stochastic differential equation or of a local martingale problem.
In the framework of models in discrete time, in Sect. 17.2 and especially in
Exercise 17.2.1, we characterized certain Markov chains as solutions of martingale
problems. In order for drift and square variation to be sufﬁcient for uniqueness of
the Markov chain described by the martingale problem, it was essential that, for any
step of the chain, we only allowed three possibilities. Here, however, the decisive
restriction is the continuity of the processes.
Takeaways For a weak solution of a stochastic differential equation, the
Brownian motion does not exist a priori. Rather it will be constructed together
with the paths of the solution. Hence, for weak solutions the focus lies
on quantitative properties such as strength of noise and drift. The explicit
dependence of the solution path on a speciﬁc Brownian motion path is
typically of no interest in this situation. Weak solutions can be constructed via
martingale problems under rather weak assumptions. However, uniqueness of
weak solutions is often an issue and requires tailor-made methods.
Exercise 26.2.1 Consider the time-homogeneous one-dimensional case (m = n =
1). Let σ and b be such that, for every X0 ∈R, there exists a unique weak solution
of
dXt = σ(Xt) dWt + b(Xt) dt

682
26
Stochastic Differential Equations
that is a strong Markov process. Further, assume that there exists an x0 ∈R with
C :=
 ∞
−∞
1
σ 2(x) exp
 x
x0
2b(r)
σ 2(r) dr

dr < ∞.
(i) Show that the measure π ∈M1(R) with density
π(dx)
dx
= C−1
1
σ 2(x) exp
 x
x0
2b(r)
σ 2(r) dr

is an invariant distribution for X.
(ii) For which values of b does the Ornstein–Uhlenbeck process dXt = σ dWt +
bXt dt have an invariant distribution? Determine this distribution and compare
the result with what could be expected by an explicit computation using the
representation in (26.3).
(iii) Compute the invariant distribution of the Cox–Ingersoll–Ross SDE (26.14)
(i.e., Feller’s branching diffusion).
(iv) Let γ, c > 0 and θ ∈(0, 1). Show that the invariant distribution of the solution
X of the SDE on [0, 1],
dXt =
2
γ Xt(1 −Xt) dWt + c(θ −Xt) dt
is the Beta distribution β2cγ/θ, 2cγ/(1−θ). ♣
Exercise 26.2.2 Let γ > 0. Let X1 and X2 be solutions of dXi
t =
S
γ Xi
t dW i
t ,
where W 1 and W 2 are two independent Brownian motions with initial values X1
0 =
x1
0 > 0 and X2
0 = x2
0 > 0. Show that Z := X1 + X2 is a weak solution of Z0 = 0
and dZt = √γ Zt dWt. ♣
26.3
Weak Uniqueness via Duality
The Stroock–Varadhan theorem provides a strong criterion for existence and
uniqueness of solutions of stochastic differential equations. However, in many cases,
the condition of locally uniform ellipticity of a (Condition (i) in Theorem 26.26) is
not fulﬁlled. This is the case, in particular, if the solutions are deﬁned only on subsets
of Rn.
Here we will study a powerful tool that in many special cases can yield weak
uniqueness of solutions.
Deﬁnition 26.27 (Duality) Let X = (Xx, x ∈E) and Y = (Y y, y ∈E′) be
families of stochastic processes with values in the spaces E and E′, respectively,
and such that Xx
0 = x a.s. and Y y
0 = y a.s. for all x ∈E and y ∈E′. We say that
X and Y are dual to each other with duality function H : E × E′ →C if, for all

26.3
Weak Uniqueness via Duality
683
x ∈E, y ∈E′ and t ≥0, the expectations E
)
H(Xx
t , y)
*
and E
)
H(x, Y y
t )
*
exist
and are equal:
E
)
H(Xx
t , y)
*
= E
)
H(x, Y y
t )
*
.
In the following, we assume that σij : Rn →R and bi : Rn →R are bounded on
compact sets for all i = 1, . . ., n, j = 1, . . . , m. Consider the time-homogeneous
stochastic differential equation
dXt = σ(Xt) dWt + b(Xt) dt.
(26.24)
Theorem 26.28 (Uniqueness via duality) Assume that, for every x ∈Rn, there
exists a solution of the local martingale problem for (σσ T , b, δx). Further, assume
that there exists a family (Y y, y ∈E′) of Markov processes with values in the
measurable space (E′, E′) and a measurable map H : Rn × E′ →C such that, for
every y ∈E′, x ∈Rn and t ≥0, the expectation E[H(x, Y y
t )] exists and is ﬁnite.
Further, let (H( ·, y), y ∈E′) be a separating class of functions for M1(Rn) (see
Deﬁnition 13.9).
For every x ∈Rn and every solution Xx of LMP(σσ T , b, δx), assume that the
duality equation holds:
E[H(Xx
t , y)] = E[H(x, Y y
t )]
for all y ∈E′, t ≥0.
(26.25)
Then the local martingale problem of (σσ T , b) is well-posed and hence (26.24) has
a unique weak solution that is a strong Markov process.
Proof By Theorem 26.25, it is enough to check that, for every x ∈Rn, every
solution Xx of LMP(σσ T , b, δx) and every t ≥0, the distribution P ◦(Xx
t )−1 is
unique. Since (H( ·, y), y ∈E′) is a separating class of functions, this follows
from (26.16).
⊓⊔
Example 26.29 (Wright–Fisher diffusion) Consider the Wright–Fisher SDE
dXt = 1[0,1](Xt)
2
γ Xt(1 −Xt) dWt,
(26.26)
where γ
>
0 is a parameter. See Fig. 26.3 for a computer simulation. By
Theorem 26.22, for every x ∈R, there exists a weak solution ( ˜X, W) of (26.26). ˜X
is a continuous local martingale with square variation
B ˜X
C
t =
 t
0
γ ˜Xs(1 −˜Xs)1[0,1]( ˜Xs) ds.

684
26
Stochastic Differential Equations
0
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
1.2
Fig. 26.3 Simulation of a Wright–Fisher diffusion with parameter γ = 1.
Let τ := inf{t > 0 :
˜Xt ̸∈[0, 1]} and let X := ˜Xτ be the process stopped at τ.
Then X is a continuous bounded martingale with
⟨X⟩t =
 t
0
γ Xs(1 −Xs)1[0,1](Xs) ds.
Hence, (X, W) is a solution of (26.26). By construction, Xt ∈[0, 1] for all t ≥0 if
X0 = ˜X0 ∈[0, 1].
Let τ ′ := inf{t > 0 :
˜Xt ∈[0, 1]}. If ˜X0 ̸∈[0, 1], then τ ′ > 0 since ˜X is
continuous. Since ˜Xτ ′ is a continuous local martingale with
B ˜Xτ ′C
≡0, we have
˜Xτ ′
t
= ˜X0 for all t ≥0. However, this implies ˜Xt = ˜X0 for all t < τ ′. Again, by
continuity of ˜X, we get τ ′ = ∞and ˜Xt = ˜X0 for all t ≥0.
Hence, it is enough to show uniqueness of the solution for ˜X0 = x ∈[0, 1]. To this
end, let Y = (Yt)t≥0 be the Markov process on N with Q-matrix
q(m, n) =
⎧
⎪⎨
⎪⎩
γ
m
2

,
if n = m −1,
−γ
m
2

,
if n = m,
0,
else.
We show duality of X and Y with respect to H(x, n) = xn:
Ex
)Xn
t
* = En
)xNt *
for all t ≥0, x ∈[0, 1], n ∈N.
(26.27)
Deﬁne mx,n(t) = Ex
)
Xn
t
*
and gx,n(t) = En
)
xNt*
. By the Itô formula,
Xn
t −xn −
 t
0
γ
n
2

Xn−1
s
(1 −Xs) ds =
 t
0
nXn−1
s
2
γ Xs(1 −Xs) dWs
is a martingale.

26.3
Weak Uniqueness via Duality
685
Taking expectations, we obtain the following recursive equations for the
moments of X:
mx,1(t) = x,
mx,n(t) = xn + γ
n
2
  t
0
mx,n−1(s) −mx,n(s) ds
for n ≥2.
(26.28)
Clearly, this system of linear differential equations can be uniquely solved recur-
sively in n.
Due to the Markov property of Y, for h > 0 and t ≥0, we have
gx,n(t + h) = En
)
xYt+h*
= En
)
EYh
)
xYt**
=
n

m=1
Pn[Yh = m] Em
)
xYt*
=
n

m=1
Pn[Yh = m] gx,m(t).
This implies
d
dt gx,n(t) = lim
h↓0 h−1 '
gx,n(t + h) −gx,n(t)
(
= lim
h↓0 h−1
n

m=1
Pn[Yh = m]

gx,m(t) −gx,n(t)

=
n

m=1
q(n, m) gx,m(t)
= γ
n
2

gx,n−1(t) −gx,n(t)

.
(26.29)
Evidently, gx,1(t) = x for all x ∈[0, 1] and t ≥0 and gx,n(0) = xn. That is, gx,n
solves (26.28), and thus (26.27) holds.
By Theorem 15.4, the family (H( ·, n), n ∈N) ⊂C([0, 1]) is separating for
M1([0, 1]); hence the conditions of Theorem 26.28 are fulﬁlled. Therefore, X is
the unique weak solution of (26.26) and is a strong Markov process. ♦
Remark 26.30 The martingale problem for the Wright–Fisher diffusion is almost
identical to the martingale problem for the Moran model (see Example 17.22)
MN = (MN
n )n∈N0 with population size N: MN is a martingale with values in the

686
26
Stochastic Differential Equations
set {0, 1/N, . . . , (N −1)/N, 1} and with square variation process
BMNC
n = 2
N2
n−1

k=0
MN
k
1 −MN
k
.
At each step, MN can either stay put or increase or decrease by 1/N. In Exer-
cise 17.2.1, we saw that this determines the process MN uniquely. Similarly as
in Theorem 21.51 for branching processes, it can be shown that the time-rescaled
Moran processes
˜MN
t
= MN
⌊N2t⌋converge to the Wright–Fisher diffusion with
γ
= 2. The Wright–Fisher diffusion thus occurs as the limiting model of a
genealogical model and describes the gene frequency (that is, the fraction) of a
certain allele in a population that ﬂuctuates randomly due to resampling. ♦
Example 26.31 (Feller’s branching diffusion) Let (ZN
n )n∈N0 be a Galton–Watson
branching process with critical geometric offspring distribution pk = 2−k−1, k ∈N0
and ZN
0 = N for any N ∈N. Then ZN is a discrete martingale and we have
E
'
ZN
n −ZN
n−1
2 ZN
n−1
(
= ZN
n−1
 ∞

k=0
pk k2 −1

= 2 ZN
n−1.
Hence ZN has square variation
⟨ZN⟩n =
n−1

k=0
2ZN
k .
Deﬁne the linearly interpolated version
ZN
t
:=

t −N−1⌊tN⌋
 
ZN
⌊tN⌋+1 −ZN
⌊tN⌋

+ 1
nZN
⌊tN⌋
of N−1ZN
⌊tN⌋. By Lindvall’s theorem (Theorem 21.51), there is a continuous Markov
process Z such that ZN
N→∞
−→
Z in distribution. See Fig. 26.4 for a computer
simulation of Z. Since it can be shown that the moments also converge, we have
that Z is a continuous martingale with square variation
⟨Z⟩t =
 t
0
2Zs ds.
In fact, in Example 26.11, we have already shown that Z is the unique solution of
the SDE
dZt =
2
2Zt dWt
(26.30)

26.3
Weak Uniqueness via Duality
687
0
1
2
3
1
2
3
4
5
Fig. 26.4 Simulation of Feller’s branching diffusion with parameter γ = 1.
with initial value Z0 = 1. There we also showed that Z is dual to Y y
t =

tγ
2 + 1
y
−1
with H(x, y) = e−xy. This implies uniqueness of the solution of (26.30) and the
strong Markov property of Z. ♦
It could be objected that in Examples 26.29 and 26.31, we considered only one-
dimensional problems for which the Yamada–Watanabe theorem (Theorem 26.10)
yields uniqueness (indeed of a strong solution) anyway. The full strength of the
method of duality is displayed only in higher-dimensionalproblems. As an example,
we consider an extension of Example 26.29.
Example 26.32 (Interacting Wright–Fisher diffusions)
The Wright–Fisher diffu-
sion from Example 26.29 describes the ﬂuctuations of the gene frequency of an
allele in one large population. Now we consider more populations, which live at
the points i ∈S := {1, . . ., N} and interact with each other by a migration that
is quantiﬁed by migration rates r(i, j) ≥0. As a model for the gene frequencies
Xt(i) at site i at time t we use the following N-dimensional SDE for X =
(X(1), . . ., X(N)):
dXt(i) =
2
γ Xt(i)(1 −Xt(i)) dW i
t +
N

j=1
r(i, j)

Xt(j) −Xt(i)

dt.
(26.31)
Here W
= (W 1, . . . , W N) is an N-dimensional Brownian motion. By Theo-
rem 26.22, this SDE has weak solutions; however, none of our general criteria for
weak uniqueness apply. We will thus show weak uniqueness by virtue of duality.

688
26
Stochastic Differential Equations
As in Example 26.29, it is not hard to show that solutions of (26.31), started at
X0 = x ∈E := [0, 1]S, remain in [0, 1]S. The diagonal terms r(i, i) do not appear
in (26.31). We use our freedom and deﬁne these terms as r(i, i) = −
j̸=i r(i, j).
Let Y = (Yt)t≥0 be the Markov process on E′ := (N0)S with the following Q-
matrix:
q(ϕ, η) =
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
ϕ(i) r(i, j),
if η = ϕ −1{i} + 1{j} for
some i, j ∈S, i ̸= j,
γ
ϕ(i)
2

,
if η = ϕ −1{i} for some i ∈S,

i∈S

ϕ(i)r(i, i) −γ
ϕ(i)
2

,
if η = ϕ,
0,
else.
Here ϕ ∈E′ denotes a generic state with ϕ(i) particles at site i ∈S, and 1{i} ∈
E′ denotes the state with exactly one particle at site i. The process Y describes a
system of particles that independently with rate r(i, j) jump from site i to site j.
If there is more than one particle at the same site i, then any of the ϕ(i)
2
 pairs of
particles coalesce with the same rate γ to one particle. The common genealogical
interpretation of this process is that (in reversed time) it describes the lines of descent
of samples of Y0(i) individuals at each site i ∈S. By migration, the lines change
sites. If two individuals have the same common ancestor, then their lines coalesce.
Clearly, for two particles to have the same ancestor at a given time, it is necessary
but not sufﬁcient for them to be at the same site.
For x ∈Rn and ϕ ∈E′, we denote xϕ := 
i∈S x(i)ϕ(i). We show that X and Y
are dual to each other with the duality function H(x, ϕ) = xϕ:
Ex[Xϕ
t ] = Eϕ[xYt]
for all ϕ ∈SN0, x ∈[0, 1]S, t ≥0.
(26.32)
Let mx,ϕ(t) := Ex[Xϕ
t ] and gx,ϕ(t) := Eϕ[xYt]. Clearly, H has the derivatives
∂iH( ·, ϕ)(x) = ϕ(i)xϕ−1{i} and ∂i∂iH( ·, ϕ)(x) = 2
ϕ(i)
2

xϕ−2 1{i}.
By the Itô formula,
Xϕ
t −Xϕ
0 −
 t
0

i,j∈S
ϕ(i)r(i, j)

Xs(j) −Xs(i)

Xϕ−1{i}
t
ds
−

i∈S
 t
0
γ
ϕ(i)
2
Xs(i)(1 −Xs(i))Xϕ−2 1{i}
s
ds

26.3
Weak Uniqueness via Duality
689
is a martingale. Taking expectations, we get a system of linear integral equations
mx,0(t) = 1,
mx,ϕ(t) = xϕ +
 t
0

i,j∈S
ϕ(i)r(i, j)

mx,ϕ+1{j}−1{i}(s) −mx,ϕ(s)

ds
+
 t
0
γ

i∈S
ϕ(i)
2

mx,ϕ−1{i}(s) −mx,ϕ(s)

ds.
(26.33)
This system of equations can be solved uniquely by induction on n = 
i∈I ϕ(i).
However, we do not intend to compute this solution explicitly. We show only that it
coincides with gx,ϕ(t) by showing that g solves an equivalent system of differential
equations.
For g as in (26.29), we obtain
d
dt gx,ϕ(t) =

η∈E′
q(ϕ, η) gx,ϕ(t)
=

i,j∈S
r(i, j)

gx,ϕ+1{j}−1{i}(t) −gx,ϕ(t)

+

i∈S
γ
ϕ(i)
2

gx,ϕ−1{i}(t) −gx,ϕ(t)

.
(26.34)
Together with the initial values gx,0(t) = 1 and gx,ϕ(0) = xϕ, the system (26.34)
of differential equations is equivalent to (26.33). Hence the duality (26.32) holds,
and thus the SDE (26.31) has a unique weak solution. (In fact, it can be shown that
there exists a unique strong solution, even if S is countably inﬁnite, as long as r then
satisﬁes certain regularity conditions such as if it is the Q-matrix of a random walk
on S = Zd; see [154].) ♦
Takeaways One tool to establish uniqueness of a weak solution of a stochas-
tic differential equation is a duality of the solution to a second process
(either deterministic or random). For Feller’s branching diffusion, we have
a deterministic dual. Interacting Wright-Fisher diffusions are dual to a system
of (delayed) coalescing random walks. In many cases the dual process can
be used to compute quantitative properties such as extinction probabilities,
ﬁxation probabilities and so on.

690
26
Stochastic Differential Equations
Exercise 26.3.1 (Extinction probability of Feller’s branching diffusion) Let
γ > 0 and let Z be the solution of dZt := √γ Zt dWt with initial value Z0 = z > 0.
Use the duality to show
Pz[Zt = 0] = exp

−2z
γ t

.
(26.35)
Use Lemma 21.44 to compute the probability that a Galton–Watson branching
process X with critical geometric offspring distribution and with X0 = N ∈N
is extinct by time n ∈N. Compare the result with (26.35). ♣

References
1. R.J. Adler, An Introduction to Continuity, Extrema, and Related Topics for General Gaussian
Processes. Institute of Mathematical Statistics Lecture Notes-Monograph Series, vol. 12
(Institute of Mathematical Statistics, Hayward, CA, 1990)
2. M. Aizenman, H. Kesten, C.M. Newman, Uniqueness of the inﬁnite cluster and continuity of
connectivity functions for short and long range percolation. Commun. Math. Phys. 111(4),
505–531 (1987)
3. M. Aizenman, H. Kesten, C.M. Newman, Uniqueness of the inﬁnite cluster and related
results in percolation, in Percolation theory and ergodic theory of inﬁnite particle systems
(Minneapolis, Minn., 1984–1985). IMA Volumes in Mathematics and Its Applications, vol. 8
(Springer, New York, 1987), pp. 13–20
4. D.J. Aldous, Exchangeability and related topics, in École d’été de probabilités de Saint-Flour,
XIII—1983. Lecture Notes in Mathematics, vol. 1117 (Springer, Berlin, 1985), pp. 1–198
5. K.B. Athreya, P.E. Ney, Branching Processes (Springer, Berlin, 1972)
6. J. Azéma, M. Yor, Le problème de Skorokhod: compléments à “Une solution simple au
problème de Skorokhod”, in Séminaire de Probabilités, XIII (Univ. Strasbourg, Strasbourg,
1977/78). Lecture Notes in Mathematics, vol. 721 (Springer, Berlin, 1979), pp. 625–633
7. J. Azéma, M. Yor, Une solution simple au problème de Skorokhod, in Séminaire de
Probabilités, XIII (Univ. Strasbourg, Strasbourg, 1977/78). Lecture Notes in Mathematics,
vol. 721 (Springer, Berlin, 1979), pp. 90–115
8. L.E. Baum, M. Katz, Convergence rates in the law of large numbers. Trans. Am. Math. Soc.
120, 108–123 (1965)
9. M. Baxter, R. Rennie, Financial Calculus (Cambridge University Press, Cambridge, 1997)
10. A.C. Berry, The accuracy of the Gaussian approximation to the sum of independent variates.
Trans. Am. Math. Soc. 49, 122–136 (1941)
11. A. Beutelspacher, Kryptologie (Vieweg + Teubner, Wiesbaden, 9th edn, 2009)
12. P. Billingsley, Convergence of Probability Measures (Wiley, New York, 1968)
13. P. Billingsley, Weak Convergence of Measures: Applications in Probability. Conference Board
of the Mathematical Sciences Regional Conference Series in Applied Mathematics, No. 5
(Society for Industrial and Applied Mathematics, Philadelphia, PA, 1971)
14. P. Billingsley, Convergence of Probability Measures, 2nd edn. Wiley Series in Probability
and Statistics: Probability and Statistics (Wiley, New York, 1999). A Wiley-Interscience
Publication
15. K. Binder, D.W. Heermann, Monte Carlo Simulation in Statistical Physics: An Introduction,
3rd edn. Springer Series in Solid-State Sciences, vol. 80 (Springer, Berlin, 1997)
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
691

692
References
16. G.D. Birkhoff, Proof of the ergodic theorem. Proc. Nat. Acad. Sci. 17, 656–660 (1931)
17. D. Blackwell, D, Kendall, The Martin boundary of Pólya’s urn scheme, and an application to
stochastic population growth. J. Appl. Probab. 1, 284–296 (1964)
18. R.M. Blumenthal, An extended Markov property. Trans. Amer. Math. Soc. 85, 52–72 (1957)
19. S. Bochner, Vorlesungen über Fouriersche Integrale. (Chelsea Publishing Company, New
York, 1932) Reprinted 1948
20. L. Breiman, Probability (Addison-Wesley Publishing Company, Reading, MA, 1968)
21. P. Brémaud, Markov Chains. Texts in Applied Mathematics, vol. 31. Gibbs ﬁelds, Monte
Carlo simulation, and queues (Springer, New York, 1999)
22. D. Brüggemann. Starke Gesetze der großen Zahlen bei blockweisen Unabhängigkeits-
bedingungen. PhD thesis, Universität zu Köln, 2002
23. R.M. Burton, M. Keane, Density and uniqueness in percolation. Commun. Math. Phys.
121(3), 501–505 (1989)
24. G. Choquet, J. Deny, Sur l’équation de convolution μ = μ ∗σ. C. R. Acad. Sci. Paris 250,
799–801 (1960)
25. Y.S. Chow, H. Teicher, Probability Theory: Independence, Interchangeability, Martingales,
3rd edn. Springer Texts in Statistics (Springer, New York, 1997)
26. K.L. Chung, Markov Chains with Stationary Transition Probabilities. Die Grundlehren der
mathematischen Wissenschaften, Bd. 104 (Springer, Berlin, 1960)
27. K.L. Chung, W.H.J. Fuchs, On the distribution of values of sums of random variables. Mem.
Am. Math. Soc. 6, 1–12 (1951)
28. P. Clifford, A. Sudbury, A model for spatial conﬂict. Biometrika 60, 581–588 (1973)
29. H. Cramér, Sur un nouveau théorème-limite de la théorie des probabilités. Actualités
Scientiﬁques et Industrielles 763, 5–23 (1938). Colloque consacré à la théorie des probabilités
30. F. Delbaen, W. Schachermayer, A general version of the fundamental theorem of asset pricing.
Math. Ann. 300(3), 463–520 (1994)
31. A. Dembo, O. Zeitouni, Large Deviations Techniques and Applications. Stochastic Modelling
and Applied Probability, vol. 38 (Springer, Berlin, 2010). Korrigierter Nachdruck der zweiten
Auﬂage von 1998
32. J.-D. Deuschel, D.W. Stroock, Large Deviations. Pure and Applied Mathematics, vol. 137
(Academic, Boston, MA, 1989)
33. P. Diaconis, D. Freedman, Finite exchangeable sequences. Ann. Probab. 8(4), 745–764 (1980)
34. J. Dieudonné, Foundations of Modern Analysis. Pure and Applied Mathematics, vol. X
(Academic, New York/London, 1960)
35. M.D. Donsker, An invariance principle for certain probability limit theorems. Mem. Am.
Math. Soc. 6, 1–12 (1951)
36. P.G. Doyle, J.L. Snell, Random Walks and Electric Networks. Carus Mathematical Mono-
graphs, vol. 22 (Mathematical Association of America, Washington, DC, 1984)
37. R.M. Dudley, Real Analysis and Probability. Cambridge Studies in Advanced Mathematics,
vol. 74 (Cambridge University Press, Cambridge, 2002). Revised reprint of the 1989 original
38. N. Dunford, J.T. Schwartz, Linear Operators. I. General Theory. With the assistance of W. G.
Bade and R. G. Bartle. Pure and Applied Mathematics, vol. 7 (Interscience Publishers, Inc.,
New York, 1958)
39. R. Durrett, Probability: Theory and Examples, 4th edn. Cambridge Series in Statistical and
Probabilistic Mathematics. (Cambridge University Press, Cambridge 2010)
40. A. Dvoretzky, P. Erd˝os, S. Kakutani, Nonincrease everywhere of the Brownian motion
process, in Proceedings of the 4th Berkeley Symposium on Mathematics, Statistics and
Probability, vol. II (University of California Press, Berkeley, CA, 1961), pp. 103–116
41. D. Egoroff, Sur les suites des fonctions measurables. C. R. Acad. Sci. Paris 152, 135–157
(1911)
42. R.J. Elliott, P.E. Kopp, Mathematics of Financial Markets, 2nd edn. Springer Finance
(Springer, New York, 2005)
43. R.S. Ellis, Entropy, Large Deviations, and Statistical Mechanics. Grundlehren der Mathema-
tischen Wissenschaften, vol. 271 (Springer, New York, 1985)

References
693
44. J. Elstrodt, Maß- und Integrationstheorie, 8th edn. (Springer, New York, 2018)
45. P. Erd˝os, R.L. Graham, On a linear diophantine problem of Frobenius. Acta Arith. 21, 399–
408 (1972)
46. C.-G. Esseen, On the Liapounoff limit of error in the theory of probability. Ark. Mat. Astr.
Fys. 28A(9), 1–19 (1942)
47. N. Etemadi, An elementary proof of the strong law of large numbers. Z. Wahrsch. Verw.
Gebiete 55(1), 119–122 (1981)
48. A. Etheridge, A Course in Financial Calculus (Cambridge University Press, Cambridge,
2002)
49. S.N. Ethier, T.G. Kurtz, Markov Processes: Characterization and Convergence. Wiley Series
in Probability and Mathematical Statistics: Probability and Mathematical Statistics (Wiley,
New York, 1986)
50. S.N. Evans, X. Zhou, Identiﬁability of exchangeable sequences with identically distributed
partial sums. Electron. Comm. Probab. 4, 9–13 (electronic) (1999)
51. W. Feller, Über den zentralen Grenzwertsatz der Wahrscheinlichkeitstheorie I. Math. Zeit. 40,
521–559 (1935)
52. W. Feller, Über den zentralen Grenzwertsatz der Wahrscheinlichkeitstheorie II. Math. Zeit.
42, 301–312 (1937)
53. W. Feller, An Introduction to Probability Theory and its Applications, vol. I, 3rd edn. (Wiley,
New York, 1968)
54. W. Feller, An Introduction to Probability Theory and its Applications, vol. II, 2nd edn. (Wiley,
New York, 1971)
55. J.A. Fill, An interruptible algorithm for perfect sampling via Markov chains. Ann. Appl.
Probab. 8(1), 131–162 (1998)
56. J.A. Fill, M. Machida, D.J. Murdoch, J.S. Rosenthal, Extension of Fill’s perfect rejection
sampling algorithm to general chains. Random Struct. Algoritm. 17(3–4), 290–316 (2000).
Proceedings of the Ninth International Conference “Random Structures and Algorithms”
(Poznan, 1999)
57. H. Föllmer, A. Schied, Stochastic Finance. de Gruyter Studies in Mathematics, vol. 27, 2nd
edn. (Walter de Gruyter & Co., Berlin, 2004)
58. D.A. Freedman, Bernard Friedman’s urn. Ann. Math. Statist 36, 956–970 (1965)
59. H.-O. Georgii, Stochastics: Introduction to Probability Theory and Statistics. de Gruyter
Lehrbuch, 2nd edn. (Walter de Gruyter & Co., Berlin, 2012)
60. A.L. Gibbs, F.E. Su, On choosing and bounding probability metrics. Int. Stat. Rev. 70(3),
419–435 (2002)
61. M.L. Glasser, I.J. Zucker, Extended Watson integrals for the cubic lattices. Proc. Nat. Acad.
Sci. U.S.A. 74(5), 1800–1801 (1977)
62. B.V. Gnedenko, A.N. Kolmogorov, Limit Distributions for Sums of Independent Random
Variables (Addison-Wesley Publishing Co., Reading, MA/London/Don Mills, ON, 1968)
63. G. Grimmett, Percolation. Grundlehren der Mathematischen Wissenschaften, vol. 321, 2nd
edn. (Springer, Berlin, 1999)
64. G.R. Grimmett, D.R. Stirzaker, Probability and Random Processes, 3rd edn. (Oxford
University Press, New York, 2001)
65. E. Grosswald, The Student t-distribution of any degree of freedom is inﬁnitely divisible. Z.
Wahrsch. Verw. Gebiete 36(2), 103–109 (1976)
66. O. Häggström, Finite Markov Chains and Algorithmic Applications. London Mathematical
Society Student Texts, vol. 52 (Cambridge University Press, Cambridge, 2002)
67. T. Hara, G. Slade, Mean-ﬁeld critical behaviour for percolation in high dimensions. Commun.
Math. Phys. 128(2), 333–391 (1990)
68. J.M. Harrison, S.R. Pliska, Martingales and stochastic integrals in the theory of continuous
trading. Stoch. Process. Appl. 11(3), 215–260 (1981)
69. P. Hartman, A. Wintner, On the law of the iterated logarithm. Am. J. Math. 63, 169–176
(1941)

694
References
70. W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications.
Biometrika 57, 97–109 (1970)
71. E. Hewitt, K.A. Ross, Abstract Harmonic Analysis. Vol. II: Structure and analysis for
compact groups. Analysis on locally compact Abelian groups. Die Grundlehren der mathe-
matischen Wissenschaften, Band 152 (Springer, New York, 1970)
72. E. Hewitt, L.J. Savage, Symmetric measures on Cartesian products. Trans. Math. Soc. 80,
470–501 (1955)
73. C.C. Heyde, On a property of the lognormal distribution. J. R. Stat. Soc. B 29, 392–393 (1963)
74. F. den Hollander, Large Deviations. Fields Institute Monographs, vol. 14 (American Mathe-
matical Society, Providence, RI, 2000)
75. R.A. Holley, T.M. Liggett, Ergodic theorems for weakly interacting inﬁnite systems and the
voter model. Ann. Probab. 3(4), 643–663 (1975)
76. B.D. Hughes, Random Walks and Random Environments, vol. 1. Oxford Science Publications
(The Clarendon Press/Oxford University Press, New York, 1995). Random walks
77. B.D. Hughes, Random Walks and Random Environments, vol. 2. Oxford Science Publications
(The Clarendon Press/Oxford University Press, New York, 1996). Random environments
78. N. Ikeda, S. Watanabe, Stochastic Differential Equations and Diffusion Processes. North-
Holland Mathematical Library, vol. 24, 2nd edn. (North-Holland Publishing Co., Amsterdam,
1989)
79. J. Jost, Partial Differential Equations. Graduate Texts in Mathematics, vol. 214, 3rd edn.
(Springer, New York, 2013)
80. G.S. Joyce, Singular behaviour of the lattice Green function for the d-dimensional hypercubic
lattice. J. Phys. A 36(4), 911–921 (2003)
81. S. Kakutani, Examples of ergodic measure preserving transformations which are weakly
mising but not strongly mixing, in Recent Advances in Topological Dynamics (Proceedings
of the Conference at Yale University, New Haven, CT, 1972, in honor of Gustav Arnold
Hedlund). Lecture Notes in Mathematics, vol. 318 (Springer, Berlin, 1973), pp. 143–149
82. O. Kallenberg, Random Measures, 4th edn. (Akademie-Verlag, Berlin, 1986)
83. O. Kallenberg, Foundations of Modern Probability, 2nd edn. Probability and Its Applications
(Springer, New York/Berlin, 2002)
84. L.V. Kantoroviˇc, G.Š. Rubinšte˘ın, On a space of completely additive functions. Vestnik
Leningrad Univ. 13(7), 52–59 (1958)
85. I. Karatzas, S.E. Shreve, Brownian Motion and Stochastic Calculus. Graduate Texts in
Mathematics, vol. 113, 2nd edn. (Springer, New York, 1991)
86. I. Karatzas, S.E. Shreve, Methods of Mathematical Finance. Applications of Mathematics,
vol. 39 (Springer, New York, 1998)
87. T. Kato, Perturbation Theory for Linear Operators, 2nd edn. Grundlehren der Mathematis-
chen Wissenschaften, Band 132. (Springer, Berlin, 1976)
88. G. Keller, Equilibrium States in Ergodic Theory. London Mathematical Society Student Texts,
vol. 42 (Cambridge University Press, Cambridge, 1998)
89. G. Keller, Wahrscheinlichkeitstheorie. Lecture Notes (German) (Universität Erlangen, 2003)
90. J.L. Kelley, General Topology. Graduate Texts in Mathematics, vol. 27 (Springer, New York,
1975). Reprint of the 1955 edition [Van Nostrand, Toronto, Ontario]
91. J.G. Kemeny, J.L. Snell, Finite Markov Chains. Undergraduate Texts in Mathematics
(Springer, New York, 1976). Reprinting of the 1960 original
92. R.W. Kenyon, J.G. Propp, D.B. Wilson, Trees and matchings. Electron. J. Combin. 7,
Research Paper 25, 34 pp. (electronic) (2000)
93. H. Kesten, Sums of stationary sequences cannot grow slower than linearly. Proc. Am. Math.
Soc. 49, 205–211 (1975)
94. H. Kesten, The critical probability of bond percolation on the square lattice equals
1
2.
Commun. Math. Phys. 74(1), 41–59 (1980)
95. H. Kesten, B.P. Stigum, A limit theorem for multidimensional Galton-Watson processes. Ann.
Math. Statist. 37, 1211–1223 (1966)

References
695
96. H. Kesten, M.V. Kozlov, F. Spitzer, A limit law for random walk in a random environment.
Compos. Math. 30, 145–168 (1975)
97. A. Khintchine, Über dyadische Brüche. Math. Z. 18, 109–116 (1923)
98. J.F.C. Kingman, Uses of exchangeability. Ann. Probab. 6(2), 183–197 (1978)
99. J.F.C. Kingman, Poisson Processes. Oxford Studies in Probability, vol. 3 (The Clarendon
Press/Oxford University Press, New York, 1993). Oxford Science Publications
100. A. Klenke, L. Mattner, Stochastic ordering of classical discrete distributions. Adv. in Appl.
Probab. 42(2), 392–410 (2010)
101. A.N. Kolmogorov, Sulla determinazione empirica di una legge di distibuzione. Giornale
Istituto Italiano degli Attuari 4, 83–91 (1933)
102. R. Korn, E. Korn, Option Pricing and Portfolio Optimization. Graduate Studies in Mathe-
matics, vol. 31 (American Mathematical Society, Providence, RI, 2001). Modern methods of
ﬁnancial mathematics, translated from the 1999 German original by the authors
103. U. Krengel, Ergodic Theorems. de Gruyter Studies in Mathematics, vol. 6 (Walter de Gruyter
& Co., Berlin, 1985)
104. S. Kullback, R.A. Leibler, On information and sufﬁciency. Ann. Math. Stat. 22, 79–86 (1951)
105. S.L. Lauritzen, Extremal Families and Systems of Sufﬁcient Statistics. Lecture Notes in
Statistics, vol. 49 (Springer, New York, 1988)
106. P. Lévy, Théorie de l’Addition des Variables Aléatoires (Gauthier-Villars, Paris, 1937)
107. P. Lévy, Processus Stochastiques et Mouvement Brownien. Suivi d’une note de M. Loève
(Gauthier-Villars, Paris, 1948)
108. J.W. Lindeberg, Eine neue Herleitung des Exponentialgesetzes in der Wahrscheinlichkeit-
srechnung. Math. Zeit. 15, 211–225 (1922)
109. T. Lindvall, Convergence of critical Galton-Watson branching processes. J. Appl. Probab. 9,
445–450 (1972)
110. R. Lyons, Y. Peres, Probability on Trees and Networks. Cambridge Series in Statistical and
Probabilistic Mathematics, vol. 42 (Cambridge University Press, New York, 2016)
111. R. Lyons, R. Pemantle, Y. Peres, Conceptual proofs of L log L criteria for mean behavior of
branching processes. Ann. Probab. 23(3), 1125–1138 (1995)
112. N. Madras, Lectures on Monte Carlo Methods. Fields Institute Monographs, vol. 16 (Ameri-
can Mathematical Society, Providence, RI, 2002)
113. D.E. Menchoff, Sur les séries des fonctions orthogonales (première partie). Fund. Math. 4,
92–105 (1923)
114. N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, E. Teller, Equation of state
calculations by fast computing machines. J. Chem. Phys. 21, 1087–1092 (1953)
115. P.-A. Meyer, Probability and Potentials (Blaisdell Publishing Co. Ginn and Co., Waltham,
MA/Toronto, ON/London, 1966)
116. S.P. Meyn, R.L. Tweedie, Markov Chains and Stochastic Stability. Communications and
Control Engineering Series (Springer, London, 1993)
117. F. Móricz, K. Tandori, An improved Menshov–Rademacher theorem. Proc. Am. Math. Soc.
124(3), 877–885 (1996)
118. P. Mörters, Y. Peres, Brownian Motion. Cambridge Series in Statistical and Probabilistic
Mathematics (Cambridge University Press, Cambridge, 2010). With an appendix by Oded
Schramm and Wendelin Werner
119. R. Motwani, P. Raghavan, Randomized Algorithms (Cambridge University Press, Cambridge,
1995)
120. A. Müller, D. Stoyan, Comparison Methods for Stochastic Models and Risks. Wiley Series in
Probability and Statistics (Wiley, Chichester, 2002)
121. M. Musiela, M. Rutkowski, Martingale Methods in Financial Modelling. Stochastic Mod-
elling and Applied Probability, vol. 36, 2nd edn. (Springer, Berlin, 2005)
122. J. von Neumann, Proof of the quasi-ergodic hypothesis. Proc. Nat. Acad. Sci. 18, 70–82
(1932)
123. J.R. Norris, Markov Chains. Cambridge Series in Statistical and Probabilistic Mathematics
(Cambridge University Press, Cambridge, 1998). Reprint of the 1997 edition

696
References
124. E. Nummelin, General Irreducible Markov Chains and Nonnegative Operators. Cambridge
Tracts in Mathematics, vol. 83 (Cambridge University Press, Cambridge, 1984)
125. R.E.A.C. Paley, N. Wiener, Fourier Transforms in the Complex Domain. American Mathemat-
ical Society Colloquium Publications, vol. 19 (American Mathematical Society, Providence,
RI, 1987). Reprint of the 1934 original
126. R.E.A.C. Paley, N. Wiener, A. Zygmund, Note on random functions. Math. Zeit. 37, 647–668
(1933)
127. R.F. Peierls, On Ising’s model of ferromagnetism. Proc. Camb. Philol. Soc. 32, 477–481
(1936)
128. V.V. Petrov, Sums of Independent Random Variables. Ergebnisse der Mathematik und ihrer
Grenzgebiete, vol. 82 (Springer, New York, 1975)
129. J. Pitman, Exchangeable and partially exchangeable random partitions. Probab. Theory
Related Fields 102(2), 145–158 (1995)
130. J. Pitman, Combinatorial Stochastic Processes. Lecture Notes in Mathematics, vol. 1875
(Springer, Berlin, 2006). Lectures from the 32nd Summer School on Probability Theory held
in Saint-Flour, July 7–24, 2002, with a foreword by Jean Picard
131. J. Pitman, M. Yor, Bessel processes and inﬁnitely divisible laws, in Stochastic integrals
(Proceedings of the Symposium at the University of Durham, Durham, 1980). Lecture Notes
in Mathematics, vol. 851 (Springer, Berlin, 1981), pp. 285–370
132. J. Pitman, M. Yor, The two-parameter Poisson-Dirichlet distribution derived from a stable
subordinator. Ann. Probab. 25(2), 855–900 (1997)
133. J. Pitman, M. Yor, On the distribution of ranked heights of excursions of a Brownian bridge.
Ann. Probab. 29(1), 361–384 (2001)
134. G. Pólya, Über eine Aufgabe der Wahrscheinlichkeitsrechnung betreffend die Irrfahrt im
Straßennetz. Math. Ann. 84, 149–160 (1921)
135. G. Pólya, Sur quelques points de la théorie de probabilités. Ann. Inst. H. Poincaré 1, 117–161
(1931)
136. Y.V. Prohorov, Convergence of random processes and limit theorems in probability theory.
Teor. Veroyatnost. i Primenen. 1, 177–238 (1956). Russian with English summary
137. J. Propp, D. Wilson, Coupling from the past: a user’s guide, in Microsurveys in Discrete
Probability (Princeton, NJ, 1997). DIMACS Series in Discrete Mathematics and Theoretical
Computer Science, vol. 41 (American Mathematical Society, Providence, RI, 1998), pp. 181–
192
138. J.G. Propp, D.B. Wilson, Exact sampling with coupled Markov chains and applications to
statistical mechanics. Random Struct. Algoritm. 9(1–2), 223–252 (1996)
139. J.G. Propp, D.B. Wilson, How to get a perfectly random sample from a generic Markov
chain and generate a random spanning tree of a directed graph. J. Algorithms 27(2), 170–217
(1998). 7th Annual ACM-SIAM Symposium on Discrete Algorithms (Atlanta, GA, 1996)
140. P.E. Protter, Stochastic Integration and Differential Equations. Applications of Mathematics
(New York), vol. 21, 2nd edn. (Springer, Berlin, 2004). Stochastic Modelling and Applied
Probability
141. H. Rademacher, Einige Sätze über Reihen von allgemeinen Orthogonalfunktionen. Math.
Ann. 87, 112–138 (1922)
142. A. Rényi, Remarks on the Poisson process. Studia Sci. Math. Hungar 2, 119–123 (1967)
143. P. Révész, Random Walk in Random and Non-random Environments, 2nd edn. (World
Scientiﬁc Publishing Co. Pte. Ltd., Hackensack, NJ, 2005)
144. D. Revuz, Markov Chains. North-Holland Mathematical Library, vol. 11, 2nd edn. (North-
Holland Publishing Co., Amsterdam, 1984)
145. D. Revuz, M. Yor, Continuous Martingales and Brownian Motion. Grundlehren der Mathe-
matischen Wissenschaften, vol. 293, 3rd edn. (Springer, Berlin, 1999)
146. R.T. Rockafellar, Convex Analysis. Princeton Mathematical Series, No. 28 (Princeton Univer-
sity Press, Princeton, NJ, 1970)

References
697
147. L.C.G. Rogers, D. Williams, Diffusions, Markov Processes, and Martingales. Vol. 1:
Foundations. Cambridge Mathematical Library (Cambridge University Press, Cambridge,
2000). Reprint of the 2nd edition from 1994
148. L.C.G. Rogers, D. Williams, Diffusions, Markov Processes, and Martingales. Vol. 2: Itô
Calculus. Cambridge Mathematical Library (Cambridge University Press, Cambridge, 2000).
Reprint of the 2nd edition from 1994
149. W. Rudin, Principles of Mathematical Analysis. International Series in Pure and Applied
Mathematics, 3rd edn. (McGraw-Hill, New York, 1976)
150. I.N. Sanov, On the probability of large deviations of random magnitudes (Russian). Mat. Sb.
N. S. 42(84), 11–44 (1957)
151. I.N. Sanov, On the probability of large deviations of random variables. Sel. Transl. Math. Stat.
Probab. 1, 213–244 (1961)
152. R.L. Schilling, L. Partzsch, Brownian Motion (De Gruyter, Berlin, 2012). An introduction to
stochastic processes, With a chapter on simulation by Björn Böttcher.
153. E. Seneta, Non-negative Matrices and Markov Chains. Springer Series in Statistics (Springer,
New York, 2006). Revised reprint of the second (1981) edition
154. T. Shiga, A. Shimizu, Inﬁnite-dimensional stochastic differential equations and their applica-
tions. J. Math. Kyoto Univ. 20(3), 395–416 (1980)
155. A.N. Shiryaev, Probability. Graduate Texts in Mathematics, vol. 95, 2nd edn. (Springer, New
York, 1996). Translation of the Russian edition from 1980
156. J. Sina˘ı, On the concept of entropy for a dynamic system. Dokl. Akad. Nauk SSSR 124,
768–771 (1959)
157. N.V. Smirnov, Sur les écarts de la courbe de distribution empirique. Matematicheskij Sbornik,
Rossijskaya Akademiya Nauk, Moscow 2, 3–16 (1939). Russian with French summary
158. F. Solomon, Random walks in a random environment. Ann. Probab. 3, 1–31 (1975)
159. F. Spitzer, Principles of Random Walks. Graduate Texts in Mathematics, vol. 34, 2nd edn.
(Springer, New York, 1976)
160. J.M. Steele, Stochastic Calculus and Financial Applications. Applications of Mathematics
(New York), vol. 45 (Springer, New York, 2001)
161. V. Strassen, The existence of probability measures with given marginals. Ann. Math. Statist.
36, 423–439 (1965)
162. D.W. Stroock, S.R.S. Varadhan, Multidimensional Diffusion Processes. Grundlehren der
Mathematischen Wissenschaften, vol. 233 (Springer, Berlin, 1979)
163. J.J. Sylvester, Mathematical questions with their solutions. Educ. Times 41, 171–178 (1884)
164. K. Tandori, Über die orthogonalen Funktionen. I. Acta Sci. Math. Szeged 18, 57–130 (1957)
165. K. Tandori, Über die Divergenz der Orthogonalreihen. Publ. Math. Debrecen 8, 291–307
(1961)
166. K. Tandori, Bemerkung über die paarweise unabhängigen zufälligen Größen. Acta Math.
Hungar. 48(3–4), 357–359 (1986)
167. S.R.S. Varadhan, Asymptotic probabilities and differential equations. Commun. Pure Appl.
Math. 19, 261–286 (1966)
168. P. Walters, An Introduction to Ergodic Theory. Graduate Texts in Mathematics, vol. 79
(Springer, New York, 1982)
169. G.N. Watson, Three triple integrals. Q. J. Math. Oxford Ser. 10, 266–276 (1939)
170. D. Williams, Probability with Martingales. Cambridge Mathematical Textbooks (Cambridge
University Press, Cambridge, 1991)
171. D.B. Wilson, J.G. Propp, How to get an exact sample from a generic Markov chain and sample
a random spanning tree from a directed graph, both within the cover time, in Proceedings
of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms (Atlanta, GA, 1996)
(ACM, New York, 1996), pp. 448–457
172. S. Wright, Evolution in Mendelian populations. Genetics 16, 97–159 (1931)
173. T. Yamada, S. Watanabe, On the uniqueness of solutions of stochastic differential equations.
J. Math. Kyoto Univ. 11, 155–167 (1971)

698
References
174. K. Yosida, Functional Analysis. Classics in Mathematics. (Springer, Berlin, 1995). Reprint of
the sixth edition from 1980
175. O. Zeitouni, Random walks in random environment, in Lectures on Probability Theory and
Statistics. Lecture Notes in Mathematics, vol. 1837 (Springer, Berlin, 2004), pp. 189–312

Notation Index
1A
indicator function of the set A
2Ω
set of all subsets of Ω
#A
cardinalityof the set A
Ac
complement Ω \ A of the set A ⊂Ω
A ∩B
intersection of the sets A and B
A ∪B
union of the sets A and B
A ⊎B
disjoint union of A and B
A ⊂B
A is a (not necessarily strict) subset of B
A \ B
difference set
A △B
symmetric difference of A and B, 31
A × B
Cartesian product of A and B
A
subset of 2Ω, usually a σ-algebra
A
B
trace of the class A on B, 10
A ⊗A′
product of the σ-algebras A and A′,304
B(E)
Borel σ-algebra on E, 8
Berp
Bernoulli distribution, 46
βr,s
Beta distribution with parameters r and s, 49
bn,p
binomial distribution,47, 336
b−
r,p
negative binomial distribution, 48, 336
C(E), Cb(E), Cc(E)
space of continuous (bounded) functions, and
with compact support, respectively, 276
Cqv
functions with continuous square variation,562
C
set of complex numbers
Caua
Cauchy distribution, 336
Cov[X, Y]
covariance of the random variables X and Y, 114
CPoiν
compound Poisson distribution, 369
δx
Dirac distribution, 12
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
699

700
Notation Index
E[X]
expectation (or mean) of the random variable X,
113
E[X; A]
=E[X 1A], 193
E[X|F]
conditional expectation, 195
expθ
exponential distribution, 49,336
F = (Ft)t∈I
ﬁltration, 215
a.s, a.e.
almost surely and almost everywhere,33
G(x, y)
Greeen function of a Markov chain, 412
Γθ,r
Gamma distribution with scale parameter θ > 0
and shape parameter r > 0, 49, 336
γp = b−
1,p
geometric distribution with parameter p, 47
gcd(M)
greatest common divisor of all m ∈M ⊂N, 436
H ·X
discrete stochastic integral of H with respect to
X, 223
I
set of invariant distributions of a Markov chain,
423
iff
if and only if
i.i.d.
independent and identically distributed, 61
Im(z)
imaginary part of z ∈C, 327
λ, λn
Lebesgue measure, n-dimensional, 27
Lip(E)
space of Lipschitz continuous functions on E,
277
Lp, Lp
Lebesgue spaces of integrable functions, 102,
163, 164
L(X)
distribution of the random variable X
M(E), Mf (E), M≤1, M1(E)
set of measures on E, ﬁnite measures on E,
(sub-) probability measures on E, respectively,
18, 276
Mloc,c
space of continuous local martingales, 565
μ ⊗ν
product of the measures μ and ν, 29, 308
μ ∗ν
convolution of the measures μ and ν, 67, 310
μ⊗n
nth power of a measure μ, 308
μ∗n
nth convolution power of a measure μ, 67
μ ≪ν
μ is absolutely continuous with respect to ν, 176
μ ⊥ν
μ and ν are mutually singular, 176
μ ≈ν
μ and ν are equivalent, 176
μ ≤st ν
μ is stochastically smaller than (or equal to) ν,
431
N, N0
N = {1, 2, 3, . . .}, N0 = N ∪{0}
Nμ,σ 2
normal distribution, 49, 336
dμ
@
dν
Radon–Nikodym derivative, 177
Ω
space of elementary events on which P is deﬁned
P
generic probability measure
P[A|B, P[A|F]
conditional probabilities, 192, 195

Notation Index
701
PX = P ◦X−1
distribution of the random variable X, 45
Poiλ
Poisson distribution with parameter λ ≥0, 48,
336
pn(x, y) = p(n)(x, y)
n-step transition probability of a Markov chain,
399
Pn
S,T , Pn
T
see page 562
ϕX
characteristic function of the random variable X,
336
ψX
generating function of the random variable X,
85
Q
set of rational numbers
R
set of real numbers
R = R ∪{−∞, +∞}
two point compactiﬁcation of the real numbers
Radp
= pδ1 + (1 −p)δ−1 Rademacher distribution,
46
Re(z)
real part of z ∈C, 327
sign(x)
= 1(0,∞)(x) −1(−∞,0)(x), sign of x ∈R, 40
σ( ·)
σ-algebra or ﬁltration generated by ·, 6, 36, 215
τ k
x
time of the kth visit of a Markov chain at x, 411
T ( ·)
tail σ-algebra, 69
UA
uniform distribution on A, 12, 35, 336
V 1(G), V 2(G)
variation and square variation of G, 561, 562
Var[X]
variance of the random variable X, 113
v-lim
vague limit, 281
w-lim
weak limit, 281
Xτ
stopped process, 235
⟨X⟩
square variation process of X,230, 562, 566, 570
f (t) ∼g(t), t →a
: ⇐⇒
limt→a f (t)/g(t) = 1
X ∼μ
the random variable X has distribution μ,45
x ∨y, x ∧y, x+, x−
maximum, minimum, positive part, negative part
of real numbers, 40
⌊x⌋,
⌈x⌉
ﬂoor and ceiling of x, 38
z
complex conjugate of z ∈C, 327
Z
set of integers
D=
equal in distribution, 45
D
−→
n→∞
, n→∞
⇒
convergence of distributions, 285
n→∞
⇒
fdd
,
n→∞
−→
fdd
convergence of ﬁnite-dimensional distributions,
546
meas
−→,
a.s.
−→,
a.e.
−→
convergence in measure, almost surely, and
almost everywhere, 148

Name Index
B
Banach, Stefan, 1892 (Kraków, now Poland) –
1945 (Lvov, now Ukraine), 171
Bayes, Thomas, 1702 (London) – 1761
(Tunbridge Wells, England), 192
Bernoulli, Jakob, 1654 (Basel, Switzerland) –
1705 (Basel), 19
Bienaymé, Irénée-Jules, 1796 (Paris) – 1878
(Paris), 116
Blackwell, David, 1919 (Centralia, Illinois) –
2010 (Berkeley, California), 119
Bochner, Salomon, 1899 (Kraków, now
Poland) – 1982 (Houston, Texas),
348
Boltzmann, Ludwig, 1844 (Vienna, Austria)
– 1906 (Duino, near Trieste, Italy),
447
Borel, Emile, 1871 (Saint-Affrique, France) –
1956 (Paris), 8
Brown, Robert, 1773 (Montrose, Scotland) –
1858 (London), 522
C
Cantelli, Francesco Paolo, 1875 (Palermo,
Italy) – 1966 (Rome, Italy), 58
Carathéodory, Constantin, 1873 (Berlin) –
1950 (Munich, Germany), 20
Cauchy, Augustin Louis, 1789 (Paris) – 1857
(near Paris), 117
Cesàro, Ernesto, 1859 (Naples, Italy) – 1906
(Torre Annunziata, Italy), 70
Chebyshev, Pafnutij Lvovich (Qebyxëv,
Pafnuti Lvoviq), 1821
(Okatavo, Russia) – 1894 (Saint
Petersburg), 121
Cramér, Harald, 1893 (Stockholm) – 1985
(Stockholm), 365
Curie, Pierre, 1859 (Paris) – 1906 (Paris), 609
D
Dieudonné, Jean Alexandre 1906 (Lille,
France) – 1992 (Paris), 328
Dirac, Paul Adrien Maurice, 1902 (Bristol,
England) – 1984 (Tallahassee,
Florida), 12
Dirichlet, Lejeune, 1805 (Düren, Germany) –
1859 (Göttingen, Germany), 463
Doob, Joseph Leo, 1910 (Cincinnati, Ohio) –
2004 (Urbana, Illinois), 229
Dynkin, Eugene, 1924 (Petrograd, now Saint
Petersburg) – 2014 (Ithaca, New
York), 3
E
Egorov, Dmitrij Fedorovich (Egorov,
Dmitri Fëdoroviq), 1869
(Moscow) – 1931 (Kazan, Russia),
152
Esseen, Carl-Gustav, 1918 (Linköping,
Sweden) – 2001 (Uppsala, Sweden
?), 363
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
703

704
Name Index
Euler, Leonard, 1707 (Basel, Switzerland) –
1783 (Saint Petersburg), 57
F
Fatou, Pierre, 1878 (Lorient, France) – 1929
(Pornichet, France), 104
Feller, William, 1906 (Zagreb, Croatia) – 1970
(New York, New York), 358
Fischer, Ernst, 1875 (Vienna, Austria) – 1954
(Cologne, Germany), 171
Fourier, Jean Baptiste Joseph, 1768 (Auxerre,
France) – 1830 (Paris), 333
Fréchet, Maurice René, 1878 (Maligny,
France) – 1973 (Paris), 172
Fubini, Guido, 1879 (Venice, Italy) – 1943
(New York, New York), 309
G
Galton, Francis, 1822 (near Birmingham,
England) – 1911 (Grayshott House,
England), 92
Gauß, Carl-Friedrich, 1777 (Braunschweig,
Germany) – 1855 (Göttingen,
Germany), 49
Gibbs, Josiah Willard, 1839 (New Haven,
Connecticut) – 1903 (New Haven,
Connecticut), 450
Green, 412
Green, George, 1793 (Nottingham, England) –
1841 (Nottingham), 412
H
Hölder, Otto Ludwig, 1859 (Stuttgart,
Germany) – 1937 (Leipzig,
Germany), 170
Hahn, Hans, 1879 (Vienna, Austria) – 1934
(Vienna), 181
Helly, Eduard, 1884 (Vienna, Austria) – 1943
(Chicago, Illinois), 293
Hesse, Ludwig Otto, 1814 (Königsberg,
now Kaliningrad, Russia) – 1874
(Munich, Germany), 169
Hewitt, Edwin, 1920 (Everett, Washington) –
1999, 265
Hilbert, David, 1862 (Königsberg, now
Kaliningrad, Russia) – 1943
(Göttingen, Germany), 172
Hopf, Eberhard, 1902 (Salzburg, Austria) –
1983, 498
I
Ionescu–Tulcea, Cassius, 1923 (Bucharest,
Romania), 317
Ising, Ernst, 1900 (Cologne, Germany) – 1988
(Peoria, Illinois), 446
Itô, Kiyosi, 1915 (Hokusei-cho, Japan) – 2008
(Kyoto, Japan), 541
J
Jensen, Johan Ludwig, 1859 (Nakskov,
Denmark) – 1925 (Copenhagen),
168
Jordan, Camille, 1838 (near Lyon, France) –
1922 (Paris), 183
K
Kesten, Harry, 1931 (Duisburg, Germany) –
2019 (Ithaca, New York), 79
Khinchin, Aleksandr Jakovlevich
(Hinqin, Aleksandr
kovleviq) 1894 (Kondrovo,
Russia) – 1959 (Moscow), 372
Kirchhoff, Gustav Robert, 1824 (Königsberg,
now Kaliningrad, Russia) – 1887
(Berlin), 467
Kolmogorov, Andrej Nikolaevich
(Kolmogorov, Andre
Nikolaeviq), 1903 (Tambow,
Russia) – 1987 (Moscow), 71
L
Laplace, Pierre-Simon, 1749 (Beaumont-
en-Auge, France) – 1827 (Paris),
161
Lebesgue, Henri Léon, 1875 (Beauvais, Oise,
France) – 1941 (Paris), 18
Legendre, Adrien-Marie, 1752 (Paris) – 1833
(Paris), 590
Levi, Beppo, 1875 (Turin, Italy) – 1961
(Rosario, Santa Fe, Argentina), 104
Lévy, Paul Pierre, 1886 (Paris) – 1971 (Paris),
345, 576
Lindeberg, Jarl Waldemar, 1876–1932, 357
Lipschitz, Rudolph, 1832 (Königsberg, now
Kaliningrad, Russia) – 1903 (Bonn,
Germany), 277
Lusin, Nikolai Nikolaevich(Lusin,
Nikola Nikolaeviq),
1883 (Irkutsk, Russia) – 1950
(Moscow), 279

Name Index
705
Lyapunov, Aleksandr Mikhajlovich
(Lpunov Aleksandr
Mihaloviq), 1857 (Jaroslavl,
Russia) – 1918 (Odessa, Ukraine),
358
M
Markov, Andrej Andreevich (Markov,
Andre Andreeviq), 1856
(Ryazan, Russia) – 1922 (Petrograd,
now Saint Petersburg), 121
Menshov, Dmitrij Evgen’evich
(Menxov, Dmitri
Evgeneviq), 1892 (Moscow) –
1988 (Moscow), 137
Minkowski, Hermann, 1864 (Alexotas,
now Kaunas, Lithuania) – 1909
(Göttingen, Germany), 171
N
Neumann, John von, 1903 (Budapest) – 1957
(Washington, D.C.), 177
Nikodym, Otton Marcin, 1889 (Zablotow,
Galicia, Ukraine) – 1974 (Utica,
New York), 177
O
Ohm, Georg Simon, 1789 (Erlangen, Germany)
– 1854 (Munich, Germany), 468
Ornstein, Leonard Salomon, 1880 (Nijmegen,
Netherlands) – 1941 (Utrecht,
Netherlands), 667
P
Paley, Raymond E. A. C., 1907 (Bournemouth,
England) – 1933 (Banff, Alberta,
Canada), 526
Parseval, Marc-Antoine,
1755 (Rosières-aux-Salines, France)
– 1836 (Paris), 536
Pascal, Blaise, 1623 (Clermont-Ferrand,
France) – 1662 (Paris), 48
Plancherel, Michel, 1885 (Bussy (Fribourg),
Switzerland) – 1967 (Zurich), 334
Poisson, Siméon Denis, 1781 (Pithiviers,
France) – 1840 (near Paris), 48
Pólya, George, 1887 (Budapest) – 1985 (Palo
Alto, CA), 347
Prohorov, Yurij Vasil’evich (Prohorov,
ri Vasileviq), 1929,
291
R
Rademacher, Hans, 1892 (Hamburg, Germany)
– 1969 (Haverford,
Pennsylvania), 137
Radon, Johann, 1887 (Tetschen, Bohemia) –
1956 (Vienna, Austria), 177
Riemann, Georg Friedrich Bernhard, 1826
(Breselenz, Germany) – 1866
(Selasca, Italy), 57
Riesz, Frigyes, 1880 (Györ, Hungary) – 1956
(Budapest, Hungary), 171
S
Saks, Stanislav (Saks, Stanislav),
1897 (Kalish, Russia (now Poland))
– 1942 (Warsaw, murdered by the
Gestapo), 256
Savage, Jimmie Leonard, 1917 (Detroit,
Michigan) – 1971 (New Haven,
Connecticut), 265
Schwarz, Hermann Amandus, 1843
(Hermsdorf, Silesia) – 1921
(Berlin), 117
Skorohod, Anatolii Volodymyrovych
(Skorohod, Anatol
Volodimiroviq), 1930
(Nikopo, Ukraine) – 2011 (Lansing,
Michigan), 431
Slutzky, Evgenij Evgen’evich (Slucki,
Evgeni Evgeneviq), 1880
(Novoe, Gouvernement Jaroslavl,
Russia) – 1948 (Moscow), 285
Stieltjes, Thomas Jan, 1856 (Zwolle,
Overijssel, Netherlands) – 1894
(Toulouse, France), 27
Stone, Marshall Harvey, 1903 (New York) –
1989 (Madras, India), 328
T
Thomson, William (Lord Kelvin), 1824
(Belfast, Northern Ireland) – 1907
(Largs, Ayrshire, Scotland), 472
U
Uhlenbeck, George Eugene, 1900 (Batavia
(now Jakarta), Indonesia) – 1988
(Boulder, Colorado), 667

706
Name Index
V
Varadhan, S.R. Srinivasa, 1940 (Madras,
India), 603
W
Watson, George Neville, 1886 (Westward Ho,
England) – 1965 (Leamington Spa,
England), 420
Watson, Henry William, 1827 (near London) –
1903 (near Coventry, England), 92
Weierstraß, Karl, 1815 (Ostenfelde,
Westphalia, Germany) – 1897
(Berlin), 328
Weiss, Pierre-Ernest, 1865 (Mulhouse, France)
– 1940 (Lyon, France), 607
Wiener, Norbert, 1894 (Columbia, Missouri) –
1964 (Stockholm), 545
Wintner, Aurel Friedrich, 1903 (Budapest) –
1958 (Baltimore, Maryland), 583
Wright, Sewall, 1889 (Melrose, Massachusetts)
– 1988 (Madison, Wisconsin), 402
Y
Yule, George Udny, 1871 (Morham, Scotland)
– 1951 (Cambridge, England), 407
Z
Zygmund, Antoni, 1900 (Warsaw) – 1992
(Chicago, Illinois), 526

Subject Index
Symbols
0–1 laws
Kolmogorov, 71
0-1 laws
Blumenthal, 526
for invariant events, 508
Hewitt–Savage, 265
∅-continuous, 16
A
a.a., see Almost all (a.a.)
Absolutely continuous, 176
Absorbing, 412
Adapted, 215
Additive, 12
a.e., see Almost everywhere (a.e.)
Algebra, 3, 328
Almost all, 33
Almost everywhere, 33
Almost surely, 33
Aperiodic, 436
Approximation theorem for measures, 31
Arbitrage, 227
Arcsine law, 531
Array of random variables, 357
Arzelà–Ascoli theorem, 547
a.s., see Almost surely (a.s.)
Azuma’s inequality, 222
B
Backwards martingale, 263
Banach space, 171
Bayes’ formula, 192, 202
Benford’s law, 502
Bernoulli distribution, 46
Bernoulli measure, 31
Bernstein–Chernov bound, 124
Bernstein polynomial, 124
Berry–Esseen theorem, 363
Bessel process, 677
Beta distribution, 49, 270, 354, 627
moments, 120
Bienaymé formula, 116
Binary model, 225
Binary splitting stochastic process, 225
Binomial distribution, 47
Black–Scholes formula, 228
Black–Scholes model, 668
Blackwell–Girshick formula, 119
Blumenthal’s 0-1 law, 526
Bochner’s theorem, 348
Boltzmann distribution, 447, 606
Bond, 73
Bond percolation, 74, 461
Borel–Cantelli lemma, 58
conditional version, 253
Borel measure, 275
Borel space, 208
Borel’s paradox, 211
Borel σ-algebra, 8
Boundary of a set, 274
Bounded in Lp, 155
Box–Muller method, 68
Branching process, 92, 254
Brownian bridge, 524, 542, 543, 552, 675
Brownian motion, 325, 522
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
707

708
Subject Index
canonical, 545
existence theorem, 523
Karhunen–Loève expansion, 541
Lévy characterization, 651
Paley–Wiener expansion, 541
reﬂection principle, 530
scaling property, 524
strong Markov property, 529
Brownian sheet, 524, 543
C
Càdlàg, 532
Call option, 226
Canonical Brownian motion, 545
Canonical measure, 372, 376, 623
Canonical process, 305
Carathéodory’s theorem, 20
Cauchy distribution, 50, 336, 659
Cauchy–Schwarz inequality, 117
conditional, 202
Centered random variable, 113
Central limit theorem, 357
Berry–Esseen, 363
Lindeberg–Feller, 358
multidimensional, 366
Cesàro limit, 70
CFP, 367
Chapman–Kolmogorov equation, 322, 400
Characteristic function, 331, 613
inversion formula, 333
Chebyshev inequality, 121
Chebyshev polynomial, 458
Chernov bound, see Bernstein–Chernov bound
Chinese restaurant process, 632
Cholesky factorization, 366
Chung–Fuchs theorem, 420, 504
Claim, contingent, 226
Closed, 8
∩-closed, 1
∪-closed, 1
\-closed, 1
Closed under complements, 1
Closure of a set, 274
CLT, see Central limit theorem (CLT)
Coloring theorem, 625
Complete measure space, 33
Complete metric, 274
Completion of a measure space, 34
Composition of kernels, 314
Compound Poisson distribution, 369
Concave function, 166
Conditional
distribution, 205
expectation, 195
independence, 266
probability, 192, 195
summation formula, 192
Conductance, 467
Consistent, 319
Content, 12
Contingent claim, 226
Continuity lemma, 160
Continuity lower/ upper, 16
Continuity theorem, Lévy’s, 345
Continuity theorem, Laplace transforms, 349
Continuous mapping theorem, 287
Contraction principle, 603
Convergence
almost everywhere, 148
almost sure, 148
in distribution, 285
of distribution functions, 285
dominated, 158
fast, 150
Lp-, 164
mean, 150
in measure, 148
in probability, 148
vague, 281
weak, 89, 281
Convex function, 166
Convex set, 165
Convolution
densities, 310
discrete distributions, 67
measures on Rn, 67, 310
Convolution semigroup, 325
Coordinate map, 304
Correlated, 114
Countable, 1
Counting measure, 13
Coupling, 75, 76, 430
Coupling from the past, 452
Covariance, 114
Covariance function, 524
Cox–Ingersoll–Ross model, 673
Cox–Ross–Rubinstein model, 227
Cramér transform, 591
Cramér–Wold device, 365
Cramér–Lundberg inequality, 239
Curie temperature, 448, 609

Subject Index
709
Curie–Weiss law, 609
Current ﬂow, 468
Cylinder set, 19, 305
D
de Finetti’s theorem, 267, 300
de Morgan’s rule, 2
Dense set, 274
Density, 13, 28, 49, 64, 102, 175
Detailed balance, 465
Diagonal sequence argument, 293
Differentiation lemma, 160
Diffusion process, 646
Dirac measure, 12
Dirichlet distribution, 628
Dirichlet problem, 657
discrete, 463
Dirichlet’s principle, 472
Distribution, 45
Bernoulli, 46
Beta, 49, 270, 354, 627
binomial, 47
Boltzmann, 447
Cauchy, 50, 336, 659
compound Poisson, 369
domain of attraction, 387
exponential, 49
Gamma, 49, 354
Lévy measure, 375
GEM, 631, 633
geometric, 47
hypergeometric, 48
multinomial, 68
negative binomial, 48, 88
normal, 49
Pascal, 48, 88
Poisson, 48
Poisson–Dirichlet, 627, 630, 633
Rademacher, 46
stable, 382, 382
t-, 368
two-sided exponential, 336
uniform, 12, 35
Distribution function, 22
empirical, 129
of a random variable, 45
Domain of attraction, 387
Donsker’s theorem, 549
Doob decomposition, 230
Doob’s inequality, 242
Doob’s regularization, 533
Double points, 616
Drift, 646
Dual space, 186
Duality, 682
Dynamical system, 495
Dynkin’s π-λ theorem, 6
Dynkin’s λ-system, see λ-system
E
Edge, 73
Empirical distribution, 268
Empirical distribution function, 129
Energy dissipation, 472
Entrance time, 411
Entropy, 131, 132, 599
dynamical system, 510, 512
Kolmogorov–Sinai, 512
relative, 599
Equivalent martingale measure, 227
Equivalent measures, 176
Ergodic, 495
Ergodic theorem
individual (Birkhoff), 498
Lp (von Neumann), 500
Escape probability, 474
Etemadi
inequality of, 138
Euler’s prime number formula, 57
Evaluation map, 544
Event, 18, 45
invariant, 80
Exchangeable, 257
Exchangeable σ-algebra, 260
Expectation, 113
Explosion, 407
Exponential distribution, 49
Extension theorem for measures, 25
F
Factorization lemma, 42
Fatou’s lemma, 104
Feller process, 534
Feller property, 534
strong, 681
Feller’s branching diffusion, 557, 673, 686
Feller semigroup, 534
Filtration, 215
right continuous, 532
usual conditions, 532
Fischer–Riesz theorem, 171
Flow, 467
Fourier inversion formula, 333
Fourier series, 174
Fréchet–Shohat, theorem of, 355

710
Subject Index
Free energy, 606
Free lunch, 227
Frobenius problem, 437
Fubini’s theorem, 309
for Itô integrals, 656
for transition kernels, 315
Functional central limit theorem, 549
Fundamental theorem of calculus, 280
G
Galton–Watson process, 92
rescaling, 553
Gambler’s ruin, 237, 456
Gambling strategy, 223
Gamma distribution, 49
Lévy measure, 375
subordinator, 628
GEM distribution, 631, 633
Generated σ-algebra, 6
generated σ-algebra, 36
Generating function, 85
Generator, 6, 404
Geometric Brownian motion, 668
Geometric distribution, 47
Gibbs sampler, 450, 451
Graph, 73
Green, 412
Green function, 412, 463
table, 421
Gronwall’s lemma, 669
H
Haar functions, 537
Hahn’s decomposition theorem, 182
Haploid, 402
Harmonic function, 423, 462
Harmonic measure, 658
Hartman–Wintner theorem, 583
Heat bath algorithm, 450
Hedging strategy, 226
Helly’s theorem, 293
Helmholtz potential, 606
Hilbert–Schmidt norm, 668
Hilbert–Schmidt operator, 316
Hilbert space, 172
Hölder-continuous, 516
Hölder’s inequality, 170
Hopf’s lemma, 498
Hoppe Urne, 633
Hypergeometric distribution, 48
I
Identically distributed, 45
Image measure, 43
Inclusion- exclusion formula, 15
Increasing process, 230
Independence
classes of events, 59
conditional, 266
of events, 55
random variables, 61
Independent and identically distributed (i.i.d.),
61
Independent copy, 430
Independent increments, 613
Indicator function, 5
Indistinguishable, 516
Inequality
Azuma, 222
Bernstein–Chernov, 124
Cauchy–Schwarz, 117
Chebyshev, 121
Chernov, see Bernstein–Chernov
Doob, 242
Etemadi, 138
Hölder, 170
Jensen, 168
Kolmogorov, 135
Markov, see Chebyshev
Minkowski, 171
Young, 170
Inﬁnitely divisible, 367
random measure, 622
Inﬁnitely divisible distribution
stochastic order, 621
Inner product, 172
Inner regularity, 33, 275
Integrable, 98, 113
square, 113
stochastic process, 214
Integral, 95, 96, 98, 99
Itô, 639
Lebesgue, 101, 107
Riemann, 107
stochastic, 541
Stratonovich, 657
Intensity measure, 612
Interior of a set, 274
Invariance principle, 550
Invariant event, 494
Inverse temperature, 606
Inversion formula, 333
Ionescu–Tulcea’s theorem, 317

Subject Index
711
Ising model, 446, 451
Isomorphic, 208
Iterated logarithm
Brownian motion, 573
Hartman–Wintner, 583
Itô formula, 649
discrete, 233
multidimensional, 655
pathwise, 649
Itô integral, 639
Fubini’s theorem, 656
product rule, 654
Itô process, 646
J
Jensen’s inequality, 168, 200
Joint density, 64
Joint distribution, 63
Jordan, decomposition theorem, 183
K
Karhunen–Loève expansion of Brownian
motion, 541
Kelvin, see Thomson
Kesten-Stigum theorem, 256
Khinchin’s law of the iterated logarithm, 583
Kirchhoff’s rule, 467
Kolmogorov–Chentsov theorem, 518
Kolmogorov’s 0–1 law, 71
Kolmogorov’s criterion for weak relative
compactness, 548
Kolmogorov’s extension theorem, 320
Kolmogorov–Sinai entropy, 512
Kolmogorov–Sinai theorem, 512
Kolmogorov’s inequality, 135
Kolmogorov–Smirnov test, 552
Kolmogorov’s three-series theorem, 362
Kullback–Leibler information, 599
L
Lack of memory of the exponential
distribution, 195
λ-system, 3
Laplace operator, 654
Laplace space, 12
Laplace transforms, 161, 331, 554, 613
continuity theorem, 349
Large deviations, 590, 594
Large deviations principle, 594
Lattice distributed, 343
Law of large numbers
speed of convergence, 135
strong, 121, 126, 264
weak, 121
LDP, see Large deviations principle (LDP)
Lebesgue–Borel measure, see Lebesgue
measure
Lebesgue integral, 101
Lebesgue measure, 27, 34
Lebesgue’s convergence theorem, 158
Lebesgue’s decomposition theorem, 177
Lebesgue–Stieltjes integral, 561
Lebesgue–Stieltjes measure, 28
Legendre transform, 590
Level set, 594
Lévy Construction of Brownian motion, 537
Lévy–Khinchin formula, 372, 376
for random measures, 623
Lévy measure, 372, 376
Cauchy distribution, 381
Gamma distribution, 375
general stable distribution, 383
symmetric stable distribution, 382
Lévy metric, 288
Lévy’s continuity theorem, 345
Lévy’s modulus of continuity, 576
Limes inferior, 5
Lindeberg condition, 357
Lindvall’s theorem, 559
Lipschitz continuous, 277
Localising sequence, 565
Locally bounded, 223
Locally compact, 274
Locally ﬁnite, 275
Local martingale, 565
Local time, 232
Logarithmic moment generating function, 590
log-normal distribution, 330
Lower semicontinuous, 594
Lp-bounded, 155
Lp-convergence, 164
Lusin, 279
Lusin’s theorem, 45
LV, 181
Lyapunov condition, 358
M
Markov chain, 392
aperiodic, 436
convergence theorem, 444
coupling, 440
discrete, 399
independent coalescence, 440
invariant distribution, 423

712
Subject Index
invariant measure, 423
irreducible, 414
Monte Carlo method, 446
null recurrent, 412
period of a state, 436
positive recurrent, 412
recurrent, 412
reversible, 465
speed of convergence, 453
transient, 412
weakly irreducible, 414
Markov inequality, 121
conditional, 202
Markov kernel, 204
Markov process, 392
Markov property, 391, 392
strong, 396
Markov semigroup, 322
Martingale, 218
backwards, 263
convergence theorem (L1), 246
convergence theorem (Lp), 247
convergence theorem (a.s.), 245
convergence theorem (backwards), 264
convergence theorems (RCLL), 535
local, 565
square variation, 230
Martingale problem, 678
discrete, 403
well-posed, 680
Martingale representation theorem, 653
Martingale transform, 223
Maximal-ergodic lemma, 498
MCMC, see Markov chain Monte Carlo
method (MCMC)
Mean, 113
Mean ﬁeld, 607
Measurable
Borel, 8
Lebesgue, 34
μ-, 23
map, 36
set, 18
Measurable space, 18
isomorphy, 208
Measure, 12
atom-free, 210
Bernoulli, 31
Borel, 275
harmonic, 658
inner regular, 33
invariant, 423
Lebesgue, 27
locally ﬁnite, 275
outer, 22
outer regular, 33
product, 31, 321
Radon, 275
regular, 275
restriction, 34
σ-ﬁnite, 12
signed, 181
stationary, 423
Measure extension theorem, 20
Measure-preserving map, 495
Measure space, 18
Mellin transform, 334
Mesh size, 562
Method of moments, 351
Metric
complete, 274
convergence in measure, 149
Lévy, 288
on C([0, ∞)), 544
Prohorov, 282
Wasserstein, 430
Metrizable, 274
Metropolis algorithm, 446
Minkowski’s inequality, 171
Mixing, 507
Modiﬁcation, 515
Modulus of continuity, Lévy’s, 576
Moments, 113
absolute, 113
Monotone, 11
Monotonicity principle of Rayleigh, 470
Monte Carlo simulation, 129
Moran Gamma subordinator, 628
Moran model, 403
Morse code, 134
Moving average, 215, 494
Multinomial coefﬁcient, 69
Multinomial distribution, 68
Multi-period binomial model, 227
N
Negative binomial distribution, 48, 88
stochastic order, 627
Normal distribution, 49
multidimensional, 49, 365
Null array, 357
Null recurrent, 412
Null set, 33
O
Ohm’s rule, 468
Open, 8

Subject Index
713
Optional sampling theorem, 234, 239
continuous time, 522
Optional stopping theorem, 235
continuous time, 522
Ornstein–Uhlenbeck process, 667
Orthogonal complement, 172
Orthogonal polynomials, 459
Outer measure, 22
Outer regularity, 33, 275
P
Paley Wiener expansion of Brownian motion,
541
Paley-Zygmund inequality, 120
Parseval’s equation, 536
Partially continuous, 345
Partition function, 606
Partition sequence, admissible, 562
Partition sum, 447
Pascal distribution, 48
Path, 517
Pathwise unique, 678
p.d.f., see Probability distribution function
(p.d.f)
Percolation, 73, 461
Perfect sampling, 452
Period, 436
Petersburg game, 105, 215, 224
p.g.f., see Probability generating function
(p.g.f.)
Phase transition, 448, 607
π-λ theorem, 6
π-system, see ∩-closed
Plancherel’s equation, 334
Points of discontinuity, 11
Poisson approximation, 90
Poisson–Dirichlet distribution, 630, 633
Poisson distribution, 48
compound, 369
Poisson point process, 614
Poisson process, 140, 393
Poisson summation formula, 532
Polarization formula, 563
Polar set, 662
Polish space, 209, 275
Pólya’s theorem, 347
Pólya’s theorem on random walks, 416
Pólya’s urn model, 269, 321, 627
generalized, 408, 411
Portemanteau theorem, 283
Positive recurrent, 412
Positive semideﬁnite, 347
Potential, 468
PPP, see Poisson point process (PPP)
Predictable, 215, 638
Preﬁx code, 131
Premeasure, 12
Previsible, 215, 638
Probability distribution function, 28
Probability generating function, 85
Probability measure, 12
Probability space, 18
Probability vector, 13
Product measurable, 638
Product measure, 29, 31, 308, 319, 321
Product-σ-algebra, 304
Product space, 304
Product topology, 304
Progressively measurable, 638
Prohorov metric, 282, 444
Prohorov’s theorem, 291
Projective limit, 320
Propp-Wilson algorithm, 452
Q
Q-matrix, 404
Q-Q-plot, 363
Quadratic covariation process, 570
R
Rademacher distribution, 46
Radon measure, 275
Radon–Nikodym derivative, 177
Random measure, 612
Random variable, 45
Random walk, 393
Chung–Fuchs theorem, 504
Green function (table), 421
on a graph, 466
Pólya’s theorem, 416
random environment, 490
range, 503
recurrence, 415
symmetric simple, 214
Random walk in a random environment, 490
Rate function, 588, 594
Rayleigh’s monotonicity principle, 470
RCLL, 532
Rectangle, 9
Rectangular cylinder, 306
Recurrent, 412
Reﬂection principle, 397
Brownian motion, 530
Regular conditional distribution, 205
Regularity of measures, 33, 275

714
Subject Index
Rejection sampling, 211
Relatively compact, 274
Replicable, 226
Resistance, 467
Resistance metric, 481
Restriction, 10
Reversible, 446, 465
Riemann integral, 107
Riemann zeta function, 57
Ring, 3
Risk-neutral, 227
S
Schauder functions, 538
SDE, see Stochastic differential equation
(SDE)
Semi-inner product, 172
Semiring, 3
Separable, 274
Separating family, 277
Separating points, 328
Shannon’s theorem, 130
Shift, 496
σ-additive, 12
σ-algebra, 1
exchangeable, 260
invariant, 494
of τ-past, 217
product, 304
tail, 69, 260
σ-compact, 274
σ-ﬁeld, see σ-algebra
σ-ring, 3
σ-subadditive, 12
Signed measure, 181
Simple function, 41
Simple random walk, 466
Singular, 176
Site percolation, 74
Size-biased distribution, 300
Skorohod coupling, 431
Skorohod’s embedding theorem, 577
Slowly varying, 387
Slutzky’s theorem, 285
Source coding theorem, 133
Spectral gap, 454
Spin, 447
Square integrable, 113
Square variation, 562
Square variation process, 230, 566
Stable distribution, 347, 382, 382
Standard deviation, 114
Stationary, 493
Step function, 107
Stirling’s formula, 351, 589
Stochastic differential equation, 665
pathwise uniqueness, 678
strong solution, 666
strong solution under Lipschitz conditions,
669
weak solution, 675
Stochastic integral, 541
discrete, 223
Stochastic kernel, 204
composition, 314
consistent family, 322
product, 313
semigroup, 322
Stochastic matrix, 400
Stochastic order, 431
inﬁnitely divisible distribution, 621
negative binomial distribution, 627
Stochastic process, 213
adapted, 215
binary splitting, 225
duality, 682
explosion, 407
Galton–Watson, 92, 254
Gaussian, 214, 524
independent increments, 214
indistinguishable, 516
integrable, 214
Markov property, 391
modiﬁcation, 515
path, 517
Poisson, 393
predictable, 215, 638
previsible, see Predictable
product measurable, 638
progressively measurable, 638
stationary, 214
stationary increments, 214
stopped, 235
strong Markov property, 396
version, 515
Stochastically larger, 431
Stone–Weierstraß theorem, 328
Stopped process, 235
Stopping time, 216
Strassen’s theorem, 432
Stratonovich integral, 657

Subject Index
715
Strong Markov property, 396
Strong solution, 666
Student’s t-distribution, 368
Sub-probability measures, 276
Subadditive, 12
sequence, 513
Subharmonic, 423
Submartingale, 218
Subordinator, 622
Supermartingale, 218
Symmetric difference, 31
Symmetric simple random walk, 214
T
Tail σ-algebra, 69, 260
t-distribution, 368
Theorem
approximation of measures, 31
Arzelà–Ascoli, 547
Bayes’ formula, 192
Beppo Levi, 104
Berry–Esseen, 363
Bochner, 348
Borel–Cantelli lemma, 58
conditional version, 253
Carathéodory, 20, 25
central limit theorem, 357
Choquet-Deny, 443
Chung–Fuchs, 420, 504
coloring, 625
continuity theorem for Laplace transforms,
349
continuous mapping, 287
Cramér, 590, 597
dominated convergence, 158
Donsker, 550
Dynkin’s π-λ, 6
Egorov, 152
ergodic
Birkhoff, 498
von Neumann, 500
Etemadi, 126
extension to measures, 25
factorization lemma, 42
Fatou’s lemma, 104
de Finetti, 267, 300
Fischer–Riesz, 171
Fréchet–Shohat, 355
Fubini, 309
Fubini for Itô integrals, 656
Fubini for transition kernels, 315
fundamental theorem of calculus, 280
Glivenko–Cantelli, 129
Hahn decomposition, 182
Hartman–Wintner, 583
Helly, 293
Hewitt–Savage, 265
Ionescu–Tulcea, 317
iterated logarithm, 574, 583
Jordan decomposition, 183
Kantorovich–Rubinstein, 430
Kesten-Stigum, 256
Kolmogorov–Chentsov, 518
Kolmogorov’s criterion for weak relative
compactness, 548
Kolmogorov’s extension, 320
Kolmogorov–Sinai, 512
Kolmogorov’s inequality, 135
Kolmogorov’s three-series theorem, 362
large deviations, 590
Lebesgue decomposition, 177
Lévy–Khinchin, 372, 376
Lévy’s continuity theorem, 345
Lindeberg–Feller, 358
Lindvall, 559
Lusin, 45, 279
Markov chain convergence, 444
martingale representation theorem, 653
measure extension, 20
method of moments, 351
monotone convergence, 104
optional sampling, 234, 239
optional sampling, continuous time, 522
optional stopping, 235
optional stopping, continuous time, 522
π-λ, 6
Paley–Wiener–Zygmund, 526
Poisson approximation, 90
Pólya, 347
Pólya’s for random walks, 416
Portemanteau, 283
Prohorov, 291
Rademacher–Menshov, 137
Radon–Nikodym, 177, 251
Rayleigh’s monotonicity principle, 470
regular conditional distribution, 205, 209
Rényi, 617
Sanov, 600
Shannon, 130
Skorohod coupling, 431
Skorohod embedding, 577
Slutzky, 285
Solomon, 491
source coding, 133
Stone–Weierstraß, 328
Strassen, 432
Stroock–Varadhan, 681

716
Subject Index
Thomson’s principle, 472
three-series, 362
Varadhan’s lemma, 603
Yamada–Watanabe, 672
Thomson’s principle, 472
Three-series theorem, 362
Tight, 290
Topological space, 8
Topology, 8
vague, 282
weak, 282
Totally bounded, 275
Totally continuous, 179
Total variation norm, 184
Tower property, 196
Trace, 10
Transformation formula, 43
Transient, 412
Transition kernel, 204, 392
Transition matrix, 399
Transition probabilities, 392
Translation invariant, 401
Trap, 462
Two-stage experiment, 303
U
Uncorrelated, 114
Uniform distribution, 12, 35
Uniformly equicontinuous, 344
Uniformly integrable, 153
Unit ﬂow, 472
Unit network, 467
Upcrossing, 244
Usual conditions, 532
V
Vague convergence, 281
Vague topology, 282
Varadhan’s lemma, 603
Variance, 114
Variation, 561
p -, 562
square, 562
Version, 515
Vitali set, 9
Voter model, 249
W
Wald’s identity, 115
Wasserstein metric, 430
Watson integral, 420
Weak convergence, 281
Weak solution, 675
Weak topology, 282
Weierstraß’s approximation theorem, 123
Weight function, 13
Weiss ferromagnet, 607
White noise, 541
Wiener process, 545
Wright–Fisher diffusion, 683
interacting, 687
Wright’s evolution model, 402
Y
Young’s inequality, 170

