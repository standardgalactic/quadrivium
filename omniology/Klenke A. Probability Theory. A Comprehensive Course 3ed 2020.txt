Universitext
AchimÂ Klenke
Probability 
Theory
AÂ Comprehensive Course
ThirdÂ Edition

Universitext

Universitext
Series Editors
Sheldon Axler
San Francisco State University
Carles Casacuberta
Universitat de Barcelona
John Greenlees
University of Warwick
Angus MacIntyre
Queen Mary University of London
Kenneth Ribet
University of California, Berkeley
Claude Sabbah
Ã‰cole Polytechnique, CNRS, UniversitÃ© Paris-Saclay, Palaiseau
Endre SÃ¼li
University of Oxford
Wojbor A. WoyczyÂ´nski
Case Western Reserve University
Universitext is a series of textbooks that presents material from a wide variety of
mathematical disciplines at masterâ€™s level and beyond. The books, often well class-
tested by their author, may have an informal, personal even experimental approach
to their subject matter. Some of the most successful and established books in the
series have evolved through several editions, always following the evolution of
teaching curricula, into very polished texts.
Thus as research topics trickle down into graduate-level teaching, ï¬rst textbooks
written for new, cutting-edge courses may make their way into Universitext.
More information about this series at http://www.springer.com/series/223

Achim Klenke
Probability Theory
A Comprehensive Course
Third Edition

Achim Klenke
Institut fÂ¨ur Mathematik
Johannes Gutenberg-UniversitÂ¨at Mainz
Mainz, Germany
ISSN 0172-5939
ISSN 2191-6675
(electronic)
Universitext
ISBN 978-3-030-56401-8
ISBN 978-3-030-56402-5
(eBook)
https://doi.org/10.1007/978-3-030-56402-5
Mathematics Subject Classiï¬cation: 60-01, 60B10, 60G42, 60G55, 60H05, 60H10, 60J10, 37-01, 28-01,
82-00
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland
AG 2020
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciï¬cally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microï¬lms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciï¬c statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afï¬liations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG.
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface to the Third Edition
New in the third edition: the sections close with a short â€œtakeawaysâ€ block where
highlights of the section are summarized sometimes on an informal level without
full rigor. Furthermore, in some places â€œreï¬‚ectionâ€ blocks have been added. They
are of different levels of difï¬culty indicated by the number of clubsuits. Finally,
there are more exercises and some new illustrations.
Many people have helped in correcting errors or improving the exposition by
asking questions and I thank all of them. In particular, I would like to thank Philipp
Neumann for many helpful comments.
Mainz, Germany
Achim Klenke
June 2020
v

Preface to the Second Edition
In the second edition of this book, many errors have been corrected. Furthermore,
the text has been extended carefully in many places. In particular, there are more
exercises and a lot more illustrations.
I would like to take the opportunity to thank all of those who helped in improving
the ï¬rst edition of this book, in particular: Michael Diether, Maren Eckhoff, Christo-
pher Grant, Matthias Hammer, Heiko Hoffmann, Martin Hutzenthaler, Martin Kolb,
Manuel Mergens, Thal Nowik, Felix Schneider, Wolfgang Schwarz, and Stephan
Tolksdorf.
A constantly updated list of errors can be found at www.aklenke.de.
Mainz
Achim Klenke
March 2013
vii

Preface to the First Edition
This book is based on two four-hour courses on advanced probability theory
that I have held in recent years at the universities of Cologne and Mainz. It is
implicitly assumed that the reader has a certain familiarity with the basic concepts
of probability theory, although the formal framework will be fully developed in this
book.
The aim of this book is to present the central objects and concepts of probability
theory: random variables, independence, laws of large numbers and central limit
theorems, martingales, exchangeability and inï¬nite divisibility, Markov chains
and Markov processes, as well as their connection with discrete potential theory,
coupling, ergodic theory, Brownian motion and the ItÃ´ integral (including stochastic
differential equations), the Poisson point process, percolation, and the theory of
large deviations.
Measure theory and integration are necessary prerequisites for a systematic
probability theory. We develop it only to the point to which it is needed for our
purposes: construction of measures and integrals, the Radonâ€“Nikodym theorem and
regular conditional distributions, convergence theorems for functions (Lebesgue)
and measures (Prohorov), and construction of measures in product spaces. The
chapters on measure theory do not come as a block at the beginning (although they
are written such that this would be possible; that is, independent of the probabilistic
chapters) but are rather interlaced with probabilistic chapters that are designed to
display the power of the abstract concepts in the more intuitive world of probability
theory. For example, we study percolation theory at the point where we barely have
measures, random variables, and independence; not even the integral is needed. As
the only exception, the systematic construction of independent random variables is
deferred to Chap. 14. Although it is rather a matter of taste, I hope that this setup
helps to motivate the reader throughout the measure-theoretical chapters.
Those readers with a solid measure-theoretical education can skip in particular
the ï¬rst and fourth chapters and might wish only to look up this or that.
In the ï¬rst eight chapters, we lay the foundations that will be needed in all
the subsequent chapters. After that, there are seven more or less independent
parts, consisting of Chaps. 9â€“20, and 23. The chapter on Brownian motion (21)
ix

x
Preface to the First Edition
makes reference to Chaps. 9â€“15. Again, after that, the three blocks consisting of
Chaps. 22, 24, and 25, 26 can be read independently.
I should like to thank all those who read the manuscript and the German
original version of this book and gave numerous hints for improvements: Roland
Alkemper, RenÃ© Billing, Dirk BrÃ¼ggemann, Anne EisenbÃ¼rger, Patrick Jahn, Arnulf
Jentzen, Ortwin Lorenz, L. Mayer, Mario Oeler, Marcus SchÃ¶lpen, my colleagues
Ehrhard Behrends, Wolfgang BÃ¼hler, Nina Gantert, Rudolf GrÃ¼bel, Wolfgang
KÃ¶nig, Peter MÃ¶rters, and Ralph Neininger, and in particular my colleague from
Munich Hans-Otto Georgii. Dr John Preater did a great job language editing the
English manuscript and also pointing out numerous mathematical ï¬‚aws.
I am especially indebted to my wife Katrin for proofreading the English
manuscript and for her patience and support.
I would be grateful for further suggestions, errors, etc. to be sent by e-mail to
math@aklenke.de.
Mainz
Achim Klenke
October 2007

Contents
1
Basic Measure Theory .....................................................
1
1.1
Classes of Sets ......................................................
1
1.2
Set Functions ........................................................
11
1.3
The Measure Extension Theorem ..................................
18
1.4
Measurable Maps ...................................................
36
1.5
Random Variables...................................................
45
2
Independence ...............................................................
53
2.1
Independence of Events ............................................
53
2.2
Independent Random Variables ....................................
61
2.3
Kolmogorovâ€™s 0â€“1 Law.............................................
69
2.4
Example: Percolation ...............................................
73
3
Generating Functions ......................................................
85
3.1
Deï¬nition and Examples ...........................................
85
3.2
Poisson Approximation.............................................
89
3.3
Branching Processes ................................................
91
4
The Integral .................................................................
95
4.1
Construction and Simple Properties ...............................
95
4.2
Monotone Convergence and Fatouâ€™s Lemma ...................... 104
4.3
Lebesgue Integral Versus Riemann Integral ....................... 107
5
Moments and Laws of Large Numbers .................................. 113
5.1
Moments ............................................................ 113
5.2
Weak Law of Large Numbers ...................................... 121
5.3
Strong Law of Large Numbers ..................................... 125
5.4
Speed of Convergence in the Strong LLN ......................... 135
5.5
The Poisson Process ................................................ 139
xi

xii
Contents
6
Convergence Theorems .................................................... 147
6.1
Almost Sure and Measure Convergence ........................... 147
6.2
Uniform Integrability ............................................... 153
6.3
Exchanging Integral and Differentiation........................... 160
7
Lp-Spaces and the Radonâ€“Nikodym Theorem.......................... 163
7.1
Deï¬nitions........................................................... 163
7.2
Inequalities and the Fischerâ€“Riesz Theorem ...................... 165
7.3
Hilbert Spaces....................................................... 172
7.4
Lebesgueâ€™s Decomposition Theorem .............................. 175
7.5
Supplement: Signed Measures ..................................... 179
7.6
Supplement: Dual Spaces........................................... 186
8
Conditional Expectations .................................................. 191
8.1
Elementary Conditional Probabilities.............................. 191
8.2
Conditional Expectations ........................................... 195
8.3
Regular Conditional Distribution .................................. 203
9
Martingales.................................................................. 213
9.1
Processes, Filtrations, Stopping Times............................. 213
9.2
Martingales.......................................................... 218
9.3
Discrete Stochastic Integral ........................................ 223
9.4
Discrete Martingale Representation Theorem and the CRR
Model................................................................ 224
10
Optional Sampling Theorems ............................................. 229
10.1
Doob Decomposition and Square Variation ....................... 229
10.2
Optional Sampling and Optional Stopping ........................ 233
10.3
Uniform Integrability and Optional Sampling..................... 239
11
Martingale Convergence Theorems and Their Applications .......... 241
11.1
Doobâ€™s Inequality ................................................... 241
11.2
Martingale Convergence Theorems ................................ 243
11.3
Example: Branching Process ....................................... 254
12
Backwards Martingales and Exchangeability ........................... 257
12.1
Exchangeable Families of Random Variables ..................... 257
12.2
Backwards Martingales ............................................. 263
12.3
De Finettiâ€™s Theorem ............................................... 266
13
Convergence of Measures.................................................. 273
13.1
A Topology Primer ................................................. 274
13.2
Weak and Vague Convergence ..................................... 281
13.3
Prohorovâ€™s Theorem ................................................ 290
13.4
Application: A Fresh Look at de Finettiâ€™s Theorem............... 300

Contents
xiii
14
Probability Measures on Product Spaces ................................ 303
14.1
Product Spaces ...................................................... 304
14.2
Finite Products and Transition Kernels ............................ 307
14.3
Kolmogorovâ€™s Extension Theorem................................. 317
14.4
Markov Semigroups ................................................ 322
15
Characteristic Functions and the Central Limit Theorem............. 327
15.1
Separating Classes of Functions.................................... 327
15.2
Characteristic Functions: Examples................................ 336
15.3
LÃ©vyâ€™s Continuity Theorem ........................................ 344
15.4
Characteristic Functions and Moments ............................ 349
15.5
The Central Limit Theorem ........................................ 356
15.6
Multidimensional Central Limit Theorem ......................... 365
16
Inï¬nitely Divisible Distributions .......................................... 367
16.1
LÃ©vyâ€“Khinchin Formula............................................ 367
16.2
Stable Distributions ................................................. 381
17
Markov Chains ............................................................. 391
17.1
Deï¬nitions and Construction ....................................... 391
17.2
Discrete Markov Chains: Examples................................ 399
17.3
Discrete Markov Processes in Continuous Time .................. 404
17.4
Discrete Markov Chains: Recurrence and Transience ............ 411
17.5
Application: Recurrence and Transience of Random Walks...... 415
17.6
Invariant Distributions .............................................. 423
17.7
Stochastic Ordering and Coupling ................................. 429
18
Convergence of Markov Chains........................................... 435
18.1
Periodicity of Markov Chains ...................................... 435
18.2
Coupling and Convergence Theorem .............................. 439
18.3
Markov Chain Monte Carlo Method ............................... 445
18.4
Speed of Convergence .............................................. 453
19
Markov Chains and Electrical Networks ................................ 461
19.1
Harmonic Functions ................................................ 462
19.2
Reversible Markov Chains ......................................... 465
19.3
Finite Electrical Networks .......................................... 467
19.4
Recurrence and Transience ......................................... 473
19.5
Network Reduction ................................................. 480
19.6
Random Walk in a Random Environment ......................... 488
20
Ergodic Theory ............................................................. 493
20.1
Deï¬nitions........................................................... 493
20.2
Ergodic Theorems .................................................. 497
20.3
Examples ............................................................ 500
20.4
Application: Recurrence of Random Walks ....................... 502
20.5
Mixing ............................................................... 506
20.6
Entropy .............................................................. 510

xiv
Contents
21
Brownian Motion ........................................................... 515
21.1
Continuous Versions ................................................ 515
21.2
Construction and Path Properties .................................. 522
21.3
Strong Markov Property ............................................ 529
21.4
Supplement: Feller Processes ...................................... 532
21.5
Construction via L2-Approximation ............................... 535
21.6
The Space C([0, âˆ)) ............................................... 544
21.7
Convergence of Probability Measures on C([0, âˆ)) ............. 546
21.8
Donskerâ€™s Theorem ................................................. 549
21.9
Pathwise Convergence of Branching Processes ................... 553
21.10
Square Variation and Local Martingales ........................... 560
22
Law of the Iterated Logarithm............................................ 573
22.1
Iterated Logarithm for the Brownian Motion ...................... 573
22.2
Skorohodâ€™s Embedding Theorem .................................. 576
22.3
Hartmanâ€“Wintner Theorem ........................................ 583
23
Large Deviations ............................................................ 587
23.1
CramÃ©râ€™s Theorem .................................................. 588
23.2
Large Deviations Principle ......................................... 594
23.3
Sanovâ€™s Theorem.................................................... 598
23.4
Varadhanâ€™s Lemma and Free Energy............................... 603
24
The Poisson Point Process ................................................. 611
24.1
Random Measures .................................................. 611
24.2
Properties of the Poisson Point Process............................ 616
24.3
The Poissonâ€“Dirichlet Distribution ................................ 627
25
The ItÃ´ Integral ............................................................. 635
25.1
ItÃ´ Integral with Respect to Brownian Motion .................... 635
25.2
ItÃ´ Integral with Respect to Diffusions ............................ 644
25.3
The ItÃ´ Formula ..................................................... 648
25.4
Dirichlet Problem and Brownian Motion .......................... 657
25.5
Recurrence and Transience of Brownian Motion.................. 659
26
Stochastic Differential Equations ......................................... 665
26.1
Strong Solutions .................................................... 665
26.2
Weak Solutions and the Martingale Problem ...................... 675
26.3
Weak Uniqueness via Duality ...................................... 682
References......................................................................... 691
Notation Index.................................................................... 699
Name Index ....................................................................... 703
Subject Index ..................................................................... 707

Chapter 1
Basic Measure Theory
In this chapter, we introduce the classes of sets that allow for a systematic
treatment of events and random observations in the framework of probability theory.
Furthermore, we construct measures, in particular probability measures, on such
classes of sets. Finally, we deï¬ne random variables as measurable maps.
1.1
Classes of Sets
In the following, let Î© Ì¸= âˆ…be a nonempty set and let A âŠ‚2Î© (set of all subsets of
Î©) be a class of subsets of Î©. Later, Î© will be interpreted as the space of elementary
events and A will be the system of observable events. In this section, we introduce
names for classes of subsets of Î© that are stable under certain set operations and we
establish simple relations between such classes.
Deï¬nition 1.1 A class of sets A is called
â€¢
âˆ©-closed (closed under intersections) or a Ï€-system if A âˆ©B âˆˆA whenever
A, B âˆˆA,
â€¢
Ïƒ-âˆ©-closed (closed under countable1 intersections) if âˆ
n=1 An âˆˆA for any
choice of countably many sets A1, A2, . . . âˆˆA,
â€¢
âˆª-closed (closed under unions) if A âˆªB âˆˆA whenever A, B âˆˆA,
â€¢
Ïƒ-âˆª-closed (closed under countable unions) if âˆ
n=1 An âˆˆA for any choice of
countably many sets A1, A2, . . . âˆˆA,
â€¢
\-closed (closed under differences) if A \ B âˆˆA whenever A, B âˆˆA, and
â€¢
closed under complements if Ac := Î© \ A âˆˆA for any set A âˆˆA.
1By â€œcountableâ€ we always mean either ï¬nite or countably inï¬nite.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_1
1

2
1
Basic Measure Theory
Deï¬nition 1.2 (Ïƒ-algebra) A class of sets A âŠ‚2Î© is called a Ïƒ-algebra if it fulï¬lls
the following three conditions:
(i) Î© âˆˆA.
(ii) A is closed under complements.
(iii) A is closed under countable unions.
Sometimes a Ïƒ-algebra is also named a Ïƒ-ï¬eld. As we will see, we can deï¬ne
probabilities on Ïƒ-algebras in a consistent way. Hence these are the natural classes
of sets to be considered as events in probability theory.
Theorem 1.3 If A is closed under complements, then we have the equivalences
A is âˆ©-closed
â‡â‡’
A is âˆª-closed,
A is Ïƒ- âˆ©-closed
â‡â‡’
A is Ïƒ- âˆª-closed.
Proof The two statements are immediate consequences of de Morganâ€™s rule
(reminder: ( Ai)c
=
 Ac
i ). For example, let A be Ïƒ-âˆ©-closed and let
A1, A2, . . . âˆˆA. Hence
âˆ

n=1
An =
 âˆ

n=1
Ac
n
c
âˆˆA.
Thus A is Ïƒ-âˆª-closed. The other cases can be proved similarly.
âŠ“âŠ”
Theorem 1.4 Assume that A is \-closed. Then the following statements hold:
(i) A is âˆ©-closed.
(ii) If in addition A is Ïƒ-âˆª-closed, then A is Ïƒ-âˆ©-closed.
(iii) Any countable (respectively ï¬nite) union of sets in A can be expressed as a
countable (respectively ï¬nite) disjoint union of sets in A.
Proof
(i) Assume that A, B âˆˆA. Hence also A âˆ©B = A \ (A \ B) âˆˆA.
(ii) Assume that A1, A2, . . . âˆˆA. Hence
âˆ

n=1
An =
âˆ

n=2
(A1 âˆ©An) =
âˆ

n=2
A1 \ (A1 \ An) = A1 \
âˆ

n=2
(A1 \ An) âˆˆA.
(iii) Assume that A1, A2, . . . âˆˆA. Hence a representation of
âˆ

n=1
An as a countable
disjoint union of sets in A is
âˆ

n=1
An = A1âŠ(A2\A1)âŠ((A3\A1)\A2)âŠ(((A4\A1)\A2)\A3)âŠ. . . .
âŠ“âŠ”

1.1
Classes of Sets
3
Remark 1.5 Sometimes the disjoint union of sets is denoted by the symbol . Note
that this is not a new operation but only stresses the fact that the sets involved are
mutually disjoint. â™¦
Deï¬nition 1.6 A class of sets A âŠ‚2Î© is called an algebra if the following three
conditions are fulï¬lled:
(i) Î© âˆˆA.
(ii) A is \-closed.
(iii) A is âˆª-closed.
If A is an algebra, then obviously âˆ…= Î© \ Î© is in A. However, in general, this
property is weaker than (i) in Deï¬nition 1.6.
Theorem 1.7 A class of sets A âŠ‚2Î© is an algebra if and only if the following three
properties hold:
(i) Î© âˆˆA.
(ii) A is closed under complements.
(iii) A is closed under intersections.
Proof This is left as an exercise.
âŠ“âŠ”
Deï¬nition 1.8 A class of sets A âŠ‚2Î© is called a ring if the following three
conditions hold:
(i) âˆ…âˆˆA.
(ii) A is \-closed.
(iii) A is âˆª-closed.
A ring is called a Ïƒ-ring if it is also Ïƒ-âˆª-closed.
Deï¬nition 1.9 A class of sets A âŠ‚2Î© is called a semiring if
(i) âˆ…âˆˆA,
(ii) for any two sets A, B âˆˆA the difference set B \ A is a ï¬nite union of mutually
disjoint sets in A,
(iii) A is âˆ©-closed.
Deï¬nition 1.10 A class of sets A âŠ‚2Î© is called a Î»-system (or Dynkinâ€™s Î»-system)
if
(i) Î© âˆˆA,
(ii) for any two sets A, B âˆˆA with A âŠ‚B, the difference set B \ A is in A, and
(iii) âˆ
n=1 An âˆˆA for any choice of countably many pairwise disjoint sets
A1, A2, . . . âˆˆA.
Example 1.11
(i) For any nonempty set Î©, the classes A = {âˆ…, Î©} and A = 2Î© are the trivial
examples of algebras, Ïƒ-algebras and Î»-systems. On the other hand, A = {âˆ…}
and A = 2Î© are the trivial examples of semirings, rings and Ïƒ-rings.

4
1
Basic Measure Theory
(ii) Let Î© = R. Then A = {A âŠ‚R : A is countable} is a Ïƒ-ring.
(iii) A = {(a, b] : a, b âˆˆR, a â‰¤b} is a semiring on Î© = R (but is not a ring).
(iv) The class of ï¬nite unions of bounded intervals is a ring on Î© = R (but is not
an algebra).
(v) The class of ï¬nite unions of arbitrary (also unbounded) intervals is an algebra
on Î© = R (but is not a Ïƒ-algebra).
(vi) Let E be a ï¬nite nonempty set and let Î© := EN be the set of all E-valued
sequences Ï‰ = (Ï‰n)nâˆˆN. For any Ï‰1, . . . , Ï‰n âˆˆE, let
[Ï‰1, . . . , Ï‰n] := {Ï‰â€² âˆˆÎ© : Ï‰â€²
i = Ï‰i for all i = 1, . . . , n}
be the set of all sequences whose ï¬rst n values are Ï‰1, . . . , Ï‰n. Let A0 = {âˆ…}.
For n âˆˆN, deï¬ne
An := {[Ï‰1, . . . , Ï‰n] : Ï‰1, . . . , Ï‰n âˆˆE}.
(1.1)
Hence A := âˆ
n=0 An is a semiring but is not a ring (if #E > 1).
(vii) Let Î© be an arbitrary nonempty set. Then
A := {A âŠ‚Î© : A or Ac is ï¬nite}
is an algebra. However, if #Î© = âˆ, then A is not a Ïƒ-algebra.
(viii) Let Î© be an arbitrary nonempty set. Then
A := {A âŠ‚Î© : A or Ac is countable}
is a Ïƒ-algebra.
(ix) Every Ïƒ-algebra is a Î»-system.
(x) Let Î© = {1, 2, 3, 4} and A =
	
âˆ…, {1, 2}, {1, 4}, {2, 3}, {3, 4}, {1, 2, 3, 4}

.
Hence A is a Î»-system but is not an algebra. â™¦
Theorem 1.12 (Relations between classes of sets)
(i) Every Ïƒ-algebra also is a Î»-system, an algebra and a Ïƒ-ring.
(ii) Every Ïƒ-ring is a ring, and every ring is a semiring.
(iii) Every algebra is a ring. An algebra on a ï¬nite set Î© is a Ïƒ-algebra.
Proof
(i) This is obvious.
(ii) Let A be a ring. By Theorem 1.4, A is closed under intersections and is hence
a semiring.
(iii) Let A be an algebra. Then âˆ…= Î© \Î© âˆˆA, and hence A is a ring. If in addition
Î© is ï¬nite, then A is ï¬nite. Hence any countable union of sets in A is a ï¬nite
union of sets.
âŠ“âŠ”

1.1
Classes of Sets
5
Deï¬nition 1.13 (liminf and limsup) Let A1, A2, . . . be subsets of Î©. The sets
lim inf
nâ†’âˆAn :=
âˆ

n=1
âˆ

m=n
Am
and
lim sup
nâ†’âˆ
An :=
âˆ

n=1
âˆ

m=n
Am
are called limes inferior and limes superior, respectively, of the sequence (An)nâˆˆN.
Remark 1.14
(i) lim inf and lim sup can be rewritten as
lim inf
nâ†’âˆAn =
	
Ï‰ âˆˆÎ© : #{n âˆˆN : Ï‰ Ì¸âˆˆAn} < âˆ

,
lim sup
nâ†’âˆ
An =
	
Ï‰ âˆˆÎ© : #{n âˆˆN : Ï‰ âˆˆAn} = âˆ

.
In other words, limes inferior is the event where eventually all of the An occur.
On the other hand, limes superior is the event where inï¬nitely many of the An
occur. In particular, Aâˆ—:= lim infnâ†’âˆAn âŠ‚Aâˆ—:= lim supnâ†’âˆAn.
(ii) We deï¬ne the indicator function on the set A by
1A(x) :=

1,
if x âˆˆA,
0,
if x Ì¸âˆˆA.
(1.2)
With this notation,
1Aâˆ—= lim inf
nâ†’âˆ1An
and
1Aâˆ—= lim sup
nâ†’âˆ
1An.
(iii) If A âŠ‚2Î© is a Ïƒ-algebra and if An âˆˆA for every n âˆˆN, then Aâˆ—âˆˆA and
Aâˆ—âˆˆA. â™¦
Proof This is left as an exercise.
âŠ“âŠ”
Theorem 1.15 (Intersection of classes of sets) Let I be an arbitrary index set, and
assume that Ai is a Ïƒ-algebra for every i âˆˆI. Hence the intersection
AI :=
	
A âŠ‚Î© : A âˆˆAi for every i âˆˆI

=

iâˆˆI
Ai
is a Ïƒ-algebra. The analogous statement holds for rings, Ïƒ-rings, algebras and Î»-
systems. However, it fails for semirings.
Proof We give the proof for Ïƒ-algebras only. To this end, we check (i)â€“(iii) of
Deï¬nition 1.2.
(i) Clearly, Î© âˆˆAi for every i âˆˆI, and hence Î© âˆˆAI .

6
1
Basic Measure Theory
(ii) Assume A âˆˆAI . Hence A âˆˆAi for any i âˆˆI. Thus also Ac âˆˆAi for any
i âˆˆI. We conclude that Ac âˆˆAI .
(iii) Assume A1, A2, . . . âˆˆAI. Hence An âˆˆAi for every n âˆˆN and i âˆˆI. Thus
A := âˆ
n=1 An âˆˆAi for every i âˆˆI. We conclude A âˆˆAI .
Counterexample for semirings: Let Î© = {1, 2, 3, 4}, A1 = {âˆ…, Î©, {1}, {2, 3},
{4}} and A2 = {âˆ…, Î©, {1}, {2}, {3, 4}}. Then A1 and A2 are semirings but A1âˆ©A2 =
{âˆ…, Î©, {1}} is not.
âŠ“âŠ”
Theorem 1.16 (Generated Ïƒ-algebra)
Let E âŠ‚2Î©. Then there exists a smallest
Ïƒ-algebra Ïƒ(E) with E âŠ‚Ïƒ(E):
Ïƒ(E) :=

AâŠ‚2Î© is a Ïƒ-algebra
AâŠƒE
A.
Ïƒ(E) is called the Ïƒ-algebra generated by E. E is called a generator of Ïƒ(E).
Similarly, we deï¬ne Î´(E) as the Î»-system generated by E.
Proof A = 2Î© is a Ïƒ-algebra with E âŠ‚A. Hence the intersection is nonempty. By
Theorem 1.15, Ïƒ(E) is a Ïƒ-algebra. Clearly, it is the smallest Ïƒ-algebra that contains
E. For Î»-systems the proof is similar.
âŠ“âŠ”
Remark 1.17 The following three statements hold:
(i) E âŠ‚Ïƒ(E).
(ii) If E1 âŠ‚E2, then Ïƒ(E1) âŠ‚Ïƒ(E2).
(iii) A is a Ïƒ-algebra if and only if Ïƒ(A) = A.
The same statements hold for Î»-systems. Furthermore, Î´(E) âŠ‚Ïƒ(E). â™¦
Theorem 1.18 (âˆ©-closed Î»-system) Let D âŠ‚2Î© be a Î»-system. Then
D is a Ï€-system
â‡â‡’
D is a Ïƒ-algebra.
Proof â€œ â‡ â€
This is obvious.
â€œ â‡’â€
We check (i)â€“(iii) of Deï¬nition 1.2.
(i) Clearly, Î© âˆˆD.
(ii) (Closedness under complements) Let A âˆˆD. Since Î© âˆˆD and by property (ii)
of the Î»-system, we get that Ac = Î© \ A âˆˆD.
(iii) (Ïƒ-âˆª-closedness) Let A, B âˆˆD. By assumption, A âˆ©B âˆˆD, and trivially
A âˆ©B âŠ‚A. Thus A \ B = A \ (A âˆ©B) âˆˆD. This implies that D is \-closed.
Now let A1, A2, . . . âˆˆD. By Theorem 1.4(iii), there exist mutually disjoint
sets B1, B2, . . . âˆˆD with âˆ
n=1 An = âˆ
n=1 Bn âˆˆD.
âŠ“âŠ”
Theorem 1.19 (Dynkinâ€™s Ï€-Î» theorem) If E âŠ‚2Î© is a Ï€-system, then
Ïƒ(E) = Î´(E).

1.1
Classes of Sets
7
Proof â€œâŠƒâ€
This follows from Remark 1.17.
â€œâŠ‚â€
We have to show that Î´(E) is a Ïƒ-algebra. By Theorem 1.18, it is enough to
show that Î´(E) is a Ï€-system. For any B âˆˆÎ´(E) deï¬ne
DB := {A âˆˆÎ´(E) : A âˆ©B âˆˆÎ´(E)}.
In order to show that Î´(E) is a Ï€-system, it is enough to show that
Î´(E) âŠ‚DB
for any B âˆˆÎ´(E).
(1.3)
In order to show that DE is a Î»-system for any E âˆˆÎ´(E), we check (i)â€“(iii) of
Deï¬nition 1.10:
(i) Clearly, Î© âˆ©E = E âˆˆÎ´(E); hence Î© âˆˆDE.
(ii) For anyA, B âˆˆDE with A âŠ‚B, we have (B\A)âˆ©E = (Bâˆ©E)\(Aâˆ©E) âˆˆÎ´(E).
(iii) Assume that A1, A2, . . . âˆˆDE are mutually disjoint. Hence
 âˆ

n=1
An

âˆ©E =
âˆ

n=1
(An âˆ©E) âˆˆÎ´(E).
By assumption, A âˆ©E âˆˆE if A, E âˆˆE; thus E âŠ‚DE if E âˆˆE. By
Remark 1.17(ii), we conclude that Î´(E) âŠ‚DE for any E âˆˆE. Hence we get that
B âˆ©E âˆˆÎ´(E) for any B âˆˆÎ´(E) and E âˆˆE. This implies that E âˆˆDB for any
B âˆˆÎ´(E). Thus E âŠ‚DB for any B âˆˆÎ´(E), and hence (1.3) follows.
âŠ“âŠ”
For an illustration of the inclusions between the classes of sets, see Fig. 1.1.
algebra
Î»-system
Ïƒ-ring
Ïƒ-algebra
ring
semiring
Ïƒ-âˆª-stable
Î© âˆˆA
âˆ©-stable
Î© âˆˆA
Ïƒ-âˆª-stable
âˆª-stable
Fig. 1.1 Inclusions between classes of sets A âŠ‚2Î©.

8
1
Basic Measure Theory
Reï¬‚ection Where does the proof of Theorem 1.19 fail if E is not âˆ©-stable? Find an
example of a class of sets E that is not âˆ©-stable and such that Ïƒ(E) Ì¸= Î´(E). â™ 
We are particularly interested in Ïƒ-algebras that are generated by topologies. The
most prominent role is played by the Euclidean space Rn; however, we will also
consider the (inï¬nite-dimensional)space C([0, 1]) of continuous functions [0, 1] â†’
R. On C([0, 1]) the norm âˆ¥f âˆ¥âˆ= supxâˆˆ[0,1] |f (x)| induces a topology. For the
convenience of the reader, we recall the deï¬nition of a topology.
Deï¬nition 1.20 (Topology) Let Î© Ì¸= âˆ…be an arbitrary set. A class of sets Ï„ âŠ‚2Î©
is called a topology on Î© if it has the following three properties:
(i) âˆ…, Î© âˆˆÏ„.
(ii) A âˆ©B âˆˆÏ„ for any A, B âˆˆÏ„.
(iii) 
AâˆˆF A âˆˆÏ„ for any F âŠ‚Ï„.
The pair (Î©, Ï„) is called a topological space. The sets A âˆˆÏ„ are called open,
and the sets A âŠ‚Î© with Ac âˆˆÏ„ are called closed.
In contrast with Ïƒ-algebras, topologies are closed under ï¬nite intersections only, but
they are also closed under arbitrary unions.
Let d be a metric on Î©, and denote the open ball with radius r > 0 centered at
x âˆˆÎ© by
Br(x) = {y âˆˆÎ© : d(x, y) < r}.
Then the usual class of open sets is the topology
Ï„ =
 
(x,r)âˆˆF Br(x) : F âŠ‚Î© Ã— (0, âˆ)

.
Deï¬nition 1.21 (Borel Ïƒ-algebra) Let (Î©, Ï„) be a topological space. The Ïƒ-
algebra
B(Î©) := B(Î©, Ï„) := Ïƒ(Ï„)
that is generated by the open sets is called the Borel Ïƒ-algebra on Î©. The elements
A âˆˆB(Î©, Ï„) are called Borel sets or Borel measurable sets.
Remark 1.22
In many cases, we are interested in B(Rn), where Rn is equipped
with the Euclidean distance
d(x, y) = âˆ¥x âˆ’yâˆ¥2 =




n

i=1
(xi âˆ’yi)2 .

1.1
Classes of Sets
9
(i) There are subsets of Rn that are not Borel sets. These sets are not easy to
construct like, for example, Vitali sets that can be found in calculus books (see
also [37, Theorem 3.4.4]). Here we do not want to stress this point but state
that, vaguely speaking, all sets that can be constructed explicitly are Borel sets.
(ii) If C âŠ‚Rn is a closed set, then Cc âˆˆÏ„ is in B(Rn) and hence C is a Borel set.
In particular, {x} âˆˆB(Rn) for every x âˆˆRn.
(iii) B(Rn) is not a topology. To show this, let V âŠ‚Rn such that V Ì¸âˆˆB(Rn).
If B(Rn) were a topology, then it would be closed under arbitrary unions. As
{x} âˆˆB(Rn) for all x âˆˆRn, we would get the contradiction V = 
xâˆˆV {x} âˆˆ
B(Rn). â™¦
In most cases the class of open sets that generates the Borel Ïƒ-algebra is too big
to work with efï¬ciently. Hence we aim at ï¬nding smaller (in particular, countable)
classes of sets that generate the Borel Ïƒ-algebra and that are more amenable. In
some of the examples, the elements of the generating class are simpler sets such as
rectangles or compact sets.
We introduce the following notation. We denote by Q the set of rational numbers
and by Q+ the set of strictly positive rational numbers. For a, b âˆˆRn, we write
a < b
if ai < bi
for all i = 1, . . . , n.
(1.4)
For a < b, we deï¬ne the open rectangle as the Cartesian product
(a, b) :=
nÃ—
i=1
(ai, bi) := (a1, b1) Ã— (a2, b2) Ã— Â· Â· Â· Ã— (an, bn).
(1.5)
Analogously,we deï¬ne [a, b], (a, b] and [a, b). Furthermore,we deï¬ne (âˆ’âˆ, b) :=
Ã—n
i=1(âˆ’âˆ, bi), and use an analogous deï¬nition for (âˆ’âˆ, b] and so on. We
introduce the following classes of sets:
E1 := {A âŠ‚Rn : A is open},
E2 := {A âŠ‚Rn : A is closed},
E3 := {A âŠ‚Rn : A is compact},
E4 := {Br(x) : x âˆˆQn, r âˆˆQ+},
E5 := {(a, b) : a, b âˆˆQn, a < b},
E6 := {[a, b) : a, b âˆˆQn, a < b},
E7 := {(a, b] : a, b âˆˆQn, a < b},
E8 := {[a, b] : a, b âˆˆQn, a < b},
E9 := {(âˆ’âˆ, b) : b âˆˆQn},
E10 := {(âˆ’âˆ, b] : b âˆˆQn},
E11 := {(a, âˆ) : a âˆˆQn},
E12 := {[a, âˆ) : a âˆˆQn}.
Theorem 1.23 The Borel Ïƒ-algebra B(Rn) is generated by any of the classes of
sets E1, . . . , E12, that is, B(Rn) = Ïƒ(Ei) for any i = 1, . . . , 12.

10
1
Basic Measure Theory
Proof We show only some of the identities.
(1) By deï¬nition, B(Rn) = Ïƒ(E1).
(2) Let A âˆˆE1. Then Ac âˆˆE2, and hence A = (Ac)c âˆˆÏƒ(E2). It follows that
E1 âŠ‚Ïƒ(E2). By Remark 1.17, this implies Ïƒ(E1) âŠ‚Ïƒ(E2). Similarly, we
obtain Ïƒ(E2) âŠ‚Ïƒ(E1) and hence equality.
(3) Any compact set is closed; hence Ïƒ(E3) âŠ‚Ïƒ(E2). Now let A âˆˆE2. The
sets AK := A âˆ©[âˆ’K, K]n, K âˆˆN, are compact; hence the countable
union A = âˆ
K=1 AK is in Ïƒ(E3). It follows that E2 âŠ‚Ïƒ(E3) and thus
Ïƒ(E2) = Ïƒ(E3).
(4) Clearly, E4 âŠ‚E1; hence Ïƒ(E4) âŠ‚Ïƒ(E1). Now let A âŠ‚Rn be an open set.
For any x âˆˆA, deï¬ne R(x) = min(1, sup{r > 0 : Br(x) âŠ‚A}). Note
that R(x) > 0, as A is open. Let r(x) âˆˆ(R(x)/2, R(x)) âˆ©Q. For any
y âˆˆA and x âˆˆ(BR(y)/3(y)) âˆ©Qn, we have R(x) â‰¥R(y) âˆ’âˆ¥x âˆ’yâˆ¥2 >
2
3R(y), and hence r(x) > 1
3R(y) and thus y âˆˆBr(x)(x). It follows that
A = 
xâˆˆAâˆ©Qn Br(x)(x) is a countable union of sets from E4 and is hence
in Ïƒ(E4). We have shown that E1 âŠ‚Ïƒ(E4). By Remark 1.17, this implies
Ïƒ(E1) âŠ‚Ïƒ(E4).
(5â€“12) Exhaustion arguments similar to that in (4) also work for rectangles. If in (4)
we take open rectangles instead of open balls Br(x), we get B(Rn) = Ïƒ(E5).
For example, we have
nÃ—
i=1
[ai, bi) =
âˆ

k=1
nÃ—
i=1

ai âˆ’1
k , bi

âˆˆÏƒ(E5).
The other inclusions Ei âŠ‚Ïƒ(Ej) can be shown similarly.
âŠ“âŠ”
Remark 1.24 Any of the classes E1, E2, E3, E5, . . . , E12 (but not E4) is a Ï€-system.
Hence, the Borel Ïƒ-algebra equals the generated Î»-system: B(Rn) = Î´(Ei) for i =
1, 2, 3, 5, . . ., 12. In addition, the classes E4, . . . , E12 are countable. This is a crucial
property that will be needed later. â™¦
Deï¬nition 1.25 (Trace of a class of sets) Let A âŠ‚2Î© be an arbitrary class of
subsets of Î© and let A âˆˆ2Î© \ {âˆ…}. The class
A
A := {A âˆ©B : B âˆˆA} âŠ‚2A
(1.6)
is called the trace of A on A or the restriction of A to A.
Theorem 1.26 Let A âŠ‚Î© be a nonempty set and let A be a Ïƒ-algebra on Î© or
any of the classes of Deï¬nitions 1.6â€“1.9. Then A
A is a class of sets of the same type
as A; however, on A instead of Î©. For Î»-systems this is not true in general.
Proof This is left as an exercise.
âŠ“âŠ”

1.2
Set Functions
11
Takeaways Ïƒ-algebras are classes of sets that are stable under countable
intersections and unions. They can be generated by classes with less structure
(algebras, rings, semirings), but also by classes with a different structure (e.g.,
a topology). In the case of a topology we get a Borel Ïƒ-algebra, that can also
be generated using simple sets such as rectangles.
Exercise 1.1.1 Let A be a semiring. Show that any countable (respectively ï¬nite)
union of sets in A can be written as a countable (respectively ï¬nite) disjoint union
of sets in A. â™£
Exercise 1.1.2 Give a counterexample that shows that, in general, the union AâˆªAâ€²
of two Ïƒ-algebras need not be a Ïƒ-algebra. â™£
Exercise 1.1.3 Let (Î©1, d1) and (Î©2, d2) be metric spaces and let f : Î©1 â†’Î©2
be an arbitrary map. Denote by Uf =
	
x âˆˆÎ©1 : f is discontinuous at x

the set
of points of discontinuity of f . Show that Uf âˆˆB(Î©1).
Hint: First show that for any Îµ > 0 and Î´ > 0 the set
UÎ´,Îµ
f
:= 	x âˆˆÎ©1 :
there are y, z âˆˆBÎµ(x) with d2(f (y), f (z)) > Î´
is open (where BÎµ(x) = {y âˆˆÎ©1 : d1(x, y) < Îµ}). Then construct Uf from such
UÎ´,Îµ
f . â™£
Exercise 1.1.4 Let Î© be an uncountably inï¬nite set and A = Ïƒ({Ï‰} : Ï‰ âˆˆÎ©).
Show that
A =
	
A âŠ‚Î© : A is countable or Ac is countable

.
â™£
Exercise 1.1.5 Let A be a ring on the set Î©. Show that A is an Abelian algebraic
ring with multiplication â€œ âˆ©â€ and addition â€œ â–³â€. â™£
1.2
Set Functions
We aim at assigning to each â€œeventâ€ (which will be formalised later) a number that
can be interpreted as the probability for the event to occur. To this end, we ï¬rst
study more general set functions that assign nonnegative numbers to subsets. Then
we describe those properties necessary for such a function to qualify as a probability
assignment.
Deï¬nition 1.27 Let A âŠ‚2Î© and let Î¼ : A â†’[0, âˆ] be a set function. We say that
Î¼ is
(i) monotone if Î¼(A) â‰¤Î¼(B) for any two sets A, B âˆˆA with A âŠ‚B,

12
1
Basic Measure Theory
(ii) additive if Î¼
 n
i=1
Ai

=
n
i=1
Î¼(Ai) for any choice of ï¬nitely many mutually
disjoint sets A1, . . . , An âˆˆA with
n
i=1
Ai âˆˆA,
(iii) Ïƒ-additive if
Î¼
 âˆ

i=1
Ai

=
âˆ

i=1
Î¼(Ai) for any choice of countably many
mutually disjoint sets A1, A2, . . . âˆˆA with
âˆ

i=1
Ai âˆˆA,
(iv) subadditive if for any choice of ï¬nitely many sets A, A1, . . . , An âˆˆA with
A âŠ‚
n
i=1
Ai, we have Î¼(A) â‰¤
n
i=1
Î¼(Ai), and
(v) Ïƒ-subadditive if for any choice of countably many sets A, A1, A2, . . . âˆˆA
with A âŠ‚
âˆ

i=1
Ai, we have Î¼(A) â‰¤
âˆ

i=1
Î¼(Ai) .
Deï¬nition 1.28 Let A be a semiring and let Î¼ : A â†’[0, âˆ] be a set function with
Î¼(âˆ…) = 0. Î¼ is called a
â€¢
content if Î¼ is additive,
â€¢
premeasure if Î¼ is Ïƒ-additive,
â€¢
measure if Î¼ is a premeasure and A is a Ïƒ-algebra, and
â€¢
probability measure if Î¼ is a measure and Î¼(Î©) = 1.
Deï¬nition 1.29 Let A be a semiring. A content Î¼ on A is called
(i) ï¬nite if Î¼(A) < âˆfor every A âˆˆA and
(ii) Ïƒ-ï¬nite if there exists a sequence of sets Î©1, Î©2, . . . âˆˆA such that Î© =
âˆ

n=1
Î©n and such that Î¼(Î©n) < âˆfor all n âˆˆN.
Example 1.30 (Contents, measures)
(i) Let Ï‰ âˆˆÎ© and Î´Ï‰(A) = 1A(Ï‰) (see (1.2)). Then Î´Ï‰ is a probability measure
on any Ïƒ-algebra A âŠ‚2Î©. Î´Ï‰ is called the Dirac measure for the point Ï‰.
(ii) Let Î© be a ï¬nite nonempty set. By
Î¼(A) := #A
#Î©
for A âŠ‚Î©,
we deï¬ne a probability measure on A = 2Î©. This Î¼ is called the uniform
distribution on Î©. For this distribution, we introduce the symbol UÎ© := Î¼.
The resulting triple (Î©, A, UÎ©) is called a Laplace space.
(iii) Let Î© be countably inï¬nite and let
A := {A âŠ‚Î© : #A < âˆor #Ac < âˆ}.

1.2
Set Functions
13
Then A is an algebra. The set function Î¼ on A deï¬ned by
Î¼(A) =

0,
if A is ï¬nite,
âˆ,
if Ac is ï¬nite,
is a content but is not a premeasure. Indeed, Î¼ 
Ï‰âˆˆÎ©{Ï‰} = Î¼(Î©) = âˆ,
but 
Ï‰âˆˆÎ© Î¼ ({Ï‰}) = 0.
(iv) Let (Î¼n)nâˆˆN be a sequence of measures (premeasures, contents) and let
(Î±n)nâˆˆN be a sequence of nonnegative numbers. Then also Î¼ := âˆ
n=1 Î±nÎ¼n
is a measure (premeasure, content).
(v) Let Î© be an (at most) countable nonempty set and let A = 2Î©. Further, let
(pÏ‰)Ï‰âˆˆÎ© be nonnegative numbers. Then A â†’Î¼(A) := 
Ï‰âˆˆA pÏ‰ deï¬nes
a Ïƒ-ï¬nite measure on 2Î©. We call p = (pÏ‰)Ï‰âˆˆÎ© the weight function of Î¼.
The number pÏ‰ is called the weight of Î¼ at point Ï‰.
(vi) If in (v) the sum 
Ï‰âˆˆÎ© pÏ‰ equals one, then Î¼ is a probability measure. In
this case, we interpret pÏ‰ as the probability of the elementary event Ï‰. The
vector p = (pÏ‰)Ï‰âˆˆÎ© is called a probability vector.
(vii) If in (v) pÏ‰ = 1 for every Ï‰ âˆˆÎ©, then Î¼ is called counting measure on Î©.
If Î© is ï¬nite, then so is Î¼.
(viii) Let A be the ring of ï¬nite unions of intervals (a, b] âŠ‚R. For a1 < b1 <
a2 < b2 < . . . < bn and A =
n
i=1
(ai, bi], deï¬ne
Î¼(A) =
n

i=1
(bi âˆ’ai).
Then Î¼ is a Ïƒ-ï¬nite content on A (even a premeasure) since âˆ
n=1(âˆ’n, n] =
R and Î¼((âˆ’n, n]) = 2n < âˆfor all n âˆˆN.
(ix) Let f : R â†’[0, âˆ) be continuous. In a similar way to (viii), we deï¬ne
Î¼f (A) =
n

i=1
 bi
ai
f (x) dx.
Then Î¼f is a Ïƒ-ï¬nite content on A (even a premeasure). The function f
is called the density of Î¼ and plays a role similar to the weight function p
in (v). â™¦
Lemma 1.31 (Properties of contents) Let A be a semiring and let Î¼ be a content
on A. Then the following statements hold.
(i) If A is a ring, then Î¼(A âˆªB) + Î¼(A âˆ©B) = Î¼(A) + Î¼(B) for any two sets
A, B âˆˆA.
(ii) Î¼ is monotone. If A is a ring, then Î¼(B) = Î¼(A) + Î¼(B \ A) for any two sets
A, B âˆˆA with A âŠ‚B.

14
1
Basic Measure Theory
(iii) Î¼ is subadditive. If Î¼ is Ïƒ-additive, then Î¼ is also Ïƒ-subadditive.
(iv) If A is a ring, then
âˆ

n=1
Î¼(An) â‰¤Î¼
 âˆ

n=1
An

for any choice of countably many
mutually disjoint sets A1, A2, . . . âˆˆA with
âˆ

n=1
An âˆˆA.
Proof
(i) Note that A âˆªB = A âŠ(B \ A) and B = (A âˆ©B) âŠ(B \ A). As Î¼ is additive,
we obtain
Î¼(A âˆªB) = Î¼(A) + Î¼(B \ A)
and
Î¼(B) = Î¼(A âˆ©B) + Î¼(B \ A).
This implies (i).
(ii) Let A âŠ‚B. Since A âˆ©B = A, we obtain Î¼(B) = Î¼(A âŠ(B \ A)) = Î¼(A) +
Î¼(B \ A) if B \ A âˆˆA. In particular, this is true if A is a ring. If A is only a
semiring, then there exists an n âˆˆN and mutually disjoint sets C1, . . . , Cn âˆˆA
such that B \ A = n
i=1 Ci. Hence Î¼(B) = Î¼(A) + n
i=1 Î¼(Ci) â‰¥Î¼(A) and
thus Î¼ is monotone.
(iii) Let n âˆˆN and A, A1, . . . , An âˆˆA with A âŠ‚n
i=1 Ai. Deï¬ne B1 = A1 and
Bk = Ak \
kâˆ’1

i=1
Ai =
kâˆ’1

i=1
(Ak \ (Ak âˆ©Ai))
for k = 2, . . . , n.
By the deï¬nition of a semiring, any Ak \ (Ak âˆ©Ai) is a ï¬nite disjoint union of
sets in A. Hence there exists a ck âˆˆN and sets Ck,1, . . . , Ck,ck âˆˆA such that
ck
i=1 Ck,i = Bk âŠ‚Ak. Similarly, there exist dk âˆˆN and Dk,1, . . . , Dk,dk âˆˆA
such that Ak \ Bk = dk
i=1 Dk,i. Since Î¼ is additive, we have
Î¼(Ak) =
ck

i=1
Î¼(Ck,i) +
dk

i=1
Î¼(Dk,i) â‰¥
ck

i=1
Î¼(Ck,i).
Again due to additivity and monotonicity, we get
Î¼(A) = Î¼
 n

k=1
ck

i=1
(Ck,i âˆ©A)

=
n

k=1
ck

i=1
Î¼(Ck,i âˆ©A)
â‰¤
n

k=1
ck

i=1
Î¼(Ck,i) â‰¤
n

k=1
Î¼(Ak).
Hence Î¼ is subadditive. By a similar argument, Ïƒ-subadditivity follows from
Ïƒ-additivity.

1.2
Set Functions
15
(iv) Let A be a ring and let A =
âˆ

n=1
An âˆˆA. Since Î¼ is additive (and thus
monotone), we have by (ii)
m

n=1
Î¼(An) = Î¼
 m

n=1
An

â‰¤Î¼(A)
for any m âˆˆN.
It follows that
âˆ

n=1
Î¼(An) â‰¤Î¼(A).
âŠ“âŠ”
Remark 1.32 The inequality in (iv) can be strict (see Example 1.30(iii)). In other
words, there are contents that are not premeasures. â™¦
If A is a ring an Î¼ is a content on A, then by Lemma 1.31, for A, B âˆˆE such that
Î¼(A), Î¼(B) < âˆ, we have
Î¼(A âˆªB) = Î¼(A) + Î¼(B) âˆ’Î¼(A âˆ©B).
Similarly, for three sets A, B, C âˆˆA with ï¬nite content, we have
Î¼(A âˆªB âˆªC) =Î¼(A âˆªB) + Î¼(C) âˆ’Î¼((A âˆ©C) âˆª(B âˆ©C))
=Î¼(A) + Î¼(B) + Î¼(C)
âˆ’Î¼(A âˆ©B) âˆ’Î¼(A âˆ©C) âˆ’Î¼(B âˆ©C) + Î¼(A âˆ©B âˆ©C).
Note that the sign of each expression changes with the number of sets that are cut.
This statement will now be generalised to an arbitrary ï¬nite number of sets.
Theorem 1.33 (Inclusionâ€“exclusion formula)
Let A be a ring and let Î¼ be a
content on A. Let n âˆˆN and A1, . . . , An âˆˆA such that Î¼(A1 âˆª. . . âˆªAn) < âˆ.
Then the following inclusion and exclusion formulas hold:
Î¼(A1 âˆª. . . âˆªAn) =
n

k=1
(âˆ’1)kâˆ’1

{i1,...,ik}âŠ‚{1,...,n}
Î¼(Ai1 âˆ©. . . âˆ©Aik),
Î¼(A1 âˆ©. . . âˆ©An) =
n

k=1
(âˆ’1)kâˆ’1

{i1,...,ik}âŠ‚{1,...,n}
Î¼(Ai1 âˆª. . . âˆªAik).
Here summation is over all subsets of {1, . . . , n} with k elements.
Proof This is left as an exercise. Hint: Use induction on n.
âŠ“âŠ”
The next goal is to characterize Ïƒ-subadditivity by a certain continuity property
(Theorem 1.36). To this end, we agree on the following conventions.

16
1
Basic Measure Theory
Deï¬nition 1.34 Let A, A1, A2, . . . be sets. We write
â€¢
An â†‘A and say that (An)nâˆˆN increases to A if A1 âŠ‚A2 âŠ‚. . . and âˆ
n=1 An =
A, and
â€¢
An â†“A and say that (An)nâˆˆN decreases to A if A1 âŠƒA2 âŠƒA3 âŠƒ. . . and
âˆ
n=1 An = A.
Assume that we have a sequence of events A1, A2, . . . that cannot all occur jointly.
Then we should have that the probability for A1, . . . , An to occur jointly vanishes
as n â†’âˆ. This is a property of continuity that cannot be deduced from the axioms
of a content and thus must be postulated separately.
Deï¬nition 1.35 (Continuity of contents) Let Î¼ be a content on the ring A.
(i) Î¼ is called lower semicontinuous if Î¼(An)
nâ†’âˆ
âˆ’â†’Î¼(A) for any A âˆˆA and
any sequence (An)nâˆˆN in A with An â†‘A.
(ii) Î¼ is called upper semicontinuous if Î¼(An)
nâ†’âˆ
âˆ’â†’Î¼(A) for any A âˆˆA and
any sequence (An)nâˆˆN in A with Î¼(An) < âˆfor some (and then eventually
all) n âˆˆN and An â†“A.
(iii) Î¼ is called âˆ…-continuous if (ii) holds for A = âˆ….
In the deï¬nition of upper semicontinuity, we needed the assumption Î¼(An) < âˆ
since otherwise we would not even have âˆ…-continuity for an example as simple as the
counting measure Î¼ on (N, 2N). Indeed, An := {n, n+1, . . .} â†“âˆ…but Î¼(An) = âˆ
for all n âˆˆN.
Theorem 1.36 (Continuity and premeasure) Let Î¼ be a content on the ring A.
Consider the following ï¬ve properties.
(i) Î¼ is Ïƒ-additive (and hence a premeasure).
(ii) Î¼ is Ïƒ-subadditive.
(iii) Î¼ is lower semicontinuous.
(iv) Î¼ is âˆ…-continuous.
(v) Î¼ is upper semicontinuous.
Then the following implications hold:
(i) â‡â‡’(ii) â‡â‡’(iii) â‡’(iv) â‡â‡’(v).
If Î¼ is ï¬nite, then we also have (iv) â‡’(iii).
Proof â€œ(i) â‡’(ii)â€
Let A, A1, A2, . . . âˆˆA with A âŠ‚âˆ
i=1 Ai. Deï¬ne B1 = A1
and Bn = An \ nâˆ’1
i=1 Ai âˆˆA for n = 2, 3, . . .. Then A = âˆ
n=1(A âˆ©Bn). Since Î¼
is monotone and Ïƒ-additive, we infer
Î¼(A) =
âˆ

n=1
Î¼(A âˆ©Bn) â‰¤
âˆ

n=1
Î¼(An).

1.2
Set Functions
17
Hence Î¼ is Ïƒ-subadditive.
â€œ(ii) â‡’(i)â€
This follows from Lemma 1.31(iv).
â€œ(i) â‡’(iii)â€
Let Î¼ be a premeasure and A âˆˆA. Let (An)nâˆˆN be a sequence in
A such that An â†‘A and let A0 = âˆ…. Then
Î¼(A) =
âˆ

i=1
Î¼(Ai \ Aiâˆ’1) = lim
nâ†’âˆ
n

i=1
Î¼(Ai \ Aiâˆ’1) = lim
nâ†’âˆÎ¼(An).
â€œ(iii) â‡’(i)â€
Assume now that (iii) holds. Let B1, B2, . . . âˆˆA be mutually
disjoint, and assume that B =
âˆ

n=1
Bn âˆˆA. Deï¬ne An =
n
i=1
Bi for all n âˆˆN. Then
it follows from (iii) that
Î¼(B) = lim
nâ†’âˆÎ¼(An) =
âˆ

i=1
Î¼(Bi).
Hence Î¼ is Ïƒ-additive and therefore a premeasure.
â€œ(iv) â‡’(v)â€
Let A, A1, A2, . . . âˆˆA with An â†“A and Î¼(A1) < âˆ. Deï¬ne
Bn = An \ A âˆˆA for all n âˆˆN. Then Bn â†“âˆ…. This implies Î¼(An) âˆ’Î¼(A) =
Î¼(Bn)
nâ†’âˆ
âˆ’â†’0.
â€œ(v) â‡’(iv)â€
This is evident.
â€œ(iii) â‡’(iv)â€
Let A1, A2, . . . âˆˆA with An â†“âˆ…and Î¼(A1) < âˆ. Then A1 \
An âˆˆA for any n âˆˆN and A1 \ An â†‘A1. Hence
Î¼(A1) = lim
nâ†’âˆÎ¼(A1 \ An) = Î¼(A1) âˆ’lim
nâ†’âˆÎ¼(An).
Since Î¼(A1) < âˆ, we have lim
nâ†’âˆÎ¼(An) = 0.
â€œ(iv) â‡’(iii)â€
(for ï¬nite Î¼) Assume that Î¼(A) < âˆfor every A âˆˆA and that
Î¼ is âˆ…-continuous. Let A, A1, A2, . . . âˆˆA with An â†‘A. Then we have A \ An â†“âˆ…
and
Î¼(A) âˆ’Î¼(An) = Î¼(A \ An)
nâ†’âˆ
âˆ’â†’0.
Hence (iii) follows.
âŠ“âŠ”
Example 1.37 (Compare Example 1.30(iii).) Let Î© be a countable set, and deï¬ne
A = {A âŠ‚Î© : #A < âˆor #Ac < âˆ},
Î¼(A) =

0,
if A is ï¬nite,
âˆ,
if A is inï¬nite.
Then Î¼ is an âˆ…-continuous content but not a premeasure. â™¦

18
1
Basic Measure Theory
Deï¬nition 1.38
(i) A pair (Î©, A) consisting of a nonempty set Î© and a Ïƒ-algebra A âŠ‚2Î© is
called a measurable space. The sets A âˆˆA are called measurable sets. If
Î© is at most countably inï¬nite and if A = 2Î©, then the measurable space
(Î©, 2Î©) is called discrete.
(ii) A triple (Î©, A, Î¼) is called a measure space if (Î©, A) is a measurable space
and if Î¼ is a measure on A.
(iii) If in addition Î¼(Î©) = 1, then (Î©, A, Î¼) is called a probability space. In this
case, the sets A âˆˆA are called events.
(iv) The set of all ï¬nite measures on (Î©, A) is denoted by Mf (Î©) := Mf (Î©, A).
The subset of probability measures is denoted by M1(Î©) := M1(Î©, A).
Finally, the set of Ïƒ-ï¬nite measures on (Î©, A) is denoted by MÏƒ(Î©, A).
Takeaways In this section, we have compiled a wish list of the properties
that a probability assignment should have: Ïƒ-additivity and normalization
(Deï¬nition 1.28). We have seen how Ïƒ-additivity follows from additivity
(which is easier to check) and continuity (Theorem 1.36). In order for the
notion of Ïƒ-additivity to make sense, the underlying class of sets must be
closed under countable set operations; that is, it must be a Ïƒ-algebra. This
shows that the concepts formed in Sect. 1.1 are sensible.
Exercise 1.2.1 Let A = {(a, b] âˆ©Q : a, b âˆˆR, a â‰¤b}. Deï¬ne Î¼ : A â†’[0, âˆ)
by Î¼

(a, b] âˆ©Q

= b âˆ’a. Show that A is a semiring and Î¼ is a content on A that
is lower and upper semicontinuous but is not Ïƒ-additive. â™£
1.3
The Measure Extension Theorem
In this section, we construct measures Î¼ on Ïƒ-algebras. The starting point will be
to deï¬ne the values of Î¼ on a smaller class of sets; that is, on a semiring. Under a
mild consistency condition, the resulting set function can be extended to the whole
Ïƒ-algebra.
Before we develop the complete theory, we begin with two examples: The
Lebesgue measure and the inï¬nite product measure. While the Lebesgue measure
is ubiquitous in analysis, the inï¬nite product measure plays an important role in
probability theory for modelling inï¬nitely many independent events.
Example 1.39 (Lebesgue measure) Let n âˆˆN and let
A = {(a, b] : a, b âˆˆRn, a â‰¤b}

1.3
The Measure Extension Theorem
19
be the semiring of half open rectangles (a, b] âŠ‚Rn (see (1.5)). The n-dimensional
volume of such a rectangle is
Î¼((a, b]) =
n

i=1
(bi âˆ’ai).
Can we extend the set function Î¼ to a (uniquely determined) measure on the Borel
Ïƒ-algebra B(Rn) = Ïƒ(A)? We will see that this is indeed possible. The resulting
measure is called Lebesgue measure (or sometimes Lebesgueâ€“Borel measure) Î» on

Rn, B(Rn)

. â™¦
Example 1.40 (Product measure, Bernoulli measure) We construct a measure for
an inï¬nitely often repeated random experiment with ï¬nitely many possible out-
comes. Let E be the set of possible outcomes. For e âˆˆE, let pe â‰¥0 be the
probability that e occurs. Hence 
eâˆˆE pe = 1. For a ï¬xed realization of the
repeated experiment, let Ï‰1, Ï‰2, . . . âˆˆE be the observed outcomes. Hence the
space of all possible outcomes of the repeated experiment is Î© = EN. As in
Example 1.11(vi), we deï¬ne the set of all sequences whose ï¬rst n values are
Ï‰1, . . . , Ï‰n:
[Ï‰1, . . . , Ï‰n] := {Ï‰â€² âˆˆÎ© : Ï‰â€²
i = Ï‰i for any i = 1, . . ., n}.
(1.7)
Let A0 = {âˆ…}. For n âˆˆN, deï¬ne the class of cylinder sets that depend only on the
ï¬rst n coordinates
An := {[Ï‰1, . . . , Ï‰n] : Ï‰1, . . . , Ï‰n âˆˆE},
(1.8)
and let A := âˆ
n=0 An.
We interpret [Ï‰1, . . . , Ï‰n] as the event where the outcome of the ï¬rst experiment
is Ï‰1, the outcome of the second experiment is Ï‰2 and ï¬nally the outcome of the
nth experiment is Ï‰n. The outcomes of the other experiments do not play a role for
the occurrence of this event. As the individual experiments ought to be independent,
we should have for any choice Ï‰1, . . . , Ï‰n âˆˆE that the probability of the event
[Ï‰1, . . . , Ï‰n] is the product of the probabilities of the individual events; that is,
Î¼([Ï‰1, . . . , Ï‰n]) =
n

i=1
pÏ‰i.
This formula deï¬nes a content Î¼ on the semiring A, and our aim is to extend Î¼ in a
unique way to a probability measure on the Ïƒ-algebra Ïƒ(A) that is generated by A.
Before we do so, we make the following deï¬nition. Deï¬ne the (ultra-)metric d
on Î© by
d(Ï‰, Ï‰â€²) =

2âˆ’inf{nâˆˆN: Ï‰nÌ¸=Ï‰â€²
n},
if Ï‰ Ì¸= Ï‰â€²,
0,
if Ï‰ = Ï‰â€².
(1.9)

20
1
Basic Measure Theory
Hence (Î©, d) is a compact metric space. Clearly,
[Ï‰1, . . . , Ï‰n] = B2âˆ’n(Ï‰) = {Ï‰â€² âˆˆÎ© : d(Ï‰, Ï‰â€²) < 2âˆ’n}.
The complement of [Ï‰1, . . . , Ï‰n] is an open set, as it is the union of (#E)n âˆ’1 open
balls
[Ï‰1, . . . , Ï‰n]c =

(Ï‰â€²
1,...,Ï‰â€²n)Ì¸=(Ï‰1,...,Ï‰n)
[Ï‰â€²
1, . . . , Ï‰â€²
n].
Since Î© is compact, the closed subset [Ï‰1, . . . , Ï‰n] is compact. As in Theorem 1.23,
it can be shown that Ïƒ(A) = B(Î©, d).
Exercise: Prove the statements made above. â™¦
Reï¬‚ection Why is there no inï¬nite product measure if 
e p(e) âˆˆ(0, âˆ) \ {1}? â™ 
The main result of this chapter is CarathÃ©odoryâ€™s measure extension theorem.
Theorem 1.41 (CarathÃ©odory)
Let A âŠ‚2Î© be a ring and let Î¼ be a Ïƒ-ï¬nite
premeasure on A. There exists a unique measure Î¼ on Ïƒ(A) such that Î¼(A) = Î¼(A)
for all A âˆˆA. Furthermore, ËœÎ¼ is Ïƒ-ï¬nite.
We prepare for the proof of this theorem with a couple of lemmas. In fact, we will
show a slightly stronger statement in Theorem 1.53.
Lemma 1.42 (Uniqueness by an âˆ©-closed generator) Let (Î©, A, Î¼) be a Ïƒ-ï¬nite
measure space and let E âŠ‚A be a Ï€-system that generates A. Assume that there
exist sets Î©1, Î©2, . . . âˆˆE such that âˆ
n=1 Î©n = Î© and Î¼(Î©n) < âˆfor all n âˆˆN.
Then Î¼ is uniquely determined by the values Î¼(E), E âˆˆE.
If Î¼ is a probability measure, the existence of the sequence (Î©n)nâˆˆN is not needed.
Proof Let Î½ be a (possibly different) Ïƒ-ï¬nite measure on (Î©, A) such that
Î¼(E) = Î½(E)
for every E âˆˆE.
Let E âˆˆE with Î¼(E) < âˆ. Consider the class of sets
DE =
	
A âˆˆA : Î¼(A âˆ©E) = Î½(A âˆ©E)

.
In order to show that DE is a Î»-system, we check the properties of Deï¬nition 1.10:
(i) Clearly, Î© âˆˆDE.
(ii) Let A, B âˆˆDE with A âŠƒB. Then
Î¼ ((A \ B) âˆ©E) = Î¼(A âˆ©E) âˆ’Î¼(B âˆ©E)
= Î½(A âˆ©E) âˆ’Î½(B âˆ©E) = Î½ ((A \ B) âˆ©E) .
Hence A \ B âˆˆDE.

1.3
The Measure Extension Theorem
21
(iii) Let A1, A2, . . . âˆˆDE be mutually disjoint and A =
âˆ

n=1
An. Then
Î¼(A âˆ©E) =
âˆ

n=1
Î¼(An âˆ©E) =
âˆ

n=1
Î½(An âˆ©E) = Î½(A âˆ©E).
Hence A âˆˆDE.
Clearly, E âŠ‚DE; hence Î´(E) âŠ‚DE. Since E is a Ï€-system, Theorem 1.19 yields
A âŠƒDE âŠƒÎ´(E) = Ïƒ(E) = A.
Hence DE = A.
This implies Î¼(A âˆ©E) = Î½(A âˆ©E) for any A âˆˆA and E âˆˆE with Î¼(E) < âˆ.
Now let Î©1, Î©2, . . . âˆˆE be a sequence such that âˆ
n=1 Î©n = Î© and Î¼(Î©n) < âˆ
for all n âˆˆN. Let En := n
i=1 Î©i, n âˆˆN, and E0 = âˆ…. Hence En = n
i=1(Ec
iâˆ’1 âˆ©
Î©i). For any A âˆˆA and n âˆˆN, we thus get
Î¼(A âˆ©En) =
n

i=1
Î¼(A âˆ©Ec
iâˆ’1) âˆ©Î©i
 =
n

i=1
Î½(A âˆ©Ec
iâˆ’1) âˆ©Î©i
 = Î½(A âˆ©En).
Since En â†‘Î© and since Î¼ and Î½ are lower semicontinuous, we infer
Î¼(A) = lim
nâ†’âˆÎ¼(A âˆ©En) = lim
nâ†’âˆÎ½(A âˆ©En) = Î½(A).
The additional statement is trivial as ËœE := E âˆª{Î©} is a Ï€-system that generates
A, and the value Î¼(Î©) = 1 is given. Hence one can choose the constant sequence
En = Î©, n âˆˆN. However, note that it is not enough to assume that Î¼ is ï¬nite. In
this case, in general, the total mass Î¼(Î©) is not uniquely determined by the values
Î¼(E), E âˆˆE; see Example 1.45(ii).
âŠ“âŠ”
Reï¬‚ection Where in the previous proof did we exploit the âˆ©-stability? What goes
wrong if âˆ©-stability is missing? Compare Example 1.45. â™ 
Example 1.43 Let Î© = Z and E = 	En : n âˆˆZ
 where En = (âˆ’âˆ, n] âˆ©Z. Then
E is a Ï€-system and Ïƒ(E) = 2Î©. Hence a ï¬nite measure Î¼ on (Î©, 2Î©) is uniquely
determined by the values Î¼(En), n âˆˆZ.
However, a Ïƒ-ï¬nite measure on Z is not uniquely determined by the values on E:
Let Î¼ be the counting measure on Z and let Î½ = 2Î¼. Hence Î¼(E) = âˆ= Î½(E) for
all E âˆˆE. In order to distinguish Î¼ and Î½ one needs a generator that contains sets of
ï¬nite measure (of Î¼). Do the sets ËœFn = [âˆ’n, n] âˆ©Z, n âˆˆN do the trick? Indeed, for
any Ïƒ-ï¬nite measure Î¼, we have Î¼( ËœFn) < âˆfor all n âˆˆN. However, the sets ËœFn
do not generate 2Î© (but which Ïƒ-algebra?). We get things to work out better if we
modify the deï¬nition: Fn = [âˆ’n/2, (n+1)/2]âˆ©Z. Now Ïƒ({Fn, n âˆˆN}) = 2Î©, and

22
1
Basic Measure Theory
hence E = {Fn, n âˆˆN} is a Ï€-system that generates 2Î© and such that Î¼(Fn) < âˆ
for all n âˆˆN. The conditions of the theorem are fulï¬lled as Fn â†‘Î©. â™¦
Example 1.44 (Distribution function) A probability measure Î¼ on the space
Rn, B(Rn) is uniquely determined by the values Î¼((âˆ’âˆ, b]) (where (âˆ’âˆ, b] =
Ã—n
i=1(âˆ’âˆ, bi], b âˆˆRn). In fact, these sets form a Ï€-system that generates
B(Rn) (see Theorem 1.23). In particular, a probability measure Î¼ on R is uniquely
determined by its distribution function F : R â†’[0, 1], x â†’Î¼((âˆ’âˆ, x]). â™¦
Example 1.45
(i) Let Î© = {1, 2, 3, 4} and E = {	1, 2}, {2, 3}
. Clearly, Ïƒ(E) = 2Î© but E is not
a Ï€-system. In fact, here a probability measure Î¼ is not uniquely determined
by the values, say Î¼({1, 2}) = Î¼({2, 3}) =
1
2. We give just two different
possibilities: Î¼ = 1
2Î´1 + 1
2Î´3 and Î¼â€² = 1
2Î´2 + 1
2Î´4.
(ii) Let Î© = {1, 2} and E = {{1}}. Then E is a Ï€-system that generates 2Î©. Hence
a probability measure Î¼ is uniquely determined by the value Î¼({1}). However,
a ï¬nite measure is not determined by its value on {1}, as Î¼ = 0 and Î½ = Î´2 are
different ï¬nite measures that agree on E. â™¦
Lemma 1.42 yields uniqueness in CarathÃ©odoryâ€™s theorem. The more challenging
part is to come up with a candidate Î¼ for the extension of the pre-measure in the
ï¬rst place. The strategy is to deï¬ne a number Î¼âˆ—(E) for each E âˆˆ2Î© by covering E
with elements of E and then determine the total content. The smallest value Î¼âˆ—(E)
that can be obtained by such an approximation is called the outer measure of E.
The second step is to check that Î¼âˆ—is a measure at least on Ïƒ(E). This gives a good
candidate for Î¼.
Deï¬nition 1.46 (Outer measure) A set function Î¼âˆ—: 2Î© â†’[0, âˆ] is called an
outer measure if
(i) Î¼âˆ—(âˆ…) = 0, and
(ii) Î¼âˆ—is monotone,
(iii) Î¼âˆ—is Ïƒ-subadditive.
Lemma 1.47 Let A âŠ‚2Î© be an arbitrary class of sets with âˆ…âˆˆA and let Î¼
be a nonnegative set function on A with Î¼(âˆ…) = 0. For A âŠ‚Î©, deï¬ne the set of
countable coverings F with sets F âˆˆA:
U(A) =

F âŠ‚A : F is at most countable and A âŠ‚

FâˆˆF
F

.
Deï¬ne
Î¼âˆ—(A) := inf
 
FâˆˆF
Î¼(F) : F âˆˆU(A)

,

1.3
The Measure Extension Theorem
23
where inf âˆ…= âˆ. Then Î¼âˆ—is an outer measure. If in addition Î¼ is Ïƒ-subadditive,
then Î¼âˆ—(A) = Î¼(A) for all A âˆˆA.
Proof We check properties (i)â€“(iii) of an outer measure.
(i) Since âˆ…âˆˆA, we have {âˆ…} âˆˆU(âˆ…); hence Î¼âˆ—(âˆ…) = 0.
(ii) If A âŠ‚B, then U(A) âŠƒU(B); hence Î¼âˆ—(A) â‰¤Î¼âˆ—(B).
(iii) Let An âŠ‚Î© for any n âˆˆN and let A âŠ‚âˆ
n=1 An. We show that Î¼âˆ—(A) â‰¤
âˆ
n=1 Î¼âˆ—(An). Without loss of generality, assume Î¼âˆ—(An) < âˆand hence
U(An) Ì¸= âˆ…for all n âˆˆN. Fix Îµ > 0. For every n âˆˆN, choose a covering
Fn âˆˆU(An) such that

FâˆˆFn
Î¼(F) â‰¤Î¼âˆ—(An) + Îµ 2âˆ’n.
Then F := âˆ
n=1 Fn âˆˆU(A) and
Î¼âˆ—(A) â‰¤

FâˆˆF
Î¼(F) â‰¤
âˆ

n=1

FâˆˆFn
Î¼(F) â‰¤
âˆ

n=1
Î¼âˆ—(An) + Îµ.
Let A âˆˆA. Since {A} âˆˆU(A), we have Î¼âˆ—(A) â‰¤Î¼(A). If Î¼ is Ïƒ-subadditive,
then for any F âˆˆU(A), we have 
FâˆˆF Î¼(F) â‰¥Î¼(A); hence Î¼âˆ—(A) â‰¥Î¼(A).
âŠ“âŠ”
Deï¬nition 1.48 (Î¼âˆ—-measurable sets) Let Î¼âˆ—be an outer measure. A set A âˆˆ2Î©
is called Î¼âˆ—-measurable if
Î¼âˆ—(A âˆ©E) + Î¼âˆ—(Ac âˆ©E) = Î¼âˆ—(E)
for any E âˆˆ2Î©.
(1.10)
We write M(Î¼âˆ—) = {A âˆˆ2Î© : A is Î¼âˆ—-measurable}.
Lemma 1.49 A âˆˆM(Î¼âˆ—) if and only if
Î¼âˆ—(A âˆ©E) + Î¼âˆ—(Ac âˆ©E) â‰¤Î¼âˆ—(E)
for any E âˆˆ2Î©.
Proof As Î¼âˆ—is subadditive, the other inequality is trivial.
âŠ“âŠ”
Lemma 1.50 M(Î¼âˆ—) is an algebra.
Proof We check properties (i)â€“(iii) of an algebra from Theorem 1.7.
(i) Î© âˆˆM(Î¼âˆ—) is evident.
(ii) (Closedness under complements)
By deï¬nition, A âˆˆM(Î¼âˆ—)
â‡â‡’Ac âˆˆ
M(Î¼âˆ—).

24
1
Basic Measure Theory
(iii) (Ï€-system)
Let A, B âˆˆM(Î¼âˆ—) and E âˆˆ2Î©. Then
Î¼âˆ—((A âˆ©B) âˆ©E) + Î¼âˆ—
(A âˆ©B)c âˆ©E

= Î¼âˆ—(A âˆ©B âˆ©E) + Î¼âˆ—(Ac âˆ©B âˆ©E) âˆª(Ac âˆ©Bc âˆ©E) âˆª(A âˆ©Bc âˆ©E)
â‰¤Î¼âˆ—(A âˆ©B âˆ©E) + Î¼âˆ—(Ac âˆ©B âˆ©E)
+ Î¼âˆ—(Ac âˆ©Bc âˆ©E) + Î¼âˆ—(A âˆ©Bc âˆ©E)
= Î¼âˆ—(B âˆ©E) + Î¼âˆ—(Bc âˆ©E)
= Î¼âˆ—(E).
Here we used A âˆˆM(Î¼âˆ—) in the last but one equality and B âˆˆM(Î¼âˆ—) in the
last equality.
âŠ“âŠ”
Lemma 1.51 An outer measure Î¼âˆ—is Ïƒ-additive on M(Î¼âˆ—).
Proof Let A, B âˆˆM(Î¼âˆ—) with A âˆ©B = âˆ…. Then
Î¼âˆ—(A âˆªB) = Î¼âˆ—(A âˆ©(A âˆªB)) + Î¼âˆ—(Ac âˆ©(A âˆªB)) = Î¼âˆ—(A) + Î¼âˆ—(B).
Inductively, we get (ï¬nite) additivity. By deï¬nition, Î¼âˆ—is Ïƒ-subadditive; hence we
conclude by Theorem 1.36 that Î¼âˆ—is also Ïƒ-additive.
âŠ“âŠ”
Lemma 1.52 If Î¼âˆ—is an outer measure, then M(Î¼âˆ—) is a Ïƒ-algebra. In particular,
Î¼âˆ—is a measure on M(Î¼âˆ—).
Proof By Lemma 1.50, M(Î¼âˆ—) is an algebra and hence a Ï€-system. By Theo-
rem 1.18, it is sufï¬cient to show that M(Î¼âˆ—) is a Î»-system.
Hence, let A1, A2, . . . âˆˆM(Î¼âˆ—) be mutually disjoint, and deï¬ne A :=
âˆ

n=1
An.
We have to show A âˆˆM(Î¼âˆ—); that is,
Î¼âˆ—(A âˆ©E) + Î¼âˆ—(Ac âˆ©E) â‰¤Î¼âˆ—(E)
for any E âˆˆ2Î©.
(1.11)
Let Bn =
n
i=1
Ai for all n âˆˆN. For all n âˆˆN, we have
Î¼âˆ—(E âˆ©Bn+1) = Î¼âˆ—
(E âˆ©Bn+1) âˆ©Bn

+ Î¼âˆ—
(E âˆ©Bn+1) âˆ©Bc
n

= Î¼âˆ—(E âˆ©Bn) + Î¼âˆ—(E âˆ©An+1).

1.3
The Measure Extension Theorem
25
Inductively, we get Î¼âˆ—(E âˆ©Bn) = n
i=1 Î¼âˆ—(E âˆ©Ai). The monotonicity of Î¼âˆ—now
implies that
Î¼âˆ—(E) = Î¼âˆ—(E âˆ©Bn) + Î¼âˆ—(E âˆ©Bc
n) â‰¥Î¼âˆ—(E âˆ©Bn) + Î¼âˆ—(E âˆ©Ac)
=
n

i=1
Î¼âˆ—(E âˆ©Ai) + Î¼âˆ—(E âˆ©Ac).
Letting n â†’âˆand using the Ïƒ-subadditivity of Î¼âˆ—, we conclude
Î¼âˆ—(E) â‰¥
âˆ

i=1
Î¼âˆ—(E âˆ©Ai) + Î¼âˆ—(E âˆ©Ac) â‰¥Î¼âˆ—(E âˆ©A) + Î¼âˆ—(E âˆ©Ac).
Hence (1.11) holds and the proof is complete.
âŠ“âŠ”
We come to an extension theorem for measures that makes slightly weaker
assumptions than CarathÃ©odoryâ€™s theorem (Theorem 1.41).
Theorem 1.53 (Extension theorem for measures) Let A be a semiring and let Î¼ :
A â†’[0, âˆ] be an additive, Ïƒ-subadditive and Ïƒ-ï¬nite set function with Î¼(âˆ…) = 0.
Then there is a unique Ïƒ-ï¬nite measure Î¼ : Ïƒ(A) â†’[0, âˆ] such that Î¼(A) =
Î¼(A) for all A âˆˆA.
Proof As A is a Ï€-system, uniqueness follows by Lemma 1.42.
In order to establish the existence of Î¼, we deï¬ne as in Lemma 1.47
Î¼âˆ—(A) := inf
 
FâˆˆF
Î¼(F) : F âˆˆU(A)

for any A âˆˆ2Î©.
By Lemma 1.47, Î¼âˆ—is an outer measure and Î¼âˆ—(A) = Î¼(A) for any A âˆˆA. We
have to show that M(Î¼âˆ—) âŠƒÏƒ(A). Since M(Î¼âˆ—) is a Ïƒ-algebra (Lemma 1.52), it
is enough to show A âŠ‚M(Î¼âˆ—).
To this end, let A âˆˆA and E âˆˆ2Î© with Î¼âˆ—(E) < âˆ. Fix Îµ > 0. Then there is a
sequence E1, E2, . . . âˆˆA such that
E âŠ‚
âˆ

n=1
En
and
âˆ

n=1
Î¼(En) â‰¤Î¼âˆ—(E) + Îµ.
Deï¬ne Bn := En âˆ©A âˆˆA . Since A is a semiring, for every n âˆˆN there is an
mn âˆˆN and sets C1
n, . . . , Cmn
n
âˆˆA such that En \ A = En \ Bn =
mn

k=1
Ck
n. Hence
E âˆ©A âŠ‚
âˆ

n=1
Bn,
E âˆ©Ac âŠ‚
âˆ

n=1
mn

k=1
Ck
n
and
En = Bn âŠ
mn

k=1
Ck
n.

26
1
Basic Measure Theory
By the deï¬nition of the outer measure and since Î¼ is assumed to be (ï¬nitely)
additive, we get
Î¼âˆ—(E âˆ©A) + Î¼âˆ—(E âˆ©Ac) â‰¤
âˆ

n=1
Î¼(Bn) +
âˆ

n=1
mn

k=1
Î¼(Ck
n)
=
âˆ

n=1

Î¼(Bn) +
mn

k=1
Î¼(Ck
n)

=
âˆ

n=1
Î¼(En)
â‰¤Î¼âˆ—(E) + Îµ.
Hence Î¼âˆ—(E âˆ©A) + Î¼âˆ—(E âˆ©Ac) â‰¤Î¼âˆ—(E) and thus A âˆˆM(Î¼âˆ—), which implies
A âŠ‚M(Î¼âˆ—). Now deï¬ne Î¼ : Ïƒ(A) â†’[0, âˆ], A â†’Î¼âˆ—(A). By Lemma 1.51, Î¼ is
a measure and Î¼ is Ïƒ-ï¬nite since Î¼ is Ïƒ-ï¬nite.
âŠ“âŠ”
Reï¬‚ection In Theorem 1.53, in general, Î¼ cannot be extended to a measure on all
of 2Î©. Why? At which point would the proof fail? Usually it is difï¬cult to show in a
speciï¬c situation that the extension to 2Î© is impossible. We refer to analysis books
like [37] where Vitali sets are used in order to show that the Lebesgue measure
cannot be deï¬ned on 2R. â™ â™ 
Example 1.54 (Lebesgue measure, continuation of Example 1.39) We aim at
extending the volume Î¼((a, b]) = n
i=1(bi âˆ’ai) that was deï¬ned on the class
of rectangles A = {(a, b] : a, b âˆˆRn, a â‰¤b} to the Borel Ïƒ-algebra B(Rn). In
order to check the assumptions of Theorem 1.53, we only have to check that Î¼ is
Ïƒ-subadditive. To this end, let (a, b], (a(1), b(1)], (a(2), b(2)], . . . âˆˆA with
(a, b] âŠ‚
âˆ

k=1
(a(k), b(k)].
We show that
Î¼((a, b]) â‰¤
âˆ

k=1
Î¼(a(k), b(k)].
(1.12)
For this purpose we use a compactness argument to reduce (1.12) to ï¬nite additivity.
Fix Îµ > 0. For any k âˆˆN, choose bÎµ(k) > b(k) such that
Î¼

(a(k), bÎµ(k)]

â‰¤Î¼

(a(k), b(k)]

+ Îµ 2âˆ’kâˆ’1.

1.3
The Measure Extension Theorem
27
Further choose aÎµ âˆˆ(a, b) such that Î¼((aÎµ, b]) â‰¥Î¼((a, b]) âˆ’Îµ
2. Now [aÎµ, b] is
compact and
âˆ

k=1
(a(k), bÎµ(k)) âŠƒ
âˆ

k=1
(a(k), b(k)] âŠƒ(a, b] âŠƒ[aÎµ, b],
whence there exists a K0 such that K0
k=1(a(k), bÎµ(k)) âŠƒ(aÎµ, b]. As Î¼ is (ï¬nitely)
subadditive (see Lemma 1.31(iii)), we obtain
Î¼((a, b]) â‰¤Îµ
2 + Î¼((aÎµ, b]) â‰¤Îµ
2 +
K0

k=1
Î¼((a(k), bÎµ(k)])
â‰¤Îµ
2 +
K0

k=1

Îµ 2âˆ’kâˆ’1 + Î¼((a(k), b(k)])

â‰¤Îµ +
âˆ

k=1
Î¼((a(k), b(k)]).
Letting Îµ â†“0 yields (1.12); hence Î¼ is Ïƒ-subadditive. â™¦
Combining the last example with Theorem 1.53, we have shown the following
theorem.
Theorem 1.55 (Lebesgue measure)
There exists a uniquely determined measure
Î»n on

Rn, B(Rn)

with the property that
Î»n((a, b]) =
n

i=1
(bi âˆ’ai)
for all a, b âˆˆRn with a < b.
Î»n is called the Lebesgue measure on Rn, B(Rn) or Lebesgueâ€“Borel measure.
Example 1.56 (Lebesgueâ€“Stieltjes measure) Let Î© = R and A = {(a, b] : a, b âˆˆ
R, a â‰¤b}. A is a semiring and Ïƒ(A) = B(R), where B(R) is the Borel Ïƒ-algebra
on R. Furthermore, let F : R â†’R be monotone increasing and right continuous.
We deï¬ne a set function
ËœÎ¼F : A â†’[0, âˆ),
(a, b] â†’F(b) âˆ’F(a).
Clearly, ËœÎ¼F (âˆ…) = 0 and ËœÎ¼F is additive.
Let (a, b], (a(1), b(1)], (a(2), b(2)], . . . âˆˆA such that (a, b] âŠ‚âˆ
n=1(a(n),
b(n)] and a < b. Fix Îµ > 0 and choose aÎµ âˆˆ(a, b) such that F(aÎµ) âˆ’F(a) < Îµ/2.
This is possible, as F is right continuous. For any k âˆˆN, choose bÎµ(k) > b(k) such
that
F(bÎµ(k)) âˆ’F(b(k)) < Îµ 2âˆ’kâˆ’1.

28
1
Basic Measure Theory
As in Example 1.54, it can be shown that ËœÎ¼F ((a, b]) â‰¤Îµ +âˆ
k=1 ËœÎ¼F ((a(k), b(k)]).
This implies that ËœÎ¼F is Ïƒ-subadditive. By Theorem 1.53, we can extend ËœÎ¼F
uniquely to a Ïƒ-ï¬nite measure Î¼F on B(R). â™¦
Deï¬nition 1.57 (Lebesgueâ€“Stieltjes measure) The measure Î¼F on

R, B(R)

deï¬ned by
Î¼F((a, b]) = F(b) âˆ’F(a)
for all a, b âˆˆR with a < b
is called the Lebesgueâ€“Stieltjes measure with distribution function F.
Example 1.58 Important special cases for the Lebesgueâ€“Stieltjes measure are the
following:
(i) If F(x) = x, then Î¼F = Î»1 is the Lebesgue measure on R.
(ii) Let f : R â†’[0, âˆ) be continuous and let F(x) =
 x
0
f (t) dt for all x âˆˆR.
Then Î¼F is the extension of the premeasure with density f that was deï¬ned in
Example 1.30(ix).
(iii) Let x1, x2, . . . âˆˆR and Î±n â‰¥0 for all n âˆˆN such that âˆ
n=1 Î±n < âˆ.
Then F = âˆ
n=1 Î±n 1[xn,âˆ) is the distribution function of the ï¬nite measure
Î¼F = âˆ
n=1 Î±nÎ´xn.
(iv) Let x1, x2, . . . âˆˆR such that Î¼ = âˆ
n=1 Î´xn is a Ïƒ-ï¬nite measure. Then Î¼
is a Lebesgueâ€“Stieltjes measure if and only if the sequence (xn)nâˆˆN does not
have a limit point. Indeed, if (xn)nâˆˆN does not have a limit point, then by the
Bolzanoâ€“WeierstraÃŸ theorem, #{n âˆˆN : xn âˆˆ[âˆ’K, K]} < âˆfor every
K > 0. If we let F(x) = #{n âˆˆN : xn âˆˆ[0, x]} for x â‰¥0 and F(x) =
âˆ’#{n âˆˆN : xn âˆˆ(x, 0)} for x < 0, then Î¼ = Î¼F . On the other hand, if Î¼ is a
Lebesgueâ€“Stieltjes measure, this is Î¼ = Î¼F for some F, then #{n âˆˆN : xn âˆˆ
(âˆ’K, K]} = F(K) âˆ’F(âˆ’K) < âˆfor all K > 0; hence (xn)nâˆˆN does not
have a limit point.
(v) If lim
xâ†’âˆ

F(x) âˆ’F(âˆ’x)

= 1, then Î¼F is a probability measure. â™¦
We will now have a closer look at the case where Î¼F is a probability measure.
Deï¬nition 1.59 (Distribution function) A right continuous monotone increasing
function F : R â†’[0, 1] with F(âˆ’âˆ) :=
lim
xâ†’âˆ’âˆF(x) = 0 and F(âˆ) :=
lim
xâ†’âˆF(x) = 1 is called a (proper) probability distribution function (p.d.f.). If we
only have F(âˆ) â‰¤1 instead of F(âˆ) = 1, then F is called a (possibly) defective
p.d.f. If Î¼ is a (sub-) probability measure on R, B(R), then FÎ¼ : x â†’Î¼((âˆ’âˆ, x])
is called the distribution function of Î¼.
Clearly, FÎ¼ is right continuous and FÎ¼(âˆ’âˆ) = 0, since Î¼ is upper semicontinuous
and ï¬nite (Theorem 1.36). Since Î¼ is lower semicontinuous, we have FÎ¼(âˆ) =
Î¼(R); hence FÎ¼ is indeed a (possibly defective) distribution function if Î¼ is a (sub-)
probability measure.

1.3
The Measure Extension Theorem
29
The argument of Example 1.56 yields the following theorem.
Theorem 1.60 The map Î¼ â†’FÎ¼ is a bijection from the set of probability measures
on

R, B(R)

to the set of probability distribution functions, respectively from the
set of sub-probability measures to the set of defective distribution functions.
We have established that every ï¬nite measure on

R, B(R)

is a Lebesgueâ€“Stieltjes
measure for some function F. For Ïƒ-ï¬nite measures, the corresponding statement
does not hold in this generality as we saw in Example 1.58(iv).
We come now to a theorem that combines Theorem 1.55 with the idea of
Lebesgueâ€“Stieltjes measures. Later we will see that the following theorem is valid
in greater generality. In particular, the assumption that the factors are of Lebesgueâ€“
Stieltjes type can be dropped.
Theorem 1.61 (Finite products of measures)
Let n âˆˆN and let Î¼1, . . . , Î¼n be
ï¬nite measures or, more generally, Lebesgueâ€“Stieltjes measures on R, B(R). Then
there exists a unique Ïƒ-ï¬nite measure Î¼ on Rn, B(Rn) such that
Î¼((a, b]) =
n

i=1
Î¼i((ai, bi])
for all a, b âˆˆRn with a < b.
We call Î¼ =:
n
 
i=1
Î¼i the product measure of the measures Î¼1, . . . , Î¼n.
Proof The proof is the same as for Theorem 1.55. One has to check that the intervals
(a, bÎµ] and so on can be chosen such that Î¼((a, bÎµ]) < Î¼((a, b]) + Îµ. Here we
employ the right continuity of the increasing function Fi that belongs to Î¼i. The
details are left as an exercise.
âŠ“âŠ”
Remark 1.62 Later we will see in Theorem 14.14 that the statement holds even
for arbitrary Ïƒ-ï¬nite measures Î¼1, . . . , Î¼n on arbitrary (even different) measurable
spaces. One can even construct inï¬nite products if all factors are probability spaces
(Theorem 14.39). â™¦
Example 1.63 (Inï¬nite product measure, continuation of Example 1.40) Let E be a
ï¬nite set and let Î© = EN be the space of E-valued sequences. Further, let (pe)eâˆˆE
be a probability vector. Deï¬ne a content Î¼ on A = {[Ï‰1, . . . , Ï‰n] : Ï‰1, . . . , Ï‰n âˆˆ
E, n âˆˆN} by
Î¼([Ï‰1, . . . , Ï‰n]) =
n

i=1
pÏ‰i.
We aim at extending Î¼ to a measure on Ïƒ(A). In order to check the assumptions
of Theorem 1.53, we have to show that Î¼ is Ïƒ-subadditive. As in the preceding
example, we use a compactness argument.

30
1
Basic Measure Theory
Let A, A1, A2, . . . âˆˆA and A âŠ‚âˆ
n=1 An. We are done if we can show that
there exists an N âˆˆN such that
A âŠ‚
N

n=1
An.
(1.13)
Indeed, due to the (ï¬nite) subadditivity of Î¼ (see Lemma 1.31(iii)), this implies
Î¼(A) â‰¤
N
n=1
Î¼(An) â‰¤
âˆ

n=1
Î¼(An); hence Î¼ is Ïƒ-subadditive.
We now give two different proofs for (1.13).
1. Proof.
The metric d from (1.9) induces the product topology on Î©; hence, as
remarked in Example 1.40, (Î©, d) is a compact metric space. Every A âˆˆA
is closed and thus compact. Since every An is also open, A can be covered by
ï¬nitely many An; hence (1.13) holds.
2. Proof.
We now show by elementary means the validity of (1.13). The procedure
imitates the proof that Î© is compact. Let Bn := A\n
i=1 Ai. We assume Bn Ì¸= âˆ…
for all n âˆˆN in order to get a contradiction. By Dirichletâ€™s pigeonhole principle
(recall that E is ï¬nite), we can choose Ï‰1 âˆˆE such that [Ï‰1] âˆ©Bn Ì¸= âˆ…for
inï¬nitely many n âˆˆN. Since B1 âŠƒB2 âŠƒ. . ., we obtain
[Ï‰1] âˆ©Bn Ì¸= âˆ…
for all n âˆˆN.
Successively choose Ï‰2, Ï‰3, . . . âˆˆE in such a way that
[Ï‰1, . . . , Ï‰k] âˆ©Bn Ì¸= âˆ…
for all k, n âˆˆN.
Bn is a disjoint union of certain sets Cn,1, . . . , Cn,mn âˆˆA. Hence, for every
n âˆˆN there is an in âˆˆ{1, . . . , mn} such that [Ï‰1, . . . , Ï‰k] âˆ©Cn,in Ì¸= âˆ…for
inï¬nitely many k âˆˆN. Since [Ï‰1] âŠƒ[Ï‰1, Ï‰2] âŠƒ. . ., we obtain
[Ï‰1, . . . , Ï‰k] âˆ©Cn,in Ì¸= âˆ…
for all k, n âˆˆN.
For ï¬xed n âˆˆN and large k, we have [Ï‰1, . . . , Ï‰k] âŠ‚Cn,in. Hence Ï‰ =
(Ï‰1, Ï‰2, . . .) âˆˆCn,in âŠ‚Bn. This implies âˆ
n=1 Bn Ì¸= âˆ…, contradicting the
assumption. â™¦
Combining the last example with Theorem 1.53, we have shown the following
theorem.
Theorem 1.64 (Product measure, Bernoulli measure) Let E be a ï¬nite nonempty
set and Î© = EN. Let (pe)eâˆˆE be a probability vector. Then there exists a unique
probability measure Î¼ on Ïƒ(A) = B(Î©) such that
Î¼([Ï‰1, . . . , Ï‰n]) =
n

i=1
pÏ‰i
for all Ï‰1, . . . , Ï‰n âˆˆE and n âˆˆN.

1.3
The Measure Extension Theorem
31
Î¼ is called the product measure or Bernoulli measure on Î© with weights (pe)eâˆˆE.
We write

eâˆˆE peÎ´e
âŠ—N := Î¼. The Ïƒ-algebra (2E)âŠ—N := Ïƒ(A) is called the
product Ïƒ-algebra on Î©.
We will study product measures in a systematic way in Chap. 14.
The measure extension theorem yields an abstract statement of existence and
uniqueness for measures on Ïƒ(A) that were ï¬rst deï¬ned on a semiring A only. The
following theorem, however, shows that the measure of a set from Ïƒ(A) can be well
approximated by ï¬nite and countable operations with sets from A.
Denote by
A â–³B := (A \ B) âˆª(B \ A)
for A, B âŠ‚Î©
(1.14)
the symmetric difference of the two sets A and B.
Theorem 1.65 (Approximation theorem for measures)
Let A âŠ‚2Î© be a
semiring and let Î¼ be a measure on Ïƒ(A) that is Ïƒ-ï¬nite on A.
(i) For any A âˆˆÏƒ(A) and Îµ > 0, there exist mutually disjoint sets A1, A2, . . . âˆˆA
such that A âŠ‚
âˆ

n=1
An and Î¼
 âˆ

n=1
An \ A

< Îµ.
(ii) For any A âˆˆÏƒ(A) with Î¼(A) < âˆand any Îµ > 0, there exists an n âˆˆN and
mutually disjoint sets A1, . . . , An âˆˆA such that Î¼

A â–³
n
k=1
Ak

< Îµ.
(iii) For any A âˆˆM(Î¼âˆ—), there are sets Aâˆ’, A+ âˆˆÏƒ(A) with Aâˆ’âŠ‚A âŠ‚A+ and
Î¼(A+ \ Aâˆ’) = 0.
Remark 1.66 (iii) implies that (i) and (ii) also hold for A âˆˆM(Î¼âˆ—) (with Î¼âˆ—
instead of Î¼). If A is an algebra, then in (ii) for any A âˆˆÏƒ(A), we even have
infBâˆˆA Î¼(A â–³B) = 0. â™¦
Proof (ii)
As Î¼ and the outer measure Î¼âˆ—coincide on Ïƒ(A) and since Î¼(A)
is ï¬nite, by the very deï¬nition of Î¼âˆ—(see Lemma 1.47) there exists a covering
B1, B2, . . . âˆˆA of A such that
Î¼(A) â‰¥
âˆ

i=1
Î¼(Bi) âˆ’Îµ/2.
Let n âˆˆN with
âˆ

i=n+1
Î¼(Bi) < Îµ
2 (such an n exists since Î¼(A) < âˆ). For any three
sets C, D, E, we have
C â–³D = (D \ C) âˆª(C \ D) âŠ‚(D \ C) âˆª(C \ (D âˆªE)) âˆªE âŠ‚(C â–³(D âˆªE)) âˆªE.

32
1
Basic Measure Theory
Choosing C = A, D = n
i=1 Bi and E = âˆ
i=n+1 Bi, this yields
Î¼

A â–³
n

i=1
Bi

â‰¤Î¼

A â–³
âˆ

i=1
Bi

+ Î¼

âˆ

i=n+1
Bi

â‰¤Î¼
 âˆ

i=1
Bi

âˆ’Î¼(A) + Îµ
2 â‰¤Îµ.
As A is a semiring, there exist a k âˆˆN and A1, . . . , Ak âˆˆA such that
n

i=1
Bi = B1 âŠ
n

i=2
iâˆ’1

j=1
(Bi \ Bj) =:
k
i=1
Ai.
(i) Let A âˆˆÏƒ(A) and En â†‘Î©, En âˆˆÏƒ(A) with Î¼(En) < âˆfor any n âˆˆN. For
every n âˆˆN, choose a covering (Bn,m)mâˆˆN of A âˆ©En with
Î¼(A âˆ©En) â‰¥
âˆ

m=1
Î¼(Bn,m) âˆ’2âˆ’nÎµ.
(This is possible due to the deï¬nition of the outer measure Î¼âˆ—, which coincides
with Î¼ on A.) Let
âˆ

m,n=1
Bn,m =
âˆ

n=1
An for certain An âˆˆA, n âˆˆN
(Exercise 1.1.1). Then
Î¼
 âˆ

n=1
An \ A

= Î¼
 âˆ

n=1
âˆ

m=1
Bn,m \ A

â‰¤Î¼
 âˆ

n=1
âˆ

m=1

Bn,m \ (A âˆ©En)


â‰¤
âˆ

n=1
 âˆ

m=1
Î¼(Bn,m)

âˆ’Î¼(A âˆ©En)

â‰¤Îµ.
(iii) Let A âˆˆM(Î¼âˆ—) and (En)nâˆˆN as above. For any m, n âˆˆN, choose An,m âˆˆ
Ïƒ(A) such that An,m âŠƒA âˆ©En and Î¼âˆ—(An,m) â‰¤Î¼âˆ—(A âˆ©En) + 2âˆ’n
m .

1.3
The Measure Extension Theorem
33
Deï¬ne Am :=
âˆ

n=1
An,m âˆˆÏƒ(A). Then Am âŠƒA and Î¼âˆ—(Am \ A) â‰¤1
m. Deï¬ne
A+ :=
âˆ

m=1
Am. Then Ïƒ(A) âˆ‹A+ âŠƒA and Î¼âˆ—(A+\A) = 0. Similarly, choose
(Aâˆ’)c âˆˆÏƒ(A) with (Aâˆ’)c âŠƒAc and Î¼âˆ—((Aâˆ’)c \ Ac) = 0. Then A+ âŠƒA âŠƒ
Aâˆ’and Î¼(A+ \ Aâˆ’) = Î¼âˆ—(A+ \ Aâˆ’) = Î¼âˆ—(A+ \ A) + Î¼âˆ—(A \ Aâˆ’) = 0.
âŠ“âŠ”
Remark 1.67 (Regularity of measures)
(Compare with Theorem 13.6.) Let Î»n be
the Lebesgue measure on

Rn, B(Rn)

. Let A be the semiring of rectangles of the
form (a, b] âŠ‚Rn; hence B(Rn) = Ïƒ(A) by Theorem 1.23. By the approximation
theorem, for any A âˆˆB(Rn) and Îµ > 0, there exist countably many A1, A2, . . . âˆˆA
with A âŠ‚âˆ
i=1 Ai and
Î»n
 âˆ

i=1
Ai \ A

< Îµ/2.
For any Ai, there exists an open rectangle Bi âŠƒAi with Î»n(Bi \ Ai) < Îµ 2âˆ’iâˆ’1
(upper semicontinuity of Î»n). Hence U = âˆ
i=1 Bi is an open set U âŠƒA with
Î»n(U \ A) < Îµ.
This property of Î»n is called outer regularity.
If Î»n(A) is ï¬nite, then for any Îµ > 0 there exists a compact K âŠ‚A such that
Î»n(A \ K) < Îµ.
This property of Î»n is called inner regularity. Indeed, let N > 0 be such that
Î»n(A)âˆ’Î»n(Aâˆ©[âˆ’N, N]n) < Îµ/2. Choose an open set U âŠƒ(Aâˆ©[âˆ’N, N]n)c such
that Î»n(U \ (A âˆ©[âˆ’N, N]n)c) < Îµ/2, and let K := [âˆ’N, N]n \ U âŠ‚A. â™¦
Deï¬nition 1.68 (Null set) Let (Î©, A, Î¼) be a measure space.
(i) A set A âˆˆA is called a Î¼-null set, or brieï¬‚y a null set, if Î¼(A) = 0. By NÎ¼
we denote the class of all subsets of Î¼-null sets.
(ii) Let E(Ï‰) be a property that a point Ï‰ âˆˆÎ© can have or not have. We say that
E holds Î¼-almost everywhere (a.e.) or for almost all (a.a.) Ï‰ if there exists a
null set N such that E(Ï‰) holds for every Ï‰ âˆˆÎ© \ N. If A âˆˆA and if there
exists a null set N such that E(Ï‰) holds for every Ï‰ âˆˆA \ N, then we say that
E holds almost everywhere on A.
If Î¼ = P is a probability measure, then we say that E holds P-almost surely
(a.s.), respectively almost surely on A.
(iii) Let A, B âˆˆA be such that Î¼(A â–³B) = 0. Then we write A = B
(mod Î¼).
Deï¬nition 1.69 A measure space (Î©, A, Î¼) is called complete if NÎ¼ âŠ‚A.

34
1
Basic Measure Theory
Remark 1.70 (Completion of a measure space) Let (Î©, A, Î¼) be a Ïƒ-ï¬nite measure
space. There exists a unique smallest Ïƒ-algebra Aâˆ—âŠƒA and an extension Î¼âˆ—of Î¼
to Aâˆ—such that (Î©, Aâˆ—, Î¼âˆ—) is complete. (Î©, Aâˆ—, Î¼âˆ—) is called the completion of
(Î©, A, Î¼). With the notation of Theorem 1.53, this completion is

Î©, M(Î¼âˆ—), Î¼âˆ—M(Î¼âˆ—)

.
Furthermore,
M(Î¼âˆ—) = Ïƒ(A âˆªNÎ¼) = {A âˆªN : A âˆˆA, N âˆˆNÎ¼}
and Î¼âˆ—(A âˆªN) = Î¼(A) for any A âˆˆA and N âˆˆNÎ¼.
In the following, we will not need these statements. Hence, instead of giving a
proof, we refer to the textbooks on measure theory (e.g., [37]). â™¦
Example 1.71 Let Î» be the Lebesgue measure (more accurately, the Lebesgueâ€“
Borel measure) on

Rn, B(Rn)

. Then Î» can be extended uniquely to a measure
Î»âˆ—on
Bâˆ—(Rn) = ÏƒB(Rn) âˆªN,
where N is the class of subsets of Lebesgueâ€“Borel null sets. Bâˆ—(Rn) is called the
Ïƒ-algebra of Lebesgue measurable sets. For the sake of distinction, we sometimes
call Î» the Lebesgueâ€“Borel measure and Î»âˆ—the Lebesgue measure. However, in
practice, this distinction will not be needed in this book. â™¦
Example 1.72 Let Î¼ = Î´Ï‰ be the Dirac measure for the point Ï‰ âˆˆÎ© on some
measurable space (Î©, A). If {Ï‰} âˆˆA, then the completion is Aâˆ—= 2Î©, Î¼âˆ—= Î´Ï‰.
In the extreme case of a trivial Ïƒ-algebra A = {âˆ…, Î©}, however, the empty set is the
only null set, NÎ¼ = {âˆ…}; hence Aâˆ—= {âˆ…, Î©}, Î¼âˆ—= Î´Ï‰. Note that, on the trivial
Ïƒ-algebra, Dirac measures for different points Ï‰ âˆˆÎ© cannot be distinguished. â™¦
Deï¬nition 1.73 Let (Î©, A, Î¼) be a measure space and Î©â€² âˆˆA. On the trace Ïƒ-
algebra A
Î©â€², we deï¬ne a measure by
Î¼
Î©â€²(A) := Î¼(A)
for A âˆˆA with A âŠ‚Î©â€².
This measure is called the restriction of Î¼ to Î©â€².
Example 1.74 The restriction of the Lebesgueâ€“Borel measure Î» on

R, B(R)

to [0, 1] is a probability measure on ([0, 1], B(R)
[0,1]). More generally, for a
measurable A âˆˆB(R), we call the restriction Î»
A the Lebesgue measure on A.
Often this measure will be denoted by the same symbol Î» when there is no danger
of ambiguity.

1.3
The Measure Extension Theorem
35
Later we will see (Corollary 1.84) that B(R)
A = B(A), where B(A) is the Borel
Ïƒ-algebra on A that is generated by the (relatively) open subsets of A. â™¦
Example 1.75 (Uniform distribution) Let A âˆˆB(Rn) be a measurable set with n-
dimensional Lebesgue measure Î»n(A) âˆˆ(0, âˆ). Then we can deï¬ne a probability
measure on B(Rn)
A by
Î¼(B) := Î»n(B)
Î»n(A)
for B âˆˆB(Rn) with B âŠ‚A.
This measure Î¼ is called the uniform distribution on A and will be denoted by
UA := Î¼. â™¦
Takeaways The measure extension theorem shows how to extend contents
from semirings to Ïƒ-algebras but usually does not give a concrete con-
struction. However, in the special case where the content was deï¬ned on
an algebra in the ï¬rst place, the measure on sets of the Ïƒ-algebra can be
approximated arbitrarily well by sets from the algebra. This will be helpful
in many places. In order for the measure extension to work, Ïƒ-additivity
is decisive. It is an interesting ï¬nding that in two important examples we
could check Ïƒ-subadditivity using topological properties. More speciï¬cally,
we used compactness arguments. At that point it was only a small step to
show that the Lebesgue measure is regular in the sense that the measure of an
arbitrary measurable set can be approximated by compact subsets as well as
by open supersets.
Exercise 1.3.1 Show the following generalization of Example 1.58(iv): A measure
âˆ
n=1 Î±nÎ´xn is a Lebesgueâ€“Stieltjes measure for a suitable function F if and only if

n: |xn|â‰¤K Î±n < âˆfor all K > 0. â™£
Exercise 1.3.2 Let Î© be an uncountably inï¬nite set and let Ï‰0 âˆˆÎ© be an arbitrary
element. Let A = Ïƒ({Ï‰} : Ï‰ âˆˆÎ© \ {Ï‰0}).
(i) Give a characterization of A as in Exercise 1.1.4 (page 11).
(ii) Show that (Î©, A, Î´Ï‰0) is complete. â™£
Exercise 1.3.3 Let (Î¼n)nâˆˆN be a sequence of ï¬nite measures on the measurable
space (Î©, A). Assume that for any A âˆˆA there exists the limit Î¼(A) :=
lim
nâ†’âˆÎ¼n(A).
Show that Î¼ is a measure on (Î©, A).
Hint: In particular, one has to show that Î¼ is âˆ…-continuous. â™£

36
1
Basic Measure Theory
1.4
Measurable Maps
A major task of mathematics is to study homomorphisms between objects; that is,
structure-preserving maps. For topological spaces, these are the continuous maps,
and for measurable spaces, these are the measurable maps.
In the rest of this chapter, we let (Î©, A) and (Î©â€², Aâ€²) be measurable spaces.
Deï¬nition 1.76 (Measurable maps)
(i) A map X : Î© â†’Î©â€² is called A â€“ Aâ€²-measurable (or, brieï¬‚y, measurable) if
Xâˆ’1(Aâ€²) := {Xâˆ’1(Aâ€²) : Aâ€² âˆˆAâ€²} âŠ‚A; that is, if
Xâˆ’1(Aâ€²) âˆˆA
for any Aâ€² âˆˆAâ€².
If X is measurable, we write X : (Î©, A) â†’(Î©â€², Aâ€²).
(ii) If Î©â€² = R and Aâ€² = B(R) is the Borel Ïƒ-algebra on R, then X : (Î©, A) â†’

R, B(R)

is called an A-measurable real map.
Example 1.77
(i) The identity map id : Î© â†’Î© is A â€“ A-measurable.
(ii) If A = 2Î© or Aâ€² = {âˆ…, Î©â€²}, then any map X : Î© â†’Î©â€² is A â€“ Aâ€²-measurable.
(iii) Let A âŠ‚Î©. The indicator function 1A : Î© â†’{0, 1} is A â€“ 2{0,1}-measurable
if and only if A âˆˆA. â™¦
Theorem 1.78 (Generated Ïƒ-algebra) Let (Î©â€², Aâ€²) be a measurable space and
let Î© be a nonempty set. Let X : Î© â†’Î©â€² be a map. The preimage
Xâˆ’1(Aâ€²) := {Xâˆ’1(Aâ€²) : Aâ€² âˆˆAâ€²}
(1.15)
is the smallest Ïƒ-algebra with respect to which X is measurable. We say that
Ïƒ(X) := Xâˆ’1(Aâ€²) is the Ïƒ-algebra on Î© that is generated by X.
Proof This is left as an exercise.
âŠ“âŠ”
We now consider Ïƒ-algebras that are generated by more than one map.
Deï¬nition 1.79 (Generated Ïƒ-algebra)
Let Î© be a nonempty set. Let I be an
arbitrary index set. For any i âˆˆI, let (Î©i, Ai) be a measurable space and let
Xi : Î© â†’Î©i be an arbitrary map. Then
Ïƒ(Xi, i âˆˆI) := Ïƒ

iâˆˆI
Ïƒ(Xi)

= Ïƒ

iâˆˆI
Xâˆ’1
i
(Ai)

is called the Ïƒ-algebra on Î© that is generated by (Xi, i âˆˆI). This is the smallest
Ïƒ-algebra with respect to which all Xi are measurable.
As with continuous maps, the composition of measurable maps is again measurable.

1.4
Measurable Maps
37
Theorem 1.80 (Composition of maps) Let (Î©, A), (Î©â€², Aâ€²) and (Î©â€²â€², Aâ€²â€²) be
measurable spaces and let X : Î© â†’Î©â€² and Xâ€² : Î©â€² â†’Î©â€²â€² be measurable maps.
Then the map Y := Xâ€² â—¦X : Î© â†’Î©â€²â€², Ï‰ â†’Xâ€²(X(Ï‰)) is A â€“ Aâ€²â€²-measurable.
Proof Obvious, since Y âˆ’1(Aâ€²â€²) = Xâˆ’1((Xâ€²)âˆ’1(Aâ€²â€²)) âŠ‚Xâˆ’1(Aâ€²) âŠ‚A.
âŠ“âŠ”
In practice, it is often not possible to check if a map X is measurable by checking
if all preimages Xâˆ’1(Aâ€²), Aâ€² âˆˆAâ€² are measurable. Most Ïƒ-algebras Aâ€² are simply
too large. Thus it comes in very handy that it is sufï¬cient to check measurability on
a generator of Aâ€² by the following theorem.
Theorem 1.81 (Measurability on a generator) Let Eâ€² âŠ‚Aâ€² be a class of Aâ€²-
measurable sets. Then Ïƒ(Xâˆ’1(Eâ€²)) = Xâˆ’1(Ïƒ(Eâ€²)) and hence
X is A - Ïƒ(Eâ€²)-measurable â‡â‡’Xâˆ’1(Eâ€²) âˆˆA
for all Eâ€² âˆˆEâ€².
If in particular Ïƒ(Eâ€²) = Aâ€², then
X is A âˆ’âˆ’Aâ€²-measurable â‡â‡’
Xâˆ’1(Eâ€²) âŠ‚A.
Proof Clearly, Xâˆ’1(Eâ€²) âŠ‚Xâˆ’1
Ïƒ(Eâ€²)

= Ïƒ

Xâˆ’1(Ïƒ(Eâ€²))

. Hence also
Ïƒ

Xâˆ’1(Eâ€²)

âŠ‚Xâˆ’1
Ïƒ(Eâ€²)

.
For the other inclusion, consider the class of sets
Aâ€²
0 :=
	
Aâ€² âˆˆÏƒ(Eâ€²) : Xâˆ’1(Aâ€²) âˆˆÏƒ(Xâˆ’1(Eâ€²))

.
We ï¬rst show that Aâ€²
0 is a Ïƒ-algebra by checking (i)â€“(iii) of Deï¬nition 1.2:
(i) Clearly, Î©â€² âˆˆAâ€²
0.
(ii) (Stability under complements)
If Aâ€² âˆˆAâ€²
0, then
Xâˆ’1((Aâ€²)c) = (Xâˆ’1(Aâ€²))c âˆˆÏƒ(Xâˆ’1(Eâ€²));
hence (Aâ€²)c âˆˆAâ€²
0.
(iii) (Ïƒ-âˆª-stability)
Let Aâ€²
1, Aâ€²
2, . . . âˆˆAâ€²
0. Then
Xâˆ’1
 âˆ

n=1
Aâ€²
n

=
âˆ

n=1
Xâˆ’1(Aâ€²
n) âˆˆÏƒ(Xâˆ’1(Eâ€²));
hence âˆ
n=1 Aâ€²
n âˆˆAâ€²
0.
Now Aâ€²
0 = Ïƒ(Eâ€²) since Eâ€² âŠ‚Aâ€²
0. Hence Xâˆ’1(Aâ€²) âˆˆÏƒ(Xâˆ’1(Eâ€²)) for any Aâ€² âˆˆ
Ïƒ(Eâ€²) and thus Xâˆ’1(Ïƒ(Eâ€²)) âŠ‚Ïƒ(Xâˆ’1(Eâ€²)).
âŠ“âŠ”

38
1
Basic Measure Theory
Corollary 1.82 (Measurability of composed maps) Let I be a nonempty index
set and let (Î©, A), (Î©â€², Aâ€²) and (Î©i, Ai) be measurable spaces for any i âˆˆI.
Further, let (Xi : i âˆˆI) be a family of measurable maps Xi : Î©â€² â†’Î©i with
Aâ€² = Ïƒ(Xi : i âˆˆI). Then the following holds: A map Y : Î© â†’Î©â€² is A â€“
Aâ€²-measurable if and only if Xi â—¦Y is A â€“ Ai-measurable for all i âˆˆI.
Proof If Y is measurable, then by Theorem 1.80 every Xi â—¦Y is measurable. Now
assume that all of the composed maps Xiâ—¦Y are A â€“ Ai-measurable. By assumption,
the set Eâ€² := {Xâˆ’1
i
(Aâ€²â€²) : Aâ€²â€² âˆˆAi, i âˆˆI} is a generator of Aâ€². Since all Xi â—¦Y
are measurable, we have Y âˆ’1(Aâ€²) âˆˆA for any Aâ€² âˆˆEâ€². Hence Theorem 1.81 yields
that Y is measurable.
âŠ“âŠ”
Recall the deï¬nition of the trace of a class of sets from Deï¬nition 1.25.
Corollary 1.83 (Trace of a generated Ïƒ-algebra) Let E âŠ‚2Î© and assume that
A âŠ‚Î© is nonempty. Then ÏƒE
A
 = Ïƒ(E)
A.
Proof Let X : A â†’Î©, Ï‰ â†’Ï‰ be the canonical inclusion; hence Xâˆ’1(B) = Aâˆ©B
for all B âŠ‚Î©. By Theorem 1.81, we have
Ïƒ

E
A

= Ïƒ({E âˆ©A : E âˆˆE})
= Ïƒ({Xâˆ’1(E) : E âˆˆE}) = Ïƒ(Xâˆ’1(E))
= Xâˆ’1(Ïƒ(E)) = {A âˆ©B : B âˆˆÏƒ(E)} = Ïƒ(E)
A.
âŠ“âŠ”
Recall that, for any subset A âŠ‚Î© of a topological space (Î©, Ï„), the class Ï„
A is
the topology of relatively open sets (in A). We denote by B(Î©, Ï„) = Ïƒ(Ï„) the Borel
Ïƒ-algebra on (Î©, Ï„).
Corollary 1.84 (Trace of the Borel Ïƒ-algebra) Let (Î©, Ï„) be a topological space
and let A âŠ‚Î© be a nonempty subset of Î©. Then
B(Î©, Ï„)
A = B

A, Ï„
A

.
Example 1.85
(i) Let Î©â€² be countable. Then X : Î© â†’Î©â€² is A â€“ 2Î©â€²-measurable if and only if
Xâˆ’1({Ï‰â€²}) âˆˆA for all Ï‰â€² âˆˆÎ©â€². If Î©â€² is uncountably inï¬nite, this is wrong in
general. (For example, consider Î© = Î©â€² = R, A = B(R), and X(Ï‰) = Ï‰ for
all Ï‰ âˆˆÎ©. Clearly, Xâˆ’1({Ï‰}) = {Ï‰} âˆˆB(R). If, on the other hand, A âŠ‚R is
not in B(R), then A âˆˆ2R, but Xâˆ’1(A) Ì¸âˆˆB(R).)
(ii) For x âˆˆR, we agree on the following notation for rounding:
âŒŠxâŒ‹:= max{k âˆˆZ : k â‰¤x}
and
âŒˆxâŒ‰:= min{k âˆˆZ : k â‰¥x}.
(1.16)

1.4
Measurable Maps
39
The maps R â†’Z, x â†’âŒŠxâŒ‹and x â†’âŒˆxâŒ‰are B(R) â€“ 2Z-measurable since for
all k âˆˆZ the preimages {x âˆˆR : âŒŠxâŒ‹= k} = [k, k + 1) and {x âˆˆR : âŒˆxâŒ‰=
k} = (k âˆ’1, k] are in B(R). By the composition theorem (Theorem 1.80), for
any measurable map f : (Î©, A) â†’R, B(R) the maps âŒŠf âŒ‹and âŒˆf âŒ‰are also
A â€“ 2Z-measurable.
(iii) A map X : Î© â†’Rd is A â€“ B(Rd)-measurable if and only if
Xâˆ’1((âˆ’âˆ, a]) âˆˆA
for any a âˆˆRd.
In fact Ïƒ((âˆ’âˆ, a], a âˆˆRd) = B(Rd) by Theorem 1.23. The analogous
statement holds for any of the classes E1, . . . , E12 from Theorem 1.23. â™¦
Example 1.86 Let d(x, y) = âˆ¥x âˆ’yâˆ¥2 be the usual Euclidean distance on Rn and
let B(Rn, d) = B(Rn) be the Borel Ïƒ-algebra with respect to the topology generated
by d. For any subset A of Rn, we have B(A, d) = B(Rn, d)
A. â™¦
We want to extend the real line by the points âˆ’âˆand +âˆ. Thus we deï¬ne
R := R âˆª{âˆ’âˆ, +âˆ}.
From a topological point of view, R will be considered as the so-called two point
compactiï¬cation by considering R as topologically isomorphic to [âˆ’1, 1] via the
map
Ï• : [âˆ’1, 1] â†’R,
x â†’
â§
âªâ¨
âªâ©
tan(Ï€x/2),
if x âˆˆ(âˆ’1, 1),
âˆ’âˆ,
if x = âˆ’1,
âˆ,
if x = +1.
In fact, Â¯d(x, y) =
Ï•âˆ’1(x) âˆ’Ï•âˆ’1(y)
 for x, y âˆˆR deï¬nes a metric on R such that
Ï• and Ï•âˆ’1 are continuous. Hence Ï• is a topological isomorphism. We denote by
Â¯Ï„ the corresponding topology induced on R and by Ï„ the usual topology on R.
Corollary 1.87 With the above notation, Â¯Ï„
R = Ï„ and hence B

R

R = B(R).
In particular, if X : (Î©, A) â†’

R, B(R)

is measurable, then in a canonical way
X is also an R-valued measurable map.
Thus R is really an extension of the real line, and the inclusion R â†’R is
measurable.
Reï¬‚ection Check that each of the families E1, . . . , E12 from Theorem 1.23 (with
n = 1) is a generator for B(R). Also check that the families {[âˆ’âˆ, a], a âˆˆQ},
{[âˆ’âˆ, a), a âˆˆQ}, {[b, âˆ], b âˆˆQ} and {(b, âˆ], b âˆˆQ} are generators of B(R).
â™ 

40
1
Basic Measure Theory
Theorem 1.88 (Measurability of continuous maps) Let (Î©, Ï„) and (Î©â€², Ï„ â€²) be
topological spaces and let f : Î© â†’Î©â€² be a continuous map. Then f is B(Î©) â€“
B(Î©â€²)-measurable.
Proof As B(Î©â€²) = Ïƒ(Ï„ â€²) and by Theorem 1.81, it is sufï¬cient to show that
f âˆ’1(Aâ€²) âˆˆÏƒ(Ï„) for all Aâ€² âˆˆÏ„ â€². However, since f is continuous, we even have
f âˆ’1(Aâ€²) âˆˆÏ„ for all Aâ€² âˆˆÏ„ â€².
âŠ“âŠ”
For x, y âˆˆR, we agree on the following notation.
x âˆ¨y = max(x, y)
(maximum),
x âˆ§y = min(x, y)
(minimum),
x+ = max(x, 0)
(positive part),
xâˆ’= max(âˆ’x, 0)
(negative part),
|x| = max(x, âˆ’x) = xâˆ’+ x+
(modulus),
sign(x) = 1{x>0} âˆ’1{x<0}
(sign function).
Analogously, for measurable real maps we write, for example, X+ = max(X, 0).
The maps x â†’x+, x â†’xâˆ’and x â†’|x| are continuous (and hence measurable
by the preceding theorem). Clearly, the map x â†’sign(x) also is measurable. Using
Corollary 1.82, we thus get the following corollary.
Corollary 1.89 If X is a real or R-valued measurable map, then the maps Xâˆ’, X+,
|X| and sign(X) also are measurable.
Theorem 1.90 (Coordinate maps are measurable) Let (Î©, A) be a measurable
space and let f1, . . . , fn : Î© â†’R be maps. Deï¬ne f := (f1, . . . , fn) : Î© â†’Rn.
Then
f is A âˆ’B(Rn)-measurable
â‡â‡’
each fi is A âˆ’B(R)-measurable.
The analogous statement holds for fi : Î© â†’R := R âˆª{Â±âˆ}.
Proof For b âˆˆRn, we have f âˆ’1((âˆ’âˆ, b)) =
n
i=1
f âˆ’1
i
((âˆ’âˆ, bi)). If each fi is
measurable, then f âˆ’1((âˆ’âˆ, b)) âˆˆA. However, the rectangles (âˆ’âˆ, b), b âˆˆRn,
generate B(Rn), and hence f is measurable. Now assume that f is measurable. For
i = 1, . . . , n, let Ï€i : Rn â†’R, x â†’xi be the projection on the ith coordinate.
Clearly, Ï€i is continuous and thus B(Rn) â€“ B(R)-measurable. Hence fi = Ï€i â—¦f is
measurable by Theorem 1.80.
âŠ“âŠ”
In the following theorem, we agree that x
0 := 0 for all x âˆˆR.
Theorem 1.91 Let (Î©, A) be a measurable space. Let h : (Î©, A) â†’R, B(R)
and f, g : (Î©, A) â†’Rn, B(Rn) be measurable maps. Then also the maps f + g,
f âˆ’g, f Â· h and f/h are measurable.

1.4
Measurable Maps
41
Proof The map Ï€ : Rn Ã— R â†’Rn, (x, Î±) â†’Î± Â· x is continuous and thus
measurable. By Theorem 1.90, (f, h) : Î© â†’Rn Ã— R is measurable. Hence also
the composed map f Â· h = Ï€ â—¦(f, h) is measurable. Similarly, we obtain the
measurability of f + g and f âˆ’g.
In order to show measurability of f/h, we deï¬ne the map H : R â†’R, x â†’1/x.
Note that by our convention H(0) = 0. Hence f/h = f Â·H â—¦h. Thus it is enough to
show that H is measurable. Clearly, H
R\{0} is continuous. For any open set U âŠ‚R,
U \{0} is also open and hence H âˆ’1(U \{0}) âˆˆB(R). Furthermore, H âˆ’1({0}) = {0}.
Concluding, we get H âˆ’1(U) = H âˆ’1(U \ {0}) âˆª(U âˆ©{0}) âˆˆB(R).
âŠ“âŠ”
Theorem 1.92 Let X1, X2, . . . be measurable maps (Î©, A) â†’(R, B(R)). Then
the following maps are also measurable:
inf
nâˆˆN Xn,
sup
nâˆˆN
Xn,
lim inf
nâ†’âˆXn,
lim sup
nâ†’âˆ
Xn.
Proof For any a âˆˆR, we have

inf
nâˆˆN Xn
âˆ’1
([âˆ’âˆ, a)) =
âˆ

n=1
Xâˆ’1
n ([âˆ’âˆ, a)) âˆˆA.
By Theorem 1.81, this implies that inf
nâˆˆN Xn is measurable. The proof for sup
nâˆˆN
Xn is
similar.
For any n âˆˆN, we deï¬ne Yn := inf
mâ‰¥n Xm. Note that Yn is measurable and hence
lim inf
nâ†’âˆXn := sup
nâˆˆN
Yn also is measurable. The proof for the limes superior is similar.
âŠ“âŠ”
We come to an important example of measurable maps (Î©, A) â†’

R, B(R)

, the
so-called simple functions.
Deï¬nition 1.93 (Simple function) Let (Î©, A) be a measurable space. A map f :
Î© â†’R is called a simple function if there is an n âˆˆN and mutually disjoint
measurable sets A1, . . . , An âˆˆA, as well as numbers Î±1, . . . , Î±n âˆˆR, such that
f =
n

i=1
Î±i 1Ai.
Remark 1.94 A measurable map that assumes only ï¬nitely many values is a simple
function. (Exercise: Show this!) â™¦
Deï¬nition 1.95 Assume that f, f1, f2, . . . are maps Î© â†’R such that
f1(Ï‰) â‰¤f2(Ï‰) â‰¤. . . and
lim
nâ†’âˆfn(Ï‰) = f (Ï‰)
for any Ï‰ âˆˆÎ©.

42
1
Basic Measure Theory
Then we write fn â†‘f and say that (fn)nâˆˆN increases (pointwise) to f . Analogously,
we write fn â†“f if (âˆ’fn) â†‘(âˆ’f ).
Theorem 1.96 Let (Î©, A) be a measurable space and let f : Î© â†’[0, âˆ] be
measurable. Then the following statements hold.
(i) There exists a sequence (fn)nâˆˆN of nonnegative simple functions such that fn â†‘
f .
(ii) There are measurable sets A1, A2, . . . âˆˆA and numbers Î±1, Î±2, . . . â‰¥0 such
that f =
âˆ

n=1
Î±n 1An.
Proof
(i) For n âˆˆN0, deï¬ne fn =

2âˆ’nâŒŠ2nf âŒ‹

âˆ§n. Then fn is measurable (by
Theorem 1.92 and Example 1.85(ii)) and assumes at most n2n + 1 different
values. Hence it is a simple function. Clearly, fn â†‘f .
(ii) Let fn be as above. Let Bn,i := {Ï‰ : fn(Ï‰) âˆ’fnâˆ’1(Ï‰) = i 2âˆ’n} and Î²n,i =
i 2âˆ’n for n âˆˆN and i = 1, . . . , 2n. Hence fn âˆ’fnâˆ’1 =
2n

i=1
Î²n,i 1Bn,i . By
changing the numeration (n, i) â†’m, we get (Î±m)mâˆˆN and (Am)mâˆˆN such that
f = f0 +
âˆ

n=1
(fn âˆ’fnâˆ’1) =
âˆ

m=1
Î±m 1Am.
âŠ“âŠ”
As a corollary to this statement on the structure of [0, âˆ]-valued measurable maps,
we show the following factorization lemma.
Corollary 1.97 (Factorization lemma) Let (Î©â€², Aâ€²) be a measurable space and
let Î© be a nonempty set. Let f : Î© â†’Î©â€² be a map. A map g : Î© â†’R is
Ïƒ(f ) â€“ B(R)-measurable if and only if there is a measurable map Ï• : (Î©â€², Aâ€²) â†’
(R, B(R)) such that g = Ï• â—¦f .
Proof â€œ â‡ â€
If Ï• is measurable and g = Ï• â—¦f , then g is measurable by
Theorem 1.80.
â€œ â‡’â€
Now assume that g is Ïƒ(f ) â€“ B(R)-measurable. First consider the case
g â‰¥0. Then there exist measurable sets A1, A2 . . . âˆˆÏƒ(f ) as well as numbers
Î±1, Î±2, . . . , âˆˆ[0, âˆ) such that g = âˆ
n=1 Î±n 1An. By the deï¬nition of Ïƒ(f ), for
any n âˆˆN there is a set Bn âˆˆAâ€² such that f âˆ’1(Bn) = An; that is, such that
1An = 1Bn â—¦f . Deï¬ne Ï• : Î©â€² â†’R by
Ï• =
âˆ

n=1
Î±n 1Bn.
Clearly, Ï• is Aâ€² â€“ B(R)-measurable and g = Ï• â—¦f .

1.4
Measurable Maps
43
Now drop the assumption that g is nonnegative. Then there exist measurable
maps Ï•âˆ’and Ï•+ such that gâˆ’= Ï•âˆ’â—¦f and g+ = Ï•+ â—¦f . Note that g+(Ï‰) âˆ§
gâˆ’(Ï‰) = 0 for all Ï‰ âˆˆÎ©. Hence
Ï‰ â†’Ï•(Ï‰) :=

Ï•+(Ï‰) âˆ’Ï•âˆ’(Ï‰),
if Ï•+(Ï‰) < âˆor Ï•âˆ’(Ï‰) < âˆ,
0,
else
does the trick.
âŠ“âŠ”
A measurable map transports a measure from one space to another.
Deï¬nition 1.98 (Image measure) Let (Î©, A) and (Î©â€², Aâ€²) be measurable spaces
and let Î¼ be a measure on (Î©, A). Further, let X : (Î©, A) â†’(Î©â€², Aâ€²) be
measurable. The image measure of Î¼ under the map X is the measure Î¼ â—¦Xâˆ’1
on (Î©â€², Aâ€²) that is deï¬ned by
Î¼ â—¦Xâˆ’1 : Aâ€² â†’[0, âˆ],
Aâ€² â†’Î¼(Xâˆ’1(Aâ€²)).
Example 1.99 Let Î¼ be a measure on Z2 and let X : Z2 â†’Z, (x, y) â†’x + y.
Then
Î¼ â—¦Xâˆ’1({x}) =

yâˆˆZ
Î¼({(x âˆ’y, y)}).
â™¦
Example 1.100 Let L : Rn â†’Rn be a linear bijection and let Î» be the Lebesgue
measure on

Rn, B(Rn)

. Then Î» â—¦Lâˆ’1
= | det(L)|âˆ’1Î». This is clear since
for any a, b âˆˆRn with a < b, the parallelepiped Lâˆ’1((a, b]) has volume
| det(Lâˆ’1)| n
i=1(bi âˆ’ai). â™¦
As a generalization of the last example, we state without proof the transformation
formula for measures with continuous densities under differentiable maps. The
proof can be found in textbooks on calculus.
Theorem 1.101 (Transformation formula in Rn) Let Î¼ be a measure on Rn that
has a continuous (or piecewise continuous) density f : Rn â†’[0, âˆ). That is,
Î¼((x, y]) =
 y1
x1
dt1 Â· Â· Â·
 yn
xn
dtn f (t1, . . . , tn)
for all x, y âˆˆRn, x â‰¤y.

44
1
Basic Measure Theory
Let A âŠ‚Rn be an open or a closed subset of Rn with Î¼(Rn \ A) = 0. Further,
let B âŠ‚Rn be open or closed. Finally, assume that Ï• : A â†’B is a continuously
differentiable bijection with derivative Ï•â€². Then the image measure Î¼ â—¦Ï•âˆ’1 has the
density
fÏ•(x) =
â§
âªâªâ¨
âªâªâ©
f (Ï•âˆ’1(x))
| det(Ï•â€²(Ï•âˆ’1(x)))|,
if x âˆˆB mit det(Ï•â€²(Ï•âˆ’1(x))) Ì¸= 0,
0,
else.
Takeaways Measurable maps are the natural maps between two measurable
spaces as they are structure preserving. We have encountered conditions for
measurability that are easy to check, e.g., continuity and measurability on a
generator. Furthermore, we have seen that compositions of measurable maps,
vectors of measurable maps and so on are again measurable.
Exercise 1.4.1 Let f : R â†’R, x â†’|x|. Show that a Borel measurable map
g : R â†’R is Ïƒ(f ) = f âˆ’1(B(R))-measurable if and only if g is even. â™£
Exercise 1.4.2 Let (Î©, A, Î¼) be a measure space and let f
: Î©
â†’R be
measurable. Assume that g : Î© â†’R fulï¬lls g = f Î¼-almost everywhere. Show
that g need not be measurable. â™£
Exercise 1.4.3 Let f : R â†’R be differentiable with derivative f â€². Show that f â€²
is B(R) â€“ B(R)-measurable. â™£
Exercise 1.4.4 (Compare Examples 1.40 and 1.63) Let Î© = {0, 1}N and let A =
(2{0,1})âŠ—N be the Ïƒ-algebra generated by the cylinder sets
	
[Ï‰1, . . . , Ï‰n] : n âˆˆN, Ï‰1, . . . , Ï‰n âˆˆ{0, 1}

.
Further, let Î¼ = ( 1
2Î´0 + 1
2Î´1)âŠ—N be the Bernoulli measure on Î© with equal weights
on 0 and 1. For all n âˆˆN, let Xn : Î© â†’{0, 1}, Ï‰ â†’Ï‰n be the nth coordinate map.
Finally, let
U(Ï‰) =
âˆ

n=1
Xn(Ï‰) 2âˆ’n
for Ï‰ âˆˆÎ©.
(i) Show that A = Ïƒ(Xn : n âˆˆN).
(ii) Show that U is A â€“ B([0, 1])-measurable.
(iii) Determine the image measure Î¼ â—¦Uâˆ’1 on ([0, 1], B([0, 1])).
(iv) Determine an Î©0 âˆˆA such that ËœU := U
Î©0 is bijective.

1.5
Random Variables
45
(v) Show that ËœUâˆ’1 is B([0, 1]) â€“ A
Î©0-measurable.
(vi) Give an interpretation of the map Xn â—¦ËœUâˆ’1. â™£
Exercise 1.4.5 (Lusinâ€™s theorem)
Let f : R â†’R be a Borel measurable map.
Show that for any Îµ > 0, there exists a closed set C âŠ‚R with Î»(R \ C) < Îµ such
that the restriction f 
C of f to C is continuous. (Note: Clearly, this does not mean
that f would be continuous in every point x âˆˆC.)
Hint: Use the inner regularity of Lebesgue measure Î» (Remark 1.67) to show
the assertion ï¬rst for indicator functions. Next construct a sequence of maps that
approximates f uniformly on a suitable set C. â™£
1.5
Random Variables
The fundamental idea of modern probability theory is to model one or more random
experiments as a probability space (Î©, A, P). The sets A âˆˆA are called events.
In most cases, the events of Î© are not observed directly. Rather, the observations
are aspects of the single experiments that are coded as measurable maps from
Î© to a space of possible observations. In short, every random observation (the
technical term is random variable) is a measurable map. The probabilities of the
possible random observations will be described in terms of the distribution of the
corresponding random variable, which is the image measure of P under X. Hence
we have to develop a calculus to determine the distributions of, for example, sums
of random variables.
Deï¬nition 1.102 (Random variables) Let (Î©â€², Aâ€²) be a measurable space and let
X : Î© â†’Î©â€² be measurable.
(i) X is called a random variable with values in (Î©â€², Aâ€²). If (Î©â€², Aâ€²)
=

R, B(R)

, then X is called a real random variable or simply a random
variable.
(ii) For Aâ€² âˆˆAâ€², we denote {X âˆˆAâ€²} := Xâˆ’1(Aâ€²) and P[X âˆˆAâ€²] := P[Xâˆ’1(Aâ€²)].
In particular, we let {X â‰¥0} := Xâˆ’1([0, âˆ)) and deï¬ne {X â‰¤b} similarly
and so on.
Deï¬nition 1.103 (Distributions) Let X be a random variable.
(i) The probability measure PX := P â—¦Xâˆ’1 is called the distribution of X.
(ii) For a real random variable X, the map FX : x â†’P[X â‰¤x] is called the
distribution function of X (or, more accurately, of PX). We write X âˆ¼Î¼ if
Î¼ = PX and say that X has distribution Î¼.
(iii) A family (Xi)iâˆˆI of random variables is called identically distributed if PXi =
PXj for all i, j âˆˆI. We write X D= Y if PX = PY (D for distribution).

46
1
Basic Measure Theory
Theorem 1.104 For any distribution function F, there exists a real random
variable X with FX = F.
Proof We explicitly construct a probability space (Î©, A, P) and a random variable
X : Î© â†’R such that FX = F.
The simplest choice would be (Î©, A) =

R, B(R)

, X : R â†’R the
identity map and P the Lebesgueâ€“Stieltjes measure with distribution function F
(see Example 1.56).
A more instructive approach is based on ï¬rst constructing, independently of
F, a sort of standard probability space on which we deï¬ne a random variable
with uniform distribution on (0, 1). In a second step, this random variable will be
transformed by applying the inverse map F âˆ’1: Let Î© := (0, 1), A := B(R)
Î©
and let P be the Lebesgue measure on (Î©, A) (see Example 1.74). Deï¬ne the left
continuous inverse of F:
F âˆ’1(t) := inf{x âˆˆR : F(x) â‰¥t}
for t âˆˆ(0, 1).
Then
F âˆ’1(t) â‰¤x
â‡â‡’t â‰¤F(x).
In particular, {t : F âˆ’1(t) â‰¤x} = (0, F(x)] âˆ©(0, 1); hence F âˆ’1 : (Î©, A) â†’

R, B(R)

is measurable and
P[{t : F âˆ’1(t) â‰¤x}] = F(x).
Concluding, X := F âˆ’1 is the random variable that we wanted to construct.
âŠ“âŠ”
Example 1.105 We present some prominent distributions of real random variables
X. These are some of the most important distributions in probability theory, and we
will come back to these examples in many places.
(i) Let p âˆˆ[0, 1] and P[X = 1] = p, P[X = 0] = 1 âˆ’p. Then PX =: Berp is
called the Bernoulli distribution with parameter p; formally
Berp = (1 âˆ’p) Î´0 + p Î´1.
Its distribution function is
FX(x) =
â§
â¨
â©
0,
if x < 0,
1 âˆ’p,
if x âˆˆ[0, 1),
1,
if x â‰¥1.
The distribution PY of Y := 2X âˆ’1 is sometimes called the Rademacher
distribution with parameter p; formally Radp = (1 âˆ’p) Î´âˆ’1 + p Î´+1. In
particular, Rad1/2 is called the Rademacher distribution.

1.5
Random Variables
47
(ii) Let p âˆˆ[0, 1] and n âˆˆN, and let X : Î© â†’{0, . . ., n} be such that
P[X = k] =
n
k

pk(1 âˆ’p)nâˆ’k.
Then PX =: bn,p is called the binomial distribution with parameters n and
p; formally
bn,p =
n

k=0
n
k

pk(1 âˆ’p)nâˆ’k Î´k.
(iii) Let p âˆˆ(0, 1] and X : Î© â†’N0 with
P[X = n] = p (1 âˆ’p)n
for any n âˆˆN0.
Then Î³p := bâˆ’
1,p := PX is called the geometric distribution2 with parameter
p; formally
Î³p =
âˆ

n=0
p (1 âˆ’p)n Î´n.
Its distribution function is F(x) = 1 âˆ’(1 âˆ’p)âŒŠx+1âŒ‹âˆ¨0
for x âˆˆR.
We can interpret X + 1 as the waiting time for the ï¬rst success in a
series of independent random experiments, any of which yields a success
with probability p. Indeed, let Î© = {0, 1}N and let P be the product measure
(1 âˆ’p)Î´0 + p Î´1
âŠ—N (Theorem 1.64), as well as A = Ïƒ([Ï‰1, . . . , Ï‰n] :
Ï‰1, . . . , Ï‰n âˆˆ{0, 1}, n âˆˆN). Deï¬ne
X(Ï‰) := inf{n âˆˆN : Ï‰n = 1} âˆ’1,
where inf âˆ…= âˆ. Clearly, any map
Xn : Î© â†’R,
Ï‰ â†’

n âˆ’1,
if Ï‰n = 1,
âˆ,
if Ï‰n = 0,
2Warning: For some authors, the geometric distribution is shifted by one to the right; that is, it is a
distribution on N.

48
1
Basic Measure Theory
is A â€“ B(R)-measurable. Thus also X = infnâˆˆN Xn is A â€“ B(R)-measurable
and is hence a random variable. Let Ï‰0 := (0, 0, . . .) âˆˆÎ©. Then P[X â‰¥n] =
P[[Ï‰0
1, . . . , Ï‰0
n]] = (1 âˆ’p)n. Hence
P[X = n] = P[X â‰¥n]âˆ’P[X â‰¥n+1] = (1âˆ’p)nâˆ’(1âˆ’p)n+1 = p (1âˆ’p)n.
(iv) Let r > 0 (note that r need not be an integer) and let p âˆˆ(0, 1]. We denote
by
bâˆ’
r,p :=
âˆ

k=0
âˆ’r
k

(âˆ’1)k pr(1 âˆ’p)k Î´k
(1.17)
the negative binomial distribution or Pascal distribution with parameters
r and p. (Here
x
k

= x(xâˆ’1)Â·Â·Â·(xâˆ’k+1)
k!
for x âˆˆR and k âˆˆN is the generalized
binomial coefï¬cient.) If r âˆˆN, then one can show as in the preceding example
that bâˆ’
r,p is the distribution of the waiting time for the rth success in a series
of random experiments. We come back to this in Example 3.4(iv).
(v) Let Î» âˆˆ[0, âˆ) and let X : Î© â†’N0 be such that
P[X = n] = eâˆ’Î» Î»n
n!
for any n âˆˆN0.
Then PX =: PoiÎ» is called the Poisson distribution with parameter Î».
(vi) Consider an urn with B âˆˆN black balls and W âˆˆN white balls. Draw n âˆˆN
balls from the urn without replacement. A little bit of combinatorics shows
that the probability of drawing exactly b âˆˆ{0, . . . , n} black balls is given by
the hypergeometric distribution with parameters B, W, n âˆˆN:
HypB,W;n

{b}

=
B
b
 W
n âˆ’b

B + W
n

for b âˆˆ{0, . . . , n}.
(1.18)
This generalizes easily to the situation of k colors and Bi balls of color
i = 1, . . . , k. As above, we get that the probability of drawing out of n
balls exactly bi balls of color i for each i = 1, . . . , k (with the restriction
b1 + . . . + bk = n and bi â‰¤Bi for all i) is given by the generalized
hypergeometric distribution
HypB1,...,Bk;n

{(b1, . . . , bk)}

=
B1
b1

Â· Â· Â·
Bk
bk

B1 + . . . + Bk
n
.
(1.19)

1.5
Random Variables
49
(vii) Let Î¼ âˆˆR, Ïƒ 2 > 0 and let X be a real random variable with
P[X â‰¤x] =
1
âˆš
2Ï€Ïƒ 2
 x
âˆ’âˆ
exp

âˆ’(t âˆ’Î¼)2
2Ïƒ 2

dt
for x âˆˆR.
Then PX =: NÎ¼,Ïƒ 2 is called the Gaussian normal distribution with parame-
ters Î¼ and Ïƒ 2. In particular, N0,1 is called the standard normal distribution.
(viii) Let Î¸ > 0 and let X be a nonnegative random variable such that
P[X â‰¤x] = P[X âˆˆ[0, x]] =
 x
0
Î¸ eâˆ’Î¸t dt
for x â‰¥0.
Then PX is called the exponential distribution
with parameter Î¸ (in
shorthand, expÎ¸).
(ix) Let Î¼ âˆˆRd and let Î£ be a positive deï¬nite symmetric d Ã— d matrix. Let X
be an Rd-valued random variable such that
P[X â‰¤x] = det(2Ï€ Î£)âˆ’1/2

(âˆ’âˆ,x]
exp

âˆ’1
2
%
t âˆ’Î¼, Î£âˆ’1(t âˆ’Î¼)
&
Î»d(dt)
for x âˆˆRd (where âŸ¨Â·, Â·âŸ©denotes the inner product in Rd). Then PX =: NÎ¼,Î£
is the d-dimensional normal distribution with parameters Î¼ and Î£. â™¦
Deï¬nition 1.106 If the distribution function F : Rn â†’[0, 1] is of the form
F(x) =
 x1
âˆ’âˆ
dt1 Â· Â· Â·
 xn
âˆ’âˆ
dtn f (t1, . . . , tn)
for x = (x1, . . . , xn) âˆˆRn,
for some integrable function f : Rn â†’[0, âˆ), then f is called the density of the
distribution.
Example 1.107
(i) Let Î¸, r > 0 and let Î“Î¸,r be the distribution on [0, âˆ) with density
x â†’
Î¸r
Î“ (r) xrâˆ’1eâˆ’Î¸x.
(Here Î“ denotes the gamma function.) Then Î“Î¸,r is called the Gamma
distribution with scale parameter Î¸ and shape parameter r.
(ii) Let r, s > 0 and let Î²r,s be the distribution on [0, 1] with density
x â†’Î“ (r + s)
Î“ (r)Î“ (s) xrâˆ’1(1 âˆ’x)sâˆ’1.
Then Î²r,s is called the Beta distribution with parameters r and s.

50
1
Basic Measure Theory
(iii) Let a > 0 and let Caua be the distribution on R with density
x â†’1
aÏ€
1
1 + (x/a)2 .
Then Caua is called the Cauchy distribution with parameter a. â™¦
Takeaways A random variable X is a measurable map from a probability
space to some measurable space. The image measure PX describes the
distribution of X. In most cases, only the distribution of a random variable
is of interest but not the underlying probability space. We have got acquainted
with some fundamental probability distributions:
â€¢
Bernoulli-distribution Berp on {0, 1}
â€¢
binomial distribution bn,p on {0, . . . , n}
â€¢
geometric distribution Î³p on N0
â€¢
negative binomial distribution (or Pascal distribution) bâˆ’
r,p on N0
â€¢
Poisson distribution PoiÎ» on N0
â€¢
hypergeometric distribution HypB,W;n on {0, . . . , n}
â€¢
normal distribution NÎ¼,Ïƒ 2 on R
â€¢
exponential distribution expÎ¸ on [0, âˆ)
â€¢
Gamma distribution Î“Î¸,r on [0, âˆ)
â€¢
Beta distribution Î²r,s on [0, 1]
â€¢
Cauchy distribution Caua on R
Exercise 1.5.1 Use the identity
âˆ’n
k

(âˆ’1)k =
n+kâˆ’1
k

to deduce (1.17) by combi-
natorial means from its interpretation as a waiting time. â™£
Exercise 1.5.2 Give an example of two normally distributed random variables X
and Y such that (X, Y) is not (two-dimensional) normally distributed. â™£
Exercise 1.5.3 Use the transformation formula (Theorem 1.101) to show the
following statements.
(i) Let X âˆ¼NÎ¼,Ïƒ 2 and let a âˆˆR \ {0} and b âˆˆR. Then (aX + b) âˆ¼NaÎ¼+b,a2Ïƒ 2.
(ii) Let X âˆ¼expÎ¸ and a > 0. Then aX âˆ¼expÎ¸/a. â™£
Exercise 1.5.4 Show that F
: R2 â†’[0, 1] is the distribution function of a
(uniquely determined) probability measure Î¼ on (R2, B(R2)) if and only if
(i) F is monotone increasing and right continuous
(ii) F((âˆ’x1, y2)) + F((y1, âˆ’x2)) â†’0 and F(x) â†’1 for all y1, y2 âˆˆR and for
x = (x1, x2) â†’âˆ,
(iii) F((y1, y2))âˆ’F((y1, x2))âˆ’F((x1, y2))+F((x1, x2)) â‰¥0 for all x1 â‰¤y1 and
x2 â‰¤y2. â™£

1.5
Random Variables
51
Exercise 1.5.5
(i) Let F and G be distribution functions on R. Use Exercise 1.5.4 to show that
(x, y) â†’F(x) âˆ§G(y) is a distribution function on R2.
(ii) Give an example of two distribution functions F and G on R2 such that
(x, y) â†’F(x) âˆ§G(y) is not a distribution function on R4.
Hint: First use the inclusion-exclusion formula (Theorem 1.33) to derive a
criterion similar to that in Exercise 1.5.4(iii). â™£

Chapter 2
Independence
The measure theory from the preceding chapter is a linear theory that could not
describe the dependence structure of events or random variables. We enter the realm
of probability theory exactly at this point, where we deï¬ne independence of events
and random variables. Independence is a pivotal notion of probability theory, and
the computation of dependencies is one of the theoryâ€™s major tasks.
In the following, (Î©, A, P) is a probability space and the sets A âˆˆA are the
events. As soon as constructing probability spaces has become routine, the concrete
probability space will lose its importance and it will be only the random variables
that will interest us. The bold font symbol P will then denote the universal object
of a probability measure, and the probabilities P[ Â·] with respect to it will always be
written in square brackets.
2.1
Independence of Events
We consider two events A and B as (stochastically) independent if the occurrence
of A does not change the probability that B also occurs. Formally, we say that A
and B are independent if
P[A âˆ©B] = P[A] Â· P[B].
(2.1)
Example 2.1 (Rolling a die twice) Consider the random experiment of rolling a
die twice. Hence Î© = {1, . . ., 6}2 endowed with the Ïƒ-algebra A = 2Î© and the
uniform distribution P = UÎ© (see Example 1.30(ii)).
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_2
53

54
2
Independence
(i) Two events A and B should be independent, e.g., if A depends only on the
outcome of the ï¬rst roll and B depends only on the outcome of the second roll.
Formally, we assume that there are sets ËœA, ËœB âŠ‚{1, . . . , 6} such that
A = ËœA Ã— {1, . . . , 6}
and
B = {1, . . . , 6} Ã— ËœB.
Now we check that A and B indeed fulï¬ll (2.1). To this end, we compute
P[A] = #A
36 = # ËœA
6 and P[B] = #B
36 = # ËœB
6 . Furthermore,
P[A âˆ©B] = #( ËœA Ã— ËœB)
36
= # ËœA
6 Â· # ËœB
6 = P[A] Â· P[B].
(ii) Stochastic independence can occur also in less obvious situations. For instance,
let A be the event where the sum of the two rolls is odd,
A =
	
(Ï‰1, Ï‰2) âˆˆÎ© : Ï‰1 + Ï‰2 âˆˆ{3, 5, 7, 9, 11}

,
and let B be the event where the ï¬rst roll gives at most a three
B = {(Ï‰1, Ï‰2) âˆˆÎ© : Ï‰1 âˆˆ{1, 2, 3}
.
Although it might seem that these two events are entangled in some way, they
are stochastically independent. Indeed, it is easy to check that P[A] = P[B] =
1
2 and P[A âˆ©B] = 1
4. â™¦
What is the condition for three events A1, A2, A3 to be independent? Of course,
any of the pairs (A1, A2), (A1, A3) and (A2, A3) has to be independent. However,
we have to make sure also that the simultaneous occurrence of A1 and A2 does not
change the probability that A3 occurs. Hence, it is not enough to consider pairs only.
Formally, we call three events A1, A2 and A3 (stochastically) independent if
P[Ai âˆ©Aj] = P[Ai] Â· P[Aj]
for all i, j âˆˆ{1, 2, 3}, i Ì¸= j,
(2.2)
and
P[A1 âˆ©A2 âˆ©A3] = P[A1] Â· P[A2] Â· P[A3].
(2.3)
Note that (2.2) does not imply (2.3) (and (2.3) does not imply (2.2)).
Example 2.2 (Rolling a die three times) We roll a die three times. Hence Î© =
{1, . . ., 6}3 endowed with the discrete Ïƒ-algebra A
=
2Î© and the uniform
distribution P = UÎ© (see Example 1.30(ii)).
(i) If we assume that for any i = 1, 2, 3 the event Ai depends only on the outcome
of the ith roll, then the events A1, A2 and A3 are independent. Indeed, as in the

2.1
Independence of Events
55
preceding example, there are sets ËœA1, ËœA2, ËœA3 âŠ‚{1, . . . 6} such that
A1 = ËœA1 Ã— {1, . . . , 6}2,
A2 = {1, . . ., 6} Ã— ËœA2 Ã— {1, . . . , 6},
A3 = {1, . . ., 6}2 Ã— ËœA3.
The validity of (2.2) follows as in Example 2.1(i). In order to show (2.3), we
compute
P[A1 âˆ©A2 âˆ©A3] = #( ËœA1 Ã— ËœA2 Ã— ËœA3)
216
=
3

i=1
# ËœAi
6
=
3

i=1
P[Ai].
(ii) Consider now the events
A1 := {Ï‰ âˆˆÎ© : Ï‰1 = Ï‰2},
A2 := {Ï‰ âˆˆÎ© : Ï‰2 = Ï‰3},
A3 := {Ï‰ âˆˆÎ© : Ï‰1 = Ï‰3}.
Then #A1 = #A2 = #A3 = 36; hence P[A1] = P[A2] = P[A3] =
1
6.
Furthermore, #(Ai âˆ©Aj) = 6 if i Ì¸= j; hence P[Ai âˆ©Aj] =
1
36. Hence (2.2)
holds. On the other hand, we have #(A1âˆ©A2âˆ©A3) = 6, thus P[A1âˆ©A2âˆ©A3] =
1
36 Ì¸= 1
6 Â· 1
6 Â· 1
6. Thus (2.3) does not hold and so the events A1, A2, A3 are not
independent. â™¦
In order to deï¬ne independence of larger families of events, we have to request the
validity of product formulas, such as (2.2) and (2.3), not only for pairs and triples
but for all ï¬nite subfamilies of events. We thus make the following deï¬nition.
Deï¬nition 2.3 (Independence of events) Let I be an arbitrary index set and let
(Ai)iâˆˆI be an arbitrary family of events. The family (Ai)iâˆˆI is called independent
if for any ï¬nite subset J âŠ‚I the product formula holds:
P
' 
jâˆˆJ
Aj
(
=

jâˆˆJ
P[Aj].
Reï¬‚ection How do you choose four events A1, A2, A3, A4 such that each pair
Ai, Aj, i Ì¸= j, and each triple Ai, Aj, Ak, #{i, j, k} = 3, is independent, but
A1, A2, A3, A4 is not? â™ 
Reï¬‚ection An event is independent of itself if A and B are independent for B = A.
Check that in this case A has either probability 0 or 1. â™ 

56
2
Independence
The most prominent example of an independent family of inï¬nitely many events is
given by the perpetuated independent repetition of a random experiment.
Example 2.4 Let E be a ï¬nite set (the set of possible outcomes of the individual
experiment) and let (pe)eâˆˆE be a probability vector on E. Equip (as in Theo-
rem 1.64) the probability space Î© = EN with the Ïƒ-algebra A = Ïƒ({[Ï‰1, . . . , Ï‰n] :
Ï‰1, . . . , Ï‰n âˆˆE, n âˆˆN}) and with the product measure (or Bernoulli measure)
P =

eâˆˆE peÎ´e
âŠ—N; that is where P
)
[Ï‰1, . . . , Ï‰n]
*
=
n

i=1
pÏ‰i. Let ËœAi âŠ‚E for any
i âˆˆN, and let Ai be the event where ËœAi occurs in the ith experiment; that is,
Ai =
	
Ï‰ âˆˆÎ© : Ï‰i âˆˆËœAi

=

(Ï‰1,...,Ï‰i)âˆˆEiâˆ’1Ã— ËœAi
[Ï‰1, . . . , Ï‰i].
Intuitively, the family (Ai)iâˆˆN should be independent if the deï¬nition of indepen-
dence makes any sense at all. We check that this is indeed the case. Let J âŠ‚N be
ï¬nite and n := max J. Formally, we deï¬ne Bj = Aj and ËœBj = ËœAj for j âˆˆJ and
Bj = Î© and ËœBj = E for j âˆˆ{1, . . . , n} \ J. Then
P
+ 
jâˆˆJ
Aj
,
= P
+ 
jâˆˆJ
Bj
,
= P
+
n

j=1
Bj
,
=

e1âˆˆËœB1
Â· Â· Â·

enâˆˆËœBn
n

j=1
pej =
n

j=1
 
eâˆˆËœBj
pe

=

jâˆˆJ
 
eâˆˆËœAj
pe

.
This is true in particular for #J = 1. Hence P[Ai] = 
eâˆˆËœAi pe for all i âˆˆN,
whence
P
+ 
jâˆˆJ
Aj
,
=

jâˆˆJ
P[Aj].
(2.4)
Since this holds for all ï¬nite J âŠ‚N, the family (Ai)iâˆˆN is independent. â™¦
If A and B are independent, then Ac and B also are independent since P[Ac âˆ©B] =
P[B] âˆ’P[A âˆ©B] = P[B] âˆ’P[A]P[B] = (1 âˆ’P[A])P[B] = P[Ac]P[B]. We
generalize this observation in the following theorem.
Theorem 2.5 Let I be an arbitrary index set and let (Ai)iâˆˆI be a family of events.
Deï¬ne B0
i = Ai and B1
i = Ac
i for i âˆˆI. Then the following three statements are
equivalent.
(i) The family (Ai)iâˆˆI is independent.
(ii) There is an Î± âˆˆ{0, 1}I such that the family (BÎ±i
i )iâˆˆI is independent.
(iii) For any Î± âˆˆ{0, 1}I, the family (BÎ±i
i )iâˆˆI is independent.

2.1
Independence of Events
57
Proof This is left as an exercise.
âŠ“âŠ”
Example 2.6 (Eulerâ€™s prime number formula)
The Riemann zeta function is
deï¬ned by the Dirichlet series
Î¶(s) :=
âˆ

n=1
nâˆ’s
for s âˆˆ(1, âˆ).
Eulerâ€™s prime number formula is a representation of the Riemann zeta function as
an inï¬nite product
Î¶(s) =

pâˆˆP

1 âˆ’pâˆ’sâˆ’1,
(2.5)
where P := {p âˆˆN : p is prime}.
We give a probabilistic proof for this formula. Let Î© = N, and for ï¬xed s > 1
deï¬ne P on 2Î© by
P[{n}] = Î¶(s)âˆ’1 nâˆ’s
for n âˆˆN.
Let pN = {pn : n âˆˆN} and Pn = {p âˆˆP : p â‰¤n}. We consider pN âŠ‚Î© as
an event. Note that P[pN] = pâˆ’s and that (pN, p âˆˆP) is independent. Indeed, for
k âˆˆN and mutually distinct p1, . . . , pk âˆˆP, we have k
i=1(piN) = (p1 Â· Â· Â· pk)N.
Thus
P
- k
i=1
(piN)
.
=
âˆ

n=1
P
)
{p1 Â· Â· Â· pkn}
*
= Î¶(s)âˆ’1 (p1 Â· Â· Â· pk)âˆ’s
âˆ

n=1
nâˆ’s
= (p1 Â· Â· Â· pk)âˆ’s =
k
i=1
P[ piN ].
By Theorem 2.5, the family ((pN)c, p âˆˆP) is also independent, whence
Î¶(s)âˆ’1 = P[{1}] = P
+ 
pâˆˆP
(pN)c
,
= lim
nâ†’âˆP
' 
pâˆˆPn
(pN)c(
= lim
nâ†’âˆ

pâˆˆPn
1 âˆ’P[ pN ] =

pâˆˆP
1 âˆ’pâˆ’s.
This shows (2.5). â™¦

58
2
Independence
If we roll a die inï¬nitely often, what is the chance that the face shows a six inï¬nitely
often? This probability should equal one. Otherwise there would be a last point in
time when we see a six and after which the face only shows a number one to ï¬ve.
However, this is not very plausible.
Recall that we formalized the event where inï¬nitely many of a series of events
occur by means of the limes superior (see Deï¬nition 1.13). The following theorem
conï¬rms the conjecture mentioned above and also gives conditions under which we
cannot expect that inï¬nitely many of the events occur.
Theorem 2.7 (Borelâ€“Cantelli lemma) Let A1, A2, . . . be events and deï¬ne Aâˆ—=
lim sup
nâ†’âˆ
An.
(i) If âˆ
n=1 P[An] < âˆ, then P[Aâˆ—] = 0. (Here P could be an arbitrary measure
on (Î©, A).)
(ii) If (An)nâˆˆN is independent and âˆ
n=1 P[An] = âˆ, then P[Aâˆ—] = 1.
Proof
(i) P is upper semicontinuous and Ïƒ-subadditive; hence, by assumption,
P[Aâˆ—] = lim
nâ†’âˆP
- âˆ

m=n
Am
.
â‰¤lim
nâ†’âˆ
âˆ

m=n
P[Am] = 0.
(ii) De Morganâ€™s rule and the lower semicontinuity of P yield
P)(Aâˆ—)c* = P
- âˆ

m=1
âˆ

n=m
Ac
n
.
= lim
mâ†’âˆP
- âˆ

n=m
Ac
n
.
.
However, for every m âˆˆN (since log(1 âˆ’x) â‰¤âˆ’x for x âˆˆ[0, 1]), by upper
continuity of P
P
+ âˆ

n=m
Ac
n
,
= lim
Nâ†’âˆP
+
N

n=m
Ac
n
,
=
âˆ

n=m

1 âˆ’P[An]

= exp
 âˆ

n=m
log 1 âˆ’P[An]
â‰¤exp

âˆ’
âˆ

n=m
P[An]

= 0.
âŠ“âŠ”
Example 2.8 We throw a die again and again and ask for the probability of seeing
a six inï¬nitely often. Hence Î© = {1, . . ., 6}N, A = (2{1,...,6})âŠ—N is the product
Ïƒ-algebra and P =


eâˆˆ{1,...,6}
1
6Î´e
âŠ—N is the Bernoulli measure (see Theorem 1.64).
Furthermore, let An = {Ï‰ âˆˆÎ© : Ï‰n = 6} be the event where the nth roll shows
a six. Then Aâˆ—= lim sup
nâ†’âˆ
An is the event where we see a six inï¬nitely often (see

2.1
Independence of Events
59
Remark 1.14). Furthermore, (An)nâˆˆN is an independent family with the property
âˆ

n=1
P[An] =
âˆ

n=1
1
6 = âˆ. Hence the Borelâ€“Cantelli lemma yields P[Aâˆ—] = 1. â™¦
Example 2.9 We roll a die only once and deï¬ne An for any n âˆˆN as the event
where in this one roll the face showed a six. Note that A1 = A2 = A3 = . . .. Then

nâˆˆN P[An] = âˆ; however, P[Aâˆ—] = P[A1] = 1
6. This shows that in Part (ii) of
the Borelâ€“Cantelli lemma, the assumption of independence is indispensable. â™¦
Example 2.10 Let Î› âˆˆ(0, âˆ) and 0 â‰¤Î»n â‰¤Î› for n âˆˆN. Let Xn, n âˆˆN, be
Poisson random variables with parameters Î»n. Then
P
)
Xn â‰¥n for inï¬nitely many n
*
= 0.
Indeed,
âˆ

n=1
P[Xn â‰¥n] =
âˆ

n=1
âˆ

m=n
P[Xn = m] =
âˆ

m=1
m

n=1
P[Xn = m]
=
âˆ

m=1
m

n=1
eâˆ’Î»n Î»m
n
m! â‰¤
âˆ

m=1
m Î›m
m!
= Î› eÎ› < âˆ.
â™¦
(2.6)
Note that in Theorem 2.7 in the case of independent events, only the probabilities
P[Aâˆ—] = 0 and P[Aâˆ—] = 1 could show up. Thus the Borelâ€“Cantelli lemma belongs
to the class of so-called 0â€“1 laws. Later we will encounter more 0â€“1 laws (see, for
example, Theorem 2.37).
Now we extend the notion of independence from families of events to families
of classes of events.
Deï¬nition 2.11 (Independence of classes of events) Let I be an arbitrary index
set and let Ei âŠ‚A for all i âˆˆI. The family (Ei)iâˆˆI is called independent if, for any
ï¬nite subset J âŠ‚I and any choice of Ej âˆˆEj, j âˆˆJ, we have
P
+ 
jâˆˆJ
Ej
,
=

jâˆˆJ
P[Ej].
(2.7)
Example 2.12 As in Example 2.4, let (Î©, A, P) be the product space of inï¬nitely
many repetitions of a random experiment whose possible outcomes e are the
elements of the ï¬nite set E and have probabilities p = (pe)eâˆˆE. For i âˆˆN, deï¬ne
Ei =
	
{Ï‰ âˆˆÎ© : Ï‰i âˆˆA} : A âŠ‚E

.
For any choice of sets Ai âˆˆEi, i âˆˆN, the family (Ai)iâˆˆN is independent; hence
(Ei)iâˆˆN is independent. â™¦

60
2
Independence
Theorem 2.13
(i) Let I be ï¬nite, and for any i âˆˆI let Ei âŠ‚A with Î© âˆˆEi. Then
(Ei)iâˆˆI is independent
â‡â‡’(2.7) holds for J = I.
(ii) (Ei)iâˆˆI is independent â‡â‡’

(Ej)jâˆˆJ is independent for all ï¬nite J âŠ‚I

.
(iii) If (Ei âˆª{âˆ…}) is âˆ©-stable, then
(Ei)iâˆˆI is independent
â‡â‡’(Ïƒ(Ei))iâˆˆI is independent.
(iv) Let K be an arbitrary set and let (Ik)kâˆˆK be mutually disjoint subsets of I. If
(Ei)iâˆˆI is independent, then  
iâˆˆIk Ei

kâˆˆK is also independent.
Proof
(i) â€œ â‡’â€
This is trivial.
(i) â€œ â‡ â€
For J âŠ‚I and j âˆˆI \ J, choose Ej = Î©.
(ii)
This is trivial.
(iii) â€œ â‡ â€
This is trivial.
(iii) â€œ â‡’â€
Let J âŠ‚I be ï¬nite. We will show that for any two ï¬nite sets J and
J â€² with J âŠ‚J â€² âŠ‚I,
P
+ 
iâˆˆJ â€²
Ei
,
=

iâˆˆJ â€²
P[Ei] for any choice

Ei âˆˆÏƒ(Ei),
if i âˆˆJ,
Ei âˆˆEi,
if i âˆˆJ â€² \ J.
(2.8)
The case J â€² = J is exactly the claim we have to show.
We carry out the proof of (2.8) by induction on #J. For #J = 0, the statement
(2.8) holds by assumption of this theorem.
Now assume that (2.8) holds for every J with #J = n and for every ï¬nite
J â€² âŠƒJ. Fix such a J and let j âˆˆI \ J. Choose J â€² âŠƒËœJ := J âˆª{j}. We show
the validity of (2.8) with J replaced by ËœJ. Since # ËœJ = n + 1, this veriï¬es the
induction step.
Let Ei âˆˆÏƒ(Ei) for any i âˆˆJ, and let Ei âˆˆEi for any i âˆˆJ â€² \(J âˆª{j}). Deï¬ne
two measures Î¼ and Î½ on (Î©, A) by
Î¼ : Ej â†’P
+ 
iâˆˆJ â€²
Ei
,
and
Î½ : Ej â†’

iâˆˆJ â€²
P[Ei].
By the induction hypothesis (2.8), we have Î¼(Ej) = Î½(Ej) for every Ej âˆˆ
Ej âˆª{âˆ…, Î©}. Since Ej âˆª{âˆ…} is a Ï€-system, Lemma 1.42 yields that Î¼(Ej) =
Î½(Ej) for all Ej âˆˆÏƒ(Ej). That is, (2.8) holds with J replaced by J âˆª{j}.

2.2
Independent Random Variables
61
(iv) This is trivial, as (2.7) has to be checked only for J âŠ‚I with
#(J âˆ©Ik) â‰¤1
for any k âˆˆK.
âŠ“âŠ”
Takeaways Two events A and B are independent if P[A âˆ©B] = P[A] Â·
P[B]. We have extended this notion to families of events and even to families
of classes of sets. The Borel-Cantelli lemma shows that inï¬nitely many of
countably many independent events occur jointly with probability either 0 or
1 depending on the summability of the probabilities of the single events.
Exercise 2.1.1 In a queue each new arriving person chooses independently a
random waiting position. What is the probability that the ï¬rst position changes
inï¬nitely often? â™£
Exercise 2.1.2 Show that the conclusion of the interesting part of the Borel-Cantelli
lemma (Theorem 2.7(ii)) still holds under the following weaker condition: Each
of the families (A1, A3, A5, . . .) and (A2, A4, A6, . . .) is independent (but not
necessarily independent of each other). â™£
2.2
Independent Random Variables
Now that we have studied independenceof events, we want to study independenceof
random variables. Here also the deï¬nition ends up with a product formula. Formally,
however, we can also deï¬ne independence of random variables via independence of
the Ïƒ-algebras they generate. This is the reason why we studied independence of
classes of events in the last section.
Independent random variables allow for a rich calculus. For example, we can
compute the distribution of a sum of two independent random variables by a simple
convolution formula. Since we do not have a general notion of an integral at hand
at this point, for the time being we restrict ourselves to presenting the convolution
formula for integer-valued random variables only.
Let I be an arbitrary index set. For each i âˆˆI, let (Î©i, Ai) be a measurable
space and let Xi : (Î©, A) â†’(Î©i, Ai) be a random variable with generated Ïƒ-
algebra Ïƒ(Xi) = Xâˆ’1
i
(Ai).
Deï¬nition 2.14 (Independent random variables) The family (Xi)iâˆˆI of random
variables is called independent if the family (Ïƒ(Xi))iâˆˆI of Ïƒ-algebras is indepen-
dent.
As a shorthand, we say that a family (Xi)iâˆˆI is â€œi.i.d.â€ (for â€œindependent and
identically distributedâ€) if (Xi)iâˆˆI is independent and if PXi = PXj for all i, j âˆˆI.

62
2
Independence
Remark 2.15
(i) Clearly, the family (Xi)iâˆˆI is independent if and only if, for any ï¬nite set J âŠ‚I
and any choice of Aj âˆˆAj, j âˆˆJ, we have
P
' 
jâˆˆJ
{Xj âˆˆAj}
(
=

jâˆˆJ
P[Xj âˆˆAj].
The next theorem will show that it is enough to request the validity of such a
product formula for Aj from an âˆ©-stable generator of Aj only.
(ii) If ( ËœAi)iâˆˆI is an independent family of Ïƒ-algebras and if each Xi is ËœAi â€“ Ai-
measurable, then (Xi)iâˆˆI is independent. This is a direct consequence of the
fact that Ïƒ(Xi) âŠ‚ËœAi.
(iii) For each i âˆˆI, let (Î©â€²
i, Aâ€²
i) be another measurable space and assume that
fi : (Î©i, Ai) â†’(Î©â€²
i, Aâ€²
i) is a measurable map. If (Xi)iâˆˆI is independent,
then (fi â—¦Xi)iâˆˆI is independent. This statement is a special case of (ii) since
fi â—¦Xi is Ïƒ(Xi) â€“ Aâ€²
i-measurable (see Theorem 1.80).â™¦
Theorem 2.16 (Independent generators) For any i
âˆˆ
I, let Ei
âŠ‚
Ai be
a Ï€-system that generates Ai. If (Xâˆ’1
i
(Ei))iâˆˆI is independent, then (Xi)iâˆˆI is
independent.
Proof By Theorem 1.81, Xâˆ’1
i
(Ei) is a Ï€-system that generates the Ïƒ-algebra
Xâˆ’1
i
(Ai) = Ïƒ(Xi). Hence the statement follows from Theorem 2.13.
âŠ“âŠ”
Example 2.17 Let E be a countable set and let (Xi)iâˆˆI be random variables with
values in (E, 2E). In this case, (Xi)iâˆˆI is independent if and only if, for any ï¬nite
J âŠ‚I and any choice of xj âˆˆE, j âˆˆJ,
P)Xj = xj for all j âˆˆJ* =

jâˆˆJ
P[Xj = xj].
This is obvious since 	{x} : x âˆˆE
 âˆª{âˆ…} is a Ï€-system that generates 2E, thus
	
Xâˆ’1
i
({xi}) : xi âˆˆE

âˆª{âˆ…} is a Ï€-system that generates Ïƒ(Xi) (Theorem 1.81). â™¦
Example 2.18 Let E be a ï¬nite set and let p = (pe)eâˆˆE be a probability vector.
Repeat a random experiment with possible outcomes e âˆˆE and probabilities pe for
e âˆˆE inï¬nitely often (see Example 1.40 and Theorem 1.64). Let Î© = EN be the
inï¬nite product space and let A be the Ïƒ-algebra generated by the cylinder sets (see
(1.8)). Let P =

eâˆˆE peÎ´e
âŠ—N be the Bernoulli measure. Further, for any n âˆˆN,
let
Xn : Î© â†’E,
(Ï‰m)mâˆˆN â†’Ï‰n,
be the projection on the nth coordinate. In other words: For any simple event Ï‰ âˆˆÎ©,
Xn(Ï‰) yields the result of the nth experiment. Then, by (2.4) (in Example 2.4), for

2.2
Independent Random Variables
63
n âˆˆN and x âˆˆEn, we have
P)Xj = xj for all j = 1, . . . , n* = P)[x1, . . . , xn]* = P
+
n

j=1
Xâˆ’1
j ({xj})
,
=
n

j=1
P)Xâˆ’1
j ({xj})* =
n

j=1
P[Xj = xj],
and P[Xj = xj] = pxj . By virtue of Theorem 2.13(i), this implies that the
family (X1, . . . , Xn) is independent and hence, by Theorem 2.13(ii), (Xn)nâˆˆN is
independent as well. â™¦
In particular, we have shown the following theorem.
Theorem 2.19 Let E be a ï¬nite set and let (pe)eâˆˆE be a probability vector on E.
Then there exists a probability space (Î©, A, P) and an independent family (Xn)nâˆˆN
of E-valued random variables on (Î©, A, P) such that P[Xn = e] = pe for any
e âˆˆE.
Later we will see that the assumption that E is ï¬nite can be dropped. Also
one can allow for different distributions in the respective factors. For the time
being, however, this theorem gives us enough examples of interesting families of
independent random variables.
Our next goal is to deduce simple criteria in terms of distribution functions and
densities for checking whether a family of random variables is independent or not.
Deï¬nition 2.20 For any i âˆˆI, let Xi be a real random variable. For any ï¬nite
subset J âŠ‚I, let
FJ := F(Xj )jâˆˆJ : RJ â†’[0, 1],
x â†’P
)
Xj â‰¤xj for all j âˆˆJ
*
= P
+ 
jâˆˆJ
Xâˆ’1
j

(âˆ’âˆ, xj]
,
.
Then FJ is called the joint distribution function of (Xj)jâˆˆJ. The probability
measure P(Xj )jâˆˆJ on RJ is called the joint distribution of (Xj)jâˆˆJ.
Theorem 2.21 A family (Xi)iâˆˆI of real random variables is independent if and only
if, for every ï¬nite J âŠ‚I and every x = (xj)jâˆˆJ âˆˆRJ ,
FJ (x) =

jâˆˆJ
F{j}(xj).
(2.9)
Proof The class of sets {(âˆ’âˆ, b], b âˆˆR} is an âˆ©-stable generator of the Borel
Ïƒ-algebra B(R) (see Theorem 1.23). Equation (2.9) says that, for any choice

64
2
Independence
of real numbers (xi)iâˆˆI, the events (Xâˆ’1
i
((âˆ’âˆ, xi]))iâˆˆI are independent. Hence
Theorem 2.16 yields the claim.
âŠ“âŠ”
Corollary 2.22 In addition to the assumptions of Theorem 2.21, we assume that
any FJ has a continuous density fJ = f(Xj )jâˆˆJ (the joint density of (Xj)jâˆˆJ). That
is, there exists a continuous map fJ : RJ â†’[0, âˆ) such that
FJ (x) =
 xj1
âˆ’âˆ
dt1 Â· Â· Â·
 xjn
âˆ’âˆ
dtn fJ (t1, . . . , tn)
for all x âˆˆRJ
(where J = {j1, . . . , jn}). In this case, the family (Xi)iâˆˆI is independent if and only
if, for any ï¬nite J âŠ‚I
fJ (x) =

jâˆˆJ
fj(xj)
for all x âˆˆRJ .
(2.10)
Corollary 2.23 Let n
âˆˆ
N and let Î¼1, . . . , Î¼n be probability measures on

R, B(R)

. Then there exists a probability space (Î©, A, P) and an independent
family of random variables (Xi)i=1,...,n on (Î©, A, P) with PXi = Î¼i for each
i = 1, . . . , n.
Proof Let Î© = Rn and A = B(Rn). Let P = /n
i=1 Î¼i be the product measure of
the Î¼i (see Theorem 1.61). Further, let Xi : Rn â†’R, (x1, . . . , xn) â†’xi be the
projection on the ith coordinate for each i = 1, . . . , n. Then, for any i = 1, . . ., n,
F{i}(x) = P[Xi â‰¤x] = P)Riâˆ’1 Ã— (âˆ’âˆ, x] Ã— Rnâˆ’i*
= Î¼i

(âˆ’âˆ, x]

Â·

jÌ¸=i
Î¼j(R) = Î¼i

(âˆ’âˆ, x]

.
Hence indeed PXi = Î¼i. Furthermore, for all x1, . . . , xn âˆˆR,
F{1,...,n}((x1, . . . , xn)) = P
+
nÃ—
i=1
(âˆ’âˆ, xi]
,
=
n

i=1
Î¼i

(âˆ’âˆ, xi]

=
n

i=1
F{i}(xi).
Hence Theorem 2.21 (and Theorem 2.13(i)) yields the independence of (Xi)i=1,...,n.
âŠ“âŠ”
Example 2.24 Let X1, . . . , Xn be independent exponentially distributed random
variables with parameters Î¸1, . . . , Î¸n âˆˆ(0, âˆ). Then
F{i}(x) =
 x
0
Î¸ieâˆ’Î¸it dt = 1 âˆ’eâˆ’Î¸ix
for x â‰¥0

2.2
Independent Random Variables
65
and hence
F{1,...,n}
(x1, . . . , xn) =
n

i=1
1 âˆ’eâˆ’Î¸ixi.
Consider now the random variable Y = max(X1, . . . , Xn). Then
FY (x) = P)Xi â‰¤x for all i = 1, . . . , n*
= F{1,...,n}

(x, . . . , x)

=
n

i=1

1 âˆ’eâˆ’Î¸ix
.
The distribution function of the random variable Z := min(X1, . . . , Xn) has a nice
closed form:
FZ(x) = 1 âˆ’P[Z > x]
= 1 âˆ’P
)
Xi > x for all i = 1, . . . , n
*
= 1 âˆ’
n

i=1
eâˆ’Î¸ix = 1 âˆ’exp

âˆ’(Î¸1 + . . . + Î¸n) x

.
In other words, Z is exponentially distributed with parameter Î¸1 + . . . + Î¸n. â™¦
Example 2.25 Let Î¼i âˆˆR and Ïƒ 2
i
> 0 for i âˆˆI. Let (Xi)iâˆˆI be real random
variables with joint density functions (for ï¬nite J âŠ‚I)
fJ (x) =

jâˆˆJ

2Ï€Ïƒ 2
j
âˆ’1
2 exp

âˆ’

jâˆˆJ
(xj âˆ’Î¼j)2
2Ïƒ 2
j

for x âˆˆRJ.
Then (Xi)iâˆˆI is independent and Xi is normally distributed with parameters
(Î¼i, Ïƒ 2
i ).
For any ï¬nite I = {i1, . . . , in} (with mutually distinct i1, . . . , in), the vector
Y = (Xi1, . . . , Xin) has the n-dimensional normal distribution with Î¼ = Î¼I :=
(Î¼i1, . . . , Î¼in) and with Î£ = Î£I the diagonal matrix with entries Ïƒ 2
i1, . . . , Ïƒ 2
in (see
Example 1.105(ix)). â™¦
Theorem 2.26 Let K be an arbitrary set and Ik, k âˆˆK, arbitrary mutually disjoint
index sets. Deï¬ne I = 
kâˆˆK
Ik.
If the family (Xi)iâˆˆI is independent, then the family of Ïƒ-algebras (Ïƒ(Xj, j âˆˆ
Ik))kâˆˆK is independent.

66
2
Independence
Proof For k âˆˆK, let
Zk =
0 
jâˆˆIk
Aj : Aj âˆˆÏƒ(Xj), #{j âˆˆIk : Aj Ì¸= Î©} < âˆ
1
be the semiring of ï¬nite-dimensional rectangular cylinder sets. Clearly, Zk is a Ï€-
system and Ïƒ(Zk) = Ïƒ(Xj, j âˆˆIk). Hence, by Theorem 2.13(iii), it is enough to
show that (Zk)kâˆˆK is independent. By Theorem 2.13(ii), we can even assume that
K is ï¬nite.
For k âˆˆK, let Bk âˆˆZk and Jk âŠ‚Ik be ï¬nite with Bk = 
jâˆˆJk Aj for certain
Aj âˆˆÏƒ(Xj). Deï¬ne J = 
kâˆˆK Jk. Then
P
+ 
kâˆˆK
Bk
,
= P
+ 
jâˆˆJ
Aj
,
=

jâˆˆJ
P[Aj] =

kâˆˆK

jâˆˆJk
P[Aj] =

kâˆˆK
P[Bk].
âŠ“âŠ”
Example 2.27 If (Xn)nâˆˆN is an independent family of real random variables,
then also (Yn)nâˆˆN = (X2n âˆ’X2nâˆ’1)nâˆˆN is independent. Indeed, for any n âˆˆ
N, the random variable Yn is Ïƒ(X2n, X2nâˆ’1)-measurable by Theorem 1.91, and
(Ïƒ(X2n, X2nâˆ’1))nâˆˆN is independent by Theorem 2.26. â™¦
Example 2.28 Let (Xm,n)(m,n)âˆˆN2 be an independent family of Bernoulli random
variables with parameter p âˆˆ(0, 1). Deï¬ne the waiting time for the ï¬rst â€œsuccessâ€
in the mth row of the matrix (Xm,n)m,n by
Ym := inf 	n âˆˆN : Xm,n = 1
 âˆ’1.
Then (Ym)mâˆˆN are independent geometric random variables with parameter p (see
Example 1.105(iii)). Indeed,
{Ym â‰¤k} =
k+1

l=1
{Xm,l = 1} âˆˆÏƒ(Xm,l, l = 1, . . . , k + 1) âŠ‚Ïƒ(Xm,l, l âˆˆN).
Hence Ym is Ïƒ(Xm,l, l
âˆˆ
N)-measurable and thus (Ym)mâˆˆN is independent.
Furthermore,
P[Ym > k] = P[Xm,l = 0, l = 1, . . . , k + 1] =
k+1

l=1
P[Xm,l = 0] = (1 âˆ’p)k+1.
Concluding, we get P[Ym = k] = P[Ym > k âˆ’1] âˆ’P[Ym > k] = p(1 âˆ’p)k. â™¦

2.2
Independent Random Variables
67
Deï¬nition 2.29 (Convolution) Let Î¼ and Î½ be probability measures on (Z, 2Z).
The convolution Î¼ âˆ—Î½ is deï¬ned as the probability measure on (Z, 2Z) such that
(Î¼ âˆ—Î½)({n}) =
âˆ

m=âˆ’âˆ
Î¼({m}) Î½({n âˆ’m}).
We deï¬ne the nth convolution power recursively by Î¼âˆ—1 = Î¼ and
Î¼âˆ—(n+1) = Î¼âˆ—n âˆ—Î¼.
Remark 2.30 The convolution is a symmetric operation: Î¼ âˆ—Î½ = Î½ âˆ—Î¼. â™¦
Theorem 2.31 If X and Y are independent Z-valued random variables, then
PX+Y = PX âˆ—PY .
Proof For any n âˆˆZ,
PX+Y ({n}) = P[X + Y = n]
= P
+ 
mâˆˆZ

{X = m} âˆ©{Y = n âˆ’m}
,
=

mâˆˆZ
P){X = m} âˆ©{Y = n âˆ’m}*
=

mâˆˆZ
PX[{m}] PY [{n âˆ’m}] = (PX âˆ—PY )[{n}].
âŠ“âŠ”
Reï¬‚ection Check that PX+Y = PXâˆ—PY does not imply that X and Y be independent.
â™ â™ 
Owing to the last theorem, it is natural to deï¬ne the convolution of two probability
measures on Rn (or more generally on an Abelian group) as the distribution of
the sum of two independent random variables with the corresponding distributions.
Later we will encounter a different (but equivalent) deï¬nition that will, however,
rely on the notion of an integral that is not yet available to us at this point (see
Deï¬nition 14.20).
Deï¬nition 2.32 (Convolution of measures)
Let Î¼ and Î½ be probability measures
on Rn and let X and Y be independent random variables with PX = Î¼ and PY = Î½.
We deï¬ne the convolution of Î¼ and Î½ as Î¼ âˆ—Î½ = PX+Y .
Recursively, we deï¬ne the convolution powers Î¼âˆ—k for all k âˆˆN and let Î¼âˆ—0 = Î´0.

68
2
Independence
Example 2.33 Let X and Y be independent Poisson random variables with param-
eters Î¼ and Î» â‰¥0. Then
P[X + Y = n] = eâˆ’Î¼eâˆ’Î»
n

m=0
Î¼m
m!
Î»nâˆ’m
(n âˆ’m)!
= eâˆ’(Î¼+Î») 1
n!
n

m=0
n
m

Î¼mÎ»nâˆ’m = eâˆ’(Î¼+Î») (Î¼ + Î»)n
n!
.
Hence PoiÎ¼ âˆ—PoiÎ» = PoiÎ¼+Î». â™¦
Takeaways Families of random variables are independent if the events they
describe are independent (Deï¬nition 2.14). In order to check independence,
it is enough to check it on a generator of the Ïƒ-algebra (Theorem 2.16). For
example, it can be enough to check independence for intervals, rectangles
or, in the discrete case, for single points. Independence of random variables
can be characterised via product formulas for their joint distribution functions
(Theorem 2.21), densities (Corollary 2.22) or weight functions (exercise!).
The distribution of a sum of independent random variables can be computed
using a convolution formula (Theorem 2.31).
Exercise 2.2.1 Let X and Y be independent random variables with X âˆ¼expÎ¸ and
Y âˆ¼expÏ for certain Î¸, Ï > 0. Show that
P[X < Y] =
Î¸
Î¸ + Ï .
â™£
Exercise 2.2.2 (Boxâ€“Muller method) Let U and V be independent random vari-
ables that are uniformly distributed on [0, 1]. Deï¬ne
X :=
2
âˆ’2 log(U) cos(2Ï€V )
and
Y :=
2
âˆ’2 log(U) sin(2Ï€V ).
Show that X and Y are independent and N0,1-distributed.
Hint: First compute the distribution of
2
âˆ’2 log(U) and then use the transformation
formula (Theorem 1.101) as well as polar coordinates. â™£
Exercise 2.2.3 (Multinomial distribution) Let m âˆˆN and let p = (p1, . . . , pm)
be a probability vector on {1, . . ., m}. Let X1, . . . , Xn be independent random
variables with values in 1, . . . , m and distribution p. We deï¬ne an Nm
0 -valued
random variable Y = (Y1, . . . , Ym) by
Yi := #{k = 1, . . . , n : Xk = i}
for i = 1, . . . , m.

2.3
Kolmogorovâ€™s 0â€“1 Law
69
Show that for k = (k1, . . . , km) âˆˆNm
0 with k1 + . . . + km = n, we have
P[Y = k] = Muln,p({k}) :=
n
k

pk.
(2.11)
Here
n
k

=

n
k1, . . . , km

=
n!
k1! Â· Â· Â· km!
is the multinomial coefï¬cient and pk = pk1
1 Â· Â· Â· pkm
m . The distribution Muln,p on
Nm
0 is called multinomial distribution with parameters n and p. â™£
2.3
Kolmogorovâ€™s 0â€“1 Law
With the Borelâ€“Cantelli lemma, we have seen a ï¬rst 0â€“1 law for independent events.
We now come to another 0â€“1 law for independent events and for independent Ïƒ-
algebras. To this end, we ï¬rst introduce the notion of the tail Ïƒ-algebra.
Deï¬nition 2.34 (Tail Ïƒ-algebra)
Let I be a countably inï¬nite index set and let
(Ai)iâˆˆI be a family of Ïƒ-algebras. Then
T

(Ai)iâˆˆI

:=

JâŠ‚I
#J<âˆ
Ïƒ
 
jâˆˆI\J
Aj

is called the tail Ïƒ-algebra of (Ai)iâˆˆI. If (Ai)iâˆˆI is a family of events, then we deï¬ne
T

(Ai)iâˆˆI

:= T

({âˆ…, Ai, Ac
i , Î©})iâˆˆI

.
If (Xi)iâˆˆI is a family of random variables, then we deï¬ne T

(Xi)iâˆˆI

:=
T

(Ïƒ(Xi))iâˆˆI

.
occurrence is independent of any ï¬xed ï¬nite subfamily of the Xi. To put it
differently, for any ï¬nite subfamily of the Xi, we can change the values of the Xi
arbitrarily without changing whether A occurs or not.
Theorem 2.35 Let J1, J2, . . . be ï¬nite sets with Jn â†‘I. Then
T

(Ai)iâˆˆI

=
âˆ

n=1
Ïƒ


mâˆˆI\Jn
Am

.
In the particular case I = N, this reads T

(An)nâˆˆN

=
âˆ

n=1
Ïƒ
 âˆ

m=n
Am

.

70
2
Independence
The name â€œtail Ïƒ-algebraâ€ is due to the interpretation of I = N as a set of times.
As is made clear in the theorem, any event in T does not depend on the ï¬rst ï¬nitely
many time points.
Proof â€œâŠ‚â€
This is clear.
â€œâŠƒâ€
Let Jn âŠ‚I, n âˆˆN, be ï¬nite sets with Jn â†‘I. Let J âŠ‚I be ï¬nite. Then there
exists an N âˆˆN with J âŠ‚JN and
âˆ

n=1
Ïƒ
 
mâˆˆI\Jn Am

âŠ‚
N

n=1
Ïƒ
 
mâˆˆI\Jn Am

= Ïƒ
 
mâˆˆI\JN Am

âŠ‚Ïƒ
 
mâˆˆI\J Am

.
The left-hand side does not depend on J. Hence we can form the intersection over
all ï¬nite J and obtain
âˆ

n=1
Ïƒ
 
mâˆˆI\Jn Am

âŠ‚T

(Ai)iâˆˆI

.
âŠ“âŠ”
Maybe at ï¬rst glance it is not evident that there are any interesting events in the
tail Ïƒ-algebra at all. It might not even be clear that we do not have T = {âˆ…, Î©}.
Hence we now present simple examples of tail events and tail Ïƒ-algebra measurable
random variables. In Sect. 2.4, we will study a more complex example.
Example 2.36
(i) Let A1, A2, . . . be events. Then the events Aâˆ—:= lim inf
nâ†’âˆAn and Aâˆ—:=
lim sup
nâ†’âˆ
An are in T ((An)nâˆˆN). Indeed, if we deï¬ne Bn :=
âˆ

m=n
Am for n âˆˆN,
then Bn â†‘Aâˆ—and Bn âˆˆÏƒ((Am)mâ‰¥N) for any n â‰¥N. Thus Aâˆ—âˆˆÏƒ((Am)mâ‰¥N)
for any N âˆˆN and hence Aâˆ—âˆˆT ((An)nâˆˆN). The case Aâˆ—is similar.
(ii) Let (Xn)nâˆˆN be a family of R-valued random variables. Then the maps Xâˆ—:=
lim infnâ†’âˆXn and Xâˆ—
:= lim supnâ†’âˆXn are T ((Xn)nâˆˆN)-measurable.
Indeed, if we deï¬ne Yn := supmâ‰¥n Xm, then for any N âˆˆN, the random
variable Xâˆ—= infnâ‰¥1 Yn = infnâ‰¥N Yn is TN := Ïƒ(Xn, n â‰¥N)-measurable
and hence also measurable with respect to T ((Xn)nâˆˆN) = âˆ
n=1 Tn.
The case Xâˆ—is similar.
(iii) Let (Xn)nâˆˆN be real random variables. Then the CesÃ ro limits
lim inf
nâ†’âˆ
1
n
n

i=1
Xi
and
lim sup
nâ†’âˆ
1
n
n

i=1
Xi

2.3
Kolmogorovâ€™s 0â€“1 Law
71
are T ((Xn)nâˆˆN)-measurable. In order to show this, choose N âˆˆN and note
that
Xâˆ—:= lim inf
nâ†’âˆ
1
n
n

i=1
Xi = lim inf
nâ†’âˆ
1
n
n

i=N
Xi
is Ïƒ((Xn)nâ‰¥N)-measurable. Since this holds for any N, Xâˆ—is T ((Xn)nâˆˆN)-
measurable. The case of the limes superior is similar. â™¦
Theorem 2.37 (Kolmogorovâ€™s 0â€“1 Law) Let I be a countably inï¬nite index set
and let (Ai)iâˆˆI be an independent family of Ïƒ-algebras. Then the tail Ïƒ-algebra is
P-trivial, that is,
P[A] âˆˆ{0, 1}
for any A âˆˆT ((Ai)iâˆˆI).
Proof It is enough to consider the case I = N. For n âˆˆN, let
Fn :=
0
n

k=1
Ak : A1 âˆˆA1, . . . , An âˆˆAn
1
.
Then F := âˆ
n=1 Fn is a semiring and Ïƒ(F) = Ïƒ(
nâˆˆN An). Indeed, for any
n âˆˆN and An âˆˆAn, we have An âˆˆF; hence Ïƒ(
nâˆˆN An) âŠ‚Ïƒ(F). On the
other hand, we have Fm âŠ‚Ïƒ(m
n=1 An) âŠ‚Ïƒ(
nâˆˆN An) for any m âˆˆN; hence
F âŠ‚Ïƒ(
nâˆˆN An).
Let A âˆˆT ((An)nâˆˆN) and Îµ > 0. By the approximation theorem for measures
(Theorem 1.65), there exists an N âˆˆN and mutually disjoint sets F1, . . . , FN âˆˆ
F such that P[A â–³(F1 âˆª. . . âˆªFN)] < Îµ. Clearly, there is an n âˆˆN such that
F1, . . . , FN âˆˆFn and thus F := F1 âˆª. . . âˆªFN âˆˆÏƒ(A1 âˆª. . . âˆªAn). Obviously,
A âˆˆÏƒ(âˆ
m=n+1 Am); hence A is independent of F. Thus
Îµ > P[A \ F] = P[A âˆ©(Î© \ F)] = P[A]

1 âˆ’P[F]

â‰¥P[A]

1 âˆ’P[A] âˆ’Îµ

.
Letting Îµ â†“0 yields 0 = P[A](1 âˆ’P[A]).
âŠ“âŠ”
Corollary 2.38 Let (An)nâˆˆN be a sequence of independent events. Then
P
'
lim sup
nâ†’âˆ
An
(
âˆˆ{0, 1}
and
P
'
lim inf
nâ†’âˆAn
(
âˆˆ{0, 1}.
Proof Essentially this is a simple conclusion of the Borelâ€“Cantelli lemma. How-
ever, the statement can also be deduced from Kolmogorovâ€™s 0â€“1 law as limes
superior and limes inferior are in the tail Ïƒ-algebra.
âŠ“âŠ”

72
2
Independence
Corollary 2.39 Let (Xn)nâˆˆN be an independent family of R-valued random vari-
ables. Then Xâˆ—:= lim infnâ†’âˆXn and Xâˆ—:= lim supnâ†’âˆXn
are almost
surely constant. That is, there exist xâˆ—, xâˆ—âˆˆR such that P[Xâˆ—= xâˆ—] = 1 and
P[Xâˆ—= xâˆ—] = 1.
If all Xi are real-valued, then the CesÃ ro limits
lim inf
nâ†’âˆ
1
n
n

i=1
Xi
and
lim sup
nâ†’âˆ
1
n
n

i=1
Xi
are also almost surely constant.
Proof Let Xâˆ—:= lim inf
nâ†’âˆXn. For any x âˆˆR, we have {Xâˆ—â‰¤x} âˆˆT ((Xn)nâˆˆN);
hence P[Xâˆ—â‰¤x] âˆˆ{0, 1}. Deï¬ne
xâˆ—:= inf{x âˆˆR : P[Xâˆ—â‰¤x] = 1} âˆˆR.
If xâˆ—= âˆ, then evidently
P[Xâˆ—< âˆ] = lim
nâ†’âˆP[Xâˆ—â‰¤n] = 0.
If xâˆ—âˆˆR, then
P[Xâˆ—â‰¤xâˆ—] = lim
nâ†’âˆP
'
Xâˆ—â‰¤xâˆ—+ 1
n
(
= 1
and
P[Xâˆ—< xâˆ—] = lim
nâ†’âˆP
'
Xâˆ—â‰¤xâˆ—âˆ’1
n
(
= 0.
If xâˆ—= âˆ’âˆ, then
P[Xâˆ—> âˆ’âˆ] = lim
nâ†’âˆP[Xâˆ—> âˆ’n] = 0.
The cases of the limes superior and the CesÃ ro limits are similar.
âŠ“âŠ”
Takeaways Consider an event that is described by the values of inï¬nitely
many random variables. If the occurrence of the event does not change when
we change ï¬nitely many values of the random variables, then the event is
called terminal. If the random variables are independent, then terminal events
either have probability 0 or 1 (Kolmogorovâ€™s 0â€“1 law). In the Borel-Cantelli
lemma we have encountered a special case.

2.4
Example: Percolation
73
Exercise 2.3.1 Let (Xn)nâˆˆN be an independent family of Rad1/2 random variables
(i.e., P[Xn = âˆ’1] = P[Xn = +1] = 1
2) and let Sn = X1 + . . . + Xn for any n âˆˆN.
Show that lim supnâ†’âˆSn = âˆalmost surely. â™£
Exercise 2.3.2 Consider two families (A1, A3, A5, . . .) and (A2, A4, A6, . . .) of
events and assume that each family is independent but they are not necessarily
independent of each other. In Exercise 2.1.2 it was shown that the conclusion of
the Borel-Cantelli lemma still holds under this weaker assumption. Now ï¬nd an
example that shows that the conclusion of Kolmogorovâ€™s 0â€“1 law need not hold
under this assumption. â™£
2.4
Example: Percolation
Consider the d-dimensional integer lattice Zd, where any point is connected to any
of its 2d nearest neighbors by an edge. If x, y âˆˆZd are nearest neighbors (that is,
âˆ¥x âˆ’yâˆ¥2 = 1), then we denote by e = âŸ¨x, yâŸ©= âŸ¨y, xâŸ©the edge that connects x
and y. Formally, the set of edges is a subset of the set of subsets of Zd with two
elements:
E =
	
{x, y} : x, y âˆˆZd with âˆ¥x âˆ’yâˆ¥2 = 1

.
Somewhat more generally, an undirected graph G is a pair G = (V, E), where V
is a set (the set of â€œverticesâ€ or nodes) and E âŠ‚{{x, y} : x, y âˆˆV, x Ì¸= y} is a
subset of the set of subsets of V of cardinality two (the set of edges or bonds).
Our intuitive understanding of an edge is a connection between two points x and
y and not an (unordered) pair {x, y}. To stress this notion of a connection, we use a
different symbol from the set brackets. That is, we denote the edge that connects x
and y by âŸ¨x, yâŸ©= âŸ¨y, xâŸ©instead of {x, y}.
Our graph (V, E) is the starting point for a stochastic model of a porous medium.
We interpret the edges as tubes along which water can ï¬‚ow. However, we want
the medium not to have a homogeneous structure, such as Zd, but an amorphous
structure. In order to model this, we randomly destroy a certain fraction 1 âˆ’p of
the tubes (with p âˆˆ[0, 1] a parameter) and keep the others. Water can ï¬‚ow only
through the remaining tubes. The destroyed tubes will be called â€œclosedâ€, the others
â€œopenâ€. The fundamental question is: For which values of p is there a connected
inï¬nite system of tubes along which water can ï¬‚ow? The physical interpretation is
that if we throw a block of the considered material into a bathtub, then the block will
soak up water; that is, it will be wetted inside. If there is no inï¬nite open component,
then the water may wet only a thin layer at the surface. See Fig. 2.1 for a computer
simulation of the percolation model.
We now come to a formal description of the model. Choose a parameter
p âˆˆ[0, 1] and an independent family of identically distributed random variables
(Xp
e )eâˆˆE with Xp
e âˆ¼Berp; that is, P[Xp
e = 1] = 1 âˆ’P[Xp
e = 0] = p for any

74
2
Independence
Fig. 2.1 Percolation on a 15 Ã— 15 grid, p = 0.42.
e âˆˆE. We deï¬ne the set of open edges as
Ep := {e âˆˆE : Xp
e = 1}.
(2.12)
Consequently, the edges in E \ Ep are called closed. Hence we have constructed
a (random) subgraph (Zd, Ep) of (Zd, E). We call (Zd, Ep) a percolation model
(more precisely, a model for bond percolation, in contrast to site percolation,
where vertices can be open or closed). An (open) path (of length n) in this subgraph
is a sequence Ï€ = (x0, x1, . . . , xn) of points in Zd with âŸ¨xiâˆ’1, xiâŸ©âˆˆEp for all
i = 1, . . . , n. We say that two points x, y âˆˆZd are connected by an open path if
there is an n âˆˆN and an open path (x0, x1, . . . , xn) with x0 = x and xn = y. In this
case, we write x â†â†’p y. Note that â€œâ†â†’pâ€ is an equivalence relation; however, a
random one, as it depends on the values of the random variables (Xp
e )eâˆˆE. For every
x âˆˆZd, we deï¬ne the (random) open cluster of x; that is, the connected component
of x in the graph (Zd, Ep):
Cp(x) := {y âˆˆZd : x â†â†’p y}.
(2.13)

2.4
Example: Percolation
75
Lemma 2.40 Let x, y âˆˆZd. Then 1{xâ†â†’py} is a random variable. In particular,
#Cp(x) is a random variable for any x âˆˆZd.
Proof We may assume x = 0. Let fy,n = 1 if there exists an open path of length
at most n that connects 0 to y, and fy,n = 0 otherwise. Clearly, fy,n â†‘1{0â†â†’py}
for n â†’âˆ; hence it sufï¬ces to show that each fy,n is measurable. Let Bn :=
{âˆ’n, âˆ’n + 1, . . . , n âˆ’1, n}d and En := {e âˆˆE : e âˆ©Bn Ì¸= âˆ…}. Then Yn :=
(Xp
e : e âˆˆEn) : Î© â†’{0, 1}En is measurable (with respect to 2({0,1}En)) by
Theorem 1.90. However, fy,n is a function of Yn, say fy,n = gy,n â—¦Yn for some map
gy,n : {0, 1}En â†’{0, 1}. By the composition theorem for maps (Theorem 1.80),
fy,n is measurable.
The additional statement holds since #Cp(x) = 
yâˆˆZd 1{xâ†â†’py}.
âŠ“âŠ”
Deï¬nition 2.41 We say that percolation occurs if there exists an inï¬nitely large
open cluster. We call
Ïˆ(p) := P[there exists an inï¬nite open cluster]
= P
' 
xâˆˆZd
{#Cp(x) = âˆ}
(
the probability of percolation. We deï¬ne
Î¸(p) := P[#Cp(0) = âˆ]
as the probability that the origin is in an inï¬nite open cluster.
By the translation invariance of the lattice, we have
Î¸(p) = P[#Cp(y) = âˆ]
for any y âˆˆZd.
(2.14)
The fundamental question is: How large are Î¸(p) and Ïˆ(p) depending on p?
We make the following simple observation.
Theorem 2.42 The map [0, 1] â†’[0, 1], p â†’Î¸(p) is monotone increasing.
Proof Although the statement is intuitively so clear that it might not need a proof,
we give a formal proof in order to introduce a technique called coupling. Let p, pâ€² âˆˆ
[0, 1] with p < pâ€². Let (Ye)eâˆˆE be an independent family of random variables with
P[Ye â‰¤q] = q for any e âˆˆE and q âˆˆ{p, pâ€², 1}. At this point, we could, for
example, assume that Ye âˆ¼U[0,1] is uniformly distributed on [0, 1]. Since we have
not yet shown the existence of an independent family with this distribution, we
content ourselves with Ye that assume only three values {p, pâ€², 1}. Hence
P[Ye = q] =
â§
â¨
â©
p,
if q = p,
pâ€² âˆ’p,
if q = pâ€²,
1 âˆ’pâ€²,
if q = 1.

76
2
Independence
Such a family (Ye)eâˆˆE exists by Theorem 2.19. For q âˆˆ{p, pâ€²} and e âˆˆE, we
deï¬ne
Xq
e :=
0 1,
if Ye â‰¤q,
0,
else.
Clearly, for any q âˆˆ{p, pâ€²}, the family (Xq
e )eâˆˆE of random variables is independent
(see Remark 2.15(iii)) and Xq
e âˆ¼Berq. Furthermore, Xp
e â‰¤Xpâ€²
e for any e âˆˆE. The
procedure of deï¬ning two families of random variables that are related in a speciï¬c
way (here â€œâ‰¤â€) on one probability space is called a coupling.
Clearly, Cp(x) âŠ‚Cpâ€²(x) for any x âˆˆZd; hence Î¸(p) â‰¤Î¸(pâ€²).
âŠ“âŠ”
With the aid of Kolmogorovâ€™s 0â€“1 law, we can infer the following theorem.
Theorem 2.43 For any p âˆˆ[0, 1], we have Ïˆ(p) =

0,
if Î¸(p) = 0,
1,
if Î¸(p) > 0.
Proof If Î¸(p) = 0, then by (2.14)
Ïˆ(p) â‰¤

yâˆˆZd
P[#Cp(y) = âˆ] =

yâˆˆZd
Î¸(p) = 0.
Now let A = 
yâˆˆZd{#Cp(y) = âˆ}. Clearly, A remains unchanged if we change
the state of ï¬nitely many edges. That is, A âˆˆÏƒ((Xp
e )eâˆˆE\F ) for every ï¬nite F âŠ‚E.
Hence A is in the tail Ïƒ-algebra T ((Xp
e )eâˆˆE) by Theorem 2.35. Kolmogorovâ€™s 0â€“1
law (Theorem 2.37) implies that Ïˆ(p) = P[A] âˆˆ{0, 1}. If Î¸(p) > 0, then Ïˆ(p) â‰¥
Î¸(p) implies Ïˆ(p) = 1.
âŠ“âŠ”
Due to the monotonicity, we can make the following deï¬nition.
Deï¬nition 2.44 The critical value pc for percolation is deï¬ned as
pc = inf{p âˆˆ[0, 1] : Î¸(p) > 0} = sup{p âˆˆ[0, 1] : Î¸(p) = 0}
= inf{p âˆˆ[0, 1] : Ïˆ(p) = 1} = sup{p âˆˆ[0, 1] : Ïˆ(p) = 0}.
We come to the main theorem of this section.
Theorem 2.45 For d = 1, we have pc = 1. For d â‰¥2, we have pc(d) âˆˆ
)
1
2dâˆ’1, 2
3
*.
Proof First consider d = 1 and p < 1. Let Aâˆ’:= {Xp
âŸ¨n,n+1âŸ©= 0 for some n < 0}
and A+ := {Xp
âŸ¨n,n+1âŸ©= 0 for some n > 0}. Let A = Aâˆ’âˆ©A+. By the Borelâ€“
Cantelli lemma, we get P[Aâˆ’] = P[A+] = 1. Hence Î¸(p) = P[Ac] = 0.
Now assume d â‰¥2.

2.4
Example: Percolation
77
Lower bound First we show pc â‰¥
1
2dâˆ’1. Clearly, for any n âˆˆN,
P[#Cp(0) = âˆ] â‰¤P
)
there is an x âˆˆCp(0) with âˆ¥xâˆ¥âˆ= n
*
.
We want to estimate the probability that there exists a point x âˆˆCp(0) with distance
n from the origin. Any such point is connected to the origin by a path without self-
intersections Ï€ that starts at 0 and has length m â‰¥n. Let Î 0,m be the set of such
paths. Clearly, #Î 0,m â‰¤2d Â·(2d âˆ’1)mâˆ’1 since there are 2d choices for the ï¬rst step
and at most 2d âˆ’1 choices for any further step. For any Ï€ âˆˆÎ 0,m, the probability
that Ï€ uses only open edges is
P[Ï€ is open] = pm.
Hence, for p <
1
2dâˆ’1,
Î¸(p) â‰¤
âˆ

m=n

Ï€âˆˆÎ 0,m
P[Ï€ is open] â‰¤
2d
2d âˆ’1
âˆ

m=n

(2d âˆ’1)p
m
=
2d
(2d âˆ’1)(1 âˆ’(2d âˆ’1)p)
(2d âˆ’1)pn nâ†’âˆ
âˆ’â†’0.
We conclude that pc â‰¥
1
2dâˆ’1.
Upper bound We can consider Zd as a subset of Zd Ã— {0} âŠ‚Zd+1. Hence,
if percolation occurs for p in Zd, then it also occurs for p in Zd+1. Hence the
corresponding critical values are ordered pc(d + 1) â‰¤pc(d).
Thus, it is enough to consider the case d = 2. Here we show pc â‰¤2
3 by using a
contour argument due to Peierls [127], originally designed for the Ising model of a
ferromagnet, see Example 18.16 and (18.9).
For N âˆˆN, we deï¬ne (compare (2.13) with x = (i, 0))
CN :=
N

i=0
Cp(i, 0)
as the set of points that are connected (along open edges) to at least one of the
points in {0, . . . , N} Ã— {0}. Due to the subadditivity of probability (and since
P[#Cp
(i, 0)

= âˆ] = Î¸(p) for any i âˆˆZ), we have
Î¸(p) =
1
N + 1
N

i=0
P
)
#Cp
(i, 0)

= âˆ
*
â‰¥
1
N + 1P
)
#CN = âˆ
*
.

78
2
Independence
Now consider those closed contours in the dual graph ( ËœZ2, ËœE) that surrounds CN if
#CN < âˆ. Here the dual graph is deï¬ned by
ËœZ2 =
1
2, 1
2

+ Z2,
ËœE =

{x, y} : x, y âˆˆËœZ2, âˆ¥x âˆ’yâˆ¥2 = 1

.
An edge Ëœe in the dual graph ( ËœZ2, ËœE) crosses exactly one edge e in (Z2, E). We
call Ëœe open if e is open and closed otherwise. A circle Î³ is a self-intersection free
path in ( ËœZ2, ËœE) that starts and ends at the same point. A contour of the set CN is a
minimal circle that surrounds CN. Minimal means that the enclosed area is minimal
(see Fig. 2.2). For n â‰¥2N, let
Î“n =

Î³ : Î³ is a circle of length n that surrounds {0, . . ., N} Ã— {0}

.
We want to deduce an upper bound for #Î“n. Let Î³ âˆˆÎ“n and ï¬x one point of Î³ .
For deï¬niteness, choose the upper point

m + 1
2, 1
2

of the rightmost edge of Î³ that
crosses the horizontal axis (in Fig. 2.2 this is the point

5 + 1
2, 1
2

). Clearly, m â‰¥N
and m â‰¤n since Î³ surrounds the origin. Starting from

m + 1
2, 1
2

, for any further
0
âˆ’1
1
5
0
âˆ’1
1
Fig. 2.2 Contour of the cluster C5.

2.4
Example: Percolation
79
edge of Î³ , there are at most three possibilities. Hence
#Î“n â‰¤n Â· 3n.
We say that Î³ is closed if it uses only closed edges (in ËœE). A contour of CN is
automatically closed and has a length of at least 2N. Hence for p > 2
3
P[#CN < âˆ] =
âˆ

n=2N
P
)
there is a closed circle Î³ âˆˆÎ“n
*
â‰¤
âˆ

n=2N
n Â·

3(1 âˆ’p)
n
Nâ†’âˆ
âˆ’â†’
0.
We conclude pc â‰¤2
3.
âŠ“âŠ”
In general, the value of pc is not known and is extremely hard to determine. In the
case of bond percolation on Z2, however, the exact value of pc can be determined
due to the self-duality of the planar graph (Z2, E). (If G = (V, E) is a planar graph;
that is, a graph that can be embedded into R2 without self-intersections, then the
vertex set of the dual graph is the set of faces of G. Two such vertices are connected
by exactly one edge; that is, by the edge in E that separates the two faces. Evidently,
the two-dimensional integer lattice is isomorphic to its dual graph. Note that the
contour in Fig. 2.2 can be considered as a closed path in the dual graph.) We cite a
theorem of Kesten [94].
Theorem 2.46 (Kesten [94]) For bond percolation in Z2, the critical value is pc =
1
2 and Î¸(pc) = 0.
Proof See, for example, the book of Grimmett [63, pages 287ff].
âŠ“âŠ”
It is conjectured that Î¸(pc) = 0 holds in any dimension d â‰¥2. However, rigorous
proofs are known only for d = 2 and d â‰¥19 (see [67]).
Uniqueness of the Inï¬nite Open Clusterâˆ—
Fix a p such that Î¸(p) > 0. We saw that with probability one there is at least one
inï¬nite open cluster. Now we want to show that there is exactly one.
Denote by N âˆˆ{0, 1, . . ., âˆ} the (random) number of inï¬nite open clusters.
Theorem 2.47 (Uniqueness of the inï¬nite open cluster) For any p âˆˆ[0, 1], we
have Pp[N â‰¤1] = 1.
Proof This theorem was ï¬rst proved by Aizenman, Kesten and Newman [2, 3]. Here
we follow the proof of Burton and Keane [23] as described in [63, Section 8.2].

80
2
Independence
The cases p = 1 and Î¸(p) = 0 (hence in particular the case p = 0) are trivial.
Hence we assume now that p âˆˆ(0, 1) and Î¸(p) > 0.
Step 1.
We ï¬rst show that
Pp[N = m] = 1
for some m = 0, 1, . . . , âˆ.
(2.15)
We need a 0â€“1 law similar to that of Kolmogorov. However, N is not measurable
with respect to the tail Ïƒ-algebra. Hence we have to ï¬nd a more subtle argument.
Let u1 = (1, 0, . . . , 0) be the ï¬rst unit vector in Zd. On the edge set E, deï¬ne the
translation Ï„ : E â†’E by Ï„(âŸ¨x, yâŸ©) = âŸ¨x + u1, y + u1âŸ©. Let
E0 :=
	
âŸ¨(x1, . . . , xd), (y1, . . . , yd)âŸ©âˆˆE : x1 = 0, y1 â‰¥0

be the set of all edges in Zd that either connect two points from {0} Ã— Zdâˆ’1
or one point of {0} Ã— Zdâˆ’1 with one point of {1} Ã— Zdâˆ’1. Clearly, the sets
(Ï„ n(E0), n âˆˆZ) are disjoint and E = 
nâˆˆZ Ï„ n(E0). Hence the random variables
Yn := (Xp
Ï„ n(e))eâˆˆE0, n âˆˆZ, are independent and identically distributed (with values
in {0, 1}E0).Deï¬ne Y = (Yn)nâˆˆZ and Ï„(Y) = (Yn+1)nâˆˆZ. Deï¬ne Am âˆˆ{0, 1}E by
{Y âˆˆAm} = {N = m}.
Clearly, the value of N does not change if we shift all edges simultaneously. That
is, {Y âˆˆAm} = {Ï„(Y) âˆˆAm}. An event with this property is called invariant or
shift invariant. Using an argument similar to that in the proof of Kolmogorovâ€™s 0â€“1
law, one can show that invariant events (deï¬ned by i.i.d. random variables) have
probability either 0 or 1 (see Example 20.26 for a proof).
Step 2.
We will show that
Pp[N = m] = 0
for any m âˆˆN \ {1}.
(2.16)
Accordingly, let m = 2, 3, . . .. We assume that P[N = m] = 1 and show that this
leads to a contradiction.
For L âˆˆN, let BL := {âˆ’L, . . . , L}d and denote by EL = {e = âŸ¨x, yâŸ©âˆˆE :
x, y âˆˆBL} the set of those edges with both vertices lying in BL. For i = 0, 1, let
Di
L := {Xp
e = i for all e âˆˆEL}. Let N1
L be the number of inï¬nite open clusters if
we consider all edges e in EL as open (independently of the value of Xp
e ). Similarly
deï¬ne N0
L where we consider all edges in EL as closed. Since Pp[Di
L] > 0, and
since N = m almost surely, we have Ni
L = m almost surely for i = 0, 1.
Let
A2
L:=

x1,x2âˆˆBL\BLâˆ’1
	Cp(x1) âˆ©Cp(x2) = âˆ…
 âˆ©	#Cp(x1) = #Cp(x2) = âˆ

2.4
Example: Percolation
81
be the event where there exist two points on the boundary of BL that lie in different
inï¬nite open clusters. Clearly, A2
L â†‘{N â‰¥2} for L â†’âˆ.
Deï¬ne A2
L,0 in a similarly way to A2
L; however, we now consider all edges e âˆˆEL
as closed, irrespective of whether Xp
e = 1 or Xp
e = 0. If A2
L occurs, then there
are two points x1, x2 on the boundary of BL such that for any i = 1, 2, there is an
inï¬nite self-intersection free open path Ï€xi starting at xi that avoids x3âˆ’i. Hence
A2
L âŠ‚A2
L,0. Now choose L large enough for P[A2
L,0] > 0.
If A2
L,0 occurs and if we open all edges in BL, then at least two of the inï¬nite
open clusters get connected by edges in BL. Hence the total number of inï¬nite open
clusters decreases by at least one. We infer Pp[N1
L â‰¤N0
L âˆ’1] â‰¥Pp[A2
L,0] > 0,
which leads to a contradiction.
Step 3.
In Step 2, we have shown already that N does not assume a ï¬nite value
larger than 1. Hence it remains to show that almost surely N does not assume the
value âˆ. Indeed, we show that
Pp[N â‰¥3] = 0.
(2.17)
This part of the proof is the most difï¬cult one. We assume that Pp[N â‰¥3] > 0 and
show that this leads to a contradiction.
We say that a point x âˆˆZd is a trifurcation point if
â€¢
x is in an inï¬nite open cluster Cp(x),
â€¢
there are exactly three open edges with endpoint x, and
â€¢
removing all of these three edges splits Cp(x) into three mutually disjoint inï¬nite
open clusters.
By T we denote the set of trifurcation points, and let TL := T âˆ©BL. Let r := Pp[0 âˆˆ
T ]. Due to translation invariance, we have (#BL)âˆ’1Ep[#TL] = r for any L. (Here
Ep[#TL] denotes the expected value of #TL, which we deï¬ne formally in Chap. 5.)
Let
A3
L:=

x1,x2,x3âˆˆBL\BLâˆ’1
 
iÌ¸=j
{Cp(xi) âˆ©Cp(xj) = âˆ…}

âˆ©
 3

i=1
{#Cp(xi) = âˆ}

be the event where there are three points on the boundary of BL that lie in different
inï¬nite open clusters. Clearly, A3
L â†‘{N â‰¥3} for L â†’âˆ.
As for A2
L,0, we deï¬ne A3
L,0 as the event where there are three distinct points on
the boundary of BL that lie in different inï¬nite open clusters if we consider all edges
in EL as closed. As above, we have A3
L âŠ‚A3
L,0.

82
2
Independence
For three distinct points x1, x2, x3 âˆˆBL \ BLâˆ’1, let Fx1,x2,x3 be the event
where for any i = 1, 2, 3, there exists an inï¬nite self-intersection free open path
Ï€xi starting at xi that uses only edges in Ep \ EL and that avoids the points xj,
j Ì¸= i. Then
A3
L,0 âŠ‚

x1,x2,x3âˆˆBL\BLâˆ’1
mutually distinct
Fx1,x2,x3.
Let L be large enough for Pp[A3
L,0] â‰¥Pp[N â‰¥3]/2 > 0. Choose three pairwise
distinct points x1, x2, x3 âˆˆBL \ BLâˆ’1 with Pp[Fx1,x2,x3] > 0.
If Fx1,x2,x3 occurs, then we can ï¬nd a point y âˆˆBL that is the starting point of
three mutually disjoint (not necessarily open) paths Ï€1, Ï€2 and Ï€3 that end at x1, x2
and x3. Let Gy,x1,x2,x3 be the event where in EL exactly those edges are open that
belong to these three paths (that is, all other edges in EL are closed). The events
Fx1,x2,x3 and Gy,x1,x2,x3 are independent, and if both of them occur, then y is a
trifurcation point. Hence
r = Pp[y âˆˆT ] â‰¥Pp[Fx1,x2,x3] Â·

p âˆ§(1 âˆ’p)
#EL > 0.
Now we show that r must equal 0, which contradicts the assumption Pp[N â‰¥3] >
0. Let KL be the set of all edges which have at least one endpoint in BL. We consider
two edges in KL as equivalent if there exists a path in BL along open edges that does
not hit any trifurcation point and which joins at least one endpoint of each of the two
edges. We denote the equivalence relation by R and let UL = KL/R be the set of
equivalence classes. (Note that the three neighboring edges of a trifurcation point
are in different equivalence classes.) We turn the set HL := UL âˆªTL into a graph
by considering two points x âˆˆTL and u âˆˆUL as neighbors if there exists an edge
k âˆˆu which is incident to x. Note that each point x âˆˆTL has exactly three neighbors
which are in UL. The points in UL can be isolated (that is, without neighbors) or can
be joined to arbitrarily many points in TL but not in UL.
A circle is a self-avoiding (ï¬nite) path that ends at its starting point. Note that
the graph HL has no circles. To show this assume there was a self-avoiding path
(h0, h1, . . . , hn) starting and ending in some point h0 = hn = x âˆˆTL. Then
h1, hnâˆ’1 âˆˆUL are distinct but connected in Kp even if we remove x. However,
by the deï¬nition of the trifurcation point x, this is impossible. On the other hand,
if there was a self-avoiding path (g0, . . . , gm) starting and ending in some point
g0 = gm = u âˆˆUL, then (g1, g2, . . . , gm, g1) is a self-avoiding path starting and
ending in g1 âˆˆTL. However, we have just shown that such a path could not exist.
Write degHL(h) for the degree of h âˆˆHL; that is, the number of neighbors of h
in HL. A point h with degHL(h) = 1 is called a leaf of HL. Obviously, only points
of UL can be leaves. Let Z be a connected component of HL that contains at least

2.4
Example: Percolation
83
one point x âˆˆTL. Since Z is a tree (that is, it is connected and contains no circles),
we have
#Z âˆ’1 = 1
2

hâˆˆZ
degHL(h).
Rearranging this formula yields an expression for the number of leaves:
#	u âˆˆZ : degHL(u) = 1
 = 2 +

hâˆˆZ
 degHL(h) âˆ’2+
â‰¥2 + #	h âˆˆZ : degHL(h) â‰¥3
â‰¥2 + #(Z âˆ©TL).
Summing over the connected components Z of HL with at least one point in TL, we
obtain
#	u âˆˆHL : degHL(u) = 1
 â‰¥#TL.
Observe that any leaf u âˆˆHL contains an edge that is incident to a point x âˆˆTL.
Hence the edges of u lie in an inï¬nite open cluster of Kp and there is at least one
edge k âˆˆu incident to a point at the boundary BL \ BLâˆ’1 of BL. For distinct leaves
these are distinct points since the leaves belong to disjoint open clusters. Hence we
get the bound
#TL â‰¤#(BL \ BLâˆ’1)
and thus
#TL
#BL
â‰¤#(BL \ BLâˆ’1)
#BL
â‰¤d
L
Lâ†’âˆ
âˆ’â†’
0.
Now r = (#BL)âˆ’1Ep[#TL] â‰¤d/L implies r = 0. (Note that in the argument we
used the notion of the expected value Ep[#TL] that will be formally introduced only
in Chap. 5.)
âŠ“âŠ”
Takeaways Independent coin tosses decide if an edge of Zd is retained
(probability p) or removed. The remaining random graph almost surely
contains a (unique) inï¬nite connected component if p is larger than a critical
value pc. For d â‰¥2, we have 0 â‰¤
1
2dâˆ’1 â‰¤pc â‰¤2
3 (Theorem 2.45). Starting
with a graph other than Zd, for example an inï¬nite binary tree, can result in
multiple inï¬nite connected components (Exercise 2.4.1).

84
2
Independence
0
Fig. 2.3 Binary tree.
Exercise 2.4.1 Let T be the inï¬nite binary tree (Fig. 2.3). That is, each point in T
has exactly three neighbours. We single out an arbitrary point of T and name it 0.
Now consider bond percolation on T with probability p.
(i) Show that pc
â‰¥1/2. Hint: Use a similar argument as in the proof of
Theorem 2.45.
(ii) Let Jn be the number of connected subgraphs of T that contain 0. Show that
Jn â‰¤4n+1. Use a contour argument similarly as in Theorem 2.45 to show that
pc â‰¤3
4. (In fact, we could use the theory of branching processes to show that
pc = 1
2.)
(iii) For p âˆˆ(pc, 1), show that with positive probability there are at least two
inï¬nite connected components.
In (iii) one can even show that almost surely there are inï¬nitely many inï¬nite
connected components. â™£

Chapter 3
Generating Functions
It is a fundamental principle of mathematics to map a class of objects that are of
interest into a class of objects where computations are easier. This map can be one to
one, as with linear maps and matrices, or it may map only some properties uniquely,
as with matrices and determinants.
In probability theory, in the second category fall quantities such as the median,
mean and variance of random variables. In the ï¬rst category, we have characteristic
functions, Laplace transforms and probability generating functions. These are useful
mostly because addition of independent random variables leads to multiplication
of the transforms. Before we introduce characteristic functions (and Laplace
transforms) later in the book, we want to illustrate the basic idea with probability
generating functions that are designed for N0-valued random variables.
In the ï¬rst section, we give the basic deï¬nitions and derive simple properties.
The next two sections are devoted to two applications: The Poisson approximation
theorem and a simple investigation of Galtonâ€“Watson branching processes.
3.1
Deï¬nition and Examples
Deï¬nition 3.1 (Probability generating function) Let X be an N0-valued random
variable. The (probability) generating function (p.g.f.) of PX (or, loosely speaking,
of X) is the map ÏˆPX = ÏˆX deï¬ned by (with the understanding that 00 = 1)
ÏˆX : [0, 1] â†’[0, 1],
z â†’
âˆ

n=0
P[X = n] zn.
(3.1)
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_3
85

86
3
Generating Functions
Theorem 3.2
(i) ÏˆX is continuous on [0, 1] and inï¬nitely often continuously differentiable on
(0, 1). For n âˆˆN, the nth derivative Ïˆ(n)
X fulï¬lls
lim
zâ†‘1 Ïˆ(n)
X (z) =
âˆ

k=n
P[X = k] Â· k(k âˆ’1) Â· Â· Â· (k âˆ’n + 1),
(3.2)
where both sides can equal âˆ.
(ii) The distribution PX of X is uniquely determined by ÏˆX.
(iii) For any r âˆˆ(0, 1), ÏˆX is uniquely determined by countably many values
ÏˆX(xi), xi âˆˆ[0, r], i âˆˆN. If the series in (3.1) converges for some z > 1,
then the statement is also true for any r âˆˆ(0, z) and we have
lim
xâ†‘1 Ïˆ(n)
X (x) = Ïˆ(n)
X (1) < âˆ
for n âˆˆN.
In this case, ÏˆX is uniquely determined by the derivatives Ïˆ(n)
X (1), n âˆˆN.
Proof The statements follow from the elementary theory of power series. For the
ï¬rst part of (iii), see, eg. [149, Theorem 8.5].
âŠ“âŠ”
Reï¬‚ection Come up with an example for X such that the series in (3.1) does not
converge for any z > 1 but lim
xâ†‘1 Ïˆâ€²
X(x) exists and is ï¬nite. â™ â™ 
Theorem 3.3 (Multiplicativity of generating functions) If X1, . . . , Xn are inde-
pendent and N0-valued random variables, then
ÏˆX1+...+Xn =
n

i=1
ÏˆXi .
Proof Let z âˆˆ[0, 1) and write ÏˆX1(z) ÏˆX2(z) as a Cauchy product
ÏˆX1(z) ÏˆX2(z) =
 âˆ

n=0
P[X1 = n] zn
  âˆ

n=0
P[X2 = n] zn

=
âˆ

n=0
zn
 n

m=0
P[X1 = m] P[X2 = n âˆ’m]

=
âˆ

n=0
zn
n

m=0
P[X1 = m, X2 = n âˆ’m]
=
âˆ

n=0
P[X1 + X2 = n] zn = ÏˆX1+X2(z).
Inductively, the claim follows for all n â‰¥2.
âŠ“âŠ”

3.1
Deï¬nition and Examples
87
Example 3.4
(i) Let X be bn,p-distributed for some n âˆˆN and let p âˆˆ[0, 1]. Then
ÏˆX(z) =
n

m=0
n
m

pm(1 âˆ’p)nâˆ’m zm =

pz + (1 âˆ’p)
n.
(3.3)
(ii) If X, Y are independent, X âˆ¼bm,p and Y âˆ¼bn,p, then, by Theorem 3.3,
ÏˆX+Y (z) =

pz + (1 âˆ’p)
m 
pz + (1 âˆ’p)
n =

pz + (1 âˆ’p)
m+n.
Hence, by Theorem 3.2(ii), X + Y is bm+n,p-distributed and thus (by Theo-
rem 2.31)
bm,p âˆ—bn,p = bm+n,p.
(iii) Let X and Y be independent Poisson random variables with parameters Î» â‰¥0
and Î¼ â‰¥0, respectively. That is, P[X = n] = eâˆ’Î»Î»n/n! for n âˆˆN0. Then
ÏˆPoiÎ»(z) =
âˆ

n=0
eâˆ’Î» (Î»z)n
n!
= eÎ»(zâˆ’1).
(3.4)
Hence X + Y has probability generating function
ÏˆPoiÎ»(z) Â· ÏˆPoiÎ¼(z) = eÎ»(zâˆ’1) eÎ¼(zâˆ’1) = ÏˆPoiÎ»+Î¼(z).
Thus X + Y âˆ¼PoiÎ»+Î¼. We conclude that
PoiÎ» âˆ—PoiÎ¼ = PoiÎ»+Î¼.
(3.5)
(iv) Let X1, . . . , Xn
âˆ¼Î³p be independent geometrically distributed random
variables with parameter p âˆˆ(0, 1). Deï¬ne Y = X1 + . . . + Xn. Then, for
any z âˆˆ[0, 1],
ÏˆX1(z) =
âˆ

k=0
p(1 âˆ’p)k zk =
p
1 âˆ’(1 âˆ’p)z.
(3.6)

88
3
Generating Functions
By the generalized binomial theorem (see Lemma 3.5 with Î±
= âˆ’n),
Theorem 3.3 and (3.6), we have
ÏˆY (z) = ÏˆX1(z)n =
pn
(1 âˆ’(1 âˆ’p)z)n
=
âˆ

k=0
pn
âˆ’n
k

(âˆ’1)k (1 âˆ’p)k zk
=
âˆ

k=0
bâˆ’
n,p({k}) zk.
Here, for r âˆˆ(0, âˆ) and p âˆˆ(0, 1],
bâˆ’
r,p =
âˆ

k=0
âˆ’r
k

(âˆ’1)k pr(1 âˆ’p)k Î´k
(3.7)
is the negative binomial distribution with parameters r and p. By the unique-
ness theorem for probability generating functions, we get Y âˆ¼bâˆ’
n,p; hence (see
Deï¬nition 2.29 for the nth convolution power) bâˆ’
n,p = Î³ âˆ—n
p . â™¦
Lemma 3.5 (Generalized binomial theorem) For Î± âˆˆR and k âˆˆN0, we deï¬ne
the binomial coefï¬cient
Î±
k

:= Î± Â· (Î± âˆ’1) Â· Â· Â· (Î± âˆ’k + 1)
k!
.
(3.8)
Then the generalized binomial theorem holds:
(1 + x)Î± =
âˆ

k=0
Î±
k

xk
for all x âˆˆC with |x| < 1.
(3.9)
In particular, we have
1
âˆš
1 âˆ’x
=
âˆ

n=0
2n
n

4âˆ’n xn
for all x âˆˆC with |x| < 1.
(3.10)
Proof The map f : x â†’(1 + x)Î± is holomorphic up to possibly a singularity
at x = âˆ’1. Hence it can be developed in a power series about 0 with radius of
convergence at least 1:
f (x) =
âˆ

k=0
f (k)(0)
k!
xk
for |x| < 1.

3.2
Poisson Approximation
89
For k âˆˆN0, the kth derivative is f (k)(0) = Î±(Î± âˆ’1) Â· Â· Â· (Î± âˆ’k + 1). Hence (3.9)
holds.
The additional claim follows by the observation that (for Î± = âˆ’1/2) we have
âˆ’1/2
n
 = 2n
n
(âˆ’4)âˆ’n.
âŠ“âŠ”
Takeaways Generating functions determine a probability distribution on N0.
They are the perfect analytic tool for studying sums of independent random
variables (on N0) as these sums translate into products of the generating
functions.
Exercise 3.1.1 Show that bâˆ’
r,p âˆ—bâˆ’
s,p = bâˆ’
r+s,p for r, s âˆˆ(0, âˆ) and p âˆˆ(0, 1]. â™£
Exercise 3.1.2 Give an example for two different probability generating functions
that coincide at countably many points xi âˆˆ(0, 1), i âˆˆN. (That is, in Theo-
rem 3.2(iii), the assumption Ïˆ(z) < âˆfor some z > 1 cannot be dropped.) â™£
3.2
Poisson Approximation
Lemma 3.6 Let Î¼ and (Î¼n)nâˆˆN be probability measures on (N0, 2N0) with gener-
ating functions Ïˆ and Ïˆn, n âˆˆN. Then the following statements are equivalent.
(i)
Î¼n({k})
nâ†’âˆ
âˆ’â†’Î¼({k}) for all k âˆˆN0.
(ii)
Î¼n(A)
nâ†’âˆ
âˆ’â†’Î¼(A)
for all A âŠ‚N0.
(iii)
Ïˆn(z)
nâ†’âˆ
âˆ’â†’Ïˆ(z)
for all z âˆˆ[0, 1].
(iv)
Ïˆn(z)
nâ†’âˆ
âˆ’â†’Ïˆ(z)
for all z âˆˆ[0, Î·) for some Î· âˆˆ(0, 1).
We write Î¼n
nâ†’âˆ
âˆ’â†’Î¼ if any of the four conditions holds and say that (Î¼n)nâˆˆN
converges weakly to Î¼.
Proof (i) â‡’(ii)
Fix Îµ > 0 and choose N âˆˆN such that Î¼({N + 1, N +
2, . . .}) < Îµ
4. For sufï¬ciently large n0 âˆˆN, we have
N

k=0
Î¼n({k}) âˆ’Î¼({k})
 < Îµ
4
for all n â‰¥n0.

90
3
Generating Functions
In particular, for any n â‰¥n0, we have Î¼n({N + 1, N + 2, . . .}) < Îµ
2. Hence, for
n â‰¥n0,
Î¼n(A) âˆ’Î¼(A)
 â‰¤Î¼n({N + 1, N + 2, . . .}) + Î¼({N + 1, N + 2, . . .})
+

kâˆˆAâˆ©{0,...,N}
Î¼n({k}) âˆ’Î¼({k})

< Îµ.
(ii) â‡’(i)
This is trivial.
(i) â‡â‡’(iii) â‡â‡’(iv)
This follows from the elementary theory of power series.
âŠ“âŠ”
Reï¬‚ection If instead of Î¼(N0) = 1, in the previous lemma we only assume
Î¼(N0) âˆˆ[0, 1], then we still have (i) â‡ (ii)
â‡â‡’
(iii)
â‡â‡’
(iv), but not
(i) â‡’(ii). Why? â™ 
Let (pn,k)n,kâˆˆN be numbers with pn,k âˆˆ[0, 1] such that the limit
Î» := lim
nâ†’âˆ
âˆ

k=1
pn,k âˆˆ(0, âˆ)
(3.11)
exists and such that lim
nâ†’âˆ
âˆ
k=1 p2
n,k = 0 (e.g., pn,k = Î»/n for k â‰¤n and pn,k = 0
for k > n). For each n âˆˆN, let (Xn,k)kâˆˆN be an independent family of random
variables with Xn,k âˆ¼Berpn,k.
Deï¬ne
Sn :=
âˆ

l=1
Xn,l
and
Sn
k :=
k

l=1
Xn,l
for k âˆˆN.
Theorem 3.7 (Poisson approximation) Under the above assumptions, the distri-
butions (PSn)nâˆˆN converge weakly to the Poisson distribution PoiÎ».
Proof The p.g.f. of the Poisson distribution is Ïˆ(z) = eÎ»(zâˆ’1) (see (3.4)). On the
other hand, Sn âˆ’Sn
k and Sn
k are independent for any k âˆˆN; hence ÏˆSn = ÏˆSn
k Â·
ÏˆSnâˆ’Sn
k . Now, for any z âˆˆ[0, 1],
1 â‰¥ÏˆSn(z)
ÏˆSn
k (z) = ÏˆSnâˆ’Sn
k (z) â‰¥1 âˆ’P[Sn âˆ’Sn
k â‰¥1] â‰¥1 âˆ’
âˆ

l=k+1
pn,l
kâ†’âˆ
âˆ’â†’1,

3.3
Branching Processes
91
hence
ÏˆSn(z) = lim
kâ†’âˆÏˆSn
k (z) =
âˆ

l=1
(pn,lz + (1 âˆ’pn,l))
= exp
 âˆ

l=1
log

1 + pn,l(z âˆ’1)


.
Note that | log(1 + x) âˆ’x| â‰¤x2 for |x| < 1
2. By assumption, max
lâˆˆN pn,l â†’0 for
n â†’âˆ; hence, for sufï¬ciently large n,

 âˆ

l=1
log

1 + pn,l(z âˆ’1)

âˆ’

(z âˆ’1)
âˆ

l=1
pn,l

â‰¤
âˆ

l=1
p2
n,l â‰¤
 âˆ

l=1
pn,l

max
lâˆˆN pn,l
nâ†’âˆ
âˆ’â†’0.
Together with (3.11), we infer
lim
nâ†’âˆÏˆSn(z) = lim
nâ†’âˆexp

(z âˆ’1)
âˆ

l=1
pn,l

= eÎ»(zâˆ’1).
âŠ“âŠ”
Takeaways The number of successes of a large number of improbable
independent events is approximately Poisson distributed. Hence the Poisson
distribution is used to model the number of rare successes in a large number
of trials.
Exercise 3.2.1 Let Î» > 0 and pn = Î»/n, n âˆˆN. In Theorem 3.7, it was shown that
the binomial distribution bn,Î»/n converges to the Poisson distribution PoiÎ». Show
this with a different approach by checking condition (i) from Lemma 3.6. â™£
3.3
Branching Processes
Branching processes are models for the random development of the size of a
population. Generating functions are the ideal tool for the analysis of such processes.

92
3
Generating Functions
Let T, X1, X2, . . . be independent N0-valued random variables. What is the
distribution of S := T
n=1 Xn? First of all, note that S is measurable since
{S = k} =
âˆ

n=0
{T = n} âˆ©{X1 + . . . + Xn = k}.
Theorem 3.8 If the random variables X1, X2, . . . are also identically distributed,
then the probability generating function of S is given by ÏˆS(z) = ÏˆT (ÏˆX1(z)).
Proof We compute
ÏˆS(z) =
âˆ

k=0
P[S = k] zk
=
âˆ

k=0
âˆ

n=0
P[T = n] P[X1 + . . . + Xn = k] zk
=
âˆ

n=0
P[T = n] ÏˆX1(z)n = ÏˆT
ÏˆX1(z).
âŠ“âŠ”
Now assume that p0, p1, p2, . . . âˆˆ[0, 1] are such that
âˆ

k=0
pk = 1. Let (Xn,i)n,iâˆˆN0
be an independent family of random variables with P[Xn,i = k] = pk for all
i, k, n âˆˆN0.
Let Z0 = 1 and
Zn =
Znâˆ’1

i=1
Xnâˆ’1,i
for n âˆˆN.
Zn can be interpreted as the number of individuals in the nth generation of a
randomly developing population. The ith individual in the nth generation has Xn,i
offspring (in the (n + 1)th generation).
Deï¬nition 3.9 (Zn)nâˆˆN0 is called a Galtonâ€“Watson process or branching process
with offspring distribution (pk)kâˆˆN0.
Probability generating functions are an important tool for the investigation of
branching processes. Hence, let
Ïˆ(z) =
âˆ

k=0
pk zk

3.3
Branching Processes
93
be the p.g.f. of the offspring distribution and let Ïˆâ€² be its derivative. Recursively,
deï¬ne the nth iterate of Ïˆ by
Ïˆ1 := Ïˆ
and
Ïˆn := Ïˆ â—¦Ïˆnâˆ’1 for n = 2, 3, . . . .
Finally, let ÏˆZn be the p.g.f. of Zn.
Lemma 3.10 Ïˆn = ÏˆZn for all n âˆˆN.
Proof For n = 1, the statement is true by deï¬nition. For n âˆˆN, we conclude
inductively by Theorem 3.8 that ÏˆZn+1 = Ïˆ â—¦ÏˆZn = Ïˆ â—¦Ïˆn = Ïˆn+1.
âŠ“âŠ”
Clearly, the probability qn := P[Zn = 0] that Z is extinct by time n is monotone
increasing in n. We denote by
q := lim
nâ†’âˆP[Zn = 0]
the extinction probability; that is, the probability that the population will eventually
die out.
Under what conditions do we have q = 0, q = 1, or q âˆˆ(0, 1)? Clearly, q â‰¥p0.
On the other hand, if p0 = 0, then Zn is monotone in n; hence q = 0.
Theorem 3.11 (Extinction probability of the Galtonâ€“Watson process)
Assume p1 Ì¸= 1. Then:
(i) F := {r âˆˆ[0, 1] : Ïˆ(r) = r} = {q, 1}.
(ii) The following equivalences hold:
q < 1
â‡â‡’
lim
zâ†‘1 Ïˆâ€²(z) > 1
â‡â‡’
âˆ

k=1
kpk > 1.
Proof
(i) We have Ïˆ(1) = 1; hence 1 âˆˆF. Note that
qn = Ïˆn(0) = Ïˆ(qnâˆ’1)
for all n âˆˆN
and qn â†‘q. Since Ïˆ is continuous, we infer
Ïˆ(q) = Ïˆ

lim
nâ†’âˆqn

=
lim
nâ†’âˆÏˆ(qn) =
lim
nâ†’âˆqn+1 = q.
Thus q âˆˆF. If r âˆˆF is an arbitrary ï¬xed point of Ïˆ, then r â‰¥0 = q0. Since Ïˆ
is monotone increasing, it follows that r = Ïˆ(r) â‰¥Ïˆ(q0) = q1. Inductively,
we get r â‰¥qn for all n âˆˆN0; that is, r â‰¥q. We conclude q = min F.
(ii) If p0+p1 = 1, then all of the statements are obvious. Now assume p0+p1 < 1.
For the ï¬rst equivalence, we distinguish two cases.

94
3
Generating Functions
Case 1:
limzâ†‘1 Ïˆâ€²(z) â‰¤1. Since Ïˆ is strictly convex, in this case, we have Ïˆ(z) >
z for all z âˆˆ[0, 1); hence F = {1}. We conclude q = 1.
Case 2:
limzâ†‘1 Ïˆâ€²(z) > 1. As Ïˆ is strictly convex and since Ïˆ(0) â‰¥0, there is a
unique r âˆˆ[0, 1) such that Ïˆ(r) = r. Hence F = {r, 1} and q = min F = r.
The second equivalence in (ii) follows by (3.2).
âŠ“âŠ”
For further reading, we refer to [5].
Takeaways A branching process dies out eventually if the mean number of
offspring is no larger than 1. More generally, the extinction probability is the
smallest ï¬xed point of the generating function of the offspring distribution.
Exercise 3.3.1 Assume that we have a branching process Z = (Zn)nâˆˆN0 with Z0 =
1 whose offspring distribution is given by p0 = 1/3 and p2 = 2/3. Compute Ïˆâ€²(1)
and the extinction probability. â™£
Exercise 3.3.2 Assume that we have a branching process Z = (Zn)nâˆˆN0 with Z0 =
1 whose offspring distribution is given by pk = 1
3 Â· (2/3)k, k âˆˆN0.
(i) Compute the generating function Ïˆ and the extinction probability q.
(ii) For this particular Ïˆ, all the iterates are of a special form and can be computed
explicitly. Do it!
(iii) Compute limnâ†’âˆÏˆn(z), z âˆˆ[0, 1]. What does the result imply for the
convergence of PZn? (Compare Lemma 3.6 and the comment below it.) â™£

Chapter 4
The Integral
Based on the notions of measure spaces and measurable maps, we introduce the
integral of a measurable map with respect to a general measure. This generalizes
the Lebesgue integral that can be found in textbooks on calculus. Furthermore,
the integral is a cornerstone in a systematic theory of probability that allows for
the deï¬nition and investigation of expected values and higher moments of random
variables.
In this chapter, we deï¬ne the integral by an approximation scheme with simple
functions. Then we deduce basic statements such as Fatouâ€™s lemma. Other important
convergence theorems for integrals follow in Chaps. 6 and 7.
4.1
Construction and Simple Properties
In the following, (Î©, A, Î¼) will always be a measure space. We denote by E the
vector space of simple functions (see Deï¬nition 1.93) on (Î©, A) and by
E+ := {f âˆˆE : f â‰¥0}
the cone (why this name?) of nonnegative simple functions. If
f =
m

i=1
Î±i 1Ai
(4.1)
for some m âˆˆN and for Î±1, . . . , Î±m âˆˆ(0, âˆ), and for mutually disjoint sets
A1, . . . , Am âˆˆA, then (4.1) is said to be a normal representation of f .
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_4
95

96
4
The Integral
Lemma 4.1 If f
=
m
i=1 Î±i 1Ai and f
=
n
j=1 Î²j 1Bj are two normal
representations of f âˆˆE+, then
m

i=1
Î±i Î¼(Ai) =
n

j=1
Î²j Î¼(Bj).
Proof If Î¼(Ai âˆ©Bj) > 0 for some i and j, then Ai âˆ©Bj Ì¸= âˆ…, and f (Ï‰) = Î±i = Î²j
for any Ï‰ âˆˆAi âˆ©Bj. Furthermore, clearly Ai âŠ‚n
j=1 Bj if Î±i Ì¸= 0, and Bj âŠ‚
m
i=1 Ai if Î²j Ì¸= 0. We conclude that
m

i=1
Î±i Î¼(Ai) =
m

i=1
n

j=1
Î±i Î¼(Ai âˆ©Bj)
=
m

i=1
n

j=1
Î²j Î¼(Ai âˆ©Bj) =
n

j=1
Î²j Î¼(Bj).
âŠ“âŠ”
This lemma allows us to make the following deï¬nition (since the value of I(f ) does
not depend on the choice of the normal representation).
Deï¬nition 4.2 Deï¬ne the map I : E+ â†’[0, âˆ] by
I(f ) =
m

i=1
Î±i Î¼(Ai)
if f has the normal representation f = m
i=1 Î±i 1Ai.
Lemma 4.3 The map I is positive linear and monotone increasing: Let f, g âˆˆE+
and Î± â‰¥0. Then the following statements hold.
(i) I(Î±f ) = Î± I(f ).
(ii) I(f + g) = I(f ) + I(g).
(iii) If f â‰¤g, then I(f ) â‰¤I(g).
Proof This is left as an exercise.
âŠ“âŠ”
Deï¬nition 4.4 (Integral) If f : Î© â†’[0, âˆ] is measurable, then we deï¬ne the
integral of f with respect to Î¼ by

f dÎ¼ := sup
	
I(g) : g âˆˆE+, g â‰¤f

.

4.1
Construction and Simple Properties
97
Remark 4.5 By Lemma 4.3(iii), we have I(f ) =
3
f dÎ¼ for any f
âˆˆE+.
Hence the integral is an extension of the map I from E+ to the set of nonnegative
measurable functions. â™¦
If f, g : Î© â†’R with f (Ï‰) â‰¤g(Ï‰) for any Ï‰ âˆˆÎ©, then we write f â‰¤g.
Analogously, we write f â‰¥0 and so on. On the other hand, we write â€œf â‰¤g
almost everywhereâ€ if the weaker condition holds that there exists a Î¼-null set N
such that f (Ï‰) â‰¤g(Ï‰) for any Ï‰ âˆˆNc.
Lemma 4.6 Let f, g, f1, f2, . . . be measurable maps Î© â†’[0, âˆ]. Then:
(i) (Monotonicity) If f â‰¤g, then
3
f dÎ¼ â‰¤
3
g dÎ¼.
(ii) (Monotone convergence) If fn
â†‘
f , then the integrals also converge:
3
fn dÎ¼ â†‘
3
f dÎ¼.
(iii) (Linearity) If Î±, Î² âˆˆ[0, âˆ], then

(Î±f + Î²g) dÎ¼ = Î±

f dÎ¼ + Î²

g dÎ¼,
where we use the convention âˆÂ· 0 := 0.
Proof
(i) This is immediate from the deï¬nition of the integral.
(ii) By (i), we have
lim
nâ†’âˆ

fn dÎ¼ = sup
nâˆˆN

fn dÎ¼ â‰¤

f dÎ¼.
Hence we only have to show
3
f dÎ¼ â‰¤sup
nâˆˆN
3
fn dÎ¼.
Let g âˆˆE+ with g â‰¤f . It is enough to show that
sup
nâˆˆN

fn dÎ¼ â‰¥

g dÎ¼.
(4.2)
Assume that the simple function g has the normal representation g
=
N
i=1 Î±i 1Ai for some Î±1, . . . , Î±N
âˆˆ
(0, âˆ) and mutually disjoint sets
A1, . . . , AN âˆˆA. For any Îµ > 0 and n âˆˆN, deï¬ne the set
BÎµ
n = {fn â‰¥(1 âˆ’Îµ) g}.

98
4
The Integral
Since fn â†‘f â‰¥g, we have BÎµ
n â†‘Î© for any Îµ > 0. Hence, by (i), for any
Îµ > 0,

fn dÎ¼ â‰¥
 
(1 âˆ’Îµ) g 1BÎµn

dÎ¼
=
N

i=1
(1 âˆ’Îµ) Î±i Î¼(Ai âˆ©BÎµ
n)
nâ†’âˆ
âˆ’â†’
N

i=1
(1 âˆ’Îµ) Î±i Î¼(Ai) = (1 âˆ’Îµ)

g dÎ¼.
Letting Îµ â†“0 implies (4.2) and hence the claim (ii).
(iii) By Theorem 1.96, any nonnegative measurable map is a monotone limit of
simple functions. Hence there are sequences (fn)nâˆˆN and (gn)nâˆˆN in E+ such
that fn â†‘f and gn â†‘g. Thus also (Î±fn + Î²gn) â†‘Î±f + Î²g. By (ii) and
Lemma 4.3, this implies

(Î±f + Î²g) dÎ¼ = lim
nâ†’âˆ

(Î±fn + Î²gn) dÎ¼
= Î± lim
nâ†’âˆ

fn dÎ¼ + Î² lim
nâ†’âˆ

gn dÎ¼ = Î±

f dÎ¼ + Î²

g dÎ¼. âŠ“âŠ”
For any measurable map f : Î© â†’R, we have f + â‰¤|f | and f âˆ’â‰¤|f |, which
implies
3
f Â± dÎ¼ â‰¤
3
|f | dÎ¼. In particular, if
3
|f | dÎ¼ < âˆ, then also
3
f âˆ’dÎ¼ <
âˆand
3
f + dÎ¼ < âˆ. Thus we can make the following deï¬nition that is the ï¬nal
deï¬nition for the integral of measurable functions.
Deï¬nition 4.7 (Integral of measurable functions) A measurable function f
:
Î© â†’R is called Î¼-integrable if 3 |f | dÎ¼ < âˆ. We write
L1(Î¼) := L1(Î©, A, Î¼) :=

f : Î© â†’R : f is measurable and
3
|f | dÎ¼ < âˆ

.
For f âˆˆL1(Î¼), we deï¬ne the integral of f with respect to Î¼ by

f (Ï‰) Î¼(dÏ‰) :=

f dÎ¼ :=

f + dÎ¼ âˆ’

f âˆ’dÎ¼.
(4.3)
If we only have
3
f âˆ’dÎ¼ < âˆor
3
f + dÎ¼ < âˆ, then we also deï¬ne
3
f dÎ¼ by
(4.3). Here the values +âˆand âˆ’âˆ, respectively, are possible.
For A âˆˆA, we deï¬ne

A
f dÎ¼ :=

(f 1A) dÎ¼.

4.1
Construction and Simple Properties
99
Theorem 4.8 Let f : Î© â†’[0, âˆ] be a measurable map.
(i) We have f = 0 almost everywhere if and only if
3
f dÎ¼ = 0.
(ii) If
3
f dÎ¼ < âˆ, then f < âˆalmost everywhere.
Proof
(i) â€œ â‡’â€ Assume f = 0 almost everywhere. Let N = {Ï‰ : f (Ï‰) > 0}. Then
f â‰¤âˆÂ· 1N and n1N â†‘âˆÂ· 1N. From Lemma 4.6(i) and (ii), we infer
0 â‰¤

f dÎ¼ â‰¤

(âˆÂ· 1N) dÎ¼ = lim
nâ†’âˆ

n1N dÎ¼ = 0.
â€œ â‡ â€
Let Nn = {f â‰¥1
n}, n âˆˆN. Then Nn â†‘N and
0 =

f dÎ¼ â‰¥
 1
n 1Nn dÎ¼ = Î¼(Nn)
n
.
Hence Î¼(Nn) = 0 for any n âˆˆN and thus Î¼(N) = 0.
(ii) Let A = {Ï‰ : f (Ï‰) = âˆ}. For n âˆˆN, we have 1
nf 1{f â‰¥n} â‰¥1{f â‰¥n}. Hence
Lemma 4.6(i) implies
Î¼(A) =

1A dÎ¼ â‰¤

1{f â‰¥n} dÎ¼ â‰¤1
n

f 1{f â‰¥n} dÎ¼ â‰¤1
n

f dÎ¼ nâ†’âˆ
âˆ’â†’0.
âŠ“âŠ”
Theorem 4.9 (Properties of the integral) Let f, g âˆˆL1(Î¼).
(i) (Monotonicity)
If f â‰¤g almost everywhere, then 3 f dÎ¼ â‰¤3 g dÎ¼.
In particular, if f = g almost everywhere, then 3 f dÎ¼ = 3 g dÎ¼.
(ii) (Triangle inequality)
 3 f dÎ¼
 â‰¤3 |f | dÎ¼.
(iii) (Linearity)
If Î±, Î² âˆˆR, then Î±f + Î²g âˆˆL1(Î¼) and

(Î±f + Î²g) dÎ¼ = Î±

f dÎ¼ + Î²

g dÎ¼.
This equation also holds if at most one of the integrals
3
f dÎ¼ and
3
g dÎ¼ is
inï¬nite.
Proof
(i) Clearly, f + â‰¤g+ a.e., hence (f + âˆ’g+)+ = 0 a.e. By Theorem 4.8, we get
3
(f + âˆ’g+)+ dÎ¼ = 0. Since f + â‰¤g+ +(f + âˆ’g+)+ (not only a.e.), we infer
from Lemma 4.6(i) and (iii)

f + dÎ¼ â‰¤
 
g+ + (f + âˆ’g+)+
dÎ¼ =

g+ dÎ¼.

100
4
The Integral
Similarly, we use f âˆ’â‰¥gâˆ’a.e. to obtain

f âˆ’dÎ¼ â‰¥

gâˆ’dÎ¼.
This implies

f dÎ¼ =

f + dÎ¼ âˆ’

f âˆ’dÎ¼ â‰¤

g+ dÎ¼ âˆ’

gâˆ’dÎ¼ =

g dÎ¼.
(ii) Since f + + f âˆ’= |f |, Lemma 4.6(iii) yields


f dÎ¼
 =


f + dÎ¼ âˆ’

f âˆ’dÎ¼
 â‰¤

f + dÎ¼ +

f âˆ’dÎ¼
=
 
f + + f âˆ’
dÎ¼ =

|f | dÎ¼.
(iii) Since |Î±f + Î²g| â‰¤|Î±| Â· |f | + |Î²| Â· |g|, Lemma 4.6(i) and (iii) yield that
Î±f +Î²g âˆˆL1(Î¼). In order to show linearity, it is enough to check the following
three properties.
(a) 3 (f + g) dÎ¼ = 3 f dÎ¼ + 3 g dÎ¼.
(b) 3 Î±f dÎ¼ = Î± 3 f dÎ¼ for Î± â‰¥0.
(c) 3 (âˆ’f ) dÎ¼ = âˆ’3 f dÎ¼.
(a) We have (f + g)+ âˆ’(f + g)âˆ’= f + g = f + âˆ’f âˆ’+ g+ âˆ’gâˆ’; hence
(f + g)+ + f âˆ’+ gâˆ’= (f + g)âˆ’+ f + + g+. By Lemma 4.6(iii), we
infer

(f +g)+ dÎ¼+

f âˆ’dÎ¼+

gâˆ’dÎ¼ =

(f +g)âˆ’dÎ¼+

f + dÎ¼+

g+ dÎ¼.
Hence

(f + g) dÎ¼ =

(f + g)+ dÎ¼ âˆ’

(f + g)âˆ’dÎ¼
=

f + dÎ¼ âˆ’

f âˆ’dÎ¼ +

g+ dÎ¼ âˆ’

gâˆ’dÎ¼
=

f dÎ¼ +

g dÎ¼.
(b) For Î± â‰¥0, we have

Î±f dÎ¼ =

Î±f + dÎ¼ âˆ’

Î±f âˆ’dÎ¼ = Î±

f + dÎ¼ âˆ’Î±

f âˆ’dÎ¼ = Î±

f dÎ¼.

4.1
Construction and Simple Properties
101
(c) We have

(âˆ’f ) dÎ¼ =

(âˆ’f )+ dÎ¼ âˆ’

(âˆ’f )âˆ’dÎ¼
=

f âˆ’dÎ¼ âˆ’

f + dÎ¼ = âˆ’

f dÎ¼.
The supplementary statement is simple and is left as an exercise.
âŠ“âŠ”
Theorem 4.10 (Image measure) Let (Î©, A) and (Î©â€², Aâ€²) be measurable spaces,
let Î¼ be a measure on (Î©, A) and let X : Î© â†’Î©â€² be measurable. Let Î¼â€² = Î¼â—¦Xâˆ’1
be the image measure of Î¼ under the map X. Assume that f : Î©â€² â†’R is Î¼â€²-
integrable. Then f â—¦X âˆˆL1(Î¼) and

(f â—¦X) dÎ¼ =

f dÎ¼ â—¦Xâˆ’1.
In particular, if X is a random variable on (Î©, A, P), then

f (x) P[X âˆˆdx] :=

f (x) PX[dx] =

f dPX =

f (X(Ï‰)) P[dÏ‰].
Proof This is left as an exercise.
âŠ“âŠ”
Example 4.11 (Discrete measure space) Let (Î©, A) be a discrete measurable space
and let Î¼ = 
Ï‰âˆˆÎ©
Î±Ï‰Î´Ï‰ for certain numbers Î±Ï‰ â‰¥0, Ï‰ âˆˆÎ©. A map f : Î© â†’R is
integrable if and only if 
Ï‰âˆˆÎ©
|f (Ï‰)| Î±Ï‰ < âˆ. In this case,

f dÎ¼ =

Ï‰âˆˆÎ©
f (Ï‰) Î±Ï‰.
â™¦
Deï¬nition 4.12 (Lebesgue integral) Let Î» be the Lebesgue measure on Rn and
let f : Rn â†’R be measurable with respect to Bâˆ—(Rn) â€“ B(R) (here Bâˆ—(Rn) is the
Lebesgue Ïƒ-algebra; see Example 1.71) and Î»-integrable. Then we call

f dÎ»
the Lebesgue integral of f . If A âˆˆB(Rn) and f : Rn â†’R is measurable (or
f : A â†’R is Bâˆ—(Rn)
A â€“ B(R)-measurable and hence f 1A is Bâˆ—(Rn) â€“ B(R)-
measurable), then we write

A
f dÎ» :=

f 1A dÎ».

102
4
The Integral
Deï¬nition 4.13 Let Î¼ be a measure on (Î©, A) and let f : Î© â†’[0, âˆ) be a
measurable map. Deï¬ne the measure Î½ by
Î½(A) :=

(1A f ) dÎ¼
for A âˆˆA.
We say that f Î¼ := Î½ has density f with respect to Î¼.
Remark 4.14 We still have to show that Î½ is a measure. To this end, we check
the conditions of Theorem 1.36. Clearly, Î½(âˆ…) = 0. Finite additivity follows from
additivity of the integral (Lemma 4.6(iii)). Lower semicontinuity follows from the
monotone convergence theorem (Theorem 4.20). â™¦
Theorem 4.15 We have g âˆˆL1(f Î¼) if and only if (gf ) âˆˆL1(Î¼). In this case,

g d(f Î¼) =

(gf ) dÎ¼.
Proof First note that the statement holds for indicator functions. Then, with the
usual arguments, extend it step by step ï¬rst to simple functions, then to nonnegative
measurable functions and ï¬nally to signed measurable functions.
âŠ“âŠ”
Deï¬nition 4.16 For measurable f : Î© â†’R, deï¬ne
âˆ¥f âˆ¥p :=

|f |p dÎ¼
1/p
,
if p âˆˆ[1, âˆ),
and
âˆ¥f âˆ¥âˆ:= inf 	K â‰¥0 : Î¼({|f | > K}) = 0
.
Further, for any p âˆˆ[1, âˆ], deï¬ne the vector space
Lp(Î¼) :=

f : Î© â†’R is measurable and âˆ¥f âˆ¥p < âˆ

.
Theorem 4.17 The map âˆ¥Â·âˆ¥1 is a seminorm on L1(Î¼); that is, for all f, g âˆˆL1(Î¼)
and Î± âˆˆR,
âˆ¥Î±f âˆ¥1 = |Î±| Â· âˆ¥f âˆ¥1,
âˆ¥f + gâˆ¥1 â‰¤âˆ¥f âˆ¥1 + âˆ¥gâˆ¥1,
âˆ¥f âˆ¥1 â‰¥0 for all f
and
âˆ¥f âˆ¥1 = 0
if f = 0
a.e.
(4.4)
Proof The ï¬rst and the third statements follow from Theorem 4.9(iii) and Theo-
rem 4.8(i). The second statement follows from Theorem 4.9(i) since |f + g| â‰¤

4.1
Construction and Simple Properties
103
|f | + |g|; hence
âˆ¥f + gâˆ¥1 =

|f + g| dÎ¼ â‰¤

|f | dÎ¼ +

|g| dÎ¼ = âˆ¥f âˆ¥1 + âˆ¥gâˆ¥1.
âŠ“âŠ”
Remark 4.18 In fact, âˆ¥Â· âˆ¥p is a seminorm on Lp(Î¼) for all p
âˆˆ[1, âˆ].
Linearity and positivity are obvious, and the triangle inequality is a consequence
of Minkowskiâ€™s inequality, which we will show in Theorem 7.17. â™¦
Theorem 4.19 Let Î¼(Î©) < âˆand 1 â‰¤pâ€² â‰¤p â‰¤âˆ. Then Lp(Î¼) âŠ‚Lpâ€²(Î¼) and
the canonical inclusion i : Lp(Î¼) â†’Lpâ€²(Î¼), f â†’f is continuous.
Proof Let f âˆˆLâˆ(Î¼) and pâ€² âˆˆ[1, âˆ). Then |f |pâ€² â‰¤âˆ¥f âˆ¥pâ€²
âˆalmost everywhere;
hence

|f |pâ€² dÎ¼ â‰¤

âˆ¥f âˆ¥pâ€²
âˆdÎ¼ = âˆ¥f âˆ¥pâ€²
âˆÂ· Î¼(Î©) < âˆ.
Thus âˆ¥f âˆ’gâˆ¥pâ€² â‰¤Î¼(Î©)1/pâ€²âˆ¥f âˆ’gâˆ¥âˆfor f, g âˆˆLâˆ(Î¼) and hence i is continuous.
Now let p, pâ€² âˆˆ[1, âˆ) with pâ€² < p and let f âˆˆLp(Î¼). Then |f |pâ€² â‰¤1 + |f |p;
hence

|f |pâ€² dÎ¼ â‰¤Î¼(Î©) +

|f |p dÎ¼ < âˆ.
Finally, let f, g âˆˆLp(Î¼). For any c > 0, we have
|f âˆ’g|pâ€² = |f âˆ’g|pâ€² 1{|f âˆ’g|â‰¤c} + |f âˆ’g|pâ€² 1{|f âˆ’g|>c} â‰¤cpâ€² + cpâ€²âˆ’p|f âˆ’g|p.
In particular, letting c = âˆ¥f âˆ’gâˆ¥p we obtain
âˆ¥f âˆ’gâˆ¥pâ€² â‰¤

cpâ€²Î¼(Î©) + cpâ€²âˆ’pâˆ¥f âˆ’gâˆ¥p
p
1/pâ€²
= (1 + Î¼(Î©))1/pâ€²âˆ¥f âˆ’gâˆ¥p.
Hence, also in this case, i is continuous.
âŠ“âŠ”
Takeaways The integral was deï¬ned ï¬rst for functions which take only
ï¬nitely many values. For more general measurable functions, the integral was
then deï¬ned as the limit of integrals of approximating elementary functions.
The full procedure is rather technical and does not allow for a smooth intuitive
description. From an abstract point of view, the integral is monotone and linear
and fulï¬lls the triangle inequality, which allows to use it to deï¬ne normed
vector spaces of functions.

104
4
The Integral
Exercise 4.1.1 Let f : R â†’R be deï¬ned by f (x) = eâˆ’x1[0,âˆ)(x), and let Î» the
Lebesgue measure on R.
(i) Find a sequence (fn) of elementary functions such that fn â†‘f .
(ii) Compute
3
fn dÎ» and determine
3
f dÎ» as a limit of integrals. â™£
Exercise 4.1.2 (Sequence spaces) Now we do not assume Î¼(Î©) < âˆ. Assume
there exists an a > 0 such that for any A âˆˆA either Î¼(A) = 0 or Î¼(A) â‰¥a. Show
that the reverse inclusion to Theorem 4.19 holds,
Lpâ€²(Î¼) âŠ‚Lp(Î¼)
if 1 â‰¤pâ€² â‰¤p â‰¤âˆ.
(4.5)
â™£
Exercise 4.1.3 Let 1 â‰¤pâ€² < p â‰¤âˆand let Î¼ be Ïƒ-ï¬nite but not ï¬nite. Show that
Lp(Î¼) \ Lpâ€²(Î¼) Ì¸= âˆ…. â™£
4.2
Monotone Convergence and Fatouâ€™s Lemma
What are the conditions that allow the interchange of limit and integral? In this
section, we derive two simple criteria that prepare us for important applications
such as the law of large numbers (Chap. 5). More general criteria will be presented
in Chap. 6.
Theorem 4.20 (Monotone convergence, Beppo Levi theorem) Let f1, f2, . . . âˆˆ
L1(Î¼) and let f : Î© â†’R be measurable. Assume fn â†‘f a.e. for n â†’âˆ. Then
lim
nâ†’âˆ

fn dÎ¼ =

f dÎ¼,
where both sides can equal +âˆ.
Proof Let N âŠ‚Î© be a null set such that fn(Ï‰) â†‘f (Ï‰) for all Ï‰ âˆˆNc. The
functions f â€²
n := (fn âˆ’f1) 1Nc and f â€² := (f âˆ’f1) 1Nc are nonnegative and fulï¬ll
f â€²
n â†‘f â€². By Lemma 4.6(ii), we have 3 f â€²
n dÎ¼
nâ†’âˆ
âˆ’â†’3 f â€² dÎ¼. Since fn = f â€²
n + f1
a.e. and f = f â€² + f1 a.e., Theorem 4.9(iii) implies

fn dÎ¼ =

f1 dÎ¼ +

f â€²
n dÎ¼
nâ†’âˆ
âˆ’â†’

f1 dÎ¼ +

f â€² dÎ¼ =

f dÎ¼.
âŠ“âŠ”
Theorem 4.21 (Fatouâ€™s lemma) Let f âˆˆL1(Î¼) and let f1, f2, . . . be measurable
with fn â‰¥f a.e. for all n âˆˆN. Then
 
lim inf
nâ†’âˆfn

dÎ¼ â‰¤lim inf
nâ†’âˆ

fn dÎ¼.

4.2
Monotone Convergence and Fatouâ€™s Lemma
105
Proof By considering (fn âˆ’f )nâˆˆN, we may assume fn â‰¥0 a.e. for all n âˆˆN.
Deï¬ne
gn := inf
mâ‰¥n fm.
Then gn â†‘lim inf
mâ†’âˆfm as n â†’âˆ, and hence by the monotone convergence theorem
(Lemma 4.6(ii)) and by monotonicity, gn â‰¤fn (thus 3 gn dÎ¼ â‰¤3 fn dÎ¼),

lim inf
nâ†’âˆfn dÎ¼ = lim
nâ†’âˆ

gn dÎ¼ â‰¤lim inf
nâ†’âˆ

fn dÎ¼.
âŠ“âŠ”
Example 4.22 (Petersburg game)
By a concrete example, we show that in Fatouâ€™s
lemma the assumption of an integrable minorant is essential. Consider a gamble
in a casino where in each round the playerâ€™s bet either gets doubled or lost. For
example, roulette is such a game. If the player bets on â€œredâ€, she gets the stake back
doubled if the ball lands in a red pocket. Otherwise the bet is lost (for the player,
not for the casino). There are 37 pockets (in European roulettes), 18 of which are
red, 18 are black and one is green (the zero). Hence, by symmetry, the chance of
winning should be p = 18/37 < 1
2. Now assume the gamble is played again and
again. We can model this on a probability space (Î©, A, P) where Î© = {âˆ’1, 1}N,
A = (2{âˆ’1,1})âŠ—N is the Ïƒ-algebra generated by the cylinder sets [Ï‰1, . . . , Ï‰n] and
P = ((1 âˆ’p)Î´âˆ’1 + pÎ´1)âŠ—N is the product measure. Denote by Dn : Î© â†’{âˆ’1, 1},
Ï‰ â†’Ï‰n the result of the nth game (for n âˆˆN). If in the ith game the player makes
a (random) stake of Hi euros, then the cumulative proï¬t after the nth game is
Sn =
n

i=1
HiDi.
Now assume the gambler adopts the following doubling strategy. In the ï¬rst round,
the stake is H1 = 1. If she wins, then she does not bet any money in the subsequent
games; that is, Hn = 0 for all n â‰¥2 if D1 = 1. On the other hand, if she loses, then
in the second game she doubles the stake; that is, H2 = 2 if D1 = âˆ’1. If she wins
the second game, she leaves the casino and otherwise doubles the stake again and
so on. Hence we can describe the strategy by the formula
Hn =

0,
if there is an i âˆˆ{1, . . ., n âˆ’1} with Di = 1,
2nâˆ’1,
else.
Note that Hn depends on D1, . . . , Dnâˆ’1 only. That is, it is measurable with respect
to Ïƒ(D1, . . . , Dnâˆ’1). Clearly, it is a crucial requirement for any strategy that the
decision for the next stake depend only on the information available at that time and
not depend on the future results of the gamble.

106
4
The Integral
The probability of no win until the nth game is (1âˆ’p)n; hence P[Sn = 1âˆ’2n] =
(1 âˆ’p)n and P[Sn = 1] = 1 âˆ’(1 âˆ’p)n. Hence we expect an average gain of

Sn dP = (1 âˆ’p)n(1 âˆ’2n) + (1 âˆ’(1 âˆ’p)n) = 1 âˆ’

2 (1 âˆ’p)
n â‰¤0
since p â‰¤1
2 (in the proï¬table casinos). We deï¬ne
S =

âˆ’âˆ,
if âˆ’1 = D1 = D2 = . . . ,
1,
else.
Then Sn
nâ†’âˆ
âˆ’â†’
S a.s. but limnâ†’âˆ
3
Sn dP <
3
S dP = 1 since S = 1 a.s.
By Fatouâ€™s lemma, this is possible only if there is no integrable minorant for the
sequence (Sn)nâˆˆN. If we deï¬ne ËœS := inf{Sn : n âˆˆN}, then indeed
P
) ËœS = 1 âˆ’2nâˆ’1*
= P
)
D1 = . . . = Dnâˆ’1 = âˆ’1 and Dn = 1
*
= p(1 âˆ’p)nâˆ’1.
Hence
3 ËœS dP = âˆ
n=1(1 âˆ’2nâˆ’1) p(1 âˆ’p)nâˆ’1 = âˆ’âˆsince p â‰¤1
2. â™¦
Takeaways Assume we are given a pointwise convergent sequence of non-
negative functions. Then the limit (inferior) of the integrals is at least as
large as the integral of the limit (Fatouâ€™s lemma). In the case of monotone
convergence we have equality. As an example where inequality holds, instead
of the standard example from calculus textbooks (fn = n Â· 1(0,1/n), f = 0),
we studied a game of hazard that we will encounter in a different context later.
Exercise 4.2.1 Let (Î©, A, Î¼) be a measure space and let f âˆˆL1(Î¼). Show that
for any Îµ > 0, there is an A âˆˆA with Î¼(A) < âˆand
3
A f dÎ¼ âˆ’
3
f dÎ¼
 < Îµ. â™£
Exercise 4.2.2 Let f1, f2, . . . âˆˆL1(Î¼) be nonnegative and such that lim
nâ†’âˆ
3
fn dÎ¼
exists. Assume there exists a measurable f with fn
nâ†’âˆ
âˆ’â†’f Î¼-almost everywhere.
Show that f âˆˆL1(Î¼) and
lim
nâ†’âˆ
 fn âˆ’f
 dÎ¼ =
lim
nâ†’âˆ

fn dÎ¼ âˆ’

f dÎ¼.
â™£
Exercise 4.2.3 Let f
âˆˆL1([0, âˆ), Î») be a Lebesgue integrable function on
[0, âˆ). Show that for Î»-almost all t âˆˆ[0, âˆ) the series âˆ
n=1 f (nt) converges
absolutely. â™£
Exercise 4.2.4 Let Î» be the Lebesgue measure on R and let A be a Borel set with
Î»(A) < âˆ. Show that for any Îµ > 0, there is a compact set C âŠ‚A, a closed set

4.3
Lebesgue Integral Versus Riemann Integral
107
D âŠ‚R \ A and a continuous map Ï• : R â†’[0, 1] with 1C â‰¤Ï• â‰¤1R\D and such
that âˆ¥1A âˆ’Ï•âˆ¥1 < Îµ.
Hint: Use the regularity of Lebesgue measure (Remark 1.67). â™£
Exercise 4.2.5 Let Î» be the Lebesgue measure on R, p âˆˆ[1, âˆ) and let f âˆˆ
Lp(Î»). Show that for any Îµ > 0, there is a continuous function h : R â†’R such that
âˆ¥f âˆ’hâˆ¥p < Îµ.
Hint: Use Exercise 4.2.4 to show the assertion ï¬rst for indicator functions, then for
simple functions and ï¬nally for general f âˆˆLp(Î»). â™£
Exercise 4.2.6 Let Î» be the Lebesgue measure on R, p âˆˆ[1, âˆ) and let f âˆˆ
Lp(Î»). A map h : R â†’R is called a step function if there exist n âˆˆN and
numbers t0 < t1 < . . . < tn and Î±1, . . . , Î±n such that h = n
k=1 Î±k 1(tkâˆ’1,tk].
Show that for any Îµ > 0, there exists a step function h such that âˆ¥f âˆ’hâˆ¥p < Îµ.
Hint:
Use the approximation theorem for measures (Theorem 1.65) with the
semiring of left open intervals to show the assertion ï¬rst for measurable indicator
functions. Then use the approximation arguments as in Exercise 4.2.5. â™£
4.3
Lebesgue Integral Versus Riemann Integral
We show that for Riemann integrable functions the Lebesgue integral and the
Riemann integral coincide.
Let I = [a, b] âŠ‚R be an interval and let Î» be the Lebesgue measure on I.
Further, consider sequences t = (tn)nâˆˆN of partitions tn = (tn
i )i=0,...,n of I (i.e.,
a = tn
0 < tn
1 < . . . < tn
n = b) that get ï¬ner and ï¬ner. That is,
|tn| := max{tn
i âˆ’tn
iâˆ’1 : i = 1, . . ., n}
nâ†’âˆ
âˆ’â†’0.
Assume that for any n âˆˆN, the partition tn+1 is a reï¬nement of tn; that is,
	
tn
0 , . . . , tn
n

âŠ‚
	
tn+1
0
, . . . , tn+1
n+1

.
For any function f : I â†’R and any n âˆˆN, deï¬ne the nth lower sum and upper
sum, respectively, by
Lt
n(f ) :=
n

i=1
(tn
i âˆ’tn
iâˆ’1) inf f

[tn
iâˆ’1, tn
i )

,
Ut
n(f ) :=
n

i=1
(tn
i âˆ’tn
iâˆ’1) sup f

[tn
iâˆ’1, tn
i )

.
A function f : I â†’R is called Riemann integrable if there exists a t such that the
limits of the lower sums and upper sums are ï¬nite and coincide. In this case, the
value of the limit does not depend on the choice of t, and the Riemann integral of f

108
4
The Integral
is deï¬ned as (see, e.g., [149])
 b
a
f (x) dx :=
lim
nâ†’âˆLt
n(f ) =
lim
nâ†’âˆUt
n(f ).
(4.6)
Theorem 4.23 (Riemann integral and Lebesgue integral) Let f : I â†’R be
Riemann integrable on I = [a, b]. Then f is Lebesgue integrable on I with integral

I
f dÎ» =
 b
a
f (x) dx.
Proof Choose t such that (4.6) holds. By assumption, there is an n âˆˆN with
|Lt
n(f )| < âˆand |Ut
n(f )| < âˆ. Hence f is bounded. We can thus replace f
by f + âˆ¥f âˆ¥âˆand hence assume that f â‰¥0. Deï¬ne
gn := f (b) 1{b} +
n

i=1
(inf f ([tn
iâˆ’1, tn
i ))) 1[tn
iâˆ’1,tn
i ),
hn := f (b) 1{b} +
n

i=1
(sup f ([tn
iâˆ’1, tn
i ))) 1[tn
iâˆ’1,tn
i ).
As tn+1 is a reï¬nement of tn, we have gn â‰¤gn+1 â‰¤hn+1 â‰¤hn. Hence there exist
g and h with gn â†‘g and hn â†“h. By construction, we have g â‰¤h and

I
g dÎ» = lim
nâ†’âˆ

I
gn dÎ» = lim
nâ†’âˆLt
n(f )
= lim
nâ†’âˆUt
n(f ) = lim
nâ†’âˆ

I
hn dÎ» =

I
h dÎ».
Hence h = g Î»-a.e. By construction, g â‰¤f â‰¤h, and as limits of simple functions,
g and h are B(I) â€“ B(R)-measurable. This implies that, for any Î± âˆˆR, the set
{f â‰¤Î±} =

{g â‰¤Î±} âˆ©{g = h}

âŠ

{f â‰¤Î±} âˆ©{g Ì¸= h}

is the union of a B(I)-set with a subset of a null set and is hence in B(I)âˆ—(the
Lebesgue completion of B(I)). Hence f is B(I)âˆ—-measurable. By the monotone
convergence theorem (Theorem 4.20), we conclude

I
f dÎ» = lim
nâ†’âˆ

I
gn dÎ» =
 b
a
f (x) dx.
âŠ“âŠ”

4.3
Lebesgue Integral Versus Riemann Integral
109
Example 4.24 Let f : [0, 1] â†’R, x â†’1Q. Then clearly f is not Riemann
integrable since Ln(f ) = 0 and Un(f ) = 1 for all n âˆˆN. On the other hand, f is
Lebesgue integrable with integral
3
[0,1] f dÎ» = 0 because Q âˆ©[0, 1] is a null set. â™¦
Remark 4.25 An improperly Riemann integrable function f on a one-sided open
interval I = (a, b] or I = [0, âˆ) is not necessarily Lebesgue integrable. Indeed,
the improper integral
3 âˆ
0
f (x) dx := limnâ†’âˆ
3 n
0 f (x) dx is deï¬ned by a limit
procedure that respects the geometry of R. The Lebesgue integral does not do that.
For example, the function f : [0, âˆ) â†’R, x â†’
1
1+x sin(x) is improperly Riemann
integrable but is not Lebesgue integrable since
3
[0,âˆ) |f | dÎ» = âˆ. â™¦
Reï¬‚ection Consider the function f (x) = 1/x, x âˆˆ[âˆ’1, 1] \ {0}, f (0) = 0.
Cauchyâ€™s principal value of the integral
3 1
âˆ’1 f (x)dx is deï¬ned as
lim
nâ†’âˆ
 âˆ’1/n
âˆ’1
1
x dx +
 1
1/n
1
x dx

= 0.
Why is this kind of limit incompatible with the concept of the Lebesgue integral? â™ 
On the one hand, improperly Riemann integrable functions need not be Lebesgue
integrable. On the other hand, there are Lebesgue integrable functions that are not
Riemann integrable (such as 1Q). The geometric interpretation is that the Riemann
integral respects the geometry of the integration domain by being deï¬ned via
slimmer and slimmer vertical rectangles (Fig. 4.1). On the other hand, the Lebesgue
integral respects the geometry of the range by being deï¬ned via slimmer and
slimmer horizontal strips. In particular, the Lebesgue integral does not make any
assumption on the geometry of the domain and is thus more universal than the
Riemann integral. In order to underline this, we present the following theorem that
will also be useful later.
Fig. 4.1 For the Riemann integral, the area under the curve is approximated by rectangles of a
ï¬xed breadth (left hand side). The Lebesgue integral approximates the area by the measure of the
levels sets (right hand side).

110
4
The Integral
Theorem 4.26 Let f : Î© â†’R be measurable and f â‰¥0 almost everywhere.
Then
âˆ

n=1
Î¼({f â‰¥n}) â‰¤

f dÎ¼ â‰¤
âˆ

n=0
Î¼({f > n})
(4.7)
and

f dÎ¼ =
 âˆ
0
Î¼({f â‰¥t}) dt.
(4.8)
Proof Deï¬ne f â€² = âŒŠf âŒ‹and f â€²â€² = âŒˆf âŒ‰. Then f â€² â‰¤f â‰¤f â€²â€² and hence
3
f â€² dÎ¼ â‰¤
3
f dÎ¼ â‰¤
3
f â€²â€² dÎ¼. Now the ï¬rst inequality of (4.7) follows from

f â€² dÎ¼ =
âˆ

k=1
Î¼({f â€² = k}) Â· k =
âˆ

k=1
k

n=1
Î¼({f â€² = k})
=
âˆ

n=1
âˆ

k=n
Î¼({f â€² = k})
=
âˆ

n=1
Î¼({f â€² â‰¥n}) =
âˆ

n=1
Î¼({f â‰¥n}).
Similarly, we infer the second inequality in (4.7) from

f â€²â€² dÎ¼ =
âˆ

n=1
Î¼({f â€²â€² â‰¥n}) =
âˆ

n=1
Î¼({f > n âˆ’1}).
If g(t) := Î¼({f â‰¥t}) = âˆfor some t > 0, then both sides in (4.8) equal âˆ.
Hence, in the following, assume g(t) < âˆfor all t > 0.
For Îµ > 0 and k âˆˆN, deï¬ne gÎµ := g âˆ§g(Îµ), f Îµ := f 1{f â‰¥Îµ} and f Îµ
k = 2kf Îµ as
well as
Î±Îµ
k := 2âˆ’k
âˆ

n=1
Î¼({f Îµ â‰¥n2âˆ’k}).
Then Î±Îµ
k
kâ†’âˆ
âˆ’â†’
3 âˆ
0
gÎµ(t) dt. Furthermore, by (4.7) (with f replaced by f Îµ
k ), we
have
Î±Îµ
k = 2âˆ’k
âˆ

n=1
Î¼({f Îµ
k â‰¥n}) â‰¤

f Îµ dÎ¼
â‰¤2âˆ’k
âˆ

n=0
Î¼({f Îµ
k > n}) = 2âˆ’k
âˆ

n=0
Î¼({f Îµ > n2âˆ’k}) â‰¤Î±Îµ
k + 2âˆ’k g(Îµ).

4.3
Lebesgue Integral Versus Riemann Integral
111
Since 2âˆ’k g(Îµ)
kâ†’âˆ
âˆ’â†’0, we get
3 âˆ
0
gÎµ(t) dt =
3
f Îµ dÎ¼. Since f Îµ â†‘f and gÎµ â†‘g
for Îµ â†“0, the monotone convergence theorem implies (4.8).
âŠ“âŠ”
Takeaways A Riemann integrable function on a compact interval is
Lebesgue integrable and the integrals coincide. For nonnegative functions, the
Lebesgue integral can be computed via a kind of partial integration formula
(Theorem 4.26).
Exercise 4.3.1 Use Theorem 4.26 to compute
3 1
0 log(x) dx and
3 Ï€
0 sin(x) dx. â™£
Exercise 4.3.2 Let f : [0, 1] â†’R be bounded. Show that f is (properly) Riemann
integrable if and only if f is Î»-a.e. continuous. â™£
Exercise 4.3.3 If f : [0, 1] â†’R is Riemann integrable, then f is Lebesgue
measurable. Give an example that shows that f need not be Borel measurable. (Hint:
Without proof, use the existence of a subset of [0, 1] that is not Borel measurable.
Based on this, construct a set that is not Borel and whose closure is a null set.) â™£
Exercise 4.3.4 Let f : [0, 1] â†’(0, âˆ) be Riemann integrable. Without using
the equivalence of the Lebesgue integral and the Riemann integral, show that
3 1
0 f (x) dx > 0. â™£

Chapter 5
Moments and Laws of Large Numbers
The most important characteristic quantities of random variables are the median,
expectation and variance. For large n, the expectation describes the typical approxi-
mate value of the arithmetic mean (X1 +. . .+Xn)/n of i.i.d. random variables (law
of large numbers). In Chap. 15, we will see how the variance determines the size of
the typical deviations of the arithmetic mean from the expectation.
5.1
Moments
In the following, let (Î©, A, P) be a probability space.
Deï¬nition 5.1 Let X be a real-valued random variable.
(i) If X âˆˆL1(P), then X is called integrable and we call
E[X] :=

X dP
the expectation or mean of X. If E[X] = 0, then X is called centered. More
generally, we also write E[X] =
3
X dP if only Xâˆ’or X+ is integrable.
(ii) If n âˆˆN and X âˆˆLn(P), then the quantities
mk := E
'
Xk(
,
Mk := E
'
|X|k(
for any k = 1, . . . , n,
are called the kth moments and kth absolute moments, respectively, of X.
(iii) If X âˆˆL2(P), then X is called square integrable and
Var[X] := E
'
X2(
âˆ’E[X]2
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_5
113

114
5
Moments and Laws of Large Numbers
is the variance of X. The number Ïƒ :=
âˆš
Var[X] is called the standard
deviation of X. Formally, we sometimes write Var[X] = âˆif E[X2] = âˆ.
(iv) If X, Y âˆˆL2(P), then we deï¬ne the covariance of X and Y by
Cov[X, Y] := E
)
X âˆ’E[X]

Y âˆ’E[Y]
*
.
X and Y are called uncorrelated if Cov[X, Y] = 0 and correlated otherwise.
Remark 5.2
(i) The deï¬nition in (ii) is sensible since, by virtue of Theorem 4.19, X âˆˆLn(P)
implies that Mk < âˆfor all k = 1, . . . , n.
(ii) If X, Y âˆˆL2(P), then XY âˆˆL1(P) since |XY| â‰¤X2 + Y 2. Hence the
deï¬nition in (iv) makes sense and we have
Cov[X, Y] = E[XY] âˆ’E[X] E[Y].
In particular, Var[X] = Cov[X, X]. â™¦
We collect the most important rules of expectations in a theorem. All of these
properties are direct consequences of the corresponding properties of the integral.
Theorem 5.3 (Rules for expectations) Let X, Y, Xn, Zn, n âˆˆN, be real integrable
random variables on (Î©, A, P).
(i) If PX = PY , then E[X] = E[Y].
(ii) (Linearity) Let c âˆˆR. Then cX âˆˆL1(P) and X + Y âˆˆL1(P) as well as
E[cX] = c E[X]
and
E[X + Y] = E[X] + E[Y].
(iii) If X â‰¥0 almost surely, then
E[X] = 0
â‡â‡’
X = 0
almost surely.
(iv) (Monotonicity) If X â‰¤Y almost surely, then E[X] â‰¤E[Y] with equality if and
only if X = Y almost surely.
(v) (Triangle inequality)
E[X]
 â‰¤E)|X|*.
(vi) If Xn â‰¥0 almost surely for all n âˆˆN, then E
' âˆ

n=1
Xn
(
=
âˆ

n=1
E[Xn].
(vii) If Zn â†‘Z for some Z, then E[Z] = limnâ†’âˆE[Zn] âˆˆ(âˆ’âˆ, âˆ].
Again probability theory comes into play when independence enters the stage; that
is, when we exit the realm of linear integration theory.
Theorem 5.4 (Independent L(P)-random variables are uncorrelated) Let
X, Y âˆˆL1(P) be independent. Then (X Y) âˆˆL1(P) and E[XY] = E[X] E[Y].
In particular, independent square integrable random variables are uncorrelated.

5.1
Moments
115
Proof Assume ï¬rst that X and Y take only ï¬nitely many values. Then XY also
takes only ï¬nitely many values and thus XY âˆˆL1(P). It follows that
E[XY] =

zâˆˆR\{0}
z P[XY = z]
=

zâˆˆR\{0}

xâˆˆR\{0}
x z
x P[X = x, Y = z/x]
=

yâˆˆR\{0}

xâˆˆR\{0}
xy P[X = x] P[Y = y]
=
 
xâˆˆR
x P[X = x]
 
yâˆˆR
y P[Y = y]

= E[X] E[Y].
For N âˆˆN, the random variables XN
:=

2âˆ’N4
2N|X|
5
âˆ§N and YN
:=

2âˆ’N4
2N|Y|
5
âˆ§N take only ï¬nitely many values and are independent as well.
Furthermore, XN â†‘|X| and YN â†‘|Y|. By the monotone convergence theorem
(Theorem 4.20), we infer
E[|XY|] = lim
Nâ†’âˆE[XNYN] = lim
Nâ†’âˆE[XN] E[YN]
=

lim
Nâ†’âˆE[XN]
 
lim
Nâ†’âˆE[YN]

= E[|X|] E[|Y|] < âˆ.
Hence XY âˆˆL1(P). Furthermore, we have shown the claim in the case where X
and Y are nonnegative. Hence (and since each of the families {X+, Y +}, {Xâˆ’, Y +},
{X+, Y âˆ’} and {Xâˆ’, Y âˆ’} is independent) we obtain
E[XY] = E[(X+ âˆ’Xâˆ’)(Y + âˆ’Y âˆ’)]
= E[X+Y +] âˆ’E[Xâˆ’Y +] âˆ’E[X+Y âˆ’] + E[Xâˆ’Y âˆ’]
= E[X+] E[Y +] âˆ’E[Xâˆ’] E[Y +] âˆ’E[X+] E[Y âˆ’] + E[Xâˆ’] E[Y âˆ’]
= E[X+ âˆ’Xâˆ’] E[Y + âˆ’Y âˆ’] = E[X] E[Y].
âŠ“âŠ”
Theorem 5.5 (Waldâ€™s identity) Let T, X1, X2, . . . be independent real random
variables in L1(P). Let P[T âˆˆN0] = 1 and assume that X1, X2, . . . are identically
distributed. Deï¬ne
ST :=
T

i=1
Xi.
Then ST âˆˆL1(P) and E[ST ] = E[T ] E[X1].

116
5
Moments and Laws of Large Numbers
Proof Deï¬ne Sn = n
i=1 Xi for n âˆˆN0. Then ST
= âˆ
n=1 Sn 1{T =n}. By
Remark 2.15, the random variables Sn and 1{T =n} are independent for any n âˆˆN and
thus uncorrelated. This implies (using the triangle inequality; see Theorem 5.3(v))
E
)
|ST |
*
=
âˆ

n=1
E
)
|Sn| 1{T =n}
*
=
âˆ

n=1
E
)
|Sn|
*
E
)
1{T =n}
*
â‰¤
âˆ

n=1
E
)
|X1|
*
n P[T = n] = E[|X1|] E[T ].
The same computation without absolute values yields the remaining part of the
claim.
âŠ“âŠ”
We collect some basic properties of the variance.
Theorem 5.6 Let X âˆˆL2(P). Then:
(i) Var[X] = E
)
(X âˆ’E[X])2*
â‰¥0.
(ii) Var[X] = 0 â‡â‡’X = E[X] almost surely.
(iii) The map f : R â†’R, x â†’E
)
(X âˆ’x)2*
is minimal at x0 = E[X] with
f (E[X]) = Var[X].
Proof
(i) This is a direct consequence of Remark 5.2(ii).
(ii) By Theorem 5.3(iii), we have E)(X âˆ’E[X])2* = 0 â‡â‡’(X âˆ’E[X])2 = 0
a.s.
(iii) Clearly, f (x) = E[X2] âˆ’2x E[X] + x2 = Var[X] + (x âˆ’E[X])2.
âŠ“âŠ”
Theorem 5.7 The map Cov : L2(P) Ã— L2(P) â†’R is a positive semideï¬nite
symmetric bilinear form and Cov[X, Y] = 0 if Y is almost surely constant. The
detailed version of this concise statement is: Let X1, . . ., Xm, Y1, . . ., Yn âˆˆL2(P)
and Î±1, . . . , Î±m, Î²1, . . . , Î²n âˆˆR as well as d, e âˆˆR. Then
Cov
â¡
â£d +
m

i=1
Î±iXi, e +
n

j=1
Î²jYj
â¤
â¦=

i,j
Î±iÎ²j Cov[Xi, Yj].
(5.1)
In particular, Var[Î±X] = Î±2Var[X] and the BienaymÃ© formula holds,
Var
- m

i=1
Xi
.
=
m

i=1
Var[Xi] +
m

i,j=1
iÌ¸=j
Cov[Xi, Xj].
(5.2)
For uncorrelated X1, . . . , Xm, we have Var
)m
i=1 Xi
*
= m
i=1 Var[Xi].

5.1
Moments
117
Proof
Cov
+
d +
m

i=1
Î±i Xi, e +
n

j=1
Î²j Yj
,
= E
+ m

i=1
Î±i(Xi âˆ’E[Xi])

n

j=1
Î²j(Yj âˆ’E[Yj])
,
=
m

i=1
n

j=1
Î±iÎ²j E)(Xi âˆ’E[Xi])(Yj âˆ’E[Yj])*
=
m

i=1
n

j=1
Î±iÎ²j Cov[Xi, Yj].
âŠ“âŠ”
Theorem 5.8 (Cauchyâ€“Schwarz inequality) If X, Y âˆˆL2(P), then

Cov[X, Y]
2 â‰¤Var[X] Var[Y].
Equality holds if and only if there are a, b, c âˆˆR with |a| + |b| + |c| > 0 and such
that aX + bY + c = 0 a.s.
Proof The Cauchyâ€“Schwarz inequality holds for any positive semideï¬nite bilinear
form and hence in particular for the covariance map. Using the notation of variance
and covariance, a simple proof looks like this:
Case 1:
Var[Y] = 0. Here the statement is trivial (choose a = 0, b = 1 and
c = âˆ’E[Y]).
Case 2:
Var[Y] > 0. Let Î¸ := âˆ’Cov[X,Y]
Var[Y] . Then, by Theorem 5.6(i),
0 â‰¤Var[X + Î¸Y] Var[Y] =

Var[X] + 2Î¸ Cov[X, Y] + Î¸2 Var[Y]

Var[Y]
= Var[X] Var[Y] âˆ’Cov[X, Y]2
with equality if and only if X + Î¸Y is a.s. constant. Now let a = 1, b = Î¸ and
c = âˆ’E[X] âˆ’b E[Y].
âŠ“âŠ”
Example 5.9
(i) Let p âˆˆ[0, 1] and X âˆ¼Berp. Then
E[X2] = E[X] = P[X = 1] = p
and thus Var[X] = p(1 âˆ’p).

118
5
Moments and Laws of Large Numbers
(ii) Let n âˆˆN and p âˆˆ[0, 1]. Let X be binomially distributed, X âˆ¼bn,p. Then
E[X] =
n

k=0
kP[X = k] =
n

k=0
k
n
k

pk (1 âˆ’p)nâˆ’k
= np Â·
n

k=1
n âˆ’1
k âˆ’1

pkâˆ’1 (1 âˆ’p)(nâˆ’1)âˆ’(kâˆ’1) = np.
Furthermore,
E[X(X âˆ’1)] =
n

k=0
k(k âˆ’1) P[X = k]
=
n

k=0
k(k âˆ’1)
n
k

pk (1 âˆ’p)nâˆ’k
= np Â·
n

k=1
(k âˆ’1)
n âˆ’1
k âˆ’1

pkâˆ’1 (1 âˆ’p)(nâˆ’1)âˆ’(kâˆ’1)
= n(n âˆ’1)p2 Â·
n

k=2
n âˆ’2
k âˆ’2

pkâˆ’2 (1 âˆ’p)(nâˆ’2)âˆ’(kâˆ’2)
= n(n âˆ’1)p2.
Hence E[X2] = E[X(Xâˆ’1)]+E[X] = n2p2 +np(1âˆ’p) and thus Var[X] =
np(1 âˆ’p).
The statement can be derived more simply than by direct computation if
we make use of the fact that bn,p = bâˆ—n
1,p (see Example 3.4(ii)). That is (see
Theorem 2.31), PX = PY1+...+Yn, where Y1, . . . , Yn are independent and Yi âˆ¼
Berp for any i = 1, . . . , n. Hence
E[X] = nE[Y1] = np,
Var[X] = nVar[Y1] = np(1 âˆ’p).
(5.3)

5.1
Moments
119
(iii) Let Î¼ âˆˆR and Ïƒ 2 > 0, and let X be normally distributed, X âˆ¼NÎ¼,Ïƒ 2. Then
E[X] =
1
âˆš
2Ï€Ïƒ 2
 âˆ
âˆ’âˆ
x eâˆ’(xâˆ’Î¼)2/(2Ïƒ 2) dx
=
1
âˆš
2Ï€Ïƒ 2
 âˆ
âˆ’âˆ
(x + Î¼) eâˆ’x2/(2Ïƒ 2) dx
= Î¼ +
1
âˆš
2Ï€Ïƒ 2
 âˆ
âˆ’âˆ
x eâˆ’x2/(2Ïƒ 2) dx = Î¼.
(5.4)
Similarly, we get Var[X] = E[X2] âˆ’Î¼2 = . . . = Ïƒ 2.
(iv) Let Î¸ > 0 and let X be exponentially distributed, X âˆ¼expÎ¸. Then
E[X] = Î¸
 âˆ
0
x eâˆ’Î¸x dx = 1
Î¸ ,
Var[X] = âˆ’Î¸âˆ’2 + Î¸
 âˆ
0
x2 eâˆ’Î¸x dx = Î¸âˆ’2

âˆ’1 +
 âˆ
0
x2 eâˆ’x dx

= Î¸âˆ’2.
â™¦
(5.5)
Theorem 5.10 (Blackwellâ€“Girshick) Let T, X1, X2, . . . be independent real ran-
dom variables in L2(P). Let P[T âˆˆN0] = 1 and let X1, X2, . . . be identically
distributed. Deï¬ne
ST :=
T

i=1
Xi.
Then ST âˆˆL2(P) and
Var[ST ] = E[X1]2 Var[T ] + E[T ] Var[X1].
Proof Deï¬ne Sn = n
i=1 Xi for n âˆˆN. Then (as in the proof of Waldâ€™s identity)
Sn and 1{T =n} are independent; hence S2
n and 1{T =n} are uncorrelated and thus
E
'
S2
T
(
=
âˆ

n=0
E
'
1{T =n} S2
n
(
=
âˆ

n=0
E[1{T =n}] E
'
S2
n
(
=
âˆ

n=0
P[T = n]

Var[Sn] + E[Sn]2

120
5
Moments and Laws of Large Numbers
=
âˆ

n=0
P[T = n]

n Var[X1] + n2 E[X1]2
= E[T ] Var[X1] + E)T 2* E[X1]2.
By Waldâ€™s identity (Theorem 5.5), we have E[ST ] = E[T ] E[X1]; hence
Var[ST ] = E
'
S2
T
(
âˆ’E[ST ]2 = E[T ] Var[X1] +

E
)
T 2*
âˆ’E[T ]2
E[X1]2,
as claimed.
âŠ“âŠ”
Reï¬‚ection In the proof of Theorem 5.10, where did we use the independence of
T ? Check that if E[Xi] = 0 for all i âˆˆN, then instead of independence of T , it is
enough to postulate: {T â‰¤n} is independent of Xn+1, Xn+2, . . . for all n. â™ â™ 
Takeaways Moments are important characteristics of probability distribu-
tions. We have seen a formula for the ï¬rst and second moment of a sum
of random variables, even if the number of summands is random itself.
Independent random variables are uncorrelated. In this case, the formulas for
the second moments of sums are particularly simple.
Exercise 5.1.1 Let X be a nonnegative random variable with ï¬nite second moment.
Use the Cauchy-Schwarz inequality for X and 1{X>0} in order to show the Paley-
Zygmund inequality
P[X > 0] â‰¥E[X]2
E[X2].
â™£
Exercise 5.1.2 Let X be an integrable real random variable whose distribution
PX has a density f (with respect to the Lebesgue measure Î»). Show (using
Theorem 4.15) that
E[X] =

R
xf (x) Î»(dx).
â™£
Exercise 5.1.3 Let X âˆ¼Î²r,s be a Beta-distributed random variable with parameters
r, s > 0 (see Example 1.107(ii)). Show that
E[Xn] =
nâˆ’1

k=0
r + k
r + s + k
for any n âˆˆN.
â™£

5.2
Weak Law of Large Numbers
121
Exercise 5.1.4 Let X1, X2, . . . be i.i.d. nonnegative random variables. By virtue of
the Borelâ€“Cantelli lemma, show that
lim sup
nâ†’âˆ
1
nXn =

0 a.s.,
if E[X1] < âˆ,
âˆa.s.,
if E[X1] = âˆ.
â™£
Exercise 5.1.5 Let X1, X2, . . . be i.i.d. nonnegative random variables. By virtue of
the Borelâ€“Cantelli lemma, show that for any c âˆˆ(0, 1)
âˆ

n=1
eXn cn

< âˆa.s.,
if E[X1] < âˆ,
= âˆa.s.,
if E[X1] = âˆ.
â™£
5.2
Weak Law of Large Numbers
Theorem 5.11 (Markov inequality, Chebyshev inequality) Let X be a real
random variable and let f : [0, âˆ) â†’[0, âˆ) be monotone increasing. Then for
any Îµ > 0 with f (Îµ) > 0, the Markov inequality holds,
P
)
|X| â‰¥Îµ
*
â‰¤E[f (|X|)]
f (Îµ)
.
In the special case f (x) = x2, we get P)|X| â‰¥Îµ* â‰¤Îµâˆ’2 E)X2*. In particular, if
X âˆˆL2(P), the Chebyshev inequality holds:
P
)
|X âˆ’E[X]| â‰¥Îµ
*
â‰¤Îµâˆ’2 Var[X].
Proof We have
E[f (|X|)] â‰¥E)f (|X|) 1{f (|X|)â‰¥f(Îµ)}
*
â‰¥E)f (Îµ) 1{f (|X|)â‰¥f(Îµ)}
*
â‰¥f (Îµ) P)|X| â‰¥Îµ*.
âŠ“âŠ”
Deï¬nition 5.12 Let (Xn)nâˆˆN be a sequence of real random variables in L1(P) and
let Sn = n
i=1(Xi âˆ’E[Xi]).
(i) We say that (Xn)nâˆˆN fulï¬lls the weak law of large numbers if
lim
nâ†’âˆP
+
1
n
Sn
 > Îµ
,
= 0
for any Îµ > 0.

122
5
Moments and Laws of Large Numbers
(ii) We say that (Xn)nâˆˆN fulï¬lls the strong law of large numbers if
P
+
lim sup
nâ†’âˆ

1
n
Sn
 = 0
,
= 1.
Remark 5.13 The strong law of large numbers implies the weak law. Indeed, if
AÎµ
n :=
 1
nSn
 > Îµ

and A =

lim sup
nâ†’âˆ
 1
nSn
 > 0

, then clearly
A =

mâˆˆN
lim sup
nâ†’âˆ
A1/m
n
;
hence P
'
lim sup
nâ†’âˆ
AÎµ
n
(
= 0 for Îµ > 0. By Fatouâ€™s lemma (Theorem 4.21), we obtain
lim sup
nâ†’âˆ
P )AÎµ
n
* = 1 âˆ’lim inf
nâ†’âˆE )1(AÎµn)c*
â‰¤1 âˆ’E
'
lim inf
nâ†’âˆ1(AÎµn)c
(
= E
+
lim sup
nâ†’âˆ
1AÎµn
,
= 0.
â™¦
Theorem 5.14 Let X1, X2, . . . be uncorrelated random variables in L2(P) with
V := supnâˆˆN Var[Xn] < âˆ. Then (Xn)nâˆˆN fulï¬lls the weak law of large numbers.
More precisely, for any Îµ > 0, we have
P
+
1
n
Sn
 â‰¥Îµ
,
â‰¤V
Îµ2n
for all n âˆˆN.
(5.6)
Reï¬‚ection Let Sn be the sum of the numbers shown when rolling a die n-times.
Then Sn/n should be close to 3.5 for large n - but close in which sense? The
weak law of large numbers states that the distribution of Sn/n is concentrated in
the vicinity of 3.5 (Fig. 5.1). On the other, the strong law of large numbers claims
that for ï¬xed Ï‰, we have Sn(Ï‰)/n
nâ†’âˆ
âˆ’â†’3.5 (Fig. 5.2).â™ 
Proof Without loss of generality, assume E[Xi] = 0 for all i âˆˆN and thus Sn =
X1 + Â· Â· Â· + Xn. By BienaymÃ©â€™s formula (Theorem 5.7), we obtain
Var
+1
n
Sn
,
= nâˆ’2
n

i=1
Var [Xi] â‰¤V
n .
By Chebyshevâ€™s inequality (Theorem 5.11), for any Îµ > 0,
P
)
|Sn/n| â‰¥Îµ
*
â‰¤
V
Îµ2 n
nâ†’âˆ
âˆ’â†’0.
âŠ“âŠ”

5.2
Weak Law of Large Numbers
123
3.3 3.33
3.37 3.4 3.43
3.47 3.5 3.53
3.57 3.6 3.63
3.67 3.7
0.00
0.05
0.10
0.15
0.20
0.25
3.3 3.33
3.37 3.4 3.43
3.47 3.5 3.53
3.57 3.6 3.63
3.67 3.7
0.00
0.05
0.10
0.15
0.20
0.25
Fig. 5.1 Rolling a die n times: Probabilities for Sn/n. Left hand side: n = 1000, Right hand side
n = 10 000. The bars show the probabilities for values in [x, x + 0.01), 3.3 â‰¤x â‰¤3.7.
0
2000
4000
6000
8000
10000
3.2
3.3
3.4
3.5
3.6
Fig. 5.2 Rolling a die n times: For a ï¬xed realisation, the values of Sn/n converge to 3.5. We have
n on the horizontal axis.
Example 5.15 (WeierstraÃŸâ€™s approximation theorem) Let f : [0, 1] â†’R be a
continuous map. By WeierstraÃŸâ€™s approximation theorem, there exist polynomials
fn of degree at most n such that
âˆ¥fn âˆ’f âˆ¥âˆ
nâ†’âˆ
âˆ’â†’0,
where âˆ¥f âˆ¥âˆ:= sup{|f (x)| : x âˆˆ[0, 1]} denotes the supremum norm of f âˆˆ
C([0, 1]) (the space of continuous functions [0, 1] â†’R).

124
5
Moments and Laws of Large Numbers
We present a probabilistic proof of this theorem. For n âˆˆN, deï¬ne the
polynomial fn by
fn(x) :=
n

k=0
f (k/n)
n
k

xk (1 âˆ’x)nâˆ’k
for x âˆˆ[0, 1].
fn is called the Bernstein polynomial of order n.
Fix Îµ > 0. As f is continuous on the compact interval [0, 1], f is uniformly
continuous. Hence there exists a Î´ > 0 such that
|f (x) âˆ’f (y)| < Îµ
for all x, y âˆˆ[0, 1] with |x âˆ’y| < Î´.
Now ï¬x p âˆˆ[0, 1] and let X1, X2, . . . be independent random variables with Xi âˆ¼
Berp, i âˆˆN. Then Sn := X1 + . . . + Xn âˆ¼bn,p and thus
E[f (Sn/n)] =
n

k=0
f (k/n) P[Sn = k] = fn(p).
We get
|f (Sn/n) âˆ’f (p)| â‰¤Îµ + 2âˆ¥f âˆ¥âˆ1{|(Sn/n)âˆ’p|â‰¥Î´}
and thus (by Theorem 5.14 with V = p(1 âˆ’p) â‰¤1
4)
|fn(p) âˆ’f (p)| â‰¤E[|f (Sn/n) âˆ’f (p)|]
â‰¤Îµ + 2âˆ¥f âˆ¥âˆP
+
Sn
n âˆ’p
 â‰¥Î´
,
â‰¤Îµ + âˆ¥f âˆ¥âˆ
2 Î´2 n
for any p âˆˆ[0, 1]. Hence âˆ¥fn âˆ’f âˆ¥âˆ
nâ†’âˆ
âˆ’â†’0. â™¦
Takeaways Laws of large numbers show that sums of very many random
variables approach their expected value. One can use second moments and
Chebyshevâ€™s inequality to establish a weak law of large numbers.
Exercise 5.2.1 (Bernsteinâ€“Chernov bound) Let n âˆˆN and p1, . . . , pn âˆˆ[0, 1].
Let X1, . . . , Xn be independent random variables with Xi = Berpi for any i =
1, . . . , n. Deï¬ne Sn = X1 + . . . + Xn and m := E[Sn]. Show that, for any Î´ > 0,
the following two estimates hold:
P
)
Sn â‰¥(1 + Î´)m
*
â‰¤

eÎ´
(1 + Î´)1+Î´
m

5.3
Strong Law of Large Numbers
125
and
P
)
Sn â‰¤(1 âˆ’Î´)m
*
â‰¤exp

âˆ’Î´2 m
2

.
Hint: For Sn, use Markovâ€™s inequality with f (x) = eÎ»x for some Î» > 0 and then
ï¬nd the Î» that optimizes the bound. â™£
5.3
Strong Law of Large Numbers
We show Etemadiâ€™s version [47] of the strong law of large numbers for identically
distributed, pairwise independent random variables. There is a zoo of strong laws
of large numbers, each of which varies in the exact assumptions it makes on the
underlying sequence of random variables. For example, the assumption that the
random variables be identically distributed can be waived if other assumptions are
introduced such as bounded variances. We do not strive for completeness but show
only a few of the statements.
In order to illustrate the method of the proof of Etemadiâ€™s theorem, we ï¬rst
present (and prove) a strong law of large numbers under stronger assumptions.
Theorem 5.16 Let X1, X2, . . . âˆˆL2(P) be pairwise independent (that is, Xi and
Xj are independent for all i, j âˆˆN with i Ì¸= j) and identically distributed. Then
(Xn)nâˆˆN fulï¬lls the strong law of large numbers.
Proof The random variables (X+
n )nâˆˆN and (Xâˆ’
n )nâˆˆN again form pairwise indepen-
dent families of square integrable random variables (compare Remark 2.15(ii)).
Hence, it is enough to consider (X+
n )nâˆˆN. Thus we henceforth assume Xn â‰¥0
almost surely for all n âˆˆN.
Let Sn = X1 + . . . + Xn for n âˆˆN. Fix Îµ > 0. For any n âˆˆN, deï¬ne kn =
âŒŠ(1 + Îµ)nâŒ‹â‰¥1
2(1 + Îµ)n. Then, by Chebyshevâ€™s inequality (Theorem 5.11),
âˆ

n=1
P
+
Skn
kn
âˆ’E[X1]
 â‰¥(1 + Îµ)âˆ’n/4
,
â‰¤
âˆ

n=1
(1 + Îµ)n/2 Var
'
kâˆ’1
n Skn
(
=
âˆ

n=1
(1 + Îµ)n/2 kâˆ’1
n
Var[X1]
â‰¤2 Var[X1]
âˆ

n=1
(1 + Îµ)âˆ’n/2 < âˆ.
(5.7)

126
5
Moments and Laws of Large Numbers
Thus, by the Borelâ€“Cantelli lemma, for P-a.a. Ï‰, there is an n0 = n0(Ï‰) such that

Skn
kn
âˆ’E[X1]
 < (1 + Îµ)âˆ’n/4
for all n â‰¥n0,
whence
lim sup
nâ†’âˆ
kâˆ’1
n Skn âˆ’E[X1]
 = 0
almost surely.
Note that kn+1 â‰¤(1 + 2Îµ)kn for sufï¬ciently large n âˆˆN. For l âˆˆ{kn, . . . , kn+1},
we get
1
1 + 2Îµ kâˆ’1
n
Skn â‰¤kâˆ’1
n+1 Skn â‰¤lâˆ’1 Sl â‰¤kâˆ’1
n
Skn+1 â‰¤(1 + 2Îµ) kâˆ’1
n+1 Skn+1.
Now 1 âˆ’(1 + 2Îµ)âˆ’1 â‰¤2Îµ implies
lim sup
lâ†’âˆ
lâˆ’1Sl âˆ’E[X1]
 â‰¤lim sup
nâ†’âˆ
kâˆ’1
n Skn âˆ’E[X1]
 + 2Îµ lim sup
nâ†’âˆ
kâˆ’1
n Skn
â‰¤2Îµ E[X1]
almost surely.
Hence the strong law of large numbers is in force.
âŠ“âŠ”
Reï¬‚ection The proof of the previous theorem made use of the fact that (X+
n )nâˆˆN
and (Xâˆ’
n )nâˆˆN are uncorrelated families. Why is it not enough to assume in the
theorem that (Xn)nâˆˆN be uncorrelated (instead of pairwise independent)? â™ 
The similarity of the variance estimates in the weak law of large numbers and in
(5.7) suggests that in the preceding theorem the condition that the random variables
X1, X2, . . . be identically distributed could be replaced by the condition that the
variances be bounded (see Exercise 5.3.1).
We can weaken the condition in Theorem 5.16 in a different direction by
requiring integrability only instead of square integrability of the random variables.
Theorem 5.17 (Etemadiâ€™s strong law of large numbers (1981)) Let X1, X2, . . .
âˆˆL1(P) be pairwise independent and identically distributed. Then (Xn)nâˆˆN fulï¬lls
the strong law of large numbers.
We follow the proof in [39, Section 2.4]. Deï¬ne Î¼ = E[X1] and Sn = X1+. . .+Xn.
We start with some preparatory lemmas. (For the â€œa.s.â€ notation see Deï¬nition 1.68.)
Lemma 5.18 For n âˆˆN, deï¬ne Yn := Xn 1{|Xn|â‰¤n} and Tn = Y1 + Â· Â· Â· + Yn. The
sequence (Xn)nâˆˆN fulï¬lls the strong law of large numbers if Tn/n
nâ†’âˆ
âˆ’â†’Î¼ a.s.

5.3
Strong Law of Large Numbers
127
Proof By Theorem 4.26, we have
âˆ

n=1
P)|Xn| > n* â‰¤E)|X1|* < âˆ. Thus, by the
Borelâ€“Cantelli lemma,
P
)
Xn Ì¸= Yn for inï¬nitely many n
*
= 0.
Hence there is an n0 = n0(Ï‰) with Xn = Yn for all n â‰¥n0, whence for n â‰¥n0
Tn âˆ’Sn
n
= Tn0 âˆ’Sn0
n
nâ†’âˆ
âˆ’â†’0.
âŠ“âŠ”
Lemma 5.19 2x

n>x
nâˆ’2 â‰¤4 for all x â‰¥0.
Proof For m âˆˆN, by comparison with the corresponding integral, we get
âˆ

n=m
nâˆ’2 â‰¤mâˆ’2 +
 âˆ
m
tâˆ’2 dt = mâˆ’2 + mâˆ’1 â‰¤2
m.
âŠ“âŠ”
Lemma 5.20
âˆ

n=1
E
)
Y 2
n
*
n2
â‰¤4 E[|X1|].
Proof By Theorem 4.26, E
)
Y 2
n
*
=
3 âˆ
0
P
)
Y 2
n > t
*
dt. Substituting x = âˆšt, we
obtain
E
'
Y 2
n
(
=
 âˆ
0
2x P[|Yn| > x] dx â‰¤
 n
0
2x P[|X1| > x] dx.
By Lemma 5.19, for m â†’âˆ,
fm(x) =
 m

n=1
nâˆ’2 1{x<n}

2x P[|X1| > x] â†‘f (x) â‰¤4 P[|X1| > x].
Hence, by the monotone limit theorem, we can interchange the summation and the
integral and obtain
âˆ

n=1
E
)
Y 2
n
*
n2
â‰¤
âˆ

n=1
nâˆ’2
 âˆ
0
1{x<n} 2x P[|X1| > x] dx
=
 âˆ
0
 âˆ

n=1
nâˆ’2 1{x<n}

2x P[|X1| > x] dx
â‰¤4
 âˆ
0
P[|X1| > x] dx = 4 E[|X1|].
âŠ“âŠ”

128
5
Moments and Laws of Large Numbers
Proof of Theorem 5.17 As in the proof of Theorem 5.16, it is enough to consider
the case Xn â‰¥0. Fix Îµ > 0 and let Î± = 1 + Îµ. For n âˆˆN, deï¬ne kn = âŒŠÎ±nâŒ‹. Note
that kn â‰¥Î±n/2. Hence, for all m âˆˆN (with n0 = âŒˆlog m/ log Î±âŒ‰),

n: knâ‰¥m
kâˆ’2
n
â‰¤4
âˆ

n=n0
Î±âˆ’2n = 4 Î±âˆ’2n0(1 âˆ’Î±âˆ’2)âˆ’1 â‰¤4(1 âˆ’Î±âˆ’2)âˆ’1 mâˆ’2.
(5.8)
The aim is to employ Lemma 5.20 to reï¬ne the estimate (5.7) for (Yn)nâˆˆN and
(Tn)nâˆˆN. For Î´ > 0, Chebyshevâ€™s inequality yields (together with (5.8))
âˆ

n=1
P
)Tkn âˆ’E
)
Tkn
* > Î´ kn
*
â‰¤Î´âˆ’2
âˆ

n=1
Var
)
Tkn
*
k2n
= Î´âˆ’2
âˆ

n=1
kâˆ’2
n
kn

m=1
Var[Ym] = Î´âˆ’2
âˆ

m=1
Var[Ym]

n: knâ‰¥m
kâˆ’2
n
â‰¤4(1 âˆ’Î±âˆ’2)âˆ’1 Î´âˆ’2
âˆ

m=1
mâˆ’2 E
)
Y 2
m
*
< âˆby Lemma 5.20.
(In the third step, we could change the order of summation since all summands are
nonnegative.) Letting Î´ â†“0, we infer by the Borelâ€“Cantelli lemma
lim
nâ†’âˆ
Tkn âˆ’E )Tkn
*
kn
= 0
almost surely.
(5.9)
By the monotone convergence theorem (Theorem 4.20), we have
E[Yn] = E)X1 1{X1â‰¤n}
*
nâ†’âˆ
âˆ’â†’
E[X1].
Hence E[Tkn]/kn
nâ†’âˆ
âˆ’â†’E[X1]. By (5.9), we also have Tkn/kn
nâ†’âˆ
âˆ’â†’E[X1] a.s. As
in the proof of Theorem 5.16, we also get (since Yn â‰¥0)
lim
lâ†’âˆ
Tl
l
= E[X1]
almost surely.
By Lemma 5.18, this implies the claim of Theorem 5.17.
âŠ“âŠ”
Reï¬‚ection In Etemadiâ€™s theorem, we assumed that the random variables
X1, X2, . . . are identically distributed. Come up with an example that shows that
this condition cannot simply be dropped. â™ â™ 
Example 5.21 (Monte Carlo integration) Let f : [0, 1] â†’R be a function and
assume we want to determine the value of its integral I :=
3 1
0 f (x) dx numerically.

5.3
Strong Law of Large Numbers
129
Assume that the computer generates numbers X1, X2, . . . that can be considered as
independent random numbers, uniformly distributed on [0, 1]. For n âˆˆN, deï¬ne the
estimated value
:In := 1
n
n

i=1
f (Xi).
Assuming f âˆˆL1([0, 1]), the strong law of large numbers yields :In
nâ†’âˆ
âˆ’â†’I a.s.
Note that the last theorem made no statement on the speed of convergence. That
is, we do not have control on the quantity P[|:In âˆ’I| > Îµ]. In order to get more
precise estimates for the integral, we need additional information; for example, the
value V1 :=
3
f 2(x) dx âˆ’I 2 if f âˆˆL2([0, 1]). (For bounded f , V1 can easily be
bounded.) Indeed, in this case, Var[:In] = V1/n; hence, by Chebyshevâ€™s inequality,
P
'
|:In âˆ’I| > Îµ nâˆ’1/2(
â‰¤V1/Îµ2.
Hence the error is at most of order nâˆ’1/2. The central limit theorem will show that
the error is indeed exactly of this order.
If f is smooth in some sense, then the usual numerical procedures yield better
orders of convergence. Hence Monte Carlo simulation should be applied only if
all other methods fail. This is the case in particular if [0, 1] is replaced by G âŠ‚Rd
for very large d. â™¦
Deï¬nition 5.22 (Empirical distribution function) Let X1, X2, . . . be real random
variables. The map Fn : R â†’[0, 1], x â†’1
n
n
i=1
1(âˆ’âˆ,x](Xi) is called the empirical
distribution function of X1, . . . , Xn.
Theorem 5.23 (Glivenkoâ€“Cantelli) Let X1, X2, . . . be i.i.d. real random variables
with distribution function F, and let Fn, n âˆˆN, be the empirical distribution
functions. Then
lim sup
nâ†’âˆ
sup
xâˆˆR
Fn(x) âˆ’F(x)
 = 0
almost surely.
Proof Fix x âˆˆR and let Yn(x) = 1(âˆ’âˆ,x](Xn) and Zn(x) = 1(âˆ’âˆ,x)(Xn) for n âˆˆ
N. Additionally, deï¬ne the left-sided limits F(xâˆ’) = limyâ†‘x F(y) and similarly
for Fn. Then each of the families (Yn(x))nâˆˆN and (Zn(x))nâˆˆN is independent.
Furthermore, E[Yn(x)] = P[Xn â‰¤x] = F(x) and E[Zn(x)] = P[Xn < x] =
F(xâˆ’). By the strong law of large numbers, we thus have
Fn(x) = 1
n
n

i=1
Yi(x)
nâ†’âˆ
âˆ’â†’F(x)
almost surely

130
5
Moments and Laws of Large Numbers
and
Fn(xâˆ’) = 1
n
n

i=1
Zi(x)
nâ†’âˆ
âˆ’â†’F(xâˆ’)
almost surely.
Formally, deï¬ne F(âˆ’âˆ) = 0 and F(âˆ) = 1. Fix some N âˆˆN and deï¬ne
xj := inf 	x âˆˆR : F(x) â‰¥j/N
,
j = 0, . . ., N,
and
Rn :=
max
j=1,...,Nâˆ’1
Fn(xj) âˆ’F(xj)
 +
Fn(xjâˆ’) âˆ’F(xjâˆ’)

.
As shown above, Rn
nâ†’âˆ
âˆ’â†’
0 almost surely. For x âˆˆ(xjâˆ’1, xj), we have (by
deï¬nition of xj)
Fn(x) â‰¤Fn(xjâˆ’) â‰¤F(xjâˆ’) + Rn â‰¤F(x) + Rn + 1
N
and
Fn(x) â‰¥Fn(xjâˆ’1) â‰¥F(xjâˆ’1) âˆ’Rn â‰¥F(x) âˆ’Rn âˆ’1
N .
Hence
lim sup
nâ†’âˆ
sup
xâˆˆR
Fn(x) âˆ’F(x)
 â‰¤
1
N + lim sup
nâ†’âˆ
Rn =
1
N .
Letting N â†’âˆ, the claim follows.
âŠ“âŠ”
Example 5.24 (Shannonâ€™s theorem) Consider a source of information that sends a
sequence of independent random symbols X1, X2, . . . drawn from a ï¬nite alphabet
E (that is, from an arbitrary ï¬nite set E). Let pe be the probability of the symbol
e âˆˆE. Formally, the X1, X2, . . . are i.i.d. E-valued random variables with P[Xi =
e] = pe for e âˆˆE.
For any Ï‰ âˆˆÎ© and n âˆˆN, let
Ï€n(Ï‰) :=
n

i=1
pXi(Ï‰)
be the probability that the observed sequence X1(Ï‰), . . . , Xn(Ï‰) occurs. Deï¬ne
Yn(Ï‰) := âˆ’log(pXn(Ï‰)). Then (Yn)nâˆˆN is i.i.d. and E[Yn] = H(p), where
H(p) := âˆ’

eâˆˆE
pe log(pe)

5.3
Strong Law of Large Numbers
131
is the entropy of the distribution p = (pe)eâˆˆE (compare Deï¬nition 5.25). By the
strong law of large numbers, we infer Shannonâ€™s theorem:
âˆ’1
n log Ï€n = 1
n
n

i=1
Yi
nâ†’âˆ
âˆ’â†’H(p)
almost surely.
â™¦
Entropy and Source Coding Theoremâˆ—
We brieï¬‚y discuss the importance of Ï€n and the entropy. How can we quantify
the information inherent in a message X1(Ï‰), . . . , Xn(Ï‰)? This information can be
measured by the length of the shortest sequence of zeros and ones by which the
message can be encoded. Of course, you do not want to invent a new code for
every message but rather use one code that allows for the shortest average coding
of the messages for the particular information source. To this end, associate with
each symbol e âˆˆE a sequence of zeros and ones that when concatenated yield the
message. The length l(e) of the sequence that codes for e may depend on e. Hence,
for efï¬ciency, those symbols that appear more often get a shorter code than the more
rare symbols. The Morse alphabet is constructed similarly (the letters â€œeâ€ and â€œtâ€,
which are the most frequent letters in English, have the shortest codes (â€œdotâ€ and
â€œdashâ€), and the rare letter â€œqâ€ has the code â€œdash-dash-dot-dashâ€). However, the
Morse code also consists of gaps of different lengths that signal ends of letters and
words. As we want to use only zeros and ones (and no gap-like symbols), we have to
arrange the code in such a way that no code is the beginning of the code of a different
symbol. For example, we could not encode one symbol with 0110 and a different
one with 011011. A code that fulï¬lls this condition is called a binary preï¬x code.
Denote by c(e) âˆˆ{0, 1}l(e) the code of e, where l(e) is its length. We can represent
the codes of all letters in a tree.
Let us construct a code C = (c(e), e âˆˆE) that is efï¬cient in the sense that it
minimizes the expected length of the code (of a random symbol)
Lp(C) :=

eâˆˆE
pe l(e).
We ï¬rst deï¬ne a speciï¬c code and then show that it is almost optimal. As a ï¬rst step,
we enumerate E = {e1, . . . , eN} such that pe1 â‰¥pe2 â‰¥. . . â‰¥peN . Deï¬ne â„“(e) âˆˆN
for any e âˆˆE by
2âˆ’â„“(e) â‰¤pe < 2âˆ’â„“(e)+1.
Let Ëœpe = 2âˆ’â„“(e) for any e âˆˆE and let Ëœqk = 
l<k Ëœpel for k = 1, . . . , N.

132
5
Moments and Laws of Large Numbers
By construction, â„“(el) â‰¤â„“(ek) for all l â‰¤k; hence the binary representation of
Ëœqk has at most â„“(ek) digits:
Ëœqk =
â„“(ek)

i=1
ci(ek) 2âˆ’i.
Here the numbers c1(ek), . . . , câ„“(ek)(ek) âˆˆ{0, 1} are uniquely determined.
Clearly, Ëœql â‰¥Ëœqk + 2âˆ’â„“(ek) for any l > k; hence
c1(ek), . . . , câ„“(ek)(ek) Ì¸= c1(el), . . . , câ„“(ek)(el)
for all l > k.
Thus C = (c(e), e âˆˆE) is a preï¬x code.
For any b > 0 and x > 0, denote by logb(x) := log(x)
log(b) the logarithm of x to base
b. By construction, âˆ’log2(pe) â‰¤l(e) â‰¤1 âˆ’log2(pe). Hence the expected length is
âˆ’

eâˆˆE
pe log2(pe) â‰¤Lp(C) â‰¤1 âˆ’

eâˆˆE
pe log2(pe).
The length of this code for the ï¬rst n symbols of our random information source
is thus approximately âˆ’n
k=1 log2(pXk(Ï‰)) = âˆ’log2 Ï€n(Ï‰). Here we have the
connection to Shannonâ€™s theorem. That theorem thus makes a statement about the
length of a binary preï¬x code needed to transmit a long message.
Now, is the code constructed above optimal, or are there codes with smaller mean
length? The answer is given by the source coding theorem for which we prepare with
a deï¬nition and a lemma.
Deï¬nition 5.25 (Entropy) Let p = (pe)eâˆˆE be a probability distribution on the
countable set E. For b > 0, deï¬ne
Hb(p) := âˆ’

eâˆˆE
pe logb(pe)
with the convention 0 logb(0) := 0. We call H(p) := He(p) (e = 2.71 . . . Eulerâ€™s
number) the entropy and H2(p) the binary entropy of p.
Note that, for inï¬nite E, the entropy need not be ï¬nite.
Lemma 5.26 (Entropy inequality) Let b and p be as above. Further, let q be a
sub-probability distribution; that is, qe â‰¥0 for all e âˆˆE and 
eâˆˆE qe â‰¤1. Then
Hb(p) â‰¤âˆ’

eâˆˆE
pe logb(qe)
(5.10)
with equality if and only if Hb(p) = âˆor q = p.
Proof Without loss of generality, we can do the computation with b = e; that is,
with the natural logarithm. Note that log(1 + x) â‰¤x for x > âˆ’1 with equality if
and only if x = 0. If in (5.10) the left-hand side is ï¬nite, then we can subtract the

5.3
Strong Law of Large Numbers
133
right-hand side from the left-hand side and obtain
H(p) +

eâˆˆE
pe log(qe) =

e: pe>0
pe log(qe/pe)
=

e: pe>0
pe log

1 + qe âˆ’pe
pe

â‰¤

e: pe>0
pe
qe âˆ’pe
pe
=

eâˆˆE

qe âˆ’pe

â‰¤0.
If q Ì¸= p, then there is an e âˆˆE with pe > 0 and qe Ì¸= pe. If this is the case, then
strict inequality holds if H(p) < âˆ.
âŠ“âŠ”
Theorem 5.27 (Source coding theorem) Let p
= (pe)eâˆˆE be a probability
distribution on the ï¬nite alphabet E. For any binary preï¬x code C = (c(e), e âˆˆE),
we have Lp(C) â‰¥H2(p). Furthermore, there is a binary preï¬x code C with
Lp(C) â‰¤H2(p) + 1.
Proof The second part of the theorem was shown in the above construction. Now
assume that a preï¬x code is given. Let L = maxeâˆˆE l(e). For e âˆˆE, let
CL(e) =
	
c âˆˆ{0, 1}L : ck = ck(e) for k â‰¤l(e)

the set of all dyadic sequences of length L that start like c(e). Since we have a
preï¬x code, the sets CL(e), e âˆˆE, are pairwise disjoint and 
eâˆˆE CL(e) âŠ‚{0, 1}L.
Hence, if we deï¬ne qe := 2âˆ’l(e), then (note that #CL(e) = 2Lâˆ’l(e))

eâˆˆE
qe = 2âˆ’L 
eâˆˆE
#CL(e) â‰¤1.
By Lemma 5.26, we have Lp(C) = 
eâˆˆE
pe l(e) = âˆ’
eâˆˆE
pe log2(qe) â‰¥H2(p).
âŠ“âŠ”
Takeaways For random variables with second moments, a strong law of
large numbers can be shown using the Borel-Cantelli lemma and Chebyshevâ€™s
inequality ï¬rst on an subsequence and then on the full sequence. For pairwise
independent random variables with ï¬rst moment, we could establish a strong
law of large number via an involved truncation procedure which allows to use
second moments estimates.
Exercise 5.3.1 Show the following improvement of Theorem 5.16: If X1, X2, . . .
âˆˆL2(P) are pairwise independent with bounded variances, then (Xn)nâˆˆN fulï¬lls
the strong law of large numbers. â™£

134
5
Moments and Laws of Large Numbers
Exercise 5.3.2 Let (Xn)nâˆˆN be a sequence of independent identically distributed
random variables with 1
n(X1 + . . . + Xn)
nâ†’âˆ
âˆ’â†’Y almost surely for some random
variable Y. Show that X1 âˆˆL1(P) and Y = E[X1] almost surely.
Hint: First show that
P
)
|Xn| > n for inï¬nitely many n
*
= 0
â‡â‡’
X1 âˆˆL1(P).
â™£
Exercise 5.3.3 Let E be a ï¬nite set and let p be a probability vector on E. Show
that the entropy H(p) is minimal (in fact, zero) if p = Î´e for some e âˆˆE. It is
maximal (in fact, log(#E)) if p is the uniform distribution on E. â™£
Exercise 5.3.4 (Subadditivity of Entropy) For i = 1, 2, let Ei be a ï¬nite set
and pi a probability vector on Ei. Let p be a probability vector on E1 Ã— E2 with
marginals p1 and p2. That is,

e2âˆˆE2
p(e1,e2) = p1
e1
and

f 1âˆˆE1
p(f 1,f 2) = p2
f 2
for all e1 âˆˆE1, f 2 âˆˆE2.
Show that H(p) â‰¤H(p1) + H(p2). â™£
Exercise 5.3.5 Let b âˆˆ{2, 3, 4, . . .}. A b-adic preï¬x code is deï¬ned in a similar
way as a binary preï¬x code; however, instead of 0 and 1, now all numbers
0, 1, . . ., bâˆ’1 are admissible. Show that the statement of the source coding theorem
holds for b-adic preï¬x codes with H2(p) replaced by Hb(p). â™£
Exercise 5.3.6 We want to check the efï¬ciency of the Morse alphabet. To this end
we need a table of the Morse code as well as the frequencies of the letters in a typical
text. The following frequencies for letters in German texts are taken from [11, p. 10].
The frequencies for other languages can be found easily, e.g., at Wikipedia.
Letter
Morse code
Frequency
A
.-
0.0651
B
-...
0.0189
C
-.-.
0.0306
D
-..
0.0508
E
.
0.1740
F
..-.
0.0166
G
-.
0.0301
H
....
0.0476
I
..
0.0755
J
.--
0.0027
K
-.-
0.0121
L
.-..
0.0344
M
-
0.0253
Letter
Morse code
Frequency
N
-.
0.0978
O
--
0.0251
P
.-.
0.0079
Q
-.-
0.0002
R
.-.
0.07
S
...
0.0727
T
-
0.0615
U
..-
0.0435
V
...-
0.0067
W
.-
0.0189
X
-..-
0.0003
Y
-.-
0.0004
Z
-..
0.0113

5.4
Speed of Convergence in the Strong LLN
135
Here â€˜.â€™ denotes a short signal while â€˜-â€™ denotes a long signal. Each letter is
ï¬nished by a pause sign. Thus the Morse code can be interpreted as a ternary preï¬x
code.
Determine the average code length of a letter and compare it with the entropy H3
in order to check the efï¬ciency of the Morse code. â™£
Exercise 5.3.7 Let m âˆˆ(0, âˆ) and let
Wm =

p = (pk)kâˆˆN0 is a probability measure on N0 and
âˆ

k=0
kpk = m

be the set of probability measures on N0 with expectation m.
(i) Show that there exists a pmax âˆˆWm that maximises the entropy; that is,
H

pmax

= suppâˆˆWm H(p).
(ii) Compute pmax explicitly. â™£
5.4
Speed of Convergence in the Strong LLN
In the weak law of large numbers, we had a statement on the speed of convergence
(Theorem 5.14). In the strong law of large numbers, however, we did not. As
we required only ï¬rst moments, in general, we cannot expect to get any useful
statements. However, if we assume the existence of higher moments, we get
reasonable estimates on the rate of convergence.
The core of the weak law of large numbers is Chebyshevâ€™s inequality. Here we
present a stronger inequality that claims the same bound but now for the maximum
over all partial sums until a ï¬xed time.
Theorem 5.28 (Kolmogorovâ€™s inequality) Let n âˆˆN and let X1, X2, . . . , Xn be
independent random variables with E[Xi] = 0 and Var[Xi] <âˆfor i = 1, . . . , n.
Further, let Sk = X1 + . . . + Xk for k = 1, . . . , n. Then, for any t > 0,
P
)
max{Sk : k = 1, . . . , n} â‰¥t
*
â‰¤
Var[Sn]
t2 + Var[Sn].
(5.11)
Furthermore, Kolmogorovâ€™s inequality holds:
P
)
max{|Sk| : k = 1, . . . , n} â‰¥t
*
â‰¤tâˆ’2 Var[Sn].
(5.12)
a generalization of Kolmogorovâ€™s inequality.

136
5
Moments and Laws of Large Numbers
Proof We decompose the probability space according to the ï¬rst time Ï„ at which
the partial sums exceed the value t. Hence, let
Ï„ := min
	
k âˆˆ{1, . . . , n} : Sk â‰¥t

and Ak = {Ï„ = k} for k = 1, . . . , n. Further, let
A =
n

k=1
Ak =
	
max{Sk : k = 1, . . . , n} â‰¥t

.
Let c â‰¥0. The random variable (Sk +c) 1Ak is Ïƒ(X1, . . . , Xk)-measurable and Snâˆ’
Sk is Ïƒ(Xk+1, . . . , Xn)-measurable. By Theorem 2.26, the two random variables are
independent, and
E)(Sk + c) 1Ak(Sn âˆ’Sk)* = E)(Sk + c) 1Ak
* E)Sn âˆ’Sk
* = 0.
Clearly, the events A1, . . . , An are pairwise disjoint; hence n
k=1 1Ak = 1A â‰¤1.
We thus obtain
Var[Sn] + c2 = E
)
(Sn + c)2*
â‰¥E
- n

k=1
(Sn + c)2 1Ak
.
=
n

k=1
E
'
(Sn + c)2 1Ak
(
=
n

k=1
E
'
(Sk + c)2 + 2(Sk + c)(Sn âˆ’Sk) + (Sn âˆ’Sk)2
1Ak
(
=
n

k=1
E
'
(Sk + c)2 1Ak
(
+
n

k=1
E
'
(Sn âˆ’Sk)2 1Ak
(
â‰¥
n

k=1
E
'
(Sk + c)2 1Ak
(
.
(5.13)
Since c â‰¥0, we have (Sk + c)2 1Ak â‰¥(t + c)2 1Ak. Hence we can continue (5.13)
to get
Var[Sn] + c2 â‰¥
n

k=1
E
'
(t + c)2 1Ak
(
= (t + c)2 P[A].
For c = Var[Sn]/t â‰¥0, we obtain
P[A] â‰¤Var[Sn] + c2
(t + c)2
= c(t + c)
(t + c)2 =
tc
t2 + tc =
Var[Sn]
t2 + Var[Sn].

5.4
Speed of Convergence in the Strong LLN
137
This shows (5.11). In order to show (5.12), choose
Â¯Ï„ := min
	
k âˆˆ{1, . . . , n} : |Sk| â‰¥t

.
Let Â¯Ak = {Â¯Ï„ = k} and Â¯A = {Â¯Ï„ â‰¤n}. We cannot now continue (5.13) as above with
c > 0. However, if we choose c = 0, then S2
k 1 Â¯Ak â‰¥t2 1 Â¯Ak. The same calculation
as in (5.13) does then yield P[ Â¯A] â‰¤tâˆ’2 Var[Sn].
âŠ“âŠ”
From Kolmogorovâ€™s inequality, we derive the following sharpening of the strong
law of large numbers.
Theorem 5.29 Let X1, X2, . . . be independent random variables with E[Xn] = 0
for any n âˆˆN and V := sup{Var[Xn] : n âˆˆN} < âˆ. Then, for any Îµ > 0,
lim sup
nâ†’âˆ
|Sn|
n1/2(log(n))(1/2)+Îµ = 0
almost surely.
Proof Let kn = 2n and l(n) = n1/2(log(n))(1/2)+Îµ for n âˆˆN. Then we have
l(kn+1)/l(kn)
nâ†’âˆ
âˆ’â†’
âˆš
2. Hence, for n âˆˆN sufï¬ciently large and k âˆˆN with
knâˆ’1 â‰¤k â‰¤kn, we have |Sk|/l(k) â‰¤2|Sk|/l(kn). Hence, it is enough to show for
every Î´ > 0 that
lim sup
nâ†’âˆ
l(kn)âˆ’1 max{|Sk| : k â‰¤kn} â‰¤Î´
almost surely.
(5.14)
For Î´ > 0 and n âˆˆN, deï¬ne AÎ´
n :=
	
max{|Sk| : k â‰¤kn} > Î´ l(kn)

. Kolmogorovâ€™s
inequality yields
âˆ

n=1
P )AÎ´
n
* â‰¤
âˆ

n=1
Î´âˆ’2(l(kn))âˆ’2 V kn =
V
Î´2(log 2)1+2Îµ
âˆ

n=1
nâˆ’1âˆ’2Îµ < âˆ.
The Borelâ€“Cantelli lemma then gives P )lim supnâ†’âˆAÎ´
n
* = 0 and hence (5.14).
âŠ“âŠ”
In Chap. 22, we will see that for independent identically distributed, square inte-
grable, centered random variables X1, X2, . . ., the following strengthening holds,
lim sup
nâ†’âˆ
|Sn|
2
2n Var[X1] log(log(n))
= 1
almost surely.
Hence, in this case, the speed of convergence is known precisely. If the X1, X2, . . .
are not independent but only pairwise independent, then the rate of convergence
deteriorates, although not drastically. Here we cite without proof a theorem that was
found independently by Rademacher [141] and Menshov [113].

138
5
Moments and Laws of Large Numbers
Theorem 5.30 (Rademacherâ€“Menshov) Let X1, X2, . . . be uncorrelated, square
integrable, centered random variables and let (an)nâˆˆN be an increasing sequence of
nonnegative numbers such that
âˆ

n=1
(log n)2aâˆ’2
n
Var[Xn] < âˆ.
(5.15)
Then lim sup
nâ†’âˆ
aâˆ’1
n
n

k=1
Xk
 = 0
almost surely.
Proof See, for example, [128].
âŠ“âŠ”
Remark 5.31 Condition (5.15) is sharp in the sense that for any increasing sequence
(an)nâˆˆN with âˆ
n=1 aâˆ’2
n (log n)2 = âˆ, there exists a sequence of pairwise indepen-
dent, square integrable, centered random variables X1, X2, . . . with Var[Xn] = 1
for all n âˆˆN such that
lim sup
nâ†’âˆ
aâˆ’1
n
n

k=1
Xk
 = âˆ
almost surely.
See [22]. There an example of [164] (see also [165, 166]) for orthogonal series is
developed further. See also [117]. â™¦
For random variables with inï¬nite variance, the statements about the rate of
convergence naturally get weaker. For example (see [8]), see the following theorem.
Theorem 5.32 (Baum and Katz [8]) Let Î³ > 1 and let X1, X2, . . . be i.i.d. Deï¬ne
Sn = X1 + . . . + Xn for n âˆˆN. Then
âˆ

n=1
nÎ³ âˆ’2 P[|Sn|/n>Îµ] < âˆfor any Îµ > 0 â‡â‡’E[|X1|Î³ ]<âˆand E[X1] = 0.
Takeaways Kolmogorovâ€™s inequality gives bounds for the maximum of
partial sums of random variables similar to Chebyshevâ€™s inequality for one
random variable. We have used this inequality in order to give an (almost
sharp) upper bound on the speed of convergence in the strong law of large
numbers (Theorem 5.29). Later, with a lot of additional effort, we will achieve
a sharp bound in Theorem 22.11.
Exercise 5.4.1 Let X1, . . . , Xn be independent real random variables and let Sk =
X1 + . . .+ Xk for k = 1, . . ., n. Show that for t > 0 Etemadiâ€™s inequality holds:
P
'
max
k=1,...,n |Sk| â‰¥t
(
â‰¤3 max
k=1,...,n P
)
|Sk| â‰¥t/3
*
.
â™£

5.5
The Poisson Process
139
5.5
The Poisson Process
We develop a model for the number of clicks of a Geiger counter in the (time)
interval I = (a, b]. The number of clicks should obey the following rules. It
should
â€¢
be random and independent for disjoint intervals,
â€¢
be homogeneous in time in the sense that the number of clicks in I = (a, b] has
the same distribution as the number of clicks in c + I = (a + c, b + c],
â€¢
have ï¬nite expectation, and
â€¢
have no double points: At any point of time, the counter makes at most one click.
We formalize these requirements by introducing the following notation:
I :=
	
(a, b] : a, b âˆˆ[0, âˆ), a â‰¤b

,
â„“((a, b]) := b âˆ’a
(the length of the interval I = (a, b]).
For I âˆˆI, let NI be the number of clicks after time a but no later than b. In
particular, we deï¬ne Nt := N(0,t] as the total number of clicks until time t. The
above requirements translate to: (NI, I âˆˆI) being a family of random variables
with values in N0 and with the following properties:
(P1) NIâˆªJ = NI + NJ if I âˆ©J = âˆ…and I âˆªJ âˆˆI.
(P2) The distribution of NI depends only on the length of I: PNI = PNJ for all
I, J âˆˆI with â„“(I) = â„“(J).
(P3) If J âŠ‚I with I âˆ©J = âˆ…for all I, J âˆˆJ with I Ì¸= J, then (NJ , J âˆˆJ ) is
an independent family.
(P4) For any I âˆˆI, we have E[NI] < âˆ.
(P5) lim supÎµâ†“0 Îµâˆ’1 P[NÎµ â‰¥2] = 0.
The meaning of (P5) is explained by the following calculation. Deï¬ne
Î» := lim sup
Îµâ†“0
Îµâˆ’1 P[NÎµ â‰¥2].
For any n âˆˆN and Îµ > 0, we have
P[N2âˆ’n â‰¥2] â‰¥âŒŠ2âˆ’n/ÎµâŒ‹P[NÎµ â‰¥2] âˆ’âŒŠ2âˆ’n/ÎµâŒ‹2 P[NÎµ â‰¥2]2.
Hence
2n P[N2âˆ’n â‰¥2] â‰¥Î» âˆ’2âˆ’nÎ»2
nâ†’âˆ
âˆ’â†’
Î».

140
5
Moments and Laws of Large Numbers
Then (because (1 âˆ’ak/k)k kâ†’âˆ
âˆ’â†’eâˆ’a if ak
kâ†’âˆ
âˆ’â†’a)
P
)
there is a double click in (0, 1]
*
= lim
nâ†’âˆP
+ 2nâˆ’1

k=0
	
N(k 2âˆ’n,(k+1)2âˆ’n] â‰¥2

,
= 1 âˆ’lim
nâ†’âˆP
+ 2nâˆ’1

k=0
	N(k 2âˆ’n,(k+1)2âˆ’n] â‰¤1
,
= 1 âˆ’lim
nâ†’âˆ
2nâˆ’1

k=0
P
)
N(k 2âˆ’n,(k+1)2âˆ’n] â‰¤1
*
= 1 âˆ’lim
nâ†’âˆ

1 âˆ’P[N2âˆ’n â‰¥2]
2n
= 1 âˆ’eâˆ’Î».
Hence we have to postulate Î» = 0. This, however, is exactly (P5).
The following theorem shows that properties (P1)â€“(P5) characterize the random
variables (NI, I âˆˆI) uniquely and that they form a Poisson process.
Deï¬nition 5.33 (Poisson process) A family (Nt, t â‰¥0) of N0-valued random
variables is called a Poisson process with intensity Î± â‰¥0 if N0 = 0 and if:
(i) For any n âˆˆN and any choice of n + 1 numbers 0 = t0 < t1 < . . . < tn, the
family (Nti âˆ’Ntiâˆ’1, i = 1, . . . , n) is independent.
(ii) For t > s â‰¥0, the difference Nt âˆ’Ns is Poisson-distributed with parameter
Î±(t âˆ’s); that is,
P[Nt âˆ’Ns = k] = eâˆ’Î±(tâˆ’s)(Î±(t âˆ’s))k
k!
for all k âˆˆN0.
See Fig. 5.3 for a computer simulation of a Poisson process.
The existence of the Poisson process has not yet been shown. We come back to
this point in Theorem 5.36.
Fig. 5.3 Simulation of a
Poisson process with rate
Î± = 0.5.
0
2
4
6
8
10
0
1
2
3
4
5
6

5.5
The Poisson Process
141
Theorem 5.34 If (NI, I âˆˆI) has properties (P1)â€“(P5), then (N(0,t], t â‰¥0) is a
Poisson process with intensity Î± := E[N(0,1]]. If, on the other hand, (Nt, t â‰¥0) is
a Poisson process, then (Nt âˆ’Ns, (s, t] âˆˆI) has properties (P1)â€“(P5).
Proof First assume that (Nt, t â‰¥0) is a Poisson process with intensity Î± â‰¥0.
Then, for I = (a, b], clearly PNI = PoiÎ±(bâˆ’a) = PoiÎ±â„“(I). Hence (P2) holds. By (i),
we have (P3). Clearly, E[NI] = Î± â„“(I) < âˆ; thus we have (P4). Finally, P[NÎµ â‰¥
2] = 1 âˆ’eâˆ’Î±Îµ âˆ’Î± Îµ eâˆ’Î±Îµ = f (0) âˆ’f (Î±Îµ), where f (x) := eâˆ’x + xeâˆ’x. The
derivative is f â€²(x) = âˆ’xeâˆ’x, whence
lim
Îµâ†“0 Îµâˆ’1 P[NÎµ â‰¥2] = âˆ’Î±f â€²(0) = 0.
This implies (P5).
Now assume that (NI, I âˆˆI) fulï¬lls (P1)â€“(P5). Deï¬ne Î±(t) := E[Nt]. Then
(owing to (P2))
Î±(s + t) = E
)
N(0,s] + N(s,s+t]
*
= E
)
N(0,s]
*
+ E
)
N(0,t]
*
= Î±(s) + Î±(t).
As t â†’Î±(t) is monotone increasing, this implies linearity: Î±(t) = t Î±(1) for any
t â‰¥0. Letting Î± := Î±(1), we obtain E[NI] = Î± â„“(I). It remains to show that
PNt = PoiÎ±t. In order to apply the Poisson approximation theorem (Theorem 3.7),
for ï¬xed n âˆˆN, we decompose the interval (0, t] into 2n disjoint intervals of equal
length,
I n(k) :=

(k âˆ’1)2âˆ’nt, k2âˆ’nt
*
,
k = 1, . . . , 2n.
Now deï¬ne Xn(k) := NI n(k) and
Xn(k) :=
0 1,
if Xn(k) â‰¥1,
0,
else.
By properties (P2) and (P3), the random variables (Xn(k), k = 1, . . . , 2n) are
independent and identically distributed. Hence also (Xn(k), k = 1, . . . , 2n) are
i.i.d., namely Xn(k) âˆ¼Berpn, where pn = P[N2âˆ’nt â‰¥1].
Finally, let Nn
t := 2n
k=1 Xn(k). Then Nn
t âˆ¼b2n,pn. Clearly, Nn+1
t
âˆ’Nn
t â‰¥0.
Now, by (P5),
P
)
Nt Ì¸= Nn
t
*
â‰¤
2n

k=1
P
)
Xn(k) â‰¥2
*
= 2n P [N2âˆ’nt â‰¥2]
nâ†’âˆ
âˆ’â†’
0.
(5.16)
Hence P
'
Nt = lim
nâ†’âˆNn
t
(
= 1. By the monotone convergence theorem, we get
Î± t = E [Nt] =
lim
nâ†’âˆE
)
Nn
t
*
=
lim
nâ†’âˆpn 2n.

142
5
Moments and Laws of Large Numbers
Using the Poisson approximation theorem (Theorem 3.7), we infer that, for any
l âˆˆN0,
P[Nt = l] =
lim
nâ†’âˆP
)
Nn
t = l
*
= PoiÎ±t({l}).
Hence PNt = PoiÎ± t.
âŠ“âŠ”
Reï¬‚ection Why do we need condition (iii) in the deï¬nition of the Poisson process?
Consider a Poisson process (Nt)tâ‰¥0 and choose an independent exponentially
distributed random variable T (it would sufï¬ce for T to have a density). Now deï¬ne
ËœNt = Nt for t Ì¸= T and let ËœNT = 0. The process ËœN fulï¬lls (i) and (ii), but not
(iii). In fact, t â†’ËœNt is not monotone. A second possibility to spoil (iii) is to deï¬ne
Nt := supr<t Nr fÃ¼r t > 0 und N0 = 0. In this case, t â†’Nt is monotone but it is
not right continuous, although (i) and (ii) hold.
In either case, where does the proof of Theorem 5.34 fail? â™ â™ 
At this point, we still have to show that there are Poisson processes at all. We present
a general two-step construction principle that will be used in a similar form later in
Chap. 24 in a more general setting. In the ï¬rst step, we determine the (random)
number of jumps in (0, 1]. In the second step, we distribute these jumps uniformly
and independently on (0, 1]. Strictly speaking, this gives the Poisson process only
on the time interval (0, 1], but it is clear how to move on: We perform the same
procedure independently for each of the intervals (1, 2], (2, 3] and so on and then
collect the jumps (see also Exercise 5.5.1).
Let Î± > 0 and let L be a PoiÎ± random variable. Further, let X1, X2, . . .
be independent random variables, that are uniformly distributed on (0, 1], i.e.,
Xk âˆ¼U(0,1] for each k. We assume that {L, X1, X2, . . .} is an independent family
of random variables. We now deï¬ne N = (Nt)tâˆˆ[0,1] by
Nt :=
L

l=1
1(0,t](Xl)
for t âˆˆ[0, 1].
(5.17)
Theorem 5.35 The family N of random variables deï¬ned in (5.17) is a Poisson
process with intensity Î± (and time set [0, 1]).
Proof We have to show that the increments of N in ï¬nitely many pairwise disjoint
intervals are independent and Poisson distributed. Hence let m âˆˆN and 0 = t0 <
t1 < . . . < tm = 1. We use the abbreviations pi := ti âˆ’tiâˆ’1 and Î»i = Î± Â· (ti âˆ’tiâˆ’1)
and show that
(Nti âˆ’Ntiâˆ’1)i=1,...,m is independent
(5.18)
and
Nti âˆ’Ntiâˆ’1 âˆ¼PoiÎ»i
for all i = 1, . . . , m.
(5.19)

5.5
The Poisson Process
143
This is equivalent to showing that for each choice of k1, . . . , km âˆˆN0, we have
P
)
Nti âˆ’Ntiâˆ’1 = ki for any i = 1, . . . , m
*
=
m

i=1

eâˆ’Î»i Î»ki
i
ki!

.
(5.20)
Write
Mn,i := #
	
l â‰¤n : tiâˆ’1 < Xl â‰¤ti

=
n

l=1
1(tiâˆ’1,ti](Xl).
By Exercise 2.2.3, the vector (Mn,1, . . . , Mn,m) is multinomially distributed with
parameters n and p = (p1, . . . , pm). That is, if we assume n := k1 + . . .+ km, then
P
)
Mn,1 = k1, . . . , Mn,m = km
*
=
n!
k1! Â· Â· Â· km! pk1
1 Â· Â· Â· pkm
m .
In order to show (5.20), note that the event in (5.20) implies L = n and that L and
(Mn,1, . . . , Mn,m) are independent. Hence we have
P
)
Nti âˆ’Ntiâˆ’1 = ki for i = 1, . . . , m
*
= P
)
{Nti âˆ’Ntiâˆ’1 = ki for i = 1, . . . , m} âˆ©{L = n}
*
= P){Mn,1 = k1, . . . , Mn,m = km} âˆ©{L = n}*
= P
)
Mn,1 = k1, . . . , Mn,m = km
*
Â· P[L = n]
=
n!
k1! Â· Â· Â· km! pk1
1 Â· Â· Â· pkm
m eâˆ’Î± Î±n
n!
=
m

i=1

eâˆ’Î»i Î»ki
i
ki!

.
âŠ“âŠ”
We close this section by presenting a further, rather elementary and instructive con-
struction of the Poisson process based on specifying the waiting times between the
clicks of the Geiger counter, or, more formally, between the points of discontinuity
of the map t â†’Nt(Ï‰). At time s, what is the probability that we have to wait
another t time units (or longer) for the next click? Since we modeled the clicks as a
Poisson process with intensity Î±, this probability can easily be computed:
P
)
N(s,s+t] = 0
*
= eâˆ’Î±t.
Hence the waiting time for the next click is exponentially distributed with parameter
Î±. Furthermore, the waiting times should be independent. We now take the waiting
times as the starting point and, based on them, construct the Poisson process.

144
5
Moments and Laws of Large Numbers
Let W1, W2, . . . be an independent family of exponentially distributed random
variables with parameter Î± > 0; hence P[Wn > x] = eâˆ’Î±x. We deï¬ne
Tn :=
n

k=1
Wk
and interpret Wn as the waiting time between the (n âˆ’1)th click and the nth click.
Tn is the time of the nth click. Appealing to this intuition we deï¬ne the number of
clicks until time t by
Nt := #{n âˆˆN0 : Tn â‰¤t}.
Hence
{Nt = k} = {Tk â‰¤t < Tk+1}.
In particular, Nt is a random variable; that is, measurable.
Theorem 5.36 The family (Nt, t â‰¥0) is a Poisson process with intensity Î±.
Proof (We follow the proof in [59, Theorem 3.34]) We must show that for any
n âˆˆN and any sequence 0 = t0 < t1 < . . . < tn, we have that (Nti âˆ’Ntiâˆ’1, i =
1, . . . , n) is independent and Nti âˆ’Ntiâˆ’1 âˆ¼PoiÎ±(tiâˆ’tiâˆ’1). We are well aware that
it is not enough to show this for the case n = 2 only. However, the notational
complications become overwhelming for n â‰¥3, and the idea for general n âˆˆN
becomes clear in the case n = 2. Hence we restrict ourselves to the case n = 2.
Hence we show for 0 < s < t and l, k âˆˆN0 that
P[Ns = k, Nt âˆ’Ns = l] =

eâˆ’Î±s (Î±s)k
k!
 
eâˆ’Î±(tâˆ’s)(Î±(t âˆ’s))l
l!

.
(5.21)
This implies that Ns and (Nt âˆ’Ns) are independent. Furthermore, by summing over
k âˆˆN0, this yields Nt âˆ’Ns âˆ¼PoiÎ±(tâˆ’s).
By Corollary 2.22, the distribution P(W1,...,Wk+l+1) has the density
x â†’Î±k+l+1 eâˆ’Î±Sk+l+1(x),
where Sn(x) := x1 + . . . + xn. It is sufï¬cient to consider l â‰¥1 since we get the
l = 0 term from the fact that the probability measure has total mass one. Hence, let
l â‰¥1. We compute
P[Ns = k, Nt âˆ’Ns = l] = P[Tk â‰¤s < Tk+1, Tk+l â‰¤t < Tk+l+1]
=
 âˆ
0
Â· Â· Â·
 âˆ
0
dx1 Â· Â· Â· dxk+l+1
Î±k+l+1 eâˆ’Î±Sk+l+1(x) 1{Sk(x)â‰¤s<Sk+1(x)} 1{Sk+l(x)â‰¤t<Sk+l+1(x)}.

5.5
The Poisson Process
145
Starting with xk+l+1, we integrate successively. In the ï¬rst step, substitute z =
Sk+l+1(x) to obtain
 âˆ
0
dxk+l+1 Î± eâˆ’Î±Sk+l+1(x) 1{Sk+l+1(x)>t} =
 âˆ
t
dz Î± eâˆ’Î±z = eâˆ’Î±t.
Now keep x1, . . . , xk ï¬xed and substitute for the remaining variables by letting y1 =
Sk+1(x) âˆ’s, y2 = xk+2, . . . , yl = xk+l to obtain
 âˆ
0
Â· Â· Â·
 âˆ
0
dxk+1 Â· Â· Â· dxk+l 1{s<Sk+1(x)â‰¤Sk+lâ‰¤t}
=
 âˆ
0
Â· Â· Â·
 âˆ
0
dy1 Â· Â· Â· dyl 1{y1+...+ylâ‰¤tâˆ’s} = (t âˆ’s)l
l!
.
(The last identity can be obtained, for example, by induction on l.) Now integrate
the remaining variables x1, . . . , xk to get
 âˆ
0
Â· Â· Â·
 âˆ
0
dx1 Â· Â· Â· dxk 1{Sk(x)â‰¤s} = sk
k! .
In total, we have
P[Ns = k, Nt âˆ’Ns = l] = eâˆ’Î±t Î±k+l sk
k!
(t âˆ’s)l
l!
;
hence (5.21) holds.
âŠ“âŠ”
Takeaways Assume that events, e.g. radioactive decays, happen at probabil-
ity â‰ˆÎ± Â·(b âˆ’a) (for some Î± > 0) in a small time interval (a, b]. Also assume
that the events in disjoints intervals come independently. Then the waiting
times between events are exponentially distributed with parameter Î± and the
total number of events up to time t is described by a Poisson process.
Exercise 5.5.1 Let Ln, Xn
k , k, n âˆˆN be independent random variables with Ln âˆ¼
PoiÎ± and Xn
k âˆ¼U(nâˆ’1,n] (the uniform distribution on (n âˆ’1, n]) for all k, n âˆˆN.
Deï¬ne
Nt := #
	
(k, n) âˆˆN2 : k â‰¤Ln and Xn
k â‰¤t

.
Show that (Nt)tâ‰¥0 is a Poisson process with intensity Î±. â™£

146
5
Moments and Laws of Large Numbers
Exercise 5.5.2 Let T > 0 and let X1, X2, . . . be i.i.d. random variables that are
uniformly distributed on [0, 1]. Let
N := max
	
n âˆˆN0 : X1 + . . . + Xn â‰¤T

and compute E[N]. â™£

Chapter 6
Convergence Theorems
In the strong and the weak laws of large numbers, we implicitly introduced the
notions of almost sure convergence and convergence in probability of random
variables. We saw that almost sure convergence implies convergence in mea-
sure/probability. This chapter is devoted to a systematic treatment of almost sure
convergence, convergence in measure and convergence of integrals. The key role
for connecting convergence in measure and convergence of integrals is played by
the concept of uniform integrability.
6.1
Almost Sure and Measure Convergence
In the following, (Î©, A, Î¼) will be a Ïƒ-ï¬nite measure space. We ï¬rst deï¬ne
in metric spaces almost sure convergence and convergence in measure and then
compare both concepts. To this end, we need two lemmas that ensure that the
distance function associated with two measurable maps is again measurable. In
the following, let (E, d) be a separable metric space with Borel Ïƒ-algebra B(E).
â€œSeparableâ€ means that there exists a countable dense subset. For x âˆˆE and r > 0,
denote by Br(x) = {y âˆˆE : d(x, y) < r} the ball with radius r centered at x.
Lemma 6.1 Let f, g : Î© â†’E be measurable with respect to A â€“ B(E). Then the
map H : Î© â†’[0, âˆ), Ï‰ â†’d(f (Ï‰), g(Ï‰)) is A â€“ B([0, âˆ))-measurable.
Proof Let F âŠ‚E be countable and dense. By the triangle inequality, d(x, z) +
d(z, y) â‰¥d(x, y) for all x, y âˆˆE and z âˆˆF. Let (zn)nâˆˆN be a sequence in F
with zn
nâ†’âˆ
âˆ’â†’x. Since d is continuous, we have d(x, zn) + d(zn, y)
nâ†’âˆ
âˆ’â†’d(x, y).
Putting things together, we infer infzâˆˆF(d(x, z) + d(z, y)) = d(x, y). Since x â†’
d(x, z) is continuous and hence measurable, the maps fz, gz : Î© â†’[0, âˆ) with
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_6
147

148
6
Convergence Theorems
fz(Ï‰) = d(f (Ï‰), z) and gz(Ï‰) = d(g(Ï‰), z) are also measurable. Thus fz +gz and
H = infzâˆˆF(fz + gz) are measurable.
(A somewhat more systematic proof is based on the fact that (f, g) is A â€“ B(E Ã—
E)-measurable (this will follow from Theorem 14.8) and that d : E Ã— E â†’[0, âˆ)
is continuous and hence B(E Ã— E) â€“ B([0, âˆ))-measurable. As a composition of
measurable maps, Ï‰ â†’d(f (Ï‰), g(Ï‰)) is measurable.)
âŠ“âŠ”
Let f, f1, f2, . . . : Î© â†’E be measurable with respect to A â€“ B(E).
Deï¬nition 6.2 We say that (fn)nâˆˆN converges to f
(i) in Î¼-measure (or, brieï¬‚y, in measure), symbolically fn
meas
âˆ’â†’f , if
Î¼({d(f, fn) > Îµ} âˆ©A)
nâ†’âˆ
âˆ’â†’0
for all Îµ > 0 and all A âˆˆA with Î¼(A) < âˆ, and
(ii) Î¼-almost everywhere (a.e.), symbolically fn
a.e.
âˆ’â†’f , if there exists a Î¼-null
set N âˆˆA such that
d(f (Ï‰), fn(Ï‰))
nâ†’âˆ
âˆ’â†’0
for any Ï‰ âˆˆÎ© \ N.
If Î¼ is a probability measure, then convergence in Î¼-measure is also called
convergence in probability. If (fn)nâˆˆN converges a.e., then we also say that
(fn)nâˆˆN converges almost surely (a.s.) and write fn
a.s.
âˆ’â†’f . Sometimes we
will drop the qualiï¬cations â€œ almost everywhereâ€ and â€œ almost surely â€.
Remark 6.3 Let A1, A2, . . . âˆˆA with An â†‘Î© and Î¼(An) < âˆfor any n âˆˆN.
Then a.e. convergence is equivalent to a.e. convergence on each An. â™¦
Remark 6.4 Almost everywhere convergence implies convergence in measure: For
Îµ > 0, deï¬ne
Dn(Îµ) =
	
d(f, fm) > Îµ for some m â‰¥n

.
Then D(Îµ) := âˆ
n=1 Dn(Îµ) âŠ‚N, where N is the null set from the deï¬nition of
almost everywhere convergence. Upper semicontinuity of Î¼ implies
Î¼

Dn(Îµ) âˆ©A

nâ†’âˆ
âˆ’â†’Î¼

D(Îµ) âˆ©A

= 0
for any A âˆˆA with Î¼(A) < âˆ. â™¦
Remark 6.5 Almost everywhere convergence and convergence in measure deter-
mine the limit up to equality almost everywhere. Indeed, let fn
meas
âˆ’â†’f and
fn
meas
âˆ’â†’g. Let A1, A2, . . . âˆˆA with An â†‘Î© and Î¼(An) < âˆfor any n âˆˆN.

6.1
Almost Sure and Measure Convergence
149
Then (since d(f, g) â‰¤d(f, fn) + d(g, fn)), for any m âˆˆN and Îµ > 0,
Î¼Am âˆ©{d(f, g) > Îµ}
â‰¤Î¼

Am âˆ©{d(f, fn) > Îµ/2}

+ Î¼

Am âˆ©{d(g, fn) > Îµ/2}
 nâ†’âˆ
âˆ’â†’0.
Hence Î¼

{d(f, g) > 0}

= 0. â™¦
Reï¬‚ection Maybe it comes as a surprise that in the deï¬nition of stochastic conver-
gence, the set A of ï¬nite measure pops up. It is used to localise the convergence.
Consider the case Î© = R, Î¼ the Lebesgue measure and fn := 1[n,n+1], f â‰¡0.
With our deï¬nition of stochastic convergence we have fn
meas
âˆ’â†’f . However, if we
do not intersect with the set A, then stochastic convergence would fail, although
we still had fn
a.e.
âˆ’â†’f . Hence convergence almost everywhere would not imply
stochastic convergence. Now this causes trouble in many places and so we chose a
deï¬nition where this implication holds. â™ 
Remark 6.6 In general, convergence in measure does not imply almost everywhere
convergence. Indeed, let (Xn)nâˆˆN be an independent family of random variables
with Xn âˆ¼Ber1/n. Then Xn
nâ†’âˆ
âˆ’â†’0 in probability but the Borelâ€“Cantelli lemma
implies lim supnâ†’âˆXn = 1 almost surely. â™¦
Theorem 6.7 Let A1, A2, . . . âˆˆA with AN â†‘Î© and Î¼(AN) < âˆfor all N âˆˆN.
For measurable f, g : Î© â†’E, let
Ëœd(f, g) :=
âˆ

N=1
2âˆ’N
1 + Î¼(AN)

AN

1 âˆ§d(f (Ï‰), g(Ï‰))

Î¼(dÏ‰).
(6.1)
Then Ëœd is a metric that induces convergence in measure: If f, f1, f2, . . . are
measurable, then
fn
meas
âˆ’â†’f
â‡â‡’
Ëœd(f, fn)
nâ†’âˆ
âˆ’â†’0.
Proof For N âˆˆN, deï¬ne
ËœdN(f, g) :=

AN

1 âˆ§d(f (Ï‰), g(Ï‰))

Î¼(dÏ‰).
Then Ëœd(f, fn)
nâ†’âˆ
âˆ’â†’0 if and only if ËœdN(f, fn)
nâ†’âˆ
âˆ’â†’0 for all N âˆˆN.
â€œ â‡’â€
Assume fn
meas
âˆ’â†’f . Then, for any Îµ âˆˆ(0, 1),
ËœdN(f, fn) â‰¤Î¼

AN âˆ©{d(f, fn) > Îµ}

+ Îµ Î¼(AN)
nâ†’âˆ
âˆ’â†’Îµ Î¼(AN).
Letting Îµ â†“0 yields ËœdN(f, fn)
nâ†’âˆ
âˆ’â†’0.

150
6
Convergence Theorems
â€œ â‡ â€
Assume Ëœd(f, fn)
nâ†’âˆ
âˆ’â†’0. Let B âˆˆA with Î¼(B) < âˆ. Fix Î´ > 0 and
choose N âˆˆN large enough that Î¼(B \ AN) < Î´. Then, for Îµ âˆˆ(0, 1),
Î¼

B âˆ©{d(f, fn) > Îµ}

â‰¤Î´ + Î¼

AN âˆ©{d(f, fn) > Îµ}

â‰¤Î´ + Îµâˆ’1 ËœdN(f, fn)
nâ†’âˆ
âˆ’â†’Î´.
Letting Î´ â†“0 yields Î¼

B âˆ©{d(f, fn) > Îµ}
 nâ†’âˆ
âˆ’â†’0; hence fn
meas
âˆ’â†’f .
âŠ“âŠ”
Consider the most prominent case E = R equipped with the Euclidean metric.
Here the integral is the basis for another concept of convergence.
Deï¬nition 6.8 (Mean convergence) Let f, f1, f2, . . . âˆˆL1(Î¼). We say that the
sequence (fn)nâˆˆN converges in mean to f , symbolically
fn
L1
âˆ’â†’f,
if âˆ¥fn âˆ’f âˆ¥1
nâ†’âˆ
âˆ’â†’0.
Remark 6.9 If fn
L1
âˆ’â†’f , then in particular
3
fn dÎ¼
nâ†’âˆ
âˆ’â†’
3
f dÎ¼. â™¦
Remark 6.10 If fn
L1
âˆ’â†’f and fn
L1
âˆ’â†’g, then f = g almost everywhere. Indeed,
by the triangle inequality, âˆ¥f âˆ’gâˆ¥1 â‰¤âˆ¥fn âˆ’f âˆ¥1 + âˆ¥fn âˆ’gâˆ¥1
nâ†’âˆ
âˆ’â†’0. â™¦
Remark 6.11 Both L1-convergence and almost everywhere convergence imply
convergence in measure. All other implications are incorrect in general. â™¦
Theorem 6.12 (Fast convergence) Let (E, d) be a separable metric space. In
order for the sequence (fn)nâˆˆN of measurable maps Î© â†’E to converge almost
everywhere, it is sufï¬cient that one of the following conditions holds.
(i) E = R and there is a p âˆˆ[1, âˆ) with fn âˆˆLp(Î¼) for all n âˆˆN and there is
an f âˆˆLp(Î¼) with
âˆ

n=1
âˆ¥fn âˆ’f âˆ¥p
p < âˆ.
(ii) There is a measurable f with
âˆ

n=1
Î¼(A âˆ©{d(f, fn) > Îµ}) < âˆfor all Îµ > 0
and for all A âˆˆA with Î¼(A) < âˆ.
In both cases, we have fn
nâ†’âˆ
âˆ’â†’f almost everywhere.
(iii) E is complete and there is a summable sequence (Îµn)nâˆˆN such that
âˆ

n=1
Î¼(A âˆ©{d(fn, fn+1) > Îµn}) < âˆ
for all A âˆˆA with Î¼(A) < âˆ.

6.1
Almost Sure and Measure Convergence
151
Proof Clearly, condition (i) implies (ii) since Markovâ€™s inequality yields that
Î¼({|f âˆ’fn| > Îµ}) â‰¤Îµâˆ’p âˆ¥f âˆ’fnâˆ¥p
p.
By Remark 6.3, it is enough to consider the case Î¼(Î©) < âˆ.
Assume (ii). Let Bn(Îµ) = {d(f, fn) > Îµ} and B(Îµ) = lim sup
nâ†’âˆ
Bn(Îµ). By the
Borelâ€“Cantelli lemma, Î¼(B(Îµ)) = 0. Let N = âˆ
n=1 B (1/n). Then Î¼(N) = 0 and
fn(Ï‰)
nâ†’âˆ
âˆ’â†’f (Ï‰)
for any Ï‰ âˆˆÎ© \ N.
Assume (iii). Let Bn = {d(fn, fn+1) > Îµn} and B = lim sup
nâ†’âˆ
Bn. Then Î¼(B) = 0
and (fn(Ï‰))nâˆˆN is a Cauchy sequence in E for any Ï‰ âˆˆÎ© \B. Since E is complete,
the limit f (Ï‰) := limnâ†’âˆfn(Ï‰) exists. For Ï‰ âˆˆB, deï¬ne f (Ï‰) = 0.
âŠ“âŠ”
Corollary 6.13 Let (E, d) be a separable metric space. Let f, f1, f2, . . . be
measurable maps Î© â†’E. Then the following statements are equivalent.
(i) fn
nâ†’âˆ
âˆ’â†’f in measure.
(ii) For any subsequence of (fn)nâˆˆN, there exists a sub-subsequence that converges
to f almost everywhere.
Proof â€œ(ii) â‡’(i)â€
Assume that (i) does not hold. Let Ëœd be a metric that induces
convergence in measure (see Theorem 6.7). Then there exists an Îµ > 0 and a
subsequence (fnk)kâˆˆN with Ëœd(fnk, f ) > Îµ for all k âˆˆN. Clearly, no subsequence of
(fnk)kâˆˆN converges to f in measure; hence neither converges almost everywhere.
â€œ(i) â‡’(ii)â€
Now assume (i). Let A1, A2, . . . âˆˆA with AN â†‘Î© and Î¼(AN) <
âˆfor any N âˆˆN. Since fnk
meas
âˆ’â†’f for k â†’âˆ, we can choose a subsequence
(fnkl )lâˆˆN such that Î¼

Al âˆ©

d

f, fnkl

> 1/l

< 2âˆ’l for any l âˆˆN. Hence, for
each N âˆˆN, we have
âˆ

l=1
Î¼

AN âˆ©

df, fnkl
 > 1
l

â‰¤N Î¼(AN) +
âˆ

l=N+1
2âˆ’l < âˆ.
By Theorem 6.12(ii), (fnkl )lâˆˆN converges to f almost everywhere on AN. By
Remark 6.3, (fnkl )lâˆˆN converges to f almost everywhere.
âŠ“âŠ”
Corollary 6.14 Let (Î©, A, Î¼) be a measure space in which almost everywhere
convergence and convergence in measure do not coincide. Then there does not exist
a topology on the set of measurable maps Î© â†’E that induces almost everywhere
convergence.
Proof Assume that there does exist a topology that induces almost everywhere
convergence. Let f, f1, f2, . . . be measurable maps with the property that fn
meas
âˆ’â†’
f , but not fn
nâ†’âˆ
âˆ’â†’f almost everywhere. Now let U be an open set that contains f ,
but with fn Ì¸âˆˆU for inï¬nitely many n âˆˆN. Hence, let (fnk)kâˆˆN be a subsequence
with fnk Ì¸âˆˆU for all k âˆˆN. Since fnk
kâ†’âˆ
âˆ’â†’f in measure, by Corollary 6.13,
there exists a further subsequence (fnkl )lâˆˆN of (fnk)kâˆˆN with fnkl
lâ†’âˆ
âˆ’â†’f almost

152
6
Convergence Theorems
everywhere. However, then fnkl âˆˆU for all but ï¬nitely many l, which yields a
contradiction!
âŠ“âŠ”
Corollary 6.15 Let (E, d) be a separable complete metric space. Let (fn)nâˆˆN be a
Cauchy sequence in measure in E; that is, for any A âˆˆA with Î¼(A) < âˆand any
Îµ > 0, we have
Î¼A âˆ©{d(fm, fn) > Îµ} âˆ’â†’0
for m, n â†’âˆ.
Then (fn)nâˆˆN converges in measure.
Proof Without loss of generality, we may assume Î¼(Î©) < âˆ. Choose a subse-
quence (fnk)kâˆˆN such that
Î¼
	
d(fn, fnk) > 2âˆ’k

< 2âˆ’k
for all n â‰¥nk.
By Theorem 6.12(iii), there is an f with fnk
kâ†’âˆ
âˆ’â†’f almost everywhere; hence, in
particular, Î¼({d(fnk, f ) > Îµ/2})
kâ†’âˆ
âˆ’â†’0 for all Îµ > 0. Now
Î¼({d(fn, f ) > Îµ}) â‰¤Î¼({d(fnk, fn) > Îµ/2}) + Î¼({d(fnk, f ) > Îµ/2}).
If k is large enough that 2âˆ’k < Îµ/2 and if n â‰¥nk, then the ï¬rst summand is smaller
than 2âˆ’k. Hence we have Î¼({d(fn, f ) > Îµ})
nâ†’âˆ
âˆ’â†’0; that is, fn
meas
âˆ’â†’f .
âŠ“âŠ”
Takeaways Almost everywhere (almost sure) convergence implies stochas-
tic convergence. Also L1-convergence implies stochastic convergence. The
opposite implications hold only under an additional condition of summability
(see Theorem 6.12).
Exercise 6.1.1 Let Î© be countable. Show that convergence in probability implies
almost everywhere convergence. â™£
Exercise 6.1.2 Give an example of a sequence that
(i) converges in L1 but not almost everywhere,
(ii) converges almost everywhere but not in L1. â™£
Exercise 6.1.3 (Egorovâ€™s theorem (1911))
Let (Î©, A, Î¼) be a ï¬nite measure
space and let f1, f2, . . . be measurable functions that converge to some f almost
everywhere. Show that, for every Îµ > 0, there is a set A âˆˆA with Î¼(Î© \ A) < Îµ
and supÏ‰âˆˆA |fn(Ï‰) âˆ’f (Ï‰)|
nâ†’âˆ
âˆ’â†’0. â™£

6.2
Uniform Integrability
153
Exercise 6.1.4 Let (Xi)iâˆˆN be independent, square integrable random variables
with E[Xi] = 0 for all i âˆˆN.
(i) Show that âˆ
i=1 Var[Xi] < âˆimplies that there exists a real random variable
X with n
i=1 Xi
nâ†’âˆ
âˆ’â†’X almost surely.
(ii) Does the converse implication hold in (i)? â™£
6.2
Uniform Integrability
From the preceding section, we can conclude that convergence in measure plus
existence of L1 limit points implies L1-convergence.Hence convergence in measure
plus relative sequential compactness in L1 yields convergence in L1. In this section,
we study a criterion for relative sequential compactness in L1, the so-called uniform
integrability.
Deï¬nition 6.16 A family F âŠ‚L1(Î¼) is called uniformly integrable if
inf
0â‰¤gâˆˆL1(Î¼) sup
f âˆˆF
 
|f | âˆ’g
+ dÎ¼ = 0.
(6.2)
Theorem 6.17 The family F âŠ‚L1(Î¼) is uniformly integrable if and only if
inf
0â‰¤g âˆˆL1(Î¼)
sup
f âˆˆF

{|f |>g}
|f | dÎ¼ = 0.
(6.3)
If Î¼(Î©) < âˆ, then uniform integrability is equivalent to either of the following two
conditions:
(i)
inf
aâˆˆ[0,âˆ) sup
f âˆˆF

(|f | âˆ’a)+ dÎ¼ = 0,
(ii)
inf
aâˆˆ[0,âˆ) sup
f âˆˆF

{|f |>a}
|f | dÎ¼ = 0.
Proof Clearly, (|f |âˆ’g)+ â‰¤|f |Â·1{|f |>g}; hence (6.3) implies uniform integrability.
Now assume (6.2). For Îµ > 0, choose gÎµ âˆˆL1(Î¼) such that
sup
f âˆˆF

(|f | âˆ’gÎµ)+ dÎ¼ â‰¤Îµ.
(6.4)
Deï¬ne 
gÎµ = 2gÎµ/2. Then, for f âˆˆF,

{|f |>
gÎµ}
|f | dÎ¼ â‰¤

{|f |>
gÎµ}
(|f | âˆ’gÎµ/2)+ dÎ¼ +

{|f |>
gÎµ}
gÎµ/2 dÎ¼.

154
6
Convergence Theorems
By construction,
3
{|f |>
gÎµ}(|f | âˆ’gÎµ/2)+ dÎ¼ â‰¤Îµ/2 and
gÎµ/2 1{|f |>
gÎµ} â‰¤

|f | âˆ’gÎµ/2
+ 1{|f |>
gÎµ};
hence also

{|f |>
gÎµ}
gÎµ/2 dÎ¼ â‰¤

{|f |>
gÎµ}
(|f | âˆ’gÎµ/2)+ dÎ¼ â‰¤Îµ
2.
Summing up, we have
sup
f âˆˆF

{|f |>
gÎµ}
|f | dÎ¼ â‰¤Îµ.
(6.5)
Clearly, (ii) implies (i). If Î¼(Î©) < âˆ, then (i) implies uniform integrability of F
since the inï¬mum is taken over the smaller set of constant functions. We still have
to show that uniform integrability implies (ii). Accordingly, assume F is uniformly
integrable (but not necessarily Î¼(Î©) < âˆ). For any Îµ > 0 (and gÎµ and ËœgÎµ as above),
choose aÎµ such that
3
{gÎµ/2>aÎµ} gÎµ/2 dÎ¼ < Îµ
2. Then

{|f |>aÎµ}
|f | dÎ¼ â‰¤

{|f |>gÎµ/2}
|f | dÎ¼ +

{gÎµ/2>aÎµ}
gÎµ/2 dÎ¼ < Îµ.
âŠ“âŠ”
Theorem 6.18
(i) If F âŠ‚L1(Î¼) is a ï¬nite set, then F is uniformly integrable.
(ii) If F, G âŠ‚L1(Î¼) are uniformly integrable, then (f + g :
f âˆˆF, g âˆˆG),
(f âˆ’g : f âˆˆF, g âˆˆG) and {|f | : f âˆˆF} are also uniformly integrable.
(iii) If F is uniformly integrable and if, for any g âˆˆG, there exists an f âˆˆF with
|g| â‰¤|f |, then G is also uniformly integrable.
Proof The proof is simple and is left as an exercise.
âŠ“âŠ”
The following theorem describes a very useful criterion for uniform integrability.
We will use it in many places.
Theorem 6.19 For ï¬nite Î¼, F âŠ‚L1(Î¼) is uniformly integrable if and only if there
is a measurable function H : [0, âˆ) â†’[0, âˆ) with limxâ†’âˆH(x)/x = âˆand
sup
f âˆˆF

H(|f |) dÎ¼ < âˆ.
H can be chosen to be monotone increasing and convex.

6.2
Uniform Integrability
155
Proof â€œ â‡ â€
Assume there is an H with the advertised properties. Then Ka :=
infxâ‰¥a H(x)
x
â†‘âˆif a â†‘âˆ. Hence, for a > 0,
sup
f âˆˆF

{|f |â‰¥a}
|f | dÎ¼ â‰¤1
Ka
sup
f âˆˆF

{|f |â‰¥a}
H(|f |) dÎ¼
â‰¤1
Ka
sup
f âˆˆF

H (|f |) dÎ¼
aâ†’âˆ
âˆ’â†’0.
â€œ â‡’â€
Assume F is uniformly integrable. As we have Î¼(Î©) <
âˆ, by
Theorem 6.17, there exists a sequence an â†‘âˆwith
sup
f âˆˆF

(|f | âˆ’an)+ dÎ¼ < 2âˆ’n.
Deï¬ne
H(x) =
âˆ

n=1
(x âˆ’an)+
for any x â‰¥0.
As a sum of convex functions, H is convex. Further, for any n âˆˆN and x â‰¥2an,
H(x)/x â‰¥n
k=1(1 âˆ’ak/x)+ â‰¥n/2; hence we have H(x)/x â†‘âˆ. Finally, by
monotone convergence, for any f âˆˆF,

H(|f (Ï‰)|) Î¼(dÏ‰) =
âˆ

n=1

(|f | âˆ’an)+ dÎ¼ â‰¤
âˆ

n=1
2âˆ’n = 1.
âŠ“âŠ”
Reï¬‚ection In the above theorem, why did we need that Î¼ is ï¬nite? Can you come
up with a counterexample for the case Î¼(Î©) = âˆ? Which part of the theorem
would still hold? â™ 
Recall the notation âˆ¥Â· âˆ¥p from Deï¬nition 4.16.
Deï¬nition 6.20 Let p âˆˆ[1, âˆ]. A family F âŠ‚Lp(Î¼) is called bounded in Lp(Î¼)
if sup{âˆ¥f âˆ¥p : f âˆˆF} < âˆ.
Corollary 6.21 Let Î¼(Î©) < âˆand p > 1. If F is bounded in Lp(Î¼), then F is
uniformly integrable.
Proof Apply Theorem 6.19 with the convex map H(x) = xp.
âŠ“âŠ”
Corollary 6.22 If (Xi)iâˆˆI is a family of square integrable random variables with
sup{|E[Xi]| : i âˆˆI} < âˆ
and
sup{Var[Xi] : i âˆˆI} < âˆ,
then (Xi)iâˆˆI is uniformly integrable.

156
6
Convergence Theorems
Proof Since E[X2
i ] = E[Xi]2 + Var[Xi], i âˆˆI, is bounded, this follows from
Corollary 6.21 with p = 2.
âŠ“âŠ”
Lemma 6.23 There is a map h âˆˆL1(Î¼) with h > 0 almost everywhere.
Proof Let A1, A2, . . . , âˆˆA with An â†‘Î© and Î¼(An) < âˆfor all n âˆˆN. Deï¬ne
h =
âˆ

n=1
2âˆ’n
1 + Î¼(An))âˆ’1 1An.
Then h > 0 almost everywhere and
3
h dÎ¼ =
âˆ

n=1
2âˆ’n
Î¼(An)
1+Î¼(An) â‰¤1.
âŠ“âŠ”
Theorem 6.24 A family F âŠ‚L1(Î¼) is uniformly integrable if and only if the
following two conditions are fulï¬lled.
(i) C := sup
f âˆˆF

|f | dÎ¼ < âˆ.
(ii) There is a function 0 â‰¤h âˆˆL1(Î¼) such that for any Îµ > 0, there is a Î´(Îµ) > 0
with
sup
f âˆˆF

A
|f | dÎ¼ â‰¤Îµ
for all A âˆˆA such that

A
h dÎ¼ < Î´(Îµ).
If Î¼(Î©) < âˆ, then (ii) is equivalent to (iii):
(iii) For all Îµ > 0, there is a Î´(Îµ) > 0 such that
sup
f âˆˆF

A
|f | dÎ¼ â‰¤Îµ
for all A âˆˆA with Î¼(A) < Î´(Îµ).
Proof â€œ â‡’â€
Let F be uniformly integrable. Let h âˆˆL1(Î¼) with h > 0 a.e. Let
Îµ > 0 and let gÎµ/3 be an Îµ/3-bound for F (as in (6.5)). Since
	
gÎµ/3 â‰¥Î±h

â†“âˆ…for
Î± â†’âˆ, for sufï¬ciently large Î± = Î±(Îµ), we have

{gÎµ/3â‰¥Î±h}
gÎµ/3 dÎ¼ < Îµ
3.
Letting Î´(Îµ) :=
Îµ
3Î±(Îµ), we get for any A âˆˆA with
3
A h dÎ¼ < Î´(Îµ) and any f âˆˆF,

A
|f | dÎ¼ â‰¤

{|f |>gÎµ/3}
|f | dÎ¼ +

A
gÎµ/3 dÎ¼
â‰¤Îµ
3 + Î±

A
h dÎ¼ +

{gÎµ/3â‰¥Î±h}
gÎµ/3 dÎ¼ â‰¤Îµ.

6.2
Uniform Integrability
157
Hence we have shown (ii). In the above computation, let A = Î© to obtain

|f | dÎ¼ â‰¤2Îµ
3 + Î±

h dÎ¼ < âˆ.
Hence we have also shown (i).
â€œ â‡ â€
Assume (i) and (ii). Let Îµ > 0. Choose h and Î´(Îµ) > 0 as in (ii) and C as
in (i). Deï¬ne h =
C
Î´(Îµ)h. Then

{|f |>h}
h dÎ¼ = Î´(Îµ)
C

{|f |>h}
h dÎ¼ â‰¤Î´(Îµ)
C

|f | dÎ¼ â‰¤Î´(Îµ);
hence, by assumption,
3
{|f |>h} |f | dÎ¼ < Îµ.
â€œ(ii) â‡’(iii)â€
Assume (ii). Let Îµ > 0 and choose Î´ = Î´(Îµ) as in (ii). Choose
K < âˆlarge enough that
3
{hâ‰¥K} h dÎ¼ < Î´/2. For all A âˆˆA with Î¼(A) < Î´/(2K),
we obtain

A
h dÎ¼ â‰¤KÎ¼(A) +

{hâ‰¥K}
h dÎ¼ < Î´;
hence
3
A |f | dÎ¼ â‰¤Îµ for all f âˆˆF.
â€œ(iii) â‡’(ii)â€
Assume (iii) and Î¼(Î©) < âˆ. Then h â‰¡1 serves the purpose.
âŠ“âŠ”
We come to the main theorem of this section.
Theorem 6.25 Let {fn
:
n âˆˆN} âŠ‚L1(Î¼). The following statements are
equivalent.
(i) There is an f âˆˆL1(Î¼) with fn
nâ†’âˆ
âˆ’â†’f in L1.
(ii) (fn)nâˆˆN is an L1(Î¼)-Cauchy sequence; that is, âˆ¥fnâˆ’fmâˆ¥1 âˆ’â†’0 for m, n â†’
âˆ.
(iii) (fn)nâˆˆN is uniformly integrable and there is a measurable map f such that
fn
meas
âˆ’â†’f .
The limits in (i) and (iii) coincide.
Proof â€œ(i) â‡’(ii)â€
This is evident.
â€œ(ii) â‡’(iii)â€
For any Îµ > 0, there is an nÎµ âˆˆN such that âˆ¥fn âˆ’fnÎµâˆ¥1 < Îµ
for all n â‰¥nÎµ. Hence âˆ¥(|fn| âˆ’|fnÎµ|)+âˆ¥1 < Îµ for all n â‰¥nÎµ. Thus gÎµ =
max{|f1|, . . . , |fnÎµ|} is an Îµ-bound for (fn)nâˆˆN (as in (6.4)). For Îµ > 0, let
Î¼

{|fm âˆ’fn| > Îµ}

â‰¤Îµâˆ’1 âˆ¥fm âˆ’fnâˆ¥1 âˆ’â†’0
for m, n â†’âˆ.
Thus (fn)nâˆˆN is also a Cauchy sequence in measure; hence it converges in measure
by Corollary 6.15.

158
6
Convergence Theorems
â€œ(iii) â‡’(i)â€
Let f be the limit in measure of the sequence (fn)nâˆˆN. Assume that
(fn)nâˆˆN does not converge to f in L1. Then there is an Îµ > 0 and a subsequence
(fnk)kâˆˆN with
âˆ¥f âˆ’fnkâˆ¥1 > 2Îµ
for all k âˆˆN.
(6.6)
Here we deï¬ne âˆ¥f âˆ’fnkâˆ¥1 = âˆif f Ì¸âˆˆL1(Î¼). By Corollary 6.13, there is a
subsequence (fnâ€²
k)kâˆˆN of (fnk)kâˆˆN with fnâ€²
k
kâ†’âˆ
âˆ’â†’f almost everywhere. By Fatouâ€™s
lemma (Theorem 4.21) with 0 as a minorant, we thus get

|f | dÎ¼ â‰¤lim inf
kâ†’âˆ

|fnâ€²
k| dÎ¼ < âˆ.
Hence f âˆˆL1(Î¼). By Theorem 6.18(ii) (with G = {f }), we obtain that the family
(f âˆ’fnâ€²
k)kâˆˆN is uniformly integrable; hence there is a 0 â‰¤g âˆˆL1(Î¼) such that
3
(|f âˆ’fnâ€²
k| âˆ’g)+ dÎ¼ < Îµ. Deï¬ne
gk = |fnâ€²
k âˆ’f | âˆ§g
for k âˆˆN.
Then gk
kâ†’âˆ
âˆ’â†’0 almost everywhere and g âˆ’gk â‰¥0. By Fatouâ€™s lemma,
lim sup
kâ†’âˆ

gk dÎ¼ =

g dÎ¼ âˆ’lim inf
kâ†’âˆ

(g âˆ’gk) dÎ¼
â‰¤

g dÎ¼ âˆ’
 
lim
kâ†’âˆ(g âˆ’gk)

dÎ¼ = 0.
Since |f âˆ’fnâ€²
k| = (|f âˆ’fnâ€²
k| âˆ’g)+ + gk, this implies that
lim sup
kâ†’âˆ
âˆ¥f âˆ’fnâ€²
kâˆ¥1 â‰¤lim sup
kâ†’âˆ
 
|f âˆ’fnâ€²
k| âˆ’g
+ dÎ¼ + lim sup
kâ†’âˆ

gk dÎ¼ â‰¤Îµ,
contradicting (6.6).
âŠ“âŠ”
Corollary 6.26 (Lebesgueâ€™s convergence theorem, dominated convergence) Let
f be measurable and let (fn)nâˆˆN be a sequence in L1(Î¼) with fn
nâ†’âˆ
âˆ’â†’
f
in
measure. Assume that there is an integrable dominating function 0 â‰¤g âˆˆL1(Î¼)
with |fn| â‰¤g almost everywhere for all n âˆˆN. Then f âˆˆL1(Î¼) and fn
nâ†’âˆ
âˆ’â†’f
in L1; hence in particular
3
fn dÎ¼
nâ†’âˆ
âˆ’â†’
3
f dÎ¼.
Proof This is a consequence of Theorem 6.25, as the dominating function ensures
uniform integrability of the sequence (fn)nâˆˆN.
âŠ“âŠ”

6.2
Uniform Integrability
159
Convergence
almost
everywhere
Stochastic
convergence
L1 convergence
subsequence
subsequence
uniform
integrability
uniform
integrability
Fig. 6.1 Implications between the concepts of convergence.
Takeaways Loosely speaking, a family of functions is uniformly integrable
if the main contributions to the integrals of those functions do not come from
extremely large values of the functions. Together with stochastic convergence,
uniform integrability is equivalent to L1-convergence (see Fig. 6.1). As a
consequence we get Lebesgueâ€™s dominated convergence theorem.
Exercise 6.2.1 Let H âˆˆL1(Î¼) with H > 0
Î¼-a.e. (see Lemma 6.23) and let
(E, d) be a separable metric space. For measurable f, g : Î© â†’E, deï¬ne
dH(f, g) :=
 1 âˆ§d(f (Ï‰), g(Ï‰)) H(Ï‰) Î¼(dÏ‰).
(i) Show that dH is a metric that induces convergence in measure.
(ii) Show that dH is complete if (E, d) is complete. â™£

160
6
Convergence Theorems
6.3
Exchanging Integral and Differentiation
We study how properties such as continuity and differentiability of functions of two
variables behave under integration with respect to one of the variables.
Theorem 6.27 (Continuity lemma) Let (E, d) be a metric space, x0 âˆˆE and let
f : Î© Ã— E â†’R be a map with the following properties.
(i) For any x âˆˆE, the map Ï‰ â†’f (Ï‰, x) is in L1(Î¼).
(ii) For almost all Ï‰ âˆˆÎ©, the map x â†’f (Ï‰, x) is continuous at the point x0.
(iii) There is a map h âˆˆL1(Î¼), h â‰¥0, such that |f ( Â·, x)| â‰¤h
Î¼-a.e. for all
x âˆˆE.
Then the map F : E â†’R, x â†’
3
f (Ï‰, x) Î¼(dÏ‰) is continuous at x0.
Proof Let (xn)nâˆˆN be a sequence in E with lim
nâ†’âˆxn = x0. Deï¬ne fn = f ( Â·, xn).
By assumption, |fn| â‰¤h and fn
nâ†’âˆ
âˆ’â†’
f ( Â·, x0) almost everywhere. By the
dominated convergence theorem (Corollary 6.26), we get
F(xn) =

fn dÎ¼
nâ†’âˆ
âˆ’â†’

f ( Â·, x0) dÎ¼ = F(x0).
Hence F is continuous at x0.
âŠ“âŠ”
Reï¬‚ection Find an example that shows that condition (iii) in Theorem 6.27 cannot
simply be dropped. â™ 
Theorem 6.28 (Differentiation lemma) Let I âŠ‚R be a nontrivial open interval
and let f : Î© Ã— I â†’R be a map with the following properties.
(i) For any x âˆˆE, the map Ï‰ â†’f (Ï‰, x) is in L1(Î¼).
(ii) For almost all Ï‰ âˆˆÎ©, the map I â†’R, x â†’f (Ï‰, x) is differentiable with
derivative f â€².
(iii) There is a map h âˆˆL1(Î¼), h â‰¥0, such that |f â€²( Â·, x)| â‰¤h Î¼-a.e. for all
x âˆˆI.
Then, for any x âˆˆI, f â€²( Â·, x) âˆˆL1(Î¼) and the function F : x â†’
3
f (Ï‰, x) Î¼(dÏ‰)
is differentiable with derivative
F â€²(x) =

f â€²(Ï‰, x) Î¼(dÏ‰).
Proof Let x0 âˆˆI and let (xn)nâˆˆN be a sequence in I with xn Ì¸= x0 for all n âˆˆN and
such that lim
nâ†’âˆxn = x0. We show that, along the sequence (xn)nâˆˆN, the difference
quotients converge. Deï¬ne
gn(Ï‰) = f (Ï‰, xn) âˆ’f (Ï‰, x0)
xn âˆ’x0
for all Ï‰ âˆˆÎ©.

6.3
Exchanging Integral and Differentiation
161
By assumption (ii), we have
gn
nâ†’âˆ
âˆ’â†’f â€²( Â·, x0)
Î¼-almost everywhere.
By the mean value theorem of calculus, for all n âˆˆN and for almost all Ï‰ âˆˆÎ©,
there exists a yn(Ï‰) âˆˆI with gn(Ï‰) = f â€²(Ï‰, yn(Ï‰)). In particular, |gn| â‰¤h almost
everywhere for all n âˆˆN. By the dominated convergence theorem (Corollary 6.26),
the limiting function f â€²( Â·, x0) is in L1(Î¼) and
lim
nâ†’âˆ
F(xn) âˆ’F(x0)
xn âˆ’x0
=
lim
nâ†’âˆ

gn(Ï‰) Î¼(dÏ‰) =

f â€²(Ï‰, x0) Î¼(dÏ‰).
âŠ“âŠ”
Example 6.29 (Laplace transform) Let X be a nonnegative random variable on
(Î©, A, P). Using the notation of Theorem 6.28, let I = [0, âˆ) and f (x, Î») = eâˆ’Î»x
for Î» âˆˆI. Then
F(Î») = E
)
eâˆ’Î»X*
is inï¬nitely often differentiable in (0, âˆ). The ï¬rst two derivatives of F are
F â€²(Î») = âˆ’E[Xeâˆ’Î»X] and F â€²â€²(Î») = E[(X2)eâˆ’Î»X]. Successively, we get the nth
derivative F (n)(Î») = E[(âˆ’X)neâˆ’Î»X]. By monotone convergence, we get
E[X] = âˆ’lim
Î»â†“0 F â€²(Î»)
(6.7)
and
E[Xn] = (âˆ’1)n lim
Î»â†“0 F (n)(Î»)
for all n âˆˆN.
(6.8)
Indeed, for Îµ > 0 and I = (Îµ, âˆ), we have
sup
xâ‰¥0, Î»âˆˆI

d
dÎ»f (x, Î»)
 =
sup
xâ‰¥0, Î»âˆˆI
x eâˆ’Î»x = Îµâˆ’1eâˆ’1 < âˆ.
Thus F fulï¬lls the assumptions of Theorem 6.28. Inductively, we get the statement
for F (n) since

dn
dÎ»n f (x, Î»)
 â‰¤(n/Îµ)neâˆ’n < âˆ
for x â‰¥0 and Î» â‰¥Îµ.
â™¦

162
6
Convergence Theorems
Takeaways Consider a function of two variables that is continuous or
differentiable with respect to one variable. Take the integral with respect to
the other variable. We have used the convergence theorems from the last
section to show that the integral is continuous or differentiable, respectively,
if a regularity assumption is fulï¬lled. In this case, integral and derivative
commute.
Exercise 6.3.1 Let X be a random variable on (Î©, A, P) and let
Î›(t) := log

E
)
etX*
for all t âˆˆR.
Show that D := {t âˆˆR : Î›(t) < âˆ} is a nonempty interval and that Î› is inï¬nitely
often differentiable in the interior of D. â™£

Chapter 7
Lp-Spaces and the Radonâ€“Nikodym
Theorem
In this chapter, we study the spaces of functions whose pth power is integrable. In
Sect. 7.2, we ï¬rst derive some of the important inequalities (HÃ¶lder, Minkowski,
Jensen) and then in Sect. 7.3 investigate the case p = 2 in more detail. Apart
from the inequalities, the important results for probability theory are Lebesgueâ€™s
decomposition theorem and the Radonâ€“Nikodym theorem in Sect. 7.4. At ï¬rst
reading, some readers might wish to skip some of the more analytic parts of this
chapter.
7.1
Deï¬nitions
We always assume that (Î©, A, Î¼) is a Ïƒ-ï¬nite measure space. In Deï¬nition 4.16,
for measurable f : Î© â†’R, we deï¬ned
âˆ¥f âˆ¥p :=

|f |p dÎ¼
1/p
for p âˆˆ[1, âˆ)
and
âˆ¥f âˆ¥âˆ:= inf
	
K â‰¥0 : Î¼(|f | > K) = 0

.
Further, we deï¬ned the spaces of functions where these expressions are ï¬nite:
Lp(Î©, A, Î¼) = Lp(A, Î¼) = Lp(Î¼) = {f : Î© â†’R measurable and âˆ¥f âˆ¥p < âˆ}.
We saw that âˆ¥Â· âˆ¥1 is a seminorm on L1(Î¼). Here our ï¬rst goal is to change âˆ¥Â· âˆ¥p
into a proper norm for all p âˆˆ[1, âˆ]. Apart from the fact that we still have to show
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_7
163

164
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
the triangle inequality, to this end, we have to change the space a little bit since we
only have
âˆ¥f âˆ’gâˆ¥p = 0
â‡â‡’
f = g
Î¼-a.e.
For a proper norm (that is, not only a seminorm), the left-hand side has to imply
equality (not only a.e.) of f and g. Hence we now consider f and g as equivalent if
f = g almost everywhere. Thus let
N = {f is measurable and f = 0
Î¼-a.e.}.
For any p âˆˆ[1, âˆ], N is a subvector space of Lp(Î¼). Thus formally we can build
the factor space. This is the standard procedure in order to change a seminorm into
a proper norm.
Deï¬nition 7.1 (Factor space)
For any p âˆˆ[1, âˆ], deï¬ne
Lp(Î©, A, Î¼) := Lp(Î©, A, Î¼)/N = { Â¯f := f + N : f âˆˆLp(Î¼)}.
For Â¯f âˆˆLp(Î¼), deï¬ne
;; Â¯f
;;
p = âˆ¥f âˆ¥p for any f âˆˆÂ¯f . Also let
3 Â¯f dÎ¼ =
3
f dÎ¼ if
this expression is deï¬ned for f .
Note that
;; Â¯f
;;
p and
3 Â¯f dÎ¼ do not depend on the choice of the representative f âˆˆÂ¯f .
Recall from Theorem 4.19 that
3 Â¯f dÎ¼ is well-deï¬ned if f âˆˆLp(Î¼) and if Î¼ is ï¬nite
but it need not be if Î¼ is inï¬nite.
We ï¬rst investigate convergence with respect to âˆ¥Â· âˆ¥p. To this end, we extend
the corresponding theorem (Theorem 6.25) on convergence with respect to âˆ¥Â· âˆ¥1.
Deï¬nition 7.2 Let p âˆˆ[1, âˆ] and f, f1, f2, . . . âˆˆLp(Î¼). If âˆ¥fn âˆ’f âˆ¥p
nâ†’âˆ
âˆ’â†’0,
then we say that (fn)nâˆˆN converges to f in Lp(Î¼) and we write fn
Lp
âˆ’â†’f.
Theorem 7.3 Let p âˆˆ[1, âˆ] and f1, f2, . . . âˆˆLp(Î¼). Then the following
statements are equivalent:
(i) There is an f âˆˆLp(Î¼) with fn
Lp
âˆ’â†’f .
(ii) (fn)nâˆˆN is a Cauchy sequence in Lp(Î¼).
If p < âˆ, then, in addition, (i) and (ii) are equivalent to:
(iii) (|fn|p)nâˆˆN is uniformly integrable and there exists a measurable f with
fn
meas
âˆ’â†’f .
The limits in (i) and (iii) coincide.
Proof For p = âˆ, the equivalence of (i) and (ii) is a simple consequence of the
triangle inequality.

7.2
Inequalities and the Fischerâ€“Riesz Theorem
165
Now let p âˆˆ[1, âˆ). The proof is similar to the proof of Theorem 6.25.
â€œ(i) â‡’(ii)â€
Note that |x + y|p â‰¤2p (|x|p + |y|p) for all x, y âˆˆR. Hence
âˆ¥fm âˆ’fnâˆ¥p
p â‰¤2p âˆ¥fm âˆ’f âˆ¥p
p + âˆ¥fn âˆ’f âˆ¥p
p
 nâ†’âˆ
âˆ’â†’0
for m, n â†’âˆ.
â€œ(ii) â‡’(iii)â€
This works as in the proof of Theorem 6.25.
â€œ(iii) â‡’(i)â€
Since |fn|p
nâ†’âˆ
âˆ’â†’
|f |p in measure, by Theorem 6.25, we have
|f |p âˆˆL1(Î¼) and hence f âˆˆLp(Î¼). For n âˆˆN, deï¬ne gn = |fn âˆ’f |p.
Then gn
nâ†’âˆ
âˆ’â†’
0 in measure, and (gn)nâˆˆN is uniformly integrable since gn â‰¤
2p (|fn|p + |f |p). Hence we get (by Theorem 6.25) âˆ¥fn âˆ’f âˆ¥p
p = âˆ¥gnâˆ¥1
nâ†’âˆ
âˆ’â†’0.
âŠ“âŠ”
Takeaways We have adapted the convergence theorems of the last chapter to
Lp convergence. This is the starting point for the investigation of topological
properties of Lp spaces in the subsequent sections.
Exercise 7.1.1 Let f : Î© â†’R be measurable. Show that the following hold.
(i) If
3
|f |p dÎ¼ < âˆfor some p âˆˆ(0, âˆ), then âˆ¥f âˆ¥p
pâ†’âˆ
âˆ’â†’âˆ¥f âˆ¥âˆ.
(ii) The integrability condition in (i) cannot be waived. â™£
Exercise 7.1.2 Let p âˆˆ(1, âˆ), f âˆˆLp(Î»), where Î» is the Lebesgue measure on
R. Let T : R â†’R, x â†’x + 1. Show that
1
n
nâˆ’1

k=0
f â—¦T k nâ†’âˆ
âˆ’â†’0
in Lp(Î»).
â™£
7.2
Inequalities and the Fischerâ€“Riesz Theorem
We present one of the most important inequalities of probability theory, Jensenâ€™s
inequality for convex functions, and indicate how to derive from it HÃ¶lderâ€™s
inequality and Minkowskiâ€™s inequality. They in turn yield the triangle inequality
for âˆ¥Â· âˆ¥p and help in determining the dual space of Lp(Î¼). However, for the formal
proofs of the latter inequalities, we will follow a different route.
Before stating Jensenâ€™s inequality, we give a primer on the basics of convexity of
sets and functions.
Deï¬nition 7.4 A subset G of a vector space (or of an afï¬ne linear space) is called
convex if, for any two points x, y âˆˆG and any Î» âˆˆ[0, 1], we have Î»x + (1 âˆ’
Î»)y âˆˆG.

166
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
Example 7.5
(i) The convex subsets of R are the intervals.
(ii) A linear subspace of a vector space is convex.
(iii) The set of all probability measures on a measurable space is a convex set. â™¦
Deï¬nition 7.6 Let G be a convex set. A map Ï• : G â†’R is called convex if for
any two points x, y âˆˆG and any Î» âˆˆ[0, 1], we have
Ï•Î»x + (1 âˆ’Î»)y â‰¤Î» Ï•(x) + (1 âˆ’Î») Ï•(y).
Ï• is called concave if (âˆ’Ï•) is convex.
Let I âŠ‚R be an interval. Let Ï• : I â†’R be continuous and in the interior
I â—¦twice continuously differentiable with second derivative Ï•â€²â€². Then Ï• is convex if
and only if Ï•â€²â€²(x) â‰¥0 for all x âˆˆI â—¦. To put it differently, the ï¬rst derivative Ï•â€² of a
convex function is a monotone increasing function. In the next theorem, we will see
that this is still true even if Ï• is not twice continuously differentiable when we pass
to the right-sided derivative D+Ï• (or to the left-sided derivative), which we show
always exists.
Theorem 7.7 Let I âŠ‚R be an interval with interior I â—¦and let Ï• : I â†’R be a
convex map. Then:
(i) Ï• is continuous on I â—¦and hence measurable with respect to B(I).
(ii) For x âˆˆI â—¦, deï¬ne the function of difference quotients
gx(y) := Ï•(y) âˆ’Ï•(x)
y âˆ’x
for y âˆˆI \ {x}.
Then gx is monotone increasing and there exist the left-sided and right-sided
derivatives
Dâˆ’Ï•(x) := lim
yâ†‘x gx(y) = sup{gx(y) : y < x}
and
D+Ï•(x) := lim
yâ†“x gx(y) = inf{gx(y) : y > x}.
(iii) For x âˆˆI â—¦, we have Dâˆ’Ï•(x) â‰¤D+Ï•(x) and
Ï•(x) + (y âˆ’x)t â‰¤Ï•(y) for any y âˆˆI
â‡â‡’
t âˆˆ[Dâˆ’Ï•(x), D+Ï•(x)].
Hence Dâˆ’Ï•(x) and D+Ï•(x) are the minimal and maximal slopes of a tangent
at x.

7.2
Inequalities and the Fischerâ€“Riesz Theorem
167
(iv) The maps x â†’Dâˆ’Ï•(x) and x â†’D+Ï•(x) are monotone increasing. x â†’
Dâˆ’Ï•(x) is left continuous and x â†’D+Ï•(x) is right continuous. We have
Dâˆ’Ï•(x) = D+Ï•(x) at all points of continuity of Dâˆ’Ï• and D+Ï•.
(v) Ï• is differentiable at x if and only if Dâˆ’Ï•(x) = D+Ï•(x). In this case, the
derivative is Ï•â€²(x) = D+Ï•(x).
(vi) Ï• is almost everywhere differentiable and Ï•(b) âˆ’Ï•(a) =
3 b
a D+Ï•(x) dx for
a, b âˆˆI â—¦.
Proof
(i) Let x âˆˆI â—¦. Assume that lim infhâ†“0 Ï•(x âˆ’h) â‰¤Ï•(x)âˆ’Îµ for some Îµ > 0. Since
Ï• is convex, for y âˆˆI â—¦such that y > x, we have
Ï•(y) â‰¥Ï•(x) + y âˆ’x
h
Ï•(x) âˆ’Ï•(x âˆ’h)
for all h > 0 with x âˆ’h âˆˆI â—¦.
Combining this with the assumption, we get Ï•(y) = âˆfor all y > x. Hence
the assumption was false. A similar argument for the right-hand side yields
continuity of Ï• at x.
(ii) Monotonicity is implied by convexity. The other claims are evident.
(iii) By monotonicity of gx, we have Dâˆ’Ï•(x) â‰¤D+Ï•(x). By construction, Ï•(x)+
(y âˆ’x)t â‰¤Ï•(y) for all y < x if and only if t â‰¥Dâˆ’Ï•(x). The inequality holds
for all y > x if and only if t â‰¤D+Ï•(x).
(iv) For Îµ > 0, by the convexity, the map x â†’gx(x + Îµ) is monotone increasing
and is continuous by (i). Being an inï¬mum of monotone increasing and
continuous functions the map x â†’D+Ï•(x) is monotone increasing and
right continuous. The statement for Dâˆ’Ï• follows similarly. As x â†’gx(y)
is monotone, we get D+Ï•(xâ€²) â‰¥Dâˆ’Ï•(xâ€²) â‰¥D+Ï•(x) for xâ€² > x. If D+Ï• is
continuous at x, then Dâˆ’Ï•(x) = D+Ï•(x).
(v) This is obvious since Dâˆ’Ï• and D+Ï• are the limits of the sequences of slopes
of the left-sided and right-sided secant lines, respectively.
(vi) For Îµ > 0, let AÎµ = {x âˆˆI : D+Ï•(x) â‰¥Îµ + limyâ†‘x D+Ï•(y)} be the set
of points of discontinuity of size at least Îµ. For any two points a, b âˆˆI with
a < b, we have #(AÎµ âˆ©(a, b)) â‰¤Îµâˆ’1(D+Ï•(b) âˆ’D+Ï•(a)); hence AÎµ âˆ©(a, b)
is a ï¬nite set. Thus AÎµ is countable. Hence also A = âˆ
n=1 A1/n is countable
and thus a null set. By (iv) and (v), Ï• is differentiable in I â—¦\ A with derivative
D+Ï•.
âŠ“âŠ”
If I is an interval, then a map g : I â†’R is called afï¬ne linear if there are numbers
a, b âˆˆR such that g(x) = ax + b for all x âˆˆI. If Ï• : I â†’R is a map, then we
write
L(Ï•) := 	g : I â†’R is afï¬ne linear and g â‰¤Ï•
.
As a shorthand, we write sup L(Ï•) for the map x â†’sup{f (x) : f âˆˆL(Ï•)}.

168
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
Corollary 7.8 Let I âŠ‚R be an open interval and let Ï• : I â†’R be a map. Then
the following are equivalent.
(i) Ï• is convex.
(ii) For any x0 âˆˆI, there exists a g âˆˆL(Ï•) with g(x0) = Ï•(x0) .
(iii) L(Ï•) is nonempty and Ï• = sup L(Ï•).
(iv) There is a sequence (gn)nâˆˆN in L(Ï•) with Ï• = limnâ†’âˆmax{g1, . . . , gn}.
Furthermore, if I âŠ‚R is an interval (not necessarily open) and Ï• : I â†’R is
convex, then we still have L(Ï•) Ì¸= âˆ….
Proof â€œ(ii) â‡’(iii) â‡â‡’(iv)â€
This is obvious.
â€œ(iii) â‡’(i)â€
The supremum of convex functions is convex and any afï¬ne linear
map is convex. Hence sup L(Ï•) is convex if L(Ï•) Ì¸= âˆ….
â€œ(i) â‡’(ii)â€
By Theorem 7.7(iii), for any x0 âˆˆI, the map
x â†’Ï•(x0) + (x âˆ’x0) D+Ï•(x0)
is in L(Ï•).
Since for the implication â€œ(i) â‡’(ii)â€ we did not need that I is open, we get the
supplementary statement.
âŠ“âŠ”
Theorem 7.9 (Jensenâ€™s inequality) Let I âŠ‚R be an interval and let X be an
I-valued random variable with E[|X|] < âˆ. If Ï• is convex, then E[Ï•(X)âˆ’] < âˆ
and
E[Ï•(X)] â‰¥Ï•(E[X]).
Proof As L(Ï•) Ì¸= âˆ…by Corollary 7.8, we can choose numbers a, b âˆˆR such that
ax + b â‰¤Ï•(x) for all x âˆˆI. Hence
E[Ï•(X)âˆ’] â‰¤E[(aX + b)âˆ’] â‰¤|b| + |a| Â· E[|X|] < âˆ.
We distinguish the cases where E[X] is in the interior I â—¦or at the boundary âˆ‚I.
Case 1. If E[X] âˆˆI â—¦, then let t+ := D+Ï•(E[X]) be the maximal slope of a tangent
of Ï• at E[X]. Then Ï•(x) â‰¥t+ Â· (x âˆ’E[X]) + Ï•(E[X]) for all x âˆˆI; hence
E[Ï•(X)] â‰¥t+ E[X âˆ’E[X]] + E[Ï•(E[X])] = Ï•(E[X]).
Case 2. If E[X] âˆˆâˆ‚I, then X = E[X] a.s.; hence E[Ï•(X)] = E[Ï•(E[X])] =
Ï•(E[X]).
âŠ“âŠ”
Jensenâ€™s inequality can be extended to Rn. To this end, we need a representation
of convex functions of many variables as a supremum of afï¬ne linear functions.
Recall that a function g : Rn â†’R is called afï¬ne linear if there is an a âˆˆRn and

7.2
Inequalities and the Fischerâ€“Riesz Theorem
169
a b âˆˆR such that g(x) = âŸ¨a, xâŸ©+ b for all x. Here âŸ¨Â·, Â·âŸ©denotes the usual inner
product on Rn.
Theorem 7.10 Let G âŠ‚Rn be open and convex and let Ï• : G â†’R be a map.
Then Corollary 7.8 holds with I replaced by G. If Ï• is convex, then Ï• is continuous
and hence measurable. If Ï• is twice continuously differentiable, then Ï• is convex if
and only if the Hessian matrix is positive semideï¬nite.
Proof As we need these statements only in the proof of the multidimensional
Jensen inequality, which will not play a central role in the following, we only
give references for the proofs. In Rockafellarâ€™s book [146], continuity follows from
Theorem 10.1, and the statements of Corollary 7.8 follow from Theorem 12.1 and
Theorem 18.8. The claim about the Hessian matrix can be found in Theorem 4.5.
âŠ“âŠ”
Theorem 7.11 (Jensenâ€™s inequality in Rn) Let G âŠ‚Rn be a convex set and let
X1, . . . , Xn be integrable real random variables with P[(X1, . . . , Xn) âˆˆG] = 1.
Further, let Ï• : G â†’R be convex. Then E[Ï•(X1, . . . , Xn)âˆ’] < âˆand
E
)
Ï•(X1, . . . , Xn)
*
â‰¥Ï•(E[X1], . . . , E[Xn]).
Proof First consider the case where G is open. Here, the argument is similar to the
proof of Theorem 7.9. Let g âˆˆL(Ï•) with
gE[X1], . . . , E[Xn] = Ï•E[X1], . . . , E[Xn].
As g â‰¤Ï• is linear, we get
E
)
Ï•(X1, . . . , Xn)
*
â‰¥E[g(X1, . . . , Xn)] = g

E[X1], . . . , E[Xn]

.
Integrability of Ï•(X1, . . . , Xn)âˆ’can be derived in a similar way to the one-
dimensional case.
Now consider the general case where G is not necessarily open. Here the problem
that arises when (E[X1], . . . , E[Xn]) âˆˆâˆ‚G is a bit more tricky than in the one-
dimensional case since âˆ‚G can have ï¬‚at pieces that in turn, however, are convex.
Hence one cannot infer that (X1, . . . , Xn) equals its expectation almost surely. We
only sketch the argument. First infer that (X1, . . . , Xn) is almost surely in one of
those ï¬‚at pieces. This piece is necessarily of dimension smaller than n. Now restrict
Ï• to that ï¬‚at piece and inductively reduce its dimension until reaching a point, the
case that has already been treated above. Details can be found, e.g., in [37, Theorem
10.2.6].
âŠ“âŠ”
Example 7.12 Let X be a real random variable with E[X2] < âˆ, I = R and
Ï•(x) = x2. By Jensenâ€™s inequality, we get
Var[X] = E[X2] âˆ’(E[X])2 â‰¥0.
â™¦

170
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
Example 7.13 Let G = [0, âˆ)Ã—[0, âˆ), Î± âˆˆ(0, 1) and Ï•(x, y) = xÎ±y1âˆ’Î±. Then Ï•
is concave (exercise!); hence, for nonnegative random variables X and Y with ï¬nite
expectation (by Theorem 7.11),
E
'
XÎ±Y 1âˆ’Î±(
â‰¤(E[X])Î± (E[Y])1âˆ’Î±.
â™¦
Example 7.14 Let G, X and Y be as in Example 7.13. Let p âˆˆ(1, âˆ). Then
Ïˆ(x, y) =

x1/p + y1/pp is concave. Hence (by Theorem 7.11)

E[X]1/p + E[Y]1/pp
â‰¥E
'
X1/p + Y 1/pp(
.
â™¦
Before we present HÃ¶lderâ€™s inequality and Minkowskiâ€™s inequality, we need a
preparatory lemma.
Lemma 7.15 (Youngâ€™s inequality) For p, q âˆˆ(1, âˆ) with 1
p + 1
q = 1 and for
x, y âˆˆ[0, âˆ),
xy â‰¤xp
p + yq
q .
(7.1)
Proof Fix y âˆˆ[0, âˆ) and deï¬ne f (x) := xp
p + yq
q âˆ’xy for x âˆˆ[0, âˆ). f is
twice continuously differentiable in (0, âˆ) with derivatives f â€²(x) = xpâˆ’1 âˆ’y and
f â€²â€²(x) = (p âˆ’1)xpâˆ’2. In particular, f is strictly convex and hence assumes its
(unique) minimum at x0 = y1/(pâˆ’1). By assumption, q =
p
pâˆ’1; hence xp
0 = yq and
thus
f (x0) =
 1
p + 1
q

yq âˆ’y1/(pâˆ’1)y = 0.
âŠ“âŠ”
Theorem 7.16 (HÃ¶lderâ€™s inequality) Let p, q âˆˆ[1, âˆ] with 1
p + 1
q = 1 and f âˆˆ
Lp(Î¼), g âˆˆLq(Î¼). Then (fg) âˆˆL1(Î¼) and
âˆ¥fgâˆ¥1 â‰¤âˆ¥f âˆ¥p Â· âˆ¥gâˆ¥q.
Proof The cases p = 1 and p = âˆare trivial. Hence, let p âˆˆ(1, âˆ). Let f âˆˆ
Lp(Î¼) and g âˆˆLq(Î¼) be nontrivial. By passing to f/âˆ¥f âˆ¥p and g/âˆ¥gâˆ¥q, we may
assume that âˆ¥f âˆ¥p = âˆ¥gâˆ¥q = 1. By Lemma 7.15, we have
âˆ¥fgâˆ¥1 =

|f | Â· |g| dÎ¼ â‰¤1
p

|f |p dÎ¼ + 1
q

|g|q dÎ¼
= 1
p + 1
q = 1 = âˆ¥f âˆ¥p Â· âˆ¥gâˆ¥q.
âŠ“âŠ”

7.2
Inequalities and the Fischerâ€“Riesz Theorem
171
Theorem 7.17 (Minkowskiâ€™s inequality)
For p âˆˆ[1, âˆ] and f, g âˆˆLp(Î¼),
âˆ¥f + gâˆ¥p â‰¤âˆ¥f âˆ¥p + âˆ¥gâˆ¥p.
(7.2)
Proof The case p = âˆis trivial. Hence, let p âˆˆ[1, âˆ). The left-hand side in
(7.2) does not decrease if we replace f and g by |f | and |g|. Hence we may assume
f â‰¥0 and g â‰¥0 and (to avoid trivialities) âˆ¥f + gâˆ¥p > 0.
Now (f + g)p â‰¤2p(f p âˆ¨gp) â‰¤2p(f p + gp); hence f + g âˆˆLp(Î¼). Apply
HÃ¶lderâ€™s inequality to f Â· (f + g)pâˆ’1 and to g Â· (f + g)pâˆ’1 to get
âˆ¥f + gâˆ¥p
p =

(f + g)p dÎ¼ =

f (f + g)pâˆ’1 dÎ¼ +

g(f + g)pâˆ’1 dÎ¼
â‰¤âˆ¥f âˆ¥p Â· âˆ¥(f + g)pâˆ’1âˆ¥q + âˆ¥gâˆ¥p Â· âˆ¥(f + g)pâˆ’1âˆ¥q
= (âˆ¥f âˆ¥p + âˆ¥gâˆ¥p) Â· âˆ¥f + gâˆ¥pâˆ’1
p
.
Note that in the last step, we used the fact that p âˆ’p/q = 1. Dividing both sides by
âˆ¥f + gâˆ¥pâˆ’1
p
yields (7.2).
âŠ“âŠ”
In Theorem 7.17, we veriï¬ed the triangle inequality and hence that âˆ¥Â· âˆ¥p is a
norm. Theorem 7.3 says that this norm is complete (i.e., every Cauchy sequence
converges). A complete normed vector space is called a Banach space. Summing
up, we have shown the following theorem.
Theorem 7.18 (Fischerâ€“Riesz)
(Lp(Î¼), âˆ¥Â· âˆ¥p) is a Banach space for every p âˆˆ
[1, âˆ].
Takeaways In this section, we have encountered the most prominent integral
inequalities: Jensenâ€™s inequality for convex functions, HÃ¶lderâ€™s inequality
and Minkowskiâ€™s inequality. Together with the topological considerations in
Sect. 7.1, these inequalities enabled us to show the celebrated Fischer-Riesz
theorem.
Exercise 7.2.1 Show HÃ¶lderâ€™s inequality by applying Jensenâ€™s inequality to the
function of Example 7.13. â™£
Exercise 7.2.2 Show Minkowskiâ€™s inequality by applying Jensenâ€™s inequality to the
function of Example 7.14. â™£
Exercise 7.2.3 Let X be a real random variable and let p, q âˆˆ(1, âˆ) with 1
p +
1
q = 1. Show that X is in Lp(P) if and only if there exists a C < âˆsuch that
|E[XY]| â‰¤C âˆ¥Yâˆ¥q for any bounded random variable Y. â™£

172
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
7.3
Hilbert Spaces
In this section, we study the case p = 2 in more detail. The main goal is the
representation theorem for continuous linear functionals on Hilbert spaces due to
Riesz and FrÃ©chet. This theorem is a cornerstone for a functional analytic proof of
the Radonâ€“Nikodym theorem in Sect. 7.4.
Deï¬nition 7.19 Let V be a real vector space. A map âŸ¨Â·, Â·âŸ©: V Ã—V â†’R is called
an inner product if:
(i) (Linearity)
âŸ¨x, Î± y + zâŸ©= Î± âŸ¨x, yâŸ©+ âŸ¨x, zâŸ©for all x, y, z âˆˆV and Î± âˆˆR.
(ii) (Symmetry)
âŸ¨x, yâŸ©= âŸ¨y, xâŸ©for all x, y âˆˆV .
(iii) (Positive deï¬niteness)
âŸ¨x, xâŸ©> 0 for all x âˆˆV \ {0}.
If only (i) and (ii) hold and âŸ¨x, xâŸ©â‰¥0 for all x, then âŸ¨Â·, Â·âŸ©is called a positive
semideï¬nite symmetric bilinear form, or a semi-inner product.
If âŸ¨Â·, Â·âŸ©is an inner product, then (V, âŸ¨Â·, Â·âŸ©) is called a (real) Hilbert space if
the norm deï¬ned by âˆ¥xâˆ¥:= âŸ¨x, xâŸ©1/2 is complete; that is, if (V, âˆ¥Â· âˆ¥) is a Banach
space.
Deï¬nition 7.20 For f, g âˆˆL2(Î¼), deï¬ne
âŸ¨f, gâŸ©:=

fg dÎ¼.
For Â¯f , Â¯g âˆˆL2(Î¼), deï¬ne âŸ¨Â¯f , Â¯gâŸ©:= âŸ¨f, gâŸ©, where f âˆˆÂ¯f and g âˆˆÂ¯g.
Note that this deï¬nition is independent of the particular choices of the representa-
tives of f and g.
Theorem 7.21 âŸ¨Â·, Â·âŸ©is an inner product on L2(Î¼) and a semi-inner product on
L2(Î¼). In addition, âˆ¥f âˆ¥2 = âŸ¨f, f âŸ©1/2.
Proof This is left as an exercise.
âŠ“âŠ”
As a corollary to Theorem 7.18, we get the following.
Corollary 7.22 (L2(Î¼), âŸ¨Â·, Â·âŸ©) is a real Hilbert space.
Lemma 7.23 If âŸ¨Â·, Â·âŸ©is a semi-inner product on the real vector space V , then
âŸ¨Â·, Â·âŸ©: V Ã— V â†’R is continuous (with respect to the product topology of the
topology on V that is generated by the pseudo-metric d(x, y) = âŸ¨x âˆ’y, x âˆ’yâŸ©1/2).
Proof This is obvious.
âŠ“âŠ”
Deï¬nition 7.24 (Orthogonal complement) Let V be a real vector space with inner
product âŸ¨Â·, Â·âŸ©. If W âŠ‚V , then the orthogonal complement of W is the following
linear subspace of V :
W âŠ¥:=
	
v âˆˆV : âŸ¨v, wâŸ©= 0 for all w âˆˆW

.

7.3
Hilbert Spaces
173
Theorem 7.25 (Orthogonal decomposition) Let (V, âŸ¨Â·, Â·âŸ©) be a Hilbert space
and let W âŠ‚V be a closed linear subspace. For any x âˆˆV , there is a unique
representation x = y + z where y âˆˆW and z âˆˆW âŠ¥.
Proof Let x âˆˆV and c := inf{âˆ¥x âˆ’wâˆ¥: w âˆˆW}. Further, let (wn)nâˆˆN be a
sequence in W with âˆ¥x âˆ’wnâˆ¥
nâ†’âˆ
âˆ’â†’c. The parallelogram law yields
âˆ¥wm âˆ’wnâˆ¥2 = 2 âˆ¥wm âˆ’xâˆ¥2 + 2 âˆ¥wn âˆ’xâˆ¥2 âˆ’4
;;;;
1
2(wm + wn) âˆ’x
;;;;
2
.
As W is linear, we have (wm + wn)/2 âˆˆW; hence âˆ¥1
2(wm + wn) âˆ’xâˆ¥â‰¥c. Thus
(wn)nâˆˆN is a Cauchy sequence: âˆ¥wm âˆ’wnâˆ¥âˆ’â†’0 if m, n â†’âˆ.
Since V is complete and W is closed, W is also complete; hence there is a y âˆˆW
with wn
nâ†’âˆ
âˆ’â†’y. Now let z := x âˆ’y. Then âˆ¥zâˆ¥= limnâ†’âˆâˆ¥wn âˆ’xâˆ¥= c by
continuity of the norm (Lemma 7.23).
Consider an arbitrary w âˆˆW \{0}. We deï¬ne Ï± := âŸ¨z, wâŸ©/âˆ¥wâˆ¥2 and get y+Ï±w âˆˆ
W; hence
c2 â‰¤âˆ¥x âˆ’(y + Ï± w)âˆ¥2 = âˆ¥zâˆ¥2 + Ï±2 âˆ¥wâˆ¥2 + 2Ï± âŸ¨z, wâŸ©= c2 âˆ’Ï±2 âˆ¥wâˆ¥2.
Concluding, we have âŸ¨z, wâŸ©= 0 for all w âˆˆW and thus z âˆˆW âŠ¥.
Uniqueness of the decomposition is easy: If x = yâ€² + zâ€² is an orthogonal
decomposition, then y âˆ’yâ€² âˆˆW and z âˆ’zâ€² âˆˆW âŠ¥as well as y âˆ’yâ€² + z âˆ’zâ€² = 0;
hence
0 = âˆ¥y âˆ’yâ€² + z âˆ’zâ€²âˆ¥2 = âˆ¥y âˆ’yâ€²âˆ¥2 + âˆ¥z âˆ’zâ€²âˆ¥2 + 2âŸ¨y âˆ’yâ€², z âˆ’zâ€²âŸ©
= âˆ¥y âˆ’yâ€²âˆ¥2 + âˆ¥z âˆ’zâ€²âˆ¥2,
whence y = yâ€² and z = zâ€².
âŠ“âŠ”
Theorem 7.26 (Rieszâ€“FrÃ©chet representation theorem) Let (V, âŸ¨Â·, Â·âŸ©) be a Hil-
bert space and let F : V â†’R be a map. Then the following are equivalent.
(i) F is continuous and linear.
(ii) There is an f âˆˆV with F(x) = âŸ¨x, f âŸ©for all x âˆˆV .
The element f âˆˆV in (ii) is uniquely determined.
Proof â€œ(ii) â‡’(i)â€
For any f âˆˆV , by deï¬nition of the inner product, the map
x â†’âŸ¨x, f âŸ©is linear. By Lemma 7.23, this map is also continuous.
â€œ(i) â‡’(ii)â€
If F â‰¡0, then choose f = 0. Now assume F is not identically zero.
As F is continuous, the kernel W := F âˆ’1({0}) is a closed (proper) linear subspace
of V . Let v âˆˆV \ W and let v = y + z for y âˆˆW and z âˆˆW âŠ¥be the orthogonal
decomposition of v. Then z Ì¸= 0 and F(z) = F(v) âˆ’F(y) = F(v) Ì¸= 0. Hence
we can deï¬ne u := z/F(z) âˆˆW âŠ¥. Clearly, F(u) = 1 and for any x âˆˆV , we
have F(x âˆ’F(x)u) = F(x) âˆ’F(x)F(u) = 0; hence x âˆ’F(x)u âˆˆW and thus

174
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
âŸ¨x âˆ’F(x)u, uâŸ©= 0. Consequently, F(x) = âŸ¨x, uâŸ©/âˆ¥uâˆ¥2. Now deï¬ne f := u/âˆ¥uâˆ¥2.
Then F(x) = âŸ¨x, f âŸ©for all x âˆˆV .
â€œUniquenessâ€
Let âŸ¨x, f âŸ©= âŸ¨x, gâŸ©for all x âˆˆV . Letting x = f âˆ’g, we get
0 = âŸ¨f âˆ’g, f âˆ’gâŸ©; hence f = g.
âŠ“âŠ”
Reï¬‚ection Find an example of a discontinuous linear map F : V â†’R. â™ 
In the following section, we will need the representation theorem for the space
L2(Î¼), which, unlike L2(Î¼), is not a Hilbert space. However, with a little bit
of abstract nonsense, one can apply the preceding theorem to L2(Î¼). Recall that
N = {f âˆˆL2(Î¼) : âŸ¨f, f âŸ©= 0} is the subspace of functions that equal zero almost
everywhere. Let L2(Î¼) = L2(Î¼)/N be the factor space. This is a special case of
the situation where (V, âŸ¨Â·, Â·âŸ©) is a linear space with complete semi-inner product.
In this case, N := {v âˆˆV : âŸ¨v, vâŸ©= 0} and V0 = V/N := {f + N : f âˆˆV }.
Denote âŸ¨v + N, w + NâŸ©0 := âŸ¨v, wâŸ©to obtain a Hilbert space (V0, âŸ¨Â·, Â·âŸ©0).
Corollary 7.27 Let (V, âŸ¨Â·, Â·âŸ©) be a linear vector space with complete semi-inner
product. The map F : V â†’R is continuous and linear if and only if there is an
f âˆˆV with F(x) = âŸ¨x, f âŸ©for all x âˆˆV .
Proof One implication is trivial. Hence, let F be continuous and linear. Then
F(0) = 0 since F is linear. Note that F(v) = F(0) = 0 for all v âˆˆN
since F is continuous. Indeed, v lies in every open neighborhood of 0; hence F
assumes at v the same value as at 0. Thus F induces a continuous linear map
F0 : V0 â†’R by F0(x + N) = F(x). By Theorem 7.26, there is an f + N âˆˆV0
with F0(x + N) = âŸ¨x + N, f + NâŸ©0 for all x + N âˆˆV0. However, F(x) = âŸ¨x, f âŸ©
for all x âˆˆV by the deï¬nition of F0 and âŸ¨Â·, Â·âŸ©0.
âŠ“âŠ”
Corollary 7.28 The map F : L2(Î¼) â†’R is continuous and linear if and only if
there is an f âˆˆL2(Î¼) with F(g) =
3
gf dÎ¼ for all g âˆˆL2(Î¼).
Proof The space L2(Î¼) fulï¬lls the conditions of Corollary 7.27.
âŠ“âŠ”
Takeaways We recognised the function spaces L2 as Hilbert spaces. In
Hilbert spaces, continuous linear maps can be represented as a scalar product
with some ï¬xed vector (Riesz-FrÃ©chet theorem).
Exercise 7.3.1 (Fourier series)
For n âˆˆN0, deï¬ne Sn, Cn : [0, 1] â†’[0, 1] by
Sn(x) = sin(2Ï€n x), Cn(x) = cos(2Ï€n x). For two square summable sequences
(an)nâˆˆN and (bn)nâˆˆN0, let ha,b := b0 + âˆ
n=1(anSn + bnCn). Further, let W be the
vector space of such ha,b.
Show the following:
(i) The functions C0, Sn, Cn, n âˆˆN form an orthogonal system in L2([0, 1], Î»).
(ii) The series deï¬ning ha,b converges in L2([0, 1], Î»).
(iii) W is a closed linear subspace of L2([0, 1], Î»).

7.4
Lebesgueâ€™s Decomposition Theorem
175
(iv) W = L2([0, 1], Î»). More precisely, for any f âˆˆL2([0, 1], Î»), there exist
uniquely deï¬ned square summable sequences (an)nâˆˆN and (bn)nâˆˆN0 such that
f = ha,b. Furthermore, âˆ¥f âˆ¥2
2 = b2
0 + âˆ
n=1(a2
n + b2
n).
Hint: Show (iv) ï¬rst for step functions (see Exercise 4.2.6). â™£
7.4
Lebesgueâ€™s Decomposition Theorem
In this section, we employ the properties of Hilbert spaces that we derived in the
last section in order to decompose a measure into a singular part and a part that is
absolutely continuous, both with respect to a second given measure. Furthermore,
we show that the absolutely continuous part has a density. Let Î¼ and Î½ be measures
on (Î©, A). By Deï¬nition 4.13, a measurable function f : Î© â†’[0, âˆ) is called a
density of Î½ with respect to Î¼ if
Î½(A) :=

f 1A dÎ¼
for all A âˆˆA.
(7.3)
On the other hand, for any measurable f : Î© â†’[0, âˆ), equation (7.3) deï¬nes
a measure Î½ on (Î©, A). In this case, we also write
Î½ = f Î¼
and
f = dÎ½
dÎ¼.
(7.4)
For example, the normal distribution Î½ = N0,1 has the density f (x) =
1
âˆš
2Ï€ eâˆ’x2/2
with respect to the Lebesgue measure Î¼ = Î» on R.
If g : Î© â†’[0, âˆ] is measurable, then (by Theorem 4.15)

g dÎ½ =

gf dÎ¼.
(7.5)
Hence g âˆˆL1(Î½) if and only if gf âˆˆL1(Î¼), and in this case (7.5) holds.
If Î½ = f Î¼, then Î½(A) = 0 for all A âˆˆA with Î¼(A) = 0. The situation is quite
the opposite for, e.g., the Poisson distribution Î¼ = PoiÏ± with parameter Ï± > 0 and
Î½ = N0,1. Here N0 âŠ‚R is a Î½-null set with Î¼(R \ N0) = 0. We say that Î½ is
singular to Î¼.
The main goal of this chapter is to show that an arbitrary Ïƒ-ï¬nite measure Î½
on a measurable space (Î©, A) can be decomposed into a part that is singular to
the Ïƒ-ï¬nite measure Î¼ and a part that has a density with respect to Î¼ (Lebesgueâ€™s
decomposition theorem, Theorem 7.33).

176
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
Theorem 7.29 (Uniqueness of the density) Let Î½ be Ïƒ-ï¬nite. If f1 and f2 are
densities of Î½ with respect to Î¼, then f1 = f2 Î¼-almost everywhere. In particular,
the density dÎ½
dÎ¼ is unique up to equality Î¼-almost everywhere.
Proof Let En â†‘Î© with Î½(En) < âˆ, n âˆˆN. Let An = En âˆ©{f1 > f2} for n âˆˆN.
Then Î½(An) < âˆ; hence
0 = Î½(An) âˆ’Î½(An) =

An
(f1 âˆ’f2) dÎ¼.
By Theorem 4.8(i), f2 1An = f1 1An Î¼-a.e. As f1 > f2 on An, we infer Î¼(An) = 0
and
Î¼({f1 > f2}) = Î¼
 
nâˆˆN
An

= 0.
Similarly, we get Î¼({f1 < f2}) = 0; hence f1 = f2 Î¼-a.e.
âŠ“âŠ”
Deï¬nition 7.30 Let Î¼ and Î½ be two measures on (Î©, A).
(i) Î½ is called absolutely continuous with respect to Î¼ (symbolically Î½ â‰ªÎ¼) if
Î½(A) = 0
for all A âˆˆA with Î¼(A) = 0.
(7.6)
The measures Î¼ and Î½ are called equivalent (symbolically Î¼ â‰ˆÎ½) if Î½ â‰ªÎ¼
and Î¼ â‰ªÎ½.
(ii) Î¼ is called singular to Î½ (symbolically Î¼ âŠ¥Î½) if there exists an A âˆˆA such
that Î¼(A) = 0 and Î½(Î© \ A) = 0.
Remark 7.31 Clearly, Î¼ âŠ¥Î½
â‡â‡’
Î½ âŠ¥Î¼. â™¦
Example 7.32
(i) Let Î¼ be a measure on

R, B(R)

with density f
with respect to the
Lebesgue measure Î». Then Î¼(A) =
3
A f dÎ» = 0 for every A âˆˆA with
Î»(A) = 0; hence Î¼ â‰ªÎ». If Î»-almost everywhere f > 0, then Î¼(A) =
3
A f dÎ» > 0 if Î»(A) > 0; hence Î¼ â‰ˆÎ». If Î»({f = 0}) > 0, then (since
Î¼({f = 0}) = 0) Î» Ì¸â‰ªÎ¼.
(ii) Consider the Bernoulli distributions Berp and Berq for p, q âˆˆ[0, 1]. If p âˆˆ
(0, 1), then Berq â‰ªBerp. If p âˆˆ{0, 1}, then Berq â‰ªBerp if and only if
p = q, and Berq âŠ¥Berp if and only if q = 1 âˆ’p.
(iii) Consider the Poisson distributions PoiÎ± and PoiÎ² for Î±, Î² â‰¥0. We have
PoiÎ± â‰ªPoiÎ² if and only if Î² > 0 or Î± = 0.
(iv) Consider the inï¬nite product measures (see Theorem 1.64) (Berp)âŠ—N and
(Berq)âŠ—N on Î© = {0, 1}N. Then (Berp)âŠ—N âŠ¥(Berq)âŠ—N if p Ì¸= q. Indeed,
for n âˆˆN, let Xn((Ï‰1, Ï‰2, . . .)) = Ï‰n be the projection of Î© to the nth
coordinate. Then under (Berr)âŠ—N the family (Xn)nâˆˆN is independent and
Bernoulli-distributed with parameter r (see Example 2.18). By the strong law

7.4
Lebesgueâ€™s Decomposition Theorem
177
of large numbers, for any r âˆˆ{p, q}, there exists a measurable set Ar âŠ‚Î©
with (Berr)âŠ—N(Î© \ Ar) = 0 and
lim
nâ†’âˆ
1
n
n

i=1
Xi(Ï‰) = r
for all Ï‰ âˆˆAr.
In particular, Ap âˆ©Aq = âˆ…if p Ì¸= q and thus (Berp)âŠ—N âŠ¥(Berq)âŠ—N. â™¦
Theorem 7.33 (Lebesgueâ€™s decomposition theorem)
Let Î¼ and Î½ be Ïƒ-ï¬nite
measures on (Î©, A). Then Î½ can be uniquely decomposed into an absolutely
continuous part Î½a and a singular part Î½s (with respect to Î¼):
Î½ = Î½a + Î½s, where Î½a â‰ªÎ¼ and Î½s âŠ¥Î¼.
Î½a has a density with respect to Î¼, and dÎ½a
dÎ¼ is A-measurable and ï¬nite Î¼-a.e.
Corollary 7.34 (Radonâ€“Nikodym theorem)
Let Î¼ and Î½ be Ïƒ-ï¬nite measures
on (Î©, A). Then
Î½ has a density w.r.t. Î¼
â‡â‡’
Î½ â‰ªÎ¼.
In this case, dÎ½
dÎ¼ is A-measurable and ï¬nite Î¼-a.e. dÎ½
dÎ¼ is called the Radonâ€“Nikodym
derivative of Î½ with respect to Î¼.
Proof One direction is trivial. Hence, let Î½ â‰ªÎ¼. By Theorem 7.33, we get that
Î½ = Î½a has a density with respect to Î¼.
âŠ“âŠ”
Proof (of Theorem 7.33) The idea goes back to von Neumann. We follow the
exposition in [37].
By the usual exhaustion arguments, we can restrict ourselves to the case where
Î¼ and Î½ are ï¬nite. By Theorem 4.19, the canonical inclusion i : L2(Î©, A, Î¼ +
Î½) â†’L1(Î©, A, Î¼ + Î½) is continuous. Since Î½ â‰¤Î¼ + Î½, the linear functional
L2(Î©, A, Î¼ + Î½) â†’R, h â†’
3
h dÎ½ is continuous. By the Rieszâ€“FrÃ©chet theorem
(here Corollary 7.28), there exists a g âˆˆL2(Î©, A, Î¼ + Î½) such that

h dÎ½ =

hg d(Î¼ + Î½)
for all h âˆˆL2(Î©, A, Î¼ + Î½)
(7.7)
or equivalently

f (1 âˆ’g) d(Î¼ + Î½) =

f dÎ¼
for all f âˆˆL2(Î©, A, Î¼ + Î½).
(7.8)

178
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
If in (7.7) we choose h = 1{g<0}, then we get that (Î¼+Î½)-almost everywhere g â‰¥0.
Similarly, with f = 1{g>1} in (7.8), we obtain that (Î¼+Î½)-almost everywhere g â‰¤1.
Hence 0 â‰¤g â‰¤1.
Now let f â‰¥0 be measurable and let (fn)nâˆˆN be a sequence of nonnegative
functions in L2(Î©, A, Î¼ + Î½) with fn â†‘f . By the monotone convergence theorem
(applied to the measure (1âˆ’g)(Î¼+Î½); that is, the measure with density (1âˆ’g) with
respect to Î¼+Î½), we obtain that (7.8) holds for all measurable f â‰¥0. Similarly, we
get (7.7) for all measurable h â‰¥0.
Let E := gâˆ’1({1}). If we let f = 1E in (7.8), then we get Î¼(E) = 0. Deï¬ne the
measures Î½a and Î½s for A âˆˆA by
Î½a(A) := Î½(A \ E)
and
Î½s(A) := Î½(A âˆ©E).
Clearly, Î½ = Î½a + Î½s and Î½s(Î© \ E) = 0; hence Î½s âŠ¥Î¼. If now A âˆ©E = âˆ…and
Î¼(A) = 0, then
3
1A dÎ¼ = 0. Hence, by (7.8), also
3
A(1 âˆ’g) d(Î¼ + Î½) = 0.
On the other hand, we have 1 âˆ’g > 0 on A; hence Î¼(A) + Î½(A) = 0 and thus
Î½a(A) = Î½(A) = 0. If, more generally, B is measurable with Î¼(B) = 0, then
Î¼(B \ E) = 0; hence, as shown above, Î½a(B) = Î½a(B \ E) = 0. Consequently,
Î½a â‰ªÎ¼ and Î½ = Î½a + Î½s is the decomposition we wanted to construct.
In order to obtain the density of Î½a with respect to Î¼, we deï¬ne f
:=
g
1 âˆ’g 1Î©\E. For any A âˆˆA, by (7.8) and (7.7) with h = 1A\E,

A
f dÎ¼ =

Aâˆ©Ec g d(Î¼ + Î½) = Î½(A \ E) = Î½a(A).
Hence f = dÎ½a
dÎ¼ .
âŠ“âŠ”
Reï¬‚ection Why do we assume Ïƒ-ï¬niteness of the measures in the Radon-Nikodym
theorem? Find an example that shows that this assumption cannot be dropped. â™ 
Takeaways Loosely speaking, a Ïƒ-ï¬nite measure Î¼ has a density with
respect to a Ïƒ-ï¬nite measure Î½ if locally Î¼ is a multiple of Î½. A necessary
and sufï¬cient condition for this to be true is that Î¼ vanishes on the sets where
Î½ vanishes. The actual density could be gained using Hilbert space theory, in
particular the Riesz-FrÃ©chet representation theorem.
Exercise 7.4.1 For every x âˆˆ(0, 1], let x = (0, x1x2x3 . . .) := âˆ
n=1 xn2âˆ’n be
the dyadic expansion (with lim supnâ†’âˆxn = 1 for deï¬niteness). Deï¬ne a map
F : (0, 1] â†’(0, 1] by
F(x) = (0, x1x1x2x2x3x3 . . .) =
âˆ

n=1
3 xn 4âˆ’n.

7.5
Supplement: Signed Measures
179
Let U be a random variable that is uniformly distributed on (0, 1] and denote by
Î¼ := PUâ—¦F âˆ’1 the distribution of F(U).
Show that the probability measure Î¼ has a continuous distribution function and
that Î¼ is singular to the Lebesgue measure Î»
(0,1]. â™£
Exercise 7.4.2 Let n âˆˆN and p, q âˆˆ[0, 1]. For which values of p and q do we
have bn,p â‰ªbn,q? Compute the Radonâ€“Nikodym derivative dbn,p
dbn,q . â™£
7.5
Supplement: Signed Measures
In this section, we show the decomposition theorems for signed measures (Hahn,
Jordan) and deliver an alternative proof for Lebesgueâ€™s decomposition theorem. We
owe some of the proofs to [89].
Deï¬nition 7.35 Let Î¼ and Î½ be two measures on (Î©, A). Î½ is called totally
continuous with respect to Î¼ if, for any Îµ > 0, there exists a Î´ > 0 such that
for all A âˆˆA
Î¼(A) < Î´
implies
Î½(A) < Îµ.
(7.9)
Remark 7.36 The deï¬nition of total continuity is similar to that of uniform inte-
grability (see Theorem 6.24(iii)), at least for ï¬nite Î¼. We will come back to this
connection in the framework of the martingale convergence theorem that will
provide an alternative proof of the Radonâ€“Nikodym theorem (Corollary 7.34). â™¦
Theorem 7.37 Let Î¼ and Î½ be measures on (Î©, A). If Î½ is totally continuous with
respect to Î¼, then Î½ â‰ªÎ¼. If Î½(Î©) < âˆ, then the converse also holds.
Proof â€œ â‡’â€
Let Î½ be totally continuous with respect to Î¼. Let A âˆˆA with
Î¼(A) = 0. For all Îµ > 0, by assumption, Î½(A) < Îµ; hence Î½(A) = 0 and thus
Î½ â‰ªÎ¼.
â€œ â‡ â€
Let Î½ be ï¬nite but not totally continuous with respect to Î¼. Then there
exist an Îµ > 0 and sets An âˆˆA with Î¼(An) < 2âˆ’n but Î½(An) â‰¥Îµ for all n âˆˆN.
Deï¬ne A := lim sup
nâ†’âˆ
An =
âˆ

n=1
âˆ

k=n
Ak. Then
Î¼(A) =
lim
nâ†’âˆÎ¼
 âˆ

k=n
Ak

â‰¤
lim
nâ†’âˆ
âˆ

k=n
Î¼(Ak) â‰¤
lim
nâ†’âˆ
âˆ

k=n
2âˆ’k = 0.

180
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
Since Î½ is ï¬nite and upper semicontinuous (Theorem 1.36), we have
Î½(A) =
lim
nâ†’âˆÎ½
 âˆ

k=n
Ak

â‰¥inf
nâˆˆN Î½(An) â‰¥Îµ > 0.
Thus Î½ Ì¸â‰ªÎ¼.
âŠ“âŠ”
Example 7.38 In the converse implication of the theorem, the assumption of
ï¬niteness is essential. For example, let Î¼ = N0,1 be the standard normal distribution
on R and let Î½ be the Lebesgue measure on R. Then Î½ has the density f (x) =
âˆš
2Ï€ ex2/2 with respect to Î¼. In particular, we have Î½ â‰ªÎ¼. On the other hand,
Î¼([n, âˆ))
nâ†’âˆ
âˆ’â†’
0 and Î½([n, âˆ)) = âˆfor any n âˆˆN. Hence Î½ is not totally
continuous with respect to Î¼. â™¦
Example 7.39 Let (Î©, A) be a measurable space and let Î¼ and Î½ be ï¬nite measures
on (Î©, A). Denote by Z the set of ï¬nite partitions of Î© into pairwise disjoint
measurable sets. That is, Z âˆˆZ is a ï¬nite subset of A such that the sets C âˆˆZ
are pairwise disjoint and 
CâˆˆZ C = Î© for all Z. For Z âˆˆZ, deï¬ne a function
fZ : Î© â†’R by
fZ(Ï‰) =

CâˆˆZ: Î¼(C)>0
Î½(C)
Î¼(C) 1C(Ï‰).
We show that the following three statements are equivalent.
(i) The family (fZ : Z âˆˆZ) is uniformly integrable in L1(Î¼) and
3
fZ dÎ¼ =
Î½(Î©) for any Z âˆˆZ.
(ii) Î½ â‰ªÎ¼.
(iii) Î½ is totally continuous with respect to Î¼.
The equivalence of (ii) and (iii) was established in the preceding theorem. If (ii)
holds, then, for all Z âˆˆZ,

fZ dÎ¼ =

CâˆˆZ: Î¼(C)>0
Î½(C) = Î½(Î©)
since Î½(C) = 0 for those C that do not appear in the sum. Now ï¬x Îµ > 0. Since
(ii) implies (iii), there is a Î´â€² > 0 such that Î½(A) < Îµ/2 for all A âˆˆA with
Î¼(A) â‰¤Î´â€². Let K := Î½(Î©)/Î´â€² and Î´ < Îµ/(2K). Then
Î¼
â›
â

CâˆˆZ: KÎ¼(C)â‰¤Î½(C)
C
â
â =

CâˆˆZ: KÎ¼(C)â‰¤Î½(C)
Î¼(C) â‰¤
1
K Î½(Î©) = Î´â€²;

7.5
Supplement: Signed Measures
181
hence

CâˆˆZ: KÎ¼(C)â‰¤Î½(C)
Î½(C) = Î½
â›
â

CâˆˆZ: KÎ¼(C)â‰¤Î½(C)
C
â
â < Îµ
2.
We conclude that for all A âˆˆA with Î¼(A) < Î´,

A
fZ dÎ¼ =

CâˆˆZ: Î¼(C)>0
Î¼(A âˆ©C) Î½(C)
Î¼(C)
=

0<KÎ¼(C)â‰¤Î½(C)
Î¼(A âˆ©C) Î½(C)
Î¼(C) +

KÎ¼(C)>Î½(C)
Î¼(A âˆ©C) Î½(C)
Î¼(C)
â‰¤Îµ
2 +

KÎ¼(C)>Î½(C)
K Î¼(A âˆ©C) â‰¤Îµ
2 + K Î¼(A) < Îµ.
Hence (fZ, Z âˆˆZ) is uniformly integrable by Theorem 6.24(iii).
Now assume (i). If Î¼ = 0, then
3
f dÎ¼ = 0 for all f ; hence Î½(Î©) = 0 and thus
Î½ â‰ªÎ¼. Hence, let Î¼ Ì¸= 0. Let A âˆˆA with Î¼(A) = 0. Then Z = {A, Ac} âˆˆZ
and fZ = 1AcÎ½(Ac)/Î¼(Ac). By assumption, Î½(Î©) =
3
fZ dÎ¼ = Î½(Ac); hence
Î½(A) = 0 and thus Î½ â‰ªÎ¼. â™¦
Deï¬nition 7.40 (Signed measure)
A set function Ï• : A â†’R is called a signed
measure on (Î©, A) if it is Ïƒ-additive; that is, if for any sequence of pairwise
disjoint sets A1, A2, . . . âˆˆA,
Ï•
 âˆ

n=1
An

=
âˆ

n=1
Ï•(An).
(7.10)
The set of all signed measures will be denoted by MÂ± = MÂ±(Î©, A).
Remark 7.41
(i) If Ï• is a signed measure, then in (7.10) we automatically have absolute
convergence. Indeed, the value of the left-hand side does not change if we
change the order of the sets A1, A2, . . .. In order for this to hold for the right-
hand side, by WeierstraÃŸâ€™s theorem on rearrangements of series, the series has
to converge absolutely. In particular, for any sequence (An)nâˆˆN of pairwise
disjoint sets, we have lim
nâ†’âˆ
âˆ
k=n |Ï•(Ak)| = 0.
(ii) If Ï• âˆˆMÂ±, then Ï•(âˆ…) = 0 since R âˆ‹Î½(âˆ…) = 
nâˆˆN Î½(âˆ…).
(iii) In general, Ï• âˆˆMÂ± is not Ïƒ-subadditive. â™¦
Example 7.42 If Î¼+, Î¼âˆ’are ï¬nite measures, then Ï• := Î¼+ âˆ’Î¼âˆ’âˆˆMÂ±. We will
see that every signed measure has such a representation. â™¦

182
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
Theorem 7.43 (Hahnâ€™s decomposition theorem)
Let Ï• be a signed measure.
Then there is a set Î©+ âˆˆA with Ï•(A) â‰¥0 for all A âˆˆA, A âŠ‚Î©+ and Ï•(A) â‰¤0
for all A âˆˆA, A âŠ‚Î©âˆ’:= Î© \ Î©+. Such a decomposition Î© = Î©âˆ’âŠÎ©+ is
called a Hahn decomposition of Î© (with respect to Ï•).
Proof Let Î± := sup
	
Ï•(A) : A âˆˆA

. We have to show that Ï• attains the maximum
Î±; that is, there exists an Î©+ âˆˆA with Ï•(Î©+) = Î±. If this is the case, then Î± âˆˆR
and for A âŠ‚Î©+, A âˆˆA, we would have
Î± â‰¥Ï•(Î©+ \ A) = Ï•(Î©+) âˆ’Ï•(A) = Î± âˆ’Ï•(A);
hence Ï•(A) â‰¥0. For A âŠ‚Î©âˆ’, A âˆˆA, we would have Ï•(A) â‰¤0 since
Î± â‰¥Ï•(Î©+ âˆªA) = Ï•(Î©+) + Ï•(A) = Î± + Ï•(A).
We now construct Î©+ with Ï•(Î©+) = Î±. Let (An)nâˆˆN be a sequence in A with
Î± = lim
nâ†’âˆÏ•(An). Let A := âˆ
n=1 An. As each An could still contain â€œportions with
negative massâ€, we cannot simply choose Î©+ = A. Rather, we have to peel off the
negative portions layer by layer.
Deï¬ne A0
n := An, A1
n := A \ An, and let
Pn :=
 n

i=1
As(i)
i
: s âˆˆ{0, 1}n

be the partition of A that is generated by A1, . . . , An. Clearly, for any B, C âˆˆPn,
either B = C or B âˆ©C = âˆ…holds. In addition, we have An =

BâˆˆPn
BâŠ‚An
B. Deï¬ne
Pâˆ’
n := {B âˆˆPn : Ï•(B) < 0},
P+
n := Pn \ Pâˆ’
n
and
Cn :=

BâˆˆP+
n
B.
Due to the ï¬nite additivity of Ï•, we have
Ï•(An) =

BâˆˆPn
BâŠ‚An
Ï•(B) â‰¤

BâˆˆP+
n
BâŠ‚An
Ï•(B) â‰¤

BâˆˆP+
n
Ï•(B) = Ï•(Cn).

7.5
Supplement: Signed Measures
183
For m â‰¤n, let En
m = Cm âˆª. . . âˆªCn. Hence, for m < n, we have En
m \ Enâˆ’1
m
âŠ‚Cn
and thus
En
m \ Enâˆ’1
m
=

BâˆˆP+
n
BâŠ‚Enm\Enâˆ’1
m
B.
In particular, this implies Ï•(En
m \ Enâˆ’1
m
) â‰¥0. For Em := 
nâ‰¥m Cn, we also have
En
m â†‘Em (n â†’âˆ) and
Ï•(Am) â‰¤Ï•(Cm) = Ï•(Em
m) â‰¤Ï•(Em
m) +
âˆ

n=m+1
Ï•(En
m \ Enâˆ’1
m
)
= Ï•

Em
m âˆª
âˆ

n=m+1
(En
m \ Enâˆ’1
m
)

= Ï•
 âˆ

n=m
En
m

= Ï•(Em).
Now deï¬ne Î©+ = âˆ
m=1 Em; hence Em â†“Î©+. Then
Ï•(Em) = Ï•

Î©+ âŠ

nâ‰¥m
(En \ En+1)

= Ï•(Î©+) +
âˆ

n=m
Ï•(En \ En+1)
mâ†’âˆ
âˆ’â†’Ï•(Î©+).
In the last step, we used Remark 7.41(i). Summing up, we have
Î± = lim
mâ†’âˆÏ•(Am) â‰¤lim
mâ†’âˆÏ•(Em) = Ï•(Î©+).
However, by deï¬nition, Î± â‰¥Ï•(Î©+); hence Î± = Ï•(Î©+). This ï¬nishes the proof.
âŠ“âŠ”
Corollary 7.44 (Jordanâ€™s decomposition theorem)
Assume Ï• âˆˆMÂ±(Î©, A) is a
signed measure. Then there exist uniquely determined ï¬nite measures Ï•+, Ï•âˆ’with
Ï• = Ï•+ âˆ’Ï•âˆ’and Ï•+ âŠ¥Ï•âˆ’.
Proof Let Î© = Î©+ âŠÎ©âˆ’be a Hahn decomposition. Deï¬ne Ï•+(A) := Ï•(Aâˆ©Î©+)
and Ï•âˆ’(A) := âˆ’Ï•(A âˆ©Î©âˆ’).
The uniqueness of the decomposition is trivial.
âŠ“âŠ”

184
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
Corollary 7.45 Let Ï• âˆˆMÂ±(Î©, A) and let Ï• = Ï•+ âˆ’Ï•âˆ’be the Jordan
decomposition of Ï•. Let Î© = Î©+ âŠÎ©âˆ’be a Hahn decomposition of Î©. Then
âˆ¥Ï•âˆ¥T V := sup
	
Ï•(A) âˆ’Ï•(Î© \ A) : A âˆˆA

= Ï•(Î©+) âˆ’Ï•(Î©âˆ’)
= Ï•+(Î©) + Ï•âˆ’(Î©)
deï¬nes a norm on MÂ±(Î©, A), the so-called total variation norm.
Proof We only have to show the triangle inequality. Let Ï•1, Ï•2 âˆˆMÂ±. Let Î© =
Î©+ âŠÎ©âˆ’be a Hahn decomposition with respect to Ï• := Ï•1 + Ï•2 and let Î© =
Î©+
i âŠÎ©âˆ’
i be a Hahn decomposition with respect to Ï•i, i = 1, 2. Then
âˆ¥Ï•1 + Ï•2âˆ¥T V = Ï•1(Î©+) âˆ’Ï•1(Î©âˆ’) + Ï•2(Î©+) âˆ’Ï•2(Î©âˆ’)
â‰¤Ï•1(Î©+
1 ) âˆ’Ï•1(Î©âˆ’
1 ) + Ï•2(Î©+
2 ) âˆ’Ï•2(Î©âˆ’
2 )
= âˆ¥Ï•1âˆ¥T V + âˆ¥Ï•2âˆ¥T V .
âŠ“âŠ”
Reï¬‚ection An important object in stochastic analysis is a random set function Ï• on
B([0, 1]) with the property that Ï•(A) âˆ¼N0,Î»(A) is normally distributed and Ï•(A)
and Ï•(B) are independent on disjoint sets A and B. With a little effort it is possible
to construct Ï• as a (random) additive set function. However, Ï• cannot be a (random)
signed measure. Why? â™ â™ â™ 
With a lemma, we prepare for an alternative proof of Lebesgueâ€™s decomposition
theorem (Theorem 7.33).
Lemma 7.46 Let Î¼, Î½ be ï¬nite measures on (Î©, A) that are not mutually singular;
in short, Î¼ Ì¸âŠ¥Î½. Then there is an A âˆˆA with Î¼(A) > 0 and an Îµ > 0 with
ÎµÎ¼(E) â‰¤Î½(E)
for all E âˆˆA with E âŠ‚A.
Proof For n âˆˆN, let Î© = Î©+
n âŠÎ©âˆ’
n be a Hahn decomposition for (Î½âˆ’1
nÎ¼) âˆˆMÂ±.
Deï¬ne M := 
nâˆˆN Î©âˆ’
n . Clearly, (Î½ âˆ’1
nÎ¼)(M) â‰¤0; hence Î½(M) â‰¤1
nÎ¼(M) for all
n âˆˆN and thus Î½(M) = 0. Since Î¼ Ì¸âŠ¥Î½, we get Î¼

Î© \ M) = Î¼(
nâˆˆN Î©+
n

> 0.
Thus Î¼(Î©+
n0) > 0 for some n0 âˆˆN. Deï¬ne A := Î©+
n0 and Îµ := 1
n0 . Then Î¼(A) > 0
and (Î½ âˆ’ÎµÎ¼)(E) â‰¥0 for all E âŠ‚A, E âˆˆA.
âŠ“âŠ”
Alternative proof of Theorem 7.33.
We show only the existence of a decompo-
sition. By choosing a suitable sequence Î©n â†‘Î©, we can assume that Î½ is ï¬nite.
Consider the set of functions
G :=
0
g : Î© â†’[0, âˆ] : g is measurable and

A
g dÎ¼ â‰¤Î½(A) for all A âˆˆA
1
,

7.5
Supplement: Signed Measures
185
and deï¬ne
Î³ := sup
 
g dÎ¼ : g âˆˆG

.
Our aim is to ï¬nd a maximal element f in G (i.e., an f for which
3
f dÎ¼ = Î³ ).
This f will be the density of Î½a.
Clearly, 0 âˆˆG; hence G Ì¸= âˆ…. Furthermore,
f, g âˆˆG
implies
f âˆ¨g âˆˆG.
(7.11)
Indeed, letting E := {f â‰¥g}, for all A âˆˆA, we have

A
(f âˆ¨g) dÎ¼ =

Aâˆ©E
f dÎ¼ +

A\E
g dÎ¼ â‰¤Î½(A âˆ©E) + Î½(A \ E) = Î½(A).
Choose a sequence (gn)nâˆˆN in G such that
3
gn dÎ¼
nâ†’âˆ
âˆ’â†’Î³ , and deï¬ne the function
fn = g1 âˆ¨. . . âˆ¨gn. Now (7.11) implies fn âˆˆG. Letting f := sup{fn : n âˆˆN}, the
monotone convergence theorem yields

A
f dÎ¼ = sup
nâˆˆN

A
fn dÎ¼ â‰¤Î½(A)
for all A âˆˆA
(that is, f âˆˆG), and

f dÎ¼ = sup
nâˆˆN

fn dÎ¼ â‰¥sup
nâˆˆN

gn dÎ¼ = Î³.
Hence
3
f dÎ¼ = Î³ â‰¤Î½(Î©). Now deï¬ne, for any A âˆˆA,
Î½a(A) :=

A
f dÎ¼
and
Î½s(A) := Î½(A) âˆ’Î½a(A).
By construction, Î½a â‰ªÎ¼ is a ï¬nite measure with density f with respect to Î¼. Since
f âˆˆG, we have Î½s(A) = Î½(A) âˆ’
3
A f dÎ¼ â‰¥0 for all A âˆˆA, and thus also Î½s is a
ï¬nite measure. It remains to show Î½s âŠ¥Î¼.
At this point we use Lemma 7.46. Assume that we had Î½s Ì¸âŠ¥Î¼. Then there would
be an Îµ > 0 and an A âˆˆA with Î¼(A) > 0 such that ÎµÎ¼(E) â‰¤Î½s(E) for all E âŠ‚A,
E âˆˆA. Then, for B âˆˆA, we would have

B
(f + Îµ 1A) dÎ¼ =

B
f dÎ¼ + ÎµÎ¼(A âˆ©B)
â‰¤Î½a(B) + Î½s(A âˆ©B) â‰¤Î½a(B) + Î½s(B) = Î½(B).

186
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
In other words, (f + Îµ 1A) âˆˆG and thus
3
(f + Îµ 1A) dÎ¼ = Î³ + ÎµÎ¼(A) > Î³ ,
contradicting the deï¬nition of Î³ . Hence in fact Î½s âŠ¥Î¼.
Takeaways A signed measure is a ï¬nite measure that can also assume
negative values. A signed measure can be written as the difference of two
ï¬nite mutually singular measures (Jordan decomposition). With the help of
signed measures we could present a different approach to proving the Radon-
Nikodym theorem.
Exercise 7.5.1 Let Î¼ be a Ïƒ-ï¬nite measure on (Î©, A) and let Ï• be a signed measure
on (Î©, A). Show that, analogously to the Radonâ€“Nikodym theorem, the following
two statements are equivalent:
(i) Ï•(A) = 0 for all A âˆˆA with Î¼(A) = 0.
(ii) There is an f âˆˆL1(Î¼) with Ï• = f Î¼; hence 3
A f dÎ¼ = Ï•(A) for all A âˆˆA.
â™£
Exercise 7.5.2 Let Î¼, Î½, Î± be ï¬nite measures on (Î©, A) with Î½ â‰ªÎ¼ â‰ªÎ±.
(i) Show the chain rule for the Radonâ€“Nikodym derivative:
dÎ½
dÎ± = dÎ½
dÎ¼
dÎ¼
dÎ±
Î±-a.e.
(ii) Show that f :=
dÎ½
d(Î¼+Î½) exists and that dÎ½
dÎ¼ =
f
1âˆ’f holds Î¼-a.e. â™£
7.6
Supplement: Dual Spaces
By the Rieszâ€“FrÃ©chet theorem (Theorem 7.26), every continuous linear functional
F : L2(Î¼) â†’R has a representation F(g) = âŸ¨f, gâŸ©for some f âˆˆL2(Î¼). On the
other hand, for any f âˆˆL2(Î¼), the map L2(Î¼) â†’R, g â†’âŸ¨f, gâŸ©is continuous
and linear. Hence L2(Î¼) is canonically isomorphic to its topological dual space
(L2(Î¼))â€². This dual space is deï¬ned as follows.
Deï¬nition 7.47 (Dual space) Let (V, âˆ¥Â· âˆ¥) be a Banach space. The dual space V â€²
of V is deï¬ned by
V â€² := {F : V â†’R is continuous and linear}.
For F âˆˆV â€², we deï¬ne âˆ¥Fâˆ¥â€² := sup{|F(f )| : âˆ¥f âˆ¥= 1}.
Remark 7.48 As F is continuous, for any Î´ > 0, there exists an Îµ > 0 such that
|F(f )| < Î´ for all f âˆˆV with âˆ¥f âˆ¥< Îµ. Hence âˆ¥Fâˆ¥â€² â‰¤Î´/Îµ < âˆ. â™¦

7.6
Supplement: Dual Spaces
187
We are interested in the case V = Lp(Î¼) for p âˆˆ[1, âˆ] and write âˆ¥Fâˆ¥â€²
p for
the norm of F âˆˆV â€². In the particular case V = L2(Î¼), by the Cauchyâ€“Schwarz
inequality, we have âˆ¥Fâˆ¥â€²
2 = âˆ¥f âˆ¥2. This can be generalized:
Lemma 7.49 Let p, q âˆˆ[1, âˆ] with 1
p + 1
q = 1. The canonical map
Îº : Lq(Î¼) â†’(Lp(Î¼))â€²
Îº(f )(g) =

fg dÎ¼
for f âˆˆLq(Î¼), g âˆˆLp(Î¼)
is an isometry; that is, âˆ¥Îº(f )âˆ¥â€²
p = âˆ¥f âˆ¥q.
Proof We show equality by showing the two inequalities separately.
â€œâ‰¤â€
This follows from HÃ¶lderâ€™s inequality.
â€œâ‰¥â€
For any admissible pair p, q and all f
âˆˆLq(Î¼), g âˆˆLp(Î¼), by the
deï¬nition of the operator norm, âˆ¥Îº(f )âˆ¥â€²
p âˆ¥gâˆ¥p â‰¥
 3
fg dÎ¼
. Deï¬ne the sign
function sign(x) = 1(0,âˆ)(x) âˆ’1(âˆ’âˆ,0)(x). Replacing g by Ëœg := |g| sign(f ) (note
that âˆ¥Ëœgâˆ¥p = âˆ¥gâˆ¥p), we obtain
âˆ¥Îº(f )âˆ¥â€²
p âˆ¥gâˆ¥p â‰¥


f Ëœg dÎ¼
 = âˆ¥fgâˆ¥1.
(7.12)
First consider the case q = 1 and f âˆˆL1(Î¼). Applying (7.12) with g â‰¡1 âˆˆLâˆ(Î¼)
yields âˆ¥Îº(f )âˆ¥â€²
âˆâ‰¥âˆ¥f âˆ¥1.
Now let q âˆˆ(1, âˆ). Let g := |f |qâˆ’1. Since qâˆ’1
q
= 1
p, we have
âˆ¥Îº(f )âˆ¥â€²
p Â· âˆ¥gâˆ¥p â‰¥âˆ¥fgâˆ¥1 = âˆ¥|f |q||1 = âˆ¥f âˆ¥q
q = âˆ¥f âˆ¥q Â· âˆ¥f âˆ¥qâˆ’1
q
= âˆ¥f âˆ¥q Â· âˆ¥gâˆ¥p.
Finally, let q = âˆ. Without loss of generality, assume âˆ¥f âˆ¥âˆâˆˆ(0, âˆ). Let
Îµ > 0. Then there exists an AÎµ âˆˆA with 0 < Î¼(AÎµ) < âˆsuch that
AÎµ âŠ‚
	
|f | > (1 âˆ’Îµ)âˆ¥f âˆ¥âˆ

.
If we let g =
1
Î¼(AÎµ) 1AÎµ, then âˆ¥gâˆ¥1 = 1 and âˆ¥Îº(f )âˆ¥â€²
1 â‰¥âˆ¥fgâˆ¥1 â‰¥(1âˆ’Îµ)âˆ¥f âˆ¥âˆ.
âŠ“âŠ”
Theorem 7.50 Let p âˆˆ[1, âˆ) and assume 1
p + 1
q = 1. Then Lq(Î¼) is isomorphic
to its dual space (Lp(Î¼))â€² by virtue of the isometry Îº.
Proof The proof makes use of the Radonâ€“Nikodym theorem (Corollary 7.34).
However, here we only sketch the proof since we do not want to go into the details of
signed measures and signed contents. A signed content Î½ is an additive set function
that is the difference Î½ = Î½+ âˆ’Î½âˆ’of two ï¬nite contents. This deï¬nition is parallel
to that of a signed measure that is the difference of two ï¬nite measures.

188
7
Lp-Spaces and the Radonâ€“Nikodym Theorem
As Îº is an isometry, Îº in particular is injective. Hence we only have to show that
Îº is surjective. Let F âˆˆ(Lp(Î¼))â€². Then Î½(A) = F(1A) is a signed content on A
and we have
|Î½(A)| â‰¤âˆ¥Fâˆ¥â€²
p (Î¼(A))1/p.
Since Î¼ is âˆ…-continuous, Î½ is also âˆ…-continuous and is thus a signed measure on A.
We even have Î½ â‰ªÎ¼. By the Radonâ€“Nikodym theorem (Corollary 7.34) (applied
to the measures Î½âˆ’and Î½+; see Exercise 7.5.1), Î½ admits a density with respect to
Î¼; that is, a measurable function f with Î½ = f Î¼.
Let
Ef :=
	
g : g is a simple function with Î¼(g Ì¸= 0) < âˆ

and let
E+
f :=
	
g âˆˆEf : g â‰¥0

.
Then, for g âˆˆEf ,
F(g) =

gf dÎ¼.
(7.13)
In order to show that (7.13) holds for all g âˆˆLp(Î¼), we ï¬rst show f âˆˆLq(Î¼). To
this end, we distinguish two cases.
Case 1: p = 1.
For every Î± > 0,
Î¼({|f | > Î±}) â‰¤1
Î± Î½({|f | > Î±})
= 1
Î± F(1{|f |>Î±}) â‰¤1
Î± âˆ¥Fâˆ¥â€²
1 Â· âˆ¥1{|f |>Î±}âˆ¥1 = 1
Î± âˆ¥Fâˆ¥â€²
1 Â· Î¼({|f | > Î±}).
This implies Î¼({|f | > Î±}) = 0 if Î± > âˆ¥Fâˆ¥â€²
1; hence âˆ¥f âˆ¥âˆâ‰¤âˆ¥Fâˆ¥â€²
1 < âˆ.
Case 2: p âˆˆ(1, âˆ).
By Theorem 1.96, there are g1, g2, . . . âˆˆE+
f such that
gn â†‘|f | Î¼-a.e. Deï¬ne hn = sign(f )(gn)qâˆ’1 âˆˆEf ; hence
âˆ¥gnâˆ¥q
q â‰¤

hnf dÎ¼ = F(hn)
â‰¤âˆ¥Fâˆ¥â€²
p Â· âˆ¥hnâˆ¥p = âˆ¥Fâˆ¥â€²
p Â· (âˆ¥gnâˆ¥q)qâˆ’1.
Thus we have âˆ¥gnâˆ¥q â‰¤âˆ¥Fâˆ¥â€²
p. Monotone convergence (Theorem 4.20) now yields
âˆ¥f âˆ¥q â‰¤âˆ¥Fâˆ¥â€²
p < âˆ; hence f âˆˆLq(Î¼).
Concluding, the map 
F : g â†’
3
gf dÎ¼ is in (Lp(Î¼))â€², and 
F(g) = F(g) for
every g âˆˆEf . Since 
F is continuous and Ef âŠ‚Lp(Î¼) is dense, we get 
F = F.
âŠ“âŠ”

7.6
Supplement: Dual Spaces
189
Remark 7.51 For p = âˆ, the statement of Theorem 7.50 is false in general. (For
ï¬nite A, the claim is trivially true even for p = âˆ.) For example, let Î© = N,
A = 2Î© and let Î¼ be the counting measure. Thus we consider sequence spaces â„“p =
Lp(N, 2N, Î¼). For the subspace â„“K âŠ‚â„“âˆof convergent sequences, F : â„“K â†’R,
(an)nâˆˆN â†’lim
nâ†’âˆan is a continuous linear functional. By the Hahnâ€“Banach theorem
of functional analysis (see, e.g., [87] or [174]), F can be extended to a continuous
linear functional on â„“âˆ. However, clearly there is no sequence (bn)nâˆˆN âˆˆâ„“1 with
F((an)nâˆˆN) =
âˆ

m=1
ambm. â™¦
Takeaways Lq is the dual space to Lp, if 1
p + 1
q = 1 and p âˆˆ[1, âˆ). This
beautiful theorem could be shown using the tools that we developed in the
previous sections for other purposes.
Exercise 7.6.1 Show that Ef âŠ‚Lp(Î¼) is dense if p âˆˆ[1, âˆ). â™£

Chapter 8
Conditional Expectations
If there is partial information on the outcome of a random experiment, the proba-
bilities for the possible events may change. The concept of conditional probabilities
and conditional expectations formalizes the corresponding calculus.
8.1
Elementary Conditional Probabilities
Example 8.1 We throw a die and consider the events
A := {the face shows an odd number},
B := {the face shows three or smaller}.
Clearly, P[A] = 1
2 and P[B] = 1
2. However, what is the probability that A occurs if
we already know that B occurs?
We model the experiment on the probability space (Î©, A, P), where Î© =
{1, . . ., 6}, A = 2Î© and P is the uniform distribution on Î©. Then
A = {1, 3, 5}
and
B = {1, 2, 3}.
If we know that B has occurred, it is plausible to assume the uniform distribution
on the remaining possible outcomes; that is, on {1, 2, 3}. Thus we deï¬ne a new
probability measure PB on (B, 2B) by
PB[C] = #C
#B
for C âŠ‚B.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_8
191

192
8
Conditional Expectations
By assigning the points in Î© \ B probability zero (since they are impossible if B
has occurred), we can extend PB to a measure on Î©:
P[C|B] := PB[C âˆ©B] = #(C âˆ©B)
#B
for C âŠ‚Î©.
In this way, we get P[A|B] =
#{1, 3}
#{1, 2, 3} = 2
3. â™¦
Motivated by this example, we make the following deï¬nition.
Deï¬nition 8.2 (Conditional probability)
Let (Î©, A, P) be a probability space
and B âˆˆA. We deï¬ne the conditional probability given B for any A âˆˆA by
P[A|B] =
â§
â¨
â©
P[A âˆ©B]
P[B]
,
if P[B] > 0,
0,
otherwise.
(8.1)
Remark 8.3 The speciï¬cation in (8.1) for the case P[B] = 0 is arbitrary and is of
no importance. â™¦
Theorem 8.4 If P[B] > 0, then P[ Â· |B] is a probability measure on (Î©, A).
Proof This is obvious.
âŠ“âŠ”
Theorem 8.5 Let A, B âˆˆA with P[A], P[B] > 0. Then
A, B are independent
â‡â‡’P[A|B] = P[A] â‡â‡’P[B|A] = P[B].
Proof This is trivial!
âŠ“âŠ”
Theorem 8.6 (Summation formula)
Let I be a countable set and let (Bi)iâˆˆI be
pairwise disjoint sets with P
)
iâˆˆI Bi
*
= 1. Then, for any A âˆˆA,
P[A] =

iâˆˆI
P[A|Bi] P[Bi].
(8.2)
Proof Due to the Ïƒ-additivity of P, we have
P[A] = P
-
iâˆˆI
(A âˆ©Bi)
.
=

iâˆˆI
P[A âˆ©Bi] =

iâˆˆI
P[A|Bi]P[Bi].
âŠ“âŠ”
Theorem 8.7 (Bayesâ€™ formula) Let I be a countable set and let (Bi)iâˆˆI be
pairwise disjoint sets with P
)
iâˆˆI Bi
*
= 1. Then, for any A âˆˆA with P[A] > 0
and any k âˆˆI,
P[Bk |A] =
P[A|Bk] P[Bk]

iâˆˆI P[A|Bi] P[Bi].
(8.3)

8.1
Elementary Conditional Probabilities
193
Proof We have
P[Bk |A] = P[Bk âˆ©A]
P[A]
= P[A|Bk] P[Bk]
P[A]
.
Now use the expression in (8.2) for P[A].
âŠ“âŠ”
Example 8.8 In the production of certain electronic devices, a fraction of 2% of
the production is defective. A quick test detects a defective device with probability
95%; however, with probability 10% it gives a false alarm for an intact device.
If the test gives an alarm, what is the probability that the device just tested is
indeed defective?
We formalize the description given above. Let
A := {device is declared as defective},
B := {device is defective},
and
P[B] = 0.02,
P[Bc] = 0.98,
P[A|B] = 0.95,
P[A|Bc] = 0.1.
Bayesâ€™ formula yields
P[B|A] =
P[A|B] P[B]
P[A|B] P[B] + P[A|Bc] P[Bc]
=
0.95 Â· 0.02
0.95 Â· 0.02 + 0.1 Â· 0.98 = 19
117 â‰ˆ0.162.
On the other hand, the probability that a device that was not classiï¬ed as defective
is in fact defective is
P[B|Ac] =
0.05 Â· 0.02
0.05 Â· 0.02 + 0.9 Â· 0.98 =
1
883 â‰ˆ0.00113.
â™¦
Now let X âˆˆL1(P). If A âˆˆA, then clearly also 1AX âˆˆL1(P). We deï¬ne
E[X; A] := E[1A X].
(8.4)
If P[A] > 0, then P[ Â· |A] is a probability measure. Since 1AX âˆˆL1(P), we have
X âˆˆL1(P[ Â· |A]). Hence we can deï¬ne the expectation of X with respect to P[ Â· |A].

194
8
Conditional Expectations
Deï¬nition 8.9 Let X âˆˆL1(P) and A âˆˆA. Then we deï¬ne
E[X|A] :=

X(Ï‰) P[dÏ‰|A] =
â§
â¨
â©
E[1AX]
P[A]
,
if P[A] > 0,
0,
else.
(8.5)
Clearly, P[B|A] = E[1B |A] for all B âˆˆA.
Consider now the situation that we studied with the summation formula for
conditional probabilities. Hence, let I be a countable set and let (Bi)iâˆˆI be pairwise
disjoint events with

iâˆˆI
Bi = Î©. We deï¬ne F := Ïƒ(Bi, i âˆˆI). For X âˆˆL1(P), we
deï¬ne a map E[X|F] : Î© â†’R by
E[X|F](Ï‰) = E[X|Bi]
â‡â‡’
Bi âˆ‹Ï‰.
(8.6)
Lemma 8.10 The map E[X|F] has the following properties.
(i) E[X|F] is F-measurable.
(ii) E[X|F] âˆˆL1(P), and for any A âˆˆF, we have

A
E[X|F] dP =

A
X dP.
Proof
(i) Let f be the map f : Î© â†’I with
f (Ï‰) = i
â‡â‡’
Bi âˆ‹Ï‰.
Further, let g : I â†’R, i â†’E[X|Bi]. Since I is discrete, g is measurable.
Since f is F-measurable, E[X|F] = g â—¦f is also F-measurable.
(ii) Let A âˆˆF and J âŠ‚I with A = 
jâˆˆJ Bj. Let J â€² := {i âˆˆJ : P[Bi] > 0}.
Hence

A
E[X|F] dP =

iâˆˆJ â€²
P[Bi] E[X|Bi] =

iâˆˆJ â€²
E[1BiX] =

A
X dP.
âŠ“âŠ”
Takeaways We have developed the notion of the (elementary) conditional
probability and have established two simple but important formulas: the
summation formula and Bayesâ€™ formula. We have also reformulated the
elementary conditional expectation and highlighted those of its properties that
allow for a generalisation to conditional expectations given Ïƒ-algebras.

8.2
Conditional Expectations
195
Exercise 8.1.1 (Lack of memory of the exponential distribution) Let X > 0 be
a strictly positive random variable and let Î¸ > 0. Show that X is exponentially
distributed if and only if
P[X > t + s|X > s] = P[X > t]
for all s, t â‰¥0.
In particular, X âˆ¼expÎ¸ if and only if P[X > t + s|X > s] = eâˆ’Î¸t for all s, t â‰¥0.
â™£
Exercise 8.1.2 Consider a theatre with n seats that is fully booked for this evening.
Each of the n people entering the theatre (one by one) has a seat reservation.
However, the ï¬rst person is absent-minded and takes a seat at random. Any
subsequent person takes his or her reserved seat if it is free and otherwise picks
a free seat at random.
(i) What is the probability that the last person gets his or her reserved seat?
(ii) What is the probability that the kth person gets his or her reserved seat? â™£
8.2
Conditional Expectations
Let X be a random variable that is uniformly distributed on [0, 1]. Assume that
if we know the value X = x, the random variables Y1, . . . , Yn are independent
and Berx-distributed. So far, with our machinery we can only deal with conditional
probabilities of the type P[ Â· |X âˆˆ[a, b]], a < b (since X âˆˆ[a, b] has positive
probability). How about P[Y1 = . . . = Yn = 1
X = x]? Intuitively, this should
be xn. We thus need a notion of conditional probabilities that allows us to deal with
conditioning on events with probability zero and that is consistent with our intuition.
In the next section, we will see that in the current example this can be done using
transition kernels. First, however, we have to consider a more general situation.
In the following, F âŠ‚A will be a sub-Ïƒ-algebra and X âˆˆL1(Î©, A, P). In
analogy with Lemma 8.10, we make the following deï¬nition.
Deï¬nition 8.11 (Conditional expectation)
A random variable Y is called a
conditional expectation of X given F, symbolically E[X|F] := Y, if:
(i) Y is F-measurable.
(ii) For any A âˆˆF, we have E[X1A] = E[Y1A].
For B âˆˆA, P[B|F] := E[1B |F] is called a conditional probability of B given
the Ïƒ-algebra F.
Theorem 8.12 E[X|F] exists and is unique (up to equality almost surely).
Since conditional expectations are deï¬ned only up to equality a.s., all equalities with
conditional expectations are understood as equalities a.s., even if we do not say so
explicitly.

196
8
Conditional Expectations
Proof
Uniqueness Let Y and Y â€² be random variables that fulï¬ll (i) and (ii). Let A = {Y >
Y â€²} âˆˆF. Then, by (ii),
0 = E[Y1A] âˆ’E[Y â€² 1A] = E[(Y âˆ’Y â€²) 1A].
Since (Y âˆ’Y â€²) 1A â‰¥0, we have P[A] = 0; hence Y â‰¤Y â€² almost surely. Similarly,
we get Y â‰¥Y â€² almost surely.
Existence Let X+ = X âˆ¨0 and Xâˆ’= X+ âˆ’X. By
QÂ±(A) := E[XÂ± 1A]
for all A âˆˆF,
we deï¬ne two ï¬nite measures on (Î©, F). Clearly, QÂ± â‰ªP; hence the Radonâ€“
Nikodym theorem (Corollary 7.34) yields the existence of F-measurable densities
Y Â± such that
QÂ±(A) =

A
Y Â± dP = E[Y Â± 1A].
Now deï¬ne Y = Y + âˆ’Y âˆ’.
âŠ“âŠ”
Deï¬nition 8.13 If Y is a random variable and X
âˆˆL1(P), then we deï¬ne
E[X|Y] := E[X|Ïƒ(Y)].
Theorem 8.14 (Properties of the conditional expectation) Let (Î©, A, P) and let
X be as above. Let G âŠ‚F âŠ‚A be Ïƒ-algebras and let Y âˆˆL1(Î©, A, P). Then:
(i) (Linearity) E[Î»X + Y |F] = Î»E[X|F] + E[ Y |F].
(ii) (Monotonicity) If X â‰¥Y a.s., then E[X|F] â‰¥E[ Y |F].
(iii) If E[|XY|] < âˆand Y is measurable with respect to F, then
E[XY |F] = Y E[X|F]
and
E[ Y |F] = E[ Y |Y] = Y.
(iv) (T owerproperty)
E[E[X|F]|G] = E[E[X|G]|F] = E[X|G].
(v) (T riangleinequality) E[|X|
F] â‰¥
E[X|F]
.
(vi) (Independence) If Ïƒ(X) and F are independent, then E[X|F] = E[X].
(vii) If P[A] âˆˆ{0, 1} for any A âˆˆF, then E[X|F] = E[X].
(viii) (Dominatedconvergence) Assume Y âˆˆL1(P), Y â‰¥0 and (Xn)nâˆˆN is
a sequence of random variables with |Xn| â‰¤Y for n âˆˆN and such that
Xn
nâ†’âˆ
âˆ’â†’X a.s. Then
lim
nâ†’âˆE[Xn|F] = E[X|F]
a.s. and in L1(P).
(8.7)

8.2
Conditional Expectations
197
Proof
(i) The right-hand side is F-measurable; hence, for A âˆˆF,
E)1A
Î»E[X|F] + E[Y |F]* = Î»E)1A E[X|F]* + E)1A E[Y |F]*
= Î»E[1A X] + E[1A Y]
= E
)
1A (Î»X + Y)
*
.
(ii) Let A = {E[X|F] < E[Y |F]} âˆˆF. Since we have X â‰¥Y, we get
E[1A (X âˆ’Y)] â‰¥0 and thus P[A] = 0.
(iii) First assume X â‰¥0 and Y â‰¥0. For n âˆˆN, deï¬ne Yn = 2âˆ’nâŒŠ2nYâŒ‹. Then
Yn â†‘Y and Yn E[X|F] â†‘Y E[X|F] (since E[X|F] â‰¥0 by (ii)). By the
monotone convergence theorem (Lemma 4.6(ii)),
E)1A Yn E[X|F]* nâ†’âˆ
âˆ’â†’E)1A Y E[X|F]*.
On the other hand,
E)1A Yn E[X|F]* =
âˆ

k=1
E)1A 1{Yn=k 2âˆ’n} k 2âˆ’n E[X|F]*
=
âˆ

k=1
E
)
1A 1{Yn=k 2âˆ’n} k 2âˆ’n X
*
= E
)
1A YnX
* nâ†’âˆ
âˆ’â†’E[1A YX].
Hence E[1A Y E[X|F]] = E[1A YX]. In the general case, write X = X+ âˆ’
Xâˆ’and Y = Y +âˆ’Y âˆ’and exploit the linearity of the conditional expectation.
(iv) The second equality follows from (iii) with Y = E[X|G] and X = 1. Now let
A âˆˆG. Then, in particular, A âˆˆF; hence
E)1AE[E[X|F]|G]* = E)1AE[X|F]* = E[1A X] = E)1A E[X|G]*.
(v) This follows from (i) and (ii) with X = X+ âˆ’Xâˆ’.
(vi) Trivially, E[X] is measurable with respect to F. Let A âˆˆF. Then X and 1A
are independent; hence E[E[X|F] 1A] = E[X 1A] = E[X] E[1A].
(vii) For any A âˆˆF and B âˆˆA, we have P[A âˆ©B] = 0 if P[A] = 0, and
P[A âˆ©B] = P[B] if P[A] = 1. Hence F and A are independent and thus
F is independent of any sub-Ïƒ-algebra of A. In particular, F and Ïƒ(X) are
independent. Hence the claim follows from (vi).
(viii) Let |Xn| â‰¤Y for any n âˆˆN and Xn
nâ†’âˆ
âˆ’â†’X almost surely. Deï¬ne Zn :=
supkâ‰¥n |Xk âˆ’X|. Then 0 â‰¤Zn â‰¤2Y and Zn
a.s.
âˆ’â†’0. By Corollary 6.26
(dominated convergence), we have E[Zn]
nâ†’âˆ
âˆ’â†’
0; hence, by the triangle

198
8
Conditional Expectations
inequality,
E)E[Xn|F]âˆ’E[X|F]
*â‰¤E[E[|Xnâˆ’X|
F]] = E[|Xnâˆ’X|] â‰¤E[Zn]
nâ†’âˆ
âˆ’â†’0.
However, this is the L1(P)-convergence in (8.7). As (Zn)nâˆˆN is decreasing,
by (ii) also (E[Zn
F])nâˆˆN decreases to some limit, say, Z. By Fatouâ€™s lemma,
E[Z] â‰¤
lim
nâ†’âˆE[E[Zn|F]] = lim
nâ†’âˆE[Zn] = 0.
Hence Z = 0 and thus E[Zn
F]
nâ†’âˆ
âˆ’â†’0 almost surely. However, by (v),
E[Xn
F] âˆ’E[X
F]
 â‰¤E[Zn|F].
âŠ“âŠ”
Reï¬‚ection Can we relax the condition in (viii) that the Xn be dominated to uniform
integrability of (Xn)nâˆˆN? â™ â™ â™ 
Remark 8.15 Intuitively, E[X|F] is the best prediction we can make for the value
of X if we only have the information of the Ïƒ-algebra F. For example, if Ïƒ(X) âŠ‚F
(that is, if we know X already), then E[X|F] = X, as shown in (iii). At the other
end of the spectrum is the case where X and F are independent; that is, where
knowledge of F does not give any information on X. Here the best prediction for X
is its mean; hence E[X] = E[X|F], as shown in (vi).
What exactly do we mean by â€œbest predictionâ€? For square integrable random
variables X, by the best prediction for X we will understand the F-measurable
random variable that minimizes the L2-distance from X. The next corollary shows
that the conditional expectation is in fact this minimizer. â™¦
Remark 8.16 Let X : Î© â†’R be a random variable such that Xâˆ’âˆˆL1(P). We can
deï¬ne the conditional expectation as the monotone limit
E[X|F] := lim
nâ†’âˆE[Xn|F],
where âˆ’Xâˆ’â‰¤X1 and Xn â†‘X. Due to the monotonicity of the conditional
expectation (Theorem 8.14(ii)) it is easy to show that the limit does not depend on
the choice of the sequence (Xn) and that it fulï¬lls the conditions of Deï¬nition 8.11.
Analogously, we can deï¬ne the conditional expectation X+ âˆˆL1(P). For this
generalization of the conditional expectation, we still have E[X|F] â‰¤E[Y |F] a.s.
if Y â‰¥X a.s. (see Exercise 8.2.1). â™¦
Corollary 8.17 (Conditional expectation as projection) Let F âŠ‚A be a Ïƒ-
algebra and let X be a random variable with E[X2] < âˆ. Then E[X|F] is the
orthogonal projection of X on L2(Î©, F, P). That is, for any F-measurable Y with
E[Y 2] < âˆ,
E
)
(X âˆ’Y)2*
â‰¥E
)
(X âˆ’E[X|F])2*
with equality if and only if Y = E[X|F].

8.2
Conditional Expectations
199
Proof First assume that E[E[X|F]2] < âˆ. (In Theorem 8.20, we will see
that we have E[E[X|F]2] â‰¤E[X2], but here we want to keep the proof self-
contained.) Let Y be F-measurable and assume E[Y 2] < âˆ. Then, by the Cauchyâ€“
Schwarz inequality, we have E[|XY|] < âˆ. Thus, using the tower property,
we infer E[XY] = E[E[X|F]Y] and E
)
XE[X|F]
*
= E
)
E[XE[X|F]
F]
*
=
E
)
E[X|F]2*
. Summing up, we have
E
)
(X âˆ’Y)2*
âˆ’E
'
X âˆ’E[X|F]
2(
= E
'
X2 âˆ’2XY + Y 2 âˆ’X2 + 2XE[X|F] âˆ’E[X|F]2(
= E
'
Y 2 âˆ’2Y E[X|F] + E[X|F]2(
= E
'
Y âˆ’E[X|F]
2(
â‰¥0.
For the case E[E[X|F]2] < âˆ, we are done. Hence, it sufï¬ces to show that
this condition follows from the assumption E[X2] < âˆ. For N âˆˆN, deï¬ne the
truncated random variables |X| âˆ§N. Clearly, we have E[E[|X| âˆ§N |F]2] â‰¤N2.
By what we have shown already (with X replaced by |X| âˆ§N and with Y = 0 âˆˆ
L2(Î©, F, P)), and using the elementary inequality a2 â‰¤2(a âˆ’b)2 + 2b2, a, b âˆˆR,
we infer
E
'
E
)
|X| âˆ§N
F
*2(
â‰¤2E
'
(|X| âˆ§N) âˆ’E[|X| âˆ§N
F]
2(
+ 2E
)
(|X| âˆ§N)2*
â‰¤4E
)
(|X| âˆ§N)2*
â‰¤4E[X2].
By Theorem 8.14(ii) and (viii), we get E[|X|âˆ§N
F] â†‘E[|X|
F] for N â†’âˆ. By
the triangle inequality (Theorem 8.14(v)) and the monotone convergence theorem
(Theorem 4.20), we conclude
E
)
E[X|F]2*
â‰¤E
)
E[|X|
F]2*
= lim
Nâ†’âˆE
)
E[|X| âˆ§N
F]2*
â‰¤4E[X2] < âˆ.
This completes the proof.
âŠ“âŠ”
Example 8.18 Let X, Y âˆˆL1(P) be independent. Then
E[X + Y |Y] = E[X|Y] + E[Y |Y] = E[X] + Y.
â™¦

200
8
Conditional Expectations
Example 8.19 Let X1, . . . , XN be independent with E[Xi] = 0, i = 1, . . . , N. For
n = 1, . . . , N, deï¬ne Fn := Ïƒ(X1, . . . , Xn) and Sn := X1 + . . . + Xn. Then, for
n â‰¥m,
E[Sn
Fm] = E[X1
Fm] + . . . + E[Xn
Fm]
= X1 + . . . + Xm + E[Xm+1] + . . . + E[Xn]
= Sm.
By Theorem 8.14(iv), since Ïƒ(Sm) âŠ‚Fm, we have
E[Sn|Sm] = E
)
E[Sn|Fm]
Sm
*
= E[Sm|Sm] = Sm.
â™¦
Next we show Jensenâ€™s inequality for conditional expectations.
Theorem 8.20 (Jensenâ€™s inequality) Let I âŠ‚R be an interval, let Ï• : I â†’R
be convex and let X be an I-valued random variable on (Î©, A, P). Further, let
E[|X|] < âˆand let F âŠ‚A be a Ïƒ-algebra. Then
âˆâ‰¥E[Ï•(X)|F] â‰¥Ï•(E[X|F]).
Proof For the existence of E[Ï•(X)|F] with values in (âˆ’âˆ, âˆ] note that Ï•(X)âˆ’âˆˆ
L1(P) and see Remark 8.16. By Exercise 8.2.2, we have E[X|F] âˆˆI a.s., hence
Ï•(E[X|F]) is well-deï¬ned.
(Recall from Deï¬nition 1.68 the jargon words â€œalmost surely on Aâ€.) Note that
X = E[X|F] on the event {E[X|F] is a boundary point of I}; hence here the
claim is trivial. Indeed, without loss of generality, assume 0 is the left boundary
of I and A := {E[X|F] = 0}. As X assumes values in I âŠ‚[0, âˆ), we have
0 â‰¤E[X 1A] = E[E[X|F] 1A] = 0; hence X1A = 0. The case of a right boundary
point is similar.
Hence now consider the event B := {E[X|F] is an interior point of I}. For every
interior point x âˆˆI, let D+Ï•(x) be the maximal slope of a tangent of Ï• at x; i.e.,
the maximal number t with Ï•(y) â‰¥(y âˆ’x)t +Ï•(x) for all y âˆˆI (see Theorem 7.7).
For each x âˆˆI â—¦, there exists a P-null set Nx such that, for every Ï‰ âˆˆB \ Nx, we
have
E
)
Ï•(X)|F
*
(Ï‰) â‰¥Ï•(x) + E
)
D+Ï•(x) (X âˆ’x)
F
*
(Ï‰)
= Ï•(x) + D+Ï•(x) E[X|F](Ï‰) âˆ’x =: ÏˆÏ‰(x).
(8.8)
Let V := Q âˆ©I â—¦. Then N := 
xâˆˆV Nx is a P-null set and (8.8) holds for every
Ï‰ âˆˆB \ N and every x âˆˆV .

8.2
Conditional Expectations
201
The map x â†’D+Ï•(x) is right continuous (by Theorem 7.7(iv)). Therefore
x â†’ÏˆÏ‰(x) is also right continuous. Hence, for every Ï‰ âˆˆB \ N, we have
Ï•E[X|F](Ï‰) = ÏˆÏ‰
E[X|F](Ï‰)
â‰¤sup
xâˆˆI â—¦ÏˆÏ‰(x) = sup
xâˆˆV
ÏˆÏ‰(x) â‰¤E
)
Ï•(X)|F
*
(Ï‰).
(8.9)
âŠ“âŠ”
Corollary 8.21 Let p âˆˆ[1, âˆ] and let F âŠ‚A be a sub-Ïƒ-algebra. Then the map
Lp(Î©, A, P) â†’Lp(Î©, F, P),
X â†’E[X|F],
is a contraction (that is, âˆ¥E[X|F]âˆ¥p â‰¤âˆ¥Xâˆ¥p) and thus continuous. Hence, for
X, X1, X2, . . . âˆˆLp(Î©, A, P) with âˆ¥Xn âˆ’Xâˆ¥p
nâ†’âˆ
âˆ’â†’0,
;;E[Xn|F] âˆ’E[X|F]
;;
p
nâ†’âˆ
âˆ’â†’0.
Proof For p âˆˆ[1, âˆ), use Jensenâ€™s inequality with Ï•(x) = |x|p. For p = âˆ, note
that |E[X|F]| â‰¤E[|X||F] â‰¤E[âˆ¥Xâˆ¥âˆ
F] = âˆ¥Xâˆ¥âˆ.
âŠ“âŠ”
Corollary 8.22 Let (Xi, i âˆˆI) be uniformly integrable and let (Fj, j âˆˆJ) be a
family of sub-Ïƒ-algebras of A. Deï¬ne Xi,j := E[Xi
Fj]. Then (Xi,j, (i, j) âˆˆI Ã—
J) is uniformly integrable. In particular, for X âˆˆL1(P), the family (E[X|Fj], j âˆˆ
J) is uniformly integrable.
Proof By Theorem 6.19, there exists a monotone increasing convex function f with
the property that f (x)/x â†’âˆ, x â†’âˆand L := supiâˆˆI E[f (|Xi|)] < âˆ. Then
x â†’f (|x|) is convex; hence, by Jensenâ€™s inequality,
E
)
f (|Xi,j|)
*
= E
)
f
E[Xi |Fj]
*
â‰¤L < âˆ.
Thus (Xi,j, (i, j) âˆˆI Ã— J) is uniformly integrable by Theorem 6.19.
âŠ“âŠ”
Example 8.23 Let Î¼ and Î½ be ï¬nite measures with Î½ â‰ªÎ¼. Let f = dÎ½
@
dÎ¼ be
the Radonâ€“Nikodym derivative and let I = {F âŠ‚A : F is a Ïƒ-algebra}. Consider
the measures Î¼F and Î½F that are restricted to F. Then Î½
CF â‰ªÎ¼
CF (since
in F there are fewer Î¼-null sets); hence the Radonâ€“Nikodym derivative fF :=
dÎ½
CF@dÎ¼
CF exists. Then (fF : F âˆˆI) is uniformly integrable (with respect
to Î¼). (For ï¬nite Ïƒ-algebras F, this was shown in Example 7.39.) Indeed, let P =
Î¼/Î¼(Î©) and Q = Î½/Î¼(Î©). Then fF = dQ
CF
@
dP
CF. For any F âˆˆF, we
thus have E[fF 1F ] =
3
F fF dP = Q(F) =
3
F f dP = E[f 1F ]; hence fF =
E[f |F]. By the preceding corollary, (fF : F âˆˆI) is uniformly integrable with
respect to P and thus also with respect to Î¼. â™¦

202
8
Conditional Expectations
Takeaways The conditional expectation of a random variable X given a Ïƒ-
algebra F is the best prediction on X that can be made given the information
coded in F (at least if X has a second moment). On the technical side,
the conditional expectation is constructed via the Radon-Nikodym theorem.
It shares the main properties of ordinary expectations (linearity, triangle
inequality, monotone and dominated convergence, Jensenâ€™s inequality) and
in addition has the so-called tower property.
Exercise 8.2.1 Show the assertions of Remark 8.16. â™£
Exercise 8.2.2 Let I âŠ‚R be an arbitrary interval and let X âˆˆL1(Î©, A, P) be
a random variable such that X âˆˆI a.s. For F âŠ‚A, show that E[X|F] âˆˆI a.s.
Is this statement still true if we require only Xâˆ’âˆˆL1(Î©, A, P) instead of X âˆˆ
L1(Î©, A, P)? â™£
Exercise 8.2.3 (Bayesâ€™ formula)
Let A âˆˆA and B âˆˆF âŠ‚A. Show that
P[B|A] =
3
B P[A|F] dP
3
P[A|F] dP .
If F is generated by pairwise disjoint sets B1, B2, . . ., then this is exactly Bayesâ€™
formula of Theorem 8.7. â™£
Exercise 8.2.4 Give an example for E[E[X|F]|G] Ì¸= E[E[X|G]|F]. â™£
Exercise 8.2.5 Show the conditional Markov inequality: For monotone increasing
f : [0, âˆ) â†’[0, âˆ) and Îµ > 0 with f (Îµ) > 0,
P)|X| â‰¥Îµ|F* â‰¤E
)
f (|X|)
F
*
f (Îµ)
.
â™£
Exercise 8.2.6 Show the conditional Cauchyâ€“Schwarz inequality: For square inte-
grable random variables X, Y,
E[XY |F]2 â‰¤E[X2|F] E[Y 2|F].
â™£
Exercise 8.2.7 Let X1, . . . , Xn be integrable i.i.d. random variables. Let Sn =
X1 + . . . + Xn. Show that
E[Xi |Sn] = 1
n Sn
for every i = 1, . . . , n.
â™£
Exercise 8.2.8 Let X1 and X2 be independent and exponentially distributed with
parameter Î¸ > 0. Compute E[X1 âˆ§X2|X1]. â™£

8.3
Regular Conditional Distribution
203
Exercise 8.2.9 Let X and Y be real random variables with joint density f and let
h : R â†’R be measurable with E[|h(X)|] < âˆ. Denote by Î» the Lebesgue measure
on R.
(i) Show that almost surely
E[h(X)|Y] =
3
h(x)f (x, Y) Î»(dx)
3
f (x, Y) Î»(dx)
.
(ii) Let X and Y be independent and expÎ¸-distributed for some Î¸ > 0. Compute
E[X|X + Y] and P[X â‰¤x |X + Y] for x â‰¥0. â™£
8.3
Regular Conditional Distribution
Let X be a random variable with values in a measurable space (E, E). With our
machinery, so far we can deï¬ne the conditional probability P[A|X] for ï¬xed A âˆˆA
only. However, we would like to deï¬ne for every x âˆˆE a probability measure
P[ Â· |X = x] such that for any A âˆˆA, we have P[A|X] = P[A|X = x] on
{X = x}. In this section, we show how to do this.
For example, we are interested in a two-stage random experiment. At the ï¬rst
stage, we manipulate a coin at random such that the probability of a success (i.e.,
â€œheadâ€) is X. At the second stage, we toss the coin n times independently with
outcomes Y1, . . . , Yn. Hence the â€œconditional distribution of (Y1, . . . , Yn) given
{X = x}â€ should be (Berx)âŠ—n.
Let X be as above and let Z be a Ïƒ(X)-measurable real random variable. By
the factorization lemma (Corollary 1.97 with f = X and g = Z), there is a map
Ï• : E â†’R such that
Ï• is E â€“ B(R)-measurable
and
Ï•(X) = Z.
(8.10)
If X is surjective, then Ï• is determined uniquely. In this case, we denote Z â—¦Xâˆ’1 :=
Ï• (even if the inverse map Xâˆ’1 itself does not exist).
Deï¬nition 8.24 Let Y
âˆˆL1(P) and X : (Î©, A) â†’(E, E). We deï¬ne the
conditional expectation of Y given X = x by E[Y |X = x] := Ï•(x), where Ï• is
the function from (8.10) with Z = E[Y |X].
Analogously, deï¬ne P[A|X = x] = E[1A
X = x] for A âˆˆA.
For a ï¬xed set B âˆˆA with P[B] > 0, the conditional probability P[ Â· |B] is a
probability measure. Is this true also for P[ Â· |X = x]? The question is a bit tricky
since for every given A âˆˆA, the expression P[A|X = x] is deï¬ned for almost all
x only; that is, up to x in a null set that may, however, depend on A. Since there are
uncountably many A âˆˆA in general, we could not simply unite all the exceptional

204
8
Conditional Expectations
sets for any A. However, if the Ïƒ-algebra A can be approximated by countably many
A sufï¬ciently well, then there is hope.
Our ï¬rst task is to give precise deï¬nitions. Then we present the theorem that
justiï¬es our hope.
Deï¬nition 8.25 (Transition kernel, Markov kernel) Let (Î©1, A1), (Î©2, A2) be
measurable spaces. A map Îº : Î©1 Ã— A2 â†’[0, âˆ] is called a (Ïƒ-)ï¬nite transition
kernel (from Î©1 to Î©2) if:
(i) Ï‰1 â†’Îº(Ï‰1, A2) is A1-measurable for any A2 âˆˆA2.
(ii) A2 â†’Îº(Ï‰1, A2) is a (Ïƒ-)ï¬nite measure on (Î©2, A2) for any Ï‰1 âˆˆÎ©1.
If in (ii) the measure is a probability measure for all Ï‰1 âˆˆÎ©1, then Îº is called a
stochastic kernel or a Markov kernel. If in (ii) we also have Îº(Ï‰1, Î©2) â‰¤1 for
any Ï‰1 âˆˆÎ©1, then Îº is called sub-Markov or substochastic.
Remark 8.26 It is sufï¬cient to check property (i) in Deï¬nition 8.25 for sets A2 from
a Ï€-system E that generates A2 and that either contains Î©2 or a sequence En â†‘Î©2.
Indeed, in this case,
D :=
	
A2 âˆˆA2 : Ï‰1 â†’Îº(Ï‰1, A2) is A1-measurable

is a Î»-system (exercise!). Since E âŠ‚D, by the Ï€â€“Î» theorem (Theorem 1.19), D =
Ïƒ(E) = A2. â™¦
Example 8.27
(i) Let (Î©1, A1) and (Î©2, A2) be discrete measurable spaces and let (Kij) iâˆˆÎ©1
jâˆˆÎ©2
be a matrix with nonnegative entries and ï¬nite row sums
Ki :=

jâˆˆÎ©2
Kij < âˆ
for i âˆˆÎ©1.
Then we can deï¬ne a ï¬nite transition kernel from Î©1 to Î©2 by Îº(i, A) =

jâˆˆA Kij. Îº is stochastic if Ki = 1 for all i âˆˆÎ©1. It is substochastic if
Ki â‰¤1 for all i âˆˆÎ©1.
(ii) If Î¼2 is a ï¬nite measure on Î©2, then Îº(Ï‰1, Â·) â‰¡Î¼2 is a ï¬nite transition kernel.
(iii) Îº(x, Â·) = Poix is a stochastic kernel from [0, âˆ) to N0 (note that x â†’
Poix(A) is continuous and hence measurable for all A âŠ‚N0).
(iv) Let Î¼ be a distribution on Rn and let X be a random variable with PX = Î¼.
Then Îº(x, Â·) = P[X + x âˆˆÂ·] = Î´x âˆ—Î¼ deï¬nes a stochastic kernel from
Rn to Rn. Indeed, the sets (âˆ’âˆ, y], y âˆˆRn form an âˆ©-stable generator of
B(Rn) and x â†’Îº(x, (âˆ’âˆ, y]) = Î¼((âˆ’âˆ, y âˆ’x]) is left continuous and
hence measurable. Hence, by Remark 8.26, x â†’Îº(x, A) is measurable for all
A âˆˆB(Rn). â™¦

8.3
Regular Conditional Distribution
205
Deï¬nition 8.28 Let Y be a random variable with values in a measurable space
(E, E) and let F âŠ‚A be a sub-Ïƒ-algebra. A stochastic kernel ÎºY,F from (Î©, F) to
(E, E) is called a regular conditional distribution of Y given F if
ÎºY,F(Ï‰, B) = P[{Y âˆˆB}|F](Ï‰)
for P-almost all Ï‰ âˆˆÎ© and for all B âˆˆE; that is, if

1B(Y) 1A dP =

ÎºY,F( Â·, B) 1A dP
for all A âˆˆF, B âˆˆE.
(8.11)
Consider the special case where F = Ïƒ(X) for a random variable X (with values
in an arbitrary measurable space (Eâ€², Eâ€²)). Then the stochastic kernel
(x, A) â†’ÎºY,X(x, A) = P[{Y âˆˆA}|X = x] = ÎºY,Ïƒ(X)

Xâˆ’1(x), A

(the function from the factorization lemma with an arbitrary value for x Ì¸âˆˆX(Î©)) is
called a regular conditional distribution of Y given X.
Theorem 8.29 (Regular conditional distributions in R) Let Y
: (Î©, A) â†’

R, B(R)

be real-valued. Then there exists a regular conditional distribution ÎºY,F
of Y given F.
Proof The strategy of the proof consists in constructing a measurable version of
the distribution function of the conditional distribution of Y by ï¬rst deï¬ning it for
rational values (up to a null set) and then extending it to the real numbers.
For r âˆˆQ, let F(r, Â·) be a version of the conditional probability P[Y
âˆˆ
(âˆ’âˆ, r]|F]. For r â‰¤s, clearly 1{Yâˆˆ(âˆ’âˆ,r]} â‰¤1{Yâˆˆ(âˆ’âˆ,s]}. Hence, by The-
orem 8.14(ii) (monotonicity of the conditional expectation), there is a null set
Ar,s âˆˆF with
F(r, Ï‰) â‰¤F(s, Ï‰)
for all Ï‰ âˆˆÎ© \ Ar,s.
(8.12)
By Theorem 8.14(viii) (dominated convergence), there are null sets Br âˆˆF, r âˆˆQ,
and C âˆˆF such that
lim
nâ†’âˆF

r + 1
n, Ï‰

= F(r, Ï‰)
for all Ï‰ âˆˆÎ© \ Br
(8.13)
as well as
inf
nâˆˆN F(âˆ’n, Ï‰) = 0
and
sup
nâˆˆN
F(n, Ï‰) = 1
for all Ï‰ âˆˆÎ© \ C.
(8.14)
Let N :=
 
r,sâˆˆQ Ar,s

âˆª
 
râˆˆQ Br

âˆªC. For Ï‰ âˆˆÎ© \ N, deï¬ne
ËœF(z, Ï‰) := inf
	
F(r, Ï‰) : r âˆˆQ, r > z

for all z âˆˆR.

206
8
Conditional Expectations
By construction, ËœF( Â·, Ï‰) is monotone increasing and right continuous. By (8.12)
and (8.13), we have
ËœF(z, Ï‰) = F(z, Ï‰)
for all z âˆˆQ and Ï‰ âˆˆÎ© \ N.
(8.15)
Therefore, by (8.14), ËœF( Â·, Ï‰) is a distribution function for any Ï‰ âˆˆÎ© \ N. For Ï‰ âˆˆ
N, deï¬ne ËœF( Â·, Ï‰) = F0, where F0 is an arbitrary but ï¬xed distribution function.
For any Ï‰ âˆˆÎ©, let Îº(Ï‰, Â·) be the probability measure on (Î©, A) with
distribution function ËœF( Â·, Ï‰). Then, for r âˆˆQ and B = (âˆ’âˆ, r],
Ï‰ â†’Îº(Ï‰, B) = F(r, Ï‰) 1Nc(Ï‰) + F0(r) 1N(Ï‰)
(8.16)
is F-measurable. Now {(âˆ’âˆ, r], r âˆˆQ} is a Ï€-system that generates B(R). By
Remark 8.26, measurability holds for all B âˆˆB(R) and hence Îº is identiï¬ed as a
stochastic kernel.
We still have to show that Îº is a version of the conditional distribution. For A âˆˆ
F, r âˆˆQ and B = (âˆ’âˆ, r], by (8.16),

A
Îº(Ï‰, B) P[dÏ‰] =

A
P
)
Y âˆˆB|F
*
dP = P
)
A âˆ©{Y âˆˆB}
*
.
As functions of B, both sides are ï¬nite measures on B(R) that coincide on the âˆ©-
stable generator
	
(âˆ’âˆ, r], r âˆˆQ

. By the uniqueness theorem (Lemma 1.42), we
thus have equality for all B âˆˆB(R). Hence P-a.s. Îº( Â·, B) = P[Y âˆˆB|F] and thus
Îº = ÎºY,F.
âŠ“âŠ”
Example 8.30 Let Z1, Z2 be independent Poisson random variables with parame-
ters Î»1, Î»2 â‰¥0. One can show (exercise!) that (with Y = Z1 and X = Z1 + Z2)
P[Z1 = k
Z1 + Z2 = n] = bn,p(k)
for k = 0, . . . , n,
where p =
Î»1
Î»1+Î»2 . â™¦
This example could still be treated by elementary means. The full strength of the
result is displayed in the following examples.
Example 8.31 Let X and Y be real random variables with joint density f (with
respect to Lebesgue measure Î»2 on R2). For x âˆˆR, deï¬ne
fX(x) =

R
f (x, y) Î»(dy).

8.3
Regular Conditional Distribution
207
Clearly, fX(x) > 0 for PX-a.a. x âˆˆR and f âˆ’1
X
is the density of the absolutely
continuous part of the Lebesgue measure Î» with respect to PX. The regular
conditional distribution of Y given X has density
P[Y âˆˆdy |X = x]
dy
= fY|X(x, y) := f (x, y)
fX(x)
for PX[dx]-a.a. x âˆˆR.
(8.17)
Indeed, by Fubiniâ€™s theorem (Theorem 14.19), the map x â†’3
B fY|X(x, y) Î»(dy) is
measurable for all B âˆˆB(R) and for A, B âˆˆB(R), we have

A
P[X âˆˆdx]

B
fY|X(x, y) Î»(dy)
=

A
P[X âˆˆdx] fX(x)âˆ’1

B
f (x, y) Î»(dy)
=

A
Î»(dx)

B
f (x, y) Î»(dy)
=

AÃ—B
f dÎ»2 = P[X âˆˆA, Y âˆˆB].
â™¦
Example 8.32 Let Î¼1, Î¼2 âˆˆR, Ïƒ1, Ïƒ2 > 0 and let Z1, Z2 be independent and
NÎ¼i,Ïƒ 2
i -distributed (i = 1, 2). Then there exists a regular conditional distribution
P[Z1 âˆˆÂ· |Z1 + Z2 = x]
for x âˆˆR.
If we deï¬ne X = Z1 + Z2 and Y = Z1, then (X, Y) âˆ¼NÎ¼,Î£ is bivariate
normally distributed with covariance matrix Î£ :=
Ïƒ 2
1 + Ïƒ 2
2 Ïƒ 2
1
Ïƒ 2
1
Ïƒ 2
1

and with Î¼ :=
Î¼1 + Î¼2
Î¼1

. Note that
Î£âˆ’1 =

Ïƒ 2
1 Ïƒ 2
2
âˆ’1
 Ïƒ 2
1
âˆ’Ïƒ 2
1
âˆ’Ïƒ 2
1 Ïƒ 2
1 + Ïƒ 2
2

= (Ïƒ 2
1 Ïƒ 2
2 )âˆ’1 BT B,

208
8
Conditional Expectations
where B =
Ïƒ1 âˆ’Ïƒ1
0
Ïƒ2

. Hence (X, Y) has the density (see Example 1.105(ix))
f (x, y) = det(2Ï€ Î£)âˆ’1/2 exp

âˆ’
1
2Ïƒ 2
1 Ïƒ 2
2
;;;;B
x âˆ’(Î¼1 + Î¼2)
y âˆ’Î¼1
;;;;
2
=

4Ï€2Ïƒ 2
1 Ïƒ 2
2
âˆ’1/2 exp

âˆ’Ïƒ 2
1 (y âˆ’(x âˆ’Î¼2))2 + Ïƒ 2
2 (y âˆ’Î¼1)2
2Ïƒ 2
1 Ïƒ 2
2

= Cx exp

âˆ’(y âˆ’Î¼x)2/2Ïƒ 2
x

.
Here Cx is a normalising constant and
Î¼x = Î¼1 +
Ïƒ 2
1
Ïƒ 2
1 + Ïƒ 2
2
(x âˆ’Î¼1 âˆ’Î¼2)
and
Ïƒ 2
x =
Ïƒ 2
1 Ïƒ 2
2
Ïƒ 2
1 + Ïƒ 2
2
.
By (8.17), P[Z1 âˆˆÂ· |Z1 + Z2 = x] has the density
y â†’fY|X(x, y) =
Cx
fX(x) exp

âˆ’(y âˆ’Î¼x)2
2Ïƒ 2x

,
hence
P[Z1 âˆˆÂ· |Z1 + Z2 = x] = NÎ¼x,Ïƒ 2x for almost all x âˆˆR.
â™¦
Example 8.33 If X and Y are independent real random variables, then for PX-
almost all x âˆˆR
P[X + Y âˆˆÂ· |X = x] = Î´x âˆ—PY .
â™¦
The situation is not completely satisfying as we have made the very restrictive
assumption that Y is real-valued. Originally we were also interested in the situation
where Y takes values in Rn or in even more general spaces. We now extend the
result to a larger class of ranges for Y.
Deï¬nition 8.34 Two measurable spaces (E, E) and (Eâ€², Eâ€²) are called isomorphic
if there exists a bijective map Ï• : E â†’Eâ€² such that Ï• is E â€“ Eâ€²-measurable and
the inverse map Ï•âˆ’1 is Eâ€² â€“ E-measurable. Then we say that Ï• is an isomorphism
of measurable spaces. If in addition Î¼ and Î¼â€² are measures on (E, E) and (Eâ€², Eâ€²)
and if Î¼â€² = Î¼ â—¦Ï•âˆ’1, then Ï• is an isomorphism of measure spaces, and the measure
spaces (E, E, Î¼) and (Eâ€², Eâ€², Î¼â€²) are called isomorphic.
Deï¬nition 8.35 A measurable space (E, E) is called a Borel space if there exists a
Borel set B âˆˆB(R) such that (E, E) and (B, B(B)) are isomorphic.

8.3
Regular Conditional Distribution
209
A separable topological space whose topology is induced by a complete metric is
called a Polish space. In particular, Rd, Zd, RN, (C([0, 1]), âˆ¥Â· âˆ¥âˆ) and so forth are
Polish. Closed subsets of Polish spaces are again Polish. We come back to Polish
spaces in the context of convergence of measures in Chap. 13. Without proof, we
present the following topological result (see, e.g., [37, Theorem 13.1.1]).
Theorem 8.36 Let E be a Polish space with Borel Ïƒ-algebra E. Then (E, E) is a
Borel space.
Theorem 8.37 (Regular conditional distribution) Let F
âŠ‚A be a sub-Ïƒ-
algebra. Let Y be a random variable with values in a Borel space (E, E) (hence,
for example, E Polish, E = Rd, E = Râˆ, E = C([0, 1]), etc.). Then there exists a
regular conditional distribution ÎºY,F of Y given F.
Proof Let B âˆˆB(R) and let Ï• : E â†’B be an isomorphism of measurable spaces.
By Theorem 8.29, we obtain the regular conditional distribution ÎºY â€²,F of the real
random variable Y â€² = Ï• â—¦Y. Now deï¬ne ÎºY,F(Ï‰, A) = ÎºY â€²,F(Ï‰, Ï•(A)) for A âˆˆE.
âŠ“âŠ”
To conclude, we pick up again the example with which we started. Now we
can drop the quotation marks from the statement and write it down formally.
Hence, let X be uniformly distributed on [0, 1]. Given X = x, let (Y1, . . . , Yn)
be independent and Berx-distributed. Deï¬ne Y = (Y1, . . . , Yn). By Theorem 8.37
(with E = {0, 1}n âŠ‚Rn), a regular conditional distribution exists:
ÎºY,X(x, Â·) = P[Y âˆˆÂ· |X = x]
for x âˆˆ[0, 1].
Indeed, for almost all x âˆˆ[0, 1],
P[Y âˆˆÂ· |X = x] = (Berx)âŠ—n.
Theorem 8.38 Let X be a random variable on (Î©, A, P) with values in a Borel
space (E, E). Let F âŠ‚A be a Ïƒ-algebra and let ÎºX,F be a regular conditional
distribution of X given F. Further, let f : E â†’R be measurable and E[|f (X)|] <
âˆ. Then
E[f (X)|F](Ï‰) =

f (x) ÎºX,F(Ï‰, dx)
for P-almost all Ï‰.
(8.18)
Proof We check that the right-hand side in (8.18) has the properties of the
conditional expectation.
It is enough to consider the case f â‰¥0. By approximating f by simple functions,
we see that the right-hand side in (8.18) is F-measurable (see Lemma 14.23 for a
formal argument). Hence, by Theorem 1.96, there exist sets A1, A2, . . . âˆˆE and
numbers Î±1, Î±2, . . . â‰¥0 such that
gn :=
n

i=1
Î±i 1Ai
nâ†’âˆ
âˆ’â†’f.

210
8
Conditional Expectations
Now, for any n âˆˆN and B âˆˆF,
E[gn(X) 1B] =
n

i=1
Î±i P[{X âˆˆAi} âˆ©B]
=
n

i=1
Î±i

B
P[{X âˆˆAi}|F] P[dÏ‰]
=
n

i=1
Î±i

B
ÎºX,F(Ï‰, Ai) P[dÏ‰]
=

B
n

i=1
Î±i ÎºX,F(Ï‰, Ai) P[dÏ‰]
=

B

gn(x) ÎºX,F(Ï‰, dx)

P[dÏ‰].
By the monotone convergencetheorem, for almost all Ï‰, the inner integral converges
to
3
f (x)ÎºX,F(Ï‰, dx). Applying the monotone convergence theorem once more,
we get
E[f (X) 1B] =
lim
nâ†’âˆE[gn(X) 1B] =

B

f (x) ÎºX,F(Ï‰, dx) P[dÏ‰].
âŠ“âŠ”
Takeaways Consider the conditional probability of some event B given a
Ïƒ-algebra. If it is chosen such that as a function of B it is a probability
measure (almost surely), then it is called a regular version of the conditional
probabilities. The existence is nontrivial as there can be uncountably many
events B and the conditional probability is deï¬ned only up to null sets. So it
is an important theorem that a regular version of the conditional probabilities
exists at least on Polish spaces (like Rd).
Exercise 8.3.1 Let (E, E) be a Borel space and let Î¼ be an atom-free measure (that
is, Î¼({x}) = 0 for any x âˆˆE). Show that for any A âˆˆE and any n âˆˆN, there exist
pairwise disjoint sets A1, . . . , An âˆˆE with n
k=1 Ak = A and Î¼(Ak) = Î¼(A)/n
for any k = 1, . . . , n. â™£
Exercise 8.3.2 Let p, q âˆˆ(1, âˆ) with
1
p + 1
q = 1 and let X âˆˆLp(P) and
Y âˆˆLq(Î¼). Let F âŠ‚A be a Ïƒ-algebra. Use the preceding theorem to show the
conditional version of HÃ¶lderâ€™s inequality:
E
)
|XY|
F
*
â‰¤E
)
|X|p F
*1/p E
)
|Y|q F
*1/q
almost surely.
â™£

8.3
Regular Conditional Distribution
211
Exercise 8.3.3 Assume the random variable (X, Y) is uniformly distributed on the
disc B := {(x, y) âˆˆR2 : x2 + y2 â‰¤1} and on [âˆ’1, 1]2, respectively.
(i) In both cases, determine the conditional distribution of Y given X = x.
(ii) Let R :=
âˆš
X2 + Y 2 and Î˜ = arctan(Y/X). In both cases, determine the
conditional distribution of Î˜ given R = r. â™£
Exercise 8.3.4 Let A âŠ‚Rn be a Borel measurable set of ï¬nite Lebesgue measure
Î»(A) âˆˆ(0, âˆ) and let X be uniformly distributed on A (see Example 1.75). Let
B âŠ‚A be measurable with Î»(B) > 0. Show that the conditional distribution of X
given {X âˆˆB} is the uniform distribution on B. â™£
Exercise 8.3.5 (Borelâ€™s paradox) Consider the Earth as a ball (as widely accepted
nowadays). Let X be a random point that is uniformly distributed on the surface.
Let Î˜ be the longitude and let Î¦ be the latitude of X. A little differently from the
usual convention, assume that Î˜ takes values in [0, Ï€) and Î¦ in [âˆ’Ï€, Ï€). Hence,
for ï¬xed Î˜, a complete great circle is described when Î¦ runs through its domain.
Now, given Î˜, is Î¦ uniformly distributed on [âˆ’Ï€, Ï€)? One could conjecture that
any point on the great circle is equally likely. However, this is not the case! If we
thicken the great circle slightly such that its longitudes range from Î˜ to Î˜ + Îµ (for
a small Îµ), on the equator it is thicker (measured in meters) than at the poles. If we
let Îµ â†’0, intuitively we should get the conditional probabilities as proportional to
the thickness (in metres).
(i) Show that P[{Î¦ âˆˆÂ·}|Î˜ = Î¸] for almost all Î¸ has the density 1
4| cos(Ï†)| for
Ï† âˆˆ[âˆ’Ï€, Ï€).
(ii) Show that P[{Î˜ âˆˆÂ·}|Î¦ = Ï†] = U[0,Ï€) for almost all Ï†.
Hint: Show that Î˜ and Î¦ are independent, and compute the distributions of Î˜
and Î¦. â™£
Exercise 8.3.6 (Rejection sampling for generating random variables) Let E be
a countable set and let P and Q be probability measures on E. Assume there is a
c > 0 with
f (e) := Q({e})
P({e}) â‰¤c
for all e âˆˆE with P({e}) > 0.
Let X1, X2, . . . be independent random variables with distribution P. Let
U1, U2, . . . be i.i.d. random variables that are independent of X1, X2, . . . and
that are uniformly distributed on [0, 1]. Let N be the smallest (random) nonnegative
integer n such that Un â‰¤f (Xn)/c and deï¬ne Y := XN.
Show that Y has distribution Q.
Remark This method for generating random variables with a given distribution Q
is called rejection sampling, as it can also be described as follows. The random
variable X1 is a proposal for the value of Y. This proposal is accepted with
probability f (X1)/c and is rejected otherwise. If the ï¬rst proposal is rejected, the
game starts afresh with proposal X2 and so on. â™£

212
8
Conditional Expectations
Exercise 8.3.7 Let E be a Polish space and let P, Q âˆˆM1(R). Let c > 0 with
f := dQ
dP â‰¤c P-almost surely. Show the statement analogous to Exercise 8.3.6. â™£
Exercise 8.3.8 Show that (R, B(R)) and

Rn, B(Rn)

are isomorphic. Conclude
that every Borel set B âˆˆB(Rn) is a Borel space. â™£

Chapter 9
Martingales
One of the most important concepts of modern probability theory is the martingale,
which formalizes the notion of a fair game. In this chapter, we ï¬rst lay the
foundations for the treatment of general stochastic processes. We then introduce
martingales and the discrete stochastic integral. We close with an application to a
model from mathematical ï¬nance.
9.1
Processes, Filtrations, Stopping Times
We introduce the fundamental technical terms for the investigation of stochastic
processes (including martingales). In order to be able to recycle the terms later in a
more general context, we go for greater generality than is necessary for the treatment
of martingales only.
In the following, let (E, Ï„) be a Polish space with Borel Ïƒ-algebra E. Further,
let (Î©, F, P) be a probability space and let I âŠ‚R be arbitrary. We are mostly
interested in the cases I = N0, I = Z, I = [0, âˆ) and I an interval.
Deï¬nition 9.1 (Stochastic process) Let I âŠ‚R. A family of random variables X =
(Xt, t âˆˆI) (on (Î©, F, P)) with values in (E, E) is called a stochastic process with
index set (or time set) I and range E.
Remark 9.2 Sometimes families of random variables with more general index sets
are called stochastic processes. We come back to this with the Poisson point process
in Chap. 24. â™¦
Remark 9.3 Following a certain tradition, we will often denote a stochastic process
by X = (Xt)tâˆˆI if we want to emphasize the â€œtime evolutionâ€ aspect rather than the
formal notion of a family of random variables. Formally, both objects are of course
the same. â™¦
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_9
213

214
9
Martingales
Example 9.4 Let I = N0 and let (Yn, n âˆˆN) be a family of i.i.d. Rad1/2-random
variables on a probability space (Î©, F, P); that is, random variables with
P[Yn = 1] = P[Yn = âˆ’1] = 1
2.
Let E = Z (with the discrete topology) and let
Xt =
t
n=1
Yn
for all t âˆˆN0.
(Xt, t âˆˆN0) is called a symmetric simple random walk on Z. â™¦
Example 9.5 The Poisson process X = (Xt)tâ‰¥0 with intensity Î± > 0 (see Sect. 5.5)
is a stochastic process with range N0. â™¦
We introduce some further terms.
Deï¬nition 9.6 If X is a random variable (or a stochastic process), we write L[X] =
PX for the distribution of X. If G âŠ‚F is a Ïƒ-algebra, then we write L[X|G] for
the regular conditional distribution of X given G.
Deï¬nition 9.7 An E-valued stochastic process X = (Xt)tâˆˆI is called
(i) real-valued if E = R,
(ii) a process with independent increments if X is real-valued and for all n âˆˆN
and all t0, . . . , tn âˆˆI with t0 < t1 < . . . < tn, we have that
(Xti âˆ’Xtiâˆ’1)i=1,...,n is independent,
(iii) a Gaussian process if X is real-valued and for all n âˆˆN and t1, . . . , tn âˆˆI,
(Xt1, . . . , Xtn) is n-dimensional normally distributed, and
(iv) integrable (respectively square integrable) if
X
is real-valued and
E[|Xt|] < âˆ(respectively E[(Xt)2] < âˆ) for all t âˆˆI.
Now assume that I âŠ‚R is closed under addition. Then X is called
(v) stationary if L
)
(Xs+t)tâˆˆI
*
= L
)
(Xt)tâˆˆI
*
for all s âˆˆI, and
(vi) a process with stationary increments if X is real-valued and
L
)
Xs+t+r âˆ’Xt+r
*
= L
)
Xs+r âˆ’Xr
*
for all r, s, t âˆˆI.
(If 0 âˆˆI, then it is enough to consider r = 0.)

9.1
Processes, Filtrations, Stopping Times
215
Example 9.8
(i) The Poisson process with intensity Î¸ and the random walk on Z are processes
with stationary independent increments.
(ii) If Xt, t âˆˆI, are i.i.d. random variables, then (Xt)tâˆˆI is stationary.
(iii) Let (Xn)nâˆˆZ be real-valued and stationary and let k âˆˆN and c0, . . . , ck âˆˆR.
Deï¬ne
Yn :=
k

i=0
ciXnâˆ’i.
Then Y = (Yn)nâˆˆZ is a stationary process. If c0, . . . , ck â‰¥0 and c0+. . .+ck =
1, then Y is called the moving average of X (with weights c0, . . . , ck). â™¦
The following two deï¬nitions make sense also for more general index sets I that
are partially ordered. However, we restrict ourselves to the case I âŠ‚R.
Deï¬nition 9.9 (Filtration)
Let F = (Ft, t âˆˆI) be a family of Ïƒ-algebras with
Ft âŠ‚F for all t âˆˆI. F is called a ï¬ltration if Fs âŠ‚Ft for all s, t âˆˆI with s â‰¤t.
Deï¬nition 9.10 A stochastic process X = (Xt, t âˆˆI) is called adapted to the
ï¬ltration F if Xt is Ft-measurable for all t âˆˆI. If Ft = Ïƒ(Xs, s â‰¤t) for all t âˆˆI,
then we denote by F = Ïƒ(X) the ï¬ltration that is generated by X.
Remark 9.11 Clearly, a stochastic process is always adapted to the ï¬ltration it
generates. Hence the generated ï¬ltration is the smallest ï¬ltration to which the
process is adapted. â™¦
Deï¬nition 9.12 (Predictable) Let I = N0 or I = N. A stochastic process X =
(Xn, n âˆˆI) is called predictable (or previsible) with respect to the ï¬ltration F =
(Fn, n âˆˆN0) if X0 is constant (if I = N0) and if for every n âˆˆN,
Xn is Fnâˆ’1-measurable.
Example 9.13 Let I = N0 and let Y1, Y2, . . . be real random variables. For n âˆˆN0,
deï¬ne Xn := n
m=1 Ym. Let
F0 = {âˆ…, Î©}
and
Fn = Ïƒ(Y1, . . . , Yn)
for n âˆˆN.
Then F = (Fn, n âˆˆN0) = Ïƒ(Y) is the ï¬ltration generated by Y = (Yn)nâˆˆN and X
is adapted to F; hence Ïƒ(X) âŠ‚F. Clearly, (Y1, . . . , Yn) is measurable with respect
to Ïƒ(X1, . . . , Xn); hence Ïƒ(Y) âŠ‚Ïƒ(X), and thus also F = Ïƒ(X).
Now let 
Xn := n
m=1 1[0,âˆ)(Ym). Then 
X is also adapted to F; however, in
general, F â«ŒÏƒ(
X). â™¦
Example 9.14 Let I = N0 and let D1, D2, . . . be i.i.d. Rad1/2-distributed random
variables (that is, P[Di = âˆ’1] = P[Di = 1] = 1
2 for all i âˆˆN). Let D = (Di)iâˆˆN
and F = Ïƒ(D). We interpret Di as the result of a bet that gives a gain or loss of one

216
9
Martingales
euro for every euro we put at stake. Just before each gamble we decide how much
money we bet. Let Hn be the number of euros to bet in the nth gamble. Clearly, Hn
may only depend on the results of the gambles that happened earlier, but not on Dm
for any m â‰¥n. To put it differently, there must be a function Fn : {âˆ’1, 1}nâˆ’1 â†’
N such that Hn = Fn(D1, . . . , Dnâˆ’1). (For example, for the Petersburg game
(Example 4.22) we had Fn(x1, . . . , xnâˆ’1) = 2nâˆ’1 1{x1=x2=...=xnâˆ’1=0}.) Hence
H is predictable. On the other hand, any predictable H has the form Hn =
Fn(D1, . . . , Dnâˆ’1), n âˆˆN, for certain functions Fn : {âˆ’1, 1}nâˆ’1 â†’N. Hence
any predictable H is an admissible gambling strategy. â™¦
Deï¬nition 9.15 (Stopping time) A random variable Ï„ with values in I âˆª{âˆ} is
called a stopping time (with respect to F) if for any t âˆˆI
{Ï„ â‰¤t} âˆˆFt.
The idea is that Ft reï¬‚ects the knowledge of an observer at time t. Whether or
not {Ï„ â‰¤t} is true can thus be determined on the basis of the information available
at time t.
Theorem 9.16 Let I be countable. Ï„ is a stopping time if and only if {Ï„ = t} âˆˆFt
for all t âˆˆI.
Proof This is left as an exercise!
âŠ“âŠ”
Example 9.17 Let I = N0 (or, more generally, let I âŠ‚[0, âˆ) be right-discrete;
that is, t < inf I âˆ©(t, âˆ) for all t â‰¥0, and hence I in particular is countable)
and let K âŠ‚R be measurable. Let X be an adapted real-valued stochastic process.
Consider the ï¬rst time that X is in K:
Ï„K := inf{t âˆˆI : Xt âˆˆK}.
It is intuitively clear that Ï„K should be a stopping time since we can determine by
observation up to time t whether {Ï„K â‰¤t} occurs. Formally, we argue that {Xs âˆˆ
K} âˆˆFs âŠ‚Ft for all s â‰¤t. Hence also the countable union of these sets is in Ft:
{Ï„K â‰¤t} =

sâˆˆIâˆ©[0,t]
{Xs âˆˆK} âˆˆFt.
Consider now the random time Ï„ := sup{t âˆˆI : Xt âˆˆK} of the last visit of X
to K. For a ï¬xed time t, on the basis of previous observations, we cannot determine
whether X is already in K for the last time. For this we would have to rely on
prophecy. Hence, in general, Ï„ is not a stopping time. â™¦
Lemma 9.18 Let I âŠ‚[0, âˆ) be closed under addition and let Ïƒ and Ï„ be stopping
times. Then:
(i) Ïƒ âˆ¨Ï„ and Ïƒ âˆ§Ï„ are stopping times.
(ii) If Ïƒ, Ï„ â‰¥0, then Ïƒ + Ï„ is also a stopping time.
(iii) If s â‰¥0, then Ï„ + s is a stopping time. However, in general, Ï„ âˆ’s is not.

9.1
Processes, Filtrations, Stopping Times
217
Before we present the (simple) formal proof, we state that in particular (i) and (iii)
are properties we would expect of stopping times. With (i), the interpretation is
clear. For (iii), note that Ï„ âˆ’s peeks into the future by s time units (in fact, {Ï„ âˆ’s â‰¤
t} âˆˆFt+s), while Ï„ + s looks back s time units. For stopping times, however, only
retrospection is allowed.
Proof
(i) For t âˆˆI, we have {Ïƒ âˆ¨Ï„ â‰¤t} = {Ïƒ â‰¤t} âˆ©{Ï„ â‰¤t} âˆˆFt and {Ïƒ âˆ§Ï„ â‰¤t} =
{Ïƒ â‰¤t} âˆª{Ï„ â‰¤t} âˆˆFt.
(ii) Let t âˆˆI. By (9.18), Ï„ âˆ§t and Ïƒ âˆ§t are stopping times for any t âˆˆI. In
particular, {Ï„ âˆ§t â‰¤s} âˆˆFs âŠ‚Ft for any s â‰¤t. On the other hand, we have
Ï„ âˆ§t â‰¤s for s > t. Hence Ï„ â€² := (Ï„ âˆ§t)+1{Ï„>t} and Ïƒ â€² := (Ïƒ âˆ§t)+1{Ïƒ>t} (and
thus Ï„ â€²+Ïƒ â€²) are Ft-measurable. We conclude {Ï„+Ïƒ â‰¤t} = {Ï„ â€²+Ïƒ â€² â‰¤t} âˆˆFt.
(iii) For Ï„ + s, this is a consequence of (9.18) (with the stopping time Ïƒ â‰¡s). For
Ï„ âˆ’s, since Ï„ is a stopping time, we have {Ï„ âˆ’s â‰¤t} = {Ï„ â‰¤t + s} âˆˆFt+s.
However, in general, Ft+s is a strict superset of Ft; hence Ï„âˆ’s is not a stopping
time.
âŠ“âŠ”
Deï¬nition 9.19 Let Ï„ be a stopping time. Then
FÏ„ :=
	
A âˆˆF : A âˆ©{Ï„ â‰¤t} âˆˆFt for any t âˆˆI

is called the Ïƒ-algebra of Ï„-past.
Example 9.20 Let I
=
N0 (or let I
âŠ‚
[0, âˆ) be right-discrete; compare
Example 9.17) and let X be an adapted real-valued stochastic process. Let K âˆˆR
and let Ï„ = inf{t : Xt â‰¥K} be the stopping time of ï¬rst entrance in [K, âˆ).
Consider the events A = {sup{Xt : t âˆˆI} > K âˆ’5} and B = {sup{Xt : t âˆˆI} >
K + 5}.
Clearly, {Ï„ â‰¤t} âŠ‚A for all t âˆˆI; hence A âˆ©{Ï„ â‰¤t} = {Ï„ â‰¤t} âˆˆFt. Thus
A âˆˆFÏ„. However, in general, B /âˆˆFÏ„ since up to time Ï„, we cannot decide whether
X will ever exceed K + 5. â™¦
Lemma 9.21 If Ïƒ and Ï„ are stopping times with Ïƒ â‰¤Ï„, then FÏƒ âŠ‚FÏ„.
Proof Let A âˆˆFÏƒ and t âˆˆI. Then A âˆ©{Ïƒ â‰¤t} âˆˆFt. Now {Ï„ â‰¤t} âˆˆFt since Ï„
is a stopping time. Since Ïƒ â‰¤Ï„, we thus get
A âˆ©{Ï„ â‰¤t} =

A âˆ©{Ïƒ â‰¤t}

âˆ©{Ï„ â‰¤t} âˆˆFt.
âŠ“âŠ”
Deï¬nition 9.22 If Ï„ < âˆis a stopping time, then we deï¬ne XÏ„(Ï‰) := XÏ„(Ï‰)(Ï‰).
Lemma 9.23 Let I be countable, let X be adapted and let Ï„ < âˆbe a stopping
time. Then XÏ„ is measurable with respect to FÏ„.

218
9
Martingales
Proof Let A be measurable and t âˆˆI. Hence {Ï„ = s} âˆ©Xâˆ’1
s (A) âˆˆFs âŠ‚Ft for all
s â‰¤t. Thus
Xâˆ’1
Ï„ (A) âˆ©{Ï„ â‰¤t} =

sâˆˆI
sâ‰¤t

{Ï„ = s} âˆ©Xâˆ’1
s (A)

âˆˆFt.
âŠ“âŠ”
For uncountable I and for ï¬xed Ï‰, in general, the map I â†’E, t â†’Xt(Ï‰) is
not measurable; hence neither is the composition XÏ„ always measurable. Here one
needs assumptions on the regularity of the paths t â†’Xt(Ï‰); for example, right
continuity. We come back to this point in Chap. 21 and leave this as a warning for
the time being.
Takeaways We have got acquainted to the notions stochastic process, ï¬ltra-
tion, adapted, stopping time, and Ïƒ-algebra of Ï„-past. These concepts form
the basic vocabulary for the description of stochastic processes, in particular
martingales, in the subsequent sections.
9.2
Martingales
Everyone who does not own a casino would agree without hesitation that the
successive payment of gains Y1, Y2, . . ., such that Y1, Y2, . . . are i.i.d. with E[Y1] =
0, could be considered a fair game consisting of consecutive rounds. In this case, the
process X of partial sums Xn = Y1 + . . . + Yn is integrable and E[Xn
Fm] = Xm
if m < n (where F = Ïƒ(X)). We want to use this equation for the conditional
expectations as the deï¬ning equation for a fair game that in the following will be
called a martingale. Note that, in particular, this deï¬nition does not require that the
individual payments be independent or identically distributed. This makes the notion
quite a bit more ï¬‚exible. The momentousness of the following concept will become
manifest only gradually.
Deï¬nition 9.24 Let (Î©, F, P) be a probability space, I âŠ‚R, and let F be a
ï¬ltration. Let X = (Xt)tâˆˆI be a real-valued, adapted stochastic process with
E[|Xt|] < âˆfor all t âˆˆI. X is called (with respect to F) a
martingale
if E[Xt
Fs] = Xs for all s, t âˆˆI with t > s,
submartingale
if E[Xt
Fs] â‰¥Xs for all s, t âˆˆI with t > s,
supermartingale
if E[Xt
Fs] â‰¤Xs for all s, t âˆˆI with t > s.

9.2
Martingales
219
Remark 9.25 Clearly, for a martingale, the map t
â†’E[Xt] is constant, for
submartingales it is monotone increasing and for supermartingales it is monotone
decreasing. â™¦
Remark 9.26 The etymology of the term martingale has not been resolved com-
pletely. The French la martingale (originally ProvenÃ§al martegalo, named after
the town Martiques) in equitation means â€œa piece of rein used in jumping and
cross country ridingâ€. Sometimes the ramiï¬ed shape, in particular of the running
martingale (French la martingale Ã  anneaux), is considered as emblematic for the
doubling strategy in the Petersburg game.
This doubling strategy itself is the second meaning of la martingale. Starting
here, a shift in the meaning towards the mathematical notion seems plausible. A
different derivation, in contrast to the appearance, is based on the function of the
rein, which is to â€œcheck the upward movement of the horseâ€™s headâ€. Thus the notion
of a martingale might ï¬rst have been used for general gambling strategies (checking
the movements of chance) and later for the doubling strategy in particular. â™¦
Remark 9.27 If I = N, I = N0 or I = Z, then it is enough to consider at each
instant s only t = s +1. In fact, by the tower property of the conditional expectation
(Theorem 8.14(iv)), we get
E[Xs+2
Fs] = E)E[Xs+2
Fs+1]
Fs
*.
Thus, if the deï¬ning equality (or inequality) holds for any time step of size one, by
induction it holds for all times. â™¦
Remark 9.28 If we do not explicitly mention the ï¬ltration F, we tacitly assume that
F is generated by X; that is, Ft = Ïƒ(Xs, s â‰¤t). â™¦
Remark 9.29 Let F and Fâ€² be ï¬ltrations with Ft âŠ‚Fâ€²
t for all t, and let X be an
Fâ€²-(sub-, super-) martingale that is adapted to F. Then X is also a (sub-, super-)
martingale with respect to the smaller ï¬ltration F. Indeed, for s < t and for the case
of a submartingale,
E[Xt
Fs] = E[E[Xt
Fâ€²
s]
Fs] â‰¥E[Xs
Fs] = Xs.
In particular, an F-(sub-, super-) martingale X is always a (sub-, super-) martingale
with respect to its own ï¬ltration Ïƒ(X). â™¦
Reï¬‚ection If X is a martingale with respect to some ï¬ltration F, then X is adapted
to any larger ï¬ltration Fâ€² âŠƒF but it is not necessarily an Fâ€²-martingale. Why? â™ 
Example 9.30 Let Y1, . . . , YN be independent random variables with E[Yt] = 0 for
all t = 1, . . . , N. Let Ft := Ïƒ(Y1, . . . , Yt) and Xt :=
t
s=1
Ys. Then X is adapted

220
9
Martingales
and integrable, and E[Yr
Fs] = 0 for r > s. Hence, for t > s,
E[Xt
Fs] = E[Xs
Fs] + E[Xt âˆ’Xs
Fs] = Xs +
t
r=s+1
E[Yr
Fs] = Xs.
Thus, X is an F-martingale.
Similarly, X is a submartingale if E[Yt] â‰¥0 for all t, and a supermartingale if
E[Yt] â‰¤0 for all t. â™¦
Reï¬‚ection In the previous example one might be tempted to assume that the Yi are
uncorrelated instead of independent. Why is this not enough? â™ 
Example 9.31 Consider the situation of the preceding example; however, now with
E[Yt] = 1 and Xt = t
s=1 Ys for t âˆˆN0. By Theorem 5.4, Y1 Â· Y2 is integrable.
Inductively, we get E[|Xt|] < âˆfor all t âˆˆN0. Evidently, X is adapted to F and
for all s âˆˆN0, we have
E[Xs+1
Fs] = E[XsYs+1
Fs] = Xs E[Ys+1
Fs] = Xs.
Hence X is an F-martingale. â™¦
Theorem 9.32
(i) X is a supermartingale if and only if (âˆ’X) is a submartingale.
(ii) Let X and Y be martingales and let a, b âˆˆR. Then (aX +bY) is a martingale.
(iii) Let X and Y be supermartingales and a, b â‰¥0. Then (aX + bY) is a
supermartingale.
(iv) Let X and Y be supermartingales. Then Z := X âˆ§Y = (min(Xt, Yt))tâˆˆI is a
supermartingale.
(v) If (Xt)tâˆˆN0 is a supermartingale and E[XT ] â‰¥E[X0] for some T âˆˆN0,
then (Xt)tâˆˆ{0,...,T } is a martingale. If there exists a sequence TN â†’âˆwith
E[XTN ] â‰¥E[X0], then X is a martingale.
Proof (i), (ii) and (iii)
These are evident.
(iv) Since |Zt| â‰¤|Xt| + |Yt|, we have E[|Zt|] < âˆfor all t âˆˆI. expectation
(Theorem 8.14(ii)), for t
> s, we have E[Zt
Fs] â‰¤E[Yt
Fs] â‰¤Ys and
E[Zt
Fs] â‰¤E[Xt
Fs] â‰¤Xs; hence E[Zt
Fs] â‰¤Xs âˆ§Ys = Zs.
(v) For t â‰¤T , let Yt := E[XT
Ft]. Then Y is a martingale and Yt â‰¤Xt. Hence
E[X0] â‰¤E[XT ] = E[YT ] = E[Yt] â‰¤E[Xt] â‰¤E[X0].
(The ï¬rst inequality holds by assumption.) We infer that Yt = Xt almost surely for
all t and thus (Xt)tâˆˆ{0,...,T } is a martingale.
Let TN â†’âˆwith E[XTN ] â‰¥E[X0] for all N âˆˆN. Then, for any t > s â‰¥0,
there is an N âˆˆN with TN > t. Hence, E[Xt
Fs] = Xs and X is a martingale.
âŠ“âŠ”

9.2
Martingales
221
Remark 9.33 Many statements about supermartingales hold mutatis mutandis for
submartingales. For example, in the preceding theorem, claim (i) holds with the
words â€œsubmartingaleâ€ and â€œsupermartingaleâ€ interchanged, claim (iv) holds for
submartingales if the minimum is replaced by a maximum, and so on. We often do
not give the statements both for submartingales and for supermartingales. Instead,
we choose representatively one case. Note, however, that those statements that
we make explicitly about martingales usually cannot be adapted easily to sub- or
supermartingales (such as (ii) in the preceding theorem). â™¦
Corollary 9.34 Let X be a submartingale and a âˆˆR. Then (X âˆ’a)+ is a
submartingale.
Proof Clearly, 0 and Y = X âˆ’a are submartingales. By (iv), (X âˆ’a)+ = Y âˆ¨0 is
also a submartingale.
âŠ“âŠ”
Theorem 9.35 Let X be a martingale and let Ï• : R â†’R be a convex function.
(i) If
E[Ï•(Xt)+] < âˆ
for all t âˆˆI,
(9.1)
then (Ï•(Xt))tâˆˆI is a submartingale.
(ii) If tâˆ—:= sup(I) âˆˆI, then E[Ï•(Xtâˆ—)+] < âˆimplies (9.1).
(iii) In particular, if p â‰¥1 and E[|Xt|p] < âˆfor all t âˆˆI, then (|Xt|p)tâˆˆI is a
submartingale.
Proof
(i) We always have E[Ï•(Xt)âˆ’] < âˆ(Theorem 7.9); hence, by assumption,
E[|Ï•(Xt)|] < âˆfor all t âˆˆI. Jensenâ€™s inequality (Theorem 8.20) then yields,
for t > s,
E[Ï•(Xt)
Fs] â‰¥Ï•(E[Xt
Fs]) = Ï•(Xs).
(ii) Since Ï• is convex, so is x â†’Ï•(x)+. Furthermore, by assumption, we have
E[Ï•(Xtâˆ—)+] < âˆ; hence Jensenâ€™s inequality implies that, for all t âˆˆI,
E[Ï•(Xt)+] = E
)
Ï•

E[Xtâˆ—Ft]
+*
â‰¤E
)
E[Ï•(Xtâˆ—)+ Ft]
*
= E
)
Ï•(Xtâˆ—)+*
< âˆ.
(iii) This is evident since x â†’|x|p is convex.
âŠ“âŠ”
Example 9.36 (See Example 9.4) Symmetric simple random walk X on Z is a
square integrable martingale. Hence (X2
n)nâˆˆN0 is a submartingale. â™¦

222
9
Martingales
Takeaways A martingale is a mathematical model for a fair game of
many rounds. Partial sums of independent centred random variables are an
important example. Submartingales are favourable games (the mean future
is better than the present) and supermartingales are unfavourable games (the
mean future is not as good as the present). Convex functions of martingales
are submartingales.
Exercise 9.2.1 Let Y be a random variable with E[|Y|] < âˆand let F be a ï¬ltration
as well as
Xt := E[Y
Ft]
for all t âˆˆI.
Show that X is an F-martingale. â™£
Exercise 9.2.2 Let (Xn)nâˆˆN0 be a predictable F-martingale. Show that Xn = X0
almost surely for all n âˆˆN0. â™£
Exercise 9.2.3 Show that the claim of Theorem 9.35 continues to hold if X is
only a submartingale but if Ï• is in addition assumed to be monotone increasing.
Give an example that shows that the monotonicity of Ï• is essential. (Compare
Corollary 9.34.) â™£
Exercise 9.2.4 (Azumaâ€™s inequality) Show the following.
(i) If X is a random variable with |X| â‰¤1 a.s., then there is a random variable Y
with values in {âˆ’1, +1} and with E[Y |X] = X.
(ii) For X as in (i) with E[X] = 0, infer that (using Jensenâ€™s inequality)
E)eÎ»X* â‰¤cosh(Î») â‰¤eÎ»2/2
for all Î» âˆˆR.
(iii) If (Mn)nâˆˆN0 is a martingale with M0 = 0 and if there is a sequence (ck)kâˆˆN of
nonnegative numbers with |Mn âˆ’Mnâˆ’1| â‰¤cn a.s. for all n âˆˆN, then
E
)
eÎ»Mn*
â‰¤exp

1
2Î»2
n

k=1
c2
k

.
(iv) Under the assumptions of (iii), Azumaâ€™s inequality holds:
P
)
|Mn| â‰¥Î»
*
â‰¤2 exp

âˆ’
Î»2
2 n
k=1 c2
k

for all Î» â‰¥0.
Hint: Use Markovâ€™s inequality for f (x) = eÎ³ x and choose the optimal Î³ . â™£

9.3
Discrete Stochastic Integral
223
9.3
Discrete Stochastic Integral
So far we have encountered a martingale as the process of partial sums of gains of
a fair game. This game can also be the price of a stock that is traded at discrete
times on a stock exchange. With this interpretation, it is particularly evident that it
is natural to construct new stochastic processes by considering investment strategies
for the stock. The value of the portfolio, which is the new stochastic process,
changes as the stock price changes. It is the price multiplied by the number of
stocks in the portfolio. In order to describe such processes formally, we introduce
the following notion.
Deï¬nition 9.37 (Discrete stochastic integral)
Let (Xn)nâˆˆN0 be an F-adapted real
process and let (Hn)nâˆˆN be a real-valued and F-predictable process. The discrete
stochastic integral of H with respect to X is the stochastic process H Â·X deï¬ned by
(H Â·X)n :=
n

m=1
Hm(Xm âˆ’Xmâˆ’1)
for n âˆˆN0.
(9.2)
If X is a martingale, then H Â·X is also called the martingale transform of X.
Remark 9.38 Clearly, H Â·X is adapted to F. â™¦
Let X be a (possibly unfair) game where Xn âˆ’Xnâˆ’1 is the gain per euro in the
nth round. We interpret Hn as the number of euros we bet in the nth game. H is then
a gambling strategy. Clearly, the value of Hn has to be decided at time n âˆ’1; that
is, before the result of Xn is known. In other words, H must be predictable.
Now assume that X is a fair game (that is, a martingale) and H is locally
bounded (that is, each Hn is bounded). Then (since E[Xn+1 âˆ’Xn
Fn] = 0)
E[(H Â·X)n+1
Fn] = E[(H Â·X)n + Hn+1(Xn+1 âˆ’Xn)
Fn]
= (H Â·X)n + Hn+1 E[Xn+1 âˆ’Xn
Fn]
= (H Â·X)n.
Thus H Â·X is a martingale. The following theorem says that the converse also
holds; that is, X is a martingale if, for sufï¬ciently many predictable processes, the
stochastic integral is a martingale.
Theorem 9.39 (Stability theorem)
Let (Xn)nâˆˆN0 be an adapted, real-valued
stochastic process with E[|X0|] < âˆ.
(i) X is a martingale if and only if, for any locally bounded predictable process H,
the stochastic integral H Â·X is a martingale.
(ii) X is a submartingale (supermartingale) if and only if H Â·X is a submartingale
(supermartingale) for any locally bounded predictable H â‰¥0.

224
9
Martingales
Proof
(i) â€œ â‡’â€
This has been shown in the discussion above.
â€œ â‡ â€
Fix an n0 âˆˆN, and let Hn = 1{n=n0}. Then (H Â·X)n0âˆ’1 = 0; hence
0 = E)(H Â·X)n0
Fn0âˆ’1
* = E)Xn0
Fn0âˆ’1
* âˆ’Xn0âˆ’1.
(ii) This is similar to (i).
âŠ“âŠ”
The preceding theorem says, in particular, that we cannot ï¬nd any locally bounded
gambling strategy that transforms a martingale (or, if we are bound to nonnegative
gambling strategies, as we are in real life, a supermartingale) into a submartingale.
Quite the contrary is suggested by the many invitations to play all kinds of â€œsure
winning systemsâ€ in lotteries.
Example 9.40 (Petersburg game) We continue Example 9.14 (see also Exam-
ple 4.22). Deï¬ne Xn := D1 + . . . + Dn for n âˆˆN0. Then X is a martingale.
The gambling strategy Hn := 2nâˆ’1 1{D1=D2=...=Dnâˆ’1=âˆ’1} for n âˆˆN and H0 = 1
is predictable and locally bounded. Let Sn = n
i=1 HiDi = (H Â·X)n be the gain
after n rounds. Then S is a martingale by the preceding theorem. In particular, we
get (as shown already in Example 4.22) that E[Sn] = 0 for all n âˆˆN. We will
come back later to the point that this superï¬cially contrasts with Sn
nâ†’âˆ
âˆ’â†’1 a.s.
(see Example 11.6).
For the moment, note that the martingale Sâ€² = (1 âˆ’Sn)nâˆˆN0, just like the one in
Example 9.31, has the structure of a product of independent random variables with
expectation 1. In fact, Sâ€²
n = n
i=1(1 âˆ’Di). â™¦
Takeaways Assume that the price of a risky asset at discrete trading times
n = 0, 1, 2, . . . is a martingale. Also assume that we follow a bounded trading
strategy that cannot use future information. Then the value of our portfolio is
described by a discrete stochastic integral which is again a martingale.
9.4
Discrete Martingale Representation Theorem
and the CRR Model
By virtue of the stochastic integral, we have transformed a martingale X via a
gambling strategy H into a new martingale H Â·X. Let us change the perspective
and ask: For ï¬xed X, which are the martingales Y (with Y0 = 0) that can be
obtained as discrete stochastic integrals of X with a suitable gambling strategy
H
= H(Y)? Possibly all martingales Y? This is not the case, in general, as
the example below indicates. However, we will see that all martingales can be

9.4
Discrete Martingale Representation Theorem and the CRR Model
225
represented as stochastic integrals if the increments Xn+1 âˆ’Xn can take only two
values (given X1, . . . , Xn). In this case, we give a representation theorem and use it
to discuss the fair price for a European call option in the stock market model of Coxâ€“
Rossâ€“Rubinstein. This model is rather simple and describes an idealized market (no
transaction costs, fractional numbers of stocks tradeable and so on). For extensive
literature on stochastic aspects of mathematical ï¬nance, we refer to the textbooks
[9, 42, 48, 57, 86, 102, 121] or [160].
Example 9.41 Consider the very simple martingale X = (Xn)n=0,1 with only two
time points. Let X0 = 0 almost surely and P[X1 = âˆ’1] = P[X1 = 0] = P[X1 =
1] =
1
3. Let Y0 = 0. Further, let Y1 = 2 if X1 = 1 and Y1 = âˆ’1 otherwise.
Then Y is manifestly a Ïƒ(X)-martingale. However, there is no number H1 such that
H1X1 = Y1. â™¦
Let T âˆˆN be a ï¬xed time. If (Yn)n=0,1,...,T is an F-martingale, then Yn =
E[YT
Fn] for all n â‰¤T . An F-martingale Y is thus determined uniquely by
the terminal values YT (and vice versa). Let X be a martingale. As (H Â·X) is
a martingale, the representation problem for martingales is thus reduced to the
problem of representing an integrable random variable V := YT as v0 + (H Â·X)T ,
where v0 = E[YT ].
We saw that, in general, this is not possible if the differences Xn+1 âˆ’Xn take
three (or more) different values. Hence we now consider the case where only two
values are possible. Here, at each time step, a system of two linear equations with
two unknowns has to be solved. In the case where Xn+1 âˆ’Xn takes three values,
the system has three equations and is thus overdetermined.
Deï¬nition 9.42 (Binary model) A stochastic process
X0, . . . , XT
is called
binary splitting or a binary model if there exist random variables D1, . . . , DT with
values in {âˆ’1, +1} and functions fn : Rnâˆ’1 Ã— {âˆ’1, +1} â†’R for n = 1, . . . , T , as
well as x0 âˆˆR such that X0 = x0 and
Xn = fn(X1, . . . , Xnâˆ’1, Dn)
for any n = 1, . . . , T.
By F = Ïƒ(X), we denote the ï¬ltration generated by X.
Note that Xn depends only on X1, . . . , Xnâˆ’1 and Dn but not on the full information
inherent in the values D1, . . . , Dn. If the latter were the case, a ramiï¬cation into
more than two values in one time step would be possible.
Theorem 9.43 (Representation theorem) Let X be a binary model and let VT
be an FT -measurable random variable. Then there exists a bounded predictable
process H and a v0 âˆˆR with VT = v0 + (H Â·X)T .
Note that F is the ï¬ltration generated by X, not the, possibly larger, ï¬ltration
generated by D1, . . . , DT . For the latter case, the claim of the theorem would be
incorrect since, loosely speaking, with H we can bet on X but not on the Di.

226
9
Martingales
Proof We show that there exist FT âˆ’1-measurable random variables VT âˆ’1 and HT
such that VT = VT âˆ’1 + HT (XT âˆ’XT âˆ’1). By a backward induction, this yields the
claim.
Since VT is FT -measurable, by the factorization lemma (Corollary 1.97) there
exists a function gT : RT â†’R with VT = gT (X1, . . . , XT ). Deï¬ne
XÂ±
T = fT (X1, . . . , XT âˆ’1, Â±1)
and
V Â±
T
= gT (X1, . . . , XT âˆ’1, XÂ±
T ).
Each of these four random variables is manifestly FT âˆ’1-measurable. Hence we are
looking for solutions VT âˆ’1 and HT of the following system of linear equations:
VT âˆ’1 + HT (Xâˆ’
T âˆ’XT âˆ’1) = V âˆ’
T ,
VT âˆ’1 + HT (X+
T âˆ’XT âˆ’1) = V +
T .
(9.3)
By construction, X+
T âˆ’Xâˆ’
T Ì¸= 0 if V +
T âˆ’V âˆ’
T Ì¸= 0. Hence we can solve (9.3) and
get
HT :=
â§
â¨
â©
V +
T âˆ’V âˆ’
T
X+
T âˆ’Xâˆ’
T ,
if X+
T Ì¸= Xâˆ’
T ,
0,
else,
and VT âˆ’1 = V +
T âˆ’HT (X+
T âˆ’XT âˆ’1) = V âˆ’
T âˆ’HT (Xâˆ’
T âˆ’XT âˆ’1).
âŠ“âŠ”
We now want to interpret X as the market price of a stock and VT as the payment
of a ï¬nancial derivative on X, a so-called contingent claim or, brieï¬‚y, claim. For
example, VT could be a (European) call option with maturity T and strike price
K â‰¥0. In this case, we have VT = (XT âˆ’K)+. Economically speaking, the
European call gives the buyer the right (but not the obligation) to buy one stock at
time T at price K (from the issuer of the option). As typically the option is exercised
only if the market price at time T is larger than K (and then gives a proï¬t of XT âˆ’K
as the stock could be sold at price XT on the market), the value of the option is
indeed VT = (XT âˆ’K)+.
At the stock exchanges, not only are stocks traded but also derivatives on stocks.
Hence, what is the fair price Ï€(VT ) for which a trader would offer (and buy) the
contingent claim VT ? If there exists a strategy H and a v0 such that VT = v0 +
(HÂ·X)T , then the trader can sell the claim for v0 (at time 0) and replicate the claim
by building a portfolio that follows the trading strategy H. In this case, the claim
VT is called replicable and the strategy H is called a hedging strategy, or brieï¬‚y
a hedge. A market in which every claim can be replicated is called complete. In this
sense, the binary model is a complete market.
If there was a second strategy H â€² and a second vâ€²
0 with vâ€²
0 + (H â€²Â·X)T = VT ,
then, in particular, v0 âˆ’vâ€²
0 = ((H â€² âˆ’H)Â·X)T . If we had v0 > vâ€²
0, then the trader
could follow the strategy H â€²âˆ’H (which gives a ï¬nal payment of VT âˆ’VT = 0) and
make a sure proï¬t of v0 âˆ’vâ€²
0. In the opposite case, v0 < vâ€²
0, the strategy H âˆ’H â€²

9.4
Discrete Martingale Representation Theorem and the CRR Model
227
ensures a risk-free proï¬t. Such a risk-free proï¬t (or free lunch in economic jargon)
is called an arbitrage. It is reasonable to assume that a market gives no opportunity
for an arbitrage. Hence the fair price Ï€(VT ) is determined uniquely once there is
one trading strategy H and a v0 such that VT = v0 + (H Â·X)T .
Until now, we have not assumed that X is a martingale. However, if X is
a martingale, then (H Â· X) is a martingale with (H Â· X)0 = 0; hence clearly
E[(H Â·X)T ] = 0. Thus
Ï€(VT ) = v0 = E[VT ].
(9.4)
Since, in this case, v0 does not depend on the trading strategy and is hence unique,
the market is automatically arbitrage-free. A ï¬nite market is thus arbitrage-free if
and only if there exists an equivalent martingale (to be deï¬ned below). In this case,
uniqueness of this martingale is equivalent to completeness of the market (â€œthe
fundamental theorem of asset pricingâ€ by Harrisonâ€“Pliska [68]). In larger markets,
equivalence holds only with a somewhat more ï¬‚exible notion of arbitrage (see [30]).
Now if X is not a martingale, then in some cases, we can replace X by a different
process Xâ€² that is a martingale and such that the distributions PX and PXâ€² are
equivalent; that is, have the same null sets. Such a process is called an equivalent
martingale, and PXâ€² is called an equivalent martingale measure. A trading strategy
that replicates VT with respect to X also replicates VT with respect to Xâ€². In
particular, the fair price does not change if we pass to the equivalent martingale
Xâ€². Thus we can compute Ï€(VT ) by applying (9.4) to the equivalent martingale.
While here this is only of interest in that it simpliï¬es the computation of fair
prices, it has an economic interpretation as a measure for the market prices that
we would see if all traders were risk-neutral; that is, for traders who price a future
payment by its mean value. Typically, however, traders are risk-averse and thus real
market prices include a discount due to the inherent risk.
Now we consider one model in greater detail.
Deï¬nition 9.44 Let T âˆˆN, a âˆˆ(âˆ’1, 0) and b > 0 as well as p âˆˆ(0, 1).
Further, let D1, . . . , DT be i.i.d. Radp random variables (that is,
P[D1 = 1] =
1 âˆ’P[D1 = âˆ’1] = p). We let X0 = x0 > 0 and for n = 1, . . . , T , deï¬ne
Xn =

(1 + b) Xnâˆ’1,
if Dn = +1,
(1 + a) Xnâˆ’1,
if Dn = âˆ’1.
X is called the multi-period binomial model or the Coxâ€“Rossâ€“Rubinstein model
(without interest returns).
As we have shown already, the CRR model is complete. Further, with the choice
p = pâˆ—:=
a
aâˆ’b, we can change X into a martingale. Hence the model is also
arbitrage-free (for all p âˆˆ(0, 1)). Now we want to compute the price of a European
call option VT := (XT âˆ’K)+ explicitly. To this end, we can assume p = pâˆ—.

228
9
Martingales
Letting A := min{i âˆˆN0 : (1 + b)i(1 + a)T âˆ’ix0 > K}, we get
Ï€(VT ) = Epâˆ—[VT ] =
T

i=0
bT,pâˆ—({i})
'
(1 + b)i(1 + a)T âˆ’ix0 âˆ’K
(+
= x0
T

i=A
T
i

(pâˆ—)i(1 âˆ’pâˆ—)T âˆ’i '
(1 + b)i(1 + a)T âˆ’i(
âˆ’K
T

i=A
bT,pâˆ—({i}).
If we deï¬ne pâ€² = (1 + b)pâˆ—, then pâ€² âˆˆ(0, 1) and 1 âˆ’pâ€² = (1 âˆ’pâˆ—)(1 + a). We
thus obtain the Coxâ€“Rossâ€“Rubinstein formula
Ï€(VT ) = x0 bT,pâ€²({A, . . . , T }) âˆ’K bT,pâˆ—({A, . . . , T }).
(9.5)
This is the discrete analogue of the celebrated Blackâ€“Scholes formula for option
pricing in certain time-continuous markets.
Takeaways Consider a stochastic process that can take only two values at
time t + 1 given the full history up to time t. Such a process is said to be
binary splitting. The main theorem says that any function of the history up to
a given time t can be represented as a discrete stochastic integral with respect
to this binary splitting process. Rephrased to the language of ï¬nancial markets
this means: If the price of a risky asset is given by a binary splitting process
than there is a hedging strategy for any contingent claim. As a by-product we
get a discrete version of the celebrated Black-Scholes formula.

Chapter 10
Optional Sampling Theorems
In Chap. 9 we saw that martingales are transformed into martingales if we apply
certain admissible gambling strategies. In this chapter, we establish a similar
stability property for martingales that are stopped at a random time. In order also
to obtain these results for submartingales and supermartingales, in the ï¬rst section,
we start with a decomposition theorem for adapted processes. We show the optional
sampling and optional stopping theorems in the second section. The chapter ï¬nishes
with the investigation of random stopping times with an inï¬nite time horizon.
10.1
Doob Decomposition and Square Variation
Let X = (Xn)nâˆˆN0 be an adapted process with E[|Xn|] < âˆfor all n âˆˆN0. We
will decompose X into a sum consisting of a martingale and a predictable process.
To this end, for n âˆˆN0, deï¬ne
Mn := X0 +
n

k=1
Xk âˆ’E[Xk
Fkâˆ’1]
(10.1)
and
An :=
n

k=1

E[Xk
Fkâˆ’1] âˆ’Xkâˆ’1

.
Evidently, Xn = Mn + An. By construction, A is predictable with A0 = 0, and
M is a martingale since
E[Mn âˆ’Mnâˆ’1
Fnâˆ’1] = E
)
Xn âˆ’E[Xn
Fnâˆ’1]
Fnâˆ’1
*
= 0.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_10
229

230
10
Optional Sampling Theorems
Theorem 10.1 (Doob decomposition) Let X = (Xn)nâˆˆN0 be an adapted inte-
grable process. Then there exists a unique decomposition X = M + A, where A
is predictable with A0 = 0 and M is a martingale. This representation of X is
called the Doob decomposition. X is a submartingale if and only if A is monotone
increasing.
Proof We only have to show uniqueness of the decomposition. Hence, let X =
M + A = Mâ€² + Aâ€² be two such decompositions. Then M âˆ’Mâ€² = Aâ€² âˆ’A is a
predictable martingale; hence (see Exercise 9.2.2) Mn âˆ’Mâ€²
n = M0 âˆ’Mâ€²
0 = 0 for
all n âˆˆN0.
âŠ“âŠ”
Example 10.2 Let I = N0 or I = {0, . . . , N}. Let (Xn)nâˆˆI be a square integrable
F-martingale (that is, E[X2
n] < âˆfor all n âˆˆI). By Theorem 9.35, Y := (X2
n)nâˆˆI
is a submartingale. Let Y = M + A be the Doob decomposition of Y. Then (X2
n âˆ’
An)nâˆˆI is a martingale. Furthermore, E[Xiâˆ’1Xi
Fiâˆ’1] = Xiâˆ’1E[Xi
Fiâˆ’1] =
X2
iâˆ’1; hence (as in (10.1))
An =
n

i=1

E[X2
i
Fiâˆ’1] âˆ’X2
iâˆ’1

=
n

i=1

E[(Xi âˆ’Xiâˆ’1)2Fiâˆ’1] âˆ’2X2
iâˆ’1 + 2 E[Xiâˆ’1Xi
Fiâˆ’1]

=
n

i=1
E
)
(Xi âˆ’Xiâˆ’1)2Fiâˆ’1
*
.
â™¦
(10.2)
Deï¬nition 10.3 Let (Xn)nâˆˆI be a square integrable F-martingale. The unique
predictable process A for which (X2
n âˆ’An)nâˆˆI becomes a martingale is called the
square variation process of X and is denoted by (âŸ¨XâŸ©n)nâˆˆI := A.
By the preceding example, we conclude the following theorem.
Theorem 10.4 Let X be as in Deï¬nition 10.3. Then, for n âˆˆN0,
âŸ¨XâŸ©n =
n

i=1
E
)
(Xi âˆ’Xiâˆ’1)2Fiâˆ’1
*
(10.3)
and
E[âŸ¨XâŸ©n] = Var[Xn âˆ’X0].
(10.4)
Remark 10.5 If Y and A are as in Example 10.2, then A is monotone increasing
since (X2
n)nâˆˆI is a submartingale (see Theorem 10.1). Therefore, A is sometimes
called the increasing process of Y. â™¦

10.1
Doob Decomposition and Square Variation
231
Example 10.6 Let Y1, Y2, . . . be independent, square integrable, centered random
variables. Then Xn := Y1 + . . . + Yn deï¬nes a square integrable martingale with
âŸ¨XâŸ©n = n
i=1 E[Y 2
i ]. In fact, An = n
i=1 E[Y 2
i
Y1, . . . , Yiâˆ’1] = n
i=1 E[Y 2
i ] (as
in Example 10.2).
Note that in order for âŸ¨XâŸ©to have the simple form as in Example 10.6, it is not
enough for the random variables Y1, Y2, . . . to be uncorrelated. â™¦
Example 10.7 Let Y1, Y2, . . . be independent, square integrable random variables
with E[Yn] = 1 for all n âˆˆN. Let Xn := n
i=1 Yi for n âˆˆN0. Then X = (Xn)nâˆˆN0
is a square integrable martingale with respect to F = Ïƒ(X) (why?) and
E)(Xn âˆ’Xnâˆ’1)2Fnâˆ’1
* = E)(Yn âˆ’1)2X2
nâˆ’1
Fnâˆ’1
* = Var[Yn] X2
nâˆ’1.
Hence âŸ¨XâŸ©n = n
i=1 Var[Yi] X2
iâˆ’1. We see that the square variation process can
indeed be a truly random process. â™¦
Example 10.8 Let (Xn)nâˆˆN0 be the one-dimensional symmetric simple random
walk
Xn =
n

i=1
Ri
for all n âˆˆN0,
where R1, R2, R3, . . . are i.i.d. and âˆ¼Rad1/2; that is,
P[Ri = 1] = 1 âˆ’P[Ri = âˆ’1] = 1
2.
Clearly, X is a martingale and hence |X| is a submartingale. Let |X| = M + A
be Doobâ€™s decomposition of |X|. Then
An =
n

i=1

E[|Xi|
Fiâˆ’1] âˆ’|Xiâˆ’1|

.
Now
|Xi| =
â§
âªâªâ¨
âªâªâ©
|Xiâˆ’1| + Ri,
if Xiâˆ’1 > 0,
|Xiâˆ’1| âˆ’Ri,
if Xiâˆ’1 < 0,
1,
if Xiâˆ’1 = 0.
Therefore,
E[|Xi|
Fiâˆ’1] =

|Xiâˆ’1|,
if |Xiâˆ’1| Ì¸= 0,
1,
if |Xiâˆ’1| = 0.

232
10
Optional Sampling Theorems
The process
An = #
	
i â‰¤n âˆ’1 : |Xi| = 0

is the so-called local time of X at 0. We conclude that (since P[X2j = 0] =
2j
j

4âˆ’j
and P[X2j+1 = 0] = 0)
E[|Xn|] = E
)
#{i â‰¤n âˆ’1 : Xi = 0}
*
=
nâˆ’1

i=0
P[Xi = 0] =
âŒŠ(nâˆ’1)/2âŒ‹

j=0
2j
j

4âˆ’j.
â™¦
(10.5)
Example 10.9 We want to generalize the preceding example further. Evidently, we
did not use (except in the last formula) the fact that X is a random walk. Rather, we
just used the fact that the differences (Î”X)n := Xn âˆ’Xnâˆ’1 take only the values
âˆ’1 and +1. Hence, now let X be a martingale with |Xn âˆ’Xnâˆ’1| = 1 almost surely
for all n âˆˆN and with X0 = x0 âˆˆZ almost surely. Let f : Z â†’R be an
arbitrary map. Then Y := (f (Xn))nâˆˆN0 is an integrable adapted process (since
|f (Xn)| â‰¤maxxâˆˆ{x0âˆ’n,...,x0+n} |f (x)|). In order to compute Doobâ€™s decomposition
of Y, deï¬ne the ï¬rst and second discrete derivatives of f :
f â€²(x) := f (x + 1) âˆ’f (x âˆ’1)
2
and
f â€²â€²(x) := f (x âˆ’1) + f (x + 1) âˆ’2f (x).
Further, let F â€²
n := f â€²(Xnâˆ’1) and F â€²â€²
n := f â€²â€²(Xnâˆ’1). By computing the cases Xn =
Xnâˆ’1 âˆ’1 and Xn = Xnâˆ’1 + 1 separately, we see that for all n âˆˆN
f (Xn) âˆ’f (Xnâˆ’1) = f (Xnâˆ’1 + 1) âˆ’f (Xnâˆ’1 âˆ’1)
2
(Xn âˆ’Xnâˆ’1)
+ 1
2f (Xnâˆ’1 âˆ’1) + 1
2f (Xnâˆ’1 + 1) âˆ’f (Xnâˆ’1)
= f â€²(Xnâˆ’1)(Xn âˆ’Xnâˆ’1) + 1
2f â€²â€²(Xnâˆ’1)
= F â€²
n Â· (Xn âˆ’Xnâˆ’1) + 1
2F â€²â€²
n .

10.2
Optional Sampling and Optional Stopping
233
Summing up, we get the discrete ItÃ´ formula:
f (Xn) = f (x0) +
n

i=1
f â€²(Xiâˆ’1)(Xi âˆ’Xiâˆ’1) +
n

i=1
1
2f â€²â€²(Xiâˆ’1)
= f (x0) + (F â€²Â·X)n +
n

i=1
1
2F â€²â€²
i .
(10.6)
Here F â€² Â·X is the discrete stochastic integral (see Deï¬nition 9.37). Now M :=
f (x0) + F â€²Â·X is a martingale by Theorem 9.39 since F â€² is predictable (and since
|F â€²
n| â‰¤maxxâˆˆ{x0âˆ’n,...,x0+n} |F â€²(x)|), and A :=
n
i=1
1
2F â€²â€²
i

nâˆˆN0
is predictable.
Hence f (X) := (f (Xn))nâˆˆN0 = M + A is the Doob decomposition of f (X). In
particular, f (X) is a submartingale if f â€²â€²(x) â‰¥0 for all x âˆˆZ; that is, if f is
convex. We knew this already from Theorem 9.35; however, here we could also
quantify how much f (X) differs from a martingale.
In the special cases f (x) = x2 and f (x) = |x|, the second derivative is f â€²â€²(x) =
2 and f â€²â€²(x) = 2Â·1{0}(x), respectively. Thus, from (10.6), we recover the statements
of Theorem 10.4 and Example 10.8.
Later we will derive a formula similar to (10.6) for stochastic processes in
continuous time (see Sect. 25.3). â™¦
Takeaways For a submartingale, the mean future is better than the present.
Subtracting the differences for each time step, we decompose a submartingale
into a sum of a martingale and a monotone increasing predictable process.
This is the so-called Doob decomposition. If X is an L2-martingale, then
X2 is a submartingale and the corresponding increasing process is called the
variance process or square variation process.
10.2
Optional Sampling and Optional Stopping
Lemma 10.10 Let I âŠ‚R be countable, let (Xt)tâˆˆI be a martingale, let T âˆˆI and
let Ï„ be a stopping time with Ï„ â‰¤T . Then XÏ„ = E[XT
FÏ„] and, in particular,
E[XÏ„] = E[X0].

234
10
Optional Sampling Theorems
Proof It is enough to show that E[XT 1A] = E[XÏ„ 1A] for all A âˆˆFÏ„. By the
deï¬nition of FÏ„, we have {Ï„ = t} âˆ©A âˆˆFt for all t âˆˆI. Hence
E[XÏ„ 1A] =

tâ‰¤T
E[Xt 1{Ï„=t}âˆ©A] =

tâ‰¤T
E
)
E[XT
Ft] 1{Ï„=t}âˆ©A
*
=

tâ‰¤T
E[XT 1A 1{Ï„=t}] = E[XT 1A].
âŠ“âŠ”
Theorem 10.11 (Optional sampling theorem) Let X = (Xn)nâˆˆN0 be a supermar-
tingale and let Ïƒ â‰¤Ï„ be stopping times.
(i) Assume there exists a T âˆˆN with Ï„ â‰¤T . Then
XÏƒ â‰¥E[XÏ„
FÏƒ],
and, in particular, E[XÏƒ] â‰¥E[XÏ„]. If X is a martingale, then equality holds
in each case.
(ii) If X is nonnegative and if Ï„ < âˆa.s., then we have E[XÏ„] â‰¤E[X0] < âˆ,
E[XÏƒ] â‰¤E[X0] < âˆand XÏƒ â‰¥E[XÏ„
FÏƒ].
(iii) Assume that, more generally, X is only adapted and integrable. Then X is a
martingale if and only if E[XÏ„] = E[X0] for any bounded stopping time Ï„.
Proof
(i) Let X = M + A be Doobâ€™s decomposition of X. Hence A is predictable and
monotone decreasing, A0 = 0, and M is a martingale. Applying Lemma 10.10
to M yields
XÏƒ = AÏƒ + MÏƒ = E[AÏƒ + MT
FÏƒ]
â‰¥E[AÏ„ + MT
FÏƒ] = E[AÏ„ + E[MT
FÏ„]
FÏƒ]
= E[AÏ„ + MÏ„
FÏƒ] = E[XÏ„
FÏƒ].
Here we used FÏ„ âŠƒFÏƒ, the tower property and the monotonicity of the
conditional expectation (see Theorem 8.14).
(ii) We have XÏ„âˆ§n
nâ†’âˆ
âˆ’â†’XÏ„ almost surely. By (i), we get E[XÏ„âˆ§n] â‰¤E[X0] for
any n âˆˆN. Using Fatouâ€™s lemma, we infer
E[XÏ„] â‰¤lim inf
nâ†’âˆE[XÏ„âˆ§n] â‰¤E[X0] < âˆ.
Similarly, we can show that E[XÏƒ] â‰¤E[X0].
Now, let m, n âˆˆN with m â‰¥n. Part (i) applied to the bounded stopping
times Ï„ âˆ§m â‰¥Ïƒ âˆ§n yields
XÏƒâˆ§n â‰¥E[XÏ„âˆ§m
FÏƒâˆ§n].

10.2
Optional Sampling and Optional Stopping
235
Now {Ïƒ < n} âˆ©A âˆˆFÏƒâˆ§n for A âˆˆFÏƒ. Hence
E
)
XÏƒ 1{Ïƒ<n}âˆ©A
*
= E
)
XÏƒâˆ§n 1{Ïƒ<n}âˆ©A
*
â‰¥E
)
XÏ„âˆ§m 1{Ïƒ<n}âˆ©A
*
.
Using Fatouâ€™s lemma, we get
E[XÏ„ 1{Ïƒ<n}âˆ©A] â‰¤lim inf
mâ†’âˆE
)
XÏ„âˆ§m 1{Ïƒ<n}âˆ©A
*
â‰¤E
)
XÏƒ 1{Ïƒ<n}âˆ©A
*
.
Monotone convergence (for n â†’âˆ) thus yields E[XÏ„ 1A] â‰¤E[XÏƒ 1A].
(iii) If X is a martingale, then the claim follows from Lemma 10.10. Now assume
that E[XÏ„] = E[X0] for any bounded stopping time Ï„. Let t > s and A âˆˆFs.
It is enough to show that E[Xt 1A] = E[Xs 1A]. Deï¬ne Ï„ = s 1A +t1Ac. Then
Ï„ is a bounded stopping time. However, by assumption,
E[Xt 1A] = E[Xt]âˆ’E[Xt 1Ac] = E[X0]âˆ’E[XÏ„]+E[Xs 1A] = E[Xs 1A].
âŠ“âŠ”
Corollary 10.12 Let X be a martingale (respectively a submartingale), and assume
(Ï„N)NâˆˆN is a monotone increasing sequence of bounded stopping times (hence Ï„N â‰¤
TN, N âˆˆN for some TN âˆˆN). Then (XÏ„N )NâˆˆN is a martingale (respectively a
submartingale) with respect to the ï¬ltration (FÏ„N )NâˆˆN.
Deï¬nition 10.13 (Stopped process) Let I
âŠ‚R be countable, let (Xt)tâˆˆI be
adapted and let Ï„ be a stopping time. We deï¬ne the stopped process XÏ„ by
XÏ„
t = XÏ„âˆ§t
for any t âˆˆI.
Further, let FÏ„ be the ï¬ltration FÏ„ = (FÏ„
t )tâˆˆI = (FÏ„âˆ§t)tâˆˆI.
Remark 10.14 XÏ„ is adapted both to F and to FÏ„. â™¦
Theorem 10.15 (Optional stopping) Let (Xn)nâˆˆN0 be a (sub-, super-) martingale
with respect to F and let Ï„ be a stopping time. Then XÏ„ is a (sub-, super-) martingale
both with respect to F and with respect to FÏ„.
Proof We give the proof only for the case where X is a submartingale. The other
cases are similar since there (âˆ’X) is a submartingale.
For each n âˆˆN0, we have
E
)XÏ„
n
*
â‰¤E
)
max
	
|Xm| : m â‰¤n

*
â‰¤E
)
|X0|] + . . . + E[|Xn|] < âˆ.
Hence XÏ„ is integrable.

236
10
Optional Sampling Theorems
Let X be a submartingale. Since {Ï„ > n âˆ’1} âˆˆFnâˆ’1, we have
E[XÏ„
n âˆ’XÏ„
nâˆ’1
Fnâˆ’1] = E[XÏ„âˆ§n âˆ’XÏ„âˆ§(nâˆ’1)
Fnâˆ’1]
= E[(Xn âˆ’Xnâˆ’1) 1{Ï„>nâˆ’1}
Fnâˆ’1]
= 1{Ï„>nâˆ’1} E[Xn âˆ’Xnâˆ’1
Fnâˆ’1]
â‰¥0, since X is an F-submartingale.
Therefore, XÏ„ is an F-submartingale. As XÏ„ is adapted to FÏ„ and since FÏ„ is the
smaller ï¬ltration, XÏ„ is also an FÏ„-submartingale (see Remark 9.29).
âŠ“âŠ”
Example 10.16 Let X be a symmetric simple random walk on Z (see Exam-
ple 10.8). Let a, b âˆˆZ with a < 0, b > 0 and let
Ï„a = inf{t â‰¥0 : Xt = a},
Ï„b = inf{t â‰¥0 : Xt = b} and Ï„a,b = Ï„a âˆ§Ï„b.
Ï„a,b is a stopping time by Lemma 9.18. Let A = {Ï„a,b = Ï„a} be the event where
X hits a before hitting b. We want to compute P[A]. By Exercise 2.3.1, almost
surely lim supnâ†’âˆXn = âˆand lim infnâ†’âˆXn = âˆ’âˆ. Therefore, almost surely
Ï„a < âˆand Ï„b < âˆ. By the optional stopping theorem, XÏ„a,b is a martingale. Since
Ï„a,b âˆ§n
nâ†’âˆ
âˆ’â†’Ï„a,b almost surely, we get XÏ„a,b
n
nâ†’âˆ
âˆ’â†’XÏ„a,b almost surely. As |XÏ„a,b
n
|
is bounded by b âˆ’a, we can infer that XÏ„a,b
n
nâ†’âˆ
âˆ’â†’XÏ„a,b also in L1. Thus
0 = lim
nâ†’âˆE
)
XÏ„a,b
n
*
= E
)
XÏ„a,b
*
= a Â· P
)
Ï„a,b = Ï„a
*
+ b Â· P
)
Ï„a,b = Ï„b
*
= b + (a âˆ’b) P[Ï„a,b = Ï„a].
We conclude that P
)
Ï„a,b = Ï„a
*
=
b
b âˆ’a . â™¦
Example 10.17 Finally, we use our machinery in order to compute E[Ï„a,b] and
E[Ï„a]. The square variation process âŸ¨XâŸ©(compare Deï¬nition 10.3) is given by
âŸ¨XâŸ©n =
n

i=1
E
'
(Xi âˆ’Xiâˆ’1)2Fiâˆ’1
(
= n;
hence

X2
n âˆ’n

nâˆˆN0 is a martingale. By the optional stopping theorem,
0 = E
)
X2
Ï„a,bâˆ§n âˆ’(Ï„a,b âˆ§n)
*
for all n âˆˆN0.
Monotone convergence yields
E
)
Ï„a,b
*
= E
)
X2
Ï„a,b
*
= a2 P
)
Ï„a,b = Ï„a
*
+ b2 P
)
Ï„a,b = Ï„b
*
= |a| Â· b.

10.2
Optional Sampling and Optional Stopping
237
In order to compute E[Ï„a], note that Ï„a,b â†‘Ï„a almost surely if b â†’âˆ. The
monotone convergence theorem thus yields E[Ï„a] = lim
bâ†’âˆE[Ï„a,b] = âˆ. â™¦
Remark 10.18 Evidently, XÏ„b = b > 0. Hence X0 < E
)
XÏ„b
F0
*
= b. The claim
of the optional sampling theorem may thus fail, in general, if the stopping time is
unbounded. â™¦
Example 10.19 (Gamblerâ€™s ruin problem) Consider a game of two persons, A and
B. In each round, a coin is tossed. Depending on the outcome, either A gets a euro
from B or vice versa. The game endures until one of the players is ruined. For
simplicity, we assume that in the beginning A has kA âˆˆN euros while B has kB =
N âˆ’kA euros, where N âˆˆN, N â‰¥kA. We want to know the probability of Bâ€™s
ruin. In Example 10.16 we saw that for a fair coin this probability is kA/N. Now we
allow the coin to be unfair.
Hence, let Y1, Y2, . . . be i.i.d. and âˆ¼Radp (that is, P[Yi = 1] = 1 âˆ’P[Yi =
âˆ’1] = p) for some p âˆˆ(0, 1) \ { 1
2}. Denote by Xn := kB + n
i=1 Yi the running
total for B after n rounds, where formally we assume that the game continues even
after one player is ruined. We deï¬ne as above Ï„0, Ï„N and Ï„0,N as the times of ï¬rst
entrance of X into {0}, {N} and {0, N}, respectively. The ruin probability of B thus
is pN
B := P[Ï„0,N = Ï„0]. Since X is not a martingale (except for the case p = 1
2
that was excluded), we use a trick to construct a martingale. Deï¬ne a new process
Z by Zn := rXn = rkB n
i=1 rYi, where r > 0 has to be chosen so that Z becomes
a martingale. By Example 9.31, this is the case if and only if
E[rY1] = pr + (1 âˆ’p)râˆ’1 = 1;
hence, if r = 1 or r = 1âˆ’p
p . Evidently, the choice r = 1 is useless (as Z does not
yield any information on X); hence we assume r = 1âˆ’p
p . We thus get
Ï„0 = inf
	
n âˆˆN0 : Zn = 1

and
Ï„N = inf
	
n âˆˆN0 : Zn = rN
.
(Note that here we cannot argue as above in order to show that Ï„0 < âˆand
Ï„N < âˆalmost surely. In fact, for p Ì¸=
1
2, only one of the statements holds.
However, using, for example, the strong law of large numbers, we obtain that
lim infnâ†’âˆXn = âˆ(and thus Ï„N < âˆ) almost surely if p > 1
2. Similarly, Ï„0 < âˆ
almost surely if p < 1
2.) As in Example 10.16, the optional stopping theorem yields
rkB = Z0 = E[ZÏ„0,N ] = pN
B + (1 âˆ’pN
B )rN. Therefore, the probability of Bâ€™s ruin
is
pN
B = rkB âˆ’rN
1 âˆ’rN .
(10.7)

238
10
Optional Sampling Theorems
If the game is advantageous for B (that is, p > 1
2), then r < 1. In this case, in the
limit N â†’âˆ(with constant kB),
pâˆ
B := lim
Nâ†’âˆpN
B = rkB.
(10.8)
â™¦
Takeaways For a martingale, by deï¬nition, the conditional expected value at
a later time given the information available at the present time is just the value
at the present time. Here we have shown that this remains true for random
times as long as they are bounded stopping times (optional sampling theorem).
For general stopping times, we have shown that the stopped martingale is
again a martingale (optional stopping theorem). The corresponding statements
also hold for submartingales and supermartingales.
Exercise 10.2.1 Let X be a square integrable martingale with square variation
process âŸ¨XâŸ©. Let Ï„ be a ï¬nite stopping time. Show the following:
(i) If E[âŸ¨XâŸ©Ï„ ] < âˆ, then
E
)
(XÏ„ âˆ’X0)2*
= E
)
âŸ¨XâŸ©Ï„
*
and
E
)
XÏ„
*
= E
)
X0
*
.
(10.9)
(ii) If E[âŸ¨XâŸ©Ï„ ] = âˆ, then both equalities in (10.9) may fail. â™£
Exercise 10.2.2 We consider a situation that is more general than the one in the
preceding example by assuming only that Y1, Y2, . . . are i.i.d. integrable random
variables that are not almost surely constant (and Xn = Y1 + . . . + Yn). We further
assume that there is a Î´ > 0 such that E[exp(Î¸Y1)] < âˆfor all Î¸ âˆˆ(âˆ’Î´, Î´).
Deï¬ne a map Ïˆ : (âˆ’Î´, Î´) â†’R by Î¸ â†’log

E[exp(Î¸Y1)]

and the process ZÎ¸ by
ZÎ¸
n := exp(Î¸Xn âˆ’nÏˆ(Î¸)) for n âˆˆN0. Show the following:
(i) ZÎ¸ is a martingale for all Î¸ âˆˆ(âˆ’Î´, Î´).
(ii) Ïˆ is strictly convex.
(iii) E
)2
ZÎ¸n
* nâ†’âˆ
âˆ’â†’0 for Î¸ Ì¸= 0.
(iv) ZÎ¸
n
nâ†’âˆ
âˆ’â†’0 almost surely.
We may interpret Yn as the difference between the premiums and the payments of
an insurance company at time n. If the initial capital of the company is k0 > 0, then
k0 + Xn is the account balance at time n. We are interested in the ruin probability
p(k0) = P
)
inf{Xn + k0 : n âˆˆN0} < 0
*
depending on the initial capital.

10.3
Uniform Integrability and Optional Sampling
239
It can be assumed that the premiums are calculated such that E[Y1] > 0. Show
that if the equation Ïˆ(Î¸) = 0 has a solution Î¸âˆ—Ì¸= 0, then Î¸âˆ—< 0. Show further that
in this case, the CramÃ©râ€“Lundberg inequality holds:
p(k0) â‰¤exp(Î¸âˆ—k0).
(10.10)
Equality holds if k0 âˆˆN and if Yi assumes only the values âˆ’1 and 1. In this case,
we get (10.8) with r = exp(Î¸âˆ—). â™£
10.3
Uniform Integrability and Optional Sampling
We extend the optional sampling theorem to unbounded stopping times. We will see
that this is possible if the underlying martingale is uniformly integrable (compare
Deï¬nition 6.16).
Lemma 10.20 Let (Xn)nâˆˆN0 be a uniformly integrable martingale. Then the family
(XÏ„ : Ï„ is a ï¬nite stopping time) is uniformly integrable.
Proof By Theorem 6.19, there exists a monotone increasing, convex function f :
[0, âˆ) â†’[0, âˆ) with lim infxâ†’âˆf (x)/x = âˆand L := supnâˆˆN0 E[f (|Xn|)] <
âˆ. If Ï„ < âˆis a ï¬nite stopping time, then by the optional sampling theorem for
bounded stopping times (Theorem 10.11 with Ï„ = n and Ïƒ = Ï„âˆ§n), E[Xn
FÏ„âˆ§n] =
XÏ„âˆ§n. Since {Ï„ â‰¤n} âˆˆFÏ„âˆ§n, Jensenâ€™s inequality yields
E
)
f (|XÏ„|) 1{Ï„â‰¤n}
*
= E
)
f (|XÏ„âˆ§n|) 1{Ï„â‰¤n}
*
â‰¤E
)
E
)
f (|Xn|)
FÏ„âˆ§n
*
1{Ï„â‰¤n}
*
= E
)
f (|Xn|) 1{Ï„â‰¤n}
*
â‰¤L.
Hence E[f (|XÏ„|)] â‰¤L. By Theorem 6.19, the family
{XÏ„, Ï„ is a ï¬nite stopping time}
is uniformly integrable.
âŠ“âŠ”
Theorem 10.21 (Optional sampling and uniform integrability) Let (Xn, n âˆˆ
N0) be a uniformly integrable martingale (respectively supermartingale) and let
Ïƒ â‰¤Ï„ be ï¬nite stopping times. Then E[|XÏ„|] < âˆand XÏƒ
= E[XÏ„
FÏƒ]
(respectively XÏƒ â‰¥E[XÏ„
FÏƒ]).
Proof First let X be a martingale. We have {Ïƒ â‰¤n} âˆ©F âˆˆFÏƒâˆ§n for all F âˆˆFÏƒ.
Hence, by the optional sampling theorem (Theorem 10.11),
E)XÏ„âˆ§n 1{Ïƒâ‰¤n}âˆ©F
* = E)XÏƒâˆ§n 1{Ïƒâ‰¤n}âˆ©F
*.

240
10
Optional Sampling Theorems
By Lemma 10.20, (XÏƒâˆ§n, n âˆˆN0) and thus (XÏƒâˆ§n 1{Ïƒâ‰¤n}âˆ©F , n âˆˆN0) are
uniformly integrable. Similarly, this holds for XÏ„. Therefore, by Theorem 6.25,
E[XÏ„ 1F ] = lim
nâ†’âˆE
)
XÏ„âˆ§n 1{Ïƒâ‰¤n}âˆ©F
*
= lim
nâ†’âˆE
)
XÏƒâˆ§n 1{Ïƒâ‰¤n}âˆ©F
*
= E[XÏƒ 1F ].
We conclude that E[XÏ„
FÏƒ] = XÏƒ.
Now let X be a supermartingale and let X = M + A be its Doob decomposition;
that is, M is a martingale and A â‰¤0 is predictable and decreasing. Since
E[|An|] = E[âˆ’An] â‰¤E[|Xn âˆ’X0|] â‰¤E[|X0|] + sup
mâˆˆN0
E[|Xm|] < âˆ,
we have An â†“Aâˆfor some Aâˆâ‰¤0 with E[âˆ’Aâˆ] < âˆ(by the monotone
convergence theorem). Hence A and thus M = X âˆ’A are uniformly integrable
(Theorem 6.18(ii)). Therefore,
E[|XÏ„|] â‰¤E[âˆ’AÏ„] + E[|MÏ„|] â‰¤E[âˆ’Aâˆ] + E[|MÏ„|] < âˆ.
Furthermore,
E[XÏ„
FÏƒ] = E[MÏ„
FÏƒ] + E[AÏ„
FÏƒ]
= MÏƒ + AÏƒ + E[(AÏ„ âˆ’AÏƒ)
FÏƒ]
â‰¤MÏƒ + AÏƒ = XÏƒ.
âŠ“âŠ”
Corollary 10.22 Let X be a uniformly integrable martingale (respectively super-
martingale) and let Ï„1 â‰¤Ï„2 â‰¤. . . be ï¬nite stopping times. Then (XÏ„n)nâˆˆN is a
martingale (respectively supermartingale).
Reï¬‚ection Find an example that shows that uniform integrability is essential in
Theorem 10.21. â™ 
Takeaways The deï¬ning property for (sub-, super-) martingales can be
extended to unbounded (but ï¬nite) stopping times if and only if the processes
are uniformly integrable.

Chapter 11
Martingale Convergence Theorems
and Their Applications
We became familiar with martingales X = (Xn)nâˆˆN0 as fair games and found
that under certain transformations (optional stopping, discrete stochastic integral)
martingales turn into martingales. In this chapter, we will see that under weak condi-
tions (non-negativity or uniform integrability) martingales converge almost surely.
Furthermore, the martingale structure implies Lp-convergence under assumptions
that are (formally) weaker than those of Chap. 7. The basic ideas of this chapter are
Doobâ€™s inequality (Theorem 11.2) and the upcrossing inequality (Lemma 11.3).
11.1
Doobâ€™s Inequality
With Kolmogorovâ€™s inequality (Theorem 5.28), we became acquainted with an
inequality that bounds the probability of large values of the maximum of a square
integrable process with independent centered increments. Here we want to improve
this inequality in two directions. On the one hand, we replace the independent
increments by the assumption that the process of partial sums is a martingale. On
the other hand, we can manage with less than second moments; alternatively, we
can get better bounds if we have higher moments.
Let I âŠ‚N0 and let X = (Xn)nâˆˆI be a stochastic process. For n âˆˆN, we denote
Xâˆ—
n = sup{Xk : k â‰¤n}
and
|X|âˆ—
n = sup{|Xk| : k â‰¤n}.
Lemma 11.1 If X is a submartingale, then, for all Î» > 0,
Î» P
)
Xâˆ—
n â‰¥Î»
*
â‰¤E
)
Xn 1{Xâˆ—nâ‰¥Î»}
*
â‰¤E
)
|Xn| 1{Xâˆ—nâ‰¥Î»}
*
.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_11
241

242
11
Martingale Convergence Theorems and Their Applications
Proof The second inequality is trivial. For the ï¬rst one, let
Ï„ := inf
	
k âˆˆI : Xk â‰¥Î»

âˆ§n.
By Theorem 10.11 (optional sampling theorem),
E[Xn] â‰¥E[XÏ„] = E
)
XÏ„ 1{Xâˆ—nâ‰¥Î»}
*
+ E
)
XÏ„ 1{Xâˆ—n<Î»}
*
â‰¥Î» P
)
Xâˆ—
n â‰¥Î»
*
+ E
)
Xn 1{Xâˆ—n<Î»}
*
.
(Note that Ï„ = n if Xâˆ—
n < Î».) Now subtract E)Xn 1{Xâˆ—n<Î»}
*.
âŠ“âŠ”
Theorem 11.2 (Doobâ€™s Lp-inequality) Let X be a martingale or a positive sub-
martingale.
(i) For any p â‰¥1 and Î» > 0,
Î»p P
)
|X|âˆ—
n â‰¥Î»
*
â‰¤E
)
|Xn|p*
.
(ii) For any p > 1,
E
)
|Xn|p*
â‰¤E
)
(|X|âˆ—
n)p*
â‰¤

p
p âˆ’1
p
E
)
|Xn|p*
.
Proof We follow the proof in [145]. As all the statements in (i) and (ii) are trivially
true if E[|X|p
n] = âˆ, we may and will assume that E[|Xn|p] < âˆ.
(i) By Theorem 9.35, (|Xn|p)nâˆˆI is a submartingale, and the claim follows by
Lemma 11.1.
(ii) The ï¬rst inequality is trivial. By Lemma 11.1, for the second inequality, we
have
Î»P
)
|X|âˆ—
n â‰¥Î»
*
â‰¤E
)
|Xn| 1{|X|âˆ—nâ‰¥Î»}
*
.
Hence, for any K > 0,
E
)
(|X|âˆ—
n âˆ§K)p*
= E
- |X|âˆ—
nâˆ§K
0
p Î»pâˆ’1 dÎ»
.
= E
+ K
0
p Î»pâˆ’1 1{|X|âˆ—nâ‰¥Î»} dÎ»
,
=
 K
0
p Î»pâˆ’1 P[|X|âˆ—
n â‰¥Î»] dÎ»

11.2
Martingale Convergence Theorems
243
â‰¤
 K
0
p Î»pâˆ’2 E
)
|Xn| 1{|X|âˆ—nâ‰¥Î»}
*
dÎ»
= p E
-
|Xn|
 |X|âˆ—
nâˆ§K
0
Î»pâˆ’2 dÎ»
.
=
p
p âˆ’1 E)|Xn| Â· (|X|âˆ—
n âˆ§K)pâˆ’1*.
HÃ¶lderâ€™s inequality then yields
E
)
(|X|âˆ—
n âˆ§K)p*
â‰¤
p
p âˆ’1 E
)
(|X|âˆ—
n âˆ§K)p*(pâˆ’1)/p Â· E
)
|Xn|p*1/p.
We raise both sides to the pth power and divide by E)(|X|âˆ—
nâˆ§K)p*pâˆ’1 (here we
need the truncation at K to make sure we divide by a ï¬nite number) to obtain
E
)
(|X|âˆ—
n âˆ§K)p*
â‰¤

p
p âˆ’1
p
E
)
|Xn|p*
.
Finally, let K â†’âˆ.
âŠ“âŠ”
Reï¬‚ection Check that Kolmogorovâ€™s inequality (5.12) is a special case of (i) for
p = 2. â™ 
Takeaways Martingales, respectively sub- and supermartingales, have so
much structure that the maximal value over a ï¬nite trajectory can be estimated
by the ï¬nal value only; at least in expectation or as a pth moment.
Exercise 11.1.1 Let (Xn)nâˆˆN0 be a submartingale or a supermartingale. Use Theo-
rem 11.2 and Doobâ€™s decomposition to show that, for all n âˆˆN and Î» > 0,
Î» P
)
|X|âˆ—
n â‰¥Î»
*
â‰¤6 E[|X0|] + 4 E[|Xn|].
â™£
11.2
Martingale Convergence Theorems
In this section, we present the usual martingale convergence theorems and give a
few small examples. We start with the core of the martingale convergence theorems,
the so-called upcrossing inequality.
Let F = (Fn)nâˆˆN0 be a ï¬ltration and Fâˆ= Ïƒ
 
nâˆˆN0 Fn

. Let (Xn)nâˆˆN0 be
real-valued and adapted to F. Let a, b âˆˆR with a < b. If we think of X as a stock

244
11
Martingale Convergence Theorems and Their Applications
a
b
Ï„0 = 0
Ïƒ1
Ï„2
Ïƒ2 Ï„3 Ïƒ3
Ï„4
Ïƒ4
Ï„5
Fig. 11.1 Four upcrossings over [a, b] are completed. One more has just started.
price, it would be a sensible trading strategy to buy the stock when its price has
fallen below a and to sell it when it exceeds b at least if we knew for sure that the
price would always rise above the level b again. Each time the price makes such an
upcrossing from a to b, we make a proï¬t of at least b âˆ’a. If we get a bound on
the maximal proï¬t we can make, dividing it by b âˆ’a gives a bound on the maximal
number of such upcrossings. If this number is ï¬nite for all a < b, then the price has
to converge as n â†’âˆ.
Let us get into the details. Deï¬ne stopping times Ïƒ0 â‰¡0 and (see Fig. 11.1)
Ï„k := inf{n â‰¥Ïƒkâˆ’1 : Xn â‰¤a}
for k âˆˆN,
Ïƒk := inf{n â‰¥Ï„k : Xn â‰¥b}
for k âˆˆN.
Note that Ï„k = âˆif Ïƒkâˆ’1 = âˆ, and Ïƒk = âˆif Ï„k = âˆ. We say that X has its
kth upcrossing over [a, b] between Ï„k and Ïƒk if Ïƒk < âˆ. For n âˆˆN, deï¬ne
Ua,b
n
:= sup{k âˆˆN0 : Ïƒk â‰¤n}
as the number of upcrossings over [a, b] until time n.
Lemma 11.3 (Upcrossing inequality) Let (Xn)nâˆˆN0 be a submartingale. Then
E
'
Ua,b
n
(
â‰¤E[(Xn âˆ’a)+] âˆ’E[(X0 âˆ’a)+]
b âˆ’a
.
Proof Recall the discrete stochastic integral H Â·X from Deï¬nition 9.37. Formally,
the intimated trading strategy H is described for m âˆˆN0 by
Hm :=

1,
if m âˆˆ{Ï„k + 1, . . . , Ïƒk} for some k âˆˆN,
0,
else.

11.2
Martingale Convergence Theorems
245
H is nonnegative and predictable since, for all m âˆˆN,
{Hm = 1} =
âˆ

k=1
{Ï„k â‰¤m âˆ’1} âˆ©{Ïƒk > m âˆ’1},
and each of the events is in Fmâˆ’1. Deï¬ne Y = max(X, a). If k âˆˆN and Ïƒk < âˆ,
then clearly YÏƒi âˆ’YÏ„i = YÏƒi âˆ’a â‰¥b âˆ’a for all i â‰¤k; hence
(H Â·Y)Ïƒk =
k

i=1
Ïƒi

j=Ï„i+1
(Yj âˆ’Yjâˆ’1) =
k

i=1
(YÏƒi âˆ’YÏ„i) â‰¥k(b âˆ’a).
For j âˆˆ{Ïƒk, . . . , Ï„k+1}, we have (H Â·Y)j = (H Â·Y)Ïƒk. On the other hand, for
j âˆˆ{Ï„k + 1, . . . , Ïƒk}, we have (H Â·Y)j â‰¥(H Â·Y)Ï„k = (H Â·Y)Ïƒkâˆ’1. Hence (H Â·Y)n â‰¥
(b âˆ’a)Ua,b
n
for all n âˆˆN.
By Corollary 9.34, Y is a submartingale, and (by Theorem 9.39) so are H Â·Y and
(1 âˆ’H)Â·Y. Now Yn âˆ’Y0 = (1Â·Y)n = (H Â·Y)n + ((1 âˆ’H)Â·Y)n; hence
E[Yn âˆ’Y0] â‰¥E
)
(H Â·Y)n
*
â‰¥(b âˆ’a)E
)
Ua,b
n
*
.
âŠ“âŠ”
Theorem 11.4 (Martingale convergence theorem) Let (Xn)nâˆˆN0 be a submartin-
gale with sup{E[X+
n ] : n â‰¥0} < âˆ. Then there exists an Fâˆ-measurable random
variable Xâˆwith E[|Xâˆ|] < âˆand Xn
nâ†’âˆ
âˆ’â†’Xâˆalmost surely.
Proof Let a < b. Since E[(Xn âˆ’a)+] â‰¤|a| + E[X+
n ], by Lemma 11.3,
E[Ua,b
n
] â‰¤|a| + E[X+
n ]
b âˆ’a
.
Manifestly, the monotone limit Ua,b := limnâ†’âˆUa,b
n
exists. By assumption, we
have E
)
Ua,b*
= limnâ†’âˆE[Ua,b
n
] < âˆ. In particular, P
)
Ua,b < âˆ
*
= 1. Deï¬ne
the Fâˆ-measurable events
Ca,b =

lim inf
nâ†’âˆXn < a

âˆ©
0
lim sup
nâ†’âˆ
Xn > b
1
âŠ‚

Ua,b = âˆ

and
C =

a,bâˆˆQ
a<b
Ca,b.
Then P)Ca,b* = 0 and thus also P[C] = 0. However, by construction, (Xn)nâˆˆN
is convergent on Cc. Hence there exists the almost sure limit Xâˆ= limnâ†’âˆXn.
Each Xn is Fâˆ-measurable; hence Xâˆalso is Fâˆ-measurable.

246
11
Martingale Convergence Theorems and Their Applications
By Fatouâ€™s lemma,
E[X+
âˆ] â‰¤sup
	
E[X+
n ] : n â‰¥0

< âˆ.
On the other hand (since X is a submartingale), again by Fatouâ€™s lemma,
E[Xâˆ’
âˆ] â‰¤lim inf
nâ†’âˆE[Xâˆ’
n ] = lim inf
nâ†’âˆ

E[X+
n ] âˆ’E[Xn]

â‰¤sup
	
E[X+
n ] : n âˆˆN0

âˆ’E[X0] < âˆ.
âŠ“âŠ”
Corollary 11.5 If X is a nonnegative supermartingale, then there is an Fâˆ-mea-
surable random variable Xâˆâ‰¥0 with E[Xâˆ] â‰¤E[X0] and Xn
nâ†’âˆ
âˆ’â†’Xâˆa.s.
Proof The preceding theorem with (âˆ’X) establishes Xâˆas the almost sure limit.
Fatouâ€™s lemma yields
E[Xâˆ] â‰¤lim inf
nâ†’âˆE[Xn] â‰¤E[X0].
âŠ“âŠ”
Reï¬‚ection Why do we need nonnegativity of X in Corollary 11.5? Find an example
of a supermartingale that does not converge. â™ 
Example 11.6 Let Sn be the account balance in the Petersburg game after the nth
round (see Example 9.40). Then S is a martingale and Sn â‰¤1 almost surely for any
n. Hence the assumptions of Theorem 11.4 are fulï¬lled and (Sn)nâˆˆN0 converges to a
ï¬nite random variable almost surely for n â†’âˆ. Since the account changes as long
as stakes are put up (that is, as long as Sn < 1), we get lim
nâ†’âˆSn = 1 almost surely.
Since E[Sn] = 0 for all n âˆˆN0, this convergence cannot hold in L1. This
observation tallies with the fact that S is not uniformly integrable. â™¦
For uniformly integrable martingales, a stronger convergence theorem holds.
Theorem 11.7 (Convergence theorem for uniformly integrable martingales)
Let (Xn)nâˆˆN0 be a uniformly integrable F- (sub-, super-) martingale. Then there
exists an Fâˆ-measurable integrable random variable Xâˆwith Xn
nâ†’âˆ
âˆ’â†’Xâˆa.s.
and in L1. Furthermore:
â€¢
Xn = E[Xâˆ
Fn] for all n âˆˆN if X is a martingale.
â€¢
Xn â‰¤E[Xâˆ
Fn] for all n âˆˆN if X is a submartingale.
â€¢
Xn â‰¥E[Xâˆ
Fn] for all n âˆˆN if X is a supermartingale.
Remark 11.8 The statement of Theorem 11.7 can be reformulated as: The process
(Xn)nâˆˆN0âˆª{âˆ} is a (sub-, super-) martingale with respect to (Fn)nâˆˆN0âˆª{âˆ}. â™¦
Proof We give the proof for the case where X is a submartingale. Uniform
integrability implies sup{E[X+
n ] :
n â‰¥0} < âˆ. By Theorem 11.4, the almost
sure limit Xâˆexists. Hence E[|Xn âˆ’Xâˆ|]
nâ†’âˆ
âˆ’â†’
0 by Theorem 6.25. By
Corollary 8.21, the L1-convergence of (Xn) implies the L1-convergence of the

11.2
Martingale Convergence Theorems
247
conditional expectations: E
)E[Xn
Fm] âˆ’E[Xâˆ
Fm]
*
nâ†’âˆ
âˆ’â†’
0. Thus, by the
triangle inequality,
E
)
E[Xâˆ
Fm] âˆ’Xm
âˆ’*
âˆ’E
)
E[Xn
Fm] âˆ’Xm
âˆ’*
â‰¤E
'E[Xâˆ
Fm] âˆ’E[Xn
Fm]

( nâ†’âˆ
âˆ’â†’0.
As X is a submartingale, we have E[Xn
Fm] âˆ’Xm
âˆ’= 0 for n â‰¥m. Therefore,
E
) 
E[Xâˆ
Fm] âˆ’Xm
âˆ’*
= 0 and thus E[Xâˆ
Fm] âˆ’Xm â‰¥0 almost surely.
âŠ“âŠ”
Corollary 11.9 Let X â‰¥0 be a martingale and let Xâˆ= lim
nâ†’âˆXn. Then E[Xâˆ] =
E[X0] if and only if X is uniformly integrable.
Proof This is a direct consequence of Theorem 6.25.
âŠ“âŠ”
Let p âˆˆ[1, âˆ). A real-valued stochastic process (Xi)iâˆˆI is called Lp-bounded if
supiâˆˆI E[|Xi|p] < âˆ(Deï¬nition 6.20). In general, for (|Xi|p)iâˆˆI to be uniformly
integrable it is not enough that (Xi)iâˆˆI be Lp-bounded. However, if X is a
martingale and if p > 1, then Doobâ€™s inequality implies that the statements are
equivalent. In particular, in this case, almost sure convergence implies convergence
in Lp.
Theorem 11.10 (Lp-convergence theorem for martingales) Let p > 1 and let
(Xn)nâˆˆN0 be an Lp-bounded martingale. Then there exists an Fâˆ-measurable
random variable Xâˆwith E[|Xâˆ|p] < âˆand Xn
nâ†’âˆ
âˆ’â†’Xâˆalmost surely and
in Lp. In particular, (|Xn|p)nâˆˆN0 is uniformly integrable.
Proof By Corollary 6.21, X is uniformly integrable. Hence the almost sure limit
Xâˆexists. By Doobâ€™s inequality (Theorem 11.2), for all n âˆˆN,
E
)
sup
	
|Xk|p : k â‰¤n

*
â‰¤

p
p âˆ’1
p
E
)
|Xn|p*
.
Therefore,
E
'
sup
	
|Xk|p : k âˆˆN0

(
â‰¤

p
p âˆ’1
p
sup

E
)
|Xn|p*
: n âˆˆN0

< âˆ.
Hence, in particular, (|Xn|p)nâˆˆN0 is uniformly integrable.
Since |Xn âˆ’Xâˆ|p â‰¤2p sup{|Xm|p : m âˆˆN0}, dominated convergence yields
E
)
|Xâˆ|p*
< âˆ
and
E
)
|Xn âˆ’Xâˆ|p* nâ†’âˆ
âˆ’â†’0.
âŠ“âŠ”
Reï¬‚ection Let (Xn) be an Lp-bounded sequence of random variables that is almost
surely convergent. In general, this does not imply that (Xn) also converges in Lp.

248
11
Martingale Convergence Theorems and Their Applications
However, for martingales, it does as we have seen in the above theorem. Exactly
where in the proof did we use the martingale property? â™ 
For the case of square integrable martingales, there is a convenient criterion for
L2-boundedness that we record as a corollary (see Deï¬nition 10.3).
Corollary 11.11 Let X be a square integrable martingale with square variation
process âŸ¨XâŸ©. Then the following four statements are equivalent:
(i) supnâˆˆN E[X2
n] < âˆ.
(ii) limnâ†’âˆE[âŸ¨XâŸ©n] < âˆ.
(iii) X converges in L2.
(iv) X converges almost surely and in L2.
Proof â€œ((i)) â‡â‡’((ii))â€
Since Var[Xn âˆ’X0] = E[âŸ¨XâŸ©n] (see Theorem 10.4),
X is bounded in L2 if and only if ((ii)) holds.
â€œ((iv)) â‡’((iii)) â‡’((i))â€
This is trivial.
â€œ((i)) â‡’((iv))â€
This is the statement of Theorem 11.10.
âŠ“âŠ”
Remark 11.12 In general, the statement of Theorem 11.10 fails for p = 1. See
Exercise 11.2.1. â™¦
Lemma 11.13 Let X be a square integrable martingale with square variation
process âŸ¨XâŸ©, and let Ï„ be a stopping time. Then the stopped process XÏ„ has square
variation process âŸ¨XÏ„ âŸ©= âŸ¨XâŸ©Ï„ := (âŸ¨XâŸ©Ï„âˆ§n)nâˆˆN0.
Proof This is left as an exercise.
âŠ“âŠ”
If in Corollary 11.11 we do not assume that the expectations of the square variation
are bounded but only that the square variation is almost surely bounded, then we
still get that X converges almost surely (albeit not in L2).
Theorem 11.14 If X is a square integrable martingale with supnâˆˆNâŸ¨XâŸ©n < âˆ
almost surely, then X converges almost surely.
Proof Without loss of generality, we can assume that X0 = 0, otherwise consider
the martingale (Xn âˆ’X0)nâˆˆN0, which has the same square variation process. For
K > 0, let
Ï„K := inf{n âˆˆN : âŸ¨XâŸ©n+1 â‰¥K}.
This is a stopping time since âŸ¨XâŸ©is predictable. Evidently, supnâˆˆNâŸ¨XâŸ©Ï„K âˆ§n â‰¤K
almost surely. By Corollary 11.11, the stopped process XÏ„K converges almost surely
(and in L2) to a random variable that we denote by XÏ„K
âˆ. By assumption, P[Ï„K =
âˆ] â†’1 for K â†’âˆ; hence X converges almost surely.
âŠ“âŠ”

11.2
Martingale Convergence Theorems
249
Example 11.15 Let X be a symmetric simple random walk on Z. That is, Xn =
n
k=1
Rk, where R1, R2, . . . are i.i.d. and âˆ¼Rad1/2:
P[R1 = 1] = P[R1 = âˆ’1] = 1
2.
Then X is a martingale; however, lim supnâ†’âˆXn = âˆand lim infnâ†’âˆXn = âˆ’âˆ.
Therefore, X does not even converge improperly. By the martingale convergence
theorem, this is consonant with the fact that X is not uniformly integrable. â™¦
Example 11.16 (Voter model, due to [28, 75]) Consider a simple model that
describes the behavior of opportunistic voters who are capable of only one out of
two opinions, say 0 and 1. Let Î› âŠ‚Zd be a set that we interpret as the sites at each
of which there is one voter. For simplicity, assume that Î› = {0, . . ., L âˆ’1}d for
some L âˆˆN. Let x(i) âˆˆ{0, 1} be the opinion of the voter at site i âˆˆÎ› and denote
by x âˆˆ{0, 1}Î› a generic state of the whole population. We now assume that the
individual opinions may change at discrete time steps. At any time n âˆˆN0, one site
In out of Î› is chosen at random and the individual at that site reconsiders his or
her opinion. To this end, the voter chooses a neighbor In + Nn âˆˆÎ› (with periodic
boundary conditions; that is, with addition modulo L in each coordinate) at random
and adopts his or her opinion. We thus get a random sequence (Xn)nâˆˆN0 of states
in {0, 1}Î› that represents the random evolution of the opinions of the whole colony.
See Fig. 11.2 for a simulation of the voter model.
For a formal description of this model, let (In)nâˆˆN and (Nn)nâˆˆN be independent
random variables. For any n âˆˆN, In is uniformly distributed on Î› and Nn is
uniformly distributed on the set N := {i âˆˆZd : âˆ¥iâˆ¥2 = 1} of the 2d nearest
neighbors of the origin. Furthermore, x = X0 âˆˆ{0, 1}Î› is the initial state. The
states at later times are deï¬ned inductively by
Xn(i) =

Xnâˆ’1(i),
if In Ì¸= i,
Xnâˆ’1(In + Nn),
if In = i.
Of course, the behavior over small periods of time is determined by the perils of
randomness. However, in the long run, we might see certain patterns. To be more
speciï¬c, the question is: In the long run, will there be a consensus of all individuals
or will competing opinions persist?

250
11
Martingale Convergence Theorems and Their Applications
Fig. 11.2 Snapshot of a voter model on an 800 Ã— 800 torus. The black dots are the Ones.
Let Mn := 
iâˆˆÎ› Xn(i) be the total number of individuals of opinion 1 at time
n. Let F be the ï¬ltration F = (Fn)nâˆˆN0, where Fn = Ïƒ(Ik, Nk : k â‰¤n) for all
n âˆˆN0. Then M is adapted to F and
E[Mn
Fnâˆ’1] = Mnâˆ’1 âˆ’E[Xnâˆ’1(In)
Fnâˆ’1] + E[Xnâˆ’1(In + Nn)
Fnâˆ’1]
= Mnâˆ’1 âˆ’

iâˆˆÎ›
P[In = i] Xnâˆ’1(i) +

iâˆˆÎ›
P[In + Nn = i] Xnâˆ’1(i)
= Mnâˆ’1
since P[In = i] = P[In + Nn = i] = Lâˆ’d for all i âˆˆÎ›. Hence M is a bounded
F-martingale and thus converges almost surely and in L1 to a random variable Mâˆ.
Since M takes only integer values, there is a (random) n0 such that Mn = Mn0 for
all n â‰¥n0. However, then also Xn = Xn0 for all n â‰¥n0. Manifestly, no state x with
x Ì¸â‰¡0 and x Ì¸â‰¡1 is stable. In fact, if x is not constant and if i, j âˆˆÎ› are neighbors
with x(i) Ì¸= x(j), then
P[Xn Ì¸= Xnâˆ’1
Xnâˆ’1 = x] â‰¥P[Inâˆ’1 = i, Nnâˆ’1 = j âˆ’i] = Lâˆ’d(2d)âˆ’1.

11.2
Martingale Convergence Theorems
251
This implies Mâˆâˆˆ{0, Ld}. Now E[Mâˆ] = M0; hence we have
P
)
Mâˆ= Ld *
= M0
Ld
and
P
)
Mâˆ= 0
*
= 1 âˆ’M0
Ld .
Thus, eventually there will be a consensus of all individuals, and the probability that
the surviving opinion is e âˆˆ{0, 1} is the initial frequency of opinion e.
We could argue more formally to show that only the constant states are stable:
Let âŸ¨MâŸ©be the square variation process of M. Then
âŸ¨MâŸ©n =
n

k=1
E)1{MkÌ¸=Mkâˆ’1}
Fkâˆ’1
* =
n

k=1
P)Xkâˆ’1(Ik) Ì¸= Xkâˆ’1(Ik + Nk)
Fkâˆ’1
*.
Hence
L2d â‰¥Var[Mn] = E[âŸ¨MâŸ©n]
=
n

k=1
P[Xkâˆ’1(Ik) Ì¸= Xkâˆ’1(Ik + Nk)]
â‰¥(2d)âˆ’1Lâˆ’d
n

k=1
P[Mkâˆ’1 Ì¸âˆˆ{0, Ld}].
Therefore, âˆ
k=1 P[Mkâˆ’1 Ì¸âˆˆ{0, Ld}] â‰¤2dL3d < âˆ, and so, by the Borelâ€“Cantelli
lemma, Mâˆâˆˆ{0, Ld}. â™¦
Example 11.17 (Radonâ€“Nikodym theorem) With the aid of the martingale con-
vergence theorem, we give an alternative proof of the Radonâ€“Nikodym theorem
(Corollary 7.34).
Let (Î©, F, P) be a probability space and let Q be another probability measure
on (Î©, A). We assume that F is countably generated; that is, there exist countably
many sets A1, A2, . . . âˆˆF such that F = Ïƒ({A1, A2, . . .}). For example, this is the
case if F is the Borel Ïƒ-algebra on a Polish space. For the case Î© = Rd, one could
take the open balls with rational radii, centered at points with rational coordinates
(compare Remark 1.24).
We construct a ï¬ltration F = (Fn)nâˆˆN by letting Fn := Ïƒ({A1, . . . , An}).
Evidently, #Fn < âˆfor all n âˆˆN. More precisely, there exists a unique ï¬nite
subset Zn âŠ‚Fn \ {âˆ…} such that B =

CâˆˆZn
CâŠ‚B
C for any B âˆˆFn. Zn decomposes Fn
into its â€œatomsâ€. Finally, deï¬ne a stochastic process (Xn)nâˆˆN by
Xn :=

CâˆˆZn: P[C]>0
Q(C)
P[C] 1C.

252
11
Martingale Convergence Theorems and Their Applications
Clearly, X is adapted to F. Let B âˆˆFn and m â‰¥n. For any C âˆˆZm, either
C âˆ©B = âˆ…or C âŠ‚B. Hence
E[Xm 1B] =

CâˆˆZm: P[C]>0
Q(C)
P[C] P[C âˆ©B] =

CâˆˆZm: CâŠ‚B
Q(C) = Q(B).
(11.1)
In particular, X is an F-martingale.
Now assume that Q is absolutely continuous with respect to P. By Example 7.39,
this implies that X is uniformly integrable. By the martingale convergence theorem,
X converges P-almost surely and in L1(P) to a random variable Xâˆ. By (11.1),
we have E[Xâˆ1B] = Q(B) for all B âˆˆ
nâˆˆN Fn and thus also for all B âˆˆF.
Therefore, Xâˆis the Radonâ€“Nikodym density of Q with respect to P.
Note that for this proof we did not presume the existence of conditional
expectations (rather we constructed them explicitly for ï¬nite Ïƒ-algebras); that is,
we did not resort to the Radonâ€“Nikodym theorem in a hidden way.
It could be objected that this argument works only for probability measures.
However, this ï¬‚aw can easily be remedied. Let Î¼ and Î½ be arbitrary (but nonzero)
Ïƒ-ï¬nite measures. Then there exist measurable functions g, h : Î© â†’(0, âˆ) with
3
g dÎ¼ = 1 and
3
h dÎ½ = 1. Deï¬ne P = gÎ¼ and Q = hÎ½. Clearly, Q â‰ªP if
Î½ â‰ªÎ¼. In this case, g
hXâˆis a version of the Radonâ€“Nikodym derivative dÎ½
dÎ¼.
The restriction that F is countably generated can also be dropped. Using the
approximation theorems for measures, it can be shown that there is always a
countably generated Ïƒ-algebra G âŠ‚F such that for any A âˆˆF, there is a B âˆˆG
with P[Aâ–³B] = 0. This can be employed to prove the general case. We do not give
the details but refer to [170, Chapter 14.13]. â™¦
Takeaways For (sub-) martingales, Doobâ€™s upcrossing lemma bounds the
number of upcrossings over a given interval. As a consequence, we get almost
sure convergence of nonnegative (super-) martingales. Uniformly integrable
(sub-, super-) martingales converge almost surely and in L1. For p > 1, Lp-
bounded martingales also converge in Lp.
Exercise 11.2.1 For p = 1, the statement of Theorem 11.10 may fail. Give an
example of a nonnegative martingale X with E[Xn] = 1 for all n âˆˆN but such that
Xn
nâ†’âˆ
âˆ’â†’0 almost surely. â™£
Exercise 11.2.2 Let X1, X2, . . . be independent, square integrable random vari-
ables with âˆ
n=1
1
n2 Var[Xn] < âˆ. Use the martingale convergence theorem to
show the strong law of large numbers for (Xn)nâˆˆN. â™£
Exercise 11.2.3 Give an example of a square integrable martingale that converges
almost surely but not in L2. â™£

11.2
Martingale Convergence Theorems
253
Exercise 11.2.4 Show that in Theorem 11.14 the converse implication may fail.
That is, there exists a square integrable martingale X that converges almost surely
but without lim
nâ†’âˆâŸ¨XâŸ©n < âˆalmost surely. â™£
Exercise 11.2.5 Show the following converse of Theorem 11.14. Let L > 0 and let
(Xn)nâˆˆN be a martingale with the property
Xn+1 âˆ’Xn
 â‰¤L
a.s.
(11.2)
Deï¬ne the events
C :=
	
(Xn)nâˆˆN converges as n â†’âˆ

,
A+ :=

lim sup
nâ†’âˆ
Xn < âˆ

,
Aâˆ’:=

lim inf
nâ†’âˆXn > âˆ’âˆ

,
F :=

sup
nâˆˆN
âŸ¨XâŸ©n < âˆ

.
Show that
C = A+ = Aâˆ’= F
(mod P).
Here equality of events (mod P) means that the events differ at most by a P-null set
(see Deï¬nition 1.68(iii)).
Hint: Use the stopping times ÏƒK = inf{n âˆˆN : |Xn| â‰¥K}; Ïƒ Â±
K = inf{n âˆˆN :
Â±Xn â‰¥K} and Ï„K as in the proof of Theorem 11.14. â™£
Exercise 11.2.6 Let the notation be as in Exercise 11.2.5. However, instead of
(11.2) we make the weaker assumption
E
'
sup
nâˆˆN
Xn+1 âˆ’Xn

(
< âˆ.
(11.3)
Show that
C = A+ = Aâˆ’
(mod P).
Hint:
Use suitable stopping times Ï±K and apply the martingale convergence
theorem (Theorem 11.4) to the stopped process XÏ±K. â™£
Exercise 11.2.7 (Conditional Borelâ€“Cantelli lemma) Let (Fn)nâˆˆN0 be a ï¬ltration
and let (An)nâˆˆN be events with An
âˆˆ
Fn for all n
âˆˆ
N. Deï¬ne Aâˆ
=
	 âˆ
n=1 P[An|Fnâˆ’1] = âˆ

and Aâˆ—= lim supnâ†’âˆAn. Show the conditional
Borelâ€“Cantelli lemma: P[Aâˆâ–³Aâˆ—] = 0.

254
11
Martingale Convergence Theorems and Their Applications
Hint: Apply Exercise 11.2.5 to Xn = âˆ
n=1(1An âˆ’P[An|Fnâˆ’1]). â™£
Exercise 11.2.8 Let p âˆˆ[0, 1] and let X = (Xn)nâˆˆN0 be a stochastic process with
values in [0, 1]. Assume that for all n âˆˆN0, given X0, . . . , Xn, we have
Xn+1 =
0 1 âˆ’p + pXn
with probability Xn,
pXn
with probability 1 âˆ’Xn.
Show that X is a martingale that converges almost surely. Compute the distribution
of the almost sure limit limnâ†’âˆXn. â™£
Exercise 11.2.9 Let f âˆˆL1(Î»), where Î» is the restriction of the Lebesgue measure
to [0, 1]. Let In,k = [k 2âˆ’n, (k + 1) 2âˆ’n) for n âˆˆN and k = 0, . . . , 2n âˆ’1. Deï¬ne
fn : [0, 1] â†’R by
fn(x) = 2n

Ik,n
f dÎ»,
if k is chosen such that x âˆˆIk,n.
Show that fn(x)
nâ†’âˆ
âˆ’â†’f (x) for Î»-almost all x âˆˆ[0, 1]. â™£
Exercise 11.2.10 Assume that F = (Fn)nâˆˆN is a ï¬ltration on the probability
space (Î©, A, P). Let Fâˆ:= Ïƒ(Fn : n âˆˆN), and let M be the vector space
of uniformly integrable F-martingales. Show that the map Î¦ : L1(Fâˆ) â†’M,
Xâˆâ†’(E[Xâˆ|Fn])nâˆˆN is an isomorphism of vector spaces. â™£
11.3
Example: Branching Process
Let p = (pk)kâˆˆN0 be a probability vector on N0 and let (Zn)nâˆˆN0 be the Galtonâ€“
Watson process with one ancestor and offspring distribution p (see Deï¬nition 3.9).
For convenience, we recall the construction of Z. Let (Xn,i)nâˆˆN0, iâˆˆN be i.i.d.
random variables with P[X1,1 = k] = pk for k âˆˆN0. Let Z0 = 1 and inductively
deï¬ne
Zn+1 =
Zn

i=1
Xn,i
for n âˆˆN0.
We interpret Zn as the size of a population at time n and Xn,i as the number of
offspring of the ith individual of the nth generation.
Let m := E[X1,1] < âˆbe the expected number of offspring of an individual and
let Ïƒ 2 := Var[X1,1] âˆˆ(0, âˆ) be its variance. Let Fn := Ïƒ(Xk,i : k < n, i âˆˆN).
Then Z is adapted to F. Deï¬ne Wn = mâˆ’n Zn.
Lemma 11.18 W is a martingale. In particular, E[Zn] = mn for all n âˆˆN.

11.3
Example: Branching Process
255
Proof We compute the conditional expectation for n âˆˆN0:
E[Wn+1
Fn] = mâˆ’(n+1) E[Zn+1
Fn]
= mâˆ’(n+1) E
- Zn

i=1
Xn,i
Fn
.
= mâˆ’(n+1)
âˆ

k=1
E
)
1{Zn=k}k Â· Xn,i
Fn
*
= mâˆ’n
âˆ

k=1
E
)
k Â· 1{Zn=k}
Fn
*
= mâˆ’n Zn = Wn.
âŠ“âŠ”
Theorem 11.19 Let Var[X1,1] âˆˆ(0, âˆ). The a.s. limit Wâˆ= lim
nâ†’âˆWn exists and
m > 1
â‡â‡’
E[Wâˆ] = 1
â‡â‡’
E[Wâˆ] > 0.
Proof Wâˆexists since W â‰¥0 is a martingale. If m â‰¤1, then (Zn)nâˆˆN converges
a.s. to some random variable Zâˆ. Note that Zâˆis the only choice since Ïƒ 2 > 0.
Now let m > 1. Since E[Znâˆ’1] = mnâˆ’1 (Lemma 11.18), by the Blackwellâ€“
Girshick formula (Theorem 5.10),
Var[Wn] = mâˆ’2n 
Ïƒ 2 E[Znâˆ’1] + m2 Var[Znâˆ’1]

= Ïƒ 2 mâˆ’(n+1) + Var[Wnâˆ’1].
Inductively, we get Var[Wn] = Ïƒ 2
n+1

k=2
mâˆ’k â‰¤Ïƒ 2 m
m âˆ’1 < âˆ. Hence W is bounded
in L2 and Theorem 11.10 yields Wn â†’Wâˆin L2 and thus in L1. In particular,
E[Wâˆ] = E[W0] = 1.
âŠ“âŠ”
Reï¬‚ection Typically, the distribution of W cannot be computed explicitly. How-
ever, here we sketch a particular situation where this is possible. Assume that the
offspring distribution is given by P[X1,1 = k] = 1
3(2/3)k, k âˆˆN0. In Lemma 3.10,
we have seen how to iterate the generating function Ïˆ(s) = E[sX1,1] = 1/(3 âˆ’2s)

256
11
Martingale Convergence Theorems and Their Applications
so as to get Ïˆn(s) = E[sZn] =
(2âˆ’2n)s+2nâˆ’1
(2âˆ’2n+1)s+2n+1âˆ’1. Compare also Lemma 21.44. By
letting s = eâˆ’Î»/2n, we obtain
lim
nâ†’âˆE[eÎ»Zn/2n] = 1 + Î»
1 + 2Î» = 1
2 + 1
2
1
1 + 2Î» = E[eâˆ’Î»W],
where in the last step we assumed that PW = 1
2Î´0 + 1
2 exp1/2. â™ â™ â™ 
The proof of Theorem 11.19 was simple due to the assumption of ï¬nite variance of
the offspring distribution. However, there is a much stronger statement that here we
can only quote (see [95], and see [111] for a modern proof).
Theorem 11.20 (Kestenâ€“Stigum [95]) Let m > 1. Then
E[Wâˆ] = 1
â‡â‡’
E[Wâˆ] > 0
â‡â‡’
E[X1,1 log(X1,1)+] < âˆ.
Takeaways A Galton-Watson branching process (Zn) with mean offspring
number m > 1 has a positive chance to survive and in this case grows
indeï¬nitely. If the offspring number has a second moment, then Zn grows
of order mn and Zn/mn is uniformly integrable. Hence Zn/mn is an almost
surely and L1-convergent martingale. In general, the growth to inï¬nity of Zn
can also be slower than mn.

Chapter 12
Backwards Martingales
and Exchangeability
With many data acquisitions, such as telephone surveys, the order in which the data
come does not matter. Mathematically, we say that a family of random variables is
exchangeable if the joint distribution does not change under ï¬nite permutations. De
Finettiâ€™s structural theorem says that an inï¬nite family of E-valued exchangeable
random variables can be described by a two-stage experiment. At the ï¬rst stage,
a probability distribution Î on E is drawn at random. At the second stage, i.i.d.
random variables with distribution Î are implemented.
We ï¬rst deï¬ne the notion of exchangeability. Then we consider backwards
martingales and prove the convergence theorem for them. This is the cornerstone
for the proof of de Finettiâ€™s theorem.
12.1
Exchangeable Families of Random Variables
Deï¬nition 12.1 Let I be an arbitrary index set and let E be a Polish space. A family
(Xi)iâˆˆI of random variables with values in E is called exchangeable if
L )XÏ±(i)

iâˆˆI
* = L )
(Xi)iâˆˆI
*
for any ï¬nite permutation Ï± : I â†’I.
Recall that a ï¬nite permutation is a bijection Ï± : I â†’I that leaves all but ï¬nitely
many points unchanged.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_12
257

258
12
Backwards Martingales and Exchangeability
Strictly speaking, the deï¬nition of exchangeability makes sense only if we
identify Y = (Xi)iâˆˆI and Y â€² = (XÏ±(i))iâˆˆI as random variables on the product space
EI. The investigation of product spaces and their Ïƒ-algebras is, however, postponed
to Chap. 14.
Remark 12.2 Clearly, the following are equivalent.
(i) (Xi)iâˆˆI is exchangeable.
(ii) Let n âˆˆN and assume i1, . . . , in âˆˆI are pairwise distinct and j1, . . . , jn âˆˆI
are pairwise distinct. Then we have L[(Xi1, . . . , Xin)] = L[(Xj1, . . . , Xjn)].
In particular (n = 1), exchangeable random variables are identically distributed. â™¦
Example 12.3
(i) If (Xi)iâˆˆI is i.i.d., then (Xi)iâˆˆI is exchangeable.
(ii) Consider an urn with N balls, M of which are black. Successively draw without
replacement all of the balls and deï¬ne
Xn :=

1,
if the nth ball is black,
0,
else.
Then (Xn)n=1,...,N is exchangeable. Indeed, this follows by elementary com-
binatorics since for any choice x1, . . . , xN âˆˆ{0, 1} with x1 + . . . + xN = M,
we have
P
)
X1 = x1, . . . , XN = xN
*
=
1
N
M
.
This formula can be derived formally via a small computation with conditional
probabilities. As we will need a similar computation for PÃ³lyaâ€™s urn model
in Example 12.29, we give the details here. Let sk = x1 + . . . + xk for k =
0, . . . , N and let
gk(x) =
0
M âˆ’sk,
if x = 1,
N âˆ’M + sk âˆ’k,
if x = 0.
Then P[X1 = x1] = g0(x1)/N and
P[Xk+1 = xk+1|X1 = x1, . . . , Xk = xk] = gk(xk+1)
N âˆ’k
for k = 1, . . . , N âˆ’1.

12.1
Exchangeable Families of Random Variables
259
Clearly, gk(0) = N âˆ’M âˆ’l, where l = #{i â‰¤k : xi = 0}. Therefore,
P[X1 = x1, . . . , XN = xN]
= P[X1 = x1]
Nâˆ’1

k=1
P[Xk+1 = xk+1|X1 = x1, . . . , Xk = xk]
= 1
N!
Nâˆ’1

k=0
gk(xk+1) =
1
N!

k: xk=1
gk(1)

k: xk=0
gk(0)
= 1
N!
Mâˆ’1

l=0
(M âˆ’l)
Nâˆ’1

l=0
(N âˆ’M âˆ’l) = M! (N âˆ’M)!
N!
.
(iii) Let Y be a random variable with values in [0, 1]. Assume that, given Y, the
random variables (Xi)iâˆˆI are independent and BerY -distributed. That is, for
any ï¬nite J âŠ‚I,
P[Xj = 1 for all j âˆˆJ
Y] = Y #J.
Then (Xi)iâˆˆI is exchangeable. â™¦
Reï¬‚ection Find an example of an exchangeable family (Xn)nâˆˆN of {0, 1}-valued
random variables that is not independent.â™ 
Let X = (Xn)nâˆˆN be a stochastic process with values in a Polish space E.
Let S(n) be the set of permutations Ï± : {1, . . ., n} â†’{1, . . ., n}. We consider
Ï± also as a map N â†’N by deï¬ning Ï±(k) = k for k > n. For Ï± âˆˆS(n)
and x = (x1, . . . , xn) âˆˆEn, denote xÏ± = (xÏ±(1), . . . , xÏ±(n)). Similarly, for
x âˆˆEN, denote xÏ± = (xÏ±(1), xÏ±(2), . . .) âˆˆEN. Let Eâ€² be another Polish space.
For measurable maps f : En â†’Eâ€² and F : EN â†’Eâ€², deï¬ne the maps f Ï± and F Ï±
by f Ï±(x) = f (xÏ±) and F Ï±(x) = F(xÏ±). Further, we write f (x) = f (x1, . . . , xn)
for x âˆˆEn and for x âˆˆEN.
Deï¬nition 12.4
(i) A map f : En â†’Eâ€² is called symmetric if f Ï± = f for all Ï± âˆˆS(n).
(ii) A map F : EN â†’Eâ€² is called n-symmetric if F Ï± = F for all Ï± âˆˆS(n). F is
called symmetric if F is n-symmetric for all n âˆˆN.
Example 12.5
(i) For x âˆˆRN, deï¬ne the nth arithmetic mean by an(x) = 1
n
n
i=1 xi. Clearly,
an is an n-symmetric map (but not m-symmetric for any m > n). Furthermore,
Â¯a(x) := lim sup
nâ†’âˆ
an(x) deï¬nes a symmetric map RN â†’R âˆª{âˆ’âˆ, +âˆ}.
(ii) The map s : RN â†’[0, âˆ], x â†’âˆ
i=1 |xi| is symmetric. Unlike Â¯a, the value
of s depends on every coordinate if it is ï¬nite.

260
12
Backwards Martingales and Exchangeability
(iii) For x âˆˆEN, deï¬ne the nth empirical distribution by Î¾n(x) =
1
n
n
i=1 Î´xi
(recall that Î´xi is the Dirac measure at the point xi). Clearly, Î¾n is an n-
symmetric map.
(iv) Let k âˆˆN and let Ï• : Ek â†’R be a map. The nth symmetrized average
An(Ï•) : EN â†’R,
x â†’1
n!

Ï±âˆˆS(n)
Ï•(xÏ±)
(12.1)
is an n-symmetric map. â™¦
Deï¬nition 12.6 Let X = (Xn)nâˆˆN be a stochastic process with values in E. For
n âˆˆN, deï¬ne
Eâ€²
n := Ïƒ(F : F : EN â†’R is measurable and n-symmetric)
and let En := Xâˆ’1(Eâ€²
n) be the Ïƒ-algebra of events that are invariant under all
permutations Ï± âˆˆS(n). Further, let
Eâ€² :=
âˆ

n=1
Eâ€²
n = ÏƒF : F : EN â†’R is measurable and symmetric
and let En := âˆ
n=1 En = Xâˆ’1(Eâ€²) be the Ïƒ-algebra of exchangeable events for X,
or brieï¬‚y the exchangeable Ïƒ-algebra.
Remark 12.7 If A âˆˆÏƒ(Xn, n âˆˆN) is an event, then there is a measurable B âŠ‚EN
with A = {X âˆˆB}. If we denote AÏ± = {XÏ± âˆˆB} for Ï± âˆˆS(n), then En = {A :
AÏ± = A for all Ï± âˆˆS(n)}. This justiï¬es the name â€œexchangeable eventâ€. â™¦
Remark 12.8 If we write În(Ï‰) := Î¾n(X(Ï‰)) =
1
n
n
i=1 Î´Xi(Ï‰) for the nth
empirical distribution, then, by Exercise 12.1.1, we have En âŠƒÏƒ(În) and En =
Ïƒ(În, Xn+1, Xn+2, . . .).. â™¦
Remark 12.9 Denote by T = 
nâˆˆN Ïƒ(Xn+1, Xn+2, . . .) the tail Ïƒ-algebra. Then
T âŠ‚E, and strict inclusion is possible.
Indeed, evidently Ïƒ(Xn+1, Xn+2, . . .) âŠ‚En for n âˆˆN; hence T âŠ‚E. Now let
E = {0, 1} and let X1, X2, . . . be independent random variables with P[Xn = 1] âˆˆ
(0, 1) for all n âˆˆN. The random variable S := âˆ
n=1 Xn is measurable with respect
to E but not with respect to T . â™¦
Theorem 12.10 Let X = (Xn)nâˆˆN be exchangeable. If Ï• : EN â†’R is measurable
and if E[|Ï•(X)|] < âˆ, then for all n âˆˆN and all Ï± âˆˆS(n),
E[Ï•(X)|En] = E[Ï•(XÏ±)|En].
(12.2)

12.1
Exchangeable Families of Random Variables
261
In particular,
E[Ï•(X)
En] = An(Ï•) := 1
n!

Ï±âˆˆS(n)
Ï•(XÏ±).
(12.3)
Proof Let A âˆˆEn. Then there exists a B âˆˆEâ€²
n such that A = Xâˆ’1(B). Let F = 1B.
Then F â—¦X = 1A. By the deï¬nition of En, the map F : EN â†’R is measurable,
n-symmetric and bounded. Therefore,
E
)
Ï•(X)F(X)
*
= E
)
Ï•(XÏ±)F(XÏ±)
*
= E
)
Ï•(XÏ±)F(X)
*
.
Here we used the exchangeability of X in the ï¬rst equality and the symmetry of F
in the second equality. From this (12.2) follows. However, An(Ï•) is En-measurable
and hence
E)Ï•(X)
En
* = E
â¡
â£1
n!

Ï±âˆˆS(n)
Ï•(XÏ±)
En
â¤
â¦= 1
n!

Ï±âˆˆS(n)
Ï•(XÏ±).
âŠ“âŠ”
Heuristic for the Structure of Exchangeable Families
Consider a ï¬nite exchangeable family X1, . . . , XN of E-valued random variables.
For n â‰¤N, what is the conditional distribution of (X1, . . . , Xn) given ÎN? For any
measurable A âŠ‚E, {Xi âˆˆA} occurs for exactly NÎN(A) of the i âˆˆ{1, . . ., N},
where the order does not change the probability. Hence we are in the situation of
drawing colored balls without replacement. More precisely, let the pairwise distinct
points e1, . . . , ek âˆˆE be the atoms of ÎN and let N1, . . . , Nk be the corresponding
absolute frequencies. Hence ÎN = k
i=1(Ni/N)Î´ei. We thus deal with balls of k
different colors and with Ni balls of the ith color. We draw n of these balls without
replacement but respecting the order. Up to the order, the resulting distribution is
thus the generalized hypergeometric distribution (see (1.19) on page 48). Hence, for
pairwise disjoint, measurable sets A1, . . . , Ak with k
l=1 Al = E, for i1, . . . , in âˆˆ
{1, . . ., k}, pairwise distinct j1, . . . , jn âˆˆ{1, . . . , N} and with the convention ml :=
#{r âˆˆ{1, . . . , n} : ir = l} for l âˆˆ{1, . . . , k}, we have
P
)
Xjr âˆˆAir for all r = 1, . . . , n
ÎN
*
=
1
(N)n
k
l=1

NÎN(Al)

ml.
(12.4)
Here we deï¬ned (n)l := n(n âˆ’1) Â· Â· Â· (n âˆ’l + 1).

262
12
Backwards Martingales and Exchangeability
What happens if we let N â†’âˆ? For simplicity, assume that for all l = 1, . . . , k,
the limit Îâˆ(Al) = limNâ†’âˆÎN(Al) exists in a suitable sense. Then (12.4)
formally becomes
P
)
Xjr âˆˆAir for all r = 1, . . . , n
Îâˆ
*
=
k
l=1
Îâˆ(Al)ml.
(12.5)
Drawing without replacements thus asymptotically turns into drawing with replace-
ments. Hence the random variables X1, X2, . . . are independent with distribution
Îâˆgiven Îâˆ.
For a formal proof along the lines of this heuristic, see Sect. 13.4.
In order to formulate (and prove) this statement (de Finettiâ€™s theorem) rigorously
in Sect. 12.3, we need some more technical tools (e.g., the notion of conditional
independence). A further tool will be the convergence theorem for backwards mar-
tingales that will be formulated in Sect. 12.2. For further reading on exchangeable
random variables, we refer to [4, 33, 98, 105].
Takeaways An event that is described by a sequence X1, X2, . . . of random
variables is called symmetric if ï¬nitely many of the Xi can be permuted
without changing the event. The event is called n-symmetric if we allow only
permutations of X1, . . . , Xn for some n. The exchangeable events form the
so-called exchangeable Ïƒ-algebra E. Every terminal event is symmetric. The
family X = (Xn)nâˆˆN is called exchangeable if ï¬nitely many of the Xi can be
permuted without changing the distribution of the family.
Exercise 12.1.1 Let n âˆˆN. Show that every symmetric function f : En â†’R
can be written in the form f (x) = g
 1
n
n
i=1 Î´xi

, where g has to be chosen
appropriately (depending on f ). â™£
Exercise 12.1.2 Derive equation (12.4) formally. â™£
Exercise 12.1.3 Let X1, . . . , Xn be exchangeable, square integrable random vari-
ables. Show that
Cov[X1, X2] â‰¥âˆ’
1
n âˆ’1 Var[X1].
(12.6)
For n â‰¥2, give a nontrivial example for equality in (12.6). â™£
Exercise 12.1.4 Let X1, X2, X3 . . . be exchangeable, square integrable random
variables. Show that Cov[X1, X2] â‰¥0. â™£

12.2
Backwards Martingales
263
Exercise 12.1.5 Show that for all n âˆˆN \ {1}, there is an exchangeable family of
random variables X1, . . . , Xn that cannot be extended to an inï¬nite exchangeable
family X1, X2, . . .. â™£
12.2
Backwards Martingales
The concepts of ï¬ltration and martingale do not require the index set I (interpreted
as time) to be a subset of [0, âˆ). Hence we can consider the case I = âˆ’N0.
Deï¬nition 12.11 (Backwards martingale) Let F = (Fn)nâˆˆâˆ’N0 be a ï¬ltration. A
stochastic process X = (Xn)nâˆˆN0 is called a backwards martingale with respect
to F if X = (Xâˆ’n)nâˆˆâˆ’N0 is an F-martingale.
Remark 12.12 A backwards martingale is always uniformly integrable. This fol-
lows from Corollary 8.22 and the fact that Xâˆ’n = E[X0
Fâˆ’n] for any n âˆˆN0.
â™¦
Example 12.13 Let X1, X2, . . . be exchangeable real random variables. For n âˆˆN,
let Fâˆ’n = En and
Yn = 1
n
n

i=1
Xi.
We show that (Yâˆ’n)nâˆˆN is an F-backwards martingale. Clearly, Y is adapted.
Furthermore, by Theorem 12.10 (with k = n and Ï•(X1, . . . , Xn) =
1
nâˆ’1(X1 +
. . . + Xnâˆ’1)),
E )Ynâˆ’1
Fâˆ’n
* = 1
n!

Ï±âˆˆS(n)
1
n âˆ’1
XÏ±(1) + . . . + XÏ±(nâˆ’1)
 = Yn.
Now replace F by the smaller ï¬ltration G
=
(Gn)nâˆˆâˆ’N that is deï¬ned by
Gâˆ’n = Ïƒ(Yâˆ’n, Xn+1, Xn+2, . . .) = Ïƒ(Yâˆ’n, Yâˆ’nâˆ’1, Yâˆ’nâˆ’2, . . .) for n âˆˆN. This
is the ï¬ltration generated by Y; thus Y is also a G-backwards martingale (see
Remark 9.29). â™¦
Let a < b and n âˆˆN. Let Ua,b
âˆ’n be the number of upcrossings of X over
[a, b] between times âˆ’n and 0. Further, let Ua,b = lim
nâ†’âˆUa,b
âˆ’n . By the upcrossing
inequality (Lemma 11.3), we have E
)
Ua,b
âˆ’n
*
â‰¤
1
bâˆ’aE
)
(X0 âˆ’a)+*
; hence P
)
Ua,b <
âˆ
*
= 1. As in the proof of the martingale convergence theorem (Theorem 11.4),
we infer the following.

264
12
Backwards Martingales and Exchangeability
Theorem 12.14 (Convergence theorem for
backwards
martingales)
Let
(Xn)nâˆˆâˆ’N0 be a martingale with respect to F = (Fn)nâˆˆâˆ’N0. Then there exists
Xâˆ’âˆ= lim
nâ†’âˆXâˆ’n almost surely and in L1. Furthermore, Xâˆ’âˆ= E[X0
Fâˆ’âˆ],
where Fâˆ’âˆ=
âˆ

n=1
Fâˆ’n.
Example 12.15 Let X1, X2, . . . be exchangeable, integrable random variables.
Further, let T = âˆ
n=1 Ïƒ(Xm, m â‰¥n) be the tail Ïƒ-algebra of X1, X2, . . . and
let E be the exchangeable Ïƒ-algebra. Then E[X1
T ] = E[X1
E] a.s. and
1
n
n

i=1
Xi
nâ†’âˆ
âˆ’â†’E[X1
E]
a.s. and in L1.
Indeed, if we let Yn := 1
n
n
i=1
Xi, then (by Example 12.13) (Yn)nâˆˆN is a backwards
martingale with respect to (Fn)nâˆˆâˆ’N = (Eâˆ’n)nâˆˆâˆ’N and thus
Yn
nâ†’âˆ
âˆ’â†’Yâˆ= E[X1
E]
a.s. and in L1.
Now, by Example 2.36(ii), Yâˆis T -measurable; hence (since T âŠ‚E and by virtue
of the tower property of conditional expectation) Yâˆ= E[X1
T ]. â™¦
Example 12.16 (Strong law of large numbers) If Z1, Z2, . . . are real and i.i.d. with
E[|Z1|] < âˆ, then
1
n
n

i=1
Zi
nâ†’âˆ
âˆ’â†’E[Z1]
almost surely.
By Kolmogorovâ€™s 0-1 law (Theorem 2.37), the tail Ïƒ-algebra T is trivial; hence we
have
E[Z1
T ] = E[Z1]
almost surely.
In Corollary 12.19, we will see that in the case of independent random variables, E
is also P-trivial. This implies E[Z1
E] = E[Z1]. â™¦
We close this section with a generalization of Example 12.15 to mean values of
functions of k âˆˆN variables. This conclusion from the convergence theorem for
backwards martingales will be used in an essential way in the next section.
Theorem 12.17 Let X = (Xn)nâˆˆN be an exchangeable family of random variables
with values in E. Assume that k âˆˆN and let Ï• : Ek â†’R be measurable with
E[|Ï•(X1, . . . , Xk)|] < âˆ. Denote Ï•(X) = Ï•(X1, . . . , Xk) and let An(Ï•) :=
1
n!

Ï±âˆˆS(n) Ï•(XÏ±). Then

12.2
Backwards Martingales
265
E[Ï•(X)
E] = E[Ï•(X)
T ] = lim
nâ†’âˆAn(Ï•)
a.s. and in L1.
(12.7)
Proof By Theorem 12.10, An(Ï•) = E[Ï•(X)
En]. Hence (An(Ï•))nâ‰¥k is a back-
wards martingale with respect to (Eâˆ’n)nâˆˆâˆ’N. Hence, by Theorem 12.14,
An(Ï•)
nâ†’âˆ
âˆ’â†’E
)
Ï•(X)
E
*
a.s. and in L1.
(12.8)
As for the arithmetic mean (Example 12.16), we can argue that limnâ†’âˆAn(Ï•) is
T -measurable. Indeed,
lim sup
nâ†’âˆ
#
	
Ï± âˆˆS(n) : Ï±âˆ’1(i) â‰¤l for some i âˆˆ{1, . . ., k}

n!
= 0
for all l âˆˆN.
Thus, for large n, the dependence of An(Ï•) on the ï¬rst l coordinates is negligible.
Together with (12.8), we get (12.7).
âŠ“âŠ”
Corollary 12.18 Let X = (Xn)nâˆˆN be exchangeable. Then, for any A âˆˆE there
exists a B âˆˆT with P[A â–³B] = 0.
Note that T âŠ‚E; hence the statement is trivially true if the roles of E and T are
interchanged.
Proof Since E âŠ‚Ïƒ(X1, X2, . . .), by the approximation theorem for measures, there
exists a sequence of measurable sets (Ak)kâˆˆN with Ak âˆˆÏƒ(X1, . . . , Xk) and such
that P[A â–³Ak]
kâ†’âˆ
âˆ’â†’0. Choose (kl)lâˆˆN such that âˆ
l=1 P[A â–³Akl] < âˆ, hence
1Akl
lâ†’âˆ
âˆ’â†’1A almost surely. Let Ck âŠ‚Ek be measurable with
Ak = {(X1, . . . , Xk) âˆˆCk}
for all k âˆˆN. Letting Ï•k := 1Ck, Theorem 12.17 implies that
1A = E[1A|E] = E
'
lim
lâ†’âˆÏ•kl(X)
E
(
= lim
lâ†’âˆE[Ï•kl(X)|E]
= lim
lâ†’âˆE[Ï•kl(X)|T ] =: Ïˆ
almost surely.
Hence there is a T -measurable function Ïˆ with Ïˆ = 1A almost surely. We can
assume that Ïˆ = 1B for some B âˆˆT .
âŠ“âŠ”
As a further application, we get the 0-1 law of Hewitt and Savage [72].
Corollary 12.19 (0-1 law of Hewittâ€“Savage) Let X1, X2, . . . be i.i.d. random
variables. Then the exchangeable Ïƒ-algebra is P-trivial; that is, P[A] âˆˆ{0, 1} for
all A âˆˆE.
Proof By Kolmogorovâ€™s 0-1 law (Theorem 2.37), T is trivial. Hence the claim
follows immediately from Corollary 12.18.
âŠ“âŠ”

266
12
Backwards Martingales and Exchangeability
Takeaways A backwards martingale (Yn)nâˆˆN0 is a stochastic process such
that (Yâˆ’m)mâˆˆâˆ’N0 is a martingale. Backwards martingales are uniformly inte-
grable and converge almost surely and in L1. For functions of exchangeable
random variables X1, X2, . . ., averaging over all permutations of X1, . . . , Xn
deï¬nes a backwards martingale. As a consequence, the terminal Ïƒ-algebra and
the exchangeable Ïƒ-algebra coincide (mod P). In particular, for i.i.d. random
variables, the exchangeable Ïƒ-algebra is P-trivial.
12.3
De Finettiâ€™s Theorem
In this section, we show the structural theorem for countably inï¬nite exchangeable
families that was heuristically motivated at the end of Sect. 12.1. Hence we shall
show that a countably inï¬nite exchangeable family of random variables is an
i.i.d. family given the exchangeable Ïƒ-algebra E. Furthermore, we compute the
conditional distribution of the individual random variables. As a ï¬rst step, we deï¬ne
conditional independence formally (see [25, Chapter 7.3]).
Deï¬nition 12.20 (Conditional independence)
Let (Î©, F, P) be a probability
space, let A âŠ‚F be a sub-Ïƒ-algebra and let (Ai)iâˆˆI be an arbitrary family of
sub-Ïƒ-algebras of F. Assume that for any ï¬nite J âŠ‚I, any choice of Aj âˆˆAj and
for all j âˆˆJ,
P
' 
jâˆˆJ
Aj
A
(
=

jâˆˆJ
P
)
Aj
A
*
almost surely.
(12.9)
Then the family (Ai)iâˆˆI is called independent given A.
A family (Xi)iâˆˆI of random variables on (Î©, F, P) is called independent
(and identically distributed) given A if the generated Ïƒ-algebras (Ïƒ(Xi))iâˆˆI are
independent given A (and the conditional distributions P[Xi âˆˆÂ· |A] are equal).
Example 12.21 Any family (Ai)iâˆˆI of sub-Ïƒ-algebras of F is independent given
F. Indeed, letting A = 
jâˆˆJ Aj,
P[A|F] = 1A =

jâˆˆJ
1Aj =

jâˆˆJ
P )Aj
F*
almost surely.
â™¦
Example 12.22 If (Ai)iâˆˆI is an independent family of Ïƒ-algebras and if A is trivial,
then (Ai)iâˆˆI is independent given A. â™¦
Example 12.23 There is no â€œmonotonicityâ€ for conditional independence in the
following sense: If F1, F2 and F3 are Ïƒ-algebras with F1 âŠ‚F2 âŠ‚F3 and such

12.3
De Finettiâ€™s Theorem
267
that (Ai)iâˆˆI is independent given F1 as well as given F3, then this does not imply
independence given F2.
In order to illustrate this, assume that X and Y are nontrivial independent real
random variables. Let F1 = {âˆ…, Î©}, F2 = Ïƒ(X + Y) and F3 = Ïƒ(X, Y). Then
Ïƒ(X) and Ïƒ(Y) are independent given F1 as well as given F3 but not given F2. â™¦
Let X = (Xn)nâˆˆN be a stochastic process on a probability space (Î©, F, P) with
values in a Polish space E. Let E be the exchangeable Ïƒ-algebra and let T be the
tail Ïƒ-algebra.
Theorem 12.24 (de Finetti) The family X = (Xn)nâˆˆN is exchangeable if and only
if there exists a Ïƒ-algebra A âŠ‚F such that (Xn)nâˆˆN is i.i.d. given A. In this case,
A can be chosen to equal the exchangeable Ïƒ-algebra E or the tail-Ïƒ-algebra T .
Proof â€œ â‡’â€
Let X be exchangeable and let A = E or A = T . For any n âˆˆN,
let fn : E â†’R be a bounded measurable map. Let
Ï•k(x1, . . . , xk) =
k
i=1
fi(xi)
for any k âˆˆN.
Let An(Ï•) be the symmetrized average from Theorem 12.17. Then
An(Ï•kâˆ’1)An(fk) = 1
n!

Ï±âˆˆS(n)
Ï•kâˆ’1(XÏ±) 1
n
n

i=1
fk(Xi)
= 1
n!

Ï±âˆˆS(n)
Ï•k(XÏ±) + Rn,k = An(Ï•k) + Rn,k,
where
Rn,k
 â‰¤2
;;Ï•kâˆ’1
;;
âˆÂ·
;;fk
;;
âˆÂ· 1
n!
1
n

Ï±âˆˆS(n)
n

i=1
1{iâˆˆ{Ï±(1),...,Ï±(kâˆ’1)}}
= 2
;;Ï•kâˆ’1
;;
âˆÂ·
;;fk
;;
âˆÂ· k âˆ’1
n
nâ†’âˆ
âˆ’â†’0.
Together with Theorem 12.17, we conclude that
An(Ï•kâˆ’1) An(fk)
nâ†’âˆ
âˆ’â†’E
)
Ï•k(X1, . . . , Xk)
A
*
a.s. and in L1.
On the other hand, again by Theorem 12.17,
An(Ï•kâˆ’1)
nâ†’âˆ
âˆ’â†’E
)
Ï•kâˆ’1 (X1, . . . , Xkâˆ’1)
A
*

268
12
Backwards Martingales and Exchangeability
and
An(fk)
nâ†’âˆ
âˆ’â†’E
)
fk(X1)
A
*
.
Hence
E
)
Ï•k(X1, . . . , Xk)
A
*
= E
)
Ï•kâˆ’1(X1, . . . , Xkâˆ’1)
A
*
E
)
fk(X1)
A
*
.
Thus we get inductively
E
- k
i=1
fi(Xi)
A
.
=
k
i=1
E
)
fi(X1)
A
*
.
Therefore, X is i.i.d. given A.
â€œ â‡ â€
Now let X be i.i.d. given A for a suitable Ïƒ-algebra A âŠ‚F. For any
bounded measurable function Ï• : En â†’R and for any Ï± âˆˆS(n), we have
E[Ï•(X)
A] = E[Ï•(XÏ±)
A]. Hence
E[Ï•(X)] = E
)
E[Ï•(X)
A]
*
= E
)
E[Ï•(XÏ±)
A]
*
= E[Ï•(XÏ±)],
whence X is exchangeable.
âŠ“âŠ”
Denote by M1(E) the set of probability measures on E equipped with the
topology of weak convergence (see Deï¬nition 13.12 and Remark 13.14). That is,
a sequence (Î¼n)nâˆˆN in M1(E) converges weakly to a Î¼ âˆˆM1(E) if and only
if 3 f dÎ¼n
nâ†’âˆ
âˆ’â†’
3 f dÎ¼ for any bounded continuous function f : E â†’R.
We will study weak convergence in Chap. 13 in greater detail. At this point, we
use the topology only to make M1(E) a measurable space, namely with the
Borel Ïƒ-algebra B(M1(E)). Now we can study random variables with values in
M1(E), so-called random measures (compare also Sect. 24.1). For x âˆˆEN, let
Î¾n(x) = 1
n
n
i=1 Î´xi âˆˆM1(E).
Deï¬nition 12.25 The random measure
În := Î¾n(X) := 1
n
n

i=1
Î´Xi
is called the empirical distribution of X1, . . . , Xn.
Assume the conditions of Theorem 12.24 are in force.
Theorem 12.26 (de Finetti representation theorem) The family X = (Xn)nâˆˆN
is exchangeable if and only if there is a Ïƒ-algebra A âŠ‚F and an A-measurable
random variable Îâˆ: Î© â†’M1(E) with the property that given Îâˆ, (Xn)nâˆˆN is
i.i.d. with L[X1|Îâˆ] = Îâˆ. In this case, we can choose A = E or A = T .

12.3
De Finettiâ€™s Theorem
269
Proof â€œ â‡ â€
This follows as in the proof of Theorem 12.24.
â€œ â‡’â€
Let X be exchangeable. Then, by Theorem 12.24, there exists a Ïƒ-algebra
A âŠ‚F such that (Xn)nâˆˆN is i.i.d. given A. As E is Polish, there exists a regular
conditional distribution (see Theorem 8.37) Îâˆ:= L[X1
A]. For measurable
A1, . . . , An âŠ‚E, we have P[Xi âˆˆAi |A] = Îâˆ(Ai) for all i = 1, . . . , n; hence
P
+ n

i=1
{Xi âˆˆAi}
Îâˆ
,
= E
+
P
+
n

i=1
{Xi âˆˆAi}
A
,Îâˆ
,
= E
+
n

i=1
Îâˆ(Ai)
Îâˆ
,
=
n

i=1
Îâˆ(Ai).
Therefore, L[X|Îâˆ] = ÎâŠ—N
âˆ.
âŠ“âŠ”
Remark 12.27
(i) In the case considered in the previous theorem, by the strong law of large
numbers, for any bounded continuous function f : E â†’R,

f dÎn
nâ†’âˆ
âˆ’â†’

f dÎâˆ
almost surely.
If in addition E is locally compact (e.g., E = Rd), then one can even show that
În
nâ†’âˆ
âˆ’â†’Îâˆ
almost surely.
(ii) For ï¬nite families of random variables there is no perfect analog of de Finettiâ€™s
theorem. See [33] for a detailed treatment of ï¬nite exchangeable families. â™¦
Example 12.28 Let (Xn)nâˆˆN be exchangeable and assume Xn âˆˆ{0, 1}. Then there
exists a random variable Y : Î© â†’[0, 1] such that, for all ï¬nite J âŠ‚N,
P
)
Xj = 1 for all j âˆˆJ
Y
*
= Y #J.
In other words, (Xn)nâˆˆN is independent given Y and BerY -distributed. Compare
Example 12.3(iii). â™¦
Example 12.29 (PÃ³lyaâ€™s urn model) (See Example 14.41, compare also [17, 135]
and [58].) Consider an urn with a total of N balls among which M are black and
M âˆ’N are white. At each step, a ball is drawn and is returned to the urn together
with an additional ball of the same color. Let
Xn :=

1,
if the nth ball is black,
0,
else,

270
12
Backwards Martingales and Exchangeability
and let Sn = n
i=1 Xi. Then
P
)
Xn = 1
X1, X2, . . . , Xnâˆ’1
*
= Snâˆ’1 + M
N + n âˆ’1.
Inductively, for x1, . . . , xn âˆˆ{0, 1} and sk = k
i=1 xi, we get
P)Xi = xi for any i = 1, . . . , n*
=

iâ‰¤n: xi=1
M + siâˆ’1
N + i âˆ’1

iâ‰¤n: xi=0
N + i âˆ’1 âˆ’M âˆ’siâˆ’1
N + i âˆ’1
=
(N âˆ’1)!
(N âˆ’1 + n)! Â· (M + sn âˆ’1)!
(M âˆ’1)!

N âˆ’M âˆ’1 + (n âˆ’sn)

!
(N âˆ’M âˆ’1)!
.
The right-hand side depends on sn only and not on the order of the x1, . . . , xn.
Hence (Xn)nâˆˆN is exchangeable. Let Z = lim
nâ†’âˆ
1
nSn. Then (Xn)nâˆˆN is i.i.d. BerZ-
distributed given Z. Hence (see Example 12.28)
E
)
Zn*
= E
)
P
)
X1 = Â· Â· Â· = Xn = 1
Z
**
= P [Sn = n]
= (N âˆ’1)!
(M âˆ’1)!
(M + n âˆ’1)!
(N + n âˆ’1)!
for all n âˆˆN.
By Exercise 5.1.3, these are the moments of the Beta distribution Î²M,Nâˆ’M on [0, 1]
with parameters (M, N âˆ’M) (see Example 1.107(ii)). A distribution on [0, 1] is
uniquely characterized by its moments (see Theorem 15.4). Hence Z âˆ¼Î²M,Nâˆ’M.
â™¦
Takeaways Consider a two-step random experiment where in the ï¬rst step
we choose a probability measure Îâˆon some space E. In the second step,
we draw i.i.d. random variables X1, X2, . . . with distribution Îâˆ. Then the
sequence X1, X2, . . . is exchangeable. Now, de Finettiâ€™s theorem states that
any inï¬nite and exchangeable family can be constructed in this way and
that Îâˆis measurable with respect to the exchangeable Ïƒ-algebra. For ï¬nite
families, this is not true.

12.3
De Finettiâ€™s Theorem
271
Exercise 12.3.1 Let (Xn)nâˆˆZ be an exchangeable family of {0, 1}-valued random
variables.
(i) Show that the distribution of (Xn)nâˆˆZ is uniquely determined by the values
mn := E[X1 Â· X2 Â· Â· Â· Xn],
n âˆˆN.
(ii) Conclude that for any random variable Y on [0, 1], the distribution is uniquely
determined by its moments mn := E[Y n], n âˆˆN. â™£

Chapter 13
Convergence of Measures
One focus of probability theory is distributions that are the result of an interplay of
a large number of random impacts. Often a useful approximation can be obtained
by taking a limit of such distributions, for example, a limit where the number of
impacts goes to inï¬nity. With the Poisson distribution, we have encountered such
a limit distribution that occurs as the number of very rare events when the number
of possibilities goes to inï¬nity (see Theorem 3.7). In many cases, it is necessary
to rescale the original distributions in order to capture the behavior of the essential
ï¬‚uctuations, e.g., in the central limit theorem. While these theorems work with real
random variables, we will also see limit theorems where the random variables take
values in more general spaces such as the space of continuous functions when we
model the path of the random motion of a particle.
In this chapter, we provide the abstract framework for the investigation of con-
vergence of measures. We introduce the notion of weak convergence of probability
measures on general (mostly Polish) spaces and derive the fundamental properties.
The reader will proï¬t from a solid knowledge of point set topology. Thus we start
with a short overview of some topological deï¬nitions and theorems.
We do not strive for the greatest generality but rather content ourselves with the
key theorems for probability theory. For further reading, we recommend [14] and
[82].
At ï¬rst reading, the reader might wish to skip this rather analytically ï¬‚avored
chapter. In this case, for the time being it sufï¬ces to get acquainted with the
deï¬nitions of weak convergence and tightness (Deï¬nitions 13.12 and 13.26), as
well as with the statements of the Portemanteau theorem (Theorem 13.16) and
Prohorovâ€™s theorem (Theorem 13.29).
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_13
273

274
13
Convergence of Measures
13.1
A Topology Primer
Excursively, we present some deï¬nitions and facts from point set topology. For
details, see, e.g., [90].
In the following, let (E, Ï„) be a topological space with the Borel Ïƒ-algebra E =
B(E) (compare Deï¬nitions 1.20 and 1.21). We will also assume that (E, Ï„) is a
Hausdorff space; that is, for any two points x, y âˆˆE with x Ì¸= y, there exist
disjoint open sets U, V such that x âˆˆU and y âˆˆV .
For A âŠ‚E, we denote by A the closure of A, by Aâ—¦the interior and by âˆ‚A the
boundary of A. A set A âŠ‚E is called dense if A = E.
(E, Ï„) is called metrizable if there exists a metric d on E such that Ï„ is induced
by the open balls BÎµ(x) := {y âˆˆE : d(x, y) < Îµ}. A metric d on E is called
complete if any Cauchy sequence with respect to d converges in E. (E, Ï„) is called
completely metrizable if there exists a complete metric on E that induces Ï„. If
(E, d) is a metric space and A, B âŠ‚E, then we write d(A, B) = inf{d(x, y) : x âˆˆ
A, y âˆˆB} and d(x, B) := d({x}, B) for x âˆˆE.
A metrizable space (E, Ï„) is called separable if there exists a countable dense
subset of E. Separability in metrizable spaces is equivalent to the existence of
a countable base of the topology; that is, a countable set U âŠ‚Ï„ with A =

UâˆˆU: UâŠ‚A U for all A âˆˆÏ„. (For example, choose the Îµ-balls centered at the
points of a countable subset and let Îµ run through the positive rational numbers.)
A compact metric space is always separable (simply choose for each n âˆˆN a ï¬nite
cover Un âŠ‚Ï„ comprising balls of radius 1
n and then take U := 
nâˆˆN Un).
A set A âŠ‚E is called compact if each open cover U âŠ‚Ï„ of A (that is,
A âŠ‚
UâˆˆU U) has a ï¬nite subcover; that is, a ï¬nite Uâ€² âŠ‚U with A âŠ‚
UâˆˆUâ€² U.
Compact sets are closed. By the Heineâ€“Borel theorem, a subset of Rd is compact
if and only if it is bounded and closed. A âŠ‚E is called relatively compact if
A is compact. On the other hand, A is called sequentially compact (respectively
relatively sequentially compact) if any sequence (xn)nâˆˆN with values in A has
a subsequence (xnk)kâˆˆN that converges to some x âˆˆA (respectively x âˆˆA). In
metrizable spaces, the notions compact and sequentially compact coincide. A set
A âŠ‚E is called Ïƒ-compact if A is a countable union of compact sets. E is called
locally compact if any point x âˆˆE has an open neighborhood whose closure
is compact. A locally compact, separable metric space is manifestly Ïƒ-compact
and there even exists a countable basis Uâ€² of the topology consisting of relatively
compact open sets. (In fact: Choose an arbitrary countable base U of the topology.
For any x âˆˆE, there exists a relatively compact neighborhood Bx âˆ‹x. Each Bx is a
union of elements of U each of which is then also relatively compact. Hence, there
exists a relatively compact Ux âˆˆU with x âˆˆUx. Now let Uâ€² := {Ux : x âˆˆE} âŠ‚U.)
If E is a locally compact metric space and if U âŠ‚E is open and K âŠ‚U is
compact, then there exists a compact set L with K âŠ‚Lâ—¦âŠ‚L âŠ‚U. (For example,
for any x âˆˆK, take an open ball BÎµx(x) of radius Îµx > 0 that is contained in U
and that is relatively compact. By making Îµx smaller (if necessary), one can assume
that the closure of this ball is contained in U. As K is compact, there are ï¬nitely

13.1
A Topology Primer
275
many points x1, . . . , xn âˆˆK with K âŠ‚V := n
i=1 BÎµxi (xi). By construction,
L = V âŠ‚U is compact.) Specializing on the case U = E, we get that for any
compact set K, there exists a relatively compact open set Lâ—¦âŠƒK.
We present one type of topological space that is of particular importance in
probability theory in a separate deï¬nition.
Deï¬nition 13.1 A topological space (E, Ï„) is called a Polish space if it is separable
and if there exists a complete metric that induces the topology Ï„.
Examples of Polish spaces are countable discrete spaces (however, not Q with
the usual topology), the Euclidean spaces Rn, and the space C([0, 1]) of continuous
functions [0, 1] â†’R, equipped with the supremum norm âˆ¥Â· âˆ¥âˆ. In practice, all
spaces that are of importance in probability theory are Polish spaces.
Let (E, d) be a metric space. A set A âŠ‚E is called totally bounded if, for any
Îµ > 0, there exist ï¬nitely many points x1, . . . , xn âˆˆA such that A âŠ‚
n

i=1
BÎµ(xi).
Evidently, compact sets are totally bounded. In Polish spaces, a partial converse is
true.
Lemma 13.2 Let (E, Ï„) be a Polish space with complete metric d. A subset A âŠ‚E
is totally bounded with respect to d if and only if A is relatively compact.
Proof This is left as an exercise.
âŠ“âŠ”
In the following, let (E, Ï„) be a topological space with Borel Ïƒ-algebra E =
B(E) := Ïƒ(Ï„) and with complete metric d. For measures on (E, E), we introduce
the following notions of regularity.
Deï¬nition 13.3 A Ïƒ-ï¬nite measure Î¼ on (E, E) is called
(i) locally ï¬nite or a Borel measure if, for any point x âˆˆE, there exists an open
neighborhood U âˆ‹x such that Î¼(U) < âˆ,
(ii) inner regular if
Î¼(A) = sup
	
Î¼(K) : K âŠ‚A is compact

for all A âˆˆE,
(13.1)
(iii) outer regular if
Î¼(A) = inf
	
Î¼(U) : U âŠƒA is open

for all A âˆˆE,
(13.2)
(iv) regular if Î¼ is inner and outer regular, and
(v) a Radon measure if Î¼ is an inner regular Borel measure.

276
13
Convergence of Measures
Deï¬nition 13.4 We introduce the following spaces of measures on E:
M(E) := 	Radon measures on (E, E)
,
Mf (E) :=
	
ï¬nite measures on (E, E)

,
M1(E) :=
	
Î¼ âˆˆMf (E) : Î¼(E) = 1

,
Mâ‰¤1(E) := 	Î¼ âˆˆMf (E) : Î¼(E) â‰¤1
.
The elements of Mâ‰¤1(E) are called sub-probability measures on E.
Further, we agree on the following notation for spaces of continuous functions:
C(E) :=
	
f : E â†’R is continuous

,
Cb(E) := 	f âˆˆC(E) is bounded
,
Cc(E) :=
	
f âˆˆC(E) has compact support

âŠ‚Cb(E).
Recall that the support of a real function f is f âˆ’1(R \ {0}).
Unless otherwise stated, the vector spaces C(E), Cb(E) and Cc(E) are equipped
with the supremum norm.
Lemma 13.5 If E is Polish and Î¼ âˆˆMf (E), then for any Îµ > 0, there is a compact
set K âŠ‚E with Î¼(E \ K) < Îµ.
Proof Let Îµ > 0. For each n âˆˆN, there exists a sequence xn
1, xn
2, . . . âˆˆE with
E =
âˆ

i=1
B1/n(xn
i ). Fix Nn âˆˆN such that Î¼

E \
Nn

i=1
B1/n

xn
i
 
< Îµ
2n . Deï¬ne
A :=
âˆ

n=1
Nn

i=1
B1/n

xn
i

.
By construction, A is totally bounded. Since E is Polish, A is compact. Furthermore,
it follows that Î¼E \ A â‰¤Î¼E \ A <
âˆ

n=1
Îµ 2âˆ’n = Îµ.
âŠ“âŠ”
Theorem 13.6 If E is Polish and if Î¼ âˆˆMf (E), then Î¼ is regular. In particular,
in this case, Mf (E) âŠ‚M(E).
Proof (Outer regularity)
Step 1. Let B âŠ‚E be closed and let Îµ > 0. Let d be a complete metric on E. For
Î´ > 0, let
BÎ´ := 	x âˆˆE : d(x, B) < Î´

13.1
A Topology Primer
277
be the open Î´-neighborhood of B. As B is closed, we have 
Î´>0 BÎ´ = B. Since Î¼ is
upper semicontinuous (Theorem 1.36), there is a Î´ > 0 such that Î¼(BÎ´) â‰¤Î¼(B)+Îµ.
Step 2. Let B âˆˆE and Îµ > 0. Consider the class of sets
A :=
	
V âˆ©C : V âŠ‚E open, C âŠ‚E closed

.
Clearly, we have E = Ïƒ(A). It is easy to check that A is a semiring. Hence by the
approximation theorem for measures (Theorem 1.65), there are mutually disjoint
sets An = Vn âˆ©Cn âˆˆA, n âˆˆN, such that B âŠ‚A := âˆ
n=1 An and Î¼(A) â‰¤
Î¼(B)+Îµ/2. As shown in the ï¬rst step, for any n âˆˆN, there is an open set Wn âŠƒCn
such that Î¼(Wn) â‰¤Î¼(Cn) + Îµ 2âˆ’nâˆ’1. Hence also Un := Vn âˆ©Wn is open. Let
B âŠ‚U := âˆ
n=1 Un. We conclude that Î¼(U) â‰¤Î¼(A)+âˆ
n=1 Îµ 2âˆ’nâˆ’1 â‰¤Î¼(B)+Îµ.
Inner regularity Replacing B by Bc, the outer regularity yields the existence of a
closed set D âŠ‚B with Î¼(B \ D) < Îµ/2. By Lemma 13.5, there exists a compact
set K with Î¼(Kc) < Îµ/2. Deï¬ne C = D âˆ©K. Then C âŠ‚B is compact and
Î¼(B \ C) < Îµ. Hence Î¼ is also inner regular.
âŠ“âŠ”
Corollary 13.7 The Lebesgue measure Î» on Rd is a regular Radon measure.
However, not all Ïƒ-ï¬nite measures on Rd are regular.
Proof Clearly, Rd is Polish and Î» is locally ï¬nite. Let A âˆˆB(Rd) and Îµ > 0. There
is an increasing sequence (Kn)nâˆˆN of compact sets with Kn â†‘Rd. Since any Kn is
bounded, we have Î»(Kn) < âˆ. Hence, by the preceding theorem, for any n âˆˆN,
there exists an open set Un âŠƒA âˆ©Kn with Î»(Un \ A) < Îµ/2n. Thus Î»(U \ A) < Îµ
for the open set U := 
nâˆˆN Un.
If Î»(A) < âˆ, then there exists an n âˆˆN with Î»(A\Kn) < Îµ/2. By the preceding
theorem, there exists a compact set C âŠ‚A âˆ©Kn with Î»((A âˆ©Kn) \ C) < Îµ/2.
Therefore, Î»(A \ C) < Îµ.
If, on the other hand, Î»(A) = âˆ, then for any L > 0, we have to ï¬nd a compact
set C âŠ‚A with Î»(C) > L. However, Î»(A âˆ©Kn)
nâ†’âˆ
âˆ’â†’âˆ; hence there exists an
n âˆˆN with Î»(A âˆ©Kn) > L + 1. By what we have shown already, there exists a
compact set C âŠ‚A âˆ©Kn with Î»((A âˆ©Kn) \ C) < 1; hence Î»(C) > L.
Finally, consider the measure Î¼ = 
qâˆˆQ Î´q. Clearly, this measure is Ïƒ-ï¬nite;
however, it is neither locally ï¬nite nor outer regular.
âŠ“âŠ”
Deï¬nition 13.8 Let (E, dE) and (F, dF ) be metric spaces. A function f : E â†’F
is called Lipschitz continuous if there exists a constant K < âˆ, the so-called
Lipschitz constant, with dF (f (x), f (y)) â‰¤K Â· dE(x, y) for all x, y âˆˆE. Denote
by LipK(E; F) the space of Lipschitz continuous functions with constant K and
by Lip(E; F) = 
K>0 LipK(E; F) the space of Lipschitz continuous functions
on E.
We abbreviate LipK(E) := LipK(E; R) and Lip(E) := Lip(E; R).
Deï¬nition 13.9 Let F âŠ‚M(E) be a family of Radon measures. A family C of
measurable maps E â†’R is called a separating family for F if, for any two

278
13
Convergence of Measures
measures Î¼, Î½ âˆˆF, the following holds:

f dÎ¼ =

f dÎ½
for all f âˆˆC âˆ©L1(Î¼) âˆ©L1(Î½)

â‡’
Î¼ = Î½.
Lemma 13.10 Let (E, d) be a metric space. For any closed set A âŠ‚E and any
Îµ > 0, there is a Lipschitz continuous map ÏA,Îµ : E â†’[0, 1] with Lipschitz constant
1/Îµ and
ÏA,Îµ(x) =

1,
if x âˆˆA,
0,
if d(x, A) â‰¥Îµ.
Proof Let Ï• : R â†’[0, 1], t â†’(t âˆ¨0) âˆ§1. For x âˆˆE, deï¬ne ÏA,Îµ(x) =
1 âˆ’Ï•

Îµâˆ’1d(x, A)

.
âŠ“âŠ”
Theorem 13.11 Let (E, d) be a metric space.
(i). Lip1(E; [0, 1]) is separating for Mf (E) and for M(E).
(ii). If, in addition, E is locally compact, then Cc(E)âˆ©Lip1(E; [0, 1]) is separating
for M(E).
Proof (i)
Case Mf (E). Let Î¼1, Î¼2 âˆˆMf (E) be such that
3
f dÎ¼1 =
3
f dÎ¼2
for all f âˆˆLip1(E; [0, 1]). It is enough to show that Î¼1(C) = Î¼2(C) for all closed
sets C âŠ‚E as the closed sets form a âˆ©-stable generator of the Borel Ïƒ-algebra
that contains E. Since Î¼1 and Î¼2 are ï¬nite measures, for the function ÏC,Îµ from
Lemma 13.10, we have
0 â‰¤ÏC,Îµ â‰¤1 âˆˆL1(Î¼i),
i = 1, 2,
for all Îµ > 0.
Note that ÏC,Îµ
Îµâ†’0
âˆ’â†’1C. Hence by the dominated convergence theorem (Corol-
lary 6.26), we have Î¼i(C) = limÎµâ†’0
3
ÏC,Îµ dÎ¼i. For any Îµ âˆˆ(0, 1], we have
ÎµÏC,Îµ âˆˆLip1(E; [0, 1]). We conclude that

ÏC,Îµ dÎ¼1 = Îµâˆ’1

(ÎµÏC,Îµ) dÎ¼1 = Îµâˆ’1

(ÎµÏC,Îµ) dÎ¼2 =

ÏC,Îµ dÎ¼2.
This implies Î¼1(C) = Î¼2(C); hence Î¼1 = Î¼2.
(i) Case M(E).
In contrast to the case Mf (E), the function 1 is not integrable.
Hence, we modify the approach by showing that it is enough to consider compact
sets K instead of C and by showing that there exists an open set U âŠƒK and a Î´ > 0
such that
ÏK,Îµ â‰¤1U âˆˆL1(Î¼i),
i = 1, 2
for all Îµ âˆˆ(0, Î´).
(13.3)
Arguing as above, this will show that Î¼1(K) = Î¼2(K) and will hence conclude the
proof.

13.1
A Topology Primer
279
Here come the details. Assume Î¼1, Î¼2 âˆˆM(E) are measures with
3
f dÎ¼1 =
3
f dÎ¼2 for all f âˆˆLip1(E; [0, 1]). If A âˆˆE, then
Î¼i(A) = sup 	Î¼i(K) : K âŠ‚A is compact
since the Radon measure Î¼i is inner regular (i = 1, 2). Hence, it is enough to show
that Î¼1(K) = Î¼2(K) for any compact set K.
Now let K âŠ‚E be compact. Since Î¼1 and Î¼2 are locally ï¬nite, for every x âˆˆK,
there exists an open set Ux âˆ‹x with Î¼1(Ux) < âˆand Î¼2(Ux) < âˆ. Since K is
compact, we can ï¬nd ï¬nitely many points x1, . . . , xn âˆˆK such that K âŠ‚U :=
n
j=1 Uxj . By construction, Î¼i(U) < âˆ; hence 1U âˆˆL1(Î¼i) for i = 1, 2. Since
Uc is closed and since Uc âˆ©K = âˆ…, we get Î´ := d(Uc, K) > 0. Let ÏK,Îµ be the
map from Lemma 13.10. By construction, equation (13.3) holds and the proof is
complete. (ii)
If E is locally compact, then in ((i)) we can choose the neighborhoods Ux to be
relatively compact. Hence U is relatively compact; thus ÏK,Îµ has compact support
and is thus in Cc(E) for all Îµ âˆˆ(0, Î´).
âŠ“âŠ”
Takeaways A Polish space is a separable topological space that allows for
a complete metric, e.g., the euclidian space Rd. Polish spaces are standard
spaces of measure theory and probability theory. Radon measures are inner
regular Borel measures (locally ï¬nite measures). Finite measures on Polish
spaces are Radon measures. The class of Lipschitz-continuous functions is
a separating family for ï¬nite measures and for Radon measures. On locally
compact spaces, also Lipschitz continuous functions with compact support
form a separating class.
Exercise 13.1.1
(i) Show that C([0, 1]) has a separable dense subset.
(ii) Show that the space (Cb([0, âˆ)), âˆ¥Â· âˆ¥âˆ) of bounded continuous functions,
equipped with the supremum norm, is not separable.
(iii) Show that the space Cc([0, âˆ)) of continuous functions with compact support,
equipped with the supremum norm, is separable. â™£
Exercise 13.1.2 Let Î¼ be a locally ï¬nite measure. Show that Î¼(K) < âˆfor any
compact set K. â™£
Exercise 13.1.3 (Lusinâ€™s theorem)
Let Î© be a Polish space, let Î¼ be a ï¬nite
measure on (Î©, B(Î©)) and let f : Î© â†’R be a map. Show that the following
two statements are equivalent:
(i) There is a Borel measurable map g : Î© â†’R with f
= g
Î¼-almost
everywhere.

280
13
Convergence of Measures
(ii) For any Îµ > 0, there is a compact set KÎµ with Î¼(Î© \ KÎµ) < Îµ such that the
restricted function f 
KÎµ is continuous. â™£
Exercise 13.1.4 Let U be a family of intervals in R such that W := 
UâˆˆU U has
ï¬nite Lebesgue measure Î»(W). Show that for any Îµ > 0, there exist ï¬nitely many
pairwise disjoint sets U1, . . . , Un âˆˆU with
n

i=1
Î»(Ui) > 1 âˆ’Îµ
3
Î»(W).
Hint: Choose a ï¬nite family Uâ€² âŠ‚U such that 
UâˆˆUâ€² U has Lebesgue measure at
least (1 âˆ’Îµ)Î»(W). Choose a maximal sequence Uâ€²â€² (sorted by decreasing lengths)
of disjoint intervals and show that each U âˆˆUâ€² is in (x âˆ’3a, x + 3a) for some
(x âˆ’a, x + a) âˆˆUâ€²â€². â™£
Exercise 13.1.5 Let C âŠ‚Rd be an open, bounded and convex set and assume that
U âŠ‚{x + rC : x âˆˆRd, r > 0} is such that W := 
UâˆˆU U has ï¬nite Lebesgue
measure Î»d(W). Show that for any Îµ > 0, there exist ï¬nitely many pairwise disjoint
sets U1, . . . , Un âˆˆU such that
n

i=1
Î»d(Ui) > 1 âˆ’Îµ
3d
Î»(W).
Show by a counterexample that the condition of similarity of the open sets in U is
essential. â™£
Exercise 13.1.6 Let Î¼ be a Radon measure on Rd and let A âˆˆB(Rd) be a Î¼-null
set. Let C âŠ‚Rd be bounded, convex and open with 0 âˆˆC. Use Exercise 13.1.5 to
show that
lim
râ†“0
Î¼(x + rC)
rd
= 0
for Î»d -almost all x âˆˆA.
Conclude that if F is the distribution function of a Stieltjes measure Î¼ on R and if
A âˆˆB(R) is a Î¼-null set, then d
dx F(x) = 0 for Î» -almost all x âˆˆA. â™£
Exercise 13.1.7 (Fundamental theorem of calculus) (Compare [37].) Let f âˆˆ
L1(Rd), Î¼ = f Î»d and let C âŠ‚Rd be open, convex and bounded with 0 âˆˆC. Show
that
lim
râ†“0
Î¼(x + rC)
rd Î»d(C)
= f (x)
for Î»d -almost all x âˆˆRd.
For the case d = 1, conclude the fundamental theorem of calculus:
d
dx

[0,x]
f dÎ» = f (x)
for Î» -almost all x âˆˆR.

13.2
Weak and Vague Convergence
281
Hint: Use Exercise 13.1.6 with Î¼q(dx) = (f (x) âˆ’q)+Î»d(dx) for q âˆˆQ, as well
as the inequality
Î¼(x + rC)
rd Î»d(C)
â‰¤q + Î¼q(x + rC)
rd Î»d(C) .
â™£
Exercise 13.1.8 Similarly as in Corollary 13.7, show the following: Let E be a Ïƒ-
compact polish space and let Î¼ be a measure on E. Then Î¼ is a Radon measure if
and only if Î¼(K) < âˆfor any compact K âŠ‚E. â™£
Exercise 13.1.9 Show that the set of rationals Q (with the standard topology) is not
a Polish space. To this end, ï¬ll in the details in the following sketch.
We assume that d is a metric on Q that induces the standard topology and such
that (Q, d) is complete. We aim at a contradiction.
Let q1, q2, . . . be an arbitrary enumeration of Q. Choose r1 âˆˆQ and Îµ1 > 0 such
that q1 Ì¸âˆˆBÎµ1(r1). Now choose successively ri+1 âˆˆBÎµi/2(ri) and Îµi+1 âˆˆ(0, Îµi/2)
such that qi+1 Ì¸âˆˆBÎµi+1(ri+1). As d is complete, there is an x âˆˆQ with {x} =
âˆ
i=1 BÎµi(ri). On the other hand, by construction, we have qk Ì¸âˆˆâˆ
i=1 BÎµi(ri) for
all k âˆˆN. â™£
13.2
Weak and Vague Convergence
In Theorem 13.11, we saw that integrals of bounded continuous functions f
determine a Radon measure on a metric space (E, d). If E is locally compact,
it is enough to consider f with compact support. This suggests that we can use
Cb(E) and Cc(E) as classes of test functions in order to deï¬ne the convergence of
measures.
Deï¬nition 13.12 (Weak and vague convergence)
Let E be a metric space.
(i) Let Î¼, Î¼1, Î¼2, . . . âˆˆMf (E). We say that (Î¼n)nâˆˆN converges weakly to Î¼,
formally Î¼n
nâ†’âˆ
âˆ’â†’Î¼ (weakly) or Î¼ = w-lim
nâ†’âˆÎ¼n, if

f dÎ¼n
nâ†’âˆ
âˆ’â†’

f dÎ¼
for all f âˆˆCb(E).
(ii) Let Î¼, Î¼1, Î¼2, . . . âˆˆM(E). We say that (Î¼n)nâˆˆN converges vaguely to Î¼,
formally Î¼n
nâ†’âˆ
âˆ’â†’Î¼ (vaguely) or Î¼ = v-lim
nâ†’âˆÎ¼n, if

f dÎ¼n
nâ†’âˆ
âˆ’â†’

f dÎ¼
for any f âˆˆCc(E).

282
13
Convergence of Measures
Remark 13.13 By Theorem 13.11, the weak limit is unique. By Theorems 13.6
and 13.11, the same holds for the vague limit if E is Polish and locally compact.
â™¦
Remark 13.14
(i) In functional analysis the notion of weak convergence is somewhat different.
Starting from a normed vector space X (here the space of ï¬nite signed mea-
sures with the total variation norm), consider the space Xâ€² of continuous linear
functionals X â†’R. The sequence (Î¼n) in X converges weakly to Î¼ âˆˆX, if
Î¦(Î¼n)
nâ†’âˆ
âˆ’â†’Î¦(Î¼) for every Î¦ âˆˆXâ€². In the case of ï¬nite signed measures this
is equivalent to: (Î¼n) is bounded and Î¼n(A)
nâ†’âˆ
âˆ’â†’Î¼(A) for any measurable
A (see [38, Theorem IV.9.5]). Comparing this to Theorem 13.16(vi), we see
that the functional analysis notion of weak convergence is stronger than ours
in Deï¬nition 13.12.
(ii) Weak convergence (as introduced in Deï¬nition 13.12) induces on Mf (E) the
weak topology Ï„w. This is the coarsest topology such that for all f âˆˆCb(E),
the map Mf (E) â†’R, Î¼ â†’3 f dÎ¼ is continuous. In functional analysis,
Ï„w corresponds to the so-called weakâˆ—-topology. Starting from a normed
vector space X (here X = Cb(E) with the norm âˆ¥Â· âˆ¥âˆ), we deï¬ne the
weakâˆ—-topology on the dual space Xâ€² by writing Î¼n
nâ†’âˆ
âˆ’â†’Î¼ if and only if
Î¼n(x)
nâ†’âˆ
âˆ’â†’Î¼(x) for all x âˆˆX. Clearly, each Î¼ deï¬nes a continuous linear
form on Cb(E) by f â†’Î¼(f ) :=
3
f dÎ¼. Hence Mf (E) âŠ‚Cb(E)â€². This
implies that Ï„w is the trace of the weakâˆ—-topology on Mf (E).
(iii) If E is separable, then it can be shown that (Mf (E), Ï„w) is metrizable; for
example, by virtue of the so-called Prohorov metric. This is deï¬ned by
dP (Î¼, Î½) := max{dâ€²
P (Î¼, Î½), dâ€²
P (Î½, Î¼)},
(13.4)
where
dâ€²
P (Î¼, Î½) := inf{Îµ > 0 : Î¼(B) â‰¤Î½(BÎµ) + Îµ for any B âˆˆB(E)},
(13.5)
and where BÎµ = {x : d(x, B) < Îµ}; see, e.g., [14, Appendix III, Theorem 5].
(It can be shown that dâ€²
P (Î¼, Î½) = dâ€²
P(Î½, Î¼) if Î¼, Î½ âˆˆM1(E).) If E is locally
compact and Polish, then (Mf (E), Ï„w) is again Polish (see [136, page 167]).
(iv) Similarly, the vague topology Ï„v on M(E) is the coarsest topology such that
for all f âˆˆCc(E), the map M(E) â†’R, Î¼ â†’
3
f dÎ¼ is continuous. If E
is locally compact, then (M(E), Ï„v) is a Hausdorff space. If, in addition, E is
Polish, then (M(E), Ï„v) is again Polish (see, e.g., [82, Section 15.7]). â™¦
While weak convergence implies convergence of the total masses (since 1 âˆˆ
Cb(E)), with vague convergence a mass defect (but not a mass gain) can be
experienced in the limit.

13.2
Weak and Vague Convergence
283
Lemma 13.15 Let E be a locally compact Polish space and let Î¼, Î¼1, Î¼2, . . . âˆˆ
M(E) be measures such that Î¼n
nâ†’âˆ
âˆ’â†’Î¼ vaguely. Then
Î¼(E) â‰¤lim inf
nâ†’âˆÎ¼n(E).
Proof Let (fN)NâˆˆN be a sequence in Cc(E; [0, 1]) with fN â†‘1. Then
Î¼(E) = sup
NâˆˆN

fN dÎ¼
= sup
NâˆˆN
lim
nâ†’âˆ

fN dÎ¼n
â‰¤lim inf
nâ†’âˆ
sup
NâˆˆN

fN dÎ¼n
= lim inf
nâ†’âˆÎ¼n(E).
âŠ“âŠ”
Clearly, the sequence (Î´1/n)nâˆˆN of probability measures on R converges weakly
to Î´0; however, not in total variation norm. Indeed, for the closed set (âˆ’âˆ, 0], we
have limnâ†’âˆÎ´1/n((âˆ’âˆ, 0]) = 0 < 1 = Î´0((âˆ’âˆ, 0]). Loosely speaking, at the
boundaries of closed sets, mass can immigrate but not emigrate. The opposite is
true for open sets: limnâ†’âˆÎ´1/n((0, âˆ)) = 1 > 0 = Î´0((0, âˆ)). Here mass can
emigrate but not immigrate. In fact, weak convergence can be characterized by this
property. In the following theorem, a whole bunch of such statements will be hung
on a coat hanger (French: portemanteau).
For measurable g : Î© â†’R, let Ug be the set of points of discontinuity of g.
Recall from Exercise 1.1.3 that Ug is Borel measurable.
Theorem 13.16 (Portemanteau) Let E be a metric space and let Î¼, Î¼1, Î¼2, . . . âˆˆ
Mâ‰¤1(E). The following are equivalent.
(i) Î¼ = w-lim
nâ†’âˆÎ¼n.
(ii)
3
f dÎ¼n
nâ†’âˆ
âˆ’â†’
3
f dÎ¼ for all bounded Lipschitz continuous f .
(iii)
3
f dÎ¼n
nâ†’âˆ
âˆ’â†’
3
f dÎ¼ for all bounded measurable f with Î¼(Uf ) = 0.
(iv) lim inf
nâ†’âˆÎ¼n(E) â‰¥Î¼(E) and lim sup
nâ†’âˆ
Î¼n(F) â‰¤Î¼(F) for all closed F âŠ‚E.
(v) lim sup
nâ†’âˆ
Î¼n(E) â‰¤Î¼(E) and lim inf
nâ†’âˆÎ¼n(G) â‰¥Î¼(G) for all open G âŠ‚E.
(vi)
lim
nâ†’âˆÎ¼n(A) = Î¼(A) for all measurable A with Î¼(âˆ‚A) = 0.
If E is locally compact and Polish, then in addition each of the following is
equivalent to the previous statements.
(vii) Î¼ = v-lim
nâ†’âˆÎ¼n and Î¼(E) = lim
nâ†’âˆÎ¼n(E).
(viii) Î¼ = v-lim
nâ†’âˆÎ¼n and Î¼(E) â‰¥lim sup
nâ†’âˆ
Î¼n(E).

284
13
Convergence of Measures
Proof â€œ(iv) â‡â‡’(v) â‡’(vi)â€
This is trivial.
â€œ(iii) â‡’(i) â‡’(ii)â€
This is trivial.
â€œ(ii) â‡’(iv)â€
Convergence of the total masses follows by using the test function
1 âˆˆLip(E; [0, 1]). Let F be closed and let ÏF,Îµ be as in Lemma 13.10. Then
lim sup
nâ†’âˆ
Î¼n(F) â‰¤inf
Îµ>0 lim
nâ†’âˆ

ÏF,Îµ dÎ¼n = inf
Îµ>0

ÏF,Îµ dÎ¼ = Î¼(F)
since ÏF,Îµ(x)
Îµâ†’0
âˆ’â†’1F(x) for all x âˆˆE.
â€œ(viii) â‡’(vii)â€
This is obvious by Lemma 13.15.
â€œ(i) â‡’(vii)â€
This is clear since Cc(E) âŠ‚Cb(E) and 1 âˆˆCb(E).
â€œ(vii) â‡’
(v)â€
Let G be open and Îµ > 0. Since Î¼ is inner regular (Theo-
rem 13.6), there is a compact set K âŠ‚G with Î¼(G) âˆ’Î¼(K) < Îµ. As E is locally
compact, there is a compact set L with K âŠ‚Lâ—¦âŠ‚L âŠ‚G. Let Î´ := d(K, Lc) > 0
and let ÏK,Î´ be as in Lemma 13.10. Then 1K â‰¤ÏK,Î´ â‰¤1L; hence ÏK,Î´ âˆˆCc(E)
and thus
lim inf
nâ†’âˆÎ¼n(G) â‰¥lim inf
nâ†’âˆ

ÏK,Î´ dÎ¼n =

ÏK,Î´ dÎ¼ â‰¥Î¼(K) â‰¥Î¼(G) âˆ’Îµ.
Letting Îµ â†’0, we get (v).
â€œ(vi) â‡’(iii)â€
Let f : E â†’R be bounded and measurable with Î¼(Uf ) = 0.
We make the elementary observation that for all D âŠ‚R,
âˆ‚f âˆ’1(D) âŠ‚f âˆ’1(âˆ‚D) âˆªUf .
(13.6)
Indeed, if f is continuous at x âˆˆE, then for any Î´ > 0, there is an Îµ(Î´) > 0 with
f (BÎµ(Î´)(x)) âŠ‚BÎ´(f (x)). If x âˆˆâˆ‚f âˆ’1(D), then there are y âˆˆf âˆ’1(D) âˆ©BÎµ(Î´)(x)
and z âˆˆf âˆ’1(Dc) âˆ©BÎµ(Î´)(x). Therefore, f (y) âˆˆBÎ´(f (x)) âˆ©D Ì¸= âˆ…and f (z) âˆˆ
BÎ´(f (x)) âˆ©Dc Ì¸= âˆ…; hence f (x) âˆˆâˆ‚D.
Let Îµ > 0. Evidently, the set A := 	y âˆˆR : Î¼ f âˆ’1 ({y})
 > 0
 of atoms of
the ï¬nite measure Î¼ â—¦f âˆ’1 is at most countable. Hence, there exist N âˆˆN and
y0 â‰¤âˆ’âˆ¥f âˆ¥âˆ< y1 < . . . < yNâˆ’1 < âˆ¥f âˆ¥âˆ< yN such that
yi âˆˆR \ A
and
|yi+1 âˆ’yi| < Îµ
for all i.
Let Ei = f âˆ’1 ([yiâˆ’1, yi)) for i = 1, . . . , N. Then E = N
i=1 Ei and by (13.6),
Î¼âˆ‚Ei
 â‰¤Î¼f âˆ’1({yiâˆ’1}) + Î¼f âˆ’1({yi}) + Î¼Uf
 = 0.
Therefore,
lim sup
nâ†’âˆ

f dÎ¼n â‰¤lim sup
nâ†’âˆ
N

i=1
Î¼n(Ei) Â· yi =
N

i=1
Î¼(Ei) Â· yi â‰¤Îµ +

f dÎ¼.

13.2
Weak and Vague Convergence
285
We let Îµ â†’0 and obtain lim sup
nâ†’âˆ
3
f dÎ¼n â‰¤
3
f dÎ¼. Finally, consider (âˆ’f ) to
obtain the reverse inequality lim inf
nâ†’âˆ

f dÎ¼n â‰¥

f dÎ¼.
âŠ“âŠ”
Deï¬nition 13.17 Let X, X1, X2, . . . be random variables with values in E. We say
that (Xn)nâˆˆN converges in distribution to X, formally Xn
D
âˆ’â†’X or Xn
nâ†’âˆ
â‡’X,
if the distributions converge weakly and hence if PX = w-lim
nâ†’âˆPXn. Sometimes we
write Xn
D
âˆ’â†’PX or Xn
nâ†’âˆ
â‡’PX if we want to specify only the distribution PX
but not the random variable X.
Theorem 13.18 (Slutzkyâ€™s theorem)
Let X, X1, X2, . . . and Y1, Y2, . . . be ran-
dom variables with values in E. Assume Xn
D
âˆ’â†’X and d(Xn, Yn)
nâ†’âˆ
âˆ’â†’0 in
probability. Then Yn
D
âˆ’â†’X.
Proof Let f : E â†’R be bounded and Lipschitz continuous with constant K. Then
f (x) âˆ’f (y)
 â‰¤K d(x, y) âˆ§2 âˆ¥f âˆ¥âˆ
for all x, y âˆˆE.
Dominated convergence yields lim sup
nâ†’âˆ
E
)f (Xn) âˆ’f (Yn)
*
= 0. Hence we have
lim sup
nâ†’âˆ
E[f (Yn)] âˆ’E[f (X)]

â‰¤lim sup
nâ†’âˆ
E[f (X)] âˆ’E[f (Xn)]
 + lim sup
nâ†’âˆ
E[f (Xn) âˆ’f (Yn)]
 = 0.
âŠ“âŠ”
Corollary 13.19 If Xn
nâ†’âˆ
âˆ’â†’X in probability, then Xn
D
âˆ’â†’X, n â†’âˆ. The
converse is false in general.
Example 13.20 If X, X1, X2, . . . are i.i.d. (with nontrivial distribution), then triv-
ially Xn
D
âˆ’â†’X but not Xn
nâ†’âˆ
âˆ’â†’X in probability. â™¦
Recall the deï¬nition of a distribution function of a probability measure from
Deï¬nition 1.59.
Deï¬nition 13.21 Let F, F1, F2, . . . be distribution functions of probability mea-
sures on R. We say that (Fn)nâˆˆN converges weakly to F, formally Fn
nâ†’âˆ
â‡’F,
Fn
D
âˆ’â†’F or F = w-lim
nâ†’âˆFn, if
F(x) = lim
nâ†’âˆFn(x) for all points of continuity x of F.
(13.7)
If F, F1, F2, . . . are distribution functions of sub-probability measures, then we
deï¬ne F(âˆ) := limxâ†’âˆF(x) and for weak convergence require in addition
F(âˆ) â‰¥lim supnâ†’âˆFn(âˆ).

286
13
Convergence of Measures
Note that (13.7) implies F(âˆ) â‰¤lim infnâ†’âˆFn(âˆ). Hence, if Fn
D
âˆ’â†’F, then
F(âˆ) = limnâ†’âˆFn(âˆ).
Example 13.22 If F is the distribution function of a probability measure on R and
Fn(x) := F(x +n) for x âˆˆR, then (Fn)nâˆˆN converges pointwise to 1. However, this
is not a distribution function, as 1 does not converge to 0 for x â†’âˆ’âˆ. On the other
hand, if Gn(x) = F(x âˆ’n), then (Gn)nâˆˆN converges pointwise to G â‰¡0. However,
G(âˆ) = 0 < lim supnâ†’âˆGn(âˆ) = 1; hence we do not have weak convergence
here either. Indeed, in each case, there is a mass defect in the limit (in the case of
the Fn on the left and in the case of the Gn on the right). However, the deï¬nition
of weak convergence of distribution functions is constructed so that no mass defect
occurs in the limit. â™¦
Theorem 13.23 Let Î¼, Î¼1, Î¼2, . . . âˆˆMâ‰¤1(R) with corresponding distribution
functions F, F1, F2, . . .. The following are equivalent.
(i) Î¼ = w-lim
nâ†’âˆÎ¼n.
(ii) Fn
D
âˆ’â†’F.
Proof â€œ(i) â‡’(ii)â€
Let F be continuous at x. Then Î¼âˆ‚(âˆ’âˆ, x] = Î¼({x}) = 0.
By Theorem 13.16, Fn(x) = Î¼n ((âˆ’âˆ, x])
nâ†’âˆ
âˆ’â†’Î¼((âˆ’âˆ, x]) = F(x).
â€œ(ii) â‡’(i)â€
Let f âˆˆLip1(R; [0, 1]). By Theorem 13.16, it is enough to show
that

f dÎ¼n
nâ†’âˆ
âˆ’â†’

f dÎ¼.
(13.8)
Let Îµ > 0. Fix N âˆˆN and choose N + 1 points of continuity y0 < y1 < . . . < yN
of F such that F(y0) < Îµ, F(yN) > F(âˆ) âˆ’Îµ and yi âˆ’yiâˆ’1 < Îµ for all i. Then

f dÎ¼n â‰¤

Fn(y0) + Fn(âˆ) âˆ’Fn(yN)

+
N

i=1
(f (yi) + Îµ)(Fn(yi) âˆ’Fn(yiâˆ’1)).
By assumption, limnâ†’âˆFn(âˆ) = F(âˆ) and Fn(yi)
nâ†’âˆ
âˆ’â†’F(yi) for every i =
0, . . . , N; hence
lim sup
nâ†’âˆ

f dÎ¼n â‰¤3 Îµ +
N

i=1
f (yi)F(yi) âˆ’F(yiâˆ’1) â‰¤4 Îµ +

f dÎ¼.
Therefore,
lim sup
nâ†’âˆ

f dÎ¼n â‰¤

f dÎ¼.
Replacing f by (1 âˆ’f ), we get (13.8).
âŠ“âŠ”

13.2
Weak and Vague Convergence
287
Corollary 13.24 Let X, X1, X2, . . . be real random variables with distribution
functions F, F1, F2, . . .. Then the following are equivalent.
(i) Xn
D
âˆ’â†’X.
(ii) E[f (Xn)]
nâ†’âˆ
âˆ’â†’E[f (X)] for all f âˆˆCb(R).
(iii) Fn
D
âˆ’â†’F.
How stable is weak convergence if we pass to image measures under some map
Ï•? Clearly, we need a certain continuity of Ï• at least at those points where the limit
measure puts mass. The following theorem formalizes this idea and will come in
handy in many applications.
Theorem 13.25 (Continuous mapping theorem) Let (E1, d1) and (E2, d2) be
metric spaces and let Ï• : E1 â†’E2 be measurable. Denote by UÏ• the set of points
of discontinuity of Ï•.
(i) If Î¼, Î¼1, Î¼2, . . . âˆˆMâ‰¤1(E1) with Î¼(UÏ•) = 0 and Î¼n
nâ†’âˆ
âˆ’â†’Î¼ weakly, then
Î¼n â—¦Ï•âˆ’1 nâ†’âˆ
âˆ’â†’Î¼ â—¦Ï•âˆ’1 weakly.
(ii) If X, X1, X2, . . . are E1-valued random variables with P[X âˆˆUÏ•] = 0 and
Xn
D
âˆ’â†’X, then Ï•(Xn)
D
âˆ’â†’Ï•(X).
Proof First note that UÏ• âŠ‚E1 is Borel measurable by Exercise 1.1.3. Hence the
conditions make sense.
(i) Let f âˆˆCb(E2). Then f â—¦Ï• is bounded and measurable and Uf â—¦Ï• âŠ‚UÏ•; hence
Î¼(Uf â—¦Ï•) = 0. By Theorem 13.16,
lim
nâ†’âˆ

f d

Î¼n â—¦Ï•âˆ’1
= lim
nâ†’âˆ

(f â—¦Ï•) dÎ¼n
=

(f â—¦Ï•) dÎ¼ =

f dÎ¼ â—¦Ï•âˆ’1.
(ii) This is obvious since PÏ•(X) = PX â—¦Ï•âˆ’1.
âŠ“âŠ”
Takeaways Weak convergence of measures is deï¬ned via convergence of
integrals of bounded continuous test functions. If the test functions are also
assumed to have compact support, we get vague convergence of measures.
Roughly speaking, the difference is that vague convergence does not imply
convergence of total masses. In fact, vague convergence is a sensible notion
even for inï¬nite measures. The most important properties of weak and vague
convergence are summarised in the portemanteau theorem and the continuous
mapping theorem. For probability measures on R, weak convergence is
tantamount to convergence of distribution functions at all points of continuity
of the limiting function.

288
13
Convergence of Measures
Exercise 13.2.1 Recall dâ€²
P from (13.5). Show that dP (Î¼, Î½) = dâ€²
P (Î¼, Î½) =
dâ€²
P (Î½, Î¼) for all Î¼, Î½ âˆˆM1(E). â™£
Exercise 13.2.2 Show that the topology of weak convergence on Mf (E) is
coarser than the topology induced on Mf (E) by the total variation norm (see
Corollary 7.45). That is, âˆ¥Î¼n âˆ’Î¼âˆ¥T V
nâ†’âˆ
âˆ’â†’0 implies Î¼n
nâ†’âˆ
âˆ’â†’Î¼ weakly. â™£
Exercise 13.2.3 Let E = R and Î¼n =
1
n
n
k=0 Î´k/n. Let Î¼ = Î»
[0,1] be the
Lebesgue measure restricted to [0, 1]. Show that Î¼ = w-lim
nâ†’âˆÎ¼n. â™£
Exercise 13.2.4 Let E = R and Î» be the Lebesgue measure on R. For n âˆˆN, let
Î¼n = Î»
[âˆ’n,n]. Show that Î» = v-lim
nâ†’âˆÎ¼n but that (Î¼n)nâˆˆN does not converge weakly.
â™£
Exercise 13.2.5 Let E = R and Î¼n = Î´n for n âˆˆN. Show that v-lim
nâ†’âˆÎ¼n = 0 but
that (Î¼n)nâˆˆN does not converge weakly. â™£
Exercise 13.2.6 (LÃ©vy metric)
For two probability distribution functions F and
G on R, deï¬ne the LÃ©vy distance by
d(F, G) = inf
	
Îµ â‰¥0 : G(x âˆ’Îµ) âˆ’Îµ â‰¤F(x) â‰¤G(x + Îµ) + Îµ for all x âˆˆR

.
Show the following:
(i) d is a metric on the set of distribution functions.
(ii) Fn
nâ†’âˆ
â‡’F if and only if d(Fn, F)
nâ†’âˆ
âˆ’â†’0.
(iii) For every P âˆˆM1(R), there is a sequence (Pn)nâˆˆN in M1(R) such that each
Pn has ï¬nite support and such that Pn
nâ†’âˆ
â‡’P. â™£
Exercise 13.2.7 We can extend the notions of weak convergence and vague con-
vergence to signed measures; that is, to differences Ï• := Î¼+ âˆ’Î¼âˆ’of measures
from Mf (E) and M(E), respectively, by repeating the words of Deï¬nition 13.12
for these classes. Show that the topology of weak convergence is not metrizable in
general.
Hint: Consider E = [0, 1].
(i) For n âˆˆN, deï¬ne Ï•n = Î´1/n âˆ’Î´2/n. Show that, for any C > 0, (CÏ•n)nâˆˆN
converges weakly to the zero measure.
(ii) Assume there is a metric that induces weak convergence. Show that then there
would be a sequence (Cn)nâˆˆN with Cn â†‘âˆand 0 = w-lim
nâ†’âˆ(CnÏ•n).
(iii) Choose an f âˆˆC([0, 1]) with f (2âˆ’n) = (âˆ’1)nCâˆ’1/2
n
for any n âˆˆN, and
show that
 3
f d(CnÏ•n)

nâˆˆN does not converge to zero.
(iv) Use this construction to contradict the assumption of metrizability. â™£

13.2
Weak and Vague Convergence
289
Exercise 13.2.8 Show that (13.4) deï¬nes a metric on M1(E) and that this metric
induces the topology of weak convergence. â™£
Exercise 13.2.9 Show the implication â€œ(vi) â‡’(iv)â€ of Theorem 13.16 directly.
â™£
Exercise 13.2.10 Let X, X1, X2, . . . and Y1, Y2, . . . be real random variables.
Assume PYn = N0,1/n for all n âˆˆN. Show that Xn
D
âˆ’â†’
X if and only if
Xn + Yn
D
âˆ’â†’X. â™£
Exercise 13.2.11 For each n âˆˆN, let Xn be a geometrically distributed random
variable with parameter pn âˆˆ(0, 1). How must we choose the sequence (pn)nâˆˆN
in order that PXn/n converges weakly to the exponential distribution with parameter
Î± > 0? â™£
Exercise 13.2.12 Let X, X1, X2, . . . be real random variables with Xn
nâ†’âˆ
â‡’X.
Show the following.
(i) E[|X|] â‰¤lim infnâ†’âˆE[|Xn|].
(ii) Let r > p > 0. If sup
nâˆˆN
E[|Xn|r] < âˆ, then E[|X|p] = lim
nâ†’âˆE[|Xn|p]. â™£
Exercise 13.2.13 Let F, F1, F2, . . . be probability distribution functions on R, and
assume Fn
nâ†’âˆ
â‡’F. Let F âˆ’1(u) = inf{x âˆˆR : F(x) â‰¥u}, u âˆˆ(0, 1), be the left
continuous inverse of F (see the proof of Theorem 1.104). Show that
F âˆ’1
n (u)
nâ†’âˆ
âˆ’â†’F âˆ’1(u) at every point of continuity u of F âˆ’1.
Conclude that F âˆ’1(u)
nâ†’âˆ
âˆ’â†’F âˆ’1(u) for Lebesgue almost all u âˆˆ(0, 1). â™£
Exercise 13.2.14 Let Î¼, Î¼1, Î¼2, . . . âˆˆM1(R) with Î¼n
nâ†’âˆ
âˆ’â†’Î¼ weakly. Show that
there exists a probability space (Î©, A, P) and real random variables X, X1, X2, . . .
on (Î©, A, P) with distributions PX = Î¼ and PXn = Î¼n, n âˆˆN, such that
Xn
nâ†’âˆ
âˆ’â†’X
P-a.s.
Hint: Use Exercise 13.2.13. â™£
Exercise 13.2.15 Let (E, d) be a metric space and let Î¼, Î¼1, Î¼2, . . . be probability
measures on E. A measurable map f : E â†’R is called uniformly integrable with
respect to (Î¼n)nâˆˆN, if
inf
a>0 sup
nâˆˆN

{|f |>a}
|f | dÎ¼n = 0.

290
13
Convergence of Measures
Let f be continuous and uniformly integrable with respect to (Î¼n)nâˆˆN and assume
that Î¼n
nâ†’âˆ
âˆ’â†’Î¼ weakly. Show that
3
|f | dÎ¼ < âˆand that

f dÎ¼n
nâ†’âˆ
âˆ’â†’

f dÎ¼.
Hint: Apply Exercise 13.2.14 to the image measures Î¼n â—¦f âˆ’1. â™£
13.3
Prohorovâ€™s Theorem
In the following, let E be a Polish space with Borel Ïƒ-algebra E. A fundamental
question is: When does a sequence (Î¼n)nâˆˆN of measures on (E, E) converge weakly
or does at least have a weak limit point? Evidently, a necessary condition is that
(Î¼n(E))nâˆˆN is bounded. Hence, without loss of generality, we will consider only
sequences in Mâ‰¤1(E). However, this condition is not sufï¬cient for the existence of
weak limit points, as for example the sequence (Î´n)nâˆˆN of probability measures on R
does not have a weak limit point (although it convergesvaguely to the zero measure).
This example suggests that we also have to make sure that no mass â€œvanishes at
inï¬nityâ€. The idea will be made precise by the notion of tightness.
We start this section by presenting as the main result Prohorovâ€™s theorem [136].
We give the proof ï¬rst for the special case E = R and then come to a couple of
applications. The full proof of the general case is deferred to the end of the section.
Deï¬nition 13.26 (Tightness) A family F âŠ‚Mf (E) is called tight if, for any
Îµ > 0, there exists a compact set K âŠ‚E such that
sup 	Î¼(E \ K) : Î¼ âˆˆF
 < Îµ.
Remark 13.27 If E is Polish, then by Lemma 13.5, every singleton {Î¼} âŠ‚Mf (E)
is tight and thus so is every ï¬nite family. â™¦
Example 13.28
(i) If E is compact, then M1(E) and Mâ‰¤1(E) are tight.
(ii) If (Xi)iâˆˆI is an arbitrary family of random variables with
C := sup{E[|Xi|] : i âˆˆI} < âˆ,
then {PXi : i âˆˆI} is tight. Indeed, for Îµ > 0 and K = [âˆ’C/Îµ, C/Îµ], by
Markovâ€™s inequality, PXi(R \ K) = P[|Xi| > C/Îµ] â‰¤Îµ.
(iii) The family (Î´n)nâˆˆN of probability measures on R is not tight.
(iv) The family (U[âˆ’n,n])nâˆˆN of uniform distributions on the intervals [âˆ’n, n],
regarded as measures on R, is not tight. â™¦

13.3
Prohorovâ€™s Theorem
291
Recall that a family F of measures is called weakly relatively sequentially compact
if every sequence in F has a weak limit point (in the closure of F).
Theorem 13.29 (Prohorovâ€™s theorem (1956)) Let (E, d) be a metric space and
F âŠ‚Mâ‰¤1(E). Then:
(i) F is tight
â‡’
F is weakly relatively sequentially compact.
(ii) If E is Polish, then also the converse holds:
F is tight
â‡
F is weakly relatively sequentially compact.
Corollary 13.30 Let E be a compact metric space. Then the sets Mâ‰¤1(E) and
M1(E) are weakly sequentially compact.
Corollary 13.31 If E is a locally compact separable metric space, then Mâ‰¤1(E)
is vaguely sequentially compact.
Proof Let (Î¼n)nâˆˆN be a sequence in Mâ‰¤1(E). We have to show that there exists a
vaguely convergent subsequence.
As E is locally compact and separable, E is Ïƒ-compact. Let U1, U2, . . . âŠ‚E be
relatively compact open sets covering E. Inductively, we deï¬ne relatively compact
open sets Wn â†‘E with Wn âŠ‚Wn+1 for all n âˆˆN. Let W1 := U1. Having deï¬ned
Wn, we choose a relatively open set Ln âŠƒWn and deï¬ne Wn+1 := Ln âˆªUn+1. Note
that for any compact C âŠ‚E, there exists an N(C) âˆˆN such that C âŠ‚Wn for all
n â‰¥N(C).
Applying
Prohorovâ€™s
theorem
(i.e.,
Corollary
13.30)
to
the
measures
(Î¼k1W n)kâˆˆN, for each n âˆˆN, we can choose a sequence (kn
l )lâˆˆN and a measure
ËœÎ¼n := w-lim
lâ†’âˆÎ¼kn
l 1W n whose support lies in W n. We may assume that the sequences
(kn
l )lâˆˆN were chosen successively such that (kn+1
l
) is a subsequence of (kn
l ).
Note that we have ËœÎ¼n(W n) â‰¤ËœÎ¼n+1(W n), but equality does not hold in general.
For f âˆˆCc(E), there exists an n0 âˆˆN such that the support of f is contained in
Wn0. Hence, for m â‰¥n â‰¥n0, we have

f d ËœÎ¼n = lim
lâ†’âˆ

f 1W n dÎ¼kn
l
= lim
lâ†’âˆ

f 1W n dÎ¼km
l
= lim
lâ†’âˆ

f 1W m dÎ¼km
l =

f d ËœÎ¼m
and thus

f d ËœÎ¼n = lim
mâ†’âˆ

f dÎ¼km
m.

292
13
Convergence of Measures
This implies that for any measurable relatively compact set A âŠ‚E, we have
ËœÎ¼m(A) = ËœÎ¼N(A)(A)
for any m â‰¥N(A).
For any measurable set A âŠ‚E, deï¬ne
Î¼(A) := sup
nâˆˆN
sup
m>n
ËœÎ¼m(A âˆ©Wn) = sup
nâˆˆN
ËœÎ¼n+1(A âˆ©Wn).
It is easy to check that Î¼ is a lower semicontinuous content and is hence a measure
(see Theorem 1.36). By construction, for any f âˆˆCc(E), we infer

f dÎ¼ = lim
nâ†’âˆ

f dÎ¼knn.
Concluding, we have Î¼ = v-lim
nâ†’âˆÎ¼knn.
âŠ“âŠ”
Remark 13.32 The implication (ii) in Theorem 13.29 is less useful but a lot simpler
to prove. Here we need that E is Polish since clearly every singleton is weakly
compact but is tight only under additional assumptions; for example, if E is Polish
(see Lemma 13.5). â™¦
Proof (of Theorem 13.29(ii))
We start as in the proof of Lemma 13.5. Let
{x1, x2, . . .} âŠ‚E be dense. For n âˆˆN, deï¬ne An,N :=
N
i=1
B1/n(xi). Then
An,N â†‘E for N â†’âˆfor all n âˆˆN. Let
Î´ := sup
nâˆˆN
inf
NâˆˆN sup
Î¼âˆˆF
Î¼(Ac
n,N).
Then there is an n âˆˆN such that for any N âˆˆN, there is a Î¼N âˆˆF with
Î¼N(Ac
n,N) â‰¥Î´/2. As F is weakly relatively sequentially compact, (Î¼N)NâˆˆN has
a weakly convergent subsequence (Î¼Nk)kâˆˆN whose weak limit will be denoted by
Î¼ âˆˆMâ‰¤1(E). By the Portemanteau theorem (Theorem 13.16(iv)), for any N âˆˆN,
Î¼(Ac
n,N) â‰¥lim inf
kâ†’âˆÎ¼Nk(Ac
n,N) â‰¥lim inf
kâ†’âˆÎ¼Nk(Ac
n,Nk) â‰¥Î´/2.
On the other hand, Ac
n,N â†“âˆ…for N â†’âˆ; hence Î¼(Ac
n,N)
Nâ†’âˆ
âˆ’â†’0. Thus Î´ = 0.
Now ï¬x Îµ > 0. By the above, for any n âˆˆN, we can choose an Nâ€²
n âˆˆN such
that Î¼(Ac
n,Nâ€²n) < Îµ/2n for all Î¼ âˆˆF. By construction, the set A := âˆ
n=1 An,Nâ€²n is
totally bounded and hence relatively compact. Further, for every Î¼ âˆˆF,
Î¼

( A )c
â‰¤Î¼(Ac) â‰¤
âˆ

n=1
Î¼(Ac
n,Nâ€²n) â‰¤Îµ.
Hence F is tight.
âŠ“âŠ”

13.3
Prohorovâ€™s Theorem
293
The other implication in Prohorovâ€™s theorem is more difï¬cult to prove, especially
in the case of a general metric space. For this reason, we ï¬rst give a proof only for
the case E = R and come to applications before proving the difï¬cult implication in
the general situation.
The problem consists in ï¬nding a candidate for a weak limit point. For
distributions on R, the problem is equivalent to ï¬nding a weak limit point for a
sequence of distribution functions. Here Hellyâ€™s theorem is the tool. It is based on
a diagonal sequence argument that will be recycled later in the proof of Prohorovâ€™s
theorem in the general case.
Let
V =
	
F : R â†’R is right continuous, monotone increasing and bounded

be the set of distribution functions of ï¬nite measures on R.
Theorem 13.33 (Hellyâ€™s theorem) Let (Fn)nâˆˆN be a uniformly bounded sequence
in V . Then there exists an F âˆˆV and a subsequence (Fnk)kâˆˆN with
Fnk(x)
kâ†’âˆ
âˆ’â†’F(x) at all points of continuity of F.
Proof We use a diagonal sequence argument. Choose an enumeration of the rational
numbers Q = {q1, q2, q3, . . . }. By the Bolzanoâ€“WeierstraÃŸ theorem, the sequence
(Fn(q1))nâˆˆN has a convergent subsequence Fn1
k(q1)
kâˆˆN. Analogously, we ï¬nd a
subsequence (n2
k)kâˆˆN of (n1
k)kâˆˆN such that

Fn2
k(q2)

kâˆˆN converges. Inductively, we
obtain subsequences (n1
k) âŠƒ(n2
k) âŠƒ(n3
k) âŠƒ. . . such that

Fnl
k(ql)

kâˆˆN converges
for all l âˆˆN. Now deï¬ne nk := nk
k. Then

Fnk(q)

kâˆˆN converges for all q âˆˆQ.
Deï¬ne 
F(q) = lim
kâ†’âˆFnk(q) and
F(x) = inf
	
F(q) : q âˆˆQ with q > x

.
As 
F is monotone increasing, F is right continuous and monotone increasing.
If F is continuous at x, then for every Îµ > 0, there exist numbers qâˆ’, q+ âˆˆ
Q, qâˆ’< x < q+ with 
F(qâˆ’) â‰¥F(x)âˆ’Îµ and 
F (q+) â‰¤F(x)+Îµ. By construction,
lim sup
kâ†’âˆ
Fnk(x) â‰¤lim
kâ†’âˆFnk(q+) = 
F(q+) â‰¤F(x) + Îµ.
Hence lim sup
kâ†’âˆ
Fnk(x) â‰¤F(x). A similar argumentfor qâˆ’yields lim inf
kâ†’âˆFnk(x) â‰¥
F(x).
âŠ“âŠ”
Reï¬‚ection Check that in the above proof, in general, we do not have F(q) = ËœF(q)
for all q âˆˆQ.â™ 

294
13
Convergence of Measures
Proof (of Theorem 13.29(i) for the case E = R) Assume F is tight and (Î¼n)nâˆˆN
is a sequence in F with distribution functions Fn : x â†’Î¼N((âˆ’âˆ, x]). By
Hellyâ€™s theorem, there is a monotone right continuous function F : R â†’[0, 1]
and a subsequence (Fnk)kâˆˆN of (Fn)nâˆˆN with Fnk(x)
kâ†’âˆ
âˆ’â†’F(x) at all points of
continuity x of F. We will show
(i) F is the distribution function of a (sub-) probability measure. That is, we have
F(âˆ’âˆ) = 0.
(ii) We have F(âˆ) â‰¥lim supkâ†’âˆFnk(âˆ).
By Theorem 13.23, this is enough to conclude the proof.
As F is tight, for every Îµ > 0, there is a K < âˆwith Fn(x) âˆ’Fn(âˆ’âˆ) < Îµ for
all n âˆˆN and x < âˆ’K. If x > K is a point of continuity of F, then
0 = lim inf
kâ†’âˆFnk(âˆ’âˆ) â‰¥lim inf
kâ†’âˆFnk(x) âˆ’Îµ
= F(x) âˆ’Îµ â‰¥F(âˆ’âˆ) âˆ’Îµ â‰¥âˆ’Îµ.
This shows (i).
As F is tight, for every Îµ > 0, there is a K < âˆwith Fn(âˆ) âˆ’Fn(x) < Îµ
for all n âˆˆN and x > K. If x > K is a point of continuity of F, then
lim supkâ†’âˆFnk(âˆ) â‰¤lim supkâ†’âˆFnk(x) + Îµ = F(x) + Îµ â‰¤F(âˆ) + Îµ. This
shows (ii).
âŠ“âŠ”
Reï¬‚ection Find an example that shows that without the tightness assumption, we
need not have F(âˆ’âˆ) = 0 nor F(âˆ) = 1.â™ 
We come to a ï¬rst application of Prohorovâ€™s theorem. The full strength of that
theorem will become manifest when suitable separating classes of functions are at
our disposal. We come back to this point in more detail in Chap. 15.
Theorem 13.34 Let E be Polish and let Î¼, Î¼1, Î¼2, . . . âˆˆMâ‰¤1(E). Then the
following are equivalent.
(i) Î¼ = w-lim
nâ†’âˆÎ¼n.
(ii) (Î¼n)nâˆˆN is tight, and there is a separating family C âŠ‚Cb(E) such that

f dÎ¼ = lim
nâ†’âˆ

f dÎ¼n
for all f âˆˆC.
(13.9)
Proof â€œ(i) â‡’(ii)â€
By the simple implication in Prohorovâ€™s theorem (Theo-
rem 13.29(ii)), weak convergence implies tightness.
â€œ(ii) â‡’(i)â€
Let (Î¼n)nâˆˆN be tight and let C âŠ‚Cb(E) be a separating class with
(13.9). Assume that (Î¼n)nâˆˆN does not converge weakly to Î¼. Then there are Îµ > 0,
f âˆˆCb(E) and (nk)kâˆˆN with nk â†‘âˆand such that


f dÎ¼nk âˆ’

f dÎ¼
 > Îµ
for all k âˆˆN.
(13.10)

13.3
Prohorovâ€™s Theorem
295
By Prohorovâ€™s theorem, there exists a Î½ âˆˆMâ‰¤1(E) and a subsequence (nâ€²
k)kâˆˆN of
(nk)kâˆˆN with Î¼nâ€²
k â†’Î½ weakly. Due to (13.10), we have
3
f dÎ¼ âˆ’
3
f dÎ½
 â‰¥Îµ;
hence Î¼ Ì¸= Î½. On the other hand,

h dÎ¼ = lim
kâ†’âˆ

h dÎ¼nâ€²
k =

h dÎ½
for all h âˆˆC;
hence Î¼ = Î½. This contradicts the assumption and thus (i) holds.
âŠ“âŠ”
We want to shed some more light on the connection between weak and vague
convergence.
Theorem 13.35 Let E be a locally compact Polish space and let Î¼, Î¼1, Î¼2, . . .
âˆˆMf (E). Then the following are equivalent.
(i) Î¼ = w-lim
nâ†’âˆÎ¼n.
(ii) Î¼ = v-lim
nâ†’âˆÎ¼n and Î¼(E) = lim
nâ†’âˆÎ¼n(E).
(iii) Î¼ = v-lim
nâ†’âˆÎ¼n and Î¼(E) â‰¥lim sup
nâ†’âˆ
Î¼n(E).
(iv) Î¼ = v-lim
nâ†’âˆÎ¼n and {Î¼n, n âˆˆN} is tight.
Proof â€œ(i) â‡â‡’(ii) â‡â‡’(iii)â€
This follows by the Portemanteau theorem.
â€œ(ii) â‡’(iv)â€
It is enough to show that for any Îµ > 0, there is a compact set
K âŠ‚E with lim supnâ†’âˆÎ¼n(E \ K) â‰¤Îµ. As Î¼ is regular (Theorem 13.6), there is
a compact set L âŠ‚E with Î¼(E \ L) < Îµ. Since E is locally compact, there exists a
compact set K âŠ‚E with Kâ—¦âŠƒL and a ÏL,K âˆˆCc(E) with 1L â‰¤ÏL,K(x) â‰¤1K.
Therefore,
lim sup
nâ†’âˆ
Î¼n(E \ K) â‰¤lim sup
nâ†’âˆ

Î¼n(E) âˆ’

ÏL,K dÎ¼n

= Î¼(E) âˆ’

ÏL,K dÎ¼ â‰¤Î¼(E \ L) < Îµ.
â€œ(iv) â‡’(i)â€
Let L âŠ‚E be compact with Î¼n(E \ L) â‰¤1 for all n âˆˆN. Let
Ï âˆˆCc(E) with Ï â‰¥1L. Since
3
Ï dÎ¼n converges by assumption, we thus have
sup
nâˆˆN
Î¼n(E) â‰¤1 + sup
nâˆˆN
Î¼n(L) â‰¤1 + sup
nâˆˆN

Ï dÎ¼n < âˆ.
Hence also
C := max(Î¼(E), sup{Î¼n(E) : n âˆˆN}) < âˆ,
and we can pass to Î¼/C and Î¼n/C. Thus, without loss of generality assume that
all measures are in Mâ‰¤1(E). As Cc(E) is a separating class for Mâ‰¤1(E) (see
Theorem 13.11), (i) follows by Theorem 13.34.
âŠ“âŠ”

296
13
Convergence of Measures
Proof of Prohorovâ€™s theorem, Part (i), general case There are two main routes
for proving Prohorovâ€™s theorem in the general situation. One possibility is to show
the claim ï¬rst for measures on Rd. (We have done this already for d = 1, see
Exercise 13.3.4 for d â‰¥2.) In a second step, the statement is lifted to sequence
spaces RN. Finally, in the third step, an embedding of E into RN is constructed. For
a detailed description, see [12] or [83].
Here we follow the alternative route as described in [13] (and later [14]) or
[44]. The main point of this proof consists in ï¬nding a candidate for a weak limit
point for the family F. This candidate will be constructed ï¬rst as a content on a
countable class of sets. From this an outer measure will be derived. Finally, we
show that closed sets are measurable with respect to this outer measure. As you see,
the argument follows a pattern similar to the proof of CarathÃ©odoryâ€™s theorem.
Let (E, d) be a metric space and let F âŠ‚Mâ‰¤1(E) be tight. Then there exists
an increasing sequence K1 âŠ‚K2 âŠ‚K3 âŠ‚. . . of compact sets in E such that
Î¼(Kc
n) <
1
n for all Î¼ âˆˆF and all n âˆˆN. Deï¬ne Eâ€² := âˆ
n=1 Kn. Then Eâ€² is
a Ïƒ-compact metric space and therefore in particular, separable. By construction,
Î¼(E \ Eâ€²) = 0 for all Î¼ âˆˆF. Thus, any Î¼ can be regarded as a measure on Eâ€².
Without loss of generality, we may hence assume that E is Ïƒ-compact and thus
separable. Hence there exists a countable base U of the topology Ï„
E on E; that is,
a countable set U of open sets such that A = 
UâˆˆU, UâŠ‚A U for any open A âŠ‚E.
Deï¬ne
Câ€² :=
	
U âˆ©Kn : U âˆˆU, n âˆˆN

and
C :=
0 N

n=1
Cn : N âˆˆN and C1, . . . , CN âˆˆCâ€²
1
.
Clearly, C is a countable set of compact sets in E, and C is stable under formation
of unions. Any Kn possesses a ï¬nite covering with sets from U; hence Kn âˆˆC.
Now let (Î¼n)nâˆˆN be a sequence in F. By virtue of the diagonal sequence
argument (see the proof of Hellyâ€™s theorem, Theorem 13.33), we can ï¬nd a
subsequence (Î¼nk)kâˆˆN such that for all C âˆˆC, there exists the limit
Î±(C) := lim
kâ†’âˆÎ¼nk(C).
(13.11)
Assume that we can show that there is a measure Î¼ on the Borel Ïƒ-algebra E of E
such that
Î¼(A) = sup 	Î±(C) : C âˆˆC with C âŠ‚A
for all A âŠ‚E open.
(13.12)

13.3
Prohorovâ€™s Theorem
297
Then
Î¼(E) â‰¥sup
nâˆˆN
Î±(Kn) = sup
nâˆˆN
lim
kâ†’âˆÎ¼nk(Kn)
â‰¥sup
nâˆˆN
lim sup
kâ†’âˆ

Î¼nk(E) âˆ’1
n

= lim sup
kâ†’âˆ
Î¼nk(E).
Furthermore, for open A and for C âˆˆC with C âŠ‚A,
Î±(C) = lim
kâ†’âˆÎ¼nk(C) â‰¤lim inf
kâ†’âˆÎ¼nk(A),
hence Î¼(A) â‰¤lim infkâ†’âˆÎ¼nk(A). By the Portemanteau theorem (Theorem 13.16),
Î¼ = w-lim
kâ†’âˆÎ¼nk; hence F is recognized as weakly relatively sequentially compact.
It remains to show that there exists a measure Î¼ on (E, E) that satisï¬es (13.12).
Clearly, the set function Î± on C is monotone, additive and subadditive:
Î±(C1) â‰¤Î±(C2),
if C1 âŠ‚C2,
Î±(C1 âˆªC2) = Î±(C1) + Î±(C2),
if C1 âˆ©C2 = âˆ…,
Î±(C1 âˆªC2) â‰¤Î±(C1) + Î±(C2).
(13.13)
We deï¬ne
Î²(A) := sup
	
Î±(C) : C âˆˆC with C âŠ‚A

for A âŠ‚E open
and
Î¼âˆ—(G) := inf 	Î²(A) : A âŠƒG is open
for G âˆˆ2E.
Manifestly, Î²(A) = Î¼âˆ—(A) for any open A. It is enough to show (Steps 1â€“3 below)
that Î¼âˆ—is an outer measure (see Deï¬nition 1.46) and that (Step 4) the Ïƒ-algebra
of Î¼âˆ—-measurable sets (see Deï¬nition 1.48 and Lemma 1.52) contains the closed
sets and thus E. Indeed, Lemma 1.52 would then imply that Î¼âˆ—is a measure on
the Ïƒ-algebra of Î¼âˆ—-measurable sets and the restricted measure Î¼ := Î¼âˆ—E fulï¬lls
Î¼(A) = Î¼âˆ—(A) = Î²(A) for all open A. Hence equation (13.12) holds.
Evidently, Î¼âˆ—(âˆ…) = 0 and Î¼âˆ—is monotone. In order to show that Î¼âˆ—is an outer
measure, it only remains to check that Î¼âˆ—is Ïƒ-subadditive.

298
13
Convergence of Measures
Step 1 (Finite subadditivity of Î²). Let A1, A2 âŠ‚E be open and let C âˆˆC with
C âŠ‚A1 âˆªA2. Let n âˆˆN with C âŠ‚Kn. Deï¬ne two sets
B1 :=
x âˆˆC : d(x, Ac
1) â‰¥d(x, Ac
2) ,
B2 :=
x âˆˆC : d(x, Ac
1) â‰¤d(x, Ac
2) .
2
A
1
1
C
A
2
B
B
Evidently, B1 âŠ‚A1 and B2 âŠ‚A2. As x â†’d(x, Ac
i ) is continuous for i = 1, 2,
the closed subsets B1 and B2 of C are compact. Hence d(B1, Ac
1) > 0. Thus there
exists an open set D1 with B1 âŠ‚D1 âŠ‚D1 âŠ‚A1. (One could choose D1 as the
union of the sets of a ï¬nite covering of B1 with balls of radius d(B1, Ac
1)/2. These
balls, as well as their closures, are subsets of A1.) Let UD1 := {U âˆˆU : U âŠ‚D1}.
Then B1 âŠ‚D1 = 
UâˆˆUD1 U. Now choose a ï¬nite subcovering {U1, . . . , UN} âŠ‚
UD1 of B1 and deï¬ne C1 := N
i=1 U i âˆ©Kn. Then B1 âŠ‚C1 âŠ‚A1 and C1 âˆˆC.
Similarly, choose C2 âˆˆC with B2 âŠ‚C2 âŠ‚A2. Thus
Î±(C) â‰¤Î±(C1 âˆªC2) â‰¤Î±(C1) + Î±(C2) â‰¤Î²(A1) + Î²(A2).
Hence also
Î²(A1 âˆªA2) = sup
	
Î±(C) : C âˆˆC with C âŠ‚A1 âˆªA2

â‰¤Î²(A1) + Î²(A2).
Step 2 (Ïƒ-subadditivity of Î²). Let A1, A2, . . . be open sets and let C âˆˆC with
C âŠ‚âˆ
i=1 Ai. As C is compact, there exists an n âˆˆN with C âŠ‚n
i=1 Ai. As
shown above, Î² is subadditive; thus
Î±(C) â‰¤Î²
 n

i=1
Ai

â‰¤
âˆ

i=1
Î²(Ai).
Taking the supremum over such C yields
Î²
 âˆ

i=1
Ai

= sup
0
Î±(C) : C âˆˆC with C âŠ‚
âˆ

i=1
Ai
1
â‰¤
âˆ

i=1
Î²(Ai).

13.3
Prohorovâ€™s Theorem
299
Step 3 (Ïƒ-subadditivity of Î¼âˆ—). Let G1, G2, . . . âˆˆ2E. Let Îµ > 0. For any n âˆˆN
choose an open set An âŠƒGn with Î²(An) < Î¼âˆ—(Gn)+Îµ/2n. By the Ïƒ-subadditivity
of Î²,
Î¼âˆ—
 âˆ

n=1
Gn

â‰¤Î²
 âˆ

n=1
An

â‰¤
âˆ

n=1
Î²(An) â‰¤Îµ +
âˆ

n=1
Î¼âˆ—(Gn).
Letting Îµ â†“0 yields Î¼âˆ— âˆ
n=1 Gn

â‰¤âˆ
n=1 Î¼âˆ—(Gn). Hence Î¼âˆ—is an outer
measure.
Step 4 (Closed sets are Î¼âˆ—-measurable). By Lemma 1.49, a set B âŠ‚E is Î¼âˆ—-
measurable if and only if
Î¼âˆ—(B âˆ©G) + Î¼âˆ—(Bc âˆ©G) â‰¤Î¼âˆ—(G)
for all G âˆˆ2E.
Taking the inï¬mum over all open sets A âŠƒG, it is enough to show that for every
open B and every open A âŠ‚E,
Î¼âˆ—(B âˆ©A) + Î¼âˆ—(Bc âˆ©A) â‰¤Î²(A).
(13.14)
Let Îµ > 0. Choose C1 âˆˆC with C1 âŠ‚A âˆ©Bc and Î±(C1) > Î²(A âˆ©Bc) âˆ’Îµ. Further,
let C2 âˆˆC with C2 âŠ‚A âˆ©Cc
1 and Î±(C2) > Î²(A âˆ©Cc
1) âˆ’Îµ. Since C1 âˆ©C2 = âˆ…and
C1 âˆªC2 âŠ‚A, we get
Î²(A) â‰¥Î±(C1 âˆªC2) = Î±(C1) + Î±(C2) â‰¥Î²(A âˆ©Bc) + Î²(A âˆ©Cc
1) âˆ’2Îµ
â‰¥Î¼âˆ—(A âˆ©Bc) + Î¼âˆ—(A âˆ©B) âˆ’2Îµ.
Letting Îµ â†’0, we get (13.14). This completes the proof of Prohorovâ€™s theorem.
â–¡
Takeaways A family of measures is called tight if for larger and larger
compacts, there is arbitrarily little mass outside the compact. By Prohorovâ€™s
theorem, in Polish spaces, tightness is equivalent to relative sequential
compactness. Since usually tightness is easier to check, we have a powerful
tool for showing the existence of accumulation points.
Exercise 13.3.1 Show that a family F âŠ‚Mf (R) is tight if and only if there exists
a measurable map f : R â†’[0, âˆ) such that f (x) â†’âˆfor |x| â†’âˆand
supÎ¼âˆˆF
3 f dÎ¼ < âˆ. â™£

300
13
Convergence of Measures
Exercise 13.3.2 Let L âŠ‚R Ã— (0, âˆ) and let F = {NÎ¼,Ïƒ 2 : (Î¼, Ïƒ 2) âˆˆL} be a
family of normal distributions with parameters in L. Show that F is tight if and only
if L is bounded. â™£
Exercise 13.3.3 If P is a probability measure on [0, âˆ) with mP := 3 x P(dx) âˆˆ
(0, âˆ), then we deï¬ne the size-biased distribution :
P on [0, âˆ) by
:
P (A) = mâˆ’1
P

A
x P(dx).
(13.15)
Now let (Xi)iâˆˆI be a family of random variables on [0, âˆ) with E[Xi] = 1. Show
that
 A
PXi

iâˆˆI is tight if and only if (Xi)iâˆˆI is uniformly integrable. â™£
Exercise 13.3.4 (Hellyâ€™s theorem in Rd)
Let x = (x1, . . . , xd) âˆˆRd and y =
(y1, . . . , yd) âˆˆRd. Recall the notation x â‰¤y if xi â‰¤yi for all i = 1, . . . , d. A map
F : Rd â†’R is called monotone increasing if F(x) â‰¤F(y) whenever x â‰¤y. F is
called right continuous if F(x) = limnâ†’âˆF(xn) for all x âˆˆRd and every sequence
(xn)nâˆˆN in Rd with x1 â‰¥x2 â‰¥x3 â‰¥. . . and x = limnâ†’âˆxn. By Vd denote the set
of monotone increasing, bounded right continuous functions on Rd.
(i) Show the validity of Hellyâ€™s theorem with V replaced by Vd.
(ii) Conclude that Prohorovâ€™s theorem holds for E = Rd. â™£
13.4
Application: A Fresh Look at de Finettiâ€™s Theorem
(After an idea of GÃ¶tz Kersting.) Let E be a Polish space and let X1, X2, . . . be an
exchangeable sequence of random variables with values in E. As an alternative to
the backwards martingale argument of Sect. 12.3, here we give a different proof of
de Finettiâ€™s theorem (Theorem 12.26). Recall that de Finettiâ€™s theorem states that
there exists a random probability measure Î on E such that, given Î, the random
variables X1, X2, . . . are independent and Î-distributed. For x = (x1, x2, . . .) âˆˆ
EN, let Î¾n(x) := 1
n
n
l=1 Î´xl be the empirical distribution of x1, . . . , xn. Let
Î¼n,k(x) := Î¾n(x)âŠ—k = nâˆ’k
n

i1,...,ik=1
Î´(xi1,...,xik )
be the distribution on Ek that describes k-fold independent sampling with replace-
ment (respecting the order) from (x1, . . . , xn). Let
Î½n,k(x) := (n âˆ’k)!
n!
n

i1,...,ik=1
#{i1,...,ik}=k
Î´(xi1,...,xik )

13.4
Application: A Fresh Look at de Finettiâ€™s Theorem
301
be the distribution on Ek that describes k-fold independent sampling without
replacement (respecting the order) from (x1, . . . , xn). For all x âˆˆEN,
;;Î¼n,k(x) âˆ’Î½n,k(x)
;;
T V â‰¤Rn,k := k(k âˆ’1)
n
.
Indeed, the probability pn,k that we do not see any ball twice when drawing k balls
(with replacement) from n different balls is
pn,k =
kâˆ’1

l=1
(1 âˆ’l/n)
and thus Rn,k â‰¥2(1âˆ’pn,k). We therefore obtain the rather intuitive statement that as
n â†’âˆthe distributions of k-samples with replacement and without replacement,
respectively, become the same:
lim
nâ†’âˆsup
xâˆˆEN
;;Î¼n,k(x) âˆ’Î½n,k(x)
;;
T V = 0.
Now let f1, . . . , fk âˆˆCb(E) and F(x1, . . . , xk) := f1(x1) Â· Â· Â· fk(xk). As the
sequence X1, X2, . . . is exchangeable, for any choice of pairwise distinct numbers
1 â‰¤i1, . . . , ik â‰¤n,
E[F(X1, . . . , Xk)] = E[F(Xi1, . . . , Xik)].
Averaging over all choices i1, . . . , ik, we get
E
)
f1(X1) Â· Â· Â· fk(Xk)
*
= E
)
F(X1, . . . , Xk)
*
= E
' 
F dÎ½n,k(X)
(
.
Hence
E
)
f1(X1) Â· Â· Â· fk(Xk)
*
âˆ’E
' 
f1 dÎ¾n(X) Â· Â· Â·

fk dÎ¾n(X)
(
=
E
' 
F dÎ½n,k(X)
(
âˆ’E
' 
F dÎ¼n,k(X)
(
â‰¤âˆ¥Fâˆ¥âˆRn,k
nâ†’âˆ
âˆ’â†’0.
We will exploit the following criterion for tightness of subsets of M1(M1(E)).
Exercise 13.4.1 Show that a subset K âŠ‚M1(M1(E)) is tight if and only if, for
any Îµ > 0, there exists a compact set K âŠ‚E with the property
Î¼
	
Î¼ âˆˆM1(E) : Î¼(Kc) > Îµ


< Îµ
for all Î¼ âˆˆK.
â™£

302
13
Convergence of Measures
Since E is Polish, PX1 is tight. Hence, for any Îµ > 0, there exists a compact set
K âŠ‚E with P[X1 âˆˆKc] < Îµ2. Therefore,
P[Î¾n(X)(Kc) > Îµ] â‰¤Îµâˆ’1 E[Î¾n(X)(Kc)] = Îµâˆ’1 P[X1 âˆˆKc] â‰¤Îµ.
Hence the family (PÎ¾n(X))nâˆˆN is tight. Let Îâˆbe a random variable (with values
in M1(E)) such that PÎâˆ= w-lim
lâ†’âˆPÎ¾nl (X) for a suitable subsequence (nl)lâˆˆN. The
map Î¾ â†’3 F dÎ¾ = 3 f1 dÎ¾ Â· Â· Â· 3 fk dÎ¾ is bounded and (as a product of continuous
maps) is continuous with respect to the topology of weak convergence on M1(E);
hence it is in Cb(M1(E)). Thus
E
' 
F dÎâŠ—k
âˆ
(
=
lim
lâ†’âˆE
' 
f1 dÎ¾nl(X) Â· Â· Â·

fk dÎ¾nl(X)
(
= E
)
f1(X1) Â· Â· Â· fk(Xk)
*
.
Note that the limit does not depend on the choice of the subsequence and is thus
unique. Summarising, we have
E
)
f1(X1) Â· Â· Â· fk(Xk)
*
= E
' 
f1 dÎâˆÂ· Â· Â·

fk dÎâˆ
(
.
Since the distribution of (X1, . . . , Xk) is uniquely determined by integrals of the
above type, we conclude that P(X1,...,Xk) = PÎâŠ—k
âˆ. In other words, (X1, . . . , Xk) D=
(Y1, . . . , Yk), where, given Îâˆ, the random variables Y1, . . . , Yk are independent
with distribution Îâˆ.
Takeaways Consider an exchangeable family X1, X2, . . . of random vari-
ables. The empirical distributions of the ï¬rst n random variables yield a tight
family which, by Prohorovâ€™s theorem, has a limit point. This approach allows
for an independent proof of de Finettiâ€™s theorem.
Exercise 13.4.2 Show that a family (Xn)nâˆˆN of random variables is exchangeable
if and only if, for every choice of natural numbers 1 â‰¤n1 < n2 < n3 . . ., we have
(X1, X2, . . .) D= (Xn1, Xn2, . . .).
Warning: One of the implications is rather difï¬cult to show. â™£

Chapter 14
Probability Measures on Product Spaces
As a motivation, consider the following example. Let X be a random variable that is
uniformly distributed on [0, 1]. As soon as we know the value of X, we toss n times
a coin that has probability X for a success. Denote the results by Y1, . . . , Yn.
How can we construct a probability space on which all these random variables
are deï¬ned? One possibility is to construct n + 1 independent random variables
Z0, . . . , Zn that are uniformly distributed on [0, 1] (see, e.g., Corollary 2.23 for the
construction). Then deï¬ne X = Z0 and
Yk =
0 1,
if Zk < X,
0,
if Zk â‰¥X.
Intuitively, this ï¬ts well with our idea that the Y1, . . . , Yn are independent as soon
as we know X and record a success with probability X.
In the above description, we have constructed by hand a two-stage experiment.
At the ï¬rst stage, we determine the value of X. At the second stage, depending
on the value of X, the values of Y = (Y1, . . . , Yn) are determined. Clearly, this
construction makes use of the speciï¬c structure of the problem. However, we now
want to develop a systematic framework for the description and construction of
multi-stage experiments. In contrast to Chap. 2, here the random variables need
not be independent. In addition, we also want to construct systematically inï¬nite
families of random variables with given (joint) distributions.
In the ï¬rst section, we start with products of measurable spaces. Then we come
to ï¬nite products of measure spaces and product measures with transition kernels.
Finally, we consider inï¬nite products of probability spaces. The main result is
Kolmogorovâ€™s extension theorem.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_14
303

304
14
Probability Measures on Product Spaces
14.1
Product Spaces
Deï¬nition 14.1 (Product space) Let (Î©i, i âˆˆI) be an arbitrary family of sets.
Denote by Î© = Ã—
iâˆˆI Î©i the set of maps Ï‰ : I â†’
iâˆˆI
Î©i such that Ï‰(i) âˆˆÎ©i
for all i âˆˆI. Î© is called the product of the spaces (Î©i, i âˆˆI), or brieï¬‚y the
product space. If, in particular, all the Î©i are equal, say Î©i = Î©0, then we write
Î© = Ã—
iâˆˆI Î©i = Î©I
0 .
Example 14.2
(i) If Î©1 = {1, . . . , 6} and Î©2 = {1, 2, 3}, then
Î©1 Ã— Î©2 =
	
Ï‰ = (Ï‰1, Ï‰2) : Ï‰1 âˆˆ{1, . . . , 6}, Ï‰2 âˆˆ{1, 2, 3}

.
(ii) If Î©0 = R and I = {1, 2, 3}, then R{1,2,3} is isomorphic to the customary R3.
(iii) If Î©0 = R and I = N, then RN is the space of sequences (Ï‰(n), n âˆˆN) in R.
(iv) If I = R and Î©0 = R, then RR is the set of maps R â†’R. â™¦
Deï¬nition 14.3 (Coordinate maps) If i âˆˆI, then Xi : Î© â†’Î©i, Ï‰ â†’Ï‰(i)
denotes the ith coordinate map. More generally, for J âŠ‚J â€² âŠ‚I, the restricted
map
XJ â€²
J
: Ã—
jâˆˆJ â€²
Î©j âˆ’â†’Ã—
jâˆˆJ
Î©j,
Ï‰â€² â†’Ï‰â€²
J
(14.1)
is called the canonical projection. In particular, we write XJ := XI
J .
Deï¬nition 14.4 (Product-Ïƒ-algebra)
Let (Î©i, Ai), i âˆˆI, be measurable spaces.
The product-Ïƒ-algebra
A =
 
iâˆˆI
Ai
is the smallest Ïƒ-algebra on Î© such that for every i âˆˆI, the coordinate map Xi is
measurable with respect to A â€“ Ai; that is,
A = Ïƒ

Xi, i âˆˆI

:= Ïƒ

Xâˆ’1
i
(Ai), i âˆˆI

.
If (Î©i, Ai) = (Î©0, A0) for all i âˆˆI, then we also write A = AâŠ—I
0 .
For J âŠ‚I, let Î©J := Ã—
jâˆˆJ
Î©j and AJ = /
jâˆˆJ
Aj.
Remark 14.5 The concept of the product-Ïƒ-algebra is similar to that of the product
topology: If ((Î©i, Ï„i), i âˆˆI) are topological spaces, then the product topology Ï„
on Î© = Ã—
iâˆˆI
Î©i is the coarsest topology with respect to which all coordinate maps
Xi : Î© âˆ’â†’Î©i are continuous. â™¦

14.1
Product Spaces
305
Deï¬nition 14.6 Let I Ì¸= âˆ…be an arbitrary index set, let (E, E) be a measurable
space, let (Î©, A) = (EI, EâŠ—I ) and let Xt : Î© â†’E be the coordinate map for
every t âˆˆI. Then the family (Xt)tâˆˆI is called the canonical process on (Î©, A).
Lemma 14.7 Let âˆ…Ì¸= J âŠ‚I. Then XI
J is measurable with respect to AI â€“ AJ .
Proof For any j âˆˆJ, Xj = XJ
j â—¦XI
J is measurable with respect to A â€“ Aj. Thus,
by Corollary 1.82, XI
J is measurable.
âŠ“âŠ”
Theorem 14.8 Let I be countable, and for every i âˆˆI, let (Î©i, Ï„i) be Polish with
Borel Ïƒ-algebra Bi = Ïƒ(Ï„i). Let Ï„ be the product topology on Î© = Ã—
iâˆˆI
Î©i and
B = Ïƒ(Ï„).
Then (Î©, Ï„) is Polish and B = /
iâˆˆI
Bi. In particular, B(Rd) = B(R)âŠ—d for
d âˆˆN.
Proof Without loss of generality, assume I = N. For i âˆˆN, let di be a complete
metric that induces Ï„i. It is easy to check that
d(Ï‰, Ï‰â€²) :=
âˆ

i=1
2âˆ’i
di(Ï‰(i), Ï‰â€²(i))
1 + di(Ï‰(i), Ï‰â€²(i))
(14.2)
is a complete metric on Î© that induces Ï„.
Now for any i âˆˆN, let Di âŠ‚Î©i be a countable dense subset and let yi âˆˆDi be
an arbitrary point. It is easy to see that the set
D =

x âˆˆÃ—
iâˆˆN
Di : xi Ì¸= yi only ï¬nitely often

is a countable dense subset of Î©. Hence Î© is separable and thus Polish.
Now, for any i âˆˆI, let Î²i = {BÎµ(xi) : xi âˆˆDi, Îµ âˆˆQ+} be a countable base of
the topology of Î©i consisting of Îµ-balls. Deï¬ne
Î² :=
âˆ

N=1
 N

i=1
Xâˆ’1
i
(Bi) : B1 âˆˆÎ²1, . . . , BN âˆˆÎ²N

.
Then Î² is a countable base of the topology Ï„; hence any open set A âŠ‚Î© is a
(countable) union of sets in Î² âŠ‚/
iâˆˆN Bi. Hence Ï„ âŠ‚/
iâˆˆN Bi and thus B âŠ‚
/
iâˆˆN Bi.
On the other hand, each Xi is continuous and thus measurable with respect to B
â€“ Bi. Therefore, B âŠƒ/
iâˆˆN Bi.
âŠ“âŠ”
Deï¬nition 14.9 (Cylinder sets) For any i âˆˆI, let Ei âŠ‚Ai be a subclass of the
class of measurable sets.
For any A âˆˆAJ , Xâˆ’1
J (A) âŠ‚Î© is called a cylinder set with base J. The set
of such cylinder sets is denoted by ZJ . In particular, if A = Ã—jâˆˆJ Aj for certain

306
14
Probability Measures on Product Spaces
Aj âˆˆAj, then Xâˆ’1
J (A) is called a rectangular cylinder with base J. The set
of such rectangular cylinders will be denoted by ZR
J . The set of such rectangular
cylinders for which in addition Aj âˆˆEj for all j âˆˆJ holds will be denoted by
ZE,R
J
.
Write
Z =

JâŠ‚I ï¬nite
ZJ ,
(14.3)
and similarly deï¬ne ZR and ZE,R. Further, deï¬ne
ZR
âˆ—=
âˆ

N=1
 N

n=1
An : A1, . . . , AN âˆˆZR

and similarly ZE,R
âˆ—
.
Remark 14.10 Every ZJ is a Ïƒ-algebra, and Z and ZR
âˆ—are algebras. Furthermore,
/
iâˆˆI Ai = Ïƒ(Z). â™¦
Lemma 14.11 If every Ei is a Ï€-system, then ZE,R is a Ï€-system.
Proof This is left as an exercise.
âŠ“âŠ”
Theorem 14.12 For any i âˆˆI, let Ei âŠ‚Ai be a generator of Ai.
(i)
/
jâˆˆJ
Aj = Ïƒ
 Ã—
jâˆˆJ Ej : Ej âˆˆEj âˆª{Î©j}

for every countable J âŠ‚I.
(ii) /
iâˆˆI
Ai = Ïƒ(ZR) = Ïƒ

ZE,R
.
(iii) Let Î¼ be a Ïƒ-ï¬nite measure on A, and assume every Ei is also a Ï€-system.
Furthermore, assume there is a sequence (En)nâˆˆN in ZE,R with En â†‘Î© and
Î¼(En) < âˆfor all n âˆˆN (this condition is satisï¬ed, for example, if Î¼ is ï¬nite
and Î©i âˆˆEi for all i âˆˆI). Then Î¼ is uniquely determined by the values Î¼(A)
for all A âˆˆZE,R.
Proof
(i) Let Aâ€²
J = Ïƒ
Ã—
jâˆˆJ
Ej : Ej âˆˆEj âˆª{Î©j} for every j âˆˆJ

. Note that
Ã—
jâˆˆJ
Ej =

jâˆˆJ
(XJ
j )âˆ’1(Ej) âˆˆAJ ,
hence Aâ€²
J âŠ‚AJ . On the other hand, (XJ
j )âˆ’1(Ej) âˆˆAâ€²
J for all j âˆˆJ and
Ej âˆˆEj. Since Ei is a generator of Ai, we have (XJ
j )âˆ’1(Aj) âˆˆAâ€²
J for all
Aj âˆˆAj, and hence AJ âŠ‚Aâ€²
J .

14.2
Finite Products and Transition Kernels
307
(ii) Evidently, ZE,R âŠ‚ZR âŠ‚A; hence also Ïƒ(ZE,R) âŠ‚Ïƒ(ZR) âŠ‚A. By
Theorem 1.81, we have Ïƒ

ZE,R
{i}

= Ïƒ(Xi) for all i âˆˆI; hence Ïƒ(Xi) âŠ‚
Ïƒ(ZE,R). Therefore, AI âŠ‚Ïƒ(ZE,R).
(iii) By (ii) and Lemma 14.11, ZE,R is a Ï€-system that generates A. Hence, the
claim follows by Lemma 1.42.
âŠ“âŠ”
Reï¬‚ection Find an example that shows that in (iii), we cannot simply drop the
assumption that there exists a sequence En â†‘Î© with Î¼(En) < âˆ. â™ 
Takeaways Consider an arbitrary product of measurable spaces. The product
Ïƒ-algebra is the smallest Ïƒ-algebra such that all coordinate maps are measur-
able. It is also induced by ï¬nite dimensional cylinder sets. For a countable
product of Polish spaces, the Borel Ïƒ-algebra of the product is the product of
the Borel Ïƒ-algebras. In either case, a probability measure on the product is
uniquely determined by its values on cylinder sets.
Exercise 14.1.1 Show that
 
iâˆˆI
Ai =

JâŠ‚I countable
ZJ .
(14.4)
Hint: Show that the right-hand side is a Ïƒ-algebra. â™£
14.2
Finite Products and Transition Kernels
Consider now the situation of ï¬nitely many Ïƒ-ï¬nite measure spaces (Î©i, Ai, Î¼i),
i = 1, . . . , n, where n âˆˆN.
Lemma 14.13 Let A âˆˆA1 âŠ—A2 and let f : Î©1 Ã— Î©2 â†’R be an A1 âŠ—A2-
measurable map. Then, for all ËœÏ‰1 âˆˆÎ©1 and ËœÏ‰2 âˆˆÎ©2,
A ËœÏ‰1 := {Ï‰2 âˆˆÎ©2 : ( ËœÏ‰1, Ï‰2) âˆˆA} âˆˆA2,
A ËœÏ‰2 := {Ï‰1 âˆˆÎ©1 : (Ï‰1, ËœÏ‰2) âˆˆA} âˆˆA1,
f ËœÏ‰1 : Î©2 â†’R,
Ï‰2 â†’f ( ËœÏ‰1, Ï‰2)
is A2-measurable,
f ËœÏ‰2 : Î©1 â†’R,
Ï‰1 â†’f (Ï‰1, ËœÏ‰2)
is A1-measurable.
Proof For ËœÏ‰1, deï¬ne the embedding map i : Î©2 â†’Î©1 Ã— Î©2 by i(Ï‰2) = ( ËœÏ‰1, Ï‰2).
Note that X1 â—¦i is constantly ËœÏ‰1 (and hence A1-measurable), and X2 â—¦i = idÎ©2
(and hence A2-measurable). Thus, by Corollary 1.82, the map i is measurable with

308
14
Probability Measures on Product Spaces
respect to A2 â€“ (A1 âŠ—A2). Hence A ËœÏ‰1 = iâˆ’1(A) âˆˆA2 and f ËœÏ‰1 = f â—¦i is
measurable with respect to A2.
âŠ“âŠ”
The following theorem generalizes Theorem 1.61.
Theorem 14.14 (Finite product measures)
There exists a unique Ïƒ-ï¬nite mea-
sure Î¼ on A := /n
i=1 Ai such that
Î¼(A1 Ã— Â· Â· Â· Ã— An) =
n

i=1
Î¼i(Ai)
for Ai âˆˆAi, i = 1, . . ., n.
(14.5)
n
 
i=1
Î¼i := Î¼1 âŠ—Â· Â· Â· âŠ—Î¼n := Î¼ is called the product measure of the Î¼i.
If all spaces involved equal (Î©0, A0, Î¼0), then we write Î¼âŠ—n
0
:=
n/
i=1
Î¼0.
Proof Let ËœÎ¼ be the restriction of Î¼ to ZR. Evidently, ËœÎ¼(âˆ…) = 0, and it is simple to
check that ËœÎ¼ is Ïƒ-ï¬nite. Let A1, A2, . . . âˆˆZR be pairwise disjoint and let A âˆˆZR
with A âŠ‚âˆ
k=1 Ak. Then, by the monotone convergence theorem,
ËœÎ¼(A) =

Î¼1(dÏ‰1) Â· Â· Â·

Î¼n(dÏ‰n) 1A((Ï‰1, . . . , Ï‰n))
â‰¤

Î¼1(dÏ‰1) Â· Â· Â·

Î¼n(dÏ‰n)
âˆ

k=1
1Ak((Ï‰1, . . . , Ï‰n)) =
âˆ

k=1
ËœÎ¼(Ak).
In particular, if A = A1  A2, one similarly gets ËœÎ¼(A) = ËœÎ¼(A1)+ ËœÎ¼(A2). Hence ËœÎ¼
is a Ïƒ-ï¬nite, additive, Ïƒ-subadditive set function on the semiring ZR with ËœÎ¼(âˆ…) = 0.
By the measure extension theorem (Theorem 1.53), ËœÎ¼ can be uniquely extended to
a Ïƒ-ï¬nite measure on A = Ïƒ(ZR).
âŠ“âŠ”
Example 14.15 For i = 1, . . . , n, let (Î©i, Ai, Pi) be a probability space. On the
space (Î©, A, P) :=
Ã—n
i=1 Î©i, /n
i=1 Ai, /n
i=1 Pi

, the coordinate maps Xi :
Î© â†’Î©i are independent with distribution PXi = Pi. â™¦
In order to formulate Fubiniâ€™s theorem rigorously, we need the following
deï¬nition.
Deï¬nition 14.16 Let (Î©, A, Î¼) a measure space and (Î©â€², Aâ€²) a measurable space.
Let N âˆˆA with Î¼(N) = 0. A map f : Î©\N â†’Î©â€² is called a Î¼-almost everywhere
deï¬ned and measurable map from (Î©, A) to (Î©â€², Aâ€²), if f âˆ’1(Aâ€²) âŠ‚A.
Remark 14.17 Let g, h : Î© â†’R be measurable ï¬nite almost everywhere. Then
g âˆ’h is almost everywhere deï¬ned and measurable. In particular, this holds if g and
h are integrable. â™¦

14.2
Finite Products and Transition Kernels
309
Remark 14.18 Assume that f is almost everywhere deï¬ned and measurable (with
null set N) and takes values in R. Deï¬ne f â€²(Ï‰) = 0 for Ï‰ âˆˆN and f â€²(Ï‰) = f (Ï‰)
else. Then f â€² is measurable (and everywhere deï¬ned). If f â€² is integrable, then we
can deï¬ne the integral
3
f dÎ¼ :=
3
f â€²dÎ¼. â™¦
Theorem 14.19 (Fubini)
Let (Î©i, Ai, Î¼i) be Ïƒ-ï¬nite measure spaces, i = 1, 2.
Let f : Î©1 Ã— Î©2 â†’R be measurable with respect to A1 âŠ—A2. If f â‰¥0 or
f âˆˆL1(Î¼1 âŠ—Î¼2), then
Ï‰1 â†’

f (Ï‰1, Ï‰2) Î¼2(dÏ‰2) is Î¼1-a.e. deï¬ned and A1-measurable,
Ï‰2 â†’

f (Ï‰1, Ï‰2) Î¼1(dÏ‰1) is Î¼2-a.e. deï¬ned and A2-measurable,
(14.6)
and

Î©1Ã—Î©2
f d(Î¼1 âŠ—Î¼2) =

Î©1

Î©2
f (Ï‰1, Ï‰2) Î¼2(dÏ‰2)

Î¼1(dÏ‰1)
=

Î©2

Î©1
f (Ï‰1, Ï‰2) Î¼1(dÏ‰1)

Î¼2(dÏ‰2).
(14.7)
Proof The proof follows the usual procedure of stepwise approximations, starting
with an indicator function.
We ï¬rst show the statement for nonnegative f . There are functions hi : Î©i â†’
(0, âˆ) such that
3
hi dÎ¼i < âˆ, i = 1, 2 (see Lemma 6.23). Now write
f (Ï‰1, Ï‰2) =
f (Ï‰1, Ï‰2)
h1(Ï‰1)h2(Ï‰2) Â· h1(Ï‰1)h2(Ï‰2).
Hence, it is enough to show the statement for the ï¬nite measures ËœÎ¼i := hiÎ¼i instead
of Î¼i, i = 1, 2.
Now assume that Î¼1 and Î¼2 are ï¬nite measures. First let f = 1A for A =
A1 Ã— A2 with A1 âˆˆA1 and A2 âˆˆA2. Then (14.6) and (14.7) hold trivially.
Now consider the set G âŠ‚A1 âŠ—A2 such that A âˆˆG if and only if (14.6)
and (14.7) hold for f = 1A. It is easy to see that G is a Dynkin system. In fact,
Î©1 Ã— Î©2 âˆˆG is trivial. If A âˆˆG and f = 1Î©1Ã—Î©2\A, then clearly
Ï‰i â†’

f (Ï‰1, Ï‰2) Î¼3âˆ’i(dÏ‰3âˆ’i)
= Î¼3âˆ’i(Î©3âˆ’i) âˆ’

1A(Ï‰1, Ï‰2) Î¼3âˆ’i(dÏ‰3âˆ’i) is Ai-measurable,
for i = 1, 2. Similarly, (14.7) holds. Hence, G is stable under complements.

310
14
Probability Measures on Product Spaces
Finally, for pairwise disjoint sets A1, A2, . . . âˆˆG and A := A1 âˆªA2 âˆª. . ., we
have
Ï‰i â†’

1A(Ï‰1, Ï‰2) Î¼3âˆ’i(dÏ‰3âˆ’i)
=
âˆ

n=1

1An(Ï‰1, Ï‰2) Î¼3âˆ’i(dÏ‰3âˆ’i) is Ai-measurable,
for i = 1, 2. Similarly, (14.7) holds for f = 1A. Hence A âˆˆG.
Now, G is a Dynkin system that contains a âˆ©-stable generator of A1âŠ—A2 (namely,
the cylinder sets A1 Ã— A2, A1 âˆˆA1, A2 âˆˆA2). Hence G = A1 âŠ—A2 by Dynkinâ€™s
Ï€-Î» theorem (Theorem 1.19).
We have thus shown that (14.6) and (14.7) hold for f = 1A for all A âˆˆA1 âŠ—A2.
Building ï¬nite sums, (14.6) and (14.7) also hold if f is a simple function.
Consider now f
â‰¥0. Then, by Theorem 1.96, there exists a sequence of
simple functions (fn)nâˆˆN with fn â†‘f . By the monotone convergence theorem
(Theorem 4.20), (14.6) and (14.7) also hold for this f .
Now let f âˆˆL1(Î¼1 âŠ—Î¼2). Then f = f + âˆ’f âˆ’with f +, f âˆ’â‰¥0 being
integrable functions. Since (14.6) and (14.7) hold for f âˆ’and f +, by Remark 14.17
and 14.18 this is true for f also.
âŠ“âŠ”
Reï¬‚ection Come up with an example of a measurable function f such that the
integrals on the right hand side of (14.7) both exist but do not coincide. Which
condition of the theorem would be violated? â™ 
In Deï¬nition 2.32, we deï¬ned the convolution of two real probability measures
Î¼ and Î½ as the distribution of the sum of two independent random variables with
distributions Î¼ and Î½, respectively. As a simple application of Fubiniâ€™s theorem, we
can give a new deï¬nition for the convolution of, more generally, ï¬nite measures on
Rn. Of course, for real probability measures, it coincides with the old deï¬nition. If
the measures have Lebesgue densities, then we obtain an explicit formula for the
density of the convolution.
Let X and Y be Rn-valued random variables with densities fX and fY . That is,
fX, fY : Rn â†’[0, âˆ] are measurable and integrable with respect to n-dimensional
Lebesgue measure Î»n and, for all x âˆˆRn,
P[X â‰¤x] =

(âˆ’âˆ,x]
fX(t) Î»n(dt)
and
P[Y â‰¤x] =

(âˆ’âˆ,x]
fY (t) Î»n(dt).
Here (âˆ’âˆ, x] = {y âˆˆRn : yi â‰¤xi for i = 1, . . . , n} (compare (1.5)).
Deï¬nition 14.20 Let n âˆˆN. For two Lebesgue integrable maps f, g : Rn â†’
[0, âˆ], deï¬ne the convolution f âˆ—g : Rn â†’[0, âˆ] by
(f âˆ—g)(x) =

Rn f (y) g(x âˆ’y) Î»n(dy).

14.2
Finite Products and Transition Kernels
311
For two ï¬nite measures Î¼, Î½ âˆˆMf (Rn), deï¬ne the convolution Î¼ âˆ—Î½ âˆˆMf (Rn)
by
(Î¼ âˆ—Î½)((âˆ’âˆ, x]) =
 
1Ax(u, v) Î¼(du) Î½(dv),
where Ax := {(u, v) âˆˆRn Ã— Rn : u + v â‰¤x}.
Lemma 14.21 The map f âˆ—g is measurable and we have f âˆ—g = g âˆ—f and

Rn(f âˆ—g) dÎ»n =

Rn f dÎ»n
 
Rn g dÎ»n

.
Furthermore, Î¼ âˆ—Î½ = Î½ âˆ—Î¼ and (Î¼ âˆ—Î½)(Rn) = Î¼(Rn) Î½(Rn).
Proof The claims follow immediately from Fubiniâ€™s theorem.
âŠ“âŠ”
Theorem 14.22 (Convolution of n-dimensional measures)
(i) If X and Y are independent Rn-valued random variables with densities fX and
fY , then X + Y has density fX âˆ—fY .
(ii) If Î¼ = f Î»n and Î½ = gÎ»n are ï¬nite measures with Lebesgue densities f and g,
then Î¼ âˆ—Î½ = (f âˆ—g)Î»n.
Proof
(i) Let x âˆˆRn and A := {(u, v) âˆˆRn Ã— Rn : u + v â‰¤x}. Repeated application of
Fubiniâ€™s theorem and the translation invariance of Î»n yields
P[X + Y â‰¤x] = P[(X, Y) âˆˆA]
=

RnÃ—Rn 1A(u, v) fX(u) fY (v)

Î»nâŠ—2 (d(u, v))
=

Rn

Rn 1A(u, v) fX(u) Î»n(du)

fY (v) Î»n(dv)
=

Rn

(âˆ’âˆ,xâˆ’v]
fX(u) Î»n(du)

fY (v) Î»n(dv)
=

Rn

(âˆ’âˆ,x]
fX(u âˆ’v) Î»n(du)

fY (v) Î»n(dv)
=

(âˆ’âˆ,x]

Rn fX(u âˆ’v) fY (v) Î»n(dv)

Î»n(du)
=

(âˆ’âˆ,x]
(fX âˆ—fY ) dÎ»n.
(ii) In (i), replace Î¼ by PX and Î½ by PY . The claim is immediate.
âŠ“âŠ”

312
14
Probability Measures on Product Spaces
We come next to a concept that generalizes the notion of product measures and
points in the direction of the example from the introduction to this chapter.
Recall the deï¬nition of a transition kernel from Deï¬nition 8.25.
Lemma 14.23 Let Îº be a ï¬nite transition kernel from (Î©1, A1) to (Î©2, A2) and let
f : Î©1 Ã— Î©2 â†’[0, âˆ] be measurable with respect to A1 âŠ—A2 âˆ’B([0, âˆ]). Then
the map
If : Î©1 â†’[0, âˆ],
Ï‰1 â†’

f (Ï‰1, Ï‰2) Îº(Ï‰1, dÏ‰2)
is well-deï¬ned and A1-measurable.
Proof By Lemma 14.13, for every Ï‰1 âˆˆÎ©1, the map fÏ‰1 is measurable with respect
to A2; hence If (Ï‰1) =
3
fÏ‰1(Ï‰2) Îº(Ï‰1, dÏ‰2) is well-deï¬ned. Hence, it remains to
show measurability of If .
If g = 1A1Ã—A2 for some A1 âˆˆA1 and A2 âˆˆA2, then clearly Ig(Ï‰1) =
1A1(Ï‰1)Îº(Ï‰1, A2) is measurable. Now let
D = 	A âˆˆA1 âŠ—A2 : I1A is A1-measurable
.
We show that D is a Î»-system:
(i) Evidently, Î©1 Ã— Î©2 âˆˆD.
(ii) If A, B âˆˆD with A âŠ‚B, then I1B\A = I1B âˆ’I1A is measurable, where we
used the fact that Îº is ï¬nite; hence B \ A âˆˆD.
(iii) If A1, A2, . . . âˆˆD are pairwise disjoint and A := âˆ
n=1 An, then I1A =
âˆ
n=1 I1An is measurable; hence A âˆˆD.
Summarising, D is a Î»-system that contains a Ï€-system that generates A1 âŠ—A2
(namely, the rectangles). Hence, by the Ï€â€“Î» theorem (Theorem 1.19), D = A1âŠ—A2.
Hence I1A is measurable for all A âˆˆA1 âŠ—A2. We infer that Ig is measurable for
any simple function g. Now let (fn)nâˆˆN be a sequence of simple functions with
fn â†‘f . For any ï¬xed Ï‰1 âˆˆÎ©1, by the monotone convergence theorem, If (Ï‰1) =
limnâ†’âˆIfn(Ï‰1). As a limit of measurable functions, If is measurable.
âŠ“âŠ”
Remark 14.24 In the following, we often write 3 Îº(Ï‰1, dÏ‰2) f (Ï‰1, Ï‰2) instead of
3 f (Ï‰1, Ï‰2) Îº(Ï‰1, dÏ‰2) since for multiple integrals this notation allows us to write
the integrator closer to the corresponding integral sign. â™¦
Theorem 14.25 Let (Î©i, Ai), i = 0, 1, 2, be measurable spaces. Let Îº1 be a ï¬nite
transition kernel from (Î©0, A0) to (Î©1, A1) and let Îº2 be a ï¬nite transition kernel
from (Î©0 Ã— Î©1, A0 âŠ—A1) to (Î©2, A2). Then the map
Îº1 âŠ—Îº2 : Î©0 Ã— (A1 âŠ—A2) â†’[0, âˆ),
(Ï‰0, A) â†’

Î©1
Îº1(Ï‰0, dÏ‰1)

Î©2
Îº2((Ï‰0, Ï‰1), dÏ‰2) 1A((Ï‰1, Ï‰2))

14.2
Finite Products and Transition Kernels
313
is well-deï¬ned and is a Ïƒ-ï¬nite (but not necessarily a ï¬nite) transition kernel from
(Î©0, A0) to (Î©1 Ã— Î©2, A1 âŠ—A2). If Îº1 and Îº2 are (sub)stochastic, then Îº1 âŠ—Îº2 is
(sub)stochastic. We call Îº1 âŠ—Îº2 the product of Îº1 and Îº2.
If Îº2 is a kernel from (Î©1, A1) to (Î©2, A2), then we deï¬ne the product Îº1 âŠ—Îº2
similarly by formally understanding Îº2 as a kernel from (Î©0 Ã— Î©1, A0 âŠ—A1) to
(Î©2, A2) that does not depend on the Î©0-coordinate.
Proof Let A âˆˆA1 âŠ—A2. By Lemma 14.23, the map
gA : (Ï‰0, Ï‰1) â†’

Îº2((Ï‰0, Ï‰1), dÏ‰2) 1A(Ï‰1, Ï‰2)
is well-deï¬ned and A0 âŠ—A1-measurable. Thus, again by Lemma 14.23, the map
Ï‰0 â†’Îº1 âŠ—Îº2(Ï‰0, A) =

Îº1(Ï‰0, dÏ‰1) gA(Ï‰0, Ï‰1)
is well-deï¬ned and A0-measurable. For ï¬xed Ï‰0, by the monotone convergence
theorem, the map A â†’Îº1 âŠ—Îº2(Ï‰0, A) is Ïƒ-additive and thus a measure.
For Ï‰0 âˆˆÎ©0 and n âˆˆN, let AÏ‰0,n := {Ï‰1 âˆˆÎ©1 : Îº2((Ï‰0, Ï‰1), Î©2) < n}.
Since Îº2 is ï¬nite, we have 
nâ‰¥1 AÏ‰0,n = Î©1 for all Ï‰0 âˆˆÎ©0. Furthermore,
Îº1 âŠ—Îº2(Ï‰0, An Ã— Î©2) â‰¤n Â· Îº1(Ï‰0, An) < âˆ. Hence Îº1 âŠ—Îº2(Ï‰0, Â·) is Ïƒ-ï¬nite and
is thus a transition kernel.
The supplement is trivial.
âŠ“âŠ”
Corollary 14.26 (Products via kernels) Let (Î©1, A1, Î¼) be a ï¬nite measure
space, let (Î©2, A2) be a measurable space and let Îº be a ï¬nite transition kernel from
Î©1 to Î©2. Then there exists a unique Ïƒ-ï¬nite measure Î¼âŠ—Îº on (Î©1Ã—Î©2, A1âŠ—A2)
with
Î¼ âŠ—Îº(A1 Ã— A2) =

A1
Îº(Ï‰1, A2) Î¼(dÏ‰1)
for all A1 âˆˆA1, A2 âˆˆA2.
If Îº is stochastic and if Î¼ is a probability measure, then Î¼ âŠ—Îº is a probability
measure.
Proof Apply Theorem 14.25 with Îº2 = Îº and Îº1(Ï‰0, Â·) = Î¼.
âŠ“âŠ”
Corollary 14.27 Let n âˆˆN and let (Î©i, Ai), i = 0, . . . , n, be measurable spaces.
For i = 1, . . . , n, let Îºi be a substochastic kernel from
 iâˆ’1
Ã—
k=0
Î©k,
iâˆ’1
/
k=0
Ak

to
(Î©i, Ai) or from (Î©iâˆ’1, Aiâˆ’1) to (Î©i, Ai). Then the recursion Îº1 âŠ—Â· Â· Â· âŠ—Îºi :=
(Îº1 âŠ—Â· Â· Â· âŠ—Îºiâˆ’1) âŠ—Îºi for any i = 1, . . . , n deï¬nes a substochastic kernel
i/
k=1
Îºk := Îº1âŠ—Â· Â· Â·âŠ—Îºi from (Î©0, A0) to

iÃ—
k=1
Î©k,
i/
k=1
Ak

. If all Îºk are stochastic,
then all
i/
k=1
Îºk are stochastic.

314
14
Probability Measures on Product Spaces
If Î¼ is a ï¬nite measure on (Î©0, A0), then Î¼i := Î¼âŠ—
i/
k=1
Îºk is a ï¬nite measure on

iÃ—
k=0
Î©k,
i/
k=0
Ak

. If Î¼ is a probability measure and if every Îºi is stochastic, then
Î¼i is a probability measure.
Proof The claims follow inductively by Theorem 14.25.
âŠ“âŠ”
Deï¬nition 14.28 (Composition of kernels) Let (Î©i, Ai) be measurable spaces,
i = 0, 1, 2, and let Îºi be a substochastic kernel from (Î©iâˆ’1, Aiâˆ’1) to (Î©i, Ai),
i = 1, 2. Deï¬ne the composition of Îº1 and Îº2 by
Îº1 Â· Îº2 : Î©0 Ã— A2 â†’[0, âˆ),
(Ï‰0, A2) â†’

Î©1
Îº1(Ï‰0, dÏ‰1) Îº2(Ï‰1, A2).
Theorem 14.29 If we denote by Ï€2 : Î©1 Ã— Î©2 â†’Î©2 the projection to the second
coordinate, then
(Îº1 Â· Îº2)(Ï‰0, A2) = (Îº1 âŠ—Îº2)

Ï‰0, Ï€âˆ’1
2 (A2)

for all A2 âˆˆA2.
In particular, the composition Îº1 Â· Îº2 is a (sub)stochastic kernel from (Î©0, A0) to
(Î©2, A2).
Proof This is obvious.
âŠ“âŠ”
Lemma 14.30 (Kernels and convolution) Let Î¼ and Î½ be probability measures
on Rd and deï¬ne the kernels Îºi : (Rd, B(Rd)) â†’(Rd, B(Rd)), i = 1, 2, by
Îº1(x, dy) = Î¼(dy) and Îº2(y, dz) = (Î´y âˆ—Î½)(dz). Then Îº1 Â· Îº2 = Î¼ âˆ—Î½.
Proof This is trivial.
âŠ“âŠ”
Theorem 14.31 (Kernels and convolution) Assume X1, X2, . . . are independent
Rd-valued random variables with distributions Î¼i := PXi, i = 1, . . . , n. Let Sk :=
X1 + . . . + Xk for k = 1, . . . , n, and deï¬ne stochastic kernels from Rd to Rd by
Îºk(x, Â·) = Î´x âˆ—Î¼k for k = 1, . . . , n. Then
 n
 
k=1
Îºk

(0, Â·) = P(S1,...,Sn).
(14.8)
Proof For k = 1, . . ., n, deï¬ne the measurable bijection Ï•k : (Rd)k â†’(Rd)k by
Ï•k(x1, . . . , xk) = (x1, x1 + x2, . . . , x1 + . . . + xk).

14.2
Finite Products and Transition Kernels
315
Evidently, B((Rd)n) = Ïƒ

Ï•n(A1 Ã— Â· Â· Â· Ã— An) : A1, . . . , An âˆˆB(Rd). Hence, it is
enough to show (14.8) for sets of this type. That is, it is enough to show that

n
 
k=1
Îºk

(0, Ï•n(A1 Ã— Â· Â· Â· Ã— An)) = P(S1,...,Sn)(Ï•n(A1 Ã— Â· Â· Â· Ã— An)) =
n

k=1
Î¼k(Ak).
For n = 1, this is clear. By deï¬nition, Îºn(ynâˆ’1, ynâˆ’1 + An) = Î¼n(An). Inductively,
we get

n
 
k=1
Îºk

(0, Ï•n(A1 Ã— Â· Â· Â· Ã— An))
=

Ï•nâˆ’1(A1Ã—Â·Â·Â·Ã—Anâˆ’1)
 nâˆ’1
 
k=1
Îºk

0, d(y1, . . . , ynâˆ’1)

Îºn

yneâˆ’1, ynâˆ’1 + An

=
 nâˆ’1

k=1
Î¼k(Ak)

Î¼n(An).
âŠ“âŠ”
Theorem 14.32 (Fubini for transition kernels)
Let (Î©i, Ai) be measurable
spaces, i = 1, 2. Let Î¼ be a ï¬nite measure on (Î©1, A1) and let Îº be a ï¬nite
transition kernel from Î©1 to Î©2. Assume that f : Î©1 Ã— Î©2 â†’R is measurable
with respect to A1 âŠ—A2. If f â‰¥0 or f âˆˆL1(Î¼ âŠ—Îº), then

Î©1Ã—Î©2
f d(Î¼ âŠ—Îº) =

Î©1

Î©2
f (Ï‰1, Ï‰2) Îº(Ï‰1, dÏ‰2)

Î¼(dÏ‰1).
(14.9)
Proof For f
=
1A1Ã—A2 with A1
âˆˆ
A1 and A2
âˆˆ
A2, the statement is
true by deï¬nition. For general f , apply the usual approximation argument as in
Theorem 14.19.
âŠ“âŠ”
Example 14.33 We come back to the example from the beginning of this chapter.
Let n âˆˆN and let (Î©2, A2) =

{0, 1}n, (2{0,1})âŠ—n
be the space of n-fold coin
tossing. For any p âˆˆ[0, 1], deï¬ne
Pp = (Berp)âŠ—n =

(1 âˆ’p)Î´0 + pÎ´1
âŠ—n.
Pp is that probability measure on (Î©2, A2) under which the coordinate maps Yi are
independent Bernoulli random variables with success probability p.
Further, let Î©1 = [0, 1], let A1 = B([0, 1]) be the Borel Ïƒ-algebra on Î©1 and let
Î¼ = U[0,1] be the uniform distribution on [0, 1]. Then the identity map X : Î©1 â†’
[0, 1] is a random variable on (Î©1, A1, Î¼) that is uniformly distributed on [0, 1].
Finally, consider the stochastic kernel Îº from Î©1 to Î©2, deï¬ned by
Îº(Ï‰1, A2) = PÏ‰1(A2).

316
14
Probability Measures on Product Spaces
If we let Î© = Î©1 Ã— Î©2, A = A1 âŠ—A2 and P = Î¼ âŠ—Îº, then X and Y1, . . . , Yn
describe precisely the random variables on (Î©, A, P) from the beginning of this
chapter. â™¦
Remark 14.34 The procedure can be extended to n-stage experiments. Let (Î©i, Ai)
be the measurable space of the ith experiment, i = 0, . . . , n âˆ’1. Let P0 be a
probability measure on (Î©0, A0). Assume that for i = 1, . . . , nâˆ’1, the distribution
on (Î©i, Ai) depends on (Ï‰1, . . . , Ï‰iâˆ’1) and is given by a stochastic kernel Îºi from
Î©0 Ã— Â· Â· Â· Ã— Î©iâˆ’1 to Î©i. The whole n-stage experiment is then described by the
coordinate maps on the probability space

nâˆ’1
Ã—
i=0
Î©i,
nâˆ’1
/
i=0
Ai, P0 âŠ—
nâˆ’1
/
i=1
Îºi

. â™¦
Takeaways For ï¬nite products of measurable spaces, we deï¬ne the product
measure. The integral of an integrable function on the product space can be
computed by successive integration (in arbitrary order) over the individual
coordinates (Fubiniâ€™s theorem).
Depending on the outcome of a random experiment, we choose the
distribution of a second random experiment (in a measurable way). The cor-
responding map is called a stochastic kernel. By concatenation of stochastic
kernels we construct multi-step random experiments. This procedure leads to
a generalisation of the concept of a product measure.
Exercise 14.2.1 Show the following convolution formulas.
(i) Normal distribution: NÎ¼1,Ïƒ 2
1 âˆ—NÎ¼2,Ïƒ 2
2 = NÎ¼1+Î¼2,Ïƒ 2
1 +Ïƒ 2
2
for all Î¼1, Î¼2 âˆˆR
and Ïƒ 2
1 , Ïƒ 2
2 > 0.
(ii) Gamma distribution: Î“Î¸,r âˆ—Î“Î¸,s = Î“Î¸,r+s for all Î¸, r, s > 0.
(iii) Cauchy distribution: Caur âˆ—Caus = Caur+s for all r, s > 0. â™£
Exercise 14.2.2 (Hilbertâ€“Schmidt operator) Let (Î©i, Ai, Î¼i), i = 1, 2, be Ïƒ-
ï¬nite measure spaces and let a : Î©1 Ã— Î©2 â†’R be measurable with

Î¼1(dt1)

Î¼2(dt2) a(t1, t2)2 < âˆ.
For f âˆˆL2(Î¼1), deï¬ne
(Af )(t2) =

a(t1, t2)f (t1) Î¼1(dt1).
Show that A is a continuous linear operator from L2(Î¼1) to L2(Î¼2). â™£
Exercise 14.2.3 (Partial integration) Let FÎ¼ and FÎ½ be the distribution functions
of locally ï¬nite measures Î¼ and Î½ on R. For x âˆˆR, deï¬ne the left-sided limit

14.3
Kolmogorovâ€™s Extension Theorem
317
F(xâˆ’) = supy<x F(y) and the jump height Î”F(x) = F(x) âˆ’F(xâˆ’). Show that,
for a < b,

(a,b]
FÎ¼ dÎ½ = FÎ¼(b)FÎ½(b) âˆ’FÎ¼(a)FÎ½(a) âˆ’

(a,b]
FÎ½(xâˆ’)Î¼(dx)
= FÎ¼(b)FÎ½(b) âˆ’FÎ¼(a)FÎ½(a) âˆ’

(a,b]
FÎ½ dÎ¼ +

a<xâ‰¤b
Î”FÎ¼(x) Î”FÎ½(x).
â™£
(14.10)
14.3
Kolmogorovâ€™s Extension Theorem
In the previous section, we saw how we can implement n-stage experiments on
a probability space. In this section, we ï¬rst show how to implement countably
many successive experiments on one probability space (Ionescuâ€“Tulceaâ€™s theorem).
Thereafter we also construct probability measures on products of uncountably many
spaces (Kolmogorovâ€™s extension theorem).
Let (Î©i, Ai), i âˆˆN0, be measurable spaces and let P0 be a probability measure
on (Î©0, A0). Let Î©i := Ã—i
k=0 Î©k and Ai = /i
k=0 Ak and
Î© :=
âˆÃ—
k=0
Î©k
and
A =
âˆ
 
k=0
Ak.
For every i âˆˆN, let Îºi be a stochastic kernel from (Î©iâˆ’1, Aiâˆ’1) to (Î©i, Ai). In
Corollary 14.27, we deï¬ned inductively probability measures Pi = P0 âŠ—/i
k=1 Îºk
on (Î©i, Ai). By construction, for i, j â‰¥k and A âˆˆAk, we had
Pi(A Ã— Î©k+1 Ã— Â· Â· Â· Ã— Î©i) = Pj(A Ã— Î©k+1 Ã— Â· Â· Â· Ã— Î©j).
(14.11)
Now we want to deï¬ne a probability measure P on (Î©, A) such that for k âˆˆN0 and
A âˆˆAk
P

A Ã—
âˆÃ—
i=k+1
Î©i

= Pk(A).
(14.12)
Theorem 14.35 (Ionescuâ€“Tulcea)
There is a uniquely determined probability
measure P on (Î©, A) such that (14.12) holds.
Proof Uniqueness is clear since the ï¬nite-dimensional rectangular cylinders form a
Ï€-system that generates A. It remains to show the existence of that measure.
We use (14.12) to deï¬ne a set function P on cylinder sets. Clearly, P is additive
and is hence a content. If we can show that P is âˆ…-continuous, then P is a

318
14
Probability Measures on Product Spaces
premeasure (by Theorem 1.36) and thus by CarathÃ©odoryâ€™s theorem (Theorem 1.41)
can be extended uniquely to a measure on A.
Hence, let A0 âŠƒA1 âŠƒA2 âŠƒ. . . be a sequence in Z with Î± := infnâˆˆN0 P(An) >
0. It is enough to show that âˆ
n=0 An Ì¸= âˆ…. Without loss of generality, we can assume
that An = Aâ€²
n Ã— Ã—âˆ
k=n+1 Î©k for certain Aâ€²
n âˆˆAn. For n â‰¥m, deï¬ne
hm,n(Ï‰0, . . . , Ï‰m) :=

Î´(Ï‰0,...,Ï‰m) âŠ—
n
 
k=m+1
Îºk


Aâ€²
n

and hm := infnâ‰¥m hm,n. Inductively, we show that for every i âˆˆN0, there exists a
Ï±i âˆˆÎ©i such that
hm(Ï±0, . . . , Ï±m) â‰¥Î±.
(14.13)
Since Aâ€²
n+1 âŠ‚Aâ€²
n Ã— Î©n+1, we have
hm,n+1(Ï‰0, . . . , Ï‰m) =

Î´(Ï‰0,...,Ï‰m) âŠ—
n+1
 
k=m+1
Îºk


Aâ€²
n+1

â‰¤

Î´(Ï‰0,...,Ï‰m) âŠ—
n+1
 
k=m+1
Îºk


Aâ€²
n Ã— Î©n+1

=

Î´(Ï‰0,...,Ï‰m) âŠ—
n
 
k=m+1
Îºk


Aâ€²
n

= hm,n(Ï‰0, . . . , Ï‰m).
Hence hm,n â†“hm for n â†’âˆand by the monotone convergence theorem,

hm dPm = inf
nâ‰¥m

hm,n dPm = inf
nâˆˆN0
Pn(Aâ€²
n) = Î±,
whence we have (14.13) for m = 0. Now assume that (14.13) holds for m âˆˆN0.
Then

hm+1(Ï±0, . . . , Ï±m, Ï‰m+1) Îºm+1

(Ï±0, . . . , Ï±m), dÏ‰m+1

=
inf
nâ‰¥m+1

hm+1,n(Ï±0, . . . , Ï±m, Ï‰m+1) Îºm+1

(Ï±0, . . . , Ï±m), dÏ‰m+1

= hm(Ï±0, . . . , Ï±m) â‰¥Î±.
Hence (14.13) holds for m + 1.

14.3
Kolmogorovâ€™s Extension Theorem
319
Let Ï± := (Ï±0, Ï±1, . . .) âˆˆÎ©. By construction,
Î± â‰¤hm,m(Ï±0, . . . , Ï±m) = 1Aâ€²m(Ï±0, . . . , Ï±m),
hence Ï± âˆˆAm for all m âˆˆN0 and thus âˆ
i=0 Ai Ì¸= âˆ….
âŠ“âŠ”
Corollary 14.36 (Product measure) For every n âˆˆN0, let Pn be a probability
measure on (Î©n, An). Then there exists a uniquely determined probability measure
P on (Î©, A) with
P

A0 Ã— Â· Â· Â· Ã— An Ã—
âˆÃ—
i=n+1
Î©i

=
n

k=0
Pk(Ak)
for Ai âˆˆAi, i = 0, . . . , n and n âˆˆN0.
/âˆ
i=0 Pi := P is called the product of the measures P0, P1, . . .. Under P, the
coordinate maps (Xi)iâˆˆN0 are independent.
Proof This follows by Ionescuâ€“Tulceaâ€™s theorem with Îºi((Ï‰0, . . . , Ï‰iâˆ’1), Â·) = Pi.
âŠ“âŠ”
We want to make a statement similar to that of Ionescuâ€“Tulceaâ€™s theorem;
however, without the assumption that the measures Pk are deï¬ned a priori by
kernels. Before we formulate the theorem, we generalize the consistency condition
(14.11). Recall that for L âŠ‚J âŠ‚I, XJ
L : Î©J âˆ’â†’Î©L denotes the canonical
projection.
Deï¬nition 14.37 A family (PJ , J âŠ‚I ï¬nite) of probability measures on the space
(Î©J, AJ ) is called consistent if
PL = PJ â—¦

XJ
L
âˆ’1
for all L âŠ‚J âŠ‚I ï¬nite.
Recall that Î© = Ã—
iâˆˆI
Î©i and A = /
iâˆˆI
Ai. Let P be a probability measure on
(Î©, A). Since XL = XJ
L â—¦XJ, the family (PJ := P â—¦Xâˆ’1
J , J âŠ‚I ï¬nite) is
consistent. Thus, consistency is a necessary condition for the existence of a measure
P on the product space with PJ := P â—¦Xâˆ’1
J . If all the measurable spaces are Borel
spaces (recall Deï¬nition 8.35), for example Rd, Zd, C([0, 1]) or more general Polish
spaces, then this condition is also sufï¬cient. We formulate this statement ï¬rst for a
countable index set.
Theorem 14.38 Let I be countable and let (Î©i, Ai) be Borel spaces for all i âˆˆI.
Let (PJ , J âŠ‚I ï¬nite) be a consistent family of probability measure. Then there
exists a unique probability measure P on (Î©, A) with PJ = P â—¦Xâˆ’1
J
for all ï¬nite
J âŠ‚I.

320
14
Probability Measures on Product Spaces
Proof Without loss of generality, assume I = N0. Let Pn := P{0,...,n}, Î©n :=
Î©{0,...,n} and An := A{0,...,n}. It is easy to check that ï¬nite products of Borel spaces
are again Borel spaces; hence (Î©n, An) is Borel for all n âˆˆN0.
Let F := {A Ã— Î©n+1 : A âˆˆAn}, Y : Î©n+1 â†’Î©n+1, (Ï‰0, . . . , Ï‰n+1) â†’Ï‰n+1
and Z : Î©n+1 â†’Î©n, (Ï‰0, . . . , Ï‰n+1) â†’(Ï‰0, . . . , Ï‰n). By Theorem 8.37 (with
Î© = Î©n+1, A = An+1 and E = Î©n+1), there is a stochastic kernel Îºâ€²
n+1 from
(Î©n+1, F) to (Î©n+1, An+1) such that Îºâ€²
n+1 is a regular conditional distribution of
Y given F (under the probability measure Pn+1). Hence, for A âˆˆAn and B âˆˆAn+1,
we have (compare (8.11))
Pn+1(A Ã— B) =

1B(Y) 1AÃ—Î©n+1 dPn+1 =

Îºâ€²
n+1( Â·, B) 1AÃ—Î©n+1 dPn+1.
Since Îºâ€²
n+1( Â·, B) is F-measurable, there is a stochastic kernel Îºn+1 from (Î©n, An)
to (Î©n+1, An+1) such that
Îºn+1
(Ï‰0, . . . , Ï‰n), Â· = Îºâ€²
n+1
(Ï‰0, . . . , Ï‰n+1), Â·
for all Ï‰0, . . . , Ï‰n+1.
Hence
Îºâ€²
n+1( Â·, B) = Îºn+1(Z( Â·), B)
and
1AÃ—Î©n+1 = 1A(Z).
We infer that
Pn+1(A Ã— B) =

Îºn+1(Z, B) 1A(Z) dPn+1
=

Îºn+1( Â·, B) 1A d

Pn+1 â—¦Zâˆ’1
=

A
Îºn+1( Â·, B) dPn.
Note that in the last equality we used the fact that (Pn)nâˆˆN0 is a projective family.
By Corollary14.26, we get Pn+1 = Pn âŠ—Îºn+1. Recursively, we obtain Pn = P0 âŠ—
/n
k=1 Îºk for all n âˆˆN. Using Theorem 14.35, this yields the claim.
âŠ“âŠ”
The last step in our construction is to replace the countable index set I by an
arbitrary index set.
Theorem 14.39 (Kolmogorovâ€™s extension theorem) Let I be an arbitrary index
set and let (Î©i, Ai) be Borel spaces, i âˆˆI. Let (PJ , J âŠ‚I ï¬nite) be a consistent
family of probability measures. Then there exists a unique probability measure P on
(Î©, A) with PJ = P â—¦Xâˆ’1
J
for every ï¬nite J âŠ‚I. P is called the projective limit
and will be denoted by P =: lim
â†âˆ’
Jâ†‘I
PJ .

14.3
Kolmogorovâ€™s Extension Theorem
321
Proof For countable J âŠ‚I, by Theorem 14.38, there is a unique probability
measure PJ on (Î©J , AJ ) with PJ â—¦(XJ
K)âˆ’1 = PK for ï¬nite K âŠ‚J. By deï¬ning
ËœPJ (Xâˆ’1
J (AJ )) := PJ (AJ) for AJ âˆˆAJ , we get a probability measure ËœPJ on
(Î©, Ïƒ(XJ)).
Let J, J â€² âŠ‚I be countable and let A âˆˆÏƒ(XJ )âˆ©Ïƒ(XJ â€²)âˆ©Z be a Ïƒ(XJ )âˆ©Ïƒ(XJ â€²)-
measurable cylinder with a ï¬nite base. Then there exists a ï¬nite K âŠ‚J âˆ©J â€² and
AK âˆˆAK with A = Xâˆ’1
K (AK). Hence ËœPJ (A) = PK(AK) = ËœPJ â€²(A). Moreover, by
Theorem 14.12, ËœPJ (A) = PK(AK) = ËœPJ â€²(A) for all A âˆˆÏƒ(XJ ) âˆ©Ïƒ(XJ â€²). Now,
by Exercise 14.1.1, for any A âˆˆA, there is a countable J âŠ‚I with A âˆˆÏƒ(XJ ).
Hence, independently of the choice of J, we can uniquely deï¬ne a set function P on
A by P(A) = ËœPJ (A). It remains to show that P is a probability measure. Evidently,
P(Î©) = 1. If A1, A2, . . . âˆˆA are pairwise disjoint and A := âˆ
n=1 An, then for
any n âˆˆN, there is a countable Jn âŠ‚I with An âˆˆÏƒ(XJn). Deï¬ne J = 
nâˆˆN Jn.
Then each An is in Ïƒ(XJ ); thus A âˆˆÏƒ(XJ ). Therefore,
P(A) = ËœPJ (A) =
âˆ

n=1
ËœPJ (An) =
âˆ

n=1
P(An).
This shows that P is a probability measure.
âŠ“âŠ”
Example 14.40 Let

(Î©i, Ï„i), i âˆˆI

be an arbitrary family of Polish spaces (recall
from Theorem 8.36 that Polish spaces are also Borel spaces). Let Ai = Ïƒ(Ï„i) and
let Pi be an arbitrary probability measure on (Î©i, Ai) for every i âˆˆI. For ï¬nite
J âŠ‚I, let PJ := /
jâˆˆJ Pj be the product measure of the Pj, j âˆˆJ. Evidently, the
family (PJ, J âŠ‚I ï¬nite) is consistent. We call
P =
 
iâˆˆI
Pi := lim
â†âˆ’
Jâ†‘I
PJ
the product measure on (Î©, A). Under P, all coordinate maps Xj are independent.
â™¦
Example 14.41 (PÃ³lyaâ€™s urn model) (Compare Example 12.29.) In an urn there are
initially k red and n âˆ’k blue balls. At each step, one ball is drawn at random and is
returned to the urn with an additional ball of the same color. Hence, at time i âˆˆN0
there are n + i balls in the urn. The random number of red balls is denoted by Xi.
For a more formal description, let n âˆˆN and k âˆˆ{0, . . . , n}. Let I = N0, Î©i =
{0, . . ., n + i}, i âˆˆN. Let P0[{k}] = 1, and deï¬ne the stochastic kernels Îºi from Î©i
to Î©i+1 by
Îºi(xi, {xi+1}) =
â§
âªâªâ¨
âªâªâ©
xi
n+i ,
if xi+1 = xi + 1,
1 âˆ’
xi
n+i ,
if xi+1 = xi,
0,
else.

322
14
Probability Measures on Product Spaces
Now let Pi+1 = Pi âŠ—Îºi. Under the measure P = lim
â†âˆ’
iâ†’âˆ
Pi, the projections (Xi, i âˆˆ
N0) describe PÃ³lyaâ€™s urn model. â™¦
Takeaways Consider an inï¬nite product of Borel measure spaces. A family
of probability measures on all ï¬nite products of these spaces is called pro-
jective if the image measures under projections coincide. By Kolmogorovâ€™s
theorem, for a projective family, there exists a probability measure on the
inï¬nite product space such that the projections coincide with the original
measures we started with. This is a universal construction of a probability
measure on the product space and it allows in a very ï¬‚exible way to construct
the large probability spaces needed for the deï¬nition of stochastic processes.
As a particularly simple application, we get an inï¬nite product measure such
that all coordinate maps are independent with a desired distribution.
14.4
Markov Semigroups
Deï¬nition 14.42 Let E be a Polish space. Let I âŠ‚R be a nonempty index set and
let (Îºs,t : s, t âˆˆI, s < t) be a family of stochastic kernels from E to E. We say
that the family is consistent if Îºr,s Â· Îºs,t = Îºr,t for any choice of r, s, t âˆˆI with
r < s < t.
Deï¬nition 14.43 Let E be a Polish space. Let I âŠ‚[0, âˆ) be an additive semigroup
(for example, I = N0 or I = [0, âˆ)). A family (Îºt : t âˆˆI) of stochastic kernels is
called a semigroup of stochastic kernels, or a Markov semigroup, if
Îº0(Ï‰, Â·) = Î´Ï‰
for all Ï‰ âˆˆE
(14.14)
and if it satisï¬es the Chapmanâ€“Kolmogorov equation:
Îºs Â· Îºt = Îºs+t
for all s, t âˆˆI.
(14.15)
Indeed, ({Îºt : t âˆˆI}, Â·) is a semigroup in the algebraic sense and the map t â†’Îºt
is a homomorphism of semigroups. In particular, the kernels commute in the sense
that Îºs Â· Îºt = Îºt Â· Îºs for all s, t âˆˆI.
Lemma 14.44 If (Îºt : t âˆˆI) is a Markov semigroup, then the family of kernels,
deï¬ned by ËœÎºs,t := Îºtâˆ’s for t > s, is consistent.
Proof This is trivial.
âŠ“âŠ”

14.4
Markov Semigroups
323
Theorem 14.45 (Kernel via a consistent family of kernels) Let I âŠ‚[0, âˆ) with
0 âˆˆI and let (Îºs,t : s, t âˆˆI, s < t) be a consistent family of stochastic kernels on
the Polish space E. Then there exists a kernel Îº from (E, B(E)) to (EI, B(E)âŠ—I)
such that, for all x âˆˆE and for any choice of ï¬nitely many numbers 0 = j0 < j1 <
j2 < . . . < jn from I, and with the notation J := {j0, . . . , jn}, we have
Îº(x, Â·) â—¦Xâˆ’1
J
=

Î´x âŠ—
nâˆ’1
 
k=0
Îºjk,jk+1

.
(14.16)
Proof First we show that, for ï¬xed x âˆˆE, (14.16) deï¬nes a probability measure
Îº(x, Â·). Deï¬ne the family (PJ : J âŠ‚I ï¬nite, 0 âˆˆJ) by PJ := Î´xâŠ—
nâˆ’1
/
k=0
Îºjk,jk+1. By
Kolmogorovâ€™s extension theorem, it is enough to show that this family is consistent.
In fact, if for 0 Ì¸âˆˆJ âŠ‚I ï¬nite, we deï¬ne PJ as the projection of PJâˆª{0} to EJ, then
the family (PJ : J âŠ‚I ï¬nite) is projective. Hence, let 0 âˆˆL âŠ‚J âŠ‚I with J âŠ‚I
ï¬nite. We have to show that PJ â—¦(XJ
L)âˆ’1 = PL. We may assume that L = J \ {jl}
for some l = 1, . . ., n. The general case can be inferred inductively.
First consider l = n. Let Aj0, . . . , Ajnâˆ’1 âˆˆB(E) and A := Ã—jâˆˆL Aj. Then
PJ â—¦(XJ
L)âˆ’1(A) = PJ (A Ã— E) = PL âŠ—Îºjnâˆ’1,jn(A Ã— E)
=

A
PL

d(Ï‰0, . . . , Ï‰nâˆ’1)

Îºjnâˆ’1,jn(Ï‰nâˆ’1, E) = PL(A).
Now let l âˆˆ{1, . . . , n âˆ’1}. For all j âˆˆL, let Aj âˆˆB(E) and Ajl := E. Deï¬ne
A := Ã—jâˆˆL Aj, and abbreviate Aâ€² = Ã—lâˆ’1
k=0 Ajk and P â€² = Î´x âŠ—/lâˆ’2
k=0 Îºjk,jk+1. For
i = 0, . . . , n âˆ’1, let
fi(Ï‰i) =
nâˆ’1
 
k=i
Îºjk,jk+1

(Ï‰i, Aji+1 Ã— Â· Â· Â· Ã— Ajn).
By assumption and using Fubiniâ€™s theorem, we get
flâˆ’1(Ï‰lâˆ’1) =

E
Îºjlâˆ’1,jl(Ï‰lâˆ’1, dÏ‰l)

Ajl+1
Îºjl,jl+1(Ï‰l, dÏ‰l+1) fl+1(Ï‰l+1)
=

Ajl+1
Îºjlâˆ’1,jl+1(Ï‰lâˆ’1, dÏ‰l+1) fl+1(Ï‰l+1).

324
14
Probability Measures on Product Spaces
This implies
PJ â—¦(XJ
L)âˆ’1(A) =

Aâ€² P â€²(d(Ï‰0, . . . , Ï‰lâˆ’1)) flâˆ’1(Ï‰lâˆ’1)
=

Aâ€² P â€²(d(Ï‰0, . . . , Ï‰lâˆ’1))

Ajl+1
Îºjlâˆ’1,jl+1(Ï‰lâˆ’1, dÏ‰l+1) fl+1(Ï‰l+1)
= PL(A).
It remains to show that Îº is a stochastic kernel. That is, we have to show that
x â†’Îº(x, A) is measurable with respect to B(E) â€“ B(E)âŠ—I. By Remark 8.26, it
sufï¬ces to check this for rectangular cylinders with a ï¬nite base A âˆˆZR since ZR
is a Ï€-system that generates B(E)âŠ—I. Hence, let 0 = t0 < t1 < . . . < tn and
B0, . . . , Bn âˆˆB(E) as well as A = n
i=0 Xâˆ’1
ti (Bi). However, by Corollary 14.27,
the following map is measurable,
x â†’Px[A] =

Î´x âŠ—
nâˆ’1
 
i=0
Îºti,ti+1

nÃ—
i=0
Bi

.
âŠ“âŠ”
Corollary 14.46 (Measures by consistent families of kernels) Under the assump-
tions of Theorem 14.45, for every probability measure Î¼ on E, there exists a unique
probability measure PÎ¼ on

EI, B(E)âŠ—I
with the following property: For any
choice of ï¬nitely many numbers 0 = j0 < j1 < j2 < . . . < jn from I, and
letting J := {j0, . . . , jn}, we have PÎ¼ â—¦Xâˆ’1
J
= Î¼ âŠ—/nâˆ’1
k=0 Îºjk,jk+1.
Proof Take PÎ¼ = 3 Î¼(dx) Îº(x, Â·).
âŠ“âŠ”
As a simple conclusion of Lemma 14.44 and Theorem 14.45, we get the following
statement that we formulate separately because it will play a central role later.
Corollary 14.47 (Measures via Markov semigroups) Let (Îºt : t âˆˆI) be a
Markov semigroup on the Polish space E. Then there exists a unique stochastic
kernel Îº from (E, B(E)) to (EI, B(E)âŠ—I) with the property: For all x âˆˆE and for
any choice of ï¬nitely many numbers 0 = t0 < t1 < t2 < . . . < tn from I, and letting
J := {t0, . . . , tn}, we have
Îº(x, Â·) â—¦Xâˆ’1
J
=

Î´x âŠ—
nâˆ’1
 
k=0
Îºtk+1âˆ’tk

.
(14.17)
For any probability measure Î¼ on E, there exists a unique probability measure
PÎ¼ on

EI, B(E)âŠ—I
with the property: For any choice of ï¬nitely many numbers
0 = t0 < t1 < t2 < . . . < tn from I, and letting J := {t0, . . . , tn}, we have
PÎ¼ â—¦Xâˆ’1
J
= Î¼ âŠ—/nâˆ’1
k=0 Îºtk+1âˆ’tk. We denote Px = PÎ´x = Îº(x, Â·) for x âˆˆE.

14.4
Markov Semigroups
325
Example 14.48 (Independent normally distributed increments) Let I = [0, âˆ) and
Î©i = R, i âˆˆ[0, âˆ), equipped with the Borel Ïƒ-algebra B = B(R). Further, let
Î© = R[0,âˆ), A = BâŠ—[0,âˆ) and let Xt be the coordinate map for t âˆˆ[0, âˆ). In the
sense of Deï¬nition 14.6, X = (Xt)tâ‰¥0 is thus the canonical process on (Î©, A).
We construct a probability measure P on (Î©, A) such that the stochastic
process X has independent, stationary, normally distributed increments (recall
Deï¬nition 9.7). That is, it should hold that
(Xti âˆ’Xtiâˆ’1)i=1,...,n is independent
for all 0 =: t0 < t1 < . . . < tn,
(14.18)
PXtâˆ’Xs = N0,tâˆ’s
for all t > s.
(14.19)
To this end, deï¬ne stochastic kernels Îºt(x, dy) := Î´x âˆ—N0,t(dy) for t âˆˆ[0, âˆ)
where N0,0 = Î´0. By Lemma 14.30, the Chapmanâ€“Kolmogorov equation holds
since (compare Exercise 14.2.1(i))
Îºs Â· Îºt(x, dy) = Î´x âˆ—(N0,s âˆ—N0,t)(dy) = Î´x âˆ—N0,s+t(dy) = Îºs+t(x, dy).
Let P0 = Î´0 and let P be the unique probability measure on Î© corresponding to P0
and (Îºt : t â‰¥0) according to Corollary 14.47. By Theorem 14.31, the equations
(14.18) and (14.19) hold.
With (Xt)tâ‰¥0, we have almost constructed the so-called Brownian motion. In
addition to the properties we required here, Brownian motion has continuous paths;
that is, the maps t â†’Xt are almost surely continuous. Note that at this point it is
not even clear that the paths are measurable maps. We will have some work to do to
establish continuity of the paths, and we will come back to this in Chap. 21. â™¦
The construction in the preceding example does not depend on the details of the
normal distribution but only on the validity of the convolution equation
N0,s+t = N0,s âˆ—N0,t.
Hence, in (14.19) we can replace the normal distribution by any parameterized
family of distributions (Î½t, t â‰¥0) with the property Î½t+s = Î½t âˆ—Î½s. Examples
include the Gamma distribution Î½t = Î“Î¸,t (for ï¬xed parameter Î¸ > 0), the Poisson
distribution Î½t = Poit, the negative binomial distribution Î½t = bâˆ’
t,p (for ï¬xed
p âˆˆ(0, 1]), the Cauchy distribution Î½t = Caut and others (compare Theorem 15.13
and Corollary 15.14). We establish the result in a theorem.
Deï¬nition 14.49 (Convolution semigroup) Let I âŠ‚[0, âˆ) be a semigroup. A
family Î½ = (Î½t : t âˆˆI) of probability distributions on Rd is called a convolution
semigroup if Î½s+t = Î½s âˆ—Î½t holds for all s, t âˆˆI.
If I = [0, âˆ) and if in addition Î½t
tâ†’0
âˆ’â†’Î´0, then the convolution semigroup is
called continuous (in the sense of weak convergence).

326
14
Probability Measures on Product Spaces
If d = 1 and Î½t((âˆ’âˆ, 0)) = 0 for all t âˆˆI, then Î½ is called a nonnegative
convolution semigroup.
For the following theorem, compare Deï¬nition 9.7.
Theorem 14.50 For any convolution semigroup (Î½t : t âˆˆI) and any x âˆˆRd, there
exists a probability measure Px on the product space (Î©, A) =

(Rd)I, B(Rd)âŠ—I
such that the canonical process (Xt)tâˆˆI is a stochastic process with Px[X0 = x] =
1, with stationary independent increments and with Px â—¦(Xt âˆ’Xs)âˆ’1 = Î½tâˆ’s
for t > s. On the other hand, every stochastic process (Xt)tâˆˆI (on an arbitrary
probability space (Î©, A, P)) with stationary independent increments deï¬nes a
convolution semigroup by Î½t = P â—¦(Xt âˆ’X0)âˆ’1 for all t âˆˆI.
Takeaways For a Markov process, the conditional distribution at time t given
the full history until some time s < t is a function of the state at time s only
and can be described by a stochastic kernel Îºs,t. On the other hand, if a family
of stochastic kernels Îºs,t, s < t, fulï¬lls the a minimal consistency condition
(the Chapman-Kolmogorov equation), then Kolmogorovâ€™s extension theorem
allows to construct a probability space and a Markov process on it that ï¬ts to
these kernels. Convolution semigroups are a special application and yield real
valued processes with independent and stationary increments.
Exercise 14.4.1 Assume that (Î½t : t â‰¥0) is a continuous convolution semigroup.
Show that Î½t = limsâ†’t Î½s for all t > 0. â™£
Exercise 14.4.2 Assume that (Î½t : t â‰¥0) is a convolution semigroup. Show that
Î½t/n
nâ†’âˆ
âˆ’â†’Î´0. â™£
Exercise 14.4.3 Show that a nonnegative convolution semigroup is continuous. â™£
Exercise 14.4.4 Show that a continuous real convolution semigroup (Î½t : t â‰¥0)
with Î½t((âˆ’âˆ, 0)) = 0 for some t > 0 is nonnegative. â™£
Exercise 14.4.5 Use the methods developed in this section to construct a stochastic
process (Xt)tâ‰¥0 with independent and stationary Poisson-distributed increments.
Furthermore, show that such a process can be constructed in such a way that almost
surely the map t â†’Xt is monotone increasing and right continuous. (Compare
Sect. 5.5.) â™£

Chapter 15
Characteristic Functions and the Central
Limit Theorem
The main goal of this chapter is the central limit theorem (CLT) for sums of
independent random variables (Theorem 15.38) and for independent arrays of
random variables (Lindebergâ€“Feller theorem, Theorem 15.44). For the latter, we
prove only that one of the two implications (Lindebergâ€™s theorem) that is of interest
in the applications.
The ideal tools for the treatment of central limit theorems are so-called char-
acteristic functions; that is, Fourier transforms of probability measures. We start
with a more general treatment of classes of test functions that are suitable to
characterize weak convergence and then study Fourier transforms in greater detail.
The subsequent section proves the CLT for real-valued random variables by means
of characteristic functions. In the ï¬fth section, we prove a multidimensional version
of the CLT.
15.1
Separating Classes of Functions
Let (E, d) be a metric space with Borel Ïƒ-algebra E = B(E).
Denote by C = {u + iv : u, v âˆˆR} the ï¬eld of complex numbers. Let
Re(u + iv) = u
and
Im(u + iv) = v
denote the real part and the imaginary part, respectively, of z = u + iv âˆˆC. Let
z = u âˆ’iv be the complex conjugate of z and |z| =
âˆš
u2 + v2 its modulus. A
prominent role will be played by the complex exponential function exp : C â†’C,
which can be deï¬ned either by Eulerâ€™s formula exp(z) = exp(u)

cos(v) + i sin(v)

or by the power series exp(z) = âˆ
n=0 zn/n!. It is well-known that exp(z1 + z2) =
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_15
327

328
15
Characteristic Functions and the Central Limit Theorem
exp(z1) Â· exp(z2). Note that Re(z) = (z + z)/2 and Im(z) = (z âˆ’z)/2i imply
cos(x) = eix + eâˆ’ix
2
and
sin(x) = eix âˆ’eâˆ’ix
2i
for all x âˆˆR.
A map f : E â†’C is measurable if and only if Re(f ) and Im(f ) are measurable
(see Theorem 1.90 with C âˆ¼= R2). In particular, any continuous function E â†’C is
measurable. If Î¼ âˆˆM(E), then we deï¬ne

f dÎ¼ :=

Re(f ) dÎ¼ + i

Im(f ) dÎ¼
if both integrals exist and are ï¬nite. Let Cb(E; C) denote the Banach space of
continuous, bounded, complex-valued functions on E equipped with the supremum
norm âˆ¥f âˆ¥âˆ= sup{|f (x)| : x âˆˆE}. We call C âŠ‚Cb(E; C) a separating class for
Mf (E) if for any two measures Î¼, Î½ âˆˆMf (E) with Î¼ Ì¸= Î½, there is an f âˆˆC such
that
3
f dÎ¼ Ì¸=
3
f dÎ½. The analogue of Theorem 13.34 holds for C âŠ‚Cb(E; C).
Deï¬nition 15.1 Let K = R or K = C. A subset C âŠ‚Cb(E; K) is called an algebra
if
(i) 1 âˆˆC,
(ii) if f, g âˆˆC, then f Â· g and f + g are in C, and
(iii) if f âˆˆC and Î± âˆˆK, then (Î±f ) is in C.
We say that C separates points if for any two points x, y âˆˆE with x Ì¸= y, there
is an f âˆˆC with f (x) Ì¸= f (y).
Theorem 15.2 (Stoneâ€“WeierstraÃŸ) Let E be a compact Hausdorff space. Let K =
R or K = C. Let C âŠ‚Cb(E; K) be an algebra that separates points. If K = C, then
in addition assume that C is closed under complex conjugation (that is, if f âˆˆC,
then the complex conjugate function f is also in C).
Then C is dense in Cb(E; K) with respect to the supremum norm.
Proof We follow the exposition in DieudonnÃ© [34, Chapter VII.3]. First consider
the case K = R. We proceed in several steps.
Step 1.
By WeierstraÃŸâ€™s approximation theorem (Example 5.15), there is a
sequence (pn)nâˆˆN of polynomials that approach the map [0, 1] â†’[0, 1], t â†’âˆšt
uniformly. If f âˆˆC, then also
|f | = âˆ¥f âˆ¥âˆlim
nâ†’âˆpn

f 2/âˆ¥f âˆ¥2
âˆ

is in the closure C of C in Cb(E; R).
Step 2.
Applying Step 1 to the algebra C yields that, for all f, g âˆˆC,
f âˆ¨g = 1
2(f + g + |f âˆ’g|)
and
f âˆ§g = 1
2(f + g âˆ’|f âˆ’g|)
are also in C.

15.1
Separating Classes of Functions
329
Step 3.
We show that for any f âˆˆCb(E; R), any x âˆˆE and any Îµ > 0, there exists
a gx âˆˆC with gx(x) = f (x) and gx(y) â‰¤f (y) + Îµ for all y âˆˆE. As C separates
points, for any z âˆˆE \ {x}, there exists an Hz âˆˆC with Hz(z) Ì¸= Hz(x) = 0. For
such z, deï¬ne hz âˆˆC by
hz(y) = f (x) + f (z) âˆ’f (x)
Hz(z)
Hz(y)
for all y âˆˆE.
In addition, deï¬ne hx := f . Then hz(x) = f (x) and hz(z) = f (z) for all
z âˆˆE. Since f and hz are continuous, for any z âˆˆE, there exists an open
neighborhood Uz âˆ‹z with hz(y) â‰¤f (y) + Îµ for all y âˆˆUz. We construct
a ï¬nite covering Uz1, . . . , Uzn of E consisting of such neighborhoods and deï¬ne
gx = min(hz1, . . . , hzn). By Step 2, we have gx âˆˆC.
Step 4.
Let f âˆˆCb(E; R), Îµ > 0 and, for any x âˆˆE, let gx be as in Step 3. As
f and gx are continuous, for any x âˆˆE, there exists an open neighborhood Vx âˆ‹x
with gx(y) â‰¥f (y) âˆ’Îµ for any y âˆˆVx. We construct a ï¬nite covering Vx1, . . . , Vxn
of E and deï¬ne g := max(gx1, . . . , gxn). Then g âˆˆC by Step 2 and âˆ¥g âˆ’f âˆ¥âˆ< Îµ
by construction. Letting Îµ â†“0, we get C = Cb(E; R).
Step 5.
Now consider K = C. If f âˆˆC, then by assumption Re(f ) = (f + Â¯f )/2
and Im(f ) = (f âˆ’Â¯f )/2i are in C. In particular, C0 := {Re(f ) : f âˆˆC} âŠ‚C is a real
algebra that, by assumption, separates points and contains the constant functions.
Hence C0 is dense in Cb(E; R). Since C = C0 + iC0, C is dense in Cb(E; C).
âŠ“âŠ”
Corollary 15.3 Let E be a compact metric space. Let K = R or K = C. Let
C âŠ‚Cb(E; K) be a family that separates points; that is, stable under multiplication
and that contains 1. If K = C, then in addition assume that C is closed under
complex conjugation.
Then C is a separating family for Mf (E).
Proof Let Î¼1, Î¼2 âˆˆMf (E) with 3 g dÎ¼1 = 3 g dÎ¼2 for all g âˆˆC. Let Câ€² be the
algebra of ï¬nite linear combinations of elements of C. By linearity of the integral,
3 g dÎ¼1 = 3 g dÎ¼2 for all g âˆˆCâ€².
For any f âˆˆCb(E, R) and any Îµ > 0, by the Stoneâ€“WeierstraÃŸ theorem, there
exists a g âˆˆCâ€² with
;;f âˆ’g
;;
âˆ< Îµ. By the triangle inequality,


f dÎ¼1 âˆ’

f dÎ¼2
 â‰¤


f dÎ¼1 âˆ’

g dÎ¼1
 +


g dÎ¼1 âˆ’

g dÎ¼2

+


g dÎ¼2 âˆ’

f dÎ¼2

â‰¤Îµ (Î¼1(E) + Î¼2(E)).
Letting Îµ
â†“
0, we get equality of the integrals and hence Î¼1
=
Î¼2 (by
Theorem 13.11).
âŠ“âŠ”

330
15
Characteristic Functions and the Central Limit Theorem
Reï¬‚ection In the Stone-WeierstraÃŸ theorem for the case K = C, it is assumed that
the algebra is closed under complex conjugation. Find an example that shows that
this condition cannot be dropped. â™ â™ 
The following theorems are simple consequences of Corollary 15.3.
Theorem 15.4 The distribution of a bounded real random variable X is character-
ized by its moments.
Proof Without loss of generality, we can assume that X takes values in E := [0, 1].
For n âˆˆN, deï¬ne the map fn : [0, 1] â†’[0, 1] by fn : x â†’xn. Further, let f0 â‰¡1.
The family C = {fn, n âˆˆN0} separates points and is closed under multiplication;
hence it is a separating class for Mf (E). Thus PX is uniquely determined by its
moments E[Xn] = 3 xn PX(dx), n âˆˆN.
âŠ“âŠ”
Example 15.5 (due to [73]) In the preceding theorem, we cannot simply drop
the assumption that X is bounded without making other assumptions (see Corol-
lary 15.33). Even if all moments exist, the distribution of X is, in general, not
uniquely determined by its moments. As an example consider X := exp(Y), where
Y âˆ¼N0,1. The distribution of X is called the log-normal distribution. For every
n âˆˆN, nY is distributed as the sum of n2 independent, standard normally distributed
random variables nY D= Y1 + . . . + Yn2. Hence, for n âˆˆN,
E[Xn] = E[enY] = E[eY1+...+Yn2 ] =
n2

i=1
E[eYi] = E[eY]n2
=
 âˆ
âˆ’âˆ
(2Ï€)âˆ’1/2 ey eâˆ’y2/2 dy
n2
= en2/2.
(15.1)
We construct a whole family of distributions with the same moments as X. By the
transformation formula for densities (Theorem 1.101), the distribution of X has the
density
f (x) =
1
âˆš
2Ï€
xâˆ’1 exp

âˆ’1
2 log(x)2

for x > 0.
For Î± âˆˆ[âˆ’1, 1], deï¬ne probability densities fÎ± on (0, âˆ) by
fÎ±(x) = f (x)

1 + Î± sin(2Ï€ log(x))

.
In order to show that fÎ± is a density and has the same moments as f , it is enough to
show that, for all n âˆˆN0,
m(n) :=
 âˆ
0
xn f (x) sin(2Ï€ log(x)) dx = 0.

15.1
Separating Classes of Functions
331
With the substitution y = log(x)âˆ’n, we get (note that sin(2Ï€(y +n)) = sin(2Ï€y))
m(n) =
 âˆ
âˆ’âˆ
eyn+n2(2Ï€)âˆ’1/2 eâˆ’(y+n)2/2 sin(2Ï€(y + n)) dy
= (2Ï€)âˆ’1/2 en2/2
 âˆ
âˆ’âˆ
eâˆ’y2/2 sin(2Ï€y) dy = 0,
where the last equality holds since the integrand is an odd function. â™¦
Theorem 15.6 (Laplace transform) A ï¬nite measure Î¼ on [0, âˆ) is character-
ized by its Laplace transform
LÎ¼(Î») :=

eâˆ’Î»x Î¼(dx)
for Î» â‰¥0.
Proof We face the problem that the space [0, âˆ) is not compact by passing to the
one-point compactiï¬cation E = [0, âˆ]. For Î» â‰¥0, deï¬ne the continuous function
fÎ» : [0, âˆ] â†’[0, 1] by fÎ»(x) = eâˆ’Î»x if x < âˆand fÎ»(âˆ) = limxâ†’âˆeâˆ’Î»x.
Then C = {fÎ», Î» â‰¥0} separates points, f0 = 1 âˆˆC and fÎ¼ Â· fÎ» = fÎ¼+Î» âˆˆ
C. By Corollary 15.3, C is a separating class for Mf ([0, âˆ]) and thus also for
Mf ([0, âˆ)).
âŠ“âŠ”
Remark 15.7 Let X and Y be independent nonnegative random variables with
Laplace transforms LX := LPX and LY := LPY , respectively. Further, let a â‰¥0 and
b â‰¥0. Then we clearly have LaX+b(t) = eâˆ’btLX(at) and LX+Y (t) = LX(t)Â·LY (t)
for t â‰¥0. â™¦
Reï¬‚ection Check the statements of the preceding remark! â™ 
Deï¬nition 15.8 For Î¼ âˆˆMf (Rd), deï¬ne the map Ï•Î¼ : Rd â†’C by
Ï•Î¼(t) :=

eiâŸ¨t,xâŸ©Î¼(dx).
Ï•Î¼ is called the characteristic function of Î¼.
Theorem 15.9 (Characteristic function) A ï¬nite measure Î¼
âˆˆ
Mf (Rd) is
characterized by its characteristic function.
Proof Let Î¼1, Î¼2
âˆˆ
Mf (Rd) with Ï•Î¼1(t)
= Ï•Î¼2(t) for all t
âˆˆ
Rd. By
Theorem 13.11(ii), Cc(Rd) is a separating class for Mf (Rd). Hence, it is enough
to show that
3
f dÎ¼1 =
3
f dÎ¼2 for all f âˆˆCc(Rd).
Let f : Rd â†’R be continuous with compact support and let Îµ > 0. Assume
that K > 0 is large enough such that f (x) = 0 for x Ì¸âˆˆ(âˆ’K/2, K/2)d and such
that Î¼i

Rd \ (âˆ’K, K)d
< Îµ, i = 1, 2. Consider the torus E := Rd/(2KZd) and
deï¬ne Ëœf : E â†’R by
Ëœf

x + 2KZd
= f (x)
for x âˆˆ[âˆ’K, K)d.
Since the support of f is contained in (âˆ’K, K)d, Ëœf is continuous.

332
15
Characteristic Functions and the Central Limit Theorem
For m âˆˆZd deï¬ne
gm : Rd â†’C,
x â†’exp

iâŸ¨Ï€m/K, xâŸ©

.
Let C be the algebra of ï¬nite linear combinations of the gm. For g âˆˆC, we have
g(x) = g(x + 2Kn) for all x âˆˆRd and n âˆˆZd. Hence, the map
Ëœg : E â†’C,
Ëœg(x + 2KZd) = g(x)
is well-deï¬ned, continuous and bounded. Furthermore, ËœC := { Ëœg : g âˆˆC} âŠ‚
Cb(E; C) is an algebra that separates points and is closed under complex conju-
gation. As E is compact, by the Stoneâ€“WeierstraÃŸ theorem, there is a g âˆˆC such
that âˆ¥Ëœg âˆ’Ëœf âˆ¥âˆ< Îµ. We infer
;;(f âˆ’g)1[âˆ’K,K]d
;;
âˆ< Îµ
and
;;(f âˆ’g)1Rd\[âˆ’K,K]d
;;
âˆâ‰¤âˆ¥gâˆ¥âˆ= âˆ¥Ëœgâˆ¥âˆâ‰¤âˆ¥Ëœf âˆ¥âˆ+ Îµ = âˆ¥f âˆ¥âˆ+ Îµ.
By assumption of the theorem,
3
g dÎ¼1 =
3
g dÎ¼2. Hence, using the triangle
inequality, we conclude


f dÎ¼1 âˆ’

f dÎ¼2
 â‰¤

|f âˆ’g| dÎ¼1 +

|f âˆ’g| dÎ¼2
â‰¤Îµ2âˆ¥f âˆ¥âˆ+ 2Îµ + Î¼1(Rd) + Î¼2(Rd).
As Îµ > 0 was arbitrary, the integrals coincide.
âŠ“âŠ”
Corollary 15.10 A ï¬nite measure Î¼ on Zd is uniquely determined by the values
Ï•Î¼(t) =

eiâŸ¨t,xâŸ©Î¼(dx),
t âˆˆ[âˆ’Ï€, Ï€)d.
Proof This is obvious since Ï•Î¼(t + 2Ï€k) = Ï•Î¼(t) for all k âˆˆZd.
âŠ“âŠ”
While the preceding corollary only yields an abstract uniqueness statement, we will
proï¬t also from an explicit inversion formula for Fourier transforms.
Theorem 15.11 (Discrete Fourier inversion formula) Let Î¼ âˆˆMf (Zd) with
characteristic function Ï•Î¼. Then, for every x âˆˆZd,
Î¼({x}) = (2Ï€)âˆ’d

[âˆ’Ï€,Ï€)d eâˆ’iâŸ¨t,xâŸ©Ï•Î¼(t) dt.

15.1
Separating Classes of Functions
333
Proof By the dominated convergence theorem,

[âˆ’Ï€,Ï€)d eâˆ’iâŸ¨t,xâŸ©Ï•Î¼(t) dt =

[âˆ’Ï€,Ï€)d eâˆ’iâŸ¨t,xâŸ©
â›
âlim
nâ†’âˆ

|y|â‰¤n
eiâŸ¨t,yâŸ©Î¼({y})
â
â dt
= lim
nâ†’âˆ

[âˆ’Ï€,Ï€)d eâˆ’iâŸ¨t,xâŸ©
|y|â‰¤n
eiâŸ¨t,yâŸ©Î¼({y}) dt
=

yâˆˆZd
Î¼({y})

[âˆ’Ï€,Ï€)d eiâŸ¨t,yâˆ’xâŸ©dt.
The claim follows since, for y âˆˆZd,

[âˆ’Ï€,Ï€)d eiâŸ¨t,yâˆ’xâŸ©dt =

(2Ï€)d,
if x = y,
0,
else.
âŠ“âŠ”
Similar inversion formulas hold for measures Î¼ on Rd. Particularly simple is
the case where Î¼ possesses an integrable density f :=
dÎ¼
dÎ» with respect to d-
dimensional Lebesgue measure Î». In this case, we have the Fourier inversion
formula,
f (x) = (2Ï€)âˆ’d

Rd eâˆ’iâŸ¨t,xâŸ©Ï•Î¼(t) Î»(dt).
(15.2)
Furthermore, by Plancherelâ€™s theorem, f âˆˆL2(Î») if and only if Ï•Î¼ âˆˆL2(Î»). In this
case, âˆ¥f âˆ¥2 = âˆ¥Ï•âˆ¥2/(2Ï€)d/2.
Since we will not need these statements in the following, we only refer to the
standard literature (e.g., [174, Chapter VI.2] or [54, Theorem XV.3.3 and Equation
(XV.3.8)]).
Takeaways A priori, checking equality of two measures by computing
integrals or checking weak convergence of a sequence of measures requires
to consider a huge class of test functions. The Stone-WeierstraÃŸ theorem and
its corollaries allow to boil down the class of test functions to a tractable
size. In fact, in many cases, it is enough to consider moments, Laplace
transforms or characteristic functions. There is some freedom in the choice
of the class of test functions so it can be adapted to the individual problem.
For example, characteristic functions work well with sums of independent
random variables.

334
15
Characteristic Functions and the Central Limit Theorem
Exercise 15.1.1 Show that, in the Stoneâ€“WeierstraÃŸ theorem, compactness of E is
essential. Hint: Let E = R and use the fact that Cb(R) = Cb(R; R) is not separable.
Construct a countable algebra C âŠ‚Cb(R) that separates points. â™£
Exercise 15.1.2 Let d âˆˆN and let Î¼ be a ï¬nite measure on [0, âˆ)d. Show that Î¼
is characterized by its Laplace transform LÎ¼(Î») =
3
eâˆ’âŸ¨Î»,xâŸ©Î¼(dx), Î» âˆˆ[0, âˆ)d. â™£
Exercise 15.1.3 Let n âˆˆN and let X1, . . . , Xn be i.i.d. exponentially distributed
random variables with parameter 1. Finally, let Y1, . . . , Yn be independent expo-
nentially distributed random variables with PYk = expk. That is, (Y1, . . . , Yn) D=
(X1, X2/2, X3/3, . . . , Xn/n). Show that
max{X1, . . . , Xn} D= Y1 + . . . + Yn.
Hint:
(i) Compute the Laplace transforms LY1, . . . , LYn and use Remark 15.7 to
compute LY1+...+Yn.
(ii) Use the explicit formula for the Laplace transform M := max{X1, . . . , Xn}
from Remark 2.24 to compute the Laplace transform
LM(t) =
n!
(t + 1)(t + 2) Â· Â· Â· (t + n)
for t â‰¥0.
(iii) Use the uniqueness theorem for Laplace transforms.
An alternative strategy of proof is: Sort the values of the Xi by size M = X(1) >
X(2) > . . . > X(n). Check that X(n)
D= Yn. Show that the conditional distribution
L
)
X(1) âˆ’X(n), . . . , X(nâˆ’1) âˆ’X(n)
|X(n)*
does not depend on X(n) and that it
equals the (unconditional) distribution of the ordered values of X1, . . . , Xnâˆ’1. By
an iteration procedure, show the even stronger statement

X(n), X(nâˆ’1), . . . , X(1)
 D=

Yn, Ynâˆ’1 + Yn, . . . , Y1 + Y2 + . . . + Yn

.
We will use this Exercise later in Example 17.27. â™£
Exercise 15.1.4 Show that, under the assumptions of Theorem 15.11, Plancherelâ€™s
equation holds:

xâˆˆZd
Î¼({x})2 = (2Ï€)âˆ’d

[âˆ’Ï€,Ï€)d |Ï•Î¼(t)|2 dt.â™£
Exercise 15.1.5 (Mellin transform)
Let X be a nonnegative real random variable.
For s â‰¥0, deï¬ne the Mellin transform of PX by
mX(s) = E[Xs]
(with values in [0, âˆ]).

15.1
Separating Classes of Functions
335
Assume there is an Îµ0 > 0 with mX(Îµ0) < âˆ(respectively mX(âˆ’Îµ0) < âˆ).
Show that, for any Îµ > 0, the distribution PX is characterized by the values mX(s)
(respectively mX(âˆ’s)), s âˆˆ[0, Îµ].
Hint: For continuous f : [0, âˆ) â†’[0, âˆ), let
Ï†f (z) =
 âˆ
0
tzâˆ’1f (t) dt
for those z âˆˆC for which the integral is well-deï¬ned. By a standard result
of complex analysis if Ï†f (s) < âˆfor an s > 1, then Ï†f is holomorphic in
{z âˆˆC : Re(z) âˆˆ(1, s)} (and is thus uniquely determined by the values Ï†f (r),
r âˆˆ(1, 1 + Îµ) for any Îµ > 0). Furthermore, for all r âˆˆ(1, s),
f (t) =
1
2Ï€ i
 âˆ
âˆ’âˆ
tâˆ’(r+iÏ)Ï†f (r + iÏ) dÏ.
(i) Conclude the statement for X with a continuous density.
(ii) For Î´ > 0, let YÎ´ âˆ¼U[1âˆ’Î´,1] be independent of X. Show that XYÎ´ has a
continuous density.
(iii) Compute mXYÎ´, and show that mXYÎ´ â†’mX for Î´ â†“0.
(iv) Show that XYÎ´ â‡’X for Î´ â†“0. â™£
Exercise 15.1.6 Let X, Y, Z be independent nonnegative random variables such
that P[Z > 0] > 0 and such that the Mellin transform mXZ(s) is ï¬nite for some
s > 0.
Show that if XZ D= YZ holds, then X D= Y. â™£
Exercise 15.1.7 Let Î¼ be a probability measure on R with integrable characteristic
function Ï•Î¼ and hence Ï•Î¼ âˆˆL1(Î»), where Î» is the Lebesgue measure on R. Show
that Î¼ is absolutely continuous with bounded continuous density f = dÎ¼
dÎ» given by
f (x) = 1
2Ï€
 âˆ
âˆ’âˆ
eâˆ’itxÏ•Î¼(t) dt
for all x âˆˆR.
Hint: Show this ï¬rst for the normal distribution N0,Îµ, Îµ > 0. Then show that Î¼âˆ—N0,Îµ
is absolutely continuous with density fÎµ, which converges pointwise to f (as Îµ â†’
0). â™£

336
15
Characteristic Functions and the Central Limit Theorem
Exercise 15.1.8 Let (Î©, Ï„) be a separable topological space that satisï¬es the T3 1
2
separation axiom: For any closed set A âŠ‚Î© and any point x âˆˆÎ© \ A, there exists
a continuous function f : Î© â†’[0, 1] with f (x) = 0 and f (y) = 1 for all y âˆˆA.
(Note in particular that every metric space is a T3 1
2 -space.)
Show that Ïƒ(Cb(Î©)) = B(Î©); that is, the Borel Ïƒ-algebra is generated by the
bounded continuous functions Î© â†’R. â™£
15.2
Characteristic Functions: Examples
Recall that Re(z) is the real part of z âˆˆC. We collect some simple properties of
characteristic functions.
Lemma 15.12 Let X be a random variable with values in Rd and characteristic
function Ï•X(t) = E
)
eiâŸ¨t,XâŸ©*
. Then:
(i) |Ï•X(t)| â‰¤1 for all t âˆˆRd and Ï•X(0) = 1.
(ii) Ï•aX+b(t) = Ï•X(at) eiâŸ¨b,tâŸ©for all a âˆˆR and b âˆˆRd.
(iii) PX = Pâˆ’X if and only if Ï• is real-valued.
(iv) If X and Y are independent, then Ï•X+Y = Ï•X Â· Ï•Y.
(v) 0 â‰¤1 âˆ’Re(Ï•X(2t)) â‰¤4(1 âˆ’Re(Ï•X(t))) for all t âˆˆRd.
Proof
(i) and (ii) are trivial.
(iii) Ï•X(t) = Ï•X(âˆ’t) = Ï•âˆ’X(t).
(iv) As eiâŸ¨t,XâŸ©and eiâŸ¨t,YâŸ©are independent random variables, we have
Ï•X+Y (t) = E
)
eiâŸ¨t,XâŸ©Â· eiâŸ¨t,YâŸ©*
= E
)
eiâŸ¨t,XâŸ©*
E
)
eiâŸ¨t,YâŸ©*
= Ï•X(t) Ï•Y (t).
(v) By the addition theorem for trigonometric functions,
1 âˆ’cos(âŸ¨2t, XâŸ©) = 2

1 âˆ’(cos(âŸ¨t, XâŸ©))2
â‰¤4

1 âˆ’cos(âŸ¨t, XâŸ©)

.
Now take the expectations of both sides.
âŠ“âŠ”
In the next theorem, we collect the characteristic functions for some of the most
important distributions.
Theorem 15.13 (Characteristic functions of some distributions)
For some
distributions P with density x â†’f (x) on R or weights P({k}), k âˆˆN0, we state
the characteristic function Ï•(t) explicitly:

15.2
Characteristic Functions: Examples
337
Distribution
Char. fct.
Name Symbol
Parameter
on
Density / Weights
Ï•(t)
normal NÎ¼,Ïƒ 2
Î¼ âˆˆR Ïƒ 2 > 0
R
1
âˆš
2Ï€Ïƒ 2 exp

âˆ’(xâˆ’Î¼)2
2Ïƒ 2

eiÎ¼t Â· eâˆ’Ïƒ 2t2/2
uniform U[0,a]
a > 0
[0, a]
1/a
eiatâˆ’1
iat
uniform U[âˆ’a,a]
a > 0
[âˆ’a, a]
1/2a
sin(at)
at
triangle Tria
a > 0
[âˆ’a, a]
1
a

1 âˆ’|x|/a
+
2 1âˆ’cos(at)
a2t2
N.N.
a > 0
R
1
Ï€
1âˆ’cos(ax)
ax2
(1 âˆ’|t|/a)+
Gamma Î“Î¸,r
Î¸ > 0 r > 0
[0, âˆ)
Î¸r
Î“ (r) xrâˆ’1 eâˆ’Î¸x
(1 âˆ’it/Î¸)âˆ’r
exponential expÎ¸
Î¸ > 0
0, âˆ)
Î¸ eâˆ’Î¸x
Î¸
Î¸ âˆ’it
two-sided exponential exp2
Î¸
Î¸ > 0
R
Î¸
2 eâˆ’Î¸|x|
1
1 + (t/Î¸)2
Cauchy Caua
a > 0
R
1
aÏ€
1
1 + (x/a)2
eâˆ’a|t|
binomial bn,p
n âˆˆN p âˆˆ[0, 1]
{0, . . . , n}
n
k

pk(1 âˆ’p)nâˆ’k
(1 âˆ’p) + peitn
negative binomial bâˆ’
r,p
r > 0 p âˆˆ(0, 1]
N0
âˆ’r
k

(âˆ’1)kpr(1 âˆ’p)k

p
1 âˆ’(1 âˆ’p)eit
r
Poisson PoiÎ»
Î» > 0
N0
eâˆ’Î» Î»k
k!
exp

Î»(eit âˆ’1)


338
15
Characteristic Functions and the Central Limit Theorem
Proof
(i) (Normal distribution) By Lemma 15.12, it is enough to consider the case
Î¼ = 0 and Ïƒ 2 = 1. By virtue of the differentiation lemma (Theorem 6.28)
and using partial integration, we get
d
dt Ï•(t) =
1
âˆš
2Ï€
 âˆ
âˆ’âˆ
eitx ix eâˆ’x2/2 dx = âˆ’t Ï•(t).
This linear differential equation with initial value Ï•(0) = 1 has the unique
solution Ï•(t) = eâˆ’t2/2.
(ii) (Uniform distribution) This is immediate.
(iii) (Triangle distribution) Note that Tria = U[âˆ’a/2,a/2] âˆ—U[âˆ’a/2,a/2]; hence
Ï•Tria(t) = Ï•U[âˆ’a/2,a/2](t)2 = 4 sin(at/2)2
a2 t2
= 2 1 âˆ’cos(at)
a2 t2
.
Here we used the fact that by the addition theorem for trigonometric functions
1 âˆ’cos(x) = sin(x/2)2 + cos(x/2)2 âˆ’cos(x) = 2 sin(x/2)2.
(iv) (N.N.) This can either be computed directly or can be deduced from (iii) by
using the Fourier inversion formula (equation (15.2)).
(v) (Gamma distribution) Again it sufï¬ces to consider the case Î¸ = 1. For
0 â‰¤b < c â‰¤âˆand t âˆˆR, let Î³b,c,t be the linear path in C from b âˆ’ibt to
c âˆ’ict, let Î´b,t be the linear path from b to b âˆ’ibt and let Ïµc,t be the linear
path from c âˆ’ict to c. Substituting z = (1 âˆ’it)x, we get
Ï•(t) =
1
Î“ (r)
 âˆ
0
xrâˆ’1 eâˆ’x eitx dx = (1 âˆ’it)âˆ’r
Î“ (r)

Î³0,âˆ,t
zrâˆ’1 eâˆ’z dz.
Hence, it sufï¬ces to show that
3
Î³0,âˆ,t zrâˆ’1 exp(âˆ’z) dz = Î“ (r).
The function z â†’zrâˆ’1 exp(âˆ’z) is holomorphic in the right complex
plane. Hence, by the residue theorem for 0 < b < c < âˆ,
 c
b
xrâˆ’1 exp(âˆ’x) dx =

Î³b,c,t
zrâˆ’1 exp(âˆ’z) dz
+

Î´b,t
zrâˆ’1 exp(âˆ’z) dz +

Ïµc,t
zrâˆ’1 exp(âˆ’z) dz.
Recall that
3 âˆ
0
xrâˆ’1 exp(âˆ’x) dx =: Î“ (r). Hence, it is enough to show that
the integrals along Î´b,t and Ïµc,t vanish if b â†’0 and c â†’âˆ.

15.2
Characteristic Functions: Examples
339
However, |zrâˆ’1 exp(âˆ’z)| â‰¤(1 + t2)(râˆ’1)/2 brâˆ’1 exp(âˆ’b) for z âˆˆÎ´b,t. As
the path Î´b,t has length b |t|, we get the estimate


Î´b,t
zrâˆ’1 eâˆ’z dz
 â‰¤br eâˆ’b (1 + t2)r/2 âˆ’â†’0
for b â†’0.
Similarly,


Ïµc,t
zrâˆ’1 eâˆ’z dz
 â‰¤cr eâˆ’c (1 + t2)r/2 âˆ’â†’0
for c â†’âˆ.
(vi) (Exponential distribution) This follows from (v) since expÎ¸ = Î“Î¸,1.
(vii) (Two-sided exponential distribution) If X and Y are independent expÎ¸-
distributed random variables, then it is easy to check that X âˆ’Y âˆ¼exp2
Î¸.
Hence
Ï•exp2
Î¸ (t) = Ï•expÎ¸ (t) Ï•expÎ¸ (âˆ’t) =
1
1 âˆ’it/Î¸
1
1 + it/Î¸ =
1
1 + (t/Î¸)2 .
(viii) (Cauchy distribution) This can either be computed directly using residue
calculus or can be inferred from the statement for the two-sided exponential
distribution by the Fourier inversion formula (equation (15.2)).
(ix) (Binomial distribution) By the binomial theorem,
Ï•(t) =
n

k=0
n
k

(1 âˆ’p)nâˆ’k(peit)k = (1 âˆ’p + peit)n.
(x) (Negative binomial distribution) By the generalized binomial theorem
(Lemma 3.5), for all x âˆˆC with |x| < 1,
(1 âˆ’x)âˆ’r =
âˆ

k=0
âˆ’r
k

(âˆ’x)k.
Using this formula with x = (1 âˆ’p) eit gives the claim.
(xi) (Poisson distribution) Clearly, Ï•PoiÎ»(t) =
âˆ

n=0
eâˆ’Î» (Î»eit)n
n!
= eÎ»(eitâˆ’1).
âŠ“âŠ”
Corollary 15.14 The following convolution formulas hold.
(i) NÎ¼1,Ïƒ 2
1 âˆ—NÎ¼2,Ïƒ 2
2 = NÎ¼1+Î¼2,Ïƒ 2
1 +Ïƒ 2
2 for Î¼1, Î¼2 âˆˆR and Ïƒ 2
1 , Ïƒ 2
2 > 0.
(ii) Î“Î¸,r âˆ—Î“Î¸,s = Î“Î¸,r+s for Î¸, r, s > 0.
(iii) Caua âˆ—Caub = Caua+b for a, b > 0.
(iv) bm,p âˆ—bn,p = bm+n,p for m, n âˆˆN and p âˆˆ[0, 1].

340
15
Characteristic Functions and the Central Limit Theorem
(v) bâˆ’
r,p âˆ—bâˆ’
s,p = bâˆ’
r+s,p for r, s > 0 and p âˆˆ(0, 1].
(vi) PoiÎ» âˆ—PoiÎ¼ = PoiÎ»+Î¼ for Î», Î¼ â‰¥0.
Proof This follows by Theorem 15.13 and by Ï•Î¼âˆ—Î½ = Ï•Î¼ Ï•Î½ (Lemma 15.12).
âŠ“âŠ”
The following theorem gives two simple procedures for calculating the characteris-
tic functions of compound distributions.
Theorem 15.15
(i) Let Î¼1, Î¼2, . . . âˆˆMf (Rd) and let p1, p2, . . . be nonnegative numbers with
âˆ

n=1
pnÎ¼n(Rd) < âˆ. Then the measure Î¼ :=
âˆ

n=1
pnÎ¼n âˆˆMf (Rd) has
characteristic function
Ï•Î¼ =
âˆ

n=1
pn Ï•Î¼n.
(15.3)
(ii) Let N, X1, X2, . . . be independent random variables. Assume X1, X2, . . .
are identically distributed on Rd with characteristic function Ï•X. Assume
N takes values in N0 and has the probability generating function fN. Then
Y :=
N
n=1
Xn has the characteristic function Ï•Y(t) = fN(Ï•X(t)).
(iii) In particular, if we let N âˆ¼PoiÎ» in (ii), then Ï•Y (t) = exp(Î»(Ï•X(t) âˆ’1)).
Proof
(i) Deï¬ne Î½n =
n
k=1
pkÎ¼k. By the linearity of the integral, Ï•Î½n =
n
k=1
pkÏ•Î¼k. By
assumption, Î¼ = w-lim
nâ†’âˆÎ½n; hence also Ï•Î¼(t) = lim
nâ†’âˆÏ•Î½n(t).
(ii) Clearly,
Ï•Y (t) =
âˆ

n=0
P[N = n] E
)
eiâŸ¨t,X1+...+XnâŸ©*
=
âˆ

n=0
P[N = n] Ï•X(t)n = fN(Ï•X(t)).
(iii) In this special case, fN(z) = eÎ»(zâˆ’1) for z âˆˆC with |z| â‰¤1.
âŠ“âŠ”

15.2
Characteristic Functions: Examples
341
Example 15.16 Let n âˆˆN, and assume that the points 0 = a0 < a1 < . . . < an and
1 = y0 > y1 > . . . > yn = 0 are given. Let Ï• : R â†’[0, âˆ) have the properties
that
â€¢
Ï•(ak) = yk for all k = 0, . . . , n and Ï• is linearly interpolated between the points
ak,
â€¢
Ï•(x) = 0 for |x| > an, and
â€¢
Ï• is even (that is, Ï•(x) = Ï•(âˆ’x)).
Assume in addition that the yk are chosen such that Ï• is convex on [0, âˆ). This is
equivalent to the condition that m1 â‰¤m2 â‰¤. . . â‰¤mn â‰¤0, where mk := ykâˆ’ykâˆ’1
akâˆ’akâˆ’1 is
the slope on the kth interval. We want to show that Ï• is the characteristic function
of a probability measure Î¼ âˆˆM1(R).
Deï¬ne pk = ak(mk+1 âˆ’mk) for k = 1, . . . , n.
Let Î¼k
âˆˆM1(R) be the distribution on R with density
1
Ï€
1âˆ’cos(akÏ€)
akx2
. By
Theorem 15.13, Î¼k has the characteristic function Ï•Î¼k(t) =

1 âˆ’|t|
ak
+
. The
characteristic function Ï•Î¼ of Î¼ := n
k=1 pkÎ¼k is then
Ï•Î¼(t) =
n

k=1
pk(1 âˆ’|t|/ak)+.
This is a continuous, symmetric, real function with Ï•Î¼(0) = 1. It is linear on each
of the intervals [akâˆ’1, ak]. See Fig. 15.1 for an example with n = 4. By partial
Ï•(t)
t
y0 = 1
y1
y2
y3
a1
a2
a3
a4
âˆ’a4
âˆ’a3
âˆ’a2
âˆ’a1
Fig. 15.1 The characteristic function Ï• from Example 15.16 with n = 4.

342
15
Characteristic Functions and the Central Limit Theorem
summation, for all k = 1, . . . , n (since mn+1 = 0),
Ï•Î¼(al) =
n

k=1
ak(mk+1 âˆ’mk)

1 âˆ’al
ak
+
=
n

k=l
(ak âˆ’al)(mk+1 âˆ’mk)
=
'
(an âˆ’al)mn+1 âˆ’(al âˆ’al)ml
(
âˆ’
n

k=l+1
(ak âˆ’akâˆ’1)mk
= âˆ’
n

k=l+1
(yk âˆ’ykâˆ’1) = yl = Ï•(al).
Hence Ï•Î¼ = Ï•. â™¦
Example 15.17 Deï¬ne the function Ï• : R â†’[âˆ’1, 1] for t
âˆˆ[âˆ’Ï€, Ï€) by
Ï•(t) = 1 âˆ’2|t|/Ï€, and assume Ï• is periodic (with period 2Ï€). By the discrete
Fourier inversion formula (Theorem 15.11), Ï• is the characteristic function of the
probability measure Î¼ âˆˆM1(Z) with Î¼({x}) = (2Ï€)âˆ’1 3 Ï€
âˆ’Ï€ cos(tx) Ï•(t) dt. In
fact, in order that Î¼ be a measure (not only a signed measure), we still have to show
that all of the masses Î¼({x}) are nonnegative. Clearly, Î¼({0}) = 0. For x âˆˆZ \ {0},
use partial integration to compute the integral,
 Ï€
âˆ’Ï€
cos(tx) Ï•(t) dt = 2
 Ï€
0
cos(tx) (1 âˆ’2t/Ï€) dt
= 4
x

1 âˆ’2
Ï€

sin(Ï€x) âˆ’4
x sin(0) + 4
Ï€x
 Ï€
0
sin(tx) dt
=
4
Ï€x2 (1 âˆ’cos(Ï€x)).
Summing up, we have
Î¼({x}) =

4
Ï€2x2 ,
if x is odd,
0,
else.
Since Î¼(Z) = Ï•(0) = 1, Î¼ is indeed a probability measure. â™¦
Example 15.18 Deï¬ne the function Ïˆ : R â†’[0, 1] for t âˆˆ[âˆ’Ï€/2, Ï€/2) by Ïˆ(t) =
1âˆ’2|t|/Ï€. Assume Ïˆ is periodic with period Ï€. If Ï• is the characteristic function of
the measure Î¼ from the previous example, then clearly Ïˆ(t) = |Ï•(t)|. On the other
hand, Ïˆ(t) = 1
2 + 1
2Ï•(2t). By Theorem 15.15 and Lemma 15.12(ii), we infer that
Ïˆ is the characteristic function of the measure Î½ with Î½(A) = 1
2Î´0(A) + 1
2Î¼(A/2)

15.2
Characteristic Functions: Examples
343
for A âŠ‚R. Hence,
Î½({x}) =
â§
âªâªâ¨
âªâªâ©
1
2,
if x = 0,
8
Ï€2x2 ,
if
x
2 âˆˆZ is odd,
0,
else.
â™¦
Example 15.19 Let Ï•(t) = (1 âˆ’2|t|/Ï€)+ be the characteristic function of the
distribution â€œN.N.â€ from Theorem 15.13 (with a
= Ï€/2) and let Ïˆ be the
characteristic function from the preceding example. Note that Ï•(t) = Ïˆ(t) for
|t| â‰¤Ï€/2 and Ï•(t) = 0 for |t| > Ï€/2; hence Ï•2 = Ï• Â· Ïˆ. Now let X, Y, Z be
independent real random variables with characteristic functions Ï•X = Ï•Y = Ï• and
Ï•Z = Ïˆ. Then Ï•XÏ•Y = Ï•XÏ•Z; hence X + Y D= X + Z. However, the distributions
of Y and Z do not coincide. â™¦
Takeaways In order to compute characteristic functions, in many cases it
is enough to have a table of characteristic functions for some repertoire of
standard distributions and to know how characteristic functions transform
under linear maps and independent sums. We have studied both in this section.
It is of a certain theoretical interest and will be needed later that triangle
functions and sums of triangle functions are characteristic functions.
Exercise 15.2.1 Let Ï• be the characteristic function of the d-dimensional random
variable X. Assume that Ï•(t) = 1 for some t Ì¸= 0. Show that P[X âˆˆHt] = 1, where
Ht = {x âˆˆRd : âŸ¨x, tâŸ©âˆˆ2Ï€Z}
=
	
y + z Â· (2Ï€t/âˆ¥tâˆ¥2
2) : z âˆˆZ, y âˆˆRd with âŸ¨y, tâŸ©= 0

.
Infer that Ï•(t + s) = Ï•(s) for all s âˆˆRd. â™£
Exercise 15.2.2 Show that there are real random variables X, Xâ€² and Y, Y â€² with the
properties (i) X D= Xâ€² and Y D= Y â€², (ii) Xâ€² and Y â€² are independent, (iii) X + Y D=
Xâ€² + Y â€², and (iv) X and Y are not independent. â™£
Exercise 15.2.3 Let X be a real random variable with characteristic function Ï•. X is
called lattice distributed if there are a, d âˆˆR such that P[X âˆˆa + dZ] = 1. Show
that X is lattice distributed if and only if there exists a u Ì¸= 0 such that |Ï•(u)| = 1.
â™£

344
15
Characteristic Functions and the Central Limit Theorem
Exercise 15.2.4 Let X be a real random variable with characteristic function Ï•.
Assume that there is a sequence (tn)nâˆˆN of real numbers such that |tn| â†“0 and
|Ï•(tn)| = 1 for any n. Show that there exists a b âˆˆR such that X = b almost surely.
If in addition, Ï•(tn) = 1 for all n, then X = 0 almost surely. â™£
15.3
LÃ©vyâ€™s Continuity Theorem
The main statement of this section is LÃ©vyâ€™s continuity theorem (Theorem 15.24).
Roughly speaking, it says that a sequence of characteristic functions converges
pointwise to a continuous function if and only if the limiting function is a charac-
teristic function and the corresponding probability measures converge weakly. We
prepare for the proof of this theorem by assembling some analytic tools.
Lemma 15.20 Let Î¼ âˆˆM1(Rd) with characteristic function Ï•. Then
|Ï•(t) âˆ’Ï•(s)|2 â‰¤2

1 âˆ’Re(Ï•(t âˆ’s))

for all s, t âˆˆRd.
Proof By the Cauchyâ€“Schwarz inequality,
|Ï•(t) âˆ’Ï•(s)|2 =


Rd eiâŸ¨t,xâŸ©âˆ’eiâŸ¨s,xâŸ©Î¼(dx)

2
=


Rd

eiâŸ¨tâˆ’s,xâŸ©âˆ’1

eiâŸ¨s,xâŸ©Î¼(dx)

2
â‰¤

Rd
eiâŸ¨tâˆ’s,xâŸ©âˆ’1
2 Î¼(dx) Â·

Rd
eiâŸ¨s,xâŸ©2 Î¼(dx)
=

Rd
eiâŸ¨tâˆ’s,xâŸ©âˆ’1eâˆ’iâŸ¨tâˆ’s,xâŸ©âˆ’1 Î¼(dx)
= 2

1 âˆ’Re(Ï•(t âˆ’s))

.
âŠ“âŠ”
Deï¬nition 15.21 Let (E, d) be a metric space. A family (fi, i âˆˆI) of maps E â†’
R is called uniformly equicontinuous if, for every Îµ > 0, there exists a Î´ > 0 such
that |fi(t) âˆ’fi(s)| < Îµ for all i âˆˆI and all s, t âˆˆE with d(s, t) < Î´.
Theorem 15.22 If F âŠ‚M1(Rd) is a tight family, then {Ï•Î¼ : Î¼ âˆˆF} is uniformly
equicontinuous. In particular, every characteristic function is uniformly continuous.
Proof We have to show that, for every Îµ > 0, there exists a Î´ > 0 such that, for all
t âˆˆRd, all s âˆˆRd with |t âˆ’s| < Î´ and all Î¼ âˆˆF, we have |Ï•Î¼(t) âˆ’Ï•Î¼(s)| < Îµ.

15.3
LÃ©vyâ€™s Continuity Theorem
345
As F is tight, there exists an N âˆˆN with Î¼([âˆ’N, N]d) > 1 âˆ’Îµ2/6 for all
Î¼ âˆˆF. Furthermore, there exists a Î´ > 0 such that, for x âˆˆ[âˆ’N, N]d and u âˆˆRd
with |u| < Î´, we have
1 âˆ’eiâŸ¨u,xâŸ© < Îµ2/6. Hence we get for all Î¼ âˆˆF
1 âˆ’Re(Ï•Î¼(u)) â‰¤

Rd
1 âˆ’eiâŸ¨u,xâŸ© Î¼(dx)
â‰¤Îµ2
3 +

[âˆ’N,N]d
1 âˆ’eiâŸ¨u,xâŸ© Î¼(dx)
â‰¤Îµ2
3 + Îµ2
6 = Îµ2
2 .
Thus, for |t âˆ’s| < Î´ by Lemma 15.20, |Ï•Î¼(t) âˆ’Ï•Î¼(s)| â‰¤Îµ.
âŠ“âŠ”
Lemma 15.23 Let (E, d) be a metric space and let f, f1, f2, . . . be maps E â†’
R with fn
nâ†’âˆ
âˆ’â†’f pointwise. If (fn)nâˆˆN is uniformly equicontinuous, then f is
uniformly continuous and (fn)nâˆˆN converges to f uniformly on compact sets; that
is, for every compact set K âŠ‚E, we have supsâˆˆK |fn(s) âˆ’f (s)|
nâ†’âˆ
âˆ’â†’0.
Proof Fix Îµ > 0, and choose Î´ > 0 such that |fn(t) âˆ’fn(s)| < Îµ for all n âˆˆN and
all s, t âˆˆE with d(s, t) < Î´. For these s, t, we thus have
|f (s) âˆ’f (t)| = lim
nâ†’âˆ|fn(s) âˆ’fn(t)| â‰¤Îµ.
Hence, f is uniformly continuous.
Now let K âŠ‚E be compact. As compact sets are totally bounded, there exists
an N âˆˆN and points t1, . . . , tN âˆˆK with K âŠ‚N
i=1 BÎ´(ti). Choose n0 âˆˆN large
enough that |fn(ti) âˆ’f (ti)| â‰¤Îµ for all i = 1, . . . , N and n â‰¥n0.
Now let s âˆˆK and n â‰¥n0. Choose a ti with d(s, ti) < Î´. Then
|fn(s) âˆ’f (s)| â‰¤|fn(s) âˆ’fn(ti)| + |fn(ti) âˆ’f (ti)| + |f (ti) âˆ’f (s)| â‰¤3Îµ.
As Îµ > 0 was arbitrary, we infer that fn
nâ†’âˆ
âˆ’â†’f uniformly on K.
âŠ“âŠ”
A map f : Rd â†’R is called partially continuous at x = (x1, . . . , xd) if, for
any i = 1, . . . , d, the map yi â†’f (x1, . . . , xiâˆ’1, yi, xi+1, . . . , xd) is continuous at
yi = xi.
Theorem 15.24 (LÃ©vyâ€™s continuity theorem) Let P, P1, P2, . . . âˆˆM1(Rd) with
characteristic functions Ï•, Ï•1, Ï•2, . . ..
(i) If P = w-lim
nâ†’âˆPn, then Ï•n
nâ†’âˆ
âˆ’â†’Ï• uniformly on compact sets.
(ii) If Ï•n
nâ†’âˆ
âˆ’â†’f pointwise for some f : Rd â†’C that is partially continuous at 0,
then there exists a probability measure Q such that Ï•Q = f and Q = w-lim
nâ†’âˆPn.

346
15
Characteristic Functions and the Central Limit Theorem
Proof
(i) By the deï¬nition of weak convergence, we have Ï•n
nâ†’âˆ
âˆ’â†’Ï• pointwise. As the
family (Pn)nâˆˆN is tight, by Theorem 15.22, (Ï•n)nâˆˆN is uniformly equicontinu-
ous. By Lemma 15.23, this implies uniform convergence on compact sets.
(ii) By Theorem 13.34, it is enough to show that the sequence (Pn)nâˆˆN is tight.
For this purpose, it sufï¬ces to show that, for every k = 1, . . . , n, the sequence
(P k
n )nâˆˆN of kth marginal distributions is tight. (Here P k
n := Pn â—¦Ï€âˆ’1
k , where
Ï€k : Rd â†’R is the projection on the kth coordinate.) Let ek be the kth unit
vector in Rd. Then Ï•P kn (t) = Ï•n(t ek) is the characteristic function of P k
n . By
assumption, Ï•P kn
nâ†’âˆ
âˆ’â†’fk pointwise for some function fk that is continuous at
0. We have thus reduced the problem to the one-dimensional situation and will
henceforth assume d = 1.
As Ï•n(0) = 1 for all n âˆˆN, we have f (0) = 1. Deï¬ne the map h :
R â†’[0, âˆ) by h(x) = 1 âˆ’sin(x)/x for x Ì¸= 0 and h(0) = 0. Clearly, h is
continuously differentiable on R. It is easy to see that Î± := inf{h(x) : |x| â‰¥
1} = 1 âˆ’sin(1) > 0. Now, for K > 0, compute (using Markovâ€™s inequality
and Fubiniâ€™s theorem)
Pn

[âˆ’K, K]c
â‰¤Î±âˆ’1

[âˆ’K,K]c h(x/K) Pn(dx)
â‰¤Î±âˆ’1

R
h(x/K) Pn(dx)
= Î±âˆ’1

R
  1
0
1 âˆ’cos(tx/K) dt

Pn(dx)
= Î±âˆ’1
 1
0
 
R

1 âˆ’cos(tx/K)

Pn(dx)

dt
= Î±âˆ’1
 1
0

1 âˆ’Re(Ï•n(t/K))

dt.
Using dominated convergence, we conclude that
lim sup
nâ†’âˆ
Pn([âˆ’K, K]c) â‰¤Î±âˆ’1 lim sup
nâ†’âˆ
 1
0

1 âˆ’Re(Ï•n(t/K))

dt
= Î±âˆ’1
 1
0

lim
nâ†’âˆ

1 âˆ’Re(Ï•n(t/K))

dt
= Î±âˆ’1
 1
0

1 âˆ’Re(f (t/K))

dt.
As f is continuous and f (0) = 1, the last integral converges to 0 for K â†’âˆ.
Hence (Pn)nâˆˆN is tight.
âŠ“âŠ”

15.3
LÃ©vyâ€™s Continuity Theorem
347
Reï¬‚ection Find an example of a pointwise convergent sequence of characteristic
functions (Ï•n) such that the limiting function Ï• is not continuous (at 0). â™ 
Applying LÃ©vyâ€™s continuity theorem to Example 15.16, we get a theorem of PÃ³lya.
Theorem 15.25 (PÃ³lya) Let f : R â†’[0, 1] be continuous and even with f (0) =
1. Assume that f is convex on [0, âˆ). Then f is the characteristic function of a
probability measure.
Proof Deï¬ne fn by fn(k/n) := f (k/n) for k = 0, . . . , n2, and assume fn is
linearly interpolated between these points. Furthermore, let fn be constant to the
right of n and for x < 0, deï¬ne fn(x) = fn(âˆ’x). This is an approximation of f on
[0, âˆ) by convex and piecewise linear functions. By Example 15.16, every fn is a
characteristic function of a probability measure Î¼n. Clearly, fn
nâ†’âˆ
âˆ’â†’f pointwise;
hence f is the characteristic function of a probability measure Î¼ = w-lim
nâ†’âˆÎ¼n on R.
âŠ“âŠ”
Corollary 15.26 For every Î± âˆˆ(0, 1] and r > 0, Ï•Î±,r(t) = eâˆ’|r t|Î± is the
characteristic function of a symmetric probability measure Î¼Î±,r on R.
Remark 15.27 In fact, Ï•Î±,r is a characteristic function for every Î± âˆˆ(0, 2] (Î± = 2
corresponds to the normal distribution), see Sect. 16.2. The distributions Î¼Î±,r are
the so-called Î±-stable distributions (see Deï¬nition 16.20): If X1, X2, . . . , Xn are
independent and Î¼Î±,a-distributed, then Ï•X1+...+Xn(t) = Ï•X(t)n = Ï•X(n1/Î± t);
hence X1 + . . . + Xn
D= n1/Î±X1. â™¦
The Stoneâ€“WeierstraÃŸ theorem implies that a characteristic function determines a
probability distribution uniquely. PÃ³lyaâ€™s theorem gives a sufï¬cient condition for
a symmetric real function to be a characteristic function. Clearly, that condition
is not necessary, as, for example, the normal distribution does not fulï¬ll it. For
general education we present Bochnerâ€™s theorem that formulates a necessary and
sufï¬cient condition for a function Ï• : Rd â†’C to be the characteristic function of a
probability measure.
Deï¬nition 15.28 A function f : Rd â†’C is called positive semideï¬nite if, for all
n âˆˆN, all t1, . . . , tn âˆˆRd and all y1, . . . , yn âˆˆC, we have
n

k,l=1
yk Â¯yl f (tk âˆ’tl) â‰¥0,
in other words, if the matrix (f (tk âˆ’tl))k,l=1,...,n is positive semideï¬nite.
Lemma 15.29 If Î¼ âˆˆMf (Rd) has characteristic function Ï•, then Ï• is positive
semideï¬nite.

348
15
Characteristic Functions and the Central Limit Theorem
Proof We have
n

k,l=1
yk Â¯yl Ï•(tk âˆ’tl) =
n

k,l=1
yk Â¯yl

eix(tkâˆ’tl) Î¼(dx)
=

n

k,l=1
yk eixtk yl eixtl Î¼(dx)
=
 
n

k=1
yk eixtk

2
Î¼(dx) â‰¥0.
âŠ“âŠ”
In the case d = 1, the following theorem goes back to Bochner (1932).
Theorem 15.30 (Bochner) A continuous function Ï• : Rd â†’C is the charac-
teristic function of a probability distribution on Rd if and only if Ï• is positive
semideï¬nite and Ï•(0) = 1.
The statement still holds if Rd is replaced by a locally compact Abelian group.
Proof For the case d = 1 see [19, Â§20, Theorem 23] or [54, Chapter XIX.2, page
622]. For the general case, see, e.g., [71, page 293, Theorem 33.3].
âŠ“âŠ”
Takeaways In order to check weak convergence of a sequence of probability
measures, it is enough to show tightness and pointwise convergence of the
characteristic functions. If the limiting function is continuous at 0, then by
Levyâ€™s theorem, tightness and hence weak convergence are automatic.
Exercise 15.3.1 (Compare [50] and [4]) Show that there exist two exchangeable
sequences X
= (Xn)nâˆˆN and Y
= (Yn)nâˆˆN of real random variables with
PX Ì¸= PY but such that
n

k=1
Xk
D=
n

k=1
Yk
for all n âˆˆN.
(15.4)
Hint:
(i) Deï¬ne the characteristic functions (see Theorem 15.13) Ï•1(t) =
1
1+t2 and
Ï•2(t) = (1 âˆ’t/2)+. Use PÃ³lyaâ€™s theorem to show that
Ïˆ1(t) :=

Ï•1(t),
if |t| â‰¤1,
Ï•2(t),
if |t| > 1,

15.4
Characteristic Functions and Moments
349
and
Ïˆ2(t) :=

Ï•2(t),
if |t| â‰¤1,
Ï•1(t),
if |t| > 1,
are characteristic functions of probability distributions on R.
(ii) Deï¬ne independent random variables Xn,i, Yn,i, n âˆˆN, i = 1, 2, and Î˜n,
n âˆˆN such that Xn,i has characteristic function Ï•i, Yn,i has characteristic
function Ïˆi and P[Î˜n = 1] = P[Î˜n = âˆ’1] = 1
2. Deï¬ne Xn = Xn,Î˜n and
Yn = Yn,Î˜n. Show that (15.4) holds.
(iii) Determine E[ei t1X1+i t2X2] and E[eit1Y1+it2Y2] for t1 = 1
2 and t2 = 2. Conclude
that (X1, X2) Ì¸D= (Y1, Y2) and thus PX Ì¸= PY . â™£
Exercise 15.3.2 Show that for any Î´ > 0 and Îµ > 0, there is a C < âˆsuch that
for any Î¼ âˆˆM1(R) with characteristic function Ï•, we have
Î¼([âˆ’Î´, Î´]c) â‰¤C
 Îµ
0
(1 âˆ’Re(Ï•(t))) dt.
For ÎµÎ´ â‰¤3 one can choose C = 12/Î´2Îµ3. Hint: Proceed as in the proof of LÃ©vyâ€™s
continuity theorem. â™£
Exercise 15.3.3 Let (Î¼n)nâˆˆN be a sequence of probability measures on R and
denote by (Ï•n)nâˆˆN the corresponding characteristic functions. Assume that we have
Ï•n(t)
nâ†’âˆ
âˆ’â†’
1 for t in a neighborhood of 0. Use Exercise 15.3.2 to show that
Î¼n
nâ†’âˆ
âˆ’â†’Î´0. â™£
Exercise 15.3.4 (Continuity theorem for Laplace transforms) Let (Î¼n)nâˆˆN be a
sequence of probability measures on [0, âˆ) and let
Ïˆn(t) =

eâˆ’txÎ¼n(dx)
for t â‰¥0,
n âˆˆN
be the Laplace transforms. We assume that there exists a map Ïˆ : [0, âˆ) â†’[0, 1]
that is continuous in 0 and such that Ïˆn
nâ†’âˆ
âˆ’â†’Ïˆ pointwise.
Show that Ïˆ is the Laplace transform of a probability measure Î¼ on [0, âˆ) and
that Î¼n
nâ†’âˆ
âˆ’â†’Î¼ weakly. â™£
15.4
Characteristic Functions and Moments
We want to study the connection between the moments of a real random variable X
and the derivatives of its characteristic function Ï•X. We start with a simple lemma.

350
15
Characteristic Functions and the Central Limit Theorem
Lemma 15.31 For t âˆˆR and n âˆˆN, we have
eit âˆ’1 âˆ’it
1! âˆ’. . . âˆ’(it)nâˆ’1
(n âˆ’1)!
 â‰¤|t|n
n! .
Proof As the nth derivative of eit has modulus 1, this follows by Taylorâ€™s formula.
âŠ“âŠ”
Theorem 15.32 (Moments and differentiability) Let X be a real random variable
with characteristic function Ï•.
(i) If E[|X|n] < âˆ, then Ï• is n-times continuously differentiable with derivatives
Ï•(k)(t) = E
)
(iX)k eitX*
for k = 0, . . . , n.
(ii) In particular, if E[X2] < âˆ, then
Ï•(t) = 1 + it E[X] âˆ’1
2t2 E[X2] + Îµ(t) t2
with Îµ(t) â†’0 for t â†’0.
(iii) Let h âˆˆR. If lim
nâ†’âˆ
|h|nE[|X|n]
n!
= 0, then, for every t âˆˆR,
Ï•(t + h) =
âˆ

k=0
(ih)k
k! E
'
eitXXk(
.
In particular, this holds if E
)
e|hX|*
< âˆ.
Proof
(i) For t âˆˆR, h âˆˆR \ {0} and k âˆˆ{1, . . . , n}, deï¬ne
Yk(t, h, x) = k! hâˆ’k eitx

eihx âˆ’
kâˆ’1

l=0
(ihx)l
l!

.
Then
E[Yk(t, h, X)] = k! hâˆ’k

Ï•(t + h) âˆ’Ï•(t) âˆ’
kâˆ’1

l=1
E)eitX(iX)l* hl
l!

.
If the limit Ï•k(t) := limhâ†’0 E[Yk(t, h, X)] exists, then Ï• is k-times differen-
tiable at t with Ï•(k)(t) = Ï•k(t).
However (by Lemma 15.31 with n = k + 1), Yk(t, h, x)
hâ†’0
âˆ’â†’(ix)keitx
for all x âˆˆR and (by Lemma 15.31 with n = k) |Yk(t, h, x)| â‰¤|x|k. As

15.4
Characteristic Functions and Moments
351
E[|X|k] < âˆby assumption, the dominated convergence theorem implies
E[Yk(t, h, X)]
hâ†’0
âˆ’â†’E[(iX)keitX] = Ï•(k)(t).
Applying the continuity lemma (Theorem 6.27) yields that Ï•(k) is continuous.
(ii) This is a direct consequence of (i).
(iii) By assumption,
Ï•(t + h) âˆ’
nâˆ’1

k=0
(ih)k
k! E
)
eitXXk*
 = |h|n
n!
E[Yn(t, h, X)]

â‰¤|h|n E[|X|n]
n!
nâ†’âˆ
âˆ’â†’0.
âŠ“âŠ”
Corollary 15.33 (Method of moments) Let X be a real random variable with
Î± := lim sup
nâ†’âˆ
1
n E
)
|X|n*1/n < âˆ.
Then the characteristic function Ï• of X is analytic and the distribution of X is
uniquely determined by the moments E[Xn], n âˆˆN. In particular, this holds if
E)et|X|* < âˆfor some t > 0.
Proof By Stirlingâ€™s formula,
lim
nâ†’âˆ
1
n! nn eâˆ’n âˆš
2Ï€ n = 1.
Thus, for |h| < 1/(3Î±),
lim sup
nâ†’âˆ
E
)
|X|n*
Â· |h|n/n! = lim sup
nâ†’âˆ
(2Ï€ n)âˆ’1/2 
E
)
|X|n*1/n Â· |h| Â· e/n
n
â‰¤lim sup
nâ†’âˆ
(2Ï€ n)âˆ’1/2 (e/3)n = 0.
Hence the characteristic function can be expanded about any point t âˆˆR in a power
series with radius of convergence at least 1/(3Î±). In particular, it is analytic and is
hence determined by the coefï¬cients of its power series about t = 0; that is, by the
moments of X.
âŠ“âŠ”

352
15
Characteristic Functions and the Central Limit Theorem
Example 15.34
(i) Let X âˆ¼NÎ¼,Ïƒ 2. Then, for every t âˆˆR,
E
)
etX*
=

2Ï€Ïƒ 2âˆ’1/2
 âˆ
âˆ’âˆ
etxeâˆ’(xâˆ’Î¼)2/2Ïƒ 2 dx
= eÎ¼t+t2Ïƒ 2/2
2Ï€Ïƒ 2âˆ’1/2
 âˆ
âˆ’âˆ
eâˆ’(xâˆ’Î¼âˆ’tÏƒ 2)2/2Ïƒ 2 dx
= eÎ¼t+t2Ïƒ 2/2 < âˆ.
Hence the distribution of X is characterized by its moments. The characteristic
function Ï•(t) = eiÎ¼t eâˆ’Ïƒ 2t2/2 that we get by the above calculation with t
replaced by it is indeed analytic. (ii) Let X be exponentially distributed with
parameter Î¸ > 0. Then, for t âˆˆ(0, Î¸),
E
)
etX*
= Î¸
 âˆ
0
etx eâˆ’Î¸x dx =
Î¸
Î¸ âˆ’t < âˆ.
Hence the distribution of X is characterized by its moments. The above
calculation with t replaced by it yields Ï•(t) = Î¸/(Î¸ âˆ’it), and this function
is indeed analytic. The fact that in the complex plane Ï• has a singularity at
t = âˆ’iÎ¸ implies that the power series of Ï• about 0 has radius of convergence
Î¸. In particular, this implies that not all exponential moments are ï¬nite. This is
reï¬‚ected by the above calculation that shows that, for t â‰¥Î¸, the exponential
moments are inï¬nite.
(iii) Let X be log-normally distributed (see Example 15.5). Then E[Xn] = en2/2.
In particular, here Î± = âˆ. In fact, in Example 15.5, we saw that here the
moments do not determine the distribution of X.
(iv) If X takes values in N0 and if Î² := lim supnâ†’âˆE[Xn]1/n < 1, then
by Hadamardâ€™s criterion ÏˆX(z) := âˆ
k=1 P[X = k] zk < âˆfor |z| <
1/Î². In particular, the probability generating function X is characterized by
its derivatives Ïˆ(n)
X (1), n âˆˆN, and thus by the moments of X. Compare
Theorem 3.2(iii). â™¦
Theorem 15.35 Let X be a real random variable and let Ï• be its characteristic
function. Let n âˆˆN, and assume that Ï• is 2n-times differentiable at 0 with derivative
Ï•(2n)(0). Then E[X2n] = (âˆ’1)n Ï•(2n)(0) < âˆ.
Proof We carry out the proof by induction on n âˆˆN0. For n = 0, the claim
is trivially true. Now, let n âˆˆN, and assume Ï• is 2n-times (not necessarily
continuously) differentiable at 0. Deï¬ne u(t) = Re(Ï•(t)). Then u is also 2n-times
differentiable at 0 and u(2kâˆ’1)(0) = 0 for k = 1, . . . , n since u is even. Since
Ï•(2n)(0) exists, Ï•(2nâˆ’1) is continuous at 0 and Ï•(2nâˆ’1)(t) exists for all t âˆˆ(âˆ’Îµ, Îµ)
for some Îµ > 0. Furthermore, Ï•(k) exists in (âˆ’Îµ, Îµ) and is continuous on (âˆ’Îµ, Îµ) for

15.4
Characteristic Functions and Moments
353
any k = 0, . . . , 2n âˆ’2. By Taylorâ€™s formula, for every t âˆˆ(âˆ’Îµ, Îµ),
u(t) âˆ’
nâˆ’1

k=0
u(2k)(0) t2k
(2k)!
 â‰¤
|t|2nâˆ’1
(2n âˆ’1)!
sup
Î¸âˆˆ(0,1]
u(2nâˆ’1)(Î¸t)
 .
(15.5)
Deï¬ne a continuous function fn : R â†’[0, âˆ) by fn(0) = 1 and
fn(x) = (âˆ’1)n (2n)! xâˆ’2n
-
cos(x) âˆ’
nâˆ’1

k=0
(âˆ’1)k x2k
(2k)!
.
for x Ì¸= 0.
By the induction hypothesis, E[X2k] = (âˆ’1)k u(2k)(0) for all k = 1, . . . , n âˆ’1.
Using (15.5), we infer
E)fn(tX) X2n* â‰¤2n
|t|
sup
Î¸âˆˆ(0,1]
|u(2nâˆ’1)(Î¸t)| â‰¤gn(t) := 2n
sup
Î¸âˆˆ(0,1]
|u(2nâˆ’1)(Î¸t)|
Î¸ |t|
.
Now Fatouâ€™s lemma implies
E)X2n* = E)fn(0)X2n* â‰¤lim inf
tâ†’0 E)fn(tX)X2n*
â‰¤lim inf
tâ†’0 gn(t) = 2n
u(2n)(0)
 < âˆ.
By Theorem 15.32, this implies E[X2n] = (âˆ’1)n u(2n)(0) = (âˆ’1)n Ï•(2n)(0).
âŠ“âŠ”
Remark 15.36 For odd moments, the statement of the theorem may fail (see, e.g.,
Exercise 15.4.4 for the ï¬rst moment). Indeed, Ï• is differentiable at 0 with derivative
i m for some m âˆˆR if and only if x P[|X| > x]
xâ†’âˆ
âˆ’â†’0 and E[X 1{|X|â‰¤x}]
xâ†’âˆ
âˆ’â†’m.
(See [54, Chapter XVII.2a, page 565].) â™¦
Takeaways A random variable with ï¬nite nth moment possesses a character-
istic function that is n-times differentiable. The moments can be read off from
the derivatives at 0. If all moments exist and do not grow too quickly, then the
moments determine the distribution.
Exercise 15.4.1 Let X and Y be nonnegative random variables with
lim sup
nâ†’âˆ
1
nE[|X|n]1/n < âˆ,
lim sup
nâ†’âˆ
1
nE[|Y|n]1/n < âˆ,

354
15
Characteristic Functions and the Central Limit Theorem
and
E[Xm Y n] = E[Xm] E[Y n]
for all m, n âˆˆN0.
Show that X and Y are independent.
Hint:
Consider the random variable Y with respect to the probability measure
XmP[ Â·]/E[Xm], and use Corollary 15.33 to show that
E[Xm 1A(Y)]/E[Xm] = P[Y âˆˆA]
for all A âˆˆB(R) and m âˆˆN0.
Now apply Corollary 15.33 to the random variable X with respect to the probability
measure P[ Â· |Y âˆˆA]. â™£
Exercise 15.4.2 Let r, s > 0 and let Z âˆ¼Î“1,r+s and B âˆ¼Î²r,s be independent (see
Example 1.107). Use Exercise 15.4.1 to show that the random variables X := BZ
and Y := (1 âˆ’B)Z are independent with X âˆ¼Î“1,r and Y âˆ¼Î“1,s. â™£
Exercise 15.4.3 Show that, for Î± > 2, the function Ï†Î±(t) = eâˆ’|t|Î± is not a
characteristic function.
(Hint: Assume the contrary and show that the corresponding random variable would
have variance zero.) â™£
Exercise 15.4.4 Let X1, X2, . . . be i.i.d. real random variables with characteristic
function Ï•. Show the following.
(i) If Ï• is differentiable at 0, then Ï•â€²(0) = i m for some m âˆˆR.
(ii) Ï• is differentiable at 0 with Ï•â€²(0) = i m if and only if (X1+. . .+Xn)/n
nâ†’âˆ
âˆ’â†’
m in probability.
(iii) Assume that Ï• is differentiable at 0 and that X1 â‰¥0 almost surely. Then
E[X1] = âˆ’i Ï•â€²(0) < âˆ. Hint: Use (ii) and the law of large numbers.
(iv) The distribution of X1 can be chosen such that Ï• is differentiable at 0 but
E[|X1|] = âˆ. â™£
Exercise 15.4.5 Let X1, X2, . . . be real random variables. For r > 0 let Mr(Xn) =
E[|Xn|r] be the rth absolute moment. For k âˆˆN let mk(Xn) = E[Xk
n] be the kth
moment if Mk(Xn) < âˆ.
(i) Assume that X is a real random variable and that (Xnl)lâˆˆN is a subsequence
such that
PXnl
lâ†’âˆ
âˆ’â†’PX weakly.
Assume further that there is an r > 0 such that supnâˆˆN Mr(Xn) < âˆ. Show
that for any k âˆˆN âˆ©(0, r) and s âˆˆ(0, r) we have Ms(X) < âˆas well as
Ms(Xnl)
lâ†’âˆ
âˆ’â†’Ms(X)
and
mk(Xnl)
lâ†’âˆ
âˆ’â†’mk(X).

15.4
Characteristic Functions and Moments
355
(ii) Assume that for any k âˆˆN the limit
mk := lim
nâ†’âˆmk(Xn)
exists and is ï¬nite (note that ï¬nitely many of the mk(Xn) may be undeï¬ned for
any k.) Show that there exists a real random variable X with mk = mk(X) for
all k âˆˆN and a subsequence (Xnl)lâˆˆN such that
PXnl
lâ†’âˆ
âˆ’â†’PX weakly.
(iii) Show the theorem of FrÃ©chetâ€“Shohat: If in (ii) the distribution of X is
determined by its moments mk(X), k âˆˆN (see Corollary 15.33), then
PXn
nâ†’âˆ
âˆ’â†’PX weakly.
â™£
Exercise 15.4.6 Let X1, X2, . . . be i.i.d. real random variables with E[X1] = 0 and
E[|X1|k] < âˆfor all k âˆˆN.
(i) Show that there exist ï¬nite numbers (dk)kâˆˆN (depending on the distribution
PX1) such that for any k, n âˆˆN we have
E
)
(X1 + . . . + Xn)2kâˆ’1* â‰¤d2kâˆ’1 nkâˆ’1
and
E
)
(X1 + . . . + Xn)2k*
âˆ’(2k)!
2k k! E
)
X2
1
*k nk â‰¤d2k nkâˆ’1.
Hint: Expand the bracket expression, sort the terms by the different mixed
moments and compute by combinatorial means the number of each type of
summand. The number of summands of the type E[X2
l1 Â· Â· Â· X2
lk] (for different
l1, . . . , lk) is of particular importance.
(ii) Let Y âˆ¼N0,1. Use Theorem 15.32(i) to show that for any k âˆˆN we have
E
)
Y 2kâˆ’1*
= 0
and
E
)
Y 2k*
= (2k)!
2k k! .
(iii) Let Sâˆ—
n = (X1 + . . . + Xn)/âˆšn Var[X1]. Use Exercise 15.4.5 to infer the
statement of the central limit theorem (compare Theorem 15.38)
PSâˆ—n
nâ†’âˆ
âˆ’â†’N0,1 weakly.
â™£

356
15
Characteristic Functions and the Central Limit Theorem
15.5
The Central Limit Theorem
In the strong law of large numbers, we saw that, for large n, the order of magnitude
of the sum Sn = X1 + . . .+ Xn of i.i.d. integrable random variables is n Â· E[X1]. Of
course, for any n, the actual value of Sn will sometimes be smaller than nÂ·E[X1] and
sometimes larger. In the central limit theorem (CLT), we study the size and shape
of the typical ï¬‚uctuations around n Â· E[X1] in the case where the Xi have a ï¬nite
variance.
We prepare for the proof of the CLT with a lemma.
Lemma 15.37 Let X1, X2, . . . be i.i.d. real random variables with E[X1] = Î¼ and
Var[X1] = Ïƒ 2 âˆˆ(0, âˆ). Let
Sâˆ—
n :=
1
âˆš
nÏƒ 2
n

k=1
(Xk âˆ’Î¼)
be the normalized nth partial sum. Then
lim
nâ†’âˆÏ•Sâˆ—n(t) = eâˆ’t2/2
for all t âˆˆR.
Proof Let Ï• = Ï•Xkâˆ’Î¼. Then, by Theorem 15.32(ii),
Ï•(t) = 1 âˆ’Ïƒ 2
2 t2 + Îµ(t) t2,
where the error term Îµ(t) goes to 0 if t â†’0. By Lemma 15.12(iv) and (ii),
Ï•Sâˆ—n(t) = Ï•

t
âˆš
nÏƒ 2
n
.
Now

1 âˆ’t2
2n
n nâ†’âˆ
âˆ’â†’eâˆ’t2/2 and


1 âˆ’t2
2n
n
âˆ’Ï•

t
âˆš
nÏƒ 2
n  â‰¤n
1 âˆ’t2
2n âˆ’Ï•

t
âˆš
nÏƒ 2
 
â‰¤n t2
nÏƒ 2
Îµ

t
âˆš
nÏƒ 2

nâ†’âˆ
âˆ’â†’0.
(Note that |un âˆ’vn| â‰¤|u âˆ’v| Â· n Â· max(|u|, |v|)nâˆ’1 for all u, v âˆˆC.)
âŠ“âŠ”

15.5
The Central Limit Theorem
357
Theorem 15.38 (Central limit theorem (CLT)) Let X1, X2, . . . be i.i.d. real
random variables with Î¼ := E[X1] âˆˆR and Ïƒ 2 := Var[X1] âˆˆ(0, âˆ). For n âˆˆN,
let Sâˆ—
n :=
1
âˆš
Ïƒ 2n
n
i=1(Xi âˆ’Î¼). Then
PSâˆ—n
nâ†’âˆ
âˆ’â†’N0,1 weakly.
For âˆ’âˆâ‰¤a < b â‰¤+âˆ, we have
lim
nâ†’âˆP[Sâˆ—
n âˆˆ[a, b]] =
1
âˆš
2Ï€
3 b
a eâˆ’x2/2 dx.
Proof By Lemma 15.37 and LÃ©vyâ€™s continuity theorem (Theorem 15.24),

PSâˆ—n

converges to the distribution with characteristic function Ï•(t)
= eâˆ’t2/2. By
Theorem 15.13(i), this is N0,1. The additional claim follows by the Portemanteau
theorem (Theorem 13.16) since N0,1 has a density; hence N0,1(âˆ‚[a, b]) = 0.
âŠ“âŠ”
Remark 15.39 If we prefer to avoid the continuity theorem, we could argue as
follows: For every K > 0 and n âˆˆN, we have P[|Sâˆ—
n| > K] â‰¤Var[Sâˆ—
n]/K2 =
1/K2; hence the sequence

PSâˆ—n

is tight. As characteristic functions determine
distributions, the claim follows by Theorem 13.34. â™¦
We want to weaken the assumption in Theorem 15.38 that the random variables
are identically distributed. In fact, we can even take a different set of summands
for every n. The essential assumptions are that the summands are independent,
each summand contributes only a little to the sum and the sum is centered and has
variance 1.
Deï¬nition 15.40 For every n âˆˆN, let kn âˆˆN and let Xn,1, . . . , Xn,kn be real
random variables. We say that (Xn,l) =

Xn,l, l = 1, . . . , kn, n âˆˆN

is an array
of random variables. Its row sum is denoted by Sn = Xn,1 + . . . + Xn,kn. The array
is called
â€¢
independent if, for every n âˆˆN, the family (Xn,l)l=1,...,kn is independent,
â€¢
centered if Xn,l âˆˆL1(P) and E[Xn,l] = 0 for all n and l, and
â€¢
normed if Xn,l âˆˆL2(P) and
kn

l=1
Var[Xn,l] = 1 for all n âˆˆN.
A centered array is called a null array if its individual components are asymptoti-
cally negligible in the sense that, for all Îµ > 0,
lim
nâ†’âˆmax
1â‰¤lâ‰¤kn
P[|Xn,l| > Îµ] = 0.
Deï¬nition 15.41 A centered array of random variables (Xn,l) with Xn,l âˆˆL2(P)
for every n âˆˆN and l = 1, . . . , kn is said to satisfy the Lindeberg condition if, for
all Îµ > 0,
Ln(Îµ) :=
1
Var[Sn]
kn

l=1
E
'
X2
n,l 1
X2
n,l> Îµ2 Var[Sn]
( nâ†’âˆ
âˆ’â†’0.
(15.6)

358
15
Characteristic Functions and the Central Limit Theorem
The array fulï¬lls the Lyapunov condition if there exists a Î´ > 0 such that
lim
nâ†’âˆ
1
Var[Sn]1+(Î´/2)
kn

l=1
E)|Xn,l|2+Î´* = 0.
(15.7)
Lemma 15.42 The Lyapunov condition implies the Lindeberg condition.
Proof For x âˆˆR, we have x2 1{|x|>Îµâ€²} â‰¤(Îµâ€²)âˆ’Î´ |x|2+Î´ 1{|x|>Îµâ€²} â‰¤(Îµâ€²)âˆ’Î´ |x|2+Î´.
Letting Îµâ€² := ÎµâˆšVar[Sn], we get
Ln(Îµ) â‰¤Îµâˆ’Î´
1
Var[Sn]1+(Î´/2)
kn

l=1
E
)
|Xn,l|2+Î´*
.
âŠ“âŠ”
Example 15.43 Let (Yn)nâˆˆN be i.i.d. with E[Yn] = 0 and Var[Yn] = 1. Let
kn = n and Xn,l =
Yl
âˆšn. Then (Xn,l) is independent, centered and normed. Clearly,
P[|Xn,l| > Îµ] = P[|Y1| > âˆšÎµn ]
nâ†’âˆ
âˆ’â†’0; hence (Xn,l) is a null array. Furthermore,
Ln(Îµ) = E)Y 2
1 1{|Y1|>Îµâˆšn}
* nâ†’âˆ
âˆ’â†’0; hence (Xn,l) satisï¬es the Lindeberg condition.
If Y1 âˆˆL2+Î´(P) for some Î´ > 0, then
n

l=1
E
)
|Xn,l|2+Î´*
= nâˆ’(Î´/2) E
)
|Y1|2+Î´* nâ†’âˆ
âˆ’â†’0.
In this case, (Xn,l) also satisï¬es the Lyapunov condition. â™¦
The following theorem is due to Lindeberg (1922, see [108]) for the implication
(i) â‡’(ii) and is attributed to Feller (1935 and 1937, see [51, 52]) for the converse
implication (ii) â‡’(i). As most applications only need (i) â‡’(ii), we only prove
that implication. For a proof of (ii) â‡’(i) see, e.g., [155, Theorem III.4.3].
Theorem 15.44 (Central limit theorem of Lindebergâ€“Feller)
Let (Xn,l) be an
independent centered and normed array of real random variables. For every n âˆˆN,
let Sn = Xn,1 + . . . + Xn,kn. Then the following are equivalent.
(i) The Lindeberg condition holds.
(ii) (Xn,l) is a null array and PSn
nâ†’âˆ
âˆ’â†’N0,1.
We prepare for the proof of Lindebergâ€™s theorem with a couple of lemmas.
Lemma 15.45 If (i) of Theorem 15.44 holds, then (Xn,l) is a null array.
Proof For Îµ > 0, by Chebyshevâ€™s inequality,
kn

l=1
P
)
|Xn,l| > Îµ
*
â‰¤Îµâˆ’2
kn

l=1
E
)
X2
n,l 1{|Xn,l|>Îµ}
*
= Îµâˆ’2 Ln(Îµ)
nâ†’âˆ
âˆ’â†’0.
âŠ“âŠ”

15.5
The Central Limit Theorem
359
In the following, Ï•n,l and Ï•n will always denote the characteristic functions of
Xn,l and Sn.
Lemma 15.46 For every n âˆˆN and t âˆˆR, we have
kn

l=1
1 âˆ’Ï•n,l(t)
 â‰¤t2
2 .
Proof For every x âˆˆR, we have |eitx âˆ’1 âˆ’itx| â‰¤t2x2
2 . Since E[Xn,l] = 0,
kn

l=1
Ï•n,l(t) âˆ’1
 =
kn

l=1
E[eitXn,l âˆ’1]

â‰¤
kn

l=1
E
)eitXn,l âˆ’itXn,l âˆ’1
*
+
E[itXn,l]

â‰¤
kn

l=1
t2
2 E[X2
n,l] = t2
2 .
âŠ“âŠ”
Lemma 15.47 If (i) of Theorem 15.44 holds, then
lim
nâ†’âˆ
 log Ï•n(t) âˆ’
kn

l=1
E
)
eitXn,l âˆ’1
* = 0.
Proof Let mn :=
max
l=1,...,kn
Ï•n,l(t) âˆ’1
. Note that, for all Îµ > 0,
eitx âˆ’1
 â‰¤

2 x2/Îµ2,
if |x| > Îµ,
Îµ |t|,
if |x| â‰¤Îµ.
This implies
Ï•n,l(t) âˆ’1
 â‰¤E
'eitXn,l âˆ’1
 1{|Xn,l|â‰¤Îµ}
(
+ E
'eitXn,l âˆ’1
 1{|Xn,l|>Îµ}
(
â‰¤Îµt + 2 Îµâˆ’2 E
'
X2
n,l 1{|Xn,l|>Îµ}
(
.
Hence, for all Îµ > 0,
lim sup
nâ†’âˆ
mn â‰¤lim sup
nâ†’âˆ

Îµt + 2 Îµâˆ’2Ln(Îµ)

= Îµt,

360
15
Characteristic Functions and the Central Limit Theorem
and thus lim
nâ†’âˆmn = 0. Now | log(x) âˆ’(x âˆ’1)| â‰¤|x âˆ’1|2 for all x âˆˆC with
|x âˆ’1| â‰¤1
2. If n is sufï¬ciently large that mn < 1
2, then
log Ï•n(t) âˆ’
kn

l=1
E[eitXn,l âˆ’1]
 =

kn

l=1

log(Ï•n,l(t)) âˆ’

Ï•n,l(t) âˆ’1

â‰¤
kn

l=1
Ï•n,l(t) âˆ’1
2
â‰¤mn
kn

l=1
Ï•n,l(t) âˆ’1

â‰¤1
2 mn t2
(by Lemma 15.46)
âˆ’â†’0
for n â†’âˆ.
âŠ“âŠ”
In order to work with the concepts of weak convergence in this proof, we introduce
the function
ft(x) :=
â§
âªâªâ¨
âªâªâ©
1
x2

eitx âˆ’1 âˆ’itx

,
if x Ì¸= 0,
âˆ’t2
2 ,
if x = 0,
(15.8)
as well as the measures Î½n âˆˆMf (R), n âˆˆN,
Î½n(dx) :=
kn

l=1
x2 PXn,l(dx).
Lemma 15.48 For every t âˆˆR, we have ft âˆˆCb(R).
Proof Clearly, ft is continuous on R \ {0}. On the other hand, for |x| â‰¥1, we have
|ft(x)| â‰¤|eitx| + 1 + |t/x| â‰¤2 + |t|. It remains to show that ft is continuous at 0.
This will imply that ft is bounded also on the compact set [âˆ’1, 1]. Taylorâ€™s theorem
(Lemma 15.31) yields
eitx âˆ’1 âˆ’itx = âˆ’t2x2
2
+ R(tx)

15.5
The Central Limit Theorem
361
with |R(tx)| â‰¤1
6|tx|3. Hence, for ï¬xed t, we have
lim
0Ì¸=xâ†’0 ft(x) = âˆ’t2
2 +
lim
0Ì¸=xâ†’0
R(tx)
x2
= âˆ’t2
2 = ft(0).
âŠ“âŠ”
Lemma 15.49 If (i) of Theorem 15.44 holds, then Î½n
nâ†’âˆ
âˆ’â†’Î´0 weakly.
Proof For every n âˆˆN, we have Î½n âˆˆM1(R) since
Î½n(R) =
kn

l=1

x2 PXn,l(dx) =
kn

l=1
Var[Xn,l] = 1.
However, for Îµ > 0, we have Î½n([âˆ’Îµ, Îµ]c) = Ln(Îµ)
nâ†’âˆ
âˆ’â†’0; hence Î½n
nâ†’âˆ
âˆ’â†’Î´0.
âŠ“âŠ”
Lemma 15.50 If (i) of Theorem 15.44 holds, then

ft dÎ½n
nâ†’âˆ
âˆ’â†’âˆ’t2
2 .
Proof By Lemma 15.48, we have ft âˆˆCb(R). Furthermore, by Lemma 15.49 we
have Î½n
nâ†’âˆ
â‡’Î´0. In other words, we have
3
ft dÎ½n
nâ†’âˆ
âˆ’â†’ft(0) = âˆ’t2/2.
âŠ“âŠ”
Proof of Theorem 15.44
â€œ(i) â‡’(ii)â€
We have to show that lim
nâ†’âˆlog Ï•n(t) = âˆ’t2
2 for every t âˆˆR. By
Lemma 15.47, this is equivalent to
lim
nâ†’âˆ
kn

l=1
Ï•n,l(t) âˆ’1 = âˆ’t2
2 .
Now ft(x) x2 +itx = eitx âˆ’1 and
3
itx PXn,l(dx) = itE[Xn,l] = 0, since the array
(Xn,l) is centered. Hence, we get
kn

l=1

Ï•n,l(t) âˆ’1

=
kn

l=1
 
ft(x) x2 + itx

PXn,l(dx)
=
kn

l=1

ft(x) x2 PXn,l(dx)

362
15
Characteristic Functions and the Central Limit Theorem
=

ft dÎ½n
nâ†’âˆ
âˆ’â†’âˆ’t2
2
(by Lemma 15.50).
âŠ“âŠ”
As an application of the Lindebergâ€“Feller theorem, we give the so-called three-
series theorem, which is due to Kolmogorov.
Theorem 15.51 (Kolmogorovâ€™s three-series theorem) Let X1, X2, . . . be inde-
pendent real random variables. Let K > 0 and Yn := Xn 1{|Xn|â‰¤K} for all n âˆˆN.
The series âˆ
n=1 Xn converges almost surely if and only if each of the following
three conditions holds:
(i)
âˆ

n=1
P[|Xn| > K] < âˆ.
(ii)
âˆ

n=1
E[Yn] converges.
(iii)
âˆ

n=1
Var[Yn] < âˆ.
Proof â€œ â‡ â€
Assume that (i), (ii) and (iii) hold. By Exercise 6.1.4, since (iii)
holds, the series âˆ
n=1(Ynâˆ’E[Yn]) converges a.s. As (ii) holds, âˆ
n=1 Yn converges
almost surely. By the Borelâ€“Cantelli lemma, there exists an N = N(Ï‰) such that
|Xn| â‰¤K; hence Xn = Yn for all n â‰¥N. Hence âˆ
n=1 Xn = Nâˆ’1
n=1 Xn+âˆ
n=N Yn
converges a.s.
â€œ â‡’â€
Assume that âˆ
n=1 Xn converges a.s. Clearly, this implies (i) (otherwise,
by the Borelâ€“Cantelli lemma, |Xn| > K inï¬nitely often, contradicting the assump-
tion).
We assume that (iii) does not hold and produce a contradiction. To this end, let
Ïƒ 2
n = n
k=1 Var[Yk] and deï¬ne an array (Xn,l; l = 1, . . ., n, n âˆˆN) by Xn,l =
(Yl âˆ’E[Yl])/Ïƒn. This array is independent, centered and normed. Since Ïƒ 2
n
nâ†’âˆ
âˆ’â†’
âˆ, for every Îµ > 0 and for sufï¬ciently large n âˆˆN, we have 2K < ÎµÏƒn; thus
|Xn,l| < Îµ for all l = 1, . . . , n. This implies Ln(Îµ)
nâ†’âˆ
âˆ’â†’
0, where Ln(Îµ) =
n
l=1
E)X2
n,l 1{|Xn,l|>Îµ}
* is the quantity of the Lindeberg condition (see (15.6)). By the
Lindebergâ€“Feller theorem, we then get Sn := Xn,1 + . . . + Xn,n
nâ†’âˆ
â‡’N0,1. As
shown in the ï¬rst part of this proof, almost sure convergence of âˆ
n=1 Xn and (i)
imply that
âˆ

n=1
Yn
converges almost surely.
(15.9)

15.5
The Central Limit Theorem
363
In particular, Tn := (Y1 + . . . + Yn)/Ïƒn
nâ†’âˆ
â‡’0. Thus, by Slutzkyâ€™s theorem, we
also have (Sn âˆ’Tn) nâ†’âˆ
â‡’N0,1. On the other hand, for all n âˆˆN, the difference
Sn âˆ’Tn is deterministic, contradicting the assumption that (iii) does not hold.
Now that we have established (iii), by Exercise 6.1.4, we see that âˆ
n=1(Yn âˆ’
E[Yn]) converges almost surely. Together with (15.9), we conclude (ii).
âŠ“âŠ”
As a supplement, we cite a statement about the speed of convergence in the central
limit theorem (see, e.g., [155, Chapter III, Â§11] for a proof). With different bounds
(instead of 0.8), the statement was found independently by Berry [10] and Esseen
[46].
Theorem 15.52 (Berryâ€“Esseen)
Let X1, X2, . . . be independent and identically
distributed with E[X1] = 0, E[X2
1] = Ïƒ 2 âˆˆ(0, âˆ) and Î³ := E[|X1|3] < âˆ. Let
Sâˆ—
n :=
1
âˆš
nÏƒ 2 (X1 +Â· Â· Â·+Xn) and let Î¦ : x â†’
1
âˆš
2Ï€
3 x
âˆ’âˆeâˆ’t2/2dt be the distribution
function of the standard normal distribution. Then, for all n âˆˆN,
sup
xâˆˆR
P )Sâˆ—
n â‰¤x* âˆ’Î¦(x)
 â‰¤
0.8 Î³
Ïƒ 3âˆšn.
Example 15.53 Let Î± âˆˆ(0, 1). Consider the distribution Î¼Î± on R with density
fÎ±(x) = 1
2Î± |x|âˆ’1âˆ’1/Î± 1{|x|â‰¥1}.
Let X1, X2, . . . , be i.i.d. random variables with distribution Î¼Î±. Then E[X1] = 0
and Ïƒ 2 := Var[X1] = 1/(1 âˆ’2Î±) < âˆif Î± < 1/2. Let Fn denote the distribution
function of Sâˆ—
n and FÎ¦ the distribution function of the standard normal distribution.
The closer Fn and FÎ¦ are, the closer lie the points (F âˆ’1
Î¦ (t), F âˆ’1
n (t)) on the diagonal
{(x, x) : x âˆˆR}. A graphical representation of the points (F âˆ’1
Î¦ (t), F âˆ’1
n (t)), t âˆˆR
is called Q-Q-plot or quantile-quantile-plot.
As Î± approaches 1/2, the distribution Î¼Î± has less and less moments. Hence we
expect the convergence in the central limit theorem to be slower. For ï¬xed n, we
expect the deviation of Fn from FÎ¦ to be larger for larger Î±. The graphs in Fig. 15.2
illustrate this. â™¦
Takeaways If a random variable is the sum of many independent centred
random variables, each of which takes mainly small values, then its distribu-
tion is close to a normal distribution. The Feller-Lindeberg theorem makes
rigorous sense of the expressions â€œmainly small valuesâ€ and â€œclose to a
normal distributionâ€ and formulates the precise statement.
Exercise 15.5.1 The argument of Remark 15.39 is more direct than the argument
with LÃ©vyâ€™s continuity theorem but is less robust: Give a sequence X1, X2, . . . of

364
15
Characteristic Functions and the Central Limit Theorem
âˆ’4
âˆ’2
0
2
4
F âˆ’1
100(t)
Î± = 0.4
F âˆ’1
Î¦ (t)
âˆ’4
âˆ’2
0
2
4
âˆ’4
âˆ’2
0
2
4
âˆ’4
âˆ’2
0
2
4
F âˆ’1
100(t)
Î± = 0.48
F âˆ’1
Î¦ (t)
Fig. 15.2 Q-Q-plots for Sâˆ—
100 from Example 15.53 with Î± = 0.4 (left) and Î± = 0.48 (right). The
abscissa shows the quantiles of the standard normal distribution. For convenience, also the diagonal
is drawn.
independent real random variables with E[|Xn|] = âˆfor all n âˆˆN but such that
X1 + . . . + Xn
âˆšn
nâ†’âˆ
â‡’N0,1.
â™£
Exercise 15.5.2 Let Y1, Y2, . . . be i.i.d. with E[Yi] = 0 and E[Y 2
i ] = 1. Let
Z1, Z2, . . . be independent random variables (and independent of Y1, Y2, . . .) with
P[Zi = i] = P[Zi = âˆ’i] = 1
2
1 âˆ’P[Zi = 0] = 1
2
1
i2 .
For i, n âˆˆN, deï¬ne Xi := Yi + Zi and Sn = X1 + . . . + Xn.
Show that nâˆ’1/2Sn
nâ†’âˆ
â‡’N0,1 but that (Xi)iâˆˆN does not satisfy the Lindeberg
condition.
Hint: Do not try a direct computation! â™£
Exercise 15.5.3 Let X1, X2, . . . be i.i.d. random variables with density
f (x) =
1
|x|3 1R\[âˆ’1,1](x).
Then E[X2
1] = âˆbut there are numbers A1, A2, . . ., such that
X1 + . . . + Xn
An
nâ†’âˆ
â‡’N0,1.
Determine one such sequence (An)nâˆˆN explicitly. â™£

15.6
Multidimensional Central Limit Theorem
365
15.6
Multidimensional Central Limit Theorem
We come to a multidimensional version of the CLT.
Deï¬nition 15.54 Let C be a (strictly) positive deï¬nite symmetric real d Ã— d matrix
and let Î¼ âˆˆRd. A random vector X = (X1, . . . , Xd)T is called d-dimensional
normally distributed with expectation Î¼ and covariance matrix C if X has the
density
fÎ¼,C(x) =
1
2
(2Ï€)d det(C)
exp

âˆ’1
2
B
x âˆ’Î¼, Câˆ’1(x âˆ’Î¼)
C
(15.10)
for x âˆˆRd. In this case, we write X âˆ¼NÎ¼,C.
Theorem 15.55 Let Î¼ âˆˆRd and let C be a real positive deï¬nite symmetric d Ã— d
matrix. If X âˆ¼NÎ¼,C, then the following statements hold.
(i) E[Xi] = Î¼i for all i = 1, . . ., d.
(ii) Cov[Xi, Xj] = Ci,j for all i, j = 1, . . . , d.
(iii) âŸ¨Î», XâŸ©âˆ¼NâŸ¨Î»,Î¼âŸ©,âŸ¨Î»,CÎ»âŸ©for every Î» âˆˆRd.
(iv) Ï•(t) := E[eiâŸ¨t,XâŸ©] = eiâŸ¨t,Î¼âŸ©eâˆ’1
2 âŸ¨t,CtâŸ©for every t âˆˆRd.
Moreover, X âˆ¼NÎ¼,C â‡â‡’(iii) â‡â‡’(iv).
Proof (i) and (ii) follow by simple computations. The same is true for (iii) and
(iv). The implication (iii) â‡’(iv) is straightforward as the characteristic function
Ï• uniquely determines the distribution of X by Theorem 15.9.
âŠ“âŠ”
Remark 15.56 For one-dimensional normal distributions, it is natural to deï¬ne the
degenerate normal distribution by NÎ¼,0 := Î´Î¼. For the multidimensional situation,
there are various possibilities for degeneracy depending on the size of the kernel of
C. If C is only positive semideï¬nite (and symmetric, of course), we deï¬ne NÎ¼,C as
that distribution on Rn with characteristic function Ï•(t) = eiâŸ¨t,Î¼âŸ©eâˆ’1
2 âŸ¨t,CtâŸ©. â™¦
Theorem 15.57 (CramÃ©râ€“Wold device) Let Xn = (Xn,1, . . . , Xn,d)T âˆˆRd, n âˆˆ
N, be random vectors. Then, the following are equivalent:
(i) There is a random vector X such that Xn
nâ†’âˆ
â‡’X.
(ii) For any Î» âˆˆRd, there is a random variable XÎ» such that âŸ¨Î», XnâŸ©nâ†’âˆ
â‡’XÎ».
If (i) and (ii) hold, then XÎ» D= âŸ¨Î», XâŸ©for all Î» âˆˆRd.
Proof Assume (i). Let Î» âˆˆRd and s âˆˆR. The map Rd â†’C, x â†’ei sâŸ¨Î»,xâŸ©is
continuous and bounded; hence we have E[ei sâŸ¨Î»,XnâŸ©]
nâ†’âˆ
âˆ’â†’E[ei sâŸ¨Î»,XâˆâŸ©]. Thus (ii)
holds with XÎ» := âŸ¨Î», XâŸ©.
Now assume (ii). Then (PXn,l)nâˆˆN is tight for every l = 1, . . . , d. Hence (PXn)nâˆˆN
is tight and thus relatively sequentially compact (Prohorovâ€™s theorem). For any weak

366
15
Characteristic Functions and the Central Limit Theorem
limit point Q for (PXn)nâˆˆN and for any Î» âˆˆRd, we have

Q(dx) eiâŸ¨Î»,xâŸ©= E
)
eiXÎ»*
.
Hence the limit point Q is unique and thus (PXn)nâˆˆN converges weakly to Q. That
is, (i) holds.
If (ii) holds, then the distributions of the limiting random variables XÎ» are
uniquely determined and by what we have shown already, XÎ» = âŸ¨Î», XâŸ©is one
possible choice. Thus XÎ» D= âŸ¨Î», XâŸ©.
âŠ“âŠ”
Theorem 15.58 (Central limit theorem in Rd) Let (Xn)nâˆˆN be i.i.d. random
vectors with E[Xn,i] = 0 and E[Xn,iXn,j] = Cij , i, j = 1, . . . , d. Let Sâˆ—
n :=
X1+...+Xn
âˆšn
. Then
PSâˆ—n
nâ†’âˆ
âˆ’â†’N0,C weakly.
Proof Let Î» âˆˆRd. Deï¬ne XÎ»
n = âŸ¨Î», XnâŸ©, SÎ»
n = âŸ¨Î», Sâˆ—
nâŸ©and Sâˆâˆ¼N0,C. Then
E[XÎ»
n] = 0 and Var[XÎ»
n] = âŸ¨Î», CÎ»âŸ©. By the one-dimensional central limit theorem,
we have PSÎ»n
nâ†’âˆ
âˆ’â†’N0,âŸ¨Î»,CÎ»âŸ©= PâŸ¨Î», SâˆâŸ©. By Theorem 15.57, this yields the claim.
âŠ“âŠ”
Takeaways For vector-valued random variables to converge, it is enough that
the projections to one-dimensional subspaces converge (CramÃ©r-Wold). We
use this to conclude a central limit theorem for multi-dimensional independent
and identically distributed random variables.
Exercise 15.6.1 Let Î¼ âˆˆRd, let C be a symmetric positive semideï¬nite real d Ã—
d matrix and let X âˆ¼NÎ¼,C (in the sense of Remark 15.56). Show that AX âˆ¼
NAÎ¼,ACAT for every m âˆˆN and every real m Ã— d matrix A. â™£
Exercise 15.6.2 (Cholesky factorization)
Let C be a positive deï¬nite symmet-
ric real dÃ—d matrix. Then there exists a real dÃ—d matrix A = (akl) with AÂ·AT = C.
The matrix A can be chosen to be lower triangular. Let W := (W1, . . . , Wd)T , where
W1, . . . , Wd are independent and N0,1-distributed. Deï¬ne X := AW +Î¼. Show that
X âˆ¼NÎ¼,C. â™£

Chapter 16
Inï¬nitely Divisible Distributions
For every n, the normal distribution NÎ¼,Ïƒ 2 is the nth convolution power of a prob-
ability measure (namely, of NÎ¼/n,Ïƒ 2/n). This property is called inï¬nite divisibility
and is shared by other probability distributions such as the Poisson distribution and
the Gamma distribution. In the ï¬rst section, we study which probability measures
on R are inï¬nitely divisible and give an exhaustive description of this class of
distributions by means of the LÃ©vyâ€“Khinchin formula.
Unlike the Poisson distribution, the normal distribution is the limit of rescaled
sums of i.i.d. random variables (central limit theorem). In the second section, we
investigate brieï¬‚y which subclass of the inï¬nitely divisible measures on R shares
this property.
16.1
LÃ©vyâ€“Khinchin Formula
For the sake of brevity, in this section, we use the shorthand â€œCFPâ€ for â€œcharacter-
istic function of a probability measure on Râ€.
Deï¬nition 16.1 A measure Î¼ âˆˆM1(R) is called inï¬nitely divisible if, for every
n âˆˆN, there is a Î¼n âˆˆM1(R) such that Î¼âˆ—n
n = Î¼. Analogously, a CFP Ï• is called
inï¬nitely divisible if, for every n âˆˆN, there is a CFP Ï•n such that Ï• = Ï•n
n. A real
random variable X is called inï¬nitely divisible if, for every n âˆˆN, there exist i.i.d.
random variables Xn,1, . . . , Xn,n such that X D= Xn,1 + . . . + Xn,n.
Manifestly, all three notions of inï¬nite divisibility are equivalent, and we will use
them synonymously. Note that the uniqueness of Î¼n and Ï•n, respectively, is by no
means evident. Indeed, n-fold divisibility alone does not imply uniqueness of the
nth convolution root Î¼âˆ—1/n := Î¼n or of Ï•n, respectively. As an example for even n,
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_16
367

368
16
Inï¬nitely Divisible Distributions
choose a real-valued CFP Ï• for which |Ï•| Ì¸= Ï• is also a CFP (see Examples 15.17
and 15.18). Then Ï•n = |Ï•|n is n-fold divisible; however, the factors are not unique.
By virtue of LÃ©vyâ€™s continuity theorem, one can show that (see Exercise 16.1.2)
Ï•(t) Ì¸= 0 for all t âˆˆR if Ï• is inï¬nitely divisible. The probabilistic meaning of this
fact is that as a continuous function log(Ï•(t)) is uniquely deï¬ned and thus there
exists only one continuous function Ï•1/n = exp(log(Ï•)/n). The nth convolution
roots are thus unique if the distribution is inï¬nitely divisible.
Example 16.2
(i) Î´x is inï¬nitely divisible with Î´âˆ—n
x/n = Î´x for every n âˆˆN.
(ii) The normal distribution is inï¬nitely divisible with Nm,Ïƒ 2 = N âˆ—n
m/n,Ïƒ 2/n.
(iii) The Cauchy distribution Caua with density x â†’(aÏ€)âˆ’1 (1 + (x/a)2)âˆ’1 is
inï¬nitely divisible with Caua = Cauâˆ—n
a/n. Indeed, Caua has CFP Ï•a(t) =
eâˆ’a|t|; hence Ï•n
a/n = Ï•a.
(iv) Every symmetric stable distribution with index Î± âˆˆ(0, 2] and scale parameter
Î³ > 0 (that is, the distribution with CFP Ï•Î±,Î³ (t) = eâˆ’|Î³ t|Î±) is inï¬nitely
divisible. Indeed, Ï•n
Î±,Î³/n1/Î± = Ï•Î±,Î³ . (To be precise, we have shown only for
Î± âˆˆ(0, 1] (in Corollary 15.26) and for Î± = 2 (normal distribution) that Ï•Î±,Î³
is in fact a CFP. In Sect. 16.2, we will show that this is true for all Î± âˆˆ(0, 2].
For Î± > 2, Ï•Î±,Î³ is not a CFP, see Exercise 15.4.3.)
(v) The Gamma distribution Î“Î¸,r with CFP Ï•Î¸,r(t) = exp(rÏˆÎ¸(t)), where
ÏˆÎ¸(t) = log(1 âˆ’it/Î¸), is inï¬nitely divisible with Î“Î¸,r = Î“ âˆ—n
Î¸,r/n.
(vi) The Poisson distribution is inï¬nitely divisible with PoiÎ» = Poiâˆ—n
Î»/n.
(vii) The negative binomial distribution bâˆ’
r,p({k}) =
âˆ’r
k

(âˆ’1)kpr(1âˆ’p)k, k âˆˆN0,
with parameters r > 0 and p âˆˆ(0, 1), is inï¬nitely divisible with bâˆ’
r,p =
(bâˆ’
r/n,p)âˆ—n. Indeed, Ï•r,p(t) = erÏˆp(t), where
Ïˆp(t) = log(p) âˆ’log

1 âˆ’(1 âˆ’p)eit
.
(viii) Let X and Y be independent with X âˆ¼N0,Ïƒ 2 and Y âˆ¼Î“Î¸,r, where Ïƒ 2, Î¸, r >
0. It can be shown that the random variable Z := X/
âˆš
Y is inï¬nitely divisible
(see [65] or [131]). In particular, Studentâ€™s t-distribution with k âˆˆN degrees
of freedom is inï¬nitely divisible (this is the case where Ïƒ 2 = 1 and Î¸ = r =
k/2).
(ix) The binomial distribution bn,p with parameters n âˆˆN and p âˆˆ(0, 1) is not
inï¬nitely divisible (why?).
(x) Somewhat more generally, there is no nontrivial inï¬nitely divisible distribu-
tion that is concentrated on a bounded interval. â™¦
A main goal of this section is to show that every inï¬nitely divisible distribution can
be composed of three generic ones:
â€¢
the Dirac measures Î´x with x âˆˆR,
â€¢
the normal distributions NÎ¼,Ïƒ 2 with Î¼ âˆˆR and Ïƒ 2 > 0, and
â€¢
(limits of) convolutions of Poisson distributions.

16.1
LÃ©vyâ€“Khinchin Formula
369
As convolutions of Poisson distributions play a special role, we will consider them
separately.
If Î½ âˆˆM1(R) with CFP Ï•Î½ and if Î» > 0, then one can easily check that Ï•(t) =
exp(Î»(Ï•Î½(t) âˆ’1)) is the CFP of Î¼Î» = âˆ
k=0 eâˆ’Î» Î»k
k! Î½âˆ—k. Hence, formally we can
write Î¼Î» = eâˆ—Î»(Î½âˆ’Î´0). Indeed, Î¼Î» is inï¬nitely divisible with Î¼Î» = Î¼âˆ—n
Î»/n. We want
to combine the two parameters Î» and Î½ into one parameter Î»Î½. For Î½ âˆˆMf (R),
we can deï¬ne Î½âˆ—n = Î½(R)n(Î½/Î½(R))âˆ—n (and Î½âˆ—n = 0 if Î½ = 0). In both cases, let
Î½âˆ—0 := Î´0. Hence we make the following deï¬nition.
Deï¬nition 16.3 The compound Poisson distribution with intensity measure Î½ âˆˆ
Mf (R) is the following probability measure on R:
CPoiÎ½ := eâˆ—(Î½âˆ’Î½(R)Î´0) := eâˆ’Î½(R)
âˆ

n=0
Î½âˆ—n
n! .
The CFP of CPoiÎ½ is given by
Ï•Î½(t) = exp

(eitx âˆ’1) Î½(dx)

.
(16.1)
In particular, CPoiÎ¼+Î½ = CPoiÎ¼ âˆ—CPoiÎ½; hence CPoiÎ½ is inï¬nitely divisible.
Example 16.4 For every measurable set A âŠ‚R \ {0} and every r > 0,
râˆ’1CPoirÎ½(A) = eâˆ’rÎ½(R)Î½(A) + eâˆ’rÎ½(R)
âˆ

k=2
rkâˆ’1Î½âˆ—k(A)
k!
râ†“0
âˆ’â†’Î½(A).
We use this in order to show that bâˆ’
r,p = CPoirÎ½ for some Î½ âˆˆMf (N). To this end,
for k âˆˆN, we compute
râˆ’1bâˆ’
r,p({k}) = r(r + 1) Â· Â· Â· (r + k âˆ’1)
r k!
pr(1 âˆ’p)k
râ†“0
âˆ’â†’(1 âˆ’p)k
k
.
If we had bâˆ’
r,p = CPoirÎ½ for some Î½ âˆˆMf (N), then we would have Î½({k}) =
(1 âˆ’p)k/k. We compute the CFP of CPoirÎ½ for this Î½,
Ï•rÎ½(t) = exp

r
âˆ

k=1
((1 âˆ’p)eit)k âˆ’(1 âˆ’p)k
k

= pr 
1 âˆ’(1 âˆ’p)eitâˆ’r
.
However, this is the CFP of bâˆ’
r,p; hence indeed bâˆ’
r,p = CPoirÎ½. â™¦
Not every inï¬nitely divisible distribution is of the type CPoiÎ½, however we have the
following theorem.

370
16
Inï¬nitely Divisible Distributions
Theorem 16.5 A probability measure Î¼ on R is inï¬nitely divisible if and only if
there is a sequence (Î½n)nâˆˆN in Mf (R \ {0}) such that CPoiÎ½n
nâ†’âˆ
âˆ’â†’Î¼.
If Î¼ is inï¬nitely divisible and Î¼n âˆˆM1(R) is such that Î¼âˆ—n
n = Î¼ for all n âˆˆN,
then Î½n = 1R\{0}nÎ¼n is a possible choice.
Since every CPoiÎ½n is inï¬nitely divisible, on the one hand we have to show that
this property is preserved under weak limits. On the other hand, we show that, for
inï¬nitely divisible Î¼, the sequence Î½n = 1R\{0}nÎ¼âˆ—1/n does the trick. We prepare
for the proof of Theorem 16.5 with a further theorem.
Theorem 16.6 Let (Ï•n)nâˆˆN be a sequence of CFPs. Then the following are
equivalent.
(i) For every t âˆˆR, the limit Ï•(t) = lim
nâ†’âˆÏ•n
n(t) exists and Ï• is continuous at 0.
(ii) For every t âˆˆR, the limit Ïˆ(t) = lim
nâ†’âˆn(Ï•n(t)âˆ’1) exists and Ïˆ is continuous
at 0.
If (i) and (ii) hold, then Ï• = eÏˆ is a CFP.
Proof The proof is based on a Taylor expansion of the logarithm,
| log(z) âˆ’(z âˆ’1)| â‰¤|z âˆ’1|2
for z âˆˆC with |z âˆ’1| < 1
2.
As an immediate consequence, we get
1
2|z âˆ’1| â‰¤| log(z)| â‰¤3
2|z âˆ’1|
for z âˆˆC with |z âˆ’1| < 1
2.
In particular, for (zn)nâˆˆN in C,
lim sup
nâ†’âˆ
n |zn âˆ’1| < âˆâ‡â‡’lim sup
nâ†’âˆ
|n log(zn)| < âˆ,
(16.2)
and limnâ†’âˆn(zn âˆ’1) = limnâ†’âˆn log(zn) if one of the limits exists.
Applying this to zn = Ï•n(t), we see that (ii) implies (i). On the other hand, (i)
implies (ii) if lim infnâ†’âˆn log(|Ï•n(t)|) > âˆ’âˆand hence if Ï•(t) Ì¸= 0 for all t âˆˆR.
Since Ï• is continuous at 0 and since Ï•(0) = 1, there is an Îµ > 0 with |Ï•(t)| > 1
2
for all t âˆˆ[âˆ’Îµ, Îµ]. Since Ï• and Ï•n are CFPs, |Ï•|2 and |Ï•n|2 are also CFPs. Thus,
since |Ï•n(t)|2n converges to |Ï•(t)|2 pointwise, LÃ©vyâ€™s continuity theorem implies
uniform convergence on compact sets. Now apply (16.2) with zn = |Ï•n(t)|2. Thus
(n(1 âˆ’|Ï•n(t)|2))nâˆˆN is bounded for t âˆˆ[âˆ’Îµ, Îµ]. Hence, by Lemma 15.12(v),
n(1 âˆ’|Ï•n(2t)|2) â‰¤4n(1 âˆ’|Ï•n(t)|2) also is bounded; thus
|Ï•(2t)|2 â‰¥lim inf
nâ†’âˆexp(4n(|Ï•n(t)|2 âˆ’1)) = (|Ï•(t)|2)4.

16.1
LÃ©vyâ€“Khinchin Formula
371
Inductively, we get |Ï•(t)| â‰¥2âˆ’(4k) for |t| â‰¤2kÎµ. Hence there is a Î³ > 0 such that
|Ï•(t)| > 1
2 eâˆ’Î³ t2
for all t âˆˆR.
(16.3)
If (i) and (ii) hold, then
log Ï•(t) = lim
nâ†’âˆn log(Ï•n(t)) = lim
nâ†’âˆn(Ï•n(t) âˆ’1) = Ïˆ(t).
By LÃ©vyâ€™s continuity theorem, as a continuous limit of CFPs, Ï• is a CFP.
âŠ“âŠ”
Corollary 16.7 If the conditions of Theorem 16.6 hold, then Ï•r is a CFP for every
r > 0. In particular, Ï• = (Ï•1/n)n is inï¬nitely divisible.
Proof If Ï•n is the CFP of Î¼n âˆˆM1(R), then ern(Ï•nâˆ’1) is the CFP of CPoirnÎ¼n.
Being a limit of CFPs that is continuous at 0, by LÃ©vyâ€™s continuity theorem, Ï•r =
erÏˆ = limnâ†’âˆern(Ï•nâˆ’1) is a CFP. Letting r =
1
n, we get that Ï• = (Ï•1/n)n is
inï¬nitely divisible.
âŠ“âŠ”
Corollary 16.8 Let Ï• : R â†’C be continuous at 0. Ï• is an inï¬nitely divisible CFP
if and only if there is a sequence (Ï•n)nâˆˆN of CFPs such that Ï•n
n(t) â†’Ï•(t) for all
t âˆˆR.
Proof One implication has been shown already in Corollary 16.7. Hence, let Ï• be
an inï¬nitely divisible CFP. Then Ï•n = Ï•1/n serves the purpose.
âŠ“âŠ”
Corollary 16.9 If (Î¼n)nâˆˆN is a (weakly) convergent sequence of inï¬nitely divisible
probability measures on R, then Î¼ = limnâ†’âˆÎ¼n is inï¬nitely divisible.
Proof Apply Theorem 16.6, where Ï•n is the CFP of Î¼âˆ—1/n
n
.
âŠ“âŠ”
Corollary 16.10 If Î¼ âˆˆM1(R) is inï¬nitely divisible, then there exists a continuous
convolution semigroup (Î¼t)tâ‰¥0 with Î¼1 = Î¼ and a stochastic process (Xt)tâ‰¥0 with
independent, stationary increments Xt âˆ’Xs âˆ¼Î¼tâˆ’s for t > s.
Proof Let Ï• be the CFP of Î¼. The existence of the convolution semigroup follows
by Corollaries 16.8 and 16.7 if we deï¬ne Î¼r by Ï•r. Since Ï•r(t) Ì¸= 0 for all t âˆˆ
R, we have Ï•r â†’1 for r â†’0 and thus the semigroup is continuous. Finally,
Theorem 14.50 implies the existence of the process X.
âŠ“âŠ”
Corollary 16.11 If Ï• is an inï¬nitely divisible CFP, then there exists a Î³ > 0 with
|Ï•(t)| â‰¥1
2eâˆ’Î³ t2 for all t âˆˆR. In particular, for Î± > 2, t â†’eâˆ’|t|Î± is not a CFP.
Proof This is a direct consequence of (16.3).
âŠ“âŠ”
Proof (of Theorem 16.5) As every CPoiÎ½n is inï¬nitely divisible, by Corollary 16.9,
the weak limit is also inï¬nitely divisible.
Now let Î¼ be inï¬nitely divisible with CFP Ï•. For n âˆˆN choose Î¼n âˆˆM1(R)
such that Î¼âˆ—n
n = Î¼ and let Ï•n the CFP of Î¼n. Then Ï•n
n = Ï•. By Theorem 16.6, we

372
16
Inï¬nitely Divisible Distributions
have en(Ï•nâˆ’1) nâ†’âˆ
âˆ’â†’Ï•. As en(Ï•nâˆ’1) is the CFP of CPoinÎ¼n, we infer CPoinÎ¼n
nâ†’âˆ
âˆ’â†’
Î¼. Now let Î½n = 1R\{0}nÎ¼n. Then CPoiÎ½n = CPoinÎ¼n
nâ†’âˆ
âˆ’â†’Î¼.
âŠ“âŠ”
Without proof, we quote the following strengthening of Corollary 16.8 that relies on
a ï¬ner analysis using the arguments from the proof of Theorem 16.6.
Theorem 16.12 Let (Ï•n,l; l = 1, . . . , kn, n âˆˆN) be an array of CFPs with the
property
sup
L>0
lim sup
nâ†’âˆ
sup
tâˆˆ[âˆ’L,L]
sup
l=1,...,kn
|Ï•n,l(t) âˆ’1| = 0.
(16.4)
Assume that, for every t âˆˆR, the limit Ï•(t) := limnâ†’âˆ
kn
l=1 Ï•n,l(t) exists and that
Ï• is continuous at 0. Then Ï• is an inï¬nitely divisible CFP.
Proof See, e.g., [54, Chapter XV.7].
âŠ“âŠ”
In the special case where for every n, the individual Ï•n,l are equal and where
kn
nâ†’âˆ
âˆ’â†’
âˆ, equation (16.4) holds automatically if the product converges to a
continuous function. Thus, the theorem is in fact an improvement of Corollary 16.8.
The beneï¬t of this theorem will become clear through the following observation.
Let (Xn,l; l = 1, . . . , kn, n âˆˆN) be an array of real random variables with CFPs
Ï•n,l. This array is a null array if and only if (16.4) holds. In fact, if P[|Xn,l| > Îµ] < Î´,
then we have |Ï•n,l(t) âˆ’1| â‰¤2Îµ + Î´ for all t âˆˆ[âˆ’1/Îµ, 1/Îµ]. Hence (16.4) holds if
the array (Xn,l) is a null array. On the other hand, (16.4) implies Ï•n,ln
nâ†’âˆ
âˆ’â†’1 for
every sequence (ln) with ln â‰¤kn. Hence Xn,ln
nâ†’âˆ
âˆ’â†’0 in probability.
From these considerations and from Theorem 16.12, we conclude the following
theorem.
Theorem 16.13 Let (Xn, l; l = 1, . . . , kn, n âˆˆN) be an independent null array of
real random variables. If there exists a random variable S with
Xn,1 + . . . + Xn,kn
nâ†’âˆ
â‡’S,
then S is inï¬nitely divisible.
As a direct application of Theorem 16.5, we give a complete description of the
class of inï¬nitely divisible probability measures on [0, âˆ) in terms of their Laplace
transforms. The following theorem is of independent interest. Here, however, it is
primarily used to provide familiarity with the techniques that will be needed for the
more challenging classiï¬cation of the inï¬nitely divisible probability measures on R.
Theorem 16.14 (LÃ©vyâ€“Khinchin formula on [0, âˆ)) Let Î¼ âˆˆM1([0, âˆ)) and
let u : [0, âˆ) â†’[0, âˆ), t â†’âˆ’log
3
eâˆ’tx Î¼(dx) be the log-Laplace transform Î¼.
Î¼ is inï¬nitely divisible if and only if there exists an Î± â‰¥0 and a Ïƒ-ï¬nite measure

16.1
LÃ©vyâ€“Khinchin Formula
373
Î½ âˆˆM((0, âˆ)) with

(1 âˆ§x) Î½(dx) < âˆ
(16.5)
and such that
u(t) = Î±t +
 
1 âˆ’eâˆ’tx
Î½(dx)
for t â‰¥0.
(16.6)
In this case, the pair (Î±, Î½) is unique. Î½ is called the canonical measure or LÃ©vy
measure of Î¼, and Î± is called the deterministic part.
Proof â€œ â‡’â€
First assume Î¼ is inï¬nitely divisible. The case Î¼ = Î´0 is trivial.
Now let Î¼ Ì¸= Î´0; hence u(1) > 0.
For n âˆˆN, there exists a Î¼n âˆˆM1(R) such that Î¼âˆ—n
n
= Î¼. Clearly, we have
Î¼n((âˆ’âˆ, 0))n â‰¤Î¼((âˆ’âˆ, 0)) = 0. Hence Î¼n is supported by [0, âˆ). Deï¬ne Î½n =
nÎ¼n âˆˆMf ([0, âˆ)). By Theorem 16.5, we have CPoiÎ½n
nâ†’âˆ
âˆ’â†’Î¼.
If we deï¬ne un(t) :=
3
(1âˆ’eâˆ’tx) Î½n(dx), then (as in (16.1)) un(t)
nâ†’âˆ
âˆ’â†’u(t) for
all t â‰¥0. In particular, un(1) > 0 for sufï¬ciently large n. Deï¬ne ËœÎ½n âˆˆM1([0, âˆ))
by ËœÎ½n(dx) := 1âˆ’eâˆ’x
un(1) Î½n(dx). Hence, for all t â‰¥0,

eâˆ’tx ËœÎ½n(dx) = un(t + 1) âˆ’un(t)
un(1)
nâ†’âˆ
âˆ’â†’
u(t + 1) âˆ’u(t)
u(1)
.
The right hand side is continuous and hence a variation of LÃ©vyâ€™s continuity
theorem for Laplace transforms (compare Exercise 15.3.4) yields that the weak
limit ËœÎ½ := w-lim ËœÎ½n (in M1([0, âˆ)) exists and is uniquely determined by u. Let
Î± := ËœÎ½({0}) u(1) and deï¬ne Î½ âˆˆM((0, âˆ)) by
Î½(dx) = u(1)(1 âˆ’eâˆ’x)âˆ’1 1(0,âˆ)(x) ËœÎ½(dx).
Since 1 âˆ§x â‰¤2(1 âˆ’eâˆ’x) for all x â‰¥0, clearly

(1 âˆ§x) Î½(dx) â‰¤2

(1 âˆ’eâˆ’x) Î½(dx) â‰¤2u(1) < âˆ.
For all t â‰¥0, the function (compare (15.8))
ft : [0, âˆ) â†’[0, âˆ),
x â†’

1âˆ’eâˆ’tx
1âˆ’eâˆ’x ,
if x > 0,
t,
if x = 0,

374
16
Inï¬nitely Divisible Distributions
is continuous and bounded (by t âˆ¨1). Hence we have
u(t) = lim
nâ†’âˆun(t) = lim
nâ†’âˆun(1)

ft d ËœÎ½n
= u(1)

ft d ËœÎ½ = Î±t +

(1 âˆ’eâˆ’tx) Î½(dx).
â€œ â‡ â€
Now assume that Î± and Î½ are given. Deï¬ne the intervals I0 = [1, âˆ) and
Ik = [1/(k + 1), 1/k) for k âˆˆN. Let X0, X1, . . . be independent random variables
with PXk = CPoi(Î½|Ik ) for k = 0, 1, . . ., and let X := Î± + âˆ
k=0 Xk. For every
k âˆˆN, we have E[Xk] =
3
Ik x Î½(dx); hence âˆ
k=1 E[Xk] =
3
(0,1) x Î½(dx) < âˆ.
Thus X < âˆalmost surely and Î± + n
k=0 Xk
nâ†’âˆ
â‡’X. Therefore,
âˆ’log E
)
eâˆ’tX*
= Î±t âˆ’
âˆ

k=0
log E
)
eâˆ’tXk*
= Î±t +
 
1 âˆ’eâˆ’tx
Î½(dx).
â€œUniquenessâ€ For x, t > 0, we have
0 â‰¤tâˆ’1 (1 âˆ’eâˆ’tx) â‰¤x âˆ§1
t
tâ†’âˆ
âˆ’â†’0.
By the dominated convergence theorem with dominating function 1 âˆ§x for t â‰¥1,
we infer
tâˆ’1

(1 âˆ’eâˆ’tx) Î½(dx)
tâ†’âˆ
âˆ’â†’0.
Thus we can compute Î± as
Î± = lim
tâ†’âˆu(t)/t.
Deï¬ne the map h : (0, âˆ) â†’(0, 1) by
h(x) = 1 âˆ’1 âˆ’eâˆ’x
x
.
Note that h(x)/(1 âˆ§x) â‰¤1 for all x > 0. Hence ËœÎ½ := hÎ½ is a ï¬nite measure and
Î½ = hâˆ’1ËœÎ½ is uniquely deï¬ned by ËœÎ½. Let
u(t) := Î±
2 + u(t) âˆ’
 t+1
t
u(s) ds
=

eâˆ’tx

1 âˆ’
 1
0
eâˆ’sxds

Î½(dx) =

eâˆ’tx ËœÎ½(dx).
That is, u is the Laplace transform of ËœÎ½ which determines ËœÎ½ and Î½ uniquely.
âŠ“âŠ”

16.1
LÃ©vyâ€“Khinchin Formula
375
Example 16.15 For an inï¬nitely divisible distribution Î¼ on [0, âˆ), we can compute
the LÃ©vy measure Î½ by the vague limit
Î½ = v-lim
nâ†’âˆnÎ¼âˆ—1/n
(0,âˆ).
(16.7)
Often Î± is also easy to obtain (e.g., via the representation from Exercise 16.1.3). For
example, for the Gamma distribution, we get Î± = 0 and
nÎ“Î¸,1/n(A) =
Î¸1/n
Î“ (1/n)/n

A
x(1/n)âˆ’1 eâˆ’Î¸x dx
nâ†’âˆ
âˆ’â†’

A
xâˆ’1 eâˆ’Î¸x dx,
hence Î½(dx) = xâˆ’1eâˆ’Î¸x dx. â™¦
For inï¬nitely divisible distributions on R, we would like to obtain a description
similar to that in the preceding theorem. However, an inï¬nitely divisible real random
variable X is not simply the difference of two inï¬nitely divisible nonnegative
random variables, as the normal distribution shows. In addition, we have more
freedom if, as in the last proof, we want to express X as a sum of independent
random variables Xk.
Hence we deï¬ne the real random variable X as the sum of independent random
variables,
X = b + XN + X0 +
âˆ

k=1
(Xk âˆ’Î±k),
(16.8)
where b âˆˆR, XN = N0,Ïƒ 2 for some Ïƒ 2 â‰¥0 and PXk = CPoiÎ½k with intensity
measure Î½k that is concentrated on Ik := (âˆ’1/k, âˆ’1/(k + 1)] âˆª[1/(k + 1), 1/k)
(with the convention 1/0 = âˆ), k âˆˆN0. Furthermore, Î±k = E[Xk] =
3
x Î½k(dx)
for k â‰¥1. In order for the series to converge almost surely, it is sufï¬cient (and also
necessary, as a simple application of Kolmogorovâ€™s three-series theorem shows) that
âˆ

k=1
Var[Xk] < âˆ.
(16.9)
(In contrast to the situation in Theorem 16.14, here it is not necessary to have
âˆ
k=1 E[|Xk âˆ’Î±k|] < âˆ. This allows for greater freedom in the choice of Î½ than
in the case of nonnegative random variables.) Now Var[Xk] =
3
x2 Î½k(dx). Hence,
if we let Î½ = âˆ
k=0 Î½k, then (16.9) is equivalent to
3
(âˆ’1,1) x2 Î½(dx) < âˆ. As Î½0 is
always ï¬nite, this in turn is equivalent to
3
(x2 âˆ§1) Î½(dx) < âˆ.

376
16
Inï¬nitely Divisible Distributions
Deï¬nition 16.16 A Ïƒ-ï¬nite measure Î½ on R is called a canonical measure if
Î½({0}) = 0 and
 
x2 âˆ§1

Î½(dx) < âˆ.
(16.10)
If Ïƒ 2 â‰¥0 and b âˆˆR, then (Ïƒ 2, b, Î½) is called a canonical triple.
To every canonical triple, by (16.8) there corresponds an inï¬nitely divisible random
variable. Deï¬ne
Ïˆ0(t) = log E)eitX0* =

I0
eitx âˆ’1 Î½(dx).
For k âˆˆN, let
Ïˆk(t) = log E
)
eit(Xkâˆ’Î±k)*
=

Ik

eitx âˆ’1 âˆ’itx

Î½(dx).
(Note that it is not a priori clear, that the logarithm in the two equations above is
well-deï¬ned. In general, the expectation could be zero for some t. However, the
right hand sides are well-deï¬ned and by (16.1) are the exponentials of the left hand
sides. Hence the logarithms could be applied on both sides. This also shows that the
expectations on the left hand side never equal zero. Hence
Ïˆ(t) := log E
)
eitX*
= âˆ’Ïƒ 2
2 t2 + ibt +
âˆ

k=0
Ïˆk(t)
satisï¬es the LÃ©vyâ€“Khinchin formula
Ïˆ(t) = âˆ’Ïƒ 2
2 t2 + ibt +
 
eitx âˆ’1 âˆ’itx 1{|x|<1}

Î½(dx).
(16.11)
Theorem 16.17 (LÃ©vyâ€“Khinchin formula) LetÎ¼ âˆˆM1(R) and
Ïˆ(t) := log

eitx Î¼(dx).
Î¼ is inï¬nitely divisible if and only if Ïˆ is well-deï¬ned and there exists a canonical
triple (Ïƒ 2, b, Î½) such that (16.11) holds. By (16.11), this triple is uniquely deter-
mined.
Again, Î½ is called the LÃ©vy measure of Î¼, Ïƒ 2 is called the Gaussian coefï¬cient and
b is called the centering constant.

16.1
LÃ©vyâ€“Khinchin Formula
377
Proof We have shown already that via (16.11) every canonical triple (Ïƒ 2, b, Î½)
corresponds to an inï¬nitely divisible distribution Î¼. It remains to show:
(i) A canonical triple is uniquely determined by (16.11).
(ii) For every inï¬nitely divisible distribution, there exists a canonical triple such
that (16.11) holds.
(i) Uniqueness. For Îµ âˆˆ[0, 1/2) and t â‰¥0, deï¬ne
gt,Îµ(x) = eitx âˆ’1 âˆ’itx 1{|x|<1âˆ’Îµ}.
For Îµ = 0, this is the function in the LÃ©vy-Khinchin formula (16.11). However,
since we will work with weak convergence and since gt,Îµ is discontinuous at
x = âˆ’(1 âˆ’Îµ) and x = 1 âˆ’Îµ, we will later need to adjust the parameter Îµ in
such a way that Î½ does not have atoms at these points of discontinuity. Finally,
we will let Îµ â†’0.
Obviously, we have |gt,Îµ(x)| â‰¤2 + |t|. Hence, for x Ì¸= 0,

gt,Îµ(x)
t2(1 âˆ§x2)
 â‰¤2 + |t|
t2
1
1 âˆ§x2
tâ†’âˆ
âˆ’â†’0.
(16.12)
For x âˆˆ(âˆ’1/2, 1/2), by Lemma 15.31, we have
gt,Îµ(x)
 =
eitx âˆ’1 âˆ’itx
 â‰¤(tx)2.
For t â‰¥1, Îµ âˆˆ[0, 1/2) and x Ì¸= 0, we thus have (note that (2 + |t|)/t2 â‰¤3)

gt,Îµ(x)
t2(1 âˆ§x2)
 â‰¤12.
(16.13)
Since (16.10) holds, by the dominated convergence theorem,
lim
tâ†’âˆ
Ïˆ(t)
t2
= âˆ’Ïƒ 2
2 + lim
tâ†’âˆ
ib
t + lim
tâ†’âˆ
 âˆ
âˆ’âˆ

gt(x)
t2(1 âˆ§x2)

(1 âˆ§x2)Î½(dx)
= âˆ’Ïƒ 2
2 .
(16.14)
This implies the uniqueness of Ïƒ 2. Thus we can and will assume Ïƒ 2 = 0 in the
following. Deï¬ne
Ïˆ(t) = Ïˆ(t) âˆ’1
2
 t+1
tâˆ’1
Ïˆ(s) ds.
(16.15)

378
16
Inï¬nitely Divisible Distributions
Then
Ïˆ(t) =

R
eitx

1 âˆ’1
2
 1
âˆ’1
eisx ds

Î½(dx) =

eitx h(x) Î½(dx),
(16.16)
where h(x) = 1 âˆ’sin(x)
x
for x Ì¸= 0 and h(0) = 0. Deï¬ne Ë†h(x) = h(x)/(1 âˆ§x2)
for x Ì¸= 0 and Ë†h(0) = 1/6. Clearly, h and Ë†h are bounded and continuous and
1
7 < 1 âˆ’sin(1) â‰¤Ë†h(x) â‰¤3
2
for any x âˆˆR.
(16.17)
Ïˆ is the characteristic function of ËœÎ½ âˆˆMf (R), where ËœÎ½(dx) = h(x)Î½(dx).
Hence ËœÎ½ is uniquely determined by Ïˆ. Since Î½(dx) = (1{xÌ¸=0}/h(x))ËœÎ½(dx), Î½
is also uniquely determined by Ïˆ. Now the number b is the difference of the
remaining terms.
(ii) Existence of a canonical triple. Let Î¼ be inï¬nitely divisible and let
Ïˆ(t) = log

eitx Î¼(dx).
Clearly, Im(Ïˆ) is odd and Re(Ïˆ(t)) â‰¤0 for all t âˆˆR. Hence Ïˆ(0) â‰¥0 (with Ïˆ
from (16.15)) and Ïˆ(0) = 0 if ReÏˆ(t) = for all t âˆˆ[âˆ’1, t]. By Exercise 15.2.4,
this is the case if and only if Î¼ = Î´b for some b âˆˆR. In this case, (0, b, 0) is
the corresponding canonical triple.
Now assume Ïˆ(0) > 0. By Theorem 16.5, there exists a sequence (Î½n)nâˆˆN in
Mf (R) with CPoiÎ½n
nâ†’âˆ
âˆ’â†’Î¼ and Î½n({0}) = 0 for any n âˆˆN. Deï¬ne
bn,Îµ =

x 1{|x|<1âˆ’Îµ} Î½n(dx)
for Îµ âˆˆ[0, 1/2).
Then, by (16.1) and with gt,Îµ from (i) (and for any Îµ âˆˆ[0, 1/2)),
Ïˆn(t) := log

eitx CPoiÎ½n(dx) =

(eitx âˆ’1) Î½n(dx) =

gt,Îµ dÎ½n + ibn,Îµt.
As in (16.16), we have
Ïˆn(t) := Ïˆn(t) âˆ’1
2
 t+1
tâˆ’1
Ïˆn(s) ds =

eitx h(x) Î½n(dx).

16.1
LÃ©vyâ€“Khinchin Formula
379
As Ïˆn
nâ†’âˆ
âˆ’â†’
Ïˆ converges uniformly on compact sets (Theorem 15.24(i)), and
since Ïˆ is continuous and thus locally bounded, we have Ïˆn
nâ†’âˆ
âˆ’â†’Ïˆ pointwise.
Therefore,

eitx h(x) Î½n(dx)
nâ†’âˆ
âˆ’â†’Ïˆ(t).
(16.18)
In particular, Ïˆn(0) > 0 for large n. If we let ËœÎ½n(dx) = (h(x)/Ïˆn(0))Î½n(dx) âˆˆ
M1(R), then
3
eitx ËœÎ½n(dx)
nâ†’âˆ
âˆ’â†’Ïˆ(t)/Ïˆ(0) and the right-hand side is continuous.
Hence, by LÃ©vyâ€™s continuity theorem, there is a ËœÎ½ âˆˆM1(R) with ËœÎ½n
nâ†’âˆ
âˆ’â†’ËœÎ½ and
Ïˆ(t) = Ïˆ(0)

eitx ËœÎ½(dx).
Let Ïƒ 2 := âˆ’6 Ïˆ(0) ËœÎ½({0}) and deï¬ne a canonical measure Î½ by
Î½(dx) = Ïˆ(0)
h(x) 1{xÌ¸=0} ËœÎ½(dx).
For any t âˆˆR and Îµ âˆˆ[0, 1/2), the map (compare (15.8))
ft,Îµ : R â†’C,
x â†’
 gt,Îµ(x)
h(x) ,
if x Ì¸= 0,
âˆ’3t2,
if x = 0,
is continuous except for the points |x| = 1 âˆ’Îµ and is bounded (by 84 t2, see (16.13)
and (16.17)). Since Î½((âˆ’1/2, 1/2)c) < âˆ, the set of Îµ such that Î½({1 âˆ’Îµ} âˆª{âˆ’1 +
Îµ}) = 0 is dense in [0, 1/2]. Let (Îµk)kâˆˆN be a sequence in [0, 1/2] such that Îµk â†“0
and Î½({1 âˆ’Îµk} âˆª{âˆ’1 + Îµk}) = 0. Fix k âˆˆN. By the Portemanteau Theorem
(Theorem 13.16(iii)), we infer

gt,Îµk dÎ½n = Ïˆn(0)

ft,Îµk d ËœÎ½n
nâ†’âˆ
âˆ’â†’Ïˆ(0)

ft,Îµk d ËœÎ½ = âˆ’Ïƒ 2
2 t2 +

gt,Îµk dÎ½.
Hence also the limit
it bÎµk := lim
nâ†’âˆit bn,Îµk = lim
nâ†’âˆ

Ïˆn(t) âˆ’

gt,Îµk dÎ½n

= Ïˆ(t) + Ïƒ 2
2 t2 âˆ’

gt,Îµk dÎ½
exists and we have
Ïˆ(t) = âˆ’Ïƒ 2
2 t2 + ibÎµkt +

gt,Îµk dÎ½.

380
16
Inï¬nitely Divisible Distributions
As |gt,Îµk(x)| â‰¤12t2(1 âˆ§x2), and since gt,Îµk(x)
kâ†’âˆ
âˆ’â†’
gt,0(x), the dominated
convergence theorem yields

gt,0 dÎ½ = lim
kâ†’âˆ

gt,Îµk dÎ½.
Also, since Î½((âˆ’1/2, 1/2)c) < âˆ, the limit
b := lim
kâ†’âˆbÎµk
exists and we have
Ïˆ(t) = âˆ’Ïƒ 2
2 t2 + ibt +

gt,0 dÎ½.
âŠ“âŠ”
Remark 16.18 There are many versions of the LÃ©vyâ€“Khinchin formula
Ïˆ(t) = âˆ’Ïƒ 2
2 t2 + ibt +
 
eitx âˆ’1 âˆ’it f (x)

Î½(dx)
that differ in the function it f (x) that is subtracted for the centering in the integral.
We chose f (x) = x 1{|x|<1} since this ï¬ts best to the construction with the random
variables Xk. However, for a given canonical measure Î½, any function Ëœf for which
3 |f âˆ’Ëœf | dÎ½ < âˆholds is possible; that is, every Ëœf for which |f (x)âˆ’Ëœf (x)|/(1âˆ§x2)
is bounded. One common function is, e.g., Ëœf (x) = sin(x). The LÃ©vy measure and
the Gaussian coefï¬cient Ïƒ 2 do not change but the b differs:
Ëœb âˆ’b =
  Ëœf âˆ’f  dÎ½.
If Î½ is a measure that is concentrated on (0, âˆ) and such that
3
(1 âˆ§x) Î½(dx) < âˆ
holds, then this f is integrable with respect to Î½ and can thus be replaced by Ëœf = 0.
Hence we recover Theorem 16.14 as a special case. However, condition (16.10) is
weaker than
3
(1 âˆ§x) Î½(dx) < âˆand thus describes a larger class of measures than
is considered in Theorem 16.14. This implies that to a canonical triple (b, 0, Î½) with
Î½((âˆ’âˆ, 0)) = 0 and
3
(1 âˆ§x) Î½(dx) = âˆ, there corresponds an inï¬nitely divisible
probability distribution Î¼ that is not concentrated on [0, âˆ), no matter how b is
chosen. â™¦
Reï¬‚ection In the proof of Theorem 16.17, why was it necessary to introduce the
Îµ > 0? How can we get rid of this technicality by replacing the function f (x) =
x 1{|x|<1} by Ëœf (x) = sin(x), as in Remark 16.18? What are the problems that come
with this approach? â™ â™ 

16.2
Stable Distributions
381
For a given inï¬nitely divisible distribution Î¼, we can compute the canonical measure
Î½ as the vague limit
Î½ = v-lim
nâ†’âˆnÎ¼âˆ—1/n
R\{0}.
(16.19)
Example 16.19 For the Cauchy distribution Caua with Ïˆ(t) = âˆ’a |t|, by symme-
try, we get b = 0 and, by (16.14), Ïƒ 2 = âˆ’2 limtâ†’âˆÏˆ(t)/t2 = 0. Finally, if A âŠ‚R
with (âˆ’Îµ, Îµ) âˆ©A = âˆ…for some Îµ > 0, then
n Cau1/n(A) = 1
Ï€

A
n2
1 + (nx)2 dx
nâ†’âˆ
âˆ’â†’
1
Ï€

A
1
x2 dx.
Hence Cau1 has the canonical triple

0, 0, (Ï€x2)âˆ’1dx

. â™¦
Takeaways An inï¬nitely divisible random variable can be written as a sum
of arbitrarily many independent and identically distributed random variables.
On the other hand, it can also be split into three characteristic parts: a
deterministic number, a normally distributed random variable and a mixture
of Poisson jumps of various sizes (LÃ©vy-Khinchin formula). Every inï¬nitely
divisible distribution is a weak limit of compound Poisson distributions.
Exercise 16.1.1 Use a variance argument to show that an inï¬nitely divisible
distribution that is concentrated on a bounded interval is a Dirac measure. â™£
Exercise 16.1.2 Let Ï• be inï¬nitely divisible, and for every n âˆˆN, let Ï•n be a CFP
with Ï•n
n = Ï•. Use LÃ©vyâ€™s continuity theorem to show that Ï•n
nâ†’âˆ
âˆ’â†’1 uniformly on
compact sets Ï•n
nâ†’âˆ
âˆ’â†’1. Conclude that Ï•(t) Ì¸= 0 for all t âˆˆR. â™£
Exercise 16.1.3 Under the conditions of Theorem 16.14, show that
Î± = sup
	
x â‰¥0 : Î¼([0, x)) = 0

.
â™£
16.2
Stable Distributions
A distribution Î¼ on the real numbers is called stable if for any n âˆˆN, the n-fold
convolution Î¼âˆ—n equals Î¼ up to an afï¬ne linear transformation. Hence stability can
be interpreted as self-similarity. We ï¬rst show that the class of stable distributions
is rather simple and can easily be parameterized. Then we quote results which say
that stable distributions are exactly those distributions that occur as limits of sums
of i.i.d. random variables.

382
16
Inï¬nitely Divisible Distributions
Symmetric Stable Distributions
For Î± âˆˆ(0, 2), let
Î¸Î± :=

R
(1 âˆ’cos(x)) |x|âˆ’Î±âˆ’1 dx =
0âˆ’2Î“ (âˆ’Î±) cos(Î±Ï€/2),
if Î± Ì¸= 1,
Ï€,
if Î± = 1.
(Note that the integral diverges for Î± âˆˆR\(0, 2)). Then Î½Î±(dx) = Î¸âˆ’1
Î±
|x|âˆ’Î±âˆ’1 dx
is a canonical measure since

(1 âˆ§x2) Î½Î±(dx) = 2 Î¸âˆ’1
Î±

Î±âˆ’1 + (2 âˆ’Î±)âˆ’1
< âˆ.
Let ÏˆÎ± be the logarithm of the characteristic function that corresponds to the
inï¬nitely divisible measure Î¼Î± with canonical triple (0, 0, Î½Î±). By the LÃ©vyâ€“
Khinchin formula, we have
ÏˆÎ±(t) =
 âˆ
âˆ’âˆ
eitx âˆ’1 âˆ’itx 1{|x|<1}
 Î¸âˆ’1
Î±
|x|âˆ’Î±âˆ’1 dx
= âˆ’Î¸âˆ’1
Î±
 âˆ
âˆ’âˆ
1 âˆ’cos(tx) |x|âˆ’Î±âˆ’1 dx
= âˆ’|t|Î±.
Hence Ï•Î±(t) := eâˆ’|t|Î± is the characteristic function of the inï¬nitely divisible
measure Î¼Î±, which is called the symmetric stable distribution with index Î±. The
name is due to the fact that, for i.i.d. random variables X1, X2, . . . that are Î¼Î±-
distributed, we have
X1 + . . . + Xn
D= n1/Î±Xn
for all n âˆˆN.
(16.20)
General Stable Distributions
Motivated by equation (16.20), we present a somewhat more general notion of
stability of a distribution.
Deï¬nition 16.20 (Stable distribution) Let Î¼ âˆˆM1(R) be a probability distri-
bution on the real numbers that is not concentrated in one point. Assume that
X1, X2, . . . are i.i.d. random variables with distribution Î¼. The distribution Î¼ is

16.2
Stable Distributions
383
said to be stable in the broad sense if there exist nonnegative numbers a1, a2, . . .
and real numbers d1, d2, . . . such that
X1 + . . . + Xn
D= an X1 + dn
for all n âˆˆN.
(16.21)
Î¼ is called stable (in the strict sense), if (16.21) holds with d1 = d2 = . . . = 0.
Î¼ is called stable in the broad sense with index Î± âˆˆ(0, 2], if (16.21) holds with
an = n1/Î±, n âˆˆN. It is called stable (in the strict sense) with index Î± âˆˆ(0, 2], if in
addition, we can choose d1 = d2 = . . . = 0.
Remark 16.21 If Î¼ is stable in the broad sense, then it is inï¬nitely divisible. â™¦
Theorem 16.22 Let Î¼ be stable in the broad sense.
(i) There is an Î± âˆˆ(0, 2] such that Î¼ is stable in the broad sense with index Î±.
(ii) If Î± = 2, then Î¼ is a normal distribution.
(iii) If Î± âˆˆ(0, 2), then the LÃ©vy measure Î½ of Î¼ has the density
Î½(dx)
dx
=

câˆ’(âˆ’x)âˆ’Î±âˆ’1,
if x < 0,
c+ xâˆ’Î±âˆ’1,
if x > 0,
(16.22)
for some câˆ’, c+ â‰¥0, câˆ’+ c+ > 0.
(iv) If Î± Ì¸= 1, then there exists a b âˆˆR such that Î¼ âˆ—Î´âˆ’b is stable with index Î±.
(v) If Î± = 1, then dn = (c+ âˆ’câˆ’) n log(n), n âˆˆN. If câˆ’= c+, then Î¼ is a
Cauchy distribution.
Remark 16.23 If Î¼ is inï¬nitely divisible with LÃ©vy measure Î½ given by (16.22),
then Ïˆ(t) := log
3
eitx Î¼(dx) is given by
Ïˆ(t)=
â§
â¨
â©
|t|Î±Î“ (âˆ’Î±)
)
(c+ + câˆ’) cos
 Ï€Î±
2

âˆ’i sign(t) (c+ âˆ’câˆ’) sin
 Ï€Î±
2
*
, Î± Ì¸= 1,
âˆ’|t|(c+ + câˆ’)
)Ï€
2 + i sign(t)(c+ âˆ’câˆ’) log(|t|)
*
, Î± = 1.
(16.23)
â™¦
Lemma 16.24 Let Î¼ be inï¬nitely divisible with canonical triple (Ïƒ 2, b, Î½); that is,
with log-characteristic function Ïˆ(t) := log
 3
eitxÎ¼(dx)

given by
Ïˆ(t) = âˆ’Ïƒ 2
2 t2 + ibt +
 
eitx âˆ’1 âˆ’itx 1{|x|<1}

Î½(dx).
Further, let a > 0, d âˆˆR, n âˆˆN and let X, X1, . . . , Xn be i.i.d. random variables
with distribution Î¼.
(i) The canonical triple of X1 + . . . + Xn is (nÏƒ 2, nb, nÎ½).

384
16
Inï¬nitely Divisible Distributions
(ii) The canonical triple of aX + d is (a2Ïƒ 2, Ëœb, Î½ â—¦mâˆ’1
a ), where ma : R â†’R,
x â†’ax is the multiplication by a and
Ëœb := ab + d + a

(1{|x|<1/a} âˆ’1{|x|<1})x Î½(dx).
(16.24)
Proof
(i) The log-characteristic function of X1 + . . . + Xn is nÏˆ.
(ii) The log-characteristic function of aX + d is
ÏˆaX+d(t) = Ïˆ(at) + idt
= âˆ’a2Ïƒ 2
2
t2 + i(ab + d)t +
 
eiatx âˆ’1 âˆ’iatx 1{|x|<1}

Î½(dx)
= âˆ’a2Ïƒ 2
2
t2 + i Ëœbt +
 
eiatx âˆ’1 âˆ’iatx 1{|x|<1/a}

Î½(dx)
= âˆ’a2Ïƒ 2
2
t2 + i Ëœbt +
 
eitx âˆ’1 âˆ’itx 1{|x|<1}

Î½ â—¦mâˆ’1
a (dx).
âŠ“âŠ”
Lemma 16.25 (Scaling of the canonical triple) Under the assumptions of Theo-
rem 16.22, let (Ïƒ 2, b, Î½) be the canonical triple of Î¼.
(i) We have
(a2
n âˆ’n)Ïƒ 2 = 0
for all n âˆˆN
(16.25)
and (with man as in Lemma 16.24)
nÎ½ = Î½ â—¦mâˆ’1
an
for all n âˆˆN.
(16.26)
(ii) If Î½ = 0, then an = n1/2 for all n âˆˆN and
dn = b

n âˆ’n1/2).
(16.27)
(iii) Assume that Î± âˆˆ(0, 2), an = n1/Î±, and that Î½ is given by (16.22). Then we
have
dn =

b + c+ âˆ’câˆ’
Î± âˆ’1
 n âˆ’n1/Î±
if Î± Ì¸= 1,
(16.28)
and
dn = (c+ âˆ’câˆ’) n log(n)
if Î± = 1.
(16.29)

16.2
Stable Distributions
385
Proof
(i) Let (a2
nÏƒ 2, Ëœbn, Î½â—¦mâˆ’1
an ) be the canonical triple of anX+dn as determined in the
preceding lemma and let (nÏƒ 2, nb, nÎ½) be the canonical triple of X1+. . .+Xn.
By (16.21) and due to the uniqueness of the canonical triple (Theorem 16.17),
we infer a2
nÏƒ 2 = nÏƒ 2, Ëœbn = nb and Î½ â—¦mâˆ’1
an = nÎ½.
(ii) If Î½ = 0, then Ïƒ 2 > 0, since by assumption, Î¼ is not concentrated in one point.
Hence, by (16.25), we get an = n1/2. By virtue of Lemma 16.24(ii), we have
nb = Ëœbn = bn1/2 + dn and thus (16.27) holds.
(iii) Using (16.24), we compute Ëœbn more explicitly:
nb = Ëœbn = bn1/Î± + dn âˆ’n1/Î±

1{nâˆ’1/Î±â‰¤|x|<1}x Î½(dx)
= bn1/Î± + dn âˆ’n1/Î±(c+ âˆ’câˆ’)
 1
nâˆ’1/Î± xâˆ’Î± dx
= bn1/Î± + dn âˆ’(c+ âˆ’câˆ’)

(1 âˆ’Î±)âˆ’1(n1/Î± âˆ’n),
if Î± Ì¸= 1,
n log(n),
if Î± = 1.
Rearranging terms yields (16.28) and (16.29).
âŠ“âŠ”
Proof (of Theorem 16.22) We distinguish the cases lim infnâ†’âˆan nâˆ’1/2 < âˆand
â€œ= âˆâ€.
Case 1.
Assume that lim infnâ†’âˆan nâˆ’1/2 < âˆ. Let C âˆˆ[1, âˆ) and let (nk)kâˆˆN
be a subsequence such that ank nâˆ’1/2
k
â‰¤C for any k âˆˆN. Then for any x âˆˆR \ {0},
we have
C2 â‰¥nâˆ’1
k (1 âˆ¨a2
nk) â‰¥
nâˆ’1
k (1 âˆ§a2
nkx2)
1 âˆ§x2
kâ†’âˆ
âˆ’â†’0.
Using (16.26) and (16.10), the dominated convergence theorem yields
 âˆ
âˆ’âˆ
(1 âˆ§x2) Î½(dx) =
 âˆ
âˆ’âˆ
nâˆ’1
k (1 âˆ§a2
nkx2)
1 âˆ§x2
(1 âˆ§x2) Î½(dx)
kâ†’âˆ
âˆ’â†’0.
That is, we have Î½ = 0. By Lemma 16.25(ii), we see that Î¼ âˆ—Î´âˆ’b is stable with
index 2. This shows (ii).
Case 2.
Assume that
an nâˆ’1/2 nâ†’âˆ
âˆ’â†’âˆ.
(16.30)

386
16
Inï¬nitely Divisible Distributions
By (16.25), we have Ïƒ 2 = 0 and hence Î½ Ì¸= 0. We deï¬ne the function
F(x) =

Î½([x, âˆ)),
if x > 0,
Î½((âˆ’âˆ, x]),
if x < 0.
Since we have Î½ Ì¸= 0, there is an x0 âˆˆR \ {0} such that F(x0) > 0. By symmetry,
we may assume that x0 > 0. Using (16.26), we infer
n F(x) = F(x/an)
for any x âˆˆR \ {0}, n âˆˆN,
and thus
F
an+1
an
k
x0

=

n
n + 1
k
F(x0)
for any k âˆˆZ.
We can rephrase this as
F(x) = (x/x0)âˆ’Î±nF(x0)
for any x âˆˆ	(an+1/an)k x0 : k âˆˆZ
,
where Î±n := log((n + 1)/n)/ log(an+1/an). Since F is monotone decreasing and
since F(x)
xâ†’âˆ
âˆ’â†’0, we have Î±n > 0 for all n âˆˆN, and

m
m + 1
  x
x0
âˆ’Î±m
â‰¤F(x)
F(x0) â‰¤
n + 1
n
  x
x0
âˆ’Î±n
for x > 0, m, n âˆˆN.
Letting x â†’âˆ, we obtain Î±m â‰¥Î±n. By symmetry, we also get Î±m â‰¤Î±n. Hence,
we deï¬ne Î± := Î±1 > 0 and get an = n1/Î± for all n âˆˆN (note that (16.21) implies
a1 = 1). By the assumption (16.30), we have Î± < 2. This shows (i).
We have F(1) = xÎ±
0 F(x0) > 0 and F(x) = xâˆ’Î± F(1) for all x > 0. Similarly,
we get F(x) = (âˆ’x)âˆ’Î±F(âˆ’1) for x < 0 (with the same Î± âˆˆ(0, 2) since it
is determined by the sequence (an)nâˆˆN). Deï¬ning c+ = Î± Î½([1, âˆ)) and câˆ’:=
Î±Î½((âˆ’âˆ, âˆ’1]), we get (16.22) and thus (iii) and (i).
The statements (iv) and (v) are immediate consequences of Lemma 16.25.
âŠ“âŠ”
Convergence to Stable Distributions
To complete the picture, we cite theorems from [54, Chapter XVII.5] (see also [62]
and [128]) that state that only stable distributions occur as limiting distributions of
rescaled sums of i.i.d. random variables X1, X2, . . ..
In the following, let X, X1, X2, . . . be i.i.d. random variables and for n âˆˆN, let
Sn = X1 + . . . + Xn.

16.2
Stable Distributions
387
Deï¬nition 16.26 (Domain of attraction) Let Î¼ âˆˆM1(R) be nontrivial. The
domain of attraction Dom(Î¼) âŠ‚M1(R) is the set of all distributions PX with
the property that there exist sequences of numbers (an)nâˆˆN and (dn)nâˆˆN with
Sn âˆ’dn
an
nâ†’âˆ
â‡’Î¼.
If Î¼ is stable (in the broader sense) with index Î± âˆˆ(0, 2], then PX is said to be in
the domain of normal attraction if we can choose an = n1/Î±.
Theorem 16.27 Let Î¼ âˆˆM1(R) be nontrivial. Then Dom(Î¼) Ì¸= âˆ…if and only if Î¼
is stable (in the broader sense). In this case, Î¼ âˆˆDom(Î¼).
In the following, an important role is played by the function
U(x) := E)X2 1{|X|â‰¤x}
*.
(16.31)
A function H : (0, âˆ) â†’(0, âˆ) is called slowly varying at âˆif
lim
xâ†’âˆ
H(Î³ x)
H(x) = 1
for all Î³ > 0.
In the following, we assume that there exists an Î± âˆˆ(0, 2] such that
U(x) xÎ±âˆ’2 is slowly varying at âˆ.
(16.32)
Theorem 16.28
(i) If PX is in the domain of attraction of some distribution, then there exists an
Î± âˆˆ(0, 2] such that (16.32) holds.
(ii) In the case Î± = 2, we have: If PX is not concentrated at one point, then (16.32)
implies that PX is in the domain of attraction of some distribution.
(iii) In the case Î± âˆˆ(0, 2), we have: PX is in the domain of attraction of some
distribution if and only if (16.32) holds and the limit
p := lim
xâ†’âˆ
P[X â‰¥x]
P[|X| â‰¥x]
exists.
(16.33)
Theorem 16.29 Let PX be in the domain of attraction of an Î±-stable distribution
(that is, assume that condition (ii) or (iii) of Theorem 16.28 holds), and assume that
(an)nâˆˆN is such that
C := lim
nâ†’âˆ
n U(an)
a2n
âˆˆ(0, âˆ)
exists. Further, let Î¼ be the stable distribution with index Î± whose characteristic
function is given by (16.23) with c+ = Cp and câˆ’= C(1 âˆ’p).

388
16
Inï¬nitely Divisible Distributions
(i) In the case Î± âˆˆ(0, 1), let bn â‰¡0.
(ii) In the case Î± = 2 and Var[X] < âˆ, let E[X] = 0.
(iii) In the case Î± âˆˆ(1, 2], let dn = n E[X] for all n âˆˆN.
(iv) In the case Î± = 1, let dn = n an E[sin(X/an)] for all n âˆˆN.
Then
Sn âˆ’dn
an
nâ†’âˆ
â‡’Î¼.
Corollary 16.30 If PX is in the domain of attraction of a stable distribution with
index Î±, then E
)
|X|Î²*
< âˆfor all Î² âˆˆ(0, Î±) and E
)
|X|Î²*
= âˆif Î² > Î± and
Î± < 2.
Takeaways A random variable X is called inï¬nitely divisible if for any n âˆˆN
it can be written as a sum of n independent and identically distributed random
variables. It is called stable if each of the summands has the same distribution
as bn + X/an for some sequences (an) and (bn). We have seen that in this
case, we must have an = n1/Î± for some Î± âˆˆ(0, 2]. A stable distribution is
characterised by its index Î± and a skewness parameter (and, of course, a scale
parameter); see Remark 16.23.
Exercise 16.2.1 Let Î¼ be an Î±-stable distribution and let Ï• be its characteristic
function.
(i) Show by a direct computation using only the deï¬nition of stability that
|Ï•(t) âˆ’1| â‰¤C|t|Î± for t close to 0 (for some C < âˆ).
(ii) Use Exercise 15.3.2 to infer that Î¼ = Î´0 if Î± > 2.
(iii) Modify the argument in order to show that for Î± > 2, the Î±-stable distributions
in the broad sense are also necessarily trivial. â™£
Exercise 16.2.2 Show that the distribution on R with density f (x) = 1 âˆ’cos(x)
Ï€x2
is not inï¬nitely divisible. â™£
Exercise 16.2.3 Let Î¦ be the distribution function of the standard normal distribu-
tion N0,1 and let F : R â†’[0, 1] be deï¬ned by
F(x) =

2

1 âˆ’Î¦

xâˆ’1/2
,
if x > 0,
0,
else.
Show the following.
(i) F is the distribution function of a 1
2-stable distribution.
(ii) If X1, X2, . . . are i.i.d. with distribution function F, then 1
n
n
k=0 Xk diverges
almost surely for n â†’âˆ.

16.2
Stable Distributions
389
Hint: Compute the density of F, and show that the Laplace transform is given by
Î» â†’eâˆ’
âˆš
2Î». â™£
Exercise 16.2.4 Which of the following distributions is in the domain of attraction
of a stable distribution and for which parameter?
(i) The distribution on R with density
f (x) =
â§
âªâªâ¨
âªâªâ©
Ï±
1
1+Î± |x|Î±,
if x < âˆ’1,
(1 âˆ’Ï±)
1
1+Î² xÎ²,
if x > 1,
0,
else.
Here Î±, Î² < âˆ’1 and Ï± âˆˆ[0, 1].
(ii) The exponential distribution expÎ¸ for Î¸ > 0.
(iii) The distribution on N with weights c nÎ± if n is even and c nÎ² if n is odd. Here
Î±, Î² < âˆ’1 and c = (2Î±Î¶(âˆ’Î±) + (1 âˆ’2Î²)Î¶(âˆ’Î²))âˆ’1 (Î¶ is the Riemann zeta
function) is the normalization constant. â™£

Chapter 17
Markov Chains
In spite of their simplicity, Markov processes with countable state space (and
discrete time) are interesting mathematical objects with which a variety of real-
world phenomenacan be modeled. We give an introduction to the basic concepts and
then study certain examples in more detail. The connection with discrete potential
theory will be investigated later, in Chap. 19. Some readers might prefer to skip the
somewhat technical construction of general Markov processes in Sect. 17.1.
There is a vast literature on Markov chains. For further reading, see, e.g., [21, 26,
64, 66, 91, 116, 123, 124, 144, 153].
17.1
Deï¬nitions and Construction
In the following, E is always a Polish space with Borel Ïƒ-algebra B(E), I âŠ‚R and
(Xt)tâˆˆI is an E-valued stochastic process. We assume that (Ft)tâˆˆI = F = Ïƒ(X) is
the ï¬ltration generated by X.
Deï¬nition 17.1 We say that X has the Markov property (MP) if, for every A âˆˆ
B(E) and all s, t âˆˆI with s â‰¤t,
P
)
Xt âˆˆA
Fs
*
= P
)
Xt âˆˆA
Xs
*
.
Remark 17.2 If E is a countable space, then X has the Markov property if and
only if, for all n âˆˆN, all s1 < . . . < sn < t and all i1, . . . , in, i âˆˆE with
P[Xs1 = i1, . . . , Xsn = in] > 0, we have
P)Xt = i
Xs1 = i1, . . . , Xsn = in
* = P)Xt = i
Xsn = in
*.
(17.1)
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_17
391

392
17
Markov Chains
In fact, (17.1) clearly implies the Markov property. On the other hand, if X has the
Markov property, then (see (8.6)) P[Xt = i
Xsn](Ï‰) = P[Xt = i
Xsn = in] for
almost all Ï‰ âˆˆ{Xsn = in}. Hence, for A := {Xs1 = i1, . . . , Xsn = in} (using the
Markov property in the second equation),
P)Xt = i , Xs1 = i1, . . . , Xsn = in
*
= E)E[1{Xt=i}
Fsn] 1A
* = E)E[1{Xt=i}
Xsn] 1A
*
= E)P[Xt = i
Xsn = in] 1A
* = P)Xt = i
Xsn = in
* P[A].
Dividing both sides by P[A] yields (17.1). â™¦
Deï¬nition 17.3 Let I âŠ‚[0, âˆ) be closed under addition and assume 0 âˆˆI. A
stochastic process X = (Xt)tâˆˆI is called a time-homogeneous Markov process with
distributions (Px)xâˆˆE on the space (Î©, A) if:
(i) For every x âˆˆE, X is a stochastic process on the probability space (Î©, A, Px)
with Px [X0 = x] = 1.
(ii) The map Îº : E Ã— B(E)âŠ—I â†’[0, 1], (x, B) â†’Px[X âˆˆB] is a stochastic
kernel.
(iii) X has the time-homogeneous Markov property (MP): For every A âˆˆB(E),
every x âˆˆE and all s, t âˆˆI, we have
Px
)
Xt+s âˆˆA
Fs
*
= Îºt(Xs, A)
Px-a.s.
Here, for every t âˆˆI, the transition kernel Îºt : E Ã— B(E) â†’[0, 1] is the
stochastic kernel deï¬ned for x âˆˆE and A âˆˆB(E) by
Îºt(x, A) := Îº

x, {y âˆˆEI : y(t) âˆˆA}

= Px [Xt âˆˆA] .
The family (Îºt(x, A), t âˆˆI, x âˆˆE, A âˆˆB(E)) is also called the family of
transition probabilities of X.
We write Ex for expectation with respect to Px, Lx[X] = Px and Lx[X|F] =
Px[X âˆˆÂ· |F] (for a regular conditional distribution of X given F).
If E is countable, then X is called a discrete Markov process.
In the special case I = N0, X is called a Markov chain. In this case, Îºn is called
the family of n-step transition probabilities.
Remark 17.4 We will see that the existence of the transition kernels (Îºt) implies
the existence of the kernel Îº. Thus, a time-homogeneous Markov process is
simply a stochastic process with the Markov property and for which the transition
probabilities are time-homogeneous. Although it is sometimes convenient to allow
also time-inhomogeneous Markov processes, for a wide range of applications it is
sufï¬cient to consider time-homogeneous Markov processes. We will not go into the

17.1
Deï¬nitions and Construction
393
details but will henceforth assume that all Markov processes are time-homogeneous.
â™¦
In the following, we will use the somewhat sloppy notation PXs[X âˆˆ
Â·] :=
Îº(Xs, Â·). That is, we understand Xs as the initial value of a second Markov process
with the same distributions (Px)xâˆˆE.
Example 17.5 Let Y1, Y2, . . . be i.i.d. Rd-valued random variables and let
Sx
n = x +
n

i=1
Yi
for x âˆˆRd
and
n âˆˆN0.
Deï¬ne probability measures Px on (Rd)N0, (B(Rd))âŠ—N0 by Px = Pâ—¦(Sx)âˆ’1. Then
the canonical process Xn : (Rd)N0 â†’Rd is a Markov chain with distributions
(Px)xâˆˆRd. The process X is called a random walk on Rd with initial value x. â™¦
Example 17.6 In the previous example, it is simple to pass to continuous time; that
is, I = [0, âˆ). To this end, let (Î½t)tâ‰¥0 be a convolution semigroup on Rd and let
Îºt(x, dy) = Î´x âˆ—Î½t(dy). In Theorem 14.50, for every x âˆˆRd, we constructed a
measure Px on

(Rd)[0,âˆ), B(Rd)âŠ—[0,âˆ)
with
Px â—¦(X0, Xt1, . . . , Xtn)âˆ’1 = Î´x âŠ—
nâˆ’1
 
i=0
Îºti+1âˆ’ti
for any choice of ï¬nitely many points 0 = t0 < t1 < . . . < tn. It is easy to check
that the map Îº : Rd Ã— B(Rd)âŠ—[0,âˆ), (x, A) â†’Px[A] is a stochastic kernel. The
time-homogeneous Markov property is immediate from the fact that the increments
are independent and stationary. â™¦
Example 17.7 (See Example 9.5 and Theorem 5.36) Let Î¸ > 0 and Î½Î¸
t ({k}) =
eâˆ’Î¸t tkÎ¸k
k! , k âˆˆN0, the convolution semigroup of the Poisson distribution. The
Markov process X on N0 with this semigroup is called a Poisson process with
(jump) rate Î¸. â™¦
As in Example 17.6, we will construct a Markov process for a more general Markov
semigroup of stochastic kernels.
Theorem 17.8 Let I âŠ‚[0, âˆ) be closed under addition and let (Îºt)tâˆˆI be a
Markov semigroup of stochastic kernels from E to E. Then there is a measurable
space (Î©, A) and a Markov process ((Xt)tâˆˆI, (Px)xâˆˆE) on (Î©, A) with transition
probabilities
Px [Xt âˆˆA] = Îºt(x, A)
for all x âˆˆE, A âˆˆB(E), t âˆˆI.
(17.2)

394
17
Markov Chains
Conversely, for every Markov process X, Equation (17.2) deï¬nes a semigroup of
stochastic kernels. By (17.2), the ï¬nite-dimensional distributions of X are uniquely
determined.
Proof â€œ â‡’â€
We construct X as a canonical process. Let Î© = E[0,âˆ) and A =
B(E)âŠ—[0,âˆ). Further, let Xt be the projection on the tth coordinate. For x âˆˆE,
deï¬ne (see Corollary 14.46) on (Î©, A) the probability measure Px such that, for
ï¬nitely many time points 0 = t0 < t1 < . . . < tn, we have
Px â—¦(Xt0, . . . , Xtn)âˆ’1 = Î´x âŠ—
nâˆ’1
 
i=0
Îºti+1âˆ’ti.
Then
Px
)
Xt0 âˆˆA0, . . . , Xtn âˆˆAn
*
=

Anâˆ’1
Px
)
Xt0 âˆˆA0, . . . , Xtnâˆ’2 âˆˆAnâˆ’2, Xtnâˆ’1 âˆˆdxnâˆ’1
*
Îºtnâˆ’tnâˆ’1(xnâˆ’1, An);
hence Px[Xtn âˆˆAn|Ftnâˆ’1] = Îºtnâˆ’tnâˆ’1(Xtnâˆ’1, An). Thus X is recognized as a
Markov process. Furthermore, we have Px[Xt âˆˆA] = (Î´x Â· Îºt)(A) = Îºt(x, A).
â€œ â‡ â€
Now let (X, (Px)xâˆˆE) be a Markov process. Then a stochastic kernel Îºt is
deï¬ned by
Îºt(x, A) := Px [Xt âˆˆA]
for all x âˆˆE, A âˆˆB(E), t âˆˆI.
By the Markov property, we have
Îºt+s(x, A) = Px [Xt+s âˆˆA] = Ex
)
PXs [Xt âˆˆA]
*
=

Px [Xs âˆˆdy]Py [Xt âˆˆA]
=

Îºs(x, dy)Îºt(y, A) = (Îºs Â· Îºt) (x, A).
Hence (Îºt)tâˆˆI is a Markov semigroup.
âŠ“âŠ”
Theorem 17.9 A stochastic process X = (Xt)tâˆˆI is a Markov process if and only
if there exists a stochastic kernel Îº : E Ã— B(E)âŠ—I â†’[0, 1] such that, for every
bounded B(E)âŠ—I âˆ’B(R)-measurable function f : EI â†’R and for every s â‰¥0
and x âˆˆE, we have
Ex
)
f ((Xt+s)tâˆˆI)
Fs
*
= EXs [f (X)] :=

EI Îº(Xs, dy) f (y).
(17.3)

17.1
Deï¬nitions and Construction
395
Proof â€œ â‡ â€
The time-homogeneous Markov property follows by (17.3) with
the function f (y) = 1A(y(t)) since PXs[Xt âˆˆA] = Px[Xt+s âˆˆA|Fs] =
Îºt(Xs, A).
â€œ â‡’â€
By the usual approximation arguments, it is enough to consider functions
f that depend only on ï¬nitely many coordinates 0 â‰¤t1 â‰¤t2 â‰¤. . . â‰¤tn. We
perform the proof by induction on n.
For n
=
1 and f an indicator function, this is the (time-homogeneous)
Markov property. For general measurable f , the statement follows by the usual
approximation arguments.
Now assume the claim is proved for n âˆˆN. Again it sufï¬ces to assume that
f is an indicator function of the type f (x) = 1B1Ã—Â·Â·Â·Ã—Bn+1(xt1, . . . , xtn+1) (with
B1, . . . , Bn+1 âˆˆB(E)). Using the Markov property (third and ï¬fth equalities in the
following equation) and the induction hypothesis (fourth equality), we get
Ex
'
f (Xt+s)tâ‰¥0
Fs
(
= Ex
'
Ex
)
f

(Xt+s)tâ‰¥0
Ftn+s
*Fs
(
= Ex
'
Ex
)
1{Xtn+1+sâˆˆBn+1}
Ftn+s
*
1B1(Xt1+s) Â· Â· Â· 1Bn(Xtn+s)
Fs
(
= Ex
'
PXtn+s
)
Xtn+1âˆ’tn âˆˆBn+1
*
1B1(Xt1+s) Â· Â· Â· 1Bn(Xtn+s)
Fs
(
= EXs
'
PXtn
)Xtn+1âˆ’tn âˆˆBn+1
* 1B1(Xt1) Â· Â· Â· 1Bn(Xtn)
(
= EXs
'
PX0
)
Xtn+1 âˆˆBn+1
Ftn
*
1B1(Xt1) Â· Â· Â· 1Bn(Xtn)
(
= EXs
'
PX0
)
Xt1 âˆˆB1, . . . , Xtn+1 âˆˆBn+1
Ftn
*(
= EXs [f (X)] .
âŠ“âŠ”
Corollary 17.10 A stochastic process (Xn)nâˆˆN0 is a Markov chain if and only if
Lx
)
(Xn+k)nâˆˆN0
Fk
*
= LXk
)
(Xn)nâˆˆN0
*
for every k âˆˆN0.
(17.4)
Proof If the conditional distributions exist, then, by Theorem 17.9, the equa-
tion (17.4) is equivalent to X being a Markov chain. Hence we only have to show
that the conditional distributions exist.
Since E is Polish, EN0 is also Polish and we have B(EN0) = B(E)âŠ—N0
(see Theorem 14.8). Hence, by Theorem 8.37, there exists a regular conditional
distribution of (Xn+k)nâˆˆN0 given Fk.
âŠ“âŠ”

396
17
Markov Chains
Theorem 17.11 Let I = N0. If (Xn)nâˆˆN0 is a stochastic process with distributions
(Px, x âˆˆE), then the Markov property in Deï¬nition 17.3(iii) is implied by the
existence of a stochastic kernel Îº1 : E Ã— B(E) â†’[0, 1] with the property that for
every A âˆˆB(E), every x âˆˆE and every s âˆˆI, we have
Px
)
Xs+1 âˆˆA
Fs
*
= Îº1(Xs, A).
(17.5)
In this case, the n-step transition kernels Îºn can be computed inductively by
Îºn = Îºnâˆ’1 Â· Îº1 =

E
Îºnâˆ’1( Â·, dx) Îº1(x, Â·).
In particular, the family (Îºn)nâˆˆN is a Markov semigroup and the distribution X is
uniquely determined by Îº1.
Proof In Theorem 17.9, let ti = i for every i âˆˆN0. For the proof of that theorem,
only (17.5) was needed.
âŠ“âŠ”
The (time-homogeneous) Markov property of a process means that, for ï¬xed time
t, the future (after t) depends on the past (before t) only via the present (that is, via
the value Xt). We can generalize this concept by allowing random times Ï„ instead
of ï¬xed times t.
Deï¬nition 17.12 Let I âŠ‚[0, âˆ) be closed under addition. A Markov process
(Xt)tâˆˆI with distributions (Px, x âˆˆE) has the strong Markov property if, for every
a.s. ï¬nite stopping time Ï„, every bounded B(E)âŠ—I âˆ’B(R) measurable function
f : EI â†’R and every x âˆˆE, we have
Ex
)
f ((XÏ„+t)tâˆˆI)
FÏ„
*
= EXÏ„ [f (X)] :=

EI Îº(XÏ„, dy) f (y).
(17.6)
Remark 17.13 If I is countable, then the strong Markov property holds if and only
if, for every almost surely ï¬nite stopping time Ï„, we have
Lx
)
(XÏ„+t)tâˆˆI
FÏ„
* = LXÏ„
)
(Xt)tâˆˆI
* := Îº(XÏ„, Â·).
(17.7)
This follows just as in Corollary 17.10. â™¦
Most Markov processes one encounters have the strong Markov property. In
particular, for countable time sets, the strong Markov property follows from the
Markov property. For continuous time, however, in general, some work has to be
done to establish the strong Markov property.
Theorem 17.14 If I âŠ‚[0, âˆ) is countable and closed under addition, then every
Markov process (Xn)nâˆˆI with distributions (Px)xâˆˆE has the strong Markov property.
Proof Let f : EI â†’R be measurable and bounded. Then, for every s âˆˆI, the
random variable 1{Ï„=s} Ex
)f 
(Xs+t)tâˆˆI
 |FÏ„
* is measurable with respect to Fs.

17.1
Deï¬nitions and Construction
397
Using the tower property of the conditional expectation and Theorem 17.9 in the
third equality, we thus get
Ex
)
f

(XÏ„+t)tâˆˆI
 FÏ„
*
=

sâˆˆI
1{Ï„=s} Ex
)
f

(Xs+t)tâˆˆI
 FÏ„
*
=

sâˆˆI
Ex
'
1{Ï„=s} Ex
)
f

(Xs+t)tâˆˆI
Fs
*FÏ„
(
=

sâˆˆI
Ex
'
1{Ï„=s} EXs
)f (Xt)tâˆˆI
*FÏ„
(
= EXÏ„
)
f

(Xt)tâˆˆI
*
.
âŠ“âŠ”
As a simple application of the strong Markov property, we show the reï¬‚ection
principle for random walks.
Theorem 17.15 (Reï¬‚ection principle)
Let Y1, Y2, . . . be i.i.d. real random vari-
ables with symmetric distribution L[Y1] = L[âˆ’Y1]. Deï¬ne X0 = 0 and Xn :=
Y1 + . . . + Yn for n âˆˆN. Then, for every n âˆˆN0 and a > 0,
P
+
sup
mâ‰¤n
Xm â‰¥a
,
â‰¤2 P[Xn â‰¥a] âˆ’P[Xn = a].
(17.8)
If we have P[Y1 âˆˆ{âˆ’1, 0, 1}] = 1, then for a âˆˆN equality holds in (17.8).
Proof Let a > 0 and n âˆˆN. Deï¬ne the time of ï¬rst excess of a (truncated at
(n + 1)),
Ï„ := inf{m â‰¥0 : Xm â‰¥a} âˆ§(n + 1).
Then Ï„ is a bounded stopping time and
sup
mâ‰¤n
Xm â‰¥a
â‡â‡’
Ï„ â‰¤n.
Let f (m, X) = 1{mâ‰¤n}

1{Xnâˆ’m>a} + 1
2 1{Xnâˆ’m=a}

. Then
f Ï„, (XÏ„+m)mâˆˆN0
 = 1{Ï„â‰¤n}

1{Xn>a} + 1
2 1{Xn=a}

.
The strong Markov property of X yields
E0
)
f

Ï„, (XÏ„+m)mâ‰¥0
 FÏ„
*
= Ï• (Ï„, XÏ„ ) ,

398
17
Markov Chains
where Ï•(m, x) = Ex[f (m, X)]. (Recall that Ex denotes the expectation for X if
X0 = x.)
Due to the symmetry of Yi, we have
Ï•(m, x)
â§
âªâªâ¨
âªâªâ©
â‰¥1
2,
if m â‰¤n and x â‰¥a,
= 1
2,
if m â‰¤n and x = a,
= 0,
if m > n.
Hence
{Ï„ â‰¤n} = {Ï„ â‰¤n} âˆ©{XÏ„ â‰¥a} âŠ‚
0
Ï•(Ï„, XÏ„ ) â‰¥1
2
1
âˆ©{Ï„ â‰¤n}
= {Ï•(Ï„, XÏ„ ) > 0} âˆ©{Ï„ â‰¤n}.
Now (17.8) is implied by
P[Xn > a] + 1
2 P[Xn = a] = E
)
f

Ï„, (XÏ„+m)mâ‰¥0
*
= E0
)
Ï•(Ï„, XÏ„ ) 1{Ï„â‰¤n}
*
â‰¥1
2 P0 [Ï„ â‰¤n] .
(17.9)
Now assume P[Y1 âˆˆ{âˆ’1, 0, 1}] = 1 and a âˆˆN. Then XÏ„ = a if Ï„ â‰¤n. Hence
{Ï•(Ï„, XÏ„ ) > 0} âˆ©{Ï„ â‰¤n} =

Ï•(Ï„, XÏ„ ) = 1
2

âˆ©{Ï„ â‰¤n}.
Thus, in the last step of (17.9), equality holds and hence also in (17.8).
âŠ“âŠ”
Reï¬‚ection Find an example for strict inequality in (17.8). â™ 
Reï¬‚ection Consider the case P[Y1 = 1] = P[Y1 = âˆ’1] =
1
2. Then we have
equality in (17.8). In fact, in this case, the reï¬‚ection principle can be derived also
in an elementary way via a bijection that changes the signs of those Yi with i > Ï„.
Each path of the process X of partial sums that ends above a corresponds to a unique
path that reaches a but ends below a.
Try and ï¬ll the details in this argument. â™ 

17.2
Discrete Markov Chains: Examples
399
Takeaways For Markov processes, the future depends upon the information
up to a given time only via the state at this very time. If the time set is
countable, this property can be generalized to random (stopping) times and
is then called strong Markov property. Markov processes can be characterised
by their transition probabilities (stochastic kernels).
Exercise 17.1.1 Let I âŠ‚R and let X = (Xt)tâˆˆI be a stochastic process. For t âˆˆI,
deï¬ne the Ïƒ-algebras that code the past before t and the future beginning with t by
Fâ‰¤t := Ïƒ(Xs : s âˆˆI, s â‰¤t)
and
Fâ‰¥t := Ïƒ(Xs : s âˆˆI, s â‰¥t).
Show that X has the Markov property if and only if, for every t âˆˆI, the Ïƒ-algebras
Fâ‰¤t and Fâ‰¥t are independent given Ïƒ(Xt) (compare Deï¬nition 12.20).
In other words, a process has the (possibly time-inhomogeneous) Markov
property if and only if past and future are independent given the present. â™£
17.2
Discrete Markov Chains: Examples
Let E be countable and I = N0. By Deï¬nition 17.3, a Markov process X =
(Xn)nâˆˆN0 on E is a discrete Markov chain (or Markov chain with discrete state
space).
If X is a discrete Markov chain, then (Px)xâˆˆE is determined by the transition
matrix
p = (p(x, y))x,yâˆˆE := (Px[X1 = y])x,yâˆˆE.
The n-step transition probabilities
p(n)(x, y) := Px [Xn = y]
can be computed as the n-fold matrix product
p(n)(x, y) = pn(x, y),
where
pn(x, y) =

zâˆˆE
pnâˆ’1(x, z)p(z, y)
and where p0 = I is the unit matrix.

400
17
Markov Chains
By induction, we get the Chapmanâ€“Kolmogorov equation (see (14.15)) for all
m, n âˆˆN0 and x, y âˆˆE,
p(m+n)(x, y) =

zâˆˆE
p(m)(x, z) p(n)(z, y).
(17.10)
Deï¬nition 17.16 A matrix (p(x, y))x,yâˆˆE with nonnegative entries and with

yâˆˆE
p(x, y) = 1
for all x âˆˆE
is called a stochastic matrix on E.
A stochastic matrix is essentially a stochastic kernel from E to E. In Theorem 17.8
we saw that, for the semigroup of kernels (pn)nâˆˆN, there exists a unique discrete
Markov chain whose transition probabilities are given by p. The arguments we gave
there were rather abstract. Here we give a construction for X that could actually be
used to implement a computer simulation of X.
Let (Rn)nâˆˆN0 be an independent family of random variables with values in EE
and with the property
P[Rn(x) = y] = p(x, y)
for all x, y âˆˆE.
(17.11)
For example, choose (Rn(x), x âˆˆE, n âˆˆN) as an independent family of random
variables with values in E and distributions
P[Rn(x) = y] = p(x, y)
for all x, y âˆˆE and n âˆˆN0.
Note, however, that in (17.11) we have required neither independence of the random
variables (Rn(x), x âˆˆE) nor that all Rn had the same distribution. Only the one-
dimensional marginal distributions are determined. In fact, in many applications it
is useful to have subtle dependence structures in order to couple Markov chains with
different initial chains. We pick up this thread again in Sect. 18.2.
For x âˆˆE, deï¬ne
Xx
0 = x
and
Xx
n = Rn(Xx
nâˆ’1)
for n âˆˆN.
Finally, let Px := L[Xx] be the distribution of Xx. Recall that this is a probability
measure on the space of sequences (EN0, B(E)âŠ—N0).

17.2
Discrete Markov Chains: Examples
401
Theorem 17.17
(i) With respect to the distribution (Px)xâˆˆE, the canonical process X on
(EN0, B(E)âŠ—N0) is a Markov chain with transition matrix p.
(ii) In particular, to any stochastic matrix p, there corresponds a unique discrete
Markov chain X with transition probabilities p.
Proof â€œ(ii)â€
This follows from (i) since Theorem 17.11 yields uniqueness of X.
â€œ(i)â€
For n âˆˆN0 and x, y, z âˆˆE, by construction,
Px[Xn+1 = z
Fn, Xn = y] = P
)
Xx
n+1 = z
Ïƒ

Rm, m â‰¤n

, Xx
n = y
*
= P
)
Rn+1(Xx
n) = z
Ïƒ

Rm, m â‰¤n

, Xx
n = y
*
= P)Rn+1(y) = z]
= p(y, z).
Hence, by Theorem 17.11, X is a Markov chain with transition matrix p.
âŠ“âŠ”
Example 17.18 (Random walk on Z) Let E = Z, and assume
p(x, y) = p(0, y âˆ’x)
for all x, y âˆˆZ.
In this case, we say that p is translation invariant. A discrete Markov chain X with
transition matrix p is a random walk on Z. Indeed, Xn
D= X0 +Z1+. . .+Zn, where
(Zn)nâˆˆN are i.i.d. with P [Zn = x] = p(0, x).
The Rn that we introduced in the explicit construction are given by Rn(x) :=
x + Zn. â™¦
Example 17.19 (Computer simulation) Consider the situation where the state space
E = {1, . . . , k} is ï¬nite. The aim is to simulate a Markov chain X with transition
matrix p on a computer. Assume that the computer provides a random number
generator that generates an i.i.d. sequence (Un)nâˆˆN of random variables that are
uniformly distributed on [0, 1]. (Of course, this is wishful thinking. But modern
random number generators produce sequences that for many purposes are close
enough to really random sequences.)
Deï¬ne r(i, 0) = 0, r(i, j) = p(i, 1) + . . . + p(i, j) for i, j âˆˆE, and deï¬ne Yn
by
Rn(i) = j
â‡â‡’
Un âˆˆ[r(i, j âˆ’1), r(i, j)).
Then, by construction, P[Rn(i) = j] = r(i, j) âˆ’r(i, j âˆ’1) = p(i, j). â™¦
Example 17.20 (Branching process as a Markov chain) We want to understand the
Galtonâ€“Watson branching process (see Deï¬nition 3.9) as a Markov chain on E =
N0.

402
17
Markov Chains
To this end, let (qk)kâˆˆN0 be a probability vector, the offspring distribution of one
individual. Deï¬ne qâˆ—0
k
= 1{0}(k) and
qâˆ—n
k
=
k

l=0
qâˆ—(nâˆ’1)
kâˆ’l
ql
for n âˆˆN
as the n-fold convolutions of q. Hence, for n individuals, qâˆ—n
k
is the probability to
have exactly k offspring. Finally, deï¬ne the matrix p by p(x, y) = qâˆ—x
y
for x, y âˆˆ
N0.
Now let (Yn,i, n âˆˆN0, i âˆˆN0) be i.i.d. with P[Yn,i = k] = qk. For x âˆˆN0,
deï¬ne the branching process X with x ancestors and offspring distribution q by
X0 = x and Xn := Xnâˆ’1
i=1 Ynâˆ’1,i. In order to show that X is a Markov chain, we
compute
P[Xn = xn
X0 = x, X1 = x1, . . . , Xnâˆ’1 = xnâˆ’1]
= P[Ynâˆ’1,1 + . . . + Ynâˆ’1,xnâˆ’1 = xn]
= Pâˆ—xnâˆ’1
Y1,1 ({xn}) = qâˆ—xnâˆ’1
xn
= p(xnâˆ’1, xn).
Hence X is a Markov chain on N0 with transition matrix p. â™¦
Example 17.21 (Wrightâ€™s evolution model) In population genetics, Wrightâ€™s evo-
lution model [172] describes the hereditary transmission of a genetic trait with
two possible speciï¬cations (say A and B); for example, resistance/no resistance
to a speciï¬c antibiotic. It is assumed that the population has a constant size of
N âˆˆN individuals and the generations change at discrete times and do not overlap.
Furthermore, for simplicity, the individuals are assumed to be haploid; that is, cells
bear only one copy of each chromosome (like certain protozoans do) and not two
copies (as in mammals).
Here we consider the case where none of the traits is favored by selection. Hence,
it is assumed that each individual of the new generation chooses independently and
uniformly at random one individual of the preceding generation as ancestor and
becomes a perfect clone of that. Thus, if the number of individuals of type A in the
current generation is k âˆˆ{0, . . ., N}, then in the new generation it will be random
and binomially distributed with parameters N and k/N.
The gene frequencies k/N in this model can be described by a Markov chain X
on E = {0, 1/N, . . . , (N âˆ’1)/N, 1} with transition matrix p(x, y) = bN,x({Ny}).
Note that X is a (bounded) martingale. Hence, by the martingale convergence
theorem (Theorem 11.7), X converges Px-almost surely to a random variable Xâˆ
with Ex[Xâˆ] = Ex[X0] = x. As with the voter model (see Example 11.16) that is
closely related to Wrightâ€™s model, we can argue that the limit Xâˆcan take only the
stable values 0 and 1. That is, Px[limnâ†’âˆXn = 1] = x = 1âˆ’Px[limnâ†’âˆXn = 0].
â™¦

17.2
Discrete Markov Chains: Examples
403
Example 17.22 (Discrete Moran model) In contrast to Wrightâ€™s model, the Moran
model also allows overlapping generations. The situation is similar to that of
Wrightâ€™s model; however, now in each time step, only (exactly) one individual gets
replaced by a new one, whose type is chosen at random from the whole population.
As the new and the old types of the replaced individual are independent, as a
model for the gene frequencies, we obtain a Markov chain X on E = {0, 1
N , . . . , 1}
with transition matrix
p(x, y) =
â§
âªâªâªâªâ¨
âªâªâªâªâ©
x(1 âˆ’x),
if y = x + 1/N,
x2 + (1 âˆ’x)2,
if y = x,
x(1 âˆ’x),
if y = x âˆ’1/N,
0,
else.
Here also, X is a bounded martingale and we can compute the square variation
process,
âŸ¨XâŸ©n =
n

i=1
E
)
(Xi âˆ’Xiâˆ’1)2Xiâˆ’1
*
= 2
N2
nâˆ’1

i=0
Xi(1 âˆ’Xi).
(17.12)
â™¦
Takeaways A Markov process indexed by the natural numbers is called a
Markov chain. Markov chains with discrete state spaces give rise to many
interesting probabilistic examples. The transition probabilities are given by
stochastic matrices.
Exercise 17.2.1 (Discrete martingale problem) Let E âŠ‚R be countable and let
X be a Markov chain on E with transition matrix p and with the property that,
for any x, there are at most three choices for the next step; that is, there exists a
set Ax âŠ‚E of cardinality 3 with p(x, y) = 0 for all y âˆˆE \ Ax. Let d(x) :=

yâˆˆE(y âˆ’x) p(x, y) for x âˆˆE.
(i) Show that Mn := Xn âˆ’nâˆ’1
k=0 d(Xk) deï¬nes a martingale M with square
variation process âŸ¨MâŸ©n = nâˆ’1
i=0 f (Xi) for a unique function f : E â†’[0, âˆ).
(ii) Show that the transition matrix p is uniquely determined by f and d.
(iii) For the Moran model (Example 17.22), use the explicit form (17.12) of the
square variation process to compute the transition matrix. â™£

404
17
Markov Chains
17.3
Discrete Markov Processes in Continuous Time
Let E be countable and let (Xt)tâˆˆ[0,âˆ) be a Markov process on E with transition
probabilities pt(x, y) = Px[Xt = y] (for x, y âˆˆE). (Some authors call such a
process a Markov chain in continuous time.)
Let x, y âˆˆE with x Ì¸= y. We say that X jumps with rate q(x, y) from x to y if
the following limit exists:
q(x, y) := lim
tâ†“0
1
t Px[Xt = y].
Henceforth we assume that the limit q(x, y) exists for all y Ì¸= x and that

yÌ¸=x
q(x, y) < âˆ
for all x âˆˆE.
(17.13)
Then we deï¬ne
q(x, x) = âˆ’

yÌ¸=x
q(x, y).
(17.14)
Finally we assume that (which is equivalent to exchangeability of the limit and the
sum over y Ì¸= x in the display preceding (17.13))
lim
tâ†“0
1
t

Px [Xt = y] âˆ’1{x=y}

= q(x, y)
for all x, y âˆˆE.
(17.15)
Deï¬nition 17.23 If (17.13), (17.14) and (17.15) hold, then q is called the Q-matrix
of X. Sometimes q is also called the generator of the semigroup (pt)tâ‰¥0.
Example 17.24 (Poisson process) The Poisson process with rate Î± > 0 (compare
Sect. 5.5) has the Q-matrix q(x, y) = Î±(1{y=x+1} âˆ’1{y=x}). â™¦
Theorem 17.25 Let q be an E Ã— E matrix such that q(x, y) â‰¥0 for all x, y âˆˆE
with x Ì¸= y. Assume that (17.13) and (17.14) hold and that
Î» := sup
xâˆˆE
|q(x, x)| < âˆ.
(17.16)
Then q is the Q-matrix of a unique Markov process X.
Intuitively, (17.15) suggests that we deï¬ne pt = etq in a suitable sense. Then,
formally, q =
d
dt pt
t=0. The following proof shows that this formal argument can
be made rigorous.

17.3
Discrete Markov Processes in Continuous Time
405
Proof Let I be the unit matrix on E. Deï¬ne
p(x, y) = 1
Î» q(x, y) + I(x, y)
for x, y âˆˆE,
if Î» > 0 and p = I otherwise. Then p is a stochastic matrix and q = Î»(p âˆ’I).
Let

(Yn)nâˆˆN0,

PY
x

xâˆˆE

be a discrete Markov chain with transition matrix p and
let (Tt)tâ‰¥0, PT
n

nâˆˆN0
 be a Poisson process with rate Î». Let Xt := YTt and Px =
PY
x âŠ—PT
0 . Then X :=

(Xt)tâ‰¥0, (Px)xâˆˆE

is a Markov process and
pt(x, y) := Px [Xt = y] =
âˆ

n=0
PT
0 [Tt = n] PY
x [Yn = y]
= eâˆ’Î»t
âˆ

n=0
Î»n tn
n! pn(x, y).
This power series (in t) converges everywhere (note that as a linear operator, p has
ï¬nite norm âˆ¥pâˆ¥âˆâ‰¤1) to the matrix exponential function eÎ»tp(x, y). Furthermore,
pt(x, y) = eâˆ’Î»teÎ»tp(x, y) = eÎ»t(pâˆ’I)(x, y) = etq(x, y).
Differentiating the power series termwise yields d
dt pt(x, y)
t=0 = q(x, y). Hence
X is the required Markov process.
Now assume that (pt)tâ‰¥0 are the transition probabilities of another Markov
process X with the same generator q; that is, with
lim
sâ†“0
1
s
ps(x, y) âˆ’I(x, y) = q(x, y).
It is easy to check that
lim
sâ†“0
1
s

pt+s(x, y) âˆ’pt(x, y)

= (q Â· pt)(x, y).
That is, we have (d/dt)pt(x, y) = q pt(x, y). Similarly, we get (d/dt)pt =
q pt(x, y). Hence also,
pt(x, y) âˆ’pt(x, y) =
 t
0

q(ps âˆ’ps)

(x, y) ds.

406
17
Markov Chains
If we let rs = ps âˆ’ps, then âˆ¥rsâˆ¥âˆâ‰¤2 and âˆ¥qâˆ¥âˆâ‰¤2Î»; hence
sup
sâ‰¤t
âˆ¥rsâˆ¥âˆâ‰¤sup
sâ‰¤t
 s
0
âˆ¥qruâˆ¥âˆdu
â‰¤âˆ¥qâˆ¥âˆsup
sâ‰¤t
 s
0
âˆ¥ruâˆ¥âˆdu â‰¤2Î»t sup
sâ‰¤t
âˆ¥rsâˆ¥âˆ.
For t < 1/2Î», this implies rt = 0. Assuming rs = 0 for all s â‰¤(n âˆ’1)t, we
conclude
sup
sâ‰¤nt
âˆ¥rsâˆ¥âˆâ‰¤2Î»
 nt
(nâˆ’1)t
âˆ¥ruâˆ¥âˆdu â‰¤2Î»t sup
sâ‰¤nt
âˆ¥rsâˆ¥âˆ= 0,
hence rs = 0 for all s â‰¤nt. By induction, we get rs = 0 hence ps = ps for all
s â‰¥0.
âŠ“âŠ”
Remark 17.26 The condition (17.16) cannot be dropped easily, as the following
example shows. Let E = N and
q(x, y) =
â§
âªâ¨
âªâ©
x2,
if y = x + 1,
âˆ’x2,
if y = x,
0,
else.
We construct explicitly a candidate X for a Markov process with Q-matrix q. Let
T1, T2, . . . be independent, exponentially distributed random variables with PTn =
expn2. Deï¬ne Sn = T1 + . . . + Tnâˆ’1 and Xt = sup{n âˆˆN0 : Sn â‰¤t}. Then, at any
time, X makes at most one step to the right. Furthermore, due to the lack of memory
of the exponential distribution (see Exercise 8.1.1),
P[Xt+s â‰¥n + 1|Xt = n]
= P[Sn+1 â‰¤t + s|Sn â‰¤t, Sn+1 > t]
= P[Tn â‰¤s + t âˆ’Sn|Sn â‰¤t, Tn > t âˆ’Sn] = P[Tn â‰¤s]
= 1 âˆ’exp(âˆ’n2s).
Therefore,
lim
sâ†“0 sâˆ’1P[Xt+s = n + 1|Xt = n] = n2
and
lim
sâ†“0 sâˆ’1
P[Xt+s = n|Xt = n] âˆ’1

= âˆ’n2;

17.3
Discrete Markov Processes in Continuous Time
407
hence
lim
sâ†“0 sâˆ’1 
P[Xt+s = m|Xt = n] âˆ’I(m, n)

= q(m, n)
for all m, n âˆˆN.
Let
Ï„ n = inf{t â‰¥0 : Xt = n} = Sn
for n âˆˆN.
Then E1[Ï„ n] = nâˆ’1
k=1
1
k2 . By monotone convergence, E1
) supnâˆˆN Ï„ n* < âˆ. That
is, in ï¬nite time, X exceeds all levels. We say that X explodes. â™¦
Example 17.27 (Yule process)
We consider an example that resembles the preced-
ing one at ï¬rst glance. However, the qualitative behaviour will be quite different.
Let E = N and let X = (Xt)tâ‰¥0 be a Markov process on E with Q-matrix
q(x, y) =
â§
âªâ¨
âªâ©
x,
if y = x + 1,
âˆ’x,
if y = x,
0,
else.
This process can be regarded as a Galton-Watson branching process in continuous
time. Each of the x individuals has an exponentially distributed lifetime with
parameter 1. When a particle dies, it has two offspring. Each of the offspring gets its
own independent exponential lifetime. Due to the lack-of-memory property of the
exponential distribution, also the remaining lifetimes of the other x âˆ’1 individuals
are independent and exponentially distributed with parameter 1. As the minimum
of x independent exp1-distributed random variables is expx-distributed, the waiting
time for the next branching event is expx-distributed. This property is reï¬‚ected by
the assumption that the jump rate q(x, x + 1) equals x.
For n âˆˆN0 and t â‰¥0, deï¬ne the probability
fn(t) := P1[Xt > n].
Clearly, we have fn(0) = 0 for all n âˆˆN. Now X jumps from n to n + 1 at rate n.
Hence, we have
d
dt fn(t) = n P1[Xt = n] = n (fnâˆ’1(t) âˆ’fn(t)).
Note that f0(t) = 1 for all t â‰¥0 and hence f â€²
1(t) = 1 âˆ’f1(t). The unique solution
of this differential equation is f1(t) = 1 âˆ’eâˆ’t. By induction, we get
P1[Xt > n] = fn(t) = (1 âˆ’eâˆ’t)n
for all n âˆˆN, t â‰¥0.

408
17
Markov Chains
In particular, we see that Xt is ï¬nite for all t. Now we determine the asymptotic
growth rate of X. For x > 0, we have
P1[eâˆ’tXt > x] = P[Xt > etx] = (1 âˆ’eâˆ’t)âŒŠetxâŒ‹tâ†’âˆ
âˆ’â†’eâˆ’x.
That is, eâˆ’tXt converges in distribution to a random variable W with W âˆ¼exp1.
We can use the jump times of X for an alternative derivation. Similarly as in
Remark 17.28, we deï¬ne independent random variables T1, T2, . . . with Tn âˆ¼expn.
Now let Sn := T1 + . . . + Tnâˆ’1 and deï¬ne X by
Xt := sup 	n âˆˆN : Sn â‰¤t
for all t â‰¥0.
Let Z1, Z2, . . . be independent exponentially distributed random variables with
parameter 1. From Exercise 15.1.3, we know that
Sn+1
D= max{Z1, . . . , Zn}.
Hence, we have
P[Xt > n] = P[Sn+1 â‰¤t] = P[Z1 â‰¤t]n = (1 âˆ’eâˆ’t)n.
â™¦
Example 17.28 (A variant of PÃ³lyaâ€™s urn model) Consider a variant of PÃ³lyaâ€™s urn
model with black and red balls (compare Example 12.29). In contrast to the original
model, we do not simply add one ball of the same color as the ball that we return.
Rather, the number of balls that we add varies from time to time. More precisely,
the kth ball of a given color will be returned together with rk more balls of the same
color. The numbers r1, r2, . . . âˆˆN are parameters of the model. In particular, the
case 1 = r1 = r2 = . . . is the classical PÃ³lyaâ€™s urn model. Let
Xn :=

1,
if the nth ball is black,
0,
else.
For the classical model, we saw (Example 12.29) that the fraction of black balls
in the urn converges a.s. to a Beta-distributed random variable Z. Furthermore,
given Z, the sequence X1, X2, . . . is independent and BerZ-distributed. A similar
statement holds for the case where r = r1 = r2 = . . . for some r âˆˆN. Indeed,
here only the parameters of the Beta distribution change. In particular (as the Beta
distribution is continuous and, in particular, does not have atoms at 0 or 1), almost
surely we draw inï¬nitely many balls of each color. Formally, P[B] = 0 where B is
the event where there is one color of which only ï¬nitely many balls are drawn.
The situation changes when the numbers rk grow quickly as k â†’âˆ. Assume
that in the beginning there is one black and one red ball in the urn. Denote by
wn = 1 + n
k=1 rk the total number of balls of a given color after n balls of that
color have been drawn already (n âˆˆN0).

17.3
Discrete Markov Processes in Continuous Time
409
For illustration, ï¬rst consider the extreme situation where wn grows very quickly;
for example, wn = 2n for every n âˆˆN. Denote by
Sn = 2(X1 + . . . + Xn) âˆ’n
the number of black balls drawn in the ï¬rst n steps minus the number of red balls
drawn in these steps. Then, for every n âˆˆN0,
P[Xn+1 = 1|Sn] =
2Sn
1 + 2Sn
and
P[Xn+1 = 0|Sn] =
2âˆ’Sn
1 + 2âˆ’Sn .
We conclude that (Zn)nâˆˆN0 := (|Sn|)nâˆˆN0 is a Markov chain on N0 with transition
matrix
p(z, zâ€²) =
â§
âªâªâ¨
âªâªâ©
2z/(1 + 2z),
if zâ€² = z + 1 > 1,
1,
if zâ€² = z + 1 = 1,
1/(1 + 2z),
if zâ€² = z âˆ’1 â‰¥0,
0,
else.
The event B from above can be written as
B = 	Zn+1 < Zn only ï¬nitely often
.
Let A =
	
Zn+1 > Zn for all n âˆˆN0

denote the event where Z ï¬‚ees directly to
âˆand let Ï„z = inf{n âˆˆN0 : Zn â‰¥z}. Evidently,
Pz[A] =
âˆ

zâ€²=z
p(zâ€², zâ€² + 1) â‰¥1 âˆ’
âˆ

zâ€²=z
1
1 + 2zâ€² â‰¥1 âˆ’21âˆ’z.
It is easy to check that P0[Ï„z < âˆ] = 1 for all z âˆˆN0. Using the strong Markov
property, we get that, for all z âˆˆN0,
P0[B] â‰¥P0[Zn+1 > Zn for all n â‰¥Ï„z] = Pz[A] â‰¥1 âˆ’21âˆ’z,
and thus P0[B] = 1. In prose, almost surely eventually only balls of one color will
be drawn.
This example was a bit extreme. In order to ï¬nd a necessary and sufï¬cient
condition on the growth of (wn), we need more subtle methods that appeal to the
above example of the explosion of a Markov process.
We will show that P[B] = 1 if and only if âˆ
n=0
1
wn < âˆ. To this end, consider
independent random variables T s
1 , T r
1 , T s
2 , T r
2 , . . . with PT rn = PT sn = expwnâˆ’1. Let
T r
âˆ= âˆ
n=1 T r
n and T s
âˆ= âˆ
n=1 T s
n . Clearly, E[T r
âˆ] = âˆ
n=0 1/wn < âˆ;
hence, in particular, P[T r
âˆ< âˆ] = 1. The corresponding statement holds for T s
âˆ.

410
17
Markov Chains
Note that T r
âˆand T s
âˆare independent and have densities (since T r
1 and T s
1 have
densities); hence we have P[T r
âˆ= T s
âˆ] = 0.
Now let
Rt := sup
	
n âˆˆN : T r
1 + . . . + T r
nâˆ’1 â‰¤t

and
St := sup
	
n âˆˆN : T s
1 + . . . + T s
nâˆ’1 â‰¤t

.
Let R := {T r
1 + . . . + T r
n , n âˆˆN} and let S := {T s
1 + . . . + T s
n , n âˆˆN} be the jump
times of (Rt) and (St). Deï¬ne U := R âˆªS = {u1, u2, . . .}, where u1 < u2 < . . ..
Let
Xn =
0 1,
if un âˆˆS,
0,
else.
Let Ln = x1 + . . . + xn. Then
P[Xn+1 = 1
X1 = x1, . . . , Xn = xn]
= P
)
un+1 âˆˆS
(uk âˆˆS â‡â‡’xk = 1) for every k â‰¤n
*
= P
)
T s
1 + . . . + T s
Ln+1 < T r
1 + . . . + T r
nâˆ’Ln+1
T s
1 + . . . + T s
Ln+1 > T r
1 + . . . + T r
nâˆ’Ln]
= P
)
T s
Ln+1 < T r
nâˆ’Ln+1
*
=
wLn
wLn + wnâˆ’Ln
.
Hence (Xn)nâˆˆN0 is our generalized urn model with weights (wn)nâˆˆN0. Consider
now the event Bc where inï¬nitely many balls of each color are drawn. Evidently,
{Xn = 1 inï¬nitely often} = {sup S = sup U} and {Xn = 0 inï¬nitely often} =
{sup R = sup U}. Since sup S = T s
âˆand sup R = T r
âˆ, we thus have P[Bc] =
P[T r
âˆ= T s
âˆ] = 0. â™¦
Takeaways A Markov processes in continuous time and with discrete state
space can be described by its jump rates (q-matrix). If the jump rates are
bounded, then the process can be constructed as a Markov chain at random
times given by a Poisson clock.
Exercise 17.3.1 Consider the Yule process X from Example 17.27. Show that
Wt := eâˆ’tXt, t â‰¥0, is a martingale. Conclude that (Wn)nâˆˆN converges almost
surely an in L1 to a random variable W that is exponentially distributed with

17.4
Discrete Markov Chains: Recurrence and Transience
411
parameter 1. (In fact, using Exercise 21.4.2, it can even be shown that (Wt)tâ‰¥0
converges to W almost surely and in L1.) â™£
Exercise 17.3.2 Let r, s, R, S âˆˆN. Consider the generalized version of PÃ³lyaâ€™s urn
model (Xn)nâˆˆN0 with rk = r and sk = s for all k âˆˆN. Assume that in the beginning
there are R red balls and S black balls in the urn. Show that the fraction of black
balls converges almost surely to a random variable Z with a Beta distribution and
determine the parameters. Show that (Xn)nâˆˆN0 is i.i.d. given Z and Xi âˆ¼BerZ for
all i âˆˆN0. â™£
Exercise 17.3.3 Show that, almost surely, inï¬nitely many balls of each color are
drawn if
âˆ

n=0
1
wn
= âˆ. â™£
17.4
Discrete Markov Chains: Recurrence and Transience
In the following, let X = (Xn)nâˆˆN0 be a Markov chain on the countable space E
with transition matrix p.
Deï¬nition 17.29 For any x âˆˆE, let Ï„x := Ï„ 1
x := inf{n > 0 : Xn = x} and
Ï„ k
x = inf

n > Ï„ kâˆ’1
x
: Xn = x

for k âˆˆN, k â‰¥2.
Ï„ k
x is the kth entrance time of X for x. For x, y âˆˆE, let
F(x, y) := Px[Ï„ 1
y < âˆ] = Px
)
there is an n â‰¥1 with Xn = y
*
be the probability of ever going from x to y. In particular, F(x, x) is the return
probability (after the ï¬rst jump) from x to x.
Note that Ï„ 1
x > 0 even if we start the chain at X0 = x.
Theorem 17.30 For all x, y âˆˆE and k âˆˆN, we have
Px
)
Ï„ k
y < âˆ
*
= F(x, y) F(y, y)kâˆ’1.
Proof We carry out the proof by induction on k. For k = 1, the claim is true
by deï¬nition. Now let k â‰¥2. Using the strong Markov property of X (see
Theorem 17.14), we get
Px
'
Ï„ k
y < âˆ
(
= Ex
'
Px
'
Ï„ k
y < âˆ
FÏ„ kâˆ’1
y
(
1{Ï„ kâˆ’1
y
<âˆ}
(
= Ex
'
F(y, y) Â· 1{Ï„ kâˆ’1
y
<âˆ}
(
= F(y, y) Â· F(x, y) F(y, y)kâˆ’2 = F(x, y) F(y, y)kâˆ’1.
âŠ“âŠ”

412
17
Markov Chains
Deï¬nition 17.31 A state x âˆˆE is called
â€¢
recurrent if F(x, x) = 1,
â€¢
positive recurrent if Ex[Ï„ 1
x ] < âˆ,
â€¢
null recurrent if x is recurrent but not positive recurrent,
â€¢
transient if F(x, x) < 1, and
â€¢
absorbing if p(x, x) = 1.
The Markov chain X is called (positive/null) recurrent if every state x âˆˆE is
(positive/null) recurrent and is called transient if every recurrent state is absorbing.
Remark 17.32 Clearly, we have:
â€œabsorbingâ€ â‡’â€œpositive recurrentâ€ â‡’â€œrecurrentâ€. â™¦
Example 17.33
(i) In Fig. 17.1, the state 2 is absorbing. If it does not get trapped in 2, the chain
will eventually jump from 5 to 6 and will not return after that. Hence 1, 3, 4
and 5 are transient. The states 6, 7 and 8 are positive recurrent. One can show
(see Exercise 17.6.1) that E6[Ï„6] = 17
4 , E7[Ï„7] = 17
5 and E8[Ï„8] = 17
8 .
(ii) The chain in Fig. 17.2 has a drift to the right if r > 1
2. Hence, in this case, every
state is transient. On the other hand, if r âˆˆ(0, 1
2), then the chain has a drift to
the left (except at the point 0) and hence visits every state again and again. Thus
the chain is recurrent. With a little thought, one can show (see Exercise 17.6.4)
that in this case, the chain is actually positive recurrent and in the remaining
case r = 1
2 it is null recurrent.â™¦
Deï¬nition 17.34 Denote by N(y) = âˆ
n=0 1{Xn=y} the total number of visits of X
to y and by
G(x, y) = Ex[N(y)] =
âˆ

n=0
pn(x, y)
the Green function of X.
1
1/2
1
1/3
1/6
1/2
1/2
1/2
1/2
3/4
1/4
1/4
3/4
1/2
1/2
1
3
8
2
4
6
7
5
Fig. 17.1 Markov chain with eight states. The numbers are the transition probabilities for the
corresponding arrows. State 2 is absorbing, the states 1, 3, 4 and 5 are transient and the states 6, 7
and 8 are (positive) recurrent.

17.4
Discrete Markov Chains: Recurrence and Transience
413
1
1âˆ’r
r
r
r
âˆ’
1
r
âˆ’
1
r
âˆ’
1
r
0
1
2
3
Fig. 17.2 Markov chain on N0 with parameter r âˆˆ(0, 1). The chain is positive recurrent if r âˆˆ
(0, 1/2), null recurrent if r = 1/2 and transient if r âˆˆ(1/2, 1).
Reï¬‚ection The Green function G is deï¬ned by a geometric series. Hence, formally
we should have G = (I âˆ’p)âˆ’1 with I the unit matrix. In which situations can this
formalism be justiï¬ed? â™ â™ 
Theorem 17.35
(i) For all x, y âˆˆE, we have (with the convention 1/0 := âˆ, 0/0 := 0 and
0 Â· âˆ:= 0)
G(x, y) =
â§
âªâªâ¨
âªâªâ©
F(x, y)
1 âˆ’F(y, y),
if x Ì¸= y
1
1 âˆ’F(y, y),
if x = y
â«
âªâªâ¬
âªâªâ­
= F(x, y) G(y, y) + 1{x=y}.
(17.17)
(ii) A non-absorbing state x âˆˆE is recurrent if and only if G(x, x) = âˆ.
Proof (ii) follows by (i). Hence, it remains to show (17.17). By Theorem 17.30, we
have
G(x, y) = Ex[N(y)] =
âˆ

k=1
Px[N(y) â‰¥k]
= 1{x=y} +
âˆ

k=1
Px
'
Ï„ k
y < âˆ
(
= 1{x=y} +
âˆ

k=1
F(x, y) F(y, y)kâˆ’1
=
â§
âªâªâ¨
âªâªâ©
F(x, y)
1 âˆ’F(y, y),
if x Ì¸= y,
1
1 âˆ’F(x, x),
if x = y.
The second equality in (17.17) is an immediate consequence.
âŠ“âŠ”
Theorem 17.36 If x is recurrent and F(x, y) > 0, then y is also recurrent, and
F(x, y) = F(y, x) = 1.
Proof Let x, y âˆˆE, x Ì¸= y, be such that F(x, y) > 0. Then there is a k âˆˆN and
states x1, . . . , xk âˆˆE with xk = y and xi Ì¸= x for all i = 1, . . . , k and such that

414
17
Markov Chains
Px [Xi = xi for all i = 1, . . . , k] > 0.
In particular, pk(x, y) > 0. By the Markov property, we have
1 âˆ’F(x, x) = Px
'
Ï„ 1
x = âˆ
(
â‰¥Px
'
X1 = x1, . . . , Xk = xk, Ï„ 1
x = âˆ
(
= Px [X1 = x1, . . . , Xk = xk] Â· Py
'
Ï„ 1
x = âˆ
(
= Px [X1 = x1, . . . , Xk = xk] (1 âˆ’F(y, x)) .
If now F(x, x) = 1, then also F(y, x) = 1. Since F(y, x) > 0, there exists an
l âˆˆN with pl(y, x) > 0. Hence, for n âˆˆN0,
pl+n+k(y, y) â‰¥pl(y, x) pn(x, x) pk(x, y).
If x is recurrent, then we conclude that
G(y, y) â‰¥
âˆ

n=0
pl+n+k(y, y) â‰¥pl(y, x)pk(x, y)G(x, x) = âˆ
and hence also that y is recurrent. Changing the roles of x and y in the above
argument, we get F(x, y) = 1.
âŠ“âŠ”
Deï¬nition 17.37 A discrete Markov chain is called
â€¢
irreducible if F(x, y) > 0 for all x, y âˆˆE, or equivalently G(x, y) > 0, and
â€¢
weakly irreducible if F(x, y) + F(y, x) > 0 for all x, y âˆˆE.
Theorem 17.38 An irreducible discrete Markov chain is either recurrent or tran-
sient. If |E| â‰¥2, then there is no absorbing state.
Proof This follows directly from Theorem 17.36.
âŠ“âŠ”
Theorem 17.39 If E is ï¬nite and X is irreducible, then X is recurrent.
Proof Evidently, for all x âˆˆE,

yâˆˆE
G(x, y) =
âˆ

n=0

yâˆˆE
pn(x, y) =
âˆ

n=0
1 = âˆ.

17.5
Application: Recurrence and Transience of Random Walks
415
As E is ï¬nite, there is a y âˆˆE with G(x, y) = âˆ. Since F(y, x) > 0, there exists
a k âˆˆN with pk(y, x) > 0. Therefore, since pn+k(x, x) â‰¥pn(x, y) pk(y, x), we
have
G(x, x) â‰¥
âˆ

n=0
pn(x, y) pk(y, x) = pk(y, x) G(x, y) = âˆ.
âŠ“âŠ”
Takeaways A state of a Markov chain is called recurrent if the chain returns
to it almost surely. Otherwise it is called transient. A recurrent state is called
positive recurrent if the expected time of return is ï¬nite; otherwise it is null
recurrent. For irreducible chains all states are in the same class: either positive
recurrent, null recurrent or transient. A state is recurrent if and only if the
expected number of visits (Green function) is inï¬nite.
Exercise 17.4.1 Let x be positive recurrent and let F(x, y) > 0. Show that y is
also positive recurrent. â™£
17.5
Application: Recurrence and Transience of Random
Walks
In this section, we study recurrence and transience of random walks on the D-
dimensional integer lattice ZD, D = 1, 2, . . .. A more exhaustive investigation can
be found in Spitzerâ€™s book [159].
Consider ï¬rst the simplest situation of symmetric simple random walk X on ZD.
That is, at each step, X jumps to any of its 2D neighbors with the same probability
1/2D. Hence, in terms of the Markov chain notation, we have E = ZD and
p(x, y) =
 1
2D ,
if |x âˆ’y| = 1,
0,
else.
Is this random walk recurrent or transient?
The central limit theorem suggests that
pn(0, 0) â‰ˆCD nâˆ’D/2
as n â†’âˆ
for some constant CD that depends on the dimension D. However, ï¬rst we have to
exclude the case where n is odd since here clearly pn(0, 0) = 0. Thus let Y1, Y2, . . .
be independent ZD-valued random variables with P[Yi = x] = p2(0, x). Then
X2n
D= Sn := Y1 + . . . + Yn for n âˆˆN0; hence G(0, 0) = âˆ
n=0 P[Sn = 0].

416
17
Markov Chains
Clearly, Y1 = (Y 1
1 , . . . , Y D
1 ) has covariance matrix Ci,j := E[Y i
1 Â· Y j
1 ] = 2
D 1{i=j}.
By the local central limit theorem (see, e.g., [20, pages 224ff] for a one-dimensional
version of that theorem or Exercise 17.5.1 for an analytic derivation), we have
nD/2p2n(0, 0) = nD/2 P[Sn = 0]
nâ†’âˆ
âˆ’â†’
2 (4Ï€/D)âˆ’D/2.
(17.18)
Now âˆ
n=1 nâˆ’Î± < âˆif and only if Î± > 1. Hence G(0, 0) < âˆif and only if
D > 2. We have thus shown the following theorem of PÃ³lya [134].
Theorem 17.40 (PÃ³lya [134]) Symmetric simple random walk on ZD is recurrent
if and only if D â‰¤2.
The procedure we used here to derive PÃ³lyaâ€™s theorem has the disadvantage that it
relies on the local central limit theorem, which we have not proved (and will not).
Hence we will consider different methods of proof that yield further insight into the
problem.
Consider ï¬rst the one-dimensional simple random walk that with probability p
jumps one step to the right and with probability 1 âˆ’p jumps one step to the left.
Then
G(0, 0) =
âˆ

n=0
2n
n
p(1 âˆ’p)n =
âˆ

n=0
âˆ’1/2
n
 âˆ’4p(1 âˆ’p)n.
Using the generalized binomial theorem (see Lemma 3.5), we get (since we have
(1 âˆ’4p(1 âˆ’p))1/2 = |2p âˆ’1|)
G(0, 0) =

1
|2pâˆ’1|,
if p Ì¸= 1
2,
âˆ,
if p = 1
2.
(17.19)
Thus, simple random walk on Z is recurrent if and only if it is symmetric; that is, if
p = 1
2.
Of course, transience in the case p Ì¸= 1
2 could also be deduced directly from the
strong law of large numbers since limnâ†’âˆ1
nXn = E0[X1] = 2p âˆ’1 almost surely.
In fact, this argument is even more robust since it uses only that the single steps of
X have an expectation that is not zero.
Consider now the situation where X does not necessarily jump to one of its
nearest neighbors but where we still have E0[|X1|] < âˆand E0[X1] = 0. The
strong law of large numbers does not yield recurrence immediately and we have to
do some work:
By the Markov property, for every N âˆˆN and every y Ì¸= x,
GN(x, y) :=
N

k=0
Px[Xk = y] =
N

k=0
Px
)
Ï„ 1
y = k
* Nâˆ’k

l=0
Py[Xl = y] â‰¤GN(y, y).

17.5
Application: Recurrence and Transience of Random Walks
417
This implies for all L âˆˆN
GN(0, 0) â‰¥
1
2L + 1

|y|â‰¤L
GN(0, y)
=
1
2L + 1
N

k=0

|y|â‰¤L
pk(0, y)
â‰¥
1
2L + 1
N

k=1

y: |y/k|â‰¤L/N
pk(0, y).
By the weak law of large numbers, we have lim infkâ†’âˆ

|y|â‰¤Îµk pk(0, y) = 1 for
every Îµ > 0. Hence, letting L = ÎµN, we get
lim inf
Nâ†’âˆGN(0, 0) â‰¥
1
2Îµ
for every Îµ > 0.
Thus G(0, 0) = âˆ, which shows that X is recurrent.
We summarize the discussion in a theorem.
Theorem 17.41 A random walk on Z with âˆ
x=âˆ’âˆ|x| p(0, x) < âˆis recurrent
if and only if âˆ
x=âˆ’âˆx p(0, x) = 0.
Now what about symmetric simple random walk in dimension D = 2 or in higher
dimensions? In order that the random walk be at the origin after 2n steps, it must
perform ki steps in the ith direction and ki steps in the opposite direction for some
numbers k1, . . . , kD âˆˆN0 with k1 + . . . + kD = n. We thus get
p2n(0, 0) = (2D)âˆ’2n

k1+...+kD=n

2n
k1, k1, . . . , kD, kD

,
(17.20)
where

N
l1,...,lr

=
N!
l1!Â·Â·Â·lr! is the multinomial coefï¬cient. In particular, for D = 2,
p2n(0, 0) = 4âˆ’2n
n

k=0
(2n)!
(k!)2((n âˆ’k)!)2
= 4âˆ’2n
2n
n

n

k=0
n
k

n
n âˆ’k

=

2âˆ’2n
2n
n
2
.

418
17
Markov Chains
Note that in the last step, we used a simple combinatorial identity that follows,
e.g., by the convolution formula (bn,p âˆ—bn,p)({n}) = b2n,p({n}). Now, by Stirlingâ€™s
formula,
lim
nâ†’âˆ
âˆšn 2âˆ’2n
2n
n

=
1
âˆšÏ€ ,
hence limnâ†’âˆnp2n(0, 0) = 1
Ï€ . In particular, we have âˆ
n=1 p2n(0, 0) = âˆ. That
is, two-dimensional symmetric simple random walk is recurrent.
For D â‰¥3, the sum over the multinomial coefï¬cients cannot be computed in
a satisfactory way. However, it is not too hard to give an estimate that shows that
there exists a c = cD such that p2n(0, 0) â‰¤c nâˆ’D/2, which implies G(0, 0) â‰¤
c âˆ
n=1 nâˆ’D/2 < âˆ(see, e.g., [53, page 361] or [59, Example 6.31]). Here,
however, we follow a different route.
Things would be easy if the individual coordinates of the chain were independent
one-dimensional random walks. In this case, the probability that at time 2n all
coordinates are zero would be the Dth power of the probability that the ï¬rst
coordinate is zero. For one coordinate, however, which moves only with probability
1/D and thus has variance 1/D, the probability of being back at the origin at time
2n is approximately (n Ï€/D)âˆ’1/2. Up to a factor, we would thus get (17.18) without
using the multidimensional local central limit theorem.
An elegant way to decouple the coordinates is to pass from discrete time to
continuous time in such a way that the individual coordinates become independent
but such that the Green function remains unchanged.
We give the details. Let (T i
t )tâ‰¥0, i = 1, . . . , D be independent Poisson processes
with rate 1/D. Let Z1, . . . , ZD be independent (and independent of the Poisson
processes) symmetric simple random walks on Z. Deï¬ne T := T 1 + . . . + T D,
Y i
t := Zi
T i
t for i = 1, . . . , D and let Yt = (Y 1
t , . . . , Y D
t ). Then Y is a Markov chain
in continuous time with Q-matrix q(x, y) = p(x, y) âˆ’1{x=y}. As T is a Poisson
process with rate 1, (XTt )tâ‰¥0 is also a Markov process with Q-matrix q. It follows
that (XTt )tâ‰¥0
D= (Yt)tâ‰¥0. We now compute
GY :=
 âˆ
0
P0[Yt = 0] dt =
 âˆ
0
âˆ

n=0
P0
)X2n = 0, Tt = 2n* dt
=
âˆ

n=0
p2n(0, 0)
 âˆ
0
eâˆ’t t2n
(2n)! dt = G(0, 0).
The two processes (Xn)nâˆˆN0 and (Yt)tâˆˆ[0,âˆ) thus have the same Green function. As
the coordinates of Y are independent, we have
GY =
 âˆ
0
P0[Y 1
t = 0]D dt.

17.5
Application: Recurrence and Transience of Random Walks
419
Hence we only have to compute the asymptotics of P0[Y 1
t
= 0] for large t. We
can argue as follows. By the law of large numbers, we have T 1
t â‰ˆt/D for large t.
Furthermore, P0[Y 1
t is even] â‰ˆ1
2. Hence we have, with nt = âŒŠt/2DâŒ‹for t â†’âˆ
(compare Exercise 17.5.2),
P0[Y 1
t = 0] âˆ¼1
2P
)
Z1
2nt = 0
*
= 1
2
2nt
nt

4âˆ’nt âˆ¼

2Ï€/D
âˆ’1/2 tâˆ’1/2.
(17.21)
Since
3 âˆ
1
tâˆ’Î± dt < âˆif and only if Î± > 1, we also have GY < âˆif and only if
D > 2. However, this is the statement of PÃ³lyaâ€™s theorem.
Finally, we present a third method of studying recurrence and transience of
random walks that does not rely on the Euclidean properties of the integer lattice
but rather on the Fourier inversion formula.
First consider a general (discrete time) irreducible random walk with transition
matrix p on ZD. By Ï†(t) = 
xâˆˆZD eiâŸ¨t,xâŸ©p(0, x) denote the characteristic function
of a single transition. The convolution of the transition probabilities translates into
powers of the characteristic function; hence
Ï†n(t) =

xâˆˆZD
eiâŸ¨t,xâŸ©pn(0, x).
By the Fourier inversion formula (Theorem 15.11), we recover the n-step transition
probabilities from Ï†n by
pn(0, x) = (2Ï€)âˆ’D

[âˆ’Ï€,Ï€)D eâˆ’iâŸ¨t,xâŸ©Ï†n(t) dt.
In particular, for Î» âˆˆ(0, 1),
RÎ» :=
âˆ

n=0
Î»npn(0, 0)
= (2Ï€)âˆ’D
âˆ

n=0

[âˆ’Ï€,Ï€)D Î»n Ï†n(t) dt
= (2Ï€)âˆ’D

[âˆ’Ï€,Ï€)D
1
1 âˆ’Î» Ï†(t) dt.
= (2Ï€)âˆ’D

[âˆ’Ï€,Ï€)D Re

1
1 âˆ’Î» Ï†(t)

dt.

420
17
Markov Chains
Now G(0, 0) = limÎ»â†‘1 RÎ» and hence
X is recurrent â‡â‡’lim
Î»â†‘1

[âˆ’Ï€,Ï€)D Re

1
1 âˆ’Î» Ï†(t)

dt = âˆ.
(17.22)
If we had Ï†(t) = 1 for some t âˆˆ(âˆ’2Ï€, 2Ï€)D \ {0}, then we would have Ï†n(t) = 1
for every n âˆˆN and hence, by Exercise 15.2.1, P0[âŸ¨Xn, t/(2Ï€)âŸ©âˆˆZ] = 1. Thus X
would not be irreducible contradicting the assumption. Due to the continuity of Ï†
for all Îµ > 0, we thus have
inf 	|Ï†(t) âˆ’1| : t âˆˆ[âˆ’Ï€, Ï€)D \ (âˆ’Îµ, Îµ)D
 > 0.
We summarize the discussion in a theorem due to Chung and Fuchs [27].
Theorem 17.42 (Chungâ€“Fuchs [27])
An irreducible random walk on ZD with
characteristic function Ï† is recurrent if and only if, for every Îµ > 0,
lim
Î»â†‘1

(âˆ’Îµ,Îµ)D Re

1
1 âˆ’Î» Ï†(t)

dt = âˆ.
(17.23)
Now consider symmetric simple random walk. Here Ï†(t) =
1
D
D
i=1 cos(ti).
Expanding the cosine function in a Taylor series, we get cos(ti) = 1 âˆ’1
2t2
i + O(t4
i );
hence 1 âˆ’Ï†(t) =
1
2Dâˆ¥tâˆ¥2
2 + O(âˆ¥tâˆ¥4
2). We infer that X is recurrent if and only if
3
âˆ¥tâˆ¥2<Îµ âˆ¥tâˆ¥âˆ’2
2
dt = âˆ. We compute this integral in polar coordinates (with CD the
surface of the unit sphere in RD):

âˆ¥tâˆ¥2<Îµ
âˆ¥tâˆ¥âˆ’2
2
dt = CD
 Îµ
0
rDâˆ’1râˆ’2 dr = âˆ
â‡â‡’
D â‰¤2.
Hence, X is recurrent if and only if D â‰¤2.
In Sect. 19.3, we will encounter a further method of proving PÃ³lyaâ€™s theorem that
has a completely different structure and that is based on the connection between
Markov chains and electrical networks.
In fact, the Chungâ€“Fuchs theorem can be used to compute the numerical values
of the Green function GD(0, 0) of symmetric simple random walk on ZD if we
compute numerically the so-called Watson integral
GD(0, 0) = (2Ï€)âˆ’D

[âˆ’Ï€,Ï€)D
D
D âˆ’(cos(x1) + . . . + cos(xD)) dx.
(17.24)

17.5
Application: Recurrence and Transience of Random Walks
421
For this purpose, we follow [80] (where there are further reï¬nements of the method)
to transform the D-fold integral into a double integral. Denote by
I0(t) := 1
Ï€
 Ï€
0
et cos(Î¸) dÎ¸
the so-called modiï¬ed Bessel function of the ï¬rst kind. Using the identity 1
Î» =
3 âˆ
0
eâˆ’Î»t dt for the integrand and applying Fubiniâ€™s theorem, we get
GD(0, 0) =
D
(2Ï€)D
 âˆ
0
eâˆ’Dt
 
[âˆ’Ï€,Ï€)D et(cos(x1)+...+cos(xD)) dx

dt
and thus
GD(0, 0) = D
 âˆ
0
eâˆ’Dt I0(t)D dt.
(17.25)
The right-hand side of (17.25) can quickly be computed numerically with great
accuracy (see Table 17.1).
For the case D = 3, Watson [169] found the expression
Table 17.1 Green function GD(0, 0) and return probability FD(0, 0) of simple symmetric
random walk on ZD. The numerical computations are based on (17.25).
D
GD(0, 0)
FD(0, 0)
2
âˆ
1
3
1.51638605915
0.34053732955
4
1.23946712185
0.19320167322
5
1.15630812484
0.13517860982
6
1.11696337322
0.10471549562
7
1.09390631559
0.08584493411
8
1.07864701202
0.07291264996
9
1.06774608638
0.06344774965
10
1.05954374789
0.05619753597
11
1.05313615291
0.05045515982
12
1.04798637482
0.04578912090
13
1.04375406289
0.04191989708
14
1.04021240323
0.03865787709
15
1.03720412092
0.03586962312
16
1.03461657857
0.03345836447
17
1.03236691238
0.03135214040
18
1.03039276285
0.02949628913
19
1.02864627888
0.02784852234
20
1.02709011674
0.02637559869

422
17
Markov Chains
G3(0, 0) = 1218 + 12
âˆš
2 âˆ’10
âˆš
3 âˆ’7
âˆš
6
Ï€2
K

(2 âˆ’
âˆš
3)(
âˆš
3 âˆ’
âˆš
2)
2
,
where K(m) =
3 1
0

(1 âˆ’t2)(1 âˆ’mt2)
âˆ’1/2 dt is the complete elliptic integral of
the ï¬rst kind with modulus m âˆˆ(âˆ’1, 1). This in turn can be expressed as a (quickly
convergent) series
K(m) = Ï€
2

1 +
âˆ

n=1
 (2n)!
4n(n!)2
2
m2

.
Glasser and Zucker [61] found an expression as a product of four Gamma functions,
G3(0, 0) =
âˆš
6
32Ï€3 Î“
 1
24

Î“
 5
24

Î“
 7
24

Î“
11
24

= 1.5163860591519780181 . . .
Takeaways Symmetric
nearest
neighbour
random
walk
on
the
D-
dimensional integer lattice is recurrent if D â‰¤2 and is transient if D > 2.
A (one-dimensional) random walk on the integers is recurrent if and only if
the jump distribution is centred. The (numerical) computation of the Green
function is possible via the Fourier inversion formula.
Exercise 17.5.1 For n âˆˆN0, let pn be the matrix of n-step transition probabilities
of simple symmetric random walk on ZD. For n âˆˆN, derive the formula (see
Theorem 15.11)
p2n(0, 0) = (2Ï€)âˆ’D

[âˆ’Ï€,Ï€)D Dâˆ’2n
cos(t1) + . . . + cos(tD)
2n dt.
By a suitable bound for the integral, conclude the convergence nD/2p2n(0, 0)
nâ†’âˆ
âˆ’â†’
2(4Ï€/D)âˆ’D/2 (see (17.18)). â™£
Exercise 17.5.2 Show (17.21) formally. â™£
Exercise 17.5.3 Use Theorem 17.42 to show that a random walk on Z2 with

xâˆˆZ2 x p(0, x) = 0 is recurrent if 
xâˆˆZ2 âˆ¥xâˆ¥2
2 p(0, x) < âˆ. â™£
Exercise 17.5.4 Use Theorem 17.42 to show that, for D â‰¥3 every irreducible
random walk on ZD is transient â™£
Exercise 17.5.5 Show
(17.25)
for
GD(0, 0)
directly
with
the
p2n(0, 0)
from (17.20) and using the representation of I0(t) as the series I0(t)
=
âˆ
k=0(k!)âˆ’2 (t/2)k. â™£

17.6
Invariant Distributions
423
17.6
Invariant Distributions
In the following, let p be a stochastic matrix on the discrete space E and let
(Xn)nâˆˆN0 be a corresponding Markov chain.
This section is devoted to the question: Which distributions are preserved under
the dynamics of the Markov chain? Of course, often the chain will not stay put in a
speciï¬c state but the distribution of the random state of the chain might nevertheless
be the same for all times. If such an invariant distribution exists, we will see in
Chap. 18 that under rather weak conditions, the distribution of a Markov chain
(started in an arbitrary state) converges in the large time limit to such an invariant
distribution.
Deï¬nition 17.43 If Î¼ is a measure on E and f : E â†’R is a map, then we
write Î¼p({x}) = 
yâˆˆE Î¼({y})p(y, x) and pf (x) = 
yâˆˆE p(x, y)f (y) if the sums
converge.
Deï¬nition 17.44
(i) A Ïƒ-ï¬nite measure Î¼ on E is called an invariant measure if
Î¼p = Î¼.
A probability measure that is an invariant measure is called an invariant
distribution. Denote by I the set of invariant distributions.
(ii) A function f : E â†’R is called subharmonic if pf exists and if f â‰¤pf .
f is called superharmonic if f â‰¥pf and harmonic if f = pf .
Remark 17.45 In the terminology of linear algebra, an invariant measure is a left
eigenvector of p corresponding to the eigenvalue 1. A harmonic function is a right
eigenvector corresponding to the eigenvalue 1. â™¦
Lemma 17.46 If f is bounded and (sub-, super-) harmonic, then (f (Xn))nâˆˆN0 is a
(sub-, super-) martingale with respect to the ï¬ltration F = Ïƒ(X) generated by X.
Proof Let f be bounded and subharmonic. Then
Ex[f (Xn)
Fnâˆ’1] = EXnâˆ’1[f (X1)] =

yâˆˆE
p(Xnâˆ’1, y)f (y)
= pf (Xnâˆ’1) â‰¥f (Xnâˆ’1).
âŠ“âŠ”
Theorem 17.47 If any point is transient, then an invariant distribution does not
exist.
Proof By assumption, G(x, y) = âˆ
n=0 pn(x, y) < âˆfor all x, y âˆˆE; hence
pn(x, y)
nâ†’âˆ
âˆ’â†’
0. For every probability measure Î¼ on E, we thus have that
Î¼pn({x})
nâ†’âˆ
âˆ’â†’0. If Î¼ was invariant, however, then we would have Î¼pn({x}) =
Î¼({x}) for all n âˆˆN.
âŠ“âŠ”

424
17
Markov Chains
Theorem 17.48 Let x be a recurrent state and let Ï„ 1
x = inf{n â‰¥1 :
Xn = x}.
Then one invariant measure Î¼x is deï¬ned by
Î¼x({y}) = Ex
â¡
â£
Ï„ 1
x âˆ’1

n=0
1{Xn=y}
â¤
â¦=
âˆ

n=0
Px
'
Xn = y, Ï„ 1
x > n
(
.
Proof First we have to show that Î¼x({y}) < âˆfor all y âˆˆE. For y = x, clearly
Î¼x({x}) = 1. For y Ì¸= x and F(x, y) = 0, we have Î¼x({y}) = 0. Now let y Ì¸= x and
F(x, y) > 0. As x is recurrent, we have F(x, y) = F(y, x) = 1 and y is recurrent
(Theorem 17.36). Let
:
F(x, y) = Px
'
Ï„ 1
x > Ï„ 1
y
(
.
Then :
F(x, y) > 0 (otherwise y would not be visited). Changing the roles of x and
y, we also get :
F(y, x) > 0.
By the strong Markov property (Theorem 17.14), we have
Ey
â¡
â£
Ï„ 1
x âˆ’1

n=0
1{Xn=y}
â¤
â¦= 1 + Ey
â¡
â¢â£
Ï„ 1
x âˆ’1

n=Ï„ 1y
1{Xn=y}; Ï„ 1
x > Ï„ 1
y
â¤
â¥â¦
= 1 +

1 âˆ’:
F(y, x)

Ey
â¡
â£
Ï„ 1x âˆ’1

n=0
1{Xn=y}
â¤
â¦.
Hence,
Ey
â¡
â£
Ï„ 1
x âˆ’1

n=0
1{Xn=y}
â¤
â¦=
1
:
F(y, x).
Therefore,
Î¼x({y}) = Ex
â¡
â£
Ï„ 1
x âˆ’1

n=0
1{Xn=y}
â¤
â¦= Ex
â¡
â¢â£
Ï„ 1
x âˆ’1

n=Ï„ 1y
1{Xn=y}; Ï„ 1
x > Ï„ 1
y
â¤
â¥â¦=
:
F (x, y)
:
F (y, x) < âˆ.
Deï¬ne pn(x, y) = Px
)
Xn = y; Ï„ 1
x > n
*
. Then, for every z âˆˆE,
Î¼x p({z}) =

yâˆˆE
Î¼x({y}) p(y, z) =
âˆ

n=0

yâˆˆE
pn(x, y) p(y, z).

17.6
Invariant Distributions
425
Case 1: x Ì¸= z.
In this case,

yâˆˆE
pn(x, y)p(y, z) =

yâˆˆE
Px
'
Xn = y, Ï„ 1
x > n, Xn+1 = z
(
= Px
'
Ï„ 1
x > n + 1; Xn+1 = z
(
= pn+1(x, z).
Hence (since p0(x, z) = 0)
Î¼x p({z}) =
âˆ

n=0
pn+1(x, z) =
âˆ

n=1
pn(x, z) =
âˆ

n=0
pn(x, z) = Î¼x({z}).
Case 2: x = z.
In this case, we have

yâˆˆE
pn(x, y)p(y, x) =

yâˆˆE
Px
'
Xn = y; Ï„1
x > n; Xn+1 = x
(
= Px
'
Ï„1
x = n + 1
(
.
Thus (since Px
)
Ï„ 1
x = 0
*
= 0)
Î¼x p({x}) =
âˆ

n=0
Px
'
Ï„ 1
x = n + 1
(
= 1 = Î¼x({x}).
âŠ“âŠ”
Corollary 17.49 If X is positive recurrent, then Ï€ :=
Î¼x
Ex
)
Ï„ 1x
* is an invariant
distribution for any x âˆˆE.
Theorem 17.50 If X is irreducible, then X has at most one invariant distribution.
Remark 17.51
(i) One could in fact show that if X is irreducible and recurrent, then an invariant
measure of X is unique up to a multiplicative factor. However, the proof is a
little more involved. Since we will not need the statement here, we leave its
proof as an exercise (compare Exercise 17.6.6; see also [39, Section 6.5]).
(ii) For transient X, there can be more than one invariant measure. For example,
consider the asymmetric random walk on Z that jumps one step to the right
with probability r and one step to the left with probability 1 âˆ’r (for some
r âˆˆ(0, 1)). The invariant measures are the nonnegative linear combinations of
the measures Î¼1 and Î¼2 given by Î¼1({x}) â‰¡1 and Î¼2({x}) = (r/(1 âˆ’r))x,
x âˆˆZ. X is transient if and only if r Ì¸= 1/2, in which case we have Î¼1 Ì¸= Î¼2.
â™¦
Proof Let Ï€ and Î½ be invariant distributions. Choose an arbitrary probability vector
(gn)nâˆˆN with gn > 0 for all n âˆˆN. Deï¬ne the stochastic matrix p(x, y) =
âˆ
n=1 gn pn(x, y). Then p(x, y) > 0 for all x, y âˆˆE and Ï€p = Ï€ as well as
Î½p = Î½.

426
17
Markov Chains
Consider now the signed measure Î¼ = Ï€ âˆ’Î½. We have Î¼p = Î¼. If we had
Î¼ Ì¸= 0, then there would exist (since Î¼(E) = 0) points x1, x2 âˆˆE with Î¼({x1}) > 0
and Î¼({x2}) < 0. Clearly, for every y âˆˆE, this would imply
Î¼({x1}) p(x1, y) +
Î¼({x2}) p(x2, y)
 <
Î¼({x1}) p(x1, y)
 +
Î¼({x2}) p(x2, y)
; hence
;; Î¼p
;;
T V =

yâˆˆE


xâˆˆE
Î¼({x})p(x, y)

<

yâˆˆE

xâˆˆE
|Î¼({x})| p(x, y) =

xâˆˆE
|Î¼({x})| = âˆ¥Î¼ âˆ¥T V .
Since this is a contradiction, we conclude that Î¼ = 0.
âŠ“âŠ”
Recall that I is the set of invariant distributions of X.
Theorem 17.52 Let X be irreducible. X is positive recurrent if and only if I Ì¸= âˆ….
In this case, I = {Ï€} with
Ï€({x}) =
1
Ex[Ï„ 1x ] > 0
for all x âˆˆE.
Proof If X is positive recurrent, then I Ì¸= âˆ…by Corollary 17.49. Now let I Ì¸= âˆ…
and Ï€ âˆˆI. As X is irreducible, we have Ï€({x}) > 0 for all x âˆˆE. Let PÏ€ =

xâˆˆE Ï€({x})Px. Fix an x âˆˆE and for n âˆˆN0, let
Ïƒ n
x = sup
	
m â‰¤n : Xm = x

âˆˆN0 âˆª{âˆ’âˆ}
be the time of last entrance in x before time n. (Note that this is not a stopping time.)
By the Markov property, for all k â‰¤n,
PÏ€
)
Ïƒ n
x = k
*
= PÏ€
)
Xk = x, Xk+1 Ì¸= x, . . . , Xn Ì¸= x
*
= PÏ€
)
Xk+1 Ì¸= x, . . . , Xn Ì¸= x |Xk = x
*
PÏ€[Xk = x]
= Ï€({x}) Px
)
X1, . . . , Xnâˆ’k Ì¸= x
*
= Ï€({x}) Px
)
Ï„ 1
x â‰¥n âˆ’k + 1
*
.

17.6
Invariant Distributions
427
Hence, for every n âˆˆN0 (since Py
)
Ï„ 1
x < âˆ
*
= 1 for all y âˆˆE),
1 =
n

k=0
PÏ€
)
Ïƒ n
x = k
*
+ PÏ€
)
Ïƒ n
x = âˆ’âˆ
*
= Ï€({x})
n

k=0
Px
'
Ï„ 1
x â‰¥n âˆ’k + 1
(
+ PÏ€
'
Ï„ 1
x â‰¥n + 1
(
nâ†’âˆ
âˆ’â†’Ï€({x})
âˆ

k=1
Px
'
Ï„ 1
x â‰¥k
(
= Ï€({x}) Ex
'
Ï„ 1
x
(
.
Therefore, Ex
)
Ï„ 1
x
*
=
1
Ï€({x}) < âˆ, and thus X is positive recurrent.
âŠ“âŠ”
Example 17.53 Let (px)xâˆˆN0 be numbers in (0, 1] and let X be an irreducible
Markov chain on N0 with transition matrix
p(x, y) =
â§
âªâ¨
âªâ©
px,
if y = x + 1,
1 âˆ’px,
if y = 0,
0,
else.
If Î¼ is an invariant measure, then the equations for Î¼p = Î¼ read
Î¼({n}) = pnâˆ’1 Î¼({n âˆ’1})
for n âˆˆN,
Î¼({0}) =
âˆ

n=0
Î¼({n})(1 âˆ’pn).
Hence we get
Î¼({n}) = Î¼({0})
nâˆ’1

k=0
pk
and (note that the sum is a telescope sum)
Î¼({0}) = Î¼({0})
âˆ

n=0
(1 âˆ’pn)
nâˆ’1

k=0
pk = Î¼({0})

1 âˆ’
âˆ

n=0
pn

.
Hence there exists a nontrivial invariant measure Î¼ (that is, Î¼({0}) can be chosen
strictly positive) if and only if âˆ
n=0 pn = 0. This, however, is true if and only if
âˆ
n=0(1 âˆ’pn) = âˆ. Using a Borelâ€“Cantelli argument, it is not hard to show that
this is exactly the condition for recurrence of X.

428
17
Markov Chains
If Î¼ Ì¸= 0, then Î¼ is a ï¬nite measure if and only if
M :=
âˆ

n=0
nâˆ’1

k=0
pk < âˆ.
Hence X is positive recurrent if and only if M < âˆ. In fact, it is not hard to show
that M is the expected time to return to 0; hence the criterion for positive recurrence
could also be deduced by Theorem 17.52.
A necessary condition for M < âˆis of course that the series âˆ
n=0(1 âˆ’pn)
diverge; that is, that X is recurrent. One sufï¬cient condition for M < âˆis
âˆ

n=0
exp

âˆ’
nâˆ’1

k=0
(1 âˆ’pk)

< âˆ.
â™¦
Takeaways An irreducible Markov chain possesses an invariant distribution
if and only if it is positive recurrent. The invariant distribution is unique and
is given as the reciprocals of the expected return times.
Exercise 17.6.1 Consider the Markov chain from Fig. 17.1 (page 412). Determine
the set of all invariant distributions. Show that the states 6, 7 and 8 are positive
recurrent and compute the expected ï¬rst entrance times
E6[Ï„6] = 17
4 ,
E7[Ï„7] = 17
5
and
E8[Ï„8] = 17
8 .
â™£
Exercise 17.6.2 Let X = (Xt)tâ‰¥0 be a Markov chain on E in continuous time with
Q-matrix q. Show that a probability measure Ï€ on E is an invariant distribution for
X if and only if 
xâˆˆE Ï€({x})q(x, y) = 0 for all y âˆˆE. â™£
Exercise 17.6.3 Let G be a countable Abelian group and let p be the transition
matrix of an irreducible random walk X on G. That is, we have p(hg, hf ) =
p(g, f ) for all h, g, f âˆˆG. (This generalizes the notion of a random walk on ZD.)
Use Theorem 17.52 to show that X is positive recurrent if and only if G is ï¬nite. â™£
Exercise 17.6.4 Let r âˆˆ[0, 1] and let X be the Markov chain on N0 with transition
matrix (see Fig. 17.2 on page 413)
p(x, y) =
â§
âªâªâªâªâ¨
âªâªâªâªâ©
1,
if x = 0 and y = 1,
r,
if y = x + 1 â‰¥2,
1 âˆ’r,
if y = x âˆ’1,
0,
else.

17.7
Stochastic Ordering and Coupling
429
Compute the invariant measure and show the following using Theorem 17.52:
(i) If r âˆˆ

0, 1
2

, then X is positive recurrent.
(ii) If r = 1
2, then X is null recurrent.
(iii) If r âˆˆ{0} âˆª
 1
2, 1
*
, then X is transient. â™£
Exercise 17.6.5
(i) Use a direct argument to show that the Markov chain in Example 17.53 is
recurrent if and only if âˆ
n=0(1 âˆ’pn) = âˆ.
(ii) Show that the expected time to return to 0 is M and infer that the chain is
positive recurrent if and only if M < âˆ.
(iii) Give examples of sequences (px)xâˆˆN0 such that the chain is (a) transient, (b)
null recurrent, (c) positive recurrent, and (d) positive recurrent but
âˆ

n=0
exp

âˆ’
nâˆ’1

k=0
(1 âˆ’pk)

= âˆ.
â™£
Exercise 17.6.6 Let X be irreducible and recurrent. Show that, as claimed in
Remark 17.51, the invariant measure is unique up to constant multiples.
Hint: Let Ï€ Ì¸= 0 be an invariant measure for X and abbreviate PÏ€ = 
xâˆˆE
Ï€({x})Px
(note that, in general, this need not be a ï¬nite measure). Let x, y âˆˆE with x Ì¸= y
and deduce by induction that
Ï€({y}) = PÏ€
)Ï„ 1
x â‰¥n, X0 Ì¸= x, Xn = y* +
n

k=1
PÏ€
)Ï„ 1
x â‰¥k, X0 = x, Xk = y*.
Infer that
Ï€({y}) â‰¥
âˆ

k=1
PÏ€
)
Ï„ 1
x â‰¥k, X0 = x, Xk = y
*
= Ï€({x}) Î¼x({y}),
where Î¼x is the invariant measure deï¬ned in Theorem 17.48. Now use the fact
that Ï€pn = Ï€ and Î¼xpn = Î¼x for all n âˆˆN to conclude that even Ï€({y}) =
Ï€({x})Î¼x({y}) holds. â™£
17.7
Stochastic Ordering and Coupling
In many situations, for the comparison of two distributions, it is helpful to construct
a product space such that the two distributions are the marginal distributions but
are not necessarily independent. We ï¬rst introduce the abstract principle of such
couplings and then give some examples.

430
17
Markov Chains
There are many concepts to order probability measures on R or Rd such that the
â€œlargerâ€ one has a greater preference for large values than the â€œsmallerâ€ one. As
one of the most prominent orders we present here the so-called stochastic order and
illustrate its connection with couplings. As an excuse for presenting this section in
a chapter on Markov chains, we ï¬ll ï¬nally use a simple Markov chain in order to
prove a theorem on the stochastic order of binomial distributions.
Deï¬nition 17.54 Let (E1, E1, Î¼1) and (E2, E2, Î¼2) be probability spaces. A prob-
ability measure Î¼ on (E1Ã—E2, E1 âŠ—E2) with Î¼( Â· Ã—E2) = Î¼1 and Î¼(E1Ã— Â·) = Î¼2
is called a coupling of Î¼1 and Î¼2.
Clearly, the product measure Î¼ = Î¼1 âŠ—Î¼2 is a coupling, but in many situations
there are more interesting ones.
Example 17.55 Let X be a real random variable and let f, g : R â†’R be monotone
increasing functions with E[f (X)2] < âˆand E[g(X)2] < âˆ. We want to show
that the random variables f (X) and g(X) are nonnegatively correlated.
To this end, let Y be an independent copy of X; that is, a random variable with
PY = PX that is independent of X. Note that E[f (X)] = E[f (Y)] and E[g(X)] =
E[g(Y)]. For all numbers x, y âˆˆR, we have (f (x) âˆ’f (y))(g(x) âˆ’g(y)) â‰¥0.
Hence
0 â‰¤E)f (X) âˆ’f (Y)g(X) âˆ’g(Y)*
= E[f (X)g(X)] âˆ’E[f (X)] E[g(Y)] + E[f (Y)g(Y)] âˆ’E[f (Y)] E[g(X)]
= 2 Cov[f (X), g(X)].
â™¦
(17.26)
Example 17.56 Let (E, Ï±) be a Polish space. For two probability measures P and
Q on (E, B(E)), denote by K(P, Q) âŠ‚M1(E Ã— E) the set of all couplings of P
and Q. The so-called Wasserstein metric on M1(E) is deï¬ned by
dW(P, Q) := inf
0 
Ï±(x, y) Ï•(d(x, y)) : Ï• âˆˆK(P, Q)
1
.
(17.27)
It can be shown that (this is the Kantorovichâ€“Rubinstein theorem [84]; see also [37,
pages 420ff])
dW(P, Q) = sup
0 
f d(P âˆ’Q) : f âˆˆLip1(E; R)
1
.
(17.28)
Compare this representation of the Wasserstein metric with that of the total variation
norm,
âˆ¥P âˆ’Qâˆ¥T V = sup
0 
f d(P âˆ’Q) : f âˆˆLâˆ(E) with âˆ¥f âˆ¥âˆâ‰¤1
1
.
(17.29)

17.7
Stochastic Ordering and Coupling
431
In fact, we can also give a deï¬nition for the total variation in terms of a coupling:
Let D := {(x, x) : x âˆˆE} be the diagonal in E Ã— E. Then
âˆ¥P âˆ’Qâˆ¥T V = inf
	
Ï•((E Ã— E) \ D) : Ï• âˆˆK(P, Q)

.
(17.30)
See [60] for a comparison of different metrics on M1(E).â™¦
As an example of a more involved coupling, we quote the following theorem that is
due to Skorohod.
Theorem 17.57 (Skorohod coupling) Let Î¼, Î¼1, Î¼2, . . . be probability measures
on a Polish space E with Î¼n
nâ†’âˆ
âˆ’â†’
Î¼. Then there exists a probability space
(Î©, A, P) with random variables X, X1, X2, . . . with PX = Î¼ and PXn = Î¼n for
every n âˆˆN such that Xn
nâ†’âˆ
âˆ’â†’X almost surely.
Proof See, e.g., [83, page 79].
âŠ“âŠ”
Reï¬‚ection For real valued random variables, a Skorohod coupling can be con-
structed explicitly using the distribution functions. How does this work in detail?
â™ 
We now come to the concept of stochastic order.
Deï¬nition 17.58 Let Î¼1, Î¼2 âˆˆM1(Rd). We write Î¼1 â‰¤st Î¼2 if

f dÎ¼1 â‰¤

f dÎ¼2
for every monotone increasing bounded function f : Rd â†’R. In this case, we say
that Î¼2 is stochastically larger than Î¼1.
Evidently, â‰¤st is a partial order on M1(Rd). The stochastic order belongs to the
class of so-called integral orders that are deï¬ned by the requirement that the integrals
with respect to a certain class of functions (here: monotone increasing and bounded)
are ordered. Other classes of functions that are often considered are convex functions
or indicator functions on lower or upper orthants.
Let F1 and F2 be the distribution functions of Î¼1 and Î¼2. Clearly, Î¼1 â‰¤st Î¼2
implies F1(x) â‰¥F2(x) for all x âˆˆRd. If d = 1, then both statements are equivalent.
However, for d â‰¥2, the condition F1 â‰¥F2 is weaker than Î¼1 â‰¤st Î¼2. For example,
consider d = 2 and
Î¼1 = 1
2Î´(0,0) + 1
2Î´(1,1)
and
Î¼2 = 1
2Î´(1,0) + 1
2Î´(0,1).
The partial order deï¬ned by the comparison of the distribution functions is called
(lower) orthant order.
For a survey on different orders of probability measures, see, e.g., [120].

432
17
Markov Chains
The following theorem was shown by Strassen [161] in larger generality for
integral orders.
Theorem 17.59 (Strassenâ€™s theorem) Let
L := 	(x1, x2) âˆˆRd Ã— Rd : x1 â‰¤x2

.
Then Î¼1 â‰¤st Î¼2 if and only if there is a coupling Ï• of Î¼1 and Î¼2 with Ï•(L) = 1.
Proof Let Ï• be such a coupling. For monotone increasing bounded f : Rd â†’R,
we have f (x1)âˆ’f (x2) â‰¤0 for every x = (x1, x2) âˆˆL; hence
3
f dÎ¼1âˆ’
3
f dÎ¼2 =
3
L

f (x1) âˆ’f (x2)

Ï•(dx) â‰¤0 and thus Î¼1 â‰¤st Î¼2.
Now assume Î¼1 â‰¤st Î¼2. We only consider the case d = 1 (see [120, Thm. 3.3.5]
for d â‰¥2). Here F((x1, x2)) := min(F1(x1), F2(x2)) deï¬nes a distribution function
on R Ã— R (see Exercise 1.5.5) that corresponds to a coupling Ï• with Ï•(L) = 1. A
somewhat more explicit representation can be obtained using random variables. Let
U be a random variable that is uniformly distributed on (0, 1). Then
Xi := F âˆ’1
i
(U) := inf
	
x âˆˆR : Fi(x) â‰¥U

is a real random variable with distribution Î¼i (see proof of Theorem 1.104). Clearly,
we have X1 â‰¤X2 almost surely; that is, P[(X1, X2) âˆˆL] = 1. Evidently, the
distribution function of (X1, X2) is F.
âŠ“âŠ”
While Strassenâ€™s theorem yields the existence of an abstract coupling, in many
examples a natural coupling can be established and used as a tool for proving, e.g.,
stochastic orders.
Example 17.60 Let n âˆˆN and 0 â‰¤p1 â‰¤p2 â‰¤1. Let Y1, . . . , Yn be independent
random variables that are uniformly distributed on [0, 1]. Deï¬ne Xi = #{k â‰¤n :
Yk â‰¤pi}, i = 1, 2. Then Xi âˆ¼bn,pi and X1 â‰¤X2 almost surely. This coupling
shows that bn,p1 â‰¤st bn,p2.
An even simpler coupling can be used to show that bm,p â‰¤st bn,p for m â‰¤n and
p âˆˆ[0, 1]. â™¦
Theorem 17.61 Let n1, n2 âˆˆN and p1, p2 âˆˆ(0, 1). We have bn1,p1 â‰¤st bn2,p2 if
and only if
(1 âˆ’p1)n1 â‰¥(1 âˆ’p2)n2
(17.31)
and
n1 â‰¤n2.
(17.32)
Proof (The proof follows the exposition in [100, Section 3]) Since bni,pi({0}) =
(1âˆ’pi)ni, conditions (17.31) and (17.32) are clearly necessary for bn1,p1 â‰¤st bn2,p2.
Hence we only have to show sufï¬ciency of the two conditions.

17.7
Stochastic Ordering and Coupling
433
Assume that (17.31) and (17.32) hold. By Example 17.60, it is enough to consider
the smallest p2 that fulï¬lls (17.31). Hence we assume (1 âˆ’p1)n1 = (1 âˆ’p2)n2.
Deï¬ne Î» := âˆ’n1 log(1 âˆ’p1) = âˆ’n2 log(1 âˆ’p2). We will construct a binomially
distributed random variable by throwing a PoiÎ»-distributed number T of balls in ni
boxes and count the number of nonempty boxes. More precisely, let T âˆ¼PoiÎ» and
let X1, X2, . . . be independent and uniformly distributed on [0, 1] and independent
of T . For n âˆˆN, t âˆˆN0 and l = 1, . . . , n, deï¬ne
Mn,t,l = #
	
s â‰¤t : Xs âˆˆ((l âˆ’1)/n, l/n]

and the number of nonempty boxes after t balls are thrown:
Nn,t :=
n

l=1
1{Mn,t,l>0}.
By Theorem 5.35, the random variables Mn,T,1, . . . , Mn,T,n are independent and
PoiÎ»/n-distributed. In particular, we have
P[Mni,T,l > 0] = 1 âˆ’eâˆ’Î»/ni = pi
and thus Nni,T âˆ¼bni,pi, i = 1, 2. Hence it sufï¬ces to show that Nn1,T â‰¤st Nn2,T .
For this in turn it is enough to show
Nn1,t â‰¤st Nn2,t
for all t âˆˆN0.
(17.33)
In fact, let f : {0, . . . , n} â†’R be monotone increasing. Then
E[f (Nn1,T )] =
âˆ

t=0
E[f (Nn1,t)] P[T = t]
â‰¤
âˆ

t=0
E[f (Nn2,t)] P[T = t] = E[f (Nn2,T )].
We use an induction argument to show (17.33). For t = 0, the claim holds trivially.
Now assume that (17.33) holds for some given t âˆˆN0. We are now at the point to
use a Markov chain. Note that (for ï¬xed n), (Nn,t)t=0,1,... is a Markov chain with
state space {0, . . ., n} and transition matrix
pn(k, l) =
â§
âªâ¨
âªâ©
k/n,
if l = k,
1 âˆ’k/n,
if l = k + 1,
0,
otherwise.

434
17
Markov Chains
We deï¬ne for k, l = 0, . . ., n
hn,l(k) =
n

j=l
pn(k, j) =
â§
âªâ¨
âªâ©
0,
if k < l âˆ’1,
1 âˆ’k/n,
if k = l âˆ’1,
1,
if k > l âˆ’1.
Then P[Nn,t+1 â‰¥l] = E[hn,l(Nn,t)] and hn,l(k) is monotone increasing both in k
and in n. Hence by the induction hypothesis, we have
P[Nn1,t+1 â‰¥l] = E[hn1,l(Nn1,t)] â‰¤E[hn1,l(Nn2,t)]
â‰¤E[hn2,l(Nn2,t)] = P[Nn2,t+1 â‰¥l].
We conclude that Nn1,t+1 â‰¤st Nn2,t+1 which completes the induction and the proof
of the theorem.
âŠ“âŠ”
Takeaways A coupling is a probability measure on a product space with
given marginals. In many situations it is desirable to have a coupling with
additional properties like all the mass lies above the diagonal. The latter
property can be achieved if the marginals are stochastically ordered. Optimal
couplings can be used also for the deï¬nitions of a metric on probability
measures such as the Wasserstein metric, for example. Using Markov chains
we construct a coupling to prove a theorem on the stochastic ordering of
binomial distributions.
Exercise 17.7.1 Use an elementary direct coupling argument to show the claim of
Theorem 17.61 for the case n2/n1 âˆˆN. â™£
Exercise 17.7.2 For the Poisson distribution, show that
PoiÎ»1 â‰¤st PoiÎ»2 â‡â‡’Î»1 â‰¤Î»2.
â™£
Exercise 17.7.3 Let n âˆˆN, p âˆˆ(0, 1) and Î» > 0. Show that
bn,p â‰¤st PoiÎ» â‡â‡’(1 âˆ’p)n â‰¥eâˆ’Î».
â™£

Chapter 18
Convergence of Markov Chains
We consider a Markov chain X with invariant distribution Ï€ and investigate
conditions under which the distribution of Xn converges to Ï€ for n â†’âˆ.
Essentially it is necessary and sufï¬cient that the state space of the chain cannot
be decomposed into subspaces
â€¢
that the chain does not leave
â€¢
or that are visited by the chain periodically; e.g., only for odd n or only for even n.
In the ï¬rst case, the chain would be called reducible, and in the second case, it would
be periodic.
We study periodicity of Markov chains in the ï¬rst section. In the second section,
we prove the convergence theorem. The third section is devoted to applications of
the convergence theorem to computer simulations with the so-called Monte Carlo
method. In the last section, we describe the speed of convergence to the equilibrium
by means of the spectrum of the transition matrix.
18.1
Periodicity of Markov Chains
We study the conditions under which a positive recurrent Markov chain X on
the countable space E (and with transition matrix p), started in an arbitrary
Î¼ âˆˆM1(E), converges in distribution to an invariant distribution Ï€; that is,
Î¼pn
nâ†’âˆ
âˆ’â†’Ï€. Clearly, it is necessary that Ï€ be the unique invariant distribution;
that is, up to a factor Ï€ it is the unique left eigenvector of p for the eigenvalue 1.
As shown in Theorem 17.50, for this uniqueness it is sufï¬cient that the chain be
irreducible.
In order for Î¼pn
nâ†’âˆ
âˆ’â†’Ï€ to hold for every Î¼ âˆˆM1(E), a certain contraction
property of p is necessary. Manifestly, 1 is the largest (absolute value of an)
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_18
435

436
18
Convergence of Markov Chains
eigenvalue of p. However, p is sufï¬ciently contractive only if the multiplicity of
the eigenvalue 1 is exactly 1 and if there are no further (possibly complex-valued)
eigenvalues of modulus 1.
For the latter property, it is not sufï¬cient that the chain be irreducible. For
example, consider on E = {0, . . ., N âˆ’1} the Markov chain with transition matrix
p(x, y) = 1{y=x+1(mod N)}. The eigenvalue 1 has the multiplicity 1. However,
all complex Nth roots of unity e2Ï€ik/N, k = 0, . . . , N âˆ’1, are eigenvalues of
modulus 1. Clearly, the uniform distribution on E is invariant but lim
nâ†’âˆÎ´xpn does
not exist for any x âˆˆE. In fact, every point is visited periodically after N steps.
In order to obtain criteria for the convergence of Markov chains, we thus have to
understand periodicity ï¬rst. Thereafter, for irreducible aperiodic chains, we state
the convergence theorem.
If m, n âˆˆN, then write m
n if m is a divisor of n; that is, if n
m âˆˆN. If M âŠ‚N,
then denote by gcd(M) the greatest common divisor of all n âˆˆM. In the following,
let X be a Markov chain on the countable space E with transition matrix p.
Deï¬nition 18.1
(i) For x, y âˆˆE, deï¬ne
N(x, y) :=
	
n âˆˆN0 : pn(x, y) > 0

.
For any x âˆˆE, dx := gcd(N(x, x)) is called the period of the state x.
(ii) If dx = dy for all x, y âˆˆE, then d := dx is called the period of X.
(iii) If dx = 1 for all x âˆˆE, then X is called aperiodic.
See Figs. 18.1 and 18.2 for illustrations of aperiodic and periodic Markov chains.
Lemma 18.2 For any x âˆˆE, there exists an nx âˆˆN with
pndx(x, x) > 0
for all n â‰¥nx.
(18.1)
1/2
1/2
1/2
1/2
1/2
1
1
1/2
Fig. 18.1 The left Markov chain is periodic with period 2, and the right Markov chain is aperiodic.

18.1
Periodicity of Markov Chains
437
1
1
1
1
1
1
1/2
1/2
2
8
5
3
4
7
6
1
1
Fig. 18.2 Here N(8, 8) = {6, 10, 12, 14, 16, . . .}; hence d8 := gcd({6, 10, 12, . . .}) = 2 and
n8 = 5. The chain thus has period 2. However, n1 = 2 and n4 = 4.
Proof Let k1, . . . , kr
âˆˆN(x, x) with gcd({k1, . . . , kr}) = dx. Then, for all
m1, . . . , mr âˆˆN0, we also have r
i=1 ki mi âˆˆN(x, x). Basic number theory then
yields that, for every n â‰¥nx := r Â· r
i=1(ki/dx), there are numbers m1, . . . , mr âˆˆ
N0 with n dx = r
i=1 ki mi. Hence (18.1) holds.
âŠ“âŠ”
The problem of ï¬nding the smallest number N such that any n dx, n â‰¥N can
be written as a nonnegative integer linear combination of k1, . . . , kr is called the
Frobenius problem. The general solution is unknown; however, for the case r = 2,
Sylvester [163] showed that N = (k1/dx âˆ’1)(k2/dx âˆ’1) is minimal. In the general
case, for N, the upper bound 2 max{ki : i = 1, . . . , r}2/(rd2
x) is known; see, e.g.,
[45].
Lemma 18.3 Let X be irreducible. Then the following statements hold.
(i) d := dx = dy for all x, y âˆˆE.
(ii) For all x, y âˆˆE, there exist nx,y âˆˆN and Lx,y âˆˆ{0, . . . , d âˆ’1} such that
nd + Lx,y âˆˆN(x, y)
for all n â‰¥nx,y.
(18.2)
Lx,y is uniquely determined, and we have
Lx,y + Ly,z + Lz,x = 0 (mod d)
for all x, y, z âˆˆE.
(18.3)
Proof
(i) Let m, n âˆˆN0 with pm(x, y) > 0 and pn(y, z) > 0. Then
pm+n(x, z) â‰¥pm(x, y) pn(y, z) > 0.
Hence we have
N(x, y) + N(y, z) := 	m + n : m âˆˆN(x, y), n âˆˆN(y, z)
 âŠ‚N(x, z).
(18.4)

438
18
Convergence of Markov Chains
If, in particular, m âˆˆN(x, y), n âˆˆN(y, x) and k â‰¥ny, then kdy âˆˆN(y, y);
hence m+kdy âˆˆN(x, y) and m+n+kdy âˆˆN(x, x). Therefore, dx
(m+n+
kdy) for every k â‰¥ny; hence dx
dy. Similarly, we get dy
dx; hence dx = dy.
(ii) Let m âˆˆN(x, y). Then m + kd âˆˆN(x, y) for every k â‰¥nx. Hence (18.2)
holds with
nx,y := nx +
Im
d
J
and
Lx,y := m âˆ’d
Im
d
J
.
Owing to (18.4), we have
(nx,y + ny,z)d + Lx,y + Ly,z âˆˆN(x, z).
Together with z = x, it follows that d
(Lx,y + Ly,x). Hence the value of Lx,y
is unique in {0, . . ., d âˆ’1} and Lx,y = âˆ’Ly,x (mod d). For general z, we infer
that d
(Lx,y + Ly,z + Lz,x); hence (18.3).
âŠ“âŠ”
Theorem 18.4 Let X be irreducible with period d. Then there exists a disjoint
decomposition of the state space
E =
dâˆ’1

i=0
Ei
(18.5)
with the property
p(x, y) > 0 and x âˆˆEi
â‡’
y âˆˆEi+1 (mod d).
(18.6)
This decomposition is unique up to cyclic permutations.
See Fig. 18.3 for an illustration of the state space decomposition of a periodic
Markov chain.
E
E
E
1
0
2
Fig. 18.3 State space decomposition of a Markov chain with period d = 3.

18.2
Coupling and Convergence Theorem
439
Property (18.6) says that X visits the Ei one after the other (see Fig. 18.3 or 18.2,
where d = 2, E0 = {1, 3, 5, 7} and E1 = {2, 4, 6, 8}). Somewhat more formally,
we could write: If x âˆˆEi for some i, then Px
)
Xn âˆˆEi+n (mod d)
*
= 1.
Proof
Existence x0 âˆˆE and let
Ei := 	y âˆˆE : Lx0,y = i
for i = 0, . . . , d âˆ’1.
Clearly, (18.5) holds. Let i âˆˆ{0, . . ., d âˆ’1} and x âˆˆEi. If y âˆˆE with p(x, y) > 0,
then Lx,y = 1 and hence Lx0,y = Lx0,x + Lx,y = i + 1 (mod d).
Uniqueness Let (
Ei, i = 0, . . ., d âˆ’1) be another decomposition that satis-
ï¬es (18.5) and (18.6). Without loss of generality, assume E0 âˆ©
E0 Ì¸= âˆ…(otherwise
permute the 
Ei cyclically until this holds). Fix an arbitrary x0 âˆˆE0 âˆ©
E0. By
assumption, p(x0, y) > 0 now implies y âˆˆE1 and y âˆˆ
E1; hence y âˆˆE1 âˆ©
E1.
Inductively, we get that pnd+i(x, y) > 0 implies y âˆˆEi âˆ©
Ei (for all n âˆˆN and
i = 0, . . . , d âˆ’1).
However, since the chain is irreducible, for every y âˆˆE, there exist numbers
n(y) and i(y) such that pn(y) d+i(y)(x0, y) > 0; hence y âˆˆEi(y) âˆ©
Ei(y). Therefore,
we have Ei = 
Ei for every i = 0, . . . , d âˆ’1.
âŠ“âŠ”
Takeaways Assume that a Markov chain can return to a given state only at
times that are a multiple of some natural number d and assume that d is the
largest number with this property. Then d is said to be the period of that
state. For irreducible chains, all states have the same period. For example,
for nearest neighbour random walk on the integers, every state has period
d = 2. If we have d = 1 for every state, then the Markov chain is called
aperiodic. For periodic chains, the state space decomposes into d subspaces
that can be entered at speciï¬c times (mod d) only. In this sense, aperiodicity
has the ï¬‚avour of an irreducibility condition which is needed in order that two
independent chains started in arbitrary states could meet each other.
18.2
Coupling and Convergence Theorem
Our goal is to use a coupling of two discrete Markov chains that are started in
different distributions Î¼ and Î½ in order to show the convergence theorem for Markov
chains.
In the following, let E be a countable space and let p be a stochastic matrix
on E. Recall the deï¬nition of a general coupling of two probability measures from
Deï¬nition 17.54.

440
18
Convergence of Markov Chains
Deï¬nition 18.5 A bivariate process ((Xn, Yn))nâˆˆN0 with values in E Ã— E is called
a coupling if (Xn)nâˆˆN0 and (Yn)nâˆˆN0 are Markov chains, each with transition
matrix p.
A coupling is called successful if P(x,y)
) 
mâ‰¥n{Xm Ì¸= Ym}
*
nâ†’âˆ
âˆ’â†’
0 for all
x, y âˆˆE.
Of course, two independent chains form a coupling, though maybe not the most
interesting one.
Example 18.6 (Independent coalescence) The most important coupling is Markov
chains that run independently until they coalesce: Let X and Y be independent
chains with transition matrix p until they ï¬rst meet. After that, the chains run
together. We call this coupling the independent coalescent. The transition matrix is
Â¯p

(x1, y1), (x2, y2)

=
â§
âªâ¨
âªâ©
p(x1, x2) Â· p(y1, y2),
if x1 Ì¸= y1,
p(x1, x2),
if x1 = y1, x2 = y2,
0,
if x1 = y1, x2 Ì¸= y2.
Denote by Ï„ := inf{n âˆˆN0 : Xn = Yn} the time of coalescence. We can construct
the coupling using two independent chains ËœX and ËœY by deï¬ning X := ËœX, ËœÏ„ :=
inf{n âˆˆN0 : ËœXn = ËœYn} and
Yn :=
0 ËœYn,
if n < ËœÏ„,
Xn,
if n â‰¥ËœÏ„.
Instead of checking by a direct computation that this process (X, Y) is indeed
a coupling with transition matrix Â¯p, consider the construction of Markov chains
from Theorem 17.17: Let (Rn(x) : n âˆˆN0, x âˆˆE) be independent random
variables with distribution P[Rn(x1) = x2] = p(x1, x2), and let ËœRn((x1, y1)) =
(Rn(x1), Rn(y1)). Then ( ËœRn)nâˆˆN0 is independent and we have
P
) ËœRn((x1, y1)) = (x2, y2)
*
= Â¯p

(x1, y1), (x2, y2)

.
As we saw in Theorem 17.17, by Xn+1 := Rn(Xn) and Yn+1 := Rn(Yn), two
Markov chains X and Y are deï¬ned with transition matrix p. On the other hand,
we have (Xn+1, Yn+1) =
ËœRn((Xn, Yn)). Hence the bivariate process is indeed a
coupling with transition matrix Â¯p. â™¦
Example 18.7 Let E = Z and p(x, y) = 1/3 if |xâˆ’y| â‰¤1 and 0 otherwise. Clearly,
p is the transition matrix of an aperiodic recurrent random walk on Z. We will show
that we can obtain a successful coupling by coalescing independent chains.
Accordingly, let ËœX and ËœY be independent random walks with transition matrix p.
Then the difference chain (Zn)nâˆˆN0 := ( ËœXn âˆ’ËœYn)nâˆˆN0 is a symmetric random walk

18.2
Coupling and Convergence Theorem
441
with ï¬nite expectation and hence recurrent. Furthermore, Z is irreducible. For any
two points x, y âˆˆZ, we thus have
P(x,y)[ËœÏ„ < âˆ] = Pxâˆ’y[Zn = 0 for some n âˆˆN0] = 1.
Therefore, X and Y coalesce almost surely. â™¦
Recurrence, irreducibility and aperiodicity alone are not sufï¬cient for the inde-
pendent coalescence coupling to be successful. In Exercise 18.2.4, an example is
studied that shows that spacial homogeneity cannot easily be dropped if we want to
have a successful coupling. Dropping the assumption of recurrence is easier, as the
following theorem shows.
Theorem 18.8 Let X be an arbitrary aperiodic and irreducible random walk on
Zd with transition matrix p. Then there exists a successful coupling (X, Y).
Proof
Step 1.
First, consider the case where p(0, x) = 3âˆ’d for all x âˆˆ{âˆ’1, 0, 1}d. The
individual coordinates X(1), . . . , X(d) of X are independent random walks on Z with
transition probabilities P0[X(i)
1
= xi] = 1/3 for xi = âˆ’1, 0, 1. By Example 18.7,
we can construct independent successful couplings (X(i), Y (i)), i = 1, . . ., d, with
merging times Ï„ (i). Deï¬ne Y = (Y (1), . . . , Y (d)) and Ï„ = max{Ï„ (1), . . . , Ï„ (d)} <
âˆ. Then (X, Y) is a successful coupling and Xn = Yn for n â‰¥Ï„.
Step 2.
Now, consider the case where
Î» := 3d min 	p(0, x) : x âˆˆ{âˆ’1, 0, 1}d
 > 0.
If Î» = 1, then the condition of Step 1 is fulï¬lled and we are done. Hence, we
assume that Î» âˆˆ(0, 1). We deï¬ne the transition matrix Ë†p on Zd by Ë†p(x, y) = 3âˆ’d
for y âˆ’x âˆˆ{âˆ’1, 0, 1}d. Note that also Ë‡p := (p âˆ’Î» Ë†p)/(1 âˆ’Î») is the transition
matrix of a random walk on Zd and that
p = Î» Ë†p + (1 âˆ’Î») Ë‡p.
Let Ë†X and Ë‡X be independent random walks with transition matrices Ë†p and Ë‡p,
respectively. Assume that Ë†X0 = X0 and Ë‡X0 = 0. Furthermore, let Z1, Z2, . . . be
i.i.d. Bernoulli random variables with parameter Î» that are independent of Ë†X and Ë‡X.
Deï¬ne Sn := Z1 + . . . + Zn for n âˆˆN and
Xn := Ë†XSn + Ë‡Xnâˆ’Sn.
That is, in each time step, a coin ï¬‚ip decides whether X makes a jump according to
the matrix Ë†p or Ë‡p. Hence X is a random walk with transition matrix p.

442
18
Convergence of Markov Chains
By Step 1, there exists a successful coupling ( Ë†X, Ë†Y) such that Ë†Y is independent of
Ë‡X and Z1, Z2, . . .. Consequently,
Yn := Ë†YSn + Ë‡Xnâˆ’Sn,
n âˆˆN,
is also a random walk with transition matrix p. Since we have Sn â†’âˆalmost
surely, the coupling (X, Y) is successful.
Step 3.
Finally, we consider the general situation. Since X is irreducible and
aperiodic, by Lemma 18.3(ii), there exists an N âˆˆN, such that the N-step transition
matrix fulï¬lls
pN(0, x) > 0
for all x âˆˆ{âˆ’1, 0, 1}d.
Hence, the random walk Xâ€² = (Xâ€²
n)nâˆˆN := (XnN)nâˆˆN fulï¬lls the condition from
Step 2. Let (Xâ€², Y â€²) be the coupling that was constructed in Step 2 and let
Ï„ := inf
	
n âˆˆN0 : Xâ€²
m = Y â€²
m for all m â‰¥n

.
Then Y â€² is a random walk with transition matrix pN. For n âˆˆN0, deï¬ne YnN := Y â€²
n.
It remains to close the gaps between the points {0, N, 2N, . . .} in such a way that Y
is a random walk and (X, Y) is a successful coupling.
Let (Ux,y,n : x, y âˆˆZd, n âˆˆN0) be an independent family of (Zd)Nâˆ’1-valued
random variables Ux,y,n = (Ux,y,n
1
, . . . , Ux,y,n
Nâˆ’1 ) such that
P[(X1, . . . , XNâˆ’1) âˆˆÂ· |X0 = x, XN = y] = PUx,y,n
for all x, y âˆˆZd with pN(x, y) > 0 and for all n âˆˆN0. We further assume that the
Ux,y,n are independent of X and Y â€². For k âˆˆ{nN + 1, . . . , (n + 1)N âˆ’1}, deï¬ne
Yk :=

U
Y â€²
n,Y â€²
n+1,n
kâˆ’nN
,
if n < Ï„,
Xk,
else.
It is easy to check that Y is indeed a random walk with transition matrix p. By
construction, the coupling (X, Y) is successful.
âŠ“âŠ”
Theorem 18.9 Let X be a Markov chain on E with transition matrix p. If there
exists a successful coupling, then every bounded harmonic function is constant.
Proof Let f : E â†’R be bounded and harmonic; hence pf = f . Let x, y âˆˆ
E, and let (X, Y) be a successful coupling. By Lemma 17.46, (f (Xn))nâˆˆN0 and
(f (Yn))nâˆˆN0 are martingales; hence we have
|f (x) âˆ’f (y)| =
E(x,y)[f (Xn) âˆ’f (Yn)]
 â‰¤2âˆ¥f âˆ¥âˆP(x,y)[Xn Ì¸= Yn]
nâ†’âˆ
âˆ’â†’0. âŠ“âŠ”

18.2
Coupling and Convergence Theorem
443
Corollary 18.10 If X is an irreducible random walk on Zd, then every bounded
harmonic function is constant.
This statement holds more generally if we replace Zd by a locally compact Abelian
group. In that form, the theorem goes back to Choquet and Deny [24], see also [144].
Proof Let p be the transition matrix of X. Let Â¯X be a Markov chain with transition
matrix Â¯p(x, y) = 1
2p(x, y) + 1
2 1{x}(y). Clearly, X and Â¯X have the same harmonic
functions. Now Â¯X is an aperiodic irreducible random walk; hence, by Theorem 18.8,
there is a successful coupling for all initial states.
âŠ“âŠ”
Reï¬‚ection Consider the random walk on the integers with transition matrix given
by p(k, k + 1) = r and p(k, k âˆ’1) = 1 âˆ’r for some r âˆˆ[0, 1]. The bounded
harmonic functions are constant, but what are the unbounded harmonic functions?
Be careful, the cases r = 1
2 and r Ì¸= 1
2 are different. â™ 
Theorem 18.11 Let p be the transition matrix of an irreducible, positive recurrent,
aperiodic Markov chain on E. Then the independent coalescent chain is a successful
coupling.
Proof Let ËœX and ËœY be two independent Markov chains on E, each with transition
matrix p. Then the bivariate Markov chain Z := (( ËœXn, ËœYn))nâˆˆN0 has the transition
matrix p deï¬ned by
p

(x1, y1), (x2, y2)

= p(x1, x2) Â· p(y1, y2).
We ï¬rst show that the matrix p is irreducible. Only here do we need aperiodicity of
p. Accordingly, ï¬x (x1, y1), (x2, y2) âˆˆE Ã— E. Then, by Lemma 18.2, there exists
an m0 âˆˆN such that
pn(x1, x2) > 0
and
pn(y1, y2) > 0
for all n â‰¥m0.
For n â‰¥m0, we thus have p n(x1, y1), (x2, y2) > 0. Hence p is irreducible.
Now deï¬ne the stopping time Ï„ of the ï¬rst entrance of ( ËœX, ËœY) into the diagonal
D := {(x, x) : x âˆˆE} by Ï„ := inf 	n âˆˆN0 :
ËœXn = ËœYn

. Let Ï€ be the invariant
distribution of ËœX. Then, clearly, the product measure Ï€ âŠ—Ï€ âˆˆM1(EÃ—E) is an (and
then the) invariant distribution of ( ËœX, ËœY ). Thus ( ËœX, ËœY) is positive recurrent (hence,
in particular, recurrent) by Theorem 17.52. Therefore, P(x,y)[Ï„ < âˆ] = 1 for all
initial points (x, y) âˆˆE Ã— E of Z.
âŠ“âŠ”
Theorem 18.12 Let X be a Markov chain with transition matrix p such that there
exists a successful coupling. Then
;;(Î¼ âˆ’Î½)pn;;
T V
nâ†’âˆ
âˆ’â†’0 for all Î¼, Î½ âˆˆM1(E).
If X is aperiodic and positive recurrent with invariant distribution Ï€, then we
have
;;LÎ¼[Xn] âˆ’Ï€
;;
T V
nâ†’âˆ
âˆ’â†’0 for all Î¼ âˆˆM1(E).

444
18
Convergence of Markov Chains
Proof It is enough to consider the case Î¼ = Î´x, Î½ = Î´y for some x, y âˆˆE.
Summation over x and y yields the general case. Let (Xn, Yn)nâˆˆN0 be a successful
coupling. Then
;;(Î´x âˆ’Î´y)pn;;
T V â‰¤2 P(x,y)[Xn Ì¸= Yn]
nâ†’âˆ
âˆ’â†’
0.
âŠ“âŠ”
We summarize the connection between aperiodicity and convergence of distribu-
tions of X in the following theorem.
Theorem 18.13 (Convergence of Markov chains) Let X be an irreducible, posi-
tive recurrent Markov chain on E with invariant distribution Ï€. Then the following
are equivalent:
(i) X is aperiodic.
(ii) For every x âˆˆE, we have
;;Lx[Xn] âˆ’Ï€
;;
T V
nâ†’âˆ
âˆ’â†’0.
(18.7)
(iii) Equation (18.7) holds for some x âˆˆE.
(iv) For every Î¼ âˆˆM1(E), we have
;;Î¼pn âˆ’Ï€
;;
T V
nâ†’âˆ
âˆ’â†’0.
Proof The implications (iv)
â‡â‡’
(ii) â‡’
(iii) are evident. The implica-
tion (i) â‡’(ii) was shown in Theorem 18.12. Hence we only show (iii) â‡’(i).
â€œ(iii) â‡’(i)â€
Assume that (i) does not hold. If X has period d â‰¥2, and if n âˆˆN
is not a multiple of d, then, by Theorem 17.52,
;;Î´xpn âˆ’Ï€
;;
T V â‰¥|pn(x, x) âˆ’Ï€({x})| = Ï€({x}) > 0.
Thus, for every x âˆˆE, we have lim sup
nâ†’âˆ
;;Î´xpn âˆ’Ï€
;;
T V > 0. Therefore, (iii) does
not hold.
âŠ“âŠ”
Takeaways For two examples of aperiodic and irreducible Markov chains,
we have constructed a coupling such that two chains meet almost surely:
Random walks on the d-dimensional integer lattice and positive recurrent
Markov chains. In both cases, we infer that bounded harmonic functions are
constant. In the latter case, we also get convergence of the Markov chain to
the invariant distribution (in distribution).
Exercise 18.2.1 Let dP be the Prohorov metric (see (13.4) and Exercise 13.2.1).
Show that dP (P, Q) â‰¤âˆšdW(P, Q) for all P, Q âˆˆM1(E). If E has a ï¬nite
diameter diam(E), then dW(P, Q) â‰¤(diam(E) + 1)dP (P, Q) for all P, Q âˆˆ
M1(E). â™£

18.3
Markov Chain Monte Carlo Method
445
Exercise 18.2.2 Consider the bivariate process (X, Y) that was constructed from ËœX
and ËœY in Example 18.6. Show that (X, Y) is a coupling with transition matrix Â¯p. â™£
Exercise 18.2.3 Let X be an arbitrary aperiodic irreducible recurrent random walk
on Zd. Show that, for any two starting points, the independent coalescent coupling
is successful.
Hint: Show that the difference of two independent recurrent random walks is a
recurrent random walk. â™£
Exercise 18.2.4 Let X be a Markov chain on Z2 with transition matrix
p((x1, x2), (y1, y2)) =
â§
âªâªâªâªâªâ¨
âªâªâªâªâªâ©
1
4,
if x1 = 0, âˆ¥y âˆ’xâˆ¥2 = 1,
1
4,
if x1 Ì¸= 0 and y1 = x1 Â± 1, x2 = y2,
1
2,
if x1 Ì¸= 0 and y1 = x1, x2 = y2,
0,
else.
Intuitively, this is the symmetric simple random walk whose vertical transitions are
all blocked away from the vertical axis. Show that X is null recurrent, irreducible
and aperiodic and that independent coalescence does not give a successful coupling.
â™£
18.3
Markov Chain Monte Carlo Method
Let E be a ï¬nite set and let Ï€ âˆˆM1(E) with Ï€(x) := Ï€({x}) > 0 for every x âˆˆE.
We consider the problem of sampling a random variable Y with distribution Ï€ on a
computer. For example, this is a relevant problem if E is a very large set and if sums
of the type 
xâˆˆE f (x)Ï€(x) have to be approximated numerically by the estimator
nâˆ’1 n
i=1 f (Yi) (see Example 5.21).
Assume that our computer has a random number generator that provides
realizations of i.i.d. random variables U1, U2, . . . that are uniformly distributed on
[0, 1]. In order for the problem to be interesting, assume also that the distribution Ï€
cannot be constructed directly too easily.
Metropolis Algorithm
We have seen already in Example 17.19 how to simulate a Markov chain on a
computer. Now the idea is to construct a Markov chain X whose distribution
converges to Ï€ in the long run. If we simulate such a chain and let it run long enough
this should give a sample that is distributed approximately like Ï€. The chain should
be designed so that at each step, only a small number of transitions are possible

446
18
Convergence of Markov Chains
in order to ensure that the procedure described in Example 17.19 works efï¬ciently.
(Of course, the chain with transition matrix p(x, y) = Ï€(y) converges to Ï€, but
this does not help a lot.) This method of producing (approximately) Ï€-distributed
samples and using them to estimate expected values of functions of interest is called
the Markov chain Monte Carlo method or, brieï¬‚y, MCMC (see [15, 112, 119]).
Let q be the transition matrix of an arbitrary irreducible Markov chain on E (with
q(x, y) = 0 for most y âˆˆE). We use this to construct the Metropolis matrix (see
[70, 114]).
Deï¬nition 18.14 Deï¬ne a stochastic matrix p on E by
p(x, y) =
â§
âªâ¨
âªâ©
q(x, y) min

1, Ï€(y)q(y,x)
Ï€(x)q(x,y)

,
if x Ì¸= y, q(x, y) > 0,
0,
if x Ì¸= y, q(x, y) = 0,
1 âˆ’
zÌ¸=x p(x, z),
if x = y.
p is called the Metropolis matrix of q and Ï€.
Note that p is reversible (see Sect. 19.2); that is, for all x, y âˆˆE, we have
Ï€(x) p(x, y) = Ï€(y) p(y, x).
(18.8)
In particular, Ï€ is invariant (check this!). We thus obtain the following theorem.
Theorem 18.15 Assume that q is irreducible and that for any x, y âˆˆE, we have
q(x, y) > 0 if and only if q(y, x) > 0. Then the Metropolis matrix p of q and Ï€ is
irreducible with unique invariant distribution Ï€. If, in addition, q is aperiodic, or q
is not reversible with respect to Ï€, then p is aperiodic.
In order to simulate a chain X that converges to Ï€, we take a reference chain with
transition matrix q and use the Metropolis algorithm: If the chain with transition
matrix q proposes a transition from the present state x to state y, then we accept this
proposal with probability
Ï€(y) q(y, x)
Ï€(x) q(x, y) âˆ§1.
Otherwise the chain X stays at x.
In the deï¬nition of p, the distribution Ï€ appears only in terms of the quotients
Ï€(y)/Ï€(x). In many cases of interest, these quotients are easy to compute even
though Ï€(x) and Ï€(y) are not. We illustrate this with an example.
Example 18.16 (Ising model) The Ising model (pronounced like the English word
â€œeasingâ€) is a thermodynamical (and quantum mechanical) model for ferromag-
netism in crystals. It makes the following assumptions:
â€¢
Atoms are placed at the sites of a lattice Î› (for example, Î› = {0, . . ., N âˆ’1}2).

18.3
Markov Chain Monte Carlo Method
447
â€¢
Each atom i âˆˆÎ› has a magnetic spin x(i) âˆˆ{âˆ’1, 1} that either points upwards
(x(i) = +1) or downwards (x(i) = âˆ’1).
â€¢
Neighboring atoms interact.
â€¢
Due to thermic ï¬‚uctuations, the state of the system is random and distributed
according to the so-called Boltzmann distribution Ï€ on the state space E :=
{âˆ’1, 1}Î›. A parameter of this distribution is the inverse temperature Î² = 1
T â‰¥0
(with T the absolute temperature).
Deï¬ne the local energy that describes the energy level of a single atom at i âˆˆÎ›
as a function H i of the state x of the whole system,
H i(x) = 1
2

jâˆˆÎ›: iâˆ¼j
1{x(i)Ì¸=x(j)}.
Here i âˆ¼j indicates that i and j are neighbors in Î› (that is, coordinate-wise mod
N, we also speak of periodic boundary conditions). The total energy (or Hamilton
function) of the system in state x is the sum of the individual energies,
H(x) =

iâˆˆÎ›
H i(x) =

iâˆ¼j
1{x(i)Ì¸=x(j)}.
The Boltzmann distribution Ï€ on E := {âˆ’1, 1}Î› for the inverse temperature Î² â‰¥0
is deï¬ned by
Ï€(x) = Zâˆ’1
Î² exp(âˆ’Î²H(x)),
where the partition sum ZÎ² = 
xâˆˆE
exp(âˆ’Î²H(x)) is the normalising constant such
that Ï€ is a probability measure.
Macroscopically, the individual spins cannot be observed but the average mag-
netization can; that is, the modulus of the average of all spins,
mÎ›(Î²) =

xâˆˆE
Ï€(x)

1
#Î›

iâˆˆÎ›
x(i)
 .
If we consider a very large system, then we are close to the so-called thermodynamic
limit
m(Î²) := lim
Î›â†‘Zd mÎ›(Î²).

448
18
Convergence of Markov Chains
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.84
0.85
0.86
0.87
0.88
0.89
0.9
0.91
0.92
Magnetization
Inverse temperature
Fig. 18.4 Computer simulation of the magnetization curve of the Ising model on a 1000 Ã— 1000
grid. The dashed vertical line indicates the critical inverse temperature.
Using a contour argument, as for percolation (see [127]), one can show that (for
d â‰¥2) there exists a critical value Î²c = Î²c(d) âˆˆ(0, âˆ) such that
m(Î²)
0> 0,
if Î² > Î²c,
= 0,
if Î² < Î²c.
(18.9)
See Fig. 18.4 for a computer simulation of the curve Î² â†’m(Î²).
For a similar model, the Weiss ferromagnet, we will prove in Example 23.20
the existence of such a phase transition. In the physical literature, Tc := 1/Î²c is
called the Curie temperature for spontaneous magnetization. This is a material-
dependent constant (chromium bromide (CrBr) 37 Kelvin, nickel 645 K, iron
1017 K, cobalt 1404 K). Below the Curie temperature, these materials are magnetic,
and above it they are not. Below the critical temperature, the magnetization increases
with decreasing temperature. We will see in a computer simulation that the Ising
model displays this critical temperature effect.
If x âˆˆE, then denote by xi,Ïƒ the state in which at site i the spin is changed to
Ïƒ âˆˆ{âˆ’1, +1}; that is,
xi,Ïƒ(j) =

Ïƒ,
if j = i,
x(j),
if j Ì¸= i.

18.3
Markov Chain Monte Carlo Method
449
Furthermore, deï¬ne the state xi in which the spin at i is reversed, xi := xi,âˆ’x(i). As
reference chain, we choose a chain with transition probabilities
q(x, y) =
 1
#Î›,
if y = xi for some i âˆˆÎ›,
0,
else.
In words, we choose a random site i âˆˆÎ› (uniformly on Î›) and invert the spin at
that site. Clearly, q is irreducible.
The Metropolis algorithm for this chain accepts the proposal of the reference
chain with probability 1 if Ï€(xi) â‰¥Ï€(x). Otherwise the proposal is accepted only
with probability Ï€(xi)/Ï€(x). However, now
H(xi) âˆ’H(x) =

j: jâˆ¼i
1{x(j)Ì¸=âˆ’x(i)} âˆ’

j: jâˆ¼i
1{x(j)Ì¸=x(i)}
= âˆ’2

j: jâˆ¼i

1{x(j)Ì¸=x(i)} âˆ’1
2

.
Hence Ï€(xi)/Ï€(x) = exp

âˆ’2Î² 
jâˆ¼i

1{x(j)=x(i)} âˆ’1
2

, and this expression is
easy to compute as it depends only on the 2d neighboring spins and, in particular,
does not require knowledge of the value of ZÎ². We thus obtain the Metropolis
transition matrix
p(x, y)=
â§
âªâªâ¨
âªâªâ©
1
#Î›

1 âˆ§exp
'
2Î² 
j: jâˆ¼i
(1{x(j)Ì¸=x(i)}âˆ’1
2)
(
, if y = xi for some i âˆˆÎ›,
1 âˆ’
iâˆˆÎ› p(x, xi), if x = y,
0, else.
For a practical simulation use the computerâ€™s random number generator to produce
independent random variables I1, I2, . . . and U1, U2, . . . with In âˆ¼UÎ› and Un âˆ¼
U[0,1]. Then deï¬ne
Fn(x) =
â§
â¨
â©
xIn,
if Un â‰¤exp
'
2Î² 
j: jâˆ¼i(1{x(j)Ì¸=x(i)} âˆ’1
2)
(
,
x,
else,
and deï¬ne the Markov chain (Xn)nâˆˆN by Xn = Fn(Xnâˆ’1) for n âˆˆN. See Figs. 18.5
and 18.6 for computer simulations of equilibrium states and metastable states of the
Ising model. â™¦

450
18
Convergence of Markov Chains
Fig. 18.5 Equilibrium states of the Ising model on an 800 Ã— 800 grid (black dot = spin +1). Left
side: below the critical temperature (Î² > Î²c); Right side: above the critical temperature.
Fig. 18.6 Ising model (150 Ã— 150 grid) below the critical temperature. Even after a long time, the
computer simulation does not produce the equilibrium state but rather so-called metastable states,
in which the Weiss domains are clearly visible.
Gibbs Sampler
We consider a situation where, as in the above example, a state consists of many
components x = (xi)iâˆˆÎ› âˆˆE and where Î› is a ï¬nite set. As an alternative to the
Metropolis chain, we consider a different procedure to establish a Markov chain
with a given invariant distribution. For the so-called Gibbs sampler or heat bath

18.3
Markov Chain Monte Carlo Method
451
algorithm, the idea is to adapt the state locally to the stationary distribution. If x is
a state and i âˆˆÎ›, then deï¬ne
xâˆ’i := {y âˆˆE : y(j) = x(j) for j Ì¸= i}.
Deï¬nition 18.17 (Gibbs sampler) Let q âˆˆM1(Î›) with q(i) > 0 for every i âˆˆÎ›.
The transition matrix p on E with
p(x, y) =

qi Ï€(xi,Ïƒ)
Ï€(xâˆ’i) ,
if y = xi,Ïƒ for some i âˆˆÎ›,
0,
else,
is called a Gibbs sampler for the invariant distribution Ï€.
Verbally, each step of the chain with transition matrix p can be described by the
following instructions.
(1) Choose a random coordinate I according to some distribution (qi)iâˆˆÎ›.
(2) With probability Ï€(xI,Ïƒ)/Ï€(xâˆ’I), replace x by xI,Ïƒ.
If I = i, then the new state has the distribution L(X|Xâˆ’i = xâˆ’i), where X is
a random variable with distribution Ï€. Note that, for the Gibbs sampler also it is
enough to know the values of the distribution Ï€ only up to the normalising constant.
(In a more general framework, the Gibbs sampler and the Metropolis algorithm can
be understood as special cases of one and the same method.) For states x and y that
differ only in the ith coordinate, we have (since xâˆ’i = yâˆ’i)
Ï€(x) p(x, y) = Ï€(x) qi
Ï€(y)
Ï€(xâˆ’i) = Ï€(y) qi
Ï€(x)
Ï€(yâˆ’i) = Ï€(y) p(y, x).
Thus the Gibbs sampler is a reversible Markov chain with invariant measure Ï€.
Irreducibility of the Gibbs sampler, however, has to be checked for each case.
Example 18.18 (Ising model) In the Ising model described above, we have xâˆ’i =
{xi,âˆ’1, xi,+1}. Hence, for i âˆˆÎ› and Ïƒ âˆˆ{âˆ’1, +1},
Ï€(xi,Ïƒxâˆ’i) =
Ï€(xi,Ïƒ)
Ï€({xi,âˆ’1, xi,+1})
=
eâˆ’Î²H(xi,Ïƒ )
eâˆ’Î²H(xi,âˆ’1) + eâˆ’Î²H(xi,+1)
=

1 + exp
'
Î²

H(xi,Ïƒ) âˆ’H(xi,âˆ’Ïƒ)
(âˆ’1
=

1 + exp
'
2Î² 
j: jâˆ¼i(1{x(j)Ì¸=Ïƒ} âˆ’1
2)
(âˆ’1
.

452
18
Convergence of Markov Chains
The Gibbs sampler for the Ising model is thus the Markov chain (Xn)nâˆˆN0 with
values in E = {âˆ’1, 1}Î› and with transition matrix
p(x, y)=
â§
â¨
â©
1
#Î›

1+exp
'
2Î² 
j: jâˆ¼i
(1{x(j)Ì¸=x(i)}âˆ’1
2)
(âˆ’1
, if y = xi for some i âˆˆÎ›,
0, otherwise.
â™¦
Perfect Sampling
The MCMC method as described above is based on hope: We let the chain run for
a long time and hope that its distribution is close to the invariant distribution. Even
if we can compute the speed of convergence (and in many cases, this is not trivial,
we come back to this point in Sect. 18.4), the distribution will never be exactly the
invariant distribution.
Although this ï¬‚aw might seem inevitable in the MCMC method, it is in fact, at
least theoretically, possible to use a very similar method that allows perfect sampling
according to the invariant distribution Ï€, even if we do not know anything about
the speed of convergence. The idea is simple. Assume that F1, F2, . . . are i.i.d.
random maps E â†’E with P[F(x) = y] = p(x, y) for all x, y âˆˆE. We have
seen how to construct the Markov chain X with initial value X0 = x by deï¬ning
Xn = Fn â—¦Fnâˆ’1 â—¦Â· Â· Â· â—¦F1(x).
Note that F n
1 (x) := F1 â—¦. . . â—¦Fn(x) D= Fn â—¦. . . â—¦F1(x). Hence we have
P[F n
1 (x) = y]
nâ†’âˆ
âˆ’â†’Ï€(y)
for every y.
However, if F n
1 turns out to be a constant map (e.g., F n
1 â‰¡xâˆ—for some random
xâˆ—), then we will also have F m
1
â‰¡xâˆ—for all m â‰¥n. If by some clever choice
of the distribution of Fn one can ensure that the stopping time T := inf{n âˆˆN :
F n
1 is constant} is almost surely ï¬nite (and this is always possible), then we will
have P[F T
1 (x) = y] = Ï€(y) for all x, y âˆˆE. A simple algorithm for this method is
the following.
(1) Let F â†idE and n â†0.
(2) Let n â†n + 1. Generate Fn and let F â†F â—¦Fn.
(3) If F is not a constant map, then go to (2).
(4) Output F(âˆ—).
This method is called coupling from the past and goes back to Propp and Wilson
[138] (see also [55, 56, 92, 137, 139, 171]). David Wilson has nice simulations and
a survey of the current research on his web site http://www.dbwilson.com/. A nice
survey on MCMC methods including coupling from the past is [66].

18.4
Speed of Convergence
453
For a practical implementation, there are two main problems: (1) The full map Fn
has to be generated and has to be composed with F. The computer time needed for
this is at least of the order of the size of the space E. (2) Checking if F is constant
needs computer time of the same order of magnitude. Consequently, the method can
be efï¬ciently implemented only if there is more structure. For example, assume that
E is partially ordered with a smallest element 0 and a largest element 1 (like the
Ising model). Further, assume that the maps Fn can be chosen to be almost surely
monotone increasing. In this case, it is enough to compute at each step F(0) and
F(1) since F is constant if the values coincide.
Takeaways In order to draw random samples (approximately) according to a
given distribution, it is sometimes feasible to simulate a suitable Markov chain
that converges to this distribution as its invariant measure. The Metropolis
algorithm constitutes a universal tool for the construction of such a Markov
chain. The Gibbs sampler is a more speciï¬c algorithm often helpful in
statistical mechanics. The technique of coupling from the past allows for
drawing exactly according to the desired distribution.
18.4
Speed of Convergence
So far we have ignored the question of the speed of convergence of the distribution
PXn to Ï€. For practical purposes, however, this is often the most interesting question.
We do not intend to go into the details and we only brieï¬‚y touch upon the topic.
Without loss of generality, assume E = {1, . . . , N}. If p is reversible (Equation
(18.8)), then f â†’pf deï¬nes a symmetric linear operator on L2(E, Ï€) (exercise!).
All eigenvalues Î»1, . . . , Î»N (listed according to the corresponding multiplicity) are
real and have modulus at most 1 since p is stochastic. Thus we can arrange the
eigenvalues by decreasing modulus Î»1 = 1 â‰¥|Î»2| â‰¥. . . â‰¥|Î»N|. If p is irreducible
and aperiodic, then |Î»2| < 1. Let Î¼1 = Ï€, Î¼2, . . . , Î¼N be an orthonormal basis
of left eigenvectors for the eigenvalues Î»1, . . . , Î»N. Then, for every probability
measure Î¼ = Î±1Î¼1 + . . . + Î±NÎ¼N, we have Î¼pn = N
i=1 Î»n
i Î±i Î¼i
nâ†’âˆ
âˆ’â†’Î±1Ï€.
Since for each n âˆˆN, the left hand side is a probability measure, we have Î±1 = 1
and
âˆ¥Î¼pn âˆ’Ï€âˆ¥T V â‰¤C|Î»2|n
(18.10)
for a constant C (that does not depend on Î¼). A similar formula holds if p is
not reversible; however, with a correction term of order at most nV âˆ’1. Here, V
is the size of the largest Jordan block square matrix for the eigenvalue Î»2 in the

454
18
Convergence of Markov Chains
Jordan canonical form of p. In particular, V is no larger than the multiplicity of the
eigenvalue with second largest modulus.
The speed of convergence is thus exponential with a rate that is determined by
the spectral gap 1 âˆ’|Î»2| of the second largest eigenvalue of p. In practice, for a
large space E, computing the spectral gap is often extremely difï¬cult.
Reï¬‚ection Why have we restricted ourselves to aperiodic Markov chains? What is
Î»2 in the periodic case? For example, consider E = {0, . . ., Nâˆ’1} and the transition
matrix given by p(k, k + 1(mod N)) = 1 for all k. â™ 
Example 18.19 Let r âˆˆ(0, 1) and N âˆˆN, N â‰¥2. Further, let E = {0, . . . , N âˆ’1}.
We consider the transition matrix
p(i, j) =
â§
â¨
â©
r,
if j = i + 1 (mod N),
1 âˆ’r,
if j = i âˆ’1 (mod N),
0,
else.
p is the transition matrix of simple (asymmetric) random walk on the discrete torus
Z/(N), which with probability r makes a jump to the right and with probability
1 âˆ’r makes a jump to the left. Clearly, p is irreducible, and p is aperiodic if and
only if N is odd. Furthermore, the uniform distribution UE is the unique invariant
distribution.
Case 1: N odd.
Let Î¸k = e2Ï€i k/N, k = 0, . . . , N âˆ’1, be the Nth roots of unity
and let the corresponding (right) eigenvectors be
xk :=

Î¸0
k , Î¸1
k , . . . , Î¸Nâˆ’1
k

.
It is easy to check that p has the eigenvalues
Î»k := r Î¸k + (1 âˆ’r) Î¸k = cos
 2Ï€k
N

+ (2r âˆ’1) i sin
 2Ï€k
N

,
k = 0, . . . , N âˆ’1.
The moduli of the eigenvalues are given by |Î»k| = f (2Ï€k/N), where
f (Ï‘) =
2
1 âˆ’4r(1 âˆ’r) sin(Ï‘)2
for Ï‘ âˆˆR.
Since N is odd, |Î»k| is maximal (except for k = 0) for k = Nâˆ’1
2
and for k = N+1
2 .
For these k, |Î»k| equals Î³ :=
2
1 âˆ’4r(1 âˆ’r) sin(Ï€/N)2. Since all eigenvalues
are different, every eigenvalue has multiplicity 1. Hence there is a constant C <
âˆsuch that
âˆ¥Î¼pn âˆ’UEâˆ¥T V â‰¤C Î³ n
for all n âˆˆN, Î¼ âˆˆM1(E).

18.4
Speed of Convergence
455
Case 2: N even.
In this case, p is not aperiodic. Nevertheless, the eigenvalues
and eigenvectors are of the same form as in Case 1. In order to get an aperiodic
chain, for Îµ > 0, deï¬ne the transition matrix
pÎµ := (1 âˆ’Îµ)p + ÎµI,
where I is the unit matrix on E. pÎµ describes the random walk on E that with
probability Îµ does not move and with probability 1 âˆ’Îµ makes a jump according
to p. Clearly, pÎµ is irreducible and aperiodic. The eigenvalues are
Î»Îµ,k = (1 âˆ’Îµ)Î»k + Îµ,
k = 0, . . . , N âˆ’1,
and the corresponding eigenvectors are the xk from above. Evidently, Î»Îµ,0 = 1,
and if Îµ > 0 is very small, then Î»Îµ,N/2 = 2Îµ âˆ’1 is the eigenvalue with the
second largest modulus. For larger values of Îµ, we have |Î»Îµ,1| > |Î»Îµ,N/2|. More
precisely, if we let
Îµ0 :=
(1 âˆ’(2r âˆ’1)2) sin(2Ï€/N)2
(1 âˆ’(2r âˆ’1)2) sin(2Ï€/N)2 + 2 cos(2Ï€/N),
then the eigenvalue with the second largest modulus has modulus
Î³Îµ = |Î»Îµ,N/2| = 1 âˆ’2Îµ,
if Îµ â‰¤Îµ0,
or
Î³Îµ = |Î»Îµ,1|
=
K
(1 âˆ’Îµ) cos

2Ï€
N

+ Îµ
2
+

(1 âˆ’Îµ)(2r âˆ’1) sin

2Ï€
N
2
,
if Îµ â‰¥Îµ0.
It is easy to check that Îµ â†’|Î»Îµ,N/2| is monotone decreasing and that Îµ â†’|Î»Îµ,1|
is monotone increasing. Hence Î³Îµ is minimal for Îµ = Îµ0.
Hence there is a C < âˆwith
âˆ¥Î¼pn
Îµ âˆ’UEâˆ¥T V â‰¤C Î³ n
Îµ
for all n âˆˆN, Î¼ âˆˆM1(E),
and the best speed of convergence (in this class of transition matrices) can be
obtained by choosing Îµ = Îµ0. â™¦

456
18
Convergence of Markov Chains
Example 18.20 (Gamblerâ€™s ruin) We consider the gamblerâ€™s ruin problem from
Example 10.19 with the probability of a gain r âˆˆ(0, 1). Here the state space is
E = {0, . . ., N}, and the transition matrix is of the form
p(i, j) =
â§
âªâªâ¨
âªâªâ©
r,
if j = i + 1 âˆˆ{2, . . ., N},
1 âˆ’r,
if j = i âˆ’1 âˆˆ{0, . . ., N âˆ’2},
1,
if j = i âˆˆ{0, N},
0,
else.
This transition matrix is not irreducible; rather it has two absorbing states 0 and N.
In Example 10.19 (Equation (10.7)) for the case r Ì¸= 1
2, and Example 10.16 for the
case r = 1
2, it was shown that, for every Î¼ âˆˆM1(E),
Î¼pn nâ†’âˆ
âˆ’â†’(1 âˆ’m(Î¼))Î´0 + m(Î¼)Î´N.
(18.11)
Here m(Î¼) = 3 pN(x) Î¼(dx), where the probability pN(x) that the chain, if started
at x, hits N is given by
pN(x) =
â§
âªâªâªâªâ¨
âªâªâªâªâ©
1 âˆ’

1âˆ’r
r
x
1 âˆ’

1âˆ’r
r
N ,
if r Ì¸= 1
2,
x
N ,
if r = 1
2.
How quick is the convergencein (18.11)? Here also the convergencehas exponential
speed and the rate is determined by the second largest eigenvalue of p.
Hence we have to compute the spectrum of p. Clearly, x0 = (1, 0, . . . , 0) and
xN = (0, . . . , 0, 1) are left eigenvectors for the eigenvalue 1. In order for x =
(x0, . . . , xN) to be a left eigenvector for the eigenvalue Î», the following equations
have to hold:
Î»xk = rxkâˆ’1 + (1 âˆ’r)xk+1
for k = 2, . . ., N âˆ’2,
(18.12)
and
Î»xNâˆ’1 = rxNâˆ’2.
(18.13)
If (18.12) and (18.13) hold for x1, . . . , xNâˆ’1, then we deï¬ne x0 :=
1âˆ’r
Î»âˆ’1x1 and
xN :=
r
Î»âˆ’1xNâˆ’1 and get that in fact xr = Î»x. We make the ansatz
Î» = (1 âˆ’r)Ï(Î¸ + Î¸) and xk = Ïk(Î¸k âˆ’Î¸k)
for k = 1, . . . , N âˆ’1,

18.4
Speed of Convergence
457
where
Ï =
2
r/(1 âˆ’r) and Î¸ âˆˆC \ {âˆ’1, +1} with |Î¸| = 1.
Thus we have Î¸Î¸ = 1 and (1 âˆ’r)Ïk+1 = rÏkâˆ’1. Therefore, for every k =
2, . . . , N âˆ’1,
Î»xk = (1 âˆ’r) Ïk+1(Î¸k âˆ’Î¸k)(Î¸ + Î¸)
= (1 âˆ’r) Ïk+1)
(Î¸k+1 âˆ’Î¸k+1) + Î¸Î¸ (Î¸kâˆ’1 âˆ’Î¸kâˆ’1)
*
= r Ïkâˆ’1(Î¸kâˆ’1 âˆ’Î¸kâˆ’1) + (1 âˆ’r) Ïk+1(Î¸k+1 âˆ’Î¸k+1)
= r xkâˆ’1 + (1 âˆ’r) xk+1.
That is, (18.12) holds. The same computation with k = N âˆ’1 shows that (18.13)
holds if and only if Î¸N âˆ’Î¸N = 0; that is, if Î¸2N = 1. In all, then, for Î¸, we get
N âˆ’1 different values (note that the complex conjugates of the values considered
here lead to the same values Î»n),
Î¸n = e(n/N)Ï€ i
for n = 1, . . . , N âˆ’1.
The corresponding eigenvalues are
Î»n = Ïƒ cos
n Ï€
N

for n = 1, . . ., N âˆ’1.
Here the variance of the individual random walk step is
Ïƒ 2 := 4r(1 âˆ’r).
(18.14)
As all eigenvalues are real, the corresponding eigenvectors are given by
xn
k = 2

r
1 âˆ’r
n/2
sin
n Ï€
N

,
k = 1, . . . , N âˆ’1.
The second largest modulus of an eigenvalue is |Î»n| = Ïƒ cos  Ï€
N
 if n = 1 or
n = N âˆ’1. Thus there exists a C > 0 such that, for every Î¼ âˆˆM1(E), we have
Î¼pn({1, . . . , N âˆ’1}) â‰¤C

Ïƒ cos
 Ï€
N
n
for every n âˆˆN.
In other words, the probability that the game has not ï¬nished up to the nth round is
at most C

Ïƒ cos(Ï€/N)
n.

458
18
Convergence of Markov Chains
An alternative approach to the eigenvalues can be made via the roots of the
characteristic polynomial
Ï‡N(x) = det(p âˆ’xI),
x âˆˆR.
Clearly, Ï‡1(x) = (1 âˆ’x)2 and Ï‡2(x) = âˆ’x(1 âˆ’x)2. Using Laplaceâ€™s expansion
formula for the determinant (elimination of rows and columns), we get the recursion
Ï‡N(x) = âˆ’x Ï‡Nâˆ’1(x) âˆ’r(1 âˆ’r) Ï‡Nâˆ’2(x).
(18.15)
The solution is (check this!)
Ï‡N(x) = (âˆ’1)Nâˆ’1 (Ïƒ/2)Nâˆ’1 (1 âˆ’x)2 UNâˆ’1

x/Ïƒ

,
(18.16)
where
Um(x) :=
âŒŠm/2âŒ‹

k=0
(âˆ’1)k
m âˆ’k
k

(2x)mâˆ’2k
denotes the so-called mth Chebyshev polynomial of the second kind.
Using de Moivreâ€™s formula, one can show that, for x âˆˆ(âˆ’Ïƒ, Ïƒ),
Ï‡N(x) = (âˆ’1)Nâˆ’1 (Ïƒ/2)Nâˆ’1 (1 âˆ’x)2 sin

N arccos

x/Ïƒ

2
1 âˆ’(x/Ïƒ)2
= (1 âˆ’x)2
Nâˆ’1

k=1

Ïƒ cos
Ï€k
N

âˆ’x

.
(18.17)
Apart from the double zero at 1, we get the zeros
Ïƒ cos Ï€k/N),
k = 1, . . . , N âˆ’1.
â™¦
Takeaways The speed at which a Markov chain converges towards its
invariant distribution is determined by the spectral gap of its transition matrix.
For two examples we could compute the spectral gap explicitly.
Exercise 18.4.1 Show (18.16). â™£
Exercise 18.4.2 Show (18.17). â™£

18.4
Speed of Convergence
459
Exercise 18.4.3 Let Î½(dx) = 2
Ï€
âˆš
1 âˆ’x2 1[âˆ’1,1](x) dx. Show that the Chebyshev
polynomials of the second kind are orthonormal with respect to Î½; that is,

UmUn dÎ½ = 1{m=n}.
â™£
Exercise 18.4.4 Let E = {1, 2, 3} and
p =
â›
âœâ
1/2 1/3 1/6
1/3 1/3 1/3
0 3/4 1/4
â
âŸâ . Compute the
invariant distribution and the exponential rate of convergence. â™£
Exercise 18.4.5 Let E = {0, . . . , N âˆ’1}, r âˆˆ(0, 1) and
p(i, j) =
â§
â¨
â©
r,
if j = i + 1 (mod N),
1 âˆ’r,
if j = i (mod N),
0,
else.
Show that p is the transition matrix of an irreducible, aperiodic random walk and
compute the invariant distribution and the exponential rate of convergence. â™£
Exercise 18.4.6 Let N âˆˆN and let E = {0, 1}N denote the N-dimensional
hypercube. That is, two points x, y âˆˆE are connected by an edge if they differ
in exactly one coordinate. Let p be the transition matrix of the random walk on E
that stays put with probability Îµ > 0 and that with probability 1 âˆ’Îµ makes a jump
to a randomly (uniformly) chosen neighboring site.
Describe p formally and show that p is aperiodic and irreducible. Compute the
invariant distribution and the exponential rate of convergence. â™£

Chapter 19
Markov Chains and Electrical Networks
We consider symmetric simple random walk on Z2. By PÃ³lyaâ€™s theorem (Theo-
rem 17.40), this random walk is recurrent. However, is this still true if we remove a
single edge from the lattice L2 of Z2? Intuitively, such a small local change should
not make a difference for a global phenomenon such as recurrence. However, the
computations used in Sect. 17.5 to prove recurrence are not very robust and would
need a substantial improvement in order to cope with even a small change. The
situation becomes even more puzzling if we restrict the random walk to, e.g., the
upper half plane {(x, y) : x âˆˆZ, y âˆˆN0} of Z2. Is this random walk recurrent?
Or consider bond percolation on Z2. Fix a parameter p âˆˆ[0, 1] and independently
declare any edge of L2 open with probability p and closed with probability 1 âˆ’p.
At a second stage, start a random walk on the random subgraph of open edges. At
each step, the walker chooses one of the adjacent open edges at random (with equal
probability) and traverses it. For p > 1
2, there exists a unique inï¬nite connected
component of open edges (Theorem 2.47). The question that we answer at the end
of this chapter is: Is a random walk on the inï¬nite open cluster recurrent or transient?
The aim of this chapter is to establish a connection between certain Markov
chains and electrical networks. This connection
â€¢
in some cases allows us to distinguish between recurrence and transience by
means of easily computable quantities, and
â€¢
in other cases provides a comparison criterion that says that if a random walk on
a graph is recurrent, then a random walk on any connected subgraph is recurrent.
Any of the questions raised above can be answered using this comparison
technique.
Some of the material of this chapter is taken from [110] and [36].
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_19
461

462
19
Markov Chains and Electrical Networks
19.1
Harmonic Functions
In this chapter, E is always a countable set and X is a discrete Markov chain on E
with transition matrix p and Green function G. Recall that F(x, y) is the probability
of hitting y at least once when starting at x. Compare Sect. 17.4, in particular,
Deï¬nitions 17.29 and 17.34.
Deï¬nition 19.1 Let A âŠ‚E. A function f : E â†’R is called harmonic on E \ A if
pf (x) = 
yâˆˆE p(x, y)f (y) exists and if pf (x) = f (x) for all x âˆˆE \ A.
Theorem 19.2 (Superposition principle) Assume f and g are harmonic on E \A
and let Î±, Î² âˆˆR. Then Î±f + Î²g is also harmonic on E \ A.
Proof This is trivial.
âŠ“âŠ”
Example 19.3 Let X be transient and let a âˆˆE be a transient state (that is, a is not
absorbing). Then f (x) := G(x, a) is harmonic on E \ {a}: For x Ì¸= a, we have
pf (x) = p
âˆ

n=0
pn(x, a) =
âˆ

n=1
pn(x, a) = G(x, a) âˆ’1{a}(x) = G(x, a).
â™¦
Example 19.4 For x âˆˆE, let Ï„x := inf{n > 0 : Xn = x}. For A âŠ‚E, let
Ï„ := Ï„A := inf
xâˆˆA Ï„x
be the stopping time of the ï¬rst entrance to A. Assume that A is chosen so that
Px[Ï„A < âˆ] = 1 for every x âˆˆE. Let g : A â†’R be a bounded function. Deï¬ne
f (x) :=

g(x),
if x âˆˆA,
Ex[g(XÏ„ )],
if x âˆˆE \ A.
(19.1)
Then f is harmonic on E \ A. We give two proofs for this statement.
1. Proof.
By the Markov property, for x Ì¸âˆˆA and y âˆˆE,
Ex
)
g(XÏ„)
X1 = y
*
=

g(y),
if y âˆˆA
Ey[g(XÏ„ )],
if y âˆˆE \ A

= f (y).
Hence, for x âˆˆE \ A,
f (x) = Ex[g(XÏ„)] =

yâˆˆE
Ex
)
g(XÏ„); X1 = y
*
=

yâˆˆE
p(x, y) Ex
)
g(XÏ„)
X1 = y
*
=

yâˆˆE
p(x, y) f (y) = pf (x).

19.1
Harmonic Functions
463
2. Proof.
We change the Markov chain by adjoining a cemetery state Î”. That is,
the new state space is ËœE = E âˆª{Î”} and the transition matrix is
Ëœp(x, y) =
â§
âªâªâ¨
âªâªâ©
p(x, y),
if x âˆˆE \ A, y Ì¸= Î”,
0,
if x âˆˆE \ A, y = Î”,
1,
if x âˆˆA âˆª{Î”}, y = Î”.
(19.2)
The corresponding Markov chain ËœX is transient, and Î” is the only absorbing state.
Furthermore, we have pf = f on E \ A if and only if Ëœpf = f on E \ A. Since
ËœG(y, y) = 1 for all y âˆˆA, we have (compare Theorem 17.35)
Px[XÏ„ = y] = Px[ËœÏ„y < âˆ] = ËœF(x, y) = ËœG(x, y)
for all x âˆˆE \ A, y âˆˆA.
Now x â†’ËœG(x, y) is harmonic on E \ A. Hence, by the superposition principle,
f (x) =

yâˆˆA
ËœG(x, y) g(y)
(19.3)
is harmonic on E \A. Due to the analogy of (19.3) to Greenâ€™s formula in continuous
space potential theory, the function ËœG is called the Green function for the equation
(p âˆ’I)f = 0 on E \ A. â™¦
Deï¬nition 19.5 The system of equations
(p âˆ’I)f (x) = 0,
for x âˆˆE \ A,
f (x) = g(x),
for x âˆˆA,
(19.4)
is called the Dirichlet problem on E \ A with respect to p âˆ’I and with boundary
value g on A.
We have shown the existence of solutions of the Dirichlet problem in Exam-
ple 19.4. In order to show uniqueness (under certain conditions) we ï¬rst derive the
maximum principle for harmonic functions.
If p = I then any function f that coincides with g on A is a solution of the
Dirichlet problem. However, even in less extreme situations the solution of (19.4)
may be ambiguous. This is the case if E \ A decomposes into domains between
which the chain that is stopped in A cannot change.
In order to describe formally the irreducibility condition that we have to impose,
we introduce the transition matrix pA of the chain stopped upon reaching A by
pA(x, y) :=
0 p(x, y),
if x Ì¸âˆˆA,
1{x=y},
if x âˆˆA.

464
19
Markov Chains and Electrical Networks
Further, deï¬ne FA for pA similarly as F was deï¬ned for p. Finally, for x âˆˆE let
Sn
A(x) =
	
y âˆˆE : (pA)n(x, y) > 0

,
for n âˆˆN0
and
SA(x) =
âˆ

n=0
Sn
A(x) = 	y âˆˆE : FA(x, y) > 0
.
Theorem 19.6 (Maximum principle) Let f be a harmonic function on E \ A.
(i) If there exists an x0 âˆˆE \ A such that
f (x0) = sup f (SA(x0)),
(19.5)
then f (y) = f (x0) for any y âˆˆSA(x0).
(ii) In particular, if FA(x, y) > 0 for all x, y âˆˆE \ A, and if there is an x0 âˆˆE \ A
such that f (x0) = sup f (E), then f (x0) = f (y) for any y âˆˆE \ A.
Proof
(i) Let m := sup f (SA(x0)). As f is harmonic on E \ A, we have pAf = f on E.
Hence, for any n âˆˆN,
f (x0) = (pA)nf (x0) =

yâˆˆSn
A(x0)
pn
A(x0, y)f (y) â‰¤m
with equality if and only if f (y) = m for all y âˆˆSn
A(x0). Since (19.5) implies
equality, we infer f (x0) = f (y) for all y âˆˆSA(x0).
(ii) This is a direct consequence of (i) since SA(x) âŠƒE \ A for any x âˆˆE \ A. âŠ“âŠ”
Theorem 19.7 (Uniqueness of harmonic functions) Assume that F(x, y) > 0 for
all x, y âˆˆE. Let A âŠ‚E be such that A Ì¸= âˆ…and E \ A is ï¬nite. Assume that f1 and
f2 are harmonic on E \ A. If f1 = f2 on A, then f1 = f2.
In other words, the Dirichlet problem (19.4) has a unique solution given by (19.3)
(or equivalently by (19.1)).
Proof By the superposition principle, f := f1 âˆ’f2 is harmonic on E \ A with
f 
A â‰¡0.
We will show f â‰¤0. Then, by symmetry, also f â‰¥0 and hence f â‰¡0. To
this end, we assume that there exists an x âˆˆE such that f (x) > 0 and deduce a
contradiction.
Since f 
A â‰¡0 and since E \ A is ï¬nite, there is an x0 âˆˆE \ A such that
f (x0) = max f (E) â‰¥f (x) > 0.

19.2
Reversible Markov Chains
465
Since F(x, y) > 0 for all x, y âˆˆE, we have
n0 := min
	
n âˆˆN0 : pn(x0, y) > 0 for some y âˆˆA

< âˆ.
Clearly, we have pn0(x0, y) = (pA)n0(x0, y) for all y âˆˆA. Hence, there exists a
y âˆˆA such that (pA)n0(x0, y) > 0, i.e., y âˆˆSA(x0). By Theorem 19.6, this implies
f (x0) = f (y) = 0 contradicting the assumption.
âŠ“âŠ”
Takeaways Let E be countable and let p be a stochastic matrix on E. Let
A âŠ‚E. A function f is called harmonic on G := E \ A if (p âˆ’I)f = 0
holds on G. If the values of f on A are prescribed, then we say that f solves a
Dirichlet problem. If p is irreducible on G and f is not constant, then f does
not assume its maximum in G. As a consequence, we get uniqueness of the
solution of the Dirichlet problem.
Exercise 19.1.1 Let p be the substochastic EÃ—E matrix that is given by p(x, y) =
Ëœp(x, y), x, y âˆˆE (with Ëœp as in (19.2)). Hence p(x, y) = p(x, y) 1xâˆˆE\A. Let I be
the unit matrix on E.
(i) Show that I âˆ’p is invertible.
(ii) Deï¬ne G := (I âˆ’p)âˆ’1. Show that G(x, y) = ËœG(x, y) for all x, y âˆˆE \ A and
that G(x, y) = 1{x=y} if x âˆˆA. In particular,
G(x, y) = Px[XÏ„A = y]
for x âˆˆE \ A and y âˆˆA.
â™£
19.2
Reversible Markov Chains
Deï¬nition 19.8 The Markov chain X is called reversible with respect to the
measure Ï€ if
Ï€({x}) p(x, y) = Ï€({y}) p(y, x)
for all x, y âˆˆE.
(19.6)
Equation (19.6) is sometimes called the equation of detailed balance. X is called
reversible if there is a Ï€ with respect to which X is reversible.
Remark 19.9 If X is reversible with respect to Ï€, then Ï€ is an invariant measure
for X since
Ï€ p({x}) =

yâˆˆE
Ï€({y}) p(y, x) =

yâˆˆE
Ï€({x}) p(x, y) = Ï€({x}).

466
19
Markov Chains and Electrical Networks
If X is irreducible and recurrent, then, by Remark 17.51, Ï€ is thus unique up to
constant multiples. â™¦
Reï¬‚ection Let X = (Xn)nâˆˆZ be a reversible Markov chain (with transition matrix
p) with respect to Ï€ and assume that PX0 = Ï€. Check that Xâ€²
n := Xâˆ’n, n âˆˆZ, is
also a Markov chain with transition matrix p. This justiï¬es the term reversible. â™ 
Example 19.10 Let (E, K) be a graph with vertex set (or set of nodes) E and with
edge set K (see page 73). By âŸ¨x, yâŸ©= âŸ¨y, xâŸ©âˆˆK, denote an (undirected) edge
that connects x with y. Let C := (C(x, y), x, y âˆˆE) be a family of weights with
C(x, y) = C(y, x) â‰¥0 for all x, y âˆˆE and
C(x) :=

yâˆˆE
C(x, y) < âˆ
for all x âˆˆE.
If we deï¬ne p(x, y) := C(x,y)
C(x) for all x, y âˆˆE, then X is reversible with respect to
Ï€({x}) = C(x). In fact,
Ï€({x}) p(x, y) = C(x) C(x, y)
C(x)
= C(x, y)
= C(y, x) = C(y) C(y, x)
C(y)
= Ï€({y}) p(y, x).
â™¦
(19.7)
Deï¬nition 19.11 Let (E, K), C and X be as in Example 19.10. Then X is called a
random walk on E with weights C. In particular, if C(x, y) = 1{âŸ¨x,yâŸ©âˆˆK}, then X is
called a simple random walk on (E, K).
Thus the random walk with weights C is reversible. However, the converse is also
true.
Theorem 19.12 If X is a reversible Markov chain and if Ï€ is an invariant
measure, then X is a random walk on E with weights C(x, y) = p(x, y) Ï€({x}). If
X is irreducible and recurrent, then Ï€ and hence C are unique up to a factor.
Proof This is obvious.
âŠ“âŠ”
Takeaways A reversible Markov chain is stationary and fulï¬lls an even
stronger equilibrium condition: The condition of detailed balance says that
on average the Markov chain jumps from x to y as often as it jumps from y to
x (for all x and y).
Exercise 19.2.1 Show that p is reversible with respect to Ï€ if and only if the linear
map L2(Ï€) â†’L2(Ï€), f â†’pf is self-adjoint. â™£

19.3
Finite Electrical Networks
467
Exercise 19.2.2 Let Î² > 0, K âˆˆN and W1, . . . , WK âˆˆR. Deï¬ne
p(i, j) := 1
Z exp(âˆ’Î²Wj)
for all i, j = 1, . . . , K,
where Z := K
j=1 exp(âˆ’Î²Wj) is the normalising constant.
Assume that in K (enumerated) urns there are a total of N indistinguishable balls.
At each step, choose one of the N balls uniformly at random. If i is the number of
the urn from which the ball is drawn, then with probability p(i, j) move the ball to
the urn with number j.
(i) Give a formal description of this process as a Markov chain.
(ii) Determine the invariant distribution Ï€ and show that the chain is reversible with
respect to Ï€. â™£
19.3
Finite Electrical Networks
An electrical network (E, C) consists of a set E of sites (the electrical contacts) and
wires between pairs of sites. The conductance of the wire that connects the points
x âˆˆE and y âˆˆE \ {x} is denoted by C(x, y) âˆˆ[0, âˆ). If C(x, y) = 0, then we
could just as well assume that there is no wire connecting x and y. By symmetry,
we have C(x, y) = C(y, x) for all x and y. Denote by
R(x, y) =
1
C(x, y) âˆˆ(0, âˆ]
the resistance of the connection âŸ¨x, yâŸ©. A particular case is that of a graph (E, K)
where all edges have the same conductance, say 1; that is, C(x, y) = 1{âŸ¨x,yâŸ©âˆˆK}.
The corresponding network (E, C) will be called the unit network on (E, K).
In the remainder of this section, assume that (E, C) is a ï¬nite electrical network.
Now let A âŠ‚E. At the points x0 âˆˆA, we apply the voltages u(x0) (e.g., using
batteries). What is the voltage u(x) at x âˆˆE \ A?
Deï¬nition 19.13 A map I : E Ã— E â†’R is called a ï¬‚ow on E \ A if it is
antisymmetric (that is, I(x, y) = âˆ’I(y, x)) and if it obeys Kirchhoffâ€™s rule:
I(x) = 0,
for x âˆˆE \ A,
I(A) = 0.
(19.8)
Here we denoted
I(x) :=

yâˆˆE
I(x, y)
and
I(A) :=

xâˆˆA
I(x).

468
19
Markov Chains and Electrical Networks
Deï¬nition 19.14 A ï¬‚ow I : E Ã— E â†’R on E \ A is called a current ï¬‚ow if there
exists a function u : E â†’R with respect to which Ohmâ€™s rule is fulï¬lled:
I(x, y) = u(x) âˆ’u(y)
R(x, y)
for all x, y âˆˆE, x Ì¸= y.
In this case, I(x, y) is called the ï¬‚ow from x to y and u(x) is called the electrical
potential (or voltage) at x.
Reï¬‚ection Give an example of a current that is not an electrical current. â™ 
Theorem 19.15 An electrical potential u in (E, C) is a harmonic function on
E \ A:
u(x) =

yâˆˆE
1
C(x) C(x, y) u(y)
for all x âˆˆE \ A.
In particular, if the network is irreducible, an electrical potential is uniquely
determined by the values on A.
Proof By Ohmâ€™s rule and Kirchhoffâ€™s rule,
u(x) âˆ’

yâˆˆE
C(x, y)
C(x) u(y) =

yâˆˆE
C(x, y)
C(x) (u(x) âˆ’u(y)) =
1
C(x)

yâˆˆE
I(x, y) = 0.
Hence u is harmonic for the stochastic matrix p(x, y) = C(x, y)/C(x). The claim
follows by the uniqueness theorem for harmonic functions (Theorem 19.7).
âŠ“âŠ”
Corollary 19.16 Let X be a Markov chain on E with edge weights C. Then u(x) =
Ex[u(XÏ„A)].
Assume A = {x0, x1} where x0 Ì¸= x1, and u(x0) = 0, u(x1) = 1. Then I(x1)
is the total ï¬‚ow into the network and âˆ’I(x0) is the total ï¬‚ow out of the network.
Kirchhoffâ€™s rule says that the ï¬‚ow is divergence-free and that the ï¬‚ows into and out
of the network are equal. In other words, the net ï¬‚ow is I(x0) + I(x1) = 0.
Recall that, by Ohmâ€™s rule, the resistance of a wire is the quotient of the potential
difference and the current ï¬‚ow. Hence we deï¬ne the effective resistance between x0
and x1 as
Reff(x0 â†”x1) = u(x1) âˆ’u(x0)
I(x1)
=
1
I(x1) = âˆ’
1
I(x0).
Correspondingly, the effective conductance is Ceff(x0 â†”x1) = Reff(x0 â†”x1)âˆ’1.
As I and u are uniquely determined by x0, x1 and C, the quantities Ceff(x0 â†”x1)
and Reff(x0 â†”x1) are well-deï¬ned and can be computed from C.
Consider now two sets A0, A1 âŠ‚E with A0 âˆ©A1 = âˆ…, A0, A1 Ì¸= âˆ…. Deï¬ne
u(x) = 0 for every x âˆˆA0 and u(x) = 1 for every x âˆˆA1. Let I be the

19.3
Finite Electrical Networks
469
corresponding current ï¬‚ow. In a manner similar to the above, we make the following
deï¬nition.
Deï¬nition 19.17 We call Ceff(A0 â†”A1) := I(A1) the effective conductance
between A0 and A1 and Reff(A0 â†”A1) :=
1
I(A1) the effective resistance between
A0 and A1.
Example 19.18
(i) Let E = {0, 1, 2} with C(0, 2) = 0, and A0 = {x0} = {0}, A1 = {x1} = {2}.
Deï¬ne u(0) = 0 and u(2) = 1. Then (with p(x, y) = C(x, y)/C(x)),
u(1) = 1 Â· p(1, 2) + 0 Â· p(1, 0) =
C(1, 2)
C(1, 2) + C(1, 0) =
R(1, 0)
R(1, 0) + R(1, 2)
=
Reff(1 â†”0)
Reff(1 â†”0) + Reff(1 â†”2).
The total current ï¬‚ow is
I({2}) = u(1) C(0, 1) =
1
R(0, 1) + R(1, 2) =
1
1
C(0,1) +
1
C(1,2)
.
Hence we have Reff(0 â†”2) =
1
I({2}) = R(0, 1) + R(1, 2) and Ceff(0 â†”2) =

C(0, 1)âˆ’1 + C(1, 2)âˆ’1âˆ’1.
(ii) (Series connection (see Fig.19.1))
Let n âˆˆN, n â‰¥2 and E = {0, . . ., n}
with conductances C(k âˆ’1, k) > 0 and C(k, l) = 0 if |k âˆ’l| > 1. By
Kirchhoffâ€™s rule, we have I(l, l + 1) = âˆ’I(x1) for any l = 0, . . . , n âˆ’1. By
Ohmâ€™s rule, we get u(1) = u(0) + I(x1) R(0, 1), u(2) = u(1) + I(x1) R(1, 2)
u(0) = 0
u(6) = 1
x1 = 6
x0 = 1
C(5, 6)
C(0, 1)
C(1, 2)
Fig. 19.1 Series connection of six resistors. The effective resistance is Reff(0 â†”6) = R(0, 1) +
. . . + R(5, 6).

470
19
Markov Chains and Electrical Networks
and so on, yielding
u(k) âˆ’u(0) = I(x1)
kâˆ’1

l=0
R(l, l + 1).
Hence
Reff(0 â†”k) = u(k) âˆ’u(0)
I(x1)
=
kâˆ’1

l=0
R(l, l + 1).
By symmetry, we also have
Reff(k â†”n) =
nâˆ’1

l=k
R(l, l + 1)
and thus Reff(0 â†”n) = Reff(0 â†”k) + Reff(k â†”n).
Finally, for k âˆˆ{1, . . ., n âˆ’1}, we get
u(k) =
Reff(0 â†”k)
Reff(0 â†”k) + Reff(k â†”n).
Note that this yields the ruin probability of the corresponding Markov chain X
on {0, . . ., n},
Pk[Ï„n < Ï„0] = u(k) = Reff(0 â†”k)
Reff(0 â†”n) =
kâˆ’1

l=0
R(l, l + 1)
N nâˆ’1

l=0
R(l, l + 1).
(19.9)
(iii) (Parallel connection (see Fig.19.2))
Let E = {0, 1}. We extend the model
a little by allowing for more than one wire to connect 0 and 1. Denote the
conductances of these wires by C1, . . . , Cn. Then, by Ohmâ€™s rule, the current
ï¬‚ow along the ith wire is Ii =
u(1)âˆ’u(0)
Ri
=
1
Ri . Hence the total current is
I = n
i=1
1
Ri and thus we have
Ceff(0 â†”1) =
n

i=1
Ci
and
Reff(0 â†”1) =
 n

i=1
1
Ri
âˆ’1
.
â™¦
In each of the three preceding examples, the effective resistance is a monotone
function of the individual resistances. This is more than just coincidence.
Theorem 19.19 (Rayleighâ€™s monotonicity principle) Let (E, C) and (E, Câ€²) be
electrical networks with C(x, y) â‰¥Câ€²(x, y) for all x, y âˆˆE.
Then, for A0, A1 âŠ‚E with A0, A1 Ì¸= âˆ…and A0 âˆ©A1 = âˆ…,

19.3
Finite Electrical Networks
471
u(0) = 0
u(6) = 1
x1 = 6
x0 = 1
R1
R2
R3
R4
R5
R6
Fig. 19.2 Parallel connection of six resistors. The effective resistance is Reff(0 â†”1) = (Râˆ’1
1
+
. . . + Râˆ’1
6 )âˆ’1.
Ceff(A0 â†”A1) â‰¥Câ€²
eff(A0 â†”A1).
The remainder of this section is devoted to the proof of this theorem. We will
need a theorem on conservation of energy and Thomsonâ€™s principle (also called
Dirichletâ€™s principle) on the minimization of the energy dissipation.
Theorem 19.20 (Conservation of energy) Let A = A0âˆªA1, and let I be a ï¬‚ow on
E \ A (but not necessarily a current ï¬‚ow; that is, Kirchhoffâ€™s rule holds but Ohmâ€™s
rule need not). Further, let w : E â†’R be a function that is constant both on A0
and on A1: w
A0 â‰¡: w0 and w
A1 â‰¡: w1. Then
(w1 âˆ’w0)I(A1) = 1
2

x,yâˆˆE
(w(x) âˆ’w(y)) I(x, y).
Note that this is a discrete version of GauÃŸâ€™s integral theorem for (wI). In fact,
Kirchhoffâ€™s rule says that I is divergence-free on E \ A.
Proof We compute

x,yâˆˆE
(w(x) âˆ’w(y))I(x, y) =

xâˆˆE

w(x)

yâˆˆE
I(x, y)

âˆ’

yâˆˆE

w(y)

xâˆˆE
I(x, y)

=

xâˆˆA

w(x)

yâˆˆE
I(x, y)

âˆ’

yâˆˆA

w(y)

xâˆˆE
I(x, y)

= w0I(A0)+w1I(A1)âˆ’w0(âˆ’I(A0))âˆ’w1(âˆ’I(A1))
= 2(w1 âˆ’w0)I(A1).
âŠ“âŠ”

472
19
Markov Chains and Electrical Networks
Deï¬nition 19.21 Let I be a ï¬‚ow on E \ A. Denote by
LI := LC
I := 1
2

x,yâˆˆE
I(x, y)2 R(x, y)
the energy dissipation of I in the network (E, C).
Theorem 19.22 (Thomsonâ€™s (or Dirichletâ€™s) principle of minimization of energy
dissipation) Let I and J be unit ï¬‚ows from A1 to A0 (that is, I(A1) = J(A1) = 1).
Assume in addition that I is a current ï¬‚ow (that is, it satisï¬es Ohmâ€™s rule with some
potential u that is constant both on A0 and on A1). Then
LI â‰¤LJ
with equality if and only if I = J. In particular, the unit current ï¬‚ow is uniquely
determined.
Proof Let D = J âˆ’I Ì¸â‰¡0 be the difference of the ï¬‚ows. Then clearly D(A0) =
D(A1) = 0. We infer

x,yâˆˆE
J(x, y)2 R(x, y)
=

x,yâˆˆE

I(x, y) + D(x, y)
2R(x, y)
=

x,yâˆˆE

I(x, y)2 + D(x, y)2
R(x, y) + 2

x,yâˆˆE
I(x, y) D(x, y) R(x, y)
=

x,yâˆˆE

I(x, y)2 + D(x, y)2
R(x, y) + 2

x,yâˆˆE

u(x) âˆ’u(y)

D(x, y).
By the principle of conservation of energy, the last term equals
2

x,yâˆˆE

u(x) âˆ’u(y)

D(x, y) = 4D(A1)(u1 âˆ’u0) = 0.
Therefore (since D Ì¸â‰¡0),
LJ = LI + 1
2

x,yâˆˆE
D(x, y)2 R(x, y) > LI.
âŠ“âŠ”
Proof (Rayleighâ€™s monotonicity principle, Theorem 19.19) Let I and I â€² be the unit
current ï¬‚ows from A1 to A0 with respect to C and Câ€², respectively. By Thomsonâ€™s

19.4
Recurrence and Transience
473
principle, the principle of conservation of energy and the assumption R(x, y) â‰¤
Râ€²(x, y) for all x, y âˆˆE, we have
Reff(A0 â†”A1) = u(1) âˆ’u(0)
I(A1)
= u(1) âˆ’u(0)
= 1
2

x,yâˆˆE
I(x, y)2 R(x, y)
â‰¤1
2

x,yâˆˆE
I â€²(x, y)2 R(x, y) â‰¤1
2

x,yâˆˆE
I â€²(x, y)2 Râ€²(x, y)
= uâ€²(1) âˆ’uâ€²(0) = Râ€²
eff(A0 â†”A1).
âŠ“âŠ”
Takeaways Let us imagine the edges of some graph as resistors in an
electrical network. We can compute the effective resistances in parallel and
serial connections. The electrical current between two contacts (vertices in
the graph) minimises the electrical power among all unit currents. We use
this to infer uniqueness of the electrical current. As a consequence we get
a formal proof for the intuitive fact that increasing the resistance along an
individual bond (or even removing the bond which is the same as increasing
the resistance to inï¬nity) increases the effective resistance between any two
given points.
19.4
Recurrence and Transience
We consider the situation where E is countable and A1 = {x1} for some x1 âˆˆE.
Let X be a random walk on E with weights C = (C(x, y), x, y âˆˆE) and hence
with transition probabilities p(x, y) = C(x, y)/C(x) (compare Deï¬nition 19.11).
The main goal of this section is to express the probability 1 âˆ’F(x1, x1) that the
random walk never returns to x1 in terms of effective resistances in the network.
In order to apply the results on ï¬nite electrical networks from the last section, we
henceforth assume that A0 âŠ‚E is such that E \ A0 is ï¬nite. We will obtain 1 âˆ’
F(x1, x1) as the limit of the probability that a random walk started at x1 hits A0
before returning to x1 as A0 â†“âˆ….

474
19
Markov Chains and Electrical Networks
Let u = ux1,A0 be the unique potential function on E with u(x1) = 1 and u(x) =
0 for any x âˆˆA0. By Theorem 19.7, u is harmonic and can be written as
ux1,A0(x) = Ex
'
1{XÏ„A0âˆª{x1}=x1}
(
= Px
)
Ï„x1 < Ï„A0
*
for every x âˆˆE \ (A0 âˆª{x1}).
Hence the current ï¬‚ow I with respect to u satisï¬es
âˆ’I(A0) = I(x1) =

xâˆˆE
I(x1, x) =

xâˆˆE

u(x1) âˆ’u(x)

C(x1, x)
= C(x1)

xâˆˆE

1 âˆ’u(x)

p(x1, x)
= C(x1)
â›
â

xÌ¸âˆˆA0âˆª{x1}
p(x1, x) Px
)Ï„A0 < Ï„x1
* +

xâˆˆA0
p(x1, x)
â
â 
= C(x1) Px1
)
Ï„A0 < Ï„x1
*
.
Therefore,
pF (x1, A0) := Px1
)
Ï„A0 < Ï„x1
*
= Ceff(x1 â†”A0)
C(x1)
=
1
C(x1)
1
Reff(x1 â†”A0).
(19.10)
Deï¬nition 19.23 We denote the escape probability of x1 by
pF (x1) = Px1
)
Ï„x1 = âˆ
*
= 1 âˆ’F(x1, x1).
We denote the effective conductance from x1 to âˆby
Ceff(x1 â†”âˆ) := C(x1) inf
	
pF (x1, A0) : A0 âŠ‚E with |E \ A0|< âˆ, A0 Ì¸âˆ‹x1

.
Lemma 19.24 For any decreasing sequence An
0 â†“âˆ…such that |E \ An
0| < âˆand
x1 Ì¸âˆˆAn
0 for all n âˆˆN, we have
Ceff(x1 â†”âˆ) =
lim
nâ†’âˆCeff(x1 â†”An
0).
Proof This is obvious since
Ceff(x1 â†”âˆ) = C(x1) inf
	
pF (x1, A0) : |E \ A0| < âˆ, A0 Ì¸âˆ‹x1

(19.11)
and since pF (x1, A0) is monotone decreasing in A0.
âŠ“âŠ”

19.4
Recurrence and Transience
475
Theorem 19.25 We have
pF (x1) =
1
C(x1) Ceff(x1 â†”âˆ).
(19.12)
In particular,
x1 is recurrent
â‡â‡’
Ceff(x1 â†”âˆ) = 0
â‡â‡’
Reff(x1 â†”âˆ) = âˆ.
Proof Let An
0 â†“âˆ…be a decreasing sequence such that |E \ An
0| < âˆand x1 Ì¸âˆˆAn
0
for all n âˆˆN. Deï¬ne Fn :=
	
Ï„An
0 < Ï„x1

. For every M âˆˆN, we have
Px1[Ï„An
0 â‰¤M] â‰¤
M

k=0
Px1[Xk âˆˆAn
0]
nâ†’âˆ
âˆ’â†’
0.
Hence Ï„An
0 â†‘âˆalmost surely, and thus Fn â†“{Ï„x1 = âˆ} (up to a null set). We
conclude
1
C(x1) Ceff(x1 â†”âˆ) =
lim
nâ†’âˆPx1[Fn] = Px1[Ï„x1 = âˆ] = pF (x1).
âŠ“âŠ”
Example 19.26 Symmetric simple random walk on E = Z is recurrent. Here
C(x, y) = 1{|xâˆ’y|=1}. The effective resistance from 0 to âˆcan be computed by
the formulas for parallel and sequence connections,
Reff(0 â†”âˆ) = 1
2
âˆ

i=0
R(i, i + 1) = âˆ.
â™¦
Example 19.27 Asymmetric simple random walk on E = Z with p(x, x + 1) =
p âˆˆ( 1
2, 1), p(x, x âˆ’1) = 1 âˆ’p
is transient. Here one choice (and thus up to
multiples the unique choice) for the conductances is
C(x, x + 1) =

p
1 âˆ’p
x
for x âˆˆZ,
and C(x, y) = 0 if |x âˆ’y| > 1. By the monotonicity principle, the effective
resistance from 0 to âˆcan be bounded by
Reff(0 â†”âˆ) =
lim
nâ†’âˆReff(0 â†”{âˆ’n, n})
â‰¤
lim
nâ†’âˆReff(0 â†”n)
=
âˆ

n=0
1 âˆ’p
p
n
=
p
2p âˆ’1 < âˆ.
â™¦

476
19
Markov Chains and Electrical Networks
0
1
2
3
4
5
Fig. 19.3 Electrical network on Z2. The bold lines are superconductors. The nth and the (n+1)th
superconductors are connected by 4(2n + 1) edges.
Reï¬‚ection Check that nearest neighbour random walk on an inï¬nite binary tree
(see Fig. 2.3) is transient. â™ 
Example 19.28 Symmetric simple random walk on E = Z2 is recurrent. Here again
C(x, y) = 1{|xâˆ’y|=1}. Let Bn = {âˆ’n, . . . , n}2 and âˆ‚Bn = Bn\Bnâˆ’1. We construct a
network Câ€² with greater conductances by adding ring-shaped superconductors along
âˆ‚B. (See Figs. 19.3 and 19.4 for illustrations.) That is, we replace C(x, y) by
Câ€²(x, y) =

âˆ,
if x, y âˆˆâˆ‚Bn for some n âˆˆN,
C(x, y),
else.
Then Râ€²
eff(Bn â†”Bc
n) =
1
4(2n+1) (note that there are 4(2n+1) edges that connect
Bn with Bc
n), and thus
Râ€²
eff(0 â†”âˆ) =
âˆ

n=0
1
4(2n + 1) = âˆ.

19.4
Recurrence and Transience
477
4 edges
12 edges
4(2n + 1) edges
0
1
2
n
n + 1
Fig. 19.4 Effective network after adding superconductors to Z2. The ring-shaped superconductors
have melted down to single points.
By the monotonicity principle, we thus have Reff(0 â†”âˆ) â‰¥Râ€²
eff(0 â†”âˆ) = âˆ.
â™¦
Example 19.29 Let (E, K) be an arbitrary connected subgraph of the square lattice
(Z2, L2). Then simple random walk on (E, K) (see Deï¬nition 19.11) is recurrent.
Indeed, by the monotonicity principle, we have
R(E,K)
eff
(0 â†”âˆ) â‰¥R(Z2,L2)
eff
(0 â†”âˆ) = âˆ.
â™¦
We formulate the method used in the foregoing examples as a theorem.
Theorem 19.30 Let C and Câ€² be edge weights on E with Câ€²(x, y) â‰¤C(x, y) for
all x, y âˆˆE. If the Markov chain X with weights C is recurrent, then the Markov
chain Xâ€² with weights Câ€² is also recurrent.
In particular, consider a graph (E, K) and a subgraph (Eâ€², Kâ€²). If simple
random walk on (E, K) is recurrent, then so is simple random walk on (Eâ€², Kâ€²).
Proof This follows from Theorem 19.25 and Rayleighâ€™s monotonicity principle
(Theorem 19.19).
âŠ“âŠ”
Example 19.31 Symmetric simple random walk on Z3 is transient. In order to prove
this, we construct a subgraph for which we can compute Râ€²
eff(0 â†”âˆ) < âˆ.
Sketch We consider the set of all inï¬nite paths starting at 0 and that
â€¢
begin by taking one step in the x-direction, the y-direction or the z-direction,
â€¢
continue by choosing a possibly different direction x, y or z and make two steps
in that direction, and
â€¢
at the nth stage choose a direction x, y or z and take 2n+1 steps in that direction.
For example, by xyyxxxxzzzzzzzz. . . we denote the path that starts with one
step in direction x, then chooses y, then x, then z and so on. Note that after two

478
19
Markov Chains and Electrical Networks
x
xx
y
z
yx
yy
yz
xz
xy
zy
yzz
yyy
xxx
zzz
zxx
zx
zyy
xzz
zz
yxx
xyy
x
y
z
yy
yx
yz
xz
zz
zx
zy
xy
xx
zzz
zxx
zyy
yzz
yyy
yxx
xyy
xzz
xxx
Fig. 19.5 Scheme of the ï¬rst three steps (two stages) of the graph from Example 19.31. The left
ï¬gure shows the actual edges where, e.g., xyy indicates that the ï¬rst step is in direction x, the
second step is in direction y and then the third step is necessarily also in direction y. In the right
ï¬gure, the nodes at the ends of xz/zx, xy/yx and yz/zy are split into two nodes and then connected
by a superconductor (bold line). If we remove the superconductors from the network, we end up
with the network of Fig. 19.6 whose effective resistance Râ€²
eff(0 â†”âˆ) is not smaller than that of
Z3. (If at the root we apply a voltage of 1 and at the points to the right the voltage 0, then by
symmetry no current ï¬‚ows through the superconductors. Thus, in fact, the network is equivalent
to that in Fig. 19.6.)
paths follow different directions for the ï¬rst time, they will not have any common
edge again, though some of the nodes can be visited by both paths.
Consider the electrical network with unit resistors. Apply a voltage of 1 at the ori-
gin and 0 at the endpoints of the paths at the nth stage. By symmetry, the potential at
a given node depends only on the distance (length of the shortest path) from the ori-
gin. We thus obtain an equivalent network if we replace multiply used nodes by mul-
tiple nodes (see Fig. 19.5). Thus we obtain a tree-shaped network: For any n âˆˆN0,
after 2n steps each path splits into three (see Fig. 19.6). The 3n paths leading from
the nodes of the nth generation to those of the (n+1)th generation are disjoint paths,
each of length 2nâˆ’1. If B(n) denotes the set of points up to the nth generation, then
Râ€²
eff
0 â†”B(n + 1)c =
nâˆ’1

k=0
Râ€²
eff
B(k) â†”B(k)c =
nâˆ’1

k=0
2k 3âˆ’k.
Therefore, Râ€²
eff(0 â†”âˆ) = 1
3
âˆ
k=0

2
3
k
= 1 < âˆ. On this tree, random walk is
transient. Hence, by Theorem 19.30, random walk on Z3 is also transient. â™¦

19.4
Recurrence and Transience
479
R(0, 1)=1/3
R(1, 2) = 2/9
R(2, 3) = 4/27
Reï¬€(0 â†”2) = 5/9
Reï¬€(0 â†”3) = 19/27
3
2
1
0
Fig. 19.6 A tree as a subgraph of Z3 on which random walk is still transient.
Takeaways A reversible Markov chain escapes from a point x to inï¬nity
(that is, it never returns to x) with positive probability if and only if in
the corresponding electrical network, the effective resistance between x and
inï¬nity is ï¬nite. We use this idea to give a different proof for the fact that
simple random walk on Zd is recurrent if and only if d â‰¤2. Furthermore, and
more importantly, we use Rayleighâ€™s monotonicity principle to show that if a
random on a graph is recurrent, then it is also recurrent on any subgraph.

480
19
Markov Chains and Electrical Networks
Exercise 19.4.1 Consider the electrical network on Zd with unit resistors between
neighboring points. Let X be a symmetric simple random walk on Zd. Finally, ï¬x
two arbitrary neighboring points x0, x1 âˆˆZd. Show the following:
(i) The effective conductance between x0 and x1 is Ceff(x0 â†”x1) = d.
(ii) If d â‰¤2, then Px0[Ï„x1 < Ï„x0] = 1
2.
(iii) If d â‰¥3, then Px0[Ï„x1 < Ï„x0 |Ï„x0 âˆ§Ï„x1 < âˆ] = 1
2. â™£
19.5
Network Reduction
Example 19.32 Consider a random walk on the graph in Fig. 19.7 that starts at x
and at each step jumps to one of its neighbors at random with equal probability.
What is the probability P that this Markov chain visits 1 before it visits 0?
We can regard the graph as an electrical network with unit resistors at each edge,
voltage 0 at 0 and voltage 1 at 1. Then P equals the voltage at point x:
P = u(x).
In order to compute u(x), we replace the network step by step by simpler networks
such that the effective resistances between 0, 1, and x remain unchanged. Hence in
each step the voltage u(x) at point x does not change. â™¦
Reduced Network
Assume that we have already reduced the network to a network with the three points
0, 1 and x and with resistors between these points Râ€²(0, 1), Râ€²(0, x) and Râ€²(1, x).
See Fig. 19.8.
0
x
1
Fig. 19.7 Initial situation.

19.5
Network Reduction
481
R (0, x)
R (0, 1)
R (x, 1)
0
x
1
Fig. 19.8 Reduced network with three nodes.
Clearly, we have
P = u(x) =
Râ€²(0, x)
Râ€²(0, x) + Râ€²(1, x).
(19.13)
If we knew the effective resistances Reff(0 â†”x), Reff(1 â†”x) and Reff(0 â†”1),
we could avoid the hassle of reducing the network and we could compute u(x)
directly. In order to derive the formula for u(x), we make the following observations.
In the reduced network, the effective resistances are easy to compute: If {a, b, c} =
{0, 1, x}, then
Reff(a â†”b) =

1
Râ€²(a, b) +
1
Râ€²(a, c) + Râ€²(b, c)
âˆ’1
.
(19.14)
Solving these three equations for Râ€²(0, 1), Râ€²(0, x) and Râ€²(1, x) and plugging
the values into (19.13) yields
P = u(x) = Reff(0 â†”1) + Reff(0 â†”x) âˆ’Reff(x â†”1)
2 Reff(0 â†”1)
.
(19.15)
In particular, in the case Râ€²(0, 1) = âˆ(or equivalently Reff(0 â†”1) = Reff(0 â†”
x) + Reff(x â†”1)), we have Reff(0 â†”x) = Râ€²(0, x) and Reff(1 â†”x) = Râ€²(1, x),
hence
u(x) =
Reff(0 â†”x)
Reff(0 â†”x) + Reff(x â†”1).
(19.16)
Since we always have u(x) âˆˆ[0, 1], rearranging the terms yields (again in the
general situation)
Reff(1 â†”x) â‰¤Reff(0 â†”1) + Reff(0 â†”x).
(19.17)
This is the triangle inequality for the effective resistances and it shows that the
effective resistance is a metric in any electrical network.

482
19
Markov Chains and Electrical Networks
Step-by-Step Reduction of the Network
Having seen how to compute u(x) from the effective resistances, we now turn to the
systematic computation of these effective resistances. Later we will come back to
the introductory example and make the computations explicit.
There are four elementary transformations for the reduction of an electrical
network:
1. Deletion of loops.
The three points on the very right of the graph form a loop
that can be deleted from the network without changing any of the remaining
voltages. In particular, any edge that directly connects 0 to 1 can be deleted.
2. Joining serial edges.
If two (or more) edges are in a row such that the nodes
along them do not have any further adjacent edges, this sequence of edges can be
substituted by a single edge whose resistance is the sum of the resistances of the
single edges (see Fig. 19.1).
3. Joining parallel edges.
Two (or more) edges with resistances R1, . . . , Rn that
connect the same two nodes can by replaced by a single edge with resistance
R = (Râˆ’1
1
+ . . . + Râˆ’1
n )âˆ’1 (see Fig. 19.2).
4. Starâ€“triangle transformation (see Exercise 19.5.1).
The star-shaped part of
a network (left in Fig. 19.9) is equivalent to the triangle-shaped part (right in
Fig. 19.9) if the resistances R1, R2, R3, 
R1, 
R2, 
R3 satisfy the condition
Ri ËœRi = Î´
for any i = 1, 2, 3,
(19.18)
where
Î´ = R1R2R3

Râˆ’1
1
+ Râˆ’1
2
+ Râˆ’1
3

=

R1 
R2 
R3

R1 + 
R2 + 
R3
.
x1
x2
x3
x
z
1
x2
x3
R1
R3
R2
R1
R3
R2
Fig. 19.9 Starâ€“triangle transformation.

19.5
Network Reduction
483
Application to Example 19.32
With the four transformations at hand, we solve the problem of Example 19.32.
Assume that initially all edges have resistance 1. In the ï¬gures we label each edge
with its resistance if it differs (in the course of the reduction) from 1.
Step 1.
Delete the loop at the right-hand side (left in Fig. 19.10).
Step 2.
Replace the series on top, bottom and right by edges with resistance 2
(right in Fig. 19.10).
Step 3.
Use the star-triangle transformation to remove the lower left node (left
in Fig. 19.11). Here R1 = 1, R2 = 2, R3 = 1, Î´ = 5, 
R1 = Î´/R1 = 5,

R2 = Î´/R2 = 5/2 and 
R3 = Î´/R3 = 5.
Step 4.
Replace the parallel edges with resistances R1 = 5 and R2 = 1 by one
edge with R = ( 1
5 + 1)âˆ’1 = 5
6 (right in Fig. 19.11).
Step 5.
Use the star-triangle transformation to remove the lower right node (left
in Fig. 19.12). Here R1 = 5, R2 = 2, R3 = 5
6, Î´ = 95/6, 
R1 = Î´/R1 = 19/6,

R2 = Î´/R2 = 95/12 and 
R3 = Î´/R3 = 19.
Step 6.
Replace the parallel edges by edges with resistances ( 12
95 + 2
5)âˆ’1 = 19
10 and
( 6
19 + 1)âˆ’1 = 19
25, respectively (right in Fig. 19.12).
0
x
1
2
2
2
1
x
0
Fig. 19.10 Steps 1 and 2.
5/2
5
5
2
1
2
x
0
5
x
2
5/2
5/6
2
1
0
Fig. 19.11 Steps 3 and 4.

484
19
Markov Chains and Electrical Networks
19
95/12
19/6
5/2
2
x
0
1
19
2
x
0
1
19/10
19/25
Fig. 19.12 Steps 5 and 6.
54/25
27/5
0
x
2
1
19
513/125
x
1
0
R (0, x) = 27/32
R (x, 1) = 27/26
R (0, 1) = 27/8
Fig. 19.13 Steps 7 and 8.
Step 7.
Use the star-triangle transformation to remove the lower right node (left
in Fig. 19.13). Here R1 = 19
10, R2 = 19
25, R3 = 1, Î´ = 513
125, 
R1 = Î´/R1 = 54
25,

R2 = Î´/R2 = 27
5 and 
R3 = Î´/R3 = 513
125.
Step 8.
Replace the three pairs of parallel edges by single edges with resistances
( 5
27 + 1)âˆ’1 = 27
32,
( 25
54 + 1
2)âˆ’1 = 27
26
and
( 1
19 + 125
513)âˆ’1 = 27
8 , respectively.
In the reduced network, we have the resistances Râ€²(0, x) = 27
32 and Râ€²(x, 1) =
27
26. Using (19.13), the probability that the random walk visits 1 before 0 is
P =
27
32
27
32 + 27
26
= 13
29.
Using the values of Râ€²(0, x), Râ€²(1, x) and Râ€²(0, 1) and equation (19.14), we
compute the effective resistances in the reduced network (and hence in the original
network):
Reff(0 â†”x) =

32
27 +
1
27
8 + 27
26
âˆ’1
= 17
24,
Reff(1 â†”x) =

26
27 +
1
27
32 + 27
8
âˆ’1
= 5
6,
Reff(0 â†”1) =

8
27 +
1
27
26 + 27
32
âˆ’1
= 29
24.

19.5
Network Reduction
485
Using (19.15) we can use the values to compute u(x):
P = u(x) =
29
24 + 17
24 âˆ’5
6
2 Â· 29
24
= 13
29.
Clearly, the latter computation is more complicated than using the resistances
Râ€² from the reduced network directly. However, it has the advantage that it can be
performed without going through all the network reduction steps if, for some reason,
we know the effective resistances already. For example, we could buy resistors in an
electronic market, solder the network and measure the resistances with a multimeter.
â™¦
Alternative Solution
A different approach to solving the problem of Example 19.32 is to use linear
algebra instead of network reduction. It is a matter of taste as to which solution
is preferable. First generate the transition matrix p of the Markov chain. To this
end, enumerate the nodes of the graph from 1 to 12 as in Fig. 19.14. The chain starts
at 2, and we want to compute the probability that it visits 3 before 5.
3
5
9
8
7
10
6
1
2
12
4
11
Fig. 19.14 Graph with enumerated nodes.

486
19
Markov Chains and Electrical Networks
Generate the matrix p of the chain that is killed at 3 and at 5 and compute G =
(I âˆ’p)âˆ’1. By Exercise 19.1.1 (with A = {3, 5}, x = 2 and y = 3), the probability
of visiting 3 before 5 is P = G(2, 3) = 13
29.
p :=
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
0 1
2
1
2 0 0 0 0 0 0 0 0 0
1
3 0 0 0 1
3
1
3 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1
2
1
2 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0
0 1
4
1
4 0 0 0 0 0 1
4
1
4 0 0
0 0 1
4
1
4 0 0 0 0 0 1
4
1
4 0
0 0 0 1
2 0 0 0 0 0 0 1
2 0
0 0 0 0 1
3
1
3 0 0 0 0 0 1
3
0 0 0 0 0 1
3
1
3 0 0 0 0 1
3
0 0 0 0 0 0 1
2
1
2 0 0 0 0
0 0 0 0 0 0 0 0 1
2
1
2 0 0
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
,
G := (I âˆ’p)âˆ’1 =
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
143
116
81
116
21
29
3
58
8
29
19
58
3
29
3
58
15
116
9
58
3
58
11
116
27
58
81
58
13
29
3
29
16
29
19
29
6
29
3
29
15
58
9
29
3
29
11
58
0
0
1
0
0
0
0
0
0
0
0
0
3
58
9
58
24
29
165
58
5
29
15
29
78
29
68
29
21
58
30
29
107
58
27
58
0
0
0
0
1
0
0
0
0
0
0
0
19
116
57
116
18
29
15
58
11
29
95
58
15
29
15
58
75
116
45
58
15
58
55
116
3
58
9
58
24
29
39
29
5
29
15
29
78
29
39
29
21
58
30
29
39
29
27
58
3
58
9
58
24
29
68
29
5
29
15
29
78
29
97
29
21
58
30
29
68
29
27
58
5
58
15
58
11
29
7
29
18
29
25
29
14
29
7
29
93
58
21
29
7
29
45
58
3
29
9
29
19
29
20
29
10
29
30
29
40
29
20
29
21
29
60
29
20
29
27
29
3
58
9
58
24
29
107
58
5
29
15
29
78
29
68
29
21
58
30
29
165
58
27
58
11
116
33
116
15
29
27
58
14
29
55
58
27
29
27
58
135
116
81
58
27
58
215
116
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
.

19.5
Network Reduction
487
Takeaways There are essentially two possibilities to systematically deter-
mine the effective resistance between two points in an electrical network.
Firstly, one can solve the system of linear equations belonging to the Markov
chain killed in the two points. Secondly, the network can be reduced in a series
of elementary steps: Resolving parallel connections, resolving serial connec-
tions and resolving intermediate points using the star-triangle transformation.
While solving the linear equations is a simple job for a computer, network
reduction can give insights into the structure of the problem and can lead to
general formulas also for similar networks.
Exercise 19.5.1 Show the validity of the star-triangle transformation. â™£
Exercise 19.5.2 Consider a random walk on the honeycomb graph shown below.
Show that if the walk starts at x, then the probability of visiting 1 before 0 is
8
17
using
(i) the method of network reduction, and
(ii) the method of matrix inversion. â™£
x
1
0
Exercise 19.5.3 Consider the graph of Fig. 19.15.
(i) For the effective conductance between a and z, show that Ceff(a â†â†’z) =
âˆš
3.
(ii) For a random walk started at a, show that the probability Pa[Ï„z < Ï„a] of visiting
z before returning to a is Pa[Ï„z < Ï„a] = 1/
âˆš
3. â™£
Exercise 19.5.4 For the graph of Fig. 19.16, determine Ceff(a â†â†’z) and Pa[Ï„z <
Ï„a]. (This is simpler than in Exercise 19.5.3!) â™£
Exercise 19.5.5 For a random walk on the graph of Fig. 19.17, determine the
probability Pa[Ï„z < Ï„a]. â™£

488
19
Markov Chains and Electrical Networks
z
a
Fig. 19.15 Simple ladder graph
z
a
Fig. 19.16 Crossed ladder graph
z
a
Fig. 19.17 Random walk on a hypercube.
19.6
Random Walk in a Random Environment
(Compare [143, 175] and [76, 77, 96].) Consider a Markov chain X on Z that at
each step makes a jump either to the left (with probability wâˆ’
i ) or to the right (with
probability w+
i ) if X is at i âˆˆZ. Hence, let wâˆ’
i âˆˆ(0, 1) and w+
i := 1 âˆ’wâˆ’
i
for
i âˆˆZ. Then X is the Markov chain with transition matrix
pw(i, j) =
â§
âªâ¨
âªâ©
wâˆ’
i ,
if j = i âˆ’1,
w+
i ,
if j = i + 1,
0,
else.
We consider (wâˆ’
i )iâˆˆZ as an environment in which X walks and later choose the
environment at random.

19.6
Random Walk in a Random Environment
489
In order to describe X in terms of conductances of an electrical network, we
deï¬ne Ï±i := wâˆ’
i /w+
i
for i âˆˆZ. Let Cw(i, j) := 0 if |i âˆ’j| Ì¸= 1 and
Cw(i + 1, i) := Cw(i, i + 1) :=
 i
k=0 Ï±âˆ’1
k ,
if i â‰¥0,
âˆ’1
k=i Ï±k,
if i < 0.
With this deï¬nition,
Cw(i, i + 1)
Cw(i)
=
1
Ï±i + 1 = w+
i
and
Cw(i, i âˆ’1)
Cw(i)
=
Ï±i
Ï±i + 1 = wâˆ’
i .
Hence the transition probabilities pw are indeed described by the Cw. Let
R+
w :=
âˆ

i=0
Rw(i, i + 1) =
âˆ

i=0
1
Cw(i, i + 1) =
âˆ

i=0
i
k=0
Ï±k
and
Râˆ’
w :=
âˆ

i=0
Rw(âˆ’i, âˆ’i âˆ’1) =
âˆ

i=0
1
Cw(âˆ’i, âˆ’i âˆ’1) =
âˆ

i=1
1

k=âˆ’i
Ï±âˆ’1
k .
Note that R+
w and Râˆ’
w are the effective resistances from 0 to +âˆand from 0 to
âˆ’âˆ, respectively. Hence
Rw,eff(0 â†”âˆ) =
1
1
Râˆ’
Ï‰ +
1
R+
Ï‰
is ï¬nite if and only if Râˆ’
w < âˆor R+
w < âˆ. Therefore, by Theorem 19.25,
X is transient
â‡â‡’
Râˆ’
w < âˆor R+
w < âˆ.
(19.19)
If X is transient, in which direction does it get lost?
Theorem 19.33
(i) If Râˆ’
w < âˆor R+
w < âˆ, then (agreeing on âˆ
âˆ= 1)
P0
)Xn
nâ†’âˆ
âˆ’â†’âˆ’âˆ* =
R+
w
Râˆ’
w + R+
w
and
P0
)Xn
nâ†’âˆ
âˆ’â†’+âˆ* =
Râˆ’
w
Râˆ’
w + R+
w
.
(ii) If Râˆ’
w = âˆand R+
w = âˆ, then lim inf
nâ†’âˆXn = âˆ’âˆand lim sup
nâ†’âˆ
Xn = âˆ
almost surely.

490
19
Markov Chains and Electrical Networks
Proof
(i) Let Ï„N := inf
	
n âˆˆN0 : Xn âˆˆ{âˆ’N, N}

. As X is transient, we have P0[Ï„N <
âˆ] = 1 and (as in (19.9))
P0
)
XÏ„N = âˆ’N
*
=
Rw,eff(0 â†”N)
Rw,eff(âˆ’N â†”N) =
Rw,eff(0 â†”N)
Rw,eff(0 â†”âˆ’N) + Rw,eff(0 â†”N).
Again, since X is transient, we infer
P0
)
Xn
nâ†’âˆ
âˆ’â†’âˆ’âˆ
*
= P
)
sup{Xn : n âˆˆN0} < âˆ
*
= lim
Nâ†’âˆP) sup{Xn : n âˆˆN0} < N*
â‰¤lim sup
Nâ†’âˆ
P)XÏ„N = âˆ’N*
=
R+
w
Râˆ’
w + R+
w
.
By symmetry (and since X is transient), we get
P0
)
Xn
nâ†’âˆ
âˆ’â†’âˆ’âˆ
*
= 1âˆ’P0
)
Xn
nâ†’âˆ
âˆ’â†’âˆ
*
â‰¥1âˆ’
Râˆ’
w
Râˆ’
w + R+
w
=
R+
w
Râˆ’
w + R+
w
.
(ii) If Râˆ’
w = R+
w = âˆ, then X is recurrent and hence every point is visited
inï¬nitely often. That is, lim supnâ†’âˆXn = âˆand lim infnâ†’âˆXn = âˆ’âˆ
a.s.
âŠ“âŠ”
We now consider the situation where the sequence w = (wâˆ’
i )iâˆˆZ is also random.
That is, we consider a two-stage experiment: At the ï¬rst stage we choose a
realization of i.i.d. random variables W = (W âˆ’
i )iâˆˆZ on (0, 1) and let W +
i
:=
1 âˆ’W âˆ’
i . At the second stage, given W, we construct a Markov chain X on Z with
transition matrix
pW (i, j) =
â§
âªâ¨
âªâ©
W âˆ’
i ,
if j = i âˆ’1,
W +
i ,
if j = i + 1,
0,
else.
Note that X is a Markov chain only given W; that is, under the probability measure
P[X âˆˆÂ· |W]. However, it is not a Markov chain with respect to the so-called
annealed measure P[X âˆˆÂ·]. In fact, if W is unknown, observing X gives an
increasing amount of information on the true realization of W. This is precisely
what memory is and is thus in contrast with the Markov property of X.
Deï¬nition 19.34 The process X is called a random walk in the random environ-
ment W.

19.6
Random Walk in a Random Environment
491
We are now in the position to prove a theorem of Solomon [158]. Let Ï±i :=
W âˆ’
i /W +
i
for i âˆˆZ and Râˆ’
W and R+
W be deï¬ned as above.
Theorem 19.35 (Solomon [158]) Assume that E[| log(Ï±0)|] < âˆ.
(i) If E[log(Ï±0)] < 0, then Xn
nâ†’âˆ
âˆ’â†’âˆa.s.
(ii) If E[log(Ï±0)] > 0, then Xn
nâ†’âˆ
âˆ’â†’âˆ’âˆa.s.
(iii) If E[log(Ï±0)] = 0, then lim inf
nâ†’âˆXn = âˆ’âˆand lim sup
nâ†’âˆ
Xn = âˆa.s.
Proof (i) and (ii)
By symmetry, it is enough to show (ii). Hence, let c :=
E[log(Ï±0)] > 0. By the strong law of large numbers, there is an nâˆ’
0
= nâˆ’
0 (Ï‰)
with
1

k=âˆ’n
Ï±âˆ’1
k
= exp

âˆ’
1

k=âˆ’n
log(Ï±k)

< eâˆ’cn/2
for all n â‰¥nâˆ’
0 .
Therefore,
Râˆ’
W =
âˆ

n=1
1

k=âˆ’n
Ï±âˆ’1
k
â‰¤
nâˆ’
0 âˆ’1

n=1
1

k=âˆ’n
Ï±âˆ’1
k
+
âˆ

n=nâˆ’
0
eâˆ’cn/2 < âˆ
a.s.
Similarly, there is an n+
0 = n+
0 (Ï‰) with
n

k=0
Ï±k > ecn/2
for all n â‰¥n+
0 .
We conclude
R+
W =
âˆ

n=0
n

k=0
Ï±k â‰¥
n+
0 âˆ’1

n=0
n

k=0
Ï±k +
âˆ

n=n+
0
ecn/2 = âˆ
a.s.
Now, by Theorem 19.33, we get Xn
nâ†’âˆ
âˆ’â†’âˆ’âˆalmost surely.
(iii)
In order to show Râˆ’
W = R+
W = âˆalmost surely, it is enough to show
lim supnâ†’âˆ
n
k=0 log(Ï±k) > âˆ’âˆand lim supnâ†’âˆ
1
k=âˆ’n log(Ï±âˆ’1
k ) > âˆ’âˆ
almost surely if E[log(Ï±0)] = 0. If log(Ï±0) has a ï¬nite variance, this follows by
the central limit theorem. In the general case, it follows by Theorem 20.21.
âŠ“âŠ”
Reï¬‚ection In the situation of Theorem 19.35, come up with an example such that
E[W +
i âˆ’W âˆ’
i ] > 0 but still Xn
nâ†’âˆ
âˆ’â†’âˆ’âˆholds. â™ 

492
19
Markov Chains and Electrical Networks
Takeaways One-dimensional random walks in random environment can be
regarded as random walks in a network of random conductances. This is a
specialty of dimension one that makes it easy to check if the random walk is
transient or recurrent.
Exercise 19.6.1 Consider the situation of Theorem 19.35 but with the random walk
restricted to N0. To this end, change the walk so that whenever it attempts to make
a step from 0 to âˆ’1, it simply stays in 0. Show that this random walk in a random
environment is
â€¢
a.s. transient if E[log(Ï±0)] < 0,
â€¢
a.s. null recurrent if E[log(Ï±0)] = 0, and
â€¢
a.s. positive recurrent if E[log(Ï±0)] > 0. â™£

Chapter 20
Ergodic Theory
Laws of large numbers, e.g., for i.i.d. random variables X1, X2, . . ., state that the
sequence of averages converges a.s. to the expected value, nâˆ’1 n
i=1 Xi
nâ†’âˆ
âˆ’â†’
E[X1]. Hence averaging over one realization of many random variables is equivalent
to averaging over all possible realizations of one random variable. In the terminol-
ogy of statistical physics this means that the time average, or path (Greek: odos)
average, equals the space average. The â€œspaceâ€ in â€œspace averageâ€ is the probability
space in mathematical terminology, and in physics it is considered the space of
admissible states with a certain energy (Greek: ergon). Combining the Greek words
gives rise to the name ergodic theory, which studies laws of large numbers for
possibly dependent, but stationary, random variables.
For further reading, see, for example [103] or [88].
20.1
Deï¬nitions
Deï¬nition 20.1 Let I âŠ‚R be a set that is closed under addition (for us the
important examples are I = N0, I = N, I = Z, I = R, I = [0, âˆ), I = Zd
and so on). A stochastic process X = (Xt)tâˆˆI is called stationary if
L [(Xt+s)tâˆˆI] = L [(Xt)tâˆˆI]
for all s âˆˆI.
(20.1)
Remark 20.2 If I = N0, I = N or I = Z, then (20.1) is equivalent to
L [(Xn+1)nâˆˆI] = L [(Xn)nâˆˆI] .
â™¦
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_20
493

494
20
Ergodic Theory
Example 20.3
(i) If X = (Xt)tâˆˆI is i.i.d., then X is stationary. If only PXt = PX0 holds for
every t âˆˆI (without the independence), then in general, X is not stationary.
For example, consider I = N0 and X1 = X2 = X3 = . . . but X0 Ì¸= X1.
Then X is not stationary.
(ii) Let X be a Markov chain with invariant distribution Ï€. If L[X0] = Ï€, then
X is stationary.
(iii) Let (Yn)nâˆˆZ be i.i.d. real random variables and let c1, . . . , ck âˆˆR. Then
Xn :=
k

l=1
cl Ynâˆ’l,
n âˆˆZ,
deï¬nes a stationary process X that is called the moving average with weights
(c1, . . . , ck). In fact, X is stationary if only Y is stationary. â™¦
Lemma 20.4 If (Xn)nâˆˆN0 is stationary, then X can be extended to a stationary
process

Xn

nâˆˆZ .
Proof Let 
X be the canonical process on Î© = EZ. For n âˆˆN, deï¬ne a probability
measure P{âˆ’n,âˆ’n+1,...} âˆˆM1
E{âˆ’n,âˆ’n+1,...} by
P{âˆ’n,âˆ’n+1,...})
Xâˆ’n âˆˆAâˆ’n, 
Xâˆ’n+1 âˆˆAâˆ’n+1, . . .
*
= P
)
X0 âˆˆAâˆ’n, X1 âˆˆAâˆ’n+1, . . .
*
.
Then {âˆ’n, âˆ’n + 1, . . .} â†‘Z and P{âˆ’n,âˆ’n+1,...}, n âˆˆN is a consistent family.
By the Ionescuâ€“Tulcea theorem (Theorem 14.35), the projective limit P
:=
lim
â†âˆ’
nâ†’âˆ
P{âˆ’n,âˆ’n+1,...} exists. By construction, 
X is stationary with respect to P and
P â—¦(
Xn)nâˆˆN0
âˆ’1 = P â—¦(Xn)nâˆˆN0
âˆ’1.
âŠ“âŠ”
In the following, assume that (Î©, A, P) is a probability space and Ï„ : Î© â†’Î©
is a measurable map.
Deï¬nition 20.5 An event A âˆˆA is called invariant if Ï„ âˆ’1(A) = A and quasi-
invariant if 1Ï„ âˆ’1(A) = 1A P-a.s. Denote the Ïƒ-algebra of invariant events by
I = 	A âˆˆA : Ï„ âˆ’1(A) = A
.
Recall that a Ïƒ-algebra I is called P-trivial if P[A] âˆˆ{0, 1} for every A âˆˆI.

20.1
Deï¬nitions
495
Deï¬nition 20.6
(i) Ï„ is called measure-preserving if
P
)
Ï„ âˆ’1(A)
*
= P[A]
for all A âˆˆA.
In this case, (Î©, A, P, Ï„) is called a measure-preserving dynamical system.
(ii) If Ï„ is measure-preserving and I is P-trivial, then (Î©, A, P, Ï„) is called
ergodic.
Lemma 20.7
(i) A measurable map f : (Î©, A) â†’R, B(R) is I-measurable if and only if
f â—¦Ï„ = f .
(ii) (Î©, A, P, Ï„) is ergodic if and only if any I-measurable f
: (Î©, I) â†’
(R, B(R)) is P-almost surely constant.
Proof
(i) The statement is obvious if f = 1A is an indicator function. The general case,
can be inferred by the usual approximation arguments (see Theorem 1.96((i))).
(ii) â€œ â‡’â€
Assume that (Î©, A, P, Ï„) is ergodic. Then, for any c âˆˆR, we have
f âˆ’1((c, âˆ)) âˆˆI and thus P[f âˆ’1((c, âˆ))] âˆˆ{0, 1}. We conclude that
f = inf
	
c âˆˆR : P
)
f âˆ’1((c, âˆ))
*
= 0

P-a.s.
â€œ â‡ â€
Assume any I-measurable map is P-a.s. constant. If A âˆˆI, then 1A
is I-measurable and hence P-a.s. equals either 0 or 1. Thus P[A] âˆˆ{0, 1}.
âŠ“âŠ”
Example 20.8 Let n âˆˆN\{1}, let Î© = Z/(n), let A = 2Î© and let P be the uniform
distribution on Î©. Let r âˆˆ{1, . . . , n} and
Ï„ : Î© â†’Î©,
x â†’x + r
(mod n).
Then Ï„ is measure-preserving. If d = gcd(n, r) and
Ai = 	i, Ï„(i), Ï„ 2(i), . . . , Ï„ nâˆ’1(i)
 = i + âŸ¨râŸ©
for i = 0, . . . , d âˆ’1,
then A0, . . . , Adâˆ’1 are the disjoint coset classes of the normal subgroup âŸ¨râŸ©âŠ´Î©.
Hence we have Ai âˆˆI for i = 0, . . . , d âˆ’1, and each A âˆˆI is a union of certain
Aiâ€™s. Hence we have
(Î©, A, P, Ï„) is ergodic
â‡â‡’
gcd(r, n) = 1.
â™¦
Example 20.9 (Rotation) Let Î© = [0, 1), let A = B(Î©) and let P = Î» be the
Lebesgue measure. Let r âˆˆ(0, 1) and Ï„r(x) = x+r (mod 1). Clearly, (Î©, A, P, Ï„r)
is a measure-preserving dynamical system. We will show
(Î©, A, P, Ï„r) is ergodic
â‡â‡’
r is irrational.

496
20
Ergodic Theory
Let f : [0, 1) â†’R be an I-measurable function. Without loss of generality, we
assume that f is bounded and thus square integrable. Hence f can be expanded in
a Fourier series
f (x) =
âˆ

n=âˆ’âˆ
cn e2Ï€in x
for P-a.a. x.
This series converges in L2, and the sequence of square summable coefï¬cients
(cn)nâˆˆZ is unique (compare Exercise 7.3.1 with cn = (âˆ’i/2)an + (1/2)bn and
câˆ’n = (i/2)an + (1/2)bn for n âˆˆN as well as c0 = b0). Now we compute
(f â—¦Ï„r)(x) =
âˆ

n=âˆ’âˆ

cn e2Ï€in r
e2Ï€in x
a.e.
By Lemma 20.7, f is I-measurable if and only if f = f â—¦Ï„r; that is, if and only
if
cn = cn e2Ï€in r
for all n âˆˆZ.
If r is irrational, this implies cn = 0 for n Ì¸= 0, and thus f is almost surely constant.
Therefore, (Î©, A, P, Ï„r) is ergodic.
On the other hand, if r is rational, then there exists some n âˆˆZ \ {0} with
e2Ï€in r = eâˆ’2Ï€in r = 1. Hence x â†’e2Ï€in x + eâˆ’2Ï€in x = 2 cos(2Ï€n x) is I-
measurable but not a.s. constant. Thus, in this case (Î©, A, P, Ï„r) is not ergodic.
â™¦
Example 20.10 Let X = (Xn)nâˆˆN0 be a stochastic process with values in a Polish
space E. Without loss of generality, we may assume that X is the canonical process
on the probability space (Î©, A, P) =

EN0, B(E)âŠ—N0, P

. Deï¬ne the shift operator
Ï„ : Î© â†’Î©,
(Ï‰n)nâˆˆN0 â†’(Ï‰n+1)nâˆˆN0.
Then Xn(Ï‰) = X0(Ï„ n(Ï‰)). Hence X is stationary if and only if (Î©, A, P, Ï„) is a
measure-preserving dynamical system. â™¦
Deï¬nition 20.11 The stochastic process X (from Example 20.10) is called ergodic
if (Î©, A, P, Ï„) is ergodic.
Example 20.12 Let (Xn)nâˆˆN0 be i.i.d. and let Xn(Ï‰) = X0(Ï„ n(Ï‰)). If A âˆˆI, then,
for every n âˆˆN,
A = Ï„ âˆ’n(A) = {Ï‰ : Ï„ n(Ï‰) âˆˆA} âˆˆÏƒ(Xn, Xn+1, . . .).

20.2
Ergodic Theorems
497
Hence, if we let T be the tail Ïƒ-algebra of (Xn)nâˆˆN (see Deï¬nition 2.34), then
I âŠ‚T
=
âˆ

n=1
Ïƒ(Xn, Xn+1, . . .).
By Kolmogorovâ€™s 0-1 law (Theorem 2.37), T is P-trivial. Hence I is also P-trivial
and therefore (Xn)nâˆˆN0 is ergodic. â™¦
Takeaways A measure preserving dynamical system consists of a probability
space (Î©, A, P) and a measure preserving map Ï„ : Î© â†’Î©. It is called
ergodic if there are no nontrivial (w.r.t. P) invariant sets. Examples for
measure preserving dynamical systems are stationary stochastic processes,
i.i.d. random variables, rotations and so on.
Exercise 20.1.1 Let G be a ï¬nite group of measure-preserving measurable maps
on (Î©, A, P) and let A0 := {A âˆˆA : g(A) = A for all g âˆˆG}.
Show that, for every X âˆˆL1(P), we have
E[X|A0] =
1
#G

gâˆˆG
X â—¦g.
â™£
20.2
Ergodic Theorems
In this section, (Î©, A, P, Ï„) always denotes a measure-preserving dynamical
system. Further, let f : Î© â†’R be measurable and
Xn(Ï‰) = f â—¦Ï„ n(Ï‰)
for all n âˆˆN0.
Hence X = (Xn)nâˆˆN0 is a stationary real-valued stochastic process. Let
Sn =
nâˆ’1

k=0
Xk
denote the nth partial sum. Ergodic theorems are laws of large numbers for (Sn)nâˆˆN.
We start with a preliminary lemma.

498
20
Ergodic Theory
Lemma 20.13 (Hopfâ€™s maximal-ergodic lemma)
Let X0 âˆˆL1(P). Deï¬ne Mn =
max{0, S1, . . . , Sn}, n âˆˆN. Then
E
)
X0 1{Mn>0}
*
â‰¥0
for every n âˆˆN.
Proof For k â‰¤n, we have Mn(Ï„(Ï‰)) â‰¥Sk(Ï„(Ï‰)). Hence
X0 + Mn â—¦Ï„ â‰¥X0 + Sk â—¦Ï„ = Sk+1.
Thus X0 â‰¥Sk+1 âˆ’Mn â—¦Ï„ for k = 1, . . . , n. Manifestly, S1 = X0 and Mn â—¦Ï„ â‰¥0
and hence also (for k = 0) X0 â‰¥S1 âˆ’Mn â—¦Ï„. Therefore,
X0 â‰¥max{S1, . . . , Sn} âˆ’Mn â—¦Ï„.
(20.2)
Furthermore, we have
{Mn > 0}c âŠ‚{Mn = 0} âˆ©{Mn â—¦Ï„ â‰¥0} âŠ‚{Mn âˆ’Mn â—¦Ï„ â‰¤0}.
(20.3)
By (20.2) and (20.3), and since Ï„ is measure-preserving, we conclude that
E )X0 1{Mn>0}
* â‰¥E)(max{S1, . . . , Sn} âˆ’Mn â—¦Ï„) 1{Mn>0}
*
= E
)
(Mn âˆ’Mn â—¦Ï„) 1{Mn>0}
*
â‰¥E
)
Mn âˆ’Mn â—¦Ï„
*
= E[Mn] âˆ’E[Mn] = 0.
âŠ“âŠ”
Theorem 20.14 (Individual ergodic theorem, Birkhoff [16])
Let f = X0 âˆˆ
L1(P). Then
1
n
nâˆ’1

k=0
Xk = 1
n
nâˆ’1

k=0
f â—¦Ï„ k
nâ†’âˆ
âˆ’â†’E[X0
I]
P-a.s.
In particular, if Ï„ is ergodic, then
1
n
nâˆ’1

k=0
Xk
nâ†’âˆ
âˆ’â†’E[X0]
P-a.s.
Proof If Ï„ is ergodic, then E[X0|I] = E[X0] and the supplement is a consequence
of the ï¬rst statement.
Consider now the general case. By Lemma 20.7, we have E[X0|I] â—¦Ï„ =
E[X0|I]
P-a.s. Hence, by passing to 
Xn := Xn âˆ’E[X0|I], without loss of
generality, we can assume E[X0|I] = 0. Deï¬ne
Z := lim sup
nâ†’âˆ
1
nSn.

20.2
Ergodic Theorems
499
Let Îµ > 0 and F := {Z > Îµ}. We have to show that P[F] = 0. From this we
infer P[Z > 0] = 0 and similarly (with âˆ’X instead of X) also lim inf
nâ†’âˆ
1
nSn â‰¥0
almost surely. Hence 1
nSn
nâ†’âˆ
âˆ’â†’0 a.s.
Evidently, Z â—¦Ï„ = Z; hence F âˆˆI. Deï¬ne
XÎµ
n := (Xn âˆ’Îµ) 1F ,
SÎµ
n := XÎµ
0 + . . . + XÎµ
nâˆ’1,
MÎµ
n := max{0, SÎµ
1, . . . , SÎµ
n},
Fn := {MÎµ
n > 0}.
Then F1 âŠ‚F2 âŠ‚. . . and
âˆ

n=1
Fn =
0
sup
kâˆˆN
1
k SÎµ
k > 0
1
=
0
sup
kâˆˆN
1
k Sk > Îµ
1
âˆ©F = F,
hence Fn â†‘F. Dominated convergence yields E
)
XÎµ
0 1Fn
* nâ†’âˆ
âˆ’â†’E
)
XÎµ
0
*
.
By the maximal-ergodic lemma (applied to XÎµ), we have E
)
XÎµ
0 1Fn
*
â‰¥0; hence
0 â‰¤E )XÎµ
0
* = E [(X0 âˆ’Îµ) 1F ] = E [E [X0|I] 1F ] âˆ’ÎµP[F] = âˆ’ÎµP[F].
We conclude that P[F] = 0.
âŠ“âŠ”
As a consequence, we obtain the statistical ergodic theorem, or Lp-ergodic
theorem, that was found by von Neumann in 1931 right before Birkhoff proved
his ergodic theorem, but was published only later in [122]. Before we formulate it,
we state one more lemma.
Lemma 20.15 Let p â‰¥1 and let X0, X1, . . . be identically distributed, real random
variables with E[|X0|p] < âˆ. Deï¬ne Yn :=
 1
n
nâˆ’1

k=0
Xk

p
for n âˆˆN. Then (Yn)nâˆˆN
is uniformly integrable.
Proof Evidently, the singleton {|X0|p} is uniformly integrable. Hence, by Theo-
rem 6.19, there exists a monotone increasing convex map f : [0, âˆ) â†’[0, âˆ)
with f (x)
x
â†’âˆfor x â†’âˆand C := E[f (|X0|p)] < âˆ. Again, by Theorem 6.19,
it is enough to show that E[f (Yn)] â‰¤C for every n âˆˆN. By Jensenâ€™s inequality
(for x â†’|x|p), we have
Yn â‰¤1
n
nâˆ’1

k=0
|Xk|p.

500
20
Ergodic Theory
Again, by Jensenâ€™s inequality (now applied to f ), we get that
f (Yn) â‰¤f

1
n
nâˆ’1

k=0
|Xk|p

â‰¤1
n
nâˆ’1

k=0
f (|Xk|p).
Hence E[f (Yn)] â‰¤
1
n
nâˆ’1

k=0
E[f (|Xk|p)] = C.
âŠ“âŠ”
Theorem 20.16 (Lp-ergodic theorem, von Neumann (1931)) Let (Î©, A, P, Ï„)
be a measure-preserving dynamical system, p â‰¥1, X0 âˆˆLp(P) and Xn = X0 â—¦Ï„ n.
Then
1
n
nâˆ’1

k=0
Xk
nâ†’âˆ
âˆ’â†’E[X0|I]
in Lp(P).
In particular, if Ï„ is ergodic, then
1
n
nâˆ’1

k=0
Xk
nâ†’âˆ
âˆ’â†’E[X0] in Lp(P).
Proof Deï¬ne
Yn :=

1
n
nâˆ’1

k=0
Xk âˆ’E[X0|I]

p
for every n âˆˆN.
By Lemma 20.15, (Yn)nâˆˆN is uniformly integrable, and by Birkhoffâ€™s ergodic
theorem, we have Yn
nâ†’âˆ
âˆ’â†’
0 almost surely. By Theorem 6.25, we thus have
lim
nâ†’âˆE[Yn] = 0.
If Ï„ is ergodic, then E[X0|I] = E[X0].
âŠ“âŠ”
Takeaways For ergodic dynamical systems, averages over Ï‰ and averages
over trajectories coincide (ergodic theorems). In general dynamical systems,
a similar statement is true if we replace the average over Ï‰ by the conditional
expectation given the Ïƒ-algebra of invariant events.
20.3
Examples
Example 20.17 Let (X, (Px)xâˆˆE) be a positive recurrent, irreducible Markov chain
on the countable space E. Let Ï€ be the invariant distribution of X. Then Ï€({x}) > 0
for every x âˆˆE. Deï¬ne PÏ€ = 
xâˆˆE Ï€({x})Px. Then X is stationary on (Î©, A, PÏ€).
Denote the shift by Ï„; that is, Xn = X0 â—¦Ï„ n.

20.3
Examples
501
Now let A âˆˆI be invariant. Then A âˆˆT =
âˆ

n=1
Ïƒ(Xn, Xn+1, . . .). By the strong
Markov property, for every ï¬nite stopping time Ïƒ (recall that FÏƒ is the Ïƒ-algebra of
the Ïƒ-past),
PÏ€[X âˆˆA
FÏƒ] = PXÏƒ [X âˆˆA].
(20.4)
Indeed, we have {X âˆˆA} = {X âˆˆÏ„ âˆ’n(A)} = {(Xn, Xn+1, . . .) âˆˆA}. For B âˆˆFÏƒ,
using the Markov property (in the third line), we get
EÏ€
)
1{XâˆˆB} 1{XâˆˆA}
*
=
âˆ

n=0

xâˆˆE
PÏ€
)
X âˆˆB, Ïƒ = n, Xn = x, X âˆˆA
*
=
âˆ

n=0

xâˆˆE
PÏ€
)
X âˆˆB, Ïƒ = n, Xn = x, X â—¦Ï„ n âˆˆA
*
=
âˆ

n=0

xâˆˆE
PÏ€
)
X âˆˆB, Ïƒ = n, Xn = x
*
Px[X âˆˆA]
= EÏ€
)
1{XâˆˆB} PXÏƒ [X âˆˆA]
*
.
In particular, if x âˆˆE and Ïƒx = inf{n âˆˆN0 : Xn = x}, then Ïƒx < âˆsince X is
recurrent and irreducible. By (20.4), we conclude that, for every x âˆˆE,
PÏ€[X âˆˆA] = EÏ€ [Px[X âˆˆA]] = Px[X âˆˆA].
Hence PXn[X âˆˆA] = PÏ€[X âˆˆA] almost surely and thus (with Ïƒ = n in (20.4))
PÏ€[X âˆˆA
X0, . . . , Xn] = PXn[X âˆˆA] = PÏ€[X âˆˆA].
Now A âˆˆI âŠ‚Ïƒ(X1, X2, . . .); hence
PÏ€[X âˆˆA
X0, . . . , Xn]
nâ†’âˆ
âˆ’â†’
PÏ€[X âˆˆA
Ïƒ(X0, X1, . . .)] = 1{XâˆˆA}.
This implies PÏ€[X âˆˆA] âˆˆ{0, 1}. Hence X is ergodic.
Birkhoffâ€™s ergodic theorem now implies that, for every x âˆˆE,
1
n
nâˆ’1

k=0
1{Xk=x}
nâ†’âˆ
âˆ’â†’Ï€({x})
PÏ€-a.s.
In this sense, Ï€({x}) is the average time X spends in x in the long run. â™¦

502
20
Ergodic Theory
Example 20.18 Let P and Q be probability measures on the measurable space
(Î©, A), and let (Î©, A, P, Ï„) and (Î©, A, Q, Ï„) be ergodic. Then either P = Q
or P
âŠ¥Q. Indeed, if P
Ì¸= Q, then there exists an f with |f | â‰¤1 and
3
f dP Ì¸=
3
f dQ. However, by Birkhoffâ€™s ergodic theorem,
1
n
nâˆ’1

k=0
f â—¦Ï„ k nâ†’âˆ
âˆ’â†’
â§
âªâ¨
âªâ©

f dP
P-a.s.,

f dQ
Q-a.s.
If we deï¬ne A :=
	 1
n
nâˆ’1
k=0 f â—¦Ï„ k nâ†’âˆ
âˆ’â†’
3
f dP

, then P(A) = 1 and Q(A) = 0.
Thus P âŠ¥Q. â™¦
Takeaways The ergodic theorem yields a law of large numbers for the
occupation times of a positive recurrent Markov chain. Furthermore, it shows
that two ergodic measures are either equal or mutually singular.
Exercise 20.3.1 Let (Î©, A) be a measurable space and let Ï„ : Î© â†’Î© be a
measurable map.
(i) Show that the set M := {Î¼ âˆˆM1(Î©) : Î¼ â—¦Ï„ âˆ’1 = Î¼} of Ï„-invariant measures
is convex.
(ii) An element Î¼ of M is called extremal if Î¼ = Î»Î¼1 + (1 âˆ’Î»)Î¼2 for some
Î¼1, Î¼2 âˆˆM and Î» âˆˆ(0, 1) implies Î¼ = Î¼1 = Î¼2. Show that Î¼ âˆˆM is
extremal if and only if Ï„ is ergodic with respect to Î¼. â™£
Exercise 20.3.2 Let p = 2, 3, 5, 6, 7, 10, . . . be square-free (that is, there is no
number r = 2, 3, 4, . . ., whose square is a divisor of p) and let q âˆˆ{2, 3, . . ., pâˆ’1}.
For every n âˆˆN, let an be the leading digit of the p-adic expansion of qn.
Show the following version of Benfordâ€™s law: For every d âˆˆ{1, . . . , p âˆ’1},
1
n#
	
i â‰¤n : ai = d

 nâ†’âˆ
âˆ’â†’log(d + 1) âˆ’log(d)
log(p)
.
â™£
20.4
Application: Recurrence of Random Walks
Let (Xn)nâˆˆN be a stationary process with values in Rd. Deï¬ne Sn := n
k=1 Xk for
n âˆˆN0. Further, let
Rn = #{S1, . . . , Sn}

20.4
Application: Recurrence of Random Walks
503
denote the range of S; that is, the number of distinct points visited by S up to time
n. Finally, let A := {Sn Ì¸= 0 for every n âˆˆN} be the event of an â€œescapeâ€ from 0.
Theorem 20.19 We have lim
nâ†’âˆ
1
nRn = P[A|I] almost surely.
Proof Let X be the canonical process on (Î©, A, P) =

(Rd)N, B(Rd)âŠ—N, P

and
let Ï„ : Î© â†’Î© be the shift; that is, Xn = X0 â—¦Ï„ n.
Evidently,
Rn = #
	
k â‰¤n : Sl Ì¸= Sk for all l âˆˆ{k + 1, . . . , n}

â‰¥#
	
k â‰¤n : Sl Ì¸= Sk for all l > k

=
n

k=1
1A â—¦Ï„ k.
Birkhoffâ€™s ergodic theorem yields
lim inf
nâ†’âˆ
1
nRn â‰¥P[A|I]
a.s.
(20.5)
For the converse inequality, consider Am = {Sl Ì¸= 0 for l = 1, . . . , m}. Then, for
every n â‰¥m,
Rn â‰¤m + #
	
k â‰¤n âˆ’m : Sl Ì¸= Sk for all l âˆˆ{k + 1, . . . , n}

â‰¤m + #
	
k â‰¤n âˆ’m : Sl Ì¸= Sk for all l âˆˆ{k + 1, . . . , k + m}

= m +
nâˆ’m

k=1
1Am â—¦Ï„ k.
Again, by the ergodic theorem,
lim sup
nâ†’âˆ
1
nRn â‰¤P[Am
I]
a.s.
(20.6)
Since Am
â†“
A and P[Am
I]
mâ†’âˆ
âˆ’â†’
P[A|I] almost surely (by Theo-
rem 8.14(8.14)), the claim follows from (20.5) and (20.6).
âŠ“âŠ”
Theorem 20.20 Let X = (Xn)nâˆˆN be an integer-valued, integrable, stationary
process with the property E[X1
I] = 0 a.s. Let Sn = X1 + . . . + Xn, n âˆˆN.
Then
P)Sn = 0 for inï¬nitely many n âˆˆN* = 1.
In particular, a random walk on Z with centered increments is recurrent (Chungâ€“
Fuchs theorem, compare Theorem 17.41).

504
20
Ergodic Theory
Proof Deï¬ne A = {Sn Ì¸= 0 for all n âˆˆN}.
Step 1.
We show P[A] = 0. (If X is i.i.d., then S is a Markov chain, and this
implies immediately that 0 is recurrent. Only for the more general case of stationary
X do we need an additional argument.) By the ergodic theorem, we have 1
nSn
nâ†’âˆ
âˆ’â†’
E[X1
I] = 0 a.s. Thus, for every m âˆˆN,
lim sup
nâ†’âˆ
1
n
max
k=1,...,n
Sk


= lim sup
nâ†’âˆ
1
n
max
k=m,...,n
Sk


â‰¤max
kâ‰¥m
|Sk|
k
mâ†’âˆ
âˆ’â†’0.
Therefore,
lim
nâ†’âˆ
1
n
max
k=1,...,n Sk

= lim
nâ†’âˆ
1
n
min
k=1,...,n Sk

= 0.
Now Rn
â‰¤1 +

max
k=1,...,n Sk

âˆ’

min
k=1,...,n Sk

; hence
1
nRn
nâ†’âˆ
âˆ’â†’
0. By
Theorem 20.19, this implies P[A] = 0.
Step 2.
Deï¬ne Ïƒn := inf{m âˆˆN : Sm+n = Sn}, Bn := {Ïƒn < âˆ} for n âˆˆN0 and
B :=
âˆ

n=0
Bn.
Since {Ïƒ0 = âˆ} = A, we have P[Ïƒ0 < âˆ] = 1. By stationarity, P[Ïƒn < âˆ] = 1
for every n âˆˆN0; hence P[B] = 1.
Let Ï„0 = 0 and inductively deï¬ne Ï„n+1 = Ï„n + ÏƒÏ„n for n âˆˆN0. Then Ï„n is the
time of the nth return of S to 0. On B we have Ï„n < âˆfor every n âˆˆN0 and hence
P)Sn = 0 inï¬nitely often* = P)Ï„n < âˆfor all n âˆˆN* â‰¥P[B] = 1.
âŠ“âŠ”
If in Theorem 20.20 the random variables Xn are not integer-valued, then there is
no hope that Sn = 0 for any n âˆˆN with positive probability. On the other hand,
in this case, there is also some kind of recurrence property, namely Sn/n
nâ†’âˆ
âˆ’â†’0
almost surely by the ergodic theorem. Note, however, that this does not exclude the
possibility that Sn
nâ†’âˆ
âˆ’â†’âˆwith positive probability; for instance, if Sn grows like
âˆšn. The next theorem shows that if the Xn are integrable, then the process of partial
sums can go to inï¬nity only with a linear speed.
Theorem 20.21 Let (Xn)nâˆˆN be an integrable ergodic process and deï¬ne Sn =
X1 + . . . + Xn for n âˆˆN0. Then the following statements are equivalent.

20.4
Application: Recurrence of Random Walks
505
(i) Sn
nâ†’âˆ
âˆ’â†’âˆalmost surely.
(ii) P
'
Sn
nâ†’âˆ
âˆ’â†’âˆ
(
> 0.
(iii)
lim
nâ†’âˆ
Sn
n = E[X1] > 0 almost surely.
If the random variables X1, X2, . . . are i.i.d. with E[X1] = 0 and P[X1 = 0] < 1,
then lim infnâ†’âˆSn = âˆ’âˆand lim supnâ†’âˆSn = âˆalmost surely.
Proof â€œ(i) â‡â‡’(ii)â€
Clearly, B := {Sn
nâ†’âˆ
âˆ’â†’âˆ} is an invariant event and thus
has probability either 0 or 1.
â€œ(iii) â‡’(i)â€
This is trivial.
â€œ(i) â‡’(iii)â€
The equality follows by the individual ergodic theorem. Hence, it is
enough to show that lim infnâ†’âˆSn/n > 0 almost surely.
Note that P[B] = 1. For n âˆˆN0 and Îµ > 0, let
AÎµ
n :=
	
Sm > Sn + Îµ for all m â‰¥n + 1

âˆ©B.
Let Sâˆ’:= inf{Sn : n âˆˆN0}. By assumption (i), we have Sâˆ’> âˆ’âˆalmost surely
and Ï„ := sup{n âˆˆN0 : Sn = Sâˆ’} is ï¬nite almost surely. Hence there is an N âˆˆN
with P[Ï„ < N] â‰¥1
2. Therefore,
P
+ Nâˆ’1

n=0
A0
n
,
= P[Ï„ < N] â‰¥1
2.
Since AÎµ
n â†‘A0
n for Îµ â†“0, there is an Îµ > 0 with p := P
)
AÎµ
0
*
â‰¥
1
4N > 0. As
(Xn)nâˆˆN is ergodic,

1AÎµn

nâˆˆN0 is also ergodic. By the individual ergodic theorem,
we conclude that 1
n
nâˆ’1
i=0 1AÎµ
i
nâ†’âˆ
âˆ’â†’p almost surely. Hence there exists an n0 =
n0(Ï‰) such that nâˆ’1
i=0 1AÎµ
i â‰¥pn
2 for all n â‰¥n0. This implies Sn â‰¥Sâˆ’+ pnÎµ
2
for
n â‰¥n0 and hence lim infnâ†’âˆSn/n â‰¥pÎµ
2 > 0.
Now we show the additional statement. Assume that E[X1] = 0 and P[X1 =
0] < 1. Hence, there is an Îµ > 0 such that P[X1 < âˆ’2Îµ] > Îµ. Let L :=
lim infnâ†’âˆSn. As shown above, we have P[L = âˆ] = 0. The event {L > âˆ’âˆ}
is invariant and hence has probability 0 or 1. We assume P[L > âˆ’âˆ] = 1 and
construct a contradiction. Inductively, deï¬ne stopping times Ï„1 := inf{k âˆˆN :
Sk < L + Îµ} and
Ï„n+1 := inf{k > Ï„n : Sk < L + Îµ}
for n âˆˆN.
By assumption, we have Ï„n < âˆalmost surely for all n. Let F = (Fn)nâˆˆN0 =
Ïƒ((Xn)nâˆˆN) be the ï¬ltration generated by X = (Xn)nâˆˆN. Let FÏ„n be the Ïƒ-algebra

506
20
Ergodic Theory
of Ï„n-past. Deï¬ne the events An := {XÏ„n+1 < âˆ’2Îµ}, n âˆˆN. On An, we have
SÏ„n+1 < L âˆ’Îµ. Clearly, An is independent of FÏ„n and thus
P
)
An
FÏ„n
*
= P[An] > Îµ.
By the conditional version of the Borel-Cantelli Lemma (see Exercise 11.2.7), we
infer
P
'
lim sup
nâ†’âˆ
An
(
= 1.
This shows that almost surely SÏ„n+1 < L âˆ’Îµ inï¬nitely often and this in turn
contradicts the assumption that L be ï¬nite.
Consequently, we have P[lim infSn = âˆ’âˆ] = 1. The statement for lim sup Sn is
similar.
âŠ“âŠ”
Remark 20.22 It can be shown that Theorem 20.21 holds also without the assump-
tion that the Xn are integrable. See [93]. â™¦
Takeaways The set of points visited by a random walk within the ï¬rst n
steps grows with n at a speed that is the probability of no return. Hence, in the
recurrent case, the set grows sublinearly. For a random walk on Z with a ï¬nite
ï¬rst moment, this shows that it is recurrent if and only if the increments are
centred. Consequently, for such a random walk, one out of three alternatives
holds: (i) The random walk goes to âˆat positive speed. (ii) The random walk
goes to âˆ’âˆat positive speed. (iii) The random walk oscillates around 0 with
a growing amplitude. It is impossible that the random walk would go to âˆ
(or âˆ’âˆ) slower than linearly.
20.5
Mixing
Ergodicity provides a weak notion of â€œindependenceâ€ or â€œmixingâ€. At the other end
of the scale, the strongest notion is â€œi.i.d.â€. Here we are concerned with notions of
mixing that lie between these two.
In the following, we always assume that (Î©, A, P, Ï„) is a measure-preserving
dynamical system and that Xn := X0 â—¦Ï„ n. We start with a simple observation.
Theorem 20.23 (Î©, A, P, Ï„) is ergodic if and only if, for all A, B âˆˆA,
lim
nâ†’âˆ
1
n
nâˆ’1

k=0
P
'
A âˆ©Ï„ âˆ’k(B)
(
= P[A] P[B].
(20.7)

20.5
Mixing
507
Proof â€œ â‡’â€
Let (Î©, A, P, Ï„) be ergodic. Deï¬ne
Yn := 1
n
nâˆ’1

k=0
1Ï„ âˆ’k(B) = 1
n
nâˆ’1

k=0
1B â—¦Ï„ k.
By Birkhoffâ€™s ergodic theorem, we have Yn
nâ†’âˆ
âˆ’â†’
P[B] almost surely. Hence
Yn 1A
nâ†’âˆ
âˆ’â†’1A P[B] almost surely. Dominated convergence yields
1
n
nâˆ’1

k=0
P
'
A âˆ©Ï„ âˆ’k(B)
(
= E [Yn 1A]
nâ†’âˆ
âˆ’â†’E [1A P[B]] = P[A] P[B].
â€œ â‡ â€
Now assume that (20.7) holds. Let A âˆˆI (recall that I is the invariant
Ïƒ-algebra) and B = A. Evidently, A âˆ©Ï„ âˆ’k(A) = A for every k âˆˆN0. Hence,
by (20.7),
P[A] = 1
n
nâˆ’1

k=0
P
'
A âˆ©Ï„ âˆ’k(A)
( nâ†’âˆ
âˆ’â†’P[A]2.
Thus P[A] âˆˆ{0, 1}; hence I is trivial and therefore Ï„ is ergodic.
âŠ“âŠ”
We consider a strengthening of (20.7).
Deï¬nition 20.24 A measure-preserving dynamical system (Î©, A, P, Ï„) is called
mixing if
lim
nâ†’âˆP
)
A âˆ©Ï„ âˆ’n(B)
*
= P[A] P[B]
for all A, B âˆˆA.
(20.8)
Remark 20.25 Sometimes the mixing property of (20.8) is called strongly mixing,
in contrast with a weakly mixing system (Î©, A, P, Ï„), for which we require only
lim
nâ†’âˆ
1
n
nâˆ’1

i=0
P
'
A âˆ©Ï„ âˆ’i(B)
(
âˆ’P[A] P[B]
 = 0
for all A, B âˆˆA.
â€œStrongly mixingâ€ implies â€œweakly mixingâ€ (see Exercise 20.5.1). On the other
hand, there exist weakly mixing systems that are not strongly mixing (see [81]). â™¦
Example 20.26 Let I = N0 or I = Z, and let (Xn)nâˆˆI be an i.i.d. sequence with
values in the measurable space (E, E). Hence Ï„ is the shift on the product space
Î© = EI, P =

PX0
âŠ—I . Let A, B âˆˆEâŠ—I . For every Îµ > 0, there exist events AÎµ
and BÎµ that depend on only ï¬nitely many coordinates and such that P[A â–³AÎµ] < Îµ
and P[B â–³BÎµ] < Îµ. Clearly, P[Ï„ âˆ’n(A â–³AÎµ)] < Îµ and P[Ï„ âˆ’n(B â–³BÎµ)] < Îµ for

508
20
Ergodic Theory
every n âˆˆZ. For sufï¬ciently large |n|, the sets AÎµ and Ï„ âˆ’n(BÎµ) depend on different
coordinates and are thus independent. This implies
lim sup
|n|â†’âˆ
P[A âˆ©Ï„ âˆ’n(B)] âˆ’P[A] P[B]

â‰¤lim sup
|n|â†’âˆ
P[AÎµ âˆ©Ï„ âˆ’n(BÎµ)] âˆ’P[AÎµ] P[BÎµ]
 + 4Îµ = 4Îµ.
Hence Ï„ is mixing. Letting A = B âˆˆI, we obtain the 0-1 law for invariant events:
P[A] âˆˆ{0, 1}. â™¦
Remark 20.27 Clearly, (20.8) implies (20.7) and hence â€œmixingâ€ implies â€œergodicâ€.
The converse implication is false. â™¦
Example 20.28 Let Î© = [0, 1), A = B([0, 1)) and let P = Î» be the Lebesgue
measure on ([0, 1), B([0, 1))). For r âˆˆ[0, 1), deï¬ne Ï„r : Î© â†’Î© by
Ï„r(x) = x + r âˆ’âŒŠx + râŒ‹= x + r
(mod 1).
If r is irrational, then Ï„r is ergodic (Example 20.9). However, Ï„r is not mixing:
Since r is irrational, there exists a sequence kn â†‘âˆsuch that
Ï„ kn
r (0) âˆˆ
1
4, 3
4

for n âˆˆN.
Hence, for A =
'
0, 1
4
(
, we have A âˆ©Ï„ âˆ’kn
r
(A) = âˆ…. Therefore,
lim inf
nâ†’âˆP
)
A âˆ©Ï„ âˆ’n
r
(A)
*
= 0 Ì¸= 1
16 = P[A]2.
â™¦
Reï¬‚ection Why is Ï„r not mixing if r is rational? â™ 
Theorem 20.29 Let X be an irreducible, positive recurrent Markov chain on the
countable space E and let Ï€ be its invariant distribution. Let PÏ€ = 
xâˆˆE
Ï€({x}) Px.
Then:
(i) X is ergodic (on (Î©, A, PÏ€)).
(ii) X is mixing if and only if X is aperiodic.
Proof
(i) This has been shown already in Example 20.17.
(ii) As X is irreducible, by Theorem 17.52, we have Ï€({x}) > 0 for every x âˆˆE.

20.5
Mixing
509
â€œ â‡’â€
Let X be periodic with period d â‰¥2. If n âˆˆN is not a multiple of d, then
pn(x, x) = 0. Hence, for A = B = {X0 = x},
lim inf
nâ†’âˆPÏ€[X0 = x, Xn = x] = lim inf
nâ†’âˆÏ€({x}) pn(x, x)
= 0 Ì¸= Ï€({x})2 = PÏ€[X0 = x]2.
Thus X is not mixing.
â€œ â‡ â€
Let X be aperiodic. In order to simplify the notation, we may assume
that X is the canonical process on EN0. Let A, B âŠ‚Î© = EN0 be measurable.
For every Îµ > 0, there exists an N âˆˆN and a ËœAÎµ âˆˆE{0,...,N} such that, letting
AÎµ = ËœAÎµ Ã— E{N+1,N+2,...}, we have P[A â–³AÎµ] < Îµ. By the Markov property, for
every n â‰¥N,
PÏ€
)
AÎµ âˆ©Ï„ âˆ’n(B)
*
= PÏ€
'
(X0, . . . , XN) âˆˆËœAÎµ, (Xn, Xn+1, . . .) âˆˆB
(
=

x,yâˆˆE
EÏ€
)1AÎµ 1{XN =x} 1{Xn=y} (Xn, Xn+1, . . .) âˆˆB*
=

x,yâˆˆE
EÏ€
)
1AÎµ 1{XN =x}
*
pnâˆ’N(x, y)Py [B] .
By Theorem 18.13, we have pnâˆ’N(x, y)
nâ†’âˆ
âˆ’â†’Ï€({y}) for all x, y âˆˆE. (For
periodic X, this is false.) Dominated convergence thus yields
lim
nâ†’âˆPÏ€
)
AÎµ âˆ©Ï„ âˆ’n(B)
*
=

x,yâˆˆE
EÏ€
)
1AÎµ 1{XN =x}
*
Ï€({y})Py[B]
= PÏ€
)
AÎµ*
PÏ€[B].
Since
PÏ€
)
AÎµ âˆ©Ï„ âˆ’n(B)
*
âˆ’P
)
A âˆ©Ï„ âˆ’n(B)
*  < Îµ, the statement follows by
letting Îµ â†’0.
âŠ“âŠ”
Takeaways Mixing is a concept of independence stronger than ergodicity but
weaker than stochastic independence. It allows dependencies between events
as long as they wash out when the events are shifted apart. An irreducible and
aperiodic positive recurrent Markov chain is mixing. Rotations are not.
Exercise 20.5.1 Show that â€œstrongly mixingâ€ implies â€œweakly mixingâ€, which in
turn implies â€œergodicâ€. Give an example of a measure-preserving dynamical system
that is ergodic but not weakly mixing. â™£

510
20
Ergodic Theory
20.6
Entropy
The entropy H(P) of a probability distribution P (see Deï¬nition 5.25) measures the
amount of randomness in this distribution. In fact, the entropy of a delta distribution
is zero and for a distribution on n points, the maximal entropy is achieved by the
uniform distribution and equals log(n) (see Exercise 5.3.3). It is natural to use the
entropy in order to quantify also the randomness of a dynamical system.
First we consider the situation of a simple shift: Let Î© = EN0, where E is a ï¬nite
set equipped with the product Ïƒ-algebra A = (2E)âŠ—N0. Let Ï„ be the shift on Î© and
let P be an invariant probability measure. For n âˆˆN, denote by Pn the projection of
P on En = E{0,...,nâˆ’1}; that is,
Pn({(e0, . . . , enâˆ’1)}) = P
'
{e0} Ã— . . . Ã— {enâˆ’1} Ã— E{n,n+1,...}(
.
Denote by hn the entropy of Pn. By Exercise 5.3.4, the entropy is subadditive:
hm+n â‰¤hm + hn
for m, n âˆˆN.
Hence the following limit exists (see Exercise 20.6.2)
h := h(P, Ï„) := lim
nâ†’âˆ
1
n hn = inf
nâˆˆN
1
n hn.
Deï¬nition 20.30 (Entropy of the simple shift)
h(P, Ï„) is called the entropy of
the dynamical system (Î©, A, P, Ï„).
Example 20.31 Assume that P is a product measure with marginals Ï€ on E. Then
h = H(Ï€) = âˆ’

eâˆˆE
Ï€({e}) log(Ï€({e})).
â™¦
Example 20.32 (Markov chain) Let (Xn)nâˆˆN0 be a Markov chain on E with transi-
tion matrix P and stationary distribution Ï€. Let (Î©, A, P, Ï„) be the corresponding
dynamical system. For x = (x0, . . . , xnâˆ’1) and 0 â‰¤k < n âˆ’1, let
p(k, x) = Ï€({xk})P(xk, xk+1) Â· Â· Â· P(xnâˆ’2, xnâˆ’1).

20.6
Entropy
511
Then the entropy of Pn is (using stationarity of Ï€ in the third line)
H(Pn) = âˆ’

x0,...,xnâˆ’1âˆˆE
p(0, x) log(p(0, x))
= âˆ’

x0,...,xnâˆ’1âˆˆE
p(0, x)
-
log(Ï€({x0})) +
nâˆ’2

k=0
log(P(xk, xk+1))
.
= H(Ï€) âˆ’
nâˆ’2

k=0

xk,...,xnâˆ’1
p(k, x) log(P(xk, xk+1))
= H(Ï€) âˆ’(n âˆ’1)

x0,x1âˆˆE
Ï€({x0})P(x0, x1) log(P(x0, x1)).
We infer that the entropy of the dynamical system is
h(P, Ï„) = âˆ’

x,yâˆˆE
Ï€({x})P(x, y) log(P(x, y)).
(20.9)
â™¦
Example 20.33 (Integer rotation) Consider the rotation of Example 20.8. Let n âˆˆ
N \ {1}, E = Z/(n) and let P be the uniform distribution on Î©. Let r âˆˆ{1, . . ., n}
and
Ï„ : Î© â†’Î©,
x â†’x + r
(mod n).
Clearly, Ï„ (n) is the identity map, hence hn = h2n = . . . and thus h(P, Ï„) = 0. â™¦
We now come to the situation of the general dynamical system. Let P be a ï¬nite
measurable partition of Î©; that is, P = {A1, . . . , Ak} for certain pairwise disjoint
non-empty sets A1, . . . , Ak âˆˆA with Î© = A1âˆª. . .âˆªAk. Denote by Pn the partition
that is generated by the sets nâˆ’1
l=0 Ï„ âˆ’l(Ail), i1, . . . , in âˆˆ{1, . . ., k}. We deï¬ne
hn(P, Ï„; P) = âˆ’

AâˆˆPn
P[A] log(P[A]).
Similarly as in the simple shift case, we obtain the subadditivity of (hn) and thus
the existence of
h(P, Ï„; P) := lim
nâ†’âˆ
1
n hn(P, Ï„; P) = inf
nâˆˆN
1
n hn(P, Ï„; P).

512
20
Ergodic Theory
Deï¬nition 20.34 (Kolmogorovâ€“Sinai entropy)
The entropy of a (general) mea-
sure-preserving dynamical system (Î©, A, P, Ï„) is
h(P, Ï„) = sup
P
h(P, Ï„; P),
where the supremum is taken over all ï¬nite measurable partitions of Î©.
Theorem 20.35 (Kolmogorovâ€“Sinai)
Let P be a generator of A; that is A =
Ïƒ
 
nâˆˆN0 Ï„ âˆ’n(P)

. Then
h(P, Ï„) = h(P, Ï„; P).
Proof See, e.g., [88, Theorem 3.2.18], [168, Theorem 4.17] or [156].
âŠ“âŠ”
The Kolmogorovâ€“Sinai theorem shows that the entropy that was introduced in
Deï¬nition 20.30 for simple shifts coincides with the entropy of Deï¬nition 20.34;
simply take P =
	
{e} Ã— EN, e âˆˆE} which generates the product Ïƒ-algebra on
Î© = EN0.
Example 20.36 (Rotation) We come back to the rotation of Example 20.9. Let Î© =
[0, 1), A = B(Î©), P = Î» the Lebesgue measure, r âˆˆ(0, 1) and Ï„r(x) = x +
r (mod 1).
First assume that r is rational. Let P be an arbitrary ï¬nite measurable partition of
Î©. Choose n âˆˆN such that rn âˆˆN0. As in Example 20.33 we obtain hn(P, Ï„r; P) =
hkn(P, Ï„r; P) for all k âˆˆN, hence h(P, Ï„r, P) = 0. Concluding, we get h(P, Ï„r) =
0.
Now assume that r is irrational. Choose the partition P = {[0, 1/2), [1/2, 1)}.
As r is irrational, it is easy to see that A is generated by 
nâˆˆN0 Ï„ âˆ’n
r
(P). Hence
h(P, Ï„r) = h(P, Ï„r, P). In order to compute the latter quantity, we ï¬rst determine
the cardinality #Pn. To this end, consider the map
Ï†n : [0, 1) â†’{0, 1}n
x â†’

1[1/2,1)(x), 1[1/2,1)(Ï„r(x)), . . . , 1[1/2,1)(Ï„ nâˆ’1
r
(x))

Clearly, we have #Ï†n([0, 1)) = #Pn. As x âˆˆ[0, 1) increases, each coordinate
1[1/2,1)(Ï„ k
r (x)), k = 1, . . . , n âˆ’1, changes its value exactly twice. Only 1[1/2,1)(x)
changes the value exactly once. Summing up, we get #Ï†n([0, 1)) â‰¤2n. The
maximal entropy of a probability measure on N points is achieved by the uniform
distribution and is log(N). Consequently, hn(P, Ï„r; P) â‰¤log(2n). We conclude that
h(P, Ï„r) = h(P, Ï„r; P) = 0.
â™¦

20.6
Entropy
513
Takeaways The entropy is an important characteristic of a dynamical system.
It measures the amount of new randomness added in each step. For Markov
chains, the entropy can be computed explicitly. This is particularly helpful
in the context of statistical mechanics when a Markov chain is needed that
maximises the entropy under certain constraints.
Exercise 20.6.1 Let Î© = [0, 1) and Ï„ : x â†’2x (mod 1). Let P be the Lebesgue
measure on Î©. Determine h(P, Ï„).
Exercise 20.6.2 Let (an)nâˆˆN be a sequence on nonnegative numbers. The sequence
is called subadditive, if am+n â‰¤am + an for all m, n âˆˆN. Show that the limit
limnâ†’âˆan/n exists and that
lim
nâ†’âˆ
1
n an = inf
nâˆˆN
1
n an.
â™£
Exercise 20.6.3 Let pi be the transition matrix of a Markov chain on the countable
set Ei with entropy hi, i = 1, 2. Compute the entropy of the bivariate chain on E1 Ã—
E2 with transition matrix p given by p((x1, x2), (y1, y2)) = p1(x1, y1)p2(x2, y2).
â™£
Exercise 20.6.4 Consider a Markov chain on E
=
{1, 2, 3} with transition
matrix p.
(i) Which p maximises the entropy?
(ii) Now we set the constraint p(2, 1) = 0. Which p maximises the entropy under
the constraint? â™£

Chapter 21
Brownian Motion
In Example 14.48, we constructed a (canonical) process (Xt)tâˆˆ[0,âˆ) with indepen-
dent stationary normally distributed increments. For example, such a process can
be used to describe the motion of a particle immersed in water or the change of
prices in the stock market. We are now interested in properties of this process X that
cannot be described in terms of ï¬nite-dimensional distributions but reï¬‚ect the whole
path t â†’Xt. For example, we want to compute the distribution of the functional
F(X) := suptâˆˆ[0,1] Xt. The ï¬rst problem that has to be resolved is to show that
F(X) is a random variable.
In this chapter, we investigate continuity properties of paths of stochastic
processes and show how they ensure measurability of some path functionals. Then
we construct a version of X that has continuous paths, the so-called Wiener process
or Brownian motion. Without exaggeration, it can be stated that Brownian motion is
the central object of probability theory.
For further reading, we recommend, e.g., [86, 118, 145, 152].
21.1
Continuous Versions
A priori the paths of a canonical process are of course not continuous since every
map [0, âˆ) â†’R is possible. Hence, it will be important to ï¬nd out which paths are
P-almost surely negligible.
Deï¬nition 21.1 Let X and Y be stochastic processes on (Î©, A, P) with time set
I and state space E. X and Y are called
(i) modiï¬cations or versions of each other if, for any t âˆˆI, we have
Xt = Yt
P-almost surely,
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_21
515

516
21
Brownian Motion
(ii) indistinguishable if there exists an N âˆˆA with P[N] = 0 such that
{Xt Ì¸= Yt} âŠ‚N
for all t âˆˆI.
Clearly, indistinguishable processes are modiï¬cations of each other. Under
certain assumptions on the continuity of the paths, however, the two notions
coincide.
Reï¬‚ection Find an example of two stochastic processes that are modiï¬cations of
each other but that are not indistinguishable. â™ 
Deï¬nition 21.2 Let (E, d) and (Eâ€², dâ€²) be metric spaces and Î³ âˆˆ(0, 1]. A map
Ï• : E â†’Eâ€² is called HÃ¶lder-continuous of order Î³ (brieï¬‚y, HÃ¶lder-Î³ -continuous)
at the point r âˆˆE if there exist Îµ > 0 and C < âˆsuch that, for any s âˆˆE with
d(s, r) < Îµ, we have
dâ€²(Ï•(r), Ï•(s)) â‰¤C d(r, s)Î³ .
(21.1)
Ï• is called locally HÃ¶lder-continuous of order Î³ if, for every t âˆˆE, there exist Îµ > 0
and C = C(t, Îµ) > 0 such that, for all s, r âˆˆE with d(s, t) < Îµ and d(r, t) < Îµ,
the inequality (21.1) holds. Finally, Ï• is called HÃ¶lder-continuous of order Î³ if there
exists a C such that (21.1) holds for all s, r âˆˆE.
In the case Î³ = 1, HÃ¶lder continuity is Lipschitz continuity (see Deï¬nition 13.8).
Furthermore, for E = R and Î³ > 1, every locally HÃ¶lder-Î³ -continuous function
is constant. Evidently, a locally HÃ¶lder-Î³ -continuous map is HÃ¶lder-Î³ -continuous
at every point. On the other hand, for a function Ï• that is HÃ¶lder-Î³ -continuous at a
given point t, there need not exist an open neighborhood in which Ï• is continuous.
In particular, Ï• need not be locally HÃ¶lder-Î³ -continuous.
Reï¬‚ection Let f : R â†’R be continuously differentiable. Check that f is HÃ¶lder-
Î³ -continuous for any Î³ âˆˆ(0, 1]. If the derivative of f is bounded, then f is also
(globally) HÃ¶lder-1-continuous, but not necessarily (globally) HÃ¶lder-Î³ -continuous
for any Î³ âˆˆ(0, 1). â™ 
We collect some simple properties of HÃ¶lder-continuous functions.
Lemma 21.3 Let I âŠ‚R and let f : I â†’R be locally HÃ¶lder-continuous of order
Î³ âˆˆ(0, 1]. Then the following statements hold.
(i) f is locally HÃ¶lder-continuous of order Î³ â€² for every Î³ â€² âˆˆ(0, Î³ ).
(ii) If I is compact, then f is HÃ¶lder-continuous.
(iii) Let I be a bounded interval of length T > 0. Assume that there exists an Îµ > 0
and an C(Îµ) < âˆsuch that, for all s, t âˆˆI with |t âˆ’s| â‰¤Îµ, we have
|f (t) âˆ’f (s)| â‰¤C(Îµ) |t âˆ’s|Î³ .
Then f is HÃ¶lder-continuous of order Î³ with constant C := C(Îµ) âŒˆT/ÎµâŒ‰1âˆ’Î³ .

21.1
Continuous Versions
517
Proof
(i) This is obvious since |t âˆ’s|Î³ â‰¤|t âˆ’s|Î³ â€² for all s, t âˆˆI with |t âˆ’s| â‰¤1.
(ii) For t âˆˆI and Îµ > 0, let UÎµ(t) := {s âˆˆI : |s âˆ’t| < Îµ}. For every t âˆˆI,
choose Îµ(t) > 0 and C(t) < âˆsuch that
|f (r) âˆ’f (s)| â‰¤C(t) Â· |r âˆ’s|Î³
for all r, s âˆˆUt := UÎµ(t)(t).
There exists a ï¬nite subcovering Uâ€² = {Ut1, . . . , Utn} of the covering U :=
{Ut, t âˆˆI} of I. Let Ï± > 0 be a Lebesgue number of the covering Uâ€²; that is,
Ï± > 0 is such that, for every t âˆˆI, there exists a U âˆˆU such that UÏ±(t) âŠ‚U.
Deï¬ne
C := max
	
C(t1), . . . , C(tn), 2âˆ¥f âˆ¥âˆÏ±âˆ’Î³ 
.
For s, t âˆˆI with |t âˆ’s| < Ï±, there is an i âˆˆ{1, . . . , n} with s, t âˆˆUti. By
assumption, we have |f (t) âˆ’f (s)| â‰¤C(ti) |t âˆ’s|Î³ â‰¤C |t âˆ’s|Î³ . Now let
s, t âˆˆI with |s âˆ’t| â‰¥Ï±. Then
|f (t) âˆ’f (s)| â‰¤2âˆ¥f âˆ¥âˆ
|t âˆ’s|
Ï±
Î³
â‰¤C |t âˆ’s|Î³ .
Hence f is HÃ¶lder-continuous of order Î³ with constant C.
(iii) Let n =
O T
Îµ
P
. For s, t âˆˆI, by assumption, |tâˆ’s|
n
â‰¤Îµ and thus
|f (t) âˆ’f (s)| â‰¤
n

k=1
f

s + (t âˆ’s)k
n

âˆ’f

s + (t âˆ’s)k âˆ’1
n

â‰¤C(Îµ) n1âˆ’Î³ |t âˆ’s|Î³ = C |t âˆ’s|Î³ .
âŠ“âŠ”
Deï¬nition 21.4 (Path properties) Let I âŠ‚R and let X = (Xt, t âˆˆI) be a
stochastic process on some probability space (Î©, A, P) with values in a metric
space (E, d). Let Î³ âˆˆ(0, 1]. For every Ï‰ âˆˆÎ©, we say that the map I â†’E,
t â†’Xt(Ï‰) is a path of X.
We say that X has almost surely continuous paths, or brieï¬‚y that X is a.s.
continuous, if for almost all Ï‰ âˆˆÎ©, the path t â†’Xt(Ï‰) is continuous. Similarly,
we deï¬ne locally HÃ¶lder-Î³ -continuous paths and so on.
Lemma 21.5 Let X and Y be modiï¬cations of each other. Assume that one of the
following conditions holds.
(i) I is countable.
(ii) I âŠ‚R is a (possibly unbounded) interval and X and Y are almost surely right
continuous.
Then X and Y are indistinguishable.

518
21
Brownian Motion
Proof Deï¬ne Nt := {Xt Ì¸= Yt} for t âˆˆI and Â¯N = 
tâˆˆI Nt. By assumption,
P[Nt] = 0 for every t âˆˆI. We have to show that there exists an N âˆˆA with
Â¯N âŠ‚N and P[N] = 0.
(i) If I is countable, then N := Â¯N is measurable and P[N] â‰¤
tâˆˆI P[Nt] = 0.
(ii) Now let I âŠ‚R be an interval and let X and Y be almost surely right continuous.
Deï¬ne
Â¯R := {X and Y are right continuous}
and choose an R âˆˆA with R âŠ‚Â¯R and P[R] = 1. Deï¬ne
I :=
0
Q âˆ©I,
if I is open to the right,
(Q âˆ©I) âˆªmax I,
if I is closed to the right,
and 
N := 
râˆˆI Nr. By (i), we have P[
N] = 0. Furthermore, for every t âˆˆI,
Nt âˆ©R âŠ‚

râ‰¥t, râˆˆI
(Nr âˆ©R) âŠ‚
N.
Hence
Â¯N âŠ‚Rc âˆª

tâˆˆI
Nt âŠ‚Rc âˆª
N =: N,
and thus P[N] â‰¤P[Rc] + P[
N] = 0.
âŠ“âŠ”
We come to the main theorem of this section.
Theorem 21.6 (Kolmogorovâ€“Chentsov) Let X = (Xt, t âˆˆ[0, âˆ)) be a real-
valued process. Assume for every T > 0, there are numbers Î±, Î², C > 0 such that
E )|Xt âˆ’Xs|Î±* â‰¤C|t âˆ’s|1+Î²
for all s, t âˆˆ[0, T ].
(21.2)
Then the following statements hold.
(i) There is a modiï¬cation 
X = (
Xt, t âˆˆ[0, âˆ)) of X whose paths are locally
HÃ¶lder-continuous of every order Î³ âˆˆ

0, Î²
Î±

.
(ii) Let Î³ âˆˆ

0, Î²
Î±

. For every Îµ > 0 and T < âˆ, there exists a number K < âˆ
that depends only on Îµ, T, Î±, Î², C, Î³ such that
P
'
| ËœXt âˆ’ËœXs| â‰¤K |t âˆ’s|Î³ , s, t âˆˆ[0, T ]
(
â‰¥1 âˆ’Îµ.
(21.3)

21.1
Continuous Versions
519
Proof
(i) It is enough to show that, for any T > 0, the process X on [0, T ] has a
modiï¬cation XT that is locally HÃ¶lder-continuous of any order Î³ âˆˆ(0, Î²/Î±).
For S, T
> 0, by Lemma 21.5, two such modiï¬cations XS and XT are
indistinguishable on [0, S âˆ§T ]; hence
Î©S,T :=

there is a t âˆˆ[0, S âˆ§T ] with XT
t Ì¸= XS
t

is a null set and thus also Î©âˆ:=

S,T âˆˆN
Î©S,T is a null set. Therefore, deï¬ning
ËœXt(Ï‰) := Xt
t (Ï‰), t â‰¥0, for Ï‰ âˆˆÎ© \ Î©âˆ, we get that ËœX is a locally HÃ¶lder-
continuous modiï¬cation of X on [0, âˆ).
Without loss of generality, assume T = 1. We show that X has a continuous
modiï¬cation on [0, 1]. By Markovâ€™s inequality, for every Îµ > 0,
P [|Xt âˆ’Xs| â‰¥Îµ] â‰¤CÎµâˆ’Î± |t âˆ’s|1+Î².
(21.4)
Hence
Xs
sâ†’t
âˆ’â†’Xt
in probability.
(21.5)
The idea is ï¬rst to construct 
X on the dyadic rational numbers and then to
extend it continuously to [0, 1]. To this end, we will need (21.5). In particular,
for Î³ > 0, n âˆˆN and k âˆˆ{1, . . . , 2n}, we have
P
)Xk2âˆ’n âˆ’X(kâˆ’1)2âˆ’n
 â‰¥2âˆ’Î³ n*
â‰¤C 2âˆ’n(1+Î²âˆ’Î±Î³ ).
Deï¬ne
An = An(Î³ ) := 	 max 	|Xk2âˆ’n âˆ’X(kâˆ’1)2âˆ’n|, k âˆˆ{1, . . ., 2n}
 â‰¥2âˆ’Î³ n
and
Bn :=
âˆ

m=n
Am
and
N := lim sup
nâ†’âˆ
An =
âˆ

n=1
Bn.
It follows that, for every n âˆˆN,
P[An] â‰¤
2n

k=1
P
)
|Xk2âˆ’n âˆ’X(kâˆ’1)2âˆ’n| â‰¥2âˆ’Î³ n*
â‰¤C 2âˆ’n(Î²âˆ’Î±Î³ ).

520
21
Brownian Motion
Now ï¬x Î³ âˆˆ(0, Î²/Î±) to obtain
P[Bn] â‰¤
âˆ

m=n
P[Am] â‰¤C 2âˆ’(Î²âˆ’Î±Î³ )n
1 âˆ’2Î±Î³ âˆ’Î²
nâ†’âˆ
âˆ’â†’0,
(21.6)
hence P[N] = 0. Now ï¬x Ï‰ âˆˆÎ© \ N and choose n0 = n0(Ï‰) such that
Ï‰ Ì¸âˆˆ
âˆ

n=n0
An. Hence
Xk2âˆ’n(Ï‰) âˆ’X(kâˆ’1)2âˆ’n(Ï‰)
 < 2âˆ’Î³ n
for k âˆˆ{1, . . . , 2n}, n â‰¥n0.
(21.7)
Deï¬ne the sets of ï¬nite dyadic rationals Dm = {k2âˆ’m, k = 0, . . . , 2m}, and let
D = 
mâˆˆN
Dm. Any t âˆˆDm has a unique dyadic expansion
t =
m

i=0
bi(t) 2âˆ’i
for some bi(t) âˆˆ{0, 1}, i = 0, . . . , m.
Let m â‰¥n â‰¥n0 and s, t âˆˆDm, s â‰¤t with |s âˆ’t| â‰¤2âˆ’n. Let u := max(Dn âˆ©
[0, s]). Then
u â‰¤s < u + 2âˆ’n
and
u â‰¤t < u + 21âˆ’n
and hence bi(t âˆ’u) = bi(s âˆ’u) = 0 for i < n. Deï¬ne
tl = u +
l
i=n
bi(t âˆ’u) 2âˆ’i
for l = n âˆ’1, . . . , m.
Then, we have tnâˆ’1 = u and tm = t. Furthermore, tl âˆˆDl for l = n, . . . , m and
tl âˆ’tlâˆ’1 â‰¤2âˆ’l
for l = n, . . . , m.
Hence, by (21.7),
|Xt(Ï‰) âˆ’Xu(Ï‰)| â‰¤
m

l=n
Xtl(Ï‰) âˆ’Xtlâˆ’1(Ï‰)
 â‰¤
m

l=n
2âˆ’Î³ l â‰¤
2âˆ’Î³ n
1 âˆ’2âˆ’Î³ .
Analogously, we obtain |Xs(Ï‰) âˆ’Xu(Ï‰)| â‰¤2âˆ’Î³ n(1 âˆ’2âˆ’Î³ )âˆ’1, and thus
|Xt(Ï‰) âˆ’Xs(Ï‰)| â‰¤2
2âˆ’Î³ n
1 âˆ’2âˆ’Î³ .
(21.8)

21.1
Continuous Versions
521
Deï¬ne C0 = 21+Î³ (1 âˆ’2âˆ’Î³ )âˆ’1 < âˆ. Let s, t âˆˆD with |s âˆ’t| â‰¤2âˆ’n0. By
choosing the minimal n â‰¥n0 such that |t âˆ’s| â‰¥2âˆ’n, we obtain by (21.8),
|Xt(Ï‰) âˆ’Xs(Ï‰)| â‰¤C0 |t âˆ’s|Î³ .
(21.9)
As in the proof of Lemma 21.3(iii), we infer (with K := C0 2(1âˆ’Î³ )n0)
|Xt(Ï‰) âˆ’Xs(Ï‰)| â‰¤K |t âˆ’s|Î³
for all s, t âˆˆD.
(21.10)
In other words, for dyadic rationals D, X(Ï‰) is (globally) HÃ¶lder-Î³ -continuous.
In particular, X is uniformly continuous on D; hence it can be extended to [0, 1].
For t âˆˆD, deï¬ne 
Xt := Xt. For t âˆˆ[0, 1] \ D and {sn, n âˆˆN} âŠ‚D with
sn âˆ’â†’t, the sequence

Xsn(Ï‰)

nâˆˆN is a Cauchy sequence. Hence the limit

Xt(Ï‰) :=
lim
Dâˆ‹sâ†’t Xs(Ï‰)
(21.11)
exists. Furthermore, the statement analogous to (21.10) holds not only for
s, t âˆˆD:

Xt(Ï‰) âˆ’
Xs(Ï‰)
 â‰¤K |t âˆ’s|Î³
for all s, t âˆˆ[0, 1].
(21.12)
Hence 
X is locally HÃ¶lder-continuous of order Î³ . By (21.5) and (21.11), we
have P
)
Xt Ì¸= 
Xt
*
= 0 for every t âˆˆ[0, 1]. Hence 
X is a modiï¬cation of X.
(ii) Let Îµ > 0 and choose n âˆˆN large enough that (see (21.6))
P[Bn] â‰¤C 2âˆ’(Î²âˆ’Î±Î³ )n
1 âˆ’2Î±Î³ âˆ’Î² < Îµ.
For Ï‰ Ì¸âˆˆBn, we conclude that (21.10) holds. However, this is exactly (21.3) with
T = 1. For general T , the claim follows by linear scaling.
âŠ“âŠ”
Remark 21.7 The statement of Theorem 21.6 remains true if X assumes values in
some Polish space (E, Ï±) since in the proof we did not make use of the assumption
that the range was in R. However, if we change the time set, then the assumptions
have to be strengthened: If (Xt)tâˆˆRd is a process with values in E, and if, for certain
Î±, Î² > 0, all T > 0 and some C < âˆ, we have
E[Ï±(Xt, Xs)Î±] â‰¤C âˆ¥t âˆ’sâˆ¥d+Î²
2
for all s, t âˆˆ[âˆ’T, T ]d,
(21.13)
then for every Î³ âˆˆ(0, Î²/Î±), there is a locally HÃ¶lder-Î³ -continuous version of X. â™¦

522
21
Brownian Motion
Takeaways The distribution of a stochastic process determines only proper-
ties that can be described by the values at countably many time points. For
example, continuity is not among those properties. Under certain moment
conditions, a stochastic process X allows for a modiï¬cation
ËœX that is
continuous and equals X with probability 1 at any given time.
Exercise 21.1.1 Show the claim of Remark 21.7. â™£
Exercise 21.1.2 Let X = (Xt)tâ‰¥0 be a real-valued process with continuous paths.
Show that, for all 0 â‰¤a < b, the map Ï‰ â†’
3 b
a Xt(Ï‰) dt is measurable. â™£
Exercise 21.1.3 (Optional sampling/ stopping)
Let F be a ï¬ltration and let
(Xt)tâ‰¥0 be an F-supermartingale with right continuous paths. Let Ïƒ and Ï„ be
bounded stopping times with Ïƒ
â‰¤Ï„. Deï¬ne Ïƒ n
:= 2âˆ’nâŒˆ2nÏƒâŒ‰and Ï„ n
:=
2âˆ’nâŒˆ2nÏ„âŒ‰.
(i) Show that E[XÏ„ m |FÏƒ n]
nâ†’âˆ
âˆ’â†’E[XÏ„ m |FÏƒ] almost surely and in L1 as well as
XÏƒn
nâ†’âˆ
âˆ’â†’XÏƒ almost surely and in L1.
(ii) Infer the optional sampling theorem for right continuous supermartingales by
using the analogous statement for discrete time (Theorem 10.11); that is, XÏƒ â‰¥
E[XÏ„ |FÏƒ].
(iii) Show that if Y is adapted, integrable and right continuous, then Y is a
martingale if and only if E[YÏ„ ] = E[Y0] for every bounded stopping time Ï„.
(iv) Assume that X is uniformly integrable and that Ïƒ â‰¤Ï„ are ï¬nite (not necessarily
bounded) stopping times. Show that XÏƒ â‰¥E[XÏ„ |FÏƒ].
(v) Now let Ï„ be an arbitrary stopping time. Deduce the optional stopping
theorem for right continuous supermartingales: (XÏ„âˆ§t)tâ‰¥0 is a right continuous
supermartingale. â™£
Exercise 21.1.4 Let X = (Xt)tâ‰¥0 be a stochastic process on (Î©, F, P) with values
in the Polish space E and with right continuous paths. Show the following.
(i) The map (Ï‰, t) â†’Xt(Ï‰) is measurable with respect to FâŠ—B([0, âˆ)) â€“ B(E).
(ii) If in addition X is adapted to the ï¬ltration F, then for any t â‰¥0, the map
Î© Ã— [0, t] â†’E, (Ï‰, s) â†’Xs(Ï‰) is Ft âŠ—B([0, t]) â€“ B(E) measurable.
(iii) If Ï„ is an F-stopping time and X is adapted, then XÏ„ is an FÏ„-measurable
random variable. â™£
21.2
Construction and Path Properties
Deï¬nition 21.8 A real-valued stochastic process B = (Bt, t âˆˆ[0, âˆ)) is called a
Brownian motion if

21.2
Construction and Path Properties
523
0
0.5
1
1.5
2
2.5
3
0.5
1
1.5
2
Fig. 21.1 Computer simulation of a Brownian motion.
(i) B0 = 0,
(ii) B has independent, stationary increments (compare Deï¬nition 9.7),
(iii) Bt âˆ¼N0,t for all t > 0, and
(iv) t â†’Bt is P-almost surely continuous.
See Fig. 21.1 for a computer simulation of a Brownian motion.
Theorem 21.9 There exists a probability space (Î©, A, P) and a Brownian motion
B on (Î©, A, P). The paths of B are a.s. locally HÃ¶lder-Î³ -continuous for every
Î³ < 1
2.
Proof As in Example 14.48 or Corollary 16.10 there exists a stochastic process X
that fulï¬lls (i), (ii) and (iii). Evidently, Xt âˆ’Xs
D= âˆšt âˆ’s X1 âˆ¼N0,tâˆ’s for all
t > s â‰¥0. Thus, for every n âˆˆN, writing Cn := E[X2n
1 ] = (2n)!
2nn! < âˆ, we have
E
'
(Xt âˆ’Xs)2n(
= E
'âˆš
t âˆ’s X1
2n(
= Cn |t âˆ’s|n .
Now let n â‰¥2 and Î³ âˆˆ(0, nâˆ’1
2n ). Theorem 21.6 yields the existence of a version B
of X that has HÃ¶lder-Î³ -continuous paths. Since all continuous versions of a process
are equivalent, B is locally HÃ¶lder-Î³ -continuous for every Î³ âˆˆ(0, nâˆ’1
2n ) and every
n â‰¥2 and hence for every Î³ âˆˆ(0, 1
2).
âŠ“âŠ”

524
21
Brownian Motion
Recall that a stochastic process (Xt)tâˆˆI is called a Gaussian process if, for every
n âˆˆN and for all t1, . . . , tn âˆˆI, we have that
(Xt1, . . . , Xtn)
is n-dimensional normally distributed.
X is called centered if E[Xt] = 0 for every t âˆˆI. The map
Î“ (s, t) := Cov[Xs, Xt]
for s, t âˆˆI
is called the covariance function of X.
Remark 21.10 The covariance function determines the ï¬nite-dimensional distribu-
tions of a centered Gaussian process since a multidimensional normal distribution
is determined by the vector of expectations and by the covariance matrix. â™¦
Theorem 21.11 Let X = (Xt)tâˆˆ[0,âˆ) be a stochastic process. Then the following
are equivalent:
(i) X is a Brownian motion.
(ii) X is a continuous centered Gaussian process with Cov[Xs, Xt] = s âˆ§t for all
s, t â‰¥0.
Proof By Remark 21.10, X is characterized by (ii). Hence, it is enough to show
that, for Brownian motion X, we have Cov[Xs, Xt] = min(s, t). This is indeed true
since for t > s, the random variables Xs and Xt âˆ’Xs are independent; hence
Cov[Xs, Xt] = Cov[Xs, Xt âˆ’Xs] + Cov[Xs, Xs] = Var[Xs] = s.
âŠ“âŠ”
Reï¬‚ection Let X = (X(s,t))s,tâ‰¥0 be a centred Gaussian process on the time set
[0, âˆ)2 with covariance function
Cov[X(s,t), X(sâ€²,tâ€²)] = (s âˆ§sâ€²) Â· (t âˆ§tâ€²).
Check that there exists a continuous modiï¬cation of X. This modiï¬cation is called
Brownian sheet. â™ â™ 
Corollary 21.12 (Scaling property of Brownian motion) If B is a Brownian
motion and if K Ì¸= 0, then (Kâˆ’1BK2 t)tâ‰¥0 is also a Brownian motion.
Example 21.13 Another example of a continuous Gaussian process is the so-called
Brownian bridge X = (Xt)tâˆˆ[0,1] that is deï¬ned by the covariance function
Î“ (s, t) = s âˆ§t âˆ’st. We construct the Brownian bridge as follows.
Let B = (Bt, t âˆˆ[0, 1]) be a Brownian motion and let
Xt := Bt âˆ’tB1.

21.2
Construction and Path Properties
525
Clearly, X is a centered Gaussian process with continuous paths. We compute the
covariance function Î“ of X,
Î“ (s, t) = Cov[Xs, Xt] = Cov[Bs âˆ’sB1, Bt âˆ’tB1]
= Cov[Bs, Bt] âˆ’s Cov[B1, Bt] âˆ’t Cov[Bs, B1] + st Cov[B1, B1]
= min(s, t) âˆ’st âˆ’st + st = min(s, t) âˆ’st.
â™¦
(21.14)
Theorem 21.14 Let (Bt)tâ‰¥0 be a Brownian motion and
Xt =

tB1/t,
if t > 0,
0,
if t = 0.
Then X is a Brownian motion.
Proof Clearly, X is a Gaussian process. For s, t > 0, we have
Cov[Xs, Xt] = ts Â· Cov[B1/s, B1/t] = ts min

sâˆ’1, tâˆ’1
= min(s, t).
Clearly, t â†’Xt is continuous at every point t > 0. To show continuity at t = 0,
consider
lim sup
tâ†“0
Xt = lim sup
tâ†’âˆ
1
t Bt
â‰¤lim sup
nâ†’âˆ
1
nBn + lim sup
nâ†’âˆ
1
n sup 	Bt âˆ’Bn, t âˆˆ[n, n + 1]
.
By the strong law of large numbers, we have limnâ†’âˆ1
nBn = 0 a.s. Using a
generalization of the reï¬‚ection principle (Theorem 17.15; see also Theorem 21.19),
for x > 0, we have (using the abbreviation B[a,b] := {Bt : t âˆˆ[a, b]})
P
)
sup B[n,n+1] âˆ’Bn > x
*
= P
)
sup B[0,1] > x
*
= 2 P[B1 > x]
=
2
âˆš
2Ï€
 âˆ
x
eâˆ’u2/2 du â‰¤1
x eâˆ’x2/2.
In particular,
âˆ

n=1
P) sup B[n,n+1] âˆ’Bn > nÎµ* < âˆfor every Îµ > 0. By the Borelâ€“
Cantelli lemma (Theorem 2.7), we infer
lim sup
nâ†’âˆ
1
n sup
	
Bt âˆ’Bn, t âˆˆ[n, n + 1]

= 0
almost surely.
Hence X is also continuous at 0.
âŠ“âŠ”

526
21
Brownian Motion
Theorem 21.15 (Blumenthalâ€™s 0-1 law, see [18]) Let B be a Brownian motion
and let F = (Ft)tâ‰¥0 = Ïƒ(B) be the ï¬ltration generated by B. Further, let F+
0 =

t>0 Ft. Then F+
0 is a P-trivial Ïƒ-algebra.
Proof Deï¬ne Y n = (B2âˆ’n+t âˆ’B2âˆ’n)tâˆˆ[0,2âˆ’n], n âˆˆN. Then (Y n)nâˆˆN is an indepen-
dent family of random variables (with values in C([0, 2âˆ’n])). By Kolmogorovâ€™s 0-1
law (Theorem 2.37), the tail Ïƒ-algebra T = 
nâˆˆN Ïƒ(Y m, m â‰¥n) is P-trivial. On
the other hand, Ïƒ(Y m, m â‰¥n) = F2âˆ’n+1; hence
F+
0
=

t>0
Ft =

nâˆˆN
F2âˆ’n+1 = T
is P-trivial.
âŠ“âŠ”
Example 21.16 Let B be a Brownian motion. For every K > 0, we have
P
)
inf
	
t > 0 : Bt â‰¥K
âˆš
t

= 0
*
= 1.
(21.15)
To check this, deï¬ne As :=
	
inf{t > 0 : Bt â‰¥K
âˆš
t } â‰¤s

and
A :=

inf
	
t > 0 : Bt â‰¥K
âˆš
t

= 0

=

s>0
As âˆˆF+
0 .
Then P[A] âˆˆ{0, 1}. By the scaling property of Brownian motion,
P[A] = inf
s>0P[As] â‰¥P[B1 â‰¥K] > 0
and thus P[A] = 1. â™¦
The preceding example shows that, for every t â‰¥0, almost surely B is not
HÃ¶lder- 1
2-continuous at t. Note that the order of quantiï¬ers is subtle. We have not
shown that almost surely B was not HÃ¶lder- 1
2-continuous at any t â‰¥0 (however,
see Remark 22.4). However, it is not too hard to show the following theorem, which
for the case Î³ = 1 is due to Paley, Wiener and Zygmund [126]. The proof presented
here goes back to an idea of Dvoretzky, ErdÃ¶s and Kakutani (see [40]).
Theorem 21.17 (Paleyâ€“Wienerâ€“Zygmund [126]) For every Î³ > 1
2, almost surely
the paths of Brownian motion (Bt)tâ‰¥0 are not HÃ¶lder-continuous of order Î³ at any
point. In particular, the paths are almost surely nowhere differentiable.
Proof Let Î³ > 1
2. It sufï¬ces to consider B = (Bt)tâˆˆ[0,1]. Denote by HÎ³,t the set of
maps [0, 1] â†’R that are HÃ¶lder-Î³ -continuous at t and deï¬ne HÎ³ := 
tâˆˆ[0,1) HÎ³,t.
The aim is to show that almost surely B Ì¸âˆˆHÎ³ . By translation invariance, this
implies that B is nowhere HÃ¶lder-Î³ -continuous a.s. in any of the countably many
intervals [n/2, (n/2) + 1), n âˆˆN0, which implies the claim of the theorem.

21.2
Construction and Path Properties
527
If t âˆˆ[0, 1) and w âˆˆHÎ³,t, then for every Î´ > 0 there exists a c = c(Î´, w) with
the property |ws âˆ’wt| â‰¤c |s âˆ’t|Î³ for every s âˆˆ[0, 1] with |s âˆ’t| < Î´. Choose a
k âˆˆN with k >
2
2Î³ âˆ’1. Then, for n âˆˆN with n â‰¥n0 := âŒˆ(k + 1)/Î´âŒ‰, i = âŒŠtnâŒ‹+ 1
and l âˆˆ{0, . . . , k âˆ’1}, we get
w(i+l+1)/n âˆ’w(i+l)/n
 â‰¤
w(i+l+1)/n âˆ’wt
 +
w(i+l)/n âˆ’wt
 â‰¤2c (k + 1)Î³ nâˆ’Î³ .
Hence, for N â‰¥2c (k + 1)Î³ , we have w âˆˆAN,n,i, where
AN,n,i :=
kâˆ’1

l=0

w :
w(i+l+1)/n âˆ’w(i+l)/n
 â‰¤N nâˆ’Î³ 
.
Deï¬ne AN,n = n
i=1 AN,n,i, AN = lim infnâ†’âˆAN,n and A = âˆ
N=1 AN. Clearly,
HÎ³ âŠ‚A. Owing to the independence of increments and since the density of the
standard normal distribution is bounded by 1, we get
P[B âˆˆAN,n,i] = P
)
|B1/n| â‰¤N nâˆ’Î³ *k = P
)
|B1| â‰¤N nâˆ’Î³ +1/2*k
â‰¤Nk nk(âˆ’Î³ +1/2).
By the choice of k and since the increments of B are stationary, we have
P
)
B âˆˆAN
*
= lim
nâ†’âˆP
+
B âˆˆ

mâ‰¥n
AN,m
,
â‰¤lim sup
nâ†’âˆ
P[B âˆˆAN,n]
â‰¤lim sup
nâ†’âˆ
n

i=1
P[B âˆˆAN,n,i]
â‰¤lim sup
nâ†’âˆ
n P[B âˆˆAN,n,1]
â‰¤Nk lim sup
nâ†’âˆ
n1+k(âˆ’Î³ +1/2) = 0
Thus P[B âˆˆA] = 0. Therefore, we almost surely have B Ì¸âˆˆHÎ³ .
âŠ“âŠ”

528
21
Brownian Motion
Takeaways We have used the Kolmogorov-Chentsov theorem to construct
Brownian motion as a continuous Gaussian process. The paths are HÃ¶lder
continuous of any order less than 1/2, but almost surely they are not HÃ¶lder
continuous of any order larger than 1/2 at any point. In particular, the paths
are almost surely nowhere differentiable. Any property of Brownian motion
that can be checked arbitrarily early after time 0 has either probability 0 or 1.
Exercise 21.2.1 Let B be a Brownian motion and let Î» be the Lebesgue measure
on [0, âˆ).
(i) Compute the expectation and variance of
3 1
0 Bs ds. (For the measurability of
the integral see Exercise 21.1.2.)
(ii) Show that almost surely Î»

{t : Bt = 0}

= 0.
(iii) Compute the expectation and variance of
 1
0

Bt âˆ’
 1
0
Bs ds
2
dt.
â™£
Exercise 21.2.2 Let B be a Brownian motion. Show that (B2
t âˆ’t)tâ‰¥0 is a martingale.
â™£
Exercise 21.2.3 Let B be a Brownian motion and Ïƒ > 0. Show that the process

exp

ÏƒBt âˆ’Ïƒ 2
2 t

tâ‰¥0 is a martingale. â™£
Exercise 21.2.4 Let B be a Brownian motion, a < 0 < b. Deï¬ne the stopping time
Ï„a,b = inf{t â‰¥0 : Bt âˆˆ{a, b}}.
Show that almost surely Ï„a,b < âˆand that P[BÏ„a,b = b] = âˆ’
a
bâˆ’a. Furthermore,
show (using Exercise 21.2.2) that E[Ï„a,b] = âˆ’ab. â™£
Exercise 21.2.5 Let B be a Brownian motion, b > 0 and Ï„b = inf{t â‰¥0 : Bt = b}.
Show the following.
(i) E[eâˆ’Î»Ï„b] = eâˆ’b
âˆš
2Î» for Î» â‰¥0. (Hint: Use Exercise 21.2.3 and the optional
sampling theorem.)
(ii) Ï„b has a 1
2-stable distribution with LÃ©vy measure
Î½(dx) =

b/(
âˆš
2Ï€)

xâˆ’3/2 1{x>0} dx.
(iii) The distribution of Ï„b has density fb(x) =
b
âˆš
2Ï€ eâˆ’b2/(2x) xâˆ’3/2. â™£
Exercise 21.2.6 Let B be a Brownian motion, a âˆˆR, b > 0 and Ï„ = inf{t â‰¥0 :
Bt = at + b}. For Î» â‰¥0, show that
E
)
eâˆ’Î»Ï„*
= exp

âˆ’ba âˆ’b
2
a2 + 2Î»

.

21.3
Strong Markov Property
529
Conclude that P[Ï„ < âˆ] = 1 âˆ§eâˆ’2ba. â™£
21.3
Strong Markov Property
Denote by Px the probability measure such that B = (Bt)tâ‰¥0 is a Brownian motion
started at x âˆˆR. To put it differently, under Px, the process (Bt âˆ’x)tâ‰¥0 is a standard
Brownian motion. While the (simple) Markov property of (B, (Px)xâˆˆR) is evident,
it takes some work to check the strong Markov property.
Theorem 21.18 (Strong Markov property) Brownian motion B with distribu-
tions (Px)xâˆˆR has the strong Markov property.
Proof Let F = Ïƒ(B) be the ï¬ltration generated by B and let Ï„ < âˆbe an F-
stopping time. We have to show that, for every bounded measurable F : R[0,âˆ) â†’
R, we have:
Ex
)F(Bt+Ï„)tâ‰¥0
FÏ„
* = EBÏ„ [F(B)].
(21.16)
It is enough to consider continuous bounded functions F that depend on only ï¬nitely
many coordinates t1, . . . , tN since these functions determine the distribution of
(Bt+Ï„)tâ‰¥0. Hence, let f : RN â†’R be continuous and bounded and F(B) =
f (Bt1, . . . , BtN ). Manifestly, the map
x â†’Ex[F(B)] = E0[f (Bt1 + x, . . ., BtN + x)]
is continuous and bounded. Now let Ï„ n := 2âˆ’nâŒŠ2nÏ„ + 1âŒ‹for n âˆˆN. Then Ï„ n is a
stopping time and Ï„ n â†“Ï„; hence BÏ„ n
nâ†’âˆ
âˆ’â†’BÏ„ almost surely. Now every Markov
process with countable time set (here all positive rational linear combinations of
1, t1, . . . , tN) is a strong Markov process (by Theorem 17.14); hence we have
Ex
)F(BÏ„ n+t)tâ‰¥0
FÏ„ n* = Ex
)f (BÏ„ n+t1, . . . , BÏ„ n+tN )
FÏ„ n*
= EBÏ„n
)
f (Bt1, . . . , BtN )
*
nâ†’âˆ
âˆ’â†’EBÏ„
)
f (Bt1, . . . , BtN )
*
= EBÏ„ [F(B)].
(21.17)
As B is right continuous, we have F

(BÏ„ n+t)tâ‰¥0
 nâ†’âˆ
âˆ’â†’F

(BÏ„+t)tâ‰¥0

almost
surely and in L1 and thus
E
'Ex
)
F

(BÏ„ n+t)tâ‰¥0
FÏ„ n*
âˆ’Ex
)
F

(BÏ„+t)tâ‰¥0
FÏ„ n*
(
â‰¤Ex
'F

(BÏ„ n+t)tâ‰¥0

âˆ’F

(BÏ„+t)tâ‰¥0

( nâ†’âˆ
âˆ’â†’0.
(21.18)

530
21
Brownian Motion
Furthermore,
FÏ„ n â†“FÏ„+ :=

Ïƒ>Ï„ is a stopping time
FÏƒ âŠƒFÏ„.
In fact, obviously, we have FÏ„n âŠƒFÏ„+ for all n. On the other hand, for A âˆˆ

nâˆˆN FÏ„n and Ïƒ > Ï„ a stopping time, we have for all t
Ft âˆ‹A âˆ©{Ï„n â‰¤t} âˆ©{Ïƒ â‰¤t} = A âˆ©{(Ïƒ âˆ¨Ï„n) â‰¤t} â†‘A âˆ©{Ïƒ â‰¤t}.
Hence, A âˆˆFÏƒ âŠ‚FÏ„+.
By (21.17) and (21.18), using the convergence theorem for backwards martin-
gales (Theorem 12.14), we get that in the sense of L1-limits
EBÏ„ [F(B)] = lim
nâ†’âˆEx
)
F

(BÏ„ n+t)tâ‰¥0
FÏ„ n*
= lim
nâ†’âˆEx
)
F

(BÏ„+t)tâ‰¥0
FÏ„ n*
= Ex
)
F

(BÏ„+t)tâ‰¥0
FÏ„+
*
.
The left-hand side is FÏ„-measurable. The tower property of conditional expectation
thus yields (21.16).
âŠ“âŠ”
Using the strong Markov property, we show the reï¬‚ection principle for Brownian
motion.
Theorem 21.19 (Reï¬‚ection principle for Brownian motion) For every a > 0 and
T > 0,
P
)
sup
	
Bt : t âˆˆ[0, T ]

> a
*
= 2 P[BT > a] â‰¤2
âˆš
T
âˆš
2Ï€
1
a eâˆ’a2/2T .
Proof By the scaling property of Brownian motion (Corollary 21.12), without loss
of generality, we may assume T = 1. Let Ï„ := inf{t â‰¥0 : Bt â‰¥a} âˆ§1. By the
strong Markov property, (Bâ€²
t)tâ‰¥0 := (BÏ„+t)tâ‰¥0 is a Brownian motion started at a
and is independent of FÏ„. By symmetry, we have Pa[Bâ€²
1âˆ’Ï„ > a|Ï„ < 1] = 1
2; hence
P[B1 > a] = P[B1 > a
Ï„ < 1] P[Ï„ < 1]
= Pa[B1âˆ’Ï„ > a] P[Ï„ < 1] = 1
2 P[Ï„ < 1].
For the inequality compute
P[B1 > a] =
1
âˆš
2Ï€
 âˆ
a
eâˆ’x2/2 dx
â‰¤
1
âˆš
2Ï€
1
a
 âˆ
a
x eâˆ’x2/2 dx =
1
âˆš
2Ï€
1
a eâˆ’a2/2.
âŠ“âŠ”

21.3
Strong Markov Property
531
As an application of the reï¬‚ection principle we derive Paul LÃ©vyâ€™s arcsine law
[107, page 216] for the last time a Brownian motion visits zero.
Theorem 21.20 (LÃ©vyâ€™s arcsine law) Let T > 0 and Î¶T := sup{t â‰¤T : Bt = 0}.
Then, for t âˆˆ[0, T ],
P
)
Î¶T â‰¤t
*
= 2
Ï€ arcsin
2
t/T

.
Proof Without loss of generality, assume T = 1 and Î¶ = Î¶1. Let 
B be a further,
independent Brownian motion. By the reï¬‚ection principle,
P[Î¶ â‰¤t] = P
)
Bs Ì¸= 0 for all s âˆˆ[t, 1]
*
=
 âˆ
âˆ’âˆ
P
)
Bs Ì¸= 0 for all s âˆˆ[t, 1]
Bt = a
*
P[Bt âˆˆda]
=
 âˆ
âˆ’âˆ
P|a|
)
Bs > 0 for all s âˆˆ[0, 1 âˆ’t]
*
P[Bt âˆˆda]
=
 âˆ
âˆ’âˆ
P0
)
|
B1âˆ’t| â‰¤|a|
*
P[Bt âˆˆda]
= P
)
|
B1âˆ’t| â‰¤|Bt|
*
.
If X and Y are independent and N0,1-distributed, then
Bt, 
B1âˆ’t
 D= âˆš
t X,
âˆš
1 âˆ’t Y.
Hence
P[Î¶ â‰¤t] = P)âˆš
1 âˆ’t |Y| â‰¤
âˆš
t |X|*
= P)Y 2 â‰¤t(X2 + Y 2)*
= 1
2Ï€
 âˆ
âˆ’âˆ
dx
 âˆ
âˆ’âˆ
dy eâˆ’(x2+y2)/2 1{y2â‰¤t(x2+y2)}.
Passing to polar coordinates, we obtain
P[Î¶ â‰¤t] = 1
2Ï€
 âˆ
0
r dreâˆ’r2/2
 2Ï€
0
dÏ• 1{sin(Ï•)2â‰¤t} = 2
Ï€ arcsin
âˆš
t

.
âŠ“âŠ”

532
21
Brownian Motion
Takeaways Brownian motion can be constructed as a strong Markov process.
This is the starting point for many conclusions. As examples, we have shown
the reï¬‚ection principle and LÃ©vyâ€™s arcsine law.
Exercise 21.3.1 (Hard problem!) Let Px be the distribution of Brownian motion
started at x âˆˆR. Let a > 0 and Ï„ = inf
	
t â‰¥0 : Bt âˆˆ{0, a}

. Use the reï¬‚ection
principle to show that, for every x âˆˆ(0, a),
Px[Ï„ > T ] =
âˆ

n=âˆ’âˆ
(âˆ’1)n Px
)
BT âˆˆ[na, (n + 1)a]
*
.
(21.19)
If f is the density of a probability distribution on R with characteristic function Ï•
and supxâˆˆR x2f (x) < âˆ, then the Poisson summation formula holds,
âˆ

n=âˆ’âˆ
f (s + n) =
âˆ

k=âˆ’âˆ
Ï•(k) e2Ï€is
for all s âˆˆR.
(21.20)
Use (21.19) and (21.20) (compare also (21.38)) to conclude that
Px[Ï„ > T ] = 4
Ï€
âˆ

k=0
1
2k+1 exp

âˆ’(2k+1)2Ï€2 T
2a2

sin

(2k+1)Ï€x
a

.
(21.21)
â™£
21.4
Supplement: Feller Processes
In many situations, a continuous version of a process would be too much to expect,
for instance, the Poisson process is generically discontinuous. However, often there
is a version with right continuous paths that have left-sided limits. At this point,
we only brieï¬‚y make plausible the existence theorem for such regular versions of
processes in the case of so-called Feller semigroups.
Deï¬nition 21.21 Let E be a Polish space. A map f : [0, âˆ) â†’E is called RCLL
(right continuous with left limits) or cÃ dlÃ g (continue Ã  droit, limites Ã  gauche) if
f (t) = f (t+) := limsâ†“t f (s) for every t â‰¥0 and if, for every t > 0, the left-sided
limit f (tâˆ’) := limsâ†‘t f (s) exists and is ï¬nite.
Deï¬nition 21.22 A ï¬ltration F = (Ft)tâ‰¥0 is called right continuous if F = F+,
where F+
t
= 
s>t Fs. We say that a ï¬ltration F satisï¬es the usual conditions (from
the French conditions habituelles) if F is right continuous and if F0 is P-complete.

21.4
Supplement: Feller Processes
533
Remark 21.23 If F is an arbitrary ï¬ltration and F+,âˆ—
t
is the completion of F+
t , then
F+,âˆ—satisï¬es the usual conditions. â™¦
Theorem 21.24 (Doobâ€™s regularization) Let F be a ï¬ltration that satisï¬es the
usual conditions and let X = (Xt)tâ‰¥0 be an F-supermartingale such that t â†’
E[Xt] is right continuous. Then there exists a modiï¬cation 
X of X with RCLL paths.
Proof For a, b âˆˆQ+, a < b and I âŠ‚[0, âˆ), let Ua,b
I
be the number of upcrossings
of (Xt)tâˆˆI over [a, b]. By the upcrossing inequality (Lemma 11.3), for every N > 0
and every ï¬nite set I âŠ‚[0, N], we have E[Ua,b
I
] â‰¤(E[|XN|]+|a|)/(b âˆ’a). Deï¬ne
Ua,b
N
= Ua,b
Q+âˆ©[0,N]. Then E[Ua,b
N ] â‰¤(E[|XN|] + |a|)/(b âˆ’a). By Exercise 11.1.1,
for Î» > 0, we have
Î» P
)
sup{|Xt| : t âˆˆQ+ âˆ©[0, N]} > Î»
*
= Î» sup

P
)
sup{|Xt| : t âˆˆI} > Î»
*
: I âŠ‚Q+ âˆ©[0, N] ï¬nite

â‰¤6 E[|X0|] + 4 E[|XN|].
Consider the event
A :=

NâˆˆN


a,bâˆˆQ+
0â‰¤a<bâ‰¤N
{Ua,b
N
< âˆ} âˆ©
	
sup{|Xt| : t âˆˆQ+ âˆ©[0, N]} < âˆ


.
We have P[A] = 1; hence A âˆˆFt for every t â‰¥0 since F satisï¬es the usual
conditions. For Ï‰ âˆˆA, for every t â‰¥0, the limit

Xt(Ï‰) :=
lim
Q+âˆ‹sâ†“t, s>t Xs(Ï‰)
exists and is RCLL. For Ï‰ âˆˆAc, we deï¬ne 
Xt(Ï‰) = 0. As F satisï¬es the usual
conditions, 
X is F-adapted. As X is a supermartingale, for every N, the family
(Xs)sâ‰¤N is uniformly integrable. Hence, by assumption,
E[
Xt] =
lim
Q+âˆ‹sâ†“t, s>t E[Xs] = E[Xt].
However, since X is a supermartingale, for every s > t, we have
Xt â‰¥E[Xs |Ft]
Q+âˆ‹sâ†“t, s>t
âˆ’â†’
E[
Xt |Ft] = 
Xt
in L1.
Therefore, Xt = 
Xt almost surely and hence 
X is a modiï¬cation of X.
âŠ“âŠ”
Reï¬‚ection Why cannot we drop the assumption that t â†’E[Xt] be right continu-
ous? â™ 

534
21
Brownian Motion
Corollary 21.25 Let (Î½t)tâ‰¥0 be a continuous convolution semigroup and assume
that
3
|x|Î½1(dx) < âˆ. Then there exists a Markov process X with RCLL paths and
with independent stationary increments PXtâˆ’Xs = Î½tâˆ’s for all t > s.
Let E be a locally compact Polish space and let C0(E) be the set of (bounded)
continuous functions that vanish at inï¬nity. If Îº is a stochastic kernel from E to E
and if f is measurable and bounded, then we deï¬ne Îºf (x) =
3
Îº(x, dy) f(y).
Deï¬nition 21.26 A Markov semigroup (Îºt)tâ‰¥0 on E is called a Feller semigroup if
f (x) = lim
tâ†’0 Îºtf (x)
for all x âˆˆE, f âˆˆC0(E)
and Îºtf âˆˆC0(E) for every f âˆˆC0(E).
Let X be a Markov process with transition kernels (Îºt)tâ‰¥0 and with respect to a
ï¬ltration F that satisï¬es the usual conditions.
Let g âˆˆC0(E), g â‰¥0. Let h =
3 âˆ
0
eâˆ’tÎºtg dt. Then
eâˆ’sÎºsh = eâˆ’s
 âˆ
0
eâˆ’tÎºsÎºtg dt =
 âˆ
s
eâˆ’tÎºtg dt â‰¤h.
Hence Xg := (eâˆ’th(Xt))tâ‰¥0 is an F-supermartingale.
The Feller property and Theorem 21.24 ensure the existence of an RCLL version

Xg of Xg. It takes a little more work to show that there exists a countable set G âŠ‚
C0(E) and a process 
X that is uniquely determined by 
Xg, g âˆˆG, and is an RCLL
version of X. See, e.g., [147, Chapter III.7ff].
Let us take a momentâ€™s thought and look back at how we derived the strong
Markov property of Brownian motion in Sect. 21.3. Indeed, there we needed only
right continuity of the paths and a certain continuity of the distribution as a function
of the starting point, which is exactly the Feller property. With a little more work,
one can show the following theorem (see, e.g., [147, Chapter III.8ff] or [145,
Chapter III, Theorem 2.7]).
Theorem 21.27 Let (Îºt)tâ‰¥0 be a Feller semigroup on the locally compact Polish
space E. Then there exists a strong Markov process (Xt)tâ‰¥0 with RCLL paths and
transition kernels (Îºt)tâ‰¥0.
Such a process X is called a Feller process.
Takeaways A Feller semigroup of stochastic kernels is a Markov semigroup
with just enough additional regularity such that we can construct an RCLL
version of the corresponding Markov process.

21.5
Construction via L2-Approximation
535
Exercise 21.4.1 (Doobâ€™s inequality) Let X
= (Xt)tâ‰¥0 be a martingale or a
nonnegative submartingale with RCLL paths. For T â‰¥0, let |X|âˆ—
T =
sup
tâˆˆ[0,T ]
|Xt|.
Show Doobâ€™s inequalities:
(i) For any p â‰¥1 and Î» > 0, we have Î»p P
)
|X|âˆ—
T â‰¥Î»
*
â‰¤E
)
|XT |p*
.
(ii) For any p > 1, we have E
)
|XT |p*
â‰¤E
)
(|X|âˆ—
T )p*
â‰¤

p
pâˆ’1
p
E
)
|XT |p*
.
Construct a counterexample that shows that right continuity of the paths of X is
essential. â™£
Exercise 21.4.2 (Martingale convergence theorems) Let X be a stochastic pro-
cess with RCLL paths. Use Doobâ€™s inequality (Exercise 21.4.1) to show that
the martingale convergence theorems (a.s. convergence (Theorem 11.4), a.s. and
L1-convergence for uniformly integrable martingales (Theorem 11.7) and the Lp-
martingale convergence theorem (Theorem 11.10)) hold for X. â™£
Exercise 21.4.3 Let p â‰¥1 and let X1, X2, X3, . . . be Lp-integrable martingales.
Assume that, for every t â‰¥0, there exists an 
Xt âˆˆLp(P) such that Xn
t
nâ†’âˆ
âˆ’â†’
Xt in
Lp.
(i) Show that (
Xt)tâ‰¥0 is a martingale.
(ii) Use Doobâ€™s inequality to show the following. If p > 1 and if X1, X2, . . . are
a.s. continuous, then there is a continuous martingale X with the following
properties: X is a modiï¬cation of 
X and Xn
t
nâ†’âˆ
âˆ’â†’Xt in Lp for every t â‰¥0.
â™£
Exercise 21.4.4 Let X be a stochastic process with values in a Polish space E and
with RCLL paths. Let F = Ïƒ(X) be the ï¬ltration generated by X and deï¬ne F+ :=
(F+
t )tâ‰¥0 by F+
t
= 
s>t Fs. Let U âŠ‚E be open and let C âŠ‚E be closed. For
every set A âŠ‚E, deï¬ne Ï„A := inf{t > 0 : Xt âˆˆA}. Show the following.
(i) Ï„C is an F-stopping time (and an F+-stopping time).
(ii) Ï„U is an F+-stopping time but in general (even for continuous X) is not an
F-stopping time. â™£
Exercise 21.4.5 Show the statement of Remark 21.23. Conclude that if F is a
ï¬ltration and if B is a Brownian motion that is an F-martingale, then B is also
an F+,âˆ—-martingale. â™£
21.5
Construction via L2-Approximation
We give an alternative construction of Brownian motion by functional analytic
means as an L2-approximation. For simplicity, as the time interval we take [0, 1]
instead of [0, âˆ).

536
21
Brownian Motion
Let H = L2([0, 1]) be the Hilbert space of square integrable (with respect to
Lebesgue measure Î») functions [0, 1] â†’R with inner product
âŸ¨f, gâŸ©=

[0,1]
f (x)g(x) Î»(dx)
and with norm âˆ¥f âˆ¥= âˆšâŸ¨f, f âŸ©(compare Sect. 7.3). Two functions f, g âˆˆH are
considered equal if f = g Î»-a.e. Let (bn)nâˆˆN be an orthonormal basis (ONB) of H;
that is, âŸ¨bm, bnâŸ©= 1{m=n} and
lim
nâ†’âˆ
;;;f âˆ’
n

m=1
âŸ¨f, bmâŸ©bm
;;; = 0
for all f âˆˆH.
In particular, for every f âˆˆH, Parsevalâ€™s equation
âˆ¥f âˆ¥2 =
âˆ

m=1
âŸ¨f, bmâŸ©2
(21.22)
holds and for f, g âˆˆH
âŸ¨f, gâŸ©=
âˆ

m=1
âŸ¨f, bmâŸ©âŸ¨g, bmâŸ©.
(21.23)
Now consider an i.i.d. sequence (Î¾n)nâˆˆN of N0,1-random variables on some
probability space (Î©, A, P). For n âˆˆN and t âˆˆ[0, 1], deï¬ne
Xn
t =

1[0,t](s)
 n

m=1
Î¾mbm(s)

Î»(ds) =
n

m=1
Î¾mâŸ¨1[0,t], bmâŸ©.
Clearly, for n â‰¥m,
E)(Xm
t âˆ’Xn
t )2* = E
-
n

k=m+1
Î¾k
B1[0,t], bk
C
 
n

l=m+1
Î¾l
B1[0,t], bl
C
.
=
n

k=m+1
B1[0,t], bk
C2 â‰¤
âˆ

k=m+1
B1[0,t], bk
C2.
Since âˆ
k=1âŸ¨1[0,t], bkâŸ©2 = âˆ¥1[0,t]âˆ¥2 = t < âˆ, we have Xn
t âˆˆL2(P) and
lim
mâ†’âˆsup
nâ‰¥m
E
)
(Xm
t âˆ’Xn
t )2*
= 0.

21.5
Construction via L2-Approximation
537
Hence

Xn
t

nâˆˆN is a Cauchy sequence in L2(P) and thus (since L2(P) is complete,
see Theorem 7.3) has an L2-limit Xt. Thus, for N âˆˆN and 0 â‰¤t1, . . . , tN â‰¤1,
lim
nâ†’âˆE
+ N

i=1

Xn
ti âˆ’Xti
2
,
= 0.
In particular,

Xn
t1, . . . , Xn
tN
 nâ†’âˆ
âˆ’â†’

Xt1, . . . , XtN

in P-probability.
Manifestly,

Xn
t1, . . . , Xn
tN

is normally distributed and centered. For s, t âˆˆ[0, 1],
we have
Cov
)
Xn
s , Xn
t
*
= E
- n

k=1
Î¾k
B
1[0,s], bk
C
  n

l=1
Î¾l
B
1[0,t], bl
C
.
=
n

k,l=1
E[Î¾kÎ¾l]
B
1[0,s], bk
CB
1[0,t], bl
C
=
n

k=1
B
1[0,s], bk
CB
1[0,t], bk
C
nâ†’âˆ
âˆ’â†’
B
1[0,s], 1[0,t]
C
= min(s, t).
Hence (Xt)tâˆˆ[0,1] is a centered Gaussian process with
Cov[Xs, Xt] = min(s, t).
(21.24)
LÃ©vy Construction of Brownian motion
Up to continuity of paths, X is thus a Brownian motion. A continuous version of X
can be obtained via the Kolmogorovâ€“Chentsov theorem (Theorem 21.6). However,
by a clever choice of the ONB (bn)nâˆˆN, we can construct X directly as a continuous
process. The Haar functions bn,k are one such choice: Let b0,1 â‰¡1 and for n âˆˆN
and k = 1, . . . , 2nâˆ’1, let
bn,k(t) =
â§
âªâªâªâªâªâ¨
âªâªâªâªâªâ©
2(nâˆ’1)/2,
if
2k âˆ’2
2n
â‰¤t < 2k âˆ’1
2n
,
âˆ’2(nâˆ’1)/2,
if
2k âˆ’1
2n
â‰¤t < 2k
2n ,
0,
else.

538
21
Brownian Motion
Then (bn,k) is an orthonormal system: âŸ¨bm,k, bn,lâŸ©= 1{(m,k)=(n,l)}. It is easy to
check that (bn,k) is a basis (exercise!). Deï¬ne the Schauder functions by
Bn,k(t) =

[0,t]
bn,k(s) Î»(ds) = B1[0,t], bn,k
C.
Let Î¾0,1, (Î¾n,k)nâˆˆN, k=1,...,2nâˆ’1 be independent and N0,1-distributed. Let
Xn := Î¾0,1 B0,1 +
n

m=1
2mâˆ’1

k=1
Î¾m,k Bm,k,
and deï¬ne ËœXt as the L2(P)-limit ËœXt = L2 âˆ’limnâ†’âˆXn
t . See Fig. 21.2 for a
computer simulation of Xn, n = 0, 1, 2, 3, 10.
Theorem 21.28 (Brownian motion, L2-approximation) There is a continuous
version X of ËœX. X is a Brownian motion and we have
lim
nâ†’âˆ
;;Xn âˆ’X
;;
âˆ= 0
P-almost surely.
(21.25)
Proof By (21.25), we have Xt = ËœXt a.s. for all t âˆˆ[0, 1]. As uniform limits of
continuous functions are continuous, (21.25) implies that X is continuous. Hence,
0
1/4
1/2
3/4
1
âˆ’1.5
âˆ’1.0
âˆ’0.5
0.0
0.5
Fig. 21.2 The processes Xn, n = 0, 1, 2, 3, 10 of the LÃ©vy construction of Brownian motion.

21.5
Construction via L2-Approximation
539
by (21.24) (and Theorem 21.11), X is a Brownian motion. Therefore, it is enough
to prove the existence of an X such that (21.25) holds.
Since (C([0, 1]), âˆ¥Â· âˆ¥âˆ) is complete, it sufï¬ces to show that P-almost surely
(Xn) is a Cauchy sequence in (C([0, 1]), âˆ¥Â· âˆ¥âˆ). Note that âˆ¥Bn,kâˆ¥âˆâ‰¤2âˆ’(n+1)/2
if n âˆˆN and Bn,kBn,l = 0 if k Ì¸= l. Hence
;;Xn âˆ’Xnâˆ’1;;
âˆâ‰¤2âˆ’(n+1)/2 max
	
|Î¾n,k|, k = 1, . . . , 2nâˆ’1
.
Therefore,
P
'
âˆ¥Xn âˆ’Xnâˆ’1âˆ¥âˆ> 2âˆ’n/4(
â‰¤
2nâˆ’1

k=1
P
'
|Î¾n,k| > 2(n+2)/4(
= 2nâˆ’1
2
âˆš
2Ï€
 âˆ
2(n+2)/4 eâˆ’x2/2dx
â‰¤2n exp

âˆ’2n/2
.
Evidently,
âˆ

n=1
P[âˆ¥Xn âˆ’Xnâˆ’1âˆ¥âˆ> 2âˆ’n/4] < âˆ; hence, by the Borelâ€“Cantelli
lemma,
P
';;Xn âˆ’Xnâˆ’1;;
âˆ> 2âˆ’n/4
only ï¬nitely often
(
= 1.
We conclude that lim
nâ†’âˆsup
mâ‰¥n
âˆ¥Xm âˆ’Xnâˆ¥âˆ= 0 P-almost surely.
âŠ“âŠ”
Brownian Motion and White Noise
The construction of Brownian motion via Haar functions has the advantage that
continuity of the paths is straightforward. For some applications, however, a
decomposition in trigonometric functions is preferable. Here as the orthonormal
basis of L2([0, 1]) we use b0 = 1 and
bn(x) =
âˆš
2 cos(nÏ€ x)
for n âˆˆN.
For t âˆˆ[0, 1] and n âˆˆN0, deï¬ne
Bn(t) =
 t
0
bn(s) Î»(ds);

540
21
Brownian Motion
that is, B0(t) = t and
Bn(t) =
âˆš
2
n Ï€ sin(nÏ€ t)
for n âˆˆN.
Let Î¾n, n âˆˆN0, be independent standard normally distributed random variables.
Deï¬ne A0 = Î¾0 and
An :=
âˆš
2
Ï€n Î¾n
for n âˆˆN.
Finally, let
Xn :=
n

k=0
Î¾k Bk;
that is,
Xn(t) = Î¾0 t +
n

k=1
Ak sin(kÏ€ t).
See Fig. 21.3 for a computer simulation of Xn, n = 0, 1, 4, 64, 8192.
0.0
0.2
0.4
0.6
0.8
1.0
âˆ’0.5
0.0
0.5
1.0
Fig. 21.3 The processes Xn, n = 0, 1, 4, 64, 8192 from the Fourier Construction of Brownian
motion.

21.5
Construction via L2-Approximation
541
As shown above, the sequence (Xn) converges in L2([0, 1]) towards a process
X, which (up to continuity of paths) has all properties of Brownian motion:
Xt = Î¾0 t +
âˆ

n=1
âˆš
2
nÏ€ Î¾n sin(nÏ€ t).
This representation of the Brownian motions goes back to Paley and Wiener who
also show that along a suitable subsequence the series converges uniformly almost
surely and hence the limit X is indeed continuous, see [125, Theorem XLIII,
page 148]. The representation is also sometimes called Karhunenâ€“LoÃ¨ve expansion.
More precisely, up to the ï¬rst summand, it is the Karhunenâ€“LoÃ¨ve expansion of the
Brownian bridge (Xt âˆ’tX1)tâˆˆ[0,1] (see, e.g., [1, Chapter 3.3]).
Taking the formal derivative
Ë™Xt := d
dt Xt = Î¾0 +
âˆš
2
âˆ

n=1
Î¾n cos(nÏ€ t)
we get independent identically distributed Fourier coefï¬cients for all frequencies.
Hence, the formal object Ë™X is often referred to as white noise as opposed to colored
noise where the coefï¬cients for the different frequencies have different distributions.
The Fourier basis is not too well suited to showing continuity of paths. For
example, the sufï¬cient criterion of absolute summability of coefï¬cients (An) fails
(see Exercise 21.5.5).
Example 21.29 (Stochastic integral Ã  la Paleyâ€“Wiener) Assume that (Î¾n)nâˆˆN is an
i.i.d. sequence of N0,1-distributed random variables. Let (bn)nâˆˆN be an orthonormal
basis of L2([0, 1]) such that Wt := limnâ†’âˆ
n
k=1 Î¾k âŸ¨1[0,t], bkâŸ©, t âˆˆ[0, 1], is a
Brownian motion. For f âˆˆL2([0, 1]), deï¬ne
I(f ) :=
âˆ

n=1
Î¾n âŸ¨f, bnâŸ©.
By Parsevalâ€™s equation and the BienaymÃ© formula, we have
âˆ¥f âˆ¥2
2 =
âˆ

n=1
âŸ¨f, bnâŸ©2 = Var
)
I(f )
*
= E
)
I(f )2*
.
Hence
I : L2([0, 1]) â†’L2(P),
f â†’I(f )
is an isometry.
(21.26)

542
21
Brownian Motion
We call
 t
0
f (s) dWs := If 1[0,t]
,
t âˆˆ[0, 1], f âˆˆL2([0, 1]),
the stochastic integral of f with respect to W. In the special case of the Fourier
basis b0(x) = 1 and bn(x) =
âˆš
2 cos(nÏ€x), n âˆˆN, this construction goes back to
Paley and Wiener [125, Theorem XLV, page 154].
The process Xt :=
3 t
0 f (s) dWs, t âˆˆ[0, 1], is centered Gaussian with covariance
function
Cov[Xs, Xt] =
 sâˆ§t
0
f 2(u) du.
In fact, it is obvious that X is centered and Gaussian (since it is a limit of
the Gaussian processes of partial sums) and has the given covariance function.
Furthermore, the existence of a continuous version can be obtained as for Brownian
motion by employing the fourth moments of the increments, which for normal
random variables can be computed from the variances (compare Theorem 21.9).
In the following we will assume for the stochastic integral that such a continuous
version is chosen.
In the special case, f =
n
i=1
Î±i 1(tiâˆ’1,ti] for some n âˆˆN and 0 = t0 < t1 < . . . <
tn and Î±1, . . . , Î±n âˆˆR, we obtain
 1
0
f (s) dWs =
n

i=1
Î±i

Wti âˆ’Wtiâˆ’1

.
â™¦
Takeaways Consider an orthonormal basis of the Hilbert space L2([0, 1])
and assign to each basis vector an i.i.d. standard normally distributed factor.
Now integrate over [0, t] and sum up. The inï¬nite series is a Gaussian process
with the same covariance function as Brownian motion. If we choose the
orthonormal basis cleverly, then we automatically get a continuous process.
As one possible choice for the basis consists of cosine functions, this
procedure is known as frequency decomposition of Brownian motion.
Exercise 21.5.1 Use the representation of Brownian motion (Wt)tâˆˆ[0,1] as a random
linear combination of the Schauder functions (Bn,k) to show that the Brownian
bridge Y = (Yt)tâˆˆ[0,1] = (Wt âˆ’tW1)tâˆˆ[0,1] is a continuous, Gaussian process with
covariance function Cov[Yt, Ys] = (s âˆ§t) âˆ’st. Further, show that
PY = lim
Îµâ†“0 P
)
W âˆˆÂ· |W1 âˆˆ(âˆ’Îµ, Îµ)
*
.
â™£

21.5
Construction via L2-Approximation
543
Exercise 21.5.2 (Compare Example 8.32.) Fix T âˆˆ(0, 1). Use an orthonormal
basis b0,1, (cn,k), (dn,k) of suitably modiï¬ed Haar functions (such that the cn,k have
support [0, T ] and the dn,k have support [T, 1]) to show that a regular conditional
distribution of WT given W1 is deï¬ned by
P[WT âˆˆÂ· |W1 = x] = NT x,T .
â™£
Exercise 21.5.3 Deï¬ne Y := (Yt)tâˆˆ[0,1] by Y1 = 0 and
Yt = (1 âˆ’t)
 t
0
(1 âˆ’s)âˆ’1 dWs
for t âˆˆ[0, 1).
Show that Y is a Brownian bridge.
Hint: Show that Y is a continuous Gaussian process with the correct covariance
function. In particular, it has to be shown that limtâ†‘1 Yt = 0 almost surely. â™£
Exercise 21.5.4 Let d âˆˆN. Use a suitable orthonormal basis on [0, 1]d to show:
(i) There is a Gaussian process (Wt)tâˆˆ[0,1]d with covariance function
Cov[Wt, Ws] =
d

i=1

ti âˆ§si

.
(ii) There is a modiï¬cation of W such that t â†’Wt is almost surely continuous (see
Remark 21.7).
A process W with properties (i) and (ii) is called a Brownian sheet. â™£
Exercise 21.5.5 Consider the coefï¬cients (An)nâˆˆN0 of the Fourier basis of the
construction of Brownian motion. Show the following statements:
(i) âˆ
n=0 A2
n < âˆalmost surely.
(ii) âˆ
n=0 |An| = âˆalmost surely.
(iii) n
k=0 Ak, n âˆˆN converges almost surely.
Hint: Kolmogorovâ€™s three-series theorem (Theorem 15.51). â™£
Exercise 21.5.6 Let t âˆˆ(0, 1) and f0(x) := t as well as
fn(x) := 2 sin(nÏ€ t)
nÏ€
cos(nÏ€ x)
for n âˆˆN, x âˆˆ[0, 1].
Show that âˆ
n=0 fn(x) = 1[0,t](x) for x âˆˆ(0, 1) \ {t}. â™£

544
21
Brownian Motion
21.6
The Space C([0, âˆ))
Are functionals that depend on the whole path of a Brownian motion measurable?
For example, is sup{Xt, t âˆˆ[0, 1]} measurable? For general stochastic processes,
this is false since the supremum depends on more than countably many coordinates.
However, for processes with continuous paths, this is true, as we will show in this
section in a somewhat more general framework.
We may consider Brownian motion as the canonical process on the space Î© :=
C([0, âˆ)) of continuous paths.
We start by collecting some properties of the space Î© = C([0, âˆ)) âŠ‚R[0,âˆ).
Deï¬ne the evaluation map
Xt : Î© â†’R,
Ï‰ â†’Ï‰(t),
(21.27)
that is, the restriction of the canonical projection R[0,âˆ) â†’R to Î©.
For f, g âˆˆC

[0, âˆ)

and n âˆˆN, let dn(f, g) :=
;;;(f âˆ’g)
[0,n]
;;;
âˆâˆ§1 and
d(f, g) =
âˆ

n=1
2âˆ’n dn(f, g).
(21.28)
Theorem 21.30 d is a complete metric on Î© := C[0, âˆ) that induces the
topology of uniform convergence on compact sets. The space (Î©, d) is separable
and hence Polish.
Proof Clearly, every dn is a complete metric on (C([0, n]), âˆ¥Â· âˆ¥âˆ). Thus, for every
Cauchy sequence (fN) in (Î©, d) and every n âˆˆN, there exists a gn âˆˆÎ© with
dn(fN, gn)
Nâ†’âˆ
âˆ’â†’0. Evidently, gn(x) = gm(x) for every x â‰¤m âˆ§n; hence there
exists a g âˆˆÎ© with g(x) = gn(x) for every x â‰¤n for every n âˆˆN. Hence, clearly,
d(fN, g)
Nâ†’âˆ
âˆ’â†’0, and thus d is complete.
The set of polynomials with rational coefï¬cients is countable and by the
WeierstraÃŸ theorem, it is dense in any (C([0, n]), âˆ¥Â· âˆ¥âˆ); hence it is dense in
(Î©, d).
âŠ“âŠ”
Theorem 21.31 With respect to the Borel Ïƒ-algebra B(Î©, d), the canonical
projections Xt, t âˆˆ[0, âˆ) are measurable. On the other hand, the Xt generate
B(Î©, d). Hence
(B(R))âŠ—[0,âˆ)
Î© = Ïƒ

Xt, t âˆˆ[0, âˆ)

= B(Î©, d).
Proof The ï¬rst equation holds by deï¬nition. For the second one, we must show the
mutual inclusions.
â€œâŠ‚â€
Clearly, every Xt : Î© âˆ’â†’R is continuous and hence (B(Î©, d) â€“ B(R))-
measurable. Thus Ïƒ

Xt, t âˆˆ[0, âˆ)

âŠ‚B(Î©, d).

21.6
The Space C([0, âˆ))
545
â€œâŠƒâ€
We have to show that open subsets of (Î©, d) are in A := (B(R))âŠ—[0,âˆ).
Since (Î©, d) is separable (Theorem 21.30), every open set is a countable union of
Îµ-balls. Hence it sufï¬ces to show that for ï¬xed Ï‰0 âˆˆÎ©, the map Ï‰ â†’d(Ï‰0, Ï‰)
is A-measurable. To this end it is enough to show that for any n âˆˆN, the map
Ï‰ â†’Yn(Ï‰) := dn(Ï‰0, Ï‰) (see (21.28)) is A-measurable. However, the map
Ï‰ â†’Zt(Ï‰) := |Xt(Ï‰) âˆ’Xt(Ï‰0)| âˆ§1
is A-measurable. Since each Ï‰ is continuous, Yn is a countable supremum
Yn =
sup
tâˆˆ[0,n]âˆ©Q
Zt
and is hence A-measurable.
âŠ“âŠ”
In the following, let A := Ïƒ

Xt, t âˆˆ[0, âˆ)

.
Corollary 21.32 The map F1 : Î© â†’[0, âˆ), Ï‰ â†’sup{Ï‰(t) : t âˆˆ[0, 1]} is
A-measurable.
Proof F1 is continuous with respect to d and hence B(Î©, d)-measurable.
âŠ“âŠ”
If B is a Brownian motion (on some probability space ( 
Î©, 
A,P)), then there
exists an Î© âˆˆ
A with P) Î© * = 1 and B(Ï‰) âˆˆC([0, âˆ)) for every Ï‰ âˆˆÎ©. Let
A = 
A
Î© and P = PA. Then B : Î© âˆ’â†’C([0, âˆ)) is measurable with respect to
(A, A). With respect to the image measure P = P â—¦Bâˆ’1 on Î© = C([0, âˆ)), the
canonical process X = (Xt, t âˆˆ[0, âˆ)) on C([0, âˆ)) is a Brownian motion.
Deï¬nition 21.33 Let P be the probability measure on Î© = C([0, âˆ)) with respect
to which the canonical process X is a Brownian motion. Then P is called the Wiener
measure. The triple (Î©, A, P) is called the Wiener space, and X is called the
canonical Brownian motion or the Wiener process.
Remark 21.34 Sometimes we want a Brownian motion to start not at X0 = 0 but
at an arbitrary point x. Denote by Px that measure on C([0, âˆ)) for which 
X =
(Xt âˆ’x, t âˆˆ[0, âˆ)) is a Brownian motion (with 
X0 = 0). â™¦
Takeaways A continuous stochastic process can be considered as a random
variable with values in the space C([0, âˆ)) of continuous functions. Here
we have studied the properties of this space as a topological space and as a
measure space.
Exercise 21.6.1 Show that the map
Fâˆ: Î© â†’[0, âˆ],
Ï‰ â†’sup 	Ï‰(t) : t âˆˆ[0, âˆ)
,
is A-measurable. â™£

546
21
Brownian Motion
21.7
Convergence of Probability Measures on C([0, âˆ))
Let X and (Xn)nâˆˆN be random variables with values in C([0, âˆ)) (i.e., continuous
stochastic processes) with distributions PX and (PXn)nâˆˆN.
Deï¬nition 21.35 We say that the ï¬nite-dimensional distributions of (Xn) converge
to those of X if, for every k âˆˆN and t1, . . . , tk âˆˆ[0, âˆ), we have
(Xn
t1, . . . , Xn
tk) nâ†’âˆ
â‡’(Xt1, . . . , Xtk).
In this case, we write Xn
nâ†’âˆ
â‡’
fdd
X or PXn
nâ†’âˆ
âˆ’â†’
fdd
PX.
Lemma 21.36 Pn
nâ†’âˆ
âˆ’â†’
fdd
P and Pn
nâ†’âˆ
âˆ’â†’
fdd
Q imply P = Q.
Proof By Theorem 14.12(iii), the ï¬nite-dimensional distributions determine P
uniquely.
âŠ“âŠ”
Theorem 21.37 Weak convergence in M1(Î©, d) implies fdd-convergence:
Pn
nâ†’âˆ
âˆ’â†’P
â‡’
Pn
nâ†’âˆ
âˆ’â†’
fdd
P.
Proof Let k âˆˆN and t1, . . . , tk âˆˆ[0, âˆ). The map
Ï• : C([0, âˆ)) â†’Rk,
Ï‰ â†’(Ï‰(t1), . . . , Ï‰(tk))
is continuous. By the continuous mapping theorem (Theorem 13.25 on page 287),
we have Pn â—¦Ï•âˆ’1 nâ†’âˆ
âˆ’â†’P â—¦Ï•âˆ’1; hence Pn
nâ†’âˆ
âˆ’â†’
fdd
P.
âŠ“âŠ”
The converse statement in the preceding theorem does not hold. However, we
still have the following.
Theorem 21.38 Let (Pn)nâˆˆN and P be probability measures on C([0, âˆ)). Then
the following are equivalent:
(i) Pn
nâ†’âˆ
âˆ’â†’
fdd
P and (Pn)nâˆˆN is tight.
(ii) Pn
nâ†’âˆ
âˆ’â†’P weakly.
Proof â€œ(ii) â‡’(i)â€
This is a direct consequence of Prohorovâ€™s theorem (Theo-
rem 13.29 with E = C([0, âˆ))).
â€œ(i) â‡’(ii)â€
By Prohorovâ€™s theorem, (Pn)nâˆˆN is relatively sequentially compact.
Let Q be a limit point for (Pnk)kâˆˆN along some subsequence (nk). Then Pnk
fdd
âˆ’â†’
Q, k â†’âˆ. By Lemma 21.36, we have P = Q.
âŠ“âŠ”

21.7
Convergence of Probability Measures on C([0, âˆ))
547
Next we derive a useful criterion for tightness of sets {Pn} âŠ‚M1(C([0, âˆ))).
We start by recalling the ArzelÃ â€“Ascoli characterization of relatively compact sets
in C([0, âˆ)) (see, e.g., [37, Theorem 2.4.7] or [174, Theorem III.3]).
For N, Î´ > 0 and Ï‰ âˆˆC([0, âˆ)), let
V N(Ï‰, Î´) := sup
	
|Ï‰(t) âˆ’Ï‰(s)| : |t âˆ’s| â‰¤Î´, s, t â‰¤N

.
Theorem 21.39 (ArzelÃ â€“Ascoli) A set A âŠ‚C([0, âˆ)) is relatively compact if and
only if the following two conditions hold.
(i) {Ï‰(0), Ï‰ âˆˆA} âŠ‚R is bounded.
(ii) For every N, we have lim
Î´â†“0 sup
Ï‰âˆˆA
V N(Ï‰, Î´) = 0.
Theorem 21.40 A family (Pi, i âˆˆI) of probability measures on C([0, âˆ)) is
weakly relatively compact if and only if the following two conditions hold.
(i) (Pi â—¦Xâˆ’1
0 , i âˆˆI) is tight; that is, for every Îµ > 0, there is a K > 0 such that
Pi
	Ï‰ : |Ï‰(0)| > K
 â‰¤Îµ
for all i âˆˆI.
(21.29)
(ii) For all Î·, Îµ > 0 and N âˆˆN, there is a Î´ > 0 such that
Pi
	
Ï‰ : V N(Ï‰, Î´) > Î·


â‰¤Îµ
for all i âˆˆI.
(21.30)
Proof â€œ â‡’â€
By Prohorovâ€™s theorem (Theorem 13.29), weak relative compact-
ness of (Pi, i âˆˆI) implies tightness of this family. Thus, for every Îµ > 0, there
exists a compact set A âŠ‚C([0, âˆ)) with Pi(A) > 1 âˆ’Îµ for every i âˆˆI. Using the
ArzelÃ â€“Ascoli characterization of the compactness of A, we infer (i) and (ii).
â€œ â‡ â€
Now assume that (i) and (ii) hold. Then, for Îµ > 0 and k, N âˆˆN, choose
numbers KÎµ and Î´N,k,Îµ such that
sup
iâˆˆI
Pi
{Ï‰ : |Ï‰(0)| > KÎµ} â‰¤Îµ
2
and
sup
iâˆˆI
Pi
0
Ï‰ : V N(Ï‰, Î´N,k,Îµ) > 1
k
1
â‰¤2âˆ’Nâˆ’kâˆ’1 Îµ.
Deï¬ne
CN,Îµ =
0
Ï‰ : |Ï‰(0)| â‰¤KÎµ, V N(Ï‰, Î´N,k,Îµ) â‰¤1
k for all k âˆˆN
1
.

548
21
Brownian Motion
By the ArzelÃ â€“Ascoli theorem, CÎµ := 
NâˆˆN
CN,Îµ is relatively compact in C([0, âˆ))
and we have
Pi(Cc
Îµ) â‰¤Îµ
2 +
âˆ

k,N=1
Pi
	
Ï‰ : V N(Ï‰, Î´N,k,Îµ) > 1/k


â‰¤Îµ
for all i âˆˆI.
Hence the claim follows.
âŠ“âŠ”
Corollary 21.41 Let (Xi, i âˆˆI) and (Yi, i âˆˆI) be families of random variables in
C([0, âˆ)). Assume that (PXi, i âˆˆI) and (PYi, i âˆˆI) are tight. Then (PXi+Yi, i âˆˆ
I) is tight.
Proof Apply the triangle inequality in order to check (i) and (ii) in the preceding
theorem.
âŠ“âŠ”
The following is an important tool to check weak relative compactness.
Theorem 21.42 (Kolmogorovâ€™s criterion for weak relative compactness) Let
(Xi, i âˆˆI) be a sequence of continuous stochastic processes. Assume that the
following conditions are satisï¬ed.
(i) The family (P[Xi
0 âˆˆÂ·], i âˆˆI) of initial distributions is tight.
(ii) For any N > 0 there are numbers C, Î±, Î² > 0 such that, for all s, t âˆˆ[0, N]
and every i âˆˆI, we have
E
)
|Xi
s âˆ’Xi
t |Î±*
â‰¤C |s âˆ’t|Î²+1.
Then the family (PXi, i âˆˆI) = (L[Xi], i âˆˆI) of distributions of Xi is weakly
relatively compact in M1(C([0, âˆ))).
Proof We check the conditions of Theorem 21.40. The ï¬rst condition of Theo-
rem 21.40 is exactly (i).
Let N > 0. By the Kolmogorovâ€“Chentsov theorem (Theorem 21.6(ii)), for Îµ > 0
and Î³ âˆˆ(0, Î²/Î±), there exists a K such that, for every i âˆˆI, we have
P
)
|Xi
t âˆ’Xi
s| â‰¤K |t âˆ’s|Î³ for all s, t âˆˆ[0, N]
*
â‰¥1 âˆ’Îµ.
This clearly implies (21.30) with Î´ = (Î·/K)1/Î³ .
âŠ“âŠ”
Takeaways In many situations, stochastic processes in continuous time are
constructed as limits of simpler processes. In order to do, criteria for relative
compactness of probability measures on C([0, âˆ)) are needed. Particularly
helpful is a moment criterion that postulates that moments of increments over
small intervals decay quickly as the intervals get smaller.

21.8
Donskerâ€™s Theorem
549
21.8
Donskerâ€™s Theorem
Let Y1, Y2, . . . be i.i.d. random variables with E[Y1] = 0 and Var[Y1] = Ïƒ 2 > 0.
For t > 0, let Sn
t = âŒŠntâŒ‹
i=1 Yi and Sn
t =
1
âˆš
Ïƒ 2nSn
t . By the central limit theorem, for
t > s â‰¥0, we have L
)Sn
t âˆ’Sn
s
* nâ†’âˆ
âˆ’â†’N0,tâˆ’s.
Let B = (Bt, t â‰¥0) be a Brownian motion. Then
L
)Sn
t âˆ’Sn
s
* nâ†’âˆ
âˆ’â†’L[Bt âˆ’Bs]
for any t > s â‰¥0.
For N âˆˆN and 0 = t0 < t1 < . . . < tN, the random variables Sn
ti âˆ’Sn
tiâˆ’1, i =
1, . . . , N, are independent, and hence, we have
L
)
(Sn
t1 âˆ’Sn
t0, . . . ,Sn
tN âˆ’Sn
tNâˆ’1)
* nâ†’âˆ
âˆ’â†’L[(Bt1 âˆ’Bt0, . . . , BtN âˆ’BtNâˆ’1)].
We infer that
L)(Sn
t1, . . . ,Sn
tN )* nâ†’âˆ
âˆ’â†’L[(Bt1, . . . , BtN )].
(21.31)
We now deï¬ne Â¯Sn as Sn but linearly interpolated:
Â¯Sn
t =
1
âˆš
Ïƒ 2n
âŒŠntâŒ‹

i=1
Yi + tn âˆ’âŒŠtnâŒ‹
âˆš
Ïƒ 2n
YâŒŠntâŒ‹+1.
(21.32)
Then, for Îµ > 0,
P
)Sn
t âˆ’Â¯Sn
t
 > Îµ
*
â‰¤Îµâˆ’2 E
)
(Sn
t âˆ’Â¯Sn
t )2*
â‰¤
1
Îµ2n
1
Ïƒ 2 E[Y 2
1 ] =
1
Îµ2n
nâ†’âˆ
âˆ’â†’0.
By Slutzkyâ€™s theorem (Theorem 13.18), we thus have convergence of the ï¬nite-
dimensional distributions to the Wiener measure PW :
PÂ¯Sn
nâ†’âˆ
â‡’
fdd
PW.
(21.33)
The aim of this section is to strengthen this convergence statement to weak
convergence of probability measures on C([0, âˆ)). The main theorem of this
section is the functional central limit theorem, which goes back to Donsker [35].
Theorems of this type are also called invariance principles since the limiting
distribution is the same for all distributions Yi with expectation 0 and the same
variance.

550
21
Brownian Motion
Theorem 21.43 (Donskerâ€™s invariance principle) In the sense of weak conver-
gence on C([0, âˆ)), the distributions of Â¯Sn converge to the Wiener measure,
L[ Â¯Sn]
nâ†’âˆ
âˆ’â†’PW.
(21.34)
Proof Owing to (21.33) and Theorem 21.38, it is enough to show that (L[ Â¯Sn], n âˆˆ
N) is tight. To this end, we want to apply Kolmogorovâ€™s moment criterion. However,
as in the proof of existence of Brownian motion, second moments are not enough;
rather we need fourth moments in order that we can choose Î² > 0. Hence the
strategy is to truncate the Yi to obtain fourth moments.
For K > 0, deï¬ne
Y K
i
:= Yi 1{|Yi|â‰¤K/2} âˆ’E[Yi 1{|Yi|â‰¤K/2}]
and
ZK
i := Yi âˆ’Y K
i
for i âˆˆN.
Then E[Y K
i ] = E[ZK
i ] = 0 and Var[ZK
i ]
Kâ†’âˆ
âˆ’â†’
0 as well as Var[Y K
i ] â‰¤Ïƒ 2,
i âˆˆN. Clearly, |Y K
i | â‰¤K for every i. Deï¬ne
T K
n :=
n

i=1
Y K
i
and
UK
n :=
n

i=1
ZK
i
for n âˆˆN.
Let Â¯T K,n
t
and Â¯UK,n
t
be the linearly interpolated versions of
T K,n
t
:=
1
âˆš
Ïƒ 2n
T K
âŒŠntâŒ‹
and

UK,n
t
:=
1
âˆš
Ïƒ 2n
UK
âŒŠntâŒ‹
for t â‰¥0.
Evidently, Â¯Sn =
Â¯T K,n + Â¯UK,n. By Corollary 21.41, it is enough to show that,
for a sequence (Kn)nâˆˆN (chosen later), the families (L[ Â¯UKn,n], n âˆˆN) and
(L[ Â¯T Kn,n], n âˆˆN) are tight.
We consider ï¬rst the remainder term. As UK is a martingale, Doobâ€™s inequality
(Theorem 11.2) yields
P
+
sup
l=1,...,n
|UK
l | > Îµâˆšn
,
â‰¤Îµâˆ’2 Var)ZK
1
*
for every Îµ > 0.
Now, if Kn â†‘âˆ, n â†’âˆ, then for every N > 0, we have
P
+
sup
tâˆˆ[0,N]
 Â¯UKn,n
t
 > Îµ
,
â‰¤
N
Îµ2 Ïƒ 2 Var
)
ZKn
1
* nâ†’âˆ
âˆ’â†’0,
hence Â¯UKn,n
nâ†’âˆ
â‡’0 in C([0, âˆ)). In particular, (L[ Â¯UKn,n], n âˆˆN) is tight.

21.8
Donskerâ€™s Theorem
551
Next, for N > 0 and s, t âˆˆ[0, N], we compute the fourth moments of the
differences Â¯T Kn,n
t+s
âˆ’Â¯T Kn,n
s
for the main term. In the following, let Kn = n1/4. Fix
n âˆˆN. We distinguish two cases:
Case 1: t < nâˆ’1.
Let k := âŒŠ(t + s)nâŒ‹. If sn â‰¥k, then
Â¯T Kn,n
t+s
âˆ’Â¯T Kn,n
s
=
tn
âˆš
nÏƒ 2 Y Kn
k+1.
If sn < k, then
Â¯T Kn,n
t+s
âˆ’Â¯T Kn,n
s
=
1
âˆš
nÏƒ 2

((t + s)n âˆ’k)Y Kn
k+1 + (k âˆ’sn)Y Kn
k

.
In either case, we have
 Â¯T Kn,n
t+s
âˆ’Â¯T Kn,n
s
 â‰¤tâˆšn
Ïƒ

|Y Kn
k
| + |Y Kn
k+1|

,
hence
E
' Â¯T Kn,n
t+s
âˆ’Â¯T Kn,n
s
4(
â‰¤n2t4
Ïƒ 4 (2Kn)2 E
'
|Y Kn
1 | + |Y Kn
2 |
2(
â‰¤16n5/2t4
Ïƒ 4
Var)Y Kn
1
* â‰¤16
Ïƒ 2 t3/2.
(21.35)
Case 2: t â‰¥nâˆ’1.
Using the binomial theorem, we get (note that the mixed terms
with odd moments vanish since E)Y Kn
1
* = 0)
E)(T Kn
n )4* = n E)(Y Kn
1 )4* + 3n(n âˆ’1) E)(Y Kn
1 )2*2
â‰¤nK2
nÏƒ 2 + 3n(n âˆ’1)Ïƒ 4.
(21.36)
Note that, for independent real random variables X, Y with E[X] = E[Y] = 0
and E)X4*, E)Y 4* < âˆand for a âˆˆ[âˆ’1, 1], we have
E)(aX + Y)4* = a4 E)X4* + 6 a2 E)X2* E)Y 2* + E)Y 4*
â‰¤E)X4* + 6 E)X2* E)Y 2* + E)Y 4* = E[(X + Y)4].

552
21
Brownian Motion
We apply this twice (with a = (t + s)n âˆ’âŒŠ(t + s)nâŒ‹and a = âŒˆsnâŒ‰âˆ’sn) and obtain
(using the rough estimate âŒˆ(t + s)nâŒ‰âˆ’âŒŠsnâŒ‹â‰¤tn + 2 â‰¤3tn) from (21.36) (since
t â‰¤N)
E
)
( Â¯T Kn,n
t+s
âˆ’Â¯T Kn,n
s
)4*
â‰¤nâˆ’2 Ïƒ âˆ’4 E
)
(T Kn
âŒˆ(t+s)nâŒ‰âˆ’T Kn
âŒŠsnâŒ‹)4*
= nâˆ’2 Ïƒ âˆ’4 E)(T Kn
âŒˆ(t+s)nâŒ‰âˆ’âŒŠsnâŒ‹)4*
â‰¤3tnK2
n
n2 Ïƒ 2 + 18t2 =
3
Ïƒ 2 tnâˆ’1/2 + 18t2
â‰¤
3
Ïƒ 2 t3/2 + 18t2 â‰¤
 3
Ïƒ 2 + 18
âˆš
N

t3/2.
(21.37)
By (21.35) and (21.37), for every N > 0, there exists a C = C(N, Ïƒ 2) such that,
for every n âˆˆN and all s, t âˆˆ[0, N], we have
E
)
( Â¯T Kn,n
t+s
âˆ’Â¯T Kn,n
s
)4*
â‰¤C t3/2.
Hence, by Kolmogorovâ€™s moment criterion (Theorem 21.42 with Î± = 4 and Î² =
1/2), (L[ Â¯T Kn,n], n âˆˆN) is tight in M1(C([0, âˆ))).
âŠ“âŠ”
Takeaways Properly rescaled sums of i.i.d. centred random variables with
second moments converge to a normally distributed random variable. Using
the moment criterion, here we have shown that also the process of partial sums
converges and that the limit is Brownian motion. This is Donskerâ€™s theorem
that is known in the physics literature as the invariance principle.
Exercise 21.8.1 Let X1, X2, . . . be i.i.d. random variables with continuous distri-
bution function F. Let Gn : [0, 1] â†’R, t â†’nâˆ’1/2 n
i=1

1[0,t](F(Xi)) âˆ’t

and
Mn := âˆ¥Gnâˆ¥âˆ. Further, let M = suptâˆˆ[0,1] |Bt|, where B is a Brownian bridge.
(i) Show that E[Gn(t)] = 0 and Cov[Gn(s), Gn(t)] = s âˆ§t âˆ’st for s, t âˆˆ[0, 1].
(ii) Show that E[(Gn(t) âˆ’Gn(s))4] â‰¤C

(t âˆ’s)2 + |t âˆ’s|/n

for some C > 0.
(iii) Conclude that a suitable continuous version of Gn converges weakly to B. For
example, choose
Hn(t) = nâˆ’1/2
n

i=1

hn(F(Xi) âˆ’t) âˆ’gn(t)

,
where hn is a suitable smoothed version of 1(âˆ’âˆ,0], for example, hn(s) =
1 âˆ’(s/Îµn âˆ¨0) âˆ§1 for some sequence Îµn â†“0, and gn(t) :=
3 1
0 hn(t âˆ’u) du.
(iv) Finally, show that Mn
nâ†’âˆ
â‡’M.

21.9
Pathwise Convergence of Branching Processes
553
Remark: The distribution of M can be expressed by the Kolmogorovâ€“Smirnov
formula ([101] and [157]; see, e.g., [133])
P[M > x] = 2
âˆ

n=1
(âˆ’1)nâˆ’1 eâˆ’2n2x2.
(21.38)
Compare (21.21). Using the statistic Mn, one can test if random variables of a known
distribution are independent. Let X1, X2, . . . and
ËœX1, ËœX2, . . . be independent
random variables with unknown continuous distribution functions F and ËœF and with
empirical distribution functions Fn and ËœFn. Further, let
Dn := sup
tâˆˆR
|Fn(t) âˆ’ËœFn(t)|.
Under the assumption that F = ËœF holds, âˆšn/2 Dn converges in distribution to M.
This fact is the basis for nonparametric tests on the equality of distributions. â™£
21.9
Pathwise Convergence of Branching Processesâˆ—
In this section, we investigate the convergence of rescaled Galtonâ€“Watson processes
(branching processes). As for sums of independent random variables, we ï¬rst show
convergence for a ï¬xed time point to the distribution of a certain limiting process.
The next step is to show convergence of ï¬nite-dimensional distributions. Finally,
using Kolmogorovâ€™s moment criterion for tightness, we show convergence in the
path space C([0, âˆ)).
Consider a Galtonâ€“Watson process (Zn)nâˆˆN0 with geometric offspring distribu-
tion
p(k) = 2âˆ’kâˆ’1
for k âˆˆN0.
That is, let Xn,i, n, i âˆˆN0 be i.i.d. random variables on N0 with P[Xn,i = k] =
p(k), k âˆˆN0, and based on the initial state Z0 deï¬ne inductively
Zn+1 =
Zn

i=1
Xn,i.
Thus Z is a Markov chain with transition probabilities p(i, j) = pâˆ—i(j), where pâˆ—i
is the ith convolution power of p. In other words, if Z, Z1, . . . , Zi are independent
copies of our Galtonâ€“Watson process, with Z0 = i and Z1
0 = . . . = Zi
0 = 1, then
Z D= Z1 + . . . + Zi.
(21.39)

554
21
Brownian Motion
We consider now the probability generating function of X1,1, Ïˆ(1)(s) := Ïˆ(s) :=
E[sX1,1], s âˆˆ[0, 1]. Denote by Ïˆ(n) := Ïˆ(nâˆ’1) â—¦Ïˆ its nth iterate for n âˆˆN. Then,
by Lemma 3.10,
Ei[sZn] = E1[sZn]i =

Ïˆ(n)(s)
i
.
For the geometric offspring distribution, Ïˆ(n) can be computed explicitly.
Lemma 21.44 For the branching process with critical geometric offspring distri-
bution, the nth iterate of the probability generating function is
Ïˆ(n)(s) = n âˆ’(n âˆ’1)s
n + 1 âˆ’ns .
Proof Compute
Ïˆ(s) =
âˆ

k=0
2âˆ’kâˆ’1 sk =
1
âˆ’s + 2.
In order to compute the iterated function, ï¬rst consider general linear rational
functions of the form f (x) = ax+b
cx+d . For such f , deï¬ne the matrix Mf =
a b
c d

.
For two linear rational functions f and g, we have Mf â—¦g = Mf Â· Mg. The powers
of M are easy to compute:
MÏˆ =
 0 1
âˆ’1 2

,
M2
Ïˆ =
âˆ’1 2
âˆ’2 3

,
M3
Ïˆ =
âˆ’2 3
âˆ’3 4

,
and inductively
Mn
Ïˆ =

âˆ’(n âˆ’1)
n
âˆ’n
n + 1

.
âŠ“âŠ”
If we let s = eâˆ’Î», then we get the Laplace transform of Zn,
Ei[eâˆ’Î»Zn] = Ïˆ(n)(eâˆ’Î»)i.
By Example 6.29, we can compute the moments of Zn by differentiating the Laplace
transform. That is, we obtain the following lemma.
Lemma 21.45 The moments of Zn are
Ei[Zk
n] = (âˆ’1)k dk
dÎ»k

Ïˆ(n)(eâˆ’Î»)i

Î»=0
.
(21.40)

21.9
Pathwise Convergence of Branching Processes
555
In particular, the ï¬rst six moments are
Ei[Zn] = i,
Ei[Z2
n] = 2i n + i2,
Ei[Z3
n] = 6i n2 + 6i2 n + i3,
Ei[Z4
n] = 24i n3 + 36i2 n2 + (12i3 + 2i) n + i4,
(21.41)
Ei[Z5
n] = 120i n4 + 240i2 n3 + (120i3 + 30i) n2 + (20i4 + 10i2) n + i5,
Ei[Z6
n] = 720i n5 + 1800i2 n4 + (1200i3 + 360i) n3,
+ (300i4 + 240i2)n2 + (30i5 + 30i3 + 2i)n + i6.
Hence, Z is a martingale, and the ï¬rst six centered moments are
Ei[(Zn âˆ’i)2] = 2i n,
Ei[(Zn âˆ’i)3] = 6i n2,
Ei[(Zn âˆ’i)4] = 24i n3 + 12i2 n2 + 2i n,
Ei[(Zn âˆ’i)5] = 120i n4 + 120i2 n3 + 30i n2,
Ei[(Zn âˆ’i)6] = 720i n5 + 1080i2 n4 + (120i3 + 360i) n3 + 60i2n2 + 2i n.
(21.42)
Proof The exact formulas for the ï¬rst six moments are obtained by tenaciously
computing the right-hand side of (21.40).
âŠ“âŠ”
Now consider the following rescaling: Fix x â‰¥0, start with Z0 = âŒŠnxâŒ‹
individuals and consider ËœZn
t := ZâŒŠtnâŒ‹
n
for t â‰¥0. We abbreviate
Lx[ ËœZn] := LâŒŠnxâŒ‹
)(nâˆ’1ZâŒŠntâŒ‹)tâ‰¥0
*.
(21.43)

556
21
Brownian Motion
Evidently, Ex[ ËœZn
t ] = âŒŠnxâŒ‹
n
â‰¤x for every n; hence (Lx[ ËœZn
t ], n âˆˆN) is tight. By
considering Laplace transforms, we obtain that, for every Î» â‰¥0, the sequence of
distributions converges:
lim
nâ†’âˆEx[eâˆ’Î» ËœZn
t ] = lim
nâ†’âˆ

Ïˆ(âŒŠtnâŒ‹)(eâˆ’Î»/n)
nx
= lim
nâ†’âˆ
nt âˆ’(nt âˆ’1)eâˆ’Î»/n
nt + 1 âˆ’nt eâˆ’Î»/n
nx
= lim
nâ†’âˆ

1 âˆ’
1 âˆ’eâˆ’Î»/n
n(1 âˆ’eâˆ’Î»/n)t + 1
nx
= exp

âˆ’lim
nâ†’âˆ
x n(1 âˆ’eâˆ’Î»/n)
n(1 âˆ’eâˆ’Î»/n)t + 1

= exp

âˆ’
Î»
Î» + 1/t (x/t)

:= Ïˆt(Î»)x.
(21.44)
However, the function Ïˆx
t
is the Laplace transform of the compound Poisson
distribution CPoi(x/t) exp1/t (see Deï¬nition 16.3).
Consider the stochastic kernel Îºt(x, dy) := CPoi(x/t) exp1/t (dy). This is the
kernel on [0, âˆ) whose Laplace transform is given by
 âˆ
0
Îºt(x, dy) eâˆ’Î»y = Ïˆt(Î»)x.
(21.45)
Lemma 21.46 (Îºt)tâ‰¥0 is a Markov semigroup and there exists a Markov process
(Yt)tâ‰¥0 with transition kernels Px[Yt âˆˆdy] = Îºt(x, dy).
Proof It sufï¬ces to check that the Chapmanâ€“Kolmogorov equation Îºt Â· Îºs
=
Îºs+t holds. We compute the Laplace transform for these kernels. For Î» â‰¥0,
applying (21.45) twice yields
 
Îºt(x, dy)Îºs(y, dz) eâˆ’Î»z =

Îºt(x, dy) exp

âˆ’
Î»y
Î»s + 1

= exp

âˆ’
Î»
Î»s+1
Î»
Î»s+1t + 1
x

= exp

âˆ’
Î»x
Î»(t + s) + 1

=

Îºt+s(x, dz) eâˆ’Î»z.
âŠ“âŠ”
Next we show that Y has a continuous version. To this end, we compute some of
its moments and then use the Kolmogorovâ€“Chentsov theorem (Theorem 21.6).

21.9
Pathwise Convergence of Branching Processes
557
Lemma 21.47 The ï¬rst k moments of Yt can be computed by differentiating the
Laplace transform,
Ex[Y k
t ] = (âˆ’1)k dk
dÎ»k

Ïˆ(Î»)x
Î»=0
,
where Ïˆt(Î») = exp

âˆ’
Î»
Î»t+1

. In particular, we have
Ex[Yt ] = x,
Ex[Y 2
t ] = 2x t + x2,
Ex[Y 3
t ] = 6x t2 + 6x2 t + x3,
Ex[Y 4
t ] = 24x t3 + 36x2 t2 + 12x3 t + x4,
Ex[Y 5
t ] = 120x t4 + 240x2 t3 + 120x3 t2 + 20x4 t + x5,
Ex[Y 6
t ] = 720x t5 + 1800x2 t4 + 1200x3 t3 + 300x4 t2 + 30x5 t + x6.
(21.46)
Hence Y is a martingale, and the ï¬rst centered moments are
Ex[(Yt âˆ’x)2] = 2x t,
Ex[(Yt âˆ’x)3] = 6x t2,
Ex[(Yt âˆ’x)4] = 24x t3 + 12x2 t2,
Ex[(Yt âˆ’x)5] = 120x t4 + 120x2 t3,
Ex[(Yt âˆ’x)6] = 720x t5 + 1080x2 t4 + 120x3 t3.
(21.47)
Theorem 21.48 There is a continuous version of the Markov process Y with tran-
sition kernels (Îºt)tâ‰¥0 given by (21.45). This version is called Fellerâ€™s (continuous)
branching diffusion.
See Fig. 26.4 for a computer simulation of Fellerâ€™s branching diffusion.
Proof For ï¬xed N > 0 and s, t âˆˆ[0, N], we have
Ex
)
(Yt+s âˆ’Ys)4*
= Ex
)
EYs[(Yt âˆ’Y0)4]
*
= Ex
)
24Ys t3 + 12Y 2
s t2*
= 24x t3 + 12(2sx + x2) t2 â‰¤

48Nx + 12x2
t2.
Thus Y satisï¬es the condition of Theorem 21.6 (Kolmogorovâ€“Chentsov)with Î± = 4
and Î² = 1.
âŠ“âŠ”

558
21
Brownian Motion
Remark 21.49
(i) By using higher moments, it can be shown that the paths of Y are HÃ¶lder-
continuous of any order Î³ âˆˆ(0, 1
2).
(ii) It can be shown that Y is the (unique strong) solution of the stochastic (ItÃ´-)
differential equation (see Examples 26.11 and 26.31)
dYt =
2
2Yt dWt,
(21.48)
where W is a Brownian motion. â™¦
Theorem 21.50 We have Lx[ ËœZn] nâ†’âˆ
âˆ’â†’
fdd
Lx[Y].
Proof As in (21.44) for 0 â‰¤t1 â‰¤t2, Î»1, Î»2 â‰¥0 and x â‰¥0, we get
lim
nâ†’âˆEx
+
eâˆ’

Î»1 ËœZn
t1+Î»2 ËœZn
t2
,
= lim
nâ†’âˆEx
'
Ex
'
eâˆ’Î»2 ËœZn
t2
 ËœZn
t1
(
eâˆ’Î»1 ËœZn
t1
(
= lim
nâ†’âˆEx
+
exp

âˆ’
Î»2
Î»2(t2 âˆ’t1) + 1
ËœZn
t1

eâˆ’Î»1 ËœZn
t1
,
= exp
â›
ââˆ’

Î»2
Î»2(t2âˆ’t1)+1 + Î»1

x

Î»2
Î»2(t2âˆ’t1)+1 + Î»1

t1 + 1
â
â 
= Ex
)
exp(âˆ’(Î»1Yt1 + Î»2Yt2))
*
.
Hence, we obtain
Lx
)
Î»1 ËœZn
t1 + Î»2 ËœZn
t2
* nâ†’âˆ
âˆ’â†’Lx
)
Î»1Yt1 + Î»2Yt2
*
.
Using the CramÃ©râ€“Wold device (Theorem 15.57), this implies
Lx
) ËœZn
t1, ËœZn
t2
* nâ†’âˆ
âˆ’â†’Lx
)
Yt1, Yt2
*
.
Iterating the argument, for every k âˆˆN and 0 â‰¤t1 â‰¤t2 â‰¤. . . â‰¤tk, we get
Lx
) ËœZn
ti

i=1,...,k
* nâ†’âˆ
âˆ’â†’Lx
)
Yti

i=1,...,k
*
.
However, this was the claim.
âŠ“âŠ”
The ï¬nal step is to show convergence in path space. To this end, we have
to modify the rescaled processes so that they become continuous. Assume that

21.9
Pathwise Convergence of Branching Processes
559
(Zn
i )iâˆˆN0, n âˆˆN is a sequence of Galtonâ€“Watson processes with Zn
0 = âŒŠnxâŒ‹. Deï¬ne
the linearly interpolated processes
Â¯Zn
t :=

t âˆ’nâˆ’1âŒŠtnâŒ‹
 
Zn
âŒŠtnâŒ‹+1 âˆ’Zn
âŒŠtnâŒ‹

+ 1
nZn
âŒŠtnâŒ‹.
Theorem 21.51 (Lindvall (1972), see [109]) As n â†’âˆ, in the sense of weak con-
vergence in M1(C([0, âˆ))), the rescaled Galtonâ€“Watson processes Â¯Zn converge to
Fellerâ€™s diffusion Y:
Lx[ Â¯Zn]
nâ†’âˆ
âˆ’â†’Lx[Y].
Proof We have shown already the convergence of the ï¬nite-dimensional distribu-
tions. By Theorem 21.38, it is thus enough to show tightness of (Lx[ Â¯Zn], n âˆˆ
N) in M1(C([0, âˆ))). To this end, we apply Kolmogorovâ€™s moment criterion
(Theorem 21.42 with Î± = 4 and Î² = 1). Hence, for ï¬xed N > 0, we compute
the fourth moments Ex
)( Â¯Zn
t+s âˆ’Â¯Zn
s )4* for s, t âˆˆ[0, N]. We distinguish two cases:
Case 1: t < 1
n.
Let k = âŒŠ(t + s)nâŒ‹. First assume that âŒŠsnâŒ‹= k. Then (by
Lemma 21.45)
Ex
)( Â¯Zn
t+s âˆ’Â¯Zn
s )4* = nâˆ’4(tn)4 EâŒŠnxâŒ‹
)(Zn
k+1 âˆ’Zn
k )4*
= t4 EâŒŠnxâŒ‹
)24Zn
k + 12(Zn
k)2 + 2Zn
k
*
= t4 
26âŒŠnxâŒ‹+ 24âŒŠnxâŒ‹k + âŒŠnxâŒ‹2
â‰¤26x t3 + 24xs t2 + x2 t2
â‰¤(50Nx + x2) t2.
In the case âŒŠsnâŒ‹= k âˆ’1, we get a similar estimate. Therefore, there is a constant
C = C(N, x) such that
Ex
)
( Â¯Zn
s+t âˆ’Â¯Zn
s )4*
â‰¤C t2
for all s, t âˆˆ[0, N] with t < 1
n.
(21.49)

560
21
Brownian Motion
Case 2: t â‰¥1
n.
Deï¬ne k := âŒˆ(t + s)nâŒ‰âˆ’âŒŠsnâŒ‹â‰¤tn + 1 â‰¤2tn. Then (by
Lemma 21.45)
Ex
)
( Â¯Zn
t+s âˆ’Â¯Zn
s )4*
â‰¤nâˆ’4EâŒŠnxâŒ‹
)
(Zn
âŒŠ(t+s)nâŒ‹âˆ’Zn
âŒŠsnâŒ‹)4*
= nâˆ’4EâŒŠnxâŒ‹
)
EZn
âŒŠsnâŒ‹[(Zn
k âˆ’Zn
0)4]
*
= nâˆ’4EâŒŠnxâŒ‹
'
24Zn
âŒŠsnâŒ‹k3 + 12(Zn
âŒŠsnâŒ‹)2k2 + 2Zn
âŒŠsnâŒ‹k
(
â‰¤nâˆ’4 
24xn(2tn)3 + (24xn sn + 12x2n2)(2tn)2 + 4xtn2
â‰¤192xt3 + (96xs + 48x2)t2 + 4xnâˆ’1t2
â‰¤(292Nx + 48x2) t2.
(21.50)
Combining the estimates (21.49) and (21.50), the assumptions of Kolmogorovâ€™s
moment criterion for tightness (Theorem 21.42) are fulï¬lled with Î± = 4 and Î² = 1.
Hence the sequence (Lx[ Â¯Zn], n âˆˆN) is tight.
âŠ“âŠ”
Takeaways Branching processes with very large populations undergo only
small relative changes in each generation. By a proper rescaling of time and
population size, we get a continuous limiting process (Lindvallâ€™s theorem).
The details are rather technical as the computation of many moments is
necessary.
21.10
Square Variation and Local Martingales
By the Paleyâ€“Wiener-Zygmund theorem (Theorem 21.17), the paths t â†’Wt
of Brownian motion are almost surely nowhere differentiable and hence have
locally inï¬nite variation. In particular, the stochastic integral
3 1
0 f (s) dWs that we
introduced in Example 21.29 cannot be understood as a Lebesgueâ€“Stieltjes integral.
However, as a preparation for the construction of integrals of this type for larger
classes of integrands and integrators (in Chap. 25), here we investigate the path
properties of Brownian motion and, somewhat more generally, of continuous local
martingales in more detail.

21.10
Square Variation and Local Martingales
561
Deï¬nition 21.52 Let G : [0, âˆ) â†’R be a continuous function. For any t â‰¥0,
deï¬ne the variation up to t by
V 1
t (G) := sup
0 nâˆ’1

i=0
Gti+1 âˆ’Gti
 : 0 = t0 â‰¤t1 â‰¤. . . â‰¤tn = t, n âˆˆN
1
.
We say that G has locally ï¬nite variation if V 1
t (G) < âˆfor all t â‰¥0. We write
Cv for the vector space of continuous functions G with continuous variation t â†’
V 1
t (G).
Remark 21.53 Clearly, V 1(F + G) â‰¤V 1(F) + V 1(G) and V 1(Î±G) = |Î±| V 1(G)
for all continuous F, G : [0, âˆ) â†’R and for all Î± âˆˆR. Hence Cv is indeed a
vector space. â™¦
Remark 21.54
(i) If G is of the form Gt =
3 t
0 f (s) ds for some locally integrable function f ,
then we have G âˆˆCv with V 1
t (G) =
3 t
0 |f (s)| ds.
(ii) If G = G+ âˆ’Gâˆ’is the difference of two continuous monotone increasing
functions G+ and Gâˆ’, then
V 1
t (G) âˆ’V 1
s (G) â‰¤(G+
t âˆ’G+
s ) + (Gâˆ’
t âˆ’Gâˆ’
s )
for all t > s,
(21.51)
hence we have G âˆˆCv. In (21.51), equality holds if Gâˆ’and G+ â€œdo not grow
on the same setsâ€; that is, more formally, if Gâˆ’and G+ are the distribution
functions of mutually singular measures Î¼âˆ’and Î¼+. The measures Î¼âˆ’and Î¼+
are then the Jordan decomposition of the signed measure Î¼ = Î¼+ âˆ’Î¼âˆ’whose
distribution function is G. Then the Lebesgueâ€“Stieltjes integral is deï¬ned by
 t
0
F(s) dGs :=

[0,t]
F dÎ¼+ âˆ’

[0,t]
F dÎ¼âˆ’.
(21.52)
(iii) If G âˆˆCv, then clearly
G+
t := 1
2

V 1
t (G) + Gt

and
Gâˆ’
t := 1
2

V 1
t (G) âˆ’Gt

is a decomposition of G as in (ii). â™¦
The fact that the paths of Brownian motion are nowhere differentiable can be used
to infer that the paths have inï¬nite variation. However, there is also a simple direct
argument.
Theorem 21.55 Let W be a Brownian motion. Then V 1
t (W) = âˆalmost surely
for every t > 0.

562
21
Brownian Motion
Proof It is enough to consider t = 1 and to show
Yn :=
2n

i=1
Wi2âˆ’n âˆ’W(iâˆ’1)2âˆ’n
 nâ†’âˆ
âˆ’â†’âˆ
a.s.
(21.53)
We have E[Yn] = 2n/2 E[|W1|] = 2n/2âˆš2/Ï€ and Var[Yn] = 1 âˆ’2/Ï€. By
Chebyshevâ€™s inequality,
âˆ

n=1
P
'
Yn â‰¤1
2 2n/22
2/Ï€
(
â‰¤
âˆ

n=1
2Ï€ âˆ’4
2n
= 2Ï€ âˆ’4 < âˆ.
Using the Borelâ€“Cantelli lemma, this implies (21.53).
âŠ“âŠ”
Evidently, the variation is too crude a measure to quantify essential path properties
of Brownian motion. Hence, instead of the increments (in the deï¬nition of the
variation), we will sum up the (smaller) squared increments. For the deï¬nition of
this square variation, more care is needed than in Deï¬nition 21.52 for the variation.
Deï¬nition 21.56 A sequence P = (Pn)nâˆˆN of countable subsets of [0, âˆ),
Pn := {t0, t1, t2, . . .}
with 0 = t0 < t1 < t2 < . . . ,
is called an admissible partition sequence if
(i) P1 âŠ‚P2 âŠ‚. . .,
(ii) sup Pn = âˆfor every n âˆˆN, and
(iii) the mesh size
|Pn| := sup
tâˆˆPn
min
sâˆˆPn, sÌ¸=t |s âˆ’t|
tends to 0 as n â†’âˆ.
If 0 â‰¤S < T , then deï¬ne
Pn
S,T := Pn âˆ©[S, T )
and
Pn
T := Pn âˆ©[0, T ).
If t = tk âˆˆPn
T , then let tâ€² := tk+1 âˆ§T = min
	
s âˆˆPn
T âˆª{T } : s > t

.
Example 21.57 Pn = {k2âˆ’n : k = 0, 1, 2, . . .}. â™¦
Deï¬nition 21.58 For continuous F, G : [0, âˆ) â†’R and for p â‰¥1, deï¬ne the
p-variation of G (along P) by
V p
T (G) := V P,p
T
(G) := lim
nâ†’âˆ

tâˆˆPn
T
Gtâ€² âˆ’Gt
p
for T â‰¥0

21.10
Square Variation and Local Martingales
563
if the limit exists. In particular, âŸ¨GâŸ©:= V 2(G) is called the square variation of G.
If T â†’V 2
T (G) is continuous, then we write G âˆˆCqv := CP
qv.
If, for every T â‰¥0, the limit
V P,2
T
(F, G) := lim
nâ†’âˆ

tâˆˆPn
T

Ftâ€² âˆ’Ft

Gtâ€² âˆ’Gt

exists, then we call âŸ¨F, GâŸ©:= V 2(F, G) := V P,2(F, G) the quadratic covariation
of F and G (along P).
Remark 21.59 If pâ€² > p and V p
T (G) < âˆ, then V pâ€²
T (G) = 0. In particular, we
have âŸ¨GâŸ©â‰¡0 if G has locally ï¬nite variation. â™¦
Remark 21.60 By the triangle inequality, we have

tâˆˆPn+1
T
Gtâ€² âˆ’Gt
 â‰¥

tâˆˆPn
T
Gtâ€² âˆ’Gt

for all n âˆˆN, T â‰¥0.
Hence in the case p = 1, the limit always exists and coincides with V 1(G) from
Deï¬nition 21.52 (and is hence independent of the particular choice of P). A similar
inequality does not hold for V 2 and thus the limit need not exist or may depend
on the choice of P. In the following, we will, however, show that, for a large
class of continuous stochastic processes, V 2 exists almost surely along a suitable
subsequence of partitions and is almost surely unique. â™¦
Remark 21.61
(i) If âŸ¨F + GâŸ©T and âŸ¨F âˆ’GâŸ©T exist, then the covariation âŸ¨F, GâŸ©T exists and the
polarization formula holds:
âŸ¨F, GâŸ©T = 1
4
âŸ¨F + GâŸ©T âˆ’âŸ¨F âˆ’GâŸ©T
.
(ii) If âŸ¨FâŸ©T , âŸ¨GâŸ©T and âŸ¨F, GâŸ©T exist, then by the Cauchyâ€“Schwarz inequality, we
have for the approximating sums
V 1
T (âŸ¨F, GâŸ©) â‰¤
2
âŸ¨FâŸ©T âŸ¨GâŸ©T .
â™¦
Remark 21.62 If f âˆˆC1(R) and G âˆˆCqv, then (exercise!) in the sense of the
Lebesgueâ€“Stieltjes integral
âŸ¨f (G)âŸ©T =
 T
0
(f â€²(Gs))2 dâŸ¨GâŸ©s.
â™¦
Corollary 21.63 If F has locally ï¬nite square variation and if âŸ¨GâŸ©â‰¡0 (hence, in
particular, if G has locally ï¬nite variation), then âŸ¨F, GâŸ©â‰¡0 and âŸ¨F + GâŸ©= âŸ¨FâŸ©.

564
21
Brownian Motion
Theorem 21.64 For Brownian motion W and for every admissible sequence of
partitions, we have
âŸ¨WâŸ©T = T
for all T â‰¥0
a.s.
Proof We prove this only for the case where
âˆ

n=1
|Pn| < âˆ.
(21.54)
For the general case, we only sketch the argument.
Accordingly, assume (21.54). If âŸ¨WâŸ©exists, then T
â†’âŸ¨WâŸ©T is monotone
increasing. Hence, it is enough to show that âŸ¨WâŸ©T exists for every T âˆˆQ+ =
Q âˆ©[0, âˆ) and that almost surely âŸ¨WâŸ©T = T . Since ( 
Wt)tâ‰¥0 =

T âˆ’1/2WtT

tâ‰¥0 is
a Brownian motion, and since âŸ¨
WâŸ©1 = T âˆ’1âŸ¨WâŸ©T , it is enough to consider the case
T = 1.
Deï¬ne
Yn :=

tâˆˆPn
1
(Wtâ€² âˆ’Wt)2
for all n âˆˆN.
Then E[Yn] = 
tâˆˆPn
1 (tâ€² âˆ’t) = 1 and
Var[Yn] =

tâˆˆPn
1
Var
)
(Wtâ€² âˆ’Wt)2*
= 2

tâˆˆPn
1
(tâ€² âˆ’t)2 â‰¤2 |Pn|.
By assumption (21.54), we thus have âˆ
n=1 Var[Yn] â‰¤2 âˆ
n=1 |Pn| < âˆ; hence
Yn
nâ†’âˆ
âˆ’â†’1 almost surely.
If we drop the assumption (21.54), then we still have Var[Yn]
nâ†’âˆ
âˆ’â†’0; hence
Yn
nâ†’âˆ
âˆ’â†’
1 in probability. However, it is not too hard to show that (Yn)nâˆˆN is a
backwards martingale (see, e.g., [140, Theorem I.28]) and thus converges almost
surely to 1.
âŠ“âŠ”
Corollary 21.65 If W and 
W are independent Brownian motions, then we have
âŸ¨W, 
WâŸ©T = 0.
Proof The continuous processes ((W + 
W)/
âˆš
2 ) and (W âˆ’
W)/
âˆš
2 ) have inde-
pendent normally distributed increments. Hence they are Brownian motions. By
Remark 21.61(i), we have
4
B
W, 
W
C
T =
B
W + 
W
C
T âˆ’
B
W âˆ’
W
C
T
= 2
B
(W + 
W)/
âˆš
2
C
T âˆ’2
B
(W âˆ’
W)/
âˆš
2
C
T = 2T âˆ’2T = 0.
âŠ“âŠ”

21.10
Square Variation and Local Martingales
565
Clearly, (Wt 
Wt )tâ‰¥0 is a continuous martingale. Now, by Exercise 21.4.2, the
process (W 2
t âˆ’t)tâ‰¥0 is also a continuous martingale. Thus, as shown above,
the processes W 2 âˆ’âŸ¨WâŸ©and W 
W âˆ’âŸ¨W, 
WâŸ©are martingales. We will see
(Theorem 21.70) that the square variation âŸ¨M(Ï‰)âŸ©of a square integrable continuous
martingale M always exists (for almost all Ï‰) and that the process âŸ¨MâŸ©is uniquely
determined by the property that M2 âˆ’âŸ¨MâŸ©is a martingale.
In order to obtain a similar statement for continuous martingales that are not
square integrable, we make the following deï¬nition.
Deï¬nition 21.66 (Local martingale) Let F be a ï¬ltration on (Î©, F, P) and let Ï„
be an F-stopping time. An adapted real-valued stochastic process M = (Mt)tâ‰¥0 is
called a local martingale up to time Ï„ if there exists a sequence (Ï„n)nâˆˆN of stopping
times such that Ï„n â†‘Ï„ almost surely and such that, for every n âˆˆN, the stopped
process MÏ„n = (MÏ„nâˆ§t)tâ‰¥0 is a uniformly integrable martingale. Such a sequence
(Ï„n)nâˆˆN is called a localising sequence for M. M is called a local martingale if M
is a local martingale up to time Ï„ â‰¡âˆ. Denote by Mloc,c the space of continuous
local martingales.
Remark 21.67 Let M be a continuous adapted process and let Ï„ be a stopping time.
Then the following are equivalent:
(i) M is a local martingale up to time Ï„.
(ii) There is a sequence (Ï„n)nâˆˆN of stopping times with Ï„n â†‘Ï„ almost surely and
such that every MÏ„n is a martingale.
(iii) There is a sequence (Ï„n)nâˆˆN of stopping times with Ï„n â†‘Ï„ almost surely and
such that every MÏ„n is a bounded martingale.
Indeed, (iii) â‡’(i) â‡’(ii) is trivial. Hence assume that (ii) holds, and deï¬ne Ï„ â€²
n
by
Ï„ â€²
n := inf{t â‰¥0 : |Mt| â‰¥n}
for all n âˆˆN.
Since M is continuous, we have Ï„ â€²
n â†‘âˆ. Hence (Ïƒn)nâˆˆN := (Ï„n âˆ§Ï„ â€²
n)nâˆˆN is a
localising sequence for M such that every MÏƒn is a bounded martingale. â™¦
Remark 21.68 A bounded local martingale M is a martingale. Indeed, assume that
|Mt| â‰¤C < âˆalmost surely for all t â‰¥0 and that (Ï„n)nâˆˆN is a localising
sequence for M. Let t > s â‰¥0 and A âˆˆFs. Then A âˆ©{Ï„n > s} âˆˆFÏ„nâˆ§s and hence
E
)
MÏ„nâˆ§t 1Aâˆ©{Ï„n>s}
*
= E
)
MÏ„nâˆ§s 1Aâˆ©{Ï„n>s}
*
.
Since Ï„n â†‘âˆ, the dominated convergence theorem (Corollary 6.26) yields
E
)
Mt 1A
*
= E
)
Ms 1A
*
.
Hence E[Mt |Fs] = Ms and thus M is a martingale. â™¦

566
21
Brownian Motion
Example 21.69
(i) Every martingale is a local martingale.
(ii) In Remark 21.68, we saw that bounded local martingales are martingales. On
the other hand, even a uniformly integrable local martingale need not be a
martingale: Let W = (W 1, W 2, W 3) be a three-dimensional Brownian motion
(that is, W 1, W 2 and W 3 are independent Brownian motions) that starts at
W0 = x âˆˆR3 \ {0}. Let
u(y) = âˆ¥yâˆ¥âˆ’1
for y âˆˆR3 \ {0}.
It is easy to check that u is harmonic; that is, â–³u(y) = 0 for all y Ì¸= 0. We will see
later (Corollary 25.34) that this implies that M := (u(Wt))tâ‰¥0 is a local martingale.
Deï¬ne a localising sequence for M by
Ï„n := inf
	
t > 0 : Mt â‰¥n

= inf
	
t > 0 : âˆ¥Wtâˆ¥â‰¤1/n

,
n âˆˆN.
An explicit computation with the three-dimensional normal distribution shows
E[Mt] â‰¤tâˆ’1/2
tâ†’âˆ
âˆ’â†’
0; hence M is integrable but is not a martingale. Since
Mt
tâ†’âˆ
âˆ’â†’0 in L1, M is uniformly integrable. â™¦
Theorem 21.70 Let M be a continuous local martingale.
(i) There exists a unique continuous, monotone increasing, adapted process
âŸ¨MâŸ©= (âŸ¨MâŸ©t)tâ‰¥0 with âŸ¨MâŸ©0 = 0 such that
M2
t âˆ’âŸ¨MâŸ©t

tâ‰¥0
is a continuous local martingale.
(ii) If M is a continuous square integrable martingale, then M2 âˆ’âŸ¨MâŸ©is a
martingale.
(iii) For every admissible sequence of partitions P = (Pn)nâˆˆN, we have
Un
T :=

tâˆˆPn
T
Mtâ€² âˆ’Mt
2 nâ†’âˆ
âˆ’â†’âŸ¨MâŸ©T
in probability
for all T â‰¥0.
The process âŸ¨MâŸ©is called the square variation process of M.
Remark 21.71 By possibly passing in (iii) to a subsequence Pâ€² (that might depend
on T ), we may assume that Un
T
nâ†’âˆ
âˆ’â†’
âŸ¨MâŸ©T almost surely. Using the diagonal
sequence argument, we obtain (as in the proof of Hellyâ€™s theorem) a sequence of
partitions such that Un
T
nâ†’âˆ
âˆ’â†’
âŸ¨MâŸ©T almost surely for all T âˆˆQ+. Since both
T â†’Un
T and T â†’âŸ¨MâŸ©T are monotone and continuous, we get Un
T
nâ†’âˆ
âˆ’â†’âŸ¨MâŸ©T

21.10
Square Variation and Local Martingales
567
for all T â‰¥0 almost surely. Hence, for this sequence of partitions, the pathwise
square variation almost surely equals the square variation process:
âŸ¨M(Ï‰)âŸ©= V 2(M(Ï‰)) = âŸ¨MâŸ©(Ï‰).
â™¦
Reï¬‚ection In (iii) we only claim stochastic convergence, not almost sure conver-
gence. Can you ï¬nd an example where the convergence is really not almost sure but
only stochastic? â™ â™ â™ 
Proof (of Theorem 21.70) Step 1.
First let |Mt| â‰¤C almost surely for all t â‰¥0
for some C < âˆ. Then, in particular, M is a martingale (by Remark 21.68). Write
Un
T = M2
T âˆ’M2
0 âˆ’Nn
T , where
Nn
T = 2

tâˆˆPn
T
Mt

Mtâ€² âˆ’Mt

,
T â‰¥0,
is a continuous martingale. Assume that we can show that, for every T
â‰¥0,
(Un
T )nâˆˆN is a Cauchy sequence in L2(P). Then also (Nn
T )nâˆˆN is a Cauchy sequence,
and we can deï¬ne 
NT as the L2-limit of (Nn
T )nâˆˆN. By Exercise 21.4.3, 
N has a
continuous modiï¬cation N, and we have Nn
T
nâ†’âˆ
âˆ’â†’NT in L2 for all T â‰¥0. Thus
there exists a continuous process âŸ¨MâŸ©with
Un
T
nâ†’âˆ
âˆ’â†’âŸ¨MâŸ©T
in L2
for all T â‰¥0,
(21.55)
and N = M2 âˆ’M2
0 âˆ’âŸ¨MâŸ©is a continuous martingale.
It remains to show that, for all T â‰¥0,
(Un
T )nâˆˆN is a Cauchy sequence in L2.
(21.56)
For m âˆˆN, let
Zm := max

Mt âˆ’Ms
2 : s âˆˆPm
T , t âˆˆPn
s,sâ€², n â‰¥m

.
Since M is almost surely uniformly continuous on [0, T ], we have Zm
mâ†’âˆ
âˆ’â†’
0
almost surely. As Zm â‰¤4C2, we infer
E
)
Z2
m
* mâ†’âˆ
âˆ’â†’0.
(21.57)
For n âˆˆN and numbers a0, . . . , an, we have
(an âˆ’a0)2 âˆ’
nâˆ’1

k=0
(ak+1 âˆ’ak)2 = 2
nâˆ’1

k=0
(ak âˆ’a0)(ak+1 âˆ’ak).

568
21
Brownian Motion
In the following computation, we apply this to each summand in the outer sum to
obtain for m âˆˆN and n â‰¥m
Um
T âˆ’Un
T =

sâˆˆPm
T

Msâ€² âˆ’Ms
2 âˆ’

tâˆˆPn
s,sâ€²

Mtâ€² âˆ’Mt
2

= 2

sâˆˆPm
T

tâˆˆPn
s,sâ€²

Mt âˆ’Ms

Mtâ€² âˆ’Mt

.
(21.58)
Since M is a martingale, for s1, s2 âˆˆPm
T and t1 âˆˆPn
s1,sâ€²
1, t2 âˆˆPn
s2,sâ€²
2 with t1 < t2,
we have
E
'
Mt1 âˆ’Ms1

Mtâ€²
1 âˆ’Mt1

Mt2 âˆ’Ms2

Mtâ€²
2 âˆ’Mt2
(
= E
'
Mt1 âˆ’Ms1

Mtâ€²
1 âˆ’Mt1

Mt2 âˆ’Ms2

E
)
Mtâ€²
2 âˆ’Mt2
Ft2
*(
= 0.
If we use (21.58) to compute the expectation of

Um
T âˆ’Un
T
2, then the mixed terms
vanish and we get (using the Cauchyâ€“Schwarz inequality in the third line)
E
)
(Un
T âˆ’Um
T )2*
= 4 E
+ 
sâˆˆPm
T

tâˆˆPn
s,sâ€²
(Mt âˆ’Ms)2(Mtâ€² âˆ’Mt)2
,
â‰¤4 E
+
Zm

tâˆˆPn
T
Mtâ€² âˆ’Mt
2
,
â‰¤4 E
)
Z2
m
*1/2 E
+ 
tâˆˆPn
T

Mtâ€² âˆ’Mt
2
2,1/2
.
(21.59)
For the second factor,
E
+ 
tâˆˆPn
T

Mtâ€² âˆ’Mt
2
2,
= E
+ 
tâˆˆPn
T

Mtâ€² âˆ’Mt
4
,
+ 2 E
+ 
sâˆˆPn
T
Msâ€² âˆ’Ms
2 
tâˆˆPn
sâ€²,T
Mtâ€² âˆ’Mt
2
,
.
(21.60)
The ï¬rst summand in (21.60) is bounded by
4C2 E
+ 
tâˆˆPn
T
Mtâ€² âˆ’Mt
2
,
= 4C2 E)(MT âˆ’M0)2* â‰¤16 C4.

21.10
Square Variation and Local Martingales
569
The second summand in (21.60) equals
2 E
+ 
sâˆˆPn
T
Msâ€² âˆ’Ms
2 E
+ 
tâˆˆPn
sâ€²,T
Mtâ€² âˆ’Mt
2
Fsâ€²
,,
= 2 E
+ 
sâˆˆPn
T

Msâ€² âˆ’Ms
2 E
)
(MT âˆ’Msâ€²)2Fsâ€²*,
â‰¤8C2 E
)
(MT âˆ’M0)2*
â‰¤32 C4.
Together with (21.59) and (21.57), we obtain
sup
nâ‰¥m
E
)
(Un
T âˆ’Um
T )2*
â‰¤16
âˆš
3 C2 E
)
Z2
m
*1/2
mâ†’âˆ
âˆ’â†’
0.
This shows (21.56).
Step 2.
Now let M âˆˆMloc,c and let (Ï„N)NâˆˆN be a localising sequence such that
every MÏ„N is a bounded martingale (see Remark 21.67). By Step 1, for T â‰¥0 and
N âˆˆN, we have
UN,n
T
:=

tâˆˆPn
T

MÏ„N
tâ€² âˆ’MÏ„N
t
2 nâ†’âˆ
âˆ’â†’âŸ¨MÏ„N âŸ©T in L2.
Since UN,n
T
= UN+1,n
T
if T â‰¤Ï„N, there is a continuous process U with UN,n
T
nâ†’âˆ
âˆ’â†’
UT in probability if T â‰¤Ï„N. Thus âŸ¨MÏ„N âŸ©T = âŸ¨MâŸ©T := UT if T â‰¤Ï„N. Since
Ï„N â†‘âˆalmost surely, for all T â‰¥0,
Un
T
nâ†’âˆ
âˆ’â†’âŸ¨MâŸ©T in probability.
As

(MÏ„N
T )2 âˆ’âŸ¨MÏ„N âŸ©T

T â‰¥0 is a continuous martingale and since âŸ¨MÏ„N âŸ©= âŸ¨MâŸ©Ï„N ,
we have M2 âˆ’âŸ¨MâŸ©âˆˆMloc,c.
Step 3.
It remains to show (ii). Let M be a continuous square integrable martingale
and let (Ï„n)nâˆˆN be a localising sequence for the local martingale M2 âˆ’âŸ¨MâŸ©. Let
T > 0 and let Ï„ â‰¤T be a stopping time. Then M2
Ï„nâˆ§Ï„ â‰¤E[M2
T |FÏ„nâˆ§Ï„] since M2
is a nonnegative submartingale. Hence (M2
Ï„nâˆ§Ï„)nâˆˆN is uniformly integrable and thus
(using the monotone convergence theorem in the last step)
E
)
M2
Ï„
*
= lim
nâ†’âˆE
)
M2
Ï„nâˆ§Ï„
*
= lim
nâ†’âˆE
)
âŸ¨MâŸ©Ï„nâˆ§Ï„
*
+ E
)
M2
0
*
= E
)
âŸ¨MâŸ©Ï„
*
+ E
)
M2
0
*
.
Thus, by the optional sampling theorem, M2 âˆ’âŸ¨MâŸ©is a martingale.
Step 4 (Uniqueness).
Let A and Aâ€² be continuous, monotone increasing, adapted
processes with A0 = Aâ€²
0 such that M2 âˆ’A and M2 âˆ’Aâ€² are local martingales. Then

570
21
Brownian Motion
also N = A âˆ’Aâ€² is a local martingale, and for almost all Ï‰, the path N(Ï‰) has
locally ï¬nite variation. Thus âŸ¨NâŸ©â‰¡0 and hence N2 âˆ’âŸ¨NâŸ©= N2 is a continuous
local martingale with N0 = 0. Let (Ï„n)nâˆˆN be a localising sequence for N2. Then
E
)
N2
Ï„nâˆ§t
*
= 0 for any n âˆˆN and t â‰¥0; hence N2
Ï„nâˆ§t = 0 almost surely and thus
N2
t = limnâ†’âˆN2
Ï„nâˆ§t = 0 almost surely. We conclude A = Aâ€².
âŠ“âŠ”
Corollary 21.72 Let M be a continuous local martingale with âŸ¨MâŸ©â‰¡0. Then
Mt = M0 for all t â‰¥0 almost surely. In particular, this holds if the paths of M have
locally ï¬nite variation.
Corollary 21.73 Let M, N
âˆˆMloc,c. Then there exists a unique continuous
adapted process âŸ¨M, NâŸ©with almost surely locally ï¬nite variation and âŸ¨M, NâŸ©0 = 0
such that
MN âˆ’âŸ¨M, NâŸ©is a continuous local martingale.
âŸ¨M, NâŸ©is called the quadratic covariation process of M and N. For every
admissible sequence of partitions P and for every T â‰¥0, we have
âŸ¨M, NâŸ©T = lim
nâ†’âˆ

tâˆˆPn
T

Mtâ€² âˆ’Mt

Ntâ€² âˆ’Nt

in probability.
(21.61)
Proof Existence Manifestly, M + N, M âˆ’N âˆˆMloc,c. Deï¬ne
âŸ¨M, NâŸ©:= 1
4

âŸ¨M + NâŸ©âˆ’âŸ¨M âˆ’NâŸ©

.
As the difference of two monotone increasing functions, âŸ¨M, NâŸ©has locally ï¬nite
variation. Using Theorem 21.70(iii), we get (21.61). Furthermore,
MN âˆ’âŸ¨M, NâŸ©= 1
4

(M + N)2 âˆ’âŸ¨M + NâŸ©

âˆ’1
4

(M âˆ’N)2 âˆ’âŸ¨M âˆ’NâŸ©

is a local martingale.
Uniqueness Let A and Aâ€² with A0 = Aâ€²
0 = 0 be continuous, adapted and with
locally ï¬nite variation such that MNâˆ’A and MNâˆ’Aâ€² are in Mloc,c. Then Aâˆ’Aâ€² âˆˆ
Mloc,c have locally ï¬nite variation; hence A âˆ’Aâ€² = 0.
âŠ“âŠ”
Corollary 21.74 If M âˆˆMloc,c and A are continuous and adapted with âŸ¨AâŸ©â‰¡0,
then âŸ¨M + AâŸ©= âŸ¨MâŸ©.
If M is a continuous local martingale up to the stopping time Ï„, then MÏ„ âˆˆMloc,c,
and we write âŸ¨MâŸ©t := âŸ¨MÏ„âŸ©t for t < Ï„.
Theorem 21.75 Let Ï„ be a stopping time, M be a continuous local martingale up
to Ï„ and Ï„0 < Ï„ a stopping time with E[âŸ¨MâŸ©Ï„0] < âˆ. Then E[MÏ„0] = E[M0], and
MÏ„0 is an L2-bounded martingale if E[M2
0] < âˆ.

21.10
Square Variation and Local Martingales
571
Proof Let Ï„n â†‘Ï„ be a localising sequence of stopping times for M such that
every MÏ„n is even a bounded martingale (see Remark 21.67). Then MÏ„0âˆ§Ï„n is also a
bounded martingale, and for every t â‰¥0, we have
E
)
M2
Ï„0âˆ§Ï„nâˆ§t
*
= E
)
M2
0
*
+ E
)
âŸ¨MâŸ©Ï„0âˆ§Ï„nâˆ§t
*
â‰¤E
)
M2
0
*
+ E
)
âŸ¨MâŸ©Ï„0
*
< âˆ.
(21.62)
Hence

(MÏ„0âˆ§Ï„nâˆ§t), n âˆˆN, t â‰¥0

is bounded in L2 and is thus uniformly
integrable. Therefore, by the optional sampling theorem for uniformly integrable
martingales,
E[MÏ„0] = lim
nâ†’âˆE[MÏ„0âˆ§Ï„n] = E[M0],
and, for t > s,
E)MÏ„0
t
Fs
* = E
'
lim
nâ†’âˆMÏ„0âˆ§Ï„n
t
Fs
(
= lim
nâ†’âˆE
)
MÏ„0âˆ§Ï„n
t
Fs
*
= lim
nâ†’âˆMÏ„0âˆ§Ï„n
s
= MÏ„0
s .
Hence MÏ„0 is a martingale.
âŠ“âŠ”
Corollary 21.76 If M âˆˆMloc,c with E[M2
0] < âˆand E)âŸ¨MâŸ©t
* < âˆfor every
t â‰¥0, then M is a square integrable martingale.
Takeaways Brownian motion is nowhere differentiable and hence has inï¬nite
variation. On the other hand, the square variation (deï¬ned as limit of sums
of squared increments along ï¬ner and ï¬ner partition sequences) is ï¬nite
over compact sets. In the general context, we identify the pathwise deï¬ned
square variation as the variance process of a local martingale M. This is the
increasing process âŸ¨MâŸ©from the Doob decomposition of M2 which turns
M2 âˆ’âŸ¨MâŸ©into a local martingale. Hence, âŸ¨MâŸ©is a measure for the random
ï¬‚uctuations of M.
Exercise 21.10.1 Show that the random variables (Yn)nâˆˆN from the proof of
Theorem 21.64 form a backwards martingale. â™£

572
21
Brownian Motion
Exercise 21.10.2 Let f : [0, âˆ) â†’R be continuous and let X âˆˆCP
qv for the
admissible sequence of partitions P. Show that
 T
0
f (s) dâŸ¨XâŸ©s = lim
nâ†’âˆ

tâˆˆPn
T
f (t)

Xtâ€² âˆ’Xt)2
for all T â‰¥0.
â™£
Exercise 21.10.3 Show by a counterexample that if M is a continuous local
martingale with M0 = 0 and if Ï„ is a stopping time with E)âŸ¨MâŸ©Ï„
* = âˆ, then
this does not necessarily imply E)M2
Ï„
* = âˆ. â™£

Chapter 22
Law of the Iterated Logarithm
For sums of independent random variables we already know two limit theorems:
the law of large numbers and the central limit theorem. The law of large numbers
describes for large n âˆˆN, the typical behavior, or average value behavior, of sums
of n random variables. On the other hand, the central limit theorem quantiï¬es the
typical ï¬‚uctuations about this average value.
In Chap. 23, we will study atypically large deviations from the average value in
greater detail. The aim of this chapter is to quantify the typical ï¬‚uctuations of the
whole process as n â†’âˆ. The main message is: While for ï¬xed time the partial sum
Sn deviates by approximately âˆšn from its expected value (central limit theorem),
the maximal ï¬‚uctuation up to time n is of order âˆšn log log n (Hartmanâ€“Wintner
theorem, Theorem 22.11).
We start with the simpler task of computing the ï¬‚uctuations for Brownian motion
(Theorem 22.1). After that, we will see how sums of independent centered random
variables (with ï¬nite variance) can be embedded in a Brownian motion (Skorohodâ€™s
theorem, Theorem 22.5). This embedding will be used to prove the Hartmanâ€“
Wintner theorem.
In this chapter, we follow essentially the exposition of [39, Section 8.8].
22.1
Iterated Logarithm for the Brownian Motion
Let (Bt)tâ‰¥0 be a Brownian motion. In Example 21.16, as an application of Blumen-
thalâ€™s 0â€“1 law, we saw that lim suptâ†“0 Bt/âˆšt = âˆa.s. Since by Theorem 21.14,
(tB1/t)tâ‰¥0 also is a Brownian motion, we get
lim sup
tâ†’âˆ
Bt
âˆšt = âˆ
a.s.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_22
573

574
22
Law of the Iterated Logarithm
The aim of this section is to replace âˆšt by a function such that the limes superior is
ï¬nite and nontrivial.
Theorem 22.1 (Law of the iterated logarithm for Brownian motion)
lim sup
tâ†’âˆ
Bt
2
2t log log(t)
= 1
a.s.
(22.1)
Before proving the theorem, we state an elementary lemma.
Lemma 22.2 Let X âˆ¼N0,1 be standard normally distributed. Then, for any x > 0,
1
âˆš
2Ï€
1
x + 1
x
eâˆ’x2/2 â‰¤P[X â‰¥x] â‰¤
1
âˆš
2Ï€
1
x eâˆ’x2/2.
(22.2)
Proof Let Ï•(t) =
1
âˆš
2Ï€ eâˆ’t2/2 be the density of the standard normal distribution.
Partial integration yields the second inequality in (22.2),
P[X â‰¥x] =
 âˆ
x
1
t (tÏ•(t)) dt = âˆ’1
t Ï•(t)

âˆ
x âˆ’
 âˆ
x
1
t2 Ï•(t) dt â‰¤1
x Ï•(x).
Similarly, we get
P[X â‰¥x] â‰¥1
x Ï•(x) âˆ’1
x2
 âˆ
x
Ï•(t) dt = 1
x Ï•(x) âˆ’1
x2 P[X â‰¥x].
This implies the ï¬rst inequality in (22.2).
âŠ“âŠ”
Proof of Theorem 22.1
Step 1. â€œâ‰¤â€
Let Î± > 1, and deï¬ne tn = Î±n for n âˆˆN. Later, we let Î± â†“1. Deï¬ne
f (t) = 2Î±2 log log t. Then by the reï¬‚ection principle (Theorem 21.19) and using
the abbreviation B[a,b] := {Bt : t âˆˆ[a, b]}, we obtain
P
'
sup B[tn,tn+1] >
2
tnf (tn)
(
â‰¤P
'
tâˆ’1/2
n+1 sup B[0,tn+1] >
2
f (tn)/Î±
(
= P
'
sup B[0,1] >
2
f (tn)/Î±
(
â‰¤
K
Î±
f (tn) eâˆ’f (tn)/2Î±
= (log Î±)âˆ’Î±
K
Î±
f (tn) nâˆ’Î±
â‰¤nâˆ’Î±
for large enough n.
(22.3)

22.1
Iterated Logarithm for the Brownian Motion
575
In the next to last step, we used
f (tn)
2Î±
= Î±

log(n log Î±)

= Î± log n + Î± log log Î±.
Since Î± > 1, the right-hand side of (22.3) is summable in n:
âˆ

n=1
P
'
sup B[tn,tn+1] >
2
tnf (tn)
(
< âˆ.
The Borelâ€“Cantelli lemma (Theorem 2.7) then yields (note that t â†’âˆštf (t) is
monotone increasing)
lim sup
tâ†’âˆ
Bt
âˆštf (t) â‰¤1
a.s.
Now let Î± â†“1 to obtain
lim sup
tâ†’âˆ
Bt
âˆš2t log log t â‰¤1
a.s.
(22.4)
Step 2. â€œâ‰¥â€
Here we show the other inequality in (22.1). To this end, we let
Î± â†’âˆ. Let Î² :=
Î±
Î±âˆ’1 > 1 and g(t) =
2
Î²2 log log t. Choose n0 large enough that
Î²g(tn) â‰¥1 for all n â‰¥n0. Then, by Brownian scaling (note that tn âˆ’tnâˆ’1 = 1
Î² tn)
and (22.2) (since (x + 1
x )âˆ’1 â‰¥1
2
1
x for x = (Î²g(tn))1/2 â‰¥1),
P
'
Btn âˆ’Btnâˆ’1 >
2
tng(tn)
(
= P
'
B1 >
2
Î²g(tn)
(
â‰¥
1
âˆš
2Ï€
1
2
1
âˆšÎ²g(tn) eâˆ’Î²g(tn)/2
=
1
âˆš
2Ï€
1
2 (log Î±)âˆ’1/Î²
1
âˆšÎ²g(tn) nâˆ’1/Î².
If Îµ âˆˆ(0, 1 âˆ’1/Î²), then, for sufï¬ciently large n âˆˆN, the right-hand side of the
above equation is â‰¥nâˆ’Îµ nâˆ’1/Î² â‰¥nâˆ’1. Hence
âˆ

n=2
P
'
Btn âˆ’Btnâˆ’1 >
2
tng(tn)
(
= âˆ.
The events are independent and hence the Borelâ€“Cantelli lemma yields
P
'
Btn âˆ’Btnâˆ’1 >
2
tng(tn)
for inï¬nitely many n
(
= 1.
(22.5)

576
22
Law of the Iterated Logarithm
Since
tn log log tn
tnâˆ’1 log log tnâˆ’1
nâ†’âˆ
âˆ’â†’Î±, (22.4) and symmetry of Brownian motion imply
that, for Îµ > 0,
Btnâˆ’1 > âˆ’(1 + Îµ) Î±âˆ’1/2 2
2tn log log tn
for almost all n âˆˆN
a.s.
(22.6)
From (22.5) and (22.6), it follows that
lim sup
nâ†’âˆ
Btn
âˆš2tn log log tn
â‰¥1
Î² âˆ’(1 + Îµ) Î±âˆ’1/2 = Î± âˆ’1
Î±
âˆ’(1 + Îµ) Î±âˆ’1/2
a.s.
Now, letting Î± â†’âˆgives lim sup
tâ†’âˆ
Bt
âˆš2t log log t â‰¥1 a.s. Together with (22.4), this
implies the claim of the theorem.
âŠ“âŠ”
Corollary 22.3 For every s â‰¥0, a.s. we have lim sup
tâ†“0
Bs+t âˆ’Bs
2
2t log log(1/t)
= 1.
Proof Without loss of generality, assume s = 0. Apply Theorem 22.1 to the
Brownian motion (tB1/t) (see Theorem 21.14).
âŠ“âŠ”
Remark 22.4 The statement of Corollary 22.3 is about the typical points s of
Brownian motion B. However, there might be points in which Brownian motion
moves faster than
2
2t log log(1/t). The precise statement is due to Paul LÃ©vy [106]:
Denote by h(Î´) :=
2
2Î´ log(1/Î´) LÃ©vyâ€™s modulus of continuity. Then
P
'
lim
Î´â†“0
sup
s,tâˆˆ[0,1]
0â‰¤tâˆ’sâ‰¤Î´
|Bt âˆ’Bs|/h(Î´) = 1
(
= 1.
(22.7)
(See, e.g., [145, Theorem I.2.5] for a proof.) This implies in particular that almost
surely B is not locally HÃ¶lder- 1
2-continuous. â™¦
Takeaways The typical ï¬‚uctuation of a Brownian motion at time t is of order
âˆšt. Its maximal value by time t, however, has size
2
2t log log(t) as t â†’âˆ.
Due to the two logarithms in this formula, this statement is called law of the
iterated logarithm. We have proved it by ï¬rst showing it along a geometric
sequence of times and then ï¬lling the gaps.
22.2
Skorohodâ€™s Embedding Theorem
In order to carry over the result of the previous section to sums of square integrable
centered random variables, we use an embedding of such random variables in

22.2
Skorohodâ€™s Embedding Theorem
577
a Brownian motion that is due to Skorohod. This technique also provides an
alternative proof of Donskerâ€™s invariance principle (Theorem 21.43).
Theorem 22.5 (Skorohodâ€™s embedding theorem) Let X be a real random vari-
able with E[X] = 0 and Var[X] < âˆ. Then on a suitable probability space we
can construct a random variable Î, a Brownian motion B that is independent of Î
and an F-stopping time Ï„ such that
BÏ„
D= X
and
E[Ï„] = Var[X].
Here the ï¬ltration F is given by Ft = Ïƒ(Î, (Bs)sâ‰¤t).
Remark 22.6 In the above theorem we can de without the additional random
variable; that is, we can choose F = Ïƒ(B). The proof is rather involved, though
(see page 579). â™¦
Corollary 22.7 Let X1, X2, . . . be i.i.d. real random variables with E[X1] = 0
and Var[X1] < âˆ. Further, let Sn = X1 + . . . + Xn, n âˆˆN. Then on a suitable
probability space there exists a ï¬ltration F, a Brownian motion B and F-stopping
times 0 = Ï„0 â‰¤Ï„1 â‰¤Ï„2 â‰¤. . . such that (Ï„n âˆ’Ï„nâˆ’1)nâˆˆN is i.i.d., E[Ï„1] = Var[X1]
and (BÏ„n)nâˆˆN
D= (Sn)nâˆˆN.
Proof (of Corollary 22.7) We only sketch the proof. The details are left to the
reader.
Choose independent triples (B(n), Î(n), Ï„ (n)), n âˆˆN, as in Theorem 22.5. Let Ï„n =
Ï„ (1) + . . . + Ï„ (n). For t â‰¤Ï„1 let Bt := B(1)
t
, and deï¬ne recursively
Bt = BÏ„n + B(n+1)
tâˆ’Ï„n ,
if Ï„n < t â‰¤Ï„n+1.
Using repeatedly the strong Markov property of Brownian motion, we see that B is
a Brownian motion. Now let Ft = Ïƒ((În)nâˆˆN, (Bs)sâ‰¤t).
âŠ“âŠ”
We prepare for the proof of Theorem 22.5 with a lemma. In order to allow measures
as integrands, we use the following notation: If Î¼ âˆˆM(E) is a measure and f âˆˆ
L1(Î¼) is nonnegative, then deï¬ne
3
Î¼(dx)f (x)Î´x := f Î¼, where f Î¼ is the measure
with density f with respect to Î¼. This is consistent since for measurable A âŠ‚E,
we then have

Î¼(dx)f (x)Î´x

(A) =

Î¼(dx)f (x)Î´x(A) =

Î¼(dx)f (x) 1A(x) = f Î¼(A).
Lemma 22.8 Let Î¼ âˆˆM1(R) with
3
x Î¼(dx) = 0 and Ïƒ 2 :=
3
x2 Î¼(dx) < âˆ.
Then there exists a probability measure Î¸ âˆˆM1((âˆ’âˆ, 0) Ã— [0, âˆ)) with
Î¼ =

Î¸(d(u, v))

v
v âˆ’u Î´u +
âˆ’u
v âˆ’u Î´v

.
(22.8)
Furthermore, Ïƒ 2 = âˆ’
3
uv Î¸(d(u, v)).

578
22
Law of the Iterated Logarithm
Proof Deï¬ne m :=
3
[0,âˆ) v Î¼(dv) = âˆ’
3
(âˆ’âˆ,0) u Î¼(du). If m = 0, then Î¸ =
Î´(âˆ’1,0) is a possible choice. Assume now m > 0 and deï¬ne Î¸ by
Î¸(d(u, v)) := mâˆ’1(v âˆ’u) Î¼(du)Î¼(dv)
for u < 0 and v â‰¥0.
Then

Î¸(d(u, v)) = mâˆ’1

(âˆ’âˆ,0)
Î¼(du)

[0,âˆ)
Î¼(dv) (v âˆ’u)
= mâˆ’1

(âˆ’âˆ,0)
Î¼(du) [m âˆ’uÎ¼([0, âˆ))]
= mâˆ’1
mÎ¼((âˆ’âˆ, 0)) + mÎ¼([0, âˆ))

= 1.
Hence, Î¸ is in fact a probability measure. Furthermore,

Î¸(d(u, v))

v
v âˆ’u Î´u +
âˆ’u
v âˆ’u Î´v

= mâˆ’1

(âˆ’âˆ,0)
Î¼(du)

[0,âˆ)
Î¼(dv) (vÎ´u âˆ’uÎ´v)
=

(âˆ’âˆ,0)
Î¼(du) Î´u +

[0,âˆ)
Î¼(dv) Î´v = Î¼.
By (22.8), we infer
Ïƒ 2 =

Î¼(dx) x2 =

Î¸(d(u, v))

v
v âˆ’u u2 +
âˆ’u
v âˆ’u v2
= âˆ’

Î¸(d(u, v)) uv. âŠ“âŠ”
Proof (Theorem 22.5) First assume that X takes only the two values u < 0 and
v â‰¥0: P[X = u] =
v
vâˆ’u = 1 âˆ’P[X = v]. Let
Ï„u,v = inf
	
t > 0 : Bt âˆˆ{u, v}

.
By Exercise 21.2.4, we have E[BÏ„u,v] = 0; hence BÏ„u,v
D= X and E[Ï„u,v] = âˆ’uv.
Now let X be arbitrary with E[X] = 0 and Ïƒ 2 := E[X2] < âˆ. Deï¬ne Î¼ = PX
and Î¸ = Î¸Î¼ as in Lemma 22.8. Further, let Î = (Îu, Îv) be a random variable with
values in (âˆ’âˆ, 0) Ã— [0, âˆ) and with distribution Î¸.
Let F = (Ft)tâ‰¥0 where Ft := Ïƒ(Î, Bs : s âˆˆ[0, t]). Deï¬ne Ï„ := Ï„Îu,Îv. By
continuity of B, we get
{Ï„ â‰¤t} =

sup
sâˆˆ[0,t]
Bs â‰¥Îv

âˆª

inf
sâˆˆ[0,t]Bs â‰¤Îu

âˆˆFt.

22.2
Skorohodâ€™s Embedding Theorem
579
Hence Ï„ is an F-stopping time (but not a Ïƒ(B)-stopping time). For x < 0,
P[X â‰¤x] =

(âˆ’âˆ,x]Ã—[0,âˆ)
Î¸(d(u, v))
v
v âˆ’u
=

(âˆ’âˆ,x]Ã—[0,âˆ)
Î¸(d(u, v)) P[BÏ„u,v = u] = P[BÏ„ â‰¤x].
For x â‰¥0, we similarly get P[X > x] = P[BÏ„ > x]. Summing up, we have
BÏ„
D= X. Furthermore,
E[Ï„] = âˆ’E[ÎuÎv] = âˆ’

Î¸(d(u, v)) uv = Ïƒ 2.
âŠ“âŠ”
Supplement: Proof of Remark 22.6
Here we prove that in Skorohodâ€™s embedding theorem we can really do without
randomized stopping times; that is, we can choose a stopping time with respect to
the ï¬ltration generated by the Brownian motion B. In other words, the stopping time
can be chosen without using additional random variables, such as the Î in the proof
given above.
An elegant proof that is based on stochastic analysis methods can be found in
AzÃ©ma and Yor; see [7] and [6]. See also [118] for a more elementary version of
that proof. Here, however, we follow an elementary route whose basic idea goes
back to Dubins.
For u < 0 < v, let Ï„u,v = inf{t > 0 : Bt âˆˆ{u, v}}. Hence, if X is a centered
random variable that takes only the values u and v, then, as shown in the proof of
Theorem 22.5, BÏ„u,v
D= X and E[Ï„u,v] = E[X2].
In a ï¬rst step, we generalize this statement to binary splitting martingales. (Recall
from Deï¬nition 9.42 that a binary splitting process at each time step has a choice of
just two different values, which may however depend on the history of the process.)
In a second step, we show that square integrable centered random variables can be
expressed as limits of such martingales.
Theorem 22.9 Let (Xn)nâˆˆN0 be a binary splitting martingale with X0 = 0. Let B
be a Brownian motion and let F = Ïƒ(B) be its canonical ï¬ltration. Then there exist
F-stopping times 0 = Ï„0 â‰¤Ï„1 â‰¤. . . such that
(Xn)nâˆˆN0
D= (BÏ„n)nâˆˆN0
and such that E[Ï„n] = E[X2
n] holds for all n âˆˆN0.

580
22
Law of the Iterated Logarithm
If (Xn)nâˆˆN0 is bounded in L2 and thus converges almost surely and in L2 to
some square integrable Xâˆ, then Ï„ := supnâˆˆN Ï„n < âˆa.s., E[Ï„] = Var[Xâˆ] and
Xâˆ
D= BÏ„ .
Proof For n âˆˆN, let fn : Rnâˆ’1 Ã— {âˆ’1, +1} â†’R and let Dn be a {âˆ’1, +1}-
valued random variable such that Xn = fn(X1, . . . , Xnâˆ’1, Dn) holds (compare
Deï¬nition 9.42). Without loss of generality, we may assume that fn is monotone
increasing in Dn. Let Ï„0 := 0 and inductively deï¬ne
Ï„n := inf
	
t > Ï„nâˆ’1 : Bt âˆˆ{fn(BÏ„1, . . . , BÏ„nâˆ’1, âˆ’1), fn(BÏ„1, . . . , BÏ„nâˆ’1, +1)}

.
Let ËœXn := BÏ„n and
ËœDn :=
0
1,
if
ËœXn â‰¥ËœXnâˆ’1,
âˆ’1,
else.
By Exercise 21.2.4 and using the strong Markov property (at Ï„nâˆ’1), we get
P
) ËœDn = 1
 ËœX1, . . . , ËœXnâˆ’1
*
=
ËœXnâˆ’1 âˆ’fn( ËœX1, . . . , ËœXnâˆ’1, âˆ’1)
fn( ËœX1, . . . , ËœXnâˆ’1, +1) âˆ’fn( ËœX1, . . . , ËœXnâˆ’1, âˆ’1)
and E[Ï„n âˆ’Ï„nâˆ’1] = E[( ËœXn âˆ’ËœXnâˆ’1)2]. On the other hand, since (Xn)nâˆˆN0 is a
martingale, we have
Xnâˆ’1 = E[Xn|X0, . . . , Xnâˆ’1]
=

i=âˆ’1,+1
P[Dn = i|X0, . . . , Xnâˆ’1] fn(X1, . . . , Xnâˆ’1, i).
Therefore,
P
)
Dn = 1
X1, . . . , Xnâˆ’1
*
=
Xnâˆ’1 âˆ’fn(X1, . . . , Xnâˆ’1, âˆ’1)
fn(X1, . . . , Xnâˆ’1, +1) âˆ’fn(X1, . . . , Xnâˆ’1, âˆ’1).
This implies (Xn)nâˆˆN0
D= ( ËœXn)nâˆˆN0. Since E[Ï„n âˆ’Ï„nâˆ’1] = E[(Xn âˆ’Xnâˆ’1)2],
and since the martingale differences (Xi âˆ’Xiâˆ’1), i âˆˆN, are uncorrelated, we get
E[Ï„n] = E[X2
n].
Finally, if (Xn) is bounded in L2, then by the martingale convergence theorem
there is a square integrable centered random variable Xâˆsuch that Xn
nâ†’âˆ
âˆ’â†’Xâˆ
almost surely and in L2. In particular, we have E[X2
n]
nâ†’âˆ
âˆ’â†’
E[X2
âˆ]. Clearly,
(Ï„n)nâˆˆN is monotone increasing and thus converges to some stopping time Ï„. By

22.2
Skorohodâ€™s Embedding Theorem
581
the monotone convergence theorem, E[Ï„] = limnâ†’âˆE[Ï„n] = limnâ†’âˆE[X2
n] =
E[X2
âˆ] < âˆ. Hence Ï„ < âˆa.s. As Brownian motion is continuous, we conclude
BÏ„ = lim
nâ†’âˆBÏ„n = lim
nâ†’âˆ
ËœXn
D= Xâˆ.
âŠ“âŠ”
We have shown the statement of Remark 22.6 in the case where the random
variable X is the limit of a binary splitting martingale. The general case is now
implied by the following theorem (Figs. 22.1 and 22.2).
Theorem 22.10 Let X be a square integrable centered random variable. Then there
exists a binary splitting martingale (Xn)nâˆˆN0 with X0 = 0 and such that Xn
nâ†’âˆ
âˆ’â†’
X almost surely and in L2.
Proof We follow the idea of the proof in [118]. Let X0 := E[X] = 0. Inductively,
for n âˆˆN, deï¬ne
Dn :=

1,
if X â‰¥Xnâˆ’1,
âˆ’1,
if X < Xnâˆ’1,
Fn := Ïƒ(D1, . . . , Dn)
and
Xn := E[X|Fn].
0
1
âˆ’1.5
1.5
0
âˆ’1
âˆ’2
2
1
3/5
2/5
2/3
1/3
1/2
1/2
1/2
1/2
Fig. 22.1 Binary splitting martingale for the random variable X with P[X = k] =
1
5 for k =
âˆ’2, âˆ’1, 0, 1, 2.

582
22
Law of the Iterated Logarithm
Hence there exists a map gn : {âˆ’1, +1}n â†’R such that gn(D1, . . . , Dn) = Xn.
Clearly, 1Dk=1 = 1Xkâ‰¥Xkâˆ’1 almost surely for all k âˆˆN. Hence the D1, . . . , Dk can
be computed from the X1, . . . , Xk. Thus there exists a map fn : Rnâˆ’1Ã—{âˆ’1, +1} â†’
R such that fn(X1, . . . , Xnâˆ’1, Dn) = Xn. Therefore, (Xn) is binary splitting.
Manifestly, (Xn)nâˆˆN0 is a martingale. By Jensenâ€™s inequality, we have E[X2
n] â‰¤
E[X2] < âˆfor all n âˆˆN. Hence (Xn)nâˆˆN0 is bounded in L2 and thus converges
almost surely and in L2 to some square integrable Xâˆ. It remains to show that
Xâˆ= X holds almost surely. To this end, we ï¬rst show
lim
nâ†’âˆDn(Ï‰)X(Ï‰) âˆ’Xn(Ï‰) =
X(Ï‰) âˆ’Xâˆ(Ï‰)

for almost all Ï‰.
(22.9)
If X(Ï‰) = Xâˆ(Ï‰), then (22.9) holds trivially. If X(Ï‰) > Xâˆ(Ï‰), then X(Ï‰) >
Xn(Ï‰) and thus Dn(Ï‰) = 1 for all sufï¬ciently large n; hence (22.9) holds. Similarly,
we get (22.9) if X(Ï‰) < Xâˆ(Ï‰).
Evidently, we have
E
)
Dn(X âˆ’Xn)
*
= E
)
Dn E[X âˆ’Xn|Fn]
*
= 0.
As

Dn(X âˆ’Xn)

nâˆˆN is bounded in L2 (and is thus uniformly integrable), we get
E[|X âˆ’Xâˆ|] = limnâ†’âˆE[Dn(X âˆ’Xn)] = 0; hence X = Xâˆa.s.
âŠ“âŠ”
â—
â—
â—
â—
â—
â—
â—
â—
â—
â—
â—
Ï„0
Ï„1
Ï„2
Ï„3 Ï„4
Ï„5
Ï„6 Ï„7
Ï„8
Ï„9
Ï„10
Bt
Fig. 22.2 Embedding of random variables with uniform distribution on {âˆ’2, âˆ’1, 0, 1, 2} in a
Brownian motion. After ï¬rst hitting {âˆ’1.5, 1} there are two possibilities. In the case where âˆ’1.5
is hit before 1, the Brownian motion continuous and is ï¬nally stopped upon hitting âˆ’2 or âˆ’1. In
the other case, we continue until the Brownian motion hits 0 or 1.5. If it is 0, the Brownian motion
stops. If it is 1.5, we continue until the motion hits 1 or 2. The random time at which the motion
if ï¬nally stopped is Ï„1. After Ï„1, we can continue in order generate another sample of the random
variable. Note that in the second period, we have to add BÏ„1 to all numbers.

22.3
Hartmanâ€“Wintner Theorem
583
Takeaways A centred square integrable random variable can be represented
by a Brownian motion evaluated at a stopping time. There is freedom in the
choice of the stopping time, but there exists an optimal (minimal) stopping
time in the sense that the expected value of the stopping time is the variance
of the random variable. It is impossible to do better. By a repetition of the
argument, the partial sums of i.i.d. centred square integrable random variables
can be embedded in the path of a Brownian motion evaluated at a sequence of
stopping times.
22.3
Hartmanâ€“Wintner Theorem
The goal of this section is to prove the law of the iterated logarithm for i.i.d. centered
square integrable random variables Xn, n âˆˆN, that goes back to Hartman and
Wintner (see [69]). For the special case of Rademacher random variables, the upper
bound was found earlier by Khinchin in 1923 (see [97]).
Theorem 22.11 (Hartmanâ€“Wintner,
law
of
the
iterated
logarithm) Let
X1, X2, . . . be i.i.d. real random variables with E[X1] = 0 and Var[X1] = 1.
Let Sn = X1 + . . . + Xn, n âˆˆN. Then
lim sup
nâ†’âˆ
Sn
âˆš2n log log n = 1
a.s.
(22.10)
The strategy of the proof is to embed the partial sums Sn of the random variables
in a Brownian motion and then use the law of the iterated logarithm for Brownian
motion. The Skorohod embedding theorem ensures that this works. We follow the
exposition in [39, Section 8.8].
Proof By Corollary 22.7, on a suitable probability space there exists a ï¬ltration F,
a Brownian motion B that is an F-martingale, and stopping times Ï„1 â‰¤Ï„2 â‰¤. . .
such that (Sn)nâˆˆN
D= (BÏ„n)nâˆˆN. Furthermore, the (Ï„n âˆ’Ï„nâˆ’1)nâˆˆN are i.i.d. with
E[Ï„n âˆ’Ï„nâˆ’1] = Var[X1] = 1.
By the law of the iterated logarithm for Brownian motion (see Theorem 22.1),
we have
lim sup
tâ†’âˆ
Bt
âˆš2t log log t = 1
a.s.
Hence, it is enough to show that
lim sup
tâ†’âˆ
|Bt âˆ’BÏ„âŒŠtâŒ‹|
âˆš2t log log t = 0
a.s.

584
22
Law of the Iterated Logarithm
By the strong law of large numbers (Theorem 5.17), we have 1
nÏ„n
nâ†’âˆ
âˆ’â†’1 a.s., so
let Îµ > 0 and let t0 = t0(Ï‰) be large enough that
1
1 + Îµ â‰¤Ï„âŒŠtâŒ‹
t
â‰¤1 + Îµ
for all t â‰¥t0.
Deï¬ne
Mt :=
sup
sâˆˆ[t/(1+Îµ), t (1+Îµ)]
|Bs âˆ’Bt|.
It is enough to show that lim sup
tâ†’âˆ
Mt
âˆš2t log log t = 0. Consider the sequence tn =
(1 + Îµ)n, n âˆˆN, and deï¬ne
Mâ€²
n :=
sup
sâˆˆ[tnâˆ’1,tn+2]
|Bs âˆ’Btnâˆ’1|.
Then (by the triangle inequality), for t âˆˆ[tn, tn+1],
Mt â‰¤2Mâ€²
n.
Let Î´ := (1+Îµ)3âˆ’1. Then tn+2âˆ’tnâˆ’1 = Î´tnâˆ’1. Brownian scaling and the reï¬‚ection
principle (Theorem 21.19) now yield
P
'
Mâ€²
n >
2
3Î´tnâˆ’1 log log tnâˆ’1
(
= P
'
sup
sâˆˆ[0,1]
|Bs| >
2
3 log log tnâˆ’1
(
â‰¤2 P
'
sup
sâˆˆ[0,1]
Bs >
2
3 log log tnâˆ’1
(
= 4 P
'
B1 >
2
3 log log tnâˆ’1
(
â‰¤
2
âˆš3 log log tnâˆ’1
exp

âˆ’3
2 log log tnâˆ’1

(Lemma 22.2)
â‰¤nâˆ’3/2
for n sufï¬ciently large.
The probabilities can be summed over n; hence the Borelâ€“Cantelli lemma yields
lim sup
tâ†’âˆ
Mt
âˆšt log log t â‰¤lim sup
nâ†’âˆ
2Mâ€²
n
âˆštnâˆ’1 log log tnâˆ’1
â‰¤2
âˆš
3Î´.
Letting Îµ â†’0, we get Î´ = (1 + Îµ)3 âˆ’1 â†’0, and hence the proof is complete.
âŠ“âŠ”

22.3
Hartmanâ€“Wintner Theorem
585
Takeaways The Skorohod embedding theorem allows to transfer the law
of the iterated logarithm to sums of i.i.d. centred square integrable random
variables.

Chapter 23
Large Deviations
Except for the law of the iterated logarithm, so far we have encountered two types of
limit theorems for partial sums Sn = X1+. . .+Xn, n âˆˆN, of identically distributed,
real random variables (Xi)iâˆˆN with distribution function F:
(1) (Weak) laws of large numbers state that (under suitable assumptions on the
family (Xi)iâˆˆN), for every x > 0,
P
)Sn âˆ’n E[X1]
 â‰¥xn
* nâ†’âˆ
âˆ’â†’0.
(23.1)
From this we get immediately that the empirical distribution functions
Fn : x â†’1
n
n

i=1
1(âˆ’âˆ,x](Xi)
converge in probability; that is, âˆ¥Fn âˆ’Fâˆ¥âˆ
nâ†’âˆ
âˆ’â†’0. In other words, for any
distribution function G Ì¸= F and any Îµ > 0 with Îµ < âˆ¥F âˆ’Gâˆ¥âˆ, we have
P
)
âˆ¥Fn âˆ’Gâˆ¥âˆ< Îµ
* nâ†’âˆ
âˆ’â†’0.
(23.2)
(2) Central limit theorems state that (under different assumptions on the family
(Xi)iâˆˆN) for every x âˆˆR
P
)
Sn âˆ’n E[X1] â‰¥xâˆšn
* nâ†’âˆ
âˆ’â†’1 âˆ’Î¦

x
âˆšVar[X1]

.
(23.3)
Here Î¦ : t â†’N0,1((âˆ’âˆ, t]) is the distribution function of the standard normal
distribution.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_23
587

588
23
Large Deviations
In each case, the typical value of Sn is n E[X1]. Equation (23.3) makes a precise
statement about the average size of the deviations (which are of order âˆšn) from
the typical value. A simple consequence is of course that the probability of large
deviations (of order n) from the typical value goes to 0; that is, (23.1) holds.
In this chapter, we compute the speed of convergence in (23.1) (CramÃ©râ€™s
theorem) and in (23.2) (Sanovâ€™s theorem).
We follow in part the expositions in [31] and [74].
23.1
CramÃ©râ€™s Theorem
Let X1, X2, . . . be i.i.d. with PXi = N0,1. Then, for every x > 0,
P[Sn â‰¥xn] = P
)
X1 â‰¥xâˆšn
*
= 1 âˆ’Î¦

xâˆšn

= (1 + Îµn)
1
x
âˆš
2Ï€n
eâˆ’n x2/2,
where Îµn
nâ†’âˆ
âˆ’â†’0 (by Lemma 22.2). Taking logarithms, we get
lim
nâ†’âˆ
1
n log P
)
Sn â‰¥xn
*
= âˆ’x2
2
for every x > 0.
(23.4)
It might be tempting to believe that a central limit theorem could be used to
show (23.4) for all centered i.i.d. sequences (Xi) with ï¬nite variance. However,
in general, the limit might be inï¬nite or might be a different function of x, as
we will show below. The moral is that large deviations depend more subtly on
the tails of the distribution of Xi than the average-sized ï¬‚uctuations do (which are
determined by the variance only). The following theorem shows this for Bernoulli
random variables.
Theorem 23.1 Let X1, X2, . . . be i.i.d. with P[X1 = âˆ’1] = P[X1 = 1] = 1
2. Then,
for every x â‰¥0,
lim
nâ†’âˆ
1
n log P[Sn â‰¥xn] = âˆ’I(x),
(23.5)
where the rate function I is given by (see Fig. 23.1)
I(z) =
 1+z
2 log(1 + z) + 1âˆ’z
2 log(1 âˆ’z),
if z âˆˆ[âˆ’1, 1],
âˆ,
if |z| > 1.
(23.6)
Remark 23.2 Here we agree that 0 log 0 = 0. This makes the restriction of I to
[âˆ’1, 1] a continuous function with I(âˆ’1) = I(1) = log 2. Note that I is strictly
convex on [âˆ’1, 1] with I(0) = 0 and I is monotone increasing on [0, 1] and is
monotone decreasing on [âˆ’1, 0]. â™¦

23.1
CramÃ©râ€™s Theorem
589
âˆ’2
âˆ’1
0
1
2
log(2)
âˆ
I(z)
z
Fig. 23.1 Rate function I(z) from (23.6).
Proof (of Theorem 23.1) For x = 0 and x > 1, the claim is trivial. For x = 1, we
have P[Sn â‰¥n] = 2âˆ’n, and thus again (23.5) holds trivially. Hence, it is enough to
consider x âˆˆ(0, 1). Since Sn+n
2
âˆ¼bn,1/2 is binomially distributed, we have
P)Sn â‰¥xn* = 2âˆ’n

kâ‰¥(1+x)n/2
n
k

.
Deï¬ne an(x) = âŒˆn(1 + x)/2âŒ‰for n âˆˆN. Since k â†’
n
k

is monotone decreasing for
k â‰¥n
2, we get
Qn(x) := max
0n
k

: an(x) â‰¤k â‰¤n
1
=

n
an(x)

.
(23.7)
We make the estimate
2âˆ’n Qn(x) â‰¤P
)
Sn â‰¥xn
*
â‰¤(n + 1) 2âˆ’n Qn(x).
(23.8)
By Stirlingâ€™s formula
lim
nâ†’âˆ
1
n!nneâˆ’nâˆš
2Ï€n = 1,

590
23
Large Deviations
we obtain
lim
nâ†’âˆ
1
n log Qn(x)
= lim
nâ†’âˆ
1
n log
n!
an(x)! Â· (n âˆ’an(x))!
= lim
nâ†’âˆ
1
n log
nn
an(x)an(x) Â· (n âˆ’an(x))nâˆ’an(x)
= lim
nâ†’âˆ
+
log(n) âˆ’an(x)
n
log

an(x)

âˆ’n âˆ’an(x)
n
log

n âˆ’an(x)
,
= lim
nâ†’âˆ
+
log(n) âˆ’1 + x
2

log
1 + x
2

+ log(n)

âˆ’1 âˆ’x
2

log
1 âˆ’x
2

+ log(n)
,
= âˆ’1 + x
2
log
1 + x
2

âˆ’1 âˆ’x
2
log
1 âˆ’x
2

= âˆ’I(x) + log 2.
Together with (23.8), this implies (23.5).
âŠ“âŠ”
Under certain assumptions on the distribution of X1, CramÃ©râ€™s theorem [29]
provides a general principle to compute the rate function I.
Theorem 23.3 (CramÃ©r [29]) Let X1, X2, . . . be i.i.d. real random variables with
ï¬nite logarithmic moment generating function
Î›(t) := log E)etX1* < âˆ
for all t âˆˆR.
(23.9)
Let
Î›âˆ—(x) := sup
tâˆˆR

tx âˆ’Î›(t)

for x âˆˆR,
the Legendre transform of Î›. Then, for every x > E[X1],
lim
nâ†’âˆ
1
n log P
)
Sn â‰¥xn
*
= âˆ’I(x) := âˆ’Î›âˆ—(x).
(23.10)
Proof By passing to Xi âˆ’x if necessary, we may assume E[Xi] < 0 and x = 0.
(In fact, if ËœXi := Xi âˆ’x, and ËœÎ› and ËœÎ›âˆ—are deï¬ned as Î› and Î›âˆ—above but for ËœXi
instead of Xi, then ËœÎ›(t) = Î›(t)âˆ’t Â·x and thus ËœÎ›âˆ—(0) = suptâˆˆR(âˆ’ËœÎ›(t)) = Î›âˆ—(x).)

23.1
CramÃ©râ€™s Theorem
591
Deï¬ne Ï•(t) := eÎ›(t) and
Ï± := eâˆ’Î›âˆ—(0) = inf
tâˆˆRÏ•(t).
By (23.9) and the differentiation lemma (Theorem 6.28), Ï• is differentiable
inï¬nitely often and the ï¬rst two derivatives are
Ï•â€²(t) = E)X1 etX1*
and
Ï•â€²â€²(t) = E)X2
1 etX1*.
Hence Ï• is strictly convex and Ï•â€²(0) = E[X1] < 0.
First consider the case P[X1 â‰¤0] = 1. Then Ï•â€²(t) < 0 for every t âˆˆR and
Ï± = lim
tâ†’âˆÏ•(t) = P[X1 = 0]. Therefore,
P[Sn â‰¥0] = P[X1 = . . . = Xn = 0] = Ï±n
and thus the claim follows.
Now let P[X1 < 0] > 0 and P[X1 > 0] > 0. Then lim
tâ†’âˆÏ•(t) = âˆ=
lim
tâ†’âˆ’âˆÏ•(t). As Ï• is strictly convex, there is a unique Ï„ âˆˆR at which Ï• assumes
its minimum; hence
Ï•(Ï„) = Ï±
and
Ï•â€²(Ï„) = 0.
Since Ï•â€²(0) < 0, we have Ï„ > 0. Using Markovâ€™s inequality (Theorem 5.11), we
estimate
P[Sn â‰¥0] = P)eÏ„Sn â‰¥1* â‰¤E)eÏ„Sn* = Ï•(Ï„)n = Ï±n.
Thus we get the upper bound
lim sup
nâ†’âˆ
1
n log P[Sn â‰¥0] â‰¤log Ï± = âˆ’Î›âˆ—(0).
The remaining part of the proof is dedicated to verifying the reverse inequality:
lim inf
nâ†’âˆ
1
n log P[Sn â‰¥0] â‰¥log Ï±.
(23.11)
We use the method of an exponential size-biasing of the distribution Î¼ := PX1 of
X1, which turns the atypical values that are of interest here into typical values. That
is, we deï¬ne the CramÃ©r transform Ë†Î¼ âˆˆM1(R) of Î¼ by
Ë†Î¼(dx) = Ï±âˆ’1eÏ„xÎ¼(dx)
for x âˆˆR.

592
23
Large Deviations
Let Ë†X1, Ë†X2, . . . be independent and identically distributed with PË†Xi = Ë†Î¼. Then
Ë†Ï•(t) := E
)
et Ë†X1*
= 1
Ï±

R
etxeÏ„x Î¼(dx) = 1
Ï± Ï•(t + Ï„).
Hence
E
) Ë†X1] = Ë†Ï•â€²(0) = 1
Ï± Ï•â€²(Ï„) = 0,
Var
) Ë†X1] = Ë†Ï•â€²â€²(0) = 1
Ï± Ï•â€²â€²(Ï„) âˆˆ(0, âˆ).
Deï¬ning Ë†Sn = Ë†X1 + . . . + Ë†Xn, we get
P[Sn â‰¥0] =

{x1+...+xnâ‰¥0}
Î¼(dx1) Â· Â· Â· Î¼(dxn)
=

{x1+...+xnâ‰¥0}

Ï± eâˆ’Ï„x1
Ë†Î¼(dx1) Â· Â· Â·

Ï± eâˆ’Ï„xn
Ë†Î¼(dxn)
= Ï±n E
'
eâˆ’Ï„ Ë†Sn 1{ Ë†Snâ‰¥0}
(
.
Thus, in order to show (23.11), it is enough to show
lim inf
nâ†’âˆ
1
n log E
'
eâˆ’Ï„ Ë†Sn 1{ Ë†Snâ‰¥0}
(
â‰¥0.
(23.12)
However, by the central limit theorem (Theorem 15.38), for every c > 0,
1
n log E
'
eâˆ’Ï„ Ë†Sn 1{ Ë†Snâ‰¥0}
(
â‰¥1
n log E
'
eâˆ’Ï„ Ë†Sn 1{0â‰¤Ë†Snâ‰¤câˆšn }
(
â‰¥1
n log

eâˆ’Ï„câˆšn P
+ Ë†Sn
âˆšn âˆˆ[0, c]
,
nâ†’âˆ
âˆ’â†’
lim
nâ†’âˆ
âˆ’Ï„câˆšn
n
+ lim
nâ†’âˆ
1
n log

N0,Var[ Ë†X1]([0, c])

= 0.
âŠ“âŠ”
Example 23.4 If PX1 = N0,1, then
Î›(t) = log

E
)
etX1*
= log

1
âˆš
2Ï€
 âˆ
âˆ’âˆ
etxeâˆ’x2/2 dx

= t2
2 .

23.1
CramÃ©râ€™s Theorem
593
Furthermore,
Î›âˆ—(z) = sup
tâˆˆR

tz âˆ’Î›(t)

= sup
tâˆˆR

tz âˆ’t2
2

= z2
2 .
Hence the rate function coincides with that of (23.4). â™¦
Example 23.5 If PX1 = 1
2Î´âˆ’1 + 1
2Î´1, then Î›(t) = log cosh(t). The maximizer tâˆ—=
tâˆ—(z) of the variational problem for Î›âˆ—solves the equation z = Î›â€²(tâˆ—) = tanh(tâˆ—).
Hence
Î›âˆ—(z) = ztâˆ—âˆ’Î›(tâˆ—) = z arctanh(z) âˆ’log

cosh(arctanh(z))

.
Now arctanh(z) = 1
2 log 1 + z
1 âˆ’z for z âˆˆ(âˆ’1, 1) and
cosh

arctanh(z)

=
1
âˆš
1 âˆ’z2 =
1
âˆš(1 âˆ’z)(1 + z).
Therefore,
Î›âˆ—(z) = z
2 log(1 + z) âˆ’z
2 log(1 âˆ’z) + 1
2 log(1 âˆ’z) + 1
2 log(1 + z)
= 1 + z
2
log(1 + z) + 1 âˆ’z
2
log(1 âˆ’z).
However, this is the rate function from Theorem 23.1. â™¦
Takeaways For random variables with exponential moments, in the weak law
of large numbers, the probability for large deviations decays exponentially
fast. The rate for the decay can be computed via the Legendre transform of
the logarithmic moment generating function.
Exercise 23.1.1 Let X be a real random variable with density f (x) = câˆ’1
eâˆ’|x|
1 + |x|3 ,
where c =
 âˆ
âˆ’âˆ
eâˆ’|x|
1 + |x|3 dx. Check if the logarithmic moment generating function
Î› is continuous and sketch the graph of Î›. â™£
Exercise 23.1.2 Let X be a real random variable and let Î›(t) := log

E
)
etX*
,
t âˆˆR be its logarithmic moment generating function. Use HÃ¶lderâ€™s inequality to
show that Î› is convex and is strictly convex in the interval where it is ï¬nite (if X is
not almost surely constant). â™£

594
23
Large Deviations
23.2
Large Deviations Principle
The basic idea of CramÃ©râ€™s theorem is to quantify the probabilities of rare events
by an exponential rate and a rate function. In this section, we develop a formal
framework for the quantiï¬cation of probabilities of rare events in which the
complete theory of large deviations can be developed. For further reading, consult,
e.g., [31, 32] or [74].
Let E be a Polish space with complete metric d. Recall that
BÎµ(x) = {y âˆˆE : d(x, y) < Îµ}
denotes the open ball of radius Îµ > 0 that is centered at x âˆˆE.
A map f
: E
â†’R = [âˆ’âˆ, âˆ] is called lower semicontinuous if,
for every a âˆˆR, the level set f âˆ’1([âˆ’âˆ, a]) âŠ‚E is closed. (In particular,
continuous maps are lower semicontinuous. On the other hand, 1(0,1) : R â†’R
is lower semicontinuous but not continuous.) An equivalent condition for lower
semicontinuity is that limÎµâ†“0 inf f (BÎµ(x)) = f (x) for all x âˆˆE. (Recall that
inf f (A) = inf{f (x) : x âˆˆA}.) If K âŠ‚E is compact and nonempty, then f
assumes its inï¬mum on K. Indeed, for the case where f (x) = âˆfor all x âˆˆK,
the statement is trivial. Now assume inf f (K) < âˆ. If an â†“inf f (K) is strictly
monotone decreasing, then K âˆ©f âˆ’1([âˆ’âˆ, an]) Ì¸= âˆ…is compact for every n âˆˆN
and hence the inï¬nite intersection also is nonempty:
f âˆ’1(inf f (K)) = K âˆ©
âˆ

n=1
f âˆ’1([âˆ’âˆ, an]) Ì¸= âˆ….
Reï¬‚ection Check that suprema of lower semicontinuous functions are lower
semicontinuous. In particular, suprema of continuous functions are lower semicon-
tinuous. Which of the functions f (x) = 1{0}(x), g(x) = 1R\Z(x), h(x) = sin(1/x)
for x Ì¸= 0 and h(0) = âˆ’1, are lower semicontinuous? â™ 
Deï¬nition 23.6 (Rate function) A lower semicontinuous function I : E â†’[0, âˆ]
is called a rate function. If all level sets I âˆ’1([âˆ’âˆ, a]), a âˆˆ[0, âˆ), are compact,
then I is called a good rate function.
Deï¬nition 23.7 (Large deviations principle) Let I be a rate function and (Î¼Îµ)Îµ>0
be a family of probability measures on E. We say that (Î¼Îµ)Îµ>0 satisï¬es a large
deviations principle (LDP) with rate function I if
(LDP 1) lim inf
Îµâ†’0
Îµ log(Î¼Îµ(U)) â‰¥âˆ’infI(U)
for every open U âŠ‚E,
(LDP 2) lim sup
Îµâ†’0
Îµ log(Î¼Îµ(C)) â‰¤âˆ’inf I(C)
for every closed C âŠ‚E.
We say that a family (Pn)nâˆˆN of probability measures on E satisï¬es an LDP with
rate rn â†‘âˆand rate function I if (LDP 1) and (LDP 2) hold with Îµn = 1/rn and
Î¼1/rn = Pn.

23.2
Large Deviations Principle
595
Often (LDP 1) and (LDP 2) are referred to as lower bound and upper bound. In
many cases, the lower bound is a lot easier to show than the upper bound.
Before we show that CramÃ©râ€™s theorem is essentially an LDP, we make two
technical statements.
Theorem 23.8 The rate function in an LDP is unique.
Proof Assume that (Î¼Îµ)Îµ>0 satisï¬es an LDP with rate functions I and J. Then, for
every x âˆˆE and Î´ > 0,
I(x) â‰¥inf I(BÎ´(x))
â‰¥âˆ’lim inf
Îµâ†’0 Îµ log

Î¼Îµ(BÎ´(x))

â‰¥âˆ’lim sup
Îµâ†’0
Îµ log

Î¼Îµ

BÎ´(x)

â‰¥inf J

BÎ´(x)

Î´â†’0
âˆ’â†’J(x).
Hence I(x) â‰¥J(x). Similarly, we get J(x) â‰¥I(x).
âŠ“âŠ”
Lemma 23.9 Let N âˆˆN and let ai
Îµ, i = 1, . . . , N, Îµ > 0, be nonnegative numbers.
Then
lim sup
Îµâ†’0
Îµ log
N

i=1
ai
Îµ =
max
i=1,...,N lim sup
Îµâ†’0
Îµ log(ai
Îµ).
Proof The sum and maximum differ at most by a factor N:
max
i=1,...,N Îµ log(ai
Îµ) â‰¤Îµ log
N

i=1
ai
Îµ â‰¤Îµ log(N) +
max
i=1,...,N Îµ log(ai
Îµ).
The maximum and limit (superior) can be interchanged and hence
max
i=1,...,N lim sup
Îµâ†’0
Îµ log(ai
Îµ) = lim sup
Îµâ†’0
Îµ log

max
i=1,...,N ai
Îµ

â‰¤lim sup
Îµâ†’0
Îµ log
 N

i=1
ai
Îµ

â‰¤lim sup
Îµâ†’0
Îµ log(N) +
max
i=1,...,N lim sup
Îµâ†’0
Îµ log(ai
Îµ)
=
max
i=1,...,N lim sup
Îµâ†’0
Îµ log(ai
Îµ).
âŠ“âŠ”
Example 23.10 Let X1, X2, . . . be i.i.d. real random variables that satisfy the
condition of CramÃ©râ€™s theorem (Theorem 23.3); i.e., Î›(t) = log(E[etX1]) < âˆ

596
23
Large Deviations
for every t âˆˆR. Furthermore, let Sn = X1 +. . .+Xn for every n. We will show that
CramÃ©râ€™s theorem implies that Pn := PSn/n satisï¬es an LDP with rate n and with
good rate function I(x) = Î›âˆ—(x) := suptâˆˆR(tx âˆ’Î›(t)). Without loss of generality,
we can assume that E[X1] = 0. The function I is lower semicontinuous, strictly
convex (in the interval where it is ï¬nite) and has its unique minimum at I(0) = 0.
By convexity, we have I(y) > I(x) whenever y > x â‰¥0 or y < x â‰¤0.
CramÃ©râ€™s theorem says that limnâ†’âˆ1
n log(Pn([x, âˆ))) = âˆ’I(x) for x > 0
and (by symmetry) limnâ†’âˆ1
n log(Pn((âˆ’âˆ, x])) = âˆ’I(x) for x < 0. Clearly, for
x > 0,
âˆ’I(x) â‰¥lim inf
nâ†’âˆ
1
n log Pn((x, âˆ))
â‰¥sup
y>x
lim inf
nâ†’âˆ
1
n log Pn([y, âˆ)) = âˆ’inf
y>x I(y)
Similarly, lim inf
nâ†’âˆ
1
n log Pn((âˆ’âˆ, x)) â‰¥âˆ’inf
y<x I(y) for x < 0. Furthermore, by the
law of large numbers, for any x > 0, we have
lim
nâ†’âˆ
1
n log Pn((âˆ’x, âˆ)) = lim
nâ†’âˆ
1
n log Pn([âˆ’x, âˆ))
= lim
nâ†’âˆ
1
n log Pn((âˆ’âˆ, x)) = lim
nâ†’âˆ
1
n log Pn((âˆ’âˆ, x])) = 0 = âˆ’I(0).
The main work has been done by showing that the family (Pn)nâˆˆN satisï¬es
conditions (LDP 1) and (LDP 2) at least for unbounded intervals. It remains to show
by some standard arguments (LDP 1) and (LDP 2) for arbitrary open and closed
sets, respectively.
First assume that C âŠ‚R is closed. Deï¬ne x+ := inf

C âˆ©[0, âˆ)

as well as
xâˆ’:= sup

C âˆ©(âˆ’âˆ, 0]

. By monotonicity of I, on (âˆ’âˆ, 0] and [0, âˆ), we get
inf I(C) = I(xâˆ’) âˆ§I(x+) (with the convention I(âˆ’âˆ) = I(âˆ) = âˆ). If xâˆ’= 0
or x+ = 0, then inf(I(C)) = 0, and (LDP 2) holds trivially. Now let xâˆ’< 0 < x+.
Using Lemma 23.9, we get
lim sup
nâ†’âˆ
1
n log Pn(C)
â‰¤lim sup
nâ†’âˆ
1
n log Pn
(âˆ’âˆ, xâˆ’] + Pn
[x+, âˆ)
= max

lim sup
nâ†’âˆ
1
n log Pn

(âˆ’âˆ, xâˆ’]

, lim sup
nâ†’âˆ
1
n log Pn

[x+, âˆ)

= max 	 âˆ’I(xâˆ’), âˆ’I(x+)
 = âˆ’infI(C).
This shows (LDP 2).

23.2
Large Deviations Principle
597
Now let U âŠ‚R be open. Let x âˆˆU âˆ©[0, âˆ) with I(x) < âˆ(if such an x
exists). Then there exists an Îµ > 0 with (x âˆ’Îµ, x + Îµ) âŠ‚U. Now
lim inf
nâ†’âˆ
1
n log Pn

(x âˆ’Îµ, âˆ)

â‰¥âˆ’I(x) > âˆ’I(x + Îµ)
= lim
nâ†’âˆ
1
n log Pn

[x + Îµ, âˆ)

.
Therefore,
lim inf
nâ†’âˆ
1
n log Pn(U) â‰¥lim inf
nâ†’âˆ
1
n log Pn((x âˆ’Îµ, x + Îµ))
= lim inf
nâ†’âˆ
1
n log Pn
(x âˆ’Îµ, âˆ) âˆ’Pn
[x + Îµ, âˆ)
= lim inf
nâ†’âˆ
1
n log

Pn

(x âˆ’Îµ, âˆ)

â‰¥âˆ’I(x).
Similarly, this also holds for x âˆˆU âˆ©(âˆ’âˆ, 0) with I(x) < âˆ; hence
lim inf
nâ†’âˆ
1
n log Pn(U) â‰¥âˆ’inf I(U).
This shows the lower bound (LDP 1). â™¦
In fact, the condition Î›(t) < âˆfor all t âˆˆR can be dropped. Since Î›(0) = 0, we
have Î›âˆ—(x) â‰¥0 for every x âˆˆR. The map Î›âˆ—is a convex rate function but is, in
general, not a good rate function. We quote the following strengthening of CramÃ©râ€™s
Theorem(see [31, Theorem 2.2.3]).
Theorem 23.11 (CramÃ©r) If X1, X2, . . . are i.i.d. real random variables, then
(PSn/n)nâˆˆN satisï¬es an LDP with rate function Î›âˆ—.
Takeaways The distributions of the arithmetic means of a growing number
of i.i.d. random variables concentrate more and more around the expected
value (under certain regularity assumptions, that is). This behaviour has been
quantiï¬ed in Sect. 23.1. Here we have developed the abstract framework
(principle of large deviations) for the description of the speed of concentration
for a sequence of probability measures. Finally, we have shown that the results
for i.i.d. random variables that we had already ï¬t in this framework.
Exercise 23.2.1 Let E = R. Show that Î¼Îµ := N0,Îµ satisï¬es an LDP with good
rate function I(x) = x2/2. Further, show that strict inequality can hold in the upper
bound (LDP 2). â™£

598
23
Large Deviations
Exercise 23.2.2 Let E = R. Show that Î¼Îµ := N0,Îµ2 satisï¬es an LDP with good
rate function I(x) = âˆÂ· 1R\{0}(x). Further, show that strict inequality can hold in
the lower bound (LDP 1). â™£
Exercise 23.2.3 Let E = R. Show that Î¼Îµ := 1
2Nâˆ’1,Îµ + 1
2N1,Îµ satisï¬es an LDP
with good rate function I(x) = 1
2 min((x + 1)2, (x âˆ’1)2). â™£
Exercise 23.2.4 Compute Î› and Î›âˆ—in the case X1 âˆ¼expÎ¸ for Î¸ > 0. Interpret
the statement of Theorem 23.11 in this case. Check that Î›âˆ—has its unique zero at
E[X1]. (Result: Î›âˆ—(x) = Î¸x âˆ’log(Î¸x) âˆ’1 if x > 0 and = âˆotherwise.) â™£
Exercise 23.2.5 Compute Î› and Î›âˆ—for the case where X1 is Cauchy distributed
and interpret the statement of Theorem 23.11. â™£
Exercise 23.2.6 Let XÎ» âˆ¼PoiÎ» for every Î» > 0. Show that Î¼Îµ := PÎµXÎ»/Îµ satisï¬es
an LDP with good rate function I(x) = x log(x/Î») + Î» âˆ’x for x â‰¥0 (and = âˆ
otherwise). â™£
Exercise 23.2.7 Let (Xt)tâ‰¥0 be a random walk on Z in continuous time that makes
a jump to the right with rate 1
2 and a jump to the left also with rate 1
2. Show that
(PÎµX1/Îµ)Îµ>0 satisï¬es an LDP with convex good rate function
I(x) = 1 + x arcsinh(x) âˆ’
2
1 + x2.
â™£
23.3
Sanovâ€™s Theorem
This section is close to the exposition in [31].
We present a large deviations principle that, unlike CramÃ©râ€™s theorem, is not
based on a linear space. Rather, we consider empirical distributions of independent
random variables with values in a ï¬nite set Î£, which often is called an alphabet.
Let Î¼ be a probability measure on Î£ with Î¼({x}) > 0 for any x âˆˆÎ£. Further,
let X1, X2, . . . be i.i.d. random variables with values in Î£ and with distribution
PX1 = Î¼. We will derive a large deviations principle for the empirical measures
Î¾n(X) := 1
n
n

i=1
Î´Xi.
Note that by the law of large numbers, P-almost surely Î¾n(X)
nâ†’âˆ
âˆ’â†’Î¼. Hence, as
the state space we get E = M1(Î£), equipped with the metric of total variation
d(Î¼, Î½) = âˆ¥Î¼ âˆ’Î½âˆ¥T V . (As Î£ is ï¬nite, in E vague convergence, weak convergence
and convergence in total variation coincide.) Further, let
En :=

Î¼ âˆˆM1(Î£) : nÎ¼({x}) âˆˆN0 for every x âˆˆÎ£

be the range of the random variables Î¾n(X).

23.3
Sanovâ€™s Theorem
599
Recall that the entropy of Î¼ is deï¬ned by
H(Î¼) := âˆ’

log

Î¼({x})

Î¼(dx).
If Î½
âˆˆM1(Î£), then we deï¬ne the relative entropy (or Kullbackâ€“Leibler
information, see [104]) of Î½ given Î¼ by
H(Î½|Î¼) :=

log
 Î½({x})
Î¼({x})

Î½(dx).
(23.13)
Since Î¼({x}) > 0 for all x âˆˆÎ£, the integrand Î½-a.s. is ï¬nite and hence the integral
also is ï¬nite. A simple application of Jensenâ€™s inequality yields H(Î¼) â‰¥0 and
H(Î½|Î¼) â‰¥0 (see Lemma 5.26 and Exercise 5.3.3). Furthermore, H(Î½|Î¼) = 0 if
and only if Î½ = Î¼. In addition, clearly,
H(Î½|Î¼) + H(Î½) = âˆ’

log

Î¼({x})

Î½(dx).
(23.14)
Since the map Î½ â†’IÎ¼(Î½) := H(Î½|Î¼) is continuous, IÎ¼ is a rate function.
Lemma 23.12 For every n âˆˆN and Î½ âˆˆEn, we have
(n + 1)âˆ’#Î£eâˆ’n H(Î½ |Î¼) â‰¤P[Î¾n(X) = Î½] â‰¤eâˆ’n H(Î½ |Î¼).
(23.15)
Proof We consider the set of possible values for the n-tuple (X1, . . . , Xn) such that
Î¾n(X) = Î½:
An(Î½) :=

k = (k1, . . . , kn) âˆˆÎ£n : 1
n
n

i=1
Î´ki = Î½

.
For every k âˆˆAn(Î½), we have (compare (23.14))
P[Î¾n(X) = Î½] = #An(Î½) P[X1 = k1, . . . , Xn = kn]
= #An(Î½)

xâˆˆÎ£
Î¼({x})nÎ½({x})
= #An(Î½) exp

n

Î½(dx) log Î¼({x})

= #An(Î½) exp  âˆ’n[H(Î½) + H(Î½|Î¼)].
Now let Y1, Y2, . . . be i.i.d. random variables with values in Î£ and with distribution
PY1 = Î½. As in the calculation for X, we obtain (since H(Î½|Î½) = 0)
1 â‰¥P[Î¾n(Y) = Î½] = #An(Î½) eâˆ’nH(Î½);
hence #An(Î½) â‰¤enH(Î½). This implies the second inequality in (23.15).

600
23
Large Deviations
The random variable n Î¾n(Y) has the multinomial distribution with parameters
(nÎ½({x}))xâˆˆÎ£. Hence the map En â†’[0, 1], Î½â€² â†’P[Î¾n(Y) = Î½â€²] is maximal at
Î½â€² = Î½. Therefore,
#An(Î½) = enH(Î½) P[Î¾n(Y) = Î½] â‰¥enH(Î½)
#En
â‰¥(n + 1)âˆ’#Î£ enH(Î½).
This implies the ï¬rst inequality in (23.15).
âŠ“âŠ”
We come to the main theorem of this section, Sanovâ€™s theorem (see [150] and [151]).
Theorem 23.13 (Sanov [150]) Let X1, X2, . . . be i.i.d. random variables with
values in the ï¬nite set Î£ and with distribution Î¼. Then the family (PÎ¾n(X))nâˆˆN of
distributions of empirical measures satisï¬es an LDP with rate n and rate function
IÎ¼ := H( Â·|Î¼).
Proof By Lemma 23.12, for every A âŠ‚E,
P)Î¾n(X) âˆˆA* =

Î½âˆˆAâˆ©En
P[Î¾n(X) = Î½]
â‰¤

Î½âˆˆAâˆ©En
eâˆ’nH(Î½ |Î¼)
â‰¤#(A âˆ©En) exp

âˆ’n inf IÎ¼(A âˆ©En)

â‰¤(n + 1)#Î£ exp

âˆ’n inf IÎ¼(A)

.
Therefore,
lim sup
nâ†’âˆ
1
n log P[Î¾n(X) âˆˆA] â‰¤âˆ’inf IÎ¼(A).
Hence the upper bound in the LDP holds (even for arbitrary A).
Similarly, we can use the ï¬rst inequality in Lemma 23.12 to get
P)Î¾n(X) âˆˆA* â‰¥(n + 1)âˆ’#Î£ exp  âˆ’n inf IÎ¼(A âˆ©En)
and thus
lim inf
nâ†’âˆ
1
n log P
)
Î¾n(X) âˆˆA
*
â‰¥âˆ’lim sup
nâ†’âˆ
inf IÎ¼(A âˆ©En).
(23.16)
Note that, in this inequality, in the inï¬mum we cannot simply replace A âˆ©En by A.
However, we show that, for open A this can be done at least asymptotically. Hence,
let A âŠ‚E be open. For Î½ âˆˆA, there is an Îµ > 0 with BÎµ(Î½) âŠ‚A. For n â‰¥(2 #Î£)/Îµ,
we have En âˆ©BÎµ(Î½) Ì¸= âˆ…and hence there exists a sequence Î½n
nâ†’âˆ
âˆ’â†’Î½ with Î½n âˆˆ

23.3
Sanovâ€™s Theorem
601
En âˆ©A for large n âˆˆN. As IÎ¼ is continuous, we have
lim sup
nâ†’âˆ
inf IÎ¼(A âˆ©En) â‰¤lim
nâ†’âˆIÎ¼(Î½n) = IÎ¼(Î½).
Since Î½ âˆˆA is arbitrary, we get lim supnâ†’âˆinf IÎ¼(A âˆ©En) = inf IÎ¼(A).
âŠ“âŠ”
Example 23.14 Let Î£
= {âˆ’1, 1} and let Î¼ =
1
2Î´âˆ’1 + 1
2Î´1 be the uniform
distribution on Î£. Deï¬ne m = m(Î½) := Î½({1})âˆ’Î½({âˆ’1}). Then the relative entropy
of Î½ âˆˆM1(Î£) is
H(Î½|Î¼) = 1 + m
2
log(1 + m) + 1 âˆ’m
2
log(1 âˆ’m).
Note that this is the rate function from Theorem 23.1. â™¦
Next we describe formally the connection between the LDPs of Sanov and CramÃ©r
that was indicated in the previous example. To this end, we use Sanovâ€™s theorem to
derive a version of CramÃ©râ€™s theorem for Rd-valued random variables taking only
ï¬nitely many different values.
Example 23.15 Let Î£ âŠ‚Rd be ï¬nite and let Î¼ be a probability measure on Î£.
Further, let X1, X2, . . . be i.i.d. random variables with values in Î£ and distribution
PX1 = Î¼. Deï¬ne Sn = X1 + . . . + Xn for every n âˆˆN. Let Î›(t) = log E
)
eâŸ¨t,X1âŸ©*
for t âˆˆRd (which is ï¬nite since Î£ is ï¬nite) and Î›âˆ—(x) = suptâˆˆRd

âŸ¨t, xâŸ©âˆ’Î›(t)

for x âˆˆRd.
We show that PSn/n

nâˆˆN satisï¬es an LDP with rate n and rate function Î›âˆ—.
Let Î¾n(X) be the empirical measure of X1, . . . , Xn. Let E := M1(Î£). Deï¬ne
the map
m : E â†’Rd,
Î½ â†’

x Î½(dx) =

xâˆˆÎ£
x Î½({x}).
That is, m maps Î½ to its ï¬rst moment. Clearly, 1
nSn = m(Î¾n(X)). For x âˆˆRd and
A âŠ‚Rd, deï¬ne
Ex := mâˆ’1({x}) = {Î½ âˆˆE : m(Î½) = x}
and
EA = mâˆ’1(A) = {Î½ âˆˆE : m(Î½) âˆˆA}.
The map Î½ â†’m(Î½) is continuous; hence EA is open (respectively closed) if A is
open (respectively closed). Let ËœI(x) := inf IÎ¼(Ex) (where IÎ¼(Î½) = H(Î½|Î¼) is the

602
23
Large Deviations
relative entropy). Then, by Sanovâ€™s theorem for open U âŠ‚Rd,
lim inf
nâ†’âˆ
1
n log PSn/n(U) = lim inf
nâ†’âˆ
1
n log PÎ¾n(X)
mâˆ’1(U)
â‰¥âˆ’inf IÎ¼

mâˆ’1(U)

= âˆ’inf ËœI(U).
Similarly, for closed C âŠ‚Rd, we have
lim sup
nâ†’âˆ
1
n log PSn/n(C) â‰¤âˆ’inf ËœI(C).
In other words, (PSn/n)nâˆˆN satisï¬es an LDP with rate n and rate function ËœI. Hence,
it only remains to show that ËœI = Î›âˆ—.
Note that t â†’Î›(t) is differentiable (with derivative Î›â€²) and is strictly convex.
Hence the variational problem for Î›âˆ—(x) admits a unique maximizer tâˆ—(x). More
precisely,
Î›âˆ—(x) = âŸ¨tâˆ—(x), xâŸ©âˆ’Î›(tâˆ—(x)),
Î›âˆ—(x) > âŸ¨t, xâŸ©âˆ’Î›(t) for all t Ì¸= tâˆ—(x), and Î›â€²(tâˆ—(x)) = x. By Jensenâ€™s inequality,
for every Î½ âˆˆM1(Î£),
Î›(t) = log

eâŸ¨t,yâŸ©Î¼(dy)
= log
 
eâŸ¨t,yâŸ©Î¼({y})
Î½({y})

Î½(dy)
â‰¥

log

eâŸ¨t,yâŸ©Î¼({y})
Î½({y})

Î½(dy)
= âŸ¨t, m(Î½)âŸ©âˆ’H(Î½|Î¼)
with equality if and only if Î½ = Î½t, where Î½t({y}) = Î¼({y})eâŸ¨t,yâŸ©âˆ’Î›(t). Hence,
âŸ¨t, xâŸ©âˆ’Î›(t) â‰¤inf
Î½âˆˆEx H(Î½|Î¼)
with equality if Î½t âˆˆEx. However, we now know that m(Î½t) = Î›â€²(t); hence we
have Î½tâˆ—(x) âˆˆEx and thus
Î›âˆ—(x) = âŸ¨tâˆ—(x), xâŸ©âˆ’Î›(tâˆ—(x)) =
inf
Î½âˆˆEx H(Î½|Î¼) = ËœI(x).
â™¦

23.4
Varadhanâ€™s Lemma and Free Energy
603
The method of the proof that we applied in the last example to derive the LDP with
rate function ËœI is called a contraction principle. We formulate this principle as a
theorem.
Theorem 23.16 (Contraction principle) Assume the family (Î¼Îµ)Îµ>0 of probability
measures on E satisï¬es an LDP with rate function I. If F is a topological space and
m : E â†’F is continuous, then the image measures (Î¼Îµ â—¦mâˆ’1)Îµ>0 satisfy an LDP
with rate function ËœI(x) = inf I(mâˆ’1({x})).
Takeaways Consider an i.i.d. sequence of random variables with values in a
ï¬nite set. The empirical distributions converge to the distribution of the ran-
dom variables. The speed of convergence is exponential and the exponential
rate function is the relative entropy. Using the contraction principle this large
deviations principle can be reduced to functions of the random variables. In
particular, we can recover CramÃ©râ€™s theorem for random variables that take
only ï¬nitely many d-dimensional values.
23.4
Varadhanâ€™s Lemma and Free Energy
Assume that (Î¼Îµ)Îµ>0 is a family of probability measures that satisï¬es an LDP with
rate function I. In particular, we know that, for small Îµ > 0, the mass of Î¼Îµ is
concentrated around the zeros of I. In statistical physics, one is often interested in
integrating with respect to Î¼Îµ (where 1/Îµ is interpreted as â€œsize of the systemâ€)
functions that attain their maximal values away from the zeros of I. In addition,
these functions are exponentially scaled with 1/Îµ. Hence the aim is to study the
asymptotics of ZÏ†
Îµ :=
3
eÏ†(x)/ÎµÎ¼Îµ(dx) as Îµ â†’0. Under some mild conditions
on the continuity of Ï†, the main contribution to the integral comes from those
points x that are not too unlikely (for Î¼Îµ) and for which at the same time Ï†(x)
is large. That is, those x for which Ï†(x) âˆ’I(x) is close to its maximum. These
contributions are quantiï¬ed in terms of the tilted probability measures Î¼Ï†
Îµ (dx) =
(ZÏ†
Îµ )âˆ’1eÏ†(x)/ÎµÎ¼Îµ(dx), Îµ > 0, for which we derive an LDP. As an application, we
get the statistical physics principle of minimising the free energy. As an example,
we analyze the Weiss ferromagnet.
We start with a lemma that is due to Varadhan [167].
Theorem 23.17 (Varadhanâ€™s Lemma [167]) Let I be a good rate function and let
(Î¼Îµ)Îµ>0 be a family of probability measures on E that satisï¬es an LDP with rate
function I. Further, let Ï† : E â†’R be continuous and assume that
inf
M>0 lim sup
Îµâ†’0
Îµ log

eÏ†(x)/Îµ 1{Ï†(x)â‰¥M} Î¼Îµ(dx) = âˆ’âˆ.
(23.17)

604
23
Large Deviations
Then
lim
Îµâ†’0 Îµ log

eÏ†(x)/Îµ Î¼Îµ(dx) = sup
xâˆˆE

Ï†(x) âˆ’I(x)

.
(23.18)
Remark 23.18 (Moment condition) The tail condition (23.17) holds if there exists
an Î± > 1 such that
lim sup
Îµâ†’0
Îµ log

eÎ±Ï†/Îµ dÎ¼Îµ < âˆ.
(23.19)
Indeed, for every M âˆˆR, we have
Îµ log

eÏ†(x)/Îµ 1{Ï†(x)â‰¥M} Î¼Îµ(dx) = M + Îµ log

e(Ï†(x)âˆ’M)/Îµ 1{Ï†(x)â‰¥M} Î¼Îµ(dx)
â‰¤M + Îµ log

eÎ±(Ï†(x)âˆ’M)/Îµ Î¼Îµ(dx)
= âˆ’(Î± âˆ’1)M + Îµ log

eÎ±Ï†(x)/Îµ Î¼Îµ(dx).
Together with (23.19), this implies (23.17). â™¦
Proof We use different arguments to show that the right-hand side of (23.18) is a
lower and an upper bound for the left-hand side.
Lower bound For any x âˆˆE and r > 0, we have
lim inf
Îµâ†’0
Îµ log

eÏ†/Îµ dÎ¼Îµ â‰¥lim inf
Îµâ†’0
Îµ log

Br(x)
eÏ†/Îµ dÎ¼Îµ
â‰¥inf Ï†(Br(x)) âˆ’I(x)
râ†’0
âˆ’â†’Ï†(x) âˆ’I(x).
Upper bound For M > 0 and Îµ > 0, deï¬ne
F Îµ
M :=

{Ï†â‰¥M}
eÏ†(x)/Îµ Î¼Îµ(dx)
and
GÎµ
M :=

{Ï†<M}
eÏ†(x)/Îµ Î¼Îµ(dx).
Deï¬ne
FM := lim sup
Îµâ†’0
Îµ log F Îµ
M
and
GM := lim sup
Îµâ†’0
Îµ log GÎµ
M.
By Lemma 23.9, for any M > 0,
lim sup
Îµâ†’0
Îµ log

eÏ†(x)/Îµ Î¼Îµ(dx) = FM âˆ¨GM.

23.4
Varadhanâ€™s Lemma and Free Energy
605
As by assumption infM>0 FM = âˆ’âˆ, it is enough to show that
sup
M>0
GM â‰¤sup
xâˆˆE

Ï†(x) âˆ’I(x)

.
(23.20)
Let Î´ > 0. For any x âˆˆE there is an r(x) > 0 with
inf I

B2r(x)(x)

â‰¥I(x) âˆ’Î´
and
sup Ï†

B2r(x)(x)

â‰¤Ï†(x) + Î´.
Let a â‰¥0. Since I is a good rate function, the level set K := I âˆ’1([0, a])
is compact. Thus we can ï¬nd ï¬nitely many x1, . . . , xN âˆˆI âˆ’1([0, a]) such that
N
i=1 Br(xi)(xi) âŠƒK. Therefore,
GÎµ
M â‰¤

{Ï†<M}âˆ©Kc eÏ†(x)/Îµ Î¼Îµ(dx) +
N

i=1

{Ï†<M}âˆ©Br(xi )(xi)
eÏ†(x)/Îµ Î¼Îµ(dx)
â‰¤eM/ÎµÎ¼Îµ(Kc) +
N

i=1
e(Ï†(xi)âˆ§M+Î´)/ÎµÎ¼Îµ

Br(xi)(xi)

= e(M+Îµ log(Î¼Îµ(Kc)))/Îµ +
N

i=1
e(Ï†(xi)âˆ§M+Î´+Îµ log(Î¼Îµ(Br(xi)(xi))))/Îµ.
Using Lemma 23.9 and the LDP, we infer
GM â‰¤(M âˆ’a) âˆ¨
max
i=1,...,N

Ï†(xi) âˆ’I(xi) + 2Î´

â‰¤(M âˆ’a) âˆ¨sup
xâˆˆE

Ï†(x) âˆ’I(x)

+ 2Î´.
By letting ï¬rst Î´ â†“0 and then a â†‘âˆ, we obtain (23.20).
âŠ“âŠ”
Theorem 23.19 (Tilted LDP) Assume that (Î¼Îµ)Îµ>0 satisï¬es an LDP with good
rate function I. Further, let Ï† : E â†’R be a continuous function that satisï¬es
condition (23.17). Deï¬ne ZÏ†
Îµ :=
3
eÏ†/Îµ dÎ¼Îµ and Î¼Ï†
Îµ âˆˆM1(E) by
Î¼Ï†
Îµ (dx) = (ZÏ†
Îµ )âˆ’1 eÏ†(x)/Îµ Î¼Îµ(dx).
Further, deï¬ne I Ï† : E â†’[0, âˆ] by
I Ï†(x) = sup
zâˆˆE
Ï†(z) âˆ’I(z) âˆ’Ï†(x) âˆ’I(x).
(23.21)
Then (Î¼Ï†
Îµ )Îµ>0 satisï¬es an LDP with rate function I Ï†.

606
23
Large Deviations
Proof This is left as an exercise. (Compare [32, Exercise 2.1.24], see also [43,
Section II.7].)
âŠ“âŠ”
Varadhanâ€™s lemma has various applications in statistical physics. Consider a Polish
space Î£ that is interpreted as the space of possible states of a particle. Further,
let Î» âˆˆM1(Î£) be a distribution that is understood as the a priori distribution
of this particle if the inï¬‚uence of energy could be neglected. If Î£ is ï¬nite or is a
bounded subset of an Rd, then by symmetry, typically Î» is the uniform distribution
on Î£. If we place n indistinguishable particles independently according to Î» on the
random positions z1, . . . , zn âˆˆÎ£, then the state of this ensemble can be described
by x :=
1
n
n
i=1 Î´zi. Denote by Î¼0
n âˆˆM1(M1(Î£)) the corresponding a priori
distribution of x; that is, of the n-particle system.
Now we introduce the hypothesis that the energy Un(x) of a state has the form
Un(x) = nU(x), where U(x) is the average energy of one particle of the ensemble
in state x.
Let T > 0 be the temperature of the system and let Î² := 1/T be the so-called
inverse temperature. In statistical physics, a key quantity is the so-called partition
function
ZÎ²
n :=

eâˆ’Î²Un dÎ¼0
n.
A postulate of statistical physics is that the distribution of the state x is the
Boltzmann distribution:
Î¼Î²
n(dx) = (ZÎ²
n )âˆ’1 eâˆ’Î²Un(x) Î¼0
n(dx).
(23.22)
Varadhanâ€™s lemma (more precisely, the tilted LDP) and Sanovâ€™s theorem are the
keys to building a connection to the variational principle for the free energy. For
simplicity, assume that Î£ is a ï¬nite set and Î» = UÎ£ is the uniform distribution
on Î£. By Sanovâ€™s theorem, (Î¼0
n)nâˆˆN satisï¬es an LDP with rate n and rate function
I(x) = H(x|Î»), where H(x|Î») is the relative entropy of x with respect to Î». By
(23.14), we have H(x|Î») = log(#Î£) âˆ’H(x), where H(x) is the entropy of x.
Deï¬ne the free energy (or Helmholtz potential) per particle as
F Î²(x) := U(x) âˆ’Î²âˆ’1H(x).
The theorem on the tilted LDP yields that the sequence of Boltzmann distributions
(Î¼Î²
n)nâˆˆN satisï¬es an LDP with rate n and rate function
I Î²(x) = Î² Â·

F Î²(x) âˆ’
inf
yâˆˆM1(Î£) F Î²(y)

.
Thus, for large n, the Boltzmann distribution is concentrated on those x that
minimize the free energy. For different temperatures (that is, for different values

23.4
Varadhanâ€™s Lemma and Free Energy
607
of Î²) these can be very different states. This is the reason for phase transitions at
critical temperatures (e.g., melting ice).
Example 23.20 We consider the Weiss ferromagnet. This is a microscopic model
for a magnet that assumes that each of n indistinguishable magnetic particles has
one of two possible orientations Ïƒi âˆˆÎ£ = {âˆ’1, +1}. The mean magnetization
m = 1
n
n
i=1 Ïƒi describes the state of the system completely (as the particles are
indistinguishable). Macroscopically, this is the quantity that can be measured. The
basic idea is that it is energetically favorable for particles to be oriented in the same
direction. We ignore the spatial structure and assume that any particle interacts with
any other particle in the same way. This is often called the mean ï¬eld assumption.
In addition, we assume that there is an exterior magnetic ï¬eld of strength h. Thus
up to constants the average energy of a particle is
U(m) = âˆ’1
2m2 âˆ’hm.
The entropy of the state m is
H(m) = âˆ’1 + m
2
log
1 + m
2

âˆ’1 âˆ’m
2
log
1 âˆ’m
2

.
Hence the average free energy of a particle is
F Î²(m) = âˆ’1
2m2 âˆ’hm + Î²âˆ’1'1 + m
2
log
1 + m
2

+ 1 âˆ’m
2
log
1 âˆ’m
2
(
.
In order to obtain the minima of F Î², we compute the derivative
0 !=
d
dmF Î²(m) = âˆ’m âˆ’h + Î²âˆ’1 arctanh(m).
Hence, m solves the equation
m = tanh(Î²(m + h)).
(23.23)
In the case h = 0, m = 0 is a solution of (23.23) for any Î². If Î² â‰¤1, then this is the
only solution and F Î² attains its global minimum at m = 0. If Î² > 1, then (23.23)
has two other solutions, mÎ²,0
âˆ’
âˆˆ(âˆ’1, 0) and mÎ²,0
+
= âˆ’mÎ²,0
âˆ’, whose values can only
be computed numerically (Fig. 23.2).
In this case, F Î² has a local maximum at 0 and has global minima mÎ²,0
Â± . For
large n, only those values of m for which F Î² is close to its minimal value can be
attained and thus the distribution is concentrated around 0 if Î² â‰¤1 and around
mÎ²,0
Â±
if Î² > 1. In the latter case, the absolute value of the mean magnetization
is
mÎ²,0
Â±
 = mÎ²,0
+
> 0. Hence, there is a phase transition between the high
temperature phase (Î² â‰¤1) without magnetization and the low temperature phase

608
23
Large Deviations
Fig. 23.2 The shifted free energy F Î²(m) âˆ’F Î²(0) of the Weiss ferromagnet without exterior ï¬eld
(h = 0).
Fig. 23.3 Shifted free energy F Î²(m) âˆ’F Î²(0) of the Weiss ferromagnet with exterior ï¬eld h =
0.04.
(Î² > 1) where so-called spontaneous magnetization occurs (that is, magnetization
without an exterior ï¬eld).
If h Ì¸= 0, then F Î² does not have a minimum at m = 0. Rather, F Î² is asymmetric and
has a global minimum mÎ²,h with the same sign as h. Furthermore, for large Î², there
is another minimum with the opposite sign (Fig. 23.3). Again, the exact values can

23.4
Varadhanâ€™s Lemma and Free Energy
609
Fig. 23.4 Weiss ferromagnet: magnetization mÎ²,h as a function of Î².
only be computed numerically (Fig. 23.4). However, for high temperatures (small
Î²), we can approximate mÎ²,h using the approximation tanh(Î²(m+h)) â‰ˆÎ²(m+h).
Hence we get
mÎ²,h â‰ˆ
h
Î²âˆ’1 âˆ’1 =
h
T âˆ’Tc
for T â†’âˆ,
(23.24)
where the Curie temperature Tc = 1 is the critical temperature for spontaneous
magnetization. The relation (23.24) is called the Curieâ€“Weiss law. â™¦
Takeaways In the context of statistical mechanics, substantial contributions
to an observable are not only due to the most frequent observations but
also due to rare but very large observations. In order to compute the mean
values and to identify the states that yield signiï¬cant contributions, we have
established a so-called tilted large deviations principle. The rate function that
shows up here is the analogue to the free energy of thermodynamics.Applying
this formalism we have been able to describe the phase transition of the Weiss
ferromagnet.

Chapter 24
The Poisson Point Process
Poisson point processes can be used as a cornerstone in the construction of very
different stochastic objects such as, for example, inï¬nitely divisible distributions,
Markov processes with complex dynamics, objects of stochastic geometry and so
forth.
In this chapter, we brieï¬‚y develop the general framework of random measures
and construct the Poisson point process and characterize it in terms of its Laplace
transform. As an application we construct a certain subordinator and show that the
Poisson point process is the invariant measure of systems of independent random
walks. Via the connection with subordinators, in the third section, we construct two
distributions that play prominent roles in population genetics: the Poissonâ€“Dirichlet
distribution and the GEM distribution.
For a nice exposition including many examples, see also [99].
24.1
Random Measures
In the following, let E be a locally compact Polish space (for example, E = Rd or
E = Zd) with Borel Ïƒ-algebra B(E). Let
Bb(E) = 	B âˆˆB(E) : B is relatively compact
be the system of bounded Borel sets and M(E) the space of Radon measures on E
(see Deï¬nition 13.3).
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_24
611

612
24
The Poisson Point Process
Deï¬nition 24.1 Denote by M = Ïƒ(IA : A âˆˆBb(E)) the smallest Ïƒ-algebra on
M(E) with respect to which all maps
IA : Î¼ â†’Î¼(A),
A âˆˆBb(E),
are measurable.
Denote by B+(E) the set of measurable maps E â†’[0, âˆ] and by BR
b (E) the set of
bounded measurable maps E â†’R with compact support. For every f âˆˆB+(E),
the integral If (Î¼) :=
3
f dÎ¼ is well-deï¬ned and for every f âˆˆBR
b (E), If (Î¼) is
well-deï¬ned and ï¬nite.
Theorem 24.2 Let Ï„v be the vague topology on M(E). Then
M = B(Ï„v) = Ïƒ

If : f âˆˆCc(E)

= Ïƒ

If : f âˆˆC+
c (E)

.
Proof This is left as an exercise. (See [82, Lemma 4.1].)
âŠ“âŠ”
Let Q
M(E) be the space of all measures on E endowed with the Ïƒ-algebra

M = Ïƒ

IA : A âˆˆBb(E)

.
Choose a countable basis U of the topology consisting of relatively compact sets.
Then we get (compare Exercise 13.1.8)
M(E) =

UâˆˆU
	Î¼ âˆˆQ
M(E) : Î¼(U) < âˆ
.
Hence M(E) âˆˆ
M. Clearly, M = 
MM(E) is the trace Ïƒ-algebra of 
M on M(E).
Here we need the slightly larger space in order to deï¬ne random measures in such a
way that all almost surely well-deï¬ned operations on random measures again yield
random measures.
Deï¬nition 24.3 A random measure on E is a random variable X on some
probability space (Î©, A, P) with values in ( Q
M(E), 
M) and with P[X âˆˆM(E)] =
1.
Theorem 24.4 Let X be a random measure on E. Then the set function E[X] :
B(E) â†’[0, âˆ], A â†’E[X(A)] is a measure. We call E[X] the intensity measure
of X. We say that X is integrable if E[X] âˆˆM(E).
Proof Clearly, E[X] is ï¬nitely additive. Let A, A1, A2, . . . âˆˆB(E) with An â†‘A.
Consider the random variables Yn := X(An) and Y = X(A). Then Yn â†‘Y and
hence, by monotone convergence, E[X](An) = E[Yn]
nâ†’âˆ
âˆ’â†’E[Y] = E[X](A).
Hence E[X] is lower semicontinuous and is thus a measure (by Theorem 1.36).
âŠ“âŠ”

24.1
Random Measures
613
Theorem 24.5 Let PX be the distribution of a random measure X. Then PX is
uniquely determined by the distributions of either of the families

(If1, . . . , Ifn) : n âˆˆN; f1, . . . , fn âˆˆC+
c (E)

(24.1)
or

(IA1, . . . , IAn) : n âˆˆN; A1, . . . , An âˆˆBb(E) pairwise disjoint

.
(24.2)
Proof The class of sets
I =
	
(If1, . . . , Ifn)âˆ’1(A) : n âˆˆN; f1, . . . , fn âˆˆC+
c (E), A âˆˆB([0, âˆ)n)

is a Ï€-system and by Theorem 24.2 it generates M. Hence the measure PX is
characterized by its values on I.
Similarly, the claim follows for
(IA1, . . . , IAn) : n âˆˆN; A1, . . . , An âˆˆBb(E).
If A1, . . . , An âˆˆBb(E) are arbitrary, then there exist 2n âˆ’1 pairwise disjoint sets
B1, . . . , B2nâˆ’1 with Ai = 
k: BkâŠ‚Ai Bk for all i = 1, . . . , n. The distribution of
(IA1, . . . , IAn) can be computed from that of (IB1, . . . , IB2nâˆ’1).
âŠ“âŠ”
In the following, let i =
âˆš
âˆ’1 be the imaginary unit.
Deï¬nition 24.6 Let X be a random measure on E. Denote by
LX(f ) = E
'
exp

âˆ’

f dX
(
,
f âˆˆB+(E),
the Laplace transform of X and by
Ï•X(f ) = E
'
exp

i

f dX
(
,
f âˆˆBR
b (E),
the characteristic function of X.
Theorem 24.7 The distribution PX of a random measure X is characterized by its
Laplace transform LX(f ), f âˆˆC+
c (E), as well as by its characteristic function
Ï•X(f ), f âˆˆCc(E).
Proof This is a consequence of Theorem 24.5 and the uniqueness theorem for char-
acteristic functions (Theorem 15.9) and for Laplace transforms (Exercise 15.1.2) of
random variables on [0, âˆ)n.
âŠ“âŠ”
Deï¬nition 24.8 We say that a random measure X on E has independent
increments if, for any choice of ï¬nitely many pairwise disjoint measurable sets
A1, . . . , An, the random variables X(A1), . . . , X(An) are independent.

614
24
The Poisson Point Process
Corollary 24.9 The distribution of a random measure X on E with independent
increments is uniquely determined by the family (PX(A), A âˆˆBb(E)).
Proof This is an immediate consequence of Theorem 24.5.
âŠ“âŠ”
Deï¬nition 24.10 Let Î¼ âˆˆM(E). A random measure X with independent incre-
ments is called a Poisson point process (PPP) with intensity measure Î¼ if, for any
A âˆˆBb(E), we have PX(A) = PoiÎ¼(A). In this case, we write PPPÎ¼ := PX âˆˆ
M1(M(E)) and say that X is a PPPÎ¼.
See Fig. 24.1 for a simulation of a Poisson point process on the unit square.
Remark 24.11 The deï¬nition of the PPP (and its construction in the following
theorem) still works if (E, E, Î¼) is only assumed to be a Ïƒ-ï¬nite measure space.
However, the characterization in terms of Laplace transforms is a bit simpler in the
case of locally compact Polish spaces considered here. â™¦
Theorem 24.12 For every Î¼ âˆˆM(E), there exists a Poisson point process X with
intensity measure Î¼.
Proof Î¼ is Ïƒ-ï¬nite since Î¼ âˆˆM(E). Hence there exist En â†‘E with Î¼(En) < âˆ
for every n âˆˆN. Deï¬ne Î¼1 = Î¼(E1 âˆ©Â·) and Î¼n = Î¼((En \ Enâˆ’1) âˆ©Â·) for n â‰¥
2. If X1, X2, . . . are independent Poisson point processes with intensity measures
Î¼1, Î¼2, . . ., then X = âˆ
n=1 Xn has intensity measure E[X] = Î¼ and hence X is
a random measure (see Exercise 24.1.1). Furthermore, it is easy to see that X has
Fig. 24.1 Poisson point process on the unit square with intensity measure 50Î».

24.1
Random Measures
615
independent increments and that
PX(A) = PX1(A) âˆ—PX2(A) âˆ—. . . = PoiÎ¼1(A) âˆ—PoiÎ¼2(A) âˆ—. . . = PoiÎ¼(A).
Hence we have X âˆ¼PPPÎ¼.
Therefore, it is enough to consider the case Î¼(E) âˆˆ(0, âˆ). Deï¬ne
Î½ = Î¼( Â·)
Î¼(E) âˆˆM1(E).
Let N, Y1, Y2, . . . be independent random variables with N âˆ¼PoiÎ¼(E) and PYi = Î½
for all i âˆˆN. Deï¬ne
X(A) =
N

n=1
1A(Yn)
for A âˆˆB(E).
The random variables 1A(Y1), 1A(Y2), . . . are independent and BerÎ½(A)-distributed;
hence we have X(A) âˆ¼PoiÎ¼(A) (see Theorem 15.15(iii)). Let n âˆˆN and let
A1, . . . , An âˆˆB(E) be pairwise disjoint. Then
Ïˆ(t) := E
'
exp

i
n

l=1
tl 1Al(Y1)
(
= 1 +
n

l=1
Î½(Al)ei tl âˆ’1,
t âˆˆRn,
is the characteristic function of (1A1(Y1), . . . , 1An(Y1)). Further, let Ï• be the
characteristic function of (X(A1), . . . , X(An)) and let Ï•l be the characteristic
function of X(Al) for l = 1, . . . , n. Hence Ï•l(tl) = exp(Î¼(Al)(eitl âˆ’1)). By
Theorem 15.15(iii), we have
Ï•(t) = E
'
exp

i
n

l=1
tl X(Al)
(
= exp Î¼(E)(Ïˆ(t) âˆ’1)
= exp

n

l=1
Î¼(Al)

ei tl âˆ’1

=
n

l=1
Ï•l(tl).
Thus X(A1), . . . , X(An) are independent. This implies X âˆ¼PPPÎ¼.
âŠ“âŠ”
Takeaways A random measure is a random variable taking values in the
space of Radon measures on a set E. For measurable A âŠ‚E, the intensity
measure yields the expected value of this random variable. The distribution of
a random measure is characterised by its characteristic function as well as by
its Laplace transform. The Poisson point process is a speciï¬c random measure
taking only integer values and whose values on disjoint sets are independent
and Poisson distributed. An example are the ï¬rst rain drops you see on the
side walk.

616
24
The Poisson Point Process
Exercise 24.1.1 Let X1, X2, . . . be random measures and Î»1, Î»2, . . . âˆˆ[0, âˆ).
Deï¬ne X := âˆ
n=1 Î»nXn. Show that X is a random measure if and only if we
have P[X(B) < âˆ] = 1 for all B âˆˆBb(E). Infer that if X is a random variable
with values in
 Q
M(E), 
M(E)

and E[X] âˆˆM(E), then X is a random measure. â™£
Exercise 24.1.2 Let Ï„w be the topology of weak convergence on M1(E) and let
Ïƒ(Ï„w) be the Borel Ïƒ-algebra on M1(E). Show that MM1(E) = Ïƒ(Ï„w). â™£
24.2
Properties of the Poisson Point Process
RÃ©nyiâ€™s Theorem
A measure Î¼ is called atom-free, if Î¼({x}) = 0 for all x âˆˆE. An integer valued
measure Î½ is said to have no double points, if Î½({x}) âˆˆ{0, 1} for all x âˆˆE. For a
random integer valued measure the property to have no double points is in fact an
event (i.e., it is measurable). This will be shown in the subsequent considerations.
In order to illustrate the main idea, ï¬rst assume that Î½ is a ï¬nite integer valued
measure on (0, 1]. Then Î½ has no double points if and only if
lim
nâ†’âˆ
sup
k=0,...,2nâˆ’1
Î½
 k
2n , k + 1
2n
(
â‰¤1.
(24.3)
Note that the condition Î½({x}) âˆˆ{0, 1} has to be fulï¬lled for uncountably many
x âˆˆ(0, 1] while condition (24.3) is a limit of conditions each involving only ï¬nitely
many subsets of (0, 1]. In particular, for a ï¬nite integer valued random measure X
on (0, 1], the property to have no double points

X({x}) â‰¤1âˆ€x âˆˆ(0, 1]

=

lim
nâ†’âˆ
sup
k=0,...,2nâˆ’1
X
 k
2n , k + 1
2n
(
â‰¤1

(24.4)
is an event. In order to show the same statement for E a locally compact Polish space
(instead of (0, 1]) we have to spend a little work. Hence, let X be a random integer
valued measure on E. Since E is Ïƒ-compact, there exists a sequence (En)nâˆˆN of
compacts with En â†‘E. It is clearly enough to show that X has almost surely no
double points on any En. Hence, without loss of generality we may and will assume
that E is compact. Since X is locally ï¬nite almost surely, as a consequence X is
ï¬nite almost surely. As E is compact, it is totally bounded. That is, for any n âˆˆN,
we can cover E by ï¬nitely many open sets Bn
1 , . . . , Bn
Nn with diameter less than 2âˆ’n
(see Lemma 13.2). By building intersections for any choice of k1 âˆˆ{1, . . . , N1}, ...,
kn âˆˆ{1, . . . , Nn}, we get the open sets
ËœBk1,...,kn :=
n

m=1
Bm
km.

24.2
Properties of the Poisson Point Process
617
By a suitable rearranging of the enumeration, we call these sets also Bn
k , k =
1, . . . , Nn. By construction, for any Bn+1
k
, there is an l such that Bn+1
k
âŠ‚Bn
l . We
construct a measurable partition of E by letting Dn
1 := Bn
1 and deï¬ning successively
Dn
k := Bn
k \
kâˆ’1

l=1
Bn
l .
In fact, the sets Dn
1, . . . , Dn
Nn âˆˆB(E) are pairwise disjoint, have diameters at most
2âˆ’n, and cover E. Note that the partition Dn+1 := {Dn+1
k
: k = 1, . . . , Nn+1}
is a reï¬nement of Dn for any n. That is, for any D = Dn+1
k
âˆˆDn+1, there is a
Dâ€² = Dn
l âˆˆDn such that D âŠ‚Dâ€². By construction, for any sequence (Dn) with
Dn âˆˆDn, n âˆˆN, we either have âˆ
n=1 Dn = âˆ…or âˆ
n=1 Dn = {x} for some x âˆˆE.
If Î¼ âˆˆMf (E) then by upper continuity, we have
lim
nâ†’âˆ
sup
k=1,...,Nn
Î¼(Dn
k ) = sup
xâˆˆE
Î¼({x}).
(24.5)
Hence, the integer valued random measure X has almost surely no double points if
and only if
lim
nâ†’âˆ
sup
k=1,...,Nn
X(Dn
k ) â‰¤1
a.s.
(24.6)
For the case E = R, the following theorem goes back to RÃ©nyi [142, Theorem 2].
Theorem 24.13 (RÃ©nyiâ€™s theorem [142]) Let Î¼ âˆˆM(E) be atom-free and let X
be an integer valued random measure on E. Then the following two statements are
equivalent.
(i) X âˆ¼PPPÎ¼.
(ii) X almost surely has no double points and
P[X(A) = 0] = eâˆ’Î¼(A)
for all A âˆˆBb(E).
(24.7)
Proof (i) â‡’(ii)
This is obvious.
(ii) â‡’
(i)
As E is locally compact and Polish, there is a sequence (En) of
compacts such that En â†‘E and Î¼(En) < âˆfor all n âˆˆN. Hence without loss
of generality we may and will assume that E is compact and Î¼ is a ï¬nite measure
on E. Furthermore, as X is almost surely a Radon measure, it is almost surely ï¬nite
on the compact E.

618
24
The Poisson Point Process
If A1, . . . , An âˆˆBb(E) are pairwise disjoint, then
P)X(A1) = 0, . . . , X(An) = 0* = P)XA1 âˆª. . . âˆªAn
 = 0*
= eâˆ’Î¼(A1âˆª...âˆªAn)
=
n

l=1
eâˆ’Î¼(Al) =
n

l=1
P[X(Al) = 0].
If we deï¬ne 
X(A) := X(A) âˆ§1 for A âˆˆB(E), then the random variables 
X(Al),
l = 1, . . . , n, are independent.
Now let (Dn)nâˆˆN be a sequence of measurable partitions of E consisting of
sets of diameter at most 2âˆ’n and such that Dn+1 is a reï¬nement of Dn for any
n âˆˆN. Such a sequence was constructed in the course of the discussion preceding
Theorem 24.13.
Let
Îµn := sup
DâˆˆDn Î¼(D).
As Î¼ is atom-free, by (24.5), we have
Îµn
nâ†’âˆ
âˆ’â†’0.
(24.8)
As X almost surely has no double points and is ï¬nite, for any A âˆˆB(E) by (24.5),
we have
lim
nâ†’âˆ

DâˆˆDn

X(D âˆ©A) = lim
nâ†’âˆ

DâˆˆDn
X(D âˆ©A) = X(A)
a.s.
(24.9)
In particular, we infer that also the random variables X(Al), l = 1, . . . , n are
independent. In other words, X is a random measure with independent increments.
Now let A âˆˆB(E) and note that 
DâˆˆDn 
X(D âˆ©A) is a sum of independent
Bernoulli random variables with success probabilities pn
D(A) := 1 âˆ’eâˆ’Î¼(Dâˆ©A) â‰¤
Îµn
nâ†’âˆ
âˆ’â†’0. We have

DâˆˆDn
pn
D(A)
nâ†’âˆ
âˆ’â†’Î¼(A)
and

DâˆˆDn
(pn
D(A))2 â‰¤Îµn

DâˆˆDn
pn
D(A)
nâ†’âˆ
âˆ’â†’0.

24.2
Properties of the Poisson Point Process
619
By the theorem on Poisson approximation (Theorem 3.7), we get X(A) âˆ¼PoiÎ¼(A).
Together with the property of independent increments this shows that X is a Poisson
point process with intensity measure Î¼.
âŠ“âŠ”
Reï¬‚ection What is the connection between RÃ©nyiâ€™s theorem and the waiting times
in the construction of the Poisson process on [0, âˆ) in Theorem 5.36? â™ 
Laplace Transform, Characteristic Function and Moments
Theorem 24.14 Let Î¼ âˆˆM(E) and let X be a Poisson point process with intensity
measure Î¼. Then X has Laplace transform
LX(f ) = exp

Î¼(dx)

eâˆ’f (x) âˆ’1

,
f âˆˆB+(E),
and characteristic function
Ï•X(f ) = exp

Î¼(dx)

eif (x) âˆ’1

,
f âˆˆBR
b (E).
Proof It is enough to show the claim for simple functions f = n
l=1 Î±l 1Al with
complex numbers Î±1, . . . , Î±n and with pairwise disjoint sets A1, . . . , An âˆˆBb(E).
(For general f , the claim follows by the usual approximation arguments.) For such
f , however,
E
)
exp

âˆ’If (X)
*
= E
+ n

l=1
eâˆ’Î±lX(Al)
,
=
n

l=1
E
'
eâˆ’Î±lX(Al)(
=
n

l=1
exp

Î¼(Al)

eâˆ’Î±l âˆ’1

= exp

n

l=1
Î¼(Al)

eâˆ’Î±l âˆ’1

= exp
 
Î¼(dx)eâˆ’f (x) âˆ’1
.
âŠ“âŠ”
Corollary 24.15 (Moments of the PPP) Let Î¼ âˆˆM(E) and X âˆ¼PPPÎ¼.
(i) If f âˆˆL1(Î¼), then E[
3
f dX] =
3
f dÎ¼.
(ii) If f âˆˆL2(Î¼) âˆ©L1(Î¼), then Var[
3
f dX] =
3
f 2 dÎ¼.
Recall that only for ï¬nite Î¼, we have the inclusion L2(Î¼) âŠ‚L1(Î¼).

620
24
The Poisson Point Process
Proof If f = f + âˆ’f âˆ’âˆˆL1(Î¼), then for the characteristic function, integral
and differentiation interchange, d
dt Ï•X(tf +) = iÏ•X(tf +)
3
f (x) eitf +(x) Î¼(dx) and
hence (by Exercise 15.4.4(iii))
E
)
If +(X)
*
= 1
i
d
dt Ï•X(tf +)
t=0 =

f + dÎ¼.
Arguing similarly with f âˆ’and adding up, we get (i).
If f âˆˆL1(Î¼) âˆ©L2(Î¼), then the argument can be iterated (using Theorem 15.35)
d2
dt2 Ï•X(tf ) = âˆ’Ï•X(tf )
+ 
f 2(x) eitf(x) Î¼(dx) +
 
f (x) eitf(x) Î¼(dx)
2 ,
,
hence we have E
)
If (X)2*
= âˆ’d2
dt2 Ï•X(tf )
t=0 = If 2(Î¼) + If (Î¼)2.
âŠ“âŠ”
Theorem 24.16 (Mapping theorem) Let E and F be locally compact Polish
spaces and let Ï† : E â†’F be a measurable map. Let Î¼ âˆˆM(E) with
Î¼ â—¦Ï†âˆ’1 âˆˆM(F) and let X be a PPP on E with intensity measure Î¼. Then X â—¦Ï†âˆ’1
is a PPP on F with intensity measure Î¼ â—¦Ï†âˆ’1.
Proof For f âˆˆB+(F),
LXâ—¦Ï†âˆ’1(f ) = LX(f â—¦Ï†) = exp
  
eâˆ’f (Ï†(x)) âˆ’1

Î¼(dx)

= exp
  
eâˆ’f (y) âˆ’1
 
Î¼ â—¦Ï†âˆ’1
(dy)

.
Now, Theorems 24.14 and 24.7 yield the claim.
âŠ“âŠ”
Inï¬nitely Divisible Random Variables
Theorem 24.17 Let Î½ âˆˆM((0, âˆ)) and let X âˆ¼PPPÎ½ on (0, âˆ). Further, deï¬ne
Y :=
3
x X(dx). Then the following are equivalent.
(i) P[Y < âˆ] > 0.
(ii) P[Y < âˆ] = 1.
(iii) 3 Î½(dx)1 âˆ§x < âˆ.
If (i)â€“(iii) hold, then Y is an inï¬nitely divisible nonnegative random variable with
LÃ©vy measure Î½.

24.2
Properties of the Poisson Point Process
621
Proof Let Yâˆ=
3
[1,âˆ) x X(dx) and Yt :=
3
(t,1) x X(dx) for t âˆˆ[0, 1). Evidently,
Y = Y0 + Yâˆ. Furthermore, it is clear that
P[Yâˆ< âˆ] > 0 â‡â‡’P[Yâˆ< âˆ] = 1 â‡â‡’Î½([1, âˆ)) < âˆ.
(24.10)
If (iii) holds, then E[Y0] =
3
(0,1) x Î½(dx) < âˆ; hence Y0 < âˆa.s. (and thus
Y < âˆa.s. by (24.10)). On the other hand, if (iii) does not hold, then Yâˆ= âˆa.s.
or E[Y0] = âˆ. While Yâˆcan have inï¬nite expectation even if Yâˆ< âˆa.s., for
Y0 this is impossible since, in contrast with Yâˆ, Y0 is composed not of a few large
contributions but many small ones so that a law of large numbers is in force. More
precisely, by Corollary 24.15, we have
Var[Yt] =

(t,1)
x2 Î½(dx) â‰¤

(t,1)
x Î½(dx) = E[Yt] < âˆ
for all t âˆˆ(0, 1).
Hence, by Chebyshevâ€™s inequality,
P
+
Yt < E[Yt]
2
,
â‰¤4 Var[Yt]
E[Yt]2
tâ†’0
âˆ’â†’0.
Thus Y0 = suptâˆˆ(0,1) Yt â‰¥E[Y0]/2 = âˆalmost surely.
Now assume that (i)â€“(iii) hold. By Theorem 24.14, Y has the Laplace transform
E
)
eâˆ’tY *
= exp

Î½(dx)

eâˆ’tx âˆ’1

.
By the LÃ©vyâ€“Khinchin formula (Theorem 16.14), Y is inï¬nitely divisible with LÃ©vy
measure Î½.
âŠ“âŠ”
Corollary 24.18 Let Î¼i âˆˆM1([0, âˆ)), i = 1, 2, be inï¬nitely divisible distribu-
tions with canonical measures Î½i âˆˆM((0, âˆ)) and deterministic parts Î±i â‰¥0
(compare Theorem 16.14). If we have
Î±1 â‰¤Î±2
and
Î½1([x, âˆ)) â‰¤Î½2([x, âˆ))
for all x > 0,
(24.11)
then Î¼1 is stochastically smaller than Î¼2; i.e., Î¼1 â‰¤st Î¼2.
Proof (The proof follows [100, Proof of Lemma 6.1]) The idea is to use a coupling
argument where based on one Poisson point process we construct the two random
variables Y1, Y2 with Yi âˆ¼Î¼i, i = 1, 2, such that Y1 â‰¤Y2 almost surely. By
Theorem 17.59, this yields the claim.
Let Gi(x) := Î½i([x, âˆ)), i = 1, 2, x > 0, and
Ï†i(y) := Gâˆ’1
i (y) = inf
	
x â‰¥0 : Gi(x) â‰¤y

for y > 0.

622
24
The Poisson Point Process
If Î½i is ï¬nite, then Ï†i(y) = 0 for y â‰¥Î½i((0, âˆ)). Let Î» denote the Lebesgue measure
on [0, âˆ). By construction, for the image measure restricted to the positive reals,
we have

Î» â—¦Ï†âˆ’1
i

(0,âˆ) = Î½i,
i = 1, 2.
Now assume that X is a PPP on (0, âˆ) with intensity measure Î». By Theorem 24.16,
the random measures
Xi :=

Î´Ï†i(x) X(dx)
 
(0,âˆ) =

X â—¦Ï†âˆ’1
i

(0,âˆ)
are PPPs with intensity measures Î½i, i = 1, 2. By Theorem 24.17, we thus have
Yi := Î±i +

Ï†i(x) X(dx) âˆ¼Î¼i
for i = 1, 2.
However, by assumption, we have G1 â‰¤G2 which implies Ï†1 â‰¤Ï†2 and thus
Y1 â‰¤Y2 a.s.
âŠ“âŠ”
Example 24.19 By Corollary 16.10, for every nonnegative inï¬nitely divisible
distribution Î¼ with LÃ©vy measure Î½, there exists a stochastic process (Yt)tâ‰¥0 with
independent stationary increments and Yt âˆ¼Î¼âˆ—t (hence with LÃ©vy measure tÎ½).
Here we give a direct construction of this process. Let X be a PPP on (0, âˆ)Ã—[0, âˆ)
with intensity measure Î½ âŠ—Î» (here Î» is the Lebesgue measure). Deï¬ne Y0 = 0 and
Yt :=

(0,âˆ)Ã—(0,t]
x Xd(x, s).
By the mapping theorem, we have X( Â· Ã— (s, t]) âˆ¼PPP(tâˆ’s)Î½; hence Yt âˆ’Ys is
inï¬nitely divisible with LÃ©vy measure (t âˆ’s)Î½. The independence of the increments
is evident. Note that t â†’Yt is right continuous and monotone increasing.
The process Y that we have just constructed is called a subordinator with LÃ©vy
measure Î½. â™¦
The procedure in the previous example can be generalized by allowing time sets
more general than [0, âˆ).
Deï¬nition 24.20 A random measure Y is called inï¬nitely divisible if, for any n âˆˆN,
there exist i.i.d. random measures Y1, . . . , Yn with Y = Y1 + . . . + Yn.
Theorem 24.21 Let Î½ âˆˆM((0, âˆ) Ã— E) with

1A(t) (1 âˆ§x) Î½(d(x, t)) < âˆ
for all A âˆˆBb(E),

24.2
Properties of the Poisson Point Process
623
and let Î± âˆˆM(E). Let X be a PPPÎ½ and
Y(A) := Î±(A) +

x 1A(t) X(d(x, t))
for A âˆˆB(E).
Then Y is an inï¬nitely divisible random measure with independent increments. For
A âˆˆB(E), Y(A) has the LÃ©vy measure Î½( Â· Ã— A).
We call Î½ the canonical measure and Î± the deterministic part of Y.
Proof This is a direct consequence of Theorems 24.16 and 24.17.
âŠ“âŠ”
Remark 24.22 We can write Y as Y = Î± +
3
xÎ´t X(d(x, t)), where Î´t is the Dirac
measure at t âˆˆE. If instead of x Î´t, we allow more general measures Ï‡ âˆˆM(E),
then we get a representation
Y = Î± +

M(E)
Ï‡ X(dÏ‡),
where X âˆ¼PPPÎ½ on M(E) and Î½ âˆˆM(M(E)) with

Î½(dÏ‡)(Ï‡(A) âˆ§1) < âˆ
for any A âˆˆBb(E). It can be shown that this is the most general form of an
inï¬nitely divisible measure on E. We call Î½ the canonical measure of Y and Î±
the deterministic part. Y is characterized by its Laplace transform which obeys the
LÃ©vyâ€“Khinchin formula:
LY (f ) = exp

âˆ’

f dÎ± +

Î½(dÏ‡)eâˆ’
3
f dÏ‡ âˆ’1
.
â™¦
Random Colorings
Let N be a Poisson random variable with parameter Î» > 0 and let Z1, Z2, . . .
independent (and independent of N) Bernoulli random variables with probability of
success p âˆˆ[0, 1]. Then
N0 :=
N

i=1
1{0}(Zi)
and
N1 :=
N

i=1
1{1}(Zi)
are independent Poisson random variables with parameters Î»0 = (1 âˆ’p)Î» and
Î»1 = pÎ». Similarly, we can allow the Zi to take values in {0, . . . , k} (for some

624
24
The Poisson Point Process
k âˆˆN) with probabilities p0, . . . , pk. Then the random variables
Nm :=
N

i=1
1{m}(Zi),
m = 0, . . . , k,
are independent and Poisson distributed with parameters Î»m = pmÎ», m = 0, . . . , k.
Often, the Zi are interpreted as colors or marks that are a given independently to the
single points of the Poisson random variable N.
While the above statements can be shown easily using elementary methods (this
remains as an exercise), we will now turn to a more general situation. We assume
that the possible colors are drawn from a locally compact Polish space F (which
includes ï¬nite or countable F and F = R) with Borel Ïƒ-algebra B(F) and that X is
a Poisson point process on a locally compact Polish space E with intensity measure
Î¼ âˆˆM(E). Let Î½ âˆˆM1(F) and let Z1, Z2, . . . be i.i.d. F-valued random variables
with distribution Î½. We assume that the Zi are independent of X. The Zi are the
colors that we want to attach to the points of X. However, in order to do so, we need
an enumeration of the points of X. Any enumeration will do the trick and since the
Zi are i.i.d., the resulting will not depend on the speciï¬c enumeration we choose (in
distribution).
We proceed similarly as in the proof of existence of the Poisson point process
(Theorem 24.12). We decompose Î¼ into a sum of ï¬nite measures Î¼ = âˆ
n=1 Î¼n
with Î¼n âˆˆMf (E), Î¼n Ì¸= 0 for any n âˆˆN. Let (Nn)nâˆˆN be independent random
variables with Nn âˆ¼PoiÎ¼n(E). Deï¬ne Î¼n := Î¼n/Î¼n(E) âˆˆM1(E). Let (Yn,i)n,iâˆˆN
and (Zn,i)n,iâˆˆN be independent (and independent of (Nn)) random variables with
Yn,i âˆ¼Î¼n and Zn,i âˆ¼Î½, n, i âˆˆN. Let
X(A) :=
âˆ

n=1
Nn

i=1
1A(Yn,i),
A âˆˆBb(E).
In the proof of Theorem 24.12, we showed that X âˆ¼PPPÎ¼.
We attach random colors Zn,i to the points Yn,i be deï¬ning

X(A Ã— B) :=
âˆ

n=1
Nn

i=1
1A(Yn,i) 1B(Zn,i),
A âˆˆBb(E), B âˆˆB(F).
Clearly, this deï¬nes a random measure

X(C) =
âˆ

n=1
Nn

i=1
1C((Yn,i, Zn,i)),
C âˆˆB(E Ã— F).
By construction, we have 
X âˆ¼PPPÎ¼âŠ—Î½.

24.2
Properties of the Poisson Point Process
625
The next generalization we focus on is that we want to allow the distribution
of the random color of a point to depend on its position but not on the positions
of the other points. More precisely, let Îº be a Markov kernel from E to F. If
x âˆˆE is a point of X, that is, if X({x}) = 1, then the color of that point will
be chosen at random with distribution Îº(x, Â·). The proper way to do this is to use
the construction outlined above but with Zn,i depending on Yn,i. More precisely, we
assume that the bivariate random variables (Yn,i, Zn,i), n, i âˆˆN, are independent
with distribution Î¼n âŠ—Îº. That is,
P[Yn,i âˆˆA, Zn,i âˆˆB] =

1A(x)Îº(x, B) Î¼n(dx)
for A âˆˆB(E), B âˆˆB(F).
Clearly, we then have that

Xn(C) :=
Nn

i=1
1C((Yn,i, Zn,i)),
C âˆˆB(E Ã— F)
is a PPPÎ¼nâŠ—Îº.
Finally, we deï¬ne

Xn(C) :=
âˆ

n=1

Xn(C) =
âˆ

n=1
Nn

i=1
1C((Yn,i, Zn,i)),
C âˆˆB(E Ã— F).
If x âˆˆE and X({x}) = 1, then we have Yn,i = x for one of the pairs (n, i) that
show up in the sum. Since L(Zn,i |Yn,i = x) = Îº(x, Â·), the color of x is distributed
according to Îº(x, Â·) (and is independent of everything else).
We observe that Î¼ âŠ—Îº = âˆ
n=1(Î¼n âŠ—Îº) to conclude:
Theorem 24.23 (Coloring theorem) 
X is a PPPÎ¼âŠ—Îº.
In some situations we are interested only in the colors and not in the positions of the
underlying points. In order to formalize this, we deï¬ne the projection Ï€ : E Ã— F â†’
F, (x, y) â†’y and let XÎº := 
X â—¦Ï€âˆ’1 be the image measure of 
X. More explicitly,
this means
XÎº(B) = ËœX(E Ã— B)
for B âˆˆBb(F).
In order for XÎº to be a random measure, we need to assume Î¼Îº = (Î¼ âŠ—Îº) â—¦Ï€âˆ’1 âˆˆ
M(F). This implies that by the projection, the colors do not concentrate to much to
violate local boundedness of XÎº.
Theorem 24.24 XÎº is a random measure with PXÎº = PPPÎ¼Îº.

626
24
The Poisson Point Process
Proof In the above notation, we have
XÎº(B) = ËœX(E Ã— B) =
âˆ

n=1
Nn

i=1
1B(Zn,i)
for B âˆˆBb(F).
Now Zn,i âˆ¼Î¼nÎº and
Î¼Îº =
âˆ

n=1
Î¼nÎº =
âˆ

n=1
Î¼n(E)Î¼nÎº.
Following the construction in the proof of Theorem 24.12 we infer the claim.
âŠ“âŠ”
We come back to the initial problem of a ï¬nite coloring of Poisson random variable.
Since we are interested in the colors but not in the positions of the points, we take
an arbitrary but sufï¬ciently rich space E. For deï¬niteness, let us assume E = [0, 1].
Let Î» > 0, and let Î¼ be Î»-times the Lebesgue measure on [0, 1]. Let k âˆˆN and F =
{0, . . ., k} and let (pm)m=0,...,k be probability weights on F. We deï¬ne Îº(x, {m}) =
pm for all x âˆˆE. Then Î¼Îº({m}) = Î»pm and the randomly colored point process
XÎº has the property that Nm := XÎº({m}), m = 0, . . . , k are independent Poisson
random variables with parameters Î»pm. However, N := X(E) âˆ¼PoiÎ».
Example 24.25 (PPP as invariant distribution) As an application of the previous
theorem, consider a stochastic process on E = Zd or E = Rd that consists of a
system of independent random walks. Hence assume that we are given i.i.d. random
variables Zi
n, i, n âˆˆN with distribution Î½ âˆˆM1(E). Further, assume that, at time n,
the position of the ith particle of our system of random walks is Si
n := Si
0+n
l=1 Zi
l ,
where Si
0 is an arbitrary, possibly random, starting point. Assume that the particles
are indistinguishable. Hence we simply add the particles at each site:
Xn(A) :=
âˆ

i=1
1A(Si
n)
for A âŠ‚E.
Each Xn is a measure on E and, if at the beginning the particles are not too
concentrated locally, it is a locally ï¬nite measure and hence a random measure.
Assume that X0 âˆ¼PPPÎ¼ for some Î¼ âˆˆM(E). Deï¬ne Îº(x, Â·) = Î´x âˆ—Î½, and
write Îºn for the n-fold application of Îº; that is, Îºn(x, Â·) = Î´x âˆ—Î½âˆ—n. We thus get
XÎº
0
D= X1. Indeed, independence of the motions of the individual particles in the
deï¬nition of XÎº
0 is exactly independence of the random walks. As X1 is also a PPP,
we get inductively XÎº
n
D= Xn+1 and thus Xn âˆ¼PPPÎ¼Îºn = PPPÎ¼âˆ—Î½âˆ—n. In particular,
X0
D= Xn if and only if Î¼ âˆ—Î½ = Î¼. Clearly, this is true if we have E = Zd and Î¼
the counting measure or if E = Rd and Î¼ is the Lebesgue measure. For example, if
E = Zd, then under rather mild assumptions on Î½ one can show that the counting
measure Î¼ = Î» is the unique (up to multiples) solution of Î¼ âˆ—Î½ = Î¼. In this case,

24.3
The Poissonâ€“Dirichlet Distribution
627
every invariant measure is a convex combination of PPPs with different intensity
measures Î¸Î». â™¦
Takeaways For non-atomic intensity measure, the Poisson point process can
be characterised by the probabilities for sets to be vacant (RÃ©nyiâ€™s theorem).
Images of Poisson point process are again Poisson point processes. If we
assign an independent random colour to each Poisson point, we get a Poisson
point process on the original space enhanced by the space of colours. Inï¬nitely
divisible nonnegative random variables can be represented as the weighted
sum of points of a Poisson point process with the canonical measure as
intensity measure. Poisson point processes can pop up as invariant states of
large particle systems, in particular in grand canonical ensembles.
Exercise 24.2.1 Use an approximation with simple functions in order to show the
claim of Corollary 24.15 without using characteristic functions. â™£
Exercise 24.2.2 Let p1, p2 âˆˆ(0, 1] and r1, r2 > 0. Show the following statement
about the stochastic order of negative binomial distributions: bâˆ’
r1,p1 â‰¤st bâˆ’
r2,p2 if and
only if
p1 â‰¥p2
and
pr1
1 â‰¥pr2
2 .
â™£
24.3
The Poissonâ€“Dirichlet Distributionâˆ—
The goal of this section is to solve the following problem. Take a stick of length 1.
Choose a point of the stick uniformly at random and break the stick at this point.
Put the left part of the stick (with length, say, W1) aside. With the remaining part of
the stick proceed just as with the original stick. Break it in two and put the left part
(of length W2) aside. Successively, we thus collect fractions of the stick of lengths
W1, W2, W3, . . .. What is the joint distribution of (W1, W2, . . .)? Furthermore, if we
order the numbers W1, W2, . . . in decreasing order W(1) â‰¥W(2) â‰¥. . ., what is the
distribution of (W(1), W(2), . . .)? And ï¬nally, why do we ask these questions in a
chapter on Poisson point processes?
Answering these questions requires some preparation. We saw that the Beta
distribution occurs naturally in PÃ³lyaâ€™s urn model as the limiting distribution of
the fraction of balls of a given color. Clearly, PÃ³lyaâ€™s urn model can be considered
for any number n â‰¥2 of colors. The limiting distribution is then the n-dimensional
generalization of the Beta distribution, namely the so-called Dirichlet distribution.
Deï¬ne the (n âˆ’1)-dimensional simplex

628
24
The Poisson Point Process
Î”n := {(x1, . . . , xn) âˆˆ[0, 1]n : x1 + . . . + xn = 1}.
Deï¬nition 24.26 Let n âˆˆ{2, 3, . . .} and Î¸1, . . . , Î¸n > 0. The Dirichlet distribution
DirÎ¸1,...,Î¸n is the distribution on Î”n that is deï¬ned for measurable A âŠ‚Î”n by
DirÎ¸1,...,Î¸n(A) =

1A(x1, . . . , xn) fÎ¸1,...,Î¸n(x1, . . . , xn) dx1 Â· Â· Â· dxnâˆ’1.
Here
fÎ¸1,...,Î¸n(x1, . . . , xn) = Î“ (Î¸1 + . . . + Î¸n)
Î“ (Î¸1) Â· Â· Â· Î“ (Î¸n) xÎ¸1âˆ’1
1
Â· Â· Â· xÎ¸nâˆ’1
n
.
If the parameters Î¸1, . . . , Î¸n are integer-valued, they correspond to the numbers of
balls of the different colors that are originally in the urn. Assume that the colors nâˆ’1
and n are light green and green and that in the dim light we cannot distinguish them.
Then we should still end up with a Dirichlet distribution in the limit but with n âˆ’1
instead of n and with Î¸nâˆ’1 + Î¸n instead of Î¸nâˆ’1 and Î¸n; that is, DirÎ¸1,...,Î¸nâˆ’2,Î¸nâˆ’1+Î¸n.
Let (Mt)tâ‰¥0 be the Moran Gamma subordinator, the stochastic process with
right continuous, monotone increasing paths t â†’Mt and independent, stationary,
Gamma-distributed increments: Mt âˆ’Ms âˆ¼Î“1,tâˆ’s for t > s â‰¥0. An important
connection between M and the Dirichlet distribution is revealed by the corollaries
of the following theorem and by Theorem 24.32.
Theorem 24.27 Let n âˆˆN, Î¸1, . . . , Î¸n > 0 and Î˜ := Î¸1 + . . . + Î¸n. Let X âˆ¼
DirÎ¸1,...,Î¸n and let Z âˆ¼Î“1,Î˜ be independent random variables. Then the random
variables Si := Z Â· Xi, i = 1, . . . , n are independent and Si âˆ¼Î“1,Î¸i.
Proof In the following, always let xn := 1 âˆ’nâˆ’1
i=1 xi and s = n
j=1 sj. Let
Î”â€²
n :=

(x1, . . . , xnâˆ’1) âˆˆ(0, 1)nâˆ’1 :
nâˆ’1

i=1
xi < 1

.
For x âˆˆÎ”â€²
n and z â‰¥0, the distribution of (X1, . . . , Xnâˆ’1, Z) has the density
f (x1, . . . , xnâˆ’1, z) =
n

j=1

x
Î¸j âˆ’1
j
R
Î“ (Î¸j)

zÎ˜âˆ’1 eâˆ’z.
Consider the map
F : Î”â€²
n Ã— (0, âˆ) â†’(0, âˆ)n,
(x1, . . . , xnâˆ’1, z) â†’(zx1, . . . , zxn).
This map is invertible with inverse map
F âˆ’1 : (s1, . . . , sn) â†’(s1/s, . . . , snâˆ’1/s, s).

24.3
The Poissonâ€“Dirichlet Distribution
629
The Jacobian determinant of F is det(F â€²(x1, . . . , xnâˆ’1, z))
=
znâˆ’1. By the
transformation formula for densities (Theorem 1.101), (S1, . . . , Sn) has density
g(s1, . . . , sn) =
f (F âˆ’1(s1, . . . , sn))
| det(F â€²(F âˆ’1(s1, . . . , sn)))|
= sÎ˜âˆ’1 eâˆ’s
snâˆ’1
n

j=1

(sj/s)Î¸j âˆ’1@
Î“ (Î¸j)

=
n

j=1

s
Î¸j âˆ’1
j
eâˆ’sj @
Î“ (Î¸j)

.
However, this is the density for independent Gamma distributions.
âŠ“âŠ”
Corollary 24.28 If ti := i
j=1 Î¸j for i = 0, . . . , n, then the random variables
X = ((Mti âˆ’Mtiâˆ’1)/Mtn, i = 1, . . . , n) and S := Mtn are independent with
distributions X âˆ¼DirÎ¸1,...,Î¸n and S âˆ¼Î“1,tn.
Corollary 24.29 Let (X1, . . . , Xn) âˆ¼DirÎ¸1,...,Î¸n. Then X1 âˆ¼Î²Î¸1,n
i=2 Î¸i and
(X2/(1 âˆ’X1), . . . , Xn/(1 âˆ’X1)) âˆ¼DirÎ¸2,...,Î¸n are independent.
Proof Let M be as in Corollary 24.28. Then X1 = Mt1/Mtn âˆ¼Î²Î¸1,tnâˆ’Î¸1. Since
X1 =
 Mtnâˆ’Mt1
Mt1
+ 1
âˆ’1
, we see that X1 depend only on Mt1 and Mtn âˆ’Mt1. On the
other hand,

X2
1 âˆ’X1
, . . . ,
Xn
1 âˆ’X1

=
Mt2 âˆ’Mt1
Mtn âˆ’Mt1
, . . . , Mtn âˆ’Mtnâˆ’1
Mtn âˆ’Mt1

is independent of Mt1. By Corollary 24.28, it is also independent of Mtn âˆ’Mt1 and
is DirÎ¸2,...,Î¸n-distributed.
âŠ“âŠ”
Corollary 24.30 Let V1, . . . , Vnâˆ’1 be independent, Vi âˆ¼Î²Î¸i,Î¸i+1+...+Î¸n and Vn =
1. Then

V1, (1 âˆ’V1)V2, (1 âˆ’V1)(1 âˆ’V2)V3, . . . ,
 nâˆ’1

i=1
(1 âˆ’Vi)

Vn

âˆ¼DirÎ¸1,...,Î¸n.
Proof This follows by iterating the claim of Corollary 24.29.
âŠ“âŠ”
It is natural to ask what happens if we distinguish more and more colors (instead
of pooling them). For simplicity, consider a symmetric situation where we have
Î¸1 = . . . = Î¸n = Î¸/n for some Î¸ > 0. Hence we consider
DirÎ¸;n := DirÎ¸,...,Î¸
for Î¸ > 0.

630
24
The Poisson Point Process
If Xn = (Xn
1, . . . , Xn
n) âˆ¼DirÎ¸/n;n, then, by symmetry, we have E[Xn
i ] = 1/n
for every n âˆˆN and i = 1, . . . , n. Hence, clearly (Xn
1, . . . , Xn
k) nâ†’âˆ
â‡’0 for any
k âˆˆN. In order to obtain a nontrivial limit, one possibility is to reorder the values
by decreasing size: Xn
(1) â‰¥Xn
(2) â‰¥. . ..
Deï¬nition 24.31 Let Î¸ > 0 and let (Mt)tâˆˆ[0,Î¸] be a Moran Gamma subordinator.
Let m1 â‰¥m2 â‰¥. . . â‰¥0 be the jump sizes of M in decreasing order and let
Ëœmi = mi/MÎ¸, i = 1, 2, . . .. The distribution of the random variables ( Ëœm1, Ëœm2, . . .)
on S := {(x1 â‰¥x2 â‰¥. . . â‰¥0) : x1 + x2 + . . . = 1} is called the Poissonâ€“Dirichlet
distribution PDÎ¸ with parameter Î¸ > 0.
To be honest, we still have to show that âˆ
i=1 Ëœmi = 1. To this end, let Y be a PPP on
(0, âˆ) Ã— (0, Î¸] with intensity measure Î½ âŠ—Î», where Î» is the Lebesgue measure and
Î½(dx) = eâˆ’xxâˆ’1 dx is the LÃ©vy measure of the Î“1,1 distribution. We can deï¬ne M
by Mt := 
(x,s): Y({x,s})=1, sâ‰¤t x. Now we have m1 = sup{x âˆˆ(0, âˆ) : Y({x} Ã—
(0, Î¸]) = 1}. Inductively, we get mn = sup{x < mnâˆ’1 : Y({x} Ã— (0, Î¸]) = 1} for
n â‰¥2. Interchanging the order of summations, we obtain MÎ¸ = âˆ
n=1 mn.
Theorem 24.32 If Xn âˆ¼DirÎ¸/n;n for n âˆˆN, then P(Xn
(1),Xn
(2),...)
nâ†’âˆ
âˆ’â†’PDÎ¸.
Proof The idea is to express the random variables Xn, n âˆˆN, in terms of the
increments of the Moran Gamma subordinator (Mt)tâˆˆ[0,Î¸] in such a way that
convergence of distributions implies almost sure convergence. Hence, let Xn
i
=
(MÎ¸i/n âˆ’MÎ¸(iâˆ’1)/n)/MÎ¸. By Corollary 24.28, we have Xn
âˆ¼DirÎ¸/n;n. Let
t1, t2, . . . âˆˆ(0, Î¸] be the positions of the jumps m1 â‰¥m2 â‰¥. . .. Evidently,
Xn
(1) â‰¥Ëœm1 for every n. If n is large enough that |t1 âˆ’t2| > Î¸/n, then Xn
(2) â‰¥Ëœm2.
Inductively, we get lim infnâ†’âˆXn
(i) â‰¥
Ëœmi almost surely. Using the convention
Xn
(i) = 0 for i > n, we have âˆ
i=1 Xn
(i) = 1 for every n âˆˆN. By Fatouâ€™s lemma, we
thus get
1 =
âˆ

i=1
Ëœmi â‰¤
âˆ

i=1
lim inf
nâ†’âˆXn
(i) â‰¤lim inf
nâ†’âˆ
âˆ

i=1
Xn
(i) = 1.
Therefore, limnâ†’âˆXn
(i) = Ëœmi almost surely.
âŠ“âŠ”
Instead of ordering the values of Xn by their sizes, there is a different way
of arranging the terms so that the distributions converge. Think of a biological
population in which a certain phenotypical property can be measured with different
levels of precision. If we distinguish n different values of this property, then we
write Xn
i for the proportion of the population that has type i âˆˆ{1, . . . , n}.
Now successively choose individuals from the population at random. Let I n
1 be
the type of the ï¬rst individual. Denote by I n
2 the type of the ï¬rst individual that is
not of type I n
1 . That is, I n
2 is the second type that we see. Now inductively deï¬ne
I n
k as the kth type that we see; that is, the type of the ï¬rst individual that has none
of the types I n
1 , . . . , I n
kâˆ’1. Consider the vector Ë†Xn = ( Ë†Xn
1, . . . , Ë†Xn
n), where Ë†Xn
k =

24.3
The Poissonâ€“Dirichlet Distribution
631
Xn
I n
k . Since the probability of the event {I n
1 = i} is proportional to the size of the
subpopulation of type i, we say that Ë†Xn is the successively size-biased vector.
The distribution of Ë†Xn does not change if we change the order of the Xn
1, . . . , Xn
n.
For example, instead of Xn
1, . . . , Xn
n, we can use the order statistics (in decreasing
order) (Xn
(1), . . . , Xn
(n)) and again end up with Ë†Xn as the successively size-biased
vector. Hence we can deï¬ne the successively size-biased vector Ë†X for the inï¬nite
vector X âˆ¼PDÎ¸. If Xn âˆ¼DirÎ¸/n;n, then by Theorem 24.32, we have Ë†Xn nâ†’âˆ
â‡’
Ë†X.
Hence we can compute the distribution of Ë†X.
Theorem 24.33 Let Î¸ > 0 and Xn âˆ¼DirÎ¸/n;n, n âˆˆN. Let X âˆ¼PDÎ¸. Further,
let V1, V2, . . . be i.i.d. random variables on [0, 1] with density x â†’Î¸(1 âˆ’x)Î¸âˆ’1.
Deï¬ne Z1 = V1 and Zk =  kâˆ’1
i=1(1 âˆ’Vi)Vk for k â‰¥2. Then:
(i)
Ë†Xn nâ†’âˆ
â‡’
Ë†X.
(ii)
Ë†X D= Z.
The distribution of Z is called the GEMÎ¸ distribution (Grifï¬thsâ€“Engenâ€“
McCloskey).
Proof Statement (i) was shown in the discussion preceding the theorem. In order
to show (ii), we compute the distribution of Ë†Xn and show that it converges to the
distribution of Z.
Let Ë†Xn,1 be the vector Ë†Xn,1 = (Xn
I n
1 , Xn
1, Xn
2, . . . , Xn
I n
1 âˆ’1, Xn
I n
1 +1, . . . , Xn
n), in
which only the ï¬rst coordinate is sampled size-biasedly. We show that
Ë†Xn,1 âˆ¼Dir(Î¸/n)+1,Î¸/n,...,Î¸/n.
(24.12)
Let f (x) =

Î“ (Î¸)/Î“ (Î¸/n)n
Â· n
k=1 x(Î¸/n)âˆ’1
k
be the density of DirÎ¸/n;n. We
compute the density Ë†f n,1 of Ë†Xn,1 by decomposing according to the value i of I n
1 :
Ë†f n,1(x) =
n

i=1
x1 f (x2, . . . , xi, x1, xi+1, . . . , xn) = n x1 f (x)
=
nÎ“ (Î¸)
Î“ (Î¸/n)n xÎ¸/n
1
n

i=2
x(Î¸/n)âˆ’1
i
=
Î“ (Î¸ + 1)
Î“ ((Î¸/n) + 1) Î“ (Î¸/n)nâˆ’1 xÎ¸/n
1
n

i=2
x(Î¸/n)âˆ’1
i
.
However, this is the density of Dir(Î¸/n)+1,Î¸/n,...,Î¸/n. By Corollary 24.29, we have
Ë†Xn,1
D= V n
1 , (1 âˆ’V n
1 )Y1, . . . , (1 âˆ’V n
1 )Ynâˆ’1
,

632
24
The Poisson Point Process
where
V n
1 âˆ¼Î²(Î¸/n)+1,Î¸(nâˆ’1)/n
and
Y = (Y1, . . . , Ynâˆ’1) âˆ¼DirÎ¸/n;nâˆ’1
are independent. Applying this to Y, we get inductively
Ë†Xn D= Zn,
(24.13)
where
Zn
1 = V n
1
and
Zn
k =
 kâˆ’1

i=1
(1 âˆ’V n
i )

V n
k
for k â‰¥2
and where V n
1 , . . . , V n
nâˆ’1 are independent and V n
i
âˆ¼Î²(Î¸/n)+1,Î¸(nâˆ’i)/n. Now it is
easy to check that Î²(Î¸/n)+1,Î¸(nâˆ’i)/n
nâ†’âˆ
âˆ’â†’Î²1,Î¸ for every i âˆˆN. Recall that Î²1,Î¸ has
the density x â†’Î¸(1 âˆ’x)Î¸âˆ’1. Hence V n
i
nâ†’âˆ
â‡’Vi for every i and thus Zn nâ†’âˆ
â‡’Z
and Ë†Xn nâ†’âˆ
â‡’Z. Together with (i), this proves claim (ii).
âŠ“âŠ”
At the beginning of this chapter, we raised the question of how the sizes W1, W2, . . .
of the stick lengths are distributed if at each step, we break the remaining part of
the stick at a point chosen uniformly at random. The preceding theorem gives the
answer: The vector (W(1), W(2), . . .) has distribution PD1, and (W1, W2, . . .) has
distribution GEM1.
The Chinese Restaurant Process
We will study a further situation in which the Poissonâ€“Dirichlet distribution arises
naturally. As the technical details get a bit tricky, we content ourselves with the
description of the problem and with stating (but not proving) two fundamental
theorems. An excellent reference for this type of problem is [130].
Consider a Chinese restaurant with countably many enumerated round tables. At
each table, there is enough space for arbitrarily many guests. Initially, the restaurant
is empty. One by one an inï¬nite number of guests arrive. The ï¬rst guest sits down at
table number one. If there are already n guests sitting at k tables, then the (n + 1)th
guest can choose between sitting down at any of the k occupied tables or at the free
table with the smallest number (that is, k + 1). Assume that the guest makes his
choice at random (and independently of the previous choices of the other guests).
For l â‰¤k, denote by Nn
l the number of guests at the lth table and assume that the
probability of choosing the lth table is (Nn
l âˆ’Î±)/(n + Î¸). Then the probability of
choosing the ï¬rst free table is (Î¸ + kÎ±)/(n + Î¸). Here Î± âˆˆ[0, 1] and Î¸ > âˆ’Î± are
parameters. We say that (Nn)nâˆˆN = (Nn
1 , Nn
2 , . . .)nâˆˆN is the Chinese restaurant
process with parameters (Î±, Î¸).

24.3
The Poissonâ€“Dirichlet Distribution
633
In the special case Î± = 0, there is a nice interpretation: Assume that the new
guest can also choose his seating position at the table (that is, his neighbor to the
right). Then, for any of the present guests, the probability of being chosen as a right
neighbor is 1/(n + Î¸). The probability of starting a new table is Î¸/(n + Î¸).
In order to study the large n behavior of Nn/n = (Nn
1 /n, Nn
2 /n, . . .), we extend
the Poissonâ€“Dirichlet distribution and the GEM distribution by a further parameter.
Deï¬nition 24.34 Let Î± âˆˆ[0, 1) and Î¸ > âˆ’Î±. Let V1, V2, . . . be independent and
Vi âˆ¼Î²1âˆ’Î±,Î¸+iÎ±. Deï¬ne Z = (Z1, Z2, . . .) by Z1 = V1 and
Zk = Vk
kâˆ’1

i=1

1 âˆ’Vi

for k â‰¥2.
Then GEMÎ±,Î¸ := PZ is called the GEM distribution with parameters (Î±, Î¸). The
distribution of the size-biased vector (Z(1), Z(2), . . .) is called the Poissonâ€“Dirichlet
distribution with parameters (Î±, Î¸), or brieï¬‚y PDÎ±,Î¸.
Explicit formulas for the densities of the ï¬nite-dimensional marginals of PDÎ±,Î¸ can
be found in [132]. Note that, for Î± = 0, we recover the classical distributions
GEMÎ¸ = GEM0,Î¸ and PDÎ¸ = PD0,Î¸.
Theorem 24.35 Let Î± âˆˆ[0, 1), Î¸ > âˆ’Î± and let (Nn)nâˆˆN be the Chinese restaurant
process with parameters (Î±, Î¸). Then PNn/n
nâ†’âˆ
âˆ’â†’PDÎ±,Î¸.
Proof See [129] or [130, Theorem 25].
âŠ“âŠ”
Reï¬‚ection The Hoppe urn is a variation of the PÃ³lya Urne. Initially, there is only
one ball in the urn and this one has a unique label. Whenever this ball is drawn it will
be returned together with a ball of a completely new colour. Whenever one of the
coloured balls is drawn, it will be returned together with a second ball of the same
colour. The unique ball is sometimes called the mutator. What is the connection
between the Hoppe urn and the Chinese restaurant process? â™ 
As for the one-parameter Poissonâ€“Dirichlet distribution, there is a representation of
PDÎ±,Î¸ in terms of the size-ordered jumps of a certain subordinator. In the following,
let Î± âˆˆ(0, 1) and let (Mt)tâˆˆ[0,1] be an Î±-stable subordinator; that is, a subordinator
with LÃ©vy measure Î½(dx) = xâˆ’Î±âˆ’1 dx. Further, let m1 â‰¥m2 â‰¥. . . â‰¥0 be
the jumps of M, Ëœmi = mi/M1 for i âˆˆN, and Ëœm = ( Ëœm1, Ëœm2, . . .). We quote the
following theorem from [130, Section 4.2].
Theorem 24.36 Let Î± âˆˆ(0, 1).
(i)
Ëœm âˆ¼PDÎ±,0.
(ii) If Î¸ > âˆ’Î±, then PDÎ±,Î¸ â‰ªPDÎ±,0 = P[ Ëœm âˆˆÂ·] and the density is
PDÎ±,Î¸(dx) =
Mâˆ’Î¸
1
E[Mâˆ’Î¸
1 ]
P[ Ëœm âˆˆdx].

634
24
The Poisson Point Process
Takeaways The Dirichlet distribution generalises the beta distribution from
two to n types. After sorting the values of a Dirichlet random variable
(X1, . . . , Xn) in decreasing order, we can take the limit as n â†’âˆand get
the so-called Poisson-Dirichlet distribution. Drawing the values of a given
realisation of a Poisson-Dirichlet random variable successively with size
biased probabilities, we get a GEM distributed vector. The GEM distribution
plays an important role in the mathematical descriptions of samples in ecology
and evolutionary genetics.
Exercise 24.3.1 Let (X, 1 âˆ’X) âˆ¼DirÎ¸1,Î¸2. Show that X âˆ¼Î²Î¸1,Î¸2 is Beta-
distributed. â™£
Exercise 24.3.2 Let X = (X1, . . . , Xn) âˆ¼DirÎ¸1,...,Î¸n. Show the following.
(i) For any permutation Ïƒ on {1, . . ., n}, we have
(XÏƒ(1), . . . , XÏƒ(n)) âˆ¼DirÎ¸Ïƒ(1),...,Î¸Ïƒ(n).
(ii) (X1, . . . , Xnâˆ’2, Xnâˆ’1 + Xn) âˆ¼DirÎ¸1,...,Î¸nâˆ’2,Î¸nâˆ’1+Î¸n. â™£
Exercise 24.3.3 Let (Nn)nâˆˆN be the Chinese restaurant process with parameters
(0, Î¸).
(i) Let Î¸ = 1.
(a) Show that P[Nn
1 = k] = 1/n for any k = 1, . . . , n,
(b) Show that, for kl = 1, . . . , n âˆ’(k1 + . . . + klâˆ’1),
P)Nn
l = kl
Nn
1 = k1, . . . , Nn
lâˆ’1 = klâˆ’1
* =
1
n âˆ’(k1 + . . . + klâˆ’1).
(c) Infer the claim of Theorem 24.35 in the case Î± = 0 and Î¸ = 1.
(ii) Let Î¸ > 0.
(a) Show that n P[Nn
1 = âŒŠnxâŒ‹]
nâ†’âˆ
âˆ’â†’Î¸(1 âˆ’x)Î¸âˆ’1 for x âˆˆ(0, 1).
(b) Show that
n P
)
Nn
l = âŒŠnxlâŒ‹
Nn
1 = âŒŠnx1âŒ‹, . . . ,Nn
lâˆ’1 = âŒŠnxlâˆ’1âŒ‹
*
nâ†’âˆ
âˆ’â†’(Î¸/yl)

1 âˆ’xl/yl
Î¸âˆ’1
for x1, . . . , xl âˆˆ(0, 1) with yl = 1 âˆ’(x1 + . . . + xlâˆ’1) > xl.
(c) As in (i), infer the claim of Theorem 24.35 for Î± = 0 and Î¸ > 0. â™£

Chapter 25
The ItÃ´ Integral
The ItÃ´ integral allows us to integrate stochastic processes with respect to the
increments of a Brownian motion or a somewhat more general stochastic process.
We develop the ItÃ´ integral ï¬rst for Brownian motion and then for generalized
diffusion processes (so-called ItÃ´ processes). In the third section, we derive the
celebrated ItÃ´ formula. This is the chain rule for the ItÃ´ integral that enables us
to do explicit calculations with the ItÃ´ integral. In the fourth section, we use the ItÃ´
formula to obtain a stochastic solution of the classical Dirichlet problem. This in turn
is used in the ï¬fth section in order to show that like symmetric simple random walk,
Brownian motion is recurrent in low dimensions and transient in high dimensions.
25.1
ItÃ´ Integral with Respect to Brownian Motion
Let W = (Wt)tâ‰¥0 be a Brownian motion on the space (Î©, F, P) with respect to
the ï¬ltration F that satisï¬es the usual conditions (see Deï¬nition 21.22). That is, W
is a Brownian motion and an F-martingale. The aim of this section is to construct
an integral
I W
t (H) =
 t
0
Hs dWs
for a large class of integrands H : Î©Ã—[0, âˆ) â†’R, (Ï‰, t) â†’Ht(Ï‰) in such a way
that (I W
t (H))tâ‰¥0 is a continuous F-martingale. Since almost all paths s â†’Ws(Ï‰)
of Brownian motion are of locally inï¬nite variation, W(Ï‰) is not the distribution
function of a signed Lebesgueâ€“Stieltjes measure on [0, âˆ). Hence I W
t (H) cannot
be deï¬ned in the framework of classical integration theory. The basic new idea is
to establish the integral as an L2-limit. We start with an elementary example to
illustrate this.
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_25
635

636
25
The ItÃ´ Integral
Example 25.1 Assume that X1, X2, . . . are i.i.d. Rad1/2 random variables; that is,
P[Xn = 1] = P[Xn = âˆ’1] = 1
2. Let (hn)nâˆˆN be a sequence of real numbers.
Under which assumptions on (hn)nâˆˆN is the series
R :=

nâˆˆN
hn Xn
(25.1)
well-deï¬ned? If 
nâˆˆN |hn| < âˆ, then the series converges absolutely for every
Ï‰. In this case, there is no problem. Now assume that only the weaker condition

nâˆˆN h2
n < âˆholds. In this case, the series (25.1) does not necessarily converge
any more for every Ï‰. However, we have E[hn Xn] = 0 for each n âˆˆN and
âˆ
n=1 Var[hn Xn] = âˆ
n=1 h2
n < âˆ. Hence RN := N
k=1 hk Xk converges in L2
(for N â†’âˆ). We can thus deï¬ne the series R in (25.1) as the L2-limit of the
partial sums RN. Note that (at least formally) for the approximating sums the order
of summation matters. In a sense, we have constructed âˆ
n=1 instead of 
nâˆˆN.
An equivalent formulation that gives a ï¬‚avor of what is to come is the following.
Denote by â„“2 the Hilbert space of square summable sequences of real numbers
with inner product âŸ¨h, gâŸ©= âˆ
n=1 hn gn and norm âˆ¥gâˆ¥= âŸ¨g, gâŸ©1/2. Let â„“f be the
subspace of those sequences with only ï¬nitely many nonzero entries. Then R(h) =

nâˆˆN hn Xn for h âˆˆâ„“f is well-deï¬ned (since it is a ï¬nite sum). Since
E
)
R(h)2*
= Var[R(h)] =

nâˆˆN
Var
)
hn Xn
*
=

nâˆˆN
h2
n = âˆ¥hâˆ¥2,
the map R : â„“f â†’L2(P) is an isometry. As â„“f âŠ‚â„“2 is dense, there is a unique
continuous extension of R to â„“2. Hence, if h âˆˆâ„“2 and (hN)NâˆˆN is a sequence
in â„“f with âˆ¥hN âˆ’hâˆ¥
Nâ†’âˆ
âˆ’â†’
0, then R(hN)
Nâ†’âˆ
âˆ’â†’
R(h) in the L2 sense. In
particular, hN
n := hn1{nâ‰¤N}, n âˆˆN, N âˆˆN, is an approximating sequence for h,
and we have R(hN) = N
n=1 hn Xn. Thus the approximation of R with the partial
sums RN that we described above is a special case of this construction. â™¦
The programme for the construction of the ItÃ´ integral I W
t (H) is the following.
First consider simple functions as integrands H; that is, the map t â†’Ht(Ï‰) is a
step function. For these H, the integral can easily be deï¬ned as a ï¬nite sum. The
next step is to extend the integral, as in Example 25.1, to integrands that can be
approximated in a certain L2-space by simple integrands.
Deï¬nition 25.2 Denote by E the vector space of maps H : Î© Ã— [0, âˆ) â†’R of
the form
Ht(Ï‰) =
n

i=1
hiâˆ’1(Ï‰) 1(tiâˆ’1,ti],
where n âˆˆN, 0 = t0 < t1 < . . . < tn and hiâˆ’1 is bounded and Ftiâˆ’1-measurable
for every i = 1, . . . , n. E is called the vector space of predictable simple processes.

25.1
ItÃ´ Integral with Respect to Brownian Motion
637
We equip E with a (pseudo) norm âˆ¥Â· âˆ¥E by deï¬ning
âˆ¥Hâˆ¥2
E =
n

i=1
E
)
h2
iâˆ’1
*
(ti âˆ’tiâˆ’1) = E
+ âˆ
0
H 2
s ds
,
.
Deï¬nition 25.3 For H âˆˆE and t â‰¥0, deï¬ne
I W
t (H) =
n

i=1
hiâˆ’1
Wtiâˆ§t âˆ’Wtiâˆ’1âˆ§t

and
I W
âˆ(H) =
n

i=1
hiâˆ’1
Wti âˆ’Wtiâˆ’1
.
Clearly, for every bounded stopping time Ï„,
E
)
I W
Ï„ (H)
*
=
n

i=1
E
)
hiâˆ’1 (W Ï„
ti âˆ’W Ï„
tiâˆ’1)
*
=
n

i=1
E
)
hiâˆ’1 E
)
W Ï„
ti âˆ’W Ï„
tiâˆ’1
Ftiâˆ’1
**
= 0
since, by the optional stopping theorem (OST), the stopped Brownian motion W Ï„
is an F-martingale. Hence (again by the OST) (I W
t (H))tâ‰¥0 is an F-martingale. In
particular, we have E
)
I W
ti+1(H) âˆ’I W
ti (H)

I W
tj+1(H) âˆ’I W
tj (H)
*
= 0 for i Ì¸= j.
Therefore,
E
)
I W
âˆ(H)2*
=
n

i=1
E
'
I W
ti (H) âˆ’I W
tiâˆ’1(H)
2(
=
n

i=1
E
'
h2
iâˆ’1

Wti âˆ’Wtiâˆ’1
2(
=
n

i=1
E)h2
iâˆ’1
* (ti âˆ’tiâˆ’1) = âˆ¥Hâˆ¥2
E.
(25.2)
From these considerations, the following statement is immediate.
Theorem 25.4
(i) The map I W
âˆ: E â†’L2(Î©, F, P) is an isometric linear map (with respect to
âˆ¥Â· âˆ¥E and âˆ¥Â· âˆ¥2).
(ii) The process

I W
t (H)

tâ‰¥0 is an L2-bounded continuous F-martingale.

638
25
The ItÃ´ Integral
Proof Only the linearity remains to be shown. However, this is trivial.
âŠ“âŠ”
The idea is to extend the map I W
âˆcontinuously from E to a suitable closure E of
E. Now as a subspace of what space should we close E? A minimal requirement is
that (Ï‰, t) â†’Ht(Ï‰) be measurable (with respect to F âŠ—B([0, âˆ))) and that H
be adapted.
Deï¬nition 25.5 A stochastic process X = (Xt)tâ‰¥0 with values in a Polish space
E is called
(i) product measurable if (Ï‰, t) â†’Xt(Ï‰) is measurable with respect to F âŠ—
B([0, âˆ)) â€“ B(E),
(ii) progressively measurable if, for every t â‰¥0, the map Î© Ã— [0, t] â†’E,
(Ï‰, s) â†’Xs(Ï‰) is measurable with respect to Ft âŠ—B([0, t]) â€“ B(E),
(iii) predictable (or previsible) if (Ï‰, t) â†’Xt(Ï‰) is measurable with respect to
the predictable Ïƒ-algebra P on Î© Ã— [0, âˆ):
P := Ïƒ

X : X is a left continuous adapted process

.
Remark 25.6 Any H âˆˆE is predictable. This property ensures that I M(H) is a
martingale for every (even discontinuous) martingale M . The notion of predictabil-
ity is important only for integration with respect to discontinuous martingales. As
we will not develop that calculus in this book, predictability will not be central for
us. â™¦
Remark 25.7 If H is progressively measurable, then H is evidently also product
measurable and adapted. With a little work, the converse can also be shown: If
H is adapted and product measurable, then there is a progressively measurable
modiï¬cation of H (see, e.g., [115, pages 68ff]). â™¦
Theorem 25.8 If H is adapted and right continuous or left continuous, then H
is progressively measurable. If H is adapted and a.s. right continuous or left
continuous, then there exists a version of H that is progressively measurable.
In particular, every predictable process is progressively measurable.
Proof See Exercise 21.1.4.
âŠ“âŠ”
We consider E as a subspace of
E0 :=

H :
product measurable, adapted and âˆ¥Hâˆ¥2 := E
'  âˆ
0
H 2
t dt
(
< âˆ

.
Let E denote the closure of E in E0.
Theorem 25.9 If H is progressively measurable (for instance, left continuous or
right continuous and adapted) and E
' 3 âˆ
0
H 2
t dt
(
< âˆ, then H âˆˆE.

25.1
ItÃ´ Integral with Respect to Brownian Motion
639
Proof Let H be progressively measurable and E
' 3 âˆ
0
H 2
t dt
(
< âˆ. It is enough
to show that, for any T > 0, there exists a sequence (H n)nâˆˆN in E such that
E
+  T
0
(Hs âˆ’H n
s )2 ds
,
nâ†’âˆ
âˆ’â†’0.
(25.3)
Step 1.
First assume that H is continuous and bounded. Deï¬ne H n
0 = 0 and
H n
t = Hi2âˆ’n T
if i2âˆ’n T < t â‰¤(i + 1)2âˆ’n T for some i = 0, . . . , 2n âˆ’1
and H n
t = 0 for t > T . Then H n âˆˆE, and we have H n
t (Ï‰)
nâ†’âˆ
âˆ’â†’Ht(Ï‰) for all
t > 0 and Ï‰ âˆˆÎ©. By the dominated convergence theorem, we get (25.3).
Step 2.
Now let H be progressively measurable and bounded. It is enough to
show that there exist continuous adapted processes H n, n âˆˆN, for which (25.3)
holds. Let
H n
t := n
 tâˆ§T
(tâˆ’1/n)âˆ¨0
Hs ds
for t â‰¥0, n âˆˆN.
Then H n is continuous, adapted and bounded by âˆ¥Hâˆ¥âˆ. By the fundamental
theorem of calculus (see Exercise 13.1.7), we have
H n
t (Ï‰)
nâ†’âˆ
âˆ’â†’Ht(Ï‰)
for Î»-almost all t âˆˆ[0, T ] and for all Ï‰ âˆˆÎ©.
(25.4)
By Fubiniâ€™s theorem and the dominated convergencetheorem, we thus conclude that
E
+  T
0
(Hs âˆ’H n
s )2 ds
,
=

Î©Ã—[0,T ]
Hs(Ï‰) âˆ’H n
s (Ï‰)2 (P âŠ—Î»)(d(Ï‰, s))
nâ†’âˆ
âˆ’â†’0.
Step 3.
Now let H be progressively measurable, and assume E
) 3 âˆ
0
H 2
t dt
*
< âˆ.
It is enough to show that there exists a sequence (H n)nâˆˆN of bounded, progressively
measurable processes such that (25.3) holds. Manifestly, we can choose H n
t
=
Ht 1{|Ht|<n}.
âŠ“âŠ”
Deï¬nition 25.10 (ItÃ´ integral) For H âˆˆE, deï¬ne the ItÃ´ integral
 âˆ
0
Hs dWs := I W
âˆ(H)
as the continuous extension of the map I W
âˆ: E â†’L2(P) to the closure E of E.
In other words, if (H n)nâˆˆN is a sequence in E with âˆ¥H âˆ’H nâˆ¥
nâ†’âˆ
âˆ’â†’0, then we
deï¬ne I W
âˆ(H) by

640
25
The ItÃ´ Integral
I W
âˆ(H) := lim
nâ†’âˆI W
âˆ

H n
in L2.
If Ï„ is a stopping time, then in the following we use the abbreviation
H (Ï„)
t
:= Ht 1{tâ‰¤Ï„}
for t â‰¥0.
(Note that this is not the stopped process H Ï„
t = HÏ„âˆ§t.)
Theorem 25.11
(i) The map I W
âˆ: E â†’L2(Î©, F, P) is linear and
E)I W
âˆ(H)2* = E
+  âˆ
0
H 2
s ds
,
.
(ii) For every H âˆˆE, the process ËœI W(H) deï¬ned by ËœI W
t (H) := I W
âˆ(H (t)) is an
L2-bounded F-martingale that has a continuous modiï¬cation I W (H).
Deï¬nition 25.12 (ItÃ´ integral as a process) Let I W (H) be the continuous version
of the martingale (I W
âˆ(H (t)))tâ‰¥0 (see Theorem 25.11(ii)). Denote by
 t
s
Hr dWr := I W
t (H) âˆ’I W
s (H)
for 0 â‰¤s â‰¤t â‰¤âˆ
the ItÃ´ integral of H with respect to Brownian motion W on the interval [s, t].
Proof (of Theorem 25.11)
(i) This is a direct consequence of the deï¬nition of I W
âˆ(H).
(ii) Let (H n)nâˆˆN be a sequence in E with âˆ¥H n âˆ’Hâˆ¥
nâ†’âˆ
âˆ’â†’
0. By Theo-
rem 25.4(ii), we have
I W
âˆ

(H n)(t)
= I W
t (H n) = E
)
I W
âˆ(H n)
Ft
*
for all t â‰¥0, n âˆˆN.
Since
;;(H n)(t) âˆ’H (t);;
â‰¤
;;H n âˆ’H
;;
nâ†’âˆ
âˆ’â†’
0, this implies (using
Corollary 8.21)
ËœI W
t (H) = lim
nâ†’âˆI W
t (H n) = lim
nâ†’âˆE)I W
âˆ(H n)
Ft
* = E)I W
âˆ(H)
Ft
*.
Hence ËœI W(H) is an L2-bounded martingale and I W
t (H n)
nâ†’âˆ
âˆ’â†’
ËœI W
t (H)
in L2 for every t â‰¥0. By Theorem 25.4(ii), I W (H n) is continuous for
every n âˆˆN. Thus, by Exercise 21.4.3, there exists a continuous modiï¬cation
I W (H) of ËœI W (H).
âŠ“âŠ”
The last step in the construction of the ItÃ´ integral is to weaken the strong
integrability condition E
) 3 âˆ
0
H 2
s ds
*
< âˆ. We start with a simple observation.

25.1
ItÃ´ Integral with Respect to Brownian Motion
641
Let Ï„ be a stopping time and recall that
3 Ï„
0 Hs dWs denotes the random variable
that for any Ï‰ assumes the value
 3 Ï„(Ï‰)
0
Hs dWs

(Ï‰).
Lemma 25.13 Let Ï„ be a stopping time and let H âˆˆE .
(i) We have
 Ï„
0
Hs dWs =
 âˆ
0
H (Ï„)
s
dWs :=
 âˆ
0
Hs 1{sâ‰¤Ï„} dWs
a.s.
(ii) In particular, for any t â‰¥0 , on the event {Ï„ â‰¥t} we have
 t
0
Hs dWs =
 t
0
H (Ï„)
s
dWs
a.s.
(iii) Let G âˆˆE be such that Hs = Gs for all s â‰¤Ï„. Then
 Ï„
0
Hs dWs =
 Ï„
0
Gs dWs
a.s.
Proof
(i) Assume ï¬rst that Ï„ takes values in {k/2n : k âˆˆN0}âˆª{âˆ} for some n âˆˆN.
Then 1{k/2nâ‰¤Ï„}1{tâˆˆ((kâˆ’1)/2n,k/2n]} âˆˆE for all k âˆˆN. If, in addition, H âˆˆE,
then also H (Ï„) âˆˆE and the claim follows directly from the deï¬nition of
the ItÃ´ integral (Deï¬nition 25.3). Now let H âˆˆE and let (H k)kâˆˆN be a
sequence in E such that âˆ¥H k âˆ’Hâˆ¥E
kâ†’âˆ
âˆ’â†’0. Writing H k,(Ï„)
t
:= H k
t 1{tâ‰¤Ï„}
we get that âˆ¥H k,(Ï„) âˆ’H (Ï„)âˆ¥E
kâ†’âˆ
âˆ’â†’0. By choosing a suitable sequence
km â†‘âˆ, we obtain
 Ï„
0
Hs dWs = lim
mâ†’âˆ
 Ï„
0
H km
s
dWs
= lim
mâ†’âˆ
 âˆ
0
H km,(Ï„)
s
dWs =
 âˆ
0
H (Ï„)
s
dWs
a.s.
Finally, assume that Ï„ is an arbitrary stopping time and deï¬ne Ï„n :=
2âˆ’nâŒˆ2nÏ„âŒ‰for n âˆˆN. Then (Ï„n) is a sequence of stopping times with Ï„n â†“
Ï„. Recall that I W(H) is continuous and note that âˆ¥H (Ï„n)âˆ’H (Ï„)âˆ¥E
nâ†’âˆ
âˆ’â†’0.

642
25
The ItÃ´ Integral
Hence by taking a suitable sequence n(m) â†‘âˆ, we get
 Ï„
0
Hs dWs = lim
mâ†’âˆ
 Ï„n(m)
0
Hs dWs
= lim
mâ†’âˆ
 âˆ
0
H (Ï„n(m))
s
dWs =
 âˆ
0
H (Ï„)
s
dWs
a.s.
(ii), (iii) These statements are direct consequences of (i).
âŠ“âŠ”
Deï¬nition 25.14 Let Eloc be the space of progressively measurable stochastic
processes H with
 T
0
H 2
s ds < âˆ
a.s.
for all T > 0.
Lemma 25.15 For every H âˆˆEloc, there exists a sequence (Ï„n)nâˆˆN of stopping
times with Ï„n â†‘âˆalmost surely and E
) 3 Ï„n
0 H 2
s ds
*
< âˆand hence such that
H (Ï„n) âˆˆE for every n âˆˆN.
Proof Deï¬ne
Ï„n := inf
0
t â‰¥0 :
 t
0
H 2
s ds â‰¥n
1
.
By the deï¬nition of Eloc, we have Ï„n â†‘âˆalmost surely. By construction, we have
;;H (Ï„n);;2 = E
) 3 Ï„n
0 H 2
s ds
*
â‰¤n.
âŠ“âŠ”
Deï¬nition 25.16 Let H âˆˆEloc and let (Ï„n)nâˆˆN be as in Lemma 25.15. For t â‰¥0,
deï¬ne the ItÃ´ integral as the almost sure limit
 t
0
Hs dWs := lim
nâ†’âˆ
 t
0
H (Ï„n)
s
dWs.
(25.5)
Theorem 25.17 Let H âˆˆEloc.
(i) The limit in (25.5) is well-deï¬ned and continuous at t. Up to a.s. equality, it is
independent of the choice of the sequence (Ï„n)nâˆˆN.
(ii) If Ï„ is a stopping time with E
) 3 Ï„
0 H 2
s ds
*
< âˆ, then the stopped ItÃ´ integral
 3 Ï„âˆ§t
0
Hs dWs

tâ‰¥0 is an L2-bounded, continuous martingale.
(iii) If E
) 3 T
0 H 2
s ds
*
< âˆfor all T > 0, then
 3 t
0 Hs dWs

tâ‰¥0 is a square
integrable continuous martingale.

25.1
ItÃ´ Integral with Respect to Brownian Motion
643
Proof
(i) By Lemma 25.13(ii), on the event {Ï„n â‰¥t}, we have
 t
0
Hs dWs =
 t
0
H (Ï„n)
s
dWs.
Hence the limit exists, is continuous and is independent of the choice of the
sequence (Ï„n)nâˆˆN.
(ii) This is immediate by Theorem 25.11.
(iii) As we can choose Ï„n = n, this follows from (ii).
âŠ“âŠ”
Theorem 25.18 Let H be progressively measurable and E
) 3 T
0 H 2
s ds
*
< âˆfor
all T > 0. Then
Mt :=
 t
0
Hs dWs,
t â‰¥0,
deï¬nes a square integrable continuous martingale, and
(Nt)tâ‰¥0 :=

M2
t âˆ’
 t
0
H 2
s ds

tâ‰¥0
is a continuous martingale with N0 = 0.
Proof It is enough to show that N is a martingale. Clearly, N is adapted. Let Ï„
be a bounded stopping time. Then
E)NÏ„
* = E
+
M2
Ï„ âˆ’
 Ï„
0
H 2
s ds
,
= E
+  âˆ
0
H (Ï„)
s
dWs
2,
âˆ’E
+  âˆ
0

H (Ï„)
s
2 ds
,
= 0.
Thus, by the optional stopping theorem (see Exercise 21.1.3(iii)), N is a martingale.
âŠ“âŠ”
Recall the notions of local martingales and square variation from Sect. 21.10.
Corollary 25.19 If H
âˆˆEloc, then the ItÃ´ integral Mt
=
3 t
0 Hs dWs is a
continuous local martingale with square variation process âŸ¨MâŸ©t =
3 t
0 H 2
s ds.
Example 25.20
(i) Wt =
3 t
0 1 dWs is a square integrable martingale, and (W 2
t âˆ’t)tâ‰¥0 is a
continuous martingale.
(ii) Since E
) 3 T
0 W 2
s ds
*
=
T 2
2
< âˆfor all T â‰¥0, Mt :=
3 t
0 Ws dWs is
a continuous, square integrable martingale, and

M2
t âˆ’
3 t
0 W 2
s ds

tâ‰¥0 is a
continuous martingale.

644
25
The ItÃ´ Integral
(iii) Assume that H is progressively measurable and bounded, and let Mt :=
3 t
0 Hs dWs. Then M is progressively measurable (since it is continuous and
adapted) and
E
+  T
0
M2
s ds
,
=
 T
0
  s
0
E
)
H 2
r
*
dr
2
ds â‰¤T 2 âˆ¥Hâˆ¥2
âˆ
2
.
Hence 
Mt :=
3 t
0 Ms dWs is a square integrable, continuous martingale and


M2
t âˆ’
3 t
0 M2
s dWs

tâ‰¥0 is a continuous martingale. â™¦
Takeaways We cannot deï¬ne an integral with respect to Brownian motion
as integrator as a Stieltjes integral. This is due to the inï¬nite variation of
paths. The ItÃ´ integral is therefore fundamentally different and is constructed
in two steps. For piecewise constant adapted integrands, it is just the weighted
sum of Brownian increments. By a clever choice of an L2 norm, the
operator that maps the integrand to the integral is an isometry. Hence, the
integral is obtained by continuous extension of the operator. It is deï¬ned for
locally square integrable adapted integrands and is itself a continuous local
martingale.
25.2
ItÃ´ Integral with Respect to Diffusions
If
H =
n

i=1
hiâˆ’1 1(tiâˆ’1,ti] âˆˆE,
(25.6)
then the elementary integral
I M
t (H) =
n

i=1
hiâˆ’1

Mtiâˆ§t âˆ’Mtiâˆ’1âˆ§t

is a martingale (respectively local martingale) if M is a martingale (respectively
local martingale). Furthermore,
E
)
(I M
âˆ(H))2*
=
n

i=1
E
)
h2
iâˆ’1(Mti âˆ’Mtiâˆ’1)2*
=
n

i=1
E
)
h2
iâˆ’1(âŸ¨MâŸ©ti âˆ’âŸ¨MâŸ©tiâˆ’1)
*
= E
+  âˆ
0
H 2
t dâŸ¨MâŸ©t
,

25.2
ItÃ´ Integral with Respect to Diffusions
645
if the expression on the right-hand side is ï¬nite. Roughly speaking, the procedure in
Sect. 25.1 by which we deï¬ned the ItÃ´ integral for Brownian motion and integrands
H âˆˆE can be repeated to construct a stochastic integral with respect to M for
a large class of integrands H. Essentially, in the deï¬nition of the norm on E we
have to replace dt (that is, the square variation of Brownian motion) by the square
variation dâŸ¨MâŸ©t of M:
âˆ¥Hâˆ¥2
M := E
+  âˆ
0
H 2
t dâŸ¨MâŸ©t
,
.
Extending the integral to the closure E works just as for Brownian motion. The
tricky point is to check whether a given integrand is in E. For example, for
discontinuous martingales M the integrands have to be predictable in order for the
stochastic integral to be a martingale (not to mention the difï¬culty of establishing
for such M, the existence of the square variation process). For the case of discrete
time processes, we saw this in Sect. 9.3. Now if M is a continuous martingale with
continuous square variation âŸ¨MâŸ©, then the following problem occurs. In the proof
of Theorem 25.9 in Step 2, in order to show that progressively measurable processes
H are in E, we used the fact that H n
t (Ï‰)
nâ†’âˆ
âˆ’â†’Ht(Ï‰) for Lebesgue-almost all t
and all Ï‰. Now if dâŸ¨MâŸ©t is not absolutely continuous with respect to the Lebesgue
measure, then this is not sufï¬cient to infer convergence of the integrals with respect
to dâŸ¨MâŸ©t. In the case of absolutely continuous square variation, however, that proof
works without change. As in Sect. 25.1, we obtain the following theorem.
Theorem 25.21 Let M be a continuous local martingale with absolutely continu-
ous square variation âŸ¨MâŸ©and let H be a progressively measurable process with
3 T
0 H 2
s dâŸ¨MâŸ©s < âˆa.s. for all T â‰¥0. Then the ItÃ´ integral Nt :=
3 t
0 Hs dMs
is well-deï¬ned and is a continuous local martingale with square variation âŸ¨NâŸ©t =
3 t
0 H 2
s dâŸ¨MâŸ©s. For any sequence (Ï„n)nâˆˆN with Ï„n â†‘âˆand
;;H (Ï„n);;
M < âˆ, and for
any family (H n,m, n, m âˆˆN) âŠ‚E with
;;H n,m âˆ’H (Ï„n);;
M
mâ†’âˆ
âˆ’â†’0, we have
 t
0
Hs dMs = lim
nâ†’âˆlim
mâ†’âˆI M
t (H m,n)
in probability for all t â‰¥0.
The following theorem formulates a certain generalization.
Theorem 25.22 Let M1 and M2 be continuous local martingales with absolutely
continuous square variation. Let H i be progressively measurable processes with
3 T
0 (H i
s )2 dâŸ¨MiâŸ©s < âˆfor i = 1, 2 and T
< âˆ. Let Ni
t
:=
3 t
0 H i
s dMi
s
for i = 1, 2. Then N1 and N2 are continuous local martingales with quadratic
covariation âŸ¨Ni, NjâŸ©t =
3 t
0 H i
s H j
s dâŸ¨Mi, MjâŸ©s for i, j âˆˆ{1, 2}. If M1 and M2
are independent, then âŸ¨N1, N2âŸ©â‰¡0.

646
25
The ItÃ´ Integral
Proof First assume H 1, H 2 âˆˆE. Then there are numbers 0 = t0 < t1 < . . . < tn
and Ftk-measurable bounded maps hi
k, i = 1, 2, k = 0, . . . , n âˆ’1 such that
H i
t (Ï‰) =
n

k=1
hi
kâˆ’1(Ï‰) 1(tkâˆ’1,tk](t).
Therefore,
Ni
t Nj
t =
n

k,l=1
hi
kâˆ’1hj
lâˆ’1

Mi
tkâˆ§t âˆ’Mi
tkâˆ’1âˆ§t

Mj
tlâˆ§t âˆ’Mj
tlâˆ’1âˆ§t

.
Those summands with k Ì¸= l are local martingales. For any of the summands with
k = l,

hi
kâˆ’1hj
kâˆ’1
Mi
tkâˆ§t âˆ’Mi
tkâˆ’1âˆ§t
Mj
tkâˆ§t âˆ’Mj
tkâˆ’1âˆ§t

âˆ’

âŸ¨Mi, MjâŸ©tkâˆ§t âˆ’âŸ¨Mi, MjâŸ©tkâˆ’1âˆ§t

tâ‰¥0
is a local martingale. Since
n

k=1
hi
kâˆ’1hj
kâˆ’1

âŸ¨Mi, MjâŸ©tkâˆ§t âˆ’âŸ¨Mi, MjâŸ©tkâˆ’1âˆ§t

=
 t
0
H i
s H j
s dâŸ¨Mi, MjâŸ©s,

Ni
t Nj
t âˆ’
3 t
0 H i
s H j
s dâŸ¨Mi, MjâŸ©s

tâ‰¥0 is a continuous local martingale.
The case of general progressively measurable H 1, H 2 that satisfy an integrabil-
ity condition follows by the usual L2-approximation arguments.
If M1 and M2 are independent, then âŸ¨M1, M2âŸ©â‰¡0.
âŠ“âŠ”
In the following, we consider processes that can be expressed as ItÃ´ integrals with
respect to a Brownian motion. For these processes, we give a different and more
detailed proof of Theorem 25.21.
Deï¬nition 25.23 Let W be a Brownian motion and let Ïƒ and b be progressively
measurable stochastic processes with
3 t
0 Ïƒ 2
s + |bs| ds < âˆalmost surely for all
t â‰¥0. Then we say that the process X deï¬ned by
Xt =
 t
0
Ïƒs dWs +
 t
0
bs ds
for t â‰¥0
is a generalized diffusion process (or, brieï¬‚y, generalized diffusion) with diffusion
coefï¬cient Ïƒ and drift b. Often X is called an ItÃ´ process.

25.2
ItÃ´ Integral with Respect to Diffusions
647
In particular, if Ïƒ and b are of the form Ïƒs = ËœÏƒ(Xs) and bs = Ëœb(Xs) for
certain maps ËœÏƒ : R â†’[0, âˆ) and Ëœb : R â†’R, then X is called a diffusion (in the
proper sense).
In contrast with generalized diffusions, we will see that under certain regularity
assumptions on the coefï¬cients, diffusions in the proper sense are Markov processes
(compare Theorems 26.8, 26.10 and 26.26).
A diffusion X can always be decomposed as X = M + A, where Mt =
3 t
0 Ïƒs dWs is a continuous local martingale with square variation âŸ¨MâŸ©t =
3 t
0 Ïƒ 2
s ds
(by Corollary 25.19) and At =
3 t
0 bs ds is a continuous process of locally ï¬nite
variation.
Clearly, for the H in (25.6), we have
 t
0
Hs dMs =
n

i=1
hiâˆ’1

Mtiâˆ§t âˆ’Mtiâˆ’1âˆ§t

=
n

i=1
hiâˆ’1
 tiâˆ§t
tiâˆ’1âˆ§t
Ïƒs dWs =
 t
0
(Hs Ïƒs) dWs.
For progressively measurable H with
3 T
0 H 2
s dâŸ¨MâŸ©s =
3 T
0 (HsÏƒs)2 ds < âˆfor
all T â‰¥0, we thus deï¬ne the ItÃ´ integral as
 t
0
Hs dMs :=
 t
0
(HsÏƒs) dWs.
Without further work, in particular, without relying on Theorem 25.21, we get the
following theorem.
Theorem 25.24 Let X = M + A be a generalized diffusion with Ïƒ and let b be
as in Deï¬nition 25.23. Let H be progressively measurable with
 T
0
H 2
s Ïƒ 2
s ds < âˆ
a.s.
for all T â‰¥0
(25.7)
and
 T
0
|Hsbs| ds < âˆ
a.s.
for all T â‰¥0.
(25.8)
Then the process Y deï¬ned by
Yt :=
 t
0
Hs dXs :=
 t
0
Hs dMs +
 t
0
Hs dAs :=
 t
0
HsÏƒs dWs +
 t
0
Hsbs ds

648
25
The ItÃ´ Integral
is a generalized diffusion with diffusion coefï¬cient (HsÏƒs)sâ‰¥0 and drift (Hsbs)sâ‰¥0.
In particular, Nt :=
3 t
0 Hs dMs is a continuous local martingale with square
variation process âŸ¨NâŸ©t =
3 t
0 H 2
s dâŸ¨MâŸ©s =
3 t
0 H 2
s Ïƒ 2
s ds.
Takeaways Diffusions are stochastic processes that are a sum of a process of
bounded variation and a stochastic integral with respect to a Brownian motion.
We have deï¬ned the ItÃ´ integral for diffusions as integrators in a procedure
similar to the one for Brownian motion. The stochastic integrals are again
diffusions.
Exercise 25.2.1 Let M be a continuous local martingale with absolutely continuous
square variation âŸ¨MâŸ©(e.g., a generalized diffusion), and let H be progressively
measurable and continuous with
3 T
0 H 2
s dâŸ¨MâŸ©s < âˆfor all T â‰¥0. Further,
assume that P = (P(n))nâˆˆN is an admissible sequence of partitions (see Deï¬ni-
tion 21.56).
(i) Show that for all T â‰¥0, in the sense of stochastic convergence, we have
 T
0
Hs dMs = lim
nâ†’âˆ

tâˆˆPn
T
Ht(Mtâ€² âˆ’Mt).
(25.9)
(ii) Show that there exists a subsequence of P such that almost surely, we
have (25.9) for all T â‰¥0. â™£
25.3
The ItÃ´ Formula
This and the following two sections are based on lecture notes of Hans FÃ¶llmer.
If t â†’Xt is a differentiable map with derivative Xâ€² and F âˆˆC1(R) with
derivative F â€², then we have the classical substitution rule
F(Xt) âˆ’F(X0) =
 t
0
F â€²(Xs) dXs =
 t
0
F â€²(Xs)Xâ€²
s ds.
(25.10)
This remains true even if X is continuous and has locally ï¬nite variation (see
Sect. 21.10); that is, if X is the distribution function of an absolutely continuous
signed measure on [0, âˆ). In this case, the derivative Xâ€² exists as a Radonâ€“
Nikodym derivative almost everywhere, and it is easy to show that (25.10) also
holds in this case.
The paths of Brownian motion W are nowhere differentiable (Theorem 21.17
due to Paley, Wiener and Zygmund) and thus have everywhere locally inï¬nite

25.3
The ItÃ´ Formula
649
variation. Hence a substitution rule as simple as (25.10) cannot be expected. Indeed,
it is easy to see that such a rule must be false: Choose F(x) = x2. Then the
right-hand side in (25.10) (with X replaced by W) is
3 t
0 2Ws dWs and is hence a
martingale. The left-hand side, however, equals W 2
t , which is a submartingale that
only becomes a martingale by subtracting t. Indeed, this t is the additional term
that shows up in the substitution rule for ItÃ´ integrals, the so-called ItÃ´ formula. A
somewhat bold heuristic puts us on the right track: For small t, Wt is of order âˆšt.
If we formally write dWt =
âˆš
dt and carry out a Taylor expansion of F âˆˆC2(R)
up to second order, then we obtain
dF(Wt) = F â€²(Wt) dWt + 1
2F â€²â€²(Wt) (dWt)2 = F â€²(Wt) dWt + 1
2F â€²â€²(Wt) dt.
Rewriting this as an integral yields
F(Wt) âˆ’F(W0) =
 t
0
F â€²(Ws) dWs +
 t
0
1
2F â€²â€²(Ws) ds.
(25.11)
(For certain discrete martingales, we derived a similar formula in Example 10.9.)
The main goal of this section is to show that this so-called ItÃ´ formula is indeed
correct.
The subsequent discussion in this section does not explicitly rely on the
assumption that we integrate with respect to Brownian motion. All that is needed is
that the function with respect to which we integrate have continuous square variation
(along a suitable admissible sequence of partitions P = (Pn)nâˆˆN)). In particular,
for Brownian motion, âŸ¨WâŸ©t = t.
In the following, let P = (Pn)nâˆˆN be an admissible sequence of partitions
(recall the deï¬nition of Cqv = CP
qv, Pn
T , Pn
S,T , tâ€² and so on from Deï¬nitions 21.56
and 21.58). Let X âˆˆC([0, âˆ)) with continuous square variation (along P)
T â†’âŸ¨XâŸ©T = V 2
T (X) = lim
nâ†’âˆ

tâˆˆPn
T
(Xtâ€² âˆ’Xt)2.
For Brownian motion, we have W âˆˆCP
qv almost surely for any admissible sequence
of partitions (Theorem 21.64) and âŸ¨WâŸ©T = T . For continuous local martingales M
passing to a suitable subsequence Pâ€² of P ensures that M âˆˆCPâ€²
qv almost surely
(Theorem 21.70).
Now ï¬x P and let X âˆˆCqv be a (deterministic) function.
Theorem 25.25 (Pathwise ItÃ´ formula) Let X âˆˆCqv and F âˆˆC2(R). Then, for
all T â‰¥0, there exists the limit
 T
0
F â€²(Xs) dXs := lim
nâ†’âˆ

tâˆˆPn
T
F â€²(Xt)(Xtâ€² âˆ’Xt).
(25.12)

650
25
The ItÃ´ Integral
Furthermore, the ItÃ´ formula holds:
F(XT ) âˆ’F(X0) =
 T
0
F â€²(Xs) dXs + 1
2
 T
0
F â€²â€²(Xs) dâŸ¨XâŸ©s.
(25.13)
Here the right integral in (25.13) is understood as a classical (Lebesgueâ€“Stieltjes)
integral.
Remark 25.26 If M is a continuous local martingale, then, by Exercise 25.2.1, the
ItÃ´ integral
3 T
0 F â€²(Ms) dMs is the stochastic limit of

tâˆˆPn
T
F â€²(Mt)(Mtâ€² âˆ’Mt) as
n â†’âˆ. Thus, in fact, for X = M(Ï‰), the pathwise integral in (25.12) coincides
with the ItÃ´ integral (a.s.). In particular, for the ItÃ´ integral of Brownian motion, the
ItÃ´ formula (25.11) holds. â™¦
Proof (of Theorem 25.25) We have to show that the limit in (25.12) exists and that
(25.13) holds.
For n âˆˆN and t âˆˆPn
T (with successor tâ€² âˆˆPn
T ), the Taylor formula yields
F(Xtâ€²) âˆ’F(Xt) = F â€²(Xt)(Xtâ€² âˆ’Xt) + 1
2F â€²â€²(Xt) Â· (Xtâ€² âˆ’Xt)2 + Rn
t ,
(25.14)
where the remainder
Rn
t =

F â€²â€²(Î¾) âˆ’F â€²â€²(Xt)

Â· 1
2(Xtâ€² âˆ’Xt)2
(for a suitable Î¾ between Xt and Xtâ€²) can be bounded as follows. As X is
continuous, C := {Xt : t âˆˆ[0, T ]} is compact and F â€²â€²
C is uniformly continuous.
Thus, for every Îµ > 0, there exists a Î´ > 0 with
|F â€²â€²(Xr) âˆ’F â€²â€²(Xs)| < Îµ
for all r, s âˆˆ[0, T ] with |Xr âˆ’Xs| < Î´.
Since X is uniformly continuous on [0, T ] and since the mesh size |Pn| of the
partition goes to 0 as n â†’âˆ, for every Î´ > 0, there exists an NÎ´ such that
sup
nâ‰¥NÎ´
sup
tâˆˆPn
T
|Xtâ€² âˆ’Xt| < Î´.
Hence, for n â‰¥NÎ´ and t âˆˆPn
T ,
|Rn
t | â‰¤1
2Îµ (Xtâ€² âˆ’Xt)2.
Summing over t âˆˆPn
T in (25.14) yields

tâˆˆPn
T

F(Xtâ€²) âˆ’F(Xt)

= F(XT ) âˆ’F(X0)

25.3
The ItÃ´ Formula
651
and

tâˆˆPn
T
|Rn
t | â‰¤Îµ

tâˆˆPn
T
(Xtâ€² âˆ’Xt)2
nâ†’âˆ
âˆ’â†’Îµ âŸ¨XâŸ©T < âˆ.
As Îµ > 0 was arbitrary, we get 
tâˆˆPn
T |Rn
t |
nâ†’âˆ
âˆ’â†’
0. We have (see Exer-
cise 21.10.2)

tâˆˆPn
T
1
2F â€²â€²(Xt)(Xtâ€² âˆ’Xt)2 nâ†’âˆ
âˆ’â†’1
2
 T
0
F â€²â€²(Xs) dâŸ¨XâŸ©s.
Hence, in (25.14) the sum of the remaining terms also has to converge. That is, the
limit in (25.12) exists.
âŠ“âŠ”
As a direct consequence, we obtain the ItÃ´ formula for the ItÃ´ integral with respect
to diffusions.
Theorem 25.27 (ItÃ´ formula for diffusions) Let Y = M + A be a (generalized)
diffusion (see Deï¬nition 25.23), where Mt =
3 t
0 Ïƒs dWs and At =
3 t
0 bs ds. Let
F âˆˆC2(R). Then we have the ItÃ´ formula
F(Yt) âˆ’F(Y0) =
 t
0
F â€²(Ys) dMs +
 t
0
F â€²(Ys) dAs + 1
2
 t
0
F â€²â€²(Ys) dâŸ¨MâŸ©s
=
 t
0
F â€²(Ys)Ïƒs dWs +
 t
0

F â€²(Ys)bs + 1
2F â€²â€²(Ys)Ïƒ 2
s

ds.
(25.15)
In particular, for Brownian motion,
F(Wt) âˆ’F(W0) =
 t
0
F â€²(Ws) dWs + 1
2
 t
0
F â€²â€²(Ws) ds.
(25.16)
As an application of the ItÃ´ formula, we characterize Brownian motion as a
continuous local martingale with a certain square variation process.
Theorem 25.28 (LÃ©vyâ€™s characterization of Brownian motion) Let X âˆˆMloc,c
with X0 = 0. Then the following are equivalent.
(i) (X2
t âˆ’t)tâ‰¥0 is a local martingale.
(ii) âŸ¨XâŸ©t = t for all t â‰¥0.
(iii) X is a Brownian motion.
Proof (iii) â‡’(i)
This is obvious.
(i) â‡â‡’(ii)
This is clear since the square variation process is unique.
(ii) â‡’(iii)
It is enough to show that Xt âˆ’Xs âˆ¼N0,tâˆ’s given Fs for t > s â‰¥0.
Employing the uniqueness theorem for characteristic functions, it is enough to show

652
25
The ItÃ´ Integral
that (with i = âˆšâˆ’1) for A âˆˆFs and Î» âˆˆR, we have
Ï•A,Î»(t) := E
)
eiÎ»(Xtâˆ’Xs) 1A
*
= P[A] eâˆ’Î»2(tâˆ’s)/2.
Applying ItÃ´â€™s formula separately to the real and the imaginary parts, we obtain
eiÎ»Xt âˆ’eiÎ»Xs =
 t
s
i Î» eiÎ»Xr dXr âˆ’1
2
 t
s
Î»2 eiÎ»Xr dr.
Therefore,
E
)
eiÎ»(Xtâˆ’Xs) Fs
*
âˆ’1
= E
+ t
s
i Î» eiÎ»(Xrâˆ’Xs) dXr
Fs
,
âˆ’1
2 Î»2 E
+ t
s
eiÎ»(Xrâˆ’Xs) dr
Fs
,
.
Now Mt := Re 3 t
s i Î» eiÎ»(Xrâˆ’Xs) dXr and Nt := Im 3 t
s i Î» eiÎ»(Xrâˆ’Xs) dXr, t â‰¥s are
continuous local martingales with
âŸ¨MâŸ©t =
 t
s
Î»2 sin

Î»(Xr âˆ’Xs)
2 dr â‰¤Î»2(t âˆ’s)
and
âŸ¨NâŸ©t =
 t
s
Î»2 cos

Î»(Xr âˆ’Xs)
2 dr â‰¤Î»2(t âˆ’s).
Thus, by Corollary 21.76, M and N are martingales. Hence we have
E
+ t
s
i Î» eiÎ»(Xrâˆ’Xs) dXr
Fs
,
= 0.
Since A âˆˆFs, Fubiniâ€™s theorem yields
Ï•A,Î»(t) âˆ’Ï•A,Î»(s) = E)eiÎ»(Xtâˆ’Xs) 1A
* âˆ’P[A]
= âˆ’1
2 Î»2
 t
s
E
)
eiÎ»(Xrâˆ’Xs) 1A
*
dr = âˆ’1
2 Î»2
 t
s
Ï•A,Î»(r) dr.
That is, Ï•A,Î» is the solution of the linear differential equation
Ï•A,Î»(s) = P[A]
and
d
dt Ï•A,Î»(t) = âˆ’1
2 Î»2 Ï•A,Î»(t).
The unique solution is Ï•A,Î»(t) = P[A] eâˆ’Î»2(tâˆ’s)/2.
âŠ“âŠ”

25.3
The ItÃ´ Formula
653
As a consequence of this theorem, we get that any continuous local martingale
whose square variation process is absolutely continuous (as a function of time) can
be expressed as an ItÃ´ integral with respect to some Brownian motion.
Theorem 25.29 (ItÃ´â€™s martingale representation theorem) Let M be a contin-
uous local martingale with M0 = 0 and absolutely continuous square variation
t â†’âŸ¨MâŸ©t. Then, on a suitable extension of the underlying probability space, there
exists a Brownian motion W with
Mt =
 t
0
K
dâŸ¨MâŸ©s
ds
dWs
for all t â‰¥0.
Proof Assume that the probability space is rich enough to carry a Brownian motion

W that is independent of M . Let
ft := lim
nâ†’âˆn

âŸ¨MâŸ©t âˆ’âŸ¨MâŸ©tâˆ’1/n

for t > 0.
Then f is a progressively measurable version of the Radonâ€“Nikodym derivative
dâŸ¨MâŸ©t
dt
. Clearly,
3 T
0 1{ft>0} f âˆ’1
t
dâŸ¨MâŸ©t â‰¤T
< âˆfor all T
> 0. Hence the
following integrals are well-deï¬ned, and furthermore, as a sum of continuous
martingales,
Wt :=
 t
0
1{fs>0} f âˆ’1/2
s
dMs +
 t
0
1{fs=0} d 
Ws
is a continuous local martingale. By Theorem 25.22, we have
âŸ¨WâŸ©t =
 t
0
1{fs>0} f âˆ’1
s
dâŸ¨MâŸ©s +
 t
0
1{fs=0} ds
=
 t
0
1{fs>0} f âˆ’1
s
fs ds +
 t
0
1{fs=0} ds
= t.
Hence, by Theorem 25.28, W is a Brownian motion. On the other hand, we have
 t
0
f 1/2
s
dWs =
 t
0
1{fs>0} f 1/2
s
f âˆ’1/2
s
dMs +
 t
0
1{fs=0} f 1/2
s
d 
Ws
=
 t
0
1{fs>0} dMs.
However,
Mt âˆ’
 t
0
1{fs>0} dMs =
 t
0
1{fs=0} dMs

654
25
The ItÃ´ Integral
is a continuous local martingale with square variation 3 t
0 1{fs=0} dâŸ¨MâŸ©s = 0 and
hence it almost surely equals zero. Therefore, we have Mt =
3 t
0 f 1/2
s
dWs, as
claimed.
âŠ“âŠ”
Reï¬‚ection In Theorem 25.29, why is it not sufï¬cient to postulate continuity of the
map t â†’âŸ¨MâŸ©t instead of absolute continuity? Find a counterexample! â™ 
We come next to a multidimensional version of the pathwise ItÃ´ formula. To
this end, let Cd
qv be the space of continuous maps X : [0, âˆ) â†’Rd, t â†’
Xt = (X1
t , . . . , Xd
t ) such that, for k, l = 1, . . ., d, the quadratic covariation
(see Deï¬nition 21.58) âŸ¨Xk, XlâŸ©exists and is continuous. Further, let C2(Rd) be
the space of twice continuously differentiable functions F on Rd with partial
derivatives âˆ‚kF and âˆ‚kâˆ‚lF, k, l = 1, . . . , d. Denote by âˆ‡the gradient and by
â–³= (âˆ‚2
1 + . . . + âˆ‚2
d) the Laplace operator.
Theorem 25.30 (Multidimensional pathwise ItÃ´ formula) Let X âˆˆCd
qv and
F âˆˆC2(Rd). Then
F(XT ) âˆ’F(X0) =
 T
0
âˆ‡F(Xs) dXs + 1
2
d

k,l=1
 T
0
âˆ‚kâˆ‚lF(Xs) dâŸ¨Xk, XlâŸ©s,
where
 T
0
âˆ‡F(Xs) dXs := lim
nâ†’âˆ

tâˆˆPn
T
d

k=1
âˆ‚kF(Xt)(Xk
tâ€² âˆ’Xk
t ).
Proof This works just as in the one-dimensional case. We leave the details as an
exercise.
âŠ“âŠ”
Remark 25.31 If each of the integrals
3 T
0 âˆ‚kF(Xs) dXk
s exists, then
 T
0
âˆ‡F(Xs) dXs =
d

k=1
 T
0
âˆ‚kF(Xs) dXk
s .
Note that existence of the individual integrals does not follow from the existence of
the integral 3 T
0 âˆ‡F(Xs) dXs.â™¦
Corollary 25.32 (Product rule) If X, Y, X âˆ’Y, X + Y âˆˆCqv, then
XT YT = X0Y0 +
 T
0
Ys dXs +
 T
0
Xs dYs + âŸ¨X, YâŸ©T
for all T â‰¥0
if both integrals exist. In particular, the product rule holds if X and Y are
continuous local martingales.

25.3
The ItÃ´ Formula
655
Proof By assumption (and using the polarization formula), the covariation âŸ¨X, YâŸ©
exists. Applying Theorem 25.30 with F(x, y) = xy, the claim follows.
For continuous local martingales, by Exercise 25.2.1, there exists a suitable
sequence of partitions P such that the integrals exist (pathwise).
âŠ“âŠ”
Now let Y = M + A be a d-dimensional generalized diffusion. Hence
Mk
t =
d

l=1
 t
0
Ïƒ k,l
s
dW l
s
and
Ak
t =
 t
0
bk
s ds
for t â‰¥0, k = 1, . . . , d.
Here W
=
(W 1, . . . , W d) is a d-dimensional Brownian motion and Ïƒ k,l
(respectively bk) are progressively measurable, locally square integrable (respec-
tively locally integrable) stochastic processes for every k, l = 1, . . . , d. Since
âŸ¨W k, W lâŸ©t = t Â· 1{k=l}, we have âŸ¨Y k, Y lâŸ©t = âŸ¨Mk, MlâŸ©t =
3 t
0 ak,l
s
ds, where
ak,l
s
:=
d

i=1
Ïƒ k,i
s
Ïƒ l,i
s
is the covariance matrix of the diffusion M. In particular, we have M âˆˆCd
qv
almost surely. Note that (by Exercise 25.2.1), there exists a partition sequence P
such that the integrals
3 t
0 Ïƒ k,l
s
âˆ‚kF(Ys) dW l
s in (25.17) exist in the pathwise sense.
As a corollary of the multidimensional pathwise ItÃ´ formula (Theorem 25.30 and
Remark 25.31), we thus get the following theorem.
Theorem 25.33 (Multidimensional ItÃ´ formula) Let Y be as above and let F âˆˆ
C2(Rd). Then
F(YT ) âˆ’F(Y0) =
 T
0
âˆ‡F(Ys) dYs + 1
2
d

k,l=1
 T
0
âˆ‚kâˆ‚lF(Ys) dâŸ¨Mk, MlâŸ©s
=
d

k,l=1
 T
0
Ïƒ k,l
s
âˆ‚kF(Ys) dW l
s +
d

k=1
 T
0
bk
s âˆ‚kF(Ys) ds
+ 1
2
d

k,l=1
 T
0
ak,l
s
âˆ‚kâˆ‚lF(Ys) ds.
(25.17)
In particular, for Brownian motion, we have
F(Wt) âˆ’F(W0) =
d

k=1
 t
0
âˆ‚kF(Ws) dW k
s + 1
2
 t
0
â–³F(Ws) ds.
(25.18)

656
25
The ItÃ´ Integral
Corollary 25.34 The process (F(Wt))tâ‰¥0 is a continuous local martingale if and
only if F is harmonic (that is, â–³F â‰¡0).
Proof If F is harmonic, then as a sum of ItÃ´ integrals, F(Wt) = F(W0) +
d
k=1
3 t
0 âˆ‚kF(Ws) dW k
s is a continuous local martingale.
On the other hand, if (F(Wt))tâ‰¥0 is a continuous local martingale, then as a
difference of continuous local martingales,
3 t
0 â–³F(Ws) ds is also a continuous local
martingale. As t â†’
3 t
0 â–³F(Ws) ds has ï¬nite variation, we have
3 t
0 â–³F(Ws) ds =
0 for all t â‰¥0 almost surely (by Corollary 21.72). Hence â–³F â‰¡0.
âŠ“âŠ”
Corollary 25.35 (Time-dependent ItÃ´ formula) If F âˆˆC2,1(Rd Ã— R), then
F(WT , T ) âˆ’F(W0, 0)
=
d

k=1
 T
0
âˆ‚kF(Ws, s) dW k
s +
 T
0

âˆ‚d+1 + 1
2(âˆ‚2
1 + . . . + âˆ‚2
d)

F(Ws, s) ds.
Proof Apply Theorem 25.33 to Y = (W 1
t , . . . , W d
t , t)tâ‰¥0.
âŠ“âŠ”
Takeaways The ItÃ´ formula is the probabilistic analogue to the substitution
rule for Riemann integrals. Any continuous local martingale with absolutely
continuous variance process can be represented as an ItÃ´ integral with respect
to some Brownian motion. In particular, it is a diffusion. Compare with the
representation theorem in discrete time that we derived in Theorem 9.43.
Exercise 25.3.1 (Fubiniâ€™s theorem for ItÃ´ integrals) Let X âˆˆCqv and assume
that g : [0, âˆ)2 â†’R is continuous and (in the interior) twice continuously
differentiable in the second coordinate with derivative âˆ‚2g. Use the product rule
(Corollary 25.32) to show that
 s
0
 t
0
g(u, v) du

dXv =
 t
0
 s
0
g(u, v) dXv

du
and
 s
0
 v
0
g(u, v) du

dXv =
 s
0
 s
u
g(u, v) dXv

du.
â™£
Exercise 25.3.2 (Stratonovich integral) Let P be an admissible sequence of
partitions, X âˆˆCP
qv and F âˆˆC2(R) with derivative f = F â€². Show that, for every

25.4
Dirichlet Problem and Brownian Motion
657
t â‰¥0, the Stratonovich integral
 T
0
f (Xt) â—¦dXt := lim
nâ†’âˆ

tâˆˆPn
T
f
Xtâ€² + Xt
2
 Xtâ€² âˆ’Xt

is well-deï¬ned, and that the classical substitution rule
F(XT ) âˆ’F(X0) =
 T
0
F â€²(Xt) â—¦dXt
holds. Show that, in contrast with the ItÃ´ integral, the Stratonovich integral with
respect to a continuous local martingale is, in general, not a local martingale. â™£
25.4
Dirichlet Problem and Brownian Motion
As for discrete Markov chains (compare Sect. 19.1), the solutions of the Dirichlet
problem in a domain G âŠ‚Rd can be expressed in terms of a d-dimensional
Brownian motion that is stopped upon hitting the boundary G.
In the following, let G âŠ‚Rd be a bounded open set.
Deï¬nition 25.36 (Dirichlet problem) Let f : âˆ‚G â†’R be continuous. A function
u : G â†’R is called a solution of the Dirichlet problem on G with boundary value
f if u is continuous, twice differentiable in G and
â–³u(x) = 0
for x âˆˆG,
u(x) = f (x)
for x âˆˆâˆ‚G.
(25.19)
For sufï¬ciently smooth domains, there always exists a solution of the Dirichlet
problem (see, e.g., [79, Section 4.4]). If there is a solution, then as a consequence of
Theorem 25.38, it is unique.
In the following, let W = (W 1, . . . , W d) be a d-dimensional Brownian motion
with respect to a ï¬ltration F that satisï¬es the usual conditions. We write Px and Ex
for probabilities and expectations if W is started at W0 = x = (x1, . . . , xd) âˆˆRd.
If A âŠ‚Rd is open, then
Ï„Ac := inf
	
t > 0 : Wt âˆˆAc
is an F-stopping time (see Exercise 21.4.4). Since G is bounded, we have G âŠ‚
(âˆ’a, a) Ã— Rdâˆ’1 for some a > 0. Thus Ï„Gc â‰¤Ï„((âˆ’a,a)Ã—Rdâˆ’1)c. By Exercise 21.2.4
(applied to W 1), for x âˆˆG,
Ex
)
Ï„Gc*
â‰¤Ex
)
Ï„((âˆ’a,a)Ã—Rdâˆ’1)c
*
= (a âˆ’x1)(a + x1) < âˆ.
(25.20)

658
25
The ItÃ´ Integral
In particular, Ï„Gc < âˆPx-almost surely. Hence WÏ„Gc is a Px-almost surely well-
deï¬ned random variable with values in âˆ‚G.
Deï¬nition 25.37 For x âˆˆG, denote by
Î¼x,G = Px â—¦W âˆ’1
Ï„Gc
the harmonic measure on âˆ‚G.
Theorem 25.38 If u is a solution of the Dirichlet problem on G with boundary
value f , then
u(x) = Ex
)
f (WÏ„Gc )
*
=

âˆ‚G
f (y) Î¼x,G(dy)
for x âˆˆG.
(25.21)
In particular, the solution of the Dirichlet problem is always unique.
Proof Let G1 âŠ‚G2 âŠ‚. . . be a sequence of open sets with x âˆˆG1, Gn â†‘G and
Gn âŠ‚G for every n âˆˆN. Hence, in particular, every Gn is compact and thus âˆ‡u
is bounded on Gn. We abbreviate Ï„ := Ï„Gc and Ï„n := Ï„Gcn.
As u is harmonic (that is, â–³u = 0), by the ItÃ´ formula, for t < Ï„,
u(Wt) = u(W0) +
 t
0
âˆ‡u(Ws) dWs = u(W0) +
d

k=1
 t
0
âˆ‚ku(Ws) dW k
s .
(25.22)
In particular, M := (u(Wt))tâˆˆ[0,Ï„) is a local martingale up to Ï„ (however, in
general, it is not a martingale). For t < Ï„n, we have
(âˆ‚ku(Ws))2 â‰¤Cn := sup
yâˆˆGn
âˆ¥âˆ‡u(y)âˆ¥2
2 < âˆ
for all k = 1, . . . , d.
Hence, by (25.20),
E
+  Ï„n
0
(âˆ‚ku(Ws))2 ds
,
â‰¤Cn Ex[Ï„n] â‰¤Cn E[Ï„] < âˆ.
Thus, by Theorem 25.17(ii), for every n âˆˆN, the stopped process MÏ„n is a
martingale. Therefore,
Ex[u(WÏ„n)] = Ex[MÏ„n] = Ex[M0] = u(x).
(25.23)
As W is continuous and Ï„n â†‘Ï„, we have WÏ„n
nâ†’âˆ
âˆ’â†’
WÏ„ âˆˆâˆ‚G. Since u is
continuous, we get
u(WÏ„n)
nâ†’âˆ
âˆ’â†’u(WÏ„ ) = f (WÏ„ ).
(25.24)

25.5
Recurrence and Transience of Brownian Motion
659
Again, since u is continuous and G is compact, u is bounded. By the dominated
convergence theorem, (25.24) implies convergence of the expectations; that is (also
using (25.23)),
u(x) = lim
nâ†’âˆEx
)
u(WÏ„n)
*
= Ex
)
f (WÏ„ )
*
.
âŠ“âŠ”
Reï¬‚ection A Dirichlet problem need not have a solution. Find an example based
on the punctured disc G := {(x, y) âˆˆR2 : x2 + y2 âˆˆ(0, 1)} that does not have a
solution. â™ 
Takeaways If the solution of a Dirichlet problem exists, then it is the
expected value of the boundary value at the random point where Brownian
motion ï¬rst leaves the domain. As similar statement for discrete Markov
chains was shown in equation (19.1).
Exercise 25.4.1 Let G = R Ã— (0, âˆ) be the open upper half plane of R2 and
x = (x1, x2) âˆˆG. Show that Ï„Gc < âˆalmost surely and that the harmonic
measure Î¼x,G on R âˆ¼= âˆ‚G is the Cauchy distribution with scale parameter x2 that
is shifted by x1: Î¼x,G = Î´x1 âˆ—Caux2. â™£
Exercise 25.4.2 Let d â‰¥3 and let G = Rdâˆ’1 Ã— (0, âˆ) be an open half space of
Rd. Let x = (x1, . . . , xd) âˆˆG. Show that Ï„Gc < âˆalmost surely and that the
harmonic measure Î¼x,G on Rdâˆ’1 âˆ¼= âˆ‚G has the density
Î¼x,G(dy)
dy
= Î“ (d/2)
Ï€d/2
xd
S
(x1 âˆ’y1)2 + . . . + (xdâˆ’1 âˆ’ydâˆ’1)2 + x2
d
.
â™£
Exercise 25.4.3 Let r > 0 and let Br(0) âŠ‚Rd be the open ball with radius r
centered at the origin. For x âˆˆBr(0), determine the harmonic measure Î¼x,Br(0). â™£
25.5
Recurrence and Transience of Brownian Motion
By PÃ³lyaâ€™s theorem (Theorem 17.40), symmetric simple random walk (Xn)nâˆˆN on
Zd is recurrent (that is, it visits every point inï¬nitely often) if and only if d â‰¤2. If
d > 2, then the random walk is transient and eventually leaves every bounded set
A âŠ‚Zd. To give a slightly different (though equivalent) formulation of this,
lim inf
nâ†’âˆâˆ¥Xnâˆ¥= 0 a.s.
â‡â‡’
d â‰¤2

660
25
The ItÃ´ Integral
and
lim
nâ†’âˆâˆ¥Xnâˆ¥= âˆa.s.
â‡â‡’
d > 2.
The main result of this section is that a similar dichotomy also holds for Brownian
motion.
Theorem 25.39 Let
W
=
(W 1, . . . , W d)
be a
d-dimensional Brownian
motion.
(i) If d â‰¤2, then W is recurrent in the sense that
lim inf
tâ†’âˆâˆ¥Wt âˆ’yâˆ¥= 0 a.s.
for every y âˆˆRd.
In particular, almost surely the path {Wt : t â‰¥0} is dense in Rd.
(ii) If d > 2, then W is transient in the sense that
lim
tâ†’âˆâˆ¥Wtâˆ¥= âˆa.s.,
and for any y âˆˆRd \ {0}, we have inf{âˆ¥Wt âˆ’yâˆ¥: t â‰¥0} > 0 almost surely.
The basic idea of the proof is to use a suitable Dirichlet problem (and the result of
Sect. 25.4) to compute the probabilities for W to hit certain balls,
BR(x) :=
	
y âˆˆRd : âˆ¥x âˆ’yâˆ¥< R

.
Let 0 < r < R < âˆand let Gr,R be the annulus
Gr,R := BR(0) \ Br(0) =
	
x âˆˆRd : r < âˆ¥xâˆ¥< R

.
Recall that, for closed A âŠ‚Rd, we write Ï„A = inf{t > 0 : Wt âˆˆA} for the
stopping time of ï¬rst entrance into A. We further write
Ï„s := inf
	
t > 0 : âˆ¥Wtâˆ¥= s

and
Ï„r,R = inf
	
t > 0 : Wt Ì¸âˆˆGr,R

.
If we start W at W0 âˆˆGr,R, then clearly Ï„r,R = Ï„r âˆ§Ï„R. On the boundary of Gr,R,
deï¬ne the function f by
f (x) =

1,
if âˆ¥xâˆ¥= r,
0,
if âˆ¥xâˆ¥= R.
(25.25)
Deï¬ne ur,R : Gr,R â†’R by
ur,R(x) = V (âˆ¥xâˆ¥) âˆ’V (R)
V (r) âˆ’V (R) ,

25.5
Recurrence and Transience of Brownian Motion
661
where V : (0, âˆ) â†’R is Newtonâ€™s potential function
V (s) = Vd(s) =
â§
âªâªâ¨
âªâªâ©
s,
if d = 1,
log(s),
if d = 2,
âˆ’s2âˆ’d,
if d > 2.
(25.26)
It is easy to check that Ï• : Rd \ {0} â†’R, x â†’Vd(âˆ¥xâˆ¥) is harmonic (that
is, â–³Ï• â‰¡0). Hence ur,R is the solution of the Dirichlet problem on Gr,R with
boundary value f . By Theorem 25.38, for x âˆˆGr,R,
Px
)Ï„r,R = Ï„r
* = Px
)âˆ¥WÏ„r,Râˆ¥= r* = Ex
)f (WÏ„r,R)* = ur,R(x).
(25.27)
Theorem 25.40 For r > 0 and x, y âˆˆRd with âˆ¥x âˆ’yâˆ¥> r, we have
Px
)Wt âˆˆBr(y) for some t > 0* =
â§
â¨
â©
1,
if d â‰¤2,

âˆ¥xâˆ’yâˆ¥
r
2âˆ’d
,
if d > 2.
Proof Without loss of generality, assume y = 0. Then
Px[Ï„r < âˆ] =
lim
Râ†’âˆPx[Ï„r,R = Ï„r] =
lim
Râ†’âˆ
V (âˆ¥xâˆ¥) âˆ’V (R)
V (r) âˆ’V (R)
=
â§
â¨
â©
1,
if d â‰¤2,
Vd(âˆ¥xâˆ¥)
Vd(r) ,
if d > 2,
since limRâ†’âˆVd(R) = âˆif d â‰¤2 and = 0 if d > 2.
âŠ“âŠ”
Proof (of Theorem 25.39) Using the strong Markov property of Brownian motion,
we get for r > 0
Px
'
lim inf
tâ†’âˆâˆ¥Wtâˆ¥< r
(
= Px
+ 
sâˆˆ(0,r)

R>âˆ¥xâˆ¥
	
âˆ¥Wtâˆ¥â‰¤s for some t > Ï„R

,
=
sup
sâˆˆ(0,r)
inf
R>âˆ¥xâˆ¥Px
)
âˆ¥Wtâˆ¥â‰¤s for some t > Ï„R
*
=
sup
sâˆˆ(0,r)
inf
R>âˆ¥xâˆ¥Px
)
PWÏ„R [Ï„s < âˆ]
*
.

662
25
The ItÃ´ Integral
However, by Theorem 25.40 (since âˆ¥WÏ„Râˆ¥= R for R > âˆ¥xâˆ¥), we have
PWÏ„R [Ï„s < âˆ] =

1,
if d â‰¤2,
(s/R)dâˆ’2,
if d > 2.
Therefore,
P
'
lim inf
tâ†’âˆâˆ¥Wtâˆ¥< r
(
=

1,
if d â‰¤2,
0,
if d > 2.
This implies the claim.
âŠ“âŠ”
Deï¬nition 25.41 (Polar set) A set A âŠ‚Rd is called polar if
Px
)
Wt Ì¸âˆˆA for all t > 0
*
= 1
for all x âˆˆRd.
Theorem 25.42 If d = 1, then only the empty set is polar. If d â‰¥2, then {y} is
polar for every y âˆˆRd.
Proof For d = 1, the statement is obvious since
lim sup
tâ†’âˆ
Wt = âˆ
and
lim inf
tâ†’âˆWt = âˆ’âˆ
a.s.
Hence, due to the continuity of W, every point y âˆˆR will be hit (inï¬nitely often).
Now let d â‰¥2. Without loss of generality, assume y = 0. If x Ì¸= 0, then
Px
)
Ï„{0} < âˆ
*
=
lim
Râ†’âˆPx
)
Ï„{0} < Ï„R
*
=
lim
Râ†’âˆinf
r>0 Px
)
Ï„r,R = Ï„r
*
=
lim
Râ†’âˆinf
r>0 ur,R(x) = 0
(25.28)
since Vd(r)
râ†’0
âˆ’â†’âˆ’âˆif d â‰¥2.
On the other hand, if x = 0, then the strong Markov property of Brownian
motion (and the fact that P0[Wt = 0] = 0 for all t > 0) implies
P0
)
Ï„{0} < âˆ
*
= sup
t>0
P0
)
Ws = 0 for some s â‰¥t
*
= sup
t>0
P0
)
PWt [Ï„{0} < âˆ]
*
= 0.
Note that in the last step, we used (25.28).
âŠ“âŠ”

25.5
Recurrence and Transience of Brownian Motion
663
Takeaways Using the well known analytic solution of a speciï¬c Dirich-
let problem (the Newton potential), we compute the probability for d-
dimensional Brownian motion to ever hit a certain ball depending on d, the
size and the distance of the ball. We conclude that Brownian motion misses
single points if d â‰¥2 and is transient if d > 2.

Chapter 26
Stochastic Differential Equations
Stochastic differential equations describe the time evolution of certain continuous
Markov processes with values in Rn. In contrast with classical differential equations,
in addition to the derivative of the function, there is a term that describes the
random ï¬‚uctuations that are coded as an ItÃ´ integral with respect to a Brownian
motion. Depending on how seriously we take the concrete Brownian motion as
the driving force of the noise, we speak of strong and weak solutions. In the ï¬rst
section, we develop the theory of strong solutions under Lipschitz conditions for
the coefï¬cients. In the second section, we develop the so-called (local) martingale
problem as a method of establishing weak solutions. In the third section, we
present some examples in which the method of duality can be used to prove weak
uniqueness.
As stochastic differential equations are a very broad subject, and since things
quickly become very technical, we only excursively touch some of the most
important results, partly without proofs, and illustrate them with examples.
26.1
Strong Solutions
Consider a stochastic differential equation (SDE) of the type
X0 = Î¾,
dXt = Ïƒ(t, Xt) dWt + b(t, Xt) dt.
(26.1)
Here W = (W 1, . . . , W m) is an m-dimensional Brownian motion, Î¾ is an Rn-
valued random variable with distribution Î¼ that is independent of W, Ïƒ(t, x) =

Ïƒij (t, x)

i=1,...,n
j=1,...,m is a real n Ã— m matrix and b(t, x) =

bi(t, x)

i=1,...,n is an n-
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5_26
665

666
26
Stochastic Differential Equations
dimensional vector. Assume the maps (t, x) â†’Ïƒij (t, x) and (t, x) â†’bi(t, x) are
measurable.
By a solution of (26.1) we understand a continuous adapted stochastic process X
with values in Rn that satisï¬es the integral equation
Xt = Î¾ +
 t
0
Ïƒ(s, Xs) dWs +
 t
0
b(s, Xs) ds
P-a.s. for all t â‰¥0.
(26.2)
Written in full, this is
Xi
t = Î¾i +
m

j=1
 t
0
Ïƒij (s, Xs) dW j
s +
 t
0
bi(s, Xs) ds
for all i = 1, . . ., n.
Now the following problem arises: To which ï¬ltration F do we wish X to be
adapted? Should it be the ï¬ltration that is generated by Î¾ and W, or do we allow F
to be larger? Already for ordinary differential equations, depending on the equation,
uniqueness of the solution may fail (although existence is usually not a problem);
for example, for f â€² = |f |1/3. If F is larger than the ï¬ltration generated by W, then
we can deï¬ne further random variables that select one out of a variety of possible
solutions. We thus have more possibilities for solutions than if F = Ïƒ(W). Indeed, it
will turn out that in some situations for the existence of a solution, it is necessary to
allow a larger ï¬ltration. Roughly speaking, X is a strong solution of (26.1) if (26.2)
holds and if X is adapted to F = Ïƒ(W). On the other hand, X is a weak solution
if X is adapted to a larger ï¬ltration F with respect to which W is still a martingale.
Weak solutions will be dealt with in Sect. 26.2.
Deï¬nition 26.1 (Strong solution) We say that the stochastic differential equa-
tion (SDE) (26.1) has a strong solution X if there exists a map F
: Rn Ã—
C([0, âˆ); Rm) â†’C([0, âˆ); Rn) with the following properties:
(i) For every t â‰¥0, the map (x, w) â†’F(x, w) is measurable with respect to
B(Rn) âŠ—Gm
t
â€“ Gn
t , where (for k = m or k = n) Gk
t := Ïƒ(Ï€s : s âˆˆ[0, t])
is the Ïƒ-algebra generated by the coordinate maps Ï€s : C([0, âˆ); Rk) â†’R,
w â†’w(s), 0 â‰¤s â‰¤t.
(ii) The process X = F(Î¾, W) satisï¬es (26.2).
Condition (i) says that the path (Xs)sâˆˆ[0,t] depends only on Î¾ and (Ws)sâˆˆ[0,t] but not
on further information. In particular, X is adapted to Ft = Ïƒ(Î¾, Ws : s âˆˆ[0, t])
and is progressively measurable; hence the ItÃ´ integral in (26.2) is well-deï¬ned if Ïƒ
and b do not grow too quickly for large x.
Remark 26.2 Clearly, a strong solution of an SDE is a generalized n-dimensional
diffusion. If the coefï¬cients Ïƒ and b are independent of t, then the solution is an
n-dimensional diffusion. â™¦
Remark 26.3 Let X be a strong solution and let F be as in Deï¬nition 26.1. If W â€² is
an m-dimensional Brownian motion on a space (Î©â€², Fâ€², Pâ€²) with ï¬ltration Fâ€², and

26.1
Strong Solutions
667
if Î¾â€² is independent of W â€² and is Fâ€²
0-measurable, then Xâ€² = F(Î¾â€², W â€²) satisï¬es the
integral equation (26.2). Hence, it is a strong solution of (26.1) with W replaced by
W â€². Thus the existence of a strong solution does not depend on the actual realization
of the Brownian motion or on the ï¬ltration F. â™¦
Deï¬nition 26.4 We say that the SDE (26.1) has a unique strong solution if there
exists an F as in Deï¬nition 26.1 such that:
(i) If W is an m-dimensional Brownian motion on some probability space
(Î©, F, P) with ï¬ltration F and if Î¾ is an F0-measurable random variable
that is independent of W and such that P â—¦Î¾âˆ’1 = Î¼, then X := F(Î¾, W) is a
solution of (26.2).
(ii) For every solution (X, W) of (26.2), we have X = F(Î¾, W).
Example 26.5 Let m = n = 1, b âˆˆR and Ïƒ > 0. The Ornsteinâ€“Uhlenbeck
process
Xt := ebtÎ¾ + Ïƒ
 t
0
e(tâˆ’s)b dWs,
t â‰¥0,
(26.3)
is a strong solution of the SDE X0 = Î¾ and
dXt = Ïƒ dWt + b Xt dt.
In the language of Deï¬nition 26.1, we have (in the sense of the pathwise ItÃ´ integral
with respect to w)
F(x, w) =

t â†’ebtx +
 t
0
e(tâˆ’s)b dw(s)

for all w âˆˆCqv (that is, with continuous square variation). Since P[W âˆˆCqv] = 1,
we can deï¬ne F(x, w) = 0 for w âˆˆC([0, âˆ); R) \ Cqv.
Indeed, by Fubiniâ€™s theorem for ItÃ´ integrals, we have (Exercise 25.3.1)
Î¾ +
 t
0
Ïƒ dWs +
 t
0
b Xs ds
= Î¾ + ÏƒWt +
 t
0
b ebsÎ¾ ds +
 t
0
Ïƒ b
 s
0
eb(sâˆ’r) dWr

ds
= Î¾ + ÏƒWt + ebt âˆ’1Î¾ +
 t
0
Ïƒ
 t
r
b eb(sâˆ’r) ds

dWr
= ebtÎ¾ +
 t
0

Ïƒ +

eb(tâˆ’r) âˆ’1

Ïƒ

dWr
= Xt.

668
26
Stochastic Differential Equations
It can be shown (see Theorem 26.8) that the solution is also (strongly) unique. â™¦
Example 26.6 Let Î±, Î² âˆˆR. The one-dimensional SDE X0 = Î¾ and
dXt = Î± Xt dWt + Î² Xt dt
(26.4)
has the strong solution
Xt = Î¾ exp

Î± Wt +

Î² âˆ’Î±2
2

t

.
In the language of Deï¬nition 26.1, we have Ïƒ(t, x) = Î±x, b(t, x) = Î²x and
F(x, w) =

t â†’x exp

Î± w(t) +

Î² âˆ’Î±2
2

t

for all w âˆˆC([0, âˆ); R) and x âˆˆR. Indeed, by the time-dependent ItÃ´ formula
(Corollary 25.35),
Xt = Î¾ +
 t
0
Î±Xs dWs +
 t
0

Î² âˆ’Î±2
2

+ 1
2Î±2

Xs ds.
Also in this case, we have strong uniqueness of the solution (see Theorem 26.8).
The process X is called a geometric Brownian motion and, for example, serves in
the so-called Blackâ€“Scholes model as the process of stock prices. â™¦
We give a simple criterion for existence and uniqueness of strong solutions. For an
n Ã— m matrix A, deï¬ne the Hilbertâ€“Schmidt norm
âˆ¥Aâˆ¥=
S
trace

A AT 
=




n

i=1
m

j=1
A2
i,j .
(26.5)
For b âˆˆRn, we use the Euclidean norm âˆ¥bâˆ¥. Since all norms on ï¬nite-dimensional
vector spaces are equivalent, it is not important exactly which norm we use.
However, the Hilbertâ€“Schmidt norm simpliï¬es the computations, as the following
lemma shows.
Lemma 26.7 Let t â†’H(t) = (Hij(t))i=1,...,n, j=1,...,m be progressively measur-
able and E
) 3 T
0 H 2
ij(t) dt
*
< âˆfor all i, j. Then
E
+;;;;
 T
0
H(t) dWt
;;;;
2,
= E
+  T
0
âˆ¥H(t)âˆ¥2 dt
,
,
(26.6)
where âˆ¥Hâˆ¥is the Hilbertâ€“Schmidt norm from (26.5).

26.1
Strong Solutions
669
Proof For i = 1, . . . , n, the process Ii(t) := m
j=1
3 t
0 Hij(s) dW j
s is a continuous
martingale with square variation process âŸ¨IiâŸ©t =
3 t
0
m
j=1 H 2
ij(s) ds. Hence
E)(Ii(T ))2* = E
+  T
0
m

j=1
H 2
ij(s) ds
,
.
The left-hand side in (26.6) equals
n

i=1
E
)
(Ii(T ))2*
= E
+  T
0
n

i=1
m

j=1
H 2
ij(s) ds
,
.
Hence the claim follows by the deï¬nition of âˆ¥H(s)âˆ¥2.
âŠ“âŠ”
Theorem 26.8 Let b and Ïƒ be Lipschitz continuous in the second coordinate. That
is, we assume that there exists a K > 0 such that, for all x, xâ€² âˆˆRn and t â‰¥0,
âˆ¥Ïƒ(t, x) âˆ’Ïƒ(t, xâ€²)âˆ¥+ âˆ¥b(t, x) âˆ’b(t, xâ€²)âˆ¥â‰¤K âˆ¥x âˆ’xâ€²âˆ¥.
(26.7)
Further, assume the growth condition
âˆ¥Ïƒ(t, x)âˆ¥2 + âˆ¥b(t, x)âˆ¥2 â‰¤K2 (1 + âˆ¥xâˆ¥2)
for all x âˆˆRn, t â‰¥0.
(26.8)
Then, for every initial point X0 = x âˆˆRn, there exists a unique strong solution X
of the SDE (26.1). This solution is a Markov process and in the case where Ïƒ and b
do not depend on t, it is a strong Markov process.
As the main tool, we need the following lemma.
Lemma 26.9 (Gronwall) Let f, g : [0, T ] â†’R be integrable and let C > 0
such that
f (t) â‰¤g(t) + C
 t
0
f (s) ds
for all t âˆˆ[0, T ].
(26.9)
Then
f (t) â‰¤g(t) + C
 t
0
eC(tâˆ’s)g(s) ds
for all t âˆˆ[0, T ].
In particular, if g(t) â‰¡G is constant, then f (t) â‰¤GeCt for all t âˆˆ[0, T ].
Proof Let F(t) =
3 t
0 f (s) ds and h(t) = F(t) eâˆ’Ct. Then, by (26.9),
d
dt h(t) = f (t) eâˆ’Ct âˆ’CF(t) eâˆ’Ct â‰¤g(t) eâˆ’Ct.

670
26
Stochastic Differential Equations
Integration yields
F(t) = eCt h(t) â‰¤
 t
0
eC(tâˆ’s) g(s) ds.
Substituting this into (26.9) gives
f (t) â‰¤g(t) + CF(t) â‰¤g(t) + C
 t
0
g(s) eC(tâˆ’s) ds.
âŠ“âŠ”
Proof (of Theorem 26.8) It is enough to show that, for every T < âˆ, there exists
a unique strong solution up to time T .
Uniqueness We ï¬rst show uniqueness of the solution. Let X and Xâ€² be two
solutions of (26.2). Then
Xt âˆ’Xâ€²
t =
 t
0

b(s, Xs) âˆ’b(s, Xâ€²
s)

ds +
 t
0

Ïƒ(s, Xs) âˆ’Ïƒ(s, Xâ€²
s)

dWs.
Hence
âˆ¥Xt âˆ’Xâ€²
tâˆ¥2 â‰¤2
;;;;
 t
0
b(s, Xs) âˆ’b(s, Xâ€²
s) ds
;;;;
2
+ 2
;;;;
 t
0
Ïƒ(s, Xs) âˆ’Ïƒ(s, Xâ€²
s) dWs
;;;;
2
.
(26.10)
For the ï¬rst summand in (26.10), use the Cauchyâ€“Schwarz inequality, and for the
second one use Lemma 26.7 to obtain
E
)
âˆ¥Xt âˆ’Xâ€²
tâˆ¥2*
â‰¤2t
 t
0
E
';;b(s, Xs) âˆ’b(s, Xâ€²
s)
;;2(
ds
+ 2
 t
0
E
';;Ïƒ(s, Xs) âˆ’Ïƒ(s, Xâ€²
s)
;;2(
ds.
Write f (t) = E
)
âˆ¥Xt âˆ’Xâ€²
tâˆ¥2*
and C := 2(T + 1)K2. Then f (t) â‰¤C
3 t
0 f (s) ds.
Hence Gronwallâ€™s lemma (with g â‰¡0) yields f â‰¡0.
Existence We use a version of the Picard iteration scheme. For N
âˆˆ
N0,
recursively deï¬ne processes XN by X0
t â‰¡x and
XN
t
:= x +
 t
0
bs, XNâˆ’1
s
 ds +
 t
0
Ïƒs, XNâˆ’1
s
 dWs
for N âˆˆN.
(26.11)

26.1
Strong Solutions
671
Using the growth condition (26.8), it can be shown inductively that
 T
0
E
';;XN
t
;;2(
dt â‰¤2(T + 1) K2

T +
 T
0
E
';;XNâˆ’1
t
;;2(
dt

â‰¤2T (T + 1) K2N1 + âˆ¥xâˆ¥2 < âˆ,
N âˆˆN.
Hence, at each step, the ItÃ´ integral is well-deï¬ned.
Consider now the differences
XN+1
t
âˆ’XN
t = It + Jt,
where
It :=
 t
0

Ïƒ(s, XN
s ) âˆ’Ïƒ(s, XNâˆ’1
s
)

dWs
and
Jt :=
 t
0

b(s, XN
s ) âˆ’b(s, XNâˆ’1
s
)

ds.
By applying Doobâ€™s L2-inequality to the nonnegative submartingale (âˆ¥Itâˆ¥2)tâ‰¥0,
using Lemma 26.7 and (26.7), we obtain
E
+
sup
sâ‰¤t
âˆ¥Isâˆ¥2
,
â‰¤4 E
)
âˆ¥Itâˆ¥2*
= 4 E
+ t
0
;;Ïƒ(s, XN
s ) âˆ’Ïƒ(s, XNâˆ’1
s
)
;;2 ds
,
â‰¤4K2
 t
0
E
';;XN
s âˆ’XNâˆ’1
s
;;2(
ds.
(26.12)
For Jt, by the Cauchyâ€“Schwarz inequality, we get
âˆ¥Jtâˆ¥2 â‰¤t
 t
0
;;b(s, XN
s ) âˆ’b(s, XNâˆ’1
s
)
;;2 ds.
Hence
E
+
sup
sâ‰¤t
âˆ¥Jsâˆ¥2
,
â‰¤t E
+ t
0
;;b(s, XN
s ) âˆ’b(s, XNâˆ’1
s
)
;;2 ds
,
â‰¤tK2
 t
0
E
';;XN
s âˆ’XNâˆ’1
s
;;2(
ds.
(26.13)

672
26
Stochastic Differential Equations
Deï¬ning
Î”N(t) := E
+
sup
sâ‰¤t
;;XN
s âˆ’XNâˆ’1
s
;;2
,
,
and C := 2K2(4 + T ) âˆ¨2(T + 1)K2(1 + âˆ¥xâˆ¥2), we obtain (using the growth
condition (26.8))
Î”N+1(t) â‰¤C
 t
0
Î”N(s) ds
for N â‰¥1
and
Î”1(t) â‰¤2t
 t
0
âˆ¥b(s, x)âˆ¥2 ds + 2
 t
0
âˆ¥Ïƒ(s, x)âˆ¥2 ds
â‰¤2(T + 1)K2
1 + âˆ¥xâˆ¥2
Â· t â‰¤C t.
Inductively, we get Î”N(t) â‰¤(Ct)N
N! . Thus, by Markovâ€™s inequality,
âˆ

N=1
P
+
sup
sâ‰¤t
;;XN
s âˆ’XNâˆ’1
s
;;2 > 2âˆ’N
,
â‰¤
âˆ

N=1
2NÎ”N(t)
â‰¤
âˆ

N=1
(2Ct)N
N!
â‰¤e2Ct < âˆ.
Using the Borelâ€“Cantelli lemma, we infer sup
sâ‰¤t
âˆ¥XN
s âˆ’XNâˆ’1
s
âˆ¥2 Nâ†’âˆ
âˆ’â†’0 a.s. Hence
a.s. (XN)NâˆˆN is a Cauchy sequence in the Banach space (C([0, T ]), âˆ¥Â· âˆ¥âˆ).
Therefore, XN converges a.s. uniformly to some X. As uniform convergence
implies convergence of the integrals, X is a strong solution of (26.2).
Markov property The strong Markov property follows from the strong Markov
property of the Brownian motion that drives the SDE.
âŠ“âŠ”
We have already seen some important examples of this theorem. Many interesting
problems, however, lead to stochastic differential equations with coefï¬cients that
are not Lipschitz continuous. In the one-dimensional case, using special comparison
methods, one can show that it is sufï¬cient that Ïƒ is HÃ¶lder-continuous of order 1
2 in
the space variable.
Theorem 26.10 (Yamadaâ€“Watanabe) Consider the one-dimensional situation
where m = n = 1. Assume that there exist K < âˆand Î± âˆˆ)1
2, 1* such that, for all

26.1
Strong Solutions
673
t â‰¥0 and x, xâ€² âˆˆR, we have
b(t, x) âˆ’b(t, xâ€²)
 â‰¤K |x âˆ’xâ€²|
and
Ïƒ(t, x) âˆ’Ïƒ(t, xâ€²)
 â‰¤K |x âˆ’xâ€²|Î±.
Then, for every X0 âˆˆR, the SDE (26.1) has a unique strong solution X and X is a
strong Markov process.
Proof See [173] or [85, Proposition 5.2.13] and [49, Theorem 5.3.11] for existence
and uniqueness. The strong Markov property follows from Theorem 26.26.
âŠ“âŠ”
Example 26.11 Consider the one-dimensional SDE
dXt =
S
Î³ X+
t dWt + a

b âˆ’X+
t

dt
(26.14)
with initial point X0 = x â‰¥0, where Î³ > 0 and a, b â‰¥0 are parameters. The
conditions of Theorem 26.10 are fulï¬lled with Î± = 1
2 and K = âˆšÎ³ + a. Obviously,
the unique strong solution X remains nonnegative if X0 â‰¥0. (In fact, it can be
shown that Xt > 0 for all t > 0 if 2ab/Î³ â‰¥1, and that Xt hits zero arbitrarily
often with probability 1 if 2ab/Î³ < 1. See, e.g., [78, Example IV.8.2, page 237].
Compare Example 26.16. See Figs. 26.1 and 26.2 for computer simulations.)
Depending on the context, this process is sometimes called Fellerâ€™s branching
diffusion with immigration or the Coxâ€“Ingersollâ€“Ross model for the time
evolution of interest rates.
0
0.5
1
1.5
5
10
15
20
25
30
Fig. 26.1 Coxâ€“Ingersollâ€“Ross diffusion with parameters Î³ = 1, b = 1 and a = 0.3. The path hits
zero again and again since 2ab/Î³ = 0.6 < 1.

674
26
Stochastic Differential Equations
0
0.5
1
1.5
2
2.5
5
10
15
20
25
30
Fig. 26.2 Coxâ€“Ingersollâ€“Ross diffusion with parameters Î³ = 1, b = 1 and a = 2. The path never
hits zero since 2ab/Î³ = 4 â‰¥1.
For the case a = b = 0, use the ItÃ´ formula to compute that
eâˆ’Î»Xt âˆ’eâˆ’Î»x âˆ’Î³ Î»2
2
 t
0
eâˆ’Î»XsXs ds = Î»
 t
0
eâˆ’Î»Xs2
Î³ Xs dWs
is a martingale. Take expectations for the Laplace transform Ï•(t, Î», x) = Ex[eâˆ’Î»Xt]
to get the differential equation
d
dt Ï•(t, Î», x) = Î³ Î»2
2 E
)
Xt eâˆ’Î»Xt*
= âˆ’Î³ Î»2
2
d
dÎ»Ï•(t, Î», x).
With initial value Ï•(0, Î», x) = eâˆ’Î»x, the unique solution is
Ï•(t, Î», x) = exp

âˆ’
Î»
(Î³/2)Î»t + 1 x

.
However (for Î³
= 2), this is exactly the Laplace transform of the transition
probabilities of the Markov process that we deï¬ned in Theorem 21.48 and that in
Lindvallâ€™s theorem (Theorem 21.51) we encountered as the limit of rescaled Galtonâ€“
Watson branching processes. â™¦

26.2
Weak Solutions and the Martingale Problem
675
Takeaways A stochastic differential equation is a standard way of describing
a continuous stochastic process. If the coefï¬cients are Lipschitz continuous,
to (almost) every path of the Brownian motion we can assign uniquely a
path of the solution of the differential equation. This is the so-called strong
solution. For a one-dimensional stochastic differential equation, we can relax
the Lipschitz condition on the diffusion coefï¬cient: it is enough that the
diffusion coefï¬cient be HÃ¶lder- 1
2-continuous.
Exercise 26.1.1 Let a, b âˆˆR. Show that the stochastic differential equation
dXt = b âˆ’Xt
1 âˆ’t dt + dWt
with initial value X0 = a has a unique strong solution for t âˆˆ[0, 1) and that
X1 := limtâ†‘1 X1 = b almost surely. Furthermore, show that the process Y = (Xt âˆ’
a âˆ’t(b âˆ’a))tâˆˆ[0,1] can be described by the ItÃ´ integral
Yt = (1 âˆ’t)
 t
0
(1 âˆ’s)âˆ’1 dWs,
t âˆˆ[0, 1),
and is hence a Brownian bridge (compare Exercise 21.5.3). â™£
26.2
Weak Solutions and the Martingale Problem
In the last section, we studied strong solutions of the stochastic differential equation
dXt = Ïƒ(t, Xt) dWt + b(t, Xt) dt.
(26.15)
A strong solution is a solution where any path of the Brownian motion W gets
mapped onto a path of the solution X. In this section, we will study the notion of
a weak solution where additional information (or additional noise) can be used to
construct the solution.
Deï¬nition 26.12 (Weak solution of an SDE) A weak solution of (26.15) with
initial distribution Î¼ âˆˆM1(Rn) is a triple
L =

(X, W), (Î©, F, P), F

,
where
â€¢
(Î©, F, P) is a probability space,
â€¢
F = (Ft)tâ‰¥0 is a ï¬ltration on (Î©, F, P) that satisï¬es the usual conditions,

676
26
Stochastic Differential Equations
â€¢
W is a Brownian motion on (Î©, F, P) and is a martingale with respect to F,
â€¢
X is continuous and adapted (hence progressively measurable),
â€¢
P â—¦(X0)âˆ’1 = Î¼, and
â€¢
(X, W) satisï¬es
Xt = X0 +
 t
0
Ïƒ(s, Xs) dWs +
 t
0
b(s, Xs) ds
P-a.s.
(26.16)
A weak solution L is called (weakly) unique if, for any further solution Lâ€² with initial
distribution Î¼, we have Pâ€² â—¦(Xâ€²)âˆ’1 = P â—¦Xâˆ’1.
Remark 26.13 Clearly, a weak solution of an SDE is a generalized n-dimensional
diffusion. If the coefï¬cients Ïƒ and b do not depend on t, then the solution is an
n-dimensional diffusion. â™¦
Remark 26.14 Clearly, every strong solution of (26.15) is a weak solution. The
converse is false, as the following example shows. â™¦
Example 26.15 Consider the SDE (with initial value X0 = 0)
dXt = sign(Xt) dWt,
(26.17)
where sign = 1[0,âˆ) âˆ’1(âˆ’âˆ,0) is the sign function. Then
Xt = X0 +
 t
0
sign(Xs) dWs
for all t â‰¥0
(26.18)
if and only if
Wt =
 t
0
dWs =
 t
0
sign(Xs) dXs
for all t â‰¥0.
(26.19)
A weak solution of (26.17) is obtained as follows. Let X be a Brownian motion on
a probability space (Î©, F, P) and F = Ïƒ(X). If we deï¬ne W by (26.19), then W is
a continuous F-martingale with square variation
âŸ¨WâŸ©t =
 t
0
(sign(Xs))2 ds = t.
Thus, by LÃ©vyâ€™s characterization (Theorem 25.28), W is a Brownian motion. Hence
((X, W), (Î©, F, P), F) is a weak solution of (26.17).
In order to show that a strong solution does not exist, take any weak solution and
show that X is not adapted to Ïƒ(W). Since, by (26.18), X is a continuous martingale
with square variation âŸ¨XâŸ©t = t, X is a Brownian motion.

26.2
Weak Solutions and the Martingale Problem
677
Let Fn âˆˆC2(R) be a convex even function with derivatives F â€²
n and F â€²â€²
n such that
sup
xâˆˆR
Fn(x) âˆ’|x|
 nâ†’âˆ
âˆ’â†’0,
|F â€²
n(x)| â‰¤1 for all x âˆˆR and F â€²
n(x) = sign(x) for |x| > 1
n. In particular, we
have
 t
0

F â€²
n(Xs) âˆ’sign(Xs)
2 ds
nâ†’âˆ
âˆ’â†’0
a.s.
and thus
 t
0
F â€²
n(Xs) dXs
nâ†’âˆ
âˆ’â†’
 t
0
sign(Xs) dXs
in L2.
(26.20)
By passing to a subsequence, if necessary, we may assume that almost sure
convergence holds in (26.20).
Since F â€²â€²
n is even, we have
Wt =
 t
0
sign(Xs) dXs = lim
nâ†’âˆ
 t
0
F â€²
n(Xs) dXs
= lim
nâ†’âˆ

Fn(Xt) âˆ’Fn(0) âˆ’1
2
 t
0
F â€²â€²
n (Xs) ds

= |Xt| âˆ’lim
nâ†’âˆ
1
2
 t
0
F â€²â€²
n (|Xs|) ds.
As the right-hand side depends only on |Xs|, s âˆˆ[0, t], W is adapted to G :=
(Ïƒ(|Xs| : s âˆˆ[0, t])). Hence Ïƒ(W) âŠ‚G â«‹Ïƒ(X), and thus X is not adapted to
Ïƒ(W). â™¦
Example 26.16 Let B = (B1, . . . , Bn) be an n-dimensional Brownian motion
started at y âˆˆRn. Let x := âˆ¥yâˆ¥2, Xt := âˆ¥Btâˆ¥2 = (B1
t )2 + . . . + (Bn
t )2 and
Wt :=
n

i=1
 t
0
1
âˆšXs
Bi
s dBi
s.
Then W is a continuous local martingale with âŸ¨WâŸ©t = t for every t â‰¥0 and
Xt = x + nt +
 t
0
2
Xs dWs.
That is, (X, W) is a weak solution of the SDE dXt = âˆš2Xt dWt +n dt. X is called
an n-dimensional Bessel process. By Theorem 25.42, B (and thus X) hits the origin

678
26
Stochastic Differential Equations
for some t > 0 if and only if n = 1. Clearly, we can deï¬ne X also for noninteger
n â‰¥0. One can show that X hits zero if and only if n â‰¤1. Compare Example 26.11.
â™¦
For the connection between existence and uniqueness of weak solutions and strong
solutions, we only quote here the theorem of Yamada and Watanabe.
Deï¬nition 26.17 (Pathwise uniqueness) A solution of the SDE (26.15) with initial
distribution Î¼ is said to be pathwise unique if, for every Î¼ âˆˆM1(Rn) and for any
two weak solutions (X, W) and (Xâ€², W) on the same space (Î©, F, P) with the same
ï¬ltration F, we have P[Xt = Xâ€²
t for all t â‰¥0] = 1.
Theorem 26.18 (Yamada and Watanabe) The following are equivalent.
(i) The SDE (26.15) has a unique strong solution.
(ii) For any Î¼ âˆˆM1(Rn), (26.15) has a weak solution, and pathwise uniqueness
holds.
If (i) and (ii) hold, then the solution is weakly unique.
Proof See [173], [148, pages 151ff] or [78, pages 163ff].
âŠ“âŠ”
Example 26.19 Let X be a weak solution of (26.17). Then âˆ’X is also a weak
solution; that is, pathwise uniqueness does not hold (although it can be shown that
the solution is weakly unique; see Theorem 26.25). â™¦
Consider the one-dimensional case m = n = 1. If X is a solution (strong or weak)
of (26.15), then
Mt := Xt âˆ’
 t
0
b(s, Xs) ds
is a continuous local martingale with square variation
âŸ¨MâŸ©t =
 t
0
Ïƒ 2(s, Xs) ds.
We will see that this characterizes a weak solution of (26.15) (under some mild
growth conditions on Ïƒ and b).
Now assume that, for all t â‰¥0 and x âˆˆRn, the nÃ—n matrix a(t, x) is symmetric
and nonnegative deï¬nite, and let (t, x) â†’a(t, x) be measurable.
Deï¬nition 26.20 An n-dimensional continuous process X is called a solution of the
local martingale problem for a and b with initial condition Î¼ âˆˆM1(Rn) (brieï¬‚y,
LMP(a, b, Î¼)) if P â—¦Xâˆ’1
0
= Î¼ and if, for every i = 1, . . ., n,
Mi
t := Xi
t âˆ’
 t
0
bi(s, Xs) ds,
t â‰¥0,

26.2
Weak Solutions and the Martingale Problem
679
is a continuous local martingale with quadratic covariation
âŸ¨Mi, MjâŸ©t =
 t
0
aij(s, Xs) ds
for all t â‰¥0, i, j = 1, . . . , n.
We say that the solution of LMP(a, b, Î¼) is unique if, for any two solutions X and
Xâ€², we have P â—¦Xâˆ’1 = P â—¦(Xâ€²)âˆ’1.
Denote by Ïƒ T the transposed matrix of Ïƒ. Clearly, a = ÏƒÏƒ T is a nonnegative
semideï¬nite symmetric n Ã— n matrix.
Theorem 26.21 X is a solution of LMP(ÏƒÏƒ T , b, Î¼) if and only if (on a suitable
extension of the probability space) there exists a Brownian motion W such that
(X, W) is a weak solution of (26.15).
In particular, there exists a unique weak solution of the SDE (26.15) with initial
distribution Î¼ if LMP(ÏƒÏƒ T , b, Î¼) is uniquely solvable.
Proof We show the statement only for the case m = n = 1. The general case needs
some consideration on the roots of nonnegative semideï¬nite symmetric matrices,
which, however, do not yield any further insight into the stochastics of the problem.
For this we refer to [85, Proposition 5.4.6].
â€œ â‡â€
If (X, W) is a weak solution, then, by Corollary 25.19, X solves the local
martingale problem.
â€œ â‡’â€
Let X be a solution of LMP(Ïƒ 2, b, Î¼). By Theorem 25.29, on an extension
of the probability space there exists a Brownian motion
ËœW such that Mt
=
3 t
0
Ïƒ(s, Xs)
 d ËœWs. If we deï¬ne
Wt :=
 t
0
sign(Ïƒ(s, Xs)) d ËœWs,
then Mt =
3 t
0 Ïƒ(s, Xs) dWs and hence (X, W) is a weak solution of (26.15).
âŠ“âŠ”
In some sense, a local martingale problem is a very natural way of writing a
stochastic differential equation; that is:
X locally has derivative (drift) b and additionally has random normally distributed
ï¬‚uctuations of size Ïƒ.
Here, a concrete Brownian motion does not appear. In fact, in most problems its
occurrence is rather artiï¬cial. Just as Markov chains are described by their transition
probabilities and not by a concrete realization of the random transitions (as in
Theorem 17.17), many continuous (space and time) processes are most naturally
described by the drift and the size of the ï¬‚uctuations but not by the concrete
realization of the random ï¬‚uctuations.
From a technical point of view, the formulation of a stochastic differential equa-
tion as a local martingale problem is very convenient since it makes SDEs accessible
to techniques such as martingale inequalities and approximation theorems that can

680
26
Stochastic Differential Equations
be used to establish existence and uniqueness of solutions. Here we simply quote
two important results.
Theorem 26.22 (Existence of solutions) Let (t, x) â†’b(t, x) and (t, x) â†’
a(t, x) be continuous and bounded. Then, for every Î¼ âˆˆM1(Rn), there exists a
solution X of the LMP(a, b, Î¼).
Proof See [148, Theorem V.23.5].
âŠ“âŠ”
Deï¬nition 26.23 The LMP(a, b) is said to be well-posed if, for every x âˆˆRn, there
exists a unique solution X of LMP(a, b, Î´x).
Remark 26.24 If Ïƒ and b satisfy the Lipschitz conditions of Theorem 26.8, then the
LMP(ÏƒÏƒ T , b) is well-posed. This follows by Theorems 26.8, 26.18 and 26.21. â™¦
In the following, we assume
(t, x) â†’Ïƒ(t, x) resp. (t, x) â†’a(t, x) is bounded on compact sets.
(26.21)
This condition ensures the equivalence of the local martingale problems to the
somewhat more common martingale problem (see [85, Proposition 5.4.11]).
Theorem 26.25 (Uniqueness in the martingale problem) Assume (26.21) and
that, for any x âˆˆRn, there exists a solution Xx of LMP(a, b, Î´x). The distribution
of Xx will be denoted by Px := P â—¦(Xx)âˆ’1.
Assume that, for any two solutions Xx and Y x of LMP(a, b, Î´x), we have
P â—¦(Xx
T )âˆ’1 = P â—¦(Y x
T )âˆ’1
for any T â‰¥0.
(26.22)
Then LMP(a, b) is well-posed, and the canonical process X is a strong Markov
process with respect to (Px, x âˆˆRn). If a = ÏƒÏƒ T , then under Px, the process X is
the unique weak solution of the SDE (26.15).
Proof See [49, Theorem 4.4.2 and Problem 49] and [85, Proposition 5.4.11].
âŠ“âŠ”
A fundamental strength of this theorem is that we do not need to check the
uniqueness of the whole process but only have to check in (26.22) the one-
dimensional marginal distributions. We will use this in Sect. 26.3 in some examples.
The existence of solutions of a stochastic differential equation (or equivalently of
a local martingale problem) is often easier to show than the uniqueness of solutions.
We know already that Lipschitz conditions for the coefï¬cients b and Ïƒ (not ÏƒÏƒ T !)
ensure uniqueness (Theorems 26.8 and 26.18), as here strong uniqueness of the
solution holds.
At ï¬rst glance, it might seem confusing that random ï¬‚uctuations have a stabil-
ising effect on the solution. That is, there are deterministic differential equations
whose solution is unique only after adding random noise terms. For example,
consider the following equation:
dXt = sign(Xt) |Xt|1/3 dt + Ïƒ dWt,
X0 = 0.
(26.23)

26.2
Weak Solutions and the Martingale Problem
681
If Ïƒ = 0, then the deterministic differential equation has a continuum of solutions
that can be parameterized by v âˆˆ{âˆ’1, +1} and T â‰¥0, namely Xt = v 2
âˆš
2 (t âˆ’
T )3/2 1{t>T }. If Ïƒ > 0, then the noise eliminates the instability of (26.23) at
x = 0. We quote the following theorem for the time-independent case from [148,
Theorem V.24.1] (see also [162, Chapter 10]).
Theorem 26.26 (Stroockâ€“Varadhan) Let aij : Rn â†’R be continuous and let
bi : Rn â†’R be measurable for i, j = 1, . . . , n. Assume
(i) a(x) = (aij(x)) is symmetric and strictly positive deï¬nite for every x âˆˆRn,
(ii) there exists a C < âˆsuch that, for all x âˆˆRn and i, j = 1, . . ., n, we have
aij(x)
 â‰¤C 1 + âˆ¥xâˆ¥2
and
bi(x)
 â‰¤C 1 + âˆ¥xâˆ¥.
Then the LMP(a, b) is well-posed and the SDE (26.15) has a unique strong
solution that is a strong Markov process. The solution X has the Feller property: For
every t > 0 and every bounded measurable f : Rn â†’R, the map x â†’Ex[f (Xt)]
is continuous.
We will present explicit examples in Sect. 26.3. Here we just remark that we have
developed a particular method in order to construct Markov processes, namely as
the solution of a stochastic differential equation or of a local martingale problem.
In the framework of models in discrete time, in Sect. 17.2 and especially in
Exercise 17.2.1, we characterized certain Markov chains as solutions of martingale
problems. In order for drift and square variation to be sufï¬cient for uniqueness of
the Markov chain described by the martingale problem, it was essential that, for any
step of the chain, we only allowed three possibilities. Here, however, the decisive
restriction is the continuity of the processes.
Takeaways For a weak solution of a stochastic differential equation, the
Brownian motion does not exist a priori. Rather it will be constructed together
with the paths of the solution. Hence, for weak solutions the focus lies
on quantitative properties such as strength of noise and drift. The explicit
dependence of the solution path on a speciï¬c Brownian motion path is
typically of no interest in this situation. Weak solutions can be constructed via
martingale problems under rather weak assumptions. However, uniqueness of
weak solutions is often an issue and requires tailor-made methods.
Exercise 26.2.1 Consider the time-homogeneous one-dimensional case (m = n =
1). Let Ïƒ and b be such that, for every X0 âˆˆR, there exists a unique weak solution
of
dXt = Ïƒ(Xt) dWt + b(Xt) dt

682
26
Stochastic Differential Equations
that is a strong Markov process. Further, assume that there exists an x0 âˆˆR with
C :=
 âˆ
âˆ’âˆ
1
Ïƒ 2(x) exp
 x
x0
2b(r)
Ïƒ 2(r) dr

dr < âˆ.
(i) Show that the measure Ï€ âˆˆM1(R) with density
Ï€(dx)
dx
= Câˆ’1
1
Ïƒ 2(x) exp
 x
x0
2b(r)
Ïƒ 2(r) dr

is an invariant distribution for X.
(ii) For which values of b does the Ornsteinâ€“Uhlenbeck process dXt = Ïƒ dWt +
bXt dt have an invariant distribution? Determine this distribution and compare
the result with what could be expected by an explicit computation using the
representation in (26.3).
(iii) Compute the invariant distribution of the Coxâ€“Ingersollâ€“Ross SDE (26.14)
(i.e., Fellerâ€™s branching diffusion).
(iv) Let Î³, c > 0 and Î¸ âˆˆ(0, 1). Show that the invariant distribution of the solution
X of the SDE on [0, 1],
dXt =
2
Î³ Xt(1 âˆ’Xt) dWt + c(Î¸ âˆ’Xt) dt
is the Beta distribution Î²2cÎ³/Î¸, 2cÎ³/(1âˆ’Î¸). â™£
Exercise 26.2.2 Let Î³ > 0. Let X1 and X2 be solutions of dXi
t =
S
Î³ Xi
t dW i
t ,
where W 1 and W 2 are two independent Brownian motions with initial values X1
0 =
x1
0 > 0 and X2
0 = x2
0 > 0. Show that Z := X1 + X2 is a weak solution of Z0 = 0
and dZt = âˆšÎ³ Zt dWt. â™£
26.3
Weak Uniqueness via Duality
The Stroockâ€“Varadhan theorem provides a strong criterion for existence and
uniqueness of solutions of stochastic differential equations. However, in many cases,
the condition of locally uniform ellipticity of a (Condition (i) in Theorem 26.26) is
not fulï¬lled. This is the case, in particular, if the solutions are deï¬ned only on subsets
of Rn.
Here we will study a powerful tool that in many special cases can yield weak
uniqueness of solutions.
Deï¬nition 26.27 (Duality) Let X = (Xx, x âˆˆE) and Y = (Y y, y âˆˆEâ€²) be
families of stochastic processes with values in the spaces E and Eâ€², respectively,
and such that Xx
0 = x a.s. and Y y
0 = y a.s. for all x âˆˆE and y âˆˆEâ€². We say that
X and Y are dual to each other with duality function H : E Ã— Eâ€² â†’C if, for all

26.3
Weak Uniqueness via Duality
683
x âˆˆE, y âˆˆEâ€² and t â‰¥0, the expectations E
)
H(Xx
t , y)
*
and E
)
H(x, Y y
t )
*
exist
and are equal:
E
)
H(Xx
t , y)
*
= E
)
H(x, Y y
t )
*
.
In the following, we assume that Ïƒij : Rn â†’R and bi : Rn â†’R are bounded on
compact sets for all i = 1, . . ., n, j = 1, . . . , m. Consider the time-homogeneous
stochastic differential equation
dXt = Ïƒ(Xt) dWt + b(Xt) dt.
(26.24)
Theorem 26.28 (Uniqueness via duality) Assume that, for every x âˆˆRn, there
exists a solution of the local martingale problem for (ÏƒÏƒ T , b, Î´x). Further, assume
that there exists a family (Y y, y âˆˆEâ€²) of Markov processes with values in the
measurable space (Eâ€², Eâ€²) and a measurable map H : Rn Ã— Eâ€² â†’C such that, for
every y âˆˆEâ€², x âˆˆRn and t â‰¥0, the expectation E[H(x, Y y
t )] exists and is ï¬nite.
Further, let (H( Â·, y), y âˆˆEâ€²) be a separating class of functions for M1(Rn) (see
Deï¬nition 13.9).
For every x âˆˆRn and every solution Xx of LMP(ÏƒÏƒ T , b, Î´x), assume that the
duality equation holds:
E[H(Xx
t , y)] = E[H(x, Y y
t )]
for all y âˆˆEâ€², t â‰¥0.
(26.25)
Then the local martingale problem of (ÏƒÏƒ T , b) is well-posed and hence (26.24) has
a unique weak solution that is a strong Markov process.
Proof By Theorem 26.25, it is enough to check that, for every x âˆˆRn, every
solution Xx of LMP(ÏƒÏƒ T , b, Î´x) and every t â‰¥0, the distribution P â—¦(Xx
t )âˆ’1 is
unique. Since (H( Â·, y), y âˆˆEâ€²) is a separating class of functions, this follows
from (26.16).
âŠ“âŠ”
Example 26.29 (Wrightâ€“Fisher diffusion) Consider the Wrightâ€“Fisher SDE
dXt = 1[0,1](Xt)
2
Î³ Xt(1 âˆ’Xt) dWt,
(26.26)
where Î³
>
0 is a parameter. See Fig. 26.3 for a computer simulation. By
Theorem 26.22, for every x âˆˆR, there exists a weak solution ( ËœX, W) of (26.26). ËœX
is a continuous local martingale with square variation
B ËœX
C
t =
 t
0
Î³ ËœXs(1 âˆ’ËœXs)1[0,1]( ËœXs) ds.

684
26
Stochastic Differential Equations
0
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
1.2
Fig. 26.3 Simulation of a Wrightâ€“Fisher diffusion with parameter Î³ = 1.
Let Ï„ := inf{t > 0 :
ËœXt Ì¸âˆˆ[0, 1]} and let X := ËœXÏ„ be the process stopped at Ï„.
Then X is a continuous bounded martingale with
âŸ¨XâŸ©t =
 t
0
Î³ Xs(1 âˆ’Xs)1[0,1](Xs) ds.
Hence, (X, W) is a solution of (26.26). By construction, Xt âˆˆ[0, 1] for all t â‰¥0 if
X0 = ËœX0 âˆˆ[0, 1].
Let Ï„ â€² := inf{t > 0 :
ËœXt âˆˆ[0, 1]}. If ËœX0 Ì¸âˆˆ[0, 1], then Ï„ â€² > 0 since ËœX is
continuous. Since ËœXÏ„ â€² is a continuous local martingale with
B ËœXÏ„ â€²C
â‰¡0, we have
ËœXÏ„ â€²
t
= ËœX0 for all t â‰¥0. However, this implies ËœXt = ËœX0 for all t < Ï„ â€². Again, by
continuity of ËœX, we get Ï„ â€² = âˆand ËœXt = ËœX0 for all t â‰¥0.
Hence, it is enough to show uniqueness of the solution for ËœX0 = x âˆˆ[0, 1]. To this
end, let Y = (Yt)tâ‰¥0 be the Markov process on N with Q-matrix
q(m, n) =
â§
âªâ¨
âªâ©
Î³
m
2

,
if n = m âˆ’1,
âˆ’Î³
m
2

,
if n = m,
0,
else.
We show duality of X and Y with respect to H(x, n) = xn:
Ex
)Xn
t
* = En
)xNt *
for all t â‰¥0, x âˆˆ[0, 1], n âˆˆN.
(26.27)
Deï¬ne mx,n(t) = Ex
)
Xn
t
*
and gx,n(t) = En
)
xNt*
. By the ItÃ´ formula,
Xn
t âˆ’xn âˆ’
 t
0
Î³
n
2

Xnâˆ’1
s
(1 âˆ’Xs) ds =
 t
0
nXnâˆ’1
s
2
Î³ Xs(1 âˆ’Xs) dWs
is a martingale.

26.3
Weak Uniqueness via Duality
685
Taking expectations, we obtain the following recursive equations for the
moments of X:
mx,1(t) = x,
mx,n(t) = xn + Î³
n
2
  t
0
mx,nâˆ’1(s) âˆ’mx,n(s) ds
for n â‰¥2.
(26.28)
Clearly, this system of linear differential equations can be uniquely solved recur-
sively in n.
Due to the Markov property of Y, for h > 0 and t â‰¥0, we have
gx,n(t + h) = En
)
xYt+h*
= En
)
EYh
)
xYt**
=
n

m=1
Pn[Yh = m] Em
)
xYt*
=
n

m=1
Pn[Yh = m] gx,m(t).
This implies
d
dt gx,n(t) = lim
hâ†“0 hâˆ’1 '
gx,n(t + h) âˆ’gx,n(t)
(
= lim
hâ†“0 hâˆ’1
n

m=1
Pn[Yh = m]

gx,m(t) âˆ’gx,n(t)

=
n

m=1
q(n, m) gx,m(t)
= Î³
n
2

gx,nâˆ’1(t) âˆ’gx,n(t)

.
(26.29)
Evidently, gx,1(t) = x for all x âˆˆ[0, 1] and t â‰¥0 and gx,n(0) = xn. That is, gx,n
solves (26.28), and thus (26.27) holds.
By Theorem 15.4, the family (H( Â·, n), n âˆˆN) âŠ‚C([0, 1]) is separating for
M1([0, 1]); hence the conditions of Theorem 26.28 are fulï¬lled. Therefore, X is
the unique weak solution of (26.26) and is a strong Markov process. â™¦
Remark 26.30 The martingale problem for the Wrightâ€“Fisher diffusion is almost
identical to the martingale problem for the Moran model (see Example 17.22)
MN = (MN
n )nâˆˆN0 with population size N: MN is a martingale with values in the

686
26
Stochastic Differential Equations
set {0, 1/N, . . . , (N âˆ’1)/N, 1} and with square variation process
BMNC
n = 2
N2
nâˆ’1

k=0
MN
k
1 âˆ’MN
k
.
At each step, MN can either stay put or increase or decrease by 1/N. In Exer-
cise 17.2.1, we saw that this determines the process MN uniquely. Similarly as
in Theorem 21.51 for branching processes, it can be shown that the time-rescaled
Moran processes
ËœMN
t
= MN
âŒŠN2tâŒ‹converge to the Wrightâ€“Fisher diffusion with
Î³
= 2. The Wrightâ€“Fisher diffusion thus occurs as the limiting model of a
genealogical model and describes the gene frequency (that is, the fraction) of a
certain allele in a population that ï¬‚uctuates randomly due to resampling. â™¦
Example 26.31 (Fellerâ€™s branching diffusion) Let (ZN
n )nâˆˆN0 be a Galtonâ€“Watson
branching process with critical geometric offspring distribution pk = 2âˆ’kâˆ’1, k âˆˆN0
and ZN
0 = N for any N âˆˆN. Then ZN is a discrete martingale and we have
E
'
ZN
n âˆ’ZN
nâˆ’1
2 ZN
nâˆ’1
(
= ZN
nâˆ’1
 âˆ

k=0
pk k2 âˆ’1

= 2 ZN
nâˆ’1.
Hence ZN has square variation
âŸ¨ZNâŸ©n =
nâˆ’1

k=0
2ZN
k .
Deï¬ne the linearly interpolated version
ZN
t
:=

t âˆ’Nâˆ’1âŒŠtNâŒ‹
 
ZN
âŒŠtNâŒ‹+1 âˆ’ZN
âŒŠtNâŒ‹

+ 1
nZN
âŒŠtNâŒ‹
of Nâˆ’1ZN
âŒŠtNâŒ‹. By Lindvallâ€™s theorem (Theorem 21.51), there is a continuous Markov
process Z such that ZN
Nâ†’âˆ
âˆ’â†’
Z in distribution. See Fig. 26.4 for a computer
simulation of Z. Since it can be shown that the moments also converge, we have
that Z is a continuous martingale with square variation
âŸ¨ZâŸ©t =
 t
0
2Zs ds.
In fact, in Example 26.11, we have already shown that Z is the unique solution of
the SDE
dZt =
2
2Zt dWt
(26.30)

26.3
Weak Uniqueness via Duality
687
0
1
2
3
1
2
3
4
5
Fig. 26.4 Simulation of Fellerâ€™s branching diffusion with parameter Î³ = 1.
with initial value Z0 = 1. There we also showed that Z is dual to Y y
t =

tÎ³
2 + 1
y
âˆ’1
with H(x, y) = eâˆ’xy. This implies uniqueness of the solution of (26.30) and the
strong Markov property of Z. â™¦
It could be objected that in Examples 26.29 and 26.31, we considered only one-
dimensional problems for which the Yamadaâ€“Watanabe theorem (Theorem 26.10)
yields uniqueness (indeed of a strong solution) anyway. The full strength of the
method of duality is displayed only in higher-dimensionalproblems. As an example,
we consider an extension of Example 26.29.
Example 26.32 (Interacting Wrightâ€“Fisher diffusions)
The Wrightâ€“Fisher diffu-
sion from Example 26.29 describes the ï¬‚uctuations of the gene frequency of an
allele in one large population. Now we consider more populations, which live at
the points i âˆˆS := {1, . . ., N} and interact with each other by a migration that
is quantiï¬ed by migration rates r(i, j) â‰¥0. As a model for the gene frequencies
Xt(i) at site i at time t we use the following N-dimensional SDE for X =
(X(1), . . ., X(N)):
dXt(i) =
2
Î³ Xt(i)(1 âˆ’Xt(i)) dW i
t +
N

j=1
r(i, j)

Xt(j) âˆ’Xt(i)

dt.
(26.31)
Here W
= (W 1, . . . , W N) is an N-dimensional Brownian motion. By Theo-
rem 26.22, this SDE has weak solutions; however, none of our general criteria for
weak uniqueness apply. We will thus show weak uniqueness by virtue of duality.

688
26
Stochastic Differential Equations
As in Example 26.29, it is not hard to show that solutions of (26.31), started at
X0 = x âˆˆE := [0, 1]S, remain in [0, 1]S. The diagonal terms r(i, i) do not appear
in (26.31). We use our freedom and deï¬ne these terms as r(i, i) = âˆ’
jÌ¸=i r(i, j).
Let Y = (Yt)tâ‰¥0 be the Markov process on Eâ€² := (N0)S with the following Q-
matrix:
q(Ï•, Î·) =
â§
âªâªâªâªâªâªâªâªâ¨
âªâªâªâªâªâªâªâªâ©
Ï•(i) r(i, j),
if Î· = Ï• âˆ’1{i} + 1{j} for
some i, j âˆˆS, i Ì¸= j,
Î³
Ï•(i)
2

,
if Î· = Ï• âˆ’1{i} for some i âˆˆS,

iâˆˆS

Ï•(i)r(i, i) âˆ’Î³
Ï•(i)
2

,
if Î· = Ï•,
0,
else.
Here Ï• âˆˆEâ€² denotes a generic state with Ï•(i) particles at site i âˆˆS, and 1{i} âˆˆ
Eâ€² denotes the state with exactly one particle at site i. The process Y describes a
system of particles that independently with rate r(i, j) jump from site i to site j.
If there is more than one particle at the same site i, then any of the Ï•(i)
2
 pairs of
particles coalesce with the same rate Î³ to one particle. The common genealogical
interpretation of this process is that (in reversed time) it describes the lines of descent
of samples of Y0(i) individuals at each site i âˆˆS. By migration, the lines change
sites. If two individuals have the same common ancestor, then their lines coalesce.
Clearly, for two particles to have the same ancestor at a given time, it is necessary
but not sufï¬cient for them to be at the same site.
For x âˆˆRn and Ï• âˆˆEâ€², we denote xÏ• := 
iâˆˆS x(i)Ï•(i). We show that X and Y
are dual to each other with the duality function H(x, Ï•) = xÏ•:
Ex[XÏ•
t ] = EÏ•[xYt]
for all Ï• âˆˆSN0, x âˆˆ[0, 1]S, t â‰¥0.
(26.32)
Let mx,Ï•(t) := Ex[XÏ•
t ] and gx,Ï•(t) := EÏ•[xYt]. Clearly, H has the derivatives
âˆ‚iH( Â·, Ï•)(x) = Ï•(i)xÏ•âˆ’1{i} and âˆ‚iâˆ‚iH( Â·, Ï•)(x) = 2
Ï•(i)
2

xÏ•âˆ’2 1{i}.
By the ItÃ´ formula,
XÏ•
t âˆ’XÏ•
0 âˆ’
 t
0

i,jâˆˆS
Ï•(i)r(i, j)

Xs(j) âˆ’Xs(i)

XÏ•âˆ’1{i}
t
ds
âˆ’

iâˆˆS
 t
0
Î³
Ï•(i)
2
Xs(i)(1 âˆ’Xs(i))XÏ•âˆ’2 1{i}
s
ds

26.3
Weak Uniqueness via Duality
689
is a martingale. Taking expectations, we get a system of linear integral equations
mx,0(t) = 1,
mx,Ï•(t) = xÏ• +
 t
0

i,jâˆˆS
Ï•(i)r(i, j)

mx,Ï•+1{j}âˆ’1{i}(s) âˆ’mx,Ï•(s)

ds
+
 t
0
Î³

iâˆˆS
Ï•(i)
2

mx,Ï•âˆ’1{i}(s) âˆ’mx,Ï•(s)

ds.
(26.33)
This system of equations can be solved uniquely by induction on n = 
iâˆˆI Ï•(i).
However, we do not intend to compute this solution explicitly. We show only that it
coincides with gx,Ï•(t) by showing that g solves an equivalent system of differential
equations.
For g as in (26.29), we obtain
d
dt gx,Ï•(t) =

Î·âˆˆEâ€²
q(Ï•, Î·) gx,Ï•(t)
=

i,jâˆˆS
r(i, j)

gx,Ï•+1{j}âˆ’1{i}(t) âˆ’gx,Ï•(t)

+

iâˆˆS
Î³
Ï•(i)
2

gx,Ï•âˆ’1{i}(t) âˆ’gx,Ï•(t)

.
(26.34)
Together with the initial values gx,0(t) = 1 and gx,Ï•(0) = xÏ•, the system (26.34)
of differential equations is equivalent to (26.33). Hence the duality (26.32) holds,
and thus the SDE (26.31) has a unique weak solution. (In fact, it can be shown that
there exists a unique strong solution, even if S is countably inï¬nite, as long as r then
satisï¬es certain regularity conditions such as if it is the Q-matrix of a random walk
on S = Zd; see [154].) â™¦
Takeaways One tool to establish uniqueness of a weak solution of a stochas-
tic differential equation is a duality of the solution to a second process
(either deterministic or random). For Fellerâ€™s branching diffusion, we have
a deterministic dual. Interacting Wright-Fisher diffusions are dual to a system
of (delayed) coalescing random walks. In many cases the dual process can
be used to compute quantitative properties such as extinction probabilities,
ï¬xation probabilities and so on.

690
26
Stochastic Differential Equations
Exercise 26.3.1 (Extinction probability of Fellerâ€™s branching diffusion) Let
Î³ > 0 and let Z be the solution of dZt := âˆšÎ³ Zt dWt with initial value Z0 = z > 0.
Use the duality to show
Pz[Zt = 0] = exp

âˆ’2z
Î³ t

.
(26.35)
Use Lemma 21.44 to compute the probability that a Galtonâ€“Watson branching
process X with critical geometric offspring distribution and with X0 = N âˆˆN
is extinct by time n âˆˆN. Compare the result with (26.35). â™£

References
1. R.J. Adler, An Introduction to Continuity, Extrema, and Related Topics for General Gaussian
Processes. Institute of Mathematical Statistics Lecture Notes-Monograph Series, vol. 12
(Institute of Mathematical Statistics, Hayward, CA, 1990)
2. M. Aizenman, H. Kesten, C.M. Newman, Uniqueness of the inï¬nite cluster and continuity of
connectivity functions for short and long range percolation. Commun. Math. Phys. 111(4),
505â€“531 (1987)
3. M. Aizenman, H. Kesten, C.M. Newman, Uniqueness of the inï¬nite cluster and related
results in percolation, in Percolation theory and ergodic theory of inï¬nite particle systems
(Minneapolis, Minn., 1984â€“1985). IMA Volumes in Mathematics and Its Applications, vol. 8
(Springer, New York, 1987), pp. 13â€“20
4. D.J. Aldous, Exchangeability and related topics, in Ã‰cole dâ€™Ã©tÃ© de probabilitÃ©s de Saint-Flour,
XIIIâ€”1983. Lecture Notes in Mathematics, vol. 1117 (Springer, Berlin, 1985), pp. 1â€“198
5. K.B. Athreya, P.E. Ney, Branching Processes (Springer, Berlin, 1972)
6. J. AzÃ©ma, M. Yor, Le problÃ¨me de Skorokhod: complÃ©ments Ã  â€œUne solution simple au
problÃ¨me de Skorokhodâ€, in SÃ©minaire de ProbabilitÃ©s, XIII (Univ. Strasbourg, Strasbourg,
1977/78). Lecture Notes in Mathematics, vol. 721 (Springer, Berlin, 1979), pp. 625â€“633
7. J. AzÃ©ma, M. Yor, Une solution simple au problÃ¨me de Skorokhod, in SÃ©minaire de
ProbabilitÃ©s, XIII (Univ. Strasbourg, Strasbourg, 1977/78). Lecture Notes in Mathematics,
vol. 721 (Springer, Berlin, 1979), pp. 90â€“115
8. L.E. Baum, M. Katz, Convergence rates in the law of large numbers. Trans. Am. Math. Soc.
120, 108â€“123 (1965)
9. M. Baxter, R. Rennie, Financial Calculus (Cambridge University Press, Cambridge, 1997)
10. A.C. Berry, The accuracy of the Gaussian approximation to the sum of independent variates.
Trans. Am. Math. Soc. 49, 122â€“136 (1941)
11. A. Beutelspacher, Kryptologie (Vieweg + Teubner, Wiesbaden, 9th edn, 2009)
12. P. Billingsley, Convergence of Probability Measures (Wiley, New York, 1968)
13. P. Billingsley, Weak Convergence of Measures: Applications in Probability. Conference Board
of the Mathematical Sciences Regional Conference Series in Applied Mathematics, No. 5
(Society for Industrial and Applied Mathematics, Philadelphia, PA, 1971)
14. P. Billingsley, Convergence of Probability Measures, 2nd edn. Wiley Series in Probability
and Statistics: Probability and Statistics (Wiley, New York, 1999). A Wiley-Interscience
Publication
15. K. Binder, D.W. Heermann, Monte Carlo Simulation in Statistical Physics: An Introduction,
3rd edn. Springer Series in Solid-State Sciences, vol. 80 (Springer, Berlin, 1997)
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
691

692
References
16. G.D. Birkhoff, Proof of the ergodic theorem. Proc. Nat. Acad. Sci. 17, 656â€“660 (1931)
17. D. Blackwell, D, Kendall, The Martin boundary of PÃ³lyaâ€™s urn scheme, and an application to
stochastic population growth. J. Appl. Probab. 1, 284â€“296 (1964)
18. R.M. Blumenthal, An extended Markov property. Trans. Amer. Math. Soc. 85, 52â€“72 (1957)
19. S. Bochner, Vorlesungen Ã¼ber Fouriersche Integrale. (Chelsea Publishing Company, New
York, 1932) Reprinted 1948
20. L. Breiman, Probability (Addison-Wesley Publishing Company, Reading, MA, 1968)
21. P. BrÃ©maud, Markov Chains. Texts in Applied Mathematics, vol. 31. Gibbs ï¬elds, Monte
Carlo simulation, and queues (Springer, New York, 1999)
22. D. BrÃ¼ggemann. Starke Gesetze der groÃŸen Zahlen bei blockweisen UnabhÃ¤ngigkeits-
bedingungen. PhD thesis, UniversitÃ¤t zu KÃ¶ln, 2002
23. R.M. Burton, M. Keane, Density and uniqueness in percolation. Commun. Math. Phys.
121(3), 501â€“505 (1989)
24. G. Choquet, J. Deny, Sur lâ€™Ã©quation de convolution Î¼ = Î¼ âˆ—Ïƒ. C. R. Acad. Sci. Paris 250,
799â€“801 (1960)
25. Y.S. Chow, H. Teicher, Probability Theory: Independence, Interchangeability, Martingales,
3rd edn. Springer Texts in Statistics (Springer, New York, 1997)
26. K.L. Chung, Markov Chains with Stationary Transition Probabilities. Die Grundlehren der
mathematischen Wissenschaften, Bd. 104 (Springer, Berlin, 1960)
27. K.L. Chung, W.H.J. Fuchs, On the distribution of values of sums of random variables. Mem.
Am. Math. Soc. 6, 1â€“12 (1951)
28. P. Clifford, A. Sudbury, A model for spatial conï¬‚ict. Biometrika 60, 581â€“588 (1973)
29. H. CramÃ©r, Sur un nouveau thÃ©orÃ¨me-limite de la thÃ©orie des probabilitÃ©s. ActualitÃ©s
Scientiï¬ques et Industrielles 763, 5â€“23 (1938). Colloque consacrÃ© Ã  la thÃ©orie des probabilitÃ©s
30. F. Delbaen, W. Schachermayer, A general version of the fundamental theorem of asset pricing.
Math. Ann. 300(3), 463â€“520 (1994)
31. A. Dembo, O. Zeitouni, Large Deviations Techniques and Applications. Stochastic Modelling
and Applied Probability, vol. 38 (Springer, Berlin, 2010). Korrigierter Nachdruck der zweiten
Auï¬‚age von 1998
32. J.-D. Deuschel, D.W. Stroock, Large Deviations. Pure and Applied Mathematics, vol. 137
(Academic, Boston, MA, 1989)
33. P. Diaconis, D. Freedman, Finite exchangeable sequences. Ann. Probab. 8(4), 745â€“764 (1980)
34. J. DieudonnÃ©, Foundations of Modern Analysis. Pure and Applied Mathematics, vol. X
(Academic, New York/London, 1960)
35. M.D. Donsker, An invariance principle for certain probability limit theorems. Mem. Am.
Math. Soc. 6, 1â€“12 (1951)
36. P.G. Doyle, J.L. Snell, Random Walks and Electric Networks. Carus Mathematical Mono-
graphs, vol. 22 (Mathematical Association of America, Washington, DC, 1984)
37. R.M. Dudley, Real Analysis and Probability. Cambridge Studies in Advanced Mathematics,
vol. 74 (Cambridge University Press, Cambridge, 2002). Revised reprint of the 1989 original
38. N. Dunford, J.T. Schwartz, Linear Operators. I. General Theory. With the assistance of W. G.
Bade and R. G. Bartle. Pure and Applied Mathematics, vol. 7 (Interscience Publishers, Inc.,
New York, 1958)
39. R. Durrett, Probability: Theory and Examples, 4th edn. Cambridge Series in Statistical and
Probabilistic Mathematics. (Cambridge University Press, Cambridge 2010)
40. A. Dvoretzky, P. ErdËos, S. Kakutani, Nonincrease everywhere of the Brownian motion
process, in Proceedings of the 4th Berkeley Symposium on Mathematics, Statistics and
Probability, vol. II (University of California Press, Berkeley, CA, 1961), pp. 103â€“116
41. D. Egoroff, Sur les suites des fonctions measurables. C. R. Acad. Sci. Paris 152, 135â€“157
(1911)
42. R.J. Elliott, P.E. Kopp, Mathematics of Financial Markets, 2nd edn. Springer Finance
(Springer, New York, 2005)
43. R.S. Ellis, Entropy, Large Deviations, and Statistical Mechanics. Grundlehren der Mathema-
tischen Wissenschaften, vol. 271 (Springer, New York, 1985)

References
693
44. J. Elstrodt, MaÃŸ- und Integrationstheorie, 8th edn. (Springer, New York, 2018)
45. P. ErdËos, R.L. Graham, On a linear diophantine problem of Frobenius. Acta Arith. 21, 399â€“
408 (1972)
46. C.-G. Esseen, On the Liapounoff limit of error in the theory of probability. Ark. Mat. Astr.
Fys. 28A(9), 1â€“19 (1942)
47. N. Etemadi, An elementary proof of the strong law of large numbers. Z. Wahrsch. Verw.
Gebiete 55(1), 119â€“122 (1981)
48. A. Etheridge, A Course in Financial Calculus (Cambridge University Press, Cambridge,
2002)
49. S.N. Ethier, T.G. Kurtz, Markov Processes: Characterization and Convergence. Wiley Series
in Probability and Mathematical Statistics: Probability and Mathematical Statistics (Wiley,
New York, 1986)
50. S.N. Evans, X. Zhou, Identiï¬ability of exchangeable sequences with identically distributed
partial sums. Electron. Comm. Probab. 4, 9â€“13 (electronic) (1999)
51. W. Feller, Ãœber den zentralen Grenzwertsatz der Wahrscheinlichkeitstheorie I. Math. Zeit. 40,
521â€“559 (1935)
52. W. Feller, Ãœber den zentralen Grenzwertsatz der Wahrscheinlichkeitstheorie II. Math. Zeit.
42, 301â€“312 (1937)
53. W. Feller, An Introduction to Probability Theory and its Applications, vol. I, 3rd edn. (Wiley,
New York, 1968)
54. W. Feller, An Introduction to Probability Theory and its Applications, vol. II, 2nd edn. (Wiley,
New York, 1971)
55. J.A. Fill, An interruptible algorithm for perfect sampling via Markov chains. Ann. Appl.
Probab. 8(1), 131â€“162 (1998)
56. J.A. Fill, M. Machida, D.J. Murdoch, J.S. Rosenthal, Extension of Fillâ€™s perfect rejection
sampling algorithm to general chains. Random Struct. Algoritm. 17(3â€“4), 290â€“316 (2000).
Proceedings of the Ninth International Conference â€œRandom Structures and Algorithmsâ€
(Poznan, 1999)
57. H. FÃ¶llmer, A. Schied, Stochastic Finance. de Gruyter Studies in Mathematics, vol. 27, 2nd
edn. (Walter de Gruyter & Co., Berlin, 2004)
58. D.A. Freedman, Bernard Friedmanâ€™s urn. Ann. Math. Statist 36, 956â€“970 (1965)
59. H.-O. Georgii, Stochastics: Introduction to Probability Theory and Statistics. de Gruyter
Lehrbuch, 2nd edn. (Walter de Gruyter & Co., Berlin, 2012)
60. A.L. Gibbs, F.E. Su, On choosing and bounding probability metrics. Int. Stat. Rev. 70(3),
419â€“435 (2002)
61. M.L. Glasser, I.J. Zucker, Extended Watson integrals for the cubic lattices. Proc. Nat. Acad.
Sci. U.S.A. 74(5), 1800â€“1801 (1977)
62. B.V. Gnedenko, A.N. Kolmogorov, Limit Distributions for Sums of Independent Random
Variables (Addison-Wesley Publishing Co., Reading, MA/London/Don Mills, ON, 1968)
63. G. Grimmett, Percolation. Grundlehren der Mathematischen Wissenschaften, vol. 321, 2nd
edn. (Springer, Berlin, 1999)
64. G.R. Grimmett, D.R. Stirzaker, Probability and Random Processes, 3rd edn. (Oxford
University Press, New York, 2001)
65. E. Grosswald, The Student t-distribution of any degree of freedom is inï¬nitely divisible. Z.
Wahrsch. Verw. Gebiete 36(2), 103â€“109 (1976)
66. O. HÃ¤ggstrÃ¶m, Finite Markov Chains and Algorithmic Applications. London Mathematical
Society Student Texts, vol. 52 (Cambridge University Press, Cambridge, 2002)
67. T. Hara, G. Slade, Mean-ï¬eld critical behaviour for percolation in high dimensions. Commun.
Math. Phys. 128(2), 333â€“391 (1990)
68. J.M. Harrison, S.R. Pliska, Martingales and stochastic integrals in the theory of continuous
trading. Stoch. Process. Appl. 11(3), 215â€“260 (1981)
69. P. Hartman, A. Wintner, On the law of the iterated logarithm. Am. J. Math. 63, 169â€“176
(1941)

694
References
70. W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications.
Biometrika 57, 97â€“109 (1970)
71. E. Hewitt, K.A. Ross, Abstract Harmonic Analysis. Vol. II: Structure and analysis for
compact groups. Analysis on locally compact Abelian groups. Die Grundlehren der mathe-
matischen Wissenschaften, Band 152 (Springer, New York, 1970)
72. E. Hewitt, L.J. Savage, Symmetric measures on Cartesian products. Trans. Math. Soc. 80,
470â€“501 (1955)
73. C.C. Heyde, On a property of the lognormal distribution. J. R. Stat. Soc. B 29, 392â€“393 (1963)
74. F. den Hollander, Large Deviations. Fields Institute Monographs, vol. 14 (American Mathe-
matical Society, Providence, RI, 2000)
75. R.A. Holley, T.M. Liggett, Ergodic theorems for weakly interacting inï¬nite systems and the
voter model. Ann. Probab. 3(4), 643â€“663 (1975)
76. B.D. Hughes, Random Walks and Random Environments, vol. 1. Oxford Science Publications
(The Clarendon Press/Oxford University Press, New York, 1995). Random walks
77. B.D. Hughes, Random Walks and Random Environments, vol. 2. Oxford Science Publications
(The Clarendon Press/Oxford University Press, New York, 1996). Random environments
78. N. Ikeda, S. Watanabe, Stochastic Differential Equations and Diffusion Processes. North-
Holland Mathematical Library, vol. 24, 2nd edn. (North-Holland Publishing Co., Amsterdam,
1989)
79. J. Jost, Partial Differential Equations. Graduate Texts in Mathematics, vol. 214, 3rd edn.
(Springer, New York, 2013)
80. G.S. Joyce, Singular behaviour of the lattice Green function for the d-dimensional hypercubic
lattice. J. Phys. A 36(4), 911â€“921 (2003)
81. S. Kakutani, Examples of ergodic measure preserving transformations which are weakly
mising but not strongly mixing, in Recent Advances in Topological Dynamics (Proceedings
of the Conference at Yale University, New Haven, CT, 1972, in honor of Gustav Arnold
Hedlund). Lecture Notes in Mathematics, vol. 318 (Springer, Berlin, 1973), pp. 143â€“149
82. O. Kallenberg, Random Measures, 4th edn. (Akademie-Verlag, Berlin, 1986)
83. O. Kallenberg, Foundations of Modern Probability, 2nd edn. Probability and Its Applications
(Springer, New York/Berlin, 2002)
84. L.V. KantoroviË‡c, G.Å . RubinÅ¡teË˜Ä±n, On a space of completely additive functions. Vestnik
Leningrad Univ. 13(7), 52â€“59 (1958)
85. I. Karatzas, S.E. Shreve, Brownian Motion and Stochastic Calculus. Graduate Texts in
Mathematics, vol. 113, 2nd edn. (Springer, New York, 1991)
86. I. Karatzas, S.E. Shreve, Methods of Mathematical Finance. Applications of Mathematics,
vol. 39 (Springer, New York, 1998)
87. T. Kato, Perturbation Theory for Linear Operators, 2nd edn. Grundlehren der Mathematis-
chen Wissenschaften, Band 132. (Springer, Berlin, 1976)
88. G. Keller, Equilibrium States in Ergodic Theory. London Mathematical Society Student Texts,
vol. 42 (Cambridge University Press, Cambridge, 1998)
89. G. Keller, Wahrscheinlichkeitstheorie. Lecture Notes (German) (UniversitÃ¤t Erlangen, 2003)
90. J.L. Kelley, General Topology. Graduate Texts in Mathematics, vol. 27 (Springer, New York,
1975). Reprint of the 1955 edition [Van Nostrand, Toronto, Ontario]
91. J.G. Kemeny, J.L. Snell, Finite Markov Chains. Undergraduate Texts in Mathematics
(Springer, New York, 1976). Reprinting of the 1960 original
92. R.W. Kenyon, J.G. Propp, D.B. Wilson, Trees and matchings. Electron. J. Combin. 7,
Research Paper 25, 34 pp. (electronic) (2000)
93. H. Kesten, Sums of stationary sequences cannot grow slower than linearly. Proc. Am. Math.
Soc. 49, 205â€“211 (1975)
94. H. Kesten, The critical probability of bond percolation on the square lattice equals
1
2.
Commun. Math. Phys. 74(1), 41â€“59 (1980)
95. H. Kesten, B.P. Stigum, A limit theorem for multidimensional Galton-Watson processes. Ann.
Math. Statist. 37, 1211â€“1223 (1966)

References
695
96. H. Kesten, M.V. Kozlov, F. Spitzer, A limit law for random walk in a random environment.
Compos. Math. 30, 145â€“168 (1975)
97. A. Khintchine, Ãœber dyadische BrÃ¼che. Math. Z. 18, 109â€“116 (1923)
98. J.F.C. Kingman, Uses of exchangeability. Ann. Probab. 6(2), 183â€“197 (1978)
99. J.F.C. Kingman, Poisson Processes. Oxford Studies in Probability, vol. 3 (The Clarendon
Press/Oxford University Press, New York, 1993). Oxford Science Publications
100. A. Klenke, L. Mattner, Stochastic ordering of classical discrete distributions. Adv. in Appl.
Probab. 42(2), 392â€“410 (2010)
101. A.N. Kolmogorov, Sulla determinazione empirica di una legge di distibuzione. Giornale
Istituto Italiano degli Attuari 4, 83â€“91 (1933)
102. R. Korn, E. Korn, Option Pricing and Portfolio Optimization. Graduate Studies in Mathe-
matics, vol. 31 (American Mathematical Society, Providence, RI, 2001). Modern methods of
ï¬nancial mathematics, translated from the 1999 German original by the authors
103. U. Krengel, Ergodic Theorems. de Gruyter Studies in Mathematics, vol. 6 (Walter de Gruyter
& Co., Berlin, 1985)
104. S. Kullback, R.A. Leibler, On information and sufï¬ciency. Ann. Math. Stat. 22, 79â€“86 (1951)
105. S.L. Lauritzen, Extremal Families and Systems of Sufï¬cient Statistics. Lecture Notes in
Statistics, vol. 49 (Springer, New York, 1988)
106. P. LÃ©vy, ThÃ©orie de lâ€™Addition des Variables AlÃ©atoires (Gauthier-Villars, Paris, 1937)
107. P. LÃ©vy, Processus Stochastiques et Mouvement Brownien. Suivi dâ€™une note de M. LoÃ¨ve
(Gauthier-Villars, Paris, 1948)
108. J.W. Lindeberg, Eine neue Herleitung des Exponentialgesetzes in der Wahrscheinlichkeit-
srechnung. Math. Zeit. 15, 211â€“225 (1922)
109. T. Lindvall, Convergence of critical Galton-Watson branching processes. J. Appl. Probab. 9,
445â€“450 (1972)
110. R. Lyons, Y. Peres, Probability on Trees and Networks. Cambridge Series in Statistical and
Probabilistic Mathematics, vol. 42 (Cambridge University Press, New York, 2016)
111. R. Lyons, R. Pemantle, Y. Peres, Conceptual proofs of L log L criteria for mean behavior of
branching processes. Ann. Probab. 23(3), 1125â€“1138 (1995)
112. N. Madras, Lectures on Monte Carlo Methods. Fields Institute Monographs, vol. 16 (Ameri-
can Mathematical Society, Providence, RI, 2002)
113. D.E. Menchoff, Sur les sÃ©ries des fonctions orthogonales (premiÃ¨re partie). Fund. Math. 4,
92â€“105 (1923)
114. N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, E. Teller, Equation of state
calculations by fast computing machines. J. Chem. Phys. 21, 1087â€“1092 (1953)
115. P.-A. Meyer, Probability and Potentials (Blaisdell Publishing Co. Ginn and Co., Waltham,
MA/Toronto, ON/London, 1966)
116. S.P. Meyn, R.L. Tweedie, Markov Chains and Stochastic Stability. Communications and
Control Engineering Series (Springer, London, 1993)
117. F. MÃ³ricz, K. Tandori, An improved Menshovâ€“Rademacher theorem. Proc. Am. Math. Soc.
124(3), 877â€“885 (1996)
118. P. MÃ¶rters, Y. Peres, Brownian Motion. Cambridge Series in Statistical and Probabilistic
Mathematics (Cambridge University Press, Cambridge, 2010). With an appendix by Oded
Schramm and Wendelin Werner
119. R. Motwani, P. Raghavan, Randomized Algorithms (Cambridge University Press, Cambridge,
1995)
120. A. MÃ¼ller, D. Stoyan, Comparison Methods for Stochastic Models and Risks. Wiley Series in
Probability and Statistics (Wiley, Chichester, 2002)
121. M. Musiela, M. Rutkowski, Martingale Methods in Financial Modelling. Stochastic Mod-
elling and Applied Probability, vol. 36, 2nd edn. (Springer, Berlin, 2005)
122. J. von Neumann, Proof of the quasi-ergodic hypothesis. Proc. Nat. Acad. Sci. 18, 70â€“82
(1932)
123. J.R. Norris, Markov Chains. Cambridge Series in Statistical and Probabilistic Mathematics
(Cambridge University Press, Cambridge, 1998). Reprint of the 1997 edition

696
References
124. E. Nummelin, General Irreducible Markov Chains and Nonnegative Operators. Cambridge
Tracts in Mathematics, vol. 83 (Cambridge University Press, Cambridge, 1984)
125. R.E.A.C. Paley, N. Wiener, Fourier Transforms in the Complex Domain. American Mathemat-
ical Society Colloquium Publications, vol. 19 (American Mathematical Society, Providence,
RI, 1987). Reprint of the 1934 original
126. R.E.A.C. Paley, N. Wiener, A. Zygmund, Note on random functions. Math. Zeit. 37, 647â€“668
(1933)
127. R.F. Peierls, On Isingâ€™s model of ferromagnetism. Proc. Camb. Philol. Soc. 32, 477â€“481
(1936)
128. V.V. Petrov, Sums of Independent Random Variables. Ergebnisse der Mathematik und ihrer
Grenzgebiete, vol. 82 (Springer, New York, 1975)
129. J. Pitman, Exchangeable and partially exchangeable random partitions. Probab. Theory
Related Fields 102(2), 145â€“158 (1995)
130. J. Pitman, Combinatorial Stochastic Processes. Lecture Notes in Mathematics, vol. 1875
(Springer, Berlin, 2006). Lectures from the 32nd Summer School on Probability Theory held
in Saint-Flour, July 7â€“24, 2002, with a foreword by Jean Picard
131. J. Pitman, M. Yor, Bessel processes and inï¬nitely divisible laws, in Stochastic integrals
(Proceedings of the Symposium at the University of Durham, Durham, 1980). Lecture Notes
in Mathematics, vol. 851 (Springer, Berlin, 1981), pp. 285â€“370
132. J. Pitman, M. Yor, The two-parameter Poisson-Dirichlet distribution derived from a stable
subordinator. Ann. Probab. 25(2), 855â€“900 (1997)
133. J. Pitman, M. Yor, On the distribution of ranked heights of excursions of a Brownian bridge.
Ann. Probab. 29(1), 361â€“384 (2001)
134. G. PÃ³lya, Ãœber eine Aufgabe der Wahrscheinlichkeitsrechnung betreffend die Irrfahrt im
StraÃŸennetz. Math. Ann. 84, 149â€“160 (1921)
135. G. PÃ³lya, Sur quelques points de la thÃ©orie de probabilitÃ©s. Ann. Inst. H. PoincarÃ© 1, 117â€“161
(1931)
136. Y.V. Prohorov, Convergence of random processes and limit theorems in probability theory.
Teor. Veroyatnost. i Primenen. 1, 177â€“238 (1956). Russian with English summary
137. J. Propp, D. Wilson, Coupling from the past: a userâ€™s guide, in Microsurveys in Discrete
Probability (Princeton, NJ, 1997). DIMACS Series in Discrete Mathematics and Theoretical
Computer Science, vol. 41 (American Mathematical Society, Providence, RI, 1998), pp. 181â€“
192
138. J.G. Propp, D.B. Wilson, Exact sampling with coupled Markov chains and applications to
statistical mechanics. Random Struct. Algoritm. 9(1â€“2), 223â€“252 (1996)
139. J.G. Propp, D.B. Wilson, How to get a perfectly random sample from a generic Markov
chain and generate a random spanning tree of a directed graph. J. Algorithms 27(2), 170â€“217
(1998). 7th Annual ACM-SIAM Symposium on Discrete Algorithms (Atlanta, GA, 1996)
140. P.E. Protter, Stochastic Integration and Differential Equations. Applications of Mathematics
(New York), vol. 21, 2nd edn. (Springer, Berlin, 2004). Stochastic Modelling and Applied
Probability
141. H. Rademacher, Einige SÃ¤tze Ã¼ber Reihen von allgemeinen Orthogonalfunktionen. Math.
Ann. 87, 112â€“138 (1922)
142. A. RÃ©nyi, Remarks on the Poisson process. Studia Sci. Math. Hungar 2, 119â€“123 (1967)
143. P. RÃ©vÃ©sz, Random Walk in Random and Non-random Environments, 2nd edn. (World
Scientiï¬c Publishing Co. Pte. Ltd., Hackensack, NJ, 2005)
144. D. Revuz, Markov Chains. North-Holland Mathematical Library, vol. 11, 2nd edn. (North-
Holland Publishing Co., Amsterdam, 1984)
145. D. Revuz, M. Yor, Continuous Martingales and Brownian Motion. Grundlehren der Mathe-
matischen Wissenschaften, vol. 293, 3rd edn. (Springer, Berlin, 1999)
146. R.T. Rockafellar, Convex Analysis. Princeton Mathematical Series, No. 28 (Princeton Univer-
sity Press, Princeton, NJ, 1970)

References
697
147. L.C.G. Rogers, D. Williams, Diffusions, Markov Processes, and Martingales. Vol. 1:
Foundations. Cambridge Mathematical Library (Cambridge University Press, Cambridge,
2000). Reprint of the 2nd edition from 1994
148. L.C.G. Rogers, D. Williams, Diffusions, Markov Processes, and Martingales. Vol. 2: ItÃ´
Calculus. Cambridge Mathematical Library (Cambridge University Press, Cambridge, 2000).
Reprint of the 2nd edition from 1994
149. W. Rudin, Principles of Mathematical Analysis. International Series in Pure and Applied
Mathematics, 3rd edn. (McGraw-Hill, New York, 1976)
150. I.N. Sanov, On the probability of large deviations of random magnitudes (Russian). Mat. Sb.
N. S. 42(84), 11â€“44 (1957)
151. I.N. Sanov, On the probability of large deviations of random variables. Sel. Transl. Math. Stat.
Probab. 1, 213â€“244 (1961)
152. R.L. Schilling, L. Partzsch, Brownian Motion (De Gruyter, Berlin, 2012). An introduction to
stochastic processes, With a chapter on simulation by BjÃ¶rn BÃ¶ttcher.
153. E. Seneta, Non-negative Matrices and Markov Chains. Springer Series in Statistics (Springer,
New York, 2006). Revised reprint of the second (1981) edition
154. T. Shiga, A. Shimizu, Inï¬nite-dimensional stochastic differential equations and their applica-
tions. J. Math. Kyoto Univ. 20(3), 395â€“416 (1980)
155. A.N. Shiryaev, Probability. Graduate Texts in Mathematics, vol. 95, 2nd edn. (Springer, New
York, 1996). Translation of the Russian edition from 1980
156. J. SinaË˜Ä±, On the concept of entropy for a dynamic system. Dokl. Akad. Nauk SSSR 124,
768â€“771 (1959)
157. N.V. Smirnov, Sur les Ã©carts de la courbe de distribution empirique. Matematicheskij Sbornik,
Rossijskaya Akademiya Nauk, Moscow 2, 3â€“16 (1939). Russian with French summary
158. F. Solomon, Random walks in a random environment. Ann. Probab. 3, 1â€“31 (1975)
159. F. Spitzer, Principles of Random Walks. Graduate Texts in Mathematics, vol. 34, 2nd edn.
(Springer, New York, 1976)
160. J.M. Steele, Stochastic Calculus and Financial Applications. Applications of Mathematics
(New York), vol. 45 (Springer, New York, 2001)
161. V. Strassen, The existence of probability measures with given marginals. Ann. Math. Statist.
36, 423â€“439 (1965)
162. D.W. Stroock, S.R.S. Varadhan, Multidimensional Diffusion Processes. Grundlehren der
Mathematischen Wissenschaften, vol. 233 (Springer, Berlin, 1979)
163. J.J. Sylvester, Mathematical questions with their solutions. Educ. Times 41, 171â€“178 (1884)
164. K. Tandori, Ãœber die orthogonalen Funktionen. I. Acta Sci. Math. Szeged 18, 57â€“130 (1957)
165. K. Tandori, Ãœber die Divergenz der Orthogonalreihen. Publ. Math. Debrecen 8, 291â€“307
(1961)
166. K. Tandori, Bemerkung Ã¼ber die paarweise unabhÃ¤ngigen zufÃ¤lligen GrÃ¶ÃŸen. Acta Math.
Hungar. 48(3â€“4), 357â€“359 (1986)
167. S.R.S. Varadhan, Asymptotic probabilities and differential equations. Commun. Pure Appl.
Math. 19, 261â€“286 (1966)
168. P. Walters, An Introduction to Ergodic Theory. Graduate Texts in Mathematics, vol. 79
(Springer, New York, 1982)
169. G.N. Watson, Three triple integrals. Q. J. Math. Oxford Ser. 10, 266â€“276 (1939)
170. D. Williams, Probability with Martingales. Cambridge Mathematical Textbooks (Cambridge
University Press, Cambridge, 1991)
171. D.B. Wilson, J.G. Propp, How to get an exact sample from a generic Markov chain and sample
a random spanning tree from a directed graph, both within the cover time, in Proceedings
of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms (Atlanta, GA, 1996)
(ACM, New York, 1996), pp. 448â€“457
172. S. Wright, Evolution in Mendelian populations. Genetics 16, 97â€“159 (1931)
173. T. Yamada, S. Watanabe, On the uniqueness of solutions of stochastic differential equations.
J. Math. Kyoto Univ. 11, 155â€“167 (1971)

698
References
174. K. Yosida, Functional Analysis. Classics in Mathematics. (Springer, Berlin, 1995). Reprint of
the sixth edition from 1980
175. O. Zeitouni, Random walks in random environment, in Lectures on Probability Theory and
Statistics. Lecture Notes in Mathematics, vol. 1837 (Springer, Berlin, 2004), pp. 189â€“312

Notation Index
1A
indicator function of the set A
2Î©
set of all subsets of Î©
#A
cardinalityof the set A
Ac
complement Î© \ A of the set A âŠ‚Î©
A âˆ©B
intersection of the sets A and B
A âˆªB
union of the sets A and B
A âŠB
disjoint union of A and B
A âŠ‚B
A is a (not necessarily strict) subset of B
A \ B
difference set
A â–³B
symmetric difference of A and B, 31
A Ã— B
Cartesian product of A and B
A
subset of 2Î©, usually a Ïƒ-algebra
A
B
trace of the class A on B, 10
A âŠ—Aâ€²
product of the Ïƒ-algebras A and Aâ€²,304
B(E)
Borel Ïƒ-algebra on E, 8
Berp
Bernoulli distribution, 46
Î²r,s
Beta distribution with parameters r and s, 49
bn,p
binomial distribution,47, 336
bâˆ’
r,p
negative binomial distribution, 48, 336
C(E), Cb(E), Cc(E)
space of continuous (bounded) functions, and
with compact support, respectively, 276
Cqv
functions with continuous square variation,562
C
set of complex numbers
Caua
Cauchy distribution, 336
Cov[X, Y]
covariance of the random variables X and Y, 114
CPoiÎ½
compound Poisson distribution, 369
Î´x
Dirac distribution, 12
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
699

700
Notation Index
E[X]
expectation (or mean) of the random variable X,
113
E[X; A]
=E[X 1A], 193
E[X|F]
conditional expectation, 195
expÎ¸
exponential distribution, 49,336
F = (Ft)tâˆˆI
ï¬ltration, 215
a.s, a.e.
almost surely and almost everywhere,33
G(x, y)
Greeen function of a Markov chain, 412
Î“Î¸,r
Gamma distribution with scale parameter Î¸ > 0
and shape parameter r > 0, 49, 336
Î³p = bâˆ’
1,p
geometric distribution with parameter p, 47
gcd(M)
greatest common divisor of all m âˆˆM âŠ‚N, 436
H Â·X
discrete stochastic integral of H with respect to
X, 223
I
set of invariant distributions of a Markov chain,
423
iff
if and only if
i.i.d.
independent and identically distributed, 61
Im(z)
imaginary part of z âˆˆC, 327
Î», Î»n
Lebesgue measure, n-dimensional, 27
Lip(E)
space of Lipschitz continuous functions on E,
277
Lp, Lp
Lebesgue spaces of integrable functions, 102,
163, 164
L(X)
distribution of the random variable X
M(E), Mf (E), Mâ‰¤1, M1(E)
set of measures on E, ï¬nite measures on E,
(sub-) probability measures on E, respectively,
18, 276
Mloc,c
space of continuous local martingales, 565
Î¼ âŠ—Î½
product of the measures Î¼ and Î½, 29, 308
Î¼ âˆ—Î½
convolution of the measures Î¼ and Î½, 67, 310
Î¼âŠ—n
nth power of a measure Î¼, 308
Î¼âˆ—n
nth convolution power of a measure Î¼, 67
Î¼ â‰ªÎ½
Î¼ is absolutely continuous with respect to Î½, 176
Î¼ âŠ¥Î½
Î¼ and Î½ are mutually singular, 176
Î¼ â‰ˆÎ½
Î¼ and Î½ are equivalent, 176
Î¼ â‰¤st Î½
Î¼ is stochastically smaller than (or equal to) Î½,
431
N, N0
N = {1, 2, 3, . . .}, N0 = N âˆª{0}
NÎ¼,Ïƒ 2
normal distribution, 49, 336
dÎ¼
@
dÎ½
Radonâ€“Nikodym derivative, 177
Î©
space of elementary events on which P is deï¬ned
P
generic probability measure
P[A|B, P[A|F]
conditional probabilities, 192, 195

Notation Index
701
PX = P â—¦Xâˆ’1
distribution of the random variable X, 45
PoiÎ»
Poisson distribution with parameter Î» â‰¥0, 48,
336
pn(x, y) = p(n)(x, y)
n-step transition probability of a Markov chain,
399
Pn
S,T , Pn
T
see page 562
Ï•X
characteristic function of the random variable X,
336
ÏˆX
generating function of the random variable X,
85
Q
set of rational numbers
R
set of real numbers
R = R âˆª{âˆ’âˆ, +âˆ}
two point compactiï¬cation of the real numbers
Radp
= pÎ´1 + (1 âˆ’p)Î´âˆ’1 Rademacher distribution,
46
Re(z)
real part of z âˆˆC, 327
sign(x)
= 1(0,âˆ)(x) âˆ’1(âˆ’âˆ,0)(x), sign of x âˆˆR, 40
Ïƒ( Â·)
Ïƒ-algebra or ï¬ltration generated by Â·, 6, 36, 215
Ï„ k
x
time of the kth visit of a Markov chain at x, 411
T ( Â·)
tail Ïƒ-algebra, 69
UA
uniform distribution on A, 12, 35, 336
V 1(G), V 2(G)
variation and square variation of G, 561, 562
Var[X]
variance of the random variable X, 113
v-lim
vague limit, 281
w-lim
weak limit, 281
XÏ„
stopped process, 235
âŸ¨XâŸ©
square variation process of X,230, 562, 566, 570
f (t) âˆ¼g(t), t â†’a
: â‡â‡’
limtâ†’a f (t)/g(t) = 1
X âˆ¼Î¼
the random variable X has distribution Î¼,45
x âˆ¨y, x âˆ§y, x+, xâˆ’
maximum, minimum, positive part, negative part
of real numbers, 40
âŒŠxâŒ‹,
âŒˆxâŒ‰
ï¬‚oor and ceiling of x, 38
z
complex conjugate of z âˆˆC, 327
Z
set of integers
D=
equal in distribution, 45
D
âˆ’â†’
nâ†’âˆ
, nâ†’âˆ
â‡’
convergence of distributions, 285
nâ†’âˆ
â‡’
fdd
,
nâ†’âˆ
âˆ’â†’
fdd
convergence of ï¬nite-dimensional distributions,
546
meas
âˆ’â†’,
a.s.
âˆ’â†’,
a.e.
âˆ’â†’
convergence in measure, almost surely, and
almost everywhere, 148

Name Index
B
Banach, Stefan, 1892 (KrakÃ³w, now Poland) â€“
1945 (Lvov, now Ukraine), 171
Bayes, Thomas, 1702 (London) â€“ 1761
(Tunbridge Wells, England), 192
Bernoulli, Jakob, 1654 (Basel, Switzerland) â€“
1705 (Basel), 19
BienaymÃ©, IrÃ©nÃ©e-Jules, 1796 (Paris) â€“ 1878
(Paris), 116
Blackwell, David, 1919 (Centralia, Illinois) â€“
2010 (Berkeley, California), 119
Bochner, Salomon, 1899 (KrakÃ³w, now
Poland) â€“ 1982 (Houston, Texas),
348
Boltzmann, Ludwig, 1844 (Vienna, Austria)
â€“ 1906 (Duino, near Trieste, Italy),
447
Borel, Emile, 1871 (Saint-Affrique, France) â€“
1956 (Paris), 8
Brown, Robert, 1773 (Montrose, Scotland) â€“
1858 (London), 522
C
Cantelli, Francesco Paolo, 1875 (Palermo,
Italy) â€“ 1966 (Rome, Italy), 58
CarathÃ©odory, Constantin, 1873 (Berlin) â€“
1950 (Munich, Germany), 20
Cauchy, Augustin Louis, 1789 (Paris) â€“ 1857
(near Paris), 117
CesÃ ro, Ernesto, 1859 (Naples, Italy) â€“ 1906
(Torre Annunziata, Italy), 70
Chebyshev, Pafnutij Lvovich (QebyxÃ«v,
Pafnuti Lvoviq), 1821
(Okatavo, Russia) â€“ 1894 (Saint
Petersburg), 121
CramÃ©r, Harald, 1893 (Stockholm) â€“ 1985
(Stockholm), 365
Curie, Pierre, 1859 (Paris) â€“ 1906 (Paris), 609
D
DieudonnÃ©, Jean Alexandre 1906 (Lille,
France) â€“ 1992 (Paris), 328
Dirac, Paul Adrien Maurice, 1902 (Bristol,
England) â€“ 1984 (Tallahassee,
Florida), 12
Dirichlet, Lejeune, 1805 (DÃ¼ren, Germany) â€“
1859 (GÃ¶ttingen, Germany), 463
Doob, Joseph Leo, 1910 (Cincinnati, Ohio) â€“
2004 (Urbana, Illinois), 229
Dynkin, Eugene, 1924 (Petrograd, now Saint
Petersburg) â€“ 2014 (Ithaca, New
York), 3
E
Egorov, Dmitrij Fedorovich (Egorov,
Dmitri FÃ«doroviq), 1869
(Moscow) â€“ 1931 (Kazan, Russia),
152
Esseen, Carl-Gustav, 1918 (LinkÃ¶ping,
Sweden) â€“ 2001 (Uppsala, Sweden
?), 363
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
703

704
Name Index
Euler, Leonard, 1707 (Basel, Switzerland) â€“
1783 (Saint Petersburg), 57
F
Fatou, Pierre, 1878 (Lorient, France) â€“ 1929
(Pornichet, France), 104
Feller, William, 1906 (Zagreb, Croatia) â€“ 1970
(New York, New York), 358
Fischer, Ernst, 1875 (Vienna, Austria) â€“ 1954
(Cologne, Germany), 171
Fourier, Jean Baptiste Joseph, 1768 (Auxerre,
France) â€“ 1830 (Paris), 333
FrÃ©chet, Maurice RenÃ©, 1878 (Maligny,
France) â€“ 1973 (Paris), 172
Fubini, Guido, 1879 (Venice, Italy) â€“ 1943
(New York, New York), 309
G
Galton, Francis, 1822 (near Birmingham,
England) â€“ 1911 (Grayshott House,
England), 92
GauÃŸ, Carl-Friedrich, 1777 (Braunschweig,
Germany) â€“ 1855 (GÃ¶ttingen,
Germany), 49
Gibbs, Josiah Willard, 1839 (New Haven,
Connecticut) â€“ 1903 (New Haven,
Connecticut), 450
Green, 412
Green, George, 1793 (Nottingham, England) â€“
1841 (Nottingham), 412
H
HÃ¶lder, Otto Ludwig, 1859 (Stuttgart,
Germany) â€“ 1937 (Leipzig,
Germany), 170
Hahn, Hans, 1879 (Vienna, Austria) â€“ 1934
(Vienna), 181
Helly, Eduard, 1884 (Vienna, Austria) â€“ 1943
(Chicago, Illinois), 293
Hesse, Ludwig Otto, 1814 (KÃ¶nigsberg,
now Kaliningrad, Russia) â€“ 1874
(Munich, Germany), 169
Hewitt, Edwin, 1920 (Everett, Washington) â€“
1999, 265
Hilbert, David, 1862 (KÃ¶nigsberg, now
Kaliningrad, Russia) â€“ 1943
(GÃ¶ttingen, Germany), 172
Hopf, Eberhard, 1902 (Salzburg, Austria) â€“
1983, 498
I
Ionescuâ€“Tulcea, Cassius, 1923 (Bucharest,
Romania), 317
Ising, Ernst, 1900 (Cologne, Germany) â€“ 1988
(Peoria, Illinois), 446
ItÃ´, Kiyosi, 1915 (Hokusei-cho, Japan) â€“ 2008
(Kyoto, Japan), 541
J
Jensen, Johan Ludwig, 1859 (Nakskov,
Denmark) â€“ 1925 (Copenhagen),
168
Jordan, Camille, 1838 (near Lyon, France) â€“
1922 (Paris), 183
K
Kesten, Harry, 1931 (Duisburg, Germany) â€“
2019 (Ithaca, New York), 79
Khinchin, Aleksandr Jakovlevich
(Hinqin, Aleksandr
kovleviq) 1894 (Kondrovo,
Russia) â€“ 1959 (Moscow), 372
Kirchhoff, Gustav Robert, 1824 (KÃ¶nigsberg,
now Kaliningrad, Russia) â€“ 1887
(Berlin), 467
Kolmogorov, Andrej Nikolaevich
(Kolmogorov, Andre
Nikolaeviq), 1903 (Tambow,
Russia) â€“ 1987 (Moscow), 71
L
Laplace, Pierre-Simon, 1749 (Beaumont-
en-Auge, France) â€“ 1827 (Paris),
161
Lebesgue, Henri LÃ©on, 1875 (Beauvais, Oise,
France) â€“ 1941 (Paris), 18
Legendre, Adrien-Marie, 1752 (Paris) â€“ 1833
(Paris), 590
Levi, Beppo, 1875 (Turin, Italy) â€“ 1961
(Rosario, Santa Fe, Argentina), 104
LÃ©vy, Paul Pierre, 1886 (Paris) â€“ 1971 (Paris),
345, 576
Lindeberg, Jarl Waldemar, 1876â€“1932, 357
Lipschitz, Rudolph, 1832 (KÃ¶nigsberg, now
Kaliningrad, Russia) â€“ 1903 (Bonn,
Germany), 277
Lusin, Nikolai Nikolaevich(Lusin,
Nikola Nikolaeviq),
1883 (Irkutsk, Russia) â€“ 1950
(Moscow), 279

Name Index
705
Lyapunov, Aleksandr Mikhajlovich
(Lpunov Aleksandr
Mihaloviq), 1857 (Jaroslavl,
Russia) â€“ 1918 (Odessa, Ukraine),
358
M
Markov, Andrej Andreevich (Markov,
Andre Andreeviq), 1856
(Ryazan, Russia) â€“ 1922 (Petrograd,
now Saint Petersburg), 121
Menshov, Dmitrij Evgenâ€™evich
(Menxov, Dmitri
Evgeneviq), 1892 (Moscow) â€“
1988 (Moscow), 137
Minkowski, Hermann, 1864 (Alexotas,
now Kaunas, Lithuania) â€“ 1909
(GÃ¶ttingen, Germany), 171
N
Neumann, John von, 1903 (Budapest) â€“ 1957
(Washington, D.C.), 177
Nikodym, Otton Marcin, 1889 (Zablotow,
Galicia, Ukraine) â€“ 1974 (Utica,
New York), 177
O
Ohm, Georg Simon, 1789 (Erlangen, Germany)
â€“ 1854 (Munich, Germany), 468
Ornstein, Leonard Salomon, 1880 (Nijmegen,
Netherlands) â€“ 1941 (Utrecht,
Netherlands), 667
P
Paley, Raymond E. A. C., 1907 (Bournemouth,
England) â€“ 1933 (Banff, Alberta,
Canada), 526
Parseval, Marc-Antoine,
1755 (RosiÃ¨res-aux-Salines, France)
â€“ 1836 (Paris), 536
Pascal, Blaise, 1623 (Clermont-Ferrand,
France) â€“ 1662 (Paris), 48
Plancherel, Michel, 1885 (Bussy (Fribourg),
Switzerland) â€“ 1967 (Zurich), 334
Poisson, SimÃ©on Denis, 1781 (Pithiviers,
France) â€“ 1840 (near Paris), 48
PÃ³lya, George, 1887 (Budapest) â€“ 1985 (Palo
Alto, CA), 347
Prohorov, Yurij Vasilâ€™evich (Prohorov,
ri Vasileviq), 1929,
291
R
Rademacher, Hans, 1892 (Hamburg, Germany)
â€“ 1969 (Haverford,
Pennsylvania), 137
Radon, Johann, 1887 (Tetschen, Bohemia) â€“
1956 (Vienna, Austria), 177
Riemann, Georg Friedrich Bernhard, 1826
(Breselenz, Germany) â€“ 1866
(Selasca, Italy), 57
Riesz, Frigyes, 1880 (GyÃ¶r, Hungary) â€“ 1956
(Budapest, Hungary), 171
S
Saks, Stanislav (Saks, Stanislav),
1897 (Kalish, Russia (now Poland))
â€“ 1942 (Warsaw, murdered by the
Gestapo), 256
Savage, Jimmie Leonard, 1917 (Detroit,
Michigan) â€“ 1971 (New Haven,
Connecticut), 265
Schwarz, Hermann Amandus, 1843
(Hermsdorf, Silesia) â€“ 1921
(Berlin), 117
Skorohod, Anatolii Volodymyrovych
(Skorohod, Anatol
Volodimiroviq), 1930
(Nikopo, Ukraine) â€“ 2011 (Lansing,
Michigan), 431
Slutzky, Evgenij Evgenâ€™evich (Slucki,
Evgeni Evgeneviq), 1880
(Novoe, Gouvernement Jaroslavl,
Russia) â€“ 1948 (Moscow), 285
Stieltjes, Thomas Jan, 1856 (Zwolle,
Overijssel, Netherlands) â€“ 1894
(Toulouse, France), 27
Stone, Marshall Harvey, 1903 (New York) â€“
1989 (Madras, India), 328
T
Thomson, William (Lord Kelvin), 1824
(Belfast, Northern Ireland) â€“ 1907
(Largs, Ayrshire, Scotland), 472
U
Uhlenbeck, George Eugene, 1900 (Batavia
(now Jakarta), Indonesia) â€“ 1988
(Boulder, Colorado), 667

706
Name Index
V
Varadhan, S.R. Srinivasa, 1940 (Madras,
India), 603
W
Watson, George Neville, 1886 (Westward Ho,
England) â€“ 1965 (Leamington Spa,
England), 420
Watson, Henry William, 1827 (near London) â€“
1903 (near Coventry, England), 92
WeierstraÃŸ, Karl, 1815 (Ostenfelde,
Westphalia, Germany) â€“ 1897
(Berlin), 328
Weiss, Pierre-Ernest, 1865 (Mulhouse, France)
â€“ 1940 (Lyon, France), 607
Wiener, Norbert, 1894 (Columbia, Missouri) â€“
1964 (Stockholm), 545
Wintner, Aurel Friedrich, 1903 (Budapest) â€“
1958 (Baltimore, Maryland), 583
Wright, Sewall, 1889 (Melrose, Massachusetts)
â€“ 1988 (Madison, Wisconsin), 402
Y
Yule, George Udny, 1871 (Morham, Scotland)
â€“ 1951 (Cambridge, England), 407
Z
Zygmund, Antoni, 1900 (Warsaw) â€“ 1992
(Chicago, Illinois), 526

Subject Index
Symbols
0â€“1 laws
Kolmogorov, 71
0-1 laws
Blumenthal, 526
for invariant events, 508
Hewittâ€“Savage, 265
âˆ…-continuous, 16
A
a.a., see Almost all (a.a.)
Absolutely continuous, 176
Absorbing, 412
Adapted, 215
Additive, 12
a.e., see Almost everywhere (a.e.)
Algebra, 3, 328
Almost all, 33
Almost everywhere, 33
Almost surely, 33
Aperiodic, 436
Approximation theorem for measures, 31
Arbitrage, 227
Arcsine law, 531
Array of random variables, 357
ArzelÃ â€“Ascoli theorem, 547
a.s., see Almost surely (a.s.)
Azumaâ€™s inequality, 222
B
Backwards martingale, 263
Banach space, 171
Bayesâ€™ formula, 192, 202
Benfordâ€™s law, 502
Bernoulli distribution, 46
Bernoulli measure, 31
Bernsteinâ€“Chernov bound, 124
Bernstein polynomial, 124
Berryâ€“Esseen theorem, 363
Bessel process, 677
Beta distribution, 49, 270, 354, 627
moments, 120
BienaymÃ© formula, 116
Binary model, 225
Binary splitting stochastic process, 225
Binomial distribution, 47
Blackâ€“Scholes formula, 228
Blackâ€“Scholes model, 668
Blackwellâ€“Girshick formula, 119
Blumenthalâ€™s 0-1 law, 526
Bochnerâ€™s theorem, 348
Boltzmann distribution, 447, 606
Bond, 73
Bond percolation, 74, 461
Borelâ€“Cantelli lemma, 58
conditional version, 253
Borel measure, 275
Borel space, 208
Borelâ€™s paradox, 211
Borel Ïƒ-algebra, 8
Boundary of a set, 274
Bounded in Lp, 155
Boxâ€“Muller method, 68
Branching process, 92, 254
Brownian bridge, 524, 542, 543, 552, 675
Brownian motion, 325, 522
Â© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Switzerland AG 2020
A. Klenke, Probability Theory, Universitext,
https://doi.org/10.1007/978-3-030-56402-5
707

708
Subject Index
canonical, 545
existence theorem, 523
Karhunenâ€“LoÃ¨ve expansion, 541
LÃ©vy characterization, 651
Paleyâ€“Wiener expansion, 541
reï¬‚ection principle, 530
scaling property, 524
strong Markov property, 529
Brownian sheet, 524, 543
C
CÃ dlÃ g, 532
Call option, 226
Canonical Brownian motion, 545
Canonical measure, 372, 376, 623
Canonical process, 305
CarathÃ©odoryâ€™s theorem, 20
Cauchy distribution, 50, 336, 659
Cauchyâ€“Schwarz inequality, 117
conditional, 202
Centered random variable, 113
Central limit theorem, 357
Berryâ€“Esseen, 363
Lindebergâ€“Feller, 358
multidimensional, 366
CesÃ ro limit, 70
CFP, 367
Chapmanâ€“Kolmogorov equation, 322, 400
Characteristic function, 331, 613
inversion formula, 333
Chebyshev inequality, 121
Chebyshev polynomial, 458
Chernov bound, see Bernsteinâ€“Chernov bound
Chinese restaurant process, 632
Cholesky factorization, 366
Chungâ€“Fuchs theorem, 420, 504
Claim, contingent, 226
Closed, 8
âˆ©-closed, 1
âˆª-closed, 1
\-closed, 1
Closed under complements, 1
Closure of a set, 274
CLT, see Central limit theorem (CLT)
Coloring theorem, 625
Complete measure space, 33
Complete metric, 274
Completion of a measure space, 34
Composition of kernels, 314
Compound Poisson distribution, 369
Concave function, 166
Conditional
distribution, 205
expectation, 195
independence, 266
probability, 192, 195
summation formula, 192
Conductance, 467
Consistent, 319
Content, 12
Contingent claim, 226
Continuity lemma, 160
Continuity lower/ upper, 16
Continuity theorem, LÃ©vyâ€™s, 345
Continuity theorem, Laplace transforms, 349
Continuous mapping theorem, 287
Contraction principle, 603
Convergence
almost everywhere, 148
almost sure, 148
in distribution, 285
of distribution functions, 285
dominated, 158
fast, 150
Lp-, 164
mean, 150
in measure, 148
in probability, 148
vague, 281
weak, 89, 281
Convex function, 166
Convex set, 165
Convolution
densities, 310
discrete distributions, 67
measures on Rn, 67, 310
Convolution semigroup, 325
Coordinate map, 304
Correlated, 114
Countable, 1
Counting measure, 13
Coupling, 75, 76, 430
Coupling from the past, 452
Covariance, 114
Covariance function, 524
Coxâ€“Ingersollâ€“Ross model, 673
Coxâ€“Rossâ€“Rubinstein model, 227
CramÃ©r transform, 591
CramÃ©râ€“Wold device, 365
CramÃ©râ€“Lundberg inequality, 239
Curie temperature, 448, 609

Subject Index
709
Curieâ€“Weiss law, 609
Current ï¬‚ow, 468
Cylinder set, 19, 305
D
de Finettiâ€™s theorem, 267, 300
de Morganâ€™s rule, 2
Dense set, 274
Density, 13, 28, 49, 64, 102, 175
Detailed balance, 465
Diagonal sequence argument, 293
Differentiation lemma, 160
Diffusion process, 646
Dirac measure, 12
Dirichlet distribution, 628
Dirichlet problem, 657
discrete, 463
Dirichletâ€™s principle, 472
Distribution, 45
Bernoulli, 46
Beta, 49, 270, 354, 627
binomial, 47
Boltzmann, 447
Cauchy, 50, 336, 659
compound Poisson, 369
domain of attraction, 387
exponential, 49
Gamma, 49, 354
LÃ©vy measure, 375
GEM, 631, 633
geometric, 47
hypergeometric, 48
multinomial, 68
negative binomial, 48, 88
normal, 49
Pascal, 48, 88
Poisson, 48
Poissonâ€“Dirichlet, 627, 630, 633
Rademacher, 46
stable, 382, 382
t-, 368
two-sided exponential, 336
uniform, 12, 35
Distribution function, 22
empirical, 129
of a random variable, 45
Domain of attraction, 387
Donskerâ€™s theorem, 549
Doob decomposition, 230
Doobâ€™s inequality, 242
Doobâ€™s regularization, 533
Double points, 616
Drift, 646
Dual space, 186
Duality, 682
Dynamical system, 495
Dynkinâ€™s Ï€-Î» theorem, 6
Dynkinâ€™s Î»-system, see Î»-system
E
Edge, 73
Empirical distribution, 268
Empirical distribution function, 129
Energy dissipation, 472
Entrance time, 411
Entropy, 131, 132, 599
dynamical system, 510, 512
Kolmogorovâ€“Sinai, 512
relative, 599
Equivalent martingale measure, 227
Equivalent measures, 176
Ergodic, 495
Ergodic theorem
individual (Birkhoff), 498
Lp (von Neumann), 500
Escape probability, 474
Etemadi
inequality of, 138
Eulerâ€™s prime number formula, 57
Evaluation map, 544
Event, 18, 45
invariant, 80
Exchangeable, 257
Exchangeable Ïƒ-algebra, 260
Expectation, 113
Explosion, 407
Exponential distribution, 49
Extension theorem for measures, 25
F
Factorization lemma, 42
Fatouâ€™s lemma, 104
Feller process, 534
Feller property, 534
strong, 681
Fellerâ€™s branching diffusion, 557, 673, 686
Feller semigroup, 534
Filtration, 215
right continuous, 532
usual conditions, 532
Fischerâ€“Riesz theorem, 171
Flow, 467
Fourier inversion formula, 333
Fourier series, 174
FrÃ©chetâ€“Shohat, theorem of, 355

710
Subject Index
Free energy, 606
Free lunch, 227
Frobenius problem, 437
Fubiniâ€™s theorem, 309
for ItÃ´ integrals, 656
for transition kernels, 315
Functional central limit theorem, 549
Fundamental theorem of calculus, 280
G
Galtonâ€“Watson process, 92
rescaling, 553
Gamblerâ€™s ruin, 237, 456
Gambling strategy, 223
Gamma distribution, 49
LÃ©vy measure, 375
subordinator, 628
GEM distribution, 631, 633
Generated Ïƒ-algebra, 6
generated Ïƒ-algebra, 36
Generating function, 85
Generator, 6, 404
Geometric Brownian motion, 668
Geometric distribution, 47
Gibbs sampler, 450, 451
Graph, 73
Green, 412
Green function, 412, 463
table, 421
Gronwallâ€™s lemma, 669
H
Haar functions, 537
Hahnâ€™s decomposition theorem, 182
Haploid, 402
Harmonic function, 423, 462
Harmonic measure, 658
Hartmanâ€“Wintner theorem, 583
Heat bath algorithm, 450
Hedging strategy, 226
Hellyâ€™s theorem, 293
Helmholtz potential, 606
Hilbertâ€“Schmidt norm, 668
Hilbertâ€“Schmidt operator, 316
Hilbert space, 172
HÃ¶lder-continuous, 516
HÃ¶lderâ€™s inequality, 170
Hopfâ€™s lemma, 498
Hoppe Urne, 633
Hypergeometric distribution, 48
I
Identically distributed, 45
Image measure, 43
Inclusion- exclusion formula, 15
Increasing process, 230
Independence
classes of events, 59
conditional, 266
of events, 55
random variables, 61
Independent and identically distributed (i.i.d.),
61
Independent copy, 430
Independent increments, 613
Indicator function, 5
Indistinguishable, 516
Inequality
Azuma, 222
Bernsteinâ€“Chernov, 124
Cauchyâ€“Schwarz, 117
Chebyshev, 121
Chernov, see Bernsteinâ€“Chernov
Doob, 242
Etemadi, 138
HÃ¶lder, 170
Jensen, 168
Kolmogorov, 135
Markov, see Chebyshev
Minkowski, 171
Young, 170
Inï¬nitely divisible, 367
random measure, 622
Inï¬nitely divisible distribution
stochastic order, 621
Inner product, 172
Inner regularity, 33, 275
Integrable, 98, 113
square, 113
stochastic process, 214
Integral, 95, 96, 98, 99
ItÃ´, 639
Lebesgue, 101, 107
Riemann, 107
stochastic, 541
Stratonovich, 657
Intensity measure, 612
Interior of a set, 274
Invariance principle, 550
Invariant event, 494
Inverse temperature, 606
Inversion formula, 333
Ionescuâ€“Tulceaâ€™s theorem, 317

Subject Index
711
Ising model, 446, 451
Isomorphic, 208
Iterated logarithm
Brownian motion, 573
Hartmanâ€“Wintner, 583
ItÃ´ formula, 649
discrete, 233
multidimensional, 655
pathwise, 649
ItÃ´ integral, 639
Fubiniâ€™s theorem, 656
product rule, 654
ItÃ´ process, 646
J
Jensenâ€™s inequality, 168, 200
Joint density, 64
Joint distribution, 63
Jordan, decomposition theorem, 183
K
Karhunenâ€“LoÃ¨ve expansion of Brownian
motion, 541
Kelvin, see Thomson
Kesten-Stigum theorem, 256
Khinchinâ€™s law of the iterated logarithm, 583
Kirchhoffâ€™s rule, 467
Kolmogorovâ€“Chentsov theorem, 518
Kolmogorovâ€™s 0â€“1 law, 71
Kolmogorovâ€™s criterion for weak relative
compactness, 548
Kolmogorovâ€™s extension theorem, 320
Kolmogorovâ€“Sinai entropy, 512
Kolmogorovâ€“Sinai theorem, 512
Kolmogorovâ€™s inequality, 135
Kolmogorovâ€“Smirnov test, 552
Kolmogorovâ€™s three-series theorem, 362
Kullbackâ€“Leibler information, 599
L
Lack of memory of the exponential
distribution, 195
Î»-system, 3
Laplace operator, 654
Laplace space, 12
Laplace transforms, 161, 331, 554, 613
continuity theorem, 349
Large deviations, 590, 594
Large deviations principle, 594
Lattice distributed, 343
Law of large numbers
speed of convergence, 135
strong, 121, 126, 264
weak, 121
LDP, see Large deviations principle (LDP)
Lebesgueâ€“Borel measure, see Lebesgue
measure
Lebesgue integral, 101
Lebesgue measure, 27, 34
Lebesgueâ€™s convergence theorem, 158
Lebesgueâ€™s decomposition theorem, 177
Lebesgueâ€“Stieltjes integral, 561
Lebesgueâ€“Stieltjes measure, 28
Legendre transform, 590
Level set, 594
LÃ©vy Construction of Brownian motion, 537
LÃ©vyâ€“Khinchin formula, 372, 376
for random measures, 623
LÃ©vy measure, 372, 376
Cauchy distribution, 381
Gamma distribution, 375
general stable distribution, 383
symmetric stable distribution, 382
LÃ©vy metric, 288
LÃ©vyâ€™s continuity theorem, 345
LÃ©vyâ€™s modulus of continuity, 576
Limes inferior, 5
Lindeberg condition, 357
Lindvallâ€™s theorem, 559
Lipschitz continuous, 277
Localising sequence, 565
Locally bounded, 223
Locally compact, 274
Locally ï¬nite, 275
Local martingale, 565
Local time, 232
Logarithmic moment generating function, 590
log-normal distribution, 330
Lower semicontinuous, 594
Lp-bounded, 155
Lp-convergence, 164
Lusin, 279
Lusinâ€™s theorem, 45
LV, 181
Lyapunov condition, 358
M
Markov chain, 392
aperiodic, 436
convergence theorem, 444
coupling, 440
discrete, 399
independent coalescence, 440
invariant distribution, 423

712
Subject Index
invariant measure, 423
irreducible, 414
Monte Carlo method, 446
null recurrent, 412
period of a state, 436
positive recurrent, 412
recurrent, 412
reversible, 465
speed of convergence, 453
transient, 412
weakly irreducible, 414
Markov inequality, 121
conditional, 202
Markov kernel, 204
Markov process, 392
Markov property, 391, 392
strong, 396
Markov semigroup, 322
Martingale, 218
backwards, 263
convergence theorem (L1), 246
convergence theorem (Lp), 247
convergence theorem (a.s.), 245
convergence theorem (backwards), 264
convergence theorems (RCLL), 535
local, 565
square variation, 230
Martingale problem, 678
discrete, 403
well-posed, 680
Martingale representation theorem, 653
Martingale transform, 223
Maximal-ergodic lemma, 498
MCMC, see Markov chain Monte Carlo
method (MCMC)
Mean, 113
Mean ï¬eld, 607
Measurable
Borel, 8
Lebesgue, 34
Î¼-, 23
map, 36
set, 18
Measurable space, 18
isomorphy, 208
Measure, 12
atom-free, 210
Bernoulli, 31
Borel, 275
harmonic, 658
inner regular, 33
invariant, 423
Lebesgue, 27
locally ï¬nite, 275
outer, 22
outer regular, 33
product, 31, 321
Radon, 275
regular, 275
restriction, 34
Ïƒ-ï¬nite, 12
signed, 181
stationary, 423
Measure extension theorem, 20
Measure-preserving map, 495
Measure space, 18
Mellin transform, 334
Mesh size, 562
Method of moments, 351
Metric
complete, 274
convergence in measure, 149
LÃ©vy, 288
on C([0, âˆ)), 544
Prohorov, 282
Wasserstein, 430
Metrizable, 274
Metropolis algorithm, 446
Minkowskiâ€™s inequality, 171
Mixing, 507
Modiï¬cation, 515
Modulus of continuity, LÃ©vyâ€™s, 576
Moments, 113
absolute, 113
Monotone, 11
Monotonicity principle of Rayleigh, 470
Monte Carlo simulation, 129
Moran Gamma subordinator, 628
Moran model, 403
Morse code, 134
Moving average, 215, 494
Multinomial coefï¬cient, 69
Multinomial distribution, 68
Multi-period binomial model, 227
N
Negative binomial distribution, 48, 88
stochastic order, 627
Normal distribution, 49
multidimensional, 49, 365
Null array, 357
Null recurrent, 412
Null set, 33
O
Ohmâ€™s rule, 468
Open, 8

Subject Index
713
Optional sampling theorem, 234, 239
continuous time, 522
Optional stopping theorem, 235
continuous time, 522
Ornsteinâ€“Uhlenbeck process, 667
Orthogonal complement, 172
Orthogonal polynomials, 459
Outer measure, 22
Outer regularity, 33, 275
P
Paley Wiener expansion of Brownian motion,
541
Paley-Zygmund inequality, 120
Parsevalâ€™s equation, 536
Partially continuous, 345
Partition function, 606
Partition sequence, admissible, 562
Partition sum, 447
Pascal distribution, 48
Path, 517
Pathwise unique, 678
p.d.f., see Probability distribution function
(p.d.f)
Percolation, 73, 461
Perfect sampling, 452
Period, 436
Petersburg game, 105, 215, 224
p.g.f., see Probability generating function
(p.g.f.)
Phase transition, 448, 607
Ï€-Î» theorem, 6
Ï€-system, see âˆ©-closed
Plancherelâ€™s equation, 334
Points of discontinuity, 11
Poisson approximation, 90
Poissonâ€“Dirichlet distribution, 630, 633
Poisson distribution, 48
compound, 369
Poisson point process, 614
Poisson process, 140, 393
Poisson summation formula, 532
Polarization formula, 563
Polar set, 662
Polish space, 209, 275
PÃ³lyaâ€™s theorem, 347
PÃ³lyaâ€™s theorem on random walks, 416
PÃ³lyaâ€™s urn model, 269, 321, 627
generalized, 408, 411
Portemanteau theorem, 283
Positive recurrent, 412
Positive semideï¬nite, 347
Potential, 468
PPP, see Poisson point process (PPP)
Predictable, 215, 638
Preï¬x code, 131
Premeasure, 12
Previsible, 215, 638
Probability distribution function, 28
Probability generating function, 85
Probability measure, 12
Probability space, 18
Probability vector, 13
Product measurable, 638
Product measure, 29, 31, 308, 319, 321
Product-Ïƒ-algebra, 304
Product space, 304
Product topology, 304
Progressively measurable, 638
Prohorov metric, 282, 444
Prohorovâ€™s theorem, 291
Projective limit, 320
Propp-Wilson algorithm, 452
Q
Q-matrix, 404
Q-Q-plot, 363
Quadratic covariation process, 570
R
Rademacher distribution, 46
Radon measure, 275
Radonâ€“Nikodym derivative, 177
Random measure, 612
Random variable, 45
Random walk, 393
Chungâ€“Fuchs theorem, 504
Green function (table), 421
on a graph, 466
PÃ³lyaâ€™s theorem, 416
random environment, 490
range, 503
recurrence, 415
symmetric simple, 214
Random walk in a random environment, 490
Rate function, 588, 594
Rayleighâ€™s monotonicity principle, 470
RCLL, 532
Rectangle, 9
Rectangular cylinder, 306
Recurrent, 412
Reï¬‚ection principle, 397
Brownian motion, 530
Regular conditional distribution, 205
Regularity of measures, 33, 275

714
Subject Index
Rejection sampling, 211
Relatively compact, 274
Replicable, 226
Resistance, 467
Resistance metric, 481
Restriction, 10
Reversible, 446, 465
Riemann integral, 107
Riemann zeta function, 57
Ring, 3
Risk-neutral, 227
S
Schauder functions, 538
SDE, see Stochastic differential equation
(SDE)
Semi-inner product, 172
Semiring, 3
Separable, 274
Separating family, 277
Separating points, 328
Shannonâ€™s theorem, 130
Shift, 496
Ïƒ-additive, 12
Ïƒ-algebra, 1
exchangeable, 260
invariant, 494
of Ï„-past, 217
product, 304
tail, 69, 260
Ïƒ-compact, 274
Ïƒ-ï¬eld, see Ïƒ-algebra
Ïƒ-ring, 3
Ïƒ-subadditive, 12
Signed measure, 181
Simple function, 41
Simple random walk, 466
Singular, 176
Site percolation, 74
Size-biased distribution, 300
Skorohod coupling, 431
Skorohodâ€™s embedding theorem, 577
Slowly varying, 387
Slutzkyâ€™s theorem, 285
Source coding theorem, 133
Spectral gap, 454
Spin, 447
Square integrable, 113
Square variation, 562
Square variation process, 230, 566
Stable distribution, 347, 382, 382
Standard deviation, 114
Stationary, 493
Step function, 107
Stirlingâ€™s formula, 351, 589
Stochastic differential equation, 665
pathwise uniqueness, 678
strong solution, 666
strong solution under Lipschitz conditions,
669
weak solution, 675
Stochastic integral, 541
discrete, 223
Stochastic kernel, 204
composition, 314
consistent family, 322
product, 313
semigroup, 322
Stochastic matrix, 400
Stochastic order, 431
inï¬nitely divisible distribution, 621
negative binomial distribution, 627
Stochastic process, 213
adapted, 215
binary splitting, 225
duality, 682
explosion, 407
Galtonâ€“Watson, 92, 254
Gaussian, 214, 524
independent increments, 214
indistinguishable, 516
integrable, 214
Markov property, 391
modiï¬cation, 515
path, 517
Poisson, 393
predictable, 215, 638
previsible, see Predictable
product measurable, 638
progressively measurable, 638
stationary, 214
stationary increments, 214
stopped, 235
strong Markov property, 396
version, 515
Stochastically larger, 431
Stoneâ€“WeierstraÃŸ theorem, 328
Stopped process, 235
Stopping time, 216
Strassenâ€™s theorem, 432
Stratonovich integral, 657

Subject Index
715
Strong Markov property, 396
Strong solution, 666
Studentâ€™s t-distribution, 368
Sub-probability measures, 276
Subadditive, 12
sequence, 513
Subharmonic, 423
Submartingale, 218
Subordinator, 622
Supermartingale, 218
Symmetric difference, 31
Symmetric simple random walk, 214
T
Tail Ïƒ-algebra, 69, 260
t-distribution, 368
Theorem
approximation of measures, 31
ArzelÃ â€“Ascoli, 547
Bayesâ€™ formula, 192
Beppo Levi, 104
Berryâ€“Esseen, 363
Bochner, 348
Borelâ€“Cantelli lemma, 58
conditional version, 253
CarathÃ©odory, 20, 25
central limit theorem, 357
Choquet-Deny, 443
Chungâ€“Fuchs, 420, 504
coloring, 625
continuity theorem for Laplace transforms,
349
continuous mapping, 287
CramÃ©r, 590, 597
dominated convergence, 158
Donsker, 550
Dynkinâ€™s Ï€-Î», 6
Egorov, 152
ergodic
Birkhoff, 498
von Neumann, 500
Etemadi, 126
extension to measures, 25
factorization lemma, 42
Fatouâ€™s lemma, 104
de Finetti, 267, 300
Fischerâ€“Riesz, 171
FrÃ©chetâ€“Shohat, 355
Fubini, 309
Fubini for ItÃ´ integrals, 656
Fubini for transition kernels, 315
fundamental theorem of calculus, 280
Glivenkoâ€“Cantelli, 129
Hahn decomposition, 182
Hartmanâ€“Wintner, 583
Helly, 293
Hewittâ€“Savage, 265
Ionescuâ€“Tulcea, 317
iterated logarithm, 574, 583
Jordan decomposition, 183
Kantorovichâ€“Rubinstein, 430
Kesten-Stigum, 256
Kolmogorovâ€“Chentsov, 518
Kolmogorovâ€™s criterion for weak relative
compactness, 548
Kolmogorovâ€™s extension, 320
Kolmogorovâ€“Sinai, 512
Kolmogorovâ€™s inequality, 135
Kolmogorovâ€™s three-series theorem, 362
large deviations, 590
Lebesgue decomposition, 177
LÃ©vyâ€“Khinchin, 372, 376
LÃ©vyâ€™s continuity theorem, 345
Lindebergâ€“Feller, 358
Lindvall, 559
Lusin, 45, 279
Markov chain convergence, 444
martingale representation theorem, 653
measure extension, 20
method of moments, 351
monotone convergence, 104
optional sampling, 234, 239
optional sampling, continuous time, 522
optional stopping, 235
optional stopping, continuous time, 522
Ï€-Î», 6
Paleyâ€“Wienerâ€“Zygmund, 526
Poisson approximation, 90
PÃ³lya, 347
PÃ³lyaâ€™s for random walks, 416
Portemanteau, 283
Prohorov, 291
Rademacherâ€“Menshov, 137
Radonâ€“Nikodym, 177, 251
Rayleighâ€™s monotonicity principle, 470
regular conditional distribution, 205, 209
RÃ©nyi, 617
Sanov, 600
Shannon, 130
Skorohod coupling, 431
Skorohod embedding, 577
Slutzky, 285
Solomon, 491
source coding, 133
Stoneâ€“WeierstraÃŸ, 328
Strassen, 432
Stroockâ€“Varadhan, 681

716
Subject Index
Thomsonâ€™s principle, 472
three-series, 362
Varadhanâ€™s lemma, 603
Yamadaâ€“Watanabe, 672
Thomsonâ€™s principle, 472
Three-series theorem, 362
Tight, 290
Topological space, 8
Topology, 8
vague, 282
weak, 282
Totally bounded, 275
Totally continuous, 179
Total variation norm, 184
Tower property, 196
Trace, 10
Transformation formula, 43
Transient, 412
Transition kernel, 204, 392
Transition matrix, 399
Transition probabilities, 392
Translation invariant, 401
Trap, 462
Two-stage experiment, 303
U
Uncorrelated, 114
Uniform distribution, 12, 35
Uniformly equicontinuous, 344
Uniformly integrable, 153
Unit ï¬‚ow, 472
Unit network, 467
Upcrossing, 244
Usual conditions, 532
V
Vague convergence, 281
Vague topology, 282
Varadhanâ€™s lemma, 603
Variance, 114
Variation, 561
p -, 562
square, 562
Version, 515
Vitali set, 9
Voter model, 249
W
Waldâ€™s identity, 115
Wasserstein metric, 430
Watson integral, 420
Weak convergence, 281
Weak solution, 675
Weak topology, 282
WeierstraÃŸâ€™s approximation theorem, 123
Weight function, 13
Weiss ferromagnet, 607
White noise, 541
Wiener process, 545
Wrightâ€“Fisher diffusion, 683
interacting, 687
Wrightâ€™s evolution model, 402
Y
Youngâ€™s inequality, 170

