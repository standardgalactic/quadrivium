
A First Course in
Chaotic Dynamical
Systems

Advances in Applied Mathemacs
Series Editor: Daniel Zwillinger
Stochasc Paral Diﬀerenal Equaons, Second Edion 
Pao-Liu Chow
CRC Standard Mathemacal Tables and Formulas, 32nd Edion
Dan Zwillinger 
Advanced Engineering Mathemacs with MATLAB, Third Edion 
Dean G. Duﬀy
Markov Processes
James R. Kirkwood
Linear and Integer Opmizaon: 
Theory and Pracce, Third Edion
Gerard Sierksma and Yori Zwols
Introducon to Financial Mathemacs 
Kevin J. Hasngs
Fast Solvers for Mesh-Based Computaons 
Maciej Paszynski
Dynamical Systems for Biological Modeling: 
An Introducon
Fred Brauer and Christopher Kribs
CRC Standard Curves and Surfaces with Mathematica®, Third Edion
David H. von Seggern
Handbook of Peridynamic Modeling 
Floriin Bobaru, John T. Foster, Philippe H. Geubelle, and Stewart A. Silling
Linear and Complex Analysis for Applicaons
John P. D’Angelo
Quadrac Programming with Computer Programs 
Michael J. Best
Green’s Funcons with Applicaons, Second Edion 
Dean G. Duﬀy
Introducon to Radar Analysis, Second Edion 
Bassem R. Mahafza 
The Second-Order Adjoint Sensivity Analysis Methodology  
Dan Gabriel Cacuci 
Green's Funcons with Applicaons, Second Edion 
Dean G. Duﬀy
Operaons Research: A Praccal Introducon, Second Edion
Michael Carter, Camille C. Price, and Ghaith Rabadi
Handbook of Mellin Transforms
Yu. A. Brychkov, O.I. Marichev, and N.V. Savischenko
hps://www.crcpress.com/Advances-in-Applied-Mathemacs/book-series/CRCADVAPPMTH?
page=1&order=pubdate&size=24&view=list&status=published,forthcoming

A First Course in
Chaotic Dynamical
Systems
Theory and Experiment
Second Edition
Robert L. Devaney

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
c⃝2020 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed on acid-free paper
International Standard Book Number-13: 978-0-367-23599-4 (Hardback)
This book contains information obtained from authentic and highly regarded sources. Rea-
sonable eﬀorts have been made to publish reliable data and information, but the author
and publisher cannot assume responsibility for the validity of all materials or the conse-
quences of their use. The authors and publishers have attempted to trace the copyright
holders of all material reproduced in this publication and apologize to copyright holders if
permission to publish in this form has not been obtained. If any copyright material has not
been acknowledged please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted,
reproduced, transmitted, or utilized in any form by any electronic, mechanical, or other
means, now known or hereafter invented, including photocopying, microﬁlming, and record-
ing, or in any information storage or retrieval system, without written permission from the
publishers.
For permission to photocopy or use material electronically from this work, please access
www.copyright.com (http://www.copyright.com/) or contact the Copyright Clearance Cen-
ter, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-
for-proﬁt organization that provides licenses and registration for a variety of users. For
organizations that have been granted a photocopy license by the CCC, a separate system
of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trade-
marks, and are used only for identiﬁcation and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

Contents
Preface to the Second Edition
ix
1
A Visual and Historical Tour
1
1.1
Images from Dynamical Systems
. . . . . . . . . . . . . . . .
1
1.2
A Brief History of Dynamics
. . . . . . . . . . . . . . . . . .
4
2
Examples of Dynamical Systems
17
2.1
An Example from Finance
. . . . . . . . . . . . . . . . . . .
17
2.2
An Example from Ecology
. . . . . . . . . . . . . . . . . . .
18
2.3
Finding Roots and Solving Equations
. . . . . . . . . . . . .
20
2.4
Diﬀerential Equations
. . . . . . . . . . . . . . . . . . . . . .
22
3
Orbits
25
3.1
Iteration
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
3.2
Orbits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
3.3
Types of Orbits
. . . . . . . . . . . . . . . . . . . . . . . . .
27
3.4
Other Orbits
. . . . . . . . . . . . . . . . . . . . . . . . . . .
30
3.5
The Doubling Function
. . . . . . . . . . . . . . . . . . . . .
31
3.6
Experiment: The Computer May Lie
. . . . . . . . . . . . .
33
4
Graphical Analysis
37
4.1
Graphical Analysis . . . . . . . . . . . . . . . . . . . . . . . .
37
4.2
Orbit Analysis
. . . . . . . . . . . . . . . . . . . . . . . . . .
39
4.3
The Phase Portrait
. . . . . . . . . . . . . . . . . . . . . . .
41
5
Fixed and Periodic Points
45
5.1
A Fixed Point Theorem . . . . . . . . . . . . . . . . . . . . .
45
5.2
Attraction and Repulsion
. . . . . . . . . . . . . . . . . . . .
46
5.3
Calculus of Fixed Points
. . . . . . . . . . . . . . . . . . . .
47
5.4
Why Is This True? . . . . . . . . . . . . . . . . . . . . . . . .
50
5.5
Periodic Points . . . . . . . . . . . . . . . . . . . . . . . . . .
55
5.6
Experiment: Rates of Convergence . . . . . . . . . . . . . . .
57
6
Bifurcations
61
6.1
Dynamics of the Quadratic Map
. . . . . . . . . . . . . . . .
61
6.2
The Saddle-Node Bifurcation . . . . . . . . . . . . . . . . . .
65
v

vi
Contents
6.3
The Period-Doubling Bifurcation . . . . . . . . . . . . . . . .
69
6.4
Experiment: The Transition to Chaos
. . . . . . . . . . . . .
73
7
The Quadratic Family
79
7.1
The Case c = −2 . . . . . . . . . . . . . . . . . . . . . . . . .
79
7.2
The Case c < –2 . . . . . . . . . . . . . . . . . . . . . . . . .
81
7.3
The Cantor Middle-Thirds Set
. . . . . . . . . . . . . . . . .
85
8
Transition to Chaos
91
8.1
The Orbit Diagram
. . . . . . . . . . . . . . . . . . . . . . .
91
8.2
The Period-Doubling Route to Chaos
. . . . . . . . . . . . .
96
8.3
Experiment: Windows in the Orbit Diagram
. . . . . . . . .
97
9
Symbolic Dynamics
105
9.1
Itineraries
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
9.2
The Sequence Space
. . . . . . . . . . . . . . . . . . . . . . .
106
9.3
The Shift Map
. . . . . . . . . . . . . . . . . . . . . . . . . .
111
9.4
Conjugacy
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
10 Chaos
121
10.1 Three Properties of a Chaotic System
. . . . . . . . . . . . .
121
10.2 Other Chaotic Systems
. . . . . . . . . . . . . . . . . . . . .
127
10.3 Manifestations of Chaos . . . . . . . . . . . . . . . . . . . . .
132
10.4 Experiment: Feigenbaum’s Constant . . . . . . . . . . . . . .
134
11 Sharkovsky’s Theorem
139
11.1 Period 3 Implies Chaos
. . . . . . . . . . . . . . . . . . . . .
139
11.2 Sharkovsky’s Theorem . . . . . . . . . . . . . . . . . . . . . .
142
11.3 The Period-3 Window . . . . . . . . . . . . . . . . . . . . . .
147
11.4 Subshifts of Finite Type . . . . . . . . . . . . . . . . . . . . .
151
12 Role of the Critical Point
159
12.1 The Schwarzian Derivative
. . . . . . . . . . . . . . . . . . .
159
12.2 Critical Points and Basins of Attraction . . . . . . . . . . . .
162
13 Newton’s Method
169
13.1 Basic Properties
. . . . . . . . . . . . . . . . . . . . . . . . .
169
13.2 Convergence and Nonconvergence
. . . . . . . . . . . . . . .
173
14 Fractals
181
14.1 The Chaos Game
. . . . . . . . . . . . . . . . . . . . . . . .
181
14.2 The Cantor Set Revisited
. . . . . . . . . . . . . . . . . . . .
183
14.3 The Sierpinski Triangle
. . . . . . . . . . . . . . . . . . . . .
184
14.4 The Sierpinski Carpet . . . . . . . . . . . . . . . . . . . . . .
186
14.5 The Koch Snowﬂake . . . . . . . . . . . . . . . . . . . . . . .
190
14.6 Topological Dimension
. . . . . . . . . . . . . . . . . . . . .
192

Contents
vii
14.7
Fractal Dimension
. . . . . . . . . . . . . . . . . . . . . . .
194
14.8
Iterated Function Systems
. . . . . . . . . . . . . . . . . . .
197
14.9
Experiment: Find the Iterated Function Systems
. . . . . .
204
14.10 Experiment: A “Real” Chaos Game . . . . . . . . . . . . . .
205
15 Complex Functions
211
15.1 Complex Arithmetic . . . . . . . . . . . . . . . . . . . . . . .
211
15.2 Complex Square Roots
. . . . . . . . . . . . . . . . . . . . .
215
15.3 Linear Complex Functions
. . . . . . . . . . . . . . . . . . .
218
15.4 Calculus of Complex Functions . . . . . . . . . . . . . . . . .
220
16 The Julia Set
229
16.1 The Squaring Function
. . . . . . . . . . . . . . . . . . . . .
229
16.2 Another Chaotic Quadratic Function
. . . . . . . . . . . . .
233
16.3 Cantor Sets Again
. . . . . . . . . . . . . . . . . . . . . . . .
235
16.4 Computing the Filled Julia Set . . . . . . . . . . . . . . . . .
240
16.5 Experiment: Filled Julia Sets and Critical Orbits . . . . . . .
245
16.6 The Julia Set as a Repeller
. . . . . . . . . . . . . . . . . . .
246
17 The Mandelbrot Set
251
17.1 The Fundamental Dichotomy . . . . . . . . . . . . . . . . . .
251
17.2 The Mandelbrot Set
. . . . . . . . . . . . . . . . . . . . . . .
254
17.3 Complex Bifurcations
. . . . . . . . . . . . . . . . . . . . . .
257
17.4 Experiment: Periods of the Bulbs
. . . . . . . . . . . . . . .
263
17.5 Experiment: Periods of the Other Bulbs . . . . . . . . . . . .
265
17.6 Experiment: How to Add
. . . . . . . . . . . . . . . . . . . .
266
17.7 Experiment: Find the Julia Set . . . . . . . . . . . . . . . . .
267
17.8 Experiment: Similarity of the Mandelbrot Set and Julia Sets
269
18 Other Complex Dynamical Systems
281
18.1 Cubic Polynomials . . . . . . . . . . . . . . . . . . . . . . . .
281
18.2 Rational Maps
. . . . . . . . . . . . . . . . . . . . . . . . . .
283
18.3 Exponential Functions . . . . . . . . . . . . . . . . . . . . . .
291
18.4 Trigonometric Functions
. . . . . . . . . . . . . . . . . . . .
298
18.5 Complex Newton’s Method
. . . . . . . . . . . . . . . . . . .
300
A Mathematical Preliminaries
305
A.1 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
305
A.2 Some Ideas from Calculus . . . . . . . . . . . . . . . . . . . .
308
A.3 Open and Closed Sets . . . . . . . . . . . . . . . . . . . . . .
309
A.4 Other Topological Concepts
. . . . . . . . . . . . . . . . . .
311
Bibliography
313
Index
317


Preface to the Second Edition
In the twenty-ﬁve years since the original version of this book was published,
much has happened in the area of mathematics known as dynamical systems.
For example, the beautiful mathematical objects known as the Mandelbrot
and Julia sets were barely ten years old when the ﬁrst edition appeared, and
most of the research involving these objects back then centered around itera-
tion of quadratic functions. Nowadays, this research has expanded to include
all sorts of diﬀerent types of functions, including higher-degree polynomials,
rational maps, exponential and trigonometric functions, and many others. As
a consequence, several new sections in this edition are devoted to these topics.
One major change in the mathematics community since the previous edi-
tion appeared has been the inclusion of undergraduate students in mathemat-
ical research projects. Over the last ﬁfteen years, I have co-authored seven
research papers on dynamical systems with undergraduates who had taken
my course using this book. In addition, some of my Ph.D. students have also
collaborated with several undergrads on research projects related to their the-
ses. The fact is that the area of dynamical systems covered in this book is
quite accessible to students and also oﬀers a wide variety of interesting open
questions for students at the undergraduate level to pursue.
The beauty of this subject is that the only prerequisite for students is a one-
year calculus course (no diﬀerential equations required). For the most part in
this book, we concentrate on iteration of real or complex quadratic functions
of the form x2 + c. So, with only a calculus background and a familiarity
with complex numbers, students can easily be exposed to many interesting
areas of current research in this area of mathematics. I also ﬁnd that this
course serves as a natural precursor to advanced courses in topology or real
and complex analysis. For example, to understand iteration of the quadratic
map, students see why abstract metric spaces (such as the sequence space)
and the ϵδ-deﬁnition of continuity (necessary to analyze the shift map on the
sequence space) are crucial to analyzing the behavior of the quadratic maps. It
would seem that studying the dynamics of a quadratic function on the real line
would be much easier than moving to its analog in an abstract metric space,
but that is by no means the case, as we show in Chapter 9. Several students
who had already taken a course in real analysis have told me that, now that
they have taken the dynamics course, they see why these more theoretical
topics are so important. So this course can serve as a bridge between the low-
level, often non-rigorous calculus courses, and the more demanding higher-
level mathematics courses.
ix

x
Preface to the Second Edition
Many of the activities students engage in while using this book involve
using the computer to investigate various concepts in dynamical systems.
There is an abundance of software available (like MATLAB and Mathematica)
to assist in these endeavors. In addition, there are plenty of other programs
available on the web that deal with speciﬁc topics covered in this course.
My website math.bu.edu/DYSYS contains a variety of applets designed by
Yakov Shapiro that many of my students have used while using this book.
Also, there are a number of computer animations available at the website
math.bu.edu/DYSYS/animations.html that show how Julia sets, the Man-
delbrot set, and fractals evolve as parameters change.
Acknowledgments
It is a pleasure to acknowledge the invaluable assistance of Ed Packel,
Bruce Peckham, Mark Snavely, Michèle Taylor, and Benjamin Wells, all of
whom read and made many ﬁne comments about this manuscript. I am
particularly indebted to Tom Scavo for his many suggestions regarding the
manuscript and the software that accompanied the ﬁrst edition of the book.
Many of the color plates in this book were produced at Boston University using
programs developed by Paul Blanchard, Yakov Shapiro, Scott Sutherland, and
Gert Vegter. Thanks are also due to Stefen Fangmeier, Chris Mayberry, Chris
Small, Sherry Smith, and Craig Upson for help producing the graphics in this
book. I especially thank my editor, Bob Ross, for convincing the new pub-
lisher of this book, Taylor & Francis, CRC Press, to allow me to produce this
new edition. Kiℓℓer Devaney veriﬁed the mathematical accuracy of the entire
text; all errors that remain are due to her1. Finally, I must thank my dear
friends Vincenzo, Gaetano, Wolfgang, Gioacchino, Richard S., Giuseppe, and
Richard W. for providing me with many hours of wonderful music while this
book was taking shape.
1If you have questions, you can email Kiℓℓer at killer@dogmail.com, though she rarely
responds to emails; rather, she prefers to simply bark back over voicemail!

1
A Visual and Historical Tour
Rather than jump immediately into the mathematics of dynamical systems,
we will begin with a brief tour of some of the amazing computer graphics
images that arise in this ﬁeld. One of our goals in this book is to explain what
these images mean, how they are generated on the computer, and why they
are important in mathematics. We will do none of the mathematics in this
chapter. For now, you should simply enjoy the images. We hope to convince
you, in the succeeding chapters, that the mathematics behind these images
is even prettier than the pictures. In the second part of the chapter, we will
present a brief history of some of the developments in dynamical systems over
the past century. You will see that many of the ideas in dynamics arose fairly
recently. Indeed, none of the computer graphics images from the tour were
seen before 1980!
1.1
Images from Dynamical Systems
This book deals with some very interesting, exciting, and beautiful topics
in mathematics—topics which, in many cases, have been discovered only in
the last ﬁfty years. The main subject of the book is dynamical systems, the
branch of mathematics that attempts to understand processes in motion. Such
processes occur in all branches of science. For example, the motion of the
planets and the galaxies in the heavens is a dynamical system, one that has
been studied for centuries by thousands of mathematicians and scientists.
The stock market is another system that changes in time, as does the earth’s
weather. The changes chemicals undergo, the rise and fall of populations, and
the motion of a simple pendulum are classical examples of dynamical systems
in chemistry, biology, and physics. Clearly, dynamical systems abound.
What does a scientist wish to do with a dynamical system? Well, since the
system is moving or changing in time, the scientist would like to predict where
the system is heading, where it will ultimately go. Will the stock market go
up or down? Will it be rainy or sunny tomorrow? Will these two chemicals
explode if they are mixed in a test tube?
Clearly, some dynamical systems are predictable, whereas others are not.
You know that the sun will rise tomorrow and that, when you add cream to
1

2
A Visual and Historical Tour
a cup of coﬀee, the resulting “chemical” reaction will not be an explosion.
On the other hand, predicting the weather a month from now or the Dow
Jones average a week from now seems impossible. You might argue that the
reason for this unpredictability is that there are simply too many variables
present in meteorological or economic systems. That is indeed true in these
cases, but this is by no means the complete answer. One of the remarkable
discoveries of twentieth-century mathematics is that very simple systems, even
systems depending on only one variable, may behave just as unpredictably as
the stock market, just as wildly as a turbulent waterfall, and just as violently
as a hurricane. The culprit, the reason for this unpredictable behavior, has
been called “chaos” by mathematicians.
Because chaos has been found to occur in the simplest of systems, scientists
may now begin to study unpredictability in its most basic form. It is to be
hoped that the study of these simpler systems will eventually allow scientists
to ﬁnd the key to understanding the turbulent behavior of systems involving
many variables such as weather or economic systems.
In this book we discuss chaos in these simple settings. We will see that
chaos occurs in elementary mathematical objects—objects as familiar as
quadratic functions—when they are regarded as dynamical systems. You
may feel at this point that you know all there is to know about quadratic
functions—after all, they are easy to evaluate and to graph. You can diﬀer-
entiate and integrate them. But the key words here are “dynamical systems.”
We will treat simple mathematical operations like taking the square root,
squaring, or cubing as dynamical systems by repeating the procedure over
and over, using the output of the previous operation as the input for the
next. This process is called iteration. This procedure generates a list of real
or complex numbers that are changing as we proceed—this is our dynamical
system. Sometimes we will ﬁnd that, when we input certain numbers into the
process, the resulting behavior is completely predictable, while other inputs
yield results that are often bizarre and totally unpredictable.
For the types of functions we will consider, the set of numbers that yield
chaotic or unpredictable behavior in the plane is called the Julia set after
the French mathematician Gaston Julia, who ﬁrst formulated many of the
properties of these sets in the 1920’s. These Julia sets are spectacularly com-
plicated, even for quadratic functions. They are examples of fractals. These
are sets which, when magniﬁed over and over again, always resemble the orig-
inal image. The closer you look at a fractal, the more you see exactly the same
object. Moreover, fractals naturally have a dimension that is not an integer,
not 1, not 2, but often somewhere in between, such as dimension 1.4176, what-
ever that means! We will discuss these concepts in more detail in Chapter 14.
Here are some examples of the types of images that we will study. In Plate
1 we show the Julia set of the simple mathematical expression z2 + c, where
both z and c are complex numbers. In this particular case, c = −.122 + .745i.
This image is called Douady’s rabbit, after the French mathematician Adrien
Douady whose work we will discuss in Chapter 17. The black region in this

Images from Dynamical Systems
3
image resembles a “fractal rabbit.” Everywhere you look, you see a pair of
ears. In the accompanying ﬁgures, we have magniﬁed portions of the rabbit,
revealing more and more pairs of ears.
As we will describe later, the black points you see in these pictures are
the “non-chaotic” points. They are points representing values of z that, under
iteration of this quadratic function, eventually tend to cycle between three
diﬀerent points in the plane. As a consequence, the dynamical behavior in the
black regions is quite predictable. All of this is by no means apparent right
now, but by the time you have read Chapter 16, you will consider this example
a good friend. Points that are colored in this picture also behave predictably:
they are points that “escape,” that is, they tend to inﬁnity under iteration.
The colors here simply tell us how quickly a point escapes, i.e., go beyond a
pre-determined bound. Red points escape fastest, followed in order by orange,
yellow, green, blue, and violet points. The boundary between these two types
of behavior—the interface between the escaping and the cycling points—is the
Julia set. This is where we will encounter all of the chaotic behavior for this
dynamical system.
In Plates 2–5, we have displayed Julia sets for other quadratic functions
of the form z2 + c. Each picture corresponds to a diﬀerent value of c. For
example, Plate 5a is a picture of the Julia set for z2 + i. As we see, these
Julia sets may assume a remarkable variety of shapes. Sometimes the images
contain large black regions as in the case of Douady’s rabbit. Other times the
Julia set looks like an isolated scatter of points, as in Plate 5b. Many of these
Julia sets are Cantor sets. These are very complicated sets that arise often in
the study of dynamics. We will begin our study of Cantor sets in Chapter 7
when we introduce the most basic fractal of all, the Cantor middle-thirds set.
All of the Julia sets in Plates 1–5 correspond to mathematical expressions
that are of the form z2 + c. As we see, when c varies, these Julia sets change
considerably in shape. How do we understand the totality of all of these shapes,
the collection of all possible Julia sets for quadratic functions? The answer is
called the Mandelbrot set. The Mandelbrot set, as we will see in Chapter 17, is
a dictionary, or picture book, of all possible quadratic Julia sets. It is a picture
in the c-plane that provides us with a road map of the quadratic Julia sets.
This image, ﬁrst viewed in 1980 by Benoit Mandelbrot, is quite important in
dynamics. It completely characterizes the Julia sets of quadratic functions.
It has been called one of the most intricate and beautiful objects in all of
mathematics. Amazingly, we still do not completely understand the structure
of this set. That is, we still do not fully understand the dynamics of the simple
quadratic function z2 + c !
Plate 6 shows the full Mandelbrot set. Note that it consists of a basic
central cardioid shape, with smaller bulbs or decorations attached. Plates 7–
11 are magniﬁcations of some of these decorations. Note how each decoration
diﬀers from the others. Buried deep in various regions of the Mandelbrot set,
we also see small black regions which are actually small copies of the entire
set. Look at the “tail” of the Mandelbrot set in Plate 7. The Mandelbrot

4
A Visual and Historical Tour
set possesses an amazing amount of complexity, as illustrated in Plate 11
and its magniﬁcations. Nonetheless, each of these small regions has a distinct
dynamical meaning, as we will discuss in Chapter 17.
In this book we will also investigate the chaotic behavior of many other
functions. For example, in Plates 12 and 13 we have displayed the Julia set for
several functions of the form c sin(z) and c cos(z). Plate 15 displays the Julia
sets for certain rational functions of the form zn+c/zn. These sets are what are
known as “Sierpinski curves,” probably the most interesting planar fractals,
as we shall discuss in Chapter 14. If we investigate exponential functions of
the form c exp(z), we ﬁnd Julia sets that look quite diﬀerent as, for example,
in Plate 16. And we can also look at the parameter planes (the c-planes) for
these maps, a portion of which is shown in Plate 17.
In addition, we have referenced a number of online videos posted on
my website that will allow you to see the dramatic changes these sys-
tems undergo as parameters vary. All of these videos are available at
math.bu.edu/DYSYS/animations.html.
The images in this mathematical tour show quite clearly the great beauty
of mathematical dynamical systems theory. But what do these pictures mean
and why are they important? These are questions that we will address in the
remainder of this book.
1.2
A Brief History of Dynamics
Dynamical systems has a long and distinguished history as a branch of math-
ematics. Beginning with the fundamental work of Isaac Newton, diﬀerential
equations became the principal mathematical technique for describing pro-
cesses that evolve continuously in time. In the eighteenth and nineteenth cen-
turies, mathematicians devised numerous techniques for solving diﬀerential
equations explicitly. These methods included Laplace transforms, power series
solutions, variation of parameters, linear algebraic methods, and many other
techniques familiar from a basic undergraduate course in ordinary diﬀerential
equations.
There was one major ﬂaw in this development. Virtually all of the analytic
techniques for solving diﬀerential equations worked mainly for linear diﬀeren-
tial equations. Nonlinear diﬀerential equations proved much more diﬃcult to
solve. Unfortunately, many of the most important processes in nature are
inherently nonlinear.
An example of this is provided by Newton’s original motivation for devel-
oping calculus and diﬀerential equations. Newton’s laws enable us to write
down the equations that describe the motion of the planets in the solar sys-
tem, among many other important physical phenomena. Known as the n-body
problem, these laws give us a system of diﬀerential equations whose solutions

A Brief History of Dynamics
5
describe the motion of n “point masses” moving in space subject only to
their own mutual gravitational attraction. If we know the initial positions and
velocities of these masses, then all we have to do is solve Newton’s diﬀerential
equation to be able to predict where and how these masses will move in the
future.
This turns out to be a formidable task. If there are only one or two point
masses, then these equations may be solved explicitly, as is often done in a
freshman or sophomore calculus or physics class. For three or more masses, the
problem today remains completely unsolved, despite the eﬀorts of countless
mathematicians over the past three centuries. It is true that numerical solu-
tions of diﬀerential equations by computers have allowed us to approximate
the behavior of the actual solutions in many cases, but there are still regimes
in the n-body problem where the solutions are so complicated or chaotic that
they defy even numerical computation.
Although the explicit solution of nonlinear ordinary diﬀerential equations
has proved elusive, there have been four landmark events over the past 130
years that have revolutionized the way we study dynamical systems. Per-
haps the most important event occurred in 1890. King Oscar II of Sweden
announced a prize for the ﬁrst mathematician who could solve the n-body
problem and thereby prove the stability of the solar system. Needless to say,
nobody solved the original problem, but the great French mathematician Henri
Poincaré came closest. In a beautiful and far-reaching paper, Poincaré totally
revamped the way we tackle nonlinear ordinary diﬀerential equations. Instead
of searching for explicit solutions of these equations, Poincaré advocated work-
ing qualitatively, using topological and geometric techniques, to uncover the
global structure of all solutions. To him, a knowledge of all possible behaviors
of the system under investigation was much more important than the rather
specialized study of individual solutions.
Poincaré’s prize-winning paper contained a major new insight into the
behavior of solutions of diﬀerential equations. In describing these solutions,
mathematicians had previously made the tacit assumption that what we now
know as stable and unstable manifolds always match up. Poincaré questioned
this assumption. He worked long and hard to show that this was always the
case, but he could not produce a proof. He eventually concluded that the
stable and unstable manifolds might not match up and could actually cross
at an angle. When he ﬁnally admitted this possibility, Poincaré saw that this
would cause solutions to behave in a much more complicated fashion than
anyone had previously imagined. Poincaré had discovered what we now call
chaos. Years later, after many attempts to understand the chaotic behavior
of diﬀerential equations, he threw up his hands in defeat and wondered if
anyone would ever understand the complexity he was ﬁnding. Thus, “chaos
theory,” as it is now called, really dates back over 130 years to the work of
Henri Poincaré.
Poincaré’s achievements in mathematics went well beyond the ﬁeld of
dynamical systems. His advocacy of topological and geometric techniques

6
A Visual and Historical Tour
opened up whole new subjects in mathematics. In fact, building on his ideas,
mathematicians turned their attention away from dynamical systems and
toward these related ﬁelds in the ensuing decades. Areas of mathematics such
as algebraic and diﬀerential topology were born and ﬂourished in the twenti-
eth century. But nobody could handle the chaotic behavior that Poincaré had
observed, so the study of dynamics languished.
There were two notable exceptions to this. One was the work of the French
mathematicians Pierre Fatou and Gaston Julia in the 1920’s on the dynamics
of complex analytic maps. They too saw chaotic behavior, this time on what
we now call the Julia set. Indeed, they realized how tremendously intricate
these Julia sets could be, but they had no computer graphics available to see
these sets, and as a consequence, this work also stopped in the 1930’s.
A little later, the American mathematician G. D. Birkhoﬀadopted
Poincaré’s qualitative point of view on dynamics. He advocated the study of
iterative processes as a simpler way of understanding the dynamical behavior
of diﬀerential equations, a viewpoint that we will adopt in this book.
The second major development in dynamical systems occurred in the
1960’s. The American mathematician Stephen Smale reconsidered Poincaré’s
crossing stable and unstable manifolds from the point of view of iteration and
showed by an example now called the “Smale horseshoe” that the chaotic
behavior that baﬄed his predecessors could indeed be understood and ana-
lyzed completely. The technique he used to analyze this is called symbolic
dynamics and will be a major tool for us in this book. At the same time, the
American meteorologist E. N. Lorenz, using a very crude computer, discov-
ered that very simple diﬀerential equations could exhibit the type of chaos
that Poincaré observed. Lorenz, who actually had been a Ph.D. student of
Birkhoﬀ’s, went on to observe that his simple meteorological model (now
called the Lorenz system) exhibited what is called sensitive dependence on
initial conditions. For him, this meant that long-range weather forecasting
was all but impossible and showed that the mathematical topic of chaos was
important in all other areas of science.
Then the third major development occurred in 1975 when T. Y. Li and
James Yorke published an amazing paper called Period Three Implies Chaos
[23]. In this paper, they showed that, if a simple continuous function on the
real line has a point which cycles with period 3 under iteration, then this func-
tion must also have cycles of all other periods. Moreover, they also showed
that this function must behave chaotically on some subset of the line. Per-
haps most importantly, this paper was essentially the ﬁrst time the word
“chaos” was used in the scientiﬁc literature, and this motivated a huge num-
ber of mathematicians, scientists, and engineers to begin investigating this
phenomenon.
Curiously, the Li-Yorke result was preceded by a research paper that had
much more substantial results. In a 1964 paper [30], Oleksandr Sharkovsky
determined that, if such a map on the real line had a cycle of period n,
then he could list exactly all of the other periods that such a map must

A Brief History of Dynamics
7
have. Unfortunately, this paper was published in Ukranian and hence was
not known at all in the west. However, after the Li-Yorke paper appeared,
this result became one of the most interesting in modern dynamical systems
theory. All of these results are described in Chapter 11.
These advances led to a tremendous ﬂurry of activity in nonlinear dynamics
in all areas of science and engineering in the ensuing decade. For example, the
ecologist Robert May found that very simple iterative processes that arise in
mathematical biology could produce incredibly complex and chaotic behavior.
The physicist Mitchell Feigenbaum, building on Smale’s earlier work, noticed
that, despite the complexity of chaotic behavior, there was some semblance
of order in the way systems became chaotic. Physicists Harry Swinney and
Jerry Gollub showed that these mathematical developments could actually be
observed in physical applications, notably in turbulent ﬂuid ﬂow. Later, other
systems, such as the motion of the former planet Pluto or the beat of the
human heart, have been shown to exhibit similar chaotic patterns. In mathe-
matics, meanwhile, new techniques were developed to help understand chaos.
John Guckenheimer and Robert F. Williams employed the theory of strange
attractors to explain the phenomenon that Lorenz had observed a decade
earlier. And tools such as the Schwarzian derivative, symbolic dynamics, and
bifurcation theory—all topics we will discuss in this book—were shown to play
an important role in understanding the behavior of dynamical systems.
The fourth and most recent major development in dynamical systems was
the availability of high-speed computing and, in particular, computer graphics.
Foremost among the computer-generated results was Mandelbrot’s discovery
in 1980 of what is now called the Mandelbrot set. This beautiful image imme-
diately reawakened interest in the old work of Julia and Fatou. Using the
computer images as a guide, mathematicians such as Bodil Branner, Adrien
Douady, John Hubbard, Dennis Sullivan, as well as Fields Medalists John Mil-
nor, Bill Thurston, Curt McMullen, Artur Avila, and Jean-Christophe Yoccoz
jumped into the ﬁeld and greatly advanced the classical theory. Other com-
puter graphics images such as the orbit diagram and the Lorenz attractor
also generated considerable interest among mathematicians and led to further
advances.
One of the most interesting side eﬀects of the availability of high speed com-
puting and computer graphics has been the development of an experimental
component in the study of dynamical systems. Whereas the old masters in the
ﬁeld had to rely solely on their imagination and their intellect, now mathe-
maticians have an invaluable additional resource to investigate dynamics: the
computer. This tool has opened up whole new vistas for dynamicists, some of
which we will sample in this book. In a series of sections called “Experiments,”
you will have a chance to uncover some of these wonderful facts yourself.

8
A Visual and Historical Tour
Plate 1: Douady’s rabbit Julia set and several magniﬁcations.
Plate 2: Dancing rabbits Julia set.

A Brief History of Dynamics
9
Plate 3: A dragon and the basilica Julia set.
Plate 4: Three and four-eared rabbit Julia sets.
Plate 5: A dendrite and a Cantor set Julia set.

10
A Visual and Historical Tour
Plate 6: The Mandelbrot set.
Plate 7: The tail of the Mandelbrot set.

A Brief History of Dynamics
11
Plate 8: A period 3 and 7 bulb in the Mandelbrot set.
Plate 9: A period 17 bulb and a magniﬁcation.
Plate 10: Another period 17 bulb and a magniﬁcation.

12
A Visual and Historical Tour
Plate 11: Another region in the Mandelbrot set.

A Brief History of Dynamics
13
Plate 12: Julia sets of (1 + 0.2i) sin(z) and (.61 + .81i) sin(z).
Plate 13: The Julia set of 2.95 cos(z).

14
A Visual and Historical Tour
Plate 14: Complex Newton’s method for z3 −1.
Plate 15: Sierpinski curve Julia sets for z3 + (−0.25 + .03i)/z3 and z2 −.004/z2.

A Brief History of Dynamics
15
Plate 16: The Julia sets of 0.36 exp(z) and 0.38 exp(z) exhibiting a major
“bifurcation.”
Plate 17: The parameter plane for λ exp(z).


2
Examples of Dynamical Systems
Our goal in this book is to describe the beautiful mathematical subject known
as dynamical systems theory. We will, for the most part, concentrate on the
mathematics itself rather than the applications of the subject. However, for
motivation, we will brieﬂy describe in this chapter four diﬀerent examples of
dynamical systems that arise in practice.
2.1
An Example from Finance
Consider the following situation. Suppose we deposit $1000 in a bank at 10
percent interest. (Wow, I wish I could ﬁnd a bank that oﬀered this interest
rate! Oh well....). We ask the question: if we leave this money untouched for n
years, how much money will we have in our account at the end of this period?
For simplicity, we assume that the 10 percent interest is added to our account
once each year at the end of the year.
This is one of the simplest examples of an iterative process or dynamical
system. Let’s denote the amount we have in the bank at the end of the nth
year by An. Our problem is to determine An for some given number of years
n. We know that A0, our initial deposit, is $1000. After 1 year we add 10
percent to this amount to get our new balance. That is,
A1 = A0 + 0.1A0 = 1.1A0.
In our speciﬁc case, A1 = $1100. At the end of the second year, we perform
the same operation
A2 = A1 + 0.1A1 = 1.1A1,
so that A2 = $1210. Continuing,
A3
=
1.1A2
A4
=
1.1A3
...
An
=
1.1An−1.
17

18
Examples of Dynamical Systems
Thus we can recursively determine the amount An once we know the previous
year’s balance.
The equation An = 1.1An−1 is an example of a (ﬁrst-order) diﬀerence
equation. In such an equation, we use information from the previous year (or
other ﬁxed time interval) to determine the current information, then we use
this information to determine next year’s amount, and so forth. As a remark,
in higher-order diﬀerence equations (which we will not discuss in this book),
we would need information from several prior years to determine the current
value.
We solve this diﬀerence equation by the process of iteration. The iterative
process involved is multiplication by 1.1. That is, if we deﬁne the function
F(x) = 1.1x, then our savings balances are determined by repeatedly applying
this
A1
=
F(A0)
A2
=
F(A1)
A3
=
F(A2)
and so forth. Note that we may also write
A2
=
F(F(A0)) = F ◦F(A0)
A3
=
F(F(F(A0))) = F ◦F ◦F(A0)
to clearly indicate that we compose F with itself repeatedly to obtain the
successive balances.
Since F(x) = 1.1x, we have
F(F(x))
=
(1.1)2x
F(F(F(x)))
=
(1.1)3x,
and, in general, the nth iteration of the function yields
F ◦· · · ◦F



n times
(x) = (1.1)nx.
So to ﬁnd An, we merely compute (1.1)n and multiply by A0. For example,
using a calculator or computer, you may easily check that A10 = $2593.74 and
A50 = $117, 390.85.
This example is quite simple: the iterations we will encounter will in general
yield much more complicated results.
2.2
An Example from Ecology
Here is another diﬀerence equation which is essentially the same as our savings
account example. Suppose we wish to predict the behavior of the population of

An Example from Ecology
19
a certain species which grows or declines as generations pass. Let’s denote the
population alive at generation n by Pn. So our question is: can we predict what
will happen to Pn as n gets large? Will Pn tend to zero so that the species
becomes extinct? Or will Pn grow without bound so that we experience a
population explosion?
There are many mathematical models to predict the behavior of popula-
tions. By far the simplest (and most naive) is the exponential growth model.
In this model we assume that the population in the succeeding generation is
directly proportional to the population in the current generation. This trans-
lates into mathematics as another diﬀerence equation
Pn+1 = rPn
where r is some constant determined by ecological conditions. Thus, given
the initial population P0, we can recursively determine the population in the
succeeding generations:
P1
=
rP0
P2
=
rP1 = r2P0
P3
=
rP2 = r3P0
...
Pn
=
rPn−1 = rnP0.
As before, we determine the behavior of the population via iteration. In this
case, the function we iterate is F(x) = rx. So
Pn = F ◦· · · ◦F



n times
(P0) = rnP0.
Note that the ultimate fate of the population depends on r. If r > 1, then rn
tends to inﬁnity with n, so we have unchecked population growth. If r < 1,
rn tends to zero, so the species becomes extinct. Finally, if r = 1, Pn = P0,
so there is never any change in the population. Thus, we can achieve our
goal of determining the fate of the species for any r. Of course, this simpliﬁed
model is highly unrealistic in that real-life populations behave in a much more
complicated fashion. For example, populations can never tend to inﬁnity. To
remedy this, we will add one assumption to our model that will take into
account the possibility of overcrowding.
Speciﬁcally, we will discuss what ecologists call the logistic model of popu-
lation growth. In this model, we assume at the outset that there is some abso-
lute maximum population that can be supported by the environment. If the
population ever reaches this number, then we have disastrous overcrowding—
food supply becomes critically short—and the species immediately dies out.
To keep the numbers manageable, let’s assume that Pn now represents the
fraction of this maximal population alive at generation n, so that 0 ≤Pn ≤1.

20
Examples of Dynamical Systems
The logistic model is then
Pn+1 = λPn(1 −Pn).
As before, λ is a constant that depends on ecological conditions. For reasons
that will become apparent later, we will always assume that 0 < λ ≤4.
Note that, in the absence of the 1−Pn factor, we are left with the previous
exponential growth model. If Pn = 0 (no individuals present), then Pn+1 = 0
as well, as we would expect. If Pn = 1, then Pn+1 = 0 as we have assumed.
Thus, to understand the growth and decline of the population under this
model, we must iterate the logistic function Fλ(x) = λx(1 −x). Unlike the
previous examples, this function is quadratic rather than linear. We will see
that this simple change gives rise to a very rich mathematical theory. Indeed,
the behavior of this function under iteration was ﬁnally understood in the
1990’s. We will spend most of this book analyzing the dynamical behavior of
this and other similar functions.
2.3
Finding Roots and Solving Equations
How do you ﬁnd
√
5 exactly? Believe it or not, the simplest method dates
back to the time of the Babylonians and involves a simple iteration. We will
make an initial guess x0 for
√
5. We assume that x0 is positive. Now, chances
are that x0 ̸=
√
5, so we will use this guess to produce a new and better guess
x1.
Here is the procedure. If x0 ̸=
√
5, then we either have x0 <
√
5 or x0 >
√
5.
In the former case, we have
√
5x0 < 5
√
5 < 5
x0
for x0 ̸= 0. On the other hand, if x0 >
√
5, then
√
5 > 5
x0
.
Thus we have either
x0 <
√
5 < 5
x0
or
5
x0
<
√
5 < x0.
So
√
5 is somewhere between x0 and 5/x0. Thus, if we take the average of x0
and 5/x0, namely
x1 = 1
2

x0 + 5
x0

,

Finding Roots and Solving Equations
21
the resulting value will lie midway between x0 and 5/x0 and so will, hopefully,
be a better approximation to
√
5. So we use this value as our next “guess” for
√
5. Continuing, we form the successive averages
x2
=
1
2

x1 + 5
x1

x3
=
1
2

x2 + 5
x2

...
Intuitively, the sequence of numbers x0, x1, x2, . . . should eventually approach
√
5.
Let’s see how this works in practice. Suppose we make the (somewhat silly)
initial guess x0 = 1 for
√
5. Then we have
x1
=
1
2 (1 + 5) = 3
x2
=
1
2

3 + 5
3

= 7
3 = 2.333 . . .
x3
=
1
2(7
3 + 15
7 ) = 47
21 = 2.238095 . . .
x4
=
2.236068 . . .
x5
=
2.236067 . . .
x6
=
2.236067 . . . ,
and we see that, very quickly, this sequence tends to the correct answer, as
√
5 = 2.236067 . . . .
Clearly, to ﬁnd other square roots, we need only replace the 5 in the formula
for our initial guess. Thus, to “ﬁnd”
√
9, we choose some initial guess, say
x0 = 2, and then
x1
=
1
2

2 + 9
2

= 3.25
x2
=
1
2

x1 + 9
x1

= 3.0096 . . .
x3
=
3.000015 . . .
x4
=
3.000000 . . .
x5
=
3.000000 . . . ,
and we see that this sequence quickly converges to
√
9 = 3. Wow! Did you
know that
√
9 is equal to 3?
A related question that arises in all branches of science and mathematics
is: How do you solve the equation F(x) = 0? For example, ﬁnding the square
root of 5 is the same as solving the equation x2 −5 = 0. There are very few

22
Examples of Dynamical Systems
functions for which it is possible to write down the solutions to this equation
explicitly. Even for polynomials, solving this equation is diﬃcult when the
degree is greater than 2, and generally impossible when the degree is 5 or
greater. Yet the problem is extremely important, so we seek other possible
methods.
One method, familiar from calculus, is Newton’s method. This method
involves the following procedure. Given a function F whose roots we are trying
to ﬁnd, we construct a new function, the Newton iteration function, given by
N(x) = x −F(x)
F ′(x).
Then we make an initial guess x0 for a root. Newton’s method is to iterate
the function N, successively computing
x1
=
N(x0)
x2
=
N(x1) = N(N(x0))
x3
=
N(x2) = N(N(N(x0)))
and so forth. Often, though by no means always, this sequence of iterates
converges to a root of F. Note that, in the special case where F(x) = x2 −5
(whose roots are ±
√
5), the Newton iteration is simply
N(x) = x −x2 −5
2x
= 1
2

x + 5
x

,
as was discussed above.
We will not take the time now to discuss why this happens or even where
the Newton iteration function comes from. Rather, we will devote all of Chap-
ter 13 to this subject.
With the advent of accessible high-speed computation, iterative algorithms
such as Newton’s method are now an extremely important and widespread
area of interest in mathematics. No longer are such algorithms primarily of
theoretical interest!
2.4
Diﬀerential Equations
Diﬀerential equations are also examples of dynamical systems. Unlike iterative
processes where time is measured in discrete intervals such as years or gen-
erations, diﬀerential equations are examples of continuous dynamical systems
wherein time is a continuous variable. Ever since the time of Newton, these
types of systems have been of paramount importance.
Recently, however, discrete dynamical systems have also received consid-
erable attention. This does not mean that continuous systems have declined

Diﬀerential Equations
23
in importance. Rather, mathematicians study discrete systems with an eye
toward applying their results to the more diﬃcult continuous case.
There are a number of ways that iterative processes enter the arena of
diﬀerential equations. For example, a solution of a diﬀerential equation is
a continuous function of time. If we look at this solution at discrete time
intervals, say at times t = 0, 1, 2, . . ., then we are really considering an iterative
process as described above.
Most often, diﬀerential equations are impossible to solve explicitly. We
must turn to the computer to generate numerical solutions. The numerical
methods used to solve these equations are often iterative processes such as
the Runge-Kutta method.
FIGURE 2.1
A surface of section.
A ﬁnal way in which iteration arises in the study of diﬀerential equations
occurs when a surface of section can be found. Suppose that we have a system
of diﬀerential equations in three dimensions whose independent variable is
time. Then the solutions we seek are curves in space parameterized by time.
Often, though not always, these curves intersect a given surface in space over
and over again as depicted in Figure 2.1. When this occurs, the study of
solutions of the equation reduces to the study of an iterative process on the
surface. Starting with any point on the surface x0, we follow the solution
through x0 until it ﬁrst reintersects the surface. Call this point of ﬁrst return
F(x0). The function F is called a ﬁrst return map and the surface is a surface
of section. Continuing to follow the solution curve, its next point of intersection
is F(F(x0)), so we see that determining the successive points of intersection
is really a problem of iterating F.
Iteration of the ﬁrst return map does not tell us all there is to know about
the solutions of the diﬀerential equation, but it does give us a lot of qualitative
information. In particular, we do not know the exact location of a solution
at each moment of time, but we do gain long-term information about the
behavior of the solution.


3
Orbits
As we saw in the previous chapter, there are many kinds of problems in science
and mathematics that involve iteration. Iteration means to repeat a process
over and over. In dynamics, the process that is repeated is the application of
a function.
In this and the next ten chapters we will consider only functions of one
real variable as encountered in elementary calculus. We will spend quite a bit
of time discussing the quadratic functions Qc(x) = x2 + c where c ∈R (a real
number) is a constant. Other functions that will arise often are the logistic
functions Fλ(x) = λx(1 −x), the exponentials Eλ(x) = λex, and the sine
functions Sμ(x) = μ sin x. Here, λ and μ are constants. The constants c, μ,
and λ are called parameters. One of the important questions we will address
later is how the dynamics of these functions change as these parameters are
varied. In the ﬁnal chapters, we will turn our attention to functions deﬁned
in the complex plane.
3.1
Iteration
As mentioned earlier, to iterate a function means to evaluate the function over
and over, using the output of the previous application as the input for the next.
This is the same process as typing a number into a calculator, then repeatedly
striking one of the function keys such as “sin” or “cos.” Mathematically, this
is the process of repeatedly composing the function with itself.
We write this as follows. For a function F, F 2(x) is the second iterate of
F, namely F(F(x)), F 3(x) is the third iterate F(F(F(x))), and, in general,
F n(x) is the n-fold composition of F with itself. For example, if F(x) = x2+1,
then
F 2(x) = (x2 + 1)2 + 1
F 3(x) = ((x2 + 1)2 + 1)2 + 1.
Similarly, if F(x) = √x, then
F 2(x) =
√x
25

26
Orbits
F 3(x) =
	√x.
It is important to realize that F n(x) does not mean raise F(x) to the nth
power (an operation we will never use). Rather, F n(x) is the nth iterate of F
evaluated at x.
3.2
Orbits
Given x0 ∈R, we deﬁne the orbit of x0 under F to be the sequence of points
x0, x1 = F(x0), x2 = F 2(x0), . . . , xn = F n(x0), . . .. The point x0 is called the
seed of the orbit.
For example, if F(x) = √x and x0 = 256, the ﬁrst few points on the orbit
of x0 are
x0
=
256
x1
=
√
256 = 16
x2
=
√
16 = 4
x3
=
√
4 = 2
x4
=
√
2 = 1.41 . . . .
As another example, if S(x) = sin x (where x is given in radians, not
degrees), the orbit of x0 = 123 is
x0
=
123
x1
=
−0.4599 . . .
x2
=
−0.4438 . . .
...
x300
=
−0.0975 . . .
x301
=
−0.0974 . . .
...
Slowly, ever so slowly, the points on this orbit tend to 0.

Types of Orbits
27
If C(x) = cos x, then the orbit of x0 = 123 is
x0
=
123
x1
=
−0.8879 . . .
x2
=
0.6309 . . .
...
x50
=
0.739085
x51
=
0.739085
x52
=
0.739085
...
After only a few iterations, this orbit seems to stop at 0.739085 . . ..
3.3
Types of Orbits
There are many diﬀerent kinds of orbits in a typical dynamical system.
Undoubtedly the most important kind of orbit is a ﬁxed point. A ﬁxed point
is a point x0 that satisﬁes F(x0) = x0. Note that F 2(x0) = F(F(x0)) =
F(x0) = x0 and, in general, F n(x0) = x0. So the orbit of a ﬁxed point is
the constant sequence x0, x0, x0, . . .. A ﬁxed point never moves. As its name
implies, it is ﬁxed by the function. For example, 0, 1, and −1 are all ﬁxed
points for F(x) = x3, while only 0 and 1 are ﬁxed points for F(x) = x2. Fixed
points are found by solving the equation
F(x) = x.
Thus, F(x) = x2 −x −4 has ﬁxed points at the solutions of
x2 −x −4 = x,
which are 1 ±
√
5, as determined by the quadratic formula. (Remember to
bring the right-hand x to the other side!)
Fixed points may also be found geometrically by examining the intersection
of the graph with the diagonal line y = x. For example, Figure 3.1 shows that
the only ﬁxed point of S(x) = sin x is x0 = 0, since that is the only point of
intersection of the graph of S with the diagonal y = x. Similarly, C(x) = cos x
has a ﬁxed point at 0.739085 . . ., as shown in Figure 3.2.
Another important kind of orbit is the periodic orbit or cycle. The point
x0 is periodic if F n(x0) = x0 for some n > 0. The least such n is called the
prime period of the orbit. Note that if x0 is periodic with prime period n, then
the orbit of x0 is just a repeating sequence of numbers
x0, F(x0), . . . , F n−1(x0), x0, F(x0), . . . , F n−1(x0), . . . .

28
Orbits
FIGURE 3.1
The ﬁxed point of S(x) = sin x is 0.
For example, 0 lies on a cycle of prime period 2 for F(x) = x2 −1, since
F(0) = −1 and F(−1) = 0. Thus the orbit of 0 is simply
0, −1, 0, −1, 0, −1, . . . .
We also say that 0 and −1 form a 2-cycle. Similarly, 0 lies on a periodic orbit of
prime period 3 or a 3-cycle for F(x) = −3
2x2+ 5
2x+1, since F(0) = 1, F(1) = 2,
and F(2) = 0. So the orbit is
0, 1, 2, 0, 1, 2, . . . .
We will see much later that the appearance of this seemingly harmless 3-cycle
has surprising implications for the dynamics of this function.
In general, it is very diﬃcult to ﬁnd periodic points exactly. For example,
to ﬁnd cycles of period 5 for F(x) = x2 −2, we would have to solve the
equation
F 5(x) −x = 0.
This is a polynomial equation of degree 25 = 32. Polynomial equations of
such high degree are usually impossible to solve exactly. More generally, to
ﬁnd cycles of period n for this function, we would have to solve a polynomial
equation of degree 2n, clearly an impossible task.
Note that if x0 has prime period k, then x0 is also ﬁxed by F 2k. Indeed
F 2k(x0) = F k(F k(x0)) = F k(x0) = x0. Similarly, x0 is ﬁxed by F nk, so we
say that x0 has period nk for any positive integer n. We reserve the word
prime period for the case n = 1.

Types of Orbits
29
FIGURE 3.2
The ﬁxed point of C(x) = cos x is 0.739085 . . ..
Also, if x0 lies on a periodic orbit of period k, then all points on the orbit
of x0 have period k as well. Indeed, the orbit of x1 is
x1, x2, . . . , xk−1, x0, x1, . . . , xk−1, x0, x1 . . . ,
which has period k.
A point x0 is called eventually ﬁxed or eventually periodic if x0 itself is
not ﬁxed or periodic, but some point on the orbit of x0 is ﬁxed or periodic.
For example, −1 is eventually ﬁxed for F(x) = x2, since F(−1) = 1, which
is ﬁxed. Similarly, 1 is eventually periodic for F(x) = x2 −1 since F(1) = 0,
which lies on a cycle of period 2. The point
√
2 is also eventually periodic for
this function, since the orbit is
√
2, 1, 0, −1, 0, −1, 0, −1, . . . .
In a typical dynamical system, most orbits are not ﬁxed or periodic. For
example, for the linear function T(x) = 2x, only 0 is a ﬁxed point. All other
orbits of T get larger and larger (in absolute value) under iteration since
T n(x0) = 2nx0. Indeed, if x0 ̸= 0, |T n(x0)| tends to inﬁnity as n approaches
inﬁnity. We denote this by
|T n(x0)| →∞.
The situation is reversed for the linear function L(x) = 1
2x. For L, only 0
is ﬁxed, but for any x0 ̸= 0,
Ln(x0) = x0
2n .

30
Orbits
Since the sequence 1/2n tends to zero, we have
Ln(x0) →0.
We say that the orbit of x0 converges to the ﬁxed point 0.
As another example, consider the squaring function F(x) = x2. If |x0| < 1,
it is easy to check that F n(x0) →0. For example, if x0 = 0.1, then the orbit
of x0 is
0.1, 0.01, 0.0001, . . . , 10−2n, . . . ,
which clearly tends to zero.
This example points out one danger in using a computer or calculator
to iterate functions. If we input 0.1 into a calculator and then press the “x2”
key repeatedly, we are computing the orbit of 0.1 under the squaring function.
However, after a few iterations, the calculator display will read 0.000 . . .. This,
of course, is false. We know that the nth point on the orbit of 0.1 is 10−2n,
which is non-zero. The calculator, however, can store numbers up to only a
ﬁnite number of decimal places. Hence 10−2n is represented as 0 for large
enough n. We will always have to keep this in mind in later sections when
we compute orbits numerically. You should be forewarned that this is not the
only way that a computer will lie to us!
3.4
Other Orbits
The simple orbits we have discussed so far—ﬁxed, periodic, and eventually
periodic orbits as well as orbits that tend to a speciﬁc limit—might tempt you
to think that dynamical systems typically have very simple behavior. Actually,
nothing could be further from the truth. One of the major discoveries in
mathematics in recent years is that many simple functions—such as quadratic
functions of a real variable—may have many orbits of incredible complexity.
We give here two very simple examples. Consider the quadratic function
F(x) = x2 −2. The orbit of 0 is very simple—it is eventually ﬁxed:
0, −2, 2, 2, 2, . . . .
But consider the orbits of nearby points. In the table in Figure 3.3, we have
listed the ﬁrst few points on the orbits of three nearby points. Notice what
happens: after a very few iterations, these orbits are far from being ﬁxed. In
fact, they seem to wander almost randomly about the interval from −2 to
2. This is our ﬁrst view of chaotic behavior, one of the main subjects of this
book.
Here is another view of one of these orbits. In Figure 3.4 we display a his-
togram of the orbit of 0.1 under x2 −2. To compute this image, we subdivided
the interval −2 ≤x ≤2 into 400 subintervals of equal width 0.01. We then

The Doubling Function
31
FIGURE 3.3
Several orbits of x2 −2.
computed 20,000 points on the orbit of 0.1 and marked oﬀone point over
each subinterval each time the orbit entered that interval. Note how the orbit
has distributed itself not quite evenly over the interval −2 ≤x ≤2. It has,
however, visited each subinterval a substantial number of times. This, too, is
one of the ingredients of chaotic behavior to which we will return later.
3.5
The Doubling Function
Our next example is one to which we will return often in this book—the
doubling function. The domain of this function is the half-open, half-closed
unit interval 0 ≤x < 1, which we denote by [0, 1). The doubling function D

32
Orbits
FIGURE 3.4
A histogram of the orbit of 0.1 under x2 −2.
is deﬁned by
D(x) =

2x
0 ≤x < 1/2
2x −1
1/2 ≤x < 1.
The graph of D is displayed in Figure 3.5. Note that D: [0, 1) →[0, 1).
We may deﬁne D more succinctly as
D(x) = 2x mod 1.
This means that D(x) is the fractional part of 2x. For example, D(0.3) = 0.6,
but D(0.6) = 1.2 −1 = 0.2, and D(0.9) = 0.8.
Note that D has lots of cycles. For example, 0 is a ﬁxed point. The points
1/3 and 2/3 lie on a 2-cycle. The point 1/5 lies on a 4-cycle:
1
5, 2
5, 4
5, 3
5, 1
5, 2
5, . . . .
And 1/9 lies on a 6-cycle:
1
9, 2
9, 4
9, 8
9, 7
9, 5
9, 1
9, . . . .
It turns out that there are many other types of orbits for this function,
including some that are not periodic, eventually periodic, or convergent to a
cycle. Indeed, as we will see later, most orbits are of none of the above types.
However, on a typical computer or calculator we never (well, okay, almost
never) see any of these orbits. This is the content of our ﬁrst experiment.

Experiment: The Computer May Lie
33
FIGURE 3.5
The graph of the doubling function.
3.6
Experiment: The Computer May Lie
Goal: The aim of this experiment is to compute a number of orbits for several
diﬀerent functions and record the results. We will see as we proceed that the
results generated by the computer can often be misleading or just plain wrong!
Procedure: Consider the following three functions.
a.
F(x) = x2 −2.
b.
G(x) = x2 + c for some c < −2 (you choose c).
c.
The doubling function D.
For each of these functions, choose ten diﬀerent initial seeds. For the dou-
bling function, each seed should be in the interval (0, 1). For F(x) = x2 −2,
each should be in the interval (−2, 2). For each chosen seed, compute the ﬁrst
200 points on the corresponding orbit. Record the results by listing the initial
seed together with what happened to the orbit; that is, determine whether
the orbit is ﬁxed, periodic, eventually periodic, or has no visible pattern.
Results: After collecting all your data, write a brief essay summarizing what
you have seen for each function. Given your data, can you make any con-
jectures about the behavior of these functions? For a given function, do all
(or almost all) orbits behave in the same way? Include in your essay your
conjectures and speculations about each function.
Notes and Questions:
1. For the doubling function, you should try certain rational values such as
x0 = 1/5 and x0 = 1/9 whose orbits we already know. Do your results agree
with what we already know? Or does the computer give false results? If so,

34
Orbits
can you explain why this happens? In a further essay, discuss the results of
this experiment together with your theory for why the computer reacted the
way it did.
2. As a hint, consider what would happen if your computer actually stored
numbers in binary form. The computer would not store the entire binary
expansion of a given number; rather, it would truncate this expansion so
that only an approximation to the number is stored. That is, numbers in the
interval 0 ≤x0 < 1 would be stored in the computer as a ﬁnite sum of the
form1
a1
2 + a2
22 + · · · + an
2n .
What happens to such numbers under iteration of the doubling function?
3. If you have access to a program that does exact rational arithmetic, use
this to compute orbits of rational numbers of the form p/q under the doubling
function. What do you now see? Can you make any conjectures about orbits
of rational points?
Exercises
1. Let F(x) = x2. Compute the ﬁrst ﬁve points on the orbit of 1/2.
2. Let F(x) = x2 + 1. Compute the ﬁrst ﬁve points on the orbit of 0.
3. Let F(x) = x2 −2. Compute F 2(x) and F 3(x).
4. Let S(x) = sin(2x). Compute S2(x), S3(x), and S4(x).
5. Let F(x) = x2. Compute F 2(x), F 3(x), and F 4(x). What is the formula for
F n(x)?
6. Let A(x) = |x|. Compute A2(x) and A3(x).
7. Find all real ﬁxed points (if any) for each of the following functions:
a.
F(x) = 3x + 2
b.
F(x) = x2 −2
c.
F(x) = x2 + 1
d.
F(x) = x3 −3x
e.
F(x) = |x|
f.
F(x) = x5
g.
F(x) = x6
h.
F(x) = x sin x
1 In practice, the computer would most likely store the number in ﬂoating point form,
which is a slight variation on this theme.

Experiment: The Computer May Lie
35
8. What are the eventually ﬁxed points for A(x) = |x|?
9. Let F(x) = 1 −x2. Show that 0 lies on a 2-cycle for this function.
10. Consider the function F(x) = |x −2|.
a.
What are the ﬁxed points for F?
b.
If m is an odd integer, what can you say about the orbit of m?
c.
What happens to the orbit if m is even?
11. How many ﬁxed points does the function T(x) = tan(x) have?
12. Does the function F(x) = −x3 have a cycle of prime period 2?
13. For which values of a and b does the linear function L(x) = ax + b have
a cycle of prime period 2?
The following four exercises deal with the doubling function D.
14. For each of the following seeds, discuss the behavior of the resulting orbit
under D.
a.
x0 = 3/10
b.
x0 = 7/10
c.
x0 = 1/8
d.
x0 = 1/16
e.
x0 = 1/7
f.
x0 = 1/14
g.
x0 = 1/11
h.
x0 = 3/22
15. Give an explicit formula for D2(x) and D3(x). Can you write down a
general formula for Dn(x)?
16. Sketch the graph of D2 and D3. What will the graph of Dn look like?
17. Using your answer to exercise 15, ﬁnd all ﬁxed points for D2 and D3. How
many ﬁxed points do D4 and D5 have? What about Dn?
The following ﬁve exercises deal with the function
T(x) =

2x
if0 ≤x ≤1/2
2 −2x
if1/2 < x ≤1.
The function T is called a tent map because of the shape of its graph on the
interval [0, 1].
18. Find a formula for T 2(x).

36
Orbits
19. Sketch the graphs of T and T 2.
20. Find all ﬁxed points for T and T 2.
21. Find an explicit formula for T 3(x) and sketch the graph of T 3.
22. What does the graph of T n look like?

4
Graphical Analysis
In this section we introduce a geometric procedure that will help us under-
stand the dynamics of one-dimensional maps. This procedure, called graphical
analysis, enables us to use the graph of a function to determine the behavior
of orbits in many cases.
4.1
Graphical Analysis
Suppose we have the graph of a function F and wish to display the orbit of
a given point x0. We begin by superimposing the diagonal line y = x on the
graph of F. As we saw in Section 3.3, the points of intersection of the diagonal
with the graph give us the ﬁxed points of F. To ﬁnd the orbit of x0, we begin
at the point (x0, x0) on the diagonal directly above x0 on the x-axis. We ﬁrst
draw a vertical line to the graph of F. When this line meets the graph, we
have reached the point (x0, F(x0)). We then draw a horizontal line from this
point to the diagonal. We reach the diagonal at the point whose y-coordinate
is F(x0), and so the x-coordinate is also F(x0). Thus we reach the diagonal
directly over the point whose x-coordinate is F(x0), the next point on the
orbit of x0.
Now we continue this procedure. Draw a vertical line from (F(x0), F(x0))
on the diagonal to the graph: this yields the point (F(x0), F 2(x0)). Then
a horizontal line to the diagonal reaches the diagonal at (F 2(x0), F 2(x0)),
directly above the next point in the orbit.
To display the orbit of x0 geometrically, we thus continue this procedure:
we ﬁrst draw a vertical line from the diagonal to the graph, then a horizontal
line from the graph back to the diagonal. The resulting “staircase” or “cobweb”
provides an illustrative picture of the orbit of x0.
Figure 4.1 shows a typical application of graphical analysis. This procedure
may be used to describe some of the dynamical behavior we saw in the previous
section. For example, in Figure 4.2 we sketch the graphical analysis of F(x) =
√x. Note that any positive x0 gives a staircase which leads to the point of
intersection of the graph of F with the diagonal. This is, of course, the ﬁxed
point at x = 1.
37

38
Graphical Analysis
FIGURE 4.1
Graphical analysis.
FIGURE 4.2
Graphical analysis of F(x) = √x and C(x) = cos x.

Orbit Analysis
39
In Figure 4.2 we also depict graphical analysis of C(x) = cos x. Note that
any orbit in this case tends again to the point of intersection of the graph of
C with the diagonal. As we observed numerically in the previous section, this
point is given approximately by 0.73908 . . . (in radians).
(a)
(b)
FIGURE 4.3
Graphical analysis of F(x) = x2 −1.1.
As we saw in the previous section, periodic points for F satisfy F n(x0) =
x0. This means that the line segments generated by graphical analysis eventu-
ally return to (x0, x0) on the diagonal, thus yielding a closed “circuit” in the
graphical analysis. Figure 4.3a shows that F(x) = x2 −1.1 admits a 2-cycle as
illustrated by the square generated by graphical analysis. Figure 4.3b shows
that many orbits tend to this cycle. This 2-cycle can be computed explicitly.
See exercise 6 in this chapter.
We cannot decipher the behavior of all orbits by means of graphical anal-
ysis. For example, in Figure 4.4 we have applied graphical analysis to the
quadratic function F(x) = 4x(1 −x). Note how complicated the orbit of x0
is! This is another glimpse of chaotic behavior.
4.2
Orbit Analysis
Graphical analysis sometimes allows us to describe the behavior of all orbits
of a dynamical system. For example, consider the function F(x) = x3. The
graph of F shows that there are three ﬁxed points: at 0, 1, and −1. These are
the solutions of the equation x3 = x, or x3 −x = 0. Graphical analysis then
allows us to read oﬀthe following behavior. If |x0| < 1 then the orbit of x0

40
Graphical Analysis
FIGURE 4.4
Graphical analysis of F(x) = 4x(1 −x).
(a)
(b)
FIGURE 4.5
Orbit analysis of F(x) = x3 for a. |x| < 1, b. |x| > 1.

The Phase Portrait
41
FIGURE 4.6
Phase portrait of F(x) = x3 and F(x) = x2.
tends to zero as depicted in Figure 4.5a. On the other hand, if |x0| > 1, then
the orbit of x0 tends to ±∞, as in Figure 4.5b.
Thus we see that we have accounted for the behavior of the orbits of all
points. When we can do this, we say that we have performed a complete orbit
analysis. While this is not always possible, we will strive in the sequel to
develop techniques that will allow us to understand as many of the orbits of
a dynamical system as possible.
At this juncture, we should emphasize that graphical analysis is by no
means a completely rigorous tool; in most cases we cannot use graphical anal-
ysis as a proof that certain dynamical phenomena occur. However, there is
no question that this procedure is a valuable tool that helps explain what is
going on.
4.3
The Phase Portrait
One succinct method for depicting all orbits of a dynamical system is the
phase portrait of the system. This is a picture on the real line of the orbits.
In the one-dimensional case, the phase portrait gives us no more information
than graphical analysis. In dimension two, however, where graphical analysis
is no longer possible, we will rely solely on the phase portrait to describe the
behavior of orbits.
In the phase portrait, we represent ﬁxed points by solid dots and the
dynamics along orbits by arrows. For example, as we saw above, for F(x) = x3,
the ﬁxed points occur at 0 and ±1. If |x0| < 1, then F n(x0) →0, whereas if
|x0| > 1, F n(x0) →±∞. The phase portrait for this map is shown in Figure
4.6.
As another example, F(x) = x2 has two ﬁxed points, at 0 and 1, and
an eventually ﬁxed point at −1. Note that if x0 < 0, then F(x0) > 0 and

42
Graphical Analysis
all subsequent points on the orbit of x0 are positive. The phase portrait of
F(x) = x2 is also shown in Figure 4.6.
Exercises
1. Use graphical analysis to describe the fate of all orbits for each of the
following functions. Use diﬀerent colors for orbits that behave diﬀerently.
a.
F(x) = 2x
b.
F(x) = 1/3x
c.
F(x) = −2x + 1
d.
F(x) = x2
e.
F(x) = −x3
f.
F(x) = x −x2
g.
S(x) = sin x
2. Use graphical analysis to ﬁnd {x0 | F n(x0) →±∞} for each of the following
functions.
a.
F(x) = 2x(1 −x)
b.
F(x) = x2 + 1
c.
T(x) =

2x
x ≤1/2
2 −2x
x > 1/2
3. Sketch the phase portraits for each of the functions in exercise 1.
4. Perform a complete orbit analysis for each of the following functions.
a.
F(x) = 1
2x −2
b.
A(x) = |x|
c.
F(x) = −x2
d.
F(x) = −x5
e.
F(x) = 1/x
f.
E(x) = ex
5. Let F(x) = |x −2|. Use graphical analysis to display a variety of orbits of
F. Use red to display cycles of period 2, blue for eventually ﬁxed orbits, and
green for orbits that are eventually periodic.
6. Consider F(x) = x2 −1.1. First ﬁnd the ﬁxed points of F. Then use the
fact that these points are also solutions of F 2(x) = x to ﬁnd the cycle of prime
period 2 for F.
7. All of the following exercises deal with dynamics of linear functions of the
form F(x) = ax + b where a and b are constants.

The Phase Portrait
43
a.
Find the ﬁxed points of F(x) = ax + b.
b.
For which values of a and b does F have no ﬁxed points?
c.
For which values of a and b does F have inﬁnitely many ﬁxed points?
d.
For which values of a and b does F have exactly one ﬁxed point?
e.
Suppose F has just one ﬁxed point and 0 < |a| < 1. Using graphical
analysis, what can you say about the behavior of all other orbits of
F? We will call these ﬁxed points attracting ﬁxed points later. Why
do we use this terminology?
f.
What is the behavior of all orbits when a = 0?
g.
Suppose F has just one ﬁxed point and |a| > 1. Using graphical
analysis, what can you say about the behavior of all other orbits of
F in this case? We call such ﬁxed points repelling. Can you explain
why?
h.
Perform a complete orbit analysis for F(x) = x + b in cases b > 0,
b = 0, and b < 0.
i
Perform a complete orbit analysis for F(x) = −x + b.


5
Fixed and Periodic Points
Fixed points and cycles are among the most important kinds of orbits in a
dynamical system, so it is important that we be able to ﬁnd them easily. As
we have seen, sometimes this involves solving equations or drawing accurate
graphs. These methods, however, are not always easily carried out. As we shall
see in this chapter, calculus comes to the rescue.
5.1
A Fixed Point Theorem
One of the simplest criteria for ﬁnding ﬁxed points is an immediate conse-
quence of the following important fact from calculus:
The Intermediate Value Theorem. Suppose F : [a, b] →R is continuous.
Suppose y0 lies between F(a) and F(b). Then there is an x0 in the interval
[a, b] with F(x0) = y0.
Simply stated, this theorem tells us that a continuous function assumes all
values between F(a) and F(b) on the interval [a, b]. An immediate consequence
is:
Fixed Point Theorem. Suppose F : [a, b] →[a, b] is continuous. Then there
is a ﬁxed point for F in [a, b].
Remarks:
1. This theorem asserts the existence of at least one ﬁxed point for F in [a, b];
there may, of course, be more. For example, all points in any interval [a, b] are
ﬁxed by the identity function F(x) = x.
2. There are several important hypotheses in this theorem, the ﬁrst two being
continuity and the fact that F takes the interval [a, b] into itself. Violation of
either of these may yield a function without ﬁxed points.
3. Also, it is important that the interval [a, b] be closed. For example, F(x) =
x2 takes the interval (0, 1/2) inside itself and is continuous, but there are no
ﬁxed points in this open interval (the ﬁxed point 0 lies outside of (0, 1/2)).
45

46
Fixed and Periodic Points
4. While the Fixed Point Theorem asserts the existence of at least one ﬁxed
point, it unfortunately does not give us any method of actually ﬁnding this
point. However, in practice, we often don’t need to know exactly where the
ﬁxed point lies. Just the knowledge that it is present in a certain interval often
suﬃces for our purposes.
The proof of the Fixed Point Theorem follows from the Intermediate Value
Theorem applied to H(x) = F(x) −x. This is a continuous function that
satisﬁes
H(a)
=
F(a) −a ≥0
H(b)
=
F(b) −b ≤0.
Thus there is a c in the interval [a, b] with H(c) = 0. This c satisﬁes F(c)−c = 0
and so is our ﬁxed point.
5.2
Attraction and Repulsion
There are two markedly diﬀerent types of ﬁxed points, attracting and repelling
ﬁxed points. We will make these notions precise in a moment, but for now the
idea behind these concepts is illustrated by the squaring function F(x) = x2.
This map has two ﬁxed points, at 0 and at 1. But note what happens to the
orbits of nearby points. If we choose any x0 with |x0| < 1, then the orbit of
x0 rapidly approaches zero. For example, the orbit of 0.1 is
0.1, 0.01, 0.0001, 0.00000001, . . . .
In fact, any x0 with 0 ≤x0 < 1, no matter how close to 1, leads to an orbit
that tends “far” from 1 and close to 0. For example, the orbit of 0.9 is
0.9, 0.81, 0.6561, 0.430467 . . . , 0.185302 . . . , 0.034336 . . . , 0.00117 . . . .
More precisely, if 0 ≤x0 < 1, then F n(x0) →0 as n →∞. On the other hand,
if x0 > 1, then again the orbit moves far from 1. For example, the orbit of 1.1
is
1.1, 1.21, 1.4641, 2.1436 . . . , 4.5950 . . . , 21.114 . . . , 445.79 . . . .
Thus, if x0 > 1, we have F n(x0) →∞as n →∞and hence the orbit tends
far from 1.
Clearly, points that are close to 0 have orbits that are attracted to 0, while
points close to 1 have orbits that are repelled, that move far from 1. Graphical
analysis of this function, as in Figure 5.1, shows vividly the diﬀerence between
these two types of ﬁxed points.

Calculus of Fixed Points
47
FIGURE 5.1
The point 0 is an attracting ﬁxed point for F(x) = x2, while 1 is repelling.
5.3
Calculus of Fixed Points
As another example, consider the linear functions A(x) = αx with 0 < α < 1
and B(x) = βx with β > 1. Each function has a ﬁxed point at 0, but this
ﬁxed point is attracting for A and repelling for B. Graphical analysis shows
this clearly in Figure 5.2.
FIGURE 5.2
Graphical analysis of (a) A(x) = αx, 0 < α < 1 and (b) B(x) = βx, β > 1.

48
Fixed and Periodic Points
Now consider the same functions, this time with −1 < α < 0 and β < −1.
Again, graphical analysis (Figure 5.3) shows that A has an attracting ﬁxed
point at 0 and B has a repelling ﬁxed point at 0. This time orbits hop back
and forth from left to right about zero, but still they either approach zero
or are repelled from zero. Clearly, the slope of these straight lines plays a
crucial role in determining whether or not a linear function has an attracting
or repelling ﬁxed point. As you saw in the exercises in the last chapter, this
fact holds for functions of the form cx+d where c and d are constants as well.
FIGURE 5.3
Graphical analysis of (a) A(x) = αx, −1 < α < 0 and (b) B(x) = βx,
β < −1.
This suggests that calculus will allow us to diﬀerentiate (pardon the lousy
pun) between attracting and repelling ﬁxed points for nonlinear functions, for
the derivative gives us the slope of the tangent line to the graph of a function.
In particular, near a ﬁxed point x0, if we examine the graph of the function
closely, the magnitude of the ﬁrst derivative F ′(x0) tells us how steeply the
graph crosses the diagonal at this point. This leads to an important deﬁnition:
Deﬁnition. Suppose x0 is a ﬁxed point for F. Then x0 is an attracting ﬁxed
point if |F ′(x0)| < 1. The point x0 is a repelling ﬁxed point if |F ′(x0)| > 1.
Finally, if |F ′(x0)| = 1, the ﬁxed point is called neutral or indiﬀerent.
The geometric rationale for this terminology is supplied by graphical anal-
ysis. Consider the graphs in Figure 5.4a,b. Both of these functions have ﬁxed
points at x0. The slope of the tangent line at x0, F ′(x0), is in both cases
less than 1 in magnitude: |F ′(x0)| < 1. Note that this forces nearby orbits
to approach x0, just as in the linear cases above. If −1 < F ′(x0) < 0, as in
Figure 5.4b, the orbit hops from one side of x0 to the other as it approaches
x0. The phase portraits in the two cases 0 < F ′(x0) < 1 and −1 < F ′(x0) < 0
are sketched in Figure 5.5.

Calculus of Fixed Points
49
FIGURE 5.4
In each case, x0 is an attracting ﬁxed point.
FIGURE 5.5
Possible phase portraits near an attracting ﬁxed point.
On the other hand, if |F ′(x0)| > 1, graphical analysis shows that nearby
points have orbits that move farther away, that is, are repelled. Again, if
F ′(x0) < −1, nearby orbits oscillate from side to side of x0 as they move
away, as in Figure 5.6b. If F ′(x0) > 1, nearby orbits do not oscillate as they
move away. As before, the phase portraits (Figure 5.7) show how nearby orbits
are repelled in these cases.
As an example, consider the function F(x) = 2x(1−x) = 2x−2x2. Clearly,
0 and 1/2 are ﬁxed points for F. We have F ′(x) = 2 −4x, so F ′(0) = 2
and F ′(1/2) = 0. Thus 0 is a repelling ﬁxed point, while 1/2 is attracting.
Graphical analysis conﬁrms this, as shown in Figure 5.8.

50
Fixed and Periodic Points
FIGURE 5.6
In each case, x0 is a repelling ﬁxed point.
FIGURE 5.7
Phase portraits near a repelling ﬁxed point.
Note that if F ′(x0) = 0, we may have several diﬀerent types of phase
portraits, as shown in Figure 5.9. In all cases, however, the ﬁxed point is
attracting.
5.4
Why Is This True?
The graphical analyses in Figures 5.4 and 5.6 are certainly convincing evidence
for the truth of our claim that the magnitude of F ′(x0) determines whether
x0 is attracting or repelling. But how do we know that this is true, especially
when the slopes of the tangent lines are close to the cut-oﬀpoints, namely
±1?

Why Is This True?
51
FIGURE 5.8
F(x) = 2x(1 −x) has an attracting ﬁxed point at 1/2 and a repelling ﬁxed
point T 0.
The answer is provided by one of the most useful theorems in all of calculus,
the Mean Value Theorem. Recall the fairly technical statement of this result:
The Mean Value Theorem. Suppose F is a diﬀerentiable function on the
interval a ≤x ≤b. Then there exists c between a and b for which the following
equation is true:
F ′(c) = F(b) −F(a)
b −a
.
The content of this theorem is best exhibited geometrically. The quantity
M = F(b) −F(a)
b −a
is the slope of the straight line connecting the two points (a, F(a)) and (b, F(b))
on the graph of F. So the theorem simply says that, provided F is diﬀerentiable
on the interval a ≤x ≤b, there is some point c between a and b at which
the slope of the tangent line, F ′(c), is exactly equal to M. This is displayed
geometrically in Figure 5.10.
For our purposes, the importance of the Mean Value Theorem lies in its
two corollaries:
Attracting Fixed Point Theorem. Suppose x0 is an attracting ﬁxed point
for F. Then there is an interval I that contains x0 in its interior and in which
the following condition is satisﬁed: if x ∈I, then F n(x) ∈I for all n and,
moreover, F n(x) →x0 as n →∞.

52
Fixed and Periodic Points
FIGURE 5.9
Phase portraits near zero for (a) F(x) = x2, (b) F(x) = x3, and (c) F(x) =
−x3.
FIGURE 5.10
The slope of the tangent line at c, F ′(c), is equal to M.

Why Is This True?
53
Proof: Since |F ′(x0)| < 1, there is a number λ > 0 such that |F ′(x0)| < λ < 1.
We may therefore choose a number δ > 0 so that |F ′(x)| < λ provided x
belongs to the interval I = [x0 −δ, x0 + δ]. Now let p be any point in I. By
the Mean Value Theorem
|F(p) −F(x0)|
|p −x0|
< λ,
so that
|F(p) −F(x0)| < λ|p −x0|.
Since x0 is a ﬁxed point, it follows that
|F(p) −x0| < λ|p −x0|.
This means that the distance from F(p) to x0 is smaller than the distance
from p to x0, since 0 < λ < 1. In particular, F(p) also lies in the interval I.
Therefore we may apply the same argument to F(p) and F(x0), ﬁnding
|F 2(p) −x0|
=
|F 2(p) −F 2(x0)|
<
λ|F(p) −F(x0)|
<
λ2|p −x0|.
Since λ < 1, we have λ2 < λ. This means that the points F 2(p) and x0
are even closer together than F(p) and x0. Thus we may continue using this
argument to ﬁnd that, for any n > 0,
|F n(p) −x0| < λn|x −x0|.
Now λn →0 as n →∞. Thus, F n(p) →x0 as n →∞. This completes the
proof.
We observe that the proof of the Attracting Fixed Point Theorem actually
tells us a little bit more than the statement of the theorem implies. The
inequality
|F n(p) −x0| < λn|x −x0|
says that nearby orbits (those beginning in I) actually converge exponentially
to the ﬁxed point. Notice that the number λ may be chosen very close to
|F ′(x0)|, so it is essentially this quantity that governs the rate of approach of
orbits to x0.
Arguing in an entirely analogous manner, we have:
Repelling Fixed Point Theorem. Suppose x0 is a repelling ﬁxed point for
F. Then there is an interval I that contains x0 in its interior and in which the
following condition is satisﬁed: if x ∈I and x ̸= x0, then there is an integer
n > 0 such that F n(x) ̸∈I.

54
Fixed and Periodic Points
These two theorems combined justify our use of the terminology “attract-
ing” and “repelling” to describe the corresponding ﬁxed points. In partic-
ular, they tell us the “local” dynamics near any ﬁxed point x0 for which
|F ′(x0)| ̸= 1.
One major diﬀerence between attracting and repelling ﬁxed points is the
fact that attracting points are “visible” on the computer, whereas repelling
ﬁxed points generally are not. We can often ﬁnd an attracting ﬁxed point by
choosing an initial seed randomly and computing its orbit numerically. If this
orbit ever enters the interval I about an attracting ﬁxed point, then we know
the fate of this orbit—it necessarily converges to the attracting ﬁxed point.
On the other hand, in the case of a repelling ﬁxed point, the randomly chosen
orbit would have to land exactly on the ﬁxed point in order for us to see it.
This rarely happens, for even if the orbit comes very close to a repelling ﬁxed
point, roundoﬀerror will throw us oﬀthis ﬁxed point and onto an orbit that
moves away.
The situation for a neutral ﬁxed point is not nearly as simple as the attract-
ing or repelling cases. For example, the identity function F(x) = x ﬁxes all
points, but none are attracting or repelling. Also, F(x) = −x ﬁxes zero, but
this is not an attracting or repelling ﬁxed point since all other points lie on
cycles of period 2. Finally, as Figure 5.11 shows, F(x) = x −x2 has a ﬁxed
point at zero which is attracting from the right but repelling from the left.
Note that |F ′(0)| = 1 in all three cases.
FIGURE 5.11
The ﬁxed point at zero for F(x) = x −x2 is neither attracting nor repelling.
On the other hand, neutral ﬁxed points may attract or repel all nearby
orbits. For example, graphical analysis shows that F(x) = x −x3 has a ﬁxed
point that attracts the orbit of any x with |x| < 1, whereas F(x) = x + x3
repels all orbits away from 0. These ﬁxed points are sometimes called weakly

Periodic Points
55
attracting or weakly repelling, since the convergence or divergence is quite
slow. This is illustrated in the experiment in Section 5.6.
5.5
Periodic Points
Just as in the case of ﬁxed points, periodic points may also be classiﬁed
as attracting, repelling, or neutral. The calculus here is only slightly more
complicated.
Let’s begin with an example. The function F(x) = x2 −1 has a cycle of
period 2 with orbit 0, −1, 0, −1, . . . . Graphical analysis as depicted in Figure
5.12 indicates that this cycle should be attracting.
FIGURE 5.12
An attracting cycle of period 2 for F(x) = x2 −1.
To see why this is the case, we examine the graph of F 2(x) = (x2−1)2−1 =
x4 −2x2, as shown in Figure 5.13. Note that F 2 has four ﬁxed points: at the
two ﬁxed points of F as well as at the period-2 points 0 and −1. Note that
the derivative of F 2, namely 4x3 −4x, vanishes at both 0 and −1, that is,
(F 2)′(0) = (F 2)′(−1) = 0. This indicates that these two points are attracting
ﬁxed points for the second iterate of F. That is, under iteration of F 2, orbits of
points nearby 0 or −1 converge to these points. Under iteration of F, however,
these orbits cycle back and forth as they converge to the 2-cycle.
These ideas motivate us to extend the deﬁnitions of attraction and repul-
sion to cycles in the natural way: a periodic point of period n is attracting
(repelling) if it is an attracting (repelling) ﬁxed point for F n. This imme-
diately brings up the question of whether periodic orbits can contain some

56
Fixed and Periodic Points
FIGURE 5.13
The graph of the second iterate of F(x) = x2 −1.
points that are attracting and some that are repelling. As we will see below,
calculus says that this is not the case.
To determine if a periodic point x0 of period n is attracting or repelling,
we must compute the derivative of F n at x0. Recalling that F n is the nth
iterate of F, not the nth power of F, we see that this demands the use of
the Chain Rule. From calculus, we know that if F and G are diﬀerentiable
functions, then the derivative of their composition is given by
(F ◦G)′(x) = F ′(G(x)) · G′(x).
In particular,
(F 2)′(x0)
=
F ′(F(x0)) · F ′(x0)
=
F ′(x1) · F ′(x0),
and
(F 3)′(x0)
=
F ′(F 2(x0)) · (F 2)′(x0)
=
F ′(x2) · F ′(x1) · F ′(x0).
Invoking the Chain Rule n −1 times, we ﬁnd:
Chain Rule Along a Cycle. Suppose x0, x1, . . . , xn−1 lie on a cycle of period
n for F with xi = F i(x0). Then
(F n)′(x0) = F ′(xn−1) · . . . · F ′(x1) · F ′(x0).

Experiment: Rates of Convergence
57
Note that this formula tells us that the derivative of F n at x0 is simply
the product of the derivatives of F at all points on the orbit. This means that
we do not have to ﬁrst compute the formula for F n. All we need ﬁnd is the
derivative of F and then plug in x0, x1, . . . , xn−1, respectively, and multiply
all of these numbers together. This saves a lot of algebra, especially if n is
large. For example, we saw above that for the function F(x) = x2 −1 that
has a 2-cycle at 0 and −1, (F 2)′(0) = 0. We computed this by ﬁrst ﬁnding the
formula for F 2 and then diﬀerentiating at 0. But, since F ′(x) = 2x, we have
quite simply F ′(0) = 0 and F ′(−1) = −2, and so, by the Chain Rule Along
a Cycle, again (F 2)′(0) = −2 · 0 = 0. Similarly, (F 2)′(−1) = −2 · 0 = 0. The
fact that, in this example, (F 2)′(0) = (F 2)′(−1) is no accident because of the
following:
Corollary. Suppose x0, x1, . . . xn−1 lie on an n-cycle for F. Then
(F n)′(x0) = (F n)′(x1) = · · · = (F n)′(xn−1).
This corollary follows immediately from the Chain Rule Along a Cycle,
since the points on the cycle are exactly the same, no matter which point is
chosen as the initial seed.
Example. Consider F(x) = −3
2x2 + 5
2x + 1. The point 0 lies on a cycle of
period 3 since F(0) = 1, F(1) = 2, and F(2) = 0. We have F ′(x) = −3x + 5
2,
so F ′(0) = 5
2, F ′(1) = −1
2, and F ′(2) = −7
2. Hence
(F 3)′(0)
=
F ′(2) · F ′(1) · F ′(0)
=
−7
2
 −1
2
 5
2

=
35
8 > 1.
Therefore this cycle is repelling.
5.6
Experiment: Rates of Convergence
Goal: In this experiment you will investigate how quickly (or slowly) an orbit
is attracted to a ﬁxed point. Your goal is to relate this speed of convergence
to the value of the derivative at the ﬁxed point.
Procedure: Each of the functions listed below has a ﬁxed point and the
orbit of 0.2 is attracted to this point. For each function, use the computer to

58
Fixed and Periodic Points
compute the orbit of 0.2 until it “reaches” the ﬁxed point, or else comes within
some designated distance from the ﬁxed point, say 10−5. We say “reaches”
in quotes because, in actuality, the orbit will never reach the ﬁxed point.
However, because of computer round-oﬀ, it may appear that the orbit has
landed on the ﬁxed point.
For each function, you should record:
a.
The ﬁxed point p.
b.
|F ′(p)|
c.
Is p attracting or neutral?
d.
The number of iterations necessary for the orbit of 0.2 to “reach”
p.
The functions you should try are:
a.
F(x) = x2 + 0.25
b.
F(x) = x2
c.
F(x) = x2 −0.24
d.
F(x) = x2 −0.75
e.
F(x) = 0.4x(1 −x)
f.
F(x) = x(1 −x)
g.
F(x) = 1.6x(1 −x)
h.
F(x) = 2x(1 −x)
i.
F(x) = 2.4x(1 −x)
j.
F(x) = 3x(1 −x)
k.
F(x) = 0.4 sin x
l.
F(x) = sin x
Results: After compiling the data, compare the results for each function. In
an essay, describe what you have observed. What is the relationship between
|F ′(p)| and the speed of convergence to p? Which ﬁxed points have fastest
convergence and which have slowest?
Notes and Questions: Each of the following functions has a cycle of period 2
that attracts the orbit of 0.2. In each case, determine the cycle experimentally
and estimate the derivative of F 2 along the cycle. (You need not solve the
equations explicitly to get exact values, although this can be done.) Again
compare the attracting vs. neutral cases.
a.
F(x) = x2 −1
b.
F(x) = x2 −1.1
c.
F(x) = x2 −1.25. Hint: The 2-cycle is given by (−1 ±
√
2)/2.

Experiment: Rates of Convergence
59
Exercises
1. For each of the following functions, ﬁnd all ﬁxed points and classify them
as attracting, repelling, or neutral.
a.
F(x) = x2 −x/2
b.
F(x) = x(1 −x)
c.
F(x) = 3x(1 −x)
d.
F(x) = (2 −x)/10
e.
F(x) = x4 −4x2 + 2
f.
S(x) = π
2 sin x
g.
S(x) = −sin x
h.
F(x) = x3 −3x
i.
A(x) = arctan x
j.
T(x) =

2x
if x ≤1
2
2 −2x
if x > 1
2
k.
F(x) = 1/x2
2. For each of the following functions, zero lies on a periodic orbit. Classify
this orbit as attracting, repelling, or neutral.
a.
F(x) = 1 −x2
b.
C(x) = π
2 cos x
c.
F(x) = −1
2x3 −3
2x2 + 1
d.
F(x) = |x −2| −1
e.
A(x) = −4
π arctan(x + 1)
f.
F(x) =

x + 1
if x ≤3.5
2x −8
if x > 3.5
3. Suppose x0 lies on a cycle of prime period n for the doubling function D.
Evaluate (Dn)′ (x0). Is this cycle attracting or repelling?
4. Each of the following functions has a neutral ﬁxed point. Find this ﬁxed
point and, using graphical analysis with an accurate graph, determine if it is
weakly attracting, weakly repelling, or neither.
a.
F(x) = x + x2
b.
F(x) = 1/x
c.
E(x) = ex−1 (ﬁxed point is x0 = 1)
d.
S(x) = sin x

60
Fixed and Periodic Points
e.
T(x) = tan x
f.
F(x) = x + x3
g.
F(x) = x −x3
h.
F(x) = −x + x3
i.
F(x) = −x −x3
j.
E(x) = −eex (ﬁxed point is x0 = −1). Hint: Examine in detail the
graph of E2(x) near x = −1 using higher derivatives of E2.
k.
L(x) = ln |x −1|
5. Suppose that F has a neutral ﬁxed point at x0 with F ′(x0) = 1. Suppose
also that F ′′(x0) > 0. What can you say about x0: is x0 weakly attracting,
weakly repelling, or neither? Use graphical analysis and the concavity of the
graph of F near x0 to support your answer.
6. Repeat exercise 5, but this time assume that F ′′(x0) < 0.
7. Suppose that F has a neutral ﬁxed point at x0 with F ′(x0) = 1 and
F ′′(x0) = 0. Suppose also that F ′′′(x0) > 0. Use graphical analysis and the
concavity of the graph of F near x0 to show that x0 is weakly repelling.
8. Repeat exercise 7, but this time assume that F ′′′(x0) < 0. Show that x0 is
weakly attracting.
9. Combine the results of exercises 5–8 to state a Neutral Fixed Point Theorem.
10. For which values of a and b does the linear function L(x) = ax + b have
a cycle of prime period 3?
11. For which values of a and b does the linear function L(x) = ax + b have
a cycle of prime period 751?
12. Consider the logistic function Fλ(x) = λx(1 −x) where λ > 0. Find all
values of λ for which Fλ has a cycle of prime period 2. Then determine the
λ-values for which this cycle is attracting, repelling, or neutral.
13. Recall that a function F(x) on the real line is said to be odd if F(−x) =
−F(x). Use this formula to ﬁnd an easy way to ﬁnd cycles of prime period 2
for F.
14. Use the results of the previous exercise to ﬁnd all values of λ for which the
odd function Gλ(x) = x3 + λx has a cycle of prime preiod 2. Then determine
the λ-values for which this cycle is attracting, repelling, or neutral.
15. Consider the sine function Sλ(x) = λ sin(x) where we assume that λ is
negative. Use the result of Exercise 13 together with graphical analysis to
determine the values of λ for which Sλ does not have a cycle of prime period
2.

6
Bifurcations
In this chapter we begin the study of the quadratic family of functions Qc(x) =
x2 +c where c is a constant. While these functions look simple enough, we will
see that their dynamics are amazingly complicated. Indeed, this behavior was
only completely understood in the 1990’s. This chapter is just the beginning of
a long story about Qc(x) = x2 + c and related dynamical systems — one that
will occupy our attention for most of the rest of this book. Here we introduce
two of the most important types of bifurcations that occur in dynamics — we
will see other types later.
6.1
Dynamics of the Quadratic Map
Throughout this chapter we let Qc denote the family of quadratic functions
Qc(x) = x2 + c. The number c is a parameter — for each diﬀerent c we get a
diﬀerent dynamical system Qc. Our goal is to understand how the dynamics
of Qc change as c varies.
As usual, our ﬁrst task is to ﬁnd the ﬁxed points of Qc. These are obtained
by solving the quadratic equation
x2 + c = x,
which yields two roots:
p+ = 1
2

1 +
√
1 −4c

p−= 1
2

1 −
√
1 −4c

.
These are the two ﬁxed points for Qc.1
Note that p+ and p−are real if and only if 1 −4c ≥0, or c ≤1/4. That
is, when c > 1/4, Qc has no ﬁxed points on the real line. When c = 1/4, we
have 1 −4c = 0, so that p+ = p−= 1/2. Finally, when c < 1/4, 1 −4c > 0, so
that p+ and p−are real and distinct. Note that we always have p+ > p−in
this case.
1We really should write p+(c) and p−(c) since both of these ﬁxed points depend on c.
However, we will usually suppress this added notation for readability.
61

62
Bifurcations
FIGURE 6.1
All orbits of Qc(x) = x2 + c for c > 1/4 tend to inﬁnity.
First consider the case c > 1/4. The graph of Qc is a parabola opening
upward. When c > 1/4, this graph does not meet the diagonal line y = x.
Hence graphical analysis shows that all orbits of Qc, when c > 1/4, tend
to inﬁnity. See Figure 6.1. Therefore we understand completely the (rather
simple) dynamics in this case.
When c decreases below 1/4, this situation changes — we encounter our
ﬁrst bifurcation. Bifurcation means a division in two, a splitting apart, and
that is exactly what has happened to the ﬁxed points of Qc. For c > 1/4,
Qc has no ﬁxed points; for c = 1/4, Qc has exactly one ﬁxed point; but for
c < 1/4, this ﬁxed point splits into two, one at p+ and one at p−. In the
next section we will call this kind of bifurcation the saddle-node or tangent
bifurcation and describe it more fully.
Using the results of the previous chapter, we can check whether the ﬁxed
points p± are attracting, repelling, or neutral. Since Q′
c(x) = 2x, we ﬁnd
Q′
c(p+) = 1 +
√
1 −4c
Q′
c(p−) = 1 −
√
1 −4c.
Note that Q′
c(p+) = 1 if c = 1/4, but Q′
c(p+) > 1 for c < 1/4 since √1 −4c > 0
for these c-values. Hence p+ is a neutral ﬁxed point when c = 1/4 but is
repelling when c < 1/4.
The situation for p−is slightly more complicated. We have Q′
c(p−) = 1
when c = 1/4 (here, of course, p−= p+ = 1/2). When c is slightly below 1/4,
Q′
c(p−) < 1 so p−becomes attracting. To ﬁnd all of the c-values for which
|Q′
c(p−)| < 1, we must solve
−1 < Q′
c(p−) < 1

Dynamics of the Quadratic Map
63
or
−1 < 1 −
√
1 −4c < 1.
Solving these inequalities yields
2 >
√
1 −4c > 0
4 > 1 −4c > 0
−3/4 < c < 1/4.
Thus, p−is an attracting ﬁxed point for Qc when −3/4 < c < 1/4. It is easy
to check that, when c = −3/4, Q′
c(p−) = 1 −√1 + 3 = −1, so p−is neutral.
When c < −3/4, Q′
c(p−) < −1, so p−is repelling.
Let’s summarize all of this in a proposition.
Proposition: The First Bifurcation. For the family Qc(x) = x2 + c:
1. All orbits tend to inﬁnity if c > 1/4.
2. When c = 1/4, Qc has a single ﬁxed point at p+ = p−= 1/2 that
is neutral.
3. For c < 1/4, Qc has two ﬁxed points at p+ and p−. The ﬁxed point
p+ is always repelling.
a. If −3/4 < c < 1/4, p−is attracting.
b. If c = −3/4, p−is neutral.
c. If c < −3/4, p−is repelling.
We make an observation here that will be useful in the next few chapters.
For any c ≤1/4, all of the interesting dynamics occurs in the interval −p+ ≤
x ≤p+. Note that Qc(−p+) = p+, so −p+ is an eventually ﬁxed point. Indeed,
graphical analysis shows that if x > p+ or x < −p+, then the orbit of x simply
tends to inﬁnity (Figure 6.2).
One can also prove that, for −3/4 < c < 1/4, all orbits in the interval
(−p+, p+) tend to the attracting ﬁxed point at p−. Proving this is straightfor-
ward when 0 ≤c < 1/4, but the proof is more complicated in the other case.
We content ourselves by simply illustrating this fact via graphical analysis in
Figure 6.3.
We now turn our attention to what happens as c decreases below −3/4.
From the above we know that the ﬁxed point p−ceases to be attracting and
becomes repelling as this occurs. We also know that there are no other cycles
when c > −3/4. So we ask if this is true for c < −3/4? The answer is no: a
cycle of period 2 appears when c < −3/4. To see this we solve the equation
Q2
c(x) = x. The resulting equation is of fourth degree and looks formidable.
x4 + 2cx2 −x + c2 + c = 0.

64
Bifurcations
FIGURE 6.2
If c ≤1/4, any x with x > p+ or x < −p+ has an orbit that tends to inﬁnity.
FIGURE 6.3
Graphical analysis shows that all orbits of Qc in the interval −p+ < x < p+
tend to p−when −3/4 < c < 1/4.

The Saddle-Node Bifurcation
65
However, we know two solutions of this equation, namely the ﬁxed points p+
and p−. Hence x −p+ and x −p−are factors of this equation (for c < 1/4).
Therefore, so is (x −p+)(x −p−) = x2 + c −x. We know what this product is
since both p−and p+ are ﬁxed points and thus solutions of x2 + c −x = 0.
Thus we may divide our fourth-degree polynomial by this quantity, obtain-
ing
x4 + 2cx2 −x + c2 + c
x2 + c −x
= x2 + x + c + 1.
Then the solutions of x2 + x + c + 1 = 0 give ﬁxed points of Q2
c that are
therefore the periodic points of period 2 for Qc. These roots are
q± = 1
2

−1 ±
√
−4c −3

.
Note that q± also depend on c. Furthermore, q± are real if and only if −4c−3 ≥
0, that is, if c ≤−3/4. Hence we have a new kind of bifurcation called a period-
doubling bifurcation. As c decreases below −3/4, two things occur: the ﬁxed
point p−changes from attracting to repelling and a new 2-cycle appears at
q±. Note that when c = −3/4, we have q+ = q−= −1/2 = p−, so these two
new periodic points originated at p−when c = −3/4.
We will leave the following two observations as exercises (see exercises 3–
5). For −5/4 < c < −3/4, the points q± lie on an attracting 2-cycle, but for
c < −5/4, they lie on a repelling 2-cycle. We may therefore summarize this
situation as follows.
Proposition: The Second Bifurcation. For the family Qc(x) = x2 + c:
1. For −3/4 < c < 1/4, Qc has an attracting ﬁxed point at p−and no
2-cycles.
2. For c = −3/4, Qc has a neutral ﬁxed point at p−= q± and no
2-cycles.
3. For −5/4 < c < −3/4, Qc has repelling ﬁxed points at p± and an
attracting 2-cycle at q±.
6.2
The Saddle-Node Bifurcation
In the next two sections we temporarily suspend our investigation of the
quadratic family to describe more completely the bifurcations encountered
in the last section. We will consider a one-parameter family of functions Fλ.
Here λ is a parameter, so that for each λ, Fλ is a function of x. We will assume
that Fλ depends smoothly on λ and x in such a family, unless otherwise noted.

66
Bifurcations
For example, Fλ(x) = λx(1 −x), Sλ(x) = λ sin(x), and Eλ(x) = exp(x) + λ
are all one-parameter families of functions.
Bifurcations occur in a one-parameter family of functions when there is
a change in the ﬁxed or periodic point structure as λ passes through some
particular parameter value. Among the most important bifurcations is the
saddle-node or tangent bifurcation.
Deﬁnition. A one-parameter family of functions Fλ undergoes a saddle-node
(or tangent) bifurcation at the parameter value λ0 if there is an open interval
I and an ϵ > 0 such that:
1.
For λ0 −ϵ < λ < λ0, Fλ has no ﬁxed points in the interval I.
2.
For λ = λ0, Fλ has one ﬁxed point in I, and this ﬁxed point is
neutral.
3.
For λ0 < λ < λ0 + ϵ, Fλ has two ﬁxed points in I, one attracting
and one repelling.
This is a complicated deﬁnition. Intuitively, this deﬁnition means the follow-
ing. A saddle-node or tangent bifurcation occurs if the functions Fλ have no
ﬁxed points in an interval I for λ-values slightly less than λ0, exactly one ﬁxed
point in I when λ = λ0, and exactly two ﬁxed points in I for λ slightly larger
than λ0.
Remarks:
1. There is nothing sacred about the inequalities in λ: a saddle-node bifurca-
tion also occurs if the direction of the bifurcation is reversed, that is, no ﬁxed
points for λ0 + ϵ > λ > λ0 and so forth.
2. Periodic points may undergo a saddle-node bifurcation. These are described
by simply replacing Fλ with F n
λ for a cycle of period n in the above deﬁnition.
3. The saddle-node bifurcation typically occurs when the graph of Fλ0 has
a quadratic tangency with the diagonal at (x0, x0) (so F ′
λ0(x0) = 1 but
F ′′
λ0(x0) ̸= 0). This condition implies that the graph of Fλ0 is either con-
cave up or down, so that near x0, Fλ0 has only the one ﬁxed point x0. For
more precise conditions that guarantee a saddle-node bifurcation, see [10].
4. The fact that Fλ0 is tangent to the diagonal at x0 is the reason for the termi-
nology “tangent” bifurcation. The term “saddle-node” comes from a descrip-
tion of this bifurcation in higher dimensions and in the ﬁeld of diﬀerential
equations. In our simple setting this terminology is not very transparent, but
it is nevertheless standard.
5. Bifurcation theory is a “local” theory in that we are only concerned about
changes in the periodic point structure near the parameter value λ0. That is
the reason for the ϵ in the deﬁnition. Usually, ϵ is small.

The Saddle-Node Bifurcation
67
FIGURE 6.4
A typical saddle-node bifurcation.
FIGURE 6.5
Phase portraits for (a) λ < λ0, (b) λ = λ0, and (c) λ > λ0.

68
Bifurcations
FIGURE 6.6
A saddle-node bifurcation in the exponential family Eλ(x) = ex + λ.
The typical saddle-node bifurcation occurs as depicted in Figure 6.4. The
accompanying phase portraits are shown in Figure 6.5.
Example. The quadratic family Qc(x) = x2 +c has a saddle-node bifurcation
at c = 1/4, as discussed in the previous section. In this example we may take
the interval I to be the entire real line. There are no ﬁxed points when c > 1/4,
a neutral ﬁxed point when c = 1/4, and a pair of ﬁxed points (one attracting,
one repelling) for −3/4 < c < 1/4. Thus we may take ϵ = 1 in this example.
Example. The family Eλ(x) = ex + λ has a saddle-node bifurcation when
λ = −1. Note that E−1(0) = 0, E′
−1(0) = 1, and E′′
−1(0) = 1. The graphs of
Eλ for λ < −1 and λ > −1 show how this bifurcation unfolds (Figure 6.6).
Example. The family Fλ(x) = λx(1−x) undergoes a bifurcation when λ = 1,
but this is not a saddle-node bifurcation. We do have F1(0) = 0 and F ′
1(0) = 1,
and there is a unique neutral ﬁxed point at x = 0. In fact, 0 is a ﬁxed point
for any λ. However, for any nonzero λ close to λ = 1, there is a second ﬁxed
point close to 0, as shown in the graphs in Figure 6.7. So this is technically
not a saddle-node bifurcation.
To understand bifurcation behavior, it is often helpful to look at the
bifurcation diagram. This is a picture in the λ, x-plane of the relevant ﬁxed
and periodic points as functions of λ. For example, in the quadratic family
Qc(x) = x2 +c, we observed a saddle-node bifurcation at c = 1/4. For c > 1/4
there were no ﬁxed points, but for c < 1/4 we found two ﬁxed points that
were given by
p±(c) = 1
2

1 ±
√
1 −4c

.

The Period-Doubling Bifurcation
69
FIGURE 6.7
A bifurcation in the logistic family Fλ(x) = λx(1 −x).
In the bifurcation diagram we plot the parameter c on the horizontal axis
versus the ﬁxed points on the vertical axis. It is perhaps perverse to plot x-
values on the vertical axis, but such is life! The bifurcation diagram for Qc
is depicted in Figure 6.8. Note that along each vertical line c = constant, we
see either zero, one, or two points corresponding to the ﬁxed points of Qc. In
Figure 6.9 we have sketched the bifurcation diagrams for the bifurcations in
the families ex + λ and λx(1 −x).
6.3
The Period-Doubling Bifurcation
Now we turn our attention to the second bifurcation encountered in the
quadratic family Qc(x) = x2 + c, the period-doubling bifurcation.
Deﬁnition. A family of functions Fλ undergoes a period-doubling bifurcation
at the parameter value λ = λ0 if there is an open interval I and an ϵ > 0 such
that:
1.
For each λ in the interval [λ0 −ϵ, λ0 + ϵ], there is a unique ﬁxed
point pλ for Fλ in I.
2.
For λ0 −ϵ < λ ≤λ0, Fλ has no cycles of period 2 in I and pλ is
attracting (resp., repelling).
3.
For λ0 < λ < λ0 + ϵ, there is a unique 2-cycle q1
λ, q2
λ in I with
Fλ(q1
λ) = q2
λ. This 2-cycle is attracting (resp., repelling). Meanwhile,
the ﬁxed point pλ is repelling (resp., attracting).
4.
As λ →λ0, we have qi
λ →pλ0.

70
Bifurcations
FIGURE 6.8
The bifurcation diagram for Qc(x) = x2 + c.
FIGURE 6.9
Bifurcation diagrams for (a) Eλ(x) = ex + λ and (b) Fλ(x) = λx(1 −x).

The Period-Doubling Bifurcation
71
Remarks:
1. Thus there are two typical cases for a period-doubling bifurcation. As the
parameter changes, a ﬁxed point may change from attracting to repelling and,
at the same time, give birth to an attracting 2-cycle. Alternatively, the ﬁxed
point may change from repelling to attracting and, at the same time, give
birth to a repelling cycle of period 2.
2. As in the saddle-node case, the direction in which the bifurcation occurs
may be reversed. Also, cycles may undergo a period-doubling bifurcation. In
this case a cycle of period n will give birth to a cycle of period 2n.
3. The period-doubling bifurcation occurs when the graph of Fλ is perpendic-
ular to the diagonal, that is, when F ′
λ(pλ0) = −1. By the chain rule, it follows
that (F 2
λ)′(pλ0) = 1, so the graph of the second iterate of Fλ is tangent to the
diagonal when the period-doubling bifurcation occurs. The precise conditions
that guarantee the occurrence of a period-doubling bifurcation may be found
in [10].
To understand the period-doubling bifurcation, let’s return to the
quadratic family Qc(x) = x2 + c. We described analytically the period-
doubling bifurcation that occurs in this family at λ = −3/4 in the ﬁrst
section of this chapter. Now let’s investigate this bifurcation geometrically.
In Figure 6.10 we have performed graphical analysis on Qc for two distinct
c-values, one before the bifurcation and one after. Note how the ﬁxed point
p−changes from attracting to repelling as c decreases through −3/4. Also
observe how orbits near p−now tend to the attracting 2-cycle after the bifur-
cation. In Figure 6.11 we have sketched the phase portraits before and after the
bifurcation.
In Figure 6.12 we display the graphs of Q2
c for c-values before, at, and
after the period-doubling bifurcation. Note how the graph “twists” through the
diagonal at the point of bifurcation to produce the 2-cycle. Figure 6.13 depicts
the bifurcation diagram for this family. In this picture we have displayed both
the ﬁxed points and the 2-cycle for Qc. Note how the 2-cycle is spawned by
the ﬁxed point p−as c decreases through −3/4.
Example. Consider the family Fλ(x) = λx −x3. Note that this family has
a ﬁxed point at 0 for all λ. When −1 < λ < 1, this ﬁxed point is attracting.
When λ = −1, 0 is neutral. And when λ < −1, 0 is repelling. A period
doubling bifurcation occurs at λ = −1. The easiest way to see this is to note
that Fλ is an odd function. That is, Fλ(−x) = −Fλ(x) for all x. In particular,
if Fλ(x0) = −x0, then we must have F 2
λ(x0) = x0. This follows from
F 2
λ(x0) = Fλ(−x0) = −Fλ(x0) = x0.
Thus we may solve the equation Fλ(x) = −x to ﬁnd 2-cycles. This yields the
equation
λx −x3 = −x,

72
Bifurcations
FIGURE 6.10
For c > −3/4, Qc has an attracting ﬁxed point, but for c < −3/4, this ﬁxed
point is repelling and there is an attracting 2-cycle.
FIGURE 6.11
Phase portraits near the period-doubling bifurcation for Qc.

Experiment: The Transition to Chaos
73
FIGURE 6.12
The graphs of Q2
c near the period-doubling bifurcation.
whose roots are x = 0, ±
√
λ + 1. The point 0 is our ﬁxed point, and the other
roots form a 2-cycle. Note that this cycle only appears when λ > −1. An
easy computation shows that the 2-cycle is repelling for these λ-values (See
exercise 15). Figure 6.14 displays graphical analysis of Fλ before and after the
bifurcation.
6.4
Experiment: The Transition to Chaos
Goal: With an eye toward the story that will begin to unfold in the next
chapter, our goal in this experiment will be to observe the dynamical behavior
of Qc(x) = x2 +c for a large number of c-values in the interval −2 ≤c ≤0.25.

74
Bifurcations
FIGURE 6.13
The bifurcation diagram for Qc.
FIGURE 6.14
The period-doubling bifurcation for the family Fλ(x) = λx −x3.

Experiment: The Transition to Chaos
75
FIGURE 6.15
The asymptotic behavior of the orbit of 0.
Procedure: You are to compute the orbit of 0 under Qc(x) = x2 + c for at
least 50 diﬀerent c-values as speciﬁed below. For each such c, the goal is to
record the ultimate or “asymptotic” behavior of the orbit of 0. This means
that we are only interested in what eventually happens to the orbit of 0. Is it
attracted to a ﬁxed point? To a k-cycle? Is there no pattern to the orbit at
all?
For each chosen c you should record both c and the ultimate behavior of
the orbit of 0. Then you should plot all of this information just as in the
bifurcation diagram. Plot the c-axis horizontally with −2 ≤c ≤0.25 and the
x-axis vertically with −2 ≤x ≤2 as depicted in Figure 6.15.
In this diagram, for each chosen c, you should record the ultimate fate of
the orbit of 0 as follows. If the orbit of 0 under Qc1 is attracted to a ﬁxed point
p1, then plot (c1, p1). If the orbit of 0 under Qc2 is attracted to a 2-cycle, q1
and q2, then plot (c2, q1) and (c2, q2). If there is no pattern to the orbit of 0,
then use a histogram to determine approximately the interval (or intervals)
in which this orbit seems to wander. Then plot these intervals vertically over
the corresponding c-value. See Figure 6.15.
To make a complete picture, you should choose at least 50 c-values dis-
tributed as follows:
1.
Five c’s in the interval −0.75 < c < 0.25.
2.
Five c’s in the interval −1.25 < c < −0.75.
3.
At least twenty equally spaced c’s in the interval −1.4 < c < −1.25.
4.
At least ﬁve equally spaced c’s in the interval −1.75 < c < −1.4.
5.
At least ten equally spaced c’s in the interval −1.78 < c < −1.76.
6.
At least ﬁve equally spaced c’s in the interval −2 < c < −1.78.

76
Bifurcations
Notes and Questions:
1. We will see later why we chose the orbit of 0 in this experiment.
2. A similar experiment may be conducted with the family of logistic functions
Fλ(x) = λx(1 −x). Here we plot λ on the horizontal axis with 0 ≤λ ≤4 and
x on the vertical axis with 0 ≤x ≤1. It is important to use the initial seed
x0 = 0.5 in this case, not x0 = 0, which is always ﬁxed for Fλ.
3. For a more complete picture, work may be divided among several groups
of experimenters, each assuming responsibility for a diﬀerent collection of c or
λ-values.
Exercises
1. Each of the following functions undergoes a bifurcation of ﬁxed points at
the given parameter value. In each case, use algebraic or graphical methods to
identify this bifurcation as either a saddle-node or period-doubling bifurcation,
or neither of these. In each case, sketch the phase portrait for typical parameter
values below, at, and above the bifurcation value.
a.
Fλ(x) = x + x2 + λ, λ = 0
b.
Fλ(x) = x + x2 + λ, λ = −1
c.
Gμ(x) = μx + x3, μ = −1
d.
Gμ(x) = μx + x3, μ = 1
e.
Sμ(x) = μ sin x, μ = 1
f.
Sμ(x) = μ sin x, μ = −1
g.
Fc(x) = x3 + c, c = 2/3
√
3
h.
Eλ(x) = λ(ex −1), λ = −1
i.
Eλ(x) = λ(ex −1), λ = 1
j.
Hc(x) = x + cx2, c = 0
k.
Fc(x) = x + cx2 + x3, c = 0
The next four exercises apply to the family Qc(x) = x2 + c.
2. Verify the formulas for the ﬁxed points p± and the 2-cycle q± given in the
text.
3. Prove that the cycle of period 2 given by q± is attracting for −5/4 < c <
−3/4.
4. Prove that this cycle is neutral for c = −5/4.
5. Prove that this cycle is repelling for c < −5/4.
Exercises 6–14 deal with the logistic family of functions given by Fλ(x) =
λx(1 −x).

Experiment: The Transition to Chaos
77
6. For which values of λ does Fλ have an attracting ﬁxed point at x = 0?
7. For which values of λ does Fλ have a nonzero attracting ﬁxed point?
8. Describe the bifurcation that occurs when λ = 1.
9. Sketch the phase portrait and bifurcation diagram near λ = 1.
10. Describe the bifurcation that occurs when λ = 3.
11. Sketch the phase portrait and bifurcation diagram near λ = 3.
12. Describe the bifurcation that occurs when λ = −1.
13. Sketch the phase portrait and bifurcation diagram near λ = −1.
14. Compute an explicit formula for the periodic points of period 2 for Fλ.
15. Consider Fλ(x) = λx −x3. Show that the 2-cycle given by ±
√
λ + 1 is
repelling when λ > −1.
16. Consider the family of functions Fλ(x) = x5−λx3. Discuss the bifurcation
of 2-cycles that occurs when λ = 2. Hint: Note that this is an odd function
for each λ.


7
The Quadratic Family
In this chapter we will continue our study of the dynamics of the quadratic
functions Qc(x) = x2 + c. In the previous chapter we saw that the dynamics
of these functions were relatively simple when c > −5/4. In this chapter
we will jump ahead a bit to study the case where c ≤−2. We will see that a
remarkable change has occurred—for these values of c the dynamical behavior
is much more complicated.
7.1
The Case c = −2
In Section 3.6 you computed a variety of orbits of Q−2(x) = x2 −2 for initial
seeds in the interval −2 ≤x ≤2. You undoubtedly saw that almost all orbits
behaved in a rather haphazard fashion. In particular, you probably found very
few periodic or eventually periodic orbits (with the exception, perhaps, of the
ﬁxed points at 2 and −1 and the eventually ﬁxed points at −2, 0, and 1). Here
we will see that there are, in fact, many more periodic points for this function
that the computer missed.
Recall that all of the interesting dynamics of Qc take place in the interval
−p+ ≤x ≤p+ where p+ is the repelling ﬁxed point with p+ > 0. All other
orbits of Qc tend to inﬁnity. For c = −2, we have p+ = 2, so we will concentrate
on the interval [−2, 2] which, in this section, we will call I. The graph of Q−2 on
I is shown in Figure 7.1. Note that Q−2 is increasing on the interval [0, 2] and
takes this subinterval onto the entire interval I in one-to-one fashion. Similarly,
Q−2 is decreasing on the interval [−2, 0] and also takes this subinterval onto I
in one-to-one fashion. Thus every point (with the sole exception of −2) in I has
exactly two preimages in I: one in [−2, 0] and the other in [0, 2]. Geometrically,
you should think of Q−2 as ﬁrst stretching and folding the interval I and then
mapping it back over itself twice as depicted in Figure 7.2.
Now let’s turn to the graph of Q2
−2. Since one application of Q−2 takes the
interval [0, 2] onto I, the second iteration of Q−2 on this interval should fold
this interval over all of I exactly as Q−2 did on I. That is, with the exception
of −2, all points in I should have two preimages in [0, 2] under Q2
−2. Of course,
the same happens in the interval [−2, 0]. This is the reason why the graph of
Q2
−2 has exactly two “valleys” as shown in Figure 7.3a. Arguing similarly,
79

80
The Quadratic Family
FIGURE 7.1
The graph of Q−2 on the interval [−2, 2].
FIGURE 7.2
Q−2 folds I over itself so that each point (except −2) is covered twice.
there are four subintervals of I that are mapped by Q2
−2 exactly onto I, and
hence Q3
−2 must fold these intervals over I as before. So the graph of Q3
−2 has
four valleys in I as shown in Figure 7.3b.
Continuing in this fashion, we see that the graph of Qn
−2 has 2n−1 valleys
in the interval I. Hence this graph must cross the diagonal at least 2n times
over I. Later we will see that this graph crosses the diagonal exactly 2n times.
In any event, each crossing gives us a periodic point of (not necessarily prime)
period n, so we have proved the following:
Theorem. The function Q−2 has at least 2n periodic points of period n in the
interval −2 ≤x ≤2.
You should contrast this with the results we saw in Section 3.6. With the
computer you found very few periodic points for Q−2, yet we now know that

The Case c < –2
81
FIGURE 7.3
The graphs of higher iterates of Q−2 on [−2, 2].
there are inﬁnitely many of them. Clearly, more is going on for this function
than meets the eye.
This also raises an important question. For the quadratic family Qc, for
c-values larger than −5/4, we saw that there were very few periodic points.
On the other hand, by the time c reaches −2, inﬁnitely many periodic points
of all periods have arisen. The big question is: How did these periodic points
arise? Where did they come from? This too is one of the main questions we
will address in the succeeding chapters.
7.2
The Case c < –2
In Section 3.6 you also computed a variety of orbits of Qc when c < −2. You
most likely saw that nearly all orbits of Qc tended to inﬁnity in this case, so
it appears that the dynamical behavior in this case is relatively simple. As in
the previous section, we will see again that this is by no means the case.
For the remainder of this section we will ﬁx a particular c-value with
c < −2. It is important to note that many of the intervals described below
depend on which c-value is chosen, so we really should index everything with
a c. However, to keep the notation simple, we will avoid this.
In Figure 7.4 we show the graph of Qc for a c-value less than −2. In this
ﬁgure we also show a box whose vertices include the points (−p+, −p+) and
(p+, p+). Note that the graph of Qc protrudes through the bottom of this box,
unlike the previous cases. As before, we denote the interval −p+ ≤x ≤p+

82
The Quadratic Family
FIGURE 7.4
The graph of Qc for c < −2.
by I. Note that, unlike the case c = −2 where the point x = −2 had only
one preimage in I, here all points in I have exactly two preimages in I. Also,
graphical analysis shows that there is an open interval in I containing 0 that
is mapped outside of I by Qc. This interval is precisely the set of points lying
above the portion of the graph outside of the box. In particular, the orbit of
any point in this interval escapes from I and so tends to inﬁnity. Let’s call this
interval A1. A1 is the set of points that escape from I after just one iteration
of Qc (see Figure 7.5).
Now any orbit that eventually leaves I must tend to inﬁnity, so we under-
stand the fate of all these orbits. Therefore it remains to understand the fate
of orbits that never escape from I. Let us denote this set of points by Λ. That
is,
Λ = {x ∈I | Qn
c (x) ∈I for all n} .
The set Λ contains all of the interesting orbits of Qc. The ﬁrst question is:
What exactly is this set Λ? What does it look like? To answer this, we will
describe instead the complement of Λ. From Figure 7.6a, we see that there
are a pair of open intervals that have the property that, if x is in one of
these intervals, then Qc(x) ∈A1. Hence the orbit of x escapes from I after
two iterations. We call this pair of intervals A2. So if x ∈A2, it follows that
Qn
c (x) →∞and x ̸∈Λ. Continuing, from Figure 7.6b, we see that there are
four smaller open subintervals having the property that if x belongs to one of
these intervals, then Qc(x) ∈A2 and again the orbit of x escapes. We denote
the union of these intervals by A3. So A3 is the set of points that escape from
I after three iterations. Continuing in this fashion, let An denote the set of
points in I whose orbit leaves I after exactly n iterations. Since each point
in I has exactly two preimages in I, the set An consists of exactly 2n−1 open

The Case c < –2
83
FIGURE 7.5
Any orbit in the interval A1 tends to inﬁnity.
intervals. If a point has an orbit that eventually escapes from I, then this
point must lie in An for some n. Hence the complement of Λ in I is just the
union of the An for all n.
What does Λ look like? To construct Λ, we ﬁrst remove A1 from the interval
I, leaving two closed intervals behind. Then we throw out A2, which from
Figure 7.6 leaves us with four closed intervals. Then we remove A3, leaving
eight closed intervals. Continuing, when we remove An, we are left with 2n
closed intervals. The set Λ is what is left after we remove all of these open
intervals. This set is called a Cantor set.
Two questions immediately arise. First, are there any points left after we
throw out all of these intervals? The answer is yes, for the ﬁxed points at p±
certainly lie in Λ. Furthermore, the endpoints of each interval that remains
after removing the An are also in Λ, for these points are eventually ﬁxed (after
n iterations they land on −p+ and so after n + 1 iterations they land on the
ﬁxed point p+). We will see later that in fact there are many, many more
points in this set.
A second observation is that Λ contains no intervals. This is a little more
diﬃcult to see. In fact we will make a simplifying assumption that allows us
to prove this more easily. Let us assume that c < −(5 + 2
√
5)/4 = −2.368 . . ..
The eﬀect of this assumption is that |Q′
c(x)| > 1 for all x ∈I −A1. In Exercise
8 you are asked to verify this fact. In particular, there is a constant μ > 1
such that |Q′
c(x)| ≥μ for all x ∈I −A1.1
Now suppose that Λ contains an interval J. Let’s say that J has length
ℓ> 0. Since |Q′
c(x)| > μ > 1 for all x ∈J, it follows from the Mean Value
1Just let μ = Q′
c(x1) where x1 is the right-hand endpoint of A1. Since Q′′
c > 0, we have
Q′
c(x) > Q′
c(x1) if x > x1.

84
The Quadratic Family
FIGURE 7.6
The intervals (a) A2 and A1, (b) and A3 and A1.
Theorem that the length of Qc(J) exceeds μℓ. This is true since, for any two
points x and y in J, the Mean Value Theorem shows that
|Qc(x) −Qc(y)| > μ|x −y|
(see Section 5.4). Also, since J ⊂Λ, we also have Qc(J) ⊂Λ. Hence we may
apply the same argument to the interval Qc(J), and we therefore conclude that
the length of Q2
c(J) exceeds μ · length of Qc(J) > μ2ℓ. Continuing, we ﬁnd
that the length of Qn
c (J) is larger than μnℓ. But μ > 1 so μn →∞. Therefore,
the length of Qn
c (J) becomes arbitrarily large. However, the interval Qn
c (J)
must lie within I, which has ﬁnite length. This contradiction establishes the
result.
Finally, we observe that Λ is a closed subset of I. Indeed, the complement
of Λ consists of the open intervals (−∞, −p+), (p+, ∞), and all of the An.
Since the union of a collection of open intervals is open, it follows that the
complement of Λ is an open set and so Λ is closed. See Appendix A.3 for more
details on open and closed sets. Let’s summarize all of these facts:
Theorem. Suppose c < −2. Then the set of points Λ whose orbits under Qc
do not tend to inﬁnity is a nonempty closed set in I that contains no intervals.
Remarks:
1. This theorem is valid for all c-values less than −2. Our proof only works
for c < −(5 + 2
√
5)/4 = −2.368 . . . . The case of c-values closer to −2 is
considerably more diﬃcult and will be omitted.

The Cantor Middle-Thirds Set
85
FIGURE 7.7
Construction of the Cantor middle-thirds set.
2. A subset of R that contains no intervals is called totally disconnected. We
will meet many such sets in the sequel, including the next section where we
investigate the prototype of such sets, the Cantor middle-thirds set.
7.3
The Cantor Middle-Thirds Set
In this section we will discuss the construction of the classical Cantor middle-
thirds set, or Cantor set for short. While this set may seem quite “pathological”
at ﬁrst, we will see that these kinds of sets arise over and over again in dynam-
ics. Moreover, the Cantor set is the most basic kind of fractal, a topic we will
investigate in detail in Chapter 14.
To construct this set we begin with the interval 0 ≤x ≤1. From this
interval we remove the middle third: the open interval 1
3 < x < 2
3. Note that
we leave the endpoints behind. What remains is a pair of closed intervals, each
of them one-third as long as the original. Now do this again: From each of
the remaining intervals we remove the middle third. That is, from the interval
0 ≤x ≤1
3, we remove 1
9 < x < 2
9, and from 2
3 ≤x ≤1 we remove 7
9 < x < 8
9.
Note that, in each case, we have again left behind the endpoints; now four
closed intervals remain, each one-ninth as long as the original interval.
We now repeat this process over and over. At each stage, we remove the
middle third of each of the intervals remaining at the previous stage. What is
left in the limit is the Cantor middle-thirds set, which we denote by K. See
Figure 7.7.
Note how similar this construction is to the construction of the set Λ in the
previous section. Indeed, it is easy to check that K is closed (same argument
as before) and totally disconnected. Certainly there are a lot of points in K;
any endpoint of one of the removed middle-thirds intervals is in K. One of the
remarkable features of the Cantor set is the fact that there are many, many
more points in K that are not endpoints. In fact, K is an uncountable set.

86
The Quadratic Family
To explain this concept, we recall that a set is called countable if it can
be put in one-to-one correspondence with the set of positive integers, that is,
we can enumerate the points in the set. A set is uncountable if it is neither
ﬁnite nor countable. For example, the set of rational numbers is a countable
set whereas the set of all real numbers, the set of all irrationals, and any inter-
val (a, b) with a ̸= b are uncountable. In general, countable sets are “small”
compared to uncountable sets.
To see that the Cantor set is uncountable, we make a brief digression into
ternary expansions of real numbers. Recall that the geometric series
∞

i=0
ai = 1 + a + a2 + a3 + · · ·
converges absolutely if |a| < 1 and, in fact,
∞

i=0
ai =
1
1 −a.
More generally,
∞

i=k
ai =
ak
1 −a.
For example,
∞

i=0
2
3
i
= 3
and
∞

i=1
1
3
i
=

1
3
1 −1
3

= 1
2.
Now suppose for each positive integer i, si is either 0, 1, or 2. Then the
series
∞

i=1
si
3i
is dominated by the convergent geometric series
∞

i=1
2
3i = 2

1
3
1 −1
3

= 1
in the sense that
0 ≤si
3i ≤2
3i
for each i. Hence, by the Comparison Test, this series converges, and we have
0 ≤
∞

i=1
si
3i ≤1.

The Cantor Middle-Thirds Set
87
Deﬁnition. The sequence of integers 0.s1s2s3 . . . where each si is either 0,1,
or 2 is called the ternary expansion of x if
x =
∞

i=1
si
3i .
Example. The sequence 0.020202 . . . is the ternary expansion of 1/4 since
0
31 + 2
32 + 0
33 + 2
34 + · · · = 2
 ∞

i=1
1
9
i
= 1
4.
The sequence 0.012012012 . . . is the ternary expansion for 5/26 since
0
31 + 1
32 + 2
33 + 0
34 + 1
35 + 2
36 + · · · = 1
32 + 1
35 + · · · + 2
33 + 2
36 + · · ·
= 1
9
∞

i=0
 1
27
i
+ 2
27
∞

i=0
 1
27
i
= 5
26.
Note that certain x-values in [0, 1] may have two diﬀerent ternary expan-
sions. For example, 1/3 has expansions 0.10000 . . . and 0.02222 . . . since
∞

i=2
2
3i = 2
9
∞

i=0
1
3
i
= 1
3.
Similarly, 8/9 has expansion 0.220000 . . . as well as 0.212222 . . . since
2
3 + 1
9 +
∞

i=3
2
3i = 7
9 + 2
27
∞

i=0
1
3i = 8
9.
This is similar to the problem that occurs for binary expansions where
sequences of 0’s and 1’s of the form 0.s1 . . . sn10000 . . . and 0.s1 . . . sn01111 . . .
represent the same numbers. For ternary expansions, it is easy to check that
the sequences of the form 0.s1 . . . sn10000 . . . and 0.s1 . . . sn02222 . . . repre-
sent the same number. Also, the two sequences of the form 0.s1 . . . sn20000 . . .
and 0.s1 . . . sn12222 . . . correspond to the same number. Note that the num-
bers for which these ambiguities occur are precisely the numbers with ﬁnite
ternary expansion 0.s1 . . . sk0000 . . . for some k, which in turn are precisely
the rational numbers that may be written in the form
p
3k for some integer p
with 0 ≤p < 3k.
How do we ﬁnd the ternary expansion of a number? We will see an easy
method later that involves dynamics, but for now we simply note that if x has
ternary expansion 0.s1s2 . . ., then the digit s1 determines which third of the

88
The Quadratic Family
interval [0, 1] x lies in. If s1 = 0, then x ∈[0, 1
3]; if s1 = 1, then x ∈[ 1
3, 2
3]; and
if s1 = 2, then x ∈[ 2
3, 1]. The reason for this is that the “tail” of the series
representing x, namely
∞

i=2
si
3i
is no larger than
∞

i=2
2
3i = 1
3.
Notice that the ambiguous x-values are exactly those that share two ternary
representations. So given the digit s1, we know which third of the unit interval
x lies in: the left third if s1 = 0, the middle third if s1 = 1, and the right third
if s1 = 2.
Arguing exactly as above, we see that the second digit s2 tells us which
third of these subintervals x lies in. That is, s2 determines the left, middle,
or right third of the interval determined at the previous stage. As above, the
reason is that the series
∞

i=3
si
3i ,
which represents the tail of the ternary expansion, is in this case no larger
than 1/9. Continuing in this fashion, we see that ternary expansions have a
direct relationship to points in the Cantor set. In particular, if x has ternary
expansion for which some entry sn = 1, then x must lie in one of the middle-
thirds intervals that was removed during the construction of K. The only
exception to this is if x is an endpoint of this interval, in which case x has
an alternative ternary expansion that has no 1’s whatsoever. Thus we may
say that the Cantor set is the set of real numbers in [0, 1] for which there is a
ternary expansion containing no 1’s.
We now see why the Cantor set is uncountable. We can set up a corre-
spondence between points in the Cantor set and points in the interval [0, 1]
as follows. Given x ∈K, consider the ternary expansion of x that contains
no 1’s. Then change every “2” in this expansion to a “1” and consider the
resulting sequence as the binary expansion of a number in [0, 1]. For example,
the ternary expansion of 1/4 is 0.020202 . . . as we saw above. So 1/4 ∈K. We
now associate to 1/4 the binary sequence 0.010101 . . . which corresponds to
1/3 since
∞

i=1
1
4
i
= 1
3.
So we can associate every point in the unit interval with at least one point
in K. As another example, the ternary expansion of the endpoint 1/3 in K is
.02222 . . ., so we may associate this point to 1/2, whose binary expansion is
.01111 . . .. Note that the endpoint 2/3 ∈K has ternary expansion .20000 . . .,
so this point may also be associated with 1/2. In any event, for every point in

The Cantor Middle-Thirds Set
89
the interval [0, 1], we may associate at least one point in K with this point.
Thus we have proved the following:
Theorem. The Cantor middle-thirds set is uncountable.
A natural question is whether or not the Cantor middle-thirds set and our
dynamically deﬁned set Λ for the quadratic map are essentially the same, or
are homeomorphic. (See Appendix A.1.) We will see that they are, but we will
use a more powerful tool to show this. This tool is symbolic dynamics, which
we will discuss in Chapter 9.
Exercises
1. List the intervals that are removed in the third and fourth stages of the
construction of the Cantor middle-thirds set.
2. Compute the sum of the lengths of all of the intervals that are removed
from the interval [0, 1] in the construction of the Cantor middle-thirds set.
What does this say about the total length of the Cantor middle-thirds set
itself?
In the next ﬁve exercises, ﬁnd the rational numbers whose ternary expansion
is given by:
3. 0.212121
4. 0.022022022
5. 0.00222
6. 0.2120101
7. 0.0101101101
8. Let Qc(x) = x2 +c with c < −2. Let I and A1 be deﬁned as in this chapter.
Prove that if c < −(5 + 2
√
5)/4, then |Q′
c(x)| > 1 for all x ∈I −A1. Hint:
Note that |Q′
c(x)| > 1 for all x > 1/2, so it suﬃces to ﬁnd the c-values for
which Qc(1/2) < −p+.
Dynamics on the Cantor middle-thirds set: The following exercises deal
with the function
T(x) =

3x
if x ≤1/2
3 −3x
if x > 1/2.
9. Sketch the graph of T and show by graphical analysis that, if x > 1 or
x < 0, then T n(x) →−∞as n →∞.
10. Find the ﬁxed points for T. What is the ternary expansion of these points?
11. Show that 3/13 and 3/28 lie on 3-cycles for T.
12. Show that if x ∈(1/3, 2/3), then T n(x) →−∞as n →∞.

90
The Quadratic Family
13. Show that if x ∈(1/9, 2/9) or x ∈(7/9, 8/9), then T n(x) →−∞as
n →∞.
14. Let Γ = {x ∈[0, 1] | T n(x) ∈[0, 1] for all n}. Prove that Γ = K, the
Cantor middle-thirds set.
15. Suppose x ∈Γ has ternary expansion 0.a1a2a3 . . . . What is the ternary
expansion of T(x)? Be careful: there are two very diﬀerent cases!
The Logistic Map: The following four exercises deal with the logistic map
Fλ(x) = λx(1 −x).
16. Prove that F4 has at least 2n periodic points of (not necessarily prime)
period n in the interval [0, 1].
17. Prove that if x > 1 or x < 0, then F n
4 (x) →−∞as n →∞.
18. Prove that if x ∈[0, 1], F n
4 (x) ̸→−∞as n →∞.
19. In an essay, describe the dynamics of Fλ when λ > 4. In the essay describe
the set of points whose orbit tends to −∞. Can you ﬁnd a λ-value for which
|F ′
λ(x)| > 1 for all x whose orbits do not escape?
20. Consider the function S(x) = π sin x. Prove that S has at least 2n periodic
points of period n in the interval [0, π].
21. Show that the function T(x) = x3 −3x has at least 3n periodic points of
period n in the interval [−2, 2].
22. Which of the following real numbers lie in the Cantor middle-thirds set?
a. x = 1/4
b. x = 1/13
c. x = 2/243
d. x = 1/243
e. x = 26/27
f. x = 3/4
g. x = π
h. x = 1/3100
i. x = 2/3100
j. x = 4/3100
23. A point in the Cantor middle-thirds set is an called an “endpoint” if it
is one of the points on the boundary of one of the removed open intervals in
[0, 1]. In the previous exercise, which of these points are endpoints?
24. How do you determine which point in the Cantor middle-thirds set is an
endpoint and which point is not an endpoint?
25. The Cantor middle-thirds set can be divided into two distinct subsets,
the set of endpoints and the set of non-endpoints. Which of these sets is the
“larger” set? And why is this the case?

8
Transition to Chaos
In previous chapters we have investigated the dynamics of Qc(x) = x2 + c
at length. We have seen that for c-values above −5/4 the dynamics of this
function are quite tame. On the other hand, by the time c reaches −2, the
dynamics become much more complicated. Our goal in this and the next
few sections is to understand how Qc and other similar functions make the
transition from simple to complicated dynamics.
8.1
The Orbit Diagram
In this section, all of our work will be experimental. We will make a series of
observations based on computer images. We will spend much of the rest of
this book trying to explain what we have seen here.
We will deal here with the orbit diagram. This image is one of the most
instructive and intricate images in all of dynamical systems. The orbit diagram
is an attempt to capture the dynamics of Qc for many diﬀerent c-values in
one picture. The result gives a good summary of the dynamics of the entire
family as well as an idea of how Qc makes the transition to chaos.
In the orbit diagram we plot the parameter c on the horizontal axis versus
the asymptotic orbit of 0 under Qc on the vertical axis. By asymptotic orbit
we simply mean that we do not plot the ﬁrst few iterations (usually 100 or
so) of 0. This allows the orbit to settle down and reach its eventual behavior;
thus we can see the “fate” of the orbit. By not plotting the ﬁrst few iterations,
we have eliminated the “transient behavior” of the orbit.
For the orbit diagram of Qc we initially choose the parameter c in the
range −2 ≤c ≤1/4 since, as we will see in the next two chapters, we
understand the dynamics of Qc completely when c is outside this interval.
We plot the asymptotic orbit of 0 under Qc on the vertical line over c. As
we know, the orbit of 0 remains in the interval [−2, 2] for these c-values,
so the coordinates on the vertical axis run from −2 to 2. Incidentally, this
is the picture you computed by hand in Section 6.4. An applet to gener-
ate this orbit diagram (as well as several others) is available at the website
math.bu.edu/DYSYS/applets/OrbitDgm.html.
91

92
Transition to Chaos
A natural question is why do we use the orbit of 0 to plot the orbit diagram.
We will see the real answer to this question in Chapter 12. For now, we simply
note that 0 is the only critical point of Qc.
Deﬁnition. Suppose F : R →R. A point x0 is a critical point of F if F ′(x0) =
0. The critical point x0 is nondegenerate if F ′′(x0) ̸= 0. Otherwise, the critical
point is degenerate.
For example, 0 is the only critical point for Qc, and it is nondegenerate.
Similarly, 1/2 is the only critical point of the logistic function Fλ(x) = λx(1−
x) (provided λ ̸= 0), and it too is nondegenerate. On the other hand, F(x) =
x3 has a degenerate critical point at 0, as does x4.
In Figure 8.1 we have displayed the full orbit diagram of Qc. Note that for c
in the range −3/4 ≤c ≤1/4, we see exactly one point on the vertical line over
c. We know why this happens: for these c-values, the orbit of 0 is attracted
to an attracting ﬁxed point, and this single point corresponds to this ﬁxed
point. As c decreases below −3/4 we see a period-doubling bifurcation: a new
attracting cycle of period 2 is born and the two points in the orbit diagram
above these points correspond to this cycle. Note that in the orbit diagram
we no longer see the repelling ﬁxed point as we do in the bifurcation diagram.
This is one of the main diﬀerences between these two images. Continuing to
decrease c, we seem to see a succession of period doublings. In Figure 8.1 the
portion of the orbit diagram inside the rectangular box in the original orbit
diagram above is magniﬁed, and Figure 8.2 contains successive magniﬁcations
of the rectangles in the previous ﬁgures. This leads to our ﬁrst observation.
Observation 1: As c decreases, we seem to see a succession of period-doubling
bifurcations. It seems that periodic points ﬁrst appear in the order
1, 2, 4, 8, . . . , 2n, . . . .
Note the large vertical white region toward the left in Figure 8.1. If you
look closely, you see that this region is not completely white but rather is
crossed by three tiny black regions at the top, middle, and bottom. For this
reason, this region is called the period-3 window. In Figure 8.3 this window
is magniﬁed. We see clearly what appears to be an attracting 3-cycle, which
then seems to undergo a sequence of period-doubling bifurcations. Figure 8.3
also shows the central portion of this window magniﬁed to make the period-
doublings plainly visible. There are other windows visible in all of these ﬁgures.
Magniﬁcations of these windows always yield the same surprising result: we
seem to see an initial periodic orbit of some period n followed by a succession
of period-doubling bifurcations. We call these regions period-n windows.
Observation 2: In each period-n window, we seem to see the appearance of
an attracting n-cycle followed by a succession of period-doubling bifurcations.

The Orbit Diagram
93
FIGURE 8.1
The orbit diagram for Qc(x) = x2 + c and a magniﬁcation.
One very obvious feature of the magniﬁcations in Figures 8.1 and 8.2 is the
similarity of these images. Neglecting for the moment the fact that the single
curve in the right of each picture represents a periodic point of period 1, 2, 4,
and 8, respectively, we see that the images in these successive magniﬁcations
are qualitatively the same. Note the appearance of a “period-3 window” to
the left in each image.
Observation 3: The orbit diagram appears to be self-similar: when we mag-
nify certain portions of the picture, the resulting image bears a striking resem-
blance to the original ﬁgure.
Of course, the words “striking resemblance” in this observation are not
very precise in a mathematical sense. We will have to describe this notion

94
Transition to Chaos
FIGURE 8.2
Further successive magniﬁcations of the orbit diagram of Qc(x) = x2 + c.
more fully later. But for now, there is no question that the orbit diagram
possesses a striking amount of self-similarity.
Note that the curves connecting what appear to be periodic orbits are
continuous as c varies—these curves never suddenly jump indicating the co-
existence of another attracting cycle. That is, for each c-value, it appears that
there is at most one attracting cycle. Of course, since we only compute one
orbit for each c-value, there may be other attracting orbits present that we
do not see since 0 is not attracted to them. Nevertheless, it is interesting that
no jumps occur among the periodic cycles that we do see.
Observation 4: It appears that there is at most one attracting cycle for each
Qc.

The Orbit Diagram
95
FIGURE 8.3
The period 3 window for Qc and a magniﬁcation.
Finally, note that there is a large proportion of c-values for which the orbit
of 0 does not seem to settle down on an attracting cycle. Even if we increase
the number of iterations as well as the number of iterations not plotted, this
regime remains quite large. This is another glimpse of chaotic behavior.
Observation 5: It appears that there is a large set of c-values for which the
orbit of 0 is not attracted to an attracting cycle.
It may appear that the orbit diagram for Qc is a rather special object.
For other functions, we might expect a completely diﬀerent image when we
perform the same experiment. Figure 8.4 displays the orbit diagram for the
logistic family Fλ(x) = λx(1 −x) with 1 ≤λ ≤4 and 0 ≤x ≤1. For this
family we have again plotted the parameter versus the asymptotic orbit of the

96
Transition to Chaos
critical point, which in this case is 1/2. Although the whole image is reversed,
note how similar this diagram is to the diagram for the quadratic function.
In the exercises we ask you to use a computer to plot the orbit diagrams for
other interesting families of functions.
FIGURE 8.4
The orbit diagram for the logistic family Fλ(x) = λx(1 −x).
8.2
The Period-Doubling Route to Chaos
Our goal in this section is to give a geometric reason for why we see an initial
sequence of period doublings in the orbit diagram. We will give a more rigorous
explanation of this in Chapter 11 when we describe Sharkovsky’s Theorem.
Our methods here, involving successive magniﬁcations of the graphs of Q2n
c ,
come close to the ideas of renormalization group analysis from theoretical
physics.
In Figure 8.5 we have plotted the graphs of Qc for six diﬀerent c-values.
In each case we have superimposed a square on the graph with vertices at
(p+, p+) and (−p+, −p+). The six diﬀerent c-values chosen exhibit dynamical
behavior that we have already studied, namely:
a. Saddle-node bifurcation point.
b. Critical point is ﬁxed.
c. Period-doubling bifurcation point.
d. Critical point has period 2.
e. Chaotic c-value.
f. Cantor set case.

Experiment: Windows in the Orbit Diagram
97
Figure 8.6 shows the graphs of Q2
c for six diﬀerent c-values. These values
are not the same as those in Figure 8.5; however, note the portions of the
graphs inside the small boxes. They resemble very closely the corresponding
portions of the graph of Qc in Figure 8.5, only on a much smaller interval. To
be precise, recall that the left-hand ﬁxed point of Qc is denoted p−. From the
graph of Q2
c, we see that there is a point to the left of p−that is mapped by Q2
c
to p−. Call this point q. This is the point that lies on the x-axis directly above
the left-hand edge of the boxes in Figure 8.6. Then Figures 8.5 and 8.6 show
that there is a resemblance between the graphs of Qc on the interval [−p+, p+]
and those of Q2
c on [q, p−]. In particular, we would expect the function Q2
c to
undergo a similar sequence of dynamical behaviors on this interval as Qc did
on the larger interval. Comparing the magniﬁed portion of the orbit diagram
in Figure 8.1 to the whole diagram in that ﬁgure, we see that this indeed
appears to be the case.
Now consider the graphs of Q2
c restricted to [q, p−]. Since these graphs each
resemble one of the quadratic functions, we expect its second iterate on the
small interval to look like the second iterate of one of the original quadratic
functions on [−p+, p+]. In particular, there should be a small subinterval of
[q, p−] on which Q4
c looks like Qc. As c decreases, we would then expect Q4
c to
undergo the same sequence of bifurcations on this smaller interval as Q2
c and
Qc on the larger intervals. Figure 8.2 bears this out.
This is the beginning of a process called renormalization [27]. At each
stage of the process, we consider the second iterate of the map at the previous
stage and then zoom in on a small subinterval on which the map resembles a
quadratic function. At the nth stage, we ﬁnd a tiny subinterval on which Q2n
c
resembles the original function. In particular, as c decreases, the graphs of
the Q2n
c
make the transition from a saddle-node bifurcation (actually, this is a
period-doubling bifurcation viewed from one side), through a period doubling,
and on into the chaotic regime. This accounts for the fact that the orbit
diagram features regions that are apparently self-similar.
8.3
Experiment: Windows in the Orbit Diagram
Goal: The goal of this experiment is twofold. The ﬁrst object is for you to
see the remarkable structures and patterns that occur in the orbit diagram.
The second aim is to investigate the similarities and diﬀerences between two
typical orbit diagrams, for the quadratic function Qc(x) = x2 + c and the
logistic function Fλ(x) = λx(1 −x). Recall that a period k window in the
orbit diagram consists of an interval of parameter values for which we ﬁnd
an initial attracting period k cycle together with all of its period-doubling
“descendants.” For example, in the big picture of the quadratic family’s orbit
diagram, we clearly see a period 1 window and a period 3 window. Remember,

98
Transition to Chaos
FIGURE 8.5
Graphs of Qc.

Experiment: Windows in the Orbit Diagram
99
FIGURE 8.6
Graphs of Q2
c.

100
Transition to Chaos
FIGURE 8.7
Windows in the orbit diagram of Qc.
“period” here means the period of the attracting orbit before it begins to period
double. See Figure 8.7.
Procedure: The object of this experiment is to catalog a number of smaller
windows in the orbit diagrams of both Qc(x) = x2 +c and Fλ(x) = λx(1−x).
Clearly, the period-1 and -3 windows are the most visible for each of the two
families. Now magnify the region between these two windows for the quadratic
family. What do you see? The two largest windows are clearly of period 5
and 6. This is the “second generation” of windows. There are other smaller
windows visible, but we record only the two widest windows at this time. We
will record this as follows:
Quadratic function:
Generation 1: 3
1
Generation 2: 3
5
6
1
Note that we put these windows in the right order. Now go to the next
generation. Find the periods of the two “largest” windows between the period-
1 and -6 window. Call these periods A and B. Then ﬁnd the periods of the
largest windows between the period-5 and -6 windows. Between the period-3
and -5 windows, there should only be one largest window, so ﬁnd its period.
You should thus be able to ﬁll in this chart by supplying the periods A–E,
which represent the periods of the largest windows in the order given.
Quadratic function:
Generation 3: 3
E
5
D
C
6
B
A
1

Experiment: Windows in the Orbit Diagram
101
Now proceed to generation 4. In this case we will ﬁnd only the largest
windows between the period-6 and period-1 windows found in the third gen-
eration, including the windows between period 6 and period B, period B and
period A, and ﬁnally period A and period 1. The largest windows have periods
α-ϵ as indicated in the following chart:
Quadratic function:
Generation 4: 6
ϵ
B
δ
γ
A
β
α
1
Notes and Questions:
1. The periods of the windows near the left end of this chart may be a judgment
call: you don’t need to spend hours trying to ﬁgure out which window is
biggest. Just eyeball it! Also, you may have to magnify the individual windows
in order to read oﬀthe periods.
2. Do this for both Qc(x) = x2 + c and Fλ(x) = λx(1 −x) and then compare
your charts for both of them. Are there any diﬀerences? Any similarities?
Write a short paragraph about this.
3. Is there a discernible pattern (especially near the period-1 end of your
chart)? What is it?
4. Using this pattern, can you predict what the period-1 end of the list at
generation 5 will be? Perhaps from the period-1 to the period-A window?
5. Thought question. Do you see the “darker” curves running through the orbit
diagram? What do you think they represent?
Exercises
For each of the following exercises, use a computer to display the corresponding
orbit diagram for the given λ and x intervals. Be sure to use the critical point
that lies in the given x-interval to plot the diagram. There are some applets
available at the website math.bu.edu/DYSYS/applets/OrbitDgm.html to
help you with this, if needed. There are some obvious diﬀerences between
these orbit diagrams and the orbit diagram for the quadratic family. Can you
explain what causes these diﬀerences?
1. Sλ(x) = λ sin(x), 1 ≤λ ≤π, 0 ≤x ≤π.
2. Pλ(x) = λx2(2 −x2), −2 ≤x ≤2.
3. Fλ(x) = λx(1 −x2/3), −3 ≤x ≤3.
The following ﬁve exercises deal with the family of functions Cλ(x) = λ cos(x).
4. Use the computer to sketch the orbit diagram for 1 ≤λ ≤2π, |x| ≤2π
using 0 as the critical point (again available at the above website). Describe
what you see.

102
Transition to Chaos
5. Explain the dramatic bifurcation that occurs at λ = 2.96 . . . .
6. Explain the dramatic bifurcation that occurs at λ = 4.188 . . . .
7. What happens if we use the critical point π instead of 0 to plot the orbit
diagram? Why?
8. What happens if we let λ > 2π? Discuss other dramatic bifurcations that
occur.
The next two exercises deal with the family of functions λx(1 −x)(1 −2x)2.
9. Use the computer to sketch the orbit diagram for 0 ≤λ ≤16 and 0 ≤x ≤1
using 1
2 +
√
2
4 = 0.8535533 . . . as the critical point. Describe what you see.
10. Using the graphs of these functions, explain the dramatic bifurcation that
occurs at λ = 13.5 . . . .
The next three exercises deal with the family of “tent maps” given by
Tc(x) =

cx
if 0 ≤x ≤1
2
−cx + c
if 1
2 < x ≤1.
11. Use the computer to sketch the orbit diagram for Tc for 0 ≤c ≤2. Use 1/2
as the “critical point,” since this is the point where Tc is non-diﬀerentiable.
Describe what you see.
12. Explain the dramatic bifurcation that occurs at c = 1.
13. Why do you not see any attracting cycles when 1 ≤c ≤2?
All of the following exercises are really essay questions. In each case, provide
graphical or numerical evidence for your answer.
14. In the orbit diagram in Figures 8.1 through 8.3, notice that there is
a “smear” near each point where a bifurcation occurs. What causes these
smears?
15. In Figure 8.8 the orbit diagram of the logistic function is plotted. Instead
of using the critical point to plot the diagram, however, we used another initial
seed, x0 = 0.123 . . . . Note the change in the diagram. Can you explain what
has happened? We will see why this does not occur when we use the critical
point in Chapter 12.
16. In Figure 8.3, note the sudden appearance of the period-3 cycle and its
window. Explain why this window opens so suddenly.
17. In Figure 8.3, the period-3 window also closes abruptly. Explain why the
orbit of 0 suddenly occupies a much larger interval as the period-3 window
closes.

Experiment: Windows in the Orbit Diagram
103
FIGURE 8.8
The orbit diagram for the logistic function using the initial seed x0 = 0.123 . . ..
18. In all of the orbit diagrams in Figures 8.1 through 8.3, there are some
very obvious darker “curves” running through the orbit diagram. Explain
what these curves are. Why does the orbit of 0 seem to accumulate on these
points? Hints: Compare the histograms for various c-values to the slice of the
orbit diagram for the corresponding c’s. Compute the orbit diagram using
only a few points on the orbit of 0 without throwing away any of these points.


9
Symbolic Dynamics
In this chapter we will introduce one of the most powerful tools for under-
standing the chaotic behavior of dynamical systems, symbolic dynamics. We
will convert the complicated behavior that we have seen for certain quadratic
functions to what appears at ﬁrst to be a completely diﬀerent dynamical sys-
tem. However, we will see that the two systems are really the same and that,
more importantly, we can understand the new system completely.
This chapter is more theoretical than the preceding chapters. We introduce
a new level of abstraction involving a “space” of sequences and a mapping on
this space that will later serve as a model for the quadratic maps. We will
see in the next section that this abstraction is totally justiﬁed when we show
that iteration of our model mapping can be completely understood. This is in
contrast to the quadratic case which is impossible to deal with analytically.
9.1
Itineraries
In this section we will deal exclusively with a quadratic function Qc = x2 + c
where c < −2. Recall that for such a function all of the interesting dynamics
occurred on the interval I = [−p+, p+]. Here p+ is the ﬁxed point of Qc given
by
p+ = 1
2

1 +
√
1 −4c

.
In this interval there is a subinterval A1 that consists of all points that leave
I under one iteration of Qc. The set Λ of all points x ∈I whose orbits never
leave I therefore lies in I −A1. The set I −A1 consists of two closed intervals
that we denote by I0 and I1 with I0 to the left of I1. Remember that both I0
and I1 actually depend on c, and for each c < −2 these intervals are disjoint
and symmetrically located about 0.
Any point in Λ has an orbit that never leaves I and hence remains for all
iterations in I0 ∪I1. So if x ∈Λ, Qn
c (x) ∈I0 ∪I1 for each n. This allows us to
make the following important deﬁnition:
105

106
Symbolic Dynamics
Deﬁnition. Let x ∈Λ. The itinerary of x is the inﬁnite sequence of 0’s and
1’s given by
S(x) = (s0s1s2 . . .),
where sj = 0 if Qj
c(x) ∈I0 and sj = 1 if Qj
c(x) ∈I1.
For example, the ﬁxed point p+ lies in I1 for all iterations, so p+ has the
itinerary S(p+) = (1111 . . .). Similarly, the eventually ﬁxed point −p+ has
itinerary S(−p+) = (01111 . . .). Note that any periodic point has an itinerary
that is a repeating sequence. A more general itinerary is shown in Figure 9.1.
FIGURE 9.1
The itinerary of x0 is S(x0) = (001011 . . .).
9.2
The Sequence Space
To set up a model system for the dynamics of Qc on Λ, we need to have a
“space” on which the dynamical system takes place. Unlike all of the previous
dynamical systems we have discussed, this model system will not reside on
the real line. Rather, it will take place on a much more abstract space called
the sequence space.
Deﬁnition. The sequence space on two symbols is the set
Σ = {(s0s1s2 . . .) | sj = 0 or 1}.
The set Σ consists of all possible sequences of 0’s and 1’s. That is, ele-
ments of Σ are sequences, not numbers. For example, (0000 . . .), (010101 . . .),
(101010 . . .), and (1111 . . .) are all distinct elements of Σ.
We are going to try to work geometrically with the space Σ. That means
we have to know what this space looks like. At ﬁrst, this may sound like an
unattainable goal. After all, the elements of Σ are sequences, not numbers that
ﬁt conveniently on a line or points that live in the plane or three-dimensional

The Sequence Space
107
space. However, we will see that, with a little metric space theory, we can
actually develop a mental image of what Σ looks like.
Let’s begin rather naively. Suppose we try to identify Σ as some subset of
the plane. Who knows what Σ would look like in the plane? Maybe a triangle
or a square or even a banana. Whatever our picture of Σ is, each “point” in Σ
must be a sequence. That is, abstractly, we should think of the entire string
of digits representing a sequence in Σ as corresponding to one point in this
picture. Perhaps Σ is the image sketched in Figure 9.2. If so, then each point
in this “space” must be a sequence of 0’s and 1’s, and two distinct points
should be two diﬀerent sequences, as indicated in the ﬁgure.
FIGURE 9.2
Perhaps the space Σ is a smiley face.
We should also be able to recognize certain subsets of Σ. For example, the
set
M0 = {s ∈Σ | s0 = 0}
consists of all sequences whose zeroth entry is 0. Its complement is
M1 = {s ∈Σ | s0 = 1}.
Roughly speaking, M0 and M1 divide Σ into equal halves, perhaps as depicted
in Figure 9.3. Similarly,
M01 = {s ∈Σ | s0 = 0, s1 = 1}
M00 = {s ∈Σ | s0 = 0, s1 = 0}
divide M0 into equal halves as shown in Figure 9.4.
Of course, given what we know so far (just the deﬁnition of Σ), we really
have no earthly way of understanding what this set and its subsets look like.
What we need is some way of determining when two points are close together

108
Symbolic Dynamics
FIGURE 9.3
M0 and M1 each occupy half of Σ.
FIGURE 9.4
M00 and M01 each occupy half of M0.
and when they are far apart. That is, we need a way to measure distances
between two points in the set. Mathematically, this means we need a metric
on the set. Now there are many ways to put a metric on a set, just as in
real life where there are many ways to measure distances, such as the straight
line distance between two points (“as the crow ﬂies”) or the distance between
the same two points as displayed on a car’s odometer. We choose to put the
following metric on Σ.
Deﬁnition. Let s = (s0s1s2 . . .) and t = (t0t1t2 . . .) be two points in Σ. The
distance between s and t is given by
d[s, t] =
∞

i=0
|si −ti|
2i
.

The Sequence Space
109
This may look like a complicated expression, but it is often easy to compute
this sum. For example, let s = (000 . . .), t = (111 . . .), and u = (010101 . . .).
Then
d[s, t]
=
∞

i=0
1
2
i
=
1
1 −1
2
= 2
d[t, u]
=
1 + 1
22 + 1
24 + · · ·
=
∞

i=0
1
4
i
= 4
3
d[s, u]
=
1
2 + 1
23 + 1
25 + · · ·
=
1
2
∞

i=0
1
4
i
= 2
3.
Note that the series deﬁning d[s, t] always converges. Indeed, si and ti are
each either 0 or 1, so |si −ti| = 0 or 1. Therefore, this series is dominated
by the geometric series ∞
i=0(1/2)i, which converges to 2. Thus the farthest
apart any two points in Σ may be is 2 units, as in the ﬁrst example above.
Deﬁnition. A function d is called a metric on a set X if for any x, y, z ∈X
the following three properties hold:
1. d[x, y] ≥0, and d[x, y] = 0 if and only if x = y.
2. d[x, y] = d[y, x].
3. d[x, z] ≤d[x, y] + d[y, z].
The pair X, d is called a metric space.
This last property, an important one, is called the triangle inequality.
Notice that all three of these properties are familiar properties of the usual
metric or distance function in Euclidean space.
Proposition. The distance d on Σ given by
d[s, t] =
∞

i=0
|si −ti|
2i
is a metric on Σ.
Proof: Let s = (s0s1s2 . . .), t = (t0t1t2 . . .) and u = (u0u1u2 . . .). Clearly,
d[s, t] ≥0 and d[s, t] = 0 if and only if s = t. Since |si −ti| = |ti −si|, it

110
Symbolic Dynamics
follows that d[s, t] = d[t, s]. Finally, for any three real numbers si, ti, ui, we
have the usual triangle inequality
|si −ti| + |ti −ui| ≥|si −ui|
from which we deduce that
d[s, t] + d[t, u] ≥d[s, u].
This completes the proof.
The reason we introduced the metric d was to decide when two sequences
in Σ were close together. The next theorem settles this issue.
The Proximity Theorem. Let s, t ∈Σ and suppose si = ti for i =
0, 1, . . . , n. Then d[s, t] ≤1/2n. Conversely, if d[s, t] < 1/2n, then si = ti
for i ≤n.
Proof. If si = ti for i ≤n, then
d[s, t]
=
n

i=0
|si −si|
2i
+
∞

i=n+1
|si −ti|
2i
=
∞

i=n+1
|si −ti|
2i
≤
∞

i=n+1
1
2i
=
1
2n .
On the other hand, if sj ̸= tj for some j ≤n, then we must have
d[s, t] ≥1
2j ≥1
2n .
Consequently, if d[s, t] < 1/2n, then si = ti for i ≤n.
In words, two sequences are close if their ﬁrst few entries agree. In par-
ticular, we can guarantee that two sequences are within 1/2n of each other if
their ﬁrst n entries are the same.
This proposition shows that our naive picture of Σ in Figures 9.2 through
9.4 is not quite correct. For example, any point in M0 must be at least 1 unit
away from any point in M1, since the initial entries of these sequences disagree.
Similarly, any point in M00 must be at least 1/2 unit away from a point in
M01 (see Figure 9.5). Continuing in this fashion, we see that our picture of
Σ cannot contain any planar regions—any such region must eventually be
subdivided into inﬁnitely many disjoint pieces. This is, of course, reminiscent
of the totally disconnected Cantor set we encountered previously. We will
make this analogy precise later.

The Shift Map
111
FIGURE 9.5
The metric d cuts Σ into disjoint pieces.
9.3
The Shift Map
Now that we have the space that will be the setting for our model dynamical
system, it is time to introduce the model mapping itself. This is the shift map
on Σ.
Deﬁnition. The shift map σ: Σ →Σ is deﬁned by
σ(s0s1s2 . . .) = (s1s2s3 . . .).
That is, σ simply drops the ﬁrst entry of any point in Σ. For example,
σ(010101 . . .) = (101010 . . .)
σ(101010 . . .) = (010101 . . .)
σ(01111 . . .) = (1111 . . .).
Note that it is easy to iterate σ—we simply continue dropping leading entries
as we iterate. That is,
σ2(s0s1s2 . . .) = (s2s3s4 . . .)
σn(s0s1s2 . . .) = (snsn+1sn+2 . . .).
This makes it easy to ﬁnd the periodic points of σ. If s is a repeating
sequence of the form
s = (s0s1 . . . sn−1s0s1 . . . sn−1 . . .) = (s0s1 . . . sn−1),

112
Symbolic Dynamics
then σn(s) = s. Conversely, any periodic point of period n for σ must be a
repeating sequence. For example, the only ﬁxed points for σ are (0000 . . .)
and (1111 . . .). The period 2 points are (010101 . . .) and (101010 . . .), and, of
course, σ maps one to the other. There are two 3-cycles for σ given by
(001) →(010) →(100) →(001)
(110) →(101) →(011) →(110).
We emphasize how easy it is to ﬁnd cycles for σ. We may clearly write
down all cycles of period n for σ just by writing any possible block of n 0’s
and 1’s and then repeating it ad inﬁnitum. Recall that it would be practically
impossible to write down all of the n-cycles for the quadratic map—this is
just one of the reasons why σ is a much simpler mapping to understand.
The shift map is clearly much diﬀerent from the usual functions encoun-
tered in calculus such as polynomials, trigonometric functions, exponentials,
and the like. Nevertheless, like its more familiar counterparts, σ is a continu-
ous function. To see why this is true, we cannot use the simpliﬁed deﬁnition of
continuity often given in calculus courses (“you can draw the graph without
lifting your pen”). Rather, we have to return to ﬁrst principles and invoke the
theoretical deﬁnition of continuity.
Deﬁnition. Suppose F : X →X is a function and X is a set equipped with
a metric d. Then F is continuous at x0 ∈X if, for any ϵ > 0, there is a
δ > 0 such that, if d[x, x0] < δ, then d[F(x), F(x0)] < ϵ. We say that F is a
continuous function if F is continuous at all x0 ∈X.
To prove that a function is continuous at x0, we must therefore be able to
accomplish the following: given any ϵ > 0 no matter how small, we must be
able to produce a δ > 0 such that, whenever x and x0 are within δ units of
each other, their images are closer together than ϵ.
This deﬁnition of continuity is one of those extremely complicated deﬁ-
nitions that often drives students mad. So before proving that the shift map
is continuous at all points, we’ll give a simple example as a warm-up. Let’s
begin by showing that σ is continuous at the ﬁxed point (0000 . . .). To prove
this, we assume that someone gives us an ϵ > 0. Our job is to ﬁnd a δ that
“works.” By this we mean that, if s is a sequence in Σ with d[s, (0000 . . .)] < δ,
then d[σ(s), (0000 . . .)] < ϵ. Now we don’t know which sequences in Σ have
images that are within an arbitrary ϵ of (0000 . . .), but we do know those that
are within 1/2n of (0000 . . .) for each n. And that will be good enough, as
long as we choose n so that 1/2n < ϵ. So we must ﬁnd δ that guarantees
that d[σ(s0s1s2 . . .), (0000 . . .)] ≤1/2n. But that’s easy! By the Proximity
Theorem, the only way this can be true is if si = 0 for i = 0, 1, 2, . . . , n + 1.
Therefore we choose δ = 1/2n+1. If d[(s0s1s2 . . .), (0000 . . .)] < δ, then
d[σ(s0s1s2 . . .), (0000 . . .)] = d[(s1s2s3 . . .), (0000 . . .)] ≤1/2n < ϵ.

Conjugacy
113
Thus we have found a δ that works.
The proof in the general case is not much more diﬃcult.
Theorem. The function σ: Σ →Σ is continuous at all points in Σ.
Proof: Suppose we are given ϵ > 0 and s = (s0s1s2 . . .). We will show that σ
is continuous at s.
Since ϵ > 0, we may pick n such that 1/2n < ϵ. We then choose δ = 1/2n+1.
If t is a point in Σ and d[t, s] < δ, then by the Proximity Theorem we must
have si = ti for i = 0, 1, . . . n + 1. That is, t = (s0 . . . sn+1tn+2tn+3 . . .).
Now σ(t) = (s1 . . . sn+1tn+2tn+3 . . .) has entries that agree with those of
σ(s) in the ﬁrst n + 1 spots1. Thus, again by the Proximity Theorem,
d[σ(s), σ(t)] ≤1/2n < ϵ.
Therefore, σ is continuous at s. Since s was arbitrary, σ is a continuous func-
tion. This completes the proof.
9.4
Conjugacy
Now that we have our model system, the shift map σ on the sequence space
Σ, it is time to relate this dynamical system to Qc on Λ. We already have a
function that relates the two, namely the itinerary function S. Recall that,
given a point x ∈Λ, the itinerary of x is a sequence S(x) in Σ. Hence we have
a mapping S : Λ →Σ.
Our ﬁrst observation is that Λ and Σ, though deﬁned in very diﬀerent
manners, are essentially identical spaces. The way to show that two spaces are
identical is to exhibit a homeomorphism between them. A homeomorphism is
a one-to-one, onto, and continuous function that also has a continuous inverse.
If we have a homeomorphism between two sets, these sets are said to be home-
omorphic. From a qualitative point of view, two sets that are homeomorphic
are essentially the same. Not only may we put the points of one set into one-
to-one correspondence with those of the other set, but, more importantly, we
may do this in a continuous fashion, taking nearby points in one set to nearby
points in the other.
Homeomorphism allows for sets to be distorted, as, for example, two ﬁnite
closed intervals are homeomorphic, even though their lengths diﬀer. But an
open interval and a closed interval are not homeomorphic. Rather than inter-
rupt the discussion of symbolic dynamics with a lengthy description of the
1 Technically, these sequences agree in the zeroth through nth spots.

114
Symbolic Dynamics
properties of homeomorphisms at this point, we refer you to Appendix A.1
for a more complete discussion of this topic.
Theorem. (Λ and Σ are the same!) Suppose c < −(5 + 2
√
5)/4. Then
S : Λ →Σ is a homeomorphism.
We will conclude this chapter with a proof of this important fact, but
before this we turn to another property of S.
Theorem. If x ∈Λ, then S ◦Qc(x) = σ ◦S(x).
This result is clear: if x ∈Λ has itinerary (s0s1s2 . . .), then by deﬁnition
x ∈Is0
Qc(x) ∈Is1
Q2
c(x) ∈Is2
and so forth. Here, Isj is either I0 or I1, depending upon the digit sj. Thus
Qc(x) ∈Is1
Q2
c(x) ∈Is2
Q3
c(x) ∈Is3,
so that S(Qc(x)) = (s1s2s3 . . .), which is σ(S(x)) as claimed.
We may describe this result pictorially as a commutative diagram:
Λ
Qc
−→
Λ
S
⏐⏐⏐
⏐⏐⏐S
Σ
−→
σ
Σ
The theorem tells us that if we start with any x ∈Λ in the upper left-hand
corner of this diagram and then follow the arrows in either possible direction,
we always end up at the same point in Σ in the lower right-hand corner.
Since S is a homeomorphism, we also have
Qc ◦S−1
=
S−1 ◦S ◦Qc ◦S−1
=
S−1 ◦σ ◦S ◦S−1
=
S−1 ◦σ.
Thus, this diagram also commutes:
Λ
Qc
−→
Λ
S−1
⏐⏐⏐
⏐⏐⏐S−1
Σ
−→
σ
Σ

Conjugacy
115
We also have
S ◦Qn
c
=
σ ◦S ◦Qn−1
c
=
σ2 ◦S ◦Qn−2
c
...
=
σn ◦S.
This is an important fact. It says that S converts orbits of Qc to orbits of σ.
Pictorially, we have
Λ
Qc
−→
Λ
Qc
−→
· · ·
Qc
−→
Λ
S
⏐⏐⏐
⏐⏐⏐S
⏐⏐⏐S
Σ
−→
σ
Σ
−→
σ
· · ·
−→
σ
Σ
Similarly, we have
Qn
c ◦S−1 = S−1 ◦σn
so S−1 converts σ-orbits to Qc-orbits. Therefore, Qc-orbits are in one-to-one
correspondence with σ-orbits. In particular, if s is a periodic point for σ, then
S−1(s) is a periodic point for Qc with the same period. If we have an eventually
periodic point for σ, then S−1 gives us an analogous point for Qc. Indeed, S−1
converts any dynamical behavior we observe for σ to corresponding behavior
for Qc. Thus the dynamics of σ on Σ and Qc on Λ are essentially the same.
As we will see in the next chapter, the dynamical behavior of σ is chaotic.
Therefore the same is true for Qc on Λ.
Homeomorphisms like S play an important role in the study of dynamical
systems, since they show that two apparently diﬀerent systems may actually
be dynamically equivalent. These maps are called conjugacies.
Deﬁnition. Let F : X →X and G: Y →Y be two functions. We say that
F and G are conjugate if there is a homeomorphism h: X →Y such that
h ◦F = G ◦h. The map h is called a conjugacy.
The previous theorems therefore give:
The Conjugacy Theorem. The shift map on Σ is conjugate to Qc on Λ
when c < −(5 + 2
√
5)/4.
We remark that this result is also valid for −(5 + 2
√
5)/4 < c < −2, but
the arguments needed in this range are more diﬃcult.

116
Symbolic Dynamics
Now let’s ﬁnish the proof that Λ and Σ are homeomorphic. To prove this
we need to show that S is one-to-one and onto and that both S and S−1 are
continuous.
One-to-one: Suppose that x, y ∈Λ with x ̸= y. Assume, however, that
S(x) = S(y). This means that Qn
c (x) and Qn
c (y) always lie in the same subin-
terval I0 or I1. We know that Qc is one-to-one on each of these intervals
and that |Q′
c(x)| > μ > 1 for all x ∈I0 ∪I1 and some μ. Now consider the
interval [x, y]. For each n, Qn
c takes this interval in one-to-one fashion onto
[Qn
c (x), Qn
c (y)]. But, as we saw in Chapter 7, the Mean Value Theorem implies
that
length [Qn
c (x), Qn
c (y)] ≥μn length [x, y].
Since μn →∞, we have a contradiction unless x = y.
Onto: We ﬁrst introduce the following notation. Let J ⊂I be a closed interval.
Let
Q−n
c
(J) = {x ∈I | Qn
c (x) ∈J}.
In particular, Q−1
c (J) denotes the preimage of J. The main observation is that,
if J ⊂I is a closed interval, then Q−1
c (J) consists of two closed subintervals,
one in I0 and one in I1. (see Figure 9.6; also consult Appendix A.3).
FIGURE 9.6
The preimage of a closed interval J is a pair of closed intervals, one in I0 and
one in I1.
To ﬁnd x ∈Λ with S(x) = s, we deﬁne
Is0s1...sn = {x ∈I | x ∈Is0, Qc(x) ∈Is1, . . . , Qn
c (x) ∈Isn}.
Since sj = 0 or 1 for each j, the set Isj is really one of I0 or I1 depending on
the digit sj. Using the notation above we may write
Is0s1...sn = Is0 ∩Q−1
c (Is1) ∩. . . ∩Q−n
c
(Isn).

Conjugacy
117
For any pair of intervals A and B, we have
Q−1
c (A ∩B) = Q−1
c (A) ∩Q−1
c (B).
Thus we may also write
Is0s1...sn
=
Is0 ∩Q−1
c

Is1 ∩. . . ∩Q−(n−1)
c
(Isn)

=
Is0 ∩Q−1
c (Is1...sn).
We claim that the Is0s1...sn are closed intervals that are nested. Clearly Is0
is a closed interval. By induction we assume that Is1...sn is a closed interval.
Then, by the observation above, Q−1
c (Is1...sn) consists of a pair of intervals,
one in I0 and one in I1. In either event, Is0 ∩Q−1
c (Is1...sn) = Is0s1...sn is a
single closed interval.
These intervals are nested because
Is0...sn = Is0...sn−1 ∩Q−n
c
(Isn) ⊂Is0...sn−1 .
Therefore we conclude that

n≥0
Is0s1...sn
is nonempty since a nested intersection of closed intervals is always nonempty.
See Appendix A.3 for a discussion of this fact. Note that if x ∈∩n≥0Is0s1...sn,
then x ∈Is0, Qc(x) ∈Is1, and so forth. Hence S(x) = (s0s1 . . .). This proves
that S is onto.
Incidentally, note that ∩n≥0Is0s1...sn consists of a unique point. This follows
immediately from the fact that S is one-to-one. In particular, we have that
diam Is0s1...sn →0 as n →∞.
Continuity: To prove that S is continuous, we again invoke the theoretical
deﬁnition of continuity given above. Let x ∈Λ, and suppose that S(x) =
s0s1s2 . . . . We will show that S is continuous at x. Let ϵ > 0. Then pick n
so that 1/2n < ϵ. Consider the closed subintervals It0t1...tn deﬁned above for
all possible combinations t0t1 . . . tn. These subintervals are all disjoint, and Λ
is contained in their union. There are 2n+1 such subintervals, and Is0s1...sn is
one of them. Hence we may choose δ such that |x −y| < δ and y ∈Λ implies
that y ∈Is0s1...sn. To do this we simply choose δ so small that the interval
of length 2δ centered at x overlaps none of the It0t1...tn with the exception of
Is0s1...sn. Therefore, S(y) agrees with S(x) in the ﬁrst n + 1 terms. Hence, by
the Proximity Theorem, we have
d[S(x), S(y)] ≤1
2n < ϵ.
This proves the continuity of S. It is easy to check that S−1 is also continuous.
Thus, S is a homeomorphism.

118
Symbolic Dynamics
Exercises
1. List all cycles of prime period 4 for the shift map.
Compute d[s, t] where:
2. s = (100), t = (001).
3. s = (100), t = (010).
4. s = (1011), t = (0101).
5. Find all points in Σ whose distance from (000 . . .) is exactly 1/2.
6. Give an example of a sequence midway between (000 . . .) and (111 . . .).
Give a second such example. Are there any other such points? Why or why
not?
7. Which point in Σ is furthest way from the point (s0s1s2 . . .) using the
metric d?
8. Let M01 = {s ∈Σ | s0 = 0, s1 = 1} and M101 = {s ∈Σ | s0 = 1, s1 =
0, s2 = 1}. What is the minimum distance between a point in M01 and a point
in M101? Give an example of two sequences that are this close to each other.
9. What is the maximum distance between a point in M01 and a point in
M101? Give an example of two sequences that are this far apart.
10. Let S be the itinerary map as deﬁned in this chapter. Prove that if s ∈Σ
is periodic under the shift map, then S−1(s) is a periodic point for Qc in Λ
with the same period. What happens if s is eventually periodic?
The N–Shift:
The following seven exercises deal with the analogue of the shift map and
sequence space for sequences that have more than two possible entries, the
space of sequences of N symbols.
11. Let ΣN denote the space of sequences whose entries are the positive inte-
gers 0, 1, . . . , N −1, and let σN be the shift map on ΣN. For s, t ∈ΣN, let
dN[s, t] =
∞

i=0
|si −ti|
N i
.
Prove that dN is a metric on ΣN.
12. What is the maximal distance between two sequences in ΣN?
13. How many ﬁxed points does σN have? How many 2-cycles? How many
cycles of prime period 2?
14. How many points in ΣN are ﬁxed by σk
N?
15. Prove that σN : ΣN →ΣN is continuous.

Conjugacy
119
16. Now deﬁne
dδ[s, t] =
∞

k=0
δk(s, t)
N k
,
where δk(s, t) = 0 if sk = tk and δk(s, t) = 1 if sk ̸= tk. Prove that dδ is also
a metric on ΣN.
17. What is the maximum distance between two points in ΣN when the metric
dδ is used?
18. Recall the function
T(x) =

3x
if x ≤1/2
3 −3x
if x > 1/2
that was discussed in the exercises at the end of Chapter 7. There we proved
that Γ = {x ∈[0, 1] | T n(x) ∈[0, 1] for all n} was the Cantor middle-thirds
set. Now deﬁne an itinerary function S : Γ →Σ, where Σ is the space of
sequences of 0’s and 1’s. Prove that S is a homeomorphism.
Remarks:
1. The above exercise shows that the set Λ for the quadratic map and the
Cantor middle-thirds set are actually homeomorphic, for they are both home-
omorphic to Σ.
2. We now have two inﬁnite sequences attached to each point x in the Cantor
set. One is the ternary expansion of x and the other is the itinerary of x. It is
tempting to seek a relationship between these two sequences. While there is a
relationship between them, it is by no means obvious. For example, the point
1 has ternary expansion 0.222 . . . but S(1) = (1000 . . .).
19. Each of the following deﬁnes a function on the space of sequences Σ. In
each case, decide if the given function is continuous. If so, prove it. If not,
explain why.
1.
F(s0s1s2 . . .) = (0s0s1s2 . . .)
2.
G(s0s1s2 . . .) = (0s00s10s2 . . .)
3.
H(s0s1s2 . . .) = (s1s0s3s2s5s4 . . .)
4.
J(s0s1s2 . . .) = (ˆs0ˆs1ˆs2 . . .) where ˆsj = 1 if sj = 0 and ˆsj = 0 if
sj = 1.
5.
K(s0s1s2 . . .) = ((1 −s0) (1 −s1) (1 −s2) . . .)
6.
L(s0s1s2 . . .) = (s0s2s4s6 . . .)
7.
M(s0s1s2 . . .) = (s1s10s100s1000 . . .)
8.
N(s0s1s2 . . .) = (t0t1t2 . . .) where tj = s0 + s1 + · · · + sj
mod 2.
That is, tj = 0 if s0 + · · · + sj is even, and tj = 1 if s0 + · · · + sj is
odd.

120
Symbolic Dynamics
9.
P(s0s1s2 . . .) = (t0t1t2 . . .) where tj = limn→∞sn if this limit
exists. Otherwise, tj = sj.
20. Is the shift map σ on the sequence space Σ conjugate to its second iterate,
σ2?
21. Are the functions G(x) = x2 −1 and H(x) = 1 −x2 conjugate on the real
line?
22. Is T(x) = tan(x) a homeomorphism between the open interval (−π/2, π/2)
and the entire real line?
23. Are the sets (0, 1) and [0, 1] homeomorphic?
24. Let F : [0, 1) →S1 (where S1 is the unit circle in the plane) be given by
F(θ) = exp(2πiθ). Is F a homeomorphism betwen these two sets?
25. Deﬁne a diﬀerent distance function d′ on Σ by d′[s, t] = 1/(k + 1), where
k is the least index for which sk ̸= tk and d′[s, s] = 0. Is d′ a metric?

10
Chaos
In this chapter we will introduce the notion of chaos. We will show that there
are many dynamical systems that are chaotic but that nevertheless can be
completely understood. We will describe how this can happen ﬁrst for the
shift map and then later in other important examples, including the quadratic
family.
10.1
Three Properties of a Chaotic System
There are many possible deﬁnitions of chaos. In fact, there is no general agree-
ment within the scientiﬁc community as to what constitutes a chaotic dynami-
cal system. However, this will not deter us from oﬀering one possible deﬁnition.
This deﬁnition has the advantage that it may be readily veriﬁed in a number
of diﬀerent and important examples. However, you should be forewarned that
there are many other possible ways to capture the essence of chaos.
To describe chaos, we need one preliminary notion from topology, that of
a dense set.
Deﬁnition. Suppose X is a set and Y is a subset of X. We say that Y is dense
in X if, for any point x ∈X, there is a point y in the subset Y arbitrarily
close to x.1
Equivalently, Y is dense in X if for any x ∈X we can ﬁnd a sequence
of points {yn} ∈Y that converges to x. For example, the subset of rational
numbers is dense in the set of real numbers. So is the subset consisting of
all irrational numbers. However, the integers are far from being dense in the
reals. Finally, the open interval (a, b) is dense in the closed interval [a, b].
To prove that a subset Y ⊂X is dense in X, we must exhibit a sequence
of points in Y that converges to an arbitrary point in X. For example, to
prove that the rational numbers are dense in R, we must ﬁnd a sequence of
1 To make the notion of “closeness” precise, we must have a metric or distance function
on the set X.
121

122
Chaos
rationals converging to any irrational. For instance, if the irrational is
√
2, a
sequence of rationals converging to this number is
1, 1.4, 1.41, 1.414, . . . .
In the general case, we begin by selecting an arbitrary real number x. If x is
rational, then we are done, so we assume that x is irrational. This means that
x has an inﬁnite decimal expansion of the form
x = an . . . a0.b1b2b3 . . . ,
where the aj and bj are digits ranging from 0 to 9. Now, for j = 1, 2, 3, . . ., set
xj = an . . . a0.b1 . . . bj.
Since xj has a ﬁnite decimal expansion, xj is a rational number. Clearly,
xj →x as j →∞. So we have found a sequence of rational numbers that
converges to x. This proves density of the rationals.
It is tempting to think of a dense subset as being a relatively large subset
of a given set. This is true in the sense that there are points in this subset
arbitrarily close to any given point in the larger set. However, a dense set may
sometimes be small in the sense that it contains only countably many points,
as, for example, the set of rationals in the real line.
Here is another way in which the set of rationals, though dense in the reals,
is small. Let R be the dense subset of the interval [0, 1] that consists of all of
the rationals in [0, 1]. We may list all of the elements of R. One such listing is
0, 1, 1
2, 1
3, 2
3, 1
4, 3
4, 1
5, 2
5, 3
5, 4
5, 1
6, . . . .
Now let ϵ be small. Consider the interval of length ϵn centered at the nth
element in the above list, where n ≥1. The union of all of these intervals
is clearly an open set. Its intersection with the interval [0, 1] is dense since
it contains all of the rationals. However, the total length of this set is small.
Indeed, the total length is at most given by
∞

n=1
ϵn =
ϵ
1 −ϵ,
which is small when ϵ is very small. For example, the total length of this set
is no larger than 1/99 when ϵ = 0.01.
Now let’s return to investigate the dynamics of the shift map σ on the
sequence space Σ. Our ﬁrst observation about this map is that the subset of
Σ that consists of all periodic points in Σ is a dense subset. To see why this
is true, we must show that, given any point s = (s0s1s2 . . .) in Σ, we can ﬁnd
a periodic point arbitrarily close by. So suppose we are given an ϵ > 0. How
do we ﬁnd a periodic point within ϵ units of s? Let’s choose an integer n so

Three Properties of a Chaotic System
123
that 1/2n < ϵ. We may now write down an explicit periodic point within 1/2n
units of s. Let tn = (s0s1 . . . sns0s1 . . . sn). The ﬁrst n + 1 entries of s and tn
are the same. By the Proximity Theorem this means that
d[s, tn] ≤1
2n < ϵ.
But tn is a repeating sequence, and so it is a periodic point of period n + 1
for σ. Since ϵ and s were arbitrary, we have succeeded in ﬁnding a periodic
point arbitrarily close to any point in Σ. Note that the sequence of sequences
{tn} converges to s as n →∞.
Note again the power of symbolic dynamics. Unlike maps like the quadratic
function, we can explicitly exhibit periodic points of any period for σ. More-
over, we can show that these points accumulate or come arbitrarily close to
any given point in Σ.
A second and even more interesting property of σ is that there is a point
whose orbit is dense in Σ. That is to say, we can ﬁnd a point in Σ whose
orbit comes arbitrarily close to any point whatsoever in Σ. Clearly, this kind
of orbit is far from periodic or eventually periodic. As above, we can write
down such an orbit explicitly for σ. Consider the point
ˆs = ( 0 1

1blocks
00 01 10 11



2blocks
000 001 . . .



3blocks
. . .

4blocks
).
In words, ˆs is the sequence which consists of all possible blocks of 0’s and 1’s
of length 1, followed by all such blocks of length 2, then length 3, and so forth.
The point ˆs has an orbit that forms a dense subset of Σ. To see this, we
again choose an arbitrary s = (s0s1s2 . . .) ∈Σ and an ϵ > 0. Again choose n
so that 1/2n < ϵ. Now we show that the orbit of ˆs comes within 1/2n units
of s. Far to the right in the expression for ˆs, there is a block of length n + 1
that consists of the digits s0s1 . . . sn. Suppose the entry s0 is at the kth place
in the sequence. Now apply the shift map k times to ˆs. Then the ﬁrst n + 1
entries of σk(ˆs) are precisely s0s1 . . . sn. So by the Proximity Theorem,
d[σk(ˆs), s] ≤1
2n < ϵ.
There is a dynamical notion that is intimately related to the property of
having a dense orbit. This is the concept of transitivity.
Deﬁnition. A dynamical system is transitive if for any pair of points x and y
and any ϵ > 0 there is a third point z within ϵ of x whose orbit comes within
ϵ of y.
In other words, a transitive dynamical system has the property that, given
any two points, we can ﬁnd an orbit that comes arbitrarily close to both.

124
Chaos
Clearly, a dynamical system that has a dense orbit is transitive, for the dense
orbit comes arbitrarily close to all points. The fact is that the converse is also
true—a transitive dynamical system has a dense orbit.2 However, we will not
prove this fact here since it uses an advanced result from real analysis known
as the Baire Category Theorem.
A third property exhibited by the shift map is sensitive dependence on
initial conditions, or sensitivity for short.
Deﬁnition. A dynamical system F depends sensitively on initial conditions
if there is a β > 0 such that, for any x and any ϵ > 0, there is a y within ϵ of
x and a k such that the distance between F k(x) and F k(y) is at least β.
In this deﬁnition it is important to understand the order of the quantiﬁers.
The deﬁnition says that, no matter which x we begin with and no matter how
small a region we choose about x, we can always ﬁnd a y in this region whose
orbit eventually separates from that of x by at least β. Moreover, the distance
β is independent of x. As a consequence, for each x, there are points arbitrarily
nearby whose orbits are eventually “far” from that of x.
Remarks:
1. The deﬁnition of sensitivity does not require that the orbit of y remain far
from x for all iterations. We only need one point on the orbit to be far from
the corresponding iterate of x.
2. There are other possible deﬁnitions of sensitive dependence. For example,
one common deﬁnition requires that certain nearby orbits diverge exponen-
tially. That is, it is sometimes required that the distance between F k(x) and
F k(y) grow like Cμk for some μ > 1 and C > 0.
3. The concept of sensitive dependence on initial conditions is a very important
notion in the study of applications of dynamical systems. If a particular system
possesses sensitive dependence, then for all practical purposes, the dynamics
of this system defy numerical computation. Small errors in computation that
are introduced by round-oﬀmay throw us oﬀthe intended orbit. Then these
errors may become magniﬁed upon iteration. Also, as always happens in real-
life systems, we can never know the exact initial point of our system no matter
how many digits of accuracy we use. As a consequence, we may be looking at
an orbit that eventually diverges from the true orbit we seek. Therefore, the
results of numerical computation of an orbit, no matter how accurate, may
bear no resemblance whatsoever to the real orbit.
Example. The function C(x) = cos x possesses no sensitivity to initial con-
ditions whatsoever. Indeed, as we saw in Figure 4.2, all orbits of C tend to
2 This is true for dynamical systems on the kinds of spaces we are considering, like the
real line or Cantor sets. But it need not be true on certain “pathological” kinds of spaces.

Three Properties of a Chaotic System
125
the attracting ﬁxed point at 0.73908 . . . . On the other hand, F(x) = √x has
sensitive dependence at 0. See Figure 4.2. Although 0 is a ﬁxed point, any
nearby point has orbit that tends to the attracting ﬁxed point at 1, hence “far
away.” On the other hand, there is no sensitive dependence at any other point
in the interval 0 < x < ∞.
To see that the shift map depends sensitively on initial conditions, we
select β = 1. For any s ∈Σ and ϵ > 0 we again choose n so that 1/2n < ϵ.
Suppose t ∈Σ satisﬁes d[s, t] < 1/2n but t ̸= s. Then we know that ti = si
for i = 0, . . . , n. However, since t ̸= s there is k > n such that sk ̸= tk. So
|sk −tk| = 1.
Now consider the sequences σk(s) and σk(t). The initial entries of each of
these sequences are diﬀerent, so we have
d[σk(s), σk(t)] ≥|sk −tk|
20
+
∞

i=1
0
2i = 1.
This proves sensitivity for the shift.
Note that we have actually proved a lot more for the shift. We have actually
shown that for any s ∈Σ, all other points have orbits that eventually separate
by at least 1 unit from the orbit of s.
These three properties are the basic ingredients of a chaotic system:
Deﬁnition. A dynamical system F is chaotic if:
1.
Periodic points for F are dense.
2.
F is transitive.
3.
F depends sensitively on initial conditions.
So we have proved
Theorem. The shift map σ: Σ →Σ is a chaotic dynamical system.
Remark. In fact, it is known [4] that a system that has a dense set of peri-
odic points and is transitive also depends sensitively on initial conditions, so
condition three above follows from the ﬁrst two.
As we saw in the previous chapter, the shift map on Σ and the quadratic
map Qc on Λ are conjugate, and therefore they are dynamically equivalent. It
is natural to ask if this implies that the quadratic map is chaotic on Λ. Indeed
Qc is chaotic on Λ, but to show this we ﬁrst have to make one observation
about dense subsets.

126
Chaos
The Density Proposition. Suppose F : X →Y is a continuous map that is
onto and suppose also that D ⊂X is a dense subset. Then F(D) is dense in
Y .
Proof: Suppose y0 ∈Y and ϵ > 0. We must produce a point z ∈F(D) within
ϵ of y0. Consider instead a preimage x0 ∈X of y0, that is, F(x0) = y0. We
can ﬁnd such an x0 since F is onto. Since F is also continuous, there is δ > 0
such that if x is within δ of x0, then F(x) is within ϵ of F(x0). Since D is
dense in X, we may choose ˆx ∈D within δ of x0. Therefore F(ˆx) lies in F(D)
within ϵ of y0. So we set z = F(ˆx). Since both ϵ and y0 were arbitrary, this
completes the proof.
Theorem. Suppose c < −(5+2
√
5)/4. Then the quadratic map Qc(x) = x2+c
is chaotic on the set Λ.
Proof: Since the itinerary map S : Λ →Σ is a conjugacy, it follows that
S−1 : Σ →Λ is a homeomorphism. Therefore the Density Proposition guar-
antees that the set of periodic points for Qc is dense in Λ, since S−1 carries
periodic points for σ to periodic points for Qc. Also, if ˆs lies on a dense orbit
for σ, then the Density Proposition also guarantees that the orbit of S−1(ˆs)
lies on a dense orbit for Qc. So to prove that Qc is chaotic, all we need to do
is exhibit sensitive dependence.
To accomplish this we need to ﬁnd a β > 0 that “works.” Recall from
Chapter 9.1 that Λ is contained in the union of two closed intervals I0 and I1,
which are disjoint. Choose β to be smaller than the minimum distance between
these two intervals. We now claim that any two Qc-orbits in Λ eventually
separate by at least β. To see this, let x, y ∈Λ with x ̸= y. Since S is a
homeomorphism, S(x) ̸= S(y) as well. As a consequence, the sequences S(x)
and S(y) diﬀer at some entry, say the kth. This means that F k(x) and F k(y)
each lie in a diﬀerent Ij. Hence the distance between F k(x) and F k(y) is at
least β. This shows that any orbit that starts close to x eventually separates
from the orbit of x by at least β and we are done.
To summarize, a chaotic map possesses three ingredients: unpredictability,
indecomposability, and an element of regularity. A chaotic system is unpre-
dictable because of the sensitive dependence on initial conditions. It cannot be
broken down or decomposed into two separate subsystems that do not inter-
act under F because of transitivity. And, in the midst of this complicated
behavior, we nevertheless have an element of regularity, namely the periodic
points that are dense.

Other Chaotic Systems
127
10.2
Other Chaotic Systems
In the previous section, we showed that the quadratic map Qc was chaotic
on the set Λ as long as c was suﬃciently negative. In one sense, this result is
unsatisfying because the set on which Qc is chaotic is “small”—as we will soon
see, Λ is a Cantor set. Indeed, it is diﬃcult to see this chaotic behavior with
a computer, as we observed in Section 3.6. On the other hand, the quadratic
function Q−2(x) = x2 −2 seems to be chaotic on the entire interval [−2, 2],
as we saw numerically in Figure 3.3. Our goal in this section is to verify this
fact.
Instead of dealing directly with x2 −2, we will again take a back-door
approach and consider a simpler system that turns out to be equivalent to
this map. Consider the function V (x) = 2|x| −2. The graph of V is displayed
in Figure 10.1. Note that this graph takes the interval [−2, 2] to itself, exactly
as x2 −2 does. Graphical analysis shows that if |x| > 2, then the orbit of x
under V tends to inﬁnity, again exactly as happened for x2 −2.
To compute higher iterates of V , we ﬁrst make use of the deﬁnition of
absolute value to write
V 2(x)
=
2 |2|x| −2| −2
=
|4|x| −4| −2
=

4|x| −6
if 4|x| −4 ≥0 ⇐⇒|x| ≥1
−4|x| + 2
if 4|x| −4 ≤0 ⇐⇒|x| ≤1.
In turn, this may be further decomposed to
V 2(x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
4x −6
if x ≥1
−4x + 2
if 0 ≤x ≤1
4x + 2
if −1 ≤x ≤0
−4x −6
if x ≤−1.
Figure 10.2 shows the graphs of V 2 and V 3. Note that the graph of V 2
consists of four linear pieces, each with slope ±4, and that the graph of V 3
consists of eight pieces, each with slope ±8. In general, the graph of V n consists
of 2n pieces, each of which is a straight line with slope ±2n. Each of these
linear portions of the graph is deﬁned on an interval of length 1/2n−2.
This fact shows immediately that V is chaotic on [−2, 2]. To see this, we
consider an open subinterval J in [−2, 2]. From the above observation, we
may always ﬁnd a subinterval of J of length 1/2n−2 on which the graph of V n
stretches from −2 to 2 (see Figure 10.3). In particular, V n has a ﬁxed point in
J, so this proves that periodic points are dense in [−2, 2]. Also, the image of
J covers the entire interval [−2, 2], so V is transitive. Finally, for any x ∈J,
there is a y ∈J such that |V n(x) −V n(y)| ≥2. Thus we may choose β = 2,
and we have sensitive dependence on initial conditions.

128
Chaos
FIGURE 10.1
The graph of V (x) = 2|x| −2.
FIGURE 10.2
The graphs of V 2 and V 3.

Other Chaotic Systems
129
FIGURE 10.3
The graph of V n stretches J over the entire interval [−2, 2].
Now we will use this fact to prove that Q−2 is also chaotic. Consider the
function C(x) = −2 cos(πx/2). This function maps the interval [−2, 2] onto
itself as shown in Figure 10.4. Every point in [−2, 2] has exactly two preimages
in [−2, 2] with the exception of −2 which has only one.
Now suppose we apply C to both x and V (x). The result is the diagram:
x
V
−→
2|x| −2
C
⏐⏐⏐
⏐⏐⏐C
−2 cos(πx/2)
−→
?
−2 cos(π|x| −π)
We ask what is the mapping F that completes this diagram: what is the
function that accomplishes the following?
−2 cos(πx/2) →−2 cos(π|x| −π).
With the help of a little trigonometry, we ﬁnd
−2 cos(π|x| −π)
=
2 cos(π|x|)
=
2 cos(πx)
=
2 cos

2 · πx
2

=

2 cos
πx
2
2
−2
=

−2 cos
πx
2
2
−2.

130
Chaos
FIGURE 10.4
C(x) = −2 cos(πx/2) takes [−2, 2] onto itself.
That is, F is the function that satisﬁes
−2 cos(πx/2)
F
−→
−2 cos
πx
2
2
−2,
or, letting u = −2 cos(πx/2), we ﬁnd that F(u) = u2 −2 = Q−2(u). That is,
we have the following commutative diagram:
[−2, 2]
V
−→
[−2, 2]
C
⏐⏐⏐
⏐⏐⏐C
[−2, 2]
−→
Q−2
[−2, 2].
It appears that C is a conjugacy between V and Q−2. However, C is not
a homeomorphism since C is not one-to-one. Nevertheless, the commutative
diagram shows that C carries orbits of V to orbits of Q−2. Since C is at
most two-to-one, it follows that C takes cycles to cycles. However, it is not
necessarily true that C preserves the period of cycles. For example, C could
conceivably take a 2-cycle for V and map it to a ﬁxed point for Q−2. Never-
theless, since C is both continuous and onto, the Density Proposition shows
that Q−2 has periodic points that are dense as well as a dense orbit. Finally,
since n may be chosen so that V n maps arbitrarily small intervals onto all of
[−2, 2], the same must be true for Q−2. This proves sensitive dependence and
we have:
Theorem. The function Q−2(x) = x2 −2 is chaotic on [−2, 2].

Other Chaotic Systems
131
The map C that converts orbits of V to orbits of Q−2 has a name. Such a
map is called a semiconjugacy. To be precise, we deﬁne:
Deﬁnition. Suppose F : X →X and G: Y →Y are two dynamical systems.
A mapping h: X →Y is called a semiconjugacy if h is continuous, onto, at
most n-to-one, and satisﬁes h ◦F = G ◦h.
As a ﬁnal example of a chaotic dynamical system, we consider now a
function that will play a major role later when we consider dynamical systems
in the complex plane. Let S1 denote the unit circle in the plane.3 That is,
S1 = {(x, y) ∈R2 | x2 + y2 = 1}.
We describe a point on S1 by giving its polar angle θ in radians. Note that θ
is deﬁned mod 2π.
Let D: S1 →S1 be given by D(θ) = 2θ. We call D the doubling map on
the circle. Note that if L is an arc on the circle, then D(L) is an arc that is
twice as long (unless the arclength of L exceeds π, in which case D(L) covers
the entire circle). So one iteration of D behaves in a fashion similar to V
above.
Theorem. The doubling map D is chaotic on the unit circle.
Proof: To prove this we will again make use of a semiconjugacy. Deﬁne the
function B : S1 →[−2, 2] given by B(θ) = 2 cos(θ). Since cos(θ) is the x-
coordinate of the point θ on S1, the map B is given geometrically by projecting
points vertically from the circle to the x-axis, and then stretching by a factor
of 2 (see Figure 10.5). Note that B is two-to-one except at the points π and
0 on S1.
Consider the diagram
S1
D
−→
S1
B
⏐⏐⏐
⏐⏐⏐B
[−2, 2]
−→
?
[−2, 2].
As before, we ask which function completes the diagram. We have
B ◦D(θ) = 2 cos(2θ),
3The notation Sn is commonly used in mathematics to denote the unit sphere in (n+1)-
dimensional Euclidean space—that is the reason for the superscript 1.

132
Chaos
FIGURE 10.5
The map B projects S1 to the x-axis.
so we must ﬁnd the function that takes B(θ) = 2 cos(θ) to B(D(θ)) = 2 cos(2θ)
for each θ. However, we may write
2 cos(2θ) = 2

2 cos2(θ) −1

= (2 cos(θ))2 −2.
So the required function is our friend the quadratic function Q−2(x) = x2 −2.
Thus D and Q−2 are semiconjugate. It is not diﬃcult to mimic the arguments
given above to complete the proof that D is chaotic on S1.
10.3
Manifestations of Chaos
There are a number of diﬀerent computer experiments that give an indica-
tion of chaotic behavior. For example, a histogram or density plot can often
indicate the presence of orbits that visit virtually every region of the inter-
val. In Figure 10.6 we display the histograms for several functions, including
F4(x) = 4x(1 −x) and G(x) = 4x3 −3x. These histograms are computed
using 30,000 iterations of a randomly chosen initial seed in each case. Note
the similarity between these histograms and that of the quadratic function
Q−2 displayed in Figure 3.4. We ask you to verify that each of these two maps
is indeed chaotic in the exercises following this chapter. We have also dis-
played the histograms for Q−1.8 and Q−1.6 in Figure 10.6. These histograms
are clearly quite diﬀerent, but they nonetheless indicate that the correspond-
ing functions have orbits that are dense in a certain interval.
Note that histograms may be misleading: the doubling function on the
unit interval is chaotic, but the computer shows (recall Section 3.6) that all
orbits tend to zero.
Sensitive dependence on initial conditions may often be noted in rather
stunning fashion using the computer, for orbits of many chaotic systems tend
to separate very quickly when sensitivity is present. For example, consider
again the chaotic quadratic function Q−2(x) = x2 −2. We have proved that

Manifestations of Chaos
133
FIGURE 10.6
Histograms for F4(x) = 4x(1 −x), G(x) = 4x3 −3x, Q−1.8(x) = x2 −1.8, and
Q−1.6(x) = x2 −1.6.

134
Chaos
FIGURE 10.7
Values of Qn
−2(x0) for x0 = 0, 0.1, 0.01, 0.001. Points are listed to only three
or four decimal places.
this function depends sensitively on initial conditions. We know that 0 is
eventually ﬁxed with orbit 0, −2, 2, 2, 2, . . . . Nearby orbits should separate
from this orbit. In the table in Figure 10.7 we illustrate this by listing the
ﬁrst ﬁfteen points on the orbits of several nearby initial seeds, 0.1, 0.01, and
0.001. Note how quickly these orbits separate: by the ﬁfteenth iteration, each
of these orbits has visited the other end of the interval [−2, 2].
Sensitive dependence is not at all surprising in functions whose derivative is
always larger than 1 in magnitude, such as in the case of the doubling function.
For x2 −2, however, this result is by no means clear. We have Q′
c(0) = 0, so
there is an interval about 0 that is contracted by Qc. This means that any
orbit that comes close to 0 is, upon the next iteration, mapped very close to
Qc(0). Hence, at least in the short run, these two orbits do not separate. In the
long run, however, we know that these orbits do tend to separate. Incidentally,
this fact provides the answer to the essay question 18 at the end of Chapter 8.
10.4
Experiment: Feigenbaum’s Constant
Goal: Using the orbit diagram, we have seen in the previous exercises and
experiments that the quadratic function Qc(x) = x2 + c, the logistic function

Experiment: Feigenbaum’s Constant
135
Fc(x) = cx(1 −x), and the sine function c sin(x) all undergo a sequence of
period-doubling bifurcations as the parameter tends to the chaotic regime.
We have also seen that magniﬁcations of the orbit diagram tend to look “the
same.” In this experiment, we will see that there really is some truth to this:
we will see that these period doubling bifurcations always occur at the same
rate.
Procedure: In this experiment you will work with either the quadratic or
the logistic family. We ﬁrst need a deﬁnition:
Deﬁnition. Suppose x0 is a critical point for F, that is, F ′(x0) = 0. If x0
is also a periodic point of F with period n, then the orbit of x0 is called
superstable. The reason for this terminology is that (F n)′(x0) = 0.
In this experiment we will ﬁrst determine the c-values at which either
Qc(x) = x2 + c or Fc(x) = cx(1 −x) have superstable cycles of periods 1,
2, 4, 8, 16, 32, and 64. Using a computer or a spreadsheet, experimentally
determine the c-values at which your function has a superstable point of the
given period. Be sure to check that this point has the correct prime period.
You should be looking in the Period-1 window of the corresponding orbit
diagram for these points.
There are a number of ways to do this. For example, you could list 1000
points on the orbit of a random initial condition. By changing the parameter,
you should then search for the “exact” c for which the critical point (0 for
Qc(x) = x2 +c, 0.5 for Fc(x) = cx(1−x)) lies on a cycle. You will usually not
be able to ﬁnd this parameter value exactly. However, you should ﬁnd the c
value for which you come closest to having the critical point periodic. Usually,
this means that you ﬁnd a point on the orbit within 10−6 of the critical point.
You should ﬁnd c accurate to seven decimal places, which is more or less the
accuracy of typical computations.
A second possibility is to zoom in on the appropriate region in the
orbit diagram to ﬁnd the c-values for which the critical point is periodic of
the given period. Some applets that allow you to do this are available at
math.bu.edu/DYSYS/OrbitDgm.html.
Another approach might be to compute the ﬁrst 2n points on the orbit
of the critical point, and then seeing how close you come to this point. Then
modify the parameter repeatedly to try to come closer to the value for which
the critical point is periodic with the right period. After ﬁnding the seven
c-values for your function, record these numbers in tabular form:
1.
c0 = c-value for period 20
2.
c1 = c-value for period 21
3.
c2 = c-value for period 22
4.
c3 = c-value for period 23
5.
c4 = c-value for period 24

136
Chaos
6.
c5 = c-value for period 25
7.
c6 = c-value for period 26
Now use a calculator or computer to compute the following ratios:
f0 = c0 −c1
c1 −c2
, f1 = c1 −c2
c2 −c3
, . . . , f4 = c4 −c5
c5 −c6
.
List these numbers in tabular form, too. Do you notice any convergence? You
should, at least if you have carried out the above search to enough decimal
places.
Notes and Questions:
1. The number this ratio converges to is called Feigenbaum’s constant. It turns
out that this number is “universal”—it appears whenever a typical family
undergoes the period-doubling route to chaos. Compare the results of both
the quadratic and logistic families. Are they the same? Try also the family
c sin x. What is the result here? The fact that these numbers are always the
same is a remarkable result due to Mitchell Feigenbaum in 1975 [18].
2. This lab can take a long time to perform. It is useful to work with friends
and divide up the tasks.
Exercises
For each of the following six sets, decide whether or not the set is dense in
[0, 1]. Give a reason for your answer.
1. S1 is the set of all real numbers in [0, 1] except those of the form 1/2n for
n = 1, 2, 3, . . . .
2. S2 is the set of all rationals in [0, 1] of the form p/2n, where p and n are
natural numbers.
3. S3 is the Cantor middle-thirds set.
4. S4 is the complement of the Cantor middle-thirds set.
5. S5 is the complement of any subset of [0, 1] which contains only countably
many points.
6. S6 is the set of real numbers whose binary expansion has only ﬁnitely many
zeroes.
For each of the following sets, decide whether or not the set is dense in Σ.
Again, give reasons.
7. T1 = {(s0s1s2 . . .) | s4 = 0}.
8. T2 is the complement of T1.

Experiment: Feigenbaum’s Constant
137
9. T3 = {(s0s1s2 . . .) | the sequence ends in all 0’s}.
10. T4 = {(s0s1s2 . . .) | at most one of the sj = 0}.
11. T5 = {(s0s1s2 . . .) | inﬁnitely many of the sj = 0}.
12. T6 is the complement of T5.
13. T7 = {(s0s1s2 . . .) | no two consecutive sj = 0}.
14. T8 is the complement of T7.
15. Find a (nontrivial) sequence of periodic points in Σ that converges to the
point (0101).
16. Is the orbit of the point (01 001 0001 00001 . . .) under σ dense in Σ?
17. Does the orbit in Exercise 16 converge to the point (000 . . .)?
18. Is it possible to give an example of an orbit under σ that accumulates on
(that is, comes arbitrarily close to but never equals) the two ﬁxed points of
σ, but which is not dense?
19. Prove that, if s ∈Σ, there are sequences t arbitrarily close to s for which
d[σn(s), σn(t)] = 2 for all suﬃciently large n.
20. Let φ(s) = (0s0s1s2 . . .). Is φ chaotic on Σ?
21. Which points are periodic under φ?
22. Prove that the set of endpoints of removed intervals in the Cantor middle-
thirds set is a dense subset of the Cantor set.
23. Let V (x) = 2|x| −2. Find the ﬁxed points of V and V 2. Compute an
expression for V 3.
24. Prove that the doubling function given by
D(x) =

2x
if x < 1
2
2x −1
if x ≥1
2
is chaotic on [0, 1). Compare this result with your observations in Section 3.6.
25. Prove that the function
T(x) =

2x
if x ≤1
2
2 −2x
if x > 1
2
is chaotic on [0, 1].
26. Use the results of the previous exercise to construct a conjugacy between
T on the interval [0, 1] and G(x) = 2x2 −1 on the interval [−1, 1].
27. Construct a conjugacy that is valid on all of R between G in the previous
exercise and Q−2. (Hint: Use a linear function of the form ax + b.)

138
Chaos
28. Prove that F4(x) = 4x(1 −x) is chaotic on [0, 1].
29. Prove that the “tripling map” on S1 given by F(θ) = 3θ is chaotic.
30. Use the results of the previous exercise to prove that G(x) = 4x3 −3x is
chaotic on [−1, 1].
31. Prove that
L(x) =

3x
if x ≤1
3
−3
2x + 3
2
if x > 1
3
is chaotic on [0, 1].

11
Sharkovsky’s Theorem
In Chapter 8 we saw that, as the quadratic function makes the transition to
chaos, there seem to be many c-values where the map is chaotic, and many
other c-values for which the dynamics are quite tame. In particular, in any
of the windows, there seems to be at most one attracting cycle and no other
dynamics. In this chapter, we will show that this is by no means the case.
In particular, we will show that there is much more going on than meets the
eye—particularly in the period-3 window.
11.1
Period 3 Implies Chaos
Before discussing Sharkovsky’s Theorem in full generality, we will prove a very
special case of this result.
The Period-3 Theorem. Suppose F : R →R is continuous. Suppose also
that F has a periodic point of prime period 3. Then F also has periodic points
of all other prime periods.
This is the theorem mentioned in Chapter 1 that appeared in an amazing
article written by T.-Y. Li and James Yorke entitled “Period Three Implies
Chaos” [23]. This paper was essentially the ﬁrst to introduce the idea of
“chaos” in simple dynamical systems and thus caused an explosion of interest
among scientists, engineers, and mathematicians in this topic.
This theorem is also remarkable for the simplicity of its statement. The
only assumption is that F is continuous. If we ﬁnd a cycle of period 3 for F,
we are guaranteed that there are inﬁnitely many other cycles for this map,
with every possible period. In particular, this shows that there is much more
going on in the orbit diagram for the quadratic map considered in the previous
chapter. In Figure 8.5, we see only a cycle of period 3 for an interval of c-values.
Somewhere in this picture there must also be a large set of other periodic
points. We don’t see them because, presumably, they are all repelling.
To prove this result we need to make two preliminary observations, both
of which assume that F is a continuous function on the real line.
139

140
Sharkovsky’s Theorem
Observation 1: Suppose I = [a, b] and J = [c, d] are closed intervals and
I ⊂J. If F(I) ⊃J, then F has a ﬁxed point in I.
This, of course, is an immediate consequence of the Intermediate Value
Theorem. Since J ⊃I, it follows that the graph of F must cross the diag-
onal somewhere over I. Figure 11.1 shows that the ﬁxed point need not be
unique—there may in fact be a number of ﬁxed points for F in I. However,
the Intermediate Value Theorem guarantees that there is at least one ﬁxed
point.
FIGURE 11.1
Since F(I) ⊃J, there is at least one ﬁxed point in I.
Observation 2: Suppose I and J are two closed intervals and F(I) ⊃J.
Then there is a closed subinterval I′ ⊂I such that F(I′) = J.
This observation does not imply that F is one-to-one on the subinterval
I′; we only claim that F maps I′ onto J (see Figure 11.2). Note also that we
do not assume here that J ⊃I as in observation 1. Now let’s turn to a proof
of the Period-3 Theorem.
Proof of the Theorem: Suppose that F has a 3-cycle given by
a →b →c →a →. . . .
If we assume that a is the leftmost point on the orbit, then there are two
possibilities for the relative positions of the points on this orbit, as shown
in Figure 11.3. We will assume the ﬁrst case a < b < c; the second case is
handled similarly.
Let I0 = [a, b] and I1 = [b, c]. Since F(a) = b and F(b) = c, we have
F(I0) ⊃I1. Similarly, since F(c) = a, we have F(I1) ⊃I0 ∪I1. Notice that
we are making use of the assumption that F is continuous at this point.

Period 3 Implies Chaos
141
FIGURE 11.2
F maps I′ ⊂I onto J.
We will ﬁrst produce a cycle of period n > 3. Later we will handle the two
special cases n = 1 and 2.
To ﬁnd a periodic point of period n, we will invoke observation 2 precisely
n times. First we note that, since F(I1) ⊃I1, there is a closed subinterval
A1 ⊂I1 that satisﬁes F(A1) = I1. Since A1 ⊂I1 and F(A1) = I1 ⊃A1, we
may invoke observation 2 again to ﬁnd a closed subinterval A2 ⊂A1 such that
F(A2) = A1. Note that, by construction, A2 ⊂A1 ⊂I1 and F 2(A2) = I1.
FIGURE 11.3
Two possibilities for the 3-cycle a →b →c.
Now continue in this fashion for n −2 steps. We produce a collection of
closed subintervals
An−2 ⊂An−3 ⊂· · · ⊂A2 ⊂A1 ⊂I1,
such that F(Ai) = Ai−1 for i = 2, . . . , n −2 and F(A1) = I1. In particular,
F n−2(An−2) = I1 and An−2 ⊂I1.
Now, since F(I0) ⊃I1 ⊃An−2, there is also a closed subinterval An−1 ⊂
I0, such that F(An−1) = An−2. Finally, since F(I1) ⊃I0 ⊃An−1, there is

142
Sharkovsky’s Theorem
another closed subinterval An ⊂I1, such that F(An) = An−1. Putting this
all together, we ﬁnd
An
F
−→An−1
F
−→· · ·
F
−→A1
F
−→I1
with F(Ai) = Ai−1 so that F n(An) = I1 (see Figure 11.4). But An ⊂I1, so
we may use observation 1 to conclude that there is a point x0 ∈An that is
ﬁxed by F n. Hence x0 has period n. We claim that x0 has prime period n.
FIGURE 11.4
Construction of the Ai.
To see this, note that F(x0) ∈An−1 ⊂I0, but F i(x0) ∈I1 for i = 2, . . . , n.
So the ﬁrst iterate of x0 lies in I0 but all others lie in I1. This proves that x0
has period ≥n, so x0 has prime period n.1
The ﬁnal cases are n = 1 and 2. These are handled by noting that F(I1) ⊃
I1, so there is a ﬁxed point in I1. Similarly, F(I0) ⊃I1 and F(I1) ⊃I0. So
there is a 2-cycle that hops back and forth between I0 and I1, using the above
argument. This completes the proof.
11.2
Sharkovsky’s Theorem
Sharkovsky’s Theorem, ﬁrst proved in 1964, is an incredibly powerful and
beautiful strengthening of the Period-3 Theorem. To state the theorem, we
1Note that x0 cannot lie in I0 ∩I1 = {b}, for in this case we would have b ∈An−1 so
F(b) = c ̸∈I0.

Sharkovsky’s Theorem
143
ﬁrst list all of the natural numbers in the following strange order:
3, 5, 7, 9, . . .
2 · 3, 2 · 5, 2 · 7, . . .
22 · 3, 22 · 5, 22 · 7, . . .
23 · 3, 23 · 5, 23 · 7, · · ·
...
. . . , 2n, . . . , 23, 22, 21, 1.
This is known as the Sharkovsky ordering of the natural numbers.
Sharkovsky’s Theorem. Suppose F : R →R is continuous. Suppose that F
has a periodic point of prime period n and that n precedes k in the Sharkovsky
ordering. Then F also has a periodic point of prime period k.
In 1964, O. N. Sharkovsky published a short paper that included this
theorem that now bears his name [30]. Originally published in Russian, this
paper remained unknown in the West until Li and Yorke published their result
ten years later. Together, these two papers have revolutionized the ﬁeld of
dynamical systems.
Note the simplicity of the hypotheses and power of the conclusion of this
theorem. From Sharkovsky’s result, we know that a continuous function that
has a periodic point of period 6 must also have cycles of all periods except
possibly an odd number greater than one. Similarly, if F has period 56 = 7·23,
then F must also have periods 72, 88, 104, . . . , 8, 4, 2, and 1—the entire tail of
the Sharkovsky list.
Perhaps even more amazing is the fact that the converse of Sharkovsky’s
Theorem is also true:
Theorem. There is a continuous function F : R →R, which has a cycle
of prime period n but no cycles of any prime period that precedes n in the
Sharkovsky ordering.
Remarks:
1. Sharkovsky’s Theorem is also true if F : I →I is continuous, where I is a
closed interval of the form [a, b]. We simply extend F to the entire real line
by deﬁning F(x) = F(a) if x < a, and F(x) = F(b) if x > b. The resulting
extension is clearly a continuous function.
2. Note that the Period-3 Theorem is an immediate corollary of Sharkovsky’s
Theorem: 3 heads the list of numbers in Sharkovsky’s ordering. Hence a con-
tinuous function with a 3-cycle has all other periods.

144
Sharkovsky’s Theorem
3. Note also that the numbers of the form 2n form the tail of the Sharkovsky
ordering. Thus, if F has only ﬁnitely many periodic points, then they all must
have periods of a power of 2. This explains in part why we always see period
doubling at the outset when a family of functions makes the transition from
simple dynamics to chaos.
4. Sharkovsky’s Theorem is not true if the “space” in question is anything
but the real line or interval. For example, the function on the circle that just
rotates all points by a ﬁxed angle 2π/n has periodic points of period n and
no other periods.
We will not present the full proof of Sharkovsky’s Theorem. The proof is
not diﬃcult: it basically involves repeated applications of the two observations
we made in the previous section. However, the two intervals I0 and I1 used in
the proof of the Period-3 Theorem must be replaced by n −1 intervals. This
means that the “bookkeeping” becomes considerably more involved. See [10]
for more details. Instead, we will give a ﬂavor of the full proof by dealing with
several special cases.
Case 1: Period k ⇒Period 1. This follows from the Intermediate Value
Theorem. Suppose x1, . . . , xk lie on the k-cycle, with
x1 < x2 < · · · < xk.
Now F(x1) must be one of the xi with i > 1, and F(xk) is similarly an xi with
i < k. Thus F(x1) = xi for some i > 1, we have F(x1) −x1 > 0. Similarly
F(xk)−xk < 0. Therefore, there is an x between x1 and xk with F(x)−x = 0,
which gives us a ﬁxed point.
Case 2: Period 4 ⇒Period 2. This case is more complicated. Suppose
x1, x2, x3, x4 form the 4-cycle with
x1 < x2 < x3 < x4.
Choose a point a between x2 and x3. Then there are two cases. The ﬁrst case
occurs if both F(x1) > a and F(x2) > a. Then we must have F(x3) < a and
F(x4) < a. Let I0 = [x1, x2] and I1 = [x3, x4]. Since the xi’s are permuted, it
follows that F(I1) ⊃I0 and F(I0) ⊃I1. Our two observations in Section 11.1
then guarantee that there is a 2-cycle that hops between I0 and I1.
The other case occurs when one of x1 or x2 is mapped to the right of a
but the other is not. For deﬁniteness, suppose F(x1) > a and F(x2) < a.
Consequently, we must have F(x2) = x1. Let I0 = [x2, x3] and I1 = [x1, x2]
(see Figure 11.5). Then we have F(I0) ⊃I1 and F(I1) ⊃I0 ∪I1. This is the
same situation we encountered in the proof of the Period-3 Theorem. Hence
there is a cycle of period 2 (and, in fact, a cycle of any period). The other
possibility is handled in similar fashion, except that we must make diﬀerent
choices for I0 and I1.

Sharkovsky’s Theorem
145
FIGURE 11.5
Period 4 ⇒Period 2.
Case 3: Period 2n ⇒Period 2k when n > k. The previous two cases take care
of the case when n = 1 or 2, so we assume n ≥3. Let ℓ= 2n−2 and consider
G(x) = F ℓ(x). The cycle of period 2n for F is a cycle of period 4 for G. It
follows from the previous case that G has a 2-cycle. But this 2-cycle for G is
a 2n−1-cycle for F. Continuing in this fashion, we see that F has cycles of all
periods 2k where k < n.
Now let us give several examples of the converse of Sharkovsky’s Theorem.
Example. Figure 11.6 shows a sketch of the graph of a piecewise linear2
function deﬁned on the interval 1 ≤x ≤5. Note that
F(1)
= 3
F(3)
= 4
F(4)
= 2
F(2)
= 5
F(5)
= 1
so that we have a 5-cycle:
1 →3 →4 →2 →5 →1 . . . .
To see that F has no periodic point of period 3, we assume that there is
such a point. From the graph, we see that
F([1, 2])
= [3, 5]
F([3, 5])
= [1, 4]
F([1, 4])
= [2, 5].
Hence, F 3([1, 2]) = [2, 5] so F 3([1, 2])∩[1, 2] = {2}, which has period 5. Hence
F 3 has no ﬁxed points in [1, 2].
2Piecewise linear simply means that the graph of the function is a ﬁnite collection of
straight lines.

146
Sharkovsky’s Theorem
FIGURE 11.6
F has period 5 but not period 3.
Similar arguments show that there are no 3-cycles in either of the intervals
[2, 3] or [4, 5]. We cannot use the same argument in the interval [3, 4], since F
itself has a ﬁxed point within this interval. However, we note that
F : [3, 4] →[2, 4]
is a decreasing function. Also,
F : [2, 4] →[2, 5]
and
F : [2, 5] →[1, 5]
are also decreasing. The composition of an odd number of decreasing functions
is decreasing. Hence
F 3 : [3, 4] →[1, 5]
is decreasing. Thus the graph of F 3 on [3, 4] meets the diagonal over [3, 4] in
exactly one point. This point must be the ﬁxed point of F. Therefore F has
no 3-cycles in [3, 4] as well. Consequently, this function has a period-5 point
but no period-3 point.
Example. Figure 11.7 shows the graph of a piecewise linear function that has
a 7-cycle given by
1 →4 →5 →3 →6 →2 →7 →1 →. . . .
Arguments similar to those in the previous example show that F has no 5-
cycle. See Exercise 6 at the end of the chapter.

The Period-3 Window
147
FIGURE 11.7
F has a 7-cycle but no 5-cycle.
11.3
The Period-3 Window
Now let’s return to our friend, the quadratic family Qc(x) = x2 + c. Recall
from Chapter 8 that there is an interval of c-values in which Qc apparently
has an attracting 3-cycle. In the corresponding window in the orbit diagram
we saw only this 3-cycle—not any of the other periodic points whose existence
Sharkovsky’s Theorem guarantees. In this and the next section we will locate
these points and show how to use symbolic dynamics to analyze them.
Using the orbit diagram for Qc, one may check that the period 3 window
ﬁrst opens for c ≈−1.75. Figure 11.8 shows the graphs of Q3
c for two c-
values near −1.75. These graphs show that this family undergoes a saddle-
node bifurcation as c decreases through −1.75 . . . .
For the remainder of this section we will consider the speciﬁc parameter
value c = −1.7548777 . . . . This value is chosen so that 0 lies on the attracting
3-cycle
0 →c →c2 + c →0.
So c is the nonzero root of the equation
0 = Q3
c(0) = (c2 + c)2 + c
(see Figure 11.9). For simplicity of notation, we will write Q = Q−1.7548777...
for the remainder of this and the next section. This c-value is called a super-
stable parameter since the derivative of Q3 along the attracting 3-cycle is 0.
Figure 11.10 shows the graph of Q3. Although diﬃcult to see from afar,
this graph has eight ﬁxed points, the two ﬁxed points of Q, the attracting

148
Sharkovsky’s Theorem
FIGURE 11.8
Graphs of Q3
c for (a) c = −1.7, (b) c = −1.76.
FIGURE 11.9
The attracting 3-cycle for Q contains 0.
3-cycle, and another repelling 3-cycle which we denote by
α →β →γ →α
with γ < β < α. From this graph we see that each of α, β, and γ has a nearby
point ˆα, ˆβ, and ˆγ, respectively, that satisﬁes
Q3(ˆα)
=
α
Q3(ˆβ)
=
β
Q3(ˆγ)
=
γ.

The Period-3 Window
149
FIGURE 11.10
The graph of Q3.
FIGURE 11.11
Magniﬁcation of the graph of Q3 showing α, ˆα.
Figure 11.11, the enlarged graph of Q3 in the vicinity of α, clearly shows the
relative positions of α and ˆα.
By graphical analysis we see that any point in the interval (α, ˆα) has an
orbit that tends under Q3 to the attracting ﬁxed point for Q3 in this interval.
The same is true in the intervals (β, ˆβ) and (ˆγ, γ). Hence we know the fate of
any orbit that enters one of these intervals—it tends to the attracting 3-cycle.
In particular, there are no other cycles in these intervals.

150
Sharkovsky’s Theorem
In Figure 11.12 we have superimposed the graphs of Q and Q3. These
graphs show that
Q(ˆα)
=
ˆβ
Q(ˆγ)
=
ˆα,
but
Q(ˆβ) = γ.
We also have
Q([α, ˆα])
=
[β, ˆβ]
Q([ˆγ, γ])
=
[α, ˆα],
but
Q([β, ˆβ]) ⊂[ˆγ, γ]
since Q(β) = Q(ˆβ) = γ.
FIGURE 11.12
Graphs of Q and Q3 superimposed. The orbit of ˆα is displayed, with ˆα the
rightmost point on the orbit, and ˆα →ˆβ →γ →α.
Let I1 = [ˆβ, α] and I0 = [γ, β]. From the graph we see that Q maps
I1 in one-to-one fashion onto I0 while Q takes I0 into I0 ∪(β, ˆβ) ∪I1. See
Figure 11.13. In particular, just as in the proof of the Period-3 Theorem, we
have
Q(I1)
⊃
I0
Q(I0)
⊃
I1 ∪I0.
Thus the proof of that theorem shows that we have periodic points of all
periods in I0 ∪I1.

Subshifts of Finite Type
151
FIGURE 11.13
The images of Q(I0) and Q(I1).
In fact, all cycles (except p+ and the attracting 3-cycle) lie in I0 ∪I1. The
only other possible locations for cycles would be in the intervals (ˆα, p+) and
(−p+, ˆγ). But graphical analysis shows that the orbit of any point in these
intervals eventually enters the interval [ˆγ, ˆα]. Once in this interval, the orbit
may never escape, since Q([ˆγ, ˆα]) ⊂[ˆγ, ˆα]. Indeed, Q([ˆγ, ˆα]) ⊂[c, ˆα] and ˆγ < c.
Thus, to understand the dynamics of Q completely, we need only analyze
the behavior of Q in the intervals I0 and I1. A slight variation of symbolic
dynamics allows us to accomplish this.
11.4
Subshifts of Finite Type
We continue using the notation Q(x) = x2 −1.7548777 . . . . To understand
the dynamics of Q completely, we need to analyze the orbits that remain for
all time in I0 ∪I1. Recall that if an orbit of a point in I0 ∪I1 ever leaves
these intervals, then that orbit must enter (β, ˆβ) and thus be attracted to the
attracting 3-cycle. Therefore, we need to understand the dynamics of Q on
the set Λ deﬁned by
Λ = {x ∈I0 ∪I1 | Qn(x) ∈I0 ∪I1 for all n}.
For a point x in Λ we deﬁne the itinerary of x, S(x), exactly as we did in
Chapter 9:
S(x) = (s0s1s2 . . .),
where sj = 0 or 1 for all j, and sj = 0 if Qj(x) ∈I0, sj = 1 if Qj(x) ∈I1.
There is one signiﬁcant diﬀerence between the possible itineraries for Q and
those for the quadratic map Qc with c < −2 discussed earlier. Suppose x
has itinerary (s0s1s2 . . .) and Qj(x) ∈I1 so that sj = 1. Since Q(I1) = I0,
it follows that Qj+1(x) ∈I0. Hence sj+1 = 0. Therefore we see that, if any
entry of the itinerary of x is 1, the entry that immediately follows must be

152
Sharkovsky’s Theorem
0. That is, not all sequences of 0’s and 1’s are allowable itineraries for Q in
Λ. For example, neither (111 . . .) nor (110110110 . . .) correspond to itineraries
of points in Λ. Equivalently, there is no ﬁxed point that resides in I1, so
(111 . . .) is not allowable. From Figure 11.12 we see that Q has a ﬁxed point
in (γ, β) ⊂I0. That is why (000 . . .) is an allowable itinerary.
Mimicking what we did in Chapter 9, we denote by Σ′ the set of all
itineraries that satisfy the above condition; that is,
Σ′ = {(s0s1s2 . . .) | sj = 0 or 1, but if sj = 1 then sj+1 = 0}.
Note that Σ′ ⊂Σ, the set of all possible sequences of 0’s and 1’s. So we may
use the same distance function introduced in Chapter 9 to measure distances
in Σ′. In particular, we may use this to show that Σ′ is a closed subset of
Σ. We are familiar with the notion of open and closed intervals in R. More
generally, we may deﬁne open and closed sets as follows.
Deﬁnition. Suppose Y is a subset of a set X equipped with a metric d. We
say that Y is an open subset of X if for any y ∈Y there is an ϵ > 0 such that,
if d[x, y] < ϵ, then x ∈Y .
That is, open sets have the property that we can always ﬁnd a small open
“ball” in Y —all points within distance ϵ—around any point in Y .
Deﬁnition. A subset V ⊂X is a closed set if the complement of V is an open
subset of X.
Thus, to show that Σ′ ⊂Σ is a closed subset, we must verify that its com-
plement is open. To see this, choose a point s = (s0s1s2 . . .) in the complement
of Σ′. We must produce an ϵ > 0 such that all points within ϵ of s also lie in
the complement of Σ′.
Since s ̸∈Σ′, there must be at least one pair of adjacent 1’s in the sequence
(s0s1s2 . . .). Suppose k is such that sk = sk−1 = 1. Let’s choose ϵ < 1/2k.
If t ∈Σ satisﬁes d[s, t] < ϵ, then the Proximity Theorem guarantees that
t0 = s0, . . . , tk = sk. In particular, tk = tk−1 = 1. Therefore t lies in the
complement of Σ′ and we have found a small “ball” about s in the complement
of Σ′. This proves that Σ′ is closed. So we have:
Proposition. Σ′ ⊂Σ is a closed subset.
The shift map σ also makes sense on Σ′. For if s is a sequence with no
pair of adjacent 1’s, then σ(s) also has this property. The natural question is
what is the relationship between Q on Λ and the shift σ restricted to Σ′. As
you might expect, the itinerary function S : Λ →Σ′ provides the answer.

Subshifts of Finite Type
153
Theorem. The itinerary function S : Λ →Σ′ is a conjugacy between Q: Λ →
Λ and σ: Σ′ →Σ′.
We will not provide the details of the proof since it is essentially the same
as that of Conjugacy Theorem in Chapter 9. The one important diﬀerence
is that |Q′(x)| is not everywhere larger than 1 on I0 ∪I1. However, one may
check that |(Qk)′(x)| > 1 for some k and all x ∈I0 ∪I1, and this is suﬃcient
to complete the proof. Full details may be found in [10].
The shift map is also chaotic on Σ′. Notice that this needs proof; just
because periodic points are dense in Σ, it does not necessarily follow that
they are dense in a subset of Σ. Similarly, how do we know that there is a
dense orbit in Σ′? We will leave the proofs of these facts as exercises since
these proofs are similar in spirit to those in Chapter 8.
Theorem. The shift map σ: Σ′ →Σ′ is chaotic.
From Sharkovsky’s Theorem we know that Q has periodic points of all
periods in Λ, but this result gives us no indication of how many cycles Q has.
For this information, we again make use of the symbolic dynamics.
Let Pern denote the set of sequences in Σ′ that are ﬁxed by σn. Note that
Per1 contains only one sequence, (000), while Per2 contains (0101), (1010),
and (000). Our goal is to ﬁnd a formula for the number of sequences in Pern
for all n.
There are three distinct types of sequences in Pern, namely
An
=
{(s0 . . . sn−1) ∈Pern | s0 = 0, sn−1 = 1}
Bn
=
{(s0 . . . sn−1) ∈Pern | s0 = 1, sn−1 = 0}
Cn
=
{(s0 . . . sn−1) ∈Pern | s0 = 0 = sn−1}.
Note that a repeating sequence of the form (1s1 . . . sn−21) does not lie in Σ′.
Let #Pern denote the number of points in Pern. Then we have
#Pern = #An + #Bn + #Cn
since An, Bn, and Cn are mutually exclusive.
To determine #Pern we will show that there is a one-to-one correspondence
between Pern+2 and Pern+1 ∪Pern. This will prove:
Theorem. #Pern+2 = #Pern+1 + #Pern for n > 0.
Proof. Choose any s = (s0s1 . . . sn+1) ∈Pern+2. We will associate a unique
sequence in either Pern+1 or Pern to s. If s0 = sn+1 then we must have
s0 = sn+1 = 0, since adjacent 1’s are not allowed. Now sn may be either 0

154
Sharkovsky’s Theorem
or 1, so s ∈Pern+2 with s0 = sn+1 = 0 determines a repeating sequence of
length n + 1, namely (0s1 . . . sn), which lies in either An+1 or Cn+1.
On the other hand, if s ∈Pern+2 but s0 ̸= sn+1, then we have two cases.
First, if s0 = 0 and sn+1 = 1, then sn = 0. So sn−1 may be either 0 or 1. Thus
s determines a unique sequence (0s1 . . . sn−1) in either An or Cn.
Finally, if s0 = 1 and sn+1 = 0, then sn may be either 0 or 1. If sn = 1
then s determines (1s1 . . . sn−1), which lies in Bn since sn−1 = 0. If sn = 0
then s determines (1s1 . . . sn−10) in Bn+1.
Now recall that Pern = An ∪Bn ∪Cn. Thus we may associate a unique
sequence in either Pern+1 or Pern to any sequence in Pern+2. Reversing the
above procedure yields the converse. This completes the proof.
This theorem allows us to determine recursively the number of periodic
points in Λ. We have already seen that #Per1 = 1 and #Per2 = 3. Then the
recursive relation yields
#Per3
=
4
#Per4
=
7
#Per5
=
11
#Per6
=
18
and so forth.
We remark that the recursive relation
#Pern+2 = #Pern+1 + #Pern
generates the well-known Fibonacci sequence when #Per1 = 1 and #Per2 = 1.
So the classical Fibonacci sequence is
1, 1, 2, 3, 5, 8, 13 . . . ,
and ours is a slight variation on this theme.
The shift map σ on Σ′ is called a subshift of ﬁnite type. It is a subshift
since Σ′ ⊂Σ. It is of ﬁnite type since it is determined by only ﬁnitely many
conditions on the entries of sequences in Σ′. In our case, the only condition is
that 1 may not follow 1.
More generally, subshifts of ﬁnite type occur as subshifts of the shift on N
symbols. Let ΣN denote the set of all sequences whose entries are 0, 1, . . . , N −
1. See the exercises following Chapter 9 regarding this set. A subshift of ﬁnite
type is deﬁned by prescribing which digits are allowed to follow given digits in
an allowable sequence. This may be visualized most eﬀectively as a directed
graph with vertices 0, 1, . . . , N −1. A directed graph consists of arrows passing
from vertices to vertices with at most one arrow going from vertex i to vertex
j. These arrows are directed, so there may be another arrow going from j
to i. The allowable sequences are then all inﬁnite paths through this graph.
For example, the subshift of ﬁnite type for which 0 cannot follow 0 but 1

Subshifts of Finite Type
155
can be followed by either 0 or 1 corresponds to the graph in Figure 11.14a.
Figure 11.14b depicts the directed graph corresponding to the full shift on 2
symbols.
FIGURE 11.14
Directed graphs for subshifts of ﬁnite type.
Subshifts of ﬁnite type need not have chaotic dynamics. For example, the
directed graph in Figure 11.15 corresponds to the subshift for which 0 may
follow 0 or 1, but 1 may only follow 1; 1 cannot follow 0.
Note that the only allowable sequences in this subshift are those of the
form
(000 . . .)
(111 . . .)
(111 . . . 1000 . . .).
Thus there are only two ﬁxed points for this dynamical system, no other
periodic points, and no dense orbit.
Exercises
1. Can a continuous function on R have a periodic point of period 48 and not
one of period 56? Why?
FIGURE 11.15
A nonchaotic subshift of ﬁnite type.

156
Sharkovsky’s Theorem
2. Can a continuous function on R have a periodic point of period 176 but
not one of period 96? Why?
3. Give an example of a function F : [0, 1] →[0, 1] that has a periodic point
of period 3 and no other periods. Can this happen?
4. The graphs in Figure 11.16 each have a cycle of period 4 given by {0, 1, 2, 3}.
One of these functions has cycles of all other periods, and one has only periods
1, 2, and 4. Identify which function has each of these properties.
FIGURE 11.16
Two graphs with period 4.
5. Suppose a continuous function F has a cycle of period n ≥3 given by
a1 < a2 < · · · < an. Suppose that F permutes the ai according to the rule
a1 →a2 →· · · an →a1. What can you say about the periods of the other
cycles for F?
6. Consider the piecewise linear graph in Figure 11.7. Prove that this function
has a cycle of period 7 but not period 5.
7. Consider the graph in Figure 11.17a. Prove that this function has a cycle
of period 6 but no cycles of any odd period.
8. Consider the function whose graph is displayed in Figure 11.17b. Prove
that this function has cycles of all even periods but no odd periods (except
1).
9. Consider the subshift of ﬁnite type Σ′ ⊂Σ determined by the rules 0 may
follow 1 and both 0 and 1 may follow 0, as discussed in Section 11.4.
a. Prove that periodic points for σ are dense in Σ′.
b. Prove that there is a dense orbit for σ in Σ′
The following four problems deal with the subshift of Σ3, the space of
sequences of 0’s, 1’s, and 2’s, determined by the rules that 1 may follow 0, 2
may follow 1, and 0, 1, or 2 may follow 2.

Subshifts of Finite Type
157
(a.)
(b.)
FIGURE 11.17
The graphs for exercises 7 and 8.
FIGURE 11.18
The subshifts associated with Exercises 15 and 16.

158
Sharkovsky’s Theorem
10. Is this subset of Σ3 closed?
11. Are periodic points dense for this subshift?
12. Is there a dense orbit for this subshift?
13. How many periodic points of periods 2, 3, and 4 satisfy these rules?
14. Construct a subshift of ﬁnite type in Σ3 which has a period-3 cycle but
no ﬁxed or period 2 points.
15. Discuss the dynamics of the subshift given by the directed graph in Fig-
ure 11.18a. Are periodic points dense for this subshift? Is there a dense orbit?
How many periodic points of period n does this subshift have?
16. Discuss the dynamics of the subshift given by the directed graph in Fig-
ure 11.18b. Are periodic points dense for this subshift? Is there a dense orbit?

12
Role of the Critical Point
In previous sections we have seen that simple dynamical systems such as the
quadratic family may possess inﬁnitely many periodic points. But, as we saw
in the orbit diagram, very few of them appear to be attracting. In this chapter
we will ﬁnd out why this is so.
12.1
The Schwarzian Derivative
The Schwarzian derivative is one of the stranger tools in dynamics. Although
this derivative has a venerable history in the ﬁeld of complex analysis, it was
only introduced into the study of dynamical systems in 1978. Functions with
negative Schwarzian derivatives have very interesting dynamical properties
that simplify their analysis.
Deﬁnition. The Schwarzian derivative of a function F is
SF(x) = F ′′′(x)
F ′(x) −3
2
F ′′(x)
F ′(x)
2
.
Many functions have negative Schwarzian derivatives. For example, the
quadratic family Qc(x) = x2 + c satisﬁes SQc(x) = −3/(2x2). Note that
SQc(x) < 0 for all x, including the critical point x = 0 where we may deﬁne
SQc(0) = −∞, since limx→0 SQc(x) = −∞. Also,
S(ex) = −1
2 < 0
S(sin x) = −1 −3
2 tan2 x < 0
S(kx(1 −x)) =
−6
(1 −2x)2 < 0.
Note that, in each case, the Schwarzian derivative at critical points is −∞.
We write SF < 0 whenever SF(x) < 0 for all x.
159

160
Role of the Critical Point
Many polynomials have negative Schwarzian derivatives, as the following
proposition shows.
Proposition. Suppose P(x) is a polynomial and all roots of P ′(x) are real
and distinct. Then SP < 0.
Proof: Since P ′(x) has real and distinct roots, we may write
P ′(x) = α(x −a1) · . . . · (x −aN).
Hence
log P ′(x) = log α +
N

i=1
log(x −ai).
Diﬀerentiating log P ′(x) via the Chain Rule, we ﬁnd
P ′′(x)
P ′(x) =
N

i=1
1
x −ai
.
Diﬀerentiating again via the Quotient Rule, we ﬁnd
P ′′′(x)P ′(x) −(P ′′(x))2
(P ′(x))2
=
P ′′′(x)
P ′(x) −
P ′′(x)
P ′(x)
2
=
−
N

i=1
1
(x −ai)2 .
Hence
SP(x)
=
P ′′′(x)
P ′(x) −
P ′′(x)
P ′(x)
2
−1
2
P ′′(x)
P ′(x)
2
= −
N

i=1
1
(x −ai)2 −1
2
 N

i=1
1
x −ai
2
<
0.
This completes the proof.
One reason for the importance of negative Schwarzian derivatives is the fact
that this property is preserved by composition of functions and consequently
by iteration.
Chain Rule for Schwarzian Derivatives. Suppose F and G are functions.
Then
S(F ◦G)(x) = SF(G(x)) · (G′(x))2 + SG(x).

The Schwarzian Derivative
161
Proof: Using the Chain Rule for ordinary derivatives, we compute
(F ◦G)′(x)
=
F ′(G(x)) · G′(x)
(F ◦G)′′(x)
=
F ′′(G(x)) · (G′(x))2 + F ′(G(x)) · G′′(x).
Diﬀerentiating once more,
(F ◦G)′′′(x) = F ′′′(G(x)) · (G′(x))3 + 3F ′′(G(x)) · G′′(x) · G′(x)
+ F ′(G(x)) · G′′′(x).
After a hefty dose of algebra (have fun!), we combine the above formulas to
ﬁnd the result.
Corollary. Suppose SF < 0 and SG < 0. Then S(F ◦G) < 0. In particular,
if SF < 0, then SF n < 0.
Proof: We have SF(G(x)) < 0 and SG(x) < 0 for all x. Hence, by the Chain
Rule for Schwarzian Derivatives,
S(F ◦G)(x) = SF(G(x)) · (G′(x))2 + SG(x) < 0.
It is diﬃcult to see geometrically what the property of negative Schwarzian
derivative means. However, the following result gives an indication of the kind
of graphs that cannot occur for functions with negative Schwarzian derivatives.
Schwarzian Min-Max Principle. Suppose SF < 0. Then F ′ cannot have
a positive local minimum or a negative local maximum.
Proof: Suppose x0 is a critical point of F ′. That is, F ′′(x0) = 0. Suppose also
that F ′(x0) ̸= 0. Then we have
SF(x0) = F ′′′(x0)
F ′(x0) < 0.
Now let’s apply the “second derivative test” from calculus, not to F, but rather
to F ′. (Be careful—this can be confusing!)
If F ′ has a positive local minimum at x0, then its second derivative F ′′′(x0)
must be non-negative. Since F ′(x0) > 0, we have
F ′′′(x0)
F ′(x0) ≥0.
This contradicts SF < 0.

162
Role of the Critical Point
Similarly, if F ′ has a negative local maximum at x0, then F ′′′(x0) ≤0 and
F ′(x0) < 0, again yielding a contradiction. This concludes the proof.
As a consequence of this proposition, we see that the graph shown in
Figure 12.1a cannot occur for a function with negative Schwarzian derivative.
Indeed, there are two points a and b where the derivative is 1. In between,
the slope is less than 1, but never negative. So F ′ must have a positive local
minimum between a and b. This is impossible by the Schwarzian Min-Max
Principle. Figure 12.1b displays a graph where F ′(x) has a negative local
maximum between a and b, each of which has derivative equal to −1. Again,
this kind of graph cannot occur if SF < 0.
FIGURE 12.1
These graphs are impossible if SF < 0.
12.2
Critical Points and Basins of Attraction
In this section we investigate how the assumption of negative Schwarzian
derivative severely limits the kinds of dynamical behavior that may occur. We
will show that each attracting periodic orbit of such a function must attract
at least one critical point of the function. We begin with several deﬁnitions.
Deﬁnition. Suppose x0 is an attracting ﬁxed point for F. The basin of attrac-
tion of x0 is the set of all points whose orbits tend to x0. The immediate basin
of attraction of x0 is the largest interval containing x0 that lies in the basin
of attraction.

Critical Points and Basins of Attraction
163
Basins of attraction for attracting cycles of period n are deﬁned using
F n instead of F. The Attracting Fixed Point Theorem (chapter 5) guar-
antees that attracting ﬁxed points and cycles have immediate basins of
attraction.
In general, but not always, the immediate basin of attraction of an attract-
ing ﬁxed point is smaller than the full basin. For F(x) = x2, the immediate
basin of attraction of the ﬁxed point 0 is (−1, 1). This is also the full basin of
attraction. For C(x) = π cos x, there is an attracting ﬁxed point at −π, but
its basin of attraction is much larger than the immediate basin of attraction
(Figure 12.2).
FIGURE 12.2
The immediate basin of attraction of −π for C(x) = π cos x is smaller than
the full basin.
Our main result in this section is the following.
Theorem. Suppose SF < 0. If x0 is an attracting periodic point for F, then
either the immediate basin of attraction of x0 extends to +∞or −∞, or else
there is a critical point of F whose orbit is attracted to the orbit of x0.
This theorem explains why we see at most one attracting periodic orbit for
the quadratic family Qc(x) = x2 + c. We know that, if |x| is suﬃciently large,
then the orbit of x tends to inﬁnity. Hence no basin of attraction extends to
±∞. Since 0 is the only critical point of Qc and SQc < 0, it follows that Qc
has at most one attracting cycle.
This is also the reason why we always use the critical point to plot the
orbit diagram for such functions as the quadratic or the logistic family. For
these families there is only one critical point. Hence, if these functions have
an attracting cycle, the critical point must “ﬁnd” it.

164
Role of the Critical Point
There may be no critical points in the basin of attraction of attracting
cycles, as the following example shows. The above theorem guarantees that
such basins must extend to inﬁnity, so there can be at most two such orbits.
Example. Consider the function Aλ(x) = λ arctan x. Since
A′
λ(x) =
λ
1 + x2 ,
Aλ has no critical points when λ ̸= 0. If, however, |λ| < 1, then 0 is an
attracting ﬁxed point. The immediate basin of attraction is the entire real
line. If λ > 1, then Figure 12.3 shows that Aλ has two attracting ﬁxed points
and both basins extend to inﬁnity. If λ < −1, Aλ has an attracting 2-cycle,
and again the immediate basin extends to inﬁnity.
FIGURE 12.3
Both immediate basins extend to inﬁnity for Aλ(x) = λ arctan x when λ > 1.
We conclude this chapter by providing a proof of this theorem in the simple
case of a ﬁxed point. For periodic points the proof is similar in spirit, but the
details are more complicated. See [10] for these details.
Proof: We will prove that the immediate basin of attraction of an attracting
ﬁxed point p either contains a critical point or else extends to inﬁnity.
The immediate basin of attraction of p must be an open interval, for oth-
erwise, by continuity, we could extend the basin beyond the endpoints. So
suppose the immediate basin of p is the interval (a, b). If either a or b are
inﬁnite we are done. So suppose both a and b are ﬁnite.
Since F maps the interval (a, b) to itself, it follows that F must preserve
the endpoints of this interval. That is, F(a) must be either a or b, and F(b)
must be a or b as well. Thus there are essentially four possibilities for the
graph of F on the interval (a, b). They are:

Critical Points and Basins of Attraction
165
FIGURE 12.4
The four possible cases for the immediate basin of attraction.
1. F(a) = a, F(b) = b
2. F(a) = b, F(b) = a
3. F(a) = a, F(b) = a
4. F(a) = b, F(b) = b
See Figure 12.4 for a picture of these four possibilities. Note that, in cases
3 and 4, F must have a maximum or a minimum in (a, b), which is therefore
attracted to p, so the theorem is true in these cases.
We deal ﬁrst with case 1. Clearly, F can have no other ﬁxed points besides
p in (a, b). We claim that F(x) > x in (a, p). To see this, note ﬁrst that we
cannot have F(x) = x in (a, p), for this would give a second ﬁxed point in
(a, b). Also, if F(x) < x for all x in (a, p), then graphical analysis shows that p

166
Role of the Critical Point
is not an attracting ﬁxed point. Consequently, we must have F(x) > x in the
interval (a, p). Similar arguments show that F(x) < x in the interval (p, b).
The Mean Value Theorem asserts that there is a point c in (a, p) such that
F ′(c) = F(a) −F(p)
a −p
= a −p
a −p = 1.
Note that c ̸= p since F ′(p) < 1. Similarly, there is a point d in (p, b) for which
F ′(d) = 1.
Thus, on the interval [c, d], which contains p in its interior, we have
F ′(c)
=
1
F ′(d)
=
1
F ′(p)
<
1.
By the Schwarzian Min-Max Principle, F ′ cannot have a positive local mini-
mum in [c, d]. Thus F ′ must become negative in [c, d], so there is at least one
point in the basin of attraction of p at which the derivative vanishes. This
gives us a critical point in the basin.
To handle case 2, we consider G(x) = F 2(x). The ﬁxed point p is still
attracting for G and (a, b) is the immediate basin of attraction of p under
G. Moreover, SG < 0 by the Chain Rule for Schwarzian Derivatives. Since
G(a) = a and G(b) = b the arguments of case 1 show that G must have a
critical point ˆx in (a, b). Since G′(ˆx) = F ′(F(ˆx)) · F ′(ˆx), it follows that one of
ˆx or F(ˆx) is a critical point of F in (a, b). This completes the proof.
As a ﬁnal remark we note that the above arguments work if p is a neutral
ﬁxed point that attracts from one side. Such points must therefore have basins
that extend to inﬁnity or else must attract a critical point.
Exercises
1. Compute the Schwarzian derivative for the following functions and decide
if SF(x) < 0 for all x.
a. F(x) = x2
b. F(x) = x3
c. F(x) = e3x
d. F(x) = cos(x2 + 1)
e. F(x) = arctan x
2. Is it true that S(F + G)(x) = SF(x) + SG(x)? If so, prove it. If not, give
a counterexample.
3. Is it true that S(F · G) = SF(x) · G(x) + F(x) · SG(x)? If so, prove it. If
not, give a counterexample.

Critical Points and Basins of Attraction
167
4. Is it true that S(cF)(x) = cSF(x), where c is a constant? If so, prove it. If
not, give a counterexample.
5. Give an example of a function that has SF(x) > 0 for at least some x-
values.
6. Prove that S(1/x) = 0 and S(ax + b) = 0. Conclude that SF(x) = 0 where
F(x) =
1
ax + b.
7. Compute SM(x) where
M(x) = ax + b
cx + d.
8. Let M be as in the previous exercise. Prove that S(M ◦F) = SF.
9. Give a formula for S(F ◦G◦H)(x) in terms of SF, SG, SH and the deriva-
tives of these functions.
10. Compute the Schwarzian derivatives of each of the following functions:
a. F(x) = tan x
b. F(x) = tan

1
3x+4

c. F(x) = sin

ex2+2
d. F(x) = 1/cos(x2 −2)


13
Newton’s Method
One of the basic applications of iteration is Newton’s method—a classical
algorithm for ﬁnding roots of a function. In this chapter we combine many of
the ideas of previous chapters to give a detailed account of this topic.
13.1
Basic Properties
Consider the problem of trying to ﬁnd the roots of a given function F, i.e.,
solving the equation F(x) = 0. As is well known, this procedure can be carried
out using algebraic methods such as factoring for only a few classes of func-
tions such as low-degree polynomials. For other functions, we must resort to
numerical methods. Among the simplest of these methods is Newton’s method.
This method (sometimes called the Newton-Raphson method) is predicated
on the following idea. Suppose we “guess” that a root of the equation F(x) = 0
is x0. Chances are that x0 will not be a solution of this equation, so we use
x0 to produce a new point x1, which will hopefully be closer to a root. The
point x1 is determined from x0 as follows. Draw the tangent line to the graph
of F at (x0, F(x0)). Unless we have made the unfortunate choice of x0 so
that F ′(x0) = 0, this tangent line is not horizontal and so meets the x-axis
at a new point which we call x1. See Figure 13.1. This is our “new” choice
for a root of F. We then iterate this procedure, with the hope that this pro-
cess will eventually converge to a root. Sometimes this happens, as shown in
Figure 13.2.
To ﬁnd a formula for x1 in terms of x0, we ﬁrst write down the equation
for the tangent line to the graph of F at (x0, F(x0)). The slope of this line is
F ′(x0). Hence the equation of the tangent line assumes the form
y = F ′(x0)x + B,
where B is determined from the fact that (x0, F(x0)) lies on the line. Substi-
tuting this information for x and y in the above equation, we ﬁnd
B = F(x0) −F ′(x0)x0.
Hence the tangent line is given by
y = F ′(x0)(x −x0) + F(x0).
169

170
Newton’s Method
FIGURE 13.1
Newton’s method yields x1 given x0.
Now x1 is determined by setting y = 0 and solving for x. We ﬁnd
x1 = x0 −F(x0)
F ′(x0).
This determines x1 in terms of x0. To apply Newton’s method we iterate this
procedure, determining in succession
x2
=
x1 −F(x1)
F ′(x1)
x3
=
x2 −F(x2)
F ′(x2)
and so forth. As shown in Figure 13.2, this sequence of points x0, x1, x2, . . .
sometimes converges to a root of F.
Thus we see that the question of ﬁnding roots of F may be recast as a
problem of iteration, not of the function F, but rather of an associated function
called the Newton iteration function.
Deﬁnition. Given a function F, the Newton iteration function associated
with F is the function
N(x) = x −F(x)
F ′(x).
Example. Consider F(x) = x2 −1. This function has two roots, at x = ±1.
The associated Newton iteration function is
N(x) = x −x2 −1
2x
= 1
2

x + 1
x

.

Basic Properties
171
FIGURE 13.2
Newton’s method converges to a root of F.
The graph of N is displayed in Figure 13.3. Note that N has two ﬁxed points,
at the roots ±1 of F. Note also that graphical analysis shows that the orbit
of any nonzero point under N converges to one of these ﬁxed points. Hence
Newton’s method succeeds in this case: if we make any initial guess x0 ̸= 0,
the corresponding orbit of x0 under N tends to one of the roots of F. Of
course, one hardly needs Newton’s method for this simple example, but this
does illustrate how this method works.
FIGURE 13.3
Newton’s method for F(x) = x2 −1.
In the above example, the roots of F appear as the ﬁxed points of N. This
is no accident, as we will see in a moment. But ﬁrst we need a digression on
the multiplicity of a root.

172
Newton’s Method
Deﬁnition. A root x0 of the equation F(x) = 0 has multiplicity k if
F [k−1](x0) = 0 but F [k](x0) ̸= 0. Here F [k](x0) is the kth derivative of F
and F [0] = F.
For example, 0 is a root of multiplicity 2 for F(x) = x2 + x3 and of
multiplicity 1 for F(x) = x + x3. It can be shown that if x0 is a root of
multiplicity k for F, then F(x) may be written in the form
F(x) = (x −x0)k G(x),
where G is a function that has no root at x0. See Exercise 11. If F is a
polynomial, then the multiplicity of any root is always ﬁnite. However, there
are examples of functions with roots of inﬁnite multiplicity. For example,
consider G(x) = exp(−1/x2) if x ̸= 0 and set G(0) = 0. It can be shown
that the kth derivative of G vanishes at 0 for all k. So 0 is a root of G with
inﬁnite multiplicity. See Exercise 12.
Newton’s Fixed Point Theorem. Suppose F is a function and N is its
associated Newton iteration function. Then x0 is a root of F of multiplicity k
if and only if x0 is a ﬁxed point of N. Moreover, such a ﬁxed point is always
attracting.
Proof. Suppose for the moment that F(x0) = 0 but F ′(x0) ̸= 0, that is, the
root has multiplicity 1. Then we have N(x0) = x0 so x0 is a ﬁxed point of N.
Conversely, if N(x0) = x0 we must also have F(x0) = 0.
To see that x0 is an attracting ﬁxed point, we use the quotient rule to
compute
N ′(x0) = F(x0)F ′′(x0)
(F ′(x0))2
.
Again assuming F ′(x0) ̸= 0, we see that N ′(x0) = 0 so that x0 is indeed an
attracting ﬁxed point.
This proves the theorem subject to the special assumption that F ′(x0) ̸=
0. If F ′(x0) = 0, we have to work harder. Let’s suppose that the root has
multiplicity k > 1 so that the (k −1)st derivative of F vanishes at x0 but the
kth does not. Thus we may write
F(x) = (x −x0)kG(x),
where G is a function that satisﬁes G(x0) ̸= 0. Then we have
F ′(x) = k(x −x0)k−1G(x) + (x −x0)kG′(x)
F ′′(x) = k(k −1)(x −x0)k−2G(x) + 2k(x −x0)k−1G′(x) + (x −x0)kG′′(x).
Therefore, after some cancellation, we have
N(x) = x −
(x −x0)G(x)
kG(x) + (x −x0)G′(x).

Convergence and Nonconvergence
173
Hence N(x0) = x0, showing that roots of F correspond to ﬁxed points of N
in this case as well. Finally we compute
N ′(x) = k(k −1)(G(x))2 + 2k(x −x0)G(x)G′(x) + (x −x0)2G(x)G
′′(x)
k2(G(x))2 + 2k(x −x0)G(x)G′(x) + (x −x0)2(G′(x))2
where we have factored out (x−x0)2k−2 from both the numerator and denom-
inator. Since G(x0) ̸= 0, we have
N ′(x0) = k −1
k
< 1.
Thus, we again see that x0 is an attracting ﬁxed point for N. This completes
the proof.
Example. Consider F(x) = x2(x −1) so N(x) = x −(x2 −x)/(3x −2). Note
that 0 and 1 are roots. We compute F ′(1) = 1, F ′(0) = 0, but F
′′(0) = −2.
Hence N ′(1) = 0 and N ′(0) = 1/2. The graphs of F and N are depicted in
Figure 13.4.
FIGURE 13.4
The graphs of F(x) = x2(x −1) and N(x) = x −(x2 −x)/(3x −2).
13.2
Convergence and Nonconvergence
Newton’s method, unfortunately, does not always converge. That is, a given
initial guess need not lead to an orbit that tends to one of the attracting ﬁxed
points of N which are, by the Newton Fixed Point Theorem, the roots of F.

174
Newton’s Method
One problem that arises occurs when the function F is not diﬀerentiable
at the root.
Example. Consider F(x) = x1/3. This function is not diﬀerentiable at the
root x = 0. Note that N(x) = −2x, which has a repelling ﬁxed point at 0.
Moreover, all other orbits tend to inﬁnity. Hence we may have no convergence
if the function F is not diﬀerentiable.
Assuming that F is diﬀerentiable may still yield problems. For example,
as we know, it is entirely possible for a dynamical system such as N to have
periodic orbits, which therefore do not tend to ﬁxed points.
Example. Consider F(x) = x3 −5x. We compute
N(x) = x −x3 −5x
3x2 −5 .
The graph of N is shown in Figure 13.5. Suppose we make the natural but
unfortunate initial guess x0 = 1. Then N(1) = −1 and N(−1) = 1 so that ±1
lie on a 2-cycle. Hence this initial guess does not lead to convergence.
FIGURE 13.5
Newton’s method for F(x) = x3 −5x showing a 2-cycle.
Note that, in this example, most of the other initial guesses do lead to
convergence. However, it may happen that intervals of initial guesses can lead
to non-convergence.
Example. Consider F(x) = (x2 −1)(x2 +A) for real values of A. We compute
N(x) = 3x4 + (A −1)x2 + A
4x3 + 2(A −1)x
.

Convergence and Nonconvergence
175
Note that N(−x) = −N(x), so N is an odd function. As we saw earlier, N
has critical points at certain roots of F and also at the points where F ′′(x)
vanishes. Hence we ﬁnd that the points
c± = ±
	
1 −A
6
are critical points for N. In Figure 13.6, the graph of N is shown in the special
case where A = 0.197017 . . . . Note that, in this case, c± both lie on a cycle,
which therefore must be attracting. Hence there is an open interval about each
of these points whose orbits converge to the 2-cycle. Thus, Newton’s method
fails to converge to roots for these initial guesses.
FIGURE 13.6
Newton’s method with an attracting 2-cycle.
The exact value of A for which c± lie on a 2-cycle is (29 −
√
720)/11, as
we ask you to show in Exercise 10. However, it may happen that no initial
guesses lead to convergence. This happens, for example, if F has no roots.
Example. Consider F(x) = x2+1. Obviously, F has no roots on the real line.
But let’s see what happens when we attempt to use Newton’s method anyway.
The Newton iteration function is N(x) = 1
2(x −1
x). Graphical analysis of N
is shown in Figure 13.7. Typical initial conditions seem to lead to orbits that
wander around the real line aimlessly. So we get no convergence to a root, as
we expected.
In fact, N is chaotic in the sense of Chapter 10. Recall the doubling function
D(x) =

2x
0 ≤x < 1/2
2x −1
1/2 ≤x < 1.

176
Newton’s Method
FIGURE 13.7
Chaos in Newton’s method for F(x) = x2 + 1.
As we saw in Chapter 10 (Exercise 20), this function behaves quite chaotically.
Deﬁne C : [0, 1) →R by C(x) = cot(πx). Then we have
C ◦D(x)
=
cot(π · D(x))
=
cot(2πx)
=
cos(2πx)
sin(2πx)
=
cos2(πx) −sin2(πx)
2 sin(πx) cos(πx)
=
1
2

cot(πx) −
1
cot(πx)

=
N ◦C(x).
Therefore, the Newton iteration function for F(x) = x2 + 1 is conjugate to
our friend the doubling function. Consequently, N is chaotic on the entire real
line.
One of the reasons for the importance of Newton’s method is the speed with
which it converges. Recall that if x0 is a root of F for which F ′(x0) ̸= 0, then
x0 is an attracting ﬁxed point for N with N ′(x0) = 0. Fixed points whose
derivative is 0 are called superattracting ﬁxed points because nearby orbits
are attracted to them very quickly. In Table 13.1 we have listed the orbits
of x0 = 100 for the Newton iteration function associated to both x(x + 1)
and x2(x + 1). In the ﬁrst case, the orbit converges rapidly; in the second, it
converges to 0, but not nearly as quickly. The reason is that Newton’s method
for x2 +x has superattracting ﬁxed points, whereas at the root 0 for x2(x+1),
we have N ′(0) = 1/2.

Convergence and Nonconvergence
177
Table 13.1 Orbits for Newton’s method applied to x(x + 1) and x2(x + 1).
There are many other methods for ﬁnding roots of functions, and many of
them involve iteration. Most methods suﬀer from the deﬁciency that they do
not always work. Some methods, when they do converge, do so more rapidly
than others. The trade-oﬀis always how often an algorithm works (its eﬃ-
ciency) versus how quickly it converges (its speed). A full study of the speed
and eﬃciency of algorithms to ﬁnd roots is one of the topics of the ﬁeld of
mathematics known as numerical analysis.
Exercises
1. Use graphical analysis to describe completely all orbits of the associated
Newton iteration function for F when
a. F(x) = 4 −2x
b. F(x) = x2 −2x
c. F(x) = x2/3
d. F(x) = x4 + x2
e. F(x) = 1/x
f. F(x) = 1
x −1
g. F(x) = x/
√
1 + x2
h. F(x) = xex

178
Newton’s Method
2. What happens when Newton’s method is applied to F(x) = √x?
3. Find all ﬁxed points for the associated Newton iteration function for F(x) =
x/(x−1)n when n = 1, 2, 3 . . . . Which are attracting and which are repelling?
4. Consider the Newton iteration function for F(x) = sec x. What are the
ﬁxed points for N? Does this contradict the Newton Fixed Point Theorem?
Why or why not?
5. Suppose P(x) and Q(x) are polynomials, and let F(x) = P(x)/Q(x). What
can be said about the ﬁxed points of the associated Newton function for F?
Which ﬁxed points are attracting and which are repelling?
6. A bifurcation. Consider the family of functions Fμ(x) = x2 + μ. Clearly,
Fμ has two roots when μ < 0, one root when μ = 0, and no real roots when
μ > 0. Your goal in these exercises is to investigate how the dynamics of the
associated Newton iteration function change as μ changes.
a.
Sketch the graphs of the associated Newton iteration function Nμ
in the three cases μ < 0, μ = 0, and μ > 0.
b.
Use graphical analysis to explain the dynamics of Nμ when μ < 0
and μ = 0.
c.
Prove that, if μ > 0, the Newton iteration function for F1 is
conjugate to the Newton iteration function for Fμ via the conju-
gacy H(x) = √μx. Conclude that the Newton iteration function is
chaotic for μ > 0.
d.
Find an analogous conjugacy when μ < 0.
7. A more complicated bifurcation. Consider the family of functions given by
Gμ(x) = x2(x −1) + μ.
a.
Sketch the graphs of the associated Newton iteration function Nμ
in the three cases of μ > 0, μ = 0, and μ < 0.
b.
Use graphical analysis to discuss the fate of all orbits in case μ = 0.
c.
Show that Nμ has exactly one critical point that is not ﬁxed for all
but one μ-value.
d.
What is the fate of the orbit of this critical point when μ > 0?
Describe this using graphical analysis.
e.
Now consider the case of μ < 0. In an essay, describe possible fates of
the orbit of this “free” critical point. Can you ﬁnd μ-values for which
this critical point is periodic? (This can be done experimentally on
a computer.) If this critical point is periodic (not ﬁxed) for a given
μ-value, what can you conclude about the convergence of Newton’s
method?

Convergence and Nonconvergence
179
8. Consider the function G(x) = x4 −x2 −11/36.
a.
Compute the inﬂection points of G. Show that they are critical
points for the associated Newton function.
b.
Prove that these two points lie on a 2-cycle.
c.
What can you say about the convergence of Newton’s method for
this function?
9. Use calculus to sketch the graph of the Newton iteration for F(x) = x(x2 +
1). For which x-values does this iteration converge to a root?
10. Prove that two of the critical points for the Newton iteration function
associated with
F(x) = (x2 −1)(x2 + A)
lie on a 2-cycle when A = (29 −
√
720)/11.
11. Prove that the equation F(x) = 0 has a root of multiplicity k at x0 if and
only if F(x) may be written in the form
F(x) = (x −x0)k G(x),
where G does not vanish at x0. Hint: Use the Taylor expansion of F about
x0.
12. Let G(x) = exp(−1/x2) if x ̸= 0 and set G(0) = 0. Compute the Newton
iteration function N for G. What can be said about the ﬁxed point of N?
Why does this occur?


14
Fractals
Technically, there is no connection between the ﬁelds of dynamical systems and
fractal geometry. Dynamics is the study of objects in motion such as iterative
processes; fractals are geometric objects that are static images. However, it has
become apparent in recent years that most chaotic regions for dynamical sys-
tems are fractals. Hence, in order to understand chaotic behavior completely,
we must pause to understand the geometric structure of fractals. This is the
topic of this chapter. We have seen the prototypical fractal, the Cantor set,
when we discussed the quadratic mapping in Chapter 7. We will see many
more such objects when we discuss complex dynamics in Chapters 16–18.
14.1
The Chaos Game
Before we begin the study of the geometry of fractal sets, we pause to show
how these sets arise as the “chaotic regime” for a dynamical system. Consider
the following process, which has been called the “Chaos Game”[3]. Begin with
three points A, B, and C in the plane forming the vertices of a triangle. Then
choose any point p0 in the plane as the initial seed for the iteration. The point
p0 need not be chosen inside the triangle.
The next point on the orbit of p0 is determined by randomly choosing
one of A, B, or C and then moving p0 halfway toward the selected vertex.
That is, p1 is the midpoint of the line between p0 and the chosen vertex.1 To
continue, we again choose one of A, B, or C randomly and then let p2 be the
midpoint of the line segment between p1 and the chosen vertex. In general,
pn+1 is obtained from pn similarly.
The sequence of points p0, p1, p2 . . . is, as usual, called the orbit of p0. As
with any dynamical system, the question is what is the fate of the orbit of
p0 under this iteration? It appears that the answer to this question would be
heavily dependent upon which sequence of vertices we choose. For example, if
we always choose A as the vertex (hardly a random choice!), then it is clear
that the pi simply converge to A. If we always choose vertex B, then the pi
1A nice way of describing this is to let A represent 1 and 2 on a die, B represent 3 and
4, and C represent 5 and 6. Rolling the die then provides the mechanism for determining
the vertex toward which we move at each step.
181

182
Fractals
converge to B. For the remainder of this section, we will always assume that
the iterations are chosen randomly.
There are then three major surprises that result from this random iterative
process. The ﬁrst surprise is that the fate of the orbit is a distinct geomet-
ric image, not a random mess as one might expect. In Figure 14.1, we have
displayed the outcome of this iterative process. To produce this picture, we
have randomly iterated 20,000 times, but did not display the ﬁrst 100 points
on the orbit. The resulting image is the Sierpinski triangle (sometimes called
the Sierpinski gasket). Then the second surprise is that this object is a fractal,
the subject of the remainder of this section.
FIGURE 14.1
The Sierpinski triangle.
Before delving in to the concept of fractals, let’s ﬁrst ask why does the
Sierpinski triangle result from this iterative process? Suppose that we started
with the initial point p0 located inside the largest white vacant triangle in
the middle of the Sierpinski triangle. Why do we see no point there? Well,
remember, we did not plot the ﬁrst 100 points on the orbit of p0, so we would
have erased p0. Then where does the next point p1 on the orbit lie? The three
original vertices A, B, and C that we chose now lie at the vertices of the
Sierpinski triangle. So, given our choice of one of these vertices, we move half
the distance to that point. A little geometry shows that the point p1 then
lies inside one of the three smaller white vacant triangles located between the
largest white vacant triangle and the three vertices. And we would have also
erased p1. Then this process continues. To ﬁnd p2, we move halfway from p1 to
one of A, B, or C. This time p2 ends up in one of the nine next smaller-sized
white vacant triangles. And on and on. After iterating very few times, our
point ends up in a white vacant triangle that is so small that we cannot see it
because of the resolution of this image. Then this orbit just bounces randomly
around the Sierpinski triangle.

The Cantor Set Revisited
183
So what do we mean by a fractal? There are a number of diﬀerent deﬁni-
tions of fractals that are currently in use. We prefer the following deﬁnition:
Deﬁnition. A fractal is a subset of Rn which is self-similar and whose fractal
dimension exceeds its topological dimension.
Obviously, some terms in this deﬁnition need explanation. We will see
later that the fractal dimension of a set need not be an integer, so this will
necessitate careful explanation as well. We will elaborate on these concepts
after ﬁrst giving four classical examples of fractal sets.
We should admit that there are many other possible deﬁnitions of a fractal
set. In particular, there are many other possible notions of the dimension of a
set, including Hausdorﬀdimension, capacity dimension, correlation dimension,
and others. We will consider here only the most elementary of these notions—
fractal dimension.
Then the third surprise arising from this iterative process is that, as long
as you have a keen eye for geometry, you can “read oﬀ” the rules that we used
to produce this image via the chaos game. Look carefully at the Sierpinski
triangle. You can see that this set consists of three self-similar pieces, one
attached to each of the vertices. And each of these self-similar pieces is exactly
one-half the size of the entire Sierpinski triangle. And these were exactly the
rules we used to create this image: three self-similar pieces (same as the number
of vertices we chose), and each self-similar piece is exactly one-half the size
of the whole Sierpinski triangle (and that was the rule we used to iterate:
move one-half the distance to each vertex when that vertex was called). We
will discuss these geometric ideas in more detail when we describe iterated
function systems later in this chapter.
14.2
The Cantor Set Revisited
We begin the study of the geometry of fractal sets by considering four impor-
tant examples. The ﬁrst is an old friend, the Cantor middle-thirds set. We
have seen already that sets like this occur naturally as the chaotic regime for
the quadratic family Qc(x) = x2 + c when c < −2.
Recall that the Cantor middle-thirds set C is obtained by successively
removing open middle thirds of intervals from the unit interval. The procedure
is depicted in Figure 14.2.
One of the most important properties of a fractal is called self-similarity.
Roughly speaking, self-similarity means that, if we examine small portions of
the set under a microscope, the image we see resembles our original set. For
example, look closely at C. Note that C may be decomposed into two distinct
subsets, the portion of C in [0, 1/3] and the portion in [2/3, 1]. If we magnify

184
Fractals
FIGURE 14.2
Construction of C, the Cantor middle-thirds set.
each of these portions of the Cantor set by a factor of three, we see that they
become the original Cantor set C.
More precisely, to magnify these portions of C, we use an aﬃne transfor-
mation. Let L(x) = 3x. If we apply L to the portion of C in [0, 1/3], we see
that L maps this portion onto the entire Cantor set. Indeed, L maps [1/9, 2/9]
to [1/3, 2/3], [1/27, 2/27] to [1/9, 2/9], and so forth (Figure 14.3). Each of the
gaps in the portion of C in [0, 1/3] is taken by L to a gap in C. That is, the
“microscope” we use to magnify C ∩[0, 1/3] is just the aﬃne transformation
L(x) = 3x.
To magnify the other half of C, namely C ∩[2/3, 1], we use another aﬃne
transformation, R(x) = 3x−2. Note that R(2/3) = 0 and R(1) = 1 so R takes
[2/3, 1] linearly onto [0, 1]. As with L, R takes gaps in C ∩[2/3, 1] to gaps in
C, so R again magniﬁes a small portion of C to give the entire set.
Using more powerful “microscopes,” we may magnify arbitrarily small por-
tions of C to give the entire set. For example, the portion of C in [0, 1/3] itself
decomposes into two self-similar pieces: one in [0, 1/9] and one in [2/9, 1/3].
We may magnify the left portion via L2(x) = 9x to yield C and the right
portion via R2(x) = 9x −2. Note that R2 maps [2/9, 1/3] onto [0, 1] linearly
as required.
Note also that, at the nth stage of the construction of C, we have 2n small
copies of C, each of which may be magniﬁed by a factor of 3n to yield the
entire Cantor set. This is self-similarity.
14.3
The Sierpinski Triangle
Now let’s consider another fractal set, the Sierpinski triangle (sometimes called
the Sierpinski gasket), which we encountered earlier while playing the chaos
game. Like the Cantor middle-thirds set, this object may also be obtained via
an inﬁnite sequence of “removals.” Begin with the equilateral triangle shown
in Figure 14.4. Then remove from the middle a triangle whose size is exactly

The Sierpinski Triangle
185
FIGURE 14.3
Self-similarity of the Cantor middle-thirds set.
half that of the original triangle. This leaves three smaller equilateral triangles,
each of which is exactly one-half the size of the original triangle. Now continue
this process. Remove the middle portions of each of the remaining triangles,
leaving nine equilateral triangles, and so forth. The resulting image after car-
rying this procedure to the limit is the Sierpinski triangle. This is exactly the
same set that is displayed in Figure 14.1. Note how the same image may be
obtained in two remarkably diﬀerent ways: via the deterministic process of
removing triangles as above and also via the random iterative methods of the
chaos game.
FIGURE 14.4
Constructing the Sierpinski triangle.
Like the Cantor middle-thirds set, the Sierpinski triangle is also self-similar.
However, in this case, the magniﬁcation factor is 2. For example, after remov-
ing the middle equilateral triangle in the ﬁrst step of this construction, we are
left with three smaller copies of the Sierpinski triangle, each of whose size is

186
Fractals
one-half the size of the entire triangle. At the nth stage of this construction,
we have 3n Sierpinski triangles, each of which may be magniﬁed by a factor
of 2n to yield the entire set.
There are many fractals that may be constructed via variations on this
theme of inﬁnite removals. For example, we may construct a similar set by
beginning with a right triangle, as in Figure 14.5. Another fractal, the “box”
fractal, is obtained by successively removing squares whose sides are one-third
as long as their predecessors, as shown in Figures 14.6 and 14.7.
FIGURE 14.5
Construction of another Sierpinski triangle.
FIGURE 14.6
Construction of the box fractal.
Note that the Sierpinski triangle and the box fractal are both connected
sets. If we remove slightly larger triangles or squares at each stage, then the
resulting set would become totally disconnected as in the case of the Cantor
middle-thirds set
14.4
The Sierpinski Carpet
Another interesting fractal is the Sierpinski carpet, which, in some sense, is the
most important planar fractal. This set is constructed as follows. Start with a

The Sierpinski Carpet
187
FIGURE 14.7
The box fractal.
square. Break this square into nine equal-sized subsquares. Then remove the
open middle subsquare. This leaves behind eight equal-sized subsquares. Then
repeat this process: break each subsquare into nine equal-sized subsquares and
then remove the open middle subsquare. Continuing this process inﬁnitely
often yields the Sierpinski carpet. See Figure 14.8.
FIGURE 14.8
The Sierpinski carpet fractal.
The Sierpinski carpet can also be generated by a random iteration process,
just like the Sierpinski triangle. This time, however, we need to use a diﬀerent
number of vertices and a diﬀerent contraction factor. This time we start with
a square. Then put vertices A-D at the corners of the square. Also put vertices
E-H at the midpoints of the edges of the square. Then, whenever one of these
eight vertices is called, we move the point on the orbit two-thirds of the way

188
Fractals
toward the corresponding vertex to generate the next point on the orbit.
Equivalently, we just contract the distance from the point to the vertex by a
factor of three. Then, playing this chaos game results in the Sierpinski carpet.
One reason this fractal is considered the most important planar fractal is
that there is an easy way to show that certain planar sets are homeomorphic
to the carpet. Recall that a set is homeomorphic to the carpet if there is a
continuous function that is one-to-one and onto and has a continuous inverse
that maps this set to the carpet. For a given set in the plane, ﬁnding an
explicit homeomorphism between this set and the carpet is almost always
impossible. However, by a remarkable theorem of Whyburn [33], there is a
“topological” criterion that determines when a set is homeomorphic to the
carpet. Whyburn’s Theorem states:
Theorem. Suppose a planar set has the following ﬁve properties:
1. compact
2. connected
3. locally connected
4. nowhere dense
5. any pair of complementary domains are bounded by simple closed
curves that are pairwise disjoint.
Then this set is homeomorphic to the Sierpinski carpet.
See the topological preliminaries in Appendix A for an explanation of the
concepts of nowhere dense and locally connected.
A second reason for the importance of the carpet is that this set is a “uni-
versal plane continuum.” What this means is that, if you take any compact,
one-dimensional curve (deﬁned speciﬁcally later in Section 14.6), then that
curve can be homeomorphically manipulated so that it ﬁts exactly inside the
Sierpinski carpet. So the carpet is a “dictionary” of all compact curves in the
plane!
Here are some examples of complicated planar curves that can be homeo-
morphically adjusted to ﬁt in the carpet. Consider ﬁrst the topologists’ sine
curve. This is the graph of the real function S(x) = sin(1/x) deﬁned on the
interval (0, 2π] together with the portion of the y-axis from −1 to 1. Note that
the graph of S(x) accumulates on this interval on the y-axis. Then this curve
can be continuously deformed to ﬁt inside the carpet. See Exercise 19.
Another more complicated curve that ﬁts in the carpet is the Knaster
continuum. This set is deﬁned as follows. Start with the Cantor middle-thirds
set deﬁned on the unit interval along the real axis in the plane. This Cantor
set is symmetric about x = 1/2. So connect any two symmetrically-located
points in the Cantor set with semi-circles lying in the upper half-plane. Note

The Sierpinski Carpet
189
that all of these semi-circles are centered at x = 1/2, the point in the middle
of the Cantor set. Now consider the right half of the Cantor set (the portion
between x = 2/3 and x = 1). This is a smaller copy of a Cantor set that is now
symmetric about x = 5/6. So we again connect any two symmetrically-located
points in this Cantor set by semi-circles, which now lie in the lower half-plane.
Then we continue this process. The left portion of the Cantor middle-thirds
set (the portion between x = 0 and x = 1/3) can also be broken into two
smaller Cantor sets. Consider again the right portion of this set (the Cantor
set between x = 2/9 and x = 1/3). This set is symmetric about the midpoint
x = 5/18, so we can again connect any two symmetrically located points with
semi-circles lying in the lower half-plane. Continuing this process inﬁnitely
often produces the Knaster continuum.
FIGURE 14.9
A portion of the outer curve in the Knaster continuum.
Note that there are now inﬁnitely many distinct curves that make up this
set. One of these curves is a curve that passes through all of the endpoints in
the Cantor middle-thirds set. This curve begins as the semi-circle connecting
0 to 1 in the upper half-plane. Then it connects 1 and 2/3 by a semi-circle in
the lower half-plane, followed by a semi-circle connecting 2/3 and 1/3 in the
upper half-plane, then another semi-circle connecting 1/3 and 2/9 in the lower
half-plane and on and on. The result is the curve that passes through all of the
endpoints of the Cantor set. See Figure 14.9. But there are uncountably many
other points in the Cantor set, so there are also inﬁnitely other curves lying in
the Knaster continuum. Even this complicated set can be homeomorphically
embedded in the Sierpinski carpet, as you will show in Exercise 20.
A third reason for the importance of the Sierpinski carpet is that this set
appears very often as “Julia sets” for rational functions in the complex plane,
as we shall see in Chapter 18.

190
Fractals
14.5
The Koch Snowﬂake
Unlike the Sierpinski triangle and carpet, the Koch snowﬂake is generated by
an inﬁnite succession of additions. This time we begin with the boundary of
an equilateral triangle with sides of length 1. The ﬁrst step in the process is
to remove the middle third of each side of the triangle, just as we did in the
construction of the Cantor set. This time, however, we replace each of these
pieces with two pieces of equal length protruding outward, which gives the
star-shaped region depicted in Figure 14.10. This new ﬁgure has twelve sides,
each of length 1/3. Now we iterate this process. From each of these sides we
remove the middle third and replace it with a triangular “bulge” extending
outward and made of two pieces of length 1/9. The result is also shown in
Figure 14.10.
FIGURE 14.10
The ﬁrst four stages in the construction of the Koch snowﬂake.
We continue this process over and over. The ultimate result is a curve that
is inﬁnitely wiggly—there are no straight lines in it whatsoever. This object
is called the Koch snowﬂake.
Clearly, there are pieces of the snowﬂake that are self-similar. Suppose
we look at the top portion of the snowﬂake. What we see is called the Koch
curve and is depicted in Figure 14.11. If we examine one third of this edge

The Koch Snowﬂake
191
and magnify this portion by a factor of 3, we again see the same ﬁgure. Note
that there are exactly four pieces of the snowﬂake that, when magniﬁed by a
factor of 3 (and possibly rotated), yield the entire edge of the snowﬂake.
FIGURE 14.11
Magniﬁcation of the Koch curve.
At each stage of the construction of the Koch curve, similar magniﬁcations
by a factor of 3 yields the previous image. As before, this means that the
ultimate ﬁgure is self-similar.
The Koch snowﬂake has an amazing geometric property: It has ﬁnite area,
but its perimeter is inﬁnite! This means that we can paint the inside of the
Koch snowﬂake, but we can never wrap a length of string around its boundary!
This is quite a contrast to the usual shapes encountered in geometry such as
squares and circles, which have ﬁnite area and perimeter.
To see why this is true, let N0, N1, N2, . . . denote the number of sides of
the snowﬂake at the corresponding stage of the construction. We have
N0
=
3
N1
=
4 · 3 = 12
N2
=
4 · 12 = 42 · 3
...
Nk
=
4Nk−1 = 4k · 3.
These numbers get large very quickly. For example, N8 gives 196,608 little
sides.
Now let’s compute the perimeter. Let Lk be the length of one segment of
the perimeter after the kth stage. At the beginning, each side has length 1;
after the ﬁrst addition, each side has length 1/3; after the second, each side

192
Fractals
has length 1/32, and so forth. We ﬁnd that, at the kth stage,
Lk = 1
3k .
Now let Pk be the perimeter of the ﬁgure at the kth stage. Clearly, Pk =
Nk · Lk, so we have
Pk = Nk · Lk
=
4k · 3 · 1
3k
=
4
3
k
· 3.
Hence Pk →∞as k →∞.
The area contained within the snowﬂake is more diﬃcult to compute, but
you can easily check using plane geometry that the snowﬂake is contained
within a square in the plane whose sides have length 2
√
3/3. Therefore this
area is certainly less than 4/3.
14.6
Topological Dimension
As we have seen in the previous four sections, one distinguishing feature of
a fractal is self-similarity. Each of the Cantor set, the Sierpinski triangle, the
carpet, and the Koch snowﬂake shares this property. But so do lines and
squares and cubes: these familiar ﬁgures from Euclidean geometry are all
self-similar. For example, a line segment may obviously be subdivided into N
smaller subintervals of equal length each of which may be magniﬁed by a factor
of N to yield the original line segment. So what distinguishes complicated sets
like Cantor sets and Sierpinski triangles from lines and squares? The answer
is their dimension.
There is no question that a line is one-dimensional. Similarly, a square
is two-dimensional, and a cube is three-dimensional. Naively speaking, the
reasons for this are obvious. There is only one “linearly independent” direction
to move along a line (backwards and forwards), two directions in a square
(length and width), and three directions in a cube (length, width, and height).
So these ﬁgures have dimensions 1, 2, and 3, respectively. But what is the
dimension of the Sierpinski triangle? Sometimes it seems that the triangle
has dimension 1—after all, we have removed all of the planar regions. On
the other hand, the Sierpinski triangle is clearly much more complicated than
a typical one-dimensional object like a line or a curve. Also, we can move
in the Sierpinski triangle in many directions—not just one—but clearly we
cannot move in every planar direction. So what then is the dimension of the
Sierpinski triangle? A nice experiment to perform is to take a vote among
your classmates as to what is the dimension of this ﬁgure: one or two? If you

Topological Dimension
193
average the results you’ll see that the answer is somewhere in between 1 and 2.
Many people say that the Sierpinski triangle is two-dimensional, but a sizeable
minority votes for one-dimensional. The votes in my classes often average 1.6,
very nearly the accurate “fractal” dimension. The point is that these fractal
images do not ﬁt neatly into any of our preconceived notions of dimension, so
we must ﬁrst re-evaluate what dimension means before assigning a dimension
to a set.
One of the crudest measurements of dimension is the notion of topological
dimension. This dimension agrees with our naive expectation that a set should
have an integer dimension. We deﬁne the topological dimension inductively.
Deﬁnition. A set S has topological dimension 0 if every point in S has arbi-
trarily small neighborhoods whose boundaries do not intersect S.
For example, a scatter of isolated points has topological dimension 0,
since each point may be surrounded by arbitrarily small neighborhoods whose
boundaries are disjoint from the set (see Figure 14.12). In particular, the Can-
tor middle-thirds set has topological dimension 0 since any two points in C
are separated by at least one gap in the Cantor set.
FIGURE 14.12
A set with topological dimension 0.
To deﬁne topological dimension k, we use induction.
Deﬁnition. A set S has topological dimension k if each point in S has arbi-
trarily small neighborhoods whose boundaries meet S in a set of dimension
k −1, and k is the smallest nonnegative integer for which this holds.
For example, a line segment in the plane has topological dimension 1 since
small disks in the plane have boundaries that meet the line in one or two
points. Similarly, a planar region has topological dimension 2 because points
in the set have arbitrarily small neighborhoods whose boundaries are one-
dimensional, as depicted in Figure 14.13.
What about the Sierpinski triangle? As shown in Figure 14.14, we may
surround points in this set with arbitrarily small ovals that meet the set in only
ﬁnitely many points. Hence the Sierpinski triangle has topological dimension

194
Fractals
FIGURE 14.13
A set with topological dimension (a) 1, (b) 2.
1. Note that we could also surround certain points by simple closed curves
(actually triangles) that lie in this set. But recall that topological dimension
is the least positive integer for which this procedure works.
14.7
Fractal Dimension
A more sensitive notion of dimension is provided by fractal dimension (some-
times called similarity dimension). Not all sets have a well-deﬁned fractal
dimension: we will consider only those sets that do, namely, those that are
aﬃne self-similar.
Deﬁnition. A set S is called aﬃne self-similar if S can be subdivided into
k congruent subsets, each of which may be magniﬁed by a constant factor M
(and possibly rotated) to yield the whole set S.
Note that all of the sets considered earlier in this chapter are aﬃne self-
similar. Also, the line, the plane, and the cube are aﬃne self-similar. We may
now use this fact to provide a diﬀerent notion of dimension; one way to realize
that these objects have diﬀerent dimensions is to observe the following. A
line is a very self-similar object: It may be decomposed into n = n1 little
“bite-size” pieces, each of which is exactly 1/n the size of the original line
and each of which, when magniﬁed by a factor of n, looks exactly like the
whole line (Figure 14.15). On the other hand, if we decompose a square into
subsquares whose sides are 1/n the size of the original square, then we ﬁnd

Fractal Dimension
195
FIGURE 14.14
Each neighborhood meets the Sierpinski triangle in a ﬁnite set of points.
we need n2 such pieces to reassemble the square. Similarly, a cube may be
decomposed into n3 pieces, each 1/n the size of the original. So the exponent
in each of these cases distinguishes the dimension of the object in question.
This exponent is the fractal dimension.
In these simple cases, it is trivial to read the exponent and ﬁnd the dimen-
sion. For more general aﬃne self-similar ﬁgures, this is not always as easy.
However, note that we may also calculate this exponent as follows.
Deﬁnition. Suppose the aﬃne self-similar set S may be subdivided into k
pieces, each of which may be magniﬁed by a factor of M to yield the whole
set S. Then the fractal dimension D of S is
D = log(k)
log(M) =
log (number of pieces)
log (magniﬁcation factor).
This deﬁnition agrees with the exponents we can already compute, since
we have for a line:
log (number of pieces) = log(n1) = 1 log n.
For a square,
log (number of pieces) = log(n2) = 2 log n,
and for a cube,
log (number of pieces) = log(n3) = 3 log n.

196
Fractals
FIGURE 14.15
Calculating the dimensions of a line and a square.
Since in each case the magniﬁcation factor is n, we ﬁnd, for a line,
D = log n1
log n = 1,
for a square,
D = log n2
log n = 2 log n
log n = 2,
and for a cube,
D = log n3
log n = 3 log n
log n = 3.
For the Sierpinski triangle, recall that we may subdivide this ﬁgure into
three self-similar pieces, each of which may be magniﬁed by a factor of 2 to
yield the whole ﬁgure. Thus we have
D = log (number of triangles)
log (magniﬁcation)
= log 3
log 2 = 1.584 . . . ,
which is by no means an integer! Let’s try this again. The Sierpinski triangle
may also be constructed by assembling nine smaller pieces as we described in
Section 14.3. Each of these smaller pieces is exactly one-fourth the size of the
original ﬁgure. Hence
D = log 9
log 4 = log 32
log 22 = 2 log 3
2 log 2 = log 3
log 2,

Iterated Function Systems
197
and we get the same dimension.
For the Sierpinski carpet, we may divide this set into eight self-similar
peieces, each of which may now be magniﬁed by a factor of three to yield the
entire carpet. So the fractal dimension of the carpet is
D = log 8
log 3 = 1.892 . . . .
So the fractal dimension of the Sierpinski carpet is larger than that of the
Sierpinski triangle, which is exactly what our eyes are telling us.
To calculate the dimension of the Koch curve, we recall that each side of the
original triangle is decomposed into four smaller pieces with a magniﬁcation
factor of 3. Therefore,
D = log 4
log 3 = 1.261 . . . .
We use the sides of the snowﬂake because no piece of the snowﬂake may be
magniﬁed to look like the whole object; pieces of the sides are self-similar,
however. If we proceed to the second stage of the construction, there are then
16 sides, but the magniﬁcation factor is 32. Again,
D = log 42
log 32 = 2 log 4
2 log 3 = 1.261 . . . .
Notice that the dimension of the curve is smaller than that of the Sierpinski
triangle and carpet. This agrees again with what our eyes are telling us (if
eyes could speak). The triangle looks larger, more two-dimensional, than the
Koch curve, and so it should have a larger dimension.
Finally, for the Cantor set, the number of intervals at each stage of the
construction is 2n, but the magniﬁcation factor is 3n. So,
D = log 2n
log 3n = n log 2
n log 3 = 0.6309. . . .
Remark. The dimensions computed in this section were easy to compute
because the magniﬁcation factor always increased at the same rate as the
number of pieces in the ﬁgure. For many fractals, this is not the case. For
example, the Julia sets that we will encounter in the next few chapters usually
have fractional dimension, but this dimension is very diﬃcult to compute.
Indeed, for many Julia sets, the exact dimension is unknown.
14.8
Iterated Function Systems
We now return to the chaos game to show that a great many fractals may be
obtained by variations on this theme. We use vector notation to denote points

198
Fractals
in the plane. Let
p0 =
x0
y0

be a point in the plane and suppose 0 < β < 1. The function
A
x
y

= β ·
x −x0
y −y0

+
x0
y0

has a ﬁxed point at p0 since A(p0) = p0. Since β < 1, it follows that A moves
any point in the plane closer to p0. Indeed, if
p =
x
y

,
then A(p) −A(p0) = β(p −p0) so the distance between p and p0 is contracted
by a factor of β. The function A is an example of a linear contraction of the
plane.
Note that the orbit of any point p in the plane converges to p0 under
iteration of A as shown in Figure 14.16.
FIGURE 14.16
Orbits under iteration of A converge to the ﬁxed point p0 if 0 < β < 1.
The chaos game from Section 14.1 was played by randomly iterating three
diﬀerent contractions. The ﬁxed points for these functions were the vertices
of the original triangle and the contraction ratio was in each case β = 1/2.
Note that, as we saw in Section 14.3, 2 = 1/β was the magniﬁcation factor
at the ﬁrst stage of the removals which generated the Sierpinski triangle. We
may therefore construct diﬀerent fractals by choosing diﬀerent β-values and
various contractions.
Deﬁnition. Let 0 < β < 1. Let p1, . . . , pn be points in the plane. Let Ai(p) =
β(p −pi) + pi for each i = 1, . . . , n. The collection of functions {A1, . . . , An}
is called an iterated function system.

Iterated Function Systems
199
To produce a fractal, we choose an arbitrary initial point in the plane and
compute its orbit under random iteration of the Ai. It can be proved [3] that
this orbit converges with probability 1 to a speciﬁc subset of the plane.
Deﬁnition. Suppose {A1, . . . , An} is an iterated function system. The set of
points to which an arbitrary orbit in the plane converges is the attractor for
the system.
Example. The Cantor middle-thirds set may be obtained as the attractor of
an iterated function system by setting
A0
x
y

=
1
3
x
y

A1
x
y

=
1
3
x −1
y

+
1
0

.
The contraction factor here is 1/3, and the ﬁxed points are located at 0 and
1 along the x-axis.
Let’s see that any orbit of the iterated function system tends to the Cantor
set. Suppose pn is the nth point on the orbit with
pn =
xn
yn

,
then yn = y0/3n, since yk+1 = yk/3 no matter which of the two contractions
we apply. Hence the orbit of any point tends toward the x-axis at a geometric
rate.
What happens to the x-coordinates of points under this iteration? This
depends upon which sequence of iterations we perform. We may describe
this sequence of iterations by means of a sequence of 0’s and 1’s given by
(s1s2s3 . . .), where each sj is either 0 or 1. We agree that if sj = 0, the jth
iteration performed is A0; if sj = 1, we apply A1 at the jth stage. For example,
if we compute the orbit of p0 using the (not so random) sequence (01 01 01 . . .),
we ﬁnd that the x-coordinates of the points on the orbit are given by
x1
=
x0
3
x2
=
x0
32 + 2
3
x3
=
x0
33 + 2
32
x4
=
x0
34 + 2
33 + 2
3
x5
=
x0
35 + 2
34 + 2
32
x6
=
x0
36 + 2
35 + 2
33 + 2
3.

200
Fractals
There is a pattern here. If n is even,
xn = x0
3n +
2
3n−1 +
2
3n−3 +
2
3n−5 + · · · + 2
3,
while if n is odd,
xn = x0
3n +
2
3n−1 +
2
3n−3 +
2
3n−5 + · · · + 2
9.
We may amalgamate both of these sums as
xn = x0
3n +
2s1
3n + 2s2
3n−1 + 2s3
3n−2 + · · · + 2sn
3

,
since s1 = s3 = s5 = · · · = 0 and s2 = s4 = · · · = 1.
Note that, as n →∞, the ﬁrst term in this sum tends to 0 while the
remaining terms tend to an inﬁnite series of the form
∞

i=1
ti
3i ,
where the ti are alternately 0 and 2. The sequence xn does not converge to a
single number. Rather, the even terms of this sequence tend to one series and
the odd to another. We have
lim
n→∞x2n
=
lim
n→∞
 x0
32n +

2
32n−1 +
2
32n−3 + · · · + 2
3

=
∞

i=1
2
32i−1 = 3
4
and
lim
n→∞x2n+1
=
lim
n→∞

x0
32n+1 +
 2
32n +
2
32n−2 + · · · + 2
32

=
∞

i=1
2
32i = 1
4
As we saw in Section 7.3, both of these points lie in the Cantor middle-thirds
set.
In the general case, we may write
xn = x0
3n +
2s1
3n + 2s2
3n−1 + 2s3
3n−2 + . . .

.

Iterated Function Systems
201
The ﬁrst term in this sum again vanishes as n →∞, showing that, in the
limit, this quantity is independent of x0. The remaining terms in parentheses
tend to an inﬁnite series, which is again of the form
∞

i=1
ti
3i ,
where ti is either 0 or 2. As in Section 7.3 we recognize these series as giving
numbers whose ternary expansion contains no digit equal to one. These, of
course, correspond to points in the Cantor set.
Remark. In this example we could have played the chaos game on the x-axis
instead of the plane. In this case the two linear contractions would be given
by
A0(x)
=
1
3x
A1(x)
=
1
3x + 2
3.
Note that the inverses of these two contractions are precisely the “micro-
scopes” we used back in Section 14.2 to view the self-similarity of C.
We emphasize that the orbit does not in general converge to a single point
in the Cantor set. Rather, as we randomly apply A0 or A1, the points on the
orbit tend to move around the set, gradually visiting all regions in the set.
Example. Consider the ﬁve points
p0 =
0
0

, p1 =
1
0

, p2 =
0
1

, p3 =
1
1

, p4 =
1/2
1/2

.
Let Ai denote the linear contraction with the ﬁxed point pi and contraction
factor 1/3. The iterated function system generated by the Ai has an attractor
which is the box fractal displayed in Figure 14.7. Note that, geometrically,
each of the Ai contracts the unit square 0 ≤x, y ≤1 onto one of the ﬁve
subsquares depicted in Figure 14.17.
There are a number of variations and generalizations of the concept of
iterated function system. For example, we may assume that each contraction
not only contracts points by a factor β toward its ﬁxed point, but also rotates
these points. To be speciﬁc, let θ be a nonzero angle. Then the function
A
x
y

= β ·
cos θ
−sin θ
sin θ
cos θ

·
x −x0
y −y0

+
x0
y0

,
where β < 1 has a ﬁxed the point at
p =
x0
y0

.

202
Fractals
FIGURE 14.17
Each Ai contracts the unit square s onto a subsquare.
Any other point in the plane is ﬁrst contracted by a factor of β toward p and
then rotated by angle θ about p.
Example. Let β = 0.9 and θ = π/2. Then
A
x
y

= 0.9 ·

0
−1
1
0

·
x −1
y −1

+
1
1

is a linear contraction that ﬁxes
p0 =
1
1

and rotates and contracts all other points as depicted in Figure 14.18.
FIGURE 14.18
An orbit of a contraction map with rotation θ = π/2 about (1,1).

Iterated Function Systems
203
Example. Let
p0 =
0
0

p1 =
1
0

p2 =
0
1

,
and let Ai be the linear contraction with rotation π/4 and contraction factor
1/2 about pi. Then this iterated function system yields the attractor depicted
in Figure 14.19.
FIGURE 14.19
An attractor generated by contraction and rotation.
Notice that there are three self-similar pieces in this fractal, each of which
is one-half the size of the original set. And each of these pieces is also rotated
by a quarter of a turn. So, again, we can read oﬀthe rules we used to generate
this set.
There are many other possible generalizations of iterated function sys-
tems. For example, linear contractions need not contract all points equally.
As discussed in linear algebra courses, there are more general types of linear
transformations that contract the plane. Another type of iterated function
system occurs if we apply the contractions with unequal probability. We refer
to [3] for a complete discussion of these topics.
Finally, it should be noted that the images generated by iterated function
systems and other iterative processes may be quite lifelike. Indeed, one major
branch of fractal geometry involves the use of iterated function systems that
give accurate representations of natural objects such as clouds, ferns, mountain
ranges, snowﬂakes, and the like. See [24].

204
Fractals
14.9
Experiment: Find the Iterated Function Systems
Goal: In this experiment you are asked to identify the iterated function sys-
tems that produced certain fractals as their attractors.
Procedure: In Figures 14.20 and 14.21 we have displayed six diﬀerent frac-
tals, each contained in the unit square in the plane. First determine how many
self-similar pieces you see in each set, and then ﬁgure out the contraction fac-
tor. Then write down explicitly the formulas in the iterated function system
that generated these images. And, ﬁnally, determine the fractal dimension of
each set.
FIGURE 14.20
Find the contractions that produce these attractors.
Results: In a brief essay, explain why you were led to choose the iterated
function system that produced one of these images. Explain with pictures
what each linear contraction in your system does to the unit square in the
plane.
Further Questions:
1. Each of the fractals in Figures 14.20 and 14.21 were obtained via iterated
function systems without rotations. Figure 14.22 displays a pair of fractals
for which the corresponding iterated function system admits some nonzero
rotations. How many self-similar pieces appear in each of these fractals? What
is the contraction factor? And what is the rotation that was used in each case?
You need not identify the formulas for the iterated function system that was
used, since ﬁnding the ﬁxed points for these contractions can be diﬃcult.
2. In Figure 14.23, we have displayed the results of another iterated function
system. This time, the image that you see is not a fractal. How did we generate
this image? Note the darker shaded regions in this image. What caused this?

Experiment: A “Real” Chaos Game
205
FIGURE 14.21
Find the contractions that produce these attractors.
3. Go to math.bu.edu/DYSYS/animations.html to view a movie called “The
Starﬁsh.” How did we make this movie? Determine the number of vertices, the
contractions, and any rotations that were used for each image. Be sure to check
your results on a computer, because there is something quite diﬀerent in the
way we mathematically produced each of these images. As a hint, probability
is involved in this process.
14.10
Experiment: A “Real” Chaos Game
Here is an actual “game” based upon the chaos game we considered earlier.
Recall that we constructed the Sierpinski triangle by starting with a triangle
and then removing the “middle” triangle, and then repeating this procedure.

206
Fractals
FIGURE 14.22
The contractions that produced these attractors involve nonzero rotations.
At stage 1, there were three remaining triangles. At stage 2, there were nine
remaining triangles. And at stage n, there were 3n remaining triangles. So
choose the set at some level n. This set consists of ﬁnitely many equal-sized
triangles. Choose one of these triangles; this will be our “target.” Then put a
point at, say, the lower-right endpoint of the original triangle. See Figure 14.24.
Then the goal of this game is to move this starting point into the interior of the
target in as few moves as possible. The way we move this point is as follows.
Let A, B, and C be the vertices of the original triangle. Then, just as in the
earlier chaos game, whenever we select one of these vertices, we simply move
the given point half the distance to the chosen vertex. Then we repeat this
procedure until our point moves into the interior (not the boundary) of the
target. No matter where we choose this target at a given level, there is always
the same minimum number of iterations necessary to move the starting point
into this target.
Goal: Find an algorithm that determines the method to move the starting
point into the chosen target in as few a number of moves as possible. That
is, determine the sequence of values of A, B, and C that you must choose to
reach the interior of the target. Then change the location of the target at that
level and determine the new sequence of values of A, B, and C that work. And
do this for all possible targets at this level. Then determine the rules that you
can follow to hit any such target.
Results: In an essay, explain the algorithm that allows you to hit any given
target at this level in the minimal number of moves. Then explain how this
algorithm can be adapted to work at any level.
Hint: There are exactly two diﬀerent ways to reach the target in the minimum
number of steps.

Experiment: A “Real” Chaos Game
207
FIGURE 14.23
What caused the darker regions in this image?
@
@@
R
Target



Starting point
FIGURE 14.24
The setup for the chaos game at level 3.

208
Fractals
Exercises
1. Without using a computer, predict the structure of the attractor generated
by the iterated function system with contraction factor β and ﬁxed points pi:
a. β = 1/3; p0 =
 0
0

, p1 =
 1
0

, p2 =
 0
1

b. β = 1/2; p0 =
 0
0

, p1 =
 1
0

c. β = 1/3; p0 =
 0
0

, p1 =
 1
0

, p2 =
 0
1

, p3 =
 1
1

2. Give explicitly the iterated function system that generates the Cantor
middle-ﬁfths set. This set is obtained by the same process that generated
the Cantor middle-thirds set, except that the middle ﬁfth of each interval is
removed at each stage. What is the fractal dimension of this set?
3. Consider the set C obtained from the interval [0, 1] by ﬁrst removing the
middle third of the interval and then removing the middle ﬁfths of the two
remaining intervals. Now iterate this process, ﬁrst removing middle thirds,
then removing middle ﬁfths. The set C is what remains when this process is
repeated inﬁnitely. Is C a fractal? If so, what is its fractal dimension?
The following seven exercises deal with the Sierpinski right triangle (see
Figure 14.5) generated by the following contractions:
A0
x
y

=
1
2
x
y

A1
x
y

=
1
2
x −1
y

+
1
0

A2
x
y

=
1
2

x
y −1

+
0
1

.
4. What are the ﬁxed points for A0, A1, and A2?
5. Show that An
1

x0
y0

converges to
 1
0

.
6. To which point does the sequence
A2
2

An
1
x0
y0

converge?
7. Show that the sequence A1 ◦An
0

x0
y0

converges to

1/2
0

.
8. Show that the sequence
(A1 ◦A0)n
x0
y0


Experiment: A “Real” Chaos Game
209
accumulates on the two points
1/3
0

and
2/3
0

.
9. On which points does the sequence
(A2 ◦A1)n
x0
y0

accumulate?
10. Show that the sequence
(A2 ◦A1 ◦A0)n
x0
y0

accumulates on the points
2/7
4/7

,
1/7
2/7

,
and
4/7
1/7

.
11. Consider the fractal generated by replacing a line segment with the smaller
segments shown in Figure 14.25, where each new segment is exactly one-third
as long as the original. Draw carefully the next two iterations of this process.
What are the fractal and topological dimensions of the resulting fractal?
FIGURE 14.25
Exercise 11.
12. Show that a set with topological dimension 0 is totally disconnected.
13. Can a fractal that is totally disconnected (topological dimension 0) have
a fractal dimension larger than 1?
14. Show that the rational numbers form a subset of the real line that has
topological dimension 0. What is the topological dimension of the set of irra-
tionals?
15. Compute exactly the area of the Koch snowﬂake.
16. Show that the Koch curve may also be obtained by the sequence of
removals shown in Figure 14.26.

210
Fractals
FIGURE 14.26
Construction of the Koch curve.
17. Consider the standard Pascal’s triangle generated by binomial coeﬃcients.
In this triangle, replace each odd number by a black dot and each even number
by a white dot. Describe the ﬁgure that results.
18. Rework exercise 17, this time replacing each number by a black dot if
it is congruent to 1 mod 3 and a white dot otherwise. (That is, points that
yield a remainder of 1 upon division by 3 are colored black.) Now describe
the resulting ﬁgure. How does it compare with the ﬁgure generated in the
previous exercise?
19. Show that the topologists’ sine curve ﬁts inside the Sierpinski carpet by
drawing a homeomorphic copy of this curve in the carpet.
20. Show that the curve in the Knaster continuum that passes through all
of the endpoints of the Cantor middle-thirds set can be homeomorphically
manipulated to lie in the Sierpinski carpet. Use this to show that the entire
Knaster continuum lies in the carpet.

15
Complex Functions
In this chapter we begin to study dynamical systems in the plane. We will
consider here functions of a complex variable. This study was initiated by
the French mathematicians Gaston Julia and Pierre Fatou in the 1920’s, but
this ﬁeld quickly died out since it was impossible at that time to view the
complicated fractal images that arise in this study. The ﬁeld was rejuvenated
by the pioneering computer graphics work of Benoit Mandelbrot in 1980 who
was able to plot the incredibly interesting objects now known as the Julia
and Mandelbrot sets. The beauty of these sets prompted many outstanding
mathematicians to enter this ﬁeld in the 1980’s, and the ﬁeld has ﬂourished
ever since. In this chapter we will introduce the basic mathematical notions
necessary to understand Julia sets of complex functions and the Mandelbrot
set, our topics in the subsequent chapters.
15.1
Complex Arithmetic
We begin with a review of complex numbers. A complex number is a number of
the form x + iy, where both x and y are real numbers and i is the imaginary
number satisfying i2 = −1. That is, i is, by deﬁnition, √−1. For example,
2 + 3i and 7 −4i are both complex numbers. Similarly, both 7 and 7i are
complex numbers, for we may write 7 = 7 + 0i and 7i = 0 + 7i.
If z = x + iy is a complex number, we call x the real part of z and y the
imaginary part. The real number

x2 + y2 is called the modulus of z. We
denote the modulus of z by |z|. We denote the set of all complex numbers by
C.
The arithmetic operations of addition and multiplication are deﬁned for
complex numbers in the natural way. For example, we add two complex num-
bers by summing their real parts and their imaginary parts. Thus
(2 + 3i) + (4 + 5i) = 6 + 8i.
Multiplication is also deﬁned in the natural manner, recalling that i2 = −1.
Thus
(x + iy) · (u + iv)
=
xu + i2yv + ixv + iyu
=
xu −yv + i(xv + yu).
211

212
Complex Functions
For example,
(1 + 2i) · (2 + 3i)
=
−4 + 7i
2i · (1 + i)
=
−2 + 2i
4i · 7i
=
−28.
Complex numbers may be depicted geometrically as points in the plane.
We simply place the complex number x+iy at the point (x, y) in the Cartesian
plane. Thus i is placed at (0,1) and 1 + i at (1, 1), as shown in Figure 15.1.
FIGURE 15.1
Some complex numbers in the complex plane.
We call the plane with points identiﬁed as complex numbers the complex
plane.
An alternative method of describing points in the complex plane is the
polar representation of a complex number. Given a complex number z = x+iy,
its polar representation is determined by the modulus of z,
|z| =

x2 + y2,
which represents the distance from the origin to z, and the polar angle of
z, which is the angle between the positive x-axis and the ray from 0 to z
measured in the counterclockwise direction. The polar angle of z is also called
the argument of z. We often write r = |z| and θ for the modulus and polar
angle of z, the familiar polar coordinates of the point (x, y). Then the polar
representation of z = x + iy is z = r cos θ + ir sin θ, as shown in Figure 15.2.
Recall Euler’s Formula from elementary calculus:
eiθ = cos θ + i sin θ.
We thus see that any complex number may also be written in polar form as
z = reiθ. For later use, we note that
|eiθ| =

cos2(θ) + sin2(θ) = 1.

Complex Arithmetic
213
FIGURE 15.2
The polar representation of z = x + iy as z = r cos θ + ir sin θ.
Geometrically, addition of complex numbers is given by the parallelogram
rule for addition of vectors in the plane. This is shown in Figure 15.3. In
particular, this ﬁgure illustrates what will become a crucial fact for us later.
The Triangle Inequality. If z and w are complex numbers, then
1. |z + w| ≤|z| + |w|, and
2. |z −w| ≥|z| −|w|.
The ﬁrst of these inequalities follows immediately from Figure 15.3. The
second is a consequence of the ﬁrst, since
|z| = |z −w + w| ≤|z −w| + |w|.
FIGURE 15.3
Complex addition.
The polar representation of complex numbers makes it particularly easy
to visualize complex multiplication. If z = r(cos θ + i sin θ) and w = ρ(cos φ +

214
Complex Functions
i sin φ), then the product zw is given by
z · w
=
rρ [(cos θ cos φ −sin θ sin φ) + i(cos θ sin φ + cos φ sin θ)]
=
rρ [cos(θ + φ) + i sin(θ + φ)] .
Thus, to multiply two complex numbers, we simply multiply their moduli and
add their polar angles as depicted in Figure 15.4.
FIGURE 15.4
Complex multiplication.
Division of complex numbers is deﬁned in a roundabout way. First, given a
complex number z = x+iy, we deﬁne its complex conjugate to be the complex
number z = x−iy. Note that z is simply the reﬂection of z through the x-axis.
We have
zz
=
(x + iy) · (x −iy)
=
x2 + y2
=
|z|2,
so zz is always a non-negative real number.
Given two complex numbers z and w, with z ̸= 0, we therefore set
w
z = w · z
z · z = w · z
|z|2 .
Since the denominator of the right-hand side is real and nonzero, this deﬁnition
of w/z makes sense. Note that this deﬁnition yields
w
z · z = w · z
|z|2 · z = w|z|2
|z|2
= w
as expected.

Complex Square Roots
215
15.2
Complex Square Roots
Given a complex number z = x+iy, there is no problem computing its square.
Indeed,
z2
=
(x + iy) · (x + iy)
=
x2 −y2 + i(2xy).
In polar representation, if
z = r(cos θ + i sin θ),
then
z2 = r2(cos 2θ + i sin 2θ),
as we saw in the previous section. That is, squaring a complex number has
the eﬀect of squaring its modulus and doubling its polar angle.
In the sequel, we will often need to undo the squaring operation. That is, we
need to know how to compute complex square roots. The polar representation
of complex multiplication tells us how to do this. Given z = r(cos θ + i sin θ)
in polar form, the two square roots of z are
±√r(cos(θ/2) + i sin(θ/2)).
Note that each of these complex numbers gives z when squared. Geometrically,
√z is obtained by taking the square root of the modulus of z and halving the
polar angle (the other square root is the negative of this number). Thus, for
example
√
i = ±

cos π
4 + i sin π
4

= ±
 1
√
2 + i · 1
√
2

,
since |i| = 1 and the polar angle of i is π/2.
Similarly,
√
1 + i = ±21/4 
cos π
8 + i sin π
8

,
since |1+i| =
√
2 and the polar angle of 1+i is π/4. The square root operation
is depicted geometrically in Figure 15.5.
Later, we will need to compute the square roots of all points in a given
region in the complex plane. Geometrically this is accomplished just as above.
We simply halve the polar angle of all points in the region and take the square
root of their moduli. This yields one of the square roots of the region. The
other square root is simply the negative of all of these points.
We speciﬁcally need to know how to compute the square root of all points
that lie on a circle in the complex plane. There are three diﬀerent possibilities,
depending upon whether the origin lies inside, on, or outside this circle. To
illustrate this, we begin with the circle of radius r centered at the origin.

216
Complex Functions
FIGURE 15.5
Complex square roots.
FIGURE 15.6
Square root of a circle not containing 0.
Clearly, the square root of this region is simply the circle of radius √r, also
centered at the origin.
To visualize this, it is helpful to imagine a particle travelling around the
original circle, with another pair of particles simultaneously tracing the paths
of the square roots. As the original particle makes one full loop around the
circle, the square roots each traverse a semicircle, since we halve the corre-
sponding polar angle.
If the origin lies outside of the circle, then the situation is quite diﬀerent.
The entire circle then lies within a wedge centered at the origin of the form
θ1 ≤θ ≤θ2, where 0 < |θ2 −θ1| < 2π. As a particle winds around this circle,
the corresponding square roots have polar angles that are constrained to lie
within the wedge θ1/2 ≤θ ≤θ2/2 and its reﬂection through the origin. As a
consequence, the square root of this circle consists of two disjoint pieces, as
shown in Figure 15.6.

Complex Square Roots
217
The last case occurs when the origin actually lies on the circle. In this
case, the square root is a curve that resembles a ﬁgure-eight (Figure 15.7).
The reason for this is that all points on the circle have exactly two square
roots, except 0, which has just one. As a particle winds around the original
circle, its square roots trace out each of the lobes of the ﬁgure-eight, meeting
at the origin precisely when the original particle reaches 0.
FIGURE 15.7
Square root of a circle containing 0 is a ﬁgure-eight.
Figure 15.8 shows the square roots of some other regions in the plane.
FIGURE 15.8
Some regions in C and their square roots.

218
Complex Functions
15.3
Linear Complex Functions
In this section we describe the dynamics of the simplest complex functions,
namely, linear functions of the form Lα(z) = αz, where α ̸= 0 is a complex
number.
Note that Lα has a ﬁxed point at z = 0. Our goal is to describe the orbits
of nonzero points under iteration of Lα. Toward that end, we write α = ρeiψ.
Let z0 = reiθ. Then we have
z1
=
ρeiψ · reiθ = ρrei(ψ+θ)
z2
=
ρ2ei·2ψ · reiθ = ρ2rei(2ψ+θ)
...
zn
=
ρnei·nψreiθ = ρnrei(nψ+θ).
Thus, there are three possible cases. If ρ < 1, then ρn →0 as n →∞.
Since
|ei(nψ+θ)| = 1
for all n, it follows that |zn| →0 as n →∞. Hence, if ρ < 1, all orbits of Lα
tend to 0.
If ρ > 1, the opposite happens. Since ρn →∞as n →∞, it follows that all
nonzero orbits tend to inﬁnity. In analogy with our analysis of real functions,
we call 0 an attracting ﬁxed point if ρ < 1 and a repelling ﬁxed point if ρ > 1.
Note that the polar angle nψ + θ changes as n increases, provided ψ ̸= 0.
This means that orbits may spiral into or away from the origin, as shown in
Figure 15.9.
FIGURE 15.9
Orbits of Lα where (a) |α| < 1 and (b) |α| > 1.
The neutral case (when ρ = 1) is more complicated than the analogous
case for real linear maps. There are two important subcases depending upon

Linear Complex Functions
219
the polar angle ψ. Let’s write
ψ = 2πτ.
The two diﬀerent cases occur when τ is rational and τ is irrational.
Suppose ﬁrst that τ = p/q where p, q ∈Z. Then we have
Lq
α(reiθ)
=
re(2πip/q)q+iθ
=
re2πip+iθ
=
reiθ.
Hence each point z0 ̸= 0 is periodic with period q for Lα. Note that all
points on the orbit of z0 lie on the circle centered at 0 with radius |z0|, as
shown in Figure 15.10.
FIGURE 15.10
Dynamics of Lα where α = e2πi/12.
When τ is irrational, the dynamics of Lα are quite diﬀerent. There are no
periodic points whatsoever for Lα (except 0), since, if Lk
α(z0) = z0 for some
k, we would have
reiθ
=
Lk
α(reiθ)
=
re2πiτk+iθ.
Therefore, for some integer m, we must have
θ + 2πm = θ + 2πkτ.
Hence τ = m/k, which is a contradiction.
In fact, one can prove more. If τ is irrational and ρ = 1, the orbit of z0 is a
dense subset of the circle whose radius is |z0|. This result is known as Jacobi’s
Theorem. To see why this is true, we must show that the orbit of z0 enters
any subarc of the circle of radius |z0| of length ϵ. To ﬁnd such a point, choose
an integer k > 2π|z0|/ϵ. The points z0, z1, . . . , zk all lie on the circle of radius
z0 about 0, and they are all distinct. Since the circumference of this circle is

220
Complex Functions
2π|z0| and 2π|z0|/k < ϵ, it follows that at least two points among the zi are
closer together than ϵ. Suppose the arc between zj and zℓhas length less than
ϵ and j > ℓ.
Consider now the function Lj−ℓ
α
. We have
Lj−ℓ
α
(z0) = e2πiτ(j−ℓ)z0,
so Lj−ℓ
α
simply rotates points by angle 2πτ(j −ℓ). Since
Lj−ℓ
α
(zℓ)
=
Lj−ℓ
α
Lℓ
α(z0)
=
Lj
α(z0)
=
zj,
it follows that this function rotates points on the circle a distance smaller than
ϵ. Hence the points Lj−ℓ
α
(z0), L2(j−ℓ)
α
(z0), . . . , Ln(j−ℓ)
α
(z0), . . . are arranged
around the circle with the distance between successive points no larger than
ϵ. It follows that the orbit of z0 must enter any subarc whose length is less
than ϵ. Since ϵ was arbitrary, it follows that the orbit of z0 is dense in the
circle of radius |z0|.
We may therefore summarize the dynamics of the linear complex maps as
follows.
Proposition. Suppose Lα(z) = αz where α = ρe2πiτ.
1. If ρ < 1, all orbits tend to the attracting ﬁxed point at 0.
2. If ρ > 1, all orbits tend to inﬁnity, except for 0, which is a
repelling ﬁxed point.
3. If ρ = 1:
a. If τ is rational, all orbits are periodic.
b. If τ is irrational, each orbit is dense on a circle centered at 0.
15.4
Calculus of Complex Functions
For a complex function F(z), we deﬁne the complex derivative F ′(z) exactly
as in the real case:
F ′(z0) = lim
z→z0
F(z) −F(z0)
z −z0
.
While this deﬁnition looks straightforward, there really is a signiﬁcant diﬀer-
ence with real functions. In the real case, we need only check the limit F ′(x0)
in two directions, as x approaches x0 from the left and from the right. In the
complex case, we must check this limit in all possible directions in the plane,
and these limits must all be the same.

Calculus of Complex Functions
221
Example. Let F(z) = z2 + c. Then
F ′(z0)
=
lim
z→z0
(z2 + c) −(z2
0 −c)
z −z0
=
lim
z→z0(z + z0)
z −z0
z −z0

=
2z0.
Hence F ′(z0) exists for each z0 ∈C.
Example. Let F(z) = z, the complex conjugate of z. At any point z0, let’s try
to compute the limit F ′(z0) along two straight lines through z0. Let γ(t) =
z0 + t and η(t) = z0 + it. The line γ is horizontal while η is vertical. We
compute
lim
t→0
γ(t) −z0
γ(t) −z0
= lim
t→0
z0 + t −z0
z0 + t −z0
= 1
lim
t→0
η(t) −z0
η(t) −z0
= lim
t→0
z0 −it −z0
z0 + it −z0
= −1.
Since these limits are diﬀerent, it follows that F(z) = z does not have a
complex derivative.
Remark. The complex derivative is a much diﬀerent object from the Jacobian
matrix studied in multivariable calculus. For example, if we regard the function
F(z) = z as the real function
F
x
y

=
 x
−y

,
then this function is diﬀerentiable in the real sense with Jacobian matrix
DF =
1
0
0
−1

.
The property of having a complex derivative is much stronger than having
partial derivatives.
Example. Let F(x + iy) = x + iy2. This function also does not possess a
complex derivative. Again let γ(t) = x0 + t + iy0 and η(t) = x0 + i(y0 + t).
Along γ(t) we have
lim
t→0
F(x0 + t + iy0) −F(x0 + iy0)
t
= lim
t→0
t
t = 1,
whereas along η(t) we have
lim
t→0
F(x0 + i(y0 + t)) −F(x0 + iy0)
it
=
lim
t→0
i(y0 + t)2 −iy2
0
it
=
lim
t→0
2y0t + t2
t
= 2y0.

222
Complex Functions
Hence these two limits are diﬀerent so the complex derivative F ′(z0) does not
exist.
The meaning of F ′(z0) is best illustrated by linear functions of the form
F(z) = αz where α ∈C. As we saw in the previous section, F expands or
contracts the plane by a factor of |α|, and F rotates the plane by an amount
equal to the polar angle of α. We easily compute F ′(z) = α for all z ∈C.
Hence we see that |F ′(z0)| indicates the local expansion or contraction of F
near z0, while the polar angle of F ′(z0) indicates the local rotation near z0.
In particular this allows us to extend our notion of attracting and repelling
ﬁxed points to the complex plane.
Deﬁnition. Suppose F is a complex function with a ﬁxed point z0, that is,
F(z0) = z0. Then
1. The ﬁxed point is attracting if |F ′(z0)| < 1.
2. The ﬁxed point is repelling if |F ′(z0)| > 1.
3. The ﬁxed point is neutral if |F ′(z0)| = 1.
Remarks:
1. Note that these deﬁnitions agree with our original deﬁnitions of these con-
cepts for real functions in Chapter 5.
2. There is one signiﬁcant diﬀerence between the complex case and the real
case. For neutral ﬁxed points, we have some new possibilities. Not only may
we have F ′(z0) = ±1, but we may also have F ′(z0) = eiθ. These types of neu-
tral ﬁxed points have nearby dynamics that may be extremely complicated. In
fact, we still do not understand the local dynamics near certain types of neu-
tral ﬁxed points. Think about this: we still do not understand the dynamical
behavior of z2 +c near certain ﬁxed points! This topic is the subject of intense
recent research. Discussing these results here would take us well beyond the
scope of this book. The interested reader may ﬁnd further discussion of this
topic in [10] or [28].
3. Again as in the case of real functions, we extend the notions of attraction
and repulsion to periodic points of period n by considering |(F n)′(z0)| instead
of |F ′(z0)|.
As in the real case, there is a natural reason for the use of the terms
“attracting” and “repelling” to describe these ﬁxed points.
Attracting Fixed Point Theorem (Complex Case). Suppose z0 is an
attracting ﬁxed point for the complex function F. Then there is a disk D of
the form |z −z0| < δ about z0 in which the following condition is satisﬁed: if
z ∈D, then F n(z) ∈D, and, moreover, F n(z) →z0 as n →∞.

Calculus of Complex Functions
223
Proof: Since |F ′(z0)| < 1, we may ﬁnd δ > 0 and μ < 1 such that, if |z−z0| < δ,
then
    
F(z) −F(z0)
z −z0
    = |F(z) −F(z0)|
|z −z0|
< μ < 1.
The disk D will be the disk of radius δ centered at z0. Hence |F(z) −z0| =
|F(z) −F(z0)| < μ|z −z0| in D. This implies that F(z) is closer to z0 than z
was by a factor of μ < 1. Applying this result n times, we ﬁnd
|F n(z) −z0| < μn|z −z0|.
This completes the proof.
As in the real case we also have an analogous result for repelling ﬁxed
points.
Repelling Fixed Point Theorem (Complex Case). Suppose z0 is a
repelling ﬁxed point for the complex function F. Then there is a disk D of
the form |z −z0| < δ about z0 in which the following condition is satisﬁed: if
z ∈D but z ̸= z0, then there is an integer n > 0 such that F n(z) ̸∈D.
We will omit the proof of this fact, since it closely resembles the proof in
the attracting ﬁxed point case.
Example. Consider Q1(z) = z2 + 1. This function has a pair of ﬁxed points
given by
q± = 1 ± i
√
3
2
.
These ﬁxed points are both repelling since
|Q′
1(q±)| = |1 ± i
√
3| = 4.
Compare the case of the real version of this function, which, as we know from
Chapter 5, has no ﬁxed or periodic points whatsoever.
For the remainder of this section, we consider only the complex quadratic
functions Qc(z) = z2 + c where c ∈C. Our goal is to show the following
important fact.
Boundary Mapping Principle: Suppose R is a closed set in the plane. If
z0 is an interior point1 in R, then Qc(z0) is an interior point of the image
Qc(R).
1 By interior point we mean there is a small open disk about z0 of the form {z | |z−z0| <
δ} that is completely contained in R.

224
Complex Functions
Remarks:
1. An equivalent way of formulating this principle is to say if z1 belongs to
the boundary of Qc(R), then the inverse images of z1 lie in the boundary of
R.
2. The Boundary Mapping Principle actually holds for any complex function
that has a complex derivative everywhere, but we will not prove this here.
3. It is important to realize that real functions of the plane do not have this
property. For example, consider F(x + iy) = x + iy2. Under F, the plane is
mapped onto the half-plane {(x, y) | y ≥0}. So points in the interior of the
plane are mapped to the boundary of the image, namely the x-axis. Recall
that this function does not possess a complex derivative.
To see why the Boundary Mapping Principle holds, we introduce the notion
of a “chunk” of a wedge about z0. Suppose ﬁrst that z0 ̸= 0 and that z0 =
r0eiθ0. Suppose r1 < r0 < r2 and θ1 < θ0 < θ2. Then we deﬁne a chunk about
z0 to be a set of the form
W = {reiθ | r1 < r < r2, θ1 < θ < θ2}
with z0 ∈W. Such a chunk is depicted in Figure 15.11. Note that z0 lies in
the interior of W.
FIGURE 15.11
A chunk of a wedge about z0.
In the special case where z0 = 0, we take the chunk to be a small disk
centered at 0.
For the squaring function Q0(z) = z2, we note that chunks are always
mapped to chunks. Indeed, the image under Q0 of the chunk W above is
given by
Q0(W) = {reiθ | r2
1 < r < r2
2, 2θ1 < θ < 2θ2}.
Note that Q0(W) contains Q0(z0) in its interior.

Calculus of Complex Functions
225
FIGURE 15.12
Qc takes a chunk about z0 to one that has been translated to Qc(z0).
In the case c ̸= 0, Qc takes chunks to regions that are chunks that have
been translated by the complex number c (see Figure 15.12).
This observation allows us to see why the Boundary Mapping Principle
holds. Given z0 inside a region R, we simply choose a small enough chunk
about z0 that lies entirely inside R. The image of this chunk then lies inside
Qc(R). By the above observation, Qc(z0) lies in the image chunk’s interior,
and therefore Qc(z0) lies in the interior of Qc(R).
Exercises
1. Compute the following:
a. (3 + 7i)2
b. (4 −2i)3
c. (7 + 2i)(5 −3i)(4i)
d. 3 + 2i
6 −5i
e.
1
(3 + 2i)2
2. Find the polar representation of each of the following complex numbers:
a. −7i
b. −6
c. 2 + 2i
d. −2 + 2i
e. 1 +
√
3i
f. −1 +
√
3i
3. Find the complex square roots of each of the complex numbers in the
previous exercise.

226
Complex Functions
4. What is the formula for the quotient of two complex numbers given in polar
representation?
5. Let Lα(z) = αz. Sketch the orbit of 1 in the plane for each of the following
values of α:
a. α = i/2
b. α = 2i
c. α = 1 +
√
3i
d. α = i
e. α = e2πi/9
f. α = e
√
2πi
6. Prove that the complex function F(z) = αz+β, where α and β are complex,
is conjugate to a linear function of the form Lγ(z) = γz. Determine γ in terms
of α and β. What happens when α = 1?
7. For which of the following functions does the complex derivative exist at
all points in the complex plane?
a. F(x + iy) = (x + iy)3
b. F(x + iy) = x2 + iy2
c. F(z) = |z|
d. F(z) = z2 + c
e. F(x + iy) = ix −y
f. F(z) = 2z(i −z)
g. F(z) = z3 + (i + 1)z
8. Find all ﬁxed points for each of the following complex functions and deter-
mine whether they are attracting, repelling, or neutral.
a. Q2(z) = z2 + 2
b. F(z) = z2 + z + 1
c. F(z) = iz2
d. F(z) = −1/z
e. F(z) = 2z(i −z)
f. F(z) = −iz(1 −z)/2
g. F(z) = z3 + (i + 1)z
9. Show that z0 = −1 + i lies on a cycle of period 2 for Qi(z) = z2 + i. Is this
cycle attracting, repelling, or neutral?
10. Show that z0 = e2πi/3 lies on a cycle of period 2 for Q0(z) = z2. Is this
cycle attracting, repelling, or neutral?
11. Show that z0 = e2πi/7 lies on a cycle of period 3 for Q0(z) = z2. Is this
cycle attracting, repelling, or neutral?
12. Show that the Boundary Mapping Principle holds for Fc(z) = zd + c.
13. Does the Boundary Mapping Principle hold for F(z) = z? Why or why
not?

Calculus of Complex Functions
227
14. Does the Boundary Mapping Principle hold for F(x + iy) = x2 + iy2?
Why or why not?
15. Give an example of a region R in the plane that has the property that,
under Q0(z) = z2, there is a boundary point of R that is mapped into the
interior of Q0(R). Does this contradict the Boundary Mapping Principle? Why
or why not?
16. Prove the Repelling Fixed Point Theorem in the complex case.


16
The Julia Set
The aim of this chapter is to introduce the notion of the Julia set of a complex
function. As we will see, the Julia set is the place where all of the chaotic
behavior of the complex function occurs. Keeping with our earlier philosophy,
we will consider here only quadratic functions of the form
Qc(z) = z2 + c.
Here both z and c are complex numbers. In Chapter 18 we will consider a few
other complex functions. We begin by revisiting three old friends.
16.1
The Squaring Function
The dynamics of the squaring function Q0(z) = z2 in the complex plane is
especially easy to understand. Let’s write z0 = reiθ. Then the orbit of z0 under
Q0 is given by
z0
=
reiθ
z1
=
r2ei(2θ)
z2
=
r4ei(4θ)
...
zn
=
r2nei(2nθ)
...
This means that there are three possible fates for the orbit of z0. If r < 1, we
have
r2n →0 as n →∞.
Hence |Qn
0(z0)| →0 as n →∞. As in the real case, Q0(0) = 0 and Q′
0(0) = 0,
so 0 is an attracting ﬁxed point. On the other hand, if r > 1, then we have
r2n →∞as n →∞,
so |Qn
0(z0)| →∞as n →∞in this case.
229

230
The Julia Set
The intermediate case is r = 1, the unit circle. If |z0| = 1, then |Q0(z0)| = 1
as well. Thus Q0 preserves the unit circle in the sense that the image of any
point on the unit circle also lies on the unit circle.
On the unit circle, the squaring map is the same as another old friend, the
doubling map. For if z0 = eiθ lies on the circle, we have Q0(z0) = ei(2θ). That
is, if we specify a point on the circle by giving its argument θ, then the image
of this point has argument 2θ. So Q0 simply doubles angles on the unit circle.
As earlier, this means that Q0 is chaotic on the unit circle. Our earlier proof
of this works in this case, but let’s prove a portion of this again using planar
arguments.
To see that periodic points are dense, we must produce a periodic point
inside any arc on the unit circle of the form θ1 < θ < θ2. That means we must
ﬁnd an n and θ so that
Qn
0(eiθ) = eiθ
with θ1 < θ < θ2. But
Qn
0(eiθ) = ei·2nθ
so we must solve
ei(2nθ) = eiθ.
The angle θ solves this equation provided
2nθ = θ + 2kπ
for some integers k, n. That is, θ must satisfy
θ =
2kπ
2n −1,
where both k, n are integers. If we ﬁx n and let k be an integer with 0 ≤
k < 2n −1, then the complex numbers with arguments 2kπ/(2n −1) are
evenly distributed around the circle as shown in Figure 16.1, with arclength
2π/(2n −1) between successive points. This follows since these points are just
the (2n −1)st roots of unity on the unit circle.
If we now choose n so that
2π
2n −1 < θ2 −θ1,
we guarantee that there is at least one point with argument 2kπ/(2n −1)
between θ1 and θ2. This point is therefore periodic with period n.
Transitivity follows as before. Any open arc θ1 < θ < θ2 on the circle is
doubled in arclength by Q0. Hence Qn
0 magniﬁes arclengths by a factor of 2n.
This means that we may choose n large enough that the image of the arc
θ1 < θ < θ2 under Qn
0 covers the entire circle and therefore any other arc.
This proves transitivity as well as sensitive dependence, for it shows that we
may ﬁnd nearby points that are eventually mapped to diametrically opposed

The Squaring Function
231
FIGURE 16.1
Points on the unit circle with arguments θ = 2kπ/(23 −1).
points on the circle. To summarize, we have given a complete orbit analysis
of Q0 on the complex plane.
Theorem. The squaring map Q0(z) = z2 is chaotic on the unit circle. If
|z| < 1 then |Qn
0(z)| →0 as n →∞. If |z| > 1 then |Qn
0(z)| →∞as n →∞.
The squaring map is extremely sensitive to initial conditions in the follow-
ing sense. Let z0 be a point on the unit circle. Given any open ball about z0,
we may always ﬁnd inside this ball a small chunk of a wedge of the form
W = {reiθ | r1 < r < r2, θ1 < θ < θ2}
with r1 < 1 < r2 that contains z0. Such a chunk is depicted in Figure 16.2.
FIGURE 16.2
A chunk of a wedge about z0.
Now the image of W is a new chunk given by
Q0(W) = {reiθ | r2
1 < r < r2
2, 2θ1 < θ < 2θ2}.

232
The Julia Set
Since r1 < 1 < r2, we have r2
1 < r1 < 1 < r2 < r2
2. Hence Q0(W) is a chunk
whose inner and outer radii are further away from r = 1, and whose total
polar angle is double that of W. See Figure 16.3. Continuing, we see that each
application of Q0 has the same eﬀect so that the size of Qn
0(W) grows with
n. Eventually, the polar angle of Qn
0(W) exceeds 2π so that, for n suﬃciently
large, Qn
0(W) is the annular region determined by
r2n
1
< r < r2n
2 .
Further applications of Q0 show that the inner radius of Qn
0(W) tends to zero
while the outer radius tends to inﬁnity. We therefore see that
∞
!
n=0
Qn
0(W) = C −{0}.
That is, the orbits of points in W eventually reach any point in C, except
0. This is extreme sensitive dependence: arbitrarily close to any point on the
unit circle there is a point whose orbit includes any given point in the plane,
with one possible exception, the origin.
FIGURE 16.3
Q0 magniﬁes the chunk W, and Q2
0 magniﬁes Q0(W).
We close this section with several deﬁnitions.
Deﬁnition. The orbit of z under Qc is bounded if there exists K such that
|Qn
c (z)| < K for all n. Otherwise, the orbit is unbounded.
For the squaring function, the orbit of any point inside and on the unit
circle is bounded; points outside the unit circle have unbounded orbits.

Another Chaotic Quadratic Function
233
Deﬁnition. The orbit of z under Qc is supersensitive if any open ball B about
z has the property that
∞
!
n=0
Qn
c (B)
is all of C, with the exception of at most one point.
For the squaring function, only points on the unit circle have supersensitive
orbits. For if |z| < 1, we may choose a small open ball about z that lies
completely inside the unit circle. Then the orbit of any point in this ball never
leaves the set {z | |z| < 1}. If |z| > 1, we may similarly ﬁnd a small open ball
outside {z | |z| ≤1} whose orbit remains outside of the unit circle.
Deﬁnition. The ﬁlled Julia set of Qc is the set of points in the complex plane
whose orbits are bounded. The Julia set of Qc is the boundary of the ﬁlled
Julia set.
We denote the ﬁlled Julia set by Kc and the Julia set by Jc. For the
squaring map we have thus shown that
K0
=
{z | |z| ≤1}
J0
=
{z | |z| = 1}.
Note also that it is precisely the points in J0 whose orbits are supersensitive
and that Q0 is chaotic on J0.
16.2
Another Chaotic Quadratic Function
Now we turn to a second example from the complex quadratic family,
Q−2(z) = z2 −2. Recall that we proved in Section 10.2 that the real ver-
sion of this function is chaotic on the interval −2 ≤x ≤2. As we will see here,
this interval is precisely the Julia set of Q−2.
Theorem. The quadratic function Q−2(z) = z2−2 on C−[−2, 2] is conjugate
to the squaring function Q0(z) = z2 on {z | |z| > 1}. Consequently, if z does
not lie in the closed interval [−2, 2], then the orbit of z under Q−2 tends to
inﬁnity.
Proof: Consider the function H(z) = z + 1/z deﬁned on the region R =
{z | |z| > 1}. H is one-to-one on R, for if H(z) = H(w), then we have
z + 1
z = w + 1
w,

234
The Julia Set
so that, after some algebra,
zw = 1.
If |z| > 1 then it follows that |w| = 1/|z| < 1 so w ̸∈R. Therefore, there is at
most one point in R that is mapped by H to a point in C −[−2, 2]. Also, H
maps R onto C −[−2, 2]. To see this, we choose w ∈C. We solve H(z) = w
via the quadratic formula, ﬁnding two solutions,
z± = 1
2

w ±

w2 −4

.
Since z+z−= 1, it follows that one of z+ or z−lies in R or else both lie on
the unit circle. In the latter case, however, it is easy to check that H(z+) =
H(z−) ∈[−2, 2]. This shows that H takes R in one-to-one fashion onto C −
[−2, 2].
Finally, an easy computation shows that
H(Q0(z)) = Q−2(H(z))
for all z. Hence Q−2 on C−[−2, 2] is conjugate to Q0 on R. Since all orbits of
Q0 tend to inﬁnity in R, it follows that all orbits of Q−2 also tend to inﬁnity
in C −[−2, 2]. This completes the proof.
Corollary. J−2 = K−2 = [−2, 2].
Using the conjugacy H, we see also that the orbit of any point in J−2
is supersensitive. Indeed, if we consider the inverse image of any open ball
about a point in J−2 under H, then we know that the squaring function Q0
eventually maps this set over the entire exterior of the unit circle in C. Hence,
via the conjugacy, this open ball is eventually mapped by Q−2 over all of C.
Remarks:
1. The conjugacy H looks diﬀerent but is actually the same as the semi-
conjugacy we encountered in Section 10.2. Indeed, if z = eiθ, then
H(z)
=
eiθ + e−iθ
=
(cos θ + i sin θ) + (cos θ −i sin θ)
=
2 cos θ,
which gave us the semi-conjugacy between z2 and z2 −2 on the Julia set of
each function.
2. It is an interesting fact that H maps straight rays perpendicular to the unit
circle to (possibly degenerate) hyperbolas that have vertices in the interval
[−2, 2] as depicted in Figure 16.4. See Exercise 8.
3. The ﬁlled Julia set of Q−2 is the interval [−2, 2] on the real line. The
boundary of this set in the plane is itself; that is why J−2 = K−2.
4. Curiously, the Julia sets J0 and J−2 are the only Julia sets in the quadratic
family that are not fractals.

Cantor Sets Again
235
FIGURE 16.4
The conjugacy H maps straight rays to hyperbolas.
16.3
Cantor Sets Again
In this section we will consider the quadratic functions Qc(z) = z2 + c in case
|c| > 2. Recall that, for real quadratic functions Qc(x) = x2+c, if c < −2, then
there is an invariant Cantor set on which Qc is chaotic. On the other hand,
when c > 2, all orbits of Qc on the real line simply tend to inﬁnity. We will see,
however, that these two subfamilies are really quite similar when viewed as
dynamical systems in the complex plane. In fact, using techniques analogous
to those introduced when we discussed symbolic dynamics in Chapter 9, it
can be shown that:
Theorem. Suppose |c| > 2. Then Jc = Kc is a Cantor set. Moreover, the
quadratic map Qc, when restricted to Jc, is conjugate to the shift map on two
symbols.
We will not provide all of the details of the proof here, since some of
the ideas involve advanced topics in complex analysis and others duplicate
arguments we gave in detail in Chapter 9. We will, however, show how the
Cantor set construction arises in this more general setting of the complex
plane.
Our ﬁrst observation is that the ﬁlled Julia set of Qc when |c| > 2 is
contained entirely inside the disk |z| < |c|.
Theorem (The Escape Criterion). Suppose |z| ≥|c| > 2. Then we have
|Qn
c (z)| →∞as n →∞.

236
The Julia Set
Proof: By the Triangle Inequality, we have
|Qc(z)|
≥
|z|2 −|c|
≥
|z|2 −|z|
since |z| ≥|c|
=
|z|(|z| −1).
Since |z| > 2, there is λ > 0 such that |z| −1 > 1 + λ. Consequently
|Qc(z)| > (1 + λ)|z|.
In particular, |Qc(z)| > |z|, so we may apply the same argument repeatedly
to ﬁnd
|Qn
c (z)| > (1 + λ)n|z|.
Thus the orbit of z tends to inﬁnity. This completes the proof.
This is an important theorem. Its corollaries will play an important role
in the sequel. We ﬁrst note that, if |c| > 2, then |Qc(0)| = |c| > 2. Hence the
orbit of 0, the critical point, necessarily escapes to inﬁnity if |c| > 2, so we
have:
Corollary 1. Suppose |c| > 2. Then the orbit of 0 escapes to inﬁnity under
Qc.
The proof of the escape criterion actually gives us a little more information.
In the proof, we only used the facts that |z| ≥|c| and |z| > 2. Hence we have
the following reﬁnement of the Escape Criterion:
Corollary 2. Suppose |z| > max {|c|, 2}. Then |Qn
c (z)| > (1 + λ)n|z| where
λ > 0, and so |Qn
c (z)| →∞as n →∞.
As an additional note, we observe that if |Qk
c(z)| > max {|c|, 2} for some
k ≥0, then we may apply this corollary to Qk
c(z) to ﬁnd:
Corollary 3. Suppose for some k ≥0 we have |Qk
c(z)| > max {|c|, 2}. Then
|Qk+1
c
(z)| > (1 + λ)|Qk
c(z)|, so |Qn
c (z)| →∞as n →∞.
Note that this corollary gives us an algorithm for computing the ﬁlled Julia
set of Qc for any c. Given any point z satisfying |z| ≤|c|, we compute the
orbit of z. If, for some n, Qn
c (z) lies outside the circle of radius max{|c|, 2},
we are guaranteed that the orbit escapes. Hence z is not in the ﬁlled Julia set.

Cantor Sets Again
237
On the other hand, if |Qn
c (z)| never exceeds this bound, then z is by deﬁnition
in Kc. We will make extensive use of this algorithm1 in the next section.
For the remainder of this section, we restrict attention to the case |c| > 2.
Let D denote the closed disk {z | |z| ≤|c|}. The ﬁlled Julia set of Qc is given
by

n≥0
Q−n
c
(D),
where Q−n
c
(D) is the preimage of D under Qn
c , that is,
Q−n
c
(D) = {z | Qn
c (z) ∈D}.
This follows since, if z ̸∈∩n≥0Q−n
c
(D), then there exists k ≥0 such that
Qk
c(z) ̸∈D and so the orbit of z tends to inﬁnity by Corollary 3. Thus we
need only understand the inﬁnite intersection ∩n≥0Q−n
c
(D) to understand Kc.
Toward that end, let C denote the circle of radius |c| centered at the origin.
Note that C is the boundary of D. The ﬁrst question is: what does Q−1
c (C)
look like? We obtain this set by ﬁrst subtracting c from any point in C. This
has the eﬀect of translating the circle so that it is centered at −c and in
fact passes through the origin. We then compute the complex square root of
all points on this new circle. As we explained in Chapter 15, this yields a
ﬁgure-eight curve as shown in Figure 16.5. Note that Q−1
c (C) is completely
contained in the interior of D since we already know that any point on or
outside of C is mapped farther away from the origin by Qc. Moreover, by the
Boundary Mapping Principle, Q−1
c (D) is precisely this ﬁgure-eight together
with its two interior “lobes.” Let us denote these lobes by I0 and I1 as shown
in Figure 16.5. Note that I0 and I1 are symmetrically located about the origin
and that Qc maps each of them onto D in one-to-one fashion.
Since Qc is one-to-one on both I0 and I1, and since Q−1
c (C) is contained
in the interior of D, it follows that Q−2
c (C) is a pair of smaller ﬁgure-eights,
one contained in the interior of I0 and one in the interior of I1. Again invoking
the Boundary Mapping Principle, we ﬁnd that Q−2
c (D) consists of these two
ﬁgure-eights together with their four lobes. We deﬁne
I00
=
{z ∈I0 | Qc(z) ∈I0}
I01
=
{z ∈I0 | Qc(z) ∈I1}
I10
=
{z ∈I1 | Qc(z) ∈I0}
I11
=
{z ∈I1 | Qc(z) ∈I1}.
Thus, Q−2
c (D) consists of a ﬁgure-eight in I0 together with its lobes I00 and
I01 and another ﬁgure-eight in I1 with lobes I10 and I11 (see Figure 16.6). Note
the similarity of this construction with the symbolic dynamics construction in
Chapter 9.
1It is perhaps better to call this a semi-algorithm, since we cannot determine whether a
point actually lies in Kc in ﬁnite time.

238
The Julia Set
FIGURE 16.5
Construction of I0 and I1.
Continuing, we see that Q−n
c
(D) consists of 2n−1 ﬁgure-eights together
with 2n lobes bounded by these curves. Let s0s1 . . . sn be a string of 0’s or 1’s.
We deﬁne
Is0s1...sn = {z ∈D | z ∈Is0, Qc(z) ∈Is1, . . . , Qn
c (z) ∈Isn}
and note that this is precisely the deﬁnition we used to discuss the real dynam-
ics of Qc when c < −2 in Chapter 9.
The arguments used there in the proof of the Conjugacy Theorem in Sec-
tion 9.4 may be mimicked here to show that Is0s1...sn is a closed lobe that
is contained in the interior of the lobe Is0s1...sn−1. Hence the Is0s1...sn form a
nested intersection of closed sets. Therefore

n≥0
Is0s1...sn
is a nonempty set. This fact is analogous to the Nested Intersection Property
discussed in Appendix A.3. Thus, if z ∈∩n≥0Is0s1...sn, then Qk
c(z) ∈D for all
k. Thus z ∈Kc.
An inﬁnite intersection of ﬁgure-eights and their lobes given by

n≥0
Is0s1...sn
is called a component of Kc. Note that any two components of Kc are neces-
sarily disjoint.
Conversely, any z ∈Kc must lie in one of these components. Consequently,
we may associate an inﬁnite string of 0’s and 1’s to any such z via the rule
S(z) = s0s1s2 . . .

Cantor Sets Again
239
FIGURE 16.6
Construction of I00, I01, I10, and I11.
provided
z ∈

n≥0
Is0s1...sn.
This string of 0’s and 1’s is identical to the itinerary deﬁned in Chapter 9. We
have therefore shown that there is a natural correspondence between points
in the sequence space on two symbols and the components of Kc. Similar
arguments to those in Chapter 9 show that this correspondence is in fact
continuous. A more diﬃcult result is the fact that each of these components
is indeed a single point. Recall that, even in the real case, we needed to make
additional assumptions (on the size of the derivative) to prove this. Using
more sophisticated techniques from complex analysis, the same result can be
proved in this case. We will not, however, go into the details here. The basic
idea is clear: the ﬁlled Julia set is a nested intersection of ﬁgure-eight curves
and their lobes as shown in Figure 16.7, and each of these intersections is a
single point, so the ﬁlled Julia set is a Cantor set.
Remarks:
1. Accepting the fact that each component of Kc is a point when |c| > 2, we
see that the Julia set and the ﬁlled Julia set are identical.
2. Figure 16.7 indicates that Qc is also extremely sensitive to initial conditions
on its Julia set when |c| > 2. Indeed, given any z ∈Kc and a small ball
containing z in its interior, we may always choose k so large that the lobe
Is0s1...sk containing z is also contained in this ball. But then Qk
c maps this
lobe onto the entire disk D, and subsequent iterations expand this disk further.
Eventually, any point in the plane lies in the image of this lobe under a
suﬃciently high iterate of Qc. Hence Qc is supersensitive on Jc.

240
The Julia Set
FIGURE 16.7
The Julia set is a nested intersection of ﬁgure-eights when |c| > 2.
3. We emphasize the fact that, when |c| > 2, the orbit of 0 tends to inﬁn-
ity. This will become important in the next chapter when we describe the
Mandelbrot set.
16.4
Computing the Filled Julia Set
In the previous sections, we discussed three very special examples of ﬁlled Julia
sets. As we will see, the typical complex quadratic function has a ﬁlled Julia
set that is geometrically much more interesting than those described earlier.
In this section we will again turn to the computer to determine experimentally
the shapes of various ﬁlled Julia sets.
The easiest way to compute the ﬁlled Julia set is to use the deﬁnition of
Kc. We consider a rectangular grid of points in some region in the plane. For
each point in this grid, we compute the corresponding orbit and ask whether
or not this orbit tends to inﬁnity. If the orbit does not escape, then our original
point is in Kc, so in the pictures in this section we will color the original point
black. If the orbit escapes, then we leave the original point white. The only
question is how we determine whether the orbit escapes to inﬁnity. For this
we can use the escape criterion in the previous section.
Algorithm for the Filled Julia Set: Choose a maximum number of itera-
tions, N. For each point z in the grid, compute the ﬁrst N points on the orbit
of z. If |Qi
c(z)| > max{|c|, 2} for some i ≤N, then stop iterating and color z
white. If |Qi
c(z)| ≤max{|c|, 2} for all i ≤N, then color z black. White points

Computing the Filled Julia Set
241
have orbits that escape, whereas black points do not, at least for the ﬁrst N
iterations. So the black points yield an approximation to the ﬁlled Julia set.
Remarks:
1. This algorithm is not foolproof. There will be points that take a larger
number of iterations to exceed the bound max{|c|, 2} than our maximum
number of iterations, N. In this case these points will be colored black although
they are not in Kc.
2. Despite this fact, it is usually best to keep the maximum number of iter-
ations low when using this algorithm. Five hundred iterations are usually
enough to give a very good approximation of Kc, except in cases where there
is a neutral periodic point in Kc. For magniﬁcations of portions of the ﬁlled
Julia set, you will need to increase the number N.
3. For the color plates of the ﬁlled Julia sets displayed in Chapter 1, we
used a slightly diﬀerent algorithm. The ﬁlled Julia set is still colored black.
Points whose orbits escape are assigned colors depending upon the number of
iterations necessary for the orbit to exceed max{|c|, 2}. Red points have orbits
that escape most quickly. Violet points have orbits that escape most slowly.
In between, points are colored shades of orange, yellow, green, and blue in
increasing order of the number of iterations necessary to escape.
For the remainder of this section, we simply summarize some of the obser-
vations that you will make using the experiments in this chapter.
Observation 1: For diﬀerent c-values, Kc assumes a wide variety of shapes.
Often, Kc consists of a large connected set in the plane. Some of these ﬁlled
Julia sets are displayed in Figure 16.8
A natural question is how to classify or understand all of these interesting
shapes. We will see in the next section that it is the Mandelbrot set that
provides a “dictionary” of all of these Julia sets.
The ﬁlled Julia sets in Figure 16.8 are remarkably diﬀerent from those we
encountered earlier in this chapter. Unlike the ﬁlled Julia sets for c = 0 (a disk)
and c = −2 (an interval), for other values of c, Kc appears to have a much
more complicated boundary. Recall that this boundary is the Julia set, Jc.
If we magnify portions of the boundary of any of the images in Figure 16.8,
we see a deﬁnite pattern of self-similarity. For example, in Figure 16.9, we
have magniﬁed several portions of K−1 in succession. At each magniﬁcation,
additional “decorations” attached to the ﬁlled Julia set are visible. This same
phenomenon occurs when the other ﬁlled Julia sets in Figure 16.8 are magni-
ﬁed. This leads to our second observation.
Observation 2: The Julia sets for Qc (with c ̸= 0, −2) appear to be self-
similar sets reminiscent of fractals.

242
The Julia Set
FIGURE 16.8
Filled Julia sets for Qc

Computing the Filled Julia Set
243
FIGURE 16.9
Magniﬁcations of the ﬁlled Julia set of Q−1, the basilica.
For many c-values, Kc seems to be one connected albeit complicated shape.
For many other c-values, however, the set Kc seems to consist of an inﬁnite
collection of sets. Some of these sets are single points, while others appear to
be disks. In particular, if we compute Kc for a c-value with |c| > 2, we see this
phenomenon. On the other hand, from our results in the previous section, we
know that Kc is a Cantor set when |c| > 2, thus this algorithm does not seem
to work well in certain cases. We will remedy this in Section 16.6 when we
present another algorithm to compute Julia sets.
We note, however, that the transition between large ﬁlled Julia sets and
these sparse ones can be abrupt. For example, in Figure 16.10, we display
the ﬁlled Julia sets for c = 0.25 and c = 0.251, each computed using 200
iterations. If you use 400 iterations to compute these images, you will see
that the ﬁlled Julia set for c = 0.25 remains essentially unchanged, whereas
the ﬁlled Julia set for c = 0.251 becomes decidedly smaller. Recall for later
use that Qc underwent a saddle-node bifurcation at c = 0.25. As another
example, in Figure 16.11, we display the ﬁlled Julia sets for c = −0.75 and
c = −0.75+0.1i, each computed using 200 iterations. Recall that Qc underwent
a period-doubling bifurcation at c = −0.75. Note how, in each case, the ﬁlled

244
The Julia Set
FIGURE 16.10
Filled Julia sets for c = 0.25 and c = 0.251.
FIGURE 16.11
Filled Julia sets for c = −0.75 and c = −0.75 + 0.1i.
Julia sets seem to shatter into isolated pieces. We will explain this in the next
chapter, but for now we simply note:
Observation 3: For many c-values, Kc appears to consist of a large num-
ber of isolated points and disks. Also, Kc seems to change abruptly from one
connected piece to many isolated points and pieces at certain special c-values.
Remark. We emphasize that the pictures of the “shattered” Julia sets in
Figures 16.10 and 16.11 are not quite correct. We will see in the next chapter
that these ﬁlled Julia sets are actually Cantor sets. The large black “blobs”
seen in these images begin to disappear when we use a larger and larger
number of iterations to compute these images.

Experiment: Filled Julia Sets and Critical Orbits
245
16.5
Experiment: Filled Julia Sets and Critical Orbits
Goal: In this experiment you will investigate the relationship between the
shape of the ﬁlled Julia set of Qc and the fate of the orbit of 0 under iteration
of Qc.
Procedure: For each of the following c-values, use a computer to draw the
ﬁlled Julia set of Qc. Record whether the ﬁlled Julia set appears to be one
connected piece or if it shatters into many isolated pieces as in Figures 16.10
and 16.11. Then compute the orbit of 0 for this c-value. Is this orbit bounded
or unbounded? You should try at least the following c-values:
a. c = −1.5 + 0.2i
b. c = −0.1 + 0.75i
c. c = −0.4 + 0.8i
d. c = 0.28 + 0.53i
e. c = −0.11 + 0.86i
f. c = −1.32
g. c = 0.48 + 0.48i
h. c = 1.5i
i. c = −0.5 + 0.57i
j. c = −0.4 + 0.4i
Results: In a brief essay, describe the relationship between the shape of the
ﬁlled Julia set and the fate of the orbit of 0.
Notes and Questions:
1. Many ﬁlled Julia sets consist of a collection of regions that are joined
together at single points. For example, consider the ﬁlled Julia set of Q−1(z) =
z2 −1 displayed in Figure 16.9. Don’t be fooled into thinking that these sets
are disconnected. When in doubt, magnify portions of the set.
2. When computing the ﬁlled Julia set for Qc, always begin with a square
centered at the origin whose sides have length 4. By the Escape Criterion,
orbits of points outside this square escape, unless |c| happens to be larger
than 2.
3. There are many computer programs on the web that allow you to
view ﬁlled Julia sets. For example, the quadratic map applet available at
math.bu.edu/DYSYS/applets/Quadr.html may be used for both quadratic
ﬁlled Julia sets and the Mandelbrot set.

246
The Julia Set
16.6
The Julia Set as a Repeller
In the ﬁrst three sections of this chapter, we discussed three examples of
speciﬁc Julia sets for Qc. Each of these Julia sets exhibited certain properties:
1. Repelling periodic points were dense in the Julia set.
2. Qc was supersensitive at any point in Jc.
Both of these properties hold for the Julia set of any Qc. We cannot prove
this here, since the proofs involve more advanced topics from complex anal-
ysis, speciﬁcally the theory of normal families. (See [10] and [28] for details.)
However, we will show that any repelling periodic point lies in Jc, as does any
preimage of this point. This will lead us to a second computer algorithm that
produces a picture of the Julia set of Qc, but not the ﬁlled Julia set.
We begin with a standard result from complex analysis, whose proof
demands somewhat more sophisticated techniques from analysis than pre-
viously encountered.
Cauchy’s Estimate. Suppose P(z) is a complex polynomial. Suppose also
that |P(z)| ≤M for all z in the disk |z −z0| ≤r. Then
|P ′(z0)| < M
r .
Proof: If we ﬁrst conjugate P via the translation L(z) = z−z0, we may assume
that z0 = 0. Suppose then that
P(z) =
d

n=0
anzn.
Consider the circle of radius r about 0 given by t →reit. We have
1
2π
" 2π
0
P(reit)
reit
dt
=
1
2π
" 2π
0
d

n=0
anrn−1ei(n−1)tdt
=
1
2π
" 2π
0
a1dt = a1 = P ′(0)
since the terms
" 2π
0
anrn−1ei(n−1)tdt
vanish when n ̸= 1 as we see by integration of
cos(n −1)t + i sin(n −1)t
over the interval 0 ≤t ≤2π.

The Julia Set as a Repeller
247
On the other hand,
    
1
2π
" 2π
0
P(reit)
reit
dt
    
≤
1
2π
" 2π
0
|P(reit)|
r
dt
≤
1
2π
" 2π
0
M
r dt
=
M
r .
Thus we have shown that
|P ′(0)| ≤M
r .
This completes the proof.
Theorem. Suppose z0 is a repelling periodic point for Qc. Then z0 ∈Jc.
Proof: Suppose z0 ̸∈Jc but z0 is a repelling periodic point with period n.
Suppose |(Qn
c )′(z0)| = λ > 1. Then there is a disk centered at z0 that lies in
Kc and thus has the property that no orbit of a point in this disk escapes to
inﬁnity. Let r be the radius of this disk. Now, for each k, Qkn
c
is a polynomial.
For each z in the disk we have, by the Escape Criterion,
|Qkn
c (z)| ≤max{|c|, 2}.
Let M = max{|c|, 2}. By the Cauchy Estimate, for each k we must have
|(Qkn
c )′(z0)| < M
r .
But
|(Qkn
c )′(z0)| = λk →∞.
This contradiction establishes the result.
Corollary. Suppose z0 is a repelling periodic point for Qc and z is a preimage
of z0. Then z ∈Jc.
The proof of this fact follows immediately from the previous theorem and
the Boundary Mapping Principle.
We turn now to a second algorithm for computing Julia sets. Unlike the
algorithm in the previous section, this one produces an image of the Julia set,
not the ﬁlled Julia set. This algorithm rests on the fact that Qc is supersen-
sitive on Jc. Choose any z ∈C (with at most one exception) and any point
z0 ∈Jc. Let U be a neighborhood of z0. By supersensitivity, there exists w ∈U

248
The Julia Set
and an iterate k such that Qk
c(w) = z. This means that, given any z ∈C, we
may ﬁnd preimages of z under Qk
c for large k arbitrarily close to any point in
Jc.2
Thus, to ﬁnd points in Jc, we will choose any z ∈C and compute its
“backward orbit.” Of course, each point w with the exception of c has two
preimages under Qc, namely ±√w −c. So, to compute the backward orbit of
w, we will make a random choice of one of these two preimages at each stage.
Backward Iteration Algorithm: Choose any point z ∈C. Compute 10,000
points on the backward orbit of z, randomly choosing one of the two possible
preimages of Qc at each stage. Plot all but the ﬁrst 100 backward iterations.
Some of the results of applying this algorithm are displayed in Figure 16.12.
While this algorithm produces a fairly accurate picture of the Julia set, you
will see that points in Jc that are reached by backward iteration are not evenly
distributed in Jc. This is evident in Figure 16.12a, where there are small gaps
in the curve that forms the Julia set of Q−1(z) = z2 −1.
Remarks:
1. This algorithm, unlike the algorithm for the ﬁlled Julia set, works particu-
larly well when the Julia set is a Cantor set. In Figure 16.13, we have displayed
the Julia set of Qc and several magniﬁcations when c = 0.5. Note how more
pieces of the Julia set become visible as we zoom in. As we will see in the
next chapter, this Julia set is in fact a Cantor set, even though it looks quite
diﬀerent from the linear Cantor sets we studied in Chapter 7.
2. This algorithm is reminiscent of the iterated function systems we studied
in Chapter 14. Instead of using a collection of linear contractions of the plane,
here we randomly iterate a pair of nonlinear functions, namely ±√w −c.
Exercises
1. Describe the ﬁlled Julia set for F(z) = z3.
2. Describe the ﬁlled Julia set for F(z) = zd for d ≥4.
3. Consider Q2(z) = z2 + 2. Let C = {z | |z| = 2}. Give an accurate sketch of
Q−1
2 (C) and Q−2
2 (C).
4. Use the techniques of Section 16.2 to conjugate F(z) = z3 to a polynomial
P(z) via H(z) = z + 1
z. What is P(z)?
2There is only one exception to this for any Qc, namely the special point z = 0, which
has only itself as a preimage in the special case where Q0(z) = z2. Hence there are no
preimages of 0 under Qk
0 near the Julia set.

The Julia Set as a Repeller
249
FIGURE 16.12
Julia sets computed via backward iteration.
5. Consider the complex function Gλ(z) = λ(z −z3). Show that the points
p±(λ) = ±
	
λ + 1
λ
lie on a cycle of period 2 unless λ = 0 or −1. Discuss the bifurcation that
occurs at λ = −1 by sketching the relative positions of p± and the ﬁxed
points of Gλ as λ increases through −1, assuming only real values.
6. Let Qi(z) = z2 + i. Prove that the orbit of 0 is eventually periodic. Is
this cycle attracting or repelling? Use the Backward Iteration Algorithm to
compute the ﬁlled Julia set for Qi. Does this set appear to be connected or
disconnected?
7. The Logistic Functions. The following exercises deal with the family of
logistic functions Fλ(z) = λz(1−z) where both λ and z are complex numbers.
a. Prove that F ′
λ(z) = λ(1 −2z) using complex diﬀerentiation.

250
The Julia Set
FIGURE 16.13
The Julia set of z2 + 0.5 and several magniﬁcations.
b. Find all ﬁxed points for Fλ.
c. Find all parameter values for which Fλ has an attracting ﬁxed point.
8. Prove that the complex function H(z) = z + 1/z takes straight rays ema-
nating from the origin to hyperbolas as depicted in Figure 16.4.
9. Now apply the map H to a circle of radius r ̸= 1 centered at the origin.
What is the image of this circle?

17
The Mandelbrot Set
Our goal in this chapter is to present some of the mathematics behind one
of the most intricate and interesting shapes in dynamics, the Mandelbrot set.
This set, ﬁrst viewed in 1980 by the mathematician Benoit Mandelbrot, has
been the subject of intense research ever since. Even though the Mandelbrot
set arises from iteration of the supposedly simple quadratic function z2 + c,
the structure of this set is still not completely understood.
17.1
The Fundamental Dichotomy
In the previous chapter we described several ﬁlled Julia sets rigorously and
many others experimentally. We noted that the ﬁlled Julia sets seemed to fall
into one of two classes: those that were connected and those that were totally
disconnected. There was apparently no “in between”: either Kc consists of one
connected piece or inﬁnitely many pieces. Here we will show that this is indeed
the case. In fact, this is one of the fundamental results of complex dynamics:
The Fundamental Dichotomy. Let Qc(z) = z2 + c. Then either
1. The orbit of the critical point 0 escapes to inﬁnity, in which case
Kc consists of inﬁnitely many disjoint components, or
2. The orbit of 0 remains bounded, in which case Kc is connected.
Just as we discussed in Chapter 16, in the ﬁrst case it can be proved that
Kc is actually a Cantor set and the dynamics of Qc on Kc is conjugate to the
shift map on two symbols. Hence we really have a stronger statement: either
Kc is totally disconnected or Kc is connected.
We have already shown that if |c| > 2, then the orbit of 0 escapes to inﬁnity
and Kc consists of inﬁnitely many components. Hence we consider here only
the case where |c| ≤2. Note that there is good reason for separating these two
cases. We have seen that K−2 is the interval [−2, 2], which is connected, and
251

252
The Mandelbrot Set
that the orbit of 0 under Q−2 is eventually ﬁxed. Hence |c| = 2 is the exact
largest value for which Kc may be connected.
Recall that the escape criterion gives us a suﬃcient condition for an orbit to
escape when |c| ≤2: if |Qn
c (0)| > 2 for some n, then the orbit of 0 tends to inﬁn-
ity. To prove the Fundamental Dichotomy, let’s ﬁrst suppose that |Qn
c (0)| →∞
as n →∞for some c with |c| ≤2. Then there is a ﬁrst iteration, say k, for
which |Qk
c(0)| > 2. Let ρ = |Qk
c(0)| and consider the circle of radius ρ, Cρ,
centered at the origin. The quadratic map Qc maps points on this circle to
the circle of radius ρ2 centered at c in the plane. However, by Corollary 3 of
the escape criterion, we know that the orbits of all points on Cρ escape to
inﬁnity. Let Dρ = {z | |z| ≤ρ}. The circle Qc(Cρ) actually encircles Cρ as
shown in Figure 17.1 since the center of this circle, c, satisﬁes |c| ≤2 < ρ.
By the Boundary Mapping Principle, the interior of the disk Dρ is mapped
to the interior of Qc(Dρ). We therefore have a situation similar to that of the
Cantor set case discussed in Section 16.3.
FIGURE 17.1
The case where the orbit of 0 escapes.
Now consider Q−1
c (Dρ). The set Q−1
c (Dρ) is completely contained in the
interior of Dρ since Cρ is mapped outside Dρ. Moreover, 0 belongs to Q−1
c (Dρ)
since Qc(0) = c and |c| < ρ. Consequently, Q−1
c (Dρ) is bounded by a simple
closed curve.
Since k is the smallest integer for which Qk
c(0) ∈Cρ, it follows that we
may repeat the above argument k −1 times. We ﬁnd that
Q−(k−1)
c
(Dρ) ⊂· · · ⊂Q−1
c (Dρ) ⊂Dρ
with Q−j
c (Dρ) contained in the interior of Q−j+1
c
(Dρ) for j = 1, . . . , k −1.
Moreover, Q−j
c (Dρ) is bounded by a simple closed curve which is mapped by
Qc to the boundary of Q−j+1
c
(Dρ), as shown in Figure 17.2.
At the kth iteration, this picture changes. The critical point 0 now belongs
to Q−k
c (Dρ). Since Qk
c(0) ∈Cρ, it follows that 0 lies on the boundary of
Q−k
c (Dρ). Hence the boundary of Q−k
c (Dρ) is a ﬁgure-eight curve, and each

The Fundamental Dichotomy
253
FIGURE 17.2
Q−(k−1)
c
(Dρ) ⊂· · · ⊂Q−1
c (Dρ) ⊂Dρ.
of the two lobes in the interior of this curve are mapped in one-to-one fashion
by Qc onto the interior of Q−k+1
c
(Dρ).
Thus we see that the preimage of Dρ pinches into two lobes precisely when
0 lies on the boundary of Q−k
c (Dρ).
The remainder of the argument is similar to that in Section 16.3. The
set Q−k−1
c
(Dρ) consists of a pair of ﬁgure-eights and their lobes lying in the
interior of Q−k
c (Dρ). In general, Q−k−n
c
(Dρ) consists of 2n disjoint ﬁgure-eights
and their lobes, so we see that the ﬁlled Julia set decomposes into inﬁnitely
many disjoint components when the orbit of 0 escapes. This proves Part 1 of
the Fundamental Dichotomy.
The only other possibility is Qk
c(0) never lies in the exterior of the circle
of radius 2. In this case, for any ρ > 2, Q−k
c (Dρ) is always a connected region
bounded by a simple closed curve. By the Connectedness Property (Appendix
A.3), ∩n≥0Q−n
c
(Dρ) is a connected set. As usual, this is the ﬁlled Julia set.
This completes the proof.
We must emphasize the incredible power and elegance of this result. For
quadratic polynomials, the ﬁlled Julia set can assume one of only two possible
shapes: a Cantor set or a connected set. There are no ﬁlled Julia sets that
consist of 2 or 40 or 100 pieces. Either the ﬁlled Julia set consists of one piece
or else it shatters into inﬁnitely many distinct pieces. Moreover, and this is a
truly amazing fact, it is the orbit of the critical point that determines which
case holds. The orbit of this one special point determines the global structure
of the set of all bounded orbits.

254
The Mandelbrot Set
17.2
The Mandelbrot Set
The Fundamental Dichotomy indicates that there are only two basic types
of ﬁlled Julia sets for Qc: those that are connected and those that consist of
inﬁnitely many disjoint components. Moreover, it is the orbit of 0 that deter-
mines which of these two cases hold. This leads to an important deﬁnition.
Deﬁnition. The Mandelbrot set M consists of all c-values for which the ﬁlled
Julia set Kc is connected. Equivalently,
M = {c ∈C | |Qn
c (0)| ̸→∞} .
It is important to realize that M is a subset of the c-plane, not the dynam-
ical plane where the Julia sets live. The Mandelbrot set is therefore a subset
of the parameter space for quadratic polynomials.
The escape criterion of Chapter 16 also gives us an algorithm for computing
the Mandelbrot set. As before, we consider a rectangular grid in the c-plane.
As we know, M is contained in the circle of radius 2 centered at the origin, so
we will always assume that our grid is contained inside the square centered at
the origin whose sides have length 4. For each point c in this grid, we compute
the corresponding orbit of 0 under Qc and ask whether or not this orbit tends
to inﬁnity. If the orbit does not escape, then our original point is in M, so
we will color the original point black. If the orbit escapes, then we leave the
original point white.
Algorithm for the Mandelbrot Set: Choose a maximum number of iter-
ations, N. For each point c in a grid, compute the ﬁrst N points on the orbit
of 0 under Qc. If |Qi
c(0)| > 2 for some i ≤N, then stop iterating and color c
white. If |Qi
c(0)| ≤2 for all i ≤N, then color c black.
Remarks:
1. As with our algorithm for displaying ﬁlled Julia sets, this algorithm is not
foolproof. There may be points for which the orbit of 0 takes more than N
iterations to escape from the circle of radius 2. These points will be colored
black even though they do not lie in M. So it is best to choose N as large as
possible.
2. For the colored plates illustrating the Mandelbrot set in Chapter 1, we
used the same coloring scheme as we used for the ﬁlled Julia sets, namely, red
c-values have critical orbits that escape fastest, followed by orange, yellow,
green, blue, and violet.

The Mandelbrot Set
255
Let’s try to understand what this image means. Suppose Qc has an attract-
ing periodic point of some period. Then the entire basin of attraction of this
point lies in Kc, and so the ﬁlled Julia set is not a Cantor set. By our discus-
sion earlier, this means that c should lie in the Mandelbrot set. The question
is where?
To answer this, let’s ﬁrst determine the set of c-values for which Qc has
an attracting or a neutral ﬁxed point. We denote this set by C1 and again
emphasize that this is a subset of the c-plane. Let zc denote the corresponding
ﬁxed point for Qc when c ∈C1. Then zc must satisfy the following pair of
equations:
Qc(z)
=
z2 + c = z
|Q′
c(z)|
=
|2z| ≤1.
The second equation says that zc lies on or inside the disk bounded by the
circle of radius 1/2. On this circle, |Q′
c(zc)| = 1, so zc is a neutral ﬁxed point.
If we write this circle as z = 1
2e2πiθ, then we ﬁnd from the ﬁrst equation that
the c-values for which Qc has a neutral ﬁxed point lie on the curve given by
c = ζ(θ) = 1
2e2πiθ −1
4e4πiθ.
This curve is the cardioid depicted in Figure 17.4. It gives the boundary of the
large black cardioid region visible in Figure 17.3. The interior of this region is
the set of c-values for which Qc has an attracting ﬁxed point.
Note that the boundary of C1 meets the real axis at two points, c = 1
4, the
saddle-node bifurcation point, and c = −3
4, the period-doubling bifurcation
point, or when θ = 0 and π, respectively. Note also that if c = ζ(θ) lies on
this curve, then Q′
c(zc) = e2πiθ. This means that, as the parameter c = ζ(θ)
winds once around the boundary of the cardioid, the corresponding derivative
FIGURE 17.3
The Mandelbrot set.

256
The Mandelbrot Set
at the ﬁxed point Q′
c(zc) winds once around the unit circle. Let’s summarize
these facts in a proposition.
Proposition (The Main Cardioid). The region C1 is bounded by a cardioid
given by
ζ(θ) = 1
2e2πiθ −1
4e4πiiθ.
For c-values in the interior of this region, Qc has an attracting ﬁxed point.
For c-values on the boundary of this region, Qc has a neutral ﬁxed point.
Moreover, as θ increases from 0 to 2π, the derivative Q′
ζ(θ) at the neutral ﬁxed
point winds once around the unit circle.
Now let’s turn to the region C2 in which Qc has an attracting or neutral
cycle of period 2. This region can also be computed explicitly, but we will
leave the details as an exercise. The relevant results are summarized in the
following Proposition.
Proposition (The Period-2 Bulb). The region C2 is bounded by a circle
given by |c+1| = 1
4, the circle of radius 1
4 centered at −1. Moreover, as c winds
around this circle, the derivative (Q2
c)′ at the 2-cycle winds once around the
unit circle.
The proof of this result is not diﬃcult. See Exercise 1. This result is also
illustrated in Figure 17.4. Note that C2 meets the real axis in the c-plane at
the period-doubling points c = −3/4 and −5/4. In the Mandelbrot set, the
period-2 bulb is the large circular region visible just to the left of the main
cardioid.
FIGURE 17.4
The regions C1 and C2.

Complex Bifurcations
257
The previous two propositions suggest that each of the decorations (or
bulbs) in M consist of c-values for which the corresponding quadratic func-
tions have an attracting cycle of a given period. Further evidence of the truth
of this fact is provided by the orbit diagram for Qc. In Figure 17.5, we have
superimposed the orbit diagram and the Mandelbrot set so that correspond-
ing real c-values are aligned vertically. That is, the real c-values that form the
horizontal axis in the orbit diagram lie directly below the corresponding real
c-values in the Mandelbrot set. Note that the real c-values for which we have
an attracting ﬁxed point or 2-cycle match up exactly, as we know to be the
case by the previous two propositions. Similarly, the smaller sequence of bulbs
along the real axis match up with the period-doubling regime in the orbit dia-
gram. Finally, note the small “blip” along the tail of the Mandelbrot set above
the period-3 window. In fact, this region is a small copy of the original Man-
delbrot set. We have magniﬁed this region in Figure 17.6 and superimposed
it above the period-3 window in the orbit diagram. Again we see that each
decoration on the Mandelbrot set corresponds to a region (at least when c is
real) where Qc has an attracting cycle of a given period.
As we have seen, the orbit of 0 determines completely the connectivity of
the ﬁlled Julia set of Qc. But there is much more to this story. As we saw
in Chapter 12, for real c, if Qc admits an attracting periodic orbit, then the
orbit of 0 must be attracted to it. The same fact is true for complex quadratic
polynomials, but the proof demands advanced techniques from complex anal-
ysis that are beyond the scope of this book. (See [10] or [28] for a discussion of
this.) Note that the Schwarzian derivative of a complex function may be com-
plex, so the ideas we exploited when the Schwarzian derivative was negative
do not hold in this case.
It thus follows that Qc can have at most one attracting cycle for each c,
and the orbit of 0 must ﬁnd this cycle if it exists. This gives another important
fact about M: the interior of each decoration or bulb attached to M consists
of c-values for which the corresponding Qc has an attracting cycle of some
given period. Again we will not prove this here, but instead will allow you to
discover this yourself as part of the following experiments.
17.3
Complex Bifurcations
In previous chapters we saw that, when parameters varied, real functions occa-
sionally encounter bifurcations, most often saddle-node or period-doubling
bifurcations. In this section, we look at these bifurcations in the complex
plane. We shall see that much more happens in these planar bifurcations.
Later in this section, we will introduce many other kinds of bifurcations that
do not appear in real families of maps.

258
The Mandelbrot Set
FIGURE 17.5
The orbit diagram and M aligned vertically.
First consider the saddle-node bifurcation for the quadratic family Qc(z) =
z2 + c. As we have seen, a saddle-node bifurcation occurs when c = 1/4. On
the real line, when c > 1/4, there are no ﬁxed points; rather all orbits simply
tend to ∞. When c = 1/4, a single ﬁxed point suddenly appears on the real
line at x0 = 1/2, and the orbits of points lying slightly to the left of x0 tended
to x0, while orbits of points to the right of x0 tended to ∞. And, ﬁnally, when
c < 1/4, two ﬁxed points appear on the real line.
In the complex plane, the local behavior is a little diﬀerent. Solving the
equation z2 + c = z shows that we have ﬁxed points at
z± = 1
2 ± 1
2
√
1 −4c.

Complex Bifurcations
259
FIGURE 17.6
The period-3 window and the corresponding portion of M.
When c > 1/4, these two ﬁxed points now lie oﬀthe real axis but in the
complex plane. The real part of z± is 1/2, and z+ lies above the real axis
while z−lies below this axis. In fact, for all c-values (except c = 1/4), z+ and
z−are distinct points in the plane. If c lies inside the main cardioid C1, then
one of the two ﬁxed points is attracting and the other is repelling, while if c
lies outside C1, both are repelling. And if c lies on the boundary of C1, one of
these two ﬁxed points is neutral.
So the local behavior of the ﬁxed points is a little diﬀerent in the complex
plane as c passes through 1/4. If c lies on a curve γ that passes from the
exterior of the main cardioid to the interior through c = 1/4, then before
c = 1/4, there are two distinct repelling ﬁxed points at z±. When c reaches
1/4, these two ﬁxed points merge together to produce a single neutral ﬁxed

260
The Mandelbrot Set
point at z0 = 1/2. And then, when c enters the main cardioid, two new ﬁxed
points reappear, one of which is attracting and the other repelling.
From a global point of view, much more happens at this saddle-node bifur-
cation. As we have seen, when c lies on the curve γ but outside the Mandelbrot
set, the Julia set of Qc is a Cantor set. But as soon as c reaches the boundary
of C1 at c = 1/4 and then enters C1, the Julia set suddenly becomes a con-
nected set. So there is a major change in the structure of the Julia set when
a saddle-node bifurcation occurs.
A somewhat similar local/global phenomenon occurs when we consider
the period-doubling bifurcation that occurs at c = −3/4. We now have two
diﬀerent ﬁxed points at z±. But we also always have two period-2 points, given
by the roots of z2 + z + c + 1 = 0, as we saw earlier. These periodic points are
q± = −1
2 ± 1
2
√
−3 −4c,
and these two points are always distinct, except when c = −3/4. So what
happens here is that, if c lies on a curve that passes from C1 to C2 through
c = −3/4, we always have two distinct ﬁxed points z± and two distinct period-
2 points q±, except when c = −3/4. When c = −3/4, the period-2 points are
given by q± = −1/2 and we also have z−= −1/2. So the two period-2 points
merge with one of the ﬁxed points to produce a single neutral ﬁxed point when
c = −3/4. When c enters C1, we have one attracting ﬁxed point and a pair
of repelling period-2 points, but when c moves inside C2, the ﬁxed point z−
becomes repelling while q± become attracting. So, just like the saddle-node
bifurcation, what we see at the bifurcation parameter is a merger between
distinct periodic points.
From a global perspective, there is also a major change in the structure of
the Julia sets as the parameter passes thorough a period-doubling bifurcation.
When c lies inside C1, as shown in Figure 17.7, the Julia set of Qc is a simple
closed curve, albeit with a somewhat complicated shape. But when c enters
C2, the Julia set suddenly includes inﬁnitely many “pinch-points,” i.e., points
at the intersections of distinct boundary components of the interior of the
Julia set. The reason for this is, when c lies in C1 near c = −3/4, the repelling
period-2 points q± lie in the Julia set and are close to each other, but they
are separated by the basin attraction of z−. But when these two points merge
with z−, the upper and lower portions of the Julia set now meet at z−. In
addition, there is a preimage of this ﬁxed point in the Julia set, so this is
another point where two diﬀerent portions of the Julia set meet. And then
this preimage of the ﬁxed point has a pair of preimages, each of which then
must lie at the intersection of a pair of arcs in the Julia set. And so forth
for all of the other preimages of this ﬁxed point under higher iterates of Qc.
Thus there are no pinch-points in the Julia set when c lies in C1, but there
are inﬁnitely many such points when c enters C2.
Now let’s turn attention to some diﬀerent types of bifurcations that occur
in complex families. Recall that the parameters on the boundary of the main

Complex Bifurcations
261
r
r
q−
q+
r
r
p
q−
q+
p
FIGURE 17.7
The Julia sets before and after the period-doubling bifurcation.
cardioid C1 are given by
c = c(θ) = 1
2e2πiθ −1
4e4πiθ,
and for each such c, there is a neutral ﬁxed point at zθ = e2πiθ/2. At this
ﬁxed point, F ′(zθ) = e2πiθ. So, for each c-value on the boundary of C1, the
corresponding map has a neutral ﬁxed point. Moreover, as c winds once around
the boundary of C1, the derivative at this ﬁxed point winds once around the
unit circle. Hence there is a unique c-value for which there is a ﬁxed point for
which the derivative is e2πip/q. We call this c-value cp/q. This is a rationally
indiﬀerent ﬁxed point. Then, at each cp/q-value, a period-q bifurcation occurs.
A period-q bifurcation is similar in spirit to the period-doubling bifur-
cation. When c is inside the main cardioid and close to cp/q, we have an
attracting ﬁxed point and a nearby repelling periodic orbit of period q. At
cp/q, the ﬁxed point and q-cycle merge to produce the single rationally indif-
ferent ﬁxed point. Then, as c exits the main cardioid, the parameter enters a
region in which Qc now has an attracting cycle of period q and, meanwhile,
the formerly attracting ﬁxed point has now become repelling.
Also, just as in the period-doubling case, as Qc undergoes this bifurcation,
the corresponding Julia sets change from a simple closed curve to a set where
there are inﬁnitely many pinch-points. Now, because we have a period-q bifur-
cation, there are exactly q interior components of the Julia set that meet at
each such pinch-point. An example of a period-tripling bifurcation is provided
in Figure 17.8.
This period-q bifurcation also gives us a map of how the decorations
attached to the main cardioid are arranged. At each point cp/q on the bound-
ary of C1, there must be a bulb attached to the main cardioid in which there
exists an attracting cycle of period q. We call this the p/q-bulb and denote it
by Bp/q. Since there can be at most one attracting cycle for Qc, these bulbs

262
The Mandelbrot Set
r
r
r
p1
p2
p3
r
r
r
p1
p2
p3
FIGURE 17.8
The Julia sets before and after the period-tripling bifurcation. Displayed is
the period-3 orbit Qc(p1) = p2, Qc(p2) = p3, and Qc(p3) = p1.
must be arranged around the boundary of C1 in the exact order of the rational
numbers between 0 and 1.
Rather than give a complete proof of the existence of period-q bifurcations,
let’s restrict to a speciﬁc example. Moreover, to make the algebra simpler, we
will work with the function Gλ(z) = λz + z2 instead of Qc. In Exercise 9, you
will see that for each c, there is a unique λ for which Qc and Gλ are conjugate.
Note that 0 is always a ﬁxed point for Gλ. Furthermore, we have G′
λ(0) =
λ. Hence 0 is an attracting ﬁxed point for Gλ when λ lies inside the unit
disk. When |λ| = 1, this ﬁxed point becomes neutral. In particular, when
λ = e2πip/q, this ﬁxed point is rationally indiﬀerent. Thus, for this family, the
unit circle plays the same role that the boundary of the main cardioid does
for Qc.
So let’s concentrate on the period-tripling bifurcation that occurs when
λ = e2πi/3. We need to ﬁnd the period-3 points. We have
Gλ(z) = λz + z2
and
G2
λ(z)
=
λ(λz + z2) + (λz + z2)2
=
z4 + 2λz3 + (λ + λ2)z2 + λ2z.
So we must solve G3
λ(z) −z = 0. A lot of enjoyable algebra gives
G3
λ(z) −z
=
λ(z4 + 2λz3 + (λ + λ2)z2 + λ2z)
+(z4 + 2λz3 + (λ + λ2)z2 + λ2z)2
=
z8 + 4λz7 + (4λ2 + 2(λ2 + λ))z6 + (2λ2 + 4λ(λ2 + λ))z5
+(4λ3 + (λ2 + λ)2 + λ)z4 + (2λ2(λ2 + λ) + 2λ2)z3
+(λ4 + λ(λ2 + λ))z2 + λ3z −z.

Experiment: Periods of the Bulbs
263
Now recall that λ = e2πi/3. So we have λ3 = 1 and λ4 = λ. Also, since
λ = cos(2π/3) + i sin(2π/3) and λ2 = cos(4π/3) + i sin(4π/3), a little bit of
trigonometry shows that λ2 + λ = −1.
Using these facts, we see that the coeﬃcient of z3 in the above equation is
given by
2λ2(λ2 + λ) + 2λ2 = 2λ2(−1) + 2λ2 = 0.
The coeﬃcient of z2 is
λ4 + λ(λ2 + λ) = λ −λ = 0.
And the ﬁnal two terms are λ3z−z = 0. Therefore our equation G3
λ(z)−z = 0
reduces to a polynomial of the form Az8 + Bz7 + Bz6 + Dz5 + Ez4 = 0 and
so we see that 0 is a root of order four for this equation. We know that our
ﬁxed point at 0 is one of those roots. The other ﬁxed point for Gλ occurs at
z = 1−e2πi/3, so this is a second root. The other six roots must then be points
lying on cycles of period 3. But this equation shows that one of those cycles
has merged with the ﬁxed point at 0 when λ = e2πi/3. Thus we see a similar
merger of a period-3 cycle and a ﬁxed point at the bifurcation value.
There is a video called “A Tour of the Mandelbrot Set” that displays the
corresponding Julia sets as a parameter wanders around a path in and out of
M which is available at math.bu.edu/DYSYS/animations.html.
17.4
Experiment: Periods of the Bulbs
As we have seen, each of the bulbs attached to the main cardioid C1 in M
meets the boundary of the main cardioid at a parameter value for which there
is a neutral ﬁxed point at which the derivative of Qc is exp(2πip/q). So this
is a period-q bulb. Recall that we call this the p/q-bulb and denote it by
Bp/q. Interestingly, you can determine the value of q by simply looking at the
antenna attached to this bulb. The antenna attached to Bp/q has a junction
point to which there are exactly q spokes attached (this includes the spoke that
connects directly to the bulb). Several such bulbs are displayed in Figure 17.9
as well as in Plate 18.
Goal: As we have seen, these bulbs are arranged around the boundary of the
main cardioid in the exact order of the rational numbers between 0 and 1.
Your goal in this experiment is to ﬁnd a way to identify the entire fraction
p/q in three diﬀerent ways.
Procedure: First, just by looking at the spokes attached to the junction
point in Bp/q, how do you determine the value of the numerator p? Second,
use a computer to plot the ﬁlled Julia set corresponding to a parameter that
lies close to the center of the bulb Bp/q. By looking at this set, can you

264
The Mandelbrot Set
FIGURE 17.9
The period-8, -9, and -13 bulbs attached to the main cardioid.
again determine the fraction p/q? Third, again use the computer to plot in
succession the orbit of the attracting cycle of period q that corresponds to the
previous parameter. Watch how this orbit evolves as you iterate. How can you
use this to determine p/q? In an essay, describe these three diﬀerent methods
for determining the fraction p/q associated with Bp/q.
Notes and Questions:
1. Using a computer, investigate the sub-bulbs hanging oﬀthe period-3 bulb
B1/3 attached to the main cardioid. Is there any relation between the ordering
of the periods of these sub-bulbs and the periods of the Bp/q? Also, by looking
at the antennas of these sub-bulbs, can you ﬁnd a way to determine both the
period of these sub-bulbs as well as the fact that they are attached to B1/3?
Some of these sub-bulbs are displayed in Plates 21 and 22. Explain what you
ﬁnd in a brief essay with some pictures.
2. Now repeat the previous investigation by looking at the period-4 bulb B1/4.

Experiment: Periods of the Other Bulbs
265
3. Several videos showing the ﬁlled Julia sets that arise as a param-
eter winds around just outside the main cardioid can be found at
math.bu.edu/DYSYS/animations.html.
17.5
Experiment: Periods of the Other Bulbs
Goal: In this experiment you will hunt for all of the bulbs in the Mandelbrot
set that correspond to attracting cycles of period n (not just those attached
to the main cardioid). As you perform this experiment, you will undoubtedly
view more of the wonderfully intricate geometric shapes that abound in M.
Procedure: Use a computer to select a c-value from a bulb and then deter-
mine the period of the corresponding attracting cycle. Find all bulbs that
feature an attracting n-cycle for n = 4, 5, and 6 (and note that sometimes
these bulbs will be the main cardioids of small copies of M).
Results: Indicate the locations of the period-4, -5, and -6 bulbs on a copy of
the Mandelbrot set. Some of these locations are indicated in Figure 17.10.
FIGURE 17.10
Periods of some of the bulbs in M.
Notes and Questions:
1. There are exactly six period-4 bulbs.
2. Next ﬁnd all of the period-5 bulbs. There are 15 of them. It is very diﬃcult
to ﬁnd all of them, but it is fun to try!

266
The Mandelbrot Set
3. Now try period 6, if you are a glutton for punishment. There are 27 of them!
Good luck! While it may seem that these bulbs are ordered in no apparent
fashion around M, there is in fact a beautiful description of how all of these
bulbs are arranged due to Douady and Hubbard [16]. Unfortunately, complete
details of their work are too advanced for this text. See [28] for more details.
4. One fact that will considerably shorten the time it takes to perform this
and some subsequent experiments is that the Mandelbrot set is symmetric
about the real axis. Moreover, the periods of symmetrically located bulbs are
the same. We ask you to verify this in exercise 2 at the end of this chapter.
Thus, for this experiment, you need only check the decorations in the upper
half-plane.
17.6
Experiment: How to Add
Goal: The aim of this experiment is to show how the concept of “Farey
addition” from the area of mathematics known as number theory arises when
viewing the arrangement of the principal bulbs Bp/q attached to the main
cardioid of M. Geometrically, the goal is to determine inductively the largest
bulb between two given bulbs attached to C1.
Procedure: To start, let’s identify the cusp of the main cardioid as the place
where the 0/1-bulb originates. Then we have, on the far-left side of the main
cardioid on the negative real axis, the place where 1/2-bulb is attached. Which
is the largest bulb between the 1/2-bulb and the 0/1-bulb in the upper half-
plane? Clearly, it is the 1/3-bulb. Now continue this process. Let a1 be the
fraction associated with the largest bulb between the 1/2-bulb and the 1/3-
bulb. Then let a2 be the fraction associated with the largest bulb between
the two previous bulbs, namely, the 1/3 and a1-bulbs. Then let a3 be the
fraction associated with the largest bulb between the previous two, the a1-
and a2-bulbs. And continue...
Notes and Questions:
1. Do you recognize the sequence generated by the denominators of
0/1, 1/2, 1/3, a1, a2, a3, . . .?
2. Can you ﬁnd a method to determine the fraction corresponding to the
largest bulb between the ak and ak+1-bulbs in this sequence? This method is
called “Farey addition.”
3. A brief video exploring zooms into the bulbs following this “Farey sequence”
is available at math.bu.edu/DYSYS/animations.html.
4. Now for some number theory. What is the fraction a1 between 1/2 and
1/3 with the smallest denominator? And what is the fraction a2 between a1
and 1/3 with the smallest denominator? And how about a3 between a1 and

Experiment: Find the Julia Set
267
a2? Do you see a similar pattern here? This is where Farey addition arises in
number theory.
Warning: Students are absolutely forbidden to use Farey addition in the real
world. Only folks with a Ph.D. in mathematics are allowed to add fractions
this way. Things become so much easier once you get your Ph.D. in math!
17.7
Experiment: Find the Julia Set
Goal: The aim of this experiment is to show you how each decoration in
the Mandelbrot set corresponds to c-values whose Julia sets are qualitatively
similar.
Procedure: Figures 17.11 and 17.12 depict eight diﬀerent ﬁlled Julia sets.
Your task is to identify the bulb in the Mandelbrot set that contains the
(a)
(b)
(c)
(d)
FIGURE 17.11
Find these Julia sets in the Mandelbrot set.

268
The Mandelbrot Set
(e)
(f)
(g)
(h)
FIGURE 17.12
More Julia sets to ﬁnd in the Mandelbrot set.
c-value that produced these Julia sets. In each case, use the computer to select
c-values from a bulb in the Mandelbrot set and then draw the corresponding
Julia set.
Results: On an image of the Mandelbrot set, indicate the approximate loca-
tions of Julia sets “a” through “h” in Figures 17.11 and 17.12.
Notes and Questions:
1. As a hint, each of the Julia sets (with only two exceptions) comes from
bulbs directly attached to the main cardioid. You may have to hunt within a
given decoration for the exact Julia set depicted, but you will quickly see that

Experiment: Similarity of the Mandelbrot Set and Julia Sets
269
all ﬁlled Julia sets from a single decoration have essentially the same features,
that is, are qualitatively the same.
2. Do you recognize any connection between the structure of the Julia sets
from a given decoration and the period of that decoration, as described in the
previous experiments?
3. Once you have found the locations of each of these Julia sets, investigate
the shapes of the Julia sets in corresponding locations in smaller copies of the
Mandelbrot set, particularly the period-3 Mandelbrot set on the real axis. Is
there any relation between these images? Explain in a brief essay.
17.8
Experiment: Similarity of the Mandelbrot Set and
Julia Sets
Goal: The goal of this experiment is to view a remarkable relationship
between the structure of the Mandelbrot set near special c-values and the
shape of the corresponding ﬁlled Julia sets.
Procedure: For a variety of diﬀerent bulbs Bp/q attached to the main car-
dioid, magnify the junction point of the antenna from which all of the spokes
emanate. Zoom in on this junction point several times. Then choose the cor-
responding c-value. Finally, use the computer to draw the ﬁlled Julia set for
this c-value. An example of this is displayed in Plates 19 and 20.
Results: Compare the structure of the magniﬁed Mandelbrot set near the
junction point with a magniﬁed portion of the corresponding ﬁlled Julia set.
Are there any similarities between these two images? Explain in an essay.
Notes and Questions: The similarity between magniﬁed portions of the
Mandelbrot set and the corresponding ﬁlled Julia sets holds only near certain
c-values such as the central junctions of the antenna. These are c-values for
which 0 is eventually periodic. Such c-values are called Misiurewicz points.
Exercises
1. Prove that Qc has an attracting 2-cycle when c lies inside the circle of
radius 1/4 centered at −1.
2. Prove that the Mandelbrot set is symmetric about the real axis. Hint: Show
this by proving that Qc is conjugate to Qc. Show that your conjugacy takes 0
to 0. Therefore the orbit of 0 has similar fates for both Qc and Qc.
The Logistic Functions. The following six exercises deal with the logistic
family Fλ(z) = λz(1 −z), where both λ and z are complex numbers.

270
The Mandelbrot Set
3. Prove that, for λ ̸= 0, |Fλ(z)| > |z| provided |z| >
1
|λ| + 1. Use this to give
the analogue of the escape criterion for the logistic family.
4. Show that if |λ| > 2 +
√
2, the orbit of the critical point of Fλ escapes to
inﬁnity.
5. Show that, if λ ̸= 0, the logistic function Fλ is conjugate to the complex
quadratic function Qc(z) = z2 + c, where c = λ
2 −λ2
4 . Let c = V (λ) be this
correspondence between λ and c. Why does this result fail if λ = 0?
6. Let L1 be the set of λ-values for which Fλ has an attracting ﬁxed point.
Compute L1 and sketch its image in the complex plane.
7. Show that the image of L1 under the correspondence V in exercise 5 is the
main cardioid in the Mandelbrot set.
8. Identify geometrically the set L2 of λ-values that are mapped to the period-
2 bulb in the Mandelbrot set by the correspondence V . How many connected
regions are in this set?
9. Prove that, for each value of λ, Gλ = λz + z2 is conjugate to a unique
function Qc(z) = z2 + c.
10. Prove that a period-4 bifurcation occurs for the family Gλ when λ = ±i.
11. Prove that the quadratic function Qc undergoes a period-tripling bifurca-
tion when c = (1/2)e2πi/3 −(1/4)e4πi/3. Do not use more than ten pages of
paper to do this algebra!
Higher Degree Polynomials. The following eight exercises deal with poly-
nomials of the form Pd,c(z) = zd + c.
12. Prove that P ′
d,c(z) = dzd−1. Conclude that, for each integer d > 1, Pd,c
has a single critical point at 0.
13. Prove the following escape criterion for Pd,c: if |z| ≥|c| and |z|d−1 > 2,
then |P n
d,c(z)| →∞as n →∞.
14. Show that if |c| > 2
1
d−1 , the orbit of the critical point of Pd,c escapes to
inﬁnity.
15. Suppose |c| > 2
1
d−1 . In a brief essay, discuss the structure of the ﬁlled
Julia set for Pd,c. What is the shape of the preimage of the circle of radius |c|
under Pd,c? Your discussion should parallel that of the discussion in Section
16.3.
16. Use the results of exercise 12 to modify the algorithm for the Mandelbrot
set to produce the analog of this set for the family Pd,c. These sets are called
the degree-d bifurcation sets. Two are displayed in Figure 17.13.

Experiment: Similarity of the Mandelbrot Set and Julia Sets
271
FIGURE 17.13
The degree-3 and degree-4 bifurcation sets.
17. For a ﬁxed value of d, ﬁnd the set of c-values for which Pd,c has an
attracting ﬁxed point. Find an expression for the boundary of this region.
Identify this region in the images generated by the previous exercise.
18. Prove that the degree-3 bifurcation set is symmetric with respect to reﬂec-
tion through the origin.
19. Prove that the degree-4 bifurcation set is symmetric with respect to
rotation through angle 2π/3. Hint: Show that P4,c is conjugate to P4,d if
d = e2πi/3c. Generalize this and the result of the previous exercise to the
degree-d bifurcation set.
20. Consider P3,c = z3 + c where the parameter c is real. Describe all of the
bifurcations that occur as c varies.
21. Now consider P3,c, where c is imaginary. Describe all of the bifurcations
that occur as c varies.
22. Show that c = −2 and c = i are Misiurewicz points for Qc, that is, 0 is
eventually periodic for Qc. On a sketch of the Mandelbrot set, locate these
two c-values as accurately as possible.

272
The Mandelbrot Set
Plate 18: The period-25 bulb in the Mandelbrot set and several magniﬁcations.

Experiment: Similarity of the Mandelbrot Set and Julia Sets
273
Plate 19: A magniﬁcation of the antenna attached to a period-7 bulb in the
Mandelbrot set.
Plate 20: A magniﬁcation of the Julia set corresponding to the parameter at the junction
point in Plate 19.

274
The Mandelbrot Set
Plate 21: The period-3 bulb in the Mandelbrot set.
Plate 22: On the left, a period 5 · 3 bulb attached to the period-3 bulb. On
the right, period 7 · 3, 9 · 3, 11 · 3, and 13 · 3 bulbs attached to the period-3
bulb.

Experiment: Similarity of the Mandelbrot Set and Julia Sets
275
Plate 23: Julia sets for the complex exponential function λ exp(z) for various
λ-values.

276
The Mandelbrot Set
Plate 24: The parameter plane for the family z3 + λ/z3.
Plate 25: Several magniﬁcations of the parameter plane for z3 + λ/z3. The
central disk consists of parameters for which the Julia set is a Cantor set of
simple closed curves. All of the other red disks contain parameters for which
the Julia set is a Sierpinski curve.

Experiment: Similarity of the Mandelbrot Set and Julia Sets
277
Plate 26: Julia sets corresponding to z2 −.6/z and z2 −.54/z. The ﬁrst Julia
set is homeomorphic to the Sierpinski triangle, while the second is
homeomorphic to the Sierpinski carpet.
Plate 27: Julia sets corresponding to z2 −.36/z2 and z2 −.27/z2. The ﬁrst
Julia set is a “generalized” Sierpinski triangle (perhaps called a “Sierpinski
square”), while the second is again homeomorphic to the Sierpinski carpet.

278
The Mandelbrot Set
Plate 28: Numerous quadratic Julia sets known as the “basilica” embedded
in the Julia set of z3 −.06/z3.
Plate 29: Numerous quadratic Julia sets known as the “Douady rabbit”
embedded in the Julia set of z3 + (.1 + .05i)/z3.

Experiment: Similarity of the Mandelbrot Set and Julia Sets
279
Plate 30: Singular perturbations of the basilica and the Douady rabbit. On
the left is the Julia set of z2 −1 −.001/z2; on the right is the Julia set of
z2 −.122 + .745i + .001/z2. Compare these to the Julia sets of z2 −1 and
z2 −.122 + .745i displayed in Plates 3 and 1.
Plate 31: Singular perturbations of the “cubic rat,” the Julia set of z3 −i.
On the left is the Julia set of z3 −i + .001/z3, and on the right is the Julia
set of z3 −i + .0001/z3.


18
Other Complex Dynamical Systems
In this chapter we introduce some very diﬀerent types of complex functions.
While we will not go into too much detail in describing their dynamical behav-
ior, we will suggest some further projects and experiments involving these
functions that students may pursue. In many cases, these projects demand
a combination of experimentation and rigorous mathematics. In each case,
there are many phenomena that are, as yet, still not understood. And these
families of complex functions often exhibit very diﬀerent dynamical behavior
compared to what we saw for the quadratic family. Since each section of this
chapter deals with a diﬀerent family of complex functions, there will be exer-
cises and experiments at the end of each section, rather than at the end of the
chapter.
18.1
Cubic Polynomials
The study of cubic polynomials is quite similar to the study of quadratics, with
one major exception. The diﬀerence is that the typical cubic polynomial has
two critical points, not just one. This means that we have several additional
phenomena that may occur in this case. For example, a cubic polynomial
may have two distinct attracting ﬁxed or periodic orbits. In addition, unlike
quadratics, where we have two distinct cases (the critical orbit either escapes
or is bounded), there are now three possibilities for cubics: both critical orbits
escape, both are bounded, and the new case, one critical orbit escapes and
the other remains bounded. Among other things, this means that the natu-
ral parameter space for cubics is four-dimensional, as there are two complex
parameters. Hence plotting the full parameter space for cubics is much more
diﬃcult, and indeed this set is currently not well understood.
As in the case of quadratic polynomials, any cubic polynomial is conjugate
to one of the special form
Ca,b(z) = z3 + az + b,
where a and b are complex. We ask you to verify this in Exercise 1. This
clearly displays the two complex parameters necessary in the cubic case [7].
281

282
Other Complex Dynamical Systems
To plot ﬁlled Julia sets of cubics, we need a condition similar to the escape
criterion of Chapter 16, which holds only for quadratic polynomials. One such
condition is given by assuming
|z| > max

|b|,

|a| + 2

.
Using the triangle inequality twice, we have
|Ca,b(z)|
=
|z3 + az + b|
≥
|z|3 −|az + b|
≥
|z|3 −|a||z| −|b|
>
|z|3 −|a||z| −|z|
=
|z|(|z|2 −(|a| + 1))
>
λ|z|
for some λ > 1. As usual, we may apply this inequality n times to ﬁnd
|Cn
a,b(z)| > λn|z|,
and hence the orbit of z must tend to inﬁnity. We have proved:
Escape Criterion for Cubics: Let Ca,b(z) = z3 + az + b. Suppose
|Cn
a,b(z)| > max(|b|,

|a| + 2)
for some n. Then the orbit of z escapes to inﬁnity.
Exercises
1. Prove that any cubic polynomial is conjugate to one of the form Ca,b(z) =
z3 + az + b.
2. What are the critical points and critical values of Ca,b?
3. Use a computer to view the ﬁlled Julia sets of Ca,b where
a. a = −1, b = 1
b. a = −1, b = 1.1
Describe the bifurcation you see as b increases from 1 to 1.1 and a remains
ﬁxed at −1. What is the exact point of bifurcation? Analyze this bifurcation
on the real line using graphical analysis.
4. Find values of a and b so that Ca,b has the property that the critical points
are ﬁxed and distinct. Describe the ﬁlled Julia set for Ca,b.
5. Find values of a and b so that both critical points lie on a cycle of period
2. Describe the ﬁlled Julia set for this function.

Rational Maps
283
6. Consider the polynomial P(z) = z3 −3z +3. Compute the critical points of
P. Show that one critical point is ﬁxed while the other has an orbit that tends
to inﬁnity. Use graphical analysis to describe the dynamics of this function on
the real line.
7. Describe the ﬁlled Julia set for the cubic polynomial in exercise 6.
8. Discuss the bifurcation that occurs in the family of real cubics Fa(x) = x3−
ax as a increases through 1. Then compute the ﬁlled Julia set of C−a,0(z) =
z3 −az. What changes occur in the ﬁlled Julia set as a passes through the
bifurcation value?
9. Find a family of cubic polynomials Ca,b having the property that all three
ﬁxed points for Ca,b tend to inﬁnity as |b| →∞.
10. Consider the cubic polynomial P(z) = z3 −1.6z + 1. Use the computer to
view the ﬁlled Julia set for this polynomial. Based upon what you see, what
do think happens to the orbits of the two critical points of P? Use graphical
analysis to explain this further.
11. Find an analogue of the escape criterion for fourth-degree polynomials.
12. Prove that any fourth-degree polynomial is conjugate to one of the form
z4 + az2 + bz + c.
18.2
Rational Maps
In this section we turn our attention to a very diﬀerent and more complicated
class of complex functions, namely, rational maps. What makes these maps
more complicated is the fact that rational maps often have many more critical
points than polynomials. In addition, the point at ∞is usually not an attract-
ing ﬁxed point, so we do not have an immediate basin of attraction near ∞
in this case as we always do for polynomials. And, ﬁnally, we also have poles,
i.e., points in C that are mapped directly onto ∞, which never happens in the
polynomial case.
Rather than plunge into the more general case of rational maps, we shall,
for simplicity, restrict attention in this section to the much more accessible
family of rational maps given by
Fλ(z) = zn + λ
zn ,
where λ is a complex parameter and n ≥2.
One reason for the interest in these maps is that they are singular pertur-
bations. What this means is that, when λ = 0, we have the simple map zn,

284
Other Complex Dynamical Systems
whose dynamics we completely understand. But, as soon as λ becomes non-
zero, the degree of this rational map jumps from n to 2n and the dynamical
behavior, as we shall see, explodes.
There are two reasons why this family of maps is “simpler.” First, as in the
polynomial case, we still have an immediate basin of attraction at ∞. For if |z|
is large, the term λ/zn is very small, so the map essentially behaves just like
zn near ∞. We will now think of the dynamics of Fλ on the Riemann sphere.
This is a sphere obtained by ﬁrst compressing C to an open disk, and then
identifying all points on the boundary of this disk to a single point. This adds
a single point at ∞in C which is then a ﬁxed point for Fλ in the Riemann
sphere. We could have done this earlier with the real line by analogously ﬁrst
compressing R to an open interval, and then identifying the two endpoints to
a single point to obtain a circle. For the map Fλ in the Riemann sphere, we
denote the immediate basin of attraction of the ﬁxed point at ∞by Bλ.
The second reason this family of maps is “simpler” is that computing
F ′
λ(z) = 0 shows that there are 2n critical points for these maps given by
λ1/2n. So it appears that we have a lot of diﬀerent orbits of critical points to
contend with. However, an easy computation shows that
Fλ(λ1/2n) = ±2
√
λ.
So there are only two critical values, which we denote by ±vλ, and therefore
only two critical orbits. What happens is that n of the critical points are
mapped to +vλ while the other n are mapped to −vλ. But, in fact, there is
really only one critical orbit. For, if n is even, ±vλ are both mapped to the
same point, so, after two iterations, all of the critical points land on the same
point and thus have the same ensuing orbit. If n is odd, we have Fλ(−z) =
−Fλ(z) for any z, so the orbits of ±z are always symmetric under the reﬂection
z →−z. So, for example, if the orbit of the critical value +vλ tends to ∞, then
so too does the orbit of −vλ. Similarly, if the orbit of one critical value tends
to an attracting cycle, then so too does the orbit of the other critical value.
Now these attracting cycles may not be the same, but they must be symmetric
under z →−z since the orbits of ±vλ are. In any event, the behaviors of all
of the critical orbits are essentially the same when n is odd as well.
One other major diﬀerence between this family of maps and polynomials
is that we now have a pole at 0. By deﬁnition, a pole is a point in C that
is mapped to ∞. So we therefore have a neighborhood of the origin that is
mapped to the immediate basin of attraction of ∞, Bλ. Now this neighborhood
may not be disjoint from Bλ as we shall see later, but, if this neighborhood is
disjoint from the basin at ∞, then this region is mapped n-to-1 onto Bλ. This
follows since, near the origin, the map Fλ is essentially λ/zn. Similarly, near
∞, Fλ is essentially zn, so, again, Fλ maps Bλ n-to-1 onto itself. Since Fλ is
a rational map of degree 2n, this means that the only preimages of Bλ in this
case are the basin itself and this neighborhood of 0. If this neighborhood of 0
is disjoint from the immediate basin of ∞, we call this neighborhood of 0 the
“trap door,” since, if the orbit of any point in C eventually enters the basin of

Rational Maps
285
∞, it must do so by passing through the trap door. We denote the trap door
by Tλ.
There are several other symmetries in this family. First, let ω be the 2nth
root of unity given by ω = e2πi/2n. So ω2n = 1, and hence ωn = −1. Then
an easy computation shows that Fλ(ωz) = −Fλ(z). So each of z and ωz are
mapped to points that are symmetric under z →−z. Just as above, this means
that the orbits of z and ωz behave symmetrically (either they both land on
the same point at the second iteration when n is even, or their entire orbits
are symmetric under z →−z when n is odd). As a consequence, the 2n points
given by ωjz all have orbits that behave in the same manner.
Another symmetry is given by the function Hλ(z) = λ1/n/z. This function
is an “involution” since H2
λ(z) = z. We have that Fλ(Hλ(z)) = Fλ(z), so the
orbits of z and Hλ(z) are the same.
For this particular family, we can again deﬁne the ﬁlled Julia set as the
set of points whose orbits do not escape to ∞. And so the Julia set J(Fλ) is
again the boundary of the ﬁlled Julia set. For more general rational maps, we
do not necessarily have a basin of ∞, so there is no “ﬁlled Julia set” in this
case. Rather, we would then deﬁne the Julia set to be the set of points where
we have sensitive dependence on initial conditions.
Now recall that, for the quadratic family z2 + c, we had the Fundamental
Dichotomy: if the orbit of the critical point tended to ∞, the Julia set was a
Cantor set, but if the orbit of the critical point did not tend to ∞, the Julia
set was a connected set. For the family Fλ, we have a somewhat diﬀerent
situation. It turns out that there are three diﬀerent ways that the orbits of
the critical values can tend to ∞. The ﬁrst occurs when the critical values lie
in the immediate basin of ∞. The second occurs when the critical values lie in
the trap door. And the third occurs when the critical values lie in neither the
trap door nor the basin of ∞, but the orbits of the critical values eventually
reach the trap door and then enter the basin of ∞. Each of these cases then
yield vastly diﬀerent types of Julia sets for Fλ.
The Escape Trichotomy. Suppose the orbits of the critical points λ1/2n tend
to ∞.
1. If the critical values lie in Bλ, then J(Fλ) is a Cantor set;
2. If the critical values lie in Tλ (which we assume is disjoint from the
basin of ∞), then J(Fλ) is a Cantor set of simple closed curves,
each of which surrounds the origin;
3. If the orbit of the critical values enters the trap door at some later
iteration, then J(Fλ) is a Sierpinski curve.
A Sierpinski curve is a planar set that is homeomorphic to the Sierpinski
carpet fractal described in Chapter 14. See Figure 18.1 for an example of each
of these three cases when n = 4.
We will not give a complete proof of the Escape Trichotomy since some of
the details involve advanced topics from complex analysis. However, we will

286
Other Complex Dynamical Systems
λ = 0.2
λ = 0.04
λ = −0.1
FIGURE 18.1
Some Julia sets for z4 + λ/z4: if λ = 0.2, J(Fλ) is a Cantor set; if λ = 0.04,
J(Fλ) is a Cantor set of circles; and if λ = −0.1, J(Fλ) is a Sierpinski curve.

Rational Maps
287
give a sketch of the geometric ideas that lie behind this result, and we will
include some of the details in the exercises.
Before beginning a sketch of the proof, ﬁrst note that all of the critical
points lie on the circle given by |z| = |λ1/2n|. In addition, there are 2n prepoles
for Fλ given by (−λ)1/2n. These are points that are mapped by Fλ to the pole
at 0. So all of the critical points and prepoles lie on the circle |z| = |λ1/2n|.
We call this circle the critical circle. Then one can easily show that Fλ maps
this circle 2n-to-1 onto the straight line segment connecting ±vλ and passing
through the origin. See Exercise 1.
To see why the Julia set is a Cantor set when the critical values lie in
Bλ, ﬁrst recall the proof of this fact in the case of quadratic polynomials.
There we found a curve in the basin of ∞that was shaped like a “ﬁgure 8”
and contained pieces of the Julia set inside each lobe of the curve. The single
critical point for this map was at the junction point of this curve. Then we
showed that each of the lobes in the interior of the ﬁgure 8 were mapped in
one-to-one fashion over a region that contained the entire ﬁgure 8 curve as
well as its interior components. The set of points that remained inside this
ﬁgure 8 for all iterates of the map was then a Cantor set and this was the
Julia set.
In the ﬁrst case of the Escape Trichotomy, recall that we have assumed
that ±vλ both lie in Bλ. So we may choose a simple closed curve γ1 that lies in
Bλ, contains both ±vλ, surrounds the origin, and is mapped strictly outside
itself in Bλ. The preimage γ0 of γ1 is not a collection of simple closed curves
since it contains all of the 2n critical points. Rather, γ0 is a single curve that
forms the entire preimage of γ1. Thus each point in γ1 has 2n preimages in
γ0, with the exception of the two critical values, each of which have only n
preimages in γ0. We can picture γ0 as a “necklace” consisting of 2n junction
points, and γ0 surrounds 2n diﬀerent disks, each of which contains one of the
prepoles. Then the two external regions of this necklace extend to ∞and to
0, so the union of these external regions is mapped 2n-to-1 onto the exterior
of γ1 in Bλ. Consequently, each of the 2n internal disks is mapped one-to-
one over the entire interior region of γ1, and so covers the entire necklace.
Thus the curve γ0 now plays the same role as the ﬁgure 8 curve did in the
quadratic case, only with many more junction points and “lobes.” Then the
same argument as in the quadratic case shows that the set of points whose
orbits remain inside these disks is a Cantor set, and the map on this set is
conjugate to the shift map on 2n symbols. This then is the Julia set in this
case.
The second case of the Escape Trichotomy occurs when the critical values
lie in the trap door Tλ. Curiously, this cannot happen when n = 2 (see Exercise
3). Thus we assume here that n ≥3.
Since we are assuming that both Bλ and Tλ are disjoint, it follows that
both of these sets are open disks in the Riemann sphere, with Tλ surrounding
the origin and Bλ surrounding ∞. Our assumption is that both of the images
of the critical points lie in Tλ, so the question is: what is the preimage of the

288
Other Complex Dynamical Systems
trap door? Can this preimage be a collection of 2n disjoint open sets, each
surrounding one of the critical points? The answer is no, because each of these
sets would then be mapped two-to-one onto Tλ since each of these sets contain
one of the critical points. But then there would be 4n preimages of each point
in Tλ. This cannot happen since Fλ is a rational map with degree 2n, so there
can be at most 2n preimages of any point in C. Consequently, at least two
of these preimages of Tλ must intersect. But recall that the orbits of Fλ are
symmetric under z →ωz, so it follows that all of the preimages of Tλ must
intersect because of this symmetry.
Thus it follows that this preimage must be a single connected set lying
between Bλ and Tλ, and this set contains all of the critical points and pre-
poles. It turns out that this preimage must be an annulus surrounding the
origin, because there cannot be any “holes” in this set (excluding the region
surrounding the origin). If there were such a hole, then by the Boundary Map-
ping Principle, its image under Fλ would have to be the entire exterior of Tλ.
So there would have to be a point in this region that is mapped to ∞. But
the only pole for Fλ is at the origin, so this cannot happen.
So we have that the preimage of Tλ is an annulus A1 that surrounds the
origin and lies between Tλ and Bλ. Then one checks easily that the preimage
of A1 is a pair of annuli, one lying between A1 and Bλ, and the other lying
between A1 and Tλ, and each surrounding the origin and mapped n-to-1 onto
A1. Then the next preimages consist of four annuli surrounding the origin.
And on and on. Then a result of McMullen [26] shows that removing all of
these annuli (plus Bλ and Tλ) leaves behind just a Cantor set of simple closed
curves surrouding the origin, which is then J(Fλ).
For the third part of the Escape Trichotomy, we have to show that if the
critical values do not lie in either Bλ or Tλ but the orbits of these points
eventually land in Bλ, then J(Fλ) is a Sierpinski curve, i.e., is homeomorphic
to the Sierpinski carpet described in Chapter 14. Now, as mentioned in that
chapter, ﬁnding such a homeomorphism between the carpet and a Sierpinski
curve is almost always impossible. But we have Whyburn’s Theorem to help
us out. All we have to show is that J(Fλ) is compact, connected, locally con-
nected, nowhere dense, and has the property that any pair of complementary
domains are bounded by simple closed curves that are pairwise disjoint. Prov-
ing the ﬁrst four of these properties is almost automatic using some ideas from
complex analysis.
First, Julia sets are always compact in the Riemann sphere, since all of
the complementary domains (if they exist) are open sets. Second, because all
of the critical orbits eventually escape to ∞, J(Fλ) must be connected. The
reason for this is that the only sets in the complement of the Julia set are
Bλ and all of its preimages. There cannot be any attracting periodic points
because there are no critical orbits available to tend to this periodic point. For
similar reasons there cannot be neutral periodic points in the complement of

Rational Maps
289
FIGURE 18.2
The parameter planes for n = 3 and n = 4.
the Julia set. Hence the Julia set is the complement of inﬁnitely many disjoint
open disks, and so J(Fλ) must be connected.
An amazing theorem in complex dynamics says that, if the critical orbits
do not meet the Julia set and the Julia set is connected, then this set must
also be locally connected. Another theorem from complex analysis (Montel’s
Theorem) says that, if the Julia set ever contains an open set (no matter
how small), then, in fact, the Julia set must be the entire Riemann sphere.
This follows immediately from super-sensitiviy on the Julia set, for if we had
an open set in the Julia set, then the forward orbit of this open set must
eventually cover the entire complex plane (minus at most one point). So all of
these points which are in the images of the open set must be in J(Fλ). Finally,
to show that the boundaries of the complementary domains are simple closed
curves requires an advanced technique called quasiconformal surgery, which
we will not plunge into in this book. See [6] and [28] for a detailed description
of all of these advanced techniques. This gives a sketch of the proof of the
Escape Trichotomy
Since the maps Fλ each have essentially only one critical orbit (up to
symmetry), we can use this orbit to display the parameter planes for these
maps. In Figure 18.2 we display the parameter planes for the cases n = 3 and
n = 4. The outer white region contains parameters for which the Julia set is
a Cantor set. The central white disk is the “McMullen domain,” i.e., the set
of parameters for which the Julia set is a Cantor set of simple closed curves.
And all of the other white disks contain parameters for which the Julia set is
a Sierpinski curve. The black region contains all of the parameters for which
the critical orbits do not escape. Plates 24 and 25 also display the parameter
plane for n = 3 with several magniﬁcations.

290
Other Complex Dynamical Systems
FIGURE 18.3
Julia sets for λ = −.001 and λ = −.00001 in the family z2 + λ/z2.
Exercises
1. Prove that the map Fλ maps the critical circle |z| = |λ1/2n| onto the straight
line connecting +vλ and −vλ.
2. Prove that when λ ̸= 0 is real, Fλ maps any circle centered at the origin
(except the critical circle) onto an ellipse whose major and minor axes lie
along the real and imaginary axes.
3. Prove that the critical values of Fλ can never lie in the trap door when
n = 2, but that this is always possible when n ≥3.
4. Use a computer to display the Julia sets for the function z2 + λ/z2 when λ
is very close to 0. Do you have any thoughts as to what happens to the Julia
sets in this case as λ →0 (but does not equal 0). In Figure 18.3 are displayed
two Sierpinski curve Julia sets in this family, one when λ = −.001 and the
other when λ = −.00001.
Experiment
Goal: In this experiment, you will investigate other types of singularly per-
turbed complex dynamical systems. It is your choice as to which family of
singularly perturbed maps you wish to investigate. Recall that a map Gλ is
said to be a singular perturbation if, for example, when the parameter λ = 0,
the map has degree n and the dynamics are completely understood. But when
λ ̸= 0, a pole has been added so the degree of the map increases and the
dynamical behavior becomes much more complicated.

Exponential Functions
291
Procedure: In this section, we always chose zn as our original map before
the perturbation. This map has a ﬁxed point at 0, and 0 is also a critical point
for the map. Then we added a pole at 0 to create the perturbation. But we
can choose other polynomials as the original map before the perturbation.
Most often, when a singular perturbation yields dramatically diﬀerent
dynamical behavior, the cause of this is that a pole of some order has been
added at a critical point, which is also ﬁxed or periodic. In Plate 30 we have
displayed the Julia sets of z2−1−.001/z2 and z2−.122+.74i+.001/z2. In both
cases we have again added a pole at the origin. In the ﬁrst case (without the
perturbation term −.001/z2), we have the simple function z2 −1, whose Julia
set is the basilica (see Plate 3 in Chapter 1). In this case, 0 is a critical point
which is periodic of period 2. In the second case (without the perturbation
term .001/z2), the map comes approximately from the center of the period-3
bulb in the Mandelbrot set whose Julia set is the Douady rabbit (see Plate
1). Again, 0 is a critical point and is very close to being periodic of period 3.
Another singularly perturbed family is given the map z3 −i + λ/z3. See
Plate 31. As before, the pole is added at the origin, which is a critical point
of period 2 for z3 −i. Note that, in this plate, the two Julia sets that are
displayed are dramatically diﬀerent even though the parameter λ does not
change very much.
Results: Choose any family of singular perturbed maps Gλ that you like.
Ideally, you should understand the behavior of the map more or less completely
when λ = 0. So ﬁrst explain the behavior of the map before the perturbation.
Then add a pole of some order, preferably at some critical point of G0 that is
also periodic. Since the dynamics of these singular perturbed maps are almost
impossible to describe completely, your task is to see if you can describe any
of the interesting changes that occur when λ ̸= 0.
18.3
Exponential Functions
To deﬁne the complex exponential function, we need to recall one of the most
beautiful formulas from elementary calculus, Euler’s Formula. This formula
relates the exponential and the trigonometric functions:
eix = cos x + i sin x.
We have used this formula before, but perhaps it is useful to recall why it is
true. To do this, we simply use the power series representation for ex evaluated

292
Other Complex Dynamical Systems
at ix, ﬁnding
eix
=
∞

n=0
(ix)n
n!
=
1 + ix −x2
2! −ix3
3! + x4
4! + ix5
5! + . . .
=
1 −x2
2! + x4
4! . . . + i(x −x3
3! + x5
5! . . .)
=
cos x + i sin x.
Note that these series converge absolutely for all x, so the above rearrange-
ment is possible. Euler’s formula allows us to deﬁne the complex exponential
function.
Deﬁnition. The complex exponential function ez is deﬁned by
ez = ex+iy
=
exeiy
=
ex cos y + iex sin y.
Note that ex+iy is deﬁned for all complex numbers. Furthermore the expo-
nential is 2πi-periodic, since
ex+iy+2πi
=
ex cos(y + 2π) + iex sin(y + 2π)
=
ex(cos y + i sin y)
=
ex+iy.
Furthermore, the complex exponential maps a vertical line of the form x = c
to a circle of radius ec centered at the origin, since
|ec+iy| = |ec(cos y + i sin y)| = ec.
Similarly, the exponential maps a horizontal line of the form y = b to a ray
emanating from the origin with angle θ = b, since
ex+ib = ex(cos b + i sin b).
There is a fundamental diﬀerence between the ﬁlled Julia sets of maps like
the exponential and polynomials. No longer do we have an escape criterion.
For example, consider the left half-plane given by
H = {x + iy | x ≤c}.
By our above remarks, any point in H is mapped by the exponential inside
the circle of radius ec centered at 0. Hence faraway points in the left half-
plane move very close to the origin after one iteration. Nonetheless, there is

Exponential Functions
293
an “approximate” escape criterion that may be used to describe the set of
orbits that escape. If the real part of z is large, say z = x + iy with x > 50,
then
|ez| = |exeiy| = ex > e50,
which is very large. Although it is not true that any orbit that reaches the
half-plane x > 50 eventually escapes, it can be shown that there is often
a nearby point whose orbit does escape. Hence we use the following as our
condition for escape:
Approximate Escape Criterion for Exponentials. Suppose Eλ(z) = λez.
If the real part of En
λ(z) exceeds 50, we say that the orbit of z “escapes.”
Remark. It is known that, unlike the case for polynomials, any point whose
orbit escapes for the complex exponential actually lies in the Julia set of
Eλ(z) = λez. As before, the set of repelling periodic points are again dense
in J(Eλ). This means that, arbitrarily close to any point in J(Eλ) there is
a point that lies on a repelling periodic orbit and also a point whose orbit
escapes to ∞, and so both of these points lie in J(Eλ). Thus the structure of
the Julia sets of complex exponential functions is quite diﬀerent from that for
polynomials. For more details on this topic, see [10].
One major diﬀerence between the exponential family and polynomials is
that Eλ has no critical points. However, Eλ does have an asymptotic value
at 0. An entire function G is said to have an asymptotic value at z0 if there
is a curve γ(t) that limits on ∞as t →a and whose image G(γ(t)) limits on
z0 as t →a. Note that any curve γ(t) for which Re γ(t) →−∞is mapped
by Eλ to a curve that limits on 0. Note also that 0 is an omitted value for
Eλ. In addition, as mentioned earlier, Eλ wraps any left half-plane Re z < c
inﬁnitely often around 0.
The asymptotic value 0 plays a similar role for Eλ as critical values do for
polynomials: if Eλ has an attracting cycle, then the orbit of 0 must tend to
it. A major diﬀerence between the exponential and quadratic case is that, if
the orbit of the asymptotic value tends to ∞, then the Julia set of Eλ is the
entire plane. For a proof, see [17] or [20].
Let’s now return to a topic we have delved into several times earlier,
namely, the saddle-node bifurcation. For the rest of this section, we will con-
sider only λ-values that are real and positive. The graphs of the real functions
Eλ show that the exponential family undergoes a saddle-node bifurcation as
λ increases. See Figure 18.4.
In fact, this bifurcation occurs when λ = 1/e. Indeed, we have E1/e(1) = 1
and E′
1/e(1) = 1, so 1 is a neutral ﬁxed point for E1/e. When 0 < λ < 1/e,
there are two ﬁxed points on R, an attracting ﬁxed point between 0 and 1,
and a repelling ﬁxed point to the right of 1. When λ increases through 1/e,
these two ﬁxed points merge at the bifurcation value, and then they reappear

294
Other Complex Dynamical Systems
-2
1
2
-2
2
FIGURE 18.4
The graphs of Eλ as λ passes through 1/e.
as two repelling ﬁxed points in the complex plane, one above the real axis
and one below, just as in the quadratic case. Moreover, when λ > 1/e, all
orbits in R now tend to ∞, so the entire real line lies in J(Eλ) in this case.
When λ ≤1/e, only points to the right of the repelling ﬁxed point escape,
while points to the left of the repelling ﬁxed point have orbits that tend to
the attracting ﬁxed point. So the portion of the real line to the left of the
repelling ﬁxed point is not in the Julia set when λ < 1/e.
As we saw for the complex quadratic function z2 + c, the saddle-node
bifurcation caused a major change in the structure of the Julia set: before the
bifurcation, the Julia set was a connected set, but after the bifurcation, the
Julia set shattered into a totally disconnected set of points, a Cantor set. For
the exponential family, this bifurcation causes a much more dramatic change
in the structure of the Julia set. When 0 < λ ≤1/e, the Julia set is an inﬁnite
collection of disjoint curves called a Cantor bouquet, each of which lies in
the right half-plane and extends oﬀto ∞[12]. But when λ increases through
1/e, the orbit of the asymptotic value 0 now tends to ∞so the Julia set sud-
denly becomes the entire complex plane. A video illustrating this “exponential
explosion” is available at math.bu.edu/DYSYS/animations.html.
Recall that the set of repelling periodic points is dense in J(Eλ). This
means that, when 0 < λ ≤1/e, all of the repelling periodic points lie in
some right half-plane. But when λ passes through 1/e, suddenly the repelling
periodic points become dense in the entire plane! Amazingly, no new peri-
odic points are born when λ passes through 1/e (except for the two repelling
ﬁxed points that reappear after the ﬁxed points in R merge when λ = 1/e).
What happens is that all of the repelling periodic points move continuously
as λ varies, and as soon as λ passes through 1/e, they somehow immediately
become dense in the entire complex plane!

Exponential Functions
295
The proof that the Julia set explodes in this manner is too complicated
to describe here. However, we will give a little glimpse of how this dynamical
behavior changes as λ increases through 1/e.
First, let’s assume that 0 < λ < 1/e. Then the graphs of Eλ show that we
have two ﬁxed points qλ and pλ in R with 0 < qλ < 1 < pλ. The ﬁxed point
qλ is attracting and pλ is repelling. Then somewhere between qλ and pλ is a
point xλ with E′
λ(xλ) = 1. In fact, we have xλ = log(1/λ). Then the graph of
Eλ shows that we have
0 < qλ < Eλ(xλ) < xλ < pλ.
Furthermore, for any point with Re z < xλ, we have |E′
λ(z)| < 1.
Now consider the half-plane given by Re z < xλ. Where are the points in
this half-plane mapped by Eλ? As we saw earlier, Eλ maps the vertical line
Re z = xλ to the circle centered at the origin whose radius is given by
λelog(1/λ) = 1,
and since
1 = Eλ(xλ) < xλ = log(1/λ),
it follows that this circle lies to the left of the vertical line Re z = xλ. More-
over, we have that the entire left half-plane Re z < xλ is mapped inside this
circle, and |E′
λ(z)| < 1 for all z in this half-plane. This means that the entire
half-plane Re z < xλ is contracted strictly inside this disk. Then the disk is
contracted inside itself by another application of Eλ, and on and on. Then it
follows that any point in the half-plane Re z < xλ is not in J(Eλ) and, in fact,
has an orbit that tends to the attracting ﬁxed point qλ.
Now let’s move on to the case λ > 1/e. Proving that J(Eλ) = C involves
a lot of techniques from advanced complex analysis, so, for simplicity, we will
restrict to the case λ = 1, i.e., the function E(z) = ez, and we will only show
there are inﬁnitely many repelling periodic points for E in the left half-plane.
Let x < 0. For any δ > 0, let Sx be the vertical strip x −δ ≤Re z ≤x.
So Sx consists of inﬁnitely many rectangles Rn
x where Rn
x is the portion of
the strip Sx satisfying (2n −1)π < Im z ≤(2n + 1)π for some given integer
n. Note that each Rn
x is mapped by E one-to-one onto an annulus centered
at the origin. The inner circular boundary of this annulus has radius ex−δ
while the outer boundary has radius ex. Therefore E(Rn
x) contains an open
neighborhood in the right half-plane that contains the open interval (ex−δ, ex)
lying along the positive real axis. Call this neighborhood Ux.
Now iterate this interval and its neighborhood forward. Since |E′| > 1
for all points in the right half-plane, it follows that this interval gets longer
and longer as we iterate. In addition, a neighborhood of these intervals is also
expanded each time we iterate. In particular, there is an iterate, say k, such
that Ek(Ux) contains an open rectangle of the form ℓ< Re z < ℓ+ 10 and
−π < Im z < π where ℓis very large. Thus there is a small open set contained
in each Rn
x that is mapped one-to-one by Ek+1 onto this rectangle. But now

296
Other Complex Dynamical Systems
E maps this rectangle onto a huge annulus whose inner circular boundary has
radius eℓand whose outer boundary has radius e10eℓ. Assuming ℓis suﬃciently
large, then it follows that this annulus covers a number of the rectangles Rn
x.
But then we have a small open set in each of these covered rectangles that
is mapped one-to-one onto the entire rectangle by Ek+2. This produces a
repelling perioidc point of period k + 2 inside the given rectangle Rn
x.
Applying this idea one further step to the right produces more rectangles
Rn
x that contain repelling periodic points. And continuing on and on produces
inﬁnitely many periodic points in the strip Sx. Then changing x produces
inﬁnitely many additional repelling periodic points in diﬀerent vertical strips.
Since x can be arbitrarily large and negative, we see that repelling periodic
points have moved all over the complex plane. A slight modiﬁcation of the
above arguments shows that this is true for Eλ whenever λ > 1/e. While this
does not prove the density of repelling periodic points, it does show that the
Julia set of Eλ has changed dramatically after the saddle-node bifurcation.
Project. Use the computer to sketch the escape and non-escape orbits for
λez. Be sure to use the approximate escape criterion as your test for escape.
As an example, the set of non-escape points for (1+2i)ez is displayed in black
in Figure 18.5. White points in this picture correspond to points whose orbits
eventually reach the region Re z > 50. A number of other Julia sets in the
exponential family are displayed in Plate 23. In these ﬁgures, colored points
are points whose orbits eventually enter the region Re z > 50, and so give an
approximation of the Julia set.
FIGURE 18.5
The Julia set for (1 + 2i)ez.

Exponential Functions
297
Exercises
1. Use a computer to view the set of escaping orbits for 0.5ez. Choose a large
enough number of iterations so that the picture “stabilizes.” What do you
conclude about the set of escaping orbits?
2. Use a computer to view the set of escaping orbits for 0.3ez. Is there a
diﬀerence between this picture and that of exercise 1? What happens if you
choose more iterations?
3. Find the set of complex λ-values such that Eλ(z) = λez has an attracting
ﬁxed point in the plane. Sketch this set in the λ-plane.
4. Use a computer to view the ﬁlled Julia sets for λez when λ is given by:
a. πi
b. 2πi
c. −2.5 + 1.5i
d. −2.7 + 1.5i
e. 1 + 0.2i
5. Use an accurate graph and graphical analysis to discuss the dynamics of
Eλ(x) = λex on the real line for a selection of λ-values in the range −4 <
λ < −2. Do you see a bifurcation? Now compute the ﬁlled Julia sets for these
values of λ. Describe what you see in an essay.
6. Show that there is a negative λ-value for which Eλ undergoes a period-
doubling bifurcation.
7. Find all ﬁxed points for the complex function G(z) = zez. Determine which
are attracting, repelling, or neutral.
8. Find all ﬁxed points for the complex function H(z) = z + ez. Which are
attracting, neutral, or repelling?
9. Let λ = τ + iy0 where y0 is ﬁxed and τ is negative. Prove that, if τ is
suﬃciently negative, then Eλ has an attracting cycle of period 2 by ﬁnding a
far-left half-plane that is contracted into itself by E2
λ.
10. Let λ = τ + iπ where τ is now positive. Show that Eλ has an attracting
cycle of period 3 when τ is suﬃciently large using the same ideas as in the
previous exercise.
The following exercises deal with the exponential function Eλ where 0 < λ <
1/e.
11. Consider the vertical strip Sτ bounded by 1 ≤Re z ≤τ and −3π ≤
Im z ≤3π. Divide Sτ into 3 equal-sized rectangles R−1, R0, and R1 whose
horizontal boundaries are given by y = kπ where k is an odd integer. Choose
τ so that the circle of radius λeτ centered at the origin surrounds these three
rectangles. Describe the set of all points whose orbits remain inside Sτ for all

298
Other Complex Dynamical Systems
iterations. Then use symbolic dynamics to describe the dynamical behavior
inside Sτ.
12. Extend the results of the previous exercise to the case of 2n + 1 similar
rectangles, n above and n below the real axis.
13. What happens if you extend the rectangles in the previous two exercises
to be strips whose real parts extend from 1 to ∞in the right half-plane? What
can you say about the set of points whose orbits now remain in these strips?
18.4
Trigonometric Functions
The complex trigonometric functions are deﬁned to be linear combinations of
the complex exponential as follows:
Sλ(z) = λ sin z = λ
2i

eiz −e−iz
Cλ(z) = λ cos z = λ
2

eiz + e−iz
.
The reason for these seemingly strange deﬁnitions is again due to Euler’s
Formula. Recall that, for real θ-values, we have
eiθ = cos θ + i sin θ.
Hence
e−iθ = cos θ −i sin θ.
If we add these two equations, we ﬁnd that
eiθ + e−iθ = 2 cos θ,
which motivates our deﬁnition of the complex cosine. Subtracting the second
equation from the ﬁrst yields the complex sine.
As with the exponential, there is no “absolute” escape criterion for the
complex sine and cosine functions. However, there is again an “approximate”
test for escape. Suppose Im z < −50. Then, if z = x + iy,
| sin z|
=
1
2|eiz −e−iz|
=
1
2|e−yeix −eye−ix|
≥
1
2

|e−y||eix| −|ey||e−ix|

=
1
2(e−y −ey).

Trigonometric Functions
299
Thus, if Im z < −50, the modulus of the image of z is quite large, since e−y is
large while ey is small. Similar arguments work in the case where Im z > 50.
As in the case of the complex exponential, it is not true that points that
satisfy |Im z| > 50 have orbits that necessarily tend to inﬁnity, but it is known
that nearby points have this property (at least for sin z and cos z).
Approximate Escape Criterion for Trigonometric Functions. Let
Sλ(z) = λ sin z. If |Im z| > 50, then we say that the orbit of z “escapes.”
A similar criterion holds for Cλ(z) = λ cos z. As with the complex expo-
nential, it is true that the escaping points also lie in the Julia sets of Sλ or
Cλ. The Julia sets for sine and cosine are displayed in Figure 18.6.
FIGURE 18.6
The white regions are the Julia sets for (a) sin z, and (b) cos z. Black points
have bounded orbits.
Project: Use the computer to view the ﬁlled Julia set and escaping orbits for
Sλ and Cλ. An applet for this is available at math.bu.edu/DYSYS/applets.
Exercises
1. Use a computer to view the Julia set of Sλ(z) = λ sin z where λ = 0.9 and
λ = 1.1. Describe the changes you see.
2. What are the dynamics of S1 on the real line? Explain using graphical
analysis.
3. Discuss the bifurcation that occurs when λ = 1 for Sλ with λ varying along
the real line.

300
Other Complex Dynamical Systems
4. Show that, if y is a real number, then Sλ(iy) = iλ sin y. Conclude that, if
both y and λ are real, Sλ preserves the imaginary axis.
5. Discuss the dynamics of Sλ on the imaginary axis when λ is real and
positive. What kind of bifurcation occurs when λ = 1?
6. Discuss the dynamics of Sλ on the imaginary axis when λ is real and
negative. What kind of bifurcation occurs when λ = −1?
7. Use the computer to draw the Julia sets of Cλ when λ = 0.6i and λ = 0.7i.
Is there a diﬀerence?
8. Consider the complex cosines Ciμ(z) = iμ cos z, where μ is a real parameter.
Show that Ciμ preserves the imaginary axis. Use graphical analysis to discuss
the bifurcation that occurs on this axis as μ passes through 0.67 . . ..
18.5
Complex Newton’s Method
Recall from Chapter 13 that Newton’s method is an iterative procedure to
solve certain equations. Given a function F, to ﬁnd the solutions of F(x) = 0,
we simply choose an initial guess x0 and then compute the orbit of x0 under
the Newton iteration function
N(x) = x −F(x)
F ′(x).
We saw earlier that roots of F were in one-to-one correspondence with attract-
ing ﬁxed points of N. Often, but not always, the orbit of x0 converges to an
attracting ﬁxed point of N, which thus yields a root of F.
In this section we extend the discussion of Newton’s method to the case
where F is a complex polynomial. The same techniques used in Chapter 13
show that the complex Newton iteration function
N(z) = z −F(z)
F ′(z)
has an attracting ﬁxed point at z0 if and only if z0 is a solution of the equation
F(z) = 0. Here z is a complex number. Hence we may try to use iteration of
N to ﬁnd roots of F in the complex plane.
Let’s now redo some of the examples we worked out in Chapter 13, this
time in the plane.
Example. Suppose F(z) = z2 −1 with roots at z = ±1. Recall from Chapter
13 that any real number x0 ̸= 0 has an orbit that tends to ±1 under the real
Newton iteration function.

Complex Newton’s Method
301
In the complex case, the Newton iteration function is
N(z) = z −z2 −1
2z
= 1
2

z + 1
z

.
We ﬁrst claim that all of the orbits of N tend to one of the roots, except those
whose seeds lie on the imaginary axis. To see this, we construct a conjugacy
with another old friend. Let
H(z) = z −1
z + 1.
Note that H is deﬁned except at z = −1 and that H(−1) = ∞. Now consider
the diagram
z
N
−→
N(z)
H
⏐⏐⏐
⏐⏐⏐H
z−1
z+1
−→
?
1
2(z+ 1
z)−1
1
2(z+ 1
z)+1.
As usual, we ask which function completes this diagram. To answer this, note
that
H ◦N(z) =
1
2

z + 1
z

−1
1
2

z + 1
z

+ 1 = z2 −2z + 1
z2 + 2z + 1 =
z −1
z + 1
2
.
Thus, if Q(z) = z2 is the complex squaring function, then
H ◦N(z) = Q ◦H(z).
Thus N is conjugate to Q! (It is easy to check that H is one-to-one; see
Exercise 1.)
Note that H takes the imaginary axis to the unit circle. This follows since
|H(iy)| =
    
iy −1
iy + 1
    = 1.
The quotient is equal to 1 since the complex numbers iy −1 and iy + 1 are
equidistant from the origin. Furthermore, H takes points z0 with Re z0 > 0
to the interior of the unit circle and points with Re z0 < 0 to the exterior of
the unit circle. In particular, H takes 1 to zero and −1 to inﬁnity. So, by the
conjugacy, if Re z0 > 0, then the orbit of z0 tends to 1 under N, whereas if
Re z0 < 0, the orbit of z0 tends to −1.
Finally, if Re z0 = 0, H takes z0 to the unit circle, where Q is known to be
chaotic (see Section 10.2). Thus we see that Newton’s method for F(z) = z2−1
converges to a root provided we choose an initial seed oﬀthe imaginary axis.
If we choose the seed on the imaginary axis, then Newton’s method does not

302
Other Complex Dynamical Systems
converge to a root and leads, in fact, to chaotic behavior. In fact, on the
imaginary axis, the Newton iteration function reduces to N(y) = 1
2(y −1
y),
and we showed that this function was chaotic in Chapter 13.
The following example explains something we discussed in detail in Chap-
ter 13. Recall that, if we try to apply real Newton iteration to the function
F(x) = x2 + 1, which has no real roots, we observe chaotic behavior. This
behavior can now be seen to be equivalent to the previous example.
Example. Let F(z) = z2 + 1 with complex Newton iteration function
N(z) = 1
2

z −1
z

.
Let
H(z) = z −i
z + i.
Note that H takes the roots of F to zero and inﬁnity. It is easy to verify that,
as in the previous example, H is a conjugacy between N and Q(z) = z2. See
Exercise 2. In addition, the Newton iteration function on the real axis in this
case is exactly the same as the Newton iteration function on the imaginary
axis in the previous case.
The previous two examples suggest that, when Newton’s method is applied
to a complex quadratic polynomial with distinct roots at z1 and z2 in the
plane,
1.
N is chaotic on the line that is the perpendicular bisector of z1 and
z2.
2.
All other orbits of N converge to z1 or z2, depending upon which
side of the perpendicular bisector the seed lies.
We ask you to verify these facts in Exercise 3. Thus, as long as we choose
points oﬀthe perpendicular bisector, Newton’s method always converges in
the quadratic case.
This fact was ﬁrst proved by the British mathematician Arthur Cayley in
1879 [8]. In a bit of mathematical overeagerness, Cayley wrote that he hoped
that similar methods could be used to solve cubic polynomials. This proof,
however, never appeared. There is a good reason for this: the cubic case is
much more diﬃcult than the quadratic case. In fact, if a cubic polynomial
has three distinct roots, then the set of points at which N fails to converge
is a fractal, much like the Julia sets of Chapter 16. Moreover, it is entirely
possible for N to admit attracting cycles that have period greater than 1.
Orbits of points that lie in the basin of a cycle of high period therefore cannot

Complex Newton’s Method
303
be attracted to one of the roots, and so Newton’s method fails to converge on
an open set of points.
To plot the results of Newton’s method in the complex plane, we make use
of the following algorithm. Given a grid of points in the plane, we compute
the orbit of each grid point under N for a maximum number of iterations,
say K. If the orbit of this point tends to a ﬁxed point, then that point is a
root of the polynomial, and we color this and all such points that tend to
this ﬁxed point with the same color. In Plate 14 in Chapter 1, we display the
outcome of Newton’s method applied to the complex polynomial z3 −1. The
three diﬀerent colored regions are the basins of attraction of the three diﬀerent
roots of z3 −1. The three largest colored regions surround the roots and are
the immediate basins of attraction of these points. All other similarly colored
regions eventually map to these immediate basins. The regions between these
basins form the Julia set for the Newton iteration function, where again we
have chaotic behavior.
Exercises
1. Prove that the function
H(z) = z −1
z + 1
is one-to-one.
2. Show that the function
H(z) = z −i
z + i
gives a conjugacy between the Newton iteration function for F(z) = z2 + 1
and Q(z) = z2.
3. Let a, b ∈C with a ̸= b. Consider the quadratic polynomial F(z) = (z −
a)(z −b). Show that the Newton iteration function corresponding to F is
conjugate to Q(z) = z2 via a conjugacy that takes a to zero and b to inﬁnity.
4. Describe the dynamics of the Newton iteration function corresponding to
F(z) = zd for d = 2, 3, 4, . . . .
5. Describe the dynamics of the Newton iteration function corresponding to
E(z) = ez.
6. Let F(z) = z2(z −1). Show that the Newton iteration function corre-
sponding to F is conjugate to the logistic function L(z) = 1
2z(1 −z) via the
conjugacy
H(z) = 1 −z
z
.
7. Prove that the Newton iteration function corresponding to the function
F(z) = zez is conjugate to the quadratic polynomial L(z) = z + z2.


A
Mathematical Preliminaries
In this appendix we will review some of the necessary notions from calculus
that we will use in this book. We will also introduce a few elementary topo-
logical notions that we will use throughout. In general, readers may skip this
section, referring back to it only if necessary. There will be certain notions
that arise during the course of this book that are beyond the scope of typi-
cal calculus courses. We will in general describe these ideas completely when
needed.
A.1
Functions
For the main part of this book, we will consider functions of one real variable.
Later, when we introduce symbolic dynamics, we will encounter functions
deﬁned on other “spaces.” Still later we will turn to functions in the complex
plane. For now, however, a function will be a real-valued function of one real
variable, just as encountered in elementary calculus.
Recall that a function is an operation that assigns to certain real numbers
x a new real number F(x). The set of allowable x-values is called the domain
of the function. The set of allowable values for F(x) is called the target space
or range. Often the domain of the function will be all real numbers, but occa-
sionally we will restrict our attention to certain subsets of the reals. We will
always denote a function by capital letters, as, for example, the cubing func-
tion F given by F(x) = x3. Here F denotes the function and F(x) denotes the
value of the function at x, namely x3. It is important to distinguish between
the function—the operation of cubing—and its value at a particular point x,
namely x3.
We denote the set of all real numbers by R. We write F : R →R to
indicate that F is a real-valued function of a real variable. If the domain of F
is the interval [a, b] and we wish to specify the target as the interval [c, d], we
will write F : [a, b] →[c, d]. This kind of notation will be important later when
we discuss functions deﬁned on the plane or other “spaces.” It also emphasizes
the fact that a function is a “dynamic” object that takes points in [a, b] and
assigns values to them in [c, d]. We think of F geometrically as moving or
305

306
Mathematical Preliminaries
mapping points in the domain to points in the target. For this reason we will
often refer to a function as a map or mapping.
Deﬁnition. A function F is called one-to-one if for any x0 and x1 in the
domain of F with x0 ̸= x1 we have F(x0) ̸= F(x1). We say that F is onto if
for each y in the target space, there is at least one x in the domain of F such
that F(x) = y.
Brieﬂy, one-to-one functions assign diﬀerent values to diﬀerent numbers
in the domain. Onto functions assume all values in the target. For example,
increasing or decreasing functions are always one-to-one. They need not be
onto, however. For example, if we consider the function A(x) = arctan(x)
as a function A: R →R, then A is increasing but not onto. If the target
space is the open interval −π/2 < x < π/2, then this function is onto. We
must always specify what the target space is when discussing whether or not a
function is onto. As another example, the function T : (−π/2, π/2) →R given
by T(x) = tan(x) is both one-to-one and onto. Note that T is not one-to-one
if we consider its domain to be all real numbers.
For a function F that is both one-to-one and onto, we may deﬁne the
inverse function F −1. This is the function that satisﬁes F −1(F(x)) = x for all
x in the domain of F and F(F −1(x)) = x for all x in the domain of F −1. For
example, A(x) = arctan(x) is the inverse of T(x) = tan(x) when the domain
of T is the interval (−π/2, π/2). Note that the domain of A is the target of
T while the target of A is the domain of T, so we could also write A = T −1
or T = A−1. As another example, the squaring function S(x) = x2 is not
one-to-one on all of R, but this function is one-to-one on the interval [0, ∞).
So if we regard S : [0, ∞) →[0, ∞), then its inverse is S−1(x) = √x with
S−1 : [0, ∞) →[0, ∞). We remark that the notation F −1 will always denote
the inverse of F. This notation will never mean 1/F(x).
Given a point y in the target of F, there are often several points in the
domain that are mapped to this point (there is only one if F is one-to-one).
The preimage of y is the set of all points x that satisfy F(x) = y. We denote
this set by F −1(y). Note the subtlety of notation here. The notation F −1
means the function that is the inverse of F. The notation F −1(y) is quite
diﬀerent: this is the set of preimages of y, and is deﬁned even if F is not one-
to-one. For example, the preimage of 0 under F(x) = x3 −x includes the three
points 0, 1, and −1. So F −1(0) = {0, ±1}. On the other hand, the preimage
of 6 under F consists of only the point 2. This is true since we may write
x3 −x −6 = (x −2)(x2 + 2x + 3),
and the roots of x2 + 2x + 3 are not real.
One of the most important notions involving functions is continuity. Often,
in introductory calculus courses, this notion is introduced somewhat infor-
mally. For example, a function F : R →R is sometimes said to be continuous

Functions
307
if one can draw its graph without lifting pen from paper. While this is an
illustrative notion for functions of a real variable, this deﬁnition is not suit-
able for the kinds of functions that we will study (particularly in Chapter 9).
Hence we need a more rigorous notion of continuity.
Deﬁnition. Let F : X →Y be a function. We say that F is continuous at x0
if
1.
F(x0) is deﬁned.
2.
limx→x0 F(x) = F(x0).
The function F is continuous if it is continuous at x0 for all x0 ∈X.
Example. The doubling function D: [0, 1) →[0, 1)
D(x) =

2x
0 ≤x < 1/2
2x −1
1/2 ≤x < 1
is not continuous at x = 1/2 since D(1/2) = 0, but the limit of D(x) as x
approaches 1/2 from the left is 1. However, D is continuous at all x ̸= 1/2 in
the domain.
Example. The function F(x) = 1/x is not continuous at 0 since F(0) is not
deﬁned. However, F is a continuous function on the domain 0 < |x| < ∞.
Deﬁnition. A function F is a homeomorphism if it has the following proper-
ties:
1.
F is one-to-one.
2.
F is onto.
3.
F is continuous.
4.
F −1 is also continuous.
If F is a homeomorphism, we say that the domain of F and its target
space are homeomorphic. For example, F(x) = x1/3 is a homeomorphism that
takes the reals to the reals with inverse F −1(x) = x3. The function A : R →
(−π/2, π/2) given by A(x) = arctan(x) is also a homeomorphism with inverse
T(x) = tan(x). This shows that the interval (−π/2, π/2) is homeomorphic to
the entire real line.

308
Mathematical Preliminaries
A.2
Some Ideas from Calculus
Most of the results in this book depend upon a solid knowledge of diﬀeren-
tial calculus in one variable. In Chapter 15, we will talk about derivatives of
complex functions, but these ideas will be introduced as needed.
Recall from calculus that the derivative of a function F at x0 is deﬁned by
F ′(x0) = lim
h→0
F(x0 + h) −F(x0)
h
or, equivalently,
F ′(x0) = lim
x→x0
F(x) −F(x0)
x −x0
.
A function is said to be diﬀerentiable at x0 if this limit exists. F is said to
be diﬀerentiable if it is diﬀerentiable at all x0 in the domain of F. Recall that
F ′(x0) gives the slope of the tangent line to the graph of F at (x0, F(x0)).
We will make use of the higher derivatives F ′′(x0) and F ′′′(x0) at various
points in this book. Thus we will tacitly assume that all derivatives of F exist,
unless otherwise noted. Such functions are called smooth or C∞. Occasionally,
we will introduce a nondiﬀerentiable or noncontinuous example, such as the
doubling function.
Example. The function F(x) = |x| is not diﬀerentiable at x0 = 0, since
lim
x→0+
F(x) −F(0)
x
= 1
lim
x→0−
F(x) −F(0)
x
= −1.
Also, G(x) = x1/3 is not diﬀerentiable at x = 0 since
lim
x→0
G(x) −G(0)
x
= ∞.
These examples represent two of the fundamental ways a function may fail to
be diﬀerentiable at a point.
One important fact from calculus is:
Diﬀerentiability ⇒Continuity. If F ′(x0) exists, then F is continuous at
x0.
Example. The doubling function D: [0, 1) →[0, 1) is not diﬀerentiable at
x = 1/2 since it is not continuous at this point. On the other hand, D′(x) = 2
for all x ∈[0, 1), x ̸= 1/2.
There are a number of other important theorems in calculus that we will
use, including the Intermediate Value Theorem and the Mean Value Theorem.
We will remind you of these results in Chapter 5 when we ﬁrst need them.

Open and Closed Sets
309
A.3
Open and Closed Sets
We will often consider functions deﬁned on closed or open intervals. A closed
interval is any interval of the form a ≤x ≤b, or [a, b] for short. According
to this deﬁnition, the single point {a} is a closed interval. Similarly, an open
interval is any interval of the form a < x < b, or (a, b) for short.
So that we don’t get into logical diﬃculties below, we will declare that
any semi-inﬁnite interval of the forms [a, ∞) or (−∞, a] are closed, while the
intervals (a, ∞) or (−∞, a) are open. This means that the entire real line is
to be regarded as both a closed and an open interval. In particular, the empty
set, the complement of the entire real line, is also both a closed and an open
interval, by deﬁnition.
Note that the intersection of two open intervals is another open interval.
Also, the intersection of two closed intervals is a closed interval. Even if either
of these intervals is empty, our convention above guarantees that these results
are true.
A subset X ⊂R is an open set if, for any point x ∈X, we can ﬁnd a small
open interval about x that lies entirely in X. A subset Y ∈R is said to be
closed if its complement in R is open. Remember that the complement of a
subset Y in R consists of all points in R that are not in Y . Subsets of R may
be neither open nor closed, as for example the interval (a, b].
One important fact about open and closed sets is the following. If A1 and
A2 are two open sets in R, then so too is A1 ∪A2, since about any point
in A1 ∪A2, we may always ﬁnd an open interval in either A1 or A2 so this
interval lies in A1 ∪A2. Similarly, A1 ∩A2 is also an open set. Likewise, if B1
and B2 are closed sets, then B1 ∩B2 and B1 ∪B2 are also closed. (This is
again why we need R and the empty set to be both closed and open.)
Instead of taking the union or intersection of two or, more generally, ﬁnitely
many open or closed sets, we will occasionally have to take unions or intersec-
tions of countably1 many intervals. Here things are slightly more complicated.
Countable Union Property. If Ai is an open set for i = 1, 2, . . . then
#∞
i=1 Ai is also an open set. If Bi is a closed set, then #∞
i=1 Bi need not be a
closed set.
In fact, the union of any collection of open sets is open, for if x lies in this
union, then x must lie in some Ai, and so there is an open interval about x
in Ai that thus lies in the union. The following example shows that countable
unions of closed set need not be closed. Let Bn = [ 1
n, 1] for n = 1, 2, . . . . Then
∞
!
n=1
Bn = (0, 1],
which is not closed.
1 A collection of sets is countable if it can be put in one-to-one correspondence with the
positive integers.

310
Mathematical Preliminaries
Countable Intersection Property. If Bi, i = 1, 2, . . ., are closed sets, then
$∞
i=1 Bi is closed. If Ai, i = 1, 2, . . ., are open sets, then $∞
i=1 Ai need not be
open.
Recall that the complement of a closed set is open, and note that the
complement of the intersection of countably many closed sets is the union
of countably many open sets. Since this union is open, it follows that the
intersection of countably many closed sets is closed. An example of the second
statement is provided by the open intervals An = (−1/n, 1/n). Note that
∞

n=1
An = {0},
which is a closed set.
Two closed intervals A and B are said to be nested if A ⊂B. Our next
observation in this section is:
Nested Intersection Property. Suppose Bi, i = 1, 2, . . . are closed,
nonempty intervals. Suppose B1 ⊃B2 ⊃. . . . Then $∞
i=1 Bi is nonempty.
The reason for this is simple. Let Bi = [li, ri]. Then our assumption is that
l1 ≤l2 ≤l3 ≤· · · ≤r3 ≤r2 ≤r1.
Let l = limi→∞and r = limi→∞ri. Clearly, l ≤r. Then the interval [l, r] lies
in the intersection of all of the Bi. Note that we may have l = r so, in that
case, we would have $∞
i=1 Bi = {l}, which is still nonempty.
We observe that if I is an open interval in R and F : R →R is continuous,
then F −1(I) is an open subset of R. To see why this is true, suppose that
F −1(I) contains an interval of the form [a, b], but that (b, c) does not lie in
F −1(I) for some c > b. Since F(b) lies in I and I is open, there is some
small interval surrounding F(b) that lies entirely in I. If F takes the interval
(b, c) outside of I, then F is necessarily discontinuous at b. This contradiction
establishes the result.
Arguing similarly using complements, it is easy to see that if I is a closed
interval, then F −1(I) is a closed subset of R if F : R →R is continuous.
Thus:
Preimage Property. Suppose F : R →R is continuous. If I is an open
interval in R, then F −1(I) is an open set. If I is a closed interval, then
F −1(I) is a closed set.
Another important notion is that of connectedness. A subset S of the real
line is connected if it has the property that whenever a, b ∈S and a ≤c ≤b,
then c is also in S. That is, if S contains any two points a and b, then S contains
all points in between. Equivalently, S is a single interval, which may be open,

Other Topological Concepts
311
closed or half-open, half-closed. In particular, our remarks after the Nested
Intersection Property show that the nested intersection of closed, connected
sets is also connected.
Connectedness Property. Suppose Bi, i = 1, 2, . . . are closed, nonempty
intervals. Suppose B1 ⊃B2 ⊃. . . . Then $∞
i=1 Bi is a connected set, in fact,
a closed interval.
We will also need to deal with closed and open subsets of the plane. A
subset S of the plane is open if, for each z0 ∈S, we may ﬁnd a small disk of
the form |z −z0| < ϵ that is entirely contained in S. A subset of the plane
is closed if its complement is open. By deﬁnition, the entire plane is both a
closed and an open set. For our purposes, we need only consider the notion of
closed, connected subsets of the plane. A closed set in the plane is said to be
connected if it cannot be written as the union of two disjoint closed subsets of
the plane. While we will not go into the proofs here, it is a fact that all ﬁve of
the above properties hold for closed and open subsets of the plane (replacing
the term closed or connected interval with closed or connected set).
A.4
Other Topological Concepts
In the chapters on fractals and complex dynamics, we encountered several
other topological concepts that are quite important. Here we go into more
detail about these concepts.
We often encountered dense sets earlier. A set X ⊂Y is said to be dense
in Y if, given any point y ∈Y , there are points in X arbitrarily close to y. For
example, the rationals are dense in the real line. So too are the irrationals.
But the set of integers is not dense in the real line, nor is the closed interval
[0, 1].
In Whyburn’s Theorem in the chapter on fractals, we encountered the term
“nowhere dense.” A subset X ⊂Y is said to be nowhere dense if the closure
of the set X has empty interior in Y , i.e., it never contains an open set.
Intuitively, a nowhere dense set is one whose points are not tightly clustered
together. For example, the integers form a nowhere dense subset of the real
line, but the set of rationals is not nowhere dense.
We also encountered the term locally connected in Whyburn’s Theorem.
A set X ⊂Y is said to be locally connected at x ∈X if, for every open set
V ⊂Y containing x, we can ﬁnd a smaller open set U ⊂V such that U ∩X is
a connected set. Then the set X is said to be locally connected if it is locally
connected for all x ∈X.
For example, recall the topologists’ sine curve from Chapter 14. This is
the graph of S(x) = sin(1/x) deﬁned over the interval (0, 2π] together with

312
Mathematical Preliminaries
the interval [−1, 1] on the y-axis. This set is locally connected at any point on
the graph of S, since we can always ﬁnd a small open neighborhood of this
point in the plane that meets the graph in a single open arc. But this set is
not locally connected at any point in the interval on the y-axis. Indeed, any
neighborhood of such a point, no matter how small, always meets the set in
inﬁnitely many disjoint arcs.

Bibliography
[1] Alexander, D. A History of Complex Dynamics. Springer Vieweg, 1994.
[2] Alexander, D., Iavernaro, F., and Rosa, A. Early Days in Complex
Dynamics: A History of Complex Dynamics During 1906-1942. Ameri-
can Math Society. 2012.
[3] Barnsley, M. Fractals Everywhere, Academic Press, 1988.
[4] Banks, J. et. al. On Devaney’s Deﬁnition of Chaos. Amer. Math.
Monthly. 99 (1992), 332-334.
[5] Blanchard, P., Devaney, R. L., and Hall, G. R. Diﬀerential Equations.
Cengage Learning, 2011.
[6] Branner, B. and Fagella, N. Quasiconformal Surgery in Holomorphic
Dynamics. Cambridge University Press, 2014.
[7] Branner, B. and Hubbard, J. The Iteration of Cubic Polynomials. Acta.
Math. 66 (1988), 143-206.
[8] Cayley, A. On the Newton-Fourier Imaginary Problem. Amer. J. Math
2(1879), 97.
[9] Curry, J. Garnett, L. and Sullivan, D. On the Iteration of a
Rational Function: Computer Experiments with Newton’s Method.
Comm. Math. Phys. 91 (1983), 267-277.
[10] Devaney, R. L. Introduction to Chaotic Dynamical Systems. CRC Press,
2003.
[11] Devaney, R. L. Singular Perturbations of Complex Polynomials. Bulletin
of the AMS 50 (2013), 391-429.
[12] Devaney, R. L. and Krych, M. Dynamics of Exp(z). Ergodic Theory and
Dynamical Systems 4 (1984), 35-52.
[13] Devaney, R. L., Look, D. M., and Uminsky, D. The Escape Trichotomy
for Singularly Perturbed Rational Maps. Indiana Univ. Math. J. 54
(2005), 1621-1634.
[14] Douady, A. and Hubbard, J. On the Dynamics of Polynomial-like Maps.
Ann. Scient. Ec. Norm. Sup. 18 (1985), 287.
313

314
Bibliography
[15] Devaney, Kiℓℓer. Dynamical Systems for Puppies. Advances in Puppy
Math 123 (2099), 1-8000.
[16] Douady, A. and Hubbard, J. On the Dynamics of Polynomial-like Maps.
Ann. Scient. Ec. Norm. Sup. 18 (1985), 287.
[17] Eremenko, A. and Lyubich, M. Iterates of Entire Functions. Soviet
Math. Dokl. 30 (1984), 592-594.
[18] Feigenbaum, M. Universality in Complex Discrete Dynamics. Los
Alamos Theoretical Division Annual Report 1975-76.
[19] Field, R. and Burger, M., eds. Oscillations and Traveling Waves in
Chemical Systems. Wiley, 1985.
[20] Goldberg, L. and Keen, L. A Finiteness Theorem for a Dynamical Class
of Entire Functions. Ergodic Theory and Dynamical Systems 6 (1986),
183-192.
[21] Guckenheimer, J. and Holmes, P. Nonlinear Oscillations, Dynamical
Systems, and Bifurcations of Vector Fields. Springer-Verlag, 1983.
[22] Hirsch, M. W., Smale, S., and Devaney, R. L. Diﬀerential Equations,
Dynamical Systems, and an Introduction to Chaos. Elsevier Academic
Press, 2013.
[23] Li, T.-Y. and Yorke, J. Period Three Implies Chaos. American Mathe-
matical Monthly 82 (1975), 985-982.
[24] Mandelbrot, B. The Fractal Geometry of Nature. W. H. Freeman, 1983.
[25] May, R. M. Theoretical Ecology: Principles and Applications. Blackwell,
1981.
[26] McMullen, C. Automorphisms of Rational Maps. In Holomorphic Func-
tions and Moduli. Springer, 1988, 31-60.
[27] McMullen, C. Complex Dynamics and Renormalization. Princeton Uni-
versity Press, 1995.
[28] Milnor, J. Dynamics in One Complex Variable. Princeton University
Press, 2006.
[29] Robinson, C. Dynamical Systems: Stability, Symbolic Dynamics, and
Chaos. CRC Press, 1995.
[30] Sharkovsky, O. M. Co-Existence of Cycles of a Continuous Mapping of
a Line onto Itself. Ukranian Math. Z. 16 (1964), 61-71.
[31] Smale, S. Diﬀeomorphisms with Many Periodic Points. In Diﬀerential
and Combinatorial Topology. Princeton University Press (1965), 63.

Bibliography
315
[32] Strogatz, S. Nonlinear Dynamics and Chaos. CRC Press, 2019.
[33] Whyburn, G. T. Topological Characterization of the Sierpinski Curve.
Fundamenta Math. 45 (1958), 320-324.


Index
aﬃne self-similar, 194
argument, 212
asymptotic orbit, 91
asymptotic value, 293
Attracting Fixed Point Theorem, 51,
222
attractor, 199
backward iteration algorithm, 248
Baire Category Theorem, 124
basin of attraction, 162
basin of attraction; immediate, 162
Bifkhoﬀ, G. D., 6
bifurcation, 62
period-doubling, 65, 69
saddle-node, 62, 66
tangent, 62, 66
bifurcation diagram, 68
boundary mapping principle, 223
bounded, 232
Cantor middle-thirds set, 85, 183
Cantor set, 3, 83
Cauchy’s Estimate, 246
chaos, 125
chaos game, 181
commutative diagram, 114
complex conjugate, 214
complex cosine, 298
complex exponential, 292
complex sine, 298
component, 238
conjugacy, 115
Conjugacy Theorem, 115
conjugate, 115
continuous function, 112
critical circle, 287
critical point, 92
cubic polynomial, 281
cycle, 27
degree-d bifurcation sets, 270
dense set, 121
Density Proposition, 126
diﬀerence equation, 18
Douady’s rabbit, 2
Douady, Adrien, 2
doubling function, 31
doubling map, 131
dynamical system, 17
Escape criterion, 235
escape trichotomy, 285
Euler’s Formula, 291
eventually ﬁxed, 29
eventually periodic, 29
Fatou, Pierre, 6
Feigenbaum’s constant, 134
ﬁlled Julia set, 233
ﬁrst return map, 23
ﬁxed point, 27
attracting, 48, 222
indiﬀerent, 48
neutral, 48, 222
repelling, 48, 222
weakly attracting, 55
weakly repelling, 55
Fixed Point Theorem, 45
fractal, 183
fractal dimension, 195
fundamental dichotomy, 251
graphical analysis, 37
homeomorphic, 113
homeomorphism, 113
317

318
Index
Intermediate Value Theorem, 45
iterated function system, 198
iteration, 2, 25
iterative process, 17
itinerary, 106
Jacobi’s Theorem, 219
Julia set, 2, 233
Julia, Gaston, 2, 6
Kiℓℓer Devaney, 314
Knaster continuum, 188
Koch curve, 190
Koch snowﬂake, 190
Li, T.-Y., 6
linear contraction, 198
logistic function, 20
logistic model, 19
Lorenz, E. N., 6
main cardioid, 256
Mandelbrot set, 3, 254
Mandelbrot, Benoit, 3
McMullen domain, 289
Mean value theorem, 51
metric, 109
metric space, 109
Misiurewicz point, 269
modulus, 211
multiplicity, 171
Newton iteration function, 22, 170
Newton’s method, 22, 169
orbit, 26, 181
orbit analysis, 41
orbit diagram, 91
parameters, 25, 61
period-q bifurcation, 261
period-2 bulb, 256
Period-3 Theorem, 139
period-3 window, 92
period-doubling bifurcation, 260
periodic orbit, 27
phase portrait, 41
Poincaré, Henri, 5
pole, 283, 284
prime period, 27
Proximity Theorem, 110
renormalization, 97
Repelling Fixed Point Theorem, 53,
223
Riemann sphere, 284
saddle-node bifurcation, 258
Schwarzian derivative, 159
Schwarzian Min-Max Principle, 161
seed, 26
self-similar, 183
semiconjugacy, 131
sensitive dependence, 6, 124
sequence space, 106
Sharkovsky ordering, 143
Sharkovsky’s Theorem, 143
Sharkovsky, Oleksandr, 6
shift map, 111
Sierpinski carpet, 186
Sierpinski curve, 4, 285, 288
Sierpinski triangle, 182, 184
singular perturbation, 283
Smale, Stephen, 6
subshift of ﬁnite type, 154
superattracting, 176
supersensitive, 233
superstable, 135, 147
surface of section, 23
symbolic dynamics, 105
tent map, 35
ternary expansion, 87
topological dimension, 193
topologists’ sine curve, 188
totally disconnected, 85
transitive, 123
trap door, 285
triangle inequality, 109, 213
unbounded, 232
uncountable set, 85
universal plane continuum, 188
Whyburn’s Theorem, 188
Yorke, James, 6

