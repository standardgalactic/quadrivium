
Media Theory
First edition

David Eppstein · Jean-Claude Falmagne
Sergei Ovchinnikov
Media Theory
Interdisciplinary Applied Mathematics
First edition
123

David Eppstein
University of California, Irvine
Department of Computer Science
Irvine, 92697-3425
USA
eppstein@ics.uci.edu
Jean-Claude Falmagne
University of California, Irvine
School of Social Sciences
Department of Cognitive Sciences
Social Science Plaza A 3171
Irvine, 92697-5100
USA
jcf@uci.edu
Sergei Ovchinnikov
San Francisco State University
Deptartment of Mathematics
Holloway Avenue 1600
San Francisco, 94132
USA
sergei@sfsu.edu
ISBN 978-3-540-71696-9
e-ISBN 978-3-540-71697-6
DOI 10.1007/978-3-540-71697-6
Library of Congress Control Number: 2007936368
© 2008 Springer-Verlag Berlin Heidelberg
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microﬁlm or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9,
1965, in its current version, and permission for use must always be obtained from Springer. Violations
are liable to prosecution under the German Copyright Law.
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply,
even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws
and regulations and therefore free for general use.
Cover Design: KünkelLopka, Heidelberg
Printed on acid-free paper
9 8 7 6 5 4 3 2 1
springer.com

Preface
The focus of this book is a mathematical structure modeling a physical or
biological system that can be in any of a number of ‘states.’ Each state is
characterized by a set of binary features, and diﬀers from some other neigh-
bor state or states by just one of those features. In some situations, what
distinguishes a state S from a neighbor state T is that S has a particular fea-
ture that T does not have. A familiar example is a partial solution of a jigsaw
puzzle, with adjoining pieces. Such a state can be transformed into another
state, that is, another partial solution or the ﬁnal solution, just by adding
a single adjoining piece. This is the ﬁrst example discussed in Chapter 1. In
other situations, the diﬀerence between a state S and a neighbor state T may
reside in their location in a space, as in our second example, in which in which
S and T are regions located on diﬀerent sides of some common border.
We formalize the mathematical structure as a semigroup of ‘messages’
transforming states into other states. Each of these messages is produced by
the concatenation of elementary transformations called ‘tokens (of informa-
tion).’ The structure is speciﬁed by two constraining axioms. One states that
any state can be produced from any other state by an appropriate kind of
message. The other axiom guarantees that such a production of states from
other states satisﬁes a consistency requirement.
What motivates our interest in this semigroup is, ﬁrst, that it provides
an algebraic formulation for mathematical systems researched elsewhere and
earlier by other means. A prominent example is the ‘isometric subgraph of
a hypercube’ (see Djokovi´c, 1973, for an early reference), that is, a subraph
in which the distance between vertices is identical to that in the parent hy-
percube. But there are many other cases. We shall outline some of them in
our ﬁrst chapter, reserving in depth treatment for later parts of this book.
Until recently, however, no common algebraic axiomatization of these out-
wardly diﬀerent concepts had been proposed. Our purpose is to give here
the ﬁrst comprehensive treatment of such a structure, which we refer to as a
‘medium.’
A second, equally importantly reason for studying media, is that they
oﬀer a highly convenient representation for a vast class of empirical situations
ranging from cognitive structures in education to the study of opinion polls
in political sciences and including, conceivably, genetics, to name just a few
pointers. They provide an appropriate medium1 where the temporal evolution
of a system can take place. Indeed, it turns out that, for some applications,
the set of states of a medium can be proﬁtably cast as the set of states of a
random walk. Moreover, under simple hypotheses concerning the stochastic
process involved, the asymptotic probabilities of the states are easy to compute
and simple to write. Accordingly, some space is devoted to the development
1 There lies the origin of the term.

VI
Preface
of a random walk on the set of states of a medium, and to the description of
a substantial application to the analysis of an opinion poll.
In this monograph, we study media from various angles: algebraic in Chap-
ters 2, 3, and 4; combinatoric in Chapters 5 and 6; geometric in Chapters 7
to 9; algorithmic in Chapters 10 and 11. Chapters 12 and 13 are devoted to
random walks on media and to applications.
Through the book, each chapter is organized into sections containing para-
graphs, which often bear titles such as Deﬁnition, Example, or Theorem.
For simplicity of reference and to facilitate a search through the book, a single
numerical system is used. For instance:
2.4.12 Lemma.
2.4.13 Deﬁnition.
are the titles of the twelfth and the thirteenth paragraphs of Chapter 2, Section
2.4. We refer to the above lemma as “Lemma 2.4.12.”
Deﬁned technical terms are typed in slanted font just once, at the place
where they are deﬁned, which is typically within a “Deﬁnition” paragraph.
Technical terms used before their deﬁnition are put between single quotes
(at the ﬁrst mention). The text of theorems and other results are also set in
slanted font.
A short history of the results leading to the concept of a medium and
ultimately to this monograph can be found in Section 1.9.
In the course of our work, we beneﬁtted from exchanges with many re-
searchers, whose reactions to our ideas inﬂuenced our writing, sometimes sub-
stantially. We want to thank, in particular, Josiah Carlson, Dan Cavagnaro,
Victor Chepoi, Eric Cosyn, Chris Doble, Aleks Dukhovny, Peter Fishburn,
Bernie Grofman, Yung-Fong Hsu, GeoﬀIverson, Duncan Luce, Louis Narens,
Michel Regenwetter, Fred Roberts, Pat Suppes, Nicolas Thi´ery, and Hasan
Uzun.
A special mention must be made of Jean-Paul Doignon, whose joint work
with Falmagne provided much of the foundational ideas behind the concept of
a medium. For a long time, we thought that Jean-Paul would be a co-author.
However, other commitments prevented him to be one of us. No doubt, had
he been a co-author, our book would have been a better one.
Last but not least, Diana, Dina, and Galina deserve much credit for var-
iously letting us be—the relevant one, that is—whenever it seemed that the
call of the media was too strong, or for gently drawing us away from them,
for our own good sake, when there was an opening. To those three, we are the
most grateful.
David Eppstein
Jean-Claude Falmagne
Sergei Ovchinnikov
August 11, 2007

Contents
1
Examples and Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
A Jigsaw Puzzle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
A Geometrical Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.3
The Set of Linear Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.4
The Set of Partial Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.5
An Isometric Subgraph of Zn . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.6
Learning Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.7
A Genetic Mutations Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.8
Notation and Conventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.9
Historical Note and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2
Basic Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.1
Token Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.2
Axioms for a Medium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.3
Preparatory Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.4
Content Families . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.5
The Eﬀective Set and the Producing Set of a State . . . . . . . . . . 30
2.6
Orderly and Regular Returns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.7
Embeddings, Isomorphisms and Submedia . . . . . . . . . . . . . . . . . . 34
2.8
Oriented Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.9
The Root of an Oriented Medium . . . . . . . . . . . . . . . . . . . . . . . . . 38
2.10 An Inﬁnite Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
2.11 Projections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
3
Media and Well-graded Families . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.1
Wellgradedness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.2
The Grading Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

VIII
Contents
3.3
Wellgradedness and Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
3.4
Cluster Partitions and Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
3.5
An Application to Clustered Linear Orders . . . . . . . . . . . . . . . . . 62
3.6
A General Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
4
Closed Media and ∪-Closed Families . . . . . . . . . . . . . . . . . . . . . . . 73
4.1
Closed Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
4.2
Learning Spaces and Closed Media . . . . . . . . . . . . . . . . . . . . . . . . 78
4.3
Complete Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
4.4
Summarizing a Closed Medium . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4.5
∪-Closed Families and their Bases . . . . . . . . . . . . . . . . . . . . . . . . . 86
4.6
Projection of a Closed Medium . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
5
Well-Graded Families of Relations . . . . . . . . . . . . . . . . . . . . . . . . . 101
5.1
Preparatory Material . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
5.2
Wellgradedness and the Fringes . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
5.3
Partial Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
5.4
Biorders and Interval Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5.5
Semiorders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
5.6
Almost Connected Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
6
Mediatic Graphs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
6.1
The Graph of a Medium. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
6.2
Media Inducing Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
6.3
Paired Isomorphisms of Media and Graphs . . . . . . . . . . . . . . . . . 130
6.4
From Mediatic Graphs to Media . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
7
Media and Partial Cubes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
7.1
Partial Cubes and Mediatic Graphs . . . . . . . . . . . . . . . . . . . . . . . . 139
7.2
Characterizing Partial Cubes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
7.3
Semicubes of Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
7.4
Projections of Partial Cubes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
7.5
Uniqueness of Media Representations . . . . . . . . . . . . . . . . . . . . . . 154
7.6
The Isometric Dimension of a Partial Cube . . . . . . . . . . . . . . . . . 158
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159

Contents
IX
8
Media and Integer Lattices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
8.1
Integer Lattices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
8.2
Deﬁning Lattice Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
8.3
Lattice Dimension of Finite Partial Cubes . . . . . . . . . . . . . . . . . . 167
8.4
Lattice Dimension of Inﬁnite Partial Cubes . . . . . . . . . . . . . . . . . 171
8.5
Oriented Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
9
Hyperplane arrangements and their media . . . . . . . . . . . . . . . . . 177
9.1
Hyperplane Arrangements and Their Media . . . . . . . . . . . . . . . . . 177
9.2
The Lattice Dimension of an Arrangement . . . . . . . . . . . . . . . . . . 184
9.3
Labeled Interval Orders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
9.4
Weak Orders and Cubical Complexes . . . . . . . . . . . . . . . . . . . . . . 188
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
10
Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
10.1 Comparison of Size Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
10.2 Input Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
10.3 Finding Concise Messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
10.4 Recognizing Media and Partial Cubes . . . . . . . . . . . . . . . . . . . . . . 217
10.5 Recognizing Closed Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
10.6 Black Box Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
11
Visualization of Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
11.1 Lattice Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
11.2 Drawing High-Dimensional Lattice Graphs. . . . . . . . . . . . . . . . . . 231
11.3 Region Graphs of Line Arrangements . . . . . . . . . . . . . . . . . . . . . . 234
11.4 Pseudoline Arrangements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
11.5 Finding Zonotopal Tilings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246
11.6 Learning Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
12
Random Walks on Media . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
12.1 On Regular Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
12.2 Discrete and Continuous Stochastic Processes . . . . . . . . . . . . . . . 271
12.3 Continuous Random Walks on a Medium . . . . . . . . . . . . . . . . . . . 273
12.4 Asymptotic Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
12.5 Random Walks and Hyperplane Arrangements . . . . . . . . . . . . . . 280
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282

X
Contents
13
Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
13.1 Building a Learning Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
13.2 The Entailment Relation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
13.3 Assessing Knowledge in a Learning Space . . . . . . . . . . . . . . . . . . . 293
13.4 The Stochastic Analysis of Opinion Polls . . . . . . . . . . . . . . . . . . . 297
13.5 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
Appendix: A Catalog of Small Mediatic Graphs . . . . . . . . . . . . . . . 305
Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321

1
Examples and Preliminaries
We begin with an example from everyday life, which will serve as a vehicle
for an informal introduction to the main concepts of media theory. Several
other examples follow, chosen for the sake of diversity, after which we brieﬂy
review some standard mathematical concepts and notation. The chapter ends
with a short historical notice and the related bibliography. Our purpose here
is to motivate the developments and to build up the reader’s intuition, in
preparation for the more technical material to follow.
1.1 A Jigsaw Puzzle
1.1.1 Gauss in Old Age. Figure 1.1(a) shows a familiar type of jigsaw puz-
zle, made from a portrait of Carl Friedrich Gauss in his old age. We call a
state of this puzzle any partial solution, formed by a linked subset of the
puzzle pieces in their correct positions. Four such states are displayed in Fig-
ure 1.1(a), (b), (c) and (d). Thus, the completed puzzle is a state. We also
regard as states the initial situation (the empty board), and any single piece
appropriately placed on the board. A careful count gives us 41 states (see
Figure 1.1.2). To each of the six pieces of the puzzle correspond exactly two
transformations which consist in placing or removing a piece. In the ﬁrst case,
a piece is placed either on an empty board, or so that it can be linked to some
pieces already on the board. In the second case, the piece is already on the
board and removing it either leaves the board empty or does not disconnect
the remaining pieces. By convention, these two types of transformations apply
artiﬁcially to all the states in the sense that placing a piece already on the
board or removing a piece that is not on the board leaves the state unchanged.
This is our ﬁrst example of a ‘medium’, a concept based on a pair (S, T)
of sets: a set S states, and a collection T of transformations capable, in some
cases, of converting a state into a diﬀerent one. The formal deﬁnition of such
a structure relies on two constraining axioms (see Deﬁnition 2.2.1).

2
1 Examples and Preliminaries
(a)                                                                                      (b)
(c)                                                                                     (d)
(a)                                                                                      (b)
(c)                                                                                     (d)
(a)                                                                                      (b)
Figure 1.1. Four states of a medium represented by the jigsaw puzzle: Carl Friedrich
Gauss in old age. The full medium contains 41 states (see Figure 1.2).
By design, none of these transformations is one-to-one. For instance, ap-
plying the transformation “adding the upper left piece of the puzzle”—the left
part of Gauss’s hat and forehead—to either of the states pictured in Figure
1.1(c) or (d) results in the same state, namely (a). In the ﬁrst case, we have
thus a loop. Accordingly, the two transformations associated with each piece
are not mutual inverses. However, each of the transformations in a pair can
undo the action of the other. We shall say that these transformations are ‘re-
verses’ of one another. For a formal deﬁnition of ‘reverse’ in the general case,
see 2.1.1.

1.1 A Jigsaw Puzzle
3
1.1.2 The Graph of Gauss’s Puzzle. When the number of states is ﬁnite,
it may be convenient to represent a medium by its graph and we shall often
do so. The medium of Gauss’s puzzle has its graph represented in Figure 1.2
below. As usual, we omit loops.
1
2
3
4
5
6
0/
1
2
3
4
5
6
12
13
24
34
35
46
56
123
124
134
135
234
345
246
346
456
356
1234
1246
1235
1345
1356
2456
1346
2345
2346
3456
12456
12356
12346
12345
23456
13456
123456
6
5
2
1
5
4
1
2
3
1
5
2
4
3
6
3
6
4
1
2
3
4
5
6
1
2
3
4
5
6
5
2
1
6
2
5
Figure 1.2. Graph of the Gauss puzzle medium. A schematic of the puzzle is a
the upper right of the graph, with the six pieces numbered 1,. . . , 6. Each of the 41
vertices of the graph represent one state of the medium, that is, one partial solution
of the puzzle symbolized by a rectangle containing the list of its pieces. Each edge
represents a pair of mutually reverse transformations, one adding a piece, and the
other removing it. To avoid cluttering the ﬁgure, only some of the edges are labeled
(by a circle).
An examination of this graph leads to further insight. For any two states
S and T, it is possible to ﬁnd a sequence of transformations whose successive
applications from S results in forming T. This ‘path’ from S to T never strays
from the allowed set of states, and can be made minimally short, that is:
its length is equal to the number of pieces which are not common to both
states. Moreover, any two such paths from S to T will involve exactly the

4
1 Examples and Preliminaries
same transformations, but they may be applied in diﬀerent orders1. As an
illustration, we have marked in Figure 1.2 two such paths from state 34 to
the completed puzzle by coloring their edges in red and blue, respectively.
These two paths are
34
1
−→134
5
−→1345
2
−→12345
6
−→123456
(1.1)
34
6
−→346
2
−→2346
5
−→23456
1
−→123456 .
(1.2)
A medium could be deﬁned from any (standard) jigsaw puzzle according to
the rules laid out here2. Such media have the remarkable property that their
set of transformations is naturally partioned into two classes of equal sizes,
namely, one corresponding to the addition of the pieces to the puzzle, and the
other one to their removal. In view of this asymmetry which also arises in other
situations, we shall talk about ‘orientation’ to describe such a bipartition (see
Deﬁnition 2.8.1). Thus, in medium terminology, a transformation is in a given
class if and only if its reverse belongs to the other class. There are important
cases, however, in which no such natural orientation exists. Accordingly, this
concept is not an integral part of the deﬁnition of a medium (cf. 2.2.1).
In fact, the next two examples involve media in which no natural orienta-
tion of the set of transformations suggests itself.
1.2 A Geometrical Example
1.2.1 An Arrangement of Hyperplanes. Let A be some ﬁnite collection
of hyperplanes in Rn. Then Rn \ (∪A) is the union of the open, convex poly-
hedral regions bounded by the hyperplanes, some (or all) of which may be
unbounded. We regard each polyhedral region as a state, and we denote by
P the ﬁnite collection of all the states. From one state P in P, it is always
possible to move to another adjacent state by crossing some hyperplane in-
cluding a facet of P. (We suppose that a single hyperplane is crossed at one
time.) We formalize these crossings in terms of transformations of the states.
To every hyperplane H in A corresponds the two ordered pairs (H−, H+) and
(H+, H−) of the two open half spaces H−and H+ separated by the hyper-
plane. These ordered pairs generate two transformations τ +
H and τ −
H of the
states, where τ +
H transforms a state to an adjacent state in H+, if possible,
and leaves it unchanged otherwise, while τ −
H transforms a state to an adjacent
state in H−, if possible, and leaves it unchanged otherwise. More formally, ap-
plying τ +
H to some state P results in some other state Q if P ⊆H−, Q ⊆H+,
1 In this particular case, the two paths represented in (1.1) and (1.2) have their
transformations in the exact opposite order, but not all pairs of diﬀerent paths
are reversed in this way (Problem 1.1).
2 In the case of larger puzzles (for instance, 3×3), there might be states with holes:
all the pieces are interconnected but there are pieces missing in the middle.

1.2 A Geometrical Example
5
and the polyhedral regions P and Q share a facet which is included in the
hyperplane separating H−and H+; otherwise, the application of τ +
H to P
does not change P. The transformation τ −
H is deﬁned symmetrically. Clearly,
the application of τ +
H cancels the action of τ −
H whenever the latter was eﬀec-
tive in modifying the state. However, as in the preceding example, τ +
H and τ −
H
are not mutual inverses. We say in such a case that τ +
H and τ −
H are mutual
reverses. Denoting by T the set of all such transformations, we obtain a pair
(P, T) which is another example of a medium. A case of ﬁve straight lines in
R2 deﬁning ﬁfteen states and ten pairs of mutually reverse transformations is
pictured in Figure 1.3. The proof that, in the general case, an arbitrary locally
ﬁnite hyperplane arrangement deﬁnes a medium is due to Ovchinnikov (2006)
(see Theorem 9.1.8 in Chapter 9 here).
S
T
l
h
i
j
k
Figure 1.3. A line arrangement in the case of ﬁve straight lines in R2 delimiting
ﬁfteen states with ten pairs of transformations. Two direct paths from state S to
state T cross the same lines in two diﬀerent orders: lihjk and ikjhl.

6
1 Examples and Preliminaries
1.3 The Set of Linear Orders
In this example, each of the 24 = 4! linear orders on the set {1, 2, 3, 4} is
regarded as a state. A transformation consists of transposing two adjacent
numbers: the transformation τij replaces an adjacent pair ji by the pair ij, or
does nothing if ji does not form an adjacent pair in the initial state. There are
thus 6 =
4
2

pairs of transformations τij, τji. Three of these transformations
are ‘eﬀective’ for the state 3142, namely:
3142
τ13
−→1342
3142
τ41
−→3412
3142
τ24
−→3124 .
As in the preceding example, no natural orientation arises here.
1.3.1 The Permutohedron. The graph of the medium of linear orders on
{1, 2, 3, 4} is displayed in Figure 1.4. Such a graph is sometimes referred to as
a permutohedron (cf. Bowman, 1972; Gaiha and Gupta, 1977; Le Conte de
Poly-Barbut, 1990). Again, we omit loops, as we shall always do in the sequel.
The edges of this polyhedron can be gathered into six families of parallel edges;
the edges in each family correspond to the same pair of transformations.
3214
4213
1234
3241
1243
1324
1432
1423
1342
2134
2143
2413
2431
2341
2314
3421
3412
3142
3124
4123
4231
4132
4312
4321
Figure 1.4. Permutohedron of {1, 2, 3, 4}. Graph of the medium of the set of linear
orders on {1, 2, 3, 4}.

1.4 The Set of Partial Orders
7
1.3.2 Remark. The family L of all linear orders on a particular ﬁnite set is
characteristically associated with the group of permutations on that family.
However, as illustrated by the graph of Figure 1.4, in which each set of parallel
edges represents a particular the pair of mutually reverse transpositions of two
adjacent objects, the concept of a medium is just as compelling as an algebraic
structure canonically associated to L.
1.4 The Set of Partial Orders
Consider an arbitrary ﬁnite set S. The family P of all strict partial orders
(asymmetric, transitive, cf. 1.8.3, p. 14) on S enjoys a remarkable property:
any partial order P can be linked to any other partial order P ′ by a sequence
of steps each of which consists of changing the order either by adding one
ordered pair of elements of S (imposing an ordering between two previously-
incomparable elements) or by removing one ordered pair (causing two pre-
viously related elements to become incomparable), without ever leaving the
family P. Moreover, this can always be achieved in the minimal number of
steps, which is equal to the ‘symmetric diﬀerence’ between P and P ′ (cf. Def-
inition 1.8.1; see Bogart and Trotter, 1973; Doignon and Falmagne, 1997, and
Chapter 5). To cast this example as a medium, we consider each partial order
as a state, with the transformations consisting in the addition or removal of
some pair. This medium is thus equipped with a natural orientation, as in the
case of the jigsaw puzzle of 1.1.1.
The graph of such a medium is displayed in Figure 1.5 for the family of
all partial orders on the set {a, b, c}. Only the edges corresponding to the
transformation P →P +{ba} are indicated. (Note that we sometimes use ‘+’
to denote disjoint union; cf. 1.8.1.) Certain oriented media satisfy an important
property: they are ‘closed’ with respect to their orientation. This property is
conspicuous in the graph of Figure 1.5: if P, P +{xy} and P +{zw} are three
partial orders on {a, b, c}, then P + {xy} + {zw} is also such a partial order
(however, see Problem 1.9).
This medium also satisﬁes the parallelism property observed in the per-
mutohedron example: each set of parallel edges represents the same pair of
mutually reverse transformations of adjacent objects. This property of certain
media is explored in Deﬁnition 2.6.4 and Theorem 2.6.5.
Chapter 5 contains a discussion of this and related examples of families
of relations, such as ‘biorders’ and ‘semiorders’ from the standpoint of media
theory. (For the partial order example, see in particular Deﬁnition 1.8.3 and
Theorem 5.3.5.).

8
1 Examples and Preliminaries
a
b
c
b
a
c
a
c
b
c
a
b
c
b
a
b
c
a
a   c
b   c
a  b  c
a   b
b   c
a
a
a
c
a
b
b
c
a   c
b
c
b
a
b
c
b
c
a
b
c
b
a
a   b
c
c
a
ba
ba
ba
ba
ba
Figure 1.5. Graph of the medium of the set of all partial orders on {a, b, c}. The
orientation of the edges represents the addition of a pair to a partial order. Only
one class of edges is labelled, corresponding to the addition of the pair ba (see 1.8.2
for this notation).
1.5 An Isometric Subgraph of Zn
Perhaps the most revealing geometric representation of a ﬁnite oriented
medium is as an isometric subgraph of the n-dimensional integer lattice Zn,
for n minimal. By ‘isometric’ we mean that the distance between vertices in
the subgraph is the same as that in Zn. Such a representation is always possi-
ble (cf. Theorems 3.3.4, 7.1.4, and 8.2.2), and algorithms are available for the
construction (see Chapter 10).

1.5 An Isometric Subgraph of Zn
9
Let M be a ﬁnite oriented medium and let G ⊂Zn be its representing
subgraph. Each state of the medium M is represented by a vertex of G, and
each pair (τ, ˜τ) of mutually reverse transformations is associated with a hy-
perplane H orthogonal to one of the coordinate axes of Zn, say qj. Suppose
that H intersects qj at the point (i1, . . . , ij, . . . , in). Let us identify M with G
(thus, we set M = G). The restriction of the transformation τ to H ∩G is a
1-1 function from H ∩G onto H′ ∩G, where H′ is a hyperplane parallel to H
and intersecting qj at the point (i1, . . . , ij + 1, . . . , in). Thus, τ moves H ∩G
one unit upward. The restriction of τ to G \ H is the identity function on that
set. The reverse transformation ˜τ moves H′ ∩G one unit downward, and is
the identity on G \ H′.
c
c
c
c
c
c
c
d
d
d
e
e
e
a
a
f
b
b
b
h
h
f
A
A‘
B
B‘
D
D‘
1
2
3
g
g
g
g
g
g
g
g
F
c
Figure 1.6. An isometric subgraph D of Z3. The orientation of the induced medium
corresponds to the natural order of the integers and is indicated by the three arrows.
To avoid cluttering the graph, the labeling of some edges is omitted.
The oriented graph D of Figure 1.6, representing a medium with 23 states
and 8 pairs of mutually reverse transformations is a special case of this sit-
uation. The arrows labeled 1, 2 and 3 indicate the orientations of the axes
q1, q2 and q3 of Z3. The plane <A, B, D> deﬁned by the vertices A, B and
D is orthogonal to q1. The 8 edges marked c correspond to the pair of trans-
formations (τc, ˜τc). The transformation τc moves <A, B, D> ∩D one unit to
the right upward, that is, onto <A′, B′, D′> ∩D, and is represented by loops
elsewhere. The transformation ˜τc is the reverse of τc.
The medium represented by D is not closed: the two transformations τf
and τc transform D′ into F and B′, respectively. But applying τc to F gives a
loop, and so does the application of τf to B′. Note that the subgraph D is not
the unique representation of the medium M in Z3. A counter clockwise rota-

10
1 Examples and Preliminaries
tion could render the four edges marked a or b parallel to the third coordinate
axis without altering the accuracy of the representation. However, because the
graph is oriented we cannot apply a similar treatment to two edges marked f.
The last two examples of this chapter deal with empirical applications3.
In both of these cases, the medium is equipped with a natural orientation.
1.6 Learning Spaces
1.6.1 Deﬁnition. Doignon and Falmagne (1999) formalize the concept of a
knowledge structure (with respect to a topic) as a family K of subsets of a
basic set Q of items4 of knowledge. Each of the sets in K is a (knowledge)
state, representing the competence of a particular individual in the population
of reference. It is assumed that ∅, Q ∈K. Two compelling learning axioms
are:
[K1] If K ⊂L are two states, with |L \ K| = n, then there is a chain of
states
K0 = K ⊂K1 ⊂· · · ⊂Kn = L
such that Ki = Ki−1 + {qi} with qi ∈Q for 1 ≤i ≤n. (We use ‘+’
to denote disjoint union.) In words, intuitively: If the state K of the
learner is included in some other state L then the learner can reach
state L by learning one item at a time.
[K2] If K ⊂L are two states, with K∪{q} ∈K and q /∈L, then L∪{q} ∈K.
In words: If item q is learnable from state K, then it is also learnable
from any state L that can be reached from K by learning more items.
A knowledge structure K satisfying Axioms [K1] and [K2] is called a learn-
ing space (cf. Cosyn and Uzun, 2005). To cast a learning space as a medium,
we take any knowledge state to be a state of the medium. The transforma-
tions consist in adding (or removing) an item q ∈Q to (from) a state; thus,
they take the form of the two functions: τq : K →K : K →K + {q} and
˜τq : K →K : K →K \{q}. This results in a ‘closed rooted medium’ (see Def-
inition 4.1.2, and Theorem 4.2.2). The study of media is thus instrumental in
our understanding of learning spaces as deﬁned by [K1] and [K2]. Note that a
learning space is known in the combinatorics literature as an ‘antimatroid’, a
structure introduced by Dilworth (1940) (cf. also Edelman and Jamison, 1985;
Korte et al., 1991; Welsh, 1995; Bj¨orner et al., 1999). An empirical application
of these concepts in the schools is reviewed in Section 13.1.
3 In particular, learning spaces provide the theoretical foundation for a widely used
internet based system for the assessment of mathematical knowledge.
4 In a scholarly context, an ‘item’ might be a type of problem to be solved, such as
‘long division’ in arithmetic.

1.7 A Genetic Mutations Scheme
11
1.7 A Genetic Mutations Scheme
The last example of this chapter is artiﬁcial. The states of the medium are lin-
ear arrangements of genes on a small portion of a chromosome5. We consider
four pairs of transformations, corresponding to mutations producing chromo-
somal aberrations observed, for example in the Drosophila melanogaster (cf.
Villee, 1967). We take the normal state to be the sequence A-B-C, where A,
B and C are three genetic segments. The four mutations are listed below.
Table 1.1. Normal state and four types of mutations
Genetic arrangements
Names
A-B-C
normal state
A-B
deletion of segment C
A-B-C-C
duplication of segment C
A-B-C-X
translocationa of segment X
B-A-C
inversion of segment AB
a From another chromosome.
1.7.1 Mutation Rules. These mutations occur in succession, starting from
the normal state A-B-C, according to the ﬁve following (ﬁctitious) rules:
[IN] The segment A-B can be inverted whenever C is not duplicated.
[TR] The translocation of the segment X can only occur in the case of a
two segment (abnormal) state.
[DE] A single segment C can always be deleted (from any state).
[DU] The segment C can be duplicated (only) in the normal state.
[RE] All the reverses of these four mutations exist, but no other mutations
are permitted.
The resulting graph in Figure 1.7 is the graph of a medium if we admit
the possibility of reverse mutations in all cases. If such reverse mutations are
rare, one can assume, in the framework of the random walk process described
in Chapter 12, that some or all the reverse mutations occur with a very low
positive probability.
5 This example is inspired by biogenetic theory but cannot be claimed to be fully
faithful to it. Our goal here is only to suggest potential applications.

12
1 Examples and Preliminaries
du
i
i
de
de
i
t
t
A-B-C-C
A-B-C
B-A-C
A-B
B-A
A-B-X
B-A-X
Figure 1.7. Oriented graph of the medium induced by the four mutations listed
in Table 1.1, according to the ﬁve rules of 1.7.1. In the labelling of the edges, i,
du, de and t stand for ‘inversion of A-B’, ‘duplication of C’, ‘deletion of C’ and
‘translocation of X’, respectively.
1.8 Notation and Conventions
We brieﬂy review the primary mathematical notations and conventions em-
ployed throughout this book. A glossary of notation is given on page 309.
1.8.1 Set Theory. Standard logical and set theoretical notation is used
throughout. We write ⇔, as usual, for logical equivalence and ⇒for impli-
cation. The notation ⊆stands for the inclusion of sets, and ⊂for the proper
(or strict) inclusion. We sometimes denote the union of disjoint sets by + or
by the summation sign . The union of all the sets in a family F of subsets
is symbolized by
∪F = {x x ∈Y for some Y ∈F},
(1.3)
and the intersection of all those sets by
∩F = {x x ∈Y for all Y ∈F}.
(1.4)
Deﬁned terms and statement of results are set in slanted font. The comple-
ment of a set Y with respect to some ﬁxed ground set X including Y is the
set Y = X \ Y .
The set of all the subsets, or power set, of a set Z is denoted by P(Z).
From (1.3) and (1.4), we get ∪P(Z) = Z and ∩P(Z) = ∅(because ∅∈P(Z)).
Note that we also write Pf(Z) for the set of all ﬁnite subsets of Z.
The size (or cardinality, or cardinal number) of a set X is written as |X|.
Two sets having the same cardinal numbers are said to be equipollent. The
symmetric diﬀerence of two sets X and Y is the set
X △Y = (X \ Y ) ∪(Y \ X).

1.8 Notation and Conventions
13
The symmetric diﬀerence distance of two sets X and Y is deﬁned by
d(X, Y ) = |X △Y |.
(1.5)
If Z is ﬁnite and the function d is deﬁned by (1.5) for all X, Y ∈P(Z), then
(P(Z), d) is a metric space. We recall that a metric space is a pair (X, d)
where X is a set, and d is a real valued function on X × X satisﬁes the three
conditions: for all x, y and z in X,
[D1] d(x, y) ≥0, with d(x, y) = 0 if and only if x = y (positive deﬁniteness);
[D2] d(x, y) = d(y, x) (symmetry);
[D3] d(x, z) ≤d(x, y) + d(y, z) (triangle inequality).
The Cartesian product of two sets X and Y is deﬁned as
X × Y = {(x, y) x ∈X & y ∈Y }
where (x, y) denotes an ordered pair and & means the logical connective
‘and.’ Writing ⇔for ‘if and only if,’ we thus have
(x, y) = (z, w)
⇐⇒
(x = z & y = w).
More generally, (x1, . . . , xn) denotes the ordered n-tuple of the elements
x1,. . . , xn, and we have
X1 × · · · × Xn = {(x1, . . . , xn) x1 ∈X1, . . . , xn ∈Xn}.
The symbols N, Z, Q, and R stand for the sets of natural numbers, integers,
rational numbers, and real numbers, respectively; N0 and R+ denote the sets
of nonnegative integers and nonnegative real numbers respectively.
1.8.2 Binary Relations, Relative Product. A set R is a binary relation
if there are two (not necessarily distinct) sets X and Y such that R ⊆X × Y .
Thus, a binary relation is a set of ordered pairs xy ∈X × Y , where xy is an
abbreviation of (x, y). In such a case, we often write xRy to mean xy ∈R.
The qualiﬁer ‘binary’ is often omitted. If R ⊆X × X, then R is said to be a
binary relation on X. The (relative) product of two relations R and S is the
relation
RS = {xz ∃y, xRySz}
(in which ∃denotes the existential quantiﬁer). If R = S, we write R2 = RR,
and in general Rn+1 = RnR for n ∈N. By convention, if R is a relation on
X, then R0 denotes the identity relation on X:
xR0y
⇐⇒
x = y.

14
1 Examples and Preliminaries
Note that when xRy and yRz, we sometimes write xRyRz for short. Elemen-
tary properties of relative products are taken for granted. For example: if R,
S, T and M are relation, then:
S ⊆M =⇒RST ⊆RMT
(1.6)
and
R(S ∪T) ⊆RS ∪RT.
(1.7)
1.8.3 Order Relations. A relation is a quasi order on a set X if it is reﬂexive
and transitive on X, that is, for all x, y, and z in X,
xRx
(reﬂexivity)
xRy & yRz
=⇒
xRz
(transitivity)
(where ‘⇒’ means ‘implies’ or ‘only if’). A quasi order R is a partial order on
X if it is antisymmetric on X, that is, for all x and y in X
xRy & yRx
=⇒
x = y.
If R is a partial order on a set X, then the pair (X, R) is referred to as
a partially ordered set. A relation R is a strict partial order on X if it is
transitive and asymmetric on X, that is, for all x, y in X,
xRy
=⇒
¬(yRx) ,
where ¬ stands for the logical ‘not.’ The Hasse diagram or covering relation
of a partial order (X, R) is the relation ˘R ⊆R such that, for all x, y and z in
X, z ˘Rx together with zRyRx implies either x = y or y = z. We say then that
x covers z. If X is inﬁnite, the Hasse diagram may be empty (see Problem
1.8). Otherwise, ˘R provide a faithful and economical summary of R. Indeed,
we have
R = ∪∞
n=0 ˘Rn = ˘R0 ∪˘R ∪· · · ∪˘Rn ∪· · ·
(1.8)
The r.h.s. (right hand side) of (1.8) is called the transitive closure of ˘R. The
Hasse diagram of a relation R is the ‘smallest relation’ (see Problem 1.4)
the transitive closure of which gives back R. In general, we write Q∗for the
transitive closure of a relation Q. Thus, we can rewrite the ﬁrst equality in
(1.8) in the compact form R = ˘R∗. The Hasse diagram of a strict partial
order can also be deﬁned (see Problem 1.8).
A partial order L on X is a linear order if it is is strongly connected, that
is, for all x, y in X,
xLy
or
yLx .
(1.9)
A relation L on X is a strict linear order if it is a strict partial order which is
connected, that is, (1.9) holds for all distinct x, y in X.

1.8 Notation and Conventions
15
Suppose that L is a strict linear order on X. A L-minimal element of
Y ⊆X is a point x ∈Y such that ¬(yLx) for any y ∈Y . A strict linear order
L on X is a well-ordering of X if every nonempty Y ⊆X has a L-minimal
element. In such case, we may say that L well-orders X.
We follow Roberts (1979) and call a strict weak order on a set X a relation
≺on X satisfying the condition: for all x, y, z ∈X,
x ≺y
⇒

¬(y ≺x) and
either x ≺z or z ≺y (or both).
(1.10)
For the deﬁnition of a weak order, see Problem 1.10.
1.8.4 Equivalence Relations, Partitions. A binary relation R is an equiv-
alence relation on a set X if it is reﬂexive, transitive, and symmetric on X,
that is, for all x, y in X, we have
xRy
⇐⇒
yRx.
The following construction is standard. Let R be a quasi order on a set X.
Deﬁne the relation ∼on X by the equivalence
x ∼y
⇐⇒
(xRy & yRx).
(1.11)
It is easily seen that the relation ∼is reﬂexive, transitive, and symmetric on
X, that is, ∼is an equivalence relation on X. For any x in X, deﬁne the set
⟨x⟩= {y ∈X x ∼y}. The family Z = X/∼= {⟨x⟩x ∈X} of subsets of X
is called the partition of X induced by ∼. Any partition Z of X satisﬁes the
following three properties
[P1] Y ∈Z implies Y ̸= ∅;
[P2] Y, Z ∈Z and Y ̸= Z imply Y ∩Z = ∅;
[P3] ∪Z = X.
Conversely, any family Z of subsets of a set X satisfying [P1], [P2], and [P3] is
a partition of X. The elements of Z are called the classes of the partition. A
partition containing just two classes is sometimes referred to as a bipartition.
An example of a bipartition was provided by the family {T+, T−} of our
puzzle Example 1.1.1, where T+ contains all the transformations consisting in
adding pieces to the puzzle, and T−those containing their reverses, that is,
removing those pieces.
1.8.5 Graphs. The language of graph theory is coextensive with that of re-
lations, with the former applying naturally when geometrical representations
are used. We will use either of them as appropriate to the situation.
A directed graph or digraph is a pair (V, A) where V is a set and A ⊆V ×V .
The elements of V are referred to as vertices and the ordered pairs in A as

16
1 Examples and Preliminaries
arcs or directed edges. The pair (V, A) may be referred to as a digraph on V .
Several pictorial representations of graphs have been given already. In Figure
1.6, for example, the vertices are all the partial orders on the set {a, b, c}, and
each of the arcs corresponds to the addition of an ordered pair to a partial
order, forming a new partial order. This illustrates the usual convention of
representing arcs by arrows and vertices by points or small circles. When the
arc vw exists, we say that ‘there is an arc from v to w.’ Two distinct vertices
v,w are called adjacent when one or both of the two arcs vw or wv exists. In
pictorial representations of graphs, loops—circular arrows joining a vertex to
itself—are routinely omitted when they provide redundant information.
As will be illustrated by many examples in this monograph, there are di-
graphs satisfying the condition: there is an arc from v to w whenever there is
an arc from w to v and vice versa. (In the terminology of relations introduced
in 1.8.4, we say then that the set of arcs regarded as a relation is symmetric.)
In such cases, the digraph is called a graph and each pair of arcs (vw, wv) is
referred as an edge of the graph which we denote by {v, w}. The permutohe-
dron of Figure 1.4 is a geometric representation of a graph. Note that, as is
customary or at least frequent, a single line between two points representing
adjacent vertices replaces the pair of arrows picturing the two arcs.
Let sn be a sequence v0, v1, . . . , vn of vertices in a digraph such that vivi+1
is an arc, for 0 ≤i ≤n −1. Such a sequence is called a walk from v0 to vn.
A segment of the walk sn is a subsequence sj, sj+1, . . . , sj+k, with 0 ≤j ≤
j + k ≤n. The walk sn is closed if v0 = vn, and open otherwise. A walk
whose vertices are all distinct, is a path. A closed path is a circuit or a cycle.
The length of a walk sn (whether open or closed), is assigned to be n. Notice
that the concepts of walk, path and circuit apply to a graph, with a sequence
of edges {vi, vi+1} = (vivi+1, vi+1vi), 0 ≤i ≤n −1. When the digraph is a
graph, there is a path of length n from v to w if and only if there is a path of
length n from w to v. In such a case, we deﬁne the (graph theoretical) distance
δ(v, w) between two distinct vertices v and w to be the length of the shortest
path from v to w, if there is such a path, and inﬁnity otherwise. We also
deﬁne δ(v, v) = 0, for all vertices v. It is easily shown (cf. Problem 1.16) that
the pair (V, δ) is a metric space, that is, the function δ satisﬁes Conditions
[D1], [D2] and [D3] in 1.8.1 (with δ = d). To avoid ambiguity when more
than one graph is under discussion, we may index the distance function by
the graph and write δG(v, w) for the distance between the vertices v and w
in the graph G = (V, A). We sometimes need to focus on part of a graph. A
graph H = (W, B) is a subgraph of a graph G = (V, A) if W ⊆V and B ⊆A;
it is an induced subgraph of G if W ⊆V and B = (W × W) ∩A. A graph
H = (W, B) is an isometric subgraph of a graph G = (V, A) if it is a subgraph
of G and moreover
δH(v, w) = δG(v, w)
(v, w ∈W).
Two graphs (V, A) and (W, B) are isomorphic if there is a bijection ϕ : V →
W such that

1.9 Historical Note and References
17
{ϕ(v), ϕ(w)} ∈B
⇐⇒
{v, w} ∈A,
for all v, w ∈V . If (W, B) is a subgraph of a graph (U, C), then we say
that ϕ is an embedding of (V, A) into (U, C). This embedding is an isometric
embedding if (W, B) is an isometric subgraph of (U, C).
In the permutohedron graph of Figure 1.4, the subgraph deﬁned by the
subset of the six vertices
W = {2134, 2143, 2413, 2431, 2341, 2314}
(forming an hexagonal face of the permutohedron) is isometric. But removing
a single point of W would deﬁne a subgraph that would not be isometric (see
Problem 1.15 in this connection).
A graph G = (V, A) is connected if any two distinct vertices of G are
endpoints of a path of G. It is bipartite if its vertex set can be partitioned
into V = V1 + V2, such that every edge of G connects a vertex in V1 with a
vertex in V2. A classical result from K¨onig (1916) is that a graph is bipartite
if and only if it contains no odd circuit, that is, a circuit with an odd number
of edges. A tree is a connected graph without cycles. A vertex in a tree is a
leaf if it is adjacent to a single vertex.
For graph terminology and results, see Busacker and Saaty (1965), Bondy
and Murphy (1976), Roberts (1984), or Bondy (1995).
1.9 Historical Note and References
The concept of a medium was introduced by Falmagne (1997), as a gener-
alization of conditions satisﬁed by certain families of relations, such as the
family P of all (strict) partial orders on a ﬁnite set S. A key property of such
a family, wellgradedness, already encountered in this chapter is that, for any
two partial orders ≺and ≺′, there necessarily exists a sequence
≺1 = ≺, ≺1, . . . , ≺n = ≺′
(1.12)
of partial orders in P such that any two consecutive partial orders in (1.12)
diﬀer by exactly one pair,
|≺i △≺i+1| = 1
(i = 1, . . . , n −1),
(1.13)
and, moreover, such a path between ≺and ≺′ in P is minimal in the sense
that:
|≺△≺′| = n.
(1.14)
This property, which is a focus of Chapter 5, is also satisﬁed by other
families of relations, such as the semiorders and the biorders (cf. Deﬁnition
5.1.1, Formulas (5.13) and (5.9)). This was shown by Doignon and Falmagne

18
1 Examples and Preliminaries
(1997), who referred to it as the ‘wellgradedness’ of such families. On hind-
sight, it should perhaps have evoked the condition of transitivity of certain
semigroups. Curiously, however, the connection between wellgradedness and
the axioms specifying a medium was made via the development of random
walk models based on such families in view of some applications in the so-
cial sciences. In computing the asymptotic probabilities of the states of these
random walks (which are formed by the relations in each of these families;
see e.g. Falmagne, 1996; Falmagne and Doignon, 1997) it was realized that
essentially—but not exactly—the same limit theorem had to be proven. The
axiomatization of the concept of a medium was the natural step taken in
Falmagne (1997), which also contains a number of basic results. This work
was further extended by Falmagne and Ovchinnikov (2002) and Ovchinnikov
(2006) (see also Ovchinnikov and Dukhovny, 2000).
Media were later investigated from an algorithmic standpoint by Eppstein
and Falmagne (2002). One of their results concerns the existence of a tight
bound for the shortest ‘reset sequence’ (cf. Ginsburg, 1958; Moore, 1956)
for a medium. They also describe a near-linear time algorithm for testing
whether an orientation is closed, and a polynomial time one for ﬁnding a
closed orientation if one exists. Those results are contained in Chapter 10.
Concepts essentially equivalents to media were investigated much earlier
by graph theorists under the name of ‘partial cubes’, that is, isometric sub-
graphs of hypercubes, beginning with Graham and Pollak (1971). Partial
cubes were characterized by Djokovi´c (1973) and Winkler (1984) (see Imrich
and Klavˇzar, 2000, which also contains references to other characterizations
of partial cubes). The ties between partial cubes and media are described in
Chapter 7. Some critical diﬀerences between partial cubes and media lie in
the language and notation which, in the case of media theory, are akin to
automata theory. Obviously, the language and notation one uses are strongly
suggestive and may lead to diﬀerent types of results, as exempliﬁed in this
volume.
The random walk models mentioned above were used for the analysis of
opinion polls, in particular those polls concerning the presidential election in
the US. Such polls are typically performed several times on the same large
sample of respondents. The results are referred to as ‘panel data.’ Among
other queries, the respondent are always asked to provide a type of ranking
of the candidates. Assuming that the panel data consist in k polls taken at
times t1, . . . , tk, this means that each respondent has provided a ﬁnite sequence
≺t1, . . . , ≺tk of some kind of order relations, such as weak orders. The form
of such data suggests an interpretation in terms of visits, by each respondent,
of the states of some random walk on the family of all such order relations.
In such a framework, these visits take place in real time and ≺t1, . . . , ≺tk is
regarded as a sequence of ‘snapshots’ revealing an aspect of the opinion of a
respondent at times t1, . . . , tk. Various random walk models have been used
to analyze the results of the 1992 US presidential election opposing Clinton,
Bush and Perot (Falmagne et al., 1997; Regenwetter et al., 1999; Hsu and

Problems for Chapter 1
19
Regenwetter, in press). The general theory of such random walks on media
is developed in Falmagne (1997) and Falmagne et al. (2007). Our last two
chapters include an exposition of this work.
A major application of media theory is to learning spaces6, which were
deﬁned on p. 10. As is established in Theorem 4.2.2, a learning space is es-
sentially a ‘rooted, closed medium.’ Learning spaces provide a model for the
structural organization of the feasible knowledge states in a topic, such as
algebra or chemistry. The particular learning space associated with a topic
is at the core of an algorithm for the assessment of knowledge in that topic.
It also guide and monitors the students’ learning. Such a system is currently
used by many schools and colleges in the US and abroad. Further discussion
of this topic will be found in Chapter 13.
In view of the wide diversity of the examples covered in this chapter and
later in this book, it seems likely that media have other useful applications.
Problems
Many of the questions asked below will be dealt with in depth in the chapters
of this book. Some of the problems cannot be solved in formal sense without
using the axioms specifying a medium, which can be found in Deﬁnition 2.2.1.
In such cases the reader should rely on the intuitive conception of a medium
developed in this chapter to analyze the problem and attempt a formalization.
We propose such exercises as a useful preparation for the rest of this volume.
1.1 In the medium of the Gauss puzzle 1.1.1, identify two states S and T,
and two distinct minimally short paths from S to T that do not have their
transformations in exact opposite orders. What are conditions (necessary and
suﬃcient) that garantee that the transformations will be in exact opposite
orders?
1.2 A facet of the permutohedron on four elements is either a square or a
regular hexagon. Describe the facets of a permutohedron on ﬁve elements.
1.3 Certain oriented media, such as that of our ﬁrst example of the puzzle,
are closed for their orientation: suppose that S is any state of the medium,
and that τ : S →Sτ and µ : S →Sµ are any two ‘positive’ transformations,
then whenever Sτ and Sµ are deﬁned as states distinct from S, then (Sτ)µ =
(Sµ)τ = Sτµ = Sµτ is also a state of the medium. Such a medium is said
to be ‘closed’ (cf. Chapter 4). Under which condition is the medium induced
by a ﬁnite set of straight line in the plane (in the sense of Section 1.2.1 and
Figure 1.3) a closed medium? Can you prove your response?
6 The exact connection between learning spaces and media was recognized only
recently.

20
1 Examples and Preliminaries
1.4 Let R be a strict partial order. Suppose that H is a family of relations
such that, for each Q ∈H, the transitive closure Q∗of Q is equal to R.
Verify that we have then ∩H = ˘R. (So, the phrase ‘the smallest relation the
transitive closure of which gives back R’ makes sense in 1.8.3.)
1.5 Verify the implication (1.6).
1.6 Prove the inclusion (1.7). Why don’t we have the equality?
1.7 The medium represented by its graph in Figure 1.7 is equipped with an
orientation. This medium is not closed under that orientation. Also, it does
not contain the state A-B-C-X . Modify the rules so as to obtain a closed
medium containing the eight states of Figure 1.7, the state A-B-C-X , plus
at most two other states.
1.8 Deﬁne the Hasse diagram of a strict partial order. Exactly when is the
Hasse diagram of a partial order or strict partial order empty?
1.9 We have seen that the medium of all partial orders on the set {a, b, c}
was closed with respect to the natural orientation of that medium, namely:
if P, P + {xy} and P + {zw} are partial orders in the same medium, then
so is P + {xy} + {zw}. Prove or disprove (by a counterexample) that that
closedness property holds for all families of partial orders on a ﬁnite set.
1.10 In the spirit of the distinction between a partial order and a strict partial
order (Deﬁnition 1.8.3), deﬁne the concept of a weak order ≾on a set X.
1.11 Let H be the collection of all the Hasse diagrams of the collection of
all the partial order on a given ﬁnite set. Is H well-graded? Hint: Examine
Equations (1.12), (1.13) and (1.14) in this connection.
1.12 Let F and G be the families of all the partial orders on the sets {a, b, c}
and {a, b, x}. Describe F \ G. Does it form a medium?
1.13 Let F and G be the families of all the partial orders on two distinct
overlapping sets. Describe F ∩G. Does it form a medium?
1.14 Consider a planar political map of the world (indicating the countries’
boundaries). In the style of the hyperplane arrangement of 1.2.1, deﬁne the
states to be the countries, and let the transformations be the crossings of a
single border between two countries. Does this construction deﬁne a medium?
Why or why not?

Problems for Chapter 1
21
1.15 Deﬁne a isometric subgraph (W, B) of the permutohedron (L, A) of
Figure 1.4, with W ⊂L, having a maximal number of point. (Thus, adding a
single point to W would destroy the isometricity.)
1.16 Let (A, V ) be a graph, and let δ be the distance on that graph as deﬁned
in 1.8.5. Prove that the pair (A, δ) is a metric space, that is, verify that the
three conditions [D1], [D2] and [D3] are satisﬁed.

2
Basic Concepts
We ﬁrst introduce the general framework of ‘token systems’ and a convenient
language for our deﬁnitions. In this context, we then formulate two indepen-
dent axioms specifying the concept of a medium and begin the development
of the main results. A glossary of notations can be found on page 309.
2.1 Token Systems
2.1.1 Deﬁnition. Let S be a set of states. A token (of information) is a
function τ : S →Sτ mapping S into itself. We write Sτ = τ(S), and
Sτ1τ2 · · · τn = τn(· · · τ2(τ1(S)) · · · ) for the function composition. By deﬁni-
tion, the identity function τ0 on S is not a token. Let T be a set of tokens
on S, with |S| ≥2 and T ̸= ∅. The pair (S, T) is then called a token system.
Let V and S be two states. Then V is adjacent to S if S ̸= V and Sτ = V
for some token τ in T. A token ˜τ is a reverse of a token τ if for any two
adjacent states S and V , we have
Sτ = V
⇐⇒
V ˜τ = S.
(2.1)
It is easily veriﬁed that a token has at most one reverse. If the reverse ˜τ of τ
exists, then τ and ˜τ are mutual reverses. We have thus ˜˜τ = τ, and adjacency
is a symmetric relation on S (Problem 2.2).
2.1.2 Deﬁnition. A message is a (possibly empty) string of elements of
the set of tokens T. A nonempty message m = τ1 . . . τn deﬁnes a function
S →Sτ1 · · · τn on the set of states S. By abuse of notation, we also write then
m = τ1 · · · τn for the corresponding function. No ambiguity will arise from
this double usage. When Sm = V for some states S, V and some message m,
we say that m produces V from S. The content of a message m = τ1 . . . τn
is the set C(m) = {τ1, . . . , τn} of its tokens. We write ℓ(m) = n to denote
the length of the message m. (We have thus |C(m)| ≤ℓ(m).) A message m

24
2 Basic Concepts
is eﬀective (resp. ineﬀective) for a state S if Sm ̸= S (resp. Sm=S) for the
corresponding function S →Sm. A message m = τ1 . . . τn is stepwise eﬀec-
tive for S if Sτ1 · · · τk ̸= Sτ0 · · · τk−1, 1 ≤k ≤n. A message which is both
stepwise eﬀective and ineﬀective for some state is called a return message or,
more briefy, a return (for that state).
A message m = τ1 . . . τn is inconsistent if it contains both a token and its
reverse, that is, if τj = ˜τi for some pair of distinct indices i and j; otherwise, it
is called consistent. A message consisting of a single token is thus consistent.
Two messages m and n are jointly consistent if mn (or, equivalently, nm) is
consistent. A consistent message which is stepwise eﬀective for some state S
and does not have any of its token occuring more than once is said to be concise
(for S). A message m = τ1 . . . τn is vacuous if the set of indices {1, . . . , n} can
be partitioned into pairs {i, j}, such τi and τj are mutual reverses.
Note that when a message m is empty, we deﬁne m = τ0, the identity
on S (which, as mentioned above, is not a token). In such a case, m is a place
holder symbol that can be deleted, as in: ‘let mn be a message in which m
is either a concise message or is empty’ (that is mn = n).
2.2 Axioms for a Medium
2.2.1 Deﬁnition. A token system (S, T) is called a medium (on S) if the
following two axioms are satisﬁed.
[Ma] For any two distinct states S, V in S, there is a concise message pro-
ducing V from S.
[Mb] Any return message is vacuous.
A medium (S, T) is ﬁnite if S is a ﬁnite set. For some comments on these
axioms, see Remark 2.2.8.
2.2.2 Lemma. In a medium, each token has a unique reverse.
Proof. For any token τ, we have Sτ = V for some distinct states S and V .
Axiom [Ma] implies that there is a concise message m producing S from V .
Hence, τm is a return for S. By Axiom [Mb], τm must be vacuous, and so
˜τ ∈C(m). As m is concise, we must have m = ˜τ. The uniqueness results
from the deﬁnition of a reverse of a token (see 2.1.1).
2.2.3 Deﬁnition. The reverse of a message m = τ1 . . . τn is deﬁned by

m = ˜τn . . . ˜τ1. The following facts are straightforward (see Problem 2.1):
(i) if m is stepwise eﬀective for S, then Sm = V
implies V 
m = S;
(ii) τ ∈C(m) if and only if ˜τ ∈C(
m); (iii) if m is consistent, so is 
m.

2.2 Axioms for a Medium
25
T

T
T
T
T
T
T
T
T
T


W
V
S
X
T
Figure 2.1. Digraph of a medium with set of states S = {S, V, W, X, T} and set of
tokens T = {τi 1 ≤i ≤6}.
T

T
S
T
W
T
3
4
V
T5
T4
S

T
T3
T
T
V
T6
[Ma]
[Mb]
X
T
Figure 2.2. Digraphs of two token systems establishing the independence of the
two Axioms [Ma] and [Mb]. Each digraph is labelled by the failing axiom.
2.2.4 Example. Figure 2.1 displays the digraph of a medium with set of
states S = {S, V, W, X, T} and set of tokens T = {τi 1 ≤i ≤6}. It is clear
that ˜τ1 = τ2, ˜τ3 = τ4, and ˜τ5 = τ6.
2.2.5 Theorem. The axioms [Ma] and [Mb] are independent.
Proof. Each of the two digraphs in Figure 2.2 on page 25 deﬁnes a token system
satisfying one of the two axioms deﬁning a medium. The labels [Ma] and [Mb]
attached to the two digraphs indicates the failing axiom (Problem 2.3).

26
2 Basic Concepts
2.2.6 Convention. Except when stated otherwise, we assume implicitly for
the rest of this chapter that we have ﬁxed a token system in which Axioms
[Ma] and [Mb] hold.
2.2.7 Lemma. Let n and m be two consistent messages producing the same
state S, and suppose that these messages are stepwise eﬀective for some not
necessarily distinct states T and V , respectively. Then n and m are jointly
consistent.
Proof. If T = V , the message n
m is a return for T which, by [Mb], must be
vacuous. Suppose that nm is inconsistent. There is then some token τ that
occurs in n and in 
m. Since n
m is vacuous, the token ˜τ must occur more
than once in it. This is impossible since n and 
m are consistent.
Suppose that T ̸= V . From Axiom [Ma], we know that there exists a
concise message w producing T from V . Thus n
mw is a return for T. By
[Mb], n
mw is vacuous. If nm is not consistent, there is some token τ ∈C(n)
with ˜τ ∈C(m), which implies that τ appears at least twice in n
m. But as
n
mw is vacuous and each of n and m is consistent, the token ˜τ must appear
at least twice in w, contradicting the hypothesis that w is concise.
2.2.8 Remark. Earlier discussions of the concept of a medium (Falmagne,
1997; Falmagne and Ovchinnikov, 2002) were based on a weaker form of [Ma]
assuming only the existence, for any two distinct states S and V , of a con-
sistent message producing V from S. The two Lemmas 2.2.2 and 2.2.7 were
taken as axioms, and a form of Axiom [Mb] was also used.
All the examples of media encountered so far were ﬁnite ones. Our ﬁrst
inﬁnite example is given below.
2.2.9 Example. Let (Z2, T) be the medium with the set of transformations
T contains all pairs of tokens τij, ˜τij deﬁned by
τij : Z2 →Z2 : (k, q) →(k, q)τij =
⎧
⎪
⎨
⎪
⎩
(k + 1, q)
if i = k, j = 1,
(k, q + 1)
if i = q, j = 2,
(k, q)
otherwise,
˜τij : Z2 →Z2 : (k, q) →(k, q)˜τij =
⎧
⎪
⎨
⎪
⎩
(k −1, q)
if i = k, j = 1,
(k, q −1)
if i = q, j = 2,
(k, q)
otherwise.
It is easily checked that Axioms [Ma] and [Mb] hold. Note that both the set
of states and the set of tokens are inﬁnite (see Problem 2.9).

2.3 Preparatory Results
27
2.3 Preparatory Results
Some simple consequences of the axioms are gathered in the next lemma.
2.3.1 Lemma. (i) No token can be identical to its own reverse.
(ii) Any consistent, stepwise eﬀective message (for some state) is concise.
(iii) For any two adjacent states S and V , there is exactly one token
producing V from S.
(iv) Let m be a message that is concise for some state, then
ℓ(m) = |C(m)| ,
(2.2)
and
C(m) ∩C(
m) = ∅.
(2.3)
(v) No token can be a 1-1 function.
(vi) Suppose that m and n are stepwise eﬀective for S and V , respectively,
with Sm = V and V n = W. Then mn is stepwise eﬀective for S, with
Smn = W.
(vii) Any vacuous message which is stepwise eﬀective for some state is a
return message for that state.
Notice that the last statement is a partial converse of Axiom [Mb].
Proof. (i) Suppose that τ = ˜τ. As τ ̸= τ0, the identity function on S, we must
have Sτ = V for some distinct states S and V . This implies S˜τ = V , and so
both τ and ˜τ produce V , contradicting Lemma 2.2.7.
(ii) Suppose that m is a consistent, stepwise eﬀective message producing
V from S, and that some token τ occurs at least twice in m. We have thus
Sm = n1τn2τn3 = V for some consistent stepwise eﬀective messages n1τ
and n2τn3. (Some of n1, n2 and n3 could of course be empty.) This implies
that Sm = Sn1τn2τ = V ′, for some state V ′. We conclude that the messages
n1τ and ˜τ 
n2 are consistent, stepwise eﬀective messages producing the state
W = Sn1˜τ from S and V , respectively. These two messages are not jointly
consistent, contradicting Lemma 2.2.7.
Suppose that Sτ1 = Sτ2 = V . The message τ1˜τ2 is a return for S. By
[Mb], this message is vacuous, so {τ1, ˜τ2} is a pair of mutually reverse tokens.
It follows that τ1 = ˜˜τ2 = τ2.
(iv) Equations (2.2) and (2.3) stem readily from the deﬁnition of a concise
message.
(v) Suppose that Sτ = V for some token τ and two adjacent states S and
V . If V τ = W ̸= V for some state W, then V = Sτ = W ˜τ, a contradiction
of Lemma 2.2.7, because, by deﬁnition, τ is a consistent message. Hence,
Sτ = V τ = V , and so τ is not a 1-1 function.
(vi) This is clear.
(vii) Let m be a vacuous message which is stepwise eﬀective for some state
S, with Sm = V . Suppose that S ̸= V . By Axiom [Ma] there is a concise

28
2 Basic Concepts
message n producing S from V . Thus, mn is a return for S, which must be
vacuous by [Mb]. Since m is vacuous, n must be vacuous. This cannot be true
because n is concise.
We introduce two graph-theoretical concepts. The ﬁrst one has been used
informally in Chapter 1.
2.3.2 Deﬁnition. The (adjacency) graph of a medium is constructed as fol-
lows: each of its vertices represents a state of the medium, and each of its
edges links two vertices representing adjacent states (cf. Deﬁnition 2.1.1).
Such graphs are undirected.
The graphs of Figures 1.2 and 1.4 are adjacency graphs, whereas the graph
of Figure 2.1 is not.
2.3.3 Deﬁnition. For a medium (S, T), we deﬁne the function
δ : S × S →N0 : (S, V ) →δ(S, V ) =
⎧
⎪
⎨
⎪
⎩
0
if S = V
|C(m)|
if Sm = V, with m
a concise message.
It is easily veriﬁed that δ is the graph theoretical distance on the graph of
(S, T) (cf. 1.8.5).
While the composition of tokens is not commutative in a medium, a weaker
form of it holds, expressed by the next result, which is crucial.
2.3.4 Theorem. Let m and n be two distinct concise messages transforming
some state S. Then
Sm = Sn
⇐⇒
C(m) = C(n).
Proof. Suppose that Sm = Sn = V . Then, V 
n = S, which yields Sm
n = S.
Thus, m
n is ineﬀective for S and also, by Lemma 2.3.1(vi), stepwise eﬀective
for that state; so, m
n is a return for S. By Axiom [Mb], m
n must be vacuous.
Take any τ ∈C(m). Because m
n is vacuous, we must have ˜τ ∈C(m
n); in
fact, ˜τ must be in C(
n) because m is consistent. This implies τ ∈C(n),
yielding C(m) ⊆C(n), and by symmetry, C(n) ⊆C(m).
Conversely, suppose that C(m) = C(n), with Sm = V ̸= Sn = W. By
Axiom [Ma], there is a concise message p producing W from V . Thus, mp˜n
is a return for S. Axiom [Mb] implies that mp˜n is vacuous. But this cannot
be since p is concise, and τ ∈C(m) if and only if ˜τ ∈C(˜n). We conclude that
we must have V = W.

2.4 Content Families
29
2.4 Content Families
2.4.1 Deﬁnition. Let (S, T) be a medium. For any state S, deﬁne the (token)
content of S as the set S of all tokens each of which is contained in at least
one concise message producing S; formally:
S = {τ ∈T ∃V ∈S and m concise such that V m = S and τ ∈C(m)}.
We refer to the family S of all the contents of the states in S as the content
family of the medium (S, T).
2.4.2 Example. As an illustration, we construct the content family of the
medium represented in Figure 2.1. We obtain
S = {τ2, τ4, τ6},
V = {τ2, τ3, τ6},

W = {τ2, τ3, τ5},

X = {τ2, τ4, τ5},
T = {τ1, τ3, τ5}.
Note the following fact regarding this family. Take any two adjacent states
in the Example of Figure 2.1, say Xτ3 = W. We have

W \ 
X = {τ3} = {˜τ4} and 
X \ 
W = {τ4} = {˜τ3}.
2.4.3 Theorem. For any token τ and any state S, we have either τ ∈S or
˜τ ∈S (but not both); so, |S| = |V | for any two states S and V . Moreover, if
S is ﬁnite, then |S| = |T|/2 for any S ∈S.
Proof. Since τ is a token, there are states Q ̸= W such that Qτ = W. By
Axiom [Ma], for any state S, there are concise messages m and n such that
S = Qm = Wn. Thus, τn
m is a return for Q, which must be vacuous by
[Mb]. Therefore, ˜τ ∈C(n) or ˜τ ∈C(
m), which yields ˜τ ∈S or τ ∈S. As
a consequence of Lemma 2.2.7, we cannot have both ˜τ ∈S and τ ∈S; so,
|S| = |V | for any two states S and V . The last statement is obvious.
2.4.4 Theorem. If Sm = V for some concise message m (thus S ̸= V ), then
V \ S = C(m), and so V △S = C(m) + C(
m) ̸= ∅.
Proof. By deﬁnition, V contains all the tokens from concise messages produc-
ing V ; so, we must have C(m) ⊆V . As we also have V 
m = S, the same
argument yields C(
m) ⊆S. Because, by Theorem 2.4.3, S cannot contain
both a token and its reverse, we obtain C(m) ⊆V \ S.
To prove the converse inclusion, suppose that τ ∈V \ S for some token τ.
Then τ must occur in some concise message producing V . Without loss of
generality, we may assume that Wτn = V for some state W, with τn concise.

30
2 Basic Concepts
Suppose that W ̸= S and let q be a concise message producing S from W. As
the message m
n˜τq is a return for S, it must be vacuous by [Mb]. Thus, we
must have
τ ∈C(m) ∪C(
n) ∪C(q).
We cannot have either τ ∈C(q) (because this would imply τ ∈S), or τ ∈C(
n)
(because this would yield τ, ˜τ ∈C(τn), with τn concise, a contradiction). We
conclude that τ ∈C(m). The last equation of the theorem results from Lemma
2.3.1(iv), Eq. (2.3).
The case S = W is left to the reader.
Any state is deﬁned by its content. Indeed, we have:
2.4.5 Theorem. For any two states S and V , we have
S = V
⇐⇒
S = V .
(2.4)
Proof. Suppose that S = V for some S ̸= V . (The other implication is trivial.)
Let q be a concise message producing V from S. From Theorem 2.4.4, we get
V △S = C(q) + C(
q) ̸= ∅, contradicting our hypothesis that S = V . We
conclude that (2.4) holds.
The content family of a medium satisﬁes a strong structural property which
will be investigated in Chapter 3.
2.5 The Eﬀective Set and the Producing Set of a State
Theorem 2.4.5 entails a characterization of each state of a medium by its
content. In fact, only a possibly small subset of the content is needed to
specify a state, enabling a more economical coding.
2.5.1 Deﬁnition. The eﬀective set and the productive set of a state S in a
medium (S, T) are the two subsets of tokens respectively deﬁned by
SE = {τ ∈T Sτ ̸= S}
SP = {τ ∈T Tτ = S ̸= T for some T ∈S}.
We have thus SP ⊆S and SE ⊆T \ S.
The importance of these two concepts is that any state in a medium is charac-
terized by either of these two sets. The next theorem is conceptually related to
a result pertaining to well–graded families (cf. Doignon and Falmagne, 1999,
Theorem 2.8; see also Deﬁnition 5.2.1 and Theorem 5.2.2 in our Chapter 5).
The connection is spelled out in Theorem 5.2.5.

2.6 Orderly and Regular Returns
31
2.5.2 Theorem. For any two states S and T in a medium (S, T), the following
ﬁve conditions are equivalent.
(i) S = T.
(ii) SE = T E.
(iii) SP = T P.
(iv) SE ⊆T.
(v) SP ⊆T \ T.
Proof. Clearly, Condition (i) implies all the others; also, (ii) and (iii) imply
(iv) and (v), respectively. It remains to show that each of (iv) and (v) implies
(i). We use contraposition. If S ̸= T, there exists a concise message τ1 . . . τn
producing T from S. By Theorem 2.4.4, this implies both ˜τ1 ∈SE ∩(T \ T)
and τ1 ∈SP ∩T, contradicting Conditions (iv) and (v), respectively.
2.6 Orderly and Regular Returns
Our presentation follows Falmagne and Ovchinnikov (2007).
2.6.1 Deﬁnition. If m and n are two concise messages producing, from a
state S, the same state V ̸= S, then m
n is a return for S. We call m
n an
orderly return for S. It is clear from Theorem 2.4.4 that the length of an
orderly return must be even (Problem 2.15).
We begin with a result of general interest for orderly returns.
2.6.2 Theorem. Let S, N, Q and W be four distinct states of a medium and
suppose that
Nτ = S,
Wµ = Q,
Sq = Nq′ = Q,
Sw′ = Nw = W
(2.5)
for some tokens τ and µ and some concise messages q, q′, w and w′ (see
Figure 2.3). Then, the four following conditions are equivalent:
(i) ℓ(q) + ℓ(w) ̸= ℓ(q′) + ℓ(w′) and µ ̸= ˜τ;
(ii) τ = µ;
(iii) C(q) = C(w) and ℓ(q) = ℓ(w);
(iv) ℓ(q) + ℓ(w) + 2 = ℓ(q′) + ℓ(w′).
Moreover, any of these conditions implies that q˜µ 
wτ is an orderly return
for S with Sq˜µ = S˜τw = W. The converse does not hold.
Proof. We prove (i) ⇒(ii) ⇔(iii) ⇒(iv) ⇒(i).
(i) ⇒(ii). Suppose that τ ̸= µ. The token ˜τ must occur exactly once in
either q or in 
w. Indeed, we have µ ̸= ˜τ, both q and w are concise, and the
message τq˜µ 
w is a return for S, and so is vacuous by [Ma]. It can be veriﬁed
that each of the two mutually exclusive, exhaustive cases:

32
2 Basic Concepts
S
N
Q
W
T
q
q’
w’
w
 M
Figure 2.3. Illustration of the conditions listed in (2.5).
[a] ˜τ ∈C(q) ∩C(w′); and [b] ˜τ ∈C( 
w) ∩C(
q′) lead to
ℓ(q) + ℓ(w) = ℓ(q′) + ℓ(w′),
(2.6)
contradicting (i). Thus, we must have τ = µ.
We only prove Case [a]. The other case is treated similarly. Since ˜τ is in
C(q), neither τ nor ˜τ can be in C(q′). Indeed, both q and q′ are concise and
q
q′τ is a return for S. It follows that both ˜τq′ and q are concise messages
producing Q from S. By Theorem 2.4.4, we must have C(˜τq′) = C(q), which
implies ℓ(˜τq′) = ℓ(q), and so
ℓ(q) = ℓ(q′) + 1.
(2.7)
A argument along the same lines shows that
ℓ(w) + 1 = ℓ(w′).
(2.8)
Adding (2.7) and (2.8) and simplifying, we obtain (2.6). The proof of Case [b]
is similar.
(ii) ⇔(iii). If µ = τ, it readily follows (since both q and w are concise and
Sq˜τ 
wτ = S) that any token in q must have a reverse in 
w and vice versa.
This implies C(q) = C(w), which in turn imply ℓ(q) = ℓ(w), and so (iii) holds.
As q˜µ 
wτ is vacuous, it is clear that (iii) implies (ii).
(iii) ⇒(iv). Since (iii) implies (ii), we have τ ∈Q \ 
N by Theorem 2.4.4.
But both q and q′ are concise, so τ ∈C(q′) \ C(q). As τq
q′ is vacuous for N,
we must have C(q) + {τ} = C(q′), yielding
ℓ(q) + 1 = ℓ(q′).
(2.9)
A similar argument gives C(w) + {τ} = C(w′) and
ℓ(w) + 1 = ℓ(w′).
(2.10)
Adding (2.9) and (2.10) yields (iv).
(iv) ⇒(i). As (iv) is a special case of the ﬁrst statement in (i), we only
have to prove that µ ̸= ˜τ. Suppose that µ = ˜τ. We must assign the token ˜τ
consistently so to ensure the vacuousness of the messages q
q′τ and τw′ 
w. By
Theorem 2.4.4, C(q) = Q \ S. Since ˜τ ∈Q and, by Theorem 2.4.3, ˜τ /∈S, the

2.6 Orderly and Regular Returns
33
only possibility is ˜τ ∈C(q) \ C(q′). For similar reasons τ ∈C(w) \ C(w′). We
obtain the two concise messages ˜τq′ and q producing Q from S, and the two
concise messages w and τw′ producing W from N. This gives ℓ(q) = ℓ(˜τq′)
and ℓ(w) = ℓ(τw′). We obtain so ℓ(q) = ℓ(q′) + 1 and ℓ(w) = ℓ(w′) + 1,
which leads to ℓ(q)+ℓ(w) = ℓ(q′)+ℓ(w′)+ 2 and contradicts (iv). Thus, (iv)
implies (i). We conclude that the four conditions (i)-(iv) are equivalent.
We now show that, under the hypotheses of the theorem, (ii) implies that
q˜µ 
wτ is an orderly return for S with Sq˜µ = S˜τw = W. Both q and w
are concise by hypothesis. We cannot have µ in C(q) because then ˜µ is in
C(
q) and the two concise messages 
q and τ = µ producing S are not jointly
consistent, yielding a contradiction of Lemma 2.2.7. Similarly, we cannot have
˜µ in C(q) since the two concise messages q and µ producing Q would not be
jointy consistent. Thus, q˜µ is a concise message producing W from S. For
like reasons, with τ = µ, ˜τw is a concise message producing W from S. We
conclude that, with τ = µ, the message q˜µ 
wτ is an orderly return for S. The
example of Figure 2.4, in which we have
µ ̸= τ,
q = α˜τ,
w = ˜µα,
w′ = α˜τ ˜µ, and q′ = α,
displays the orderly return α˜τ ˜µ˜αµτ for S. It serves as a counterexample to
the implication: if q˜µ 
wτ is an orderly return for S, then τ = µ.
S
N
Q
W
T
 M
T
 M
A
~
A
A
~
Figure 2.4. The medium represented above (cf. Problem 2.19) shows that, under
the conditions of Theorem 2.6.2, the hypothesis that q˜µ ewτ is an orderly return for
S does not imply τ = µ, with q = α˜τ, w = ˜µα, q′ = α, and w′ = α˜τ ˜µ.
2.6.3 Remark. In fact, each of the conditions (i)-(iv) in Theorem 2.6.2 im-
plies that, not only q˜µ 
wτ, but also various other messages are orderly return
(see Problem 2.8).
In 2.6.1, the concept of an orderly return was deﬁned with respect to
a particular state. The next deﬁnition and theorem concern a situation in
which a vacuous message is an orderly return with respect to everyone of the
produced states. In such a case, any token occurring in a return must have its
reverse at the exact ‘opposite’ place in the return. Several examples of such
situations are provided by the ‘hexagons’ in the permutohedron of Figure 1.4
on p. 6.

34
2 Basic Concepts
2.6.4 Deﬁnition. Let τ1 . . . τ2n be an orderly return for some state S. For any
1 ≤i ≤n, the two tokens τi and τi+n are called opposite. A return
τ1 . . . τ2n from S is regular if it is orderly and, for 1 ≤i ≤n, the message
τiτi+1 . . . τi+n−1 is concise for Sτ1 . . . τi−1.
2.6.5 Theorem. Let m = τ1 . . . τ2n be an orderly return for some state S.
Then the following three conditions are equivalent.
(i) The opposite tokens of m are mutual reverses.
(ii) The return m is regular.
(iii) For 1 ≤i ≤2n −1, the message τi . . . τ2n . . . τi−1 is an orderly return
for the state Sτ1 . . . τi−1.
Proof. We prove (i) ⇒(ii) ⇒(iii) ⇒(i). In what follows Si = Sτ0τ1 . . . τi for
0 ≤i ≤2n, so S0 = S2n = S.
(i) ⇒(ii). Since m is an orderly return, for 1 ≤j ≤n, there is only one
occurrence of the pair {τj, ˜τj} in m. Since ˜τj = τj+n, there are no occurrences
of {τj, ˜τj} in p = τi · · · τi+n−1, so it is a concise message for Si−1.
(ii) ⇒(iii). Since m is a regular return, any message p = τi · · · τi+n−1
is concise, so any token of this message has a reverse in the message q =
τi+n . . . τ2n . . . τi−1. Since p is concise and ℓ(q) = n, the message q is concise.
It follows that pq is an orderly return for the state Si−1.
(iii) ⇒(i). Since the message τi . . . τ2n . . . τi−1 is an orderly return for Si−1,
the messages q = τi+1 . . . τi+n−1 and q′ = τi . . . τi+n−1 are concise for the
states S′ = Si and N = Si−1, respectively, and produce the state Q = Si+n−1.
Likewise, the messages w = ˜τi−1 . . . ˜τ2n . . . ˜τi+n and w′ = ˜τi . . . ˜τ2n . . . ˜τi+n are
concise for the states N = Si−1 and S′ = Si, respectively, and produce the
state W = Si+n. It is clear that ℓ(q) + ℓ(w) + 2 = ℓ(q′) + ℓ(w′). By Theorem
2.6.2, τi+n = ˜τi.
2.6.6 Remark. Examples of media with returns that are not regular and
yet satisfy Conditions (i)-(iv) of Theorem 2.6.2 are easily constructed (see
Problem 2.13).
Following Ovchinnikov (2006), we now introduce a couple of general tools
for the study of media.
2.7 Embeddings, Isomorphisms and Submedia
2.7.1 Deﬁnition. Let (S, T) and (S′, T′) be token systems. A pair (α, β) of
1-1 functions α : S →S′, β : T →T′ such that
Sτ = T
⇐⇒
α(S)β(τ) = α(T)
(S, T ∈S, τ ∈T)
is called an embedding of the token system (S, T) into the token system (S′, T′).
If the functions α and β are bijections, then these two token systems are said

2.7 Embeddings, Isomorphisms and Submedia
35
to be isomorphic and the embedding (α, β) is referred to as an isomorphism
of (S, T) onto (S′, T′).
It is easily veriﬁed that, in such a case, if one of the token systems is a
medium, so is the other (cf. Problem 2.10). Recall that if (S, T) is a medium
and τ1, τ2 ∈T with Sτ1 = Sτ2 ̸= S for some S ∈S, then τ1 = τ2 by
Lemma 2.3.1(iii).
Thus, if (α, β) is an isomorphism of a medium onto another medium, we
have β(˜τ) = 
β(τ). Indeed, for a given τ there are two distinct states S and T
such that S˜τ = T. Then
α(S)β(˜τ) = α(T) ⇐⇒
S˜τ = T ⇐⇒Tτ = S ⇐⇒α(T)β(τ) = α(S) ⇐⇒α(S) 
β(τ) = α(T),
and so β(˜τ) = 
β(τ).
We extend the function β of an isomorphism (α, β) to the semigroup of
messages by deﬁning
β(τ1 . . . τn) = β(τ1) . . . β(τn)
for any message m = τ1 . . . τn. It is clear that the image of a concise message
by the function β is a concise message.
Take a medium (S, T) together with a subset Q of S consisting of at least
two states. Let T′ be the collection of all restrictions to Q of tokens in T. The
pair (Q, T′) is not necessarily a medium. The medium represented by its graph
in Figure 2.1 provides an example: taking the restrictions of the tokens to the
subset {S, T} does not yield a medium (cf. Problem 2.11).
We introduce the appropriate concepts for the discussion of such matters.
2.7.2 Deﬁnition. Let (S, T) be a token system and let Q be a nonempty
subset of S. For any τ ∈T, the function
τQ : Q →Q : S →SτQ =

Sτ
if Sτ ∈Q,
S
otherwise
is called the reduction1 of τ to Q. Note that the reduction of a token to a
subset Q of states may be the identity on Q. A token system (Q, TQ) where
TQ = {τQ}τ∈T \ {τ0} is the set of all reductions of tokens in T to Q diﬀerent
from the identity τ0 on Q is referred to as the reduction of (S, T) to Q. We
call (Q, TQ) a token subsystem of (S, T). If both (S, T) and (Q, TQ) are media,
then (Q, TQ) is a submedium of (S, T). (This deﬁnition implies that (S, T) is a
submedium of itself.)
1 The concept of ‘reduction’ is closely related to, but distinct from, the concept of
‘restriction’ of a function to a subset of its domain. The standard interpretation
of ‘restriction’ would not remove pairs (S, Sτ) in which S ∈Q but Sτ ∈(S \ Q).

36
2 Basic Concepts
2.7.3 Remarks. (a) The above deﬁnition readily implies that if (S, T) and
(Q, TQ) are two media, with (Q, TQ) a reduction of (S, T) to Q, then τQ = µQ
only if τ = µ, for any τQ and µQ in TQ.
(b) The image (α(S), β(T)) of a token system (S, T) under some embedding
(α, β) : (S, T) →(S′, T′) is not, in general, the reduction of (S′, T′) to α(S)
(cf. Problem 2.12). As shown by Theorem 2.7.4, however, this is true in the
case of media.
2.7.4 Theorem. Suppose that (α, β) is an embedding of a medium (S, T)
into a medium (S′, T′). Then the reduction (α(S), T′
α(S)) of (S′, T′) to α(S) is
isomorphic to (S, T).
Proof. For τ ∈T, we use the abbreviation β′(τ) = β(τ)α(S) (thus, the re-
duction of β(τ) to α(S)). Let Sτ = T ̸= S. Then α(S)β(τ) = α(T) for
α(S) ̸= α(T) in α(S). Hence β′ maps T into T′
α(S). Let us show that (α, β′) is
an isomorphism from (S, T) onto (α(T), T′
α(S)).
(i) β′ is onto T′
α(S). Suppose that τ ′
α(S) ̸= τ0 for some τ ′ ∈T′. Then, there
are P ̸= Q ∈S such that
α(P)τ ′
α(S) = α(P)τ ′ = α(Q).
Let Q = mP, where m is a concise message from P. We have
α(Q) = α(Pm) = α(P)β(m) = α(P)τ ′
implying, by Theorem 2.3.4, that β(m) = τ ′ since β(m) is a concise message.
Hence, m = τ for some τ ∈T. Thus, β(τ) = τ ′, which implies
β′(τ) = β(τ)α(S) = τ ′
α(S).
(ii) β′ is 1-1. Suppose that β′(τ) = β′(µ). Since β′(τ) and β′(µ) are tokens
on α(S) and (S′, T′) is a medium, we have β(τ) = β(µ) by Remark 2.7.3 (a).
Hence τ = µ.
(iii) Finally, for any S, T ∈S in and τ ∈T
Sτ = T
⇐⇒
α(S)β′(τ) = α(T)
because
Sτ = T
⇐⇒
α(S)β(τ) = α(T).
2.8 Oriented Media
In three of the ﬁve examples encountered in our ﬁrst chapter, the medium
was endowed with an ‘orientation’ dictated by the nature of the tokens. The
deﬁnition below speciﬁes the idea of an orientation.

2.8 Oriented Media
37
2.8.1 Deﬁnition. An orientation of a medium (S, T) is a partition of its set
of tokens into two classes T+ and T−respectively called positive and negative
such that for any τ ∈T, we have
τ ∈T+
⇐⇒
˜τ ∈T−.
A medium (S, T) equipped with an orientation {T+, T−} is said to be oriented
by {T+, T−} and tokens from T+ (resp. T−) are called positive (resp. negative).
Except when speciﬁed otherwise, an oriented medium (S, T) will be implicitly
taken to have its orientation denoted by {T+, T−}. The positive (resp. nega-
tive) content of a state S is the set S+ = S ∩T+ (resp. S−= S ∩T−) of its
positive (resp. negative) tokens. We deﬁne the two families
S+ = {S+ S ∈S}
and
S−= {S−S ∈S}.
Thus, S+ and S−denote the families of all the positive and negative contents,
respectively. Any message containing only positive (resp. negative) tokens is
called positive (resp. negative). We say that two messages have the same sign
when they are both positive, or both negative. A corresponding terminology
applies to tokens. Note that a ﬁnite medium (S, T) can be given 2|T|/2 diﬀerent
orientations (Problem 2.20).
2.8.2 Remark. Deﬁnition 2.7.1 is consistent with a situation in which two
oriented media (S, T) and (Q, L) are isomorphic but their respective orienta-
tions {T+, T−} and {L+, L−} do not match. For example, we can have an
isomorphism (α, β) of (S, T) onto (Q, L), such that τ ∈T+ while β(τ) ∈L−.
In fact, if (S, T) and (Q, L) are isomorphic, they would remain so under any
changes of orientations. There are cases in which a more demanding concept
is required.
2.8.3 Deﬁnition. Two oriented media (S, T) and (Q, L) are said to be sign-
isomorphic if there is an isomorphism (α, β) of (S, T) onto (Q, L) such that
β(T+) = L+ (and so β(T−) = L−).
Let (S, T) be a medium with an orientation {T+, T−}. Then any sub-
medium (Q, TQ) of (S, T) has an induced orientation {T+
Q, T−
Q} deﬁned from
{T+, T−} by the equivalence
τQ ∈T+
Q
⇐⇒
τ ∈T+.
Except when indicated otherwise, a submedium of an oriented medium is
implicitly assumed to be equipped with its induced orientation.
As a consequence of Theorems 2.4.3 and 2.4.5, we have:
2.8.4 Theorem. For any two states S and V of an oriented medium (S, T),
we have
S = V
⇐⇒
S+ = V +.

38
2 Basic Concepts
A similar result holds obviously for negative contents.
Proof. The necessity is trivial. Regarding the suﬃciency, note that if both
S+ = V + and S−= V −hold, then
S = S+ + S−= V + + V −= V ,
and so S = V by Theorem 2.4.5. It suﬃces thus to prove that S+ = V +
implies S−= V −. Suppose that S+ = V + and take any τ ∈T. We have
successively
τ ∈S−
⇐⇒
˜τ ∈T+ \ S+
(by Theorem 2.4.3)
⇐⇒
˜τ ∈T+ \ V +
(because S+ = V +)
⇐⇒
τ ∈V −
(by Theorem 2.4.3).
2.8.5 Theorem. If S and V are two distinct states in an oriented medium,
with Sm = V for some positive concise message m, then S+ ⊂V +.
Proof. If m is a concise positive message producing V from S, then 
m is
concise and negative, and S = V 
m, with S \ V = C(
m) by Theorem 2.4.4.
Thus, any token in S \ V is negative. This implies S+ ⊂V +.
2.9 The Root of an Oriented Medium
It is natural to ask how an orientation could be systematically constructed so
as to reﬂect properties of the medium. One principle for such a construction
is described below.
2.9.1 Deﬁnition. The root of an oriented medium is a state R such that,
for any other state S, any concise message producing S from R is positive. A
oriented medium having a root is said to be rooted. By abuse of language, we
sometimes say that the orientation of a medium is rooted (at the state S) if
the medium is rooted for that orientation and S is the root.
2.9.2 Theorem. In an oriented medium M, a state R is a root if and only if
R+ = ∅. Thus, M has at most one root and may in fact have no root.
Proof. (Suﬃciency.) Suppose that R is a state, with R+ = ∅. Let m be a
concise message such that Rm = S; thus, S
m = R. Recall that R\ S = C(
m)
by Theorem 2.4.4. Thus, if 
m contains a positive token, then R+ ̸= ∅. Thus,

m is negative, and so m is positive. Since this holds for any message m
eﬀective for R, the state R must be a root.

2.10 An Inﬁnite Example
39
(Necessity.) Suppose that R is a root. By Theorem 2.8.5 and the deﬁnition
of a root, we have R+ ⊂S+ for any state S ̸= R. If R+ contains some positive
token τ, then τ belongs to the contents of all the states. This implies that ˜τ
is not eﬀective for any state, and so is the identity function, which is not a
token by deﬁnition. We conclude that R+ must be empty.
For an example of a medium without a root, take the medium of Figure
2.1 with an orientation having the set of positive tokens T+ = {τ2, τ4, τ5}.
2.9.3 Theorem. For any medium (S, T) and any state R in S, there exists an
orientation making R the root of (S, T).
Proof. Deﬁne such an orientation by setting T−= R. Then, for any state
S ̸= R and any concise message m producing S from R, we have C(m) =
(S \ R) ⊆T+ by Theorem 2.4.4. Thus, m is positive.
The following type of oriented medium will play a role, in later develop-
ments, as a component of larger media.
2.9.4 Deﬁnition. A rooted medium N = (S, T), with |S| = n ≥3 for some
n ∈N, is a n-star if its root is adjacent to all the other n −1 states. (Thus,
such a medium has n −1 pairs of tokens.) We say that N is a star if there
exist some n ∈N such that N is a n-star.
The next section contains an example in which all the sets of positive
contents are uncountable. We have, however, the following result.
2.9.5 Theorem. For any medium, there exists an orientation ensuring that
the positive contents of all the states are ﬁnite sets. In particular, the states
of any rooted medium have ﬁnite positive contents.
Proof. Indeed, by Theorem 2.9.3 we can arbitrarily assign any state to be the
root R of the medium. We have R+ = ∅, and for any other state S, with
Rm = S for some concise message m, we have S+ = C(m) = S \ R, with
C(m) ﬁnite.
2.10 An Inﬁnite Example
In the medium of the example below, not only are the set of states and the set
of tokens inﬁnite, but so are the contents of all the states; in fact, all theses
states are uncountable.
2.10.1 Example. Let Pf(R) be the set of all ﬁnite subsets of R. We deﬁne
a medium (S, T) with S = {SX X ∈Pf(R), SX = R \ X} and T containing,
for any real number x, the pair τx, ˜τx of mutually reverse tokens deﬁned by

40
2 Basic Concepts
Sτx =

S ∪{x}
if S = SX for some X ∈Pf, with x ∈X,
S
otherwise;
(2.11)
S˜τx =

S \ {x}
if S = SX for some X ∈Pf, with x /∈X,
S
otherwise.
(2.12)
This example anticipates the main theme of Chapter 3 in which it is shown
that such token systems are indeed media (see, in particular, Theorem 3.3.4).
Clearly, S and T are uncountable, and so are the contents of all the states.
Moreover, suppose that we deﬁne now an orientation by having the positive
tokens and the negative tokens speciﬁed by (2.11) and (2.12), respectively.
Then, all the positive contents are uncountable, but all the negative ones
are ﬁnite. Essentially the same counterexample is obtained if one replaces
R by any set X of arbitrary cardinality, with the set of states deﬁned by
{SX X ∈Pf(X), SX = X \ X}. The exact role played by the ﬁnite sets is
discussed in details in Chapter 3.
2.10.2 Remark. As shown by Example 2.10.1, the positive contents may be
uncountable in some cases. Incidentally, in this example, we could take the root
to be the set R of all real numbers, and redeﬁne the orientation accordingly,
with the positive tokens becoming the negative ones and vice-versa. We obtain
the situation described in the second statement of Theorem 2.9.5, with the
positive contents being all the ﬁnite sets of real numbers.
2.11 Projections
The concept discussed in this section is due to Cavagnaro (2006). A projection
of a medium resemble a submedium in that it summarizes the structure.
The similarity stops there. A submedium focusses on a part of a medium
by choosing a subset of states and redeﬁning (reducing, cf. Deﬁnition 2.7.2)
the tokens to that subset. By contrast, a projection gives a macroscopic view
of a medium in the form of a new medium whose states are fundamentally
diﬀerent from the original ones.
The interest of such a construction is obvious. A particularly useful imple-
mentation arises in the context of learning spaces, a topic already mentioned
in Chapter 1 (Deﬁnition 1.6.1). We recall that, in this application of media
theory, a state of the relevant medium corresponds to a ‘knowledge state’ of
a student, that is, the set of problems that the student is capable of solving.
In the case of a placement test, determining the exact knowledge state of a
student may be costly, and locating the student in a suitable class of simi-
lar states may be suﬃcient to decide which courses the student is capable of
taking. The concept of a projection is then the appropriate tool.
To obtain a projection of a medium (S, T), one selects a ‘symmetric’ sub-
set U of its tokens (thus, τ ∈U if and only if ˜τ ∈U), which is used to deﬁne

2.11 Projections
41
an equivalence relation on S. The corresponding equivalence classes form the
states of the new medium under construction. The tokens in U are then re-
deﬁned so that they act on these equivalence classes on a manner that is
consistent with their action in (S, T).
2.11.1 Example. A good intuition of the concept of projection can be gath-
ered from studying the medium pictured by its graph in Figure 2.5 together
with one of its possible projections. This particular medium, which is rep-
resented at the bottom of the ﬁgure, has been encountered earlier: it is the
medium of all the linear orders on the set {1, 2, 3, 4} (cf. Figure 1.4, page 6).
So, each of the 24 linear orders is a state, and a token consists of the transpo-
sition of two adjacent element in a linear order. There are thus 12 =
4
2

× 2
tokens. Denoting this medium by (S, T), we deﬁne the symmetric subset of
tokens U = {τ13, τ31, τ23, τ32} ⊂T, with τij : xjiy →xjiy and x or y possibly
empty (so, 1234τ32 = 1324). These two pairs of tokens are represented by the
red and blue edges in the graph at the bottom of the ﬁgure.
We then gather in the same equivalence class two linear orders l and l′
whenever there is a concise message m producing l from l′ and such that
U ∩C(m) = ∅. For example, the two linear orders 4123 and 2134 are in
the same equivalence class because 4123τ21τ24τ14τ34 = 2134. (Note that, as a
consequence of Axiom [Mb], if n is another concise message producing l from
l′, then necessarily also U∩C(n) = ∅.) We obtain the four equivalence classes
represented by the graphs in each of the four boxes at the top of the ﬁgure.
Each of these boxes represents one of the new states and is a vertex of the
graph representing the projection. The red and blue edges are consistent with
the edges of the same color in the bottom graph, and represents the pairs of
tokens of the projection. It is clear that this graph represents a medium.
We now generalize this example and justify this construction.
2.11.2 Deﬁnition. Suppose that (S, T) is a medium. Let U be a nonempty,
symmetric subset of T, that is: τ ∈U if and only if ˜τ ∈U for any token τ ∈T.
Deﬁne a relation ∼on S by
S ∼T
⇐⇒
S △T ⊆T \ U .
(2.13)
2.11.3 Lemma. As deﬁned by (2.13), ∼is an equivalence relation on S.
Proof. The relation ∼is clearly reﬂexive and symmetric. The transitivity of
∼follows from the fact that, for any four sets X, Y , Z and W, we have
(X △Y ⊆W) ∧(Y △Z ⊆W)
=⇒
(X ∪Y ∪Z) \ (X ∩Y ∩Z) ⊆W
=⇒
X △Z ⊆W .
Indeed, suppose that S ∼T and T ∼R. Setting X = S, Y = T, Z = R and
W = T \ U, the above implication yield S △R ⊆T \ U, and so S ∼R.

42
2 Basic Concepts
23-32
23-32
31-13
31-13
3214
4213
1234
3241
1243
1324
1432
1423
1342
2134
2143
2413
2431
2341
2314
3421
3412
3142
3124
4123
4231
4132
4312
4321
Figure 2.5. Projection of the medium of the linear orders on the set {1, 2, 3, 4} by
the two pairs of tokens (τ13, τ31) and (τ23, τ32), with τij : nyxm →njim and n or
m possibly empty. The graph of the original medium is the permutohedron pictured
at the bottom of the ﬁgure, with the colors red and blue marking the two pairs of
tokens. the projection is pictured at the top (cf. Figure 1.4, page 6).
In the next deﬁnition, we start from a medium (S, T) and use the equiva-
lence relation ∼induced by some U ⊆T via (2.13) to gather the states into
equivalence classes that will form the states of a new medium. Notice that
any token in U, when it is eﬀective, always maps a state from one equivalence
class to one in some other equivalence class. With this in mind, we redeﬁne
the tokens in the set U so that they apply to the classes themselves, serving
thus as the tokens of the new medium and completing the construction.
2.11.4 Deﬁnition. Suppose that (S, T) is a medium. Let U be a nonempty
symmetric subset of T and let ∼be the equivalence relation on S induced by
U via (2.13). Deﬁne

2.11 Projections
43
[S] = {T ∈S S ∼T},
(S ∈S);
S|U = {[S] S ∈S},
τ|U : S|U →S|U : [S] →[S]τ|U,
(τ ∈U);
with
[S]τ|U =

[T]
if S ̸∼T and ∃(Q, W) ∈[S] × [T], Qτ = W,
[S]
otherwise,
(2.14)
T|U = {τ|U τ ∈U}.
We refer to the pair (S|U, T|U) as the projection of (S, T) under U.
2.11.5 Lemma. (i) For each τ ∈U, τ|U is a well-deﬁned function.
(ii) (S|U, T|U) is a token system.
(iii) 
τ|U = ˜τ|U for any τ ∈U.
Proof. (i) Suppose that Q, M ∈[S], with Qτ = R, Mτ = W, Q ̸∼R and
M ̸∼W. We have to show that [R] = [W]. Using Theorem 2.4.4 (with τ = m),
Qτ = R and Mτ = W yield
{τ} = R \ Q = 
W \ 
M ⊆R ∩
W.
(2.15)
Since Q ∼M, we deduce from (2.15) that R △
W = Q △
M ⊆T \ U ; so
R ∼W, and [R] = [W] follows.
(ii) This follows immediately from (i) and the fact that U ̸= ∅.
(iii) For τ ∈(T \ U) and S ̸∼T, we have
S 
τ|U = T ⇔Tτ|U = S ⇔Tτ = S ⇔S˜τ = Q ⇔S˜τ|U = T.
The other case is also straightforward.
Except for details of formulation, the next result is due to Cavagnaro
(2006).
2.11.6 Theorem. Let (S, T) be a medium and let U be a symmetric subset
of T. Then, the three following statements are true.
(i) The projection (S|U, T|U) of (S, T) under U is a medium.
(ii) For each state S ∈S such that |[S]| > 1, the token subsystem ([S], T[S])
of (S, T) is a submedium of (S, T).
(iii) Suppose that the set {T+, T−} is an orientation of (S, T). Deﬁne
T+
|U = {τ|U ∈T|U τ ∈T+} and T−
|U = {τ|U ∈T|U τ ∈T−}; then, the set
{T+
|U, T−
|U} is an orientation of the projection (S|U, T|U) of (S, T). We have
τ|U ∈T+
|U ⇐⇒
τ|U ∈T−
|U ⇐⇒τ ∈T+
(τ|U ∈T|U).

44
2 Basic Concepts
The orientations of (S, T) and (S|U, T|U) are thus consistent: the set U ‘imports’
the orientation of (S, T) into the projection (S|U, T|U).
Proof. (i) By Lemma 2.11.5 (ii), the pair (S|U, T|U) is a token system. We
prove that (S|U, T|U) satisﬁes [Ma] and [Mb].
[Ma]. Take any two distinct states [S] and [T] in the projection (S|U, T|U).
Let m be a concise message producing T from S in the medium (S, T).
Such a message exists by [Ma] applied to (S, T). We decompose the message
m in terms of the equivalence classes (forming states in S|U) visited along the
way. For some positive integer n, we obtain the decomposition form
Sm = S0m = S0m0τ1m1 . . . mn−1τnmn = T,
with
∪n
i=0 C(mi) ⊆(T \ U),
{τ1, . . . , τn} ⊆U
(2.16)
and
S0m0 = S1 ∈[S1] = [S],
(initial class)
S0m0τ1 = S2 ∈[S2] ̸= [S1]
(second class visited)
. . .
S0m0τ1m1 . . . τi−1mi−1τi = S2i ∈[S2i] ̸= [S2i−1],
(ith class visited)
. . .
S0m0τ1m1 . . . τnmn = S2n+1 ∈[S2n+1] = [T],
(ﬁnal class)
Note that all the component messages mi, 0 ≤i ≤n, are either concise or
empty. On the other hand, at least τ1 must exist because [S] ̸= [T]. This
decomposition makes it clear that the message m producing T from S in
(S, T) may be compacted, with its tokens τ1, . . . , τn in U redeﬁned by (2.14)
as a concise message p = τ1|U . . . τn|U producing [T] from [S] in the projected
token system (S|U, T|U). The conciseness of p follows from that of m: the
consistency of m entails that of p by Lemma 2.11.5(iii); none of the tokens in
p repeats itself because none of the tokens in m does; and the eﬀectiveness of
some τi ∈C(m) for some state S, implies that of τi|U for [S].
[Mb]. Let p = τ1|U . . . τn|U be a message that is stepwise eﬀective for some
state [S] in S|U. Inverting the construction performed above in the proof of
[Ma], there clearly exists a corresponding message m = m0τ1m1 . . . τnmn in
(S, T) such that each of the component messages mi, 0 ≤i ≤n is concise
or empty and the two inclusions of (2.16) are satisﬁed. So, m is stepwise
eﬀective for S. Suppose that p is ineﬀective for [S], that is, p is a return for
[S] in (S|U, T|U). Then m is a return for S in (S, T); we have
[S]τ1|U . . . τn|U = [S],
Sm0τ1m1 . . . τnmn = S.
This implies that m is vacuous because m satisﬁes [Mb] in (S, T). Since both
U and T \ U are symmetric, any token τi, 1 ≤i ≤n, must have its reverse in
{τ1, . . . , τn}. Thus, p must be vacuous by Lemma 2.11.5(iii). We have shown
that both [Ma] and [Mb] hold and so (S|U, T|U) is a medium.

Problems for Chapter 2
45
(ii) We verify that [Ma] and [Mb] also hold for any token subsystem
([S], T[S]) of (S, T). (We use the notation of 2.7.2.) Starting with [Ma], let
T and Q be two states of [S]. Thus, T ∼Q and by deﬁnition of ∼in (2.13),
there exists a concise message m = τ1 . . . τn in (S, T) producing T from Q,
with C(m) ⊆T \ U. We have thus Qτ1 . . . τi = Qi ∈[S] for 1 ≤i ≤n. This
implies that τ1[S] . . . τn[S] is a concise message of ([S], T[S]) producing T from
Q. So, Axiom [Ma] holds for (S, T). Finally, let m = τ1[S] . . . τn[S] be a mes-
sage of ([S], T[S]) which is a return for some Q ∈[S]. Then, the corresponding
message τ1 . . . τn of (S, T) is also a return for Q. As such, it is vacuous by [Mb]
applied to (S, T), and it follows that m must be vacuous for ([S], T[S]). As the
token subsystem ([S], T[S]) satisﬁes [Ma] and [Mb], it is a medium.
(iii) This is straightforward.
2.11.7 Remark. Our presentation of these results diﬀers from that in Cav-
agnaro (2006). He deﬁnes the concept of the ‘projection’ of a token system
(S, T) directly via an arbitrary equivalence relation ∼on the set of states.
Writing S∼for the partition of S induced by ∼, and [S] for the class of the
partition containing state S (as we do), he deﬁnes for each token τ ∈S a
relation τ ∗on S∼by the equivalence
[S]τ ∗[Q]
⇐⇒
∃S′ ∈[S] such that S′τ ∈[Q].
(2.17)
Note that the relations τ ∗deﬁned by (2.17) are not necessarily functions
(Problem 2.25). Writing T∼for the set of all the relations τ ∗diﬀerent from
the identity on S∼, he then investigates conditions on ∼entailing that the
pair (S∼, T∼) is a medium if the token system (S, T) is a medium.
Problems
2.1 Verify the facts (i), (ii) and (iii) mentioned in Deﬁnition 2.2.3.
2.2 Verify formally that, in a token system, any token has at most one reverse,
and that if ˜τ is the reverse of τ, then ˜˜τ = τ, that is, τ and ˜τ are mutual reverses.
2.3 Verify the independence of the two Axioms [Ma] and [Mb] of a medium
(Theorem 2.2.5 and Figure 2.2).
2.4 In the genetic mutation example of Chapter 1, construct the content of
all the states of the medium deﬁned by the graph of Figure 1.7.
2.5 Verify formally that the token system formed by the family of all strict
partial orders on a ﬁnite set Y satisﬁes Axioms [Ma] and [Mb] of a medium
(with the tokens of the two types: P →P ∪{xy} and P →P \ {xy}).

46
2 Basic Concepts
2.6 (Continuation.) Describe the contents of the states in this example, and
compare such a description with the standard deﬁnition of a binary relation.
2.7 (Continuation.) With the same deﬁnition of the tokens as in Problem
2.5, check whether the token system formed by the family of all strict weak
orders on a ﬁnite set is a medium. Which of the axioms is not satisﬁed? How
would you redeﬁne the tokens so that a medium obtains?
2.8 Verify that each the four conditions (i)-(iv) of Theorem 2.6.2 imply that,
not only q˜µ 
wτ, but various other messages are orderly returns (for S or N).
Find those messages and verify that they are indeed orderly returns.
2.9 Argue that, in a medium, the set of states and the set of tokens are either
both ﬁnite, or both inﬁnite.
2.10 Prove that if two token systems are isomorphic and one of them is a
medium, so is the other (cf. Deﬁnition 2.7.1).
2.11 For the medium deﬁned by its graph on Figure 2.1, describe exactly
what is obtained by limiting the set of states to {S, T}, and taking the re-
striction of the six tokens to that set. Why don’t we obtain a medium? Do we
still, at least, have a token system?
2.12 Show by a counterexample that the image (α(S), β(T)) of a token system
(S, T) under some embedding (α, β) : (S, T) →(S′, T′) is not necessarily the
reduction of (S′, T′) to α(S).
2.13 Construct some examples of media with orderly returns that are not
regular. At least one of these example should satisfy Conditions (i)-(iv) of
Theorem 2.6.2.
2.14 Use Theorem 2.4.4 to prove Theorem 2.3.4.
2.15 Prove that the length of any orderly return is even.
2.16 This is a continuation of Problem 1.14 of Chapter 1. Consider the token
system induced by a political map of the world, the countries representing the
states and each possible crossing of a single border representing a transforma-
tion. Which axioms of a medium are satisﬁed?

Problems for Chapter 2
47
2.17 A concise message m for S is called maximally concise for S if there is
no token τ such that mτ is concise for S. A state M is called a center2 of the
medium if all maximally concise messages for M have the same length. Does
a center necessary exist? Could there be more than one center in a medium?
2.18 Describe the contents of the states in the medium of Example 2.2.9.
2.19 Verify that the token system represented in Figure 2.4 is a medium.
2.20 Prove that a ﬁnite medium (S, T) can be given 2|T|/2 diﬀerent orienta-
tions.
2.21 Given an example of a non rooted medium with a countable number of
tokens and such that each of its states has a ﬁnite positive content. Can we
have a medium having some, but not all, of its states having ﬁnite positive
contents?
2.22 To Axioms [Ma] and [Mb] of a medium, add the Axiom [Mc] stating
that the tokens are commutative transformations. Is [Ma] consistent with [Ma]
and [Mb]? What are the consequences of a token system satisfying [Ma], [Mb]
and [Mc]?
2.23 Take any natural number n which is not a prime, and let n = ni1
1 . . . nik
k
be its prime factorization. Let Nn be the set of all numbers m ≤n which are
either prime or have a factorization involving the same prime numbers as n.
(Thus, if n = 18, then N18 = {2, 3, 6, 9, 12, 18}.) Deﬁne a set Tn = {τnj h} of
transformations on Nn by
τnj h : S →Sτnj h =

S × nj if (S/nh−1
j
) ∈N and (S/nh+1
j
) /∈N
S otherwise.
Is the pair (Nn, Tn) a medium? If so, what can you say about such a medium?
Construct the digraph for the case N24. Suppose that we add 1 to Nn and
redeﬁne Tn appropriately. What would be the answers to the above questions
then?
2.24 The Rubik’s Cube has been analyzed from the standpoint of group
theory (see for example, Joyner, 2002). Is it possible to formalize the trans-
formations of the cube in terms of the tokens of a medium? What would be
the states and the tokens?
2.25 Show by a counterexample that the relations deﬁned by (2.17) need not
be functions.
2.26 Prove part (iii) of the Projection Theorem 2.11.6.
2 See Chepoi et al. (2002) for a closely related concept.

3
Media and Well-graded Families
While the axioms of a medium do not require the sets of states or tokens
to be ﬁnite or otherwise limit their cardinality, they nevertheless impose an
essential ﬁniteness constraint on the structure. One goal of this chapter is to
clarify this issue. A second goal is to study the tight link existing between the
concept of a medium and certain families of sets called ‘well-graded.’ The two
goals are related.
We begin by observing that the content of the states in a medium exhibit a
strong structural property which can be surmised from examining the contents
of the ﬁve states in Example 2.2.4. These contents are recalled below:
S = {τ2, τ4, τ6},
V = {τ2, τ3, τ6},

W = {τ2, τ3, τ5},

X = {τ2, τ4, τ5},
T = {τ1, τ3, τ5}.
Notice that the contents of the two adjacent states S and V diﬀer by
exactly two tokens, namely τ3 and τ4, which are mutual reverses. A similar
observation can be made for any two adjacent states in the medium of Figure
2.1: for any two adjacent states Y and Z, we have1
|Y △Z| = d(Y , Z) = 2.
As asserted in Theorem 3.1.7 and as readily follows from Theorem 2.4.4,
this equation holds in fact for any medium. Deﬁnition 3.1.5 generalizes that
property.
3.1 Wellgradedness
We begin by recalling some basic set-theoretical facts. We omit the proofs
(cf. 1.8.1 and Problem 3.5 at the end of this chapter).
1 We recall that d(P, Q) denotes the symmetric diﬀerence distance between two
sets P and Q; cf. 1.8.1, Equation (1.5).

50
3 Media and Well-graded Families
3.1.1 Lemma. For any three sets P, Q and S, we have
P △Q ⊆(P △S) ∪(S △Q).
(3.1)
Consequently, if both P △S and S △Q are ﬁnite, so is P △Q; thus
d(P, Q) ≤d(P, S) + d(S, Q),
with moreover
d(P, Q) = d(P, S) + d(S, Q) ⇐⇒P ∩Q ⊆S ⊆P ∪Q.
(3.2)
3.1.2 Deﬁnition. Let F be a family of subsets of a set X, and let k be a
natural number. A k-graded path between two distinct sets P and Q (or
from P to Q) in F is a sequence P0 = P, P1, . . . , Pn = Q in F such that
d(Pi, Pi+1) = k for 0 ≤i ≤n−1, and d(P, Q) = kn. A 1-graded path is called
a tight path.
For any two distinct subsets P and Q of X, we refer to the set
[P, Q] = {S ∈F P ⊆S ⊆Q}
(3.3)
as the interval (of F) between P and Q. (Note that such intervals may be
empty.) Of particular interest in the sequel are the intervals of the form [P ∩
Q, P ∪Q] with P, Q ∈F.
For comments and references about these concepts, see Remark 3.1.6. Var-
ious facts about tight paths are gathered in the next two lemmas.
3.1.3 Lemma. Suppose that P0 = P, P1, . . . , Pn = Q is a tight path between
two sets P and Q in some family F of subsets of a set X. Then, for any two
indices i, j ∈{0, 1, . . . , n}, we have d(Pi, Pj) = |j −i|.
Proof. As the result trivially holds for i = j, we assume that i < j. By the
triangle inequality, we have
n = d(P0, Pn) ≤d(P0, Pi) + d(Pi, Pj) + d(Pj, Pn)
≤i + (j −i) + (n −j) = n.
The lemma follows.
3.1.4 Lemma. Suppose that P0 = P, P1, . . . , Pn = Q is a tight path between
two
sets
P
and
Q
in
some
family
F
with
∪F
=
X;
then,
for
0 ≤j ≤k ≤m ≤n and k ≤n −1, the following four properties hold:
(i)
Pk+1 =

either
Pk + {x} and x ∈Q \ P,
or
Pk \ {x} and x ∈P \ Q,
for some x ∈X;

3.1 Wellgradedness
51
(ii)
Pk ∈[Pj ∩Pm, Pj ∪Pm];
(iii)
d(Pj, Pm) = d(Pj, Pk) + d(Pk, Pm);
(iv)
Pi, Pi+1, . . . , Pj is a tight path between Pi and Pj.
Proof. By Lemma 3.1.3, we have |Pk △Pk+1| = d(Pk, Pk+1) = 1. Hence,
Pk △Pk+1 = {x} for some x ∈X, and (i) follows. Both (iii) and (iv) result
easily from Lemma 3.1.3, and (ii) is an easy consequence of (iii) and (3.2).
3.1.5 Deﬁnition. Let F be a family F of subsets of a set X. The family F is
k-graded if there is a k-graded path between any two of its sets. We say that
a 1-graded family is a well-graded or a wg-family (cf. Doignon and Falmagne,
1997; Falmagne and Doignon, 1997)2. Thus, if F is a wg-family, there is a
tight path between any two of its (distinct) sets. Mostly of interest here are
well-graded and 2-graded families. We discuss a few important examples of
well-graded families of relations in Chapter 5.
For any x ∈X, deﬁne
x∗= {y ∈X ∀P ∈F, y ∈P ⇔x ∈P}.
(3.4)
Thus, y ∈x∗if and only if x ∈y∗. Clearly, the family {x∗x ∈X} is a partition
of X. Notice that if ∪F ⊂X, then X\∪F is a class of that partition. The family
F is discriminative if, for all x ∈X, the subset x∗is a singleton. It is easily
shown that, for a family F, being well-graded and being discriminative are
independent conditions (cf. Problem 3.2). However, any wg-family F satisfying
∪F = X and | ∩F| ≤1 is discriminative (see Lemma 3.2.5). This does not
hold in general for k-graded families, with k ≥2.
3.1.6 Remark. By and large, our terminology follows Doignon and Falmagne
(1997). A concept closely related to that of tight path was introduced earlier
and independently by Restle (1959) (revisited in Luce and Galanter, 1963)
and Bogart and Trotter (1973), labelled linear arrays and linear sets, respec-
tively. We prefer to reserve the terms ‘line’ or ‘linear’ for cases where their
use may be dictated by a compelling geometric representation (cf. Problems
3.14, 3.15 and 3.16).
As an application of Deﬁnition 3.1.5 to media, we have the following.
3.1.7 Theorem. The content family S of the set of states S of a medium is
2-graded. Speciﬁcally, let S and V be any two distinct states, and let m =
τ1 . . . τn be a concise message producing V from S, with
S = S0, S0τ1 = S1, S1τ2 = S2, . . . , Sn−1τn = Sn = V.
(3.5)
Then, we have
2 This concept was introduced earlier under a diﬀerent name; see Kuzmin and
Ovchinnikov (1975), Ovchinnikov (1980).

52
3 Media and Well-graded Families
Si \ Si−1 = {τi} and
Si−1 \ Si = {˜τi}
(1 ≤i ≤n),
(3.6)
and d(S, V ) = 2n. Moreover, S is discriminative and satisﬁes ∩S = ∅.
Proof. Let S, V and m = τ1 . . . τn be as in the theorem. Invoking Theorem
2.4.4, we get
d(S, V ) = |(S \ V ) ∪(V \ S)| = |C(m)| + |C(
m)| = 2n,
(3.7)
and so d(S, V ) = 2n. By the deﬁnition of m, we have the sequence of states
listed in (3.5). Using Theorem 2.4.4 again, we see that their content must
satisfy (3.6) and so d(Si−1, Si) = 2 for 1 ≤i ≤n −1.
To prove that the S is discriminative, we must show that τ ∗̸= µ∗for any
two distinct tokens τ and µ. We have Sτ = V and Rµ = W, for some states
S ̸= V and R ̸= W. The case S = R and V = W is prevented by Lemma
2.3.1(iii). Suppose that S ̸= R and V = W. By [Ma], there is a concise message
n producing R from S. So, ˜τnµ is a return message for V , which is vacuous
by [Mb]. Since τ ̸= µ, we have τ ∈C(n), implying τ ∈R. As we also have
µ ∈V (which is distinct from R by Theorem 2.4.5), we get τ ∗̸= µ∗. In the
case S = R, V ̸= W, the same argument applied to ˜τ and ˜µ gives ˜τ ∗̸= ˜µ∗,
which yields again τ ∗̸= µ∗. The argument in the last remaining case (S ̸= R,
V ̸= W) is similar. The fact that ∩S = ∅follows easily from the deﬁnition of
the content of state.
A crucial relationship exists between oriented media and wg-families,
which is the focus of this chapter. The following construction will be useful
to clarify the relationship.
3.2 The Grading Collection
3.2.1 Deﬁnition. Let F be a family of sets, with |F| ≥2 and X = ∪F, and
suppose that, for any x ∈X \ ∩F, there is some Q and S in F satisfying
Q △S = {x}. The family F is then said to be graded. For such a family, let
G+
F and G−
F be two families of functions
G+
F = {γx x ∈X \ ∩F, γx : F →F},
G−
F = {˜γx x ∈X \ ∩F, ˜γx : F →F}
with the functions γx and ˜γx deﬁned, for every x ∈X by
γx : S →Sγx =

S + {x}
if x /∈S, S ∪{x} ∈F
S
otherwise,
(3.8)
˜γx : S →S˜γx =

S \ {x}
if x ∈S, S \ {x} ∈F
S
otherwise.
(3.9)
The family GF = G+
F ∪G−
F is called the grading collection of F.

3.2 The Grading Collection
53
The next three lemmas explore the concept of gradedness and its relation-
ship to wellgradedness.
3.2.2 Lemma. Any graded family F satisfying | ∩F| ≤1 is discriminative.
Proof. Take x ∈X = ∪F and y ∈x∗(cf. 3.1.5). If x ∈X \ ∩F, we have
S △P = {x} for some S, P ∈F with, say, S \ P = {x}. This implies x = y,
and so x∗= {x}. The case x ∈∩F follows from (3.4) and | ∩F| = 1.
3.2.3 Lemma. Let F be a graded family of sets with X = ∪F, and let GF be
its grading collection. Then, the following hold.
(i) The pair (F, GF) is a token system.
(ii) For any x ∈X \ ∩F, the tokens γx and ˜γx deﬁned by (3.8) and (3.9)
are mutual reverses.
(iii) The token system (F, GF) satisﬁes Axiom [Mb] of a medium, that is,
any return message is vacuous.
Proof. (i) We have |F| ≥2 by deﬁnition. Take any x ∈X \ ∩F. It is clear that
both γx and ˜γx are mapping F into itself. Neither of these two functions can
be the identity on F. Indeed, since F is graded, we have {x} = S △P for some
S, P ∈F. We can assume that {x} = S \ P; so
S = Pγx = Sγx
and
P = S˜γx = P ˜γx.
(3.10)
Thus (F, GF) is a token system.
(ii) It is clear that a result similar to (3.10) holds for any V, W ∈F with
{x} = V △W. Accordingly, the tokens γx and ˜γx are mutual reverses.
(iii) Suppose that m is a return message for some P ∈F; thus, we have
Pm = P. Let γx be any token of m, where γx and ˜γx are deﬁned as in (3.8)
and (3.9). Because m is ineﬀective for P, the reverse ˜γx of γx must also occur
in m. Each of γx and ˜γx may occur more than once. However, since m is
stepwise eﬀective for P, the occurrences of γx and ˜γx must alternate. Assume
that γx occurs in m before any ˜γx (the argument is similar in the other case).
This means that x /∈P. But then the last occurrence of ˜γx in m cannot be
followed by any γx (since otherwise, we would get x /∈P because of the ﬁrst
γx, and x ∈P because of the last one). Thus, the number of occurrences of γx
and ˜γx is the same. Since this holds for any γx occurring in m, the message
m is vacuous.
3.2.4 Convention. In the sequel, when a wg-family F is under discussion
without explicit mention of a ground set X such that S ∈F implies S ⊆X,
we implicitly assume this ground set to be X = ∪F.
3.2.5 Lemma. Any wg-family F is graded. Accordingly, a wg-family F is
discriminative if | ∩F| ≤1.

54
3 Media and Well-graded Families
Proof. Let F be the wg-family, with X = ∪F. Take any x ∈X \ ∩F. Thus,
there are two sets Q and S in F such that x ∈S \ Q. By deﬁnition of a
wg-family, there is a tight path Q0 = Q, Q1, . . . , Qn = S. Let Qj be the ﬁrst
set containing x in that tight path. We must have j ≥1 and Qj \{x} = Qj−1,
yielding Qj △Qj−1 = {x}. So, F is graded. The second statement results from
Lemma 3.2.2.
The following result is a foreseeable consequence of Theorems 3.1.7 and
Lemma 3.2.5, and a crucial tool.
3.2.6 Theorem. In an oriented medium (S, T), the family S+ of all positive
contents is well-graded and satisﬁes both ∪S+ = T+ and ∩S+ = ∅. It is thus
also discriminative.
Proof. Take any two distinct S+, V + ∈S+. From Theorem 3.1.7, we know
that for any concise message m = τ1 . . . τn producing V from S, with
S = S0, S0τ1 = S1, S1τ2 = S2, . . . , Sn−1τn = Sn = V,
(3.11)
we have
Si \ Si−1 = {τi} and
Si−1 \ Si = {˜τi}
(1 ≤i ≤n),
(3.12)
and moreover, d(S, V ) = 2n. The sequence (3.11) induces the sequence S+ =
S+
0 , S+
1 , . . . , S+
n = V +. By Theorem 2.4.3, exactly one of the τi and ˜τi in (3.12)
is positive. Thus, we have either S+
i \ S+
i−1 = {τi} ∈T+ or S+
i−1 \ S+
i = {˜τi} ∈
T+, and so d(S+
i , S+
i+1) = 1, for 1 ≤i ≤n, with d(S+, V +) = d(S, V )/2 = n.
For any τ + ∈T+, there are distinct S and T in S such that Sτ + = T; so
τ + ∈T, yielding ∪S+ = T+. The fact that the family S+ satisﬁes ∩S+ = ∅
results easily from Theorem 3.1.7. Using Lemma 3.2.5, we conclude that S+
is also discriminative.
By symmetry, a similar result clearly holds for the negative contents.
3.3 Wellgradedness and Media
The next theorem characterizes the graded families that represent media.
3.3.1 Theorem. Let F be a graded family of subsets of a set X = ∪F and
let GF be its grading collection. Then, the pair (F, GF) is an oriented medium
with orientation {G+
F, G−
F} if and only if F is well-graded.
Proof. (Suﬃciency.) We know by Lemma 3.2.3(i) that (F, GF) is a token sys-
tem. Axiom [Mb] holds by Lemma 3.2.3(iii). We show that the wellgraded-
ness of the family F implies Axiom [Ma]. For any distinct S, V ∈F with
d(S, V ) = n, there is a sequence of sets S0 = S, S1, . . . , Sn = V such that

3.3 Wellgradedness and Media
55
d(Si, Si+1) = 1 for 0 ≤i < n. This means that either Si+1 = Si + {xi} or
Si+1 = Si \ {xi} for some xi ∈X. In other terms, we have either Si+1γxi = Si
or Si+1˜γxi = Si. Thus, V = Sγ1 . . . γn, with either γi = γxi or γi = ˜γxi
for 1 ≤i ≤n. The message γ1 . . . γn is concise for S because d(S, V ) = n.
Since for any x ∈X, we have γx ∈G+
F and ˜γx ∈G−
F, the pair (G+
F, G−
F) is an
orientation of the medium (F, GF).
(Necessity.) Let M = (F, GF) be the medium of the theorem, with orien-
tation (G+
F, G−
F). Take any two distinct states S, V ∈F. From Axiom [Ma],
we know that there exists for some n ∈N a concise message m = γ1 . . . γn
producing V from S with
Sγ1 = S0γ1 = S1, . . . , Sn−1γn = V.
By the deﬁnition of the medium M, we have for each 1 ≤i ≤n some xi ∈X
such that either γi = γxi or γi = ˜γxi, which yields
Siγxi = Si + {xi} = Si+1
or
Si˜γxi = Si \ {xi} = Si+1.
(3.13)
Thus, d(Si, Si+1) = 1 for 1 ≤i ≤n. It remains to show that d(S, V ) = n. We
use induction. We already have shown that d(S, S1) = d(S0, S1) = 1. Suppose
that d(S, Si) = i for some 1 ≤i < n. As indicated in (3.13), we have two
possible ways of constructing Si+1 from Si.
Case 1. Si+1 = Si + {xi}. Then xi /∈S because otherwise there must be
some token γk = ˜γi, with k < i and Skγk = Sk \{xi}. This cannot be because
m is concise. So, we have d(S, Si+1) = i + 1.
Case 2. Si+1 = Si \ {xi}. A similar argument based on the conciseness
of m leads us to assert that xi ∈S ∩Si, yielding also d(S, Si+1) = i + 1.
Applying induction, the theorem follows.
3.3.2 Deﬁnition. For any wg-family of sets F with ∪F = X, we denote
by (F, WF) the oriented medium deﬁned by Theorem 3.3.1, writing thus
WF = GW. We call (F, WF) the representing medium of the family F, oriented
by {W+
F, W−
F}, with W+
F = G+
F and W−
F = G−
F deﬁned by (3.8) and (3.9).
3.3.3 Theorem. Any oriented medium (S, T) is sign-isomorphic to the rep-
resenting medium (S+, WbS+) of its family S+ of positive contents, with the
isomorphism (α, β) deﬁned by
α(S) = S+
(S ∈S),
(3.14)
and for each pair of tokens (τ, ˜τ) in T+ × T−
β(τ) = γτ
(γτ ∈W+
bS+)
(3.15)
β(˜τ) = ˜γ˜τ
(˜γ˜τ ∈W−
bS+).
(3.16)

56
3 Media and Well-graded Families
Proof. It is clear from (3.14) and Theorem 2.8.4 that α is a bijection of S onto
S+, and from (3.15) and (3.16)—via (3.8) and (3.9)—that β is a bijection of
T onto WbS+ satisfying β(T+) = W+
bS+ and β(T−) = W−
bS+. We must show that
(α, β) is an embedding of (S, T) into (S+, WbS+) (cf. Deﬁnition 2.7.1). For any
S ∈S and τ ∈T, we must consider four possible cases.
(i) τ ∈T+;
(a) τ /∈S+, S+ ∪{τ} ∈S+; by the deﬁnitions of α in (3.14) and β in
(3.15) and the deﬁnition of γτ in (3.8), we have
α(S)β(τ) = α(T) ⇐⇒S+γτ = T + ⇐⇒S+ + {τ} = T + ⇐⇒Sτ = T.
The last equivalence results from the deﬁnition of the positive content
of a state in a medium.
(b) τ ∈S+ or S+ ∪{τ} /∈S+; then, omitting the justiﬁcations which are
similar to those used in Case (i)(a), we have
α(S)β(τ) = α(T) ⇐⇒S+γτ = T + ⇐⇒S+ = T + ⇐⇒Sτ = T.
Similar arguments establish the two remaining cases, that is:
(ii) τ ∈T−;
(a) τ ∈S+, S+ \ {τ} ∈S+;
(b) τ /∈S+ or S+ \ {τ} /∈S+.
We leave the proof of these two cases as Problem 3.4.
An earlier version of this result which does not mention the ‘sign’ aspect of
the isomorphism, was established by Ovchinnikov and Dukhovny (2000) (see
also Ovchinnikov, 2006).
A number of important families of relations are wg-families and so lead to
media via Theorem 3.3.1. We have encountered one of them, the strict partial
order family, in Chapter 1. We discuss other important examples in Chapter 5.
In the case of an inﬁnite oriented medium, Theorem 3.3.3 gives a repre-
sentation in terms of a wg-family of inﬁnite sets. However, if no orientation is
given, a representation as a wg-family of ﬁnite sets is always possible. From
Theorems 2.9.5 and 3.3.3, we derive:
3.3.4 Theorem. Any medium (S, T) is isomorphic to the representing medium
of a well-graded subfamily F of Pf(S), with |F| = |S|.
As made clear by Example 2.10.1 and Remark 2.10.2, this result does not
assume any bound on the cardinality of S, T, or the contents of the states.
Proof. Using Theorem 2.9.5, choose an orientation {T+, T−} of (S, T) ensuring
that the positive contents of all the states are ﬁnite sets. By Theorem 3.2.6,
which holds for any oriented medium, S+ is a wg-family. Using Theorem 3.3.3,
we can assert that (S, T) is sign-isomorphic to (S+, WbS+); thus |S+| = |S|.

3.4 Cluster Partitions and Media
57
This section, culminating with Theorems 3.3.1, 3.3.3 and 3.3.4, stresses
the important role played by well-graded families in the study of media. In
the rest of this chapter we pursue the investigation of this concept. While the
power set P(X) of a ﬁnite set X is obviously well-graded, this is no longer
the case if X is inﬁnite. However, we can always partition P(X) into inﬁnite,
well-graded classes. In fact, such classes may be of arbitrary cardinality (for
a large enough set X), leading thus to the study of large media.
3.4 Cluster Partitions and Media
In Example 2.10.1, we introduced the well-graded subfamily of R containing
all the complements of ﬁnite subsets of R. The intersection of this subfamily
is clearly empty. There are other well-graded subfamilies of R, such as Pf(R),
or the subfamily
{SX SX = Q \ X, with X ∈Pf(Q)}.
In fact, there are uncountably many well-graded subfamilies of P(R) (see The-
orem 3.4.4). By Theorem 3.3.1, each of these well-graded families represents
an oriented medium. This prompts a systematic investigation of the collection
of the well-graded subfamilies of a set.
Except when indicated otherwise, we deal in this section with a set X of
arbitrary cardinality, and a subfamily F of P(X) which is graded in the sense
of Deﬁnition 3.2.1. Thus, by Lemma 3.2.2, F is discriminative if ∩F = ∅. We
recall that GF denotes the grading collection of F and that the pair (F, GF) is a
token system satisfying Axiom [Mb] (see Lemma 3.2.3(iii)). By Theorem 3.3.1,
Axiom [Ma] also holds if and only if (F, GF) is well-graded. Without loss of
generality, we suppose that ∪F = X.
Our study of the graded subfamilies of P(X) inducing media via Theorem
3.3.1 will rely on some geometrical concepts.
3.4.1 Deﬁnition. Let ▷◁be a binary relation on P(X) deﬁned by
P ▷◁Q
⇐⇒
(P △Q) ∈Pf(X).
We also write
⟨S⟩= {V ∈P(X) V ▷◁S}
(S ∈P(X)),
(3.17)
P(X)▷◁= {⟨S⟩S ∈P(X)}.
(3.18)
For any S ∈P(X), we refer to ⟨S⟩as a cluster (subfamily) of P(X), and
to P(X)▷◁as the cluster partition of P(X) (a term justiﬁed by the theorem
below). There is no ambiguity in the phrase ‘a cluster family F’ without
explicit mention of a ground set X because we can deﬁne X = ∪F. We have
then F = ⟨S⟩for some S ∈F, with ⟨S⟩deﬁned by (3.17).

58
3 Media and Well-graded Families
3.4.2 Remark. Our use of the term ‘cluster’ is consistent with its usage in
statistics, in which it refers to “a maximal collection of suitably similar objects
drawn from a larger collection of objets” (from the entry “Graph-theoretical
cluster analysis”, Matula, 1983, in the Encyclopedia of Statistical Sciences,
Vol. 3, p. 511). In particular, the function s(P, Q) = e−d(P,Q) on P(X)×P(X),
with d taking its values in the extended real line is a ‘similarity measure’ in
the sense of cluster analysis (cf. Harary, 1969).
3.4.3 Theorem. The following statements hold for any nonempty set X.
(i) The relation ▷◁is an equivalence relation on P(X) and P(X)▷◁is the
partition of P(X) induced by ▷◁;
(ii) ⟨∅⟩is the class of all the ﬁnite subsets of X;
(iii) ⟨S⟩is a wg-family for any S ∈P(X).
Much more can be said about the cluster subfamilies ⟨S⟩of P(X) (see for
example Theorems 3.4.5, 3.4.6, and especially 3.4.11).
Proof. (i) The transitivity of ▷◁results from Lemma 3.1.1. Since the relation
▷◁is symmetric and reﬂexive by deﬁnition, it is an equivalence relation and
its induced partition is clearly P(X)▷◁as deﬁned by (3.18).
(ii) We have obviously S ∈⟨∅⟩if and only if S ∈Pf(X).
(iii) Take any two distinct sets P and Q in ⟨S⟩. Then, by Lemma
3.1.1, we have d(P, Q) = n for some n ∈N. So, there exists a sequence
S0 = P, S1, . . . , Sn = Q, in P(X) with d(Si, Si+1) = 1 for 0 ≤i ≤n −1. It
suﬃces to show that all the sets Si are in ⟨S⟩. Since d(P, S1) = 1, we have
P ▷◁S1, which together with S ▷◁P and the transitivity of ▷◁established
in (i) yields S ▷◁S1 and so S1 ∈⟨S⟩. An induction completes the argument,
establishing the wellgradedness of ⟨S⟩. It is clear that ∩⟨S⟩= ∅.
3.4.4 Remarks. (a) The set P(R)▷◁is uncountable. Indeed, consider the un-
countable collection of families {⟨]−∞, α]⟩α ∈R \ Q} ⊂P(R)▷◁. If α ̸= β,
then ]−∞, α] △]−∞, β] is uncountable. Thus, a diﬀerent cluster of P(R)▷◁is
deﬁned by each α ∈R \ Q.
(b) Accordingly, by Theorem 3.4.3(iii), uncountably many clusters of P(R)
are wg-families.
3.4.5 Theorem. Take any S in P(X), and denote3 by d the restriction to ⟨S⟩
of the symmetric diﬀerence distance on P(X). The following two statements
hold:
(i) (⟨S⟩, d) is a metric space;
(ii) for any R, P and Q in ⟨S⟩, we have
d(P, R) + d(R, Q) = d(P, Q) ⇐⇒R ∈[P ∩Q, P ∪Q].
3 For simplicity, by abuse of notation.

3.4 Cluster Partitions and Media
59
Proof. (i) Since, d(P, Q) = |P △Q| is a nonnegative real number for any P
and Q in ⟨S⟩, we have d(P, Q) ≥0 with d(P, Q) = 0 if and only if P = Q,
and d(P, Q) = d(Q, P) (cf. 1.8.1). The triangle inequality follows from Lemma
3.1.1. So does (ii).
Thus, the equivalence relation ▷◁partitions the family P(X) into disjoint
metric spaces (⟨S⟩, d), with each class ⟨S⟩forming a cluster.
3.4.6 Theorem. Any two metric spaces (⟨S⟩, d) and (⟨S′⟩, d) are isometric.
Proof. If X is a ﬁnite set, then ⟨∅⟩is the only equivalence class; so ⟨S⟩=
⟨S′⟩= ⟨∅⟩and the conclusion of the theorem follows trivially. So we may
assume that X is an inﬁnite set and S′ = ∅. Deﬁne
α : ⟨S⟩→⟨∅⟩: Z →Z △S
(Z ∈⟨S⟩).
(3.19)
By the identity
(Z △S) △(Z′ △S) = Z △Z′,
(3.20)
α is an isometric embedding of ⟨S⟩into ⟨∅⟩.
For Y ∈⟨∅⟩, let Z = S △Y . Then
α(Z) = (S △Y ) △S = Y,
(3.21)
so α is a bijection.
By deﬁnition of a wg-family, there always exists a tight path between any
two sets (cf. 3.1.5). This concept evokes that of a concise message producing
a state from another in a token system. The following theorem speciﬁes the
connection between the two concepts.
3.4.7 Theorem. Let (F, GF) be a token system with X = ∪F and let P and
Q be two distinct sets in the family F. A message m = γ1γ2 · · · γn producing
Q from P is concise if and only if
P0 = P, P1 = P0γ1, . . . , Pn = Pn−1γn = Q
(3.22)
is a tight path between P and Q.
Proof. (Necessity.) We use induction on n = ℓ(m). Suppose that m = γ1.
Since γ1 is eﬀective and either γ1 = γx or γ1 = ˜γx for some x ∈X, we have
either Q = P +{x} or P = Q+{x}. Therefore d(P, Q) = 1. Now, let us assume
that the statement holds for all concise messages p with ℓ(p) = n −1 and
let m = γ1γ2 · · · γn be a concise message. Clearly, m1 = γ2 · · · γn is a concise
message producing Q from P1 = Pγ1 and ℓ(m1) = n−1. Suppose γ1 = γx for
some x ∈X. Since m is stepwise eﬀective and consistent, x ∈Q\P. Therefore,
with P1 = Pγ1 = P + {x}, we have
P1 ∈[P ∩Q, P ∪Q].
(3.23)

60
3 Media and Well-graded Families
Now suppose γ1 = ˜γx for some x ∈X. Because m is stepwise eﬀective and
consistent, we have x ∈P \ Q. With P1 = P \ {x}, we also get (3.23). Thus,
by Lemma 3.1.1, Formula (3.2), we obtain d(P, Q) = d(P, P1) + d(P1, Q). By
the induction hypothesis, (3.22) is a tight path from X to Y .
(Suﬃciency.) Let P0 = P, P1 = P0γ1, . . . , Pn = Pn−1γn = Q be a tight
path from P to Q for some message m = γ1 · · · γn. By deﬁnition, m is stepwise
eﬀective. To prove consistency, we use again induction on n. The statement
is trivially true for n = 1. Suppose it holds for all messages of length less
than n and let m be a message of length n. Suppose m is inconsistent. By
the induction hypothesis, this can occur only if either γ1 = γx, γn = ˜γx or
γ1 = ˜γx, γn = γx for some x ∈X. In the former case, x ∈P1, x /∈P ∪Q.
In the latter case, we have x /∈P1 with x ∈P ∪Q. In both cases, we obtain
P1 /∈[P ∩Q, P ∪Q], a contradiction.
From Theorem 3.4.7, we immediately derive:
3.4.8 Corollary. If (F, GF) is a medium, then F ⊆⟨S⟩for some S ∈P(X).
3.4.9 Remark. We will revisit the concept of a cluster family in Chapter 4,
where we consider a special case of Theorem 3.4.8. We prove there (cf. The-
orem 4.3.12), that the situation of a medium (F, GF) with the wg-family F
being equal to a cluster (rather than a subset of one, as in Theorem 3.4.8)
can arise if and only the medium is ‘complete’ in the sense deﬁned in 4.3.1.
We know (cf. Problem 2.11 in Chapter 2) that the reduction of a medium
is not necessarily a medium. The following results holds, however.
3.4.10 Theorem. (i) For any S ∈P(X) the token system (⟨S⟩, W⟨S⟩) is a
medium.
(ii) The reduction of the medium (⟨S⟩, W⟨S⟩) to a family F ⊆⟨S⟩is a
medium if and only if F is a wg-family.
Proof. (i) For a given S ∈P(X), the cluster family ⟨S⟩is a wg-family of
subsets of X (cf. Theorem 3.4.3(ii)). Hence, by Theorem 3.3.1, (⟨S⟩, W⟨S⟩) is
a medium.
(ii) By Deﬁnition 2.7.2, the reduction of (⟨S⟩, W⟨S⟩) to F is the token
system (F, GF). The statement of the theorem follows from Theorem 3.3.1.
3.4.11 Theorem. For any two S′, S ∈P(X), the media (⟨S′⟩, W⟨S′⟩) and
(⟨S⟩, W⟨S⟩) are isomorphic. In particular, any medium (⟨S⟩, W⟨S⟩) is isomor-
phic to the medium (Pf(X), WPf(X)) of all ﬁnite subsets of X.
Proof. It suﬃces to consider the case when S′ = ∅. We deﬁne as follows the
isomorphism (α, β) of (⟨∅⟩, W⟨∅⟩) onto (⟨S⟩, W⟨S⟩):

3.4 Cluster Partitions and Media
61
α : Pf(X) →⟨S⟩: P →P △S,
β : WPf(X) →W⟨S⟩: γ →β(γ),
β(γ) : ⟨S⟩→⟨S⟩: T →Tβ(γ)
with
Tβ(γ) =

T \ {x}
if (x ∈S and γ = γx) or (x /∈S and γ = ˜γx),
T ∪{x}
if (x /∈S and γ = γx) or (x ∈S and γ = ˜γx).
(3.24)
Clearly, α and β are bijections. We prove the implication
Pγ = Q
=⇒
α(P)β(γ) = α(Q).
For each of the four possibilities of (3.24), we have the two alternative x ∈P
and x /∈P, so we have eight cases to consider.
Case 1. γ = γx, x ∈S.
(a) x ∈P. Then, Q = P and
α(P)β(γ) = (P △S) \ {x} = P △S = Q △S.
(b) x /∈P. Then, Q = P ∪{x} and
α(P)β(γ) = (P △S) \ {x} = P △(S \ {x}) = Q △S.
Case 2. γ = γx, x /∈S.
(a) x ∈P. Then, Q = P and
α(P)β(γ) = (P △S) ∪{x} = P △S = Q △S.
(b) x /∈P. Then Q = P ∪{x} and
α(P)β(γ) = (P △S) ∪{x} = Q △S.
Case 3. γ = ˜γx, x ∈S.
(a) x ∈P. Then, Q = P \ {x} and
α(P)β(γ) = (P △S) ∪{x} = Q △S.
(b) x /∈P. Then, Q = P and
α(P)β(γ) = (P △S) ∪{x} = P △S = Q △S.
Case 4. γ = ˜γx, x /∈S.
(a) x ∈P. Then, Q = P \ {x} and
α(P)β(γ) = (P △S) \ {x} = Q △S.
(b) x /∈P. Then, Q = P and
α(P)β(γ) = (P △S) \ {x} = P △S = Q △S.
The converse implication: α(P)β(γ) = α(Q) only if Pγ = Q, is established
along the same lines and is left as Problem 3.8.
The following result follows readily from Corollary 3.4.8, and Theorems
3.4.10 and 3.4.11.

62
3 Media and Well-graded Families
3.4.12 Theorem. The representing medium (F, WF) of any wg-family F is
isomorphic to a submedium of the medium (Pf(X), WPf(X)) of all ﬁnite sub-
sets of X = ∪F.
3.4.13 Remark. Theorem 3.4.12 provides another route to the representa-
tion Theorem 3.3.4. Notice that a medium that is both inﬁnite and oriented
may have inﬁnite positive contents of all its states. Consider, for instance, the
wg-family of subsets of Z in the form ]−∞, n] (cf. Problem 3.20(ii)).
3.5 An Application to Clustered Linear Orders
The representation theorems of this chapter, combined with the concept of
a cluster partition, provide powerful tools for uncovering and classify media.
We illustrate applications of these tools here by constructing a medium rep-
resentation of the family of all the strict linear orders (cf. 1.8.3) contained in
a cluster ⟨L0⟩, where L0 is a particular strict linear order on a ground set X.
Such a representation proceeds by ﬁrst constructing a wg-family, along the
lines of Theorem 3.3.14.
This example is interesting for two reasons. One is that the family of all
strict linear orders on a set is never well-graded; rather, in the ﬁnite case for
example, it is 2-graded (Falmagne, 1997). This fact oﬀers a more direct way of
constructing a medium representation of a set of strict linear orders, in which
the tokens consists of transpositions of pairs of adjacent elements in a strict
linear order. These two media are in fact isomorphic (for a given cluster). We
consider this topic at the end of this section.
The second reason is that, while by Theorem 3.4.11 any two clusters ⟨S1⟩
and ⟨S2⟩deﬁne isomorphic media, such an isomorphism does not necessarily
hold for media induced by families of strict linear orders in diﬀerent clusters.
In other words, if L1 and L2 are strict linear order taken in diﬀerent clusters,
and L1 and L2 are the set of strict linear order at ﬁnite distances of L1 and L2,
respectively, then the media induced by L1 and L2 along the lines sketched
above are not necessarily isomorphic (see Problem 3.17).
We prepare our construction by a few lemmas. We recall that x is said to
cover y in some strict linear order L if yLx and there is no z such that yLzLx
(cf. 1.8.3, and Problem 1.8 in Chapter 1)5.
3.5.1 Lemma. If L is a strict linear order, then (L \ {yx}) ∪{xy} is also a
strict linear order if and only if x covers y in L.
4 For a diﬀerent approach involving a countable set of strict linear orders, see
Problem 3.9 and Ovchinnikov (2006).
5 There are strict linear orders in which there are no x, y such that x covers y. In
other words, the covering relation is empty. Consider the set R of all real numbers
equipped with its natural strict linear order (see Example 3.5.4 (a)).

3.5 An Application to Clustered Linear Orders
63
Proof. (Necessity.) Suppose that L′ = (L\{yx})∪{xy} is a strict partial order.
If yLzLx for some z, then also zL′x and yL′z, yielding yL′x by transitivity.
So, both yL′x and xL′y, contradicting the asymmetry of L′.
(Suﬃciency.) Suppose that x covers y in L. As L′ is asymmetric and
connected by deﬁnition, we only have to verify its transitivity. Assume that
uL′vL′w. We have to verify three cases.
1. uv = yx, so uLv with vL′w yielding vLw because w ̸= x and w ̸= y; we
obtain uLw by the transitivity of L, and so uL′w.
2. vw = yx, so vLw with uL′v yielding uLv because u ̸= x and v ̸= y; we
obtain again uLw and thus uL′w.
3. uLv, uv ̸= yx and vLw, vw ̸= yx; then uLw by the transitivity of L, and
uw ̸= yx because x covers y in L; so uL′w.
This completes the proof.
3.5.2 Lemma. Suppose that L and L′ are two distinct strict linear orders on
a set X, with L △L′ ﬁnite. Then the two following conditions hold:
(i) there exists xy ∈L \ L′ such that y covers x in L; in fact, we have a
ﬁnite sequence x1, . . . , xn in X such that xi+1 covers xi in L for 1 ≤i ≤n −1
and we have
x1Lx2L . . . Lxn−1Lxn
and
xnL′xn−1L′ . . . L′x2L′x1,
(3.25)
L △L′ = {xixj ∈X 1 ≤i ≤n, 1 ≤j ≤n, i ̸= j};
(3.26)
(ii) either both L and L′ well-order X, or neither of them does.
Proof. (i) Because L and L′ are connected and asymmetric,
xy ∈L △L′ ⇒(xLy ⇔yL′x).
As L △L′ is ﬁnite, so is Y = {x ∈X xy ∈L △L′, y ∈X}; say |Y | = n. The
restriction of L to Y is a strict linear order on a ﬁnite set, whose elements can
be labeled x1, . . . , xn in such a way that (3.25) holds with xi+1 covering xi in
L, 1 ≤i ≤n −1, and (3.26) follows from the labelling of the elements in Y .
(ii) Using (i), we get that if L is a well-ordering of X, so must be L′. We
leave as Problem 3.12 the construction of two strict linear orders some set Z,
at ﬁnite distance from each other, neither of them well-ordering Z.
A particular construction will be used, which deserves a name.
3.5.3 Deﬁnition. Let P(Y)▷◁be the cluster partition of a set Y, and let F be
a family of subsets of Y. For any S ∈F, we call ⟨S⟩∩F the trace of F on the
cluster ⟨S⟩. In particular, if Y = X × X for some set X, and L is the set of all
linear orders on X, then for any L ∈L, we call ⟨L⟩∩L a linear trace. It is
clear from Lemma 3.5.2(ii) that if L is a well-ordering of Y then the trace of
L on ⟨L⟩only contains well-orderings. Such a trace is called a well-ordering
trace.

64
3 Media and Well-graded Families
3.5.4 Examples. (a) A linear trace may be reduced to a single linear order.
Take the set R of real numbers, and let P(R × R)▷◁the cluster partition of
the family of all the relations on R. Denote by < the natural order of the
reals and by L the set of all strict linear orders on R. The trace of L on ⟨<⟩
contains a single linear order, namely <.
(b) On the other hand, the trace of L on ⟨W⟩, where W is a well-ordering
of R is uncountable (see Problem 3.13).
(c) Diﬀerent well-orderings on the same set may deﬁne diﬀerent well-
ordering traces. Consider the set N of natural numbers with its natural order-
ing < and the ordering
1 <′ 3 <′ . . . <′ 2n + 1 < . . . <′ 2 <′ 4 <′ . . . <′ 2n <′ . . .
(Thus, the odd numbers precede all the even numbers in <′.) Both < and <′
are well-orderings of N. Write LN for the set of all strict linear orders on N.
The traces of LN on ⟨<⟩and ⟨<′⟩are disjoint. These traces are inﬁnite, and
equipollent (see Problems 3.10 and 3.11 in this connection).
We shall also need the following fact.
3.5.5 Lemma. Let P, Q and R be antisymmetric, connected binary relations
on the same set. Then
P ∩R = Q ∩R
⇐⇒
P = Q.
Proof. Suppose P ∩R = Q ∩R and let xy ∈P. If xy ∈R, then xy ∈Q.
Otherwise, yx ∈R. Since yx /∈P, we have yx /∈Q implying xy ∈Q. Thus
P ⊆Q. By symmetry, P = Q.
As the main theorem of this section , we have:
3.5.6 Theorem. Let L be the set of all strict linear orders on a set X, and
take any L0 in L. Suppose that L0 = ⟨L0⟩∩L, where ⟨L0⟩is a cluster of
P(X × X) and L0 is the linear trace of L on ⟨L0⟩, contains more than one
linear order, and deﬁne the function
α : L0 →⟨L0⟩: L →L ∩L0 .
(3.27)
Then, α is a 1-1 mapping of the set of linear orders L0 onto a wg-family of
partial orders, all included in L0.
In particular, if X is a ﬁnite set, then L0 = L and the function α deﬁned
by (3.27) is a 1-1 mapping of the set L of all the strict linear orderings on X
onto a well-graded family of partial orders included in L0. As we have seen
in Example 3.5.4 (a), L0 may be reduced to a single strict linear order and
the function α is then trivial. But nontrivial cases are easy to come by (see
Examples 3.5.4 (b) and (c)).

3.5 An Application to Clustered Linear Orders
65
Proof. From Lemma 3.5.5, we know that α is a one-to-one mapping from L0
onto the set of partial orders α(L0) ⊆L0. Let P, P ′ be two distinct partial
orders in α(L0) and L, L′ be the corresponding strict linear orders. Using
Lemma 3.5.2(i), we can assert the existence of a pair xy ∈L such that y
covers x and xy /∈L′. By Lemma 3.5.1, L′′ deﬁned by
L′′ = (L \ {xy}) ∪{yx} ∈L0
is a linear order. Then
P ′′ = L′′ ∩L0 = ((L ∩L0) \ (L0 ∩{xy})) ∪(L0 ∩{yx})
=

P \ {xy},
xy ∈L0,
P ∪{yx},
xy /∈L0,
where xy ∈P if xy ∈L0 and yx /∈P if xy /∈L0. Hence, P ′′ ̸= P and
d(P, P ′′) = 1. Clearly, L ∩L′ ⊆L′′ ⊆L ∪L′. Therefore
P ∩P ′ = L ∩L′ ∩L0 ⊆P ′′ = L′′ ∩L0 ⊆(L ∪L′) ∩L0 = P ∪P ′,
that is, P ′′ ∈[P ∩P ′, P ∪P ′]. Invoking Theorem 3.4.5(ii), we obtain
d(P, P ′) = d(P, P ′′) + d(P ′′, P ′) = 1 + d(P ′′, P ′)
and the result follows by induction.
As announced, we ﬁnally obtain the medium representation:
3.5.7 Theorem. Let X, L, L0, L0 and α be as in Theorem 3.5.6. The pair
(α(L0), Wα(L0)), with the set of tokens Wα(L0) as in 3.3.2, is a medium with
orientation (W+
α(L0), W−
α(L0)) and tokens deﬁned, for any P = L∩L0 ∈α(L0)
and xy ∈L0, by
ρxy : P →Pρxy =

P + {xy},
if P + {xy} ∈α(L0),
P,
otherwise,
(3.28)
for ρxy ∈W+
α(L0), and
˜ρxy : P →P ˜ρxy =

P \ {xy},
if P \ {xy} ∈α(L0),
P,
otherwise,
(3.29)
for ˜ρxy ∈W−
α(L0).
Indeed, since α(L0) is a well-graded family of subsets of L0, we can ap-
ply Theorem 3.3.1 and take α(L0) to be the set of states of the medium
(α(L0), Wα(L0)) (with Wα(L0) = Gα(L0), cf. Deﬁnition 3.3.2), equipped with
the orientation (W+
α(L0), W−
α(L0)) and tokens deﬁned by (3.28) and (3.29).
Simple examples show that α(L0) is a proper subset of the set of all strict
partial orders contained in L0. This subset is characterized in the following
proposition.

66
3 Media and Well-graded Families
3.5.8 Theorem. Let L be a strict linear order on a set Z and P ⊆L be a
strict partial order. Suppose also that P = L ∩L′ for some relation L′ on Z.
Then P ′ = L \ P is a strict partial order if and only if L′ is a strict linear
order.
Proof. (Suﬃciency.) Suppose P = L ∩L′. It suﬃces to prove that P ′ = L \ P
is transitive. Let xy, yz ∈P ′; then xz ∈L. Suppose xz /∈P ′. Then xz ∈P,
implying xz ∈L′. Since xy, yz ∈P ′, we have xy /∈L′ and yz /∈L′, yielding
yx, zy ∈L′, which implies zx ∈L′, a contradiction.
(Necessity.) Suppose now that P ⊆L and P ′ = L \ P are strict partial
orders. It is easily veriﬁed (cf. Problem 3.19) that
P = L ∩L′
⇐⇒
L′ = P ∪P ′−1.
(3.30)
We have to show that L′ is a strict linear order. It is asymmetric by its
deﬁnition in the r.h.s. of (3.30). To establish its connectedness, notice that
the set {P ∪P ′−1, P −1, P ′} is a partition of (Z × Z) \ IZ, where IZ is the
identity on Z. Thus xy /∈L′ implies xP −1y or xP ′y; so, yPx or yP ′−1x, and
in either case yL′x.
It remains to show that L′ is transitive. Suppose that xL′yL′z. It suﬃces
to consider only two cases:
(i) xPy, yP ′−1z. Since P −1∩P ′−1 = ∅, we must have x̸= z, with moreover
xz ∈{P ∪P ′−1, P −1, P ′}. If xP ∪P ′−1z, then xL′z. Suppose that xP −1z;
thus, zPx, yielding zPy since xPy. We obtain yP −1z, contradicting yP ′−1z
(because P −1∩P ′−1 = ∅). Finally, xP ′z together with yP ′−1z yields xP ′zP ′y,
and so xP ′y, contradicting xPy (again P −1 ∩P ′−1 = ∅).
(ii) xP ′−1y, yPz, with as above x ̸= z. Again, we must have xz ∈{P ∪
P ′−1, P −1, P ′}. Arguments similar to those used in Case (i) give xP ∪P ′−1z,
and thus xL′z, as the only valid possibility.
We illustrate Theorem 3.5.7 by an example in the ﬁnite case; we have thus
L0 = L ⊆⟨L0⟩= ⟨∅⟩(see also Example 1.3.1).
3.5.9 Example. Let X = {1, 2, 3}. For simplicity, we recode the 3! = 6 strict
linear orders on X as 3-tuples:
L0 →123,
L1 →213,
L2 →231,
L3 →321,
L4 →312,
L5 →132.
These triples are represented by the six vertices in the diagram6 of Figure 3.1
(which is also, after an appropriate relabeling of the vertices, the adjacency
graph of the medium).
6 One can compare this diagram with the diagram shown in Figure 5 in Falmagne
(1997).

3.5 An Application to Clustered Linear Orders
67
123
213
231
321
312
132
Figure 3.1. The diagram of L for |X| = 3.
The strict partial orders forming the wg-family α(L0) are included in L0:
L0 = {12, 13, 23},
L1 ∩L0 = {13, 23},
L2 ∩L0 = {23},
L3 ∩L0 = ∅,
L4 ∩L0 = {12},
L5 ∩L0 = {12, 13}.
Note that the graph in Figure 3.1 is the graph of the permutohedron Π2
(see, for instance Ziegler, 1995). The graph depicted in Figure 1.3.1 is the
graph of the permutohedron Π3.
3.5.10 An Unoriented Representation of Linear Orders. We construct
here a medium representation of L0 which is is not oriented. In fact, no natu-
ral representation is available. This representation can nevertheless be shown
to be isomorphic to the one spelled out in Theorem 3.5.7 (Problem 3.18).
Let us rewrite (3.28) explicitly as
(L ∩L0)ρxy =

(L ∩L0) + {xy},
if (L ∩L0) + {xy} ∈α(L0),
L ∩L0,
otherwise,
=

(L + {xy}) ∩L0,
if (L + {xy}) ∩L0 = L′ ∩L0,
L ∩L0,
otherwise,
where L′ is some well-ordering of X. Since yx /∈L0, we have
(L + {xy}) ∩L0 = ((L \ {yx}) + {xy}) ∩L0 = L′ ∩L0.
(3.31)
As x covers y in L, Lemma 3.5.1 implies that L′ = (L \ {yx}) + {xy} is a
strict linear order. Equation (3.31) suggests a diﬀerent kind of token directly
transforming a strict linear order in L0 into another. We deﬁne for xy ∈L0
τxy : L0 →L0 : L →Lτxy
=

(L \ {yx}) + {xy} if x covers y in L,
L
otherwise.
(3.32)

68
3 Media and Well-graded Families
Notice that, for xy ∈L0 and with ρxy deﬁned by (3.28),
(L ∩L0)ρxy = Lτxy ∩L0.
(3.33)
A similar argument relying on (3.29) shows that, again for xy ∈L0,
(L ∩L0)˜ρxy = Lτyx ∩L0 = L˜τxy ∩L0.
(3.34)
We obtained the set of tokens T = {τxy, ˜τxy}xy∈L0 by ‘pulling back’ to-
kens from the set Wα(L0). The medium (L0, T) is isomorphic to the medium
(α(L0), Wα(L0)) (Problem 3.18). It is the ‘linear medium’ introduced in Fal-
magne (1997).
3.6 A General Procedure
The steps used above to construct the linear medium (L0, T) from the medium
(α(L0), Wα(L0)) exemplify a general procedure, based on the concept of media
isomorphism, for constructing new media from old ones. Suppose that X is
a set of features endowed with some particular ‘transformation’ structure S
which is not necessarily that of wg-family of sets. Suppose also that there is
a medium (S, T) which models the set X and its structure S in the sense that
there is a bijection α : X →S and that the tokens from T may be regarded as
representing, in a natural way, the transformation occurring in (X, S). Let us
deﬁne a family T′ of functions τ ′ : X →X by ‘pulling back’ tokens from T:
τ ′ = α ◦τ ◦α−1,
and let β : τ ′ →τ. We have the following proposition:
3.6.1 Theorem. The pair (α, β) is an isomorphism from the token system
(X, T′) onto the medium (S, T). Accordingly7, the token system (X, T′) is a
medium.
We shall use this construction in our deﬁnition of a medium on the family
of all the weak orders on a ﬁnite set in Chapter 9.
Problems
3.1 Which parts of Lemma 3.1.4, if any, hold for a k-graded path? Prove
your answer.
7 See Problem 2.10 in Chapter 2.

Problems for Chapter 3
69
3.2 Let F be a family of subsets of a set X = ∪F. Verify that the family
{x∗x ∈X} is a partition of X (cf. Deﬁnition 3.1.5). Prove that the two
conditions: (i) F is well-graded, and (ii) F is discriminative, are independent.
From Lemma 3.2.5, we know that any wg-family F satisfying ∩F = ∅is
discriminative. Show by a counterexample that this result does hold in general
for k-graded families, with k ≥2. In this connection, ponder Theorem 3.1.7,
however.
3.3 In which of the examples considered in Chapter 1 is the content family
2-graded (cf. Deﬁnition 3.1.5)?
3.4 Prove the two remaining cases in Theorem 3.3.3.
3.5 Prove Lemma 3.1.1. Especially, verify Formula (3.2).
3.6 In the study of the well-graded families of subsets of a set X, why is there
no loss of generality in formulating the hypotheses ∩F = ∅and ∪F = X?
3.7 Verify the identity (3.20) and also the second equation in (3.21).
3.8 Verify the converse implication α(P)β(γ) = α(Q) only if Pγ = Q in the
proof of Theorem 3.4.11.
3.9 Let < be the natural linear order on N. A relation L on N is a locally
ﬁnite linear order if there exists n ∈N such that
pLq
⇐⇒
p < q,
(p, q > n).
We write then Ln = L and L0 = <. Prove that the family {Ln n = 0, 1, . . .}
of locally ﬁnite linear orders on N is well-graded (cf. Ovchinnikov, 2006).
3.10 Prove that the two well-ordering traces of Example 3.5.4 are equipollent.
3.11 (Continuation.) Generalizing this example, show that there are count-
ably many well-ordering traces of N on the clusters of P(N × N).
3.12 Find a set Z and two strict linear orders on Z at ﬁnite distance from
each other, neither of them well-orders Z.
3.13 Prove that the trace of the set L of all strict linear orders on R on ⟨W⟩,
where W is a well-ordering of R is uncountable.

70
3 Media and Well-graded Families
3.14 For any three P, Q and S in P(R), deﬁne the ternary relation
⟨PSQ⟩⇔S ∈[P, Q],
(3.35)
with [P, Q] as in (3.3). Consider the following axioms formalizing a ‘collinear
betweenness’ relation for triples of points (cf. Prenowitz and Jordan, 1965):
[B1] (Symmetry Property) ⟨PSQ⟩⇒⟨QSP⟩.
[B2] (Anticyclic Property) ⟨PSQ⟩⇒¬⟨QPS⟩.
[B3] (Linear Coherence) P, Q and S are collinear if and only if one of
the following three hold: ⟨PSQ⟩or ⟨PQS⟩or ⟨SPQ⟩.
[B4] (Separation Property) Suppose that T colline and is distinct from
P, Q and S. Then ⟨PTQ⟩implies ⟨QTS⟩or ⟨PTS⟩, but not both.
[B5] (Existence) If P ̸= Q, there exists S, T and W such that ⟨SPQ⟩,
⟨PTQ⟩and ⟨PQW⟩.
Which of these axioms is satisﬁed by the relation ⟨. . .⟩deﬁned by (3.35)? Prove
your response by an argument or a counterexample. (Omit the ‘collinearity’
for the moment.)
3.15 (Continuation.) Answer the same question, but with a diﬀerent deﬁni-
tion of the ternary relation ⟨. . .⟩, namely: Let P, S and Q be states in a token
system. Deﬁne ⟨PSQ⟩if there is a concise message m = nq producing Q from
P, such that n is a concise message producing S from P.
3.16 (Continuation.) Could you deﬁne ‘collinearity’ (for sets or for states
in a token system) so that the ternary relation ⟨. . .⟩satisﬁes all the axioms
[B1]-[B5], with either of the two deﬁnitions?
3.17 Show by a counterexample that the media induced, via Theorems 3.5.6
and 3.5.7, from linear traces in diﬀerent clusters are not necessarily isomor-
phic.
3.18 Prove that the medium (L0, T) constructed in 3.5.10 is isomorphic to
the medium (α(L0), Wα(L0)) of Theorem 3.5.7.
3.19 Verify the equivalence (3.30) in the proof of Theorem 3.5.8.

Problems for Chapter 3
71
3.20 Let J be a nondegenerate (bounded or unbounded) interval in Z and
let TJ be the set of transformations of J deﬁned by
τi : x →xτi =

x + 1,
if x = i,
x,
otherwise,
and
˜τi : x →x˜τi =

x −1,
if x = i + 1,
x,
otherwise,
for {i, i + 1} ⊆J and x ∈J.
(i) Prove that (J, TJ) is a medium.
(ii) Prove that the medium (J, TJ) is isomorphic to the medium (F, WF) where
F is the wg-family of sets in the form (−∞, k] ∩J.
3.21 Prove that the set LF of all strict linear orders on a ﬁnite set X is
2-graded.
3.22 (Continuation.) For every pair xy ∈X × X of distinct elements, deﬁne
a function
τxy : LF →LF : L →Lτxy
by the equation
Lτxy =

(L \ {yx}) ∪{xy}
if x covers y in L,
L
otherwise.
Let Q be the collection of all the functions τxy, with xy ∈X×X, x ̸= y. Prove
that the pair (LF, Q) is a medium.
3.23 This problem and the next one investigate the possibility that the struc-
ture of a well-graded family (and so of the corresponding medium) could be
captured by a relation guiding the organization and the compatibility of the
tokens. Let X be a set, let R be a binary relation on X, and let B be a family
of subsets of X. Deﬁne the operation ▷: 2P(X) →2P(X×X) by the equation
B ▷R = B + {Y ⊆X ∃Z ∈B, ∃zx ∈Z × (X \ Z), Y = Z + {x} and zRx}
and then recursively B0 = B, and Bn+1 = Bn ▷R, for n ∈N0.
The R-closure of B is the family BR = ∪∞
n=0Bn. Under which necessary
and suﬃcient conditions on a family F of subsets of a set X does there exists
a relation R on X and a subset B ⊆F such that F = BR, that is, F is the
R-closure of B?
3.24 (Continuation.) Investigate a similar problem with R ⊆2X × X.

4
Closed Media and ∪-Closed Families
Several examples of structures representable by media discussed earlier enjoy
a closedness1 property. For instance, the family of all partial orders on a set
is closed under intersections (cf. Theorem 5.3.5). We deﬁne this concept for
media and investigate its properties.
4.1 Closed Media
We begin by recalling standard concepts of closedness in set theory.
4.1.1 Deﬁnition. A family of sets F is closed under unions, or ∪-closed,
(resp. closed under intersections, or ∩-closed) if for any nonempty2 G ⊆F we
have ∪G ∈F (resp. ∩G ∈F). We say that a family F is closed under ﬁnite
unions or ∪f-closed if ∪G ∈F for any ﬁnite, nonempty subfamily G ⊆F.
Similar terminology and notation are used for ﬁnite intersections.
A family of sets F is closed under subsets if, for any nonempty set S ∈F,
and any subset T ⊂S, T also belongs to F. Families of ﬁnite sets that are
closed under subsets are sometimes called independence systems or abstract
simplicial complexes (cf. Korte et al., 1991)
Thus, the family of all partial orders on a set is ∩-closed, as recalled above.
The next deﬁnition captures a related concept of closedness in the framework
of a medium.
4.1.2 Deﬁnition. An oriented medium (S, T) is u-closed (resp. i-closed) if for
any state S and any two distinct positive (resp. negative) tokens τ, τ ′ both
eﬀective for S, we have
(Sτ = V, Sτ ′ = W)
=⇒
V τ ′ = Wτ.
(4.1)
1 We reserve the term ‘closure’ for the operation, as in ‘transitive closure.’
2 For some authors, the subfamily G may be empty, with ∪∅= ∅. So, a ∪-closed
family automatically contains the empty set. We do not use this convention here.

74
4 Closed Media and ∪-Closed Families
Results concerning u-closed media can be reformulated for i-closed media in
a straightforward manner. In the sequel, we simplify our language and write
that a medium is closed if it is an oriented medium that is u-closed. A medium
that is not closed is said to be open. Clearly, a medium can be closed under
one orientation without being closed under some other orientation. When a
medium (F, WF) is deﬁned, as in Theorem 3.3.1, from a wg-family F, then F
is closed under ﬁnite unions—or ∪f-closed—if and only if (F, WF) is closed in
the sense of Deﬁnition 4.1.2 (see Corollary 4.1.10).
4.1.3 Theorem. In an oriented medium (S, T), the two conditions below are
equivalent:
(i) (S, T) is closed.
(ii) Let m = τ1 . . . τn be any positive concise message from some state
S, with S1 = S, and Si+1 = Siτi for 1 ≤i < n. If a positive token
τ /∈C(m) is eﬀective for some state Si, 1 ≤i < n, it is also eﬀective
for any state Sj, i < j ≤n.
The proof is left as Problem 4.1. As a hint of a forthcoming result (Theorem
4.2.2), compare Condition (ii) with Axiom [K2] of a learning space on page 10.
Another useful consequence of the closedness condition is given below.
4.1.4 Theorem. Let n = τ1 . . . τkτk+1 . . . τn be a concise message from
some state S in a closed medium, with τk negative and τk+1 positive. Then
Sτ1 · · · τkτk+1 · · · τn = Sτ1 · · · τk+1τk · · · τn.
In other words, the tokens τk and τk+1 in the original message n can be
transposed without changing the state produced.
Proof. Let T = Sτ1 · · · τk. Then, there are distinct states W and W ′ such that
T 
τk = W = Sτ1 · · · τk−1 and Tτk+1 = W ′. Since both 
τk and τk+1 are positive
and the medium is closed, we get Wτk+1 = W ′ 
τk, and thus also, successively
Sτ1 · · · τk−1τk+1τk = Wτk+1τk = W ′ 
τkτk = W ′
= Tτk+1 = Sτ1 · · · τkτk+1.
4.1.5 Deﬁnition. Suppose that n = mpm′, with m and m′ two possibly
ineﬀective messages, and p an eﬀective one. Then p is a segment of n. If m
is empty, then (as m can be omitted) p is an initial segment or preﬁx of n.
Similarly, if m′ is empty, then p is an terminal segment or suﬃx of n. With
respect to some orientation, a segment is said to be positive (resp. negative)
if it contains only positive (resp. negative) tokens.

4.1 Closed Media
75
4.1.6 Deﬁnition. In an oriented medium, a concise message m producing a
state V from a state S is called canonical if it satisﬁes one of the following
three cases:
[1]
m is positive;
[2]
m is negative;
[3]
m = nn′, with n a positive preﬁx and n′ a negative suﬃx.
In Case [3], the canonical message m = nn′ is said to be mixed.
4.1.7 Theorem. For any two distinct states S and V in a closed medium,
there is a canonical message producing V from S.
Proof. By [Ma], there is a concise message p = τ1 . . . τn producing V from S.
Suppose that p is not canonical. Then there must be an index i such that τi
is negative and τi+1 positive. By Theorem 4.1.4, the tokens τi and τi+1 can
be transposed without changing the state produced. The result follows.
4.1.8 Theorem. In an oriented medium, suppose that a state V is produced
from a state S by mixed canonical message n = mm′, with Sm = T and m
a positive preﬁx of n; then, S+ ∪V + = T +.
Proof. By Theorem 2.8.5, S+ ⊂T +. We have also V + ⊂T + because 
m′ is
positive, concise for V , and produces T from V . This implies that S+ ∪V + ⊆
T +. We get
T + \ (S+ ∪V +) = ( T + \ S+) ∩( T + \ V +) = C(m) ∩C(
m′) = ∅,
the last equation holding because mm′ is concise. Thus, T + ⊆S+ ∪V +, and
the result obtains.
4.1.9 Theorem. For any two states S and V in a closed medium (S, T), there
is a unique state T whose positive content is the union of the positive contents
of S and V . Consequently, the family S+ of all the positive contents is closed
under ﬁnite unions, and the family T−of all the negative contents is closed
under ﬁnite intersections.
Proof. For any two states S and V , there is a canonical message p producing
V from S. Suppose that p is positive, then clearly S+ ⊂V +, which gives
S+ ∪V + = V + ∈T+, and T = V . If p is negative, then 
p is positive,
and produces S from V , with a similar result. The case where p is a mixed
canonical message is an immediate consequence of Theorem 4.1.8. The set T is
unique because any state is deﬁned by its content. The statement concerning
the negative contents follows because, for any state W, we have 
W −= T\
W +.
Thus with S, V and T as above, we obtain

76
4 Closed Media and ∪-Closed Families
S−∩V −= S+ ∩V + = S+ ∪V + = T + = T −.
From Theorem 4.1.9 and the deﬁnitions, we get immediately:
4.1.10 Corollary. Suppose that a medium (F, WF) has been deﬁned from a
wg-family F of subsets of some ﬁnite set, in the sense of Deﬁnition 3.3.2. Then,
any set S in the family F is in a 1-1 correspondence x →γx with the positive
content S+ of the corresponding state S of the medium (F, WF). Moreover,
the family F is ∪f-closed if and only if the medium (F, WF) is also closed.
4.1.11 Theorem. In a ﬁnite closed medium (S, T), there is a unique state
Λ which is produced only by positive messages. Consequently, its positive
content is identical to its content. In fact, we have Λ+ = Λ = T+, and so
| Λ| = |T|/2.
Proof. As the collection S of states is ﬁnite, we can show by induction that
there exists a state whose positive content is equal to ∪S∈T S+. Because a
state is deﬁned by its content, this state is unique. As it contains all the
positive tokens, it cannot contain any negative one: by Theorem 2.4.3 , we
have | Λ| = |T|/2.
4.1.12 Deﬁnition. A state S in a medium with orientation {T+, T−} is called
the apex of the medium for that orientation, or more brieﬂy the apex of
{T+, T−}, if S = T+. Thus, the state Λ introduced in Theorem 4.1.11 is the
apex of the closed medium. By Theorem 2.4.5, any oriented medium can have
at most one apex.
Each state S of a medium can be the apex for a particular orientation by
assuming that the set of positive tokens of that orientation is equal to S. This
class of orientations has interesting properties.
4.1.13 Deﬁnition. Let M = (S, T) be a medium with orientation {T+, T−}.
For any state S in S we say that M is apex oriented (for S) if T+ = S. In
such a case, we may write T+
S = T+ and T−
S = T−.
By Theorem 4.1.11, any ﬁnite closed oriented medium is apex-oriented.
We now investigate media for which all apex orientations form closed me-
dia, anticipating our investigation in Theorem 4.3.3 of media for which all
orientations form closed media.
4.1.14 Deﬁnition. Let u, v, w and x be vertices in a graph G. Then x is a
median for the triple (u, v, w) if x belongs to a shortest path in G between
each pair of vertices in the triple. The graph G is a median graph if every
triple of vertices has a unique median.

4.1 Closed Media
77
Finite median graphs have been extensively studied; see, e.g., Imrich et al.
(1999) or Imrich and Klavˇzar (2000). Alternative characterizations of them
are known; for example, they are exactly the ‘retracts’ of hypercubes (Bandelt,
1984). Every ﬁnite median graph is a partial cube (Mulder, 1980), from which
it will follow by Theorem 7.1.10 that it is the graph of a medium. However,
we will not use this result in what follows.
4.1.15 Example. Let G be a path. Then, if (u, v, w) is any triple of distinct
vertices, the smallest connected subgraph of G that contains all three vertices
in the triple is itself a path, with two of the triple as its endpoints. The third
vertex of the triple is the median. Thus, any triple has a unique median and
G is a median graph.
4.1.16 Lemma. Let G be the graph of a medium M, and let (S, T, U) be a
triple of vertices in G that has a median V . Then a token τ belongs to V if
and only if it belongs to at least two of S, T, and U.
Proof. Suppose that a token τ ∈V does not belong to T nor U. Then any
path from T to U via V would correspond to a message mn producing U
from T with Tm = V , V n = U, τ ∈C(m) and ˜τ ∈n. So, mn would not
be concise. Accordingly, V could not be on a shortest path from T to U. By
symmetry, the same reasoning applies to the other cases in which fewer than
two of the contents S, T, and U contain τ.
Conversely, suppose that τ ∈(S ∪T) \ U. Since V belongs to a shortest
path in G between S and T, we necessarily have m = np for some concise
messages m, n and p, with one of the two cases: (i) Sn = V and Sm = T; or
(ii) Tn = V and Tm = S. Since τ ∈S ∪T, we get τ ∈V in either case. The
other possible situations arising from the hypothesis that the token τ belong
to at least two of S, T, and U are dealt with by similar arguments.
4.1.17 Theorem. Let M be a ﬁnite medium and let G be the graph of M.
Then all apex orientations of M give rise to closed media if and only if G is a
median graph.
Proof. (Suﬃciency.) Assume that G is a median graph and let {T+
T , T−
T } be
the apex orientation for some state T. Suppose that the positive tokens τ and
ρ are both eﬀective for some state S. Since G is a median graph, we may ﬁnd
a median U of the triple (Sτ, Sρ, T). (Lemma 5.4.3(iii) and Theorem 2.4.4
imply that the vertices in that triple must be distinct.) We will show that
this entails U = Sρτ = Sτρ. We must have S ̸= U ̸= Sτ because U must
be on a shortest path from Sρ to T. Similarly, we must have U ̸= Sρ, as U
must be on a shortest path from Sτ to T. As we have eliminated all three
vertices on the shortest path Sρ–S–Sτ from Sρ to Sτ, the vertex U must be
the middle vertex on a diﬀerent shortest path from Sρ to Sτ. We conclude
that U = Sρτ = Sτρ must be true. Thus, the condition deﬁning the closure
of a medium is satisﬁed and the medium is closed.

78
4 Closed Media and ∪-Closed Families
(Necessity.) Assume that all apex orientations of M form closed media. To
show that G is a median graph, we must prove that any triple of (S, T, U)
of vertices has a median. To do so, we consider the apex orientation for T.
Invoking Theorem 4.1.7, let m be a canonical message from S to U according
to this orientation and let n be the positive preﬁx of m. Then Sn is the
desired median. The uniqueness of this median follows from Lemma 4.1.16.
Thus, any such triple has a unique median, and so G is a median graph.
We ﬁnish this section with a result that is more naturally stated in terms of
i-closed families than u-closed families. This will be relevant for the discussion
of weak orders in Section 9.4.
4.1.18 Theorem. Let F be an independence system. Then F is a wg-family
and the associated oriented medium (F, WF) is i-closed.
We leave the proof as an exercise (Problem 4.7).
4.2 Learning Spaces and Closed Media
This important representation of certain closed media has been deﬁned in
Chapter 1. We recall that, as mentioned there, a learning space is called
an antimatroid in combinatorics (Edelman and Jamison, 1985; Welsh, 1995;
Bj¨orner et al., 1999). We begin our discussion with the following result due
to Cosyn and Uzun (2005).
4.2.1 Theorem. The two following conditions are equivalent for a ﬁnite fam-
ily F of subsets:
(i) F is a learning space (in the sense of Deﬁnition 1.6.1);
(ii) F contains the empty set and is well-graded and ∪-closed.
Proof. Note that both conditions imply the ﬁniteness of the set Q = ∪F.
Indeed, in both cases, we have ∅, Q ∈F. So, the ﬁniteness of Q results from
∅⊂Q and either [K1] for Condition (i) or wellgradedness for Condition (ii).
(ii) ⇒(i). Let F be a ∪-closed wg-family. It is clear that Axiom [K1]
is satisﬁed since it involves special cases of the situations covered by the
wellgradedness condition. Suppose that K ⊂L, with K, K ∪{q} and L in F
with q /∈L. Because F is ∪-closed, we have (K ∪{q}) ∪L = L ∪{q} ∈F; so,
[K2] holds.
(i) ⇒(ii). We begin by proving that F is ∪-closed. Take any distinct,
nonempty L and K in F . Applying [K1] to ∅⊂L, we obtain a sequence
q1, . . . , qn in L forming a chain
∅⊂{q1} ⊂· · · ⊂{q1, . . . , qi} ⊂· · · ⊂{q1, . . . , qn} = L,
(4.2)
with
{q1, . . . , qi} ∈F
(1 ≤i ≤n).
(4.3)

4.2 Learning Spaces and Closed Media
79
But we also have ∅⊂K, which by ∅∪{q1} ∈F yields K ∪{q1} ∈F, using
[K2]. By induction, we derive K ∪L ∈F from [K2] and (4.2), (4.3). Since Q
is ﬁnite, F is ∪-closed.
Turning to the wellgradedness, we take any two distinct K and L in F. As
shown above, we must have K ∪L ∈F. Axioms [K1] implies the existence of
two chains of subsets of F
K ⊂K ∪{q1} ⊂· · · ⊂K ∪{q1, . . . , qn} = K ∪L,
L ⊂L ∪{v1} ⊂· · · ⊂L ∪{v1, . . . , vm} = K ∪L,
with n = |L \ K| and m = |K \ L|, yielding m + n = |(L \ K) + (K \ L)|.
The theorem follows from deﬁning the sequence
K0 = K,
Ki = K ∪{q1, . . . , qi},
(1 ≤i ≤n)
Kn+j = (K ∪L) \ {vm, . . . , vm−j+1}
(1 ≤j ≤m),
so Km+n = L.
4.2.2 Theorem. The two following propositions are equivalent for an ori-
ented medium M = (S, T):
(i) M is a closed rooted medium.
(ii) The collection S+ of positive contents of the states of M is a learning space
in the sense of Deﬁnition 1.6.1.
Proof. (i) ⇒(ii). We have to show that both T+ and ∅are in S+, and that
Axioms [K1] and [K2] hold. The fact that T+ ∈S+ is established by Theorem
4.1.11. Since M is rooted, ∅∈S+ results from Theorem 2.9.2. From Theorems
3.2.6 and 4.1.9, we know that S+ is a wg-family that is ∪-closed. Accordingly,
by Theorem 4.2.1, the collection S+ of positive contents must be a learning
space.
(ii) ⇒(i). By Theorem 2.8.4, any state in an oriented medium is deﬁned
by its positive content. Observe that if the positive tokens τ + and µ+ are
eﬀective for some state S of M, then

(Sτ +)
+
= S+ + {τ +}
and

(Sµ+)
+
= S+ + {µ+}.
Because S+ is ∪-closed,
V + = S+ + {τ +} + {µ+}
is the positive content of some state V , with necessarily V = Sτµ = Sµτ. So,
M is closed. We have ∅∈S+ by deﬁnition of a learning space as a particular
kind of knowledge structure. Thus ∅is the positive content of some state R
that is a root of M, by Theorem 2.9.2.
We turn to media that are called ‘complete’ because they are endowed
with a total symmetry (cf. Theorems 4.3.3 and 4.3.6).

80
4 Closed Media and ∪-Closed Families
4.3 Complete Media
4.3.1 Deﬁnition. A medium is complete if for any state S and any token τ,
either τ or ˜τ is eﬀective for S.
4.3.2 Theorem. Let (S, T) be a complete medium. For any state S and any
two distinct tokens τ, τ ′ both eﬀective for S, we have
(Sτ = V, Sτ ′ = W)
=⇒
V τ ′ = Wτ.
Proof. By the completeness of (S, T), either τ or ˜τ is eﬀective for W. Suppose
that W ˜τ = T ̸= W. Then T ̸= V (otherwise, we would have a return for S of
odd length). Let m be a concise message producing V from T. By [Mb], the
message τ ′˜τm˜τ must be vacuous, which is impossible because m is concise. It
follows that τ is eﬀective for W. By symmetry, τ ′ is eﬀective for V . Suppose
that P = Sττ ′ ̸= Q = Sτ ′τ. Let n be a concise message producing Q from
P. Thus, p = ττ ′n˜τ ˜τ ′ is a return message for S. By Axiom [Mb], this is
impossible if n is concise.
4.3.3 Theorem. A medium is complete if and only if it is closed under any
orientation.
Proof. (Necessity.) By Theorem 4.3.2, a complete medium is closed under any
orientation.
(Suﬃciency.) Suppose that (S, T) is closed under any orientation. Take any
S ∈S and any τ ∈T. Since τ is a token, there is a state V such that τ is
eﬀective for V . Let m = τ1 . . . τn be a concise message producing S from V .
We consider two possible cases:
Case 1: τ /∈C(m). By Theorem 2.9.3, there exists an orientation making
V the root of (S, T). Since V is a root, the token τ and the message m are
both positive. By Theorem 4.1.3, τ is eﬀective for S.
Case 2: τ ∈C(m). If τ = τn, then ˜τ is eﬀective for S. Suppose that τ = τi
for i < n, and let W = V τ1 . . . τi. Then ˜τ is eﬀective for W and does not occur
in the concise message n = τi+1 . . . τn producing S from W. By Theorem 2.9.3,
there exists an orientation making W the root of (S, T). Since W is a root, the
token ˜τ and the message n are both positive. By Theorem 4.1.3, ˜τ is eﬀective
for S.
4.3.4 Example. Consider a collection H of n hyperplanes xi = 0, 1 ≤i ≤n,
in Rn. Following the steps outlined in 1.2.1, we construct a medium which is
complete in the sense of Deﬁnition 4.3.1. Each state is a region in Rn deﬁned
by a system of inequalities xiPi0, 1 ≤i ≤n, where each Pi stands for either
inequality < or > of the reals. There are 2n states and any state has facets
deﬁned by all n hyperplanes in H.

4.3 Complete Media
81
4.3.5 Example. As an application of Theorem 3.3.1, we consider the rep-
resenting closed medium (Pf(Z), WPf(Z)) of the wg-family of all the ﬁnite
subsets of a set Z (cf. Deﬁnition 3.3.2). This medium has a natural orienta-
tion and is clearly complete (see Problem 4.2). If Z is a ﬁnite set, then the
medium (Pf(Z), WPf(Z)) is isomorphic to the medium of Example 4.3.4, with
n = |Z|.
4.3.6 Theorem. A medium (S, T) is complete if and only if for some orien-
tation {T+, T−}, we have
Pf(T+) = S+ = {S+ S ∈S},
(4.4)
that is, every ﬁnite subset of positive tokens is the positive content of some
state. Moreover, any medium isomorphic to a complete medium is complete.
Proof. (Suﬃciency.) Let {T+, T−} be some orientation and suppose that (4.4)
holds. Take any state S ∈S and any token τ + ∈T+. By Theorem 2.4.3, we
have either τ + ∈S or τ −∈S. Suppose that τ + ∈S+. By Eq. (4.4), there
exists some state T with T + = S+ \ {τ +}. Since (S, T) is a medium, there is
by [Ma] a concise message from S to T. This message can only be the single
token τ −. Thus, τ −is eﬀective for S. In the case τ −∈S, a similar argument
establishes that there is a state T with S+ ∪{τ +} = T +, with τ + eﬀective for
S. Thus, (S, T) is complete by Deﬁnition 4.3.1.
(Necessity.) Suppose that (S, T) is complete and let T0 be one of its state.
By Theorem 2.9.3, there exists an orientation making T0 the root of (S, T).
Theorem 2.9.2 implies that T +
0 = ∅. Because (S, T) is complete, every positive
token τ is eﬀective on T0. Thus, for every τ ∈T+, {τ} is the positive content
of a state. By Theorems 4.3.3 and 4.1.9, the family S+ of all the positive
contents is ∪f-closed. Accordingly, we must have S+ = Pf(T+).
The last proposition is obvious.
4.3.7 Theorem. If (S, T) is an oriented medium, then its sign-isomorphic
representing medium (S+, WbS+) is a submedium of the complete medium
(P(S+), WP(bS+)).
This derives immediately from Theorem 3.3.3. As a preparation for the
next section, we have the following deﬁnition and results relating star me-
dia (cf. Deﬁnition 2.9.4) and completeness.
4.3.8 Deﬁnition. A rooted medium (S, T) is an extended star or E-star if
it has a star submedium (Q, V) with the same root satisfying |V| = |T|. An
E-star N = (Q, V) that is a submedium of some oriented, not necessarily
rooted, medium M is called a E-star of M if there is no E-star submedium
N′ = (Q′, V′) of M having the same root as N and satisfying Q ⊂Q′ and
|V′| = |V|. It is clear that any oriented medium has at least one E-star.

82
4 Closed Media and ∪-Closed Families
In the display of an oriented medium as a digraph, we will often indicate
only the edges corresponding to the positive tokens. We may sometimes refer
to such a digraph as a positive digraph.
a
b
d
c
a
b
c
a
b
c
b
a
b
c
R
a
a
a
b
b
b
c
c
c
R
R
R
A
B
C
D
Figure 4.1. The digraphs A, B and C represent E-stars, but the digraph D does
not. The digraph in C is that of a complete medium.
The labeling of the edges is critical in a digraph representation of an E-star.
For example, A, B, C and D in Figure 4.1 are positive digraphs of rooted media
(with only their positive token represented). Each of A, B, and C represent
E-stars, but the digraph in D does not: its star submedium has 2 × 3 tokens
while the full rooted medium has 2 × 4 tokens, contradicting the deﬁnition of
an E-star.
4.3.9 Theorem. Any closed E-star is a complete medium.
Proof. Let N = (Q, V) be a closed E-star with V+ = {τ1, . . . , τn} and a root
denoted by R. By deﬁnition of the root of an E-star, we must have R+ = ∅
and 
Rτi
+ = {τi} for 1 ≤i ≤n. Since N is closed, Theorem 4.1.9 implies that
Q+ is closed under ﬁnite unions; so Q+ = Pf(V+). Applying Theorem 4.3.6,
we conclude that N is complete.
4.3.10 Lemma. Suppose that S is a state of a medium (S, T), and that Sτ ̸=
S ̸= Sτ ′ for some tokens τ and τ ′, with moreover either Sττ ′ = Sτ or Sτ ′τ =
Sτ ′. Then there exists a open E-star (Q, TQ) of (S, T) such that S ∈Q with
τQ and τ ′
Q the reductions of τ and τ ′ to Q, respectively.

4.4 Summarizing a Closed Medium
83
This lemma is useful in proving the theorem below. We leave the two proofs
as Problem 4.9.
4.3.11 Theorem. A medium is closed if and only if all its E-stars are closed.
Finally, we return, from the standpoint of the completeness of media, to the
cluster subfamilies studied in Chapter 3. We learned from Theorem 3.4.6 that,
for a ﬁxed set X, all the clusters ⟨S⟩of the power set P(X) form isometric met-
ric spaces (⟨S⟩, d) (where d stands for the restriction to ⟨S⟩of the symmetric
diﬀerence distance on P(X)). We also know that all the media (⟨S⟩, W⟨S⟩) are
isomorphic; in particular, they are isomorphic to (Pf(X), WPf(X)) (cf. The-
orems 3.4.10(i) and 3.4.11). In addition, it is easy to see that any medium
(⟨S⟩, W⟨S⟩) is complete. The converse is also true as the following theorem
asserts.
4.3.12 Theorem. Let F be a wg-family of subsets of a set X. The representing
medium (F, WF) is complete if and only if F = ⟨S⟩for some S ∈P(X).
Proof. We only need to establish the necessity. Suppose thus that (F, WF) is
a complete medium. By Theorem 3.4.8, we have F ⊆⟨S⟩for some S ∈P(X).
For a given P ∈⟨S⟩, let k = d(P, S). We prove that P ∈F by induction on
k. If k = 1, then either P = S + {x} or P = S \ {x} for some x ∈X and
P ̸= S. In the former case, x /∈S implying that ˜γx is not eﬀective on S. By
completeness, Sγx = P. Thus P ∈F. Similarly, if P = S \ {x}, then x ∈S
and S˜γx = P. Suppose Q ∈F for all Q ∈⟨S⟩such that d(S, Q) = k and let
P be an element in ⟨S⟩such that d(S, P) = k + 1. Then there exists R ∈F
such that d(S, R) = k and d(R, P) = 1. Because ⟨R⟩= ⟨S⟩, it follows from
the above argument that P ∈F.
4.4 Summarizing a Closed Medium
In certain cases, a structure can be economically summarized by a well chosen
part it. A familiar case is the Hasse diagram ˘P of a partial order P on a ﬁnite
set: the transitive closure of ˘P is equal to P (cf. 1.8.3, Eq. (1.8)). We face a
similar situation in the case of certain empirical large rooted media, whose
number of states may occasionally be of the order of millions3. An appealing
idea is to represents such a medium by a much smaller rooted submedium
whose ‘closure’ would reconstruct the large medium. The last two theorems
suggest that the essential step towards the closure of a rooted medium is the
closure of all its E-stars. This has to be done recursively since, typically, the
closure of one E-star may create new ones.
While this idea is attractive, its application to the closure of some open
medium is delicate because the most obvious potential technique is not feasi-
ble.
3 Personal communication from Eric Cosyn concerning learning spaces (cf. Theorem
4.2.1 and Chapter 13).

84
4 Closed Media and ∪-Closed Families
4.4.1 A Counterexample. A priori, an appealing method is to go back to
the deﬁnition of ‘closed medium’ and to enforce it recursively on some open
medium (S, T), namely:
1. pick a state W such that, for two distinct tokens τ and µ
Wτ ̸= W ̸= Wµ with Wτµ = Wτ, Wµτ = Wµ ;
(4.5)
2. add a new state S to S and recast the tokens τ and µ as the tokens
τ ′ : S ∪{S} →S ∪{S} and µ′ : S ∪{S} →S ∪{S} deﬁned by:
τ ′ : T →Tτ ′ =
⎧
⎪
⎨
⎪
⎩
Tτ
if S ̸= T ̸= Wµ
S
if T = Wµ
T
otherwise
(4.6)
µ′ : T →Tµ′ =
⎧
⎪
⎨
⎪
⎩
Tµ
if S ̸= T ̸= Wτ
S
if T = Wτ
T
otherwise.
(4.7)
Figure 4.2 demonstrates that this method does not necessarily lead to
construct a medium. In the open medium4 pictured by the digraph A, there
are four possible cases of some state W satisfying the condition of Eq. (4.5).
The corresponding vertices are labeled W1, . . . , W4 in that digraph. There are
thus four ways of adding the state S. In each these cases, which are displayed
by the digraphs B, C, D, and E, there is no consistent message from the new
state S to one of the other state. Accordingly, the resulting token system fails
Axiom [Ma] and so is not a medium.
The required construction is more elaborate and we shall follow a rather
diﬀerent route in the next section, based on the fact that any oriented medium
can be faithfully represented by its family of positive contents. We just discuss
here the much simpler case of the closure of an exemplary E-star.
4.4.2 Example. Consider the medium M = (S, T) displayed in Figure 4.3 by
the digraph of its positive tokens. It is a slight modiﬁcation of the example of
Figure 2.1 setting its root to be W and equipped with the orientation deﬁned
by T+ = {τ1, τ4, τ6}. The complete medium forming the closure M of the
medium M has the collection of positive contents (cf. Theorem 4.3.6)
P{τ1, τ4, τ6} = {∅, {τ1}, {τ4}, {τ6}, {τ4, τ6}, {τ1, τ4},
{τ1, τ6}, {τ1, τ4, τ6}}
ﬁve of which are already in the E-star of the ﬁgure. We are thus missing three
states. The expanded set of states is
S = S + {S{τ1,τ4}, S{τ1,τ6}, S{τ1,τ4,τ6}}.
4 The fact that this particular medium is rooted has no bearing on our discussion.

4.4 Summarizing a Closed Medium
85
F
F
F=
F
F
A                                                      B
a
b
c
d
S
a
b
c
d
S
a
b
c
d
S
a
b
c
d
C                                                   D                                                     E
S
W2
a
b
c
d
W1
W3
W4
Figure 4.2. The positive digraph A represents an open medium, while B, C, D and
E picture four failed attempts to construct an enlarged medium by adding a state
S via the method of Eqs. (4.6)–(4.7).
Y
V
W
T
X
T
T
T
T
T
T
T
{     ,     }
T
{     }
T
{     }
{     }
T
0
M
M
W
X
Y
V
T
Figure 4.3. Positive digraph of an E-star M
= (S, T) with root W, S
=
{V, W, X, Y, T}, and T+ = {τ1, τ4, τ6}. The graph of the closure M
of M is also
indicated schematically.
We also have to expand the deﬁnition of the three pairs of tokens (τi, ˜τi),
i = 1, 4, 6. To avoid repetition, we only give ﬁve examples illustrating all the
important cases for the positive tokens. Denoting by τi , ˜τi , i = 1, 4, 6 the
‘expansions’ of the tokens of M, we get

86
4 Closed Media and ∪-Closed Families
Tτ1 = Tτ1 = T,
Wτ1 = Wτ1 = T,
Xτ1 = S{τ1,τ4},
(4.8)
S{τ1,τ4}τ1 = S{τ1,τ4},
S{τ1,τ4}τ6 = S{τ1,τ4,τ6}.
(4.9)
The neologism ‘expansion’ is justiﬁed. As illustrated by the last equation
in (4.8), we cannot use ‘extension’ there because, as some loops have been
removed, some of the images of states under τi are changed under τi . (For
symmetrical reasons, we used ‘reduction’ rather than ‘restriction’ in our deﬁ-
nition of a submedium—cf. 2.7.2.)
4.5 ∪-Closed Families and their Bases
As announced, we investigate here another avenue for summarizing a closed
medium. For some of the material in this section, we follow Doignon and
Falmagne (1999) except that we do not assume that the empty set necessarily
belongs to the ∪-closed family. Any result adapted from their monograph is
marked by ‘[DF99].’ Some additional results in this section are from Eppstein
et al. (2007).
4.5.1 Deﬁnition. The (ﬁnite) span of a family of sets F is the family F′
containing any set which is the union of some (ﬁnite) subfamily5 of F. In
such a case, we write S(F) = F′ (resp. Sf(F) = F′) and we say that F spans
(resp. (ﬁnitely) spans) F′. By deﬁnition S(F) and Sf(F) are thus ∪-closed and
∪f-closed, respectively. A base of a ∪-closed family H is a minimal subfamily
I of H spanning H (where ‘minimal’ is meant with respect to set inclusion: if
S(F) = H for some F ⊆I, then F = I.) Note that a base of a ∪f-closed family
need not be ﬁnite (cf. Problem 4.8).
4.5.2 Lemma. The ﬁnite span of a wg-family is well-graded.
Proof. Let Sf(F) be the ﬁnite span of some wg-family F. Take any two distinct
X, Y in Sf(F). Since Sf(F) is ∪f-closed by deﬁnition, X ∪Y is in Sf(F). Notice
that S △T is a ﬁnite set for any S, T ∈Sf(F). (This follows easily from the
facts that F is a wg-family and that both S and T are ﬁnite unions of sets in
F.) We can thus write d(X, Y ) = d(X, X ∪Y ) + d(X ∪Y, Y ). Accordingly, it
suﬃces to prove that there is in Sf(F) a tight path
X1 = X, X2, . . . , Xn = X ∪Y,
(4.10)
with in fact Xi ⊂Xi+1, 1 ≤i ≤n −1. By deﬁnition of the ﬁnite span,
there exists ﬁnite G, H ⊆F such that X = ∪G and Y = ∪H. Without loss of
5 Contrary to the convention used by Doignon and Falmagne (1999), the empty
subfamily of F is not allowed; so ∅∈S(F) only if ∅∈F.

4.5 ∪-Closed Families and their Bases
87
generality (exchanging the roles of X and Y if needed), we can assume that
there exists some H ∈H such that H \ X ̸= ∅. Choose G ∈G arbitrarily. By
the well-gradedness of F, there is a tight path G1 = G, . . . , Gm = H. Let k
be the ﬁrst index such that Gk \ X ̸= ∅. (Such an index must exist because
H \ X ̸= ∅.) We necessarily have |Gk \ X| = 1. Deﬁning X2 = (∪G) ∪Gk, we
obtain X1 = X ⊂X2 ⊆X ∪Y with |X2 \ X1| = 1. An induction completes
the proof.
Note that a base of a ∪-closed wg-family need not be well-graded.
4.5.3 Example. The ∪-closed wg-family
F = {∅, {a}, {b}, {c}, {a, b}, {a, c}, {b, c}, {c, d}, {a, b, c},
{a, c, d}, {b, c, d}, {a, b, c, d}, {a, b, c, d, e}}.
(4.11)
has the base
{∅, {a}, {b}, {c}, {c, d}, {a, b, c, d, e}},
which is not well-graded. Moreover, F has two minimal well-graded subfamilies
spanning F:
{∅, {a}, {b}, {c}, {a, b}, {a, c}, {c, d}, {a, b, c},
{a, c, d}, {a, b, c, d}, {a, b, c, d, e}},
(4.12)
{∅, {a}, {b}, {c}, {a, b}, {b, c}, {c, d}, {a, b, c},
{b, c, d}, {a, b, c, d}, {a, b, c, d, e}}.
(4.13)
In the context of Theorems 3.3.1 and 3.3.3 we can of course consider
the family represented by (4.11) as that of the positive contents of a closed
medium. This example raises the question: how can we recognize or charac-
terize a base of a wg-family? One answer is given as Theorem 4.5.13 for the
∪f-closed case.
4.5.4 Example. The unique base of the set Pf(Z) of all ﬁnite subsets of Z
is the family
{{0}, {1}, {−1}, . . . , {n}, {−n}, . . .}.
4.5.5 Example. A base of a family which is both ∪-closed and ∩-closed (that
is, closed under intersection) is not necessarily well-graded. Indeed, consider
the family
G = {∅, {a}, {b}, {d}, {a, b}, {a, d}, {b, d}, {a, b, c}, {a, b, d},
{a, b, c, d}, {a, b, c, d, e}},
for which {∅, {a}, {b}, {d}, {a, b, c}, {a, b, c, d, e}} is a base.

88
4 Closed Media and ∪-Closed Families
4.5.6 Theorem. [DF99] Let B be a base of a ∪-closed family F. If G is any
family spanning F, then B ⊆G. Accordingly, any ∪-closed family has at most
one base.
Proof. Let B, F and G be as in the statement of the theorem and take any
X ∈B. So X ∈F and there exists H ⊆G such that X = ∪H. Since B is a
base of F, there is for any Y ∈H a subfamily BY of B such that Y = ∪BY .
We obtain
X = ∪H = ∪(∪Y ∈HBY ) ∈B.
(4.14)
As B is a minimal family spanning F, the set X cannot be the union of other
sets in B. So, the only possibility for (4.14) to be true is to have H = {X},
yielding X ∈G.
4.5.7 Theorem. [DF99] Finite ∪-closed families have always a base.
Proof. Consider the set S(F) of all the families spanning some ∪-closed family
F, partially ordered by inclusion. If F is ﬁnite, that partial order has a minimal
element, which by Theorem 4.5.6 is equal to ∩S.
If a ∪-closed family F has a base, its element can be described precisely:
for any X in F, we can test whether or not X belongs to the base of F.
4.5.8 Deﬁnition. For any x in ∪F, where F is a ∪-closed family, an atom at
x is a minimal set of F containing x (where ‘minimal’ is with respect to set
inclusion). A set X in F is called an atom6 if either X = ∅∈F, or there is
some x ∈∪F such that X is an atom at x.
The next two theorems recast results from Doignon and Falmagne (1999).
4.5.9 Theorem. [DF99] A nonempty set X in a ∪-closed family F is an atom
if and only if X ∈H for any subfamily H of F such that ∪H = X.
We omit the proof (see Problem 4.11.)
4.5.10 Theorem. Let A be the collection of all the atoms of a ∪-closed family
F, with X = ∪F.
(i) Suppose that for every point of X there is an atom at x. Then A is the
base of F.
(ii) If F has a base B, then A = B. In such a case, there is not necessarily
an atom at every point of X.
6 Our meaning of the term ‘atom’ is diﬀerent from its usage in lattice theory;
cf. Birkhoﬀ(1967), Davey and Priestley (1990). It also slightly diﬀers from that
in Doignon and Falmagne (1999) because we do not allow the empty union of a
family (see Footnote 5).

4.5 ∪-Closed Families and their Bases
89
Proof. Let A be the collection of all the atoms of F. Suppose that there is an
atom at every point of X. We ﬁrst assume that ∅/∈F. Thus, all the atoms
are nonempty. We claim that A must be the base of F. Notice that, for any
X in F, the set AX = {Y ∈A ∃x ∈X, x ∈Y ⊆X} exists because there is
an atom at every point of X ⊆X. We have thus ∪AX = X and so A spans X.
Let now H be another subfamily of F spanning F. Take any Z ∈A. Since H
spans F, there must be a subfamily G of H such that ∪G = Z. By Theorem
4.5.9, we must have Z ∈G ⊆H; this yields A ⊆H. Thus A is a minimal
family spanning F and so is its base. In the case ∅∈F, we have ∅∈A by
deﬁnition with ∪{∅} = ∅, and so A is also the base.
It remains to show that if the base B of F exists, then every X in B must
be an atom. It is clear that we must have ∅∈B if ∅∈F. Suppose that some
nonempty X in B is not an atom. Then, there must exist for every x ∈X a
set Yx ⊂X containing x. We have thus ∪x∈XYx = X. We obtain the family
G = (B \ {X}) ∪({Yx x ∈X} spanning F, with G ̸⊆B, which is impossible
by Theorem 4.5.6 and our hypothesis that B is the base of F. This proves
that every X ∈B is an atom. The wg-family H in Counterexample 4.5.12 is
∪-closed and is its own base, but has no atom at the point 1.
4.5.11 Remarks. (a) Various algorithmic issues are raised by the material in
this section, such as: how do we construct the base of a ∪-closed family F? How
do we eﬃciently deploy either of these the bases to recover F? An algorithm
for constructing the base of a ﬁnite ∪-closed family was proposed by Dowling
(1993b). The problem of recovering all the states given the base is discussed
in Chapter 10.
(b) In Theorem 4.5.10, we are assuming that the base and the set of
atoms exists, without assuming that the family is ﬁnite. In fact, there are
inﬁnite ∪-closed families having a base (cf. Problem 4.12). As shown by the
counterexample below, there are also inﬁnite wg-families with no base.
4.5.12 A Counterexample. Consider the inﬁnite family F = G + H, with
G = {Gn Gn = {. . . ,
1
n + 1, 1
n}, n > 1}
(4.15)
H = {Hn Hn = Gn + {1}, Gn ∈G}.
(4.16)
The family F is ∪-closed and well-graded and there is no atom at 1. It is easily
veriﬁed that this ∪-closed family F has no base (Problem 4.16). The ∪-closed
family H is its own base and has not atom at 1 either.
As a consequence of Lemma 4.5.2, we have:
4.5.13 Theorem. Let F be a ∪f-closed family with base B. Then F is a wg-
family if and only if, for any two distinct sets K and L in B, there is a tight
path in F from K to L ∪K. Thus, if B contains the empty set, then F is
well-graded if and only if there is a tight path from ∅to K for any K in B.

90
4 Closed Media and ∪-Closed Families
In other words, the ﬁrst statement asserts that F is well-graded if and
only if d(K, L) is ﬁnite for any two sets K and L in B and moreover, if
d(K, K ∪L) = n > 1, there exists for all 1 ≤i ≤n −1, a subfamily A(i) ⊆B
such that K ⊂∪A(i) ⊂K ∪L and d(K, ∪A(i)) = i.
Proof. As F is ∪f-closed with base B, the necessity is clear. To establish the
suﬃciency, we point out that the family B∗deﬁned by
M ∈B∗⇐⇒

M = ∪fA for some A ⊆B such that
K ⊆∪fA ⊆K ∪L for some K, L ∈B
(4.17)
includes B since K = ∪{K} and K ⊆∪{K} ⊆K ∪L for any K and L in B.
Moreover, it follows from the deﬁnition of B∗that for any ﬁnite subfamily L
of B∗, there is a ﬁnite subfamily K of B such that ∪L = ∪K. Thus, B∗ﬁnitely
spans F. We claim that B∗is well-graded, which implies by Lemma 4.5.2 that
F is well-graded. The main line of our argument is similar to that used in the
proof of Lemma 4.5.2.
Take any two distinct V, W ∈B∗. By deﬁnition of B∗, we have V = ∪fV
and W = ∪fW for some subfamilies V and W of B. It follows easily from
Condition (i) of the theorem that d(V, V ∪W) is ﬁnite, say d(V, V ∪W) = n.
We must show that there exists in B∗a tight path V0 = V, V1, . . . , Vn = V ∪W
from V to V ∪W. Without loss of generality (exchanging the roles of V and
W if needed), we can assume that there is some H ∈W such that H \V ̸= ∅.
Choose G ∈V arbitrarily. Then G ⊂H ∪G ⊆V ∪W, with H and G in B.
By hypothesis, there is a tight path G0 = G, G1, . . . , Gm = G ∪H from G to
G ∪H in F, with G ⊂Gi ⊂G ∪H and d(G, Gi) = i for 1 ≤i ≤m. Let k
be the ﬁrst index such that Gk \ V ̸= ∅. (Such an index must exist because
H \ V ̸= ∅.) We necessarily have |Gk \ V | = 1. Deﬁning V1 = (∪V) ∪Gk, we
obtain V0 = V ⊂V1 ⊆V ∪W with |V1 \ V0| = 1. An induction completes the
proof. The second statement follows easily (see Problem 4.13).
4.5.14 Remarks. (a) The set B∗constructed in the proof of Theorem 4.5.13
is not necessarily a minimal wg-family spanning F. Indeed, the deﬁnition of
B∗by (4.17) includes all the unions ∪A(i), while only some of them may be
needed. An example of such a situation was provided by the wg-family of
Example 4.5.3. In this case, each of (4.12) and (4.13) is a minimal wg-family
including the base and spanning the wg-family F deﬁned by (4.11). The set
B∗in this case would be the union of the two families in (4.12) and (4.13),
which is in fact equal to F.
(b) The results concerning the base of a ∪-closed wg-family have a straight-
forward application to closed media. In view of the relationship between a
closed medium and the ∪-closed wg-family of its positive contents described
by Theorems 3.3.3, 4.1.9 and 4.2.2, any closed medium can be faithfully and
economically summarized by the base B of its family of positive contents,
whenever such a base exists (see Theorem 4.5.17). Note that when this base

4.5 ∪-Closed Families and their Bases
91
is graded in the sense of Deﬁnition 3.2.1 with a grading collection GB, then
Lemma 3.2.3(i) tells us that (B, GB) is a token system which can be con-
structed. The usefulness of such a translation is actually doubtful, as sug-
gested by Example 4.5.3 and the corresponding digraphs of Figure 4.4. The
closed medium is that corresponding to the wg-family F of Example 4.5.3 and
is represented by the positive digraph A. The positive digraph B is that of the
token system representing the base of the family of positive contents of F ; C
and D represent the closed media induced by the two minimal wg-subfamilies
of F spanning F.
c
a
a
{b,c}
{a}
b
d
d
d
e
{a,b,c,d,e}
a
b
a
a
c
c
c
b
b
b
{b}
{a, b}
{b,c,d}
{a,c}
{a,c,d}
{a,b,c}
{c}
{c,d}
{a,b,c,d}
{b}
{a}
c
a
b
d
{c}
{c,d}
{a,b,c,d,e}
A
B
C
D
Figure 4.4. The positive digraph A is that of the representing closed medium of
the ∪-closed family F deﬁned by Eq. (4.11) in Example 4.5.3. The positive digraph
B is that of the token system representing the base of the family of positive con-
tents of F (notice that the vertex corresponding to the state with positive content
{a, b, c, d, e} has no link to the other vertices); C and D are those of the two open
media corresponding to the two minimal wg-subfamilies (4.12 ) and (4.13) spanning
the family F deﬁned by (4.11).
(c) A diﬀerent approach was taken by Koppen (1989) to capture the well-
gradedness of a ∪-closed family F, based on a property of the ‘surmise system’
of the family F. The concept of a surmise system was introduced by Doignon
and Falmagne as a pair (X, σ), where σ is a function mapping a ground set
X into P(P(X)) and satisfying certain conditions (Doignon and Falmagne,
1985, 1999). In particular, for any x ∈X, any C ∈σ(x) must contain x and
must be minimal for set inclusion among the sets in σ(x). In the context of
learning spaces applied to education, the interpretation of a family σ(x) is
that from observing that a student has mastered problem x, one can infer
that the student has also mastered all the problems in at least one subset C

92
4 Closed Media and ∪-Closed Families
in σ(x). In other words, the sets in σ(x) are the possible sets of prerequisites
for the mastery of x.
Related mathematical results regarding can also be found in the literature
of convex geometries (Edelman and Jamison, 1985; Van de Vel, 1993).
The following theorem paves the way for the application to closed media
of the results concerning the existence of the base of a ∪-closed wg-family.
Indeed, by Theorem 4.2.2, we know that the family of positive contents of a
closed rooted medium is a learning space.
4.5.15 Theorem. Any learning space has a base.
Notice that no assumption of ﬁniteness is made here.
Proof. Let F be a learning space, with ∪F = X. By Theorem 4.2.1, F
contains the empty set and is well-graded. Take any x ∈X, and any set
S ∈F containing x. By the wellgradedness of F, there exists at least one
chain of sets ∅⊂S1, . . . , Sn = S with Si ∈F and |Si+1 \ Si| = 1 for
1 ≤i ≤n −1. Note that all such chains have the same cardinality n. Let
K = {Kk k ∈J} be the collection of all such well-graded chains from ∅to S,
and let S = {Si,k 1 ≤i ≤n, k ∈J} be the family of all the sets belonging to
such chains; thus
∅⊂S1,k ⊂. . . ⊂Si,k ⊂. . . ⊂Sn,k = S
(k ∈J).
The collection K is ﬁnite, since |K| ≤n!. Let j be the smallest index 1 ≤j ≤n
such that x ∈Sj,k for some set Sj,k ∈S. (There may be more than one such
set in S.) The set Sj,k is thus an atom at x. So, there is an atom at every
point of X. By Theorem 4.5.10, the set of all those atoms is the base of F.
4.5.16 Deﬁnition. By extension, we call the base of a closed medium the
base of its family of positive contents.
4.5.17 Theorem. (i) Any ﬁnite closed medium has a base.
(ii) Any rooted closed medium has a base.
(iii) Some inﬁnite closed media have no base.
Proof. We recall that, by Theorem 3.3.1, the family S+ of positive contents of
an oriented medium M = (S, T) is well-graded and satisﬁes both ∪S+ = T+
and ∩S+ = ∅. By Theorem 4.1.9 and Corollary 4.1.10, the medium M is
closed if and only if S+ is closed under ﬁnite unions.
(i) This is clear by Theorem 4.5.7 and the fact that S+ is ﬁnite.
(ii) As Theorem 4.2.2 implies that S+ is a learning space, this case follows
from Theorem 4.5.15.
(iii) Take the medium M induced by the family of positive contents deﬁned
by the equivalence

4.5 ∪-Closed Families and their Bases
93
τq ∈S+
⇐⇒
q ∈(G + H),
(4.18)
with G and H as in equations (4.15) and (4.16) of Counterexample 4.5.12.
Then S+ is ∪-closed and so M is closed. But S+ has no atom at τ1 and
thus has no base by Theorem 4.5.10. The positive digraph of this medium is
displayed in Figure 4.5.
.
..
.
..
.
..
.
..
1
1
1
1
1
 1
2
 1
2
 1
3
 1
3
 1
n
 1
n
 1
n  
1
n1    
1  1
n  
1
n1    
1  1
4   1
5    
 1
4   1
5    
 1
3   1
4    
1  1
3   1
4    
1  1
2   1
3    
 1
2   1
3    
Figure 4.5. Positive digraph of the closed medium induced by the family of positive
contents bS+ deﬁned by Eq. (4.18); cf. Eqs. (4.15) and (4.16) of Counterexample
4.5.12. The positive content of the corresponding state is indicated near each vertex.
We end this section with a reformulation, in the context of a medium, of
the well–known Union-Closed Sets Conjecture proposed by Frankl in 19797
but stated in print much later, for example as an open problem by D. Duﬀus
(in Rival, 1985, p. 525), and in any event by Frankl himself (see Frankl, 1995,
p. 1296).
4.5.18 Deﬁnition. For any medium (S, T) and any τ ∈T, we write
Sτ = {S ∈S τ ∈S}.
(4.19)
4.5.19 Conjecture. Let (S, T) be a closed medium with orientation {T+, T−}.
Then there exists a token τ ∈T+ and a 1-1 function f : S˜τ →Sτ.
7 Frankl’s original formulation involved sets closed under intersection, not union.

94
4 Closed Media and ∪-Closed Families
While proving Conjecture 4.5.19 would only establish a special case of the
Union-Closed Sets Conjecture (which does not assume wellgradedness), it may
achieve a useful step. There are numerous partial results of the Union-Closed
Sets Conjecture. Some of them could be found, for example, in Sarvate and
Renaud (1989, 1990); Lo Faro (1994a,b); Vaughan (2002), but the question is
still open.
4.6 Projection of a Closed Medium
The concept of a projection of a medium (S, T) was introduced in Chapter 2
as a token system constructed from (S, T) by gathering the states in S into
equivalence classes, and arranging for each of these classes to be a state of the
new token system. The corresponding equivalence relation ∼is obtained by
choosing a symmetric subset U ⊆T of tokens (that is, τ ∈U if and only if
˜τ ∈U), and declaring that S ∼V for two states of S if V is produced from
S by a concise messages whose tokens are all in T \ U. The tokens in U are
then redeﬁned so as to act on the equivalence classes (see Deﬁnitions 2.11.2
and 2.11.4). We have seen in Theorem 2.11.6 that not only is the projection
so deﬁned a genuine medium—which we denoted by (S|U, T|U)—but each of
the equivalence classes other than singletons forms the set of states of a sub-
medium of (S, T). Moreover, if (S, T) is oriented, then so is (S|U, T|U), and the
orientation of (S|U, T|U) is in fact ‘inherited’ from (S, T). We show here that
a similar hereditary property holds in the case where (S, T) is closed.
For convenience, we recall the deﬁnitions of the projection concepts given
in 2.11.4. We start with a medium (S, T) and choose a nonempty symmetric
subset U of T. We then deﬁne the equivalence relation ∼on S induced by U
via the formula
S ∼T
⇐⇒
⎧
⎪
⎨
⎪
⎩
either S = T
or Sm = T and C(m) ⊆(T \ U)
for some concise message m.
(4.20)
[S] = {T ∈S S ∼T},
(S ∈S);
S|U = {[S] S ∈S},
τ|U : S|U →S|U : [S] →[S]τ|U,
(τ ∈U);
with
[S]τ|U =

[T]
if S ̸∼T and ∃(Q, W) ∈[S] × [T], Qτ = W,
[S]
otherwise,
(4.21)
T|U = {τ|U τ ∈U}.
The pair (S|U, T|U) is called the projection of (S, T) under U.

4.6 Projection of a Closed Medium
95
4.6.1 Theorem. Suppose that M = (S, T), U and M|U = (S|U, T|U) are as
above, and have the matching orientations {T+, T−}, {T+
|U, T−
|U}, with
T+
|U = {τ|U ∈T|U τ ∈T+},
T−
|U = {τ|U ∈T|U τ ∈T−}.
(4.22)
If M is closed, the following two statements are true.
(i) M|U is also closed and we have
(Sτ = T, Sτ ′ = T ′, T ̸= T ′)
=⇒
([T] ̸= [T ′], [T]τ ′
|U = [T ′]τ|U)
(τ, τ ′ ∈T+ ∩U, τ|U, τ ′
|U ∈T+
|U).
(ii) If M is rooted, then M|U is also rooted. Moreover, if R is the root of M,
then [R] is the root of M|U.
Proof. Note that by Theorem 2.11.6, (S|U, TU) is a medium.
(i) If τ|U, τ ′
|U ∈T+
|U, with [S]τ|U ̸= [S]τ ′
|U, then Sτ ̸= Sτ ′ and Sττ ′ = Sτ ′τ
by deﬁnition of T+
|U and T−
|U in (4.22) and because M is closed. This gives
[Sτ]τ ′
|U = [S]τ|Uτ ′
|U = [Sτ ′]τ|U = [S]τ ′
|Uτ|U.
(ii) Since the root R of M is in [R], the messages from [R] producing all
the other states of (S|U, T|U) are positive by (4.22).
4.6.2 Example. The situation described in statement (ii) of the above
theorem is illustrated by Figure 4.6, which displays a rooted medium
M represented by its family of positive contents, which is a learning space
on the set {A, B, C, D, E, F} (cf. Theorem 4.2.2). The set of tokens of M is
thus T = {γA, ˜γA, . . . , γF , ˜γF }. Deﬁning U = {γB, ˜γB, γD, ˜γD, γE, ˜γE, γF , ˜γF }
gives the projection M|U which is also represented by its own learning space.
4.6.3 Remark. Note that if a medium (S, T) is closed for some orientation
{T+, T−}, then any submedium (Q, TQ), with Q ⊂S, is closed for the orienta-
tion {T+
Q, T+
Q} induced by {T+, T−}, that is, τQ ∈T+
Q if and only if τ ∈T+ (see
Problem 4.19). This fact obviously applies, in particular to all the submedia
([S], T[S]) of Theorem 4.6.1 with S ∈S.
Example 4.6.2 was motivated by the concept of a learning space. Our
next and last illustration, in Figure 4.7 and Example 4.6.4, is inspired by the
technique of triangulation in computational geometry.
4.6.4 Example. A triangulation of a planar point set is a graph, drawn with
non-crossing straight line segments as edges, having the points as its vertices,
such that all interior faces of the drawing are triangles. Two triangles are
connected by a ﬂip if and only if they diﬀer by the removal of one edge and
the insertion of a single replacement edge. Eppstein (2007a) proved that the
system of triangulations and ﬂips of a point set forms the states and tokens

96
4 Closed Media and ∪-Closed Families
A
BD
AC
BC
AB
BDF
ABC
BCD
BCE
ABD
ABCD
ABCE
BCDF
ABCDF
ABCDE
ABCDEF
BCDEF
ABCEF
BCDE
BCEF
ABDF
B
C
BDF
BDEF
BDE
BEF
BD
BE
B
Ø
Ø
B
D
E
F
Figure 4.6. A rooted medium M = (S, T) represented by its family of positive
contents forming a learning space on the set {A, B, C, D, E, F}, together with one
of its projection M|U = (S|U, T|U) represented the same way, as a learning space on
the set {B, D, E, F}.
of a medium, if and only if the point set does not contain any ﬁve points
forming the vertices of an empty pentagon; that is, a pentagon that does
not contain any other points from the set. In this medium, there are two
tokens for each pair of edges that can be ﬂipped; each such token performs
the replacement of one edge in the pair for the other, in triangulations for
which such a replacement is possible. The medium is closed when oriented by
ﬂips towards the Delaunay triangulation.

4.6 Projection of a Closed Medium
97
Figure 4.7. The medium of triangulations on a 3 × 3 grid of integer points in the
plane. The states of the medium are grouped according to the set of length-
√
2
edges present in each triangulation, forming a projection onto a four-dimensional
hypercube. The number of lines drawn between each pair of groups of states indicates
the number of transitions of the original medium connecting the pair of groups. From
Eppstein (2007a).
In particular, the integer lattice contains no empty pentagon, so we get a
medium for any m×n grid of integer points; Figure 4.7 depicts the states and
transitions of the resulting medium for a 3 × 3 grid of nine points. This ﬁgure
depicts a projection of the medium in which the set U of tokens deﬁning the
projection are the ﬂips that preserve the length of the ﬂipped edge. Such a ﬂip
must replace one length-
√
2 diagonal of a unit square by the other diagonal of
the same square. If U is the set of tokens corresponding to length-preserving
ﬂips, then the grouping in the ﬁgure depicts the projection of the medium
for U. In any m × n grid, and any triangulation of such a grid in which
all edges have unit length or length
√
2, each length-preserving ﬂip can be

98
4 Closed Media and ∪-Closed Families
performed independently of each other such ﬂip; thus, the number of states in
the projection for this set of tokens is 2(m−1)(n−1). In the depicted case of a
3×3 grid, the resulting projection is a 4-dimensional hypercube. The original
medium has 64 states, shown in the ﬁgure as the small triangulations, while
its projection has 16 states, shown as the groups of triangulations enclosed by
dashed circles.
Problems
4.1 Prove Theorem 4.1.3.
4.2 Verify that the medium deﬁned in Example 4.3.5 is complete. Let Z be a
nonempty set. Give an example of a well-graded subfamily F ⊂Pf(Z) (where
Pf(Z) is the set of all ﬁnite subsets of Z) inducing a complete medium in the
sense of (3.8) and (3.9) and Deﬁnition 3.3.2. What can we say about such a
family?
4.3 A medium is said to be taut if, for any two tokens τ and τ ′ and any
orderly circuit mττ ′n, the segment ττ ′ must be part of an orderly circuit of
length 4. Prove or disproved that any oriented taut medium having a root
must be closed.
4.4 Disprove the following proposition by a counterexample: If N is a closed
submedium of a ﬁnite closed medium M. If N and M have the same number
of tokens, then N = M.
4.5 Prove by a counterexample that the statement in the ﬁrst sentence of
Theorem 4.1.11 does not hold if the word ‘ﬁnite’ is removed.
4.6 Which conditions (necessary and/or suﬃcient) on the digraph of an ori-
ented medium ensure that the family of all positive contents is closed under
intersection?
4.7 Prove Theorem 4.1.18.
4.8 Give an example of a ∪f-closed family having an inﬁnite base.
4.9 Prove Lemma 4.3.10 and Theorem 4.3.11.

Problems for Chapter 4
99
4.10 Deﬁnition. A quasimedium is a token system (S, T) satisfying Axiom
[Mb], plus the following weaker version of Axiom [Ma]:
[Ma†] For any two distinct states S and V in S, there is a message trans-
forming S into V .
Which part, if any, of Lemma 2.3.1 remains true? Prove your results and give
a counterexample for any part of the lemma that no longer holds.
4.11 Prove Theorem 4.5.9.
4.12 Can an inﬁnite ∪-closed wg-family have a base? Give an example or
prove that this cannot happen.
4.13 Prove the last statement in Theorem 4.5.13.
4.14 Sketch an algorithm for verifying that the base of a ﬁnite ∪-closed family
satisﬁes the condition of Theorem 4.5.13.
4.15 (Continuation.) Assuming that the base of a ﬁnite ∪-closed family does
not satisfy the condition of Theorem 4.5.13, sketch an algorithm adding miss-
ing states in some optimal way (for example minimizing the number of new
states), thus ensuring that the resulting ∪-closed family is well-graded.
4.16 (a) Verify the ∪-closed family of Counterexample 4.5.12 has no base and
has no atom at the point 1. (b) Verify that the wg-family H of this example
is ∪-closed is its own base, with again no atom at the point 1.
4.17 For a closed medium (S, T), denote by S[τ1,...,τn] the subset of all states
S such that τi is eﬀective for S, for 1 ≤i ≤n. Consider S[τ] and S[τ ′] with
τ ̸= τ ′; described S[τ] ∩S[τ ′] in each of the possible cases and try to derive
some conclusions.
4.18 We can now reformulate Theorem 3.4.12 in the context of complete me-
dia. Prove the following: The representing medium (F, WF) of any wg-family
F is a submedium of a complete medium and is isomorphic to a submedium
of the complete medium (Pf(X), WPf(X)) of all ﬁnite subsets of X = ∪F.
4.19 Verify that if a medium (S, T) is closed for some orientation {T+, T−},
then any submedium (Q, TQ), with Q ⊂S, is closed for the orientation
{T+
Q, T+
Q} induced by {T+, T−}, that is, τQ ∈T+
Q if and only if τ ∈T+.

5
Well-Graded Families of Relations
We have seen in Chapter 3 that wg-families of sets oﬀer a systematic way of
representing oriented media in which the sets of the family stand for the states
of the medium, and the addition or removal of a given point from any set stand
for a token or its reverse. The representation results are formulated by Theo-
rems 3.3.3 and 3.3.4. The purpose of this chapter is to establish that several
well-known families of relations, such as the partial orders, the biorders, the
interval orders and the semiorders are well-graded, and can thus be repre-
sented by media. We also discuss another family, the almost connected orders
or ac-orders, which are well-graded if and only if the size of their ground set
does not exceed four, oﬀering thus a revealing counterexample.
The material in this chapter follows closely Doignon and Falmagne (1997)
and, in the last section, Doble et al. (2001). For all these examples, we assume
that the sets involved are ﬁnite.
5.0.1 Remark. The ﬁniteness assumption simpliﬁes our discussion, but is not
critical. Following the pattern used in Chapter 3 in our treatment of a possibly
inﬁnite family of all the linear orders on a set that are at ﬁnite distance from
one of them, we could consider the family F of all the semiorders (for example)
on some arbitrary set X that are at ﬁnite distance from one of them, that is,
lying in one class of the cluster partition P(X × X)▷◁(cf. Deﬁnition 3.4.1).
With some adaptation of the techniques of this chapter, we could prove that
the family F is well-graded. The other families of relations discussed in this
chapter could be dealt with similarly. However interesting such a development
would be, it would go beyond what is intended here, which is to provide a
collection of examples of well-known relations whose families deﬁne media. In
any event, a few of the problems at the end of the chapter are devoted to
exploring this avenue.

102
5 Well-Graded Families of Relations
5.1 Preparatory Material
In some of our proofs, we use relative product calculus and notation whenever
they enable substantially shorter arguments. We recall some concepts encoun-
tered earlier but speciﬁed here in compact set-theoretical notation. We also
introduces a couple of new properties.
5.1.1 Deﬁnition. Let X be of arbitrary cardinality, and let R be a relation
on that set. We deﬁne
IX = R0 = {xx x ∈X}
as the identity on X
R−1 = {xy yx ∈R}
as the converse of R
¯R = {xy xy /∈R, x, y ∈X}
as the complement of R
(with respect to X × X).
When no ambiguity can arise regarding the ground set X, we abbreviate IX
as I. As recalled above from 1.8.2, we have R0 = I.
A relation R on X is
reﬂexive
if
I ⊆R
(5.1)
irreﬂexive
if
I ∩R = ∅
(5.2)
symmetric
if
R ⊆R−1
(5.3)
asymmetric
if
R ⊆¯R−1
(5.4)
antisymmetric
if
R ∩R−1 ⊆I
(5.5)
transitive
if
RR ⊆R
(5.6)
strongly connected
if
¯R−1 ⊆R
(5.7)
n-connected
if
Rn ¯R−1 ⊆R.
(5.8)
Thus, R is 0-connected if and only if it is strongly connected ( ¯R−1 ⊆R), and
R is 2-connected if and only if
xRy ∧yRz ∧¬(wRz) ⇒xRw
(x, y, z, w ∈X).
Our last condition also involve a second set Y which is possibly (but not
necessarily) distinct from X. A relation R ⊆X × Y is
a biorder
if
R ¯R−1R ⊆R.
(5.9)
We say then that R is a biorder from X to Y. The biorder deﬁning condition
applies obviously also to the case in which X = Y.
Five types of relations are studied here from the standpoint of the wellgrad-
edness of their families: the partial orders, the biorders, the interval orders,
the semiorders, and the almost connected orders, or ac-orders. We deﬁne or
redeﬁne four of these concepts.

5.2 Wellgradedness and the Fringes
103
A relation R on a set X is
a partial order
if
it is transitive and asymmetric
(5.10)
a strict weak order
if
it is 1-connected and asymmetric
(5.11)
an interval order
if
it is irreﬂexive biorder
(5.12)
a semiorder
if
it is a 2-connected interval order
(5.13)
an ac-order
if
it is 2-connected and asymmetric.
(5.14)
5.1.2 Remark. The almost connected orders or ac-orders are especially in-
teresting because they are well-graded only if |X| ≤4, but satisfy in general
the weaker properties of being ‘upgradable’ and ‘downgradable.’ We discuss
this concept in the last section.
We introduce an important tool for the study of wg-families.
5.2 Wellgradedness and the Fringes
5.2.1 Deﬁnition. Let F be a graded family of subsets of a set X = ∪F; that
is, |F| ≥2 and for any x ∈X \ ∩F, there is some Q and S in F satisfying
Q △S = {x}; cf. Deﬁnition 3.2.1. Writing S = X \ S for any S ∈F, deﬁne the
three sets
SI = {x ∈S S \ {x} ∈F},
SO = {x ∈S S + {x} ∈F},
SF = SO ∪SI.
The sets SI, SO, and SF are called the inner fringe, the outer fringe, and the
fringe of the set S ∈F, respectively. Note that the fringes of a set are always
deﬁned with respect to a particular family of sets.
The following result is due to Doignon and Falmagne (1997). Except for
minor details1, the proof below is essentially that given in their monograph
Doignon and Falmagne (1999, Theorem 2.8, p. 48), and is included here for
completeness2.
5.2.2 Theorem. The ﬁve conditions listed below are equivalent for any
graded family of sets F. Conditions (ii) to (v) apply to any two sets S and T
in F.
1 Our deﬁnition of wellgradedness slightly diﬀers from that used in Doignon and
Falmagne (1999) but equivalent to it, as established in fact by their Theorem 2.8
2 An adaptation of the concept of fringe to the states of a medium was already
encountered in Chapter 2; see Deﬁnition 2.5.1 and Theorem 2.5.2.

104
5 Well-Graded Families of Relations
(i) The family F is well-graded.
(ii) There exists a path (Sj)0≤j≤k from S = S0 to T = Sk such that, for
0 ≤j ≤k −1, we have
Sj ∩T ⊆Sj+1 ⊆Sj ∪T .
(5.15)
(iii) (S △T) ∩SF ̸= ∅.
(iv) If SI ⊆T and SO ⊆T, then S = T.
(v) If the four inclusions
SI ⊆T,
SO ⊆T,
T I ⊆S, and T O ⊆S
hold, then S = T.
Proof. We prove (i) ⇒(ii) ⇒(iii) ⇒(iv) ⇒(v) ⇒(i).
(i) ⇒(ii). By deﬁnition of wellgradedness (3.1.2), there exists a tight path
S0 = S, S1, . . . , Sk = T from S to T. Problem 5.2 requires the reader to prove
that such a tight path veriﬁes (5.15) for 0 ≤j ≤k −1.
(ii) ⇒(iii). Take any two states S and T, and let (Sj)0≤j≤k be the path
described in Condition (ii). Then S and S1 diﬀer by exactly one point x, and
we have moreover S ∩T ⊆S1 ⊆S ∪T. Either the x belongs to S, or it belongs
to T, but not both. Hence x belongs to (S △T) ∩T F.
(iii) ⇒(iv). Proceeding by contradiction, we take two sets S and T sat-
isfying SI ⊆T and SO ⊆¯T, with some x ∈(S △T) ∩SF. If x ∈S, then
x ∈SI ⊆T, contradicting x ∈S △T. Hence x /∈S, but then x ∈T ∩SO,
yielding x ∈SO ⊆¯T, a contradiction.
(iv) ⇒(v). Trivial.
(v) ⇒(i). Let S and T be two distinct sets in F with d(S, T) = k > 0.
We establish (i) by constructing a tight path (Sj)0≤j≤k from S and T. Since
S ̸= T, Condition (v) implies that there must be some point
x ∈(SI \ T) ∪(SO ∩T) ∪(T I \ S) ∪(T O ∩S).
If x ∈SI\T, we set S1 = S\{x}. In the other three cases, we set S1 = S∪{x}
or Sk−1 = T \ {x} or Sk−1 = T ∪{x}. We obtain either d(S1, T) = k −1 (in
the ﬁrst two cases), or d(S, Sk−1) = k −1 (in the last two cases). The result
follows by induction.
5.2.3 Remark. A consequence of Theorem 5.2.2 is that any set in a well-
graded family F is deﬁned by its fringes in the sense of the condition
[F]
(SI = T I and SO = T O) ⇐⇒R = S
(S, T ∈F).
However, Condition [F] does not imply wellgradedness (Problem 5.6).
On the other hand, if a family F is closed under ﬁnite intersection and also
satisﬁes ∅∈F, then it is well-graded if and only if any set in F is deﬁned by
its inner fringe in the sense of the condition

5.2 Wellgradedness and the Fringes
105
[IF]
SI = T I ⇐⇒S = T
(S, T ∈F).
The proof of this statement is left as Problem 5.9.
We have encountered statements similar to [F] and [IF] in Chapter 2,
concerning the eﬀective set and the productive sets of a state in a medium
(cf. Deﬁnition 2.5.1 and Theorem 2.5.2). We recall that, by Theorem 3.2.6,
the family S+ of positive content of an oriented medium (S, T) is well–graded.
The links between the eﬀective and the productive sets SE and SP of a state
S and the fringes of S+ with respect to S+ are speciﬁed below.
5.2.4 Deﬁnition. For any subset of tokens Γ in a medium (S, T) we write

Γ = {τ ∈T ˜τ ∈T \ Γ}.
5.2.5 Theorem. Let (S, T) be an oriented medium, with orientation {T+, T−}
and family of positive contents S+. Then, the following two equalities hold for
any state S:
SE =

S+O
∪


S+
I
(5.16)
SP =

S+I
∪


S+
O
.
(5.17)
Proof. For any token τ and state S, we have successively,
τ ∈SE ⇐⇒

τ ∈T+ or τ ∈T−
and (Sτ = T ̸= S)
(for some T ∈S)
⇐⇒

τ ∈

S+O
or

τ ∈T−, Sτ = T ̸= S

(for some T ∈S)
⇐⇒

τ ∈

S+O
or

˜τ ∈T+, T ˜τ = S ̸= T

(for some T ∈S)
⇐⇒

τ ∈

S+O
or

˜τ ∈

S+I
⇐⇒

τ ∈

S+O
or

τ ∈


S+
I

⇐⇒
τ ∈

S+O
∪


S+
I

.
The argument establishing (5.17) is similar (Problem 5.4).

106
5 Well-Graded Families of Relations
5.3 Partial Orders
We use the results of the following four lemmas to show that the family of all
the partial orders on a ﬁnite set is well-graded (see Theorem 5.3.5).
5.3.1 Lemma. Let F be a family of subsets closed under ﬁnite intersection.
Then F is well-graded if and only if for any two sets S, T in F with S ⊂T
and |T \ S| = k, there exists a chain of sets S0 = S ⊂S1 ⊂. . . ⊂Sk = T in F
such that |Sj \ Sj−1| = 1 for j = 1, 2, . . . , k.
Proof. The necessity follows immediately from the deﬁnition of wellgradedness.
The suﬃciency is also easily established: if T and T ′ are in F, then so is
T ∩T ′ and there exists two chains S0 = T ∩T ′ ⊂S1 ⊂. . . ⊂Sk = T and
S′
0 = T ∩T ′ ⊂S′
1 ⊂. . . ⊂S′
m = T such that |Sj \ Sj−1| = 1 for j = 1, 2, . . . , k
and |S′
i \ S′
i−1| = 1 for i = 1, 2, . . . , m. Concatenating these two chains and
relabelling the indices yields the sequence
T0 = T = Sk, T1 = Sk−1, . . . , Tk = S0 = T ∩T ′ = S′
0,
Tk+1 = S′
1, . . . , Tk+m = S′
m = T ′
required by the deﬁnition of wellgradedness.
We now specify the fringes in a family of all partial orders of a ﬁnite set.
5.3.2 Lemma. The two fringes of a partial order P on a ﬁnite set are de-
scribed by the formulas
P I = P \ PP
(5.18)
P O = ¯P \ (I ∪¯PP −1 ∪P −1 ¯P).
(5.19)
We omit the proof (Problem 5.5). Note that P I is the Hasse diagram of P. The
pairs in the outer fringe P O of P are referred to as critical pairs or nonforced
pairs by Trotter (1992).
In passing, we prove a variant of Lemma 3.5.1 which is of general interest
and is relevant to Problem 5.7.
5.3.3 Lemma. Suppose that L is a strict linear order. Then L \ {xy} is a
partial order if and only if x covers y in L.
Proof. (Necessity.) Let L and P = L \ {xy} be a strict linear order and a
partial order, respectively. We cannot have both xPz and zPy, because then
also xPy by the transitivity of P, contradicting the construction of P. So, x
covers y in L.
(Suﬃciency.) Let L be strict linear order in which x covers y. The relation
P = L \ {xy} is asymmetric by deﬁnition. To verify its transitivity, suppose
that uPvPw. If |{x, y} ∩{u, v, p}| ≤1, we get uLvLw, and uLw follows
from the transitivity of L, which gives uPw because uw ̸= xy. Suppose that
|{x, y} ∩{u, v, p}| = 2. Three cases must be checked.

5.4 Biorders and Interval Orders
107
1. uv = yx, so uLv with vPw yielding vLw because w ̸= x and w ̸= y; we
obtain uLw by the transitivity of L, and so uPw.
2. vw = yx, so vLw with uPv yielding uLv because u ̸= x and v ̸= y; we
obtain again uLw and thus uPw.
3. uLv, uv ̸= yx and vLw, vw ̸= yx; then uLw by the transitivity of L, and
uw ̸= yx because x covers y in L; so uPw.
5.3.4 Lemma. Suppose that P and Q are two partial orders on the same
set X satisfying Q ⊂P and d(P, Q) = n ∈N. Then there exists a chain
Q0 = Q ⊂Q1 ⊂. . . ⊂Qn = P of partial orders such that d(Qi, Qi+1) = 1 for
0 ≤i ≤n −1.
Proof. Pick a pair xy ∈P I and deﬁne Qn−1 = P \ {xy}; so, d(P, Qn−1) = 1
and, since Q ⊆Qn−1 ⊂Qn = P, we obtain d(Q, Qn−1) = n −1. The lemma
follows by induction.
5.3.5 Theorem. The family P of all partial orders on a ﬁnite set X is closed
under intersection and well-graded.
Proof. It is well-known (and in any event, easily veriﬁed—see Problem 5.1)
that the intersection of a family of partial orders is a partial order. This
implies that the family P is closed under ﬁnite intersection. Applying ﬁrst
Lemma 5.3.4, and then Lemma 5.3.1, we conclude that P is well-graded.
This result is due to Bogart (1973) (cf. also Kuzmin and Ovchinnikov,
1976).
5.4 Biorders and Interval Orders
The concept of a biorder ﬁrst appeared in the literature in the form of a device
for the measurement of human attitudes or aptitudes (Guttman, 1944). It was
widely used in the behavioral sciences under the name ‘Guttman scales.’ The
corresponding combinatoric object, called a ‘Ferrers relation’, was indepen-
dently studied by Riguet (1951) (see also Cogis, 1982). The connection was
established by Ducamp and Falmagne (1969), who relabelled them ‘bi-quasi-
series’ in the context of ordinal measurement. They proved that, in the case
of ﬁnite sets X and Y, a relation R ⊆X × Y satisﬁes the biorder condition
(5.9), that is, R ¯R−1R ⊆R, if and only if there exists functions f : X →R
and g : Y →R such that
xRy
⇐⇒
f(x) > g(y)
(x ∈X, y ∈Y).
(5.20)
Also independently, Fishburn (1970) introduced the interval orders which,
as we have seen, are irreﬂexive biorders from X to X. The name ‘biorder’ was

108
5 Well-Graded Families of Relations
coined3 by Doignon et al. (1984), who extended the representation (5.20) to
the case of inﬁnite sets X and Y satisfying a condition of order density. This
term is justiﬁed by the fact that a biorder R ⊆X × Y induces two strict
weak orders; one on the set X, deﬁned by R ¯R−1; and the other on the set
Y, deﬁned by ¯R−1R (see Lemma 5.4.1(ii)). The wellgradedness of the family
of all biorders between two ﬁnite sets X and Y was proved by Doignon and
Falmagne (1997). A slightly more detailed version of their argument is given
here. The corresponding result for interval orders is also stated4. We suppose
throughout that any biorder under consideration belongs to the family of all
the biorders from a ﬁnite set X to a ﬁnite set Y.
We begin with some straightforward consequences of the deﬁnition of a
biorder. We omit the simple proofs of Lemmas 5.4.1 and 5.4.3 and of Theorem
5.4.2 (see Problems 5.8, 5.10 and 5.11).
5.4.1 Lemma. If R is a biorder, then:
(i) ¯R and R−1 are biorders;
(ii) R ¯R−1 and ¯R−1R are strict weak orders.
Not surprisingly, the main tool of our proof lies in the two fringes of the
biorders in the family. The next theorem specify those fringes.
5.4.2 Theorem. The inner and outer fringes of a biorder R from X to Y are
respectively deﬁned by
RI = R \ R ¯R−1R,
and
RO = ¯R \ ¯R R−1 ¯R.
We immediately reformulate these two equalities in the next lemma.
5.4.3 Lemma. For any biorder R, we have
R ∩RI = R ¯R−1R,
(5.21)
¯R−1 ∩RO = ¯RR−1 ¯R.
(5.22)
To establish that the family of all biorders between two ﬁnite sets is well-
graded, we prove that any two biorders in the family satisﬁes Condition (iv)
of Theorem 5.2.2. The next theorem is the key step. A more intricate ver-
sion of the same idea is also exploited in the next section to deal with the
wellgradedness of semiorders (cf. Deﬁnition 5.5.3 and Theorem 5.5.4).
3 As far as we can tell, the name ‘biorder’ is gaining acceptance.
4 The wellgradedness of interval orders, which was presented as an obvious corollary
in Doignon and Falmagne (1997), results in fact from a similar, but separate
argument.

5.4 Biorders and Interval Orders
109
5.4.4 Lemma. Any biorder R in the family of all biorders between two ﬁnite
sets X and Y satisﬁes the condition
R = ∪∞
n=0(R ¯R−1)nR = ∪∞
n=0(RI(RO)−1)nRI.
(5.23)
Proof. We show that
R ⊆∪∞
n=0(R ¯R−1)nR ⊆∪∞
n=0(RI(RO)−1)nRI ⊆R.
(5.24)
The ﬁrst inclusion follows from the term n = 0 in the r.h.s. To get the second
inclusion, take any xy ∈∪∞
n=0(R ¯R−1)nR. Thus, xy is in at least one of the
terms (R ¯R−1)nR and may belong to more than one. Because X and Y are
ﬁnite, we may suppose that
xy ∈(R ¯R−1)kR
(5.25)
with k maximal. This implies that each of the k + 1 factors R of the product
in (5.25) can be replaced by RI with still xy ∈(RI ¯R−1)kRI. Indeed, if this
were not true, there would be some z, either in Y with xz ∈R ∩RI = R ¯R−1R
or in X with xz ∈R ∩RI = R ¯R−1R, both equalities resulting from (5.21).
This would imply that we could rewrite (5.25) with (k + 2) + 1 factors R,
contradicting the maximality of k. A similar argument, based on (5.22), proves
that we can replace each of the k factors ¯R−1 in (5.25) by (RO)−1, and still
have xy ∈(RI(RO)−1)kRI. Thus, the second inclusion in (5.24) holds. To
obtain the third inclusion, we notice that RI ⊆R and both RI(RO)−1RI ⊆
R and R(RO)−1RI ⊆R by the biorder inclusion R ¯R−1R ⊆R. This gives
(RI(RO)−1)0RI = RI ⊆R for n = 0, and for any n > 0, using induction,
(RI(RO)−1)nRI =
⊆R



(RI(RO)−1)(RI(RO)−1) . . . (RI(RO)−1)



n products (RI(RO)−1)
RI
⊆
⊆R



(R(RO)−1)(RI(RO)−1) . . . (RI(RO)−1)



one product (R(RO)−1), n −2 products (RI(RO)−1)
RI
. . .
⊆R(RO)−1)RI ⊆R.
We conclude that (5.23) holds.
5.4.5 Lemma. For any two biorders R and S from X to Y, we have
(RI ⊆S and RO ⊆¯S)
=⇒
R = S.

110
5 Well-Graded Families of Relations
Proof. Suppose that RI ⊆S ∧RO ⊆¯S. We have successively
R = ∪∞
n=0(RI(RO)−1)nRI
(by Lemma 5.4.4)
⊆∪∞
n=0(S ¯S−1)nS
(because RI ⊆S and RO ⊆¯S)
= S
(by Lemma 5.4.4).
To establish the converse inclusion, note that both ¯R and ¯S are also
biorders (Lemma 5.4.1(i)), and that ( ¯R)I = RO and ( ¯R)O = RI (Problem
5.8(iii)). Our hypothesis can be restated as ( ¯R)I ⊆¯S and ( ¯R)O ⊆( ¯S). Using
the argument of the ﬁrst part of this proof yields ¯R ⊆¯S, so S ⊆R.
5.4.6 Theorem. The family F of all the biorders R from a ﬁnite set X to a
ﬁnite set Y is well-graded.
Proof. Notice that F is a graded family. Indeed, for any xy ∈X × Y, both
X × Y and X × Y \ {xy} are biorders. The result follows readily from Lemma
5.4.5 and the implication (iv) ⇒(i) of Theorem 5.2.2.
5.4.7 Theorem. The family of all interval orders on a ﬁnite set X is well-
graded.
Although every interval order on a set X is a biorder from X to X, Theorem
5.4.7 cannot be regarded as a corollary of Theorem 5.4.6 because a biorder
from a set to itself may be reﬂexive: consider the biorder X × X. However, a
careful check shows that the argument used to establish the wellgradedness
of biorders also applies to the interval orders. The veriﬁcation is left to the
reader (Problem 5.13).
5.5 Semiorders
From Deﬁnition 5.1.1, (5.13), we know that a relation R on a set X is a
semiorder if the following three conditions are satisﬁed:
R ∩I = ∅
(R is irreﬂexive)
(5.26)
R ¯R−1R ⊆R
(R is a biorder)
(5.27)
RR ¯R−1 ⊆R
(R is 2-connected).
(5.28)
The concept of a semiorder is due to by Luce (1956) who, inspired by
the notion of ‘just-noticeable-diﬀerence’ in psychophysics, introduced it as a
form of linear order tempered by a (ﬁxed) threshold. The standard numerical
representation for semiorder is consistent with this intuition. It was shown by
Scott and Suppes (1958) that if X is a ﬁnite set, then R is a semiorder if and
only if there exists a function f : X →R such that

5.5 Semiorders
111
xRy
⇐⇒
f(x) > f(y) + 1.
(5.29)
Note that (5.29) is a special case of (5.20) (Problem 5.14).
The family of all the semiorders on a ﬁnite set is well-graded. Our argument
establishing this fact is similar to that used in the previous section to prove the
wellgradedness of a family of biorders, but relies on a more intricate machinery.
We begin by noting some useful equivalences between formulas.
5.5.1 Lemma. For any relation R, we have:
R ¯R−1R ⊆R
⇐⇒
¯RR−1 ¯R ⊆¯R
(5.30)
and
RR ¯R−1 ⊆R
⇐⇒
¯R−1RR ⊆R
(5.31)
⇐⇒
¯R ¯RR−1 ⊆¯R
(5.32)
⇐⇒
R−1 ¯R ¯R ⊆¯R.
(5.33)
We omit the simple proofs (Problem 5.15). Next, we specify the fringes of
a semiorder.
5.5.2 Theorem. The family of all semiorders on a ﬁnite set X is graded.
Moreover, the inner and outer fringes of a semiorder R on X are deﬁned by
the equalities
RI = R \

R ¯R−1R ∪¯R−1R R ∪R R ¯R−1
(5.34)
and
RO = ¯R \

I ∪¯R R−1 ¯R ∪R−1 ¯R ¯R ∪¯R ¯R R−1
.
(5.35)
Problem 5.16 requires the reader to verify these facts.
Our next deﬁnition introduces a compact notation for two particular types
of unions of products of the two relations R and ¯R−1. These devices will permit
us to deal eﬃciently with a wide variety of products of the type RR ¯R−1R,
¯R−1RR ¯R−1, etc.
5.5.3 Deﬁnition. For any product r = R1 · · · Rn, n ∈N of relations on the
same set, we denote by cR(r) the number of occurrences of the relation R
in the product r; thus cR(RR ¯R−1R) = 3 and c ¯
R−1(RR ¯R−1R) = 1. We then
deﬁne, for any two relation R and S on the same set, the collection of products
RRS = {r r = R1 · · · Rn, n ∈N, Ri = R or Ri = S, 1 ≤i ≤n},
and the two unions
R ⊵S =

{r ∈RRS cR(r) ≥cS(r)}
R ▷S =

{r ∈RRS cR(r) > cS(r)}.

112
5 Well-Graded Families of Relations
Thus, the diﬀerence between R ⊵S and R ▷S is that the products included
in the later have strictly more R’s than S’s. For example, R ▷¯R−1 is the
union of the products
R, RR, . . .
(c ¯
R−1(r) = 0)
RR ¯R−1, R ¯R−1R, ¯R−1RR, RRR ¯R−1, RR ¯R−1R, . . .
(c ¯
R−1(r) = 1)
RRR ¯R−1 ¯R−1, RR ¯R−1R ¯R−1, . . . , RRRR ¯R−1 ¯R−1, . . .
(c ¯
R−1(r) = 2)
. . .
The following result is our key step.
5.5.4 Theorem. For any semiorder R on a ﬁnite set X, we have
R = R ▷¯R−1 = RI ▷( ¯RO)−1.
(5.36)
We establish this theorem via the intermediate result below.
5.5.5 Lemma. The relation R ⊵¯R−1 is irreﬂexive if R is a semiorder.
Proof. We prove by induction on n + m that, for all n ≥m, n ≥1, we have
r = R1 · · · Rn+m ⊆¯I
(r ∈RR ¯
R−1, cR(r) = n ≥c ¯
R−1 = m, n ≥1).
Since R ⊵¯R−1 is the union of all such products, this proves the lemma.
Because R is irreﬂexive, we have r = R ⊆¯I, thus for cR(r) + c ¯
R−1(r) =
1 + 0 = 1. The inclusion r ⊆¯I also holds for cR(r) + c ¯
R−1(r) = 1 + 1 = 2 and
cR(r) + c ¯
R−1(r) = 2 + 0 = 2 because both R ¯R−1 and ¯R−1R are irreﬂexive
(Problem 5.8(ii)), and RR ⊆R. Suppose that n+m = k. If n = k and m = 0,
we get r = Rk ⊆R, which is irreﬂexive. In all other cases, the expression of
the product r must contain a partial product having one of the six forms:
(1) RR ¯R−1,
(2) R ¯R−1R,
(3) ¯R−1RR,
(4) R ¯R−1 ¯R−1,
(5) ¯R−1R ¯R−1,
(6) ¯R−1 ¯R−1R .
Using Lemma 5.5.1, we see that the ﬁrst three products can be replaced
by R, and the last three producs by ¯R−1. This results in replacing r with
cR(r) + c ¯
R−1(r) = n + m = k by r′ with cR(r′) + c ¯
R−1(r′) = n′ + m′ = k −2.
An induction argument establishes the lemma.
Proof of Theorem 5.5.4. We prove that
R ⊆R ▷¯R−1 ⊆RI ▷( ¯RO)−1 ⊆R.
(5.37)
Observation. If a product r in the union R ▷¯R−1 has a subproduct m
containing some pair zz, say r = n z m z p, then removing that subproduct
m from r yields some other product r′ = np ⊆R ▷¯R−1 such that

5.5 Semiorders
113
cR(r′) −c ¯
R−1(r′) > cR(r) −c ¯
R−1(r).
(5.38)
This is a consequence of Lemma 5.5.5: removing the subproduct m must
increase the diﬀerence between the number of R’s and the number of ¯R−1’s.
The ﬁrst inclusion in (5.37) holds by the deﬁnition of ▷. Suppose that
xy ∈R ▷¯R−1. This implies that x r y for some product r ⊆R ▷¯R−1.
Obviously, there may be more than one such product. Consider the set V of
all sequences x = x0, . . . , xk = y for some k ∈N, such that xi (R ∪¯R−1) xi+1
for 0 ≤i ≤k −1. Suppose that xi = xj for some 0 ≤i < j ≤k, say
xiRixi+1Ri+1 · · · Rjxj, with Ri+h = R or Ri+h = ¯R−1 for 0 ≤h ≤j −i.
By the above Observation, removing RiRi+1 · · · Rj = m from the product
r leaves a product r′ satisfying (5.38). Because there is a ﬁnite number of
sequences in V having no repeated elements, there is at least one product
q ⊆R ▷¯R−1 such that x q y and cR(q) is maximal. Take one such product q.
We claim that any occurrence of R in the product q can be replaced by RI.
Indeed, if this were not true for a particular instance of R in q, we could,
in view of Eq. (5.34) in Theorem 5.5.2, replace that R by one of R ¯R−1R,
¯R−1RR or RR ¯R−1, thus yielding in each of these three cases a product q′
still satisfying x q′ y, with cR(q′) −c ¯
R−1(q′) = cR(q) −c ¯
R−1(q), but also
cR(q′) = cR(q) + 1,
contradicting the maximality of cR(q). A similar argument, based on choosing
q so that c ¯
R−1(q) is maximal and x q y holds, shows that each ¯R−1 in q can
be replaced by (RO)−1. We have thus R ▷¯R−1 ⊆RI ▷( ¯RO)−1. As RI ⊆R
and (RO)−1 ⊆¯R−1, we also have RI ▷( ¯RO)−1 ⊆R ▷¯R−1, which gives
RI ▷( ¯RO)−1 = R ▷¯R−1. It remains to show that R ▷¯R−1 ⊆R. Suppose
that xy ∈(R ▷¯R−1); thus x r y for some product r ⊆R ▷¯R−1. Since
cR(r) > c ¯
R−1(r) ≤0, we have either r = Rn ⊆R for ≥1, in which case
xy ∈R, or the product r must have a subproduct having one of the three
forms:
RR ¯R−1,
R ¯R−1R, and ¯R−1RR,
(5.39)
each of which is included in R. This subproduct may be removed from the
expression of r, yielding a product r′ with still x r′ y and
cR(r′) −c ¯
R−1(r′) = cR(r) −c ¯
R−1(r)
cR(r′) = cR(r) −1 .
Applying induction, we can reduce r ultimately to one of the forms in (5.39),
which yields r ⊆R, and so xy ∈R.
5.5.6 Lemma. Let R and S be two semiorders on a ﬁnite set X; then
(RI ⊆S ∧RO ⊆¯S ∧SI ⊆R ∧SO ⊆¯R)
=⇒
R = S.
Proof. Use Theorem 5.5.4.

114
5 Well-Graded Families of Relations
5.5.7 Theorem. The family of all semiorders on a ﬁnite set is well-graded.
Proof. Use the implication (v) ⇒(i) of Theorem 5.2.2 together with Lemma
5.5.6.
5.5.8 Remark. Results related to our Lemma 5.5.6 have been obtained
by Pirlot (1991) who introduces the concept of a ‘reduced semiorder’ as a
semiorder S on a set X satisfying the condition
(∀z ∈X, xSz ⇔ySz and zSx ⇔zSy)
⇐⇒
x = y.
He deﬁnes the concept of ‘noses’ and ‘hollows’, which correspond, for reduced
semiorders, to the pairs in the outer and inner fringes in our sense, respec-
tively. He shows that a reduced semiorder is deﬁned by its noses and hollows.
Theorem 5.5.2, which5 is due to Doignon and Falmagne (1997), solves a prob-
lem raised by Pirlot in the conclusions of his paper.
5.6 Almost Connected Orders
We recall that a relation R on a set X is an ac-order if it is asymmetric and
2-connected, that is, R satisﬁes the condition
R2 ¯R−1 ⊆R.
(5.40)
Evidently, the term ‘almost connected’ was chosen because (5.40) is a natural
generalization of a connectedness condition6. Other names are used for Con-
dition (5.40), such as ‘semitransitivity’, by Chipman (1971), Fishburn (1997)
and Fishburn and Trotter (1999). Monjardet (1978) refers to ac-orders as ‘S-
relations’, and Fishburn (1985) calls them ‘partial semiorders.’ Examples and
counterexamples of ac-orders are displayed in Figure 5.1.
5.6.1 Remarks. This section summarizes the results of Doble et al. (2001),
from which Figures 5.1, 5.2 and 5.3 are adapted. Example (a) is in fact bor-
rowed from Fishburn (1985). It is a semiorder, a special case of an ac-order.
Example (b) is a strict weak order. Examples (c) and (d) are ac-orders which
are neither semiorders nor strict weak orders. Each of Examples (f) and (g)
satisﬁes exactly one of the two axioms of ac-orders: Counterexample (f) fails
asymmetry, and Counterexample (g) 2-connectedness. Neither (e) nor (h) is
an ac-order.
5 Along with most of the results presented so far in this chapter.
6 For example, a relation R is strongly connected if R0 ¯R−1 ⊆R holds. It is a strict
weak order if it is asymmetric and satisﬁes R ¯R−1 ⊆R, another connectedness
condition.

5.6 Almost Connected Orders
115
Examples
Counterexamples
A
AAU

 ?
A
AAU


•C
C
C
CCW
•
z
w
t
•
•
•
x
y
(a)
?
QQQQ
s
s •
r
•
@
@
@
R
?
•@
@
@
R
@
@
@
R
(e)
?
•
•
?
•
•
?
•
(b)




@
@
@
R
•
•
•
•@
@
@
R




•
b
•
d
(c)
a •




@
@
@
R•c
?
?
•e




@
@
@
R•
f
•
4
• 5




• 6
(d)
?
@
@
@
R
1 •
•
2
• 3




?
?
•
7
• 8
A
A
A
AAU




?






(h)
?
•
?
•
•
•
•
@
@
@
R
@
@
@
R
•
@
@
@
R
(g)
?
•
?
• •
•
Fails
2-connectedness
(f)
•
?
•
•




-

Fails
Assymetry
Figure 5.1. Examples and counterexamples of ac-orders.
Even though the attention given to ac-orders is relatively recent, notewor-
thy results have been obtained. For example, Fishburn (1985) showed that the
product of two ac-orders is an ac-order (Problem 5.18). Fishburn and Trot-
ter (1999) note that the (order) dimension of ﬁnite ac-orders (in the sense
of Dushnik and Miller, 1941) is unbounded, and that so are the semiorder
dimension and the interval order dimension. For other recent results, see also
Skandera (2001), Trenk (1998) and Gimbel and Trenk (1998).
Only those results from Doble et al. (2001) that are relevant to wellgrad-
edness will be detailed here. Among other facts established in that paper, we
mention the following: if W ⊂R ⊂W ′, where R is any relation and (W, W ′) is
a covering pair of strict weak orders on the same set, that is, there is no strict
weak order W ′′ satisfying W ⊂W ′′ ⊂W ′, then R is an ac-order. A partial
converse also holds. Other results of that paper are covered in the problem
section.
We omit the proof of the next lemma (Problem 5.17).
5.6.2 Lemma. Any ac-order R is is transitive and irreﬂexive. Moreover, the
product R ¯R−1 is irreﬂexive.
We turn to the fringes. As customary, we write I for the identity on the
ground set X.

116
5 Well-Graded Families of Relations
5.6.3 Theorem. The inner and outer fringes of an ac-order R in the family
A of all the ac-orders on a ﬁnite set X are deﬁned by the two equations
RI = R \ (RR ¯R−1 ∪¯R−1RR),
(5.41)
RO = ¯R \ (I ∪¯R ¯RR−1 ∪R−1 ¯R ¯R) .
(5.42)
Proof. Suppose that x(RI ∩RR ¯R−1)y. By deﬁnition of the inner fringe, we
have RI ⊆R, and S = R \ {xy} is an ac-order; moreover, xRzRw ¯R−1y for
some z, w ∈X. We claim that
xSzSw ¯S−1y
(5.43)
must hold because neither z nor w may be in {x, y}. Indeed, we have z /∈
{x, y} since S is irreﬂexive and does not contain xy by deﬁnition. As for
w /∈{x, y}, this must be true since w = x would contradict the transitivity
and irreﬂexivity of R together applied to xRRx, and w = y would yield
yR ¯R−1y, contradicting the irreﬂexivity of R ¯R−1 for an ac-order R. Hence,
(5.43) holds, which implies xSy because S is an ac-order, but contradicts
S = R \ {xy}. The proof that RI ∩¯R−1RR = ∅is obtained by a similar
contradiction. We have thus RI ⊆R \ (RR ¯R−1 ∪¯R−1RR).
To prove the reverse inclusion, it suﬃces to show that for any
zw ∈R \ (RR ¯R−1 ∪¯R−1RR),
(5.44)
the relation T = R\{zw} is an ac-order. Note that z ̸= w and that T is asym-
metric because R is. Suppose that TT ¯T −1 ̸⊆T; we have thus xTsTt ¯T −1y
and xy /∈T for some x, s, t, y ∈X, which implies xRsRt and either yt = zw
and xy /∈R, or xy = zw. In the ﬁrst case, we get y ¯R−1xRsRt, yielding
z ¯R−1xRsRw, contradicting (5.44). The second case gives x ¯R−1y because
x ¯T −1y; so xRsR ¯R−1y, that is zRsR ¯R−1w, again a contradiction of (5.44).
Turning to the outer fringe, we suppose that xy ∈RO. Thus, S = R +
{xy} is an ac-order. Thus ¬(xIy) because ac-orders are irreﬂexive. We must
still prove that xy /∈( ¯R ¯RR−1 ∪R−1 ¯R ¯R). Suppose that x ¯R ¯RR−1y; thus,
x ¯Rs ¯RtR−1y for some s, t ∈X. We get xSy, together with ySt and s ¯S−1x
(because yRt and x ¯R−1s). This gives s ¯S−1xSySt, yielding sSt because S is
an ac-order, but contradicting s ¯Rt. Similarly, xR−1 ¯R ¯Ry gives xR−1s ¯Rt ¯Ry
for some s, t ∈X, which yields sSxSy ¯S−1t, and thus sSt, again contradicting
s ¯Rt. We conclude that RO ⊆¯R \ (I ∪¯R ¯RR−1 ∪R−1 ¯R ¯R).
Suppose now that
xy ∈¯R \ (I ∪¯R ¯RR−1 ∪R−1 ¯R ¯R).
(5.45)
We have to prove that S = R +{xy} is an ac-order, that is, verify asymmetry
and 2-connectedness. Because R is asymmetric, the only way S could fail
asymmetry arises with yRx. Note that ¬(xIy), and so x ̸= y. Because R is

5.6 Almost Connected Orders
117
irreﬂexive, we get x ¯Rx. This leads to x ¯R ¯RR−1y, giving xRy, which together
with yRx contradict the asymmetry of R. We conclude that S is asymmetric.
It remains to show that S = R + {xy} is 2-connected. Given that R is 2-
connected, this could fail in only two cases:
1. sSxSy ¯S−1t and s ¯St; but then sRx, x ¯Ry, t ¯Ry and s ¯Rt, yielding xR−1s ¯Rt ¯Ry,
contradicting xy /∈R−1 ¯R ¯R assumed by (5.45).
2. xSySt ¯S−1s and x ¯Ss; but then x ¯Ry, yRt, s ¯Rt and x ¯Rs, yielding x ¯Rs ¯RtR−1y,
contradicting xy /∈¯R ¯RR−1 assumed by (5.45).
Thus ¯R \ (I ∪¯R ¯RR−1 ∪R−1 ¯R ¯R) ⊆RO and so (5.42) holds, completing the
proof of the theorem.
One additional concept is needed.
5.6.4 Deﬁnition. For any relation R on a set X, we denote by ∥R the incom-
parability relation of R on X, that is
x ∥y
⇐⇒
(x ¯Ry and y ¯Rx)
(x, y ∈X).
We may simply write ∥when the context makes it clear that ∥R is intended.
We recall that ˘∥denotes the transitive closure of the incomparability relation
∥on X (cf. 1.8.3).
5.6.5 Theorem. The family A of all the ac-orders on a ﬁnite set X is well-
graded if and only if |X| ≤4.
Proof. If |X| ≤3, the ac-orders on X are confounded with the partial orders
on that set and the result follows from Theorem 5.3.5. In the case |X| = 4, we
relie on the implication (v) ⇔(i) in Theorem 5.2.2 to prove the wellgradedness
of A. Take any R and S in A and suppose that RI ⊆S, RO ⊆¯S, SI ⊆R,
and SO ⊆¯R. If RI = R and SI = S, we get R ⊆S and S ⊆R; thus, R = S.
So, we can assume that RI ⊂R. An examination of the possible cases leads
to conclude that there are only two (see Figure 5.2):
x ∥yRzRwR−1x
(Case 1)
and
xR−1yRzRw ∥x
(Case 2).
Case 1 gives RI = {yz, zw}, and because RI ⊆S, we get
ySzSw.
(5.46)
Since RO = {yx, xz} and RO ⊆¯S, we have y ¯Sx and x ¯Sz. Now, y ¯Sx together
with (5.46) gives x ¯S−1ySzSw, which gives xSw because S is an ac-order.
Thus, it remains to show that x ∥y. But we already have y ¯Sx, and xSy cannot
hold because it would give xSySz, and so xSz by transitivity, contradicting
x ¯Sz. We have thus R = S in Case 1. The proof in Case 2 is similar. By the
implication (i) ⇒(v) in Theorem 5.2.2, the family A is thus well-graded if
|X| = 4.

118
5 Well-Graded Families of Relations
•
•
•w
?
•
@@
R



z
y
x
Case 1: x ∥yRzRwR−1x
Case 2: xR−1yRzRw
x •
•
•
y
•
?
@@
R



z
w
Figure 5.2. The graphs of Case 1 and Case 2 for |X| = 4 in the proof of Theorem
5.6.5.
Figure 5.3 illustrates the argument establishing that A is not well-graded
when |X| = n ≥5. With obvious notation, we have RI
n = {31, 42} = SI
n and
RO
n = {32, 41} = SO
n , but Rn and Sn are diﬀerent relations. Condition (v) of
Theorem 5.2.2 fails, and since Condition (v) is equivalent to Conditiom (i), A
is not well-graded.
•
?
•
?
•
6
•





 •
7
@
@
@
R



 . . .
•
@
@
@
R
n
PPPPPPP
q
•
5
?
•
@
@
@
R




1
3
2
4
Rn
Sn
•





 •
7
@
@
@
R



 . . .
•
@
@
@
R
n
PPPPPPP
q
•?
5
•
1
3 •
•
•
7
•
?
@
@
@
R




4
2
?
2




@
@
@
R
•
6
Figure 5.3.
The graphs of two distinct ac-orders on an n-element set having
their respective inner and outer fringes identical, a contradiction of Condition (v)
of Theorem 5.2.2.
Properties closely related, but weaker than well-gradedness do hold for the
family A.
5.6.6 Deﬁnition. Any set in a family F is upgradable (respectively, downgrad-
able) if it has a nonempty outer fringe (respectively, inner fringe). The fam-
ily F is called upgradable if all its nonmaximal sets are upgradable. It is
called downgradable if all its nonminimal sets are downgradable. A family F
is weakly graded if for any two of its (distinct) sets S and T, there exists a
sequence S0 = S, S1, . . . , Sn = T such that d(Si, Si+1) = 1 for 0 ≤i ≤n −1.

Problems for Chapter 5
119
5.6.7 Remarks. (a) Upgradability and downgradability, jointly satisﬁed, do
not imply weak gradedness (Problem 5.19). However, the family A of all ac-
orders on any ﬁnite set X is weakly graded because the empty relation is an
ac-order.
(b) Evidently, if wellgradedness holds, so do upgradability and downgrad-
ability.
(c) The concepts of upgradability and downgradability are relative to a
particular family of sets. However, if F ⊆G for two families of sets F and G,
and some set S ∈F is upgradable (respectively, downgradable) in F, then S is
also upgradable (respectively, downgradable) in G. For example, any semiorder
is upgradable (respectively, downgradable) in A if is not a linear order (re-
spectively, is not empty).
(d) Any linear order, weak order, or semiorder is an ac-order, which is
itself a partial order. Denoting by L, W, SO and P for the families of linear
orders, weak orders, semiorders, and partial orders, respectively, on a set X,
we have in fact
L ⊆W ⊆SO ⊆AP ,
(5.47)
with all inclusions being strict if |X| ≥4.
5.6.8 Theorem. The family A of all the ac-orders on a ﬁnite set X is both
upgradable and downgradable.
Sketch of proof. Take any R ∈A. Suppose that R is a semiorder which
is neither empty nor a linear order. Then, by Theorem 5.5.7 and Remarks
5.6.7 (b), (c) and (d), it is both upgradable and downgradable in A. So, we
can suppose that R is not a semiorder. This means that R fails the biorder
axiom: there must be x, y, z, and w in X such that xRy and zRw, but neither
xRw, nor zRy. In this case, it can be shown that we must have both xy ∈RI
and xw ∈RO.
The argument proceeds by contradiction. If R \ {xy} is not an ac-order
and is asymmetric (since R is asymmetric) it cannot be 2-connected. This ob-
servation leads to consider two cases, bot of which leading to a contradiction.
The proof that xw ∈RO is in a similar vein.
Problems
5.1 Verify that the intersection of a family of partial orders is a partial order.
5.2 Prove that any tight path S0 = S, S1, . . . , Sk = T between two distinct
sets S and T of a well-graded family veriﬁes (5.15) for 0 ≤j ≤k −1.
5.3 Prove by a counterexample that Condition [F] in Remark 5.2.3 does not
imply wellgradedness.

120
5 Well-Graded Families of Relations
5.4 Prove Equation (5.17) in Theorem 5.2.5.
5.5 Prove Lemma 5.3.2.
5.6 Prove that Condition [F] does not imply wellgradedness.
5.7 Suppose that X is uncountable. Let L be a well-ordering of X, and L the
family of all linear orders on X. Let P(X × X)▷◁be the cluster partition of
X according to Deﬁnition 3.4.1. The strict linear order L is a partial order.
Let P be the set of all partial orders on X. As a well-ordering, L contains a
pair xy such that y cover x. By Lemma 5.3.3, L \ {xy} is a partial order at
ﬁnite distance from L. Prove that there are uncountably many partial orders
at ﬁnite distance from L, and ⟨L⟩∩P is thus uncountable.
5.8 Prove that if R is a biorder, then
(i) both ¯R and R−1 are biorders;
(ii) both R ¯R−1 and ¯R−1R are strict weak orders (cf. (1.10));
(iii) ( ¯R)I = RO and ( ¯R)O = RI.
5.9 Prove the following result stated in Remark 5.2.3: If a family of sets F
is closed under ﬁnite intersection and satisﬁes ∅∈F, then it is well-graded
if and only if any set in F is deﬁned by its inner fringe in the sense of the
condition
[IF]
SI = T I ⇐⇒S = T
(S, T ∈F).
(Hint: use Lemma 5.3.1.)
5.10 Prove Theorem 5.4.2.
5.11 Prove Lemma 5.4.3.
5.12 Let X and Y be two arbitrary sets. Prove that if L is a linear order on
Z = X ∪Y, then R = L ∩(X × Y) is a biorder from X to Y. Argue that since
Z can be well-ordered, a biorder always exist between any two sets.
5.13 Prove Theorem 5.4.7.

Problems for Chapter 5
121
5.14 Prove that if R is a biorder from X to X with a numerical representation
xRy
⇐⇒
f(x) > g(y)
(x, y ∈X)
with f : X →R, g : X →R and f(x) −g(x) = f(y) −g(y), constant for all
x, y ∈X, then R is a semiorder on X.
5.15 Verify all the equivalences in Lemma 5.5.1.
5.16 Verify that the expressions for the inner fringe and the outer fringe of
a semiorder are those given by (5.34) and (5.35).
5.17 Verify that an ac-order R is transitive and irreﬂexive, and that R ¯R−1
is also irreﬂexive.
5.18 Prove that the product of two ac-order is an ac-order.
5.19 Construct an example showing that a family that is both upgrad-
able and downgradable is not necessarily weakly graded. Formulate a (nec-
essary and suﬃcient) condition for weak gradedness, given upgradability and
downgradability (cf. Deﬁnition 5.6.6 and Remark 5.6.7 (a)).
5.20 Prove all the inclusions in Eq. (5.47) of Remark 5.6.7(d), including the
statement regarding the strict inclusions.
5.21 Fill the gaps and complete the proof of Theorem 5.6.8.

6
Mediatic Graphs
6.1 The Graph of a Medium
This chapter follows closely Falmagne and Ovchinnikov (2007).
6.1.1 Deﬁnition. A graph representation of a medium (S, T) is a bijection
γ : S →V , where V is a set of vertices of a graph (V, E), such that for distinct
states S, T, we have Sτ = T for some token τ if and only if {γ(S), γ(T)} is
an edge of the graph; formally,
{γ(S), γ(T)} ∈E ⇐⇒(∃τ ∈T)(Sτ = T)
(S, T ∈S, S ̸= T).
(6.1)
We say then that the graph (V, E), which has no loops, represents the
medium1. A graph (V, E) representing a medium (S, T) is called the graph
of the medium (S, T) (cf. Deﬁnition 2.3.2) if V = S, the edges in E are deﬁned
as in (6.1), and γ is the identity mapping. Clearly, any medium has its graph.
We shall prove in this chapter that the converse also holds, namely: the graph
of a medium deﬁnes its medium (see Theorem 6.4.5).
We recall that two graphs (V, E) and (V ′E′) are isomorphic (see Section
1.8.5) if there exists a bijection ϕ : V →V ′ such that
{P, Q} ∈E ⇐⇒{ϕ(P), ϕ(Q)} ∈E′
(P, Q ∈E, P ̸= Q).
(6.2)
6.1.2 Lemma. Any graph which is isomorphic to a graph representing a
medium M also represents M.
Proof. From (6.1) and (6.2), it follows that if γ is a graph representation of a
medium M by a graph G, and ϕ is an isomorphism of G onto some graph G′,
then ϕ ◦γ is a graph representation of M by G′.
It is intuitively clear that shortest paths in the graph of a medium corre-
spond to concise messages of that medium. Our next lemma formalizes this
intuition.
1 An exemplary collection of small mediatic graphs is displayed on Figures A.1, A.2
and A.3 of the Appendix on page 305.

124
6 Mediatic Graphs
6.1.3 Lemma. Let γ : S →V be the representation of a medium (S, T)
by a graph G = (V, E). If m = τ1 . . . τm is a concise message producing a
state T from a state S, then the sequence of vertices (γ(Si))0≤i≤m, where
Si = Sτ0τ1 . . . τi, for 0 ≤i ≤m, forms a shortest path joining γ(S) and γ(T)
in G. Conversely, if a sequence (γ(Si))0≤i≤m is a shortest path connecting
γ(S0) = γ(S) and γ(Sm) = γ(T), then m = τ1 . . . τm with Sτ0τ1 . . . τi = Si,
for 0 ≤i ≤m, is a concise message producing T from S.
Proof. (Necessity.) Let γ(P0) = γ(S), γ(P1), . . . , γ(Pn) = γ(T) be a path in G
joining γ(S) to γ(T). Correspondingly, there is a stepwise eﬀective message
n = ρ1 · · · ρn such that Pi = Tρ1 . . . ρn−i for 0 ≤i < n. The message mn is
a return for S. By Axiom [Mb], this message is vacuous. Since m is a concise
message for S, we must have
ℓ(m) = m ≤ℓ(n) = n.
(Suﬃciency.) Let now γ(S0) = γ(S), γ(S1), . . . , γ(Sm) = γ(T) be a short-
est path from γ(S) to γ(T) in G. Then, there are some tokens τi, 1 ≤i ≤m
such that Siτi+1 = Si+1 for 0 ≤i < m. The message m = τ1 . . . τm produces
the state T from the state S. An argument akin to that used in the foregoing
paragraph shows that m is a concise message for S.
We now establish a result of the same vein for the regular returns of a
medium (cf. Deﬁnition 2.6.4).
6.1.4 Deﬁnition. We recall that a sequence of vertices sm = (vi)0≤i≤m such
that {vi, vi+1} are edges in a graph is a circuit if vm = v0 and all the vertices
v1, . . . , vm are diﬀerent (see Section 1.8.5, page 16). By abuse of language, we
say that the edges {vi, vi+1} belong to the circuit sm, for 0 ≤i ≤m −1. The
circuit sm is even if it has an even number of edges: m = 2n; any two of its
edges {vi, vi+1} and {vi+n, vi+n+1}, 0 ≤i ≤n −1 are then called opposite. A
circuit is minimal if at least one shortest path between any two of its vertices
is a segment of the circuit. A graph is even if all its circuits are even.
6.1.5 Lemma. Let γ : S →V be the representation of a medium M = (S, T)
by a graph G = (V, E). If m = τ1 . . . τ2n is a regular return for some state
S ∈S, then the sequence of vertices (γ(Si))0≤i≤2n, where Si = Sτ0τ1 · · · τi,
for 0 ≤i ≤2n, forms an even, minimal circuit of G. Conversely, if a se-
quence (γ(Si))0≤i≤2n is an even minimal circuit of G, then m = τ1 . . . τm,
with Sτ0τ1 · · · τi = Si for 0 ≤i ≤2n, is a regular return for S in M.
Note that S0 = S2n = S.
Proof. In the notation of the lemma, let m be a regular return for some
state S. Thus, by deﬁnition of a regular return (cf. 2.6.4), τ1 . . . τn and
˜τ2n . . . ˜τn+1 are concise messages for S. By Lemma 6.1.3, the sequence of

6.2 Media Inducing Graphs
125
vertices (γ(Si))0≤i≤n, where Si = Sτ0τ1 · · · τi, for 0 ≤i ≤n, forms a short-
est path joining γ(S) and γ(T), with T = Sτ1 · · · τn. Similarly, the sequence
γ(S2n), γ(S2n−1), . . . , γ(Sn+1) is another shortest path joining γ(S) and γ(T).
Since γ is a 1-1 function, all the vertices γ(Si) are distinct, and so the sequence
(γ(Si))0≤i≤2n is an even circuit. This circuit is a minimal one. Indeed, by def-
inition of a regular return, all the messages τiτi+1 . . . τi+n−1 are concise for
Sτ0τ1 · · · τi−1. So, by Lemma 6.1.3, all the sequences γ(Si), . . . , γ(Si+n−1) are
shortest paths between γ(Si) and γ(Si+n−1), which implies that at least one
shortest path between any two vertices of the circuit (γ(Si))0≤i≤2n is a seg-
ment of that circuit. We omit the proof of the converse part of this lemma.
The argument is based on the converse part of Lemma 6.1.3 and is similar
(see Problem 6.2).
6.1.6 Remark. A close reading of this proof shows that opposite tokens τi,
τi+n = ˜τi in a regular return correspond to opposite edges {γ(Si), γ(Si+1)},
{γ(Si+n, γ(Si+1+n)} in the even minimal circuit of the representing graph,
with Si+1 = Siτi and Si+n = Si+n+1τi+n.
6.2 Media Inducing Graphs
Our next task is to characterize the graphs representing media in terms of
graph concepts. Some necessary conditions are easily inferred from the axioms
of a medium. For example, Axiom [Ma] forces the graph to be connected, and
[Mb] demands that it is even. By convention, the graph should not have any
loops. However, as shown by the two example below, these three conditions
are not suﬃcient to characterize the graph of a medium.
6.2.1 Two Counterexamples. The graphs corresponding to the digraphs
A and B in Figure 6.1 are connected and all their circuits are even. Moreover,
they have no loops. Yet, neither A nor B can yield the graph of a medium.
We leave to the reader to prove this for Figure 6.1A (Problem 6.3).
L
J
N
H
W
R
U
K
M
T
N
T
T
N
N
A
B
Figure 6.1. Neither of these graphs is that of a medium. The token system corre-
sponding to Digraph B contradicts [Ma]. Which of the properties of a medium is
contradicted by Digraph A?

126
6 Mediatic Graphs
Here is why in the case of B. The circuit pictured in red is even and min-
imal. By Lemma 6.1.5, it must represent a regular return in a medium. From
Remark 6.1.6, we know that the same token must be matched to opposite
edges of the circuit. Accordingly, the same token ν has been assigned to the
arcs JM and RW. (To simplify the graph, only one token from each pair of
mutually reverse tokens is indicated.) The circuit containing the six vertices
L, K, N, W, R and H is also even and minimal. Thus, the arcs LK and RW
must be assigned the same token, and since RW has been assigned token ν,
that token must also be assigned to TL. The argument governing the place-
ment of the token τ are similar. The consequence, however, is that there is no
concise message from L to J: any message producing J from L contains either
both ν and ˜ν, or both ˜τ and τ. Axiom [Ma] is thus violated. This example will
be crucial in our understanding of the appropriate axiomatization of a graph
capable of representing a medium.
In our failed attempt at representing a medium in Figure 6.1, we have cho-
sen to picture the arcs representing the same token by parallel arcs (forming
two sides of an implicit rectangle). The intuition that the opposite arcs of even
minimal circuits should be parallel is a sound one, and suggests the construc-
tion of an equivalence relation on the set of set of arcs of the digraph. Such
a construction is delicate, however, and the two examples of media pictured
below by their digraphs must be taken into account.
6.2.2 Examples. Together with the examples of Figure 6.1, Examples A and
B in Figure 6.2 will also guide and illustrate our choice of concepts and axioms.
H
N
J
W
T
N
Z
T
T
N
Z
L
M
L
J
R
W
T
N
Z
T
T
N
Z
H
N
Z
N
M
A
B
Figure 6.2. Two examples of graphs of media. In Example B, diﬀerent to-
kens are assigned to arcs HL and MW, which are are opposite in the circuit
N, H, L, J, W, M, N. This circuit is not minimal. Compare with the situation of the
arcs LJ and NW in Example A.

6.2 Media Inducing Graphs
127
6.2.3 Deﬁnition. We denote by ⃗E = {ST {S, T} ∈E} the set of all the
arcs of a graph G = (V, E). The like relation2 of the graph G is a relation L
on ⃗E deﬁned by
ST L PQ
⇐⇒
(δ(S, P) + 1 = δ(T, Q) + 1 = δ(S, Q) = δ(T, P))
({S, T}, {P, Q} ∈E).
In Example B in Figure 6.2, we have NH L WJ because
δ(H, J) + 1 = δ(N, W) + 1 = δ(H, W) = δ(N, J),
but HL L MW does not hold because
δ(H, M) = δ(L, W) = 2
and
4 = δ(H, W) ̸= δ(L, M) = 1.
The point is that the arcs HL and MW
are opposite in the circuit
H, L, J, W, M, N, H, but this circuit is not minimal.
The like relation is clearly reﬂexive and symmetric. Moreover, we have
ST L PQ
⇐⇒
TS L QP
({S, T}, {P, Q} ∈E).
(6.3)
We now come to the main concept of this chapter. We recall that a graph
is bipartite if and only if it is even (K¨onig, 1916, and see 1.8.5, page 17).
6.2.4 Deﬁnition. Let G = (V, E) be a graph equipped with its like rela-
tion L . The graph G is called mediatic if the following three axioms hold.
[G1] G is connected.
[G2] G is bipartite.
[G3] L is transitive.
The set of vertices is not assumed to be ﬁnite. It is easily veriﬁed that any
graph isomorphic to a mediatic graph is mediatic (see Problem 6.1).
Axiom [G3] eliminates the counterexample of Figure 6.1B. Indeed, we have
LK L RW L JM
but not
LK L JM
since
δ(L, J) = 4,
δ(K, M) = 2,
δ(L, M) = 3 = δ(K, J).
The following result is immediate.
2 The like relation is analogous to the Djokovi´c-Winkler relation on the edges of
a graph, described in Chapter 7; the exact connection between these relations is
spelled out in Theorem 7.2.5.

128
6 Mediatic Graphs
6.2.5 Lemma. The like relation L of a mediatic graph (V, E) is an equiva-
lence relation on ⃗E.
6.2.6 Deﬁnition. We denote by
⟨ST⟩= {PQ ∈⃗E ST L PQ}
the equivalence class containing the arc ST (in the partition of ⃗E induced
by L ).
We will show that a graph representing a medium is mediatic (see Theo-
rem 6.2.9). Our next lemma is the ﬁrst step.
6.2.7 Lemma. Let γ be the representation of a medium M = (S, T) by a
graph G = (S, E) which is equipped with its like relation L . Suppose that
γ(N)γ(S) L γ(W)γ(Q). Then Nτ = S and Wτ = Q for some τ ∈T. In fact,
there exists an orderly return q˜τ 
wτ for S in M, with Sq˜τ = S˜τw = W;
thus q and w are concise with ℓ(q) = ℓ(m). Such a circuit is not necessarily
regular.
Proof. We abbreviate our notation and write Sγ = γ(S) for all S ∈S
(for this proof only). By deﬁnition, N γSγ L W γQγ implies that δ(Sγ, Qγ) =
δ(N γ, W γ) = δ(N γ, Qγ) −1 = δ(Sγ, W γ) −1; so, there are, for some n ∈N,
two shortest paths
Sγ
0 = Sγ, Sγ
1 , . . . , Sγ
n = Qγ
and
N γ
0 = N γ, N γ
1 , . . . , N γ
n = W γ
between Sγ and Qγ, and N γ and W γ, respectively. Moreover,
Sγ
0 = Sγ, Sγ
1, . . ., Sγ
n = Qγ, W γ and N γ
0 = N γ, N γ
1, . . ., N γ
n = W γ, Qγ
are also shortest paths. Using Lemma 6.1.3, we can assert the existence of
two concise messages q and w such that Sq = Q and Nw = W, with ℓ(q) =
ℓ(w) = n. Also, for some tokens τ and µ, we have Nτ = S and Wµ = Q with
q′ = τq and w′ = ˜τw concise for N and S, respectively, and ℓ(q′) = ℓ(w′) =
n+1. We are exactly in the situation of Theorem 2.6.2 (see Figure 2.3). Using
the implication (iv) ⇒(ii) of this theorem, we obtain τ = µ. Condition (i)
of the same theorem also implies that q˜τ 
wτ is an orderly return for S, with
Sq˜τ = S˜τw = W. The example of Figure 6.3 shows that, with q = w = νζ,
such a circuit need not be regular.
6.2.8 Convention. Any graph representing a medium comes implicitly or
explicitly equipped with its like relation L . When several such graphs are
considered, we distinguish their respective like relations by diacritics, such as
L ′ or L ∗.

6.2 Media Inducing Graphs
129
S
N
Q
W
T
N
Z
T
T
N
Z
Figure 6.3. Under the hypotheses of Lemma 6.2.7, with NS L WQ, the orderly
return q˜τ ˜wτ = νζ˜τ ˜ν ˜ζτ for S is not regular. For example, ζ˜τ ˜ζ is not concise for Sν
(cf. Deﬁnition 2.6.4).
6.2.9 Theorem. Any graph representing a medium is mediatic.
Proof. Because any graph isomorphic to a mediatic graph is mediatic, we can
invoke Lemma 6.1.2 and content ourselves with proving that the graph of a
medium is mediatic (which simpliﬁes our notation). Denote the medium by
M = (S, T), and let G = (S, E) be its graph. We prove that G satisﬁes [G1],
[G2] and [G3].
[G1] Axiom [Ma] requires that G be connected.
[G2] Axiom [Mb] implies that G must be even. Hence, by K¨onig’s Theorem,
it must be bipartite.
[G3] Suppose that NS L PR L WQ. By Lemma 6.2.7 (applied twice), there
must be some tokens τ and µ such that Nτ = S, Pτ = R, Pµ = R
and Wµ = Q, so τ = µ. Let then q and w′ be two concise messages
from S, and let w and bq′ be two concise messages from N, such that
Sq = Q,
Sw′ = W,
Nw = W,
Nq′ = Q.
The situation is exactly that of Theorem 2.6.2, with the same notation
(see Figure 2.3). Because τ = µ, Condition (ii) of this theorem holds.
We conclude that Conditions (iii) and (iv) also hold, which leads to
δ(S, Q) + 1 = δ(N, W) + 1 = δ(S, W) = δ(N, Q).
We have thus NS L WQ; so, L is transitive.
We leave the proof of the next lemma as Problem 6.5.
6.2.10 Lemma. Let G = (V, E) and G′ = (V ′, E′) be two mediatic graphs,
with their respective like relations L and L ′, and let ϕ be a bijection of V
onto V ′. Then ϕ is an isomorphism of G onto G′ if and only if
ST L PQ
⇐⇒
ϕ(S)ϕ(T) L ′ϕ(P)ϕ(Q)
(S, T, P, Q ∈V ).

130
6 Mediatic Graphs
6.2.11 Remark. The like relation is the fundamental tool for the study of
mediatic graphs. We shall see that any mediatic graph G can be used to
construct a medium M that has G as its graph. Each of the equivalence
classes ⟨ST⟩of the partition induced by the like relation contains ‘parallel’
arcs of the graph, and will turn out to correspond to a particular token τ of the
medium under construction, with the class ⟨TS⟩corresponding to the reverse
token ˜τ. Before proceeding to such a construction, we establish in Theorem
6.3.1 a useful result which precisely links the isomorphism of media to that
of their graphs. We recall (cf. Deﬁnition 2.7.1, page 34) that two media (S, T)
and (S′, T′) are isomorphic if there exists a pair (α, β) of bijections α : S →S′
and β : T →T′ such that Sτ = V if and only if α(S)β(τ) = α(V ), for all
states S and V in S and tokens τ in T.
6.3 Paired Isomorphisms of Media and Graphs
6.3.1 Theorem. Suppose that M = (S, T) and M′ = (S′, T′) are two media
and let G = (S, E) and G′ = (S′, E′) be their respective graphs. Then M and
M′ are isomorphic if and only if G and G′ are isomorphic; more precisely:
(i) if (α, β) is an isomorphism of M onto M′, then α : S →S′ is an
isomorphism of G onto G′ in the sense of (6.2);
(ii) if ϕ : S →S′ is an isomorphism of G onto G′ in the sense of (6.2), then
there exists a bijection β : T →T′ such that (ϕ, β) is an isomorphism of M
onto M′.
Proof. (i) Suppose that (α, β) is an isomorphism of M onto M′. For any two
distinct S, T in S, we have successively
{S,T} ∈E
⇐⇒(∃τ ∈T)(Sτ = T)
(G is the graph of M)
⇐⇒(∃τ ∈T)(α(S)β(τ) = α(T))
(M and M′ are isomorphic)
⇐⇒{α(S), α(T)} ∈E′
(G′ is the graph of M′),
and so
{S, T} ∈E ⇐⇒{α(S), α(T)} ∈E′
(S, T ∈S, S ̸= T).
We conclude that α : S →S′ is an isomorphism of G onto G′.
(ii) Let ϕ : S →S′ be an isomorphism of G onto G′. Deﬁne a function
β : T →T′ by
β(τ) = τ ′ ⇐⇒(∀S, T ∈S)(Sτ = T ⇔ϕ(S)τ ′ = ϕ(T)).
(6.4)
We ﬁrst verify that the r.h.s. of the equivalence (6.4) correctly deﬁnes β as
a bijection of T onto T′. For any τ ∈T, there exists distinct states S and

6.3 Paired Isomorphisms of Media and Graphs
131
T in S such that Sτ = T and {S, T} ∈E. Fix S and T temporarily. By
the isomorphism ϕ : S →S′ of G onto G′, we have {ϕ(S), ϕ(T)} ∈E′, and
because G′ is the graph of M′, we necessarily have ϕ(S)τ ′ = ϕ(T) for some
τ ′ ∈T′, which is unique by Lemma 2.3.1(iii). The hypothesis that ϕ is an
isomorphism of G onto G′ ensures that we must have an equivalence in the
r.h.s. of (6.4).
Next, we show that β(τ) does not depend upon the choice of S and T. Let
P, Q be another pair of distinct states in S such that Pτ = Q, and let P = Sm
and Q = Tn for some concise messages m = τ1 . . . τm and n = µ1 . . . µn. By
Lemma 2.2.7, τn and mτ are concise messages. Invoking the implication (ii)
⇒(iii) in Theorem 2.6.2, we get ℓ(m) = ℓ(n) and C(m) = C(n), and so
m = n. Denote by L and L ′ the like relations of G and G′ respectively. We
have thus shown that ST L PQ. By Lemma 6.2.10, we also have
ϕ(S)ϕ(T) L ′ϕ(P)ϕ(Q).
Because ϕ(S)τ ′ = ϕ(T), Lemma 6.2.7 applies, yielding ϕ(P)τ ′ = ϕ(Q). Thus,
β is a well-deﬁned function.
We still have to prove that β is indeed a bijection. For any τ ′ ∈T′ there
are some S′, T ′ ∈T′ such that S′τ ′ = T ′. We have thus {S′, T ′} ∈E′, and
since ϕ is an isomorphism of G onto G′, also {ϕ−1(S′), ϕ−1(T ′)} ∈E, with
ϕ−1(S′)τ = ϕ−1(T ′) for some τ ∈T. Thus β maps T onto T′. Suppose now
that β(τ) = β(µ) = τ ′ ∈T′. This implies that for some S, T, P, Q ∈S and
N, M ∈S′, we must have
Sτ = T,
Pµ = Q, and Nτ ′ = M,
(6.5)
together with
ϕ(S) = ϕ(P) = N and ϕ(T) = ϕ(Q) = M
by the deﬁnition of β. As ϕ is a 1-1 function, we obtain S = P and T = Q in
(6.5). Using Lemma 2.3.1(ii), we get τ = µ. Thus, β is a 1-1 function and so
a bijection.
The fact that (ϕ, β) is an isomorphism of M onto M′ follows from the
deﬁnition of β by (6.4). We have
Sτ = T
⇐⇒
ϕ(S)β(τ) = ϕ(T)
(S, T ∈S)
whether or not {S, T} ∈E.
Having deﬁned the graph of a medium and shown that such a graph is
necessarily mediatic, we now go in the opposite direction and construct a
medium from an arbitrary mediatic graph.

132
6 Mediatic Graphs
6.4 From Mediatic Graphs to Media
6.4.1 Deﬁnition. Let G = (S, E) be a mediatic graph equipped with its like
relation L . For any ST ∈⃗E, deﬁne a function
τST : S →S : P →PτST
by the formula
PτST =

Q if ST L PQ,
P otherwise.
(6.6)
We denote by T = {τST
ST ∈⃗E} the set containing all those transformations.
It is easily veriﬁed that the pair (S, T) is a token system. Such a token system
is said to be induced by the mediatic graph G. Theorem 6.4.3 establishes that
a token system K induced by a mediatic graph G is in fact a medium. We say
that K is the medium of the graph G. Notice that, since L is an equivalence
relation on ⃗E, we have τST = τP Q whenever ST L PQ. In such a case, we have
in fact ⟨ST⟩= ⟨PQ⟩. The choice of a particular pair ST ∈⟨PQ⟩to denote
a token τST is thus arbitrary. Occasionally, we may in fact vary our notation
so as to make an argument more intuitive or immediate. Notice that, as a
consequence of this deﬁnition, whenever {S, T} ∈E, then also ST L ST, and
so SτST = T.
This construction is motivated by Theorem 6.4.3. We ﬁrst prove a lemma.
6.4.2 Lemma. Let (S, T) be the token system constructed in Deﬁnition 6.4.1.
For any {S, T} ∈E the tokens τST and τT S deﬁned by (6.6) are mutual
reverses.
Proof. For any distinct states S, T, P and Q, we have
PτST = Q
⇐⇒
ST L PQ
(by deﬁnition)
⇐⇒
TS L QP
(by (6.3))
⇐⇒
QτT S = P
(by deﬁnition),
and so τT S is the reverse of τST .
6.4.3 Theorem. The token system (S, T) induced, in the sense of 6.4.1, by
a mediatic graph G = (S, E) is a medium.
Proof. We verify that (S, T) satisﬁes Axioms [Ma] and [Mb] of a medium.
[Ma] For any S, T ∈S, there is a shortest path S0 = S, S1, . . . , Sn = T
between S and T in G. This implies that, for 0 ≤i ≤n −1, we have
{Si, Si+1} ∈E, which yields SiτSiSi+1 = Si+1. It follows that the message
m = τS0S1 . . . τSn−1Sn produces T from S and is stepwise eﬀective. To prove

6.4 From Mediatic Graphs to Media
133
that m is concise, we must still show that it is consistent and without repe-
titions. The message m is consistent since otherwise we would have
ShτMN = Sh+1
and
SkτNM = Sk+1
(6.7)
for some indices h and k, with h < k, and some NM ∈⃗E. Since τMN is the
reverse of τNM , the last equality in (6.7) can be rewritten as Sk+1τMN = Sk.
Thus, by deﬁnition of the tokens in (6.6), the above statement (6.7) leads to
ShSh+1 L MN L Sk+1Sk which, by transitivity, gives SkSk+1 L Sh+1Sh . Be-
cause h < k, we can apply the deﬁnition of the like function L in 6.2.3 and
derive
k + 1 −h = δ(Sk+1, Sh) = δ(Sk, Sh+1) = k −1 −h
yielding the absurdity 1 = −1. Thus, m is consistent. Suppose that m has
repeated tokens, say SiτSiSi+1 = Si+1 and Si+kτSiSi+1 = Si+k+1 for some
indices 0 ≤i < n and 0 ≤i + k < n. This would give SiSi+1 L Si+kSi+k+1,
leading to
d(Si, Si+k+1) = k + 1 > k −1 = d(Si+1, Si+k),
while by the deﬁnition of L we should have d(Si, Si+k+1) = d(Si+1, Si+k), a
contradiction. Thus, the message m is concise.
[Mb] Let m = τS0S1τS1S2 . . . τSn−1Sn be a return message for some state S;
we have thus S0 = Sn = S. In the terminology of G, we have a closed walk
S = S0, S1, . . . , Sn = S. We denote this closed walk by W and we write ⃗EW
for the set of all its arcs SiSi+1, 0 ≤i ≤n−1. By [G2] and K¨onig’s Theorem,
such a closed walk is even; so n = 2q for some q ∈N. We prove by induction
on q that m is vacuous. The case q = 1 (the smallest possible return) is trivial,
so we suppose that [Mb] holds for any 1 ≤p < q and prove that [Mb] also
holds for q = p. We consider two cases.
Case 1: W is an isometric subgraph of G. Thus, W is a minimal circuit
of G. Take any token τSiSi+1 in m. Since (with the addition modulo k in the
indices), we have for 0 ≤i < n
δ(Si+1, Si+k) = δ(Si, Si+k+1) = k −1,
δ(Si, Si+k) = δ(Si+1, Si+k+1) = k,
we obtain SiSi+1 L Si+k+1Si+k. By the deﬁnition of the tokens in (6.6) and
the transitivity and symmetry of L , we get for any P, Q ∈S
PτSiSi+1 = Q ⇐⇒SiSi+1 L PQ
⇐⇒Si+k+1Si+k L PQ
⇐⇒PτSi+k+1Si+k = Q
⇐⇒QτSi+kSi+k+1 = P.
We conclude that τSi+kSi+k+1 and τSiSi+1 are mutual reverses, and so m is
vacuous. (Note that the induction hypothesis has not been used here.)

134
6 Mediatic Graphs
S0
Si
Sj
mij
mj0
m0i
p
~
T
T
mij
T
W
L
Figure 6.4. Case 2 in the proof of Axiom [Mb] in Theorem 6.4.3: the closed walk
W is not an isometric subgraph.
Case 2: W is not an isometric subgraph of G. Then, there are two vertices
Si and Sj in W, with i < j, and a shortest path L from Si to Sj in G with
δij = δ(Si, Sj) < min{j −i, i+n−j} (see Figure 6.4). Thus, j −i and i+n−j
are the lengths of the two segments of W with endpoints Si and Sj. For
simplicity, we can assume without loss of generality that Si and Sj are the
only vertices of L that are also in W. Let p the straight message producing
Sj from Si and corresponding to the shortest path L in the sense of Lemma
6.1.3. We also split m into the three messages:
m0i = τS0S1 . . . τSi−1Si
mij = τSiSi+1 . . . τSj−1Sj
mj0 = τSj Sj+1 . . . τSn−1S0 .
We have thus m = m0imijmj0. Note that the two messages m0ipmj0 and

pmij have a length strictly smaller that n = 2q. By the induction hypothesis,
these two messages are vacuous. Accordingly, for any token τ of p, there is an
reverse token ˜τ either in m0i or in mj0. (In Figure 6.4 the token ˜τ is pictured
as being part of m0i.) Considered from the viewpoint of the message 
pmij
from Sj, the token ˜τ is in 
p with its reverse τ in mij. The two reverses of
the tokens in p and 
p, form a pair of mutually reverse tokens {τ, ˜τ} in m.
Such a pair can be obtained for any token τ in p. Augmenting the set of all
those pairs by the set of mutually reverse tokens in m0i, mij and mj0, we
obtain a partition of the set C(m) into pairs of mutually reverse tokens, which
establishes that the message m is vacuous.
We have shown that the token system (S, T) satisﬁes Axioms [Ma] and
[Mb]. The proof is thus complete.
6.4.4 Remark. In the above proof, the inductive argument used to establish
Case 2 of [Mb] may convey the mistaken impression that the situation is
always straightforward. The graph pictured in Figure 6.4 is actually glossing
over some intricacies. The non-isometric subgraph W is pictured in red in
Figure 6.5 and is not ‘convex.’ We can see how the inductive stage splitting

6.4 From Mediatic Graphs to Media
135
the closed walk W by the shorthest path L may lead to form, in each of the
two smaller closed walks, pairs {µ, ˜µ} and {ν, ˜ν} which correspond in fact to
the same pair of tokens in W. Since the arcs corresponding to µ and ν are in
the like relation L , the mistaken assignment is temporary.
M
M
N
T
T
N
T
Sj
L
p
Si
S0
W
Figure 6.5. The non-isometric subgraph W of Case 2 in the proof of [M3] in
Theorem 6.4.3 is pictured in red. The inductive stage of the proof leads to form
temporarily, in each of the two smaller closed walks delimited by the shortest path
L, pairs {µ, ˜µ} and {ν, ˜ν} corresponding to the same pair of mutually reverse tokens
in W.
We ﬁnally obtain:
6.4.5 Theorem. Let S an arbitrary set, with |S| ≥2. Denote by M the set
of all media on S, and by G the set of all mediatic graphs on S. There exists
a bijection f : M →G : M →f(M) such that G = f(M) is the graph of M in
the sense of Deﬁnition 6.1.1 if and only if M is the medium of the mediatic
graph G in the sense of Deﬁnition 6.4.1.
Proof. Because the set S of states is constant in M and confounded with the
constant set of vertices in G, we could reinterpret the function f as a mapping
of the family T of all sets of token T making (S, T) a medium, into the family
E of all sets of edges E making (S, E) a mediatic graph. However, any set
of edges E of a mediatic graph on S is characterized by its like relation L ,
or equivalently, by the partition of ⃗E induced by L . We choose the latter
characterization for the purpose of this proof, and denote by ⃗EL the set of all
the partitions of the sets of arcs ⃗E induced by the like relations characterizing
the sets of edges in the collection E.
From Lemmas 6.2.9 and 6.4.3, we know that the graph of a medium is
mediatic, and that the token system induced by a mediatic graph is a medium.
We have to show that the functions
f : T →⃗EL
and
g : ⃗EL →T
implicitly deﬁned by (6.1) and (6.6), respectively, are mutual inverses. Note
that, for any T ∈T, the partition f(T) is deﬁned via a function f mapping T

136
6 Mediatic Graphs
into the the partition f(T). Writing as before ⟨ST⟩for the equivalence class
containing the arc ST, we have
Pτ = Q
⇐⇒
f(τ) = ⟨PQ⟩
(τ ∈T; P, Q ∈S).
(6.8)
Proceeding similarly, but inversely, for the function g, we notice that it deﬁnes,
for each ⃗EL in ⃗EL the set of tokens g( ⃗EL) via a function g mapping ⃗EL into
the set of tokens g( ⃗EL); we obtain
⟨ST⟩= ⟨PQ⟩
⇐⇒
Pg(⟨ST⟩) = Q
(S, T, P, Q ∈S).
(6.9)
Combining (6.8) and (6.9) we obtain
Pτ = Q ⇐⇒f(τ) = ⟨PQ⟩⇐⇒P(g ◦f)(τ) = Q
(τ ∈T; P, Q ∈S).
We have thus g = f −1 and so g = f−1. Conversely, we have
⟨ST⟩= ⟨PQ⟩⇐⇒Pg(⟨ST⟩) = Q ⇐⇒(f ◦g)(⟨ST⟩) = ⟨PQ⟩
(S, T, P, Q ∈S),
yielding f = g−1 and so f = g−1.
Problems
6.1 Prove that any graph isomorphic to a mediatic graph is mediatic.
6.2 Prove the converse in Lemma 6.1.5.
6.3 Prove that Digraph A in Figure 6.1 cannot give the graph of a medium.
6.4 Prove that the three axioms [G2], [G3] and [G3] deﬁning a mediatic graph
are independent.
6.5 Prove Lemma 6.2.10.
6.6 Suppose that (S, T) is a token system induced by a mediatic graph (S, E)
in the sense of Deﬁnition 6.4.1. Prove that any concise message τ1 . . . τn pro-
ducing a state T from a state S corresponds to a shortest path
S = S0, S1 = S0τ1, . . . , Sn = T = Sn−1τn
from S to T.

Problems for Chapter 6
137
6.7 Prove that Deﬁnition 6.4.1 and Eq. (6.6) properly deﬁne a token system.
6.8 Can any closed walk S = S0, S1, . . . , S2n = S that is not a circuit be
decomposed into segments Si, Si+1, . . . , Si+2k = Si that form circuits? If this
is not true, give a counterexample and formulate the correct decomposition.
6.9 Is it true that, given a medium and its representing graph, there is a 1-1
correspondence between the orderly returns of the medium and the minimal
circuits of the graph? Can you formulate a correct statement in this regard?
6.10 Show how [G3] rules out the Counterexample 6.2.1B.
6.11 Prove the statement made in Remark 6.1.6.
6.12 Derive a contradiction to the
axioms of a mediatic graph or of
Remark 6.1.6 in the graph pictured
in Figure 6.6 on the right. A failed at-
tempt at an assignment of the tokens
to the edges should facilitate your
analysis of the situation.
M
N
X
A
A
B
F
F
N
B
M
B
A
X
A
X
M
N
F
X
M
N
F
N
M
P
Q
S
T
W
L
H
Figure 6.6. Why is this not the graph of a medium?
6.13 Let (G, E) be a graph equipped with its like relation L . Suppose that
Axioms [G1] and [G2] of a mediatic graph hold, but not [G3]. Can you obtain a
mediatic graph, and thus also a medium, by simply constructing the transitive
closure of L ? Prove your answer.

7
Media and Partial Cubes
Isometric subgraphs of hypercubes, or ‘partial cubes’, were ﬁrst studied by
Graham and Pollak (1971) in connection with modeling communication net-
works. Partial cubes are graphs that are isometrically embeddable into hy-
percubes (Imrich and Klavˇzar, 2000). We use partial cubes in our studies
of structural properties of wg-families of sets and media. In particular, we
characterize mediatic graphs as partial cubes.
7.1 Partial Cubes and Mediatic Graphs
The n-dimensional cube (or n-cube) is the graph on {0, 1}n in which two
vertices form an edge if and only if they diﬀer in exactly one position. The
n-cube can be equivalently deﬁned as the graph on the power set P(X), where
X is a set of cardinality n; two sets P, Q ∈P(X) form an edge if and only if
|P △Q| = 1. Following R. Rado’s suggestion, Djokovi´c (1973) extended the
latter deﬁnition to arbitrary sets X.
7.1.1 Deﬁnition. The cube on a set X is the graph
H(X) = (Pf(X), E)
where
E = {{P, Q} ⊆Pf(X) |P △Q| = 1}.
A graph G is called a partial cube if it is isometrically embeddable into the
cube H(X) for some set X. Thus, isometric subgraphs of the cube H(X) are
partial cubes on X.
7.1.2 Example. Figure 7.1 depicts the four-dimensional cube H(X) on the
set X = {a, b, c, d}. This graph has 24 = 16 vertices and 1
2 · 4 · 24 = 32 edges.

140
7 Media and Partial Cubes
Ø
{a}
{a,b}
{a,b,c}
{a,b,c,d}
{b,c,d}
{a,c}
{b,d}
{a,b,d}
{b,c}
{a,c,d}
{c,d}
{a,d}
b
{ }
c
{ }
{d}
Figure 7.1. The cube H({a, b, c, d}).
7.1.3 Theorem. The graph distance δ on the cube H(X) coincides with the
distance d between sets in Pf(X):
δ(P, Q) = d(P, Q) = |P △Q|,
for all P, Q ∈Pf(X).
Proof. Take any two distinct sets P, Q ∈Pf(X), and consider a sequence of sets
obtained from P by removing successively all the elements from P \Q and then
adding successively all the elements of Q \ P until the set Q is obtained. This
sequence of sets form a path of length d(P, Q). Therefore, δ(P, Q) ≤d(P, Q).
In any path from P to Q two adjacent vertices diﬀer by one element; the sets
P and Q diﬀer by |P △Q| elements. Hence,
δ(P, Q) ≥|P △Q| = d(P, Q).
The result follows.
From this result and the deﬁnitions of a partial cube and of a wg-family
of sets (cf. Deﬁnition 3.1.5), we obtain immediately:
7.1.4 Theorem. An induced subgraph of a cube H(X) is a partial cube on
X if and only if the set of its vertices is a wg-family of sets.
7.1.5 Example. Let X = {x1, . . . , xn} be a set of cardinality n. The family
{∅, {x1}, {x1, x2}, . . . , {x1, . . . , xn}}
is well-graded and induces a path of length n in H(X). For instance, the
family {∅, {a}, {a, b}, {a, b, c}} deﬁnes a path of length three in Figure 7.2.
Accordingly, any path is a partial cube.

7.1 Partial Cubes and Mediatic Graphs
141
7.1.6 Example. Let X = {a, b, c}. The family of sets
{∅, {a}, {a, b}, {a, b, c}, {b, c}}
is not well-graded and induces a path of length 4 in H(X) (see Figure 7.2).
This path is a partial cube but not a partial cube on the set X.
{a}
{b}
{c}
{a,b}
{a,c}
{b,c}
{a,b,c}

Figure 7.2. A nonisometric path in the cube H({a, b, c}).
By Theorem 3.3.4, any medium is isomorphic to the representing medium
of a wg-family of ﬁnite sets. It is also clear that the graph of the representing
medium of a wg-family F is the partial cube induced by F. Thus we have the
following result:
7.1.7 Theorem. A graph G represents a medium if and only if G is a partial
cube.
Let G be a partial cube. As such, G can be isometrically embedded into
some cube H(X). This graph admits isometric representations as partial cubes
on various sets X. For instance, the graph K2 (the complete graph on two
vertices) can be isometrically embedded in diﬀerent ways into any cube H(X)
with |X| > 2. It is desirable to ‘minimize’ the class of cubes H(X) that can be
used as target graphs for isometric embeddings of G. We do it by ‘retracting
the domain’ of a wg-family of sets.
7.1.8 Deﬁnition. Let F′ be a family of subsets of a set X′. We deﬁne the
retraction of F′ as a family F of subsets of X = ∪F′ \ ∩F′ consisting of the
intersections of sets in F′ with X. It is clear that F satisﬁes the following two
conditions
∩F = ∅
and
∪F = X.
(7.1)
From the media theory point of view, the retraction F of F′ is obtained by
eliminating ‘inactive’ elements from the set X′ (cf. Deﬁnition 3.2.1).
7.1.9 Theorem. The retraction F of a wg-family F′ is a wg-family. The par-
tial cubes induced by F′ and F are isomorphic and the respective representing
media are isomorphic.

142
7 Media and Partial Cubes
Proof. It suﬃces to prove that the metric spaces F′ and F are isometric. We
deﬁne a mapping α : F′ →F by P →P ∩X. Clearly, α is surjective. We have
(P ∩X) △(Q ∩X) = (P △Q) ∩X = (P △Q) ∩(∪F′ \ ∩F′) = P △Q.
Thus, d(α(P), α(Q)) = d(P, Q). Consequently, α is an isometry.
We now show that the classes of mediatic graphs and partial cubes are
identical.
7.1.10 Theorem. A graph is mediatic if and only if it is a partial cube.
Proof. (Necessity.) By Theorem 6.4.5, a mediatic graph is the graph of a
medium. Therefore, by Theorem 7.1.7, it is a partial cube.
(Suﬃciency.) Let G be a partial cube. By Theorem 7.1.9, we may assume
that G is induced by a wg-family F of ﬁnite subsets of some set X satisfying
conditions (7.1). By Theorems 3.3.1 and 6.2.9, G is a mediatic graph.
Note that the concepts of mediatic graphs and partial cubes are introduced
in diﬀerent ways: the former one uses intrinsic structures of a graph and their
properties, whereas the latter one involves extrinsic objects (cubes). In the
next two sections we give intrinsic characterizations of partial cubes.
7.2 Characterizing Partial Cubes
Partial cubes were characterized by Djokovi´c (1973) and Winkler (1984) (see
Imrich and Klavˇzar, 2000, for references to other characterizations of partial
cubes). Before presenting these results, we review some notions and facts from
graph theory.
Only connected graphs are considered in this section.
7.2.1 Deﬁnition. Let G = (V, E) be a graph and δ be its distance function.
For any edge {a, b} ∈E we deﬁne a subset Wab of V by
Wab = {w ∈V
δ(w, a) < δ(w, b)}.
Following Eppstein (2005b), we call the sets Wab (and their corresponding
induced subgraphs) semicubes of the graph G. The semicubes Wab and Wba
are called opposite semicubes.
Clearly, two opposite semicubes are disjoint. The pairs of opposite semi-
cubes provide a characterization of bipartite graphs.
7.2.2 Theorem. A graph G = (V, E) is bipartite if and only if, for any edge
{a, b}, the semicubes Wab and Wba form a partition of V .

7.2 Characterizing Partial Cubes
143
Proof. We recall that a connected graph G is bipartite if and only if for
every vertex x there is no edge {a, b} with δ(x, a) = δ(x, b) (see, for instance,
Asratian et al., 1998). Now it suﬃces to note that for any edge {a, b} and
x ∈V ,
δ(x, a) = δ(x, b)
⇐⇒
x /∈Wab ∪Wba.
The result of the following lemma is instrumental and will be used often
in the chapter.
7.2.3 Lemma. If x ∈Wab for some semicube Wab, then
δ(x, b) = δ(x, a) + 1.
Proof. For any x ∈Wab, we have, by the deﬁnition of a semicube and the
triangle inequality, we have
δ(x, a) < δ(x, b) ≤δ(x, a) + δ(a, b) = δ(x, a) + 1.
The result follows, since δ takes values in N.
Two binary relations on the set of edges of a graph play a central role in
characterizing partial cubes. They are Djokovi´c’s relation θ (Djokovi´c, 1973)
and Winkler’s relation Θ (Winkler, 1984).
7.2.4 Deﬁnition. Let G = (V, E) be a graph.
(i) The relation θ on E is deﬁned by
{x, y}θ{u, v} ⇔({u, v} joins a vertex in Wxy with a vertex in Wyx) (7.2)
(ii) The relation Θ on E is deﬁned by
{x, y}Θ{u, v}
⇔
δ(x, u) + δ(y, v) ̸= δ(x, v) + δ(y, u)
(7.3)
(see Figure 7.3).
The like relation L (see Deﬁnition 6.2.3) on the set ⃗E of arcs of a graph
G = (V, E) and Winkler’s relation Θ on the set E of edges are closely related
concepts as the following theorem asserts.
u
u
u
u
x
y
u
v
.....................................................................................................
.....................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. .............
Figure 7.3. Deﬁnition of Θ.

144
7 Media and Partial Cubes
7.2.5 Theorem. Let {x, y} and {u, v} be two pairs of adjacent vertices of a
graph G = (V, E). Then
xy L uv
⇒
{x, y}Θ{u, v},
where xy, uv ∈⃗E and L is the like relation on ⃗E. If G is a bipartite graph,
then
{x, y}Θ{u, v}
⇒
(xy L uv
or
xy L vu).
Proof. Let xy L uv, that is,
δ(x, u) + 1 = δ(y, v) + 1 = δ(x, v) = δ(y, u).
By (7.3), we have {x, y}Θ{u, v}.
Suppose now that G is bipartite and {x, y}Θ{u, v}. By Theorem 7.2.2,
either x ∈Wuv or x ∈Wvu. If x ∈Wuv, then, by Lemma 7.2.3,
δ(x, v) = δ(x, u) + 1,
and, by (7.3),
δ(y, v) ̸= δ(y, u) + 1,
which implies, by Theorem 7.2.2 and Lemma 7.2.3, that
δ(y, u) = δ(y, v) + 1.
By applying the triangle inequality twice, we obtain
δ(x, u) + 1 = δ(x, v) ≤δ(y, v) + δ(x, y) = δ(y, v) + 1 =
= δ(y, u) ≤δ(x, u) + δ(x, y) = δ(x, u) + 1.
It follows that
δ(x, u) + 1 = δ(y, v) + 1 = δ(x, v) = δ(y, u),
that is, xy L uv.
A similar argument shows that xy L vu if x ∈Wvu.
It is clear that both relations θ and Θ are reﬂexive and Θ is symmetric;
in fact, so is θ:
7.2.6 Lemma. The relation θ is a symmetric relation on E.
Proof. Suppose that {x, y}θ{u, v} with u ∈Wxy and v ∈Wyx; the case that
u ∈Wyx and v ∈Wxy is symmetric. By Lemma 7.2.3 and the triangle in-
equality, we have
δ(u, x) = δ(u, y) −1 ≤δ(u, v) + δ(v, y) −1 = δ(v, y) =
= δ(v, x) −1 ≤δ(v, u) + δ(u, x) −1 = δ(u, x).
Hence,
δ(u, x) = δ(v, x) −1
and
δ(v, y) = δ(u, y) −1.
Therefore, x ∈Wuv and y ∈Wvu. It follows that {u, v}θ{x, y}.

7.2 Characterizing Partial Cubes
145
7.2.7 Lemma. θ ⊆Θ.
Proof. Let {x, y}θ{u, v} with u ∈Wxy and v ∈Wyx. By Lemma 7.2.3,
δ(x, u) + δ(y, v) = δ(x, v) −1 + δ(y, u) −1 ̸= δ(x, v) + δ(y, u).
Hence, {x, y}Θ{u, v}.
In all but one case, the relations θ and Θ are distinct (see Problem 7.5).
7.2.8 Theorem. A graph G is bipartite if and only if θ = Θ.
Proof. (Necessity.) Suppose that ¬({x, y}θ{u, v}). Then, by Theorem 7.2.2,
either u, v ∈Wxy or u, v ∈Wyx. We assume that u, v ∈Wxy (the other case
is treated similarly). By Lemma 7.2.3, we have
δ(x, u) + δ(y, v) = δ(y, u) −1 + δ(x, v) + 1 = δ(x, v) + δ(y, u),
so ¬({x, y}Θ{u, v}). It follows that Θ ⊆θ. Applying Lemma 7.2.7, we get
θ = Θ.
(Suﬃciency.) Suppose that G is not bipartite. By Theorem 7.2.2, there
is an edge {x, y} such that Wxy ∪Wyx is a proper subset of V . Since G is
connected, there is an edge {u, v} with u /∈Wxy ∪Wyx and v ∈Wxy ∪Wyx.
Clearly, ¬({u, v}θ{x, y}). On the other hand,
δ(x, u) + δ(y, v) ̸= δ(x, v) + δ(y, u),
since u /∈Wxy∪Wyx and v ∈Wxy∪Wyx. Thus, {x, y}Θ{u, v}, a contradiction,
since we assumed that θ = Θ.
We need one more concept from graph theory.
7.2.9 Deﬁnition. Let G = (V, E) be a graph. A subset W ⊆V is convex in
G if
δ(a, x) + δ(x, b) = δ(a, b)
⇒
x ∈W,
for a, b ∈W, x ∈V .
7.2.10 Remark. A semicube of a bipartite graph is not necessarily convex.
For instance, some semicubes of the complete bipartite graph K2,3 depicted
in Figure 6.1A are not convex.
Convexity of semicubes is a central property of graphs in Djokovi´c’s char-
acterization of partial cubes (see Theorem 7.2.15(ii) below).
7.2.11 Lemma. Let G = (V, E) be a bipartite graph such that all its
semicubes are convex. If {x, y}θ{u, v}, then the two pairs of semicubes
{Wxy, Wyx} and {Wuv, Wvu} are identical partitions of the set V .

146
7 Media and Partial Cubes
Proof. We may assume that u ∈Wxy and v ∈Wyx. Suppose that there is
z ∈Wxy such that z /∈Wuv. Then, by Theorem 7.2.2, z ∈Wvu and, by
Lemma 7.2.3, δ(z, v) = δ(z, u) −1. Thus we have
δ(z, v) + δ(v, u) = δ(z, u) −1 + 1 = δ(z, u).
Since Wxy is convex and z, u ∈Wxy, the vertex v must be in Wxy, a contradic-
tion. It follows that Wxy ⊆Wuv. A similar argument shows that Wyx ⊆Wvu.
By Theorem 7.2.2, we have Wxy = Wuv and Wyx = Wvu.
The next lemma is an immediate consequence of Lemma 7.2.11 and The-
orem 7.2.8.
7.2.12 Lemma. Let G = (V, E) be a bipartite graph such that all its
semicubes are convex. Then the relations θ and Θ are equivalence relations
on E.
The next theorem summarizes basic properties of partial cubes.
7.2.13 Theorem. If G = (V, E) is a partial cube, then the following hold.
(i) G is a bipartite graph.
(ii) Each pair of opposite semicubes form a partition of V .
(iii) All semicubes are convex subsets of V .
(iv) Θ and θ are equivalence relations on E, and
(v) There is a 1-1 correspondence between the set of partitions of E deﬁned by
opposite semicubes and the quotient-set E/θ, that is, the set of equivalence
classes of the relation θ.
Proof. We may assume that G is a partial cube on some set X, that is, G is
an isometric subgraph of the cube H(X) (cf. Deﬁnition 7.1.1).
(i) It suﬃces to note that if two sets in H(X) are connected by an edge
then they have diﬀerent parity, that is, one is odd and another is even.
(ii) Follows from (i) and Theorem 7.2.2.
(iii) Note that vertices of G are ﬁnite subsets of X. Let WAB be a semicube
of G. We may assume that A = B∪{a} for a /∈B. By Lemmas 7.2.3 and 3.1.1,
C ∩B ⊆A ⊆C ∪B
for any C ∈WAB. It follows that a ∈C for any C ∈WAB. In the same vein,
a /∈C for any C ∈WBA. Let U, V ∈WAB and C be a vertex of G such that
d(U, C) + d(C, V ) = d(U, V ).
Suppose that C ∈WBA. By Lemma 3.1.1,
U ∩V ⊆C ⊆U ∪V,
a contradiction, since a ∈U, a ∈V but a /∈C. Hence, WAB is convex.

7.2 Characterizing Partial Cubes
147
(iv) Follows from (iii) and Lemma 7.2.12.
(v) Follows from (iii) and Lemma 7.2.11.
We need one more property of relations θ and Θ to establish the main
result of this section.
7.2.14 Lemma. Let e and f be two distinct edges of a shortest path P in a
graph G. Then neither eθf nor eΘf hold.
Proof. Let P = x0, x1, . . . , xn be a shortest path from x0 to xn and e =
{xi, xi+1} and f = {xj, xj+1} be two edges in P, where i < j. Then δ(xi, xj) <
δ(xi, xj+1) and δ(xi+1, xj) < δ(xi+1, xj+1), so xi, xi+1 ∈Wxj,xj+1. Hence,
¬(eθf).
We also have
δ(xi, xj) + δ(xi+1, xj+1) = (δ(xi+1, xj) + 1) + (δ(xi, xj+1) −1),
which implies that ¬(eΘf).
The following theorem puts forth characterizations of partial cubes due
to Djokovi´c (1973) and Winkler (1984) (cf. Theorem 2.10 in Imrich and
Klavˇzar, 2000).
7.2.15 Theorem. Let G = (V, E) be a connected graph. The following state-
ments are equivalent:
(i) G is a partial cube.
(ii) G is bipartite and all semicubes of G are convex.
(iii) G is bipartite and θ is an equivalence relation.
(iv) G is bipartite and Θ is an equivalence relation.
Proof. (i) ⇒(ii). Follows from Theorem 7.2.13(i),(iii).
(ii) ⇒(iii). Follows from Lemma 7.2.12.
(iii) ⇒(i). We say that two edges e and f are θ-equivalent if eθf. By
Theorem 7.2.2, each pair of opposite semicubes of G form a partition of V .
We orient these partitions by calling, in an arbitrary way, one of the two
opposite semicubes in each partition a positive semicube. Let us assign to
each x ∈V the set W +(x) of all the positive semicubes containing x. In the
next paragraph we prove that the family F = {W +(x)}x∈V is well-graded and
that the assignment x →W +(x) is an isometry between G and F.
Let x and y be two distinct vertices of G. We say that a positive semicube
W separates x and y if either x ∈W, y ∈W or x ∈W, y ∈W (W stands for
the complement of W). Let P be a shortest path
x0 = x, x1, . . . , xn = y
from x to y. By Lemma 7.2.14, no two distinct edges of P stand in the rela-
tion θ. Therefore distinct edges of P deﬁne distinct positive semicubes that

148
7 Media and Partial Cubes
clearly separate x and y. Moreover, any edge deﬁning a positive semicube that
separates x and y is θ-equivalent to one of the edges of P. Indeed, otherwise,
for this edge, say {u, v}, we would have x ∈Wuv and y ∈Wvu or y ∈Wuv
and x ∈Wvu. In either case, there is an edge in P that joins semicubes Wuv
and Wvu, a contradiction. It follows that any semicube in W +(x) △W +(y)
is deﬁned by a unique edge in P and any edge in P deﬁnes a semicube in
W +(x) △W +(y). Therefore F is a wg-family of sets and
d(W +(x), W +(y)) = δ(x, y).
By Theorem 3.4.12, the family F is isometric to a wg-family of ﬁnite sets.
Hence, G is a partial cube.
(iii) ⇔(iv). Follows from Theorem 7.2.8.
The next deﬁnition enables another useful characterization of partial cubes.
7.2.16 Deﬁnition. Let J be a set of colours. A J-edge-colouring of a graph
G = (V, E) is a function E →J. We also say that edges of G are coloured by
elements of J.
7.2.17 Theorem. A graph G = (V, E) is a partial cube if and only if it is
possible to color its edges by elements of some set J in such a way that:
(i) the edges of any shortest path of G are of diﬀerent colours;
(ii) in each closed walk of G every colour appears an even number of times.
Proof. (Necessity.) Without loss of generality, we may assume that G = (F, E)
is an isometric subgraph of a cube H(J) such that ∩F = ∅and ∪F = J for
a wg-family F. For any edge {S, T} of G there is an element j ∈J such that
S △T = {j}, so we can colour the edges of G by the elements of J.
(i) Let S0 = S, S1, . . . , Sn = T be a shortest path from S to T in G. For
every i, we have S ∩T ⊆Si ⊆S ∪T. Therefore,
{ji} = Si−1 △Si ⊆S △T.
Since (Si) is a shortest path, |S △T| = d(S, T) = n. It follows that all colours
ji are distinct.
(ii) Let S0, S1, . . . , Sn = S0 be a closed walk W in G and let Ep = {Sp−1, Sp}
be the ﬁrst edge in W coloured by j, so Sp−1 △Sp = {j}. We assume that
j /∈Sp−1 and j ∈Sp; the other case is treated similarly. Since Ep is the ﬁrst
edge of W coloured by j, we must have j /∈S0. Because the walk W is closed
and j ∈Sp, we must have another occurrence of j in W. Let Eq = {Sq−1, Sq}
be the next edge of W coloured by j. We have j ∈Sq−1 and j /∈Sq. By
repeating this argument, we partition the occurrences of j in W into pairs, so
the total number of these occurrences must be even.
(Suﬃciency.) Let S0 be a ﬁxed vertex of G. For any vertex S ∈V and a
shortest path p from S0 to S, we deﬁne

7.3 Semicubes of Media
149
JS = {j ∈J | j is a colour of an edge of p},
and JS0 = ∅. The set JS is well-deﬁned. Indeed, let q be another shortest
path from S0 to S and ˜q be its reverse, so p˜q is a closed walk. By (i) and (ii),
JS does not depend on the choice of p.
The correspondence α : S →JS deﬁnes an isometric embedding of G into
the cube H(J). Indeed, for S, T ∈V , let p (resp. q) be a shortest path from
S0 to S (resp. T) and let r be a shortest path from S to T. By (ii) applied to
the closed walk pr˜q and (i), we have
j ∈JS △JT
⇐⇒
j is a colour of an edge of r,
so δ(S, T) = |JS △JT | = d(JS, JT ).
The next result is a restatement of Theorem 7.1.7, with an alternative
proof based on Theorem 7.2.17.
7.2.18 Theorem. The graph of a medium is a partial cube.
Proof. Let (S, T) be a medium and G be its graph. For any edge of G there
is a unique pair of tokens {τ, ˜τ} deﬁning that edge. Let us colour edges of
G by elements of the set J = {{τ, ˜τ}}τ∈T. Since the shortest paths of G
correspond to the concise messages of (S, T) (cf. Lemma 6.1.3), condition (i)
of Theorem 7.2.17 is satisﬁed. A closed walk W in G deﬁnes a closed message
m for a vertex of W. By Axiom [Mb], the message m is vacuous. Thus every
colour appears an even number of times in the walk W. The result follows
from Theorem 7.2.17.
7.3 Semicubes of Media
The concept of a semicube will be very useful in our investigation of media
embeddings into lattices later in Chapter 8. In this section we introduce a
media counterpart of this concept.
7.3.1 Deﬁnition. Let (S, T) be a medium. For τ ∈T, the subset
Sτ = {S ∈S τ ∈S}
of S is called a semicube. The semicubes Sτ and S˜τ are called opposite.
By Theorem 2.4.3, we have
Sτ ∩S˜τ = ∅
and
Sτ ∪S˜τ = S
for any τ ∈T,
so pairs of opposite semicubes form partitions of S.
Semicubes are rather special sets of states. In particular, the construction
of the semicubes for a pair of tokens τ and ˜τ can be viewed as a special

150
7 Media and Partial Cubes
case of the projection of a medium (cf. Deﬁnition 2.11.2) with U = {τ, ˜τ}.
By Theorem 2.11.6(ii) with U = {τ, ˜τ}, the reduction (Sτ, TSτ ) of a medium
(S, T) to the semicube Sτ is a submedium of (S, T). Clearly, the graph of the
submedium (Sτ, TSτ ) is a semicube of the graph of the medium. We use this
fact to calculate the average length of a ﬁnite medium in Theorem 7.3.4.
7.3.2 Deﬁnition. Let M = (S, T) be a ﬁnite medium with n states. The
average length ℓa(M) of the medium M is deﬁned by
ℓa(M) =
1
n(n −1)

S∈S

T ∈S
δ(S, T).
(7.4)
The average length ℓa(G) of the partial cube G representing the medium M
is deﬁned by the same formula.
Note that ℓa(M) is the average length of all the concise messages of the
medium M. To establish a useful formula for ℓa(M), we ﬁrst prove a general
proposition (cf. Imrich and Klavˇzar, 2000).
Let Q = {0, 1}m be the vertex set of the m-dimensional cube endowed
with the usual Hamming distance
dH(u, v) =
m

i=1
|ui −vi|,
where u = (u1, . . . , um) and v = (v1, . . . , vm) are vertices of the cube.
For 1 ≤i ≤m, we denote by
Q′
i = {v ∈Q vi = 0}
and
Q′′
i = {v ∈Q vi = 1}
the opposite facets of Q.
7.3.3 Lemma. For X ⊆Q, let X′
i = X ∩Q′
i and X′′
i = X ∩Q′′
i . Then
1
2

u∈X

v∈X
dH(u, v) =
m

i=1
|X′
i||X′′
i |.
Proof. We have

u∈X

v∈X
dH(u, v) =

u∈X

v∈X
m

i=1
|ui −vi| =
m

i=1
 
u∈X

v∈X
|ui −vi|

.
Note that |ui −vi| = 1 if and only if u ∈X′
i, v ∈X′′
i or u ∈X′′
i , v ∈X′
i;
otherwise, |ui −vi| = 0. Therefore

u∈X

v∈X
|ui −vi| = 2 |X′
i||X′′
i |.
The result follows.

7.4 Projections of Partial Cubes
151
7.3.4 Theorem. Let M = (S, T) be a ﬁnite medium with n states and 2m
tokens. Then
ℓa(M) =
2
n(n −1)

{τ,˜τ}
|Sτ||S˜τ|,
where the sum is taken over the set of all pairs of mutually reverse tokens.
Proof. Let (Q, TQ) be the medium with set of states Q = {0, 1}m and tokens
deﬁned by
γi(u) =

(u1, . . . , um),
if ui = 0,
(u1, . . . , 1 −ui, . . . , um),
if ui = 1,
and
˜γi(u) =

(u1, . . . , 1 −ui, . . . , um),
if ui = 0,
(u1, . . . , um),
if ui = 1.
It is clear that (Q, TQ) is a medium isomorphic to the complete medium
(P(Z), WP(Z)), where Z = {1, . . . , m}. By Theorem 3.3.4, there is an isomor-
phic embedding
(α, β) : (S, T) →(Q, TQ),
which deﬁnes an isometric embedding (S, δ) →(Q, dH). It is not diﬃcult to
verify that the image α(Sτ) of a semicube Sτ is a subset of a facet of Q,
and that opposite semicubes are mapped into opposite facets of Q. The result
follows from Lemma 7.3.3.
7.4 Projections of Partial Cubes
We begin by extending the usual deﬁnition of a projection of a ﬁnite dimen-
sional cube onto its face to arbitrary cubes H(X).
7.4.1 Deﬁnition. Let U be a nonempty subset of a set X. A projection of
the cube H(X) onto the cube H(U) is the mapping
ϕ : P →P ∩U
for P ∈Pf(X).
Since
(P △Q) ∩U = (P ∩U) △(Q ∩U),
(7.5)
the projection ϕ maps an edge {P, Q} of H(X) into either a single vertex of
H(U) or into an edge of H(U). Thus, for a subgraph G = (F, E) of H(X), the
projection ϕ deﬁnes a subgraph ϕ(G) of H(U) that we call the projection of
G into H(U).
7.4.2 Theorem. The projection of a partial cube on X into H(U) is a partial
cube on U.

152
7 Media and Partial Cubes
Proof. It suﬃces to prove that the projection of a shortest path in H(X) is
a shortest path in H(U). Let R0 = P, R1, . . . , Rn = Q be a shortest path in
H(X), so d(P, Q) = n. Then Ri △Ri+1 = {xi} with distinct xi ∈P △Q for
0 ≤i < n. By (7.5),
{xi} ∩U = (Ri △Ri+1) ∩U = (Ri ∩U) △(Ri+1 ∩U) = ϕ(Ri) △ϕ(Ri+1).
Therefore, {ϕ(Ri), ϕ(Ri+1} is an edge if and only if
xi ∈(P △Q) ∩U = ϕ(P) △ϕ(Q).
It follows that distinct vertices ϕ(Ri) form a shortest path in H(U).
As we proved in this chapter (Theorems 7.1.7 and 7.2.18), the graph of a
medium is a partial cube. In what follows we establish a rather transparent
interpretation (Theorem 7.4.3) of projections of media (as deﬁned in 2.11.4)
in terms of partial cube projections. By Theorem 3.3.4, any medium is iso-
morphic to the representing medium (F, WF) of some wg-family F of ﬁnite
subsets of a set X, so we consider only representing media. Moreover, by The-
orem 7.1.9, we may assume that conditions (7.1) are satisﬁed.
There is a 1-1 correspondence established by {γx, ˜γx} ↔x, between sym-
metric subsets of WF and subsets of X. For a given nonempty, symmetric
subset U of WF, we denote the corresponding subset of X by U.
Let S ̸= T be two states in F and let m = τ1 . . . τn be a concise message
producing T from S. Then each τi is either γxi or ˜γxi for xi ∈S △T. We also
have xi ̸= xj for i ̸= j and ∪i{xi} = S △T. From this observation and (7.5),
we obtain the equivalences:
C(m) ⊆(WF \ U)
⇔
S △T ⊆X \ U
⇔
S ∩U = T ∩U.
Thus, S ∼T (see Deﬁnition 2.11.2) if and only if the projections of S and
T into the cube H(U) are equal. It follows that classes of the equivalence
relation ∼are uniquely determined by projections of elements of F into the
cube H(U). In fact, we have the following result:
7.4.3 Theorem. The graph of the projection of a medium (F, WF) under U
is the projection of the graph of (F, WF) into the cube H(U).
We leave the details of the proof to the reader (Problem 7.17).
The projections ϕ of partial cubes on a set X into a cube H(U) have a
particularly simple description in the case when U = X \ {a} for some a ∈X.
Let G be a partial cube on X with a vertex set F, where F is a wg-family
of sets satisfying conditions
∩F = ∅
and
∪F = X,
(7.6)
and let U = X \ {a}. We denote by ϕa the projection of H(X) onto H(U).
Then

7.4 Projections of Partial Cubes
153
ϕa(R) =

R,
if a /∈R,
R \ {a},
if a ∈R,
for R ∈F.
Thus, we have a partition of F into two families of sets:
{R ∈F ϕa(R) = R} = {R ∈F a /∈R},
(7.7)
and
{R ∈F ϕa(R) ̸= R} = {R ∈F a ∈R}.
(7.8)
7.4.4 Theorem. (i) The families deﬁned by (7.7) and (7.8) are opposite
semicubes of the partial cube G.
(ii) For any pair {WP Q, WQP } of opposite semicubes, there is a unique
a ∈X such that the pair of sets {R ∈F a /∈R} and {R ∈F a ∈R} form
the same partition of F as WP Q and WQP .
(iii) There is a 1-1 correspondence between the set X = ∪F and the set of
all pairs of opposite semicubes.
Proof. (i) By (7.6), there are S, T ∈F such that a /∈S and a ∈T. Let
R0 = S, R1, . . . , Rn = T be a shortest path in G. There is an index i such
that a /∈Ri and a ∈Ri+1. We denote P = Ri and Q = Ri+1. Clearly,
Q = P + {a}. By the deﬁnition of a semicube, Lemma 7.2.3, and (3.2), we
have equivalences
R ∈WP Q
⇔
d(R, P) < d(R, Q)
⇔
d(R, P) + d(P, Q) = d(R, Q)
⇔R ∩Q ⊆P ⊆R ∪Q
⇔
a /∈R,
where the last equivalence is easily veriﬁed for Q = P + {a}. It follows that
{R ∈F ϕa(R) = R} = WP Q.
A similar argument shows that {R ∈F ϕa(R) ̸= R} = WQP .
(ii) Let {P, Q} be an edge of G. We may assume that Q = P + {a} for
some a ∈X. Then, for any R ∈F,
R △Q = R △(P + {a}) =

(R △P) + {a},
if a ∈R,
R △P,
if a /∈R.
Hence |R △P| < |R △Q| if and only if a ∈R. It follows that
WP Q = {R ∈F a ∈R}
and
WQP = {R ∈F a /∈R}
(7.9)
If {S, T} is another edge deﬁning the pair {WP Q, WQP }, then S and T belong
to diﬀerent semicubes in this pair. By (7.9), S △T = {a}. Thus the element
a is uniquely deﬁned by the pair {WP Q, WQP }.
(iii) Follows immediately from (i) and (ii).

154
7 Media and Partial Cubes
7.4.5 Remark. Geometrically, the edges {P, Q} of the partial cube G of the
theorem with P △Q = {a} are ‘parallel’ edges of the cube H(X) and ϕa
projects G along these edges into H(U), which can be regarded as a ‘facet’ of
H(X). The resulting graph ϕa(G) is isomorphic to the isometric contraction
of the partial cube G (Imrich and Klavˇzar, 2000; Ovchinnikov, 2007).
7.4.6 Remark. Let U = F \ {a1, . . . , an}. Then the projection ϕ of H(X) is
a composition of projections ϕai in arbitrary order (Problem 7.18). Thus, in
the ﬁnite case, a projection can be deﬁned as a composition of contractions.
7.5 Uniqueness of Media Representations
Theorem 3.3.4 asserts that any medium (S, T) is isomorphic to the medium
(F, WF) of a well-graded family F of ﬁnite subsets of some set X. In this
section we show that this representation is unique in some precise sense.
Suppose that (F1, WF1) and (F2, WF2) are two representations of (S, T).
By Theorem 7.1.9, we may assume that conditions (7.1) are satisﬁed. The
media (F1, WF1) and (F2, WF2) are isomorphic, which implies that the sets
X1 = ∪F1 and X2 = ∪F2 have the same cardinality. It follows that the cubes
H(X1) and H(X2) are isomorphic. Thus we may assume that X1 = X2 = X
and consider two isomorphic media (F1, WF1) and (F2, WF2) representing
(S, T) with ∪F1 = ∪F2 = X and ∩F1 = ∩F2 = ∅. The graphs of these
media are isomorphic partial subcubes of the cube H(X). On the other hand,
by Theorems 7.1.10 and 6.4.5, isomorphic partial cubes represent isomorphic
media.
The uniqueness problem is formulated geometrically as follows:
7.5.1 Uniqueness Problem. Show that, given two isometric partial sub-
cubes of H(X), there is an isometry of H(X) onto itself that maps one of the
partial cubes onto the other.
We shall use the following general ‘homogeneity’ properties of a metric
space (cf. Bogatyi, 2002):
7.5.2 Deﬁnition. Let Y be a metric space and K be a nonempty family of
subsets of Y . The space Y is said to be K-homogeneous if, for every two
subsets A, B ∈K and an isometry A →B, this isometry can be extended to
an isometry of the entire space Y onto itself. If K is the family of all singletons
in Y , then the space Y is said to be homogeneous. If K is the family of all
subsets of Y , then the space Y is said to be fully homogeneous (cf. Burago
et al., 2001).
We denote by WG the collection of all wg-families F satisfying condi-
tions (7.1):

7.5 Uniqueness of Media Representations
155
∩F = ∅
and
∪F = X.
We shall prove an even stronger statement than the one formulated in 7.5.1,
namely, that H(X) is a WG-homogeneous metric space, that is, any isometry
between two partial cubes on X can be extended to an isometry of the hyper-
cube H(X) (see Theorem 7.5.11).
7.5.3 Remark. Note, that H(X) is not a fully homogeneous space, since an
isometry between two subsets of H(X) cannot be extended, in general, to an
isometry of the cube H(X) (cf. Problem 7.10). On the other hand, H(X) is a
homogeneous metric space (cf. Problem 7.11).
A general remark is in order. Let Y be a homogeneous metric space, A
and B be two metric subspaces of Y , and α be an isometry from A onto B.
Let c be a ﬁxed point in Y . For a given a ∈A, let b = α(a) ∈B. Since Y
is homogeneous, there are isometries β and γ of Y such that β(a) = c and
γ(b) = c. Then λ = γαβ−1 is an isometry from α(A) onto β(B) such that
λ(c) = c. Clearly, α is extendable to an isometry of Y if and only if δ is
extendable. Therefore, in the case of the space H(X), we may consider only
well-graded families of subsets containing the point ∅and isometries between
these families ﬁxing this point.
To prove the main theorem of this section (Theorem 7.5.11), we ﬁrst es-
tablish some technical results.
7.5.4 Deﬁnition. For F ∈WG, with ∅∈F and |F| > 1, we deﬁne a function
rF : ∪F →N by
rF(x) = min{|A| x ∈A, A ∈F}.
For k ∈N, the sets XF
k are deﬁned by
XF
k = {x ∈∪F rF(x) = k}.
We have XF
i ∩XF
j = ∅for i ̸= j, and ∪k XF
k = ∪F. Some of the sets XF
k
could be empty for k > 1, although XF
1 is not empty, since, by the wellgrad-
edness property, F contains at least one singleton (we assumed that ∅∈F).
7.5.5 Example. Let X = {a, b, c} and F be the wg-family of Example 2.1;
thus,
F = {∅, {a}, {b}, {a, b}, {a, b, c}}.
We have rF(a) = rF(b) = 1, rF(c) = 3 and
XF
1 = {a, b}, XF
2 = ∅, XF
3 = {c}.
7.5.6 Lemma. For A ∈F and x ∈A, we have
rF(x) = |A|
⇒
A \ {x} ∈F.
(7.10)

156
7 Media and Partial Cubes
Proof. Let k = |A|. Since F is well-graded, there is a nested sequence A0 =
∅⊆A1 ⊆· · · ⊆Ak = A. Since rF(x) = k, we have x /∈Ai for i < k. It follows
that A \ {x} = Ak−1 ∈F.
Let us recall from Theorem 3.4.5(ii) that
A ∈[B ∩C, B ∪C] ⇔d(B, A) + d(A, C) = d(B, C),
(7.11)
for all A, B, C ∈P(X). It follows that
A ∈[B ∩C, B ∪C] ⇔α(A) ∈[α(B) ∩α(C), α(B) ∪α(C)]
(7.12)
for A, B, C ∈F1 and an isometry α : F1 →F2.
In the sequel, F1 and F2 are two well-graded families of ﬁnite subsets of
X both containing ∅, and α : F1 →F2 is an isometry such that α(∅) = ∅.
7.5.7 Deﬁnition. We deﬁne a relation σ between ∪F1 and ∪F2 (therefore,
σ ⊆∪F1 × ∪F2) by means of the following construction. By (7.10), for
x ∈∪F1 there is A ∈F1 such that x ∈A, rF1(x) = |A|, and A \ {x} ∈F1.
Since ∅⊆A \ {x} ⊂A, we have, by (7.12), α(A \ {x}) ⊂α(A). Since
d (A \ {x}, A) = 1, there is y ∈∪F2 such that α(A) = α(A \ {x}) + {y}. In
this case we say that xy ∈σ.
7.5.8 Lemma. If x ∈XF1
k
and xy ∈σ, then y ∈XF2
k .
Proof. Let A ∈F1 be a set of cardinality k deﬁning rF1(x) = k. Since |A| =
d (∅, A) = d (∅, α(A)) = |α(A)| and y ∈α(A), we have rF2(y) ≤k. Suppose
that m = rF2(y) < k. Then, by (7.10), there is B ∈F2 such that y ∈B,
|B| = m, and B \ {y} ∈F2. Clearly,
α(A \ {x}) ∩B ⊆α(A) ⊆α(A \ {x}) ∪B.
By (7.12), we have
(A \ {x}) ∩α−1(B) ⊆A ⊆(A \ {x}) ∪α−1(B).
It follows that x ∈α−1(B), a contradiction, because
rF1(x) = k
and
|α−1(B)| = m < k.
Thus rF2(y) = k, that is, y ∈XF2
k .
We proved that, for every k ≥1, the restriction of σ to XF1
k
× ∪F2 is a
relation σk ⊆XF1
k × XF2
k .
7.5.9 Lemma. The relation σk is a bijection for every k ≥1.

7.5 Uniqueness of Media Representations
157
Proof. Suppose that there are z ̸= y such that xy ∈σk and xz ∈σk. Then,
by (7.10), there are two distinct sets A, B ∈F1 such that
k = rF1(x) = |A| = |B|, A \ {x} ∈F1, B \ {x} ∈F1,
and
α(A) = α(A \ {x}) + {y}, α(B) = α(B \ {x}) + {z}.
We have
d (α(A), α(B)) = d (A, B) = d (A \ {x}, B \ {x})
= d (α(A) \ {y}, α(B) \ {z}).
Thus y, z ∈α(A) ∩α(B), that is, in particular, that z ∈α(A) \ {y}, a contra-
diction, because rF2(z) = k and |α(A) \ {y}| = k −1.
By applying the above argument to α−1, we prove that σk is a bijection.
It follows from the previous lemma that σ is a bijection from ∪F1 = X
onto ∪F2 = X, that is, σ is a permutation on the set X.
7.5.10 Lemma. α(A) = σ(A) for any A ∈F1.
Proof. We prove this statement by induction on k = |A|. The case k = 1 is
trivial, since α({x}) = {σ1(x)} for {x} ∈F1.
Suppose that α(A) = σ(A) for all A ∈F1 such that |A| < k. Let A be a
set in F1 of cardinality k. By the wellgradedness property, there is a nested
sequence {Ai}0≤i≤k of distinct sets in F1 with A0 = ∅and Ak = A. Thus,
A = Ak−1 + {x} for some x ∈∪F1). Clearly, m = rF1(x) ≤k.
If m = k, then α(A) = α(Ak−1) ∪{σ(x)} = σ(A), by the deﬁnition of σ
and the induction hypothesis.
Suppose now that m < k. There is a set B ∈F1 containing x such
that |B| = m. By the wellgradedness property, there is a nested sequence
{Bi}0≤i≤m of distinct sets in F1 with B0 = ∅and Bm = B. We have x /∈Bi
for i < m, since m = rF1(x). Therefore, B = Bm−1 + {x}. Clearly,
Bm−1 ∩A ⊆B ⊆Bm−1 ∪A.
By (7.12),
α(B) ⊆α(Bm−1) ∪α(A).
Thus, by the induction hypothesis, we have
σ(Bm−1) + {σ(x)} = σ(B) ⊆σ(Bm−1) ∪α(A).
Hence, σ(x) ∈α(A). Since α(A) = σ(Ak−1) + {y} for y /∈σ(Ak−1) and
x /∈Ak−1, we have y = σ(x), that is, α(A) = σ(A).
From this lemma, we immediately obtain:

158
7 Media and Partial Cubes
7.5.11 Theorem. The space H(X) is WG-homogeneous.
7.5.12 Remark. In the case of a ﬁnite set X, Theorem 7.5.11 is a consequence
of Theorem 19.1.2 in Deza and Laurent (1997).
In the proof of Theorem 7.5.11 we used two kinds of isometries of H(X):
isometries that map elements of H(X) to the empty set, and isometries deﬁned
by permutations on X. It is not diﬃcult to show that these isometries generate
the isometry group of H(X):
7.5.13 Theorem. The isometry group of H(X) is generated by permutations
on the set X and functions
ϕA : S →S △A,
(S ∈H(X)).
We omit the proof (see Problem 7.19).
7.6 The Isometric Dimension of a Partial Cube
7.6.1 Deﬁnition. (Djokovi´c, 1973) Let X be a set. The dimension of the
hypercube H(X) is the cardinality of the set X. The isometric dimension
dimI(G) of a partial cube G is the minimum possible dimension of a hypercube
H(X) in which G is isometrically embeddable.
Clearly, isomorphic partial cubes have the same isometric dimension. Thus,
by Theorem 7.1.9, we may consider only partial cubes that are induced by
wg-families of ﬁnite sets satisfying conditions (7.1). We recall that, by the
implication (i) ⇒(iii) of Theorem 7.2.15, the Djokovi´c’s relation θ of a graph
G = (E, V ) is an equivalence relation on E if G is a partial cube. The notation
E/θ refers to the partition on E induced by the equivalence θ (cf. 1.8.4). By
Theorems 7.2.13(v) and 7.4.4, we have the following result.
7.6.2 Theorem. Let G = (V, E) be a partial cube induced by a wg-family F
of ﬁnite subsets of a set X such that ∩F = ∅and ∪F = X. Then
dimI(G) = |E/θ| = |X|,
where θ is Djokovi´c’s equivalence relation on E.
7.6.3 Corollary. Let M = (S, T) be a medium and G be its representing
graph. Then
dimI(G) = |T|/2.
Proof. By Theorem 3.3.4, we may assume that M = (F, WF) for a wg-family
F of ﬁnite subsets of a set X satisfying conditions (7.1). Each element x ∈X
deﬁnes a pair of tokens {τx, ˜τx}. The result follows from Theorem 7.6.2.

Problems for Chapter 7
159
Problems
7.1 Let M is a medium with n states and 2m tokens.
(i) Show that m + 1 ≤n ≤2m.
(ii) Show that m + 1 and 2m are exact bounds for n.
7.2 Let T be a tree with n vertices. Show that T is a partial cube and ﬁnd
dimI(T).
7.3 Let C2n be a cycle of even length. Show that C2n is a partial cube and
ﬁnd dimI(C2n). What are equivalence classes of relations θ and Θ? What are
semicubes of C2n?
7.4 Let C2n+1 be a cycle of odd length. Show that the relation θ is the
identity relation on the set of edges of C2n+1 and that the relation Θ is not
transitive.
7.5 Let G = K2,3 be a complete bipartite graph with 2 + 3 = 5 vertices.
Show that the relation Θ is not transitive on the set of edges of G. Describe
semicubes of the graph G.
7.6 Give an example of a graph G for which the second part of Theorem 7.2.5
does not hold.
Figure 7.4. The graph in Problem 7.7.
7.7 Show that the graph depicted in Figure 7.4 is not a partial cube.
7.8 Show that a connected, bipartite graph in which every edge is contained
in at most one cycle is a partial cube.
7.9 Let X = {a, b, c}. Show that the 3-cube H(X) is fully homogeneous.
7.10 Let X = {a, b, c, d}. Show that the 4-cube H(X) is not fully homoge-
neous.
7.11 Prove that any cube H(X) is a homogeneous metric space.
7.12 Let P be a path of length n and M be the medium represented by P.
Find the average length ℓa(M) of M.
7.13 Show that the average length of the cycle C2n is
n2
2n−1.

160
7 Media and Partial Cubes
Figure 7.5. The graph in Problem 7.15.
7.14 Show that the average length of the complete medium on n states is
n2n−1
2n−1 .
7.15 Let G be the graph shown in Figure 7.5.
(i) Show that G is a partial cube.
(ii) Find the isometric dimension dimI(G).
(iii) Find the average length of the corresponding medium.
7.16 Let P and Q be two vertices of the cube H(X). Show that the subgraph
induced by the interval [P ∩Q, P ∪Q] is isomorphic to the cube H(U) where
U = (P ∪Q) \ (P ∩Q).
7.17 Restore the details of the proof of Theorem 7.4.3.
7.18 Let ϕa be the projection of H(X) onto H(U), where U = F \ {a}, and
let ϕ be the projection of H(X) onto H(U), where U = F \ {a1, . . . , an}.
(i) Show that ϕaϕb = ϕbϕa for all a, b ∈X.
(ii) Show that ϕ = ϕa1 · · · ϕan.
7.19 Prove Theorem 7.5.13.

8
Media and Integer Lattices
Because any ﬁnite medium has an isomorphic representation as a ﬁnite dimen-
sional partial cube, it is also representable as a ﬁnite isometric subgraph of
some integer lattice. Obviously, the dimension of a lattice representation may
be much lower than the dimension of a partial cube representing the medium,
making this representation an invaluable tool in visualizing large media. We
already used lattice representations for this purpose in previous chapters.
In this chapter (following Eppstein, 2005b) we establish the minimum di-
mension of a lattice representation of a given partial cube. We extend these
results to handle inﬁnite as well as ﬁnite partial cubes and to handle both
oriented and unoriented media.
8.1 Integer Lattices
In order to deﬁne the dimension of inﬁnite partial cubes, we need a notion
of inﬁnite dimensional integer lattices. As the Cartesian product of inﬁnitely
many copies of Z does not form a connected graph, we cannot use it directly
in our deﬁnitions. Instead we base our deﬁnition on a single connected com-
ponent of this Cartesian product. Essentially the same notion is called a weak
Cartesian Product by Imrich and Klavˇzar (2000).
8.1.1 Deﬁnition. The support of a real valued function f on a set X is the
subset of X on which f takes a nonzero value. We denote by ZX the collection
of all functions f : X →Z with ﬁnite support. The integer lattice on X is the
graph Z(X) having ZX as its set of vertices and whose set of edges contains
all {f, g} such that
|f(x) −g(x)| = 1
for some x ∈X, and
f(y) = g(y)
for all y ∈X \ {x}.
The dimension of the integer lattice Z(X) is the cardinality of X. If X has
ﬁnite cardinality d, we write Z(X) = Zd.

162
8 Media and Integer Lattices
8.1.2 Theorem. The integer lattice Z(X) is a connected graph with the graph
distance given by
δZ(f, g) =

x∈X
|f(x) −g(x)|.
(8.1)
Proof. The set of arguments where the values of f and g diﬀer,
A = {x ∈X f(x) ̸= g(x)},
is a subset of the union of the supports of f and g, and therefore ﬁnite; thus
δZ(f, g) is a ﬁnite integer for every f and g.
We ﬁrst prove by induction on δZ that the value δZ(f, g) deﬁned as a sum
in the lemma is greater than or equal to to the graph distance. That is, we
assume as an induction hypothesis that every f ′ and g′ with δZ(f ′, g′) < D
can be connected by a path of length at most δZ(f ′, g′), and show that this
hypothesis implies the existence of a path of length δZ(f, g) = D connecting
f to g. As a base case, if δZ(f, g) = 0, then f and g are clearly the same
vertex and form the endpoints of a path of length zero. Otherwise, let f and
g be two distinct vertices in Z(X) with δZ(f, g) = D. Let a be any element of
A, as deﬁned above, and swap f and g if necessary so that that f(a) > g(a).
Deﬁne the function h ∈ZX by the formula
h(x) =

f(x) −1,
if x = a,
f(x),
otherwise.
Then δZ(h, g) = δZ(f, g) −1. By the induction hypothesis there exists a path
in Z(X) of length δZ(f, g) −1 between h and g. Concatenating this path with
the edge in Z(X) between f and h yields a path of length δZ(f, g) between f
and g.
To ﬁnish the proof, we prove in the other direction that, for every f and
g the value δZ(f, g) is less than or equal to the graph distance. Let h0 =
f, h1, . . . , hn = g be a path from f to g in Z(X). We must show that this path
has length at least δZ(f, g). But since h1 can diﬀer from h0 in only a single
function value, δZ(h1, g) ≥δZ(f, g) −1 and the result follows by induction
on n.
Since δZ(f, g) is bounded above and below by the graph distance, it is
equal to that distance.
8.1.3 Remark. In the case of a ﬁnite-dimensional lattice Zd the distance
deﬁned by (8.1) is the usual ℓ1-distance on Zd.
8.2 Deﬁning Lattice Dimension
As the following theorem shows, isometric embedding into integer lattices is
closely related to isometric embedding into hypercubes.

8.2 Deﬁning Lattice Dimension
163
8.2.1 Deﬁnition. Let a given set X be given, and let A be a subset of X.
Then the indicator function χA : X →{0, 1} is deﬁned by
χA(x) =

1,
if x ∈A,
0,
otherwise.
Observe that the support of χA is A itself.
8.2.2 Theorem. For any set X, the hypercube H(X) can be embedded iso-
metrically into Z(X), and the integer lattice Z(X) can be embedded isometri-
cally into H(X × Z).
Proof. The function α : A →χA, where χA is the indicator function of A ⊆X,
is clearly an isometric embedding of the cube H(X) into the integer lattice
Z(X).
In the other direction, for f ∈Z(X) deﬁne the set
Bf = {(x, k) ∈X × Z k ≤f(x)}.
Then
Bf △Bg = {(x, k) ∈X × Z g(x) < k ≤f(x) or f(x) < k ≤g(x)}.
Let Af = Bf △B0, where 0 stands for the zero function on X. Clearly, Af is
a ﬁnite set, Af △Ag = Bf △Bg, and
d(Af, Ag) = |Af △Ag| = |Bf △Bg| =

x∈X
|f(x) −g(x)| = δZ(f, g),
so β : f →Af is an isometric embedding of the integer lattice Z(X) into the
cube H(X × Z).
8.2.3 Corollary. The graph Z(X) is a partial cube.
8.2.4 Corollary. A graph is a partial cube if and only if it is isometrically
embeddable into an integer lattice.
Proof. If a graph is a partial cube, it can be isometrically embedded into some
H(X), and (by Theorem 8.2.2 and transitivity of isometric embedding) also
into the integer lattice Z(X). On the other hand, if a graph embeds into an
integer lattice Z(X), then by Theorem 8.2.2 it also embeds into H(X×Z) and
is therefore a partial cube.
As every partial cube can be embedded into an integer lattice, it makes
sense to ask what the minimum dimension of such an embedding can be. That
is, we use these embeddings to deﬁne a notion of lattice dimension for partial
cubes.

164
8 Media and Integer Lattices
8.2.5 Deﬁnition. The lattice dimension dimZ(G) of a partial cube G is the
minimum cardinality of a set X such that G is isometrically embeddable into
Z(X).
We can use the connection between hypercubes and integer lattices to
bound the lattice dimension in terms of the isometric dimension:
8.2.6 Corollary. For any partial cube G
dimZ(G) ≤dimI(G).
Proof. By Theorem 7.6.2, G can be isometrically embedded into H(X), where
X is a set of cardinality dimI(G). The result follows from the isometric em-
bedding of H(X) into Z(X) given by Theorem 8.2.2.
Theorem 8.3.5, later in this chapter, strengthens Corollary 8.2.6 for ﬁnite
partial cubes by quantifying the diﬀerence between dimZ(G) and dimI(G).
8.2.7 Example. To illustrate the deﬁnitions above, we consider a simple case
when G is a ﬁnite tree T = (V, E). It is not diﬃcult to see (cf. Deza and
Laurent, 1997) that a ﬁnite tree T is indeed a partial cube and dimI(T) = |E|.
Figure 8.1. Tree T.
.......................................................................................................................................................
.......................................................................................................................................................
.......................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. .............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. .............
Figure 8.2. A nonisometric embedding of T into Z2.
Let T be the tree shown in Figure 8.1. A possible embedding of T into
Z2 is shown in Figure 8.2. This embedding is not isometric. An isometric
embedding of T into Z2 is shown in Figure 8.3. Clearly, dimZ(T) = 2, whereas
dimI(T) = 6. Note that 2 is half the number of leaves in T.

8.2 Deﬁning Lattice Dimension
165
t
t
t
t
t
t
t
.............................................................................................................................................................................................................................................................................................................
............................................................................
............................................................................
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
Figure 8.3. An isometric embedding of T into Z2.
The lattice dimension of any tree may be easily calculated:
8.2.8 Theorem. Let T be a ﬁnite tree with m leaves. Then
dimZ(T) = ⌈m/2⌉.
A lower bound of ⌈m/2⌉on dimZ(T) is easily established, as each leaf
must be the unique positive or negative extreme point in some dimension, so
completing the proof merely requires embedding any tree in a lattice of the
stated dimension. For a detailed proof see Hadlock and Hoﬀman (1978), Deza
and Laurent (1997) (Proposition 11.1.4), and Ovchinnikov (2004).
The following lemma can be useful in providing a lower bound on the
dimension of more general media and partial cubes. We omit the proof (see
Problem 8.9).
8.2.9 Lemma. Let G′ be an isometric subgraph of a partial cube G. Then
dimZ(G′) ≤dimZ(G).
8.2.10 Corollary. Suppose a partial cube G has a vertex v of degree d. Then
dimZ(G) ≥⌈d/2⌉.
Proof. The tree T formed by v and its neighbors has d leaves; no two of these
leaves can be adjacent in G since G is bipartite, so T forms an isometric
subgraph of G. The result follows from Theorem 8.2.8 and Lemma 8.2.9.
8.2.11 Example. We now describe a more complicated number-theoretic ex-
ample of a partial cube, involving the partitions of an integer, a well-studied
concept in number theory. As we show, these partitions can be represented as
a partial cube; lattice embedding turns out to be more convenient than set
labeling as a way of proving that the graph we form is a partial cube, and
naive methods suﬃce to estimate the lattice dimension of this partial cube.
8.2.12 Deﬁnition. A partition of a positive integer k is a sequence p0p1p2 . . .
of positive integers, with pi ≥pi+1, summing to k. For instance, there are
seven partitions of the integer 5: 5, 41, 32, 311, 221, 2111, and 11111. For
any k, we may form a graph Pk having the partitions of k as its vertices; two
partitions p0p1p2 . . . and p′
0p′
1p′
2 . . . are adjacent in this graph if there exist
δ ∈{1, −1} and i > 0 such that p0 = p′
0 + δ, pi = p′
i −δ, and pj = p′
j for
j ̸∈{0, i}. Figure 8.4 depicts one such graph, P7.

166
8 Media and Integer Lattices
Figure 8.4. The graph P7 of partitions of the integer 7.
In the result below, we use standard “big theta” notation: f(x) = Θ(g(x))
if and only if both f(x) = O(g(x)) and g(x) = O(f(x)).
8.2.13 Theorem. Pk is a partial cube with dimZ(Pk) = Θ(
√
k).
Proof. To show an upper bound on the dimension, we exhibit an embedding
of Pk into a lattice of dimension 2⌊
√
k⌋and prove that this embedding is
isometric. To do so, deﬁne
qj = |{xi | i >
√
k and pi ≥j}|.
We embed Pk into a lattice by placing a partition p0p1p2 . . . at the lattice
coordinates p1p2 . . . p⌊
√
k⌋q1q2q3 . . . q⌊
√
k⌋. We note that, for j >
√
k, qj = 0,
as any partition of k can have at most
√
k values that are each larger than
√
k, so all such large values occur too early in the sorted sequence of pi to be
included in the deﬁnition of qj.
If P and P ′ are partitions adjacent in Pk, via an adjacency deﬁned by the
pair (δ, i), then P and Q diﬀer only by a single unit in the single coordinate pi
(if i ≤
√
k) or qx where x = max(pi, p′
i) (otherwise). Therefore, the endpoints
of any path of length λ in Pk can be embedded at distance at most λ in the
lattice.
In the other direction, suppose P and P ′ are partitions at distance λ in the
lattice; we prove by induction on λ that P and Q can be connected by a path
of length λ in Pk. As a base case, when λ = 0, P and P ′ must be the same
partition: for, pi for i >
√
k can be recovered by the formula pi = max{j | i ≤
qj + ⌊
√
k⌋}, and p0 can be recovered by the formula p0 = k −
i>0 pi.
To complete the induction for λ > 0, let i = max{j | pj ̸= p′
j}, and
suppose (without loss of generality) that pj > p′
j. Then we ﬁnd a new state
Q adjacent to P in Pk deﬁned by a pair (δ = −1, i). This adjacent Q has
the lattice coordinate pi (if i ≤
√
k) or qpi (otherwise) one step closer to the
coordinates of P ′. By induction, there exists a path of length λ −1 from Q to
P ′, which together with the edge from P to Q forms the desired path.

8.3 Lattice Dimension of Finite Partial Cubes
167
Thus, we have proven that Pk is an isometric subgraph of Z2⌊
√
k⌋, so it is
a partial cube of at most this lattice dimension. To complete the proof, we
must show a matching lower bound on the dimension. Choose n such that
n(n + 1)/2 ≤k, (n + 1)(n + 2)/2 > k; then n =
√
2n + O(1). The triangular
partition
1 + 2 + 3 + · · · + (n −1) + (k −(n(n −1)/2)) = k
has 2n −1 neighbors in P7, so a lower bound dimZ(Pk) ≥n = Ω(
√
k) follows
from Corollary 8.2.10.
8.3 Lattice Dimension of Finite Partial Cubes
In this section we establish a more precise relation between the isometric and
lattice dimensions of a ﬁnite partial cube G. Speciﬁcally, we show that the
diﬀerence between these two dimensions can be counted by the number of
edges in a matching of an auxiliary graph, which we deﬁne below.
8.3.1 Deﬁnition. Let G = (V, E) be a partial cube. Denote by Sc(G) the
semicube graph, a graph the vertices of which are the set of semicubes of G
(see Deﬁnition 7.2.1). Two vertices Wab and Wcd are connected by an edge in
Sc(G) if
Wab ∪Wcd = V
and
Wab ∩Wcd ̸= ∅.
(8.2)
An example of a semicube graph is depicted in Figure 8.5.
A
B
C
D
E
F
G
H
I
J
AD
ABD
EH
ABCD
EFH
ABCD
EFGHI
J
GIJ
CF
GIJ
BCEF
GHIJ
BCG
ABCE
FGIJ
ADEF
HIJ
DH
Figure 8.5. A partial cube (left) and its semicube graph (right). The label of each
vertex in the semicube graph is formed by the letters representing the corresponding
set of partial cube vertices; for instance, the vertex on the lower left of the semicube
graph, labeled BCEFGHIJ, corresponds to the semicube {B, C, E, F, G, H, I, J}.
It is easy to verify that condition (8.2) is equivalent to each of the following
two conditions:
Wba ⊂Wcd
or
Wdc ⊂Wab,
(8.3)

168
8 Media and Integer Lattices
where ⊂stands for the proper inclusion.
Let G be a ﬁnite isometric subgraph of Zd, where d = dimZ(G). The
projection of G into the k’th coordinate axis is a path Pk in Z. Since d is the
lattice dimension of G, the length lk of Pk is a positive number. Thus G is
actually embedded into the complete grid graph
P = P1 × P2 × · · · × Pd,
(8.4)
where × stands for the Cartesian product. It is easy to see that the equivalence
classes of Djokovi´c’s relation θ for the graph G are in one-to-one correspon-
dence with the edges in the paths Pk. By Theorem 7.6.2,
dimI(G) =
d

k=1
lk.
Without loss of generality, we may assume that each Pk is in the form
Pk = (0, 1, . . . , lk).
8.3.2 Deﬁnition. A matching in an undirected graph is a set of edges, no
two of which share any endpoint.
8.3.3 Lemma. Let G be a ﬁnite partial cube which is isometrically embedded
into Zd for some d. Then there exists a (possibly empty) matching M in the
semicube graph Sc(G), such that
d = dimI(G) −|M|.
Proof. It can be easily seen that all semicubes in G are intersections of G with
complete grid graphs P ′
k,j and P ′′
k,j where
P ′
k,j = P1 × · · · × Qj
k × · · · × Pd, P ′′
k,j = P1 × · · · × Rj
k × · · · × Pd,
Qj
k = (0, 1, . . . , j), 0 ≤j < lk, and Rj
k = (j, . . . , lk), 0 < j ≤lk.
We deﬁne Lk,j = P ′
k,j ∩G and Uk,j = P ′′
k,j ∩G. Clearly, Lk,j ∪Uk,j = V and
Lk,j ∩Uk,j ̸= ∅.
Let M be the set of edges in Sc(G) connecting the semicubes Lk,j and Uk,j.
Clearly, the set M is a matching in Sc(G), that is, it is a set of independent
edges. Therefore,
|M| =
d

k=1
(lk −1) = dimI(G) −d.

8.3 Lattice Dimension of Finite Partial Cubes
169
8.3.4 Lemma. If M is a matching in the semicube graph Sc(G) of a ﬁnite
partial cube G, then there exists an isometric embedding of G into Zd, where
d = dimI(G) −|M|.
Proof. Let H be the graph obtained from M by adding an edge between each
pair of opposite semicubes Wab and Wba. Clearly, any vertex of H has a degree
one or two. Suppose that the semicubes Wab and Wcd are connected in M.
The diagram below shows a typical fragment of the graph H.
Wba −→Wab −→Wcd
(8.5)
By (8.3), Wba ⊂Wcd, that is, Wcd is a proper superset of Wba (the orientation
in (8.5) is consistent with this set inclusion). This is also true for alternating
vertices in any path in H, starting at Wba. Hence, H has no cycles and there-
fore is a union of disjoint paths Qk, 1 ≤k ≤d, for some d. There are 2 dimI(G)
semicubes of G, of which 2|M| are matched in M. There are two endpoints
per path Qk, and the set of these endpoints consists of 2 dimI(G) −2|M|
unmatched vertices in Sc(G). Thus, d = dimI(G) −|M|.
Note that each path Qk starts and ends with an edge connecting two
opposite semicubes. Thus, the length lk of each path is an odd number.
Choosing, for each path, an orientation deﬁned by one of the set inclusions
in (8.3) (cf. (8.5)), we number the vertices of Sc(G) so that Sk,i denotes the ith
vertex of path Qk (0 ≤i ≤lk). It is convenient to deﬁne Sk,−1 = Sk,lk+1 = V .
By (8.3), we have the two chains of proper inclusions for vertices in a given
path Qk:
Sk,0 ⊂Sk,2 ⊂· · · ⊂Sk,2x ⊂· · · ⊂Sk,lk−1 ⊂Sk,lk+1 = V,
(8.6)
and
V = Sk,−1 ⊃Sk,1 ⊃· · · ⊃Sk,2x−1 ⊃· · · ⊃Sk,lk−2 ⊃Sk,lk
(8.7)
For a given vertex v ∈V , let Sk,2x be the ﬁrst set in (8.6) containing v.
Let us deﬁne λk(v) = x. Then
λ(v) = (λ1(v), . . . , λd(v))
maps V into Zd. It remains to verify that λ deﬁnes an isometric embedding
of G into Zd.
Note that if v ∈Sk,2x, where x = λk(v), then v ∈Sk,2x−1. Indeed, other-
wise, we would have v ∈Sk,2x−2, since Sk,2x−2∪Sk,2x−1 = V . This contradicts
the deﬁnition of λk(v). A similar argument shows that v /∈Sk,2x+1. Thus λk(v)
can be equivalently deﬁned as a unique number x such that v ∈Sk,2x∩Sk,2x−1.
Let u, v ∈V . Any semicube S that separates u and v in G (that is, either
u ∈S, v /∈S or u /∈S, v ∈S) belongs to a single path, say, Qk. The number
of semicubes in the form Sk,2x that separate u and v is |λk(u) −λk(v)|. It is

170
8 Media and Integer Lattices
the same number for semicubes in the form Sk,2x−1 (cf. (8.7)). Therefore, the
total number of semicubes in G separating u and v is 2 
k |λk(u) −λk(v)|,
which is twice the distance between λ(u) and λ(v) in Zd. On the other hand,
if an edge {a, b} belongs to a shortest path connecting vertices u and v, then
semicubes Wab and Wba separate u and v and any semicube separating u and
v is in one of these forms. Hence, the number of semicubes separating u and
v is twice the distance between vertices u and v in G. We proved that
δZd(λ(u), λ(v)) = δG(u, v).
Thus, λ is an isometric embedding of G into Zd.
Lemmas 8.3.3 and 8.3.4 together yield the following theorem:
8.3.5 Theorem. For any ﬁnite partial cube G,
dimZ(G) = dimI(G) −|M|,
where M is a maximum matching in the semicube graph Sc(G).
A
B
C
D
E
F
G
H
I
J
AD
ABD
EH
ABCD
EFH
ABCD
EFGHI
J
GIJ
CF
GIJ
BCEF
GHIJ
BCG
ABCE
FGIJ
ADEF
HIJ
DH
Figure 8.6. A matching in the semicube graph of Figure 8.5, and the corresponding
embedding of a partial cube into Z2, from Eppstein (2005b).
Figure 8.6 shows a maximum matching in the semicube graph for the
example from Figure 8.5, and the corresponding minimum dimension lattice
embedding of the partial cube from that ﬁgure.
8.3.6 Remark. Figure 8.3 shows an isometric embedding of the tree T into a
(4×2)-grid. The same tree is isometrically embedded into a (3×3)-grid in Fig-
ure 8.7. Although the grid P in (8.4) is not uniquely deﬁned by a partial cube
G, as these two ﬁgures show, the set L = {l1, · · · , ld}, where d = dimZ(G),
determines both the lattice and isometric dimensions of G. Namely,
dimZ(G) = |L|
and
dimI(G) = l1 + · · · + ld.

8.4 Lattice Dimension of Inﬁnite Partial Cubes
171
t
t
t
t
t
t
t
.............................................................................................................................................................................................................................................................................................................
............................................................................
............................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
Figure 8.7. Another isometric embedding of T into Z2.
8.4 Lattice Dimension of Inﬁnite Partial Cubes
We may characterize the lattice dimension of inﬁnite partial cubes by their
ﬁnite isometric subgraphs. First, we establish some auxiliary results.
Let G = (V, E) be a connected graph. For v0 ∈V and any ﬁnite integer k
we set
Nk(v0) = {v ∈V
δ(v, v0) ≤k}
and call this set the ball of radius k and center v0. It is clear that N0(v0) = {v0}
and Ni(v0) ⊆Ni+1(v0).
8.4.1 Lemma. If the ball Nk(v0) is inﬁnite, then there is a vertex in this ball
of inﬁnite degree.
Proof. Since N0(v0) is ﬁnite and Nk(v0) is inﬁnite, there is i such that Ni(v0)
is ﬁnite and Ni+1(v0) is inﬁnite. It suﬃces to note that any vertex in Ni+1(v0)
is adjacent to a vertex in Ni(v0).
The convex hull of a set X ⊆V is the intersection of all convex subsets
of V containing X. The following lemma recasts a result from Kuzmin and
Ovchinnikov (1975) in the terms of this chapter.
8.4.2 Lemma. Let G be a partial cube. The convex hull of any ﬁnite set of
vertices of G is a ﬁnite set.
Proof. We may assume that G = (F, WF) for a wg-family of ﬁnite subsets of
some set X. Let P ⊂F be ﬁnite. By Theorem 3.4.5(ii), the set
{R ∈F
∩P ⊆R ⊆∪P}
is convex. Clearly, it is ﬁnite and contains P. The result follows.
Note that, in general, the result of Lemma 8.4.2 does not hold for an
inﬁnite bipartite graph which is not a partial cube (cf. Problem 8.3).

172
8 Media and Integer Lattices
8.4.3 Theorem. For a partial cube G and any integer k, dimZ(G) ≤k if and
only if dimZ(G′) ≤k for all ﬁnite isometric subgraphs G′ of G. If dimZ(G) is
inﬁnite, then dimZ(G) = dimI(G).
Proof. For the ﬁrst claim of the theorem, it suﬃces to prove that, if all ﬁnite
isometric subgraphs G′ can be embedded into Zd, then so can G itself. Let
v0 be a ﬁxed vertex of G. Then if the ball Ni(v0) were inﬁnite, Lemma 8.4.1
would allow us to ﬁnd isometric subtrees of G consisting of a single vertex
with 2d + 2 neighbors. By Theorem 8.2.8 these would have dimension d + 1.
But this contradicts the assumption that all isometric subgraphs of G have
dimension at most d; this contradiction proves the ﬁniteness of the ball Ni(v0).
As all balls Ni(v0) are ﬁnite, Lemma 8.4.2 implies that the convex hulls Gi of
these balls are also ﬁnite. These convex hulls form a nested sequence
G0 = {v0} ⊆G1 ⊆· · · ⊆Gi ⊆· · ·
of ﬁnite isometric subgraphs such that ∪iGi = G.
Form a tree L, the vertices of which are embeddings of Gi into Zd such
that v0 is placed at the origin. The parent of a vertex corresponding to an
embedding f : Gi →Zd is the embedding of Gi−1 formed by restricting f to
the vertices of Gi−1. L is inﬁnite if G is inﬁnite, but each vertex has ﬁnitely
many children, so by K¨onig’s Inﬁnity Lemma (Diestel, 2000) it has an inﬁnite
path. Any two embeddings of this path that both place the same vertex v
of G must place v at the same lattice point as each other, and every vertex
of G is placed by all but ﬁnitely many embeddings of the path, so we can
derive from this path a consistent embedding of all vertices of G into Zd. This
embedding is isometric, as any path in G can be covered by some subgraph
Gi for suﬃciently large i.
It remains to prove the case of the theorem in which dim Z(G) is inﬁnite.
By Corollary 8.2.6, dimI(G) ≥dimZ(G). Consider an isometric embedding
of G into Z(X), where |X| = dimZ(G). Composing this embedding with the
embedding of Theorem 8.2.2 from Z(X) into H(X × Z),
dimI(G) ≤|X × Z| = |X| = dimZ(G)
and the result follows.
8.5 Oriented Media
In the case of oriented ﬁnite media, it is natural to desire an integer lattice
embedding that respects the orientation.
8.5.1 Deﬁnition. Let M be a ﬁnite oriented medium endowed with the orien-
tation {T+, T−}. Then, an oriented embedding of M is an isometric embedding
of its underlying unoriented medium into Zd for some d, with the property

8.5 Oriented Media
173
that, for each state S and positive token τ ∈T+, Sτ is placed at a point with
coordinate values greater than or equal to those of S. The oriented lattice
dimension dimZ+(M) is the minimum dimension of a lattice Zd in which M is
orientally embeddable.
t
t
t
t
.................................................................................................................................................... ...........
.................................................................................................................................................... ...........
.................................................................................................................................................... ...........
S
T
U
V
τ1
τ2
τ3
Figure 8.8. A medium on four states embedded in Z.
Consider, for instance, the medium in Figure 8.8 with orientation deﬁned
by T+ = {τ1, ˜τ2, τ3}. It is clear that with this orientation the medium in
Figure 8.8 is not embeddable into Z; however it has an oriented embedding
into Z2. Thus, its oriented lattice dimension is 2.
As it turns out, the same idea of ﬁnding matchings in an associated
semicube graph can be used to compute the oriented lattice dimension.
8.5.2 Deﬁnition. We deﬁne oriented semicube graph Sc+(M) of an oriented
medium M with orientation {T+, T−} the be a graph having all semicubes of
M as the set of its vertices. Two vertices Sτ and Sτ ′ are connected in Sc+(M),
where τ ∈T+ and τ ′ ∈T−, if Sτ ∪Sτ ′ = S and Sτ ∩Sτ ′ ̸= ∅.
The oriented semicube graph can equivalently be seen as the subgraph of
the semicube graph Sc(M) in which we keep only edges between semicubes
Sτ and Sτ ′ for pairs τ and τ ′ that are oppositely oriented (see Figure 8.9).
A
B
C
D
E
F
G
H
I
J
AD
ABD
EH
ABCD
EFH
ABCD
EFGHI
J
GIJ
CF
GIJ
BCEF
GHIJ
BCG
ABCE
FGIJ
ADEF
HIJ
DH
Figure 8.9. The oriented semicube graph of an oriented partial cube (cf. Figure 8.5).
8.5.3 Lemma. Let M be a ﬁnite oriented medium which is orientally embed-
ded into Zd for some d. Then there exists a (possibly empty) matching M in
the oriented semicube graph Sc+(M), such that
d = dimZ+(M) −|M|.

174
8 Media and Integer Lattices
Proof. As in the proof of Lemma 8.3.3, we observe that all semicubes of M
can be represented geometrically as intersections with complete grid graphs
Lk,j and Uk,j, and let M be the set of edges in Sc+(M) connecting semicubes
Lk,j and Uk,j. It follows from the orientation of the embedding of M that each
such edge connects semicubes Sτ and Sτ ′ for pairs τ and τ ′ that are oppositely
oriented. The equality of d with dimZ+(M) −|M| follows in the same manner
as in the proof of Lemma 8.3.3.
8.5.4 Lemma. If M is a matching in the oriented semicube graph Sc+(M)
of a ﬁnite oriented medium M, then there exists an oriented embedding of M
into Zd, where
d = dimI(G) −|M|.
Proof. Since Sc+(M) is a subgraph of Sc(M), M is also a matching in Sc(M),
and we can use Lemma 8.3.4 to construct an isometric embedding of M from
it. It follows from the deﬁnition of Sc+(M) and the construction of the em-
bedding in the proof of that lemma that the sequence of tokens along each
coordinate dimension of the resulting embedding have a consistent orienta-
tion. By negating the coordinates in which this orientation is negative, we
construct an oriented embedding of M.
Lemmas 8.5.3 and 8.5.4 together yield the following theorem.
8.5.5 Theorem.
dimZ+(M) = dimI(M) −|M|,
for any ﬁnite oriented medium M, where M is a maximum matching in the
oriented semicube graph Sc+(M).
As in the unoriented case, we may extend the deﬁnition of oriented lattice
dimension to inﬁnite oriented media by taking the maximum dimension of
any ﬁnite submedium of M; we omit the details.
Problems
8.1 Let G be the graph shown below. Find dimI(G), dimZ(G), and ℓa(G).

Problems for Chapter 8
175
8.2 Let Cn be a cycle of length n.
(i) Prove that Cn is a partial cube if and only if n is even (cf. Problems 7.3
and 7.4 in Chapter 7).
(ii) Prove that dimI(C2n) = dimZ(C2n) = n.
(iii) If a cycle Cn is an isometric subgraph of a partial cube G, show that
n ≤2 dimZ(G).
8.3 Let A and B be two disjoint sets. We denote KA,B the complete bipartite
graph on the set of vertices A + B. Show that the result of Lemma 8.4.2 does
not hold for an inﬁnite bipartite graph KA,B.
8.4 Prove that the three conditions in Equations (8.2) and (8.3) are equiva-
lent.
8.5 Let G be a partial cube and {Wab, Wxy}, {Wba, Wuv} be two edges in
the semicube graph Sc(G). Prove that {Wxy, Wuv} is an edge in Sc(G).
8.6 Describe the graph Sc(Cn) where Cn is the cycle of length n.
8.7 What is the semicube graph of the cube H(X)?
8.8 Prove Theorem 8.2.8. (Hint: Use Theorem 8.3.5.)
8.9 Prove Lemma 8.2.9.
8.10 Let P be a path of length d and G = P n be the complete grid
P × · · · × P



n factors
. Show that limn→∞
ℓa(G)
n
= d(d + 2)
3(d + 1) (cf. Problem 7.14 in Chap-
ter 7).
8.11 Let T be a rooted tree with ℓleaves, viewed as an oriented medium.
Show that dimZ+(T) = ℓ.
8.12 Find the oriented lattice dimension of the graph shown in Figure 1.5.
8.13 Let G be the graph shown in Figure 2.1.
(i) Find the lattice dimension dimZ(G).
(ii) Find the oriented lattice dimension dimZ+(G) for the orientation given
by F+ = {τ1, τ3, τ6}.
8.14 Prove that, for any oriented medium M,
dimZ(M) ≤dimZ+(M) ≤2 dimZ(M).

9
Hyperplane arrangements and their media
Hyperplane arrangements in a ﬁnite dimensional vector space, as illustrated by
Example 1.2.1, are a rich and useful source of media examples. We prove that
the ‘regions’ of a hyperplane arrangements deﬁne a medium, give examples
of such media, and compute their isometric and lattice dimensions. Then we
apply geometric techniques to show that families of ‘labeled interval orders’
and weak orders can be cast as media. This part of the chapter supplements
the results presented in Chapter 5.
9.1 Hyperplane Arrangements and Their Media
We begin with general deﬁnitions and facts about hyperplane arrangements.
For details and proofs, the reader is referred to Bj¨orner et al. (1999); Bourbaki
(2002); Gr¨unbaum (1972); Orlik and Terano (1992); Stanley (1996); Zaslavsky
(1975); Ziegler (1995). In our presentation we follow Ovchinnikov (2005, 2006).
9.1.1 Deﬁnition. An arrangement A of hyperplanes is a locally ﬁnite family
A = {Hi}i∈J of aﬃne hyperplanes in Rn, that is, any open ball in Rn intersects
only a ﬁnite number of hyperplanes in A. We say that an arrangement is
ﬁnite if it has only ﬁnitely many hyperplanes. A central arrangement is an
arrangement of hyperplanes all of which contain the origin.
9.1.2 Remark. A central arrangement is necessarily ﬁnite. There are at most
countably many hyperplanes in any arrangement A, so the index set J is
either ﬁnite or countable. Every hyperplane can be represented (though not
in a unique way) by an aﬃne linear function li(x) = n
j=1 aijxj + bi, that is,
Hi = {x ∈Rn li(x) = 0}.
We assume a ﬁxed choice of representation for each hyperplane and refer to

178
9 Hyperplane arrangements and their media
H+
i = {x ∈Rn li(x) > 0}
and
H−
i = {x ∈Rn li(x) < 0},
as the open half-spaces separated by Hi.
The hyperplane arrangement A partitions Rn into subsets called ‘cells’. It
is convenient to deﬁne cells in terms of their sign vectors.
9.1.3 Deﬁnition. Given an arrangement A in Rn, we associate to every point
x ∈Rn its sign vector (function) X(x) deﬁned by
X(x) : J →{+, −, 0}J : i →Xi(x) =
⎧
⎪
⎨
⎪
⎩
+
if x ∈H+
i ,
−
if x ∈H−
i ,
0
if x ∈Hi.
The set of all points x ∈Rn having the same sign vector is called a cell in
the partition of Rn deﬁned by A. Each cell is convex and open relative to the
aﬃne subspace spanned by the cell. The dimension of a cell is the number of
nonzeros in its sign vector. The n-dimensional cells are called regions of A.
9.1.4 Deﬁnition. A hyperplane Hi ∈A separates regions P and Q if P ⊆
H+
i and Q ⊆H−
i , or P ⊆H−
i and Q ⊆H+
i . Equivalently, Hi separates regions
P and Q if the sign vectors for P and Q diﬀer only in their ith coordinate.
Two regions P and Q are adjacent if there is a unique hyperplane Hi in A
separating them.
9.1.5 Deﬁnition. The region graph G of an arrangement A has the set P of
regions as the set of vertices. The set of edges of G consists of all the pairs
{P, Q} of adjacent regions in P.
,
,,
,,,
,9
Figure 9.1. The Boolean arrangement B2 and its region graph.
9.1.6 Example. Let A be the arrangement of two coordinate lines in the
plane shown in Figure 9.1. The regions (2-dimensional cells) of A are the
quadrants I–IV. The four 1-dimensional cells are the positive and negative
parts of the coordinate lines. The only 0-dimensional cell is the point (0, 0).
The graph of this arrangement is the cycle C4 (cf. Deﬁnition 9.1.12 below).

9.1 Hyperplane Arrangements and Their Media
179
We now construct a token system (P, T) representing the regions and ad-
jacencies of an arrangement (cf. Example 1.2.1).
9.1.7 Deﬁnition. Let A = {Hi}i∈J be a hyperplane arrangement. We deﬁne
the token system (P, T) associated with A. The set P of states is the collection
of regions of A. We deﬁne the set T of tokens to be the union ∪i∈J{τ −
i , τ +
i },
with, for every i ∈J, the two functions τ −
i
and τ +
i
deﬁned by
τ +
i : P →P : P →Pτ +
i =

Q
if P ⊂H−
i , Q ⊂H+
i , with P, Q adjacent,
P
otherwise;
τ −
i : P →P : P →Pτ −
i =

Q
if P ⊂H+
i , Q ⊂H−
i , with P, Q adjacent,
P
otherwise.
It is easily veriﬁed that τ +
i and τ −
i are genuine tokens (well-deﬁned functions,
distinct from the identity on P), and mutual reverses (Problem 9.1).
The following theorem is the main result of this section.
9.1.8 Theorem. Let A = {Hi}i∈J be a hyperplane arrangement in Rn. The
token system (P, T) of Deﬁnition 9.1.7 is a medium.
Proof. We show that axioms [Ma] and [Mb] deﬁning a medium are satisﬁed.
[Ma]. To ﬁnd a concise message transforming a state S into another state
V , let s and v be points chosen within regions S and V , so that line segment
sv does not pass through any cell of the arrangement of dimension lower than
n −1. This is always possible, for if we ﬁx s to be any point in S, then the
union of all line segments connecting s with points in V and passing through
cells of dimension less than n −1 has dimension less than n. Let the sequence
of arrangement hyperplanes intersected by line segment sv be H1, . . . Hk, with
each Hi in this sequence separating points s and v. This sequence is ﬁnite,
since A is locally ﬁnite; clearly, all the hyperplanes in the sequence are distinct.
For 1 ≤i ≤k, we deﬁne
τi =

τ −
i
if s ∈H−
i , v ∈H+
i ,
τ +
i
if s ∈H+
i , v ∈H−
i .
Then τ1 . . . τk is a concise message transforming S into V . Therefore, Axiom
[Ma] is satisﬁed.
[Mb]. Suppose that a message m = τ1 . . . τk is stepwise eﬀective for some
state S and ineﬀective for that state, so S = Sm. We need to show that m
is vacuous. Let si be a point in Si = Sτ0 . . . τi for 0 ≤i < k and sk = s0.
We connect successive points si’s by directed line segments to obtain a closed
oriented piecewise linear curve C in Rn. Each directed line segment in C
intersects a single hyperplane H ∈A and corresponds to a unique token τ in
C(m). The next occurrence of a line segment in C intersecting H corresponds

180
9 Hyperplane arrangements and their media
to the reverse token ˜τ ∈C(m). Since C is closed, there are even number of
line segments intersecting H, equally many in each direction. Thus, we can
partition the tokens in m into pairs of mutually reverse tokens, so [Mb] is
satisﬁed.
As the two axioms hold, (P, T) is a medium.
The region graph G of an arrangement A represents the medium (P, T)
via Deﬁnitions 6.1.1 and 9.1.7. In view of Theorem 7.1.7, Theorem 9.1.8 can
be reformulated as follows.
9.1.9 Theorem. The region graph of a hyperplane arrangement is a partial
cube.
9.1.10 Remark. The same proof goes through, essentially unchanged, to
show that hyperplane arrangements restricted to a convex subset of Rn sim-
ilarly form media and partial cube region graphs (Ovchinnikov, 2005). For
example, Figure 9.2 shows an arrangement of three lines in the plane, re-
stricted to the convex subset bounded by an ellipse, that provides a geometric
realization of the medium shown earlier in Figure 2.1.
Figure 9.2. An arrangement of three lines (shown dashed), restricted to the shaded
ellipse, produces a medium isomorphic to the one in Figure 2.1.
9.1.11 Remark. The region graph G of a ﬁnite arrangement A = {Hi}i∈J
is the tope graph of the oriented matroid associated with the arrangement A
(see Handa, 1990; Bj¨orner et al., 1999). It is known that these graphs form iso-
metric subgraphs of hypercubes; for instance, see Proposition 4.2.3 in Bj¨orner
et al. (1999) or Theorem 28 of G¨artner and Welzl (1994). Theorem 9.1.9 ex-
tends this result to inﬁnite arrangements.
Particularly important classes of ﬁnite hyperplane arrangements in Rn
are introduced below. We give examples of inﬁnite arrangements later in this
section.

9.1 Hyperplane Arrangements and Their Media
181
9.1.12 Deﬁnition. The Boolean arrangement Bn is the central arrangement
of the coordinate hyperplanes in Rn deﬁned by the linear functions li(x) = xi
(cf. Example 4.3.4).
The central arrangement of all the hyperplanes in Rn that are deﬁned by
the linear functions lij(x) = xi −xj for i < j is called the braid arrangement
Bn (also known as the Coxeter arrangement).
For d = (d1, . . . , dn) with di > 0, the deformation An,d of the braid ar-
rangement Bn is deﬁned by the aﬃne linear functions
lij = xi −xj −dj,
for i ̸= j.
(9.1)
The next three examples illustrate these deﬁnitions.
9.1.13 Example. The region graph of the Boolean arrangement B2 is shown
in Figure 9.1. In general, the region graph of Bn is the cube on the set
{1, . . . , n}.
Figure 9.3. Left: The braid arrangement B3 and its region graph, a cycle C6. Right:
an isometric embedding of C6 into the cube.
9.1.14 Example. The region graph of the braid arrangement B3 is shown
in Figure 9.3 (left). The three dashed lines are intersections of the planes in
R3 deﬁning the braid arrangement B3 with the plane x1 + x2 + x3 = 0. The
region graph of B3 is the cycle C6 which is the graph of the permutohedron Π2
(cf. Figure 3.1). Its isometric embedding into the cube is shown in Figure 9.3
(right).
9.1.15 Example. Let d = (1, 1, 1). The region graph of the deformation A3,d
of the braid arrangement B3 is shown in Figure 9.4. Again, the dashed lines
are intersections of the planes in R3 deﬁning the arrangement A3,d with the
plane x1 + x2 + x3 = 0. By Theorem 9.1.9, this graph is a partial cube (cf.
Figure 1.5). Thus, this geometric method can provide an alternative proof of
Theorem 5.5.7 (see Corollary 9.3.4).

182
9 Hyperplane arrangements and their media
Figure 9.4. The region graph of A3,d.
Figure 9.5. The acyclic orientations of the graph C4; two orientations are connected
by an edge when they diﬀer by a single edge ﬂip.
9.1.16 Example. (cf. Orlik and Terano, 1992, p.57.) We now discuss a graph-
theoretic token system which can be easily proven to be a medium by repre-
senting it as an arrangement. Consider any directed acyclic graph D. Then,
if one reverses any edge of the transitive reduction of D (the Hasse diagram
of the partial order represented by D), the result is again a directed acyclic
graph. However, reversing an edge that is not part of the transitive reduction
forms a cycle, leading to a directed graph that is not acyclic. This suggests
a token system in which the states are directed acyclic graphs and the trans-
formations are acyclicity-preserving edge reversals. For instance, Figure 9.5
shows fourteen directed acyclic graphs, the directed acyclic orientations of a
square, with two graphs connected by an edge in the drawing whenever they
diﬀer in the orientation of a single edge.

9.1 Hyperplane Arrangements and Their Media
183
9.1.17 Deﬁnition. Let G be an undirected graph. Then an acyclic orienta-
tion of G is a directed acyclic graph formed by assigning a direction to each
edge of G. We construct from G a token system (P, T), where P consists of
the set of all acyclic orientations of G. T contains two tokens for each edge of
G, one token for each assignment of a direction to each edge. If τ is the token
corresponding to the direction (a, b) on edge {a, b}, then the action of τ on an
acyclic orientation S is to reverse edge (b, a), if (b, a) is a directed edge of the
state S and if the result of reversing that edge is another acyclic orientation;
otherwise τ leaves S unchanged.
9.1.18 Theorem. The token system (P, T) deﬁned from the acyclic orien-
tations of a ﬁnite graph G with n vertices is isomorphic to a token system
deﬁned from a subarrangement of the braid arrangement Bn.
Proof. Associate each vertex of G with the index of one of the coordinates
in a Cartesian coordinate system for Rn. Let A be the arrangement of hy-
perplanes xi = xj, for each pair {i, j} forming an edge of G; that is, A is a
subarrangement of the braid arrangement Bn. If x is a point in a region of
A, we may ﬁnd an orientation of G from x by orienting an edge {i, j} from
xi to xj whenever xi > xj, and from xj to xi otherwise; note that, since x is
in one of the regions, xi cannot equal xj. It is easy to see that this orienta-
tion does not depend on the choice of x within its region, so in this way we
can associate regions of A with acyclic orientations of G, in such a way that
adjacent regions correspond to orientations that diﬀer in the orientation of a
single edge.
We leave it to the reader to show that this association indeed deﬁnes an
isomorphism between the two token systems (see Problem 9.2).
Thus, for example, the token system shown in Figure 9.5 can be repre-
sented by an arrangement in which four hyperplanes, corresponding to the
four edges of the square, lie in a space of four dimensions corresponding to
the four vertices of the square. Stanley (1996) calls the arrangement A formed
from G in the proof above a graphical arrangement.
9.1.19 Corollary. The token system of acyclic orientations of any ﬁnite undi-
rected graph forms a medium.
9.1.20 Remark. The family of strict linear orderings of a ﬁnite set is isomor-
phic to the family of acyclic orientations of a complete graph. Thus, Theo-
rem 9.1.18 can be viewed as a geometric generalization of the result that the
strict linear orders of a ﬁnite set form a medium, a result that we generalized
in a diﬀerent way, to linear orders of inﬁnite sets, in Theorem 3.5.6.
9.1.21 Remark. Not all partial cubes are the region graphs of hyperplane
arrangements. For instance, the graph of the medium shown in Figure 2.1 is
not the region graph of any hyperplane arrangement in Rn for any n (cf. Prob-
lem 9.4).

184
9 Hyperplane arrangements and their media
Figure 9.6. Fragments of two inﬁnite line arrangements and their region graphs.
We conclude this section with two examples of inﬁnite arrangements and
their graphs.
9.1.22 Examples. In each of the drawings of Figure 9.6, an inﬁnite arrange-
ment of parallel lines is depicted by dashed lines. The corresponding region
graphs are 1-skeletons of tilings of the plane by squares (left) and hexagons
(right).
9.2 The Lattice Dimension of an Arrangement
Media derived from arrangements have many attractive combinatorial and
geometric properties which make some tasks simpler than in the general case
of media. To exemplify this statement, we compute in this section the lattice
dimension (cf. Deﬁnition 8.2.5) of the region graph of an arrangement A.
Let G be the region graph of arrangement A. By Corollary 7.6.3, the
isometric dimension (cf. Deﬁnition 7.6.1) of the graph G is equal to the car-
dinality of the set A, that is, dimI(G) = |A|. Therefore, by Theorem 8.3.5,
in order to evaluate dimZ(G), we need to ﬁnd the cardinality of a maximum
matching M in the semicube graph Sc(G).
9.2.1 Lemma. The semicubes in the region graph G of an arrangement A
are the sets of all regions that lie on one side of hyperplanes in A.
Proof. Let P and Q be two adjacent regions and H be the unique hyperplane
in A that separates these regions. Let R be a region that lies on the same
side of H as P. Any hyperplane that separates R and P is diﬀerent from H.
Therefore, it separates regions R and Q, since H is the only hyperplane in A
separating P and Q. The distance between two regions is equal to the number
of hyperplanes in A separating these two regions (see Problem 9.5). It follows
that δ(R, P) < δ(R, Q). Similarly, δ(R, Q) < δ(R, P), if the regions R and Q
lie on the same side of H. Hence the semicube WP Q consists of all regions
lying on the same side of H as P.

9.2 The Lattice Dimension of an Arrangement
185
Thus, the semicubes in G can be identiﬁed with half-spaces deﬁned by the
hyperplanes in A.
9.2.2 Lemma. Let A be a ﬁnite arrangement of parallel hyperplanes in Rn,
G be its region graph, and M be a maximum matching in Sc(G). Then
|M| = |A| −1.
Proof. As we indicated before, dimI G = |A|. Clearly, G is a path. Hence,
dimZ(G) = 1. We have
|M| = dimI(G) −dimZ(G) = |A| −1,
by Theorem 8.3.5.
9.2.3 Theorem. Let A = A1 ∪· · · ∪Am be a union of hyperplane arrange-
ments in Rn such that hyperplanes in each Ai are parallel and hyperplanes
in distinct Ai’s are not parallel. Let G be the region graph of A. Then
dimZ(G) = m.
Proof. By Theorem 8.4.3, we need only consider ﬁnite isometric subgraphs
of G; any such subgraph can be viewed as part of the arrangement of a ﬁnite
subset of A, so we need only consider the case in which each Ai is ﬁnite. By
Deﬁnition 8.3.1, two semicubes are connected by an edge in Sc(G) if they
have a nonempty intersection and their union is the set of all regions of A.
By Lemma 9.2.1, if two hyperplanes in A are not parallel, the four semicubes
deﬁned by these hyperplanes are not mutually adjacent in Sc(G). Therefore,
any matching in Sc(G) consists of edges connecting semicubes deﬁned by
parallel hyperplanes in A. Let M be a maximum matching in Sc(G). By
Lemma 9.2.2,
|M| =
m

i=1
(|Ai| −1) = |A| −m.
By Theorem 8.3.5,
dimZ(G) = dimI(G) −|M| = |A| −(|A| −m) = m.
As hyperplanes in a central arrangement cannot be parallel, the result can
be simpliﬁed for that case.
9.2.4 Corollary. If A is a central arrangement and G is its region graph,
then
dimI(G) = dimZ(G) = |A|.
9.2.5 Example. Let G be the graph of the arrangement shown in Figure 9.7.
This arrangement consists of three pairs of parallel planes. Thus, dimI(G) = 6
and dimZ(G) = 3. The embedding of G into Z3 is shown in Figure 9.8. Clearly,
G cannot be isometrically embedded into the 2-dimensional integer lattice.

186
9 Hyperplane arrangements and their media
Figure 9.7. A hyperplane arrangement consisting of three pairs of parallel planes.
Figure 9.8. The region graph of the arrangement from Figure 9.7.
9.3 Labeled Interval Orders
In this section we show that the family of all labeled interval orders on a
ﬁnite set is well-graded. Our presentation follows Ovchinnikov (2005), where
a similar result is established for a wide class of families of partial orders.
Stanley (1996) introduced labeled interval orders as a generalization of
semiorders. We deﬁne these relations as follows.
9.3.1 Deﬁnition. Let ρ be a positive function on a ﬁnite set X. (We may
refer to ρ as a length function or threshold.) A binary relation R on X is a
ρ-labeled interval order if there exists a real-valued function f on X such that
aRb
⇔
f(a) > f(b) + ρ(b),
(9.2)
for all a, b ∈X. Any function f deﬁning the relation R by (9.2) is said to be
a representing function for R.
We denote by IOρ the family of ρ-labeled interval orders on X. If ρ is a
constant function, then (9.2) deﬁnes a semiorder on X (cf. (5.29)). The family
of all semiorders on X is denoted SO.
Let V = RX be the n-dimensional vector space of all real-valued functions
on X. Any function f in V deﬁnes a labeled interval order R by (9.2). Let
J = (X × X) \ {(x, x)}x∈X. For ab ∈J, we deﬁne aﬃne linear functions lab on
V by

9.3 Labeled Interval Orders
187
lab(f) = f(a) −f(b) −ρ(b),
and hyperplanes Hab by
Hab = {f ∈V
lab(f) = 0}.
Note that all hyperplanes Hab are distinct. They form a hyperplane arrange-
ment A which is the deformation An,ρ (see Deﬁnition 9.1.12) of the braid
arrangement Bn in V . Corresponding half-spaces, H+
ab and H−
ab, are deﬁned
by
H+
ab = {f ∈V
f(a) > f(b) + ρ(b)}
and
H−
ab = {f ∈V
f(a) < f(b) + ρ(b)},
respectively.
For a given region P of A, we deﬁne
JP = {ab ∈J P ⊆H+
ab}.
Since P is a region, P ⊆H+
ab or P ⊆H−
ab for any ab ∈J. It follows that all
functions in P represent the same labeled interval order R as deﬁned by (9.2).
Clearly, R = JP , that is, J = {JP P ∈P} ⊆IOρ. In other words, J is a family
of labeled interval orders which are representable by functions from regions of
the arrangement A.
To prove that J = IOρ, we need to show that for any function representing
a given labeled interval order there is a function in a region of A representing
the same order.
9.3.2 Lemma. Let R be a labeled interval order and f be its representing
function. There is a function g representing R such that g ∈V \ ∪ab∈JHab.
Proof. Suppose ﬁrst R = ∅. Then, for any function f representing R, we have,
by (9.2), f(x) ≤f(y) + ρ(y) for all x, y ∈X. Let us deﬁne
g(x) = λ = max{f(y) y ∈X},
for all x ∈X.
Clearly, g represents the empty relation and does not belong to any of hyper-
planes in the form Hab.
Let R ∈IOρ, R ̸= ∅, and let f be a function representing R. Let δ be a
number satisfying inequalities
max
xy∈R

ρ(y)
f(x) −f(y)

< δ < 1,
(9.3)
and let g = δf. We show ﬁrst that g represents R.
Suppose that ab ∈R. then
g(a) −g(b) −ρ(b) = δ[f(a) −f(b)] −ρ(b) > 0,

188
9 Hyperplane arrangements and their media
by the ﬁrst inequality in (9.3). On the other hand, if
g(a) > g(b) + ρ(b)
for some a, b ∈X, then f(a) > f(b) and
0 < g(a) −g(b) −ρ(b) = δ[f(a) −f(b)] −ρ(b)
< f(a) −f(b) −ρ(b),
by the second inequality in (9.3). Hence, ab ∈R. This shows that g represents
the relation R.
Suppose g ∈Hab for some ab ∈J, that is, that g(a) = g(b) + ρ(b), or,
equivalently, δ[f(a) −f(b)] = ρ(b). Since δ < 1, we have
f(a) −f(b) > ρ(b),
that is, ab ∈R. Since g represents R, we have g(a) > g(b) + ρ(b), a contradic-
tion. Therefore, g ∈V \ ∪ab∈JHab.
We proved that IOρ = J. The next result follows immediately from Theo-
rem 9.1.8.
9.3.3 Theorem. The family IOρ of labeled interval orders on X is well-
graded. The representing token system (IOρ, WIOρ) is a medium.
As a corollary we have a result of Doignon and Falmagne (1997) (see also
Theorem 5.5.7):
9.3.4 Corollary. The family SO of semiorders on X is well-graded.
Finally, note, that there are n(n −1) hyperplanes in the arrangement
A = An,ρ and n(n−1)
2
pairs of parallel hyperplanes in this arrangement. By
Theorem 9.2.3,
dimI(IOρ) = n(n −1)
and
dimZ(IOρ) = n(n −1)
2
.
9.4 Weak Orders and Cubical Complexes
A (strict) weak order on a set X is a 1-connected, asymmetric binary relation
on X (cf. (1.10) and the equivalent Deﬁnition 5.1.1). The following theorem is a
well-known result from representational measurement theory (see Theorem 3.1
in Roberts, 1979).
9.4.1 Theorem. A binary relation R on a ﬁnite set X is a weak order if and
only if there exists a function f : X →R such that
aRb
⇔
f(a) > f(b),
(9.4)
for all a, b ∈X.

9.4 Weak Orders and Cubical Complexes
189
Any function f deﬁning the relation R by (9.4) is said to be a representing
function for R. The family of weak orders on a given ﬁnite set X is denoted
by WO. This family is ordered by the inclusion relation and we often treat it
as a partially ordered set.
9.4.2 Example. Let X = {a, b, c}. There are 13 weak orders on X; they are
represented by vertices of the diagram shown in Figure 9.9 (cf. Figure 2 in
Kemeny and Snell, 1972). In this diagram, for instance, a ∼b ≺c denotes the
weak order R = {ca, cb}, which is representable by any function f such that
f(a) = f(b) < f(c).
The empty weak order ∅is denoted by a ∼b ∼c and representable by
constant functions. The diagram in Figure 9.9 is the Hasse diagram of the
partial order WO.
The family WO shown in Figure 9.9 is not well-graded. Indeed, the distance
between the weak order R = {ca, cb} and the empty weak order ∅is 2,
but there is no weak order diﬀerent from R and ∅that lies between them.
Nevertheless, it is possible to model in a natural way the family of weak orders
on a ﬁnite set X by a wg-family of sets. In fact, the diagram in Figure 9.9
gives a hint, as it has an obvious cubical structure.
To realize this approach we introduce two useful descriptions of weak or-
ders.
Let R be a weak order on X and let f be its representing function. We
write x ≺y if f(x) < f(y) and x ∼y if f(x) = f(y) (cf. Figure 9.9). It is
clear that ∼is an equivalence relation on the set X and ≺deﬁnes a linear
order on the quotient set X/ ∼of equivalence classes of the relation ∼. Let
a  b  c
a  b  c
a  b  c
b  a  c
b  a  c
b  c  a
b  c  a
c  b  a
c  a  b
c  a  b
a  c  b
a  c  b
a  c  b
Figure 9.9. The diagram of weak orders on X = {a, b, c}.

190
9 Hyperplane arrangements and their media
X1, . . . , Xk be the equivalence classes of the relation ∼enumerated according
to the relation ≺. Then
xRy
⇔
x ∈Xi, y ∈Xj,
for some i < j.
(9.5)
In this case, we write R = ⟨X1, . . . , Xk⟩and say that R is a weak k-order
and that Xi’s are indiﬀerence classes of R. In particular, weak n-orders are
linear orders, and the only weak 1-order is the empty weak order. The set of
all weak k-orders on X is denoted by WO(k).
Another useful representation of WO is given by the cells of the braid
arrangement Bn. We begin with a simple example.
9.4.3 Example. The cells of the braid arrangement B3 are shown in Fig-
ure 9.10 (cf. Figure 9.3). The 3-cells (regions) are labeled R1, . . . , R6, 2-cells
(facets of regions) are shown by the rays, and the only 1-cell is represented by
the dot at the center of the drawing. Note that this ﬁgure is the intersection
of B3 with the plane x1 + x2 + x3 = 0 (cf. Example 9.1.14).
R1
R2
R3
R4
R6
R5
Figure 9.10. Cells of the braid arrangement B3
As in the previous section, V = RX is the n-dimensional vector space of
all real-valued functions on X. Let R0 be a ﬁxed asymmetric and strongly
connected binary relation on X. For ab ∈R0 we deﬁne hyperplanes Hab in V
by
Hab = {f ∈V
f(a) = f(b)}.
Clearly, these hyperplanes are distinct and form the braid arrangement Bn.
Corresponding half-spaces are deﬁned as follows:
H+
ab = {f ∈V
f(a) > f(b)}
and
H−
ab = {f ∈V
f(a) < f(b)},
for ab ∈R0.

9.4 Weak Orders and Cubical Complexes
191
The sign vectors
Xab(f) =
⎧
⎪
⎨
⎪
⎩
+,
if f ∈H+
ab,
−,
if f ∈H−
ab,
0,
if f ∈Hab,
ab ∈R0,
deﬁne cells of Bn (cf. Deﬁnition 9.1.3). The proof of the next lemma is left as
Problem 9.9.
9.4.4 Lemma. Two sign vectors Xab(f) and Xab(g) are equal if and only if
functions f and g represent the same weak order on X.
9.4.5 Deﬁnition. Let A be an arrangement. The face poset F(A) is the set
of all cells of A ordered by inclusion of their topological closures.
By Lemma 9.4.4, there is one-to-one correspondence between cells of Bn
and weak orders on X. This correspondence has a clear geometric ﬂavor as
illustrated by drawings in Figures 9.3, 9.9, and 9.10. In the case of the braid
arrangement Bn, the posets WO and F(Bn) are isomorphic (see Problem 9.11).
We obtain a representation of the family of weak orders on X by a wg-
family of sets, by showing that the Hasse diagram of (isomorphic) posets
F(Bn) and WO is a partial cube. For this we use representations of weak orders
as ordered partitions of the set X (cf. Janowitz, 1984; Ovchinnikov, 2006). This
representation will provide us with a tool for constructing a medium on weak
orders.
The following theorem is the statement of Problem 19 on p.115 in Mirkin
(1979). The proof is straightforward and omitted (see Problem 9.14).
9.4.6 Theorem. A weak order R = ⟨X1, . . . , Xk⟩contains a weak order R′
if and only if
R′ =
 i1

j=1
Xj,
i2

j=i1+1
Xj, . . . ,
k
j=im
Xj

for some sequence of indices 1 ≤i1 < i2 · · · < im ≤k.
One can say (see Mirkin, 1979, Chapter 2) that R′ ⊂R if and only if
the indiﬀerence classes of R′ are “enlargements of the adjacent indiﬀerence
classes” of R.
9.4.7 Corollary. A weak order W = ⟨X1, . . . , Xk⟩covers a weak order W ′
in WO if and only if
W ′ = ⟨X1, . . . , Xi ∪Xi+1, . . . , Xk⟩
for some 1 ≤i < k.

192
9 Hyperplane arrangements and their media
The proof is left as Problem 9.15.
Let R be a weak order. We denote by JR the set of all weak 2-orders that
are contained in R.
9.4.8 Theorem. A weak order admits a unique representation as a union
of weak 2-orders, that is, for any R ∈WO there is a uniquely deﬁned set
J ⊆WO(2) such that
R =

U∈J
U.
(9.6)
Proof. Clearly, the empty weak order has a unique representation in the form
(9.6) with J = ∅.
Let R = ⟨X1, . . . , Xk⟩be a weak order with more than one indiﬀerence
class. By Theorem 9.4.6, each weak order in JR is in the form
Ri =

∪i
1Xj, ∪k
i+1Xj
 
,
1 ≤i < k.
By (9.5), we have
xRy
⇔
(∃p) xRpy
⇔
x(∪k
i=1Ri)y.
Thus R = ∪k
i=1Ri. This proves (9.6) with J = JR.
Let R = ⟨X1, . . . , Xk⟩be a weak order in the form (9.6). It is clear that
J ⊆JR. Suppose that Rs /∈J, for some s. Let x ∈Xs and y ∈Xs+1. Then
xy ∈R and xy /∈Ri, for i ̸= s, a contradiction. It follows that J = JR, which
proves uniqueness of representation (9.6).
Let J be the family of subsets of the set WO(2) in the form JR, ordered
by inclusion. The following theorem is an immediate consequence of Theo-
rem 9.4.8.
9.4.9 Theorem. The correspondence R →JR is an isomorphism of posets
WO and J.
Clearly, the empty weak order on X corresponds to the empty subset of
WO(2) and the set LO of all linear orders on X is in 1-1 correspondence with
maximal elements in J.
9.4.10 Theorem. The family J is an independence system.
Proof. Let J′ be a subset of JR for some R ∈WO. Then R = !
U∈JR U. Let
R′ = !
U∈J′ U. As a union of negatively transitive relations, the relation R′
itself is negatively transitive. It is asymmetric, since R′ ⊆R. Thus, R′ is a
weak order. By Theorem 9.4.8, J′ = JR′ ∈J. It follows that the family J is
closed under taking subsets, the deﬁning property of an independence system
(cf. Deﬁnition 4.1.1).

9.4 Weak Orders and Cubical Complexes
193
9.4.11 Theorem. Let (J, WJ) be the representing medium (cf. Deﬁnition 3.3.2)
of the family J. Then (J, WJ) is an i-closed medium.
Proof. This is an immediate consequence of Theorems 9.4.10 and 4.1.18.
Let α : WO →J be the isomorphism from Theorem 9.4.9. We obtain a
token system (WO, T) by ‘pulling back’ tokens from WJ to WO, as it was done
in 3.5.10 for linear media. Namely, for γ ∈WJ, we deﬁne τγ by
τγ = α ◦γ ◦α−1,
that is, Rτγ = α−1(α(R)γ) for R ∈WO. Let T = {τγ}γ∈WJ. We deﬁne
β(τγ) = γ. Clearly, (α, β) is an isomorphism from the token system (WO, T)
to the medium (J, WJ). Therefore, (WO, T) is an i-closed medium itself. Tokens
in T are deﬁned by the weak 2-orders on the set X.
In what follows, we describe eﬀective actions of tokens in T in terms of
weak orders.
Let V = ⟨A, B⟩be a weak 2-order on X. We regard sets A and B as sets
of ‘dominated’ and ‘dominating’ elements, respectively, (relative, of course, to
the weak 2-order V ). The weak 2-order V deﬁnes two mutually reverse tokens
τV and ˜τV in T by means of the bijection β−1. We consider eﬀective actions
of τV and ˜τV on the states in WO separately.
(i) The case of τV . Let R = ⟨X1, . . . , Xk⟩be a weak order on which τV is
eﬀective, that is, RτV ̸= R. Then V /∈JR and JR ∪{V } ∈J, according to
the deﬁnition of token actions in (J, WJ). Thus, by Theorem 9.4.8, R ∩V is
a weak order and R covers R ∩V in WO. The indiﬀerence classes of R ∩V
are in the forms Xi ∩A and Xi ∩B. Since R ̸= R ∩V , there is p such that
X′
p = Xp ∩A and X′′
p = Xp ∩B form a partition of Xp. By Corollary 9.4.7,
RτV =

X1, . . . , X′
p, X′′
p , . . . , Xk
 
,
where Xi ⊂A for i < p, Xi ⊂B for i > p. In other words, the action of
τV partitions the indiﬀerence class Xp of R into subsets of ‘dominated’ and
‘dominating’ elements according to V . The remaining indiﬀerence classes of R
consist entirely of either ‘dominated’ or ‘dominating’ alternatives with respect
to V (cf. Figure 9.11).
(ii) The case of ˜τV . Again, let R = ⟨X1, . . . , Xk⟩be a weak order on
which ˜τV is eﬀective. Then V
∈JR which implies R ⊂V . By Theo-
rem 9.4.6, there is 1 ≤p < k such that V =

∪p
i=1Xi, ∪k
i=p+1Xi
 
. By The-
orem 9.4.8, the weak order R˜τV is the intersection of weak 2-orders in the
form Rq =

∪q
i=1Xi, ∪k
i=q+1Xi
 
with q ̸= p. The indiﬀerence classes of R˜τV
are intersections of the indiﬀerence classes of Rq’s with q ̸= p. It follows that
R˜τV = ⟨X1, . . . , Xp ∪Xp+1, . . . , Xk⟩.
Since A = ∪p
i=1Xi and B = ∪k
i=p+1Xi, the action of ˜τV joins the indiﬀer-
ence classes Xp and Xp+1. These classes consist of maximal (with respect

194
9 Hyperplane arrangements and their media
R
V
RtV
X1
Xp
X1
Xk
Xk
Xp
Xp
‘’
‘
A
B
Figure 9.11. An eﬀective action of the token τV
R
V
RtV
X1
Xp»Xp+1
X1
Xk
Xk
Xp+1
Xp
A
B
~
Figure 9.12. An eﬀective action of the token ˜τV
to R) ‘dominated’ elements in A and minimal ‘dominating’ elements in B,
respectively, (cf. Figure 9.12).
The braid arrangement Bn has a rich geometric structure that provides for
various representations of the poset WO. First, by Theorem 9.4.9, the poset
WO can be modeled by a set of vertices of the (oriented) unit cube of the
dimension d = |WO(2)| = 2n −2 (cf. Problem 9.13) by using characteristic
functions χ(JR) of the sets JR. Let L ∈WO(n) be a linear order on X. Then
JL is a maximal element in J and, by the proof of Theorem 9.4.11, the convex
hull of {χ(JR) R ∈WO R ⊆L} is a subcube CL of [0, 1]d. The dimension
of CL is n −1. The collection of all cubes CL with L ∈WO(n) and all their
subcubes form a cubical complex C(WO) which is a subcomplex of [0, 1]d.
Clearly, C(WO) is a complex of the dimension n −1 and the (oriented) 1-
skeleton of this complex is isomorphic to the Hasse diagram of WO.
The dimension dim C(WO) = n −1 is much smaller than the dimension
d = 2n −2 of the space Rd in which C(WO) was realized. Simple examples
indicate that C(WO) can be realized in a space of a smaller dimension. For
instance, a weak order R on X is a subset of the set (X × X) \ {(x, x)}x∈X and
therefore can be represented by a 0/1-vector in Rn(n−1). Note that the convex
hull of 0/1-vectors representing weak orders is a weak order polytope (Fiorini
and Fishburn, 2004). Clearly, we obtained a realization of the complex C(WO)
in the n(n −1)-dimensional vector space.
We obtain a realization of C(WO) even in a smaller space by ‘unfolding’
the complex in the previous representation. Figure 9.9 is instructive. Consider

9.4 Weak Orders and Cubical Complexes
195
x
y
z
Figure 9.13. “Monkey Saddle”.
it as a drawing of three-dimensional diagram with weak orders
b ≺a ∼c,
a ∼b ≺c,
a ≺b ∼c
represented by the three coordinate unit vectors. Then we have a realization
of the complex C(WO) for X = {a, b, c}, which is shown in Figure 9.13. This
is a ‘ﬂat’ analog of the popular smooth surface z = x3 −3xy2 know under the
name “monkey saddle”. This example suggests that the complex C(WO) can
be realized in n(n−1)
2
-dimensional space (cf. Problem 9.12).
It is clear that it is impossible to place six squares on the plane in such a
way that they represent the complex C(WO) (here, n = 3). Thus, in general,
there is no geometric realization of the (n−1)-dimensional complex C(WO) in
Rn−1. On the other hand, there is a complex in Rn−1 which is combinatorially
equivalent to C(WO).
According to Ziegler (1995, p.18), “k-faces (of the permutohedron Πn−1)
correspond to ordered partitions of (the set X) into n−k nonempty parts” (see
also Barbut and Monjardet, 1970, p.54). In other words, each face of the per-
mutohedron Πn−1 represents a weak order on X. Linear orders on X are
represented by the vertices of Πn−1 and the trivial weak order on X is repre-
sented by Πn−1 itself. Weak 2-orders are in one-to-one correspondence with
the facets of Πn−1. Let L be a vertex of Πn−1, and consider the set of barycen-
ters of all faces of Πn−1 containing L. A direct computation (cf. Problem 9.19)
shows that the convex hull of these points is a (combinatorial) cube of dimen-
sion n −1. This also follows from a more general statement of Corollary 7.18
in Ziegler (1995).
The complex depicted in Figure 9.14 (cf. Figure 9.9) is a combinatorial
equivalent of the complex C(WO) for n = 3. The colored quadrilaterals rep-
resent maximal cubes in C(WO) (cf. Figure 9.13). The union of these quadri-
laterals is the permutohedron Π2.

196
9 Hyperplane arrangements and their media
Figure 9.14. The complex C(WO) for n = 3
It is not diﬃcult to calculate the isometric and lattice dimensions of the
partial cube WO. We have (see Problems 9.13, 9.12, and 9.16):
dimI(WO) = 2n −2
and
dimZ(WO) = n(n −1)
2
(9.7)
Problems
9.1 Prove that the functions τ +
i
and τ −
i
introduced in Deﬁnition 9.1.7 are
genuine tokens (that is, distinct from the identity on P), and mutual reverses.
9.2 Complete the proof of Theorem 9.1.18.
9.3 Let P be a non connected partial order on a ﬁnite set X and let P be
the set of all linear extensions of P. (There are at least two such extensions;
see Trotter, 1992, p.9). We deﬁne a token system (P, T) in which the set of
tokens
T = {τab ab ∈X × X, a ̸= b, {ab, ba} ∩P = ∅}
is deﬁned, for all τab ∈T, by
Lτab = Q
⇐⇒
(L \ {ba}) ∪{ab} = Q
(L, Q ∈P, L \ Q = {ba}, Q \ L = {ab}).
Prove that (P, T) is a medium.
9.4 Prove that the region graph of a hyperplane arrangement contains a ver-
tex incident to a single edge, if and only if the hyperplanes of the arrangement
are all parallel to each other. Show from this that the medium of Figure 2.1
does not come from a hyperplane arrangement in Rn.
9.5 Let G be the region graph of an arrangement A. Show that the graph
distance between two vertices of G equals the number of hyperplanes in A
separating the corresponding regions of A.

Problems for Chapter 9
197
9.6 Show that the medium formed from an n-dimensional braid arrangement
is isomorphic to the medium of linear orders on n items deﬁned in Chapter 3.
9.7 Let A be the arrangement of lines (cf. Example 9.1.22):
y =
√
3x + i,
y = −
√
3 + j,
y = k,
i, j, k ∈Z,
and let A(n) be a subarrangement A deﬁned by the conditions |i| < n, |j| < n,
and |k| < n. The region graph Hn of A(n) is the nth benzenoid graph from
the coronene/circumcoronene series. Show that Hn has 6n2 vertices (Imrich
and Klavˇzar, 2000).
9.8 Let C be a cycle in the graph of Z2 and let GC be a subgraph formed
by the vertices and edges lying on and in the interior of C. Show that GC is
a partial cube.
9.9 Prove Lemma 9.4.4.
9.10 Let P be the set of all partial orders on a given ﬁnite set X with more
than two elements, and let ρ be a positive function on X. Prove the following
statements:
(i) WO is a proper subset of IOρ.
(ii) If |X| = 3, then SO = IOρ = P.
(iii) If |X| ≥4, then IOρ is a proper subset of P.
(iv) If |X| = 4, then SO ⊆IOρ.
(v) If |X| = 4 and ρ is not a constant function, then SO is a proper subset
of IOρ.
(vi) If |X| ≥5, then there exist ρ such that
SO \ IOρ ̸= ∅
and
IOρ \ SO ̸= ∅.
9.11 Show that the partially ordered set WO and the face poset F(Bn) of
the braid arrangement are isomorphic.
9.12 Let |X| = n. Show that the cubical complex C(WO) can be realized in
Zd, where d = n(n−1)
2
(cf. Figure 9.13).
9.13 Let |X| be a ﬁnite set of cardinality n. Prove that
(i) |WO(2)| = 2n −2.

198
9 Hyperplane arrangements and their media
(ii) |WO(n −1)| = n!(n−1)
2
.
(iii) |WO| = n
k=1 S(n, k)k!, where S(n, k) is a Stirling number of the
second kind (cf. Stanley (1986)).
9.14 Prove Theorem 9.4.6.
9.15 Prove Corollary 9.4.7.
9.16 Prove (9.7).
9.17 Let n = |X|. Show that
la(LO) = n!n(n −1)
4(n! −1) ∼0.25(n2 −1),
where la is the average length function (cf. Deﬁnition 7.3.2) and ∼stands for
“asymptotically equivalent”.
9.18 Let X be a ﬁnite set, n = |X|, and f(n) = |WO| (cf. Problem 9.13(iii)).
(i) Show that, for n = 3, la(WO) = 30
13, where la is the average length
function (cf. Deﬁnition 7.3.2).
(ii) Show that
la(WO) = 2 n−1
k=1
n
k

f(k)f(n −k)[f(n) −f(k)f(n −k)]
f(n)[f(n) −1]
.
(iii) Use a computer algebra program to plot the ﬁrst 100 values of la(WO).
What is your conjecture about the asymptotic behavior of la(WO)?
9.19 Let L be a vertex of the permutohedron Πn. Let CL be the convex hull
of the baricenters of all faces of Πn containing L. Show that the face poset of
the polyhedron CL is isomorphic to the face poset of the n-dimensional cube.

10
Algorithms
In this chapter, we investigate eﬃcient algorithms for solving media-theoretic
problems. We follow Eppstein and Falmagne (2002) and concentrate on a
number of fundamental algorithms for representing media and for converting
between diﬀerent representations of a medium. We also study basic media-
theoretic concepts such as concise messages and closedness. In the next chapter
we will apply these techniques in the algorithmic visualization of media.
In general, in the study of algorithms, we are interested in worst-case
eﬃciency: how can we design algorithms that are guaranteed to solve the
problem of interest correctly, using a number of computational steps that is
guaranteed to be bounded by a slowly-growing function of the input size?
Since, as we have seen in Chapter 6, media can be represented as graphs, all
the standard graph-theoretic algorithms can be applied (such as breadth ﬁrst
search for ﬁnding shortest paths to each state from a single starting state). We
are not interested here in duplicating material on these algorithms, as it can
be found in any standard algorithms text (e.g., Cormen et al., 2003). Instead,
we focus on problems that are speciﬁc to media (e.g., closedness and lattice
dimension) or problems where the knowledge that the input is a medium
can be used to gain some computational eﬃciency with respect to general
graph-theoretic algorithms (e.g., ﬁnding concise messages between every pair
of states).
We assume implicitly throughout this chapter that all media under con-
sideration are ﬁnite.
10.1 Comparison of Size Parameters
We have spoken of analyzing the running time of algorithms in terms of the size
of the input. However, , when the input is a medium, several parameters can
be taken as deﬁning its size. We consider here three diﬀerent size parameters of
media and prove relations between these parameters that allow us to compare
running times that involve more than one of these parameters.

200
10 Algorithms
10.1.1 Deﬁnition. We write that f(x) = O(g(x)) whenever there exist con-
stants x0 and c0 such that, for all x > x0, f(x) ≤c0g(x).
10.1.2 Remark. As is standard in the study of algorithms, all time bounds
will be speciﬁed using the O-notation deﬁned above. This convention allows
our analysis to be performed independently of the details of the computer
system on which an algorithm is implemented, and to avoid the need for a
more precise deﬁnition of what constitutes a single operation.
10.1.3 Deﬁnition. We will assume that an algorithm of interest is operating
on a medium M = (S, T). As we have seen, such a medium may be represented
alternatively as a partial cube graph G = (V, E). In the graph algorithms liter-
ature, the numbers of vertices and edges in a graph are conventionally denoted
n and m, respectively, but we eschew that notation as these letters are over-
loaded with other uses (for instance, the dimension of a Euclidean space).
Instead, we will represent these quantities in our analysis as |V | and |E| re-
spectively. Similarly, we represent the numbers of states and tokens of medium
M by |S| and |T| respectively. Apparently, this gives us four size parameters
with which to analyze our algorithms, but only three of these parameters
are independent, as |V | = |S|. We will use |V | and |S| interchangeably in our
analysis, preferring one or the other according to whether the context suggests
more of a graph-theoretic or media-theoretic interpretation.
While three size parameters amount to a great simpliﬁcation relative to
the multiplicity of diﬀerent media we may wish to analyze, they neverthe-
less complicate the comparison of algorithm run times. If we may solve the
same problem in two ways, one via an algorithm analyzed in terms of |V |
and |E|, and another via an algorithm analzed in terms of |S| and |T|, how
may we compare the two algorithms to determine which one is better? To
this end, we show the following relations between these size parameters. All
logarithms should be assumed to have base 2, although the base is irrelevant
when appearing within O-notation.
We begin with a technical lemma. The bound it states appears to be well
known (compare Lemma 3 of Matouˇsek, 2006) but for completeness we prove
it here.
10.1.4 Lemma. In any family F of n sets, the number of unordered pairs of
sets (P, Q) with |P ∆Q| = 1 is at most 1
2n log2 n.
Proof. Let M(n) denote the maximum possible number of unordered pairs of
sets (P, Q) with |P ∆Q| = 1 for a family of n sets. We use induction on n to
prove that M(n) ≤1
2n log2 n. As a base case, for n = 1, a family of one set
has no such pairs, so M(1) = 0.
If n > 1, let F be a family of sets realizing the maximum value of M(n),
choose x ∈∪F, belonging to some but not all sets in F, and divide F into two

10.1 Comparison of Size Parameters
201
subfamilies Fx and F¯x where Fx consists of the members of F that contain x
and F¯x consists of the remaining members of F. Let |Fx| = a and |F¯x| = b.
Then each set P in F may be used to form at most one pair (P, P ∆{x}) such
that one set in the pair belongs to Fx and the other set in the pair belongs to
F¯x, so the number of pairs of this type is at most min(a, b).
The number of pairs of sets, diﬀering by a single element, that do not have
one set in each subfamily is at most M(a) + M(b). Therefore,
M(n) ≤max
a+b=n M(a) + M(b) + min(a, b)
= max
1≤c≤n
2
M(c) + M(n −c) + c
≤max
1≤c≤n
2
1
2c log2 c + 1
2(n −c) log2(n −c) + c
≤max
1≤c≤n
2
1
2c(log2 n −1) + 1
2(n −c) log2 n + c
= 1
2n log2 n.
Here c = min{a, b}, the replacement of M(c) by 1
2c log2 c and of M(n −c)
by 1
2(n −c) log2(n −c) uses the induction hypothesis, and the replacement of
log2 c by log2 n −1 uses the fact that c ≤n/2.
10.1.5 Theorem. The following relations hold between the size parameters
|V |, |E|, |S|, and |T| of a medium M = (S, T) represented by a partial cube
graph G = (V, E):
log |S| = O(|T|),
(10.1)
|T| = O(|S|),
(10.2)
|S| = |V | = O(|E|),
(10.3)
and
|E| = O(|V | log |V |).
(10.4)
Proof.
(10.1): It follows from Theorem 3.3.3 that every state of the medium can be
uniquely associated with a subset of the |T|/2 positive tokens of some
orientation of the medium. Therefore, |S| ≤2|T|/2, or equivalently,
log |S| ≤|T|/2.
(10.2): Choose an initial state S0. For each other state Si let τi be a token
that acts on Si in a concise message transforming Si to S0; then the
set of pairs Si, Siτi forms the set of edges in a tree T; each path from
S0 to Si in T is a shortest path in the graph representing the medium.

202
10 Algorithms
For each token τ, let S be a state for which Sτ ̸= S. Then the path
from S to Sτ formed by concatenating the paths in T from S to S0
and from S0 to Sτ corresponds to a message in the medium that as
the single-token message τ. Therefore, somewhere in tree T there is a
state Si for which τi = τ. But tree T has |S| −1 edges, so there can
be at most |S| −1 token-reverse pairs in the medium.
(10.3): The fact that |V | = O(|E|) can be seen from the same tree T of
shortest paths described above: it contains |V |−1 edges, each of which
is an edge of G and G may have other edges not in T. Therefore,
|V | ≤|E| + 1 = O(|E|).
(10.4): Let F be a well-graded set family representing the given medium. Then
each edge in E corresponds to a pair of sets in F that diﬀer in a single
element, so the result follows from Lemma 10.1.4.
Further relations may be derived from these, as is suggested in Prob-
lem 10.2. In what follows we assume the standard RAM model of compu-
tation, in which we may store medium states and tokens in single machine
words, and perform machine word operations in constant time per operation.
In cases where our bounds depend on the number of bits that may be stored
in a single machine word, we use W to denote this number.
10.2 Input Representation
Before we can deﬁne and analyze algorithms on media, we need to know some-
thing about how those algorithms represent the media they work with, and
what basic operations are available to them. Whatever input representation
we choose should be space-eﬃcient, should allow our algorithms to quickly list
the elements of the sets S and T, and quickly ﬁnd the result Sτ of applying
token τ to state S.
10.2.1 Deﬁnition. The following two representations of a medium are de-
ﬁned directly in terms of the action of tokens on states. The ﬁrst representation
is natural and simpler, while the second applies well-known data structures
for greater space eﬃciency at minimal cost in time per operation.
Transition table
In this representation, we store a two-dimensional matrix M, with rows
indexed by states and columns indexed by tokens. Each entry M[S, t]
stores the state St reached by the action of that token on that state.
Thus, the result of any such action may be found by table lookup in
constant time. The amount of storage space necessary to store this table
is O(|S| · |T|). In order to quickly list all states and tokens of the medium,
we may wish to augment this matrix with separate lists of the medium’s
states and tokens. In many implementation languages, matrices may be

10.2 Input Representation
203
most eﬃciently indexed by integers rather than whatever objects we are
using to represent the states and tokens; in this case we may wish to store
auxiliary translation tables mapping the states and tokens into integers
in the ranges [0, |S| −1] and [0, |T| −1] respectively. These translation
tables do not change by more than a constant factor the overall storage
requirements of this data structure.
Hashed transition table
Although the transition table’s matrix M allows fast lookups, it uses a
large amount of space for media that have many ineﬀective transitions.
Instead, we may replace it by a hash table, a standard data structure
for storing sparse tables of (key, value) pairs. Such a structure consists of
an array H and a hash function h that maps keys to table indices; the
(key, value) pair corresponding to key k is generally stored at H[h(k)].
The hash function must be carefully chosen so that few pairs ki, kj have a
collision h(ki) = h(kj), and various strategies have been developed in the
hash table literature for choosing h and for handling such collisions when
they arise; see a standard algorithms text such as Cormen et al. (2003) for
details. In our application of hashing to media, the keys will be the pairs
S, τ such that Sτ ̸= S, and the values stored for those keys will be Sτ.
Thus, in H[h(S, τ)] we store the triple (S, τ, Sτ). To look up the result of
applying a token τ to a state S, we examine the table entry H[h(S, τ)],
and determine whether it contains a triple matching S and τ. If it does,
we can determine Sτ from the third entry of the triple. If H[h(S, τ)]
does not match, we apply the hash table’s collision handling procedure
to either determine an alternate location for key (S, τ) or determine that
(S, τ) was not one of the keys used to index the hash table. If (S, τ) is a
valid key involved in a collision, this collision handling procedure will ﬁnd
its associated value Sτ; if, instead, (S, τ) is not one of the keys, we can
determine that Sτ = S.
It is conventional in computer science to analyze hash tables as taking a
constant amount of time per operation (albeit slower than a table lookup
as each operation involves computing the hash function) using space pro-
portional to the number of (key, value) pairs. This analysis can be made
rigorous by assuming that the hash function’s values are independent ran-
dom variables and analyzing the expected time per operation of an ap-
propriate collision handling procedure; generally the level of randomness
required to make this analysis rigorous is less than what is incorporated
into the hash tables implemented in most programming libraries, but nev-
ertheless this style of analysis matches well with practical experience of
hash tables. Applying this analysis to hashed transition tables, we get con-
stant expected time to look up the eﬀect of a token on a state. The space
is O(|E|), as we need store exactly 2|E| (key, value) pairs, one per eﬀective
state-token transition, where E denotes the set of edges of a partial cube
representation of the medium.

204
10 Algorithms
Table 10.1. Transition table for the medium of Figure 2.1.
τ1 τ2 τ3 τ4 τ5 τ6
S:
S
S
V
S
X
S
T: T
W
T
T
T
T
V : V
V
V
S W V
W: T
W W X W V
X: X X W X X
S
10.2.2 Example. Table 10.1 depicts a transition table for the medium de-
picted in Figure 2.1. The table has one row for each of the ﬁve states of the
medium, and one column for each of the medium’s six tokens. Table 10.2
shows the (key, value) pairs of a hashed transition table for the same medium.
Table 10.2. The (key, value) pairs of a hashed transition table for the medium of
Figure 2.1.
key
(S, τ3) (S, τ5) (T, τ2) (V, τ4) (V, τ5) (W, τ1) (W, τ4) (W, τ6) (X, τ3) (X, τ6)
value
V
X
W
S
W
T
X
V
W
S
10.2.3 Deﬁnition. We have seen in Chapter 7 that media may be repre-
sented mathematically as partial cube graphs. This graphical representation
may also be useful in computer algorithms. While there are many ways of rep-
resenting graphs in computers (Cormen et al., 2003), we concentrate here on
variations of one of the most common and most useful graph representations:
the adjacency list.
Adjacency list
We represent the graph G = (V, E) of the medium by a collection of
vertex and edge objects. Each edge object includes pointers to the two
incident vertex objects, and each vertex object has a pointer to a list
object, each item of which points to one of the edge objects incident to
that vertex. This representation requires space O(|V | + |E|) = O(|E|)
and is therefore as space-eﬃcient as the hashed transition table. However,
without further elaboration it is somewhat lacking in usefulness for media-
theoretic algorithms, because it is not straightforward to look up the eﬀect
of a token on a state: the states are represented as graph vertices but the
tokens are not represented at all.
Vertex-labeled adjacency list
In deﬁnition 7.1.1, a partial cube was deﬁned in terms of an isometric em-
bedding of a graph G into a hypercube H(X), which can equivalently be
thought of as a labeling of the vertices of G by binary numbers (represent-
ing the hypercube vertices) in such a way that the graph distance between

10.2 Input Representation
205
vertices equals the Hamming distance between the vertices’ labels. It is
natural to incorporate this deﬁnition into our input representation. We
can do this by storing an adjacency list together with a binary number
label associated with each vertex object. These numbers will be |T|/2 bits
long, as long as there exist no positions at which the bits of all vertices’
labels agree. Thus, if each bit of each label is stored in a separate memory
cell, this representation requires O(|E| + |V | · |T|) = O(|S| · |T|) storage
cells total. However, it may be somewhat more eﬃcient than the transi-
tion table representation in models of computation in which we may store
some number W of bits per memory word; in this case the total number
of words needed for this representation is O(|E| + |S| · |T|/W). We can
deﬁne, for each position i of these numbers and for each bit j ∈{0, 1}, a
token τi,j that transitions from a vertex with label x to a vertex in which
the ith bit of the label of x has been replaced by j, if such a vertex exists.
In order to look up the eﬀect of a transition, we may wish to augment this
data structure with a hash table mapping vertex labels to the associated
vertices, so that we can determine quickly whether a vertex with a modi-
ﬁed label exists in the graph. Compared to the transition table, this data
structure has the advantage that we can list all states reachable by eﬀec-
tive transitions from a given state, in time proportional to the number of
eﬀective transitions, without having to take the time to examine ineﬀec-
tive tokens. However the space is higher relative to the hashed transition
table, motivating our ﬁnal representation.
Edge-labeled adjacency list
We augment an adjacency list representation by storing, associated with
each edge object, the two tokens whose transitions connect states repre-
sented by the edge’s endpoints, and the direction of each token’s transi-
tion. As with the adjacency list, the space is O(|E|). This data structure
enables us to ﬁnd, not just the states reachable by eﬀective transitions
from a given state, but the tokens that lead to those transitions. However,
ﬁnding the result of a transition Sτ requires scanning through the entire
adjacency list of the vertex corresponding to state S.
10.2.4 Remark. It is also possible to consider a representation in which we
do not explicitly store the graph structure, and instead keep only a list of
the vertex labels described above as part of the vertex-labeled adjacency list
representation. The graph structure implicit in this list of labels can then be
recovered by ﬁnding pairs of labels that diﬀer in a single bit. An approximate
dictionary structure of Brodal and G¸asieniec (1996) allows this recovery of
the graph structure to be performed eﬃciently: in time O(|S| · |T|) one can
compute a data structure of size O(|S|·|T|) which allows the neighbors of each
vertex to be listed in time O(|T|) per vertex, so the total time to convert this
representation to a vertex-labeled adjacency list is O(|S| · |T|).

206
10 Algorithms
S 000
X 010
V 001
W 011
T 111
τ6 τ5
τ3 τ4
τ4 τ3
τ2 τ1
τ6 τ5
Figure 10.1. Labeled adjacency list for the medium of Figure 2.1.
10.2.5 Example. Figure 10.1 depicts an adjacency list representation for the
medium depicted in Figure 2.1. This representation has one vertex object
(drawn as a wide rounded rectangle) for each of the ﬁve states of the medium,
one edge object (drawn as a tall narrow rounded rectangle) for each of the
medium’s ﬁve pairs of eﬀective transitions and their reverses, and a list object
(drawn as a sequence of small squares) for the list of edges incident to each
vertex. Pointers from one object to another are drawn as arrows, and we have
included labels both on the vertices (binary numbers) and the edges (two
tokens associated with the two pointers to the endpoints of the edge).
10.2.6 Remark. If we desire a space-eﬃcient data structure that allows us
both to look up transition results in constant time and to ﬁnd all eﬀective
transitions in time proportional to the number of such transitions, we may
combine the hashed transition table and the edge-labeled adjacency list, for
a total space bound of O(|E|), and time O(1) per transition or per eﬀective
transition listed.
In some cases it may also be of use to add to our representations an
auxiliary table from which we can look up the reverse of each token. Such a
table requires storage O(|T|), and may be constructed easily from the edge-
labeled adjacency list, as it stores the tokens with their reverses at each edge.
We now discuss algorithms for converting among these input represen-
tations. A chart of these representations and their conversions is shown in
Figure 10.2.
10.2.7 Theorem. We may convert the transition table representation to the
hashed transition table, and vice versa, in time O(|S| · |T|).

10.2 Input Representation
207
Transition table
Space: O(|S| · |T|)

Theorem 10.2.7
Time: O(|S| · |T|)

Vertex-labeled adjacency list
Space: O(|E| + |S| · |T|/W)

Theorem 10.2.10
Time: O(|S| · |T|)

Hashed transition table
Space: O(|E|)

Theorem 10.2.8
Time: O(|E|)
 Edge-labeled adjacency list
Space: O(|E|)
Adjacency list
Space: O(|E|)
Theorem 10.2.16
Time: O(|S| · |T|)

Figure 10.2. Media representations and conversions between them.
Proof. To convert a transition table into a hashed transition table, initialize
H to be an empty hash table, loop through all state-token pairs S, t, for each
pair use the transition table to look up the result of the transition St, compare
this result to S, and if diﬀerent add key S, t and value St to H. To convert
a hashed transition table into a transition table, initialize matrix M[S, t] = S
for all state-token pairs S, t, then loop through all key-value pairs in the hash
table. For each key S, t and value St, change M[S, t] to St.
10.2.8 Theorem. We may convert the hashed transition table representation
to the edge-labeled adjacency list representation, and vice versa, in expected
time O(|E|).
Proof. To convert a hashed transition table into an edge-labeled adjacency
list, create a vertex object for each state, and create an empty hash table of
edge objects keyed by their endpoints. Loop through all key-value pairs in the
hash table. For each key S, t and value St in the hash table, create (if it does
not exist already) an edge object connecting S and St, and add this object to
the adjacency lists of S and St and to the hash table of edge objects. Also,
whether the edge object was created or already existed, store t as one of the
two tokens associated with that edge. When the conversion is complete, the
hash table of edge objects may be discarded.
To convert an edge-labeled adjacency list into a hashed transition table,
simply create an empty hash table and add to it two entries for each edge of
the graph.
In order to eﬃciently convert the vertex-labeled adjacency list to the edge-
labeled adjacency list, we need some bit-manipulation data structures.

208
10 Algorithms
10.2.9 Lemma. Suppose we are given as input a collection of n B-bit binary
words. Then in time O(nB) we can construct a data structure that allows us
to look up the position of the ﬁrst bit at which any two words of our input
diﬀer, in time O(1) per lookup.
Proof. We build a trie. A trie is a binary tree that has a node for each preﬁx
of each input word. The parent of a nonempty preﬁx is the preﬁx with one
fewer bit, formed by removing the last bit from w, and this parent relation
deﬁnes the tree structure of the trie. The root of the trie is the zero-length
word, and its leaves are the n input words. A trie can be built in time O(nB)
by adding words to it one at a time. Each time we add a word we may step
down a path from the root to the new leaf in time O(B) per added word.
Then, the position of the ﬁrst diﬀerence between two words w1 and w2
equals the length of the word forming the least common ancestor of w1 and
w2 in this trie. We may process any tree, in time linear in the number of tree
nodes, so that least common ancestor queries in that tree may be answered in
constant time per query (see, e.g., Bender and Farach-Colton, 2000). Applying
such a least common ancestor data structure to our trie gives the result.
10.2.10 Theorem. We may convert the vertex-labeled adjacency list repre-
sentation to the edge-labeled adjacency list, and vice versa, in time O(|S|·|T|).
Proof. In one direction, suppose we have a vertex-labeled adjacency list. We
use the data structure of Lemma 10.2.9 to determine the position i at which
the labels of the two endpoints of each edge diﬀer, and we label that edge
with the two tokens ti,0 and ti,1 deﬁned in our description of the vertex-
labeled adjacency list representation. It takes time O(|S| · |T|) to initialize the
data structure of Lemma 10.2.9, after which we can label all edges in total
time O(|E|).
In the other direction, suppose we have an edge-labeled adjacency list,
from which we have extracted the tokens to form a sequence of |T|/2 token-
reverse pairs. We initialize a label L to the all-zero bitvector, and perform a
depth-ﬁrst traversal of the graph starting from an arbitrarily chosen vertex v0.
Each time our traversal ﬁrst reaches a vertex v, we assign it the label L, and
each time our traversal crosses an edge labeled with the tokens from the ith
token-reverse pair in the sequence, we change the ith bit of L from 0 to 1 or
vice versa. In this way, each vertex v is assigned a label in which the nonzero
bits correspond to the tokens on a concise message from v0 to v. Clearly, such
a labeling of the graph must be distance-preserving.
10.2.11 Remark. Converting an edge-labeled adjacency list to an adjacency
list is a trivial matter of omitting the labels, and may be performed in time
O(|E|). The sequence of results in the remainder of this section, in which we
follow Eppstein (2007b), describes a slower conversion in the other direction.
Recall that the Djokovi´c-Winkler relation Θ deﬁned by the equivalence (7.2)

10.2 Input Representation
209
holds for two edges e = {x, y} and = {u, v} of G, thus eΘf, if and only if
δ(x, u) + δ(y, v) ̸= δ(x, v) + δ(y, u).
10.2.12 Lemma. Let pq be an edge in a bipartite graph G. Then pqΘrs if
and only if, for exactly one of r and s, there is a shortest path to p that passes
through q.
Proof. If neither r nor s has such a path, then δ(q, r) = δ(p, r) + 1 and
δ(q, s) = δ(p, s) + 1, so δ(p, r) + δ(q, s) = δ(p, r) + 1 + δ(p, s) = δ(q, r) + δ(p, s)
by associativity of addition, and it is not the case that pqΘrs. Similarly, if both
r and s have such paths, then δ(q, r) = δ(p, r) −1 and δ(q, s) = d(p, s) −1, so
δ(p, r)+δ(q, s) = δ(p, r)−1+δ(p, s) = δ(q, r)+δ(p, s). Thus in neither of these
cases can pq and rs be related. If, on the other hand, exactly one of r and s has
such a path, we may assume (by swapping r and s if necessary) that it is r that
has the path through q. Then δ(q, r) = δ(p, r)−1 while δ(q, s) = δ(p, s)+1, so
δ(p, r) + δ(q, s) = δ(p, r) + δ(p, s) + 1 ̸= δ(p, r) −1 + δ(p, s) = δ(q, r) + δ(p, s),
so in this case pqΘrs.
10.2.13 Remark. Thus, to ﬁnd the equivalence class of edge pq, we may per-
form a breadth ﬁrst search rooted at p, maintaining an extra bit of information
for each vertex v traversed by the search: whether v has a shortest path to p
that passes through q. This bit is set to false initially for all vertices except
for q, for which it is true. Then, when the breadth ﬁrst search traverses an
edge from a vertex v to a vertex w, such that w has not yet been visited by
the search (and is therefore farther from p than v), we set the bit for w to
be the disjunction of its old value with the bit for v. As we will show, we can
apply this technique to ﬁnd several edge classes at once. Speciﬁcally, we will
ﬁnd the equivalence classes of each edge pq incident to a single vertex p, by
performing a single breadth ﬁrst search rooted at p. We observe that no two
such edges pq and pr can be related to each other by Θ.
10.2.14 Remark. Our algorithm will need eﬃcient data structures for stor-
ing and manipulating bit vectors, which we now describe. Our algorithms de-
pend on a model of computation in which integers of at least log |V | bits may
be stored in a single machine word, and in which addition, bitwise Boolean
operations, comparisons, and table lookups can be performed on log |V |-bit
integers in constant time per operation. The constant-time assumption is stan-
dard in the analysis of algorithms, and any machine model that is capable of
storing an address large enough to address the input to our problem has ma-
chine words with at least log |V | bits.
We store a bitvector with k bits in ⌈1+k/ log |V |⌉words, by packing log |V |
bits per machine word. The disjunction operation on two such bitvectors, and
the symmetric diﬀerence operation on two such bitvectors, may be performed
by applying single-word disjunction or symmetric diﬀerence operations to each

210
10 Algorithms
p
0000
q0
1000
q1
0100
q2
0010
q3
0001
1010
1100
0110
0110
1110
0011
0111
0111
0111
0110
[pq0]
[pq0]
[pq1]
[pq1]
[pq1]
[pq1]
[pq1]
[pq2]
[pq2]
[pq2]
[pq2]
[pq0]
[pq0]
[pq2]
[pq3]
[pq3]
[pq3]
[pq3]
Figure 10.3. Data for the algorithm of Lemma 10.2.15. The left-to-right order of
the vertices indicates their distance from the leftmost vertex p, and therefore their
position in the breadth ﬁrst traversal of the graph. Each vertex is labeled with a
bitvector indicating which vertices qi belong to shortest paths to p, and the edges
of the graph are labeled [pqi] if they are part of the equivalence class of edge pqi.
of the words in this representation. To test whether a bitvector is nonzero,
we use a comparison operation to test whether each of its words is nonzero.
To test whether a bitvector has exactly one nonzero bit, and if so ﬁnd out
which bit it is, we again use comparisons to test whether there is exactly one
word in its representation that is nonzero, and then look up that word in a
table that stores either the index of the nonzero bit (if there is only one) or
a ﬂag value denoting that there is more than one nonzero bit. Thus, all these
operations may be performed in time O(1 + k/ log |V |) per operation.
10.2.15 Lemma. Let G be any partial cube graph with n vertices and m
edges, and let p be a vertex in G that is incident to the largest number of
edges among all vertices of G. Then there is an algorithm which ﬁnds the
equivalence classes of Θ for each edge in G incident to p, in time O(|V |) per
equivalence class.
Proof. Let k denote the number of incident edges of p, which must be at least
2m/n. We denote the k neighbors of p in G by qi, for an index i satisfying
0 ≤i < k. We create, for each vertex of G, a bitvector Dv with k bits; we
denote the ith bit of this structure as Dv[i]. Bit Dv[i] will eventually be 1 if
v has a shortest path to p that passes through qi; initially, we set all of these
bits to 0, and then set we set Dqi[i] = 1.
Next, we perform a breadth ﬁrst traversal of G, starting at p. When this
traversal visits a vertex v, it considers all edges vw such that w has not yet
been visited; due to the breadth ﬁrst ordering of the vertices, each such edge
must be part of a shortest path from p to w. The algorithm then sets all bits

10.3 Finding Concise Messages
211
Dw[i] to be the disjunction of their previous values with the corresponding
bits Dv[i].
Finally, once the breadth ﬁrst search is complete and all data structures
Dv have reached their ﬁnal values, we examine each edge vw in the graph. If
Dv = Dw, we ignore edge vw, as it will not be equivalent to any edge pqi.
Otherwise, we compute a bitvector B as the symmetric diﬀerence of Dv and
Dw, and assign vw to the equivalence class of the edge pqi for which B[i] is
nonzero. Figure 10.3 shows this assignment of edges to classes for a simple
example graph.
All stages of the algorithm perform O(|E|) steps, each one of which involves
O(1) of the bitvector operations described by Remark 10.2.14, so the total time
is O(|E|(1 + k/ log |V |)) = O(k|V |), as claimed.
10.2.16 Theorem. We may convert from the adjacency list representation
into the edge-labeled adjacency list representation in time O(|S| · |T|).
Proof. Given a graph G, we ﬁnd the maximum degree vertex p in G and apply
the algorithm of Lemma 10.2.15 to identify the equivalence classes of all ad-
jacent edges, thus labeling those edges. Next, we ﬁnd a graph G′ representing
the projection (as per Theorem 2.11.6) of the symmetric set of edge labels
created by the application of Lemma 10.2.15. In graph-theoretic terms, this
projection may be found in linear time by contracting all labeled edges. We
apply the conversion algorithm recursively to label the edges of G′, undo the
edge contraction, and copy the labels of the contracted graph’s edges to the
corresponding edges of G.
The time for contracting and uncontracting is dominated by the time to
apply Lemma 10.2.15, which is O(|V |) = O(|S|) per equivalence class found.
Therefore, the total time is O(|S| · |T|).
10.2.17 Remark. Unless stated otherwise, we will assume for the rest of our
algorithms that the input medium is represented by an edge-labeled adjacency
list, as this representation is space-eﬃcient, eﬃciently convertable to the other
representations, and (unlike the hashed transition table) deterministic.
10.3 Finding Concise Messages
We now follow Eppstein and Falmagne (2002) in describing an eﬃcient algo-
rithm for ﬁnding concise messages and distances between all pairs of states
in a medium. This could be done in total time O(|V | · |E|) by performing
a sequence of breadth ﬁrst traversals in the graph representing the medium,
starting a diﬀerent traversal at each state, but the following algorithm is more
eﬃcient. Together with the O(|S| · |T|)-time algorithm for labeling the edges
of an unlabeled partial cube graph, described in Theorem 10.2.16, this fast
distance computation algorithm forms a key step in the recent algorithm of
Eppstein (2007b) for eﬃciently recognizing partial cube graphs.

212
10 Algorithms
10.3.1 Lemma. For any medium, and any starting state S of the medium,
there is a message m of at most 2|V | −3 tokens, such that applying m to
S produces a sequence of states that includes every state of the medium.
Message m may be constructed algorithmically in time O(|E|) from a labeled
adjacency list representation of the medium.
Proof. We apply a standard depth-ﬁrst search algorithm to the adjacency
list representation. This algorithm is recursive, and begins by a recursive call
having the initial state S as an argument; it maintains as it progresses a bit for
each state of the medium, representing whether or not that state has already
been included in the traversal. When called with a state Q as argument, the
algorithm marks Q as having been included in the traversal; then, it loops in
sequence through the states that can be reached from Q by a single transition.
If this loop reaches a state R that has not yet been included in the traversal,
the algorithm is called recursively with R as argument.
To turn this search procedure into a message, we build m by concate-
nating one token onto it at a time from an initial empty message. When the
loop through the neighbors of Q ﬁnds an untraversed state R and calls the
algorithm recursively with argument R, it also concatenates onto m a token
τ such that Qτ = R, and when it returns from the recursive call to R, it also
concatenates onto m the reverse of τ. In this way, Sm is always equal to the
state currently being considered by the algorithm, and the sequence of states
produced by applying m to S is always equal to the sequence of states that
have been traversed so far by the algorithm.
At the end of this depth ﬁrst search procedure, m is a stepwise eﬀective
but ineﬀective message for S. It has length 2|V | −2, since each state is the
argument for one recursive call and since the recursive call for each state other
than S is associated with the addition of two tokens onto m. To produce the
message of length 2|V | −3 described in the statement of the Lemma, we may
remove the ﬁnal token from m.
10.3.2 Remark. If S is the root of a star medium (cf. Deﬁnition 2.9.4), the
bound of 2|V | −3 on the length of m cannot be improved; see Problem 10.9.
10.3.3 Theorem. Given any medium, in time O(|V |2) we can build a table
of dimensions |V |×|V | that stores, for each pair of states S and Q, two pieces
of information: the distance dSQ from S to Q, and a token τSQ such that τSQ
is eﬀective for S and τSQ belongs to a concise message transforming S to Q.
Proof. We apply the conversions of Theorem 10.2.8 and Theorem 10.2.7 so
that we have both the input edge-labeled adjacency list and a state-transition
table allowing us to test in constant time whether a token is eﬀective for
a given state. We use Lemma 10.3.1 to ﬁnd a sequence of all the states in
the medium, connected by transitions of the medium. We then traverse the
medium by stepping from state to state in this sequence, maintaining as we

10.3 Finding Concise Messages
213
do a data structure that allows us to compute the table entries dSQ and τSQ
for each traversed state Q.
The data structure that we maintain as we traverse the medium consists
of the following components:
•
A doubly-linked list L of pairs (τ, Λτ), where each τ is a token in the
content of Q and Λτ is a pointer to a linked list described below.
•
A pointer from each state S ̸= Q to the ﬁrst pair (τ, Λτ) in L for which
Sτ is eﬀective.
•
Linked lists Λτ for each pair (τ, Λτ), listing the states pointing to that
pair.
The pointers from each state S to the associated pair (τ, Λτ) provide half
of the information we are trying to compute: τ is an eﬀective token for S that
is in the content of Q, and therefore can be stored as τSQ. We record this
information for Q when the traversal ﬁrst reaches Q. The other information,
the numeric distances dSQ to Q, can easily be computed in time O(|V |) for
each Q by traversing the tree formed by the eﬀective transitions SτSQ. Thus,
it remains to show how to initialize and maintain the data structures described
above as we perform our traversal.
To initialize the data structures, we determine the content of the initial
state Q by performing a depth-ﬁrst traversal of the graph and recording the
tokens labeling the depth ﬁrst search tree edges. We then create an empty
list Λτ for each token τ in the content of the initial state Q. We make a
list L of the pairs (τ, Λτ) in an arbitrary order. Then, for each state S, we
ﬁnd a pointer to the ﬁrst (τ, Λτ) in this list such that τ is eﬀective for S, by
sequentially searching L, using our transition table to test whether each token
in the sequence is eﬀective for S in constant time per test.
It remains to describe how to update the data structure as we perform
each step from a state Q to a new state Qτ = Q′ of the depth ﬁrst traversal.
The token ˜τ reversing this transition belongs to the content of Q, so prior to
the transition it is listed as part of some pair (˜τ, Λ˜τ) in L. We remove this
pair from L, and append a new pair (τ, Λτ) to the end of L, where Λτ is a
new empty list. We must then recompute the pointers from each state S that
had previously been pointing to (˜τ, Λ˜τ). We do so by sequentially searching
list L, starting at the position of the deleted pair (˜τ, Λ˜τ), for the ﬁrst pair
(τ ′, Λτ ′) such that τ ′ is eﬀective for S; once we ﬁnd τ ′, we append S to Λτ ′.
We set the pointer for Q to the pair (τ, Λτ) without searching, since τ will be
the only token in ˆQ′ that is eﬀective for Q.
We ﬁnish the proof by analyzing the time used by this algorithm. Finding
the content of Q takes time O(|E|), initializing L takes time O(|V |), and
initializing the pointers for each state takes time O(|T|) per state, or O(|V |·|T|)
overall. List L initially contains |T|/2 pairs, and each traversal step appends a
new pair to L. Therefore, the total number of pairs added to L over the course
of the algorithm is at most |T|/2+2|V |−3 = O(|V |). The most expensive part
of the algorithm is the sequential searching to ﬁnd a new eﬀective pair. For

214
10 Algorithms
each state S, the sequence of sequential search steps never revisits a position
in L, so the total number of steps of sequential searching over the course of
the algorithm is at most |V |(|T|/2 + 2|V | −3) = O(|V |2). Computing numeric
distances also takes a total of O(|V |2) time, and the other data structure
update steps take only constant time per traversal step. Therefore, the total
time for the algorithm is O(|V |2).
From the table constructed above, one can construct a concise message m
such that Sm = Q for any two states S and Q, in time O(|m|), by repeatedly
using the table to ﬁnd eﬀective tokens in the message.
10.3.4 Example. We describe step-by-step the algorithm above as it ﬁnds
concise messages in the medium of Figure 2.1. Recall that the adjacency list
and transition table data structures used by the algorithm are depicted in
Figure 10.1 and Table 10.1 respectively. In the depth ﬁrst traversal used by
the algorithm, we will test the edges out of each vertex in order by their
position in the adjacency lists depicted in Figure 10.1.
To make visually apparent the distinction between lists that happen to
contain a single item and the items within the lists, in this example, we rep-
resent a list of items using a syntax borrowed from the Python programming
language, in which the list is enclosed in square brackets or parentheses and
list items are separated by commas. Thus, [1] represents a list with a single
item in it, which should be thought of as a diﬀerent type of object than the
number 1 that is the ﬁrst and only item in the list [1]. Similarly, we use a
Python-like syntax to represent the pointers that map states to items in L:
each pointer is represented as a colon-separated pair state : item, and the set
of these pairs is enclosed in curly brackets. To avoid confusion over whether
it is appropriate to use mathematical equality to describe a relationship that
is contingent on the step at which it is tested, we also represent the value
of the program’s variables by following the variable name by a colon and a
value, rather than using the equal sign that would be more typical in computer
science writing.
1. We begin the traversal at the state S. The tokens in the content of S are
τ2, τ4, and τ6. We order these arbitrarily (in our example, we will use the
numeric order of the subscripts) and initialize list L to
L : [(τ2, Λ2), (τ4, Λ4), (τ6, Λ6)].
The initial value of the set of pointers from states to L assigns each state
(other than our initial state S) to the ﬁrst token in L that is eﬀective for
that state and belongs to a concise message that transforms that state
into S:
{T : (τ2, Λ2), V : (τ4, Λ4), W : (τ4, Λ4), X : (τ6, Λ6)}.
The edges corresponding to these eﬀective transitions form a spanning
tree of G, from which we can calculate the distances from each state to V :

10.3 Finding Concise Messages
215
V and X are at distance one, W is at distance two, and T is at distance
three. Finally, each Λi stores a sequence of the states pointing to it:
Λ2 : [T]
Λ4 : [V, W]
λ6 : [X].
2. The depth ﬁrst traversal of G follows the ﬁrst edge out of S, leading to
the transition Sτ3 = V . We remove τ4, which is the reverse of τ3, from L,
and append τ3:
L : [(τ2, Λ2), (τ6, Λ6), (τ3, Λ3)].
For each state in Λ4 other than the new position of the traversal (that is,
only state W) we search sequentially through the positions of L after the
deleted pair for the next eﬀective token. The ﬁrst position tested is the
one for τ6, which is eﬀective. So we update the pointers from states to L,
including as well a new pointer from S and deleting the one from V :
{S : (τ3, Λ3), T : (τ2, Λ2), W : (τ6, Λ6), X : (τ6, Λ6)}.
These pointers give eﬀective tokens for each state on a concise message to
V . After updating the lists Λi to reﬂect these changes, they stand at
Λ2 : [T]
Λ3 : [S]
Λ6 : [X, W].
3. The depth ﬁrst traversal attempts to use the ﬁrst edge out of V , corre-
sponding to the transition V τ4 = S, but this leads to a state that has
already been visited, so the transition is ignored and our data structures
remain unchanged.
4. The second edge out of V leads to the transition V τ5 = W. Updating the
data structures for this transition gives
L : [(τ2, Λ2), (τ3, Λ3), (τ5, Λ5)].
The pointers from states to L are
{S : (τ3, Λ3), T : (τ2, Λ2), V : (τ5, Λ5), X : (τ3, Λ3)}
(giving eﬀective tokens on concise messages from each state to W), and
the lists Λi are
Λ2 : [T]
Λ3 : [S, X]
Λ5 : [V ].

216
10 Algorithms
5. The ﬁrst edge out of W leads back to the already-visited state V . The
second edge corresponds to the transition Wτ4 = X. Updating our data
structures for this transition leads to a situation with
L : [(τ2, Λ2), (τ5, Λ5), (τ4, Λ4)],
pointers from states
{S : (τ5, Λ5), T : (τ2, Λ2), V : (τ5, Λ5), W : (τ4, Λ4)}
(giving eﬀective tokens on concise messages from each state to X), and
the lists are
Λ2 : [T]
Λ4 : [W]
Λ5 : [T, V ].
6. Both edges out of X lead to already-visited states, so the depth ﬁrst
traversal returns to W to try the remaining edge out of it, via the transi-
tion Xτ3 = W. Updating our data structures for this transition leads to
a situation with
L : [(τ2, Λ2), (τ5, Λ5), (τ3, Λ3)].
The pointers from states are
{S : (τ5, Λ5), T : (τ2, Λ2), V : (τ5, Λ5), X : (τ3, Λ3)},
and the lists are
Λ2 : [T]
Λ3 : [X]
Λ5 : [S, V ].
Note that our data structures, while still valid, are in a diﬀerent conﬁgu-
ration than they were the ﬁrst time our traversal reached W: the tokens
in L appear in a diﬀerent order, and this leads to other changes in the
rest of our data structures.
7. The ﬁnal edge out of W corresponds to the eﬀective transition Wτ1 = T.
We update our data structures to
L : [(τ5, Λ5), (τ3, Λ3), (τ1, Λ1)],
with pointers from states
{S : (τ5, Λ5), V : (τ5, Λ5), W : (τ1, Λ1), X : (τ3, Λ3)}

10.4 Recognizing Media and Partial Cubes
217
(giving eﬀective tokens on concise messages from each state to T), and
lists
Λ1 : [W]
Λ3 : [X]
Λ5 : [S, V ].
8. The remaining steps backtrack through the depth ﬁrst traversal without
reaching any additional unexplored states, and we omit them from our
example (cf. Problem 10.11).
10.4 Recognizing Media and Partial Cubes
As an application of our algorithm for ﬁnding concise messages eﬃciently, we
use it as part of an algorithm for verifying that an input in one of the formats
described earlier is a correct description of a medium.
10.4.1 Theorem. If we are given as input an object purported to be a
medium, in the transition table, hashed transition table, edge-labeled adja-
cency list, or vertex-labeled adjacency list format, we can test whether the
input is in fact a medium in time O(|S|2).
Proof. Our algorithm works most directly for the vertex-labeled adjacency list
format. If the input is an edge-labeled adjacency list, we use Theorem 10.2.10
to construct from it a vertex-labeled adjacency list. This algorithm uses only
the assumption that the edge labels consistently group the tokens into token-
reverse pairs; if not, we terminate the algorithm and report that the input
is invalid. Once we have constructed a vertex-labeled adjacency list, we use
Lemma 10.2.9 to verify that, for each eﬀective transition St of the edge-labeled
adjacency list, the ﬁrst diﬀering bit in the labels of S and of St is the one
corresponding to token t. If this is so, and the vertex-labeled adjacency list
validly describes a medium, then the edge-labeled adjacency validly describes
the same medium. If the input is a transition table (hashed or not), we use
Theorem 10.2.8 to convert it to an edge-labeled adjacency list and then pro-
ceed as above. If this conversion process attempts to label the same orientation
of the same edge with multiple tokens, or leaves some orientation of an edge
unlabeled, we terminate the algorithm and report that the input is invalid;
otherwise, the reverse conversion will result in a transition table identical to
our input, so if the resulting adjacency list validly describes a medium, then
the transition table validly describes the same medium.
With our input in vertex-labeled format, we apply Lemma 10.2.9 twice,
once on the labels of the vertices and once on the reverses of those labels
(that is, the labeled graph formed by replacing the token labeling each edge

218
10 Algorithms
by its reverse). With these two data structures, we may verify that, for each
edge of the adjacency list structure, the two endpoints of that edge diﬀer in
exactly one bit of their labels. From this we may conclude (using the triangle
inequality for Hamming distance) that the graph distances between any two
vertices are at least equal to the Hamming distances between their labels.
Finally, we apply Theorem 10.3.3 to ﬁnd, for each vertex v of the graph
representing the purported medium, a tree of paths from each other vertex to
v, such that if the graph is indeed a medium the paths will be shortest paths
to v. If the algorithm of this theorem ever fails to ﬁnd an eﬀective transition
from some vertex w towards the current node v of its depth ﬁrst traversal,
and hence fails to ﬁnd the tree of paths to v, we terminate the algorithm and
report that the input is invalid. For each v, once the tree of paths is found,
we test for each edge of the tree that the vertex label on the endpoint nearer
to v is closer to the label of v than is the vertex label on the endpoint farther
than v. If this is the case, then along any path from another vertex to v in
this tree, each label bit can change at most once, so the path length equals
the Hamming distance between labels.
If our input passes all of these tests, it describes a labeled graph in which
graph distances are always greater than or equal to the Hamming distance of
the labels, and in which any two vertices can be connected by a path with
path length equal to the Hamming distance of their labels. Such a graph must
be a partial cube, and the labeling deﬁnes a valid medium structure on the
graph.
The most time consuming steps of the algorithm reside in the application
of Theorem 10.3.3 and the testing of each edge of each shortest path tree;
these steps take total time O(|S|2).
10.4.2 Remark. Eppstein (2007b) describes a simpliﬁed procedure for test-
ing whether an edge-labeled graph describes a medium, that is also based
on applying Theorem 10.3.3. However, the simpliﬁcation is only guaranteed
to work for labels produced by a modiﬁed version of the algorithm of Theo-
rem 10.2.16. By combining Theorem 10.2.16 and Theorem 10.4.1, we can de-
termine whether an unlabeled input graph is a partial cube in time O(|V |2),
as was shown by Eppstein (2007b).
10.5 Recognizing Closed Media
In this section, we consider the problems of determining whether an ori-
ented medium is closed, and of ﬁnding a closed orientation for an unoriented
medium. A naive algorithm for testing whether an orientation is closed would
test each triple S, τ, and τ ′, where S is any state and τ and τ ′ are any two
diﬀerent positive tokens, to determine whether S ̸= Sτ and S ̸= Sτ ′ but
Sτ = Sττ ′. If any triple is found for which all three of these inequalities

10.5 Recognizing Closed Media
219
and equalities are true, then the medium is not closed. However, there are
O(|S| · |T|2) triples to test, leading to a high running time. Our closedness
testing algorithm reduces this time bound by using the adjacency list struc-
ture of our representation and the following lemma to reduce the number of
triples to be tested.
10.5.1 Deﬁnition. We use the notation SE+ to refer to the set of positive
tokens of an oriented medium that are eﬀective for S.
10.5.2 Lemma. In any closed oriented medium (S, T), for any state S,
|SE+| ≤log2 |S|.
Proof. For each P ⊂SE+, let mP be a message formed by concatenating the
tokens in P. Then mP is stepwise eﬀective for S (by the assumption that the
medium is closed), so the positive content of S diﬀers from that of SmP by
exactly the tokens in P, from which it follows that two subsets P ̸= P ′ of
SE+ have SmP ̸= SmP ′. As each subset of SE+ gives rise to a diﬀerent state
in this way, there can be at most |S| possible subsets of SE+, from which the
bound follows.
10.5.3 Remark. It is natural to deﬁne a closedness testing algorithm based
on this property: ﬁrst check whether the input medium satisﬁes Lemma 10.5.2
and, if so, test only those triples S, τ, τ ′ where τ and τ ′ belong to SE+.
There are two drawbacks to this approach: ﬁrst, for media not satisfying
the lemma, we can be sure that they are not closed but we do not ﬁnd an
explicit triple for which closure is violated. And second, to perform the tests
eﬃciently we apparently require a hashed transition table representation of
the medium, and the hash table operations of that representation force us to
use expected-case analysis instead of giving a deterministic worst-case time
bound. We remediate both of these issues with a more sophisticated technique,
described below, that is based on a second property about the number of
eﬀective positive tokens in closed media.
10.5.4 Lemma. In any closed oriented medium, let S be any state and let τ
be a positive token. Then |Sτ E+| ≥|SE+| −1.
Proof. By the deﬁnition of a closed medium, every positive eﬀective token for
S other than τ itself must also be eﬀective for Sτ (whether or not Sτ ̸= S).
10.5.5 Remark. The bound of this lemma need not be tight; see Prob-
lem 10.12. For the case when τ is a negative token, see Problem 10.13.

220
10 Algorithms
10.5.6 Theorem. Given an edge-labeled adjacency list representation of a
medium, and an orientation on that medium, we can determine whether the
medium is closed, and if not ﬁnd a triple S, τ, τ ′ such that τ and τ ′ are
eﬀective on S but τ ′ is not eﬀective on Sτ, in time O(|E| · log |V |).
Proof. We can compute |Sτ E+| for each state S in total time O(m). If some
state S and positive token τ are such that p(Sτ) < p(S)−1, then the medium
is not closed. In this case, we can compare the lists of eﬀective tokens for S
and St in time O(|T|) and ﬁnd a token τ ′ that is eﬀective for S but ineﬀective
for Sτ; S, τ, and τ ′ form the desired triple.
Next, if |Sτ E+| ≥|SE+| −1 is true for all S and positive τ, but some
state has more than log2 |S| positive eﬀective tokens, we can follow a sequence
of positive eﬀective transitions from that state until we ﬁnd a state S with
exactly 1 + ⌊log2 |S|⌋positive eﬀective tokens. We will apply the remainder
of our algorithm to the submedium formed by the states reachable from S
via the positive tokens that are eﬀective on S. This submedium still violates
Lemma 10.5.2, so searching within this submedium will not prevent us from
ﬁnding the triple we desire. This submedium can be constructed algorithmi-
cally in linear time by applying a depth ﬁrst search from S in the adjacency
list representation, following only transitions for token pairs the positive to-
ken of which is eﬀective on S, and copying all searched vertices and edges to
an edge-labeled adjacency list representation of the submedium. By restrict-
ing our attention to this submedium, we can assume without loss of generality
that the number of positive eﬀective tokens at each node is at most log2 |S|+1.
Finally, we make a sorted list of the O(log |S|) positive tokens eﬀective
at each state of the (restricted) medium, in total time O(|E| log log |V |); the
additional doubly-logarithmic factor in this time bound comes from applying
a sorting routine to a collection of lists of logarithmic size, the total length of
which is O(|E|). For each state S, and each positive token τ eﬀective for S,
we merge the two sorted lists for S and Sτ to determine whether the list for
S contains a token τ ′ that is missing from the list for Sτ. If so, we report S,
τ, and τ ′ as the triple that witnesses the fact that the medium is not closed.
Finally, if our medium passes all the tests above, we report that it is closed.
The time for this algorithm is dominated by the times to merge sorted lists;
there are O(|E|) such merges performed (one per positive eﬀective transition)
and each takes time O(log |V |), so the total time is O(|E| log |V |).
Next, we consider the problem of ﬁnding closed orientations for unoriented
media.
10.5.7 Remark. Not every medium has a closed orientation; for instance,
there is no closed orientation of the medium having six states in a cycle.
10.5.8 Lemma. In any medium the number of triples S, τ, τ ′ where τ ̸= τ ′
and where both τ and τ ′ are eﬀective for S is at most min( 1
2|E| · |T|, |V |2).

10.5 Recognizing Closed Media
221
Proof. Exactly 2|E| pairs S, τ have τ active for S. Each such pair can form
a triple with at most |T|/2 tokens τ ′ (because only one of each token-reverse
pair can be eﬀective for S), and each triple comes from two pairs (one for τ
and one for τ ′), so the total number of triples is at most 1
2|E| · |T|.
Each triple S, τ, τ ′ can be associated with the pair of states Sτ, Sτ ′. There
are fewer than 1
2|V |2 pairs of states, and each possible pair of states can only
be associated with two triples: the other triple that can be associated with
the pair Sτ, Sτ ′ is Sττ ′, ˜τ, ˜τ ′. Therefore, the number of triples is at most
twice the number of pairs of states, |V |2.
Since we have separately proved that the number of triples is at most
1
2|E|·|T| and that it is at most |V |2, it must be at most the minimum of these
two quantities.
10.5.9 Remark. The example of the hypercube shows that the bound of
Lemma 10.5.8 cannot be simpliﬁed to O(|S| · |T|), while the example of the
star medium shows that it cannot be simpliﬁed to O(|E| log |V |).
10.5.10 Theorem. If we are given an unoriented medium, we can ﬁnd a
closed orientation, if one exists, or determine that no such orientation exists,
in time O(min(|E| · |T|, |V |2)).
Proof. We translate the problem to an instance of 2-SAT (see, e.g., Aspvall
et al., 1979); that is, a problem in which we are given a boolean formula in the
form of a conjunction, each clause of which is a disjunction of two variables or
negated variables, and must determine whether all variables can be assigned
truth values in such a way as to make the overall formula true.
We do so by creating a Boolean variable for each token in the medium,
where the truth of variable t in a truth assignment for our instance will corre-
spond to the positivity of token τ in an orientation of the medium. By adding
clauses t ∨˜t and ¬t ∨¬˜t, we guarantee that exactly one of the two variables t
and ˜t corresponding to tokens τ and ˜τ is true, so that the truth assignments of
the instance correspond exactly to orientations of the medium. We then add
further clauses ¬t ∨¬t′ for each triple S, τ, τ ′ such that τ and τ ′ are eﬀective
for S but ττ ′ is not stepwise eﬀective. In an orientation corresponding to a
truth assignment satisfying these clauses, τ and τ ′ cannot both be positive,
so triple S, τ, τ ′ will not violate the deﬁnition of a closed orientation. Thus,
our 2-SAT instance will have a satisfying truth assignment if and only if the
medium has a closed orientation, and the closed orientation, if it exists, can
be determined easily from the truth assignment.
We can construct the 2-SAT instance by using a transition table to test
each triple S, τ, and τ ′, where τ and τ ′ belong to the adjacency list of tokens
eﬀective for S. By Lemma 10.5.8 the time for this construction is O(min(|E| ·
|T|, |V |2)). As it has |T| variables, the 2-SAT instance has size O(|T|2), and
can be solved in time proportional to its size as shown by Aspvall et al. (1979).

222
10 Algorithms
10.5.11 Remark. The solvable 2-SAT instances can be characterized in
terms of the nonexistence of a cyclic chain of implications that includes both
a variable and its negation; it would be possible to translate this back into
a characterization of the media having closed orientations, but the resulting
characterization is unsatisfactory. It would be of interest to ﬁnd a more natural
characterization of the media having closed orientations.
10.5.12 Example. We apply the algorithm of Theorem 10.5.10 to the medium
depicted in Figure 2.1. The resulting 2-SAT instance consists of the formula
(τ1 ∨τ2) ∧(¬τ1 ∨¬τ2) ∧
(τ3 ∨τ4) ∧(¬τ3 ∨¬τ4) ∧
(τ5 ∨τ6) ∧(¬τ5 ∨¬τ6) ∧
(¬τ1 ∨¬τ4) ∧(¬τ1 ∨¬τ6),
the ﬁrst six clauses of which enforce that the orientation of each token’s reverse
is the reverse of the token’s orientation. The last two clauses prevent the pairs
τ1, τ4 and τ1, τ6 from being positive in the orientation, as if they were the
triples W, τ1, τ4 or W, τ1, τ6 would violate the deﬁnition of a closed medium.
This 2-SAT instance can be satisﬁed, for instance, by a truth assignment in
which τ1, τ4, and τ6 are false and τ2, τ3, and τ5 are true. This truth assignment
corresponds to the orientation {T+, T−} with T+ = {τ2, τ3, τ5} and T−=
{τ1, τ4, τ6}). The oriented medium formed by this orientation is closed.
10.5.13 Remark. An alternative method for ﬁnding closed orientations is
based on the observation (Theorem 4.1.11) that any closed orientation of
a ﬁnite medium has a unique apex S, a state having no positive eﬀective
transitions, and that an orientation with apex S must be the of the form
{S, T \ S}. We can use Theorem 10.5.6 to test each orientation of this form
and determine whether one is closed. However this does not seem to lead to
a method more eﬃcient than the one described above.
10.6 Black Box Media
A medium may have exponentially many states, relative to its number of
tokens, making storage of all states and transitions infeasible. However, for
many media, a single state can easily be stored, and state transitions can be
constructed algorithmically. The relative ease of storing a single state and per-
forming transitions versus ﬁnding the whole medium can be seen, for instance,
in the medium of linear extensions of a partial order described in Problem 9.3:
one can represent a state as a permutation of elements of a partial order, and
apply a token to a state by attempting the swap of two elements and by test-
ing whether the result is still a linear extension of the partial order, without

10.6 Black Box Media
223
computing or storing the set of all linear extensions. Similarly, for the medium
of acyclic orientations described in Example 9.1.16, one can represent a state
as an orientation for each edge of the given graph, and apply a token to a state
by attempting the reversal of an edge and by testing whether the result is still
an acyclic orientation, without computing or storing the set of all acyclic ori-
entations. More generally, we have discussed in Deﬁnition 4.5.1 the concept of
a base, which may be used to summarize succinctly any closed medium; one
may represent a state in a medium summarized in this way as a union of base
sets, and one may apply a token by adding or removing an element from the
set and testing whether the result is again a union of base sets.
Thus, we would like to design algorithms for media that do not depend on
storing an explicit list of states and state transitions. However, we would like
to do this in as general way as possible, not depending on details of the state
representation. This motivates an oracle-based model of media, similar to the
black box groups from computational group theory (Babai and Szemer´edi,
1984). We are interested here in the limits that a severely restricted input
model such as we give below may place on our ability to compute with media.
Developing algorithms for such a model allows them to be applied very gen-
erally, in cases where it is inconvenient to construct ahead of time an explicit
list of the states and transitions of the medium.
10.6.1 Deﬁnition. We deﬁne a black box medium to be a representation of
a medium consisting of the following parts:
•
A list of the tokens of the medium.
•
A procedure transitionFunction that takes as input the representation
of a state S and a token t, and produces as output the representation of
the state St.
•
The representation of a single state S0.
We require each state to have a unique representation, so that states can be
compared for equality. However the details of the state representation and
transition function of a black box medium are unavailable to an algorithm
that processes a medium of this form.
10.6.2 Example. Media formed by a hyperplane arrangement (cf. Chapter 9)
can be described as black box media as follows. We represent a state (that
is, a chamber of the arrangement) as the set of halfspaces containing it, with
one halfspace bounded by each hyperplane of the arrangement. We represent a
token as an individual halfspace. The transition function takes as input a state
S and a halfspace h, and returns the state formed by replacing the complement
of h by h in the set of halfspaces representing S, if such a state exists, or it
returns S itself if the modiﬁed state would not be part of the arrangement.
To implement the transition function, we need to determine whether a set of
halfspaces has a nonempty intersection; this can be done in polynomial time
by linear programming. Therefore, we can represent this medium as a black
box medium without explicitly constructing all chambers of the arrangement.

224
10 Algorithms
This linear programming test can also be viewed as an example of another
implicit model of a medium, an independence oracle (Karp et al., 1985) in
which we represent a well-graded set family (in our example, a family of
halfspaces) by using a bitmap to represent a set, and perform a transition
by changing a single bit of the bitmap and calling another function (in our
example, the linear programming feasibility test) to determine whether the
modiﬁed set belongs to the family. However, the independence oracle model
provides greater computational power than the black box model; for instance,
given two bitmaps representing well-graded sets S and Q, one can quickly ﬁnd
an eﬀective transition from S that is in the content of Q, by testing bits in
the symmetric diﬀerence of the two bitmaps until ﬁnding one that leads to
another set within the family. In contrast, for the black box model, ﬁnding a
token that gives an eﬀective transition from a state S and is in the content of
another state Q appears to require a much lengthier exploration process.
We can bound the amount of memory required to store a single state
by a parameter s. We denote by T the amount of time required per call to
transitionFunction. In this context, we consider “polynomial time” to mean
time that is polynomial in |T| and T, and “polynomial space” to mean a space
bound that is polynomial in |T| and s.
One of the most basic computational problems for a black box medium is to
ﬁnd all of its possible states. As with any deterministic ﬁnite automaton, one
could list all states by performing a depth ﬁrst traversal of the state transition
graph. However, performing a depth-ﬁrst search eﬃciently requires keeping
track of the set of already-visited states, so that the search can recognize
when it has reached a state that it has already explored, and backtrack rather
than repeatedly exploring the same states. If the medium is large enough to
make an adjacency list representation infeasibly large, then it would also likely
be infeasible to store this set of already-visited nodes. As we now show, it is
possible instead to traverse all states of a black box medium, using an amount
of storage limited to only a constant number of states.
The main idea behind our traversal algorithm is to use a modiﬁed version
of the reverse search procedure of Avis and Fukuda (1996). The reverse search
procedure allows one to list all the states of a general state transition system,
as long as one can deﬁne canonical paths: sequences of transitions from each
state to an initially given state S0 such that the union of the transitions on
all the paths forms a spanning tree of the state space, the canonical path tree.
If one can quickly determine whether a transition belongs to the canonical
path tree, then one can list the states by traversing this tree, ignoring the
transitions that do not form edges in the tree. In our case, canonical paths
can be constructed from the orientation (
S0, T \ 
S0). If we have an ordered
list of the positive tokens of this orientation, then a step in a canonical path
from state S can be found by taking the ﬁrst token in the list that is eﬀective
on S. The diﬃculty, however, is that we are not given the orientation, and
cannot construct it without searching the medium, the task we are trying to
solve. Fortunately, we can interleave the construction of the orientation and

10.6 Black Box Media
225
the enumeration of states, in a way that allows the reverse search algorithm
to proceed, taking polynomial time per state and using polynomial space.
10.6.3 Theorem. If we are given a black box medium, we can list all states
of the medium in time O(|S| · |T|2T) and space O(s + |T|).
Proof. We perform the reverse search procedure described above, building a
list of positive tokens in the orientation deﬁned by S0 and simultaneously
searching the tree of canonical paths; the canonical path from a state to S0 is
found by applying the ﬁrst eﬀective token stored in the list being built. The
data stored by the algorithm consists of the current state S in the search, the
list of positive tokens discovered so far, and a pointer to the ﬁrst token τ in
this list for which we have not yet searched transition Sτ. At any point in the
algorithm, the tokens on the canonical path from the current state S to S0
will have already been included in our list of positive tokens. Initially, the list
of positive tokens is empty, S = S0, and τ is the ﬁrst token in the list.
At each step of the algorithm, we test transition Sτ as follows: if τ is
already listed in the list of positive tokens, it cannot be the reverse of a step
in a canonical path, and we set τ to the next token in the list of all tokens.
Similarly, if Sτ is ineﬀective we set τ to the next token. If τ is eﬀective, then
we search the list of tokens for the reverse token ˜τ satisfying Sτ ˜τ = S. The
path formed by composing the transition from Sτ back to S with the canonical
path from S to S0 must correspond to a concise message (otherwise it would
include τ and τ would have been already included in the list of positive tokens)
so ˜τ must be positive; we include it in the list of positive tokens. We then check
whether ˜τ is the ﬁrst listed positive token that is eﬀective for Sτ. If it is the
ﬁrst eﬀective positive token, then the transition from S to Sτ is the reverse
of a canonical step, so we set S to Sτ, reset τ to the token at the beginning
of the token list, output state Sτ, and continue searching at the new state. If
not, we set τ to the next token in the list and continue searching from t.
Whenever the token τ advances past the end of the list of tokens in our
search, this indicates that we have exhausted all transitions from the state S.
So, we return to the parent of S in the canonical path tree, by searching the
list of positive tokens for the ﬁrst one that is eﬀective on S. We must then
also reset the token τ to the appropriate position in the list of tokens. We
do this by searching sequentially through the list of tokens for the one that
caused the parent of S to transition to S. When we advance past the end of
the list of tokens for state S0, the search is complete.
Each step maintains the invariants discussed above. By induction on the
lengths of canonical paths, each state is output exactly once, when it is found
by the reverse of a canonical step from its parent in the canonical path tree.
The space bound is easy to compute from the set of data stored by the algo-
rithm. For each eﬀective transition τ from each state S, we perform O(|T|)
calls to the transition function: one scan of the token list to ﬁnd the reverse
˜τ and determine whether Sτ is canonical, a second scan of the token list to
ﬁnd the eﬀective transitions from Sτ (if Sτ was canonical), and a third scan

226
10 Algorithms
of the token list to ﬁnd the correct position of τ after returning from Sτ to S.
Therefore, the total number of calls to the transition function is O(|T|2) per
state, which dominates the total running time of the algorithm.
Table 10.3. Python implementation of reverse search for black box media states.
def mediumStates(s0, tokens, transitionFunction):
”””
List all states of a medium.
The input is a starting state s0, a list of tokens, and the transition
function (state ,token)−>state of a medium. The output is the sequence of
states of the medium. We do not assume that the tokens are organized into
reverse pairs . The memory usage consists of a constant number of states,
together with additional data linear in the number of tokens. The algorithm
is a stackless version of the reverse search technique of Avis and Fukuda.
”””
tokens = list(tokens) # make sure we can reuse the list of tokens
positiveTokens = [] # ordered list of tokens on concise messages to s0
def step(state, default=None):
”””
Find the ﬁrst token on a concise message from state to s0,
and return the next state on that path.
If no token is found, return
default after searching for a token that takes the given state to it .
”””
for t in positiveTokens:
x = transitionFunction(state, t)
if x != state:
return x
positiveTokens.extend([t for t in tokens
if transitionFunction(state, t) == default])
return default
state = s0
yield state
tokenSequence = iter(tokens)
while True:
try:
x = transitionFunction(state, tokenSequence.next())
if x != state and x != s0 and step(x,state) == state:
state = x
yield state
tokenSequence = iter(tokens)
except StopIteration:
# We reach here after exhausting all tokens for the current state .
# Backtrack to the parent and reset the token sequence pointer.
if state == s0:
return
parent = step(state)
tokenSequence = iter(tokens)
for token in tokenSequence:
if transitionFunction(parent, token) == state:
break
state = parent

Problems for Chapter 10
227
Table 10.3 displays an implementation of our reverse search procedure
in the Python programming language. The yield keyword triggers Python’s
simple generator protocol, which creates an iterator object suitable for use in
for-loops and similar contexts and returns it from each call to mediumStates.
Problems
10.1 Let G = (V, E) be a partial cube graph. Prove that |E| = 1
2|V | log2 |V |
if and only if G is a hypercube.
10.2 For each of the following pairs of functions, determine which of the two
would be preferable as the running time bound of an algorithm.
(i) |S| log |S| versus |S| · |T|.
(ii) |S| · |T| versus |S|2.
(iii) |V |2 log |V | versus |V | · |E|.
10.3 Draw the transition table for the medium shown in Figure 6.2(A).
10.4 List the key-value pairs for the hashed transition table representation
of the medium shown in Figure 6.2(A).
10.5 Draw the labeled adjacency list representation for the medium shown
in Figure 6.2(A).
10.6 Draw the transition table for the medium shown in Figure 6.2(B).
10.7 List the key-value pairs for the hashed transition table representation
of the medium shown in Figure 6.2(B).
10.8 Draw the labeled adjacency list representation for the medium shown
in Figure 6.2(B).
10.9 Let S be the root of a star medium (S, T), and let m be a message such
that applying m to S produces a sequence of states that includes all states of
S. Prove that the number of tokens in m is at least 2|S| −3.
10.10 Let S be a state in a medium M = (S, T), such that either M is not a
star or S is not its root. Prove that there exists a message m of fewer than
2|S| −3 tokens, such that applying m to S produces a sequence of states that
includes all states of S.

228
10 Algorithms
10.11 Complete Example 10.3.4 by describing the conﬁguration of the algo-
rithm’s data structures after each of the remaining traversal steps until the
depth ﬁrst traversal returns to the original starting vertex.
10.12 Give an example of a closed oriented medium, a state S in that
medium, and a positive token τ, such that τ is eﬀective for S and |Sτ E+| >
|SE+| −1.
10.13 Let S be a state of a closed oriented medium and let τ be a negative
token. Prove that |Sτ E+| ≤|SE+| + 1.

11
Visualization of Media
In this chapter, following Eppstein (2005a), we describe methods for the pla-
nar layout of ﬁnite media and partial cube graphs in a way that makes the
medium structure apparent to the human viewer. Our focus is on graph draw-
ing techniques that may be eﬃciently implemented in a computer algorithm.
The algorithms we consider are based on two principles: embedding the state
transition graph in a low-dimensional integer lattice (as described in Chap-
ter 8) and projecting the lattice onto the plane, or drawing the medium as a
zonotopal tiling. After this material, we describe some more specialized algo-
rithms for drawing learning spaces, as in Eppstein (2006).
The deﬁnition of a graph drawing, below, is essentially the same as that
in Di Battista et al. (1999).
11.0.1 Deﬁnition. Let f be a continuous one-to-one function from the closed
interval [0, 1] to the plane R2. Then the image under f of the open interval
(0, 1) is a simple curve, with endpoints f(0) and f(1). A drawing of a graph
G is an assignment of a point for each vertex of G, and a simple curve for each
edge of G, such that an edge (u, v) is assigned to a curve that has the points
assigned to u and v as its endpoints. As a shorthand, we refer to a drawing of
the graph of a medium M as a drawing of M.
A straight-line drawing is a drawing in which each curve is an open line
segment. A planar drawing is a drawing in which the points assigned to the
vertices and the curves assigned to the edges are all disjoint from each other. A
classical result in this area is F´ary’s theorem (e.g., see section 4.10 of Di Bat-
tista et al., 1999) which states that any ﬁnite graph that has a planar drawing
has a planar straight-line drawing.
If U is the union of the points and curves in a planar drawing, then a
face of the drawing is a connected component of the complement of U. We
will need to distinguish between bounded faces of drawings (that is, faces
contained within a bounded region of the plane) and unbounded faces. Any
planar drawing of a ﬁnite graph will have exactly one unbounded face, but
drawings of inﬁnite graphs may have multiple unbounded faces, or no un-

230
11 Visualization of Media
bounded faces. An exterior edge or exterior vertex of a drawing is an edge or
vertex that lies on the boundary of an unbounded face, and an interior edge
or interior vertex is an edge or vertex that is not exterior.
11.1 Lattice Dimension
As we describe in Chapter 8, the minimum dimension of an integer lattice into
which a given medium may be isometrically embedded has a simple charac-
terization involving graph matching, from which it follows that the dimension
(and a minimum-dimension embedding) may be constructed eﬃciently. If the
lattice dimension of a medium is low, we may be able to use the embedding
directly as part of an eﬀective drawing algorithm. For instance, if a medium
M can be embedded isometrically onto the planar integer lattice Z2, then
we can use the lattice positions as vertex coordinates of a drawing in which
each edge is a vertical or horizontal unit segment. As we describe below, it is
sometimes also possible to ﬁnd planar drawings from three-dimensional lattice
embeddings.
11.1.1 Deﬁnition. The isometric projection of a three dimensional lattice is
formed by mapping each point (x, y, z) onto the point

2x −y −z
3
, 2y −x −z
3
, 2z −x −z
3

on the plane x+y +z = 0; that is, it is the vector projection perpendicular to
the vector (1, 1, 1). The name, “isometric projection,” indicates that the unit
vectors of the lattice are mapped to vectors that have the same lengths as each
other; it has little to do with isometry or projection in the media-theoretic
senses.
11.1.2 Remark. If M can be embedded isometrically onto the cubic lattice
Z3, in such a way that the isometric projection of Z3 maps the states of
M to distinct planar points, then the straight-line drawing with these point
placements is planar and has unit length edges meeting each other at 60◦and
120◦angles. For instance, Figure 9.4 can be viewed in this way as a drawing
formed by an isometric projection of a three-dimensional lattice embedding.
We now brieﬂy describe our algorithm for ﬁnding low-dimensional lattice
embeddings more generally.
11.1.3 Theorem. Suppose that we are given a ﬁnite medium M = (S, T),
and a hypercube isometry f : G →{0, 1}τ, where G is the graph of M. Then
we can compute in time O(|S| · |T|2) the lattice dimension d of G, and in the
same time construct a lattice isometry g : G →Zd.

11.2 Drawing High-Dimensional Lattice Graphs
231
Proof. We construct the semicube graph Sc(G) as deﬁned in Chapter 8 directly
from the deﬁnition: there is one semicube per token in T, and we can test
whether any two semicubes should be connected by an edge in the semicube
graph in time O(|S|), so the total time for this step is O(|S|·|T|2). We then use
a maximum matching algorithm to ﬁnd a matching with the largest possible
number of edges in Sc(G); as Micali and Vazirani (1980) show, this can be
done in time O(|T|2.5). We can then transform the matching in Sc(G) to a
collection of d paths in time O(|S|·|T|) by adding to the matching an edge from
each semicube to its complement. The dth coordinate of a vertex in the lattice
embedding equals the number of semicubes that contain the vertex in even
positions along the dth path. The total time is dominated by the O(|S| · |T|2)
bound for ﬁnding Sc(G).
It is essential for the eﬃciency of this technique that the embedding of
the medium into Zd be isometric. Even for a tree (a very special case of a
partial cube) it is NP-complete to ﬁnd an embedding into Z2 with unit length
edges that maps distinct vertices to distinct lattice points but is not otherwise
required to be distance-preserving (Bhatt and Cosmodakis, 1987).
We can use this embedding algorithm as part of a graph drawing system,
by embedding our input medium in the lattice of the lowest possible dimension
and then projecting that lattice onto the plane. For two-dimensional lattices,
no projection is needed, and we have already discussed in Remark 11.1.2 the
projection of certain three-dimensional integer lattices onto two-dimensional
planar drawings. We discuss more general techniques for lattice projection in
the next section.
11.2 Drawing High-Dimensional Lattice Graphs
Two-dimensional lattice embeddings of media, and some three-dimensional
embeddings, lead to planar graph drawings with all edges short and all an-
gles bounded away from zero. However, we are interested in drawing media
that may not have such well-behaved lattice embeddings. We describe here a
method for transforming any lattice embedding of any medium into a drawing
with the following properties:
[V1] All vertices are assigned distinct integer coordinates in Z2.
[V2] All edges are drawn as straight line segments.
[V3] No edge passes closer than unit distance to a vertex that is not one of
its endpoints.
[V4] The line segments representing two edges of the drawing are translates
of each other if and only if the two edges are parallel in the lattice
embedding.

232
11 Visualization of Media
[V5] The medium corresponding to a Cartesian product of intervals of N,
[a0, b0] × [a1, b1] × · · · [ad−1, bd−1] is drawn in area O(n2), where n is
the number of its states.
Because of Property [V4], the lattice embedding and hence the medium
structure of the state transition graph can be read from the drawing. To
draw a lattice-embedded medium, we map Zd to Z2 linearly, by choosing
two particular vectors X and Y ∈Zd, and using these vectors to map any
point p ∈Zd to the point (X · p, Y · p) ∈Z2 (here “·” denotes the inner
product of vectors). We now describe how to choose these vectors X and Y in
order to achieve the desired properties of our drawing. If L ⊆Zd is the set of
vertex placements in the lattice embedding of our input medium, deﬁne a slice
Li,j = {p ∈L pi = j} to be the subset of vertices having ith coordinate equal
to j. We choose the coordinates Xi sequentially, from smaller i to larger, so
that all slices Li,j are separated from each other in the range of x-coordinates
they are placed in. Speciﬁcally, set X0 = 0. Then, for i > 0, deﬁne
Xi = max
j

min
p∈Li,j
i−1

k=0
Xkpk −
max
q∈Li,j−1
i−1

k=0
Xkqk

,
where the outer maximization is over all j such that Li,j and Li,j−1 are both
nonempty. We deﬁne Y similarly, but we choose its coordinates in the opposite
order, from larger i to smaller: Yd−1 = 0, and
Yi = max
j

min
p∈Li,j
d−1

k=i+1
Xkpk −
max
q∈Li,j−1
d−1

k=i+1
Xkqk

.
11.2.1 Theorem. The projection method described above satisﬁes proper-
ties [V1]–[V5]. The method’s running time is O(|S| · |T|2).
Proof. Property [V2] and Property [V4] follow immediately from the fact that
our drawing is formed by projecting Zd linearly onto Z2, and from the fact
that the formulas used to calculate X and Y assign diﬀerent values to diﬀerent
coordinates of these vectors.
All vertices are assigned distinct coordinates (Property [V1]): for, if ver-
tices p and q diﬀer in the ith coordinates of their lattice embeddings, they
belong to diﬀerent slices Li,j and Li,j′ and are assigned X coordinates that
diﬀer by at least Xi (unless i = Xi = 0 in which case their Y coordinates
diﬀer by at least Yi).
The separation between vertices and edges (Property [V3]) is almost
equally easy to verify: consider the case of three vertices p, q, and r, with
an edge {p, q} to be separated from r. Since p and q are connected by an
edge, their lattice embeddings must diﬀer in only a single coordinate i. If r
diﬀers from p and q only in the same coordinate, it is separated from edge
{p, q} by a multiple of (Xi, Yi). Otherwise, there is some coordinate i′ ̸= i

11.2 Drawing High-Dimensional Lattice Graphs
233
in which r diﬀers from both p and q. If i′ > i, the construction ensures that
the slice Li′,j containing pq is well separated in the x-coordinate from the
slice Li′,j′ containing r, and if i′ < i these slices are well separated in the y
coordinate.
Finally, we consider Property [V5]. For Cartesian products of intervals, in
the formula for Xi, the value for the subexpression minp∈Li,j
i−1
k=0 Xkpk is
the same for all j considered in the outer maximization, and the value for the
subexpression maxq∈Li,j−1
i−1
k=0 Xkqk is also the same for all j considered in
the outer maximization, because the slices are all just translates of each other.
Therefore, there is no gap in x-coordinates between vertex placements of each
successive slice of the medium. Since our drawings of these media have vertices
occupying contiguous integer x coordinates and (by a symmetric argument)
y coordinates, the total area is at most n2.
The time for implementing this method is dominated by that for ﬁnding a
minimum-dimension lattice embedding of the input graph, which is bounded
as stated in Theorem 11.1.3.
Figure 11.1. Lattice drawing of six-dimensional hypercube.
11.2.2 Example. When applied to a hypercube, the coordinates Xi become
powers of two, and this vertex placement algorithm produces a uniform place-
ment of vertices (Figure 11.1) closely related to the Hammersley point set
commonly used in numerical computation and computer graphics in view of
its low discrepancy properties (Wong et al., 1997).

234
11 Visualization of Media
Figure 11.2. Lattice drawings of four irregular media with three-dimensional lat-
tice embeddings (from Eppstein, 2005b). The bottom left drawing is of a medium
isomorphic to the weak ordering medium previously shown in a more symmetrical
form in Figure 9.9.
11.2.3 Example. Figure 11.2 provides several additional examples of media
drawn by this lattice projection method, including another view of the medium
of weak orders from Example 9.4.2.
11.3 Region Graphs of Line Arrangements
We now turn our attention from drawing methods that apply to all media,
and instead consider methods that work for speciﬁc types of media. In this
section, we describe a form of planar graph duality that can be applied to
ﬁnd straight-line planar drawings for the region graphs of line arrangements
in R2.
11.3.1 Deﬁnition. Suppose D is a planar drawing of a graph, in which each
edge separates two distinct faces, and R is the union of the closures of the
bounded faces of D. In this case we say that D is a tiling of R, and that the
closure of each face of D is a tile of the tiling. A mosaic is a tiling of R2 in
which all faces are regular polygons.
A polygon P is centrally symmetric if it is a translate of its pointwise
reﬂection through the origin. For example a regular n-gon is centrally sym-
metric if and only if n is even. A zonotopal tiling is a planar straight-line
graph drawing in which each bounded face is a centrally symmetric polygon.
For additional tiling terminology, results, and further references, see, for
instance, Gr¨unbaum and Shephard (1987) and Senechal (1995). For more on
ﬁnite zonotopal tilings see e.g. Felsner and Weil (2001).

11.3 Region Graphs of Line Arrangements
235
Figure 11.3. A line arrangement (left), with a symmetric convex polygon corre-
sponding to each of its vertices; joining these polygons along their edges forms a
zonotopal tiling (right).
We now describe a construction for zonotopal tilings as drawings of the
region graphs of certain arrangements of lines. Subsequently, in Section 11.4,
we will use a similar construction to precisely characterize the graphs that
can be drawn as zonotopal tilings, as region graphs of more general kinds of
arrangements. In Section 11.5, we will use zonotopal tilings constructed in this
way as part of algorithms for visualizing a class of media more general than
those formed from line arrangements, and in Section 11.6 we will examine a
special subclass of these graphs that correspond to learning spaces.
Let A be a locally ﬁnite line arrangement. Form a set of centrally symmet-
ric convex polygons, one per vertex of the arrangement, with unit length sides
perpendicular to the lines meeting at that vertex. Then, form a cell complex
by gluing together two such polygons along an edge whenever they correspond
to adjacent vertices along the same line of the arrangement. It can be seen
that this cell complex has cells which meet at interior vertices (correspond-
ing to bounded cells of the arrangement) at angles totaling 2π, while each
boundary vertex of the complex (corresponding to an unbounded cell of the
arrangement) has angles totaling at most π. Therefore, it forms a drawing of
the region graph of A that covers a convex subset of the plane by tiles, each
of which is a centrally symmetric and strictly convex polygon.
This construction, which is shown in Figure 11.3, can also be performed
in the following equivalent way. Choose a vertex of the region graph of the
arrangement to be placed at the origin of the plane. Then, for each other
vertex v, ﬁnd a straight path in the graph from the origin to v, and set the co-
ordinates of v to be the sum of unit vectors perpendicular to the arrangement
lines corresponding to the edges in the straight path. The axioms deﬁning a
medium can be used to show that these coordinates are independent of the
choice of straight path to v, and that the choice of base point aﬀects the
overall vertex placement only by a translation.

236
11 Visualization of Media
Figure 11.4. A 2-grid (left, dashed), and a 3-grid (right, dashed), superimposed on
their dual zonotopal tilings (solid).
Figure 11.5. Another 3-grid and its dual zonotopal tiling.
11.3.2 Example. A line arrangement consisting of k inﬁnite families of par-
allel lines, spaced at unit distance within each family, is called a k multigrid.
The zonotopal tiling formed by drawing the region graph of a 2-multigrid is
just the usual periodic tiling of the plane by edge-to-edge rhombi or squares
(Figure 11.4, left). The tiling of the plane by edge-to-edge equilateral triangles
can be viewed as a 3-multigrid, the drawing of the region graph of which is
a zonotopal tiling of the plane by regular hexagons (Figure 11.4, right). By
Theorem 9.1.9, this hexagonal lattice is a drawing of an inﬁnite partial cube.
In fact, this lattice is isometrically embeddable into the graph of the lattice
Z3 (Deza and Shtogrin, 2002).

11.3 Region Graphs of Line Arrangements
237
Figure 11.6. The mosaic of octagons and squares (left), and the mosaic of do-
decagons, hexagons, and squares (right).
Figure 11.7. A portion of a Penrose rhombic tiling (left), and a pentagrid (right).
11.3.3 Example. Another 3-grid is shown in Figure 11.5. The line arrange-
ment itself deﬁnes a mosaic of hexagons and triangles, but the drawing of
its region graph shown in this ﬁgure has faces that are rhombs. It is almost
obvious from the drawing that the region graph is isometrically embeddable
into Z3. Note that graphs shown in Figures 1.5 and 9.3 are ﬁnite isometric
subgraphs of the graph in Figure 11.5.
11.3.4 Example. Two more mosaics, of octagons and squares and of do-
decagons, hexagons, and squares, are shown in Figures 11.6. These are again
drawings of partial cubes, as they are drawings of region graphs of line ar-
rangements with regularly spaced lines having four and six diﬀerent slopes
respectively. However, these arrangements are not multigrids, because lines of
diﬀerent slopes are spaced at diﬀerent distances.
11.3.5 Example. A more sophisticated example of a tiling that is the draw-
ing of an inﬁnite partial cube is given by a Penrose rhombic tiling shown in
Figure 11.7(left). A construction suggested by de Bruijn (1981) demonstrates
that these kind of tilings can be formed from the region graphs of a partic-
ular class of line arrangements known as pentagrids: 5-grids such as the one
in Figure 11.7(right), having equal angles between each pair of parallel line

238
11 Visualization of Media
Figure 11.8. A zonotopal tiling that is not the region graph of a line arrangement.
families, and satisfying certain additional constraints on the placement of the
grids relative to each other. It follows implicitly from de Bruijn (1981) that
these rhombic tilings are isometrically embeddable in Z5 (see also Deza and
Shtogrin, 2002).
11.4 Pseudoline Arrangements
As described in the previous section, every line arrangement leads to a zono-
topal tiling of a convex polygon. The reverse is not true; some zonotopal
tilings, even of convex polygons, are not drawings of region graphs of line
arrangements (e.g., Figure 11.8). In general, such tilings arise from non-
stretchable pseudoline arrangements; see, e.g., Gr¨unbaum (1972). However,
Eppstein (2005a) (who we follow here) characterized ﬁnite zonotopal tilings
in terms of a generalization of line arrangements, known as weak pseudoline
arrangements. The signiﬁcance of these results for media is that it will lead to
techniques for visualizing media by drawing them in the plane as zonotopal
tilings: the characterization we give in this section for these tilings is the basis
for the visualization algorithms described later in this chapter.

11.4 Pseudoline Arrangements
239
11.4.1 Deﬁnition. Following Shor (1991), we deﬁne a pseudoline to be the
image of a line under a homeomorphism of the plane (see Remark 11.4.2).
That is, if f is a continuous one-to-one mapping of the plane to itself, and ℓis
a line in the plane, then f(ℓ) is a pseudoline. It follows from this deﬁnition that
a pseudoline is a non-self-crossing curve in the plane that extends to inﬁnity
in both directions and partitions the plane into two parts. A weak pseudoline
arrangement is a collection of ﬁnitely many pseudolines, such that any pair
of pseudolines has at most one point of intersection, and such that if any two
pseudolines intersect then they cross properly at their intersection point. Weak
arrangements were studied by de Fraysseix and Ossona de Mendez (2004); they
generalize both pseudoline arrangements (in which each pair of pseudolines
must cross; see, e.g., Gr¨unbaum, 1972) and hyperbolic line arrangements, and
are a special case of extendible pseudosegment arrangements (Chan, 2003).
A region of a weak pseudoline arrangement A is a connected component
of R2 \ A. The region graph of a weak pseudoline arrangement A is deﬁned
analogously to that of a line arrangement, as having a vertex for each region
and an edge between the vertices corresponding to any two regions that are
separated by a single pseudoline.
11.4.2 Remark. There is considerable disagreement in the mathematical lit-
erature over the proper deﬁnition of a pseudoline. Two common deﬁnitions
are, ﬁrst, that a pseudoline is an uncontractible simple closed curve in the
projective plane (e.g., Gr¨unbaum, 1972), or, second, that a pseudoline is the
monotone curve formed as the graph of a continuous function y = f(x) in the
(x, y) plane (e.g., Edelsbrunner, 1987). Berman (2007) suggests as an alterna-
tive deﬁnition that a pseudoline is the result of replacing a bounded segment
of a line by a simple curve that does not cross the rest of the line. None of these
deﬁnitions is suitable for deﬁning the weak pseudoline arrangements consid-
ered here, as they do not allow regions of the plane to be bounded by more
than two nonintersecting pseudolines. Instead, de Fraysseix and Ossona de
Mendez (2004) deﬁne a pseudoline as a subset of the plane homeomorphic to
the real line, but their deﬁnition is overbroad as it allows curves that do not
separate the plane into two components.
11.4.3 Lemma. Every zonotopal tiling with ﬁnitely many tiles is a drawing
of the region graph of a weak pseudoline arrangement.
Proof. Draw a collection of line segments connecting the opposite pairs of
edge midpoints in each bounded face of the drawing, as shown in Figure 11.9.
These segments meet up at their endpoints to form piecewise-linear curves
in the plane; in the unbounded face, extend these curves to inﬁnity without
adding any additional crossings.
Each of these curves passes through a family of parallel edges of the zono-
topal tiling. Any crossing between these curves occurs within a tile of the

240
11 Visualization of Media
Figure 11.9. Converting a zonotopal tiling to a weak pseudoline arrangement
(from Eppstein (2005a)).
tiling, between two line segments that pass through pairs of tiling edges with
diﬀerent slopes; in particular, this implies that no curve can cross itself, so each
curve is a pseudoline. However, we must still show that any two pseudolines
cross at most once, so that they form a weak pseudoline arrangement.
We may rotate the plane if necessary so no tiling edge is vertical. Each
pseudoline then partitions the plane into a left side (the side containing the
leftmost vertices of the tiles it passes through) and a right side (the side
containing the rightmost vertices of the tiles it passes through). The boundary
of each tile can be partitioned at the leftmost and rightmost vertices into a top
boundary and bottom boundary. We view each pseudoline as being oriented
from the point it enters the tile on the bottom boundary towards the point
it exits the tile on the top boundary; this orientation is consistent with our
deﬁnition of the left and right sides of the pseudoline.
With this choice, suppose that a curve c1, passing through a family of
tiling edges with slope s1, crosses curve c2, passing through a family of tiling
edges with slope s2. Necessarily, s1 ̸= s2; assume s1 > s2. The points of c1
that occur earlier than the crossing point in the orientation of c1 belong to the
right side of c2, and the points of c2 that occur later than the crossing point
belong to the left side of c2. Similarly, the points of c2 earlier than the crossing
point belong to the left side of c1, and the points of c2 later than the crossing
point belong to the right side of c1. There is no way for these curves to switch
sides in this way other than at a crossing, so c1 and c2 can cross only once.
This argument applies to any pair of pseudolines in the arrangement, so each
pair crosses at most once and the result is a weak pseudoline arrangement.
Our tiling is the region graph of this arrangement.
To prove a converse result, we need some technical material on cyclic
orders.

11.4 Pseudoline Arrangements
241
11.4.4 Deﬁnition. A cyclic order on a set S is an assignment of a value ±1
to every ordered triple of distinct elements from S, such that:
1. The value assigned to (a, b, c) equals that assigned to (b, c, a) and (c, a, b),
and is the negation of the value assigned to (a, c, b), (b, a, c), and (c, b, a).
2. For any four distinct elements a, b, c, and d, exactly one of (a, d, b), (b, d, c),
and (c, d, a) is assigned the same value as (a, b, c).
If (a, b, c) is assigned +1, we say that this triple is in clockwise order, while if
it is assigned −1, we say that it is counterclockwise.
11.4.5 Example. Let S be any subset of points on a unit circle in the Carte-
sian plane, and assign (a, b, c) the value +1 if the arc of the circle extending
clockwise from a to c contains b. Then this is assignment is a cyclic order
on S.
For ﬁnite sets, cyclic orders may equivalently be deﬁned in terms of di-
rected graphs:
11.4.6 Lemma. Let S be a ﬁnite set with a cyclic order, with |S| ≥3, and
form a graph G having the elements of S as vertices, with a directed edge
from a to b if there is no c in the order for which (a, c, b) is assigned +1. Then
G is a directed cycle, and any triple (a, b, c) is assigned +1 in the cyclic order
if and only if there is a simple directed path from a to c in G that passes
through b.
Proof. If |S| = 3, with (a, b, c) assigned +1, the axioms deﬁning a cyclic order
show that the graph contains edges ab, bc, and ca, and has the property
described. Otherwise, let x be any member of S; by induction, there exists a
graph G′ describing the cyclic order on the smaller set S′ = S \{x}. It follows
from the axioms deﬁning a cyclic order that there is a unique edge yz of G′
for which (y, x, z) is assigned +1; replacing edge yz by a path of two edges yx
and xz forms the required graph G for S.
11.4.7 Lemma. Let S be any countable set with a cyclic order. Then there
exists a function f that maps elements of S to distinct points on the unit
circle, such that the values assigned to (a, b, c) and (f(a), f(b), f(c)) are equal
for every a, b, and c.
Proof. As S is countable, we can assume that its elements form a sequence
xi, i = 0, 1, 2, . . . . We will ﬁx the values of f(xi) in the ordering given by
this sequence. Thus, suppose that we have already ﬁxed all f(xj) for j < i,
and now wish to choose a value for f(xi). The points f(xj), j < i, form a
polygon, the edges of which form the graph G for these points described by
Lemma 11.4.6. As in the proof of that lemma, there is a unique edge f(a)f(b)
of this polygon such that (a, xi, b) is assigned +1 in the cyclic order. We
set f(xi) to equal the midpoint of the circular arc from f(a) to f(b); from

242
11 Visualization of Media
Lemma 11.4.6, this can be seen to preserve the cyclic ordering of all triples
involving points (xi, xj, xk) with j, k < i.
11.4.8 Lemma. Let A be a weak pseudoline arrangement, and partition each
pseudoline of A into two rays. Then there exists a cyclic ordering on the rays,
such that two pseudolines ℓand ℓ′ cross if and only if the rays r1, r2, r′
1, and
r′
2 into which they are partitioned occur in the cyclic order (r1, r′
1, r2, r′
2) or
(r1, r′
2, r2, r′
1).
Proof. To determine the cyclic ordering of a triple of rays (a, b, c), we consider
the subarrangement A′ formed by the (at most three) pseudolines containing
these rays. A′ forms a drawing with at most six rays; each ray of a, b, and c
coincides except for a ﬁnite portion of its length with one of the rays of the
drawing. So we may determine the cyclic ordering of (a, b, c) from the order
in which the rays of the drawing extend to inﬁnity.
11.4.9 Lemma. The region graph of any weak pseudoline arrangement can
be drawn as a zonotopal tiling.
Proof. We mimic the construction of a zonotopal tiling from a line arrange-
ment, by choosing arbitrarily a vertex r0 of the region graph of the arrange-
ment to place at the origin, forming a unit vector vℓfor each line ℓof the ar-
rangement, and placing each vertex v of the region graph at the point formed
by summing the vectors corresponding to edges of the shortest path from v
to v0 in the region graph. We then draw a line segment between each pair of
vertex placements corresponding to adjacent regions in the region graph.
To ﬁnish the description of the construction, we need to describe how to
choose the vector vℓ. By Lemma 11.4.8, the inﬁnite ends of the pseudolines
extend to inﬁnity in a consistent circular ordering, so by Lemma 11.4.7 we may
assign to each pseudoline ℓtwo points pℓ,0 and pℓ,1 on the unit circle, consistent
with that ordering, such that no two pseudolines are assigned the same point,
and such that two pseudolines ℓand ℓ′ cross if and only if their assigned points
appear in the cyclic order pℓ,0, pℓ′,0, pℓ,1, pℓ′,1 or its reverse. We number these
points in such a way that, if ℓis oriented from the end corresponding to pℓ,0
to the end corresponding to pℓ,1, the region corresponding to v0 is on the right
side of this oriented curve. We then let vℓbe a unit vector formed by scaling
the vector pℓ,1 −pℓ,0.
As we now show, this placement of vertices corresponds to a planar
straight-line drawing of the region graph in which each face has as its bound-
ary a non-self-intersecting polygon and in which the bounded faces are cen-
trally symmetric polygons; thus, it is a zonotopal tiling. First, we describe
the bounded faces. If c is a point where two or more pseudolines of the ar-
rangement meet, the drawing constructed as above contains a polygon having
vertices corresponding to the regions meeting at c. The exterior angle at each
successive vertex of this polygon equals the angle between successive lines

11.4 Pseudoline Arrangements
243
pℓ,0pℓ,1, from which it follows that this polygon is convex and centrally sym-
metric; it will form a face in our drawing. A similar argument shows that
the angles of adjacent pairs of edges around each vertex in our drawing of
the region graph add to 2π. Thus, our drawing is locally planar. However,
we still must verify that the unbounded face of the drawing is drawn in a
non-self-crossing way, as that does not follow from the above assertions.
The unbounded face of the drawing corresponds to the cyclic sequence of
unbounded regions in the arrangement, which are separated by unbounded
arcs of pseudolines. This sequence of unbounded regions corresponds to a
polygonal chain of vertices in our drawing; we must verify that this polygonal
chain f does not cross itself. To verify this, we prove a stronger property:
that, for each point q on an edge e of f, there is a ray rq with q as its starting
point that extends to inﬁnity without crossing any other edge or vertex of the
drawing. To ﬁnd rq, suppose that e belongs to an edge of the region graph
corresponding to a pair of regions separated by an unbounded arc of pseudoline
ℓ, corresponding to the point pℓ,0. We let r be a ray starting at pℓ,0, tangent
to the unit circle in a clockwise direction, and form rq by translating r so that
it starts at q instead of at pℓ,0. Then no other edge e′ of f, corresponding to
a pair of regions separated by pseudoline ℓ′, can block rq, because to do so
it would have to have a slope inconsistent with our choice of pℓ′,0 and pℓ′
1:
the most extreme slopes possible for e′ are slightly to the clockwise of rq,
for an edge e′ counterclockwise of e around f for which pℓ′,0 and pℓ′
1 are both
clockwise of and near pℓ,0, or slightly to the counterclockwise of rq, for an edge
e′ clockwise of e around f for which pℓ′,0 and pℓ′
1 are both counterclockwise
of and near pℓ,0.
As our placement of the vertices of the region graph can be represented
as a collection of faces, each faces non-self-crossing and glued together in a
non-self-crossing way, with each bounded face being a centrally symmetric
polygon, the result is a zonotopal tiling.
11.4.10 Theorem. A partial cube G can be drawn as a zonotopal tiling if
and only if it the region graph of a weak pseudoline arrangement.
Proof. The implication in one direction is Lemma 11.4.3, and the other direc-
tion is Lemma 11.4.9.
11.4.11 Theorem. Let G be a graph drawn as a zonotopal tiling. Then G is
a partial cube.
Proof. By Theorem 11.4.10, we may instead assume that G is the region graph
of a weak pseudoline arrangement. We may arbitrarily choose a positive side
for each pseudoline, and label the regions of the arrangement by the set of
positive sides of pseudolines containing them. We must show that this labeling
is distance-preserving.
In one direction, each edge in G separates two regions whose labels diﬀer
by a single element. By repeated application of the triangle inequality for the

244
11 Visualization of Media
symmetric diﬀerence distance, any path in G must be at least as large as the
distance between the regions corresponding to its endpoints.
In the other direction, suppose we are given any two regions c1 and c2
in a weak pseudoline arrangement A bounded by a simply connected subset
of the plane. We must show that there exists a path in G connecting them
with length at most equal to the distance between the regions. We prove this
by induction on the distance; as a base case, if c1 = c2 there clearly exists a
zero-length path in G having the corresponding vertices as endpoints.
If A contains a pseudoline that does not separate c1 from c2, we consider
the subarrangement formed by removing from A the region of the plane op-
posite c1 and c2 from that pseudoline, and removing the pseudoline itself. The
resulting subset of the plane is again simply connected by the Jordan Curve
Theorem, and (as each pseudoline crosses the removed one at most once) we
again have a weak pseudoline arrangement in this simply connected subset.
The region graph of this arrangement is a subgraph of G, and the labels of c1
and c2 in this smaller arrangement are at the same distance as they were in
G, as the only removed pseudolines are those that do not separate c1 from c2.
By a sequence of such removals we reach a situation where c1 and c2 belong to
a weak arrangement A′ of pseudolines in which every pseudoline separates c1
from c2, and in which the distance between the labels of c1 and c2 is equal to
their distance in the original arrangement. Let c3 be any region neighboring
c1 in A′. Then c3 has a label that is closer to c2’s by one unit, compared to
c1’s label, so we may ﬁnd the desired path by concatenating a path from c3
to c2 (which must exist by the induction hypothesis) to an edge from c1 to c3.
11.4.12 Example. Some ﬁnite subgraphs of the hexagonal lattice play im-
portant roles in chemistry (see, for instance Gutman and Cyvin, 1989). Let C
be a simple cycle of the hexagonal lattice. A benzenoid graph BC is formed
by the vertices and edges of this lattice lying on and in the interior of C. Fig-
ure 11.10 illustrates this deﬁnition (interior edges of the graph BC are shown
by dashed lines).
Figure 11.10. A benzenoid graph BC.

11.4 Pseudoline Arrangements
245
It is clear from this example that a benzenoid graph is not, generally speak-
ing, an isometric subgraph of the hexagonal lattice. Nevertheless, a benzenoid
graph is a partial cube itself. This was proven using a geometric argument
by Imrich and Klavˇzar (2000), but it also follows immediately from Theo-
rem 11.4.11 since every benzenoid graph is a zonotopal tiling.
Figure 11.11. A squaregraph.
11.4.13 Deﬁnition. A squaregraph (Chepoi et al., 2002) is a graph drawn in
the plane with quadrilateral faces in such a way that each interior vertex of
the drawing has four or more incident edges. Squaregraphs are a special case
of the median graphs discussed in Chapter 4 (Bandelt and Chepoi, 2005). An
example of a squaregraph is shown in Figure 11.11.
11.4.14 Lemma. Every squaregraph is the region graph of a weak pseudoline
arrangement.
Proof. As in the proof of Lemma 11.4.3, we form a system of curves by con-
necting opposite edge midpoints within each quadrilateral of the squaregraph
(keeping the connecting curve interior to the quadrilateral even in cases where
the quadrilateral is drawn as concave) and by extending each boundary edge
midpoint to inﬁnity without further crossings. We must show that this curve
system is a weak pseudoline arrangement.
Suppose, for a contradiction, that this curve system is not a weak pseudo-
line arrangement. Then we have one of three types of feature that prevent it
from being a weak pseudoline arrangement: some curve is closed, some curve
crosses itself, or some two curves cross twice. In all three cases, the quadri-
laterals that the curve or curves forming the feature pass through surround
a bounded region of the plane, and contribute three edges to each vertex on
the boundary of the region, with the exception of at most two vertices which
have four edges from these quadrilaterals.
The set of quadrilaterals inside this region must themselves form a square-
graph. But it can be shown by Euler’s formula (cf. Problem 11.11) that any

246
11 Visualization of Media
squaregraph has at least four boundary vertices with degree two. When ad-
joined to the quadrilaterals surrounding the region in question, these vertices
would form interior vertices with degree three in the overall graph, contradict-
ing the assumption that it is a squaregraph. This contradiction shows that
the curve system we formed must be a weak pseudoline arrangement.
11.4.15 Corollary. Every squaregraph can be drawn as a zonotopal tiling.
11.4.16 Corollary. Every squaregraph is a partial cube.
11.4.17 Example. A polyomino (Golomb, 1994) is a simply connected union
of squares in the plane, meeting edge to edge; Figure 11.12 shows the distinct
polyominos formed from up to ﬁve squares. The vertices and edges of most
of these examples form isometric subsets of Z2, but this is not true e.g. for
the U-shaped pentomino in the bottom left of the ﬁgure. Nevertheless, every
pentomino forms a squaregraph and is therefore a partial cube.
Figure 11.12. The polyominos of up to ﬁve squares.
11.5 Finding Zonotopal Tilings
In the previous section, we characterized the media that can be drawn as zono-
topal tilings: they are the media formed from weak pseudoline arrangements.
We now describe algorithms for eﬃciently constructing drawings of this type.
Note that not every medium, and not even every medium with a planar
state transition graph, can be drawn as a zonotopal tiling; see for instance
Figure 11.13 for media that have planar mediatic graphs but that cannot be
drawn as a zonotopal tiling.
We now describe how to eﬃciently construct a zonotopal tiling correspond-
ing to a given medium, if one exists.

11.5 Finding Zonotopal Tilings
247
Figure 11.13. Media with planar mediatic graphs that cannot be drawn as a zono-
topal tiling.
11.5.1 Deﬁnition. A graph is k-vertex-connected if there is no set of k −1
vertices the removal of which disconnects the remaining graph. In particular
a 2-vertex-connected graph is called biconnected and a 3-vertex-connected
graph is called triconnected.
11.5.2 Deﬁnition. An SPQR tree (Di Battista and Tamassia, 1989; Mutzel,
2003) is a tree structure that represents the triconnected components of a
graph, and is a standard tool in graph drawing and planar embedding algo-
rithms. Each node v in the SPQR tree of G has associated with it a multigraph
Gv consisting of some subset of vertices of G, edges of G, and virtual edges
representing contracted parts of the remaining graph that can be separated
from the edges of Gv by a split pair of vertices (the endpoints of the virtual
edge). Each non-virtual edge of G occurs exactly once as an edge in some
Gv. If two SPQR tree nodes are connected by an edge in the tree, each has a
virtual edge connecting two vertices shared by both nodes.
The SPQR tree for a graph contains four types of nodes:
•
An S node v is associated with a graph Gv that is a simple cycle (or
polygon) of virtual edges.
•
A P node v is associated with a graph Gv that consists of two vertices
connected by three or more parallel virtual edges.
•
A Q node v is associated with a graph Gv formed by two vertices connected
by a single non-virtual edge.
•
An R node v is associated with a graph Gv that is triconnected and in
which all edges are virtual.
An SPQR tree representing a given graph may be formed recursively by
the following procedure:
•
If the graph contains a non-virtual edge, replace it by a virtual edge,
form the SPQR tree of the replaced graph, and form a Q node for the
replaced edge, connecting it to a node in the SPQR tree that contains the
corresponding virtual edge.

248
11 Visualization of Media
•
If the graph consists of a cycle of virtual edges, form an S node for it, and
if the graph consists of two vertices connected by three or more parallel
edges, form a P node for it.
•
If the graph is not of either of the two types described above, but contains
a split pair, separate the graph into two smaller graphs (both containing
copies of a virtual edge connecting the two vertices of the split pair), form
SPQR trees for these two graphs, and connect the two trees by an edge
connecting nodes containing the two virtial edges corresponding to the
split pair.
•
If none of the previous cases applies, the remaining graph must be tricon-
nected. Form an R node for it.
Mutzel (2003) describes a more eﬃcient linear-time procedure for con-
structing SPQR trees.
11.5.3 Deﬁnition. If D is a planar graph drawing, we deﬁne the type of the
embedding to consist of the clockwise ordering of the edges around each face
of the embedding. We say that two embedding types are equivalent either
when they are consist of the same set of cyclic orderings, or when each cyclic
ordering in one embedding type is the reverse of the corresponding cyclic
ordering in the other embedding type.
The interior and exterior edges of an embedding type may be determined
from the embedding type: an interior edge will be listed as part of the cyclic
orderings of two faces of the embedding, and those orderings will pass in
opposite directions through the edge, whereas the two cyclic orderings of faces
that contain an exterior edge will both traverse the edge in the same direction.
For the same reason we may determine the bounded and unbounded faces of
an embedding directly from its embedding type.
Observe that the region graph of a weak pseudoline arrangement can be
given an embedding type by listing the edges in clockwise order around each
region of the arrangement, and that this type is equivalent to the embedding
type of the drawing we have constructed of the region graph of the arrange-
ment as a zonotopal tiling. As a shorthand, we call this embedding type the
embedding type of the arrangement.
We call a graph ambiguously embeddable if it has multiple inequivalent
embedding types that are the embedding types of weak pseudoline arrange-
ments.
11.5.4 Lemma. Let G = (V, E) be a biconnected planar partial cube. Then
G cannot be ambiguously embeddable. If G is the region graph of an arrange-
ment, its embedding type can be found in time O(|V |).
Proof. We form the SPQR tree of G, and root it arbitrarily; let (sv, tv) denote
the split pair connecting a non-root node v to its parent, and let Hv denote
the graph (with one virtual edge) represented by the SPQR subtree rooted

11.5 Finding Zonotopal Tilings
249
at v. We work bottom up in the rooted tree, showing by induction on tree
size that the following properties hold for each node of the tree:
1. Each graph Hv has at most one equivalence class of embedding types that
can include the embedding type of a weak pseudoline arrangement.
2. If v is a non-root node, and Hv has the embedding type of a weak pseudo-
line arrangement, then edge {sv, tv} is an exterior edge of that embedding
type.
3. If v is a non-root node, and Hv has the embedding type of a weak pseu-
doline arrangement, form the path pv by removing virtual edge svtv from
the unbounded face of Hv. Then pv must be part of the unbounded face of
any embedding type of G that is an embedding type of a weak pseudoline
arrangement.
SPQR trees are divided into four diﬀerent cases (represented by the initials S,
P, Q, and R) and our proof follows the same case analysis, below, in each case
showing that the properties at each node follow from the same properties at
the descendant nodes.
Trivial case: If Gv consists of a single graph edge and a single virtual edge
(a Q-node), then clearly there can only be one planar embedding (up to
reﬂection) of Gv.
Parallel case: If Gv consists of three or more edges connecting (sv, tv) (a P-
node). In this case, G can only have the embedding type of a weak pseu-
doline arrangement if Gv has three edges, one of which corresponds to an
edge of G. For, if all three edges of Gv are virtual edges, each of which
corresponds to a nontrivial subgraph of G, the two faces of any drawing of
G that separate the middle subgraph from the other two subgraphs could
not both be drawn strictly convexly.
Since our initial graph G is not a multigraph, it must have exactly one
edge connecting sv to tv, and the other two edges of Gv must be virtual.
Further, the argument above implies that the edge connecting sv to tv
must be in the interior of any drawing of G.
If v is the root of the SPQR tree, it has two children u and w. In this
case, the embedding of Hv = G must be formed by placing Hu and Hw
on opposite sides of the edge {sv, tv}, with the paths pu and pv facing
outwards. If these conditions are satisﬁed, we have found as desired a
unique embedding for G. If v is not the root, it has one child u, as the
other virtual edge connects v to its parent; Hv diﬀers from Hu by the
addition of a single non-virtual edge {sv, tv}. As before, the non-virtual
edge must be sandwiched between the two other parts of G, so the only
possible embedding of Hv is to place the non-virtual edge {sv, tv} parallel
to the virtual edge of Hu connecting the same two vertices, on the internal
side of this virtual edge.
Series case: If Gv is a polygon (an S-node) then the embedding of Hv is formed
by orienting the graph Hu for each child node u so that pu is placed on the

250
11 Visualization of Media
outside of the polygon. If v is the root of the SPQR tree, this completes
the proof that the embedding of G is unique. Otherwise, {sv, tv} must be
on the unbounded face of Hv (since it is an edge of the polygon. Path pv
must lie along the unbounded face of any embedding of G, because (if any
child of v is nontrivial) it contains vertices already required to lie along
the unbounded face from lower levels of the SPQR tree. If all children of
v are trivial, then Hv is just the same polygon as Gv, and separates two
faces in any planar embedding of G; in this case pv must lie along the
unbounded face because it is not possible for two strictly convex internal
faces to share a path of three or more vertices.
Rigid case: In the ﬁnal case, Gv is a triconnected graph, which must be pla-
nar (else G has no planar drawing). Such graphs have a unique planar
embedding up to the choice of unbounded face. By the same reasoning
as in the parallel case, each virtual edge must lie on the unbounded face,
or else it would be sandwiched between two internal faces leading to a
nonconvexity in the drawing. We divide into subcases according to the
number of virtual edges.
•
If there are no virtual edges, then G is itself 3-connected. If G is to
have the embedding type of a pseudoline arrangement with L lines,
then the unbounded face of G must have 2L edges. No other face of
G could have so many edges, because G has at least four faces and
any internal face with k edges would correspond to crossings between
(k/2)(k/2−1)/2 pairs of pseudolines, leaving no crossings for the other
faces. So in this case the unbounded face can be uniquely identiﬁed
as the face with the largest number of edges. (In fact we can prove
that no 3-connected graph can be drawn as a zonotopal tiling, but the
proof is more complex, and we reuse this subcase’s reasoning in the
next subcase.)
•
If there is a single virtual edge, it must be on the unbounded face, so
this narrows down the choice of the unbounded face to two possibilities,
the two faces of Gv containing the virtual edge. By the same reasoning
as for the subcase with no virtual edges, these two faces must have
diﬀering numbers of edges and the unbounded face must be the one
with the larger number of edges. If v is not the root, it has no children
and Hv = Gv; otherwise, the embedding of Hv is formed from that of
Gv by orienting the child of v with pv along the unbounded face of Gv.
•
If there are two or more virtual edges, there can only be one face in Gv
containing these edges, which must be the unbounded face of Gv. The
embedding of Hv is ﬁxed by placing the graph Hu for each child u of v
so that the unbounded face of Hu (minus the virtual edge connecting
it to Gv) lies along the unbounded face of Gv.

11.5 Finding Zonotopal Tilings
251
11.5.5 Theorem. Given a partial cube graph G = (V, E), we can determine
whether G is the region graph of a weak pseudoline arrangement, and if so
construct a drawing of G as a zonotopal tiling, in time O(|V |).
Proof. If G is biconnected, we choose a planar embedding of G by the method
of Lemma 11.5.4. Otherwise, each articulation point of G must be on the
unbounded face of any embedding. We ﬁnd biconnected components of G,
embed each component by Lemma 11.5.4, and verify that these embeddings
place the articulation points on the unbounded faces of each component. We
then connect the embeddings together into a single embedding having as its
unbounded face the edges that are exterior in each biconnected component; the
choice of this embedding may not be unique but does not aﬀect the correctness
of our algorithm.
Certain graphs, such as odd cycles, may be embedded by the method of
Lemma 11.5.4 even though they do not have the embedding type of a weak
pseudoline arrangement. Thus, once we have an embedding of G, we must still
verify that it has the embedding type of a weak pseudoline arrangement, and
construct a face-symmetric planar drawing. We ﬁrst make sure all faces of G
are even, and construct an arrangement of curves A dual to G. We verify that
A has no closed curves, a necessary condition for it to be a weak pseudoline
arrangement. We defer the veriﬁcation that each curve in A crosses each other
such curve at most once until later in the algorithm.
We then produce vertex placements for a drawing of the region graph of
A as described in the proof of Lemma 11.4.9. We test for each edge of the
resulting drawing that the endpoints of that edge are placed at unit distance
apart with the expected slope, and we test that each internal face of G is drawn
as a correctly oriented strictly convex and centrally symmetric polygon. If so,
our algorithm returns the drawing it has constructed; otherwise, it returns a
failure result indicating that no drawing as a zonotopal tiling exists.
If A were not a weak pseudoline arrangement, either due to a curve self-
crossing or to two curves crossing each other with the wrong orientation, the
face of G dual to that crossing point would be drawn as a nonconvex polygon
or as an incorrectly oriented convex polygon. However, our algorithm tests
for both of these possibilities. Thus if our input passes all these tests we have
determined that it is the region graph of a weak pseudoline arrangement and
found a drawing as a zonotopal tiling.
We note that the seemingly very closely related algorithmic problem of
determining whether a planar graph is the region graph of a two-dimensional
line arrangement is NP-hard (Shor, 1991) and therefore unlikely to have an
eﬃcient solution.
11.5.6 Example. Examples of drawings produced by the face-symmetric pla-
nar drawing algorithm of Theorem 11.5.5 are shown in Figure 11.14.

252
11 Visualization of Media
Figure 11.14. Face-symmetric planar drawings of three irregular media.
11.6 Learning Spaces
Recall (Section 1.6 and Theorem4.2.1) that a learning space is a medium
formed by a well-graded set family that is closed under pairwise unions and
includes the empty set. As established by Theorem 4.2.2, any learning space
can be represented by a closed, rooted medium. We describe algorithms for
drawing such media. For some omitted proofs and details, see Eppstein (2006).
11.6.1 Deﬁnition. Learning spaces are equipped with a natural orientation
coming from the set membership relation. With this orientation, they can
be viewed as directed acyclic graphs having a unique source (vertex without
incoming edges) at the empty set, and a unique sink (vertex without outgoing
edges) at the set corresponding to the domain of the learning space. In the
graph theory literature, such graphs are known as st-oriented or as having a
bipolar orientation (Ebert, 1983; Even and Tarjan, 1976).
It is natural, then, to consider learning spaces for which the associated
bipolar orientation is compatible with a planar drawing of the graph, in that
the source and sink can both be placed on the unbounded face of a pla-
nar drawing: bipolar oriented graphs with such an embedding are known as
st-planar, so the learning spaces with this property can be called st-planar
learning spaces.
As we show, st-planar learning spaces can be characterized by drawings of
a very speciﬁc type: Every st-planar learning space has a drawing in which all
bounded faces are convex quadrilaterals with the bottom side horizontal and
the left side vertical. We call such a drawing an upright-quad drawing, and
we describe linear time algorithms for ﬁnding an upright-quad drawing of any
st-planar learning space. Conversely, every upright-quad drawing comes from
an st-planar learning space in this way.

11.6 Learning Spaces
253
Ø
{a}
{a,b}
{a,b,c}
{a,b,c,d}
{a,b,c,d,e}
{a,b,c,d,e,f}
{a,b,c,d,f}
{a,b,d,f}
{b,c,d,f}
{b,d,f}
{a,b,d}
{b,d}
{d}
{a,d}
a
a
a
a
a
b
b
b
c
c
c
c
d
d
d
d
e
e
f
f
f
f
Figure 11.15. An st-planar learning space, from Eppstein (2006).
11.6.2 Example. An example of an st-planar learning space is shown in Fig-
ure 11.15; in the left view, the vertices of a drawing of the graph are labeled
by the corresponding sets in a well-graded ∪-closed set family, while on the
right view, each edge is labeled by the name of a token in the corresponding
medium. Positive tokens are drawn as edges oriented from lower left to upper
right.
Ø
{b}
{a,b}
{a}
{b,c}
{a,b,c}
{c}
{a,c}
Figure 11.16. A learning space that is planar but not st-planar, from Eppstein
(2006). There is no drawing of this learning space in which the source and sink are
both exterior vertices; in the drawing shown, the sink is interior.
11.6.3 Example. Figure 11.16 shows an example of a learning space that is
planar but not st-planar: the power set on three elements, forming a graph
with the structure of a cube. In any planar embedding of this graph, the vertex
representing the empty set and the vertex representing the whole domain are
on diﬀerent faces, so they cannot both be on the unbounded face of any
drawing.

254
11 Visualization of Media
(x0,y0)
(x1,y1)
(x3,y3)
(x2,y2)
Figure 11.17. Left: An upright quadrilateral. Right: An upright-quad drawing.
From Eppstein (2006).
11.6.4 Deﬁnition. For any subset S of points in the plane, we say that (x, y)
is minimal if no other point (x′, y′) in the set has x′ ≤x and y′ ≤y, and
maximal if no other point (x′, y′) in the set has x′ ≥x and y′ ≥y. Any ﬁnite
set S has at least one minimal point and at least one maximal points, but
these points may not be unique.
Let D be a drawing of a graph G, v be a vertex in G, and Sv be the set of
points assigned by D to v and to the neighbors of v in G. We say that v is a
minimal vertex of the drawing if the point assigned to v is minimal in Sv, and
we say that v is a maximal vertex of the drawing if the point assigned to v is
maximal in Sv. Note that any drawing has at least one minimal vertex and at
least one maximal vertex: if S is the set of all points assigned by D to vertices
in G, then the minimal and maximal points in S correspond to minimal and
maximal vertices in G (respectively). However, a drawing may have additional
minimal or maximal vertices that do not correspond to minimal or maximal
points of the larger set S (see Problem 11.13).
Let Q be a convex quadrilateral having the four points in a set S as its
corners. We say that Q is an upright quadrilateral if S has a unique minimal
point and a unique maximal point, such that the edges of Q incident to the
minimal point are horizontal and vertical. That is, it is the convex hull of four
points {(xi, yi) 0 ≤i < 4} where x0 = x1 < x2 ≤x3 and y0 = y2 < y1 ≤y3
(Figure 11.17, left). We deﬁne the bottom edge of an upright quadrilateral to
be the horizontal edge incident to the minimal point, the left edge to be the
vertical edge incident to the minimal point, and the top edge and right edge
to be the edges opposite the bottom and left edges respectively.
We deﬁne an upright-quad drawing of a graph G to be planar straight-line
drawing D of G with the following properties:
[U1] There is exactly one minimal vertex of D and exactly one maximal vertex
of D.
[U2] Every bounded face of the drawing is an upright quadrilateral, the sides
of which are edges of the drawing.

11.6 Learning Spaces
255
In an upright-quad drawing, all edges connect a pair of points (x, y) and
(x′, y′) with x′ ≤x and y′ ≤y; if we orient each such edge from (x′, y′) to
(x, y) then the resulting graph is directed acyclic with a unique source and
sink.
As we now show, upright-quad drawings may be produced from a certain
special type of weak pseudoline arrangement.
11.6.5 Deﬁnition. A right angle is a geometric ﬁgure in R2 formed by two
perpendicular rays that share a common endpoint; this endpoint is usually
called the vertex of the angle, but to avoid confusion with graph-theoretic
terminology we instead call it the corner of the right angle. If A is a right angle,
R2 \ A has two components, the interior of the right angle (the convex set
between the two rays) and the exterior of the right angle (the complementary
concave set).
Two right angles are parallel if the intersection of their interiors is also
the interior of a right angle. Note that parallelism is an equivalence relation.
Two parallel right angles are coincident if one of the rays forming one of the
angles is a subset of one of the rays forming the other angle. A ﬁnite collection
of co-planar parallel right angles, no two of which are coincident is called an
arrangement of parallel right angles.
By convention, we consider for the remainder of this section arrangements
of parallel right angles in which each right angle is parallel to the negative
quadrant of the Cartesian coordinate system. That is, the two rays bounding
each angle run parallel to the x- and y−axes of the coordinate system, and
the corner of each angle is its unique maximal point.
We may view any right angle as a (non-smooth) curve in the plane. It is
straightforward to observe that an arrangement of parallel right angles is thus
a special type of arrangement of pseudolines. As with any pseudoline arrange-
ment, we may deﬁne a region graph that has one vertex per region of the
arrangement, with two vertices adjacent whenever the corresponding regions
are separated by a single curve of the arrangement. For our arrangements of
parallel right angles, it is convenient to draw the region graph by assigning
each region’s vertex to the unique maximal point of its region, except for the
upper right region which has no maximal point. We draw the vertex for the
upper region at any point with x and y coordinates strictly larger than those
of any curve in our arrangement.
11.6.6 Theorem. The assignment of vertices to points in the plane described
above produces an upright-quad drawing for the region graph of any arrange-
ment of parallel right angles.
Proof. The drawing’s edges consist of ﬁnite segments of the rays forming
the angles, together with diagonal segments within each region that connect
corners of angles to the region’s maximal point; none of these edges cross, so

256
11 Visualization of Media
Figure 11.18. Left: an arrangement of parallel right angles. Right: the region graph
of the arrangement, drawn with each vertex (except the top right one) at the max-
imal point of its region. From Eppstein (2006).
we have a planar straight-line drawing. Each ﬁnite region of the arrangement
is bounded above and to the right by the rays of a right angle, either one
of the angles of the given arrangement or the angle that forms the boundary
of the intersection of two of the interiors of given angles. Each ﬁnite region
is also bounded below and to the left by a staircase formed by a union of
interiors of angles of the arrangement; the drawing’s edges subdivide this
region into upright quadrilaterals by diagonals connecting the concave corners
of the region to its maximal point. A similar sequence of upright quadrilaterals
connects the staircase formed by the union of interiors of all given angles to
the point representing the upper right region, which is the unique maximal
vertex of the drawing. The unique minimal vertex of the drawing represents
the region formed by the intersection of the interiors of all given angles. Thus,
all requirements of an upright-quad drawing are met.
11.6.7 Example. Figure 11.18 shows an arrangement of parallel right angles
(left), and the region graph of the arrangement drawn as described above
(right). As can be seen from the ﬁgure, the drawing of the region graph is an
upright-quad drawing.
11.6.8 Theorem. The region graph of any arrangement A of parallel right
angles is the mediatic graph of an st-planar learning space.
Proof. As A is a weak pseudoline arrangement, its region graph is the mediatic
graph of a medium by Theorem 11.4.11. When the tokens represented by each
angle of A are oriented from the lower left of the arrangement to the upper
right, the resulting medium is rooted at the most extreme region to the lower
left of the drawing. Thus, by Theorem 4.2.2, if we show that this orientation
of the medium is also closed, it will follow that it is a learning space.
If a region of A, associated with set S, has a single angle c of A as its
upper right boundary, there can be no two distinct states Sτ and Sρ for
positive tokens τ and ρ in the associated medium, and closure is satisﬁed

11.6 Learning Spaces
257
x
y
x ∉ S
y ∉ S
x ∉ S
y ∈ S
x ∈ S
y ∉ S
x ∈ S
y ∉ S
x ∈ S
y ∈ S
Figure 11.19. Left: A curve arrangement A(G) corresponding to an st-planar learn-
ing space. Right: Two crossings between the same two curves lead to a contradic-
tion, so A must be a weak pseudoline arrangement (Lemma 11.6.10). From Eppstein
(2006).
vacuously. On the other hand, if a region r of A, associated with set S, has
a ray bounding the angle associated with token τ as its upper boundary and
a ray bounding the angle associated with token ρ as its right boundary, then
the only successors of S in the associated medium can be Sτ and Sρ. In this
case, the region diagonally opposite r across the vertex where x and y meet is
associated with the state Sτρ = Sρτ, so again the deﬁnition of closure is met.
Thus, the region graph represents a learning space, and by Theorem 11.6.6 it
is st-planar.
11.6.9 Deﬁnition. Deﬁne a zone of a token τ in an st-planar learning space
M to be the set of bounded faces of the st-planar drawing of M that contain
edges labeled by τ. It can be shown that a zone consists of a sequence of
faces, in which consecutive faces in the sequence each share an edge labeled
by x. Further, the two edges labeled by τ in any face of the zone partition the
boundary of the face into two paths with equal numbers of edges.
We may form a curve arrangement A(M) from an st-planar drawing of
M as follows. For each token τ, we draw a curve Cτ that crosses each edge
labeled by τ and passes only through the bounded faces of the zone of τ. Each
bounded face of the drawing is crossed by two such curves, which we draw
in such a way that they cross exactly once within the face. We extend these
curves to inﬁnity past the exterior edges of the drawing without any crossings
in the unbounded face (Figure 11.19, left).
11.6.10 Lemma. If M is an st-planar learning space, then A(M) is a weak
pseudoline arrangement.
Proof. The curves in A(M) are topologically equivalent to lines and meet only
at crossings. Suppose for a contradiction that two curves labeled τ and ρ
in A(M) cross more than once. Then (Figure 11.19, right) there would exist
two or more disjoint regions between the curves, and there could be no concise

258
11 Visualization of Media
path between states in the upper left region to states in the lower right region,
contradicting the deﬁning axioms of a medium.
11.6.11 Deﬁnition. We are now ready to deﬁne the vertex coordinates for
our upright-quad drawing algorithm. Let D be a given st-planar drawing of
a learning space. Consider the sequence of labels x0, x1, . . . xℓ−1 occurring
on the right path from the bottom to the top vertex of the external face
of the drawing. For any vertex v of our given st-planar learning space, let
X(v) = min{i xi /∈v}. If v is the topmost vertex of the drawing, deﬁne
instead X(v) = ℓ. Similarly, consider the sequence of labels y0, y1, . . . yℓ−1
occurring on the left path from the bottom to the top vertex of the external
face of the drawing. For any vertex v of our given st-planar learning space, let
Y (v) = min{i yi /∈v}. If v is the topmost vertex of the drawing, deﬁne instead
Y (v) = ℓ. We call this system of coordinates the upright-quad coordinates
for D.
11.6.12 Lemma. Let D be an st-planar drawing of a learning space. Then
the upright-quad coordinates for D form a drawing of the region graph of
A(M) in which the lower left boundary of each zone follows a right angle,
parallel to the negative quadrant of the Cartesian coordinate system, and no
two of these parallel right angles share a boundary line.
Speciﬁcally, if token τ appears in position x in the right path of the draw-
ing, and position y in the left path, then the lower left boundary of its zone
lies on the right angle with apex (x, y).
11.6.13 Corollary. The coordinates described above form a drawing of a
region graph of translated parallel right angles, and therefore form an upright-
quad drawing of M.
11.6.14 Example. A drawing produced by the technique described above,
for the st-planar learning space from Example 11.6.2 is shown on the left of
Figure 11.20. As in standard st-planar dominance drawing algorithms (Di Bat-
tista et al., 1999) we may compact the drawing by merging coordinate values
X(v) = i and X(v) = i+1 whenever the merge would preserve the dominance
ordering of the vertices; a compacted version of the same drawing is shown
on the right of Figure 11.20.
We summarize the results of this section:
11.6.15 Theorem. Every st-planar learning space M = (S, T) has an upright-
quad drawing in an integer grid of area O(|T|2) that may be found in time
O(|S|).

11.6 Learning Spaces
259
X(v) = 0
x0 = a
Y(v) = 0
y0 = d
Y(v) = 1
y1 = b
Y(v) = 2
y2 = f
Y(v) = 3
y3 = c
Y(v) = 4
y4 = a
Y(v) = 5
y5 = e
Y(v) = 6
X(v) = 1
x1 = b
X(v) = 2
x2 = c
X(v) = 3
x3 = d
X(v) = 4
x4 = e
X(v) = 5
x5 = f
X(v) = 6
Ø
{a}
{a,b}
{a,b,c}
{a,b,c,d}
{a,b,c,d,e}
{a,b,c,d,e,f}
{d}
{a,d}
{a,b,d}
{b,d}
{b,d,f}
{b,c,d,f}
{a,b,c,d,f}
{a,b,d,f}
X(v) = 0
Y(v) = 0
Y(v) = 1
Y(v) = 2
Y(v) = 3
Y(v) = 4,5,6
X(v) = 1
X(v) = 2
X(v) = 3.4
X(v) = 5,6
Ø
{a}
{a,b}
{a,b,c}
{a,b,c,d}
{a,b,c,d,e}
{a,b,c,d,e,f}
{d}
{a,d}
{a,b,d}
{b,d}
{b,d,f}
{b,c,d,f}
{a,b,c,d,f}
{a,b,d,f}
Figure 11.20. Left: coordinates for conversion of st-planar learning space to
upright-quad drawing. Right: the same drawing with compacted coordinates. From
Eppstein (2006).
Proof. We construct an st-planar embedding for M, form from it the parallel
right angle arrangement A(M), and use the indices of the curves to assign
coordinates to vertices as above. The coordinates of the vertices in a face f
may be assigned by referring only to the labels of edges in f, in time O(|f|);
therefore, all coordinates of G may be assigned in linear time. The area bound
follows easily.
11.6.16 Corollary. Any st-planar learning space M = (S, T) has |S| ≤1 +
(|T|/2 + 1)|T|/4.
Proof. Our drawing technique assigns each vertex (other than the topmost
one) a pair of coordinates associated with a pair of elements {xi, yj} ⊂T+
(possibly with xi = yj), and each pair of elements can supply the coordinates
for only one vertex. Thus, there can only be one more vertex than subsets of
one or two members of T+.
11.6.17 Example. Figure 11.21 shows an st-planar learning space formed
from the well-graded family of sets that are the unions of a preﬁx and a suﬃx
of a totally ordered set. Learning spaces formed in this way have a number
of states exactly matching the bound of Corollary 11.6.16, showing that this
bound is tight.
We have shown that every st-planar learning space can be represented as
the region graph of an arrangement of parallel right angles, every arrange-
ment of parallel right angles represents an st-planar learning space in this
way, and every region graph of an arrangement of parallel right angles or st-
planar learning space has an upright-quad drawing. Eppstein (2006) addition-
ally shows that every upright-quad drawing represents an st-planar learning
space, although not all such drawings have vertices placed at the maximal
points of regions in an arrangement of parallel right angles; we omit the de-
tails.

260
11 Visualization of Media
Ø
{a}
{a,b}
{a,b,c}
{a,b,c,d}
{a,b,c,d,e}
{a,b,c,d,e,f}
{a,b,c,d,f}
{a,b,c,f}
{a,b,f}
{a,f}
{f}
{e,f}
{a,e,f}
{a,b,e,f}
{a,b,c,e,f}
{d,e,f}
{a,d,e,f}
{a,b,d,e,f}
{c,d,e,f}
{a,c,d,e,f}
{b,c,d,e,f}
Figure 11.21. The family of sets formed by the union of a preﬁx and a suﬃx of
some ordered universe forms an st-planar learning space with the maximum possible
number of states. From Eppstein (2006).
Problems
11.1 Let M be embedded isometrically onto the cubic lattice Z3, in such a
way that the isometric projection of that lattice (see Deﬁnition 11.1.1) projects
diﬀerent vertices to distinct positions in the plane. Show that all faces of the
resulting drawing must be regular hexagons or 60◦-120◦rhombi.
11.2 Find a planar drawing of a medium, using only regular hexagons and
60◦-120◦rhombi as faces, that is not the isometric projection of any three-
dimensional lattice embedding of the medium.
11.3 Find a drawing of a biconnected graph G as a zonotopal tiling, such
that the edges of G have only three distinct slopes, that cannot be drawn
using only regular hexagons or 60◦-120◦rhombi.
11.4 Find a medium such that the projection method of Section 11.2 pro-
duces a drawing that has no edge crossings but does not form a zonotopal
tiling.
11.5 Describe the coordinates of the drawing produced by the projection
method of Section 11.2 on a graph in the form of a cycle of 2n vertices. What
is the area of the minimal axis-aligned rectangle containing the drawing, as a
function of n?
11.6
(i) Show that a cycle of 2n vertices can be drawn as a symmetric convex
polygon, with integer vertex coordinates, within a rectangle of area
O(n3).

Problems for Chapter 11
261
(ii) Show that a cycle of 2n vertices can be drawn as a symmetric con-
vex polygon, with integer vertex coordinates, within a square of area
O(n3).
(iii) Show that, if a cycle of 2n vertices is drawn as a symmetric con-
vex polygon, with integer vertex coordinates, then the minimal axis-
aligned rectangle containing the cycle has area Ω(n3).
11.7 Figure 11.22 below shows cycles of 4, 6, 8, and 10 vertices, drawn as non-
convex polygons with integer coordinates using only unit-length edges. The
drawings are symmetric under 180◦rotation, and therefore can be formed as
the projection of a lattice embedding of the cycles.
(i) Prove that, for any n, a 2n-vertex cycle can be embedded in this way
into a square of area O(n).
(ii) In a drawing of a 2n-vertex cycle be drawn as a rotationally-symmetric
non-self-crossing polygon with integer vertex coordinates, and unit-
length edges, let there be v1 vertices with convex angles, v2 vertices
with concave angles, and v3 vertices with 180◦angles. Prove that
v1 = v2 + 4 and that v3 ≤v + 1 + v + 2.
(iii) The drawings for 2n = 4 and 2n = 10 have no 180◦angles. More
generally, for which n can a 2n-vertex cycle be drawn as a rotationally-
symmetric non-self-crossing polygon with integer vertex coordinates,
unit-length edges, and no 180◦angles?
Figure 11.22. Figure for Problem 11.7
11.8 Find a zonotopal tiling that is a drawing of the region graph of the line
arrangement in Figure 1.3.
11.9 Find an example of a tiling of a non-simply-connected region of the
plane, by strictly convex centrally symmetric tiles, that is not the drawing of
the mediatic graph of a partial cube.

262
11 Visualization of Media
11.10 Find an example of a tiling of a convex region of the plane, by convex
but not necessarily strictly convex centrally symmetric tiles (that is, some
internal angles can equal pi), that is not the drawing of the mediatic graph of
a partial cube.
11.11 Find a planar straight line drawing of a ﬁnite graph G, such that all
bounded faces of the drawing are convex quadrilaterals and G is not a partial
cube.
11.12 Use Euler’s formula E −V + F = 2 for planar graphs to prove that
every squaregraph has at least four degree-two exterior vertices.
11.13 Find a graph G, a drawing D of G, and a vertex v, such that v is a
minimal vertex of the drawing, but such that the point assigned to v is not a
minimal point among the set of all points assigned to vertices by D.
11.14 Find a drawing of the st-planar learning space shown in Figure 11.6.2
in which all bounded faces are drawn as parallelograms.
11.15 Prove that any st-planar learning space has a drawing in which all
bounded faces are drawn as parallelograms.
11.16 Find a drawing of a planar graph in which all bounded faces are drawn
as parallelograms, but for which the graph does not represent an st-planar
learning space.
11.17 Find a planar straight line drawing of a graph that satisfes property
[U2] of an upright-quad drawing, but that does not satisfy [U1], and that is
not the drawing of an st-planar learning space.

12
Random Walks on Media
In some ﬁnite or countable situations, a medium (S, T) can serve as the alge-
braic component of a random walk model whose states coincide with those of
the medium1. The basic idea is that there exists a probability distribution
ϑ : T →[0, 1] : τ →ϑτ
on the set of all tokens, such that, if a token-event occurs, then the probability
of a transition from some state S to some state T ̸= S is equal to ϑτ if Sτ = T
and vanishes otherwise. We also suppose that there is an ‘initial’ distribution
η : S →[0, 1] : S →ηS
on the set of all states. This distribution governs the choice of ﬁrst state. The
pair (η, ϑ) deﬁnes a stochastic process which is properly called a ‘random walk’
because the transitions can occur only between adjacent states. A realization
of the process is a sequence of states, which is induced by ﬁrst sampling the
distribution η on S, and then sequentially sampling the distribution ϑ on T.
12.0.1 Example. An illustration is given in Figure 12.1 which displays the
beginning of a sequence of states in the permutohedron medium Π2 of Exam-
ple 3.5.9. This type of ‘cyclical random walk’ was already considered by Feller
(1968). However, we use it here as an exemplary case of a general type of
random walk on the states of a ﬁnite medium. We shall refer to this example
on several occasions in our presentation of the theory.
We recall that the states are the six strict linear orders on the set {1, 2, 3}.
We use on the graph the abbreviation ijk to mean the strict linear order
{ij, ik, jk}. Such abbreviations will be used in the sequel whenever convenient.
We denote by L3 the set of those six strict linear orders, and by T3 the
1 Some of the material in this chapter follows Chapter 22 in Falmagne (2003) and
Falmagne et al. (2007). The introduction to Markov chains is included for com-
pleteness. These concepts and results can be found in any standard text such as
Chung (1967), Barucha-Reid (1974), or Parzen (1994).

264
12 Random Walks on Media
0
1
2
3
4
5
Permutohedron on {1,2,3}.
Only half of the tokens are
marked, corresponding to
the clockwise circuit.
Trial number and token
132
123
312
213
321
231
132
312
123
231
321
132
312
123
321
132
123
321
213
213
213
231
231
132
321
213
231
321
231
123
213
123
123
132
213
312
231
321
Initial State
T 31
T 13
T 12
T 23
T 21
T 21
T 13
T 31
T 32
T 12
T 23
T 21
Figure 12.1. A realization of a random walk on the permutohedron medium Π2 of
Example 3.5.9. The initial state on trial 0 is 132, presumably selected from sampling
the initial probability distribution η on the set of states. The sequence of ensuing
states, namely 321, 132, 321, 312, 123, is obtained by sampling the probability
distribution ϑ on the set of tokens. These states are produced by the sequence of
tokens τ21, τ31, τ13, τ12, τ23, τ21. Note that the tokens τ21 and τ12 are ineﬀective for
the state 132 on two occasions: no transition takes place on trials 0 and 3.
corresponding set of tokens τij, i, j ∈{1, 2, 3}, i ̸= j, which are deﬁned by the
equation
τij : L3 →L3 : L →Lτij =

(L \ {ji}) ∪{ij}
if j covers i
L
otherwise.
In this example the states observed on the successive trials are:
trials
0
1
2
3
4
5
. . .
states
132
312
132
132
123
213
. . .
The symmetry inherent in the axioms deﬁning a medium, together with some
hypotheses on the probability distribution ϑ, ensures that the asymptotic
distribution on the set of states exists. It is in fact easy to describe: the
asymptotic probability of some state S ∈S is proportional to the product of

12.1 On Regular Markov Chains
265
the probabilities ϑτ of all the tokens τ occuring in any of the concise messages
producing S, that is, all the tokens belonging to S (cf. Deﬁnition 2.4.1; see
Theorem 12.4.1).
Such a mechanism may provide a suitable model for the evolution of a
physical, biological, or social system subjected to a constant probabilistic
barrage of ‘token-events’, each of which may induce a ‘mutation’ of its state
taking the form of an addition or a removal of some constituent feature. We
develop the theory for two variants of this idea in this chapter. In one of
them, we assume that the token-events occur on discrete times numbered
0, 1, . . . , n, . . ., giving rise to what is called a ‘discrete parameter’ random walk
(cf. Deﬁnition 12.2.1). This case is illustrated in Figure 12.1. The other variant
deals with a phenomenon in which a token-event can occur at any instant of
a potentially inﬁnite interval of time. This leads to describe a ‘continuous
parameter’ random walk. We only consider random walks on the states of
ﬁnite media. Random walks for inﬁnite media—for example, random walks
on a tessellation of the plane (cf. Coxeter, 1973, Section IV)—can be deﬁned
by standard methods. We do not cover such material here because, as far as
we know, no relevant application exists. We begin by brieﬂy reviewing some
standard facts on regular Markov chains2.
12.1 On Regular Markov Chains
Loosely speaking a Markov chain is a precise description, in the language
of probability theory, of a system with a very limited memory of its past.
Consider a system (a random walk on a medium, say) whose states evolve
over time. Suppose that the states have been observed on j discrete moments
or ‘trials’ numbered n1 < n2 < . . . < nj. (These trials are not necessarily
consecutive and we know nothing about the states of the system on any other
trials.) Suppose also that the state of the system on any later trial nj+k only
depends upon that last observed state on trial nj. A system satisfying such
a property for any choice of trials numbers n1, n2, . . . , nj, nj+k is said to be
‘Markovian3.’ In words: a system is Markovian if the prediction of its future
state only depends upon the last recorded state. Let us state this idea formally.
12.1.1 Deﬁnition. Let X0, X1, . . . , Xn, . . . be a sequence of random variables
taking their values on the same ﬁnite set S. We write P for the probability
measure of the common sample space of these random variables. Suppose that,
for any positive integer n and any event E depending only on the values of
the random variables X0, X1, . . . Xn−1, we have, for any S, V ∈S,
P(Xn+1 = V
Xn = S, E) = P(Xn+1 = V
Xn = S).
(12.1)
2 For Markov chain terminology in this chapter, we follow mostly Kemeny and Snell
(1960).
3 From the Russian mathematician Andrei Andre¨ıevich Markov (1856-1922).

266
12 Random Walks on Media
Then, the sequence (Xn) is a (ﬁnite) Markov chain. Note that in this case
we also have
P(Xn+1 = V
Xn = S, . . . , X1, X0) = P(Xn+1 = V
Xn = S).
(12.2)
The formulations of the Markovian property in terms of (12.1) and (12.2)
are actually equivalent (see Problem 12.1.) The set S is the state space of the
chain, and the elements of S are called the states. Note in passing the fortunate
coincidence that the term ‘state’ is used consistently for a medium and the
corresponding Markov chain on that medium. We shall use the abbreviations
pn(S) = P(Xn = S)
(12.3)
tn,m(S, V ) = P(Xm = V
Xn = S).
(12.4)
Thus, Eq. (12.1) can be rewritten as
P(Xn+1 = V
Xn = S, E) = tn,n+1(S, V ).
The quantities tn,m(S, V ) are referred to as the transition probabilities of the
chain (Xn). Deﬁning the chain requires thus specifying the initial probabili-
ties p0(S) of the states and the one-step transition probabilities tn,n+1(S, V ).
When these transition probabilities do not depend upon the trial number,
that is, when
tn,n+1(S, V ) = tm,m+1(S, V )
(12.5)
for all S, V ∈S and n, m ∈N0, then the Markov chain is called homogeneous
or, equivalently, is said to have stationary transition probabilities. In this case,
there are numbers t(S, V ) deﬁned for all states S and V in S such that, for
all trial numbers n ∈N0,
t(S, V ) = P(Xn+1 = V
Xn = S).
(12.6)
We have thus
t(S, V ) ≥0,
for all S, T ∈S;
(12.7)

V ∈S
t(S, V ) = 1,
for all S ∈S.
(12.8)
This case is of special interest here because we suppose that the transitions
between states result from the tokens-events, which occur with constant prob-
abilities.
The following result is fundamental, and holds whether or not the chain
is homogeneous.
12.1.2 Theorem. For any trial numbers 0 ≤n < m < r and any states S
and V in S,
tn,r(S, V ) =

W ∈S
tn,m(S, W)tm,r(W, V ).
(12.9)
Equation (12.9) is known as the Chapman-Kolmogorov Equation.

12.1 On Regular Markov Chains
267
Proof. We have by deﬁnition
tn,r(S, V ) = P(Xr = V
Xn = S)
=

W ∈S
P(Xr = V
Xm = W, Xn = S)P(Xm = W Xn = S)
=

W ∈S
P(Xr = V
Xm = W)P(Xm = W Xn = S)
=

W ∈S
tn,m(S, W)tm,r(W, V ).
12.1.3 Corollary. For any trial numbers 0 ≤n < m < r, and any states i,
j, and k in S,
tn,r(i, j) ≥tn,m(i, k)tm,r(k, j).
(12.10)
12.1.4 Matrix Notation. Results concerning ﬁnite Markov chains are con-
veniently written in the notation of vectors and matrices. Let the elements
of a state space S be numbered 1, 2, . . . , q. Thus, the variables i, k, and j in
Eqs. (12.10) run in the set {1, 2, . . . , q}. Let
Tn,m =
⎛
⎜
⎜
⎜
⎜
⎝
tn,m(1, 1) tn,m(1, 2) . . . tn,m(1, q)
tn,m(2, 1) tn,m(2, 2) . . . tn,m(2, q)
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
tn,m(q, 1) tn,m(q, 2) . . . tn,m(q, q)
⎞
⎟
⎟
⎟
⎟
⎠
(12.11)
denote a square matrix, the cell (i, j) of which contains the probability of a
transition from state i on trial n to state j on trial m. Note that the prob-
abilities of each row of the matrix Tn,m sum to one. Such a matrix is often
called a transition matrix, or a stochastic matrix. Extending the notation
introduced in (12.3), we also write
pn =

pn(1), . . . , pn(t)

(12.12)
for the vector of the state probabilities on trial n. In the notation of (12.11)
and (12.12), the Chapman-Kolmogorov Equation (cf. Theorem 12.1.2) has the
compact expression
Tn,r = Tn,mTm,r,
(12.13)
for any positive integers n < m < r. A simple expression is available for
the vector of the state probabilities on trial n + 1 as a function of the state
probabilities on trial n and of the transition probabilities. We clearly have,
for any trial number n and any state i in S,
pn+1(i) =

k∈S
pn(k)tn,n+1(k, i).

268
12 Random Walks on Media
Using the standard notation for the product of a vector by a matrix, this
becomes
pn+1 = pnTn,n+1.
By induction, it follows that
pn+m = pmTm,m+1Tm+1,m+2 · · · Tn−1,n.
Thus, in particular,
pn = p0T0,1T1,2 · · · Tn−1,n.
(12.14)
Of particular interest in the sequel is the case in which the Markov chain is
homogeneous. The transition probabilities are then constant (see Eq. (12.6))
and all the one-step transition matrices Tn,n+1 are identical to some basic
transition matrix
T = (t(i, j)),
(i, j ∈{1, . . . , q}).
In the theorem below, Tk stands for the kth power of the matrix T.
12.1.5 Theorem. In an homogeneous Markov chain (Xn) with a transition
matrix T, the transition probabilities tn,m(i, j) only depend upon the diﬀer-
ence m −n. Speciﬁcally, we have
Tn,m = Tm−n.
(12.15)
Moreover, for any trial number n ≥1,
pn = p0Tn
(12.16)
where p0 is the initial vector of probabilities of the states, and pn is the vector
of probabilities of those states on trial n.
Proof. Equation (12.15) follows from Equation (12.13), which yields
Tn,m = Tn,n+1Tn+1,n+2 · · · Tm−1,m = Tm−n,
since each of the factors in the product is equal to T.
Equation (12.16) is then obtained from the fact that, by deﬁnition of T0,n
and by Eq. (12.15), we get pn = p0T0,n = p0Tn .
12.1.6 Deﬁnition. In view of this result, it makes sense in the homogeneous
case to write tk(i, j) for the conditional probability of a transition from state
i on trial n to state j on trial n + k, for any nonnegative integers n; that is,
tk(i, j) = P(Xn+k = j Xn = i).
(12.17)
Note that t1(i, j) = t(i, j), and that tk(i, j) is the entry in the cell (i, j)
of the matrix Tk and satisﬁes tk(i, j) = tn,n+k(i, j) for every integer n ≥0
(cf. Eq. (12.4)).

12.1 On Regular Markov Chains
269
We now focus on the special kind of homogeneous Markov chains that
provided the title of this section.
12.1.7 Deﬁnition. A ﬁnite, homogeneous Markov chain (Xn) is regular if
there is a positive integer N such that whenever n ≥N, then tn(i, j) > 0
for all states i, j in S. Thus, all entries of the matrix Tn are positive for any
n ≥N. By convention, we say that a Markov chain is regular to mean that it
is also ﬁnite and homogeneous.
12.1.8 Remark. Actually, the deﬁnition of a regular Markov chain given here
is often given in the form of as a theorem stating the equivalence of regular-
ity and a collection of other properties, homogeneity being one of them. Our
discussion is only intended to establish economically some key results regard-
ing random walks on ﬁnite media. A diﬀerent way of obtaining regularity is
sketched in Problem 12.16.
The next theorem concerns the convergence of the transition probabilities
for large n and is the fundamental result for regular Markov chains.
12.1.9 Theorem. For any state j in a regular Markov chain, there is a num-
ber αj > 0 such that 
j∈S αj = 1, and for any pair (i, j) of states, we have
lim
n→∞tn(i, j) = αj.
In other terms, the powers Tn of the transition matrix T are converging to
a stochastic matrix A, each of the q = |S| rows of which is the same vector
α = (α1, . . . , αq).
We postpone the proof of this result to establish a preliminary lemma, in
which we show that for 1 ≤j ≤q, the jth column vector of the matrix Tn
tends to a vector containing all identical terms αj; that is, as n →∞, we have
⎛
⎜
⎜
⎜
⎜
⎝
tn(1, j)
tn(2, j)
. . .
. . .
tn(q, j)
⎞
⎟
⎟
⎟
⎟
⎠
→
⎛
⎜
⎜
⎜
⎜
⎝
αj
αj
. . .
. . .
αj
⎞
⎟
⎟
⎟
⎟
⎠
.
12.1.10 Lemma. Let T = (t(i, j)), i, j ∈{1, . . . q}, be a stochastic matrix
with positive entries. For any index j, let Mn(j) be the maximum value in
the jth column vector of Tn, and let mn(j) be the minimum value in that
column vector. Then, the sequence mn(j) is nondecreasing and the sequence
Mn(j) is nonincreasing. Accordingly, the sequence
rn(j) = Mn(j) −mn(j),
(n ∈N)
specifying the range of values in that column vector is nonincreasing and in
fact tends to zero.

270
12 Random Walks on Media
Proof. Let (i, j) be any pair of states, and let δ be the smallest entry in the
matrix T. Witout loss of generality, suppose that mn(j) = tn(1, j). Using the
Chapman-Kolmogorov Equation (Theorem 12.1.2), we obtain successively
tn+1(i, j) =

k∈S
t1(i, k)tn(k, j)
≤t1(i, 1)mn(j) + (1 −t1(i, 1)) Mn(j)
≤δmn(j) + (1 −δ)Mn(j)
= Mn(j) −δ (Mn(j) −mn(j)) .
We have in particular
Mn+1(j) ≤Mn(j) −δ (Mn(j) −mn(j))
(12.18)
which shows that the sequence Mn(j) is nonincreasing. A similar argument
applied to the sequence mn(j) yields
mn+1 ≥mn(j) + δ (Mn(j) −mn(j)) ,
or, equivalently,
−mn+1 ≤−mn(j) −δ (Mn(j) −mn(j)) .
(12.19)
Adding (12.18) and (12.19) and grouping terms, we obtain
rn+1(j) = Mn+1(j) −mn+1(j)
≤Mn(j) −mn(j) −2δ (Mn(j) −mn(j))
= (Mn(j) −mn(j)) (1 −2δ)
= rn(j)(1 −2δ) .
Hence for n > 1,
rn(j) ≤r1(j)(1 −2δ)n−1 .
(12.20)
Since 0 < 2δ < 1, we have rn(j) →0, as asserted.
Proof of Theorem 12.1.9. If the entries of the transition matrix of the Markov
chain are all positive, the result follows from Lemma 12.1.10. Indeed, the two
sequences mn(j) and Mn(j) converge, since they are monotonic and bounded.
Because the range rn(j) tends to zero, these two sequences must converge to
the same limit, which we denote by αj. By deﬁnition of mn(j) and Mn(j),
we have 0 < mn(j) ≤tn(i, j) ≤Mn(j) for any pair of states (i, j), yielding
limn→∞tn(i, j) = αj, with necesssarily q
j=1 αj = 1.
In general, the matrix T may have some zero entries. However, by Theorem
12.1.7, there is a positive integer N such that all the entries of TN are positive.
Applying Lemma 12.1.10 to the matrix TN, it follows that, for any state j, the
sequence rNn(j) tends to zero as n →∞. Because rNn(j) is nonincreasing,
we must conclude that it tends to zero. The rest of the argument is as in the
ﬁrst paragraph of this proof.
The next result completes the picture.

12.2 Discrete and Continuous Stochastic Processes
271
12.1.11 Theorem. Let p0 = (p0(1), . . . , p0(q)) be the initial vector of state
probabilities, and suppose that all the conditions of Theorem 12.1.9 are stat-
isﬁed, with in particular Tn →A. Then:
(i) p0Tn tends to the vector α, for any arbitrarily chosen vector p0;
(ii) α is the unique vector satisfying the equation αT = α;
(iii) AT = TA = A.
Proof. We have p0A = α because all the rows of the matrix A are identical
to α and 
j∈S p0(j) = 1. This leads to
lim
n→∞p0Tn = p0A = α ,
which proves (i). Let q be any vector satisfying qT = q. By induction, we get
qTn = q. Condition (ii) follows from Condition (i) since
lim
n→∞qTn = α = q.
Finally, (iii) results from the string of equalities
A = limn→∞Tn = limn→∞TnT = AT = limn→∞TTn = TA.
Thus, for a regular Markov chain (Xn), regardless of the initial vector p0,
the long range—or asymptotic—probabilities of the states will be those spec-
iﬁed by the vector α = (α1, . . . , αq). The vector α is often referred to as
the stationary distribution of the Markov chain (Xn). The following suﬃcient
condition for a vector α = (α1, . . . , αq) to be a stationary distribution will be
instrumental.
12.1.12 Lemma. Let T = (t(i, j)), i, j ∈{1, . . . , q} be the transition matrix
of a regular Markov chain, and let α = (α1, . . . , αq) be a vector deﬁning a
probability distribution. Suppose that
αit(i, j) = αjt(j, i)
(i, j ∈{1, . . . , q}).
Then, α is the unique stationary distribution of the Markov chain.
Proof. It suﬃces to verify that q
i αi=1t(i, j) = αj and use Theorem 12.1.11(ii).
12.2 Discrete and Continuous Stochastic Processes
There are important situations in which a Markov chain is only one of the
components of a more complex stochastic processes. This potentially applies
to the random walks on media. The two key components are the state of the
random walk on trial n (or at time t—the two cases will be considered) and
the last token-event having occurred before or on trial n (or time t). Other
components may also be introduced which depend on those two. We introduce
here the relevant terminology.

272
12 Random Walks on Media
12.2.1 Deﬁnition. Let (X1,n, . . . , Xr,n)n∈N0 be a sequence of r-tuples of
jointly distributed random variables. Such a sequence of r-tuples is called
a discrete (parameter) process because the index set is the countable set N0
of non–negative integers.
A partial example of a realization of such a process has been given in
Figure 12.1, which displays graphically a sequence of pairs (state, token) in
the course of ﬁrst 6 trials. In some real life cases, it makes sense to suppose
that the events occur in the real time interval R+ = [0, ∞[.
12.2.2 Deﬁnition. Let (X1,t, . . . , Xr,t)t∈R+ be a sequence of r-tuples of
jointly distributed random variables. Such a sequence is called a continuous
parameter stochastic process in view of its index set R+.
Homogeneous Markov chains have been deﬁned in 12.1.1 by the property
tn,n+1(R, S) = tm,m+1(R, S),
(n, m ∈N0)
which states that the one-step transition probabilities from state R to state
S do not depend upon the trial number. Homogeneous Markov processes are
conceptually similar, in the sense that the transition probabilities from some
state at time t to some other state at time t + δ only depend upon the time
diﬀerence δ.
12.2.3 Deﬁnition. We say that a continuous stochastic process (Xt) is a
Markov process if
P(Xtn+1 = Sn+1 Xtn = Sn, . . . , Xt1 = S1) = P(Xtn+1 = Sn+1 Xtn = Sn)
(tn+1 > tn > . . . > t1).
In such a case, the stochastic process (Xt) is deﬁned by the pairwise condi-
tional probabilities
P(Xt+δ) = S Xt = R).
(12.21)
that the process is in state S at time t + δ given that it is in state R at
time t. A Markov process (Xt) is homogeneous if the conditional probabilities
in Eq. (12.21) do not depend upon t. In this case, we can deﬁne the transition
function4
tδ(R, S) = P(Xt+δ) = S Xt = R).
(12.22)
There is no need for us to recall facts from the theory of continuous Markov
processes because we shall derive all our results from a distinguished Markov
chain embedded in5 the continuous Markov process under consideration.
4 Compare with (12.5) and (12.6).
5 This can be read as “deﬁned from.”

12.3 Continuous Random Walks on a Medium
273
12.3 Continuous Random Walks on a Medium
The results described here are based on Falmagne (1997). We consider some
organism capable of evolving from one discrete state to some other one under
the inﬂuence of a barrage of punctual token-events. Both the set S of feasible
states of the organism and the set T of possible token-events are ﬁnite, and
the pair (S, T) satisﬁes Axioms [Ma] and [Mb] of a medium. The state of the
organism is observed continuously from time zero on and continuously after
that, and so are the arrival times and the identities of the tokens. We suppose
that the arrival times of the tokens are governed by a homogeneous Poisson
process6. Whenever a Poisson event occurs, a token-event is sampled from a
probability distribution ϑ on T, which is invariant over time. The resulting
continuous parameter stochastic process has thus three components:
(1) the state of the organism at any time t ≥0;
(2) the number of tokens having occurred from time 0 up to and including
time t;
(3) the last token to occur before or at time t.
We introduce these three concepts formally.
12.3.1 Stochastic Concepts. We assume that there exists some probability
distribution
η : S →[0, 1] : S →ηS
on the set of states, governing the choice of the initial state of the process,
and a positive probability distribution
ϑ : T →]0, 1] : τ →ϑτ
on the set of tokens. The evolution is described in terms of three collections
of random variables corresponding to the three components of the stochastic
process outlined above. For t ∈]0, ∞[,
St
denotes the state of the random walk at time t,
Nt
speciﬁes the number of tokens that have occurred in the
half-open interval of time ]0, t], and
Tt
is the last token to occur before or at time t. We set Tt = 0
if no token has occurred, that is, if Nt = 0.
Thus, St takes its values in the set S of states, Nt is a nonnegative integer,
and Tt ∈(T ∪{0}). The random variables Nt will turn out to be the counting
random variables of a Poisson process governing the delivery of the token-
events (see Axiom [T]).
6 Some of our results would still hold under the weaker assumption of renewal
process.

274
12 Random Walks on Media
The following random variables will also be instrumental:
Nt,t+δ = Nt+δ −Nt
denoting the number of tokens in the half open interval ]t, t + δ].
Axioms
The three axioms below specify the stochastic process (Nt, Tt, St)t>0 up to
the parameters (ηS)S∈S and (ϑτ)τ∈T for the two probability distributions, and
a parameter λ > 0 specifying the intensity of the Poisson process. A discrete
random walk (Mn)n∈N0 describing the succession of states of S is then deﬁned
from (Nt, Tt, St)t>0 as an embedded process (cf. e.g. Parzen (1994)). The
notation Et stands for any arbitrarily chosen history of the process before
time t > 0; E0 denotes the empty history.
[T] (Occurrence of the tokens.) The occurrence times of the token-
events are governed by a homogeneous Poisson process of intensity λ. When
a Poisson event is realized, the token τ is selected with probability ϑτ >
0, regardless of past events. Thus, for any nonnegative integer k, any real
numbers t > 0 and δ > 0, and any history Et,
P(Nt,t+δ = k Et) = (λδ)ke−λδ
k!
(12.23)
P(Tt+δ = τ Nt,t+δ = 1, Et)
= P(Tt+δ = τ Nt,t+δ = 1) = ϑτ > 0 .
(12.24)
[I] (Initial state.) Initially, the system is in state S with probability
ηS. The system remains in that state at least until the occurrence of the ﬁrst
token-event. That is, for any S ∈S and t > 0
P(St = S Nt = 0) = ηS.
[L] (Learning.) If R is the state of the system at time t, and a single
token τ occurs between times t and t + δ, then the state at time t + δ will be
Rτ regardless of past events before time t. Formally, we have
P(St+δ = S Tt+δ = τ, Nt,t+δ = 1, St = R, Et)
= P(St+δ = S Tt+δ = τ, Nt,t+δ = 1, St = R) = d(S, Rτ) ,
where d is the Kronecker d function on S × S, that is
d(S, T) =

1
if S = T,
0
otherwise .

12.3 Continuous Random Walks on a Medium
275
12.3.2 Deﬁnition. A 5-tuple (S, T, Nt, Tt, St)t>0, where (S, T) is a medium
and (Nt, Tt, St)t>0 satisﬁes Axioms [I], [T] and [L] for some appropriate λ, η
and ϑ, is called a Poisson driven random walk on the medium (S, T), or more
brieﬂy, a Poisson walk on (S, T).
12.3.3 Convention. In the rest of this chapter, we suppose implicitly that
(S, T, Nt, Tt, St)t>0 is such a Poisson walk.
Basic Results
Notice that
P(St+δ = S St = R)
=
∞

k=0
P(St+δ = S Nt,t+δ = k, St = R) P(Nt,t+δ = k St = R)
=
∞

k=0
P(St+δ = S Nt,t+δ = k, St = R) P(Nt,t+δ = k) .
(12.25)
Indeed, by the Poisson process Axiom [T], the arrival of the tokens after time
t are independent of any events in the process occurring before t, and so
P(Nt,t+δ = k St = R) = P(Nt,t+δ = k).
12.3.4 Lemma. For any positive real numbers t, t′, δ and δ′, any k ∈N, and
any two states S and T ∈S, we have
P(St+δ = S Nt,t+δ = k, St = R)
= P(St′+δ′ = S Nt′,t′+δ′ = k, S′
t = R).
(12.26)
Proof. We use induction on k. For k = 1, Eq. (12.26) follows from Axioms [T]
and [L] via
P(St+δ =S Nt,t+δ =1, St =R)
=

τ∈T
P(St+δ =S Tt = τ, Nt,t+δ =1, St =R) ϑτ =

τ∈T
d(S, Rτ) ϑτ,
independent of t and δ. If (12.26) holds for a certain k = j we use the abbre-
viation
ξj(R, S) = P(St+δ = S Nt,t+δ = j, St = R).
So, suppose that (12.26) holds for k = 1, . . . , j. Denote by t + Vj,t the time
of the occurrence of the j-th Poisson event to be realized after time t. Thus,
Vj,t is a Gamma distributed random variable with parameters j and λ. We

276
12 Random Walks on Media
write gj,t and Gj,t for the density function and the distribution function of
Vj,t, respectively. Notice that for 0 < δ′ < δ the three formulas
(Nt,t+δ = j + 1, Vj,t = δ′),
(Nt+δ′,t+δ = 1, Vj,t = δ′),
and
(Nt,t+δ′ = j, Nt+δ′,t+δ = 1, Vj,t = δ′)
denote the same event. With this in mind, we have successively
P(St+δ = S Nt,t+δ = j + 1, St = R)
=

Q∈S
( δ
0
P(St+δ = S Nt,t+δ = j + 1, St+δ′ = Q, Vj,t = δ′, St = R)
P(St+δ′ = Q Nt,t+δ′ = j, St = R) gj,t(δ′)
Gj,t(δ) dδ′
=

Q∈S
( δ
0
P(St+δ = S Nt+δ′,t+δ = 1, St+δ′ = Q)
P(St+δ′ = Q Nt,t+δ′ = j, St = R) gj,t(δ′)
Gj,t(δ) dδ′
=

Q∈S
ξ1(Q, S)ξj(R, Q)
( δ
0
gj,t(δ′)
Gj,t(δ) dδ′
=

Q∈S
ξ1(Q, S)ξj(R, Q),
independent of t, and δ.
Lemma 12.3.4 justiﬁes the following deﬁnition.
12.3.5 Deﬁnition. For any t > 0, δ > 0, k ∈N, and R, S ∈S, deﬁne
ξk(R, S) = P(St+δ = S Nt,t+δ = k, St = R) .
(12.27)
12.3.6 Theorem. The stochastic process (St) is a homogeneous Markov pro-
cess, with transition probability function p deﬁned by
pδ(R, S) = P(St+δ = S St = R)
=
∞

k=0
ξk(R, S) (λδ)ke−λδ
k!
.
(12.28)
Proof. Apply (12.25), (12.27), and Eq. (12.23) of Axiom [T].
Thus, pδ(R, S) is the probability of a transition from state R to state S in
δ units of time.

12.3 Continuous Random Walks on a Medium
277
12.3.7 Deﬁnition. We recall that two distinct states R and S of a medium
are called adjacent if there exists some token τ such that Rτ = S or, equiva-
lently, S˜τ = R. Since the only possible transitions are those occurring between
adjacent states, we refer to the Markov process (St) as a random walk process
on the medium (S, T).
In the vein of Lemma 12.3.4, we have the following lemma, generalizing
Axiom [I].
12.3.8 Lemma. For any t > 0, t′ > 0, n ∈N0, and S ∈S, we have
P(St = S Nt = n) = P(St′ = S Nt′ = n).
(12.29)
The proof is in the style of that of Lemma 12.3.4 (see Problem 12.4).
We now turn to the asymptotic probabilities of the states. To this end, we
deﬁne an embedded discrete random walk keeping track of the state of the
process on the arrival of each of the tokens.
12.3.9 Deﬁnition. We deﬁne a collection (Mn)n∈N0 specifying the state of
the process when either n = 0 or the nth token occurs. Using Axiom [I] and
Lemma 12.3.4, Eq. 12.29, we have for any S ∈S
P(Mn = S) = P(St = S Nt = n);
(12.30)
thus, in particular,
P(M0 = S) = P(St = S Nt = 0) = ηS.
(12.31)
For convenience of reference to the Markov chain results recalled in the early
part of this chapter, we write
t(R, S) = t1(R, S) = ξ1(R, S)
(R, S ∈S)
tn(R, S) = ξn(R, S)
(n ∈N, R, S ∈S)
T = (t(R, S))R,S∈S
Tn = (tn(R, S))R,S∈S .
12.3.10 Example. An example of a transition matrix in the case of the ran-
dom walk on the permutohedron medium Π2 of Example 3.5.9 and Figure 12.1
is displayed below. We recall that L3 denotes the set of the six strict linear
orders 1,2,3, and T3 the corresponding set of tokens τij, with i, j ∈{1, 2, 3},
i ̸= j, deﬁned by the equation
τij : L3 →L3 : L →Lτij =

(L \ {ji}) ∪{ij}
if j covers i
L
otherwise.
Writing ϑij > 0 for the probability of token τij, we have the transition matrix

278
12 Random Walks on Media
T =
123
132
213
231
312
321
123
132
213
231
312
321
⎡
⎢⎢⎢⎢⎢⎢⎣
∗
ϑ32
ϑ21
0
0
0
ϑ23
∗
0
0
ϑ13
0
ϑ12
0
∗
ϑ31
0
0
0
0
ϑ13
∗
0
ϑ32
0
ϑ13
0
0
∗
ϑ21
0
0
0
ϑ23
ϑ12
∗
⎤
⎥⎥⎥⎥⎥⎥⎦
(12.32)
in which the ‘∗’ are space saving symbols denoting expressions ensuring that
the entries on each line add up to 1 (thus, the ‘∗’ symbol in the cell (123,123)
represents 1 −ϑ32 −ϑ21).
12.3.11 Theorem. The stochastic process (Mn)n∈N0 is a regular Markov
chain with initial probabilities and transition probabilities deﬁned, for any R
and S in S, respectively by
P(M0 = S) = ηS,
(12.33)
P(Mn+1 = S Mn = R) = t(R, S)
(n ∈N0).
(12.34)
Proof. We only prove that (Mn)n∈N0 is regular. (For the rest of Theorem
12.3.11, see Problem 12.5.) According to Deﬁnition 12.1.7, we have to prove
that for some positive integer N, all the entries of the matrix Tn are positive
if n ≥N. We denote by τV W the token producing W from V , where V and W
are distinct states. For any two states S and R, there is a at least one concise
message mSR = τS1S2 . . . τSm−1Sm, with S = S1 and R = Sm, producing R
from S. This fact implies that tm(S, R) > 0. Indeed, let us denote by ϑV W > 0
the probability of token τV W . The entry in the cell (S, R) of the matrix Tm
must satisfy
tm(S, R) = P(Mm = Sm M0 = S0)
≥P(Mm = Sm, Mm−1 = Sm−1, . . . , M1 = S1 M0 = S0)
(12.35)
= ϑS0S1 × . . . × ϑSm−1Sm > 0,
(12.36)
with an equality replacing the inequality in (12.35) if there is only one concise
message7 producing R from S. In general, let N(S, R) be the length of a
concise message producing R from S, and let N be the smallest common
multiple of all the numbers N(S, R), for all pairs of states (S, R). Clearly, all
the entries of Tn are positive if n ≥N.
7 If there is more than one concise message producing R from S, then all these
messages have the same content and length N(S, R) = m (cf. Theorem 2.3.4),
and so have the same probability expressed in the l.h.s. of (12.36), but this fact
need not be used in this proof.

12.4 Asymptotic Probabilities
279
12.4 Asymptotic Probabilities
12.4.1 Theorem. The asymptotic probabilities of the states of the random
walk (Mn)n∈N0 exist and coincide with those of the random walk process (St).
We have in fact, for any S ∈S,
lim
n→∞P(Mn = S) = lim
t→∞P(St = S) =
/
τ∈bS ϑτ

R∈S
/
µ∈b
R ϑµ
.
(12.37)
Proof. Since (Mn) is regular, we can use Theorem 12.1.9 and assert that the
powers Tn of the transition matrix T are converging to a stochastic matrix A
having each of its q = |S| rows equal to the same vector α = (α1, . . . , αq), the
stationary distribution. It remains to show that this stationary distribution
is that speciﬁed by 12.37. We use Lemma 12.1.12, and prove that for any
R, S ∈S, and writing K for the denominator in (12.37),
1
K
⎛
⎝0
τ∈b
R
ϑτ
⎞
⎠t(R, S) = 1
K
⎛
⎝0
τ∈bS
ϑτ
⎞
⎠t(S, R) .
(12.38)
Recalling the notation △for the symmetric diﬀerence between sets, we con-
sider three cases:
t(R, S) = t(S, R) = 0,
|R △S| > 2,
(Case 1),
t(R, S) = t(S, R) = t(S, S) > 0,
R = S,
(Case 2),
t(R, S) = ϑµ > 0, t(S, R) = ϑ˜µ > 0,
R △S = {µ, ˜µ},
(Case 3)
(for some µ ∈T in Case 3). In Case 1, both sides of (12.38) vanish, whereas
in Case 2, the two expressions on both sides of the equation are identical.
Equation (12.38) also holds in Case 3 since it is equivalent to
⎛
⎝
0
τ∈( b
R∩bS)
ϑτ
⎞
⎠ϑµϑ˜µ =
⎛
⎝
0
τ∈( b
R∩bS)
ϑτ
⎞
⎠ϑ˜µϑµ .
Since we have limn→∞P(Mn = S) = limt→∞P(St = S) (cf. Problem 12.8),
this completes the proof of the theorem.
12.4.2 Remark. In some situations, it makes sense to suppose that the con-
ditional probability of a transition from some state R of the random walk to
some state S ̸= R depends not only on the probability ϑτ of the token τ such
that Rτ = S, but also on R. For example, we might have both Rτ = S and
Wτ = V but the conditional probabilities of a transition to state R would
be diﬀerent and denoted, for example, by ϑτ νR and ϑτ νW , the ﬁrst factor
representing the contribution of some external source, and the second one
the speciﬁc eﬀect on a particular state. A close reading of the above proof

280
12 Random Walks on Media
indicates that the argument used to justify Eq. (12.38) would also apply in
such a case. A version of Theorem 12.4.1 would thus hold, with the products
in Eq. (12.37) having many more factors. This would result in a model with
|T| × |S| −1 independent parameters, which might be of some interest in a
case where extensive sequential data are available. Note that submodels may
be considered in which the number of parameters νR might be substantially
smaller than |S|.
In some experimental situation, organisms may be observed repeatedly at
short intervals of time8. We limit ourselves here to two successive observations
separate by a short interval of time δ. Using Theorem 12.4.1 and Theorem
12.3.6, an explicit expression can be obtained for the asymptotic joint proba-
bility of observing the states R and S at time t and time t+δ, respectively. We
write, as before, ξR,S(k) for the k-step transition probability from the state
R to the state S in the companion Markov chain on S, and pR,S(δ) for the
probability of a transition between the same two states, in δ units of time, in
the stochastic process (St). Deﬁning
q(R) = lim
t→∞P(St = R),
we get
lim
t→∞P(St = R, St+δ = S) = lim
t→∞(P(St = R) P(St+δ = S St = R))
= q(R) pδ(R, S).
From Theorem 12.4.1 and Theorem 12.3.6, we derive:
12.4.3 Theorem. For all states R and S and all δ > 0,
lim
t→∞P(St = R, St+δ = S) =
/
τ∈b
R ϑτ

V ∈S
/
µ∈bV ϑµ
∞

k=0
ξR,S(k) (λδ)ke−λδ
k!
.
We leave the details of the argument as Problem 12.10.
12.5 Random Walks and Hyperplane Arrangements
The results of the previous section are obviously valid for any special case of a
medium. For example, the asymptotic probabilities of a random walk on the
regions of a hyperplane arrangement9 are exactly those described by Theo-
rems 12.4.1 and 12.4.3, provided of course that the region-to-region transition
8 If the interval of time between successive observation is long, then the observations
become essentially independent, and asymptotic results such as Theorem 12.4.1
can be used.
9 Cf. Deﬁnition 9.1.7 and Theorem 9.1.8.

12.5 Random Walks and Hyperplane Arrangements
281
probabilities are consistent with Axioms [T], [I], and [L]. This application is
of interest in view of a similar random walk on the regions of a hyperplane
arrangement investigated by Brown and Diaconis (1998) (see also Bidigare
et al., 1999). We brieﬂy spell out here the diﬀerences between the two ran-
dom walks. We only discuss the discrete case, which is that considered in the
Brown and Diaconis’s paper (referred to below as [BR]).
The following attributes are common to both random walks.
1. The states of the random walk are the regions of some hyperplane ar-
rangement A = {Hi}i∈J.
2. In fact, these states are those of a token system and the set of tokens is
deﬁned from some features of the arrangement A.
3. A probability distribution ϑ is postulated on the set of those tokens, and a
region-to-region transition occur when a token is selected that is eﬀective
on the current state. The values of all the probabilities are assumed to be
positive (by deﬁnition for us and in an important special case for [BR]).
The essential diﬀerence lies in the deﬁnition of the tokens. In our case,
each hyperplane gives rise to two mutually reverse tokens which govern the
back and forth transitions between two adjacent regions. As a result, the token
system turns out to be a medium, which leads to the asymptotic formulas of
Theorems 12.4.1 and 12.4.3. In the [BD] model, it is assumed that a token is
associated to each of the faces of the regions deﬁned by A. Let us denote by F
the collection of all these faces, and by TF = {τF
F ∈F} the corresponding
collection of the tokens. Suppose that the random walk is in region S and that
some token τF has been randomly selected from the distribution ϑ. We have
then SτF = T for some region T if T is the closest region to S having F as a
face. Notice that if S and T are two adjacent regions, then
SτT = T
and
TτS = S.
(12.39)
This implies that the graph of the medium at the core of our random walk
on the regions of the arrangement is a subgraph of the graph of the [BD] token
system. However, (12.39) does not mean that whenever S and T are adjacent
regions, then τS and τT are mutual reverses. Indeed, the pair of equations
(12.39) hold even if the regions S and T are not adjacent. Thus, our random
walk could not arise as a special case of the [BD] random walk simply by
assuming that the probability distribution ϑ on TF vanishes on all the faces
that are not regions. As an illustration of these remarks, Figure 12.2 displays
a non-central arrangement deﬁned by three lines. There are 19 faces:
7 regions
F1, . . . , F7,
6 rays
F8, . . . , F13,
3 segments
F14, F15 and F16,
3 points
F17, F18 and F19.

282
12 Random Walks on Media
1
2
3
4
5
6
7
8
9
10
11
12
13
F
F
F
F
F
F
F
F
F
F
14
15
16
F
F
17
18
19
F
F
F
F
F
F
F
Figure 12.2. The non-central arrangement of three lines; in red the corresponding
mediatic graph. Nineteen faces, labelled F1, . . . , F19, are deﬁned by the four regions.
The mediatic graph deﬁned by the arrangement is pictured in red. The
three segments emerging from region F2 represent the three pairs of mutually
reverse tokens linking region F2 to the three adjacent regions F3, F7 and F1.
By contrast, in the token system deﬁned in the [BD] model, the region F2
can produce all the other regions of the arrangement by application of the
appropriate tokens, with several diﬀerent tokens producing the same state in
some cases. (So, the graph of this stoken system is not a simple graph.) There
is one token per face in this model. Denoting by τi the token corresponding
to face Fi, 1 ≤i ≤19, we have indeed:
F2τ3 = F2τ10 = F3,
F2τ4 = F2τ11 = F4,
F2τ5 = F5,
F2τ6 = F2τ12 = F6,
F2τ1 = F2τ13 = F1,
F2τ7 = F2τ15 = F2τ19 = F2τ16 = F7.
So, the token system deﬁned by the [BD] model is not a medium. Still, the
asymptotic probabilities of the states exists, but their description is more
complicated (cf. Brown and Diaconis, 1998; Bidigare et al., 1999).
Problems
The Markov chain concepts introduced in the ﬁrst part of this chapter have
been kept to the minimum useful for the derivation of the asymptotic results
states in Theorems 12.4.1 and 12.4.3, which will be used in some of the ap-
plications described in Chapter 13. In Problems 12.11-12.16, we introduce a
few other standard concepts and results.

Problems for Chapter 12
283
12.1 Prove that the two formulations (12.1) and (12.2) are equivalent.
12.2 Axiomatize directly—that is, not as an embedded process—a discrete
random walk on a medium.
12.3 Would regularity still hold with the following weakened version of Ax-
iom [Ma]: For any two states R and S, there exists a message producing R
from S?
12.4 Prove Lemma 12.3.8.
12.5 Prove that the stochastic process (Mn)n∈N0 is a Markov chain satisfying
12.33 and 12.34 (cf. Theorem 12.3.11).
12.6 Show that for all n ≥N all the entries of the matrix Tn are positive,
where T is deﬁned by (12.32). What is the minimum N for which this is true,
and why? (Explain in terms of media concepts.)
12.7 Axiomatize and investigate the random walk sketched in Remark 12.4.2.
Restate and prove for this new model the most important results, such as the
asymptotic probabilities of the states.
12.8 Prove that we have indeed limn→∞P(Mn = S) = limt→∞P(St = S) as
stated at the end of the proof of Theorem 12.4.1.
12.9 By Theorem 12.1.9, the successive powers Tn of the transition matrix T
converge (as n →∞) to a stochastic matrix A having identical rows. The speed
of convergence is surprizingly fast. Simulate this convergence by computation
on an example (using a software such as Mathematica). Take the matrix T to
be consistent with the probabilities of the tokens of a medium.
12.10 Prove Theorem 12.4.3.
12.11 Let ↣be a binary relation on the set of states S of an homogeneous
Markov chain, deﬁned by: i ↣j ⇔i = j or tn(i, j) > 0 for some n ∈N,
with tn as in Deﬁnition 12.3.9. When i ↣j, we say that j is accessible from
i, or i communicates with j. This relation will be used to gather the states
into classes of mutually accessible states. The relation ↣is the accessibility
relation of the Markov chain (Xn). A state j such that j ↣k ↣j for some
state k is called a return state. Prove that the relation ↣is a quasi-order,
that is ↣is transitive and reﬂexive (cf. 1.8.3, page 14).

284
12 Random Walks on Media
12.12 (Continuation.) Let S be the set of equivalence classes induced by the
accessibility relation ↣, and let ≾be the corresponding partial order on the
set S. For any state i, we denote by [i] the class of all states j such that
both i ↣j and j ↣i hold. Thus, S = {[i] i ∈S}, and for all i, j ∈S,
[i] ≾[j] ⇐⇒i ↣j. The elements of S are thus classes of states. Every
maximal element of S (for the partial order ≾) is an ergodic class, and the
elements of an ergodic class are called ergodic states. An element of S which
is not ergodic is said to be a transient class. An element of a transient class
is called a transient state. We denote by E and E, respectively, the set of
all ergodic states and the family of all ergodic classes. The letters U and U
stand for the set of all transient states and the family of all transient classes,
respectively. Thus, S = E + U and S = E + U. When an ergodic class contains
a single state, this state is called absorbing. Prove that any Markov chain has
at least one ergodic state, but there may not be any transient state.
12.13 (Continuation.) Prove that a state i of a homogeneous Markov chain
is absorbing if and only if t(i, i) = 1.
12.14 (Continuation.) A ﬁnite Markov chain tends to evolve towards the
ergodic classes. Prove the following: For a ﬁnite Markov chain (Xn) with the
family E of ergodic classes, we have
lim
n→∞P(Xn ∈∪E) = 1.
12.15 (Continuation.) As indicated above, a state j is a return state if j ↣
i ↣j for some state i. Thus, j is a return state if the set R(j) = {n ∈
N tn(j, j)} is not empty. In such a case, the set R(j) is necessarily inﬁnite
since we obviously have n + m ∈R(j) for any n, m ∈R(j). The period of any
return state j is the greatest common divisor of R(j). A state is said to be
aperiodic if it has period 1. A homogeneous Markov chain is aperiodic if all
its states are aperiodic. Prove that if two states are mutually accessible, then
they necessarily have the same period.
12.16 (Continuation.) A chain without transient classes is called ergodic.
Such a chain may have several ergodic classes, however. When a chain has a
unique ergodic class, then this chain is said to be irreducible. The justiﬁca-
tion for this terminology is that a chain with several ergodic classes may be
decomposed into components chains, each with a single ergodic class. Each of
these subchains may be studied separately since there is no communication
between the ergodic classes. Prove that a ﬁnite homogeneous Markov chain is
regular if and only if it is ergodic, irreducible, and aperiodic.

13
Applications
In this chapter, we describe two quite diﬀerent extended examples of media.
The ﬁrst one was encountered several times already (in Chapter 1, 4, and 11)
under the title ‘Learning Spaces.’ It deals with a situation where the states of
the medium are the possible knowledge states of individuals in some academic
subject such as arithmetic or algebra. We begin by discussing a method for
constructing a learning space on the basis of a teacher’s expertise on the topic,
and then outline a probabilistic algorithm for the assessment of knowledge in
such learning spaces. The second example is also probabilistic. The states of
a medium are taken to represent the latent opinion of potential voters. The
evolution of these opinions over (continuous) time are modeled as a random
walk whose states are exactly the states of the medium. This type of model
has been used extensively to analyze the changes over time observed in the
voting behavior of respondents to a political poll. The application described
here, which relies on the real time random walk theory developed in Chapter
12, is based on extensive data pertaining to the 1992 presidential election
context opposing Bill Clinton, George H.W. Bush, and Ross Perot.
13.1 Building a Learning Space
Consider a topic in mathematical education, such as elementary algebra1.
From the standpoint of assessing the students’ competence, this topic can
be delineated by a ﬁnite set Q of problem types, or items, that a student
must learn to solve. We call instance a particular case of a problem type,
obtained for example by choosing the numbers involved in the problem, or
the exact phrasing of a ‘word problem2.’ The set Q speciﬁes the curriculum.
1 We closely follow Falmagne et al. (2006b) in our description of this ﬁrst applica-
tion.
2 Our use of the term item is consistent with the meaning in Doignon and Falmagne
(1999), but diﬀers from the usage in psychometrics, where ‘item’ is referred to
what we call ‘instance.’

286
13 Applications
An examination of a representative sample of textbooks indicates that, for
beginning algebra (sometimes called “Algebra 1”), the set Q contains approx-
imately 250 problem types (see Remark 13.1.1(a)). Recalling Deﬁnition 1.6.1,
a pair (Q, K) is a knowledge structure if K is a family of subsets of Q contain-
ing all the knowledge states that are feasible, that is, that could characterize
some individual in a population of reference. In other words, an individual in
knowledge state K in K can, in principle3 solve all the problem types in K
and would fail any problem in Q\K. It is assumed that a knowledge structure
K contains ∅and ∪K = Q: it is possible for someone to know everything, and
for somebody else to know nothing at all in Q. In practice, because algebra
is a highly structured topic, whose concepts are practically always taught in
approximately the same order, |K| is considerably smaller than 2250, the num-
ber of subsets in set of size 250. Typically4, |K| is of the order of 108, which
is within the capabilities of modern P.C.’s. Further constraints are imposed
on K in the form of the two axioms recalled below, making the pair (Q, K) a
learning space (cf. 1.6.1).
[K1] If K ⊂L are two states, with |L \ K| = n, then there is a chain of
states K0 = K ⊂K1 ⊂· · · ⊂Kn = L such that Ki = Ki−1 + {qi}
with qi ∈Q for 1 ≤i ≤n.
[K2] If K ⊂L are two states, with K∪{q} ∈K and q /∈L, then L∪{q} ∈K.
Some reﬂection shows that both of these axioms are quite sensible from a
pedagogical standpoint. Taken together, they are formally equivalent to the
hypothesis that K is a wg-family which is closed under unions (cf. Theorem
4.2.1). In fact, K can be regarded as the collection of positive contents of a
rooted, closed medium (Theorem 4.2.2).
13.1.1 Remarks. (a) For concreteness, six examples of items and instances in
beginning algebra are given in Table 13.1. Since some of these items obviously
cover a considerable number of instances, the number of speciﬁc problems
implicitly involved in an assessment based on Q and K is very large.
(b) The construction of the collection K of knowledge states in a practi-
cal situation is for the time being a very demanding task, relying in part on
the judgement of expert teachers responding to probing questions about the
curriculum. These questions can be generated systematically by the QUERY
routine developed by Koppen (1993), Dowling (1993a), Dowling (1993b) and
Cosyn and Thi´ery (2000) (see also Villano, 1991; M¨uller, 1989; Kambouri
et al., 1994; Dowling, 1994; Doignon and Falmagne, 1999). The resulting
structure is only a preliminary step, potentially plagued by inconsistencies
in the experts’ responses (see Kambouri, 1991), and in need of reﬁnements
and corrections dictated by a statistical analysis of students’ data. Neverthe-
less, because the theoretical basis of the QUERY routine is intimately related
3 Discounting careless errors, for example.
4 For topics in elementary mathematics such as arithmetic, geometry or algebra.

13.1 Building a Learning Space
287
to the very deﬁnition of a learning space, and so of a closed, rooted medium
(cf. Theorem 4.2.2) we will brieﬂy review its principles here.
13.1.2 The Query Routine. From the standpoint of an expert, such as an
experienced teacher, the ﬁrst step, or Block 1, of the the QUERY routine
takes the form a series of questions such as
[Q1] Suppose that a student is not capable of solving problem p. Would
this student also fail problem p′?
The respondents are told to discount chance factors such as careless errors and
lucky guesses. More complex questions are asked in Blocks 2, 3, etc. which
are discussed in Section 13.2. Assuming that the experts are both logically
consistent and reliable, the positive responses to questions of the type [Q1]
induce a quasi order on the set Q of items. In practice, only a small subset
of the set of possible questions needs to be asked. This is due in part to the
transitivity of the quasi order: in QUERY, each of the successive questions is
chosen so as to maximize the number of potential inferences. An example of
the quasi orders obtainable at the end of Block 1 is represented by its Hasse
diagram5 in Figure 13.1 which is reproduced from Falmagne et al. (2006b), as
is Table 13.1.
Thus, an answer “Yes” to [Q1] is represented by a sequence of arcs begin-
ning at the vertex representing p’ and ending at the vertex representing p in
the Hasse diagram of Figure 13.1. For concreteness, the vertices corresponding
to six actual problem types are represented in the diagram by the red dots
labelled (a),. . . ,(f). The text of some of the instances of the six problems types
is given in the second column of Table 13.1.
We will show in this section that such a quasi order deﬁnes a wg-family
of sets closed under both union and intersection, thereby inducing a medium
which is both u-closed and i-closed (see Deﬁnition 4.1.2).
13.1.3 Deﬁnition. We recall from Deﬁnition 3.1.5 that a knowledge struc-
ture K on a set Q is discriminative if
q = t
⇐⇒
(∀K ∈K : q ∈K ⇔t ∈K)
(q, t ∈Q).
(13.1)
A knowledge structure is called a knowledge space if it is closed under union.
It is called quasi ordinal if it is closed under both union and intersection. A
quasi ordinal knowledge structure is partially ordinal if it is discriminative.
We also recall the notation Kq = {K ∈K q ∈K} for all q ∈Q.
5 We assume that the items have been gathered in the equivalence classes of the
quasi order, inducing a partial order (see Deﬁnition 13.1.3). Actually, this partic-
ular Hasse diagram, which only covers part of beginning algebra, was obtained
from the combined results of Block 1 of QUERY with some experts, with an
extensive analysis of students’ data.

288
13 Applications
a
b
c
d
e
f
Figure 13.1. Hasse diagram of the partial order obtained from Block 1 of the
QUERY routine for part of Beginning Algebra (from Falmagne et al., 2006b). The
vertices marked a-f refer to Problems types (a)-(f) of Table 13.1.
Notice that the r.h.s. of (13.1) deﬁnes an equivalence relation on Q. Thus,
for any knowledge structure K, the elements of Q can be gathered into equiv-
alence classes so as to form a discriminative knowledge structure. The main
tool to establish that a quasi order deﬁnes a well-graded knowledge structure
closed under union and intersection is Theorem 13.1.5, which is due to Birkhoﬀ
(1937). The proof given below is that of Doignon and Falmagne (1999) and is
included for completeness. We rely on a preparatory lemma.

13.1 Building a Learning Space
289
Table 13.1. Six types of problems in Elementary Algebra
Name of problem type
Example of Problem
(a)
Word problem on proportions A car travels on the freeway at an
(Type 1)
average speed of 52 miles per hour.
How many miles does it travel in
5 hours and 30 minutes?
(b)
Plotting a point in the
Using the pencil, mark the point at
coordinate plane
the coordinates (1, 3).
(c)
Multiplication of monomials
Perform the following multiplication:
4x4y4 · 2x · 5y2
and simplify your answer as much as
possible.
(d)
Greatest common factor of
Find the greatest common factor of
two monomials
the expressions 14t6y and
4tu5y8.
Simplify your answer as much as
possible.
(e)
Graphing the line through a
Graph the line with slope −7 passing
given point with a given slope through the point (−3, −2).
(f )
Writing the equation of the
Write an equation for the line that
line through a given point and passes through the point (−5, 3) and is
perpendicular to a given line
perpendicular to the line 8x + 5y = 11.
13.1.4 Lemma. If K and K′ are two quasi ordinal knowledge structures on
the same set Q, then
(∀q, t ∈Q : Kq ⊆Kt ⇔K′
q ⊆K′
t)
⇐⇒
K = K′.
(13.2)
Proof. The suﬃciency is immediate. Suppose that K ∈K. This implies
K = ∪s∈K (∩K′
s) = K′.
(13.3)
Note that K′ ∈K′ because K′ is quasi ordinal. We will prove that in fact
K = K′. Take any t ∈K′. By deﬁnition of K′, we must have q ∈K such that
t ∈∩K′
q. This gives K′
q ⊆K′
t. By the equivalence in the l.h.s. of (13.2), we get
Kq ⊆Kt; thus t ∈∩Kq, yielding t ∈K. We obtain K′ ⊆K, and by (13.3),
K = K′. We conclude that K ⊆K′, and by symmetry, K = K′.
13.1.5 Theorem. There is a 1-1 correspondence between the collection of all
quasi ordinal knowledges structures K on a set Q and the collection of all
quasi orders Q on Q. This correspondence is speciﬁed by the two equivalences
q Q t
⇐⇒
(∀K ∈K : t ∈K ⇒q ∈K)
(q, t ∈Q)
(13.4)
K ∈K
⇐⇒
(∀q, t ∈Q : t ∈K ⇒q ∈K)
(K ⊆Q).
(13.5)
Moreover, under this correspondence, partial orders are mapped onto partially
ordinal knowledge structures.

290
13 Applications
Note that (13.4) can be written compactly as
q Q t
⇐⇒
Kq ⊇Kt ,
(q, t ∈Q).
(13.6)
Proof. The compact form (13.6) of the equivalence (13.4) clearly deﬁnes the
relation Q as a quasi order on Q. Conversely, for any quasi order Q on Q,
the equivalence (13.5) deﬁnes a family K of subsets of Q. We show that such
family is a partially ordinal knowledge structure. It obviously contains Q
and ∅(the latter because in this case the implication in the r.h.s. of (13.5)
holds vacuously). Thus K is a knowledge structure. Suppose that {Ki i ∈I}
is a subfamily of K. By (13.5), we have
∪i∈IKi ∈K
⇐⇒
(∀q, t ∈Q : (t ∈∪i∈IKi) ⇒(q ∈∪i∈IKi)),
So, suppose that qQt with t ∈∪i∈IKi for some t ∈Q. We obtain t ∈Kj for
some index j ∈I. This implies q ∈Kj by (13.5) yielding q ∈∪i∈IKi; and so
(∪i∈IKi) ∈K. The proof that we also have (∩i∈IKi) ∈K is similar. Thus, to
each quasi order Q on Q corresponds a quasi ordinal knowledge structure K
on Q. We now show that the correspondence is 1-1.
Let K be the collection of all the quasi ordinal knowledge structures K on
Q, and let Q be the collection of all quasi orders Q on Q. We prove that the
two mappings
f : K →Q : K →f(K) = Q,
g : Q →K : Q →g(Q) = K,
deﬁned by (13.4) and (13.5) are mutual inverses. The function f must be
injective by Lemma 13.1.4 and the equivalence (13.6) restating (13.4). Take
any quasi order Q on Q, with say K = g(Q) and f(K) = Q′. We will show
that Q = Q′; thus any quasi order is in the range of the function f. Since f is
injective, f and g must be mutual inverses.
Suppose that pQq. With (13.5) deﬁning g, this implies Kq ⊆Kp, yielding
pQ′q by (13.6); thus, Q ⊆Q′. Conversely, if pQ′q, then since f −1(Q′) = K, we
get again Kq ⊆Kp, which gives pQq by (13.6). We get Q′ ⊆Q and so Q = Q′.
The last statement concerning ordinal spaces is immediate.
13.1.6 Theorem. Any partially ordinal knowledge structure is well-graded,
and so can be regarded as the family of positive contents of a u-closed and
i-closed medium.
Proof. We prove that any partially ordinal knowledge structure K is a learning
space and use Theorem 4.2.1. Suppose that L and K ⊂L are in K. If K +{q}
is also in K, then L + {q} = L ∪(K + {q}) ∈K because K is closed under
union. So, Axiom [K2] of a learning space holds (see Deﬁnition 1.6.1). Turning
to Axiom [K1], recall that K is discriminative. Thus, for two distinct items
in L \ K there is some N ∈K containing one but not both of them. (If
|L \ K| = 1, there is nothing to prove.) Since K is closed under intersection

13.2 The Entailment Relation
291
and union, K ∪(L∩N) is in K, with K ⊂K ∪(L∩N) ⊂L. Axiom [K1] follows
by induction. Using the implication (i)⇒(ii) of Theorem 4.2.1, we conclude
that K is well-graded.
To sum up, collecting all the responses of an expert to the questions of
type [Q1] gives a partial order which by Theorems 13.1.5 and 13.1.6, provides
a learning space closed under intersection. The interest of such a structure is
that it can be conveniently summarized by a Hasse diagram. On the negative
side, there are no pedagogically sound arguments supporting the closure under
intersection. Moreover, stopping the QUERY routine after Block 1 has the
eﬀect of retaining in the knowledge structure a potentially large number of
states that are never encountered in practice. Obviously, the presence of such
useless states lengthen the assessment. The remaining blocks of the QUERY
routine solve this diﬃculty, at least in principle6. Its output is a family of
sets closed under union, but not necessarily well-graded nor closed under
intersection. This part of the QUERY routine, although of theoretical interest,
is not used in practice with human experts. We review the results in the next
section.
The data resulting from questions of type [Q1] are only the ﬁrst step in
the construction of a satisfactory learning space. This initial learning space is
generally adequate and can proﬁtably be used by the schools, but is far from
fully satisfactory. During Step 2, this preliminary learning space is gradually
(and manually) altered on the basis of students’ data. This second phase takes
several months. While this method has been shown to yield, in practice, very
reliable assessment results (see Falmagne et al., 2006a), it pertains more to
art than to technique, and is prohibitively labor intensive. Much progress
remains to be done in this area. One promising, realistic possibility would
consist in automatizing the reﬁnement of a learning space via an algorithm
computing a statistical index of the ﬁt of a current learning space with relevant
statistics on students’s responses, and implementing an change of the learning
space whenever whenever a threshold is reached by such an index. Such a
development is in the works.
13.2 The Entailment Relation
The remaining blocks of the QUERY routine ask more demanding questions
of the following type.
[Q2] Suppose that a student has not mastered problems p1, p2, . . . , pn.
Would this student also fail problem p′?
As in the case of [Q1], the expert is told to discount careless errors and
lucky guesses. Obviously, [Q2] generalizes [Q1]; thus n = 1, 2, . . . in [Q2]
6 If not in fact, because the questions of type [Q2] are much more diﬃcult and the
experts tend to be much less reliable.

292
13 Applications
corresponds to Block 1, 2, . . . of the QUERY routine. The positive responses
to all the questions covered by [Q2] deﬁne a relation R ⊆P(Q) × Q, which is
consistent with the (unknown) family K if R satisﬁes the equivalence
S R q
⇐⇒
(∀K ∈K : S ∩K = ∅⇒q /∈K)
(13.7)
(S ∈P(Q) \ {∅}, q ∈Q).
The meaning of the relation R is captured by the following two theorems,
due to Doignon and Falmagne (1999). We omit both proofs. We ask the reader
to provide the proof of Theorem 13.2.1 in Problem 13.3; for the proof of
Theorem 13.2.3, see Doignon and Falmagne (1999).
13.2.1 Theorem. Let (Q, K) be a knowledge structure and suppose that the
relation R is deﬁned by (13.7); then,
(i) (∀s ∈S, T R s) ∧S R t =⇒T R t ;
(ii) q ∈S ⊆Q =⇒SRq.
Thus, Condition (ii) states that R extends the inverse membership relation.
13.2.2 Deﬁnition. A relation R ⊆(P(Q) \ {∅}) × Q satisfying Conditions
(i) and (ii) of Theorem 13.2.1 is called an entailment for Q.
The next theorem generalizes the result of Birkhoﬀ(1937) recalled as our
Theorem 13.1.5.
13.2.3 Theorem. Let Q be a nonempty set. There exists a 1-1 correspon-
dence between the family of all knowledge spaces K on Q and the collection
of all entailments R for Q. This correspondence is speciﬁed by the two equiv-
alences
S R q
⇐⇒
(∀K ∈K : S ∩K = ∅⇒q /∈K)
(13.8)
K ∈K
⇐⇒
(∀(S, q) ∈R : S ∩K = ∅⇒q /∈K)
(13.9)
(S ∈P(Q) \ {∅}, q ∈Q).
We omit the proof (see Doignon and Falmagne, 1999, Theorem 5.5). Interest-
ingly, in the kind of situations considered here, that is, topics in elementary
mathematics, the questioning of the experts by the QUERY routine termi-
nates relatively early. Experiments have shown that the full knowledge space
may be obtained, in some cases, with n ≤5 in [Q2] (see Kambouri, 1991).
Nevertheless, asking questions of type [Q2] to expert teachers is not a very
proﬁtable exercise because, as mentioned earlier, their responses are not reli-
able. In particular, the agreement between teachers is relatively poor at least
for questions of type n ≥2 in [Q2]. To palliate this unreliability of the experts,
Cosyn and Thi´ery (2000) have developed a ‘PENDING STATUS’ variation
of the QUERY routine in which the responses of an expert are only imple-
mented after a conﬁrmation. In other words, a response r to a question q is

13.3 Assessing Knowledge in a Learning Space
293
temporarily stored in a stack until a response to a later question either con-
tradicts r (by implication), in which case q and r are deleted, or that response
conﬁrms r, which is then implemented. This technique can be used for both
[Q1] and [Q2] types of questions. It has obvious advantages, and can even be
modiﬁed to compute a personal index of reliability for an expert, enabling the
selection of competent experts whose judgement may be more trustworthy.
So far, however, it has not been used in practice.
13.3 Assessing Knowledge in a Learning Space
Taking for granted that we have a suitable learning space, the goal of an as-
sessment is to uncover, by eﬃcient questioning the state of a student under
examination7. The situation is similar to that of adaptive testing—i.e. the
computerized forms of the GRE and other standardized tests (see, for ex-
ample Wainer et al., 2000)—except that the outcome of the assessment is a
knowledge state, rather than a numerical estimate of a student’s competence
in the topic. The procedure follows a scheme outlined in Figure 13.2, which
is reproduced from Falmagne et al. (2006b) (as are the other ﬁgures in this
section8).
Subject's
response
Questioning
     Rule
Updating
    Rule
Plausibility
of the states
on trial n
Plausibility
of the states
on trial n+1
Selected
problem
Figure 13.2. Transition diagram of the assessment procedure.
At the outset of the assessment procedure (trial 1), an a priori proba-
bility (referred to as ‘plausibility’ in Figure 13.2) is assigned to each of the
knowledges states, depending on what is known about the student, such as
the age or the school year. The sum of these probabilities is thus equal to 1.
They play no role in the ﬁnal result of the assessment but may be helpful
in shortening it. If no useful information is available, then all the states are
assigned the same probability. The ﬁrst problem p1 is selected so as to be
7 In this section, we follow the description of the algorithm given in Falmagne
et al. (2006b,a). The algorithm was originally proposed by Falmagne and Doignon
(1988a). A discrete procedure, based on a ﬁnite Markov chain, can be found in
Falmagne and Doignon (1988b).
8 With the permission of Falmagne’s co-authors.

294
13 Applications
‘maximally informative.’ More than one interpretation can be given to this
term. It means here that, on the basis of the a priori probability distribution
on the set of states, the student has about a 50% chance of knowing how to
solve p1. In other words, the sum of the probabilities of all the states con-
taining p1 is as close to .5 as possible9. If several problems are maximally
informative in the above sense (as may happen at the beginning of an assess-
ment), one of these problems is randomly selected. The student is then asked
to solve an instance of that problem, also picked at random. The student’s
response is then checked by the system, and the probability distribution is
modiﬁed according to the following updating rule. If the student gave a cor-
rect response to p1, the probability of each of the states containing p1 is
increased and, correspondingly, the probability of each of the states not con-
taining p1 is decreased (so that the overall probability, summed over all the
states, remains equal to 1). A false response given by the student has the
opposite eﬀect: the probability of all the states not containing p1 is increased,
and that of the remaining states decreased. The exact formula of the operator
modifying the probability distribution will not be recalled here; see Deﬁnition
10.10 in Doignon and Falmagne (1999). It is proved there that this operator
is commutative, in the sense that its cumulative eﬀect in the course of a full
assessment does not depend upon the order in which the problems have been
proposed to the student. This commutativity property is consistent with the
fact that, as observed by Mathieu Koppen10, this operator is Bayesian. If the
student does not know how to solve a problem, he or she can choose to answer
“I don’t know” instead of guessing. This results in a substantial11 increase in
the probability of the states not containing p1, thereby decreasing the total
number of questions required to uncover the student’s state. Problem p2 is
then chosen by a mechanism identical to that used for selecting p1, and the
probability values are increased or decreased according to the student’s re-
sponse via the same updating rule. Further problems are dealt with similarly.
In the course of the assessment, the probability of some states gradually in-
creases. The assessment procedure stops when two criteria are fulﬁlled: (1) the
entropy of the probability distribution, which measures the uncertainty of the
assessment system regarding the student’s state, reaches a critical low level,
and (2) there is no longer any useful question to be asked (all the problems
have either a very high or a very low probability of being solved correctly).
At that moment, a few likely states remain and the system selects the most
likely one among them. Note that, because of the stochastic nature of the as-
sessment procedure, the ﬁnal state may very well contain a problem to which
9 A diﬀerent interpretation of ‘maximally informative’ was also investigated, based
on the minimization of the expected entropy of the probability distribution. This
method did not result in an improvement, and was computationally more de-
manding (Problem 13.4).
10 Personal communication.
11 As compared to a false response, in which case the increase would be less: a false
response could be imputed to a careless error.

13.3 Assessing Knowledge in a Learning Space
295
the student gave a false response. Such a response is thus regarded as due to
a careless error. As mentioned earlier, because all the problems have either
open-ended responses or multiple choice responses with a large number of
possible solutions, the probability of lucky guesses is negligible.
To illustrate the evolution of an assessment, a graphic representation is
used in the form of a probability map of the learning space, which evolves in
the course of an assessment. For practical reasons, the example given by Fal-
magne et al. (2006b) and reproduced here is a small scale one, which concerns
a part of arithmetic consisting in 108 problems, rather that the full arithmetic
domain whose large number of states would render the graphic representation
computationally more diﬃcult. In principle, each colored pixel in the oval
shape of Figure 13.3 represents one of the 57,147 states of the learning space
for that part of arithmetic. (Because of graphics limitations, some grouping
of similar states into a single pixel was necessary.)
Empty state
Full state
Entropy = 8.19
108
Most likely
Most unlikely
Figure 13.3. Probability map of the learning space representing the exemplary
part of arithmetic under discussion.
Knowledge states are ordered along the abscissa according to the number
of problems they contain, from 0 problems on the far left to 108 problems on
the far right. The leftmost point stands for the empty knowledge state, which
is that of a student knowing nothing at all in that part of arithmetic. The
rightmost point represents the full domain of 108 problem. The points located
on any vertical line within the oval represent knowledge states containing
exactly the number of problems indicated on the abscissa.
The oval shape given to the map reﬂects, with some idealization, the fact
that, by and large, there are many more states around the middle of the
scale than around the edges. For instance, there are 1,668 states containing
exactly 75 problems, but fewer than 100 states containing either more than 100
problems or fewer than 10 problems. The arrangement of the points on any
vertical line is arbitrary.
The color of a pixel indicates the probability of the corresponding state.
A color coded logarithmic scale, pictured on the right of Figure 13.3, is used
to represent the values of the probabilities. Red, orange, and yellow-white

296
13 Applications
indicate states with a probability exceeding the mean of the distribution,
with yellow-white marking the most likely states. Conversely, dark blue, blue,
and light blue represent states that are less likely than the mean, with dark
blue marking the least likely states.
The spiral display of Figure 13.4 represents a sequence of probability maps
describing the evolution of an assessment from the initial state, before the ﬁrst
problem, to the end, after the response to the last problem is recorded by the
system and acted upon to compute the last map. The complete assessment
took 24 questions, which is close to the average for this part of arithmetic. The
initial map results from preliminary information obtained from that student.
The reddish strip of that map represents the a priori relatively high proba-
bilities of the knowledge states containing between 58 and 75 problems: as a
six grader, this student can be assumed to have mastered about two thirds of
this curriculum.
Final state
Final likelihood
Initial likelihood
Q. #24
(correct)
Q. #23
(correct)
(correct)
(false)
Q. #3
(failed)
Q. #16
(failed)
(failed)
Q. #17
Q. #9
(not known)
(correct)
Q. #10
E = 9.55
E = 3.36
E = 3.06
E = 3.68
E = 4.81
E = 4.94
E = 5.02
E = 6.29
E = 6.82
E = 7.63
E = 9.21
E = 9.37
Entropy = 10.20
Question #1
Q. #2
Most unlikely
Most likely
Figure 13.4. Sequence of probability maps representing an assessment converging
toward the student’s knowledge state. In the ﬁnal map, the slected state is marked
by the long arrow pointing to the circle.

13.4 The Stochastic Analysis of Opinion Polls
297
Next to each of the maps in Figure 13.4 ﬁgure the entropy of the corre-
sponding probability distribution and the student’s response to the question
(correct, false, or not known). The initial entropy is 10.20, which is close to
the theoretical maximum of 10.96 obtained for a uniform distribution on a set
of 57,147 knowledge states. The entropy decreases gradually as more informa-
tion is gathered by the system via the student’s responses to the questions.
Eventually, after 24 questions have been answered, a single very bright point
remains (indicated by the red arrow) among mostly dark blue points and a
few bright points. This very bright point indicates the most likely knowledge
state for that student, based on the responses to the problems. The assessment
stops at that time because the entropy has reached a critical low level and the
next ‘best’ problem to ask has only a 19% chance of being solved, and so would
not be very informative. In this particular case only 24 problems have suﬃced
to pinpoint the student’s knowledge state among 57,147 possible ones. This
striking eﬃciency is achieved by the numerous inferences implemented by the
system in the course of the assessment. With the full arithmetic curriculum
from the 4th grade up, the assessment takes around 30-35 questions.
In Falmagne et al. (2006a), the authors analyze the reliability/validity
of such an assessment in beginning algebra by the following method. In the
course of each assessment, an extra problem is a posed to the student, the
response to which is not taken into account in gauging the knowledge state of
the student. The student’s response can be predicted from the assessed state
and correlated with the actual response. The observed correlations (in the
form of odds ratios) are quite high.
13.4 The Stochastic Analysis of Opinion Polls
In our last example, we review a very diﬀerent type of application of stochastic
media theory in which the states of a medium coincide with those of a random
walk describing the evolution of voters’ opinions, as revealed by political polls.
The states are typically order relations of some sort, such as semiorders or
weak orders. Our discussion in this section draws on the theoretical approach
and the empirical results presented in Falmagne and Doignon (1997), Regen-
wetter et al. (1999), Falmagne et al. (2007), Hsu et al. (2005), and Hsu and
Regenwetter (in press) (see also Falmagne, 1997; Falmagne et al., 1997). The
analysis of the data relies essentially on the results presented in Chapter 12,
in particular Theorems 12.4.1 and 12.4.3.
The exemplary data considered here consists of the responses given by po-
tential voters, called the respondents, to surveys of their opinions concerning
the three major candidates in the 1992 Presidential Election in the US. The
candidates in that election were George Bush, Bill Clinton and Ross Perot.
Two surveys, one performed before the election, and the other just after, are
analyzed jointly, the respondent being the same in both surveys. These re-
spondent were classiﬁed in terms of their political aﬃliation (independent,

298
13 Applications
democrat, or republican). The set of respondents is referred as a panel and is
regarded as a random sample in the population of potential voters. For each
survey, the opinion of a respondent is expressed in the form of a thermometer
score, attributed to each of the three candidates, and ranging from 0 to 100.
For one particular respondent at some time t of a survey, these scores might
be, with obvious abbreviations for the names of the candidates,
(b, 45),
(c, 50),
and ( p, 37).
(13.10)
13.4.1 A Random Walk on Weak Orders. In this model, which was de-
veloped by Falmagne et al. (1997) and tested experimentally by Regenwetter
et al. (1999) and Hsu and Regenwetter (in press), only the (strict) weak order
relation (cf. 1.8.3, page 14) induced by the thermometer scores is retained, so
that (13.10) gets translated in a straightforward manner into p ≺b ≺c . The
relation ≺is one of the 6 possible linear orders on the set {b, c, p}. Overall,
there are 13 weak orders on that set, which are represented by their Hasse
diagrams in each of the 13 black frames Figure 13.5. These 13 weak orders
are regarded as the states of a medium, which is represented by the black
digraph in Figure 13.5. (Disregard the pale red part of the ﬁgure for the mo-
ment.) There are two pairs of tokens (τi, ˜τi) and (τ−i, ˜τ−i) per candidate, with
i ∈{b, c, p}. The eﬀect of the tokens can be inferred from the digraph. It can
be seen from the graph that the tokens τi “push” a candidate up in the weak
order, inducing a diﬀerent weak order in which candidate i has a diﬀerent
relative position, while the token τ−i has the opposite eﬀect. More precisely,
let W be the set of all weak orders on the set {b, c, p}; thus, W is the set of
states of the medium. For any tokens τi and τ−i and any weak order ≺∈W,
deﬁne for any j ̸= k in {b, c, p} distinct from i:
≺τi = ≺′
⇐⇒
⎧
⎪
⎨
⎪
⎩
≺= ∅, j ≺′ i, k ≺′ i,
or j ≺i, j ≺k, j ≺′ k ≺′ i,
≺= ≺′ otherwise;
(13.11)
≺τ−i = ≺′
⇐⇒
⎧
⎪
⎨
⎪
⎩
≺= ∅, i ≺′ j, i ≺′ k,
or i ≺j, k ≺j, i ≺′ k ≺′ j,
≺= ≺′ otherwise.
(13.12)
The reverses ˜τi and ˜τ−i are then automatically deﬁned. Writing T for the
collection of all such tokens, it is easily veriﬁed that (W, T) is a medium. (The
digraph of Figure 13.5 represented in black deﬁnes a mediatic graph.)
As two polls have been taken, the data consists of the numbers of respon-
dents having given thermometer scores consistent with a pair (≺, ≺′) for each
pair of weak orders on W. We are thus in the framework of the continuous
random walks on media developed in Chapter 12. We suppose that the ﬁrst
poll was taken at time t, long after the beginning of the campain, and the
second poll at time t + δ, with δ relatively short. The asymptotic Theorems

 3EB 2QL@E>PQF@  K>IVPFP LC .MFKFLK /LIIP

b
c
p
b     c
b
p     c
    c
p     c
    b
    p
b     c
p
b
c
p
c
b
b
c
p     b
b
c
p
b
p
c
p
b
c
p
c
b
b
c
p
c
p
b
c
b
p
b
p
c
    p
b     c
    c
p     b
    b
p     c
p     c
    b
p     b
    c
b     c
    p
T-c
Tp
Tp
Tp
Tc
Tc
Tc
Tb
Tb
Tb
Xo
Xo
Xo
Xo
Xo
Xo
Xo
Xo
Xo
Xo
Xo
Xo
Xo
T-c
T-p
T-p
T-b
T-b
T-b
T-p
T-c
(%  (K ?I>@H LKIV AFDO>ME LC QEB JBAFRJ LC >II QEB TB>H LOABOP LK QEB PBQ
& ' 1 3EB CRII AFDO>ME OBMOBPBKQP QEB JBAFRJ LC >II QELPB TB>H LOABOP QLDBQEBO
TFQE QEBFO =COLWBK PF?IFKDP FKAF@>QBA FK M>IB OBA $>@E TB>H LOABO FP OBMOBPBKQBA ?V
FQP '>PPB AF>DO>J 3L PFJMIFCV QEB DROB LKIV QEB @BKQOFCRD>I QLHBKP >OB FKAF@>QBA
LK QEB DO>ME 3EB B B@Q LC > QLHBK FP QL =MRPE > @>KAFA>QB LKB PQBM RM LO ALTK FK
QEB TB>H LOABO PBB QEB QBUQ CLO ABQ>FIP
 CPF  CTG VJWU GURGEKCNN[ TGNGXCPV $RRNKGF VQ VJG EWTTGPV UKVWCVKQP
7JGQTGO  UVCVGU VJCV HQT CP[ VYQ  	 KP 
NKO
8
  8 "   8 "	
"
 
 


 
 
 
.
-,
/


"
/

E 	/? 
E
.
-,
/



KP YJKEJ 

300
13 Applications
ϑτ
is the probability of token τ ∈T, with τ = τi, τ = ˜τi, τ = τ−i or
τ = ˜τ−i, i ∈{b, c, p} (with a similar convention for ϑµ);
ξ≺,≺′(k)
is the probability of transition from state ≺to state ≺′ in k steps
of the random walk (that is, the entry for the cell (≺, ≺′) in the
kth power of the transition matrix);
λ
is the parameter of the Poisson process governing the delivery of
the tokens.
Note that, because the election took place between the two polls, the token
probabilities involved in the factor ξ≺,≺′(k) in B, which represents the cell
(≺, ≺′) in the kth power of the transition matrix of the random walk, should
not be assumed to be identical to those entering in the computation of the
factor A in (13.13). Also, it makes sense to allow all the parameters to be dif-
ferent for the three political aﬃlliations. The hypothesis that these parameters
were identical was tested and soundly rejected.
Actually, in the application of the model to the polling data performed by
Regenwetter et al. (1999), the political aﬃliation was represented by a random
variable12 with the eﬀect that the actual equation used for the prediction is
somewhat more complicated than (13.13). Also, the summation factor B in
(13.13) was replaced by an approximation. The parameters were estimated
by two methods: by minimizing the Chi-square statistic and by maximizing
the log-likelihood of the data, using a Conjugate Gradient Algorithm in both
cases. An example of the results is given in Table 13.2, which displays both
the data at the top of the cell, that is the number of responses for each pair
of weak orders, and the predictions of the model at the bottom13. There
were, obviously, a similar table for each of the two other aﬃliations of the
respondents.
While the ﬁt of the model to the data was satisfactory from a statistical
standpoint, it was noticed that most of the discrepancy between the model
and the data came from the diagonals of the three tables, which contained rel-
atively large numbers for the data entries. This can be veriﬁed in Table 13.2, in
which these numbers are set in bold font (see the diagonal cells). In fact, these
numbers are maximal for their row and column in all cases except three. In
other words, the respondents—or at least some of them—had a striking aver-
sion against changing their mind about the candidates, a feature which was
not represented in the weak order model. To account for such a phenomenon,
Hsu et al. (2005) imagined a mechanism, operating in conjunction with the
weak order model, by which some respondents might at a certain point “tune
12 The random selection of the panel of respondents was performed without any a
priori control of the political aﬃliation.
13 A dash in a cell indicates an empirical frequency of 0. Such cells were pooled with
others for the analysis. We do not enter into such details of the analysis here (see
Regenwetter et al., 1999; Hsu and Regenwetter, in press).

13.4 The Stochastic Analysis of Opinion Polls
301
Table 13.2. Results of the two polls for the respondents classifying themselves
as independents. The rows refer to the ﬁrst poll. Each cell contains the observed
number of respondents (top) and the number predicted by the weak order model
(bottom).
b
p
c
b
p
c
p
b
c
p
b
c
p
c
b
c
p
b
c
p
b
c
b
p
c
b
p
b
c
p
b
c
p
b
c
p
∅
b
p
c
26
21
3
7
6
4
-
-
2
1
1
0
-
2
1
4
2
10
9
14
10
3
2
b
p
c
4
4
5
5
10
7
1
3
-
2
1
-
-
1
1
4
1
1
1
3
2
1
1
p
b
c
8
4
10
10
17
20
10
9
10
8
1
3
2
1
-
-
2
2
-
-
1
3
p
b
c
3
1
3
3
7
7
10
6
7
11
5
5
-
3
1
-
2
1
1
1
1
1
1
2
p
c
b
1
0
1
2
3
5
9
8
38
30
12
14
12
9
-
-
2
1
2
0
2
0
-
c
p
b
1
0
1
1
-
1
2
8
10
6
7
13
10
3
2
2
2
2
1
-
3
0
-
c
p
b
-
-
-
1
1
6
5
11
8
58
71
9
10
9
9
-
2
0
-
2
1
c
b
p
-
-
-
-
2
1
3
3
13
14
10
7
10
11
-
1
1
-
3
1
c
b
p
1
0
-
-
1
1
3
2
3
4
33
19
15
18
37
35
5
8
3
3
1
1
-
b
c
p
-
2
2
3
1
3
2
2
2
5
3
2
5
1
5
11
10
17
7
3
7
2
3
3
2
b
c
p
13
11
2
3
4
1
3
2
1
1
-
-
3
2
10
6
11
10
32
32
11
18
2
4
b
c
p
9
8
-
2
1
1
1
1
1
-
1
1
1
1
2
2
3
3
6
11
15
8
3
2
∅
1
1
2
1
1
1
2
1
-
3
2
2
3
3
1
-
3
1
1
1
1
1
4
1
out” and stop paying attention to the stimuli relevant to the campaign. This
could happen under the inﬂuence of some unobservable or unrecorded event,
such as excessively negative campaigning, or simply “election fatigue.” Such
respondents might of course at some point “tune in” again for some reason or
other. This mechanism was implemented in a framework very similar to that
of the weak order model by the introduction, for each weak order ≺∈W, of a
frozen sibling ≺∗representing the same weak order on {b, c, p} but a diﬀerent
state of the medium, in which the respondent was momentarily impervious to
events of the campaign. Two new types of mutually reverse tokens were also
introduced, the eﬀect of which was to induce a respondent to change his or
her state from ≺to ≺∗or vice versa. To avoid a substantial increase in the
number of parameters in the model, they assumed that the same pair of pa-
rameters ξo and ˜ξo were governing the probabilities of transition between any
weak order of a standard kind and its frozen sibling. The resulting medium,
whose graph is indicated in Figure 13.5, was referred to as the tune-in-and-out
extension of the weak order model, or TIO extension. Note that each frozen

302
13 Applications
sibling is pictured in pale red and partly hidden behind its corresponding
‘responsive’ sibling. Following our previous convention, only the centrifugal
tokens are represented in the graph.
The idea behind the TIO extension can obviously be applied to other order
relations, such as the semiorders or the linear orders. The TIO extension of
the weak order model was systematically tested, together with a variety of
other models, by Hsu and Regenwetter (in press). It was shown to provide the
best explanation, among those considered, for the panel data collected for the
three US presidential election of 1992, 1996 and 2000.
13.5 Concluding Remarks
The two applications described this chapter have led to extensive empirical
implementation. The learning spaces discussed in the ﬁrst part of the chapter
enable the assessment engine of a mathematical education software used today
by several hundreds thousands students in the US and elsewhere. The random
walks on media have been successfully and repeatedly used for the study of
opinion polls, based on large sets of data.
On the face of it, these applications diﬀer widely. The most important
diﬀerence lies in the conceptual meanings of the states of the medium in the
two cases. In the learning spaces, a state is a collection of problem types
that a student has mastered in a mathematical topic, while in the case of the
opinion polls, a state is an order relation, such as a weak order, a semiorder
or a linear order. Another important distinction concerns the way probability
and stochastic processes are used in the two cases.
Yet, the concept of a medium is at the core of the structure in both cases,
and the role played by the axioms is essential. It is our view that these two
examples are only the beginning of a potentially long list of applications.
To identify those empirical cases susceptible of an interpretation in terms of
media, some criteria have to be fulﬁlled, which we review here as our parting
pointer. There are four such criteria.
1. The set of features. There must be a fundamental set of deﬁning
features or units: the problem types in the learning spaces are such features.
When the states are order relations, the features may be the ordered pairs of
some basic set. But not always. Sometimes, the features may be quite subtle.
What could be the units in the case of the weak orders? Why shouldn’t the
ordered pairs form these units in such a case (Problem 13.5)?
2. The states or the organisms made of those features. Each of the
states must be deﬁnable by a unique subset of those features. Media theory
provides the algorithm for ﬁnding this subset: it consists of the content of the
state.
3. The links between the states or the organisms. Even though the
states can be very large, even uncountable, there is always at least one direct,
ﬁnite path—a sequence of features—from on state S to another state V . This

Problems for Chapter 13
303
path tells you exactly in what way S and V diﬀer. Actually, the path can be
viewed as an algorithm for constructing a state from another state.
The above description begins to suggest possible applications in biology
(genetics), chemistry, or other ﬁelds in which the basic objects are made of
parts assembled in a certain way. However, there is a critical restriction:
4. In general, there is no golden path between two states. When
there are several paths—we have called those ‘messages’—all of them must
have the same length, and must go through the same steps—we have called
them ‘tokens’. Only the order of those steps may diﬀer.
Problems
13.1 On the basis of the Hasse diagram of Figure 13.1, specify completely
the entailment relation restricted to the six problem types (a)-(f).
13.2 Verify that the r.h.s. of (13.1) deﬁnes an equivalence relation on Q, for
any knowledge structure K. Clarify the relationship between that equivalence
relation and the quasi orders in the statement of Theorem 13.1.5.
13.3 Prove Theorem 13.2.1.
13.4 Design an algorithm for selecting p1 (and p2, p3, . . .) which is maximally
informative in a sense diﬀerent from that described on page 294, and based
on the idea of minimizing the expected entropy of the probability distribution
on the set of knowledge states on the next trial of the assessment.
13.5 What are the ‘units’ making the states in the example of the opinion
polls analyzed in terms of weak orders (cf. our question on page 302). How
is the deﬁnition of a unit changed in the TIO extension of the weak order
model?
13.6 How many parameters must be estimated in the weak order model with
a panel selected with a ﬁxed number of respondents, but random subsamples
of independents, democrat and republicans?
13.7 Write an expression based on Eq. (13.13) for the joint probability of
observing (after recoding the thermometer scores) the weak orders ≺and ≺′
at times t and t + δ (respectively) for large t and for a respondent selected
randomly in a panel composed of N respondents, with ni independents, nd
democrats, and nr republicans.
13.8 Can you think of plausible application of stochastic media theory in
sport, based on one or more rankings of a ﬁxed set of top athletes, based on
their performance and updated weekly? How about developing the equations
of a model for such an aplication?

Appendix: A Catalog of Small Mediatic Graphs
p connected bipartite graphs mediatic graphs trees
2
1
1
1
3
1
1
1
4
3
3
2
5
5
4
3
6
17
12
6
7
44
25
11
8
182
78
23
Table A. The number of connected bipartite graphs, mediatic graphs, and trees
with 2–8 vertices.
Any tree T with q edges and m leaves is a mediatic graph of isometric
dimension dimI(T) = q and of lattice dimesion dimZ(T) = ⌈m/2⌉.
All mediatic graphs with less than nine vertices that are not trees are
shown in Figures A.1–A.3. The numbers p, q; r, s at the bottom of cells stand
for:
p - the number of vertices of the graph,
q - the number of edges of the graph,
r - the isometric dimension of the graph,
s - the lattice dimension of the graph.
The coloring of vertices corresponds to the bipartition of the vertex set.

306
Appendix
4, 4; 2, 2
M1
M2
5, 5; 3, 2
M3
6, 6; 4, 2
M4
6, 6; 4, 2
M5
6, 6; 4, 2
M6
6, 6; 3, 3
M7
6, 7; 3, 2
7, 7; 5, 2
M8
M9
7, 7; 5, 3
M10
7, 7; 5, 2
M11
7, 7; 4, 3
M12
7, 7; 5, 3
M13
7, 7; 5, 3
M14
7, 7; 5, 2
M15
7, 7; 5, 2
M16
7, 7; 5, 2
M17
7, 7; 5, 2
M18
7, 8; 4, 2
M19
7, 8; 4, 2
M20
7, 8; 4, 2
M21
7, 9; 3, 3
Figure A.1.Mediatic graphs with 4–7 vertices; not trees.

Small Mediatic Graphs
307
M22
M23
M24
M25
M26
M27
M28
M29
M30
M31
M32
M33
M38
M35
M36
M37
M39
M40
M41
M42
M43
M44
M45
M46
M47
M48
M49
8, 8; 6, 2
8, 8; 6, 3
8, 8; 6, 3
8, 8; 6, 2
8, 8; 6, 2
8, 8; 6, 2
8, 8; 5, 3
8, 8; 6, 2
8, 8; 6, 2
8, 8; 5, 3
8, 8; 6, 2
8, 8; 6, 3
8, 8; 6, 2
M34
8, 8; 6, 2
8, 8; 6, 2
8, 8; 6, 3
8, 8; 6, 3
8, 8; 4, 4
8, 8; 6, 2
8, 8; 5, 3
8, 8; 6, 2
8, 8; 6, 2
8, 8; 6, 2
8, 8; 5, 3
8, 8; 5, 3
8, 8; 6, 2
8, 8; 6, 2
8, 8; 6, 2
Figure A.2. Mediatic graphs with 8 vertices, part I; not trees.

308
Appendix
M50
M51
M52
M53
M54
M55
M56
M57
M58
M59
M60
M61
M62
M63
M64
M65
M66
M67
M68
M69
M70
M71
M72
M73
M74
M75
M76
M77
8, 8; 6, 2
8, 8; 6, 2
8, 8; 6, 2
8, 8; 6, 3
8, 8; 6, 2
8, 8; 6, 3
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 3
8, 9; 5, 3
8, 9; 4, 3
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 9; 5, 2
8, 10; 4, 3
8, 10; 4, 2
8, 10; 4, 3
8, 10; 4, 2
8, 10; 4, 3
8, 10; 4, 3
8, 12; 3, 3
Figure A.3. Mediatic graphs with 8 vertices, part II; not trees.

Glossary
⇔
the logical equivalence standing for ‘if and only if’
&, ¬
the logical conjunction ‘and’ and negation ‘not’
∃, ∀
existential and universal quantiﬁers
∅
empty set
∈
set membership
⊆, ⊂
set inclusion, and proper (or strict) set inclusion
∪, ∩, \
union, intersection, and diﬀerence of sets
+, 
ordinary addition or the union of disjoint sets
f(B)
if B is a set and f a function, the image of B by f
|X|
number of elements (or cardinality) of a set X
P(X)
power set of the set X (i.e., the set of all subsets of X)
Pf(X)
the set of all ﬁnite subsets of X
X1 × . . . × Xn
Cartesian product of the sets X, . . . , Xn
N
the set of all natural numbers 1, . . . , n, . . .
N0
the set of nonnegative integers 0, 1, . . . , n, . . .
Q
the set of all rational numbers
R
the set of all real numbers
R+
the set of all nonnegative real numbers [0, ∞[
Z
the set of all integers
P
a probability measure
S
typically, the set of states of a medium
S
content of a state S
S
family of all the contents of the states in S
token
a mapping τ : S →S : S →Sτ
message
a composition of tokens
T
typically, the set of tokens of a medium
{T+, T−}
a bipartition of T deﬁning an orientation
Sτ
the image of the state S by the token τ
Sm
the image of the state S by the message m

310
]x, y[
open interval of real numbers {z ∈R x < z < y}
[x, y]
closed interval of real numbers {z ∈R x ≤z ≤y}
]x, y], [x, y[
real, half open intervals
˘R
Hasse diagram of a partial order R
R∗
transitive closure of a relation R
S(F), Sf(F)
span and ﬁnite span of a family F of sets
marks the end of a proof
l.h.s., r.h.s.
‘left-hand side’ and ‘right-hand side’ (of a formula)
⟨. . .⟩
betweenness relation for triples of points;
or the class containing “. . .” in a partition;
or a weak order in terms of its indiﬀerence classes
(cf. Theorem 9.4.6)

Bibliography
B. Aspvall, M.F. Plass, and R.E. Tarjan. A linear time algorithm for testing
the truth of certain quantiﬁed Boolean formulas. Information Processing
Letters, 8:121–123, 1979.
A.S. Asratian, T.M.J. Denley, and R. H¨aggkvist. Bipartite Graphs and their
Applications. Cambridge University Press, Cambridge, London, and New
Haven, 1998.
D. Avis and K. Fukuda. Reverse search for enumeration. Discrete Applied
Mathematics, 65:21–46, 1996.
L. Babai and E. Szemer´edi. On the complexity of matrix group problems I.
In Proceedings of the Twenty Fifth Annual IEEE Symposium on Founda-
tions of Computer Science, pages 229–240, Los Alamitos, Calif., 1984. IEEE
Computer Society Press.
H.J. Bandelt. Retracts of hypercubes. Journal of Graph Theory, 8(4):501–510,
1984.
H.J. Bandelt and V. Chepoi. Metric graph theory and geometry: a survey.
Manuscript, 2005.
M. Barbut and B. Monjardet. Ordre et Classiﬁcation. Collection Hachette
Universit´e, Paris, 1970.
A.T. Barucha-Reid.
Elementary Probability with Stochastic Processes.
Springer-Verlag, Berlin, Heidelberg, and New York, 1974.
M.A. Bender and M. Farach-Colton. The LCA problem revisited. In LATIN
2000: Theoretical Informatics, 4th Latin American Symposium, Punta del
Este, Uruguay, April 10-14, 2000, Proceedings, volume 1776 of Lecture
Notes in Computer Science, pages 88–94, Berlin, Heidelberg, and New York,
2000. Springer-Verlag.
L.W. Berman. Symmetric simplicial pseudoline arrangements. Manuscript,
submitted for journal publication., 2007.
S.N. Bhatt and S.S. Cosmodakis. The complexity of minimizing wire lengths
in VLSI layouts. Information Processing Letters, 25:263–267, 1987.

312
Bibliography
P. Bidigare, P. Hanlon, and D. Rockmore. A combinatorial description of
the spectrum for the Tsetlin library and its generalization to hyperplane
arrangements. Duke Mathematical Journal, 99(1):135–174, 1999.
G. Birkhoﬀ. Rings of sets. Duke Mathematical Journal, 3:443–454, 1937.
G. Birkhoﬀ. Lattice Theory. American Mathematical Society, Providence,
R.I., 1967.
A. Bj¨orner, M. Las Vergnas, B. Sturmfels, N. White, and G.M. Ziegler. Ori-
ented Matroids. Cambridge University Press, Cambridge, London, and New
Haven, second edition, 1999.
K.P. Bogart. Maximal dimensional partially ordered sets. I. Hiraguchi’s the-
orem. Discrete Mathematics, 5:21–31, 1973.
K.P. Bogart and W.T. Trotter. Maximal dimensional partially ordered sets.
II. Characterization of 2n-element posets with dimension n. Discrete Math-
ematics, 5:33–43, 1973.
S.A. Bogatyi. Metrically homogeneous spaces. Russian Mathematical Surveys,
57:221–240, 2002.
J.A. Bondy.
Basic graph theory: paths and circuits.
In R.L. Graham,
M. Gr¨otschel, and L. Lov´asz, editors, Handbook of Combinatorics, vol-
ume 1. The M.I.T. Press, Cambridge, MA, 1995.
J.A. Bondy and U.S.R. Murphy. Graph Theory with Applications. North-
Holland Publishing Co., Amsterdam and New York, 1976.
N. Bourbaki. Lie Groups and Lie Algebras. Springer-Verlag, Berlin, Heidel-
berg, and New York, 2002.
V.J. Bowman. Permutation polyhedra. SIAM Journal on Applied Mathemat-
ics, 22:580–589, 1972.
G.S. Brodal and L. G¸asieniec. Approximate dictionary queries. In Proceedings
of the 7th Annual Symposium on Combinatorial Pattern Matching, pages
65–74, 1996.
K.S. Brown and P. Diaconis. Random walks and hyperplane arrangements.
Annals of Probability, 26(4):1813–1854, 1998.
D. Burago, Y. Burago, and S. Ivanov. A Course in Metric Geometry. American
Mathematical Society, Providence, R.I., 2001.
R.G. Busacker and T.L. Saaty. Finite Graphs and Networks—An Introduction
with Applications. McGraw-Hill, Boston and New York, 1965.
D.R. Cavagnaro. Projection of a medium. Submitted to Journal of Mathe-
matical Psychology, 2006.
T.M. Chan. On levels in arrangements of curves. Discrete and Computational
Geometry, 29(3):375–393, April 2003.
V. Chepoi, F. Dragan, and Y. Vax`es. Center and diameter problems in plane
triangulations and quadrangulations. In Proceedings of the Thirteenth An-
nual ACM-SIAM Symposium on Discrete Algorithms, pages 346–355, Jan-
uary 2002.
J.S. Chipman. Consumption theory without transitive indiﬀerence. In J.S.
Chipman, L. Hurwicz, M.K. Richter, and H.F. Sonnenschein, editors, Pref-

Bibliography
313
erences, Utility, and Demand, pages 224–253. Harcourt Brace Jovanovich,
1971.
K.L. Chung.
Markov Chains with Stationary Transition Probabilities.
Springer-Verlag, Berlin, Heidelberg, and New York, 2nd edition, 1967.
O. Cogis. Ferrers digraphs and threshold graphs. Discrete Mathematics, 38:
33–46, 1982.
T.H. Cormen, C.E. Leiserson, R.L. Rivest, and C. Stein.
Introduction to
Algorithms. The M.I.T. Press, Cambridge, MA, 2nd edition, 2003.
E. Cosyn and N. Thi´ery. A Practical Procedure to Build a Knowledge Struc-
ture. Journal of Mathematical Psychology, 44:383–407, 2000.
E. Cosyn and H.B. Uzun. Axioms for learning spaces. To be submitted to
Journal of Mathematical Psychology, 2005.
H.S.M. Coxeter. Regular Polytopes. Dover, 1973.
B.A. Davey and H.A. Priestley. Introduction to Lattices and Order. Cam-
bridge University Press, Cambridge, London, and New Haven, 1990.
N.G. de Bruijn. Algebraic theory of Penrose’s non-periodic tilings of the plane.
Indagationes Mathematicae, 43:38–66, 1981.
H. de Fraysseix and P. Ossona de Mendez.
Stretching of Jordan arc con-
tact systems. In Graph Drawing: 11th International Symposium, GD 2003,
Perugia, Italy, September 21–24, 2003, volume 2912 of Lecture Notes in
Computer Science, pages 71–85, Berlin, Heidelberg, and New York, 2004.
Springer-Verlag.
M. Deza and M. Laurent. Geometry of Cuts and Metrics. Springer-Verlag,
Berlin, Heidelberg, and New York, 1997.
M. Deza and M.I. Shtogrin. Mosaics and their isometric embeddings. Izvestia:
Mathematics, 66:443–462, 2002.
G. Di Battista and R. Tamassia. Incremental planarity testing. In Proceedings
of the Thirtieth Annual IEEE Symposium on Foundations of Computer
Science, pages 436–441, Los Alamitos, Calif., 1989. IEEE Computer Society
Press.
G. Di Battista, P. Eades, R. Tamassia, and I.G. Tollis.
Graph Drawing:
Algorithms for the Visualization of Graphs. Prentice Hall, Englewood Cliﬀs,
New Jersey, 1999.
R. Diestel. Graph Theory. Springer-Verlag, Berlin, Heidelberg, and New York,
2000.
R.P. Dilworth. Lattices with unique irreducible decompositions. Annals of
Mathematics, 41:771–777, 1940.
D.Z. Djokovi´c.
Distance preserving subgraphs of hypercubes.
Journal of
Combinatorial Theory, Ser. B, 14:263–267, 1973.
C.W. Doble, J.-P. Doignon, J.-Cl. Falmagne, and P.C. Fishburn.
Almost
connected orders. Order, 18(4):295–311, 2001.
J.-P. Doignon and J.-Cl. Falmagne. Well-graded families of relations. Discrete
Mathematics, 173:35–44, 1997.
J.-P. Doignon and J.-Cl. Falmagne.
Knowledge Spaces.
Springer-Verlag,
Berlin, Heidelberg, and New York, 1999.

314
Bibliography
J.-P. Doignon and J.-Cl. Falmagne. Spaces for the Assessment of Knowledge.
International Journal of Man-Machine Studies, 23:175–196, 1985.
J.-P. Doignon, A. Ducamp, and J.-Cl. Falmagne. On realizable biorders and
the biorder dimension of a relation. Journal of Mathematical Psychology,
28:73–109, 1984.
C.E. Dowling. Applying the basis of a knowledge space for controlling the
questioning of an expert. Journal of Mathematical Psychology, 37:21–48,
1993a.
C.E. Dowling. On the irredundant construction of knowledge spaces. Journal
of Mathematical Psychology, 37:49–62, 1993b.
C.E. Dowling. Integrating diﬀerent knowledge spaces. In G.H. Fischer and
D. Laming, editors, Contributions to Mathematical Psychology, Psychomet-
rics, and Methodology, pages 149–158. Springer-Verlag, Berlin, Heidelberg,
and New York, 1994.
A. Ducamp and J.-Cl. Falmagne. Composite measurement. Journal of Math-
ematical Psychology, 6:359–390, 1969.
B. Dushnik and E.W. Miller. Partially ordered sets. American Journal of
Mathematics, 63:600–610, 1941.
J. Ebert. st-ordering of the vertices of biconnected graphs. Computing, 30:
19–33, 1983.
P.H. Edelman and R. Jamison. The theory of convex geometries. Geometrica
Dedicata, 19:247–271, 1985.
H. Edelsbrunner. Algorithms in Combinatorial Geometry. Springer-Verlag,
1987.
D. Eppstein. Happy endings for ﬂip graphs. In Proc. 23rd Annual ACM Symp.
Computational Geometry, 2007a.
Electronic preprint cs.CG/0610092,
arXiv.org.
D. Eppstein. Algorithms for drawing media. In Graph Drawing: 12th Interna-
tional Symposium, GD 2004, New York, NY, USA, September 29–October
2, 2004, volume 3383 of Lecture Notes in Computer Science, pages 173–183,
Berlin, Heidelberg, and New York, 2005a. Springer-Verlag.
D. Eppstein. The lattice dimension of a graph. European Journal of Combi-
natorics, 26(6):585–592, 2005b.
D. Eppstein. Upright-quad drawing of st-planar learning spaces. In Graph
Drawing: 14th International Symposium, GD 2006, Karlsruhe, Germany,
September 18–20, 2006, Lecture Notes in Computer Science, Berlin, Hei-
delberg, and New York, 2006. Springer-Verlag.
D. Eppstein. Recognizing partial cubes in quadratic time. Electronic preprint
0705.1025, arXiv.org, 2007b.
D. Eppstein and J.-Cl. Falmagne. Algorithms for media. Electronic preprint
cs.DS/0206033, arXiv.org, 2002.
D. Eppstein, J.-Cl. Falmagne, and H.B. Uzun. On verifying and engineering
the well-gradedness of a union-closed family. Electronic preprint 0704.2919,
arXiv.org, 2007.

Bibliography
315
S. Even and R.E. Tarjan. Computing an st-numbering. Theoretical Computer
Science, 2:339–344, 1976.
J.-Cl. Falmagne. Lectures in Elementary Probability and Stochastic Processes.
McGraw-Hill, Boston and New York, 2003.
J.-Cl. Falmagne. A stochastic theory for the emergence and the evolution of
preference structures. Mathematical Social Sciences, 31:63–84, 1996.
J.-Cl. Falmagne. Stochastic token theory. Journal of Mathematical Psychol-
ogy, 41(2):129–143, 1997.
J.-Cl. Falmagne and J.-P. Doignon. Stochastic evolution of rationality. Theory
and Decision, 43:107–138, 1997.
J.-Cl. Falmagne and J-P. Doignon. A class of stochastic procedures for the
assessment of knowledge. British Journal of Mathematical and Statistical
Psychology, 41:1–23, 1988a.
J.-Cl. Falmagne and J-P. Doignon. A Markovian procedure for assessing the
state of a system. Journal of Mathematical Psychology, 32:232–258, 1988b.
J.-Cl. Falmagne and S. Ovchinnikov. Media theory. Discrete Applied Mathe-
matics, 121:83–101, 2002.
J.-Cl. Falmagne and S. Ovchinnikov. Mediatic graphs. Electronic preprint
0704.0994, arXiv.org, 2007.
J.-Cl. Falmagne, M. Regenwetter, and B. Grofman. A stochastic model for
the evolution of preferences. In A.A.J. Marley, editor, Choice, Decision and
Measurement: Essays in Honor of R. Duncan Luce. Erlbaum, New Jersey
and London, 1997.
J.-Cl. Falmagne, E. Cosyn, C. Doble, N. Thi´ery, and H.B. Uzun. Assessing
Mathematical Knowledge in a Learning Space: Validity and/or Reliability.
Submitted to Psychological Review, 2006a.
J.-Cl. Falmagne, E. Cosyn, J.-P. Doignon, and N. Thi´ery. The assessment of
knowledge, in theory and in practice. In B. Ganter and L. Kwuida, edi-
tors, Formal Concept Analysis, 4th International Conference, ICFCA 2006,
Dresden, Germany, February 13–17, 2006, Lecture Notes in Artiﬁcial Intel-
ligence, pages 61–79. Springer-Verlag, Berlin, Heidelberg, and New York,
2006b.
J.-Cl. Falmagne, Y.-F. Hsu, F. Leite, and M. Regenwetter. Stochastic appli-
cations of media theory: Random walks on weak orders or partial orders.
Discrete Applied Mathematics, 2007. doi: 10.1016/j.dam.2007.04.032.
W. Feller. An Introduction to Probability Theory and its Applications, vol-
ume 1. John Wiley & Sons, London and New York, 3rd edition, 1968.
S. Felsner and H. Weil. Sweeps, arrangements and signotopes. Discrete Ap-
plied Mathematics, 109(1):67–94, April 2001.
S. Fiorini and P.C. Fishburn. Weak order polytopes. Discrete Mathematics,
275:111–127, 2004.
P.C. Fishburn.
Utility Theory for Decision Making.
John Wiley & Sons,
London and New York, 1970.
P.C. Fishburn.
Interval orders and interval graphs.
John Wiley & Sons,
London and New York, 1985.

316
Bibliography
P.C. Fishburn.
Generalizations of semiorders: A review note.
Journal of
Mathematical Psychology, 41:357–366, 1997.
P.C. Fishburn and W.T. Trotter. Split semiorders. Discrete Mathematics,
195:111–126, 1999.
P. Frankl.
Extremal Set Systems.
In R.L. Graham, M. Gr¨otschel, and
L. Lov´asz, editors, Handbook of Combinatorics, volume 2. The M.I.T. Press,
Cambridge, MA, 1995.
P. Gaiha and S.K Gupta.
Adjacent vertices on a permutohedron.
SIAM
Journal on Applied Mathematics, 32(2):323–327, 1977.
B. G¨artner and E. Welzl. Vapnik-Chervonenkis dimension and (pseudo-)hy-
perplane arrangements.
Discrete and Computational Geometry, 12:399–
432, 1994.
J.G. Gimbel and A.N. Trenk.
On the weakness of an ordered set.
SIAM
Journal of Discrete Mathematics, 11(4):655–663, 1998.
S. Ginsburg. On the length of the smallest uniform experiment which distin-
guishes the terminal states of a machine. Journal of the ACM, 5:266–280,
1958.
S.W. Golomb.
Polyominoes: Puzzles, Patterns, Problems, and Packings.
Princeton Science Library. Princeton University Press, NJ, 2nd edition,
1994.
R.L. Graham and H. Pollak. On addressing problem for loop switching. Bell
Systems Technical Journal, 50:2495–2519, 1971.
B. Gr¨unbaum. Arrangements and Spreads. Number 10 in Regional Conference
Series in Mathematics. American Mathematical Society, Providence, R.I.,
1972.
B. Gr¨unbaum and G.C. Shephard. Tilings and Patterns. W.H. Freeman, New
York, 1987.
I. Gutman and S.J. Cyvin. Introduction to the Theory of Benzenoid Hydro-
carbons. Springer-Verlag, Berlin, Heidelberg, and New York, 1989.
L. Guttman.
A basis for scaling qualitative data.
American Sociological
Review, 9:139–150, 1944.
F. Hadlock and F. Hoﬀman.
Manhatten trees.
Utilitas Mathematica, 13:
55–67, 1978.
K. Handa. A characterization of oriented matroids in terms of topes. European
Journal of Combinatorics, 11:41–45, 1990.
F. Harary. Graph Theory. Addison-Wesley, Reading, Mass., 1969.
Y.-F. Hsu and M. Regenwetter. Application of stochastic media theory to
1992, 1996 and 2000 national election study panel data. Chinese Journal of
Psychology, in press.
Y.-F. Hsu, J.-Cl. Falmagne, and M. Regenwetter.
The tuning in-and-out
model: a random walk and its application to presidential election surveys.
Journal of Mathematical Psychology, 49:276–289, 2005.
W. Imrich and S. Klavˇzar. Product Graphs. John Wiley & Sons, London and
New York, 2000.

Bibliography
317
W. Imrich, S. Klavˇzar, and H.M. Mulder. Median graphs and triangle-free
graphs. SIAM Journal on Discrete Mathematics, 12(1):111–118, 1999.
M.F. Janowitz. On the semilattice of weak orders of a set. Mathematical
Social Sciences, 8:229–239, 1984.
D. Joyner. Adventures in Group Theory—Rubik’s Cube, Merlin’s Machine,
and other Mathematical Toys. The Johns Hopkins University Press, Balti-
more and London, 2002. ISBN 0-8018-6947-1.
M. Kambouri. Knowledge assessment: A comparison between human experts
and computerized procedure. PhD thesis, New York University, New York,
1991.
M. Kambouri, M. Koppen, M. Villano, and J.-Cl. Falmagne. Knowledge as-
sessment: Tapping human expertise by the QUERY routine. International
Journal of Human-Computer Studies, 40:119–151, 1994.
R.M. Karp, E. Upfal, and A. Wigderson. Are search and decision problems
computationally equivalent?
In Proceedings of the Seventeenth Annual
ACM Symposium on Theory of Computing, pages 464–475, May 1985.
J.G. Kemeny and J.L. Snell. Finite Markov Chains. Van Nostrand, Princeton,
N.J., 1960.
J.G. Kemeny and J.L. Snell. Mathematical Models in Social Sciences. The
M.I.T. Press, Cambridge, MA, 1972.
D. K¨onig. ¨Uber Graphen und ihren Anwendung auf Determinanten-theorie
und Mengenlehre. Mathematische Annalen, 77:453–465, 1916.
M. Koppen. Extracting human expertise for constructing knowledge spaces:
An algorithm. Journal of Mathematical Psychology, 37:1–20, 1993.
M. Koppen. Ordinal Data Analysis: Biorder Representation and Knowledge
Spaces.
Doctoral dissertation, Katholieke Universiteit te Nijmegen, Ni-
jmegen, The Netherlands, 1989.
B. Korte, L. Lov´asz, and R. Schrader. Greedoids. Number 4 in Algorithms
and Combinatorics. Springer-Verlag, 1991.
V.B. Kuzmin and S. Ovchinnikov. Geometry of preference spaces I. Automa-
tion and Remote Control, 36:2059–2063, 1975.
V.B. Kuzmin and S. Ovchinnikov. Geometry of preference spaces II. Automa-
tion and Remote Control, 37:110–113, 1976.
Cl. Le Conte de Poly-Barbut.
Le diagramme du treillis permutoh`edre est
Intersection des diagrammes de deux produits directs d’ordres totaux.
Math´ematiques, Informatique et Sciences Humaines, 112:49–53, 1990.
G. Lo Faro.
A note on the union-closed sets conjecture.
Journal of the
Australian Mathematical Society, Ser. A, 57:230–236, 1994a.
G. Lo Faro. Union-closed sets conjecture: improved bounds. Journal of Com-
binatorial Mathematics, 16:97–102, 1994b.
R.D. Luce. Semiorders and a theory of utility discrimination. Econometrica,
24:178–191, 1956.
R.D. Luce and E. Galanter. Psychophysical scaling. In R.D. Luce, R.R. Bush,
and E. Galanter, editors, Handbook of Mathematical Psychology, volume 1.
John Wiley & Sons, London and New York, 1963.

318
Bibliography
J. Matouˇsek. The number of unique-sink orientations of the hypercube. Com-
binatorica, 26(1):91–99, 2006.
D.W. Matula. Graph-theoretical cluster analysis. In S. Kotz and N.L. John-
son, editors, Encyclopedia of Statistical Sciences, volume 3. John Wiley &
Sons, London and New York, 1983. C.B. Read, associate editor.
S. Micali and V.V. Vazirani. An O(
√
V E) algorithm for ﬁnding maximum
matching in general graphs. In Proceedings of the Twenty First Annual
IEEE Symposium on Foundations of Computer Science, pages 17–27, Los
Alamitos, Calif., 1980. IEEE Computer Society Press.
B.G. Mirkin. Group Choice. Winston, Washington, D.C., 1979.
B. Monjardet. Axiomatiques et propri´et´es des quasi-ordres. Math´ematique et
Sciences Humaines, 63:51–82, 1978.
E.F. Moore. Gedanken-experiments on sequential machines. Automata Stud-
ies, Princeton University Press, Annals of Mathematics Studies 34:129–153,
1956.
H.M. Mulder. The interval function of a graph. Mathematical Centre Tracts
142, Mathematical Centre, Amsterdam, 1980.
C.E. M¨uller. A procedure for facilitating an expert’s judgments on a set of
rules. In E.E. Roskam, editor, Mathematical Psychology in Progress, Recent
Research in Psychology, pages 157–170. Springer-Verlag, Berlin, Heidelberg,
and New York, 1989.
P. Mutzel.
The SPQR-tree data structure in graph drawing.
In J.C.M.
Baeten, J.K. Lenstra, J. Parrow, and G.J. Woeginger, editors, Automata,
Languages and Programming, 30th International Colloquium, ICALP 2003,
Eindhoven, The Netherlands, June 30–July 4, 2003, volume 2719 of Lecture
Notes in Computer Science, pages 34–46, Berlin, Heidelberg, and New York,
June 2003. Springer-Verlag.
P. Orlik and H. Terano.
Arrangements of Hyperplanes.
Springer-Verlag,
Berlin, Heidelberg, and New York, 1992.
S. Ovchinnikov.
The lattice dimension of a tree.
Electronic preprint
math.CO/0402246, arXiv.org, 2004.
S. Ovchinnikov.
Media theory: representations and examples.
Electronic
preprint arXiv:math/0512282v1, arXiv.org, 2006.
S. Ovchinnikov. Hyperplane arrangements in preference modeling. Journal of
Mathematical Psychology, 49:481–488, 2005.
S. Ovchinnikov. Partial cubes: structures, characterizations and constructions.
Electronic preprint arXiv:0704.0010v1v1, arXiv.org, 2007.
S. Ovchinnikov. Convexity in subsets of lattices. Stochastica, IV:129–140,
1980.
S. Ovchinnikov and A. Dukhovny. Advances in media theory. International
Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 8(1):45–
71, 2000.
E. Parzen. Stochastic Processes. Holden-Day, San Francisco, 1994.
M. Pirlot. Synthetic description of a semiorder. Discrete Applied Mathemat-
ics, 31:299–308, 1991.

Bibliography
319
W. Prenowitz and M. Jordan. Basic Concepts of Geometry. Blaisdell Pub-
lishing Company, Waltham, MA, 1965.
M. Regenwetter, J.-Cl. Falmagne, and B. Grofman. A stochastic model of
preference change and its application to 1992 presidential election panel
data. Psychological Review, 106(2):362–384, 1999.
F. Restle. A metric and an ordering on sets. Psychometrika, 24(3):207–220,
1959.
J. Riguet.
Les relations de Ferrers.
Compte Rendus des Sc´eances de
l’Acad´emie des Sciences (Paris), 232:1729–1730, 1951.
I. Rival, editor. Graphs and Order: The Role of Graphs in the Theory of
Ordered Sets and Its Applications. Reidel, Dordrecht, 1985.
F.S. Roberts. Measurement Theory, with Applications to Decisionmaking,
Utility, and the Social Sciences. Addison-Wesley, Reading, Mass., 1979.
F.S. Roberts. Applied Combinatorics. Prentice Hall, Englewood Cliﬀs, New
Jersey, 1984.
D.G. Sarvate and J.-C. Renaud. On the union-closed sets conjecture. Ars
Combinatoris, 27:149–153, 1989.
D.G. Sarvate and J.-C. Renaud. Improved bounds for the union-closed sets
conjecture. Ars Combinatoris, 29:181–185, 1990.
D. Scott and P. Suppes. Foundational aspects of theories of measurement.
Journal of Symbolic Logic, 23:113–128, 1958.
M. Senechal. Quasicrystals and Geometry. Cambridge University Press, Cam-
bridge, London, and New Haven, 1995.
P.W. Shor. Stretchability of pseudolines is NP-hard. In P. Gritzmann and
B. Sturmfels, editors, Applied Geometry and Discrete Mathematics, vol-
ume 4 of DIMACS Series in Discrete Mathematics and Theoretical Com-
puter Science, pages 531–554. American Mathematical Society, Providence,
R.I., 1991.
M. Skandera. A characterization of (3 + 1)-free posets. Journal of Combina-
torial Theory, Ser. A, 93:655–663, 2001.
R.P. Stanley. Enumerative Combinatorics, volume 2. Wadsworth and Brook-
s/Cole, Monterey, California, 1986.
R.P. Stanley. Hyperplane arrangements, interval orders, and trees. Proceed-
ings of the National Academy of Sciences of the United States of America,
93:2620–2625, 1996.
A.N. Trenk. On k-weak orders: Recognition and a tolerance result. Discrete
Mathematics, 181:223–237, 1998.
W.T. Trotter. Combinatorics and Partially Ordered Sets: Dimension Theory.
The Johns Hopkins University Press, Baltimore and London, 1992.
M. Van de Vel. The theory of convex structures. North-Holland Publishing
Co., Amsterdam and New York, 1993.
T.P. Vaughan. Families implying the Frankl conjecture. European Journal of
Combinatorics, 23:851–860, 2002.
M. Villano.
Computerized knowledge assessment: Building the knowledge
structure and calibrating the assessment routine. PhD thesis, New York

320
Bibliography
University, New York, 1991. In Dissertation Abstracts International, vol.
552, p. 12B.
C. Villee. Biology. W.B. Saunders Company, Philadelphia, 5th edition, 1967.
H. Wainer, N.J. Dorans, D. Eignor, R. Flaugher, B.F. Green, R.J. Mislevy,
L. Steinberg, and D. Thissen. Computerized Adaptive Testing: A Primer.
Lawrence Erlbaum Associates, New Jersey and London, 2000.
D.J.A. Welsh.
Matroids: Fundamental concepts.
In R.L. Graham,
M. Gr¨otschel, and L. Lov´asz, editors, Handbook of Combinatorics, vol-
ume 1. The M.I.T. Press, Cambridge, MA, 1995.
P.M. Winkler. Isometric embedding in products of complete graphs. Discrete
Applied Mathematics, 7:221–225, 1984.
T.-T. Wong, W.-S. Luk, and P.-A. Heng. Sampling with Hammersley and
Halton points. Journal of Graphics Tools, 2(2):9–24, 1997.
T. Zaslavsky. Facing up to arrangements: face count formulas for partitions
of space by hyperplanes, volume 154 of Memoirs of the AMS. American
Mathematical Society, Providence, R.I., 1975.
G.M. Ziegler. Lectures on Polytopes. Springer-Verlag, Berlin, Heidelberg, and
New York, 1995.

Index
K-homogeneous space, 154
P(X)▷◁, cluster partition, 58
P(Z), power set of Z, 12
Pf(Z), 12, 81, 98
WG-homogeneous space, 154
▷◁, 58
∩-closed family, 73, 87
∪-closed family, 73, 78, 79, 86–94
∪f-closed family, 73
⟨S⟩, cluster, 58
d, see Kronecker d
n-star, see star
2-SAT, 221
abstract simplicial complex, see
independence system
accessible, see state
acyclic orientation, 181, 222
adjacency graph, 28
adjacency list, 204
edge-labeled, 205
vertex-labeled, 205
adjacent
states, 4, 23, 277
vertices, 16
algorithm, 199
antisymmetric, see relation
apex, 76, 222
arc, 15
arrangement, see hyperplane, 177
Boolean, 180
braid, 180
central, 177, 180, 185
deformation of, 180
graphical, 183
non-stretchable, 238
of lines, or line arrangement, 5
of right angles, 255
simple, 237
weak pseudoline, 238, 246, 255
Aspvall, B., 221
Asratian, A.S., 143
asymmetric, see relation
asymptotic probabilities, 279
atom, 88
average length, 150
Avis, D., 224
axioms
for a medium, 24
learning space, 10
Babai, L., 223
ball, 171
Bandelt, H.J., 77, 245
Barbut, M., 195
Barucha-Reid, A.T., 263
base, 222
of a ∪-closed family, 86
Bender, M.A., 208
benzenoid graph, 197, 244
Berman, L.W., 238
betweenness, see relation
Bhatt, S., 231
big theta, 166

322
Index
binary, see relation
biorder, see relation
bipartite, see graph
bipartition, 4, 15
Birkhoﬀ’s Theorem, 289
generalisation, 292
Birkhoﬀ, G., 88
Bj¨orner, A., 10, 78, 177
black box medium, 223
Bogart, K.P., 7, 107
Bogatyi, S.A., 154
Bondy, J.A., 17
bounded
face of a drawing, 229
Bourbaki, N., 177
Bowman, V.J., 6
breadth-ﬁrst search, 199
Brodal, G.S., 205
Brown, K.S., 281
Busacker, R.G., 17
Bush, G.H.W., 19, 285, 297
cardinal number, 12
cardinality, 161
Cartesian, see product
Cavagnaro, D.R., 40, 45
cell, 178
center, 47
centrally symmetric, 234
Chan, T., 238
Chapman-Kolmogorov Equation, 267
Chepoi, V., 47, 245
Chung, K.L, 263
circuit
even, 124
in a graph, 16, 124
minimal, 124
class
absorbing, 283
equivalence, 283
ergodic, 283
of a partition, 15
transient, 283
Clinton, W., 19, 285, 297
closed medium, see medium
closedness
condition, see medium
closure
of an E-star, 83
transitive, 14
cluster, 58
analysis, 58
partition, 58
clustered
linear orders, 62–68, 81
Cogis, O., 107
coincident
right angles, 255
commutativity (weak form), 28
complement
of a set, 12
complete, see medium
computational group theory, 223
concise, see message
connected, see graph
consistent, see message
content
of a message, 23
of a state, 29
content family, 29
convex
for media, 135
hull, 171
Cormen, T.H., 199, 203, 204
corner
of a right angle, 255
Cosmodakis, S., 231
Cosyn, E., 10, 78, 286–293
covering relation, see Hasse diagram
Coxeter, H.S.M., 180, 265
critical pair, 106
cube, 139, 253
partial, 139, 200, 201, 204, 210, 211,
218, 227
cubical complex, 194
cycle, 16
length, 16
Cyvin, S.J., 244
Davey, B.A., 88
de Bruijn, N.G., 237
deformation
of an arrangement, 181
degree
of a vertex, 165
Delaunay triangulation, 96
deletion, see mutation
depth-ﬁrst search, 224

Index
323
Deza, M., 157, 164, 165, 235, 237
Di Battista, G., 229, 247, 258
Diaconis, P., 281
Diestel, R., 172
digraph, 15
positive, 82
Dilworth, R.P., 10
dimension, 158
isometric, 158
lattice (integer), 161
lattice (partial cube), 164
oriented lattice, 172
directed, see graph, edge
discrepancy, 233
discriminative, 51, 288
distance (in a graph), 16
distribution
stationary, 271
Djokovi´c, D.Z., 139, 142, 143, 145, 147,
158
Djokovi´c–Winkler relation, 209
Doble, C.W., 101, 114–119
Doignon, J.-P., 7, 10, 17, 30, 51, 86, 88,
92, 101–119, 285–297
Dowling, C.E., 89, 287
downgradable, 103, 118
Dragan, F., 47, 245
drawing, 229
planar, 229
straight-line, 229
upright-quad, 254
Drosophila melanogaster, 11
Ducamp, A., 107
Dukhovny, A., 18, 56
duplication, see mutation
Dushnik, B., 115
E-star, 81
Eades, P., 229, 258
Ebert, J., 252
Edelman, P.H., 10, 78, 92
Edelsbrunner, H., 238
edge, 15
directed, 15
opposite, 124
edge-colouring, 148
eﬀective, see message
embedding, see graph, 34, 37
empty message, see message
entailment, 292
Eppstein, D., 18, 86, 142, 161, 199, 209,
211, 218, 229, 234, 238, 252
equipollent, 12
equivalence, see relation
ergodic, see chain, class, state
Even, S., 252
expansion
of a token, 86
extended star (medium)
see also E-star, 81
exterior
edge, 229
of a right angle, 255
vertex, 229
face poset, 191
Falmagne, J.-Cl., 7, 10, 17–19, 30, 51,
62, 66, 68, 86, 88, 92, 101–119,
123–137, 199, 211, 263, 273,
285–302
Farach-Colton, M., 208
Felsner, S., 234
Fiorini, S., 194
Fishburn, P.C., 107, 114, 115, 194
ﬂip graph, 96
Frankl, P., 94
Fraysseix, H. de, 238
fringe
of a set in a family, 103
inner, 30, 103
outer, 30, 103
Fukuda, K., 224
fully homogeneous space, 154
function
symmetric, 13
F´ary’s theorem, 229
Gaiha, P., 6
Galanter, E., 51
G¸asieniec, L., 205
Gauss puzzle, 1–4
Gauss, C.F., 1
genetic mutation, 11
Gimbel, J.G., 115
Ginsburg, S., 18
Golomb, S.W., 246
grading collection, 53, 57
Graham, P.L., 139

324
Index
graph, 16, 28
st-oriented, 252
adjacency, see adjacency
biconnected, 246
bipartite, 17
connected, 17
directed, 15
directed acyclic, 252
distance, 16
embedding, 17
isomorphic, 17
of a medium, 123
oriented semicube, 173
semicube, 167, 231
triconnected, 246
graph drawing, 229
grid
pentagrid, 237
Grofman, B., 297
group
isometry, 158
of permutations, 7
Gr¨unbaum, B., 177, 234, 238
Gupta, S.K, 6
Gutman, I., 244
Guttman scales, 107
Guttman, L., 107
Hadlock, F., 165
Hammersley points, 233
Harary, F., 58
hash table, 203
Hasse diagram, 14, 20, 183, 189
Heng, P.-A., 233
Hoﬀman, F., 165
hollows, 114
Hsu, Y.-F., 19, 297
Huzun, H.B., 10
hypercube, V, 98, 221, 233
hyperplanes
arrangement, 4, 80, 223
i-closed, see medium
Imrich W., 159
Imrich, W., 77, 142, 147, 150, 244
inconsistent, see message
independence (of axioms), 25
independence system, 73, 78, 192
indicator function, 162, 163
indiﬀerence class, 190
ineﬀective, see message
initial probabilities, 266
input size, 199
instance, 285
integer lattice, 98, 161
integer partition, 165
interior
edge, 229, 244
of a right angle, 255
vertex, 229, 235, 244, 245
inverse of a transformation, 1
inversion, see mutation
isometric subgraph, 8, 16, 26
isometry group, see group
isomorphic, see graph
isomorphism, 37
media, 34
sign-isomorphism, 37
token systems, 34
item, 285
item (of knowledge), 10
Jamison, R., 10, 78, 92
Janowitz, M.F., 191
jigsaw puzzle, 1
Johnson, N.L., 58
jointly consistent, see message
Jordan, M., 70
Joyner, D., 47
k-graded, see well-graded
Kambouri, M., 287, 293
Karp, R.M., 224
Kemeny, J.G., 189, 265
Klavˇzar, S., 77, 142, 147, 150, 159, 244
knowledge state, 10
knowledge structure, 10
K¨onig’s Inﬁnity Lemma, 172
K¨onig, D., 17, 172
Koppen, M., 92, 287–294
Korte, B., 10, 73
Kotz, S., 58
Kronecker d, 274
Kuzmin, V.B., 51, 171
Las Vergnas, M., 177
lattice dimension, 230
Laurent, M., 157, 164, 165

Index
325
Le Conte de Poly-Barbut, Cl., 6
leaf, 17
learning space, 10, 19, 40, 78, 79, 252,
285–293
least common ancestors, 208
Leiserson, C.E., 199, 203, 204
Leite, F., 19
length, see message, see message
of a cycle, 16
of a path, 16
length function, 186
limit, see asymptotic
line arrangement, see arrangement
linear extension, 222
linear medium, see medium
linear order, see relation
linear programming, 223
linear trace, 64
Lo Faro, G., 94
Lov´asz, L., 10, 73
Luce, R.D., 51, 111
Luk, W.-S., 233
Markov chain
aperiodic, 284
ﬁnite, 266
homogeneous, 266
irreducible, 284
Markov, A.A., 265
matching, 168
Matouˇsek, J., 200
Matula, D.W., 58
maximal, see message
median graph, 76, 245
medium, 23
closed, 7, 10, 19, 74, 218
complete, 80
i-closed, 74, 78, 192
linear medium, 68
of a graph, 132
open, 74
rooted, 19, 38
taut, 98
u-closed, 74
message, 23
canonical, 74
circuit (orderly), 128
circuit (regular), 128
concise, 24, 201, 225
consistent, 24
eﬀective, 24
empty, 24, 74
inconsistent, 24
ineﬀective, 24
jointly consistent, 24
length, 24
maximal, 47
mixed, 74
negative, 37, 74
positive, 37, 74
producing, 24
return, 24
return (orderly), 31
return (regular), 34, 34
reverse, 24
stepwise eﬀective, 24
vacuous, 24
metric space, 13
Micali, S., 231
Miller, E.W., 115
minimal element, 14
Mirkin, B.G., 191
Monjardet, B., 195
Moore, E.F., 18
mosaic, 234
of dodecagons, hexagons
and squares, 237
of hexagons, 235, 237
of octagons and squares, 237
of squares, 235, 237
of triangles, 235
of triangles and hexagons, 237
Mulder, H.M., 77
M¨uller, C.E., 287
multigrid, 236
Murphy, U.S.R, 17
mutation, see genetic mutation
deletion, 11
duplication, 11
inversion, 11
translocation, 11
Mutzel, P., 247
nonforced pair, 106
noses, 114
NP-complete, 231
number theory, 165

326
Index
O-notation, 200
opposite, see token
oracle, 223
independence, 224
order
weak, 78, 188
orientation, 4, 6, 7, 9, 37
apex, 76
bipolar, 252
induced, 37
oriented lattice dimension, see
dimension
oriented semicube graph, see graph
Orlik, P., 177
Ossona de Mendez, P., 238
Ovchinnikov, S., 5, 18, 34, 51, 56, 62,
69, 107, 123–137, 165, 171, 186,
191
partial cube, 77, see cube
partial order, see relation
partition, 15
integer, 165
Parzen, E., 263, 274
path
between two vertices, 16
length, 16
tight, 50
pending status, 293
pentagon, 96
permutation, 7
permutohedron, 6, 7
Perot, H.R., 19, 285, 297
Pirlot, M., 114
Plass, M.F., 221
Poisson walk, 275
Pollak, H.O., 139
polygon
centrally symmetric, 234
polyomino, 246
polytope
weak order, 194
poset, 189
positive deﬁniteness, 13
power set, 12, 253
preﬁx, see segment
Prenowitz, W., 70
Priestley, H.A., 88
problem type, 285
producing, see message
product
Cartesian, 13
of relations, 13
projection
isometric, 230
pseudoline, 238
puzzle, 1
Python, 227
QUERY, 287–293
Rado, R., 139
RAM model of computation, 202
random walk, 11, 18, 263
process, 277
Read, C.B., 58
reduction, 35
reﬂexive, see relation
Regenwetter, M., 19, 297–302
region, 178
region graph, 178, 255
regular, see message
relation
n-connected, 103
(strict) weak order, 15
2-connected, 103, 110
ac-order, 114–119
accessibility, 283
antisymmetric, 14, 103
asymmetric, 103
betweenness, 70
binary, 13
biorder, 17, 103, 107–110
communicates, 283
equivalence, 15, 283
Ferrers, 107
identity, 14
indiﬀerence, 186
interval order, 103, 107, 110
irreﬂexive, 103
like, 127, 143
linear order, 6, 14, 62–68, 81
partial order, 14, 20, 103, 283
quasi order, 14
reﬂexive, 14, 103
semiorder, 17, 103, 110–114
strict linear order, 14
strict partial order, 14, 20

Index
327
strongly connected, 14, 103
symmetric, 103
transitive, 14, 103
weak order, 15, 188
weak k-order, 190
relative product, see product
Renaud, J.C., 94
representation theorem, 56
representing function, 186, 189
representing medium, 55
Restle, F., 51
restriction, 35
retraction, 141
return, see message
reverse, 1, see token
reverse search, 224
right angle, 255
Riguet, J., 107
Rival, I., 94
Rivest, R.L., 199, 203, 204
Roberts, F.S., 15, 17
root, 38
Rubik’s Cube, 47
Saaty, T.L., 17
Sarvate, D.G., 94
satisﬁability problem, 221
Schrader, R., 10, 73
Scott, D., 111
segment, 74
initial, 74
negative, 74
positive, 74
preﬁx, 74
suﬃx, 74
terminal, 74
semicube, 142
in a medium, 149
opposite, 142, 149
semicube graph, see graph
semigroup, V
transitivity in, 17
semiorder, see relation, 181
Senechal, M., 234
Shephard, G.C., 234
Shor, P.W., 238, 251
Shtogrin, M.I., 235, 237
sign vector, 178
sign-isomorphism, see isomorphism
simple generator protocol, 227
simplicial complex, see independence
system
sink vertex, 252
Skandera, M., 115
Snell, J.L., 189, 265
source vertex, 252
span of a family of sets, 86
SPQR tree, 247
squaregraph, 245
Stanley, R.P., 177, 183, 186
star (medium), 39, 81, 212, 221, 227
state, 1
absorbing, 284
accessible, 283
aperiodic, 284
ergodic, 283
period (of a state), 284
return, 283
transient, 283
state (of a medium), 23
stationary distribution, 271
Stein, C., 199, 203, 204
stepwise eﬀective, see message
stochastic matrix, see transition
stochastic process, 263
strict linear order, see relation
strict partial order, see relation
Sturmfels, B., 10, 78, 177
subgraph, 8, 16
convex, 145
isometric, 9
submedium, 34, 36, 61
subsystem, see token
suﬃx, see segment
Suppes, P., 111
support, 161
surmise system, 92
symmetric
diﬀerence, 7, 12
diﬀerence distance, 12
system, see token
Szemer´edi, E., 223
Tamassia, R., 229, 247, 258
Tarjan, R.E., 221, 252
taut, see medium
Terano, H., 177
terminal, see segment

328
Index
thermometer score, 297
Thi´ery, N., 287–293
tight, see path
tiling, 234
Penrose, 237
zonotopal, 234
token, 23
opposite, 34
reverse, 23
subsystem, 36
system, 23
Tollis, I.G., 229, 258
tope graph, 180
trace
(well-ordering), 64
linear, 64
transition
matrix, 267
one-step, 266
probabilities, 266
stationary probabilities, 266
transition table, 202
hashed, 203
transitive, see relation
transitive closure, see closure
transitive reduction, 183
translocation, see mutation
tree, 17, 164
Trenk, A.N., 115
triangle inequality, 13
triangulation, 96
trie, 208
Trotter, W.T., 106, 114
truth assignment, 221
u-closed, see medium
Upfal, E., 224
upgradable, 103, 118
upright quadrilateral, 254
Uzun, H.B., 78, 86
vacuous, see message
Van de Vel, M., 92
Vaughan, T.P., 94
Vax`es, Y., 47, 245
Vazirani, V. V., 231
vertex connectivity, 246
Villee, C., 11
walk, 16
closed, open, 16
length, 16
weak order, see relation
Weil, H., 234
well-graded, 51
well-ordering, 14, 63, 64
well-orders, 14
wellgradedness, 15, 17, 51
Welsh, D.J.A., 10, 78
wg-family, 51, 79
White, N., 177
Wigderson, A., 224
Winkler, P., 142, 143, 147
Wong, T.-T., 233
worst-case analysis, 199
Zaslavsky, T., 177
Ziegler, G., 67, 177, 195
zone, 257
zonotopal tiling, 234

